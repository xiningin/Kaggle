{"cell_type":{"8a1b1dfc":"code","de36e38f":"code","1d7aa492":"code","728cf31c":"code","0e85ee01":"code","def84dec":"code","9c1e080b":"code","145f5e82":"code","e73c445a":"code","879af7fe":"code","f10b808f":"code","7cc585c2":"code","605a64fe":"code","6ae4c496":"code","05a9ef97":"code","6d27ad3b":"code","db275877":"code","87b36d5d":"code","a1c0cf2c":"code","64816a22":"code","bdf70a69":"code","d7cd5051":"code","404fef90":"code","239bc021":"code","f146c360":"code","f8c4fa38":"code","06300c02":"code","d6546830":"code","5fca6be8":"code","944c6a71":"code","d0795e35":"code","e1988ee0":"code","e292781a":"code","bc41313d":"code","b5925e8c":"code","8284ea98":"code","692ac7fa":"code","4bec4c40":"code","d1080a3e":"code","5a84a5bb":"code","8452930b":"code","0a6ba56c":"code","040013e8":"code","f567b79f":"code","ed71a8cb":"code","c66a2de8":"code","6c5e45df":"code","d5199d78":"code","6d745b5c":"code","22488bd3":"code","0d1c4228":"code","a6c40b39":"code","57a91cbb":"code","9f678c49":"code","4911c235":"code","24f06bcc":"code","18fefd33":"code","2014d089":"code","3ae719e6":"code","c1db862f":"code","442f5963":"code","3661a0cb":"code","0a7e5713":"markdown","de83d431":"markdown","7c7c852e":"markdown","3f431bfb":"markdown","aa320ad1":"markdown","8730837c":"markdown","425e634b":"markdown","ce0bb679":"markdown","47a1cbea":"markdown","6c32be51":"markdown","f49c39d2":"markdown","45fa0420":"markdown","bf8bafff":"markdown","6a30a2a6":"markdown","b59207ac":"markdown","e05e5b97":"markdown","483d8c8f":"markdown","31c5f3d3":"markdown","a43dcc10":"markdown","610dab60":"markdown","2c953a24":"markdown"},"source":{"8a1b1dfc":"# importing libraries that will be used\nimport numpy as np\nimport pandas as pd\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom collections import Counter\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import roc_auc_score, recall_score\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.ensemble import IsolationForest\nfrom xgboost import XGBClassifier\nfrom imblearn.ensemble import BalancedRandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score,GridSearchCV\nimport optuna","de36e38f":"def imputer(X_train, X_test):\n    imp = SimpleImputer(strategy='median')\n    X_train = imp.fit_transform(X_train)\n    X_test = imp.transform(X_test)\n    \n    X_train = pd.DataFrame(X_train, columns = col)\n    X_test = pd.DataFrame(X_test, columns = col)\n    return X_train, X_test, imp","1d7aa492":"def scaler(X_train, X_test):\n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n    X_test = scaler.transform(X_test)\n    \n    return X_train, X_test, scaler","728cf31c":"def reduction(X_train, X_test):\n    X_train_corr = X_train[:,[-4, -3, -2]]\n    X_test_corr = X_test[:, [-4, -3, -2]]\n    \n    pca = PCA(n_components=1)\n    X_train_reduced = pca.fit_transform(X_train_corr)\n    X_test_reduced = pca.fit_transform(X_test_corr)\n    \n    # removing 3 features from train and test set and adding new feature\n    X_train = X_train[:, :-3]\n    X_test = X_test[:, :-3]\n    X_train = np.hstack((X_train, X_train_reduced))\n    X_test = np.hstack((X_test, X_test_reduced))\n    \n    print('explained variance: ', pca.explained_variance_ratio_.sum())\n    return X_train, X_test, pca","0e85ee01":"def random_over_sample(X_train, y_train, over_sampling_strategy='auto'):\n    over = RandomOverSampler(sampling_strategy=over_sampling_strategy)\n    X_train_resample, y_train_resample = over.fit_resample(X_train, y_train)\n    print(f\"After Over Sampling: {Counter(y_train_resample)}\")    \n    \n    return X_train_resample, y_train_resample","def84dec":"def smote_over_sample(X_train, y_train, over_sampling_strategy='auto'):\n    over = SMOTE(sampling_strategy=over_sampling_strategy)\n    X_train_resample, y_train_resample = over.fit_resample(X_train, y_train)\n    print(f\"After Over Sampling: {Counter(y_train_resample)}\")    \n    \n    return X_train_resample, y_train_resample","9c1e080b":"def random_under_sample(X_train, y_train, under_sampling_strategy='auto'):\n    under = RandomUnderSampler(sampling_strategy=under_sampling_strategy)\n    X_train_resample, y_train_resample = under.fit_resample(X_train, y_train)\n    print(f\"After Under Sampling: {Counter(y_train_resample)}\")\n    return X_train_resample, y_train_resample","145f5e82":"train = pd.read_csv('..\/input\/iba-ml1-mid-project\/train.csv')","e73c445a":"train['credit_line_utilization']=train['credit_line_utilization'].str.replace(',', '.').astype(np.float64)","879af7fe":"X = train.iloc[:,1:-1]\ny = train.iloc[:,-1].values\nX['debt_payment']=X['monthly_income']*X['ratio_debt_payment_to_income']\nX['remain'] = X['monthly_income'] - X['number_dependent_family_members']*250","f10b808f":"X","7cc585c2":"imp = SimpleImputer(strategy='median')\nX = imp.fit_transform(X)","605a64fe":"scale = StandardScaler()\nX = scale.fit_transform(X)","6ae4c496":"pca = PCA(1)\nX_reduced = pca.fit_transform(X[:,7:10])\nX = np.hstack((X,X_reduced))\nprint('explained variance: ', pca.explained_variance_ratio_.sum())","05a9ef97":"X.shape","6d27ad3b":"model = RandomForestClassifier(n_estimators=340)\nmodel.fit(X, y)\nmodel.feature_importances_","db275877":"# dropping less important featurs\nX = X[:, [0, 2, 3, 5, 6, 10, 11, 12]]\nX.shape","87b36d5d":"iso = IsolationForest(contamination=0.05)\nyhat = iso.fit_predict(X)\nmask = yhat != -1\nX, y = X[mask, :] ,y[mask]","a1c0cf2c":"# imbalance before resampling\nCounter(y)","64816a22":"\"\"\"\nfunction uses model to train on one fold of Stratified KFold split(it can be done on all the folds and average can be \ntaken, but it would take longer time for each model and it will be used for final prediction) and then predicts on imbalanced data\ntaken with regular train_test_split to check how model performs when it sees imbalanced data \n\"\"\"\ndef evaluate_model(model, X_resampled, y_resampled, X=X, y=y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.4, random_state=1)\n    cv = StratifiedKFold(7)\n    for train_idx, test_idx in cv.split(X_resampled, y_resampled):\n        X_train = X_resampled[train_idx]\n        y_train = y_resampled[train_idx]\n        model.fit(X_train, y_train)\n        break\n    return roc_auc_score(y_test, model.predict(X_test))","bdf70a69":"# manual over sampling\nX_resampled, y_resampled = random_over_sample(X, y, 0.3)","d7cd5051":"# manual under sampling\nX_resampled, y_resampled = random_under_sample(X_resampled, y_resampled, 0.4)","404fef90":"model_ada = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1, class_weight={0:1,1:2}),\n                   n_estimators=100)\ncv = StratifiedKFold(n_splits=7)","239bc021":"# model evaluation with Stratified KFold split\nscores_ada = cross_val_score(model_ada, X_resampled, y_resampled, scoring='roc_auc', cv=cv)\nscores_ada.mean()","f146c360":"# further evaluation\nevaluate_model(model_ada, X_resampled, y_resampled)","f8c4fa38":"model_xgb = XGBClassifier(use_label_encoder=False, n_estimators=100, max_depth=4, eval_metric='auc')","06300c02":"scores_xgb = cross_val_score(model_xgb, X_resampled, y_resampled, scoring='roc_auc', cv=cv)\nscores_xgb.mean()","d6546830":"evaluate_model(model_xgb, X_resampled, y_resampled)","5fca6be8":"model_rf_resample = RandomForestClassifier(n_estimators=100, max_depth=10, class_weight={0:1,1:6})","944c6a71":"scores_rf_resample = cross_val_score(model_rf_resample, X_resampled, y_resampled, scoring='roc_auc', cv=cv)\nscores_rf_resample.mean()","d0795e35":"evaluate_model(model_rf_resample, X_resampled, y_resampled)","e1988ee0":"model_rf = RandomForestClassifier(n_estimators=50, max_depth=10, class_weight={0:1,1:12})","e292781a":"scores_rf = cross_val_score(model_rf, X, y, scoring='roc_auc', cv=cv)\nscores_rf.mean()","bc41313d":"evaluate_model(model_rf, X, y)","b5925e8c":"model_rf_balanced = BalancedRandomForestClassifier(n_estimators=50, sampling_strategy='all', \\\n                                                   class_weight={0:1,1:20})","8284ea98":"scores_rf_balanced = cross_val_score(model_rf_balanced, X, y, scoring='roc_auc', cv=cv)\nscores_rf_balanced.mean()","692ac7fa":"evaluate_model(model_rf_balanced, X, y)","4bec4c40":"test = pd.read_csv('..\/input\/iba-ml1-mid-project\/test.csv')\nID = test.iloc[:,0].values\ntest = test.iloc[:,1:]\ntest","d1080a3e":"test['credit_line_utilization']=test['credit_line_utilization'].str.replace(',', '.').astype(np.float64)\ntest['debt_payment']=test['monthly_income']*test['ratio_debt_payment_to_income']\ntest['remain'] = test['monthly_income'] - test['number_dependent_family_members']*250\ntest","5a84a5bb":"test = imp.transform(test)\ntest = scale.transform(test)","8452930b":"test = np.hstack((test, pca.transform(test[:,7:10])))","0a6ba56c":"test = test[:, [0, 2, 3, 5, 6, 10, 11, 12]]\ntest.shape","040013e8":"result_rf_balanced = pd.DataFrame(ID, columns=['Id'])\ny_pred = np.zeros((result_rf_balanced.shape[0], 1))\nfor train_idx, test_idx in cv.split(X, y):\n    X_train = X[train_idx]\n    y_train = y[train_idx]\n    model_rf_balanced.fit(X_train, y_train)\n    y_pred += (model_rf_balanced.predict_proba(test)[:, 1]).reshape(-1,1) \/ 7\n    \nresult_rf_balanced['Predicted'] = y_pred","f567b79f":"result_rf_balanced","ed71a8cb":"result_rf_balanced.to_csv('result_rf_balanced', index=False)","c66a2de8":"from eli5.sklearn import PermutationImportance\nfrom eli5 import show_weights","6c5e45df":"# permutation importance for test data of last split from StratifiedKFold\nX_test, y_test = X[test_idx], y[test_idx]\nperm = PermutationImportance(model_rf_balanced).fit(X_test, y_test)\nfeatures = ['age', 'monthly_income', 'number_of_credit_lines', 'ratio_debt_payment_to_income', 'credit_line_utilization', 'debt_payment', 'remain', 'late_payments']\nshow_weights(perm, feature_names=features)","d5199d78":"# permutation importance for train data of last split from StratifiedKFold\nperm_train = PermutationImportance(model_rf_balanced).fit(X_train, y_train)\nshow_weights(perm_train, feature_names=features)","6d745b5c":"import shap\nshap.initjs()","22488bd3":"X_train_df = pd.DataFrame(X_train, columns=features)\nX_train_df","0d1c4228":"medians = X_train_df.median().values.reshape((1, -1))\nexplainer = shap.KernelExplainer(lambda x: model_rf_balanced.predict_proba(x)[:, 1], medians)","a6c40b39":"shap_values_single = explainer.shap_values(test[0,:], nsamples=10000)\nshap.force_plot(explainer.expected_value, shap_values_single, test[0,:])","57a91cbb":"shap_values_single = explainer.shap_values(test[1,:], nsamples=10000)\nshap.force_plot(explainer.expected_value, shap_values_single, test[1,:])","9f678c49":"shap_values_single = explainer.shap_values(test[2,:], nsamples=10000)\nshap.force_plot(explainer.expected_value, shap_values_single, test[2,:])","4911c235":"shap_values_single = explainer.shap_values(test[3,:], nsamples=10000)\nshap.force_plot(explainer.expected_value, shap_values_single, test[3,:])","24f06bcc":"shap_values_single = explainer.shap_values(test[4,:], nsamples=10000)\nshap.force_plot(explainer.expected_value, shap_values_single, test[4,:])","18fefd33":"shap_values_single = explainer.shap_values(test[5,:], nsamples=10000)\nshap.force_plot(explainer.expected_value, shap_values_single, test[5,:])","2014d089":"shap_values_single = explainer.shap_values(test[6,:], nsamples=10000)\nshap.force_plot(explainer.expected_value, shap_values_single, test[6,:])","3ae719e6":"shap_values_single = explainer.shap_values(test[7,:], nsamples=10000)\nshap.force_plot(explainer.expected_value, shap_values_single, test[7,:])","c1db862f":"shap_values = explainer.shap_values(test[range(0, test.shape[0], 25),:], nsamples=1000) ","442f5963":"shap.force_plot(explainer.expected_value, shap_values, test[range(0, test.shape[0], 25),:])","3661a0cb":"shap.summary_plot(shap_values, test[range(0, test.shape[0], 25),:])","0a7e5713":"Here I use stratified kfold split with 7 split, fit model each time on train data and make prediction with an actual test data, then average the predictions","de83d431":"## AdaBoostClassifier","7c7c852e":"As we see from importances, 2 new features have higher importance and besides that last column which is combination for 3 highly correlated features has higher importance than all 3 of them individually.","3f431bfb":"### Visualizing all features together (since giving whole test data results in shap giving an error about being slow to handle thousands of rows, subsample of test data has been given to visualize","aa320ad1":"## **Resultant Prediction**","8730837c":"## Functions for Preprocessing","425e634b":"## RandomForestClassifier without resampling","ce0bb679":"### SHAP values","47a1cbea":"## Preproceesing of train data and Dimensionality reduction for 3 highly correlated features (mentioned on EDA)","6c32be51":"### Visualizing each feature individually","f49c39d2":"## Model Explaination for BalancedRandomForestClassifier","45fa0420":"## Feature Selection with RandomForestClassifier","bf8bafff":"## Adding 2 new features to test data and applying dataprocessing steps","6a30a2a6":"## RandomForestClassifier with resampling","b59207ac":"## Outlier Detection with IsolotionForest","e05e5b97":"## BalancedRandomForestClassifier","483d8c8f":"# Prediction with different models","31c5f3d3":"### Permutation importance","a43dcc10":"## Reading train dataset, correcting typo and adding new features based on EDA","610dab60":"## XGBClassifier","2c953a24":"As it is shown from results BalancedRandomForestClassifier has higher roc_auc score for imbalanced data, Therefore I will use this model for final prediction"}}