{"cell_type":{"d148dd6c":"code","6b695711":"code","2775df25":"code","2b7a6c85":"code","30d5f787":"code","6a603db8":"code","b4184fa3":"code","17783448":"code","7a232b02":"code","f6dde405":"code","2a65bd32":"code","5101b093":"code","8e0fc31d":"code","33d34d6b":"code","ceba6066":"code","ab7fe177":"code","28d9f2f1":"code","25b0ac9a":"code","86cbe1da":"code","3369b950":"code","8b2811e3":"code","5a8c08d1":"code","3fce524e":"code","75078fd6":"code","1db37fc6":"code","d76fda5f":"code","c3526c71":"code","a4868819":"markdown","9908e5eb":"markdown","c732547b":"markdown","a588c8f4":"markdown","d8280830":"markdown","ddd534d7":"markdown","5d4112c1":"markdown","1bd9b8df":"markdown","2c16126f":"markdown","c0d58039":"markdown","496fe817":"markdown","66385972":"markdown","d4d01542":"markdown","59c1c93c":"markdown","67faa1b5":"markdown","dbb073ce":"markdown","27022a5a":"markdown","69f2fd88":"markdown","43f08bec":"markdown","90626b5c":"markdown","296d0ff0":"markdown","59c1dc5d":"markdown","16a4e175":"markdown","ebcd7958":"markdown","227af12d":"markdown","c1184206":"markdown","85bc1bd9":"markdown","8a63befa":"markdown","62c84fc6":"markdown","da89b73c":"markdown","5cef2241":"markdown","350e0192":"markdown","e7c84340":"markdown","35dd84fb":"markdown","31b9ad14":"markdown","6f9eef77":"markdown","a58986fa":"markdown","4adc9319":"markdown","7b5445f6":"markdown","737f9df2":"markdown","10eeb8f9":"markdown"},"source":{"d148dd6c":"# CELDA 1\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import Sequential, layers, Input\nfrom tensorflow.keras.models import load_model\nfrom pickle import load\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\ndef checkpoint(df):\n    s = df.dtypes.to_dict()\n    hay_error = False\n    for key, val in s.items():\n        if key in ['artist_name', 'mode', 'track_name']:\n            print('Error en dataframe: ten\u00e9s que eliminar la columna', key)\n            hay_error = True\n        if val == 'object':\n            print('Error en dataframe: la columna {} es categ\u00f3rica'.format(key))\n            hay_error = True\n    if not hay_error:\n        print(\"OK! Pod\u00e9s seguir adelante!\")\n    else:\n        print(\"Volv\u00e9 sobre tus pasos para corregir los errores.\")\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\nprint()\nprint(\"Inicializaci\u00f3n terminada!\\n(En las siguientes celdas pueden aparecer warnings, \u00a1no te preocupes!)\")","6b695711":"# CELDA 2\n\n# Definimos cinco canciones\n# En 'columnas' se especifican los atributos tenidos en cuenta. Deben ser los mismos que los usados durante el entrenamiento de los modelos.\ncolumnas = ['popularity', 'danceability', 'energy', 'key', 'loudness', 'liveness', 'valence', 'tempo', 'duration']\n\n# Definimos cinco canciones dando valores a los atributos. Cada lista dentro de 'new_songs_raw' es una canci\u00f3n.\nnew_songs_raw = [\n    [0.0, 0.504, 0.614, 7.0, -9.236, 0.112, 0.547, 168.066, 3.07],\n    [1.0, 0.356, 0.937, 5.0, -7.185, 0.149, 0.212, 145.908, 4.91],\n    [1.0, 0.514, 0.0814, 6.042909312233719, -17.149, 0.219, 0.232, 64.97, 0.0],\n    [1.0, 0.435, 0.729, 6.0, -4.697, 0.756, 0.646, 165.897, 6.26],\n    [0.0, 0.571, 0.6, 9.0, -7.239, 0.365, 0.325, 147.905, 5.62]\n]\n\n# Generamos un dataframe con el conjunto de canciones\nnew_songs = pd.DataFrame(new_songs_raw, columns = columnas)\nnew_songs","2775df25":"## CELDA 3\n\n# Vamos a predecir el g\u00e9nero musical para las cinco canciones que definimos en la celda de c\u00f3digo #2\n# Para obtener las predicciones vamos a utilizar dos modelos de predicci\u00f3n ya entrenados en los datos del laboratorio.\n\n# Codificaci\u00f3n de los g\u00e9neros musicales en el dataset train.csv:\n# 0 = 'Rock'; 1 = 'Indie'; 2 = 'Pop'; 3 = 'Metal'; 4 = 'Instrumental'\n\n# Lista de g\u00e9neros musicales de acuerdo a la codificaci\u00f3n anterior\nlista_generos = ['Rock', 'Indie', 'Pop', 'Metal', 'Instrumental']\n\n# Valores reales de los g\u00e9neros musicales de las cinco canciones a predecir\n# Canci\u00f3n 1 --> 'Indie'; Canci\u00f3n 2 --> 'Metal'; Canci\u00f3n 3 --> 'Instrumental'; Canci\u00f3n 4 --> 'Indie'; Canci\u00f3n 5 --> 'Rock' \nlabels_correctas = ['Indie', 'Metal', 'Instrumental', 'Indie', 'Rock']\n\n# Funci\u00f3n auxiliar para mostrar los resultados\n# Muestra cada predicci\u00f3n de una canci\u00f3n, junto con su etiqueta correcta\n# Calcula el porcentaje de aciertos en las predicciones\ndef mostrar_predicciones(predictions):\n    aciertos = 0\n    cant_predicciones = len(predictions) # cantidad de predicciones (5)\n    for i, p in enumerate(predictions.argmax(axis = 1)):\n        valor_correcto = labels_correctas[i] # valor esperado\n        valor_prediccion = lista_generos[p] # valor de la predicci\u00f3n\n        print(\"Ejemplo {}:\\n\\tPredicci\u00f3n => {}\\n\\tCorrecto => {}\".format(i+1, valor_prediccion, valor_correcto))\n        \n        # Si la predicci\u00f3n coincide con el valor esperado, sumamos un acierto\n        if valor_prediccion == valor_correcto:\n            aciertos += 1\n    \n    print(\"Porcentaje de aciertos: {}\/{} = {:.2%}\".format(aciertos, cant_predicciones, (aciertos \/ cant_predicciones)))\n\n# Cargar Scaler\n# Realiza una normalizaci\u00f3n sobre los datos que vamos a predecir.\nscaler = load(open('..\/input\/dcic-ia-2021-laboratorio\/scaler.pkl', 'rb'), encoding=\"latin1\")\nscaled_new_songs = scaler.transform(new_songs)\n\n###################################\n\n## Parte 1: Predicci\u00f3n con un \u00e1rbol de decisi\u00f3n (AD)\nclf = load(open('..\/input\/dcic-ia-2021-laboratorio\/model_dt.pkl', 'rb')) # Cargamos el AD usando la funci\u00f3n load(file)\npredictions_DT = clf.predict(scaled_new_songs) # Usamos la funci\u00f3n predict() para predecir los g\u00e9neros de las canciones\n\nprint(\"Predicciones con \u00c1rbol de Decisi\u00f3n:\")\nmostrar_predicciones(predictions_DT)\nprint('-'*50)\n\n###################################\n\n## Parte 2: Predicci\u00f3n con una red neuronal artificial (RNA)\nmodel = load_model('..\/input\/dcic-ia-2021-laboratorio\/model_neural_net.h5') # Cargamos la RNA usando la funci\u00f3n load_model(file)\npredictions_RNA = model.predict(scaled_new_songs) # Usamos la funci\u00f3n predict() para predecir los g\u00e9neros de las canciones\n\nprint(\"Predicciones con Red Neuronal Artificial:\")\nmostrar_predicciones(predictions_RNA)\n\n###################################\n\n# Descomentar las siguientes l\u00edneas para ver cada matriz de predicciones\n# print(\"-\"*50)\n# print(predictions_DT)\n# print(predictions_RNA)","2b7a6c85":"# CELDA 4\n\n# Cargar del dataset para entrenamiento.\ndf = pd.read_csv('..\/input\/dcic-ia-2021-laboratorio\/train.csv')\n\nprint(\"Cantidad de ejemplos: {}\\nCantidad de columnas: {}\".format(df.shape[0], df.shape[1]))\n\n# Ver los primeros ejemplos del dataset.\ndf.head(5)","30d5f787":"# CELDA 5\n\n# primeras 10 filas del dataset\n# df.head(10)\n\n# \u00faltimas 10 filas del dataset\n# df.tail(10)\n\n# filas con atributo 'class' en Pop (2)\n# df.loc[(df['class'] == 2)] \n\n# filas con atributo 'class' en Rock (0) o Pop (2)\n# df.loc[df['class'].isin([0, 2])] \n\n# filas con atributo 'popularity' en alto\n# df.loc[df['popularity'] == 'alto'] \n\n# filas donde 'popularity' es alto y la duraci\u00f3n de la canci\u00f3n es menor a 2 minutos\n# df.loc[(df['popularity'] == 'alto') & (df['duration'] < 2)] \n\n# secci\u00f3n del dataset conteniendo solo el nombre de la canci\u00f3n y su categor\u00eda\n# df[['track_name', 'class']] \n\n# secci\u00f3n del dataset conteniendo solo el nombre de la canci\u00f3n y su categor\u00eda, para las canciones de popularidad alta.\n# df.loc[df['popularity'] == 'alto'][['track_name', 'class']]","6a603db8":"# CELDA 6\n\n# Nombre de las columnas\nprint(\"Columnas del dataset: {}\".format(list(df.columns)))\nprint(\"-\"*50)\n\n# Vemos informaci\u00f3n b\u00e1sica sobre las columnas del dataset\nprint(df.info(memory_usage = False))\nprint(\"-\"*50)\n\n# Columnas que tienen valores nulos (NaN)\nprint(\"Columnas con valores nulos:\")\nfor column in df.columns:\n    if df[column].isna().sum() > 0:\n        print(\"-> {} => {} nulos\".format(column, df[column].isna().sum()))\n\nprint(\"-\"*50)\n\n# Informaci\u00f3n sobre columnas categ\u00f3ricas\nprint(\"Columnas categ\u00f3ricas:\")\nfor column in df.columns:\n    if df[column].dtype == 'object':\n        values = df[column].unique()\n        print(\"-> {} => {} valores distintos\".format(column, len(df[column].unique())))\n\nprint(\"-\"*50)\n\n# Distribuci\u00f3n de los ejemplos (filas del dataset) para cada clase\nprint(\"Distribuci\u00f3n de target (cantidad de ejemplos):\")\nprint(df['class'].value_counts())","b4184fa3":"# CELDA 7\n\ndf.describe()\n# df.describe(include = ['object'])","17783448":"# CELDA 8\n\n# \u00bfCu\u00e1ntos valores distintos aparecen en la columna 'mode'?\nprint(\"Cantidad de valores distintos para la columna 'mode': {}\".format(len(df['mode'].unique())))","7a232b02":"# CELDA 9\n\n# Obtenemos el valor m\u00e1s frecuente en la columna 'popularity' \nmost_common_popularity = df['popularity'].mode()[0]\n# Usando el valor anterior, completamos los valores nulos de la columna.\ndf['popularity'] = df['popularity'].fillna(most_common_popularity)\n\n# TO-DO: obtenga el valor promedio en la columna 'key' \n# mean_key = ___\n\n# TO-DO: complemente los nulos de la columna 'key' con el valor obtenido.\n# df['key'] = ___\n\nprint(\"Verificando valores nulos:\")\nprint(df.isna().sum())","f6dde405":"# CELDA 10\n\n# TO-DO: Use un diccionario para definir un mapeo para la columna 'popularity', descomentando la l\u00ednea siguiente.\n\n# mapeo = {\n#     'bajo': 0,\n#     ...\n# }\n\n# Modificamos la columna 'popularity' a partir del mapeo anterior\ndf_nuevo = df.copy() ## hacemos una copia del dataframe df.\ndf_nuevo['popularity'] = df['popularity'].map(mapeo) ## la modificaci\u00f3n se hace sobre df_nuevo (df no se modifica).\n\nprint(\"Mapeo aplicado...\")\nprint(\"IMPORTANTE: Verificar el resultado en la siguiente celda de c\u00f3digo!\")","2a65bd32":"# CELDA 11.a\n\n# Descomentar para ver el dataframe antes de aplicar el mapeo\n# df.head(10)","5101b093":"# CELDA 11.b\n\n# Descomentar para ver el dataframe luego de aplicar el mapeo\n# df_nuevo.head(10)","8e0fc31d":"# CELDA 12\n\n# TO-DO: Eliminar las columnas que no son relevantes y\/o no pueden utilizarse en la RNA o AD\n\n# cols_eliminar = [___] # Ingrese los nombres de las columnas a eliminar (entre comillas)\n\ndf_adecuado = df_nuevo.drop(columns = cols_eliminar)\n\nprint(\"Cantidad de ejemplos: {}\\nCantidad de columnas: {}\".format(df_adecuado.shape[0], df_adecuado.shape[1]))","33d34d6b":"# CELDA 13\n\n# Ejecutar para verificar que el dataframe est\u00e9 correcto y poder seguir adelante. \n# En caso de estar todo bien, imprime un mensaje \"OK! Pod\u00e9s seguir adelante!\"\n# En caso de encontrar un error, tendr\u00e1s que revisar el trabajo previo.\n\ncheckpoint(df_adecuado)","ceba6066":"# CELDA 14\n\n# Separamos la columna target en una nueva variable y la eliminamos del dataframe.\ny = np.asarray(df_adecuado['class'])\nprint(\"Etiquetas: {}\".format(y))\nprint(\"-\"*30)\n\n# Eliminamos la columna 'class' del dataframe (generamos df_final, mientras que df_adecuado no se ve modificado)\ndf_final = df_adecuado.drop(columns = ['class'])\n\n# OneHotEncoder\nenc = OneHotEncoder(handle_unknown='ignore')\n\n# La funci\u00f3n fit_transform devuelve una transformaci\u00f3n de los datos que recibe.\ny_enc = enc.fit_transform(y.reshape(-1, 1)).toarray()\n\nprint(\"Etiquetas (one-hot encoding):\\n{}\".format(y_enc))\nprint(\"-\"*30)\n\nprint(\"Mapeo del encoder:\")\nfor val, codif in zip(enc.categories_[0].tolist(), enc.transform(enc.categories_[0].reshape(-1, 1)).toarray()):\n    print(\"Label: {} ==> Codificaci\u00f3n One-Hot ==> {}\".format(val, codif))","ab7fe177":"# CELDA 15\n\n# test_size = ___\n\nX_train, X_val, y_train, y_val = train_test_split(df_final, y_enc, test_size = test_size, random_state = 10)\n\nprint(\"Datos de entrenamiento:\\n\\tCantidad de ejemplos (filas): {}\\n\\tCantidad de atributos (columnas): {}\\n\".format(X_train.shape[0], X_train.shape[1]))\nprint(\"Datos de validaci\u00f3n:\\n\\tCantidad de ejemplos (filas): {}\\n\\tCantidad de atributos (columnas): {}\".format(X_val.shape[0], X_val.shape[1]))","28d9f2f1":"# CELDA 16\n\n# TO-DO: completar lista profundidades con valores enteros.\n# profundidades = [___]\n\nfor prof in profundidades:\n    # Para cada profundidad, se ajusta un AD con esa profundidad m\u00e1xima.\n    clf = DecisionTreeClassifier(max_depth = prof)\n    \n    # Se ajusta el AD con los datos de entrenamiento\n    clf = clf.fit(X_train, y_train)\n    \n    # Se calcula un resultado usando el conjunto de validaci\u00f3n\n    predictions = clf.predict(X_val)\n    print(\"Con profundidad = {}, el resultado obtenido es: {:.3} (F1-score)\\n\".format(prof,\n        f1_score(np.argmax(y_val, axis = 1), np.argmax(predictions, axis = 1), average = 'macro')))","25b0ac9a":"# CELDA 17\n\n# MAX = ___\n\n# Creamos AD con profundidad m\u00e1xima MAX\nclf = DecisionTreeClassifier(max_depth = MAX)\n\n# Ajustamos el AD con los datos de entrenamiento\nclf = clf.fit(X_train, y_train)\n\n# Informaci\u00f3n sobre el AD aprendido\nprint(\"Profundidad del \u00e1rbol: {}\".format(clf.get_depth()))\nprint(\"Cantidad de nodos (internos + hojas): {}\".format(clf.tree_.node_count))\nprint(\"Cantidad de hojas: {}\".format(clf.get_n_leaves()))\nprint()\n\n# Predicciones sobre el conjunto de validaci\u00f3n\npredictions = clf.predict(X_val)\n\n# Reporte de clasificaci\u00f3n\nprint(classification_report(np.argmax(y_val, axis = 1), np.argmax(predictions, axis = 1), target_names = lista_generos))","86cbe1da":"# CELDA 18\n\ndef get_class_name(valores, clases):\n    ## Devuelve un entero en [0, 4] que representa una clase\n    for i, x in enumerate(valores):\n        if x[0] == 0 or x[1] == 0:\n            return clases[i]\n\n#############################\nn_nodes = clf.tree_.node_count # cantidad de nodos del \u00e1rbol\nv_nodes = clf.tree_.value # valor de los ejemplos de los nodos\nn_leaves = clf.get_n_leaves() # cantidad de hojas del \u00e1rbol\nchildren_left = clf.tree_.children_left # hijos izquierdos de los nodos del \u00e1rbol\nchildren_right = clf.tree_.children_right # hijos derechos de los nodos del \u00e1rbol\nfeature = clf.tree_.feature # atributos usados para hacer las divisiones en cada nodo\nthreshold = clf.tree_.threshold # umbral computado para hacer las divisiones en cada nodo\nattribute_names = df.columns # atributos del dataset\nclasses = ['Rock', 'Indie', 'Pop', 'Metal', 'Instrumental'] # nombre de las clases de clasificaci\u00f3n\n\nstack = [(0, 0)]\nnode_depth = np.zeros(shape=n_nodes, dtype=np.int64)\nis_leaf = np.zeros(shape=n_nodes, dtype=bool)\n\nwhile len(stack) > 0:\n    ## elegimos un nodo de la pila\n    node_id, depth = stack.pop()\n    node_depth[node_id] = depth\n    \n    ## si el nodo tiene hijos con distinto ID, entonces es un nodo interno.\n    ## si los hijos tienen igual ID, entonces el nodo es una hoja.\n    ## Notar que es un \u00e1rbol binario\n    is_split_node = children_left[node_id] != children_right[node_id]\n    if is_split_node:\n        ## para un nodo interno, agrego los hijos a la pila\n        stack.append((children_left[node_id], depth + 1))\n        stack.append((children_right[node_id], depth + 1))\n    else:\n        is_leaf[node_id] = True\n\nprint(\"El \u00e1rbol de decisi\u00f3n tiene {} nodos, de los cuales {} son nodos hojas.\".format(n_nodes, n_leaves))\nprint(\"La estructura es la siguiente:\\n\")\n\n## Para cada nodo del \u00e1rbol:\n### Si es hoja, muestro la decisi\u00f3n que toma\n### Si es interno, muestro el atributo del nodo y sus hijos.\nfor i in range(n_nodes):\n    if is_leaf[i]:\n        leaf_value = get_class_name(v_nodes[i], classes)\n        print(\"{}El \\033[4mnodo {}\\033[0m es un nodo hoja --> \\033[1mDecisi\u00f3n: {}\\033[0m\\n\".format(node_depth[i]*\"\\t\", i, leaf_value))\n    else:\n        left_child = children_left[i]\n        right_child = children_right[i]\n        attribute, tr_value = feature[i], round(threshold[i], 2) \n        print(\"{}El \\033[4mnodo {}\\033[0m es un nodo interno. Ir a nodo {} si {} <= {}. Caso contrario, ir a nodo {}\\n\".format(\n                node_depth[i]*\"\\t\", i, left_child, attribute_names[attribute], tr_value, right_child \n        ))","3369b950":"# CELDA 19\n\n## Representaci\u00f3n gr\u00e1fica de un \u00e1rbol de decisi\u00f3n\n## Ejecutar s\u00f3lo si el AD tiene poca profundidad\n\nplt.rcParams[\"figure.figsize\"] = (22, 10)\nplot_tree(clf, class_names = classes, feature_names = df.columns, impurity = False, fontsize = 11)\nplt.show()","8b2811e3":"# CELDA 20\n\nnum_features = X_train.shape[1] ## cantidad de atributos en X_train y X_val\nnum_outputs = y_train.shape[1] ## cantidad de categor\u00edas posibles (5 g\u00e9neros musicales)\n\ndef define_model():\n    model = Sequential()\n    \n    # Capa de entrada de la red\n    model.add(Input(shape=(num_features ))) ## tama\u00f1o de la entrada a la RNA\n\n    #TO-DO: Complete la red. Ingrese al menos dos capas nuevas.\n    #___\n    \n    # Capa de salida de la red\n    model.add(layers.Dense(num_outputs, activation = 'softmax')) ## tama\u00f1o de la salida = cantidad de clases = 5\n\n    # TO-DO: definir un valor para learning rate\n    # lr = ___\n\n    # opt = tf.keras.optimizers.Adam(learning_rate = lr)\n    opt = tf.keras.optimizers.SGD(learning_rate = lr)\n\n    model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = 'accuracy')\n    return model\n\nprint(\"\u00a1Estructura de la red definida!\\n\")\n\n# Se crea el modelo, a\u00fan sin entrenar\nmodel = define_model()\n\n# Obtenemos una descripci\u00f3n de la estructura\nmodel.summary()","5a8c08d1":"# CELDA 21\n\n# TO-DO: completar las siguientes variables\n# epochs = ___\n# batch_size = ___\n# verbose = ___\nval_data = (X_val, y_val)\n\nprint(\"-\"*100)\n# TO-DO: Utilice el m\u00e9todo model.fit para entrenar la RNA definida.\n# Hint: los dos primeros par\u00e1metros son los datos de entrenamiento y sus etiquetas. Pod\u00e9s ver el siguiente link para m\u00e1s detalles.\n# https:\/\/keras.io\/api\/models\/model_training_apis\/#fit-method\n\n# history = model.fit(X_train, y_train, ...)","3fce524e":"# CELDA 22\n\n# TO-DO: Valide el entrenamiento.\n# Hint: Hay que utilizar los datos de validaci\u00f3n juntos con sus etiquetas. Pod\u00e9s ver el siguiente link para m\u00e1s detalles.\n# https:\/\/keras.io\/api\/models\/model_training_apis\/#evaluate-method\n\n# ----","75078fd6":"# CELDA 23\n\n# TO-DO: Realice predicciones sobre el conjunto de validaci\u00f3n, usando model.predict(...)\n# https:\/\/keras.io\/api\/models\/model_training_apis\/#predict-method\n\n# Predicciones sobre el conjunto de validaci\u00f3n\n# predictions = ___\n\n# Reporte de clasificaci\u00f3n\nprint(classification_report(np.argmax(y_val, axis = 1), np.argmax(predictions, axis = 1), target_names = lista_generos))","1db37fc6":"# CELDA 24\n\n# Descomentar para ver la matriz de predicciones\n# print(predictions)\n\n# Descomentar para ver el efecto de la funci\u00f3n argmax() sobre predictions\n# np.argmax(predictions, axis = 1)","d76fda5f":"# CELDA 25\n\ndf = pd.read_csv('..\/input\/dcic-ia-2021-laboratorio\/test.csv')\n\n## Separamos los IDs de los ejemplos de test. Recordar que la RNA necesita las mismas entradas que se usaron para entrenar.\nids = df['id'] ## IDs de los ejemplos en el conjunto de test\ndf = df.drop(columns= ['id']) ## Eliminamos la columna de id del dataframe que separamos.\n\n# Completar valores nulos\ndf['popularity'] = df['popularity'].fillna(most_common_popularity)\ndf['key'] = df['key'].fillna(mean_key)\n\n# Variable popularity representada con n\u00fameros\ndf['popularity'] = df['popularity'].map(mapeo)\n\n# Eliminar columnas\ndf = df.drop(columns = cols_eliminar)\nprint(\"Cantidad de ejemplos: {}\\nCantidad de columnas: {}\".format(df.shape[0], df.shape[1]))\nprint(\"-\"*100)\n\n# Realizar las predicciones usando la \u00faltima RNA entrenada\npredictions = model.predict(df)\npredictions = np.argmax(predictions, axis = 1)\n\n# Generar archivo de submission\nsubmission = pd.DataFrame({\n    'id': ids,\n    'class': predictions\n})\n# Guardamos el dataframe como un archivo csv.\nsubmission.to_csv('my_submission.csv', index = False)\n\n# Vemos las primeras l\u00edneas del archivo.\nsubmission.head()","c3526c71":"scaler = StandardScaler()\n\nX_train = scaler.fit_transform(X_train)\nX_val = scaler.transform(X_val)\n# X_test = scaler.transform(X_test) # Necesario para el conjunto de test\n\n# Podemos ver el conjunto de datos luego de realizar la normalizaci\u00f3n.\n# pd.DataFrame(X_train, columns = df.columns)","a4868819":"Con lo que hemos visto hasta el momento, **\u00bfeliminar\u00edas alguna de las columnas del dataset?** \u00bfHay alg\u00fan atributo que creas que no va a servir para encontrar un patr\u00f3n en los datos?\n\n### To-Do Task #3: Eliminar atributos irrelevantes\n* Eliminar las columnas del dataset que considera no relevantes, definiendo en la celda #12 una lista con los nombres de los atributos que desea eliminar. (**Importante: No eliminar la columna *target***).\n* Puede hacer *df_nuevo.columns* para ver nuevamente los atributos del dataset.\n* Luego, **ejecut\u00e1 la celda de chequeo** (celda de c\u00f3digo #13) para saber que est\u00e1 todo en orden y poder continuar con el laboratorio.","9908e5eb":"## Valores Nulos\n\nLa informaci\u00f3n anterior nos muestra que tenemos dos columnas en las cuales aparecen valores nulos. Dicho de otra manera, en el dataset tenemos ejemplos para los cuales los atributos *popularity* y\/o *key* no tiene un valor definido.\n\n* popularity - 186 nulos\n* key - 950 nulos\n\nSabiendo que no podemos ingresar valores nulos a un \u00c1rbol de Decisi\u00f3n o a una Red Neuronal (ya sea para su entrenamiento o para realizar predicciones), en la pr\u00e1ctica tenemos distintas alternativas para eliminarlos.\n\n1. La alternativa m\u00e1s radical consiste en **eliminar la columna (el atributo) del dataset**. Por ejemplo, en este caso eliminar\u00edamos las columnas *popularity* y *key*, las cuales ya no podr\u00edan utilizarse para entrenar. Es una alternativa viable cuando se tiene un gran porcentaje de nulos en la columna.\n2. Una segunda alternativa es **eliminar los ejemplos (las filas) del dataset que tengan un valor nulo**. Es una opci\u00f3n viable si tenemos un dataset con muchos ejemplos y podemos afrontar la p\u00e9rdida de estos datos.\n3. La tercera alternativa es **completar los valores nulos** siguiendo alguna pol\u00edtica, la cual depender\u00e1 del tipo de columna.\n  * Para columnas categ\u00f3ricas (como *popularity*) podemos reemplazar los nulos con el valor m\u00e1s frecuente en la columna. Tambi\u00e9n podemos asignar un valor fijo.\n  * Para columnas num\u00e9ricas (como *key*) podemos reemplazar los nulos con el valor promedio de la columna, el valor medio, el m\u00ednimo, el m\u00e1ximo o un valor fijo.\n\n**La soluci\u00f3n depende del problema en cuesti\u00f3n**, pero se puede experimentar con distintas opciones y quedarse con la que permita obtener mejores resultados.\n\nEntonces, **\u00bfqu\u00e9 hacemos con los valores nulos que tenemos en el dataset?** En nuestro caso vamos a completarlos como sigue:\n\n* *popularity* - Completamos los nulos con el valor m\u00e1s frecuente de la variable.\n* *key* - Completamos los nulos con el valor promedio de la variable.\n\nComo son de distinto tipo, debemos trabajarlas de forma separada. Usaremos la funci\u00f3n de pandas *fillna()*.\n\nLink: https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.DataFrame.fillna.html\n\n### To-Do Task #1: Completar los valores nulos\n* Observe lo realizado para completar la columna *popularity* en la celda de c\u00f3digo #9.\n* Siguiendo lo anterior, obtenga el valor promedio del atributo *key* y almac\u00e9nelo en la variable *mean_key* (*Hint:* usualmente se lo llama 'mean').\n* Luego de haber obtenido el valor promedio, complete los nulos de la columna *key* utilizando la variable *mean_key*.\n* Recordar que siempre pueden utilizar nuevas celdas de c\u00f3digo para hacer pruebas.\n\nComo resultado de la ejecuci\u00f3n, deber\u00eda ver un texto que indica que, **para cada atributo quedan cero valores nulos**.","c732547b":"**Haga doble click para ver una ayuda**\n<!-- \nPara agregar una capa usamos\nmodel.add(<< LAYER >>)\n\ndonde LAYER es una capa Dense que se construye como sigue:\nlayers.Dense( <<< nro de neuronas >>> , activation = << ver arriba >>)\n-->","a588c8f4":"A partir de la informaci\u00f3n anterior, **contest\u00e1 las siguientes preguntas**:\n\n* \u00bfQu\u00e9 diferencia not\u00e1s entre las columnas *popularity, energy y key*?\n* \u00bfQu\u00e9 podemos concluir en base al *count* de cada columna en contraste al total de filas del dataframe?\n* \u00bfQu\u00e9 opin\u00e1s de la distribuci\u00f3n de ejemplos para cada una de las categor\u00edas de la clasificaci\u00f3n?\n\n**Doble Click aqu\u00ed para ver las respuestas!**\n\n<!-- 1. La columna 'popularity' es categ\u00f3rica, es decir toma valores de un conjunto finito de opciones (\u00bfCu\u00e1ntos valores distintos tiene popularity?).\n        La columna 'energy' es num\u00e9rica y no tiene ning\u00fan valor nulo.\n        La columna 'key' es num\u00e9rica pero tiene valores nulos. \n\n    2.  El count nos indica la cantidad de celdas cuyo valor no es nulo. Para una determinada columna, si el valor de count es menor a la cantidad total de ejemplos en el dataset (RangeIndex 8743 entries), entonces la columna tendr\u00e1 celdas sin valor.\n\n    3. Se puede ver que las categor\u00edas est\u00e1n desbalanceadas, es decir difiere la cantidad de ejemplos para cada categor\u00eda a clasificar. Esto es importante al momento de evaluar la performance de la RNA o \u00c1rbol de Decisi\u00f3n. -->","d8280830":"**Opcional**: pod\u00e9s ver el formato de las predicciones usando la celda de c\u00f3digo que sigue.","ddd534d7":"### To-Do Task #8: Configurar el entrenamiento\nHabiendo definido la estructura de la red neuronal, lleg\u00f3 el momento de entrenarla utilizando los datos de entrenamiento (X_train e y_train). Para ello, usamos la funci\u00f3n **model.fit()**. La funci\u00f3n nos devuelve informaci\u00f3n del proceso de entrenamiento, que queda referenciada con la variable *history*. \n\n* Indique a qu\u00e9 refieren los siguientes par\u00e1metros y pruebe con distintos valores de cada uno:\n    * validation_data\n    * epochs\n    * batch_size\n    * verbose\n* En la celda de c\u00f3digo #21, complete con valores las variables que utilizar\u00e1 en la llamada al m\u00e9todo model.fit(). Notar el uso de los datos de validaci\u00f3n.\n    * epochs (*Hint*: empezar con un valor positivo peque\u00f1o)\n    * batch_size (*Hint*: en general, se usan potencias de 2)\n    * verbose (*Hint*: 0, 1 o 2)\n    \nPod\u00e9s leer sobre estos par\u00e1metros en el siguiente link:\n\nLink: https:\/\/keras.io\/api\/models\/model_training_apis\/#fit-method\n\n**Como resultado de la ejecuci\u00f3n de la celda #21** vas a ver c\u00f3mo avanza el entrenamiento de la RNA (si pusiste verbose > 0 en model.fit()).","5d4112c1":"A\u00fan no hemos utilizado los datos del conjunto de test que brinda la competencia. Vamos a usarlos ahora para **calcular predicciones y enviarlas a la competencia**.\n\nPara los datos de test hay que hacer el **mismo preprocesamiento que hicimos con los datos de entrenamiento**. En la siguiente celda ya te lo damos hecho. Nota que usamos las mismas variables que fuimos definiendo a lo largo del laboratorio (por ejemplo, *most_common_popularity*, *mean_key*).\n\nAdem\u00e1s, la variable **model** es la \u00faltima RNA que entrenamos.\n\n**Importante**: Si realizaste alg\u00fan cambio por tu cuenta (que no estaba en el template) deb\u00e9s hacerlo tambi\u00e9n sobre los datos de test.","1bd9b8df":"# Laboratorio IA - DCIC\n# \u00c1rboles de Decisi\u00f3n y Redes Neuronales Artificiales\n\nDurante el transcurso de este laboratorio aprender\u00e1n conceptos y herramientas para el preprocesamiento de datos, junto con la construcci\u00f3n, entrenamiento y generaci\u00f3n de predicciones utilizando \u00c1rboles de Decisi\u00f3n y Redes Neuronales Artificiales (RNA). El objetivo ser\u00e1 desarrollar un modelo que permita predecir el g\u00e9nero musical asociado a una canci\u00f3n.\n\n## Plan de Trabajo.\n\nLas tareas a realizar son las siguientes:\n\n* Importar el dataset, visualizar y analizar detalles del mismo.\n* Preprocesamiento de datos:\n  * Modificaciones de columnas con variables categ\u00f3ricas.\n  * Procesamiento de columnas con valores nulos.\n  * An\u00e1lisis y extracci\u00f3n de columnas irrelevantes.\n* Construir un \u00c1rbol de Decisi\u00f3n.\n* Definir y realizar el entrenamiento de una RNA.\n* Generar predicciones para nuevos ejemplos.\n* Analizar los resultados obtenidos.\n* Subir los resultados obtenidos a la competencia de Kaggle.\n\nA lo largo de este notebook van a encontrar **celdas de texto**, donde se explican diferentes conceptos te\u00f3ricos y de implementaci\u00f3n. Por otro lado encontrar\u00e1n **celdas de c\u00f3digo**, que en algunos casos tendr\u00e1n que completar para poder avanzar y llegar al final del laboratorio. Cada celda de c\u00f3digo a completar va a estar asociada a una tarea, explicada inmediatamente antes de la celda. La mayor\u00eda de las celdas, sin embargo, no necesitan trabajo adicional m\u00e1s que ejecutarlas... pero no las pases por alto, son importantes para lo que viene en IA 2021!\n\n## El Dataset.\n\nEl dataset que vamos a utilizar en el laboratorio para entrenar un modelo de predicci\u00f3n, contiene un **gran n\u00famero de canciones caracterizadas con diferentes atributos**: artista, nombre de la canci\u00f3n, popularidad, grado de \"bailabilidad\", grado de \"energ\u00eda\", duraci\u00f3n en minutos, entre otros (ver Tabla). A lo largo del laboratorio iremos explorando los datos contenidos en el dataset. Pod\u00e9s ver el archivo de datos *train.csv* en la parte derecha de la pantalla (en *Data -> input -> dcic-ia-2021-laboratorio --> train.csv*).\n\n![image.png](attachment:d0d4444c-7d1b-4c94-851b-b0c24a8899cc.png)\n\nLa \u00faltima columna (**class**) indica el g\u00e9nero de cada canci\u00f3n a trav\u00e9s de un n\u00famero entero y la utilizaremos como *target* a predecir. Cada n\u00famero representa a un g\u00e9nero musical, de la siguiente manera:\n* 0 representa **'Rock'**;\n* 1 representa **'Indie'**;\n* 2 representa **'Pop'**;\n* 3 representa **'Metal'**;\n* 4 representa **'Instrumental'**\n\n## Librer\u00edas.\n\nA lo largo del laboratorio se usan principalmente tres librer\u00edas:\n1. **Pandas**: Permite utilizar y analizar los datos. Link: https:\/\/pandas.pydata.org\/docs\/\n2. **Scikit-learn**: Permite manipular los datos e implementar diversos algoritmos de *Machine Learning*. Link: https:\/\/scikit-learn.org\/stable\/\n3. **Keras**: Permite implementar Redes Neuronales Artificiales de manera intuitiva. Link: https:\/\/keras.io\/getting_started\/\n\nEn distintas celdas van a aparecer otros enlaces a la documentaci\u00f3n de ciertas funciones implementadas en estas librer\u00edas.\n\n## Suerte!\n","2c16126f":"**Una de las ventajas de trabajar con \u00c1rboles de Decisi\u00f3n es su interpretabilidad**. Ante un nuevo ejemplo, podemos conocer el camino desde la ra\u00edz del \u00e1rbol hasta la hoja que nos brinda la predicci\u00f3n. Esta informaci\u00f3n nos puede servir como justificaci\u00f3n de la nueva predicci\u00f3n. \n\nIlustramos esta caracter\u00edstica en las siguientes dos celdas de c\u00f3digo:\n\n* En la primera se recorre el \u00e1rbol, de manera relativamente sencilla, para obtener una representaci\u00f3n de su estructura.\n* En la segunda, se utiliza una funci\u00f3n de scikit-learn que permite graficar el \u00e1rbol.\n    \n    * Link *plot_tree*: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.plot_tree.html#sklearn.tree.plot_tree \n\n**Importante**: Ejecutar las celdas de c\u00f3digo #18 y #19 s\u00f3lo si el \u00c1rbol de Decisi\u00f3n tiene poca profundidad (con MAX < 5).","c0d58039":"**\u00bfPor qu\u00e9 esto es un problema en el entrenamiento de un modelo de predicci\u00f3n?**\n\n**Doble Click aqu\u00ed para ver la respuesta!**\n\n<!-- Las columnas que toman un \u00fanico valor para todos los ejemplos NO van a ayudar al algoritmo de aprendizaje a descubrir un patr\u00f3n en los datos. Pese a que se pueden dejar, en general se eliminan del dataset antes del entrenamiento. -->\n","496fe817":"#### Ya vimos como resolver el problema de predecir el g\u00e9nero musical de una canci\u00f3n usando un \u00c1rbol de Decisi\u00f3n como clasificador. \nEn la pr\u00f3xima secci\u00f3n vamos a resolver el problema **construyendo una Red Neuronal Artificial**. Cuando tengamos los resultados, los vamos a poder comparar con los que obtuvimos reci\u00e9n.","66385972":"## Variables categ\u00f3ricas \n\nUna variable es categ\u00f3rica si toma valores de un conjunto finito de posibilidades. Usualmente sus valores son strings, con lo cual debemos transformarlas a una representaci\u00f3n num\u00e9rica para que sirva como entrada a la RNA o un \u00c1rbol de Decisi\u00f3n. \n\nUna variable categ\u00f3rica puede ser de dos tipos:\n* **Nominal**: las categor\u00edas no tienen un orden inherente.\n  * Ejemplos: color de un veh\u00edculo, la ciudad en la que vive una persona.\n* **Ordinal**: las categor\u00edas s\u00ed tienen un orden inherente, que puede ayudar a reconocer un patr\u00f3n en los datos.\n  * Ejemplos: notas de un examen A+, A, B o C.\n\nEn nuestro caso, nuestro dataset tiene las columnas *popularity*, *artist_name* y *track_name* que son categ\u00f3ricas. Sin embargo, es importante notar la siguiente diferencia entre ellas: mientras que *popularity* tiene 4 valores posibles (bajo, medio, alto y muy_alto), *artist_name* tiene 5149 valores distintos y *track_name* 7942.\n\n**Reflexione:** \u00bfEl nombre de la canci\u00f3n nos va a ayudar a reconocer el g\u00e9nero de la misma? \u00bfY el nombre del artista?\n\n**Doble Click aqu\u00ed para ver la respuesta!**\n<!-- El nombre de una canci\u00f3n no nos dice nada sobre el g\u00e9nero musical, con lo cual no nos resulta \u00fatil. \nRespecto al nombre del artista, podemos suponer que todas las canciones de un mismo artista pueden ser del mismo tipo, sin embargo en este dataset tenemos muchos artistas diferentes que se repiten muy pocas veces. Por esto, el nombre del artista tampoco va a ser \u00fatil para reconocer un patr\u00f3n. -->","d4d01542":"**\u00bfCu\u00e1l es el resultado que nos interesa?**\n\nAnalice a qu\u00e9 corresponden los valores de:\n- Accuracy\n- Precision\n- Recall\n- F1\n\n**Doble Click aqu\u00ed para ver la respuesta!**\n<!-- \nDe manera general, cuando las clases est\u00e1n balanceadas (para cada clase tenemos un n\u00famero similar de ejemplos), podemos elegir accuracy como la medida de performance. En cambio, si las clases est\u00e1n desbalanceadas, precision, recall y f1-score son m\u00e1s adecuadas.\n-->","59c1c93c":"# Secci\u00f3n 4 - Desarrollo de una Red Neuronal Artificial\n\nEn esta secci\u00f3n vamos a utilizar los mismos datos de entrenamiento y validaci\u00f3n, pero esta vez plantearemos una **soluci\u00f3n usando una RNA**. Debemos definir la estructura de la red neuronal, los par\u00e1metros para el entrenamiento (llamados *hiperpar\u00e1metros*) y ejecutar dicho entrenamiento y la evaluaci\u00f3n. En las siguientes celdas iremos realizando estos pasos hasta un obtener un resultado sobre los datos de validaci\u00f3n.\n\n### To-Do Task #7: Definir RNA\nA continuacion se definar\u00e1 la estructura de la RNA:\n* Como se puede ver en la celda de c\u00f3digo #20, en la funci\u00f3n *define_model()* ya se encuentra definida la capa de entrada y la capa de salida de la red. \n* Complete la estructura, **agregando al menos 2 capas ocultas nuevas**.\n    * *Hint:* Use layers.Dense para agregar una capa nueva y considere que el par\u00e1metro *activation* puede ser 'relu' o 'sigmoid').\n    \n    layers.Dense( <<< nro de neuronas>>> , activation = << ver arriba>>).\n    \n    * *Hint:* Prestar atenci\u00f3n a la forma en que se agrega la capa de salida de la red.\n\n* Adem\u00e1s, asigne a la variable *lr*, que representa el **ratio de aprendizaje**, un valor decimal apropiado. (Hint: se sugiere un valor en [0.0000001, 1]).\n\nLink de inter\u00e9s:\n* *Sequential Model*: https:\/\/keras.io\/api\/models\/sequential\/#sequential-class\n* Optimizadores en Keras: https:\/\/keras.io\/api\/optimizers\/#optimizers\n* M\u00e9tricas en Keras: https:\/\/keras.io\/api\/metrics\/ \n* M\u00e9todo *compile*: https:\/\/keras.io\/api\/models\/model_training_apis\/#compile-method\n\n**La estructura que se forma se puede visualizar** de la siguiente manera (la siguiente imagen es s\u00f3lo a modo de ejemplo). Not\u00e1 lo siguiente:\n* En naranja tenemos la capa de entrada, que tendr\u00e1 una neurona por cada atributo de los datos.\n* En gris tenemos las capas ocultas, para las cuales no tenemos restricciones, ni en cuanto a la cantidad de capas que podemos agregar, ni a la cantidad de neuronas de cada una de esas capas. \n* En verde tenemos la capa de salida, que tendr\u00e1 una neurona por cada categor\u00eda de clasificaci\u00f3n.\n* La figura muestra s\u00f3lo algunas conexiones. En la realidad **cada neurona en una capa se conecta con cada neurona de la capa siguiente**.\n\n![nn_incomp (1).jpg](attachment:797a0789-6dc2-44bb-85a3-f851b6056835.jpg)\n\nUna vez que completes la funci\u00f3n y ejecutes la celda #20, **vas a ver una peque\u00f1a tabla que muestra las capas de la RNA creada** y la cantidad de par\u00e1metros entrenables que tiene.","67faa1b5":"### To-Do Task #9: Evaluar RNA entrenada\n* Luego de entrenar la RNA, utilice el m\u00e9todo *evualuate()* para **validar el entrenamiento** utilizando el conjunto de validaci\u00f3n (X_val).\n    * Hint: se usa pr\u00e1cticamente igual que la funci\u00f3n fit(), aunque solo le vamos a pasar los datos de validaci\u00f3n.\n    \n    model.evaluate( <<< datos validaci\u00f3n >>> , << etiquetas validaci\u00f3n >>)    \n\nPod\u00e9s leer sobre los par\u00e1metros de la funci\u00f3n en el siguiente link:\n\nLink: https:\/\/keras.io\/api\/models\/model_training_apis\/#evaluate-method","dbb073ce":"**Opcional:** Experimente con los siguientes comandos para visualizar diferentes porciones del dataset. Cada comando permite obtener diferentes partes del dataset seg\u00fan valores espec\u00edficos de atributos que sirven como filtro. Para ello, debe **descomentar un comando cada vez y ejecutar la celda de c\u00f3digo**.","27022a5a":"# Secci\u00f3n 5 - Submit de Resultados","69f2fd88":"Observ\u00e1 con detenimiento la celda de c\u00f3digo #3 y prest\u00e1 atenci\u00f3n a los comentarios. Luego, ejecutala sin hacer cambios. Como resultado de la ejecuci\u00f3n, debajo de la celda deber\u00eda aparecer texto, mostrando las predicciones para cada canci\u00f3n definidas en la celda de c\u00f3digo anterior, tanto de un \u00c1rbol de Decisi\u00f3n como tambi\u00e9n de una Red Neuronal Artificial.\n\nLuego, pod\u00e9s **descomentar las \u00faltimas tres l\u00edneas y volver a ejecutar la celda**, para ver el formato de las predicciones de cada modelo.","43f08bec":"En lo que sigue del laboratorio se proponen diferentes tareas que se resumen a continuaci\u00f3n:\n* Secci\u00f3n 1 y 2: Carga y preparaci\u00f3n de los datos.\n* Secci\u00f3n 3: Entrenamiento y evaluaci\u00f3n de un \u00c1rbol de Decisi\u00f3n.\n* Secci\u00f3n 4: Dise\u00f1o, entrenamiento y evaluaci\u00f3n de una Red Neuronal.\n* Secci\u00f3n 5: Predicciones sobre un conjunto nuevo de datos.","90626b5c":"## Resumen de lo que hemos realizado\n\nHasta el momento hemos realizar lo siguiente:\n1. Cargamos los datos.\n2. Analizamos los datos para determinar qu\u00e9 pre-procesamiento era necesario realizar.\n3. Completamos valores nulos.\n4. Transformamos la columna *popularity*, pasando de categ\u00f3rica a num\u00e9rica.\n5. Eliminamos columnas irrelevantes o problem\u00e1ticas.\n6. Codificamos la columna target.\n7. Separamos una parte de los datos para validaci\u00f3n.\n\n## En las secciones que siguen\n\n1. En la secci\u00f3n 3 vamos a construir un \u00c1rbol de Decisi\u00f3n.\n2. En la secci\u00f3n 4 vamos a dise\u00f1ar y entrenar una Red Neuronal Artificial.\n3. En la secci\u00f3n 5 haremos predicciones y subiremos los resultados a la competencia.","296d0ff0":"### To-Do Task #10: Obtener predicciones\n* Realizar predicciones sobre el conjunto de validaci\u00f3n y asignarlo a la variable *predictions* (*Hint:* Utilice el m\u00e9todo **predict()**).\n    * Hint: es muy similar a lo que hiciste en la celda anterior, pero en este caso no usamos las etiquetas. \n\nPod\u00e9s leer sobre los par\u00e1metros de la funci\u00f3n en el siguiente link:\n\nLink: https:\/\/keras.io\/api\/models\/model_training_apis\/#predict-method","59c1dc5d":"**M\u00e9trica**: Una m\u00e9trica es una funci\u00f3n matem\u00e1tica que **permite evaluar la performance de un modelo predictivo**. Existen distintas m\u00e9tricas, algunas m\u00e1s convenientes que otras dependiendo del problema que pretendemos resolver. \n\nEn la celda anterior, para las cinco predicciones de un modelo, computamos el \"porcentaje de acierto\". Esta es una m\u00e9trica utilizada com\u00fanmente, denominada *accuracy* (o *exactitud*). M\u00e1s adelante en el laboratorio introduciremos otras tres m\u00e9tricas, que resultan m\u00e1s apropiadas para nuestro problema: *precision*, *recall* y *f1*.","16a4e175":"# Secci\u00f3n 0 - Una breve demostraci\u00f3n de uso de un modelo entrenado\nEn las siguientes celdas de c\u00f3digo importamos dos modelos previamente entrenados en el dataset *train.csv* de este laboratorio:\n* Un \u00c1rbol de Decisi\u00f3n.\n* Una Red Neuronal Artificial.\n\nVamos a utilizar estos modelos para predecir el g\u00e9nero musical de cinco canciones. Las canciones van a tener el mismo formato que los datos de entrenamiento, no van a ser un track de sonido, sino un conjunto de valores para ciertos atributos que ambos modelos esperan recibir.","ebcd7958":"En este punto, para completar la entrega deb\u00e9s:\n1. Click en \"Save version\", arriba a la derecha.\n2. Cuando termine de ejecutar, click en el n\u00famero de versi\u00f3n (al lado de \"Save version\").\n3. En esa pantalla, click en los tres puntos de la \u00faltima versi\u00f3n (lado derecho de la pantalla).\n4. Completar los datos y enviarlo.\n\nTambi\u00e9n pod\u00e9s consultar el documento [*Uso de Kaggle*](https:\/\/docs.google.com\/document\/d\/1wSDC-2cr8-WoPpcjCI7Ad6hmmC3jfPc9oCxdqPcfSdY\/edit?usp=sharing) para guiarte!\n\nEn caso de encontrar alg\u00fan inconveniente, descarg\u00e1 el archivo *my_submission.csv* en el panel derecho *Data -> output -> \/kaggle\/working --> my_submission.csv*. Pod\u00e9s subirlo en la pantalla principal de la competencia o consultarnos!","227af12d":"### To-Do Task #6: Ajustar un \u00c1rbol de Decisi\u00f3n\n* En la celda #17, asigne a la variable MAX el valor de profundidad que mayor resultado obtuvo en la celda anterior.\n* Al ejecutar la celda, **se ajusta un nuevo AD con profundidad m\u00e1xima MAX**, usando los datos de entrenamiento (X_train) y sus etiquetas (y_train).\n* Luego, se hacen **predicciones sobre los datos de validaci\u00f3n** (X_val) usando el AD entrenado.\n* Finalmente, se muestran los resultados obtenidos con estas predicciones. Para ello, **se comparan las predicciones con las etiquetas de los datos de validaci\u00f3n** (y_val).","c1184206":"# Secci\u00f3n 3 - Desarrollo de un \u00c1rbol de Decisi\u00f3n","85bc1bd9":"# Secci\u00f3n 2 - Pre-procesamiento de los datos\n\nEn la primera secci\u00f3n analizamos los datos que tenemos a disposici\u00f3n y encontramos que tenemos **atributos categ\u00f3ricos** (*artist_name*, *track_name* y *popularity*) y atributos con **valores nulos** (*popularity* y *key*). Debido a que tanto un \u00c1rbol de Decisi\u00f3n como una RNA no pueden procesar informaci\u00f3n con estas caracter\u00edsticas, en esta secci\u00f3n vamos a:\n1. **Completar los valores nulos**, y\n2. **Convertir atributos categ\u00f3ricos en num\u00e9ricos**.\n\n\u00a1Comencemos!","8a63befa":"Los \u00c1rboles de Decisi\u00f3n es uno de los algoritmos cl\u00e1sicos de aprendizaje supervisado. El algoritmo permite representar los ejemplos de un conjunto de entrenamiento relacionando sus atributos y la etiqueta que marca la respuesta correcta de cada ejemplo. Un \u00e1rbol de decisi\u00f3n tiene las siguientes caracter\u00edsticas:\n\n* Los nodos internos se etiquetan con atributos que caracterizan a los ejemplos.\n* Los arcos salientes de un nodo etiquetado con un atributo A se etiquetan con cada valor posible de A.\n* Las hojas marcan una decisi\u00f3n o etiqueta de respuesta.\n\nEl algoritmo visto en clase permite el manejo de atributos categ\u00f3ricos (los atributos tienen un rango de valores discreto y finito). En las celdas siguientes presentamos una manera de construir un \u00e1rbol de decisi\u00f3n que es ligeramente diferente, ya que va a recibir datos num\u00e9ricos exclusivamente.\n\nLos \u00c1rboles de Decisi\u00f3n son muy atractivos en la pr\u00e1ctica debido a su **simplicidad y su facilidad de interpretaci\u00f3n**. En otras palabras, podemos entender m\u00e1s f\u00e1cilmente la forma en que se construye el \u00e1rbol y obtener una justificaci\u00f3n cuando realiza una nueva predicci\u00f3n. Estas dos caracter\u00edsticas son m\u00e1s dif\u00edciles de conseguir con algoritmos m\u00e1s sofisticados, como por ejemplo las Redes Neuronales.\n\nEn las siguientes celdas **vamos a construir un \u00c1rbol de Decisi\u00f3n usando los datos** de entrenamiento (X_train) y obtener resultados sobre los datos de validaci\u00f3n (X_val). M\u00e1s adelante vas a poder **comparar estos resultados con los que te brinde la soluci\u00f3n usando una RNA**.\n\n### To-Do Task #5: Probar distintos \u00c1rboles de Decisi\u00f3n\n* En la celda #16, complete la lista *profundidades* con valores enteros (Hint: utizar algunos valores entre 1 y 30).\n* En la misma celda, se ajustan tantos \u00e1rboles de decisi\u00f3n como elementos tenga la lista.\n* Como resultado de la celda #16, deber\u00edas ver una l\u00ednea de texto indicando el resultado obtenido por un AD para cada valor de profundidad de la lista *profundidades*.\n\nLink *documentaci\u00f3n*: \n\n* https:\/\/scikit-learn.org\/stable\/modules\/tree.html\n* https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier","62c84fc6":"**Haga doble click para ver una posible soluci\u00f3n**\n<!-- \nUna posible soluci\u00f3n quedar\u00eda como sigue:\n\ndef define_model():\n    model = Sequential()\n    \n    # Capa de entrada de la red\n    model.add(Input(shape=(num_features ))) ## tama\u00f1o de la entrada a la RNA\n\n    #TO-DO: Complete la red. Ingrese al menos dos capas nuevas.\n    model.add(layers.Dense(64, activation = 'relu'))\n    model.add(layers.Dense(32, activation = 'relu'))\n    \n    # Capa de salida de la red\n    model.add(layers.Dense(num_outputs, activation = 'softmax')) ## tama\u00f1o de la salida = cantidad de clases = 5\n\n    # TO-DO: definir un valor para learning rate\n    lr = 0.0001\n\n    opt = tf.keras.optimizers.SGD(learning_rate = lr)\n\n    model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = 'accuracy')\n    return model\n-->\n","da89b73c":"Podemos obtener informaci\u00f3n sobre los atributos num\u00e9ricos (columnas del dataframe de tipo *int* o *float*), como por ejemplo los valores m\u00e1ximo y m\u00ednimo que toma, la media (mean) y la cantidad de ejemplos no nulos (count). Para ello usamos la funci\u00f3n *describe()*. La misma funci\u00f3n tambi\u00e9n permite obtener informaci\u00f3n sobre columnas categ\u00f3ricas, agregando el par\u00e1metro *include=['object']*. **Ejecut\u00e1 la siguiente celda para ver esta nueva informaci\u00f3n**.","5cef2241":"Como hicimos con el \u00e1rbol de decisi\u00f3n, vamos a prestar atenci\u00f3n a las m\u00e9tricas *precision*, *recall* y *F1-score* ya que el conjunto de ejemplos no est\u00e1 balanceado. \n\nEn este punto, **si ves que para alguna de las clases da malos resultados** (por ejemplo, los valores de la categor\u00eda Indie son todos cercanos a cero), pod\u00e9s modificar la RNA en la funci\u00f3n *define_model()* y **volver a ejecutar** todo a partir de ese punto. Cuando est\u00e9s satisfecho, segu\u00ed adelante con las celdas que faltan.\n\nTambi\u00e9n pod\u00e9s **comparar los resultados** con los obtenidos usando el \u00c1rbol de Decisi\u00f3n. \u00bfCon cu\u00e1l te fue mejor? En los primeros intentos es muy probable que los resultados de la RNA sean peores que los del \u00c1rbol de Decisi\u00f3n. Una RNA es una estructura m\u00e1s compleja y **es m\u00e1s dificil encontrar la configuraci\u00f3n m\u00e1s conveniente**. Adem\u00e1s, **no hay una receta** que funcione para todos los problemas... Es un proceso experimental, de **prueba y error**, que concluye cuando estamos satisfechos con el resultado obtenido.","350e0192":"Observ\u00e1 con detenimiento la celda de c\u00f3digo #2, prestando atenci\u00f3n a los comentarios. Luego **ejecutala sin cambiar nada**. Debajo de la celda, como resultado de la ejecuci\u00f3n, deber\u00eda aparecer una tabla (que llamamos **DataFrame**) con 5 filas de datos (m\u00e1s una fila de encabezado). **Cada fila representa una canci\u00f3n distinta**.","e7c84340":"# Secci\u00f3n 1 - Primeros pasos (carga y visualizaci\u00f3n de datos)\nEn el siguiente bloque de c\u00f3digo se realizan las siguientes tareas:\n\n*   **Importar** el dataset, utilizando el archivo *train.csv*. El dataset se importa como una tabla de datos en pandas, que se denomina *Dataframe*.\n\n    Link: https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.read_csv.html\n*   **Obtener** el n\u00famero de filas y columnas del mismo utilizando su propiedad *shape*.\n*   **Listar** los primeros 10 elementos del dataset utilizando la funci\u00f3n *head*.\n\nRecordar que la \u00faltima columna indica el g\u00e9nero de cada canci\u00f3n a trav\u00e9s de un n\u00famero entero. Cada n\u00famero representa a un g\u00e9nero musical, de la siguiente manera:\n* 0 representa **'Rock'**;\n* 1 representa **'Indie'**;\n* 2 representa **'Pop'**;\n* 3 representa **'Metal'**;\n* 4 representa **'Instrumental'**\n\n**Ejecutar la siguiente celda de c\u00f3digo sin cambiar nada**.","35dd84fb":"# Bonus Track 2\n## Una aplicaci\u00f3n interactiva\n\nEn el siguiente enlace te dejamos una aplicaci\u00f3n desarrollada para la materia en a\u00f1os anteriores. La misma permite construir una RNA, configurar el entrenamiento y ejecutarlo en un problema de clasificaci\u00f3n de im\u00e1genes.\n\nLink: https:\/\/fedeschmidt.github.io\/aplicacion\/","31b9ad14":"## Separando un conjunto de validaci\u00f3n\n\nNecesitamos una porci\u00f3n de los datos para verificar el funcionamiento del modelo aprendido. Este conjunto de datos se denomina **conjunto de validaci\u00f3n**. Un clasificador **no aprende de estos datos**, sino que se usan para verificar lo aprendido.\n\n### To-Do Task #4: Separar datos\n* En la celda de c\u00f3digo #15, definir un valor para la variable *test_size* en el intervalo (0, 1) y ejecutar la celda. Este valor indica el porcentaje de los datos que vamos a destinar al conjunto de validaci\u00f3n. El resto quedar\u00e1 como datos de entrenamiento.\n\nLink *train_test_split*: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.train_test_split.html?highlight=train_test_split#sklearn.model_selection.train_test_split\n\n**Reflexione:** \u00bfQu\u00e9 pasar\u00eda si tomamos un conjunto de validaci\u00f3n muy peque\u00f1o (por caso, un 1% de los datos)? \u00bfQu\u00e9 pasar\u00eda si tomamos un conjunto muy grande de validaci\u00f3n (por caso, 95% de los datos)?\n\n**Doble Click aqu\u00ed para ver la respuesta!**\n<!-- Si tomamos una porci\u00f3n muy peque\u00f1a de los datos para validar el modelo entrenado, puede ocurrir que el resultado obtenido en esos datos no represente correctamente el funcionamiento de la RNA.\n Por el contrario, si destinamos la mayor parte de los datos a validaci\u00f3n, dejando una porci\u00f3n peque\u00f1a para entrenar, el modelo puede no aprender patrones generales de los datos y dar un mal resultado. Recordar que los datos de validaci\u00f3n no se usan para aprender, sino para verificar lo aprendido.\nEn general, se toma entre 10% y 25% de los datos para validaci\u00f3n (dependiendo de la cantidad de datos totales que tengamos). -->","6f9eef77":"**An\u00e1lisis de los datos:** \n\nEn las siguientes celdas de c\u00f3digo vamos a obtener m\u00e1s informaci\u00f3n acerca de los datos con los que estamos trabajando. En particular buscamos conocer:\n1. Los nombres de las columnas de la tabla (utilizando la propiedad *columns* del dataframe).\n2. Para cada columna del dataframe, el tipo de la misma (utilizando *DataFrame.info()*).\n\n En pandas, el tipo de un dato puede ser num\u00e9rico (*int64*, *float64*), categ\u00f3rico (*object*) o de tipo fecha (*datetime*). Tanto una RNA como un \u00c1rbol de Decisi\u00f3n (de acuerdo a la librer\u00eda que vamos a utilizar) necesitan que todas sus entradas sean num\u00e9ricas.\n\n3. **Aquellas columnas que tienen valores nulos**. Si existe alguna, deseamos conocer la cantidad de nulos.\n4. La cantidad de valores que toman las **variables categ\u00f3ricas**.\n5. La cantidad de ejemplos para cada clase en la columna objetivo *class*.\n\n**Ejecutar la siguiente celda de c\u00f3digo sin cambiar nada**.","a58986fa":"## Lectura: Columna target\n\nAntes de entrenar un clasificador debemos **codificar la columna target** (*class* en este caso). \n\nEn primer lugar, separamos la columna target del dataframe y luego la codificamos usando una **representaci\u00f3n One-Hot encoding**. \nEn este caso vamos a usar el m\u00f3dulo OneHotEncoder de *scikit-learn*. Pod\u00e9s leer m\u00e1s en el siguiente link.\n\nLink: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.OneHotEncoder.html?highlight=onehotencoder#sklearn.preprocessing.OneHotEncoder\n\n**Ejecut\u00e1 la siguiente celda de c\u00f3digo #14 sin cambiar nada**.","4adc9319":"# Bonus Track 1\n## Normalizaci\u00f3n de los atributos\n\nUna t\u00e9cnica de pre-procesamiento de los datos que puede resultar importante es la normalizaci\u00f3n de los atributos. Si tenemos atributos que est\u00e1n en diferentes escalas de valores, algunos algoritmos de Machine Learning pueden verse perjudicados por esas diferencias, lo que dificulta encontrar un patr\u00f3n en los datos. Por ejemplo, si para describir una persona tenemos un atributo *altura* medido en metros (por ejemplo, 1.85 mts) y un atributo *peso* medido en kilogramos (por ejemplo, 90 kgs), el segundo va a dominar al primero en muchos algoritmos de aprendizajes, simplemente porque sus valores son mucho m\u00e1s grandes.\n\nEn la siguiente celda de c\u00f3digo te dejamos unas l\u00edneas que permiten transformar los datos a una misma escala. Para hacerlo, ten\u00e9s que ponerlas en la celda donde separaste los datos de entrenamiento y validaci\u00f3n.\n\nNuestros experimentos nos muestran que con esto podemos ganar cerca de 10% de accuracy en datos de test! \n\nPod\u00e9s leer m\u00e1s en el siguiente link: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler","7b5445f6":"Para comenzar, **sin cambiar nada**, ejecut\u00e1 la siguiente celda de c\u00f3digo (usando el bot\u00f3n de Play que aparece a la izquierda de la celda al pararte en ella). Al hacerlo, debajo de la celda deber\u00eda aparecer texto, que es el resultado de la ejecuci\u00f3n.","737f9df2":"**Reflexione:** \u00bfQu\u00e9 ocurre con la columna *'mode'*? Note que la desviaci\u00f3n est\u00e1ndar (std) es cero. \n\nEn el caso de que no visualice el problema de la columna \"mode\", **ejecute la siguiente celda de c\u00f3digo**.","10eeb8f9":"Codificar una variable categ\u00f3rica con tantos valores distintos suele ser un problema, no porque no pueda hacerse sino porque dificulta el aprendizaje de un patr\u00f3n en los datos. Por esta raz\u00f3n, vamos a representar de manera num\u00e9rica s\u00f3lo la columna *popularity*.\n\nPara obtener una representaci\u00f3n num\u00e9rica podemos emplear dos estrategias:\n1. One-hot encoding: genera una columna por cada valor posible de la variable (en este caso, *popularity* tiene 4 valores posibles), poniendo un 1 en la columna adecuada dependiendo del valor (y cero en las dem\u00e1s).\nPara esto podemos usar la funci\u00f3n *get_dummies* de pandas. Se usa con variables nominales.\n\n    Link: https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.get_dummies.html\n\n2. Ordinal encoding: representa cada valor de la variable categ\u00f3rica con un n\u00famero entero, manteniendo el orden entre los valores.\nSe usa con variables ordinales.\n\n**Reflexione:** En nuestro caso, *popularity* toma valores **bajo, medio, alto o muy_alto**. \u00bfQu\u00e9 tipo de variable categ\u00f3rica es? \u00bfQu\u00e9 encoding es m\u00e1s adecuado?\n\n**Doble Click aqu\u00ed para ver la respuesta!**\n<!-- Vemos que existe un orden entre los valores de la variable, con lo cual es ordinal. Luego, pese a que se pueden implementar ambas alternativas de encoding, el m\u00e1s apropiado es el ordinal. -->\n\n### To-Do Task #2: Transformar atributos categ\u00f3ricos\n* En la celda de c\u00f3digo #10, utilice un diccionario para **definir un mapeo** para la columna *popularity*, asignando un n\u00famero a cada valor categ\u00f3rico posible (*Hint:* Comience en cero y **mantenga el orden** de las categor\u00edas originales).\n* Recuerde que los valores para *popularity* son: 'bajo', 'medio', 'alto' y 'muy_alto'.\n* Luego, ejecutando las celdas #11.a y #11.b, pod\u00e9s visualizar el dataframe original (antes de aplicar el mapeo) y la nueva versi\u00f3n para **verificar el resultado obtenido**."}}