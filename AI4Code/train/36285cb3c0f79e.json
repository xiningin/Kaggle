{"cell_type":{"6e05fe2d":"code","d6f4cd88":"code","3abd2b05":"code","4538af01":"code","6a09c9b5":"code","a0c95f5e":"code","44f6a8fa":"code","6c75f589":"code","206ad46e":"code","8fd89676":"code","e369e333":"code","ca5d99fc":"code","b1e0b46e":"code","8400ec37":"code","30a67ce3":"code","79a3c159":"code","fabd1450":"code","1980b539":"code","1e40b50e":"code","7a3c1d59":"code","cb105494":"code","23a849c8":"code","154bcb12":"code","8033e3f9":"code","bf08c6ba":"code","654f0592":"markdown","f96bfed3":"markdown","845d7902":"markdown","bb9c825e":"markdown","37442254":"markdown","c3b5be0b":"markdown"},"source":{"6e05fe2d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm\nimport gc\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision","d6f4cd88":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nprint(device)","3abd2b05":"DIR_PATH = \"\/kaggle\/input\/petfinder-pawpularity-score\/\"\nIMG_SIZE = 128","4538af01":"def get_train_file_path(id):\n    return f\"{DIR_PATH}train\/{id}.jpg\"\n\ndf = pd.read_csv(f\"{DIR_PATH}train.csv\")\ndf['file_path'] = df['Id'].apply(get_train_file_path)","6a09c9b5":"\"\"\"\n!pip install timm\nimport sys\nsys.path.append(\"..\/input\/module\")\nfrom transfer_learning import make_image_feature\nnum_classes = 1000\n\n# global average \u306f\u5168\u7d50\u5408\u306b\u884c\u304f\u3068\u3053\u3057\u304b\u306a\u3044\u3002\nfeatures = make_image_feature(df['Id'], num_classes=num_classes)\n\ncol = [\"Id\"]\nfor i in range(num_classes):\n    col.append(f\"img_feature{i+1}\")\ndf_img_feature = pd.DataFrame(features, columns=col)\ndf_img_feature.to_csv(f\"\/kaggle\/working\/pre_output.csv\")\ndf_all = pd.merge(df, df_img_feature, on=\"Id\")\ndf_all.to_csv(f\"\/kaggle\/working\/train_merged.csv\")\n\ndel features\ngc.collect()\n\"\"\"\npass # \u30bb\u30eb\u306e\u51fa\u529b\u304c\u3046\u3063\u3068\u3046\u3057\u3044","a0c95f5e":"#df_all = pd.read_csv(\"\/kaggle\/input\/petfinder-data\/train_merged.csv\", index_col=0)\n#df_all.head()\n\ndf_img_feature = pd.read_csv(\"\/kaggle\/input\/petfinderdata\/pre_output.csv\", index_col=0)\ndf_all = pd.merge(df, df_img_feature, on=\"Id\")\ndf_all.head()","44f6a8fa":"# normalization\ndef normalization(series):\n    if series.name not in ['Id', 'Pawpularity', 'file_path']:\n        series = (series - series.mean()) \/ series.std()\n    return series\n\ndf_all = df_all.apply(normalization)","6c75f589":"class PetDataSet(Dataset):\n    def __init__(self, df, transforms=None):\n        self.df = df\n        feature_cols = [col for col in df.columns if col not in ['Id', 'Pawpularity', 'file_path']]\n        self.targets = df['Pawpularity'].values\n        self.data = df[feature_cols].values\n        self.transforms = transforms # <-\u8aad\u307f\u51fa\u3057\u6642\u306b\u524d\u51e6\u7406\u3092\u3059\u308b\u3084\u3064\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        meta = self.data[index, :12]\n        im_feature = self.data[index, 12:]\n        target = self.targets[index]\n        \n        if self.transforms:\n            pass\n            \n        return im_feature.astype('float32'), meta.astype('float32'), target.astype('float32')","206ad46e":"# 10\u51fa\u529b\u306eEfficientNet\u3067\u753b\u50cf\u304b\u3089\u7279\u5fb4\u91cf\u3092\u51fa\u3057\u3066\u3001metadata\u3068cat\u3057\u3066\u63a8\u8ad6\n# cat\u4ee5\u964d\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af(\u7dda\u5f62\u30e2\u30c7\u30eb)\u3060\u3051\u5b66\u7fd2\nclass NeuralNet(nn.Module):\n    def __init__(self):\n        super(NeuralNet, self).__init__()\n        #self.flatten = nn.Flatten()\n        self.image_layer = nn.Sequential(\n            #nn.Dropout(0.2),\n            nn.Linear(1000, 32),\n            nn.ReLU(),\n            nn.Linear(32, 20)\n        )\n        self.output_layer = nn.Sequential(\n            #nn.Dropout(0.2),\n            nn.Linear(20+12, 8),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(8, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x_im, x_meta):\n        #x = self.flatten(x)\n        im_out = self.image_layer(x_im)\n        connected = torch.cat([im_out, x_meta], axis=1)\n        output = self.output_layer(connected) * 100\n        return output\n    \ndef init_weights(m):\n    if type(m) == nn.Linear:\n        torch.nn.init.xavier_uniform_(m.weight)\n        m.bias.data.fill_(0.01)","8fd89676":"# coustruct model\nai = NeuralNet().to(device)\nai.apply(init_weights)\n\n# make train, validate dataset\nds = PetDataSet(df_all)\nn_samples = len(ds) \ntrain_size = int(n_samples * 0.9) \nval_size = n_samples - train_size\n\ntrain_dataset, val_dataset = torch.utils.data.random_split(ds, [train_size, val_size])","e369e333":"BATCH_SIZE = 64\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 2)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size = len(val_dataset), shuffle = False, num_workers = 2)\nfull_train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = len(train_dataset), shuffle = False, num_workers = 2)","ca5d99fc":"# mati modal\u3060\u3068\u3046\u307e\u304f\u3044\u304d\u306b\u304f\u3044\ndef train_one_epoch(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    mean = 0\n    for n, (x_im, x_meta, target) in enumerate(dataloader):\n        x_im = x_im.to(device)\n        x_meta = x_meta.to(device)\n        target = target.unsqueeze(1).to(device)\n        pred = model(x_im, x_meta)\n        loss = loss_fn(pred, target)\n        mean += loss \/ BATCH_SIZE\n        \n        optimizer.zero_grad() # \u524d\u56de\u8a08\u7b97\u3057\u305f\u52fe\u914d\u3092\u30af\u30ea\u30a2\n        loss.backward()\n        optimizer.step()\n        \n    return mean\n\ndef validation(val_loader, model, mess=True):\n    for x_im, x_meta, target in val_loader:\n        x_im = x_im.to(device)\n        x_meta = x_meta.to(device)\n        target = target.unsqueeze(1).to(device)\n        pred = model(x_im, x_meta)\n        loss = loss_fn(pred, target)\n\n        return loss.item()","b1e0b46e":"epochs =  100\nloss_fn = nn.MSELoss()\noptimizer = torch.optim.Adam(ai.parameters(), lr=1e-3, weight_decay=30)\n#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n\nlog = []\nval_log = []\nvalid = True\nai.train()\nfor i in tqdm(range(epochs)):\n    loss = train_one_epoch(train_loader, ai, loss_fn, optimizer)\n    #scheduler.step()\n    log.append(loss)\n    if valid:\n        val_log.append(validation(val_loader, ai, mess=False))\n    # print(f\"{i}_th epoch done: loss = {loss}\")","8400ec37":"plt.title(\"MSE\")\nplt.xlabel(\"epochs\")\nplt.plot(log, label=\"train_loss\")\nplt.plot(val_log, label=\"val_loss\")\nplt.legend()\nplt.show()","30a67ce3":"ai.eval()\nprint(\"MSE =\", validation(val_loader, ai)) # 22\u70b9\u304f\u3089\u3044\u9593\u9055\u3063\u3066\u308b 484","79a3c159":"ai.eval()\nfor x_im, x_meta, target in val_loader:\n    x_im = x_im.to(device)\n    x_meta = x_meta.to(device)\n    target = target.unsqueeze(1).to(device)\n    pred = ai(x_im, x_meta)\n    \nn_pred = pred.to(\"cpu\").detach().numpy().copy()\nn_target = target.to(\"cpu\").detach().numpy().copy()","fabd1450":"# y=x\u306b\u306a\u3063\u3066\u305f\u3089\u3044\u3044\n\nplt.figure(figsize=(5,5))\nplt.scatter(n_target, n_pred, marker=\".\")\nplt.xlabel(\"true\")\nplt.ylabel(\"pred\")\nplt.xlim(0,100)\nplt.ylim(0,100)\nplt.show()","1980b539":"er = abs(n_pred-n_target)\nprint(np.mean(er))\nplt.hist(er, bins=100)\nplt.xlim(0,100)\nplt.show()","1e40b50e":"\"\"\"\n!pip install timm\nimport timm\n\ndef test_image_feature(id_series, num_classes=10, IMG_SIZE=128):\n    pretrained = timm.create_model('efficientnet_b5', pretrained=True, num_classes=num_classes)\n    pretrained = pretrained.to(device)\n    features = []\n    for i, path in tqdm(enumerate(os.listdir(\"\/kaggle\/input\/petfinder-pawpularity-score\/test\"))):\n        Id = path.split(\".\")[0]\n        path = \"\/kaggle\/input\/petfinder-pawpularity-score\/test\/\" + path\n        img = cv2.imread(path)\n        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype('float32') \/ 255.\n        img = img.reshape((1,)+img.shape)\n        img = torch.from_numpy(img).clone()\n        img = img.permute(0,3,1,2)\n        img = img.to(device)\n        feature = pretrained(img)[0].tolist()\n        feature.insert(0, Id)\n        features.append(feature)\n        del img, feature\n        gc.collect()\n\n    return features\n\nnum_classes = 1000\n\n# global average \u306f\u5168\u7d50\u5408\u306b\u884c\u304f\u3068\u3053\u3057\u304b\u306a\u3044\u3002\nfeatures = test_image_feature(df['Id'], num_classes=num_classes)\ncol = [\"Id\"]\nfor i in range(num_classes):\n    col.append(f\"img_feature{i+1}\")\ntest_img_feature = pd.DataFrame(features, columns=col)\ntest_img_feature.to_csv(\"\/kaggle\/working\/test_img_feature.csv\", index=False)\n\"\"\"\npass","7a3c1d59":"test_img_feature = pd.read_csv(\"\/kaggle\/input\/test-data\/test_img_feature.csv\")\ntest_img_feature.head()","cb105494":"test_df = pd.read_csv(\"\/kaggle\/input\/petfinder-pawpularity-score\/test.csv\")\ntest_df[\"Pawpularity\"] = np.nan\ntest_df = pd.merge(test_df, test_img_feature, on=\"Id\")\ntest_df.head()","23a849c8":"test_dataset = PetDataSet(test_df)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size = len(test_dataset), shuffle = False, num_workers = 2)","154bcb12":"def test(test_loader, model):\n    for x_im, x_meta, target in test_loader:\n        x_im = x_im.to(device)\n        x_meta = x_meta.to(device)\n        pred = model(x_im, x_meta)\n        \n    return pred","8033e3f9":"evaluation = test(test_loader, ai).to(\"cpu\").detach().numpy().copy()\nevaluation = pd.DataFrame(np.vstack((test_df[\"Id\"].values, evaluation[:,0])).T, columns=[\"Id\", \"Pawpularity\"])\nevaluation.Pawpularity = evaluation.Pawpularity.astype(float)\nevaluation = evaluation.round({\"Pawpularity\":2})","bf08c6ba":"evaluation.to_csv(\"\/kaggle\/working\/submission.csv\", index=False)","654f0592":"# test","f96bfed3":"## training","845d7902":"## construction","bb9c825e":"## validation","37442254":"## consideration","c3b5be0b":"# \u753b\u50cf\u30c7\u30fc\u30bf\u3068\u30e1\u30bf\u30c7\u30fc\u30bf\u304b\u3089\u3001Pawpularity\u3092\u4e88\u6e2c\u3059\u308b\u3002"}}