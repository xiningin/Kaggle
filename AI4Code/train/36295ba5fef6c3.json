{"cell_type":{"83789db6":"code","4eeaf752":"code","6acaf9d0":"code","12589caf":"code","15d86022":"code","5006e7f0":"code","4522720e":"code","b4f88337":"code","ff382994":"code","e217c4f5":"code","3d30fadc":"code","d9252da4":"code","55e1b23d":"code","9901f636":"code","3d59c6f9":"code","a082d390":"code","12e22701":"code","7d68e374":"code","a37e7587":"code","5ec24ccb":"code","c4171f1c":"code","118bc517":"code","579680d6":"code","f86ead42":"code","c3a93520":"code","f3322789":"code","1396ecc6":"code","2d61d57e":"code","68c5aca4":"code","c78d1437":"code","b35cce03":"markdown","51e529ab":"markdown","b323fce3":"markdown","ebf2e519":"markdown","20803cc4":"markdown","76269ef0":"markdown","30c59acf":"markdown","181c135b":"markdown","877889b7":"markdown","f6f4db88":"markdown","8e014487":"markdown","a7c8127c":"markdown","7afac282":"markdown","e3165c59":"markdown","f39aed51":"markdown","035cc837":"markdown","e49458c3":"markdown","39524b11":"markdown","6302c672":"markdown","13dd486c":"markdown","2971e6c0":"markdown","fdb70b58":"markdown","9e831b2f":"markdown","1bb2703e":"markdown","8b70c99d":"markdown","ad773431":"markdown","8e2a1d3f":"markdown","c382ea48":"markdown","1f3ef9da":"markdown","23ba4d5c":"markdown"},"source":{"83789db6":"# Import necessary modules for data analysis and data visualization. \n# Data analysis modules\n# Pandas is probably the most popular and important modules for any work related to data management. \nimport pandas as pd\n\n# numpy is a great library for doing mathmetical operations. \nimport numpy as np\n\n# Some visualization libraries\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n## Some other snippit of codes to get the setting right \n## This is so that the chart created by matplotlib can be shown in the jupyter notebook. \n%matplotlib inline \n%config InlineBackend.figure_format = 'retina' ## This is preferable for retina display. \n\nimport warnings ## importing warnings library. \nwarnings.filterwarnings('ignore') ## Ignore warning\n\nimport os ## imporing os\n\nprint(os.listdir(\"..\/input\/\")) ","4eeaf752":"## Importing the datasets\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","6acaf9d0":"import pandas_profiling\ntrain.profile_report()","12589caf":"test.profile_report()","15d86022":"## Take a look at the overview of the dataset. \ntrain.sample(5)","5006e7f0":"test.sample(5)","4522720e":"#draw a bar plot of survival by sex\nsns.barplot(x=\"Sex\", y=\"Survived\", data=train)\n\n#print percentages of females vs. males that survive\nprint(\"Percentage of females who survived:\", train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of males who survived:\", train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts(normalize = True)[1]*100)","b4f88337":"#draw a bar plot of survival by Pclass\nsns.barplot(x=\"Pclass\", y=\"Survived\", data=train)\n\n#print percentage of people by Pclass that survived\nprint(\"Percentage of Pclass = 1 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 1].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of Pclass = 2 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 2].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of Pclass = 3 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 3].value_counts(normalize = True)[1]*100)","ff382994":"#draw a bar plot for SibSp vs. survival\nsns.barplot(x=\"SibSp\", y=\"Survived\", data=train)\n\n#I won't be printing individual percent values for all of these.\nprint(\"Percentage of SibSp = 0 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 0].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of SibSp = 1 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 1].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of SibSp = 2 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 2].value_counts(normalize = True)[1]*100)","e217c4f5":"#draw a bar plot for Parch vs. survival\nsns.barplot(x=\"Parch\", y=\"Survived\", data=train)\nplt.show()","3d30fadc":"#sort the ages into logical categories\ntrain[\"Age\"] = train[\"Age\"].fillna(-0.5)\ntest[\"Age\"] = test[\"Age\"].fillna(-0.5)\nbins = [-1, 0, 5, 12, 18, 24, 35, 60, np.inf]\nlabels = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\ntrain['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = labels)\ntest['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = labels)\n\n#draw a bar plot of Age vs. survival\nsns.barplot(x=\"AgeGroup\", y=\"Survived\", data=train)\nplt.show()","d9252da4":"train[\"CabinBool\"] = (train[\"Cabin\"].notnull().astype('int'))\ntest[\"CabinBool\"] = (test[\"Cabin\"].notnull().astype('int'))\n\n#calculate percentages of CabinBool vs. survived\nprint(\"Percentage of CabinBool = 1 who survived:\", train[\"Survived\"][train[\"CabinBool\"] == 1].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of CabinBool = 0 who survived:\", train[\"Survived\"][train[\"CabinBool\"] == 0].value_counts(normalize = True)[1]*100)\n#draw a bar plot of CabinBool vs. survival\nsns.barplot(x=\"CabinBool\", y=\"Survived\", data=train)\nplt.show()","55e1b23d":"train = train.drop(['Cabin', 'Ticket', 'PassengerId'], axis = 1)\ntest = test.drop(['Cabin', 'Ticket'], axis = 1)","9901f636":"print(\"Number of people embarking in Southampton (S):\")\nsouthampton = train[train[\"Embarked\"] == \"S\"].shape[0]\nprint(southampton)\n\nprint(\"Number of people embarking in Cherbourg (C):\")\ncherbourg = train[train[\"Embarked\"] == \"C\"].shape[0]\nprint(cherbourg)\n\nprint(\"Number of people embarking in Queenstown (Q):\")\nqueenstown = train[train[\"Embarked\"] == \"Q\"].shape[0]\nprint(queenstown)","3d59c6f9":"train = train.fillna({\"Embarked\": \"S\"})","a082d390":"train.AgeGroup.value_counts()","12e22701":"train.Name.sample(5)","7d68e374":"#create a combined group of both datasets\ncombine = [train, test]\n\n#extract a title for each Name in the train and test datasets\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train['Title'], train['Sex'])","a37e7587":"#replace various titles with more common names\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Capt', 'Col',\n    'Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\n    \n    dataset['Title'] = dataset['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\ntrain[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","5ec24ccb":"#map each of the title groups to a numerical value\ntitle_mapping = {'Mr': 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 6}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    \ntrain.head()","c4171f1c":"# fill missing age with mode age group for each title\nmr_age = train[train[\"Title\"] == 1][\"AgeGroup\"].mode() #Young Adult\nmiss_age = train[train[\"Title\"] == 2][\"AgeGroup\"].mode() #Student\nmrs_age = train[train[\"Title\"] == 3][\"AgeGroup\"].mode() #Adult\nmaster_age = train[train[\"Title\"] == 4][\"AgeGroup\"].mode() #Baby\nroyal_age = train[train[\"Title\"] == 5][\"AgeGroup\"].mode() #Adult\nrare_age = train[train[\"Title\"] == 6][\"AgeGroup\"].mode() #Adult\n\nage_title_mapping = {1: \"Young Adult\", 2: \"Student\", 3: \"Adult\", 4: \"Baby\", 5: \"Adult\", 6: \"Adult\"}\n\nfor x in range(len(train[\"AgeGroup\"])):\n    if train[\"AgeGroup\"][x] == \"Unknown\":\n        train[\"AgeGroup\"][x] = age_title_mapping[train[\"Title\"][x]]\n        \nfor x in range(len(test[\"AgeGroup\"])):\n    if test[\"AgeGroup\"][x] == \"Unknown\":\n        test[\"AgeGroup\"][x] = age_title_mapping[test[\"Title\"][x]]","118bc517":"#map each Age value to a numerical value\nage_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\ntrain['AgeGroup'] = train['AgeGroup'].map(age_mapping)\ntest['AgeGroup'] = test['AgeGroup'].map(age_mapping)\n\n#dropping the Age feature for now, might change\ntrain = train.drop(['Age'], axis = 1)\ntest = test.drop(['Age'], axis = 1)\n\ntrain.AgeGroup = train.AgeGroup.astype(int)\ntrain.head()","579680d6":"#drop the name feature since it contains no more useful information.\ntrain = train.drop(['Name'], axis = 1)\ntest = test.drop(['Name'], axis = 1)","f86ead42":"#map each Sex value to a numerical value\nsex_mapping = {\"male\": 0, \"female\": 1}\ntrain['Sex'] = train['Sex'].map(sex_mapping)\ntest['Sex'] = test['Sex'].map(sex_mapping)\n\ntrain.head()","c3a93520":"#map each Embarked value to a numerical value\nembarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\ntrain['Embarked'] = train['Embarked'].map(embarked_mapping)\ntest['Embarked'] = test['Embarked'].map(embarked_mapping)\n\ntrain.head()","f3322789":"#fill in missing Fare value in test set based on mean fare for that Pclass \nfor x in range(len(test[\"Fare\"])):\n    if pd.isnull(test[\"Fare\"][x]):\n        pclass = test[\"Pclass\"][x] #Pclass = 3\n        test[\"Fare\"][x] = round(train[train[\"Pclass\"] == pclass][\"Fare\"].mean(), 4)\n        \n#map Fare values into groups of numerical values\ntrain['FareBand'] = pd.qcut(train['Fare'], 4, labels = [1, 2, 3, 4])\n#draw a bar plot of FareBand vs. survival\nsns.barplot(x=\"FareBand\", y=\"Survived\", data=train)\nplt.show()\n\ntest['FareBand'] = pd.qcut(test['Fare'], 4, labels = [1, 2, 3, 4])\n\n#drop Fare values\ntrain = train.drop(['Fare'], axis = 1)\ntest = test.drop(['Fare'], axis = 1)\n","1396ecc6":"train.head()","2d61d57e":"from sklearn.model_selection import train_test_split\n\npredictors = train.drop(['Survived'], axis=1)\ntarget = train[\"Survived\"]\nx_train, x_val, y_train, y_val = train_test_split(predictors, target, test_size = 0.22, random_state = 0)","68c5aca4":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\ndectree = DecisionTreeClassifier()\ndectree.fit(x_train, y_train)\ny_pred = dectree.predict(x_val)\nacc_decisiontree = round(accuracy_score(y_pred, y_val) * 100, 2)\nprint(acc_decisiontree)","c78d1437":"#set ids as PassengerId and predict survival \nids = test['PassengerId']\npredictions = dectree.predict(test.drop('PassengerId', axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\nsubmission = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\nsubmission.to_csv('submission.csv', index=False)","b35cce03":"Na coluna \"Embarked\":","51e529ab":"# Conjunto de treinamento","b323fce3":"Na coluna \"Sex\":","ebf2e519":"***\n<img src=\"https:\/\/media.giphy.com\/media\/10QLXvi1KM8heo\/source.gif\" width=\"400\">\n# Part 1: Importando dados e bibliotecas\n<a id=\"import_libraries**\"><\/a>\n## 1a. Carregando bibliotecas\n\nPython \u00e9 uma linguagem fant\u00e1stica, com uma comunidade vibrante que produz muitas bibliotecas incr\u00edveis. N\u00e3o sou muito f\u00e3 de importar tudo de uma s\u00f3 vez para os rec\u00e9m-chegados. Ent\u00e3o, vou apresentar algumas bibliotecas necess\u00e1rias por enquanto e, \u00e0 medida que prosseguirmos, continuaremos a desempacotar novas bibliotecas quando parecer apropriado.\n","20803cc4":"**Por que dois conjuntos?**\n\n<img src=\"https:\/\/miro.medium.com\/max\/2796\/1*FUZS9K4JPqzfXDcC83BQTw.png\" width=\"800\">","76269ef0":"***\n## 1d. Visualizando os dados\n<a id=\"aboutthisdataset\"><\/a>","30c59acf":"Na coluna \"Fare\":\n\nVamos separar os valores dos tickets em grupos l\u00f3gicos, assim como preencher valores vazios no dataset de treinamento.","181c135b":"**Na coluna \"Age\":**\nA coluna possui muitos dados faltando, ent\u00e3o vamos tentar preench\u00ea-los de forma mais inteligente. Para isso, vamos primeiro observar a coluna \"Name\":","877889b7":"#### Cabin\nCabin = n\u00famero da cabine.\nSe tem cabine, provavelmente era rico -> maior chance de sobreviver","f6f4db88":"Precisamos preencher os dados nas colunas que tem valores vazios\n\n**Na coluna \"Embarked\":**","8e014487":"Agora que extra\u00edmos o t\u00edtulo, podemos remover a coluna \"Name\" pois n\u00e3o \u00e9 necess\u00e1ria.","a7c8127c":"<img src=\"http:\/\/data.freehdw.com\/ships-titanic-vehicles-best.jpg\"  Width=\"800\">","7afac282":"Vamos remover as colunas \"Cabin\", \"PassengerId\" e Ticket, pois n\u00e3o nos d\u00e1 mais informa\u00e7\u00f5es","e3165c59":"#### Age","f39aed51":"***\n# Dia de Codar no Titanic\n<a id=\"aboutthiskernel\"><\/a>\n\nOl\u00e1! Esse notebook foi criado para uma introdu\u00e7\u00e3o a Machine Learning feita no evento Dia de Codar em Bras\u00edlia, no dia 7 de dezembro de 2019. A ideia \u00e9 mostrar na pr\u00e1tica como funciona um ciclo de desenvolvimento de uma solu\u00e7\u00e3o com ML e mostrar como Estat\u00edstica pode nos ajudar!\n\nPodem acompanhar pelo celular:\n* Dia de Codar no Titanic 1: http:\/\/bit.ly\/diadecodar1\n* Dia de Codar no Titanic 2: http:\/\/bit.ly\/diadecodar2\n\n### Objetivos\n- <b>Apresentar um processo<\/b> para minera\u00e7\u00e3o de dados.\n- <b>Fazer uma an\u00e1lise estat\u00edstica<\/b> para entender melhor os dados.\n- <b>Realizar uma an\u00e1lise explorat\u00f3ria de dados<\/b> do Titanic e construir algumas visualiza\u00e7\u00f5es.\n- <b>Classificar<\/b>: usar aprendizagem de m\u00e1quina para tentar prever os sobreviventes do Titanic\n\n\n***\n<img src=\"https:\/\/media.giphy.com\/media\/ApV2pfsCbXqFi\/source.gif\" width=\"500\">\n## Sobre o Titanic\n\nEm 15 de abril de 1912, durante sua viagem inaugural, o amplamente considerado \"inafund\u00e1vel\" RMS Titanic afundou ap\u00f3s colidir com um iceberg. Infelizmente, n\u00e3o havia barcos salva-vidas suficientes para todos a bordo, resultando na morte de 1502 dos 2224 passageiros e tripulantes. Embora houvesse algum elemento de sorte envolvido na sobreviv\u00eancia, parece que alguns grupos de pessoas eram mais propensos a sobreviver do que outros. Dessa forma, queremos construir um modelo preditivo que responda \u00e0 pergunta: \u201c**que tipo de pessoas t\u00eam maior probabilidade de sobreviver?**\u201d\n\n**Problema**: Identificar os passageiros e tripulantes que sobreviveram o Titanic com base nos seus dados\n\n","035cc837":"***\n## 2. Constru\u00e7\u00e3o dos modelos\n\nAntes de mais nada, vamos construir um primeiro modelo simples para classificar os dados e avaliar seu desempenho.\n\nUm dos modelos mais simples de Machine Learning \u00e9 o de \u00c1rvores de Decis\u00e3o.\n<img src=\"https:\/\/miro.medium.com\/max\/410\/0*LHzDR-s89Ggfqn7p.png\" width=\"600\">\n\n","e49458c3":"#### SibSp\nSibSp = n\u00famero de irm\u00e3os ou c\u00f4njuges","39524b11":"#### Parch\nParch = n\u00famero de pais e filhos","6302c672":"Primeiro, vamos analisar o desempenho desse modelo com dados que sabemos o resultado, ou seja, os dados de treinamento. Para isso, temos que separar uma parte dos dados de treinamento para poder testar o modelo.","13dd486c":"***\n## 1.e Limpando os dados\nVamos preencher os valores que n\u00e3o est\u00e3o presentes e remover as informa\u00e7\u00f5es desnecess\u00e1rias.","2971e6c0":"#### PClass\nPClass = Ticket Class","fdb70b58":"# Conjunto de teste","9e831b2f":"#### Sexo","1bb2703e":"***\n## 1c. Preview dos dados\n<a id=\"glimpse\"><\/a>\n","8b70c99d":"***\n# Part 3: Submeter as classifica\u00e7\u00f5es\n<a id=\"submit_predictions\"><\/a>\n","ad773431":"Esse notebook foi feito a partir dos notebooks\n* [A Statistical Analysis & ML workflow of Titanic](https:\/\/www.kaggle.com\/masumrumi\/a-statistical-analysis-ml-workflow-of-titanic) do Masum Rumi\n* [Titanic Survival Predictions (Beginner)](https:\/\/www.kaggle.com\/nadintamer\/titanic-survival-predictions-beginner) da Nadim Tamer","8e2a1d3f":"***\n<img src=\"https:\/\/media.giphy.com\/media\/3ocrtl1PeOnK79ud78\/giphy.gif\" width=\"500\">\n# Parte 0: Processo\n\n<a id=\"crispdm\"><\/a>\n## CRISP-DM\n\nO CRISP-DM (Cross-industry standard process for data mining) \u00e9 um processo com etapas iterativas para constru\u00e7\u00e3o de solu\u00e7\u00f5es em Aprendizagem de M\u00e1quina.\n\n1. Entendimento do Dom\u00ednio\n2. Entendimento dos Dados\n3. Processamento\n4. Cria\u00e7\u00e3o dos Modelos\n5. Avalia\u00e7\u00e3o\n6. Deploy\n\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/b\/b9\/CRISP-DM_Process_Diagram.png\/800px-CRISP-DM_Process_Diagram.png\" width=\"400\">\n","c382ea48":"**> Sample dos dados**","1f3ef9da":"***\n## 1b. Carregando os dados","23ba4d5c":"Como a maioria das pessoas vem de Southampton (S), vamos preencher os valores que faltam (que s\u00e3o poucos) com 'S'."}}