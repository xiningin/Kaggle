{"cell_type":{"d99c9611":"code","54ac424e":"code","97e4bf9a":"code","9c5e306a":"code","b401b82b":"code","20b0f980":"code","4adcdaa3":"code","bef0aed5":"code","8b5e72fe":"code","63783dba":"code","c3d293ec":"code","44ee1f7b":"code","6f16086e":"code","def55ab9":"code","92201459":"code","12c2c393":"code","144df1b3":"markdown","16c94b63":"markdown","99005aa9":"markdown","78642b35":"markdown"},"source":{"d99c9611":"import tensorflow as tf","54ac424e":"!wget -c https:\/\/labs.criteo.com\/wp-content\/uploads\/2015\/04\/dac_sample.tar.gz -O - | tar -xz\n# !wget -c http:\/\/go.criteo.net\/criteo-research-kaggle-display-advertising-challenge-dataset.tar.gz  -O - | tar -xz","97e4bf9a":"import pandas as pd\nfrom sklearn import preprocessing","9c5e306a":"# Load the dataset and fill the nan with 0\ncolumns = ['label', *(f'I{i}' for i in range(1, 14)), *(f'C{i}' for i in range(1, 27))]\ndf = pd.read_csv('dac_sample.txt', sep='\\t', names=columns).fillna(0)\ndf","b401b82b":"# Preprocess Dense Features\ndense_cols = [c for c in columns if 'I' in c]\ndf[dense_cols] = preprocessing.StandardScaler().fit_transform(df[dense_cols])\ndf","20b0f980":"# Preprocess Categorical Features\ncat_cols = [c for c in columns if 'C' in c]\nmappings = {\n    col: dict(zip(values, range(len(values))))\n    for col, values in map(lambda col: (col, df[col].unique()), cat_cols)\n}\nfor col, mapping in mappings.items():\n    df[col] = df[col].map(mapping.get)\ndf","4adcdaa3":"label_counts = df.groupby('label')['I1'].count()\nprint(f'Baseline: {max(label_counts.values) \/ sum(label_counts.values) * 100}%')","bef0aed5":"import tensorflow as tf","8b5e72fe":"dense_cols = [c for c in df.columns if 'I' in c]\ncat_cols = [c for c in df.columns if 'C' in c]\nemb_counts = [len(df[c].unique()) for c in cat_cols]","63783dba":"from keras.utils.np_utils import to_categorical","c3d293ec":"TRAIN_SPLIT = 0.2\nVALIDATION_SPLIT = 0.5\n\nds = tf.data.Dataset.zip((\n    tf.data.Dataset.from_tensor_slices((\n        tf.cast(df[dense_cols].values, tf.float32),\n        tf.cast(df[cat_cols].values, tf.int32),\n    )),\n    tf.data.Dataset.from_tensor_slices((\n        tf.cast(to_categorical(df['label'].values, num_classes=2), tf.float32)\n    ))\n)).shuffle(buffer_size=2048)\n\n\nds_test = ds.take(int(len(ds) * TRAIN_SPLIT))\nds_train = ds.skip(len(ds_test))\nds_valid = ds_test.take(int(len(ds_test) * VALIDATION_SPLIT))\nds_test = ds_test.skip(len(ds_valid))","44ee1f7b":"def MLP(arch, activation='relu', out_activation=None):\n    mlp = tf.keras.Sequential()\n\n    for units in arch[:-1]:\n        mlp.add(tf.keras.layers.Dense(units, activation=activation))\n\n    mlp.add(tf.keras.layers.Dense(arch[-1], activation=out_activation))\n\n    return mlp\n\n\nclass SecondOrderFeatureInteraction(tf.keras.layers.Layer):\n    def __init__(self, self_interaction=False):\n        super(SecondOrderFeatureInteraction, self).__init__()\n        self.self_interaction = self_interaction\n\n    def call(self, inputs):\n        batch_size = tf.shape(inputs[0])[0]\n        concat_features = tf.stack(inputs, axis=1)\n\n        dot_products = tf.matmul(concat_features, concat_features, transpose_b=True)\n\n        ones = tf.ones_like(dot_products)\n        mask = tf.linalg.band_part(ones, 0, -1)\n        out_dim = int(len(inputs) * (len(inputs) + 1) \/ 2)\n\n        if not self.self_interaction:\n            mask = mask - tf.linalg.band_part(ones, 0, 0)\n            out_dim = int(len(inputs) * (len(inputs) - 1) \/ 2)\n\n        flat_interactions = tf.reshape(tf.boolean_mask(dot_products, mask), (batch_size, out_dim))\n        return flat_interactions\n\n\nclass DLRM(tf.keras.Model):\n    def __init__(\n            self,\n            embedding_sizes,\n            embedding_dim,\n            arch_bot,\n            arch_top,\n            self_interaction,\n    ):\n        super(DLRM, self).__init__()\n        self.emb = [tf.keras.layers.Embedding(size, embedding_dim) for size in embedding_sizes]\n        self.bot_nn = MLP(arch_bot, out_activation='relu')\n        self.top_nn = MLP(arch_top, out_activation='sigmoid')\n        self.interaction_op = SecondOrderFeatureInteraction(self_interaction)\n\n    def call(self, input):\n        input_dense, input_cat = input\n        emb_x = [E(x) for E, x in zip(self.emb, tf.unstack(input_cat, axis=1))]\n        dense_x = self.bot_nn(input_dense)\n\n        Z = self.interaction_op(emb_x + [dense_x])\n        z = tf.concat([dense_x, Z], axis=1)\n        p = self.top_nn(z)\n\n        return p","6f16086e":"model = DLRM(\n    embedding_sizes=emb_counts,\n    embedding_dim=2,\n    arch_bot=[8, 2],\n    arch_top=[128, 64, 2],\n    self_interaction=False\n)\n\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n    metrics=['accuracy']\n)","def55ab9":"BATCH_SIZE = 128\n\nhistory =model.fit(\n    ds_train.batch(BATCH_SIZE),\n    validation_data=ds_valid.batch(BATCH_SIZE),\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(patience=6, restore_best_weights=True)\n    ],\n    epochs=100,\n    verbose=1,\n)\n","92201459":"model.summary()","12c2c393":"results = model.evaluate(ds_test.batch(BATCH_SIZE))\nprint(f'Loss {results[0]}, Accuracy {results[1]}')","144df1b3":"# Deep Learning Recommendation Model for Personalization and Recommendation Systems (DLRM)\nImplementation of https:\/\/arxiv.org\/abs\/1906.00091 in Tensorflow","16c94b63":"## Load and preprocess the data","99005aa9":"## Build and Train the model","78642b35":"## Download the dataset"}}