{"cell_type":{"1d1309f5":"code","582a411e":"code","ab8620ee":"code","24b10a91":"code","c5a08151":"code","23c96970":"code","206e2588":"code","5a489d8a":"code","8c90d224":"code","4bf42328":"code","1799e6b5":"code","e67e465f":"code","3ec1733e":"code","20a611c7":"code","0f13899e":"code","a2d74e2d":"code","a2ad208f":"code","90535a74":"code","8d5ff8dc":"code","3a853c95":"code","ac4a1b7c":"code","9bab8390":"code","5fa67cec":"code","160941ac":"code","d677b6f3":"code","5efa3f18":"code","12ea2181":"code","6aab341b":"code","09f8944a":"code","88b2f82c":"code","c7c734c9":"code","a804843f":"code","50cb695e":"code","c5d38064":"code","60e0814a":"code","4bb37ac1":"code","d462b974":"code","ca75ae58":"code","a0a9d68b":"code","5e959e53":"code","9babcc18":"code","f4f0ac2b":"code","b0064564":"code","41b72ced":"code","57adb0b6":"code","b326cc18":"code","4259b651":"code","fe48eeae":"code","c64425d5":"markdown","ff42ce36":"markdown","0a71132e":"markdown","0041a91d":"markdown","dccfea55":"markdown","275b1d41":"markdown","65c01bd2":"markdown","5739afa6":"markdown","acdf7b53":"markdown","b3da06eb":"markdown","ea952d3e":"markdown","a98a8931":"markdown","03f1a757":"markdown","c3df48c5":"markdown","533ba279":"markdown","72afa890":"markdown","9e035964":"markdown","86c0d292":"markdown","e401b06d":"markdown","b65f30b3":"markdown","c5ca2c55":"markdown"},"source":{"1d1309f5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","582a411e":"import sklearn\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge ,Lasso\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, PolynomialFeatures\nfrom sklearn.metrics import mean_squared_log_error as msle\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom xgboost import XGBRegressor\n%matplotlib inline","ab8620ee":"train = pd.read_csv('\/kaggle\/input\/bike-sharing-demand\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/bike-sharing-demand\/test.csv')","24b10a91":"train.head()","c5a08151":"test.head()","23c96970":"train.drop(['casual', 'registered'], axis=1, inplace=True)","206e2588":"train.info()","5a489d8a":"train.describe()","8c90d224":"train['datetime'] = pd.to_datetime(train['datetime'], errors='coerce')\ntest['datetime'] = pd.to_datetime(test['datetime'], errors='coerce')\n","4bf42328":"train.info()","1799e6b5":"train.columns","e67e465f":"categorical_cols=['season','holiday','workingday','weather']\nnumerical_cols=['temp','atemp','humidity','windspeed']\nlabel='count'","3ec1733e":"train['Month'] = train['datetime'].dt.month\ntest['Month'] = test['datetime'].dt.month\ntrain['Year'] = train['datetime'].dt.year\ntest['Year'] = test['datetime'].dt.year\ntrain['WeekDay'] = train['datetime'].dt.weekday\ntest['WeekDay'] = test['datetime'].dt.weekday\ntrain['Hour'] = train['datetime'].dt.hour\ntest['Hour'] = test['datetime'].dt.hour","20a611c7":"train.head()","0f13899e":"categorical_cols.extend(['Month', 'Year', 'WeekDay', 'Hour'])","a2d74e2d":"def encodetime(train,test,col,label):\n    d3=train[[col,label]].groupby(col).mean()\n    d3.sort_values(by='count',ascending=False)\n    plt.scatter(x=d3.index,y=d3['count'])\n    plt.xlabel(col)\n    d3=d3.sort_values(by='count')\n    d3['w']=np.arange(train[col].nunique())\n    dic=dict(zip(d3.index,d3['w']))\n    train[col]=train[col].map(dic)\n    test[col]=test[col].map(dic)","a2ad208f":"encodetime(train,test,'Year',label)","90535a74":"encodetime(train,test,'Month',label)\n","8d5ff8dc":"encodetime(train,test,'Hour',label)\n","3a853c95":"encodetime(train,test,'WeekDay',label)\n","ac4a1b7c":"def boxplot(x,y,**kwargs):\n    sns.boxplot(x=x,y=y)\n    x=plt.xticks(rotation=90)\nf=pd.melt(train,id_vars=['count'],value_vars=categorical_cols)\ng=sns.FacetGrid(f,col='variable',col_wrap=2,sharex=False)\ng.map(boxplot,'value','count')","9bab8390":"sns.pairplot(train[[*numerical_cols,'count']])","5fa67cec":"\nf, ax = plt.subplots(figsize=(10, 10))\ncorr = train[[*numerical_cols,'count']].corr()\nsns.heatmap(corr,cmap=sns.diverging_palette(220, 10, as_cmap=True),square=True, ax=ax, annot = True)","160941ac":"f, ax = plt.subplots(figsize=(15, 15))\ncorr = train.corr()\nsns.heatmap(corr,cmap=sns.diverging_palette(220, 10, as_cmap=True),square=True, ax=ax, annot = True)","d677b6f3":"# train=pd.get_dummies(train,columns=['season'])\n# test=pd.get_dummies(test,columns=['season'])\n","5efa3f18":"train.columns","12ea2181":"# defining Lag features\n\nfeatures=['holiday', 'workingday', 'weather', 'temp', 'atemp', 'Hour']\n\ndef lag(data,features, shift):\n    for feature in features:\n        data['lag_'+str(shift)+'_'+feature] = data[feature].shift(shift)","6aab341b":"# lag features for train data\nfor i in range(1,5):\n    lag(train, features, i)\n    lag(train, features, -i)\n    \n    \n    \n# lag features for test data\nfor i in range(1,5):\n    lag(test, features, i)\n    lag(test, features, -i)\n\n","09f8944a":"# for i in [14,30,60]\n#     shifted = temps.shift(1)\n#     window = shifted.rolling(window=i)\n#     means = window.mean()\n#     dataframe = concat([means, temps], axis=1)\n#     dataframe.columns = ['mean(t-2,t-1)', 't+1']","88b2f82c":"# for i in [14,30,60]:\n#     print('Rolling period:', i)\n#     train['rolling_mean_'+str(i)] = train.groupby(['id'])['count'].transform(lambda x: x.shift(1).rolling(i).mean())\n#     temp_df['rolling_std_'+str(i)]  = temp_df.groupby(['id'])['count'].transform(lambda x: x.shift(1).rolling(i).std())","c7c734c9":"print(train.shape)\nprint(test.shape)","a804843f":"train.isnull().sum()","50cb695e":"train.fillna(-1, inplace=True)\ntest.fillna(-1, inplace=True)","c5d38064":"train.tail()","60e0814a":"train['count'].plot(kind='hist')","4bb37ac1":"## using box cox transform\n\ndef trans(x,l1=0.3,l2=0):\n    if l1!=0:\n        return ((x+l2)**l1-1)\/l1\n    else:\n        return np.log(x+l2)\ndef rev_trans(x,l1=0.3,l2=0):\n    return (x*l1+1)**(1\/l1)-l2\n\nz=train[label].apply(trans)   \nsns.displot(z , kde=True, height=8.27, aspect=11.7\/8.27)","d462b974":"from sklearn.model_selection import TimeSeriesSplit\n\nX = train.drop(['count','datetime'],axis=1)\nxtest = test.drop(['datetime'],axis=1)\ny = train['count']\n\ntss = TimeSeriesSplit(n_splits = 5)\nfor train_index, test_index in tss.split(X):\n    X_train, X_valid = X.iloc[train_index, :], X.iloc[test_index,:]\n    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]","ca75ae58":"xt,xv,yt,yv=train_test_split(X,y,test_size=0.2,random_state=0)","a0a9d68b":"def mk_model_xgb(xt,xv,yt,yv,func1,func2,lr=1,min_child_weight =25,colsample_bytree = 0.8,md=None):\n    model =XGBRegressor( colsample_bytree = colsample_bytree, learning_rate = lr,min_child_weight =min_child_weight, max_depth=md )\n    ytt=yt.apply(func1)\n    model.fit(xt,ytt)\n    ypt=np.apply_along_axis(func2,arr=model.predict(xt),axis=0)\n    ypv=np.apply_along_axis(func2,arr=model.predict(xv),axis=0)\n    print('training r2:',r2_score(yt,ypt))\n    print('Validation r2:',r2_score(yv,ypv))\n    print('training rmsle:',np.sqrt(msle(yt,ypt)))\n    print('validation rmsle:',np.sqrt(msle(yv,ypv)))\n    return model","5e959e53":"# applying model on time_series_split\n_=mk_model_xgb(X_train,X_valid,y_train,y_valid,func1=trans,func2=rev_trans,lr=0.2,min_child_weight =20,colsample_bytree = 0.8,md=20)","9babcc18":"# applying model on train_test_split\n_=mk_model_xgb(xt,xv,yt,yv,func1=trans,func2=rev_trans,lr=0.2,min_child_weight =20,colsample_bytree = 0.8,md=20)","f4f0ac2b":"# fit the model on box cox of the target\nmodel=XGBRegressor(colsample_bytree = 0.8, learning_rate = 0.2,min_child_weight =20, max_depth=20).fit(X,y.apply(trans))\n","b0064564":"xtest.head()","41b72ced":"# predict the box cox values of the target\nlog_y_pred = model.predict(xtest)","57adb0b6":"# transform predicted y into its skewed version\nyp=np.apply_along_axis(rev_trans,arr=log_y_pred,axis=0)\nyp = np.round(yp)","b326cc18":"plt.hist(yp)","4259b651":"submission = test[['datetime']].copy()\nsubmission['count'] = yp\nsubmission.head()","fe48eeae":"submission.to_csv('\/kaggle\/working\/submission.csv', index=False)","c64425d5":"### visualizing Catergorical columns","ff42ce36":"### it seems that test data doesn't have casual and registered columns so we have to drop them from the training set","0a71132e":"### heatmap","0041a91d":"### Using XGradient Boosting Regressor","dccfea55":"### no null values exit, all features are numeric except datetime which we should change its type to datetime","275b1d41":"## EDA","65c01bd2":"### loading data","5739afa6":"### temp and atemp columns are highly corrolated\n### hour column is highly corrolated with the label(count)\n### temp and atemp have 0.39 of corrolation with the label","acdf7b53":"### Encoding Weather and Season (One Hot Encoding)","b3da06eb":"### Model Training and Testing","ea952d3e":"### extract categorical and numerical variables","a98a8931":"### seems that train test split lead to low rmsle","03f1a757":"### Encoding time data ordered by mean of label in each category","c3df48c5":"## team members\n### 1- mahmoud abdelmohsen abdelhai\n### 2- mostafa mohamed essawi","533ba279":"### splitting date into train and validation using train test split","72afa890":"### train model on the whole dataset","9e035964":"### target is skewed left","86c0d292":"### create new features (month, year, hour, weekday)","e401b06d":"### splitting date into train and validation using time series split","b65f30b3":"### generate the csv submission file","c5ca2c55":"### visualizing numeric columns"}}