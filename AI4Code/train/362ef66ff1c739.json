{"cell_type":{"5ad68dc9":"code","16b77d2f":"code","d69ff0cd":"code","9e165ef9":"code","9337fc81":"code","68e3d0b8":"code","f27fa726":"markdown"},"source":{"5ad68dc9":"!pip install 'git+https:\/\/github.com\/facebookresearch\/detectron2.git'","16b77d2f":"import detectron2\nfrom pathlib import Path\nimport random, cv2, os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pycocotools.mask as mask_util\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer\nfrom detectron2.engine import BestCheckpointer\nfrom detectron2.checkpoint import DetectionCheckpointer\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer, ColorMode\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\nfrom detectron2.data.datasets import register_coco_instances\nfrom detectron2.utils.logger import setup_logger\nfrom detectron2.evaluation.evaluator import DatasetEvaluator\nfrom detectron2.structures import polygons_to_bitmask\nfrom detectron2.evaluation import inference_on_dataset, print_csv_format\nfrom detectron2.utils import comm\nsetup_logger()","d69ff0cd":"dataDir=Path('..\/input\/livecell-dataset\/LIVECell_dataset_2021\/images')\ncfg = get_cfg()\nregister_coco_instances('sartorius_train',{}, '..\/input\/livecell-dataset\/livecell_annotations_train.json', dataDir)\nregister_coco_instances('sartorius_val',{},'..\/input\/livecell-dataset\/livecell_annotations_val.json', dataDir)\nregister_coco_instances('sartorius_test',{}, '..\/input\/livecell-dataset\/livecell_annotations_test.json', dataDir)\nmetadata = MetadataCatalog.get('sartorius_train')\ntrain_ds = DatasetCatalog.get('sartorius_train')","9e165ef9":"def polygon_to_rle(polygon, shape=(520, 704)):\n    #print(polygon)\n    mask = polygons_to_bitmask([np.asarray(polygon) + 0.25], shape[0], shape[1])\n\n    rle = mask_util.encode(np.asfortranarray(mask))\n    return rle\n\n# Taken from https:\/\/www.kaggle.com\/theoviel\/competition-metric-map-iou\ndef precision_at(threshold, iou):\n    matches = iou > threshold\n    true_positives = np.sum(matches, axis=1) == 1  # Correct objects\n    false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n    false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n\ndef score(pred, targ):\n    pred_masks = pred['instances'].pred_masks.cpu().numpy()\n    enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in pred_masks]\n    enc_targs = list(map(lambda x:x['segmentation'], targ))\n    enc_targs = [polygon_to_rle(enc_targ[0]) for enc_targ in enc_targs]\n    ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, ious)\n        p = tp \/ (tp + fp + fn)\n        prec.append(p)\n    return np.mean(prec)\n\nclass MAPIOUEvaluator(DatasetEvaluator):\n    def __init__(self, dataset_name):\n        dataset_dicts = DatasetCatalog.get(dataset_name)\n        self.annotations_cache = {item['image_id']:item['annotations'] for item in dataset_dicts}\n            \n    def reset(self):\n        self.scores = []\n\n    def process(self, inputs, outputs):\n        for inp, out in zip(inputs, outputs):\n            if len(out['instances']) == 0:\n                self.scores.append(0)    \n            else:\n                targ = self.annotations_cache[inp['image_id']]\n                self.scores.append(score(out, targ))\n\n    def evaluate(self):\n        return {\"MaP IoU\": np.mean(self.scores)}\n\nclass Trainer(DefaultTrainer):\n        \n    @classmethod\n    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n        return MAPIOUEvaluator(dataset_name)\n    \n    def build_hooks(self):\n        \n        # copy of cfg\n        cfg = self.cfg.clone()\n        \n        # build the original model hooks\n        hooks = super().build_hooks()\n        \n        # add the best checkpointer hook\n        hooks.insert(-1, BestCheckpointer(cfg.TEST.EVAL_PERIOD, \n                                         DetectionCheckpointer(self.model, cfg.OUTPUT_DIR),\n                                         \"MaP IoU\",\n                                         \"max\",\n                                         ))\n        return hooks","9337fc81":"cfg.merge_from_file(model_zoo.get_config_file(\"Misc\/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv.yaml\"))\ncfg.DATASETS.TRAIN = (\"sartorius_train\", \"sartorius_test\")\ncfg.DATASETS.TEST = (\"sartorius_val\",)\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"Misc\/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv.yaml\")  # Let training initialize from model zoo\ncfg.SOLVER.IMS_PER_BATCH = 1\ncfg.SOLVER.BASE_LR = 0.0005 \ncfg.SOLVER.MAX_ITER = 10000\ncfg.SOLVER.STEPS = []       \n# cfg.SOLVER.CHECKPOINT_PERIOD = (len(DatasetCatalog.get('sartorius_train')) + len(DatasetCatalog.get('sartorius_test'))) \/\/ cfg.SOLVER.IMS_PER_BATCH  # Once per epoch\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   \ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 8\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\ncfg.TEST.EVAL_PERIOD = (len(DatasetCatalog.get('sartorius_train')) + len(DatasetCatalog.get('sartorius_test'))) \/\/ (cfg.SOLVER.IMS_PER_BATCH*3)  # Once per epoch\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\nprint(cfg.OUTPUT_DIR)\ntrainer = Trainer(cfg) \ntrainer.resume_or_load(resume=False)\ntrainer.train()","68e3d0b8":"!ls .\/output\/model_best.pth","f27fa726":"### Load the LIVECell data"}}