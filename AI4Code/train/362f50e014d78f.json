{"cell_type":{"f901af6d":"code","aa69d362":"code","ea8bbd79":"code","3122f812":"code","dda6b723":"code","a5862406":"code","ffa89f23":"code","00ba43d6":"code","184bbdc9":"code","33d3e1f4":"code","86bee0b2":"code","a768f5c6":"code","c91b30a3":"code","85c9b818":"code","2ff53c8f":"code","10e74313":"code","981025a9":"code","2e6373a8":"code","709a9e4d":"code","c462eb72":"code","6e74e7ce":"code","306e8a06":"code","54d0d00f":"code","45e605dd":"code","7e5f774a":"code","6f4afa34":"code","3f4ec78a":"code","02f5fbcf":"code","cf4fe0f7":"code","d98ce32e":"code","6c126603":"code","554536ed":"code","f07310d5":"code","9011369f":"code","ab1c98a2":"code","ecbe48d1":"code","b03c15ed":"code","74e22f8a":"code","c2703f52":"code","a9e637ba":"code","ede67d64":"code","eae6ae27":"code","bd37f461":"code","fb669171":"code","0a9d8254":"code","d2445b0e":"code","5c0526d4":"code","37123816":"code","dbd3b773":"code","e2d64cc8":"code","21c39da1":"code","c4f35835":"code","72823868":"code","d7a92ab5":"code","23a9bf2c":"code","87a0eb6b":"code","4261a06f":"code","003be760":"code","e7aead63":"code","01976603":"code","28b8c69b":"code","8f27100d":"code","db92494c":"code","ad90ef3c":"code","d8e4fbec":"code","549fc705":"code","002583a0":"code","e71c43f4":"code","243e121a":"code","bb377e80":"code","0b462de5":"code","edcd2816":"code","b3e48c55":"code","40be0d32":"code","2856b1bb":"code","49c25192":"code","06bff9ee":"code","04e45d4a":"code","73c7b27f":"code","8a64296a":"code","ae910d50":"code","379e86cb":"code","68a7513a":"code","370c4fcf":"code","6c3c2e48":"code","780e5c4e":"code","8eb596b9":"code","c86658b5":"code","6e17d5d2":"markdown","9023613b":"markdown","5494c658":"markdown","497b538d":"markdown","85295028":"markdown","97511f3e":"markdown","29cf6dff":"markdown","5ae4eab5":"markdown","cad0e011":"markdown","8e74b18c":"markdown","903db708":"markdown","418710a7":"markdown","81f81767":"markdown","f3c1290e":"markdown","f5faae47":"markdown","4d4a97ff":"markdown","6bb1c4ec":"markdown","40a3bf18":"markdown","5cce1827":"markdown","e83fd680":"markdown","ddd9d92a":"markdown","ada4e924":"markdown","9d645d71":"markdown","cae97da3":"markdown","7b277928":"markdown","19108b53":"markdown","33bd9914":"markdown","c7f3733b":"markdown","8b164ecd":"markdown","4780c5de":"markdown","de92053d":"markdown","f62b1ccf":"markdown","066fc2e0":"markdown","e4dd5d7d":"markdown","ddb9a100":"markdown","d76ffeaf":"markdown","4371a51c":"markdown","e3adf5d3":"markdown","a999a03b":"markdown","21e97a2e":"markdown","bfa7adf0":"markdown"},"source":{"f901af6d":"!nvidia-smi","aa69d362":"!pip install -U efficientnet","ea8bbd79":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\nimport math\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.layers import *\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nimport tensorflow.keras.models as M\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.callbacks as C\nimport efficientnet.tfkeras as efn\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#\u0443\u0432\u0435\u043b\u0438\u0447\u0438\u043c \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u044b\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0433\u0440\u0430\u0444\u0438\u043a\u043e\u0432\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#\u0433\u0440\u0430\u0444\u0438\u043a\u0438 \u0432 svg \u0432\u044b\u0433\u043b\u044f\u0434\u044f\u0442 \u0431\u043e\u043b\u0435\u0435 \u0447\u0435\u0442\u043a\u0438\u043c\u0438\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint(os.listdir(\"..\/input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","3122f812":"!pip freeze > requirements.txt","dda6b723":"EPOCHS               = 5  # \u044d\u043f\u043e\u0445 \u043d\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\nBATCH_SIZE           = 64 # \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u043c batch \u0435\u0441\u043b\u0438 \u0441\u0435\u0442\u044c \u0431\u043e\u043b\u044c\u0448\u0430\u044f, \u0438\u043d\u0430\u0447\u0435 \u043d\u0435 \u0432\u043b\u0435\u0437\u0435\u0442 \u0432 \u043f\u0430\u043c\u044f\u0442\u044c \u043d\u0430 GPU\nLR                   = 0.001\nVAL_SPLIT            = 0.15 # \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u0434\u0430\u043d\u043d\u044b\u0445 \u0432\u044b\u0434\u0435\u043b\u044f\u0435\u043c \u043d\u0430 \u0442\u0435\u0441\u0442 = 15%\n\nCLASS_NUM            = 10  # \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0432 \u043d\u0430\u0448\u0435\u0439 \u0437\u0430\u0434\u0430\u0447\u0435\nIMG_SIZE             = 224 # \u043a\u0430\u043a\u043e\u0433\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u043f\u043e\u0434\u0430\u0435\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f \u0432 \u0441\u0435\u0442\u044c\nIMG_CHANNELS         = 3   # \u0443 RGB 3 \u043a\u0430\u043d\u0430\u043b\u0430\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '..\/input\/sf-dl-car-classification\/'\nPATH = \"..\/working\/car\/\" # \u0440\u0430\u0431\u043e\u0447\u0430\u044f \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044f","a5862406":"# \u0423\u0441\u0442\u0430\u043d\u0430\u043b\u0438\u0432\u0430\u0435\u043c \u043a\u043e\u043d\u043a\u0440\u0435\u0442\u043d\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 random seed \u0434\u043b\u044f \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438\nos.makedirs(PATH,exist_ok=False)\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0","ffa89f23":"train_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()","00ba43d6":"train_df.info()","184bbdc9":"train_df.Category.value_counts()\n# \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u0440\u0430\u0432\u043d\u043e\u043c\u0435\u0440\u043d\u043e\u0435 - \u044d\u0442\u043e \u0445\u043e\u0440\u043e\u0448\u043e","33d3e1f4":"print('\u0420\u0430\u0441\u043f\u0430\u043a\u043e\u0432\u044b\u0432\u0430\u0435\u043c \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438')\n\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(DATA_PATH+data_zip,\"r\") as z:\n        z.extractall(PATH)\n        \nprint(os.listdir(PATH))","86bee0b2":"# \u041f\u0440\u0438\u043c\u0435\u0440\u044b \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u043f\u043e \u043a\u043b\u0430\u0441\u0441\u0430\u043c\nfor category in range(10):\n    plt.figure(figsize=(16, 4))\n\n    cat_image = train_df[train_df['Category'] == category].sample(4)\n    cat_image_paths = cat_image['Id'].values\n    cat_image_cat = cat_image['Category'].values\n\n    for index, path in enumerate(cat_image_paths):\n        im = PIL.Image.open(PATH+f'train\/{cat_image_cat[index]}\/{path}')\n        plt.subplot(1,4, index+1)\n        plt.imshow(im)\n        plt.title('Class: '+str(cat_image_cat[index]))\n        plt.axis('off')\n    plt.show()","a768f5c6":"image = PIL.Image.open(PATH+'\/train\/0\/100380.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","c91b30a3":"!pip install git+https:\/\/github.com\/mjkvaak\/ImageDataAugmentor","85c9b818":"from ImageDataAugmentor.image_data_augmentor import *\nimport albumentations as A","2ff53c8f":"AUG = A.Compose([\n    A.HorizontalFlip(p=0.25),\n    A.ToGray(p=0.15),\n#    A.ToSepia(p=0.25),\n    A.OneOf([\n        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.35),\n    A.ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(-0.06, 0.06), rotate_limit=(-10, 10), interpolation=0, border_mode=0, value=(0, 0, 0), mask_value=None),\n    A.GaussianBlur(p=0.05),\n    A.HueSaturationValue(p=0.25),\n    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_lower=1, num_shadows_upper=2, shadow_dimension=5, always_apply=False, p=0.25),\n])","10e74313":"train_datagen = ImageDataAugmentor(\n        rescale=1.\/255,\n        augment=AUG,\n        validation_split=VAL_SPLIT\n)\ntest_datagen = ImageDataAugmentor(rescale=1.\/255)","981025a9":"# \u0417\u0430\u0432\u0435\u0440\u043d\u0435\u043c \u043d\u0430\u0448\u0438 \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440:\ntrain_generator = train_datagen.flow_from_directory(\n        PATH+'train\/',\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE,\n        class_mode='categorical',\n        shuffle=True, seed=RANDOM_SEED,\n        subset='training')        # set as training data\ntest_generator = train_datagen.flow_from_directory(\n        PATH+'train\/',\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE,\n        class_mode='categorical',\n        shuffle=True, seed=RANDOM_SEED,\n        subset='validation')      # set as validation data\ntest_sub_generator = test_datagen.flow_from_dataframe( \n        dataframe=sample_submission,\n        directory=PATH+'test_upload\/',\n        x_col=\"Id\",\n        y_col=None,\n        shuffle=False,\n        class_mode=None,\n        seed=RANDOM_SEED,\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE)","2e6373a8":"'''train_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    rotation_range = 5,\n#    shear_range=0.15,\n    zoom_range=[0.85,1.15],\n    brightness_range=[0.5, 1.5],\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    validation_split=VAL_SPLIT, # set validation split\n    horizontal_flip=False,\n#    fill_mode=\"nearest\",\n)\n\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)'''","709a9e4d":"'''train_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',      # \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044f \u0433\u0434\u0435 \u0440\u0430\u0441\u043f\u043e\u043b\u043e\u0436\u0435\u043d\u044b \u043f\u0430\u043f\u043a\u0438 \u0441 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0430\u043c\u0438 \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload\/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)'''","c462eb72":"input_shape","6e74e7ce":"base_model = efn.EfficientNetB6(weights='imagenet', include_top=False, input_shape=input_shape)","306e8a06":"base_model.summary()","54d0d00f":"# \u041d\u0435 \u0442\u0440\u0435\u043d\u0438\u0440\u0443\u0435\u043c \u0431\u0430\u0437\u043e\u0432\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0430 \u043f\u0435\u0440\u0432\u043e\u043c \u044d\u0442\u0430\u043f\u0435\nbase_model.trainable = False","45e605dd":"# Making Model\nmodel=M.Sequential()\nmodel.add(base_model)\nmodel.add(BatchNormalization())\nmodel.add(L.GlobalAveragePooling2D())\n#model.add(L.Dropout(0.25))\n#model.add(L.Flatten())\nmodel.add(L.Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(L.Dropout(0.25))     # or 0.5\nmodel.add(L.Dense(CLASS_NUM, activation='softmax'))","7e5f774a":"model.summary()","6f4afa34":"# How many layers\nprint(len(model.layers))","3f4ec78a":"len(model.trainable_variables)","02f5fbcf":"# Check the trainable status of the individual layers\nfor layer in model.layers:\n    print(layer, layer.trainable)","cf4fe0f7":"LR = 0.001\nEPOCHS = 5\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","d98ce32e":"checkpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True,verbose=1)\n#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00001)\ncallbacks_list = [checkpoint, earlystop]","6c126603":"history = model.fit(\n                    train_generator,\n                    steps_per_epoch = train_generator.samples\/\/train_generator.batch_size,\n#                    steps_per_epoch = len(train_generator),\n                    validation_data = test_generator, \n                    validation_steps = test_generator.samples\/\/test_generator.batch_size,\n#                    validation_steps = len(test_generator),\n                    epochs = EPOCHS,\n                    callbacks = callbacks_list\n                    )","554536ed":"# \u041f\u043e\u0434\u0433\u0440\u0443\u0437\u0438\u043c \u043b\u0443\u0447\u0448\u0443\u044e \u0438\u0442\u0435\u0440\u0430\u0446\u0438\u044e \u0432 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438 (best_model)\nmodel.save('..\/working\/model_step1.hdf5')\nmodel.load_weights('best_model.hdf5')","f07310d5":"# \u041f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043d\u0430 \u044d\u0442\u043e\u043c \u0448\u0430\u0433\u0435\nscores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","9011369f":"def plot_history(history):\n    plt.figure(figsize=(10,5))\n    #plt.style.use('dark_background')\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs = range(len(acc))\n\n    plt.plot(epochs, acc, 'b', label='Training acc')\n    plt.plot(epochs, val_acc, 'g', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n\n    #plt.figure()\n    plt.figure(figsize=(10,5))\n    #plt.style.use('dark_background')\n    plt.plot(epochs, loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'g', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n\n    plt.show()\n\nplot_history(history)","ab1c98a2":"print(\"Number of layers in the base model: \", len(base_model.layers))","ecbe48d1":"base_model.trainable = True\n\n# Fine-tune from this layer onwards\nfine_tune_at = len(base_model.layers)\/\/2\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable =  False\nlen(base_model.trainable_variables)","b03c15ed":"# Check the trainable status of the individual layers\nfor layer in model.layers:\n    print(layer, layer.trainable)","74e22f8a":"# \u0418\u0437\u043c\u0435\u043d\u0438\u043c \u0433\u0438\u043f\u0435\u0440\u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b\nLR=0.0001\nEPOCHS = 10\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","c2703f52":"# LearningRateScheduler - HandMade\nlr_list = [1e-03, 2e-03, 5e-03, 2e-03, 1e-03, 5e-04, 2.5e-04, 1e-04, 1e-04, 5e-05]\ndef schedule(epoch):\n    return lr_list[epoch]","a9e637ba":"checkpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1)\nlr_scheduler = LearningRateScheduler(schedule, verbose=1)\ncallbacks_list = [checkpoint, earlystop, lr_scheduler]","ede67d64":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch = train_generator.samples\/\/train_generator.batch_size,\n        validation_data = test_generator, \n        validation_steps = test_generator.samples\/\/test_generator.batch_size,\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","eae6ae27":"model.save('..\/working\/model_step2.hdf5')\nmodel.load_weights('best_model.hdf5')","bd37f461":"scores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","fb669171":"plot_history(history)","0a9d8254":"base_model.trainable = True","d2445b0e":"BATCH_SIZE = 16\nLR=0.00001\nEPOCHS = 10","5c0526d4":"train_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',      # \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044f \u0433\u0434\u0435 \u0440\u0430\u0441\u043f\u043e\u043b\u043e\u0436\u0435\u043d\u044b \u043f\u0430\u043f\u043a\u0438 \u0441 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0430\u043c\u0438 \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload\/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)","37123816":"model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","dbd3b773":"'''# LearningRateScheduler - Exponential Decay\n# Define configuration parameters\nstart_lr = LR\nexp_decay = 0.33\n\n# Define the scheduling function\ndef schedule(epoch):\n    def lr(epoch, start_lr, exp_decay):\n        return start_lr * math.exp(-exp_decay*epoch)\n    return lr(epoch, start_lr, exp_decay)'''","e2d64cc8":"'''# LearningRateScheduler - HandMade\nlr_list = [5e-5, 5e-5, 7e-5, 8e-5, 3e-5, 2e-5, 1.5e-5, 1e-5, 4e-5, 2.5e-5, 2e-5, 1e-5, 1e-5, 5e-6, 5e-6]\ndef schedule(epoch):\n    return lr_list[epoch]'''","21c39da1":"# LearningRateScheduler - One CLR\n# LR \u0440\u0430\u0441\u0442\u0435\u0442 \u043e\u0442 start_lr \u043b\u0438\u043d\u0435\u0439\u043d\u043e rampup_epochs \u044d\u043f\u043e\u0445 \u0434\u043e max_lr, \u0437\u0430\u0442\u0435\u043c 3 \u0434\u0435\u043b\u0430\u0435\u0442 \u0448\u0430\u0433\u0430 \u043d\u0430 max_lr, \u0434\u0430\u043b\u0435\u0435 \u0443\u0431\u044b\u0432\u0430\u0435\u0442 \u043f\u043e \u044d\u043a\u0441\u043f\u043e\u043d\u0435\u043d\u0442\u0435 \u043d\u0435 \u043e\u0447\u0435\u043d\u044c \u043a\u0440\u0443\u0442\u043e \u0432 \u0441\u0442\u043e\u0440\u043e\u043d\u0443 min_lr \n# Define configuration parameters\nstart_lr = 0.00001\nmin_lr = 0.000001\nmax_lr = 0.0001\nrampup_epochs = 4\nsustain_epochs = 2\nexp_decay = 0.8\n\n# Define the scheduling function\ndef schedule(epoch):\n    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n        if epoch < rampup_epochs:\n            lr = (max_lr - start_lr)\/rampup_epochs * epoch + start_lr\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr\n        else:\n            lr = (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n        return lr\n    return lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay)","c4f35835":"checkpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1)\nlr_scheduler = LearningRateScheduler(schedule, verbose=1)\ncallbacks_list = [checkpoint, earlystop, lr_scheduler]","72823868":"#from tensorflow import keras\n#model = keras.models.load_model(\"..\/working\/last_model\/\")\n#model = M.load_model(\"..\/working\/last_model\/\")","d7a92ab5":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch = train_generator.samples\/\/train_generator.batch_size,\n        validation_data = test_generator, \n        validation_steps = test_generator.samples\/\/test_generator.batch_size,\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","23a9bf2c":"model.save('..\/working\/model_step3.hdf5')\nmodel.load_weights('best_model.hdf5')","87a0eb6b":"scores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","4261a06f":"plot_history(history)","003be760":"EPOCHS               = 5\nBATCH_SIZE           = 4 # \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u043c batch \u0435\u0449\u0451 \u0431\u043e\u043b\u044c\u0448\u0435, \u0438\u043d\u0430\u0447\u0435 \u043d\u0435 \u0432\u043b\u0435\u0437\u0435\u0442 \u0432 \u043f\u0430\u043c\u044f\u0442\u044c \u043d\u0430 GPU\nLR                   = 1e-6\n\nIMG_SIZE             = 512 # \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u0432\u0430\u0435\u043c \u0440\u0430\u0437\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a\nIMG_CHANNELS         = 3\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)","e7aead63":"AUG = A.Compose([\n    A.HorizontalFlip(p=0.25),\n    A.ToGray(p=0.25),\n#    A.ToSepia(p=0.5),\n    A.OneOf([\n        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.5),\n    A.ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(-0.06, 0.06), rotate_limit=(-10, 10), interpolation=0, border_mode=0, value=(0, 0, 0), mask_value=None),\n#    A.GaussianBlur(p=0.05),\n#    A.HueSaturationValue(p=0.25),\n    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_lower=1, num_shadows_upper=2, shadow_dimension=5, always_apply=False, p=0.25),\n])","01976603":"train_datagen = ImageDataAugmentor(\n        rescale=1.\/255,\n        augment=AUG,\n        validation_split=VAL_SPLIT\n)\ntest_datagen = ImageDataAugmentor(rescale=1.\/255)","28b8c69b":"'''train_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n#    rotation_range = 5,\n#    shear_range=0.15,\n    zoom_range=[0.85,1.15],\n#    brightness_range=[0.75, 1.25],\n    width_shift_range=0.1,\n#    height_shift_range=0.1,\n    validation_split=VAL_SPLIT, # set validation split\n    horizontal_flip=False,\n#    fill_mode=\"nearest\",\n)\n\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)'''","8f27100d":"train_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',       \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') \n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train\/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') \n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload\/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)\n","db92494c":"# \u0437\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c \u0437\u0430\u043d\u043e\u0432\u043e \u043d\u0430 \u043d\u043e\u0432\u044b\u0445 \u0440\u0430\u0437\u043c\u0435\u0440\u0430\u0445 \u0444\u043e\u0442\u043e\nbase_model = efn.EfficientNetB6(weights='imagenet', include_top=False, input_shape=input_shape)","ad90ef3c":"model=M.Sequential()\nmodel.add(base_model)\nmodel.add(BatchNormalization())\nmodel.add(L.GlobalAveragePooling2D())\n#model.add(L.Dropout(0.25))\n#model.add(L.Flatten())\nmodel.add(L.Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(L.Dropout(0.25))     # or 0.5\nmodel.add(L.Dense(CLASS_NUM, activation='softmax'))","d8e4fbec":"# \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u043c\u043e\u0434\u0435\u043b\u044c, \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u043d\u0443\u044e \u0432 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0443\u044e \u0441\u0435\u0441\u0441\u0438\u044e\n#from tensorflow import keras\n#model = keras.models.load_model(\"..\/input\/modelstep4last\/model_step4.hdf5\")","549fc705":"model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","002583a0":"#model.load_weights('best_model.hdf5')\n#model.load_weights(\"..\/input\/modelstep4last\/model_step4.hdf5\")","e71c43f4":"model.summary()","243e121a":"# \u041f\u0435\u0440\u0435\u0433\u0440\u0443\u0436\u0430\u0435\u043c callbacks, \u0447\u0442\u043e\u0431\u044b \u0443\u0431\u0440\u0430\u0442\u044c lr_scheduler \ncheckpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1)\ncallbacks_list = [checkpoint, earlystop]","bb377e80":"# \u041e\u0431\u0443\u0447\u0430\u0435\u043c\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch = train_generator.samples\/\/train_generator.batch_size,\n        validation_data = test_generator, \n        validation_steps = test_generator.samples\/\/test_generator.batch_size,\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n        )","0b462de5":"model.save('..\/working\/model_step4.hdf5')\nmodel.load_weights('best_model.hdf5')","edcd2816":"#model.load_weights('model_step4.hdf5')","b3e48c55":"scores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","40be0d32":"plot_history(history)  ","2856b1bb":"model.load_weights('best_model.hdf5')","49c25192":"AUG = A.Compose([\n    A.HorizontalFlip(p=0.25),\n    A.ToGray(p=0.25),\n    A.OneOf([\n        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.25),\n    A.ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(-0.06, 0.06), rotate_limit=(-10, 10), interpolation=0, border_mode=0, value=(0, 0, 0), mask_value=None),\n    A.GaussianBlur(p=0.05),\n    A.HueSaturationValue(p=0.25),\n    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_lower=1, num_shadows_upper=2, shadow_dimension=5, always_apply=False, p=0.25),\n])","06bff9ee":"test_datagen = ImageDataAugmentor(rescale=1.\/255)","04e45d4a":"'''test_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    rotation_range = 5,\n    shear_range=0.15,\n    zoom_range=[0.85,1.15],\n    brightness_range=[0.75, 1.25],\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n#    validation_split=VAL_SPLIT, # set validation split\n    horizontal_flip=True,\n#    fill_mode=\"nearest\",\n)'''","73c7b27f":"BATCH_SIZE = 4","8a64296a":"test_sub_generator = test_datagen.flow_from_dataframe( \n        dataframe=sample_submission,\n        directory=PATH+'test_upload\/',\n        x_col=\"Id\",\n        y_col=None,\n        shuffle=False,\n        class_mode=None,\n        seed=RANDOM_SEED,\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE)","ae910d50":"tta_steps = 5\npredictions = []\n\nfor i in range(tta_steps):\n    preds = model.predict(test_sub_generator, verbose=1) \n    predictions.append(preds)\n\npred = np.mean(predictions, axis=0)","379e86cb":"predictions = np.argmax(pred, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]\nfilenames_with_dir=test_sub_generator.filenames\n\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload\/','')\nsubmission.to_csv('submission.csv', index=False)\nprint('Save submit')","68a7513a":"submission.head()","370c4fcf":"test_sub_generator.samples","6c3c2e48":"test_sub_generator.reset()\npredictions = model.predict(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","780e5c4e":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload\/','')\nsubmission.to_csv('submission.csv', index=False)\nprint('Save submit')","8eb596b9":"submission.head()","c86658b5":"# Clean PATH\n#import shutil\n#shutil.rmtree(PATH)","6e17d5d2":"\u041e\u0431\u0443\u0447\u0430\u0435\u043c:","9023613b":"# Step 1","5494c658":"\u0417\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u044b 4 \u043f\u0440\u0438\u043c\u0435\u0440\u043d\u043e \u043e\u0434\u0438\u043d\u0430\u043a\u043e\u0432\u044b\u0445 \u043f\u043e \u0441\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u0435 \u044d\u0442\u0430\u043f\u0430 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0438, \u0442\u0435\u043f\u0435\u0440\u044c \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442","497b538d":"\u041d\u0430 \u044d\u0442\u043e\u043c \u044d\u0442\u0430\u043f\u0435 \u0434\u043e\u0441\u0442\u0438\u0433\u0430\u0435\u0442\u0441\u044f \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043f\u043e\u0440\u044f\u0434\u043a\u0430 0.70 ","85295028":" \u0426\u0435\u043b\u044c \u044d\u0442\u043e\u0433\u043e \u043f\u0440\u043e\u0435\u043a\u0442\u0430 - \u043f\u0435\u0440\u0432\u043e\u0435 \u043f\u0440\u0430\u043a\u0442\u0438\u0447\u0435\u0441\u043a\u043e\u0435 \u0437\u043d\u0430\u043a\u043e\u043c\u0441\u0442\u0432\u043e \u0441 \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u044f\u043c\u0438 \u0438 \u043f\u0440\u0438\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u0441\u0442\u044b\u0445 \u043f\u0440\u0438\u0435\u043c\u043e\u0432 \u0434\u043b\u044f \u0443\u043b\u0443\u0447\u0448\u0435\u043d\u0438\u044f \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u0430 \u0440\u0430\u0431\u043e\u0442\u044b \u0441\u043e\u0431\u0440\u0430\u043d\u043d\u043e\u0439 \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0438.  \n \n \u041a\u0440\u0430\u0442\u043a\u0430\u044f \u0441\u0445\u0435\u043c\u0430 \u0434\u0435\u0439\u0441\u0442\u0432\u0438\u0439:\n \n 1. \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a \u0438 \u0434\u0430\u043d\u043d\u044b\u0445  \n 2. \u041f\u0440\u0435\u0434\u0432\u0430\u0440\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0439 \u0430\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u043d\u044b\u0445\n 3. \u0410\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 Albumentations \u0438 \u043f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\u043e\u0432 \u0434\u0430\u043d\u043d\u044b\u0445\n 4. Transfer Learning - \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0438 \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u043e\u0441\u043d\u043e\u0432\u044b \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u043e\u0439 \u043d\u0430 Imagenet \u0441\u0435\u0442\u0438 EfficientNetB6\n 5. Fine Tuning - \u043f\u043e\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u0442\u0435\u043b\u044c\u043d\u043e\u0435 \u0432\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u0435 \u0432 \u0440\u0430\u0431\u043e\u0442\u0443 \u0441\u043b\u043e\u0435\u0432 \u0441\u0435\u0442\u0438 EfficientNetB6 (0% - 50% -100%)\n 6. \u041f\u043e\u0434\u0431\u043e\u0440 Learning Rate \u0432\u0440\u0443\u0447\u043d\u0443\u044e \u0438 \u0447\u0435\u0440\u0435\u0437 callbacks, \u043f\u043e\u0434\u0431\u043e\u0440 optimizer\n 7. \u0423\u0432\u0435\u043b\u0438\u0447\u0435\u043d\u0438\u0435 \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u043f\u043e\u0434\u0430\u0432\u0430\u0435\u043c\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 \u043d\u0430 \u043f\u043e\u0441\u043b\u0435\u0434\u043d\u0435\u043c \u044d\u0442\u0430\u043f\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0441\u0435\u0442\u0438 \u0434\u043b\u044f \u043f\u043e\u0432\u044b\u0448\u0435\u043d\u0438\u044f \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438\n 8. Test Time Augmentation (TTA) \u0434\u043b\u044f \u0443\u0441\u0440\u0435\u0434\u043d\u0435\u043d\u0438\u044f \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u0445 \u043f\u0440\u0435\u0434\u0438\u043a\u0442\u043e\u0432 \u0438 \u0438\u0441\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u044f \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0445 \u043e\u0448\u0438\u0431\u043e\u043a\n\n \u041e\u0441\u043d\u043e\u0432\u043e\u0439 \u0434\u043b\u044f \u043f\u0440\u043e\u0435\u043a\u0442\u0430 \u043f\u043e\u0441\u043b\u0443\u0436\u0438\u043b\u0438 \u043d\u043e\u0443\u0442\u0431\u0443\u043a\u0438  BaseLine \u0438 transfer-learning-keras-flowers-sf-dl-v2 \u0438\u0437 \u043a\u0443\u0440\u0441\u0430. ","97511f3e":"# Submission with TTA","29cf6dff":"## \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","5ae4eab5":"\u0421\u043e\u0431\u0438\u0440\u0430\u0435\u043c \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u044c: \u043a \u0431\u0430\u0437\u043e\u0432\u043e\u0439 EfficientNetB6 \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0434\u0432\u0430 \u043f\u043b\u043e\u0442\u043d\u044b\u0445 \u0441\u043b\u043e\u044f, \u0432\u0442\u043e\u0440\u043e\u0439 \u0438\u0437 \u043d\u0438\u0445 - \u043d\u0435\u043f\u043e\u0441\u0440\u0435\u0434\u0441\u0442\u0432\u0435\u043d\u043d\u043e \u0434\u043b\u044f \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438.  \n\u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u0442\u0430\u043a\u0436\u0435 \u0432\u0441\u043f\u043e\u043c\u043e\u0433\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0435 Pooling \u0438 Dropout \u0441\u043b\u043e\u0438, \u0430 \u0442\u0430\u043a\u0436\u0435 BatchNormalization","cad0e011":"\u0420\u0430\u0437\u043c\u043e\u0440\u043e\u0437\u0438\u043c \u043f\u043e\u043b\u043e\u0432\u0438\u043d\u0443 \u0441\u043b\u043e\u0435\u0432 \u0431\u0430\u0437\u043e\u0432\u043e\u0439 \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0438","8e74b18c":"\u0421\u043e\u0431\u0438\u0440\u0430\u0435\u043c \u043d\u0430\u0431\u043e\u0440 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0439 \u0438\u0441\u0445\u043e\u0434\u043d\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439","903db708":"\u041f\u0435\u0440\u0435\u043e\u043f\u0440\u0435\u0434\u0435\u043b\u044f\u0435\u043c \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440 \u0434\u0430\u043d\u043d\u044b\u0445, \u0447\u0442\u043e\u0431\u044b \u0443\u0447\u0435\u0441\u0442\u044c \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u0440\u0430\u0437\u043c\u0435\u0440\u0430 \u0431\u0430\u0442\u0447\u0430","418710a7":"# \u041f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0435 \u0431\u0435\u0437 TTA","81f81767":"# \u0418\u0442\u043e\u0433\u0438:","f3c1290e":"# \u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438","f5faae47":"# \u041a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439","4d4a97ff":"**\u0420\u0430\u0431\u043e\u0442\u0430\u0435\u043c \u0441 Tensorflow v2**","6bb1c4ec":"\u041d\u0430 \u044d\u0442\u043e\u043c \u044d\u0442\u0430\u043f\u0435 \u0434\u043e\u0441\u0442\u0438\u0433\u0430\u0435\u0442\u0441\u044f \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043f\u043e\u0440\u044f\u0434\u043a\u0430 0.960 - 0.965  \n\u0418\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435 LearningRateScheduler \u043d\u0435 \u0434\u0430\u0435\u0442 \u0437\u0430\u043c\u0435\u0442\u043d\u043e\u0433\u043e \u0443\u043b\u0443\u0447\u0448\u0435\u043d\u0438\u044f  \n\u0417\u0430\u0442\u0440\u0430\u0442\u044b \u0432\u0440\u0435\u043c\u0435\u043d\u0438 - 8 \u043c\u0438\u043d\u0443\u0442 \u043d\u0430 \u044d\u043f\u043e\u0445\u0443, \u0432\u0441\u0435\u0433\u043e - 80 \u043c\u0438\u043d","40a3bf18":"\u0423\u0432\u0435\u043b\u0438\u0447\u0438\u0432\u0430\u0435\u043c \u0440\u0430\u0437\u043c\u0435\u0440 \u043f\u043e\u0434\u0430\u0432\u0430\u0435\u043c\u044b\u0445 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439, \u043f\u0440\u0438\u0445\u043e\u0434\u0438\u0442\u0441\u044f \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0442\u044c batch \u0438 \u0440\u0435\u0437\u043a\u043e \u0432\u043e\u0437\u0440\u0430\u0441\u0442\u0430\u0435\u0442 \u0432\u0440\u0435\u043c\u044f \u043e\u0431\u0441\u0447\u0438\u0442\u044b\u0432\u0430\u043d\u0438\u044f \u043e\u0434\u043d\u043e\u0439 \u044d\u043f\u043e\u0445\u0438","5cce1827":"\u041d\u0430 \u044d\u0442\u043e\u043c \u044d\u0442\u0430\u043f\u0435 \u0434\u043e\u0441\u0442\u0438\u0433\u0430\u0435\u0442\u0441\u044f \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c \u043f\u043e\u0440\u044f\u0434\u043a\u0430 0.970 - 0.975, \u043d\u043e \u0435\u0441\u0442\u044c \u043f\u043e\u0442\u0435\u043d\u0446\u0438\u0430\u043b \u0440\u043e\u0441\u0442\u0430 \u043f\u0440\u0438 \u0443\u0432\u0435\u043b\u0438\u0447\u0435\u043d\u0438\u0438 \u043a\u043e\u043b-\u0432\u0430 \u044d\u043f\u043e\u0445  \n\u0417\u0430\u0442\u0440\u0430\u0442\u044b \u0432\u0440\u0435\u043c\u0435\u043d\u0438 - 40 \u043c\u0438\u043d\u0443\u0442 \u043d\u0430 \u044d\u043f\u043e\u0445\u0443, \u0432\u0441\u0435\u0433\u043e - 200 \u043c\u0438\u043d","e83fd680":"# Big Images","ddd9d92a":"# No Power CNN","ada4e924":"\u0414\u043e\u0431\u0430\u0432\u0438\u043c LearningRateScheduler \u0434\u043b\u044f \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f LR \u0432 \u0445\u043e\u0434\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f.  \n\u041f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u043f\u0440\u043e\u0444\u0438\u043b\u044c \u0441 \u043d\u0435\u0431\u043e\u043b\u044c\u0448\u0438\u043c \u0445\u043e\u043b\u043c\u043e\u043c, \u0447\u0442\u043e\u0431\u044b \u0432\u044b\u0439\u0442\u0438 \u0438\u0437 \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0433\u043e \u043b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u043c\u0438\u043d\u0438\u043c\u0443\u043c\u0430","9d645d71":"* \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0430 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0430 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439 Albumentations\n* \u041f\u0440\u0438\u043c\u0435\u043d\u0435\u043d transfer learning \u0441 fine-tuning\n* \u0418\u0441\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u043d\u044b \u0440\u0430\u0437\u043d\u044b\u0435 \u043f\u043e\u0434\u0445\u043e\u0434\u044b \u043a \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044e LR, \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u0435 optimizer\n* \u0420\u0430\u0437\u043c\u0435\u0440 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438 \u0438 \u0431\u0430\u0442\u0447 \u0438\u0437\u043c\u0435\u043d\u044f\u043b\u0438\u0441\u044c \u043d\u0430 \u0440\u0430\u0437\u043d\u044b\u0445 \u044d\u0442\u0430\u043f\u0430\u0445   \n* \u0421\u0434\u0435\u043b\u0430\u043d TTA (Test Time Augmentation)\n* \u041b\u0443\u0447\u0448\u0438\u0439 \u0434\u043e\u0441\u0442\u0438\u0433\u043d\u0443\u0442\u044b\u0439 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 - 0.97558\n* BaseLine \u0438 \u043d\u043e\u0443\u0442\u0431\u0443\u043a \u0438\u0437 \u0443\u0447\u0435\u0431\u043d\u043e\u0433\u043e \u043a\u0443\u0440\u0441\u0430 \u0443\u043f\u0440\u043e\u0441\u0442\u0438\u043b\u0438 \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u0437\u0430\u0434\u0430\u043d\u0438\u044f \u043d\u0430 80%, \u043f\u043e\u0437\u0432\u043e\u043b\u0438\u0432  \n  \u0441\u043e\u0441\u0440\u0435\u0434\u043e\u0442\u043e\u0447\u0438\u0442\u044c\u0441\u044f \u043d\u0435\u043f\u043e\u0441\u0440\u0435\u0434\u0441\u0442\u0432\u0435\u043d\u043d\u043e \u043d\u0430 \u0432\u044b\u0447\u0438\u0441\u043b\u0438\u0442\u0435\u043b\u044c\u043d\u043e\u0439 \u0447\u0430\u0441\u0442\u0438 - \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0438 \u043d\u0435\u0439\u0440\u043e\u0441\u0435\u0442\u0438 ","cae97da3":"\u0414\u043b\u044f \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0443 Albumentations","7b277928":"\u041f\u0440\u043e\u0431\u0443\u0435\u043c \u0440\u0430\u0437\u043d\u044b\u0435 LearningRateScheduler \u0438\u0437 callbacks","19108b53":"\u0412\u043a\u043b\u044e\u0447\u0430\u0435\u043c \u0431\u0430\u0437\u043e\u0432\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c \u043d\u0430 100% \u0438 \u0443\u043c\u0435\u043d\u044c\u0448\u0430\u0435\u043c BATCH_SIZE \u0434\u043e 16, \u0447\u0442\u043e\u0431\u044b \u043d\u0435 \u043f\u0435\u0440\u0435\u0433\u0440\u0443\u0437\u0438\u0442\u044c GPU.","33bd9914":"# Full Power CNN","c7f3733b":"# Step 3","8b164ecd":"### \u0417\u0430\u0433\u0440\u0443\u0436\u0430\u0435\u043c \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u0443\u044e \u0441\u0435\u0442\u044c EfficientNetB6:","4780c5de":"# \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445","de92053d":"\u041d\u0430 \u044d\u0442\u043e\u043c \u044d\u0442\u0430\u043f\u0435 \u0434\u043e\u0441\u0442\u0438\u0433\u0430\u0435\u0442\u0441\u044f \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044c 0.940 - 0.945  \n\u0417\u0430\u0442\u0440\u0430\u0442\u044b \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u043d\u0430 \u043f\u0435\u0440\u0432\u044b\u0435 \u0434\u0432\u0430 \u044d\u0442\u0430\u043f\u0430 - 100 \u043c\u0438\u043d\u0443\u0442","f62b1ccf":"# \u041e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438","066fc2e0":"# Step 4","e4dd5d7d":"Test Time Augmentation (TTA) \u0434\u043b\u044f \u0443\u0441\u0440\u0435\u0434\u043d\u0435\u043d\u0438\u044f \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u0445 \u043f\u0440\u0435\u0434\u0438\u043a\u0442\u043e\u0432 \u0438 \u0438\u0441\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u044f \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0445 \u043e\u0448\u0438\u0431\u043e\u043a","ddb9a100":"### \u0410\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445","d76ffeaf":"\u0412\u0438\u0434\u0438\u043c, \u0447\u0442\u043e \u043a\u043b\u0430\u0441\u0441\u044b \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u044e\u0442 \u0440\u0430\u0437\u043d\u044b\u043c \u043c\u043e\u0434\u0435\u043b\u044f\u043c\/\u043c\u0430\u0440\u043a\u0430\u043c \u0430\u0432\u0442\u043e\u043c\u043e\u0431\u0438\u043b\u0435\u0439: \u043a\u043b\u0430\u0441\u0441 1 - \u0444\u043e\u0440\u0434 \"\u0424\u043e\u043a\u0443\u0441\", \u043a\u043b\u0430\u0441\u0441 8 - \u0444\u043e\u043b\u044c\u043a\u0441\u0432\u0430\u0433\u0435\u043d \"\u041f\u0430\u0441\u0441\u0430\u0442\", \u043e\u0441\u0442\u0430\u043b\u044c\u043d\u044b\u0435 - \n\u044d\u0442\u043e 8 \u0440\u0430\u0437\u043d\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u0412\u0410\u0417. \u0424\u043e\u0442\u043e \u0440\u0430\u0437\u043b\u0438\u0447\u0430\u044e\u0442\u0441\u044f \u043f\u043e \u0440\u0430\u0437\u043c\u0435\u0440\u0430\u043c, \u044f\u0440\u043a\u043e\u0441\u0442\u0438, \u0447\u0435\u0442\u043a\u043e\u0441\u0442\u0438, \u0440\u0430\u043a\u0443\u0440\u0441\u0430\u043c, \u043f\u0435\u0440\u0441\u043f\u0435\u043a\u0442\u0438\u0432\u0435 \u0438 \u0442\u0434.  \n\u041f\u0440\u0438 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u043c\u043e\u0436\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0432\u0441\u0435 \u044d\u0442\u0438 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044f.","4371a51c":"# Step 2","e3adf5d3":"# Half Power CNN","a999a03b":"\u0414\u043e\u0431\u0430\u0432\u0438\u043c ModelCheckpoint, \u0447\u0442\u043e\u0431\u044b \u0441\u043e\u0445\u0440\u0430\u043d\u044f\u0442\u044c \u043f\u0440\u043e\u0433\u0440\u0435\u0441\u0441 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 \u043c\u043e\u0436\u043d\u043e \u0431\u044b\u043b\u043e \u043f\u043e\u0442\u043e\u043c \u043f\u043e\u0434\u0433\u0440\u0443\u0437\u0438\u0442\u044c \u0438 \u0434\u043e\u043e\u0431\u0443\u0447\u0438\u0442\u044c \u043c\u043e\u0434\u0435\u043b\u044c, \u0438  \nEarlyStopping \u043d\u0430 \u0431\u0443\u0434\u0443\u0449\u0435\u0435","21e97a2e":"### \u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445","bfa7adf0":"# EDA \/ \u0410\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445"}}