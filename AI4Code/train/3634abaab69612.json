{"cell_type":{"db21c897":"code","660accdb":"code","a779f79b":"code","96cf5dd6":"code","fbf25c50":"code","e871acdc":"code","ddd20964":"code","30d2b448":"code","63a0303f":"code","f3fe165b":"code","2bf735d9":"code","b1d5db9b":"code","ddaedc18":"code","46370e7d":"code","8afefdc8":"code","f9ba7f86":"code","977f4124":"code","af4507aa":"code","fac9e24c":"code","533f1073":"code","3b4461b2":"code","970a113b":"code","ff8666ca":"code","bc68885f":"code","d146393b":"code","75947b8f":"code","94c4daa9":"code","73188066":"code","5cdcb188":"code","f014558c":"code","9c2771df":"code","51c71098":"code","d9f4c9b2":"code","2ecda1a2":"code","968a04d8":"code","3583a042":"code","fab0d146":"code","8579ce0a":"code","66950e2a":"code","cdc71f4f":"code","47a7ca0e":"code","b44035d4":"code","e53efe4c":"code","f7459e76":"markdown","68030ccb":"markdown","3822d4da":"markdown","b582909c":"markdown","0e5665b9":"markdown","a5c9b4f1":"markdown","470a3865":"markdown","cd1e6cbe":"markdown","2fed8b6d":"markdown","2b58aeb6":"markdown","8edf817a":"markdown","8985c0a7":"markdown","1d959300":"markdown"},"source":{"db21c897":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","660accdb":"import pandas as pd\nimport numpy as np\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#Some default display settings.\nimport seaborn as sns\nsns.set(style = \"white\",color_codes=True)\nsns.set(font_scale=1.5)\nfrom IPython.display import display\npd.options.display.max_columns = None\n\n\nfrom sklearn.model_selection import GridSearchCV #to fine tune Hyperparamters using Grid search\nfrom sklearn.model_selection import RandomizedSearchCV# to seelect the best combination(advance ver of Grid Search)\n\n# importing some ML Algorithms \nfrom sklearn.linear_model import LogisticRegression # y=mx+c\nfrom sklearn.tree import DecisionTreeRegressor # Entropy(impurities),Gain. \nfrom sklearn.ensemble import RandomForestRegressor # Average of Many DT's\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Testing Libraries - Scipy Stats Models\nfrom scipy.stats import shapiro # Normality Test 1\nfrom scipy.stats import normaltest # Normality Test 2\nfrom scipy.stats import anderson # Normality Test 3\nfrom statsmodels.graphics.gofplots import qqplot # plotting the Distribution of Y with a Line of dot on a 45 degree Line.\n\n# Model Varification\/Validation Libraries\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import ShuffleSplit\n\n\n# Matrices and Reporting Libraries\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error,r2_score\nfrom sklearn.metrics import make_scorer\nfrom statsmodels.tools.eval_measures import rmse\nfrom sklearn.model_selection import learning_curve","a779f79b":"\n\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()\n\n","96cf5dd6":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","fbf25c50":"train_data.shape , test_data.shape","e871acdc":"train_data.columns , test_data.columns","ddd20964":"sns.countplot(x= 'Sex',data=train_data)","30d2b448":"sns.countplot(x='Survived',hue='Sex',data=train_data)","63a0303f":"men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\nwomen = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women*100)\nprint(\"% of men who survived:\", rate_men*100)","f3fe165b":"sns.countplot(x='Survived',hue='Pclass',data=train_data)","2bf735d9":"sns.distplot(train_data[\"Age\"],bins=50)","b1d5db9b":"train_data[\"Fare\"].plot.hist(bins=40,figsize=(10,6))\nplt.xlabel(\"Fare\")","ddaedc18":"sns.barplot(x= 'Sex',y='Survived',data=train_data)","46370e7d":"plt.figure(figsize=(7,6))\nsns.heatmap(train_data.isnull(),yticklabels= False,cmap='viridis')","8afefdc8":"plt.figure(figsize=(7,6))\nsns.heatmap(test_data.isnull(),yticklabels= False,cmap='viridis')","f9ba7f86":"# Training Data\nsns.boxplot(y=\"Age\",x=\"Pclass\",data=train_data)\n","977f4124":"def train_age(col):\n    Age= col[0]\n    Pclass=col[1]\n    \n    if pd.isnull(Age):\n        if Pclass==1:\n            return 37\n        elif Pclass==2:\n            return 31\n        else:\n            return 27\n    else:\n        return Age\n        ","af4507aa":"train_data[\"Age\"] = train_data[[\"Age\",\"Pclass\"]].apply(train_age,axis=1)","fac9e24c":"train_data.drop(\"Cabin\",axis=1,inplace=True)\ntrain_data.head()","533f1073":"plt.figure(figsize=(7,6))\nsns.heatmap(train_data.isnull(),yticklabels= False,cmap='viridis')","3b4461b2":"test_data.isnull().sum()","970a113b":"plt.figure(figsize=(7,6))\nsns.heatmap(test_data.isnull(),yticklabels= False,cmap='viridis')","ff8666ca":"test_data.isnull().sum()","bc68885f":"#Testing Data\nsns.boxplot(y=\"Age\",x=\"Pclass\",data=test_data)","d146393b":"def test_age(col):\n    age = col[0]\n    pclass=col[1]\n    \n    if pd.isnull(age):\n        if pclass==1:\n            return 42\n        elif pclass==2:\n            return 28\n        else:\n            return 25\n    else:\n        return age","75947b8f":"test_data['Age']= test_data[['Age','Pclass']].apply(test_age,axis=1)\n","94c4daa9":"test_data.head()","73188066":"plt.figure(figsize=(7,6))\nsns.heatmap(test_data.isnull(),yticklabels= False,cmap='viridis')","5cdcb188":"test_data.drop(\"Cabin\",axis=1,inplace=True)\ntest_data.dropna(inplace=True)\ntest_data.head()","f014558c":"plt.figure(figsize=(7,6))\nsns.heatmap(test_data.isnull(),yticklabels= False,cmap='viridis')","9c2771df":"test_data.isnull().sum()","51c71098":"combined_data = train_data.append(test_data,ignore_index=True)\nprint(combined_data.head())\nprint(combined_data.shape)\n","d9f4c9b2":"combined_data.shape","2ecda1a2":"combined_data.drop([\"Name\",\"Ticket\"],axis=1)","968a04d8":"train_data.shape , test_data.shape , combined_data.shape","3583a042":"features = [\"PassengerId\",\"Survived\",\"Pclass\", \"Sex\",\"Age\", \"SibSp\", \"Parch\",\"Fare\",\"Embarked\"]\nds = pd.get_dummies(combined_data[features],drop_first=True)\nds","fab0d146":"train,test = ds[0:len(train_data)],ds[len(test_data):]","8579ce0a":"train.shape , test.shape , ds.shape","66950e2a":"x_feature = train.drop('Survived',axis=1)\ny_target = train['Survived']","cdc71f4f":"X_train,X_test,y_train,y_test = train_test_split(x_feature,y_target,test_size= 0.30 , random_state=4)","47a7ca0e":"X_train.shape,X_test.shape,y_train.shape,y_test.shape","b44035d4":"lr = LogisticRegression()\nlr.fit(X_train,y_train)","e53efe4c":"rmc = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nrmc.fit(X_train,y_train)\npredictions = rmc.predict(X_test)\noutput = pd.DataFrame({'PassengerId': X_test.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\nprint(cross_val_score(rmc,x_feature,y_target,scoring='accuracy'))\n\nresults=cross_val_score(rmc,x_feature,y_target,scoring='accuracy')\nprint(results.mean()*100)","f7459e76":"# EDV","68030ccb":"-- We can notice here that as the Age above 30 the class of Ticket is Higher as well. 30 to 50 age people are wealthy generally. \n- So Class1 average age of people 27 to 50 = 37\n- similarly, Class2 avg age of people 21 to 37 = 31\n- and class3 avg age of people 19 to 35 = 27\nWe can fill the Nulls based on these averages with respect to Pclass\n\n-- Also the Cabin column has more Nulls than the Data itself. So lets drop that column","3822d4da":"## Dealing with the Null values.","b582909c":"Most fare price of the tickets are between 0 to 100$ . Its way back in 1912. ","0e5665b9":"Men are more in numbers who were deceased in the tragedy.","a5c9b4f1":"-- We can notice here that as the Age above 30 the class of Ticket is Higher as well. 30 to 50 age people are wealthy generally. \n- So Class1 average age of people 31 to 50 = 42\n- similarly, Class2 avg age of people 21 to 35 = 28\n- and class3 avg age of people 19 to 33 = 25\nWe can fill the Nulls based on these averages with respect to Pclass\n\n- Also the Cabin column has more Nulls than the Data itself. So lets drop that column\n-  Fare column has just one Null and hence we can drop that row","470a3865":"this graph also concludes that the female survival is more compared to Male.","cd1e6cbe":"# Checking the Nulls","2fed8b6d":"Null are taken care in Training Data Set.","2b58aeb6":"We all know that the men were more in numbers onboard. And this graph proves the same.","8edf817a":"Out off all People, people of age between 20 and 40 were more onboard.","8985c0a7":"## Lets do the same wrangling process for our testing data","1d959300":"people who were deceased are more in Class 3. "}}