{"cell_type":{"71050280":"code","5a38ef22":"code","121f2907":"code","1c0e5f48":"code","b8ed9d96":"code","b6d0190c":"code","400a7dc7":"code","f0deae60":"code","8e87f30c":"code","139c201b":"code","5fac7fa9":"code","5d298906":"code","cfae1487":"code","79ec49b8":"code","ecfcead6":"code","a7d22d24":"markdown","f0d321b3":"markdown","e58bbc2a":"markdown","e51a51c4":"markdown","78c16976":"markdown"},"source":{"71050280":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nfrom sklearn.model_selection import train_test_split\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport json\nfrom tqdm import tqdm\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","5a38ef22":"RECIPE_INGREDIENTS_PATH = '..\/input\/recipe-ingredients-dataset\/'\nFASTTEXT_PATH = '..\/input\/fasttext-crawl-300d-2m\/crawl-300d-2M.vec'","121f2907":"# Codes borrowed from [The Effect of Word Embeddings on Bias](https:\/\/www.kaggle.com\/nholloway\/the-effect-of-word-embeddings-on-bias\/data)\n\ndef get_coefs(word, *arr):\n    return word, np.asarray(arr, dtype='float32')\n\n\ndef load_embeddings(path):\n    with open(path) as f:\n        return dict(get_coefs(*line.strip().split(' ')) for line in tqdm(f, position=0))\n\n    \ndef build_matrix(word_index, path):\n    embedding_index = load_embeddings(path)\n    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n    for word, i in tqdm(word_index.items(), position=0):\n        try:\n            embedding_matrix[i] = embedding_index[word]\n        except KeyError:\n            embedding_matrix[i] = np.random.normal(-1, 1, (1, 300))\n    return embedding_matrix","1c0e5f48":"def build_dataset(data_path, cuisine=True):\n    \n    x_rid = []\n    y_rid = []\n    i_rid = []\n    \n    with open(data_path) as f:\n        rid_list = json.load(f)\n    \n        for rid in tqdm(rid_list, position=0):\n            x_rid.append([ing for ing in rid['ingredients']])\n            if cuisine:\n                y_rid.append(rid['cuisine'])\n            i_rid.append(rid['id'])\n        \n    return i_rid, x_rid, y_rid","b8ed9d96":"def n_gram_sequences(ingredients, tokenizer):\n    tokenizer.fit_on_texts(ingredients)\n    total_words = len(tokenizer.word_index) + 1\n    \n    x_sequences = []\n    for items in ingredients:\n        token_list = tokenizer.texts_to_sequences([items])[0]\n        for i in range(1, len(token_list)):\n            n_grams = token_list[: i + 1]\n            x_sequences.append(n_grams)\n    \n    return x_sequences, total_words, tokenizer\n\n\ndef n_gram_padded(x_sequences):\n    max_len = max([len(x) for x in x_sequences])\n    x_sequences = np.array(pad_sequences(x_sequences, maxlen=max_len, padding='pre'))\n    predictors, label = x_sequences[:, :-1], x_sequences[:, -1]\n    return predictors, label, max_len","b6d0190c":"i_rid_train, x_rid_train, y_rid_train = build_dataset(RECIPE_INGREDIENTS_PATH + 'train.json')\ni_rid_test, x_rid_test, _ = build_dataset(RECIPE_INGREDIENTS_PATH + 'test.json', cuisine=False)\n\nprint('Train:')\nprint('Number of recipes-ingredients %d' % (len(i_rid_train)))\nprint('Number of unique ingredients %d' % (len(list(set(x for l in x_rid_train for x in l)))))\nprint('Number of unique recipes %d' % (len(list(set(y_rid_train)))))\n\nprint()\nprint('Test')\nprint('Number of recipes-ingredients %d' % (len(i_rid_test)))\nprint('Number of unique ingredients %d' % (len(list(set(x for l in x_rid_test for x in l)))))","400a7dc7":"ingredients = x_rid_train + x_rid_test\ningredients = [' '.join([item.replace(' ', '-') for item in items]) for items in ingredients]\n\nprint('Number of recipes-ingredients %d' % len(ingredients))\nprint('Sample: %s' % ingredients[10])","f0deae60":"tokenizer = Tokenizer()\nx_sequences, total_words, tokenizer = n_gram_sequences(ingredients, tokenizer)\npredictors, labels, max_len = n_gram_padded(x_sequences)\n\nx_train, x_test, y_train, y_test = train_test_split(predictors, labels, test_size=0.05, random_state=42)\n\nprint('Predictors %s' % str(predictors.shape))\nprint('Labels %s' % str(labels.shape))\nprint('Train: %s, Test: %s' % (len(x_train), len(x_test)))\nprint('Max length of sequences %d' % max_len)","8e87f30c":"fasttext_matrix = build_matrix(tokenizer.word_index, FASTTEXT_PATH)\nprint(\"Number of unique words %d\" % fasttext_matrix.shape[0])","139c201b":"print(x_train[0], y_train[0])","5fac7fa9":"def create_model(max_len, rnn_units, total_words, embedding_matrix):\n    inputs = keras.layers.Input(shape=(max_len,))\n    x = keras.layers.Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(inputs)\n    # x = keras.layers.Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=True)(inputs)\n    x = keras.layers.CuDNNGRU(rnn_units, name='gru_1')(x)\n    outputs = tf.keras.layers.Dense(total_words, activation='softmax', name='output')(x)\n    \n    model = keras.Model(inputs=inputs, outputs=outputs)\n    model.compile(\n        loss='sparse_categorical_crossentropy', \n        metrics=['accuracy'],\n        optimizer='adam')\n    \n    return model","5d298906":"model = create_model(max_len - 1, 100, total_words, fasttext_matrix)\nmodel.summary()","cfae1487":"r = model.fit(x_train, y_train, validation_split=0.05, epochs=10, batch_size=256, verbose=1)","79ec49b8":"def sample(preds, temperature=1.0):\n    preds = np.asarray(preds).astype('float64')\n    preds = np.log(preds) \/ temperature\n    exp_preds = np.exp(preds)\n    preds = exp_preds \/ np.sum(exp_preds)\n    probas = np.random.multinomial(1, preds, 1)\n    return np.argmax(probas)\n\ndef generate_text(seed_text, next_words, max_len, model, tokenizer):\n    idx2word = {idx: word for word, idx in tokenizer.word_index.items()}\n    # Converting our start string to numbers (vectorizing)\n    x_pred = tokenizer.texts_to_sequences([seed_text])[0]\n    x_pred = np.array(pad_sequences([x_pred], maxlen=max_len - 1, padding='pre'))\n    \n    # Empty string to store our results\n    text_generated = []\n    \n    # Low temperatures results in more predictable text.\n    # Higher temperatures results in more surprising text.\n    # Experiment to find the best setting.\n    temperature = 1.0\n    \n    # Here batch size == 1\n    model.reset_states()\n    for i in range(next_words):\n        predictions = model.predict(x_pred, verbose=0)[0]\n        predicted_id = sample(predictions, temperature)\n        text_generated.append(idx2word[predicted_id])\n    \n    return seed_text + ' ' + ' '.join(text_generated)","ecfcead6":"print(generate_text(\"pimentos sweet-pepper dried-oregano olive-oil\", 5, max_len, model, tokenizer))","a7d22d24":"# Config","f0d321b3":"# Generation","e58bbc2a":"# Arch","e51a51c4":"# Preparing the data","78c16976":"# Utils"}}