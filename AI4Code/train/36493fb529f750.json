{"cell_type":{"3289e499":"code","3a93bc2f":"code","f34fc0e8":"code","b07d3d71":"code","4739a317":"code","e0487177":"code","36a52888":"code","5b5abe4e":"code","bfc30d71":"code","7c33411b":"code","94cf89d6":"code","3891a398":"code","1e8fd3be":"code","9a55afc7":"code","d6dc3a6d":"code","b927b938":"code","188aa860":"code","6b66aa4a":"code","5e3ccb0b":"code","837a3e6a":"code","c360c726":"code","0c56c1be":"code","174e838a":"code","a82f3e31":"code","5a78eae5":"code","ad273be0":"code","c4910c7e":"code","abb873f7":"code","2bafe6c3":"code","5a54474b":"code","5f4ce11d":"code","554c3712":"code","58943a93":"code","b23caced":"code","a7248faf":"code","d82274b5":"code","f383e06b":"code","4b7c7a28":"code","c7a6404a":"code","40f1df17":"code","1b166a9a":"code","06d3bcc3":"code","88321e36":"code","a8c1a9fb":"code","88939288":"code","11f7aa75":"code","96250473":"markdown","83636152":"markdown","3ea062bd":"markdown","352da62e":"markdown","1a405e76":"markdown","f3b5232d":"markdown","6eb19c25":"markdown","493e084e":"markdown","36ef053e":"markdown","945c4943":"markdown","dd666d9b":"markdown","417d97b4":"markdown","b9eaa799":"markdown","287f7fc7":"markdown","1159b3b6":"markdown","07ef389e":"markdown","e5d5a9f0":"markdown","a43ee9ad":"markdown","c0a9699e":"markdown","50c1b925":"markdown","a3d43aee":"markdown","79ae8a74":"markdown","a4f85b51":"markdown","d887d7e5":"markdown","82eba984":"markdown","b47f6d8b":"markdown","0537f922":"markdown","fd109782":"markdown","6f816fa8":"markdown","491f429a":"markdown","767b278a":"markdown","cc4ef4a0":"markdown","08021210":"markdown","7fa9c351":"markdown","55191069":"markdown","4ca6ce7e":"markdown","b06a5cc1":"markdown","707dd41a":"markdown"},"source":{"3289e499":"# Import common libraries used in Data Analysis\nimport numpy as np # for array operations\nimport pandas as pd # for dataframe manipulation \nimport matplotlib.pyplot as plt # together with Seaborn to visualize data\nimport seaborn as sns\nimport warnings; warnings.filterwarnings(\"ignore\") # to ignore warnings caused of incoming library deprecations","3a93bc2f":"data = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/daniel-bss\/MarketBasketAnalysis\/main\/bread_basket.csv\")\nprint(\"DataFrame shape:\", data.shape)\ndata.head() # Data for the first 5 rows","f34fc0e8":"data.info()","b07d3d71":"# Take a look of data summary, as in Descriptive Statistics\ndata.describe()","4739a317":"sns.displot(data = data, bins = 15, x = \"Transaction\", height = 5, aspect = 1.5)\nplt.title(\"Transaction Distribution\", size = 16)\nplt.xlabel(\"Transaction\", size = 16); plt.ylabel(\"\") \nplt.show()","e0487177":"# We use pandas' method to_datetime(), and match the time formatting on what the date_time column is storing\n\ndata['date_time'] = pd.to_datetime(data['date_time'], format = \"%d-%m-%Y %H:%M\")","36a52888":"data[\"date_time\"].dtype","5b5abe4e":"data[\"month\"] = data['date_time'].dt.month\ndata[\"day\"] = data['date_time'].dt.weekday\ndata[\"hour\"] = data['date_time'].dt.hour","bfc30d71":"# final result\ndata.head()","7c33411b":"plt.figure(figsize=(13,5))\nsns.set_palette(\"muted\")\n\nsns.barplot(x = data[\"Item\"].value_counts()[:10].index, y = data[\"Item\"].value_counts()[:10].values)\nplt.xlabel(\"\"); plt.ylabel(\"\")\nplt.xticks(size = 13, rotation = 45)\nplt.title('10 Most Purchased Items', size = 17)\nplt.show()","94cf89d6":"data_perbulan = data.groupby('month')['Transaction'].count()\ndata_perbulan = pd.concat([data_perbulan.iloc[4:], data_perbulan.iloc[:4]])\n\nplt.figure(figsize = (8,5))\nsns.barplot(\n    x = [\"October\", \"November\", \"December\", \"January\", \"February\", \"March\", \"April\"], \n    y = data_perbulan.values, color = \"#D5AAD3\")\nplt.xticks(size = 12, rotation = -30)\nplt.title(\"Total Transactions Every Month (October - April)\", size = 16)","3891a398":"data_perday = data.groupby('day')['Transaction'].count()\n\nplt.figure(figsize = (8,5))\nsns.barplot(\n    x = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"], \n    y = data_perday.values, color = \"#BFFCC6\")\nplt.xticks(size = 12, rotation = -30)\nplt.title(\"Total Transactions Each Day\", size = 17)","1e8fd3be":"data_perhour = data.groupby(\"hour\")[\"Transaction\"].count()\n\nplt.figure(figsize=(12,6))\nsns.barplot(x = data_perhour.index, y = data_perhour.values, color = \"#85E3FF\")\nplt.xlabel('Hour', size = 15)\nplt.title('Number of Orders Each Hour', size = 17)\nplt.xticks(size = 13)\nplt.show()","9a55afc7":"data_period_day = data.groupby(['period_day','Item'])['Transaction'].count().reset_index().sort_values(['period_day','Transaction'],ascending=False)\nhari = [['morning', 'Pagi'],\n        ['afternoon', 'Siang'],\n        ['evening', 'Sore'],\n        ['night', 'Malam']]","d6dc3a6d":"fig, ax = plt.subplots(ncols = 2, nrows = 2, figsize = (17,9))\n\nindex = 0\nfor i in range(len(ax)):\n    for j in range(len(ax[0])):\n        data_temp = data_period_day[data_period_day[\"period_day\"] == hari[index][0]].head(10)\n        sns.barplot(x = data_temp[\"Transaction\"], y = data_temp[\"Item\"], ax = ax[i,j], color = \"#FF968A\")\n        ax[i,j].set_xlabel(\"\"); ax[i,j].set_ylabel(\"\")\n        if index != 3:\n            ax[i,j].set_title(f\"10 Pesanan Terbanyak di {hari[index][1]} Hari\")\n        else:\n            ax[i,j].set_title(f\"6 Pesanan Terbanyak di {hari[index][1]} Hari\")\n        index += 1\nplt.show()","b927b938":"# Menerapkan pandas apply pada kolom \"Item\" yang mengembalikan strings.lower():\ndata[\"Item\"] = data[\"Item\"].apply(lambda item: item.lower())","188aa860":"# Memastikan setiap nilai \"Item\" bersih dari whitespace:\ndata[\"Item\"] = data[\"Item\"].apply(lambda item: item.strip())","6b66aa4a":"data = data[[\"Transaction\", \"Item\"]].copy()\ndata.head(10)","5e3ccb0b":"# Import library mlxtend (Machine Learning Extensions), yang menyediakan tambahan function Machine Learing di luar Scikit Learn\n\nfrom mlxtend.frequent_patterns import association_rules, apriori","837a3e6a":"# Membentuk tabel yang menghitung jumlah item yang dibeli oleh masing-masing customer\n# Dengan cara mengelompokannya berdasarkan kolom \"Transaction\" dan \"Item\"\n# Kemudian di-aggregate dengan method .count()\n\nitem_count = data.groupby([\"Transaction\", \"Item\"])[\"Item\"].count().reset_index(name = \"Count\")\nitem_count.head(10)","c360c726":"# Membuat pivot table, dengan menetapkan \"Transaction\" sebagai index, dan \"Item\" sebagai kolom\/features\n# Kemudian mengisi parameter values dengan \"Count\" \n# Sehingga kita bisa mengetahui berapa jumlah suatu item A yang di beli oleh seorang customer\n\nitem_count_pivot = item_count.pivot_table(index='Transaction', columns='Item', values='Count', aggfunc='sum').fillna(0)\nprint(\"Ukuran dataset:\", item_count_pivot.shape)\nitem_count_pivot.head()","0c56c1be":"# Mengubah seluruh tipe data menjadi integer\n\nitem_count_pivot = item_count_pivot.astype(\"int32\")\nitem_count_pivot.head()","174e838a":"# Membuat function encode dengan ketentuan:\n# Jika item tersebut dibeli, maka kita mengubah nilainya menjadi 1\n# Jika item tidak dibeli, maka nilainya menjadi 0\n\ndef encode(x):\n    if x <= 0:\n        return 0\n    elif x >= 1:\n        return 1\n    \nitem_count_pivot = item_count_pivot.applymap(encode)\nitem_count_pivot.head()","a82f3e31":"# Summary akhir:\n\nprint(\"Ukuran dataset:\", item_count_pivot.shape)\nprint(\"Jumlah transaksi:\", item_count_pivot.shape[0])\nprint(\"Jumlah items:\", item_count_pivot.shape[1])","5a78eae5":"support = 0.01 # atau 1%\nfrequent_items = apriori(item_count_pivot, min_support = support, use_colnames = True)\nfrequent_items.sort_values(\"support\", ascending = False).head(10)","ad273be0":"metric = \"lift\"\nmin_threshold = 1\n\nrules = association_rules(frequent_items, metric = metric, min_threshold = min_threshold)[[\"antecedents\", \"consequents\", \"support\", \"confidence\", \"lift\"]]\nrules.sort_values('confidence', ascending = False, inplace = True)\nrules.head(15)","c4910c7e":"ant = list(rules[\"antecedents\"].apply(lambda x: list(x))) # membuat list dari kolom antecedents\ncons = list(rules[\"consequents\"].apply(lambda x: list(x))) # membuat list dari kolom consequents","abb873f7":"ant_clear = []\ncons_clear = []\nfor i,j in zip(ant, cons):\n    if (len(i) > 1) or (len(j) > 1):\n        for a in i :\n            for b in j:\n                ant_clear.append(a)\n                cons_clear.append(b)\n    else:\n        ant_clear.append(i[0])\n        cons_clear.append(j[0])","2bafe6c3":"chord_data = pd.concat([pd.Series(ant_clear), pd.Series(cons_clear)], axis = 1)\nchord_data.columns = [\"From\", \"To\"]\nchord_data[\"Weight\"] = 10000 * np.ones(len(ant_clear))\nchord_data[\"Weight\"] = chord_data[\"Weight\"].astype(\"int64\")\nchord_data.head(10)","5a54474b":"chord_data = chord_data[[\"From\", \"Weight\", \"To\"]].copy()\nchord_data.head(15)","5f4ce11d":"chord_data.to_csv(\"chord_data.csv\", index = False)","554c3712":"pd.read_csv(\"chord_data.csv\")","58943a93":"data_depl = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/daniel-bss\/breadbasket\/main\/bread_basket.csv\")\ndata_depl.head()","b23caced":"data_depl['date_time'] = pd.to_datetime(data_depl['date_time'], format = \"%d-%m-%Y %H:%M\")\n\ndata_depl[\"month\"] = data_depl['date_time'].dt.month\ndata_depl[\"day\"] = data_depl['date_time'].dt.weekday","a7248faf":"data_depl[\"month\"].replace([i for i in range(1, 12 + 1)], [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"], inplace = True)\ndata_depl[\"day\"].replace([i for i in range(6 + 1)], [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"], inplace = True)","d82274b5":"data_depl.head()","f383e06b":"def get_data(period_day = '', weekday_weekend = '', month = '', day = ''):\n    data = data_depl.copy()\n    filtered = data.loc[\n        (data[\"period_day\"].str.contains(period_day)) & \n        (data[\"weekday_weekend\"].str.contains(weekday_weekend)) & \n        (data[\"month\"].str.contains(month.title())) &\n        (data[\"day\"].str.contains(day.title()))\n    ]\n    return filtered if filtered.shape[0] else \"Data tidak tersedia!\"","4b7c7a28":"# Testing\nreq_data = get_data(\"morning\", \"weekend\", \"January\", \"Sunday\")\ntry:\n    display(req_data.shape)\n    display(req_data.head())\nexcept:\n    display(req_data)","c7a6404a":"item_count = req_data.groupby([\"Transaction\", \"Item\"])[\"Item\"].count().reset_index(name = \"Count\")\nitem_count.head()","40f1df17":"item_count_pivot = item_count.pivot_table(index='Transaction', columns='Item', values='Count', aggfunc='sum').fillna(0)\nitem_count_pivot.head()","1b166a9a":"def encode(x):\n    if x <= 0:\n        return 0\n    elif x >= 1:\n        return 1\n    \nitem_count_pivot = item_count_pivot.applymap(encode)\nitem_count_pivot.head()","06d3bcc3":"from mlxtend.frequent_patterns import association_rules, apriori","88321e36":"support = 0.01 # atau 1%\nfrequent_items = apriori(item_count_pivot, min_support = support, use_colnames = True)\nfrequent_items.sort_values(\"support\", ascending = False).head(10)","a8c1a9fb":"metric = \"lift\"\nmin_threshold = 1\n\nrules = association_rules(frequent_items, metric = metric, min_threshold = min_threshold)[[\"antecedents\", \"consequents\", \"support\", \"confidence\", \"lift\"]]\nrules.sort_values('confidence', ascending = False, inplace = True)\ndisplay(rules.shape)\nrules","88939288":"def parse_list(x):\n    x = list(x)\n    if len(x) == 1:\n        return x[0]\n    elif len(x) > 1:\n        return \", \".join(x)\n    \ndef return_item_df(item_antecedents):\n    data = rules[[\"antecedents\", \"consequents\"]].copy()\n    \n    data[\"antecedents\"] = data[\"antecedents\"].apply(parse_list)\n    data[\"consequents\"] = data[\"consequents\"].apply(parse_list)\n    \n    return list(data.loc[data[\"antecedents\"] == item_antecedents].iloc[0,:])\n    ","11f7aa75":"datax = return_item_df(\"Cake\")\ndatax","96250473":"Dataset consists of 5 features, which are:\n<ul>\n    <li><b>Transaction<\/b>: A unique customer's code given everytime a person orders for the first time<\/li>\n    <li><b>Item<\/b>: Products of food and beverage such as Coffee dan Sandwich<\/li>\n    <li><b>date_time<\/b>: Timestamp of an order being done, with a time format of \"dd-mm-yyyy hh:mm\"<\/li>\n    <li><b>period_day<\/b>: Stating the parts of the day (morning, afternoon, evening, and night)<\/li>\n    <li><b>weekday_weekend<\/b>: Stating whether it's weekday or weekend on that day<\/li>\n<\/ul>","83636152":"Terakhir, data yang akan kita gunakan untuk membuat model adalah `Transaction` dan `Item`","3ea062bd":"---","352da62e":"Because of data was collected from last October to early April, we get no information from May to September.<br>\nBut at least have an insight that this Bakery Store has its highest revenue on November. ","1a405e76":"<img src=\"https:\/\/raw.githubusercontent.com\/daniel-bss\/breadbasket\/main\/img\/chord_diagram.png\">","f3b5232d":"### Association Rules","6eb19c25":"Terlihat bahwa Kopi dan Roti adalah item yang paling dominan dibeli. Kemudian diikuti juga oleh pembelian Teh pada posisi ke-3.","493e084e":"# 6. Deployment","36ef053e":"### Total Transactions Each Day","945c4943":"# 5. Evaluation","dd666d9b":"### Top 10 most purchased items","417d97b4":"### Transactions every month","b9eaa799":"# I'm still on process on translating this to English, because I first made this in Bahasa Indonesia, and never thought of uploading this to Kaggle \ud83d\ude01","287f7fc7":"<html>\n<body>\n    <img src=\"https:\/\/raw.githubusercontent.com\/daniel-bss\/breadbasket\/main\/img\/dataset-cover.png\" style=\"width: 100%; height:220px;\">\n    <h1 style=\"text-align: center\">MARKET BASKET ANALYSIS<\/h1>\n    <hr style=\"border: 2px solid black;\">\n    <h1>1. Business Understanding<\/h1>\n    <p>It is important for companies as well as small business to plan their products which are going to put on sale, in intention of maximizing revenue. But quite often happens a situation where products are unbalancedly sold. Some products are sold quickly and some are not likely to be touched.<\/p>\n    <p>In this notebook, we have a <a href=\"https:\/\/www.kaggle.com\/mittalvasu95\/the-bread-basket\" target=\"_blank\">dataset<\/a> provided by Kaggle, which was originally shared by a bakery shop located in Edinburgh. This dataset stores about 7 months of transaction record, and we would like to use this data to help this bakery shop to optimize their sellings, by performing Market Basket Analysis to extract information about which item relates to which.<\/p>\n    <p>With that being said, we started by noting some Problem Statements, which are: \n    <ol>\n        <li>What products are commonly bought by customers?<\/li>\n        <li>On what circumtances, such as time, day, or month, happens to be a high traffic of transaction?<\/li>\n        <li>What are products which are commonly bought together by customers?<\/li>\n    <\/ol>\n<\/body>\n<\/html>","1159b3b6":"Selanjutnya dalam Data Preparation, akan dilakukan sedikit integrasi data, mengingat dataset ini sudah bersih dari <i>invalid<\/i> dan <i>missing values<\/i>.\n<br>\nData Integration yang akan dilakukan adalah memastikan kolom `Item` bersih dari <i>whitespaces<\/i>, dan juga menormalisasi data dengan mengubah semua <i>strings<\/i> pada kolom `Item` menjadi <i>lowercase<\/i>.","07ef389e":"Because `Transaction` is the only feature that has data type of numeric, so `data.describe()` returns only that one column.<br>\n<br>\nIn terms of statistics, we can guess that `Transaction` has a pretty good distribution or not skewed, given that the range between the quartiles is not significantly different. But telling from the standard deviation that is pretty high, meaning that there are some big values around its mean.","e5d5a9f0":"Mungkin kita sudah menduga-duga bahwa Kopi dan Roti akan menempati posisi teratas lagi, setelah kita sudah melakukan beberapa visualisasi data sebelumnya. Ternyata dugaan kita benar, Kopi dan Roti memiliki persentase <i>support<\/i> yang cukup tinggi, artinya benar bahwa memang <i>items<\/i> ini paling sering dibeli.\n<br><br>\nPertanyaannya, dengan apakah Kopi dan Roti itu biasa dibeli bersamaan? Apakah customers hanya membeli Kopi atau Roti saja? Untuk menjawab pertanyaan tersebut, kita menerapkan <i>Association Rules<\/i>, yang dapat menghitung <i>Confidence<\/i> dan <i>Lift<\/i> pada item-item yang dibeli bersamaan","a43ee9ad":"From our presumption, turns out it's true that the distribution is not skewed. What made the standard deviation high is because the distribution is \"uniform\". Meaning there are quite many data with big values around the mean.","c0a9699e":"### Melihat 10 items terpopuler pada setiap `period_day` (Pagi, Siang, Sore, Malam)","50c1b925":"From the given dataset, we will do some data extraction, describing, and also exploration. Or in other words, doing an Exploratory Data Analysis.","a3d43aee":"Terlihat bahwa Kopi sering dibeli bersamaan dengan Roti Bakar, kemudian Roti sering dibeli bersamaan dengan <i>Pastry<\/i>","79ae8a74":"Maupun Pagi, Siang, atau pun Sore, Kopi dan Roti selalu menempati 2 Pesanan terbanyak.\n<br>\nKarena pesanan pada malam hari sangat sedikit, yaitu 14, sepertinya sulit untuk menyimpulkan bahwa <i>customers<\/i> di malam hari ada vegetarian.","a4f85b51":"# 4. Modeling","d887d7e5":"<!-- <img src=\"https:\/\/raw.githubusercontent.com\/daniel-bss\/breadbasket\/main\/img\/chord_diagram.png\"> -->","82eba984":"### Melihat jumlah pesanan setiap jamnya.","b47f6d8b":"Kini kita sudah membentuk tabel yang berisi informasi pembelian 9464 <i>customers<\/i>. Dari 93 items yang dijual, kita bisa tahu item apa saja yang dibeli oleh seorang customer dan berapa jumlahnya.","0537f922":"### Inisialisasi model Apriori dengan minimum support sebesar 1%\nArtinya, untuk setiap 100 transaksi, kita ingin <b>minimal<\/b> ada 1 transaksi yang melibatkan pembelanjaan 2 atau lebih item secara bersamaan!","fd109782":"It can be seen that this dataset only have on numerical feature, which is `Transaction`.<br>\nSpeaking of missing values, fortunately this dataset has no \"null\" values, or `NaN` meaning that this dataset or completely filled","6f816fa8":"As we can see above, now the date_time column is a \"datetime\" type, and no longer just \"object\"<br>\n<br>\nNow we can take the month, day of week, and hour by appending a new features named `month`, `day`, and `hour`","491f429a":"Dari dataset yang diberikan, hanya kolom `Transaction`-lah yang bersifat numerik, maka dari itu `data.describe()` hanya mengembalikan 1 kolom.\n<br><br>\nTerlihat bahwa data `Transaction` memiliki distribusi yang cukup baik, karena tidak ada lonjakan signifikan antara nilai kuantil-kuantilnya, namun deviasi standarnya masih cenderung terlalu besar, yang menandakan bahwa banyak nilai-nilai yang jauh dari mean-nya.\n<br><br>\nUntuk lebih jelasnya, mari lihat histogramnya.","767b278a":"Dalam percobaan <i>Market Basket Analysis<\/i> ini, algoritma yang digunakan adalah <i>Apriori Algorithm<\/i>, salah satu algoritma dalam <i>Association Analysis<\/i> yang juga merupakan ranah <i>Unsupervised Learning<\/i>. \n<br><br>\nAda beberapa <i>metrics<\/i> yang digunakan untuk mengukur performa dari algoritma <i>Apriori<\/i> ini, yaitu:\n<ol>\n    <li><b>Support<\/b>: persentase jumlah keberadaan item dalam seluruh dataset.<\/li>\n    <li><b>Confidence<\/b>: persentase jumlah keberadaan 2 item (A dan B) bersamaan terhadap jumlah keberadaan 1 item ang berkaitan (item A).<\/li>\n    <li><b>Lift<\/b>: kecenderungan item B dibeli bersama item A, jika item A juga dibeli.<\/li>\n<\/ol>","cc4ef4a0":"To help more on extracting insight, it will be very helpful if we change the `date_time` which is now still read as an object or ordinary string, into \"datetime\", so we can get the corresponding month, day, and specific hour on the time when the orders are being done.","08021210":"# 3. Data Preparation","7fa9c351":"It can be seen that Coffee is significantly higher than Bread on the 2nd position, followed by small portion of Tea, and  gradually decreasing from Cake to the rest.","55191069":"We can see that the transactions are mostly crowded on Saturday. Probably people there like to spend their weekend specifically on Saturday there. ","4ca6ce7e":"Terlihat bahwa mayoritas pesanan terjadi antara jam 9 sampai jam 3, atau dari pagi hingga menjelang sore.","b06a5cc1":"# 2. Data Understanding","707dd41a":"Kita menginginkan batas minimum <i>lift<\/i>-nya sebesar 1. \n<br><br>\nNilai <i>Lift<\/i> memiliki rentang nilai antara 0 hingga tak terhingga.<br>\nSemakin tinggi <i>lift<\/i>, maka menandakan bahwa kedua item cenderung sering dibeli bersamaan, sebaliknya jika di bawah 1, artinya kedua item tersebut tidak memiliki relasi sama sekali, atau sangat jarang dibeli bersamaan"}}