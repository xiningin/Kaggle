{"cell_type":{"a7f9a9f0":"code","7b6cb469":"code","3bb7aafb":"code","5ae305f4":"code","13849101":"code","7795cbf2":"code","e558f7a6":"code","eb228b46":"code","43158769":"code","7f7291cd":"code","024a686b":"code","db912c24":"code","475b2c19":"code","43ac0aca":"code","18a0fc1c":"code","b02ed9e7":"code","0aca1bb7":"code","332204d5":"code","bbae31ee":"code","680c8eeb":"code","4b6a91e3":"code","8783b109":"code","9c215cf4":"markdown","b8c8e966":"markdown","c2c20396":"markdown","fc7c7b3b":"markdown","11c5bbfa":"markdown","82ba0c85":"markdown"},"source":{"a7f9a9f0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport keras as ks\nimport os\nimport cv2","7b6cb469":"train_dir = \"..\/input\/real-life-industrial-dataset-of-casting-product\/casting_data\/casting_data\/train\/\"\ntest_dir = \"..\/input\/real-life-industrial-dataset-of-casting-product\/casting_data\/casting_data\/test\/\"","3bb7aafb":"def get_image(path):\n    img = cv2.imread(path,0)\n    print(img.shape)\n    plt.imshow(img,cmap=\"gray\")","5ae305f4":"image = \"..\/input\/real-life-industrial-dataset-of-casting-product\/casting_data\/casting_data\/train\/def_front\/cast_def_0_0.jpeg\"","13849101":"get_image(image)","7795cbf2":"def datapreprocessing(main_dir,bsize):\n    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n    \n    train_gen = ImageDataGenerator(rescale=1.0\/255,\n                                   zoom_range=0.2,\n                                   shear_range=0.2,\n                                   horizontal_flip=True,\n                                   #fill_mode='nearest'\n                                  )\n\n    train_generator = train_gen.flow_from_directory(\n        directory=main_dir,\n        target_size=(64,64),\n        batch_size=bsize,\n        color_mode=\"grayscale\",\n        shuffle=True,\n        subset=\"training\",\n        class_mode='binary')\n    \n    return train_generator","e558f7a6":"traingen = datapreprocessing(train_dir,20)\nvalidgen = datapreprocessing(test_dir,20)","eb228b46":"labelnames = traingen.class_indices\nlabelnames","43158769":"#Function that can build a dataframe on passing folderpath.\ndef getdata(folder_path):\n    sig = pd.DataFrame(columns=['image_abs_path','image_labels'])\n    for key,value in labelnames.items():\n        #print(\"processing for label: {}\".format(label))\n        label_i = folder_path+\"\/\"+str(key)\n        #read directory\n        dirs_label_i =  os.listdir(label_i)\n        idx = 0\n        for image in dirs_label_i:\n            #create a absolute image path\n            sig_i = os.path.join(label_i,image)\n            #print('Absolute path for image no. {} and label {}: {}'\\\n                  #.format(idx,label,flower_i))\n\n            #fill the dataframe with path and label\n            sig = sig.append({'image_abs_path':sig_i,\n                            'image_labels':key},\n                           ignore_index=True)\n            idx += 1\n    return sig","7f7291cd":"#Create Train Dataframe as repository of paths and labels.\nvalid = getdata(test_dir)","024a686b":"valid","db912c24":"# Fetch n number of images from train data frame\ndef get_n_images(n,df,label):\n    import warnings\n    warnings.filterwarnings('ignore')\n    train = df[df[\"image_labels\"]==label]\n    print(len(train))\n    i = 0\n    m = n\/2\n    plt.figure(figsize=(12, 6))\n    for path in train['image_abs_path'][0:n]:\n        plt.subplot(2,m,i+1)\n        get_image(path)\n        #plt.title(train['image_labels'][i])\n        i += 1\n    plt.tight_layout()\n    plt.show()","475b2c19":"def visualize_gen(train_generator):   \n    #Visualising Images Processed\n    plt.figure(figsize=(6, 3))\n    for i in range(0, 10):\n        plt.subplot(2, 5, i+1)\n        for X_batch, Y_batch in train_generator:\n            image = X_batch[0]        \n            plt.axis(\"off\")\n            plt.imshow((image*255).astype(np.uint8),cmap='gray')\n            break\n    plt.tight_layout()\n    plt.show()","43ac0aca":"visualize_gen(traingen)","18a0fc1c":"input_shape = traingen.image_shape\ninput_shape","b02ed9e7":"def imageclf2(input_shape):\n    from tensorflow import keras as ks\n    #from tensorflow.keras import regularizers\n    model = ks.models.Sequential()\n    #building architecture\n    #Adding layers\n    model.add(ks.layers.Conv2D(8,(3,3),\n                               strides=1,\n                               activation=\"relu\",\n                               padding='same',\n                               name=\"layer1\",\n                               input_shape=input_shape))\n    model.add(ks.layers.MaxPooling2D(pool_size=2,strides=2))\n    #model.add(ks.layers.Dropout(0.5))\n    model.add(ks.layers.Conv2D(8,(3,3),strides=1,padding=\"same\",activation=\"relu\",name=\"layer2\"))\n    model.add(ks.layers.MaxPooling2D(pool_size=2,strides=2))\n#     model.add(ks.layers.Dropout(0.5))\n#     model.add(ks.layers.Conv2D(64,(3,3),strides=1,padding=\"same\",activation=\"relu\",name=\"layer3\"))\n#     model.add(ks.layers.MaxPooling2D(pool_size=2,strides=2))\n#     model.add(ks.layers.Dropout(0.5))\n#     model.add(ks.layers.Conv2D(64,(3,3),strides=1,padding=\"same\",activation=\"relu\",name=\"layer4\"))\n#     model.add(ks.layers.MaxPooling2D(pool_size=2,strides=2))\n#     model.add(ks.layers.Dropout(0.5))\n    \n    \n    model.add(ks.layers.Flatten())\n    model.add(ks.layers.Dense(128,activation=\"relu\",\n                              name=\"layer5\"))\n    model.add(ks.layers.Dense(128,activation=\"relu\",\n                              name=\"layer6\"))\n    #model.add(ks.layers.Dropout(0.5))\n    \n    model.add(ks.layers.Dense(1,activation=\"sigmoid\",\n                              name=\"output\"))\n    model.summary()\n    \n    return model\n","0aca1bb7":"def compiler2(model,train_generator,valid_generator,epchs,bsize=32,lr=0.0001):\n\n    from tensorflow import keras as ks\n    callbck = ks.callbacks.EarlyStopping(monitor='val_loss',patience=10,\n                                         verbose=2,\n                                         restore_best_weights=True,) \n    \n    opt = ks.optimizers.Adam(learning_rate=lr)\n    \n    model.compile(loss=\"binary_crossentropy\",\n                      optimizer=opt,\n                      metrics=[\"accuracy\"])\n    history = model.fit(train_generator,\n                        epochs=epchs,\n                        callbacks=[callbck],\n                        validation_data=valid_generator,\n                        verbose = 1,\n                        #steps_per_epoch = train_generator.n \/\/ bsize\n                       )\n    #Visualise curves\n    plt.plot(history.history['accuracy'], label='train_acc')\n    plt.plot(history.history['val_accuracy'], label='valid_acc')\n\n    plt.title('lrate='+str(lr), pad=-50)\n    plt.legend()\n    plt.grid(True)\n    return model,history","332204d5":"model01 = imageclf2(input_shape)","bbae31ee":"model_com01 = compiler2(model01,traingen,validgen,10)","680c8eeb":"#Visualise loss curves\nhistory = model_com01[1]\nplt.plot(history.history['loss'], label='loss')\nplt.plot(history.history['val_loss'], label='val_loss')\nplt.legend()\nplt.grid()\nplt.show()","4b6a91e3":"def get_predictions(n):\n    import keras as ks\n    image1= validgen[0][0][n]\n    #print(image1.shape)\n    plt.imshow(image1)\n    input_arr = ks.preprocessing.image.img_to_array(validgen[0][0][n])\n    input_arr = np.array([input_arr])  # Convert single image to a batch.\n    predictions = model_com01[0].predict_classes(input_arr)\n    #our dictionary starts from 1 whereas model has classes from 0.\n    return predictions","8783b109":"get_predictions(10)","9c215cf4":"## Create Image Data Generator","b8c8e966":"### Get Prediction and visualise the output.","c2c20396":"## Build the Compiler","fc7c7b3b":"# Metal Defect Classifier\n- This application of detecting defect on metal surface is an example of how deep learning can be implemented to Industrial Processes. \n- It will reduce the inprocess error and add a middle layer to quality inspection.","11c5bbfa":"### Fit Model and Evaluate","82ba0c85":"## Build Model's Architecture"}}