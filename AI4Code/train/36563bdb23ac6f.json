{"cell_type":{"9d3bd067":"code","56b6f07f":"code","8ad537e7":"code","c9af9088":"code","ee816c5c":"code","6eb4a411":"code","8ab42ac0":"code","bb731e42":"code","5f2d5df3":"code","a4026427":"code","8d4661fd":"code","6cbf94b9":"code","f086ee77":"markdown","14ee289a":"markdown","47cd719b":"markdown","a73a783f":"markdown","dbe25fac":"markdown","8b1a438d":"markdown","484340fe":"markdown","7d6b79b2":"markdown","30848957":"markdown","ae62477f":"markdown"},"source":{"9d3bd067":"#Importing required libraries \n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split","56b6f07f":"data = pd.read_csv('..\/input\/mushroom-classification\/mushrooms.csv')\ndata.head()","8ad537e7":"for each_class in data.columns:\n    print(f\"{each_class} : {data[each_class].isnull().sum()}\")","c9af9088":"X = data.drop('class', axis = 1)\nY = data['class']","ee816c5c":"enc = OneHotEncoder()\nX_trans = enc.fit_transform(X)","6eb4a411":"X_train, X_test, y_train, y_test = train_test_split(X_trans, Y, test_size = 0.3, random_state = 7)","8ab42ac0":"KNN = KNeighborsClassifier(n_neighbors = 10)\nLR = LogisticRegression(penalty='l2')\nNB = BernoulliNB()\n\nmodels = {'knn':KNN, 'lr': LR, 'nb':NB}\n\ndef train(model, X, Y):\n    model.fit(X, Y)\n        \ndef predict(model, X_test):\n    return model.predict(X_test)\n\ndef accuracy(Y_pred, Y_test):\n    return accuracy_score(Y_test, Y_pred)","bb731e42":"pred = []\nfor k,v in models.items():\n    train(v, X_train, y_train)\n    pred.append((k, accuracy(predict(v, X_test), y_test)))","5f2d5df3":"for x in pred:\n    print(f\"{x[0]} : {x[1]*100}\")","a4026427":"confusion_matrix(y_test, predict(KNN, X_test)) #Confusion matrix for KNN","8d4661fd":"confusion_matrix(y_test, predict(LR, X_test)) #Confusion matrix for Logistic Regression","6cbf94b9":"confusion_matrix(y_test, predict(NB, X_test)) ##Confusion matrix for Naive Bayes","f086ee77":"As all the featuures are categorical, we convert them into numeric format using OneHotEncoder","14ee289a":"As we can see both KNN and Logistic Regression got perfect scores while Naive Bayes did reasonably well.","47cd719b":"Checking data for missing values:","a73a783f":"Let's take a look at the confusion matrix.","dbe25fac":"Now let's train the models and store the predicted values in a list:","8b1a438d":"Loading data","484340fe":"P.S. I am a complete beginner so please excuse my mistakes \ud83d\ude05.","7d6b79b2":"Functions to Train and Test models:","30848957":"Splitting dataset into train and test","ae62477f":"There aren't any missing values"}}