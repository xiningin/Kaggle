{"cell_type":{"57bbe1ef":"code","715cdf71":"code","085d0905":"code","fdf144ba":"code","74b4812a":"code","3e20971e":"code","35793630":"code","943a8fec":"code","572ce93a":"code","d6a8a507":"code","8b33b08d":"code","117e53a2":"code","2175abe2":"code","5f30ab0e":"code","cddd66ca":"code","534718b2":"code","12ff0300":"code","d96f5bb3":"code","7a005509":"code","d79fb86b":"code","a5d7b477":"code","ce3a3e2f":"code","eb9068c6":"code","50e76ae5":"code","e16d19b1":"code","6ff7a2b9":"code","03907f32":"code","9cbe84ab":"code","31cad9a2":"code","a3c51274":"code","2da31ef1":"code","fca75902":"code","fd8bdd24":"code","b9e8c221":"code","93ea6dc2":"code","9daf94da":"code","c4eedbe4":"code","731fefd6":"code","65f5c49c":"code","fe748caa":"code","3d0de1ea":"code","337416c1":"code","3a4e272e":"code","f4d0d6ca":"code","efba4a5d":"code","29f57ef6":"code","2247ad94":"code","5f8d736e":"code","ee602ebb":"code","e8769b9d":"code","382f38c9":"code","313bf8c5":"code","544b08a2":"code","dded6df7":"code","abb1706f":"code","f6f2a030":"code","646c9c6c":"code","b1551ab5":"code","a09ce2bb":"code","09f88f6d":"code","167454fd":"code","1ecf6bbe":"code","0890e8b4":"code","d7545c30":"code","92639c04":"code","7985cb22":"code","c856b405":"code","a9aecf8f":"code","ce1529f9":"code","4567a38f":"code","3dbbf469":"code","16072900":"code","10c12dc5":"code","31752259":"code","6c02a719":"code","aea0ff45":"code","7b225434":"code","8a787731":"code","529885b6":"code","f08d0729":"code","3bb92714":"code","effd2a50":"code","b365b31d":"code","b4c479ad":"code","4a0fad9b":"code","d35f911c":"code","d2bc44cb":"code","6ab046e7":"code","c1614772":"code","187fc7eb":"code","b6909765":"markdown","d2beef62":"markdown","178ef844":"markdown","d7ccebae":"markdown","4bdedafd":"markdown","3e2630dc":"markdown","6a9ca3b8":"markdown","98ea291f":"markdown","e1304967":"markdown","9ab2921f":"markdown","2a567442":"markdown","b2fab2e4":"markdown","103c5ff4":"markdown","d4936950":"markdown","4391943b":"markdown","3378c85d":"markdown","2f6db368":"markdown","a8098415":"markdown","62c04f71":"markdown","0d648e72":"markdown","fbc6b83b":"markdown","fd6c94d4":"markdown","4a595d4a":"markdown","121bb17e":"markdown","d1fda77b":"markdown","ac4bdf73":"markdown","33ff886b":"markdown","aa275be7":"markdown","26f1449a":"markdown","871a9896":"markdown","93cae9cd":"markdown","3061a430":"markdown","c4559d1d":"markdown","8da09f5b":"markdown","aed753d9":"markdown","83886041":"markdown","988ee81e":"markdown","b6cb8113":"markdown","273d2b89":"markdown","3b627f9e":"markdown","0918b865":"markdown","dddf82e8":"markdown"},"source":{"57bbe1ef":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndata_train = pd.read_csv('..\/input\/train.csv')\ndata_test = pd.read_csv('..\/input\/test.csv')","715cdf71":"display(data_train.sample(3))\ndisplay(data_test.sample(3))","085d0905":"display(data_train.head())\ndisplay(data_test.head())\ndisplay(data_test.tail())","fdf144ba":"data_train.describe() ","74b4812a":"data_test.describe()","3e20971e":"print(str(data_train.shape)+ ' -> data_train')\nprint(str(data_test.shape)+ ' -> data_test')","35793630":"data_train.info()","943a8fec":"data_train = data_train.drop(columns=['Name', 'Ticket', 'Fare', 'Cabin']) # dropping columns which are unnecessary for analysis\ndata_test = data_test.drop(columns=['Name', 'Ticket', 'Fare', 'Cabin']) # doing same for data_test to maintain similar structure of dataframes for both train and test sets\n","572ce93a":"display(data_train.Age.value_counts(dropna=False).sort_index())\ndisplay(data_test.Age.value_counts(dropna=False).sort_index())","d6a8a507":"data_train.Age = data_train.Age.fillna(data_train.Age.mean()) #filling all nulls in 'Age' column with the mean age\ndata_test.Age = data_test.Age.fillna(data_test.Age.mean()) #filling all nulls in 'Age' column with the mean age\n\n","8b33b08d":"display(data_train.Embarked.value_counts(dropna=False))\ndisplay(data_test.Embarked.value_counts(dropna=False))\n","117e53a2":"data_train.Embarked = data_train.Embarked.fillna('S') #filling all nulls in 'Embarked' column with 'S'\n","2175abe2":"b = data_train.pop('Survived') # from data_train, pop the 'Survived' column \ndata_train = pd.concat([data_train, b], axis=1) # and add it to the end of data_train\ndisplay(data_train.head())\n","5f30ab0e":"display ( data_train.Age.value_counts(dropna=False).sort_index() )\ndisplay ( data_test.Age.value_counts(dropna=False).sort_index() )","cddd66ca":"display ( data_train.Sex.value_counts(dropna=False).sort_index() )\ndisplay( data_test.Sex.value_counts(dropna=False).sort_index() )","534718b2":"display ( (data_train.Pclass.value_counts(dropna=False).sort_index()) )\ndisplay ( (data_test.Pclass.value_counts(dropna=False).sort_index()) )","12ff0300":"display ( data_train.Survived.value_counts(dropna=False).sort_index() )\n","d96f5bb3":"display ( data_train.SibSp.value_counts(dropna=False).sort_index() )\ndisplay ( data_test.SibSp.value_counts(dropna=False).sort_index() )","7a005509":"display ( data_train.Parch.value_counts(dropna=False).sort_index() )\ndisplay ( data_test.Parch.value_counts(dropna=False).sort_index() )","d79fb86b":"display ( data_train.Embarked.value_counts(dropna=False).sort_index() )\ndisplay ( data_test.Embarked.value_counts(dropna=False).sort_index() )","a5d7b477":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# notes : \n# sns.set()\n# f, ax = plt.subplots(figsize=(19, 19))\n# sns.heatmap(data_train, annot=True, linewidths=.5, ax=ax)\n# -- above not working -- \n\n\n","ce3a3e2f":"print( ' data_train ')\n\nsns.set(style=\"dark\")\n# Compute the correlation matrix\ncorr = data_train.corr()\ndisplay(corr)\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(2, 900, as_cmap=True)\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, cmap=cmap, vmax=1, vmin=-1, center=0,\n            square=True, linewidths=.05, linecolor='grey') \n\n\n\n\n\nprint( ' data_test ')\n\nsns.set(style=\"dark\")\n# Compute the correlation matrix\ncorr = data_test.corr()\ndisplay(corr)\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(2, 900, as_cmap=True)\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, cmap=cmap, vmax=1, vmin=-1, center=0,\n            square=True, linewidths=.05, linecolor='grey') \n\n\n\n","eb9068c6":"plt.figure(figsize=(15,5))\n\nplt.subplot(1,2,1)\nplt.title('TRAIN')\nmy_palette = {1:'g', 2:'c', 3:'y'}\nsns.boxplot(data_train['Pclass'], data_train['Age'], palette=my_palette, saturation= 40) \nplt.xticks = [1,2,3]\n\nplt.subplot(1,2,2)\nplt.title('TEST')\nmy_palette = {1:'g', 2:'c', 3:'y'}\nsns.boxplot(data_test['Pclass'], data_test['Age'], palette=my_palette, saturation= 40) \nplt.xticks = [1,2,3]\n","50e76ae5":"plt.figure(figsize=(30,20))\nplt.subplot(1,2,1)\nplt.title('TRAIN')\nplt.scatter( data_train['Pclass'], data_train['Age'], c='red', marker='d', s= 6.0)\nplt.xticks = ([1,2,3])\n\nplt.subplot(1,2,2)\nplt.title('TEST')\nplt.scatter( data_test['Pclass'], data_test['Age'], c='red', marker='d', s= 6.0)\nplt.xticks = ([1,2,3])","e16d19b1":"display ( sns.countplot(x=data_train['Survived'], hue=data_train['Sex'], data=data_train, palette='Spectral', saturation=10) )\n","6ff7a2b9":"plt.figure(figsize=(30,20))\nplt.subplot(2,6,1)\nplt.title('EMBARKED VS. SURVIVAL')\nsns.countplot(x=data_train['Embarked'], hue=data_train['Survived'], palette='winter')\nplt.ylim(0,700)\nplt.legend()\nplt.subplot(2,6,2)\nplt.title('EMBARKED VS. SEX')\nsns.countplot(x=data_train['Embarked'], hue=data_train['Sex'], palette='spring')\nplt.ylim(0,700)\n\n# plt.figure(figsize=(5,5))\n# sns.countplot(x=data_train['Survived'], hue=data_train['Embarked'], palette= 'summer', alpha=0.3)\n# plt.ylim(0,600) -- this code will put two graphs in one -- \n\nplt.subplot(2,6,3)\nplt.title('SURVIVAL VS. SEX')\nsns.countplot(x=data_train['Survived'], hue=data_train['Sex'], palette= 'autumn')\nplt.ylim(0,700)\n\nplt.subplot(2,6,4)\nplt.title('Distribution of Gender')\nsns.countplot(x=data_train['Sex'], hue=data_train['Sex'], palette= 'summer')\nplt.ylim(0,700)\n\nplt.subplot(2,6,5)\nplt.title('Distribution of Embarked Location')\nsns.countplot(x=data_train['Embarked'], hue=data_train['Embarked'], palette= 'summer')\nplt.ylim(0,700)\n\n\nplt.subplot(2,6,6)\nplt.title('Distribution of Survival')\nsns.countplot(x=data_train['Survived'], hue=data_train['Survived'], palette= 'summer')\nplt.ylim(0,700)","03907f32":"plt.figure(figsize=(30,20))\n\nplt.subplot(2,6,2)\nplt.title('EMBARKED VS. SEX')\nsns.countplot(x=data_test['Embarked'], hue=data_test['Sex'], palette='spring')\nplt.ylim(0,700)\n\nplt.subplot(2,6,4)\nplt.title('Distribution of Gender')\nsns.countplot(x=data_test['Sex'], hue=data_test['Sex'], palette= 'summer')\nplt.ylim(0,700)\n\nplt.subplot(2,6,5)\nplt.title('Distribution of Embarked Location')\nsns.countplot(x=data_test['Embarked'], hue=data_test['Embarked'], palette= 'summer')\nplt.ylim(0,700)\n","9cbe84ab":"plt.figure(figsize=(20,6))\nplt.subplot(1,3,1)\nplt.title('data_train : CLASS VS. SURVIVAL')\nsns.countplot(x=data_train['Pclass'], hue=data_train['Survived'], palette='cool')\nplt.ylim(0,700)\nplt.legend(['Died','Survived'])\n\nplt.subplot(1,3,2)\nplt.title('data_train : CLASS VS. GENDER')\nsns.countplot(x=data_train['Pclass'], hue=data_train['Sex'], palette='magma')\nplt.ylim(0,700)\nplt.legend(['Male', 'Female'])\n\nplt.subplot(1,3,3)\nplt.title('data_train : GENDER VS. SURVIVAL')\nsns.countplot(x=data_train['Sex'], hue=data_train['Survived'], palette='prism')\nplt.ylim(0,700)\nplt.legend(['Died', 'Survived'])\n\n\nplt.figure(figsize=(10,10))\nplt.subplot(1,1,1)\nplt.title('data_test : CLASS VS. GENDER')\nsns.countplot(x=data_test['Pclass'], hue=data_test['Sex'], palette='magma')\nplt.ylim(0,300)\nplt.legend(['Male', 'Female'])","31cad9a2":"data_train[(data_train.Embarked=='S')].groupby(['Pclass', 'Sex']).size() #.plot(kind='bar', cmap='summer')","a3c51274":"data_test[(data_test.Embarked=='S') ].groupby(['Pclass', 'Sex']).size()#.plot(kind='bar', cmap='summer')","2da31ef1":"data_train.shape","fca75902":"data_train.head()","fd8bdd24":"data_test.shape","b9e8c221":"data_test.head()","93ea6dc2":"data_train = pd.get_dummies(data_train, columns=['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked'])\ndata_train.info()","9daf94da":"data_test = pd.get_dummies(data_test, columns=['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked'])\ndata_test.info()","c4eedbe4":"data_train['Age'] = (data_train.Age\/\/10*10)","731fefd6":"data_test['Age'] = (data_test.Age\/\/10*10)","65f5c49c":"data_train = pd.get_dummies(data_train, columns=['Age'])","fe748caa":"data_test = pd.get_dummies(data_test, columns=['Age'])","3d0de1ea":"b = data_train.pop('Survived')\ndata_train = pd.concat([data_train, b], axis=1)\ndata_train.head()","337416c1":"X = data_train.drop(columns = ['Survived', 'PassengerId'], axis=1)","3a4e272e":"X","f4d0d6ca":"y = data_train.Survived","efba4a5d":"y","29f57ef6":"# X   #418 rows\n# y   #891 rows\n\ndata_train.info()","2247ad94":"y.head()","5f8d736e":"plt.figure(figsize=(8,8))\nplt.title('data_train : CLASS 1 VS. SURVIVAL')\nsns.countplot(x=data_train['Pclass_1'], hue=data_train['Survived'], palette='magma')\nplt.ylim(0,700)\nplt.legend(['Did not survive', 'Survived'])","ee602ebb":"plt.figure(figsize=(8,8))\nplt.title('data_train : CLASS 2 VS. SURVIVAL')\nsns.countplot(x=data_train['Pclass_2'], hue=data_train['Survived'], palette='magma')\nplt.ylim(0,700)\nplt.legend(['Did not survive', 'Survived'])","e8769b9d":"plt.figure(figsize=(8,8))\nplt.title('data_train : CLASS 3 VS. SURVIVAL')\nsns.countplot(x=data_train['Pclass_3'], hue=data_train['Survived'], palette='magma')\nplt.ylim(0,700)\nplt.legend(['Did not survive', 'Survived'])","382f38c9":"from sklearn.model_selection import train_test_split","313bf8c5":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=2)","544b08a2":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score","dded6df7":"num_trees = 1000\nmax_features = 3\nkfold = KFold(n_splits=10, random_state=7)\nrfc = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)","abb1706f":"X_train.shape","f6f2a030":"X_test.shape","646c9c6c":"y_train.shape","b1551ab5":"y_test.shape","a09ce2bb":"type(y_train)","09f88f6d":"rfc.fit(X_train, y_train)","167454fd":"rfc.score(X_train, y_train) ","1ecf6bbe":"rfc.score(X_test, y_test)","0890e8b4":"y_pred = rfc.predict(X_test)","d7545c30":"y_pred # this is an array of predictions","92639c04":"from sklearn.metrics import accuracy_score","7985cb22":"acc = accuracy_score(y_test, y_pred)","c856b405":"acc","a9aecf8f":"type(y_test)","ce1529f9":"X_test.shape","4567a38f":"y_test.shape","3dbbf469":"data_train.shape","16072900":"data_test.shape","10c12dc5":"data_test.isnull().sum()","31752259":"data_test.head()","6c02a719":"np.array(y_test).reshape(-1,1).shape","aea0ff45":"data_train.shape","7b225434":"data_train.head()","8a787731":"X_train.head()","529885b6":"X_train.shape","f08d0729":"y_train.head()","3bb92714":"y_train.shape","effd2a50":"X_test.head()","b365b31d":"X_test.shape","b4c479ad":"y_test.head()","4a0fad9b":"y_test.shape","d35f911c":"data_test = data_test.drop(columns=['PassengerId'])","d2bc44cb":"data_test.shape","6ab046e7":"df = pd.DataFrame({'PassengerId': range(892, 1310), 'Survived': (rfc.predict(data_test))})","c1614772":"type(df)","187fc7eb":"df.to_csv('TitanicDataSetKaggleVersion2.csv', index=False)","b6909765":"## **DATA_TRAIN **\n\n* We can see from 1, of those who embarked on area 'S', more people lost their lives than survived compared to 'C' and 'Q'.\n* Also, of those who embarked on 'S', majority of them were males. Therefore, in 3, we can see that males tended to lose their lives more than females, possibly due to the huge imbalance in the number of men on the Titanic in general. As a result, the number of females who survived is greater than the number of males who survived (see 6).\n* Looking at 4, we see that huge imbalance in the distribution of males vs females. Therefore, it is not surprising that more men died than women. \n* Looking at 5, we see a huge imbalance in how many embarked at 'S' vs 'C' and 'Q'. Therefore, it is not surprising that those who embarked at 'S' had the highest proportion of those who died compared to 'C' or 'Q'.\n  \n* However, in the cases of 'C' and 'Q' embarkments, the survived vs not survived levels are approximately balanced. It seems like those who embarked at 'S' and were male had the highest chances of dying.\n* The graph 6 suggests that more people died than survived. It is evident that the reasons for this are that :   1. More people boarded at 'S' than 'C' or 'Q'. 2. More men boarded at 'S', 'C', and 'Q' than women. 3. Hence, more men were on the Titanic than women. 4. More men died than women. 5. Therefore, more passengers died than survived.\n\n\n## **DATA_TEST **\n\n* Embarked vs. Sex graphs for data_train and data_test are similar in proportions (number of males (or females) who embarked in any area \/ total number of passengers)\n* 'Distribution of Gender' graphs for data_train and data_test are similar in proportions (number of males \/ total number of passengers, number of females \/ total number of passengers)\n* 'Distribution of Embarked Location' graphs for data_train and data_test are similar in proportions ( number of people who embarked in any area \/ total number of passengers) with slight variations. The variations are that the proportions can be little higher or lower than expected, but it's not significant enough to skew the results.","d2beef62":"**Exploring the data further : **","178ef844":"## Importing train_test_split","d7ccebae":"try out other variations of this to see if you get similar results as before !","4bdedafd":"# Change CSV into DataFrame\n\nCSV files can be loaded into a dataframe by calling `pd.read_csv` . After loading the training and test files, print a `sample` to see what you're working with.","3e2630dc":"so there are 2 NaNs to take care of in data_train. I will replace those NaNs with the mode of the Embarked column, which we can see is 'S'.","6a9ca3b8":"**The model has been fitted to the training data, X_train and y_train.**","98ea291f":"### Analyzing shapes of the dataframes","e1304967":"Now, will be shifting the 'Survived' column to the end of the dataframe for easier analysis","9ab2921f":"---","2a567442":"----","b2fab2e4":"Successfully completed one-hot encoding on the dataframe's columns","103c5ff4":"Even after using .drop() method, data_train hasn't been permanently altered. From this, the 'Survived' column is selected as 'y'.","d4936950":"## SCATTERPLOT ANALYSIS OF PASSENGERS' AGES IN EACH CLASS","4391943b":"The distribution of males and females in 2nd class are slightly different in proportions and slightly more different in 3rd class for data_train and data_test dataframes. However, this should not alter the results significantly.","3378c85d":"It is confirmed that there are no more nulls in any of the columns of data_train and data_test.","2f6db368":"---","a8098415":"There seems to be similar distributions of ages in Classes 1, 2, and 3 in data_train and data_test with the exception of 1st class in data_train which has more younger people than data_test does. Another exception is 3rd class in data_train has more elder people than data_test does.","62c04f71":"## DATA VISUALIZATION ","0d648e72":"# Machine Learning from Start to Finish with Scikit-Learn\n\nThis notebook covers the basic Machine Learning process in Python step-by-step. Go from raw data to at least 78% accuracy on the Titanic Survivors dataset. \n\n### Steps Covered\n\n\n1. Importing  a DataFrame\n2. Visualize the Data\n3. Cleanup and Transform the Data\n4. Encode the Data\n5. Split Training and Test Sets\n6. Fine Tune Algorithms\n7. Cross Validate with KFold\n8. Upload to Kaggle","fbc6b83b":"**The columns 'SibSp', 'Parch', 'Sex', 'Embarked', and 'Pclass' contain categorical data. Machine Learning Algorithms cannot process categorical data. So, one-hot encoding is applied to these columns in order to convert the data into numbers. One-hot encoding is done below using pandas get_dummies() . Also, it cannot process **","fd6c94d4":"# **Import required libraries and packages. Convert CSV files into dataframes named data_train and data_test**","4a595d4a":"-----","121bb17e":"Interesting question : The test accuracy score is 79.82%. What can be done to increase the score? \n","d1fda77b":"Of the people who were in first class, more people died than survived. \n\nOf the people who were in second class, approximately equal numbers of passengers survived or died. So the ratio of survived : not survived would be almost 1:1 .\n\nConsidering the people who were in third class , more passengers died than those who survived.","ac4bdf73":"---","33ff886b":"**As we can see from above, data_test is similar to data_train, except that data_test does not contain the 'Survived' column. The reason is that the target or dependent variable is 'Survived'. That is, we are going to predict 'Survived' values. Therefore, it is not going to be given to us in data_test. **","aa275be7":"Interesting question : why is the training accuracy score only 88.77% and not 100% ? ","26f1449a":"Having more than 5 siblings \/ spouses was very rare.","871a9896":"the distribution of people in 3rd class in data_train and data_test are different from each other when we consider the outliers. Otherwise, all classes have similar distributions in both data_train and data_test.","93cae9cd":"177 missing ages in train set\n\n86 missing ages in test set \n\nI will replace the missing ages with average age","3061a430":"**DATA_TRAIN**\n\nmore males lost their lives than females did\n\nmore females survived than the males did","c4559d1d":"**As earlier, the model predicted survival with an accuracy of 79.82%.**","8da09f5b":"### Filling in null values with means of their respective columns","aed753d9":"Using RandomForestClassifier on the Titanic dataset helped predict survival of passengers with an accuracy of 79.37% .","83886041":"## **Initial exploration of data**","988ee81e":"## Boxplot Analysis of passengers' ages in each class","b6cb8113":"### CHECKING FOR NULL VALUES IN ALL COLUMNS IN BOTH DATA_TRAIN AND DATA_TEST","273d2b89":"Using 'dropna = False' inside value_counts() method enables us to include counts of null values when performing value_counts() ","3b627f9e":"## ANALYSIS OF GENDER AND SURVIVAL STATUS","0918b865":"NOTE : drop passengerid for both above ****","dddf82e8":"Important to note : Embarked and Sex are not included in the correlation tables or matrices, since they do not have numerical values.\n\nDATA_TRAIN \n\nFrom the correlation matrix of data_train, we can see that:\n1. As Pclass increases (going from 1st to 3rd class), the survival rate decreases, as denoted by the light red shade between Pclass and Survived.\n2. As Age increases, the Pclass tends to be lower (that is, older passengers tended to be in the first class more than second class , and more than third class.)\n3. As Age increased, the survival rate tended to be lower. That is, older passengers were less likely to survive, even though they had greater probability of being in upper classes. This is very ironic.\n\nDATA_TEST\n\nThis also seems to be the case for data_test, since the colors are approximately the same in both heatmaps."}}