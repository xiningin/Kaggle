{"cell_type":{"6e537b92":"code","110585a1":"code","cc4039fc":"code","24a4754e":"code","e45aca40":"code","b633db77":"code","4ab7c7f6":"code","6e11839a":"code","b1194874":"code","087baf2f":"markdown","f16bfa53":"markdown","ec583aa3":"markdown","623772f4":"markdown","197b7007":"markdown","21e82e3a":"markdown","13ebc1e9":"markdown","8f40a7b8":"markdown"},"source":{"6e537b92":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport optuna\nfrom catboost import CatBoostRegressor\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom optuna.samplers import TPESampler\nfrom sklearn.model_selection import KFold\noptuna.logging.set_verbosity(optuna.logging.WARNING)","110585a1":"train = pd.read_csv('..\/input\/tabular-playground-series-aug-2021\/train.csv')\nprint('train shape:',train.shape)","cc4039fc":"# Train data\nX_train = train.drop(columns = ['loss','id'])\ny_train = train['loss'].values","24a4754e":"def getCbHyperparameters(trial):\n    cb_params = {\n        'iterations':trial.suggest_int(\"iterations\", 1000, 5000),\n        'od_wait':trial.suggest_int('od_wait', 500, 2000),\n        'loss_function':'RMSE',\n        'task_type':\"GPU\",\n        'eval_metric':'RMSE',\n#         'leaf_estimation_method': trial.suggest_categorical(\"leaf_estimation_method\", [\"Newton\", \"Gradient\"]),\n        'bootstrap_type': 'Bernoulli',\n        'learning_rate' : trial.suggest_uniform('learning_rate',0.02,1),\n        'reg_lambda': trial.suggest_uniform('reg_lambda',1e-5,100),\n        'subsample': trial.suggest_uniform('subsample',0,1),\n        'random_strength': trial.suggest_uniform('random_strength',10,50),\n        'depth': trial.suggest_int('depth',1,15),\n        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',1,30),\n        'leaf_estimation_iterations': trial.suggest_int('leaf_estimation_iterations',1,15)\n#         'grow_policy': trial.suggest_categorical(\"grow_policy\", [\"SymmetricTree\", \"Depthwise\", \"Lossguide\"])\n    }\n    return cb_params","e45aca40":"def objective(trial, X, y):\n    \n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=.3, random_state=1337)\n    \n    cb_param = getCbHyperparameters(trial)\n\n    eval_set = [(X_valid, y_valid)]\n    \n    cb_regressor = CatBoostRegressor(**cb_param)\n\n    # Model Fit\n    cb_regressor = cb_regressor.fit(X_train, y_train)\n    \n    # Model Prediction\n    preds = cb_regressor.predict(X_valid)\n    \n    # Compute rmse\n    rmse = np.sqrt(mean_squared_error(y_valid, preds))\n    \n    return rmse","b633db77":"# Callback function to print log messages when the best trial is updated\n\ndef logging_callback(study, frozen_trial):\n    previous_best_value = study.user_attrs.get(\"previous_best_value\", None)\n    if previous_best_value != study.best_value:\n        study.set_user_attr(\"previous_best_value\", study.best_value)\n        print(\n            \"Trial {} finished with best value: {}. \".format(\n            frozen_trial.number,\n            frozen_trial.value\n            )\n        )","4ab7c7f6":"%%time\n\nstudy = optuna.create_study(sampler=TPESampler(seed=1337), direction='minimize', study_name='cb')\nfunc = lambda trial: objective(trial, X_train, y_train)\n\nstudy.optimize(func, timeout=60*5, callbacks=[logging_callback]) # timeout = seconds * minutes. Longer timeout will tend to lead to better hyperparameter tuning.","6e11839a":"print(f\"\\tBest value (rmse): {study.best_value:.5f}\")\nprint(f\"\\tBest params:\")\nfor key, value in study.best_params.items():\n    print(f\"\\t\\t{key}: {value}\")","b1194874":"import joblib\n\njoblib.dump(study, \"cb_study.pkl\")","087baf2f":"# Define objective function","f16bfa53":"# Custom logging callback function","ec583aa3":"# Load dataset","623772f4":"# Initiate experiment to find best hyperparameters","197b7007":"This is a follow up notebook of [Catboost 101 - Baseline](https:\/\/www.kaggle.com\/aayush26\/tps-aug-2021-catboost-101-baseline).\n\n\nThe scope of this notebook is to perform hyperparameter tuning and store the best hyperparameters found for Catboost model. \n\nThe stored file can later be loaded into another notebook by using `Kaggle Add data` or directly copy-paste the best params displayed in the output cell.\n\n### Pre-requisite\n1. [GPU version] Change the accelerator to GPU in order to be able to exexute this notebook.\n2. [CPU version] Delete the following hyper params present in getCbHyperparameters(): `'task_type':\"GPU\",`","21e82e3a":"# Save the study containing the best hyperparameters for the CatBoost model","13ebc1e9":"# Imports","8f40a7b8":"# Setup CatBoost hyperparameters for experiment"}}