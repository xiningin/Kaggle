{"cell_type":{"09ed7c66":"code","4cc8a499":"code","ae8841b3":"code","3d4e98d7":"code","eaa9c4af":"code","9e64da82":"code","2cb315af":"code","cda96bf0":"code","e6feab5f":"code","696d76b5":"code","54f4d131":"code","b0bee87a":"code","62d87de4":"code","a97702ee":"code","6f6441d0":"code","2162701d":"code","9e522c12":"code","18926a4d":"code","416cea45":"code","10b0a1c9":"code","030e72d3":"code","319cdc7b":"code","f68cfe36":"code","57508698":"code","d9a47b8e":"code","0dfcf97f":"code","2960edf2":"code","7009be39":"code","6c5da8f5":"code","b40f0f60":"code","ee93c18b":"code","d54578ad":"code","cb26aede":"code","f4ba2554":"code","864087c3":"code","0c27a21a":"code","25e4b962":"code","ce286307":"code","ffacc33c":"code","c54428ea":"code","33567440":"code","6e1bc382":"code","9e32ad66":"code","6e814b64":"code","df1159db":"code","bed596d2":"code","2c0d46dc":"code","df233654":"code","3492baa2":"code","acb8912e":"code","b6f1c46b":"code","b294f5dd":"code","f71a15ee":"code","d1c2d460":"code","06a4d2e3":"code","2b44c3dd":"markdown","19db53f8":"markdown","6721c2ab":"markdown","33e59b20":"markdown","9f434a4e":"markdown","08f5bcd0":"markdown","0e490bd7":"markdown","3f7c50e7":"markdown","44a92b76":"markdown","a3e6974e":"markdown","ace332c2":"markdown","6f7dc052":"markdown","4a7d837b":"markdown","1ed613c3":"markdown","0eeaab2a":"markdown","89795fcd":"markdown","4403fa9a":"markdown","d9b20e3a":"markdown","60ff0d18":"markdown","42c699f9":"markdown","e0f22a10":"markdown","4867a43e":"markdown","766b78e4":"markdown","c3cafaab":"markdown","ca807a08":"markdown","75bce36f":"markdown","49ad6bb3":"markdown","22450b24":"markdown","bf3ea8af":"markdown","217b349d":"markdown","3d87ef2f":"markdown","75498fba":"markdown","05f2e7be":"markdown","cc3ec9a4":"markdown","cbbe6e4a":"markdown","da1a3870":"markdown"},"source":{"09ed7c66":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4cc8a499":"!pip install seaborn\n!pip install bubbly\n!pip install plotly\n!pip install IPython\n!pip install eli5\n!pip install shap\n!pip install pdpbox","ae8841b3":"import pandas as pd\nfrom IPython.display import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.font_manager as fm\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\nfrom bubbly.bubbly import bubbleplot\nimport warnings\nfrom sklearn.model_selection import train_test_split\nwarnings.filterwarnings('ignore')\nfrom sklearn.ensemble import RandomForestClassifier\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nimport shap\nfrom pdpbox import pdp, info_plots\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn import tree\nimport numpy as np\nfrom sklearn.tree import export_graphviz\nimport graphviz","3d4e98d7":"dt = pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')\ndt.head()","eaa9c4af":"# data shape\ndt.shape","9e64da82":"# Check data type\ndt.info()","2cb315af":"# Change columns's name generally\ndt.columns = ['age', 'sex', 'chest_pain_type', 'resting_blood_pressure', 'cholesterol', 'fasting_blood_sugar', 'rest_ecg', 'max_heart_rate_achieved',\n       'exercise_induced_angina', 'st_depression', 'st_slope', 'num_major_vessels', 'thalassemia', 'target']","cda96bf0":"# Divided features by scale\ncategory_ft_dt = dt[['sex','chest_pain_type','fasting_blood_sugar','rest_ecg','exercise_induced_angina','st_slope','num_major_vessels','thalassemia','target']]\nnumeric_ft_dt = dt[['age','resting_blood_pressure','cholesterol','max_heart_rate_achieved','st_depression','target']]\ntarget = dt[['target']]","e6feab5f":"print('category features','\\n',category_ft_dt.head())\nprint('numeric features','\\n',numeric_ft_dt.head())","696d76b5":"# categories value change string\neda_heart1=dt.copy()\neda_heart1['sex'][eda_heart1['sex']==0] ='female'\neda_heart1['sex'][eda_heart1['sex']==1] ='male'\neda_heart1['chest_pain_type'][eda_heart1['chest_pain_type']==0] = 'typical angina'\neda_heart1['chest_pain_type'][eda_heart1['chest_pain_type']==1] = 'atypical angina'\neda_heart1['chest_pain_type'][eda_heart1['chest_pain_type']==2] = 'non-anginal pain'\neda_heart1['chest_pain_type'][eda_heart1['chest_pain_type']==3] = 'asymptomatic'\neda_heart1['fasting_blood_sugar'][eda_heart1['fasting_blood_sugar']==0] = 'lower than 120mg\/ml'\neda_heart1['fasting_blood_sugar'][eda_heart1['fasting_blood_sugar']==1] = 'greater than 120mg\/ml'\neda_heart1['rest_ecg'][eda_heart1['rest_ecg']==0] = 'normal'\neda_heart1['rest_ecg'][eda_heart1['rest_ecg']==1] = 'ST-T wave abnormality'\neda_heart1['rest_ecg'][eda_heart1['rest_ecg']==2] = 'left ventricular hypertrophy'\neda_heart1['exercise_induced_angina'][eda_heart1['exercise_induced_angina']==0] = 'no'\neda_heart1['exercise_induced_angina'][eda_heart1['exercise_induced_angina']==1] = 'yes'\neda_heart1['st_slope'][eda_heart1['st_slope']==0] = 'upsloping'\neda_heart1['st_slope'][eda_heart1['st_slope']==1] = 'flat'\neda_heart1['st_slope'][eda_heart1['st_slope']==2] = 'downsloping'\neda_heart1['thalassemia'][eda_heart1['thalassemia']==0] = 'Unknown'\neda_heart1['thalassemia'][eda_heart1['thalassemia']==1] = 'normal'\neda_heart1['thalassemia'][eda_heart1['thalassemia']==2] = 'fixed defect'\neda_heart1['thalassemia'][eda_heart1['thalassemia']==3] = 'reversable defect'\neda_heart1['target'][eda_heart1['target']==0] = '< 50% diameter narrowing'\neda_heart1['target'][eda_heart1['target']==1] = '> 50% diameter narrowing'","54f4d131":"eda_heart1.head()","b0bee87a":"plt.rcParams['axes.axisbelow'] = True\nplt.figure(figsize=(30,30))\nfor i in range(len(category_ft_dt.columns)):\n    plt.subplot(3,3,i+1)\n    sns.countplot(eda_heart1[category_ft_dt.columns[i]])\n    plt.xlabel(category_ft_dt.columns[i],size=20)\n    plt.ylabel('count',size=20, rotation=0,labelpad=30)\n    plt.xticks(fontsize=15)\n    plt.yticks(fontsize=15)\n    plt.grid(axis='y')","62d87de4":"print('category data ratio','\\n')\nfor i in category_ft_dt.columns:\n    print(i, '\\n')\n    for j in eda_heart1[i].value_counts().index:\n        print(j,' : ',round(eda_heart1[i].value_counts()[j]\/eda_heart1.shape[0]*100,2),'%')\n    print()","a97702ee":"xlabeling=['sex','chest_pain_type','fasting_blood_sugar','rest_ecg','exercise_induced_angina','st_slope','num_major_vessels','thalassemia']\nfor i in range(len(xlabeling)):\n    f,ax = plt.subplots(figsize=(10,8))\n    sns.countplot(x=xlabeling[i],hue=\"target\",data=eda_heart1)\n    bars = ax.patches\n    half = int(len(ax.patches)\/2)\n    plt.xlabel(xlabeling[i],size=20)\n    plt.ylabel('count',size=20, rotation=0,labelpad=30)\n    plt.xticks(fontsize=15)\n    plt.yticks(fontsize=15)\n    plt.legend(loc=1,prop={'size':20})\n    plt.grid(axis='y')\n\n    for first,second in zip(bars[:half],bars[half:]):\n        height1 =  first.get_height()\n        height2 = second.get_height()\n        total_height= height1+height2\n        ax.text(first.get_x()+first.get_width()\/2, height1+1,'{0:.0%}'.format(height1\/total_height), ha ='center')\n        ax.text(second.get_x()+second.get_width()\/2, height2+1,'{0:.0%}'.format(height2\/total_height), ha ='center')","6f6441d0":"labeling = ['age','resting_blood_pressure','cholesterol','max_heart_rate_achieved','st_depression']\ngraph_title=['age','resting_blood_pressure','cholesterol','max_heart_rate_achieved','st_depression']\ny_labeling = ['age','mm\/hg','mg\/dl','heart_rate','inclination']\nplt.figure(figsize=(40,20))\nfor i in  range(len(labeling)):\n    plt.subplot(2,3,i+1)\n    sns.boxplot('target',labeling[i],data=numeric_ft_dt)\n    plt.title(graph_title[i],size=30)\n    plt.xlabel('target',size=20)\n    plt.ylabel(y_labeling[i],size=20, rotation=0,labelpad=53)\n    plt.xticks(fontsize=15)\n    plt.yticks(fontsize=15)","2162701d":"numeric_ft_dt.drop(['target'],axis=1).describe()","9e522c12":"eda_heart2=numeric_ft_dt.copy()\neda_heart2['interval_age']=pd.cut(eda_heart2.age,bins=[28,38,48,58,68,78])\neda_heart2['interval_resting_blood_pressure']=pd.cut(eda_heart2.resting_blood_pressure,bins=range(min(eda_heart2.resting_blood_pressure),max(eda_heart2.resting_blood_pressure)+20,20))\neda_heart2['interval_cholesterol']=pd.cut(eda_heart2.cholesterol,bins=range(min(eda_heart2.cholesterol),max(eda_heart2.cholesterol)+100,100))\neda_heart2['interval_max_heart_rate_achieved']=pd.cut(eda_heart2.max_heart_rate_achieved,bins=range(min(eda_heart2.max_heart_rate_achieved),max(eda_heart2.max_heart_rate_achieved)+20,20))\neda_heart2['interval_st_depression']=pd.cut(eda_heart2.st_depression,bins=[-0.1,1,2,3,4,5,6,7])","18926a4d":"eda_heart2['target_name']=eda_heart1['target']\nlabeling = ['interval_age','interval_resting_blood_pressure','interval_cholesterol','interval_max_heart_rate_achieved','interval_st_depression']\nfor i in range(len(labeling)):\n    f,ax = plt.subplots(figsize=(10,8))\n    sns.countplot(x=labeling[i],hue=\"target_name\",data=eda_heart2)\n    bars = ax.patches\n    half = int(len(ax.patches)\/2)\n    plt.title(graph_title[i],size=30)\n    plt.xlabel(labeling[i],size=20)\n    plt.ylabel('count',size=20, rotation=0,labelpad=30)\n    plt.xticks(fontsize=15)\n    plt.yticks(fontsize=15)\n    plt.legend(loc=1,prop={'size':20})\n    plt.grid(axis='y')\n\n    for first,second in zip(bars[:half],bars[half:]):\n        height1 =  first.get_height()\n        height2 = second.get_height()\n        total_height= height1+height2\n        ax.text(first.get_x()+first.get_width()\/2, height1+1,'{0:.0%}'.format(height1\/total_height), ha ='center')\n        ax.text(second.get_x()+second.get_width()\/2, height2+1,'{0:.0%}'.format(height2\/total_height), ha ='center')","416cea45":"# nan% check\nfor i in labeling:\n    for j in range(len(eda_heart2[i].unique())):\n        print(eda_heart2[i].unique()[j],round((len(eda_heart2[eda_heart2[i]==eda_heart2[i].unique()[j]]))\/303,4))","10b0a1c9":"numeric_ft_dt['target']==numeric_ft_dt.target.astype('object')\ndum=pd.get_dummies(numeric_ft_dt.target,prefix='target')\ncorr_numeric_dt=pd.concat([numeric_ft_dt,dum],axis=1).drop('target',axis=1)\ncorr_numeric_dt.head()","030e72d3":"plt.figure(figsize=(20,10))\nsns.heatmap(numeric_ft_dt.corr(),annot =True, cmap = 'Wistia')\nplt.title('Heatmap for the Dataset',fontsize=20)\nplt.show()","319cdc7b":"sns.pairplot(numeric_ft_dt, hue='target')\nplt.show()","f68cfe36":"association_dt=eda_heart1[['sex','chest_pain_type','fasting_blood_sugar','rest_ecg','exercise_induced_angina','st_slope','thalassemia','target']]\nassociation_dt.astype('category')","57508698":"sex_crosstab=pd.crosstab(association_dt['sex'],association_dt.target,margins=True)\nchest_pain_type_crosstab=pd.crosstab(association_dt['chest_pain_type'],association_dt.target,margins=True)\nfasting_blood_sugar_crosstab=pd.crosstab(association_dt['fasting_blood_sugar'],association_dt.target,margins=True)\nrest_ecg_crosstab=pd.crosstab(association_dt['rest_ecg'],association_dt.target,margins=True)\nexercise_induced_angina_crosstab=pd.crosstab(association_dt['exercise_induced_angina'],association_dt.target,margins=True)\nst_slope_crosstab=pd.crosstab(association_dt['st_slope'],association_dt.target,margins=True)\nthalassemia_crosstab=pd.crosstab(association_dt['thalassemia'],association_dt.target,margins=True)","d9a47b8e":"from scipy.stats import chisquare, chi2_contingency, fisher_exact\nstat, p, dof, expect=chi2_contingency(sex_crosstab.iloc[:-1,:-1])\nprint('test statistic : ',round(stat,4),'\\n',\n     'p_value : ',round(p,5),'\\n',\n     'freedom : ',dof,'\\n',\n     'Expected frequency : ',expect)\nsex_crosstab","0dfcf97f":"stat, p, dof, expect=chi2_contingency(chest_pain_type_crosstab.iloc[:-1,:-1])\nprint('test statistic : ',round(stat,4),'\\n',\n     'p_value : ',round(p,5),'\\n',\n     'freedom : ',dof,'\\n',\n     'Expected frequency : ',expect)\nchest_pain_type_crosstab","2960edf2":"stat, p, dof, expect=chi2_contingency(fasting_blood_sugar_crosstab.iloc[:-1,:-1])\nprint('test statistic : ',round(stat,4),'\\n',\n     'p_value : ',round(p,5),'\\n',\n     'freedom : ',dof,'\\n',\n     'Expected frequency : ',expect)\nfasting_blood_sugar_crosstab","7009be39":"stat, p, dof, expect=chi2_contingency(rest_ecg_crosstab.iloc[:-1,:-1])\nprint('test statistic : ',round(stat,4),'\\n',\n     'p_value : ',round(p,5),'\\n',\n     'freedom : ',dof,'\\n',\n     'Expected frequency : ',expect)\n\nrest_ecg_crosstab","6c5da8f5":"stat, p, dof, expect=chi2_contingency(exercise_induced_angina_crosstab.iloc[:-1,:-1])\nprint('test statistic : ',round(stat,4),'\\n',\n     'p_value : ',round(p,5),'\\n',\n     'freedom : ',dof,'\\n',\n     'Expected frequency : ',expect)\nexercise_induced_angina_crosstab","b40f0f60":"stat, p, dof, expect=chi2_contingency(st_slope_crosstab.iloc[:-1,:-1])\nprint('test statistic : ',round(stat,4),'\\n',\n     'p_value : ',round(p,5),'\\n',\n     'freedom : ',dof,'\\n',\n     'Expected frequency : ',expect)\nst_slope_crosstab","ee93c18b":"stat, p, dof, expect=chi2_contingency(thalassemia_crosstab.iloc[:-1,:-1])\nprint('test statistic : ',round(stat,4),'\\n',\n     'p_value : ',round(p,5),'\\n',\n     'freedom : ',dof,'\\n',\n     'Expected frequency : ',expect)\nthalassemia_crosstab","d54578ad":"train_data=eda_heart1.copy()","cb26aede":"for i in ['sex','chest_pain_type','fasting_blood_sugar','rest_ecg','exercise_induced_angina','st_slope','thalassemia']:\n    aa=pd.get_dummies(train_data[i])\n    train_data=pd.concat([train_data,aa],axis=1)\n    train_data=train_data.drop([i],axis=1)","f4ba2554":"train_data=pd.concat([train_data.drop(['target'],axis=1),dt['target']],axis=1)\ntrain_data['target']=train_data['target'].astype('category')","864087c3":"X = train_data.drop(['target'],axis=1)\ny = train_data['target']","0c27a21a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=True, stratify=y, random_state=123)","25e4b962":"clf = RandomForestClassifier(max_depth=5, random_state=0)\nclf.fit(X_train,y_train)","ce286307":"export_graphviz(clf.estimators_[0],feature_names=X_train.columns,filled=True, out_file='tree.dot')\n\n# \uc0dd\uc131\ub41c .dot \ud30c\uc77c\uc744 .png\ub85c \ubcc0\ud658\nfrom subprocess import call\ncall(['dot', '-Tpng', 'tree.dot', '-o', 'decistion-tree.png', '-Gdpi=600'])\n\n# jupyter notebook\uc5d0\uc11c .png \uc9c1\uc811 \ucd9c\ub825\nfrom IPython.display import Image\nImage(filename = 'decistion-tree.png')","ffacc33c":"y_pred=clf.predict(X_test)","c54428ea":"cm=confusion_matrix(y_test,y_pred)","33567440":"print('training accuracy : ', round(clf.score(X_train,y_train),2))\nprint('test accuracy : ',clf.score(X_test,y_test),'\\n')\nprint(classification_report(y_test,y_pred))\nsns.heatmap(cm,annot =True, annot_kws = {'size':15},cmap='PuBu')\nplt.title('confusion_matrix')\nplt.xticks([0.5,1.5],('< 50% dn predict','> 50% dn predict'))\nplt.yticks([0.5,1.5],('< 50% diameter narrowing','> 50% diameter narrowing'),rotation=0)","6e1bc382":"y_pred_quant = clf.predict_proba(X_test)[:,1]\n\nfpr,tpr,thresholds = roc_curve(y_test, y_pred_quant)\nfig, ax = plt.subplots()\nax.plot(fpr,tpr)\nax.plot([0,1],[0,1],transform=ax.transAxes, ls=\"-\",c='.3')\nplt.xlim([0.0,1.0])\nplt.ylim([0.0,1.0])\n\nplt.rcParams['figure.figsize'] = (6,5)\nplt.title('ROC curve for diabetes classifier',fontweight = 30)\nplt.xlabel('False Positive Rate (1- Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.grid()\nplt.show()\nauc = auc(fpr,tpr)\nprint('AUC Score :',round(auc,2))","9e32ad66":"# model accuracy\nclf.score(X_test,y_test)","6e814b64":"# Feature importance\nperm = PermutationImportance(clf,random_state=0).fit(X_test,y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist(),top=26)","df1159db":"train_data2=dt.copy()\nfor i in ['sex','chest_pain_type','fasting_blood_sugar','rest_ecg','exercise_induced_angina','st_slope','thalassemia']:\n    aa=pd.get_dummies(train_data2[i],prefix=i)\n    train_data2=pd.concat([train_data2,aa],axis=1)\n    train_data2=train_data2.drop([i],axis=1)\nX = train_data2.drop(['target'],axis=1)\ny = train_data2['target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=True, stratify=y, random_state=123)\nclf2 = RandomForestClassifier(max_depth=5, random_state=0)\nclf2.fit(X_train,y_train)","bed596d2":"clf2.score(X_test,y_test)","2c0d46dc":"base_features = train_data2.columns.values.tolist()\nbase_features.remove('target')\naa=['st_depression','num_major_vessels','age','resting_blood_pressure','cholesterol','max_heart_rate_achieved']\nfor i in range(len(aa)):\n    feat_name = aa[i]\n    pdp_dist = pdp.pdp_isolate(model=clf, dataset=X_test,\n                               model_features = base_features,\n                               feature = feat_name)\n\n    pdp.pdp_plot(pdp_dist, feat_name)\nplt.show()","df233654":"explainer = shap.TreeExplainer(clf)\nshap_values = explainer.shap_values(X_test)\n\nshap.summary_plot(shap_values[1],X_test, plot_type='bar')","3492baa2":"shap.summary_plot(shap_values[1], X_test)","acb8912e":"def patient_analysis(model, patient):\n  explainer = shap.TreeExplainer(model)\n  shap_values = explainer.shap_values(patient)\n  shap.initjs()\n  return shap.force_plot(explainer.expected_value[1], shap_values[1], patient)","b6f1c46b":"patients = X_test.iloc[1,:].astype(float)\npatient_analysis(clf, patients)","b294f5dd":"patients = X_test.iloc[5,:].astype(float)\npatient_analysis(clf, patients)","f71a15ee":"from sklearn.neighbors import KNeighborsClassifier\nneigh = KNeighborsClassifier()\nneigh.fit(X_train,y_train)\nneigh.score(X_test,y_test)","d1c2d460":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X_train,y_train)\ngnb.score(X_test,y_test)","06a4d2e3":"from sklearn.svm import LinearSVC\nlsvc = LinearSVC()\nlsvc.fit(X_train,y_train)\nlsvc.score(X_test,y_test)","2b44c3dd":"# Data preprocessing","19db53f8":"![graph1](https:\/\/datascienceschool.net\/upfiles\/831d9dfbdcee499c9e32f39831d757f2.png)\n![graph2](https:\/\/datascienceschool.net\/upfiles\/219c35d779eb4eb38be3fa0cc6b9ed38.png)","6721c2ab":"When That expected frequency < 5 is data proportion 1\/4, Using Fisher exact test. but sometimes similar. haha","33e59b20":"# Data shape","9f434a4e":"  ## How it work\n - Using bootstrap to extract samples(Trees)\n - Imlementation combines classifiers by averaging their probabilistic prediction, instead of\n   letting each classifier vote for a single class.  \n   \n## Why use it\n - Individual decision trees typically exhibit high variance and tend to overfit. so randomforest\n achieve a reduced variance by combining diverse trees. but sometimes at the cost of a sli-\n ght increase in bias. The variance reduction is often significant hence yielding an overall\n better model.  \n \n## When activating randomforest, what method using?\n - Gini index\n","08f5bcd0":"# Data EDA","0e490bd7":"### feature definition\n - age : 29~77                                                                  \n - sex : 0 = female, 1 = male                                                   \n - cp : chest pain type(category=0,1,2,3)                                       \n  -- Value 0: typical angina                                                 \n  -- Value 1: atypical angina                                                \n  -- Value 2: non-anginal pain                                               \n  -- Value 3: asymptomatic                                                   \n - trestbps : resting blood pressure(in mm Hg on admission to the hospital)     \n - chol : serum cholestoral in mg\/dl                                             \n - fbs : fasting blood sugar >120 mg\/dl (1=True, 0=False)                       \n - restecg : resting electrocardiographic result(category=0,1,2)  \n  -- Value 0: normal                                                         \n  -- Value 1: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV)   \n  -- Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria                       \n - thalach : maximum heart rate achieved                                        \n - exang : exercise induced angina (1=yes, 0=no)                                \n - oldpeak : ST depression induced by exercise relative to rest                 \n - slope : the slope of the peak exercise ST segment(category:0,1,2)  \n  -- Value 1: upsloping                                                      \n  -- Value 2: flat                                                           \n  -- Value 3: downsloping                                                    \n - ca : number of major vessels(0-3) colored by flourosopy                      \n - thal : A blood disorder called thalassemia                                   \n3 =normal, 6=fixed defect, 7= reversable defect  \n - target : yes=1 or no=0 diagnosis of heart disease (angiographic disease status)   \n  -- Value 0: < 50% diameter narrowing                                         \n  -- Value 1: > 50% diameter narrowing                                        ","3f7c50e7":"Import Packages","44a92b76":"# category feature's target value ratio","a3e6974e":"# numeric features correlation graph & scatter plot matrix checking","ace332c2":" similiary score","6f7dc052":"# Data Background Knowledge\n## [electrocardiographic normal]\n![image](https:\/\/w7.pngwing.com\/pngs\/160\/614\/png-transparent-qt-interval-long-qt-syndrome-pr-interval-t-wave-qrs-complex-electrocardiogram-angle-text-heart-thumbnail.png)","4a7d837b":"## Roc curve \n- The ROC curve is created by plotting the true positive rate(TPR) against the false positive rate(FPR) at various threshold setting.\n- x axis : False Positive Rate(1 \u2013 specificity), y axis : True Positive Rate(sensitivity) \n- ROC curve can be generated by plotting the cumulative distribution function","1ed613c3":"## [graph1]\nTo increase recall, you can lower the threshold to judge as positive so that even if there is only a little evidence, you can judge it as positive. But\nIn this case, even though it is negative, the sample data judged as positive increases as well, and the fallout increases at the same time. Conversely to lower the fallout\nIf the criterion for judging positive is strict, the number of sample data that has been judged negative due to lack of evidence increases as well, so\nAll.\n\n## [graph2]\nIt is a graph drawn along TPR and FPR with the threshold of graph1 starting at the right end and going to the left end. => Roc Curve","0eeaab2a":"### confusion matrix\n---\n\nThe classification result of the trained binary classification model can be summarized as the following 2x2 matrix, which is called a confusion matrix.\nIn this table, Actual Negative class and Actual Positive class represent the actual value of Target, and Predicted Negative class and Predicted Positive class represent the classification result of the classification model.\nHere, negative indicates positive or true positive or false.\nIn general, in the error matrix, the true value of target is shown in the row and the classification result is shown in the column.\n\n|  | **Predicted Negative class** | **Predicted Positive class** |\n|:---|:---|:---|\n|**Actual Negative class** | True Nagative(TN) | False Positive(FP) |\n|**Actual Positive class** | False Negative(FN) | True Positive(TP) |\n\nThe meanings of TN (True Nagative), FP (False Positive), FN (False Negative), and TP (True Positive) described in each cell of the error matrix are as follows.\n\n-True Positive (TP): The frequency of predicting the actual positive as a positive  \n-False Positive (FP): The frequency of predicting that the actual negative is positive (the frequency of making a type 1 error)  \n-False Negative (FN): The frequency of predicting that the actual positive is negative (the frequency of making a type 2 error)  \n-True Negative (TN): The frequency of predicting the actual negative value as negative","89795fcd":"# Features description\n### Stat description\n       1. age : interval scale, values = [29, 77] , dtypes = int\n       2. sex : nominal scale, values = 0,1\n       3. cp : nominal scale, values = 0,1,2,3\n       4. trestbps : interval scale, values = [94, 200] , dtypes = int\n       5. chol : interval scale, values = [126, 564] , dtypes = int\n       6. fbs : nominal scale, values = 0,1\n       7. restecg : nominal scale, values = 0,1,2\n       8. thalach : interval scale, value = [71, 202], dtypes = int\n       9. exang : nominal scale, value = 0,1\n      10. oldpeak : interval scale, value = [0, 6.2] dtypes = float\n      11. slope : nominal scale, value = 0,1,2\n      12. ca : nominal scale, value = 0,1,2,3\n      13. thal : nominal scale, value = 0,1,2,3\n      14. target : nominal scale, value = 0,1\n","4403fa9a":"## Graphing interval data","d9b20e3a":"Check the difference with other models (net standard)","60ff0d18":"## reference\n\n1. https:\/\/www.kaggle.com\/tentotheminus9\/what-causes-heart-disease-explaining-the-model\n\n2. https:\/\/www.kaggle.com\/roshansharma\/heart-diseases-analysis\n","42c699f9":"# Data description(from UCI)\n- data size : (303, 14), Number of instances : 303 , feature : 14\n- missing values : None \n- Data source url : archive.ics.uci.edu\/ml\/datasets\/heart + disease \n- This database contains 76 attributes, but all published experiments refer to using a subset\n  of 14 of them. In particular, the Cleveland database is the only one that has been used by\n  ML researchers to this date. The \"goal\" field refers to the presence of heart disease\n  in the patient. It is integer valued from 0 (no presence) to 4. Experiments with\n  the Cleveland database have concentrated on simply attempting to distinguish presence\n  (values 1,2,3,4) from absence (value 0). The names and social security numbers of the patients\n  were recently removed from the database, replaced with dummy values.","e0f22a10":"((sex, chest_pain_type, rest_ecg, exercise_induced_angina, st_slope, thalassemia), target) have association (p-value : 0.05)","4867a43e":"### Box plot","766b78e4":"Classification model performance evaluation scale  \n\n## 1.Accuracy\n\n  - A measure of the degree to which it is properly classified, and is the relative frequency of properly classified data.\n  - Accuracy is an intuitive evaluation measure that indicates the performance of the model, but it is a measure that needs to be supplemented for unbalanced data. \n  \n## 2.Precision\n\n  - It is called precision or positive predictive value (PPV, positive predictive value).\n  - It is the percentage of what is actually predicted as positive.\n  - Precision is an appropriate measure of evaluation when it is desirable to reduce false positives. \n\n## 3. Recall (recall rate)\n  - Also known as sensitivity, hit rate, and true positive rate (TPR).\n  - It is the ratio of the data actually positive in the data classified as positive.\n  - Recall rate is an appropriate evaluation measure when it is desirable to reduce False Negatives.\n  - Reproducibility and precision have a negative correlation.\n\n## 4. F1 score\n  - It is calculated as the harmonic average of precision and recall.\n  - Since precision and recall are considered together, unbalanced data is considered a more rational measure than accuracy.\n\n## 5. Fall-out (false positive rate)\n  - The proportion of positive among samples that do not belong to actual positive (the smaller the value, the better)","c3cafaab":"## AUC (Area Under the Curve)\n - When the fallout is the same, the recall is large or the recall is the same, the smaller the fallout, the closer the AUC is to 1, which is a good model.","ca807a08":"# Test for independece(chi-squared test)","75bce36f":"From this data, it was confirmed that there are two thalassemia's unknown.  \nUnknown target ratio = 1:1.  \nso these outliers subtract from the data.\n","49ad6bb3":"The code below was created by referring to other notebooks. I will leave the source. If you need an explanation about it, you can check it there.","22450b24":"Thank you for reading my notebook","bf3ea8af":"# Interval estimation","217b349d":"## feature(slope and restecg)  \n### slope : S point ~ T point's inclination\n### restecg : This is the result of making a judgment by looking at the graph.","3d87ef2f":"## Graphing nominal data","75498fba":"### Box Explain  \nClassification Criteria ; G.I. , samples: number of samples, value: number of data, calss: more than target values names  \nAlthough samples = sum(value), the value tends to be different because the bootstrap sample is currently being used. The reason is to use it to prevent learning of the same training set. In other words, when bootstrap is used, samples are extracted by the restoration extraction method and have randomness, and various DecisionTrees can be created. DecisionTrees (estimators=100) are classified and averaged to prevent overfitting of DecisionTrees, reducing variance.  \n\n\u203b If you set the features to be used, you can calculate more various DecisionTree types.","05f2e7be":"# Traing, Test data accuracy & Confusion Matrix(Heat map) & ROC curve","cc3ec9a4":"# Model\n\n## using randomforestclassifier","cbbe6e4a":"I use data type float and dummies","da1a3870":"Positive correlation : max_heart_rate_achieved because blood vessels are narrowed and blood does not flow well, the heart beats a lot."}}