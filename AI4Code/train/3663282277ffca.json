{"cell_type":{"e6bb49bb":"code","fdd43eb3":"code","fc855cee":"code","cac6263a":"code","2cfca53a":"code","a324afa9":"code","add2fc59":"code","55a8f91e":"code","a3daa7b7":"code","2d238ae4":"code","cc571fe7":"code","15c08b5d":"code","6ce17777":"code","90984433":"code","78c79c42":"code","3be615d3":"code","f41db70d":"code","a87a4ec4":"code","f36eb364":"code","8c137111":"code","c45cd235":"code","a9505383":"code","969a7c2c":"code","5a171a34":"markdown","f7651b6a":"markdown","8ec0d236":"markdown","d011106a":"markdown","d5720a41":"markdown","3fa83590":"markdown","c4cb1f97":"markdown","130607b1":"markdown","9c0b3f58":"markdown","13b90563":"markdown","3df4e271":"markdown","88d63c62":"markdown","038c6ddc":"markdown","c06db912":"markdown","4e57c994":"markdown","f9764ac4":"markdown"},"source":{"e6bb49bb":"%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom torch import nn\nfrom collections import OrderedDict\nfrom IPython.display import clear_output\nfrom sklearn.metrics import confusion_matrix\nimport torchvision.transforms as transforms\nimport numpy as np\nimport seaborn as sns\nimport torchvision.models \nimport albumentations \nimport torch\nimport os","fdd43eb3":"!pip install -q split-folders\n!splitfolders --output \/kaggle\/tmp\/flowers_dataset --ratio .5 .2 .3 -- ..\/input\/flowers-recognition\/flowers\n!rm -r \/kaggle\/tmp\/flowers_dataset\/train\/flowers \/kaggle\/tmp\/flowers_dataset\/val\/flowers \/kaggle\/tmp\/flowers_dataset\/test\/flowers ","fc855cee":"class AlbumentationTransforms:\n    def __init__(self, transforms):\n        self.transforms = transforms\n\n    def __call__(self, x):\n        x = np.array(x)\n        return self.transforms(image=x)[\"image\"]\n\ndataset_root = \"\/kaggle\/tmp\/flowers_dataset\"\n\nagumentations = albumentations.Compose([\n    albumentations.Downscale(scale_min=0.6, scale_max=0.99, p=0.2),\n    albumentations.HorizontalFlip(p=0.5),\n    albumentations.VerticalFlip(p=0.1),\n    albumentations.RandomFog(fog_coef_lower=0.1,\n                             fog_coef_upper=0.5, alpha_coef=0.05, p=0.5),\n    albumentations.RandomBrightnessContrast(),\n    albumentations.RandomGamma(gamma_limit=(50, 150), p=0.4),\n    albumentations.OpticalDistortion(p=0.2),\n    albumentations.Blur(blur_limit=2, p=0.2)\n])\n\ntrain_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    AlbumentationTransforms(agumentations),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n                         std=(0.229, 0.224, 0.225))\n])\n\ntest_val_transforms = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize((224, 224)),\n    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n                         std=(0.229, 0.224, 0.225))\n])\n\ntrain_dataset = ImageFolder(os.path.join(dataset_root, \"train\"),\n                            transform=train_transforms)\nval_dataset = ImageFolder(os.path.join(dataset_root, \"val\"),\n                          transform=test_val_transforms)\ntest_dataset = ImageFolder(os.path.join(dataset_root, \"test\"),\n                          transform=test_val_transforms)","cac6263a":"def image_to_numpy(image):\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    unnormalize = transforms.Normalize((-mean \/ std), (1.0 \/ std))\n    image = unnormalize(image).numpy()\n    return np.transpose(image, (1, 2, 0))\n    \nldr = DataLoader(train_dataset, batch_size=10, shuffle=True)","2cfca53a":"x, y = next(iter(ldr))\nfig, axs = plt.subplots(nrows=3, ncols=3, figsize=(6, 6),\n                       subplot_kw={\"xticks\": [], \"yticks\": []})\n\nfig.suptitle(\"Training dataset\")\nfor i, ax in enumerate(axs.flat):\n    ax.set_title(train_dataset.classes[y[i]])\n    ax.imshow(image_to_numpy(x[i]))","a324afa9":"ldr = DataLoader(train_dataset, batch_size=len(train_dataset))\n_, y = next(iter(ldr))\nplt.title(\"Histogram of labels in all datasets\")\nplt.hist(y.numpy(), bins=len(train_dataset.classes), rwidth=0.5)\n_ = plt.xticks(range(len(train_dataset.classes)), train_dataset.classes)","add2fc59":"base_model = torchvision.models.densenet201(pretrained=True)\nbase_model.classifier = nn.Identity()\n\nfor param in base_model.parameters():\n    param.requires_grad = False\n\nmodel = nn.Sequential(OrderedDict([\n    (\"base_model\", base_model),\n    (\"classifier\", nn.Sequential(nn.Dropout(p=0.5), nn.Linear(1920, 5)))\n]))\n\nmodel.base_model = model.base_model.eval()","55a8f91e":"def accuracy(preds, labels):\n    cmp = preds == labels\n    return float(cmp.sum())\/len(labels)\n\ndef train_epoch(model, loader, optimizer, criterion, device):\n    model.classifier.train()\n    losses = []\n    labels = np.array([])\n    preds = np.array([])\n\n    for x, y in loader:\n        labels = np.append(labels, y.detach().numpy())\n        x = x.to(device)\n        y = y.to(device)\n\n        y_hat = model(x)\n        loss = criterion(y_hat, y)\n        loss.backward()\n        optimizer.step()\n\n        with torch.no_grad():\n            y_hat = y_hat.argmax(axis=1)\n            y_hat = y_hat.cpu().numpy()\n            preds = np.append(preds, y_hat)\n            losses.append(loss.cpu())\n\n    return np.average(losses), accuracy(preds, labels)\n\ndef evaluate(model, loader, criterion, device):\n    model.classifier.eval()\n    losses = []\n    labels = np.array([])\n    preds = np.array([])\n\n    for x, y in loader:\n        with torch.no_grad():\n            labels = np.append(labels, y.detach().numpy())\n            x = x.to(device)\n            y = y.to(device)\n\n            y_hat = model(x)\n            loss = criterion(y_hat, y)\n            losses.append(loss.cpu())\n\n            y_hat = y_hat.argmax(axis=1)\n            y_hat = y_hat.cpu().numpy()\n            preds = np.append(preds, y_hat)\n\n    return np.average(losses), accuracy(preds, labels), preds, labels","a3daa7b7":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nbatch_size = 256\nepochs = 20","2d238ae4":"val_loader = DataLoader(val_dataset, num_workers=6, batch_size=batch_size, shuffle=False)\ntrain_loader = DataLoader(train_dataset, num_workers=6, batch_size=batch_size, shuffle=True)\n\ncriterion = nn.CrossEntropyLoss()\nmodel = model.to(device)\noptimizer = torch.optim.RMSprop(model.parameters(), lr=0.0005)","cc571fe7":"train_loss_history = []\ntrain_acc_history = []\nval_loss_history = []\nval_acc_history = []\n\nfor epoch in range(epochs):\n    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n    val_loss, val_acc, _,_ = evaluate(model, val_loader, criterion, device)\n    train_loss_history.append(train_loss)\n    train_acc_history.append(train_acc)\n    val_loss_history.append(val_loss)\n    val_acc_history.append(val_acc)\n    print(f\"epoch {epoch+1}\/{epochs}: loss: {train_loss}, val_loss: {val_loss}, acc: {train_acc}, val_acc: {val_acc}\")\n    \nclear_output()","15c08b5d":"plt.title(\"Loss\")\nplt.plot(train_loss_history, label=\"train\")\nplt.plot(val_loss_history, label=\"val\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.legend()","6ce17777":"plt.title(\"Accuracy\")\nplt.plot(train_acc_history, label=\"train\")\nplt.plot(val_acc_history, label=\"val\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"accuracy\")\nplt.legend()","90984433":"model.classifier.eval()\n\nfor param in model.classifier.parameters():\n    param.requires_grad = False\n\nfor param in model.base_model.features.denseblock4.parameters():\n    param.requires_grad = True","78c79c42":"optimizer = torch.optim.SGD(model.parameters(), lr=0.00005)\nepochs = 20","3be615d3":"train_loss_history = []\ntrain_acc_history = []\nval_loss_history = []\nval_acc_history = []\n\nfor epoch in range(epochs):\n    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n    val_loss, val_acc, _, _ = evaluate(model, val_loader, criterion, device)\n    train_loss_history.append(train_loss)\n    train_acc_history.append(train_acc)\n    val_loss_history.append(val_loss)\n    val_acc_history.append(val_acc)\n    print(f\"epoch {epoch+1}\/{epochs}: loss: {train_loss}, val_loss: {val_loss}, acc: {train_acc}, val_acc: {val_acc}\")\n    \nclear_output()","f41db70d":"plt.title(\"Loss\")\nplt.plot(train_loss_history, label=\"train\")\nplt.plot(val_loss_history, label=\"val\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"loss\")\nplt.legend()","a87a4ec4":"plt.title(\"Accuracy\")\nplt.plot(train_acc_history, label=\"train\")\nplt.plot(val_acc_history, label=\"val\")\nplt.xlabel(\"epoch\")\nplt.ylabel(\"accuracy\")\nplt.legend()","f36eb364":"model.eval()\ntest_loader = DataLoader(test_dataset, num_workers=6, batch_size=256, shuffle=False)\ntest_loss, test_acc, preds, labels = evaluate(model, test_loader, criterion, device)","8c137111":"test_loss","c45cd235":"test_acc","a9505383":"def plot_confusion_matrix(preds, labels, annotations, round_to=2):\n    mat = confusion_matrix(labels, preds)\n    mat =  mat.astype(\"float\") \/ mat.sum(axis=1)[:, np.newaxis]\n    mat = np.round(mat, round_to)\n\n    sns.heatmap(mat, annot=True, xticklabels=annotations,\n            yticklabels=annotations)","969a7c2c":"plot_confusion_matrix(preds, labels, test_dataset.classes)","5a171a34":"## Dataset\n\nIn this project we will use dataset which contains 4242 images of flowers from 5 different classes:\n\n- chamomile \n- tulip\n- rose\n- sunflower\n- dandelion\n\nFirst let's split dataset into training dataset (50%), validation dataset (20%) an test dataset (30%).\nWe will do this using a tool callled split-folders.","f7651b6a":"As we can see we gain around ~2% of accuracy by performing fine tuning.","8ec0d236":"## Evaluation\n\nNow let's evaluate performance of the model on a test set.","d011106a":"As we can see the classifier has quite decent accuracy.\n\nAlso we can see the the best classification accuracy corresponds to the classes that had the most samples.","d5720a41":"Now let's create datasets and define agumentations that will be used for training dataset.","3fa83590":"Dataset is reasonably well balanced so let's proceed to training.","c4cb1f97":"We get ~91% of accuracy from transfer learning. Now let's see whether we can improve our model further by fine tuning the base model.","130607b1":"## Model\n\nBecause this dataset is relatively small we will use transfer learning and fine tunning to obtain better results compared to direct training.\nDuring my experiments I determined that from pretrained models in torchvision.models, the best base model for this particular task seem to be \ndensenet-201.\n\nWe will prepare the pretrained model by:\n\n- Replacing classification layer with a multilayer perceptron\n- Disabling gradient computation for base model.\n- Setting base model to the inference mode (so batch normalization will not be updated).\n\nWe will also add dropout to the linear layer because model is overfitting despite agumentation.","9c0b3f58":"From experiments I determined that RMSprop seem to be the best suited for this task. We will set very low learning rate as model has a tendency to be unstable during training.","13b90563":"Optimizer for this model will be ","3df4e271":"## Transfer learning\n\nNow we will train linear classification layer.","88d63c62":"Now let's visualize agumented data and make histogram of classes.","038c6ddc":"## Fine tuning\n\nNow let's unlock dense block 4 and fine tune it. For this step classifier layer will be locked and set to inference mode.","c06db912":"# Flower classifier using DenseNet and transfer learning\n\nThe goal of this project is to create a flower classifier by performing transfer learning and then fine tuning pretrained DenseNet model.","4e57c994":"Now let's plot histogram of samples to make sure that dataset is reasonably well balanced.\nDue to way datasets were sampled, distribution is the same in all sets so we will plot it only from training dataset.","f9764ac4":"## Imports"}}