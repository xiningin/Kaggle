{"cell_type":{"f7b2c5a5":"code","66d10bc9":"code","d4559844":"code","7dc7622d":"code","bc7f11f3":"code","1808be4a":"code","ed870042":"markdown"},"source":{"f7b2c5a5":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os\n\n# Importing Deep Learning Libraries to build cnn model\n\nfrom keras.preprocessing.image import load_img, img_to_array # Load the images and Convert images into array ,\n#to be faded to the model easily as model will not take the image, It will take the array from the image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D # Layers are required to build cnn model\nfrom keras.models import Model,Sequential\nfrom keras.optimizers import Adam,SGD,RMSprop","66d10bc9":"picture_size = 48 #Images will be standarized to be the same standard size\nfolder_path = \"..\/input\/face-expression-recognition-dataset\/images\/\"","d4559844":"expression = 'happy'\n\nplt.figure(figsize= (12,12))\nfor i in range(1, 10, 1):\n    plt.subplot(3,3,i)\n    img = load_img(folder_path+\"train\/\"+expression+\"\/\"+\n                  os.listdir(folder_path + \"train\/\" + expression)[i], target_size=(picture_size, picture_size))\n    plt.imshow(img)   \nplt.show()","7dc7622d":"batch_size  = 128\n\ndatagen_train  = ImageDataGenerator()# To contain the data which is coming from the directory\ndatagen_val = ImageDataGenerator()\n\ntrain_set = datagen_train.flow_from_directory(folder_path+\"train\", # It should go inside the training folder and  it should take all the images from it and give it to the trai_set\n                                              target_size = (picture_size,picture_size),\n                                              color_mode = \"grayscale\",\n                                              batch_size=batch_size,\n                                              class_mode='categorical',\n                                              shuffle=True)\n\n\ntest_set = datagen_val.flow_from_directory(folder_path+\"validation\",\n                                              target_size = (picture_size,picture_size),\n                                              color_mode = \"grayscale\",\n                                              batch_size=batch_size,\n                                              class_mode='categorical',\n                                              shuffle=False)","bc7f11f3":"# That is to build the artifitial neural network, to detect different different emotions.\nfrom keras.optimizers import Adam,SGD,RMSprop\n\n\nno_of_classes = 7 # Because they are seven possible outcomes\n# NOTE\n# ANN have different layers that are below \n# These all layers combined will make tha ANN or Deep Neural Network\nmodel = Sequential()\n\n#1st CNN layer\nmodel.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1))) # You do not need to define input_shape in each CNN layer\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25)) # It has been defined to prevent the model to get overfitted\n\n#2nd CNN layer\nmodel.add(Conv2D(128,(5,5),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout (0.25))\n\n#3rd CNN layer\nmodel.add(Conv2D(512,(3,3),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout (0.25))\n\n#4th CNN layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\n#Fully connected 1st layer\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n\n# Fully connected layer 2nd layer\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(no_of_classes, activation='softmax'))\n\n\n\nopt = Adam(lr = 0.0001)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy']) # categorical_crossentropy : Because they are different categories.\nmodel.summary()","1808be4a":"# Fit the model with the training and validation data\nfrom keras.optimizers import RMSprop,SGD,Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau # Reduce learning rate on pattern\n\ncheckpoint = ModelCheckpoint(\".\/model.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n# early_stopping : So if i am getting the best model and validation,  and the accuracy is not increasing then it  is going to the early_stopping\n# SO THAT : it should not overfit the model.\n\n# If the model accuracy is not increasing then -> Contiuing with the number of epohs is a time wasting ,,, So that is the need for [early_stopping]\nearly_stopping = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=3,\n                          verbose=1,\n                          restore_best_weights=True\n                          )\n\nreduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=3,\n                              verbose=1,\n                              min_delta=0.0001)\n\ncallbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n\nepochs = 48\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer = Adam(lr=0.001),\n              metrics=['accuracy'])\nhistory = model.fit_generator(generator=train_set,\n                                steps_per_epoch=train_set.n\/\/train_set.batch_size,\n                                epochs=epochs,\n                                validation_data = test_set,\n                                validation_steps = test_set.n\/\/test_set.batch_size,\n                                callbacks=callbacks_list\n                                )","ed870042":"# Fitting the Model with Training and Validation Data."}}