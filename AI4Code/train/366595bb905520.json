{"cell_type":{"5e8aadf6":"code","95992b2a":"code","77d53a3e":"code","35474e41":"code","e926fefd":"code","44b08156":"code","6b270fbe":"code","5cb65c2f":"code","b74fc62d":"code","3c48fa61":"code","4c707e8d":"code","0da72722":"code","2a297edc":"code","8b138855":"code","58abec45":"code","13b2f5c0":"code","039abb80":"code","66405604":"code","03e51ccf":"code","b087c19b":"markdown","f6bd2bde":"markdown","b720dcec":"markdown","c9ade77a":"markdown","97066cc1":"markdown","851045ee":"markdown","2e5c0a5f":"markdown","f1e38edb":"markdown","d2577beb":"markdown","024d1afe":"markdown","529a6904":"markdown"},"source":{"5e8aadf6":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\nimport pandas as pd\nimport time\nimport glob\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport os\nimport PIL\nimport cv2\nimport shutil\nfrom sklearn.metrics import confusion_matrix, classification_report","95992b2a":"train_df = pd.read_csv('..\/input\/covidx-cxr2\/train.txt', sep=\" \", header=None)\ntrain_df.columns=['patient id', 'file_paths', 'labels', 'data source']\ntrain_df=train_df.drop(['patient id', 'data source'], axis=1 )","77d53a3e":"train_df.head()","35474e41":"test_df = pd.read_csv('..\/input\/covidx-cxr2\/test.txt', sep=\" \", header=None)\ntest_df.columns=['id', 'file_paths', 'labels', 'data source' ]\ntest_df=test_df.drop(['id', 'data source'], axis=1 )","e926fefd":"test_df.head()","44b08156":"train_path = '..\/input\/covidx-cxr2\/train\/'\ntest_path = '..\/input\/covidx-cxr2\/test\/'","6b270fbe":"train_df['labels'].value_counts()","5cb65c2f":"file_count = 2158\nsamples = []\nfor category in train_df['labels'].unique():    \n    category_slice = train_df.query(\"labels == @category\")    \n    samples.append(category_slice.sample(file_count, replace=False,random_state=1))\ntrain_df = pd.concat(samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)\nprint ( train_df['labels'].value_counts())\nprint (len(train_df))","b74fc62d":"train_df, valid_df = train_test_split(train_df, train_size=0.9, random_state=0)","3c48fa61":"print(train_df.labels.value_counts())\nprint(valid_df.labels.value_counts())\nprint(test_df.labels.value_counts())","4c707e8d":"target_size=(224,224)\nbatch_size=64","0da72722":"train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input, horizontal_flip=True, zoom_range=0.1)\ntest_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input)\ntrain_gen = train_datagen.flow_from_dataframe(train_df, directory=train_path, x_col='file_paths', y_col='labels', target_size=target_size, batch_size=batch_size, color_mode='rgb', class_mode='binary')\nvalid_gen = test_datagen.flow_from_dataframe(valid_df, directory=train_path, x_col='file_paths', y_col='labels', target_size=target_size, batch_size=batch_size, color_mode='rgb', class_mode='binary')\ntest_gen = test_datagen.flow_from_dataframe(test_df, directory=test_path, x_col='file_paths', y_col='labels', target_size=target_size, batch_size=batch_size, color_mode='rgb', class_mode='binary')","2a297edc":"base_model = tf.keras.applications.ResNet50V2(include_top=False, input_shape=(224,224,3))","8b138855":"model = tf.keras.Sequential([\n    base_model, \n    tf.keras.layers.GlobalAveragePooling2D(), \n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.BatchNormalization(), \n    tf.keras.layers.Dropout(0.2), \n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","58abec45":"lr=0.001\nmodel.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr), metrics=['accuracy'])","13b2f5c0":"patience = 1\nstop_patience = 3\nfactor = 0.5\n\ncallbacks = [\n    tf.keras.callbacks.ModelCheckpoint(\"classify_model.h5\", save_best_only=True, verbose = 0),\n    tf.keras.callbacks.EarlyStopping(patience=stop_patience, monitor='val_loss', verbose=1),\n    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=factor, patience=patience, verbose=1)\n]","039abb80":"epochs = 30\nhistory = model.fit(train_gen, validation_data=valid_gen, epochs=epochs, callbacks=callbacks, verbose=1)","66405604":"plt.plot(history.history['loss'], label='Loss (training data)')\nplt.plot(history.history['val_loss'], label='Loss (validation data)')\nplt.title('Loss for Training')\nplt.ylabel('Loss')\nplt.xlabel('No. epoch')\nplt.legend(['train', 'validation'], loc=\"upper left\")\nplt.show()\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","03e51ccf":"best_model = model\nbest_model.load_weights('.\/classify_model.h5')\nbest_model.evaluate(test_gen)","b087c19b":"# **Splitting Train Df into Train and Valid**","f6bd2bde":"# **Model Training**","b720dcec":"Dataset is severely unbalanced. We will balance the number of positive and negative cases.  ","c9ade77a":"# **Predictions on Test Set**","97066cc1":"# **Balancing Classes**","851045ee":"# **Create Model**","2e5c0a5f":"# **Callbacks**","f1e38edb":"# **Image Data Generators**","d2577beb":"# **Import Relevant Libraries**","024d1afe":"# **Creating Train and Test Dataframes**","529a6904":"Split train_df into train and valid df. "}}