{"cell_type":{"40a01f86":"code","227b7a04":"code","e81f2509":"code","e266e010":"code","608bc181":"code","f221f216":"code","d56f8bbf":"code","050a0427":"code","c4189c9b":"code","5f5eda73":"code","3dc0eee5":"code","4c29377a":"code","ed19253f":"code","e6fb26f9":"code","6669f129":"code","6270e134":"code","c27c94ad":"code","0c17467f":"code","3a7113a4":"code","744128af":"code","9a460a21":"code","929509bd":"code","81f3e7e2":"code","f4f403d2":"code","ea9f1463":"code","6de5af53":"code","deb71a73":"code","a6a989ae":"code","bdc5b697":"code","7187a17f":"code","bba807b7":"code","d988b11b":"markdown","4d37753d":"markdown","d061efdc":"markdown"},"source":{"40a01f86":"!conda install '\/kaggle\/input\/pydicom-conda-helper\/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","227b7a04":"!pip install ..\/input\/segmentation-model-pt\/segmentation_models_pytorch-0.2.0-py3-none-any.whl --no-index --no-deps","e81f2509":"!pip install ..\/input\/segmentation-model-pt\/pretrainedmodels-0.7.4\/pretrainedmodels-0.7.4","e266e010":"!pip install ..\/input\/segmentation-model-pt\/efficientnet_pytorch-0.6.3\/efficientnet_pytorch-0.6.3\/","608bc181":"!pip install ..\/input\/timm-pytorch-image-models\/pytorch-image-models-master\/","f221f216":"import timm","d56f8bbf":"import os\n\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nimport torch\nfrom torch import nn\nimport cv2\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2","050a0427":"DIM = (512,512,3)\nBATCH_SIZE = 4\n\nCANDIDATES = [\n    {\n        'model_path':'..\/input\/siimstudyclfmodels\/v303\/v303\/Fold0_effb7_unetplusplus_v303_dungnb_use_2stage_pretrain_ValidLoss0.733_ValidAcc0.000_ValidAUC0.796_ValidmAP0.366_Ep11.pth'\n    },\n    {\n        'model_path':'..\/input\/siimstudyclfmodels\/v303\/v303\/Fold1_effb7_unetplusplus_v303_dungnb_use_2stage_pretrain_ValidLoss0.722_ValidAcc0.000_ValidAUC0.799_ValidmAP0.362_Ep03.pth'\n    },\n    {\n        'model_path':'..\/input\/siimstudyclfmodels\/v303\/v303\/Fold2_effb7_unetplusplus_v303_dungnb_use_2stage_pretrain_ValidLoss0.695_ValidAcc0.000_ValidAUC0.825_ValidmAP0.382_Ep16.pth'\n    },\n    {\n        'model_path':'..\/input\/siimstudyclfmodels\/v303\/v303\/Fold3_effb7_unetplusplus_v303_dungnb_use_2stage_pretrain_ValidLoss0.687_ValidAcc0.000_ValidAUC0.821_ValidmAP0.380_Ep18.pth'\n    },\n    {\n        'model_path':'..\/input\/siimstudyclfmodels\/v303\/v303\/Fold4_effb7_unetplusplus_v303_dungnb_use_2stage_pretrain_ValidLoss0.718_ValidAcc0.000_ValidAUC0.822_ValidmAP0.401_Ep10.pth'\n    },\n    \n]\n","c4189c9b":"df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\nfast_sub = False\n\n# if df.shape[0] == 2477:\n#     fast_sub = True\n#     fast_df = pd.DataFrame(([['00086460a852_study', 'negative 1 0 0 1 1'], \n#                          ['000c9c05fd14_study', 'negative 1 0 0 1 1'], \n#                          ['65761e66de9f_image', 'none 1 0 0 1 1'], \n#                          ['51759b5579bc_image', 'none 1 0 0 1 1']]), \n#                        columns=['id', 'PredictionString'])\n# else:\n#     fast_sub = False\n","5f5eda73":"import numpy as np\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data","3dc0eee5":"def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https:\/\/www.kaggle.com\/xhlulu\/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im","4c29377a":"split = 'test'\nsave_dir = f'\/kaggle\/tmp\/{split}\/'\n\nos.makedirs(save_dir, exist_ok=True)\n\nsave_dir = f'\/kaggle\/tmp\/{split}\/study\/'\nos.makedirs(save_dir, exist_ok=True)\nif fast_sub:\n    xray = read_xray('..\/input\/siim-covid19-detection\/train\/00086460a852\/9e8302230c91\/65761e66de9f.dcm')\n    im = resize(xray, size=600)  \n    study = '00086460a852' + '_study.png'\n    im.save(os.path.join(save_dir, study))\n    xray = read_xray('..\/input\/siim-covid19-detection\/train\/000c9c05fd14\/e555410bd2cd\/51759b5579bc.dcm')\n    im = resize(xray, size=600)  \n    study = '000c9c05fd14' + '_study.png'\n    im.save(os.path.join(save_dir, study))\nelse:   \n    for dirname, _, filenames in tqdm(os.walk(f'..\/input\/siim-covid19-detection\/{split}')):\n        for file in filenames:\n            # set keep_ratio=True to have original aspect ratio\n            xray = read_xray(os.path.join(dirname, file))\n            im = resize(xray, size=600)  \n            study = dirname.split('\/')[-2] + '_study.png'\n            im.save(os.path.join(save_dir, study))\n","ed19253f":"import numpy as np \nimport pandas as pd\nif fast_sub:\n    df = fast_df.copy()\nelse:\n    df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\nid_laststr_list  = []\nfor i in range(df.shape[0]):\n    id_laststr_list.append(df.loc[i,'id'][-1])\ndf['id_last_str'] = id_laststr_list\n\nstudy_len = df[df['id_last_str'] == 'y'].shape[0]","e6fb26f9":"df['id_last_str']","6669f129":"study_len","6270e134":"# IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600, 512)\n\n#load_dir = f\"\/kaggle\/input\/{COMPETITION_NAME}\/\"\nif fast_sub:\n    sub_df = fast_df.copy()\nelse:\n    sub_df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\nsub_df = sub_df[:study_len]\ntest_paths = f'\/kaggle\/tmp\/{split}\/study\/' + sub_df['id'] +'.png'\n\nsub_df['negative'] = 0\nsub_df['typical'] = 0\nsub_df['indeterminate'] = 0\nsub_df['atypical'] = 0\n\n\nlabel_cols = sub_df.columns[2:]\n\nsub_df['test_path'] = test_paths","c27c94ad":"from typing import Optional, List\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.cuda.amp import autocast\n\nfrom segmentation_models_pytorch.encoders import get_encoder\nfrom segmentation_models_pytorch.unet.decoder import UnetDecoder\nfrom segmentation_models_pytorch.unetplusplus.decoder import UnetPlusPlusDecoder\nfrom segmentation_models_pytorch.deeplabv3.decoder import DeepLabV3PlusDecoder\nfrom segmentation_models_pytorch.fpn.decoder import FPNDecoder\nfrom segmentation_models_pytorch.linknet.decoder import LinknetDecoder\nfrom segmentation_models_pytorch.base import SegmentationHead\nfrom segmentation_models_pytorch.base import initialization as init\n\nclass PretrainModel(nn.Module):\n    def __init__(\n        self,\n        encoder_name: str = \"timm-efficientnet-b7\",\n        encoder_weights: Optional[str] = None,\n        classes: int = 4,\n        in_features: int = 2560, \n        pretrained_path=None, \n        pretrained_num_classes=None,\n    ):\n        super(PretrainModel, self).__init__()\n        self.in_features = in_features\n        if pretrained_path is None:\n            self.encoder = get_encoder(\n                encoder_name,\n                in_channels=3,\n                depth=5,\n                weights=encoder_weights,\n            )\n            if 'timm-efficientnet' in encoder_name:\n                self.hidden_layer = nn.Sequential(*list(self.encoder.children())[-4:])\n                del self.encoder.global_pool\n                del self.encoder.act2\n                del self.encoder.bn2\n                del self.encoder.conv_head\n            elif 'timm-seresnet' in encoder_name or 'timm-resnet' in encoder_name:\n                self.hidden_layer = nn.AdaptiveAvgPool2d(output_size=1)\n        else:\n            print('Load pretrain: {}'.format(pretrained_path))\n            model = PretrainModel(\n                encoder_name=encoder_name,\n                encoder_weights=encoder_weights,\n                classes=pretrained_num_classes,\n                in_features=in_features, \n                pretrained_path=None, \n                pretrained_num_classes=None)\n            model.load_state_dict(torch.load(pretrained_path, map_location='cpu'))\n            self.encoder = model.encoder\n            self.hidden_layer = model.hidden_layer\n            del model\n\n        self.fc = nn.Linear(in_features, 1024, bias=True)\n        self.cls_head = nn.Linear(1024, classes, bias=True)\n\n        init.initialize_head(self.fc)\n        init.initialize_head(self.cls_head)\n\n    @autocast(enabled=True)\n    def forward(self, x):\n        x = self.encoder(x)[-1]\n        x = self.hidden_layer(x)\n        x = x.view(-1, self.in_features)\n        x = self.fc(x)\n        x = F.relu(x)\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = self.cls_head(x)\n        return x\n\nclass SiimCovidAuxModel(nn.Module):\n    def __init__(\n        self,\n        encoder_name: str = \"timm-efficientnet-b7\",\n        encoder_weights: Optional[str] = None,\n        decoder_use_batchnorm: bool = True,\n        decoder_channels: List[int] = (256, 128, 64, 32, 16),\n        decoder_attention_type: Optional[str] = None,\n        decoder: Optional[str] = 'unet',\n        classes: int = 4,\n        in_features: int = 2560,\n        encoder_pretrained_path=None, \n        encoder_pretrained_num_classes=None,\n        model_pretrained_path=None, \n        model_pretrained_num_classes=None,\n        test_mode=False,\n    ):\n        super(SiimCovidAuxModel, self).__init__()\n        self.in_features = in_features\n        self.test_mode = test_mode\n\n        if model_pretrained_path is None:\n            if encoder_pretrained_path is None:\n                model = PretrainModel(\n                            encoder_name=encoder_name,\n                            encoder_weights=encoder_weights,\n                            classes=classes,\n                            in_features=in_features, \n                            pretrained_path=None, \n                            pretrained_num_classes=None)\n            else:\n                print('load pretrain', encoder_pretrained_path)\n                model = PretrainModel(\n                            encoder_name=encoder_name,\n                            encoder_weights=encoder_weights,\n                            classes=encoder_pretrained_num_classes,\n                            in_features=in_features, \n                            pretrained_path=None, \n                            pretrained_num_classes=None)\n                model.load_state_dict(torch.load(encoder_pretrained_path, map_location='cpu'))\n            self.encoder = model.encoder\n            self.hidden_layer = model.hidden_layer\n            del model\n            self.fc = nn.Linear(in_features, 1024, bias=True)\n            self.cls_head = nn.Linear(1024, classes, bias=True)\n\n            if decoder == 'unet':\n                self.decoder = UnetDecoder(\n                    encoder_channels=self.encoder.out_channels,\n                    decoder_channels=decoder_channels,\n                    n_blocks=5,\n                    use_batchnorm=decoder_use_batchnorm,\n                    center=True if encoder_name.startswith(\"vgg\") else False,\n                    attention_type=decoder_attention_type,\n                )\n            elif decoder == 'unetplusplus':\n                self.decoder = UnetPlusPlusDecoder(\n                    encoder_channels=self.encoder.out_channels,\n                    decoder_channels=decoder_channels,\n                    n_blocks=5,\n                    use_batchnorm=decoder_use_batchnorm,\n                    center=True if encoder_name.startswith(\"vgg\") else False,\n                    attention_type=decoder_attention_type,\n                )\n            elif decoder == 'fpn':\n                self.decoder = FPNDecoder(\n                    encoder_channels=self.encoder.out_channels,\n                    encoder_depth=5,\n                    pyramid_channels=256,\n                    segmentation_channels=128,\n                    dropout=0.2,\n                    merge_policy=\"add\",\n                )\n            elif decoder == 'linknet':\n                self.decoder = LinknetDecoder(\n                    encoder_channels=self.encoder.out_channels,\n                    n_blocks=5,\n                    prefinal_channels=32,\n                    use_batchnorm=decoder_use_batchnorm,\n                )\n            elif decoder == 'deeplabv3plus':\n                decoder_atrous_rates = [12, 24, 36]\n                encoder_output_stride = 16\n                self.encoder.make_dilated(\n                    stage_list=[5],\n                    dilation_list=[2]\n                )\n                self.decoder = DeepLabV3PlusDecoder(\n                    encoder_channels=self.encoder.out_channels,\n                    out_channels=decoder_channels,\n                    atrous_rates=decoder_atrous_rates,\n                    output_stride=encoder_output_stride,\n                )\n            else:\n                raise ValueError('Decoder error!!!')\n\n            if decoder == 'unet' or decoder == 'unetplusplus':\n                self.segmentation_head = SegmentationHead(\n                    in_channels=decoder_channels[-1],\n                    out_channels=1,\n                    activation='sigmoid',\n                    kernel_size=3,\n                )\n            elif decoder == 'deeplabv3plus':\n                self.segmentation_head = SegmentationHead(\n                    in_channels=self.decoder.out_channels,\n                    out_channels=1,\n                    activation='sigmoid',\n                    kernel_size=1,\n                    upsampling=4,\n                )\n            elif decoder == 'fpn':\n                self.segmentation_head = SegmentationHead(\n                    in_channels=self.decoder.out_channels,\n                    out_channels=1,\n                    activation='sigmoid',\n                    kernel_size=1,\n                    upsampling=4,\n                )\n            elif decoder == 'linknet':\n                self.segmentation_head = SegmentationHead(\n                    in_channels=32, \n                    out_channels=1, \n                    activation='sigmoid',\n                    kernel_size=1\n                )\n            else:\n                raise ValueError('Decoder error!!!')\n\n            init.initialize_head(self.fc)\n            init.initialize_head(self.cls_head)\n            init.initialize_decoder(self.decoder)\n            init.initialize_head(self.segmentation_head)\n        else:\n            print('Load pretrain: {}'.format(model_pretrained_path))\n            model = SiimCovidAuxModel(\n                encoder_name=encoder_name,\n                encoder_weights=None,\n                decoder=decoder,\n                classes=model_pretrained_num_classes,\n                in_features=in_features,\n                decoder_channels=decoder_channels,\n                encoder_pretrained_path=None,\n                encoder_pretrained_num_classes=None,\n                model_pretrained_path=None, \n                model_pretrained_num_classes=None,\n                test_mode=False,\n            )\n            model.load_state_dict(torch.load(model_pretrained_path, map_location='cpu'))\n\n            self.encoder = model.encoder\n            self.hidden_layer = model.hidden_layer\n            self.decoder = model.decoder\n            self.segmentation_head = model.segmentation_head\n            self.fc = nn.Linear(in_features, 1024, bias=True)\n            self.cls_head = nn.Linear(1024, classes, bias=True)\n            del model\n            init.initialize_head(self.fc)\n            init.initialize_head(self.cls_head)\n    \n    @autocast(enabled=True)\n    def forward(self, x):\n        if self.test_mode:\n            features = self.encoder(x)\n            xcls = self.hidden_layer(features[-1])\n            xcls = xcls.view(-1, self.in_features)\n            xcls = self.fc(xcls)\n            xcls = F.relu(xcls)\n            xcls = F.dropout(xcls, p=0.5, training=self.training)\n            xcls = self.cls_head(xcls)\n            return xcls\n        else:\n            features = self.encoder(x)\n            xseg = self.decoder(*features)\n            xseg = self.segmentation_head(xseg)\n\n            xcls = self.hidden_layer(features[-1])\n            xcls = xcls.view(-1, self.in_features)\n            xcls = self.fc(xcls)\n            xcls = F.relu(xcls)\n            xcls = F.dropout(xcls, p=0.5, training=self.training)\n            xcls = self.cls_head(xcls)\n\n            return xseg, xcls\n","0c17467f":"class ClfTestDataset(torch.utils.data.Dataset):\n    \n    def __init__(self, csv, transforms=None):\n        self.csv = csv.reset_index()\n        self.augmentations = transforms\n\n    def __len__(self):\n        return self.csv.shape[0]\n\n    def __getitem__(self, index):\n        row = self.csv.iloc[index]\n        image = cv2.imread(row.test_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations:\n            augmented = self.augmentations(image=image)\n            image = augmented['image']\n        \n        if('clf_label_idx' in self.csv.columns):\n            return torch.tensor(image), torch.tensor(row.clf_label_idx)\n        \n        return image\n    \n\ndef get_test_transforms(candidate):\n    dim = candidate.get('dim', DIM)\n    print(dim)\n    return A.Compose(\n        [\n            A.Resize(dim[0],dim[1],always_apply=True),\n            A.Normalize(),\n            ToTensorV2(p=1.0)\n        ]\n    )","3a7113a4":"from tqdm.notebook import tqdm \n\ndef clf_predict_fn(dataloader, model, device):\n    model.eval()\n    tk0 = tqdm(enumerate(dataloader), total=len(dataloader))\n    batch_preds=[]\n    \n    for i, inps in tk0:\n        inps = inps.to(device)\n        with torch.cuda.amp.autocast(enabled=True):\n            logits = model(inps)\n            if(torch.isnan(logits.sum())):\n                print(torch.isnan(logits.sum(axis=1)).sum())\n            sum_check_nan = logits.sum(axis=1)\n            logits[torch.isnan(sum_check_nan), :] = 0.25\n            \n        probs = nn.functional.softmax(logits, dim=-1)\n        batch_preds.append(probs.detach().cpu().numpy())\n        \n        del inps, logits, probs, sum_check_nan\n        torch.cuda.empty_cache()\n        \n    return np.concatenate(batch_preds)","744128af":"cfg = dict()\ncfg['encoder_name'] = 'timm-efficientnet-b7'\ncfg['encoder_weight'] = None\ncfg['decoder'] = 'unetplusplus'\ncfg['in_features'] = 2560\ncfg['decoder_channels'] = [256, 128, 64, 32, 16]\ncfg['encoder_pretrained_path'] = None\ncfg['model_pretrained_num_classes'] = 4","9a460a21":"for candidate in CANDIDATES:\n    cfg['model_pretrained_path'] = candidate.get('model_path')\n    model = SiimCovidAuxModel(\n    encoder_name=cfg['encoder_name'],\n    encoder_weights=cfg['encoder_weight'],\n    decoder=cfg['decoder'],\n    classes=4,\n    in_features=cfg['in_features'],\n    decoder_channels=cfg['decoder_channels'],\n    encoder_pretrained_path=None ,\n    encoder_pretrained_num_classes=None,\n    model_pretrained_path=None, \n    model_pretrained_num_classes=cfg['model_pretrained_num_classes'],\n    test_mode=True)\n    \n    model.load_state_dict(torch.load(cfg['model_pretrained_path'], map_location='cpu'))\n    model.to('cuda:0')\n    print()\n    \n    batch_size = candidate.get('batch_size', BATCH_SIZE)\n    test_dataset = ClfTestDataset(sub_df, get_test_transforms(candidate))\n    test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n    \n    sub_df[label_cols] += clf_predict_fn(test_dataloader, model, torch.device('cuda:0'))\n    \n    del model\n    torch.cuda.empty_cache()\n    \nsub_df[label_cols] \/= len(CANDIDATES)","929509bd":"batch_size","81f3e7e2":"sub_df.columns = ['id', 'PredictionString1', 'negative', 'typical', 'indeterminate', 'atypical', 'test_path']\ndf = pd.merge(df, sub_df, on = 'id', how = 'left')","f4f403d2":"for i in range(study_len):\n    negative = df.loc[i,'negative']\n    typical = df.loc[i,'typical']\n    indeterminate = df.loc[i,'indeterminate']\n    atypical = df.loc[i,'atypical']\n    df.loc[i, 'PredictionString'] = f'negative {negative} 0 0 1 1 typical {typical} 0 0 1 1 indeterminate {indeterminate} 0 0 1 1 atypical {atypical} 0 0 1 1'","ea9f1463":"df_study = df[['id', 'PredictionString']]\n\n# df.to_csv('submission.csv',index=False)\n# df","6de5af53":"sub_df = df_study.fillna('')\ndef remove_prediction_on_image_level(row):\n    if(row['id'].endswith('_image')):\n        row['PredictionString'] = ''\n    return row\nsub_df = sub_df.apply(remove_prediction_on_image_level, axis=1)","deb71a73":"sub_df.iloc[0].PredictionString","a6a989ae":"# 'negative 0.01657867431640625 0 0 1 1 typical 0.76240234375 0 0 1 1 indeterminate 0.13795166015625 0 0 1 1 atypical 0.083038330078125 0 0 1 1'","bdc5b697":"sub_df.iloc[1].PredictionString","7187a17f":"# 'negative 0.277313232421875 0 0 1 1 typical 0.082476806640625 0 0 1 1 indeterminate 0.1296875 0 0 1 1 atypical 0.510546875 0 0 1 1'","bba807b7":"sub_df.to_csv('submission.csv',index=False)","d988b11b":"# study string","4d37753d":"# study predict","d061efdc":"# .dcm to .png"}}