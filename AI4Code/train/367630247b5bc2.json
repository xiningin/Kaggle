{"cell_type":{"671ecc4a":"code","8ef3640e":"code","b16d6d21":"code","35b3915b":"code","b03bc65c":"code","123edf19":"code","7d08eab1":"code","d2438732":"code","01332afb":"code","a58433f5":"code","9723b0a2":"code","4f6783c1":"code","f7e018e1":"code","9e639d23":"code","7f688853":"code","000c6402":"code","c136d197":"code","87361fcf":"code","6a5c319a":"code","b9f8c0a8":"code","c18e7aa7":"code","d94132af":"code","dcddd3ae":"code","41eab079":"code","f4332f3b":"code","f2219ab7":"code","e245e03c":"code","b3245fcc":"code","403aebb4":"code","c367c89d":"code","0bc87817":"code","5b55286b":"code","c5aac9f4":"code","d92a15ce":"code","c18d9f2a":"code","88914d57":"code","f81c48e1":"code","7c71bd34":"markdown","715410fa":"markdown","3b5b1786":"markdown","e4f874a3":"markdown","23340683":"markdown","bac8e167":"markdown","15c93a7c":"markdown","03b11db5":"markdown","1137e688":"markdown","2bde58d7":"markdown","d1df958a":"markdown","900c813a":"markdown","401afead":"markdown","f88008c5":"markdown","d7f9f312":"markdown","aae5ccb0":"markdown","1b5d7df9":"markdown","9a0c57de":"markdown","0e321043":"markdown","b4606ba7":"markdown","6ffa4ef6":"markdown","aebef461":"markdown"},"source":{"671ecc4a":"import os\nimport imageio\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport shutil\nimport imageio\n%matplotlib inline\n\nimport scipy.ndimage as ndi\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom keras.utils import plot_model\nimport keras.backend.tensorflow_backend as tfback\nfrom keras.regularizers import l1, l2\nfrom keras.utils.vis_utils import plot_model\nfrom keras.models import Model, Sequential\nfrom keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D, SeparableConv2D\nfrom keras.optimizers import SGD, Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nimport tensorflow as tf\n\n#Kaggle notebook input directory\ninput_path = '\/kaggle\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/'","8ef3640e":"def _get_available_gpus():\n    \"\"\"Get a list of available gpu devices (formatted as strings).\n\n    # Returns\n        A list of available GPU devices.\n    \"\"\"\n    #global _LOCAL_DEVICES\n    if tfback._LOCAL_DEVICES is None:\n        devices = tf.config.list_logical_devices()\n        tfback._LOCAL_DEVICES = [x.name for x in devices]\n    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n\ntfback._get_available_gpus = _get_available_gpus\ntfback._get_available_gpus()","b16d6d21":"#tf.config.experimental_list_devices()\ntf.config.list_logical_devices()","35b3915b":"#Ploting some samples\n\nfig, ax = plt.subplots(1, 3, figsize=(15, 7))\nax=ax.ravel()\nplt.tight_layout()\n\nfor i,_dir in enumerate(['COVID-19\/', 'NORMAL\/', 'Viral Pneumonia\/']):\n    im_file = os.listdir(input_path+_dir)[0]\n    full_path = input_path+_dir+im_file\n    ax[i].imshow(plt.imread(full_path), cmap='gray')\n    ax[i].set_title('Condition: {}'.format(_dir[:-1]))","b03bc65c":"n_covid = len(os.listdir(input_path + 'COVID-19\/'))\nn_normal = len(os.listdir(input_path + 'NORMAL\/'))\nn_pneumonia = len(os.listdir(input_path + 'Viral Pneumonia'))\nprint('COVID: {} images, Normal: {} images, Pneumonia: {} images \\nTotal images: {}.'.format(n_covid, n_normal, n_pneumonia, (n_covid+n_normal+n_pneumonia)))","123edf19":"# Data visualization for pixel distribution \n\nfig, ax = plt.subplots(2, 3, figsize=(15, 7))\nax=ax.ravel()\nplt.subplots_adjust(hspace=0.4, )\n\nfor i,_dir in enumerate(['COVID-19\/', 'NORMAL\/', 'Viral Pneumonia\/']):\n    im_file = os.listdir(input_path+_dir)[0]\n    full_path = input_path+_dir+im_file\n    im=imageio.imread(full_path)\n    hist=ndi.histogram(im, min=0, max=255, bins=256)\n    cdf = hist.cumsum() \/ hist.sum()\n    ax[i].plot(hist)\n    ax[i].set_title('Histogram {}'.format(_dir[:-1]))\n    ax[i].grid()\n    ax[i+3].plot(cdf, 'g')\n    ax[i+3].set_title('Cum. Dist. Function {}'.format(_dir[:-1]))\n    ax[i+3].grid()","7d08eab1":"# Creating folders for train and test samples\n\nos.mkdir('..\/working\/train')\nos.mkdir('..\/working\/test')","d2438732":"# Copying the source folder to train and test documents\n\ndef copytree(src, dst, symlinks=False, ignore=None):\n    if not os.path.exists(dst):\n        os.makedirs(dst)\n    for item in os.listdir(src):\n        s = os.path.join(src, item)\n        d = os.path.join(dst, item)\n        if os.path.isdir(s):\n            if(item=='NORMAL' or item=='Viral Pneumonia'):\n                os.mkdir(d)\n                for file in os.listdir(s):\n                    shutil.copy2(s+'\/'+file, d+'\/'+file)\n            else:\n                copytree(s, d, symlinks, ignore)\n        else:\n            if not os.path.exists(d) or os.stat(s).st_mtime - os.stat(d).st_mtime > 1:\n                shutil.copy2(s, d)\n                \ncopytree('..\/input\/covid19-radiography-database\/COVID-19 Radiography Database\/', '..\/working\/train')","01332afb":"# Checking how many files we have in the newest folders\n\ncnt=0\nos.listdir('..\/working\/train')\nfor file in {'COVID-19', 'NORMAL', 'Viral Pneumonia'}:\n    for files in os.listdir(os.path.join('..\/working\/train\/',file)):\n        cnt+=1\ncnt","a58433f5":"#Removing unnecessary data\n\nos.remove('..\/working\/train\/COVID-19.metadata.xlsx')\nos.remove('..\/working\/train\/README.md.txt')\nos.remove('..\/working\/train\/Viral Pneumonia.matadata.xlsx')\nos.remove('..\/working\/train\/NORMAL.metadata.xlsx')","9723b0a2":"# Moving 20 percent data to test folder\nsrc = '..\/working\/train'\ndst = '..\/working\/test'\nos.mkdir('..\/working\/test\/COVID-19')\nos.mkdir('..\/working\/test\/Viral Pneumonia')\nos.mkdir('..\/working\/test\/NORMAL')\n\nfor folders in os.listdir(src):\n    num_files = len(os.listdir(os.path.join(src,folders)))\n    cut_length = int(num_files*0.2)\n    cnt=0\n    for files in os.listdir(os.path.join(src, folders)):\n        shutil.move(os.path.join(src, folders, files), os.path.join(dst, folders, files))\n        if(cnt==cut_length):\n            break\n        cnt+=1","4f6783c1":"# Defining some constant variables to use in the preprocessor\n\ntrain_path  = '..\/working\/train'\ntest_path =  '..\/working\/test'\nIMAGE_SIZE    = (350, 350) # 150x150 (height, width) pixels\nNUM_CLASSES   = 3 #COVID-19, NORMAL and PNEUMONIA\nBATCH_SIZE    = 32  # try reducing batch size or freeze more layers if your GPU runs out of memory\nNUM_EPOCHS    = 20 # idem for epochs","f7e018e1":"#Train datagen here is a preprocessor\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   horizontal_flip = False ,\n                                   vertical_flip = False ,\n                                   validation_split = 0.2,\n                                    data_format='channels_last')\n\ntrain_batches = train_datagen.flow_from_directory(train_path,\n                                                  target_size=IMAGE_SIZE,\n                                                  shuffle=True,\n                                                  subset = \"training\",\n                                                  class_mode=\"categorical\"\n                                                  )\n\nvalid_batches = train_datagen.flow_from_directory(train_path,\n                                                  target_size=IMAGE_SIZE,\n                                                  shuffle=True,\n                                                  subset = \"validation\",\n                                                  class_mode=\"categorical\"\n                                                  )","9e639d23":"### Model 1\ndef fit_model_1():\n    \n    # define model\n    model = Sequential()\n    \n    #Convolve block\n    model.add(Conv2D(8, kernel_size=(3, 3), activation='relu',padding='same',input_shape=(250,250, 3)))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n    model.add(Conv2D(16, kernel_size=(5, 5), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n    model.add(Flatten())\n    model.add(Dense(120, activation='relu'))\n    model.add(Dense(60, activation='relu'))\n    \n    #Output layer\n    model.add(Dense(3, activation='softmax'))\n    \n    # compile model\n    opt = Adam(lr=0.001)\n    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n    \n    #Defining callbacks\n    early_stop = EarlyStopping(patience=3, monitor='val_accuracy')\n    \n    # fit model\n    STEP_SIZE_TRAIN=train_batches.n\/\/train_batches.batch_size\n    STEP_SIZE_VALID=valid_batches.n\/\/valid_batches.batch_size\n    result=model.fit_generator(train_batches,\n                        validation_data = valid_batches,\n                        callbacks=[early_stop],\n                        epochs = NUM_EPOCHS                        \n                       )\n    return model","7f688853":"# Fitting the model\n\nmodel = fit_model_1()","000c6402":"# Getting the model structure\n\nmodel.summary()","c136d197":"def get_model_2():\n    # define model\n    model = Sequential()\n    \n    #Convolve block\n    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu',input_shape=(250, 250, 3)))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n    model.add(Flatten())\n    model.add(Dense(64, activation='relu'))\n    \n    #Output layer\n    model.add(Dense(3, activation='softmax'))\n    \n    # compile model\n    opt = Adam(lr=0.001)\n    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n    \n    #Defining callbacks\n    early_stop = EarlyStopping(patience=3, monitor='val_accuracy')\n    \n    # fit model\n    STEP_SIZE_TRAIN=train_batches.n\/\/train_batches.batch_size\n    STEP_SIZE_VALID=valid_batches.n\/\/valid_batches.batch_size\n    result=model.fit_generator(train_batches,\n                        validation_data = valid_batches,\n                        validation_steps = STEP_SIZE_VALID,\n                        callbacks=[early_stop],\n                        epochs = NUM_EPOCHS                        \n                       )\n    return model","87361fcf":"# Fitting the model\n\nmodel_2 = get_model_2()","6a5c319a":"#Getting the model's structure\n\nmodel_2.summary()","b9f8c0a8":"def get_model_3():\n    # define model\n    model = Sequential()\n    \n    model.add(Conv2D(16, kernel_size=(3, 3), activation='relu',padding='same',input_shape=(250, 250, 3)))\n    model.add(Conv2D(16, kernel_size=(3, 3), activation='relu',padding='same'))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n    model.add(Flatten())\n    model.add(Dense(512, activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n    \n    #Output layer\n    model.add(Dense(3, activation='softmax'))\n    \n    # compile model\n    opt = Adam(lr=0.001)\n    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n    \n    #Defining callbacks\n    early_stop = EarlyStopping(patience=2, monitor='val_accuracy')\n    \n    # fit model\n    STEP_SIZE_TRAIN=train_batches.n\/\/train_batches.batch_size\n    STEP_SIZE_VALID=valid_batches.n\/\/valid_batches.batch_size\n    result=model.fit_generator(train_batches,\n                        steps_per_epoch =STEP_SIZE_TRAIN,\n                        validation_data = valid_batches,\n                        validation_steps = STEP_SIZE_VALID,\n                        callbacks=[early_stop],\n                        epochs = NUM_EPOCHS                        \n                       )\n    return model","c18e7aa7":"model_3 = get_model_3()","d94132af":"model_3.summary()","dcddd3ae":"#Train datagen here is a preprocessor\ntrain_datagen = ImageDataGenerator(rescale=1.\/255,\n                                   horizontal_flip = False ,\n                                   vertical_flip = False,\n                                   zca_whitening=True,\n                                   validation_split = 0.2,\n                                   data_format='channels_last')\n\ntrain_batches = train_datagen.flow_from_directory(train_path,\n                                                  target_size=IMAGE_SIZE,\n                                                  shuffle=True,\n                                                  subset = \"training\",\n                                                  class_mode=\"categorical\"\n                                                  )\n\nvalid_batches = train_datagen.flow_from_directory(train_path,\n                                                  target_size=IMAGE_SIZE,\n                                                  shuffle=True,\n                                                  subset = \"validation\",\n                                                  class_mode=\"categorical\"\n                                                  )","41eab079":"# Defining the model\n\ndef get_refine_model():\n    # define model\n    model = Sequential()\n    \n    #Convolve block\n    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(350, 350, 3)))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n    model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.6))\n    \n    model.add(Conv2D(128, kernel_size=(5, 5), padding='same', activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n    model.add(Dropout(0.3))\n    model.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n    model.add(Dropout(0.3))\n    model.add(Conv2D(256, kernel_size=(5, 5), padding='same', activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n    model.add(Dropout(0.3))\n\n    ","f4332f3b":"# Fitting the model\n\nclassifier, result = get_refine_model()","f2219ab7":"def plot_accs(result, epochs):\n    acc = result.history['accuracy']\n    loss = result.history['loss']\n    val_acc = result.history['val_accuracy']\n    val_loss = result.history['val_loss']\n    plt.figure(figsize=(15, 5))\n    plt.subplot(121)\n    plt.plot(range(1,epochs), acc[1:], label='Train_acc')\n    plt.plot(range(1,epochs), val_acc[1:], label='Test_acc')\n    plt.title('Accuracy over ' + str(epochs) + ' Epochs', size=15)\n    plt.legend()\n    plt.grid(True)\n    plt.subplot(122)\n    plt.plot(range(1,epochs), loss[1:], label='Train_loss')\n    plt.plot(range(1,epochs), val_loss[1:], label='Test_loss')\n    plt.title('Loss over ' + str(epochs) + ' Epochs', size=15)\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n    \nplot_accs(result, 15)","e245e03c":"classifier.summary()","b3245fcc":"plot_model(classifier, to_file='new_classifier.png', show_shapes=True, show_layer_names=True)","403aebb4":"# The best val_acc\n\nmax(result.history['val_accuracy'])","c367c89d":"# The best accuracy\nmax(result.history['accuracy'])","0bc87817":"# Get the best weights\n\nclassifier.load_weights('COVID_classifier.hdf5')","5b55286b":"# Preprocessing test set\n\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)\n\neval_generator = test_datagen.flow_from_directory(\n        test_path,\n        target_size=IMAGE_SIZE,\n        batch_size=1,\n        class_mode=\"categorical\")\neval_generator.reset()","c5aac9f4":"# Evaluating the model\n\neval_generator.reset()  \nx = classifier.evaluate_generator(eval_generator,\n                           steps = np.ceil(len(eval_generator) \/ 1),\n                           use_multiprocessing = False,\n                           verbose = 1,\n                           workers=1\n                           )\n\n\nprint('Test loss:' , x[0])\nprint('Test accuracy:',x[1])","d92a15ce":"scores = classifier.predict_generator(eval_generator)\ny_pred=np.argmax(scores, axis=1)","c18d9f2a":"print(confusion_matrix(eval_generator.classes, y_pred))","88914d57":"print(classification_report(eval_generator.classes, y_pred))","f81c48e1":"cf = confusion_matrix(eval_generator.classes, y_pred)\nsns.heatmap(cf, annot=True, cmap=\"YlGnBu\")","7c71bd34":"> * ## Configura\u00e7\u00f5es","715410fa":"* ### Second Model","3b5b1786":"In this section I'll fit the new model created by me inspired on the two better models that I've tested above.","e4f874a3":"* ## Analysing the datasets","23340683":"# **CNN COVID-19 Classifier**","bac8e167":"## Predicting","15c93a7c":"In the code below, I'll import the libraries necessary to develop the model","03b11db5":"It seems thehe newer versions of Tensor Flow is having some problems with Keras compatibility about devices configutarion (we'll use GPU), to run the model in the final sessions I'll define the function for devices configuration as you can see in the next cell.","1137e688":"* ## Pre-processing images","2bde58d7":"To build a new architeture model is appropiate to base on the most powerful already existing models.\nLet's fit three models based on the LeNet-5 and VGG architecturies, and then we'll obtain which of them works better for this dataset.\n\nThe two firsts models were based on the LeNet-5. They're a Conv-Pool-Conv-Pool kind of architecture.","d1df958a":"* ## Fitting the models","900c813a":"On the next part of the code I'll apply some preprocessing image techniques to achieve a good classifier (avoid overfitting for example), the ImageDataGenerator function applies all the processing that you define in its arguments before  fitting the model, also with the flow_from_directory function it'll splits the data in train and test samples according to their respective directories.","401afead":"The difference for the second model is that I double the value of the filters for each next layer","f88008c5":"To get a better perfomance of this new model I've maintened a similar structure of Conv-Pool-Conv-Pool, but choosing different attributes while I was getting better accuracies (val_accuracy). \n\nIt was created another train_datagen that contains more preprocessing techniques aiming to avoid overfitting.","d7f9f312":"> The histograma of intensity pixels and the cumulative distribution function, help us to understand how the intensity pixels are spread in the image.","aae5ccb0":"* ### First Model","1b5d7df9":"I'll use the saved model that was evaluated above to predict the pacient conditions with the unseen data in the test folder.","9a0c57de":"* ## Fitting the new Model","0e321043":"This notebook contains all the process to build a new model of XRay image classifier for COVID-19.","b4606ba7":"For more information about the dataset avaliable, i'll ploting some samples with the data visualization libs, also it'll be ploting two graphics about the pixel intensity distribution of three image, one for each clinical condition","6ffa4ef6":"Checking how many samples we have for each condition and total files:","aebef461":"shutil.rmtree('..\/working\/train')\nshutil.rmtree('..\/working\/test')"}}