{"cell_type":{"68f5b299":"code","c30bad06":"code","8fb8fb67":"code","8ef4bba3":"code","56e8d80f":"code","50ae614c":"code","c6edb3ef":"code","35e70a23":"code","0e24d94e":"code","652a75a6":"code","9ffed09c":"code","dbe66044":"code","308b0233":"code","f1e8bccd":"code","cc3bbbe0":"code","8512f64b":"code","0d01625a":"code","54902d17":"code","30100ba0":"code","43233d9d":"code","fd11f652":"code","6276b344":"code","dbdbdc5d":"code","2a977986":"code","204ed556":"code","83aa5930":"code","04a7ddec":"code","a84f75a5":"code","6e7e167a":"code","904f0e18":"code","f67c5c39":"code","4a4bca0c":"code","68cd224b":"code","69ad3145":"code","0eb1b5ce":"code","e2f2a5e2":"code","f4ad2b10":"code","278c2442":"code","fd8b2081":"code","b3685d4f":"code","f2604168":"code","cdb7f0ed":"code","1ff0a970":"code","fe302876":"code","4498b156":"code","dbe846b7":"code","d6e808e3":"code","e569601a":"code","689fcc25":"code","d9429a3f":"code","f1f66959":"code","a8fd7c1e":"code","d4e5e748":"code","2822179e":"code","d37a40ef":"code","a97acf77":"code","ecca237a":"code","a010820b":"code","7234d4ab":"markdown","9cbc8055":"markdown","2265ab3a":"markdown","ac37deba":"markdown","f59d1ae7":"markdown","126d2367":"markdown","868c3390":"markdown","b61406c2":"markdown","5dd242cf":"markdown","9c5bcaef":"markdown","3bf6fadf":"markdown","b52337d6":"markdown","a778382a":"markdown","208340d1":"markdown","e4094eae":"markdown","a251984f":"markdown","2e6cbbab":"markdown","b0875326":"markdown"},"source":{"68f5b299":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport random\nimport seaborn as sns\nimport datetime as dt\nfrom math import sqrt\n\nfrom sklearn.cluster import AgglomerativeClustering, DBSCAN, KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.mixture import GaussianMixture","c30bad06":"df= pd.read_csv('\/kaggle\/input\/supermarket-data\/supermarket_data.csv')","8fb8fb67":"df","8ef4bba3":"df['SHOP_DATE'] = pd.to_datetime(df['SHOP_DATE'], format='%Y%m%d')","56e8d80f":"df['WEEKDAY'] = df['SHOP_DATE'].map(lambda date: date.strftime('%A'))\ndf['DAY'] = df['SHOP_DATE'].map(lambda date: date.day)\ndf['MONTH'] = df['SHOP_DATE'].map(lambda date: date.month)\ndf['YEAR'] = df['SHOP_DATE'].map(lambda date: date.year)","50ae614c":"cleanup = {\"WEEKDAY\": {\"Monday\": 1, \"Tuesday\": 2, \"Wednesday\": 3, \"Thursday\": 4,\n                                  \"Friday\": 5, \"Saturday\": 6, \"Sunday\":7 }}","c6edb3ef":"df = df.replace(cleanup)","35e70a23":"preprocessed_df = df.copy(deep=True)\npreprocessed_df['count_txn'] = 1\n\npreprocessed_df","0e24d94e":"def smart_pivot_table(df, value, index, column, aggfunc, **kwargs):\n    pv = pd.pivot_table(\n        df,\n        values=value,\n        index=index,\n        columns=column,\n        aggfunc=aggfunc,\n        **kwargs\n    )\n    pv.columns = [f\"{col}_{aggfunc}_{value}\" for col in pv.columns.values]\n\n    return pv","652a75a6":"def extract_features(df):\n    dfs = []\n    dfs.append(\n        smart_pivot_table(\n            df,\n            value='SPEND',\n            index='CUST_CODE',\n            column='STORE_CODE',\n            aggfunc='sum',\n            fill_value=0,\n        )\n    )\n#     dfs.append(\n#         smart_pivot_table(\n#             df,\n#             value='SPEND',\n#             index='CUST_CODE',\n#             column='STORE_CODE',\n#             aggfunc='mean',\n#             fill_value=0,\n#         )\n#     )\n    dfs.append(\n        smart_pivot_table(\n            df,\n            value='QUANTITY',\n            index='CUST_CODE',\n            column='STORE_CODE',\n            aggfunc='sum',\n            fill_value=0,\n        )\n    )\n#     dfs.append(\n#         smart_pivot_table(\n#             df,\n#             value='QUANTITY',\n#             index='CUST_CODE',\n#             column='STORE_CODE',\n#             aggfunc='mean',\n#             fill_value=0,\n#         )\n#     )\n    dfs.append(\n        smart_pivot_table(\n            df,\n            value='count_txn',\n            index='CUST_CODE',\n            column='STORE_CODE',\n            aggfunc='sum',\n            fill_value=0,\n        )\n    )\n    dfs.append(\n        (\n            smart_pivot_table(\n                df,\n                value='count_txn',\n                index='CUST_CODE',\n                column='STORE_CODE',\n                aggfunc='mean',\n                fill_value=0,\n            )\n                .sum(axis=1)\n                .to_frame()\n                .rename(columns={0: 'store_visited'})\n        )\n    )\n    dfs.append(\n        (\n            df\n                .groupby(['CUST_CODE', 'SHOP_HOUR'])\n                .size()\n                .reset_index()\n                .sort_values(['CUST_CODE', 0])\n                .groupby(['CUST_CODE'])\n                .last()\n                .rename(columns={'SHOP_HOUR': 'mode_SHOP_HOUR'})\n        )[[\n            'mode_SHOP_HOUR'\n        ]]\n    )\n    dfs.append(\n        (\n            df.groupby(['CUST_CODE', 'WEEKDAY'])\n                .size()\n                .reset_index()\n                .sort_values(['CUST_CODE', 0])\n                .groupby(['CUST_CODE'])\n                .last()\n                .rename(columns={'WEEKDAY': 'mode_WEEKDAY'})\n        )  [[\n                        'mode_WEEKDAY'\n                    ]]\n    )\n    dfs.append(\n    (df.groupby(['CUST_CODE', 'BASKET_ID'])['QUANTITY']\n    .sum()\n    .reset_index()\n    .groupby(['CUST_CODE'])['QUANTITY'].mean() \n    .reset_index()\n    .rename(columns={'QUANTITY': 'AVG_QUANTITY_PER_BASKET'})\n    .set_index('CUST_CODE')\n\n    ))\n    dfs.append(\n    (df.groupby(['CUST_CODE', 'BASKET_ID'])['SPEND']\n    .sum()\n    .reset_index()\n    .groupby(['CUST_CODE'])['SPEND'].mean() \n    .reset_index()\n    .rename(columns={'SPEND': 'AVG_SPEND_PER_BASKET'})\n    .set_index('CUST_CODE')\n    ))\n    return (\n        pd\n            .concat(\n                dfs,\n                axis=1,\n                join='outer'\n            )\n            .fillna(0)\n    )","9ffed09c":"def standardize(df):\n    return (df - df.mean()) \/ df.std()","dbe66044":"extracted_df = extract_features(preprocessed_df)\nextracted_df","308b0233":"extracted_df.columns","f1e8bccd":"df['SHOP_DATE'].max()","cc3bbbe0":"# setting now to the last transaction date in the dataset\nNOW = dt.datetime(2008,7,6)\n\n\n# RFM Table\nRFM_table=df.groupby('CUST_CODE').agg({'SHOP_DATE': lambda x: (NOW - x.max()).days, # Recency\n                                                'BASKET_ID': lambda x: len(x.unique()), # Frequency\n                                                'SPEND': lambda x: x.sum()})    # Monetary \n\nRFM_table['SHOP_DATE'] = RFM_table['SHOP_DATE'].astype(int)\n\nRFM_table.rename(columns={'SHOP_DATE': 'recency', \n                         'BASKET_ID': 'frequency',\n                         'SPEND': 'monetary_value'}, inplace=True)\nRFM_table.head()","8512f64b":"quantiles = RFM_table.quantile(q=[0.25,0.5,0.75])\nquantiles","0d01625a":"# Converting quantiles to a dictionary, easier to use.\nquantiles = quantiles.to_dict()\n##  RFM Segmentation ----\nRFM_Segment = RFM_table.copy()\n# Arguments (x = value, p = recency, monetary_value, frequency, k = quartiles dict)\ndef R_Class(x,p,d):\n    if x <= d[p][0.25]:\n        return 4\n    elif x <= d[p][0.50]:\n        return 3\n    elif x <= d[p][0.75]: \n        return 2\n    else:\n        return 1\n    \n# Arguments (x = value, p = recency, monetary_value, frequency, k = quartiles dict)\ndef FM_Class(x,p,d):\n    if x <= d[p][0.25]:\n        return 1\n    elif x <= d[p][0.50]:\n        return 2\n    elif x <= d[p][0.75]: \n        return 3\n    else:\n        return 4\nRFM_Segment['R_Quartile'] = RFM_Segment['recency'].apply(R_Class, args=('recency',quantiles,))\nRFM_Segment['F_Quartile'] = RFM_Segment['frequency'].apply(FM_Class, args=('frequency',quantiles,))\nRFM_Segment['M_Quartile'] = RFM_Segment['monetary_value'].apply(FM_Class, args=('monetary_value',quantiles,))\nRFM_Segment['RFMClass'] = RFM_Segment.R_Quartile.map(str) \\\n                            + RFM_Segment.F_Quartile.map(str) \\\n                            + RFM_Segment.M_Quartile.map(str)","54902d17":"#Who are my best customers?\n#RFMClass = 444\nRFM_Segment[RFM_Segment['RFMClass']=='444'].sort_values('monetary_value', ascending=False).head()","30100ba0":"#Which customers are at the verge of churning?\n#Customers who's recency value is low (customers are at the verge of churning)\n\nRFM_Segment[RFM_Segment['R_Quartile'] <= 2 ].sort_values('monetary_value', ascending=False).head()","43233d9d":"#Who are the lost customers?\n#Customers who's recency, frequency as well as monetary values are low \n\nRFM_Segment[RFM_Segment['RFMClass']=='111'].sort_values('recency',ascending=False).head()","fd11f652":"#Who are loyal customers?\n#Customers with high frequency value\n\nRFM_Segment[RFM_Segment['F_Quartile'] == 4 ].sort_values('monetary_value', ascending=False).head()","6276b344":"\nsegt_map = {\n    r'4[4][4]': 'Best Customers',\n    r'[2-4][3-4][4]': 'Loyal Customers',\n    r'[3-4][1-3][1-3]': 'Potential Customers',\n    r'[3-4][1-2][1-2]': 'New Customers',\n    r'[2-3][1-2][1-2]': 'Promissing',\n    r'[3-4][3-4][3-4]': 'Customers Needing Attention',\n    r'[2-3][1-3][1-3]': 'About To Sleep',\n    r'[1-2]4[1-4]': 'Can\\'t Lose Them',\n    r'[1-2][2-4][2-4]': 'At Risk',\n    r'[1-2][1-2][1-2]': 'Churned Customer',\n    r'[1-4][1-4][1-4]': 'Other Customer'\n}\n\nsegmented_rfm = RFM_Segment.copy()\n\nsegmented_rfm['segment'] = segmented_rfm['R_Quartile'].map(str) + segmented_rfm['F_Quartile'].map(str) + segmented_rfm['M_Quartile'].map(str)\n\nsegmented_rfm['segment'] = segmented_rfm['segment'].replace(segt_map, regex=True)\n\nsegmented_rfm = segmented_rfm.reset_index()","dbdbdc5d":"segmented_rfm","2a977986":"# Visualization\nimport matplotlib.pyplot as plt\nsegments_counts = segmented_rfm['segment'].value_counts().sort_values(ascending=True)\n\nfig, ax = plt.subplots()\n\nbars = ax.barh(range(len(segments_counts)),\n              segments_counts,\n              color='silver')\nax.set_frame_on(False)\nax.tick_params(left=False,\n               bottom=False,\n               labelbottom=False)\nax.set_yticks(range(len(segments_counts)))\nax.set_yticklabels(segments_counts.index)\n\nfor i, bar in enumerate(bars):\n        value = bar.get_width()\n        if segments_counts.index[i] in ['Best Customers']:\n            bar.set_color('firebrick')\n        ax.text(value,\n                bar.get_y() + bar.get_height()\/2,\n                '{:,} ({:}%)'.format(int(value),\n                                   int(value*100\/segments_counts.sum())),\n                va='center',\n                ha='left'\n               )\n\nplt.show()","204ed556":"extracted_df = extract_features(preprocessed_df)\nstandardized_df = standardize(extracted_df)\n\nstandardized_df #no RFM features","83aa5930":"RFM_features = segmented_rfm[['CUST_CODE', 'recency', 'frequency', 'monetary_value', 'R_Quartile',\n       'F_Quartile', 'M_Quartile']].set_index('CUST_CODE')\nRFM_features.head()","04a7ddec":"df_for_cluster = pd.concat([extracted_df,RFM_features], axis=1)\ndf_for_cluster.head() ","a84f75a5":"standardized_df_RFM = standardize(RFM_features)\nstandardized_df_all = pd.concat([standardized_df,standardized_df_RFM], axis=1)\nstandardized_df_all","6e7e167a":"standardized_df_all.columns","904f0e18":"pca = PCA(n_components=2)\npca_data = pca.fit_transform(standardized_df_all)\n\nplt.scatter(x=pca_data[:,0], y=pca_data[:,1], alpha=0.2)\nplt.figure(figsize=(20,20))\nplt.show()","f67c5c39":"pca = PCA(n_components=2)\npca_data = pca.fit_transform(df_for_cluster)\n\nplt.scatter(x=pca_data[:,0], y=pca_data[:,1], alpha=0.2)\nplt.figure(figsize=(20,20))\nplt.show()","4a4bca0c":"pca = PCA(n_components=2)\npca_data = pca.fit_transform(standardized_df)\n\nplt.scatter(x=pca_data[:,0], y=pca_data[:,1], alpha=0.2)\nplt.figure(figsize=(20,20))\nplt.show()","68cd224b":"def find_optimal_number_of_clusters(\n    data,\n    min_n=2,\n    max_n=15,\n    random_state=None,\n    display=False,\n):\n\n    n_list = list(range(min_n, max_n+1))\n\n    def calculate_wcss():\n        wcss = []\n        for n in n_list:\n            kmeans = KMeans(n_clusters=n, random_state=random_state)\n            kmeans.fit(data)\n            wcss.append(kmeans.inertia_)\n        \n        return wcss\n    \n    wcss = calculate_wcss()\n    x1, y1 = n_list[0], wcss[0]\n    x2, y2 = n_list[-1], wcss[-1]\n    distances = []\n    for x0, y0 in zip(n_list, wcss):\n        numerator = abs((y2-y1)*x0 - (x2-x1)*y0 + x2*y1 - y2*x1)\n        denominator = sqrt((y2 - y1)**2 + (x2 - x1)**2)\n        distances.append(numerator\/denominator)\n    max_idx = distances.index(max(distances))\n\n    if display:\n        plt.figure(1, figsize = (10, 6))\n        plt.plot(n_list, wcss, '-', alpha=0.5)\n        plt.xlabel('Number of Clusters')\n        plt.ylabel('Within Clusters Sum-of-Squares')\n        plt.show()\n    \n    return n_list[max_idx]","69ad3145":"optimal_n = find_optimal_number_of_clusters(\n    standardized_df_all,\n    min_n=2,\n    max_n=15,\n    random_state=0,\n    display=True,\n)\n\noptimal_n","0eb1b5ce":"kmeans = KMeans(n_clusters=optimal_n, random_state=0).fit(standardized_df_all)\npredicted_clusters = kmeans.predict(standardized_df_all)\n\n# dbscan = DBSCAN(eps=5, min_samples=2).fit(standardized_df)\n# predicted_clusters = dbscan.labels_\n\n# gm = GaussianMixture(n_components=4, covariance_type='diag', random_state=0).fit(standardized_df)\n# predicted_clusters = gm.predict(standardized_df)\n\n# ac = AgglomerativeClustering(n_clusters=8).fit(standardized_df)\n# predicted_clusters = ac.labels_\n\npredicted_clusters","e2f2a5e2":"result_df = df_for_cluster.copy(deep=True)\nresult_df['cluster'] = predicted_clusters\n\nresult_df","f4ad2b10":"result_df['cluster'].value_counts().plot.bar()\nresult_df['cluster'].value_counts()","278c2442":"result_df[result_df['cluster'] == result_df['cluster'].value_counts().idxmax()]","fd8b2081":"pca = PCA(n_components=2)\npca_data = pca.fit_transform(standardized_df_all)\n\nplt.scatter(x=pca_data[:,0], y=pca_data[:,1], c=result_df['cluster'], alpha=0.2)\nplt.figure(figsize=(20,20))\nplt.show()","b3685d4f":"sum_result_df = (\n    result_df\n        .groupby(['cluster'])\n        .sum()\n        .reset_index()\n)[[\n    'STORE00001_sum_SPEND',\n    'STORE00002_sum_SPEND',\n    'STORE00003_sum_SPEND',\n    'STORE00004_sum_SPEND',\n    'cluster',\n]]\n\nmelted_sum_result_df = pd.melt(\n    sum_result_df,\n    id_vars='cluster',\n    var_name='store',\n    value_name='total',\n)\n\nsns.catplot(\n    x='cluster',\n    y='total',\n    hue='store',\n    data=melted_sum_result_df,\n    kind='bar',\n)\nplt.plot()\nsum_result_df","f2604168":"mean_result_df = (\n    result_df\n        .groupby(['cluster'])\n        .mean()\n        .reset_index()\n)[[\n    'STORE00001_sum_SPEND',\n    'STORE00002_sum_SPEND',\n    'STORE00003_sum_SPEND',\n    'STORE00004_sum_SPEND',\n    'cluster',\n]]\n\nmelted_mean_result_df = pd.melt(\n    mean_result_df,\n    id_vars='cluster',\n    var_name='store',\n    value_name='total',\n)\n\nsns.catplot(\n    x='cluster',\n    y='total',\n    hue='store',\n    data=melted_mean_result_df,\n    kind='bar',\n)\nplt.plot()\nmean_result_df","cdb7f0ed":"result_df.columns","1ff0a970":"mode_shop_hour_df = (\n    result_df\n        .groupby(['cluster'])\n        .agg(lambda x: pd.Series.mode(x)[0])\n        .reset_index()\n)[[\n   'mode_SHOP_HOUR',\n   'cluster',\n]]\n\nmelted_mode_shop_hour_df = pd.melt(\n    mode_shop_hour_df,\n    id_vars='cluster',\n    var_name='shop_hour',\n    value_name='total',\n)\n\nsns.catplot(\n    x='cluster',\n    y='total',\n    hue='shop_hour',\n    data=melted_mode_shop_hour_df,\n    kind='bar',\n)\nplt.plot()\nmode_shop_hour_df","fe302876":"(result_df\n        .groupby(['cluster'])\n        .mean()\n        .reset_index()\n)[['cluster', 'store_visited','STORE00001_sum_SPEND', 'STORE00002_sum_SPEND', 'STORE00003_sum_SPEND',\n       'STORE00004_sum_SPEND',\n        'AVG_QUANTITY_PER_BASKET',\n       'AVG_SPEND_PER_BASKET', 'recency', 'frequency', 'monetary_value',\n       'R_Quartile', 'F_Quartile', 'M_Quartile']]","4498b156":"def find_popular_items(df, store_name, top_n):\n    return (\n        df[\n            df['STORE_CODE'] == store_name\n        ]\n            .groupby(['PROD_CODE'])['QUANTITY']\n            .sum()\n            .sort_values(ascending=False)\n            .head(top_n)\n            .index\n            .tolist()\n    )","dbe846b7":"def cal_prob(row):\n    sum_val = row.sum()\n    l = []\n    for val in row.values[:-1]:\n        ratio = val \/ sum_val\n        l.append(ratio)\n    ratio = (sum_val - row.values[:-1].sum()) \/ sum_val\n    l.append(ratio)\n    \n    return pd.Series(l)","d6e808e3":"mean_result_df","e569601a":"prob_df = (\n    mean_result_df\n        .set_index('cluster')\n        .apply(cal_prob, axis=1)\n)\nprob_df.columns = [col.split('_')[0] for col in mean_result_df.columns.drop('cluster')]\n\nprob_df","689fcc25":"result_df_cluster = result_df[['cluster']].reset_index()\nresult_df_cluster[result_df_cluster['cluster'] ==2 ]","d9429a3f":"df_with_cluster = preprocessed_df.copy(deep=True)\ndf_with_cluster['cluster'] = df_with_cluster['CUST_CODE'].map(result_df['cluster'])\n\ndf_with_cluster","f1f66959":"# selected_cust_code = 'CUST0000999935' # cluster 3\n# selected_cust_code = 'CUST0000000107'# cluster 0\n# selected_cust_code = 'CUST0000019927' #cluster 2","a8fd7c1e":"\ndef Recommend_products(selected_cust_code) :\n    cluster_num = df_with_cluster[\n    df_with_cluster['CUST_CODE'] == selected_cust_code\n    ].iloc[0]['cluster']\n\n    cluster_prob = prob_df.loc[cluster_num].sort_values(ascending=False)\n\n    random_stores = random.choices(\n    cluster_prob.index,\n    weights=cluster_prob.values,\n    k=10)\n\n    pop_items_store1 = find_popular_items(\n    df=df_with_cluster,\n    store_name='STORE00001',\n    top_n=10\n    )\n    pop_items_store2 = find_popular_items(\n        df=df_with_cluster,\n        store_name='STORE00002',\n        top_n=10\n    )\n    pop_items_store3 = find_popular_items(\n        df=df_with_cluster,\n        store_name='STORE00003',\n        top_n=10\n    )\n\n    pop_items_store4 = find_popular_items(\n        df=df_with_cluster,\n        store_name='STORE00004',\n        top_n=10\n    )\n    rec_items = []\n\n    while len(rec_items) < 10:\n        for store in random_stores:\n            if (store == 'STORE00001'):\n                items = random.choices(\n                pop_items_store1,\n                k=1)\n                if items not in rec_items:\n                    rec_items.append(items)\n            elif (store == 'STORE00002'):\n                items = random.choices(\n                pop_items_store2,\n                k=1)\n                if items not in rec_items:\n                    rec_items.append(items)\n            elif (store == 'STORE00003'):\n                items = random.choices(\n                pop_items_store3,\n                k=1)\n                if items not in rec_items:\n                    rec_items.append(items)\n            else :\n                items = random.choices(\n                pop_items_store4,\n                k=1)\n                if items not in rec_items:\n                    rec_items.append(items)\n    return rec_items","d4e5e748":"#recommend top seller in each store\nRecommend_products('CUST0000000107')","2822179e":"output_cluster = df_for_cluster.reset_index()\noutput_cluster['cluster'] = output_cluster['CUST_CODE'].map(result_df['cluster'])\noutput_cluster = output_cluster.rename(columns={'cluster':'Kmeans_cluster'})","d37a40ef":"output_rfm = segmented_rfm[['CUST_CODE','RFMClass','segment']].rename(columns={'segment':'RFM_segment'})","a97acf77":"output = pd.merge(output_cluster,output_rfm)","ecca237a":"cleanup = {\"mode_WEEKDAY\": {1:\"Monday\", 2:\"Tuesday\", 3: \"Wednesday\", 4:\"Thursday\",\n                                  5:\"Friday\", 6:\"Saturday\", 7:\"Sunday\"}}\noutput = output.replace(cleanup)","a010820b":"output.to_csv('.\/customer_segment_result.csv')","7234d4ab":"write output for vistualization in tableau","9cbc8055":"## find popular items in each store","2265ab3a":"Now that we knew our customers segments we can choose how to target or deal with each segment.\n\nFor example:\n\nBest Customers - Champions: Reward them. They can be early adopters to new products. Suggest them \"Refer a friend\".\n\nAt Risk: Send them personalized emails to encourage them to shop.","ac37deba":"# Data Preparation","f59d1ae7":"## Recommend products","126d2367":"- 0 -> low RFM, low total spending\n- 1 -> High RFM, shop at store1 \n- 2 -> High RFM, shop at store 3\n- 3 -> Medium RFM\n- 4 -> High RFM, shop store 2\n- 5 -> High RFM, shop store 4\n","868c3390":"# Recommend product by store\u2019s popular items","b61406c2":"[link to tableau dashboard](https:\/\/public.tableau.com\/app\/profile\/preeyanuch.leelapisuth\/viz\/Supermarketdataanalysis\/Market_Basket_Analysis) ","5dd242cf":"# All features","9c5bcaef":"# PCA","3bf6fadf":"# Data Collection","b52337d6":"## Feature Extraction","a778382a":"# RFM","208340d1":"# Installing & Importing Libraries","e4094eae":"We will use standardized_df_all","a251984f":"# Modeling (K-means)","2e6cbbab":"## Reading Files","b0875326":"## Data Preprocessing"}}