{"cell_type":{"1ecf77ee":"code","e413a2c4":"code","ceb7ae7a":"code","2b274c25":"code","ae2cea40":"code","f89528ad":"code","de66d218":"code","e4e0c3d5":"code","0fd1aec1":"code","484e7efb":"code","df60d68e":"code","6ee111e2":"code","ada57741":"code","d765b041":"code","106c3b63":"code","836d1e85":"code","4254949a":"code","2505174f":"code","180046d3":"code","18785564":"code","e10bbed4":"code","511a0c6d":"code","c2c886b3":"code","27ddaf34":"code","d17d314a":"code","22f2381b":"code","5a9a4ca3":"code","e5c59371":"code","6538e8ab":"code","87ec8e6b":"code","591aab2c":"code","273bf26c":"code","3f43e9ad":"code","a50e46e2":"code","03befa0a":"code","495b8e18":"code","1773f145":"code","f274a06e":"code","19421f57":"markdown","d8b84840":"markdown","1e21ea20":"markdown","e31af27f":"markdown","ded1f2ce":"markdown","b9ed7353":"markdown","3c696198":"markdown","a2bf3fca":"markdown","d7dcd5eb":"markdown","0ccdf38f":"markdown","fb9c983a":"markdown","d16b270d":"markdown","1a945416":"markdown","c799e4f1":"markdown","d69e90aa":"markdown","a551a7a4":"markdown","d416d23d":"markdown","d4a97152":"markdown","2c3a192a":"markdown","535d4a54":"markdown","67dd95dc":"markdown","a568638a":"markdown","824e59a4":"markdown","94ae262e":"markdown","8d4b8c17":"markdown","5b861bcf":"markdown","c6492e2a":"markdown"},"source":{"1ecf77ee":"import pandas as pd\nimport numpy as  np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","e413a2c4":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix","ceb7ae7a":"from keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.callbacks import ReduceLROnPlateau","2b274c25":"\ntrain_X = pd.read_csv('..\/input\/digit-recognition-dataset\/Digit Recognition\/trian_data1.csv')\ntest_X = pd.read_csv('..\/input\/digit-recognition-dataset\/Digit Recognition\/test_data1.csv')\ntrain_y = pd.read_csv('..\/input\/digit-recognition-dataset\/Digit Recognition\/train.csv')\ntest= pd.read_csv('..\/input\/digit-recognition-dataset\/Digit Recognition\/Test.csv')\nsample_sub = pd.read_csv('..\/input\/digit-recognition-dataset\/Digit Recognition\/Sample_submission.csv')","ae2cea40":"print('Train dataset has {} rows and {} columns'.format(train_X.shape[0],train_X.shape[1]))\nprint('test dataset has {} rows and {} columns'.format(test_X.shape[0],test_X.shape[1]))\n","f89528ad":"train_X.head()","de66d218":"test_X.head()","e4e0c3d5":"train_y.head()\ntrain_y = train_y.iloc[:,1]\n","0fd1aec1":"\ntrain_y.head()\n","484e7efb":"y = train_y.value_counts()\nsns.barplot(y.index,y)\n","df60d68e":"train_X = train_X \/255\ntest_X =test_X \/255","6ee111e2":"train_X= train_X.values.reshape(-1,28,28,1)\ntest_X = test_X.values.reshape(-1,28,28,1)\n","ada57741":"print('The shape of train set now is',train_X.shape)\nprint('The shape of test set now is',test_X.shape)","d765b041":"train_y = to_categorical(train_y)","106c3b63":"X_train,X_test,y_train,y_test = train_test_split(train_X,train_y,random_state = 42 , test_size=0.20)","836d1e85":"plt.imshow(X_train[0][:,:,0])","4254949a":"datagen = ImageDataGenerator(\n            featurewise_center = False, # set input mean to 0 over the dataset\n            samplewise_center = False,  # set each sample mean to 0\n            featurewise_std_normalization = False, # divide inputs by std of the dataset\n            samplewise_std_normalization = False,  # divide each input by its std\n            zca_whitening = False,   # apply ZCA whitening\n            rotation_range = 10,     # randomly rotate images in the range (degrees, 0 to 180)\n            zoom_range = 0.1,       # Randomly zoom image \n            width_shift_range = 0.1,  # randomly shift images horizontally (fraction of total width)\n            height_shift_range = 0.1, # randomly shift images vertically (fraction of total height)\n            horizontal_flip = False,  # randomly flip images\n            vertical_flip = False     # randomly flip images\n)\n\ndatagen.fit(X_train)","2505174f":"model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu'))\n\nmodel.add(BatchNormalization(momentum = .05))\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization(momentum=0.05))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization(momentum=.05))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(10, activation = \"softmax\"))","180046d3":"model.summary()","18785564":"optimizer = Adam(learning_rate=0.001 , beta_1=0.9 ,beta_2 = 0.999)","e10bbed4":"model.compile(optimizer=optimizer , loss=['categorical_crossentropy'],metrics = ['accuracy'])\n","511a0c6d":"learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc',\n                                            patience = 5 ,\n                                            verbose = 1,\n                                            factor = 0.5 , \n                                            min_lr = 0.00001)\n","c2c886b3":"epochs = 20\nbatch_size = 100","27ddaf34":"history = model.fit_generator(datagen.flow(X_train,y_train,batch_size = batch_size),\n                              epochs = epochs ,\n                              validation_data = (X_test,y_test),\n                              verbose = 2,\n                              steps_per_epoch = X_train.shape[0]\/\/batch_size,\n                              callbacks =[learning_rate_reduction])\n","d17d314a":"fig,ax=plt.subplots(2,1)\nfig.set\nx=range(1,1+epochs)\nax[0].plot(x,history.history['loss'],color='red')\nax[0].plot(x,history.history['val_loss'],color='blue')\n\nax[1].plot(x,history.history['accuracy'],color='red')\nax[1].plot(x,history.history['val_accuracy'],color='blue')\nax[0].legend(['trainng loss','validation loss'])\nax[1].legend(['trainng acc','validation acc'])\nplt.xlabel('Number of epochs')\nplt.ylabel('accuracy')","22f2381b":"y_pre_test=model.predict(X_test)\ny_pre_test=np.argmax(y_pre_test,axis=1)\ny_test=np.argmax(y_test,axis=1)","5a9a4ca3":"conf=confusion_matrix(y_test,y_pre_test)\nconf=pd.DataFrame(conf,index=range(0,10),columns=range(0,10))","e5c59371":"\n\nconf\n\n","6538e8ab":"plt.figure(figsize=(8,6))\nsns.set(font_scale=1.4)#for label size\nsns.heatmap(conf, annot=True,annot_kws={\"size\": 16},cmap=plt.cm.Blues)# font size","87ec8e6b":"x=(y_pre_test-y_test!=0).tolist()\nx=[i for i,l in enumerate(x) if l!=False]","591aab2c":"fig,ax=plt.subplots(1,4,sharey=False,figsize=(15,15))\n\nfor i in range(4):\n    ax[i].imshow(X_test[x[i]][:,:,0])\n    ax[i].set_xlabel('Real {}, Predicted {}'.format(y_test[x[i]],y_pre_test[x[i]]))\n    ","273bf26c":"y_pre_test","3f43e9ad":"test_y = model.predict(test_X)\ntest_y =np.argmax(test_y,axis=1)\n","a50e46e2":"test_y","03befa0a":"test1 = test","495b8e18":"test1 = test1.iloc[:,0:1]","1773f145":"test1","f274a06e":"output = pd.DataFrame({'filename': test1.iloc[1:,0],\n                     'label': test_y})\noutput.to_csv('submission1.csv', index=False)","19421f57":"**Pixel 0 to Pixel 783**: These are the pixel values of the image metrics.That is each row contains 28 * 28 = 784 (0-783 here) values here.Each one of these values indicates the pixel value at i x 28 + j th pixel position in the image metric.","d8b84840":"## Evaluatin our approach using graph","1e21ea20":"# Digit Recognition","e31af27f":"## Fitting Our Model","ded1f2ce":"* **pandas** - we use pandas to handle our csv files\n* **matplotlib & seaborn** - used for charting and plotting","b9ed7353":"I did not apply a vertical_flip nor horizontal_flip since it could have lead to misclassify symetrical numbers such as 6 and 9.","3c696198":"**train_y** file contains a target value i.e **label** for train data\n","a2bf3fca":"In order to avoid overfitting problem , we need to expand our dataset artificially.\n\nWe can do it by some **data augmentation techniques**.\n\nBy applying these techniques we can double or triple the number of training examples and create a very robust model.","d7dcd5eb":"## Modelling\n\n### CNN","0ccdf38f":"## Generating more data","fb9c983a":"## Normalize pixel values\n\nFor most image data, the pixel values are integers with values between 0 and 255.\n\nNeural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. As such it is good practice to normalize the pixel values so that each pixel value has a value between 0 and 1.\n\nIt is valid for images to have pixel values in the range 0-1 and images can be viewed normally.\n\nThis can be achieved by dividing all pixels values by the largest pixel value; that is 255. This is performed across all channels, regardless of the actual range of pixel values that are present in the image.","d16b270d":"## Checking Target class distribution.","1a945416":"## Some Misclassified Images","c799e4f1":"Digit racognition using CNN.\n\nI am using data from analytics vidya digit recognition competition.","d69e90aa":"Reference and credit:\n\n1.[Analytics Vidya](http:\/\/www.analyticsvidhya.com\/blog\/2018\/12\/guide-convolutional-neural-network-cnn\/)\n\n2.[Kaggle notebook](http:\/\/www.kaggle.com\/shahules\/indian-way-to-learn-cnn)\n\n","a551a7a4":"## Optimizer\n\n\nIn simpler terms, optimizers shape and mold your model into its most accurate possible form by futzing with the weights. The loss function is the guide to the terrain, telling the optimizer when it\u2019s moving in the right or wrong direction.","d416d23d":"* **sklearn** - Popular ML library.We will use it for splitting our data.","d4a97152":"## Understanding the train and test data","2c3a192a":"## Importing required libraries","535d4a54":"* **Keras** : Popular Deep learning library,we will use it to build our CNN Network.","67dd95dc":"## Encoding Target Values\n\n\n\nNow we will encode our target value.Keras inbuild library to_categorical() is used to do the on-hot encoding.","a568638a":"## Loading data","824e59a4":"## Reshape","94ae262e":"## Predicting for test data","8d4b8c17":"## Splitting train and test data\n\nNow we will split out training data into train and validation data. 20 percent of the training data will be used for validation purpose.","5b861bcf":"## Confusion Matrix","c6492e2a":"## Leraning rate reduction\n\n\n\nIn order to make the optimizer converge faster and closest to the global minimum of the loss function, i used an annealing method of the learning rate (LR).\n\nWith the ReduceLROnPlateau function from Keras.callbacks, i choose to reduce the LR by half if the accuracy is not improved after 3 epochs."}}