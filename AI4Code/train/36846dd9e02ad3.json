{"cell_type":{"bf2a651f":"code","4b2b4646":"code","20c15fba":"code","99e40f04":"code","df7ed12f":"code","5d468bd8":"code","bfa80dcd":"code","5bbb5632":"code","d1e98763":"code","f6a5c4e2":"code","421738af":"code","6e5d40dc":"code","2c5e29cd":"code","59207a90":"code","38f153cd":"code","0d3c9ff1":"code","1d48991c":"code","996a54e3":"code","11738820":"code","27e2e28a":"code","77c204c4":"code","75b4aace":"code","620e909f":"code","9d1c5e88":"markdown","2bac792a":"markdown","7e17f7b7":"markdown","d938e4b0":"markdown","e5b24081":"markdown","781eb50b":"markdown","cac1718c":"markdown","60398dad":"markdown","09153579":"markdown","ecc187b8":"markdown","bed46cd8":"markdown"},"source":{"bf2a651f":"#!pip install torchvision","4b2b4646":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\n\nimport os\nimport glob\nimport sys\nsys.setrecursionlimit(100000)  #this will increase the capacity of the stack \n\nimport torch\nimport torchvision\nfrom torch import nn, optim\nimport torch.nn.functional as F\n\nfrom PIL import Image, ImageFile\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\n#from torch.utils.data import datasets\nfrom torchvision import models\n\nimport imageio\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%config IPCompleter.greedy=True","20c15fba":"print(torch.__version__)","99e40f04":"os.listdir('..\/input')","df7ed12f":"USE_GPU = True","5d468bd8":"traindata_dir = '..\/input\/aptos2019-blindness-detection\/train_images\/'\ntrain_label = pd.read_csv('..\/input\/aptos2019-blindness-detection\/train.csv')\n\ntrain_label.head(10)\n#print(traindata_dir)\n\n#print(os.listdir(traindata_dir))\n","bfa80dcd":"train_label[\"diagnosis\"].value_counts().plot(kind=\"pie\")","5bbb5632":"#train_label = pd.read_csv('..\/input\/aptos2019-blindness-detection\/train.csv', header=0).iloc[:,2:4]\n#train_label.head(20)","d1e98763":"testdata_dir = '..\/input\/aptos2019-blindness-detection\/test_images'\ntest_label = pd.read_csv(\"..\/input\/aptos2019-blindness-detection\/test.csv\", encoding='latin-1')\n\n#print(os.listdir(testdata_dir))\ntest_label.head()\n","f6a5c4e2":"plt.figure(figsize=[15,15])\ni = 1\nfor img_name in train_label['id_code'][:12]:\n    img = mpimg.imread(traindata_dir + img_name + '.png')\n    plt.subplot(6,4,i)\n    plt.imshow(img)\n    i += 1\nplt.show()","421738af":"class DRTrainDataset(Dataset):\n    def __init__(self, data_label, data_dir, transform):\n        super().__init__()\n        self.data_label = data_label\n        self.data_dir = data_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data_label)\n    \n    def __getitem__(self, index):       \n        img_name = self.data_label.id_code[index] + '.png'\n        label = self.data_label.diagnosis[index]          \n        img_path = os.path.join(self.data_dir, img_name)   \n            \n        image = mpimg.imread(img_path)\n        image = (image + 1) * 127.5\n        image = image.astype(np.uint8)\n        \n        image = self.transform(image)\n        \n        \n        return image, label","6e5d40dc":"from IPython.display import Image\n\nlistOfImageNames = ['..\/input\/aptos2019-blindness-detection\/train_images\/000c1434d8d7.png',\n                    '..\/input\/aptos2019-blindness-detection\/train_images\/001639a390f0.png',\n                   '..\/input\/aptos2019-blindness-detection\/train_images\/002c21358ce6.png',\n                    '..\/\/input\/aptos2019-blindness-detection\/train_images\/005b95c28852.png',\n                    '..\/input\/aptos2019-blindness-detection\/train_images\/005b95c28852.png'\n                   ]\n\nfor imageName in listOfImageNames:\n    display(Image(filename=imageName))","2c5e29cd":"\ntrain_transform = transforms.Compose([transforms.ToPILImage(mode='RGB'),\n                                  transforms.RandomHorizontalFlip(),\n                                  transforms.Resize(265),\n                                  transforms.CenterCrop(224),\n                                  transforms.ToTensor(),\n                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntest_transform = transforms.Compose([transforms.ToPILImage(mode='RGB'), \n                                  transforms.Resize(265),\n                                  transforms.CenterCrop(224),\n                                  transforms.ToTensor(),\n                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrain_data = DRTrainDataset(data_label = train_label, data_dir = traindata_dir, transform = train_transform)\ntest_data = DRTrainDataset(data_label = test_label, data_dir = testdata_dir, transform = test_transform)\n\n\ntrain_loader = DataLoader(dataset = train_data, batch_size=64, shuffle=True)\n\ntest_loader = DataLoader(dataset = test_data, batch_size=64)\n","59207a90":"import torch\nfrom torchvision import datasets, transforms\n\n# Use GPU if it's available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = torchvision.models.resnet50()\n\nmodel.load_state_dict(torch.load(\"..\/input\/resnet50\/resnet50.pth\"))\n\nmodel","38f153cd":"# Build a feed-forward network\n#I'll freeze the parameters so I don't back-propagate through them\n\nfor param in model.parameters():\n    param.requires_grad = False\n    ","0d3c9ff1":"#print(model)","1d48991c":"import time\n\nmodel.fc = nn.Linear(2048, 5)\nmodel.to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.01)\nloss_func = nn.CrossEntropyLoss()","996a54e3":"# # number of epochs to train the model\n# num_epochs = 20\n\n# valid_loss_min = np.Inf # track change in validation loss\n\n# for epoch in range(1, num_epochs+1):\n\n#     # keep track of training and validation loss\n#     train_loss = 0.0\n    \n    \n#     ###################\n#     # train the model #\n#     ###################\n#     model.train()\n#     for inputs, label in train_loader:\n#         # move tensors to GPU if CUDA is available\n#         inputs, label = inputs.to(device), label.to(device)\n#         # clear the gradients of all optimized variables\n#         optimizer.zero_grad()\n#         # forward pass: compute predicted outputs by passing inputs to the model\n#         output = model(inputs)\n#         # calculate the batch loss\n#         loss = loss_func(output, label)\n#         # backward pass: compute gradient of the loss with respect to model parameters\n#         loss.backward()\n#         # perform a single optimization step (parameter update)\n#         optimizer.step()\n#         # update training loss\n#         train_loss += loss.item()*inputs.size(0)\n    \n    \n#     # print training\/validation statistics \n#     print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss))","11738820":"epochs = 15\nsteps = 0\nrunning_loss = 0\nprint_every = 5\n\nloss_log=[] \n\nfor epoch in range(epochs):\n    model.train()\n        \n    for ii, (inputs, labels) in enumerate(train_loader):\n        inputs, labels = inputs.cuda(), labels.cuda()\n             \n        optimizer.zero_grad()\n        output = model(inputs)                    \n        loss = loss_func(output, labels)\n        loss.backward()\n        optimizer.step()\n        \n        if ii % 1000 == 0:\n            loss_log.append(loss.item())\n        # inside the for-loop:\n        if epoch % 10 == 9:\n          torch.save(model.state_dict(), 'train_valid_exp4-epoch{}.pth'.format(epoch+1))\n    print('Epoch: {} - Loss: {:.6f}'.format(epoch + 1, loss.item()))\n\n      ","27e2e28a":"initial_submission = pd.read_csv('..\/input\/aptos2019-blindness-detection\/sample_submission.csv')\ntest_data = DRTrainDataset(data_label = initial_submission, data_dir = testdata_dir, transform = test_transform)\ntest_loader = DataLoader(dataset = test_data, shuffle=False)","77c204c4":"%%time\n# Prediction\npredict = []\nmodel.eval()\n\nwith torch.no_grad():\n    for i, (inputs, _) in enumerate(test_loader):\n        inputs = inputs.cuda()\n        output = model(inputs)\n        output = output.cpu().detach().numpy()\n        predict.append(output[0])","75b4aace":"initial_submission['diagnosis'] = np.argmax(predict, axis=1)\ninitial_submission.head(15)","620e909f":"initial_submission.to_csv('submission.csv', index=False)","9d1c5e88":"****Loading Training Dataset****","2bac792a":"> **Training The Model**","7e17f7b7":"This is my very first Kaggle competition. Working with this very important dataset is an opportunity for me to use the skills I have learned from many different areas of Deep Learning and Python to find a solution that will be beneficial to people. \n\nFramework: PyTorch","d938e4b0":"Let's manually view 5 random images from the train_image dataset.","e5b24081":"**Processing The Dataset (Train and Test data)****","781eb50b":"***Creating The Submission File Containing The Predictions***","cac1718c":"**Loading Test Dataset**","60398dad":"**Visualizing The Training Dataset**","09153579":"*****Definition of Model Architecture*****","ecc187b8":"***Model Testing and Validation***","bed46cd8":"***Data Processing***"}}