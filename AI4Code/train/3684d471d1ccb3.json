{"cell_type":{"686fa030":"code","db65862e":"code","9d13822e":"code","bbd225fd":"code","996c3f59":"code","8e6afa0a":"code","83ecb439":"code","bb78bc8f":"code","1c888baa":"code","2372468b":"code","7fd9aaa5":"code","7b1a1b0d":"code","d965b7d2":"code","05950f1d":"code","322f75c4":"code","503d1a13":"code","30e0b3a8":"code","36d17bd8":"code","c97cd315":"code","aa32b3e5":"markdown","7e286d8b":"markdown","75aa8190":"markdown","644e29a3":"markdown","7f867430":"markdown","5565890a":"markdown","5a2ff091":"markdown"},"source":{"686fa030":"# install skorch wrapper for pytorch\n!pip install -U skorch","db65862e":"# import libraries for file processing\nimport os\n\n# libraries for image processing\nimport cv2\nimport numpy as np\nimport pandas as pd\n\n# pytorch libraries\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data import random_split\n\n# skorch wrapper classes and functions\nfrom skorch import NeuralNetClassifier\nfrom skorch.dataset import CVSplit\nfrom skorch.callbacks import LRScheduler, Checkpoint \nfrom skorch.callbacks import Freezer, EarlyStopping\n\n# albumentations for image augmentation\nimport albumentations\nfrom albumentations import pytorch\n\n# for multiprocessing\nimport multiprocessing as mp\n\n# plot graphs for data exploration\nimport matplotlib.pyplot as plt","9d13822e":"# Here we seed our environmental variables and pytorch variables\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\n    seed_everything(42)","bbd225fd":"# Read train dataset from file\ndataset_dir = '\/kaggle\/input\/graphs-dataset\/graphs'        \ndataset_files = os.listdir(dataset_dir)\n\nprint(len(dataset_files))","996c3f59":"# class for dataset loading, labeling and augmentation\nclass Graphs(Dataset):\n    def __init__(self, dir_path, file_list, transform=None):\n        self.dir_path = dir_path\n        self.file_list = file_list\n        self.transform = transform\n        self.label_dict = {'just_image' : 0, 'bar_chart' : 1, 'diagram' : 2, \n                           'flow_chart' : 3, 'graph' : 4, 'growth_chart' : 5,\n                           'pie_chart' : 6, 'table' : 7}\n\n    def __len__(self):\n        return len(self.file_list)\n    \n    def __getitem__(self, idx):\n        image_name = os.path.join(self.dir_path, self.file_list[idx])\n        \n        if image_name.split('.')[::-1][0] == \"gif\":\n            gif = cv2.VideoCapture(image_name)\n            _, image = gif.read()\n        else:\n            image = cv2.imread(image_name)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        for name, label in self.label_dict.items():\n            if name in image_name.split('\/')[::-1][0]:\n                self.label = label\n                break\n\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n\n        return image, self.label","8e6afa0a":"# declaration of constant variables\nbatch_size = 128\nnum_workers = mp.cpu_count()\nimg_size = 224\nn_classes = 8","83ecb439":"# function that prepares dataset for further training\ndef prepare_datasets(dataset_dir, dataset_files):\n    # augmentation parameters for train\n    data_transforms = albumentations.Compose([\n        albumentations.Resize(img_size, img_size),\n        albumentations.HorizontalFlip(),\n        albumentations.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.10,\n                                        rotate_limit=15),\n        albumentations.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        pytorch.ToTensor()\n    ]) \n\n    dataset = Graphs(dataset_dir, dataset_files, transform=data_transforms)\n    \n    test_size = int(len(dataset) * 0.3)\n    train_set, test_set = random_split(dataset, \n                                  (len(dataset_files)-test_size, test_size))\n    \n    print(f'Train dataset length: {len(train_set)}')\n    print(f'Testset dataset length: {len(test_set)}')\n    \n    return train_set, test_set","bb78bc8f":"# get prepared datasets from files stored in directory\ntrain_set, test_set = prepare_datasets(dataset_dir, dataset_files)\n\n# create dataloaders for loading data in batches=128\ntrainloader = DataLoader(train_set, batch_size=batch_size,\n                         pin_memory=True, num_workers=num_workers, shuffle=True)\ntestloader = DataLoader(test_set, batch_size=batch_size,\n                        pin_memory=True, num_workers=num_workers)","1c888baa":"train_images, train_labels = map(list, zip(*[(X.size(), y) \n                                             for X, y in iter(train_set)]))\ntest_images, test_labels = map(list, zip(*[(X.size(), y) \n                                             for X, y in iter(test_set)]))","2372468b":"# plot bar chart to observe amount of images by classes in dataset\nclass_names = ['just_image', 'bar_chart', 'diagram', 'flow_chart', 'graph',\n               'growth_chart', 'pie_chart', 'table']\n\n_, train_counts = np.unique(train_labels, return_counts=True)\n_, test_counts = np.unique(test_labels, return_counts=True)\n\npd.DataFrame({'train': train_counts, 'test': test_counts},\n             index=class_names).plot.bar()\nplt.show()","7fd9aaa5":"# plot pie chart to observe proportion of classes in dataset\nfigure, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 10))\nax1.pie(train_counts, explode=(0, 0, 0, 0, 0, 0, 0, 0) , \n        labels=class_names, autopct='%1.1f%%')\nax1.set_title('Proportion of each observed category (Train)')\n\nax2.pie(test_counts, explode=(0, 0, 0, 0, 0, 0, 0, 0) , \n        labels=class_names, autopct='%1.1f%%')\nax2.set_title('Proportion of each observed category (Test)')\n\nplt.show()","7b1a1b0d":"# print images with labels\ntrain_samples, train_classes = next(iter(trainloader))\n\nfig = plt.figure(figsize=(16, 16))\nfig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\nfor i in range(25):\n    plt.subplot(5, 5, i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(np.transpose(train_samples[i], (1, 2, 0)), cmap=plt.cm.binary)\n    plt.xlabel(class_names[train_classes[i]])\nplt.show()","d965b7d2":"# class which uses DenseNet169 pretrained model\n# + added custom classifier in the last layer\nclass DenseNet169(nn.Module):\n    def __init__(self, output_features, num_units=512, drop=0.5,\n                 num_units1=512, drop1=0.5):\n        super().__init__()\n        model = torchvision.models.densenet169(pretrained=True)\n        n_inputs = model.classifier.in_features\n        model.classifier = nn.Sequential(\n                                nn.Linear(n_inputs, num_units),\n                                nn.ReLU(),\n                                nn.Dropout(p=drop),\n                                nn.Linear(num_units, num_units1),\n                                nn.ReLU(),\n                                nn.Dropout(p=drop1), \n                                nn.Linear(num_units1, output_features))\n        self.model = model\n        \n    def forward(self, x):\n        return self.model(x)","05950f1d":"# callback functions for models\n\n# DenseNet169\n# callback for Reduce on Plateau scheduler \nlr_scheduler = LRScheduler(policy='ReduceLROnPlateau',\n                                    factor=0.5, patience=1)\n# callback for saving the best on validation accuracy model\ncheckpoint = Checkpoint(f_params='best_model_densenet169.pkl',\n                                 monitor='valid_acc_best')\n# callback for freezing all layer of the model except the last layer\nfreezer = Freezer(lambda x: not x.startswith('model.classifier'))\n# callback for early stopping\nearly_stopping = EarlyStopping(patience=5)","322f75c4":"# NeuralNetClassifier for based on DenseNet169 with custom parameters\ndensenet = NeuralNetClassifier(\n    # pretrained DenseNet169 + custom classifier \n    module=DenseNet169,\n    module__output_features=n_classes,\n    # criterion\n    criterion=nn.CrossEntropyLoss,\n    # batch_size = 128\n    batch_size=batch_size,\n    # number of epochs to train\n    max_epochs=100,\n    # optimizer Adam used\n    optimizer=torch.optim.Adam,\n    optimizer__lr = 0.001,\n    optimizer__weight_decay=1e-6,\n    # shuffle dataset while loading\n    iterator_train__shuffle=True,\n    # load in parallel\n    iterator_train__num_workers=num_workers,\n    # stratified kfold split of loaded dataset\n    train_split=CVSplit(cv=5, stratified=True, random_state=42),\n    # callbacks declared earlier\n    callbacks=[lr_scheduler, checkpoint, freezer, early_stopping],\n    # use GPU or CPU\n    device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n)","503d1a13":"# fit prepared model with custom parameters\n\ndensenet.fit(train_set, y=np.array(train_labels))","30e0b3a8":"print('Accuracy: {:.5f}%'.format(densenet.score(test_set, test_labels) * 100))","36d17bd8":"pred_classes = np.array([])\nfor batch_idx, (X_test, y_test) in enumerate(testloader):\n    pred_classes = np.append(pred_classes, densenet.predict(X_test).tolist())\nprint('DenseNet169 prediction done!')","c97cd315":"# print images with labels\ntest_samples, test_classes = next(iter(testloader))\n\nfig = plt.figure(figsize=(16, 16))\nfig.suptitle(\"Some examples of images with predictions\", fontsize=16)\nfor i in range(25):\n    plt.subplot(5, 5, i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(np.transpose(test_samples[i], (1, 2, 0)), cmap=plt.cm.binary)\n    plt.xlabel(class_names[int(pred_classes[i])])\nplt.show()","aa32b3e5":"## Preparing datasets","7e286d8b":"## Seed environment","75aa8190":"## Training the models","644e29a3":"## Importing all necessary libraries","7f867430":"## Preparing models","5565890a":"## Downloading required things","5a2ff091":"## Exploring the data"}}