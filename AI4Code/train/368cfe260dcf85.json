{"cell_type":{"3370d206":"code","fb015074":"code","e942ece1":"code","49ff6a3b":"code","5687c092":"code","82ff8aeb":"code","eb4fad16":"code","b1a48eab":"code","16a2bcba":"code","8eb57760":"code","7f730413":"code","b067da01":"code","775a4f02":"code","0f443310":"code","20fff367":"code","03712986":"code","afb539a9":"code","7562ffe0":"code","05597b2c":"code","4d7ca639":"code","1a5e6e98":"code","f50acc9e":"code","5ae3b4dd":"code","e47e5118":"code","da7076ef":"code","90bfaf6f":"code","4cc87a41":"code","c53207d8":"code","7db8d59e":"code","31413fad":"code","800f1de9":"code","e848be38":"code","471f9f32":"code","22861dc7":"code","e6698abd":"code","6311ba01":"code","bb7ae608":"code","ab8bf6ab":"code","c48b0d4f":"code","b62fda7b":"code","f4f01134":"code","29466fd6":"markdown","c137b99e":"markdown","f13abe85":"markdown","d4f48a69":"markdown","27570a18":"markdown","66000c8d":"markdown"},"source":{"3370d206":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport cv2\nfrom tensorflow import keras\nimport tensorflow as tf\nimport keras\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.losses import binary_crossentropy\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.models import load_model\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.utils import image_dataset_from_directory\nimport PIL,gc,os,sys\nimport imageio","fb015074":"train_df = pd.read_csv('..\/input\/sartorius-cell-instance-segmentation\/train.csv')\nprint(train_df.shape)\ntrain_df.head(4)","e942ece1":"path = ''\nimage_path = os.path.join(path, '..\/input\/sartoriuscellinstancesegmentationmaskpng\/TrainImage2x2\/')\nmask_path = os.path.join(path, '..\/input\/sartoriuscellinstancesegmentationmaskpng\/TrainMask2x2\/')\nimage_list = sorted(os.listdir(image_path))\nmask_list = sorted(os.listdir(mask_path))\nimage_list = [image_path+i for i in image_list]\nmask_list = [mask_path+i for i in mask_list]\n#print(image_list)","49ff6a3b":"def rle_decode(mask_rle, shape, color=1):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background.\n    ref: https:\/\/www.kaggle.com\/inversion\/run-length-decoding-quick-start\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros((shape[0] * shape[1]), dtype=np.float32)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n    return img.reshape(shape)\n\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    ref: https:\/\/www.kaggle.com\/dragonzhang\/positive-score-with-detectron-3-3-inference\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef make_predictions(dataset, num, keras_model):\n    '''\n    For a tf.Dataset, makes predictions for n=num (num =-1 or all_images takes all images in the dataset), \n    images using a keras_model. Returns a list of predicted masks, each as ndarray. \n    '''\n    predictions = []\n    if dataset:\n        for image in dataset.take(num):\n            image = image[None]\n            pred_mask = keras_model.predict(image)\n            # changes shape from (1,512,512,1) to (512,512)\n            pred_mask = pred_mask[0, :, :, 0]\n            # fix overlaps\n            if check_overlap(msk=pred_mask)==True:\n                pred_mask = pred_mask[None]\n                pred_mask = fix_overlap(msk=pred_mask)\n            # transforms ndarray values to 0s and 1s\n            pred_mask =  np.where( pred_mask > 0.5, 1, 0)\n            predictions.append(pred_mask)\n    return predictions\n\ndef get_mask(image_id, df):\n    '''\n    Uses rle_decode() to get ndarray from mask using image_id in dataframe (df).\n    ref: https:\/\/www.kaggle.com\/barteksadlej123\/sartors-tf-starter\n    '''\n    current = df[df[\"id\"] == image_id]\n    labels = current[\"annotation\"].tolist()\n    \n    mask = np.zeros((HEIGHT, WIDTH))\n    for label in labels:\n        mask += rle_decode(label, (HEIGHT, WIDTH))\n    mask = mask.clip(0, 1)\n    \n    return mask\n\n\n#  fix overlaps: \n\ndef check_overlap(msk):\n    '''\n    Checks if there are overlap in a mask (msk).\n    ref: https:\/\/www.kaggle.com\/awsaf49\/sartorius-fix-overlap\n    '''\n    msk = msk.astype(np.bool).astype(np.uint8)\n    return np.any(np.sum(msk, axis=-1)>1)\n\n\ndef fix_overlap(msk):\n    '''\n    Args:\n        mask: multi-channel mask, each channel is an instance of cell, shape:(520,704,None)\n    Returns:\n        multi-channel mask with non-overlapping values, shape:(520,704,None) \n    ref: https:\/\/www.kaggle.com\/awsaf49\/sartorius-fix-overlap\n    '''\n    msk = np.array(msk)\n    msk = np.pad(msk, [[0,0],[0,0],[1,0]])\n    ins_len = msk.shape[-1]\n    msk = np.argmax(msk,axis=-1)\n    msk = tf.keras.utils.to_categorical(msk, num_classes=ins_len)\n    msk = msk[...,1:]\n    msk = msk[...,np.any(msk, axis=(0,1))]\n    return msk\n","5687c092":"len(image_list)","82ff8aeb":"image_list[0:4]","eb4fad16":"mask_list[0:4]","b1a48eab":"N = 1000\nimg = cv2.imread(image_list[N])\nmask = cv2.imread(mask_list[N],cv2.IMREAD_GRAYSCALE)\nprint(mask.shape)\n#mask = np.array([max(mask[i, j]) for i in range(mask.shape[0]) for j in range(mask.shape[1])]).reshape(img.shape[0], img.shape[1])\n\nfig, arr = plt.subplots(1, 2, figsize=(14, 10))\narr[0].imshow(img)\narr[0].set_title('Image')\narr[1].imshow(mask)\narr[1].set_title('Segmentation')","16a2bcba":"def rle_decode(mask_rle, shape, color=1):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros((shape[0] * shape[1], shape[2]), dtype=np.float32)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n    return img.reshape(shape)\n\n\ndef build_masks(labels,input_shape, colors=True):\n    height, width = input_shape\n    if colors:\n        mask = np.zeros((height, width, 3))\n        for label in labels:\n            mask += rle_decode(label, shape=(height,width , 3), color=np.random.rand(3))\n    else:\n        mask = np.zeros((height, width, 1))\n        for label in labels:\n            mask += rle_decode(label, shape=(height, width, 1))\n    mask = mask.clip(0, 1)\n    return mask\n\ndef rle2maskResize(rle):\n    # CONVERT RLE TO MASK \n    if (len(rle)==0): \n        return np.zeros((256,256) ,dtype=np.uint8)\n    \n    height= 520\n    width = 704\n    mask= np.zeros( width*height ,dtype=np.uint8)\n\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]-1\n    lengths = array[1::2]    \n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n    \n    return mask.reshape( (height,width), order='F' )[::2,::2]\n\ndef make_predictions(dataset, num, keras_model):\n    '''\n    For a tf.Dataset, makes predictions for n=num (num =-1 or all_images takes all images in the dataset), \n    images using a keras_model. Returns a list of predicted masks, each as ndarray. \n    '''\n    predictions = []\n    if dataset:\n        for image in dataset.take(num):\n            image = image[None]\n            pred_mask = keras_model.predict(image)\n            # changes shape from (1,512,512,1) to (512,512)\n            pred_mask = pred_mask[0, :, :, 0]\n            # fix overlaps\n            if check_overlap(msk=pred_mask)==True:\n                pred_mask = pred_mask[None]\n                pred_mask = fix_overlap(msk=pred_mask)\n            # transforms ndarray values to 0s and 1s\n            pred_mask =  np.where( pred_mask > 0.5, 1, 0)\n            predictions.append(pred_mask)\n    return predictions","8eb57760":"image_list_ds = tf.data.Dataset.list_files(image_list, shuffle=False)\nmask_list_ds = tf.data.Dataset.list_files(mask_list, shuffle=False)\n\nfor path in zip(image_list_ds.take(3), mask_list_ds.take(3)):\n    print(path)","7f730413":"image_filenames = tf.constant(image_list)\nmasks_filenames = tf.constant(mask_list)\n\ndataset = tf.data.Dataset.from_tensor_slices((image_filenames, masks_filenames))\n\nfor image, mask in dataset.take(5):\n    print(image)\n    print(mask)","b067da01":"def normalize(input_image, input_mask):\n    input_image = tf.cast(input_image, tf.float32) \/ 255.0\n    input_mask -= 1\n    return input_image, input_mask","775a4f02":"def load_image(input_image1, input_mask1):\n    input_image = tf.image.resize(input_image1, (512, 512))\n    input_mask = tf.image.resize(input_mask1, (512, 512))\n\n    input_image, input_mask = normalize(input_image, input_mask)\n\n    return input_image, input_mask","0f443310":"# constants\n\nDEBUG = False\n\nSEED = 123\nWIDTH, HEIGHT = 260, 352\nRESIZE_WIDTH, RESIZE_HEIGHT = 256, 256\nBATCH_SIZE = 32\nBUFFER_SIZE = 32\nVAL_SPLIT = 0.2\n\nAUTO = tf.data.AUTOTUNE\n\nEPOCHS = 20","20fff367":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(image_list, mask_list, test_size=VAL_SPLIT, random_state=SEED)\nprint(X_train[0:4])\nprint(y_train[0:4])","03712986":"X_train_ds = tf.data.Dataset.list_files(X_train, shuffle=False)\nX_test_ds = tf.data.Dataset.list_files(X_test, shuffle=False)\ny_train_ds = tf.data.Dataset.list_files(y_train, shuffle=False)\ny_test_ds = tf.data.Dataset.list_files(y_test, shuffle=False)","afb539a9":"X_train_filenames = tf.constant(X_train)\nX_test_filenames = tf.constant(X_test)\ny_train_filenames = tf.constant(y_train)\ny_test_filenames = tf.constant(y_test)\nprint(X_train_filenames)","7562ffe0":"###### tempimg = imageio.imread(X_train[1])\ntempmask = cv2.imread(y_train[1],cv2.IMREAD_GRAYSCALE)\ntempimg = cv2.imread(X_train[1])\nprint(tempmask.shape)\nprint(tempimg.shape)\ntempmask = cv2.resize(tempmask,(RESIZE_WIDTH,RESIZE_WIDTH))\ntempimg = cv2.resize(tempimg,(RESIZE_WIDTH,RESIZE_WIDTH))\nprint(tempmask.shape)\nprint(tempimg.shape)\nfig, arr = plt.subplots(1, 2, figsize=(14, 10))\narr[0].imshow(tempimg)\narr[0].set_title('Image')\narr[1].imshow(tempmask)\narr[1].set_title('Segmentation')","05597b2c":"def train_generator(X,y):\n    \n    for image_id in X:\n        image = cv2.imread(image_id) \n                \n        image = cv2.resize(image, (RESIZE_HEIGHT, RESIZE_WIDTH))\n        \n        image = image.astype(np.float32)\n    for image_id in y:\n        mask = cv2.imread(image_id,cv2.IMREAD_GRAYSCALE) \n        \n        \n        mask = cv2.resize(mask, (RESIZE_HEIGHT, RESIZE_HEIGHT))\n        mask = mask.reshape((*mask.shape, 1))\n        mask = mask.astype(np.int32)\n    yield image, mask","4d7ca639":"# use the generator to get training and validation sets\ntrain_ds = tf.data.Dataset.from_generator(\n    lambda : train_generator(X_train,y_train), \n    output_types=(tf.float32, tf.int32),\n    output_shapes=((RESIZE_HEIGHT, RESIZE_WIDTH,3), (RESIZE_HEIGHT, RESIZE_WIDTH,1)))\n\nvalid_ds = tf.data.Dataset.from_generator(\n    lambda : train_generator(X_test,y_test), \n    output_types=(tf.float32, tf.int32),\n    output_shapes=((RESIZE_HEIGHT, RESIZE_WIDTH,3), (RESIZE_HEIGHT, RESIZE_WIDTH,1)))","1a5e6e98":"class Augment(tf.keras.layers.Layer):\n    def __init__(self, seed=SEED):\n        super().__init__()\n    # both use the same seed, so they'll make the same random changes.\n        self.augment_inputs = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed)\n        self.augment_labels = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed)\n\n    def call(self, inputs, labels):\n        inputs = self.augment_inputs(inputs)\n        labels = self.augment_labels(labels)\n        return inputs, labels","f50acc9e":"# \"build the input pipeline, applying the augmentation after batching the inputs\"\n\ntrain_ds = (\n    train_ds\n    .shuffle(BUFFER_SIZE)\n    .batch(BATCH_SIZE)\n    .repeat()\n    .map(Augment())\n    .prefetch(AUTO))\n\nvalid_ds = (\n    valid_ds\n    .batch(BATCH_SIZE)\n    .repeat()\n    .prefetch(AUTO))","5ae3b4dd":"train_ds.take(2)","e47e5118":"def display(display_list):\n    plt.figure(figsize=(20, 20))\n\n    title = ['Input Image', 'True Mask','Predicted Mask']\n\n    for i in range(len(display_list)):\n        plt.subplot(1, len(display_list), i+1)\n        plt.title(title[i])\n        try:\n            plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n        except:\n            plt.imshow(display_list[i])\n        plt.axis('off')\n    plt.show()","da7076ef":"for images, masks in train_ds.take(2):\n    sample_image, sample_mask = images[0], masks[0]\n    print(sample_image.shape)\n    print(sample_mask.shape)\n    display([sample_image, sample_mask])","90bfaf6f":"from keras import backend as K\nfrom keras.losses import binary_crossentropy\nimport tensorflow as tf\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef iou_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n    iou = K.mean((intersection + smooth) \/ (union + smooth), axis=0)\n    return iou\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(tf.cast(y_true, tf.float32), y_pred) + 0.5 * dice_loss(tf.cast(y_true, tf.float32), y_pred)","4cc87a41":"# !pip download segmentation_models","c53207d8":"!pip install segmentation_models --no-index --find-links ..\/input\/cell-segmentation","7db8d59e":"import segmentation_models as sm\nsm.set_framework('tf.keras')\nsm.framework()","31413fad":"BACKBONE = 'resnet34'\npreprocess_input = sm.get_preprocessing(BACKBONE)","800f1de9":"train_ds = preprocess_input(train_ds)\nvalid_ds = preprocess_input(valid_ds)","e848be38":"from segmentation_models import Unet\nfrom segmentation_models.utils import set_trainable\n\n\nbase_model = Unet('efficientnetb3',input_shape=(256, 256, 3), classes=3, activation='sigmoid',encoder_weights='imagenet')\ninp = Input(shape=(256, 256, 3))\nl1 = base_model(inp)\nout = Conv2D(1, (1, 1))(l1) # map N channels data to 3 channels\nmodel = Model(inp, out, name=base_model.name)\nmodel.compile(optimizer='adam', loss=bce_dice_loss,metrics=[dice_coef,iou_coef,'accuracy']) #bce_dice_loss binary_crossentropy\nmodel.summary()\n","471f9f32":"# try out the model to check what it predicts before training\n\ndef create_mask(pred_mask):\n    pred_mask = tf.where(pred_mask > 0.5,1,0)\n    return pred_mask\n\n\ndef show_predictions(dataset=None, num=1):\n    if dataset:\n        for image, mask in dataset.take(num):\n            pred_mask = model.predict(image)\n            pred_mask = pred_mask.reshape((256,256,1))\n            display([image[0], mask[0], pred_mask])\n    else:\n        display([sample_image, sample_mask,\n                 create_mask(model.predict(sample_image[tf.newaxis, ...])[0])])\n\n        \nshow_predictions(train_ds)\n","22861dc7":"\nfrom keras.callbacks import Callback, ModelCheckpoint\ncheckpoint = ModelCheckpoint(\n    'model1.h5', \n    monitor='val_loss', \n    verbose=0, \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto'\n)\n\nhistory = model.fit(\n    train_ds,\n    validation_data=valid_ds,\n    steps_per_epoch=60,\n    validation_steps=10,\n    callbacks=[checkpoint],\n    use_multiprocessing=False,\n    workers=4,\n    epochs=10,\n    verbose = 1\n)\nhist_df = pd.DataFrame(history.history)\nhist_df.to_csv('history.csv')\n# PLOT TRAINING\nplt.figure(figsize=(15,5))\nplt.plot(range(history.epoch[-1]+1),history.history['val_iou_coef'],label='Val_iou_coef')\nplt.plot(range(history.epoch[-1]+1),history.history['iou_coef'],label='Trn_iou_coef')\nplt.title('IOU'); plt.xlabel('Epoch'); plt.ylabel('iou_coef');plt.legend(); \nplt.show()\n\n# PLOT TRAINING\nplt.figure(figsize=(15,5))\nplt.plot(range(history.epoch[-1]+1),history.history['val_iou_coef'],label='Val_iou_coef')\nplt.plot(range(history.epoch[-1]+1),history.history['iou_coef'],label='Trn_iou_coef')\nplt.title('IOU'); plt.xlabel('Epoch'); plt.ylabel('iou_coef');plt.legend(); \nplt.show()\n\nmodel.save('.\/model.h5')\n","e6698abd":"loaded_model = load_model('..\/input\/k\/pasanjayaweera\/cell-segmentation\/model.h5', compile = False)","6311ba01":"#model.save('.\/model.h5')","bb7ae608":"test_img = cv2.imread('..\/input\/sartoriuscellinstancesegmentationmaskpng\/TrainImage2x2\/0030fd0e6378_3.png')\ntrue_mask = cv2.imread('..\/input\/sartoriuscellinstancesegmentationmaskpng\/TrainMask2x2\/0030fd0e6378_3_mask.png')\ntest_img = cv2.resize(test_img,(256,256))\ntrue_mask = cv2.resize(true_mask,(256,256))\ntest_img1 = np.expand_dims(test_img,axis = 0)\npred_mask = loaded_model.predict(test_img1)\npred_mask = pred_mask.reshape((256,256,1))\ndisplay([test_img, true_mask, pred_mask])","ab8bf6ab":"test_path = '..\/input\/sartorius-cell-instance-segmentation\/test\/'\ntest_ids = [  os.path.join(test_path, each)  for each in os.listdir(test_path) if each.endswith('.png')]\ndef test_generator(image_ids):\n    for image_id in image_ids:\n        image = cv2.imread(image_id) \n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)        \n        image = cv2.resize(image, (RESIZE_HEIGHT, RESIZE_WIDTH))\n        image = image.astype(np.float32)\n        yield image\n        \n# test dataset from test data generator \ntest_ds = tf.data.Dataset.from_generator(\n    lambda : test_generator(test_ids), \n    output_types=(tf.float32),\n    output_shapes=((RESIZE_HEIGHT, RESIZE_WIDTH, 3)) )\n# test image ids and predictions\ntest_predictions = make_predictions(dataset=test_ds, num=len(test_ids), keras_model=model)\n","c48b0d4f":"# encode predections in the RL format\ntest_predictions = [rle_encode(mask) for mask in test_predictions] \n#print(test_predictions)","b62fda7b":"# transform full image paths to ids \nfrom pathlib import Path\ntest_ids = [Path(ID).stem for ID in test_ids]","f4f01134":"# generate submission data frame \nsubmisssion = pd.DataFrame.from_dict({'id': test_ids, 'predicted': test_predictions} )\nsubmisssion = submisssion.sort_values( ['id'], ascending=True )\nprint(submisssion.head(), 'n')\ncsv_output = os.path.join('.\/', 'submission.csv') \nsubmisssion.to_csv(csv_output, index=False)","29466fd6":"#### Visualize an image example and its corresponding mask from the dataset.","c137b99e":"#### Prediction and submission","f13abe85":"### 2.1 - Split Your Dataset into Unmasked and Masked Images","d4f48a69":"In addition, the image color values are normalized to the [0,1] range.","27570a18":"### Check out the some of the unmasked and masked images from the dataset:","66000c8d":"The following class performs a simple augmentation by randomly-flipping an image. Go to the Image augmentation tutorial to learn more."}}