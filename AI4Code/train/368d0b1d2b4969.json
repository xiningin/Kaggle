{"cell_type":{"59a04962":"code","9860990c":"code","4a2ee2f6":"code","649676ab":"code","64ddafbf":"code","6fa3d802":"code","3d1e22a5":"code","914a1b5a":"code","d4b718d3":"code","376aee67":"code","249854a6":"code","024fc6a8":"code","63b400c5":"code","2877a404":"code","482a249a":"code","d6cac594":"code","185b2f3c":"code","86ab45c4":"code","831d8823":"code","47f0545c":"code","cc355263":"code","d088a526":"markdown"},"source":{"59a04962":"import sys\nsys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')","9860990c":"import numpy as np\nimport pandas as pd \nimport os\nimport time \nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom collections import defaultdict\nfrom tqdm import tqdm\nfrom sklearn import model_selection, preprocessing \nimport cv2\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nimport copy\n\nimport torch \nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nfrom torch.utils.data import Dataset, DataLoader \nimport torchvision\nfrom torchvision import models, transforms \nfrom torch.cuda.amp import autocast, GradScaler\n","4a2ee2f6":"params = {\n    \"model\": \"efficientnet_b3\", #\"model\": \"resnet50\",\n    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n    \"lr\": 0.0001,\n    \"batch_size\": 4,\n    \"num_workers\": 16,\n    \"num_epochs\": 10,\n    \"T_0\":6, # CosineAnnealingWarmRestarts\n    \"min_lr\":1e-6\n}","649676ab":"ROOT_DIR = \"..\/input\/ranzcr-clip-catheter-line-classification\"\ntest_dir = \"..\/input\/ranzcr-clip-catheter-line-classification\/test\/\"\nmodel_path = \"..\/input\/ranzr-clip-train-pytorch\/\"","64ddafbf":"os.listdir(ROOT_DIR)","6fa3d802":"df = pd.read_csv(os.path.join(ROOT_DIR, \"sample_submission.csv\"))","3d1e22a5":"df.head(5)","914a1b5a":"len(df['StudyInstanceUID'].unique())","d4b718d3":"classes = df.columns[1:]","376aee67":"len(classes)","249854a6":"labels = df[classes]","024fc6a8":"labels","63b400c5":"#img_list = os.list_dir(os.path.join(ROOT_DIR, df[\"StudyInstanceUID\"]+\".jpg\"))","2877a404":"classes = ['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal', 'NGT - Abnormal',\n       'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal',\n       'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal',\n       'Swan Ganz Catheter Present']","482a249a":"class RANZRDataset(Dataset):\n    def __init__(self, data_dir, df, transform=None):\n        self.data_dir = data_dir\n        self.df = df\n        self.files = df[\"StudyInstanceUID\"].values\n        self.transform = transform\n        \n    def __getitem__(self, idx):\n        img_name = self.files[idx]\n        file_path = f\"{self.data_dir}{img_name}\"+\".jpg\"\n        image = Image.open(file_path).convert('RGB')\n        image = np.array(image)\n#         image = cv2.imread(file_path)\n#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        #print(file_path)\n        if self.transform:\n            augmented = self.transform(image = image)\n            image = augmented[\"image\"]\n        \n    \n        \n        return image\n    def __len__(self):\n        return len(self.df)\n        \n        ","d6cac594":"dataset = RANZRDataset(test_dir, df)\nimg = dataset[0]\nplt.imshow(img)\nplt.show()\nimg.shape","185b2f3c":"def get_valid_transform():\n    return A.Compose([\n        A.RandomResizedCrop(300, 300),\n        #A.Flip(0.5),\n        #A.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]),\n        ToTensorV2(),\n\n    ])","86ab45c4":"# import timm\n\n# class RANZRModel(nn.Module):\n#     def __init__(self, model_name=params[\"model\"], pretrained=False):\n#         super().__init__()\n#         self.model = timm.create_model(model_name, pretrained=pretrained)\n#         n_features = self.model.fc.in_features\n#         self.model.fc = nn.Linear(n_features, len(classes))\n\n#     def forward(self, x):\n#         x = self.model(x)\n#         return x\n#efficientnet\nimport timm\n#EFFICIENTNET-B7\nclass RANZRModel(nn.Module):\n    def __init__(self, model_name=params[\"model\"], pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, len(classes))\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","831d8823":"def inference(model,states, test_loader):\n    preds = []\n    model.to(\"cpu\")\n    for image in tqdm(test_loader, total = len(test_loader)):\n        avg_preds = []\n        image = image.to(\"cpu\").float()\n        for state in states:\n            model.load_state_dict(state)\n            model.eval() \n            with torch.no_grad():\n                y_preds = model(image)\n                avg_preds.append(y_preds.sigmoid().to('cpu').numpy())\n        avg_preds = np.mean(avg_preds, axis=0)\n        preds.append(avg_preds)\n\n    preds = np.concatenate(preds)\n    return preds","47f0545c":"models_weights = []\nfor file in os.listdir(model_path):\n    if file.endswith(\".pth\"):\n        models_weights.append(file)\nmodels_weights","cc355263":"model = RANZRModel(model_name=params[\"model\"], pretrained=False)\nmodel.to(\"cpu\")\nstates = [torch.load(f\"{model_path}{weights}\", map_location=torch.device('cpu')) for weights in models_weights] \n#states\ntest_dataset = RANZRDataset(test_dir, df, get_valid_transform())\ntest_loader = DataLoader(test_dataset, shuffle=False, pin_memory = True)\npredictions = inference(model, states, test_loader)\n\ndf[classes] = predictions\ndf[['StudyInstanceUID'] + classes].to_csv('.\/submission.csv', index=False)\ndf.head()\n","d088a526":"**Training noteebook can found here https:\/\/www.kaggle.com\/razatabish\/ranzr-clip**"}}