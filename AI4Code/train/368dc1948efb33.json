{"cell_type":{"be68317a":"code","39d4dfa7":"code","5ecd8512":"code","1a2db52f":"code","4689063e":"code","5a57fd94":"code","d52e1a53":"code","c3c86f26":"code","cd661a7e":"code","0b052d49":"code","ede0452f":"code","ae4ef20b":"code","9694ab25":"code","98faac2c":"code","90c39253":"code","284cf25f":"code","348cf44f":"code","f87cdadf":"code","8feb5cc8":"code","312ac0d4":"code","cee6af9e":"code","67e406a8":"code","74d90197":"code","5baec290":"code","4aaaf81e":"code","a8d2e3d2":"code","4cbdb8a3":"code","88f57192":"code","e63274ee":"code","42c52803":"code","cccf2996":"code","40694c7e":"code","f091182e":"code","d05eb33b":"code","8843d1a2":"code","56d55792":"code","5a8acc35":"code","6615e1c8":"code","29bd4ff5":"code","f3106e83":"code","29b5405b":"code","a675f7be":"code","29d344d1":"code","04aab750":"code","0b023646":"code","387f61b8":"code","fd2ba34e":"code","4413eeb6":"code","c9fb278c":"code","d7b65c5d":"code","bdefc238":"code","c3f7e864":"code","3cc0294e":"code","0f66254c":"code","c2f3b0bb":"code","56f0c579":"code","fbe78090":"code","fc53439f":"code","1930d787":"code","a0b9d4fe":"code","69cf2204":"code","dd97cad7":"code","4dd7c8af":"code","7227f952":"code","71a80d36":"code","687092ad":"code","8eac8850":"code","da101208":"code","88c97994":"code","eede2a13":"code","06da6913":"code","49db06a7":"code","175bc635":"code","c444e341":"markdown","09760e7f":"markdown","25e6cdf2":"markdown","e01342b0":"markdown","5e71c420":"markdown","b363db4a":"markdown","c7eb2c1c":"markdown","34b8b89b":"markdown","0b446ba4":"markdown","4d53a662":"markdown","656973c7":"markdown","a0b65f8e":"markdown","253418a0":"markdown","f7864f94":"markdown","56ca2691":"markdown","f3579819":"markdown","0fe64704":"markdown","30dee7d5":"markdown","f00b2d31":"markdown","8fe9e410":"markdown","7373533c":"markdown","b01eb53b":"markdown","65e9244a":"markdown","996c9fb6":"markdown","265fb05d":"markdown","117820c0":"markdown","463ad594":"markdown","6b0adec7":"markdown","6c80ec7b":"markdown","4265a4b2":"markdown","c8454018":"markdown","6e9654c2":"markdown","0f85c681":"markdown","e5398992":"markdown"},"source":{"be68317a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","39d4dfa7":"import re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n%matplotlib inline","5ecd8512":"train_df=pd.read_csv('..\/input\/titanic\/train.csv')\ntrain_df","1a2db52f":"train_df.info()","4689063e":"null_percent=train_df.isnull().sum()\/len(train_df)*100\nnull_percent.sort_values(ascending=False)","5a57fd94":"sns.heatmap(train_df.isnull(),yticklabels=False,cbar=False)","d52e1a53":"train_df.describe()","c3c86f26":"train_df.columns=map(str.lower,train_df.columns)\ntrain_df","cd661a7e":"train_df.groupby('survived').count().passengerid","0b052d49":"fig=px.sunburst(train_df,path=['sex','survived'],values='passengerid')\nfig.show()","ede0452f":"fig = px.violin(train_df, y=\"age\", x=\"sex\", color=\"survived\",points='all', box=False, hover_data=train_df.columns, range_y=[train_df.age.min()-.5, train_df.age.max()+.5])\nfig.show()","ae4ef20b":"fig = px.histogram(train_df, x=\"age\",y=\"survived\",color=\"pclass\", marginal=\"box\",hover_data=train_df.columns)\nfig.show()","9694ab25":"sns.countplot(data=train_df,x='pclass')","98faac2c":"sns.countplot(data=train_df,x='pclass',hue='survived')","90c39253":"sns.countplot(data=train_df,x='sex',hue='survived')","284cf25f":"train_df.ticket.describe()","348cf44f":"train_df.loc[train_df['ticket'] == '1601']\n","f87cdadf":"train_df.loc[train_df['ticket']=='CA. 2343']","8feb5cc8":"train_df.loc[train_df['name'].str.contains(\"Sage\")]\n","312ac0d4":"train_df['new_cabin'] = train_df.cabin.dropna().astype(str).str[0] \n","cee6af9e":"train_df.groupby(by=['new_cabin','pclass']).pclass.count()\n","67e406a8":"train_df.groupby(by='pclass').pclass.count()\n","74d90197":"train_df.loc[(train_df.survived==0) & (train_df['cabin'].isnull())].count()","5baec290":"train_df=train_df.drop(columns='new_cabin')","4aaaf81e":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(train_df.drop(columns=['survived']),train_df.survived,random_state=42)","a8d2e3d2":"def CExist(df):\n    df['cabin']=df['cabin'].fillna(0)\n    df.cabin=df.cabin.apply(lambda x: 0 if x==0 else 1)\n    return df\n    ","4cbdb8a3":"x_train=CExist(x_train)\nx_train","88f57192":"train_df['name'].apply(lambda name: name.split(',')[1].split('.')[0].strip()).value_counts()","e63274ee":"normalized_titles = {\"Capt\":\"o\",\n                     \"Col\":\"o\",\n                     \"Major\":\"o\",\n                     \"Jonkheer\":\"r\",\n                     \"Don\":\"r\",\n                     \"Sir\" :\"r\",\n                     \"Dr\":\"o\",\n                     \"Rev\":\"o\",\n                     \"the Countess\":\"r\",\n                     \"Dona\":\"r\",\n                     \"Mme\":\"Mrs\",\n                     \"Mlle\":\"Miss\",\n                     \"Ms\":\"Mrs\",\n                     \"Mr\" :\"Mr\",\n                     \"Mrs\" :\"Mrs\",\n                     \"Miss\":\"Miss\",\n                     \"Master\":\"Master\",\n                     \"Lady\":\"r\"}\ndef normalize_titles(df):\n    df['title']=df['name'].apply(lambda name:name.split(',')[1].split('.')[0].strip()).map(normalized_titles)\n    return df\n","42c52803":"x_train=normalize_titles(x_train)","cccf2996":"x_train","40694c7e":"train_df.name.apply(lambda x:len(x)).describe()","f091182e":"def name_length(df):\n    df['name_len']=df.name.apply(lambda x:1 if len(x)>25 else 0)\n    return df","d05eb33b":"x_train=name_length(x_train)\nx_train","8843d1a2":"def fill_age(trainset,testset=None):\n    if testset is None:\n        trainset=trainset.fillna(trainset.median())\n        return trainset\n    else:\n        testset=testset.fillna(trainset.age.median())\n        return testset","56d55792":"x_train = fill_age(x_train)\nx_train","5a8acc35":"def age_categorize(trainSet):\n  interval = (0, 5, 12, 18, 25, 35, 60, 100)\n  age_cat = ['babies', 'children', 'teenage', 'student', 'young', 'adult', 'senior']\n  trainSet[\"age_cat\"] = pd.cut(trainSet.age, interval, labels=age_cat)\n  return trainSet","6615e1c8":"x_train = age_categorize(x_train)\nx_train","29bd4ff5":"def family(df):\n    df['family']=df['sibsp']+df['parch']\n    df['family']=df['family'].apply(lambda x:1 if x>0 else 0)\n    return df","f3106e83":"x_train=family(x_train)\nx_train","29b5405b":"def fare_categorize(trainSet):\n  quant = (-1, 0, 8, 15, 31, 600)\n  label_quants = ['NoInf', 'quart_1', 'quart_2', 'quart_3', 'quart_4']\n  trainSet[\"fare_cat\"] = pd.cut(trainSet.fare, quant, labels=label_quants)\n  return trainSet","a675f7be":"x_train=fare_categorize(x_train)\n","29d344d1":"x_train","04aab750":"def get_dummies_t(dataFrame):\n  for column in dataFrame.columns:\n    if (dataFrame[column].nunique()<10  and dataFrame[column].dtype==np.dtype('O')) or (dataFrame[column].nunique()<10 and dataFrame[column].nunique()>2):\n      if column == \"sibsp\" or column == \"parch\" or column == \"ticket_token\":\n        continue\n      if column == \"title\":\n        dataFrame = dataFrame.join(pd.get_dummies(dataFrame[column], prefix=column))\n        dataFrame.drop(columns=column, inplace = True)\n        continue\n      dataFrame = dataFrame.join(pd.get_dummies(dataFrame[column], prefix=column, drop_first=True))\n      dataFrame.drop(columns=column, inplace = True)\n  return dataFrame","0b023646":"x_train=get_dummies_t(x_train)\nx_train","387f61b8":"def drop_text(dataFrame):\n  for column in dataFrame.columns:\n    if dataFrame[column].dtype==object:\n      dataFrame.drop(columns=column, inplace = True)\n  return dataFrame","fd2ba34e":"x_train=drop_text(x_train)","4413eeb6":"x_train","c9fb278c":"from sklearn.preprocessing import StandardScaler\n\ndef scale_test(x_train,x_test=None):\n    scaler=StandardScaler()\n    scaler.fit(x_train)\n    if x_test is None:\n        return pd.DataFrame(scaler.transform(x_train),columns=x_train.columns)\n    return pd.DataFrame(scaler.transform(x_test),columns=x_test.columns)","d7b65c5d":"#x_train=scale_test(x_train)","bdefc238":"x_train","c3f7e864":"def prepare_test(x_train, x_test):\n  x_test = CExist(x_test)\n  x_test = normalize_titles(x_test)\n  x_test = name_length(x_test)\n  x_test = fill_age(x_train, x_test)\n  x_test = age_categorize(x_test)\n  x_test = fare_categorize(x_test)\n  x_test = family(x_test)\n  x_test = get_dummies_t(x_test)\n  x_test = drop_text(x_test)\n  #x_test = scale_test(x_train, x_test)\n\n  return x_test","3cc0294e":"prepare_test(x_train,x_test)","0f66254c":"from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n\ndef classification_metrics(y_test,predict):\n    print(\"Confusion Matrix:\\n\")\n    print(confusion_matrix(y_test,predict))\n    print(\"\\nAccuracy: \",accuracy_score(y_test,predict))\n    print(\"\\nClassification report:\\n\")\n    print(classification_report(y_test,predict))","c2f3b0bb":"from sklearn.linear_model import RidgeClassifier\n\nrc= RidgeClassifier(class_weight=None, solver='auto', fit_intercept=True,tol=0.001)\nrc.fit(x_train,y_train)\npredict=pd.DataFrame(data=rc.predict(prepare_test(x_train,x_test)),index=x_test.index)","56f0c579":"classification_metrics(y_test,predict)","fbe78090":"from sklearn.linear_model import LogisticRegression\n\nlr=LogisticRegression(max_iter=10000,random_state=0)\nlr.fit(x_train,y_train)\npredict=pd.DataFrame(data=lr.predict(prepare_test(x_train,x_test)),index=x_test.index)\nclassification_metrics(y_test,predict)","fc53439f":"from sklearn.svm import SVC\nsvC=SVC(random_state=0)\nsvC.fit(x_train,y_train)\npredict=pd.DataFrame(data=svC.predict(prepare_test(x_train, x_test)),index=x_test.index)\nclassification_metrics(y_test,predict)","1930d787":"from sklearn.tree import DecisionTreeClassifier\ndtc=DecisionTreeClassifier(random_state=0)\ndtc.fit(x_train,y_train)\npredict=pd.DataFrame(data=dtc.predict(prepare_test(x_train,x_test)),index=x_test.index)\nclassification_metrics(y_test,predict)","a0b9d4fe":"from sklearn.ensemble import ExtraTreesClassifier\netc=ExtraTreesClassifier(random_state=0, n_estimators=10)\netc.fit(x_train,y_train)\npredict=pd.DataFrame(data=etc.predict(prepare_test(x_train,x_test)),index=x_test.index)\nclassification_metrics(y_test,predict)","69cf2204":"from sklearn.ensemble import RandomForestClassifier\nrfC = RandomForestClassifier(criterion='entropy', max_depth= 8, max_leaf_nodes=20, min_samples_leaf=4, n_estimators= 600, random_state=0)\n\nrfC.fit(x_train, y_train)\npredict = pd.DataFrame(data=rfC.predict(prepare_test(x_train, x_test)), index = x_test.index)\nclassification_metrics(y_test, predict)","dd97cad7":"from sklearn.ensemble import AdaBoostClassifier\n\nabC = AdaBoostClassifier(random_state=0, n_estimators=7, learning_rate=0.9)\nabC.fit(x_train, y_train)\npredict = pd.DataFrame(data=abC.predict(prepare_test(x_train, x_test)), index = x_test.index)\nclassification_metrics(y_test, predict)","4dd7c8af":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbC = GradientBoostingClassifier(random_state=0, n_estimators=10)\ngbC.fit(x_train, y_train)\npredict = pd.DataFrame(data=gbC.predict(prepare_test(x_train, x_test)), index = x_test.index)\nclassification_metrics(y_test, predict)","7227f952":"from xgboost import XGBClassifier\n\nxgB = XGBClassifier(random_state=0)\nxgB.fit(x_train, y_train)\npredict = pd.DataFrame(data=xgB.predict(prepare_test(x_train, x_test)), index = x_test.index)\nclassification_metrics(y_test, predict)","71a80d36":"#Importing the auxiliar and preprocessing librarys \nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.model_selection import train_test_split, KFold, cross_validate\nfrom sklearn.metrics import accuracy_score\n\n#Models\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import RidgeClassifier, SGDClassifier, LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier, RandomTreesEmbedding\n\nclfs = []\nseed = 3\n\nclfs.append((\"LogReg\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"LogReg\", LogisticRegression())])))\n\nclfs.append((\"XGBClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"XGB\", XGBClassifier())]))) \nclfs.append((\"KNN\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"KNN\", KNeighborsClassifier())]))) \n\nclfs.append((\"DecisionTreeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"DecisionTrees\", DecisionTreeClassifier())]))) \n\nclfs.append((\"RandomForestClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RandomForest\", RandomForestClassifier())]))) \n\nclfs.append((\"GradientBoostingClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"GradientBoosting\", GradientBoostingClassifier(max_features=15, n_estimators=150))]))) \n\nclfs.append((\"RidgeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RidgeClassifier\", RidgeClassifier())])))\n\nclfs.append((\"BaggingRidgeClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"BaggingClassifier\", BaggingClassifier())])))\n\nclfs.append((\"ExtraTreesClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"ExtraTrees\", ExtraTreesClassifier())])))\n\n#'neg_mean_absolute_error', 'neg_mean_squared_error','r2'\nscoring = 'accuracy'\nn_folds = 10\n\nresults, names  = [], [] \nparams = []\nfor name, model  in clfs:\n    #kfold = KFold(n_splits=n_folds, random_state=seed, shuffle=True)\n    cv_results = cross_val_score(model, x_train, y_train, cv= 5, scoring=scoring, n_jobs=-1)    \n    params.append(model.get_params)\n    names.append(name)\n    results.append(cv_results)    \n    msg = \"%s: %f (+\/- %f)\" % (name, cv_results.mean(),  cv_results.std())\n    print(msg)","687092ad":"params\n","8eac8850":"testData=pd.read_csv('..\/input\/titanic\/test.csv')\nsub=pd.read_csv('..\/input\/titanic\/gender_submission.csv',index_col='PassengerId')\ntestData.columns=map(str.lower,testData.columns)\nprepare_test(x_train,testData)","da101208":"accuracies = []\nfor model in [rc, lr, svC, dtc, etc, rfC, abC, gbC, xgB]:\n  predict = model.predict(prepare_test(x_train, testData))\n  accuracies.append((accuracy_score(sub, predict), model))\nsorted(accuracies, key=lambda x: x[0])[-1]","88c97994":"accuracies","eede2a13":"testData['Survived']=abC.predict(prepare_test(x_train,testData))","06da6913":"testData","49db06a7":"testData.rename(columns={\"passengerid\":\"PassengerId\"},inplace=True)","175bc635":"testData[[\"PassengerId\",\"Survived\"]].to_csv(\"submission.csv\",index=False)","c444e341":"The Age column has 177 missing values while Cabin has 687 missing values and embark column has 2 missing values.Lets see the percentages.","09760e7f":"# **DATA CLEANING AND FEATURE SELECTION**","25e6cdf2":"Lets rename the columns for simplicity as all in lower case letters.","e01342b0":"**Sex**","5e71c420":"**Fill Age**","b363db4a":"**Logistic Regression**","c7eb2c1c":"**Random Forest Classifier**","34b8b89b":"**AdaBoost**","0b446ba4":"**Drop Text Columns**","4d53a662":"**Title** ","656973c7":"# **Data Visualization**","a0b65f8e":"**ExtraTreesClassifier**","253418a0":"**Gradient Boosting**","f7864f94":" **Train Test Split**","56ca2691":"# **Exploratory Data Analysis**","f3579819":"**CLASS**","0fe64704":"**Cabin**","30dee7d5":"# **Final Prediction**","f00b2d31":"# **Test Preperation**","8fe9e410":"**Ridge Classifier**","7373533c":"**Fare Categories**","b01eb53b":"How many people lived and how many people died?","65e9244a":"The affect of the age and sex towards death or survived.","996c9fb6":"The affect of the class and age on survival.","265fb05d":"**Name Lenght**","117820c0":"The knowledge of the cabin of the passenger directly has an influence on survival rate therefore, the cabin knowledge can be changed with 1 and 0 which are representing known or unknown.","463ad594":"**SVM**","6b0adec7":"**XGBoost**","6c80ec7b":"**Encoding Categorical Data**","4265a4b2":"**Decision Tree**","c8454018":"**Age Groups**","6e9654c2":"# **Model Training**","0f85c681":"At first we should examine the data.","e5398992":"**Family Boarded**"}}