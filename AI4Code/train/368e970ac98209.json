{"cell_type":{"fbd62fd7":"code","d84afd54":"code","09f238db":"code","d9c43a96":"code","3fcb02ba":"code","3268ce2d":"code","05bb7ce1":"code","4f7c1560":"markdown"},"source":{"fbd62fd7":"out_size = 640","d84afd54":"import os\n\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm.auto import tqdm\nfrom pathos.multiprocessing import ProcessingPool as Pool\nfrom functools import partial","09f238db":"import numpy as np\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\ndef read_xray(path, voi_lut = True, fix_monochrome = True):\n    # Original from: https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n    # \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n               \n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n        \n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n        \n    return data","d9c43a96":"def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n    # Original from: https:\/\/www.kaggle.com\/xhlulu\/vinbigdata-process-and-resize-to-image\n    im = Image.fromarray(array)\n    \n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n    \n    return im\n\n\ndef worker(filepath, save_dir, load_dir, out_size=out_size):\n    xray = read_xray(load_dir + filepath)\n    im = resize(xray, size=out_size, keep_ratio=True)\n    im.save(save_dir + filepath.replace('dicom', 'png'))\n    return xray.shape\n\n\ndef worker_train(filepath, worker_fn):\n    shape = worker_fn(filepath)\n    return (filepath.replace('.dicom', ''), *shape[:2])","3fcb02ba":"image_id = []\ndim0 = []\ndim1 = []\nfor split in ['train', 'test']:\n    load_dir = f'..\/input\/vinbigdata-chest-xray-abnormalities-detection\/{split}\/'\n    save_dir = f'\/kaggle\/tmp\/{split}\/'\n\n    os.makedirs(save_dir, exist_ok=True)\n    \n    worker_fn = partial(worker, save_dir=save_dir, load_dir=load_dir)\n    cur_worker_fn = partial(worker_train, worker_fn=worker_fn) if split == 'train' else worker_fn\n    with Pool(12) as p:\n        results = p.map(cur_worker_fn, os.listdir(load_dir))\n    if split == 'train':\n        for img_id, *cur_dim in results:\n            image_id.append(img_id)\n            dim0.append(cur_dim[0])\n            dim1.append(cur_dim[1])\n\n    # for file in tqdm(os.listdir(load_dir)):\n    #     # set keep_ratio=True to have original aspect ratio\n        ","3268ce2d":"%%time\n!tar -zcf train.tar.gz -C \"\/kaggle\/tmp\/train\/\" .\n!tar -zcf test.tar.gz -C \"\/kaggle\/tmp\/test\/\" .","05bb7ce1":"df = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1})\ndf.to_csv('train_meta.csv', index=False)","4f7c1560":"**By using the output of this notebook, you are accepting the [competition rules](https:\/\/www.kaggle.com\/c\/vinbigdata-chest-xray-abnormalities-detection\/rules).**\n\n\n## References\n\n- Monochrome fix and scaling: https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n- Resizing and saving image: https:\/\/www.kaggle.com\/xhlulu\/vinbigdata-process-and-resize-to-image"}}