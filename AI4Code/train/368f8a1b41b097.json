{"cell_type":{"caa1d8c5":"code","73e96918":"code","2ddc4b1e":"code","031688b2":"code","eeba0dc5":"code","76493283":"code","0442b651":"code","d500f26f":"code","3bf31cc8":"code","94c7e386":"code","8844e9da":"code","fa5cc575":"code","199a217d":"code","2bca41f8":"code","4a470ccc":"code","9f2e4cb8":"code","eff32be8":"code","eb369e1d":"markdown","9340bf47":"markdown","9c123eff":"markdown"},"source":{"caa1d8c5":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Flatten, Dense, Dropout ,BatchNormalization\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras.models import load_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras import models\n\nimport pandas as pd\nimport numpy as np\nimport time\nimport datetime\nimport matplotlib.pyplot as plt","73e96918":"train_images = 40591 #number of train images\nval_images = 10101 #number of validation images\ntrain_batchsize = 50 #number of train images in each batch\nval_batchsize = 50 #number of validation images in each batch\nimg_shape=(224,224) #image shape","2ddc4b1e":"#since the dataset is huge, we use generators to train the model\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\nx_train = train_datagen.flow_from_directory(\n    directory=r'..\/input\/flower-datatree\/datatree\/train\/', #location of train images\n    batch_size=train_batchsize,\n    target_size=img_shape,\n    class_mode=\"categorical\", #classification \n    shuffle=True, #shuffling the train images\n    seed=42 #seed for the shuffle\n)\n\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255)\nx_validation = validation_datagen.flow_from_directory(\n    directory=r'..\/input\/flower-datatree\/datatree\/validation\/', #location of validation images\n    batch_size=val_batchsize,\n    target_size=img_shape,\n    class_mode=\"categorical\", #classification\n    shuffle=True, #shuffling the validation images\n    seed=42 #seed for the shuffle\n)\n","031688b2":"#building the model architecture\n\nmodel = Sequential()\n\nmodel.add(ResNet50(include_top=False, pooling='avg', weights='imagenet'))\n\nmodel.add(Dense(102, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n\nmodel.summary()","eeba0dc5":"train_steps=int(np.ceil(train_images\/\/train_batchsize)) #number of steps for training the model\nval_steps=int(np.ceil(val_images\/\/val_batchsize)) #number of steps for validating the model\nprint(train_steps,val_steps)","76493283":"early_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, verbose=1, mode='auto')\n# Reducing the learning Rate if result is not improving\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', min_delta=0.0004, patience=2, factor=0.1, min_lr=1e-6, mode='auto',verbose=1)\n","0442b651":"savepath=\"flowermodel.hdf5\"\ncheckpoint = ModelCheckpoint(savepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max') \n#saves the model only with the highest validation accuracy","d500f26f":"start=time.time()\ncnn=model.fit_generator(x_train,steps_per_epoch = train_steps,validation_data=x_validation,validation_steps = val_steps,epochs=20,callbacks=[early_stop, reduce_lr , checkpoint],verbose=1)  \nend=time.time()\n\nprint('training time: '+str(datetime.timedelta(seconds=(end-start))))","3bf31cc8":"#accuracy\nprint(cnn.history.keys())\nplt.plot(cnn.history['acc'])\nplt.plot(cnn.history['val_acc'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.plot(np.argmax(cnn.history[\"val_acc\"]), np.max(cnn.history[\"val_acc\"]), marker=\"x\", color=\"r\",label=\"best model\")\nplt.legend(['Training set', 'Test set','best'], loc='upper left')\nplt.show()\n\n#loss\nplt.plot(cnn.history['loss'])\nplt.plot(cnn.history['val_loss'])\nplt.title('Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Training set', 'Test set'], loc='upper left')\nplt.show()","94c7e386":"test_datagen = ImageDataGenerator(rescale=1.\/255)\nx_test = test_datagen.flow_from_directory(\n    directory=r'..\/input\/flower-datatree\/datatree\/',\n    target_size=img_shape,\n    classes=['test'],\n    batch_size=1,\n    shuffle=False\n)","8844e9da":"test_images = 2009\n\ntest_stepsize = test_images\nx_test.reset() #\npredict = model.predict_generator(x_test ,steps=test_stepsize , verbose=1)\nprint(predict)","fa5cc575":"predict.shape","199a217d":"predictions=[] #saving all the prediction on the test images\nfor i in predict:\n    predictions.append(np.argmax(i)+1)","2bca41f8":"#undoing the sorting of the categories caused by ImageDataGenerator\n####very very important####\nactual=[str(i) for i in range(1,103)]\ngen=sorted(actual)\n\nlabels={}\n\nfor i in range(1,103):\n    labels[i]=int(gen[i-1])\nn_predictions=[]\nfor i in predictions:\n    n_predictions.append(labels[i])\n\npredictions = n_predictions","4a470ccc":"from collections import Counter\nfreq=Counter()\nfreq.update(predictions)","9f2e4cb8":"import matplotlib.pylab as plt\n\nlists = sorted(freq.items()) # sorted by key, return a list of tuples\nx, y = zip(*lists) # unpack a list of pairs into two tuples\nplt.figure(figsize=(20,5))\nplt.bar(x, y)\nplt.xlabel('category')\nplt.ylabel('number of images')\nplt.title(\"test results\")\nplt.show()","eff32be8":"names=[i for i in range(18540,20549)]\nresults = pd.Series(predictions,name = \"category\")\nnames=pd.Series(names,name = \"image_id\")\nsubmission = pd.concat([names,results],axis = 1)\nsubmission.to_csv(\"output.csv\",index=False)","eb369e1d":"This was a hackerearth challenge\n\nGiven a large class of flowers, 102 to be precise. Build a flower classification model which is discriminative between classes but can correctly classify all flower images belonging to the same class. There are a total of 20549 (train + test) images of flowers. Predict the category of the flowers present in the test folder with good accuracy.\n","9340bf47":"# **Predciting test data using the trained model**","9c123eff":"# **Flower Classification CNN**"}}