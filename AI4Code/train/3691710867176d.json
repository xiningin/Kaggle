{"cell_type":{"9cee4039":"code","f7c09c06":"code","b6b7740c":"code","6d54ac90":"code","59c7ecb6":"code","259f358a":"code","83dfa492":"code","0c88689a":"code","e09a3d6c":"code","90bd41a8":"code","e5491035":"code","79f36716":"code","cf4276ac":"code","9a191c9d":"code","9b62f023":"code","7cfd8a1f":"code","3f8e309a":"code","987e9aaa":"code","25080a65":"code","407ef2f7":"code","3d9b55e5":"code","b91557e7":"code","a3dcd077":"code","29ecd303":"code","b504a724":"code","2bc1312f":"code","5ad402da":"code","81a74931":"code","eccef0f0":"code","dc9283bc":"code","f1f943cc":"code","6608bfa1":"code","7faa0320":"code","d028c87c":"code","b65a5bb6":"code","1f528947":"markdown","ea4b5105":"markdown","f661fa8b":"markdown","a719181c":"markdown","ab70e1a1":"markdown","3e3885c8":"markdown","ceb6df46":"markdown","9d0e1a0b":"markdown","7db6fb66":"markdown","83292a1a":"markdown","e7824f4b":"markdown","67d10701":"markdown","16c25522":"markdown","bb7adb94":"markdown","5eed3128":"markdown"},"source":{"9cee4039":"import matplotlib.pyplot as plt \nimport numpy as np \nimport os \nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\n\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n","f7c09c06":"df = pd.read_csv(\"..\/input\/real-time-advertisers-auction\/Dataset.csv\")","b6b7740c":"df.tail(n=5)","6d54ac90":"#calculating CPM\n#calculating the value that the Advertisers Bid for the month of June\n# CPM(the value which was the winning bid value) = \n#((revenue of the publisher*100)\/revenue_share_percentage)\/measurable_impressions)*1000\n\n\ndef weird_division(n, d):\n    return n \/ d if d else 0\n\ndf['CPM'] = df.apply(lambda x: weird_division(((x['total_revenue']*100)),x['measurable_impressions'])*1000 , axis=1)\n","59c7ecb6":"#we can remove integration type as it has only one value and revenue share percent as that we have already used and \n#is only one single value as well\ndf.drop(['integration_type_id' , 'revenue_share_percent'], axis = 1, inplace=True)","259f358a":"# we can remove total impressions as well as that is account the same information as measurable impressions \n# also let us try to see if viewable\/measurable impressions are corellated to revenue or not \n\ndf['View\/measurable'] = df.apply(lambda x: weird_division(x['viewable_impressions'],x['measurable_impressions']) , axis=1)\n","83dfa492":"df.drop([ 'total_impressions'], axis = 1, inplace=True)","0c88689a":"df.isnull().sum()","e09a3d6c":"# There're three parts. But actually four. The train set will be divided on 2 parts (train and val). \n# Also we have test_df and part of dataset for generating some encodings.\n\ntrain_df = df[(df.date < \"2019-06-22 00:00:00\") & (df.date >= \"2019-06-11 00:00:00\")]\n\n\ntest_df = df[(df.date >= \"2019-06-22 00:00:00\") ]\n\nstats = df[df.date < \"2019-06-11 00:00:00\"]\n\n","90bd41a8":"\ntrain_df = train_df[train_df['CPM'].between(0,  train_df['CPM'].quantile(.95))]\n\ntest_df = test_df[test_df['CPM'].between(0,  test_df['CPM'].quantile(.95))]\nstats = stats[stats['CPM'].between(0,  stats['CPM'].quantile(.95))]","e5491035":"print(\"Train_df dates: \" , np.unique(train_df.date))\n\nprint(\"Test_df dates: \" , np.unique(test_df.date))\nprint(\"Stats_df dates: \" , np.unique(stats.date))","79f36716":"print(train_df.shape)\n\nprint(test_df.shape)\nprint(stats.shape)","cf4276ac":"stats.info()","9a191c9d":"def add_target_encoding(train_df, stats, col_name, target_n):\n    \n    stats_temp_mean = stats.groupby(col_name).mean()[target_n].reset_index()\n    stats_temp_mean.columns = [col_name,  '{0}_{1}_agg'.format(target_n, col_name)]\n    \n    stats_temp_sum = stats.groupby(col_name).sum()[target_n].reset_index()\n    stats_temp_sum.columns = [col_name,  '{0}_{1}_sum'.format(target_n, col_name)]\n    \n    stats_temp_std = stats.groupby(col_name).std()[target_n].reset_index()\n    stats_temp_std.columns = [col_name,  '{0}_{1}_std'.format(target_n, col_name)]\n    \n    stats_temp_max = stats.groupby(col_name).max()[target_n].reset_index()\n    stats_temp_max.columns = [col_name,  '{0}_{1}_max'.format(target_n, col_name)]\n    \n    train_df = pd.merge(train_df, stats_temp_mean, how='left', left_on=col_name, right_on=col_name)\n    train_df = pd.merge(train_df, stats_temp_sum, how='left', left_on=col_name, right_on=col_name)\n    train_df = pd.merge(train_df, stats_temp_std, how='left', left_on=col_name, right_on=col_name)\n    train_df = pd.merge(train_df, stats_temp_max, how='left', left_on=col_name, right_on=col_name)\n\n    return train_df","9b62f023":"def two_features_encoding(train_df, stats, col1, col2, target_n):\n    \n    stats_temp_mean = stats.groupby([col1, col2]).mean()[target_n].reset_index()\n    stats_temp_mean.columns = [col1, col2, 'combined_{0}_{1}_{2}_agg'.format(target_n, col1, col2)]\n    \n    stats_temp_sum = stats.groupby([col1, col2]).sum()[target_n].reset_index()\n    stats_temp_sum.columns = [col1, col2,  'combined_{0}_{1}_{2}_sum'.format(target_n, col1, col2)]\n\n\n    train_df = pd.merge(train_df, stats_temp_mean, how='left', left_on=[col1, col2], right_on=[col1, col2])\n\n    train_df = pd.merge(train_df, stats_temp_sum, how='left', left_on=[col1, col2], right_on=[col1, col2])\n    \n    return train_df","7cfd8a1f":"train_df = add_target_encoding(train_df, stats, \"site_id\", 'CPM')\ntrain_df = add_target_encoding(train_df, stats, \"ad_type_id\", 'CPM')\ntrain_df = add_target_encoding(train_df, stats, \"geo_id\", 'CPM')\ntrain_df = add_target_encoding(train_df, stats, \"device_category_id\", 'CPM')\ntrain_df = add_target_encoding(train_df, stats, \"advertiser_id\", 'CPM')\ntrain_df = add_target_encoding(train_df, stats, \"line_item_type_id\", 'CPM')\ntrain_df = add_target_encoding(train_df, stats, \"os_id\", 'CPM')\ntrain_df = add_target_encoding(train_df, stats, \"monetization_channel_id\", 'CPM')\ntrain_df = add_target_encoding(train_df, stats, \"ad_unit_id\", 'CPM')\ntrain_df = add_target_encoding(train_df, stats, \"order_id\", 'CPM')\n\n\ntest_df = add_target_encoding(test_df, stats, \"site_id\", 'CPM')\ntest_df = add_target_encoding(test_df, stats, \"ad_type_id\", 'CPM')\ntest_df = add_target_encoding(test_df, stats, \"geo_id\", 'CPM')\ntest_df = add_target_encoding(test_df, stats, \"device_category_id\", 'CPM')\ntest_df = add_target_encoding(test_df, stats, \"advertiser_id\", 'CPM')\ntest_df = add_target_encoding(test_df, stats, \"line_item_type_id\", 'CPM')\ntest_df = add_target_encoding(test_df, stats, \"os_id\", 'CPM')\ntest_df = add_target_encoding(test_df, stats, \"monetization_channel_id\", 'CPM')\ntest_df = add_target_encoding(test_df, stats, \"ad_unit_id\", 'CPM')\ntest_df = add_target_encoding(test_df, stats, \"order_id\", 'CPM')\n\n","3f8e309a":"train_df = two_features_encoding(train_df, stats, \"device_category_id\",'os_id', 'CPM')\ntrain_df = two_features_encoding(train_df, stats, \"ad_type_id\", 'os_id', 'CPM')\ntrain_df = two_features_encoding(train_df, stats, \"device_category_id\",\"ad_type_id\", 'CPM')\ntrain_df = two_features_encoding(train_df, stats, \"site_id\",\"ad_unit_id\", 'CPM')\ntrain_df = two_features_encoding(train_df, stats, \"monetization_channel_id\",\"device_category_id\", 'CPM')\ntrain_df = two_features_encoding(train_df, stats, \"ad_unit_id\", \"geo_id\", 'CPM')\n\ntest_df = two_features_encoding(test_df, stats, \"device_category_id\",'os_id', 'CPM')\ntest_df = two_features_encoding(test_df, stats, \"ad_type_id\", 'os_id', 'CPM')\ntest_df = two_features_encoding(test_df, stats, \"device_category_id\",\"ad_type_id\", 'CPM')\ntest_df = two_features_encoding(test_df, stats, \"site_id\",\"ad_unit_id\", 'CPM')\ntest_df = two_features_encoding(test_df, stats, \"monetization_channel_id\",\"device_category_id\", 'CPM')\ntest_df = two_features_encoding(test_df, stats, \"ad_unit_id\", \"geo_id\", 'CPM')","987e9aaa":"def uniq_row(df, stats, target_n):\n    \"\"\"\n    This function takes one last row from stats_df having the same features and takes its CPM.\n    \"\"\"\n    cols = ['site_id', 'ad_type_id', 'geo_id',\n                                     'device_category_id', 'advertiser_id',\n                                     'order_id', 'line_item_type_id', 'os_id',\n                             'monetization_channel_id', 'ad_unit_id']\n\n    stats_temp_mean = stats.drop_duplicates(subset=cols, keep='last')\n    stats_temp_mean =stats_temp_mean[cols + [ 'CPM']]                           \n    stats_temp_mean.columns = cols + [ 'unique_values_mean']\n    df = pd.merge(df, stats_temp_mean, how='left', left_on=cols, right_on=cols)\n        \n    return df","25080a65":"train_df =  uniq_row(train_df, stats, \"CPM\")   \ntest_df =  uniq_row(test_df, stats, \"CPM\")   \n\ntrain_df.fillna(-1, inplace=True)\ntest_df.fillna(-1, inplace=True)","407ef2f7":"drop_col = ['date', 'site_id', 'ad_type_id', 'geo_id',\n'device_category_id', 'advertiser_id',\n'order_id', 'line_item_type_id', 'os_id',\n'monetization_channel_id', 'ad_unit_id', 'total_revenue']\n\ntrain_df.drop(drop_col, inplace=True, axis=1)\ntest_df.drop(drop_col, inplace=True, axis=1)\n","3d9b55e5":"train_df.head()","b91557e7":"params = {'learning_rate': 0.005,\n          'num_iterations': 2000,\n          'objective': 'regression',\n          'metric': 'mse',   \n          'num_leaves': 512,\n          'verbosity': -1,\n          'data_random_seed': 2,\n          'bagging_fraction': 0.8,\n          'feature_fraction': 0.6,\n          'nthread': 6,\n          'lambda_l1': 0.5,\n          'lambda_l2': 1,\n          'loss' : 'mse'\n          }","a3dcd077":"\ncolumns = list(train_df.columns)\n\ncolumns.remove(\"CPM\")","29ecd303":"kf = KFold(n_splits=8, shuffle=True, random_state=3289)\n\nfor index, (train_index, test_index) in enumerate(kf.split(train_df[columns])):\n    \n\n    d_train = lgb.Dataset(train_df.iloc[train_index][columns].values, label=train_df.loc[train_index]['CPM'].values)\n    d_valid = lgb.Dataset(train_df.iloc[test_index][columns].values, label=train_df.loc[test_index]['CPM'].values)\n    watchlist = [d_train, d_valid]\n    \n    evals_result = {}\n\n    model = lgb.train(params,\n                    train_set=d_train, early_stopping_rounds=200,\n\n                    valid_sets=watchlist,\n                    verbose_eval=200, evals_result=evals_result)\n    \n    test_df['CPM_PRED_{0}'.format(index)]  = model.predict(test_df[columns].values)\n","b504a724":"test_df.head()","2bc1312f":"cols = [i for  i in test_df.columns if \"CPM_PRED\" in i]","5ad402da":"test_df['CPM_PRED'] = np.mean( test_df[cols], axis=1)","81a74931":"test_df.head()","eccef0f0":"mean_squared_error(test_df['CPM'].values, test_df['CPM_PRED'].values)","dc9283bc":"test_df.loc[test_df.CPM_PRED < 0, 'CPM_PRED'] = 0","f1f943cc":"mean_squared_error(test_df['CPM'].values, test_df['CPM_PRED'].values)","6608bfa1":"test_df[['CPM', 'CPM_PRED']].sample(n=5)","7faa0320":"def plotImp(model, X , num = 20):\n    \"\"\"\n    \n    To visualize feature importance.\n    \"\"\"\n    feature_imp = pd.DataFrame({'Value':model.feature_importance(),'Feature':X.columns})\n    plt.figure(figsize=(40, 20))\n    sns.set(font_scale = 3)\n    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", \n                                                        ascending=False)[0:num])\n    plt.title('LightGBM Features')\n    plt.tight_layout()\n    \n    plt.show()\n","d028c87c":"plotImp(model, train_df[columns])","b65a5bb6":"print(\"Final MSE is: {0}\".format(mean_squared_error(test_df['CPM'].values, test_df['CPM_PRED'].values)))","1f528947":"### Import libraries","ea4b5105":"Just get mean of predictions","f661fa8b":"### Precounting target","a719181c":"### Import data","ab70e1a1":"Hochu zachot\n","3e3885c8":"### Weird DS","ceb6df46":"### Stats + Feature Engineering","9d0e1a0b":"Well my first improvement is some encoding. Here's an implementation","7db6fb66":"Two features encoding.. ","83292a1a":"Well, there's a lot of equal rows cause categorical features don't have many values. Just take one last equal row from stats and take its CPM\n","e7824f4b":"### Checker (test prediction)","67d10701":"### Define a model","16c25522":"Some post processing","bb7adb94":"### Dividing data","5eed3128":"Generate some stats"}}