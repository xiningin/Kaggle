{"cell_type":{"7a3ff1e8":"code","35083d9b":"code","b80ce450":"code","5220bca4":"code","a693264c":"code","6f0e9fd5":"code","47f4b0c1":"code","b1e48870":"code","0ccc8c19":"code","6ff3c920":"code","b3a85a73":"code","a5fbfce6":"code","eebc7816":"code","588d251d":"code","ec4483ac":"code","6eb9d972":"code","2fb9c5a8":"code","93394e4a":"code","ba9ef2ab":"code","312be983":"code","9706668d":"code","38a46ecc":"code","67351322":"code","7fd35097":"code","2d6333ab":"code","6c947496":"code","1331139a":"code","6f9ed504":"code","e5d9c5fc":"code","08628c92":"code","f27f1ffc":"code","d568434f":"code","ca19cfce":"code","32ae8777":"markdown","fd28f59f":"markdown","772bd764":"markdown","c0b20cf6":"markdown","ea6ddae7":"markdown","54727fad":"markdown","23d87300":"markdown","2dfd8862":"markdown","9b8521b1":"markdown","ff840886":"markdown","c8420be9":"markdown","8536b750":"markdown","9147ec4b":"markdown","733d28c3":"markdown","e63c7ce6":"markdown","bfb81155":"markdown","a3408648":"markdown","db20409b":"markdown","110c595d":"markdown","c192b50c":"markdown","c3643106":"markdown","612f2f6d":"markdown","4082580c":"markdown","e3986b7e":"markdown","deee7b70":"markdown"},"source":{"7a3ff1e8":"pip install --user prince","35083d9b":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport prince # https:\/\/github.com\/MaxHalford\/prince","b80ce450":"DATA=\"\/kaggle\/input\/heart-failure-prediction\/\"\n\n# call it generic table df because there is only one file\ndf = pd.read_csv(DATA+\"heart.csv\")","5220bca4":"df.sample(5)","a693264c":"df.describe()","6f0e9fd5":"df.info()","47f4b0c1":"# numcols = df.columns[df.dtypes!='O'] # inferior method\nnumcols = df.select_dtypes(['number']).columns\ndf[numcols].head()","b1e48870":"# catcols = df.columns[df.dtypes=='O']  # inferior method\ncatcols = df.select_dtypes(['object']).columns\ndf[catcols].head()","0ccc8c19":"# See what categories there are in each categorical feature\nfor col in catcols:\n    print (col, df[col].unique())","6ff3c920":"heartDisease = df['HeartDisease']\n# goodbye target column\ndf = df.drop(['HeartDisease'],axis=1)","b3a85a73":"df.hist(bins=30, figsize=(15, 10))","a5fbfce6":"# plot one feature against all features\n# choosing to plot diagonals as histogram i.e. empirical distribution, so as to not draw any misleading conclusions\n# can plot only lower corner to save time\nsns.pairplot(df, diag_kind='hist', hue='FastingBS', palette='CMRmap_r')","eebc7816":"corr = df.corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values,\n            cmap=sns.diverging_palette(220, 10, as_cmap=True),\n            annot=True)","588d251d":"# create new categorical col for FastingBS\ndf['FastingBSCategorical'] = df['FastingBS'].map({0: 'Low', 1: 'High'})\ndf['FastingBSCategorical'] = df['FastingBSCategorical']\n\n# drop FastingBS\ndf.drop(['FastingBS'], axis=1, inplace=True)","ec4483ac":"# update catcols variable\ncatcols = df.select_dtypes(['object']).columns\n\n# convert object columns to categorical columns\ndf[catcols] = df[catcols].astype('category')","6eb9d972":"# now all Dtypes are either numbers or category.\n# about half the memory usage as well\ndf.info()","2fb9c5a8":"# count the na's\ndf.isna().sum()","93394e4a":"# replace 0 with na, then count the na's\ndf.replace(0, np.nan).isna().sum()\n\n# now some missing values show up in RestingBP and Cholesterol","ba9ef2ab":"# this mean is incorrect. The 0s are pulling the mean leftwards.\ndf['Cholesterol'].mean()","312be983":"# the 0s should rightfully be NaNs\ndf['Cholesterol'] = df['Cholesterol'].replace(0, np.nan)","9706668d":"# this is more reflective of the sample mean\ndf['Cholesterol'].mean()","38a46ecc":"df['Cholesterol'].median()","67351322":"# visualize cholesterol to decide which to use\ndf['Cholesterol'].replace(0,np.nan).hist(bins=100)","7fd35097":"# use median instead of mean because there are some extremely high cholesterol values that is pulling the mean up\n# use fillna to impute missing values\ndf['Cholesterol'] = df['Cholesterol'].fillna(df['Cholesterol'].median())","2d6333ab":"# again replace 0s with NaNs in RestingBP\ndf['RestingBP'] = df['RestingBP'].replace(0, np.nan)","6c947496":"df['RestingBP'].hist(bins=100)","1331139a":"df['RestingBP'] = df['RestingBP'].replace(np.nan, 120)","6f9ed504":"# separate columns based on whether we are doing PCA or MCA\npca_cols = df.select_dtypes(['number']).columns\nprint(len(pca_cols), 'features used for PCA are', pca_cols.tolist())\n\nmca_cols = df.select_dtypes(['category']).columns\nprint(len(mca_cols), 'features used for MCA are', mca_cols.tolist())","e5d9c5fc":"df[mca_cols].head()","08628c92":"# instantiate MCA class\nmca = prince.MCA(n_components = 2)\n\n# get principal components\nmca = mca.fit(df[mca_cols])","f27f1ffc":"# project categories onto mca copmonents\n# implicitly calls transform(X)\n# what we want to see is for the points belonging to the same color to be as far apart as possible, for all colors\nax = mca.plot_coordinates(df[mca_cols])\n# ax.get_figure().savefig('MCAplot.svg')","d568434f":"# instantiate PCA class\npca = prince.PCA(n_components = 2)\n\n# get princical components\npca = pca.fit(df[pca_cols])","ca19cfce":"# project data it was trained on, and plot it\n# implicitly calls transform(X)\npca.plot_row_coordinates(df[pca_cols])","32ae8777":"## Joint distributions of pairs of numerical features","fd28f59f":"## Check for unmeasured values indicated by `0` ","772bd764":"## Say farewell to target `HeartDisease` column\n\nHeart disease is our prediction target. So we will only be working on predictors from now on. Otherwise it is easy to cheat based on hindsight.\n\nOnly after this can we begin visualizing our data.","c0b20cf6":"I only want to visualize the data as it is, without imposing any assumption of what kind of distribution it is sampled from. Hence, I will go with scatterplot and histograms, rather than parameterized distributions which look nice but can be misunderstanding. \n\nI am choosing to use `FastingBS` as feature to color the data points rather than include them in the scatterplot. This is because `FastingBS` takes only two values - `0` or `1`.","ea6ddae7":"## Correlation analysis of numerical features","54727fad":"We can visualize the projection using `plot_coordinates` method of the `MCA` class.","23d87300":"# Part 1: Exploratory data visualization","2dfd8862":"See that the _mode_ of cholesterol values is 0, implying that the cholesterol values of most patients are not available. We will address this in the preprocessing stage below.\n\n`Oldpeak` is the ST depression, and for most people without heart disease, it takes the value 0. There are some healthy individuals with extreme values of `Oldpeak`, but most of these values are populated by individuals with heart disease.\n\nApart from `Oldpeak`, the continuous features could be samples of underlying gaussian distributions. `Oldpeak` seems to be generated from a geometric distribution for `0` and above.","9b8521b1":"There is little correlation between numerical features. The strongest correlation of `-0.38` is between `Age` and `MaxHR`. However, as people tend to ignore correlation of below `0.7`, we will treat the numerical features as independent.","ff840886":"Looking at the `HeartDisease` column, we see that the ratio of individuals with HD and without HD are quite well balanced. We can express the _maximum likelihood estimator_ for the probability of some unknown person of having heart failure, $\\hat{\\theta}$, as 0.55, corresponding to the expectation of the `HeartDisease` random indicator variable (denote as $X$).\n\n\\begin{equation}\nP(X = x) = \\theta^{x}(1-\\theta)^{1-x}\n\\end{equation} where _x_ is one of 2 events (`0` or `1`), and $\\theta$ is unknown parameter whose $MLE$ is\n\n\\begin{equation}\n\\hat{\\theta} = 0.553377\n\\end{equation}\n\nIt does not take a medically trained person to tell that factors like age, resting blood pressure, etc, influence cardiac health. Thus, if we know the age, resting blood pressure, etc of a person, then the _conditional probability_ of this individual having heart failure will increase or decrease. ","c8420be9":"# Part 3: MCA and PCA\n\nWe now do MCA and PCA. This is preparation for the next step where we use the projections of the MCA and PCA components in place of our features for clustering. This allows us to cluster on all features.\n\nWe will use the `prince` library (https:\/\/github.com\/MaxHalford\/prince) for both MCA and PCA. It is really easy to use.","8536b750":"## Load in our dataset","9147ec4b":"## Categorical vs numerical predictor features","733d28c3":"## Imputing unmeasured values with \"typical\" values\n\nImputing is a procedure where missing values in a feature are replaced with typical values _within_ the dataset. By typical, we want it to be as indistinguishable from other values of that feature as possible. This is perfomed with the hope that, during machine learning, the incompleteness of  this feature will not be as detrimental as dropping the entire feature altogether.","e63c7ce6":"## Am I going to encode bimodal categories?\nHere that it is actually possible to binary-encode two features - `Sex` and `ExerciseAngina`. \n\nWhile one can take this approach, I am not going to do so. PCA is meant for _continuous_ values, not discrete values.\n\nInstead, I will leave it as a categorical variable, then run it through multiple correspondence analysis (MCA). \n\nThe use of MCA together with PCA on continuous features is based on Hycene's suggestion on a Kaggle discussion page (https:\/\/www.kaggle.com\/general\/19741).","bfb81155":"### In summary, here are the discrete and continuous features:\n\n#### Discrete features for MCA\n\n1. Sex\n2. Chest pain type\n3. Resting ECG\n4. ExerciseAngina\n5. ST_Slope\n6. FastingBS\n\n#### Continuous features for PCA \n1. Age\n2. RestingBP\n3. Cholesterol\n4. MaxHR\n5. Oldpeak","a3408648":"I will replace resting BP with the mode, because the data looks quantized and `120` stands out as a particularly common measurement. Hence, filling the 1 `NaN` value with 120 will do the least harm because it is already the most common value.\n\nAnother way of thinking is, if you showed 100 people this distribution, and ask them to guess the reading of one new person given that you knew nothing about him or her. I bet most people would say `120`.","db20409b":"There are no `na` values in any features. This is not to say there are unmeasured values. As shown below, a lot of `cholesterol` values are `0` which means they were not measured (we cannot possibly have `0` cholesterol levels). Only the `0`s in `Oldpeak` and `FastingBS` are normal. The rest are not, and indicate that the values were not measured for those patients.\n\nHence, there are missing values in two features - `RestingBP` and `Cholesterol`","110c595d":"## Marginal distributions of numerical features","c192b50c":"## First glances at the dataset","c3643106":"![MCA](https:\/\/github.com\/JiaGengChang\/KaggleImages\/blob\/main\/MCAplot.svg?raw=true)","612f2f6d":"## Converting FastingBS to a category\n\nHaving to decide to do MCA for categorical variables, and PCA for numerical variables,  we now transition from looking at the data catageorical\/numerical-wise to discrete\/continuous-wise. \n\nThis means that FastingBS should be converted to a categorical, because MCA and not PCA is more appropriate for a bimodal variable.","4082580c":"# Part 2: Preprocessing","e3986b7e":"## Prior probability of heart disease (cheating)","deee7b70":"# Part 0: Getting familiar with the data"}}