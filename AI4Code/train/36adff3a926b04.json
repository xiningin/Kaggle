{"cell_type":{"938ec796":"code","9c44117c":"code","dc0e4529":"code","646b26da":"code","94354ef2":"code","9f1a1d09":"code","d7f66025":"code","0982e58d":"code","656983ae":"code","6d392375":"code","f89cd596":"markdown","c2f2ec9d":"markdown","f915376c":"markdown","6137cced":"markdown"},"source":{"938ec796":"# Importing the libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","9c44117c":"# Importing the mall dataset with pandas\ndataset = pd.read_csv(\"..\/input\/mailcustomers\/Mall_Customers.csv\")\nX = dataset.iloc[:,[3,4]].values","dc0e4529":"dataset.head()","646b26da":"# Using the elbow method to find the optimal number of clusters\nfrom sklearn.cluster import KMeans\nwcss = []\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters=i,init='k-means++',max_iter=300,n_init=10,random_state=0)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1,11),wcss)\nplt.title(\"The Elbow Method\")\nplt.xlabel(\"Number of clusters\")\nplt.ylabel(\"WCSS\")\nplt.show()","94354ef2":"# Applying k-means to the mall dataset\nkmeans = KMeans(n_clusters=5,init='k-means++',max_iter=300,n_init=10,random_state=0)\ny_kmeans = kmeans.fit_predict(X)","9f1a1d09":"print(y_kmeans)","d7f66025":"# Visualizing the clusters\nplt.scatter(X[y_kmeans == 0, 0],X[y_kmeans== 0,1],s=100,c='red',label=\"Careful\")\nplt.scatter(X[y_kmeans == 1, 0],X[y_kmeans== 1,1],s=100,c='blue',label=\"Standard\")\nplt.scatter(X[y_kmeans == 2, 0],X[y_kmeans== 2,1],s=100,c='green',label=\"Target\")\nplt.scatter(X[y_kmeans == 3, 0],X[y_kmeans== 3,1],s=100,c='cyan',label=\"Careless\")\nplt.scatter(X[y_kmeans == 4, 0],X[y_kmeans== 4,1],s=100,c='magenta',label=\"Sensible\")\nplt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],s=300,c='yellow',label='Centroids')\nplt.title('Clusters of clients')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","0982e58d":"# Using the dendrogram to find the optimal number of clusters\nimport scipy.cluster.hierarchy as sch\ndendrogram = sch.dendrogram(sch.linkage(X,method='ward'))\nplt.title('Dendrogram')\nplt.xlabel('Customers')\nplt.ylabel('Euclidean distances')\nplt.tight_layout()\nplt.show()","656983ae":"# Fitting the hierarchical clustering to the mall dataset\nfrom sklearn.cluster import AgglomerativeClustering\nhc = AgglomerativeClustering(n_clusters=5,affinity='euclidean',linkage='ward')\ny_hc = hc.fit_predict(X)","6d392375":"# Visualizing the clusters\nplt.scatter(X[y_hc == 0, 0],X[y_hc== 0,1],s=100,c='red',label=\"Careful\")\nplt.scatter(X[y_hc == 1, 0],X[y_hc== 1,1],s=100,c='blue',label=\"Standard\")\nplt.scatter(X[y_hc == 2, 0],X[y_hc== 2,1],s=100,c='green',label=\"Target\")\nplt.scatter(X[y_hc == 3, 0],X[y_hc== 3,1],s=100,c='cyan',label=\"Careless\")\nplt.scatter(X[y_hc == 4, 0],X[y_hc== 4,1],s=100,c='magenta',label=\"Sensible\")\nplt.title('Clusters of clients')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","f89cd596":"# Dendrogram\n\nA dendrogram is a diagram that shows the hierarchical relationship between objects. It is most commonly created as an output from hierarchical clustering. The main use of a dendrogram is to work out the best way to allocate objects to clusters. ","c2f2ec9d":"# Hierarchical Clustering\n\nhierarchical clustering (also called hierarchical cluster analysis or HCA) is a method of cluster analysis which seeks to build a hierarchy of clusters. Strategies for hierarchical clustering generally fall into two types:\n\n**Agglomerative**: This is a \"bottom-up\" approach: each observation starts in its own cluster, and pairs of clusters are merged as one moves up the hierarchy.\n\n**Divisive**: This is a \"top-down\" approach: all observations start in one cluster, and splits are performed recursively as one moves down the hierarchy.","f915376c":"# Elbow Method\n\nElbow is one of the most famous methods by which you can select the right value of k and boost your model performance. We also perform the hyperparameter tuning to chose the best value of k.\n\nIt is an empirical method to find out the best value of k. It picks up the range of values and takes the best among them. It calculates the sum of the square of the points and calculates the average distance.\n\nWhen the value of k is 1, the within-cluster sum of the square will be high. As the value of k increases, the within-cluster sum of square value will decrease.\n\nFinally, we will plot a graph between k-values and the within-cluster sum of the square to get the k value. we will examine the graph carefully. At some point, our graph will decrease abruptly. That point will be considered as a value of k.","6137cced":"# KNN Clustering"}}