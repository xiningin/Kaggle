{"cell_type":{"bd1e067f":"code","50fef502":"code","9df8ec7b":"code","4c386ceb":"code","2639b33e":"code","2396b0fc":"code","0ba803df":"code","a1fff04c":"code","eb572594":"code","ef6c9aac":"code","697f76bf":"code","792b7e65":"code","6bc5c472":"code","ef9afffe":"code","7b55664a":"code","e73bdc80":"code","01b619b8":"code","ab6e6e80":"code","636d084a":"code","7c4efe55":"code","4450c591":"code","becda0c3":"code","fe873f21":"code","baed6b26":"code","48ec8bf6":"code","b740b817":"code","7a6e6b4a":"code","b8c80d33":"code","7f14eb58":"code","d3c0b13e":"code","cf53a46d":"code","2956be44":"code","6525274c":"code","d2c91d2a":"code","0b35102f":"code","c24fe7d1":"code","6a27a820":"code","64eff274":"code","61293133":"markdown","d17be323":"markdown","8504ae0e":"markdown","f12c1566":"markdown","250924ea":"markdown","37d65b8b":"markdown","756fe8c0":"markdown","e9dceb86":"markdown","74610eed":"markdown","0b4e0951":"markdown","fa0db292":"markdown","91b0c21b":"markdown","84d751b5":"markdown","f58bd6a6":"markdown","aef88aa1":"markdown","6da13248":"markdown","e79ec0eb":"markdown","ba4e7639":"markdown","a7637f1f":"markdown","2ad52174":"markdown","60f73374":"markdown"},"source":{"bd1e067f":"!pip install joypy --progress-bar off","50fef502":"import os\nimport random\nimport seaborn as sns\nimport cv2\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport PIL\n\nimport nilearn as nl\nimport nilearn.plotting as nlplt\nimport nibabel as nib\nimport h5py\nimport plotly.graph_objs as go\nfrom IPython.display import Image, display\nimport joypy\nimport warnings\nwarnings.filterwarnings(\"ignore\")","9df8ec7b":"os.listdir('\/kaggle\/input\/trends-assessment-prediction\/')","4c386ceb":"BASE_PATH = '..\/input\/trends-assessment-prediction'\n\ntrain_data_dir = f'{BASE_PATH}\/fMRI_train'\ntest_data_dir = f'{BASE_PATH}\/fMRI_test'\n","2639b33e":"loading_data = pd.read_csv(f'{BASE_PATH}\/loading.csv')\ntrain_data = pd.read_csv(f'{BASE_PATH}\/train_scores.csv')\nsample_submission = pd.read_csv(f'{BASE_PATH}\/sample_submission.csv')\nfnc_df = pd.read_csv(\"..\/input\/trends-assessment-prediction\/fnc.csv\")\n","2396b0fc":"loading_data.head()","0ba803df":"loading_data.shape","a1fff04c":"train_data.head()","eb572594":"train_data.shape","ef6c9aac":"total = train_data.isnull().sum()\npercent = total\/train_data.isnull().count()*100\nmissing_train_data= pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_train_data.head()","697f76bf":"def plot_bar(df, feature, title='', show_percent = False, size=2):\n    f, ax = plt.subplots(1,1, figsize=(4*size,3*size))\n    total = float(len(df))\n    sns.barplot(np.round(df[feature].value_counts().index).astype(int), df[feature].value_counts().values, alpha=0.8, palette='Set2')\n\n    plt.title(title)\n    if show_percent:\n        for p in ax.patches:\n            height = p.get_height()\n            ax.text(p.get_x()+p.get_width()\/2.,\n                    height + 3,\n                    '{:1.2f}%'.format(100*height\/total),\n                    ha=\"center\", rotation=45) \n    plt.xlabel(feature, fontsize=12, )\n    plt.ylabel('Number of Occurrences', fontsize=12)\n    plt.xticks(rotation=90)\n    plt.show()","792b7e65":"plot_bar(train_data, 'age', 'age count and %age plot', show_percent=True, size=3)","6bc5c472":"temp_data =  train_data.drop(['Id'], axis=1)\nplt.figure(figsize = (15, 10))\nsns.heatmap(temp_data.corr(), annot = True, cmap=\"brg\")\nplt.yticks(rotation=0) \nplt.show()","ef9afffe":"temp_data =  loading_data.drop(['Id'], axis=1)\n\nplt.figure(figsize = (20, 20))\nsns.heatmap(temp_data.corr(), annot = True, cmap=\"RdYlGn\")\nplt.yticks(rotation=0) \n\nplt.show()","7b55664a":"temp_data =  loading_data.drop(['Id'], axis=1)\n# Create correlation matrix\ncorrel = temp_data.corr().abs()\n\n# Select upper triangle of correlation matrix\nupper = correl.where(np.triu(np.ones(correl.shape), k=1).astype(np.bool))\n# Find index of feature columns with correlation greater than 0.5\nto_drop = [column for column in upper.columns if any(upper[column] > 0.5)]\n\nprint('Very high correlated features: ', to_drop)","e73bdc80":"import joypy\n\ntargets= loading_data.columns[1:]\n\n\nplt.figure(figsize=(16,10), dpi= 90)\nfig, axes = joypy.joyplot(loading_data, column=list(targets), ylim='own', figsize=(14,10))\n\n# Decoration\nplt.title('Distribution of features IC_01 to IC_29', fontsize=22)\nplt.show()","01b619b8":"!wget https:\/\/github.com\/Chaogan-Yan\/DPABI\/raw\/master\/Templates\/ch2better.nii","ab6e6e80":"mask_filename = f'{BASE_PATH}\/fMRI_mask.nii'\nsubject_filename = '..\/input\/trends-assessment-prediction\/fMRI_train\/10015.mat'\nsmri_filename = 'ch2better.nii'\nmask_niimg = nl.image.load_img(mask_filename)","636d084a":"def load_subject(filename, mask_niimg):\n    subject_data = None\n    with h5py.File(subject_filename, 'r') as f:\n        subject_data = f['SM_feature'][()]\n    # It's necessary to reorient the axes, since h5py flips axis order\n    subject_data = np.moveaxis(subject_data, [0,1,2,3], [3,2,1,0])\n    subject_niimg = nl.image.new_img_like(mask_niimg, subject_data, affine=mask_niimg.affine, copy_header=True)\n    return subject_niimg\nsubject_niimg = load_subject(subject_filename, mask_niimg)\nprint(\"Image shape is %s\" % (str(subject_niimg.shape)))\nnum_components = subject_niimg.shape[-1]\nprint(\"Detected {num_components} spatial maps\".format(num_components=num_components))","7c4efe55":"nlplt.plot_prob_atlas(subject_niimg, bg_img=smri_filename, view_type='filled_contours', draw_cross=False,title='All %d spatial maps' % num_components, threshold='auto')","4450c591":"grid_size = int(np.ceil(np.sqrt(num_components)))\nfig, axes = plt.subplots(grid_size, grid_size, figsize=(grid_size*10, grid_size*10))\n[axi.set_axis_off() for axi in axes.ravel()]\nrow = -1\nfor i, cur_img in enumerate(nl.image.iter_img(subject_niimg)):\n    col = i % grid_size\n    if col == 0:\n        row += 1\n    nlplt.plot_stat_map(cur_img, bg_img=smri_filename, title=\"IC %d\" % i, axes=axes[row, col], threshold=3, colorbar=False)\n    ","becda0c3":"from nilearn import datasets\n\n# haxby dataset to have EPI images and masks\nhaxby_dataset = datasets.fetch_haxby()\n\n# print basic information on the dataset\nprint('First subject anatomical nifti image (3D) is at: %s' %\n      haxby_dataset.anat[0])\nprint('First subject functional nifti image (4D) is at: %s' %\n      haxby_dataset.func[0])  # 4D data\n\nhaxby_anat_filename = haxby_dataset.anat[0]\nhaxby_mask_filename = haxby_dataset.mask_vt[0]\nhaxby_func_filename = haxby_dataset.func[0]\n\n# one motor contrast map from NeuroVault\nmotor_images = datasets.fetch_neurovault_motor_task()\nstat_img = motor_images.images[0]","fe873f21":"from nilearn import plotting\n\n# Visualizing t-map image on EPI template with manual\n# positioning of coordinates using cut_coords given as a list\nplotting.plot_stat_map(stat_img,\n                       threshold=3, title=\"plot_stat_map\",\n                       cut_coords=[36, -27, 66])","baed6b26":"plotting.plot_glass_brain(stat_img, title='plot_glass_brain',\n                          threshold=3)","48ec8bf6":"from nilearn import datasets\n\nrest_dataset = datasets.fetch_development_fmri(n_subjects=20)\nfunc_filenames = rest_dataset.func\nconfounds = rest_dataset.confounds","b740b817":"# Import dictionary learning algorithm from decomposition module and call the\n# object and fit the model to the functional datasets\nfrom nilearn.decomposition import DictLearning\n\n# Initialize DictLearning object\ndict_learn = DictLearning(n_components=8, smoothing_fwhm=6.,\n                          memory=\"nilearn_cache\", memory_level=2,\n                          random_state=0)\n# Fit to the data\ndict_learn.fit(func_filenames)\n# Resting state networks\/maps in attribute `components_img_`\n# Note that this attribute is implemented from version 0.4.1.\n# For older versions, see the note section above for details.\ncomponents_img = dict_learn.components_img_\n\n# Visualization of functional networks\n# Show networks using plotting utilities\nfrom nilearn import plotting\n\nplotting.plot_prob_atlas(components_img, view_type='filled_contours',\n                         title='Dictionary Learning maps')","7a6e6b4a":"# Import Region Extractor algorithm from regions module\n# threshold=0.5 indicates that we keep nominal of amount nonzero voxels across all\n# maps, less the threshold means that more intense non-voxels will be survived.\nfrom nilearn.regions import RegionExtractor\n\nextractor = RegionExtractor(components_img, threshold=0.5,\n                            thresholding_strategy='ratio_n_voxels',\n                            extractor='local_regions',\n                            standardize=True, min_region_size=1350)\n# Just call fit() to process for regions extraction\nextractor.fit()\n# Extracted regions are stored in regions_img_\nregions_extracted_img = extractor.regions_img_\n# Each region index is stored in index_\nregions_index = extractor.index_\n# Total number of regions extracted\nn_regions_extracted = regions_extracted_img.shape[-1]\n\n# Visualization of region extraction results\ntitle = ('%d regions are extracted from %d components.'\n         '\\nEach separate color of region indicates extracted region'\n         % (n_regions_extracted, 8))\nplotting.plot_prob_atlas(regions_extracted_img, view_type='filled_contours',\n                         title=title)\n","b8c80d33":"from nilearn.connectome import ConnectivityMeasure\n\ncorrelations = []\n# Initializing ConnectivityMeasure object with kind='correlation'\nconnectome_measure = ConnectivityMeasure(kind='correlation')\nfor filename, confound in zip(func_filenames, confounds):\n    # call transform from RegionExtractor object to extract timeseries signals\n    timeseries_each_subject = extractor.transform(filename, confounds=confound)\n    # call fit_transform from ConnectivityMeasure object\n    correlation = connectome_measure.fit_transform([timeseries_each_subject])\n    # saving each subject correlation to correlations\n    correlations.append(correlation)\n\n# Mean of all correlations\nimport numpy as np\nmean_correlations = np.mean(correlations, axis=0).reshape(n_regions_extracted,\n                                                          n_regions_extracted)\n\n\ntitle = 'Correlation between %d regions' % n_regions_extracted\n\n# First plot the matrix\ndisplay = plotting.plot_matrix(mean_correlations, vmax=1, vmin=-1,\n                               colorbar=True, title=title)\n\n# Then find the center of the regions and plot a connectome\nregions_img = regions_extracted_img\ncoords_connectome = plotting.find_probabilistic_atlas_cut_coords(regions_img)\n\nplotting.plot_connectome(mean_correlations, coords_connectome,\n                         edge_threshold='90%', title=title)","7f14eb58":"from sklearn.svm import SVR\nfrom sklearn.model_selection import KFold\n\ndef metric(y_true, y_pred):\n    return np.mean(np.sum(np.abs(y_true - y_pred), axis=0)\/np.sum(y_true, axis=0))\n\n","d3c0b13e":"fnc_df.shape","cf53a46d":"df = fnc_df.merge(loading_data, on=\"Id\")\ndf.head()","2956be44":"train_score = pd.read_csv(\"..\/input\/trends-assessment-prediction\/train_scores.csv\")\ntrain_score.head()","6525274c":"train_score[\"is_train\"] = True\ndf = df.merge(train_score, on=\"Id\", how=\"left\")\ndf.head()","d2c91d2a":"test_df = df[df[\"is_train\"] != True].copy()\ndf = df[df[\"is_train\"] == True].copy()\n\ndf.shape, test_df.shape","0b35102f":"fnc_features, loading_features = list(fnc_df.columns[1:]), list(loading_data.columns[1:])\n\n# Giving less importance to FNC features since they are easier to overfit due to high dimensionality.\nFNC_SCALE = 1\/500\n\ndf[fnc_features] *= FNC_SCALE\ntest_df[fnc_features] *= FNC_SCALE","c24fe7d1":"%%time\nNUM_FOLDS = 7\nkf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=0)\n\n\nfeatures = loading_features + fnc_features\n\noveral_score = 0\nfor target, c, w in [(\"age\", 100, 0.3), (\"domain1_var1\", 10, 0.175), (\"domain1_var2\", 10, 0.175), (\"domain2_var1\", 10, 0.175), (\"domain2_var2\", 10, 0.175)]:    \n    y_oof = np.zeros(df.shape[0])\n    y_test = np.zeros((test_df.shape[0], NUM_FOLDS))\n    \n    for f, (train_ind, val_ind) in enumerate(kf.split(df, df)):\n        train_df, val_df = df.iloc[train_ind], df.iloc[val_ind]\n        train_df = train_df[train_df[target].notnull()]\n\n        model = SVR(C=c, cache_size=3000.0)\n        model.fit(train_df[features], train_df[target])\n\n        y_oof[val_ind] = model.predict(val_df[features])\n        y_test[:, f] = model.predict(test_df[features])\n        \n    df[\"pred_{}\".format(target)] = y_oof\n    test_df[target] = y_test.mean(axis=1)\n    score = metric(df[df[target].notnull()][target].values, df[df[target].notnull()][\"pred_{}\".format(target)].values)\n    overal_score += w*score\n    print(target, np.round(score, 4))\n    print()\n    \nprint(\"Overal score:\", np.round(overal_score, 4))","6a27a820":"sub_df = pd.melt(test_df[[\"Id\", \"age\", \"domain1_var1\", \"domain1_var2\", \"domain2_var1\", \"domain2_var2\"]], id_vars=[\"Id\"], value_name=\"Predicted\")\nsub_df[\"Id\"] = sub_df[\"Id\"].astype(\"str\") + \"_\" +  sub_df[\"variable\"].astype(\"str\")\n\nsub_df = sub_df.drop(\"variable\", axis=1).sort_values(\"Id\")\nassert sub_df.shape[0] == test_df.shape[0]*5\nsub_df.head(10)","64eff274":"sub_df.to_csv(\"submission.csv\", index=False)","61293133":"# Exploratory Data Analysis","d17be323":"# Brain Development Function","8504ae0e":"DPABI is a toolbox for Data Preprocessing and Analysing  Brain Imaging; using ch2bettertemplate to visualize various dimesion, axis, gray matter of brain.","f12c1566":"* **JoyPy** is a one-function Python package based on matplotlib + pandas with a single purpose.\n* **Nilearn** is a Python module for fast and easy statistical learning on NeuroImaging data.\nIt leverages the scikit-learn Python toolbox for multivariate statistics with applications such as predictive modelling, classification, decoding, or connectivity analysis.\n* **NiBabel** Read \/ write access to some common neuroimaging file formats.\n* **HDF5** lets you store huge amounts of numerical data, and easily manipulate that data from NumPy.\n","250924ea":"# Submission Part","37d65b8b":"# Load Dataset","756fe8c0":"#### From the above heatmap we can see that Age and domain1_var1 corelated and significant, let's go forward.","e9dceb86":"# HeatMap","74610eed":"from the above plot we can understand Top 5 most frequent ages are 57, 60, 54, 55, 50.","0b4e0951":"## Let's make a heatmap of Loading Data","fa0db292":"IC_13, IC_14 having high co relation value here !","91b0c21b":"# Check dataset list and type","84d751b5":"# Import Libraries","f58bd6a6":"    \n**<span style=\"color:Red\">I have just started to working in this project, so it is on progress, I will update time by time**\n### Please upvote this kernel if you like it  :-)","aef88aa1":"# Individual Component Feautures of all 53","6da13248":"### <span style=\"color:Blue\">What you are understanding and what is the possibility regarding Neuroimaging and Neuromorphic Computing, kindly comment below to share your knowledge :-)","e79ec0eb":"# Visualization using Nilearn\n\nthis portion is inspired by Soham Mukherjee's Kernal, adding the link of his kernal.\n\nhttps:\/\/www.kaggle.com\/soham1024\/visualization-using-nilearn","ba4e7639":"**Thanks Again for going through the Kernel \u2661**","a7637f1f":"![image.png](attachment:image.png)","2ad52174":"# <span style=\"color:Purple\">TReNDS  \ud83c\udd7d\ud83c\udd74\ud83c\udd81\ud83c\udd7e\ud83c\udd78\ud83c\udd7c\ud83c\udd70\ud83c\udd76\ud83c\udd78\ud83c\udd7d\ud83c\udd76  Visualization, Analysis and Evaluation \u2714\n\n## Multiscanner normative age and assessments prediction with brain function, structure, and connectivity.\nIn this competition, we will predict multiple assessments plus age from multimodal brain MRI features. Due to the complexity of the brain and differences between scanners, generalized approaches will be essential to effectively propel multimodal neuroimaging research forward. \n    \n    \n    ","60f73374":"# Work in Progress , kindly Upvote if you like the notebook \u2764"}}