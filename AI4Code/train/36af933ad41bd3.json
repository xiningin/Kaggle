{"cell_type":{"720bd2bc":"code","ab1e7562":"code","c90a35b5":"code","1fc36b27":"code","cd721312":"code","1323383e":"code","5bf2c048":"code","bc93b668":"code","7954824e":"code","599a2ce7":"markdown","97de9f5e":"markdown","9989c4cb":"markdown","953e5155":"markdown","9ca2b092":"markdown","7517ae4d":"markdown","0023bd3d":"markdown","96fa4bc1":"markdown","d6cb7224":"markdown"},"source":{"720bd2bc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport json\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ab1e7562":"## -- Training Sentiment Metedata -- ##\njson_path = \"..\/input\/train_sentiment\"\njson_list = os.listdir(json_path)\n\njdict_train = {}\nfor js in json_list:\n    with open(os.path.join(json_path, js), encoding=\"utf8\") as json_file:\n        json_text = json.load(json_file)\n        jdict_train[js[0:-5]] = json_text[\"documentSentiment\"][\"magnitude\"]\n## -- Testing Sentiment Metedata -- ##\njson_path = \"..\/input\/test_sentiment\"\njson_list = os.listdir(json_path)\n\njdict_test = {}\nfor js in json_list:\n    with open(os.path.join(json_path, js), encoding=\"utf8\") as json_file:\n        json_text = json.load(json_file)\n        jdict_test[js[0:-5]] = json_text[\"documentSentiment\"][\"magnitude\"]\n\nprint(len(jdict_train))\nprint(len(jdict_test))\n","c90a35b5":"df_train_data = pd.read_csv(\"..\/input\/train\/train.csv\", header=0, index_col=\"PetID\")\ndf_test_data = pd.read_csv(\"..\/input\/test\/test.csv\", header=0, index_col=\"PetID\")\n\ndf_sent_train = pd.DataFrame.from_dict(jdict_train, orient=\"index\", columns=[\"Magnitude\"])\ndf_sent_test = pd.DataFrame.from_dict(jdict_test, orient=\"index\", columns=[\"Magnitude\"])\n\njoined_train = df_train_data.merge(df_sent_train, how=\"left\", left_index=True, right_index=True)\njoined_train[\"PredictionType\"] = \"Training\"\njoined_train[\"Magnitude\"] = joined_train[\"Magnitude\"].fillna(value=joined_train[\"Magnitude\"].mean())\n                                                             \njoined_test = df_test_data.merge(df_sent_test, how=\"left\", left_index=True, right_index=True)\njoined_test[\"PredictionType\"] = \"Testing\"\njoined_test[\"AdoptionSpeed\"] = 100\njoined_test[\"Magnitude\"] = joined_test[\"Magnitude\"].fillna(value=joined_test[\"Magnitude\"].mean())\n\nfull_df =  joined_train.append(joined_test)\n\nprint(full_df.info())","1fc36b27":"data_type_dict = {\n        \"category\":[\"Type\", # 1 = Dog, 2 = Cat\n                    \"Breed1\", # Primary breed of pet (Refer to BreedLabels dictionary)\n                    \"Breed2\", # Secondary, if mixed\n                    \"Gender\", # 1 = Male, 2 = Female, 3 = Mixed, if profile represents group of pets\n                    \"Color1\", # Color 1 of pet (Refer to ColorLabels dictionary)\n                    \"Color2\", \n                    \"Color3\", \n                    \"MaturitySize\", # Size at maturity (1 = Small, 2 = Medium, 3 = Large, 4 = Extra Large, 0 = Not Specified)\n                    \"FurLength\", # Fur length (1 = Short, 2 = Medium, 3 = Long, 0 = Not Specified)\n                    \"Vaccinated\", # Pet has been vaccinated (1 = Yes, 2 = No, 3 = Not Sure)\n                    \"Dewormed\", # Pet has been dewormed (1 = Yes, 2 = No, 3 = Not Sure)\n                    \"Sterilized\", # Pet has been spayed \/ neutered (1 = Yes, 2 = No, 3 = Not Sure)\n                    \"Health\", # Health Condition (1 = Healthy, 2 = Minor Injury, 3 = Serious Injury, 0 = Not Specified)\n                    \"State\" # State location in Malaysia (Refer to StateLabels dictionary)\t\t\t\t\t\t\t\t\n                    ],\n        \"float\":[\"Age\", # Months\n                 \"Quantity\", # Number of pets represented in profile\n                 \"Fee\", # Adoption fee (0=Free)\n                 \"VideoAmt\", # Total uploaded videos for this pet\n                 \"PhotoAmt\", # Total uploaded photos for this pet\n                 \"Magnitude\", # From the Sentiment metadata\n                 ],\n        \"int8\":[\"AdoptionSpeed\"], # Categorical speed of adoption. Lower is faster. This is the value to predict.]\n        \"object\":[\"PredictionType\"] # Custom indeifyer of testing\/training set\"\n                 }\n\noutput_var = \"AdoptionSpeed\"\n\n\n# df_train = pd.DataFrame()\ndf_learn = pd.DataFrame()\nfor typ,col in data_type_dict.items():\n    for c in col:\n        df_learn[c] = full_df[c].astype(typ)\n\nprint(df_learn.info())","cd721312":"df_learn = pd.get_dummies(df_learn)\n\nX_train_whole = df_learn[df_learn[\"PredictionType_Training\"] == 1].drop(output_var, axis=1)\ny_train_whole = df_learn[df_learn[\"PredictionType_Training\"] == 1][output_var]\n\nfrom sklearn.model_selection import train_test_split\nrnd = 0\nX_train, X_test, y_train, y_test = train_test_split(X_train_whole, y_train_whole, \n                                                    test_size=0.20, \n                                                    random_state=rnd).copy()","1323383e":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import LinearSVC\n\n\nmodels = {\"Random Forest\":RandomForestClassifier(random_state=rnd),\n          \"K-neighbors\":KNeighborsClassifier(),\n          \"Linear SVC\":LinearSVC(random_state=rnd)\n         }\n\nfor desc, mod in models.items():\n    print(desc)\n    mod.fit(X_train, y_train)\n    print(mod.score(X_test, y_test))","5bf2c048":"mod = RandomForestClassifier(n_estimators=120, random_state=rnd)\nmod.fit(X_train_whole, y_train_whole)","bc93b668":"pred = mod.predict(df_learn[df_learn[\"PredictionType_Testing\"] == 1].drop(output_var, axis=1))\n\ndf_test_data[\"AdoptionSpeed\"] = pred\nsubmission = df_test_data[\"AdoptionSpeed\"]\nprint(submission.head(10).to_string())","7954824e":"submission.to_csv(\"submission.csv\", index=True, index_label=\"PetID\", header=[\"AdoptionSpeed\"])","599a2ce7":"The next step is to import both training and testing datasets, join the *Magnitude* metadata to it, and finally concatenate it to a single dataframe. I perform this concatenation so that I can appropriately one-hot encode the categorical data as to have the same shape for testing\/training inputs. \n\nThe joins are performed on the left to enure no loss of actual training or testing observations. Since Magnitude has some null values, I impute the mean before combining the dataset as to reduce data *leakage*.\n\nA new column is added called \"PredictionType\" to distinguish between the testing and training sets. \n\nOn the testing set, the column \"AdoptionSpeed\" is missing, so I add it with values of 100 which are unrealistic. These values will be overwritten by the predicted values later. ","97de9f5e":"**Hello!**\n\nThis Kernel is for the PetFinder.my Adoption Prediction Kaggle competition submission. The goal is to assign each pet a value from 1-4 which corresponds to the amount of time it takes to get adopted. The higher the number, the longer it takes. The full challenge can be found at this [link](https:\/\/www.kaggle.com\/c\/petfinder-adoption-prediction). Here I take a simple approach to defining features, joining multiple datasets, comparing a few different algorithms, and making predcitons based on the best models. Let's get started by importing all the right packages.\n\nI will include some factors from the the sentiment metadata, so I'll need a JSON package. ","9989c4cb":"Now a full dataframe has been constructed with training and testing sets with an extra column from the sentiment metadata. My next step is to convert all the columns into their proper type and drop those that might be irrelevant (like Name). \n\nMy approach is one that prioritizes readability. \n","953e5155":"Now is the excited step of preparing the data for use in a machine learning algorithm. In this step I will one-hot encode the categorical factors, then split the full dataset into a \"whole\" training set,  then subset the \"whole\" training set further for test\/train validation. ","9ca2b092":"Great! It's now time to make a prediction on our testing data (complete with testing sentiment metadata ) and prepare the submission file.","7517ae4d":"It appears that Random Forest gives the best scores out of the box, so I'll choose this one to proceed with tuning. I encourage you to fork this Kernel and try for yourself different parameters. \n\nBelow is one that I found works best at about 0.401 accuracy score with 120 estimators. Now to retrain on the entire training set.","0023bd3d":"**Thank you for reading**. As always, please drop a comment or upvote this Kernel if it helped you at all. \n\nMichael Greene","96fa4bc1":"Now I will choose from three different models with default parameters for a quick comparison. I'll use the default score method to assess them. ","d6cb7224":"The first thing I want to do is extract the \"Magnitude\" of the \"documentSentiment\" from both sentiment metadata files (testing and training). I'll store this data in a dictionary. In lieu of a cuteness metrric, I will use this quantity as a possibly predictive factor. "}}