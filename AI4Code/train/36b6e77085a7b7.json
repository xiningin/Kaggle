{"cell_type":{"eda7a59f":"code","45a34c47":"code","e4847622":"code","17386cc8":"code","07f53e01":"code","68f96346":"code","806b34a1":"code","67107239":"code","f1ee22c1":"code","4f23167c":"code","f23652ea":"code","a5198c48":"code","df02912c":"code","e7ea6959":"code","119e1a3b":"code","7ca264be":"code","aadd9eab":"code","fc4473fd":"code","1d175513":"code","9edfb075":"code","d582c207":"code","35fb837b":"code","f8cd924f":"code","dae2c44f":"code","f0f74c86":"code","c2cf6f92":"code","362b4d84":"code","6948ff31":"code","a96fdeca":"markdown","9ef2b28d":"markdown","7f159739":"markdown","c0e83cba":"markdown","1400e681":"markdown","116361e1":"markdown","1693fb92":"markdown","85bb39fc":"markdown","f3733fb5":"markdown","66073d98":"markdown","8596b788":"markdown","380b3bc9":"markdown","45d7d5d1":"markdown","9800d131":"markdown","728f8384":"markdown","6a0ab635":"markdown","8bffbb76":"markdown","4c85b243":"markdown","df43ce14":"markdown","0fa742df":"markdown","6459b8d5":"markdown","c729f93b":"markdown","7581baa2":"markdown"},"source":{"eda7a59f":"!pip install nb_black -q","45a34c47":"%load_ext nb_black","e4847622":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib.pyplot as plt\n\nfor dirname, _, filenames in os.walk(\"\/kaggle\/input\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","17386cc8":"data = pd.read_csv(\"\/kaggle\/input\/appdata10\/appdata10.csv\", low_memory=True)\ndata[\"hour\"] = data.hour.str.slice(1, 3)\ndata.info()","07f53e01":"data.isna().sum()","68f96346":"print(data.shape)\nprint(len(data.user.unique()))","806b34a1":"data.drop_duplicates(\"user\", inplace=True)","67107239":"table = data.corr()\nwith sns.axes_style(\"white\"):\n    mask = np.zeros_like(table)\n    mask[np.triu_indices_from(mask)] = True\n    plt.figure(figsize=(10, 10))\n    sns.heatmap(\n        round(table, 2),\n        cmap=\"Reds\",\n        mask=mask,\n        vmax=table.max().max(),\n        vmin=table.min().min(),\n        linewidths=0.5,\n        annot=True,\n        annot_kws={\"size\": 12},\n    ).set_title(\"Correlation Matrix App behavior dataset\")","f1ee22c1":"aux = pd.DataFrame(\n    data.groupby([\"dayofweek\", \"enrolled\"]).count()[\"user\"]\n).reset_index()\naux.enrolled = aux.enrolled.astype(str)\nfig = px.bar(\n    aux, y=\"user\", x=\"dayofweek\", color=\"enrolled\", text=\"user\", barmode=\"group\"\n)\nfig.update_traces(texttemplate=\"%{text:.2s}\", textposition=\"outside\")\nfig.update_layout(\n    title_text=\"Part of the week Users use to enroll.\",\n    title_font_size=20,\n    yaxis_title=\"Count\",\n    xaxis_title=\"Weekdays (0 = Sunday)\",\n)\nfig.show()","4f23167c":"aux = pd.DataFrame(data.groupby([\"hour\", \"enrolled\"]).count()[\"user\"]).reset_index()\naux.enrolled = aux.enrolled.astype(str)\nfig = px.bar(aux, y=\"user\", x=\"hour\", color=\"enrolled\", text=\"user\", barmode=\"group\")\nfig.update_traces(texttemplate=\"%{text:.2s}\", textposition=\"outside\")\nfig.update_layout(\n    title_text=\"Part of the day Users use to enroll.\",\n    title_font_size=20,\n    yaxis_title=\"Count\",\n    xaxis_title=\"Hour of the day (24h format)\",\n)\nfig.show()","f23652ea":"fig = px.histogram(data, x=\"numscreens\", marginal=\"box\", color=\"enrolled\", opacity=0.9,)\nfig.update_layout(\n    title_text=\"Histogram of number of screens (numscreens) accessed by users.\",\n    title_font_size=20,\n    yaxis_title=\"Count\",\n    xaxis_title=\"Number of screnns accessed\",\n)\nfig.show()","a5198c48":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Define color sets of paintings\nlabels = [\"No\", \"Yes\"]\nbin_colors = [\"red\", \"green\"]\nminigame = (\n    data.minigame.value_counts().reset_index().sort_values(\"index\").minigame.values\n)\nliked = data.liked.value_counts().reset_index().sort_values(\"index\").liked.values\nupf = (\n    data.used_premium_feature.value_counts()\n    .reset_index()\n    .sort_values(\"index\")\n    .used_premium_feature.values\n)\nenrolled = (\n    data.enrolled.value_counts().reset_index().sort_values(\"index\").enrolled.values\n)\n\n# Create subplots, using 'domain' type for pie charts\nspecs = [\n    [{\"type\": \"domain\"}, {\"type\": \"domain\"}],\n    [{\"type\": \"domain\"}, {\"type\": \"domain\"}],\n]\n\nfig = make_subplots(\n    rows=2,\n    cols=2,\n    specs=specs,\n    subplot_titles=[\"Minigame\", \"Used Premium Feature\", \"Enrolled\", \"Liked\"],\n)\n\n# Define pie charts\nfig.add_trace(\n    go.Pie(\n        labels=labels,\n        values=minigame,\n        name=\"Did the minigame?\",\n        marker_colors=bin_colors,\n    ),\n    1,\n    1,\n)\nfig.add_trace(\n    go.Pie(\n        labels=labels,\n        values=liked,\n        name=\"DId the user liked?\",\n        marker_colors=bin_colors,\n    ),\n    1,\n    2,\n)\nfig.add_trace(\n    go.Pie(\n        labels=labels, values=upf, name=\"Was premium user?\", marker_colors=bin_colors\n    ),\n    2,\n    1,\n)\nfig.add_trace(\n    go.Pie(\n        labels=labels,\n        values=enrolled,\n        name=\"Enrolled in the game?\",\n        marker_colors=bin_colors,\n    ),\n    2,\n    2,\n)\n\n# Tune layout and hover info\nfig.update_traces(\n    hole=0.3,\n    textposition=\"inside\",\n    hoverinfo=\"name\",\n    textinfo=\"percent\",\n    textfont_size=15,\n)\nfig.update_layout(\n    height=500,\n    width=700,\n    title_text=\"Binaries columns in pizza visualiation\",\n    title_font_size=20,\n    showlegend=False,\n)\n\nfig = go.Figure(fig)\nfig.show()","df02912c":"aux = data.dropna()\ndata[\"time_to_enroll\"] = pd.to_datetime(aux.enrolled_date) - pd.to_datetime(\n    aux.first_open\n)","e7ea6959":"how_much_days = [str(i.days) for i in data[\"time_to_enroll\"].dropna()]\nfig = px.histogram(how_much_days, height=400)\nfig.update_layout(\n    title_text=\"Histogram of time to enroll in days (how much time to enroll our customers?)\",\n    title_font_size=20,\n    xaxis_title=\"Time in days\",\n    yaxis_title=\"Count\",\n)\n\nfig.show()\nfig = px.histogram(how_much_days, height=400, log_y=True)\nfig.update_layout(\n    title_text=\"Histogram of time to enroll in days (how much time to enroll our customers?) - Log_y transformation\",\n    title_font_size=20,\n    xaxis_title=\"Time in days\",\n    yaxis_title=\"Count in log scale\",\n)\nfig.show()","119e1a3b":"import matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom string import punctuation\nimport nltk\n\npunctuation = [p for p in punctuation]\nstopwords = nltk.corpus.stopwords.words(\"english\")\nstopwords = stopwords + punctuation + [\"...\"] + [\"!!\"]\ntoken_punct = nltk.WordPunctTokenizer()\nstemmer = nltk.RSLPStemmer()\n\n\ndef remove_punct(my_str):\n    no_punct = \"\"\n    for char in my_str:\n        if char not in punctuation:\n            no_punct = no_punct + char\n    return no_punct\n\n\ndef tokenizer_column(serie):\n    clear_col = list()\n    for row in serie:\n        new_line = list()\n        line = token_punct.tokenize(remove_punct(row.lower()))\n        for word in line:\n            if word not in stopwords:  # stopwords\n                new_line.append(stemmer.stem(word))\n        clear_col.append(\" \".join(new_line))\n    return clear_col\n\n\ndef wordcloud(text, column_name, title):\n    all_words = \" \".join([text for text in text[column_name]])\n    wordcloud = WordCloud(\n        width=800, height=500, max_font_size=110, collocations=False\n    ).generate(all_words)\n    plt.figure(figsize=(24, 12))\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.title(title)\n    plt.show()\n\n\nwordcloud(data, \"screen_list\", \"screens\")","7ca264be":"result = []\n[result.extend(el) for el in data.screen_list.str.split(\",\")]\nresult_set = set(result)\nscreen_list_dummies = pd.get_dummies(\n    pd.Series(result), prefix_sep=\",\", columns=result_set\n)\nscreen_list_dummies[\"enrolled\"] = data.enrolled","aadd9eab":"df = (screen_list_dummies.mean() * 100).reset_index()\ndf.columns = [\"screen\", \"acessed\"]\nfig = px.bar(\n    df.sort_values(\"acessed\", ascending=False)[1:],\n    x=\"screen\",\n    y=\"acessed\",\n    color=\"acessed\",\n    height=600,\n)\nfig.update_layout(\n    title_text=\"The most accessed screens in the App\",\n    title_font_size=20,\n    xaxis_title=\"Screen's names\",\n    yaxis_title=\"Access by users in %\",\n    xaxis_tickangle=45,\n)\n\nfig.show()","fc4473fd":"table = screen_list_dummies.corr()\nwith sns.axes_style(\"white\"):\n    plt.figure(figsize=(12, 12))\n    sns.heatmap(round(table, 4), cmap=\"Reds\", vmax=1, vmin=0, linewidths=0,).set_title(\n        \"Correlation matrix between screen access\"\n    )","1d175513":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import OneHotEncoder\n\nenc = OneHotEncoder(handle_unknown=\"ignore\")\n\ndata.screen_list = tokenizer_column(data.screen_list.str.replace(\",\", \" \"))\nvectorizer = TfidfVectorizer(\n    max_features=400,\n    min_df=10,\n    ngram_range=(1, 3),\n    analyzer=\"word\",\n    stop_words=\"english\",\n)\n\nX = np.concatenate(\n    (\n        ## NLP`\n        vectorizer.fit_transform(data[\"screen_list\"]).toarray(),\n        ## OHE\n        enc.fit_transform(data[[\"dayofweek\", \"hour\", \"age\", \"numscreens\",]]).toarray(),\n        ## BIN\n        data[[\"minigame\", \"used_premium_feature\", \"liked\",]].values,\n    ),\n    axis=1,\n)\n\ny = data.enrolled.values","9edfb075":"X.shape","d582c207":"import time\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\n\n# Models\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import BayesianRidge\n\nmodels = [\n    (\"RandomForestClassifier\", RandomForestClassifier()),\n    (\"MLPClassifier\", MLPClassifier()),\n    (\"BayesianRidge\", BayesianRidge()),\n]\n\n\ndef train_test_validation(model, name, X, Y):\n    print(f\"Starting {name}.\")  # Debug\n    ini = time.time()  # Start clock\n    scores = cross_val_score(model, X, Y, cv=4)  # Cross-validation\n    fim = time.time()  # Finish clock\n    print(f\"Finish {name}.\")  # Debug\n    return (name, scores.mean(), scores.max(), scores.min(), fim - ini)","35fb837b":"%%time\nresults = [ train_test_validation(model[1], model[0], X, y) for model in models ] # Testing for all models\nresults = pd.DataFrame(results, columns=['Classifier', 'Mean', 'Max', 'Min', 'TimeSpend (s)']) # Making a data frame\nresults","f8cd924f":"from sklearn.model_selection import RandomizedSearchCV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start=1, stop=1000, num=100)]\n# Number of features to consider at every split\nmax_features = [\"auto\", \"sqrt\"]\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(1, 1100, num=110)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 20, 25, 30]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4, 6, 8, 10]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {\n    \"n_estimators\": n_estimators,\n    \"max_features\": max_features,\n    \"max_depth\": max_depth,\n    \"min_samples_split\": min_samples_split,\n    \"min_samples_leaf\": min_samples_leaf,\n    \"bootstrap\": bootstrap,\n}\n\n# Use the random grid to search for best hyperparameters\n# First create the base model to tune\nrf = RandomForestClassifier(n_jobs=-1)\n# Random search of parameters, using 3 fold cross validation,\n# search across 100 different combinations, and use all available cores\nrf_random = RandomizedSearchCV(\n    estimator=rf,\n    param_distributions=random_grid,\n    n_iter=30,\n    cv=4,\n    verbose=10,\n    random_state=42,\n    n_jobs=-1,\n)\n# Fit the random search model\nrf_random.fit(X[:10000], y[:10000])","dae2c44f":"p = rf_random.best_params_\nprint(p)\nrfr = RandomForestClassifier(\n    n_estimators=p[\"n_estimators\"],\n    max_features=p[\"max_features\"],\n    max_depth=p[\"max_depth\"],\n    min_samples_split=p[\"min_samples_split\"],\n    min_samples_leaf=p[\"min_samples_leaf\"],\n    bootstrap=p[\"bootstrap\"],\n    n_jobs=-1,\n)\n\nresults = train_test_validation(rfr, \"RandomForestRegressorT\", X, y)\nresults = pd.DataFrame(results).T\nresults.columns = [\"Classifier\", \"Mean\", \"Max\", \"Min\", \"TimeSpend (s)\"]\nresults","f0f74c86":"%%time\nfrom sklearn.manifold import TSNE\n\n\nX_embedded = TSNE(n_components=2, n_jobs=-1).fit_transform(X[:10000])\nX_embedded.shape","c2cf6f92":"df = pd.DataFrame(X_embedded)\ndf.columns = [\"Component 1\", \"Component 2\"]\ndf[\"Target\"] = y[:10000]\n\nfig = px.scatter(df, x=\"Component 1\", y=\"Component 2\", color=\"Target\")\nfig.update_layout(\n    title_text=\"Class visualization in 2D.\",\n    title_font_size=20,\n    yaxis_title=\"Component 2\",\n    xaxis_title=\"Component 1\",\n)\nfig.show()","362b4d84":"%%time\nX_embedded_3D = TSNE(n_components=3,n_jobs=-1).fit_transform(X[:10000])\nX_embedded_3D.shape","6948ff31":"df_3D = pd.DataFrame(X_embedded_3D)\ndf_3D.columns = [\"Component 1\", \"Component 2\", \"Component 3\"]\ndf_3D[\"Target\"] = y[:10000]\n\nfig = px.scatter_3d(\n    df_3D, x=\"Component 1\", y=\"Component 2\", z=\"Component 3\", color=\"Target\"\n)\nfig.update_layout(\n    title_text=\"Class visualization in 3D.\", title_font_size=20,\n)\nfig.show()","a96fdeca":"# Importing the libs","9ef2b28d":"There's a small difference between the days of the week.","7f159739":"# Data transformation","c0e83cba":"Looks like we have a relationship between the numscreens and enrolled, how much screen my user sees, more a probability to enroll.","1400e681":"## Hour","116361e1":"There are no relations between the screens access, something like if you wanna go to this screen you must pass through another screen.","1693fb92":"## Binaries features (minigame, used_premium_feature, enrolled, and liked)","85bb39fc":"## Random Forest","f3733fb5":"## How much time to enroll? (in days)","66073d98":"#### Two dimensions ","8596b788":"**How much NaN values we have in the whole dataset?**","380b3bc9":"## Day of week","45d7d5d1":"## Features Visualization","9800d131":"**First correlation matrix using the numerical columns.**","728f8384":"**User column is a unique id?**","6a0ab635":"There's a huge difference between the part of the day in which the user accesses the app to use and enroll.","8bffbb76":"## Screen list","4c85b243":"#### Three dimensions","df43ce14":"I like to use a code formatter for python. =)","0fa742df":"# Machine Learning\n## Testing models","6459b8d5":"# TSNE","c729f93b":"## Numscreens","7581baa2":"**Dropping duplicates lines...**"}}