{"cell_type":{"9e4f3a87":"code","f0ba1f0d":"code","79789d33":"code","52243ad5":"code","f66c25a7":"code","d9e72f16":"code","0d4c7fed":"code","4988e4ac":"code","52547c8a":"code","e117ed25":"code","8440bab6":"code","1f0f56f7":"code","cbea6f48":"code","9ba7a076":"code","4686560b":"code","9dee9684":"code","c7bf471d":"code","8c5467e0":"code","6deb87ad":"code","7d221900":"code","0288d2c2":"code","766e71cc":"code","ff21a578":"code","b70f7316":"code","d7efa8e3":"code","950db166":"code","73252a8c":"code","f249bc53":"code","1147adf6":"code","5182f047":"code","0d93e9e1":"code","9f1265dc":"code","5a4a8161":"code","fe09dc5d":"code","13861ef7":"code","485fd330":"code","2efc3aa3":"code","671a4233":"code","1c3a95c6":"code","6b7a2902":"code","57bed1b9":"code","a035c04f":"code","8ef45000":"code","d97515d6":"code","29b7bba8":"code","ff06d80f":"code","29595532":"code","9332f9bd":"code","f48d71fe":"code","b8bbe363":"code","30a73991":"code","6fd43fb8":"markdown","0354351b":"markdown","2498f0c9":"markdown","dafc3529":"markdown","10880835":"markdown","b4a3f0e7":"markdown"},"source":{"9e4f3a87":"# loading guns (-_-)... i'm kidding loading requred packages \nimport numpy as np\nimport pandas as pd\nimport math \nimport matplotlib.pyplot as plt\nimport missingno as msno\nimport seaborn as sns","f0ba1f0d":"#useing pands we load the dataset  \ndata = pd.read_csv(\"..\/input\/insurance.csv\")\ndfrev = pd.read_csv(\"..\/input\/insurance.csv\")","79789d33":"data.head()","52243ad5":"data.isnull().sum().any()","f66c25a7":"data.dtypes","d9e72f16":"data.shape","0d4c7fed":"#LabelEncoder to cover classes to num value \nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(data['smoker'])\ndata['smoker']=le.transform(data['smoker'])\nle.fit(data['region'])\ndata['region']=le.transform(data['region'])\nle.fit(data['sex'])\ndata['sex']=le.transform(data['sex'])\ndata.head()","4988e4ac":"#correlations plot\nsns.heatmap(data.corr(),annot=True, cmap='terrain', linewidths=0.1)\nfig=plt.gcf()\nfig.set_size_inches(8,6)\nplt.show()","52547c8a":"sns.regplot(x=\"bmi\", y=\"charges\", data=data)","e117ed25":"from sklearn.model_selection import train_test_split","8440bab6":"data_X = data.drop(['charges'],axis=1)\ndata_Y = data['charges']  \n\ntrainX, testX, train_Y, test_Y = train_test_split(data_X, data_Y, test_size=0.2, random_state=122)","1f0f56f7":"print(trainX.shape)\nprint(testX.shape)\nprint(train_Y.shape)\nprint(test_Y.shape)","cbea6f48":"#standardizeding  the data\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(trainX)\ntrainX = scaler.transform(trainX) \ntestX = scaler.transform(testX)","9ba7a076":"#Loading the  Linear Regression Model \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\nreg = LinearRegression()\nX_train, X_test, y_train, y_test = train_test_split(trainX, train_Y, test_size=0.4, \n                                                    random_state=123)\nreg.fit(X_train, y_train)\npredict1 = reg.predict(testX)\nr2_score(test_Y,predict1) ","4686560b":"# regression coefficients \nprint('Coefficients: \\n', reg.coef_) \n\n# variance score: 1 means perfect prediction \nprint('Variance score: {}'.format(reg.score(X_test, y_test))) \n\n# plot for residual error \n\n## setting plot style \nplt.style.use('fivethirtyeight') \n\n## plotting residual errors in training data \nplt.scatter(reg.predict(X_train), reg.predict(X_train) - y_train, \n\t\t\tcolor = \"green\", s = 10, label = 'Train data') \n\n## plotting residual errors in test data \nplt.scatter(reg.predict(X_test), reg.predict(X_test) - y_test, \n\t\t\tcolor = \"blue\", s = 10, label = 'Test data') \n\n## plotting line for zero residual error \nplt.hlines(y = 0, xmin = 0, xmax = 50, linewidth = 2) \n\n## plotting legend \nplt.legend(loc = 'upper right') \n\n## plot title \nplt.title(\"Residual errors\") \n\n## function to show plot \nplt.show() \n","9dee9684":"X_train, X_test, y_train, y_test = train_test_split(trainX, train_Y, test_size=0.4, \n                                                    random_state=125)\nreg.fit(X_train, y_train)\npredict2 = reg.predict(testX)\nr2_score(test_Y,predict2) ","c7bf471d":"X_train, X_test, y_train, y_test = train_test_split(trainX, train_Y, test_size=0.4, \n                                                    random_state=205)\nreg.fit(X_train, y_train)\npredict3 = reg.predict(testX)\nr2_score(test_Y,predict3) ","8c5467e0":"X_train, X_test, y_train, y_test = train_test_split(trainX, train_Y, test_size=0.4, \n                                                    random_state=4050)\nreg.fit(X_train, y_train)\npredict4 = reg.predict(testX)\nr2_score(test_Y,predict4) ","6deb87ad":"X_train, X_test, y_train, y_test = train_test_split(trainX, train_Y, test_size=0.4, \n                                                    random_state=900)\nreg.fit(X_train, y_train)\npredict5 = reg.predict(testX)\nr2_score(test_Y,predict5) ","7d221900":"X_train, X_test, y_train, y_test = train_test_split(trainX, train_Y, test_size=0.4, \n                                                    random_state=800)\nreg.fit(X_train, y_train)\npredict6 = reg.predict(testX)\nr2_score(test_Y,predict6) ","0288d2c2":"X_train, X_test, y_train, y_test = train_test_split(trainX, train_Y, test_size=0.4, \n                                                    random_state=220)\nreg.fit(X_train, y_train)\npredict7 = reg.predict(testX)\nr2_score(test_Y,predict7) ","766e71cc":"X_train, X_test, y_train, y_test = train_test_split(trainX, train_Y, test_size=0.4, \n                                                    random_state=200)\nreg.fit(X_train, y_train)\npredict8 = reg.predict(testX)\nr2_score(test_Y,predict8) ","ff21a578":"X_train, X_test, y_train, y_test = train_test_split(trainX, train_Y, test_size=0.4, \n                                                    random_state=115)\nreg.fit(X_train, y_train)\npredict9 = reg.predict(testX)\nr2_score(test_Y,predict9)","b70f7316":"X_train, X_test, y_train, y_test = train_test_split(trainX, train_Y, test_size=0.4, \n                                                    random_state=100)\nreg.fit(X_train, y_train)\npredict10 = reg.predict(testX)\nr2_score(test_Y,predict10) ","d7efa8e3":"d = {'predict1':predict1,'predict2':predict2,'predict3':predict3,'predict4':predict4,'predict5':predict5,'predict6':predict6,'predict7':predict7,'predict8':predict8,'predict9':predict9,'predict10':predict10}\npredict = pd.DataFrame(d)","950db166":"testY = test_Y.to_frame()\ntestY = testY.reset_index()\ntestY = testY.drop('index',axis = 1)\ntestY.head()","73252a8c":"avg_pred = predict.mean(axis = 1)\nvariance = predict.var(axis = 1)\npredict['Avg_pred'] = avg_pred\npredict['Variance'] = variance * .9\npredict['actual'] = testY['charges']","f249bc53":"predict['Error'] = (predict['predict1'] - predict['actual']) ** 2 + \\\n                     (predict['predict2'] - predict['actual']) ** 2 + \\\n                     (predict['predict3'] - predict['actual']) ** 2 + \\\n                     (predict['predict4'] - predict['actual']) ** 2 + \\\n                     (predict['predict5'] - predict['actual']) ** 2 + \\\n                     (predict['predict6'] - predict['actual']) ** 2 + \\\n                     (predict['predict7'] - predict['actual']) ** 2 + \\\n                     (predict['predict8'] - predict['actual']) ** 2 + \\\n                    (predict['predict9'] - predict['actual']) ** 2 + \\\n                    (predict['predict10'] - predict['actual']) ** 2 \npredict['Error'] = predict['Error'] \/ 10 ","1147adf6":"sns.swarmplot(x='Variance',y='Error',data=predict)","5182f047":"linear_reg_predict = predict\nlinear_reg_predict.head()","0d93e9e1":"ML_Regr_bias_var_err = pd.DataFrame()\nKnn_Regr_bias_var_err = pd.DataFrame()\nDT_Regr_bias_var_err = pd.DataFrame()\nRF_Regr_bias_var_err = pd.DataFrame()\nSVM_Regr_bias_var_err = pd.DataFrame()","9f1265dc":"from sklearn import linear_model\nfrom sklearn.metrics import r2_score\n\ndef test_pred_ML_Regr(X_train, y_train):\n    regr = linear_model.LinearRegression()\n    regr_model = regr.fit(X_train, y_train)\n    pred = regr_model.predict(testX)\n    print(\"r2_score:\",r2_score(test_Y,pred))\n    return pred","5a4a8161":"from sklearn.neighbors import KNeighborsRegressor\nfrom sklearn import neighbors\nfrom sklearn.metrics import mean_squared_error \nfrom math import sqrt","fe09dc5d":"rmse_val = [] #to store rmse values for different k\nfor K in range(20):\n    K = K+1\n    model = neighbors.KNeighborsRegressor(n_neighbors = K)\n    x_train, x_test, y_train, y_test = train_test_split(trainX, train_Y, test_size=0.4, random_state = 123)\n    knn_model = model.fit(x_train, y_train)  #fit the model\n    pred=knn_model.predict(testX) #make prediction on test set\n    error = sqrt(mean_squared_error(test_Y,pred)) #calculate rmse\n    rmse_val.append(error) #store rmse values\n    print('RMSE value for k= ' , K , 'is:', error)","13861ef7":"def test_pred_Knn_Regr(X_train, y_train):\n    knn = neighbors.KNeighborsRegressor(n_neighbors = 6)\n    knn_model = knn.fit(X_train, y_train)\n    pred = knn_model.predict(testX)\n    print(\"r2_score:\",r2_score(test_Y,pred))\n    return pred","485fd330":"from sklearn.tree import DecisionTreeRegressor\nDt_regr = DecisionTreeRegressor(max_depth=5)\n\ndef test_pred_DT_Regr(X_train, y_train):\n    Dt_regr_model = Dt_regr.fit(X_train, y_train)\n    pred = Dt_regr_model.predict(testX)\n    print(\"r2_score:\",r2_score(test_Y,pred))\n    return pred","2efc3aa3":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.datasets import make_regression\n\ndef test_pred_RF_Regr(X_train, y_train):\n    RF_regr = RandomForestRegressor(max_depth=2, random_state=0, n_estimators=100)\n    RF_regr_model = RF_regr.fit(X_train, y_train)\n    pred = RF_regr_model.predict(testX)\n    print(\"r2_score:\",r2_score(test_Y,pred))\n    return pred","671a4233":"from sklearn.svm import SVR\n\ndef test_pred_SVM_Regr(X_train, y_train):\n    SVM_regr = SVR()\n    SVM_regr_model = SVM_regr.fit(X_train, y_train)\n    pred = SVM_regr_model.predict(testX)\n    print(\"r2_score:\",r2_score(test_Y,pred))\n    return pred","1c3a95c6":"def sample_predict_target():\n    randm_state = 300\n    for index in range(1,11):\n        #print(\"index:\",index)\n        col = \"predict\" + str(index)\n        print(\"column:\",col)\n        X_train, t_x, y_train, t_Y = train_test_split(trainX, train_Y, test_size=0.4, random_state= randm_state+index)\n        Knn_Regr_bias_var_err[col] =test_pred_Knn_Regr(X_train, y_train)\n        DT_Regr_bias_var_err[col] =test_pred_DT_Regr(X_train, y_train)\n        RF_Regr_bias_var_err[col] =test_pred_RF_Regr(X_train, y_train)\n        SVM_Regr_bias_var_err[col] =test_pred_SVM_Regr(X_train, y_train)\n        \n    return","6b7a2902":"def calc_bias_var_err(predict):\n    #print(\"inside: calc_bias_var_err\")\n    avg_pred = predict.mean(axis = 1)\n    variance = predict.var(axis = 1)\n    predict['avg_pred'] = avg_pred\n    predict['variance'] = variance * .9\n    predict['actual'] = testY['charges']\n    #print(\"inside1: calc_bias_var_err\")\n    predict['bias'] = (predict['avg_pred'] - predict['actual']) ** 2\n    print(\"inside2: calc_bias_var_err\")\n    predict['error'] = (predict['predict1'] - predict['actual']) ** 2 + \\\n                     (predict['predict2'] - predict['actual']) ** 2 + \\\n                     (predict['predict3'] - predict['actual']) ** 2 + \\\n                     (predict['predict4'] - predict['actual']) ** 2 + \\\n                     (predict['predict5'] - predict['actual']) ** 2 + \\\n                     (predict['predict6'] - predict['actual']) ** 2 + \\\n                     (predict['predict7'] - predict['actual']) ** 2 + \\\n                     (predict['predict8'] - predict['actual']) ** 2 + \\\n                    (predict['predict9'] - predict['actual']) ** 2 + \\\n                    (predict['predict10'] - predict['actual']) ** 2 \n    print(\"inside3: calc_bias_var_err\")\n    predict['error'] = predict['error'] \/ 10 \n    print(\"returning from: calc_bias_var_err\")\n    return predict","57bed1b9":"test_pred_Knn_Regr_arry=test_pred_Knn_Regr(X_train, y_train)\ntest_pred_Knn_Regr_arry= pd.DataFrame(test_pred_Knn_Regr_arry)\ntest_pred_Knn_Regr_arry.head()","a035c04f":"sample_predict_target()","8ef45000":"Knn_Regr_bias_var_err.head()","d97515d6":"linear_reg_predict_var_err = calc_bias_var_err(linear_reg_predict)\nKnn_Regr_bias_var_err= calc_bias_var_err(Knn_Regr_bias_var_err)\nDT_Regr_bias_var_err= calc_bias_var_err(DT_Regr_bias_var_err)\nRF_Regr_bias_var_err= calc_bias_var_err(RF_Regr_bias_var_err)\nSVM_Regr_bias_var_err= calc_bias_var_err(SVM_Regr_bias_var_err)","29b7bba8":"Knn_Regr_bias_var_err.head()","ff06d80f":"DT_Regr_bias_var_err.head()","29595532":"RF_Regr_bias_var_err.head()","9332f9bd":"SVM_Regr_bias_var_err.head()","f48d71fe":"def calc_avg_bias_var_err(summary_Regr_bias_var_err,model_df, model):\n    print(\"inside: calc_avg_bias_var_err: model\\n\",model)\n    #model_df.head(10)\n    error = model_df.bias + model_df.variance\n    print(\"bias+variance: error:\\n\",error.head(10))\n    print(\"calculated error:\\n\",model_df.error.head(10))\n    \n    #print(model_df.head(10))\n    bias_avg = model_df.bias.mean()\n    var_avg = model_df.variance.mean()\n    err_avg = model_df.error.mean()\n    \n    summary_Regr_bias_var_err.append((model,bias_avg,var_avg,err_avg))\n    print(\"returning from: calc_avg_bias_var_err\")\n    return summary_Regr_bias_var_err","b8bbe363":"summary_Regr_bias_var_err = []\nsummary_Regr_bias_var_err= calc_avg_bias_var_err(summary_Regr_bias_var_err,linear_reg_predict,\"ML_Regr\")\nsummary_Regr_bias_var_err= calc_avg_bias_var_err(summary_Regr_bias_var_err,Knn_Regr_bias_var_err,\"Knn_Regr\")\nsummary_Regr_bias_var_err= calc_avg_bias_var_err(summary_Regr_bias_var_err,DT_Regr_bias_var_err,\"DT_Regr\")\nsummary_Regr_bias_var_err= calc_avg_bias_var_err(summary_Regr_bias_var_err,RF_Regr_bias_var_err,\"RF_Regr\")\nsummary_Regr_bias_var_err= calc_avg_bias_var_err(summary_Regr_bias_var_err,SVM_Regr_bias_var_err,\"SVM_Regr\")   \n\ndf_avg_bias_var_err = pd.DataFrame.from_records(summary_Regr_bias_var_err, columns=['Model','bias','variance','error'])\n","30a73991":"df_avg_bias_var_err","6fd43fb8":"look like age and smoking is highly correated to charges ","0354351b":"I fell the best way to convert the categorical to numerical columns is useing *LabelEncoder* ","2498f0c9":"Variance and Bias of all the models ","dafc3529":"lets have a birds eye viwe on the dataset","10880835":"We all know that data is not behaved in the manner that we want\/need, that explanes all the upcoming methods and algos understand the flow of data","b4a3f0e7":"The idea is to keep the 20% data as unseen data and the 80% to learn, further we split the 80% into 40-60% to train the model, the way we feed the data to train is also a factor so, we take different random state(seed value) and see how the model behaves.\nThen we calculate the bias and variance that is given by Error i.e Sum of squred error\nSSE is the sum of the squared differences between each observation and its group's mean. It can be used as a measure of variation within a data set \n\nvariance :\nThe variance (\u03c32), is defined as the sum of the squared distances of each term in the distribution from the mean (\u03bc), divided by the number of terms in the distribution (N).\n![image.png](attachment:image.png)\n\nBias measures how far your observed value is from a target value. Determine bias by a reference value or estimate from outside sources such as proficiency testing results or the Bio-Rad Unity\u2122 Interlaboratory Program. Express bias as a percentage.\n"}}