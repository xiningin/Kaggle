{"cell_type":{"dc9e7a52":"code","2e83a7f3":"code","39ec690d":"code","1bbb6451":"code","1cd784d7":"code","7a735a8a":"code","765aafd5":"code","b5192904":"code","09a26838":"code","6861230c":"code","cc659efd":"code","c0b22272":"code","0f52d325":"code","2a01977e":"code","84f9316f":"code","c00d60b8":"code","056adf15":"markdown","72295004":"markdown","02db2a47":"markdown","e447d685":"markdown","2be10f2b":"markdown","b6680766":"markdown","20067602":"markdown","7230df27":"markdown","ccb0894b":"markdown","240ccada":"markdown","208d8330":"markdown","37a2c95f":"markdown","fc815a08":"markdown","6027c766":"markdown","c6cdb5ed":"markdown","cf0788c4":"markdown"},"source":{"dc9e7a52":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2e83a7f3":"path = \"\/kaggle\/input\/predicting-a-pulsar-star\/pulsar_stars.csv\"\nstars = pd.read_csv(path)\nresults = []\nprint(\"size of our data : \", len(stars))\nstars.head()","39ec690d":"print(\"Checking if there is missing values :\\n\",stars.isnull().sum())","1bbb6451":"stars.columns\nstars.rename(columns={\" Excess kurtosis of the DM-SNR curve\": \" Excess kurtosis of the DM SNR curve\",\" Skewness of the DM-SNR curve\":\"Skewness of the DM SNR curve\", \" Mean of the DM-SNR curve\" : \" Mean of the DM SNR curve\", \" Standard deviation of the DM-SNR curve\" : \" Standard deviation of the DM SNR curve\" },inplace=True)\nstars.columns","1cd784d7":"cor = stars.corr()","7a735a8a":"import seaborn as sns; sns.set()\nplt.figure(figsize=(18,10))\n\n\nax = sns.heatmap(\n    cor, \n    center=0,\n    vmin = -1, vmax = 1.0,\n    linewidth=.9,\n    cmap =  sns.color_palette(\"RdBu_r\", 7),#cmap=\"YlGnBu\",\n    annot=True,\n    square=True,\n\n)","765aafd5":"mask = np.zeros_like(cor)\nmask[np.triu_indices_from(mask)] = True\n\nwith sns.axes_style(\"white\"):\n    f, ax = plt.subplots(figsize=(18, 10))\n    ax = sns.heatmap(cor, center = 0, linewidth = 0.9, vmin = -1, vmax = 1, \n    cmap =  sns.color_palette(\"RdBu_r\", 7),annot = True, mask=mask, square=True)\n    ","b5192904":"corr_m = cor.abs()\nsol = (corr_m.where(np.triu(np.ones(corr_m.shape), k=1).astype(np.bool))\n                 .stack()\n                 .sort_values(ascending=False))\nsol[:3]","09a26838":"from heapq import nlargest\nfrom operator import itemgetter\nimport itertools\nfrom itertools import combinations\nfrom scipy import stats\nall_cor = []\nall_cord = {}\nfor one,two in itertools.combinations(stars.columns,2):\n\n    v,_ = stats.pearsonr(stars[one],stars[two])\n    all_cor.append(f\"Correlation btw {one} and {two} is: {v:.4f}\")\n    all_cord[one+\"-\"+two] = round(v,4)\n\nall_cor\n\nm = dict(sorted(all_cord.items(), key = itemgetter(1), reverse = True)[:3])\nprint(\"The 3 strongest correlations are : \",m)","6861230c":"\nimport matplotlib.pyplot as plt\n\ni = 0\nplt.figure()\nf, ax = plt.subplots(1, 3, figsize=(21, 7), sharex=True)\n#for first,sec in itertools.combinations(stars.columns.drop(stars.columns[len(stars.columns)-1]),2):\nfor key,val in m.items():\n    #print(first,sec)\n    pair = key.split(\"-\")\n    first = pair[0]\n    sec = pair[1]\n    \n    sns.scatterplot(x=first, y=sec, data=stars, hue=\"target_class\", ax = ax[i])\n    if i == 2:\n        break\n    i += 1\n    ","cc659efd":"fr = 0.1\nvsize = int(len(stars)*fr)\n\ntrain = stars[:-2*vsize]\nvalid = stars[-2*vsize:-vsize]\ntest = stars[:-vsize]\n\nfor each in [train,valid,test]:\n    print(f\"Percentage of target values : {stars.target_class.mean():.4f}\")","c0b22272":"import lightgbm as lgb\nfrom sklearn import metrics\nval_pred = []\nground = []\ndef training(feat_cols):\n    plt.figure()\n    global val_pred, ground\n    evals_result = {}\n    \n    dtrain = lgb.Dataset(data=train[feat_cols], label=train[\"target_class\"])\n    dvalid = lgb.Dataset(data=valid[feat_cols], label=valid[\"target_class\"])\n    dtest = lgb.Dataset(data=test[feat_cols], label=test[\"target_class\"])\n\n    param = {\"num_leaves\" : 64, \"objectives\":\"binary\"}\n    param[\"metric\"] = \"auc\"\n\n    num_round = 500\n    bst = lgb.train(param,dtrain,num_round,valid_sets=[dvalid],evals_result = evals_result, early_stopping_rounds = 10)\n    \n    #lgb.plot_metric(evals_result, metric=\"auc\", figsize=(7,7))\n    lgb.plot_importance(bst, max_num_features=10,figsize=(10,10))\n    \n    ypred = bst.predict(test[feat_cols])\n    score = metrics.roc_auc_score(test[\"target_class\"], ypred)\n\n    val_pred = ypred\n    ground = test[\"target_class\"]\n    \n    print(f\"our score is: {score:.4f}\")\n    return score, dvalid","0f52d325":"\nfeatures = []\nfor key,val in m.items():\n    feat = key.split(\"-\")\n    for each2 in feat:\n        if each2 not in features:\n            features.append(each2)\n#features\nres = {\"baseline\":\"\",\"selected features\":\"\"}\n\nres[\"selected features\"],_ = (training(features))\n\n## With all columns:\nfeat_cols = stars.columns.drop(\"target_class\")\nres[\"baseline\"],_ = (training(feat_cols))\n\nres\n\n","2a01977e":"diferr = pd.DataFrame(columns=[\"Prediction\", \"Ground_Truth\"])\ndiferr[\"Ground_Truth\"] = ground\ndiferr[\"Prediction\"] = val_pred\ndiferr\nprint(\"Predictions for label = 0. Not pulsar stars\\n\",diferr.loc[diferr[\"Ground_Truth\"]==0])\nprint(\"Predictions for label = 1. Pulsar stars\\n\",diferr.loc[diferr[\"Ground_Truth\"]==1])","84f9316f":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (roc_curve, auc, accuracy_score)\nfrom sklearn.model_selection import GridSearchCV\n\nplt.figure(figsize=(10,10))\nvalAcc = accuracy_score(ground, np.round(val_pred))\nfprVal, tprVal, thresholdsVal = roc_curve(ground, val_pred)\nvalAUC =  auc(fprVal, tprVal)\nprint(\"Our threscholds : {}. Type : {}. Lenght : {}\".format(thresholdsVal, type(thresholdsVal), len(thresholdsVal)))\nprint(\"valAUC : {} and valAcc : {}\".format(valAUC, valAcc))\n#Plot ROC curve from tpr and fpr.\nplt.plot(fprVal, tprVal, label=\"Validation\")\nplt.legend()\nplt.ylabel('True positive rate.')\nplt.xlabel('False positive rate')\nplt.title(\"ROC curve for validation\")\nplt.show()","c00d60b8":"import csv\ncsvfile = \"\/kaggle\/working\/results.csv\"\n\nwith open(csvfile, \"w\") as output:\n    writer = csv.writer(output, lineterminator='\\n')\n    for val in results:\n        writer.writerow([val])  \n","056adf15":"Defining our model:","72295004":"We can see that our model has a much higher prediction of TPR than of FPT! This is way our score is close to the value 1 (0.9897)","02db2a47":"For better visualization, we can plot some scatter graphs to see the correlations between the features. We will not display all possible combinations. But you can do that uncommenting the the first foor loop!","e447d685":"results =[\"base_TEST_all_columns0.9897150578428906\",\n          \"base_TEST_first_4_columns0.9862164089395752\",\n          \"base_TEST_last_4_columns0.9355167561834904\",\n          \"base_TEST_1st_and_7th_columns0.9742193387833641\",\n          \"base_TEST_1st_and_3th_columns0.971777916403\",\n          \"base_TEST_first_2_columns0.9605646569128446\"]","2be10f2b":"This correlation matrix is visualized for instance with a heatmap plot:","b6680766":"Choosing the feature columns:","20067602":"1. From the above graphs, we can easily observe the positive correlation between the features as the linear relation between them has a positive coefficient (an increase in one of the variables result in an increase of the other one).\n2. Mean of the DM SNR curve doesn't tell us much about the nature of the star (we have Pulsar and not-Pulsar stars from all the possible range of this variable)\n3. In the other hand, the Standard Deviation of the DM SNR says us that stars with this variable with values < 40 have a great probability to be a Pulsar\n4. The same for the Skewness of the Integrated Profile: stars with values > 10 has a great probability to be a Pulsar","7230df27":"These numbers may not tell too much if we don't know exactly what a binary regression classifier is doing. \n\nAccordling to https:\/\/developers.google.com\/machine-learning\/crash-course\/classification\/roc-and-auc:\n\n> AUC provides an aggregate measure of performance across all possible classification thresholds. One way of interpreting AUC is as the probability that the model ranks a random positive example more highly than a random negative example. For example, given the following examples, which are arranged from left to right in ascending order of logistic regression predictions:\n> \n> Positive and negative examples ranked in ascending order of logistic regression score\n![graph](http:\/\/developers.google.com\/machine-learning\/crash-course\/images\/AUCPredictionsRanked.svg)> \n> Figure 6. Predictions ranked in ascending order of logistic regression score.\n> \n> AUC represents the probability that a random positive (green) example is positioned to the right of a random negative (red) example.\n\nNow it make sense that our model is predicting a probability that is bigger for targeting 1 than for targeting 0. This is because, for classifying a star as a Pulsar Star (label = 1), the model should predict a probability that is closer to 1 than the probability of a not Pulsar Star (label = 0). The last should predict probabilities that are closer to 0.\n\nBelow we can visualize the ROC curve, that is the area below the graph formed by the True Positive Rate (the model is predicting well) and the False Positive Rate (the model is saying that a star is a Pulsar Star when actually is not)\n","ccb0894b":"Score for all columns features : **0.9897150578428906 with 17 iterations**\nScore for first 4 columns as features : **0.9862164089395752 with 19 iterations**\nScore for last 4 columns as features : 0.9355167561834904 with 16 iterations\nScore for 1st and 7th columns as features: **0.9742193387833641 with 17 iterations**\nScore for 1st and 3th columns as features (*worst pearson'r correlation): 0.971777916403* with 26 iterations\nScore for first 2 columns as features *(best pearson'r correlation) :0.9605646569128446* with 12 iterations","240ccada":"As a symetrical matrix, we can just visualize its half:","208d8330":"Obs : targe_class = 0 means that the star is not a \"Pulsar Star\", whereas 1 is a \"Pulsar Star\"","37a2c95f":"Now lets take a look at what the model has as output from its predictions:","fc815a08":"Lets see the correlations between the features!","6027c766":"![https:\/\/storage.googleapis.com\/kaggle-datasets-images\/25855\/32949\/ed5875d8aff7555fb428720964cc173f\/dataset-cover.jpg?t=2018-05-09-14-31-28](http:\/\/storage.googleapis.com\/kaggle-datasets-images\/25855\/32949\/ed5875d8aff7555fb428720964cc173f\/dataset-cover.jpg?t=2018-05-09-14-31-28)\n\nPREDICTING A PULSAR STAR\nDr Robert Lyon\n\nHTRU2 is a data set which describes a sample of pulsar candidates collected during the High Time Resolution Universe Survey .\n\nPulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter .\n\nAs pulsars rotate, their emission beam sweeps across the sky, and when this crosses our line of sight, produces a detectable pattern of broadband radio emission. As pulsars\nrotate rapidly, this pattern repeats periodically. Thus pulsar search involves looking for periodic radio signals with large radio telescopes.\n\nEach pulsar produces a slightly different emission pattern, which varies slightly with each rotation . Thus a potential signal detection known as a 'candidate', is averaged over many rotations of the pulsar, as determined by the length of an observation. In the absence of additional info, each candidate could potentially describe a real pulsar. However in practice almost all detections are caused by radio frequency interference (RFI) and noise, making legitimate signals hard to find.\n\nMachine learning tools are now being used to automatically label pulsar candidates to facilitate rapid analysis. Classification systems in particular are being widely adopted,\nwhich treat the candidate data sets as binary classification problems. Here the legitimate pulsar examples are a minority positive class, and spurious examples the majority negative class.\n\nThe data set shared here contains 16,259 spurious examples caused by RFI\/noise, and 1,639 real pulsar examples. These examples have all been checked by human annotators.\n\nEach row lists the variables first, and the class label is the final entry. The class labels used are 0 (negative) and 1 (positive).\n\nAttribute Information:\nEach candidate is described by 8 continuous variables, and a single class variable. The first four are simple statistics obtained from the integrated pulse profile (folded profile). This is an array of continuous variables that describe a longitude-resolved version of the signal that has been averaged in both time and frequency . The remaining four variables are similarly obtained from the DM-SNR curve . These are summarised below:\n\nMean of the integrated profile.\nStandard deviation of the integrated profile.\nExcess kurtosis of the integrated profile.\nSkewness of the integrated profile.\nMean of the DM-SNR curve.\nStandard deviation of the DM-SNR curve.\nExcess kurtosis of the DM-SNR curve.\nSkewness of the DM-SNR curve.\nClass\nHTRU 2 Summary\n17,898 total examples.\n1,639 positive examples.\n16,259 negative examples.\n\nSource: https:\/\/archive.ics.uci.edu\/ml\/datasets\/HTRU2\n\nDr Robert Lyon\nUniversity of Manchester\nSchool of Physics and Astronomy\nAlan Turing Building\nManchester M13 9PL\nUnited Kingdom\nrobert.lyon '@' manchester.ac.uk","c6cdb5ed":"Lets see how performant will be our model with less features. We will notice that the difference is not big. Actually, as we are not dealing with a huge big dataset and lightGBM is a fast model, we should not concern about reducing the data as we did (even if just only 2 columns reduction...)","cf0788c4":"> Getting the 3 strongest correlations with Pearsonr: (we can notice that from the previous correlation matrix, the first 2 are almost the equals)"}}