{"cell_type":{"2d931cbb":"code","f4ca84e6":"code","6c4ca812":"code","ad6fc9a7":"code","51898c52":"code","ad56d666":"code","beef8c05":"code","f82e8b7e":"code","6c4a5bd6":"code","bb17de04":"code","0e5cee2a":"code","a8c7300d":"code","b10fa305":"markdown","b13bafc4":"markdown","c7776851":"markdown","5e3a3fd6":"markdown","751e9b37":"markdown","379acce9":"markdown","8fe07899":"markdown"},"source":{"2d931cbb":"from fastai.vision.all import *","f4ca84e6":"import cv2\n\ndef DarkChannel(im,sz):\n    b,g,r = cv2.split(im)\n    dc = cv2.min(cv2.min(r,g),b);\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(sz,sz))\n    dark = cv2.erode(dc,kernel)\n    return dark\n\ndef AtmLight(im,dark):\n    [h,w] = im.shape[:2]\n    imsz = h*w\n    numpx = int(max(math.floor(imsz\/1000),1))\n    darkvec = dark.reshape(imsz,1);\n    imvec = im.reshape(imsz,3);\n\n    indices = darkvec.argsort();\n    indices = indices[imsz-numpx::]\n\n    atmsum = np.zeros([1,3])\n    for ind in range(1,numpx):\n       atmsum = atmsum + imvec[indices[ind]]\n\n    A = atmsum \/ numpx;\n    return A\n\ndef TransmissionEstimate(im,A,sz):\n    omega = 0.95;\n    im3 = np.empty(im.shape,im.dtype);\n\n    for ind in range(0,3):\n        im3[:,:,ind] = im[:,:,ind]\/A[0,ind]\n\n    transmission = 1 - omega*DarkChannel(im3,sz);\n    return transmission\n\ndef Guidedfilter(im,p,r,eps):\n    mean_I = cv2.boxFilter(im,cv2.CV_64F,(r,r));\n    mean_p = cv2.boxFilter(p, cv2.CV_64F,(r,r));\n    mean_Ip = cv2.boxFilter(im*p,cv2.CV_64F,(r,r));\n    cov_Ip = mean_Ip - mean_I*mean_p;\n\n    mean_II = cv2.boxFilter(im*im,cv2.CV_64F,(r,r));\n    var_I   = mean_II - mean_I*mean_I;\n\n    a = cov_Ip\/(var_I + eps);\n    b = mean_p - a*mean_I;\n\n    mean_a = cv2.boxFilter(a,cv2.CV_64F,(r,r));\n    mean_b = cv2.boxFilter(b,cv2.CV_64F,(r,r));\n\n    q = mean_a*im + mean_b;\n    return q;\n\ndef TransmissionRefine(im,et):\n    gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY);\n    gray = np.float64(gray)\/255;\n    r = 60;\n    eps = 0.0001;\n    t = Guidedfilter(gray,et,r,eps);\n\n    return t;\n\ndef Recover(im,t,A,tx = 0.1):\n    res = np.empty(im.shape,im.dtype);\n    t = cv2.max(t,tx);\n\n    for ind in range(0,3):\n        res[:,:,ind] = (im[:,:,ind]-A[0,ind])\/t + A[0,ind]\n\n    return res\n\n# CUSTOM\ndef cv2_to_plt(image):\n    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\ndef dehaze(image_path:Path, output_path:Path):\n    src = cv2.imread(str(image_path))\n\n    I = src.astype('float64')\/255\n    dark = DarkChannel(I,15)\n    A = AtmLight(I,dark)\n    te = TransmissionEstimate(I,A,15)\n    t = TransmissionRefine(src,te)\n    J = Recover(I,t,A,0.1)\n    \n    cv2.imwrite(str(output_path\/image_path.name), J*255);","6c4ca812":"fn = '..\/input\/planets-dataset\/planet\/planet\/train-jpg\/train_10002.jpg'\n\nsrc = cv2.imread(fn)\n\nI = src.astype('float64')\/255\n\ndark = DarkChannel(I,15)\nA = AtmLight(I,dark)\nte = TransmissionEstimate(I,A,15)\nt = TransmissionRefine(src,te)\nJ = Recover(I,t,A,0.1);","ad6fc9a7":"plt.imshow(dark);","51898c52":"plt.imshow(t);","ad56d666":"plt.imshow(cv2_to_plt(src));","beef8c05":"plt.imshow(cv2_to_plt(J.astype('float32')));","f82e8b7e":"# Input\ntrain_img_path = Path('..\/input\/planets-dataset\/planet\/planet\/train-jpg')\nimg_files = get_image_files(train_img_path)\n\n# Output\ntrain_img_output_path = Path(\".\/train-jpg\")\ntrain_img_output_path.mkdir(exist_ok=True)","6c4a5bd6":"for img_file in progress_bar(img_files):\n    dehaze(img_file, train_img_output_path)","bb17de04":"# Input\ntest_img_path = Path('..\/input\/planets-dataset\/planet\/planet\/test-jpg')\nimg_files = get_image_files(test_img_path)\n\n# Output\ntest_img_output_path = Path(\".\/test-jpg\")\ntest_img_output_path.mkdir(exist_ok=True)","0e5cee2a":"for img_file in progress_bar(img_files):\n    dehaze(img_file, test_img_output_path)","a8c7300d":"# Input\ntest_img_path = Path('..\/input\/planets-dataset\/test-jpg-additional\/test-jpg-additional')\nimg_files = get_image_files(test_img_path)\n\n# Output\ntest_img_output_path = Path(\".\/test-jpg\")\ntest_img_output_path.mkdir(exist_ok=True)","b10fa305":"# Planet: Understanding the Amazon from Space","b13bafc4":"## Test images","c7776851":"## Training images","5e3a3fd6":"## Additional Test Images","751e9b37":"## Single image","379acce9":"The paper [Review on Haze Removal Methods](http:\/\/www.ijsrp.org\/research-paper-0716\/ijsrp-p5522.pdf) explores different techniques for removing haze from an image.\n\nThe techniques are split into two categories; multi-image and single image. Since multi-image techniques require multiple images of the same scene, which we don't have, we need to focus on the singel image haze removal techniques.\n\nFrom reading the paper, [Improved single image dehazing using dark channel prior](https:\/\/www.researchgate.net\/profile\/Gupta_Ashutosh\/publication\/276223001_Single_Image_Dehazing_Using_Improved_Dark_Channel_Prior\/links\/5552f22a08ae6943a86d8d20\/Single-Image-Dehazing-Using-Improved-Dark-Channel-Prior.pdf) looks the most promising.\n\nThis technique should be the same as *Dark channel prior*, except when calculating atmospheric light, the window size is increased to 31.\n\nAn implementation of the *Dark channel prior* technique is found in [this Github repo](https:\/\/github.com\/He-Zhang\/image_dehaze).\n\nBelow is a modified version of that code.","8fe07899":"*Removing haze from images with Single Image Dehazing Using Improved Dark Channel Prior.*"}}