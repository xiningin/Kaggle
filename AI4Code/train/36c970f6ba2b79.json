{"cell_type":{"060429ab":"code","59acfe4e":"code","e6ff592c":"code","318abaec":"code","548dac7d":"code","989fea31":"code","4c75f16f":"code","4f565a63":"code","65bd8150":"code","c29ce45d":"code","f254f3c7":"code","8ad224e7":"code","23c867d6":"code","b04b643a":"code","6d5166a7":"code","3b87b372":"code","12fe772e":"code","8b789ede":"code","71dc9876":"code","e320be98":"code","8ab9228b":"code","8e1b6f7c":"code","f12c0a72":"code","c08135d2":"markdown","4807e8f4":"markdown","7b09e0da":"markdown","1a5bd0cd":"markdown","cbddf080":"markdown","7d116d7e":"markdown","718edd54":"markdown","327d0c0b":"markdown","87150e4d":"markdown","b257ec70":"markdown"},"source":{"060429ab":"import torch\nprint(\"PyTorch version: \", torch.__version__)\nprint(\"GPU: \", torch.cuda.is_available())\nprint(\"Type: \", torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else \"CPU\")","59acfe4e":"import ast\nimport glob\nimport os\nimport yaml\n\nimport numpy as np\nimport pandas as pd\n\n\nfrom IPython.display import Image, display\nfrom IPython.core.magic import register_line_cell_magic\nfrom shutil import copyfile\nfrom tqdm import tqdm\ntqdm.pandas()\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","e6ff592c":"HOME_DIR = '\/kaggle\/working'\nDATASET_PATH = '\/kaggle\/input\/tensorflow-great-barrier-reef'","318abaec":"# I just used spllited dataset by @julian3833 - Reef - A CV strategy: subsequences! \n# https:\/\/www.kaggle.com\/julian3833\/reef-a-cv-strategy-subsequences \n\ndf = pd.read_csv(\"..\/input\/reef-cv-strategy-subsequences-dataframes\/train-validation-split\/train-0.1.csv\")\ndf.head(3)","548dac7d":"def add_path(row):\n    return f'{DATASET_PATH}\/train_images\/video_{row.video_id}\/{row.video_frame}.jpg'\n\ndef num_boxes(annotations):\n    annotations = ast.literal_eval(annotations)\n    return len(annotations)\n\ndf['path'] = df.apply(lambda row: add_path(row), axis=1)\ndf['num_bbox'] = df['annotations'].apply(lambda x: num_boxes(x))\nprint(\"New path and annotations preprocessing completed\")\n\ndf.head(3)","989fea31":"df = df[df.num_bbox > 0]\n\nprint(f'Dataset images with annotations: {len(df)}')\ndf.head(3)","4c75f16f":"def add_new_path(row):\n    if row.is_train:\n        return f\"{HOME_DIR}\/yolo_dataset\/images\/train\/{row.image_id}.jpg\"\n    else:\n        return f\"{HOME_DIR}\/yolo_dataset\/images\/valid\/{row.image_id}.jpg\"\n    \ndf['new_path'] = df.apply(lambda row: add_new_path(row), axis=1)\nprint(\"New image path for train\/valid created\")\ndf.head(3)","4f565a63":"print(df['path'][16])\nprint(df['new_path'][16])\nprint(df['image_path'][16])","65bd8150":"os.makedirs(f\"{HOME_DIR}\/yolo_dataset\/images\/train\")\nos.makedirs(f\"{HOME_DIR}\/yolo_dataset\/images\/valid\")\nos.makedirs(f\"{HOME_DIR}\/yolo_dataset\/labels\/train\")\nos.makedirs(f\"{HOME_DIR}\/yolo_dataset\/labels\/valid\")\nprint(f\"Directory structure yor Yolov5 created\")","c29ce45d":"def copy_file(row):\n    copyfile(row.path, row.new_path)\n    \n_ = df.progress_apply(lambda row: copy_file(row), axis=1)\n\nprint(\"Sucessfully copy file for train and valid\")","f254f3c7":"IMG_WIDTH, IMG_HEIGHT = 1280, 720\n\ndef get_yolo_format_bbox(bbox, img_w, img_h):\n    w = bbox['width']\n    h = bbox['height']\n    \n    if (bbox['x'] + bbox['width'] > img_w):\n        w = img_w - bbox['x']\n    if (bbox['y'] + bbox['height'] > img_h):\n        h = img_h - bbox['y']\n    \n    xc = bbox['x'] + int(np.round(w\/2))\n    yc = bbox['y'] + int(np.round(h\/2))\n    \n    # normalize\n    return [xc\/img_w, yc\/img_h, w\/img_w, h\/img_h]\n\nfor index, row in tqdm(df.iterrows()):\n    annotations = ast.literal_eval(row.annotations)\n    bboxes = []\n    for annot in annotations:\n        bbox = get_yolo_format_bbox(annot, IMG_WIDTH, IMG_HEIGHT)\n        bboxes.append(bbox)\n        \n    if row.is_train:\n        file_name = f\"{HOME_DIR}\/yolo_dataset\/labels\/train\/{row.image_id}.txt\"\n        os.makedirs(os.path.dirname(file_name), exist_ok=True)\n    else:\n        file_name = f\"{HOME_DIR}\/yolo_dataset\/labels\/valid\/{row.image_id}.txt\"\n        os.makedirs(os.path.dirname(file_name), exist_ok=True)\n        \n    with open(file_name, 'w') as f:\n        for i, bbox in enumerate(bboxes):\n            label = 0\n            bbox = [label] + bbox\n            bbox = [str(i) for i in bbox]\n            bbox = \" \".join(bbox)\n            f.write(bbox)\n            f.write(\"\\n\")\n\nprint(\"Annotations in Yolov5 format for all images created.\")","8ad224e7":"train_data = os.listdir('\/kaggle\/working\/yolo_dataset\/labels\/train')\nnum_train_file = len(train_data)\nprint(\"Number of txt file in train folder: \", num_train_file)\n\nvalid_data = os.listdir('\/kaggle\/working\/yolo_dataset\/labels\/valid')\nnum_valid_file = len(valid_data)\nprint(\"Number of txt file in valid foler: \", num_valid_file)","23c867d6":"%cat '\/kaggle\/working\/yolo_dataset\/labels\/train\/{train_data[10]}'","b04b643a":"# Download YOLOv5\n# !git clone https:\/\/github.com\/ultralytics\/yolov5\n# !cp -r ..\/input\/yolov5 .\/\n!cp -r \/kaggle\/input\/yolov5 \/kaggle\/working\/\n!ls","6d5166a7":"!pip install torchvision --upgrade -q\n!pip install wandb --upgrade","3b87b372":"%cd yolov5\n\n# Install dependencies\n!pip install -qr requirements.txt","12fe772e":"data_yaml = dict(\n    train = f\"{HOME_DIR}\/yolo_dataset\/images\/train\",\n    val = f\"{HOME_DIR}\/yolo_dataset\/images\/valid\",\n    nc = 1, # number of class\n    names = ['cots'] # classes\n)\n\nwith open(f'{HOME_DIR}\/yolov5\/data\/data.yaml', 'w') as outfile:\n    yaml.dump(data_yaml, outfile, default_flow_style=False)\n\nprint(\"Dataset configuration file for YOLOv5 is created\")\n\n%cat \/kaggle\/working\/yolov5\/data\/data.yaml\n","8b789ede":"!ls '\/kaggle\/working\/yolov5\/data'","71dc9876":"# change directory\n%cd ..","e320be98":"# more about Secrets -> https:\/\/www.kaggle.com\/product-feedback\/114053\nimport wandb\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\nwandb_api = user_secrets.get_secret(\"wandb_api\") \nwandb.login(key=wandb_api)\nwandb.login(anonymous='must')","8ab9228b":"%cd yolov5","8e1b6f7c":"BATCH_SIZE = 4\nEPOCHS = 20\nIMG_SIZE=1280\n# Selected_Fold=4  #0..4","f12c0a72":"#best_weights = '\/kaggle\/input\/nfl-weights\/yolov5\/kaggle-reef\/exp\/weights\/best.pt' --weights {best_weights} \\\n!python train.py --img {IMG_SIZE} \\\n                 --batch {BATCH_SIZE} \\\n                 --epochs {EPOCHS} \\\n                 --data data.yaml \\\n                 --weights yolov5l6.pt \\\n                 --project kaggle-Reef \\\n                 --device 0 \\\n#                  --evolve","c08135d2":"### CHECK PYTORCH VERSION","4807e8f4":"### 3. CREATE YOLOv5 ANNOTATIONS","7b09e0da":"### 4. CREATE YOLOv5 DATASET CONFIGURATION FILE","1a5bd0cd":"All training results are saved to runs\/train\/ with incrementing run directories, i.e. runs\/train\/exp2, runs\/train\/exp3 etc.","cbddf080":"4C. Train YOLOv5 with W&B","7d116d7e":"4B. CREATE YOLOv5 DATASET CONFIGURATION FILE","718edd54":"### 4. INSTALL YOLOv5\n\n4A. CLONE YOLOv5 GIT REPOSITORY","327d0c0b":"### 2. CREATE DATASET FILE STRUCTURE","87150e4d":"### 1. PREPARE DATASET","b257ec70":"### IMPORT LIBRARY"}}