{"cell_type":{"93c0a890":"code","06f5a455":"code","2bb0ea67":"code","e5cb1869":"code","095f0029":"code","7ac39053":"code","0e3fc994":"code","27eafc45":"code","1dcb9531":"code","f8c5c328":"code","b437d861":"code","0848ab1d":"code","580122fb":"code","626510a4":"code","a3b78697":"code","f4850356":"code","c2599ce5":"code","b4488531":"code","cc288d4f":"code","9da40a6c":"code","6f3a8253":"code","08a81694":"code","f85e0770":"code","920a909f":"code","26d5e6af":"code","73a746c7":"code","c2dc68bb":"code","f8871260":"code","8d25770c":"code","43e5325b":"code","67344858":"code","9332b256":"code","9dbbdda7":"code","cdf570ae":"code","50edf3c5":"code","ad5e63ee":"code","7457e110":"code","a594e31f":"code","d0545f06":"code","3dd6f933":"code","3d1278b5":"code","932091b0":"code","05314fcb":"code","8ac721b5":"code","e3d65763":"code","38a26017":"code","e41422b4":"code","8dc0238d":"code","9aecd512":"code","fba4f382":"code","c8dec494":"code","6421b1a1":"code","988084c9":"code","dfeb0e6b":"code","6d4d6bd0":"code","dae2a4c4":"code","8739a512":"code","c9b5d784":"code","51c899bd":"code","be3eecac":"code","5ff40b98":"code","9b7edede":"code","ab6eb381":"code","fbefed8d":"code","bac943a7":"code","b1efaa97":"code","6c2311e6":"code","a305a55b":"code","f1ef4a4a":"code","29b9bdac":"code","a5e6c2f8":"code","4cacc772":"code","1d36f9a5":"code","f3f97db1":"code","8df5c490":"code","e9dec217":"code","6c2cfaeb":"code","412fdac6":"code","e753b600":"code","c96b8b11":"code","82e71007":"code","b5197486":"code","1859b2f4":"code","ea98573d":"code","ba5854cd":"code","32867f23":"code","ad2e7942":"code","0f87ebe3":"code","c2647d99":"code","c66bed6c":"code","c05ac011":"code","622ccffa":"code","ed5c6b61":"code","67e7fa38":"code","3156cef2":"code","ddacdc8e":"code","549acdf2":"code","85601f6b":"code","3e067d54":"code","77496ed5":"code","8b4e5030":"code","bbf0963f":"code","0a7f77e4":"code","2d4e7155":"code","f85c4518":"code","b223dbe1":"code","958474e0":"code","cf563523":"code","a5ce3733":"code","b2267fdb":"code","1376573b":"code","7bee3d00":"code","183af8f2":"code","f665a835":"code","99ed049f":"code","37c647d7":"code","fdef5a21":"code","fe7e6afc":"code","ab671211":"code","688fc520":"code","62d87786":"code","a5f9dc1a":"code","fc99f40f":"code","aa46950d":"code","01dd6d6c":"code","f6f32a68":"code","c90a0094":"code","b2057907":"code","8b08b742":"code","e5ce217f":"code","2ce115b1":"code","09e14776":"code","d14e7e78":"code","362ac0ad":"code","b62085f9":"code","b88439cc":"code","9edf4efd":"code","d8e0d5e0":"markdown","f518d58f":"markdown","79a4c5f2":"markdown"},"source":{"93c0a890":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","06f5a455":"import pandas as pd       \nimport matplotlib as mat\nfrom matplotlib import rcParams\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn import metrics\n\n\nimport scipy\nfrom scipy.integrate import simpson\n\n\n\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\n\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, QuantileTransformer\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, auc\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB, ComplementNB\n\npd.set_option('max_column', None)\nplt.style.use(\"ggplot\")\nsns.set_style('darkgrid')\n\n\n\nimport shap\n\nimport warnings\n#warnings.filterwarnings('ignore')\npd.set_option('max_column', None)\nsns.set(font_scale=1)\n","2bb0ea67":"# Change the plot style and the background of the grid\nplt.style.use(\"seaborn\")\nsns.set_style('darkgrid')\n%matplotlib inline","e5cb1869":"df= pd.read_csv('\/kaggle\/input\/default-of-credit-card-clients-dataset\/UCI_Credit_Card.csv')\n","095f0029":"df","7ac39053":"df.drop(['ID'],axis=1, inplace=True)","0e3fc994":"df","27eafc45":"df.rename(columns={'PAY_0' : 'PAY_1', 'default.payment.next.month' : 'Default'}, inplace=True)\ndf","1dcb9531":"df.info()","f8c5c328":"df.isnull().sum()","b437d861":"df.describe().T","0848ab1d":"df.head()","580122fb":"sns.set(font_scale=1)\ntotal_cnt = df['Default'].count()\nrcParams['figure.figsize'] = 10,6\nsns.set(font_scale= 2)\nsns.set_style(\"white\")\nax = sns.countplot(x=\"Default\" , data=df, palette = 'Blues_r')\nax.set_title('Defaulted Count')\nplt.legend(loc = 'upper right')\nfor p in ax.patches:\n    x, height , width = p.get_x() , p.get_height() , p.get_width()\n    ax.text(x + width \/ 2, height + 10, f'{height} \/ {height \/ total_cnt * 100:2.1f}%', va='center', ha='center', size=20)\n\nsns.despine()","626510a4":"sns.set(font_scale=1)\ntotal_cnt = df['Default'].count()\nsns.set(font_scale = 2)\nsns.set_style(\"white\")\nsns.set_palette(\"bright\")\nplt.figure(figsize=(12,8))\ndf['Default'].value_counts().plot.pie(autopct = '%1.1f%%', \n                                               shadow = True,\n                                               colors = ['grey', 'green'])\nplt.legend(labels=['No Default', 'Default'])\nplt.show()","a3b78697":"# Sex : feature \ndf['SEX'].value_counts()","f4850356":"df['Default'].groupby(df['SEX']).value_counts(normalize=True)","c2599ce5":"plt.figure(figsize=(12,4))","b4488531":"sns.set(font_scale=1)\nplt.figure(figsize=(12,8))\nax = sns.countplot(x='SEX' ,hue=\"Default\", data=df,  palette = 'Blues_r')\nplt.xlabel('Sex')\nplt.ylabel('Number of clients')\nplt.ylim(0,20000)\nplt.xticks([0,1], ['Male', 'Female'])\nfor p in ax.patches:\n    ax.annotate((p.get_height()), (p.get_x()+0.16, p.get_height()+1000))\n    #print(p.get_height())\n    print(p.get_x()+0.16, p.get_height()+1000)\nplt.show()","cc288d4f":"sns.set(font_scale=1)\nplt.figure(figsize=(10,4))\nax = sns.barplot(x=\"SEX\", y=\"Default\", data=df,palette = 'Blues_r' ,ci=None)\nplt.ylabel(\"% of Default\", fontsize=12)\nplt.ylim(0,0.5)\nplt.xticks([0,1],['Male', 'Female'], fontsize = 12)\n\nfor p in ax.patches:\n    ax.annotate(\"%.2f\" %(p.get_height()), (p.get_x()+0.35, p.get_height()+0.03),fontsize=13)\n\nplt.show()","9da40a6c":"# feature EDUCATION\ndf['EDUCATION'].unique()","6f3a8253":"# the value 0 in 'EDUCATION' don't match the possible values for this feature according to the original dataset\ndf[df['EDUCATION'] == 0].EDUCATION.count()","08a81694":"df['EDUCATION'].value_counts()","f85e0770":"df['Default'].groupby(df['EDUCATION']).value_counts()","920a909f":"df.loc[:,'EDUCATION'] = df.loc[:,'EDUCATION'].replace(0,5)\ndf.loc[:,'EDUCATION'] = df.loc[:,'EDUCATION'].replace(6,5)\ndf.loc[:,'EDUCATION'] = df.loc[:,'EDUCATION'].replace(5,4)","26d5e6af":"df['EDUCATION'].value_counts()","73a746c7":"df['Default'].groupby(df['EDUCATION']).value_counts(normalize = True)","c2dc68bb":"sns.set(font_scale=1)\nplt.figure(figsize=(12,4))\nax = sns.countplot(data=df , x='EDUCATION', hue=\"Default\",palette = 'flare' )\nplt.xlabel(\"Education\", fontsize= 12)\nplt.ylabel(\"# of Clients\", fontsize= 12)\nplt.ylim(0,12000)\nplt.xticks([0,1,2,3],['Grad school', 'University', 'High School','Others'])\nfor p in ax.patches:\n    ax.annotate((p.get_height()), (p.get_x()+0.11, p.get_height()+500))\n\nplt.show()","f8871260":"sns.set(font_scale=1)\nplt.figure(figsize=(12,4))\nax = sns.barplot(data=df , x='EDUCATION', y=\"Default\",palette = 'flare' , ci=None)\nplt.ylabel(\"% of Default\", fontsize= 12)\nplt.ylim(0,0.5)\nplt.xticks([0,1,2,3],['Grad school', 'University', 'High School','Others'],fontsize=11)\nfor p in ax.patches:\n    ax.annotate(\"%.2f\" %(p.get_height()), (p.get_x()+0.30, p.get_height()+0.03), fontsize=14)\n\nplt.show()","8d25770c":"# Considering only the first three levels, it seems like a higher education translates to a lower chance of default\n# However both other and unknown have a lower probability","43e5325b":"# feature : MARRIAGE\ndf['MARRIAGE'].value_counts()","67344858":"df['Default'].groupby(df['MARRIAGE']).value_counts(normalize=True)","9332b256":"plt.figure(figsize=(12,4))\nsns.set(font_scale=1)\nax = sns.barplot(x = \"MARRIAGE\", y = \"Default\", data = df, palette = 'rocket', ci = None)\n\nplt.ylabel(\"% of Default\", fontsize= 12)\nplt.ylim(0,0.5)\nplt.xticks([0,1,2,3],['Unknown', 'Married', 'Single', 'Divorce'], fontsize = 11)\n\nfor p in ax.patches:\n    ax.annotate(\"%.2f\" %(p.get_height()), (p.get_x()+0.30, p.get_height()+0.03),fontsize=13)\n\nplt.show()","9dbbdda7":"# Most people fall on 'married' or 'single' category\n# Unknown category present a lower probability of default","cdf570ae":"# Comparing male\/female \n# considering a similar education level and status('married' or 'single')","50edf3c5":"df.groupby(by=['MARRIAGE', 'SEX'])['Default'].value_counts(normalize=True)","ad5e63ee":"plt.figure(figsize=(12,8))\nsns.set(font_scale=1)\nax = sns.barplot(x = \"SEX\", y = \"Default\", hue = \"MARRIAGE\", data = df, palette = 'rocket', ci = None)\n\nplt.ylabel(\"% of Default\", fontsize= 12)\nplt.ylim(0,0.5)\nplt.xticks([0,1],['Male', 'Female'], fontsize = 12)\n\nfor p in ax.patches:\n    ax.annotate(\"%.2f\" %(p.get_height()), (p.get_x()+0.06, p.get_height()+0.03),fontsize=12)\n\nplt.show()","7457e110":"df.groupby(by=['EDUCATION','SEX'])['Default'].value_counts(normalize=True)","a594e31f":"plt.figure(figsize=(12,8))\nsns.set(font_scale=1)\nax = sns.barplot(x = \"SEX\", y = \"Default\", hue = \"EDUCATION\", data = df, palette = 'rocket', ci = None)\n\nplt.ylabel(\"% of Default\", fontsize= 12)\nplt.ylim(0,0.5)\nplt.xticks([0,1],['Male', 'Female'], fontsize = 12)\n\nfor p in ax.patches:\n    ax.annotate(\"%.2f\" %(p.get_height()), (p.get_x()+0.035, p.get_height()+0.03),fontsize=12)\n\nplt.show()","d0545f06":"# in every single comparison, the probability was higher for men","3dd6f933":"# feature : Age\n\ndf.AGE.unique().sum()","3d1278b5":"sns.set(font_scale=1)\nplt.figure(figsize=(12,6))\nsns.distplot(df['AGE'])\nplt.ticklabel_format(style='plain', axis='x')\nplt.ylabel('')\nplt.show()","932091b0":"df.loc[(df['Default'] == 0),'LIMIT_BAL']","05314fcb":"df.head()","8ac721b5":"sns.set(font_scale=1)\nplt.figure(figsize=(12,4))\nsns.kdeplot(df.loc[(df['Default'] == 0), 'AGE'], label='No Default', shade=True) # kernel density estiamtion \nsns.kdeplot(df.loc[(df['Default'] == 1), 'AGE'] ,label='Default', shade=True)\nplt.ticklabel_format(style='plain', axis='x') \nplt.ylabel('')\nplt.legend()\nplt.show()","e3d65763":"# Between the age 25 and 40 the chance of default is a little lower \n# we could divide our dataset in bins and check the percentage of default in each age group ","38a26017":"df.head()","e41422b4":"df['AgeBin'] = pd.cut(df['AGE'], [20,25,30,35,40,50,60,80])   # bin values into discrete intervals\nprint(df['AgeBin'].value_counts())","8dc0238d":"df['Default'].groupby(df['AgeBin']).value_counts(normalize = True)","9aecd512":"plt.figure(figsize=(12,4))\nsns.set(font_scale=1)\ndf['AgeBin'] = df['AgeBin'].astype('str')\nAgeBin_order = ['(20, 25]', '(25, 30]', '(30, 35]', '(35, 40]', '(40, 50]', '(50, 60]', '(60, 80]']\n\nax = sns.countplot(data = df, x = 'AgeBin', hue=\"Default\", palette = 'rocket', order = AgeBin_order)\n\nplt.xlabel(\"Age Group\", fontsize= 12)\nplt.ylabel(\"# of Clients\", fontsize= 12)\nplt.ylim(0,8000)\n\nfor p in ax.patches:\n    ax.annotate((p.get_height()), (p.get_x()+0.075, p.get_height()+300))\n\nplt.show()","fba4f382":"plt.figure(figsize=(12,4))\nsns.set(font_scale=1)\nax = sns.barplot(x = 'AgeBin', y=\"Default\", data=df , palette = 'rocket', ci = None, order = AgeBin_order)\n\nplt.xlabel(\"Age Group\", fontsize= 12)\nplt.ylabel(\"% of Default\", fontsize= 12)\nplt.ylim(0,0.5)\n\nfor p in ax.patches:\n    ax.annotate(\"%.2f\" %(p.get_height()), (p.get_x()+0.25, p.get_height()+0.03),fontsize=13)\n\nplt.show()","c8dec494":"# the lowest chance of default are regestered around [30-35] , while the highest occur at ([20-25] and 60+)","6421b1a1":"# feature : LIMIT_BAL : amount of given credit\nplt.figure(figsize=(12,4))\nsns.set(font_scale=1)\nsns.distplot(df['LIMIT_BAL'])\nplt.ticklabel_format(style='plain', axis='x') #repressing scientific notation on x\nplt.ylabel('')\nplt.show()","988084c9":"plt.figure(figsize=(12,4)) \nsns.set(font_scale=1)\n# kernel density estimation\nsns.kdeplot(df.loc[(df['Default'] == 0), 'LIMIT_BAL'], label = 'No default', shade=True)\nsns.kdeplot(df.loc[(df['Default'] == 1), 'LIMIT_BAL'], label = 'Default', shade = True)\nplt.ticklabel_format(style='plain', axis='x') \nplt.ylabel('')\nplt.legend()\nplt.show()","dfeb0e6b":"# observation : most customers have 200k or less of credit limit. \n# A higher concentration of customers in default on that range","6d4d6bd0":"# LIMIT_BAL: Amount of given credit in NT dollars \ndf['LimitBin'] = pd.cut(df['LIMIT_BAL'],[5000, 50000, 100000, 150000, 200000, 300000, 400000, 500000, 1100000])\nprint(df['LimitBin'].value_counts())","dae2a4c4":"df['Default'].groupby(df['LimitBin']).value_counts(normalize=True)","8739a512":"plt.figure(figsize=(14,4))\nsns.set(font_scale=1)\ndf['LimitBin'] = df['LimitBin'].astype('str') # astype() : cast a pandas object to a specified dtype\n\nLimitBin_order = ['(5000, 50000]', '(50000, 100000]', '(100000, 150000]', '(150000, 200000]',\n                '(200000, 300000]', '(300000, 400000]', '(400000, 500000]', '(500000, 1100000]']\n\nax = sns.countplot(data=df, x='LimitBin' , hue=\"Default\", palette = 'rocket', order = LimitBin_order)\n\nplt.xlabel(\"Amount of Given Credit\", fontsize= 12)\nplt.ylabel(\"# of Clients\", fontsize= 12)\nplt.ylim(0,8000)\nax.tick_params(axis=\"x\", labelsize= 9.5)\n\nfor p in ax.patches:\n    ax.annotate((p.get_height()), (p.get_x()+0.075, p.get_height()+300))\n    \nplt.show()","c9b5d784":"plt.figure(figsize=(14,4))\nsns.set(font_scale=1)\nax = sns.barplot(x = \"LimitBin\", y = \"Default\", data = df, palette = 'rocket', ci = None, order = LimitBin_order)\n\n \nplt.xlabel(\"Amount of Given Credit\", fontsize= 12)\nplt.ylabel(\"% of Default\", fontsize= 12)\nplt.ylim(0,0.5)\n\nfor p in ax.patches:\n    ax.annotate(\"%.2f\" %(p.get_height()), (p.get_x()+0.25, p.get_height()+0.03),fontsize=13)\n\nplt.show()","51c899bd":"# observation : there is a significant rate of default (over 30%) from customers with 50k or less of credit limit\n# => the higher the limit, the lower is the chance of defaulting","be3eecac":"# Amount of Given Credit (LIMIT_BAL) + Demographic Features (SEX, EDUCATION , MARRIAGE)","5ff40b98":"df.groupby('SEX')['LIMIT_BAL'].mean()","9b7edede":"plt.figure(figsize=(12,6))\nsns.set(font_scale=1)\nsns.boxplot(x=\"SEX\", y=\"LIMIT_BAL\",data=df, palette = 'rocket', showmeans=True, \n           meanprops={\"markerfacecolor\":\"red\", \"markeredgecolor\":\"black\",\"markersize\":\"10\"})\n\nplt.ticklabel_format(style='plain', axis='y')\nplt.xticks([0,1],['Male','female'], fontsize = 12)\n\nplt.show()\n\n# seaborn boxplot : (categorical destribution plots) median, bottom quartile(25th percentile) , top quartile(25th percentile) (interquartile range IQR) and whiskers(1.5*IQR)\n# showmeans=True : mean triangle","ab6eb381":"df.groupby('EDUCATION')['LIMIT_BAL'].mean()","fbefed8d":"plt.figure(figsize=(14,6))\nsns.set(font_scale=1)\nsns.boxplot(x = \"EDUCATION\", y = \"LIMIT_BAL\", data = df, palette = 'rocket', showmeans=True, \n            meanprops={\"markerfacecolor\":\"red\",  \"markeredgecolor\":\"black\", \"markersize\":\"10\"})\n\nplt.ticklabel_format(style='plain', axis='y') #repressing scientific notation   \nplt.xticks([0,1,2,3,4],['Grad School','University','High School','Others','Unknown'], fontsize = 11)\n\nplt.show()","bac943a7":"df.groupby('MARRIAGE')['LIMIT_BAL'].mean()","b1efaa97":"plt.figure(figsize=(14,6))\nsns.set(font_scale=1)\nsns.boxplot(x = \"MARRIAGE\", y = \"LIMIT_BAL\", data = df, palette = 'rocket', showmeans=True, \n            meanprops={\"markerfacecolor\":\"red\",  \"markeredgecolor\":\"black\", \"markersize\":\"10\"})\n\nplt.ticklabel_format(style='plain', axis='y') #repressing scientific notation    \nplt.xticks([0,1,2,3],['Unknown', 'Married', 'Single', 'Divorce'], fontsize = 11)\n\nplt.show()","6c2311e6":"df.groupby('AgeBin')['LIMIT_BAL'].mean()","a305a55b":"plt.figure(figsize=(14,6))\nsns.set(font_scale=1)\nsns.boxplot(x = \"AgeBin\", y = \"LIMIT_BAL\",data = df, palette = 'rocket', order = AgeBin_order, showmeans=True, \n            meanprops={\"markerfacecolor\":\"red\",  \"markeredgecolor\":\"black\", \"markersize\":\"10\"})\n\nplt.ticklabel_format(style='plain', axis='y') #repressing scientific notation    \nplt.xlabel(\"Age Group\", fontsize= 12)\n\nplt.show()","f1ef4a4a":"# observation :","29b9bdac":"# we could analyze the relationship the credit limit and the combination of two demographic features","a5e6c2f8":"sns.set(font_scale=1)\nplt.figure(figsize=(14,6))\nsns.boxplot(x=\"EDUCATION\" , y=\"LIMIT_BAL\", hue='SEX',data=df, palette = 'rocket', showmeans=True, \n            meanprops={\"markerfacecolor\":\"red\",  \"markeredgecolor\":\"black\", \"markersize\":\"10\"})\nplt.ticklabel_format(style='plain', axis='y') #repressing scientific notation   \nplt.xticks([0,1,2,3,4],['Grad School','University','High School','Others','Unknown'], fontsize = 11)\n\nplt.show()","4cacc772":"plt.figure(figsize=(14,6))\nsns.set(font_scale=1)\nsns.boxplot(x = \"MARRIAGE\", y = \"LIMIT_BAL\", hue = 'SEX', data = df, palette = 'rocket', showmeans=True, \n            meanprops={\"markerfacecolor\":\"red\",  \"markeredgecolor\":\"black\", \"markersize\":\"10\"})\n\nplt.ticklabel_format(style='plain', axis='y') #repressing scientific notation    \nplt.xticks([0,1,2,3],['Unknown', 'Married', 'Single', 'Divorce'], fontsize = 11)\n\nplt.show()","1d36f9a5":"sns.set(font_scale=1)\nplt.figure(figsize=(14,6))\n\nsns.boxplot(x = \"AgeBin\", y = \"LIMIT_BAL\", hue = 'SEX', data = df, palette = 'rocket', order = AgeBin_order, showmeans=True, \n            meanprops={\"markerfacecolor\":\"red\",  \"markeredgecolor\":\"black\", \"markersize\":\"10\"})\n\nplt.ticklabel_format(style='plain', axis='y') #repressing scientific notation    \nplt.xlabel(\"Age Group\", fontsize= 12)\n\nplt.show()","f3f97db1":"# we saw earlier that the average given credit for women was slightly higher than for men. that still holds up for several combinations \n# of categories, except among customers that(have a grad school diploma \/ are married \/ are 50+ years old)","8df5c490":"# feature : repayment status (PAY_X) ","e9dec217":"df.head()","6c2cfaeb":"pay_cols = ['PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\nfor pay_col in pay_cols:\n    print(df[pay_col].unique())","412fdac6":"pay_x_fts = ['PAY_1', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\nplt.figure(figsize=(15,12))\nsns.set(font_scale=1)\nfor i,col in enumerate(pay_x_fts):\n    plt.subplot(3,2,i+1)\n    ax = sns.countplot(df.loc[:,col], palette = 'rocket')\n    plt.ylim(0,20000)\n    plt.ylabel('')\n    plt.tight_layout()\n    \n    for p in ax.patches:\n        ax.annotate((p.get_height()) , (p.get_x() + 0.08 , p.get_height()+500), fontsize = 11)\nplt.show()","e753b600":"plt.figure(figsize=(15,12))\nsns.set(font_scale=1)\nfor i,col in enumerate(pay_x_fts):\n    plt.subplot(3,2,i + 1)\n    ax = sns.barplot(x=col, y=\"Default\", data=df, palette = 'rocket', ci = None)\n    plt.ylabel(\"% of Default\", fontsize= 12)\n    plt.ylim(0,1.2)\n    plt.tight_layout()\n    \n    for p in ax.patches:\n        ax.annotate(\"%.2f\" %(p.get_height()), (p.get_x()+0.09, p.get_height()+0.03),fontsize=13)\n\nplt.show()","c96b8b11":"# observation : Most customers are duly paying their credit card bills. And it's pretty clear that their likelihood of default are much lower than the rest.","82e71007":"# we'll be following the same approach used to analyze 'Age' and 'Limit_Bal' , showing destribution and density , than dividing data inbins to get a clear\n# percentage of default for each group","b5197486":"# feature : Amount of Bill Statement (BILL_AMTX)\nsns.set(font_scale=1)\n\nbill_amtx_fts = ['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']\nplt.figure(figsize=(15,12))\n\nfor i,col in enumerate(bill_amtx_fts):\n    plt.subplot(3,2,i+1)\n    sns.distplot(df.loc[:,col])\n    plt.ticklabel_format(style='plain', axis='x') #repressing scientific notation    \n    plt.ylabel('')\n    plt.tight_layout()\n\nplt.show()","1859b2f4":"df.head()","ea98573d":"plt.figure(figsize=(15,12))\nsns.set(font_scale=1)\nfor i,col in enumerate(bill_amtx_fts):\n    plt.subplot(3,2,i+1)\n    sns.kdeplot(df.loc[(df['Default'] == 0), col], label = 'No Default', shade=True)\n    sns.kdeplot(df.loc[(df['Default'] == 1), col], label = 'Default', shade = True)\n    plt.xlim(-50000,200000)\n    plt.ylabel('')\n    plt.legend()\n    plt.tight_layout()\nplt.show()","ba5854cd":"df['BILL_AMT1_bin'] = df['BILL_AMT1'].copy()\ndf['BILL_AMT2_bin'] = df['BILL_AMT2'].copy()\ndf['BILL_AMT3_bin'] = df['BILL_AMT3'].copy()\ndf['BILL_AMT4_bin'] = df['BILL_AMT4'].copy()\ndf['BILL_AMT5_bin'] = df['BILL_AMT5'].copy()\ndf['BILL_AMT6_bin'] = df['BILL_AMT6'].copy()","32867f23":"bill_amtx_bins = ['BILL_AMT1_bin', 'BILL_AMT2_bin', 'BILL_AMT3_bin', 'BILL_AMT4_bin', 'BILL_AMT5_bin', 'BILL_AMT6_bin']\n\nfor i,col in enumerate(bill_amtx_bins):\n    df[col] = pd.cut(df[bill_amtx_bins[i]],[-350000,-1,0,25000, 75000, 200000, 2000000] )\n    print(df[col].value_counts())","ad2e7942":"for col in bill_amtx_bins:\n    print(df.Default.groupby(df[col]).value_counts(normalize=True))","0f87ebe3":"plt.figure(figsize=(15,12))\nsns.set(font_scale=1) \nfor i,col in enumerate(bill_amtx_bins):    \n    plt.subplot(3,2,i + 1)\n    ax = sns.countplot(data = df, x = col, hue=\"Default\", palette = 'rocket')\n    plt.ylim(0,13000)\n    plt.ylabel('')\n    plt.xticks([0,1,2,3,4,5],['0 <', '= 0', '0-25k', '25k-75k', '75k-200k', '>200k'], fontsize = 11)\n    plt.tight_layout()\n\n    for p in ax.patches:\n        ax.annotate((p.get_height()), (p.get_x()+0.04, p.get_height()+700), fontsize = 11)    \n        \nplt.show()","c2647d99":"# observation : those who have a negative bill statement have a lower chance of default than the rest.\n# ","c66bed6c":"# Amount of Previous Payment (PAY_AMTX) \npay_amtx_fts = ['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\nplt.figure(figsize=(15,12))\nsns.set(font_scale=1) \n\n\nfor i,col in enumerate(pay_amtx_fts):\n    plt.subplot(3,2,i+1)\n    sns.distplot(df.loc[:,col])\n    plt.ticklabel_format(style='plain', axis='x') \n    plt.ylabel('')\n    plt.tight_layout()\n\nplt.show()","c05ac011":"plt.figure(figsize=(15,12))\nsns.set(font_scale=1) \n\n\nfor i,col in enumerate(pay_amtx_fts):\n    plt.subplot(3,2,i + 1)   \n    sns.kdeplot(df.loc[(df.Default == 0), col ],label  = 'No Default', shade=True )\n    sns.kdeplot(df.loc[(df.Default == 1), col ], label  = 'Default', shade = True )\n    plt.xlim(0,100000)\n    plt.ylabel('')\n    plt.legend()\n    plt.tight_layout()\n\nplt.show()","622ccffa":"df.head()","ed5c6b61":"# limit_bal ","67e7fa38":"def get_info(var, bins=10, rwidth=0.5):\n    plt.figure(figsize=(15,12))\n    sns.set(font_scale=1)\n    df[[var]].plot(kind='box')\n    print(df[var].describe())","3156cef2":"get_info('LIMIT_BAL')","ddacdc8e":"# We see alot of outliers from the boxplot. Most values should be clustered at a lower end of the spectrum, ","549acdf2":"df","85601f6b":"data = df.copy()","3e067d54":"data.columns","77496ed5":"\ndata = data.drop(bill_amtx_bins, axis = 1)\n\ndata = data.drop(['AgeBin', 'LimitBin'], axis = 1)\ndata","8b4e5030":"data.head()","bbf0963f":"plt.subplots(figsize=(30,20))\nsns.heatmap(data.corr(), annot=True)\nplt.show()","0a7f77e4":"#raise SystemExit(\"Stop right there!\")","2d4e7155":"data = df.copy()","f85c4518":"dataframe = data.drop(bill_amtx_bins, axis = 1)\ndataframe = dataframe.drop(['AgeBin', 'LimitBin'], axis = 1)\ndataframe","b223dbe1":"# drop duplicated rows\ndataframe = dataframe.drop_duplicates(subset=[col for col in dataframe.columns if col != 'Default'])\ndataframe.shape","958474e0":"bill_amt = ['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']\npay_amt  = ['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']","cf563523":"bill_statement_sum = dataframe[bill_amt].sum(axis=1)\nprint(f\"Number of observation with zero total bill amount {sum(bill_statement_sum == 0)}\")","a5ce3733":"bill_statement_sum_index = bill_statement_sum.loc[bill_statement_sum > 0].index\ndataframe = dataframe.loc[bill_statement_sum_index]\ndataframe.shape","b2267fdb":"features_col = [col for col in dataframe.columns if col not in ['Default']]\n\nfeatures = dataframe[features_col]\ntarget = dataframe['Default']","1376573b":"SEED=2020\nX, X_test, y, y_test = train_test_split(features,\n                                        target,\n                                        test_size=.2,\n                                        shuffle=True,\n                                        random_state=SEED,\n                                        stratify=target\n                                        )","7bee3d00":"X_test.shape","183af8f2":"# proportion des modalit\u00e9s de 'default' entre train set et test set\nunique_train, count_train = np.unique(y, return_counts=True)\nprint(f\"y train value counts: \\n {np.asanyarray((unique_train, count_train\/y.shape[0])).T}\")\nprint('\\n')\nunique_test, count_test = np.unique(y_test, return_counts=True)\nprint(f\"y test value counts: \\n {np.asanyarray((unique_test, count_test\/y_test.shape[0])).T}\")","f665a835":"# https:\/\/github.com\/tensorbored\/kds\/blob\/master\/kds\/metrics.py\ndef decile_table(y_true, y_prob, labels=True, round_decimal=3):\n    \"\"\"Generates the Decile Table from labels and probabilities\n    \n    The Decile Table is creared by first sorting the customers by their predicted \n    probabilities, in decreasing order from highest (closest to one) to \n    lowest (closest to zero). Splitting the customers into equally sized segments, \n    we create groups containing the same numbers of customers, for example, 10 decile \n    groups each containing 10% of the customer base.\n    \n    Args:\n        y_true (array-like, shape (n_samples)):\n            Ground truth (correct\/actual) target values.\n        y_prob (array-like, shape (n_samples, n_classes)):\n            Prediction probabilities for each class returned by a classifier\/algorithm.\n        labels (bool, optional): If True, prints a legend for the abbreviations of\n            decile table column names. Defaults to True.\n        round_decimal (int, optional): The decimal precision till which the result is \n            needed. Defaults to '3'.\n    Returns:\n        dt: The dataframe dt (decile-table) with the deciles and related information.\n    Example:\n        >>> import kds\n        >>> from sklearn.datasets import load_iris\n        >>> from sklearn.model_selection import train_test_split\n        >>> from sklearn import tree\n        >>> X, y = load_iris(return_X_y=True)\n        >>> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,random_state=3)\n        >>> clf = tree.DecisionTreeClassifier(max_depth=1,random_state=3)\n        >>> clf = clf.fit(X_train, y_train)\n        >>> y_prob = clf.predict_proba(X_test)\n        >>> kds.metrics.decile_table(y_test, y_prob[:,1])\n    \"\"\"\n    y_true = np.array(y_true)\n    y_prob = np.array(y_prob)\n\n    df = pd.DataFrame()\n    df['y_true'] = y_true\n    df['y_prob'] = y_prob\n    # df['decile']=pd.qcut(df['y_prob'], 10, labels=list(np.arange(10,0,-1))) \n    # ValueError: Bin edges must be unique\n\n    df.sort_values('y_prob', ascending=False, inplace=True)\n    df['decile'] = np.linspace(1, 11, len(df), False, dtype=int)\n\n    # dt abbreviation for decile_table\n    dt = df.groupby('decile').apply(lambda x: pd.Series([\n        np.min(x['y_prob']),\n        np.max(x['y_prob']),\n        np.mean(x['y_prob']),\n        np.size(x['y_prob']),\n        np.sum(x['y_true']),\n        np.size(x['y_true'][x['y_true'] == 0]),\n    ],\n        index=([\"prob_min\", \"prob_max\", \"prob_avg\",\n                \"cnt_cust\", \"cnt_resp\", \"cnt_non_resp\"])\n    )).reset_index()\n\n    dt['prob_min']=dt['prob_min'].round(round_decimal)\n    dt['prob_max']=dt['prob_max'].round(round_decimal)\n    dt['prob_avg']=round(dt['prob_avg'],round_decimal)\n    # dt=dt.sort_values(by='decile',ascending=False).reset_index(drop=True)\n\n    tmp = df[['y_true']].sort_values('y_true', ascending=False)\n    tmp['decile'] = np.linspace(1, 11, len(tmp), False, dtype=int)\n\n    dt['cnt_resp_rndm'] = np.sum(df['y_true']) \/ 10\n    dt['cnt_resp_wiz'] = tmp.groupby('decile', as_index=False)['y_true'].sum()['y_true']\n\n    dt['resp_rate'] = round(dt['cnt_resp'] * 100 \/ dt['cnt_cust'], round_decimal)\n    dt['cum_cust'] = np.cumsum(dt['cnt_cust'])\n    dt['cum_resp'] = np.cumsum(dt['cnt_resp'])\n    dt['cum_resp_wiz'] = np.cumsum(dt['cnt_resp_wiz'])\n    dt['cum_non_resp'] = np.cumsum(dt['cnt_non_resp'])\n    dt['cum_cust_pct'] = round(dt['cum_cust'] * 100 \/ np.sum(dt['cnt_cust']), round_decimal)\n    dt['cum_resp_pct'] = round(dt['cum_resp'] * 100 \/ np.sum(dt['cnt_resp']), round_decimal)\n    dt['cum_resp_pct_wiz'] = round(dt['cum_resp_wiz'] * 100 \/ np.sum(dt['cnt_resp_wiz']), round_decimal)\n    dt['cum_non_resp_pct'] = round(\n        dt['cum_non_resp'] * 100 \/ np.sum(dt['cnt_non_resp']), round_decimal)\n    dt['KS'] = round(dt['cum_resp_pct'] - dt['cum_non_resp_pct'], round_decimal)\n    dt['lift'] = round(dt['cum_resp_pct'] \/ dt['cum_cust_pct'], round_decimal)\n\n    if labels is True:\n        print_labels()\n\n    return dt[['decile', 'cum_resp_pct', 'cum_resp_pct_wiz']]\n\ndef area_ratio(pcg):\n    # Area of the model \n    area_model = auc(np.append(0, pcg.decile.values), np.append(0, pcg.cum_resp_pct.values))\n    # Area of the base model\n    area_base = auc(np.append(np.arange(0, 100, 10), 100), np.append(np.arange(0, 10, 1), 10))\n    # Area between model and base\n    diff_base_model = area_model - area_base\n    # Area of the wizard\n    area_wizard = auc(np.append(0, pcg.decile.values), np.append(0, pcg.cum_resp_pct_wiz.values))\n    # Area between wizard and base\n    diff_wizard_base = area_wizard - area_base\n    # area ratio\n    area_ratio = diff_base_model \/ diff_wizard_base\n    return area_ratio\n\ndef plot_lift_chart(pcg, area_ratio, title='Cumulative Gain Plot',\n                         title_fontsize=14, text_fontsize=10, figsize=None):\n    \"\"\"Generates the cumulative Gain Plot from labels and probabilities\n    The cumulative gains chart is used to determine the effectiveness of a\n    binary classifier. A detailed explanation can be found at\n    http:\/\/www2.cs.uregina.ca\/~dbd\/cs831\/notes\/lift_chart\/lift_chart.html \n    The implementation here works only for binary classification.\n    \n    Args:\n        y_true (array-like, shape (n_samples)):\n            Ground truth (correct) target values.\n        y_prob (array-like, shape (n_samples, n_classes)):\n            Prediction probabilities for each class returned by a classifier.\n        title (string, optional): Title of the generated plot. Defaults to\n            \"Decile-wise Lift Plot\".\n        title_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values (8, 10, 12, etc.)\n            Defaults to 14.\n        text_fontsize (string or int, optional): Matplotlib-style fontsizes.\n            Use e.g. \"small\", \"medium\", \"large\" or integer-values (8, 10, 12, etc.)\n            Defaults to 10.\n        figsize (2-tuple, optional): Tuple denoting figure size of the plot\n            e.g. (6, 6). Defaults to ``None``.\n    Returns:\n        None\n    Example:\n        >>> import kds\n        >>> from sklearn.datasets import load_iris\n        >>> from sklearn.model_selection import train_test_split\n        >>> from sklearn import tree\n        >>> X, y = load_iris(return_X_y=True)\n        >>> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,random_state=3)\n        >>> clf = tree.DecisionTreeClassifier(max_depth=1,random_state=3)\n        >>> clf = clf.fit(X_train, y_train)\n        >>> y_prob = clf.predict_proba(X_test)\n        >>> kds.metrics.plot_cumulative_gain(y_test, y_prob[:,1])\n    \"\"\"\n\n    # Cumulative Gains Plot\n    # plt.subplot(2, 2, 3)\n    plt.plot(np.append(0, pcg.decile.values), np.append(0, pcg.cum_resp_pct.values), marker='o', label='Model')\n    plt.plot(np.append(0, pcg.decile.values), np.append(0, pcg.cum_resp_pct_wiz.values), 'c--', label='Wizard')\n    # plt.plot(list(np.arange(1,11)), np.ones(10), 'k--',marker='o')\n    plt.plot([0, 10], [0, 100], 'k--', marker='o', label='Random')\n    plt.text(4, 30, f\"Area ratio: {area_ratio}\")\n    plt.title(title, fontsize=title_fontsize)\n    plt.xlabel('Deciles', fontsize=text_fontsize)\n    plt.ylabel('% Resonders', fontsize=text_fontsize)\n    plt.legend(borderpad=1)\n    plt.grid(True)\n    # plt.show()","99ed049f":"scaler = MinMaxScaler() # StandardScaler MinMaxScaler\nscaler.fit(X)\nscaled_x = scaler.transform(X)\nscaled_test = scaler.transform(X_test)\nX.loc[:, features_col] = scaled_x\nX_test.loc[:, features_col] = scaled_test","37c647d7":"# Classifier implementing the k-nearest neighbors vote.\nknn = KNeighborsClassifier(n_neighbors=10, #number of neighbors to use\n                           algorithm='kd_tree', # algo used to compute the nearest neighbors\n                           n_jobs=-1, # number of parallel jobs to run for neighbors search : -1 means using all processors.\n                           weights='uniform' # Weight function used in prediction : uniform means that all the points in each neighborhood are weighted equally.\n                          )\nknn.fit(X, y) # fit knn classifier \ntrain_pred = knn.predict(X) # returns labels of the train data\ntrain_proba = knn.predict_proba(X) # returns probability estimates for the train data \ntrain_pcg = decile_table(y, train_proba[:, 1], labels=False) # calling the decile_table function with 'y' : labels for train \n#                                                                                                and 'train_proba[:, 1]' : column  that contains the probability estimated for default==1\ntest_pred = knn.predict(X_test)# returns labels of the test data\ntest_proba = knn.predict_proba(X_test) # returns probability estimates for the test data \ntest_pcg = decile_table(y_test, test_proba[:, 1], labels=False) # calling the decile_table function with y_test and probability estimates of default==1\nerror_rate_train = 1 - accuracy_score(y, train_pred)\narea_ratio_train = area_ratio(train_pcg) # calling area_ratio function \nerror_rate_test = 1 - accuracy_score(y_test, test_pred)\narea_ratio_test = area_ratio(test_pcg)\nprint(f\"KNN error rate on train set (training): {error_rate_train} | area ratio on train set (training): {area_ratio_train}\\n\")\nprint(f\"KNN error rate on test (valid) set: {error_rate_test} | area ratio on test (valid) set: {area_ratio_test} \\n\")\nplot_lift_chart(test_pcg, area_ratio_test, title='Lift Chart KNN on test set')","fdef5a21":"%%time\n\nNSPLITS = 5 # number of folds\nSHUFFLE =True\n\noof_label = np.zeros((X.shape[0]))\noof_proba = np.zeros((X.shape[0], 2))\ntest_proba = np.zeros((X_test.shape[0], 2))\n\nerror_rate_valids = []  \narea_ratio_valids = []\n\n\nskf = StratifiedKFold(n_splits=NSPLITS, shuffle=SHUFFLE, random_state=SEED)\n# Stratified K-Folds provides train and test indices to split the data in train and test folds.\n# the folds are made by preserving the percentage of samples for each class.\n\n\n\nknn = KNeighborsClassifier(n_neighbors=10, algorithm='kd_tree', n_jobs=-1)\n\ncounter = 1\n\nfor trn_idx, vld_idx in skf.split(X, y):\n    \n    print(f\"CV {counter}\")\n    \n    # split the train data into NSPLITS=5 folds\n    # x_valid and y_valid are considered as a holdout or test data set.\n    # y_train and y_valid are considered as a training data set.\n    x_train, x_valid  = X.iloc[trn_idx].values, X.iloc[vld_idx].values \n    y_train, y_valid  = y.iloc[trn_idx].values, y.iloc[vld_idx].values \n    \n    print(f\"Shape pf valid data: {x_valid.shape}\")\n    knn.fit(x_train, y_train)\n    \n    oof_pred_label = knn.predict(x_valid) # predicted labels on the out_of_fold data : the data were not used during the training of the model.\n    oof_pred_proba = knn.predict_proba(x_valid) # predicted labels on the out_of_fold data\n    oof_label[vld_idx] = oof_pred_label\n    oof_proba[vld_idx] = oof_pred_proba\n    \n    y_pred_test = knn.predict_proba(X_test) # probability estimates for the test set \n    valid_pcg = decile_table(y_valid, oof_pred_proba[:, 1], labels=False)\n    score_valid = 1 - accuracy_score(y_valid, oof_pred_label) # compute the error score for the holdout or test data set.\n    area_ratio_valid = area_ratio(valid_pcg) # compute area_ratio score for the holdout or test data set.\n    print(f\"error rate fold {counter} score: {score_valid} | area ratio score: {area_ratio_valid}\")\n    \n    error_rate_valids.append(score_valid) # appending the error scores of the holdouts to a list. \n    area_ratio_valids.append(area_ratio_valid) # appending the area_ratio scores of the holdouts to a list. \n    test_proba += y_pred_test \/ NSPLITS\n    counter += 1\n    print(\"\\n\")\n\ny_pred_label = test_proba.argmax(1) #Returns the indices of the maximum values along an axis.\ntest_pcg = decile_table(y_test, test_proba[:,1], labels=False)\ntest_area_ratio = area_ratio(test_pcg)\nprint(f\"Error rate CV score: {np.mean(np.array(error_rate_valids))} | Area ratio score: {np.mean(np.array(area_ratio_valids))}\\n\")\nprint(f\"Error rate test (validation) score: {1 - accuracy_score(y_test, y_pred_label)} | Area ratio score: {test_area_ratio}\")\nplot_lift_chart(test_pcg, test_area_ratio, title='Lift Chart KNN on test set')\nprint(\"\\n\")","fe7e6afc":"import xgboost as xgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.utils import class_weight\nfrom sklearn import metrics","ab671211":"# extreme gradient boosting trees :\n# boosting : Ensemble learning technique that works by combining several weak learners into a model with strng accuracy\n# in gradient boosting each predictor tries to improve on its predecessor by reducing the errors.\n# at each iteration it fits a new predictor to the residual errors made by the previous predictor.Models are added sequentially until no further improvements can be made.","688fc520":"from functools import partial\nimport optuna","62d87786":"# defining an objective function to be optimized :\ndef objective(trial):\n\n\n    param_grid = {\n        \"objective\": \"binary:logistic\", # the loss function : logistic regression for binary classification\n        \"eval_metric\":'error', # specify eval metric for xgboost\n        'tree_method':'gpu_hist', \n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7]), # colsample_bytree is the subsample ratio of columns when constructing each tree\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7]), # Subsample ratio of the training instances\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.009,0.01, 0.02]), \n        'max_depth': trial.suggest_categorical('max_depth', [5,6,7,9,11]), # max depth of the decision trees \n        'min_child_weight': trial.suggest_categorical('min_child_weight', [10, 30, 60, 100, 200])}\n\n    skf = StratifiedKFold(n_splits=NSPLITS, shuffle=SHUFFLE, random_state=SEED)\n\n    xgb_score = []\n    counter = 1\n    for trn_idx, vld_idx in skf.split(X, y):\n\n        # train valid separation\n        print(f\"CV {counter}\/{NSPLITS}\")\n        print('\\n')\n        \n        # DMatrix a data structure used by XGBoost, which is optimized both for memory efficiency and training speed.  \n        # We can construct a DMatrix from different data sources (numpy ,...)\n        d_train = xgb.DMatrix(X.iloc[trn_idx].values, y.iloc[trn_idx].values)\n        d_val = xgb.DMatrix(X.iloc[vld_idx].values, y.iloc[vld_idx].values)\n        \n        # Fit and train xgboost\n        model = xgb.train(param_grid,\n                          d_train, # train set\n                          evals=[(d_val, \"val\")], # evaluation set\n                          num_boost_round=10000,\n                          verbose_eval=50,\n                          early_stopping_rounds=100\n                         )\n    \n        # Predictions and score on validation data\n        pred_val = model.predict(d_val)\n        predictions = [round(value) for value in pred_val] \n        score = 1 - accuracy_score(y.iloc[vld_idx], predictions)\n        print(f\"Fold {counter} Xgboost {score}\")\n        xgb_score.append(score)\n        counter += 1\n  \n    return np.mean(np.array(xgb_score))","a5f9dc1a":"# Create a study object and invoke the optimize method over 100 trials :\n#study = optuna.create_study(direction='minimize') \n#study.optimize(objective, n_trials=100)\n#print('Number of finished trials:', len(study.trials))\n#print('Best trial:', study.best_trial.params)","fc99f40f":"# optuna hyperparameter tuning output :\nBest_trial= {'colsample_bytree': 0.7, 'subsample': 0.4, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 100, \"objective\": \"binary:logistic\",\n        \"eval_metric\":'error' , 'tree_method':'gpu_hist'}","aa46950d":"# fiting XGBoost with **Best_trial and cross-validation :\n%%time\n\nNSPLITS = 5\nSHUFFLE =True\n\noof_label = np.zeros((X.shape[0])) \noof_proba = np.zeros((X.shape[0], 2))\ntest_proba = np.zeros((X_test.shape[0], 2))\n\nerror_rate_valids = []\narea_ratio_valids = []\n\n\nskf = StratifiedKFold(n_splits=NSPLITS, shuffle=SHUFFLE, random_state=SEED)\n\n\ncounter = 1\n\nfor trn_idx, vld_idx in skf.split(X, y):\n    \n    # split the train data into NSPLITS=5 folds\n    # x_valid and y_valid are considered as a holdout or test data set.\n    # y_train and y_valid are considered as a training data set.\n    print(f\"CV {counter}\")\n    x_train, x_valid  = X.iloc[trn_idx].values, X.iloc[vld_idx].values\n    y_train, y_valid  = y.iloc[trn_idx].values, y.iloc[vld_idx].values\n    \n    \n    print(f\"Shape pf valid data: {x_valid.shape}\")\n    # Fit and train xgboost\n    model = xgb.XGBClassifier(**Best_trial)\n    model.fit(x_train, y_train, \n                eval_set=[(x_valid,y_valid)], # evaluation on the validation set\n                verbose=100, early_stopping_rounds=200)\n    \n    oof_pred_label = model.predict(x_valid)  # predicted labels on the out_of_fold data : the data were not used during the training of the model.\n    oof_pred_proba = model.predict_proba(x_valid)# predicted labels on the out_of_fold data\n    oof_label[vld_idx] = oof_pred_label\n    oof_proba[vld_idx] = oof_pred_proba\n    \n    y_pred_test = model.predict_proba(X_test)# probability estimates for the test set \n    valid_pcg = decile_table(y_valid , oof_pred_proba[:, 1], labels=False)\n    score_valid = 1 - accuracy_score(y_valid , oof_pred_label)# compute the error score for the holdout or test data set.\n    area_ratio_valid = area_ratio(valid_pcg) # compute area_ratio score for the holdout or test data set.\n    print(f\"error rate fold {counter} score: {score_valid} | area ratio score: {area_ratio_valid}\")\n    \n    error_rate_valids.append(score_valid)# appending the error scores of the holdouts to a list. \n    area_ratio_valids.append(area_ratio_valid) # appending the area_ratio scores of the holdouts to a list. \n    test_proba += y_pred_test \/ NSPLITS\n    counter += 1\n    print(\"\\n\")\n\ny_pred_label = test_proba.argmax(1)#Returns the indices of the maximum values along an axis.\ntest_pcg = decile_table(y_test, test_proba[:, 1], labels=False)\ntest_area_ratio = area_ratio(test_pcg)\nprint(f\"Error rate CV score: {np.mean(np.array(error_rate_valids))} | Area ratio score: {np.mean(np.array(area_ratio_valids))}\\n\")\nprint(f\"Error rate test (validation) score: {1 - accuracy_score(y_test, y_pred_label)} | Area ratio score: {test_area_ratio}\")\nplot_lift_chart(test_pcg, test_area_ratio, title='Lift Chart XGBClassifier on test set')\nprint(\"\\n\")","01dd6d6c":"# DecisionTreeClassifier ","f6f32a68":"%%time\n\nNSPLITS = 5\nSHUFFLE =True\n\noof_label = np.zeros((X.shape[0]))\noof_proba = np.zeros((X.shape[0], 2))\ntest_proba = np.zeros((X_test.shape[0], 2))\n\nerror_rate_valids = []\narea_ratio_valids = []\n\n\nskf = StratifiedKFold(n_splits=NSPLITS, shuffle=SHUFFLE, random_state=SEED)\n\n\ncounter = 1\n\nfor trn_idx, vld_idx in skf.split(X, y):\n    \n    print(f\"CV {counter}\")\n    x_train, x_valid  = X.iloc[trn_idx].values, X.iloc[vld_idx].values\n    y_train, y_valid  = y.iloc[trn_idx].values, y.iloc[vld_idx].values\n    \n    \n    print(f\"Shape pf valid data: {x_valid.shape}\")\n    # Fit and train DecisionTreeClassifier\n    model = DecisionTreeClassifier(max_depth=7, # The maximum depth of the tree to prevent overfitting\n                                   criterion='gini', # gini impurity\n                                   random_state=SEED\n                                   )\n\n    model.fit(x_train, y_train)\n    \n    oof_pred_label = model.predict(x_valid) #the predicted label for the test folds\n    \n    oof_pred_proba = model.predict_proba(x_valid) \n    \n    oof_label[vld_idx] = oof_pred_label\n    oof_proba[vld_idx] = oof_pred_proba\n    \n    y_pred_test = model.predict_proba(X_test)\n    \n    valid_pcg = decile_table(y_valid , oof_pred_proba[:, 1], labels=False)\n    \n    score_valid = 1 - accuracy_score(y_valid , oof_pred_label) # score de chaque fold\n    \n    area_ratio_valid = area_ratio(valid_pcg)\n    \n    print(f\"error rate fold {counter} score: {score_valid} | area ratio score: {area_ratio_valid}\")\n    \n    error_rate_valids.append(score_valid) # append error rate folds\n    area_ratio_valids.append(area_ratio_valid)\n    test_proba += y_pred_test \/ NSPLITS # predictproba for all the folds ***\n    counter += 1\n    print(\"\\n\")\n\ny_pred_label = test_proba.argmax(1)\n\ntest_pcg = decile_table(y_test, test_proba[:, 1], labels=False)\n\ntest_area_ratio = area_ratio(test_pcg)\nprint(f\"Error rate CV score: {np.mean(np.array(error_rate_valids))} | Area ratio score: {np.mean(np.array(area_ratio_valids))}\\n\")\nprint(f\"Error rate test (validation) score: {1 - accuracy_score(y_test, y_pred_label)} | Area ratio score: {test_area_ratio}\")\nplot_lift_chart(test_pcg, test_area_ratio, title='Lift Chart DecisionTreeClassifier on test set')\nprint(\"\\n\")\n","c90a0094":"from sklearn.linear_model import LogisticRegression","b2057907":"def objective_logistic(trial):\n\n    \n\n    solver = trial.suggest_categorical(\"solver\", [ 'liblinear',  'lbfgs', 'sag', 'saga'])\n    C = trial.suggest_float(\"C\", 0.0, 1.0) # Inverse of regularization strength\n\n   \n    \n\n        # 'penalty' parameter isn't relevant for this solver,\n        # so we always specify 'l2' as the dummy value.\n\n\n    logistic = LogisticRegression(max_iter=200, solver=solver, C=C,random_state=SEED)\n\n    skf = StratifiedKFold(n_splits=NSPLITS, shuffle=SHUFFLE, random_state=SEED)\n\n    logistic_score = []\n    counter = 1\n    for trn_idx, vld_idx in skf.split(X, y):\n\n        # train valid separation\n        print(f\"CV {counter}\/{NSPLITS}\")\n        print('\\n')\n        x_train, x_valid  = X.iloc[trn_idx].values, X.iloc[vld_idx].values\n        y_train, y_valid  = y.iloc[trn_idx].values, y.iloc[vld_idx].values\n        \n        # Fit and train logistic\n        logistic.fit(x_train,y_train)\n    \n        # Predictions and score on validation data\n        pred_val = logistic.predict(x_valid)\n        \n        score = 1 - accuracy_score(y_valid, pred_val)\n        print(f\"Fold {counter} logistic {score}\")\n        logistic_score.append(score)\n        counter += 1\n  \n    return np.mean(np.array(logistic_score))","8b08b742":"# Create a study object and invoke the optimize method over 100 trials :\n#study = optuna.create_study(direction=\"minimize\")\n#study.optimize(objective_logistic, n_trials=100)\n#\n#print(\"Number of finished trials: \", len(study.trials))\n#print(\"Best trial:\")\n#trial = study.best_trial\n#print(\"  Value: \", trial.value)\n#print(\"  Params: \")\n#for key, value in trial.params.items():\n#    print(\"    {}: {}\".format(key, value))","e5ce217f":"Params = {'solver': 'saga' ,'C': 0.9960292949722489} ","2ce115b1":"%%time\n\nNSPLITS = 5\nSHUFFLE =True\n\noof_label = np.zeros((X.shape[0]))\noof_proba = np.zeros((X.shape[0], 2))\ntest_proba = np.zeros((X_test.shape[0], 2))\n\nerror_rate_valids = []\narea_ratio_valids = []\n\n\nskf = StratifiedKFold(n_splits=NSPLITS, shuffle=SHUFFLE, random_state=SEED)\n\n\ncounter = 1\n\nfor trn_idx, vld_idx in skf.split(X, y):\n    \n    \n    print(f\"CV {counter}\")\n    # split the train data into NSPLITS=5 folds\n    # x_valid and y_valid are considered as a holdout or test data set.\n    # y_train and y_valid are considered as a training data set.\n    x_train, x_valid  = X.iloc[trn_idx].values, X.iloc[vld_idx].values\n    y_train, y_valid  = y.iloc[trn_idx].values, y.iloc[vld_idx].values\n    \n    \n    print(f\"Shape pf valid data: {x_valid.shape}\")\n    # Fit and train LogisticRegression\n    model = LogisticRegression(**Params,penalty='l2',max_iter=200)\n\n    model.fit(x_train, y_train)\n    \n    oof_pred_label = model.predict(x_valid)# predicted labels on the out_of_fold data : the data were not used during the training of the model.\n    oof_pred_proba = model.predict_proba(x_valid)# predicted labels on the out_of_fold data\n    oof_label[vld_idx] = oof_pred_label\n    oof_proba[vld_idx] = oof_pred_proba\n    \n    y_pred_test = model.predict_proba(X_test)# probability estimates for the test set \n    valid_pcg = decile_table(y_valid , oof_pred_proba[:, 1], labels=False)\n    score_valid = 1 - accuracy_score(y_valid , oof_pred_label) # compute the error score for the holdout or test data set.\n    \n    area_ratio_valid = area_ratio(valid_pcg) # compute area_ratio score for the holdout or test data set.\n    print(f\"error rate fold {counter} score: {score_valid} | area ratio score: {area_ratio_valid}\")\n    error_rate_valids.append(score_valid)\n    area_ratio_valids.append(area_ratio_valid)\n    test_proba += y_pred_test \/ NSPLITS\n    counter += 1\n    print(\"\\n\")\n\ny_pred_label = test_proba.argmax(1) #Returns the indices of the maximum values along an axis.\ntest_pcg = decile_table(y_test, test_proba[:, 1], labels=False)\ntest_area_ratio = area_ratio(test_pcg)\nprint(f\"Error rate CV score: {np.mean(np.array(error_rate_valids))} | Area ratio score: {np.mean(np.array(area_ratio_valids))}\\n\")\nprint(f\"Error rate test (validation) score: {1 - accuracy_score(y_test, y_pred_label)} | Area ratio score: {test_area_ratio}\")\nplot_lift_chart(test_pcg, test_area_ratio, title='Lift Chart logistic on test set')\nprint(\"\\n\")","09e14776":"%%time\n\nNSPLITS = 5\nSHUFFLE =True\n\noof_label = np.zeros((X.shape[0]))\noof_proba = np.zeros((X.shape[0], 2))\ntest_proba = np.zeros((X_test.shape[0], 2))\n\nerror_rate_valids = []\narea_ratio_valids = []\n\n\nskf = StratifiedKFold(n_splits=NSPLITS, shuffle=SHUFFLE, random_state=SEED)\n\n\ncounter = 1\n\nfor trn_idx, vld_idx in skf.split(X, y):\n    \n    print(f\"CV {counter}\")\n    x_train, x_valid  = X.iloc[trn_idx].values, X.iloc[vld_idx].values\n    y_train, y_valid  = y.iloc[trn_idx].values, y.iloc[vld_idx].values\n    \n    \n    print(f\"Shape pf valid data: {x_valid.shape}\")\n    # Fit and train RandomForestClassifier\n    model = RandomForestClassifier(max_depth=7, # The maximum depth of the tree\n                                   n_estimators=400, # the number of trees the algorithm builds before taking the maximum voting or the averages of predictions\n                                   criterion='gini', # gini impurity\n                                   verbose=0)\n\n    model.fit(x_train, y_train)\n    \n    oof_pred_label = model.predict(x_valid) #the predicted label for the test folds\n    \n    oof_pred_proba = model.predict_proba(x_valid) \n    \n    oof_label[vld_idx] = oof_pred_label\n    oof_proba[vld_idx] = oof_pred_proba\n    \n    y_pred_test = model.predict_proba(X_test)\n    \n    valid_pcg = decile_table(y_valid , oof_pred_proba[:, 1], labels=False)\n    \n    score_valid = 1 - accuracy_score(y_valid , oof_pred_label) # score de chaque fold\n    \n    area_ratio_valid = area_ratio(valid_pcg)\n    \n    print(f\"error rate fold {counter} score: {score_valid} | area ratio score: {area_ratio_valid}\")\n    \n    error_rate_valids.append(score_valid) # append error rate folds\n    area_ratio_valids.append(area_ratio_valid)\n    test_proba += y_pred_test \/ NSPLITS # predictproba for all the folds ***\n    counter += 1\n    print(\"\\n\")\n\ny_pred_label = test_proba.argmax(1)\n\ntest_pcg = decile_table(y_test, test_proba[:, 1], labels=False)\n\ntest_area_ratio = area_ratio(test_pcg)\nprint(f\"Error rate CV score: {np.mean(np.array(error_rate_valids))} | Area ratio score: {np.mean(np.array(area_ratio_valids))}\\n\")\nprint(f\"Error rate test (validation) score: {1 - accuracy_score(y_test, y_pred_label)} | Area ratio score: {test_area_ratio}\")\nplot_lift_chart(test_pcg, test_area_ratio, title='Lift Chart RandomForestClassifier on test set')\nprint(\"\\n\")\n","d14e7e78":"def objective_random_forest(trial):\n\n    \n\n    params = {\n            'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n            'max_depth': trial.suggest_int('max_depth', 4, 50),\n            'min_samples_split': trial.suggest_int('min_samples_split', 1, 150),\n            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 60)\n        }\n\n    \n    rfc = RandomForestClassifier(**params,n_jobs=2,random_state=SEED)\n\n    skf = StratifiedKFold(n_splits=NSPLITS, shuffle=SHUFFLE, random_state=SEED)\n\n    rfc_score = []\n    counter = 1\n    for trn_idx, vld_idx in skf.split(X, y):\n\n        # train valid separation\n        print(f\"CV {counter}\/{NSPLITS}\")\n        print('\\n')\n        x_train, x_valid  = X.iloc[trn_idx].values, X.iloc[vld_idx].values\n        y_train, y_valid  = y.iloc[trn_idx].values, y.iloc[vld_idx].values\n        \n        # Fit and train RandomForestClassifier\n        rfc.fit(x_train,y_train)\n    \n        # Predictions and score on validation data\n        pred_val = rfc.predict(x_valid)\n        \n        score = 1 - accuracy_score(y_valid, pred_val)\n        print(f\"Fold {counter} RFC {score}\")\n        rfc_score.append(score)\n        counter += 1\n  \n    return np.mean(np.array(rfc_score))","362ac0ad":"#study = optuna.create_study(direction=\"minimize\")\n#study.optimize(objective_random_forest, n_trials=100)\n#\n#print(\"Number of finished trials: \", len(study.trials))\n#print(\"Best trial:\")\n#trial = study.best_trial\n#print(\"  Value: \", trial.value)\n#print(\"  Params: \")\n#for key, value in trial.params.items():\n#    print(\"    {}: {}\".format(key, value))","b62085f9":"Params= {\n    'n_estimators': 972,\n    'max_depth': 45,\n    'min_samples_split': 85,\n    'min_samples_leaf': 18}","b88439cc":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis","9edf4efd":"%%time\n\nNSPLITS = 5\nSHUFFLE =True\n\noof_label = np.zeros((X.shape[0]))\noof_proba = np.zeros((X.shape[0], 2))\ntest_proba = np.zeros((X_test.shape[0], 2))\n\nerror_rate_valids = []\narea_ratio_valids = []\n\n\nskf = StratifiedKFold(n_splits=NSPLITS, shuffle=SHUFFLE, random_state=SEED)\n\n\ncounter = 1\n\nfor trn_idx, vld_idx in skf.split(X, y):\n    \n    print(f\"CV {counter}\")\n    x_train, x_valid  = X.iloc[trn_idx].values, X.iloc[vld_idx].values\n    y_train, y_valid  = y.iloc[trn_idx].values, y.iloc[vld_idx].values\n    \n    \n    print(f\"Shape pf valid data: {x_valid.shape}\")\n    # Fit and train LinearDiscriminantAnalysis\n    model = LinearDiscriminantAnalysis(solver='svd')\n\n    model.fit(x_train, y_train)\n    \n    oof_pred_label = model.predict(x_valid)\n    oof_pred_proba = model.predict_proba(x_valid)\n    oof_label[vld_idx] = oof_pred_label\n    oof_proba[vld_idx] = oof_pred_proba\n    \n    y_pred_test = model.predict_proba(X_test)\n    valid_pcg = decile_table(y_valid , oof_pred_proba[:, 1], labels=False)\n    score_valid = 1 - accuracy_score(y_valid , oof_pred_label)\n    \n    area_ratio_valid = area_ratio(valid_pcg)\n    print(f\"error rate fold {counter} score: {score_valid} | area ratio score: {area_ratio_valid}\")\n    error_rate_valids.append(score_valid)\n    area_ratio_valids.append(area_ratio_valid)\n    test_proba += y_pred_test \/ NSPLITS\n    counter += 1\n    print(\"\\n\")\n\ny_pred_label = test_proba.argmax(1)\ntest_pcg = decile_table(y_test, test_proba[:, 1], labels=False)\ntest_area_ratio = area_ratio(test_pcg)\nprint(f\"Error rate CV score: {np.mean(np.array(error_rate_valids))} | Area ratio score: {np.mean(np.array(area_ratio_valids))}\\n\")\nprint(f\"Error rate test (validation) score: {1 - accuracy_score(y_test, y_pred_label)} | Area ratio score: {test_area_ratio}\")\nplot_lift_chart(test_pcg, test_area_ratio, title='Lift Chart LinearDiscriminantAnalysis on test set')\nprint(\"\\n\")","d8e0d5e0":"## Exploratory Data Analysis","f518d58f":"## Preparation et modelisation","79a4c5f2":"### Hyperparameter tuning using optuna"}}