{"cell_type":{"a9a7c361":"code","076a3c3a":"code","a98fffb6":"code","9bd19205":"code","7d15b419":"code","68becec0":"code","8c69b92e":"code","7d3e49d0":"code","7d47894e":"code","b82e469e":"code","7dd06f87":"code","87c9527b":"code","faba1611":"code","1f9d291f":"code","5e7b8e7c":"code","c19ad86f":"code","6be1b7e6":"code","1690ea32":"code","e6a2ec7b":"code","9758ecaf":"code","3d928512":"code","1d3c0c39":"code","49dee538":"code","f55394bd":"code","d7c82709":"code","bc139bf8":"code","64ab7cde":"code","88135d61":"code","88f9b22b":"code","bac1e521":"code","f4576ab1":"code","49470cee":"code","9ea9ce7f":"code","bd844a7f":"code","b94bd1c8":"code","1589dcbc":"code","c354f66b":"code","6afc8032":"code","08f626e5":"code","9d532cbf":"code","774026ef":"code","bb9d7419":"code","fb7a6570":"code","471afcee":"code","46e8f3bc":"code","456d05c9":"code","7ef207f0":"code","46000162":"code","76b89d96":"code","41a44e9d":"code","8c1a8ff6":"markdown","cb8ea1b0":"markdown","fff412c2":"markdown","ac0ccc78":"markdown","61d9cf61":"markdown","0104a23f":"markdown","d4c5f30e":"markdown","8cdf0e7c":"markdown","9ba06072":"markdown","3e6f55b0":"markdown","337de73c":"markdown","f8405b01":"markdown","cee832a1":"markdown","8202d922":"markdown","643c7646":"markdown","185411e1":"markdown","9bd48580":"markdown","8f45f97e":"markdown","7654e41e":"markdown","9e2667f6":"markdown","3991e769":"markdown","b173d66a":"markdown","7d793892":"markdown","c933d8c0":"markdown","7042b7f9":"markdown","5de9425b":"markdown","06bb3fd6":"markdown","d2d0c8a6":"markdown","f4ecde5e":"markdown","ae1ce7b7":"markdown","cc00033c":"markdown","ab503c0e":"markdown","b29e2f67":"markdown","b0274cd9":"markdown","32c2080b":"markdown","2d33b48c":"markdown","cdf9af52":"markdown","2b053f87":"markdown","37b99fdf":"markdown","7a8c76a3":"markdown","517cffd1":"markdown","f85b9484":"markdown"},"source":{"a9a7c361":"#importing the libraries that we use\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nsns.set(color_codes=True) # adds a nice background to the graphs\n%matplotlib inline","076a3c3a":"cust_df = pd.read_excel('..\/input\/bank-loan-modelling\/Bank_Personal_Loan_Modelling.xlsx','Data')","a98fffb6":"cust_df.head(10).style.background_gradient(cmap=\"RdYlBu\")","9bd19205":"cust_df.columns","7d15b419":"cust_df.info()  #Shape of the DataSet","68becec0":"cust_df[[\"Age\",\"Experience\",\"Income\",\"CCAvg\",\"Mortgage\"]] = cust_df[[\"Age\",\"Experience\",\"Income\",\"CCAvg\",\"Mortgage\"]].astype(float)","8c69b92e":"cust_df.info()","7d3e49d0":"cust_df.describe().T","7d47894e":"cust_cat = cust_df.loc[:,[\"Family\",\"Education\",\"Personal Loan\",\"Securities Account\",\"CD Account\",\"Online\",\"CreditCard\"]]\ncust_num = cust_df.loc[:,[\"ID\",\"Age\",\"Experience\",\"Income\",\"ZIP Code\",\"CCAvg\",\"Mortgage\"]]","b82e469e":"cust_cat.head()","7dd06f87":"cust_num.head()","87c9527b":"cust_num[\"Mortgage\"].value_counts()","faba1611":"cust_df.skew() #skewness of the data","1f9d291f":"Target = cust_df[\"Personal Loan\"]","5e7b8e7c":"#Plots to see the distribution of the Categorical features individually\n\nplt.figure(figsize= (20,15))\nplt.subplot(3,3,1)\nsns.countplot(cust_df[\"Family\"], color='lightblue')\nplt.xlabel('Family')\n\nplt.subplot(3,3,2)\nsns.countplot(cust_df[\"Education\"], color='lightgreen')\nplt.xlabel('Education')\n\nplt.subplot(3,3,3)\nsns.countplot(cust_df[\"Securities Account\"], color='pink')\nplt.xlabel('Securities Account')\n\nplt.subplot(3,3,4)\nsns.countplot(cust_df[\"CD Account\"], color='gray')\nplt.xlabel('CD Account')\n\nplt.subplot(3,3,5)\nsns.countplot(cust_df[\"Online\"], color='cyan')\nplt.xlabel('Online')\n\nplt.subplot(3,3,6)\nsns.countplot(cust_df[\"CreditCard\"], color='Aquamarine')\nplt.xlabel('CreditCard')\n\nplt.show()","c19ad86f":"#Plots to see the distribution of the Continuos features individually\nplt.figure(figsize= (20,15))\nplt.subplot(2,2,1)\nplt.hist(cust_df[\"Age\"], color='lightblue', edgecolor = 'black', alpha = 0.7)\nplt.xlabel('Age')\n\nplt.subplot(2,2,2)\nplt.hist(cust_df[\"Experience\"], color='lightgreen', edgecolor = 'black', alpha = 0.7)\nplt.xlabel('Experience')\n\nplt.subplot(2,2,3)\nplt.hist(cust_df[\"Income\"], color='orange', edgecolor = 'black', alpha = 0.7)\nplt.xlabel('Income')\n\nplt.subplot(2,2,4)\nplt.hist(cust_df[\"Mortgage\"], color='Pink', edgecolor = 'black', alpha = 0.7)\nplt.xlabel('Mortgage')\n\nplt.figure(figsize= (20,15))\nplt.subplot(4,1,1)\nsns.boxplot(x= cust_df[\"Age\"], color='lightblue')\n\nplt.subplot(4,1,2)\nsns.boxplot(x= cust_df[\"Experience\"], color='lightblue')\n\nplt.subplot(4,1,3)\nsns.boxplot(x= cust_df[\"Income\"], color='lightblue')\n\nplt.subplot(4,1,4)\nsns.boxplot(x= cust_df[\"Mortgage\"], color='lightblue')\n\nplt.show()","6be1b7e6":"#Checking the pair plot between each feature\nsns.pairplot(cust_df)  #pairplot\nplt.show()","1690ea32":"#Analysis between Target Variable and Other categorical variables.\nplt.figure(figsize= (20,15))\nplt.subplot(3,3,1)\nsns.countplot(cust_df[\"Education\"],palette=\"Greens\",hue=cust_df[\"Personal Loan\"])\n\nplt.subplot(3,3,2)\nsns.countplot(cust_df[\"Online\"],palette=\"Greens\",hue=cust_df[\"Personal Loan\"])\n\nplt.subplot(3,3,3)\nsns.countplot(cust_df[\"Family\"],palette=\"Greens\",hue=cust_df[\"Personal Loan\"])\n\nplt.subplot(3,3,4)\nsns.countplot(cust_df[\"CreditCard\"],palette=\"Greens\",hue=cust_df[\"Personal Loan\"])\n\nplt.subplot(3,3,5)\nsns.countplot(cust_df[\"Securities Account\"],palette=\"Greens\",hue=cust_df[\"Personal Loan\"])\n\nplt.subplot(3,3,6)\nsns.distplot(cust_df[cust_df[\"Personal Loan\"]==1][\"Mortgage\"],kde=True,hist=False,color='red',label=\"Mortgage customer with PL\")\nsns.distplot(cust_df[cust_df[\"Personal Loan\"]==0][\"Mortgage\"],hist=False,kde=True,color='green',label=\"Mortgage customer without PL\")\nplt.legend()\nplt.show();","e6a2ec7b":"cust_df.corr()","9758ecaf":"#Correlation\nplt.figure(figsize= (15,10))\nsns.heatmap(cust_df.corr())\nplt.show()","3d928512":"#count plot of \nsns.countplot(Target, palette='hls')\nplt.show()","1d3c0c39":"n_true = len(cust_df.loc[cust_df[\"Personal Loan\"] == 1])\nn_false = len(cust_df.loc[cust_df[\"Personal Loan\"] == 0])\nprint(\"Number of customers who bought personal loan: {0} ({1:2.2f}%)\".format(n_true, (n_true \/ (n_true + n_false)) * 100 ))\nprint(\"Number of customers who didn't bought personal loan: {0} ({1:2.2f}%)\".format(n_false, (n_false \/ (n_true + n_false)) * 100))","49dee538":"cust_df.info()","f55394bd":"avg_Exp = cust_df[\"Experience\"].mean()\nprint(f\"Average Experience {avg_Exp}\")\ncust_df[\"Experience\"] = cust_df[\"Experience\"].apply(lambda x : avg_Exp if x<0 else x)","d7c82709":"Q1 = cust_df[\"Income\"].quantile(0.25)\nQ3 = cust_df[\"Income\"].quantile(0.75)\nIQR = Q3 - Q1\nwhisker = Q1 + 1.5 * IQR\ncust_inc = cust_df[\"Income\"].apply(lambda x : whisker if x>whisker else x)","bc139bf8":"Q1 = cust_df[\"Mortgage\"].quantile(0.25)\nQ3 = cust_df[\"Mortgage\"].quantile(0.75)\nIQR = Q3 - Q1\nwhisker = Q1 + 1.5 * IQR\ncust_mor = cust_df[\"Mortgage\"].apply(lambda x : whisker if x>whisker else x)","64ab7cde":"cust_df[\"Income\"]=cust_inc\ncust_df[\"Mortgage\"]=cust_mor","88135d61":"cust_df.head().style.background_gradient(cmap=\"RdYlBu\")","88f9b22b":"cust_df[\"Mortgage\"]= np.log1p(cust_df[\"Mortgage\"])\nsns.distplot(cust_df[\"Mortgage\"])\nplt.show()","bac1e521":"#Standardise the numerical columns\nscalar = StandardScaler()\ncust_df[\"Experience\"]=scalar.fit_transform(cust_df[[\"Experience\"]])\ncust_df[\"Income\"]=scalar.fit_transform(cust_df[[\"Income\"]])\ncust_df[\"CCAvg\"]=scalar.fit_transform(cust_df[[\"CCAvg\"]])\ncust_df[\"Mortgage\"]=scalar.fit_transform(cust_df[[\"Mortgage\"]])","f4576ab1":"X = cust_df.drop(['Personal Loan'],axis=1)     # Predictor feature columns \nY = Target   # Predicted class (1, 0) \n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)\n# 1 is just any random seed number\n\nx_train.head()","49470cee":"print(\"{0:0.2f}% data is in training set\".format((len(x_train)\/len(cust_df.index)) * 100))\nprint(\"{0:0.2f}% data is in test set\".format((len(x_test)\/len(Target.index)) * 100))","9ea9ce7f":"print(\"Original Personal Loan Values of customer who bought : {0} ({1:2.2f}%)\".format(n_true, (n_true \/ (n_true + n_false)) * 100 ))\nprint(\"Original Personal Loan Values of customer who didn't buy  : {0} ({1:2.2f}%)\".format(n_false, (n_false \/ (n_true + n_false)) * 100))\nprint(\"\")\nprint(\"Training Personal Loan Values of customer who bought    : {0} ({1:0.2f}%)\".format(len(y_train[y_train[:] == 1]), (len(y_train[y_train[:] == 1])\/len(y_train)) * 100))\nprint(\"Training Personal Loan Values of customer who didn't buy   : {0} ({1:0.2f}%)\".format(len(y_train[y_train[:] == 0]), (len(y_train[y_train[:] == 0])\/len(y_train)) * 100))\nprint(\"\")\nprint(\"Test Personal Loan Values of customer who bought        : {0} ({1:0.2f}%)\".format(len(y_test[y_test[:] == 1]), (len(y_test[y_test[:] == 1])\/len(y_test)) * 100))\nprint(\"Test Personal Loan Values of customer who didn't buy       : {0} ({1:0.2f}%)\".format(len(y_test[y_test[:] == 0]), (len(y_test[y_test[:] == 0])\/len(y_test)) * 100))\nprint(\"\")","bd844a7f":"def logistReg(x_train,y_train,solver=\"liblinear\"):\n    # Fit the model on train\n    model = LogisticRegression(solver=solver)\n    model.fit(x_train, y_train)\n    #predict on test\n    y_predict = model.predict(x_test)\n    y_predictprob = model.predict_proba(x_test)\n\n    coef_df = pd.DataFrame(model.coef_,columns=list(x_train.columns))\n    coef_df['intercept'] = model.intercept_\n    model_score = model.score(x_train, y_train)\n    print(f\"Accuracy of Training Data: {model_score}\")\n    model_score = model.score(x_test, y_test)\n    print(f\"Accuracy of Test Data: {model_score}\")\n    print(coef_df)\n    print(metrics.classification_report(y_test,y_predict))\n    cm=metrics.confusion_matrix(y_test, y_predict, labels=[1, 0])\n\n    df_cm = pd.DataFrame(cm, index = [i for i in [\"1\",\"0\"]],\n                      columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\n    plt.figure(figsize = (8,5))\n    sns.heatmap(df_cm, annot=True)\n    plt.show()\n    print(\"f1 score\", metrics.f1_score(y_test,y_predict))\n    print(\"Auc Roc Score: \",metrics.roc_auc_score(y_test,y_predict))\n    return y_predictprob,y_predict","b94bd1c8":"y_predProb,y_pred = logistReg(x_train,y_train)","1589dcbc":"X = cust_df.drop([\"Personal Loan\",\"Age\",\"ZIP Code\",\"CreditCard\",\"ID\",\"Online\"],axis=1)     # Predictor feature columns \nY = Target   # Predicted class (1, 0) \n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=46)\n# 1 is just any random seed number\n\nx_train.head()","c354f66b":"y_predpob,y_pred=logistReg(x_train,y_train)","6afc8032":"sns.countplot(y_train)\nplt.show()","08f626e5":"y_train.value_counts()","9d532cbf":"#Undersampling the majority\nxtrain_resampled, ytrain_resampled = RandomUnderSampler(sampling_strategy=0.2,random_state=46).fit_resample(x_train,y_train)\nsns.countplot(ytrain_resampled)\nplt.show()\ny_predProb,y_predict = logistReg(xtrain_resampled,ytrain_resampled)","774026ef":"fprLR, tprLR, threshLR = metrics.roc_curve(y_test, y_predProb[:,1], pos_label=1)","bb9d7419":"scores =[]\n#OverSampling the minority to get the better results\nxtrain_resampled, ytrain_resampled = SMOTE(sampling_strategy=1,random_state=46).fit_resample(x_train,y_train)\nfor k in range(1,50):\n    NNH = KNeighborsClassifier(n_neighbors = k, weights = 'distance', metric='euclidean' )\n    NNH.fit(xtrain_resampled, ytrain_resampled)\n    scores.append(NNH.score(x_test, y_test))","fb7a6570":"plt.plot(range(1,50),scores)\nplt.show()","471afcee":"NNH = KNeighborsClassifier(n_neighbors= 5 , weights = 'distance', metric='euclidean' )\nNNH.fit(xtrain_resampled, ytrain_resampled)\ny_predKnn = NNH.predict(x_test)","46e8f3bc":"print(metrics.classification_report(y_test,y_predKnn))\ncm=metrics.confusion_matrix(y_test, y_predKnn, labels=[1, 0])\n\ndf_cm = pd.DataFrame(cm, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (8,5))\nsns.heatmap(df_cm, annot=True)\nplt.show()\nprint(f'Score of Knn Test Data : {NNH.score(x_test,y_test)}')\nprint(f'Score of Knn Train Data : {NNH.score(xtrain_resampled,ytrain_resampled)}')\nprint(f\"Roc AUC score of KNN : {metrics.roc_auc_score(y_test,y_predKnn)}\")\nprint(f\"f1 score of KNN : {metrics.f1_score(y_test,y_predKnn)}\\n\")","456d05c9":"pred_prob_NNH = NNH.predict_proba(x_test)\nfprNNH, tprNNH, threshNNH = metrics.roc_curve(y_test, pred_prob_NNH[:,1], pos_label=1)","7ef207f0":"NBmodel = GaussianNB()\nNBmodel.fit(xtrain_resampled,ytrain_resampled)\ny_NBPred = NBmodel.predict(x_test)","46000162":"print(metrics.classification_report(y_test,y_NBPred))\ncm=metrics.confusion_matrix(y_test, y_NBPred, labels=[1, 0])\n\ndf_cm = pd.DataFrame(cm, index = [i for i in [\"1\",\"0\"]],\n                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\nplt.figure(figsize = (8,5))\nsns.heatmap(df_cm, annot=True)\nplt.show()\nprint(f'Score of NB Test Data : {NBmodel.score(x_test,y_test)}')\nprint(f'Score of NB Train Data : {NBmodel.score(xtrain_resampled,ytrain_resampled)}')\nprint(f\"Roc AUC score of NB : {metrics.roc_auc_score(y_test,y_NBPred)}\")\nprint(f\"f1 score of NB : {metrics.f1_score(y_test,y_NBPred)}\\n\")","76b89d96":"pred_prob_NB = NBmodel.predict_proba(x_test)\nfprNB, tprNB, threshNB = metrics.roc_curve(y_test, pred_prob_NB[:,1], pos_label=1)","41a44e9d":"# plot roc curves\nplt.figure(figsize=(15,10))\nplt.plot(fprLR, tprLR, linestyle='--',color='orange', label='Logistic Regression')\nplt.plot(fprNNH, tprNNH, linestyle='--',color='green', label='KNN')\nplt.plot(fprNB, tprNB, linestyle='--', color='blue', label='Naive Bayes')\n# title\nplt.title('ROC curve')\n# x label\nplt.xlabel('False Positive Rate(1-True Positive Rate)')\n# y label\nplt.ylabel('True Positive rate')\n\nplt.legend(loc='best')\nplt.show();","8c1a8ff6":"Now lets check customers who bought personal loan and who didn't buy personal loan","cb8ea1b0":"There are 14 features available in the provided Dataset","fff412c2":"##### Read bank customer data","ac0ccc78":"### Naive Bayes","61d9cf61":"<span style=\"font-family: Arial; font-weight:bold;font-size:2.5em;color:#0e92ea\">Model Buidling","0104a23f":"- Logistic regression results for the Upsampled data is not prominent so undersampled the majoirty class ","d4c5f30e":"<center>\n<span style=\"font-family: Arial; font-weight:bold;font-size:1.9em;color:#0e92ea\"> <h3> Personal Loan Analytics\n<\/center>\n\n###### Objective:\nThe classification goal is to predict the likelihood of a liability customer buying personal loans.\nThis case is about a bank (Thera Bank) whose management wants to explore ways of converting its liability customers to personal loan customers (while retaining them as depositors)\n\n###### Exploratory Data Analysis\n    - Univariate Analysis - Outlier and Frequency Analysis\n    - Bivariate Analysis - Visualization\n    - Variable Reduction - Multicollinearity\n\n###### Data Pre-Processing - \n    - Missing Values Treatment - Numerical (Mean\/Median imputation) and Categorical (Separate Missing Category or Merging)\n    - Outlier Treatment\n    - Skewness reduction of variable\n    - Standardising the Numerical columns\n    \n###### Model Build and Model Diagnostics\n    - Train and Test split\n    - Significance of each Variable\n    - Gini and ROC \/ Concordance analysis - Rank Ordering\n    - Classification Table Analysis - Accuracy\n\n###### Model Validation\n    - ROC Curve - p-value and sign testing for the model coefficients\n    - Diagnostics check to remain similar to Training Model build\n    - BootStrapping, if necessary\n###### Choose the best model\n    - Draw an ROC_AUC curve of all the models and choose which performs better.","8cdf0e7c":"### Target Column Distribution","9ba06072":"- The Data gathered is not even \n- Only few of the liability customers showed interest in buying personal loan.","3e6f55b0":"<span style=\"font-family: Arial; font-weight:bold;font-size:2.5em;color:#0e92ea\">Data Pre Processing","337de73c":"### K-NN Classification Model","f8405b01":"#### Lets improve the model based on the removal of variables which are not mostly contributing and also removing multicolinear variables","cee832a1":"### Outlier Treatment\n###### IQR","8202d922":"- There are negative values in Experience columns which is not possible so imputing the negative values with mean of the Experience","643c7646":"It is evident from the plot that the AUC for the KNN ROC curve is higher than that for the Logistic Regression and Naive Bayes ROC curve. \n\nTherefore, we can say that KNN did a better job of classifying the positive class in the dataset.","185411e1":"Accuracies are good for both train and test data but we don't consider accuracy as main metric in classification because ACCURACY = (TP+TN)\/(TP+TN+FP+FN).\n\nIf the model predicts all the data points as positive then accuracy score is 100% but it is not a proper model.\n\nBy predicting everything as positive which are actually positive could lead to many problems. Accuracy is not a recommended metric here.\n\nf1-score is hormonic mean of precision and recall which can be considered to improve the model.\n\nSo lets improve the f1score = 2*((precision*recall)\/(precision+recall)) ","9bd48580":"### Spliting the Data","8f45f97e":"### Skewness reduction","7654e41e":"- The number of customers with higher education are buying Personal Loan compared to other groups.\n- Customers who operates online are more tend to take loans compared to non online users.\n- Family with size more than 2 are more intrested in personal loans\n- Customers with no credit card are more intrested to buy personal loans\n- Customers with no security accounts are more intrested in buying personal loans\n- There is a higher correlation in Age and Experience feature so we can drop one of them.\n- Correlation coefficient of ID and target variable Personal Loan is negative and close to zero so we can drop the variable.\n- Correlation coefficient of Age and Experience are negative and close to zero so we can drop these variables as well.\n- Correlation coefficient of Zip code variable is also close to zero so we can drop this variable .","9e2667f6":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.9em;color:#0e92ea\">Univariate Analysis","3991e769":"### Lets Segregate Categorical  and Continuous feature","b173d66a":"##### Above plot gives us the best k value to choose based on the score","7d793892":"- We could see the Mortgage column is more right skewed to reduce the skewness we can go with log transformations\n\n\nThe logarithm, x to log base 10 of x, or x to log base e of x (ln x), or x to log base 2 of x, is a strong transformation and can be used to reduce right skewness.\n\nThe square, x to x\u00b2, has a moderate effect on distribution shape and it could be used to reduce left skewness.","c933d8c0":"We will use 70% data for training and 30% of the data for testing.","7042b7f9":"<span style=\"font-family: Arial; font-weight:bold;font-size:2.5em;color:#0e92ea\"> Exploratory Data Analysis","5de9425b":"### Import necessary packages","06bb3fd6":"### As per the problem statement the target Variable\/Dependent Variable is Personal Loan Column","d2d0c8a6":"#### Imputing Data","f4ecde5e":"### END**","ae1ce7b7":"### Inference from Bivariate Analysis","cc00033c":"Lets check the split of data","ab503c0e":"### Inferences from Univariate Analysis :\n- Average age group of customers is 45yrs\n- Average Experience of customers is 20\n- Most of the customers are of age group 55\n- There are no null values in the data\n- 75% of the family members of the customer are 3\n- 75% of the customers are using Online banking facility.\n- Majority of the Customers are with experience between 20-30yrs\n- Outliers are present in Mortage and Income feature\n- Income and Mortage are right skewed \n- CCAVG , Mortgage, Personal Loan, Securities Account, CD Account are highly skewed\n- Mortage is extremly positive squared\n- There are negative values in the Experience Columns which is impossible imputation is required on it.","b29e2f67":"<span style=\"font-family: Arial; font-weight:bold;font-size:1.9em;color:#0e92ea\">Bivariate Analysis","b0274cd9":"8 Customers who actually bought personal loan but missclassified as non liable customer to purchase personal loan\n\n14 Customers who are not interested in personal loan but missclassified as liable customer to purchase PL.\n\nThe ROC_AUC Score States that the above model is able to distingush postives and negatives with 96.8%","32c2080b":"### Logistic Regression","2d33b48c":"IF found this Notebook Helpful. Please vote it.","cdf9af52":"#### As we already aware the target column is not symmetrical distributed lets upsample it","2b053f87":"- There are no missing values in the dataset\n- There are outliers in income and mortage column as per the above univariate analysis","37b99fdf":"- Most of the elements ie., more than 50% are 0. Hence it is very sparse column","7a8c76a3":"##### Lets study each column distribution","517cffd1":"#### Attribute Information:\n- ID :  Customer ID\n- Age :  Customer's age in completed years\n- Experience :  #years of professional experience\n- Income :  Annual income of the customer\n- ZIP Code :  Home Address ZIP code.\n- Family :  Family size of the customer\n- CCAvg :  Avg. spending on credit cards per month\n- Education : Education Level.\n            1. Undergrad\n            2. Graduate\n            3. Advanced\/Professional\n- Mortgage :  Value of house mortgage if any.\n- Personal Loan : Did this customer accept the personal loan offered in the last campaign?\n- Securities Account : Does the customer have a securities account with the bank?\n- CD Account : Does the customer have a certificate of deposit (CD) account with the bank?\n- Online : Does the customer use internet banking facilities?\n- Credit card : Does the customer use a credit card issued by Thera Bank?","f85b9484":"##                               Personal Loan Customer Perdiction "}}