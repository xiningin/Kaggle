{"cell_type":{"ada76322":"code","c5a78509":"code","f96b236e":"code","ba3cfb56":"code","c28bdd6a":"code","f9874a8a":"code","cd801f0c":"code","bcd8edf7":"code","6332ce42":"code","113d5d62":"code","86a79774":"markdown","afdb2f2e":"markdown","ac1b7af3":"markdown","deb052bc":"markdown","7240cefe":"markdown","056cf399":"markdown","c2588cc1":"markdown","d4dad19a":"markdown","f5b08401":"markdown","1e148f39":"markdown","c6d213cd":"markdown"},"source":{"ada76322":"# Load train & test data\nfrom __future__ import division\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\n\ndef get_img_paths(set_folder):\n    '''\n    Lists all paths in a given folder\n    '''\n    img_paths = []\n    for sub_folder in ['NORMAL', 'PNEUMONIA']:\n        directory = set_folder + '\/' + sub_folder\n        img_paths += [directory + '\/' + f for f in os.listdir(directory) if f[0] != '.']\n    return img_paths\n\ndef img_path_to_np_array(path, size):\n    '''\n    Loads image located at path into a numpy array of shape (size, size)\n    '''\n    img = cv2.imread(path)   # reads an image in the BGR format\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)   # COLOR_BGR2RGB for color\n    img = cv2.resize(img, dsize=(size, size), interpolation=cv2.INTER_CUBIC)\n    return img\n\ndef get_label(image_path):\n    '''\n    Assigns a label to an image\n    0 stands for healthy patient\n    1 stands for pneumonia\n    '''\n    return 1*('virus' in image_path or 'bacteria' in image_path)\n\ndef load_data(set_folder, size):\n    '''\n    Loads both NORMAL & PNEUMONIA images into two numpy arrays\n    '''\n    img_paths = get_img_paths(set_folder)\n    Y = np.array([get_label(img_path) for img_path in img_paths])\n    X = np.array([img_path_to_np_array(img_path, size) for img_path in img_paths])\n    X = np.reshape(X, (-1, size, size, 1))\n    X = X.astype('float32')\n    X = X\/255\n    return X, Y\n\nsize = 100 # we resize the original images into arrays of shape (size, size)\nchest_xray_folder = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/\"\ntrain_X, train_Y = load_data(chest_xray_folder + \"\/train\", size)\ntest_X, test_Y = load_data(chest_xray_folder + \"\/test\", size)\nvalid_X, valid_Y = load_data(chest_xray_folder + \"\/val\", size)","c5a78509":"# Plot training, validation and test set summary\ndef plot_train_validation_test_summary(train_Y, valid_Y, test_Y):\n    '''\n    Plots training, validation and test set sizes\n    '''\n    bars = ('Training', 'Validation', 'Test')\n    count = [train_Y.size, valid_Y.size, test_Y.size]\n    pos = np.arange(len(bars))\n    plt.bar(pos, count)\n    plt.xticks(pos, bars)\n    plt.title('Training, validation and test set sizes')\n    plt.show()\n    print(\"Size of the training set: \" + str(train_Y.size))\n    print(\"Size of the test set: \" + str(test_Y.size))\n    print(\"Size of the validation set: \" + str(valid_Y.size))\n    \nplot_train_validation_test_summary(train_Y, valid_Y, test_Y)","f96b236e":"# add validation set back into training set and create new validation set from test set\ndef shuffle_randomly(X, Y):\n    '''\n    Shuffles X and Y TOGETHER\n    '''\n    randomize = np.arange(Y.size)\n    np.random.shuffle(randomize)\n    X, Y = X[randomize, :, :, :], Y[randomize]\n    return X, Y\n\ndef concatenate_and_shuffle_randomly(X_a, Y_a, X_b, Y_b):\n    '''\n    Concatenates two datasets (X_a, Y_a) and (X_b, Y_b) into one new dataset (X, Y)\n    '''\n    X = np.concatenate((X_a, X_b), axis=0)\n    Y = np.concatenate((Y_a, Y_b), axis=0)\n    # shuffle X and Y TOGETHER\n    X, Y = shuffle_randomly(X, Y)\n    return X, Y\n\ntrain_X, train_Y = concatenate_and_shuffle_randomly(train_X, train_Y, valid_X, valid_Y)\n\nfrom sklearn.model_selection import train_test_split\nvalid_X, test_X, valid_Y, test_Y = train_test_split(test_X, test_Y, test_size=0.5, random_state=13)\n\nplot_train_validation_test_summary(train_Y, valid_Y, test_Y)","ba3cfb56":"# Plot training data summary\ndef plot_data_summary(Y):\n    '''\n    Plots data label summary\n    '''\n    bars = ('Healthy lungs', 'Pneumonia')\n    count = [np.sum(Y == 0), np.sum(Y == 1)]\n    pos = np.arange(len(bars))\n    plt.bar(pos, count)\n    plt.xticks(pos, bars)\n    plt.title('Training set label distribution')\n    print(\"Number of negative examples:\" + str(np.sum(Y == 0)))\n    print(\"Number of positive examples:\" + str(np.sum(Y == 1)))\n\nplot_data_summary(train_Y)","c28bdd6a":"# Augment training data and ensure it is correctly balanced\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndef augment_data_helper(X, Y, cardinal, rotation_range, shift, horizontal_flip, zoom_range, blur_range):\n    '''\n    Augments data contained in X, Y by applying rotations, horizontal & vertical shifts, horizontal flips and zoom\n    '''\n    \n    def blur(img):\n        size = img.shape[0]\n        blur_size = int(np.random.randint(4) * blur_range * size\/3)\n        if blur_size == 0:\n            return img\n        img = cv2.resize(img, dsize=(size, size), interpolation=cv2.INTER_CUBIC)\n        img = cv2.blur(img,(blur_size, blur_size))\n        img = np.reshape(img, (size, size, 1))\n        return img\n    \n    # define an image data generator using keras ImageDataGenerator\n    datagen = ImageDataGenerator(preprocessing_function= blur,\n                                 rotation_range=rotation_range,\n                                 width_shift_range=shift, height_shift_range=shift,\n                                 horizontal_flip=horizontal_flip,\n                                 zoom_range=zoom_range)\n    # fit parameters from data\n    datagen.fit(X)\n    # configure batch size and retrieve one batch of images\n    first_batch = True\n    for X_batch, Y_batch in datagen.flow(X, Y, batch_size=Y.size):\n        if first_batch:\n            X_augmented = X_batch\n            Y_augmented = Y_batch\n            first_batch = False\n        else:\n            X_augmented = np.concatenate((X_augmented, X_batch), axis=0)\n            Y_augmented = np.concatenate((Y_augmented, Y_batch), axis=0)\n        if Y_augmented.size >= cardinal:\n            break\n    X_augmented = X_augmented[:cardinal, :, :, :]\n    Y_augmented = Y_augmented[:cardinal]\n    return X_augmented, Y_augmented\n\ndef augment_data(X, Y, cardinal, rotation_range, shift, horizontal_flip, zoom_range, blur_range):\n    '''\n    Augments data contained in X, Y by applying rotations, horizontal & vertical shifts, and horizontal flips\n    Ensures the final output contains as many negative examples as positive examples\n    '''\n    # separate positive from negative training examples\n    X_0, Y_0 = X[Y == 0], Y[Y == 0]\n    X_1, Y_1 = X[Y == 1], Y[Y == 1]\n    \n    # augment negative and positive training examples separately\n    # we want our augmented dataset to be of size cardinal\n    # so we create one positive augmented subset of size cardinal\/2 and one negative augmented subset of size cardinal\/2\n    subset_cardinal = int(cardinal\/2)\n    X_augmented_0, Y_augmented_0 = augment_data_helper(X_0, Y_0, subset_cardinal, rotation_range, shift, horizontal_flip, zoom_range, blur_range)\n    X_augmented_1, Y_augmented_1 = augment_data_helper(X_1, Y_1, subset_cardinal, rotation_range, shift, horizontal_flip, zoom_range, blur_range)\n    \n    X_augmented, Y_augmented = concatenate_and_shuffle_randomly(X_augmented_0, Y_augmented_0, X_augmented_1, Y_augmented_1)\n    \n    return X_augmented, Y_augmented\n\ntrain_X, train_Y = augment_data(train_X, train_Y, cardinal=100000, rotation_range=10, shift=0.1, horizontal_flip=True, zoom_range=0.2, blur_range=0.15)\nplot_data_summary(train_Y)","f9874a8a":"# Plot some training set examples to illustrate data augmentation (rotations, shifts, horizontal flips)\ndef plot_some_examples(X, Y, pred=None):\n    '''\n    Plots 9 randomly selected examples\n    '''\n    randomize = np.arange(Y.size)\n    np.random.shuffle(randomize)\n    for i in range(9):\n        plt.subplot(330 + 1 + i)\n        plt.imshow(X[randomize[i]].reshape(X.shape[1], X.shape[2]), cmap=plt.get_cmap('gray'))\n        plt.xticks([]), plt.yticks([])\n        plt.title('Pneumonia' if Y[randomize[i]] else 'Healthy lungs')\n        if pred is not None:\n            plt.xlabel('Actual: ' + str(Y[randomize[i]]))\n            plt.title('Prediction: ' + str(pred[randomize[i]]))\n    plt.subplots_adjust(hspace = 1), plt.show()\n    \nplot_some_examples(train_X, train_Y)","cd801f0c":"def balance_data(X, Y):\n    '''\n    Balances out labels from set by removing some of the dominant label examples\n    '''\n    X, Y = shuffle_randomly(X, Y)\n    # separate positive from negative examples\n    X_0, Y_0 = X[Y == 0], Y[Y == 0]\n    X_1, Y_1 = X[Y == 1], Y[Y == 1]\n    min_size = min(Y_0.size, Y_1.size)\n    # subset positive and negative examples so that we end up with the same amount of each\n    X_0, Y_0 = X_0[:min_size, :, :, :], Y_0[:min_size]\n    X_1, Y_1 = X_1[:min_size, :, :, :], Y_1[:min_size]\n    # concatenate and shuffle randomly\n    X, Y = concatenate_and_shuffle_randomly(X_0, Y_0, X_1, Y_1)\n    return X, Y\n\nvalid_X, valid_Y = balance_data(valid_X, valid_Y)","bcd8edf7":"# Convolutional Neural Network\nimport keras\nfrom keras.models import Sequential, Input, Model, load_model\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom keras.layers.advanced_activations import LeakyReLU\n\n# Initialize CNN\nnn_model = Sequential()\n# Convolution layer 1\nnn_model.add(Conv2D(16, kernel_size=(3, 3), activation='linear', input_shape=(size, size, 1), padding='same'))\nnn_model.add((LeakyReLU(alpha=0.1)))\nnn_model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nnn_model.add(Dropout(0.4))\n# Convolution layer 2\nnn_model.add(Conv2D(32, kernel_size=(3, 3), activation='linear', padding='same'))\nnn_model.add((LeakyReLU(alpha=0.1)))\nnn_model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nnn_model.add(Dropout(0.4))\n# Convolution layer 3\nnn_model.add(Conv2D(64, kernel_size=(3, 3), activation='linear', padding='same'))\nnn_model.add((LeakyReLU(alpha=0.1)))\nnn_model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\nnn_model.add(Dropout(0.4))\n# Flat part\nnn_model.add(Flatten())\nnn_model.add(Dense(64, activation='linear'))\nnn_model.add(LeakyReLU(alpha=0.1))\nnn_model.add(Dropout(0.4))\nnn_model.add(Dense(1, activation='sigmoid'))\n\n# Compile CNN\nnn_model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])","6332ce42":"# Train CNN\nnn_train = nn_model.fit(train_X, train_Y, batch_size=64, epochs=3, verbose=1, validation_data=(valid_X, valid_Y))","113d5d62":"# Plot learning curves and compute accuracy on the test set\ndef plot_learning_curves(nn_train, test_X, test_Y):\n    accuracy = nn_train.history['acc']\n    val_accuracy = nn_train.history['val_acc']\n    test_accuracy = nn_model.evaluate(test_X, test_Y, verbose=0)[1]\n    epochs = range(len(accuracy))\n\n    plt.plot(epochs, accuracy, color='blue', label='Training accuracy')\n    plt.plot(epochs, val_accuracy, color='red', label='Validation accuracy')\n    plt.title('Learning curves - Test set accuracy = ' + str(round(test_accuracy, 3)))\n    plt.xlabel('Epoch number')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.show()\n\nplot_learning_curves(nn_train, test_X, test_Y)\n\n# Plot some test set examples\ntest_X_for_plot, test_Y_for_plot = balance_data(test_X, test_Y)\ntest_predictions_for_plot = nn_model.predict_classes(test_X_for_plot)\nplot_some_examples(test_X_for_plot, test_Y_for_plot, test_predictions_for_plot)\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\n\n# Confusion matrix\ntest_predictions = nn_model.predict_classes(test_X)\nreport = classification_report(test_Y, test_predictions)\nconfusion = confusion_matrix(test_Y, test_predictions)\n\n# Plot confusion matrix\ndef plot_confusion_matrix(confusion):\n    '''\n    Plot confusion matrix\n    '''\n    ax= plt.subplot()\n    sns.heatmap(confusion, annot=True, ax=ax, fmt='g'); #annot=True to annotate cells\n    ax.set_xlabel('Prediction');ax.set_ylabel('Reality'); \n    ax.set_title('Confusion matrix'); \n    ax.xaxis.set_ticklabels(['Normal lungs', 'Pneumonia']); ax.yaxis.set_ticklabels(['Normal lungs', 'Pneumonia'])\n    \nplot_confusion_matrix(confusion)\nprint(report)","86a79774":"In this article we try to automate pneumonia diagnosis on pediatric chest X-ray images provided by the Guangzhou Women and Children\u2019s Medical Center, Guangzhou (China). The images display both healthy and unhealthy lungs.\n![](https:\/\/i.imgur.com\/jZqpV51.png)\nAlthough pneumonia can be either bacterial or viral, our goal is not to distinguish between the two types of pneumonia. We solely aim at _diagnosing_ pneumonia.\n\nLet us take a first look at our dataset.","afdb2f2e":"Let us also balance out our validation set, so as to make validation accuracy more meaningful:","ac1b7af3":"The dataset comprises a train set, a test set and a validation set. As given, the train set and the test set contain 5,216 and 624 images respectively. However, with 16 images only, the validation set is very small:","deb052bc":"The next step is to define our machine learning model. Unsurprisingly, we will use a Convolutional Neural Network (CNN). In fact: in the past few years, CNNs have proven extremely effective at computer vision tasks, including (but not limited to) object recognition and object detection.\n\nUsing `keras.models` and `keras.layers` we will sequentially define our neural network structure:\n* 3 convolutional layers\n* 2 fully connected layers\n\nIn each convolutional layer we use a leaky ReLU activation, perform max pooling and apply dropout for regularization. While we use a leaky ReLU activation (along with dropout) in the first of the two fully connected layers, we use a sigmoid function in the last layer. Our final goal of binary classification motivates this choice.","7240cefe":"We can now train our convolutional neural network. We choose to train 3 epochs with a batch size of 64.\nNot too large a batch size allows our network to make progress right away rather than having to wait for an entire pass over the training set. Conversely, not too small a batch size allows us to take advantage of parallelization.","056cf399":"We achieve a ~90% accuracy on the test set, a ~95% recall and a ~85% precision. This is a quite good accuracy considering that the neural network training lasted ~20 minutes and that the network was trained from scratch, i.e. no transfer learning.","c2588cc1":"Though still quite small, our validation set size is now acceptable.\nOne other important aspect to look at is the class balancing in the training set:","d4dad19a":"Now that the model is trained it is time to see how good it does on the test set:","f5b08401":"Therefore we decided not to use the given validation set for validation but, rather, to plug it back into our training set. We then built our own validation set by randomly sampling half of the examples from the test set, yielding a validation set and a new test set. This ensures that the validation set comes from the same distribution as the test set, which is crucial in any machine learning endeavor.","1e148f39":"At this time our training, test and validation sets are properly defined. Moreover, our training set is perfectly balanced with 50,000 negative and 50,000 positive examples, which add up to a total of 100,000 training examples. Let us generate some visualizations to illustrate the above mentioned data augmentation. One can see how our new training images are slightly tilted and not perfectly centered:","c6d213cd":"The training set appears **very imbalanced, with 1,349 negative cases VS 3,883 positive cases**. Our goal in the next section will be to rebalance and \"augment\" the training set.\nTraining set augmentation consists of generating training examples ourselves, i.e. generating fake X-rays, by applying some transformations to the X-rays we already have:\n* tiny rotations: if an image is a chest X-ray then a slightly rotated version of this image is also a chest X-ray\n* tiny vertical & horizontal shifts: if an image is a chest X-ray then the same image shifted a little bit up, down, left or right is also a chest X-ray\n* horizontal shifts: if an image is a chest X-ray then the same image flipped horizontally is also a chest X-ray (this is assuming that the human body is symmetrical, which it is not really but it turns out it does not matter in the case of pneumonia diagnosis)\n* zooms: if an image is a chest X-ray then a slight zoom into this image is also a chest X-ray\n* Gaussian blur: if an image is a chest X-ray then the same image slightly blurred is also a chest X-ray\n\nTo generate these new transformed images, we use the `ImageDataGenerator` function from the `keras.preprocessing.image` library for data augmentation."}}