{"cell_type":{"3ce224a3":"code","13a02258":"code","06787302":"code","56edb4ab":"code","8ad7c529":"code","a29c543b":"code","bf28fa1a":"code","386dbed3":"code","be346446":"code","778429a9":"code","8d807cbd":"code","41e97605":"code","dc56a3cc":"code","db17d6e8":"code","5482ee6e":"code","a1c8df6b":"markdown","50fe57a8":"markdown","924586c1":"markdown","b5171553":"markdown","8414ae7b":"markdown","2654f59b":"markdown","56869187":"markdown","b963a132":"markdown","33499b94":"markdown"},"source":{"3ce224a3":"import cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom glob import glob","13a02258":"datadir = '\/kaggle\/input\/shopee-product-matching'\n\ntrain_image_dir = f'{datadir}\/train_images'\ntest_image_dir = f'{datadir}\/test_images'\n\ntrain_image_paths = glob(f'{train_image_dir}\/*.jpg')\nprint('Train images:', len(train_image_paths))\ntest_image_paths = glob(f'{test_image_dir}\/*.jpg')\nprint('Test images:', len(test_image_paths))","06787302":"df_train = pd.read_csv(f'{datadir}\/train.csv')\ndf_test = pd.read_csv(f'{datadir}\/test.csv')\ndf_sub = pd.read_csv(f'{datadir}\/sample_submission.csv')\n\ndf_train.head()","56edb4ab":"df_test.head()","8ad7c529":"df_sub.head()","a29c543b":"df_train.posting_id.value_counts()","bf28fa1a":"image_counts = df_train.image.value_counts()\nprint(image_counts.head(20))\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 8))\nax.set_xlabel('N appearances of image filename')\nax.set_ylabel('Counts')\nax.hist(image_counts, bins=10, range=(0, 10))","386dbed3":"n_visualize = 5\n\nfig, axes = plt.subplots(1, n_visualize, figsize=(n_visualize*5, 5))\nfor i in range(n_visualize):\n    record = df_train.iloc[i]\n    filename = record.image\n    phash = record.image_phash\n    title = record.title\n    \n    ax = axes[i]\n    path = f'{train_image_dir}\/{filename}'\n    image = cv2.imread(path)[:,:,::-1]\n    image = cv2.resize(image, (256, 256))\n    ax.imshow(image)\n    ax.set_title(f'phash: {phash}')\n    print(f'Title {i+1}:', title)","be346446":"n_visualize = 3\n\nfig, axes = plt.subplots(1, n_visualize, figsize=(n_visualize*5, 5))\nfor i in range(n_visualize):\n    record = df_test.iloc[i]\n    filename = record.image\n    title = record.title\n    phash = record.image_phash\n    \n    ax = axes[i]\n    path = f'{test_image_dir}\/{filename}'\n    image = cv2.imread(path)[:,:,::-1]\n    image = cv2.resize(image, (256, 256))\n    ax.imshow(image)\n    ax.set_title(f'phash: {phash}')\n    print(f'Title {i+1}:', title)","778429a9":"phash_counts = df_train.image_phash.value_counts()\nprint(phash_counts)\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 8))\nax.set_xlabel('N appearances of image_phash value')\nax.set_ylabel('Counts')\nax.hist(phash_counts, bins=20, range=(0, 20))","8d807cbd":"n_vis_phash = 3\nn_samples = 3\n\nfig, axes = plt.subplots(n_vis_phash, n_samples, figsize=(n_samples*5, n_vis_phash*5))\nfor i in range(n_vis_phash):\n    sample_phash = phash_counts.index[i]\n    df_sample = df_train[df_train.image_phash == sample_phash]\n    \n    for j in range(n_samples):\n        record = df_sample.iloc[j]\n        filename = record.image\n        title = record.title\n        phash = record.image_phash\n    \n        ax = axes[i][j]\n        path = f'{train_image_dir}\/{filename}'\n        image = cv2.imread(path)[:,:,::-1]\n        image = cv2.resize(image, (256, 256))\n        ax.imshow(image)\n        ax.set_title(f'phash: {phash}')\n        print(f'Title {i+1}:', title)","41e97605":"print(df_train.title.head(20))\n\ndef count_words(sentence):\n    return len(sentence.split(' '))\n\ndf_train['n_words'] = df_train.title.map(count_words)\nfig, ax = plt.subplots(1, 1, figsize=(10, 8))\nax.set_xlabel('N words of title')\nax.set_ylabel('Counts')\nax.hist(df_train.n_words, bins=20, range=(0, 40))","dc56a3cc":"df_train.n_words.value_counts().sort_index(ascending=False).head(10)","db17d6e8":"label_counts = df_train.label_group.value_counts()\nprint(label_counts)\nprint('Total:', len(label_counts))\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 8))\nax.set_xlabel('N appearances of label_group')\nax.set_ylabel('Counts')\nax.hist(label_counts, bins=20, range=(0, 20))","5482ee6e":"n_vis_phash = 5\nn_samples = 4\n\nfig, axes = plt.subplots(n_vis_phash, n_samples, figsize=(n_samples*5, n_vis_phash*5), constrained_layout=True)\nfig.suptitle('Different image but same product', fontsize=16)        \nfor i in range(n_vis_phash):\n    sample_label = label_counts.index[i]\n    df_sample = df_train[df_train.label_group == sample_label]\n    \n    for j in range(n_samples):\n        record = df_sample.iloc[j]\n        filename = record.image\n        title = record.title\n        phash = record.image_phash\n    \n        ax = axes[i][j]\n        path = f'{train_image_dir}\/{filename}'\n        image = cv2.imread(path)[:,:,::-1]\n        image = cv2.resize(image, (256, 256))\n        ax.imshow(image)\n        ax.set_title(f'phash: {phash}')\n        print(f'Title {i+1}:', title)","a1c8df6b":"# Explore label_group column\n\nlabel_group connects the same product in posts (possively with different images). Because our goal is to predict the same product, label_group seems to be a key variable in this competition.\n\nIn the case predicting label_group from other variables, population of each label_group value should be cared.\nSome label_group value (e.g. 854939659 in below) appears only 2 times. Splitting train set into train\/val set can result in the case that 1. one for train (of train) set and one for val set or 2. only appear in one side. This situation requires careful split and evaluation strategy.\n\nAdditionally, this can be viewed as ***many classes and few sample per class*** situation. I think metric learning is a possible approach for this, like https:\/\/www.kaggle.com\/c\/humpback-whale-identification","50fe57a8":"## Visualize test images","924586c1":"# Explore posting_id and image columns\n\n- posting_id: unique\n- image: most is unique but not all","b5171553":"I hope this notebook may help you ;)","8414ae7b":"# Explore image_phash column\n\nphash (perceptual hash) associates the same image from different posts.","2654f59b":"Maximum number of words < 70. Recent deep NLP models can easily handle sentence with such length (e.g. BERT often allows 512 input length).","56869187":"## Visualize train images","b963a132":"# Explore title column\n\n- title column is a short description sentence of product. Each title is composed of ~70 words at most (see below histogram).\n- Mostly English, but other languages and proper nouns are also included.","33499b94":"# Inspect dataset\n\n- Train set has abount 30k images\n- Test set makes only 3 images publicly available\n- Columns\n    - posting_id: unique id for the posted image\n    - image: filename of each image. Most is unique, but not all\n    - image_phash: perceptual hash value associated with an image, see details in https:\/\/en.wikipedia.org\/wiki\/Perceptual_hashing\n    - title: description sentence\n    - label_group: ID of identical product (can be posted with different image). Only in train set."}}