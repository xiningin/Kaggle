{"cell_type":{"d588a59a":"code","bbfb3e8d":"code","247d84d9":"code","0e2f1e73":"code","90267fa6":"code","f87ea8c8":"code","67d4924c":"code","f0bb7cb6":"code","e9520240":"code","00965036":"code","3b773ff7":"code","09005949":"code","b5261e9b":"code","4e397432":"code","b6c2d3a8":"code","dd3b7bed":"code","88fa09e3":"code","9420b50c":"code","86c996a7":"code","e0930efa":"code","e2f25197":"code","643d2ca0":"code","258293ed":"code","b33bbe2d":"code","875babae":"code","39377f18":"code","d39b976a":"code","fcf1b340":"code","6d10ce66":"code","d7a76d9a":"code","cce9ae4d":"code","b8ee1e99":"code","09fc3e06":"code","18b3a6f9":"code","ccd9d996":"code","33e7754e":"code","5599dd8d":"code","0fdabd9b":"code","deb15951":"code","d6eab758":"code","f43ffb7f":"code","2241fa4b":"code","7eb504aa":"code","a88749a4":"code","8a88d3c8":"code","fab98478":"code","74b9139f":"code","1de09370":"code","d9c4afaa":"code","c12e3c3c":"code","551354cc":"code","d29979fb":"code","ff8afcb8":"markdown","a15f66a2":"markdown","f2ebbbc4":"markdown","64b78a5d":"markdown","bf4ff3a4":"markdown","41dbf84e":"markdown","9f23e7b4":"markdown","ab958b5b":"markdown","4aa6ab85":"markdown","ef636134":"markdown","50a195c8":"markdown","1ede9c8b":"markdown","03383c69":"markdown","01d63eab":"markdown","d64407d4":"markdown","c53c5f7c":"markdown","1fedb6dd":"markdown"},"source":{"d588a59a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bbfb3e8d":"#Import libraries for descriptive analysis\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n%matplotlib inline","247d84d9":"df = pd.read_csv('\/kaggle\/input\/loan-data-set\/loan_data_set.csv')","0e2f1e73":"#Visualize the table\ndf.head()","90267fa6":"#Types of attributes\/missing values\ndf.info()","f87ea8c8":"#df['Loan_Status'].value_counts(normalize=True).plot.bar(label = '% of loan approvals')\n\nplt.figure(figsize=(2, 2))\n\nfig = df['Loan_Status'].value_counts(normalize=True).plot(kind='bar')\nfig.set_title('% Loan of approvals')","67d4924c":"fig = plt.figure(figsize=(18,2))\nax1 = fig.add_subplot(161)\ndf['Gender'].value_counts(normalize=True).plot(kind='bar')\nax2 = fig.add_subplot(162)\ndf['Married'].value_counts(normalize=True).plot(kind='bar')\nax3 = fig.add_subplot(163)\ndf['Dependents'].value_counts(normalize=True).plot(kind='bar')\nax4 = fig.add_subplot(164)\ndf['Self_Employed'].value_counts(normalize=True).plot(kind='bar')\nax5 = fig.add_subplot(165)\ndf['Property_Area'].value_counts(normalize=True).plot(kind='bar')\nax6 = fig.add_subplot(166)\ndf['Education'].value_counts(normalize=True).plot(kind='bar')\nax1.title.set_text('Gender')\nax2.title.set_text('Married?')\nax3.title.set_text('Dependents?')\nax4.title.set_text('Self Employed?')\nax5.title.set_text('Property_Area')\nax6.title.set_text('Education')\nplt.show()","f0bb7cb6":"#Function to plot multiple colour bar charts\ndef plot_bar(dataframe, group_col, hue_col, count_col):\n    df_grp = dataframe.groupby([group_col, hue_col]).count()[count_col]\n    df_grp = df_grp.reset_index()\n    df_grp['Percentage'] = 100*(df_grp[count_col]\/len(dataframe))\n    print(df_grp)\n    g = sns.catplot(x=group_col, y=\"Percentage\",\n                hue=hue_col,\n                data=df_grp, kind=\"bar\",\n                height=4, aspect=.7);\n\ndef plot_bar_within(dataframe, group_col, hue_col, count_col):\n    #Create another set of plots to inspect within class approvals\n    df_grp = dataframe.groupby([group_col, hue_col]).count()[count_col]\n    df_grp = df_grp.reset_index()\n    #df_grp['Percentage'] = 100*(df_grp[count_col]\/len(dataframe))\n    #print(df_grp)\n    categories = list(set(df_grp[group_col]))\n    print(categories)\n    for item in categories:\n        df_temp = df_grp[df_grp[group_col] == item]\n        df_temp['Percentage'] = 100*(df_temp[count_col]\/df_temp[count_col].sum())\n        plt.figure()\n        g2 = sns.barplot(x=hue_col, y = 'Percentage', data=df_temp).set_title(item)\n        print(df_temp)\n        \n","e9520240":"#Custom plotting function for categorical attributes\nplot_bar(df, 'Gender', 'Loan_Status', 'Loan_ID')\napproved_applications= 75+339\nprop_female_approved = 75\/approved_applications\nprint('No of approved applications:')\nprint(approved_applications)\nprint('Proportion of female approved applications')\nprint(prop_female_approved)","00965036":"#Plot bar for \nplot_bar_within(df, 'Loan_Status', 'Gender', 'Loan_ID')","3b773ff7":"#plot_bar_within(df, 'Gender', 'Loan_Status', 'Loan_ID')","09005949":"Gender = pd.crosstab(df['Gender'], df['Loan_Status'])\nGender.div(Gender.sum(1).astype(float), axis = 0).plot(kind='bar', stacked=True)","b5261e9b":"#Custom plotting function for categorical attributes\nplot_bar(df, 'Loan_Status', 'Married', 'Loan_ID')\napproved = 134+285\nprint(approved)\napproved_married = 285\/approved\nprint(approved_married)","4e397432":"plot_bar_within(df, 'Married', 'Loan_Status', 'Loan_ID')","b6c2d3a8":"plot_bar_within(df, 'Loan_Status', 'Married', 'Loan_ID')","dd3b7bed":"Married = pd.crosstab(df['Married'], df['Loan_Status'])\nDependents = pd.crosstab(df['Dependents'], df['Loan_Status'])\nEducation = pd.crosstab(df['Education'], df['Loan_Status'])\nSelf_Employed = pd.crosstab(df['Self_Employed'], df['Loan_Status'])\n\nMarried.div(Married.sum(1).astype(float), axis = 0).plot(kind='bar', stacked=True)\nplt.show()\nDependents.div(Dependents.sum(1).astype(float), axis = 0).plot(kind='bar', stacked=True)\nplt.show()\nEducation.div(Education.sum(1).astype(float), axis = 0).plot(kind='bar', stacked=True)\nplt.show()\nSelf_Employed.div(Self_Employed.sum(1).astype(float), axis = 0).plot(kind='bar', stacked=True)\nplt.show()","88fa09e3":"Credit_History = pd.crosstab(df['Credit_History'], df['Loan_Status'])\nProperty_Area = pd.crosstab(df['Property_Area'], df['Loan_Status'])\n\nCredit_History.div(Credit_History.sum(1).astype(float), axis = 0).plot(kind='bar', stacked=True)\nplt.show()\nProperty_Area.div(Property_Area.sum(1).astype(float), axis = 0).plot(kind='bar', stacked=True)\nplt.show()","9420b50c":"df2 = df.reset_index()\ndf2 = df2.dropna()\nprint(df2.head())\nplt.figure(figsize=(15,5))\nplt.subplot(131)\nsns.distplot(df['ApplicantIncome'])\nplt.subplot(132)\ndf['ApplicantIncome'].plot(kind='box')\nplt.subplot(133)\nsns.scatterplot(data=df, x=\"ApplicantIncome\", y=\"LoanAmount\", hue='Loan_Status')","86c996a7":"fig2 = plt.figure()\ndf.boxplot(column = 'ApplicantIncome', by='Gender')","e0930efa":"fig2 = plt.figure()\ndf.boxplot(column = 'ApplicantIncome', by='Education')","e2f25197":"fig2 = plt.figure()\ndf.boxplot(column = 'ApplicantIncome', by='Married')","643d2ca0":"fig2 = plt.figure()\ndf.boxplot(column = 'ApplicantIncome', by='Property_Area')","258293ed":"fig2 = plt.figure()\ndf.boxplot(column = 'ApplicantIncome', by='Loan_Status')","b33bbe2d":"#Bins on the applicant income\nbins = [0,2500,4000,6000,81000]\ngroup = ['Low', 'Average', 'High', 'Very High']\ndf['IncomeBin'] = pd.cut(df['ApplicantIncome'], bins, labels = group)\n#df.head()\nIncome_bin = pd.crosstab(df['IncomeBin'], df['Loan_Status'])\nIncome_bin","875babae":"df.info()","39377f18":"###MOdel building for explanability","d39b976a":"#Define the target and the training set - dropping the ID to avoid too many categories\/confusion\ny = df['Loan_Status']\nfeatures_raw = df.drop(columns=['Loan_Status', 'Loan_ID'], axis = 1)","fcf1b340":"features_proc = features_raw\nfeatures_raw.info()","6d10ce66":"#Convert missing values to NA in float fields\nfeatures_proc['LoanAmount'] = features_raw.LoanAmount.replace(0,np.nan)\nfeatures_proc['Loan_Amount_Term'] = features_raw.Loan_Amount_Term.replace(0,np.nan)\nfeatures_proc['Credit_History'] = features_raw.Credit_History.replace(0,np.nan)","d7a76d9a":"#Transform categorical data\nfeatures_proc = pd.get_dummies(features_proc)\nfeatures_proc.head()","cce9ae4d":"###Now take trainingd ata into array\nX = features_proc.values\nX.shape","b8ee1e99":"features_proc.iloc[0]","09fc3e06":"#Impute missing values in the data (using mean value)\nfrom sklearn.impute import SimpleImputer \nimp = SimpleImputer(strategy='mean')\nimp.fit(X)\nX = imp.transform(X)","18b3a6f9":"X[0] #All missing values are filled\nX.shape","ccd9d996":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\ntree_model = DecisionTreeClassifier(random_state=0, max_depth=5, min_samples_split=5).fit(train_X, train_y)","33e7754e":"y_pred = tree_model.predict(val_X)\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(val_y, y_pred)","5599dd8d":"val_y.value_counts()","0fdabd9b":"from sklearn.metrics import classification_report\nprint(classification_report(val_y, y_pred))","deb15951":"#Validation dataframe\ndf_val = pd.DataFrame(data=val_X, columns=feature_names)\ndf_val['true_label'] = list(val_y)\ndf_val['pred_label'] = y_pred","d6eab758":"df_val.info()","f43ffb7f":"df_val.head()","2241fa4b":"True_vals = pd.crosstab(df_val['Married_Yes'], df_val['true_label'])\nPredicted_vals = pd.crosstab(df_val['Married_Yes'], df_val['pred_label'])\n\nTrue_vals.div(True_vals.sum(1).astype(float), axis = 0).plot(kind='bar', stacked=True)\nplt.show()\nPredicted_vals.div(Predicted_vals.sum(1).astype(float), axis = 0).plot(kind='bar', stacked=True)\nplt.show()","7eb504aa":"True_vals","a88749a4":"Predicted_vals","8a88d3c8":"feature_names = [i for i in features_proc.columns]","fab98478":"from sklearn import tree\nimport graphviz\n\ntree_graph = tree.export_graphviz(tree_model, out_file=None, feature_names=feature_names)\ngraphviz.Source(tree_graph)","74b9139f":"row_to_show = 7\ndf_val2 = df_val.drop(columns=['true_label', 'pred_label'], axis = 1)\ndata_for_prediction = df_val2.iloc[row_to_show]  # use 1 row of data here. Could use multiple rows if desired\ndata_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n\n\ntree_model.predict_proba(data_for_prediction_array)","1de09370":"df_val.iloc[row_to_show]","d9c4afaa":"import shap  # package used to calculate Shap values\n\n# Create object that can calculate shap values\nexplainer = shap.TreeExplainer(tree_model)\n\n# Calculate Shap values\nshap_values = explainer.shap_values(data_for_prediction)","c12e3c3c":"shap.initjs()\nshap.force_plot(explainer.expected_value[1], shap_values[1], data_for_prediction)","551354cc":"data_for_prediction_array","d29979fb":"import shap  # package used to calculate Shap values\n\n# Create object that can calculate shap values\nexplainer = shap.TreeExplainer(tree_model)\n\n# calculate shap values. This is what we will plot.\n# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\nshap_values = explainer.shap_values(df_val2)\n\n# Make plot. Index of [1] is explained in text below.\nshap.summary_plot(shap_values[1], df_val2)","ff8afcb8":"Can keep doing this exploration for all the variable sin the data","a15f66a2":"Now create a tree model to see how a default classifier outputs Y\/N predictions","f2ebbbc4":"Explore other attributes like credit history and property type against loan approval rates. Looks like more loans are approved when credit history requirements are met... and also in urban areas and semi urban compared to rural. ","64b78a5d":"**1.c.1 Does gender have an impact on loan applications?**\nLooks like 20% of loan applications are from female applicants and remaining are male applicants, though within gender, proportion of loan rejections is ~30% for both males and females. 80% of approved applications (n = 414) are female while the remainder are male. However, within class, rejection rates for males and females are similar so this is an artifact of having a lower number of female applicants **historical bias**. Models could potentially learn Gender = M as a feature for approving a loan application","bf4ff3a4":"**Feature Understanding (defining some less obvious features)**\n\n* Loan_ID: Unique identifier for loan\n* Applicant Income & Co-applicant Income: applicable when applying as a family\n* Loan amount: requested loan amount\n* Loan Amount Term: Requested time period in months\n* Credit History: Flag to identify if credit history meets requirements\n* Loan Status: Target = Y or N if house loan is approved or rejected\n\n**Moving on to data visualization**","41dbf84e":"1.b. We can explore all categorical values with barplots & suplots\n* 80% of loan applicants are male, while only 20% are female - this could introduce historical bias when training a model for loan approvals\n* More than 60% of house loan applicants are married\n* About 40% have dependents (children)\n* Less than 20% are self employed\n* Less than 30% of loan applicants are applying from rural areas\n* 80% of the loans are given to graduates\n\n","9f23e7b4":"**Let's read in the sample dataset from Analytics Vidhya (Loan Prediction course):**\n<div><\/div>\nDataset: https:\/\/www.kaggle.com\/burak3ergun\/loan-data-set\n<div><\/div>\nProblem Statement: Taken from the kaggle dataset link\n<div><\/div>\nhttps:\/\/courses.analyticsvidhya.com\/courses\/loan-prediction-practice-problem-using-python?utm_source=practice_problem_Loan_Prediction-III&utm_medium=Datahack\n\nIn this course, we are solving a real life case study of Dream Housing Finance. The company deals in all home loans. They have a presence across all urban, semi-urban and rural areas. Customers first apply for a home loan after that company validates the customer's eligibility. The company wants to automate the loan eligibility process (real-time) based on customer detail provided while filling online application form.\n\nBy the end of the course, you will have a solid understanding of Classification problem and Various approaches to solve the probem\n","ab958b5b":"Explore Applicant Income by different demographic variables, given the wide range:\n* Average income for males higher than females\n* Graduates have a wider range of higher incomes than non-graduates\n* Married applicants also have higher income","4aa6ab85":"Being Married seems to be an important feature... ","ef636134":"**1. Let's understand the dataset and attributes**","50a195c8":"1.c. We want to overlay another dimension to our plots to visualize loan approvals by group and identify potential sources of bias","1ede9c8b":"**1.c.2. what about marital status?**\nLooks like 64% of all loan applications are from married individuals. 68% of all approved loans come from individuals who are married. Within the married group, 70% of loans were approved while this figure was 60% in the non-married group","03383c69":"Compare Gender for approved and not approved loans","01d63eab":"1.d. Explore numerical data","d64407d4":"visualise the output and score the model","c53c5f7c":"Now let's try to build the model - preprocess the data","1fedb6dd":"1.a. Total number of records in data (rows) = 614 and exploring the target (Loan Status Y\/N) shows that 69% of loans have been approved"}}