{"cell_type":{"8b5abf87":"code","f38a8f7d":"code","8eb65a94":"code","307128fc":"code","a0d3b42b":"code","d29ad635":"code","447b0d8c":"code","d21211c2":"code","24ad6204":"code","3ff9a769":"code","7bef29f6":"code","5049946d":"markdown","d3f7eecb":"markdown","8c854166":"markdown","9b4c6a44":"markdown","f191943e":"markdown","4eb40b71":"markdown","f7fec8bd":"markdown"},"source":{"8b5abf87":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n# Load data in the data frame\ndf_breastCancer = pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')","f38a8f7d":"# analyse the shape of the breastcancer dataframe\nprint('shape of breast cancer.csv:', df_breastCancer.shape)","8eb65a94":"df_breastCancer.head(3)","307128fc":"# looking for possible target values as boolean or object data type\ndf_breastCancer.dtypes","a0d3b42b":"# transform the diagnosis Character into binary value for array calculation\n# M = Malignant ,B = benign \ndf_breastCancer.diagnosis[df_breastCancer.diagnosis == 'M'] = 1\ndf_breastCancer.diagnosis[df_breastCancer.diagnosis == 'B'] = 0\n\n# switch data type to bool for clear training target value  \ndf_breastCancer.diagnosis = df_breastCancer.diagnosis.astype('bool')\n\n# Check transform result\nprint(df_breastCancer.diagnosis)","d29ad635":"# build Features X and target Variable y \nX = df_breastCancer[['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'area_mean', 'smoothness_mean',\n       'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']]\ny = df_breastCancer['diagnosis']\nX.shape, y.shape","447b0d8c":"# Split in train and train set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2 , random_state=11)\n\n#test split by array shape\nX_train.shape, X_test.shape, y_train.shape, y_test.shape \n# print(y_train)","d21211c2":"from sklearn.decomposition import PCA\n\n# instantiate the class PCA with a variance of 90% from the original data\npca = PCA(n_components=0.9)\n\n# learning the model und transforming the over training data\nX_train_fact = pca.fit_transform(X_train)\nX_test_fact = pca.transform(X_test)\n\n# get the Result in the exp_var as numpy array\nexp_var = pca.explained_variance_ratio_\nsum_exp_var = sum(exp_var)\n\nprint('explained variance by factor:', exp_var)\nprint('sum explained variance all factors:{:.3f}' .format(sum_exp_var))","24ad6204":"# instantiation and training of the data model\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)","3ff9a769":"# Evaluation of the data model woth confusion matrix\nfrom sklearn.metrics import accuracy_score, confusion_matrix\ny_test_pred = model.predict(X_test)\naccuracy = accuracy_score(y_test, y_test_pred)\nmatrix = confusion_matrix(y_test, y_test_pred)\nprint('confusion matrix: ', '\\n',matrix)\nprint('accuracy: ', accuracy)","7bef29f6":"X_pred = [[6., 3., 4., 1., 5., 2., 3., 9., 1.]]\n\n# # retrain the model with higher probability\ny_test_pred_proba = model.predict_proba(X_test)\n\n\n\n# Limit the estimation to 99%\ny_test_pred_proba99 = [0 if prob[0] > .99 else 1 for prob in y_test_pred_proba]\n\naccuracy99 = accuracy_score(y_test, y_test_pred_proba99)\nmatrix99 = confusion_matrix(y_test, y_test_pred_proba99)\nprint('confusion matrix: ', '\\n',matrix99)\nprint('accuracy: ', accuracy99)","5049946d":"The error diagnosis is excluded the accuracy decreases over 50%. THis has an high impact on the diagnosis but a big gain for the reliability.\n","d3f7eecb":"### Principle Component Analysis\nPrinciple Componentn Analysis (PCA) can be used to reduce the number of features by identify the relevant ones and to find and understand dependencies between features. In this case, the amount of features is manageable but i would like to see if there are dependencies between some features and how big they are.","8c854166":"## Exploratory Analysis","9b4c6a44":"# Breast Cancer Classifier with Logistic Regression \nThis Notebook is about the training a breast cancer Classifier with  Logistic-Regression.\n\nLogistic regression is used to classify instances based on the values of their predictor variables. The output is the probability that an input data item belongs to a certain class (compare the support vector machine, where the output is the single class that best fits the input data item).","f191943e":"### Conlusion and increasing of reliabilty\n\nThe accuracy of the trained Logistic Regression Model is 89%. The Confusion matrix shows  that 73 cases are correct classified with 3 errors. 29 diagnosis are cancer positiv, 9 cancer diagnosis are incorrect. \n\nTo exclude the 3 missed Cancer diagnosis, to eliminitate the risk of unseen cancer diagnossis, the prediction treshold will be incereased to 99%.  \n","4eb40b71":"## Load and Perapare Datasets\nImport of standard libraries and basic funtions to include data sets in the notebook.","f7fec8bd":"## Logistic Regression with Scikit-Learn\nAfter the Exploratory Analysis, the Target Value 'diagnosis' is identified. Import of the Wisconsin-Breast-Cancer Data set. Including the Features of cell attributes for the train set."}}