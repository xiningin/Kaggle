{"cell_type":{"63dab428":"code","d90b2e78":"code","eda72b66":"code","80c6830e":"code","b47e8afb":"code","f0fc216d":"code","4d392343":"code","aa636877":"code","74d8c53c":"code","fc1d98ea":"code","576b08a1":"code","8f455ff0":"code","3f757518":"code","a9d6b0b3":"code","426bb945":"markdown","53a460ba":"markdown","b0175f59":"markdown","864ae9b2":"markdown"},"source":{"63dab428":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d90b2e78":"import pandas as pd\nimport numpy as np\nfrom plotly.offline import iplot, plot, init_notebook_mode\ninit_notebook_mode(connected=True)\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nimport random\nfrom calendar import month_abbr\n\nfrom statsmodels.tsa import stattools\n\nimport seaborn as sns\nsns.set()\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix\n\n# Packages required for data visualization and modelling","eda72b66":"# Set your own project id here\nPROJECT_ID = 'your-google-cloud-project'\nfrom google.cloud import bigquery\nbigquery_client = bigquery.Client(project=PROJECT_ID)\nfrom google.cloud import storage\nstorage_client = storage.Client(project=PROJECT_ID)","80c6830e":"df = pd.read_csv(\"\/kaggle\/input\/milk-price\/daily_milk_rate.csv\")\ndf.info()\ndf.dropna(0, how='any', inplace = True)\nprint(df.info())\n\ndf['date'] = pd.to_datetime(df['Date'], dayfirst=True)\ndf.drop(['Date'], axis=1, inplace=True)\ndf.set_index(['date'], drop=True, inplace=True)\ndf\n# thus the data has 5 day a week resolution.","b47e8afb":"cities = df['Centre_Name'].value_counts()\nprint('\\n',cities.keys)\n\ncommodities = df['Commodity_Name'].value_counts()\nprint('\\n',commodities.keys)\n\n# Sorting in descending fashion according to number of available data points.\n# Since data points are of \"daily or so\" resolution thus It gives us a hint to what should be the resolution of plots to capture the pattern.","f0fc216d":"# since there are many cities So we decide to visualize data just for DELHI\n# And later on compare with other cities later on in the code.\ncity = 'DELHI'\ndf.loc[df['Centre_Name']==city]\n\n# why to carry Commodity_Name since right now it is Redundant column due to the fact that the dataset only comprices of Milk prices.\ndf.drop(['Commodity_Name'], axis=1, inplace=True)\n\n# segregate data of a particular city Eg: Delhi\nCity_df = df.loc[df['Centre_Name']== city]\n\n# and now we are dropping the Centre Name as well, since that too becomes a redundant column now.\n# sO DROP IT LIKE ITS HOT \ud83e\ude94\nCity_df.drop(['Centre_Name'], axis=1, inplace=True )\nCity_df = pd.Series(City_df['Price'])\nprint(City_df.head(15))\n# the fashion in which date time is printed in the output is YYYY-MM-DD. Because of a certain reason.\n\nyears = City_df.index.year.value_counts().index\n# This line is the James bond \ud83d\udd2b of our code. Learning from mistakes.\n\nCity_df.index.year.value_counts()\n# just to make sure we're on the right track!! This gives us a clue to the TS bias towards Year.\n# Though it looks biased but let's move on.","4d392343":"# Line and scatter plot both \nfig = go.Figure()\n\n# Add traces\nfig.add_trace(go.Scatter(x = City_df.index, y = City_df.values,\n                         mode = 'markers',\n                         name = 'markers'))\n\nfig.add_trace(go.Scatter(x = City_df.index, y = City_df.values,\n                         mode = 'lines+markers',\n                         name = 'lines+markers'))\n\nfig.add_trace(go.Scatter(x = City_df.index, y = City_df.values,\n                         mode = 'lines',\n                         name = 'lines'))\n\nfig.update_layout(title = \"Price v\/s Date\",\n                  xaxis_title = \"Date_Month_Year\",\n                  yaxis_title = \"Price (\u20b9)\",\n                  font = dict(\n                          family = \"Courier New, monospace\",\n                          size = 18,\n                          color = \"#7f7f7f\"\n                  )\n                 )\nfig.show()","aa636877":"# Color map in scatter plot to show gradient\nfig = go.Figure(data = go.Scatter(x = City_df.index, y = City_df.values,\n                                 mode = 'markers',\n                                 marker = dict(\n                                     size = 10,\n                                     color = City_df.values,\n                                     colorscale = 'Viridis',\n                                 showscale = True\n                                 )\n                            )\n               )\n\nfig.update_layout(title = \"Cmap Price v\/s Date\",\n                  xaxis_title = \"Date_Month_Year\",\n                  yaxis_title = \"Prices (\u20b9)\",\n                  font = dict(\n                          family = \"Courier New, monospace\",\n                          size = 18,\n                          color = \"#7f7f7f\"\n                  )\n                 )\n\nfig.show()","74d8c53c":"# Histograms\n\nfig = go.Figure()\nfig.add_trace(go.Histogram(histfunc = \"avg\", x = City_df.index,\n                           y = City_df.values,\n                          name = \"avg\"))\n\nfig.update_layout(title = \"Avg.Price v\/s Date_span\",\n                  xaxis_title = \"Date_Month_Year\",\n                  yaxis_title = \"Prices (\u20b9)\",\n                  font = dict(\n                          family = \"Courier New, monospace\",\n                          size = 18,\n                          color = \"#7f7f7f\"\n                  )\n                 )\nfig.show()\n\n\n''' Here if is getting clumsy.\nBut on a side note Histograms do not give us a meaningful insight on yearly resolution and above all the fact that\nmilk prices are more about change than absolute values so to prove it we, need to get a distribution plot.'''","fc1d98ea":"''' A box plot is a statistical representation of numerical data through their quartiles.\nThe ends of the box represent the lower and upper quartiles,\nwhile the median (second quartile) is marked by a line inside the box.'''\n\nfig = go.Figure()\nfig.add_trace(go.Box(x = City_df.index.year, y = City_df.values,\n             boxmean = 'sd',\n             name = 'Mean & SD',\n             marker_color = 'royalblue'))\n\nfig.update_layout(\n    xaxis=dict(showgrid=False, zeroline=False, showticklabels=True),\n    yaxis=dict(zeroline=False, gridcolor='white'),\n    paper_bgcolor='rgb(233,233,233)',\n    plot_bgcolor='rgb(233,233,233)',\n    title_text=\"Box Plot of Yearly Prices\"\n)\n\nfig.show()\n\n# Now you could see why. Why can't yearly resolution give us a meaningful insight of the data just have a look at the value of sigma (SD)","576b08a1":"\n\nCity_df_after_2010 = City_df.loc[City_df.index.year >= 2010]\nCity_df_after_2010.head(10)\n\nfig = go.Figure()\nfig.add_trace(go.Box(x = City_df_after_2010.index.year, y = City_df_after_2010.values,\n             boxmean = 'sd',\n             name = 'Mean & SD',\n             marker_color = 'royalblue'))\n\nfig.update_layout(\n    xaxis=dict(showgrid=False, zeroline=False, showticklabels=True),\n    yaxis=dict(zeroline=False, gridcolor='white'),\n    paper_bgcolor='rgb(233,233,233)',\n    plot_bgcolor='rgb(233,233,233)',\n    title_text=\"Box Plot of Yearly Prices\"\n)\n\nfig.show()\n\n\n# Now we'll visualize data in a different sense. In terms of a batch of days or maybe weeks.\n# But before that we Could have an exploded view of the boxplot of trimmed dataset.\n# Box for 2015 is flat due to the fact that it has only 78 points and all of them have a single value that is \u20b938\/lit.\n","8f455ff0":"# Random set visualization on daily resolution keep N <= 60\n\nN =[10,20,30,40,50,60]\nfor N_points in N:\n    random_date_time = random.randint(0,len(City_df_after_2010.index)-N_points)\n    input(f\"\\n\\nShowing graph of {N_points} points\")\n    print(f\"randomly chosen date and time is {City_df_after_2010.index[random_date_time]}\")\n\n    # actually what you could see as Hour in th output is something that pops out by default.\n    # this does not imply that the point corresponds to 12 in the midnight since the data has day's resolution so we do not have to worry about the timestamp\n\n    random_day_set = []\n    for day in range(N_points):\n      random_day_set.append(City_df_after_2010.index[random_date_time + day])\n\n    # Which plot could give us a deep and accurate insight to the pattern if it exists?\n    # answer to this question is quite debateable but let us go with line plots.\n    # let us give it a hit. For  N = 10,20,30,40,50 and 60 if we do not find any meaningful insight then it would imply that pattern does not have a daily resolution.\n    # Once we detect a pattern then we could go about quantifying it using Auto-correlation function.\n    # But the essential question remains the same and that is when does prices start deviating from their lagging values and in what pattern if any.\n    \n    #print(random_day_set,'\\n')\n    #City_df_after_2010.loc[random_day_set]\n    #print (City_df_after_2010,'\\n')\n    fig = go.Figure()\n    # Add Traces\n    fig.add_trace(go.Scatter(x=City_df_after_2010.loc[random_day_set].index, y=City_df_after_2010.loc[random_day_set].values,\n                             mode='lines+markers',\n                             name='lines+markers'))\n    fig.show()\n\n# Click on output screen to enlarge. and this is what has been happening most of the times that with N=60 prices fluctuate. ","3f757518":"# With this what we could conclude is that the data is not varying over a resolution of days. So let us check once again for resolution of months\nN =[3,4,5,6] # in months roughly around 20 entries each month\nfor N_points in N:\n    random_date_time = random.randint(0,len(City_df_after_2010.index)-N_points*20)\n    input(f\"\\n\\nShowing graph of {N_points} points\")\n    print(f\"randomly chosen date and time is {City_df_after_2010.index[random_date_time]}\")\n\n    # actually what you could see as Hour in th output is something that pops out by default.\n    # this does not imply that the point corresponds to 12 in the midnight since the data has day's resolution so we do not have to worry about the timestamp\n\n    random_day_set = []\n    for day in range(N_points*20):\n      random_day_set.append(City_df_after_2010.index[random_date_time + day])\n\n    # Which plot could give us a deep and accurate insight to the pattern if it exists?\n    # answer to this question is quite debateable but let us go with line plots.\n    # let us give it a hit. For  N = 10,20,30,40,50 and 60 if we do not find any meaningful insight then it would imply that pattern does not have a daily resolution.\n    # Once we detect a pattern then we could go about quantifying it using Auto-correlation function.\n    # But the essential question remains the same and that is when does prices start deviating from their lagging values and in what pattern if any.\n    \n    #print(random_day_set,'\\n')\n    #City_df_after_2010.loc[random_day_set]\n    #print (City_df_after_2010,'\\n')\n    fig = go.Figure()\n    # Add Traces\n    fig.add_trace(go.Scatter(x=City_df_after_2010.loc[random_day_set].index, y=City_df_after_2010.loc[random_day_set].values,\n                             mode='lines+markers',\n                             name='lines+markers'))\n    fig.show()\n    \n","a9d6b0b3":"# With this what we could conclude is that the data is varying over a resolution of months not days. So let us check once again\n# Thus now with logical reasoning and quantitative plots we conclude that having a violon plot of monthly resolution will serve the purpose.\n# Half the work is done.\nlist_years = [City_df_after_2010.index.year.values]\nlist_years = np.unique(np.array(list_years))\n\nlist_month = [City_df_after_2010.index.month.values]\nlist_month = np.unique(np.array(list_month))\n\n\n\nfor year in list_years:\n    fig = go.Figure()\n    for month in list_month:\n        y = City_df_after_2010.loc[City_df_after_2010.index.month == month]\n        y = y.loc[y.index.year == year]\n        print(y)\n        x = month_abbr[month]\n        print(x)\n        type(y)\n\n# pERRRRR.... fectO\n        ","426bb945":"'''MANAGING A DATASET WITH SUCH ENORMOUS NUMBER OF POINTS CAN LEAD TO A DECEPTIVE INTERPRETATION\n To Demonstrate this fact let us look at The following three plots\n namely\n 1.) Scatter and Line plot of Prices v\/s date\n 2.) Scatter plot with Cmap of Prices v\/s date\n 3.) Histogram of Avg.Price v\/s Date_span\n \n \"APPEARANCES CAN BE DECEPTIVE\"\n '''","53a460ba":"'''\nBut before moving ahead we must trim the values before 2010. That's the secret of magic\nRecipie and revisit box plot.\n'''","b0175f59":"**DUE FROM HERE**\n\n\n'''Combined statistical representations with Distplots \"Distribution plots\"\nThe same plot will be used for comparing the prices in different parts\nof our nation.\nBut for now let us look at data from the City that is chosen on Histogram,\nDistribution and Rug plots of the data on a monthly resolution.\nNamely Basic Distplots will reveal whatever we want to know'''\n","864ae9b2":"''' Now We'll tell you why?\n Why can't these plots capture the essence of milk prices even when they look to have some significant pattern on yearly basis?\n The significant pattern seems to be of monotonically increasing.\n But is that so?\n Let us answer these questions one by one.\n '''"}}