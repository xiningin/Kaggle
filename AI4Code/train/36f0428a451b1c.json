{"cell_type":{"ab34a587":"code","da8460a4":"code","55cabfb9":"code","47ff42d9":"code","26518783":"code","e142edd9":"code","87c0166f":"code","6fae62fe":"code","5433e076":"code","39ac5ec3":"code","7afedfe2":"code","b4649e53":"code","a36f96de":"code","87a5680d":"code","86d952a9":"code","2ce6f4b5":"code","e3206c3f":"code","b1dd8168":"code","9bd321c1":"code","6070806f":"code","795de132":"code","2fd64f59":"code","9686d5de":"code","e03c2b69":"code","6aecbaf1":"code","2a40c911":"code","17cf5b44":"code","53ca5efd":"code","93d8dd17":"code","6fa89672":"code","b6a77d82":"code","728e30cc":"code","f90154d4":"code","e0362691":"code","08639cf6":"code","0cb388b1":"code","77da217a":"code","993a272e":"code","d983ed2b":"code","4f7f9065":"code","8acdc140":"code","8aa5eac0":"code","c6b7850d":"code","93b4de54":"code","2c0b3afb":"code","c4caa5b2":"code","01c441f4":"code","b011b3b6":"code","cbd57e8e":"code","a4604912":"code","fabd5ba8":"code","01bd838e":"code","343f938e":"code","82e6c88c":"code","a65088b1":"code","a5dc482d":"code","b153201b":"code","efe832dd":"code","53cb48e3":"code","9e77377b":"code","9e452581":"code","01396db1":"code","b4052056":"code","2de9337c":"code","e3139d42":"code","9b2fb723":"code","287a532f":"code","f8f2c5fc":"code","625d3608":"code","ee979e9c":"code","1193b462":"code","64e5cc9e":"code","1d5d82be":"code","c3fcc3c5":"code","70c33713":"code","e017f015":"code","2b33606c":"markdown","f15cf2c9":"markdown","1a196df0":"markdown","26b89357":"markdown","bc688ebb":"markdown","3826be13":"markdown","55362e3b":"markdown","e3f3b34f":"markdown","a1f7fed2":"markdown","4e03a6a4":"markdown","c049ca83":"markdown","1ae9b924":"markdown","caa9a112":"markdown","9ce843e6":"markdown","182157a5":"markdown","4b916e8f":"markdown","b7295c91":"markdown","65e61d63":"markdown","56cbe00c":"markdown","b0927d9e":"markdown","0d357f43":"markdown","2d7946b0":"markdown","5ac3bdc9":"markdown","100fe03a":"markdown","d05502da":"markdown","6f4be385":"markdown","8b115809":"markdown","7cdfb4d2":"markdown","62b8d19a":"markdown","4a538be7":"markdown"},"source":{"ab34a587":"# Suppressing Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","da8460a4":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","55cabfb9":"# Importing Pandas and NumPy\nimport pandas as pd, numpy as np, seaborn as sns,matplotlib.pyplot as plt","47ff42d9":"pd.set_option('display.max_columns', None)","26518783":"# Importing all datasets\nchurn_data = pd.read_csv(\"\/kaggle\/input\/telecom-churn-data-sets\/churn_data.csv\")\nchurn_data.head()","e142edd9":"customer_data = pd.read_csv(\"\/kaggle\/input\/telecom-churn-data-sets\/customer_data.csv\")\ncustomer_data.head()","87c0166f":"internet_data = pd.read_csv(\"\/kaggle\/input\/telecom-churn-data-sets\/internet_data.csv\")\ninternet_data.head()","6fae62fe":"# Merging on 'customerID'\ndf_1 = pd.merge(churn_data, customer_data, how='inner', on='customerID')","5433e076":"# Final dataframe with all predictor variables\ntelecom = pd.merge(df_1, internet_data, how='inner', on='customerID')","39ac5ec3":"# Let's see the head of our master dataset\ntelecom.head()","7afedfe2":"# Let's check the dimensions of the dataframe\ntelecom.shape","b4649e53":"# let's look at the statistical aspects of the dataframe\ntelecom.describe()","a36f96de":"# Let's see the type of each column\ntelecom.info()","87a5680d":"#The varaible was imported as a string we need to convert it to float\n# telecom['TotalCharges'] = telecom['TotalCharges'].astype(float) \ntelecom.TotalCharges = pd.to_numeric(telecom.TotalCharges, errors='coerce')","86d952a9":"telecom.info()","2ce6f4b5":"\nplt.figure(figsize=(20,40))\nplt.subplot(10,2,1)\nax = sns.distplot(telecom['tenure'], hist=True, kde=False, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})\nax.set_ylabel('# of Customers')\nax.set_xlabel('Tenure (months)')\nplt.subplot(10,2,2)\nax = sns.countplot(x='PhoneService', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,3)\nax =sns.countplot(x='Contract', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,3)\nax =sns.countplot(x='Contract', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,4)\nax =sns.countplot(x='PaperlessBilling', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,5)\nax =sns.countplot(x='PaymentMethod', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,6)\nax =sns.countplot(x='Churn', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,7)\nax =sns.countplot(x='gender', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,8)\nax =sns.countplot(x='SeniorCitizen', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,9)\nax =sns.countplot(x='Partner', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,10)\nax =sns.countplot(x='Dependents', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,11)\nax =sns.countplot(x='MultipleLines', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,12)\nax =sns.countplot(x='InternetService', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,13)\nax =sns.countplot(x='OnlineSecurity', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,14)\nax =sns.countplot(x='OnlineBackup', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,15)\nax =sns.countplot(x='DeviceProtection', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,16)\nax =sns.countplot(x='TechSupport', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,17)\nax =sns.countplot(x='StreamingTV', data=telecom)\nax.set_ylabel('# of Customers')\n\nplt.subplot(10,2,18)\nax =sns.countplot(x='StreamingMovies', data=telecom)\nax.set_ylabel('# of Customers')\nplt.subplot(10,2,19)\nax = sns.distplot(telecom['MonthlyCharges'], hist=True, kde=False, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})\nax.set_ylabel('# of Customers')\nax.set_xlabel('MonthlyCharges')\nplt.subplot(10,2,20)\nax = sns.distplot(telecom['TotalCharges'], hist=True, kde=False, \n             bins=int(180\/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 4})\nax.set_ylabel('# of Customers')\nax.set_xlabel('TotalCharges');","e3206c3f":"sns.pairplot(telecom)\nplt.show()","b1dd8168":"plt.figure(figsize=(25, 10))\nplt.subplot(1,3,1)\nsns.boxplot(x = 'tenure', y = 'Churn', data=telecom)\nplt.subplot(1,3,2)\nsns.boxplot(x = 'MonthlyCharges', y = 'Churn', data=telecom)\nplt.subplot(1,3,3)\nsns.boxplot(x = 'TotalCharges', y = 'Churn', data=telecom)\nplt.show()","9bd321c1":"# List of variables to map\n\nvarlist =  ['PhoneService', 'PaperlessBilling', 'Churn', 'Partner', 'Dependents']\n\n# Defining the map function\ndef binary_map(x):\n    return x.map({'Yes': 1, \"No\": 0})\n\n# Applying the function to the housing list\ntelecom[varlist] = telecom[varlist].apply(binary_map)","6070806f":"telecom.head()","795de132":"# Creating a dummy variable for some of the categorical variables and dropping the first one.\ndummy1 = pd.get_dummies(telecom[['Contract', 'PaymentMethod', 'gender', 'InternetService']], drop_first=True)\n\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom, dummy1], axis=1)","2fd64f59":"telecom.head()","9686d5de":"# Creating dummy variables for the remaining categorical variables and dropping the level with big names.\n\n# Creating dummy variables for the variable 'MultipleLines'\nml = pd.get_dummies(telecom['MultipleLines'], prefix='MultipleLines')\n# Dropping MultipleLines_No phone service column\nml1 = ml.drop(['MultipleLines_No phone service'], 1)\n#Adding the results to the master dataframe\ntelecom = pd.concat([telecom,ml1], axis=1)\n\n# Creating dummy variables for the variable 'OnlineSecurity'.\nos = pd.get_dummies(telecom['OnlineSecurity'], prefix='OnlineSecurity')\nos1 = os.drop(['OnlineSecurity_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,os1], axis=1)\n\n# Creating dummy variables for the variable 'OnlineBackup'.\nob = pd.get_dummies(telecom['OnlineBackup'], prefix='OnlineBackup')\nob1 = ob.drop(['OnlineBackup_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,ob1], axis=1)\n\n# Creating dummy variables for the variable 'DeviceProtection'. \ndp = pd.get_dummies(telecom['DeviceProtection'], prefix='DeviceProtection')\ndp1 = dp.drop(['DeviceProtection_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,dp1], axis=1)\n\n# Creating dummy variables for the variable 'TechSupport'. \nts = pd.get_dummies(telecom['TechSupport'], prefix='TechSupport')\nts1 = ts.drop(['TechSupport_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,ts1], axis=1)\n\n# Creating dummy variables for the variable 'StreamingTV'.\nst =pd.get_dummies(telecom['StreamingTV'], prefix='StreamingTV')\nst1 = st.drop(['StreamingTV_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,st1], axis=1)\n\n# Creating dummy variables for the variable 'StreamingMovies'. \nsm = pd.get_dummies(telecom['StreamingMovies'], prefix='StreamingMovies')\nsm1 = sm.drop(['StreamingMovies_No internet service'], 1)\n# Adding the results to the master dataframe\ntelecom = pd.concat([telecom,sm1], axis=1)","e03c2b69":"telecom.head()","6aecbaf1":"# We have created dummies for the below variables, so we can drop them\ntelecom = telecom.drop(['Contract','PaymentMethod','gender','MultipleLines','InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n       'TechSupport', 'StreamingTV', 'StreamingMovies'], 1)","2a40c911":"# Checking for outliers in the continuous variables\nnum_telecom = telecom[['tenure','MonthlyCharges','SeniorCitizen','TotalCharges']]","17cf5b44":"# Checking outliers at 25%, 50%, 75%, 90%, 95% and 99%\nnum_telecom.describe(percentiles=[.25, .5, .75, .90, .95, .99])","53ca5efd":"# Adding up the missing values (column-wise)\ntelecom.isnull().sum()","93d8dd17":"print('No. of Null Records for TotalCharges:',telecom.TotalCharges.isnull().sum())","6fa89672":"print('No. of Records for TotalCharges:',len(telecom))","b6a77d82":"print('No. of non Records for TotalCharges:',len(telecom)-telecom.TotalCharges.isnull().sum())","728e30cc":"# Checking the percentage of missing values\nround(100*(telecom.isnull().sum()\/len(telecom.index)), 2)","f90154d4":"telecom = telecom.dropna()\ntelecom = telecom.reset_index(drop=True)\n\n","e0362691":"# Checking percentage of missing values after removing the missing values\nround(100*(telecom.isnull().sum()\/len(telecom.index)), 2)","08639cf6":"from sklearn.model_selection import train_test_split","0cb388b1":"# Putting feature variable to X\nX = telecom.drop(['Churn','customerID'], axis=1)\n\nX.head()","77da217a":"# Putting response variable to y\ny = telecom['Churn']\n\ny.head()","993a272e":"# Splitting the data into train and test\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)","d983ed2b":"from sklearn.preprocessing import StandardScaler","4f7f9065":"scaler = StandardScaler()\n\nX_train[['tenure','MonthlyCharges','TotalCharges']] = scaler.fit_transform(X_train[['tenure','MonthlyCharges','TotalCharges']])\n\nX_train.head()","8acdc140":"X_test[['tenure','MonthlyCharges','TotalCharges']] = scaler.transform(X_test[['tenure','MonthlyCharges','TotalCharges']])\n\nX_test.head()","8aa5eac0":"### Checking the Churn Rate\nchurn = (sum(telecom['Churn'])\/len(telecom['Churn'].index))*100\nchurn","c6b7850d":"# Importing matplotlib and seaborn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","93b4de54":"# Let's see the correlation matrix \nplt.figure(figsize = (25,25))        # Size of the figure\nsns.heatmap(telecom.corr(),annot = True,cmap=\"tab20c\")\nplt.show()","2c0b3afb":"plt.figure(figsize=(10,8))\ntelecom.corr()['Churn'].sort_values(ascending = False).plot(kind='bar');","c4caa5b2":"X_test = X_test.drop(['MultipleLines_No','OnlineSecurity_No','OnlineBackup_No','DeviceProtection_No','TechSupport_No',\n                       'StreamingTV_No','StreamingMovies_No'], 1)\nX_train = X_train.drop(['MultipleLines_No','OnlineSecurity_No','OnlineBackup_No','DeviceProtection_No','TechSupport_No',\n                         'StreamingTV_No','StreamingMovies_No'], 1)","01c441f4":"plt.figure(figsize = (25,25))\nsns.heatmap(X_train.corr(),annot = True,cmap=\"tab20c\")\nplt.show()","b011b3b6":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nmodel = GaussianNB()","cbd57e8e":"# fit the model with the training data\nmodel.fit(X_train,y_train)","a4604912":"# predict the target on the train dataset\npredict_train = model.predict(X_train)\npredict_train","fabd5ba8":"trainaccuracy = accuracy_score(y_train,predict_train)\nprint('accuracy_score on train dataset : ', trainaccuracy)","01bd838e":"# Check for the VIF values of the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif.tail()","343f938e":"features_to_remove = vif.loc[vif['VIF'] >= 4.99,'Features'].values\nfeatures_to_remove = list(features_to_remove)\nprint(features_to_remove)","82e6c88c":"X_train = X_train.drop(columns=features_to_remove, axis = 1)\nX_train.head()","a65088b1":"X_test = X_test.drop(columns=features_to_remove, axis = 1)\nX_test.head()","a5dc482d":"# fit the model with the training data\nmodel.fit(X_train,y_train)","b153201b":"# predict the target on the train dataset\npredict_train = model.predict(X_train)\npredict_train","efe832dd":"trainaccuracy = accuracy_score(y_train,predict_train)\nprint('accuracy_score on train dataset : ', trainaccuracy)","53cb48e3":"# Check for the VIF values of the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train.columns\nvif['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","9e77377b":"from sklearn import metrics\n# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train, predict_train )\nprint(confusion)\n","9e452581":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","01396db1":"# Let's see the sensitivity of our model\ntrainsensitivity= TP \/ float(TP+FN)\ntrainsensitivity","b4052056":"# Let us calculate specificity\ntrainspecificity= TN \/ float(TN+FP)\ntrainspecificity","2de9337c":"# Calculate false postive rate - predicting churn when customer does not have churned\nprint(FP\/ float(TN+FP))","e3139d42":"# Positive predictive value \nprint (TP \/ float(TP+FP))","9b2fb723":"def draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return None","287a532f":"draw_roc(y_train,predict_train)","f8f2c5fc":"#Looking at the confusion matrix again","625d3608":"from sklearn.metrics import precision_score, recall_score\nprecision_score(y_train,predict_train)","ee979e9c":"recall_score(y_train,predict_train)","1193b462":"# predict the target on the test dataset\npredict_test = model.predict(X_test)\nprint('Target on test data\\n\\n',predict_test)","64e5cc9e":"confusion2 = metrics.confusion_matrix(y_test, predict_test )\nprint(confusion2)","1d5d82be":"# Let's check the overall accuracy.\ntestaccuracy= accuracy_score(y_test,predict_test)\ntestaccuracy","c3fcc3c5":"# Let's see the sensitivity of our lmodel\ntestsensitivity=TP \/ float(TP+FN)\ntestsensitivity","70c33713":"# Let us calculate specificity\ntestspecificity= TN \/ float(TN+FP)\ntestspecificity","e017f015":"# Let us compare the values obtained for Train & Test:\nprint(\"Train Data Accuracy    :{} %\".format(round((trainaccuracy*100),2)))\nprint(\"Train Data Sensitivity :{} %\".format(round((trainsensitivity*100),2)))\nprint(\"Train Data Specificity :{} %\".format(round((trainspecificity*100),2)))\nprint(\"Test Data Accuracy     :{} %\".format(round((testaccuracy*100),2)))\nprint(\"Test Data Sensitivity  :{} %\".format(round((testsensitivity*100),2)))\nprint(\"Test Data Specificity  :{} %\".format(round((testspecificity*100),2)))","2b33606c":"#### Checking the Correlation Matrix","f15cf2c9":"### Step 7: Model Building\nLet's start by splitting our data into a training set and a test set.","1a196df0":"From the distribution shown above, you can see that there no outliers in your data. The numbers are gradually increasing.","26b89357":"It means that 11 * 100\/7043 = 0.1561834%, best is to remove these observations from the analysis","bc688ebb":"# EDA","3826be13":"We have almost 27% churn rate","55362e3b":"After dropping highly correlated variables now let's check the correlation matrix again.","e3f3b34f":"# Naive Bayes","a1f7fed2":"## Telecom Churn Case Study\nWith 21 predictor variables we need to predict whether a particular customer will switch to another telecom provider or not. In telecom terminology, this is referred to as churning and not churning, respectively.","4e03a6a4":"### Step 4: Test-Train Split","c049ca83":"### Step 1: Importing and Merging Data","1ae9b924":"It is a classification technique based on Bayes\u2019 theorem with an assumption of independence between predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature.","caa9a112":"# VIF","9ce843e6":"# Plotting the ROC Curve","182157a5":"#### Checking for Missing Values and Inputing Them","4b916e8f":"Now you can see that you have all variables as numeric.","b7295c91":"Now we don't have any missing values","65e61d63":"#### Checking for Outliers","56cbe00c":"## Precision and Recall","b0927d9e":"### Step 2: Inspecting the Dataframe","0d357f43":"#### Dropping highly correlated dummy variables","2d7946b0":"### Step 11: Making predictions on the test set","5ac3bdc9":"# VIF","100fe03a":"### Step 6: Looking at Correlations","d05502da":"#### Converting some binary variables (Yes\/No) to 0\/1","6f4be385":"#### For categorical variables with multiple levels, create dummy features (one-hot encoded)","8b115809":"### Step 5: Feature Scaling","7cdfb4d2":"#### Dropping the repeated variables","62b8d19a":"# Final Observation:","4a538be7":"#### Combining all data files into one consolidated dataframe"}}