{"cell_type":{"435be44a":"code","746f6aad":"code","eae499d9":"code","a28bb174":"code","3b422221":"code","5133a52f":"code","7dda77fc":"code","1c19d831":"code","1b61a1f6":"code","80f1551d":"code","290fa60e":"code","f60c125e":"markdown","819089d9":"markdown","cdb2883c":"markdown","cd89a104":"markdown","63e31801":"markdown","25221b00":"markdown","22d388bf":"markdown","eb203ab9":"markdown","75c7be98":"markdown","8932c4fa":"markdown"},"source":{"435be44a":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom wordcloud import WordCloud\nimport math","746f6aad":"dataset = pd.read_csv(\"\/kaggle\/input\/reddit-wallstreetsbets-posts\/reddit_wsb.csv\")","eae499d9":"title_raw = []\nscore = []\n\nfor i in range(len(dataset)):\n    title_raw.append(dataset[\"title\"][i])\n    score.append(int(dataset[\"score\"][i]))","a28bb174":"tokenizer = tf.keras.preprocessing.text.Tokenizer()\ntokenizer.fit_on_texts(title_raw)\ntitle = tokenizer.texts_to_sequences(title_raw)\n\nprint(len(tokenizer.word_index))","3b422221":"scores = {\"0\":0, \"1-10\":0, \"11-100\":0, \"101-1000\":0, \"1001-10000\":0, \"10001-100000\":0, \"100001->\":0}\n\nfor i in score:\n    if i < 1:\n        scores[\"0\"] += 1\n    elif i < 11:\n        scores[\"1-10\"] += 1\n    elif i < 101:\n        scores[\"11-100\"] += 1\n    elif i < 1001:\n        scores[\"101-1000\"] += 1\n    elif i < 10001:\n        scores[\"1001-10000\"] += 1\n    elif i < 100001:\n        scores[\"10001-100000\"] += 1\n    else:\n        scores[\"100001->\"] += 1\n\nfig = plt.figure(figsize=(9, 3))\nax = fig.add_axes([0,0,1,1])\nscore_label = [\"0\", \"1-10\", \"11-100\", \"101-1000\", \"1001-10000\", \"10001-100000\", \"100001->\"]\nvalue = [scores[\"0\"], scores[\"1-10\"], scores[\"11-100\"], scores[\"101-1000\"], scores[\"1001-10000\"], scores[\"10001-100000\"], scores[\"100001->\"]]\nax.bar(score_label,value)\nplt.show()","5133a52f":"def plot_cloud(wordcloud):\n    plt.figure(figsize=(40, 30))\n    plt.imshow(wordcloud) \n    plt.axis(\"off\")","7dda77fc":"total_posts=0\n\nfor i in value:\n    total_posts+=i\n\noverallfreqs={}\n    \nfor word, index in tokenizer.word_index.items():\n      overallfreqs[word] = 0\n    \nfor i in title:\n    for j in i:\n        for word, index in tokenizer.word_index.items():\n          if j == index:\n            overallfreqs[word] += 1\n            break\n    \n    \nfor word, index in tokenizer.word_index.items():\n      overallfreqs[word] \/= total_posts\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(overallfreqs)\n\nplot_cloud(wordcloud)","1c19d831":"total_posts=scores[\"0\"] + scores[\"1-10\"]\n\nfreqto10 = {}\n\nfor word, index in tokenizer.word_index.items():\n      freqto10[word] = 0\n    \nfor i in range(len(title)):\n    if score[i] < 11:\n        for j in title[i]:\n            for word, index in tokenizer.word_index.items():\n              if j == index:\n                freqto10[word] += 1\n                break    \n    \nfor word, index in tokenizer.word_index.items():\n      freqto10[word] \/= total_posts\n        \nfor word, index in tokenizer.word_index.items():\n    if freqto10[word] != 0 and overallfreqs[word] != 0:\n        freqto10[word] \/= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(freqto10)\n\nplot_cloud(wordcloud)","1b61a1f6":"total_posts=scores[\"11-100\"] + scores[\"101-1000\"]\n\nfreq11to1000 = {}\n\nfor word, index in tokenizer.word_index.items():\n      freq11to1000[word] = 0\n    \nfor i in range(len(title)):\n    if score[i] > 10 or score[i] < 1001:\n        for j in title[i]:\n            for word, index in tokenizer.word_index.items():\n              if j == index:\n                freq11to1000[word] += 1\n                break    \n    \nfor word, index in tokenizer.word_index.items():\n      freq11to1000[word] \/= total_posts\n        \nfor word, index in tokenizer.word_index.items():\n    if freq11to1000[word] != 0 and overallfreqs[word] != 0:\n        freq11to1000[word] \/= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(freq11to1000)\n\nplot_cloud(wordcloud)","80f1551d":"total_posts=scores[\"1001-10000\"] + scores[\"10001-100000\"]\n\nfreq1001to100000 = {}\n\nfor word, index in tokenizer.word_index.items():\n      freq1001to100000[word] = 0\n    \nfor i in range(len(title)):\n    if score[i] > 1000 or score[i] < 100001:\n        for j in title[i]:\n            for word, index in tokenizer.word_index.items():\n              if j == index:\n                freq1001to100000[word] += 1\n                break    \n    \nfor word, index in tokenizer.word_index.items():\n      freq1001to100000[word] \/= total_posts\n        \nfor word, index in tokenizer.word_index.items():\n    if freq1001to100000[word] != 0 and overallfreqs[word] != 0:\n        freq1001to100000[word] \/= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(freq1001to100000)\n\nplot_cloud(wordcloud)","290fa60e":"total_posts=scores[\"100001->\"]\n\nfreqover100001 = {}\n\nfor word, index in tokenizer.word_index.items():\n      freqover100001[word] = 0\n    \nfor i in range(len(title)):\n    if score[i] > 100001:\n        for j in title[i]:\n            for word, index in tokenizer.word_index.items():\n              if j == index:\n                freqover100001[word] += 1\n                break    \n    \nfor word, index in tokenizer.word_index.items():\n      freqover100001[word] \/= total_posts\n        \nfor word, index in tokenizer.word_index.items():\n    if freqover100001[word] != 0 and overallfreqs[word] != 0:\n        freqover100001[word] \/= overallfreqs[word]\n        \nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set2').generate_from_frequencies(freqover100001)\n\nplot_cloud(wordcloud)","f60c125e":"# most relatively common words 1001 to 100000 upvotes","819089d9":"# imports","cdb2883c":"# preprocessing data","cd89a104":"# distribution of upvotes","63e31801":"# most common words overall","25221b00":"I will try to take on any suggestions... I hope you enjoyed. Please consider voting this notebook while you enjoy those chicken tendies","22d388bf":"# most relatively common words 100001 and up upvotes","eb203ab9":"I think this shows that some words are very common in post titles of various popularities. As well as this the words overall are very different from the distributions over the wider english language","75c7be98":"# most relatively common words 11 to 1000 upvotes","8932c4fa":"# most relatively common words up to 10 upvotes"}}