{"cell_type":{"0348b50d":"code","423fc10b":"code","2b7a5fa6":"code","4a2b2685":"code","fc55f8bc":"code","492df610":"code","c9a69259":"code","ff422a52":"code","fe428870":"code","f9f6792f":"markdown","6d72d0db":"markdown","3a895a96":"markdown","7d5206f6":"markdown","545f69f8":"markdown","c6b356ac":"markdown","afd591e9":"markdown","48f931f4":"markdown","0c564ac0":"markdown","f3c1e947":"markdown","ca7af0f8":"markdown"},"source":{"0348b50d":"import pandas as pd\ndataset=pd.read_csv('https:\/\/raw.githubusercontent.com\/marquisvictor\/Creating-a-Bias-Free-Testset\/master\/housing.csv')\nprint('The size of the Dataset is', len(dataset))\ndataset.head()","423fc10b":"simple_sample_1=dataset.sample(int(len(dataset)\/5))\nsimple_sample_1.head()","2b7a5fa6":"def get_p_values(population, sample):\n  import scipy\n  from scipy import stats\n  p_values_dict={}\n  for column in population.columns.tolist():\n    statistic, p_value=scipy.stats.ks_2samp(sample[column].dropna().tolist(), population[column].dropna().tolist(), alternative='two-sided', mode='auto')\n    p_values_dict[column]=p_value\n  return p_values_dict","4a2b2685":"get_p_values(dataset, simple_sample_1)","fc55f8bc":"correlation_matrix=dataset.corr()\ncorrelation_matrix['median_house_value'].sort_values(ascending=False)","492df610":"import numpy as np\n# Divide by 1.5 to limit the number of income categories\ndataset[\"median_income_category\"] = np.ceil(dataset[\"median_income\"] \/ 1.5)\n# showing the frequency of each category\ndataset.median_income_category.value_counts().sort_index()","c9a69259":"# Label those above 5 as 5\ndataset[\"median_income_category\"].where(dataset[\"median_income_category\"] < 5, 5.0, inplace=True)\ndataset.median_income_category.value_counts().sort_index()","ff422a52":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\nfor train_index, test_index in split.split( dataset, dataset[\"median_income_category\"]):\n    stratified_sample = dataset.loc[test_index]\nstratified_sample.head()","fe428870":"get_p_values(dataset, stratified_sample)","f9f6792f":"# Stratified Random Sampling\nIn Stratified Random Sampling it is important to choose a strata or the subpopulation. The most optimal way to do it is to choose the feature which is most imporant (highest correlation with the target variable) and stratify the population on the basis of this feature. ","6d72d0db":"In Machine Learning we often need to work with very large datasets, which sometimes may be computationally expensive. During these times, it makes more sense to create a smaller sample of this large dataset and train or models in this smaller dataset. While doing this it is important to ensure that we do not lose statistical information about our population. We also need to esnure that out sample is not biased and is a representative of our population. We explore some methods to ensure this.","3a895a96":"We see that all the columns have a p-value > 0.05 and hence we cannot reject the Null Hypothesis that they come from different distributions, implying sample is statistically significant.","7d5206f6":"We see that all the columns have a p-value > 0.05 and hence we cannot reject the Null Hypothesis that they come from different distributions, implying sample is statistically significant.","545f69f8":"For the purpose of this notebook document we will work with California House Dataset.","c6b356ac":"## (Optional)\n\nTo ensure our sample does not lose statistical significance with respect to the population, we conduct some statistical tests. For an easier implementation, we make an acceptable assumption: Consider each variable (feature\/ column) independently from the others.\nFor each feature we compare the probability distribution of the sample with that of the population. If all them are significant then the sample \"Passes our Test\" else we retry with another sample. \nWe use Kolmogorov-Smirnov test.\n\nTo conduct these tests we use the [`scipy`](https:\/\/docs.scipy.org\/doc\/scipy\/\/reference\/index.html) library, which is an Open Source Python library, which is used in mathematics, engineering, scientific and technical computing. ","afd591e9":"We will take two approaches at this juncture:\n\n\n1.   ## Simple Random Sampling\n  *   This is fairly easy to achieve and is the most direct method of probability sampling.\n  *   There is a risk of introducing sampling bias.\n  * To be more confident of the sample, statistical tests may be performed on each of the features of the dataset.\n\n2.  ## Stratified Random Sampling\n  * Ensures the sample is a representative of the whole population.\n  * Subpopulations or strata are defined and simple random samples are generated from each subpopulation.\n  * This approach reduces the sampling error.","48f931f4":"All we did above is create 5 strata (or subpopulations) on the basis of which we will sample.","0c564ac0":"# Simple Random Sampling\nWe use [`pandas.DataFrame.sample`](https:\/\/pandas.pydata.org\/pandas-docs\/stable\/reference\/api\/pandas.DataFrame.sample.html) to get a simple random sample. It returns a random sample of items from an axis of object.\n\n","f3c1e947":"# Sampling!","ca7af0f8":"So we see in this example that median_income has highest correlation and we choose this feature to stratify the dataset. For this we first need to create a new column to create the strata."}}