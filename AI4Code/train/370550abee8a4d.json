{"cell_type":{"66071920":"code","a6638ac6":"code","7d2c1541":"code","45bf8f56":"code","d9b8976d":"code","d7d9d7fe":"code","3292b7b3":"code","36f49e02":"code","338cd3b4":"code","78e4e77f":"code","235211f6":"code","d2096223":"code","cb15903f":"code","bf26e447":"code","9c79b99d":"code","152a9f1e":"code","4f4b6d41":"code","bbfa5f28":"code","92183524":"code","12f68bef":"code","9ec8f1df":"code","7bdd4c58":"code","18d99944":"code","df9f5118":"code","6389423c":"code","8ac23b81":"code","9253f753":"code","d60da78f":"code","9374e466":"code","d68d97c9":"code","acb2cdaa":"code","3d50991d":"code","4ddc2797":"code","4a2899dd":"code","b7e08d4f":"code","83dbbeaa":"code","18f333fd":"code","26f33292":"code","d7802716":"code","06cc961d":"code","b3246ccd":"code","e5ddc37b":"code","14a8badb":"code","af99722b":"code","8e188a51":"code","b9c452d4":"code","dc8807ac":"code","d9a8bec4":"markdown","5952162d":"markdown","1ad85515":"markdown","ef57ecfc":"markdown","281db1fb":"markdown","8e9e8b82":"markdown","51267bba":"markdown","6a60a84f":"markdown","4adf9ad9":"markdown","e34c5cbf":"markdown","46064529":"markdown","7f17c2be":"markdown","35f5df3f":"markdown","3c3b9fa7":"markdown","8003be1a":"markdown","09480ac4":"markdown","40817837":"markdown","a9005d99":"markdown","7304c4ad":"markdown","2486e248":"markdown","c22cac11":"markdown","ab8870e5":"markdown","7bd7b6ca":"markdown","e07cbd6f":"markdown","6640a8a2":"markdown"},"source":{"66071920":"# Libraries\nimport wandb\nimport pandas as pd\nimport numpy as np\nimport re\nimport os\nimport string\nfrom datetime import datetime\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom matplotlib.offsetbox import AnnotationBbox, OffsetImage\nfrom wordcloud import WordCloud, ImageColorGenerator\nfrom wordcloud import STOPWORDS as stopwords_wc\nfrom statsmodels.tsa.stattools import adfuller       ### Augmented Dickey Fuller\n\nimport cupy\nimport cudf\nimport cuml\nfrom cuml.tsa.arima import ARIMA\n\n# Color palette\nmy_colors = [\"#ce8f5a\", \"#efd199\", \"#80c8bc\", \"#5ec0ca\", \"#6287a2\"]\nsns.palplot(sns.color_palette(my_colors))\n\n# Set Style\nsns.set_style(\"white\")\nmpl.rcParams['xtick.labelsize'] = 16\nmpl.rcParams['ytick.labelsize'] = 16\nmpl.rcParams['axes.spines.left'] = False\nmpl.rcParams['axes.spines.right'] = False\nmpl.rcParams['axes.spines.top'] = False\n\nclass color:\n    BOLD = '\\033[1m' + '\\033[93m'\n    END = '\\033[0m'\n    \n# W&B\nos.environ[\"WANDB_SILENT\"] = \"true\"\n# Secrets \ud83e\udd2b\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb\")","a6638ac6":"! wandb login $secret_value_0","7d2c1541":"def offset_png(x, y, path, ax, zoom, offset):\n    '''For adding other .png images to the graph.\n    source: https:\/\/stackoverflow.com\/questions\/61971090\/how-can-i-add-images-to-bars-in-axes-matplotlib'''\n    \n    img = plt.imread(path)\n    im = OffsetImage(img, zoom=zoom)\n    im.image.axes = ax\n    x_offset = offset\n    ab = AnnotationBbox(im, (x, y), xybox=(x_offset, 0), frameon=False,\n                        xycoords='data', boxcoords=\"offset points\", pad=0)\n    ax.add_artist(ab)\n    \n\n    \ndef show_values_on_bars(axs, h_v=\"v\", space=0.4):\n    '''Plots the value at the end of the a seaborn barplot.\n    axs: the ax of the plot\n    h_v: weather or not the barplot is vertical\/ horizontal'''\n    \n    def _show_on_single_plot(ax):\n        if h_v == \"v\":\n            for p in ax.patches:\n                _x = p.get_x() + p.get_width() \/ 2\n                _y = p.get_y() + p.get_height()\n                value = int(p.get_height())\n                ax.text(_x, _y, format(value, ','), ha=\"center\") \n        elif h_v == \"h\":\n            for p in ax.patches:\n                _x = p.get_x() + p.get_width() + float(space)\n                _y = p.get_y() + p.get_height()\n                value = int(p.get_width())\n                ax.text(_x, _y, format(value, ','), ha=\"left\")\n\n    if isinstance(axs, np.ndarray):\n        for idx, ax in np.ndenumerate(axs):\n            _show_on_single_plot(ax)\n    else:\n        _show_on_single_plot(axs)\n        \n\n\ndef emoji_extractor(string, remove=False):\n    '''Removes Emoji from a text.'''\n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               u\"\\U0001f926-\\U0001f937\"\n                               u\"\\U00010000-\\U0010ffff\"\n                               u\"\\u2640-\\u2642\"\n                               u\"\\u2600-\\u2B55\"\n                               u\"\\u200d\"\n                               u\"\\u23cf\"\n                               u\"\\u23e9\"\n                               u\"\\u231a\"\n                               u\"\\ufe0f\"  # dingbats\n                               u\"\\u3030\"\n                               \"]+\", flags=re.UNICODE)\n    if remove == False:\n        # Extract emoji\n        return emoji_pattern.findall(string)\n    else:\n        # Remove emoji from text\n        return emoji_pattern.sub(r'', string)\n\ndef clean_emoji(x):\n    if len(x) == 0:\n        return ''\n    else:\n        return x[0]\n    \n    \n    \ndef clean_tweets(df):\n    '''Returns the dataframe with the tweet column cleaned.'''\n    \n    # ----- Remove \\n, \\t, \\xa0 -----\n    df['tweet'] = df['tweet'].apply(lambda x: x.replace('\\n', ''))\n    df['tweet'] = df['tweet'].apply(lambda x: x.replace('\\xa0', ''))\n    df['tweet'] = df['tweet'].apply(lambda x: x.replace('\\t', ''))\n    \n    # ----- Remove pic.twitter and http:\/\/ + https:\/\/ links -----\n    df['tweet'] = df['tweet'].apply(lambda x: re.sub(r'http\\S+', '', x))\n    df['tweet'] = df['tweet'].apply(lambda x: re.sub(r'https\\S+', '', x))\n    df['tweet'] = df['tweet'].apply(lambda x: re.sub(r'pic.twitter\\S+', '', x))\n    \n    # ----- Remove mentions and hashtags -----\n    df['tweet'] = df['tweet'].apply(lambda x: re.sub(r'#\\S+', '', x))\n    df['tweet'] = df['tweet'].apply(lambda x: re.sub(r'@\\S+', '', x))\n    \n    # ----- Extract Emojis and Remove from Tweet -----\n    df['tweet_emojis'] = df['tweet'].apply(lambda x: emoji_extractor(x, remove=False))\n    df['tweet_emojis'].replace('', np.nan, inplace=True)\n#     df[\"tweet_emojis\"] = df[\"tweet_emojis\"].apply(lambda x: clean_emoji(x))\n    \n    df['tweet'] = df['tweet'].apply(lambda x: emoji_extractor(x, remove=True))\n    \n    # ----- Strip of whitespaces -----\n    df['tweet'] = df['tweet'].apply(lambda x: x.strip())\n    df['tweet'] = df['tweet'].apply(lambda x: ' '.join(x.split()))\n    \n    # ----- Remove punctuation & Make lowercase -----\n    df['tweet'] = df['tweet'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n    df['tweet'] = df['tweet'].apply(lambda x: x.lower())\n    \n    return df","45bf8f56":"# === Tweets ===\ntweets = pd.read_csv(\"..\/input\/all-elon-musks-tweets\/TweetsElonMusk.csv\")\ntweets = tweets[[\"id\", \"date\", \"time\", \"username\", \n                 \"tweet\", \"mentions\", \"urls\", \"photos\", \"replies_count\", \n                 \"retweets_count\", \"likes_count\", \"hashtags\", \"link\"]]\n\n# Create new features\ntweets[\"year\"] = tweets[\"date\"].apply(lambda x: x.split(\"-\")[0])\n# Clean Tweets\ntweets = clean_tweets(df=tweets)\n\n# === Bitcoin ===\nbitcoin = cudf.read_csv(\"..\/input\/bitcoin-historical-data\/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv\")\n\n# === Dogecoin ===\ndogecoin = pd.read_csv(\"..\/input\/dogecoin-historical-data\/DOGE-USD.csv\")\n\n\n# Prints\nprint(color.BOLD + \"Tweets shape:\" + color.END, \"{}\".format(tweets.shape), \"\\n\" +\n      color.BOLD + \"Bitcoin shape:\" + color.END, \"{}\".format(bitcoin.shape), \"\\n\" +\n      color.BOLD + \"Dogecoin shape:\" + color.END, \"{}\".format(dogecoin.shape))\n\n# There are many missing values in Bitcoin data\nplt.figure(figsize = (25, 11))\nsns.heatmap(bitcoin.isna().as_matrix()[::10], cmap = [my_colors[1], \n                                                      my_colors[2]], xticklabels=bitcoin.columns)\nplt.title(\"Missing values in Bitcoin Data\", size=20);\n\n# Hence, we'll drop them\nbitcoin.dropna(axis=0, inplace=True)","d9b8976d":"# Save Tweets data to W&B Artifacts\n### versioned by me like the datasets\nrun = wandb.init(project='bitcoin-musk', name='all_elonmusk_tweets')\nartifact = wandb.Artifact(name='tweets', \n                          type='dataset')\nartifact.add_file(\"..\/input\/all-elon-musks-tweets\/TweetsElonMusk.csv\")\n\nwandb.log_artifact(artifact)\nwandb.finish()","d7d9d7fe":"run = wandb.init(project='bitcoin-musk', name='elonmusk_analysis')","3292b7b3":"# Yearly evolution\ndate_count_df = tweets[tweets[\"year\"]!=\"2021\"].groupby(\"year\")[\"tweet\"].count().reset_index()\n\n# Plot\nplt.figure(figsize=(25, 11))\nax = sns.lineplot(data=date_count_df, x=\"year\", y=\"tweet\", lw=8, color=my_colors[3])\nplt.title(\"Tweet Count Evolution\", size=25)\nplt.xlabel(\"Year\", size=20)\nplt.ylabel(\"Frequency\", size=20)\nsns.despine(left=True);\n\n# Picture\npath='..\/input\/all-elon-musks-tweets\/images\/images\/elon_rocket.png'\noffset_png(x=6.9, y=2000, path=path, ax=ax, zoom=0.27, offset=0)","36f49e02":"def create_wandb_lineplot(x_data, y_data, x_name, y_name, title, log):\n    '''Create and save barplot in W&B Environment.\n    x_data & y_data: Pandas Series containing x & y data\n    x_name & y_name: strings containing axis names\n    title: title of the graph\n    log: string containing name of log'''\n    \n    # Save Graph in W&B Dashboard as well\n    data = [[label, val] for (label, val) in zip(x_data, y_data)]\n\n    table = wandb.Table(data=data, columns = [x_name, y_name])\n    wandb.log({log : wandb.plot.line(table, x_name, y_name,\n                                                  title=title)})","338cd3b4":"create_wandb_lineplot(x_data=date_count_df[\"year\"], y_data=date_count_df[\"tweet\"], \n                      x_name=\"year\", y_name=\"tweet count\", \n                      title=\"Tweet Count Evolution\", log=\"tweet_evolution\")","78e4e77f":"# Get Popularity Information\npopularity = [\"likes_count\", \"retweets_count\", \"replies_count\"]\npopularity_df = tweets[tweets[\"year\"]!=\"2021\"].groupby(\"year\").agg({popularity[0] : 'sum',\n                                                                    popularity[1] : 'sum',\n                                                                    popularity[2] : 'sum',\n                                                                    'tweet' : 'count'}).reset_index()\npopularity_df[\"likes_count\"] = popularity_df[\"likes_count\"]\/popularity_df[\"tweet\"]\npopularity_df[\"retweets_count\"] = popularity_df[\"retweets_count\"]\/popularity_df[\"tweet\"]\npopularity_df[\"replies_count\"] = popularity_df[\"replies_count\"]\/popularity_df[\"tweet\"]\n\n# Plot\nfig, (ax1, ax2, ax3) = plt.subplots(3, figsize=(25, 15))\naxs = [ax1, ax2, ax3]\nplt.suptitle(\"Popularity\", size=25)\nsns.barplot(data=popularity_df, x=\"year\", y=\"likes_count\", lw=5, color=my_colors[0], ax=ax1)\nsns.barplot(data=popularity_df, x=\"year\", y=\"retweets_count\", lw=5, color=my_colors[1], ax=ax2)\nsns.barplot(data=popularity_df, x=\"year\", y=\"replies_count\", lw=5, color=my_colors[2], ax=ax3)\nnames = [\"Average Likes\", \"Average Retweets\", \"Average Replies\"]\nfor ax, n in zip(axs, names):\n    ax.set_xlabel(\"\", size=20)\n    ax.set_ylabel(n, size=20)\n    ax.get_yaxis().set_ticks([])\n#     ax.title.set_text(n)\n    show_values_on_bars(axs=ax, h_v=\"v\", space=0.4)\nsns.despine(left=True);","235211f6":"def create_wandb_barplot(x_data, y_data, x_name, y_name, title, log):\n    '''Create and save barplot in W&B Environment.\n    x_data & y_data: Pandas Series containing x & y data\n    x_name & y_name: strings containing axis names\n    title: title of the graph\n    log: string containing name of log'''\n    \n    # Save Graph in W&B Dashboard as well\n    data = [[label, val] for (label, val) in zip(x_data, y_data)]\n\n    table = wandb.Table(data=data, columns = [x_name, y_name])\n    wandb.log({log : wandb.plot.bar(table, x_name, y_name,\n                                                  title=title)})","d2096223":"# Create W&B Barplots\ncreate_wandb_barplot(x_data=popularity_df[\"year\"], y_data=popularity_df[\"likes_count\"], \n                     x_name=\"year\", y_name=\"likes\", \n                     title=\"Likes Evolution\", log=\"likes_evolution\")\ncreate_wandb_barplot(x_data=popularity_df[\"year\"], y_data=popularity_df[\"retweets_count\"], \n                     x_name=\"year\", y_name=\"retweets\", \n                     title=\"Retweets Evolution\", log=\"retweets_evolution\")\ncreate_wandb_barplot(x_data=popularity_df[\"year\"], y_data=popularity_df[\"replies_count\"], \n                     x_name=\"year\", y_name=\"replies\", \n                     title=\"Replies Evolution\", log=\"replies_evolution\")","cb15903f":"# Make worldcloud\nall_tweets = \" \".join(token for token in tweets[\"tweet\"])\nstopwords_wc = set(stopwords_wc)\nfont_path = \"..\/input\/all-elon-musks-tweets\/acetone_font.otf\"\n\nwordcloud = WordCloud(stopwords=stopwords_wc, font_path=font_path,\n                      max_words=1500,\n                      max_font_size=350, random_state=42,\n                      width=2000, height=1000,\n                      colormap = \"twilight\")\nwordcloud.generate(all_tweets)\n\n# Plot\nplt.figure(figsize = (16, 8))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show();","bf26e447":"WordCloud.to_file(wordcloud, \"wordcloud.png\")\n\n# Save image to W&B\nwandb.log({\"wordcloud\": wandb.Image(\".\/wordcloud.png\")})","9c79b99d":"# Retrieve only Bitcoin Information\nbitcoin_tweets = tweets[tweets[\"tweet\"].str.contains(\"bitcoin\")].reset_index(drop = True)\ndogecoin_tweets = tweets[tweets[\"tweet\"].str.contains(\"dogecoin\")].reset_index(drop = True)\n\n# Information\nprint(color.BOLD + \"% of tweets about Bitcoin:\" + color.END, \"{:.3}%\".format(bitcoin_tweets.shape[0]\/tweets.shape[0]*100), \"\\n\" +\n      color.BOLD + \"% of tweets about Dogecoin:\" + color.END, \"{:.3}%\".format(dogecoin_tweets.shape[0]\/tweets.shape[0]*100))\n\ntop = bitcoin_tweets.sort_values(\"likes_count\", ascending=False)[:7][\"tweet\"]\nprint(\"\\n\", color.BOLD + \"Most liked BITCOIN tweets:\" + color.END)\nfor k, text in enumerate(top):\n    print(f\"{k+1}. {text}\")\n    \ntop = dogecoin_tweets.sort_values(\"likes_count\", ascending=False)[:7][\"tweet\"]\nprint(\"\\n\", color.BOLD + \"Most liked DOGECOIN tweets:\" + color.END)\nfor k, text in enumerate(top):\n    print(f\"{k+1}. {text}\")","152a9f1e":"wandb.finish()","4f4b6d41":"run = wandb.init(project='bitcoin-musk', name='bitcoin_analysis')","bbfa5f28":"plt.figure(figsize = (25, 11))\nplt.plot(bitcoin[\"Timestamp\"].to_array(), bitcoin[\"Weighted_Price\"].to_array(), color=my_colors[0], lw=3)\nplt.title(\"Bitcoin Price over time\", size=25)\nplt.xlabel(\"Time\", size=20)\nplt.ylabel(\"$ Price\", size=20);","92183524":"# Log to W&B\ncreate_wandb_lineplot(x_data=bitcoin[\"Timestamp\"][::50].to_array(), y_data=bitcoin[\"Weighted_Price\"][::50].to_array(), \n                     x_name=\"timestamp\", y_name=\"$price\", \n                     title=\"Price Evolution\", log=\"price_evolution\")","12f68bef":"plt.figure(figsize = (25, 11))\nplt.plot(bitcoin[\"Timestamp\"].to_array(), bitcoin[\"Volume_(Currency)\"].to_array(), color=my_colors[2], lw=3)\nplt.title(\"Bitcoin Volume over time\", size=25)\nplt.xlabel(\"Time\", size=20)\nplt.ylabel(\"Volume\", size=20);","9ec8f1df":"# Log to W&B\ncreate_wandb_lineplot(x_data=bitcoin[\"Timestamp\"][::50].to_array(), y_data=bitcoin[\"Volume_(Currency)\"][::50].to_array(), \n                     x_name=\"timestamp\", y_name=\"volume\", \n                     title=\"Volume Evolution\", log=\"volume_evolution\")","7bdd4c58":"wandb.finish()","18d99944":"run = wandb.init(project='bitcoin-musk', name='stationarity')","df9f5118":"def test_stationarity(x, log=\"non-stationary\"):\n    '''Test stationarity of a Time Series variable.'''\n    \n    # Perform Dickey Fuller test    \n    result = adfuller(x)\n    print('ADF Stastistic: %f'%result[0])\n    print('p-value: %f'%result[1])\n    pvalue=result[1]\n    \n    for key,value in result[4].items():\n        if result[0]>value:\n            print(color.BOLD + \"The graph is non stationary! (it has a trend)\" + color.END)\n            wandb.log({log : round(result[1], 5)})\n            break\n        else:\n            print(color.BOLD + \"The graph is stationary! (it doesn't have a trend)\" + color.END)\n            wandb.log({log : round(result[1], 5)})\n            break;\n    \n    print('Critical values:')\n    for key,value in result[4].items():\n        print('\\t%s: %.3f ' % (key, value))\n    \n    # Determing rolling statistics\n    rolmean = x.rolling(window=22,center=False).mean()\n    rolstd = x.rolling(window=12,center=False).std()\n    \n    # Plot rolling statistics:\n    plt.figure(figsize=(25, 11))\n    orig = plt.plot(x, color=my_colors[0], lw=8, label='Original')\n    mean = plt.plot(rolmean, color=my_colors[2], lw=2.5, ls=\"--\",  label='Rolling Mean')\n    std = plt.plot(rolstd, color=my_colors[3], lw=3, label = 'Rolling Std')\n    plt.legend(loc='best', fontsize=20)\n    plt.title('Rolling Mean & Standard Deviation', size=25)\n    plt.show(block=False)\n    \n    # Log to W&B\n    create_wandb_lineplot(x_data=pd.Series(range(len(rolmean))), y_data=pd.Series(rolmean), \n                          x_name=\"timestamp\", y_name=\"rolmean\", \n                          title=\"Stationarity Analysis\", log=log)","6389423c":"price = pd.Series(bitcoin[\"Weighted_Price\"][::70].to_array())\ntest_stationarity(price, log=\"non-stationary\")","8ac23b81":"# Adjust by applying natural log over the series\nadjusted_price = cupy.log(bitcoin[\"Weighted_Price\"])\n\nprice_adjusted = pd.Series(cupy.asnumpy(adjusted_price)[::70])\ntest_stationarity(price_adjusted, log=\"stationary\")","9253f753":"# Save the price with no trend into a new variable\nbitcoin[\"log_price\"] = adjusted_price","d60da78f":"wandb.finish()","9374e466":"# Fit an ARI model - AR(1) + I(1)\nar_model = ARIMA(bitcoin[\"Weighted_Price\"][::100], order=(1,1,0), fit_intercept=True)\nar_model.fit()\n\n# Print Information on the model\nprint(color.BOLD + \"log-likelihood (smaller the better):\" + color.END, \"{:,.8}\".format(ar_model.llf[0]))\nprint(color.BOLD + \"\\nCorrected Akaike Information Criterion (AICc) (smaller the better):\" + color.END, \"{:,.8}\".format(ar_model.aicc[0]))\nprint(color.BOLD + \"\\nBayesian Information Criterion (BIC) (smaller the better):\" + color.END, \"{:,.8}\".format(ar_model.bic[0]))","d68d97c9":"# Fit an MA model - I(1) + MA(1)\nma_model = ARIMA(bitcoin[\"Weighted_Price\"][::100], order=(0,1,1), fit_intercept=True)\nma_model.fit()\n\n# Print Information on the model\nprint(color.BOLD + \"log-likelihood (smaller the better):\" + color.END, \"{:,.8}\".format(ma_model.llf[0]))\nprint(color.BOLD + \"\\nCorrected Akaike Information Criterion (AICc) (smaller the better):\" + color.END, \"{:,.8}\".format(ma_model.aicc[0]))\nprint(color.BOLD + \"\\nBayesian Information Criterion (BIC) (smaller the better):\" + color.END, \"{:,.8}\".format(ma_model.bic[0]))","acb2cdaa":"# Fit an MARIMA model AR(1) + I(1) + MA(2)\narima_model = ARIMA(bitcoin[\"Weighted_Price\"][::100], order=(1, 1, 2), fit_intercept=True)\narima_model.fit()\n\n# Print Information on the model\nprint(color.BOLD + \"log-likelihood (smaller the better):\" + color.END, \"{:,.8}\".format(arima_model.llf[0]))\nprint(color.BOLD + \"\\nCorrected Akaike Information Criterion (AICc) (smaller the better):\" + color.END, \"{:,.8}\".format(arima_model.aicc[0]))\nprint(color.BOLD + \"\\nBayesian Information Criterion (BIC) (smaller the better):\" + color.END, \"{:,.8}\".format(arima_model.bic[0]))","3d50991d":"run = wandb.init(project='bitcoin-musk', name='arima_predict')","4ddc2797":"def append(my_list, value):\n    '''.append() function does not exist for arrays (only for lists).\n    So we will make a function that tweaks this a bit.'''\n    \n    # Convert from array to list\n    my_list = my_list.tolist()\n    # Append new value\n    my_list.append(value)\n    # Convert back to array\n    my_list = cupy.asarray(my_list)\n    \n    return my_list","4a2899dd":"# ========== VARIABLES ==========\npercent = 0.99           ### percent of data to be used\nno_future_preds = 10    ### number of values to predict in the future\n# ===============================\n\nwandb.log({'percent_of_data':percent, 'future_values':no_future_preds})","b7e08d4f":"# Select only a small portion of the data\nsample_data = adjusted_price[percent*len(adjusted_price) : len(adjusted_price)]\nprint(color.BOLD + \"All data shape:\" + color.END, sample_data.shape)\n\n# Split into Train and Test data\nsplit = len(sample_data) - no_future_preds\n\ntrain_price = sample_data[:split]\ntest_price = sample_data[split:]\n\npred_list, actual_list, error_list = [], [], []","83dbbeaa":"# For each value in the 100 prices in test set\nfor k in range(len(test_price)):\n    \n    # Fit the arima model onto train data\n    arima_model = ARIMA(train_price, order=(1, 1, 2), fit_intercept=True)\n    arima_model.fit()\n    \n    # Predict next value\n    predicted_out = arima_model.forecast(1)[0]\n    predicted_out = np.exp(predicted_out)\n    \n    # Append the original value to training data\n    actual_out = test_price[k]\n    train_price = append(my_list=train_price, value=cupy.asnumpy(actual_out).min())\n    actual_out = np.exp(actual_out)\n    \n    # Compute the error of model\n    error = (abs(predicted_out - actual_out) \/ actual_out) * 100\n    print(color.BOLD + f\"Step {k}. | \" + color.END, \"Predicted: {} | Actual: {} | ERROR: {}\".format(predicted_out, actual_out, error))\n    \n    # Append information\n    pred_list.append(predicted_out)\n    actual_list.append(actual_out)\n    error_list.append(error)\n    \n    # Log to W&B\n    wandb.log({\"predicted\": float(predicted_out[0])}, step=k)\n    wandb.log({\"actual\": float(actual_out)}, step=k)\n    wandb.log({\"error\": float(error[0])}, step=k)","18f333fd":"# Prepare info to be plotted\nerror_list = [l[0].tolist() for l in error_list]\npred_list = [l[0].tolist() for l in pred_list]\nactual_list = [l.tolist() for l in actual_list]","26f33292":"print(color.BOLD + 'Average Error:' + color.END, (sum(error_list) \/ float(len(error_list))))\n\n# Plot\nplt.figure(figsize=(25, 11))\ntime = [t for t in range(len(test_price))]\n\nplt.plot(time, pred_list, color=my_colors[0], label=\"Predicted\", lw=5)\nplt.plot(time, actual_list, color=my_colors[2], label=\"Actual\", lw=5)\nplt.title('Actual Vs Predicted Views Forecasting', size=25)\nplt.xlabel('Time', size=20)\nplt.ylabel('Price', size=20)\nplt.legend(fontsize=18);","d7802716":"# Log to W&B\ncreate_wandb_lineplot(x_data=time, y_data=pred_list, \n                      x_name=\"time\", y_name=\"predictions\", \n                      title=\"Prediction Forecast\", log=\"prediction\")\ncreate_wandb_lineplot(x_data=time, y_data=actual_list, \n                      x_name=\"time\", y_name=\"actuals\", \n                      title=\"Actuals Values\", log=\"actuals\")","06cc961d":"def plot_prediction(actual, prediction, zoom=5000):\n    '''Plot actual and forecasted values in time.\n    actual: a GPU array of actual data in time\n    prediction: the predicted values from ARIMA model\n    zoom: number of observations (out of 3 million) to plot'''\n\n    actual_range = actual.count()\n    predict_range = prediction.count()\n    all_range = actual_range + predict_range\n    \n    plt.figure(figsize = (25, 10))\n    plt.plot(range(actual_range-zoom, actual_range), actual[actual_range-zoom:actual_range].to_array(), color=my_colors[0], lw=4, label=\"Actual\")\n    plt.plot(range(actual_range, all_range), prediction.to_array(), color=my_colors[3], lw=4, ls=\"--\", label=\"Predicted\")\n    plt.legend(fontsize=20)\n    plt.title(\"Prediction of Bitcoin Price\", size=25)\n    plt.xlabel(\"Time\", size=20)\n    plt.ylabel(\"log Price\", size=20);","b3246ccd":"arima_model2 = ARIMA(sample_data, order=(1, 1, 2), fit_intercept=True)\narima_model2.fit()\npredictions = arima_model2.forecast(30)","e5ddc37b":"plot_prediction(actual=cudf.Series(sample_data), prediction=cudf.Series(predictions), zoom=70)","14a8badb":"wandb.finish()","af99722b":"# Get bitcoin info\nbtc_tweets = tweets[tweets[\"tweet\"].str.contains(\"bitcoin\")].reset_index(drop = True)\n# Convert date to number\nbtc_tweets[\"date\"] = btc_tweets[\"date\"].apply(lambda x: datetime.fromisoformat(x).timestamp())\n# Get only latest bitcoin data (as Elon never tweeted before 2018)\nbtc_prices = bitcoin.sort_values(\"Timestamp\", ascending=False).head(2000000)\ntimestamps = btc_tweets[\"date\"]\n\nfor k, tweet in enumerate(btc_tweets[\"tweet\"]): print(color.BOLD + f\"{k+1}.\" + color.END, tweet)\n\n# Get intersection\nx_values = cupy.asnumpy(btc_prices[btc_prices[\"Timestamp\"].isin(timestamps)][\"Timestamp\"])\ny_values = cupy.asnumpy(btc_prices[btc_prices[\"Timestamp\"].isin(timestamps)][\"Weighted_Price\"])\n\n# Plot\nplt.figure(figsize = (25, 11))\nfor x, y in zip(x_values, y_values):\n    plt.scatter(x, y, color=\"#FF451D\", lw=13, zorder=2)\nplt.plot(btc_prices[\"Timestamp\"].to_array(), btc_prices[\"Weighted_Price\"].to_array(), color=my_colors[3], lw=3, zorder=1)\nplt.title(\"Bitcoin Price & Elon's Tweets\", size=25)\nplt.xlabel(\"Time\", size=20)\nplt.ylabel(\"$ Price\", size=20);","8e188a51":"# Get bitcoin info\nbtc_tweets = tweets[tweets[\"tweet\"].str.contains(\"bitcoin\")].reset_index(drop = True)\n# Convert date to number\nbtc_tweets[\"date\"] = btc_tweets[\"date\"].apply(lambda x: datetime.fromisoformat(x).timestamp())\n# Get only latest bitcoin data (as Elon never tweeted before 2018)\nbtc_prices = bitcoin.sort_values(\"Timestamp\", ascending=False).head(80000)\ntimestamps = btc_tweets[\"date\"]\n\nfor k, tweet in enumerate(btc_tweets[\"tweet\"][:3]): print(color.BOLD + f\"{k+1}.\" + color.END, tweet)\n\n# Get intersection\nx_values = cupy.asnumpy(btc_prices[btc_prices[\"Timestamp\"].isin(timestamps)][\"Timestamp\"])\ny_values = cupy.asnumpy(btc_prices[btc_prices[\"Timestamp\"].isin(timestamps)][\"Weighted_Price\"])\n\n# Plot\nplt.figure(figsize = (25, 11))\nfor x, y in zip(x_values, y_values):\n    plt.scatter(x, y, color=\"#FF451D\", lw=13, zorder=2)\nplt.plot(btc_prices[\"Timestamp\"].to_array(), btc_prices[\"Weighted_Price\"].to_array(), color=my_colors[3], lw=3, zorder=1)\nplt.title(\"Last 3 tweets in time\", size=25)\nplt.xlabel(\"Time\", size=20)\nplt.ylabel(\"$ Price\", size=20);","b9c452d4":"# Get bitcoin info\ndgc_tweets = tweets[tweets[\"tweet\"].str.contains(\"dogecoin\")].reset_index(drop = True)\n# Convert date to number\ndgc_tweets[\"date\"] = dgc_tweets[\"date\"].apply(lambda x: datetime.fromisoformat(x).timestamp())\ntimestamps = dgc_tweets[\"date\"]\n\ndgc_prices = dogecoin.sort_values(\"Date\", ascending=False).head(800)\ndgc_prices[\"Date\"] = dgc_prices[\"Date\"].apply(lambda x: datetime.fromisoformat(x).timestamp())\n\nfor k, tweet in enumerate(dgc_tweets[\"tweet\"]): print(color.BOLD + f\"{k+1}.\" + color.END, tweet)\n\n# Get intersection\nx_values = dgc_prices[dgc_prices[\"Date\"].isin(timestamps)][\"Date\"]\ny_values = dgc_prices[dgc_prices[\"Date\"].isin(timestamps)][\"Adj Close\"]\n\n# Plot\nplt.figure(figsize = (25, 11))\nfor x, y in zip(x_values, y_values):\n    plt.scatter(x, y, color=\"#FF451D\", lw=13, zorder=2)\nplt.plot(dgc_prices[\"Date\"], dgc_prices[\"Adj Close\"], color=my_colors[3], lw=3, zorder=1)\nplt.title(\"Dogecoin Price & Elon's Tweets\", size=25)\nplt.xlabel(\"Time\", size=20)\nplt.ylabel(\"$ Price\", size=20);","dc8807ac":"# Get bitcoin info\ndgc_tweets = tweets[tweets[\"tweet\"].str.contains(\"dogecoin\")].reset_index(drop = True)\n# Convert date to number\ndgc_tweets[\"date\"] = dgc_tweets[\"date\"].apply(lambda x: datetime.fromisoformat(x).timestamp())\ntimestamps = dgc_tweets[\"date\"]\n\ndgc_prices = dogecoin.sort_values(\"Date\", ascending=False).head(90)\ndgc_prices[\"Date\"] = dgc_prices[\"Date\"].apply(lambda x: datetime.fromisoformat(x).timestamp())\n\nfor k, tweet in enumerate(dgc_tweets[\"tweet\"][:6]): print(color.BOLD + f\"{k+1}.\" + color.END, tweet)\n\n# Get intersection\nx_values = dgc_prices[dgc_prices[\"Date\"].isin(timestamps)][\"Date\"]\ny_values = dgc_prices[dgc_prices[\"Date\"].isin(timestamps)][\"Adj Close\"]\n\n# Plot\nplt.figure(figsize = (25, 11))\nfor x, y in zip(x_values, y_values):\n    plt.scatter(x, y, color=\"#FF451D\", lw=13, zorder=2)\nplt.plot(dgc_prices[\"Date\"], dgc_prices[\"Adj Close\"], color=my_colors[3], lw=3, zorder=1)\nplt.title(\"Dogecoin Price & Elon's Tweets\", size=25)\nplt.xlabel(\"Time\", size=20)\nplt.ylabel(\"$ Price\", size=20);","d9a8bec4":"> The [W&B Dashboard](https:\/\/wandb.ai\/andrada\/bitcoin-musk?workspace=user-andrada):\n\n<center><img src=\"https:\/\/i.imgur.com\/N6m3nyh.png\" width=800><\/center>\n\n## II. Testing Stationarity\n\nOur time series data **can have a trend or not**. It is of the utmost importance to determine how the series is behaving before applying any model to it.\n\n> **Augmented Dicky Fuller test**: it determines how strongly a time series is defined by a trend.\n\n**Hypothesis**:\n1. Null Hypothesis (H0): Null hypothesis of the test is that the time series can be represented by a unit root that **is not stationary**.\n2. Alternative Hypothesis (H1): Alternative Hypothesis of the test is that the time series **is stationary**.\n\n### Why is Stationarity Important?\nFor data to be stationary, the statistical properties of a system **do not change over time**. This does not mean that the values for each data point have to be the same, but the overall behavior of the data should remain constant.\n\nIf the data is non-stationary (meaning it has a trend), we need to **remove** it in order to proceed with the analysis.\n\n*My Reference: [Bitcoin Price Prediction](https:\/\/towardsdatascience.com\/bitcoin-price-prediction-using-time-series-forecasting-9f468f7174d3)*","5952162d":"### TODO:\n* Import W&B overlapped graphs","1ad85515":"## V. Predicting Bitcoin Price\n\nNow, let's predict Bitcoin Prices by using an ARIMA (1, 1, 2) model.\n\nThe steps will be:\n* Selecting only a small portion of data `test`: we don't have to train on all 3 mil rows of data. Choosing data that is closer ","ef57ecfc":"> You can observe some sudden peaks within a few days (1 do 4 days) of the making of the tweet.\n\n# 4. \ud83d\udd87 Is there correlation between Dogecoin and Elon Musk's Tweets?\n\nIs there?\n\n<center><img src=\"https:\/\/media.alephnews.ro\/2021\/04\/musk-meme-doge.jpg\" width=500><\/center>","281db1fb":"## IV. What tipe of ARIMA should I choose?\n\n### ARIMA:\n* AR: Auto Regressive model\n* I: Integrated\n* MA: Moving Average\n\nLet's take them step by step :)\n\n### Auto Regressive Model\n\n> An autoregressive (AR) model **predicts future behavior based on past behavior**. It's used for forecasting when there is **some correlation between values in a time series** and the values that precede and succeed them.\n\n**Criterias**\n\nLog Likelihood, Akaike and Bayesian Information Criterion are indicators that tell us how well our model is performing, meaning **how much information it's lost**. The less information lost, the better the model. Hence, we'll try to tweak these parameters and get ourselves the best model.","8e9e8b82":"> It doesn't really look like there is any strong correlation or that the tweets drive peaks.\n\n## Closer Look\n\nLet's use a magnifying glass and look closer to our points in time.","51267bba":"## Closer Look","6a60a84f":"<img src=\"https:\/\/i.imgur.com\/zK75gSX.gif\">\n\n<center><h1>\ud83d\udcb0 Bitcoin (&Dogecoin) Prices, Elon Musk and RAPIDS \ud83d\udcb0<\/h1><\/center>\n\n# Introduction\n\nWhat does a virtual coin that people like or hate, an excentric person that wants to get old on Mars and the suite of software libraries on GPUs all have in common?\n\nWell, you know what they say ... if you want, you can find a correlation anywhere you look ... if you're really, deeply paying attention.\n\n> **\ud83d\udfe2 Goal**: This notebook has the purpose of analysing and predicting bitcoin prices using RAPIDS, as well as identifying if there is any impact from Elon Musk's tweets on the fluctuation of the bitcoin prices.\n\n### \ud83d\udcda Libraries & Functions\n> You can learn more about W&B in [this great kernel right here](https:\/\/www.kaggle.com\/ayuraj\/experiment-tracking-with-weights-and-biases).","4adf9ad9":"And surprise surprise! The series has a trend (is non stationary). We could have noticed that by only using our naked eye, but we always need to double check.\n\n## III. From non-stationarity to stationarity\nNow that we now our series has a trend, we need to remove it in order to proceed with the models.\n\nWe can do that by applying a **natural log** to our series. Let's see how that's done!","e34c5cbf":"### \ud83d\udce5 Read in Data","46064529":"> The [W&B Dashboard](https:\/\/wandb.ai\/andrada\/bitcoin-musk?workspace=user-andrada):\n\n<center><img src=\"https:\/\/i.imgur.com\/Vl8Hixr.png\" width=800><\/center>\n\n# 2. \ud83d\udcc8 Predict Future Bitcoin Price using RAPIDS\n\n> We'll use the RAPIDS distribution for this experiment, as our **data is extremely large** (more than 3 million observations). You can find out more about [RAPIDS and cuml here](https:\/\/github.com\/rapidsai\/cuml\/tree\/branch-0.20\/notebooks).","7f17c2be":"## I. Tweet Count Evolution\n> **\ud83d\udcdd Note**: At the beginning of his tweeting journey, he was barely using the platform a few times in a year. 2015 was his breaking point, when he started tweeting more and more every year. It's also the year when Elon became ... well, he became **the rockstar** we know now. He was already known before, but 2015 got him on a whole new level, by announcing *Tesla's Powerwall battery* and putting out his personal life through *his biography*.","35f5df3f":"# 1. \ud83d\ude80 Elon Musk's personality\n\nOk, let's have a bit of fun first. Let's see how the tweets look, his progression over time and get an overall feel of how, what, when he tweets. This will help us understand a bit of his behavior, as well as address and analyse the tweets that mention **Bitcoin**.","3c3b9fa7":"> This is how the logs look now in our Dashboard:\n\n<center><img src=\"https:\/\/i.imgur.com\/CIrYGU7.png\" width=800><\/center>","8003be1a":"> The [W&B Dashboard](https:\/\/wandb.ai\/andrada\/bitcoin-musk?workspace=user-andrada):\n\n<center><img src=\"https:\/\/i.imgur.com\/AKCHbUi.png\" width=800><\/center>\n\n# 3. \ud83d\udd87 Is there correlation between Bitcoin and Elon Musk's Tweets?\n\nLet's find out!\n\nIn order to do this, I've decided to look at the points in time when Elon tweeted about Bitcoin.\n\n<center><img src=\"https:\/\/sm.pcmag.com\/t\/pcmag_uk\/news\/e\/elon-musk-\/elon-musk-tells-followers-to-use-signal-messaging-app-amid-w_p8u9.1920.jpg\" width = 450><\/center>\n\n## Overall View","09480ac4":"## IV. Let's talk about Bitcoin and ... Dogecoin?\n\nI wanted to throw Dogecoin in there for fun. I mean ... you never know.","40817837":"## II. Popularity\n\n> **\ud83d\udcdd Note**: It seems that his popularity grew with the number of tweets. He increased gradually in likes with the peak in 2020 (and I bet he'll continue in 2021 as well), but the replies reached a peak as well (he's communicating more with a broader audience, who's speaking back).\n<center><img src=\"https:\/\/media2.giphy.com\/media\/2Y8Iq3xe121Ba3hUAM\/giphy.gif\" width=400><\/center>","a9005d99":"### Moving Average Model\n> The moving-average model specifies that the output variable **depends linearly on the current and various past values** of a stochastic (imperfectly predictable) term.","7304c4ad":"# \u23f3 Work in Progress\n\n<img src=\"https:\/\/i.imgur.com\/cUQXtS7.png\">\n\n# \u2328\ufe0f\ud83c\udfa8 Specs on how I trained using RAPIDS\n### (on my local machine)\n* Z8 G4 Workstation \ud83d\udda5\n* 2 CPUs & 96GB Memory \ud83d\udcbe\n* NVIDIA Quadro RTX 8000 \ud83c\udfae\n* RAPIDS version 0.18 \ud83c\udfc3\ud83c\udffe\u200d\u2640\ufe0f","2486e248":"## I. Analyse Bitcoin Evolution","c22cac11":"### Use ARIMA to forecast the Future","ab8870e5":"### Auto Regressive Integrated Moving Average\n\n> Explains a given time series based on its own past values, that is, its own **lags** and the **lagged** forecast errors, so that equation can be used to forecast future values.","7bd7b6ca":"> Link to **your own key** in W&B: https:\/\/wandb.ai\/authorize","e07cbd6f":"> **Pro Tip**: If you would like to change something in the W&B Graph and you want it to show in the Dashboard, simply click \"Detach\" at the top after you've made your changes:\n\n<center><img src=\"https:\/\/i.imgur.com\/NjIxgxj.png\" width=800><\/center>","6640a8a2":"## III. Most Frequent Words\n\n> **\ud83d\udcdd Note**:  alot of talk about **Tesla, rocket, Mars, starship, launch**. To be observed that the wording sounds super positive: yes, yeah, good, thank, people, sure. I like that a lot, he's always super positive and enthusiastin in his messages.\n\n<center><img src=\"https:\/\/i.pinimg.com\/originals\/62\/57\/d3\/6257d3ab7e42e96407944416ca9d3f18.gif\" width = 450><\/center>"}}