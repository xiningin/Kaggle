{"cell_type":{"f729f186":"code","d4bfa1d1":"code","0a14046a":"code","38d15a71":"code","feb2be6c":"code","490b49a8":"code","48abac4c":"code","698621fd":"code","6d70bf2b":"code","fe185456":"code","e999a346":"code","08fe63dd":"code","21b213fb":"code","4aec5474":"code","826c1245":"code","70908b3a":"code","77736559":"code","10f84098":"code","af65a4d2":"code","ba23faab":"code","3b1e71f1":"code","9b9b3164":"code","4879c040":"code","3da07753":"code","5ef3be15":"code","c51bf1b6":"code","93b8022a":"code","d0466011":"code","a87321d0":"code","cb551d8d":"code","a95f5474":"code","a03f447d":"code","ff7f1af6":"code","b6c22894":"code","9f67156e":"code","bff68435":"code","67b23bc4":"code","d0c73604":"code","1c755f4e":"code","d9b43a9b":"code","8b492e79":"code","7f48ba85":"code","b867ec6c":"markdown","3a1a9812":"markdown","d2afa3e5":"markdown","a7ac115b":"markdown","4a973efe":"markdown","0c70de5b":"markdown","631d91ba":"markdown","084f6bcd":"markdown","6c128c96":"markdown","cd8e777a":"markdown"},"source":{"f729f186":"%matplotlib inline\n\n# For simple vectorized calculations\nimport numpy as np\n\n# Mainly data handling and representation\nimport pandas as pd\n\n# Models\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, BatchNormalization, Activation, Dropout\nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import Model\n\n# Data preparation\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\n\n# Plotting and display\nfrom IPython.display import display\nfrom matplotlib import pyplot as plt\n\nnp.random.seed(0)","d4bfa1d1":"# Path of the file to read.\ntrain_file_path = '..\/input\/train.csv'\n\n# Read the file\ndigit_data_orig = pd.read_csv(train_file_path)\n\n# The shape of the data\ndigit_data_orig.shape","0a14046a":"# Separate the label from the data\ny_orig = digit_data_orig.iloc[:, 0].values.reshape(-1,1)\n\nm = y_orig.shape[0]\nprint(\"The number of images: m = {}\".format(m))\n\n# There are 42000 images so 42000 labels\nprint(\"The shape of y: {}\".format(y_orig.shape))","38d15a71":"# One-hot encode the categorical values\ndef one_hot_encode_categories(y):\n    \n    encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n\n    y_one_hot = pd.DataFrame(encoder.fit_transform(y), columns=encoder.get_feature_names())\n        \n    return y_one_hot, encoder","feb2be6c":"# One hot encode y\ny_one_hot, encoder = one_hot_encode_categories(y_orig)\n\n# Strip the category names\ny_one_hot.columns = pd.DataFrame(y_one_hot.columns)[0].apply(lambda x: x[-1])\n\n# The number of categories\nn_y = y_one_hot.shape[1]\nprint(\"The number of categories: n_y = {}\".format(n_y))\n\n# A few examples\nprint(y_orig[0:10])\ny_one_hot.head()","490b49a8":"# Let's see how many examples are ther from each category\ndisplay(pd.DataFrame(y_one_hot.sum(axis=0)).transpose())\n\n# Plot the values\nplt.bar(y_one_hot.columns, y_one_hot.sum(axis=0))\n\n# There is approximately the same number of examples there are from each category","48abac4c":"# Separate the image data\nX_orig = digit_data_orig.iloc[:, 1:].values.reshape(-1,1)\n\nprint(\"The shape of X without reshaping: {}\".format(X_orig.shape))\n\n# There are 42000 images and 64x64 pixel each image which is 32928000 total","698621fd":"# Let's reshape the images and view some\nX_reshaped = X_orig.reshape(-1,28,28)\n\ndef plot_sample_images(X, y, images_to_show=10, random=True):\n\n    fig = plt.figure(1)\n\n    images_to_show = min(X.shape[0], images_to_show)\n\n    # Set the canvas based on the numer of images\n    fig.set_size_inches(18.5, images_to_show * 0.3)\n\n    # Generate random integers (non repeating)\n    if random == True:\n        idx = np.random.choice(range(X.shape[0]), images_to_show, replace=False)\n    else:\n        idx = np.arange(images_to_show)\n        \n    # Print the images with labels\n    for i in range(images_to_show):\n        plt.subplot(images_to_show\/10 + 1, 10, i+1)\n        plt.title(str(y[idx[i]]))\n        plt.imshow(X[idx[i], :, :], cmap='Greys')\n        \n\n# Choose how many images you would like to see\nimages_to_show = 30\n\nplot_sample_images(X_reshaped, y_orig, images_to_show=images_to_show)","6d70bf2b":"# The number of X features are 28*28 = 784\nn_x = 28*28\n\nprint(\"The number of X features are: n_x = {}\".format(n_x))","fe185456":"# Scale the image pixel values from 0-255 to 0-1 range so the neural net can to converge faster\nX_scaled = X_reshaped \/ 255\n\nprint(\"Original scale: {} - {}\".format(X_reshaped.min(), X_reshaped.max()))\nprint(\"New scale: {} - {}\".format(X_scaled.min(), X_scaled.max()))","e999a346":"X = X_scaled.reshape(-1, 28, 28, 1)\ny = y_one_hot","08fe63dd":"# We can train a model using directly the images, let's first do that","21b213fb":"def model_definition():\n    # Define a simple model in Keras\n    model = Sequential()\n\n    # Add layers to the model\n\n    # Add convolutional layer\n    model.add(Conv2D(50, kernel_size=(5,5), input_shape=(28,28,1)))\n\n    # Add ReLu activation function\n    model.add(Activation('relu'))\n\n    # Add dropout layer for generalization\n    model.add(Dropout(0.05))\n\n    # Add maxpool layer\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n\n    # Add batch normalization to help learning and avoid vanishing or exploding gradient\n    model.add(BatchNormalization())\n\n    # Add convolutional layer\n    model.add(Conv2D(50, kernel_size=(3,3)))\n\n    # Add ReLu activation function\n    model.add(Activation('relu'))\n\n    # Add dropout layer for generalization\n    model.add(Dropout(0.05))\n\n    # Maxpool layer\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n\n    # Add batch normalization to help learning and avoid vanishing or exploding gradient\n    model.add(BatchNormalization())\n\n    # Add flatten layer to get 1d data for dense layer\n    model.add(Flatten())\n\n    # Dense layer\n    model.add(Dense(100, input_dim=650))\n    \n    # Add ReLu activation function\n    model.add(Activation('relu'))\n\n    # Dense layer\n    model.add(Dense(10))\n    \n    # Add sigmoid activation function to get values beteween 0-1\n    model.add(Activation('softmax'))\n    \n    return model","4aec5474":"model = model_definition()","826c1245":"# Define the hyperparameters\n\nbatch_size = 32\nepochs = 100","70908b3a":"# Define the loss function, this is a categorical cross entropy\nloss = categorical_crossentropy","77736559":"# Define the optimizer\noptimizer = Adam(lr=0.0005)","10f84098":"# Compile the model\nmodel.compile(loss=loss, optimizer=optimizer, metrics=[\"categorical_accuracy\"])","af65a4d2":"# Let's see the model configuration\nmodel.summary()","ba23faab":"# Split the data into train and validation parts\ntrain_X, val_X, train_y, val_y = train_test_split(X, y.values, random_state=1)\n\nprint(\"The train image shape: {}\".format(train_X.shape))\nprint(\"The train label shape: {}\".format(train_y.shape))","3b1e71f1":"# Define the augmentation properties\ngenerator = ImageDataGenerator(#featurewise_center=True,\n                               #samplewise_center=True,\n                               #featurewise_std_normalization=True,\n                               #samplewise_std_normalization=True,\n                               #zca_whitening=False,\n                               #zca_epsilon=1e-06,\n                               rotation_range=10,\n                               width_shift_range=0.1,\n                               height_shift_range=0.1,\n                               #brightness_range=None,\n                               shear_range=5,\n                               zoom_range=0.1,\n                               cval=0.0,)\n\n# Fit the augmentation to the images\ngenerator.fit(X)\n\nX_augmented, y_augmented = generator.flow(train_X, train_y, batch_size=batch_size).next()\n\n# Plot some augmented images\nplot_sample_images(X_augmented[:10,:,:,0], encoder.inverse_transform(y_augmented)[:10,0], 10)","9b9b3164":"# Let's train the model\nhistory = model.fit_generator(generator.flow(train_X, train_y, batch_size=batch_size),\n                              steps_per_epoch=len(train_X) \/ batch_size,\n                              validation_data=[val_X, val_y],\n                              epochs=epochs)","4879c040":"def plot_history(history):# Plot the loss and accuracy\n    # Format the train history\n    history_df = pd.DataFrame(history.history, columns=history.history.keys())\n\n    \n    # Plot the accuracy\n    fig = plt.figure()\n    fig.set_size_inches(18.5, 10)\n    ax = plt.subplot(211)\n    ax.plot(history_df[\"categorical_accuracy\"], label=\"categorical_accuracy\")\n    ax.plot(history_df[\"val_categorical_accuracy\"], label=\"val_categorical_accuracy\")\n    ax.legend()\n    plt.title('Score during training.')\n    plt.xlabel('Training step')\n    plt.ylabel('Accuracy')\n    plt.grid(b=True, which='major', axis='both')\n    \n    # Plot the loss\n    ax = plt.subplot(212)\n    ax.plot(history_df[\"loss\"], label=\"loss\")\n    ax.plot(history_df[\"val_loss\"], label=\"val_loss\")\n    ax.legend()\n    plt.title('Loss during training.')\n    plt.xlabel('Training step')\n    plt.ylabel('Loss')\n    plt.grid(b=True, which='major', axis='both')\n    \n    plt.show()","3da07753":"plot_history(history)","5ef3be15":"# The result seems to be good, so let's train the data on the whole train dataset\n\n# Reinitialize the model\n#model = model_definition()\n\n# Compile the model\nmodel.compile(loss=loss, optimizer=optimizer, metrics=[\"categorical_accuracy\"])\n\n# Train the model on the full train data\nfinal_history = model.fit_generator(generator.flow(X, y, batch_size=batch_size),\n                                              steps_per_epoch=len(X) \/ batch_size,\n                                              epochs=epochs)","c51bf1b6":"def plot_history(history):# Plot the loss and accuracy\n    # Format the train history\n    history_df = pd.DataFrame(history.history, columns=history.history.keys())\n    display(history_df)\n    \n    fig = plt.figure()\n    ax = plt.subplot(111)\n    for i in range(history_df.shape[1]):\n        ax.plot(history_df.iloc[:,i], label=history_df.columns[i])\n    ax.legend()\n    plt.title('Score() and loss during training.')\n    plt.xlabel('Training step')\n    plt.ylabel('Accuracy and Loss')\n    plt.grid(b=True, which='major', axis='both')\n    plt.show()\n\nplot_history(final_history)","93b8022a":"# Path of the file to read.\ntrain_file_path = '..\/input\/test.csv'\n\n# Read the file\ntest_data_orig = pd.read_csv(train_file_path)\n\n# The shape of the data\ntest_data_orig.shape","d0466011":"# Let's reshape the images and view some\nX_test_reshaped = test_data_orig.values.reshape(-1, 28, 28, 1)\nprint(X_test_reshaped.shape)\n# Choose how many images you would like to see\nimages_to_show = 30\n\nplot_sample_images(X_test_reshaped[:, :, :, 0], np.zeros((X_test_reshaped.shape[0])), images_to_show=images_to_show)","a87321d0":"# Scale the image pixel values from 0-255 to 0-1 range so the neural net can to converge faster\nX_test_scaled = X_test_reshaped \/ 255\n\n# The final X_test\nX_test = X_test_scaled","cb551d8d":"# Predict the labels\ntest_preds_unscaled = model.predict(X_test)","a95f5474":"# Inverse transform the predictions to the original scale\ntest_preds = encoder.inverse_transform(test_preds_unscaled)[:,0]","a03f447d":"# Save the predictions\noutput = pd.DataFrame({'ImageId': range(1, test_preds.shape[0] + 1),\n                       'Label': test_preds})\n\noutput.to_csv('submission.csv', index=False)","ff7f1af6":"model.summary()","b6c22894":"# Get the output of the last activation function\nlayer_name = 'dense_4'\n\n# Define an intermediate model\nintermediate_layer_model = Model(inputs=model.input,\n                                 outputs=model.get_layer(layer_name).output)\n\n# Calculate the values of the intermediate model\nintermediate_output = intermediate_layer_model.predict(X)","9f67156e":"PCA_transformer = PCA()\n        \n# Fit and transform\nactivation_7_PCA = PCA_transformer.fit_transform(intermediate_output)","bff68435":"# %matplotlib inline\nnumber_of_points = 10000\n\nx1 = activation_7_PCA[:number_of_points, 0]\nx2 = activation_7_PCA[:number_of_points, 1]\n\nfig = plt.figure()\nfig.set_size_inches(18.5, 10)\n\nplt.scatter(x=x1,\n            y=x2,\n            c=(y_orig[:number_of_points])[:, 0],\n            cmap=\"tab10\")\n\nax = plt.subplot(111)\n\nfor i in range(number_of_points):\n    if not i % 100:\n        ax.annotate(str(y_orig[i]), (x1[i], x2[i]))\n\nplt.title('Last layer visualization using PCA 2D')\nplt.show()","67b23bc4":"\nfrom mpl_toolkits.mplot3d import Axes3D\n\nnumber_of_points = 1000\n\nx1 = activation_7_PCA[:number_of_points, 0]\nx2 = activation_7_PCA[:number_of_points, 1]\nx3 = activation_7_PCA[:number_of_points, 2]\n\nfig = plt.figure()\nfig.set_size_inches(10, 10)\n\n\n\nax = plt.subplot(111, projection='3d')\n\nax.scatter(xs=x1,\n            ys=x2,\n            zs=x3,\n            c=(y_orig[:number_of_points])[:,0],\n            cmap=\"tab10\",)\n\nfor i in range(number_of_points):\n    if not i % 10:\n        ax.text(x1[i], x2[i], x3[i], str(y_orig[i]))\n\nplt.title('Last layer visualization using PCA 3D')\nplt.show()","d0c73604":"augmented_data_batch = 100000\nX_aug, y_aug_real_unscaled = generator.flow(X, y.values, batch_size=augmented_data_batch).next()\n\n# Print examples when the model made bad decisions\ny_aug_preds_unscaled = model.predict(X_aug)\n# Inverse transform the predictions to the original scale\ny_aug_preds = encoder.inverse_transform(y_aug_preds_unscaled)\ny_aug_real = encoder.inverse_transform(y_aug_real_unscaled)","1c755f4e":"y_aug_all = pd.DataFrame([y_aug_preds[:,0], y_aug_real[:,0]]).transpose()\ny_aug_all.columns = [\"y predicted\", \"y real\"]\ny_aug_all.head(10)\nplot_sample_images(X_aug[:10, :, :, 0], y_aug_real, 10, random=False)","d9b43a9b":"pred_errors = y_aug_all[y_aug_all['y predicted'] != y_aug_all['y real']]\ntotal_errors = pred_errors.shape[0]\n\nprint(\"The total number of errors from {} augmented image: {}\".format(augmented_data_batch, total_errors))\nprint(\"Which is {0:.3f}%\".format(total_errors\/augmented_data_batch * 100))","8b492e79":"errors_by_category = []\nerror_count_by_category = []\n\nfor i in range(n_y):\n    \n    errors_by_category.append(pred_errors[pred_errors[\"y real\"] == i])\n\n    error_count_by_category.append(errors_by_category[i].shape[0])\n\nerror_count_by_category_df = pd.DataFrame(error_count_by_category).transpose()\n\nprint(\"Number of errors by category: \")\ndisplay(error_count_by_category_df)\n\nfig = plt.figure()\nax = plt.subplot(111)\nplt.bar(x=error_count_by_category_df.columns, height=error_count_by_category_df.values[0]\/total_errors * 100)\n\nplt.title('Percentage of error by category')\nplt.xlabel('Categories')\nplt.ylabel('Percentage of error (%)')\n#plt.xticks(range(n_y))\nplt.show()","7f48ba85":"for errors in errors_by_category:\n    plot_sample_images(X_aug[errors.index, :, :, 0], errors[\"y predicted\"].values, 10, random=False)\n    plt.show()","b867ec6c":"This notebook is focusing on data analysis, visualizations ans error analysis. Brought to you by eLearn:inga","3a1a9812":"## Simple model definition","d2afa3e5":"### Import the test data","a7ac115b":"### Error analysis","4a973efe":"### Image augmentation","0c70de5b":"### Transform the test data","631d91ba":"### Predict the output values","084f6bcd":"### Show the learned visualization by PCA","6c128c96":"# >99.4% model + PCA visualizations + Error analysis","cd8e777a":"## Data exploration"}}