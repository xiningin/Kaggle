{"cell_type":{"b255c8b9":"code","3ecc295b":"code","a127604f":"code","9c5502b4":"code","af1659b1":"code","0e8c3204":"code","be8c57cb":"code","33c387ba":"code","f4f3c2ee":"code","13d33bf7":"code","eb3ddbf4":"code","f7b0e406":"code","545abb7d":"code","036d9e6a":"code","bca62f6e":"code","f881f035":"code","ac8d392a":"code","8bd2724a":"code","c7d67ce1":"code","54801aff":"code","8d092214":"code","b55e123c":"code","ee655455":"code","9bf9fce7":"code","9f7cbb34":"code","f0ae20e6":"code","ad010ab2":"code","b8fdb505":"code","36449829":"code","64a74763":"code","94931bc5":"code","b929286b":"code","32df0aa1":"code","eeeab04c":"code","fd2299f5":"code","6896fe64":"code","1849fd0b":"code","3def31b2":"code","6d437683":"code","fa4fc2f5":"code","ad746353":"code","16f95346":"code","e21a9cc1":"code","ac1e8770":"code","6cce4330":"code","e84ee03c":"code","79d8b742":"markdown","8eea413a":"markdown","e92b6074":"markdown","ac924ae7":"markdown","7d4f9ff9":"markdown","0a0bfe7e":"markdown","bfa12507":"markdown","f3595ee6":"markdown","4da1074b":"markdown","6aa83921":"markdown","035b6e63":"markdown","fa9b4bad":"markdown","ff601ed0":"markdown","c6dfd9e3":"markdown","89bae0c8":"markdown","1232b57a":"markdown","40780e17":"markdown","f9d9ad1b":"markdown","549c8c93":"markdown","03a30bc5":"markdown","285d527c":"markdown","580bfea5":"markdown","2094e56d":"markdown","545561a0":"markdown","bd8eeba6":"markdown","bece498d":"markdown","a292d942":"markdown","f54b096f":"markdown","3644a8d2":"markdown","c1e31b57":"markdown","9a09efb5":"markdown","68119e50":"markdown","e7c72497":"markdown","2687be30":"markdown"},"source":{"b255c8b9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd# data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import OneHotEncoder,MinMaxScaler\nfrom sklearn.impute import KNNImputer\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score,auc,roc_curve\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3ecc295b":"file =pd.read_csv('\/kaggle\/input\/mri-and-alzheimers\/oasis_longitudinal.csv')","a127604f":"file.head()","9c5502b4":"def sepdatatype(data):\n    categorical_data=pd.DataFrame()\n    numerical_data=pd.DataFrame()\n    \n    for col in data.columns:\n        if data[col].dtype=='O':\n            categorical_data = pd.concat([categorical_data,pd.DataFrame(data[col])],axis=1)\n        else:\n            numerical_data = pd.concat([numerical_data,pd.DataFrame(data[col])],axis=1)\n    return categorical_data,numerical_data","af1659b1":"[cat_data,num_data]=sepdatatype(file)","0e8c3204":"num_data.describe()","be8c57cb":"Label = pd.DataFrame(cat_data['Group'])","33c387ba":"cat_data = cat_data.drop(['Subject ID','MRI ID','Group'],axis=1)","f4f3c2ee":"onc = OneHotEncoder()\ncat2num = pd.DataFrame(onc.fit_transform(cat_data).toarray())","13d33bf7":"cat2num","eb3ddbf4":"cat2num=cat2num.drop([2],axis=1)","f7b0e406":"def olrem(data):\n    length = data.shape[0]\n    Q1 = data.quantile(0.25)\n    Q3 = data.quantile(0.75)\n    IQR = Q3 - Q1\n    lrange = Q1 - 1.5*IQR\n    urange = Q3 + 1.5*IQR\n    for i in range(length):\n        \n        if data[i]<lrange or data[i]>urange:\n            data[i]=0\n        \n    return data  ","545abb7d":"def repol(data):\n    length = data.shape[0]\n    for col in data.columns:\n        \n        Q1 = data[col].quantile(0.25)\n        Q3 = data[col].quantile(0.75)\n        IQR = Q3 - Q1\n        lrange = Q1 - 1.5*IQR\n        urange = Q3 + 1.5*IQR\n        \n        mn = olrem(data[col]).mean()\n        for j in range(length):\n            \n            if data[col][j]<lrange or data[col][j]>urange:\n                data[col][j] = mn\n    return data","036d9e6a":"olrnum_data = repol(num_data)","bca62f6e":"olrnum_data","f881f035":"olrnum_data.isna().sum()","ac8d392a":"imputer = KNNImputer()\nimputed = imputer.fit_transform(olrnum_data)\nimputed_data = pd.DataFrame(imputed,columns = olrnum_data.columns)","8bd2724a":"imputed_data.isna().sum()","c7d67ce1":"total_data = pd.concat([imputed_data,cat2num,Label],axis = 1)","54801aff":"sns.countplot(x='Group',data = total_data)","8d092214":"total_data['Group'] = total_data['Group'].replace(['Nondemented','Demented','Converted'],[0,1,1])","b55e123c":"sns.countplot(x='Group',data = total_data)","ee655455":"\ny= total_data['Group']\n","9bf9fce7":"X= total_data.drop(['Group'],axis = 1)","9f7cbb34":"X_train,X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state = 22)","f0ae20e6":"X","ad010ab2":"scaling = MinMaxScaler()\nXs = scaling.fit(X_train)\nX_train = Xs.transform(X_train)\nX_test = Xs.transform(X_test)","b8fdb505":"L = [0.0001,0.001,0.01,0.1]\nsolver =['lbfgs','adam']\nactivation =['logistic','tanh','relu']\nlearning_rate = ['constant','adaptive']\nhidden_layer_sizes=[25,50,100,150]\n\nparameters = {\n              'learning_rate_init' : L,\n              'solver':solver,\n              'activation':activation,\n              'learning_rate':learning_rate,\n              'hidden_layer_sizes':hidden_layer_sizes\n}\nmlp = MLPClassifier()\n\nmlprandom = RandomizedSearchCV(estimator = mlp,param_distributions = parameters, n_iter = 100, cv=3, n_jobs = -1,random_state=42)\n","36449829":"mlprandom.fit(X_train, y_train)","64a74763":"mlprandom.best_params_","94931bc5":"L = [0.005, 0.009,0.01,0.05,0.09,0.1]\nsolver =['lbfgs','adam']\nactivation =['logistic','tanh']\nlearning_rate = ['constant','adaptive']\nhidden_layer_sizes=[80,100,120,140]\n\nparameters = {\n              'learning_rate_init' : L,\n              'solver':solver,\n              'activation':activation,\n              'learning_rate':learning_rate,\n              'hidden_layer_sizes':hidden_layer_sizes\n}\n\nmlpgrid = GridSearchCV(estimator = mlp,param_grid = parameters, cv=3, n_jobs = -1)\n","b929286b":"mlpgrid.fit(X_train,y_train)","32df0aa1":"mlpgrid.best_params_","eeeab04c":"mlpfinal = MLPClassifier(solver='adam', learning_rate_init = 0.005, learning_rate = 'constant', hidden_layer_sizes = 80, activation = 'logistic')","fd2299f5":"mlpfinal.fit(X_train,y_train)","6896fe64":"predictionm = mlpfinal.predict(X_test)\nacc = accuracy_score(y_test,predictionm)\nacc","1849fd0b":"from sklearn.model_selection import cross_val_score\n\nscore = cross_val_score(mlpfinal,X_train,y_train,cv=5)\n\nscore","3def31b2":"rfcl = RandomForestClassifier()\nn_estimators =[50,100,150,200,250]\ncriterion = ['gini','entropy']\nmin_samples_split = [2,3,5,7]\nmin_samples_leaf = [0.05,0.08,1,1.5,2,2.5,3]\nmax_features = ['auto','sqrt','log2']\nbootstrap = [True, False]\n\nrfparam = {\n           'n_estimators' : n_estimators,\n           'criterion' : criterion,\n           'min_samples_split' : min_samples_split,\n           'min_samples_leaf' : min_samples_leaf,\n           'max_features' : max_features,\n           'bootstrap' : bootstrap\n          }\nrfgrid = GridSearchCV(estimator = rfcl, param_grid = rfparam,cv=5, n_jobs = -1)","6d437683":"rfgrid.fit(X_train,y_train)","fa4fc2f5":"rfgrid.best_params_","ad746353":"rffinal = RandomForestClassifier(bootstrap=True, criterion = 'gini', max_features = 'auto', min_samples_leaf = 0.05, n_estimators = 50, min_samples_split = 5)","16f95346":"rffinal.fit(X_train,y_train)\npredictionr = rffinal.predict(X_test)\nacc_sc = accuracy_score(y_test,predictionr)\nacc_sc","e21a9cc1":"fprr,tprr,thr = roc_curve(y_test,predictionr)\nauc(fprr,tprr)","ac1e8770":"import matplotlib.pyplot as plt\nplt.plot(fprr, tprr, linestyle='--')\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n\nplt.legend()\n\nplt.show()","6cce4330":"from sklearn.model_selection import cross_val_score\nrffoldscore = cross_val_score(rffinal,X_train,y_train,cv=5)\n\nrffoldscore\nplt.hist(rffoldscore)","e84ee03c":"fi = pd.DataFrame(rffinal.feature_importances_)\nfi = fi.T\nfi\nfi.columns = X.columns\nfi.plot.bar()","79d8b742":"It can be seen that, there are three classes, Demented, nondemented and converted. But , here the converted class is for the group of people, who has been diagnosed with ALzheimer's diseases lately, but earlier they were not diseased. So, according to the current condition converted can be considered as Demented. So, that wholedata set is now separated into two classes, where nondemanted is labelled with 0 and demented is labelled with 1.","8eea413a":"So, the feature set and the labels are separated into two groups, named X and y respectively. \n\nNow they are splitted in train and test data set with train test ration 70:30","e92b6074":"Now, the imputed_data is the data set after imputing. Now we can check weather the data set is free of NAN values","ac924ae7":"The feature set is not standardized yet. So, we should standardize the feature set. Now the train data set is used to evaluate the parameters mean, maximum value and minimum value and then these are used to scale both train and test set. Here, the maximum value will be 1 and minimum value will be 0 and others will be in between.","7d4f9ff9":"The dataset is checked if there is any imbalance between classes. But, as the difference between classes is not significant, so it is better not to assign any prcossed data.","0a0bfe7e":"As the model is trained with data set, now we can get the best parameters derived from rNdom search.","bfa12507":"So, fold validation score of 0.98, 0.97 and 0.91 are received for 3 folds and 0.94 is received for 2 folds.","f3595ee6":"The 5 fold cross validation results are also checked.","4da1074b":"AUC score is calculated and ROC curve is plotted to check the performance","6aa83921":"It can be seen that CDR and MMSE are most important testing criterias for the evaluation. nWBV comes in the third place. ","035b6e63":"Now the trained model is ready to predict the test data set and prediction accuracy can be evaluated from that.","fa9b4bad":"The data set is comprised of 15 columns. The group column represents the label here. It tells about the popultaion divided into demented and nondemented group. Therefore, there are total 14 features. It can be seen that, 5 features are categorical and 9 features are numerical.","ff601ed0":"These are 5 fold cross validation accuracy results: 92.5%, 96.2%, 96.2%, 96.2% and 92.3%","c6dfd9e3":"So, the olrnum_data is the modified dataset, outliers replaced by the mean of the outlier removed data set.\n","89bae0c8":"Now the same process has been applied from Random Forest Classifier","1232b57a":"Now the MLP classifier has been finally trained with the evaluated best set of parameters. ","40780e17":"As the gender column has two kind of different data Male and Female, it should give two column data output. But for another feature, which is hand, there is only one column, which depicts there is only one kind of data. It means the feature is not useful.\nSo the column will be dropped.","f9d9ad1b":"One hot encoding provides the encoded data set with, one unit enables and othe units disabled. Therefore, number of variations in the data set is number of columns in encoded data set. ","549c8c93":"The 'Group' column of the categorical data is identified as Label.","03a30bc5":"Now, the whole feature set will be received after collating the processed numericla data set and converted categorical data set.","285d527c":"This is very clear that the any kind of indentification parameters are not very useful for training the model. The IDs and the label are dropped down from the categorical data set, which leaves with 2 categorical features.","580bfea5":"It can be observed that only two features have NAN values, SES has 19 NAN values and MMSE has 2.","2094e56d":"Now it is time to build and train models for learning the data set.","545561a0":"First, the MLP (Multi Layer Perceptron) classifier is used. A few hyperparameters are assigned with a set of values. The best hyperparameter values will be received after feeding the dataset.\nRandom Search cross validation technique is used to evaluate the best hyperparameter.","bd8eeba6":"From the Random Forest model,the accuracy received is 91%","bece498d":"Now, we have to check for NAN values in the featureset. ","a292d942":"Now, we have used Grid Search Cross Validation with the best hyper parameters and it's nearby values to get more accurate idea about the preferrable hyper parameters. ","f54b096f":"This function is designed to replace the outlier values with mean of the outlier removed columns.","3644a8d2":"Here testing accuracy of 92% is received.","c1e31b57":"The function \"sepdatatype\" has been formed to separate these two type of data types, categorical and numerical. ","9a09efb5":"The function 'olrem' is designed to remove the outliers from a column and get the reduced data set. This will give imbalanced data set, because every column will have different number of outliers. So, this will only be used to replace the outliers with the mean of outlier removed data set.","68119e50":"Importance of features is evaluated and depicted through bar plot.","e7c72497":"After training, best hyperparameters have been recieved. ","2687be30":"To replace the NAN values, the imputer has to be used. Here KNN imputer method has been applied, where the postional NAN values are replaced by the possible values from neighbouring elements."}}