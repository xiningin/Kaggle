{"cell_type":{"2373ef06":"code","8aa87a70":"code","f57ab3f1":"code","ce18dab3":"code","01dfc93b":"code","ab607ad4":"code","76c93c69":"code","47a48d8a":"code","4839b991":"code","7dafea83":"code","dcb03b46":"code","a84689ed":"code","6af333ad":"code","aac6e831":"code","acc69514":"code","a6c7247e":"code","a4436904":"code","296a9635":"code","1d31ecb6":"code","73a348cf":"code","dcbfc75b":"code","6b42e183":"code","122a0584":"code","d77752b9":"code","bad03f26":"code","c4c223c1":"code","1d1d7f64":"code","01be821f":"code","a6dcf5ef":"code","192591c6":"code","ab04ce8b":"code","a958088b":"code","870b0b40":"code","de479838":"code","75e07e33":"code","3052ddb9":"code","13d94f47":"markdown","b3426180":"markdown","559f28f0":"markdown","ff85f301":"markdown","30a7aad9":"markdown","b2f2f620":"markdown","6fbe4d8b":"markdown","606dbe2a":"markdown","e5b3604f":"markdown","8cbca57b":"markdown","bb1794f0":"markdown","85f77b11":"markdown","b4063d62":"markdown","64991889":"markdown","19e0cd5b":"markdown","c5e08368":"markdown","a6a3bf65":"markdown","5af90b3c":"markdown","90eec4ce":"markdown","fa531806":"markdown","6094936d":"markdown","e6dbf2a1":"markdown","c9973da2":"markdown","64331d42":"markdown","b5d36d3f":"markdown","5877893c":"markdown","478ebd4f":"markdown","4ca905c6":"markdown","22da1142":"markdown","17cd5b65":"markdown","6e505379":"markdown","558283fa":"markdown","80829c96":"markdown","a40ef1c4":"markdown","2399943d":"markdown","a322da64":"markdown","7e64bca8":"markdown","761271c5":"markdown","8e4b2b62":"markdown","2126a920":"markdown"},"source":{"2373ef06":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8aa87a70":"import numpy as np\nimport pandas as pd\n\nimport missingno as msno\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Colors are at https:\/\/developer.mozilla.org\/en-US\/docs\/Web\/CSS\/color_value","f57ab3f1":"df_RESULT = pd.DataFrame()","ce18dab3":"def percent(val, total):\n    return round(100 * val\/total, 2)","01dfc93b":"# Helper functions\ndef printCols(cat, cols, cols_top3, cols_other, cols_none):\n    print(f\"COLS_{cat}       {len(cols):2d}\", end=': ');          [print(col[0], end=', ') for col in cols]; print()\n    print(f\"COLS_{cat}_TOP3  {len(cols_top3):2d}\", end=': ');     [print(col, end=', ') for col in cols_top3]; print()\n    print(f\"COLS_{cat}_OTHER {len(cols_other):2d}\", end=': ');    [print(col[0], end=', ') for col in cols_other]; print()\n    print(f\"COLS_{cat}_NONE  {len(cols_none):2d}\", end=': ');     [print(col[0], end=', ') for col in cols_none]; print()\n\ndef getCols(cat, colprefix,colnone):\n    PREFIX_LEN = len(colprefix)\n    COLS_NONE = list(filter(lambda x: True if x[0]==colnone else False, df.columns.to_list()))\n    COLS = list(filter(lambda x: True if x[0][:PREFIX_LEN]==colprefix and x not in COLS_NONE else False, df.columns.to_list()))\n    COLS_TOP3    = [x[0] for x in df[COLS].count().sort_values(ascending=False).index[:3].values]\n    COLS_OTHER   = list(filter(lambda x: True if x[0] not in COLS_TOP3 else False, COLS))\n    #printCols(cat, COLS, COLS_TOP3, COLS_OTHER, COLS_NONE)\n    return COLS, COLS_TOP3, COLS_OTHER, COLS_NONE\n    \ndef convert2percent(df, col, total_col):\n    df[col] = df[col]\/ df[total_col]\n    return df[col].apply(lambda x: round(x*100,2))\n\n# Inplace of column with string values, create a new column with 1s & 0s \n# Old: df[('Q7_Part_1', 'What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Python')] = 'Python'\n# New: df['Python'] = 1\ndef createNewCol(df_old, oldCol, df_new, newCol, value):\n    df_new[newCol] = df_old[oldCol]\n    # strip the value of the leading and trailing empty spaces\n    df_new.loc[~df_new[newCol].isnull(), newCol] = df_new[~df_new[newCol].isnull()][newCol].apply(lambda x: x.strip())\n    return  df_new[newCol].apply(lambda x: 1 if x== value else 0)\n\n# Create a dataframe with overall and specific category values. Plot a bar graph to compare \ndef compare(df, df_overall, df_specific, cat_other, col_other, ax, title=''):\n    # Create a df with the overall users as percentage\n    df_all = pd.DataFrame()\n    df_all.loc['Count','Overall']=df.shape[0]\n    df_all = pd.concat([df_all, df_specific])\n    df_all.loc[cat_other,'Overall']=df_all.loc[cat_other,'Overall']\/len(col_other)\n    df_all['Overall'] = df_all['Overall'].apply(lambda x: round((x\/df.shape[0])*100,2))\n    #df_pl_all\n\n    # Create different df for woman < 40 and woman > 40\n    df_woman_lt40 = df_overall.loc[('<40', 'Woman'),:].to_frame()#; print(\"df_pl_woman_lt40\\n\", df_pl_woman_lt40);print()\n    df_woman_gt40 = df_overall.loc[('>40', 'Woman'),:].to_frame()#; print(\"df_pl_woman_gt40\\n\", df_pl_woman_gt40)\n\n    # Concatenate the overall and the woman < 40 and woman > 40 data \n    df_temp = pd.concat([df_all, df_woman_lt40, df_woman_gt40], axis=1, join='inner') \n    #print(df_temp)\n    df_temp.drop('Count', inplace=True)\n    ax = df_temp.plot.bar( ylim=(0,100), ax=ax);annotate(ax, title) #figsize=(15, 6),\n    return df_temp\n\n# This uses seaborn library to plot the bar plot and udpates the dataframe accordingly\ndef compare_sb(df, df_summary, df_temp, cat_other, col_other, ax, title=''):\n    othercol = cat_other\n    #print(\"df_temp- before\\n\", othercol, df_temp)\n\n    df_temp['Count'] = df_temp['Overall'].apply(lambda x: round((x\/df.shape[0])*100,2))\n    df_temp['Age-Group'] = 'Overall'\n    df_temp.reset_index(inplace=True)\n    df_temp.rename(columns={'index':'Category'}, inplace=True)\n    #print(df_temp[df_temp['Category']==othercol]['Count'] )\n    df_temp.loc[df_temp['Category']==othercol,'Count'] = df_temp[df_temp['Category']==othercol]['Count'].apply(lambda x: round(x\/len(COLS_OTHER),2))\n    df_temp.drop(columns=['Overall'], inplace=True)\n    #print(\"df_temp - after\\n\", df_temp)\n\n    df_summary = df_summary.drop(columns='Count').stack().reset_index()\n    df_summary.rename(columns={'level_2':'Category', 0:'Count'}, inplace=True)\n    df_summary = df_summary[df_summary['Gender']=='Woman']\n    df_summary['Age-Group'] = df_summary[['AgeGroup', 'Gender']].apply(lambda row: '-'.join(row.values.astype(str)), axis=1)\n    df_summary.drop(columns=['AgeGroup','Gender'],inplace=True)\n    df_summary = pd.concat([df_temp, df_summary])\n    #print(df_summary)\n\n    #plt.figure(figsize=(15,6))\n    ax = sns.barplot(x='Category', y='Count', hue='Age-Group', data=df_summary)\n    ax.set_title(title); ax.set_xlabel(''); ax.set_ylabel(''); ax.set_ylim([0, 100])\n    for i in range(3):\n        #ax.bar_label(ax.containers[i], fmt='%.1f%')\n        ax.bar_label(container = ax.containers[i], labels = [f'{value:2.1f}%' for value in ax.containers[i].datavalues])\n\n# Create a dataframe with users wrt Age-group and Gender \ndef createSpecificAndSummary(df,topcol1, topcol2, topcol3, othercol, nonecol, othercols):\n    df_temp = df.agg({topcol1:np.sum,topcol2:np.sum,topcol3:np.sum, othercol:np.sum, nonecol:np.sum}).to_frame()\n    df_temp.rename(columns={0:\"Overall\"}, inplace=True)\n    #print(df_temp)\n\n    df_summary = df.groupby(by=['AgeGroup','Gender']).agg({'AgeGroup':'count',topcol1:np.sum,topcol2:np.sum,topcol3:np.sum, othercol:np.sum, nonecol:np.sum})\n    df_summary.rename(columns={\"AgeGroup\":\"Count\"}, inplace=True)\n\n    df_summary[topcol1] = convert2percent(df_summary,topcol1,\"Count\")\n    df_summary[topcol2] = convert2percent(df_summary,topcol2,\"Count\")\n    df_summary[topcol3] = convert2percent(df_summary,topcol3,\"Count\")\n\n    df_summary[othercol]  = df_summary[othercol]\/ df_summary[\"Count\"]\n    df_summary[othercol]  = df_summary[othercol].apply(lambda x: round(x*100\/len(othercols),2))\n\n    df_summary[nonecol]   = convert2percent(df_summary,nonecol,\"Count\")\n    df_summary['Count']   = df_summary['Count'].apply(lambda x: round((x\/df.shape[0])*100,2))\n    return df_temp, df_summary\n\n# Summarise the values of the category - total, top 3 values, other & none\ndef summarise(df, df_new, cat, cols, cols_other, col_none, \n                        top1col1, top1col2, top1val, \n                        top2col1, top2col2, top2val, \n                        top3col1, top3col2, top3val, ax=None, title=\"\"):\n\n    COL_COUNT, COL_OTHER, COL_NONE = f'{cat}-Count', f'{cat}-Other', f'{cat}-None'\n\n    df_new[COL_COUNT]  = df[cols].count(axis=1)\n    df_new[top1col2]   = createNewCol(df, top1col1 , df_new, top1col2, top1val)\n    df_new[top2col2]   = createNewCol(df, top2col1 , df_new, top2col2, top2val)\n    df_new[top3col2]   = createNewCol(df, top3col1 , df_new, top3col2, top3val)\n    df_new[COL_NONE]   = createNewCol(df, col_none, df_new, COL_NONE, \"None\")\n    df_new[COL_OTHER]  = df[cols_other].count(axis=1) \n    df_new[COL_COUNT]  = df[cols].count(axis=1) # None is not considered\n\n    # Fill None for rows where no option was selected\n    #print(\"BEFORE\", df_new[(df_new[COL_COUNT]==0)][COL_COUNT].sum(), df_new[COL_NONE].sum())\n    df_new.loc[(df_new[COL_COUNT]==0) & (df_new[COL_NONE]==0), COL_NONE] = 1\n    #print(\"AFTER\", df_new[COL_NONE].sum())\n\n    #print(df_new.head())\n    # Update the median and max values in the df_RESULT\n    df_RESULT.loc[cat,'Count-Median'] = df_new[COL_COUNT].median()\n    df_RESULT.loc[cat,'W<40-Median'] =df_new[(df_new['Gender']=='Woman')&(df_new['AgeGroup']=='<40')][COL_COUNT].median()\n    df_RESULT.loc[cat,'W>40-Median'] =df_new[(df_new['Gender']=='Woman')&(df_new['AgeGroup']=='>40')][COL_COUNT].median()\n    df_RESULT.loc[cat,'Count-Max'] = df_new[COL_COUNT].max()\n    df_RESULT.loc[cat,'W<40-Max'] =df_new[(df_new['Gender']=='Woman')&(df_new['AgeGroup']=='<40')][COL_COUNT].max()\n    df_RESULT.loc[cat,'W>40-Max'] =df_new[(df_new['Gender']=='Woman')&(df_new['AgeGroup']=='>40')][COL_COUNT].max()\n\n    # Create a df with the IDE and total number of IDE users\n    df_temp, df_summary = createSpecificAndSummary(df_new, top1col2, top2col2, top3col2, COL_OTHER, COL_NONE, cols_other)\n\n    #df_ = compare(df, df_summary, df_temp, COL_OTHER, cols_other, ax, title)\n    df_ = compare_sb(df, df_summary, df_temp, COL_OTHER, cols_other, ax, title)\n    #plotBox(df_new, COL_COUNT)  \n    return df_#, df_temp, df_summary     ","ab607ad4":"def plotBox(df, col):\n    df_man = df[df['Gender']=='Man'][['AgeGroup', col]]#;print(df_man.head())\n    df_woman = df[df['Gender']=='Woman'][['AgeGroup', col]]#;print(df_woman.head())\n    plt.figure(figsize=(18, 5), dpi=80)\n\n    ax = plt.subplot(1, 4, 1); df_woman[df_woman['AgeGroup']=='<40'].hist(ax=ax); plt.title('Woman < 40')\n    ax = plt.subplot(1, 4, 2); df_woman[df_woman['AgeGroup']=='>40'].hist(ax=ax); plt.title('Woman > 40') \n    ax = plt.subplot(1, 4, 3); df_man.boxplot(by='AgeGroup', ax=ax); ax.set_title('Man')        \n    ax = plt.subplot(1, 4, 4); df_woman.boxplot(by='AgeGroup',ax=ax); ax.set_title('Woman') \n\ndef plotSankey(nodes, links, title, width, height):\n    data = go.Sankey(node = nodes, link = links)\n    fig = go.Figure(data)\n    fig.update_layout(title=title,  font_size=16, width=width,height=height,)\n    fig.show()\n\ndef showTreeMap(df, tree, values, title):\n    fig = px.treemap(df, path=[px.Constant(\"all\")] + tree, values=values,     \n                    color_discrete_map={'(?)':'lightgrey', 'Lunch':'gold', 'Dinner':'darkblue'})\n    fig.update_traces(root_color=\"lightgrey\")\n    #fig.update_traces(hovertemplate=)\n    fig.update_layout(title=title,  margin = dict(t=50, l=25, r=25, b=25))\n    fig.show()\n\ndef annotate(ax, title='', strformat='', divideby=1):\n    # Annotate\n    for p in ax.patches:\n        # format(, '.1f')\n        value = p.get_height()\/divideby\n        ax.annotate(f\"{value:.1f}{strformat}\", \n                    (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                    ha = 'center', va = 'center', \n                    xytext = (0, 9), \n                    textcoords = 'offset points')\n    ax.set_title(title)","76c93c69":"df = pd.read_csv('..\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv', header=[0,1])","47a48d8a":"df.info()","4839b991":"print(df.columns.tolist()[0:10])","7dafea83":"df.iloc[0,:].to_frame().to_csv(\"Columns.csv\")","dcb03b46":"msno.matrix(df.iloc[:,:7])","a84689ed":"df_new = pd.DataFrame()\ndf_new['Age']       = df['Q1', 'What is your age (# years)?']\ndf_new['Gender']    = df['Q2', 'What is your gender? - Selected Choice']\ndf_new['Country']   = df['Q3', 'In which country do you currently reside?']\ndf_new.info()","6af333ad":"df_new.groupby(by='Age').agg({\"Age\":'count'}).rename(columns={'Age':'Count'}).reset_index(inplace=True)\nprint(df_new['Gender'].value_counts())\nprint(df_new.head())","aac6e831":"df_new['Gender'] = df_new['Gender'].apply(lambda x: x if x in ['Man', 'Woman'] else 'Other')\ndf_new[\"AgeGroup\"] = df_new['Age'].apply(lambda x: '<40' if x in ['18-21', '22-24', '25-29', '30-34', '35-39'] else '>40')\ndf_new.head()","acc69514":"COLS_GENDER = ['Man', 'Woman', 'Other']\nCOLS_AGE = ['18-29','30-39','40-49','50-59','60-69','70+']\nCOLOR_MAP_GENDER = {'(?)':'lightgrey', 'Man':'dodgerblue', 'Woman':'lightcoral', 'Other':'gold'}\n\ndef getAgeGenderPivotDF():\n    COLS_18_29, COLS_30_39, COLS_40_49, COLS_50_59 = ['18-21', '22-24', '25-29'], ['30-34','35-39'], ['40-44','45-49'], ['50-54','55-59']\n\n    df_ = df_new.groupby(by=['Age','Gender']).agg({'Gender':'count'}).rename(columns={'Gender':'Count'})\n    df_.reset_index(inplace=True)\n    #print(df_.head())\n\n    df_summary = pd.pivot_table(data = df_,  values='Count', index=['Age'], columns=['Gender'], aggfunc=np.sum, fill_value=0)\n    df_summary = df_summary[COLS_GENDER]\n\n    #print(df_summary)\n    df_summary.loc['18-29',COLS_GENDER ] = df_summary.loc[COLS_18_29, COLS_GENDER].sum(); df_summary.drop(index=COLS_18_29, inplace=True)\n    df_summary.loc['30-39',COLS_GENDER ] = df_summary.loc[COLS_30_39, COLS_GENDER].sum(); df_summary.drop(index=COLS_30_39, inplace=True)\n    df_summary.loc['40-49',COLS_GENDER ] = df_summary.loc[COLS_40_49, COLS_GENDER].sum(); df_summary.drop(index=COLS_40_49, inplace=True)\n    df_summary.loc['50-59',COLS_GENDER ] = df_summary.loc[COLS_50_59, COLS_GENDER].sum(); df_summary.drop(index=COLS_50_59, inplace=True)\n    df_summary = df_summary.reindex(index = COLS_AGE)\n    df_summary['Count'] = df_summary['Man'] + df_summary['Woman'] + df_summary['Other']\n    df_summary.reset_index(inplace=True)\n    df_summary[\"AgeGroup\"] = df_summary['Age'].apply(lambda x: '<40' if x in ['18-29','30-39'] else '>40')\n    #print(df_summary)\n    return df_summary\n\ndef plotAgeGenderSankey(df):\n    LABELS  = [ f'[{age}]yrs-{gender}' for age in COLS_AGE for gender in COLS_GENDER  ]#; print(LABELS[0:3])\n    VALUES  = [ int(df[df['Age']==age][col].values[0]) for age in COLS_AGE for col in COLS_GENDER ]#;print(VALUES)\n    NODES   = dict( label = [f'{col} yrs' for col in COLS_AGE] + COLS_GENDER, hovertemplate=\" \",\n                    color = [ \"seagreen\",   \"lightseagreen\",   \"tomato\",  \"orange\",  \"peru\",    \"brown\"] + ['dodgerblue', 'lightcoral', 'gold'],\n                    x     = [ 0.1]*6 + [1]*6,\n                    y     = [ 0.15, 0.5, 0.7, 0.8, 0.9, .95,] + [0.3, 0.75, 0.9])\n    LINKS   = dict( source = [0]*3 + [1]*3 + [2]*3 + [3]*3 + [4]*3 + [5]*3 + [6]*3, target = [ 6, 7, 8]*6, \n                    value =  VALUES, label = LABELS, hovertemplate=\"%{label}\",     \n                    color =  [\"lightgreen\"]*3 + [\"paleturquoise\"]*3 +[\"sandybrown\"]*3 + ['khaki'] * 3 + ['moccasin']*3 + ['bisque']*3)        \n    plotSankey(NODES, LINKS, \"Age & Gender - What is the distribution?\", 1000, 600)\n    # Colors are at https:\/\/developer.mozilla.org\/en-US\/docs\/Web\/CSS\/color_value\n\ndef getAgeGenderDF():\n    df_ = df_new.groupby(by=['Age','Gender','AgeGroup']).agg({'Gender':'count'}).rename(columns={'Gender':'Count'})\n    df_.reset_index(inplace=True)\n    total = df_['Count'].sum()\n    df_[\"Count\"] = df_['Count'].apply(lambda x: percent(x, total))\n    #print(df_.head())\n    return df_","a6c7247e":"def showTreeMap(df, tree, values, title, width, height):\n    fig = px.treemap(df, path=[px.Constant(\"all\")] + tree, values=values,  \n                    color='Gender', color_discrete_map={'(?)':'lightgrey', 'Man':'dodgerblue', 'Woman':'lightcoral', 'Other':'gold'})\n    fig.update_traces(root_color=\"lightgrey\")\n    #fig.update_traces(values=values, hovertemplate='{values}')\n    fig.update_layout(title=title,  width=width, height=height, margin = dict(t=50, l=25, r=25, b=25))\n    fig.show()\n\ndef plotTreeMapSP(df, tree, values, color, colors, fig, row, col):\n    subfig = px.treemap(df, path=[px.Constant(\"all\")] + tree, values=values, color=color, color_discrete_map=colors)\n    #print(type(subfig.data[0]))\n    subfig.update_traces(root_color=\"lightgrey\")\n    #subfig.update_traces(values=df[values], hovertemplate='{values}')\n    subfig.update_layout(width=600, height=400, margin = dict(t=50, l=25, r=25, b=25))\n    fig.add_trace(subfig.data[0], row=row, col=col)\n    return fig\n\ndef plotLineSP(df, x, y, color, colormap, fig, row, col, w, h):\n    subfig = px.line(df, x=x, y=y, color=color, color_discrete_map=colormap)\n    subfig.update_traces(mode=\"markers+lines\", hovertemplate=None)\n    #subfig.update_layout(width=w, height=h, margin = dict(t=50, l=25, r=25, b=25))\n    for data in subfig.data:\n        fig.add_trace(data, row=row, col=col)\n    return fig\n\ndef plotLine(df, x, y, color, colormap, title):#, fig, row, col, w, h):\n    fig = px.line(df, x=x, y=y, color=color, color_discrete_map=colormap)\n    fig.update_traces(mode=\"markers+lines\", hovertemplate=None)\n    fig.update_layout(title=title, width=600, height=400, margin = dict(t=50, l=25, r=25, b=25))\n    fig.show()\n    return fig\n\ndef plotTreeMapLine(df):\n    #print(df.groupby(by=['AgeGroup','Gender']).agg({'Count':np.sum}))\n    fig = make_subplots( cols = 2, rows = 1, column_widths = [0.4, 0.4],\n                        subplot_titles = ('<b>Age & Gender - What is the distribution?<br \/>&nbsp;<br \/>', '<b>Age & number of members<br \/>&nbsp;<br \/>'),\n                        specs = [[{'type': 'treemap', 'rowspan': 1}, {'type': 'Scatter'}]])\n    fig = plotTreeMapSP(df, ['Age', 'Gender'], 'Count', \"Gender\", COLOR_MAP_GENDER, fig, 1, 1)\n    fig = plotLineSP(df, 'Age', 'Count', 'Gender', COLOR_MAP_GENDER, fig, 1, 2, 600, 300 )\n    fig.show()","a4436904":"df_ = getAgeGenderPivotDF(); plotAgeGenderSankey(df_)\ndf_ = getAgeGenderDF(); plotTreeMapLine(df_)\nshowTreeMap(df_, ['AgeGroup', 'Gender'], 'Count',\"Gender & Age Groups\", 1000, 500)","296a9635":"def getAgeGenderCountryPivotDF():\n    df_ = df_new.groupby(by=['AgeGroup','Gender','Country']).agg({'AgeGroup':'count'})\n    df_.rename(columns={'AgeGroup':'Count'}, inplace=True)\n    #print(df_)\n\n    df_summary = pd.pivot_table(df_, index=['Gender', 'AgeGroup'],columns = ['Country'], values ='Count', aggfunc=np.sum).loc[['Man','Woman'],TOP_COUNTRIES]\n    #print(df_summary)\n\n    df_summary['Total'] = 0\n    df_summary.loc[('Man','<40'), 'Total']   = df_.loc[('<40','Man'),:].sum().values[0] # \/ df.shape[0])*100\n    df_summary.loc[('Man','>40'), 'Total']   = df_.loc[('>40','Man'),:].sum().values[0] #\/ df.shape[0])*100 \n    df_summary.loc[('Woman','<40'), 'Total'] = df_.loc[('<40','Woman'),:].sum().values[0] #\/ df.shape[0])*100 \n    df_summary.loc[('Woman','<40'), 'Total'] = df_.loc[('>40','Woman'),:].sum().values[0] #\/ df.shape[0])*100\n    df_summary = df_summary\/ df.shape[0]*100 #.round(2)\n    df_summary = df_summary.round(2)\n    df_summary.reset_index(inplace=True)\n    #print(df_summary.head())\n    return df_summary\n\ndef getAgeGenderCountryDF():\n    df_ = df_new.groupby(by=['AgeGroup','Gender','Country']).agg({'AgeGroup':'count'})\n    df_.rename(columns={'AgeGroup':'Count'}, inplace=True)\n    total = df.shape[0]\n    df_['Count'] = df_['Count'].apply(lambda x: percent(x, total)) \n\n    df_.reset_index(inplace=True)\n    df_ = df_[df_['Country'].isin(TOP_COUNTRIES)]\n\n    #print(df_.head())\n    return df_\n\ndef plotTreeMaps(df):\n    fig = make_subplots(cols = 2, rows = 1, column_widths = [0.4, 0.4],\n                    subplot_titles = ('<b>Gender, Age & Country - Distribution<br \/>&nbsp;<br \/>', '<b>Age Group, Country - Distribution of Women <br \/>&nbsp;<br \/>'),\n                    specs = [[{'type': 'treemap', 'rowspan': 1}, {'type': 'treemap', 'rowspan': 1}]])\n    fig = plotTreeMapSP(df, ['Gender', 'AgeGroup','Country'], 'Count', \"Gender\", COLOR_MAP_GENDER, fig, 1, 1)\n    fig = plotTreeMapSP(df[df['Gender']=='Woman'], ['Gender', 'AgeGroup','Country'], 'Count', \"Gender\", COLOR_MAP_GENDER, fig, 1, 2)\n    fig.show()","1d31ecb6":"df_new.groupby(by='Country').agg({'Country':'count'}).rename(columns={'Country':'Count'}).sort_values(by='Count', ascending=False)\nTOP_COUNTRIES = df_new.groupby(by='Country').agg({'Country':'count'}).rename(columns={'Country':'Count'}).sort_values(by='Count', ascending=False)[:3].index.tolist()\n#print(TOP_COUNTRIES)\ndf_ = getAgeGenderCountryDF()\n#print(df_.groupby(by=['AgeGroup','Gender']).agg({'Count':np.sum}))\nplotTreeMaps(df_)","73a348cf":"def getXXX(df_, cols, col):\n    df_temp = df_[cols].groupby(by=[col]).agg({col: 'count'})\n    df_temp.rename(columns={col:'count'}, inplace=True)\n    df_temp['count'] = 100 * df_temp['count']\/df_.shape[0]\n    df_temp.reset_index(inplace=True)\n    #print(df_temp)\n    return df_temp\n\ndef getYYY(df_, col):\n    cols = ['Age','Gender','AgeGroup',col]\n    #print(\"Missing values:\", df_[col].isnull().sum())\n    #print(df_[cols].head())\n\n    df_all = getXXX(df_, cols, col)\n    df_wlt40 = getXXX(df_[(df_new['Gender']=='Woman') & (df_['AgeGroup']=='<40')], cols, col)\n    df_wgt40 = getXXX(df_[(df_new['Gender']=='Woman') & (df_['AgeGroup']=='>40')], cols, col)\n\n    fig = plt.figure(figsize=(20, 5))\n    ax = plt.subplot(1, 3, 1); ax = df_all.plot.bar(col, ax=ax); annotate(ax, 'Overall'); ax.set_ylim(0, 100)\n    ax = plt.subplot(1, 3, 2); ax = df_wlt40.plot.bar(col, ax=ax); annotate(ax, 'Woman < 40'); ax.set_ylim(0, 100)\n    ax = plt.subplot(1, 3, 3); ax = df_wgt40.plot.bar(col, ax=ax); annotate(ax, 'Woman > 40'); ax.set_ylim(0, 100)\n    fig.suptitle(f'{col} & Gender', fontsize=16)","dcbfc75b":"COLS_EDU = ('Q4', 'What is the highest level of formal education that you have attained or plan to attain within the next 2 years?')\ndf[COLS_EDU].value_counts(normalize=True)*100\n\ndf_new['Education'] = df[COLS_EDU].apply(lambda x: 'None' if x in ['I prefer not to answer','No formal education past high school', 'Some college\/university study without earning a bachelor\u2019s degree'] else x )\ngetYYY(df_new, 'Education')","6b42e183":"TOP_COUNTRIES = df_new.groupby(by=['Country']).agg({'Country':'count'}).rename(columns={'Country':'Count'}).sort_values(by='Count', ascending=False)[:10].index.values.tolist()\n#print(TOP_COUNTRIES)\ndf_ = df_new[(df_new['Gender']=='Woman') & (df_new['AgeGroup']=='>40') & (df_new['Country'].isin(TOP_COUNTRIES))]\n#print(df_[['Country', 'Education']].head())\n\ndf_ = df_.groupby(by=['Country', 'Education']).agg({'Education':'count'}).rename(columns={'Education':'Count'}).reset_index()\nplt.figure(figsize=(15, 5))\ndf_ = pd.pivot_table(df_, index=['Education'],columns = ['Country'], values ='Count', aggfunc=np.sum)\nsns.heatmap(df_,annot=True, fmt=\"g\", cmap=\"YlGnBu\"); plt.xticks(rotation=45)\nplt.show()","122a0584":"COLS_INDUSTRY = ('Q20', 'In what industry is your current employer\/contract (or your most recent employer if retired)? - Selected Choice')\ndf[COLS_INDUSTRY].value_counts(normalize=True)*100;print()\ndf_new['Industry'] = df[COLS_INDUSTRY].apply(lambda x: x if x in ['Computers\/Technology','Academics\/Education', 'Accounting\/Finance', 'Manufacturing\/Fabrication', 'Medical\/Pharmaceutical', 'Government\/Public Service'] else 'Other' )\ngetYYY(df_new, 'Industry')\n\nCOLS_ROLE = ('Q5', 'Select the title most similar to your current role (or most recent title if retired): - Selected Choice')\ndf[COLS_ROLE].value_counts(normalize=True)*100\ndf_new['Role'] = df[COLS_ROLE]\ngetYYY(df_new, 'Role')","d77752b9":"df_ = df_new[(df_new['Gender']=='Woman') & (df_new['AgeGroup']=='>40')]\n#print(df_['Industry'].value_counts())\n\nfig = make_subplots(cols = 2, rows = 1, column_widths = [0.4, 0.4],\n                    subplot_titles = ('<b>Education and Industry<br \/>&nbsp;<br \/>', '<b>Education and Role<br \/>&nbsp;<br \/>'),\n                    specs = [[{'type': 'sunburst', 'rowspan': 1}, {'type': 'sunburst', 'rowspan': 1}]])\n\nsubfig = px.sunburst(df_, path=['Education', 'Industry'], color='Education',\n                                color_discrete_map={'(?)':'black',\"Master\u2019s degree\":'lightgreen', \"Bachelor\u2019s degree\":'chocolate', \n                                            'Doctoral degree':'dodgerblue', \"None\":'lightgray', \"Professional doctorate\":'darkblue'})\nsubfig.update_layout(showlegend=False, \n                plot_bgcolor='white', \n                margin=dict(pad=20),\n                xaxis={'showticklabels': True},\n                yaxis_title=None,\n                xaxis_title=None,\n                yaxis={'categoryorder':'total ascending'},\n                title_text=\"<b>Education and Industry<\/b>\",\n                title_x=0.5,\n                font=dict(family=\"serif\", size=17, color='#000000'),\n                title_font_size=30)\nsubfig.update_layout(width=600, height=400, margin = dict(t=50, l=25, r=25, b=25))\nfig.add_trace(subfig.data[0], row=1, col=1)\n\ndf_['Role'] = df_['Role'].apply(lambda x: x if x in ['Other', 'Data Scientist','Research Scientist', 'Currently not employed ',\n                                            'Data Analyst ', 'Student'] else 'Other')\nsubfig = px.sunburst(df_, path=['Education', 'Role'], color='Education',\n                               color_discrete_map={'(?)':'black',\"Master\u2019s degree\":'lightgreen', \"Bachelor\u2019s degree\":'chocolate', \n                                            'Doctoral degree':'dodgerblue', \"None\":'lightgray', \"Professional doctorate\":'darkblue'})\nsubfig.update_layout(showlegend=False, \n                plot_bgcolor='white', \n                margin=dict(pad=20),\n                xaxis={'showticklabels': True},\n                yaxis_title=None,\n                xaxis_title=None,\n                yaxis={'categoryorder':'total ascending'},\n                title_text=\"<b>Education and Role<\/b>\",\n                title_x=0.5,\n                font=dict(family=\"serif\", size=17, color='#000000'),\n                title_font_size=30)\nsubfig.update_layout(width=600, height=400, margin = dict(t=50, l=25, r=25, b=25))\nfig.add_trace(subfig.data[0], row=1, col=2)\n\nfig.update_layout(width=1200,height=500,) #autosize=False,\nfig.show()\n\n# KAGGLE\nfig = plt.figure(figsize=(16, 5))\n\ndf_ = df_new[(df_new['Gender']=='Woman') & (df_new['AgeGroup']=='>40')]\n#print(df_[['Education','Role']].head())\ndf_ = df_.groupby(by=['Education','Industry']).agg({'Industry':'count'}).rename(columns={'Industry':'Count'}).reset_index()\ndf_ = pd.pivot_table(df_, index=['Education'],columns = ['Industry'], values ='Count', aggfunc=np.sum)\nax=plt.subplot(1,2,1)\nsns.heatmap(df_,annot=True, fmt=\"g\", cmap=\"YlGnBu\")\n\n\ndf_ = df_new[(df_new['Gender']=='Woman') & (df_new['AgeGroup']=='>40')]\n#print(df_[['Education','Role']].head())\ndf_ = df_.groupby(by=['Education','Role']).agg({'Role':'count'}).rename(columns={'Role':'Count'}).reset_index()\ndf_ = pd.pivot_table(df_, index=['Education'],columns = ['Role'], values ='Count', aggfunc=np.sum)\nax=plt.subplot(1,2,2)\nsns.heatmap(df_,annot=True, fmt=\"g\", cmap=\"YlGnBu\")\n\nfig.suptitle('Education Vs Industry & Role', fontsize=16)\nplt.show()","bad03f26":"COLS_SAL = ('Q25', 'What is your current yearly compensation (approximate $USD)?')\ndf[COLS_SAL].value_counts(normalize=True).sort_values(ascending=False)\ndf_new['Salary'] = df[COLS_SAL]\n#getYYY(df_new, 'Salary')\n\ncol = 'Salary'\ncols = ['Age','Gender','AgeGroup',col]\n#print(\"Missing values:\", df_new[col].isnull().sum())\n#print(df_[cols].head())\n\nSAL_VALUES = ['$0-999', '1,000-1,999', '2,000-2,999', '3,000-3,999', '4,000-4,999', '5,000-7,499', '7,500-9,999','10,000-14,999', '15,000-19,999', '20,000-24,999','25,000-29,999', '30,000-39,999', '40,000-49,999', '50,000-59,999', '60,000-69,999', '70,000-79,999', '80,000-89,999', '90,000-99,999', '100,000-124,999', '125,000-149,999', '150,000-199,999','200,000-249,999', '$500,000-999,999', '>$1,000,000']\ndf_ = df_new\ntotal = df_.shape[0]\ndf_all = df_[cols].groupby(by=[col]).agg({col: 'count'})\ndf_all.rename(columns={col:'count'}, inplace=True)\ndf_all = df_all.reindex(SAL_VALUES)\ndf_all.reset_index(inplace=True)\ndf_all['count'] = round((df_all['count']\/total)*100,2)\n#print(df_all)\n\ndf_ = df_new[(df_new['Gender']=='Woman') & (df_new['AgeGroup']=='<40')]\ntotal = df_.shape[0]\ndf_wlt40 = df_[cols].groupby(by=[col]).agg({col: 'count'})\ndf_wlt40.rename(columns={col:'count'}, inplace=True)\ndf_wlt40 = df_wlt40.reindex(SAL_VALUES)\ndf_wlt40.reset_index(inplace=True)\ndf_wlt40['count'] = round((df_wlt40['count']\/total)*100,2)\n#print(df_wlt40)\n\n\ndf_ = df_new[(df_new['Gender']=='Woman') & (df_new['AgeGroup']=='>40')]\ntotal = df_.shape[0]\ndf_wgt40 = df_[cols].groupby(by=[col]).agg({col: 'count'})\ndf_wgt40.rename(columns={col:'count'}, inplace=True)\ndf_wgt40 = df_wgt40.reindex(SAL_VALUES)\ndf_wgt40.reset_index(inplace=True)\ndf_wgt40['count'] = round((df_wgt40['count']\/total)*100,2)\n#print(df_wgt40)\n\nplt.figure(figsize=(20, 5))\nax = plt.subplot(1, 3, 1); ax = df_all.plot.bar(col, ax=ax); annotate(ax, 'Overall'); ax.set_ylim(0, 18)\nax = plt.subplot(1, 3, 2); ax = df_wlt40.plot.bar(col, ax=ax); annotate(ax, 'Woman < 40'); ax.set_ylim(0, 18)\nax = plt.subplot(1, 3, 3); ax = df_wgt40.plot.bar(col, ax=ax); annotate(ax, 'Woman > 40'); ax.set_ylim(0, 18)","c4c223c1":"plt.figure(figsize=(10, 6)); ax = plt.subplot(1,1 ,1)\nCAT = \"PL\"; Q_PREFIX = \"Q7\"\nQ_PART_PREFIX = f'{Q_PREFIX}_Part_'; COL_NONE = f'{Q_PART_PREFIX}12'\nCOLS, _, COLS_OTHER, _ = getCols(CAT, Q_PREFIX, COL_NONE, )\ndf[COLS].head()\nsummarise(df, df_new, CAT, COLS, COLS_OTHER, COL_NONE,\n            f'{Q_PART_PREFIX}1', f'{CAT}Python', \"Python\",\n            f'{Q_PART_PREFIX}3', f'{CAT}SQL', \"SQL\",\n            f'{Q_PART_PREFIX}5', f'{CAT}C++', \"C++\", ax, 'Usage - Programming Languages') ","1d1d7f64":"plt.figure(figsize=(20, 6))\n\nCAT, Q_PREFIX = \"IDE\", \"Q9\"\nQ_PART_PREFIX = f'{Q_PREFIX}_Part_'; COL_NONE = f'{Q_PART_PREFIX}12'\nCOLS, _, COLS_OTHER, _ = getCols(CAT, Q_PREFIX, COL_NONE, )\ndf[COLS].head()\nax = plt.subplot(1, 2, 1)\nsummarise(df, df_new, CAT, COLS, COLS_OTHER, COL_NONE,\n            f'{Q_PART_PREFIX}11', f'{CAT}-JupyterNB', \"Jupyter Notebook\",\n            f'{Q_PART_PREFIX}4', f'{CAT}-VSCode', \"Visual Studio Code (VSCode)\",\n            f'{Q_PART_PREFIX}5', f'{CAT}-PyCharm', \"PyCharm\", \n            ax=ax, title=\"IDE - Usage\") \n\nCAT, Q_PREFIX = \"HNB\", \"Q10\"\nQ_PART_PREFIX = f'{Q_PREFIX}_Part_'; COL_NONE = f'{Q_PART_PREFIX}16'\nCOLS, _, COLS_OTHER, _ = getCols(CAT, Q_PREFIX, COL_NONE, )\ndf[COLS].head()\nax = plt.subplot(1, 2, 2)\nsummarise(df, df_new, CAT, COLS, COLS_OTHER, COL_NONE,\n            f'{Q_PART_PREFIX}2', f'{CAT}-Colab', \"Colab Notebooks\",\n            f'{Q_PART_PREFIX}1', f'{CAT}-Kaggle', \"Kaggle Notebooks\",\n            f'{Q_PART_PREFIX}10', f'{CAT}Google', \"Google Cloud Notebooks (AI Platform \/ Vertex AI)\", \n            ax=ax, title=\"Hosted Notebook - Usage\") ","01be821f":"COLS_ML_USE = ('Q15','For how many years have you used machine learning methods?')\nprint(df[COLS_ML_USE].value_counts(normalize=True)*100);print()\n\nCOLS_PL_USE = ('Q6', 'For how many years have you been writing code and\/or programming?')\nprint(df[COLS_PL_USE].value_counts(normalize=True)*100)\n\ndf_new['MLUsage'] = df[COLS_ML_USE].apply(lambda x: '0 years' if x == 'I do not use machine learning methods' else x )\ndf_new['PLUsage'] = df[COLS_PL_USE].apply(lambda x: '0 years' if x == 'I have never written code' else x)\n\nCOLS_USAGE = ['Age','Gender','AgeGroup','PL-Count','MLUsage','PLUsage']\ndf_new[COLS_USAGE].head()","a6dcf5ef":"def plotMLPLUsage(df, ax, title):\n    df.rename(columns={'MLUsage':'Count'},inplace=True)\n    df.reset_index(inplace=True)\n    #print(df.sort_values(by=['MLUsage','PLUsage']).head())\n    #print(df[df['MLUsage'] == '20 or more years'])\n\n    df_mlpl = pd.pivot_table(df, index=['PLUsage'], columns = ['MLUsage'], values ='Count', aggfunc=np.sum)\n    df_mlpl = df_mlpl[['0 years', 'Under 1 year', '1-2 years', '2-3 years', '3-4 years', '4-5 years', '5-10 years', '10-20 years', '20 or more years']]\n    df_mlpl = df_mlpl.reindex(index = ['< 1 years', '1-3 years','3-5 years', '5-10 years', '10-20 years', '20+ years'] )\n    \n    #fig, ax = plt.subplots(figsize=(10,8)) \n    if ax is None: \n        sns.heatmap(df_mlpl, annot=True, fmt=\"g\", cmap=\"YlGnBu\")\n    else:\n        sns.heatmap(df_mlpl, annot=True, fmt=\"g\", ax=ax, cmap=\"YlGnBu\")","192591c6":"df_all = df_new[COLS_USAGE].groupby(by=['MLUsage','PLUsage']).agg({ 'MLUsage': 'count'})\ndf_wlt40 = df_new[(df_new['Gender']=='Woman') & (df_new['AgeGroup']=='<40')][COLS_USAGE].groupby(by=['MLUsage','PLUsage']).agg({ 'MLUsage': 'count'})\ndf_wgt40 = df_new[(df_new['Gender']=='Woman') & (df_new['AgeGroup']=='>40')][COLS_USAGE].groupby(by=['MLUsage','PLUsage']).agg({ 'MLUsage': 'count'})\n\nfig = plt.figure(figsize=(20, 5)); fig.suptitle('Machine Learning & Programming Language - Overall Usage', fontsize=16)\nplotMLPLUsage(df_all, None, 'Overall');plt.show()\n\nfig = plt.figure(figsize=(20, 5)); fig.suptitle('Machine Learning & Programming Language - Usage by Women', fontsize=16)\nax = plt.subplot(1, 2, 1); plotMLPLUsage(df_wlt40, ax, 'Woman < 40')\nax = plt.subplot(1, 2, 2); plotMLPLUsage(df_wgt40, ax, 'Woman > 40')","ab04ce8b":"plt.figure(figsize=(20, 6))\n\nCAT, Q_PREFIX = \"VIZ\", \"Q14\"\nQ_PART_PREFIX = f'{Q_PREFIX}_Part_'; COL_NONE = f'{Q_PART_PREFIX}11'\nCOLS, _, COLS_OTHER, _ = getCols(CAT, Q_PREFIX, COL_NONE, );df[COLS].head()\nax = plt.subplot(1, 2, 1)\nsummarise(df, df_new, CAT, COLS, COLS_OTHER, COL_NONE,\n            f'{Q_PART_PREFIX}1', f'{CAT}-Matplotlib', \"Matplotlib\",\n            f'{Q_PART_PREFIX}2', f'{CAT}-Seaborn', \"Seaborn\",\n            f'{Q_PART_PREFIX}3', f'{CAT}-plotly', \"Plotly \/ Plotly Express\", \n            ax, \"Data Visualisation - Usage\")\n\nCAT, Q_PREFIX = \"MLFW\", \"Q16\"\nQ_PART_PREFIX = f'{Q_PREFIX}_Part_'; COL_NONE = f'{Q_PART_PREFIX}17'\nCOLS, _, COLS_OTHER, _ = getCols(CAT, Q_PREFIX, COL_NONE, );df[COLS].head()\nax = plt.subplot(1, 2, 2)\nsummarise(df, df_new, CAT, COLS, COLS_OTHER, COL_NONE,\n            f'{Q_PART_PREFIX}1', f'{CAT}-Scikit-learn', \"Scikit-learn\",\n            f'{Q_PART_PREFIX}2', f'{CAT}-TensorFlow', \"TensorFlow\",\n            f'{Q_PART_PREFIX}3', f'{CAT}-Keras', \"Keras\", \n            ax, \"ML Framework - Usage\")","a958088b":"plt.figure(figsize=(24, 6))\n\nax = plt.subplot(1, 3, 1)\nCAT, Q_PREFIX = \"MLA\", \"Q17\"\nQ_PART_PREFIX = f'{Q_PREFIX}_Part_'; COL_NONE = f'{Q_PART_PREFIX}11'\nCOLS, _, COLS_OTHER, _ = getCols(CAT, Q_PREFIX, COL_NONE, )\ndf[COLS].head()\nsummarise(df, df_new, CAT, COLS, COLS_OTHER, COL_NONE,\n            f'{Q_PART_PREFIX}1', f'{CAT} Linear\/\\nLogistic\\n Regression', \"Linear or Logistic Regression\",\n            f'{Q_PART_PREFIX}2', f'{CAT} Decision\\nTrees\\n\/Random Forests', \"Decision Trees or Random Forests\",\n            f'{Q_PART_PREFIX}3', f'{CAT} Gradient\\nBoosting', \"Gradient Boosting Machines (xgboost, lightgbm, etc)\", ax=ax, title=\"ML Algorithms-Usage\") \n\nax = plt.subplot(1, 3, 2)\nCAT, Q_PREFIX = \"CV\", \"Q18\"\nQ_PART_PREFIX = f'{Q_PREFIX}_Part_'; COL_NONE = f'{Q_PART_PREFIX}6'\nCOLS, _, COLS_OTHER, _ = getCols(CAT, Q_PREFIX, COL_NONE, )\ndf[COLS].head()\nsummarise(df, df_new, CAT, COLS, COLS_OTHER, COL_NONE,\n            f'{Q_PART_PREFIX}4', f'{CAT}-Image\\nclassification', \"Image classification and other general purpose networks (VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc)\",\n            f'{Q_PART_PREFIX}2', f'{CAT}-Image\\nsegmentation', \"Image segmentation methods (U-Net, Mask R-CNN, etc)\",\n            f'{Q_PART_PREFIX}3', f'{CAT}-Object\\ndetection', \"Object detection methods (YOLOv3, RetinaNet, etc)\", ax=ax, title=\"Computer Vision-Usage\") \n\nax = plt.subplot(1, 3, 3)\nCAT, Q_PREFIX  = \"NLP\", \"Q19\"\nQ_PART_PREFIX = f'{Q_PREFIX}_Part_'; COL_NONE = f'{Q_PART_PREFIX}5'\nCOLS, _, COLS_OTHER, _ = getCols(CAT, Q_PREFIX, COL_NONE, )\ndf[COLS].head()\nsummarise(df, df_new, CAT, COLS, COLS_OTHER, COL_NONE,\n            f'{Q_PART_PREFIX}1', f'{CAT}-Word\\nembeddings', \"Word embeddings\/vectors (GLoVe, fastText, word2vec)\",\n            f'{Q_PART_PREFIX}4', f'{CAT}-Encoder-\\ndecorder\\nmodels', \"Encoder-decorder models (seq2seq, vanilla transformers)\",\n            f'{Q_PART_PREFIX}2', f'{CAT}-Transformer\\nlanguage\\nmodels', \"Transformer language models (GPT-3, BERT, XLnet, etc)\", ax=ax, title=\"Natural Language Processing-Usage\") \n\nplt.figure(figsize=(15, 6))\n\nax = plt.subplot(1, 1, 1)\nCAT = \"AML\"; Q_PREFIX = \"Q36_A\"\nQ_PART_PREFIX = f'{Q_PREFIX}_Part_'; COL_NONE = f'{Q_PART_PREFIX}7'\nCOLS, _, COLS_OTHER, _ = getCols(CAT, Q_PREFIX, COL_NONE, )\ndf[COLS].head()\nsummarise(df, df_new, CAT, COLS, COLS_OTHER, COL_NONE,\n            f'{Q_PART_PREFIX}3', f'{CAT}-Model selection', \"Automated model selection (e.g. auto-sklearn, xcessiv)\",\n            f'{Q_PART_PREFIX}1', f'{CAT}-Data augmentation', \"Automated data augmentation (e.g. imgaug, albumentations)\",\n            f'{Q_PART_PREFIX}5', f'{CAT}-Hyperparameter tuning', \"Automated hyperparameter tuning (e.g. hyperopt, ray.tune, Vizier)\", \n            ax, title='AutoML-Usage') ","870b0b40":"plt.figure(figsize=(24, 6))\n\nax = plt.subplot(1, 3, 1)\nCOLS_HW, COLS_HW_TOP3, COLS_HW_OTHER, COLS_HW_NONE = getCols('HW',  'Q12', 'Q12_Part_5', )\ndf[COLS_HW].head()\nsummarise(df, df_new, 'HW', COLS_HW, COLS_HW_OTHER, 'Q12_Part_5',\n            'Q12_Part_1', 'HW-Nvidia\\nGPUs', \"NVIDIA GPUs\",\n            'Q12_Part_2', 'HW-Google\\nCloud TPUs', \"Google Cloud TPUs\",\n            'Q12_Part_4', 'HW-AWS\\nInferentia Chips', \"AWS Inferentia Chips\", ax, title=\"Hardware-Usage\")\n\nax = plt.subplot(1, 3, 2)\nCAT = \"CCPLT\"; COL_NONE = 'Q27_A_Part_11'\nCOLS, _, COLS_OTHER, _ = getCols(CAT,  'Q27_A', COL_NONE, )\ndf[COLS].head()\nsummarise(df, df_new, CAT, COLS, COLS_OTHER, COL_NONE,\n            'Q27_A_Part_1', 'CCPLT-Amazon\\nWeb Services', \"Amazon Web Services (AWS)\",\n            'Q27_A_Part_3', 'CCPLT-Google\\nCloud Platform', \"Google Cloud Platform (GCP)\",\n            'Q27_A_Part_2', 'CCPLT-Microsoft\\nAzure', \"Microsoft Azure\", \n            ax, title=\"Cloud Computing Platform-Usage\")\n\n# TODO: None comes in top 3 so the plot is screwed up   \nax = plt.subplot(1, 3, 3)        \nCAT = \"CCP\"\nCOL_NONE = 'Q29_A_Part_4'\nCOLS, _, COLS_OTHER, _ = getCols(CAT,  'Q29_A', COL_NONE, )\ndf[COLS].head()\nsummarise(df, df_new, CAT, COLS, COLS_OTHER, COL_NONE,\n            'Q29_A_Part_1', 'CCP-Amazon Elastic\\nCompute Cloud ', \"Amazon Elastic Compute Cloud (EC2)\",\n            'Q29_A_Part_3', 'CCP-Google Cloud\\nCompute Engine', \"Google Cloud Compute Engine\",\n            'Q29_A_Part_3', 'CCP-Google Cloud\\nCompute Engine', \"Google Cloud Compute Engine\",\n            ax, title=\"Cloud Computing Products-Usage\") ","de479838":"plt.figure(figsize=(24, 6))\n\nax = plt.subplot(1, 3, 1)\nCAT = \"MMLP\";COL_NONE = 'Q31_A_Part_9'\nCOLS, _, COLS_OTHER, _ = getCols(CAT,  'Q31_A', COL_NONE, )\ndf[COLS].head()\nsummarise(df, df_new, CAT, COLS, COLS_OTHER, COL_NONE,\n            'Q31_A_Part_1', 'MMLP-AWS', \"Amazon SageMaker\",\n            'Q31_A_Part_3', 'MMLP-GCP', \"Azure Machine Learning Studio\",\n            'Q31_A_Part_2', 'MMLPAzure', \"Databricks\", ax, \"Managed Machine Learning Products-Usage\") \n\nax = plt.subplot(1, 3, 2)\nCAT = \"ATML\"; COL_NONE = 'Q37_A_Part_7'\nCOLS, _, COLS_OTHER, _ = getCols(CAT,  'Q37_A', COL_NONE, )\ndf[COLS].head()\nsummarise(df, df_new, CAT, COLS, COLS_OTHER, COL_NONE,\n            'Q37_A_Part_1', CAT+ '-' + 'GC', \"Google Cloud AutoML\",\n            'Q37_A_Part_3', CAT+ '-' + 'Azure', \"Azure Automated Machine Learning\",\n            'Q37_A_Part_2', CAT+ '-' + 'Amazon', \"Amazon Sagemaker Autopilot\", ax, \"Auto ML Tools-Usage\") \n\nax = plt.subplot(1, 3, 3)\nCAT = \"MLEXP\"; COL_NONE = 'Q38_A_Part_11'\nCOLS, _, COLS_OTHER, _ = getCols(CAT,  'Q37_A', COL_NONE, )\ndf[COLS].head()\nsummarise(df, df_new, CAT, COLS, COLS_OTHER, COL_NONE,\n            'Q38_A_Part_7', CAT+ '-' + 'Polyaxon', \"Polyaxon\",\n            'Q38_A_Part_1', CAT+ '-' + 'Neptune', \"Neptune.ai\",\n            'Q38_A_Part_6', CAT+ '-' + 'Guild', \"Guild.ai\", ax, \"Manage Machine Learning Experiments-Usage\" ) ","75e07e33":"plt.figure(figsize=(24, 6))\n\nax = plt.subplot(1, 3, 1)\nCAT = \"DSP\"; Q_PREFIX = \"Q30_A\"\nQ_PART_PREFIX = f'{Q_PREFIX}_Part_'; COL_NONE = f'{Q_PART_PREFIX}7'\nCOLS, _, COLS_OTHER, _ = getCols(CAT, Q_PREFIX, COL_NONE, )\ndf[COLS].head()\nsummarise(df, df_new, CAT, COLS, COLS_OTHER, COL_NONE,\n            f'{Q_PART_PREFIX}3', CAT+ '-' + 'AWSS3', \"Amazon Simple Storage Service (S3)\",\n            f'{Q_PART_PREFIX}5', CAT+ '-' + 'GCS', \"Google Cloud Storage (GCS)\",\n            f'{Q_PART_PREFIX}1', CAT+ '-' + 'AZURE', \"Microsoft Azure Data Lake Storage\", ax, \"Data Storage Products-Usage\") \n\nax = plt.subplot(1, 3, 2)\nCAT = \"BDP\"; Q_PREFIX = \"Q32_A\"\nQ_PART_PREFIX = f'{Q_PREFIX}_Part_'; COL_NONE = f'{Q_PART_PREFIX}20'\nCOLS, _, COLS_OTHER, _ = getCols(CAT, Q_PREFIX, COL_NONE, )\ndf[COLS].head()\nsummarise(df, df_new, CAT, COLS, COLS_OTHER, COL_NONE,\n            f'{Q_PART_PREFIX}1', CAT+ '-' + 'MySQL', \"MySQL\",\n            f'{Q_PART_PREFIX}2', CAT+ '-' + 'PostgreSQL', \"PostgreSQL\",\n            f'{Q_PART_PREFIX}8', CAT+ '-' + 'MSSQL', \"Microsoft SQL Server\", ax, \"Big Data Products-Usage\") \n\nax = plt.subplot(1, 3, 3)\nCAT = \"BIT\"; Q_PREFIX = \"Q34_A\"\nQ_PART_PREFIX = f'{Q_PREFIX}_Part_'; COL_NONE = f'{Q_PART_PREFIX}16'\nCOLS, _, COLS_OTHER, _ = getCols(CAT, Q_PREFIX, COL_NONE, )\ndf[COLS].head()\nsummarise(df, df_new, CAT, COLS, COLS_OTHER, COL_NONE,\n            f'{Q_PART_PREFIX}5', CAT+ '-' + 'Tableau', \"Tableau\",\n            f'{Q_PART_PREFIX}2', CAT+ '-' + 'PowerBI', \"Microsoft Power BI\",\n            f'{Q_PART_PREFIX}3', CAT+ '-' + 'Google\\nDataStudio', \"Google Data Studio\", ax, \"Business Intelligence Tools-Usage\") ","3052ddb9":"fig=plt.figure(figsize=(10, 8));fig.suptitle('Technology Usage - Overall Trends', fontsize=16)\nsns.heatmap(df_RESULT, annot=True, fmt=\"g\", cmap=\"YlGnBu\")","13d94f47":"## 3. Development Toolset\/Environment - Usage\nHow have the **Women > 40 years** adopted Technology? How many of the Programming Languages, IDE, Tools, Frameworks do they use in their work?","b3426180":"The overall trend of usage of Programming Languages for the ```Women >40``` is similar to overall and Woman <40. The most used programming languages are in the order Python, SQL, C++\n\nThe python users in the ```Women >40``` is lesser than the rest.\n\nThe number of ```Women >40``` not using any programming language is 14.4 which is significantly higher than the overall and women<40 category.","559f28f0":"### 5.2 Managed Machine Learning Products, Auto ML Tools, Manage Machine Learning Experiments","ff85f301":"Most of the **overall** and **women <40 years** communities have been using programming languages for **< 5 years** and have been using ML for **< 3 years**. Very few have been using Programming Languages and ML beyond these numbers.\n\nFor obvious reasons (age), more percentage of the ```Women >40``` community has been using programming languages and ML for more years compared to that of their counterparts.","30a7aad9":"**Women > 40 years** form a minute 3% sub-group of practioners majoirty of them coming from the **United States of America**\n\nWrt **Education and Profession**\n- \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f They have mostly **Masters degree** followed by Doctors, Bachelors, None and then Professional doctorate.\n- Higher percentage of them are in the Academics\/Education followed by Computers\/Technology. \n- \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f Most of them are in the Data Scientist and Research Scientist roles\n- \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f Their salaries are in general higher than their counterparts (owing to their experience)\n\nLet's look at the **Usage of Technology** of this **Women >40 years** category. The usage of technology is a good indicator of Proficiency.\n- **Development Toolset\/Environment**: Their overall trend of usage of Programming Languages, **IDE** and **Hosted Notebook** usage is similar for the ```Women >40``` is similar to **overall** and **Women <40** categories. \n    - The number of **women > 40** users not using any programming language,IDE and Hosted Notebook is significantly higher than the overall and women<40 category. \n    - \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f More percentage of this community has been using programming languages and ML for more years compared to that of their counterparts.\n    - In all the categories of gender and age groups, \n        - matplotlib, seaborn, plotly are most used visualization libraries \n        - scikit learn, tensorflow and keras are most used for general machine learning frameworks\n- **Machine Learning Concepts, Practices**: The trend of usage of the ML algorithms, CV, NLP & AutoML are again same across all the gender-age group categories. A big percentage of the community have not started to use the higher order ML concepts like CV, NLP & AutoML. \n    - \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f Interestingly in the usage of ML Algorithms, the **Women > 40 years** have a slight upper hand compared to their **<40 years** counterparts. \n- **Managed Platforms & Products**: Almost similar trend across categories in the Hardware & Cloud technologies, Data & BI Tools. The adoption of these higher end platforms is very very less! \n    - \u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f Here again, the **Women > 40 years** have a slight upper hand compared to their **<40 years** counterparts and in some cases **overall** numbers also.\n\n_TODO: If time permits I will continue with the analysis of the \"the topics they hope to become more familiar with\". This set will indicate the **interest** of the group in the ML & Data science field._  ","b2f2f620":"As we can see in each of the age groups, the number of women is far lesser than that of men. And with increase in age, the number of members (and women) involved in ML & DS is decreasing. A **minuscule 3%** of the total community forms the **>40 women** sub group.\n\nA person who is 40+ years now in 2021 must have been born in the 1970s, graduated in the 1990s. These are the times when women are not known to be taking up technical areas of work. This probably explains why the women form a small part of the technical community in general and ML & DS community in specific. Moreover, the ML and DS has gained momentum in the early 2010s. That leaves even lesser opportunity for the women graduated in 1990s to get involved in this space. \n\n*Note: The 'Other' gender is lesser than Man & Woman but since 'Other' community is not the focus in the current analysis, ignoring it*","6fbe4d8b":"#### Age and Gender - Data processing","606dbe2a":"## 1. Demographics","e5b3604f":"The typical usages for ```Women >40``` follow a similar trend as the overall and the Women < 40 categories. ","8cbca57b":"The trend across categories in the **IDE** and **Hosted Notebook** usage is also similar. The most used IDEs are Jupyter Notebook, VS Code and PyCharm\n\nThe number of women > 40 not using any IDE and Hosted Notebook is 16.8 and 43.6 respectively which is again significantly higher than the overall and women<40 category.","bb1794f0":"## Machine Learning & Data Science: Women >40years","85f77b11":"### 1.1 Age and Gender\nHow many men and women are distributed across various age groups? What percentage of members form the **Women >40years** group? Are there far more men in the technology space than women?","b4063d62":"In the <40 years category, most members (including women) are coming from **India** while in the >40 years category, most members seem to be coming from **United States of America**\n\nSince the environment in the **United States of America** became more conduicive for women earlier on, we probably see more women in the >40 category. But **India** seems to be fast catching up with the ML & DS technology!!","64991889":"The trend of usage of the ML algorithms, CV, NLP & AutoML are again same across all the gender-age group categories. A big percentage of the community have not started to use the higher order ML concepts like CV, NLP & AutoML\n\nInterestingly in the usage of ML Algorithms, the **Women > 40 years** have a slight upper hand compared to their **<40 years** counterparts. ","19e0cd5b":"Almost similar trend across categories in the Data & BI Tools. Here again, the number of members who are not using ay of the technologies is much higher than those who are using specific Products\/Tools.\n\nIn the category of products, the **Women > 40 years** have a significant upper hand compared to their **<40 years** counterparts and in some cases **overall** numbers also.","c5e08368":"### 3.2 IDEs & Hosted Notebooks","a6a3bf65":"Overall and Woman<40 categories, the members mostly have Bachelor's & Masters degree followed by No degree, Doctor, Professional Doctor\n\nBut **Women >40** have mostly **Masters degree** followed by Doctors, Bachelors, None and then Professional doctorate. This is probably expected due to the age factor.","5af90b3c":"Most ```women>40 years``` from USA have Master's, Bachelor's and Doctoral degree while in India the order of preference seems to be Master's, Doctoral and then Bachelor's degree.","90eec4ce":"## 6. Technology Usage - Overall Trends\n\nLet's look at the typical and max usages of the tools, products and platforms across the **overall**, **women<40 years** and **women>40 years** categories","fa531806":"Almost similar trend across categories in the Hardware & Cloud technologies as well. The number not using any of these technologies is significantly higher than those who are using specific Harward.\n\nHere again, in the usage of Cloud Computing platforms & products, the **Women > 40 years** have a slight upper hand compared to their **<40 years** counterparts. ","6094936d":"## 4. Machine Learning Concepts, Practices - Usage\nHow is the usage of ML Algorithms and areas like Computer Vision, Natural Language Processing (NLP) & AutoML?","e6dbf2a1":"### 5.3 Data Storage Products, Big Data Product, Business Intelligence Tools","c9973da2":"### 1.2 Country\nWhich countries do the women > 40 come from? How is this distribution comapred to the other categories?","64331d42":"##### Visulisations","b5d36d3f":"### 5.1 Hardware, Cloud Computing Platform, Cloud Computing Products","5877893c":"### 3.1 Programming Languages","478ebd4f":"### 3.4 Data Visualization & Machine Learning Framework","4ca905c6":"## 2. Education and Profession\nWhat kind of **education** do the **Women > 40 years** have? Which **Industries** and in what kind og **Roles** do they mostly work in? What is the **Salaries** do they typically earn?","22da1142":"### 3.3 Programming Language & Machine Learning Usage","17cd5b65":"The adoption of these higher end platforms is very very less!","6e505379":"#### Functions","558283fa":"The salaries of the women > 40yrs is higher than their counterparts (owing to their experience)","80829c96":"## 5. Managed Platforms & Products - Usage\nHow is the adoption of the community to the Cloud hosted, manager platforms and products? These definitely need higher skills and experience","a40ef1c4":"#### Imports","2399943d":"## End Notes","a322da64":"### Prologue\n\nI am a **45+ years woman** in the technology space for over 2 decades and in the data science and machine learning domain for around 3 years. In the last 20 or so years, I have been encountering lesser and lesser women around me in the technology space in general. This number dwindles further when it comes to data science and machine learning space. I am curious \ud83e\udd14...curious to know how the **Women >40years** practitioners are faring in the ML and DS field! \n\nThis year's Kaggle's annual Machine Learning and Data Science Survey attempts to give a comprehensive view of the current state of data science and machine learning. The survery had questions about the participant's education, profession, usage of development tools and environment and the areas that the participant wishes to learn in the future. We can hope to find answers for some of the questions from these survey results with **25,973** participants (from 18 yeara to 70+ years) from 66 countries across the world. \n\nLet's compare the characteristics of **Women >40years** practitioners with the **overall members** and the **Women <40years** in each of the aspects - like demographices and the usage of technology (tools, products, libraries)","7e64bca8":"Higher percentage of the women > 40yrs are in the Academics\/Education (other than 'Others' category) followed by Computers\/Technology. These are also the top 2 industries for the overall and women < 40 yrs but with lesser percentages.\n\nWhile in the Overall & Women < 40 years categories, most of them are students followed by Data Scientists, the women>40 years fall in the Data Scientist, Research Scientist roles (apart from Other category)","761271c5":"#### Read dataset","8e4b2b62":"In all the categories of gender and age groups, \n- matplotlib, seaborn, plotly are most used visualization libraries \n- scikit learn, tensorflow and keras are most used for general machine learning frameworks","2126a920":"```women>40 years``` with\n- **Master**'s degree are into **Other**, **Computers\/Technology** and **Academic\/Education** Industry in **Other** and **Data Scientist** Roles \n- **Doctoral** degree are into **Academic\/Education** & **Other** Industry in **Research Scientist** and **Data Scientist** Roles \n- **Bachelor**'s degree are in **Other** Industry in **Other** Roles"}}