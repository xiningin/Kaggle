{"cell_type":{"8288450a":"code","25c3cea5":"code","296ab8d2":"code","eae40cf0":"code","e8d42a6a":"code","236444da":"code","8d54ee5c":"code","22246faa":"code","3c1fd6ba":"code","b5f25f77":"code","16a710a0":"code","a217c66e":"code","778eab74":"code","cb70499a":"code","da259627":"code","afd7c180":"code","99bf264c":"code","5c727a26":"code","b3b45b19":"code","01bd3a71":"code","21d01c6f":"code","270dad30":"code","33453fbb":"code","99b7c02d":"markdown","4d948988":"markdown","56b003f1":"markdown","f0f5de85":"markdown","3dab9b90":"markdown","cc764444":"markdown","0573c763":"markdown","f79a53e6":"markdown","6b725059":"markdown","031f2192":"markdown"},"source":{"8288450a":"import os\n\nIMAGE_SIZE = (536, 960)\n\nif not os.path.exists(\"unet.py\"):\n    if not os.path.exists(\"PyTorch-2D-3D-UNet-Tutorial\"):\n        !git clone https:\/\/github.com\/fakhrul\/PyTorch-2D-3D-UNet-Tutorial.git\n    %cd PyTorch-2D-3D-UNet-Tutorial\n!ls","25c3cea5":"import torch\nif not torch.cuda.is_available():\n    raise Exception('GPU not avaialable. CPU training will be too slow')\nprint('device name', torch.cuda.get_device_name())","296ab8d2":"# Install dependecies\n!pip install \"git+https:\/\/github.com\/napari\/napari.git#egg=napari[all]\"\n!pip install torchsummary","eae40cf0":"import os\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport random\n\nFOLDER_LOCATION = '\/kaggle\/input\/boat-seagull\/'\nNO_OF_IMAGE = 5\n\nimage_list = []\nmask_list = []\nfor i in range(NO_OF_IMAGE):\n    file = random.choice(os.listdir(os.path.join(FOLDER_LOCATION, 'images\/')))\n    image = cv2.imread(os.path.join(os.path.join(FOLDER_LOCATION, 'images\/'),file))\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n    image_list.append(image)\n\n    mask = cv2.imread(os.path.join(os.path.join(FOLDER_LOCATION, 'masks\/'),file))\n    mask = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)\n    mask_list.append(mask)\n\nimage_list = np.array(image_list)\nmask_list = np.array(mask_list)\n#mask_list = mask_list.reshape(NO_OF_IMAGE, mask_list.shape[1],mask_list.shape[2], 1)\nprint(\"input_images shape and range\", image_list.shape, image_list.min(), image_list.max())\nprint(\"target_masks shape and range\", mask_list.shape, mask_list.min(), mask_list.max(), np.unique(mask_list))\n\nfig, ax = plt.subplots(NO_OF_IMAGE, 2,figsize=(20,20))\nfor i in range(NO_OF_IMAGE):\n    ax[i][0].imshow(image_list[i], cmap='gray')\n    ax[i][1].imshow(mask_list[i], cmap='gray')\n\nplt.show()","e8d42a6a":"import numpy as np\n\nfrom transformations import ComposeDouble, FunctionWrapperDouble, create_dense_target, normalize_01\nfrom customdatasets import SegmentationDataSet1\nfrom torch.utils.data import DataLoader\nfrom sklearn.model_selection import train_test_split\nimport pathlib\nfrom skimage.transform import resize\n\n# root directory\nroot = '\/kaggle\/input\/boat-seagull\/'\n\n\ndef get_filenames_of_path(path: str, ext: str = '*'):\n    full_path_list = [os.path.join(path, file_name) for file_name in os.listdir(path)]\n    return  full_path_list\n    \"\"\"Returns a list of files in a directory\/path. Uses pathlib.\"\"\"\n#    filenames = [file for file in path.glob(ext) if file.is_file()]\n#    return filenames\n\n\n# input and target files\ninputs = get_filenames_of_path(os.path.join(root,'images'))\ntargets = get_filenames_of_path(os.path.join(root,'masks'))\n\n# training transformations and augmentations\ntransforms = ComposeDouble([\n    FunctionWrapperDouble(create_dense_target, input=False, target=True),\n    FunctionWrapperDouble(np.moveaxis, input=True, target=False, source=-1, destination=0),\n    FunctionWrapperDouble(normalize_01)\n])\n\n# random seed\nrandom_seed = 42\n\n# split dataset into training set and validation set\ntrain_size = 0.8  # 80:20 split\n\ninputs_train, inputs_valid = train_test_split(\n    inputs,\n    random_state=random_seed,\n    train_size=train_size,\n    shuffle=True)\n\ntargets_train, targets_valid = train_test_split(\n    targets,\n    random_state=random_seed,\n    train_size=train_size,\n    shuffle=True)\n\n# dataset training\ndataset_train = SegmentationDataSet1(inputs=inputs_train,\n                                    targets=targets_train,\n                                    transform=transforms)\n\n# dataset validation\ndataset_valid = SegmentationDataSet1(inputs=inputs_valid,\n                                    targets=targets_valid,\n                                    transform=transforms)\n\n# dataloader training\ndataloader_training = DataLoader(dataset=dataset_train,\n                                 batch_size=2,\n                                 shuffle=True)\n\n# dataloader validation\ndataloader_validation = DataLoader(dataset=dataset_valid,\n                                   batch_size=2,\n                                   shuffle=True)\n","236444da":"x, y = next(iter(dataloader_training))\n\nprint(f'x = shape: {x.shape}; type: {x.dtype}')\nprint(f'x = min: {x.min()}; max: {x.max()}')\nprint(f'y = shape: {y.shape}; class: {y.unique()}; type: {y.dtype}')\nz = y.reshape(2,1,1080,1920)\nprint(z.shape)","8d54ee5c":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(2,2, figsize=(20,20))\nax[0][0].imshow(x[0].permute(1,2,0), cmap='gray')\nax[0][1].imshow(y[0], cmap='gray')\nax[1][0].imshow(x[1].permute(1,2,0), cmap='gray')\nax[1][1].imshow(y[1], cmap='gray')\n\nplt.show()","22246faa":"import torch\nfrom unet import UNet\n\n#IMAGE_SIZE = (1080, 1920)\n\n#IMAGE_SIZE = (270, 480)\n\nmodel = UNet(in_channels=1,\n             out_channels=2,\n             n_blocks=4,\n             start_filters=32,\n             activation='relu',\n             normalization='batch',\n             conv_mode='same',\n             dim=2)\n\nx = torch.randn(size=(1, 1, IMAGE_SIZE[0], IMAGE_SIZE[1]), dtype=torch.float32)\nwith torch.no_grad():\n    out = model(x)\n\nprint(f'Out: {out.shape}')","3c1fd6ba":"from torchsummary import summary\nsummary = summary(model, (1, IMAGE_SIZE[0], IMAGE_SIZE[1]), device='cpu')","b5f25f77":"# Imports\nimport pathlib\nfrom transformations import ComposeDouble, normalize_01, AlbuSeg2d, FunctionWrapperDouble, create_dense_target\nfrom sklearn.model_selection import train_test_split\nfrom customdatasets import SegmentationDataSet3, SegmentationDataSet2\nimport torch\nimport numpy as np\nfrom unet import UNet\nfrom trainer import Trainer\nfrom torch.utils.data import DataLoader\nfrom skimage.transform import resize\nimport albumentations\n\n# root directory\nroot = '\/kaggle\/input\/boat-seagull\/'\n\n\ndef get_filenames_of_path(path: str, ext: str = '*'):\n    full_path_list = [os.path.join(path, file_name) for file_name in os.listdir(path)]\n    return  full_path_list\n\n\n# input and target files\ninputs = get_filenames_of_path(os.path.join(root,'images'))\ntargets = get_filenames_of_path(os.path.join(root,'masks'))\n\n# pre-transformations\npre_transforms = ComposeDouble([\n    FunctionWrapperDouble(resize,\n                          input=True,\n                          target=False,\n                          output_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n    FunctionWrapperDouble(resize,\n                          input=False,\n                          target=True,\n                          output_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1]),\n                          order=0,\n                          anti_aliasing=False,\n                          preserve_range=True),\n])\n\n# training transformations and augmentations\ntransforms_training = ComposeDouble([\n    AlbuSeg2d(albumentations.HorizontalFlip(p=0.5)),\n    FunctionWrapperDouble(create_dense_target, input=False, target=True),\n    FunctionWrapperDouble(np.moveaxis, input=True, target=False, source=-1, destination=0),\n    FunctionWrapperDouble(normalize_01)\n])\n\n# validation transformations\ntransforms_validation = ComposeDouble([\n    FunctionWrapperDouble(resize,\n                          input=True,\n                          target=False,\n                          output_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n    FunctionWrapperDouble(resize,\n                          input=False,\n                          target=True,\n                          output_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1]),\n                          order=0,\n                          anti_aliasing=False,\n                          preserve_range=True),\n    FunctionWrapperDouble(create_dense_target, input=False, target=True),\n    FunctionWrapperDouble(np.moveaxis, input=True, target=False, source=-1, destination=0),\n    FunctionWrapperDouble(normalize_01)\n])\n\n# random seed\nrandom_seed = 42\n\n# split dataset into training set and validation set\ntrain_size = 0.8  # 80:20 split\n\ninputs_train, inputs_valid = train_test_split(\n    inputs,\n    random_state=random_seed,\n    train_size=train_size,\n    shuffle=True)\n\ntargets_train, targets_valid = train_test_split(\n    targets,\n    random_state=random_seed,\n    train_size=train_size,\n    shuffle=True)\n\n# inputs_train, inputs_valid = inputs[:80], inputs[80:]\n# targets_train, targets_valid = targets[:80], targets[:80]\n\n# dataset training\ndataset_train = SegmentationDataSet3(inputs=inputs_train,\n                                    targets=targets_train,\n                                    transform=transforms_training,\n                                    use_cache=True,\n                                    pre_transform=pre_transforms)\n\n# dataset validation\ndataset_valid = SegmentationDataSet3(inputs=inputs_valid,\n                                    targets=targets_valid,\n                                    transform=transforms_validation,\n                                    use_cache=True,\n                                    pre_transform=pre_transforms)\n\n# dataloader training\ndataloader_training = DataLoader(dataset=dataset_train,\n                                 batch_size=2,\n                                 shuffle=True)\n\n# dataloader validation\ndataloader_validation = DataLoader(dataset=dataset_valid,\n                                   batch_size=2,\n                                   shuffle=True)\n\n\n# test\n\nroot_test = '\/kaggle\/input\/boat-seagull\/test_images\/'\n\n# input and target files\ninputs_test = get_filenames_of_path(os.path.join(root_test,'images'))\ntargets_test = get_filenames_of_path(os.path.join(root_test,'masks'))\n\n# pre-transformations\npre_transforms = ComposeDouble([\n    FunctionWrapperDouble(resize,\n                          input=True,\n                          target=False,\n                          output_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n    FunctionWrapperDouble(resize,\n                          input=False,\n                          target=True,\n                          output_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1]),\n                          order=0,\n                          anti_aliasing=False,\n                          preserve_range=True),\n])\n\n# validation transformations\ntransforms_test = ComposeDouble([\n    FunctionWrapperDouble(resize,\n                          input=True,\n                          target=False,\n                          output_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n    FunctionWrapperDouble(resize,\n                          input=False,\n                          target=True,\n                          output_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1]),\n                          order=0,\n                          anti_aliasing=False,\n                          preserve_range=True),\n    FunctionWrapperDouble(create_dense_target, input=False, target=True),\n    FunctionWrapperDouble(np.moveaxis, input=True, target=False, source=-1, destination=0),\n    FunctionWrapperDouble(normalize_01)\n])\n\n# dataset validation\ndataset_test = SegmentationDataSet3(inputs=inputs_test,\n                                    targets=targets_test,\n                                    transform=transforms_test,\n                                    use_cache=True,\n                                    pre_transform=pre_transforms)\n\n\n\n# dataloader validation\ndataloader_test = DataLoader(dataset=dataset_test,\n                                   batch_size=2,\n                                   shuffle=False)","16a710a0":"# device\ndevice = 'cpu'\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    torch.device('cpu')\n\n#HYPER PARAMTERES\nTRAIN_SIZE = .8\nIMAGE_SIZE = (536, 960)\nBATCH_SIZE = 2\nLEARNING_RATE = 0.0001\n\n\n# model\nmodel = UNet(in_channels=3,\n             out_channels=2,\n             n_blocks=4,\n             start_filters=32,\n             activation='relu',\n             normalization='batch',\n             conv_mode='same',\n             dim=2).to(device)\n\n\n# criterion\ncriterion = torch.nn.CrossEntropyLoss()\n\n# optimizer\n#optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\n\n\n# trainer\ntrainer = Trainer(model=model,\n                  device=device,\n                  criterion=criterion,\n                  optimizer=optimizer,\n                  training_DataLoader=dataloader_training,\n                  validation_DataLoader=dataloader_validation,\n                  test_DataLoader = dataloader_test,\n                  lr_scheduler=None,\n                  epochs=50,\n                  epoch=0,\n                  notebook=True)\n\n# start training\ntraining_losses, validation_losses, lr_rates, validation_iou, val_dice, test_loss, test_iou, test_dice = trainer.run_trainer()","a217c66e":"print(val_dice)","778eab74":"def plot_training(training_losses,\n                  validation_losses,\n                  learning_rate,\n                  gaussian=True,\n                  sigma=2,\n                  figsize=(8, 6)\n                  ):\n    \"\"\"\n    Returns a loss plot with training loss, validation loss and learning rate.\n    \"\"\"\n\n    import matplotlib.pyplot as plt\n    from matplotlib import gridspec\n    from scipy.ndimage import gaussian_filter\n\n    list_len = len(training_losses)\n    x_range = list(range(1, list_len + 1))  # number of x values\n\n    fig = plt.figure(figsize=figsize)\n    grid = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)\n\n    subfig1 = fig.add_subplot(grid[0, 0])\n    subfig2 = fig.add_subplot(grid[0, 1])\n\n    subfigures = fig.get_axes()\n\n    for i, subfig in enumerate(subfigures, start=1):\n        subfig.spines['top'].set_visible(False)\n        subfig.spines['right'].set_visible(False)\n\n    if gaussian:\n        training_losses_gauss = gaussian_filter(training_losses, sigma=sigma)\n        validation_losses_gauss = gaussian_filter(validation_losses, sigma=sigma)\n\n        linestyle_original = '.'\n        color_original_train = 'lightcoral'\n        color_original_valid = 'lightgreen'\n        color_smooth_train = 'red'\n        color_smooth_valid = 'green'\n        alpha = 0.25\n    else:\n        linestyle_original = '-'\n        color_original_train = 'red'\n        color_original_valid = 'green'\n        alpha = 1.0\n\n    # Subfig 1\n    subfig1.plot(x_range, training_losses, linestyle_original, color=color_original_train, label='Training',\n                 alpha=alpha)\n    subfig1.plot(x_range, validation_losses, linestyle_original, color=color_original_valid, label='Validation',\n                 alpha=alpha)\n    if gaussian:\n        subfig1.plot(x_range, training_losses_gauss, '-', color=color_smooth_train, label='Training', alpha=0.75)\n        subfig1.plot(x_range, validation_losses_gauss, '-', color=color_smooth_valid, label='Validation', alpha=0.75)\n    subfig1.title.set_text('Training & validation loss')\n    subfig1.set_xlabel('Epoch')\n    subfig1.set_ylabel('Loss')\n\n    subfig1.legend(loc='upper right')\n\n    # Subfig 2\n    subfig2.plot(x_range, learning_rate, color='black')\n    subfig2.title.set_text('Learning rate')\n    subfig2.set_xlabel('Epoch')\n    subfig2.set_ylabel('LR')\n\n    return fig\n\n\nfig = plot_training(training_losses, validation_losses, lr_rates, gaussian=True, sigma=1, figsize=(10, 4))","cb70499a":"# save the model\nmodel_name =  'boat_model.pt'\ntorch.save(model.state_dict(), pathlib.Path.cwd() \/ model_name)","da259627":"# device\ndevice = 'cpu'\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    torch.device('cpu')\n\n# model\nmodel = UNet(in_channels=3,\n             out_channels=2,\n             n_blocks=4,\n             start_filters=32,\n             activation='relu',\n             normalization='batch',\n             conv_mode='same',\n             dim=2).to(device)\n\n# criterion\ncriterion = torch.nn.CrossEntropyLoss()\n\n# optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)","afd7c180":"from lr_rate_finder import LearningRateFinder\nlrf = LearningRateFinder(model, criterion, optimizer, device)\nlrf.fit(dataloader_training, steps=1000)","99bf264c":"lrf.plot()","5c727a26":"# Imports\nimport pathlib\n\nimport numpy as np\nimport torch\nfrom skimage.io import imread\nfrom skimage.transform import resize\n\nfrom inference import predict\nfrom transformations import normalize_01, re_normalize\nfrom unet import UNet\nimport os\n\n# root directory\nroot = '\/kaggle\/input\/boat-seagull\/'\n\ndef get_filenames_of_path(path: str, ext: str = '*'):\n    full_path_list = [os.path.join(path, file_name) for file_name in os.listdir(path)]\n    return  full_path_list\n    \"\"\"Returns a list of files in a directory\/path. Uses pathlib.\"\"\"\n#    filenames = [file for file in path.glob(ext) if file.is_file()]\n#    return filenames\n\n\n# input and target files\nimages_names = get_filenames_of_path(os.path.join(root,'test'))\n\n# read images and store them in memory\nimages = [imread(img_name) for img_name in images_names]\n\n# Resize images and targets\nimages_res = [resize(img, (128, 128, 3)) for img in images]\nprint(len(images_res))\n#resize_kwargs = {'order': 0, 'anti_aliasing': False, 'preserve_range': True}\n#targets_res = [resize(tar, (128, 128), **resize_kwargs) for tar in targets]","b3b45b19":"import pathlib\n\nimport numpy as np\nimport torch\nfrom skimage.io import imread\nfrom skimage.transform import resize\n\nfrom inference import predict\nfrom transformations import normalize_01, re_normalize\nfrom unet import UNet\n\ndevice = 'cpu'\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    torch.device('cpu')\n\n# model\nmodel = UNet(in_channels=3,\n             out_channels=2,\n             n_blocks=4,\n             start_filters=32,\n             activation='relu',\n             normalization='batch',\n             conv_mode='same',\n             dim=2).to(device)\n\n\nmodel_name = 'boat_model.pt'\nmodel_weights = torch.load(pathlib.Path.cwd() \/ model_name)\n\nmodel.load_state_dict(model_weights)","01bd3a71":"# preprocess function\ndef preprocess(img: np.ndarray):\n    img = np.moveaxis(img, -1, 0)  # from [H, W, C] to [C, H, W]\n    img = normalize_01(img)  # linear scaling to range [0-1]\n    img = np.expand_dims(img, axis=0)  # add batch dimension [B, C, H, W]\n    img = img.astype(np.float32)  # typecasting to float32\n    return img\n\n\n# postprocess function\ndef postprocess(img: torch.tensor):\n    img = torch.argmax(img, dim=1)  # perform argmax to generate 1 channel\n    img = img.cpu().numpy()  # send to cpu and transform to numpy.ndarray\n    img = np.squeeze(img)  # remove batch dim and channel dim -> [H, W]\n    img = re_normalize(img)  # scale it to the range [0-255]\n    return img\n","21d01c6f":"# predict the segmentation maps \noutput = [predict(img, model, preprocess, postprocess, device) for img in images]","270dad30":"import matplotlib.pyplot as plt\n\nidx = 2\n#img_nap = viewer.add_image(images_res[idx], name='Input')\n#tar_nap = viewer.add_labels(targets_res[idx], name='Target')\n#out_nap = viewer.add_labels(output[idx], name='Prediction')\nTOTAL_IMAGE = len(images)\nfig, ax = plt.subplots(4,2, figsize=(20,20))\n\n#for i in range(TOTAL_IMAGE):\n#    ax[i][0].imshow(images[i], cmap='gray')\n#    ax[i][1].imshow(output[i], cmap='gray')\n\nax[0][0].imshow(images[0], cmap='gray')\nax[0][1].imshow(output[0], cmap='gray')\nax[1][0].imshow(images[1], cmap='gray')\nax[1][1].imshow(output[1], cmap='gray')\nax[2][0].imshow(images[2], cmap='gray')\nax[2][1].imshow(output[2], cmap='gray')\nax[3][0].imshow(images[3], cmap='gray')\nax[3][1].imshow(output[3], cmap='gray')\nplt.show()","33453fbb":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(2,2, figsize=(20,20))\nax[0][0].imshow(x[0].permute(1,2,0), cmap='gray')\nax[0][1].imshow(y[0], cmap='gray')\nax[1][0].imshow(x[1].permute(1,2,0), cmap='gray')\nax[1][1].imshow(y[1], cmap='gray')\n\nplt.show()","99b7c02d":"# Training","4d948988":"# Learning Rate Finder","56b003f1":"# Prepare Architecture","f0f5de85":"# Validate the dataset files","3dab9b90":"# Test Prediction","cc764444":"References\n1. https:\/\/github.com\/usuyama\/pytorch-unet\/blob\/master\/pytorch_unet_resnet18_colab.ipynb\n2. https:\/\/towardsdatascience.com\/creating-and-training-a-u-net-model-with-pytorch-for-2d-3d-semantic-segmentation-dataset-fb1f7f80fe55","0573c763":"# Prepare Data Loader","f79a53e6":"Test the data loader","6b725059":"Based on the picture, the best curve is at 10-2 = 0.01\n","031f2192":"# Environment Preparation"}}