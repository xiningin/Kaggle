{"cell_type":{"86a26157":"code","8c37e4ec":"code","53e8b391":"code","2d52b270":"code","bd7f93ef":"code","cf207463":"code","dde5da67":"code","98974cbb":"code","fc9b7f3e":"code","43844575":"code","1130c417":"code","99f00086":"code","751b45a2":"code","b4d9fc95":"code","d2ba71d2":"code","6bd9e896":"code","1ae37bf2":"code","ceabccf5":"code","fc82bdad":"code","4b2ac20f":"code","9b218e40":"code","1bf64be3":"code","4e0cf839":"code","f593c09a":"code","feedba13":"code","7ad42e5e":"code","731de093":"code","dd374df2":"code","0622ab08":"code","9feb9922":"code","74eba638":"code","254f0e42":"code","efba894b":"code","04064099":"code","73824100":"code","2d947dd9":"code","824c0057":"code","8ad32a73":"code","8f4560f3":"markdown","32df7eea":"markdown","56d5cdf3":"markdown","3f15ac80":"markdown","690d71e1":"markdown","5f581023":"markdown","7b289b97":"markdown","a6b34c0d":"markdown","cb37ebd9":"markdown","38f6a9a0":"markdown","eff0efc6":"markdown","f2c318cc":"markdown","a6bcb475":"markdown","ffa483d2":"markdown","b53a87f8":"markdown","0f109750":"markdown","d9b83fd0":"markdown","1614cd33":"markdown","a6988147":"markdown","3a3a68f0":"markdown","ba7af023":"markdown","c43727dc":"markdown","29b86fe4":"markdown","bf5ef32a":"markdown","e99311b0":"markdown","544ef531":"markdown","0b5db8d5":"markdown","f6f946ae":"markdown"},"source":{"86a26157":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8c37e4ec":"data_train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2022\/train.csv')\ndata_train","53e8b391":"data_test = pd.read_csv('\/kaggle\/input\/tabular-playground-series-jan-2022\/test.csv')\ndata_test","2d52b270":"data_train.describe()","bd7f93ef":"data_train.info()","cf207463":"print(data_train.isnull().values.any())","dde5da67":"country = data_train['country'].unique()\nprint('Unique value of country column: ',country)","98974cbb":"import matplotlib.pyplot as plt\n\n# figure(figsize=(8, 6), dpi=80)\ndata_train.value_counts(data_train['country']).plot.bar()\nplt.title('Data Distribution')\nplt.xlabel('Country')\nplt.ylabel('counts')\n# plt.legend()\nplt.show()","fc9b7f3e":"store = data_train['store'].unique()\nprint('Unique value of store column: ', store)","43844575":"# figure(figsize=(8, 6), dpi=80)\ndata_train.value_counts(data_train['store']).plot.bar()\nplt.title('Data Distribution')\nplt.xlabel('Store')\nplt.ylabel('counts')\n# plt.legend()\nplt.show()","1130c417":"product = data_train['product'].unique()\nprint('Unique value of product column: ', product)","99f00086":"data_train.value_counts(data_train['product']).plot.bar()\nplt.title('Data Distribution')\nplt.xlabel('Product')\nplt.ylabel('counts')\n# plt.legend()\nplt.show()","751b45a2":"duplicate = data_train[data_train.duplicated()]\nprint('Number of duplicated rows from dataset: ', duplicate.shape)","b4d9fc95":"print(data_train.isnull().sum())","d2ba71d2":"print(data_train.groupby('country').num_sold.sum())\ndata_train.groupby('country').num_sold.sum().plot(kind='bar')\nplt.title('Number of sold per Country')\nplt.xlabel('country')\nplt.ylabel('total')\n# plt.legend()\nplt.show()","6bd9e896":"data_train['date'] = pd.to_datetime(data_train['date'], errors='coerce')\ncountry = data_train.set_index('date')\ndf_country = country.groupby(['country', pd.Grouper(freq='y')]).num_sold.sum()\nprint(df_country)\ndf_country.plot(kind='bar')","1ae37bf2":"print(data_train.groupby('store').num_sold.sum())\ndata_train.groupby('store').num_sold.sum().plot(kind='bar')\nplt.title('Number of sold per Store')\nplt.xlabel('store')\nplt.ylabel('total')\n# plt.legend()\nplt.show()","ceabccf5":"data_train['date'] = pd.to_datetime(data_train['date'], errors='coerce')\nstore = data_train.set_index('date')\ndf_store = store.groupby(['store', pd.Grouper(freq='y')]).num_sold.sum()\nprint(df_store)\ndf_store.plot(kind='bar')","fc82bdad":"print(data_train.groupby('product').num_sold.sum())\ndata_train.groupby('product').num_sold.sum().plot(kind='bar')\nplt.title('Number of sold per Product')\nplt.xlabel('product')\nplt.ylabel('total')\n# plt.legend()\nplt.show()","4b2ac20f":"data_train['date'] = pd.to_datetime(data_train['date'], errors='coerce')\nproduct = data_train.set_index('date')\ndf_product = product.groupby(['product', pd.Grouper(freq='y')]).num_sold.sum()\nprint(df_product)\ndf_product.plot(kind='bar')","9b218e40":"print(data_train['country'].unique())","1bf64be3":"data_train['country'].replace(['Finland', 'Norway', 'Sweden'], [1, 2, 3], inplace=True)\ndata_train","4e0cf839":"print(data_train['store'].unique())","f593c09a":"data_train['store'].replace(['KaggleMart', 'KaggleRama'], [1, 2], inplace=True)\ndata_train","feedba13":"print(data_train['product'].unique())","7ad42e5e":"data_train['product'].replace(['Kaggle Mug', 'Kaggle Hat', 'Kaggle Sticker'], [1, 2, 3], inplace=True)\ndata_train","731de093":"X = data_train[['country', 'store', 'product']]\ny = data_train['num_sold']","dd374df2":"from sklearn import linear_model\nregression = linear_model.LinearRegression()\nregression.fit(X,y)","0622ab08":"data_test['country'].replace(['Finland', 'Norway', 'Sweden'], [1, 2, 3], inplace=True)\ndata_test['store'].replace(['KaggleMart', 'KaggleRama'], [1, 2], inplace=True)\ndata_test['product'].replace(['Kaggle Mug', 'Kaggle Hat', 'Kaggle Sticker'], [1, 2, 3], inplace=True)","9feb9922":"data_test","74eba638":"# get_data = data_test[['country', 'store' 'product']]\nget_data = data_test.iloc[:, 2:5]\nget_data\n\n# y_test = data_test['country','store', 'product']\n# y_test","254f0e42":"prediction = regression.predict(get_data)\nprediction","efba894b":"submission = pd.DataFrame({'row_id':data_test['row_id'], 'num_sold':prediction})\nsubmission","04064099":"#save submission to csv file\nsubmission.to_csv('submission.csv', index=False)","73824100":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators = 100, random_state = 0) \nrf.fit(X,y)","2d947dd9":"rf_pred = rf.predict(get_data)\nrf_pred","824c0057":"rf_submission = pd.DataFrame({'row_id':data_test['row_id'], 'num_sold':prediction})\nrf_submission","8ad32a73":"rf_submission.to_csv('rf_submission.csv', index=False)","8f4560f3":"#### **Number of Sold per Country for each year**","32df7eea":"## **2. Store**","56d5cdf3":"## **3. Product**","3f15ac80":"#### **1. Country**","690d71e1":"I use 2 algorithm to predict,there are Linear Regression and Random Forest Regression","5f581023":"#### **3. Product**","7b289b97":"#### **Number of Sold per Store for each year**","a6b34c0d":"#### **3. Product**","cb37ebd9":"# **Exploratory Data Analysis (EDA)**","38f6a9a0":"#### **Number of sold per Product**","eff0efc6":"## **Change data to numerical**","f2c318cc":"# **Unique value from each columns and Data Distribution plot**","a6bcb475":"to see how data types of train data","ffa483d2":"from above, there are no row has null value","b53a87f8":"to see if each column has a null value, this is the code below to see it","0f109750":"# **Import Dataset**","d9b83fd0":"We can see from above, there's no duplicate rows in dataset. (value is 0 as row and value is 6 as columns). Let us to see null values from each column.","1614cd33":"#### **Number of Sold per Product for each year**","a6988147":"## **1. Country**","3a3a68f0":"#### **1.Country**","ba7af023":"# **Prediction**","c43727dc":"## **Random Forest Regression**","29b86fe4":"#### **Number of sold per Store**","bf5ef32a":"#### **2. Store**","e99311b0":"#### **2. Store**","544ef531":"# **Descriptive Analysis (Data Train)**","0b5db8d5":"### **Number of sold per country**","f6f946ae":"## **Linear Regression**"}}