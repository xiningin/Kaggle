{"cell_type":{"dd33fa90":"code","4746cc95":"code","7cb0add5":"code","09041b08":"code","5c423b0b":"code","eaaa2b61":"code","e6a455ec":"code","c7b49780":"code","d91a54a4":"code","5f72c793":"code","ce5d78e5":"code","c9aba10e":"code","c57a87a5":"code","3f6b99d6":"code","9fbec00d":"code","00ed7c35":"code","186cd880":"code","10e3fae4":"code","d988c179":"code","8fb224cb":"code","57fb551a":"code","14c6b941":"code","99d45366":"code","07b03202":"code","9c069dc3":"code","e81d30e2":"code","f3db0435":"code","69864785":"code","a5761675":"code","6a7a95c7":"code","31214ac4":"code","3d40df8d":"code","7e6ab187":"code","619ea037":"code","93e63f96":"code","932fddcb":"code","ae152729":"code","42a4faa6":"code","1020751f":"code","0d78c44b":"markdown","bd2aa34a":"markdown","cf821e25":"markdown","b651b957":"markdown","e41c6ca7":"markdown","871d9479":"markdown","cf09a766":"markdown","6820a8ff":"markdown","557068b2":"markdown","7a06f8a3":"markdown","b87d80d1":"markdown","36d1b7b6":"markdown","fc3c80e8":"markdown","faf6a9a0":"markdown","12cac236":"markdown","663ad422":"markdown","46a01335":"markdown","abd9fd6d":"markdown","abdd9698":"markdown","25032c03":"markdown","5bddd216":"markdown","ed5333b2":"markdown","a024e854":"markdown","f3b92722":"markdown","57339ba4":"markdown","70f2f853":"markdown","43fc1562":"markdown","51d7d502":"markdown","cb92c31f":"markdown","057ba759":"markdown","d31fcc39":"markdown","69271c6b":"markdown","ada99d19":"markdown","bba9b8dd":"markdown","a9f00495":"markdown","c01a66b8":"markdown","a8488128":"markdown","194ad881":"markdown","17790fc3":"markdown","7ae7525a":"markdown","4f51571e":"markdown","31c0ffbf":"markdown","acfbf4fa":"markdown"},"source":{"dd33fa90":"# Remove warning messages\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport random\n\n# navigation and read files\nimport glob\nimport os\n\n# Read HDF5 binary data format: convenient for large data storage\nimport h5py\n\n# Read and display images\nimport matplotlib.pyplot as plt\nimport imageio\nimport cv2\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import img_to_array\n#from tensorflow import keras\n\n# DL dependancies\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, LeakyReLU,GlobalMaxPooling2D\nfrom tensorflow.keras.metrics import top_k_categorical_accuracy,categorical_accuracy\nfrom tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping","4746cc95":"# Path of images\nPATH_TO_DATA = '..\/input\/classification-of-handwritten-letters\/'\nCSV_FILES =  ['letters.csv', 'letters2.csv', 'letters3.csv']","7cb0add5":"def import_data(CSV_FILE):\n    data = pd.read_csv(PATH_TO_DATA + CSV_FILE)\n    # Create path extention for corresponding folders that contains images \n    data['source'] = CSV_FILE[:-4]+'\/'\n    return data","09041b08":"data1 = import_data(CSV_FILES[0])\ndata2 = import_data(CSV_FILES[1])\ndata3 = import_data(CSV_FILES[2])\ndata = pd.concat([data1, data2, data3], ignore_index=True)\n\n# I won't use these data anymore\ndel(data1, data2, data3)","5c423b0b":"# Shuffle data\ndata = shuffle(data, random_state = 42)","eaaa2b61":"data.head()","e6a455ec":"# Get all labels in one string\nletters = '' \nfor letter in data.letter.unique():\n    letters += letter\n    \n# Which letter is written on each image\nlabels = data.label","c7b49780":"def ohe_letters(label):\n    '''\n    One hot encoding for the target label\n    '''\n    resu = np.zeros(len(letters))\n    index = letters.index(label)\n    resu[index] = 1\n    return resu\n\ndef ohe_backgrounds(label):\n    '''\n    One hot encoding for background column\n    '''\n    resu = np.zeros(len(data.background.unique()))\n    resu[label] = 1\n    return resu","d91a54a4":"data['encoded_letter'] = data['letter'].apply(lambda x:ohe_letters(x))\ndata['encoded_background'] = data['background'].apply(lambda x:ohe_backgrounds(x))","5f72c793":"data.head()","ce5d78e5":"# Store all png images into one numpy array\nimages = []\n# Will be the target\nencoded_labels = []\n\nbackgrounds = []\nencoded_backgrounds = []\n\n# I want to be sure that every image is consitent\nfor i, row in data.iterrows():\n    img_name = row['file']\n    numpy_image = cv2.imread(os.path.join(PATH_TO_DATA + row['source'], img_name))\n    if numpy_image.shape == (32, 32, 3):\n        images.append(numpy_image)\n        encoded_labels.append(row['encoded_letter'])\n        backgrounds.append(row['background'])\n        encoded_backgrounds.append(row['encoded_background'])\n        \n# Normalize array of images\nimages = np.array(images)\/255","c9aba10e":"def display_image(images_list, list_of_labels = np.arange(9)):\n    \n    # plot first few images\n    plt.figure(figsize=(12,12))\n    for index in list_of_labels:\n        \n        # Get corresponding label\n        ohe_label = encoded_labels[index]\n        index_letter = list(ohe_label).index(1)\n        associated_letter = letters[index_letter]\n\n        # Get background\n        associated_background = backgrounds[index]\n        \n        \n        # define subplot\n        plt.subplot(330 + 1 + index)\n        plt.title('Label: %s \\n'%associated_letter+\\\n                 'Background: %s\\n'%associated_background,\n                 fontsize=18)\n        # plot raw pixel data\n        plt.imshow(images[index])\n        \n    plt.subplots_adjust(bottom = 0.001)  # the bottom of the subplots of the figure\n    plt.subplots_adjust(top = 0.99)\n    # show the figure\n    plt.show()","c57a87a5":"display_image(images)","3f6b99d6":"# Define X_data and target\nX = np.array(images.copy())\ny = np.array(encoded_labels.copy())\n\n# Stratified train_test split on labels\nX_train, X_val, y_train, y_val = train_test_split(X, y, \n                                                  test_size=.2, \n                                                  stratify = y, \n                                                  random_state=42)","9fbec00d":"# Define image dimensions\nIMG_ROWS = 32\nIMG_COLS = 32\n# 3 stands for RGB images, 1 if greyscaled images\nINPUT_SHAPE = (IMG_ROWS, IMG_COLS, 3)\n\n# Number of classes to consider\nNUM_CLASSES = len(letters)\n# Group of training samples\nBATCH_SIZE = 64\n# Number of complete presentations of the dataset to be learned\nEPOCHS = 100","00ed7c35":"def top_3_categorical_accuracy(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k=3)","186cd880":"def CNN_model(activation = 'softmax', \n              loss = 'categorical_crossentropy', \n              optimizer = 'adam', \n              metrics = ['accuracy', top_3_categorical_accuracy]):\n    \n    model = Sequential()\n    model.add(Conv2D(32, kernel_size = (3, 3),\n                     activation = 'relu',\n                     input_shape = INPUT_SHAPE))\n    model.add(Conv2D(64, (3, 3), activation = 'relu'))\n    model.add(Conv2D(128, (4, 4), activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(128, activation = 'relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(NUM_CLASSES, activation = activation))\n    \n    # Compile the model\n    model.compile(loss = loss,\n                  optimizer = optimizer, \n                  metrics = metrics)\n    \n    return model","10e3fae4":"# Init CNN model\ncnn_model = CNN_model()\n\n# Save weights only for best model\ncheckpointer = ModelCheckpoint(filepath = 'weights.best.letters.hdf5', \n                               verbose = 2, \n                               save_best_only = True)\n\n# Reduce learning rate when a metric has stopped improving\nlr_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                 patience=10, \n                                 verbose=2, \n                                 factor=.75)\n\n# If score doesn't improve during patience=20 epochs, stop learning\nestopping = EarlyStopping(monitor='val_loss', \n                          patience=20, \n                          verbose=2)\n\n# Training\nhistory = cnn_model.fit(X_train, y_train,\n                        batch_size = BATCH_SIZE,\n                        epochs = EPOCHS,\n                        verbose = 1,\n                        validation_data = (X_val, y_val),\n                        callbacks = [checkpointer, lr_reduction, estopping])","d988c179":"# list all data in history\nprint(history.history.keys())","8fb224cb":"def plot_history(model_history):\n\n    plt.figure(figsize = (20,15))\n    \n    plt.subplot(221)\n    # summarize history for accuracy\n    plt.plot(model_history.history['top_3_categorical_accuracy'])\n    plt.plot(model_history.history['val_top_3_categorical_accuracy'])\n    plt.title('top_3_categorical_accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.grid()\n    \n    plt.subplot(222)\n    # summarize history for accuracy\n    plt.plot(model_history.history['accuracy'])\n    plt.plot(model_history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.grid()\n    \n    plt.subplot(223)\n    # summarize history for loss\n    plt.plot(model_history.history['loss'])\n    plt.plot(model_history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.grid()\n    \n    plt.subplot(224)\n    # summarize history for lr\n    plt.plot(model_history.history['lr'])\n    plt.title('learning rate')\n    plt.ylabel('lr')\n    plt.xlabel('epoch')\n    plt.grid()\n    \n    plt.show()","57fb551a":"plot_history(history)","14c6b941":"# loading the model with the best validation accuracy\ncnn_model.load_weights('weights.best.letters.hdf5')\ncnn_model.evaluate(X_val, y_val)","99d45366":"def load_image(path_filename):\n\t# load the image\n\timg = load_img(path_filename, target_size=(32, 32))\n\t# convert to array\n\timg = img_to_array(img)\n\t# reshape into a single sample with 1 channel\n\timg = img.reshape(1, 32, 32, 3)\n\t# prepare pixel data\n\timg = img.astype('float32')\n\timg = img \/ 255.0\n\treturn img","07b03202":"def get_true_label(path_filename, dataframe, column_to_get):\n    filename = os.path.basename(os.path.normpath(path_filename))\n    index_row = data[data['file']==filename].index[0]\n    return data.loc[index_row, column_to_get]","9c069dc3":"img = load_image(PATH_TO_DATA+'letters3\/01_235.png')","e81d30e2":"# predict the class\na_letter = cnn_model.predict_classes(img)\n\nplt.imshow(img[0])\nprint('predicted:', letters[a_letter[0]])\nprint('true label:', get_true_label(PATH_TO_DATA+'letters3\/01_235.png', data, 'letter'))","f3db0435":"def load_random_images(number_of_images_to_load = 9):\n    images = []\n    true_labels = []\n    true_backgrounds = []\n    \n    which_folder = [random.randint(1,3) for _ in range(number_of_images_to_load)]\n    for index_folder in which_folder:\n        if index_folder == 1:\n            path = PATH_TO_DATA+'letters\/'\n        else:\n            path = PATH_TO_DATA+'letters'+str(index_folder)+'\/'\n        nb_files = len(os.listdir(path))\n        \n        index_image = random.randint(0, len(os.listdir(path)))\n        \n        image = load_image(path + os.listdir(path)[index_image])\n        label = get_true_label(path + os.listdir(path)[index_image], data, 'letter')\n        background = get_true_label(path + os.listdir(path)[index_image], data, 'background')\n\n        images.append(image)\n        true_labels.append(label)\n        true_backgrounds.append(background)\n        \n    return images, true_labels, true_backgrounds","69864785":"def classes_predictions(images_list_to_classify, true_labels, model):\n    \n    # plot first few images\n    plt.figure(figsize=(12,12))\n    for index, image in enumerate(images_list_to_classify):\n        \n        a_letter = model.predict_classes(image)\n        associated_letter = letters[a_letter[0]]\n        \n        # define subplot\n        plt.subplot(330 + 1 + index)\n        plt.title('Predicted Label: %s \\n'%associated_letter+\\\n                  'True Label: %s\\n'%true_labels[index],\n                 fontsize=18)\n        # plot raw pixel data\n        plt.imshow(image[0])\n        \n    plt.subplots_adjust(bottom = 0.001)  # the bottom of the subplots of the figure\n    plt.subplots_adjust(top = 0.99)\n        \n    # show the figure\n    plt.show()","a5761675":"test_images, true_labels, true_backgrounds = load_random_images()","6a7a95c7":"classes_predictions(test_images, true_labels, cnn_model)","31214ac4":"# Define X_data and target\nX = np.array(images.copy())\ny = np.array(encoded_backgrounds.copy())","3d40df8d":"# Stratified train_test split on labels\nX_train, X_val, y_train, y_val = train_test_split(X, y, \n                                                  test_size=.2, \n                                                  stratify = y, \n                                                  random_state=42)","7e6ab187":"# Define image dimensions\nIMG_ROWS = 32\nIMG_COLS = 32\n# 3 stands for RGB images, 1 if greyscaled images\nINPUT_SHAPE = (IMG_ROWS, IMG_COLS, 3)\n\n# Number of classes to consider\nNUM_CLASSES = len(set(backgrounds))\n# Group of training samples\nBATCH_SIZE = 32\n# Number of complete presentations of the dataset to be learned\nEPOCHS = 100","619ea037":"def CNN_back_model(activation = 'softmax', \n              loss = 'categorical_crossentropy', \n              optimizer = 'adam', \n              metrics = ['accuracy', top_3_categorical_accuracy]):\n    \n    model = Sequential()\n    model.add(Conv2D(32, kernel_size = (3, 3),\n                     activation = 'relu',\n                     input_shape = INPUT_SHAPE))\n    model.add(Conv2D(64, (3, 3), activation = 'relu'))\n    model.add(Conv2D(128, (4, 4), activation = 'relu'))\n    model.add(MaxPooling2D(pool_size = (2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(128, activation = 'relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(NUM_CLASSES, activation = activation))\n    \n    # Compile the model\n    model.compile(loss = loss,\n                  optimizer = optimizer, \n                  metrics = metrics)\n    \n    return model","93e63f96":"# Init CNN model\nbackground_model = CNN_back_model()\n\n# Save weights only for best model\ncheckpointer = ModelCheckpoint(filepath = 'weights.best.letters.hdf5', \n                               verbose = 2, \n                               save_best_only = True)\n\n# Reduce learning rate when a metric has stopped improving\nlr_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                 patience=10, \n                                 verbose=2, \n                                 factor=.75)\n\n# If score doesn't improve during patience=20 epochs, stop learning\nestopping = EarlyStopping(monitor='val_loss', \n                          patience=20, \n                          verbose=2)\n\n# Training\nhistory_background = background_model.fit(X_train, y_train,\n                                          batch_size = BATCH_SIZE,\n                                          epochs = EPOCHS,\n                                          verbose = 1,\n                                          validation_data = (X_val, y_val),\n                                          callbacks = [checkpointer, lr_reduction, estopping])","932fddcb":"plot_history(history_background)","ae152729":"# loading the model with the best validation accuracy\nbackground_model.load_weights('weights.best.letters.hdf5')\nbackground_model.evaluate(X_val, y_val)","42a4faa6":"def improved_classes_predictions(images_list_to_classify, true_labels, true_backgrounds, letter_model, backg_model):\n    \n    # plot first few images\n    plt.figure(figsize=(12,12))\n    for index, image in enumerate(images_list_to_classify):\n        \n        a_letter = letter_model.predict_classes(image)\n        associated_letter = letters[a_letter[0]]\n        \n        a_background_letter = background_model.predict_classes(image) \n        \n        # define subplot\n        plt.subplot(330 + 1 + index)\n        plt.title('Predicted Label: %s \\n'%associated_letter+\\\n                  'True Label: %s\\n'%true_labels[index]+\\\n                  'Predicted Background: %s\\n'%a_background_letter[0]+\\\n                  'True Background: %s\\n'%true_backgrounds[index],\n                 fontsize=18)\n        # plot raw pixel data\n        plt.imshow(image[0])\n        \n    plt.subplots_adjust(bottom = 0.001)  # the bottom of the subplots of the figure\n    plt.subplots_adjust(top = 0.99)\n        \n    # show the figure\n    plt.show()","1020751f":"improved_classes_predictions(test_images, true_labels, true_backgrounds, cnn_model , background_model)","0d78c44b":"**<font size=\"2\"><a href=\"#summary\">Back to summary<\/a><\/font>**\n\n-------","bd2aa34a":"## <font color='blue'>5.1 Setup<\/font>","cf821e25":"## <font color='blue'>2.2 Reshape, Filter and Normalize<\/font>","b651b957":"* **Convolutional layer** \n\n> <div align=\"justify\"><font size=\"3\">The very first layer where we extract features from the images in our datasets. Due to the fact that pixels are only related with the adjacent and close pixels, convolution allows us to preserve the relationship between different parts of an image. Convolution is basically filtering the image with a smaller pixel filter to decrease the size of the image without loosing the relationship between pixels. When we apply convolution to 5x5 image by using a 3x3 filter with 1x1 stride (1 pixel shift at each step). We will end up having a 3x3 output (64% decrease in complexity).<\/font><\/div>","e41c6ca7":"## <font color='blue'>3.6 Plot history errors<\/font>","871d9479":"# <div id=\"chap5\">5. Going further, A model for background recognition<\/div>","cf09a766":"# <div id=\"chap3\">3. A CNN Model for Handwritten Letters Classification<\/div>","6820a8ff":"## <font color='blue'>3.3 Good reflexes to have<\/font>","557068b2":"<div align=\"justify\"><font size=\"3\">For each row, we get the letter, its index in letters vector, the handwritten letter as .png file, the background of the paper the letter was written and the source. The goal of the preprocessing step is to encode the background and the letter column.<\/font><\/div>","7a06f8a3":"Meaning of background categories\n\n* striped = 0\n* gridded = 1\n* no background = 2\n* graph paper = 3","b87d80d1":"* **LeakyRelu**\n\n> <div align=\"justify\"><font size=\"3\">The advantage of using Leaky ReLU instead of ReLU is that in this way we cannot have vanishing gradient. Parametric ReLU has the same advantage with the only difference that the slope of the output for negative inputs is a learnable parameter while in the Leaky ReLU it's a hyperparameter.","36d1b7b6":"## <font color='blue'>3.5 Create model<\/font>","fc3c80e8":"## <font color='blue'>2.3 Display letters<\/font>","faf6a9a0":"<div align=\"justify\"><font size=\"3\">We're all set and the data are ready to feed the model. Let's create the model now.<\/font><\/div>","12cac236":"## <font color='blue'>4.1 Load one prediction<\/font>","663ad422":"### <font color=\"orange\">CNN layers","46a01335":"## <font color='blue'>1.3 Concatenate Data<\/font>","abd9fd6d":"## <font color='blue'>3.4 Define a custom metric<\/font>","abdd9698":"## <font color='blue'>1.2 Import Data<\/font>","25032c03":"<div align='center'><font size=\"5\" color='#353B47'>Handwritten Letters Classification<\/font><\/div>\n<div align='center'><font size=\"4\" color=\"#353B47\">With Convolutional Neural Networks<\/font><\/div>\n<br>\n<hr>","5bddd216":"# References\n\n* Many thanks to <a href=\"https:\/\/www.kaggle.com\/olgabelitskaya\">Olga Belitskaya<\/a> for the huge work on the <a href=\"https:\/\/www.kaggle.com\/olgabelitskaya\/classification-of-handwritten-letters\">data<\/a>\n* Insightful <a href=\"https:\/\/towardsdatascience.com\/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d\">article<\/a> on MNIST classification with CNN\n* Explanation of <a href=\"https:\/\/computersciencewiki.org\/index.php\/Max-pooling_\/_Pooling\">MaxPooling<\/a>\n* The <a href=\"https:\/\/towardsdatascience.com\/the-vanishing-gradient-problem-69bf08b15484\">vanishing gradient<\/a> problem","ed5333b2":"## <font color='blue'>1.1 Dependancies<\/font>","a024e854":"# <div id=\"chap1\">1. Setup<\/div>","f3b92722":"# <div id=\"chap1\">4. Evaluation<\/div>","57339ba4":"**<font size=\"2\"><a href=\"#summary\">Back to summary<\/a><\/font>**\n\n------","70f2f853":"* **Pooling layer**\n\n> <div align=\"justify\"><font size=\"3\">When constructing CNNs, it is common to insert pooling layers after each convolution layer to reduce the spatial size of the representation to reduce the parameter counts which reduces the computational complexity. In addition, pooling layers also <b>helps with the overfitting problem<\/b>. Basically we select a pooling size to reduce the amount of the parameters by selecting the maximum, average, or sum values inside these pixels.<\/font><\/div>","43fc1562":"## <font color='blue'>5.2 Evaluation & prediction plots<\/font>","51d7d502":"# <div id=\"chap2\">2. Preprocessing<\/div>","cb92c31f":"**<font size=\"2\"><a href=\"#summary\">Back to summary<\/a><\/font>**\n\n------","057ba759":"## <font color='blue'>3.1 What is a CNN ?<\/font>\n\n<div align=\"justify\"><font size=\"3\">A CNN is quite similar to Classic Neural Networks (RegularNets) where there are neurons with weights and biases. Just like in RegularNets, we use a loss function and an optimizer in CNNs. Additionally though, in CNNs, there are Convolutional Layers, Pooling Layers, and Flatten Layers. CNNs are mainly used for image classification.","d31fcc39":"## <font color='blue'>2.4 Prepare Train and Validation set<\/font>","69271c6b":"## <div id=\"summary\">Table of contents<\/div>\n\n**<font size=\"2\"><a href=\"#chap1\">1. Setup<\/a><\/font>**\n**<br><font size=\"2\"><a href=\"#chap2\">2. Preprocessing<\/a><\/font>**\n**<br><font size=\"2\"><a href=\"#chap3\">3. A CNN Model for Handwritten Letters Classification<\/a><\/font>**\n**<br><font size=\"2\"><a href=\"#chap4\">4. Evaluation<\/a><\/font>**\n**<br><font size=\"2\"><a href=\"#chap5\">5. Going further, A model for background recognition<\/a><\/font>**","ada99d19":"## <font color='blue'>1.4 Shuffle data<\/font>","bba9b8dd":"* **Add dropout**\n\n> <div align=\"justify\"><font size=\"3\">Dropout refers to ignoring neurons during the training phase of certain set of neurons which is chosen at random.","a9f00495":"<hr>\n<br>\n<div align='justify'><font color=\"#353B47\" size=\"4\">Thank you for taking the time to read this notebook. I hope that I was able to answer your questions or your curiosity and that it was quite understandable. <u>any constructive comments are welcome<\/u>. They help me progress and motivate me to share better quality content. I am above all a passionate person who tries to advance my knowledge but also that of others. If you liked it, feel free to <u>upvote and share my work.<\/u> <\/font><\/div>\n<br>\n<div align='center'><font color=\"#353B47\" size=\"3\">Thank you and may passion guide you.<\/font><\/div>","c01a66b8":"<div align=\"justify\"><font size=\"3\">The data has the correct format, we can now extract the information we need to train a model.<\/font><\/div>","a8488128":"## <font color='blue'>4.2 Load multiple predictions<\/font>","194ad881":"## <font color='blue'>3.2 Parameters<\/font>","17790fc3":"## <font color='blue'>2.1 One hot encoding<\/font>","7ae7525a":"**<font size=\"2\"><a href=\"#summary\">Back to summary<\/a><\/font>**\n\n-------","4f51571e":"* **Add callbacks**\n\n> <div align=\"justify\"><font size=\"3\">A callback is a function that is to be executed after another function has finished executing hence the name 'call back'. With callbacks, you can define earlystopping criterias for your model if it doesn't learn anymore through epochs. Callback allows you to store some information at the end of each epoch so you can check your model's performance.","31c0ffbf":"**<font size=\"2\"><a href=\"#summary\">Back to summary<\/a><\/font>**\n\n------","acfbf4fa":"* **Flatten layer**\n\n> <div align=\"justify\"><font size=\"3\">Flattens the input. Does not affect the batch size.<\/font><\/div>"}}