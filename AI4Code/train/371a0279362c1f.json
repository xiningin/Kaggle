{"cell_type":{"87ae2d52":"code","037d8486":"code","6a6e8735":"code","d76b38fe":"code","b74f5ca5":"code","3da0a12b":"code","ad23d159":"code","901f681b":"code","5b298176":"code","67d71b16":"code","cf1cfd98":"code","8eb68eca":"code","122e86a0":"code","39cd89f8":"code","f1a55e12":"code","475f0c8a":"code","fa88a0ea":"code","13591e4c":"code","58a192fc":"code","d82f1a0e":"code","05d2c427":"code","9ecde3a9":"code","56024489":"code","c8e68e22":"code","819763ff":"code","28378cc7":"code","c991c8b8":"code","f0f421d2":"code","87647621":"code","5bb87cbb":"code","e601d08d":"code","803b7064":"code","1248ed1c":"code","100f7215":"code","d5a740da":"code","2b2d5e63":"code","a6ad75f2":"code","1a742186":"code","acf73288":"code","b540a8f8":"code","f9abd57c":"code","1236e09e":"code","544915ab":"code","3e20e43f":"code","51546604":"code","a0dc9a56":"code","67072c2d":"code","b4c61959":"code","c2fbfefd":"code","6c1cc0dd":"code","4c1e64f8":"code","1b37a14d":"markdown","e6142d77":"markdown","2aa1eadb":"markdown","641b2db9":"markdown","86f0f9ef":"markdown","8c782034":"markdown","0bd7a68c":"markdown","d7d8d648":"markdown","debc28d8":"markdown","cc80f5f2":"markdown","05a460ad":"markdown","773437c9":"markdown","4a55154f":"markdown","b2c83726":"markdown","db59d603":"markdown","b9fe35c3":"markdown","2e4c53be":"markdown","b6067bc9":"markdown","25dba0be":"markdown","00550283":"markdown","301ae698":"markdown","4dff0541":"markdown","5a269966":"markdown","245fc55d":"markdown","e354cf18":"markdown","368b89bc":"markdown","e846e006":"markdown","5665bfcb":"markdown","3e96e563":"markdown","5b6492be":"markdown","b3a75e1c":"markdown","6407e15a":"markdown","a7dd0ea6":"markdown","dc22e201":"markdown","9f7c0728":"markdown","210cec83":"markdown","be75d937":"markdown","5c63d1dc":"markdown","098ac15a":"markdown","9ce75b01":"markdown","e79c1435":"markdown","a003fa78":"markdown","5938c994":"markdown","bc8abed3":"markdown","f89c40dd":"markdown","73aac568":"markdown","13becd27":"markdown","4456e840":"markdown"},"source":{"87ae2d52":"import warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(font='IPAGothic')\nimport numpy as np\nimport statsmodels.api as sm","037d8486":"train = pd.read_csv('..\/input\/train.csv' ,parse_dates=['date'],index_col='date')#('..\/input\/train.csv' ,parse_dates=['date'],index_col='date')\ntest = pd.read_csv('..\/input\/test.csv', parse_dates=['date'],index_col='date')#('..\/input\/test.csv', parse_dates=['date'],index_col='date')\ndf = pd.concat([train,test],sort=True)\nsample = pd.read_csv('..\/input\/sample_submission.csv')#('..\/input\/sample_submission.csv')","6a6e8735":"buf = df[(df.item==1)&(df.store==1)].copy()","d76b38fe":"res = sm.tsa.seasonal_decompose(buf.sales.dropna(),freq=365)\nfig = res.plot()\nfig.set_figheight(8)\nfig.set_figwidth(15)\nplt.show()","b74f5ca5":"#train_test_split\ntr_start,tr_end = '2014-01-01','2017-09-30'\nte_start,te_end = '2017-10-01','2017-12-31'\ntra = buf['sales'][tr_start:tr_end].dropna()\ntes = buf['sales'][te_start:te_end].dropna()","3da0a12b":"#ADF-test(Original-time-series)\nres = sm.tsa.adfuller(buf['sales'].dropna(),regression='ct')\nprint('p-value:{}'.format(res[1]))","ad23d159":"#ADF-test(differenced-time-series)\nres = sm.tsa.adfuller(buf['sales'].diff().dropna(),regression='c')\nprint('p-value:{}'.format(res[1]))","901f681b":"#ADF-test(Original-time-series)\nres = sm.tsa.adfuller(buf['sales']['2015-01-01':].dropna(),regression='ct')\nprint('p-value:{}'.format(res[1]))","5b298176":"#ADF-test(differenced-time-series)\nres = sm.tsa.adfuller(buf['sales']['2015-01-01':].diff().dropna(),regression='c')\nprint('p-value:{}'.format(res[1]))","67d71b16":"#we use tra.diff()(differenced data), because this time series is unit root process.\nfig,ax = plt.subplots(2,1,figsize=(20,10))\nfig = sm.graphics.tsa.plot_acf(tra.diff().dropna(), lags=50, ax=ax[0])\nfig = sm.graphics.tsa.plot_pacf(tra.diff().dropna(), lags=50, ax=ax[1])\nplt.show()","cf1cfd98":"resDiff = sm.tsa.arma_order_select_ic(tra, max_ar=7, max_ma=7, ic='aic', trend='c')\nprint('ARMA(p,q) =',resDiff['aic_min_order'],'is the best.')","8eb68eca":"arima = sm.tsa.statespace.SARIMAX(tra,order=(7,1,7),freq='D',seasonal_order=(0,0,0,0),\n                                 enforce_stationarity=False, enforce_invertibility=False,).fit()\narima.summary()\n#We can use SARIMAX model as ARIMAX when seasonal_order is (0,0,0,0) .","122e86a0":"res = arima.resid\nfig,ax = plt.subplots(2,1,figsize=(15,8))\nfig = sm.graphics.tsa.plot_acf(res, lags=50, ax=ax[0])\nfig = sm.graphics.tsa.plot_pacf(res, lags=50, ax=ax[1])\nplt.show()","39cd89f8":"from sklearn.metrics import mean_squared_error\npred = arima.predict(tr_end,te_end)[1:]\nprint('ARIMA model MSE:{}'.format(mean_squared_error(tes,pred)))","f1a55e12":"pd.DataFrame({'test':tes,'pred':pred}).plot();plt.show()","475f0c8a":"sarima = sm.tsa.statespace.SARIMAX(tra,order=(7,1,7),seasonal_order=(7,1,7,1),\n                                enforce_stationarity=False, enforce_invertibility=False,freq='D').fit()\nsarima.summary()","fa88a0ea":"res = sarima.resid\nfig,ax = plt.subplots(2,1,figsize=(15,8))\nfig = sm.graphics.tsa.plot_acf(res, lags=50, ax=ax[0])\nfig = sm.graphics.tsa.plot_pacf(res, lags=50, ax=ax[1])\nplt.show()","13591e4c":"from sklearn.metrics import mean_squared_error\npred = sarima.predict(tr_end,te_end)[1:]\nprint('SARIMA model MSE:{}'.format(mean_squared_error(tes,pred)))","58a192fc":"pd.DataFrame({'test':tes,'pred':pred}).plot();plt.show()","d82f1a0e":"buf.groupby(buf.index.month).sales.mean().plot();plt.show()","05d2c427":"buf.groupby(buf.index.weekday).sales.mean().plot();plt.show()","9ecde3a9":"plt.plot(buf[0:363].sales.dropna().values)\nplt.plot(buf[364:727].sales.dropna().values);plt.show()","56024489":"buf = df[(df.item==1)&(df.store==1)].copy()#reset buf\n#month one hot encoding\nbuf['month'] = buf.index.month\nmonth_dummies = pd.get_dummies(buf['month'])\nmonth_dummies.columns = ['month-'+ str(m) for m in range(1,13)]\nbuf = pd.concat([buf, month_dummies], axis=1, join_axes=[buf.index]).drop(['month'],axis=1)\n#dayofweek one hot encoding\nbuf['dayofweek'] = buf.index.weekday\nweek_dummies = pd.get_dummies(buf['dayofweek'])\nweek_dummies.columns = ['dayofweek-'+ str(w) for w in range(0,7)]\nbuf = pd.concat([buf, week_dummies], axis=1, join_axes=[buf.index]).drop(['dayofweek'],axis=1)\n#Satday,Sunday\nbuf['weekend'] = (buf.index.dayofweek>4).astype(int)#Satday,Sunday\n#Sunday\n#buf['sunday'] = (buf.index.dayofweek==6).astype(int)#Satday,Sunday","c8e68e22":"#shifted data\n#buf['sales_shifted_91'] = buf.sales.shift(91)\nbuf['sales_shifted_728'] = buf.sales.shift(728)\nbuf['sales_shifted_364'] = buf.sales.shift(364)","819763ff":"tr_start,tr_end = '2015-01-01','2017-09-30'\nte_start,te_end = '2017-10-01','2017-12-31'\ntra = buf['sales'][tr_start:tr_end].dropna()\ntes = buf['sales'][te_start:te_end].dropna()\nexog_train = buf.drop(['id','store','item','sales'],axis = 1)[tr_start:tr_end].dropna()\nexog_test = buf.drop(['id','store','item','sales'],axis = 1)[te_start:te_end].dropna()","28378cc7":"arimax = sm.tsa.statespace.SARIMAX(tra,order=(7,1,7),seasonal_order=(0,0,0,0),exog = exog_train,freq='D',\n                                  enforce_stationarity=False, enforce_invertibility=False,).fit()\narimax.summary()\n#We can use SARIMAX model as ARIMAX when seasonal_order is (0,0,0,0) .","c991c8b8":"res = arimax.resid\nfig,ax = plt.subplots(2,1,figsize=(15,8))\nfig = sm.graphics.tsa.plot_acf(res, lags=50, ax=ax[0])\nfig = sm.graphics.tsa.plot_pacf(res, lags=50, ax=ax[1])\nplt.show()","f0f421d2":"from sklearn.metrics import mean_squared_error\npred = arimax.predict(tr_end,te_end,exog = exog_test)[1:]\nprint('ARIMAX model MSE:{}'.format(mean_squared_error(tes,pred)))","87647621":"pd.DataFrame({'test':tes,'pred':pred}).plot();plt.show()","5bb87cbb":"arimax.plot_diagnostics(figsize=(15, 12))","e601d08d":"sarimax = sm.tsa.statespace.SARIMAX(tra,order=(7,1,7),seasonal_order=(1,0,5,1),exog = exog_train,\n                                enforce_stationarity=False, enforce_invertibility=False,freq='D').fit()\nsarimax.summary()","803b7064":"res = sarimax.resid\nfig,ax = plt.subplots(2,1,figsize=(15,8))\nfig = sm.graphics.tsa.plot_acf(res, lags=50, ax=ax[0])\nfig = sm.graphics.tsa.plot_pacf(res, lags=50, ax=ax[1])\nplt.show()","1248ed1c":"from sklearn.metrics import mean_squared_error\npred = sarimax.predict(tr_end,te_end,exog = exog_test)[1:]\nprint('SARIMAX model MSE:{}'.format(mean_squared_error(tes,pred)))","100f7215":"pd.DataFrame({'test':tes,'pred':pred}).plot();plt.show()","d5a740da":"sarimax.plot_diagnostics(figsize=(15, 12))","2b2d5e63":"arimax.resid.plot();plt.show()","a6ad75f2":"res_df = pd.DataFrame(arimax.resid,columns=['resid'])\nres_df.sort_values(by='resid',ascending=False).head(5)","1a742186":"plt.figure(figsize=(10,15))\npiv_val = buf.pivot_table(values='sales',\n                          index=buf.index.day,\n                          columns=buf.index.month,\n                          aggfunc='mean')\nsns.heatmap(piv_val)\nplt.show()","acf73288":"buf[(buf.index.day == 28)&(buf.index.month == 6)]['sales']","b540a8f8":"#traindata predict\npred = arimax.predict(tr_start,tr_end,exog = exog_train)[1:]\npd.DataFrame({'train':tra['2017-06-20':'2017-06-30'],\n              'pred':pred['2017-06-20':'2017-06-30']}).plot();plt.show()","f9abd57c":"#outlier etc...\nbuf['outlier_flag']=0\nbuf.loc[buf.index == '2017-06-28','outlier_flag']=1","1236e09e":"tr_start,tr_end = '2015-01-01','2017-09-30'\nte_start,te_end = '2017-10-01','2017-12-31'\ntra = buf['sales'][tr_start:tr_end].dropna()\ntes = buf['sales'][te_start:te_end].dropna()\nexog_train = buf.drop(['id','store','item','sales'],axis = 1)[tr_start:tr_end].dropna()\nexog_test = buf.drop(['id','store','item','sales'],axis = 1)[te_start:te_end].dropna()","544915ab":"arimax_2 = sm.tsa.statespace.SARIMAX(tra,order=(7,1,7),seasonal_order=(0,0,0,0),exog = exog_train,\n                                enforce_stationarity=False, enforce_invertibility=False,freq='D').fit()\narimax_2.summary()","3e20e43f":"res = arimax_2.resid\nfig,ax = plt.subplots(2,1,figsize=(15,8))\nfig = sm.graphics.tsa.plot_acf(res, lags=50, ax=ax[0])\nfig = sm.graphics.tsa.plot_pacf(res, lags=50, ax=ax[1])\nplt.show()","51546604":"from sklearn.metrics import mean_squared_error\npred = arimax_2.predict(tr_end,te_end,exog = exog_test)[1:]\nprint('ARIMAX model MSE:{}'.format(mean_squared_error(tes,pred)))","a0dc9a56":"pd.DataFrame({'test':tes,'pred':pred}).plot();plt.show()","67072c2d":"arimax_2.plot_diagnostics(figsize=(15, 12))","b4c61959":"train = pd.read_csv('..\/input\/train.csv' ,parse_dates=['date'],index_col='date')\ntest = pd.read_csv('..\/input\/test.csv', parse_dates=['date'],index_col='date')\ndf = pd.concat([train,test],sort=True)\nsample = pd.read_csv('..\/input\/sample_submission.csv')","c2fbfefd":"#month one hot encoding\ndf['month'] = df.index.month\nmonth_dummies = pd.get_dummies(df['month'])\nmonth_dummies.columns = ['month-'+ str(m) for m in range(1,13)]\ndf = pd.concat([df, month_dummies], axis=1, join_axes=[df.index]).drop(['month'],axis=1)\n#dayofweek one hot encoding\ndf['dayofweek'] = df.index.weekday\nweek_dummies = pd.get_dummies(df['dayofweek'])\nweek_dummies.columns = ['dayofweek-'+ str(w) for w in range(0,7)]\ndf = pd.concat([df, week_dummies], axis=1, join_axes=[df.index]).drop(['dayofweek'],axis=1)\n#Satday,Sunday\ndf['weekend'] = (df.index.dayofweek>4).astype(int)#Satday,Sunday\n\n#shifts\nshifts = [364,728]\nfor s in shifts:\n    df['store_item_shifted-'+str(s)] = df.groupby([\"item\",\"store\"])['sales'].transform(lambda x:x.shift(s))","6c1cc0dd":"results = []\ntr_start,tr_end = '2015-01-01','2017-09-30'\nte_start,te_end = '2017-10-01','2017-12-31'\nfor i in range(1,51):\n    for s in range(1,11):\n        buf = df[(df.item==i)&(df.store==s)].copy()\n        #buf['sales_shifted_728'] = buf.sales.shift(728)\n        #buf['sales_shifted_364'] = buf.sales.shift(364)\n        #target_exog = buf[~buf.id.isnull()].drop(['id','store','item','sales'],axis = 1)#exog for predict.\n        target_exog = buf[te_start:].drop(['id','store','item','sales'],axis = 1)#exog for predict.\n        \n        #train_test_split\n        tra = buf['sales'][tr_start:tr_end]#.dropna()\n        tes = buf['sales'][te_start:te_end]#.dropna()\n        exog_train = buf.drop(['id','store','item','sales'],axis = 1)[tr_start:tr_end]#.dropna()\n        #exog_test = buf.drop(['id','store','item','sales'],axis = 1)[te_start:te_end]#.dropna()\n        \n        #fitting\n        mod = sm.tsa.statespace.SARIMAX(tra,order=(7,1,7),seasonal_order=(0,0,0,0),exog = exog_train,freq='D',\n                                       enforce_stationarity=False, enforce_invertibility=False).fit()\n        pred = mod.get_prediction(tr_end,'2018-03-31',exog =target_exog)#pd.concat([exog_test,target_exog]))\n        results.extend(pred.predicted_mean['2018-01-01':])\n        print('item:',i,'store:',s,'Finished.')","4c1e64f8":"sample['sales'] = results\nsample.to_csv('submission.csv',index=False)","1b37a14d":"Sales gropu by day of the week.","e6142d77":"# modules import","2aa1eadb":"The two data looks like the same.","641b2db9":"It seems that ARIMAX model's prediction is better than SARIMAX model's.  \nAnd  because SARIMA(X) model has a issue(seasonal period parameter),we choose ARIMAX model.","86f0f9ef":"Usually,\u3000We try to testing\u3000both data Original and Diff.  \nLike the results above, When Original-data is not stationary and Diff-data is stationary,the time series is called unit root process.  \nFor unit root process, We use ARIMA or SARIMA model.","8c782034":"# ARIMAX Model's summary check","0bd7a68c":"# SARIMA model","d7d8d648":" I don't know the best way to estimate seasonal_order(sp,sd,sq,s) parameters.  \nparameter s:\n- 1 for yearly\n- 4 for quarterly\n- 12 for monthly\n- 52 for weekly\n- 365 for daily \n\n[https:\/\/www.statsmodels.org\/dev\/generated\/statsmodels.tsa.statespace.sarimax.SARIMAX.html](https:\/\/www.statsmodels.org\/dev\/generated\/statsmodels.tsa.statespace.sarimax.SARIMAX.html) \n\nWhen we choose period 365,It will run out of memory.  \nIt will probably, SARIMA model is unsuitable to solve this problem.  \n[Forecasting with long seasonal periods(for R)](https:\/\/robjhyndman.com\/hyndsight\/longseasonality\/)  \n[Deciding the value of period in seasonal ARIMA (for R)](https:\/\/stats.stackexchange.com\/questions\/225995\/deciding-the-value-of-period-in-seasonal-arima-r)  \n\nFor now,we choose period 1.","debc28d8":"Clearly,this data is growing(has a trend).","cc80f5f2":"# Train & Test Data split","05a460ad":"We have to choice a model, After we comfirm that a data has a trend(is stationary) or not.  \nFor example, ARMA model is premised that the data is stationary.","773437c9":"The results of Jarque-Bera test and Ljung-Box test provide an indication of the validity of this model.\n \n In this model's summary, Jarque-Bera test's Prob is under 0.05.  \n It means that this model's resid is not following a normal distribution.  \n In other words, some infomations still remain in this model's resid.  \n \nLook at the histgram which was output by plot_diagnostics method,\nIt looks like slightly skew.\n\nLjung-Box test:\n[https:\/\/en.wikipedia.org\/wiki\/Ljung%E2%80%93Box_test](https:\/\/en.wikipedia.org\/wiki\/Ljung%E2%80%93Box_test)\n\nJarque-Bera test:\n[https:\/\/en.wikipedia.org\/wiki\/Jarque%E2%80%93Bera_test](https:\/\/en.wikipedia.org\/wiki\/Jarque%E2%80%93Bera_test)","4a55154f":"Sales gropu by month","b2c83726":"The histgram looks like still skew, but Jarque-Bera test's Prob is over 0.05.  \nIt means that this model's resid is following a normal distribution.    \n\nAn added featrue was useless to grow up predict accuracy.  \nbut, we were able to make a better model.","db59d603":"# ARIMAX model","b9fe35c3":"# Model choice","2e4c53be":"# data-set reading","b6067bc9":"The outlier is the sales in '2017-06-28'.  \nIs the date an anniversary or something?","25dba0be":"each models have parameters.\n- ARMA model:(p,q)\n- ARIMA model:(p,d,q)\n- SARIMA model:(p,d,q)(sp,sd,sq,s)\n- ARIMAX model:(p,d,q) + exog\n- SARIMAX model:(p,d,q)(sp,sd,sq,s) +exog","00550283":"This model's resid have few autocorrelation.  \nIt means that We were able to make a good model.","301ae698":"What is adfuller method parameter 'regression'?\n- \u2019c\u2019 : constant only (default)\n- \u2019ct\u2019 : constant and trend\n- \u2019ctt\u2019 : constant, and linear and quadratic trend\n- \u2019nc\u2019 : no constant, no trend\n\n[https:\/\/www.statsmodels.org\/dev\/generated\/statsmodels.tsa.stattools.adfuller.html](https:\/\/www.statsmodels.org\/dev\/generated\/statsmodels.tsa.stattools.adfuller.html) \n","4dff0541":"We make a new featrue and added.","5a269966":"From results,We decided that Original time series is not stational.    \nWe will try to using ARIMA model.","245fc55d":"# ARIMA model","e354cf18":"Update : 2018-09-11   \nThis kernel is what I wrote method of time series analysis that I know.  \nPlease let me know if I make any mistakes.\n\nThe order of explain is as follows.\n1. Overview of the data\n2. Model choice\n3. Correlograms\n4. ARIMA\n5. SARIMA\n6. Make featrues1\n7. ARIMAX\n8. SARIMAX\n9. Model's summary check\n10. Make featrues2\n11. Search best parameters\n12. Submit Prediction \n\nReferenced documents:\n-  [http:\/\/barnesanalytics.com\/analyzing-multivariate-time-series-using-arimax-in-python-with-statsmodels](http:\/\/barnesanalytics.com\/analyzing-multivariate-time-series-using-arimax-in-python-with-statsmodels) ","368b89bc":"It seems that there is outlier in this model's resid on late June.","e846e006":"We can use ADF-test to check stationary of the data.","5665bfcb":"It's important to choose carefully a period of the data which will be used in predicting. Because, The results depend on the period.","3e96e563":"import itertools\nfrom sklearn.metrics import mean_squared_error\n\np = q = range(7,8)\npdq = list(itertools.product(p, [1], q))\nsp = sq = range(1,8)#range(0,1) <- ARIMAX\nseasonal_pdq = list(itertools.product(sp, [0,1], sq,[1]))#rlist(itertools.product(sp, [0], sq,[0]))<- ARIMAX\n\nparams = []\nparams_s = []\naics = []\nmses = []\ncnt = 0\nfor param in pdq:\n    for param_seasonal in seasonal_pdq:\n\n        try:\n            mod = sm.tsa.statespace.SARIMAX(tra,\n                                            order=param,\n                                            exog = exog_train,\n                                            seasonal_order=param_seasonal,\n                                            freq='D',\n                                            enforce_stationarity=False,\n                                            enforce_invertibility=False)\n\n            results = mod.fit()\n\n            pred = results.get_prediction(start = pd.to_datetime(tr_end),\n                                      end = pd.to_datetime(te_end),exog=exog_test)\n\n            params.append(param)\n            params_s.append(param_seasonal)\n            aics.append(results.aic)\n            mses.append(mean_squared_error(tes,pred.predicted_mean[1:]))\n\n\n            #if cnt % 8 == 0:\n            print('SARIMAX{}x{} - AIC:{} - MSE:{}'.format(param,\n                                                            param_seasonal,\n                                                            results.aic,\n                                                        mses[-1]))\n                #cnt += 1\n\n        except:\n            continue\n\nmin_ind = aics.index(min(aics))\nbestparam = (params[min_ind],params_s[min_ind])\nprint('best_param_aic:',bestparam,' aic:',min(aics))\nmin_ind = mses.index(min(mses))\nbestparam = (params[min_ind],params_s[min_ind])\nprint('best_param_mse:',bestparam,' mse:',min(mses))\n\nprint('Finish!!')","5b6492be":"# Overview of the data.","b3a75e1c":"# Submit Prediction","6407e15a":"# Make featrues2","a7dd0ea6":"Let's try to make some features.\n- month\n- dayofweek\n- sales_shifted_364(1year_shift)\n- sales_shifted_728(2year_shift)","dc22e201":"# Correlograms","9f7c0728":"# Introduction","210cec83":"# SARIMAX model","be75d937":"# Make features1","5c63d1dc":"28th June 2017's sales is too big as other 28th June sales!   \nBesides, that one day is a weekday.","098ac15a":"Autocorrelogram & Partail Autocorrelogram is useful that to estimate each models parametaers.","9ce75b01":"We got parameters (7,1,7).","e79c1435":"Let's see overview of the data.  \nWe can use seasonal_decompose method to separate into four graphs(Observed,Trend,Seasonal,Residual).  \nWhat is seasonal_decompose method parameter 'freq'?\n- freq = 365 : trend of year.  \n- freq = 30 : trend of month.  \n- freq = 7 : trend of week.  \n\nWe choose 'freq=365' ,because this data is long term.","a003fa78":"From results,looks like ARIMA(p=7,d=1,q=?) model.","5938c994":"if we use arma_order_select_ic method, it is very easy to search best parameters(p,q) of ARMA model.","bc8abed3":"We can search best parameters of SARIMAX on this code.","f89c40dd":"# Search best parameters","73aac568":"It seems that SARIMA model's prediction is better than ARIMA model's.","13becd27":"Next,We try to ARIMAX and SARIMAX model.  \nARIMAX(SARIMAX) is what added  exogenous regressors to ARIMA(SARIMA) .","4456e840":"We use item1_store1_sales time series in this kernel."}}