{"cell_type":{"713605a6":"code","54ebdc5f":"code","4d1cec99":"code","d837886e":"code","cefb6b10":"code","9ff4ccb7":"code","6f6a527f":"code","5d2f8c89":"code","63829738":"code","3f5cda2c":"code","96740edf":"code","10bfca15":"code","1a3612c5":"markdown"},"source":{"713605a6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","54ebdc5f":"# print(open(\"\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv\"))\n# # load the dataset\ndataset = pd.read_csv(\"\/kaggle\/input\/sms-spam-collection-dataset\/spam.csv\", encoding='latin_1')\ndataset.head()","4d1cec99":"# remove all the empty columns\ndataset = dataset.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\ndataset.head()","d837886e":"# printing top 5 messages \nprint(dataset.iloc[:5,:])","cefb6b10":"import nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import stopwords\nimport string\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score","9ff4ccb7":"# remove the stop words from the messages\ndef remove_stopwords(sentence):\n    words = sentence.split()\n    result = []\n    for word in words:\n        if word not in stopwords.words('english'):\n            result.append(word)\n    ans = \" \".join(result)\n    return ans\n\ndef remove_punctuations(sentence):\n    words = sentence.split()\n    for i, word in enumerate(words):\n        temp_word = \"\"\n        for c in word:\n            if c not in string.punctuation:\n                temp_word+=c\n        words[i] = temp_word\n    return \" \".join(words)\n\ndef stem(sentence):\n    # stem the given sentence\n    words = sentence.split()\n    stemmer = PorterStemmer()\n    for i, word in enumerate(words):\n        words[i] = stemmer.stem(word)\n    return \" \".join(words)\n    \n\ndef preprocess_text(sentence):\n    # remove stopwords\n    new_sentence = remove_stopwords(sentence)\n    # first remove punctuations\n    new_sentence = remove_punctuations(new_sentence)\n    # perform stemming\n    new_sentence = stem(new_sentence)\n    return new_sentence\n        \n# create a word vector using any technique\n\ndef bow(corpus):\n    \"\"\"\n    generates bag of words\n    \"\"\"\n    from sklearn.feature_extraction.text import CountVectorizer\n    cv = CountVectorizer(max_features=5000)\n    X = cv.fit_transform(corpus)\n    X = X.toarray()\n    return X\n","6f6a527f":"corpus = []\nfor i in range(len(dataset)):\n    msg = dataset['v2'][i].lower()\n    msg = preprocess_text(msg)\n    corpus.append(msg)\nprint(corpus[:10])","5d2f8c89":"X = bow(corpus)\nprint(X.shape)\nprint(type(X))","63829738":"# get the Y \ny = pd.get_dummies(dataset['v1'])\n# only one column would suffice\ny = y.iloc[:,1] # every value, if 0 identifies msg as normal, if 1 its a spam\nprint(y.shape)\n","3f5cda2c":"\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)","96740edf":"model = MultinomialNB()\nmodel.fit(X_train, y_train)\n# prediction time\npredictions = model.predict(X_test)\n","10bfca15":"score = accuracy_score(y_test, predictions)\ncm = confusion_matrix(y_test, predictions)\nprint(f\"confusion matrix: {cm}\")\nprint(f\"accuracy score: {score}\")","1a3612c5":"**EXPLORATORY DATA ANALYSIS******"}}