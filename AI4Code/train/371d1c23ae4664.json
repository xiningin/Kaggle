{"cell_type":{"ff457d2f":"code","8d8aa255":"code","cbed1996":"code","4f8886b1":"code","73c5dd3e":"code","d7179ac3":"code","117f7a66":"code","f8c3fda5":"code","f99b2306":"code","5ef2193d":"code","9e2f49ee":"code","2208599a":"code","510cd986":"code","2f4a7463":"code","1e16fb4d":"code","cda37d29":"code","40585927":"code","86e8987f":"markdown","245cfe8c":"markdown","3a753a8a":"markdown","8b1c8d56":"markdown","24205750":"markdown","31155135":"markdown","0a27a775":"markdown","870f3e4a":"markdown","fd727f83":"markdown","54f3a740":"markdown","6a524e3e":"markdown","bc097d5a":"markdown","752d7e49":"markdown","b252a5a1":"markdown","e5f0e3cd":"markdown","ed881bad":"markdown"},"source":{"ff457d2f":"# Folders and files in dataset\nimport glob\nprint(glob.os.listdir(\"\/kaggle\/input\/landmark-recognition-2020\/\"))","8d8aa255":"import pandas as pd\nimport numpy as np\ntrainCsv = pd.read_csv(\"\/kaggle\/input\/landmark-recognition-2020\/train.csv\")\n\nprint(f\"Shape of train.csv dataframe: {trainCsv.shape}\")","cbed1996":"# Head sample\ntrainCsv.head(3)","4f8886b1":"# Tail sample\ntrainCsv.tail(3)","73c5dd3e":"landmarkValueCount = pd.value_counts(trainCsv[\"landmark_id\"])\nprint(f\"Number of n\/a values:\\n{trainCsv.isna().sum()}\")\nprint(\"No n\/a found.\\n\")\nprint(\"All Id: \", len(trainCsv[\"id\"]), \"\\nUnique Id: \", len(pd.unique(trainCsv[\"id\"])))\nprint(\"No id is repeted.\\n\")\nprint(f\"Unique number of landmark id: {len(trainCsv['landmark_id'].unique())}\\n\")\nprint(f\"Average Images per class: {len(trainCsv)\/len(trainCsv['landmark_id'].unique())}\")\n\nprint(f\"Mininum number of images of a landmark: {min(landmarkValueCount)}\")\nprint(f\"Maximum number of images of a landmark: {max(landmarkValueCount)}\")\nprint(f\"Average number of images of a landmark: {np.mean(landmarkValueCount.values)}\\n\")\nprint(f\"Number of landmark having 2 images: {sum(landmarkValueCount==2)}\")\nprint(f\"Number of landmark having 6272 images: {sum(landmarkValueCount==6272)}\")\nprint(f\"Number of landmark having 19 images: {sum(landmarkValueCount==19)}\")","d7179ac3":"import matplotlib.pyplot as plt\nimport seaborn as sns","117f7a66":"plt.figure(figsize=(15,7))\nax = sns.distplot(trainCsv[\"landmark_id\"])\nplt.xlabel('landmark_id')\nplt.title(\"Distribution of landmark_id\")\nplt.show()","f8c3fda5":"fig, ax = plt.subplots(1,2,figsize=(20,7))\nsns.distplot(landmarkValueCount, ax=ax[0])\nax[0].set_xlabel('landmark_id count')\nax[0].set_title(\"Distribution of landmark_id count\")\n\nsns.distplot(np.log10(landmarkValueCount), ax=ax[1])\nax[1].set_xlabel('Log of landmark_id count')\nax[1].set_title(\"Distribution of log of landmark_id count\")\nplt.show()","f99b2306":"plt.figure(figsize=(15,7))\nsample = landmarkValueCount[0:50].reset_index()\nax = sns.barplot(\"index\", \"landmark_id\", data=sample, order=sample[\"index\"], palette=\"Blues_d\")\nfor item in ax.get_xticklabels(): item.set_rotation(90)\nfor i, v in enumerate(sample[\"landmark_id\"].iteritems()):        \n    ax.text(i-.5 ,v[1], \"{:,}\".format(v[1]), rotation=\"45\")\nplt.xlabel('landmark_id')\nplt.ylabel('count of images')\nplt.title(\"Count of images per landmark_id\")\nplt.show()","5ef2193d":"plt.figure(figsize=(15,7))\nsample = landmarkValueCount[-50:].reset_index()\nax = sns.barplot(\"index\", \"landmark_id\", data=sample, order=sample[\"index\"], palette=\"Blues_d\")\nfor item in ax.get_xticklabels(): item.set_rotation(90)\nfor i, v in enumerate(sample[\"landmark_id\"].iteritems()):        \n    ax.text(i-.5 ,v[1], \"{:,}\".format(v[1]), rotation=\"45\")\nplt.xlabel('landmark_id')\nplt.ylabel('count of images')\nplt.title(\"Count of images per landmark_id\")\nplt.show()","9e2f49ee":"plt.figure(figsize=(15,7))\nsample = landmarkValueCount[0:len(landmarkValueCount):int(len(landmarkValueCount)\/50)].reset_index()\nax = sns.barplot(\"index\", \"landmark_id\", data=sample, order=sample[\"index\"], palette=\"Blues_d\")\nfor item in ax.get_xticklabels(): item.set_rotation(90)\nfor i, v in enumerate(sample[\"landmark_id\"].iteritems()):        \n    ax.text(i-.5 ,v[1], \"{:,}\".format(v[1]))\nplt.xlabel('landmark_id')\nplt.ylabel('count of images')\nplt.title(\"Count of images per landmark_id\")\nplt.show()","2208599a":"plt.figure(figsize=(15,7))\nsample = landmarkValueCount[0:len(landmarkValueCount):int(len(landmarkValueCount)\/50)].reset_index()\nsample = sample[1:]\nax = sns.barplot(\"index\", \"landmark_id\", data=sample, order=sample[\"index\"], palette=\"Blues_d\")\nfor item in ax.get_xticklabels(): item.set_rotation(90)\nfor i, v in enumerate(sample[\"landmark_id\"].iteritems()):        \n    ax.text(i ,v[1], \"{:,}\".format(v[1]), va ='bottom')\nplt.xlabel('landmark_id')\nplt.ylabel('count of images')\nplt.title(\"Count of images per landmark_id after removing most occured landmark_id\")\nplt.show()","510cd986":"hue = np.zeros_like(landmarkValueCount)\n\nhue[landmarkValueCount<3000] = 1\nhue[landmarkValueCount<1000] = 2\nhue[landmarkValueCount<300] = 3\nhue[landmarkValueCount<3] = 4\ncl = [\"images>3000\", \"1000<images<3000\", \"300<images<1000\", \"3<images<300\", \"0<images<3\"]\n\n\nfig, ax = plt.subplots(1,2,figsize=(20,7))\nsns.scatterplot(landmarkValueCount.index, landmarkValueCount.values, alpha=.5, hue = hue, s=100, ax=ax[0], palette=\"bright\")\nax[0].set_xlabel('Landmark_id count')\nax[0].set_ylabel('Count of images')\nax[0].set_title(\"Count of images per landmark_id\")\nax[0].legend(cl)\n\nsns.scatterplot(landmarkValueCount.index, np.log10(landmarkValueCount.values), alpha=.5, hue = hue, s=100, ax=ax[1], palette=\"bright\")\nax[0].set_xlabel('Log of Landmark_id count')\nax[1].set_ylabel('Count of images')\nax[1].set_title(\"Count of log of images per landmark_id\")\nplt.show()\n","2f4a7463":"hueSort = pd.value_counts(hue).sort_index()\nhuedf = pd.Series(hueSort.values, index=cl).reset_index()\npercent = huedf.iloc[:,1]\/len(hue)*100\nhuedfPerc = pd.concat([huedf, percent], axis=1)\nhuedfPerc.columns = [\"Desc\", \"Count of images\", \"Percent of count of images\"]\nhuedfPerc[\"Desc\"] = \"Landmark Id having \"+ huedfPerc[\"Desc\"]\nhuedfPerc","1e16fb4d":"from PIL import Image\nimagePath = glob.glob(\"\/kaggle\/input\/landmark-recognition-2020\/train\/0\/0\/*\/*\")[:40]\n\nfig, ax = plt.subplots(10, 4, figsize=(15, 40))\nax = np.ravel(ax)\nfor i in range(40):\n    ax[i].imshow(Image.open(imagePath[i]))\n","cda37d29":"submittionSample = pd.read_csv(\"\/kaggle\/input\/landmark-recognition-2020\/sample_submission.csv\")\nsubmittionSample.head(3)","40585927":"submittionSample.info()","86e8987f":"### First 50 samples Bar plot: Count of images per landmark_id","245cfe8c":"### Evaluation\nSubmissions are evaluated using Global Average Precision (GAP) at k, where k=1. This metric is also known as micro Average Precision (\u03bcAP), as per [1,2]. It works as follows:\n\nFor each test image, you will predict one landmark label and a corresponding confidence score. The evaluation treats each prediction as an individual data point in a long list of predictions (sorted in descending order by confidence scores), and computes the Average Precision based on this list.\n\nIf a submission has N predictions (label\/confidence pairs) sorted in descending order by their confidence scores, then the Global Average Precision is computed as:\n\nGAP = 1\/M * \u2211(P(i)rel(i)): i -> 0 to N\n\nwhere:\n\nN is the total number of predictions returned by the system, across all queries\n\nM is the total number of queries with at least one landmark from the training set visible in it (note that some queries may not depict landmarks)\n\nP(i) is the precision at rank i\nrel(i) denotes the relevance of prediciton i: it\u2019s 1 if the i-th prediction is correct, and 0 otherwise","3a753a8a":"### Last 50 samples Bar plot: Count of images per landmark_id","8b1c8d56":"### Information extraction","24205750":"### Overall 50 samples Bar plot: Count of images per landmark_id","31155135":"### Scatter plot: Count of images per landmark_id an log of images per landmark_id","0a27a775":"## About train.csv","870f3e4a":"### Distribution plot: Landmark Id Count and log of Landmark Id Count","fd727f83":"For each id in the test set, you can predict at most one landmark and its corresponding confidence score. **Some images contain no landmarks.** You may decide not to predict any result for a given query, by submitting an empty prediction. The submission file should contain a header and have the following format (larger scores denote more confident matches):\n\nid,landmarks\n\n000088da12d664db,______8815 0.03\n\n0001623c6d808702,\n\n0001bbb682d45002,______5328 0.5\n\netc.","54f3a740":"### Sample Images","6a524e3e":"### For better understanding","bc097d5a":"## Ploting train.csv","752d7e49":"### Distribution plot: Landmark Id","b252a5a1":"#### As we can see in above plot, 6272 images have landmark_id=138982. which is squeezeing our plot.\n#### Let's remove first landmark_id and look again","e5f0e3cd":"### Submission File","ed881bad":"## Data Description\n\nDataset consist of:\n\n* **train.csv**: CSV file having information about 'image id' and 'landmark id'\n\n* **sample_submission.csv**: CSV file having information about submition format\n\n* **train**: FOLDER having images for training  *Since there are a large number of images, each image is placed within three subfolders according to the first three characters of the image id (i.e. image abcdef.jpg is placed in a\/b\/c\/abcdef.jpg).*\n\n* **test**: FOLDER having images for testing\n\nIn this competition, you are asked to take test images and recognize which landmarks (if any) are depicted in them.\n"}}