{"cell_type":{"76b34423":"code","798d26fd":"code","d304b7e1":"code","2473c664":"code","5bd1880d":"code","6d51696e":"code","c5608278":"code","dc66b139":"code","9ad55bc3":"code","5d993970":"code","f85784e5":"code","22df4d02":"code","78483ee3":"code","ed00244b":"code","e8503313":"code","e483864a":"code","4fec6e88":"code","4af72f39":"code","607df92f":"code","c3096ca2":"code","91bcd99a":"code","505e3ad6":"code","345a0964":"code","5a1378f9":"code","51b4a4aa":"code","518c249a":"code","822cd409":"code","c01942ec":"code","ce55c68c":"code","fc759082":"code","0b9d55eb":"code","910516be":"code","5f4d0444":"code","ba22d454":"code","e2dc9488":"code","db59c334":"markdown","b6195d1a":"markdown","e5a4b716":"markdown","8940f697":"markdown","2de230f3":"markdown","dc6989ed":"markdown","e8751e6d":"markdown","7748adc3":"markdown","83e7ccec":"markdown","3617c6a4":"markdown","6992c64c":"markdown","325d7006":"markdown","794a3a2e":"markdown","bb800d70":"markdown","bf43ee15":"markdown","30703ffa":"markdown","5f511db7":"markdown","add9eac9":"markdown","ea4df0d2":"markdown","76924b97":"markdown","9855adba":"markdown","4a8aa4c2":"markdown","4165537b":"markdown","c9c43147":"markdown","a5ca029f":"markdown","93f4e98b":"markdown","8f73c155":"markdown","6ad248b8":"markdown","98afd049":"markdown","55e22b92":"markdown","bad8bf36":"markdown","0b8ec8ab":"markdown","c3ad2528":"markdown","2d9ce42c":"markdown","3b9fd61a":"markdown"},"source":{"76b34423":"%matplotlib inline\n\n# Essentials: Data Cleansing and ETL\nimport pandas as pd\nimport numpy as np\n\n# Plotting\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom matplotlib.legend_handler import HandlerLine2D\n\n# Algorithms\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.metrics import roc_curve, auc # good for evaluation of binary classification problems\nfrom sklearn.model_selection import train_test_split","798d26fd":"df = pd.read_csv('..\/input\/NFL Play by Play 2009-2017 (v4).csv')\ndf.head(10)","d304b7e1":"df.info()","2473c664":"print(\"Rows: \",len(df))","5bd1880d":"# take the dataframe for field goals above and shorten the scope of the columns to just FG information\nplays = ['Date','GameID','qtr','time','yrdline100','PlayType','FieldGoalResult','FieldGoalDistance','posteam','DefensiveTeam','PosTeamScore','DefTeamScore','Season']\nplays = df[plays]\n\n# Filter out any random results of NA for the Play Type\nplays = plays[plays.PlayType != 'NA']","6d51696e":"# take the dataframe for field goals above and shorten the scope of the columns to just FG information\nplay_attr = ['GameID','qtr','TimeSecs','yrdline100','ydstogo','Drive','down','PlayType','PassAttempt','RushAttempt','Yards.Gained','posteam','DefensiveTeam','PosTeamScore','DefTeamScore','Season']\nplays = df[play_attr]\n\nplays = plays[plays.PlayType.notna() & (plays.PlayType != 'No Play') & (plays.PlayType != 'Kickoff') & (plays.PlayType != 'Extra Point')]\nplays=plays.rename(columns = {'posteam':'Team'})\nplays.head(5)","c5608278":"# group by qtr: count\nregulation_plays = plays[plays.qtr != 5]\nax = regulation_plays.groupby(['qtr'])['PassAttempt','RushAttempt'].sum().plot.bar(figsize=(20,9),color=['saddlebrown','orange'],rot=0,fontsize=16)\nax.set_title(\"Amount of Plays each Quarter - by Rush or Pass\", fontsize=24)\nax.set_xlabel(\"Quarter\", fontsize=18)\nax.set_ylabel(\"# of Plays\", fontsize=14)\nax.set_alpha(0.8)\n\n# set individual bar lables using above list\nfor i in ax.patches:\n    # get_x: width; get_height: verticle\n    ax.text(i.get_x()+.04, i.get_height()-1500, str(round((i.get_height()), 2)), fontsize=16, color='black',rotation=0)\n","dc66b139":"# group by qtr: count\nplays_down = plays[plays.down <= 3]\nax = plays_down.groupby(['down'])['PassAttempt','RushAttempt'].sum().plot.bar(figsize=(20,9),color=['saddlebrown','orange'],rot=0,fontsize=16)\nax.set_title(\"Play Calling by Down - by Rush or Pass\", fontsize=24)\nax.set_xlabel(\"Down\", fontsize=18)\nax.set_ylabel(\"# of Plays\", fontsize=14)\nax.set_alpha(0.8)\n\n# set individual bar lables using above list\nfor i in ax.patches:\n    # get_x: width; get_height: verticle\n    ax.text(i.get_x()+.06, i.get_height()-2400, str(round((i.get_height()), 2)), fontsize=16, color='black',rotation=0)","9ad55bc3":"plays_down = plays[(plays.down <= 3) & (plays.qtr < 5) & (plays.Team == 'CLE')]\nax = plays_down.groupby(['Season','GameID'])['PassAttempt','RushAttempt'].sum().plot.line(color=['saddlebrown','orange'],figsize=(20,9),rot=0,fontsize=16)\nax.set_title(\"Season Play Calling - Cleveland Browns\", fontsize=24)\nax.set_ylabel(\"# Plays\", fontsize=14)\nax.set_alpha(0.8)","5d993970":"# Get average results for offensive plays by game for model\n# to preserve the dataframe's shape (with GameID being unique), I'm going to use a split-apply-merge strategy\n\n# Split - from origional DF: Get 2 DF's for plays that are labeled Run or Pass\nr_off_agg = df[(df.PlayType == 'Run')]\np_off_agg = df[(df.PlayType == 'Pass')|(df.PlayType == 'Sack')]\n\n# Apply - groupby aggregation to find the Median yards by game, team, PlayType, and qtr\nr_off_agg = r_off_agg.groupby(['GameID','qtr','posteam'])['Yards.Gained'].mean().reset_index()\np_off_agg = p_off_agg.groupby(['GameID','qtr','posteam'])['Yards.Gained'].mean().reset_index()\n\nr_off_agg = r_off_agg.rename(columns={'Yards.Gained':'RushingMean'}) # Rename the columns for clarity\np_off_agg = p_off_agg.rename(columns={'Yards.Gained':'PassingMean'})\n\n# Merge - Combine the Away and Home averages into one dataframe\noff_agg = pd.merge(r_off_agg,\n                 p_off_agg,\n                 left_on=['GameID','qtr','posteam'],\n                 right_on=['GameID','qtr','posteam'],\n                 how='outer')\n\noff_agg.head(8)","f85784e5":"off_tendencies = df[df.PlayType.notna()&\n              (df.PlayType != 'No Play')&\n              (df.PlayType != 'Kickoff')&\n              (df.PlayType != 'Extra Point')&\n              (df.PlayType != 'End of Game')&\n              (df.PlayType != 'Quarter End')&\n              (df.PlayType != 'Half End')&\n              (df.PlayType != 'Two Minute Warning')&\n              (df.PlayType != 'Field Goal')&\n              (df.PlayType != 'Punt') &\n              (df.PlayAttempted == 1)]\n\n# Moving average by team, quarter, and season. This is a rolling average to consider recent decisions to compensate for coaching changes\noff_tendencies = off_tendencies.groupby(['GameID','posteam','Season','qtr'])['PassAttempt','RushAttempt'].sum().reset_index()\noff_tendencies['PassingWA']=off_tendencies.groupby(['posteam','qtr','Season']).PassAttempt.apply(lambda x: x.shift().rolling(8,min_periods=1).mean().fillna(x))\noff_tendencies['RushingWA']=off_tendencies.groupby(['posteam','qtr','Season']).RushAttempt.apply(lambda x: x.shift().rolling(8,min_periods=1).mean().fillna(x))\noff_tendencies = off_tendencies.drop(columns=['PassAttempt', 'RushAttempt'])\noff_tendencies[(off_tendencies.posteam == 'CLE')&(off_tendencies.qtr == 1)].head(20)","22df4d02":"# to limit the data size, lets look at one team to begin\nteam = 'CLE'","78483ee3":"# take the dataframe for plays above and define particular columns we want\nplay_attr = ['PlayAttempted','GameID','qtr','TimeSecs','yrdline100','ydstogo','Drive','down','PlayType','GoalToGo',\n             'TimeUnder','PlayTimeDiff','PassAttempt','RushAttempt','posteam','DefensiveTeam','PosTeamScore',\n             'DefTeamScore','Season','HomeTimeouts_Remaining_Pre','AwayTimeouts_Remaining_Pre','No_Score_Prob',\n             'Opp_Field_Goal_Prob','Opp_Safety_Prob','Win_Prob','HomeTeam','ExpPts']\nplays = df[play_attr]\n\n\n# filter out the records that we wont use to predict run or pass\nplays = plays[plays.PlayType.notna()&\n              (plays.PlayType != 'No Play')&\n              (plays.PlayType != 'Kickoff')&\n              (plays.PlayType != 'Extra Point')&\n              (plays.PlayType != 'End of Game')&\n              (plays.PlayType != 'Quarter End')&\n              (plays.PlayType != 'Half End')&\n              (plays.PlayType != 'Two Minute Warning')&\n              (plays.PlayType != 'Field Goal')&\n              (plays.PlayType != 'Punt')]\n\n# assure that there was a play attempted to filter out penalties before the play occured.\nplays = plays[plays.PlayAttempted == 1]\n\n# add data regarding offensive stats\nplays = pd.merge(plays,\n                off_agg,\n                left_on=['GameID','qtr','posteam'],\n                right_on=['GameID','qtr','posteam'],\n                how='left')\n\n# merge data for moving average play calling tendencies\nplays = pd.merge(plays,\n                off_tendencies,\n                left_on=['GameID','qtr','posteam','Season'],\n                right_on=['GameID','qtr','posteam','Season'],\n                how='left')\n\nplays=plays.rename(columns = {'posteam':'Team'})\n\n# filter on just possessions by the cleveland browns (woof woof)\nplays = plays[(plays['Team'] == team)]\nplays.head(5)","ed00244b":"# get score difference for each play cleveland is in possession of the ball\nplays['ScoreDiff'] = plays['PosTeamScore'] - plays['DefTeamScore']\n\n# add column to show boolean indicator for whether the Browns are winning or losing (I expect a lot of 0's)\nplays['CurrentScoreBool'] = plays.apply(lambda x: 1 if x.ScoreDiff > 0 else 0, axis=1)\n\n# add column to show if the Brownies are playing at home\nplays['Home'] = plays.apply(lambda x: 1 if x.HomeTeam == team else 0, axis=1)\n\n# changing the timeouts attributes to reflect the posteam: CLE and the defensive teams remaining timeouts\nplays['PosTO_PreSnap'] = plays.apply(lambda x: x.HomeTimeouts_Remaining_Pre if x.HomeTimeouts_Remaining_Pre == team else x.AwayTimeouts_Remaining_Pre, axis=1)\nplays['DefTO_PreSnap'] = plays.apply(lambda x: x.HomeTimeouts_Remaining_Pre if x.HomeTimeouts_Remaining_Pre != team else x.AwayTimeouts_Remaining_Pre, axis=1)\n\n# indicator for 2-minute situations\nplays['TwoMinuteDrill'] = plays.apply(lambda x: 1 if (\n    (((x.TimeSecs <= 0)&(x.TimeSecs >= 120))|((x.TimeSecs <= 1920)&(x.TimeSecs >= 1800)))&\n    (x.CurrentScoreBool == 0)) else 0, axis=1)\n                                      ","e8503313":"plays.info()","e483864a":"# need to clean float data and transfer to integer\nplays.TimeSecs = plays.TimeSecs.fillna(0).astype(int)\nplays.yrdline100 = plays.yrdline100.fillna(0).astype(int)\nplays.down = plays.down.fillna(0).astype(int)\nplays.PosTeamScore = plays.PosTeamScore.fillna(0).astype(int)\nplays.DefTeamScore = plays.DefTeamScore.fillna(0).astype(int)\nplays.RushingMean = plays.RushingMean.fillna(0).astype(int)\nplays.PassingMean = plays.PassingMean.fillna(0).astype(int)\nplays.ScoreDiff = plays.ScoreDiff.fillna(0).astype(int)\nplays.PlayTimeDiff = plays.PlayTimeDiff.fillna(0).astype(int)\nplays.GoalToGo = plays.GoalToGo.fillna(0).astype(int)\n\nplays.RushingWA = plays.RushingWA.fillna(0).round(0).astype(int)\nplays.PassingWA = plays.PassingWA.fillna(0).round(0).astype(int)","4fec6e88":"# play type changed to integer using map - removing others\n# PlayTypes = {\"Run\": 0, \"QB Kneel\": 0, \"Pass\": 1, \"Sack\": 1, \"Spike\": 1}\n# cle.PlayType = cle.PlayType.map(PlayTypes)\n# cle.PlayType = cle.PlayType.fillna(0)\n# cle.PlayType = cle.PlayType.astype(int)\nplays = plays[(plays.PassAttempt == 1)|(plays.RushAttempt == 1)]\nplays['PlayType'] = plays.apply(lambda x: 1 if x.PassAttempt == 1 else 0, axis=1)\nplays.PlayType = plays.PlayType.fillna(0).astype(int)\n\n\n# changing float64 to float32\nplays.No_Score_Prob = plays.No_Score_Prob.fillna(0).astype(np.float32)\nplays.Opp_Field_Goal_Prob = plays.Opp_Field_Goal_Prob.fillna(0).astype(np.float32)\nplays.Opp_Safety_Prob = plays.Opp_Safety_Prob.fillna(0).astype(np.float32)\nplays.Win_Prob = plays.Win_Prob.fillna(0).astype(np.float32)\nplays.ExpPts = plays.ExpPts.fillna(0).astype(np.float32)\n\n\nplays.No_Score_Prob = pd.qcut(plays['No_Score_Prob'], 5, labels=False)\nplays.Opp_Field_Goal_Prob = pd.qcut(plays['Opp_Field_Goal_Prob'], 5, labels=False)\nplays.Opp_Safety_Prob = pd.qcut(plays['Opp_Safety_Prob'], 5, labels=False)\nplays.Win_Prob = pd.qcut(plays['Win_Prob'], 5, labels=False)\nplays.ExpPts = pd.qcut(plays['ExpPts'], 5, labels=False)\n","4af72f39":"# drop unneeded columns to begin to de-clutter the set\nplays = plays[plays.down != 0]\nplays = plays.drop(columns=['PlayAttempted','HomeTeam','Team','DefensiveTeam',\n                        'HomeTimeouts_Remaining_Pre','AwayTimeouts_Remaining_Pre','RushAttempt','PassAttempt'])\n\nplays = plays.rename(columns = {'Drive_x':'Drive'})\nplays.head(5)","607df92f":"# Define our prediction data\nplays_predictors = ['ydstogo','down','ScoreDiff','PosTO_PreSnap','No_Score_Prob','Drive','Season','TimeSecs','TimeUnder','PlayTimeDiff','Opp_Field_Goal_Prob']\nX = plays[plays_predictors]\n\n# Define the prediction target: PlayType\ny = plays.PlayType","c3096ca2":"# Split our data into training and test data for both our target and prediction data sets\n# random state = 0 means we get same result everytime if we want ot change later\ntrain_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)","91bcd99a":"# Decision Tree Classifier\ndesc_tree = DecisionTreeClassifier()\ndesc_tree.fit(train_X, train_y)\n\ndt_predictions = desc_tree.predict(val_X)\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(val_y, dt_predictions)\ndt_roc_auc = auc(false_positive_rate, true_positive_rate)","505e3ad6":"# Random Forest Classification\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(train_X, train_y)\n\nrf_predictions = random_forest.predict(val_X)\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(val_y, rf_predictions)\nrf_roc_auc = auc(false_positive_rate, true_positive_rate)","345a0964":"# Logistic Regression\nlog_reg = LogisticRegression()\nlog_reg.fit(train_X, train_y)\n\nlr_predictions = log_reg.predict(val_X)\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(val_y, lr_predictions)\nlr_roc_auc = auc(false_positive_rate, true_positive_rate)","5a1378f9":"# K-Means Clustering\nknn = KNeighborsClassifier(n_neighbors = 5)\nknn.fit(train_X, train_y)\n\nknn_predictions = knn.predict(val_X)\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(val_y, knn_predictions)\nknn_roc_auc = auc(false_positive_rate, true_positive_rate)","51b4a4aa":"# Gaussian Naive Bayes\ngnb = GaussianNB()\ngnb.fit(train_X, train_y)\n\ngnb_predictions = gnb.predict(val_X)\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(val_y, gnb_predictions)\ngnb_roc_auc = auc(false_positive_rate, true_positive_rate)","518c249a":"gbc = GradientBoostingClassifier()\ngbc.fit(train_X, train_y)\n\ngbc_predictions = gbc.predict(val_X)\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(val_y, gbc_predictions)\ngbc_roc_auc = auc(false_positive_rate, true_positive_rate)","822cd409":"results = pd.DataFrame({\n    'Model': ['Decision Tree', 'Random Forest', 'Logistic Regression', 'KNN',\n              'Naive Bayes', 'Gradient Boosting Classifier'],\n    'AUC': [dt_roc_auc, rf_roc_auc, lr_roc_auc, knn_roc_auc, gnb_roc_auc, gbc_roc_auc]})\nresult_df = results.sort_values(by='AUC', ascending=False)\nresult_df = result_df.set_index('AUC')\nresult_df.head(7)","c01942ec":"importances = pd.DataFrame({'feature':train_X.columns,'importance':np.round(gbc.feature_importances_,3)})\nimportances = importances.sort_values('importance',ascending=False).set_index('feature')\nimportances.plot.bar(figsize=(20,9),rot=0)","ce55c68c":"x_train, x_test, y_train, y_test = train_test_split(X, y,random_state = 0)\n\nmodel = GradientBoostingClassifier()\nmodel.fit(x_train, y_train)\n\ny_pred = model.predict(x_test)\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nroc_auc","fc759082":"# a couple learning rates to see how they affect the outcome of our model\nlearning_rates = [0.2, 0.175 ,0.15, 0.125, 0.1, 0.075, 0.05, 0.025, 0.01]\n\ntrain_results = []\ntest_results = []\ntrain_results = []\ntest_results = []\nfor eta in learning_rates:\n    model = GradientBoostingClassifier(learning_rate=eta)\n    model.fit(x_train, y_train)\n\n    train_pred = model.predict(x_train)\n\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n\n    y_pred = model.predict(x_test)\n\n\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n\nline1, = plt.plot(learning_rates, train_results, 'b', label=\"Train AUC\")\nline2, = plt.plot(learning_rates, test_results, 'r', label=\"Test AUC\")\n\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n\nplt.ylabel('AUC score')\nplt.xlabel('learning rate')\nplt.show()","0b9d55eb":"# n_estimators to adjust to tune outcome\nn_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200]\n\ntrain_results = []\ntest_results = []\nfor estimator in n_estimators:\n    model = GradientBoostingClassifier(n_estimators=estimator)\n    model.fit(x_train, y_train)\n\n    train_pred = model.predict(x_train)\n\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n\n    y_pred = model.predict(x_test)\n\n\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n\nline1, = plt.plot(n_estimators, train_results, 'b', label=\"Train AUC\")\nline2, = plt.plot(n_estimators, test_results, 'r', label=\"Test AUC\")\n\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n\nplt.ylabel('AUC score')\nplt.xlabel('n_estimators')\nplt.show()","910516be":"max_depths = np.linspace(1, 7, 7, endpoint=True)\n\ntrain_results = []\ntest_results = []\nfor max_depth in max_depths:\n    model = GradientBoostingClassifier(max_depth=max_depth)\n    model.fit(x_train, y_train)\n\n    train_pred = model.predict(x_train)\n\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n\n    y_pred = model.predict(x_test)\n\n\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n\nline1, = plt.plot(max_depths, train_results, 'b', label=\"Train AUC\")\nline2, = plt.plot(max_depths, test_results, 'r', label=\"Test AUC\")\n\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n\nplt.ylabel('AUC score')\nplt.xlabel('Tree depth')\nplt.show()","5f4d0444":"min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n\ntrain_results = []\ntest_results = []\nfor min_samples_split in min_samples_splits:\n    model = GradientBoostingClassifier(min_samples_split=min_samples_split)\n    model.fit(x_train, y_train)\n\n    train_pred = model.predict(x_train)\n\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n\n    y_pred = model.predict(x_test)\n\n\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n\nline1, = plt.plot(min_samples_splits, train_results, 'b', label=\"Train AUC\")\nline2, = plt.plot(min_samples_splits, test_results, 'r', label=\"Test AUC\")\n\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n\nplt.ylabel('AUC score')\nplt.xlabel('min samples split')\nplt.show()","ba22d454":"min_samples_leafs = np.linspace(0.1, 0.5, 5, endpoint=True)\ntrain_results = []\ntest_results = []\nfor min_samples_leaf in min_samples_leafs:\n    model = GradientBoostingClassifier(min_samples_leaf=min_samples_leaf)\n    model.fit(x_train, y_train)\n\n    train_pred = model.predict(x_train)\n\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n\n    y_pred = model.predict(x_test)\n\n\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n\nline1, = plt.plot(min_samples_leafs, train_results, 'b', label=\"Train AUC\")\nline2, = plt.plot(min_samples_leafs, test_results, 'r', label=\"Test AUC\")\n\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n\nplt.ylabel('AUC score')\nplt.xlabel('min samples leaf')\nplt.show()","e2dc9488":"max_features = list(range(1,X.shape[1]))\ntrain_results = []\ntest_results = []\nfor max_feature in max_features:\n    model = GradientBoostingClassifier(max_features=max_feature)\n    model.fit(x_train, y_train)\n\n    train_pred = model.predict(x_train)\n\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n\n    y_pred = model.predict(x_test)\n\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n\nline1, = plt.plot(max_features, train_results, 'b', label=\"Train AUC\")\nline2, = plt.plot(max_features, test_results, 'r', label=\"Test AUC\")\n\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n\nplt.ylabel('AUC score')\nplt.xlabel('Maximum Features')\nplt.show()\n","db59c334":"<body>We can see that 0.05 (possibly .045) is our data's best fit. Higher Learning rates will result in overfitting the data.<\/body>","b6195d1a":"<h1>Cleveland Browns<\/h1>","e5a4b716":"<h4>Learning Rate Tuning<\/h4>","8940f697":"<h3>Model Outcomes<\/h3>\n<p>Lets show each models' results measured using the AUC (Area Under Curve) method. I'm using this method becuase it suits binary decision models well, which is what our target value (run or pass) represents.<\/p>","2de230f3":"<h2>Gradient Boosting Classification Tuning<\/h2>","dc6989ed":"<h1>Analysis <\/h1>\n<body>\n    <p>To continue the project I want to look into play calling...<\/p>\n<\/body>","e8751e6d":"<h3>Offensive Tendencies and Trends<\/h3>\n<p>Beyond the average rushing and passing stats by quarter, I believe something else that participates in the determination of the play being a rush or a pass can be described as the tendencies of a coach making the calls. I'm looking to answer the question of what has been done most recently and over time to know the proportions of running plays vs passing plays over a period of time.<\/p>","7748adc3":"<body>\n    <p>As we can see, it seems that passing plays are more prominant in all categories. Recently, the play calling in the NFL has changed to a more pass-friendly offensive approach which has resulted in the value of high quality quarterbacks. The final goal here is to determine when teams are running the ball or passing the ball, so its helpful to get an idea of the aggregation first. One important distinction here is that the 2nd and 4th quarters see a spike in the amount of passing attempts but the rushing attempts remains fairly constant across the quarters. This is most likely due to teams trying to score before the possession changes in the 2nd half or to win at the end of the game due to the time-friendly rule that the clock stops after an incomplete pass and being able to throw the ball towards the sideline to stop the clock.\n<\/p>\n<\/body>","83e7ccec":"<h3>Changing\/Adding Parameters<\/h3>\n<p>Here, I'm creating an attribute for the score differential (because the other varies and I'd rather just do it in one line), the current score boolean indicator to show whether the team is winning or losing, the Home team indicator to be 1 if the possession team is home or away, and changing the timeout parameters to reflect the defensive team and defensive team instead of the home and away teams.<\/p>","3617c6a4":"<p>I'm going to reset the training and testing variables and follow a guide found at: https:\/\/maviator.github.io\/2017\/12\/24\/InDepth-Gradient-Boosting\/ by Mohtadi Be Fraj to further investigate the parameters contained in Sci Kit Learn's Gradient Boosting Classifier. I highly recommend his reading his blog to see in-depth explanations to understand how various modeling techniques!<\/p>","6992c64c":"<h1>\nExploratory Analysis - Predicting the Play Type\n<\/h1>","325d7006":"<h3>Adjusting Feature Data Types<\/h3>\n<body>\n    <p>Now that our dataset has much of the desired information contained in it, we can look at the data types for each attribute and make adjustments as needed:<\/p>\n<\/body>","794a3a2e":"**This notebook's purpose is to explore NFL data from 2009-2017. The goal is to hopefully provide useful analysis for others to use or to provide useful code for others to learn from.**","bb800d70":"<p>To easily adjust the team I'm looking at, I'm using a team variable to easily change if needed.<\/p>\n\n<h3>Joining our New Parameters<\/h3>\n<p>Below, I'm joining the previously calculated parameters to the main data set. I am filtering out plays that have play types that aren't of a run or pass type, so that means eliminating Special Teams plays and other tuples of unneeded data.<\/p>","bf43ee15":"<body>In both above cases, requiring the model to consider all of the features at each node will result in overfitting.<\/body>\n<h4>Maximum Features<\/h4>","30703ffa":"<body>\n    <p>Now that we have a few more hyperparameters to contribute to our data modelling, we can move on and begin to break the data down to see if we can understand whether we can accurately predict the play calling of an NFL offensive coordinator. I'm going to take a look at my beloved Cleveland Browns because well - maybe theres a reason they cant win football games?<\/p>\n<\/body>","5f511db7":"<h1>Data Cleansing<\/h1>\n<p>Taking a look at what we're up against with pandas .info()<\/p>","add9eac9":"<h3>Pass and Rush Attempts League-Wide by Quarter of the Game:<\/h3>","ea4df0d2":"<body>\n    <p>Now the float attributes are modified to int-type. Below, I'm going to need to change our target parameter to show the rushing attempt vs the pass attempts. I could also use the commented out lines, but after trying them both ways it really doesn't make a difference.<\/p>\n    <p>Also, I need to adjust the probability odds that are in the DataFrame. to do this, I'm using Pandas built-in functionality to bin the probabilities into 4 equal categories of integers.<\/p>\n<\/body>","76924b97":"<h1>Building Models and Making Predictions<\/h1>\n<p>First, we need to define our target variable, y as well as define our decision parameters, X.<\/p>","9855adba":"<h4>Estimators<\/h4>","4a8aa4c2":"<body>\n    <p>First, we'll want to gather stats regarding the Mean yards gained for running or passing plays by the team with possession of the ball. This will assure that we can reference the teams' relative performance that game when making a decision. I chose the Mean and not the Median to account for 'big plays' that can affect a coaches optimism of certain play calls. Finding this value is important to factor in because it definitely weighs on a human decision. For instance, imagine telling Bill Belicheck to go for it on 4th and 6 at the 30 yard line when the offense has struggled to move the ball all game. He'd probably break the clipboard over your head!<\/p>\n<\/body>\n<h3>Offensive Averages by Quarter<\/h3>","4165537b":"<p>We can see that **Gradient Boosting Classification** is the best model for predicting run or pass. Lets take this and dive further into the results to take a look at further tuning our gradient boosting classification model.<\/p>\n<h2>Feature Importance<\/h2>\n<p>Lets plot the influence each of our hyperparameters have on our predictions:<\/p>","c9c43147":"<body>\n    <p>To get a better idea of how certain variables impact the offensive coordinators play calling, we need to dive into the data and see if we can find any interesting aspects that could be related to the play calls.<\/p>\n<\/body>","a5ca029f":"<body>Above, we can see that past around 75 estimators, our model's accuracy is overfitting.<\/body>\n<h4>Maximum Depths<\/h4>","93f4e98b":"<h3>\nLooking at the Data\n<\/h3>\n<body>\n    We can see that the data is particularily encompassing. 102 Columns of data is a lot more data than we'll need while building potential models. This is because more attributes can typically cause over-fitting for any method we decide to impliment.\n    <\/body>","8f73c155":"<h1>NFL ANALYSIS - Series 2: Predicting Run or Pass<\/h1>\n<body>\n    <p>This Data origionates from the curtousy of Kaggle user Max Horowitz (@ https:\/\/www.kaggle.com\/maxhorowitz). He has used nflscrapR to obtain the data and also represents https:\/\/www.cmusportsanalytics.com\/. nflscrapeR is an R package engineered to scrape NFL data by researchers Maksim Horowitz, Ron Yurko, and Sam Ventura.<\/p>\n<\/body>\n\n<p>**Series 2 - Predicting Run or Pass:** Knowing whether the next play is going to be a run or a pass is tremendous advantage to a defensive coordinator. In this portion of the series, I'm going to load, explore, clean, and model the data to try and predict the play type for the Cleveland Browns. Following this, I'm going to see if I can make any changes to tune our best model.<\/p>","6ad248b8":"<h1>\nImporting Data\n<\/h1>","98afd049":"<body>Above, we can see that anything beyond a max depth of 2 results in overfitting.<\/body>\n<h4>Minimum Samples Split and Minimum Leaf Sample<\/h4>","55e22b92":"<h1>Prepreparing Data for Building Model<\/h1>\n<body>\n    <p>Any model you build is only as good as the parameters its built on. We need to tune the data to maximize the potential of the model to minizime the amount of loss. To do so, here's a list of parameters I'll be using based on different aspects of a football game that contribute to the decision to call a passing play vs a running play:<\/p>\n    <ul>\n        <li>**Target: PlayType**<\/li>\n        <li>**TimeSecs:** Time left in game in seconds. Coaches often try to control the clock based on the score.<\/li>\n        <li>**Score Differential:** This factors in with the time to signify coaches decisions to rush or pass to take advantage of the clock.<\/li>\n        <li>**qtr:** Quarter the play is in (1-5 where 5 = overtime).<\/li>\n        <li>**Mean Rushing Yards by qtr:** This will help the models distinguish the current rushing success. Coaches will often make decisions based on the relative advantages on the field.<\/li>\n        <li>**Offensive Tendencies:** The moving average of the amount of rushing or passing plays called by quarter.<\/li>\n        <li>**Timeouts Remaining (Pre-snap):** Important to know the timeouts remaining for the teams to know whether to run the ball and force timeouts or to pass to save timeouts.<\/li> \n        <li>**Yardline100:** Yard line the ball is on relative to the goal line. (99-50 is own side of field\/ 49-1 is opponent's side).<\/li>\n        <li>**PlayTimeDiff:** The time between the last snap and the current play.<\/li>\n        <li>**No_Score_Prob:** The probability of there being no score within the half.<\/li>\n        <li>**TimeUnder:** Amount of time left in the half in minutes.<\/li>\n        <li>**Win_Prob:** The probability of winning the game with respect to the possession team.<\/li>\n        <li>**Season:** the season that the game is in.<\/li>\n        <li>**Down and Yards to Go for 1st down:** The down of the play. Coaches usually distinguish decisions by the amount of yards to gain for a first down. I suspect this is a major attribute due to 3rd and long basically gaurenteeing a pass in tight score differentials.<\/li>\n    <\/ul>\n    <p>I'm going to break the information down for the rushing yards gained and the weighted averages for the count of the plays to prepare for joining to the data set. Following this, we can break the 'plays' DataFrame down and further determine clean the data to place in our models.<\/p>\n<\/body>\n","bad8bf36":"<body>\n    <p>Finally, we can drop some columns that we know we will not want to use in our models:<\/p>\n<\/body>","0b8ec8ab":"<p>Using train_test_split, we can easily segment our dataset into training data and testing data. Using these values we can easily build our models and measure the model accuracy.<\/p>","c3ad2528":"<h3>Play Call by Down<\/h3>\n","2d9ce42c":"<h3>Taking a Closer Look<\/h3>","3b9fd61a":"<p>Above, we can see that the # of features maximizes the model's potential at about 12 Features, but the difference isn't that variable in this case as the number of features rises for the model's test predictions.<\/p>"}}