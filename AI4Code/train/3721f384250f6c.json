{"cell_type":{"6f79886b":"code","c00170cd":"code","b19ac09f":"code","b780aed1":"code","d2e40bf5":"code","d2381bf4":"code","8d786f46":"code","aa7bafe9":"code","dcf28acb":"code","eb545e3a":"code","976b1072":"code","7dde11cc":"code","c5617aa9":"code","0cd9a08d":"code","800d2398":"code","2b6202ef":"code","f676b11c":"code","d442b074":"code","4a1634b3":"code","08cf4321":"code","71df52e7":"code","9016fb87":"code","393b1159":"code","60986271":"markdown","d2626855":"markdown","579d4e6f":"markdown","78df7206":"markdown","aa2b6b5e":"markdown","7986fa6c":"markdown","b81b7aff":"markdown","f3ea0b5e":"markdown","3b08c8f9":"markdown","75331c32":"markdown","1a50db07":"markdown","4baa2ff7":"markdown","7f57650f":"markdown","0d949137":"markdown","0f8f5190":"markdown","4f6ba6b5":"markdown","d07e6890":"markdown","9ca1691b":"markdown","4b7eb535":"markdown","d8ecc0c3":"markdown","c0357b03":"markdown"},"source":{"6f79886b":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\nimport csv\nimport cv2\nimport gc\nimport operator\nimport random\nimport warnings\nfrom os.path import split\n\nfrom sklearn.utils import class_weight\nfrom numpy import array\nfrom numpy import argmax\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom random import shuffle\nfrom IPython.display import Image\nfrom pathlib import Path\nimport matplotlib.image as mpimg\nfrom keras import layers\nfrom keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nfrom keras.utils import np_utils\nimport keras.backend as K\nfrom keras.models import Sequential\nfrom keras import optimizers\nfrom collections import Counter\n","c00170cd":"trainDir = \"..\/input\/whale-categorization-playground\/train\/train\"\ntestDir=\"..\/input\/whale-categorization-playground\/test\/test\/\"\nvaluesFile= \"..\/input\/whale-categorization-playground\/train.csv\"","b19ac09f":"\ntrainData = pd.read_csv(valuesFile)","b780aed1":"def rgb2grey(rgb): \n    if len(rgb.shape)==3:\n        return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140]) \n    else:\n        return rgb\n\n\ndef transform_image(img):\n    resized = cv2.resize(img, (64, 64), cv2.INTER_LINEAR)\n    \n    normalized = cv2.normalize(resized, None, 0.0, 1.0, cv2.NORM_MINMAX)\n                         \n    \n    normalized= np.expand_dims(normalized, axis=2)\n\n    \n    return normalized","d2e40bf5":"def imageprep(dataset):\n    \n    if dataset==\"train\":\n        namelist=os.listdir(trainDir) \n        filedir=trainDir\n    elif dataset==\"test\":\n        namelist=os.listdir(testDir)\n        filedir=testDir\n    \n    X_train = np.zeros((len(namelist), 64, 64, 1))\n    \n    \n    for i in range(len(namelist)):\n      \n        img = mpimg.imread(filedir+\"\/\"+namelist[i])\n        \n        gs_img= rgb2grey(img)\n        \n        trans_img= transform_image(gs_img)\n        \n        X_train[i] = trans_img\n    \n            \n    return X_train","d2381bf4":"def labelprep(Y):\n    \n    labels_encoder = LabelEncoder()\n    \n    onehot_encoder = OneHotEncoder(sparse=False)\n    \n    int_encoded = labels_encoder.fit_transform(Y)\n    \n    int_encoded = int_encoded.reshape(len(int_encoded), 1)\n      \n    onehot_encoded = onehot_encoder.fit_transform(int_encoded)\n   \n    return onehot_encoded, labels_encoder","8d786f46":"X = imageprep(\"train\")\n\n\nprint(\"Shape of train data: \", X.shape)","aa7bafe9":"Y = trainData['Id']\n\ny, label_encoder = labelprep(array(Y))","dcf28acb":"outputdim=len(np.unique(Y))","eb545e3a":"model = Sequential()\n\nmodel.add(Conv2D(32, (5, 5), strides = (1, 1), input_shape = (64, 64, 1)))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D((3, 3)))\n\nmodel.add(Conv2D(64, (3, 3), strides = (1,1)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization(axis = 3))\nmodel.add(AveragePooling2D((3, 3)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation=\"relu\"))\nmodel.add(Dropout(0.65))\nmodel.add(Dense(outputdim, activation='softmax'))\n\nmodel.summary()\n\nmodel.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])","976b1072":"class_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(Y),\n                                                 Y)\nclass_weights = {i : class_weights[i] for i in range(len(class_weights))}","7dde11cc":"ini_weights=model.get_weights()\nhistory = model.fit(X, y, epochs=400, batch_size=100, verbose=1)\ngc.collect()\nweights0=model.get_weights()","c5617aa9":"plt.plot(history.history['accuracy'])\nplt.title('Accuracy of CNN, training set, no AUG, no class weights')\nplt.ylabel('Accuracy')\nplt.xlabel('Training epoch')\nplt.show()","0cd9a08d":"model.set_weights(ini_weights)\nhistory_weights = model.fit(X, y, epochs=400, batch_size=100, verbose=1, class_weight= class_weights)\ngc.collect()\nweights1=model.get_weights()","800d2398":"plt.plot(history_weights.history['accuracy'])\nplt.title('Accuracy of CNN, training set, no AUG, with class weights')\nplt.ylabel('Accuracy')\nplt.xlabel('Training epoch')\nplt.show()","2b6202ef":"datagen = image.ImageDataGenerator( \n    #rescale=1.\/255,\n    #rotation_range=15,\n    #width_shift_range=.15,\n    #height_shift_range=.15,\n    horizontal_flip=True)\n\ndatagen.fit(X)\n\n\n\ngc.collect()","f676b11c":"model.set_weights(ini_weights)\nhistory_aug=model.fit_generator(datagen.flow(X, y, batch_size=100), epochs=400, verbose=1)\ngc.collect()\nweights2=model.get_weights()","d442b074":"plt.plot(history_aug.history['accuracy'])\nplt.title('CNN, augmented flips, no class weights')\nplt.ylabel('Accuracy on test set')\nplt.xlabel('Learning epoch')\nplt.show()","4a1634b3":"model.set_weights(ini_weights)\nhistory1=model.fit_generator(datagen.flow(X, y, batch_size=100), epochs=400, verbose=1, class_weight= class_weights)\ngc.collect()\nweights3=model.get_weights()","08cf4321":"\nplt.plot(history1.history['accuracy'])\nplt.title('CNN, augmented flips,  class weights')\nplt.ylabel('Accuracy on test set')\nplt.xlabel('Learning epoch')\nplt.show()","71df52e7":"plt.plot(history1.history['accuracy'],'r-', label=\"AUG, CW\")\nplt.plot(history_aug.history['accuracy'], 'b-', label=\"AUG, NO CW\")\nplt.plot(history_weights.history['accuracy'], label= \"NO AUG, CW\")\nplt.plot(history.history['accuracy'], label=\"NO AUG, NO CW\")\nplt.rcParams[\"figure.figsize\"] = (20,20)\nplt.legend()\nplt.title('CNN traning set accuracy')\nplt.ylabel('Accuracy on test set')\nplt.xlabel('Learning epoch')\nplt.show()","9016fb87":"X_test = imageprep(\"test\")\n\n\nprint(\"Shape of train data: \", X_test.shape)","393b1159":"\nfilelist=os.listdir(testDir) \nmodel.set_weights(weights2)\nwith open(\"sample_submission.csv\",\"w\") as f:\n    with warnings.catch_warnings():\n        f.write(\"Image,Id\\n\")\n        warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n      \n        for i in range(len(filelist)):\n            filename=filelist[i]\n            y = model.predict_proba(X_test[i].reshape(1,64,64,1))\n\n            predicted_args = np.argsort(y)[0][::-1][:5]\n\n            inverted = label_encoder.inverse_transform(predicted_args)\n\n            image = split(filename)[-1]\n\n            predicted_args = \" \".join( inverted)\n\n         \n\n            f.write(\"%s,%s\\n\" %(image, predicted_args))","60986271":"Image transformation function: greyscale and resize to (64,64). ","d2626855":"We see that this simple CNN is capable to fit training data with accuracy of 91%","579d4e6f":"# Submission of results","78df7206":"Before applying the classification model we will transform the images into greyscale and resize them. One hot encoding will be applied to transform the labels. ","aa2b6b5e":"Let's try to learn with class weights: ","7986fa6c":"Now we prepare the data to be used for training.","b81b7aff":"# Classification model and results","f3ea0b5e":"The paths to files: ","3b08c8f9":"We can observe here that usage of both augmentation and class weighting resulted in significant loss of accuracy (83%). We suggest to use the model with augmentation without class weighting for prediction of test set. We could also try other augmentation transformations, but there is not enough time for this. ","75331c32":"Computing class weights with corresponding sklearn function: ","1a50db07":"Let's try to use the simplest augmentation procedure:","4baa2ff7":"**Whales identification model**\n\nIdea of solution: \n\n1) Due to extreme imbalance of label distribution we have thousands of classes with just one sample. We have to use augmentation to create more samples for underrepresented classes.\n\n2) We can't split randomly the training set to use some samples for validation, because many classes have only one sample. Even if augmentation is used, there is a risk that certain classes will not be represented by training set after splitting. \n\n3) Due to different color scheme in dataset and limited computational resourses we transform all images into grey scale. \n\n4) Another thing we can try is class weighting, which will increase significance of underrepresented classes. \n\nTherefore we test the CNN with different settings and estimate the results of classification of training set. The preference will be given to the network that uses augmentation and class weighting, if its performance is not significantly worser than the performance of network trained without these settings.  ","7f57650f":"# Preprocessing of data","0d949137":"We see that introduction of class weights didn't result in decrease of performance, the network still has 83% accuracy. ","0f8f5190":"Let's start with simple convolutional neural network with two convolutional layers and two fully connected ones.","4f6ba6b5":"Convertion of labels to one-hot variables for learning","d07e6890":"Create submission file and write the results into it:","9ca1691b":"Preparing test images: ","4b7eb535":"We can see that introduction of augmentation (horizontal flips) slightly affected precision on training set, 90% accuracy was achieved. ","d8ecc0c3":"Let compare the learning process for several settings:\n\n1) No Augmentation, no class weights\n2) No Augmentation, class weights \n3) Augmentation, no class weights\n4) Augmentation, class weights","c0357b03":"Next we try both augmentation and class weighting: "}}