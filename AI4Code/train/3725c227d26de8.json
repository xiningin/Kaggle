{"cell_type":{"aedf9844":"code","c0c86991":"code","4c5725aa":"code","513fd3da":"code","5fc0aa38":"code","9498f5b8":"code","a9626c98":"code","6cd3d7d4":"code","424bd2c8":"code","d966558e":"code","1df0e107":"code","0e80e223":"code","c85a9a32":"code","3b5b3d53":"markdown","3a9d2498":"markdown"},"source":{"aedf9844":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c0c86991":"import numpy as np\nfrom sklearn import datasets\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import LinearSVC\n%matplotlib inline\n#import matplotlib\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import make_moons\nX, y = make_moons(n_samples=100, noise=0.15, random_state=42)\n\ndef plot_dataset(X, y, axes):\n    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bs\")\n    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\")\n    plt.axis(axes)\n    plt.grid(True, which='both')\n    plt.xlabel(r\"$x_1$\", fontsize=20)\n    plt.ylabel(r\"$x_2$\", fontsize=20, rotation=0)\n\nplot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\nplt.show()","4c5725aa":"from sklearn.datasets import make_moons\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\n\npolynomial_svm_clf = Pipeline([\n        (\"poly_features\", PolynomialFeatures(degree=3)),\n        (\"scaler\", StandardScaler()),\n        (\"svm_clf\", LinearSVC(C=10, loss=\"hinge\", random_state=42))\n    ])\n\npolynomial_svm_clf.fit(X, y)","513fd3da":"def plot_predictions(clf, axes):   # Helper Function\n    x0s = np.linspace(axes[0], axes[1], 100)\n    x1s = np.linspace(axes[2], axes[3], 100)\n    x0, x1 = np.meshgrid(x0s, x1s)\n    X = np.c_[x0.ravel(), x1.ravel()]\n    y_pred = clf.predict(X).reshape(x0.shape)\n    y_decision = clf.decision_function(X).reshape(x0.shape)\n    plt.contourf(x0, x1, y_pred, cmap=plt.cm.brg, alpha=0.2)\n    plt.contourf(x0, x1, y_decision, cmap=plt.cm.brg, alpha=0.1)\n\nplot_predictions(polynomial_svm_clf, [-1.5, 2.5, -1, 1.5])\nplot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\n\nplt.show()","5fc0aa38":"from sklearn.svm import SVC\n\npoly_kernel_svm_clf = Pipeline([\n        (\"scaler\", StandardScaler()),\n        (\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=1, C=5))\n    ])\npoly_kernel_svm_clf.fit(X, y)","9498f5b8":"poly100_kernel_svm_clf = Pipeline([\n        (\"scaler\", StandardScaler()),\n        (\"svm_clf\", SVC(kernel=\"poly\", degree=10, coef0=100, C=5))\n    ])\npoly100_kernel_svm_clf.fit(X, y)","a9626c98":"plt.figure(figsize=(11, 4))\n\nplt.subplot(121)\nplot_predictions(poly_kernel_svm_clf, [-1.5, 2.5, -1, 1.5])\nplot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\nplt.title(r\"$d=3, r=1, C=5$\", fontsize=18)\n\nplt.subplot(122)\nplot_predictions(poly100_kernel_svm_clf, [-1.5, 2.5, -1, 1.5])\nplot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\nplt.title(r\"$d=10, r=100, C=5$\", fontsize=18)\n\nplt.show()","6cd3d7d4":"from sklearn.svm import SVC\n\npoly_kernel_svm_clf = Pipeline([\n        (\"scaler\", StandardScaler()),\n        (\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=1, C=5))\n    ])\npoly_kernel_svm_clf.fit(X, y)","424bd2c8":"poly100_kernel_svm_clf = Pipeline([\n        (\"scaler\", StandardScaler()),\n        (\"svm_clf\", SVC(kernel=\"poly\", degree=10, coef0=100, C=5))\n    ])\npoly100_kernel_svm_clf.fit(X, y)","d966558e":"plt.figure(figsize=(11, 4))\n\nplt.subplot(121)\nplot_predictions(poly_kernel_svm_clf, [-1.5, 2.5, -1, 1.5])\nplot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\nplt.title(r\"$d=3, r=1, C=5$\", fontsize=18)\n\nplt.subplot(122)\nplot_predictions(poly100_kernel_svm_clf, [-1.5, 2.5, -1, 1.5])\nplot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\nplt.title(r\"$d=10, r=100, C=5$\", fontsize=18)\n\nplt.show()","1df0e107":"def gaussian_rbf(x, landmark, gamma):\n    return np.exp(-gamma * np.linalg.norm(x - landmark, axis=1)**2)","0e80e223":"rbf_kernel_svm_clf = Pipeline([\n        (\"scaler\", StandardScaler()),\n        (\"svm_clf\", SVC(kernel=\"rbf\", gamma=5, C=0.001))\n    ])\nrbf_kernel_svm_clf.fit(X, y)","c85a9a32":"from sklearn.svm import SVC\n\ngamma1, gamma2 = 0.1, 5\nC1, C2 = 0.001, 1000\nhyperparams = (gamma1, C1), (gamma1, C2), (gamma2, C1), (gamma2, C2)\n\nsvm_clfs = []\nfor gamma, C in hyperparams:\n    rbf_kernel_svm_clf = Pipeline([\n            (\"scaler\", StandardScaler()),\n            (\"svm_clf\", SVC(kernel=\"rbf\", gamma=gamma, C=C))\n        ])\n    rbf_kernel_svm_clf.fit(X, y)\n    svm_clfs.append(rbf_kernel_svm_clf)\n\nplt.figure(figsize=(11, 7))\n\nfor i, svm_clf in enumerate(svm_clfs):\n    plt.subplot(221 + i)\n    plot_predictions(svm_clf, [-1.5, 2.5, -1, 1.5])\n    plot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\n    gamma, C = hyperparams[i]\n    plt.title(r\"$\\gamma = {}, C = {}$\".format(gamma, C), fontsize=16)\n\nplt.show()","3b5b3d53":"**Using Similarity Functions - RF Gaussian Filter****","3a9d2498":"![](http:\/\/)**Use SVC - Uses the kernel trick ( speed execution)**"}}