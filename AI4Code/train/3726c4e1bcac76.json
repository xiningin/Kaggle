{"cell_type":{"dd53d38d":"code","582f15ac":"code","3d1c5b84":"code","561610fc":"code","0a3ab584":"code","6d13dfcf":"code","10835cc2":"code","035d4ef7":"code","dc9e94a8":"code","82c3c4f0":"code","991f8620":"code","0b2c3c07":"code","afaac1bd":"code","47b1e342":"markdown","74427f06":"markdown","8aea65bb":"markdown","41abdd17":"markdown","306e1017":"markdown","64754080":"markdown","409b069b":"markdown","20d4a571":"markdown","093adb55":"markdown","8f8da381":"markdown","2810275d":"markdown","9f449eb4":"markdown","48d9fa3a":"markdown","09fa82b8":"markdown"},"source":{"dd53d38d":"import numpy as np\nfrom skimage.io import imread\nfrom skimage import measure\nfrom skimage import color\nfrom skimage import data, img_as_float\nimport matplotlib.pyplot as plt\nfrom skimage import morphology\nfrom skimage import util\nfrom skimage import filters\nfrom scipy import ndimage\nfrom skimage import feature\nfrom skimage import transform\nfrom skimage import draw\nimport pandas as pd\nfrom PIL import Image\n\nPATH = '\/kaggle\/input\/image-processing\/' # Data PAth","582f15ac":"img = imread(PATH+'shapes.jpg')\ngray_img = color.rgb2gray(img)\n\ncontours = measure.find_contours(gray_img,level=0.7)\n\nf,ax = plt.subplots(1,2,figsize=(15,5),sharex=True,sharey=True)\nax = ax.ravel()\n\nax[0].imshow(img)\nax[0].set_title('Original')\n\nax[1].imshow(gray_img,cmap='gray')\nfor n,contour in enumerate(contours):\n    ax[1].plot(contour[:,1],contour[:,0],lw=5)\nax[1].set_title('Detected Contours')\n       \nplt.show()","3d1c5b84":"img = imread(PATH+'contour.jpeg')\ngray_img = color.rgb2gray(img)\n\ncontours = measure.find_contours(gray_img,level=0.66)\n\nf,ax = plt.subplots(1,2,figsize=(15,5))\nax[1].imshow(gray_img,cmap='gray')\n\nax[0].imshow(img)\nfor n,contour in enumerate(contours):\n    ax[1].plot(contour[:,1],contour[:,0],lw=5)","561610fc":"buildings = imread(PATH+'buildings.jpeg')\ngray_buildings = color.rgb2gray(buildings) # convert to gray scale\n\n# use gauss or bilateral filters and sharpening here but as our image is in good quailt, we don't need\n\nsobel_edges = filters.sobel(gray_buildings)\nroberts_edges = filters.roberts(gray_buildings)\n\nf,ax = plt.subplots(1,3,figsize=(15,6))\n\nax[0].imshow(buildings)\nax[0].set_title('Original')\n\nax[1].imshow(sobel_edges,cmap='gray')\nax[1].set_title('Sobel')\n\nax[2].imshow(roberts_edges,cmap='gray')\nax[2].set_title('Roberts')\n\nplt.show()","0a3ab584":"noisy_img = np.array(Image.open(PATH+'noisy image.png'))\nnoisy_gray = color.rgb2gray(noisy_img)\nfiltered_img = ndimage.gaussian_filter(noisy_img,sigma=(3,3)) # sigma can be in terms of a single float \ndetected = feature.canny(filtered_img,sigma=0.7)\n\nf,ax = plt.subplots(1,3,figsize=(15,5))\n\nax[0].imshow(noisy_gray,cmap='gray')\nax[0].set_title('Original Grayscale')\n\nax[1].imshow(filtered_img,cmap='gray')\nax[1].set_title('Gaussian Filtered')\n\nax[2].imshow(detected,cmap='gray')\nax[2].set_title('Detected Edges')\nplt.show()","6d13dfcf":"board = data.checkerboard()\ntransform_obj = transform.AffineTransform(scale=(0.91,0.87),rotation=(0.23),shear=0.33,\n                                          translation=(101,-53))\n# translation will shift the image pixels to (x+x_trans,y+y_trans) position or it can shift the image from\n# - top to bottom or right left if given coordinates\n# scaling is increasing or decreasing the size of image by a factor\n# shear works like changing a square to a rhomboid\n\ntransformed_img = transform.warp(board,transform_obj)\ncorner_img = feature.corner.corner_harris(transformed_img)\n\nf,ax = plt.subplots(1,3,figsize=(15,5))\n\nax[0].imshow(board,cmap='gray')\nax[0].set_title('Original')\n\nax[1].imshow(transformed_img,cmap='gray')\nax[1].set_title('Transformed')\n\nax[2].imshow(corner_img,cmap='gray')\nax[2].set_title('Detected Corners')\nplt.show()","10835cc2":"x_y_corner_coords = feature.corner.corner_peaks(corner_img)\nx_y_corner_sub = feature.corner.corner_subpix(transformed_img,x_y_corner_coords) # change window size param\n# find the subpixels\ndf = pd.DataFrame() # to compare the difference in the corner positions\ndf['X Before'] = x_y_corner_coords[:,0]\ndf['X After'] = x_y_corner_sub[:,0]\ndf['Y Before'] = x_y_corner_coords[:,1]\ndf['Y After'] = x_y_corner_sub[:,1]\ndf.head()","035d4ef7":"f,ax = plt.subplots(1,3,figsize=(15,5))\nf.suptitle('There are Multiple findings at same point in Default pixels')\n\nax[0].imshow(transformed_img,cmap='gray')\nax[0].set_title('Both Findings')\nax[0].plot(x_y_corner_coords[:,1],x_y_corner_coords[:,0],color='green',markersize=17,ls='none',marker='*',\n           label='Default Peaks')\n\nax[0].plot(x_y_corner_sub[:,1],x_y_corner_sub[:,0],color='red',markersize=7,ls='none',marker='o',\n           label='Sub Pixels')\n\nax[0].legend()\n\n\nax[1].imshow(transformed_img,cmap='gray')\nax[1].set_title('default Pixels')\nax[1].plot(x_y_corner_coords[:,1],x_y_corner_coords[:,0],color='green',markersize=15,ls='none',marker='*')\n\nax[2].imshow(transformed_img,cmap='gray')\nax[2].set_title('Sub Pixels')\nax[2].plot(x_y_corner_sub[:,1],x_y_corner_sub[:,0],color='green',markersize=15,ls='none',marker='*')\n\n\nplt.show()","dc9e94a8":"# You can define your OWN Foreground and Background so I have used the inverted image too\n\nimg = imread(PATH+'bimodal.jpeg')\ngray = color.rgb2gray(img)\ngray_invert = util.invert(gray) # just to demonstrate that it just separates the bimodal histogram\nthresh_gray= filters.threshold_otsu(gray)\nthresh_invert = filters.threshold_otsu(gray_invert)\nprint(f'Otsu Threshold of Grayscale Image is: {thresh_gray}')\nprint(f'Otsu Threshold of Inverted Grayscale Image is: {thresh_invert}')\n\nbinary_gray = gray > thresh_gray\nbinary_invert = gray < thresh_invert\n\nf,ax = plt.subplots(2,2,figsize=(12,8))\nax = ax.ravel()\n\nax[0].imshow(gray,cmap='gray')\nax[0].set_title('GrayScale')\n\nax[1].imshow(binary_gray,cmap='gray')\nax[1].set_title('Binary Gray Image > thresh')\n\nax[2].imshow(gray_invert,cmap='gray')\nax[2].set_title('Inverted Grayscale')\n\nax[3].imshow(binary_invert,cmap='gray')\nax[3].set_title('Binary Inverted Image < thresh')\n\nplt.show()","82c3c4f0":"f,ax = plt.subplots(1,2,figsize=(15,4))\n\nax[0].imshow(img)\nax[0].set_title('Original Image')\n\nax[1].hist(gray.ravel(),bins=256)\nax[1].set_title('Histogram of Grayscale Image')\nax[1].set_ylabel('Count')\nax[1].set_xlabel('Pixels Intensities')\nplt.show()","991f8620":"rgb_img = imread(PATH+'archi.jpeg')\nimg = color.rgb2gray(rgb_img)\n\nf,ax = plt.subplots(1,2,figsize=(15,5))\nax[0].imshow(rgb_img)\nax[0].set_title('RGB Image')\n\nax[1].hist(rgb_img.ravel(),bins=256) #nota bimodal histogram\nax[1].set_title('Histogram of RGB Image')\nax[1].set_ylabel('Count')\nax[1].set_xlabel('Pixels Intensities')\nplt.show()","0b2c3c07":"f,ax = filters.try_all_threshold(img,verbose=False,figsize=(8,15))\n_ = ax[0].set_title('Grayscale version of Original')","afaac1bd":"img = imread(PATH+'archi.jpeg')\ngray = color.rgb2gray(img)\nthresh = filters.threshold_local(gray,block_size=37) # 37 pixels makes a block or neighbour\nprint(f'Local Threshold: {thresh}')\n\nbinary = gray > thresh\n\nf,ax = plt.subplots(1,2,figsize=(15,6))\nax = ax.ravel()\n\nax[0].imshow(img,cmap='gray')\nax[0].set_title('Original')\n\nax[1].imshow(binary,cmap='gray')\nax[1].set_title('Binary Image > thresh')\n\nplt.show()","47b1e342":"There are 2 peaks going around 0.1 and 0.7 means the forest or bakground lies in 0.1 distribution as it makes the most of the part and the horse lies in 0.7 and that is exactly why this image is separable so clearly.\n\n**TRY USING THE ABOVE IMLEMENTATION ON `buildings.jpeg` or `archi.jpeg` and check Histogram**","74427f06":"# Contour Detection\nFind the area or lines where pixel intensities are same. Our module will be using the **Marching Squares Algorithm** for contour detection. Contour detection is hugely used for mapping of areas at same level such in geography to find out areas at same sea level.","8aea65bb":"#### Try all the thresholds\nBecause it is hard to find the optimal value in case images are not clearly bimodal. ","41abdd17":"# Object Detection\/Separation\n## Thresholding\nClassify Pixels of an image in diffrent categories(black\/white, Foreground\/Background etc) and can be seen as a method to create **Binary** image from a **Grayscale** image and segment objects from the background. **All the Pixels greater than the threshold belongs to one category and the pixels less than belongs to other one**\n1. Global or Histogram Based: Fast but uses the Historam of the whole image pixels intensities but ignores relation among neighbouring pixels.\n2. Local Thresholding: Slow, Computationally Expensive but considers local or neighbouring pixels","306e1017":"# Continue...\nI'll be writing a specialised notebook about the `Object Segmentation` in the next part.","64754080":"# Edge Detection\n1. Search Based Algo (Firt order Partial Derivatives)\n2. Zero Crossing (Second order PArtial Derivatives)\n\nIdea is to see the values where there is abrupt change in pixel intensities. \n\n**Working:**\n1. Find the derivatives of X and Y to see where there are intnsities changing. I can be X,Y or some direction .\n2. Find the Gradients of Magnitude. What does that even mean?? It means to find the exact direction where the intensities are getting to a minimum or maximum.\n3. Apply a threshold on gradient to say \"okay! at this threshold, the gradients are making sense and giving me edges\"\n\n**GENERAL STEPS TO APPLY BEFORE EDGE DETECTION METHODS**\n\nAlways Convert  to Grayscale\n1. Smoothening Images ( Bilateral or Gaussian Filters) (Large Sigma in Gaussian Filter, Less Sensitive to Noise and detects only Large Edges are detected)\n2. Enhance Image (Sharpening)\n3. Detect Edge\n4. If not good, apply a few more of Steps 1 and 2","409b069b":"### Find Statistical Significance\nFind if a corner is actually a corner made by intesection of two lines or just a single point","20d4a571":"## Search Based\n### Sobel and Roberts Edge Detection Algo\nThey use a sliding Kernel specially designed to detect the edges which is iterated over the whole image in steps. Sounds familiar? Yes, Exactly. It is Convolution Function with Sobel Kernel.","093adb55":"### Local Thresholding\n**Very Useful for the images where there are large variations in the background. Just like in the buildings images. It provides more details**","8f8da381":"### Global Algorithm\nA Bimodal Histogram of an image can be separated into two different histograms of a grayscale image which means are there are mainly 2 different types of distributions of pixels one of which belongs to `blackish` and other `whitish` or in other words, one of those belongs to image and other belongs to background.\nIf you want to know more about the Histogram Representation, You can [check Part-1](#)\n#### Otsu Threshold\nOne of the most used thresholding algorithm. Otsu's thresholding method involves iterating through all the possible threshold values and calculating a measure of spread (variance) for the pixel levels each side of the threshold, i.e. the pixels that either fall in foreground or background. The aim is to find the threshold value where the sum of foreground and background spreads is at its minimum. OR\n**Find a threshold value where `intra` class Variance is Minimal and `Inter-class` Variance is Maximal**","2810275d":"# Corner Detection\n## Harris Corner Detection Algorithm\nCorners have very low self similarity means they are different from the other neighbouring points in some way be it intensity or something else. Suppress the weak points or weak corners to get just the strong or sharp corners.","9f449eb4":"### Find Corners","48d9fa3a":"## Zero Crossing\n### Canny\nEnhances Signal to Noise Ratio so that it can be used in noisy images too","09fa82b8":"# Hi!!!\nThis is the 2nd Part of a 3 Part Series on Image Processing. If You are New to Image Processing, Please Check [Part 1](https:\/\/www.kaggle.com\/deshwalmahesh\/image-processing-1-basic-ocr-feature-pooling-conv) where I have briefly explained mant things for image processing such as Basic operations on images like reading, cropping, resizing, flipping, color space conversion etc.. And the nsome intermediate steps like Convolution, Pooling, Custom Filters, Reconstruction using Erosion, Dilation , Finding Convex Hull, Noise Reduction, Histogram, Feature Detection, OCR to read itext from data and how to compare 2 images using Structural Similarity.\n\nIn this Notebook We'll be covering:\n1. Contour Detection\n2. Edge Detection\n3. Corner Detection\n4. Thresholding to Seperate Object From Backgrounf using Canny, Median, Yen etc\n5. Working of Sobel Filters\n\nPlease do check out [Part3](https:\/\/www.kaggle.com\/deshwalmahesh\/image-processing-3-segmentation-autoencoder-dictl) for advanced Image Segmentation and object seperation using Canny, Sobel and Watrshed Algo. Autoencoders to find Latent features to denoise image and fanomaly detector, Dictonary Learning to decrease dimensionality."}}