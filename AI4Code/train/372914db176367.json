{"cell_type":{"57b2d09a":"code","a267ebee":"code","dad79fd8":"code","9020d0eb":"code","f0ddc6c0":"code","75d05f2c":"code","283215c9":"code","099c356c":"code","753dee8c":"code","b0f6b6fb":"code","afa4bdc9":"code","51ac5922":"code","5d288498":"code","96b3216a":"code","f7f1cb14":"code","e09ebc54":"code","19a7d3d9":"code","87bda96d":"code","d78929b3":"code","a9d10bd2":"code","e7fd75b9":"markdown","73e4cd95":"markdown","0fb69e80":"markdown","9f4e1940":"markdown","f5c3eae0":"markdown","fe321970":"markdown","013e9b9d":"markdown","79edc8f1":"markdown","2c4abe95":"markdown","96871347":"markdown","2a6132f3":"markdown"},"source":{"57b2d09a":"\nimport pandas as pd\nimport numpy as np\nimport skimage\nimport skimage.io\nimport skimage.transform\nimport scipy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sys\nimport random\nfrom sklearn.model_selection import train_test_split\n\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Conv2D,MaxPool2D,Flatten,Dropout,BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\nnp.random.seed(42)\n# Global variables\nimg_folder='..\/input\/bee_imgs\/bee_imgs\/'\nimg_width=100\nimg_height=100\nimg_channels=3\n\n# Any results you write to the current directory are saved as output.","a267ebee":"bees=pd.read_csv('..\/input\/bee_data.csv')\nbees.head()","dad79fd8":"bees.shape","9020d0eb":"bees=pd.read_csv('..\/input\/bee_data.csv', \n                index_col=False,  \n                parse_dates={'datetime':[1,2]},\n                dtype={'subspecies':'category', 'health':'category','caste':'category'})\n\ndef read_or_skip(file):\n    \"\"\"This function is to supress imageio exception if file doesn't exist\"\"\"\n    try:\n        img = skimage.io.imread(img_folder + file)\n        img = skimage.transform.resize(img, (img_width, img_height), mode='reflect')\n        return img[:,:,:img_channels]\n    except:\n        #print('Skipping %s. %s' %(file, sys.exc_info()[1]))\n        return None\n\nbees['img'] = bees['file'].apply(read_or_skip)\nbees.dropna(inplace=True)\n\n# Print sample data without img array\nbees.drop('img',axis=1).head()","f0ddc6c0":"bees.head()","75d05f2c":"bees.shape","283215c9":"f, ax = plt.subplots(nrows=2,ncols=2,figsize=(12,8))\nbees['subspecies'].value_counts().plot(kind='bar',ax=ax[0,0])\nax[0,0].set_ylabel('Count')\nax[0,0].set_title('Subspecies')\n\n\nbees['location'].value_counts().plot(kind='bar',ax = ax[0,1])\nax[0,1].set_title('Location')\nax[0,1].set_ylabel('Count')\n\nbees['caste'].value_counts().plot(kind='bar',ax = ax[1,0])\nax[1,0].set_title('Caste')\nax[1,0].set_ylabel('Count')\n\nbees['health'].value_counts().plot(kind='bar',ax = ax[1,1])\nax[1,1].set_title('Health')\nax[1,1].set_ylabel('Count')\n\nf.subplots_adjust(hspace=0.7)\nf.tight_layout()\nplt.show()\n","099c356c":"import imageio","753dee8c":"# Select first X subspecies titles \ncolumns=7\nsubspecies = bees['subspecies'].unique()[:7]\nf, ax = plt.subplots(nrows=1,ncols=7, figsize=(12,3))\ni=0\n\n# Draw the first found bee of given subpecies\nfor s in subspecies:\n    if s == 'healthy': continue\n    file=img_folder + bees[bees['subspecies']==s].iloc[0]['file']\n    im=imageio.imread(file)\n    ax[i].imshow(im, resample=True)\n    ax[i].set_title(s, fontsize=8)\n    i+=1\n    \nplt.suptitle(\"Subspecies of Bee\")\nplt.tight_layout()\nplt.show()\n\n","b0f6b6fb":"healthy = bees[bees['health'] == 'healthy'].iloc[:5]\n\nf, ax = plt.subplots(nrows=1,ncols=5, figsize=(12,3))\n# Read image of original size from disk, because bees['img'] contains resized numpy array\nfor i in range(0,5): \n    file = img_folder + healthy.iloc[i]['file']\n    ax[i].imshow(imageio.imread(file))\n\nplt.suptitle(\"Healthy Bees\")\nplt.tight_layout()\nplt.show()","afa4bdc9":"healths_cat = bees['health'].cat.categories\nhealths_cat","51ac5922":"healths_cat.size","5d288498":"f, ax = plt.subplots(1, healths_cat.size-1, figsize=(12,3))\ni=0\n\nfor c in healths_cat:\n    if c == 'healthy': continue\n    bee = bees[bees['health'] == c].iloc[0]\n    f = bee['file']\n    f_path= img_folder + f\n    ax[i].imshow(imageio.imread(f_path))\n    ax[i].set_title(bee['health'], fontsize=8)\n    i += 1\nplt.suptitle(\"Sick Bees\")    \nplt.tight_layout()\nplt.show()","96b3216a":"# Prepare train and test data\nlabels = pd.get_dummies(bees.subspecies, drop_first=True)\nX = np.stack(bees.img)\ntrain_data, test_data, train_labels, test_labels = train_test_split(X, labels)\n# Build and train CNN model\nmodel1=Sequential()\nmodel1.add(Conv2D(5, kernel_size=3, input_shape=(img_width, img_height,3), activation='relu'))\nmodel1.add(MaxPool2D(2))\nmodel1.add(Conv2D(10, kernel_size=3, activation='relu'))\nmodel1.add(Flatten())\nmodel1.add(Dense(labels.columns.size, activation='softmax'))\nmodel1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\ntraining = model1.fit(train_data, train_labels, validation_split=0.2, epochs=20, batch_size=10)","f7f1cb14":"## Trained model analysis and evaluation\nf, ax = plt.subplots(2,1, figsize=(5,5))\nax[0].plot(training.history['loss'])\nax[0].set_title('Detect kind of Bee: loss')\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Loss')\n\n# Accuracy\nax[1].plot(training.history['acc'])\nax[1].set_title('Detect kind of Bee: accuracy')\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Accuracy')\nplt.tight_layout()\nplt.show()\n\n# Accuracy by subspecies\ntest_pred = model1.predict(test_data)\nacc_by_subspecies = np.logical_and((test_pred > 0.5), test_labels).sum()\/test_labels.sum()\nacc_by_subspecies.plot(kind='bar', title='Subspecies prediction accuracy')\nplt.ylabel('Accuracy')\nplt.show()\n\n# Loss function and accuracy\ntest_res = model1.evaluate(test_data, test_labels)\nprint('Evaluation: loss function: %s, accuracy:' % test_res[0], test_res[1])","e09ebc54":"# Prepare train and test data\nlabels = pd.get_dummies(bees.health)\nX = np.stack(bees.img)\ntrain_data, test_data, train_labels, test_labels = train_test_split(X, labels)\n\n# Data augmentation - a little bit rotate, zoom and shift input images.\ngenerator = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\ngenerator.fit(train_data)\n\n# Split train data to train and validation\ntrain_data, train_data_val, train_labels, train_labels_val = train_test_split(train_data, \n                                                                              train_labels,\n                                                                              test_size=0.1)  \n# Build and train CNN model\nmodel2 = Sequential()\nmodel2.add(Conv2D(6, kernel_size=3, input_shape=(img_width, img_height,3), activation='relu'))\nmodel2.add(MaxPool2D(2))\nmodel2.add(Conv2D(12, kernel_size=3, activation='relu'))\nmodel2.add(Flatten())\nmodel2.add(Dense(labels.columns.size, activation='softmax'))\nmodel2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# We'll stop training if no improvement after some epochs\nearlystopper = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n\n# Train\ntraining = model2.fit_generator(generator.flow(train_data,train_labels, batch_size=20),\n                               epochs = 20,\n                               validation_data=(train_data_val, train_labels_val),\n                               steps_per_epoch=20,  # batch_size\n                               callbacks=[earlystopper])","19a7d3d9":"f, ax = plt.subplots(2,1, figsize=(5,5))\n\n# Loss function\nax[0].plot(training.history['loss'])\nax[0].set_title('Detect Bee health: loss')\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Loss')\n\n# Accuracy\nax[1].plot(training.history['acc'])\nax[1].set_title('Detect Bee health: accuracy')\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Accuracy')\nplt.tight_layout()\nplt.show()\n\n# Prediction accuracy by health status\ntest_pred = model2.predict(test_data)\nacc_by_health = np.logical_and((test_pred > 0.5), test_labels).sum()\/test_labels.sum()\nacc_by_health.plot(kind='bar', title='Health prediction accuracy')\nplt.ylabel('Accuracy')\nplt.tight_layout()\nplt.show()\n\ntest_res = model2.evaluate(test_data, test_labels)\nprint('Evaluation: loss function: %s, accuracy:' % test_res[0], test_res[1])","87bda96d":"# Common function for visualization of kernels\ndef visualize_layer_kernels(img, conv_layer, title):\n    \"\"\"\n    Displays how input sample image looks after convolution by each kernel\n    :param img: Sample image array\n    :param conv_layer: Layer of Conv2D type\n    :param title: Text to display on the top \n    \"\"\"\n    # Extract kernels from given layer\n    weights1 = conv_layer.get_weights()\n    kernels = weights1[0]\n    kernels_num = kernels.shape[3]\n    \n    # Each row contains 3 images: kernel, input image, output image\n    f, ax = plt.subplots(kernels_num, 3, figsize=(7, kernels_num*2))\n\n    for i in range(0, kernels_num):\n        # Get kernel from the layer and draw it\n        kernel=kernels[:,:,:3,i]\n        ax[i][0].imshow((kernel * 255).astype(np.uint8), vmin=0, vmax=255)\n        ax[i][0].set_title(\"Kernel %d\" % i, fontsize = 9)\n        \n        # Get and draw sample image from test data\n        ax[i][1].imshow((img * 255).astype(np.uint8), vmin=0, vmax=255)\n        ax[i][1].set_title(\"Before\", fontsize=8)\n        \n        # Filtered image - apply convolution\n        img_filt = scipy.ndimage.filters.convolve(img, kernel)\n        ax[i][2].imshow((img_filt * 255).astype(np.uint8), vmin=0, vmax=255)\n        ax[i][2].set_title(\"After\", fontsize=8)\n        \n    plt.suptitle(title)\n    plt.tight_layout()\n    plt.subplots_adjust(top=0.93)\n    plt.show()   ","d78929b3":"# Take sample image to visualize convolutoin\nidx = random.randint(0,len(test_data)-1)\nimg = test_data[idx,:,:,:]\n# Take 1st convolutional layer and look at it's filters\nconv1 = model1.layers[0]\nimg = visualize_layer_kernels(img, conv1, \"Subspecies CNN. Layer 0\")\n\n# Take sample image to visualize convolutoin\nidx = random.randint(0,len(test_data)-1)\nimg = test_data[idx,:,:,:]\n# Take another convolutional layer and look at it's filters\nconv2 = model1.layers[2]\nres = visualize_layer_kernels(img, conv2, \"Subspecies CNN. Layer 2\")","a9d10bd2":"# Take sample image to visualize convolutoin\nidx = random.randint(0,len(test_data)-1)\nimg = test_data[idx,:,:,:]\n# Take 1st convolutional layer and look at it's filters\nconv1 = model2.layers[0]\nvisualize_layer_kernels(img, conv1, \"Health CNN layer 0\")\n\n# Take sample image to visualize convolutoin\nidx = random.randint(0,len(test_data)-1)\nimg = test_data[idx,:,:,:]\n# Take another convolutional layer and look at it's filters\nconv2 = model2.layers[2]\nvisualize_layer_kernels(img, conv2, \"Health CNN layer 2\")","e7fd75b9":"### 3.2 Look at Bees images\n\n#### Subspecies of Bee\n","73e4cd95":"### 5. CNN model for Bee health detection\n#### 5.1 Prepare data and train Bee health detection model\u00b6\n","0fb69e80":"### 4.2 Evaluate bee subspecies detection model\n","9f4e1940":"### 6.2 Visualize convolutions in Bee health CNN","f5c3eae0":"### 6. Visualization of Conv2D layers\n\nLet's look how our models process images. Our models contains Conv2D layers with kernels inside. We are going to convolve a sample image through kernels and see how does it look before and after each kernel. For each kernel visualize: kernel itself, input image, output image. No idea how to interprete these results, let's do it for fun :)\n\nFunction for Conv2D layers visualization:\n","fe321970":"### 5.2 Evaluate Bee health detection model","013e9b9d":"### 4. CNN Model for Bee subspecies detection\n#### 4.1 Prepare data and train Bee subspecies detection CNN","79edc8f1":"### Sick Bees","2c4abe95":"### Read Bee data\n","96871347":" ### Bee data EDA\n ####  Distribution of bees by categories","2a6132f3":"### Healthy Bees"}}