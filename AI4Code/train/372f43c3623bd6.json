{"cell_type":{"b7b4415a":"code","3e977677":"code","4f2702d6":"code","f63219f9":"code","3f6be9eb":"code","e720ba80":"code","bb38195b":"code","99891ce7":"code","605bea78":"code","9ef9f9ab":"code","879ac18f":"code","896a42f3":"code","e28f48d4":"code","cee114f8":"code","e2c042fa":"code","b2d4631d":"code","5ea46de0":"code","882be7ec":"code","07a6831d":"code","b92d1b81":"code","8b28abae":"code","09f22314":"code","74bba7c3":"code","b4893f9e":"code","5a40a999":"code","7ec7c788":"code","efba91be":"code","a31786cd":"code","2b83001e":"code","96331904":"code","79806bf4":"code","25e131c9":"code","65f4abb6":"code","c8c0412c":"code","97f78cb4":"code","1edd1fa7":"code","2c757c1e":"code","b36af9d6":"code","76a482df":"code","dec6926a":"code","94e0670d":"code","7177e5fb":"code","af41eca4":"code","98805297":"code","f13b64a5":"code","d504f556":"code","7697168b":"code","07ab195e":"code","0822eb84":"code","eb672666":"code","ef35a64b":"code","933617f3":"code","8b6c29d3":"code","887ee022":"code","880c39ce":"code","0a8a8adb":"code","390aa01a":"code","1d3b2868":"code","c1c357e7":"code","495b9455":"code","9b88b174":"code","52443792":"code","638ea798":"code","814886ce":"code","42a2aa91":"code","a99b2720":"code","14fa22a6":"code","b6211326":"code","2be05e12":"code","9db10075":"code","9739e676":"code","c4540fd0":"code","11afd980":"code","c5a40968":"code","fb2669d1":"code","b0ea4aac":"code","988964c3":"code","ca07f757":"code","3947cfd0":"code","59e1e12e":"code","dcfac1a8":"code","63adf208":"code","f2d167a1":"code","81c76693":"code","6aff72c9":"code","d86385f5":"code","096293a6":"code","09c49891":"code","f83d62ec":"code","5152d3f7":"code","b10f8f29":"code","cbdd6e84":"code","fcda6f92":"code","775f0ada":"code","b9519090":"code","569decb4":"code","066b721e":"code","c92e18c4":"code","7389d044":"code","1cbfca75":"code","af9bde8d":"code","5f828150":"code","46b1f5f7":"code","82f5375e":"code","d6379aa3":"code","20bcf99a":"code","e4af50df":"code","00e9f913":"code","bf4924c9":"code","a79c571f":"code","cff1f2a5":"code","73cceea8":"code","54c9f31c":"code","6605c04f":"code","9c3844f6":"code","9cda72fc":"code","4b2a3d2f":"code","2ff71903":"code","921234ce":"code","2df96378":"code","fdc22b16":"code","63afb6a8":"code","e9f35dcd":"code","1afdc825":"code","d1118b15":"code","2a74351e":"code","86c7a511":"code","5e39944f":"code","8f509b66":"code","7f29b515":"code","45ed74d2":"code","d6b4787d":"code","0fd65679":"code","d4cced54":"code","9e05f6ef":"code","10c93070":"code","98c245a9":"code","e7db6583":"code","9312a331":"code","6ec67972":"code","5ec91ec1":"code","a1aae5c4":"code","aa6c9e1a":"code","bee65710":"code","ae877679":"code","b14c1453":"code","1286cfb3":"code","e6ae6b01":"code","0efebb48":"code","5fc8aa31":"code","249ae8c5":"code","1418e27a":"code","ac6656a4":"code","01cf67dd":"code","620b167f":"code","c6bee491":"code","d41b17e6":"code","ef0b9a1b":"code","0ea78c74":"code","9895b17d":"code","71c97855":"code","6c76bc25":"code","1fbd44b0":"code","33df63fe":"code","781ff314":"code","366899d1":"code","2d9aac00":"code","5b81073a":"code","db8fc2ca":"code","36ba560b":"code","d7674546":"code","40633d2b":"code","6142ce6c":"code","d4a64314":"code","38a11eb4":"code","f6b68d27":"code","23d57ebd":"code","9203114f":"code","ae26efc3":"code","5e6c4dd2":"code","e9c46d2c":"code","34c9db7c":"code","8a155fd2":"code","f8d97a1a":"code","9e90499e":"code","8c785de8":"code","c90e2d0b":"code","0e7c7ce6":"code","f3c4c5be":"code","c17c06dc":"code","960b9d18":"code","aca299c9":"code","bfe2347d":"code","799dd2df":"code","54340cd4":"code","0b7e0c83":"code","6634748b":"code","232b224a":"code","9b900545":"code","c32e05de":"code","7d98f25a":"code","acbf3e36":"code","295f5aec":"code","35db4ca4":"code","209b6e10":"code","928778b9":"code","854d2ad5":"code","6cad56f1":"code","34a9e184":"code","9115a2fb":"code","5d50b443":"code","2e1fcd6a":"code","3e503def":"code","3a00fd9f":"code","84d65b0a":"code","acf6aa59":"code","bec2239b":"code","b96d83de":"code","97cc8a03":"code","737070ed":"code","ce998a48":"code","7226239a":"code","c1b174de":"code","10e30854":"code","c8d0e34e":"code","5684d4be":"code","b2a87db4":"code","942ff352":"code","e2757d87":"code","ac3468d6":"code","3683ae37":"code","fe8ee6d5":"code","6eb4b68b":"code","ad73e0aa":"code","187f90ec":"code","40d52323":"code","5991cbb9":"code","2d7c007b":"code","049b510f":"code","b0b7ddce":"code","a7a0bd67":"code","38e0fda7":"code","5b82590a":"code","486a9b05":"code","8838000d":"code","e389df45":"code","b355a543":"code","8f79087d":"code","45ded2ff":"code","40f9334f":"code","da4a2962":"code","ad352626":"code","1a7c9311":"code","82e89e2e":"code","cea67eb0":"code","6c32d862":"code","46a493a4":"code","7ae87d21":"code","fd13fbf9":"code","50e41fbc":"code","3a2ea62e":"code","e17e4951":"code","e94b1575":"code","a9f96d99":"code","179d813c":"code","9d595c0e":"code","6c60b3c3":"code","e1165600":"code","a33324a5":"code","d80f99b2":"code","58db9fdf":"code","a6a99c39":"code","ce427d14":"code","0610b289":"code","f67c23f8":"code","628475a8":"code","27222187":"code","ce7f81f2":"code","7a9ed79d":"code","42ea4f24":"code","ffd4929a":"code","f9da6af0":"code","3d50eeae":"code","58508a75":"code","9bbb22cd":"code","47dc85d7":"code","394e3baf":"code","622a28a5":"code","75c94490":"code","a486f905":"code","a463efb6":"code","91fbff02":"code","25754471":"code","79c7c7b4":"code","fc849313":"code","3c76c991":"code","6f35ecc1":"code","576d4dbf":"code","fd64bf22":"code","ac6bfb60":"code","dd132fb8":"code","3f0eb797":"code","58749e05":"code","9f63c8f5":"code","fa3e6f2c":"code","908079a6":"code","847b6e6a":"code","abf16a69":"code","e287cfbf":"code","456bd8b9":"code","73cf80fb":"code","d0d7655e":"code","4cc53c20":"code","2e90ee59":"code","200960cf":"code","0cf636e1":"code","eda28d2d":"code","0566ece3":"code","f72cb2d1":"code","84e8731a":"code","d0c6ed62":"code","bc23059a":"code","143174e7":"code","1862faaf":"markdown","3c7d9cf0":"markdown","8fcf05d2":"markdown","355f09a5":"markdown","f1849012":"markdown","3bce3965":"markdown","66c8b265":"markdown","c44418eb":"markdown","d13060ed":"markdown","934426ad":"markdown","9fd747a1":"markdown","869896f5":"markdown","d6293dcc":"markdown","7978d69b":"markdown","5ac58409":"markdown","942abde2":"markdown","3e89ef4e":"markdown","ee8abaf0":"markdown","30a3cb68":"markdown","084f79a3":"markdown","b2f65eb9":"markdown","453c4121":"markdown","661074e1":"markdown","c8826aca":"markdown","c8a0d446":"markdown","3e62c44d":"markdown","56b111cc":"markdown","c53c6418":"markdown","a0c18b13":"markdown","8d53ea02":"markdown","65efa32b":"markdown","98c7194f":"markdown","e053ef05":"markdown","a00c8ead":"markdown","a558f00e":"markdown","735533e7":"markdown","b8b9e399":"markdown","1bcd3260":"markdown","df8e70bc":"markdown","69afdbdb":"markdown","eb48d50b":"markdown","4ab0e730":"markdown","26a5caee":"markdown","efaf6f17":"markdown","42ae08b0":"markdown","8cc40161":"markdown","db7f99e1":"markdown","a90426c3":"markdown","c2c3f784":"markdown","12b45f7a":"markdown","8d8f5c60":"markdown","37730a73":"markdown","908014b0":"markdown","df0ec048":"markdown","4578b1bd":"markdown","901e1d25":"markdown","abe2540a":"markdown","0d0e888d":"markdown","cb851f1f":"markdown","02be0acc":"markdown","08777c1a":"markdown","6edf0d31":"markdown","4fbc0c1e":"markdown","2700da29":"markdown","b44b7f0c":"markdown","7d1e34aa":"markdown","df5aeeec":"markdown","12bc8864":"markdown","bd2e8c4d":"markdown","fc7952a3":"markdown","d6a14346":"markdown","b3433b17":"markdown","b7d38e8a":"markdown","18a97a24":"markdown","668690a6":"markdown","9e48dc69":"markdown","5645e4a6":"markdown","bcd69344":"markdown","78f6c16b":"markdown","414012f7":"markdown","9fc0eb5e":"markdown","f150c97a":"markdown","59bc5b9e":"markdown","f0605ccc":"markdown","e4dfd929":"markdown","d793a81f":"markdown","40900dd5":"markdown","5dedd446":"markdown","3ad5d117":"markdown","08ac2690":"markdown","c8e4a268":"markdown","a15269bc":"markdown","4a684eb5":"markdown","ff0a140b":"markdown","8c033605":"markdown","2f3f021c":"markdown","973d4ce4":"markdown","128fdc53":"markdown","8b1dd658":"markdown","6b0ffc00":"markdown","fedec090":"markdown","ed629b95":"markdown"},"source":{"b7b4415a":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport requests as rq\nimport gzip\nfrom wordcloud import WordCloud\nimport scipy as sp\nimport plotly\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nfrom scipy import stats\ninit_notebook_mode(connected=True) \nsns.set(color_codes=True)\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew\nfrom scipy.stats.stats import pearsonr\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew\nfrom scipy.stats.stats import pearsonr\n\n\n%config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook\n%matplotlib inline\n\n%matplotlib inline\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","3e977677":"sales_df = pd.read_csv('..\/input\/video-game-sales-with-ratings\/Video_Games_Sales_as_at_22_Dec_2016.csv', na_values=['NA'])","4f2702d6":"#Good dataframe, lots to analyse, lots of information and alot of games.\nsales_df.head()","f63219f9":"sales_df.info()","3f6be9eb":"sales_df.describe()","e720ba80":"sales_df.dtypes","bb38195b":"sales_df.drop_duplicates(subset=['Name', 'Platform'], inplace=True)","99891ce7":"sales_df.drop(['Critic_Count'] ,inplace =True, axis =1)\nsales_df.drop(['User_Count'] ,inplace =True, axis =1)","605bea78":"sales_df['User_Score'].unique()","9ef9f9ab":"sales_df['User_Score'].fillna(0,inplace=True)","879ac18f":"sales_df['User_Score'] = sales_df['User_Score'].replace('tbd', np.nan)","896a42f3":"sales_df['User_Score'].fillna(0,inplace=True)","e28f48d4":"sales_df['User_Score'].replace(0, np.nan, inplace=True)","cee114f8":"sales_df.User_Score = sales_df.User_Score.astype(float)","e2c042fa":"sales_df.info()","b2d4631d":"sales_df.isnull().sum().sort_values(ascending=False).head(20)","5ea46de0":"total = sales_df.isnull().sum().sort_values(ascending=False)\npercent = (sales_df.isnull().sum()\/sales_df['Global_Sales'].count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)","882be7ec":"missing_column_sales= missing_data[missing_data['Total']>0].index\nmissing_column_sales","07a6831d":"sales_df[pd.isnull(sales_df['Name'])]","b92d1b81":"sales_df.drop(659, inplace =True)","8b28abae":"sales_df[pd.isnull(sales_df['Name'])]","09f22314":"sales_df['Publisher'].fillna('Unknown', inplace=True)","74bba7c3":"sales_df.dropna(subset=['Year_of_Release'], inplace=True)","b4893f9e":"sales_df['Rating'].fillna('Unknown', inplace=True)","5a40a999":"sales_df.drop(['Developer'] ,inplace =True, axis =1)","7ec7c788":"sales_df.info()","efba91be":"sales_df.head()","a31786cd":"sales_df.isnull().sum().sort_values(ascending=False).head(20)","2b83001e":"sales_df.groupby(['Year_of_Release']).size()","96331904":"init_notebook_mode(connected=True)\nyear_count = sales_df.groupby('Year_of_Release', axis=0).count().reset_index()[['Year_of_Release','Name']]\nyear_count.Year_of_Release = year_count.Year_of_Release.astype('int')","79806bf4":"trace = go.Scatter(\n    x = year_count.Year_of_Release,\n    y = year_count.Name,\n    mode = 'lines',\n    name = 'lines'\n    \n)\n\n\nlayout = go.Layout(\n    title='Release by Year',\n    yaxis=dict(\n        title='Count'\n    ),\n    xaxis=dict(\n        title='Year'\n    ),\n    height=600, width=600\n)\n\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","25e131c9":"drop_year = [1980.0, 1981.0, 1982.0,1983.0,1984.0,1985.0,1986.0,1987.0,1988.0,1989.0, 1990.0, 1991.0,1992.0,1993.0, 1994.0, 1995.0 ,2017.0,2020.0]","65f4abb6":"sales_df[~sales_df.Year_of_Release.isin(drop_year)]","c8c0412c":"sales = sales_df[~sales_df.Year_of_Release.isin(drop_year)]","97f78cb4":"sales.groupby(['Year_of_Release']).size()","1edd1fa7":"sales.head()","2c757c1e":"sales.info()","b36af9d6":"sales.dtypes","76a482df":"sales.describe()","dec6926a":"steam_data = pd.read_csv(\"..\/input\/steam-data-info\/games-features.csv\")","94e0670d":"steam_data.head()","7177e5fb":"steam_data.drop(['RequiredAge' ,'ResponseID','QueryID', 'ResponseName','DemoCount','DeveloperCount','DLCCount','MovieCount','PackageCount',\n 'PublisherCount','ScreenshotCount','AchievementCount','AchievementHighlightedCount','ControllerSupport',\n 'IsFree', 'FreeVerAvail', 'PurchaseAvail',\n 'SubscriptionAvail','PlatformWindows','PlatformLinux','PlatformMac','PCReqsHaveMin','PCReqsHaveRec','LinuxReqsHaveMin','LinuxReqsHaveRec','MacReqsHaveMin','MacReqsHaveRec','CategorySinglePlayer',\n                  'CategoryMultiplayer','CategoryCoop','CategoryMMO','CategoryInAppPurchase','CategoryIncludeSrcSDK','CategoryIncludeLevelEditor','CategoryVRSupport','GenreIsNonGame','GenreIsIndie','GenreIsAction',\n                  'GenreIsAdventure','GenreIsCasual','GenreIsStrategy',\n                  'GenreIsRPG','GenreIsSimulation','GenreIsEarlyAccess','GenreIsFreeToPlay',\n                  'GenreIsSports','GenreIsRacing','GenreIsMassivelyMultiplayer',\n 'SupportEmail', 'SupportURL','DRMNotice','ExtUserAcctNotice','HeaderImage','LegalNotice', 'SupportedLanguages','Website','PCMinReqsText','PCRecReqsText','LinuxMinReqsText','LinuxRecReqsText','MacMinReqsText','MacRecReqsText','Background','PriceCurrency', 'SteamSpyPlayersVariance', 'SteamSpyOwners' , 'SteamSpyOwners', 'Metacritic', 'SteamSpyOwnersVariance','SteamSpyPlayersEstimate', 'RecommendationCount', 'ReleaseDate', 'PriceInitial'], inplace=True, axis = 1)","af41eca4":"steam_data.head()","98805297":"steam_data.info()","f13b64a5":"steam_data[pd.isnull(steam_data['QueryName'])]","d504f556":"steam_data.drop(steam_data.index[269], inplace =True )","7697168b":"steam_data.replace(\" \", np.NaN, inplace=True)","07ab195e":"steam_data.head()","0822eb84":"steam_data.dropna(subset=['DetailedDescrip'], inplace = True)","eb672666":"steam_data.info()","ef35a64b":"steam_data.head()","933617f3":"#Change this column name to 'Name' so \n#it can be joined with the sales df easier if necessary\nsteam_data=steam_data.rename(columns = {'QueryName' : 'Name'})","8b6c29d3":"games_df = sales.merge(steam_data, how='left', on='Name')","887ee022":"games_df.info()","880c39ce":"games_df.head()","0a8a8adb":"games_df.Platform = games_df.Platform.astype('category')\ngames_df.Platform.describe()","390aa01a":"games_df.info()","1d3b2868":"relevant_years = [2014.0, 2015.0, 2016.0]","c1c357e7":"relevant_games = games_df[games_df.Year_of_Release.isin(relevant_years)]","495b9455":"relevant_games.Platform = games_df.Platform.astype('category')\nrelevant_games.Platform.describe()","9b88b174":"relevant_games['Year_of_Release'].unique()","52443792":"relevant_games.head()","638ea798":"platform_count = games_df.groupby('Platform', axis=0).count().reset_index()[['Platform','Name']].sort_values(by = \"Name\", ascending=True)","814886ce":"layout = go.Layout(\n    title='Total Release by Platforms',\n    yaxis=dict(\n        title='Platform'\n    ),\n    xaxis=dict(\n        title='Count'\n    ),\n    height=600, width=600\n)\n\ntrace = go.Bar(\n            x=platform_count.Name,\n            y=platform_count.Platform,\n            orientation = 'h'\n        )\n\n\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig, show_link=False)","42a2aa91":"platGenre = pd.crosstab(games_df.Platform,games_df.Genre)\nplatGenreTotal = platGenre.sum(axis=1).sort_values(ascending = False)\nplt.figure(figsize=(8,6))\nsns.barplot(y = platGenreTotal.index, x = platGenreTotal.values, orient='h')\nplt.ylabel = \"Platform\"\nplt.xlabel = \"The amount of games\"\nplt.show()","a99b2720":"platform_count = relevant_games.groupby('Platform', axis=0).count().reset_index()[['Platform','Name']].sort_values(by = \"Name\", ascending=True)","14fa22a6":"layout = go.Layout(\n    title='Total Release by Platforms, 2013-2016',\n    yaxis=dict(\n        title='Platform'\n    ),\n    xaxis=dict(\n        title='Count'\n    ),\n    height=600, width=600\n)\n\ntrace = go.Bar(\n            x=platform_count.Name,\n            y=platform_count.Platform,\n            orientation = 'h'\n        )\n\n\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig, show_link=False)","b6211326":"platGenre = pd.crosstab(relevant_games.Platform,relevant_games.Genre)\nplatGenreTotal = platGenre.sum(axis=1).sort_values(ascending = False)\nplt.figure(figsize=(8,6))\nsns.barplot(y = platGenreTotal.index, x = platGenreTotal.values, orient='h')\nplt.ylabel = \"Platform\"\nplt.xlabel = \"The amount of games\"\nplt.show()","2be05e12":"table_count = pd.pivot_table(relevant_games,values=['Global_Sales'],index=['Year_of_Release'],columns=['Platform'],aggfunc='count',margins=False)\n\nplt.figure(figsize=(19,16))\nsns.heatmap(table_count['Global_Sales'],linewidths=.5,annot=True,fmt='2.0f',vmin=0)\nplt.title('Game Releases')","9db10075":"sns.factorplot(x=\"Platform\", y=\"Global_Sales\", data=relevant_games, size= 4, aspect =2)","9739e676":"sales_by_platform = games_df.groupby(['Platform','Name'], axis = 0).sum().reset_index()[['Platform','Name','Global_Sales']]","c4540fd0":"import random\nfrom numpy import * \nplatforms = sales_by_platform.Platform.unique()\ntraces = []\nc = ['hsl('+str(h)+',50%'+',50%)' for h in linspace(0, 360, len(platforms))]\n\nfor i in range(len(platforms)):\n    platform= platforms[i]\n    df_platform = sales_by_platform[sales_by_platform.Platform == platform]\n    trace = go.Box(\n        y=np.array(df_platform.Global_Sales),\n        name=platform,\n        boxmean=True,\n        marker={'color': c[i]}\n    )\n    \n    traces.append(trace)\n\nlayout = go.Layout(\n    title='Sales by platform (Alot of outliers) ',\n    showlegend=False,\n    yaxis=dict(\n        title='Sales (in Millions)'\n    ),\n    height=700, width=700,\n    margin=go.Margin(\n        l=100,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    )\n)\n    \n\nfig = go.Figure(data=traces, layout=layout)\niplot(fig)\n","11afd980":"# The outliers consist of:\ngames_df.groupby(['Platform','Name'], axis = 0).\\\n         sum()[['Global_Sales']].\\\n         sort_values(by=\"Global_Sales\", ascending = False).\\\n         reset_index()[:20]","c5a40968":"PERCENTAGE = 0.99\ntraces = []\n\nfor i in range(len(platforms)):\n    platform = platforms[i]\n    df_platform = sales_by_platform[sales_by_platform.Platform == platform]\n    df_platform = df_platform[df_platform.Global_Sales > df_platform.Global_Sales.quantile(PERCENTAGE)]\n    \n    trace = go.Box(\n        y=np.array(df_platform.Global_Sales),\n        name=platform,\n        boxmean=True,\n        marker={'color': c[i]}\n    )\n    \n    traces.append(trace)\n\nlayout = go.Layout(\n    title='Sales by platform (TOP 1% games)',\n    showlegend=False,\n    yaxis=dict(\n        title='Sales (in Millions)'\n    ),\n    height=700, width=700,\n    margin=go.Margin(\n        l=100,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    )\n)\n    \n\nfig = go.Figure(data=traces, layout=layout)\niplot(fig)","fb2669d1":"PERCENTAGE = 0.95\ntraces = []\n\nfor i in range(len(platforms)):\n    platform = platforms[i]\n    df_platform = sales_by_platform[sales_by_platform.Platform == platform]\n    df_platform = df_platform[df_platform.Global_Sales < df_platform.Global_Sales.quantile(PERCENTAGE)]\n    \n    trace = go.Box(\n        y=np.array(df_platform.Global_Sales),\n        name=platform,\n        boxmean=True,\n        marker={'color': c[i]}\n    )\n    \n    traces.append(trace)\n\nlayout = go.Layout(\n    title='Sales by platform (significant outliers dropped)',\n    showlegend=False,\n    yaxis=dict(\n        title='Sales (in Millions)'\n    ),\n    height=700, width=700,\n    margin=go.Margin(\n        l=100,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    )\n)\n    \n\nfig = go.Figure(data=traces, layout=layout)\niplot(fig)","b0ea4aac":"table = games_df.pivot_table('Global_Sales', index='Platform', columns='Year_of_Release', aggfunc='sum')\nplatforms = table.idxmax()\nannualsales = table.max()\nyears = table.columns.astype(int)\ndata = pd.concat([platforms, annualsales], axis=1)\ndata.columns = ['Platform', 'Global Sales']\n\nplt.figure(figsize=(12,8))\nax = sns.pointplot(y = 'Global Sales', x = years, hue='Platform', data=data, size=15)\nax.set_xlabel(xlabel='Year', fontsize=16)\nax.set_ylabel(ylabel='Global Sales Per Year', fontsize=16)\nax.set_title(label='Highest Total Platform Revenue in $ Millions Per Year', fontsize=20)\nax.set_xticklabels(labels = years, fontsize=12, rotation=50)\nplt.show();","988964c3":"platforms = np.sort(sales.Platform.unique())[::-1]\n\ndef get_traces2(sales, region):\n    regional_df = sales.groupby(['Platform','Year_of_Release'], axis=0).sum().reset_index()[['Platform','Year_of_Release', region]]\n    years = list(range(1996,2018))\n    \n    temp_dict = {}\n    for platform in platforms:\n        temp_dict[platform] = {}\n        for year in years:\n            try:\n                temp_value = round(np.array(regional_df[(regional_df.Platform == platform) & \n                                   (regional_df.Year_of_Release == year)][region])[0],2)\n            except:\n                temp_value = 0\n            temp_dict[platform][year] = temp_value\n    \n    traces = []\n    for platform in platforms:\n        trace = go.Bar(\n            x = years,\n            y = list(temp_dict[platform].values()),\n            name=platform\n        )\n        traces.append(trace)\n    \n    return traces","ca07f757":"print(platforms)","3947cfd0":"data = get_traces2(sales, 'Global_Sales')\nlayout = go.Layout(\n        barmode='stack',\n        title = 'Sales change in Global',\n        xaxis=dict(\n            title='Year_of_Release'\n        ),\n        yaxis=dict(\n            title='Sales (in Millions)'\n        ),\n    \n        height=800, width=800,\n        margin=go.Margin(\n            l=100,\n            r=50,\n            b=100,\n            t=100,\n            pad=4\n        )\n    )\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","59e1e12e":"data = get_traces2(games_df, 'NA_Sales')\nlayout = go.Layout(\n        barmode='stack',\n        title = 'Sales change in North America',\n        xaxis=dict(\n            title='Year'\n        ),\n        yaxis=dict(\n            title='Sales (in Millions)'\n        ),\n    \n        height=800, width=800,\n        margin=go.Margin(\n            l=100,\n            r=50,\n            b=100,\n            t=100,\n            pad=4\n        )\n    )\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","dcfac1a8":"data = get_traces2(games_df, 'EU_Sales')\nlayout = go.Layout(\n        barmode='stack',\n        title = 'Sales change in Europe',\n        xaxis=dict(\n            title='Year'\n        ),\n        yaxis=dict(\n            title='Sales (in Millions)'\n        ),\n    \n        height=800, width=800,\n        margin=go.Margin(\n            l=100,\n            r=50,\n            b=100,\n            t=100,\n            pad=4\n        )\n    )\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","63adf208":"data = get_traces2(games_df, 'JP_Sales')\nlayout = go.Layout(\n        barmode='stack',\n        title = 'Sales change in Japan',\n        xaxis=dict(\n            title='Year'\n        ),\n        yaxis=dict(\n            title='Sales (in Millions)'\n        ),\n    \n        height=800, width=800,\n        margin=go.Margin(\n            l=100,\n            r=50,\n            b=100,\n            t=100,\n            pad=4\n        )\n    )\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","f2d167a1":"def get_percent_traces2(df, region):\n    temp_df = df.groupby(['Year_of_Release','Platform'], axis=0).sum()[[region]]\n    df_pcts = temp_df.groupby(level=0).apply(lambda x: 100 * x \/ float(x.sum()))\n    df_pcts = df_pcts.reset_index()\n    regional_df = df_pcts[df_pcts.Year_of_Release < 2017] \n    \n    years = list(range(1996,2018))\n    \n    temp_dict = {}\n    for platform in platforms:\n        temp_dict[platform] = {}\n        for year in years:\n            try:\n                temp_value = round(np.array(regional_df[(regional_df.Platform == platform) & \n                                   (regional_df.Year_of_Release == year)][region])[0],2)\n            except:\n                temp_value = 0\n            temp_dict[platform][year] = temp_value\n    \n    \n    traces = []\n    for platform in platforms:\n        trace = go.Bar(\n            x = years,\n            y = list(temp_dict[platform].values()),\n            name=platform\n        )\n        traces.append(trace)\n    \n    return traces","81c76693":"data = get_percent_traces2(games_df, 'Global_Sales')\nlayout = go.Layout(\n        barmode='stack',\n        title = 'Sales Percentage of Platforms over Years in Global',\n        xaxis=dict(\n            title='Year'\n        ),\n        yaxis=dict(\n            title='Sales (in Millions)'\n        ),\n    \n        height=800, width=800,\n        margin=go.Margin(\n            l=100,\n            r=50,\n            b=100,\n            t=100,\n            pad=4\n        )\n    )\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","6aff72c9":"plt.subplots(figsize=(15,15))\nmax_platforms=games_df.groupby('Platform')['Platform'].count()\nmax_platforms=max_platforms[max_platforms.values>1]\nmax_platforms.sort_values(ascending=True,inplace=True)\nmean_games=games_df[games_df['Platform'].isin(max_platforms.index)]\nabc=mean_games.groupby(['Year_of_Release','Platform'])['Critic_Score'].mean().reset_index()\nabc=abc.pivot('Year_of_Release','Platform','Critic_Score')\nsns.heatmap(abc,annot=True,cmap='RdYlGn',linewidths=0.4)\nplt.title('Average Score By Platforms')\nplt.show()","d86385f5":"relevant_games[\"Year_of_Release\"].unique()","096293a6":"publisher_sales = relevant_games.groupby('Publisher', axis=0).sum().reset_index()[['Publisher','Global_Sales']].sort_values(by = \"Global_Sales\", ascending=True)\npublisher_sales = publisher_sales.tail(n=30)\n\nlayout = go.Layout(\n    title='Sales by Publisher (Top 30) 2014-2016' ,\n\n    xaxis=dict(\n        title='Sales (in Millions)'\n    ),\n    height=700, width=700,\n    margin=go.Margin(\n        l=300,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    )\n)\n\ntrace = go.Bar(\n            x=publisher_sales.Global_Sales,\n            y=publisher_sales.Publisher,\n            orientation = 'h'\n        )\n\n\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","09c49891":"most_pub = relevant_games.groupby('Publisher').Global_Sales.sum()\nmost_pub.sort_values(ascending=False)[:20]\n\ntable_publisher = pd.pivot_table(relevant_games[relevant_games.Publisher.isin(most_pub.sort_values(ascending=False)[:20].index)],values=['Global_Sales'],index=['Year_of_Release'],columns=['Publisher'],aggfunc='sum',margins=False)\n\n\nplt.figure(figsize=(19,16))\nsns.heatmap(table_publisher['Global_Sales'],linewidths=.5,annot=True,vmin=0.01,cmap='PuBu')\nplt.title('Sum Publisher Global_sales of games')","f83d62ec":"new_df = relevant_games\nnew_df['Game_Count'] = 1\nnew_df = new_df.groupby(['Publisher']).sum().reset_index()[['Publisher', 'Global_Sales','Game_Count']]\nnew_df['Revenue_per_game'] = new_df.Global_Sales\/new_df.Game_Count\n\nnew_df = new_df.sort_values(by = \"Revenue_per_game\", ascending=True).\\\n                            tail(n=30)\nlayout = go.Layout(\n    title='Revenue_per_game by Publisher (Top 30) 2014-2016',\n\n    xaxis=dict(\n        title='Revenue_per_game (in Millions)'\n    ),\n    height=700, width=700,\n    margin=go.Margin(\n        l=250,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    )\n)\n\ntrace = go.Bar(\n            x=new_df.Revenue_per_game,\n            y=new_df.Publisher,\n            orientation = 'h'\n        )\n\n\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","5152d3f7":"genre_count = games_df.groupby('Genre', axis=0).count().reset_index()[['Genre','Name']].sort_values(by = \"Name\", ascending=True)\nlayout = go.Layout(\n    title='Releases by Genre, 1996-2016',\n   \n    xaxis=dict(\n        title='Releases'\n    ),\n    height=400, width=600\n)\n\ntrace = go.Bar(\n            x=genre_count.Name,\n            y=genre_count.Genre,\n            orientation = 'h'\n        )\n\n\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","b10f8f29":"genre_count = relevant_games.groupby('Genre', axis=0).count().reset_index()[['Genre','Name']].sort_values(by = \"Name\", ascending=True)\nlayout = go.Layout(\n    title='Releases by Genre, 2014-2016',\n   \n    xaxis=dict(\n        title='Releases'\n    ),\n    height=400, width=600\n)\n\ntrace = go.Bar(\n            x=genre_count.Name,\n            y=genre_count.Genre,\n            orientation = 'h'\n        )\n\n\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","cbdd6e84":"plt.subplots(figsize=(15,15))\nmax_genres=games_df.groupby('Genre')['Genre'].count()\nmax_genres=max_genres[max_genres.values>1]\nmax_genres.sort_values(ascending=True,inplace=True)\nmean_games=games_df[games_df['Genre'].isin(max_genres.index)]\nabc=mean_games.groupby(['Year_of_Release','Genre'])['Critic_Score'].mean().reset_index()\nabc=abc.pivot('Year_of_Release','Genre','Critic_Score')\nsns.heatmap(abc,annot=True,cmap='RdYlGn',linewidths=0.4)\nplt.title('Average Score By Genre\"s')\nplt.show()","fcda6f92":"table_count = pd.pivot_table(relevant_games,values=['Global_Sales'],index=['Year_of_Release'],columns=['Genre'],aggfunc='count',margins=False)\n\nplt.figure(figsize=(14,10))\nsns.heatmap(table_count['Global_Sales'],linewidths=.5,annot=True,fmt='2.0f',vmin=0)\nplt.title('Count of games')","775f0ada":"sales_by_genre = relevant_games.groupby(['Genre','Name'], axis = 0).sum().reset_index()[['Genre','Name','Global_Sales']]","b9519090":"import random\nfrom numpy import * \ngenres = sales_by_genre.Genre.unique()\ntraces = []\nc = ['hsl('+str(h)+',50%'+',50%)' for h in linspace(0, 360, len(genres))]\n\nfor i in range(len(genres)):\n    genre = genres[i]\n    df_genre = sales_by_genre[sales_by_genre.Genre == genre]\n    trace = go.Box(\n        y=np.array(df_genre.Global_Sales),\n        name=genre,\n        boxmean=True,\n        marker={'color': c[i]}\n    )\n    \n    traces.append(trace)\n\nlayout = go.Layout(\n    title='Sales by Genre (A lot of outliers)',\n    showlegend=False,\n    yaxis=dict(\n        title='Sales (in Millions)'\n    ),\n    height=700, width=700,\n    margin=go.Margin(\n        l=100,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    )\n)\n    \n\nfig = go.Figure(data=traces, layout=layout)\niplot(fig)","569decb4":"# After delete outlier\n\nPERCENTAGE = 0.95\ntraces = []\n\nfor i in range(len(genres)):\n    genre = genres[i]\n    df_genre = sales_by_genre[sales_by_genre.Genre == genre]\n    df_genre = df_genre[df_genre.Global_Sales < df_genre.Global_Sales.quantile(PERCENTAGE)]\n    \n    trace = go.Box(\n        y=np.array(df_genre.Global_Sales),\n        name=genre,\n        boxmean=True,\n        marker={'color': c[i]}\n    )\n    \n    traces.append(trace)\n\nlayout = go.Layout(\n    title='Sales by Genre (TOP 1% removed)',\n    showlegend=False,\n    yaxis=dict(\n        title='Sales (in Millions)'\n    ),\n    height=700, width=700,\n    margin=go.Margin(\n        l=100,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    )\n)\n    \n\nfig = go.Figure(data=traces, layout=layout)\niplot(fig)","066b721e":"PERCENTAGE = 0.99\ntraces = []\n\nfor i in range(len(genres)):\n    genre = genres[i]\n    df_genre = sales_by_genre[sales_by_genre.Genre == genre]\n    df_genre = df_genre[df_genre.Global_Sales > df_genre.Global_Sales.quantile(PERCENTAGE)]\n    \n    trace = go.Box(\n        y=np.array(df_genre.Global_Sales),\n        name=genre,\n        boxmean=True,\n        marker={'color': c[i]}\n    )\n    \n    traces.append(trace)\n\nlayout = go.Layout(\n    title='Sales by Genre (TOP 1%)',\n    showlegend=False,\n    yaxis=dict(\n        title='Sales (in Millions)'\n    ),\n    height=700, width=700,\n    margin=go.Margin(\n        l=100,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    )\n)\n    \n\nfig = go.Figure(data=traces, layout=layout)\niplot(fig)","c92e18c4":"sns.violinplot(x=\"Global_Sales\", y=\"Genre\", data=relevant_games, size=8)\n#sales per genre in the timeframe 2014-2016","7389d044":"# Get list of unique genres\ngenres = np.sort(games_df.Genre.unique())[::-1]\n\ndef get_traces(games_df, region):\n    regional_df = games_df.groupby(['Genre','Year_of_Release'], axis=0).sum().reset_index()[['Genre','Year_of_Release', region]]\n    years = list(range(1996,2018))\n    \n    temp_dict = {}\n    for genre in genres:\n        temp_dict[genre] = {}\n        for year in years:\n            try:\n                temp_value = round(np.array(regional_df[(regional_df.Genre == genre) & \n                                   (regional_df.Year_of_Release == year)][region])[0],2)\n            except:\n                temp_value = 0\n            temp_dict[genre][year] = temp_value\n    \n    traces = []\n    for genre in genres:\n        trace = go.Bar(\n            x = years,\n            y = list(temp_dict[genre].values()),\n            name=genre\n        )\n        traces.append(trace)\n    \n    return traces","1cbfca75":"data = get_traces(games_df, 'Global_Sales')\nlayout = go.Layout(\n        barmode='stack',\n        title = 'Sales change in Global',\n        xaxis=dict(\n            title='Year_of_Release'\n        ),\n        yaxis=dict(\n            title='Sales (in Millions)'\n        ),\n    \n        height=800, width=800,\n        margin=go.Margin(\n            l=100,\n            r=50,\n            b=100,\n            t=100,\n            pad=4\n        )\n    )\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","af9bde8d":"data = get_traces(games_df, 'NA_Sales')\nlayout = go.Layout(\n        barmode='stack',\n        title = 'Sales change in North America',\n        xaxis=dict(\n            title='Year'\n        ),\n        yaxis=dict(\n            title='Sales (in Millions)'\n        ),\n    \n        height=700, width=800,\n        margin=go.Margin(\n            l=100,\n            r=50,\n            b=100,\n            t=100,\n            pad=4\n        )\n    )\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","5f828150":"data = get_traces(games_df, 'EU_Sales')\nlayout = go.Layout(\n        barmode='stack',\n        title = 'Sales change in Europe',\n        xaxis=dict(\n            title='Year'\n        ),\n        yaxis=dict(\n            title='Sales (in Millions)'\n        ),\n    \n        height=700, width=800,\n        margin=go.Margin(\n            l=100,\n            r=50,\n            b=100,\n            t=100,\n            pad=4\n        )\n    )\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","46b1f5f7":"data = get_traces(games_df, 'JP_Sales')\nlayout = go.Layout(\n        barmode='stack',\n        title = 'Sales change in Japan',\n        xaxis=dict(\n            title='Year'\n        ),\n        yaxis=dict(\n            title='Sales (in Millions)'\n        ),\n    \n        height=700, width=800,\n        margin=go.Margin(\n            l=100,\n            r=50,\n            b=100,\n            t=100,\n            pad=4\n        )\n    )\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","82f5375e":"data = get_traces(games_df, 'Other_Sales')\nlayout = go.Layout(\n        barmode='stack',\n        title = 'Sales change in Other regions',\n        xaxis=dict(\n            title='Year'\n        ),\n        yaxis=dict(\n            title='Sales (in Millions)'\n        ),\n    \n        height=700, width=800,\n        margin=go.Margin(\n            l=100,\n            r=50,\n            b=100,\n            t=100,\n            pad=4\n        )\n    )\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","d6379aa3":"def get_percent_traces(df, region):\n    temp_df = df.groupby(['Year_of_Release','Genre'], axis=0).sum()[[region]]\n    df_pcts = temp_df.groupby(level=0).apply(lambda x: 100 * x \/ float(x.sum()))\n    df_pcts = df_pcts.reset_index()\n    regional_df = df_pcts[df_pcts.Year_of_Release < 2017] \n    \n    years = list(range(1996,2018))\n    \n    temp_dict = {}\n    for genre in genres:\n        temp_dict[genre] = {}\n        for year in years:\n            try:\n                temp_value = round(np.array(regional_df[(regional_df.Genre == genre) & \n                                   (regional_df.Year_of_Release == year)][region])[0],2)\n            except:\n                temp_value = 0\n            temp_dict[genre][year] = temp_value\n    \n    \n    traces = []\n    for genre in genres:\n        trace = go.Bar(\n            x = years,\n            y = list(temp_dict[genre].values()),\n            name=genre\n        )\n        traces.append(trace)\n    \n    return traces","20bcf99a":"data = get_percent_traces(games_df, 'Global_Sales')\nlayout = go.Layout(\n        barmode='stack',\n        title = 'Sales Percentage of Genres over Years in Global',\n        xaxis=dict(\n            title='Year'\n        ),\n        yaxis=dict(\n            title='Sales (in Millions)'\n        ),\n    \n        height=700, width=800,\n        margin=go.Margin(\n            l=100,\n            r=50,\n            b=100,\n            t=100,\n            pad=4\n        )\n    )\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","e4af50df":"sales_by_year = games_df.groupby('Year_of_Release', axis=0).sum().reset_index()[['Year_of_Release','NA_Sales','EU_Sales','JP_Sales','Other_Sales','Global_Sales']]\nsales_by_year.Year = sales_by_year.Year_of_Release.astype('int')\nsales_by_year.head()","00e9f913":"trace_Global = go.Scatter(\n    x = sales_by_year.Year,\n    y = sales_by_year.Global_Sales,\n    mode = 'none',\n    name = 'Global_Sales',\n    fill='tonexty',\n)\n\ntrace_NA = go.Scatter(\n    x = sales_by_year.Year,\n    y = sales_by_year.NA_Sales,\n    mode = 'none',\n    fill='tonexty',\n    name = 'NA_Sales'\n)\n\ntrace_EU = go.Scatter(\n    x = sales_by_year.Year,\n    y = sales_by_year.EU_Sales,\n    mode = 'none',\n    fill='tonexty',\n    name = 'EU_Sales'\n)\n\ntrace_JP = go.Scatter(\n    x = sales_by_year.Year,\n    y = sales_by_year.JP_Sales,\n    mode = 'none',\n    fill='tonexty',\n    name = 'JP_Sales'\n)\n\ntrace_Other = go.Scatter(\n    x = sales_by_year.Year,\n    y = sales_by_year.Other_Sales,\n    mode = 'none',\n    fill='tozeroy',\n    name = 'Other_Sales'\n)\n\n\n\nlayout = go.Layout(\n    title='Sales by Region',\n\n    xaxis=dict(\n        title='Year'\n    ),\n    yaxis=dict(\n        title='Sales (in Millions)'\n    ),\n    \n    height=600, width=800,\n    margin=go.Margin(\n        l=100,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    )\n)\n\n\nfig = go.Figure(data=[trace_Other, trace_JP, trace_EU, trace_NA, trace_Global], layout=layout)\niplot(fig)","bf4924c9":"games_df.info()","a79c571f":"games_df.head()","cff1f2a5":"descriptions = games_df.dropna(subset=['AboutText'])","73cceea8":"descriptions.head()","54c9f31c":"descriptions = descriptions.drop_duplicates()","6605c04f":"descriptions.info()","9c3844f6":"descriptions['DetailedDescrip'] = descriptions['DetailedDescrip'].str.lower()","9cda72fc":"descriptions['AboutText'] = descriptions['AboutText'].str.lower()","4b2a3d2f":"descriptions['Genre'].unique()","2ff71903":"#example, calculate the frequency of action- words in descriptions of action games\nfrom __future__ import unicode_literals\nfrom __future__ import division\nfrom textblob import TextBlob\n\naction = descriptions[descriptions.Genre == \"Action\"]\naction_freq = []\nfor review in action.AboutText:\n    review = TextBlob(review)\n    num_exciting = review.words.count(\"exciting\")\n    num_kill = review.words.count(\"kill\")\n    num_steal = review.words.count(\"steal\")\n    num_deadly = review.words.count(\"deadly\")\n    num_exhilerating = review.words.count(\"exhilerating\")\n    num_thrilling = review.words.count(\"thrilling\")\n    total_action = num_exciting+num_kill+num_steal+num_deadly+num_exhilerating+num_thrilling\n    action_freq.append(total_action)\n\nprint(sum(action_freq)\/ len(action_freq))","921234ce":"import numpy as np\ndef locate_max(list):\n    biggest = np.max(list)\n    return biggest, [index for index, element in enumerate(list) \n                      if biggest == element]","2df96378":"locate_max(action_freq)","fdc22b16":"action.AboutText.iloc[73]","63afb6a8":"def action_score(descriptions):\n    action_freq = []\n    for review in descriptions:\n        review = TextBlob(review)\n        num_exciting = review.words.count(\"exciting\")\n        num_kill = review.words.count(\"kill\")\n        num_steal = review.words.count(\"steal\")\n        num_deadly = review.words.count(\"deadly\")\n        num_exhilerating = review.words.count(\"exhilerating\")\n        num_thrilling = review.words.count(\"thrilling\")\n        total_action = num_exciting+num_kill+num_steal+num_deadly+num_exhilerating+num_thrilling\n        action_freq.append(total_action)\n    return float(sum(action_freq)\/len(action_freq))\n","e9f35dcd":"action_score(descriptions.AboutText)","1afdc825":"action_list = []\nfor genre in descriptions.Genre.unique():\n    df_genre = descriptions[descriptions.Genre == genre]\n    action = action_score(df_genre.AboutText)\n    action_list.append((genre,action))\n\n# sorting from high action to low action   \nsorted_action_list = sorted(action_list, key=lambda x: -x[1])","d1118b15":"df_action = pd.DataFrame(sorted_action_list,columns=[\"Genre\",\"action_score\"])","2a74351e":"df_action.head()","86c7a511":"#This performs very very well. \n#Shooter and action are very closely linked, the results are not surprising\nimport matplotlib.pyplot as plt\nplt.rcdefaults()\nfig, ax = plt.subplots()\ngenres = tuple(df_action.Genre.tolist())[:15]\ngenres = [TextBlob(i) for i in genres]\ny_pos = np.arange(len(genres))\nperformance = np.array(df_action.action_score)[:15]\nerror = np.random.rand(len(genres))\n\nplt.barh(y_pos, performance, align='center', alpha=0.5)\nplt.yticks(y_pos, genres)\nplt.title('Game genres by action-score')\n \nplt.show()","5e39944f":"#Let's try the same technique to see what types \n#of words are typically used to describe games which sell well\nHighseller = descriptions[descriptions.Global_Sales > np.percentile(descriptions.Global_Sales,90)]","8f509b66":"Highseller.head()","7f29b515":"sports = descriptions[descriptions.Genre == \"Sports\"]\nsports_freq = []\nfor review in sports.AboutText:\n    review = TextBlob(review)\n    num_experience = review.words.count(\"experience\")\n    num_ball = review.words.count(\"ball\")\n    num_realistic = review.words.count(\"realistic\")\n    num_latest = review.words.count(\"latest\")\n    num_team = review.words.count(\"team\")\n    num_pro = review.words.count(\"pro\")\n    total_sports = num_experience+num_ball+num_realistic+num_latest+num_team+num_pro\n    sports_freq.append(total_sports)\n\nprint(sum(sports_freq)\/ len(sports_freq))","45ed74d2":"def sports_score(descriptions):\n    sports_freq = []\n    for review in descriptions:\n        review = TextBlob(review)\n        num_experience = review.words.count(\"experience\")\n        num_ball = review.words.count(\"ball\")\n        num_realistic = review.words.count(\"realistic\")\n        num_latest = review.words.count(\"latest\")\n        num_team = review.words.count(\"team\")\n        num_pro = review.words.count(\"pro\")\n        total_sports = num_experience+num_ball+num_realistic+num_latest+num_team+num_pro\n        sports_freq.append(total_sports)\n    return float(sum(sports_freq)\/len(sports_freq))\n","d6b4787d":"sports_score(descriptions.AboutText)","0fd65679":"sports_list = []\nfor genre in descriptions.Genre.unique():\n    df_genre = descriptions[descriptions.Genre == genre]\n    sports = sports_score(df_genre.AboutText)\n    sports_list.append((genre,sports))\n\n# sorting from high sweeetness to low sweetness    \nsorted_sports_list = sorted(sports_list, key=lambda x: -x[1])","d4cced54":"df_sports = pd.DataFrame(sorted_sports_list,columns=[\"Genre\",\"sports_score\"])","9e05f6ef":"df_sports.head()","10c93070":"#This performs very very well. \n#Shooter and action are very closely linked, the results are not \n#surprising\nimport matplotlib.pyplot as plt\nplt.rcdefaults()\nfig, ax = plt.subplots()\ngenres = tuple(df_sports.Genre.tolist())[:15]\ngenres = [TextBlob(i) for i in genres]\ny_pos = np.arange(len(genres))\nperformance = np.array(df_sports.sports_score)[:15]\nerror = np.random.rand(len(genres))\n\nplt.barh(y_pos, performance, align='center', alpha=0.5)\nplt.yticks(y_pos, genres)\nplt.title('Game Genres by sports-score')\n \nplt.show()","98c245a9":"reviewed = descriptions.dropna()","e7db6583":"reviewed.info()","9312a331":"goodreviews = reviewed[reviewed.User_Score > np.percentile(reviewed.User_Score,90)]","6ec67972":"freq = []\nfor review in goodreviews.Reviews:\n    review = TextBlob(review)\n    num_best = review.words.count(\"best\")\n    num_amazing = review.words.count(\"amazing\")\n    num_fantastic = review.words.count(\"fantastic\")\n    num_great = review.words.count(\"great\")\n    num_brilliant = review.words.count(\"brilliant\")\n    num_impressive = review.words.count(\"impressive\")\n    total = num_best+num_amazing+num_fantastic+num_great+num_brilliant+num_impressive\n    freq.append(total)\n\nprint 'The number of good words given in a review of high rated games per review is:' \nprint  (sum(freq)\/ len(freq))","5ec91ec1":"freq = []\nfor review in goodreviews.Reviews:\n    review = TextBlob(review)\n    num_terrible = review.words.count(\"terrible\")\n    num_bad = review.words.count(\"bad\")\n    num_worst = review.words.count(\"worst\")\n    num_never = review.words.count(\"never\")\n    num_regret = review.words.count(\"regret\")\n    num_waste = review.words.count(\"waste\")\n    total = num_terrible+num_bad+num_worst+num_never+num_regret+num_waste\n    freq.append(total)\n\nprint 'The number of bad words given in a review of high rated games per review is:' \nprint  (sum(freq)\/ len(freq))","a1aae5c4":"badreviews = reviewed[reviewed.User_Score < np.percentile(reviewed.User_Score,10)]","aa6c9e1a":"freq = []\nfor review in badreviews.Reviews:\n    review = TextBlob(review)\n    num_best = review.words.count(\"best\")\n    num_amazing = review.words.count(\"amazing\")\n    num_fantastic = review.words.count(\"fantastic\")\n    num_great = review.words.count(\"great\")\n    num_brilliant = review.words.count(\"brilliant\")\n    num_impressive = review.words.count(\"impressive\")\n    total = num_best+num_amazing+num_fantastic+num_great+num_brilliant+num_impressive\n    freq.append(total)\n\nprint 'The number of good words given in a review of bad rated games per review is:' \nprint  (sum(freq)\/ len(freq))","bee65710":"freq = []\nfor review in badreviews.Reviews:\n    review = TextBlob(review)\n    num_terrible = review.words.count(\"terrible\")\n    num_bad = review.words.count(\"bad\")\n    num_worst = review.words.count(\"worst\")\n    num_never = review.words.count(\"never\")\n    num_regret = review.words.count(\"regret\")\n    num_waste = review.words.count(\"waste\")\n    total = num_terrible+num_bad+num_worst+num_never+num_regret+num_waste\n    freq.append(total)\n\nprint 'The number of bad words given in a review of bad rated games per review is:' \nprint  (sum(freq)\/ len(freq))","ae877679":"Actiongames  = descriptions[descriptions['Genre'].str.contains('Action')]","b14c1453":"from subprocess import check_output\nfrom wordcloud import WordCloud, STOPWORDS\nmpl.rcParams['font.size']=16                #10 \nmpl.rcParams['savefig.dpi']=200             #72 \nmpl.rcParams['figure.subplot.bottom']=.1 \n\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=stopwords,\n                          max_words=200,\n                          max_font_size=40, \n                          random_state=42\n                         ).generate(str(Actiongames['AboutText']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()\n","1286cfb3":"from subprocess import check_output\nfrom wordcloud import WordCloud, STOPWORDS\nmpl.rcParams['font.size']=12                #10 \nmpl.rcParams['savefig.dpi']=100             #72 \nmpl.rcParams['figure.subplot.bottom']=.1 \n\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=stopwords,\n                          max_words=200,\n                          max_font_size=40, \n                          random_state=42\n                         ).generate(str(Actiongames['DetailedDescrip']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()\n","e6ae6b01":"Shootergames = descriptions[descriptions['Genre'].str.contains('Shooter')]","0efebb48":"from subprocess import check_output\nfrom wordcloud import WordCloud, STOPWORDS\nmpl.rcParams['font.size']=12                #10 \nmpl.rcParams['savefig.dpi']=100             #72 \nmpl.rcParams['figure.subplot.bottom']=.1 \n\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=stopwords,\n                          max_words=200,\n                          max_font_size=40, \n                          random_state=42\n                         ).generate(str(Shootergames['DetailedDescrip']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()\n","5fc8aa31":"from subprocess import check_output\nfrom wordcloud import WordCloud, STOPWORDS\nmpl.rcParams['font.size']=12                #10 \nmpl.rcParams['savefig.dpi']=100             #72 \nmpl.rcParams['figure.subplot.bottom']=.1 \n\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=stopwords,\n                          max_words=200,\n                          max_font_size=40, \n                          random_state=42\n                         ).generate(str(Shootergames['AboutText']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()\n","249ae8c5":"Sportsgames  = descriptions[descriptions['Genre'].str.contains('Sports')]","1418e27a":"from subprocess import check_output\nfrom wordcloud import WordCloud, STOPWORDS\nmpl.rcParams['font.size']=12                #10 \nmpl.rcParams['savefig.dpi']=100             #72 \nmpl.rcParams['figure.subplot.bottom']=.1 \n\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=stopwords,\n                          max_words=200,\n                          max_font_size=40, \n                          random_state=42\n                         ).generate(str(Sportsgames['AboutText']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()\n","ac6656a4":"from subprocess import check_output\nfrom wordcloud import WordCloud, STOPWORDS\nmpl.rcParams['font.size']=12                #10 \nmpl.rcParams['savefig.dpi']=100             #72 \nmpl.rcParams['figure.subplot.bottom']=.1 \n\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=stopwords,\n                          max_words=200,\n                          max_font_size=40, \n                          random_state=42\n                         ).generate(str(Sportsgames['DetailedDescrip']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","01cf67dd":"Highseller = descriptions[descriptions.Global_Sales > np.percentile(descriptions.Global_Sales,90)]","620b167f":"from subprocess import check_output\nfrom wordcloud import WordCloud, STOPWORDS\nmpl.rcParams['font.size']=12                #10 \nmpl.rcParams['savefig.dpi']=100             #72 \nmpl.rcParams['figure.subplot.bottom']=.1 \n\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=stopwords,\n                          max_words=300,\n                          max_font_size=40, \n                          random_state=42\n                         ).generate(str(Highseller['DetailedDescrip']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","c6bee491":"from subprocess import check_output\nfrom wordcloud import WordCloud, STOPWORDS\nmpl.rcParams['font.size']=12                #10 \nmpl.rcParams['savefig.dpi']=100             #72 \nmpl.rcParams['figure.subplot.bottom']=.1 \n\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=stopwords,\n                          max_words=200,\n                          max_font_size=40, \n                          random_state=42\n                         ).generate(str(Highseller['AboutText']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","d41b17e6":"Lowsellers = descriptions[descriptions.Global_Sales < np.percentile(descriptions.Global_Sales,10)]","ef0b9a1b":"from subprocess import check_output\nfrom wordcloud import WordCloud, STOPWORDS\nmpl.rcParams['font.size']=12                #10 \nmpl.rcParams['savefig.dpi']=100             #72 \nmpl.rcParams['figure.subplot.bottom']=.1 \n\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=stopwords,\n                          max_words=200,\n                          max_font_size=40, \n                          random_state=42\n                         ).generate(str(Lowsellers['AboutText']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","0ea78c74":"from subprocess import check_output\nfrom wordcloud import WordCloud, STOPWORDS\nmpl.rcParams['font.size']=12                #10 \nmpl.rcParams['savefig.dpi']=100             #72 \nmpl.rcParams['figure.subplot.bottom']=.1 \n\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=stopwords,\n                          max_words=300,\n                          max_font_size=40, \n                          random_state=42\n                         ).generate(str(Lowsellers['DetailedDescrip']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","9895b17d":"from subprocess import check_output\nfrom wordcloud import WordCloud, STOPWORDS\nmpl.rcParams['font.size']=12                #10 \nmpl.rcParams['savefig.dpi']=100             #72 \nmpl.rcParams['figure.subplot.bottom']=.1 \n\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=stopwords,\n                          max_words=300,\n                          max_font_size=40, \n                          random_state=42\n                         ).generate(str(Lowsellers['Reviews']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()","71c97855":"games_df.head()","6c76bc25":"games_df.drop(['AboutText'] ,inplace =True, axis =1)\ngames_df.drop(['ShortDescrip'] ,inplace =True, axis =1)\ngames_df.drop(['DetailedDescrip'] ,inplace =True, axis =1)\ngames_df.drop(['Reviews'] ,inplace =True, axis =1)\ngames_df['PriceFinal'].fillna((games_df['PriceFinal'].mean()), inplace=True)","1fbd44b0":"games_df.head()","33df63fe":"df = games_df.copy()","781ff314":"df['Platform'] = df['Platform'].astype(object)","366899d1":"cols = ['Platform', 'Genre', 'Publisher', 'Rating']\nfor col in cols:\n    uniques = df[col].value_counts().keys()\n    uniques_dict = {}\n    ct = 0\n    for i in uniques:\n        uniques_dict[i] = ct\n        ct += 1\n\n    for k, v in uniques_dict.items():\n        df.loc[df[col] == k, col] = v","2d9aac00":"df1 = df[['Platform','Genre','Publisher','Year_of_Release','Critic_Score','User_Score','Global_Sales', 'PriceFinal']]\ndf1 = df1.dropna().reset_index(drop=True)\ndf1 = df1.astype('float64')","5b81073a":"mask = np.zeros_like(df1.corr())\nmask[np.triu_indices_from(mask)] = True\ncmap = sns.diverging_palette(730, 300, sep=20, as_cmap=True, s=85, l=15, n=20) # note: 680, 350\/470\nwith sns.axes_style(\"white\"):\n    fig, ax = plt.subplots(1,1, figsize=(15,8))\n    ax = sns.heatmap(df1.corr(), mask=mask, vmax=0.2, square=True, annot=True, fmt=\".3f\", cmap=cmap)","db8fc2ca":"games_df.head()","36ba560b":"fig, ax = plt.subplots(1,1, figsize=(12,5))\nsns.regplot(x=\"Critic_Score\", y=\"Global_Sales\", data=df1, ci=None, color=\"#75556c\", x_jitter=.02).set(ylim=(0, 17.5))","d7674546":"fig, ax = plt.subplots(1,1, figsize=(12,5))\nsns.regplot(x=\"Critic_Score\", y=\"Global_Sales\", data=df1.loc[df1.Year_of_Release >= 2014],\n            truncate=True, x_bins=15, color=\"#75556c\").set(ylim=(0,4), xlim=(50, 95))","40633d2b":"(\"The skewness of Global_Sales is {}\".format(games_df['Global_Sales'].skew()))","6142ce6c":"(\"The skewness of NA_Sales {}\".format(games_df['NA_Sales'].skew()))","d4a64314":"(\"The skewness of EU_Sales {}\".format(games_df['EU_Sales'].skew()))","38a11eb4":"(\"The skewness of Other_Sales {}\".format(games_df['Other_Sales'].skew()))","f6b68d27":"(\"The skewness of User_Score {}\".format(games_df['User_Score'].skew()))","23d57ebd":"(\"The skewness of Critic_Score {}\".format(games_df['Critic_Score'].skew()))","9203114f":"plt.hist(games_df['Global_Sales'], bins=100)\nplt.show()","ae26efc3":"games_df.head()","5e6c4dd2":"genrelist = ['Action','Adventure','Fighting','Platform','Puzzle','Sports','Racing','Role_Playing','Shooter','Strategy']\nsubdata = games_df[games_df['Genre'].isin(genrelist)]\nsubdata = subdata.dropna()","e9c46d2c":"from sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\nlabel_encoder = label_encoder.fit(subdata['Genre'])\nlabel_encoded_y = label_encoder.transform(subdata['Genre'])\nsubdata['encoded_genre'] = label_encoded_y\nsubdata.head()","34c9db7c":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf = TfidfVectorizer(\n    min_df=5, max_features=100, strip_accents='unicode',lowercase =True,\n    analyzer='word', token_pattern=r'\\w+', use_idf=True, \n    smooth_idf=True, sublinear_tf=True, stop_words = 'english').fit(subdata[\"Name\"])","8a155fd2":"features = tfidf.get_feature_names()","f8d97a1a":"features","9e90499e":"X_tfidf_text = tfidf.transform(subdata[\"Name\"])\nsubdata_2 = pd.DataFrame(X_tfidf_text.toarray())\nsubdata = subdata.reset_index()\nsubdata_2['encoded_genre'] = subdata['encoded_genre']\n#Also adding variety for better readibility\nsubdata_2['Genre'] = subdata['Genre']","8c785de8":"from sklearn.cross_validation import train_test_split\nseed = 7\n\n#Split into train and test\ntest_size = 0.2\ny = subdata_2['encoded_genre']\nX = subdata_2.drop(['encoded_genre','Genre'], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n# fit model no training data\nimport xgboost as xgb\nclf = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05)","c90e2d0b":"clf.fit(X_train, y_train)","0e7c7ce6":"y_pred = clf.predict(X_test)","f3c4c5be":"from sklearn.metrics import accuracy_score\n\naccuracy = accuracy_score(y_pred, y_test)\n\"Accuracy is: %.2f%%\" % (accuracy * 100.0)","c17c06dc":"games_df.head()","960b9d18":"dfa = games_df\ndfa = dfa.copy()\ndfa.head()","aca299c9":"dfb = dfa[['Name','Platform','Genre','Publisher','Year_of_Release','Critic_Score','Global_Sales']]\ndfb = dfb.dropna().reset_index(drop=True)\ndf2 = dfb[['Platform','Genre','Publisher','Year_of_Release','Critic_Score','Global_Sales']]\ndf2['Hit'] = df2['Global_Sales']\ndf2.drop('Global_Sales', axis=1, inplace=True)","bfe2347d":"def hit(sales):\n    if sales >= 1:\n        return 1\n    else:\n        return 0\n\ndf2['Hit'] = df2['Hit'].apply(lambda x: hit(x))","799dd2df":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\nfrom sklearn import svm","54340cd4":"df2[:5]","0b7e0c83":"df_copy = pd.get_dummies(df2)","6634748b":"df_copy[:5]","232b224a":"df3 = df_copy\ny = df3['Hit'].values\ndf3 = df3.drop(['Hit'],axis=1)\nX = df3.values","9b900545":"Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.50, random_state=2)","c32e05de":"radm = RandomForestClassifier(random_state=2).fit(Xtrain, ytrain)\ny_val_1 = radm.predict_proba(Xtest)\nprint(\"Validation accuracy: \", sum(pd.DataFrame(y_val_1).idxmax(axis=1).values\n                                   == ytest)\/len(ytest))","7d98f25a":"log_reg = LogisticRegression().fit(Xtrain, ytrain)\ny_val_2 = log_reg.predict_proba(Xtest)\nprint(\"Validation accuracy: \", sum(pd.DataFrame(y_val_2).idxmax(axis=1).values\n                                   == ytest)\/len(ytest))","acbf3e36":"all_predictions = log_reg.predict(Xtest)\nprint(classification_report(ytest, all_predictions))","295f5aec":"fig, ax = plt.subplots(figsize=(3.5,2.5))\nsns.heatmap(confusion_matrix(ytest, all_predictions), annot=True, linewidths=.5, ax=ax, fmt=\"d\").set(xlabel='Predicted Value', ylabel='Expected Value')\n#'Training Set Confusion Matrix'","35db4ca4":"indices = np.argsort(radm.feature_importances_)[::-1]\n\n# Print the feature ranking\nprint('Feature ranking (top 10):')\n\nfor f in range(10):\n    print('%d. feature %d %s (%f)' % (f+1 , indices[f], df3.columns[indices[f]],\n                                      radm.feature_importances_[indices[f]]))","209b6e10":"not_hit_copy = df_copy[df_copy['Hit'] == 0]","928778b9":"df4 = not_hit_copy\ny = df4['Hit'].values\ndf4 = df4.drop(['Hit'],axis=1)\nX = df4.values","854d2ad5":"df4.head()","6cad56f1":"pred = log_reg.predict_proba(X)","34a9e184":"dfb.head()","9115a2fb":"dfb = dfb[dfb['Global_Sales'] < 1]","5d50b443":"dfb['Hit_Probability'] = pred[:,1]","2e1fcd6a":"dfb = dfb[dfb['Year_of_Release'] == 2016]\ndfb.sort_values(['Hit_Probability'], ascending=[False], inplace=True)\ndfb = dfb[['Name', 'Platform', 'Hit_Probability']]","3e503def":"dfb[:100].reset_index(drop=True)","3a00fd9f":"dfb[100:-1].reset_index(drop=True)","84d65b0a":"gamespred = games_df.copy()","acf6aa59":"gamespred.dtypes","bec2239b":"gamespred.drop(['NA_Sales'] ,inplace =True, axis =1)\ngamespred.drop(['EU_Sales'] ,inplace =True, axis =1)\ngamespred.drop(['JP_Sales'] ,inplace =True, axis =1)\ngamespred.drop(['Other_Sales'] ,inplace =True, axis =1)\ngamespred.drop(['Name'] ,inplace =True, axis =1)","b96d83de":"gamespred['Platform'] = gamespred['Platform'].astype(object)","97cc8a03":"gamespred['Global_Sales'] = np.log1p(gamespred['Global_Sales'])","737070ed":"gamespred['Global_Sales'].skew()","ce998a48":"gamespred['Global_Sales'] = np.log1p(gamespred['Global_Sales'])\ngamespred['Global_Sales'].skew()","7226239a":"gamespred.head()","c1b174de":"gamespred = gamespred.dropna().reset_index(drop=True)","10e30854":"gamespred.head()","c8d0e34e":"gamespred.dtypes","5684d4be":"dummy_df = pd.get_dummies(gamespred)","b2a87db4":"dummy_df = dummy_df.reset_index()","942ff352":"dummy_df.rename(columns={'index':'Id'}, inplace=True)","e2757d87":"dummy_df.head()","ac3468d6":"from numpy import exp \ndef gaussian(x, amp, cen, wid): \n    return amp * exp(-(x-cen)**2 \/ wid)","3683ae37":"import lmfit\nfrom lmfit import Model \ngmodel = Model(gaussian)\n\ngmodel.param_names\ngmodel.independent_vars\n\nparams = gmodel.make_params(cen=5, amp = 200, wid =1)","fe8ee6d5":"gmodel.set_param_hint('a', value=1.0)\ngmodel.set_param_hint('b', value=0.3, min=0, max=1.0)","6eb4b68b":"y = dummy_df.User_Score\nx = dummy_df.Critic_Score","ad73e0aa":"result = gmodel.fit(y, params, x=x, amp=5,cen=5,wid=1)","187f90ec":"print(result.fit_report())","40d52323":"plt.plot(x, y,         'bo')\nplt.plot(x, result.init_fit, 'k--')\nplt.plot(x, result.best_fit, 'r-')\nplt.title('correlation between LM fit Critic and user score')\nplt.show()","5991cbb9":"from numpy import exp \ndef gaussian(x, amp, cen, wid): \n    return amp * exp(-(x-cen)**2 \/ wid)","2d7c007b":"import lmfit\nfrom lmfit import Model \ngmodel = Model(gaussian)\n\ngmodel.param_names\ngmodel.independent_vars\n\nparams = gmodel.make_params(cen=5, amp = 200, wid =1)","049b510f":"gmodel.set_param_hint('a', value=1.0)\ngmodel.set_param_hint('b', value=0.3, min=0, max=1.0)","b0b7ddce":"y = dummy_df.Global_Sales\nx = dummy_df.User_Score","a7a0bd67":"result = gmodel.fit(y, params, x=x, amp=5,cen=5,wid=1)","38e0fda7":"print(result.fit_report())","5b82590a":"plt.plot(x, y,         'bo')\nplt.plot(x, result.init_fit, 'k--')\nplt.plot(x, result.best_fit, 'r-')\nplt.show()","486a9b05":"gmodel.set_param_hint('a', value=1.0)\ngmodel.set_param_hint('b', value=0.3, min=0, max=1.0)","8838000d":"y = dummy_df.Global_Sales\nx = dummy_df.Critic_Score","e389df45":"print(result.fit_report())","b355a543":"plt.plot(x, y,         'bo')\nplt.plot(x, result.init_fit, 'k--')\nplt.plot(x, result.best_fit, 'r-')\nplt.show()","8f79087d":"from sklearn.linear_model import LinearRegression\nX = dummy_df.drop('Global_Sales', axis = 1)\n\nlm = LinearRegression()\nlm","45ded2ff":"lm.fit(X, dummy_df.Global_Sales)","40f9334f":"lm.intercept_","da4a2962":"len(lm.coef_)","ad352626":"coeffs = pd.DataFrame(zip(X.columns, lm.coef_), columns = ['features', 'estimatedCoefficients'])","1a7c9311":"coeffs.sort_values('estimatedCoefficients')","82e89e2e":"lm.predict(X)[0:5]","cea67eb0":"plt.scatter(dummy_df.Global_Sales, lm.predict(X))\n#plt.ylabel(\"Predicted sales\")\n#plt.xlabel(\"Real sales\")\nplt.title(\"sales vs predicted sales\")\nplt.show()\n","6c32d862":"lm.score(X,y)","46a493a4":"mseFull = np.mean((dummy_df.Global_Sales - lm.predict(X)) **2)\nmseFull\n# this is a good mean squared error, showing that this \n#is a very good predictor of future prices. ","7ae87d21":"dummy_df.head()","fd13fbf9":"from sklearn.linear_model import LinearRegression\nX = dummy_df.drop('Critic_Score', axis = 1)\n\nlm = LinearRegression()\nlm","50e41fbc":"lm.fit(X, dummy_df.Critic_Score)","3a2ea62e":"lm.intercept_","e17e4951":"len(lm.coef_)","e94b1575":"coeffs = pd.DataFrame(zip(X.columns, lm.coef_), columns = ['features', 'estimatedCoefficients'])","a9f96d99":"coeffs.sort_values('estimatedCoefficients')","179d813c":"lm.predict(X)[0:5]","9d595c0e":"plt.scatter(dummy_df.Critic_Score, lm.predict(X))\n#plt.ylabel(\"Predicted sales\")\n#plt.xlabel(\"Real sales\")\nplt.title(\"Critic_Score vs predicted Critic_Score\")\nplt.show()\n","6c60b3c3":"mseFull = np.mean((dummy_df.Critic_Score - lm.predict(X)) **2)\nmseFull\n# this is a good mean squared error, showing that this \n#is a very good predictor of future prices. ","e1165600":"from sklearn.cross_validation import train_test_split\nseed = 7\n\n#Split into train and test\ntest_size = 0.2\n\nX = dummy_df.drop(['Global_Sales'], axis=1)\n\nX_train = X[:X.shape[0]]\nX_test = X\ny = dummy_df['Global_Sales']\n\n# fit model no training data","a33324a5":"from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\nfrom sklearn.model_selection import cross_val_score\n\ndef rmse_cv(model):\n    rmse= np.sqrt(-cross_val_score(model, X_train, y, scoring=\"neg_mean_squared_error\", cv = 5))\n    return(rmse)","d80f99b2":"model_ridge = Ridge()","58db9fdf":"alphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]\ncv_ridge = [rmse_cv(Ridge(alpha = alpha)).mean() \n            for alpha in alphas]","a6a99c39":"cv_ridge = pd.Series(cv_ridge, index = alphas)\ncv_ridge.plot(title = \"Validation - Just Do It\")\n#plt.xlabel(\"alpha\")\n#plt.ylabel(\"rmse\")","ce427d14":"cv_ridge.min()","0610b289":"model_lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005]).fit(X_train, y)","f67c23f8":"rmse_cv(model_lasso).mean()","628475a8":"coef = pd.Series(model_lasso.coef_, index = X_train.columns)","27222187":"(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")","ce7f81f2":"imp_coef = pd.concat([coef.sort_values().head(10),\n                     coef.sort_values().tail(10)])","7a9ed79d":"import matplotlib\nmatplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\nimp_coef.plot(kind = \"barh\")\nplt.title(\"Coefficients in the Lasso Model\")","42ea4f24":"#let's look at the residuals as well:\nmatplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n\npreds = pd.DataFrame({\"preds\":model_lasso.predict(X_train), \"true\":y})\npreds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\npreds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")","ffd4929a":"import xgboost as xgb","f9da6af0":"dtrain = xgb.DMatrix(X_train, label = y)\ndtest = xgb.DMatrix(X_test)\n\nparams = {\"max_depth\":2, \"eta\":0.1}\nmodel = xgb.cv(params, dtrain,  num_boost_round=500, early_stopping_rounds=100)","3d50eeae":"model.loc[30:,[\"test-rmse-mean\", \"train-rmse-mean\"]].plot()","58508a75":"model_xgb = xgb.XGBRegressor(n_estimators=360, max_depth=2, learning_rate=0.1) #the params were tuned using xgb.cv\nprint(model_xgb.fit(X_train, y))","9bbb22cd":"rmse_cv(model_xgb).mean()","47dc85d7":"xgb_preds = np.expm1(model_xgb.predict(X_test))\nlasso_preds = np.expm1(model_lasso.predict(X_test))","394e3baf":"predictions = pd.DataFrame({\"xgb\":xgb_preds, \"lasso\":lasso_preds})\npredictions.plot(x = \"xgb\", y = \"lasso\", kind = \"scatter\")","622a28a5":"preds = xgb_preds","75c94490":"solution1 = pd.DataFrame({\"id\":dummy_df.Id, \"Global_Sales\":dummy_df.Global_Sales, \"Pred_Sales\":preds })","a486f905":"solution1","a463efb6":"preds = lasso_preds","91fbff02":"solution2 = pd.DataFrame({\"id\":dummy_df.Id, \"Global_Sales\":dummy_df.Global_Sales, \"Pred_Sales\":preds })","25754471":"solution2","79c7c7b4":"preds = 0.7*lasso_preds + 0.3*xgb_preds","fc849313":"solution = pd.DataFrame({\"id\":dummy_df.Id, \"Global_Sales\":dummy_df.Global_Sales, \"Pred_Sales\":preds })","3c76c991":"solution","6f35ecc1":"preds = 0.85*lasso_preds + 0.15*xgb_preds","576d4dbf":"solution3 = pd.DataFrame({\"id\":dummy_df.Id, \"Global_Sales\":dummy_df.Global_Sales, \"Pred_Sales\":preds })","fd64bf22":"solution3","ac6bfb60":"dummy_df.head()","dd132fb8":"relevant_games2 = dummy_df[dummy_df.Year_of_Release.isin(relevant_years)]","3f0eb797":"relevant_games2.head()","58749e05":"from sklearn.linear_model import LinearRegression\nX = relevant_games2.drop('Global_Sales', axis = 1)\n\nlm = LinearRegression()\nlm","9f63c8f5":"lm.fit(X, relevant_games2.Global_Sales)","fa3e6f2c":"lm.intercept_","908079a6":"len(lm.coef_)","847b6e6a":"coeffs = pd.DataFrame(zip(X.columns, lm.coef_), columns = ['features', 'estimatedCoefficients'])","abf16a69":"coeffs.sort_values('estimatedCoefficients', ascending =True)","e287cfbf":"lm.predict(X)[0:5]","456bd8b9":"plt.scatter(relevant_games2.Global_Sales, lm.predict(X))\n#plt.ylabel(\"Predicted sales\")\n#plt.xlabel(\"Real sales\")\nplt.title(\"Price vs predicted price\")\nplt.show()\n","73cf80fb":"mseFull = np.mean((relevant_games2.Global_Sales - lm.predict(X)) **2)\nmseFull\n# this is a good mean squared error, showing that this \n#is a very good predictor of future prices. ","d0d7655e":"from sklearn.cross_validation import train_test_split\nseed = 7\n\n#Split into train and test\ntest_size = 0.2\n\nX = relevant_games2.drop(['Global_Sales'], axis=1)\n\nX_train = X[:X.shape[0]]\nX_test = X\ny = relevant_games2['Global_Sales']\n\n# fit model no training data","4cc53c20":"from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\nfrom sklearn.model_selection import cross_val_score\n\ndef rmse_cv(model):\n    rmse= np.sqrt(-cross_val_score(model, X_train, y, scoring=\"neg_mean_squared_error\", cv = 5))\n    return(rmse)","2e90ee59":"model_ridge = Ridge()","200960cf":"alphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]\ncv_ridge = [rmse_cv(Ridge(alpha = alpha)).mean() \n            for alpha in alphas]","0cf636e1":"cv_ridge = pd.Series(cv_ridge, index = alphas)\ncv_ridge.plot(title = \"Validation - Just Do It\")\n#plt.xlabel(\"alpha\")\n#plt.ylabel(\"rmse\")","eda28d2d":"cv_ridge.min()","0566ece3":"model_lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005]).fit(X_train, y)","f72cb2d1":"rmse_cv(model_lasso).mean()","84e8731a":"coef = pd.Series(model_lasso.coef_, index = X_train.columns)","d0c6ed62":"(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")","bc23059a":"imp_coef = pd.concat([coef.sort_values().head(15),\n                     coef.sort_values().tail(15)])","143174e7":"import matplotlib\nmatplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\nimp_coef.plot(kind = \"barh\")\nplt.title(\"Coefficients in the Lasso Model\")","1862faaf":"As you can see out sales figure are skewed horribly, this needs to be considered when using machine learning, or predicting future values.\nMost machine learning techniques assume normally skewed data, as a result of this before we undertake any machine learning we should deskew the data so it increases the accuracy of the results. \nI will attempt to use boxcox as it will most accurately unskew the data","3c7d9cf0":"Setting the columns up so that they can be changed to keys later for the sake of machine learning. ","8fcf05d2":"# Machine learning techniques","355f09a5":"# LMfit","f1849012":"From here will we use linear regression to see which coefficents it will come up with which will most openly impact Global_Sales.","3bce3965":"The linear regression parameters given are surprising, however seeing there price vs predicted price they are somewhat accurate. \nPast publisher it recommends: \nPs4, shooter, adventure and also recommends smaller publisher showing good things for the small games CEO. ","66c8b265":"As we can see here, none of the genres really have a great normal distribution, there are significant amounts of outliers skewing our visualisation, in order to see which games on average sell the best, we should analyse without the outliers. \n\nHowever, from this I can draw that action games DO rely on the genre's big sellers, i.e. COD and other big sellers they don't have the consistently high sellers which other genres do as we can see their normal distribution is no where near as good as Platform, Racing, Shooter and Sports. Meaning despite it being largely the best selling genre it may not be important to target games to it unless you expect it to catch on hugely. ","c44418eb":"The most accurate model is a mixture of the xgb model and the lasso model gives an almost 10% accurate depication of sales, meaning it could predict future sales given the parameters with good accuracy. ","d13060ed":"# Further Models\n\nNow we are going to use regularized linear regression models from the scikit learn module. I'm going to try both l_1(Lasso) and l_2(Ridge) regularization. I'll also define a function that returns the cross-validation rmse error so we can evaluate our models and pick the best tuning par.\nCredit: https:\/\/www.kaggle.com\/apapiu\/regularized-linear-models","934426ad":"The first result is surprising, games with low user score have even higher rate of words which are very positive about the game. Suggesting that reviews depend on the user and in order to get an accurate user opinion we must have a large array of reviews and an average score. \nThe second result is less so confusing as it shows what we expect in that low scoring games receive a high amount of bad words to describe them. In contrast to the 0 words to describe high rated games. ","9fd747a1":"# Correlation between Columns \nCredit: https:\/\/inclass.kaggle.com\/ignacioch\/predicting-vg-hits-1-million-sales-with-lr-rfc","869896f5":"For my visualisation and my interpretation of the data, for the sake of my client we are going to work to provide analysis from the start of the dataset but also shrink the dataset down and analyse trends the start of the release of the next generation consoles as that is the most relevant data. This is important as redundant consoles potentially aren't worth analysing unless there is an overall picture provided. I.e. the N64 etc.\nCredit to: \n - https:\/\/www.kaggle.com\/jiehu15\/eda-by-plotly-on-game-sales-dataset","d6293dcc":"The average score overall is 0.43, significantly less than the score for just action games, showing it is a good signifier for what genre a game is. ","7978d69b":"This means squared error shows that these parameters are accurate for the linear regression and the score is excellent meaning the coefficiencts provided should be relatively accurate. ","5ac58409":"As we can see here, since 1996 the most publisher game is from the Action genre. \nMore important however, is the fact that from 2014-2016 the % of action releases grew by a large amount and they are now a main part of the market. This suggests: \n- Action games are the most popular releases but; \n- Action games are also the most crowded market.","942abde2":"Checking for outliers in terms of years released. For me, due to the fact this information is for a modern day game company, some of the much older data, is smaller and possibly much less relevant.\nAs a result of this I will filter some of the much more dated years out.","3e89ef4e":"From the above diagrams we can see that the bigger publishers i.e. EA, Activision, Nintendo etc are the highest sellers in the years of 2014-2016. \n\nIt is important to note however they put out the most amount of games and as a result these may not accurately reflect how many sales per game they have as a result I will visualise this below.","ee8abaf0":"# Merging the sales and the steam dataset.\nDespite not being potentially as good as the amazon data I have failed to successfully scrape the information from it.\n\nAs a result I will work from the game sales and steam reviews dataframes. \n\nThese will be merged together with the sales dataframe being the main focus due to the fact it has more useful and analysable data. ","30a3cb68":"# Machine learning techniques","084f79a3":"# - Using the steam dataframe to utilise with wordcloud which words usually describe genres and best sellers. Etc.\n\n- Credit to: https:\/\/www.kaggle.com\/rosado\/sentiment-analysis-text-mining","b2f65eb9":"From the documentation of this each column means the following: QueryID - (Integer) The original ID in idlist.csv\n\n- ResponseID - (Integer) The ID returned in the Steam response (should equal QueryID)\n\n- QueryName - (Text) The original name in idlist.csv\n\n- ResponseName - (Text) The name returned in the Steam response (should equal QueryName)\n\n- ReleaseDate - (Text) Appears to the be the initial release date for the game\n\n- RequiredAge - (Integer) list named required_age in JSON\n\n- DemoCount - (TextualCount) list named demos in JSON\n\n- DeveloperCount - (TextualCount) list named developers in JSON\n\n- DLCCount - (TextualCount) list named dlc in JSON\n\n- Metacritic - (Integer) numeric score from metacritic object in JSON\n\n- MovieCount - (TextualCount) list named movies in JSON (used object id for unique count)\n\n- PackageCount - (TextualCount) list named packages in JSON\n\n- RecommendationCount - (Integer) from recommendations.total in JSON\n\n- PublisherCount - (TextualCount) list named publishers in JSON\n\n- ScreenshotCount - (TextualCount) list named screenshots in JSON\n\n- AchievementCount - (Integer) achievements.total in JSON\n\n- AchievementHighlightedCount - (TextualCount) for achievements.highlighted in JSON\n\n- ControllerSupport - (Boolean) True if controller_support was full\n\n- IsFree - (Boolean) is_free in JSON\n\n- FreeVerAvail - (Boolean) True if is_free_license is True in package_groups list\n\n- PurchaseAvail - (Boolean) True if price_in_cents_with_discount greater than 0 in package_groups list\n\n- SubscriptionAvail - (Boolean) True if is_recurring_subscription is True in package_groups\n\n- PlatformWindows - (Boolean) True if platforms.windows is True\n\n- PlatformLinux - (Boolean) True if platforms.linux is True\n\n- PlatformMac - (Boolean) True if platforms.mac is True\n\n- PCReqsHaveMin - (Boolean) True if pc_requirements.minimum is non-empty string\n\n- PCReqsHaveRec - (Boolean) True if pc_requirements.recommended is non-empty string\n\n- LinuxReqsHaveMin - (Boolean) True if linux_requirements.minimum is non-empty string\n\n- LinuxReqsHaveRec - (Boolean) True if linux_requirements.recommended is non-empty string\n\n- MacReqsHaveMin - (Boolean) True if mac_requirements.minimum is non-empty string\n\n- MacReqsHaveRec - (Boolean) True if mac_requirements.recommended is non-empty string\n\n- CategorySinglePlayer - (Boolean) True if for any i, categories[i].description is \"single-player\"\n\n- CategoryMultiplayer - (Boolean) True if for any i, categories[i].description is one of: \"cross-platform multiplayer\", \"local multi-player\", \"multi-player\", \"online multi-player\", \"shared\/split screen\"\n\n- CategoryCoop - (Boolean) True if for any i, categories[i].description is one of: \"co-op\", \"local co-op\", \"online co-op\"\n\n- CategoryMMO - (Boolean) True if for any i, categories[i].description is \"mmo\"\n\n- CategoryInAppPurchase - (Boolean) True if for any i, categories[i].description is \"in-app purchases\"\n\n- CategoryIncludeSrcSDK - (Boolean) True if for any i, categories[i].description is \"includes source sdk\"\n\n- CategoryIncludeLevelEditor - (Boolean) True if for any i, categories[i].description is \"includes level editor\"\n\n- CategoryVRSupport - (Boolean) True if for any i, categories[i].description is \"vr support\"\n\n- GenreIsNonGame - (Boolean) True if for any i, genres[i].description is one of: \"utilities\", \"design & illustration\", \"animation & modeling\", \"software training\", \"education\", \"audio production\", \"video production\", \"web publishing\", \"photo editing\", \"accounting\"\n\n- GenreIsIndie - (Boolean) True if for any i, genres[i].description is \"indie\"\n\n- GenreIsAction - (Boolean) True if for any i, genres[i].description is \"action\"\n\n- GenreIsAdventure - (Boolean) True if for any i, genres[i].description is \"adventure\"\n\n- GenreIsCasual - (Boolean) True if for any i, genres[i].description is \"casual\"\n\n- GenreIsStrategy - (Boolean) True if for any i, genres[i].description is \"strategy\"\n\n- GenreIsRPG - (Boolean) True if for any i, genres[i].description is \"rpg\"\n\n- GenreIsSimulation - (Boolean) True if for any i, genres[i].description is \"simulation\"\n\n- GenreIsEarlyAccess - (Boolean) True if for any i, genres[i].description is \"early access\"\n\n- GenreIsFreeToPlay - (Boolean) True if for any i, genres[i].description is \"free to play\"\n\n- GenreIsSports - (Boolean) True if for any i, genres[i].description is \"sports\"\n\n- GenreIsRacing - (Boolean) True if for any i, genres[i].description is \"racing\"\n\n- GenreIsMassivelyMultiplayer - (Boolean) True if for any i, genres[i].description is \"massively multiplayer\"\n\n- PriceCurrency - (Text) price_overview.currency in JSON\n\n- PriceInitial - (Float) price_overview.initial in JSON, divided by 100.0 to converts cents to currency\n\n- PriceFinal - (Float) price_overview.final in JSON, divided by 100.0 to converts cents to currency\n\n- SteamSpyOwners - (steamspy.com) total owners, which includes free weekend trials and other possibly spurious numbers.\n\n- SteamSpyOwnersVariance - (steamspy.com) total owners, which includes free weekend trials and other possibly spurious numbers. Note that this is not technically variance: according to steamspy.com, \"the real number... lies somewhere on... [value +\/- variance]\"\n\n- SteamSpyPlayersEstimate - (steamspy.com) best estimate of total number of people who have played the game since March 2009\n\n- SteamSpyPlayersVariance - (steamspy.com) errors bounds on SteamSpyPlayersEstimate. Note that this is not technically variance: according to steamspy.com, \"the real number... lies somewhere on... [value +\/- variance]\"\n\n- SupportEmail - (Textual) support_info.email in JSON\n\n- SupportURL - (Textual) support_info.url in JSON\n\n- AboutText - (Textual) about_the_game in JSON\n\n- Background - (Textual) background in JSON\n\n- ShortDescrip - (Textual) short_description in JSON\n\n- DetailedDescrip - (Textual) detailed_description in JSON\n\n- DRMNotice - (Textual) drm_notice in JSON\n\n- ExtUserAcctNotice - (Textual) ext_user_account_notice in JSON\n\n- HeaderImage - (Textual) header_image in JSON\n\n- LegalNotice - (Textual) legal_notice in JSON\n\n- Reviews - (Textual) reviews in JSON\n\n- SupportedLanguages - (Textual) supported_languages in JSON\n\n- Website - (Textual) website in JSON\n\n- PCMinReqsText - (Textual) text of pc_requirements.minimum\n\n- PCRecReqsText - (Textual) text of pc_requirements.recommended\n\n- LinuxMinReqsText - (Textual) text of linux_requirements.minimum\n\n- LinuxRecReqsText - (Textual) text of linux_requirements.recommended\n\n- MacMinReqsText - (Textual) text of mac_requirements.minimum\n\n- MacRecReqsText - (Textual) text of mac_requirements.recommended\n\nAs you can see this contains alot of useful information, however it also contains significant information we either already have or information that is completely useless as a result I will drop the rows I can not use as below.\nThe only rows I will keep are as follows \n- QueryName\n- RequiredAge - This has many blanks columns and needs resolved\n- PriceFinal - This will be useful to analyse what sales are like depending on price\n- AboutText - Useful for Textblob and sentiment analysis\n- ShortDescrip- Useful for Textblob and sentiment analysis\n- Detailed Descrip - Useful for Textblob and sentiment analysis\n- Reviews -  Useful for Textblob and sentiment analysis\n\nThis must be cleaned the same way the the game sales one was done.","453c4121":"As we can see from this the highest selling Genre is action games, this is really the only constant the other genres are usually less consistent depending on what is released that year but the other games which have a a large market are: \n1. Adventure\n2. Role Playing\n3. shooter \n4. sports\nThese are all genres alongside action that have a large market and are bought alot. \n\nFrom here we should look into whether action games relies on it's high selling games or whether on average it is the best genre to target, i.e. whether it's normal distribution is good or whether this genre relies on games going 'viral'. ","661074e1":"At this point so the dataset is cleaned up but we have to deal will the blank data, which as you can see above there is plenty of and it seems there is more than can be seen straight away, as a result we have to changed the form of some columns and make sure all Nan values are easily found. ","c8826aca":"I have chosen to select the games sales dataframe:\nFrom looking at this, this is a good dataframe in terms of having alot to analyse in terms of figure not just in terms of sales but also in terms of it's release year and more. Much more detail than IGN or steam data.","c8a0d446":"From the above diagram we can see the strongest correlations are:\n\n- Critic scores-to-global sales: We'll take a closer look at this below.\n\n- Year of release-to-platform: This makes sense since new platforms come out periodically.\n\n- User_Score to Critic_Score: This also make sense as they both usually follow the same pattern.\n\n- Price_Final to Platform - This makes sense since new prices come out periodically.","3e62c44d":"The above diagram does a great job at demonstrating that there is generally an era where a games console will be the leading console, which has went from Ps, to Wii, 360, PS3 and finally being our current generation of the PS4, backing up the point I would suggest the PS4 is the current best platform to focus on. ","56b111cc":"# Loading in and cleaning the selected datasets","c53c6418":"At this point the dataframe is clean and ready for visualisation and analysis","a0c18b13":"This gives us a great visualisation of the market share, from this I can state that the main genres to focus on in order are: \n1. Shooter\n2. Sports \n3. Action\n4. Role Playing\n5. The other genres...","8d53ea02":"From here to analyse what factors have the biggest impact on mainly global_sales, we will see which columns are correlated mostly highly. ","65efa32b":"Carrying on from above we will attempt to see the importance of the name of a game. \n\nThis will be an sklearn machine learning to see how accurately the name of the game depicts the genre of the game. ","98c7194f":"Furthermore, the regression model provides us with good coefficients that should impact critic score and inadvertantly increase Global_Sales. The most important coefficients is genre which was suggested in the visulisations earlier in the notebook. ","e053ef05":"Furthermore, the description columns have accurately depicted that sports games are sportier than the rest of the columns based on a few words, this is important as it shows that for a game to show what genre it is, the description of that game must contain words which competing games would use themselves.","a00c8ead":"In this part of the notebook I visualise the difference in releases and sales globally based on the platform which the game is released on. ","a558f00e":"From here we will work from games copied from the original dataframe so we aren't messing it up for future use. \nAlso we will disregard all sales apart from Global_Sales as this is the important number from the perspective of the client.","735533e7":"The results received from this are satisfactory, however, as done above I believe that it may be more accurate at predicting useful coefficients for the client if the dataset focuses on the relevant years, I will do so below with the Lasso model and Linear Regression. ","b8b9e399":"The results of this are excellent as the games at the top from experience are games which are likely to sell very well and the games are the bottom are very unlikely to sell well, showing the accuracy of the machine learning concepts. ","1bcd3260":"This tells us that the features included within the name depict to an accuracy of 50% what genre the game will be. Showing us the importance of a good name, and how it will show the type of game it is, meaning for a games company it will be important for the name to be appropriate. ","df8e70bc":"As an overall summary from the above visualisations, I would suggest to a games marketing executive that, all aspects of a game i.e. genre, platform and publisher will affect the popularity and sales of the game. \nFurther to this, consideration needs to be given to the area which you are targetting. I would summarise in the following manner: \n\nEU\/NA\/Other area: \n- platform recommendation: PS4, Xbox One, 3DS, WiiU, PC\n- Genre recommendation: Shooter, Sports games, Role Playing, Action Games, Adventure\n\nJP area:\n- platform recommendation: 3DS, PS4, WiiU \n- Genre recommendation: Role playing games, Action games, Fighting games\n\n\nFrom this I would suggest that despite being a handicap as a small publisher, there is still a good chance that games released although not as many that the games will sell well even with large company competition.","69afdbdb":"The following sets out a number of words which would typically be used to describe action games and sees if this accurately reflects words which are used to describe games which are in the action genre.","eb48d50b":"This shows the value of breaking the dataset down into more recent data. As PS2 has the most releases, the PS4 in the past few years has much more than the PS2 as it is outdated. ","4ab0e730":"# Machine learning prep","26a5caee":"This means that per description that 0.59 of these words are used for action genre games, from here we should see how this compares to other genres, to see whether this is a good score or not.","efaf6f17":"Due to the significant amount of missing data we need to deal with it appropriately, by filling it with relevant information or just dropping it to ensure it won't skew the data in future.","42ae08b0":"From here I will analyse the impact of the the words used in reviews in games reviewed badly and reviewed well and see if reviews accurately depict the rating of the game. ","8cc40161":"The below code focuses on the impact of the platform of the game and how it sells in different geographical locations.","db7f99e1":"In the below section I will analyse the importance of a games description in depicting it's genre, and how well the words use in descriptions accurately predict which genre the game is. ","a90426c3":"With the outliers removed we can see that even considering how long the PS4, and Xbox one have been out they are selling similarly well to their older rivals, with the data less skewed, we can see that ntomaling most consoles are selling around the same within their normal distrubtion but the PS4 have a better number of high sellers than most of the new consoles. ","c2c3f784":"From a ctritic_score point of the genre is less important, as the scores vary greatly the past few yasrs Action games have scored consistently whilst Strategy and Platform games clearly depend on the games released. \nFrom this I would draw the conclusion that: \n- Hit games in terms of critic score come in genres such as role playing, Strategy and platform games. \n- Games like action, shooter and fighting tending to get more consistently decent scores and most seem to get around the 70 mark. ","12b45f7a":"* From this we can see and the sort by year we can see that were significantly less games from 1980 until the late ninties, as a result, I would say the games before 1996 or so would be considered outliers for a number of different reasons. Most significantly they were produced in a much less competitive market and it is important that these games may skew any findings as a director of sales would only be interested in the results from games in the not so distant past in my opinion. \n\n* Further to this I can see that despite the fact this data was produced in 2016 it includes data from 2017 onwards, these should also be dropped. ","8d8f5c60":"This again backs up what is said above, the most common outliers are in the top 1%, it is obvious that without these the genre isn't as dominant in the market as it seems. ","37730a73":"From here will we use LMfit to see the best fit for Critic score- User-score, Critic_Score-global_sales and USer_Score to Global_Sales","908014b0":"From this we can see again that the Japanese market doesn't follow the same patterns as the global trends, if the market of Japan were to be the developers target I would change my recommended course of action, and focus on the following genres: \n1. Role playing games\n2. Action games\n3. Fighting games\n\nThe rest of the genres have a very small market and as a result if it's a game outside of this genre perhaps JP isn't the idea target market. ","df0ec048":"Another issue is that user score is an object this needs to be changed, this needs addressed, so for future analysis it is all in the same format and can be visualised appropriately.","4578b1bd":"# Importing an external dataframe\n'https:\/\/data.world\/craigkelly\/steam-game-data' - This is the link contains a significant data from games that are all sold on the platform STEAM. Although alot of the games here aren't PC games sold on steam their game reviews will generally be the same despite the platform. Same thing goes for the game price and a number of other useful factors I will be utilising in order to analyse much of the data in greater detail.","901e1d25":"We will need to drop the review data as it may cause issues with machine learning and correlations due to its mass of NA data and pricefinal will need to be filled with the mean of its column for the sake of accuracy. ","abe2540a":"# Year by year, regional analysis","0d0e888d":"From this visualisation we can see many of the games which have sold amounts which could be considered anomolies are on platforms which have been around for a long time, i.e. previous generation consoles, and these tend to have a weirder distrubution. For our purpose this is less useful for any analysis due to the skewed distribution. ","cb851f1f":"For this element of machine learning. We will use SKlearn to see what the biggest factors are in impacting whether a game will be a 'HIT' in the future, meaning that it will sell over 1million copies. ","02be0acc":"This is the reason I am going to do further analysis in that I am going to split it up into more modern years. As I would suggest if I was going to release a game today that you should not focus on the PS2. Simply it has been out the longest.","08777c1a":"From this I can draw the conclusion that the most influential regions are EU and NA in terms of sales. \nHowever, the sales figures from NA aren't as huge as they used to be, important to note is the raising importance of the EU sales, however due to their similar taste in games I would suggest that on a global scale focussing on their tastes is important to maximise sales.","6edf0d31":"These seem like reasonable coefficients to impact the sales, however I believe that they are skewed by old data and these should be re run to predict more accurate coefficients. ","4fbc0c1e":"This visualises what we seen above the only genre that performs better is shooter games, these are closely interlinked meaning that the accuracy is still there. ","2700da29":"# Textblob and wordcloud\nCredit - https:\/\/www.kaggle.com\/allunia\/eda-en-text-normalization","b44b7f0c":"Surprisingly to me, even more games have been released onto the Playstation Vita, from this it seems like the Playstations are dominating on releases and if a developer were to develop a new game I would suggest that a focus should be developing on the PS4.","7d1e34aa":"EU top recent platforms: \n1. PS4 (Massively popular) \n2. Xbox one (Much less than the PS4) \n3. PC\n4. 3DS\n5. WiiU ","df5aeeec":"The results of these are as expected, games with high scores receieve no words which would suggest it is a bad a game and a high rate of words which would suggest it is a great game.","12bc8864":"As the two main markets and sellers of global regions, the two EU and NA sales figures tend to follow the same pattern as the global sales patterns. Which is the following genres are most popular: \n1. Shooter games\n2. Sports games\n3. Role Playing\n4. Action Games\n5. Adventure","bd2e8c4d":"# Platform analysis & visualistion","fc7952a3":"# Regional analysis and visualisation","d6a14346":"As stated above and seen above, there is useful information in this dataset, however there is also significant amounts of useless data, this will be dropped below.","b3433b17":"# Publisher analysis and visualisation","b7d38e8a":"From this and the previous visualisations I can conclude that on a global scale, producers should focus on: \n1. Shooter games\n2. Sports games\n3. Role Playing\n4. Action Games\n5. Adventure","18a97a24":"Based on the above visualisation I can say: \n - PS4 and xbox releases are the most common and are the main market for releases\n - Past that the previous generation consoles still receive new games, but less by the year.\n - Furthmore, WiiU and Nintendo products continued to be released at a slower rate but they still have a strong market. \n - PC is a smaller market but definitely not deteriorating, growing the past few years.","668690a6":"# Notebook One\nTechnical areas included\/ to include:\n* Cleaning\/ understanding the data\n* Detailed data visualisation.\n* Text blob, word cloud to see how descriptions of games are working.\n* Machine learning processes. LMfit, linear regression.\n\n\n- Who is your customer? \n  * Small video game company CEO or director of marketing\/sales, deciding which direction their future projects should take. What genre, what platform, what area of the world to target it, how to name it, how to describe it, in general how to market so it sells well.\n  \n  \n- What are they concerned with?\n  * Increasing Revenues by increasing video game sales, by learning the correct areas to target their project.\n  \n  \n- What would you like to find out for your customer?  \n  * Finding out which platform of game there is a gap in the market for.\n  * Finding out which genre of game ia likely to sell.\n  * Finding out which area is growing and which area should be targeted. \n  * As a small company how impacted are the sales likely to be in comparison to a larger company. \n  * Finding out the impact game reviews have on sales.\n  * Finding out which type of games are most likely to receive high reviews. \n  * Find out what types of words to describe games most influence the number of sales.\n  * Find out which words are used to describe which genres are how influential they are in detailing the genre of game. ","9e48dc69":"This is useful as it shows us the remaining relevant platforms: PS4, PC, 3DS, XBox One, WiiU and PSV.\nFrom this we can clearly see that the platforms remaining do not cause a significant difference to the score provided by critic. Which makes sense, so from the point of view the platform isn't as relevant.","5645e4a6":"Again we can see that other games have a better or as good spread of game sales as action games, meaning it is not the dominant game in the market anymore. ","bcd69344":"Japan top platforms, dramatically different from global trends: \n1. 3DS is massive\n2. PS4\n3. PSVita (anomoly for JP) \n4. WiiU\n5. PS3\n\nSurprising as literally no PC games are played in JP and pretty much all Microsoft is none existent. Proving that what region you aim your game at is very important.","78f6c16b":"# Genre analysis and visualisation","414012f7":"# games_sales dataset\nThis dataset comes from: 'https:\/\/www.kaggle.com\/gregorut\/videogamesales' and is then built on at: 'https:\/\/www.kaggle.com\/rush4ratio\/video-game-sales-with-ratings' \nThe original dataset is described as ' This dataset contains a list of video games with sales greater than 100,000 copies. It was generated by a scrape of vgchartz.com.' And then being built on is desribed as 'Motivated by Gregory Smith's web scrape of VGChartz Video Games Sales, this data set simply extends the number of variables with another web scrape from Metacritic. Unfortunately, there are missing observations as Metacritic only covers a subset of the platforms. Also, a game may not have all the observations of the additional variables discussed below. Complete cases are ~ 6,900'\n\nPotential Limitations from above:\n- From the describe function it is clear to see that there are quite alot of missing values within a number of the columns this will have to be addressed.\n- There are clearly significant amounts of duplicate data this must be dealt with also.\n\nThe columns included are described as: \n- Name - The games name, changed to title and merged with previous data\n- Platform - Platform of the games release (i.e. PC,PS4, etc.) from vgchartz.com.\n- Year - Year of the game's release from vgchartz.com. \n- Genre - Genre of the game from vgchartz.com.\n- Publisher - Publisher of the game, from vgchartz.com. This describes who publishes the game. There should be no issues with this data.\n- NA_Sales - Sales in North America (in millions) from vgchartz.com, this should also bring no issues in relation to analysis.\n- EU_Sales - Sales in Europe (in millions) from vgchartz.com, this should also bring no issues in relation to analysis.\n- JP_Sales - Sales in Japan (in millions) from vgchartz.com, this should also bring no issues in relation to analysis.\n- Other_Sales - Sales in the rest of the world (in millions) from vgchartz.com, this should also bring no issues in relation to analysis.\n- Global_Sales - Total worldwide sales.(in millions)  from vgchartz.com, this should also bring no issues in relation to analysis.\n- Critic_score - Aggregate score compiled by Metacritic staff, from metacritic.com, should be changed to out of 10 as that is how the rest of the score are marked.\n- Critic_count - The number of critics used in coming up with the score from above, pulled from the website. \n- User_score - Score by Metacritic's subscribers, from the website.\n- User_count - Number of users who gave the user_score, from the website. This may be dropped as it has little potential to be useful for analysis\n- Developer - Party responsible for creating the game\n- Rating - The ESRB ratings, all from the metacritic and vgchartz.com websites. ","9fc0eb5e":"The above diagram backs up the point made above, the current console of importance is the PS4 selling 70m copies in the midway point of 2016, which is impressive in comparison to it's rivals. \nIn 2015 and 2016 the top consoles globally consist of: \n1. PS4\n2. XBox One\n3. 3DS (Surprisingly) \n4. WiiU\n5. PC","f150c97a":"Creating a dataframe of games which have good reviews, i.e. top 10% user score","59bc5b9e":"We will drop and change the type and unskew columns which could have a negative impact on the accuracy of the upcoming machine learning. ","f0605ccc":"This follows the same patterns as the global sales statistics","e4dfd929":"This is an acceptable level of skewedness, it is now acceptable that the machine learning will be appropriately accurate. ","d793a81f":"From here I will Use wordcloud to analyse what words are typically used to describe games from different genres. \nAnd games that sell well or really badly, whether words are used to describe high selling games and the same for low selling games. ","40900dd5":"For now I am going to leave some of the null values in the critic and user score as I will be mostly handling the other columns and the blank data later on will be dropped or filled with the mean of the column.\nI have cleaned the dataset so that the blank columns are minimised, and from here it should make it easier to analyse.","5dedd446":"When it is broken down further, we can see that per game the larger companies are still some of the best selling but there is more variety and some smaller publishers are in and around the big ones unlike the graph above.\n \nAs a result of this, I would suggest even though having a big publisher put the game out is an advantage an indie company can sell well as suggested by the above 'Hello Games'.\n\nFrom here it is important that I am able to visualise the impact that the Genre of the game has on the sales.","3ad5d117":"This creates a new data frame only including games released from 1996 - 2016 \nA better range of games discounting some outliers","08ac2690":"This is an excellent list of coeffiencts as it tells us things that we previously knew, that Action, adventure and shooters games are likely to sell well. Larger publishers are also likely to sell well. But past this Critic Score has an impact, and PS4 is the way to go in terms of platform, recommending against PC releases and Misc genre. ","c8e4a268":"Once again, this proves on a global scale, the PS4 (Over 50%!) is the way to go if hoping for a decent sales figure, followed by the XBox one (20%) then the 3DS, smaller PC & WiiU and a few sales on older platforms. \nFrom here we can definitely see that PS4 is the platform for the future to focus on and as a result I would recommend any publisher focuses on it to maximise sales. \n\nFrom here we need further visualisation of the impact of the publisher and genre of the game.","a15269bc":"This backs up what was said before, without action games huge outliers, the sales aren't as good as the normal distribution of shooters, platformers, sports, racing, fighting and role playing games. \nFrom this I would suggest Focusing releases on action games would not be recommened in a possibly over crowded and household name reliant genre. ","4a684eb5":"For the following, it is obvious that there are some games which are significantly more successful than can be useful for the purposes of analysis, particularly from the perspective of a smaller company as these games usually have large company backing and go viral. \nAs a result I will analyse the platform sales taking out the outliers.","ff0a140b":"As seen above we can see that this puts the following features as things that will make a game sell more than 1 million hits. This is as expected that Critic Score is number one, followed by publisher, genre and Platform. These seem reasonable and we will apply this to the below games which were recently released and under 1m sales. ","8c033605":"North American Consoles to focus on: \n1. PS4\n2. Xbox One\n3. 3DS\n4. WiiU\n5. PC","2f3f021c":"I will use the Lasso model and the xgBoost to predict what coefficients impact sales most and predict future sales from this. ","973d4ce4":"These diagrams show as the correlation in that as Critic_Score goes up, in general the global_Sales rise with it, only marginally but at the lower ends of sales, it is an important factor to influence global_Sales.\n\nThis ties back into a diagram referenced above, that certain genres arelikely to recieve higher scores, this should be considered as it will impact the games sales.","128fdc53":"Checking the skewedness of numerical data.\nFor numerical machine learning this will have to be unskewed for accuracy of prediction. ","8b1dd658":"# Linear Regression","6b0ffc00":"Seeing how the dataset is broken down, how many null values are there? Are they in the appropriate datatype, how many rows are there, should I drop any? etc...","fedec090":"These coefficients seems sort of accurate but again skewed by outdated data again. ","ed629b95":"Begin to clean the dataset, by dropping duplicates, filling or dropping columns with too many null rows, dropping useless rows and ensuring data is of the appropriate type."}}