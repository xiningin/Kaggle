{"cell_type":{"2eac7126":"code","cdeca55f":"code","836802c1":"code","6cc0ec44":"code","85535415":"code","a543b3f7":"code","0b4fc790":"code","2624db31":"code","5191fedf":"code","5a756a6c":"code","b7824fdc":"code","363782b5":"code","1547b256":"code","a250c2ad":"code","06303468":"code","eee1b005":"code","0cf65943":"code","6dce7d02":"code","1a2f4232":"code","209849d0":"code","a86e7f03":"code","f7303ce4":"code","8bcc0712":"code","302212e7":"code","2502376f":"markdown","1413cac8":"markdown","ab73a5a7":"markdown","2c97790b":"markdown","2d34e2ae":"markdown","68971c91":"markdown"},"source":{"2eac7126":"%matplotlib inline\n\nimport os\nimport sys\nimport multiprocessing as mp\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport warnings\n\nfrom functools import partial\nfrom scipy.stats import skew, kurtosis, iqr\nfrom sklearn.externals import joblib\nfrom tqdm import tqdm_notebook as tqdm\n\nwarnings.filterwarnings('ignore')","cdeca55f":"def add_features(feature_name, aggs, features, feature_names, groupby):\n    feature_names.extend(['{}_{}'.format(feature_name, agg) for agg in aggs])\n    for agg in aggs:\n        if agg == 'kurt':\n            agg_func = kurtosis\n        elif agg == 'iqr':\n            agg_func = iqr\n        else:\n            agg_func = agg\n        g = groupby[feature_name].agg(agg_func).reset_index().rename(index=str, columns={feature_name: '{}_{}'.format(feature_name, agg)})\n        features = features.merge(g, on='SK_ID_CURR', how='left')\n    return features, feature_names\n\n\ndef add_features_in_group(features, gr_, feature_name, aggs, prefix):\n    for agg in aggs:\n        if agg == 'sum':\n            features['{}{}_sum'.format(prefix, feature_name)] = gr_[feature_name].sum()\n        elif agg == 'mean':\n            features['{}{}_mean'.format(prefix, feature_name)] = gr_[feature_name].mean()\n        elif agg == 'max':\n            features['{}{}_max'.format(prefix, feature_name)] = gr_[feature_name].max()\n        elif agg == 'min':\n            features['{}{}_min'.format(prefix, feature_name)] = gr_[feature_name].min()\n        elif agg == 'std':\n            features['{}{}_std'.format(prefix, feature_name)] = gr_[feature_name].std()\n        elif agg == 'count':\n            features['{}{}_count'.format(prefix, feature_name)] = gr_[feature_name].count()\n        elif agg == 'skew':\n            features['{}{}_skew'.format(prefix, feature_name)] = skew(gr_[feature_name])\n        elif agg == 'kurt':\n            features['{}{}_kurt'.format(prefix, feature_name)] = kurtosis(gr_[feature_name])\n        elif agg == 'iqr':\n            features['{}{}_iqr'.format(prefix, feature_name)] = iqr(gr_[feature_name])\n        elif agg == 'median':\n            features['{}{}_median'.format(prefix, feature_name)] = gr_[feature_name].median()\n        return features\n\ndef parallel_apply(groups, func, index_name='Index', num_workers=1, chunk_size=100000):\n    n_chunks = np.ceil(1.0 * groups.ngroups \/ chunk_size)\n    indeces, features  = [],[]\n    for index_chunk, groups_chunk in tqdm(chunk_groups(groups, chunk_size), total=n_chunks):\n        with mp.pool.Pool(num_workers) as executor:\n            features_chunk = executor.map(func, groups_chunk)\n        features.extend(features_chunk)\n        indeces.extend(index_chunk)\n    features = pd.DataFrame(features)\n    features.index = indeces\n    features.index.name = index_name\n    return features\n\ndef chunk_groups(groupby_object, chunk_size):\n    n_groups = groupby_object.ngroups\n    group_chunk, index_chunk = [],[]\n    for i, (index, df) in enumerate(groupby_object):\n        group_chunk.append(df)\n        index_chunk.append(index)\n\n        if (i + 1) % chunk_size == 0 or i + 1 == n_groups:\n            group_chunk_, index_chunk_ = group_chunk.copy(), index_chunk.copy()\n            group_chunk, index_chunk = [],[]\n            yield index_chunk_, group_chunk_","836802c1":"application  = pd.read_csv('..\/input\/application_train.csv')\ninstallments = pd.read_csv('..\/input\/installments_payments.csv')","6cc0ec44":"installments.head()","85535415":"INSTALLMENTS_PAYMENTS_AGGREGATION_RECIPIES = []\nfor agg in ['mean', 'min', 'max', 'sum', 'var']:\n    for select in ['AMT_INSTALMENT',\n                   'AMT_PAYMENT',\n                   'DAYS_ENTRY_PAYMENT',\n                   'DAYS_INSTALMENT',\n                   'NUM_INSTALMENT_NUMBER',\n                   'NUM_INSTALMENT_VERSION'\n                   ]:\n        INSTALLMENTS_PAYMENTS_AGGREGATION_RECIPIES.append((select, agg))\nINSTALLMENTS_PAYMENTS_AGGREGATION_RECIPIES = [(['SK_ID_CURR'], INSTALLMENTS_PAYMENTS_AGGREGATION_RECIPIES)]","a543b3f7":"groupby_aggregate_names = []\nfor groupby_cols, specs in tqdm(INSTALLMENTS_PAYMENTS_AGGREGATION_RECIPIES):\n    group_object = installments.groupby(groupby_cols)\n    for select, agg in tqdm(specs):\n        groupby_aggregate_name = '{}_{}_{}'.format('_'.join(groupby_cols), agg, select)\n        application = application.merge(group_object[select]\n                              .agg(agg)\n                              .reset_index()\n                              .rename(index=str,\n                                      columns={select: groupby_aggregate_name})\n                              [groupby_cols + [groupby_aggregate_name]],\n                              on=groupby_cols,\n                              how='left')\n        groupby_aggregate_names.append(groupby_aggregate_name)","0b4fc790":"application.head()","2624db31":"application_agg = application[groupby_aggregate_names + ['TARGET']]\napplication_agg_corr = abs(application_agg.corr())","5191fedf":"application_agg_corr.sort_values('TARGET', ascending=False)['TARGET']","5a756a6c":"positive_ID = application[application['TARGET']==1]['SK_ID_CURR'].tolist()\npositive_ID[:4]","b7824fdc":"value_counts = installments[installments['SK_ID_CURR'].isin(positive_ID)]['SK_ID_CURR'].value_counts()","363782b5":"value_counts.head()","1547b256":"sns.distplot(value_counts)","a250c2ad":"installments_one = installments[installments['SK_ID_CURR']==328162]","06303468":"installments_one.sort_values(['DAYS_INSTALMENT'],ascending=False).head(10)","eee1b005":"# installments_ = installments[installments['SK_ID_CURR'].isin(positive_ID[:100])]\ninstallments_ = installments.sample(10000)\ninstallments_['instalment_paid_late_in_days'] = installments_['DAYS_ENTRY_PAYMENT'] - installments_['DAYS_INSTALMENT'] \ninstallments_['instalment_paid_late'] = (installments_['instalment_paid_late_in_days'] > 0).astype(int)\ninstallments_['instalment_paid_over_amount'] = installments_['AMT_PAYMENT'] - installments_['AMT_INSTALMENT']\ninstallments_['instalment_paid_over'] = (installments_['instalment_paid_over_amount'] > 0).astype(int)","0cf65943":"features = pd.DataFrame({'SK_ID_CURR':installments_['SK_ID_CURR'].unique()})\ngroupby = installments_.groupby(['SK_ID_CURR'])","6dce7d02":"installments_.head()","1a2f4232":"feature_names = []\n\nfeatures, feature_names = add_features('NUM_INSTALMENT_VERSION', \n                                       ['sum','mean','max','min','std', 'median','skew', 'kurt','iqr'],\n                                     features, feature_names, groupby)\n\nfeatures, feature_names = add_features('instalment_paid_late_in_days', \n                                       ['sum','mean','max','min','std', 'median','skew', 'kurt','iqr'],\n                                     features, feature_names, groupby)\n\nfeatures, feature_names = add_features('instalment_paid_late', ['sum','mean'],\n                                     features, feature_names, groupby)\n\nfeatures, feature_names = add_features('instalment_paid_over_amount', \n                                       ['sum','mean','max','min','std', 'median','skew', 'kurt','iqr'],\n                                     features, feature_names, groupby)\n\nfeatures, feature_names = add_features('instalment_paid_over', ['sum','mean'],\n                                     features, feature_names, groupby)\n    \ndisplay(features.head())","209849d0":"def last_k_instalment_features(gr, periods):\n    gr_ = gr.copy()\n    gr_.sort_values(['DAYS_INSTALMENT'],ascending=False, inplace=True)\n    \n    features = {}\n\n    for period in periods:\n        gr_period = gr_.iloc[:period]\n\n        features = add_features_in_group(features,gr_period, 'NUM_INSTALMENT_VERSION', \n                                       ['sum','mean','max','min','std', 'median','skew', 'kurt','iqr'],\n                                         'last_{}_'.format(period))\n        \n        features = add_features_in_group(features,gr_period, 'instalment_paid_late_in_days', \n                                       ['sum','mean','max','min','std', 'median','skew', 'kurt','iqr'],\n                                         'last_{}_'.format(period))\n        features = add_features_in_group(features,gr_period ,'instalment_paid_late', \n                                     ['count','mean'],\n                                         'last_{}_'.format(period))\n        features = add_features_in_group(features,gr_period ,'instalment_paid_over_amount', \n                                       ['sum','mean','max','min','std', 'median','skew', 'kurt','iqr'],\n                                         'last_{}_'.format(period))\n        features = add_features_in_group(features,gr_period,'instalment_paid_over', \n                                     ['count','mean'],\n                                         'last_{}_'.format(period))\n    \n    return features","a86e7f03":"func = partial(last_k_instalment_features, periods=[1,5,10,20,50,100])\n\ng = parallel_apply(groupby, func, index_name='SK_ID_CURR',\n                   num_workers=16, chunk_size=10000).reset_index()\nfeatures = features.merge(g, on='SK_ID_CURR', how='left')\n\ndisplay(features.head())","f7303ce4":"from sklearn.linear_model import LinearRegression","8bcc0712":"def trend_in_last_k_instalment_features(gr, periods):\n    gr_ = gr.copy()\n    gr_.sort_values(['DAYS_INSTALMENT'],ascending=False, inplace=True)\n    \n    features = {}\n\n    for period in periods:\n        gr_period = gr_.iloc[:period]\n\n\n        features = _add_trend_feature(features,gr_period,\n                                      'instalment_paid_late_in_days','{}_period_trend_'.format(period)\n                                     )\n        features = _add_trend_feature(features,gr_period,\n                                      'instalment_paid_over_amount','{}_period_trend_'.format(period)\n                                     )\n    return features\n\ndef _add_trend_feature(features,gr,feature_name, prefix):\n    y = gr[feature_name].values\n    try:\n        x = np.arange(0,len(y)).reshape(-1,1)\n        lr = LinearRegression()\n        lr.fit(x,y)\n        trend = lr.coef_[0]\n    except:\n        trend=np.nan\n    features['{}{}'.format(prefix,feature_name)] = trend\n    return features","302212e7":"func = partial(trend_in_last_k_instalment_features, periods=[10,50,100,500])\n\ng = parallel_apply(groupby, func, index_name='SK_ID_CURR',\n                   num_workers=16, chunk_size=10000).reset_index()\nfeatures = features.merge(g, on='SK_ID_CURR', how='left')\n\ndisplay(features.head())","2502376f":"## Per id k last installment information","1413cac8":"## Aggregations","ab73a5a7":"# Solution 4","2c97790b":"## per id aggregations","2d34e2ae":"## per id dynamic ","68971c91":"# Feature Engineering\n## Solution 3"}}