{"cell_type":{"9f9fc1e3":"code","459161ce":"code","207b0436":"code","872340ec":"code","4b8d3d49":"code","f3aebaf3":"code","111b14b6":"code","5320c241":"code","22d351a7":"code","9d697834":"code","924be095":"code","e34d7845":"code","d4f4dc25":"code","814c6449":"code","73c07462":"code","3d497a81":"code","6a15300c":"code","686a7976":"code","07be0e8f":"code","94acddca":"markdown","1be7395f":"markdown","b4283ed8":"markdown","6643c624":"markdown","876834b7":"markdown","836a6add":"markdown","770aea9d":"markdown","41669450":"markdown","7654e9e5":"markdown","c628a8c3":"markdown","a0b71c68":"markdown","eca46d54":"markdown","6d62f480":"markdown"},"source":{"9f9fc1e3":"import os\nimport glob\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport resnet\nimport warnings\nwarnings.simplefilter('ignore')\n\nfrom skimage import io\nfrom skimage.transform import rescale\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import roc_auc_score\nfrom keras import optimizers\nfrom keras.callbacks import *","459161ce":"DATASET_PATH = '..\/input\/cxr-dataset'\n\n# There are two classes of images that we will deal with\ndisease_cls = ['effusion', 'nofinding']","207b0436":"effusion_path = os.path.join(DATASET_PATH, disease_cls[0], '*')\neffusion = glob.glob(effusion_path)\neffusion = io.imread(effusion[0])\n\nnormal_path = os.path.join(DATASET_PATH, disease_cls[1], '*')\nnormal = glob.glob(normal_path)\nnormal = io.imread(normal[0])\n\nf, axes = plt.subplots(1, 2, sharey=True)\nf.set_figwidth(10)\n    \naxes[0].imshow(effusion, cmap='gray')\naxes[1].imshow(normal, cmap='gray')","872340ec":"print('effusion', effusion.shape)\nprint('normal ',normal.shape)","4b8d3d49":"datagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=10,\n    width_shift_range=0,\n    height_shift_range=0,\n    vertical_flip=False,)\n\ndef preprocess_img(img, mode):\n    img = (img - img.min())\/(img.max() - img.min())\n    img = rescale(img, 0.25, multichannel=True, mode='constant')\n    \n    if mode == 'train':\n        if np.random.randn() > 0:\n            img = datagen.random_transform(img)\n    return img","f3aebaf3":"img_channels = 1\nimg_rows = 256\nimg_cols = 256\nnb_classes = 2\nEARLY_STOP_PATIENCE = 5\nEPOCHS = 100\n\nmodel_path = 'cxr_resnet_18_%sx%s.h5' % (img_rows, img_cols)","111b14b6":"class AugmentedDataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, mode='train', ablation=None, disease_cls = ['nofinding', 'effusion'], \n                 batch_size=32, dim=(256, 256), n_channels=1, shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.labels = {}\n        self.list_IDs = []\n        self.mode = mode\n        \n        for i, cls in enumerate(disease_cls):\n            paths = glob.glob(os.path.join(DATASET_PATH, cls, '*'))\n            brk_point = int(len(paths)*0.8)\n            if self.mode == 'train':\n                paths = paths[:brk_point]\n            else:\n                paths = paths[brk_point:]\n            if ablation is not None:\n                paths = paths[:int(len(paths)*ablation\/100)]\n            self.list_IDs += paths\n            self.labels.update({p:i for p in paths})\n        \n            \n        self.n_channels = n_channels\n        self.n_classes = len(disease_cls)\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) \/ self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        y = np.empty((self.batch_size), dtype=int)\n        \n        delete_rows = []\n\n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            img = io.imread(ID)\n            img = img[:, :, np.newaxis]\n            if img.shape == (1024, 1024,1):\n                img = preprocess_img(img, self.mode)\n                X[i,] = img\n                y[i] = self.labels[ID]\n            else:\n                delete_rows.append(i)\n                continue\n                \n        X = np.delete(X, delete_rows, axis=0)\n        y = np.delete(y, delete_rows, axis=0)\n        \n        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)","5320c241":"model = resnet.ResnetBuilder.build_resnet_18((img_channels, img_rows, img_cols), nb_classes)\nmodel.compile(loss='categorical_crossentropy',optimizer='SGD',\n              metrics=['accuracy'])\ntraining_generator = AugmentedDataGenerator('train', ablation=5)\nvalidation_generator = AugmentedDataGenerator('val', ablation=5)\n\nmodel.fit_generator(generator=training_generator,\n                    validation_data=validation_generator,\n                    epochs=1)","22d351a7":"model = resnet.ResnetBuilder.build_resnet_18((img_channels, img_rows, img_cols), nb_classes)\nmodel.compile(loss='categorical_crossentropy',optimizer='SGD',\n              metrics=['accuracy'])\n\ntraining_generator = AugmentedDataGenerator('train', ablation=5)\nvalidation_generator = AugmentedDataGenerator('val', ablation=5)\n\nmodel.fit_generator(generator=training_generator,\n                    validation_data=None,\n                    epochs=5)","9d697834":"class roc_callback(Callback):\n    \n    def on_train_begin(self, logs={}):\n        logs['val_auc'] = 0\n\n    def on_epoch_end(self, epoch, logs={}):\n        y_p = []\n        y_v = []\n        for i in range(len(validation_generator)):\n            x_val, y_val = validation_generator[i]\n            y_pred = self.model.predict(x_val)\n            y_p.append(y_pred)\n            y_v.append(y_val)\n        y_p = np.concatenate(y_p)\n        y_v = np.concatenate(y_v)\n        roc_auc = roc_auc_score(y_v, y_p)\n        print ('\\nVal AUC for epoch{}: {}'.format(epoch, roc_auc))\n        logs['val_auc'] = roc_auc","924be095":"model = resnet.ResnetBuilder.build_resnet_18((img_channels, img_rows, img_cols), nb_classes)\nmodel.compile(loss='categorical_crossentropy',optimizer='SGD',\n              metrics=['accuracy'])\n\ntraining_generator = AugmentedDataGenerator('train', ablation=20)\nvalidation_generator = AugmentedDataGenerator('val', ablation=20)\n\nauc_logger = roc_callback()\n\nmodel.fit_generator(generator=training_generator,\n                    validation_data=validation_generator,\n                    epochs=5, callbacks=[auc_logger])","e34d7845":"from functools import partial\nimport keras.backend as K\nfrom itertools import product\n\ndef w_categorical_crossentropy(y_true, y_pred, weights):\n    nb_cl = len(weights)\n    final_mask = K.zeros_like(y_pred[:, 0])\n    y_pred_max = K.max(y_pred, axis=1)\n    y_pred_max = K.reshape(y_pred_max, (K.shape(y_pred)[0], 1))\n    y_pred_max_mat = K.cast(K.equal(y_pred, y_pred_max), K.floatx())\n    for c_p, c_t in product(range(nb_cl), range(nb_cl)):\n        final_mask += (weights[c_t, c_p] * y_pred_max_mat[:, c_p] * y_true[:, c_t])\n    cross_ent = K.categorical_crossentropy(y_true, y_pred, from_logits=False)\n    return cross_ent * final_mask\n\nbin_weights = np.ones((2,2))\nbin_weights[0, 1] = 5\nbin_weights[1, 0] = 5\nncce = partial(w_categorical_crossentropy, weights=bin_weights)\nncce.__name__ ='w_categorical_crossentropy'","d4f4dc25":"model = resnet.ResnetBuilder.build_resnet_18((img_channels, img_rows, img_cols), nb_classes)\nmodel.compile(loss=ncce, optimizer='SGD',\n              metrics=['accuracy'])\n\ntraining_generator = AugmentedDataGenerator('train', ablation=5)\nvalidation_generator = AugmentedDataGenerator('val', ablation=5)\n\nmodel.fit_generator(generator=training_generator,\n                    validation_data=None,\n                    epochs=1)","814c6449":"class DecayLR(keras.callbacks.Callback):\n    def __init__(self, base_lr=0.01, decay_epoch=1):\n        super(DecayLR, self).__init__()\n        self.base_lr = base_lr\n        self.decay_epoch = decay_epoch \n        self.lr_history = []\n        \n    def on_train_begin(self, logs={}):\n        K.set_value(self.model.optimizer.lr, self.base_lr)\n\n    def on_epoch_end(self, epoch, logs={}):\n        new_lr = self.base_lr * (0.5 ** (epoch \/\/ self.decay_epoch))\n        self.lr_history.append(K.get_value(self.model.optimizer.lr))\n        K.set_value(self.model.optimizer.lr, new_lr)","73c07462":"model = resnet.ResnetBuilder.build_resnet_18((img_channels, img_rows, img_cols), nb_classes)\nsgd = optimizers.SGD(lr=0.005)\n\nbin_weights = np.ones((2,2))\nbin_weights[1, 1] = 10\nbin_weights[1, 0] = 10\nncce = partial(w_categorical_crossentropy, weights=bin_weights)\nncce.__name__ ='w_categorical_crossentropy'\n\nmodel.compile(loss=ncce,optimizer= sgd,\n              metrics=['accuracy'])\ntraining_generator = AugmentedDataGenerator('train', ablation=50)\nvalidation_generator = AugmentedDataGenerator('val', ablation=50)\n\nauc_logger = roc_callback()\n\ncheckpoint = ModelCheckpoint(model_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\nearly_stopping = EarlyStopping(monitor='val_acc', mode='max', patience=EARLY_STOP_PATIENCE, \n                   restore_best_weights=True, verbose=1)\n\n\ndecay = DecayLR()\n\nmodel.fit_generator(generator=training_generator,\n                    validation_data=validation_generator,\n                    epochs=EPOCHS, callbacks=[auc_logger, decay, checkpoint,early_stopping])","3d497a81":"#saving the weights\nmodel.save_weights(model_path)\nmodel.summary()","6a15300c":"val_model = resnet.ResnetBuilder.build_resnet_18((img_channels, img_rows, img_cols), nb_classes)\n\n#load the saved weights\nval_model.load_weights(model_path)","686a7976":"effusion_path = os.path.join(DATASET_PATH, disease_cls[0], '*')\neffusion = glob.glob(effusion_path)\neffusion = io.imread(effusion[-8])\nplt.imshow(effusion,cmap='gray')","07be0e8f":"img = preprocess_img(effusion[:, :, np.newaxis], 'validation')\nval_model.predict(img[np.newaxis,:])","94acddca":"After deeply examining our data and building some preliminary models, we are finally ready to build a model that will perform our prediction task.","1be7395f":"Our data is in the form of grayscale (black and white) images of chest x-rays. To perform our classification task effectively, we need to perform some pre-processing of the data.\n\nFirst, we load all the relevant libraries.","b4283ed8":"## 5. Making a Prediction - Inference","6643c624":"## 2. Model building","876834b7":"## 3. Ablation Run","836a6add":"We will be using a Resnet in this (you learnt about Resnets previously). \n\nFor this to work, the script that defines the resnet model (resnet.py) should reside in the same folder as this notebook","770aea9d":"Neural networks have revolutionised image processing in several different domains. Among these is the field of medical imaging. In the following notebook, we will get some hands-on experience in working with Chest X-Ray (CXR) images.\n\nThe objective of this exercise is to identify images where an \"effusion\" is present. This is a classification problem, where we will be dealing with two classes - 'effusion' and 'nofinding'. Here, the latter represents a \"normal\" X-ray image.\n\nThis same methodology can be used to spot various other illnesses that can be detected via a chest x-ray. For the scope of this demonstration, we will specifically deal with \"effusion\".","41669450":"## 1. Data Pre-processing","7654e9e5":"Next, we read the \"effusion\" and \"nofinding\" images.","c628a8c3":"### Data Augmentation ###\n\nNow that we have read the images, the next step is data augmentation. We use the concept of a \"data generator\" that you learnt in the last section.","a0b71c68":"## 4. Final Run","eca46d54":"# Analysis of Chest X-Ray images","6d62f480":"In the previous notebook, you learnt about Ablation. Briefly, an ablation run is when you systematically modify certain parts of the input, in order to observe the equivalent change in the input.\n\nFor the following section, we'll be using the Data Generator concept that you previously worked on."}}