{"cell_type":{"9cc0c188":"code","e9d86647":"code","7b49257f":"code","904fbc9b":"code","db54321c":"code","c6e3043a":"code","6d90b81f":"code","8995aaa1":"code","84cb172a":"code","6f6b798d":"code","860bc6fc":"code","b59886c5":"code","5c2e04b8":"code","4f740ba3":"code","f23ab00f":"code","d132d39e":"code","4b6b821e":"code","a94e88bd":"code","66d414af":"code","63aed736":"code","63767e7c":"code","53b07d89":"code","2be04388":"code","39b951e5":"code","83ddb48d":"code","26fec6ce":"code","0171cab5":"markdown","cb43af5b":"markdown","b64d8fb1":"markdown","d8450083":"markdown","4536e070":"markdown","33dceda5":"markdown","fe3eb9e8":"markdown","d6d946ca":"markdown","3494ffbe":"markdown","b5503e90":"markdown","808b2633":"markdown"},"source":{"9cc0c188":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","e9d86647":"data =pd.read_csv('..\/input\/Pokemon.csv')     # data read","7b49257f":"data.info()     #data's information","904fbc9b":"data.head()  # first 5 rows","db54321c":"data.tail()  # last 5 rows","c6e3043a":"data.columns # give me column names","6d90b81f":"data.shape  ## shape gives number of rows and columns in a tuble","8995aaa1":"# frequency of pokemon types\nprint(data['Type 2'].value_counts(dropna = False))   # if there are nan values that also be counted","84cb172a":"# For example max Speed is 180 or min attack is 5\ndata.describe() # ignore null entries","6f6b798d":"# For example: compare defense of pokemons that are legendary  or not\n# Black line at top is max\n# Blue line at top is 75%\n# Green line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\n# -------------------------------------------\n# boxplot parameters\n# column : Column name or list of names, or vector.\n# by : Column in the DataFrame to pandas.DataFrame.groupby(). \n# ax : The matplotlib axes to be used by boxplot.\n# fontsize : Tick label font size in points or as a string (e.g., large).\n# grid : Setting this to True will show the grid.\n# figsize : The size of the figure to create in matplotlib.\n\ndata.boxplot(column='Defense',by = 'Legendary',fontsize = 'large', figsize = (8,8) )","860bc6fc":"# Merge data\nnew_data = data.head()  # I only take 5 rows into new data\nnew_data   #show new_data\n","b59886c5":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=new_data,id_vars ='Name' , value_vars =['HP','Speed'])\nmelted     # show melted","5c2e04b8":"# Lets reverse\nmelted.pivot(index ='Name' , columns ='variable', values = 'value' )","4f740ba3":"# Create 2 dataframe\ndata1 = data.head()\ndata2 = data.tail()\nconc_data_row = pd.concat([data1,data2],axis=0, ignore_index=True ) # axis=0 dataframes in row \nconc_data_row   # show","f23ab00f":"# Create 2 dataframe\ndata1 = data['HP'].head()\ndata2 = data['Speed'].head()\nconc_data_col = pd.concat([data1,data2],axis=1 )  \nconc_data_col   # show","d132d39e":"data.dtypes","4b6b821e":"# convert object(str) -----> categorical\n# convert int ------> float\ndata['Type 1'] =data['Type 1'].astype('category')\ndata['Defense'] =data['Defense'].astype('float')","a94e88bd":"# Type 2 changed from object to category\n# Speed changed from int to float\ndata.dtypes","66d414af":"#Type 2 has 414 non-null object so it has 386 null object\ndata.info()","63aed736":"#Lets chech Type 2\ndata[\"Type 2\"].value_counts(dropna =False)","63767e7c":"#Lets drop nan values (delete)\ndata1 = data   # also we will use data to fill missing value so I assign it to data1 variable\ndata1['Type 2'].dropna(inplace = True) # inplace = True means we do not assign it to new variable. Changes automatically assigned to data","53b07d89":"# Assert statement:\nassert 1==1   # return nothing because it is true","2be04388":"# False so give me error\n#assert 1==2","39b951e5":"assert data['Type 2'].notnull().all()  # returns nothing because we drop nan values","83ddb48d":"data[\"Type 2\"].fillna('empty',inplace=True)","26fec6ce":"assert data['Type 2'].notnull().all()  # returns nothing because we do not have nan values","0171cab5":"<a id=\"5\"><\/a> <br>\n### TIDY DATA\nWe tidy data with melt().\nDescribing melt is confusing. Therefore lets make example to understand it.","cb43af5b":"<a id=\"4\"><\/a> <br>\n### VISUAL EXPLORATORY DATA ANALYSIS\n* Box plots: A data set shows five summaries. At least minimum, first quarter, median, third quarter and maximum.","b64d8fb1":"What we learned at the end of this chapter:\n* Diagnose data for cleaning\n* Exploratory data analysis\n* Visual exploratory data analysis\n* Tidy data\n* Pivoting data\n* Concatenating data\n* Data types\n* Missing data and testing with assert","d8450083":"**Content:**\n1. [Cleaning Data](#1)\n    1. [Diagnose data for cleaning](#2)\n    1. [Exploratory data analysis](#3)\n    1. [Visual exploratory data analysis](#4)\n    1. [Tidy data](#5)\n    1. [Pivoting data](#6)\n    1. [Concatenating data](#7)\n    1. [Data types](#8)\n    1. [Missing data and testing with assert](#9)","4536e070":"<a id=\"3\"><\/a> <br>\n### EXPLORATORY DATA ANALYSIS\nvalue_counts(): Frequency counts\n<br>outliers: the value that is considerably higher or lower from rest of the data\n* Lets say value at 75% is Q3 and value at 25% is Q1. \n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n<br>We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\n<br> What is quantile?\n\n* 1,3,4,5,8,9,10,12,13,17,18,21,23\n* The median is the number that is in **middle** of the sequence. In this case it would be 10.\n\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 10, which is 4.\n* The upper quartile, you find the median between the median and the largest number i.e. between 10 and 23, which will be 17 according to the question above.","33dceda5":"<a id=\"7\"><\/a> <br>\n### CONCATENATING DATA\nWe can concatenate two dataframe ","fe3eb9e8":"<a id=\"6\"><\/a> <br>\n### PIVOTING DATA\nReverse of melting.","d6d946ca":"<a id=\"2\"><\/a> <br>\n### DIAGNOSE DATA for CLEANING\nWe need to diagnose and clean data before exploring.\n<br>Unclean data:\n* Column name inconsistency like upper-lower case letter or space between words\n* missing data\n* different language\n\n<br> We will use head, tail, columns, shape and info methods to diagnose data","3494ffbe":"<a id=\"8\"><\/a> <br>\n### DATA TYPES\nData types: object(string),boolean,  integer, float and categorical.\n<br> We can make conversion data types like from str to categorical or from int to float\n<br> Why is category important: \n* make dataframe smaller in memory \n* can be utilized for anlaysis especially for sklear(we will learn later)","b5503e90":"<a id=\"9\"><\/a> <br>\n### MISSING DATA and TESTING WITH ASSERT\nIf we encounter with missing data, what we can do:\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean\n<br>Assert statement: check that you can turn on or turn off when you are done with your testing of the program","808b2633":"<a id=\"1\"><\/a> <br>\n# 1.CLEANING DATA"}}