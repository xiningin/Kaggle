{"cell_type":{"7c3ae598":"code","7c9dc923":"code","5fb1a690":"code","8a4eb0f8":"code","02b337d2":"code","f7ddb568":"code","db32578e":"code","1bee6310":"code","3d888fa3":"code","1229a123":"code","08a64597":"code","4fba791e":"code","4c124850":"code","47e5cb3f":"code","2dcc2463":"code","13ed7701":"code","fc8b77fa":"code","8fe7dc0c":"code","d74f8044":"code","717802b4":"code","82ab6322":"code","ed10917f":"code","4975fec4":"code","6b3d6fc3":"code","58f8ad51":"code","0c91eaa0":"code","f8f03c06":"code","cbecfc32":"code","5d321cf5":"code","d3a97030":"code","21696602":"code","6aeaec9f":"code","ae9cc6ab":"code","bc3e15ed":"code","a33a53de":"code","03c0bf7f":"code","9050b112":"code","a82dac34":"code","1e36f692":"markdown","c0877b71":"markdown","c80fc05b":"markdown","9e0c753a":"markdown","8a36cacd":"markdown","07d0c417":"markdown","8125b396":"markdown","40070462":"markdown","16065811":"markdown","a9afd0e7":"markdown"},"source":{"7c3ae598":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","7c9dc923":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        print(_)\n        print(filename)\n        print(dirname)\ntrain_df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ncombine = [train_df, test_df]","5fb1a690":"# preview the data\ntrain_df.head()","8a4eb0f8":"train_df.info()\nprint('_'*40)\ntest_df.info()","02b337d2":"train_df.describe()\n# Review survived rate using `percentiles=[.61, .62]` knowing our problem description mentions 38% survival rate.\n# Review Parch distribution using `percentiles=[.75, .8]`\n# SibSp distribution `[.68, .69]`\n# Age and Fare `[.1, .2, .3, .4, .5, .6, .7, .8, .9, .99]`","f7ddb568":"train_df.describe(include=['O'])","db32578e":"sns.heatmap(train_df.corr(), annot=True)","1bee6310":"a = sns.FacetGrid(train_df, col='Pclass')\na.map(plt.hist, 'Survived', alpha=.5, bins=20)\ntrain_df[['Pclass','Survived']].groupby(['Pclass'],as_index=False).mean().sort_values(by='Survived',ascending=False)","3d888fa3":"b = sns.FacetGrid(train_df, hue='Survived')\nb.map(plt.hist, 'Age', alpha=.5, bins=20)\nb.add_legend()","1229a123":"c = sns.FacetGrid(train_df, col='Survived')\nc.map(plt.hist, 'SibSp', Alpha=.5, bins=20)\nc.add_legend()\ntrain_df[['SibSp','Survived']].groupby(['SibSp'],as_index=False).mean().sort_values(by='Survived',ascending=False)","08a64597":"c = sns.FacetGrid(train_df, col='Survived')\nc.map(plt.hist, 'Parch', Alpha=.5, bins=20)\nc.add_legend()\ntrain_df[['Parch','Survived']].groupby(['Parch'],as_index=False).mean().sort_values(by='Survived',ascending=False)","4fba791e":"c = sns.FacetGrid(train_df, hue='Survived')\nc.map(plt.hist, 'Fare', Alpha=.5, bins=40)\nc.add_legend()","4c124850":"for dataset in combine:\n    dataset['Title']=dataset['Name'].str.extract('([A-Za-z]+)\\.',expand=False)\npd.crosstab(train_df['Title'], train_df['Survived'])","47e5cb3f":"pd.crosstab(train_df['Title'], train_df['Sex'])","2dcc2463":"title_group = train_df[['Title','Age']].groupby(['Title'],as_index=False).mean()\nfor ind in title_group.index:\n    for dataset in combine:\n        dataset.loc[(dataset.Age.isnull())&(dataset.Title==title_group.loc[ind,'Title']),'Age']=title_group.loc[ind,'Age']\ntrain_df.info()","13ed7701":"c = sns.FacetGrid(train_df)\nc.map(sns.barplot, 'Sex', 'Survived', alpha = 0.5)\nc.add_legend()","fc8b77fa":"c = sns.FacetGrid(train_df, col='Sex')\nc.map(sns.barplot, 'Embarked', 'Survived', alpha = 0.5)\nc.add_legend()","8fe7dc0c":"passenger = test_df['PassengerId']\ntrain_df = train_df.drop(['Ticket','Cabin', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Ticket', 'Cabin', 'PassengerId'], axis=1)\ncombine = [train_df, test_df]","d74f8044":"nu = train_df[train_df['Embarked'].isnull()]\nnu.head()","717802b4":"dd = sns.FacetGrid(train_df,col='Pclass')\ndd.map(sns.barplot,'Embarked','Fare',alpha=.5)\ndd.add_legend()","82ab6322":"train_df.loc[train_df['Embarked'].isnull(),'Embarked'] = 'C'","ed10917f":"train_df.info()","4975fec4":"for dataset in combine:\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\ntrain_df.describe()","6b3d6fc3":"for dataset in combine:\n    dataset.loc[ dataset['SibSp'] <= 0, 'SibSp'] = 0\n    dataset.loc[(dataset['SibSp'] > 0) & (dataset['SibSp'] <= 2), 'SibSp'] = 1\n    dataset.loc[(dataset['SibSp'] > 2) & (dataset['SibSp'] <= 4), 'SibSp'] = 2\n    dataset.loc[ dataset['SibSp'] > 4, 'SibSp'] = 3\ntrain_df.describe()","58f8ad51":"for dataset in combine:\n    dataset.loc[ dataset['Parch'] <= 0, 'Parch'] = 0\n    dataset.loc[(dataset['Parch'] > 0) & (dataset['Parch'] <= 3), 'Parch'] = 1\n    dataset.loc[(dataset['Parch'] > 3) & (dataset['Parch'] <= 6), 'Parch'] = 2\n    dataset.loc[ dataset['Parch'] > 6, 'Parch'] = 4\ntrain_df.describe()","0c91eaa0":"train_df['FareBand'] = pd.cut(train_df['Fare'], 100)\naaa = train_df[['FareBand','Survived']].groupby('FareBand',as_index=False).sum()\nbbb = train_df[['FareBand','Survived']].groupby('FareBand',as_index=False).count()\nccc=pd.DataFrame(columns=['FareBand','rate'])\nccc['FareBand'] = aaa['FareBand']\nccc['rate'] = aaa['Survived'] \/ bbb['Survived']\nccc.sort_values(by='rate').head(10)","f8f03c06":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 5, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 5) & (dataset['Fare'] <= 10), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 10) & (dataset['Fare'] <= 15), 'Fare'] = 2\n    dataset.loc[ dataset['Fare'] > 15, 'Fare'] = 3\ntrain_df = train_df.drop(['FareBand'],axis=1)\ntrain_df.head()","cbecfc32":"train_df[['Title','Age']].groupby('Title',as_index=False).mean()","5d321cf5":"pd.crosstab(train_df['Title'],train_df['Sex'],)","d3a97030":"combine=[train_df,test_df]\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Capt','Don','Jonkheer','Rev'],'staff')\n    dataset['Title'] = dataset['Title'].replace(['Col','Major','Dr'],'Sir')\n    dataset['Title'] = dataset['Title'].replace(['Countess','Lady'],'Mrs')\n    dataset['Title'] = dataset['Title'].replace(['Mlle','Mme','Ms'],'Miss')\ntrain_df.head()","21696602":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\ntrain_df.head()","6aeaec9f":"for dataset in combine:\n    dataset.loc[dataset.Sex=='male','Sex'] = 0\n    dataset.loc[dataset.Sex=='female','Sex'] = 1\ntrain_df.head()","ae9cc6ab":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\ntrain_df.head()","bc3e15ed":"test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\ntest_df['Embarked'].fillna(test_df['Embarked'].dropna().median(), inplace=True)\ntrain_df.head()","a33a53de":"train_df = train_df.drop(['Name'],axis=1)\ntest_df = test_df.drop(['Name'],axis=1)","03c0bf7f":"X_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test = test_df","9050b112":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)","a82dac34":"submission = pd.DataFrame({\n        \"PassengerId\": passenger,\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('\/kaggle\/working\/submission.csv', index=False)","1e36f692":"**Which features contain blank, null or empty values?**\n\n**What are the data types for various features?**","c0877b71":"## Analyze by pivoting features\n\nTo confirm some of our observations and assumptions, we can quickly analyze our feature correlations by pivoting features against each other. We can only do so at this stage for features which do not have any empty values. It also makes sense doing so only for features which are categorical (Sex), ordinal (Pclass) or discrete (SibSp, Parch) type.\n\n- **Pclass** We observe significant correlation (>0.5) among Pclass=1 and Survived (classifying #3). We decide to include this feature in our model.\n- **Sex** We confirm the observation during problem definition that Sex=female had very high survival rate at 74% (classifying #1).\n- **SibSp and Parch** These features have zero correlation for certain values. It may be best to derive a feature or a set of features from these individual features (creating #1).","c80fc05b":"**What is the distribution of numerical feature values across the samples?**","9e0c753a":"## Acquire data","8a36cacd":"- Categorical: Survived, Sex, and Embarked. Ordinal: Pclass.\n- Continous: Age, Fare. Discrete: SibSp, Parch.","07d0c417":"# Titanic Data Science Solutions\n\n## Workflow stages\n\nThe competition solution workflow goes through seven stages described in the Data Science Solutions book.\n\n1. Question or problem definition.\n2. Acquire training and testing data.\n3. Wrangle, prepare, cleanse the data.\n4. Analyze, identify patterns, and explore the data.\n5. Model, predict and solve the problem.\n6. Visualize, report, and present the problem solving steps and final solution.\n7. Supply or submit the results.\n\n## Question and problem definition\n\n> Knowing from a training set of samples listing passengers who survived or did not survive the Titanic disaster, can our model determine based on a given test dataset not containing the survival information, if these passengers in the test dataset survived or not.","8125b396":"### Assumtions based on data analysis","40070462":"**Which features are mixed data types?**\n\nNumerical, alphanumeric data within same feature. These are candidates for correcting goal.\n\n**Which features may contain errors or typos?**","16065811":"## Analyze by describing data","a9afd0e7":"**What is the distribution of categorical features?**"}}