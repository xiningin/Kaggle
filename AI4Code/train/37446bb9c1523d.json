{"cell_type":{"dd83ade2":"code","9bd0083f":"code","bf52da03":"code","3211789f":"code","5d5df91c":"code","2639572f":"code","1e9098fc":"code","ddd22b5c":"markdown","b04576db":"markdown","99792e7a":"markdown","ad032752":"markdown","09ba9979":"markdown"},"source":{"dd83ade2":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# GaussianMixture\nfrom sklearn.mixture import GaussianMixture\n\n# PCA - use for plot\nfrom sklearn.decomposition import PCA\n\n#ignore warning messages \nimport warnings\nwarnings.filterwarnings('ignore') ","9bd0083f":"# Get data \ntrain = pd.read_csv(\"..\/input\/train.csv\")\n\n# Splite data the X - Our data , and y - the prdict label\nX = train.drop('label',axis = 1)\ny = train['label'].astype('category')\n\nX.head()","bf52da03":"dataset = X[y == 6].reset_index().drop(\"index\",axis = 1)\n\nplt.figure(figsize = (10,8))\nrow, colums = 3, 3\nfor i in range(9):  \n    plt.subplot(colums, row, i+1)\n    plt.imshow(dataset.iloc[i].values.reshape(28,28),interpolation='nearest', cmap='Greys')\nplt.show()","3211789f":"# Im use PCA to set dematntion into 2D (for plot)\n# and use GMM to plot the Gaussian probability distributions\n\npca = PCA(n_components = 2)\ndataset_2D = pca.fit_transform(dataset)\n\ngmm = GaussianMixture(n_components=2)\ngmm.fit(dataset_2D)\n\nplt.figure(figsize = (10,8))\n\n# plot GMM center and classes\nplt.subplot(2, 1, 1)\nplt.scatter(dataset_2D[:,0], dataset_2D[:,1], c = gmm.predict(dataset_2D))\nplt.scatter(gmm.means_[:, 0], gmm.means_[:,1])\nplt.title(\"GMM center and classes\")\n\n# plot GMM center and score\nplt.subplot(2, 1, 2)\nplt.scatter(dataset_2D[:,0], dataset_2D[:,1], c = gmm.score_samples(dataset_2D))\nplt.scatter(gmm.means_[:, 0], gmm.means_[:,1])\nplt.title(\"GMM center and score\")\n\nplt.show()","5d5df91c":"n_components = [10,20,30,40,50]\naics = []\nfor n in n_components:\n    print(n) # just for progress print \n    model = GaussianMixture(n, covariance_type='full', random_state=0)\n    aics.append(model.fit(dataset).aic(dataset))\nplt.plot(n_components, aics);","2639572f":"n_components = 20 # selected by AIC\n\ngmm = GaussianMixture(n_components=n_components)\ngmm.fit(dataset)","1e9098fc":"plt.figure(figsize = (10,8))\nrow, colums = 3, 3\nfor i in range(9):  \n    plt.subplot(colums, row, i+1)\n    toShow = gmm.sample()[0]\n    plt.imshow(toShow.reshape(28,28),interpolation='nearest', cmap='Greys')\nplt.show()","ddd22b5c":"Create GMM model and fit","b04576db":"When we try to create new samples from GMM, We try to take data that look closes to the GMM means (centers)","99792e7a":"After we have an GMM train, we can use sample() func for create new data","ad032752":"Check the AIC  as a function as the number of GMM components for dataset:  [Akaike information criterion (AIC)](https:\/\/en.wikipedia.org\/wiki\/Akaike_information_criterion)","09ba9979":"A Gaussian mixture model (GMM) attempts to find a mixture of multi-dimensional Gaussian probability distributions that best model any input dataset\n\nYou can read more about it in [widipedia](https:\/\/en.wikipedia.org\/wiki\/Mixture_model#General_mixture_model) and [sklrean](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.mixture.GaussianMixture.html)"}}