{"cell_type":{"b9e96f48":"code","21546ccb":"code","7d5f749d":"code","a578ebc4":"code","81b57d65":"code","300028ee":"code","6bd701cd":"code","0b6be48a":"code","ba91803d":"code","0bf90d04":"code","64da9241":"code","67e9cec8":"code","81ccc95a":"code","5c534651":"code","0377f604":"code","da05c1c8":"code","8b625727":"code","fbe24fab":"code","d9e96c2c":"code","7c402fb3":"code","d7d5257d":"code","33b59b1e":"code","b898e090":"code","487dd398":"code","f685de1f":"code","d6e1062d":"code","541b78fe":"code","9442df8c":"code","0dd718c0":"code","9baaf625":"code","6860932d":"code","d751696d":"code","87801f5d":"code","4d093d64":"code","8dcee2d8":"code","7b514f95":"code","a3f60713":"code","7f18cba2":"code","ed1c4da5":"code","3096b0a6":"code","7e3e057a":"code","07486932":"code","290a9a75":"code","c1d7c337":"code","aca45f6e":"code","f1676745":"code","9c2f2afb":"code","dfd0a9c5":"code","0404cbc4":"markdown","2a7891e5":"markdown","7c73019a":"markdown","e09fbd55":"markdown","6420ad5f":"markdown"},"source":{"b9e96f48":"import pandas as pd\nimport numpy as np\n# ^^^ pyforest auto-imports - don't write above this line","21546ccb":"import plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt","7d5f749d":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","a578ebc4":"path_train = '..\/input\/crop-recommendation-dataset\/Crop_recommendation.csv'\ndata = pd.read_csv(path_train)","81b57d65":"data.info()","300028ee":"data","6bd701cd":"data['label'].value_counts()","0b6be48a":"data.rename(columns={'N':'nitrogen','P':'phosphorus','K':'potassium'}, inplace=True)","ba91803d":"data.isnull().sum()","0bf90d04":"data_copy = data.round()","64da9241":"label_map = {j:i for i,j in enumerate(data['label'].unique())}","67e9cec8":"data_copy['label'] = data['label'].replace(label_map)","81ccc95a":"data_copy['potassium_bin'] = pd.cut(data_copy['potassium'],bins = 20)\ndata_copy['potassium_bin'] = data_copy['potassium_bin'].apply(lambda x : str(x))","5c534651":"data_copy['phosphorus_bin'] = pd.cut(data_copy['phosphorus'],bins = 7)\ndata_copy['phosphorus_bin'] = data_copy['phosphorus_bin'].apply(lambda x : str(x))","0377f604":"data_copy['nitrogen_bin'] = pd.cut(data_copy['nitrogen'],bins = 7)\ndata_copy['nitrogen_bin'] = data_copy['nitrogen_bin'].apply(lambda x : str(x))","da05c1c8":"data_copy['humidity_bin'] = pd.cut(data_copy['humidity'],bins = 8)\ndata_copy['humidity_bin'] = data_copy['humidity_bin'].apply(lambda x : str(x))","8b625727":"data_copy['temperature_bin'] = pd.cut(data_copy['temperature'],bins = 7)\ndata_copy['temperature_bin'] = data_copy['temperature_bin'].apply(lambda x : str(x))","fbe24fab":"data_copy['rainfall_bin'] = pd.cut(data_copy['rainfall'],bins = 9)\ndata_copy['rainfall_bin'] = data_copy['rainfall_bin'].apply(lambda x : str(x))","d9e96c2c":"data_copy['label_'] = data['label']","7c402fb3":"fig = px.parallel_categories(data_copy[['label_','potassium_bin','phosphorus_bin','nitrogen_bin','ph']],color_continuous_scale= px.colors.sequential.Inferno)\nfig.show()\n","d7d5257d":"fig = px.parallel_categories(data_copy[['label_','humidity_bin','temperature_bin','rainfall_bin']])\nfig.show()\n","33b59b1e":"y = data.round().groupby('label').agg((['min', 'max']))\ny","b898e090":"x = pd.DataFrame(columns=data.columns[:-1])\ndf = data.round()\n\nfor label in data['label'].unique():\n    data_ = df[df['label'] == label].iloc[:,:-1]\n    \n    for i, col in enumerate(x.columns):\n        max_ = data_[col].max()\n        min_ = data_[col].min()\n\n        x.loc[label,col] = f'{min_} - {max_}'","487dd398":"x","f685de1f":"data","d6e1062d":"data['label_map'] = data['label'].replace(label_map)\ndata = data.round()","541b78fe":"X = data.drop(columns = ['label','label_map'])\n\nY = data['label_map']","9442df8c":"def check_mutlicolinearity(data_x):\n    corr = data_x.corr()\n    corr = pd.DataFrame(np.tril(corr, k=-1),      # gets Lower triangular matrix\n                        columns=data_x.columns,\n                        index=data_x.columns)  \n\n    corr = corr.replace(0.000000, np.NAN)\n    count_of_total_correlation_values = corr.count().sum()\n\n    for i in [0.5, 0.6, 0.7, 0.8, 0.9]:\n        data_corr = corr[abs(corr) > i]\n        count_greater_than_thresh = data_corr.count().sum()\n        print(f'Percent Values Greater than {i} co-relation : {count_greater_than_thresh\/count_of_total_correlation_values}')\n    return corr","0dd718c0":"def plot_corr( corr,threshold = 0.5):\n    data_corr = corr[abs(corr) > threshold]\n    sns.heatmap(data_corr, annot=True, cmap=\"YlGnBu\")\n    plt.show()","9baaf625":"corr = check_mutlicolinearity(X)","6860932d":"import seaborn as sns\nplot_corr(corr)","d751696d":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif","87801f5d":"fs = SelectKBest(score_func=f_classif, k='all')\nfs.fit(X, Y)","4d093d64":"fig = px.bar(x = X.columns, y =fs.scores_, template = 'plotly_dark',log_y=True)  ## Log-Graph\nfig.show()","8dcee2d8":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, random_state = 0)","7b514f95":"from sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LogisticRegression\nimport statsmodels.api as sm\nfrom sklearn.ensemble import RandomForestClassifier","a3f60713":"from sklearn.tree import DecisionTreeClassifier","7f18cba2":"from sklearn.metrics import classification_report,hamming_loss,roc_auc_score,confusion_matrix","ed1c4da5":"def base_estimator(x_train, x_test, y_train, y_test,est = LogisticRegression):\n#     x_train, x_test, y_train, y_test = train_test_split(data_X,data_Y,random_state = 0)\n    \n    if est == LogisticRegression:\n        mod = est(random_state=0, multi_class = 'ovr', max_iter = 200)\n        mod.fit(x_train.values, y_train.values)\n    \n    else:    \n        mod = est(random_state=0)\n        mod.fit(x_train.values, y_train.values)\n\n    y_train_predict = mod.predict(x_train)\n    y_test_predict = mod.predict(x_test)\n    \n    print(classification_report(y_train,y_train_predict))\n    \n    print('-'*50)\n    print(classification_report(y_test,y_test_predict))\n    ","3096b0a6":"base_estimator(x_train, x_test, y_train, y_test, LogisticRegression )","7e3e057a":"base_estimator(x_train, x_test, y_train, y_test, RandomForestClassifier )","07486932":"base_estimator(x_train, x_test, y_train, y_test, DecisionTreeClassifier )","290a9a75":"model = LogisticRegression(random_state=0,n_jobs=-1, multi_class='ovr', max_iter=200)\nmodel.fit(x_train, y_train)","c1d7c337":"y_predict_logit = model.predict(x_test)\nprint(classification_report(y_test,y_predict_logit,target_names = label_map.keys() ))","aca45f6e":"### params Checking","f1676745":"import plotly.graph_objs as go\n","9c2f2afb":"df_coeff = pd.DataFrame(model.coef_, columns = X.columns, index = label_map.keys())\n# df_coeff['intercept'] = model.intercept_ # uncomment to use intercept also\n\nfig = go.Figure()\ncols = df_coeff.columns\nfor index in df_coeff.index:\n    fig.add_trace(go.Scatter(y = df_coeff.loc[index,:].values, x = cols,\n                    mode='lines',\n                    name= index))\nfig.update_layout(template = 'plotly_dark')\nfig.show()","dfd0a9c5":"from sklearn.tree import DecisionTreeClassifier, export_graphviz\nfrom sklearn import tree\nfrom IPython.display import SVG\nfrom graphviz import Source\nfrom IPython.display import display                               \nfrom ipywidgets import interactive\n\nlab = data['label'].unique()\nlabels = X.columns\ndef plot_tree(crit, split, depth, min_split, min_leaf=1):\n    estimator = DecisionTreeClassifier(random_state = 0 \n          , criterion = crit\n          , splitter = split\n          , max_depth = depth\n          , min_samples_split=min_split\n          , min_samples_leaf=min_leaf)\n    estimator.fit(X, Y)\n    graph = Source(tree.export_graphviz(estimator\n          , out_file=None\n          , feature_names=labels\n          , class_names=lab\n          , filled = True))\n\n    display(SVG(graph.pipe(format='svg')))\n    return estimator\n\ninter=interactive(plot_tree \n   , crit = [\"gini\", \"entropy\"]\n   , split = [\"best\", \"random\"]\n   , depth=[None, 1,2,3,4]\n   , min_split=[2,1.0,0.5,0.1]\n   , min_leaf=[1,2,0.1,0.5,])\ndisplay(inter)","0404cbc4":"#### Feature_Selection","2a7891e5":"#### ","7c73019a":"### Models","e09fbd55":"#### Multi-colinearity","6420ad5f":"### Process"}}