{"cell_type":{"fb116652":"code","f7ceeb39":"code","7bcb7368":"code","0fb70339":"code","19eec435":"code","6418d8df":"code","b2cf3cce":"code","7a5303b3":"code","c8254127":"code","0e7f48dd":"code","a2a02fd7":"code","de86ca33":"code","4e5cb9fc":"code","bd97ec45":"code","6a742b20":"code","256b7907":"code","7910935c":"code","693683ad":"code","1c366db3":"code","18f50096":"code","99d4d08c":"code","d9741a43":"code","bd3847ee":"code","e1a93b90":"code","c0349559":"code","55f15d87":"markdown","e5f5c4e0":"markdown","67a60ef0":"markdown","58912afe":"markdown","ebaade3b":"markdown"},"source":{"fb116652":"# Built-in packages\nimport json\n\n# Third party packages\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom imblearn.over_sampling import SMOTE\n\n# Charting options\nsns.set(context= \"notebook\", color_codes=True)\n%matplotlib inline","f7ceeb39":"df = pd.read_csv(\"\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\")\ncol_names = df.columns[:-1]\ntarget_col = [\"DEATH_EVENT\"]\nnum_cols = [\"age\", \"creatinine_phosphokinase\", \"ejection_fraction\", \"platelets\" , \"serum_creatinine\", \"serum_sodium\" , \"time\"]\nbin_cols = [\"high_blood_pressure\", \"sex\", \"smoking\", \"anaemia\", \"diabetes\"]\ndf.head()","7bcb7368":"# Check if any of the columns have null values\nprint(df.isnull().sum())","0fb70339":"df_summary = df.describe()\ndf.describe()","19eec435":"def draw_axvlines(plt, col):\n    mean = df_summary.loc[\"mean\", col]\n    q1 = df_summary.loc[\"25%\", col]\n    q2 = df_summary.loc[\"50%\", col]\n    q3 = df_summary.loc[\"75%\", col]\n    plt.axvline(mean, color = \"g\");              # Plotting a line to mark the mean \n    plt.axvline(q1, color = \"b\");                # Plotting a line to mark Q1 \n    plt.axvline(q2, color = \"navy\");             # Plotting a line to mark Q2 \n    plt.axvline(q3, color = \"purple\");           # Plotting a line to mark Q3\n    plt.legend({\"Mean\": mean, \"25%\" : q1, \"50%\" : q2, \"75%\" : q3});\n\nfig, axes = plt.subplots(5, 2, figsize = (20,20));\nfig.suptitle('Distribution charts for Age, Experience and income.');\n\n\n# Create boxplot to show distribution of Age\nsns.boxplot(df[\"age\"], ax = axes[0][0], color = \"mediumslateblue\");\naxes[0][0].set(xlabel = 'Distribution of Age');\n\npp = sns.distplot(df[\"age\"], ax = axes[0][1], bins = 10, color = \"mediumslateblue\");\naxes[0][1].set(xlabel = 'Distribution of Age');\ndraw_axvlines(pp, \"age\");\n\n\n# Create boxplot to show distribution of creatinine_phosphokinase\nsns.boxplot(df[\"creatinine_phosphokinase\"], ax = axes[1][0], color = \"mediumslateblue\");\naxes[1][0].set(xlabel = 'Distribution of creatinine_phosphokinase');\n\npp = sns.distplot(df[\"creatinine_phosphokinase\"], ax = axes[1][1], bins = 10, color = \"mediumslateblue\");\naxes[1][1].set(xlabel = 'Distribution of creatinine_phosphokinase');\ndraw_axvlines(pp, \"creatinine_phosphokinase\")\n\n\n# Create boxplot to show distribution of platelets\nsns.boxplot(df[\"platelets\"], ax = axes[2][0], color = \"mediumslateblue\");\naxes[2][0].set(xlabel = 'Distribution of platelets');\n\npp = sns.distplot(df[\"platelets\"], ax = axes[2][1], color = \"mediumslateblue\");\naxes[2][1].set(xlabel = 'Distribution of platelets');\ndraw_axvlines(pp, \"platelets\")\n\n\n# Create boxplot to show distribution of serum_creatinine\nsns.boxplot(df[\"serum_creatinine\"], ax = axes[3][0], color = \"mediumslateblue\");\naxes[3][0].set(xlabel = 'Distribution of serum_creatinine');\n\npp = sns.distplot(df[\"serum_creatinine\"], ax = axes[3][1], color = \"mediumslateblue\");\naxes[3][1].set(xlabel = 'Distribution of serum_creatinine');\ndraw_axvlines(pp, \"serum_creatinine\")\n\n# Create boxplot to show distribution of ejection_fraction\nsns.boxplot(df[\"ejection_fraction\"], ax = axes[4][0], color = \"mediumslateblue\");\naxes[4][0].set(xlabel = 'Distribution of ejection_fraction');\n\npp = sns.distplot(df[\"ejection_fraction\"], ax = axes[4][1], color = \"mediumslateblue\");\naxes[4][1].set(xlabel = 'Distribution of ejection_fraction');\ndraw_axvlines(pp, \"ejection_fraction\")","6418d8df":"# A function that returns value counts for a column split by personal_loan\ndef groupby_get_cc_count(tdf, col):\n    tdf = tdf.groupby([col, \"DEATH_EVENT\"])[\"DEATH_EVENT\"].count().reset_index(level = 0)\n    tdf.columns = [col, \"count\"]\n    tdf = tdf.reset_index()\n    return tdf","b2cf3cce":"fig, axes = plt.subplots(1, 3, figsize = (20,5));\n\nfor ix, i in enumerate([\"high_blood_pressure\", \"sex\", \"smoking\"]):\n    xx = groupby_get_cc_count(df[[i, \"DEATH_EVENT\"]], i)\n    sns.barplot(xx[i], xx[\"count\"], hue = xx[\"DEATH_EVENT\"], palette = \"cividis\", ax = axes[ix]);\n    \nfig, axes = plt.subplots(1, 2, figsize = (20,5));\n\nfor ix, i in enumerate([\"anaemia\", \"diabetes\"]):\n    xx = groupby_get_cc_count(df[[i, \"DEATH_EVENT\"]], i)\n    sns.barplot(xx[i], xx[\"count\"], hue = xx[\"DEATH_EVENT\"], palette = \"cividis\", ax = axes[ix]);","7a5303b3":"sns.scatterplot(x = \"time\", y = \"serum_sodium\", data = df[[\"serum_sodium\", \"time\", \"DEATH_EVENT\"]], hue = \"DEATH_EVENT\");","c8254127":"xx = df[target_col[0]].value_counts().reset_index()\nsns.barplot(x = \"index\", y = \"DEATH_EVENT\", data=xx, palette = \"cividis\");","0e7f48dd":"col_names = list(df.columns)\ncol_names.remove(target_col[0])\n\nX = df[col_names]\ny = df[target_col[0]]\n\noversample = SMOTE()\nX, y = oversample.fit_resample(X, y)\n\n\ndf = pd.concat([pd.DataFrame(X), pd.DataFrame(y)], axis=1)\ndf.columns = col_names + target_col\ndf","a2a02fd7":"xx = df[target_col[0]].value_counts().reset_index()\nsns.barplot(x = \"index\", y = \"DEATH_EVENT\", data=xx, palette = \"cividis\");","de86ca33":"df_train = df","4e5cb9fc":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nstd = StandardScaler()\n\nscaled = std.fit_transform(df[num_cols])     # Standardize the columns to get them on the same scale\nscaled = pd.DataFrame(scaled, columns=num_cols)\n\ndf_train = pd.concat([scaled, df[bin_cols + target_col]], axis=1)\n\ndf_train.head()","bd97ec45":"plt.figure(figsize=(15,10))\nsns.heatmap(df_train.corr(), annot=True, fmt='.2g');","6a742b20":"from sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\nmodel = ExtraTreesClassifier()\n\ncol_names = list(df_train.columns)\ncol_names.remove(target_col[0])\n\nX = df_train[col_names]\ny = df_train[target_col[0]]\n\nmodel.fit(X,y)\nprint(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n#plot graph of feature importances for better visualization\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(10).plot(kind='barh')\nplt.show()","256b7907":"col_names = ['age', \"serum_creatinine\", \"serum_sodium\", \"ejection_fraction\", \"time\"]\nX = df_train[col_names]      # Contains the independent columns \ny = df_train[target_col]     # Our target column","7910935c":"from sklearn.model_selection import train_test_split\n\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\ntrain_y = train_y[target_col[0]]\ntest_y = test_y[target_col[0]]","693683ad":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport collections\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, accuracy_score\nconf_matrix_all = {}\na = []\ndef death_event_prediction(name, algo, training_x, testing_x, training_y, testing_y, plot) :\n    global a\n    algo.fit(training_x,training_y)                           # Fit the training data set to the algorithm passed.\n    predictions = algo.predict(testing_x)                     # Get all predictions\n    probabilities = algo.predict_proba(testing_x)             # Get probablities of predictions\n\n    conf_matrix = confusion_matrix(testing_y, predictions)    # Get confusion matrix using the predictions\n    tn, fp, fn, tp = conf_matrix.ravel()\n    \n    conf_matrix_all[name] = conf_matrix                       # Save confusion matrix values to a dictionary\n    a = conf_matrix    \n    \n    print(\"Classification report:\")                           # Print the classification report\n    print(classification_report(testing_y, predictions))\n  \n    model_roc_auc = roc_auc_score(testing_y, predictions)           # Get the Area under the curve number\n    fpr,tpr,thresholds = roc_curve(testing_y, probabilities[:,1])   # Get False postive rate and true positive rate\n\n    print (\"Area under the curve: \", model_roc_auc)\n    print(accuracy_score(testing_y, predictions))\n    \n    if plot:\n        fig, axes = plt.subplots(1,2, figsize=(25, 5))\n        conf_matrix = np.flip(conf_matrix)\n        \n        conf_2 = conf_matrix.astype(str)\n        labels = np.array([['\\nTP','\\nFN'],['\\nFP','\\nTN']])\n        labels = np.core.defchararray.add(conf_2, labels)\n        sns.heatmap(conf_matrix, fmt='', annot = labels, ax=axes[0], cmap=\"YlGnBu\", xticklabels=[1, 0], yticklabels=[1, 0]);                                           # Plot the confusion matrix\n        axes[0].set(xlabel='Predicted', ylabel='Actual')\n\n        plt.title('Receiver Operating Characteristic')\n        sns.lineplot(fpr, tpr, ax=axes[1])                                         # Plot the ROC curve\n        plt.plot([0, 1], [0, 1],'--')                                              # Plot the diagonal line\n        axes[1].set_xlim([0, 1])                                                   # Set x-axis limit to 0 and 1\n        axes[1].set_ylim([0, 1])                                                   # Set y-axis limit to 0 and 1\n        axes[1].set(xlabel = 'False Positive Rate', ylabel = 'True Positive Rate');\n        plt.show();","1c366db3":"lr  = LogisticRegression(C=1e2, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, penalty=\"l2\")\n\ndeath_event_prediction(\"Logistic Regression\", lr, train_X, test_X, train_y, test_y, plot = True)","18f50096":"knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric=\"manhattan\", metric_params=None, n_neighbors = 10, weights='distance')\n\ndeath_event_prediction(\"K-nearest Neighbors\", knn, train_X, test_X, train_y, test_y, plot=True)","99d4d08c":"svc = SVC(C=2.0, kernel='linear', degree= 2, gamma=1.0, random_state=None,\n          coef0=0.0, shrinking=True, probability=True,tol=0.001,\n          cache_size=200, class_weight=None, verbose=False,max_iter= -1)\n\ndeath_event_prediction(\"Support Vector Classifier\", svc, train_X, test_X, train_y, test_y, plot=True)","d9741a43":"dtc = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=10, min_samples_split=2, \n                             min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, \n                             random_state=None, max_leaf_nodes=None, min_impurity_decrease=0, \n                             min_impurity_split=None, class_weight=None, presort='deprecated', ccp_alpha=0.0)\n\ndeath_event_prediction(\"Decision Tree\", dtc, train_X, test_X, train_y, test_y, plot=True)","bd3847ee":"rfc = RandomForestClassifier(n_estimators = 100, max_depth = 15, criterion = \"entropy\", \n                               min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', \n                               max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, \n                               bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, \n                               warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n\ndeath_event_prediction(\"Random Forest\", rfc,train_X,test_X,train_y,test_y, plot=True) ","e1a93b90":"from xgboost import XGBClassifier\n\nxgc = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n                        colsample_bytree=1, gamma=0, learning_rate=0.2, max_delta_step=0,\n                        max_depth = 16, min_child_weight=1, missing=None, n_estimators=100,\n                        objective='binary:logistic', random_state=0, reg_alpha=0, reg_lambda=1, \n                        scale_pos_weight=1, subsample=1)\n\ndeath_event_prediction(\"XGBoost\", xgc, train_X, test_X, train_y, test_y, plot=True)","c0349559":"import math\nfig, axes = plt.subplots(2,3, figsize = (20, 12))\n\ncnt = 0\nfor r in range(2):\n    for c in range(3):\n        try:\n            conf_matrix = np.flip(list(conf_matrix_all.values())[cnt])\n            conf_2 = conf_matrix.astype(str)\n            labels = np.array([['\\nTP','\\nFN'],['\\nFP','\\nTN']])\n            labels = np.core.defchararray.add(conf_2, labels)\n            \n            sns.heatmap(conf_matrix, fmt='', annot = labels, ax=axes[r, c], cmap=\"YlGnBu\", xticklabels=[1, 0], yticklabels=[1, 0]);\n            axes[r, c].set(title=list(conf_matrix_all.keys())[cnt])\n            cnt += 1\n        except:\n            pass","55f15d87":"As suspected, all the four columns have a lot of outliers.","e5f5c4e0":"### Import all necessary libraries","67a60ef0":"### SMOTE (Synthetic Minority Oversampling Technique) for balancing data","58912afe":"### Read the dataset","ebaade3b":"Looking at the max and Q3 value, it seems like there are a few outlier in the columns **creatinine_phosphokinase**, **ejection_fraction**, **platelets** and **serum_creatinine**"}}