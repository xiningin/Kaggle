{"cell_type":{"629c8a8f":"code","0294fb25":"code","c9fc7660":"code","685a847e":"code","ec699a0f":"code","8f014b38":"code","768e9b70":"code","4baa731b":"code","8f81bc31":"code","038650ea":"code","ac300928":"code","fef5268b":"code","1049f4d0":"code","287696bf":"code","9c87c035":"code","32bdad6f":"code","64e23e90":"code","2b445a9e":"code","a0c04782":"code","29e10659":"code","3d7d0a22":"code","d0bedf97":"code","b67f9aa4":"code","309e8647":"code","a85bb546":"code","117bb72c":"code","b9813dcb":"code","393f0bae":"code","61cbf567":"code","35cf3443":"code","ba8f8082":"code","8f544636":"code","00c297e6":"code","a34b7507":"code","126c33c0":"markdown","4775f071":"markdown","3bc3d0a8":"markdown","864f9af6":"markdown"},"source":{"629c8a8f":"%%capture\n!pip install pycaret[full]","0294fb25":"import pandas as pd\nimport numpy as np \nfrom pycaret.regression import *","c9fc7660":"train = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv',index_col='row_id')\ntest = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv',index_col='row_id')","685a847e":"gdp_df = pd.read_csv('..\/input\/gdp-data\/GDP_data_2015_to_2019_Finland_Norway_Sweden.csv')","ec699a0f":"amazon = pd.read_csv('..\/input\/amazonn\/multiTimeline (2).csv')\ntemp = amazon.index.tolist()\namzn = []\nfor i in range(1,len(temp)):\n    amzn.append([temp[i][0],temp[i][1],temp[i][2],amazon.iloc[i,0]])","8f014b38":"swed = {}\nfinl = {}\nnorw = {}","768e9b70":"for i in range(len(amzn)):\n    if (amzn[i][0][:4],amzn[i][0][5:7]) not in swed:\n        swed[(int(amzn[i][0][5:7]),int(amzn[i][0][:4]))] = amzn[i][1]\n        finl[(int(amzn[i][0][5:7]),int(amzn[i][0][:4]))] = amzn[i][2]\n        norw[(int(amzn[i][0][5:7]),int(amzn[i][0][:4]))] = amzn[i][3]\n    ","4baa731b":"finl","8f81bc31":"gdp_df.columns = ['year', 'Finland', 'Norway', 'Sweden']\n\ngdp_df = pd.melt(gdp_df, id_vars=['year'], value_vars=['Finland', 'Norway', 'Sweden'], var_name='country', value_name='gdp')\ngdp_df['year'] = 'Y' + gdp_df['year'].astype(str)","038650ea":"def pre_process(df):\n    \n    df['date'] = pd.to_datetime(df['date'])\n    df['week']= df['date'].dt.week\n    df['month'] = df['date'].dt.month\n    df['year'] = 'Y'+df['date'].dt.year.astype(str)\n    df['quarter'] = 'Q'+df['date'].dt.quarter.astype(str)\n    df['day'] = df['date'].dt.day\n    df['dayofyear'] = df['date'].dt.dayofyear\n    df.loc[(df.date.dt.is_leap_year) & (df.dayofyear >= 60),'dayofyear'] -= 1\n    df['weekend'] = df['date'].dt.weekday >=5\n    df['weekday'] = 'WD' + df['date'].dt.weekday.astype(str)\n    #df['Newyear'] = 0\n    #df.loc[(df.date.dt.dayofyear >= 300 ) | (df.date.dt.dayofyear <30)]['Newear'] = 1\n    #df['Newyearb'] = df['dayofyear'] > 300\n    #df['Newyeara'] = df['dayofyear'] < 30\n    df.drop(columns=['date'],inplace=True)\n\npre_process(train)\npre_process(test)\n\n#combining GDP Dataset\ntrain = train.merge(gdp_df, how='left', on=['year', 'country'])\ntest = test.merge(gdp_df, how='left', on=['year', 'country'])\n\n#initialize new column for amazon data\ntrain['amazon'] = 0\ntest['amazon'] = 0\n\nfor i in range(len(train)):\n    if train.iloc[i,0] == 'Sweden':\n        train.amazon.iloc[i] = int(swed[(int(train.iloc[i]['month']),int(train.iloc[i]['year'][1:]))]) \n    elif train.iloc[i,0] == 'Finland':\n        train.amazon.iloc[i] = int(finl[(int(train.iloc[i]['month']),int(train.iloc[i]['year'][1:]))]) \n    elif train.iloc[i,0] == 'Norway':\n        train.amazon.iloc[i] = int(norw[(int(train.iloc[i]['month']),int(train.iloc[i]['year'][1:]))]) \n\n        \n        \nfor i in range(len(test)):\n    if test.iloc[i,0] == 'Sweden':\n        test.amazon.iloc[i] = int(swed[(int(test.iloc[i]['month']),int(test.iloc[i]['year'][1:]))])\n    elif test.iloc[i,0] == 'Finland':\n        test.amazon.iloc[i] = int(finl[(int(test.iloc[i]['month']),int(test.iloc[i]['year'][1:]))])\n    elif test.iloc[i,0] == 'Norway':\n        test.amazon.iloc[i] = int(norw[(int(test.iloc[i]['month']),int(test.iloc[i]['year'][1:]))]) \n","ac300928":"train['amazon'] = train['amazon'].astype('int') \ntest['amazon'] = test['amazon'].astype('int') \ntrain.info(), test.info()","fef5268b":"train.head()","1049f4d0":"impactcalc = {}\n\nfor i in range(len(train)):\n    if (train.country.iloc[i],train.year.iloc[i],train.iloc[i,2], train.store.iloc[i]) not in impactcalc:\n        impactcalc[(train.country.iloc[i],train.year.iloc[i],train.iloc[i,2], train.store.iloc[i])] = [train.num_sold.iloc[i]]\n    else:\n        impactcalc[(train.country.iloc[i],train.year.iloc[i],train.iloc[i,2], train.store.iloc[i])].append(train.num_sold.iloc[i])","287696bf":"impact_mean = {}\nfor i in impactcalc.keys():\n    impact_mean[i] = sum(impactcalc[i])\/len(impactcalc[i])","9c87c035":"impact_mean\ntrain['impact'] = 0\nfor i in range(len(train)):\n    train.impact.iloc[i] = train.num_sold.iloc[i]\/impact_mean[(train.country.iloc[i],train.year.iloc[i],train.iloc[i,2], train.store.iloc[i])]","32bdad6f":"lastyear = {}\nfor i in range(len(train)):\n    if (train.country.iloc[i],'Y'+str(int(str(train.year.iloc[i])[1:])+1),train.iloc[i,2], train.store.iloc[i], train.iloc[i,9]) in lastyear:\n        print(\"oops\", (train.country.iloc[i],train.year.iloc[i],train.iloc[i,2], train.store.iloc[i], train.iloc[i,9]))\n    lastyear[(train.country.iloc[i],'Y'+str(int(str(train.year.iloc[i])[1:])+1),train.iloc[i,2], train.store.iloc[i], train.iloc[i,9])] = train.impact.iloc[i]","64e23e90":"train.head()","2b445a9e":"# Credit to https:\/\/www.kaggle.com\/c\/web-traffic-time-series-forecasting\/discussion\/36414\ndef SMAPE(y_true, y_pred):\n    denominator = (np.abs(y_true) + np.abs(y_pred)) \/ 2.0\n    diff = np.abs(y_true - y_pred) \/ denominator\n    diff[denominator == 0] = 0.0\n    if np.mean(diff)>10:\n        return 4*np.mean(diff)\n    return np.mean(diff)","a0c04782":"detail_impact = {}\nfor i in range(len(train)):\n    if (train.country.iloc[i],train.year.iloc[i],train.iloc[i,2], train.store.iloc[i], train.iloc[i,9]) in detail_impact:\n        print(\"oops\", (train.country.iloc[i],train.year.iloc[i],train.iloc[i,2], train.store.iloc[i], train.iloc[i,9]))\n    detail_impact[(train.country.iloc[i],train.year.iloc[i],train.iloc[i,2], train.store.iloc[i], train.iloc[i,9])] = train.impact.iloc[i]","29e10659":"detail_impact","3d7d0a22":"testimp = {}\nstartidx = 0\nfor i in range(len(train)):\n    if train.year.iloc[i] == 'Y2015':\n        startidx = i\n    else:\n        train.impact.iloc[i] = lastyear[(train.country.iloc[i],train.year.iloc[i],train.iloc[i,2], train.store.iloc[i],train.iloc[i,9])]\n        #train.impact.iloc[i] = detail_impact[(train.country.iloc[i],'Y'+str(int(str(train.year.iloc[i])[1:])-1),train.iloc[i,2], train.store.iloc[i],train.iloc[i,9])]","d0bedf97":"test['impact'] = 0\nfor i in range(len(test)):\n    test.impact.iloc[i] = lastyear[(test.country.iloc[i],test.year.iloc[i],test.iloc[i,2], test.store.iloc[i],test.iloc[i,8])]\n    #test.impact.iloc[i] = detail_impact[(test.country.iloc[i],'Y2018',test.iloc[i,2], test.store.iloc[i],test.iloc[i,8])] * 1.05","b67f9aa4":"test.head()","309e8647":"reg = setup(data = train.iloc[0:],\n            target = 'num_sold',\n      transform_target=True,\n      transform_target_method='box-cox',  # https:\/\/www.statisticshowto.com\/box-cox-transformation\/\n      silent=True,\n      feature_interaction = True,\n      normalize=True,\n      normalize_method='maxabs',\n      session_id = 42,  # It is equivalent to 'random_state' in scikit-learn.\n      data_split_shuffle = False,  # When set to False, prevents shuffling of rows during 'train_test_split'.\n      fold=10,\n           use_gpu=True)","a85bb546":"models(internal=True)[['Name', 'GPU Enabled']]\n#tuned_dt_skopt = tune_model(dt, search_library = 'scikit-optimize')","117bb72c":"add_metric('SMAPE', 'SMAPE', SMAPE, greater_is_better = False)\ntop =compare_models(sort = 'SMAPE',n_select = 2)","b9813dcb":"evaluate_model(lgbm)","393f0bae":"lgbm =compare_models(sort = 'SMAPE',include=['lightgbm'])\nrf =compare_models(sort = 'SMAPE',include=['rf'])","61cbf567":"blend = blend_models(top)\npredict_model(blend)","35cf3443":"final_blend = finalize_model(blend)\npredict_model(final_blend)","ba8f8082":"preds = predict_model(final_blend, data=test)\nsub = pd.DataFrame(list(zip(test.index,preds.Label)),columns = ['row_id', 'num_sold'])\nfor i in range(len(sub)):\n    sub.iloc[i,0] = i+26298\nsub.to_csv('submission1.csv', index = False)\nprint(sub.head(),sub.describe())","8f544636":"sub.to_csv('submission36.csv', index = False)\nprint(sub.head(),sub.describe())","00c297e6":"preds = predict_model(lgbm, data=test)\nsub1 = pd.DataFrame(list(zip(test.index,preds.Label)),columns = ['row_id', 'num_sold'])\npreds = predict_model(rf, data=test)\nsub2 = pd.DataFrame(list(zip(test.index,preds.Label)),columns = ['row_id', 'num_sold'])\nfor i in range(len(sub1)):\n    sub1.iloc[i,0] = i+26298\n    sub1.iloc[i,1] = (sub1.iloc[i,1]+sub2.iloc[i,1])\/2\nsub1.to_csv('combination1.csv', index = False)\nprint(sub1.head(),sub1.describe())","a34b7507":"preds = predict_model(lgbm, data=test)\nsub1 = pd.DataFrame(list(zip(test.index,preds.Label)),columns = ['row_id', 'num_sold'])\nfor i in range(len(sub1)):\n    sub1.iloc[i,0] = i+26298\nsub1.to_csv('lgbm.csv', index = False)\nprint(sub1.head(),sub1.describe())","126c33c0":"Creating Monthly sales Activity country ,( Month, Year ) wise and saving it in hashmap.. Working on Daily sales Activity currently using Amazon's sales activity only","4775f071":"Using Amazon's sales activity along with GDP --- Ensemble Model","3bc3d0a8":"Based on amazon's sales activity during that period adding it to our test and train Data","864f9af6":"GDP Dataset Year wise for Finaland, Norway and Sweden"}}