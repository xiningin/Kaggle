{"cell_type":{"49f341cd":"code","b586153d":"code","d0b871a1":"code","ad16da72":"code","cf63f1a1":"code","fc961069":"code","6e198231":"code","1442d6bc":"code","868ffbf2":"code","12cbd032":"code","79e9d9cd":"code","2407b512":"code","cd064c74":"code","c4e7cf6c":"code","98c5eb82":"code","a66773c3":"code","2fdcd3a5":"code","7047861f":"code","9061b9f1":"code","cb48579f":"code","f9d0c7b6":"code","8bc371c3":"code","c071dcc4":"code","61676b13":"code","7ba6092c":"code","a45c9b4e":"code","1b2d03ec":"code","4c3168b5":"code","3dec2419":"code","ddbe2976":"code","6c8406ce":"code","69e76b9a":"code","061efbf4":"code","0f0223f1":"code","db781b5d":"code","5cf02389":"code","ba455b90":"code","9d5c53e1":"markdown","1983d005":"markdown","6d0d2f09":"markdown","ec38678a":"markdown","7efcddc3":"markdown","b6b02cc8":"markdown","3531a3cf":"markdown","5d90cd80":"markdown","6ff43622":"markdown","4b9bff93":"markdown"},"source":{"49f341cd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b586153d":"train_path = \"\/kaggle\/input\/digit-recognizer\/train.csv\"\ntest_path = \"\/kaggle\/input\/digit-recognizer\/test.csv\"\nsample_submission_path = \"\/kaggle\/input\/digit-recognizer\/sample_submission.csv\"","d0b871a1":"train = pd.read_csv(train_path)\ntest = pd.read_csv(test_path)\nsample_submission = pd.read_csv(sample_submission_path)","ad16da72":"train.head(3)","cf63f1a1":"test.head(3)","fc961069":"sample_submission.head(3)","6e198231":"import torch\nfrom torchvision.transforms import Normalize \nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom tqdm.notebook import tqdm","1442d6bc":"class LoadImagesLabels(Dataset):\n    def __init__(self, data_frame, stats = None, kind=\"train\"):\n        self.stats = stats\n        self.kind = kind\n        self.imgs, self.labels = self.get_data(data_frame)\n        \n    def get_data(self, data_frame):\n        imgs = np.zeros(shape=(data_frame.shape[0], 1, 28, 28), dtype=np.float32)\n        labels = None\n        \n        if self.kind != \"test\":\n            labels = np.zeros(shape=(data_frame.shape[0]), dtype=np.int64)\n            \n        for idx, row in tqdm(data_frame.iterrows(), total=data_frame.shape[0],\n                            desc=\"Extracting images and labels\"):\n            list_row = row.tolist()\n            \n            if self.kind != \"test\":\n                labels[idx] = int(list_row[0])\n                imgs[idx, :] = np.asarray(list_row[1:], dtype=np.float32).reshape(1, 28, 28)\n            else:\n                imgs[idx, :] = np.asarray(list_row, dtype=np.float32).reshape(1, 28, 28)\n                \n        if self.stats is None:\n            self.stats = {\"mean\": (imgs.reshape(-1, 1, 28**2)\/255.0).mean(2).sum(0)\/imgs.shape[0], \n                          \"std\": (imgs.reshape(-1, 1, 28**2)\/255.0).std(2).sum(0)\/imgs.shape[0]}\n            # Create stats\n            self.create_stats_dataset()\n        else:\n            self.normalize = Normalize(mean=self.stats[\"mean\"], std=self.stats[\"std\"])\n            \n        return imgs, labels\n    \n    def create_stats_dataset(self):\n        self.normalize = Normalize(mean=self.stats[\"mean\"], std=self.stats[\"std\"])\n        self.unormalize = Normalize(mean=-self.stats[\"mean\"]\/self.stats[\"std\"], std=1\/self.stats[\"std\"])\n        \n    def __len__(self):\n        return len(self.imgs)\n    \n    def __getitem__(self, idx):\n        if self.labels is None:\n            return self.normalize(torch.from_numpy(self.imgs[idx]\/255.0))\n        else:\n            return self.normalize(torch.from_numpy(self.imgs[idx]\/255.0)), torch.tensor(self.labels[idx], dtype=torch.int64)","868ffbf2":"dataset = LoadImagesLabels(train)\ntrain_dataset, val_dataset = random_split(dataset,\n                                          [int(len(dataset)*0.7), len(dataset)-int(len(dataset)*0.7)])\ntest_dataset = LoadImagesLabels(test, dataset.stats, \"test\")","12cbd032":"import matplotlib.pyplot as plt\nimport random","79e9d9cd":"def plot_some_samples(data, unormalize, k=10, nrows=3, kind=\"train\"):\n    \n    k = k + (nrows - k%nrows)\n    ncols = k\/\/3\n    \n    random_choices = random.sample(range(len(data)), k)\n    fig, axs = plt.subplots(nrows, ncols, figsize=(10, 5), tight_layout=True)\n    \n    nrow_i, ncol_j = 0, 0\n    \n    for sample_idx in random_choices:\n        label = None\n        if kind != \"test\":\n            img, label = data[sample_idx]\n        else:\n            img = data[sample_idx]\n        ground_truth = \"no hay\" if label is None else \"number: \" + str(label.item())\n        \n        axs[nrow_i, ncol_j].imshow(unormalize(img).numpy().squeeze(), \n                                   cmap=\"gray\")\n        axs[nrow_i, ncol_j].set_title(ground_truth)\n        axs[nrow_i, ncol_j].set_axis_off()\n            \n        if ncol_j >= ncols - 1:\n            nrow_i += 1\n            ncol_j = 0\n        else:\n            ncol_j += 1\n \n    plt.show()","2407b512":"plot_some_samples(train_dataset, dataset.unormalize, kind=\"train\")","cd064c74":"plot_some_samples(val_dataset, dataset.unormalize, kind=\"val\")","c4e7cf6c":"plot_some_samples(test_dataset, dataset.unormalize, kind=\"test\")","98c5eb82":"import multiprocessing\ntrain_dataloader = DataLoader(train_dataset, num_workers=multiprocessing.cpu_count(), shuffle=True, batch_size=2**6)\nval_dataloader = DataLoader(val_dataset, num_workers=multiprocessing.cpu_count(), shuffle=False, batch_size=8)","a66773c3":"import torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport pytorch_lightning as pl\nfrom torchvision import models\nimport pytorch_lightning.callbacks as pl_callbacks","2fdcd3a5":"class ClassificationModel(pl.LightningModule):\n    def __init__(self, learning_rate, weights=None):\n        super(ClassificationModel, self).__init__()\n        self.learning_rate = learning_rate\n        self.loss = nn.CrossEntropyLoss(weight=weights)\n        pretrained_resnet = models.resnet18(pretrained=True)\n        self.encoder = nn.Sequential(\n            nn.Upsample(size=(224, 224), mode='bilinear', align_corners=True),\n            nn.Conv2d(in_channels=1, out_channels=3, kernel_size=1),\n            nn.BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False),\n            pretrained_resnet\n        )\n        self.decoder = nn.Sequential(\n            nn.ReLU(inplace=True),\n            nn.Linear(in_features=1000, out_features=10)\n        )\n        \n    def configure_optimizers(self):\n        return optim.Adam(self.parameters(), lr=(self.learning_rate))\n    \n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n    \n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        y_pred = self(x)\n        loss = self.loss(y_pred, y)\n        self.log(\"train_loss\", loss, on_epoch=True, \n                 prog_bar=True, logger=False)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        y_pred = self(x)\n        loss = self.loss(y_pred, y)\n        self.log(\"val_loss\", loss, on_epoch=True, \n                 prog_bar=True, logger=False)","7047861f":"model = ClassificationModel(1e-4)\n\ntrainer = pl.Trainer(gpus=1, max_epochs=100)\n\n# Run learning rate finder\nlr_finder = trainer.tuner.lr_find(model, train_dataloader, val_dataloader)\n\n# Results can be found in\nlr_finder.results\n\n# Plot with\nfig = lr_finder.plot(suggest=True)\nfig.show()\n\n# Pick point based on plot, or get suggestion\nnew_lr = lr_finder.suggestion()\n\n# update hparams of the model\nmodel.learning_rate = new_lr","9061b9f1":"# Fit model\ntrainer.fit(model, train_dataloader, val_dataloader)","cb48579f":"train_accuracy = pl.metrics.Accuracy(compute_on_step=False)\nvalid_accuracy = pl.metrics.Accuracy(compute_on_step=False)\ntrain_predictions, train_real = [], []\nvalid_predictions, valid_real = [], []\n\nmodel.eval()\nmodel.cuda()\n\nfor x, y in tqdm(train_dataloader):\n    with torch.no_grad():\n        y_pred = model(x.cuda())\n    train_accuracy(y_pred.cpu(), y)\n    train_predictions += (list(y_pred.argmax(dim=1).cpu()))\n    train_real += list(y)\n\nfor x, y in tqdm(val_dataloader):\n    with torch.no_grad():\n        y_pred = model(x.cuda())\n    valid_accuracy(y_pred.cpu(), y)\n    valid_predictions += (list(y_pred.argmax(dim=1).cpu()))\n    valid_real += list(y)\n    \n# total accuracy over all training batches\ntotal_train_accuracy = train_accuracy.compute()\n\n# total accuracy over all validation batches\ntotal_valid_accuracy = valid_accuracy.compute()","f9d0c7b6":"print(\"training accuracy\", round(total_train_accuracy.item() * 100, 3), \"%\")\nprint(\"validation accuracy\", round(total_valid_accuracy.item() * 100, 3), \"%\")","8bc371c3":"valid_real = [v.item() for v in valid_real]\nvalid_predictions = [v.item() for v in valid_predictions]\ntrain_real = [v.item() for v in train_real]\ntrain_predictions = [v.item() for v in train_predictions]\n","c071dcc4":"from sklearn.metrics import confusion_matrix\n\nvalid_matrix = confusion_matrix(valid_real, valid_predictions, labels=range(10))\ntrain_matrix = confusion_matrix(train_real, train_predictions, labels=range(10))","61676b13":"def plot_matrix(matrix):\n    import seaborn as sns\n    group_counts = [\"{0:0.0f}\\n\".format(value).strip() for value in matrix.flatten()]\n    group_counts = np.asarray(group_counts).reshape(matrix.shape[0],matrix.shape[1])\n\n    sns.heatmap(matrix, annot=group_counts, fmt=\"\", cmap=\"Blues\")\n    plt.ylabel(\"GROUND TRUTH\")\n    plt.xlabel(\"PREDICTION\")\n    plt.show()","7ba6092c":"plot_matrix(valid_matrix)","a45c9b4e":"plot_matrix(train_matrix)","1b2d03ec":"fail_images = []\nreal_labels, fail_labels = [], []\nfor x, y in tqdm(val_dataloader):\n    with torch.no_grad():\n        y_pred = model(x.cuda())\n    y_pred = y_pred.argmax(dim=1).cpu()\n    mask = (y_pred == y).numpy()\n    idxs = np.where(mask == False)[0]\n    if idxs.shape[0] > 0:\n        for idx in idxs:\n            fail_images.append(x[idx])\n            real_labels.append(y[idx].item())\n            fail_labels.append(y_pred[idx].item())\n            \nfail_images = dataset.unormalize(torch.stack(fail_images, dim=0))","4c3168b5":"def plot_fail_images(fail_images, real_labels, fail_labels):\n    idx_images = random.sample(range(len(real_labels)), 10)\n    fig, axs = plt.subplots(5, 2, figsize=(14, 9), tight_layout=True)\n    for idx_plot, ax in enumerate(axs):\n        ax[0].imshow(fail_images[idx_plot].squeeze(), cmap=\"gray\")\n        ax[0].set_title(\"real: \" + str(real_labels[idx_plot]) + \", predict: \" + str(fail_labels[idx_plot]))\n        ax[0].set_axis_off()\n        \n        ax[1].imshow(fail_images[idx_plot + len(axs)].squeeze(), cmap=\"gray\")\n        ax[1].set_title(\"real: \" + str(real_labels[idx_plot + len(axs)]) + \", predict: \" + str(fail_labels[idx_plot + len(axs)]))\n        ax[1].set_axis_off()\n        \n    plt.show()","3dec2419":"plot_fail_images(fail_images, real_labels, fail_labels)","ddbe2976":"model.to_torchscript(\"\/kaggle\/working\/mnist_digit.torch.pt\")","6c8406ce":"sample_submission.head(3)","69e76b9a":"submission = sample_submission.copy()","061efbf4":"model.eval()\n\npredicted_labels = []\nfor idx, img in tqdm(enumerate(test_dataset), total=len(test_dataset)):\n    with torch.no_grad():\n        y_predict = model(img.unsqueeze(0).cuda())\n    predicted_labels.append(y_predict.argmax(dim=1).cpu().item()) ","0f0223f1":"submission.head()","db781b5d":"submission[\"Label\"] = predicted_labels\nsubmission.to_csv('\/kaggle\/working\/submission.csv',index=False)","5cf02389":"stats = dataset.stats\nstats = {'mean': [float(m) for m in stats['mean']], 'std': [float(std) for std in list(stats['std'])]}","ba455b90":"import json\n\njson.dump(stats, open('\/kaggle\/working\/stats.json', 'w'))","9d5c53e1":"# Model","1983d005":"# Submit prediction","6d0d2f09":"# Save stats","ec38678a":"# Create Datasets","7efcddc3":"# Read csv files","b6b02cc8":"# Make some interpretability","3531a3cf":"# Confussion matrix","5d90cd80":"# Show some images","6ff43622":"# Save model","4b9bff93":"# Metrics accuracy"}}