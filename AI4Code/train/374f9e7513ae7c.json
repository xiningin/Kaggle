{"cell_type":{"07525154":"code","9b0d4c77":"code","18fd9e22":"code","ad670cc5":"code","b9db0280":"code","f4b9508b":"code","4d8ee252":"code","0fc132cc":"code","59595a25":"code","80fda876":"code","f7ceeb16":"markdown","3271c847":"markdown","f59ebdcd":"markdown"},"source":{"07525154":"!pip install git+https:\/\/github.com\/tensorflow\/docs","9b0d4c77":"import warnings; warnings.filterwarnings('ignore')\nimport pandas as pd,numpy as np,tensorflow as tf\nimport h5py,imageio,os\nimport seaborn as sn,pylab as pl\nfrom keras.preprocessing import image as kimage\nfrom tensorflow_docs.vis import embed\nfrom tqdm import tqdm\nfrom PIL import ImageFile\nImageFile.LOAD_TRUNCATED_IMAGES=True \nfpath='..\/input\/child-and-adult-emotions\/'","18fd9e22":"def path_to_tensor(img_path,fpath=fpath):\n    img=kimage.load_img(fpath+img_path, \n                        target_size=(160,160))\n    x=kimage.img_to_array(img)\n    return np.expand_dims(x,axis=0)\ndef paths_to_tensor(img_paths):\n    tensor_list=[path_to_tensor(img_path) \n                 for img_path in tqdm(img_paths)]\n    return np.vstack(tensor_list)\ndef plcmap(cmap,n):\n    return [pl.cm.get_cmap(cmap)(i\/n)[:3] \n            for i in range(1,n+1)]\ndef animate(images):\n    converted_images=np.clip(images*255,0,255)\\\n    .astype(np.uint8)\n    imageio.mimsave('animation.gif',converted_images)\n    return embed.embed_file('animation.gif')\ndef interpolate_hypersphere(v1,v2,steps):\n    v1norm=tf.norm(v1)\n    v2norm=tf.norm(v2)\n    v2normalized=v2*(v1norm\/v2norm)\n    vectors=[]\n    for step in range(steps):\n        interpolated=v1+(v2normalized-v1)*step\/(steps-1)\n        interpolated_norm=tf.norm(interpolated)\n        interpolated_normalized=\\\n        interpolated*(v1norm\/interpolated_norm)\n        vectors.append(interpolated_normalized)\n    return tf.stack(vectors)","ad670cc5":"catlabels1=['adult','child']\ncatlabels2=['serious','sad','glad']\nflist=sorted(os.listdir(fpath))\nlabels1=np.array([int(el[:2]) for el in flist],\n               dtype='int32')-1\nlabels2=np.array([int(el[3:5]) for el in flist],\n               dtype='int32')-1\nimages=np.array(paths_to_tensor(flist),\n                dtype='float32')\/255\nN=labels1.shape[0]; n=int(.2*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(12).shuffle(shuffle_ids)\nimages=images[shuffle_ids]\nlabels1,labels2=\\\nlabels1[shuffle_ids],labels2[shuffle_ids]\nx_test,x_train=images[:n],images[n:]\ny_test1,y_train1=labels1[:n],labels1[n:]\ny_test2,y_train2=labels2[:n],labels2[n:]","b9db0280":"pd.DataFrame([[x_train.shape,x_test.shape],\n              [x_train.dtype,x_test.dtype],\n              [y_train1.shape,y_test1.shape],\n              [y_train1.dtype,y_test1.dtype],\n              [y_train2.shape,y_test2.shape],\n              [y_train2.dtype,y_test2.dtype]],               \n             columns=['train','test'])\n","f4b9508b":"with h5py.File('ChildAdultImages.h5','w') as f:\n    f.create_dataset('train_images',data=x_train)\n    f.create_dataset('train_labels1',data=y_train1)\n    f.create_dataset('train_labels2',data=y_train2)\n    f.create_dataset('test_images',data=x_test)\n    f.create_dataset('test_labels1',data=y_test1)\n    f.create_dataset('test_labels2',data=y_test2)\nos.stat('ChildAdultImages.h5')","4d8ee252":"set(labels1),set(labels2)","0fc132cc":"pl.figure(figsize=(10,5))\ndata=np.array([labels1,labels2]).T\ndata=pd.DataFrame(data,\\\ncolumns=['adult-child','emotions'])\nsn.countplot(x='emotions',hue='adult-child',\n             data=data,palette=\"Pastel2\")\npl.title('Emotion Distribution',fontsize=20);","59595a25":"n=np.random.randint(10)\nprint('Label1: ',y_test1[n],catlabels1[y_test1[n]])\nprint('Label2: ',y_test2[n],catlabels2[y_test2[n]])\npl.figure(figsize=(3,3))\npl.imshow((x_test[n]));","80fda876":"imgs=interpolate_hypersphere(x_test[1],x_test[2],180)\nanimate(imgs)","f7ceeb16":"## Data Processing","3271c847":"## Code Modules","f59ebdcd":"## Data Representation"}}