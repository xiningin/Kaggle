{"cell_type":{"04f4963f":"code","96cc703a":"code","93039c4b":"code","86513a32":"code","5b4d34ea":"code","2997509a":"code","2fe79942":"code","e3071ccb":"code","2c90bce7":"code","3ed9ad3c":"code","c1a542c5":"code","f13cfad4":"code","74c0fd04":"code","72cff788":"code","e00bdd24":"code","d44ffbc7":"code","16306313":"code","138bc0b8":"code","f90ed93f":"code","329badbc":"code","073b2747":"markdown","3459b393":"markdown","b9fcae2c":"markdown","513cd590":"markdown","f2336904":"markdown","30fa1e61":"markdown","108b5a4e":"markdown","2c6690e7":"markdown","b7111532":"markdown","8262ac66":"markdown","be7abdc4":"markdown","ccebd248":"markdown","f60fa283":"markdown","4ac8f5e2":"markdown","9cd5cba5":"markdown"},"source":{"04f4963f":"import pandas as pd\n\nimport matplotlib.pyplot as plt\n\nimport scikitplot as skplt\n\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report \nfrom sklearn.linear_model import SGDClassifier\n\nfrom sklearn.svm import SVC","96cc703a":"# Read csv file into dataframe\ndf = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\n\nY = df['DEATH_EVENT']\nX = df[['age', 'ejection_fraction','serum_creatinine','time']]\nX.head()","93039c4b":"import seaborn as sns\n\n# Heatmap to Invertigate Correlation in Data\nsns.set()\nfig, ax = plt.subplots(figsize=(9, 6))\nsns.heatmap(df.corr(), linewidths=.5, ax=ax, cmap='Blues')\n\nplt.show()","86513a32":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify = Y, test_size=0.2, random_state=52)\n\nprint('Shape of X_train:', X_train.shape)\nprint('Shape of X_test:', X_test.shape)\nprint('Shape of Y_train:', Y_train.shape)\nprint('Shape of Y_test:', Y_test.shape)","5b4d34ea":"# Changing the kernel function\n\nkernels = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]","2997509a":"report_listt = []\n\ni = 1\nfor k in kernels:\n    print(\"Model\",i,\"with Kernel =\", k)\n    i = i + 1\n    model = SVC(kernel= k, C = .01)\n    model.fit(X_train, Y_train)\n\n    Y_predict = model.predict(X_test)\n    \n    report = classification_report(Y_test, Y_predict, output_dict=True)\n    report_listt.append(report)\n    \n    print(classification_report(Y_test, Y_predict))","2fe79942":"import matplotlib.pyplot as plt\n\ny_prec = []\ny_rec = []\n\nfor i in range(len(kernels)):\n    y_prec.append(report_listt[i]['macro avg']['precision'])\n    y_rec.append(report_listt[i]['macro avg']['recall'])\n    \nfor i in range(len(kernels)):\n    print(\"Kernel -\",kernels[i],\" :: Avg Accuracy -\", y_prec[i])\n    \n# creating the bar plot \nplt.plot(kernels, y_prec)\nplt.title(\"Kernels) vs Average Precision\")\nplt.xlabel(\"Kernels\")\nplt.ylabel(\"Average Precision\")\nplt.savefig(\"kernels_svm1.png\")\nplt.show()","e3071ccb":"# Change values of c to identify the best model.\n\nclistt = [10, 1, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.01, 0.001]\n\nreport_listt = []\n\ni = 1\nfor c in clistt:\n    print(\"Model\",i,\"with C =\", c)\n    i = i + 1\n    model = SVC(kernel='linear', C = c)\n    model.fit(X_train, Y_train)\n\n    Y_predict = model.predict(X_test)\n    \n    report = classification_report(Y_test, Y_predict, output_dict=True)\n    report_listt.append(report)\n    \n    print(classification_report(Y_test, Y_predict))\n    ","2c90bce7":"import matplotlib.pyplot as plt\n\ny_prec = []\n\nfor i in range(len(report_listt)):\n    y_prec.append(report_listt[i]['macro avg']['precision'])\n    \nfor i in range(len(clistt)):\n    print(\"C(Regularization parameter) -\",clistt[i],\" :: Avg Accuracy -\", y_prec[i])\n","3ed9ad3c":"# creating the line plot \nplt.plot(clistt, y_prec)\nplt.title(\"C(Regularization parameter) vs Average Precision\")\nplt.xlabel(\"C(Regularization parameter)\")\nplt.ylabel(\"Average Precision\")\nplt.savefig(\"c_svm.png\")\nplt.show()","c1a542c5":"# Change values of gamma to identify the best model.\n\nglistt = [1, 0.1, 0.01, 0.001, 0.0001]\n\nreport_listt = []\n\ni = 1\nfor g in glistt:\n    print(\"Model\",i,\"with gamma =\", g)\n    i = i + 1\n    model = SVC(kernel='linear', gamma = g)\n    model.fit(X_train, Y_train)\n\n    Y_predict = model.predict(X_test)\n    \n    report = classification_report(Y_test, Y_predict, output_dict=True)\n    report_listt.append(report)\n    \n    print(classification_report(Y_test, Y_predict))","f13cfad4":"import matplotlib.pyplot as plt\n\ny_prec = []\n\nfor i in range(len(report_listt)):\n    y_prec.append(report_listt[i]['macro avg']['precision'])\n    \nfor i in range(len(glistt)):\n    print(\"Gamma (Kernel coefficient) -\",glistt[i],\" :: Avg Accuracy -\", y_prec[i])","74c0fd04":"# creating the bar plot \nplt.plot(glistt, y_prec)\nplt.title(\"Gamma (Kernel coefficient) vs Average Precision.\")\nplt.xlabel(\"Gamma (Kernel coefficient)\")\nplt.ylabel(\"Average Precision\")\nplt.savefig(\"gamma_svm.png\")\nplt.show()","72cff788":"# Best model is for  C  =  0.2\nfrom sklearn.metrics import accuracy_score\n\nmodel = SVC(kernel='linear', C = .2)\nmodel.fit(X_train, Y_train)\n\nY_predict = model.predict(X_test)\n\nskplt.metrics.plot_confusion_matrix(Y_test, Y_predict, figsize=(4,4), \n                                title='Confusion Matrix: SVM',\n                                normalize=True,\n                                cmap='Blues')\n\ns1 = accuracy_score(Y_test, Y_predict)\ns1","e00bdd24":"print(classification_report(Y_test, Y_predict))","d44ffbc7":"# from sklearn.model_selection import GridSearchCV \n  \n# # defining parameter range \n# param_grid = {'C': [0.01, 0.1, 0.2, 0.5, 1, 10, 100, 1000],  \n#               'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n#               'kernel': ['rbf', 'linear', 'poly', 'sigmoid']}  \n  \n# grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n  \n# # fitting the model for grid search \n# grid.fit(X_train, Y_train)","16306313":"# # print best parameter after tuning \n# print(grid.best_params_) \n  \n# # print how our model looks after hyper-parameter tuning \n# print(grid.best_estimator_)","138bc0b8":"model = SVC(kernel='poly', C = 0.001, gamma = 0.01)\nmodel.fit(X_train, Y_train)\n\nY_predict = model.predict(X_test)\n\nskplt.metrics.plot_confusion_matrix(Y_test, Y_predict, figsize=(6,6), \n                                    title='Confusion Matrix: SVM',\n                                    normalize=True,\n                                    cmap='Blues')\n\ns1 = accuracy_score(Y_test, Y_predict)\n\nplt.show()\ns1","f90ed93f":"report = classification_report(Y_test, Y_predict)\nprint(report)","329badbc":"model = SVC(kernel='poly', C = 0.001, gamma = 0.01)\nmodel.fit(X_train, Y_train)\n\nY_predict = model.predict(X_test)\n\nskplt.metrics.plot_confusion_matrix(Y_test, Y_predict, figsize=(6,6), \n                                    title='Confusion Matrix: SVM',\n                                    normalize=True,\n                                    cmap='Blues')\n\ns1 = accuracy_score(Y_test, Y_predict)\n\nplt.show()\ns1","073b2747":"## Hyperparameter Tuning of C (Regularization parameter)","3459b393":"## Plot - C(Regularization parameter) vs Average Precision.","b9fcae2c":"Applying Gridsearch to find the best Model.","513cd590":"## Feature Selection","f2336904":"## Apply Grid search feature in sklearn to find best hyperparamenters(C, gamma).","30fa1e61":"## Best SVM using Grid Search","108b5a4e":"## Try different kernel tuning mecahnisms","2c6690e7":"Only Linear kernel provides good accuracy. We now have Regualarisation and Gamma parameter to tune.","b7111532":"## Final Model Confusion matrix and Classification Report","8262ac66":"Athul Mathew Konoor - 20016  M-Tech AI and DS 19AI613 Machine Learning Lab Evaluation- Hyper Parameter Tuning.","be7abdc4":"## Hyperparameter Tuning of Gamma (Kernel coefficient)","ccebd248":"## Heart Faliure Prediction using SVM(Support Vector Machine)","f60fa283":"All gamma values gives the same precision as per above live chart","4ac8f5e2":"## Plot - Gamma (Kernel coefficient) vs Average Precision.","9cd5cba5":"## Confusion Matrix and Classification Report of current best Model"}}