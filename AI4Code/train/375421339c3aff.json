{"cell_type":{"5d650e91":"code","ada17318":"code","97fa1578":"code","44813d21":"code","753887fb":"code","601db0f9":"code","812d52e0":"code","705bb2e3":"code","acc2184f":"code","d6873990":"code","9c612fe2":"code","3d70aad5":"markdown","d4620dba":"markdown","99158609":"markdown","d2d7bc95":"markdown","ffc9b213":"markdown","5520adf2":"markdown","bdb5126c":"markdown","5cfa8362":"markdown","682a042a":"markdown","616b1d05":"markdown","1a939527":"markdown","f11132ab":"markdown"},"source":{"5d650e91":"!unzip ..\/input\/cassava-disease\/train.zip -d ..\/working\n!unzip ..\/input\/cassava-disease\/test.zip -d ..\/working","ada17318":"# import glob\n# import cv2\n# import os\n# import numpy as np\n# #reading image values in pixels width * hight * channels\n\n# ext = ['jpg', 'jpeg']    # Add image formats here\n# subfolders = ['cbb','cbsd','cgm','cmd','healthy']\n# data = []\n# labels = []\n\n# for subfolder in subfolders:\n#     N = len([iq for iq in os.scandir('..\/working\/train\/%s\/'%subfolder)])\n#     print('reading %s folder [%d files]...'%(subfolder,N))\n#     files = []\n#     imdir = '..\/working\/train\/%s\/'%subfolder\n#     [files.extend(glob.glob(imdir + '*.' + e)) for e in ext]\n#     data.extend([cv2.imread(file) for file in files])\n#     labels.extend([subfolder for file in files])\n\n# print('done !')","97fa1578":"import tensorflow as tf\n\ndirectory = '..\/working\/train\/'\n\ndataset = tf.keras.preprocessing.image_dataset_from_directory(\n    directory,\n    labels=\"inferred\",\n    label_mode=\"int\",\n    class_names=None,\n    color_mode=\"rgb\",\n    batch_size=32,\n    image_size=(256, 256),\n    shuffle=True,\n    seed=123,\n    validation_split=0.3,\n    subset=\"validation\",\n    interpolation=\"bilinear\",\n    follow_links=False,\n)\n\n# dataset := tf.data.Dataset","44813d21":"(x,y,x2,y2) = dataset.unbatch() # <- THIS ISNT WORKING, NEED SOMETHING ELSE","753887fb":"# normalize the inputs from 0-255 to [0,1] by dividing by 255\n    \nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\nX_train = X_train \/ 255.0\nX_test = X_test \/ 255.0","601db0f9":"from keras.utils import np_utils\n# one hot encode outputs\ny_train = np_utils.to_categorical(y_train)\ny_test = np_utils.to_categorical(y_test)\nclass_num = y_test.shape[1]","812d52e0":"# input_size = X_train.shape[1:]\ninput_size = 32\n# class_num = y_test.shape[1]\nclass_num = 5\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\n\nmodel = Sequential()\n\n\nmodel.add(Conv2D(32, (3, 3), input_shape=input_size, padding='same'))\nmodel.add(Activation('relu'))\n\nmodel.add(Conv2D(32, (3, 3), input_shape=(3, 32, 32), activation='relu', padding='same'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n    \nmodel.add(Conv2D(128, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(256, kernel_constraint=maxnorm(3)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n    \nmodel.add(Dense(128, kernel_constraint=maxnorm(3)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\n\nmodel.add(Dense(class_num))\nmodel.add(Activation('softmax'))","705bb2e3":"epochs = 25\noptimizer = 'adam'\n\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","acc2184f":"print(model.summary())","d6873990":"numpy.random.seed(seed)\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=64)","9c612fe2":"# Model evaluation\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","3d70aad5":"architecture:\n\n\nin (32x32)  ->\n\n            -> [conv (32x32) + relu] -> [conv (32x32) + relu] -> [dropout (0.2) + batch normalize] ->\n\n            -> [conv (64x64) + relu] -> [maxPool (2x2)]       -> [dropout (0.2) + batch normalize] ->\n            \n            -> [conv (64x64) + relu] -> [maxPool (2x2)]       -> [dropout (0.2) + batch normalize] ->\n            \n            -> [conv (128x128) + relu]                        -> [dropout (0.2) + batch normalize] ->\n            \n            -> [flatten]                                      -> [dropout (0.2)]                   ->\n            \n            -> [dense (256x256) + relu]                       -> [dropout (0.2) + batch normalize] ->\n            \n            -> [dense (128x128) + relu]                       -> [dropout (0.2) + batch normalize] ->\n            \n            \n            \n-> dense (?x?) -> softmax ->","d4620dba":"### 1.0 unzipping train and test into output folder","99158609":"## 1.1 importing folder directly into dataset","d2d7bc95":"### 1.2 converting data (TODO)\nconvert dataset into [X_train,y_train]\n\nand later on will do the same for test:","ffc9b213":"# Image Recognition with a CNN","5520adf2":"## 2. Designing the Model","bdb5126c":"## 1.3 more prepping data parts","5cfa8362":"## 1.1 (old) read data\nload the data into the RAM (6GB)","682a042a":"## 1. prepping the Data","616b1d05":"### 2.1 Create the model","1a939527":"Defining model architecture","f11132ab":"### 2.2 Model Architecture"}}