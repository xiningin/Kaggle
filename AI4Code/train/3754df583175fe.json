{"cell_type":{"90f24936":"code","f1be2291":"code","cb49ba85":"code","117001bf":"code","686a5519":"code","26a7add1":"code","686c5056":"code","57c5be78":"code","3c04ca84":"code","0bf52b9e":"code","c01ff7ef":"code","4dba8e36":"code","8e6970d5":"code","8f9ba54b":"code","36f0aaaf":"code","057390c7":"code","6da5bc7d":"code","68b53d77":"code","118c2afa":"code","062b5fb0":"code","c333c26a":"code","9bceb3bf":"code","7f9ad84c":"code","ddfce454":"code","af76021a":"code","8112bcc1":"code","97e1a6ae":"code","730e0da5":"code","6aca47b7":"code","e38acdb6":"code","4a9e21d1":"code","5c0f4321":"code","322ff22f":"markdown","24d48fa6":"markdown","bda883b3":"markdown","dc212210":"markdown","b83f854a":"markdown","57a86fa7":"markdown","d6146ec2":"markdown","8b0f11cb":"markdown","ddf4ca8a":"markdown","a70ef28a":"markdown","9489620c":"markdown"},"source":{"90f24936":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f1be2291":"\n# import standard libraries\n\n\nimport pandas as pd\nimport os\nimport sys\nimport numpy as np\nimport re\n\nfrom IPython.core.display import display,HTML\ndisplay(HTML(\"<style>div.output_area pre {white-space: pre;}<\/style>\"))\n# %reload_ext sparksql_magic\n\npd.set_option('display.max_rows',None)","cb49ba85":"!pip install pyspark","117001bf":"from termcolor import colored, cprint\n# import plotting libraries\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nimport pyspark\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()","686a5519":"pd.set_option('display.max_colwidth', None)\n\nimport warnings\nwarnings.filterwarnings('ignore')","26a7add1":"# train = pd.read_csv('..\/input\/predict-test-scores-of-students')\ndf = spark.read.option(\"header\",True).csv('..\/input\/predict-test-scores-of-students')\ndf.show(3,False)","686c5056":"df = df.withColumn('n_student',col('n_student').cast('int'))\\\n.withColumn('pretest',col('pretest').cast('int'))\\\n.withColumn('posttest',col('posttest').cast('int'))\ndf.printSchema()","57c5be78":"# show number of unique value in all columns except student id, pretest, posttest score\ndf_col_list = df.select([i for i in df.columns if i not in \n                       {'student_id','pretest','posttest'}])\nfor i in df_col_list.columns:\n    print(colored('--Showing-- Column --> {}'.format(i) ,'blue', attrs=['reverse', 'blink']))\n    print('* number of unique value in',i)\n    print(df.select(i).distinct().count())","3c04ca84":"# show number of student and school by school setting\ndf.groupby(['school_setting'])\\\n.agg(countDistinct('student_id').alias('ttl_student')\n    ,countDistinct('school').alias('ttl_school')\n    ,avg('pretest').cast('decimal(12,2)').alias('avg_pre')\n    ,avg('posttest').cast('decimal(12,2)').alias('avg_post'))\\\n.select('school_setting','ttl_student','ttl_school'\n       ,((col('ttl_student')\/col('ttl_school')).cast('decimal(12,2)').alias('avg_std\/sch'))\n       ,'avg_pre','avg_post')\\\n.show(100,False)","0bf52b9e":"\n# show number of student and school by school type\n\ndf.groupby(['school_setting','school_type'])\\\n.agg(countDistinct('student_id').alias('ttl_student')\n    ,countDistinct('school').alias('ttl_school'))\\\n.select('school_setting','school_type','ttl_student','ttl_school'\n       ,((col('ttl_student')\/col('ttl_school')).cast('decimal(12,2)').alias('avg_std\/sch')))\\\n.orderBy('ttl_student', ascending=False)\\\n.show(100,False)","c01ff7ef":"# show number of type of classroom by school setting, and type\n\ndf.groupby(['school_setting','school_type'])\\\n.agg(countDistinct('student_id').alias('ttl_student')\n    ,countDistinct('school').alias('ttl_school')\n    ,countDistinct('classroom').alias('ttl_clsrm'))\\\n.select('school_setting','school_type','ttl_student','ttl_school','ttl_clsrm')\\\n.orderBy('ttl_student', ascending=False)\\\n.show(100,False)","4dba8e36":"# show number of student and school by qualification for free lunch by locations\n\ndf.groupby(['school_setting','lunch'])\\\n.agg(countDistinct('student_id').alias('ttl_student')\n    ,countDistinct('school').alias('ttl_school')\n    ,avg('pretest').cast('decimal(12,2)').alias('avg_pre')\n    ,avg('posttest').cast('decimal(12,2)').alias('avg_post'))\\\n.select('school_setting','lunch','ttl_student','ttl_school'\n       ,'avg_pre','avg_post')\\\n.orderBy('ttl_student', ascending=False)\\\n.show(100,False)","8e6970d5":"# how many different teaching methodologies in each school\ndf.groupby(['school'])\\\n.agg(countDistinct('teaching_method').alias('num_teachmethod'))\\\n.orderBy('num_teachmethod', ascending=False)\\\n.show(100,False)","8f9ba54b":"# summary test score after study\ndf.withColumn('final',when(col('pretest')>col('posttest'),'lower')\n             .when(col('pretest')==col('posttest'),'equal')\n             .when(col('pretest')<col('posttest'),'higher'))\\\n.groupby(['final'])\\\n.agg(countDistinct('student_id').alias('ttl_std'))\\\n.orderBy('ttl_std', ascending=False)\\\n.show()","36f0aaaf":"# show score growth by each dimension\ncol_list = ['school','school_setting','school_type','classroom','teaching_method','n_student','gender','lunch']\nfor i in col_list:\n    df.groupby([i])\\\n    .agg(count(i).cast('decimal(12,2)').alias('ttl')\n        ,avg('pretest').cast('decimal(12,2)').alias('avg_pre')\n    ,avg('posttest').cast('decimal(12,2)').alias('avg_post'))\\\n    .select(i,'ttl','avg_pre','avg_post'\n       ,((col('avg_post')-col('avg_pre'))\/col('avg_pre')).cast('decimal(12,2)').alias('growth')\n       ).orderBy('growth', ascending=False).show(100,False)","057390c7":"sns.set_theme(style=\"darkgrid\")\n\ndf = df.toPandas()\ndf.head()\n\n# drop column \"student_id\" as student_id is an independent column\ncorr_df = df.drop(['student_id'],1)\ncorr_df.head()","6da5bc7d":"\n#  creates the correlation matrix between all the features except for student id\ncol_list = ['school','school_setting','school_type','classroom','teaching_method','n_student'\n            ,'gender','lunch','pretest','posttest']\n\nfor i in col_list:\n    corr_df[i] = corr_df[i].astype('category').cat.codes\nprint(colored(' Show correlation between variables ', 'blue', attrs=['reverse', 'blink']))\ncorr_df.corr()","68b53d77":"# plot between variables\nsns.pairplot(corr_df, diag_kind='kde')","118c2afa":"\n# strong connection between pretest score and post test score\nprint(colored(' Show correlation between variables - heatmap ', 'blue', attrs=['reverse', 'blink']))\n\nplt.figure(figsize=(12,8))\nsns.heatmap(corr_df.corr(),annot=True)","062b5fb0":"\n# number of students are not eligible for free lunch\nplt.figure(figsize=(12,8))\nsns.countplot(x=\"school_setting\", hue=\"lunch\", data=df)","c333c26a":"\n# Non-public school tend to have a higher pretest score\nsns.lmplot(x='pretest',y='posttest',data = df,hue ='school_type',height= 6)","9bceb3bf":"# How teching method effect pretest and posttest score\nsns.lmplot(x='pretest',y='posttest',data = df,hue ='teaching_method',height= 8)","7f9ad84c":"# given summary of post-test result, how it perform after pre- test\nconditions = [\n    (corr_df['pretest'] == corr_df['posttest']),\n    (corr_df['pretest'] < corr_df['posttest']),\n    (corr_df['pretest'] > corr_df['posttest'])]\nchoices = ['same','higher','lower']\ncorr_df['summary'] = np.select(conditions, choices)\ncorr_df.head()","ddfce454":"# filtered out student who are outlier, assigned new df name as \"clean_df\"\nclean_df = corr_df[corr_df['summary']=='higher']\n# # drop gender, due to it shows no effect on post test\nclean_df = clean_df.drop(['gender','summary'],axis=1)\n\n\nplt.subplots(figsize=(12,8))\nplt.xticks(np.arange(0, 80, step=5))\nsns.set_theme(style=\"darkgrid\")\nsns.distplot( clean_df[\"posttest\"])","af76021a":"from sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.neural_network import MLPRegressor\n\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics","8112bcc1":"x = clean_df.drop(['posttest'],axis=1)\ny = clean_df['posttest']\n\nX_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state = 123)","97e1a6ae":"#LinearRegression\nlr = LinearRegression()\n#training the model on training data\nlr.fit(X_train, y_train)\ny_pred = lr.predict(X_test)\n\nprint('Accuracy - LinearRegression: %.2f%%'%(lr.score(X_test,y_test)*100))","730e0da5":"#GradientBoostingRegressor\ngradientBoost = GradientBoostingRegressor(random_state=1234,learning_rate=0.03, n_estimators=300)\ngradientBoost.fit(X_train,y_train)\n\n\nprint('Accuracy - GradientBoostingRegressor: %.2f%%'%(gradientBoost.score(X_test, y_test)*100))","6aca47b7":"\n#random forest regression\n\nregr = RandomForestRegressor(max_depth=300, random_state=0, n_estimators=300)\nregr.fit(X_train,y_train)\n\nprint('Accuracy - RandomForestRegression: %.2f%%'%(regr.score(X_test, y_test)*100))","e38acdb6":"from sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.datasets import make_regression\n\nX, y = make_regression(n_features=300, n_informative=5,random_state=0, shuffle=False)\n#Multi-layer Perceptron regressor\nclf =MLPRegressor(hidden_layer_sizes=1000, activation='relu', solver='adam', alpha=0.0001\n      , batch_size='auto', learning_rate='adaptive', learning_rate_init=0.005)\nclf.fit(X_train,y_train)\n\nprint('Accuracy - Multi-layer Perceptron regressor: %.2f%%'%(clf.score(X_test, y_test)*100))","4a9e21d1":"ans = regr.predict(X_test)\n","5c0f4321":"# get predictive col\nfinal_output = pd.DataFrame(ans,columns={\"pred_posttest\"})\n#get true val col\ny_test_df = pd.DataFrame(y_test, index=None,columns={\"posttest\"}).reset_index(drop=True)\n# export output\npd.concat([final_output,y_test_df],axis=1).to_csv('.\/predict_testscore_output.csv')","322ff22f":"from above information, 99% of students have a better post test score, hence remove those who has lower or qual to pretest score\n\n","24d48fa6":"**RandomForestRegression**","bda883b3":"**Multi-layer Perceptron regressor**","dc212210":"## Data Exploration","b83f854a":"\n**Observation : Overall**\n\n* Gender share equally propotion across dataset\n* Urban location has more number of students and number of schools when comparing with other location type. However, Suburban has the highest average number of student per school(102 students\/ school)\n* 83% of all school have both Experimental and Standard teaching methodolody, except at UAGPU, ANKYI, KZKKE has only standard; and FBUMG has only Experimental teaching.\n* public school has more variety type of class room than non-public school, and 74% of students study in public school\n* ~57% of students are not eligible for free lunch, 38% of them study in Suburban schools.","57a86fa7":"**LinearRegression** As we see the pretest-posttest relation in a strightline, hence firstly try with linear regression\n\n","d6146ec2":"**GradientBoostingRegressor**","8b0f11cb":"# Model fitting","ddf4ca8a":"**Visualisation**","a70ef28a":"\n**Observation : correlation between variables**\n* Strong connection between pretest and posttest score\n* School, School_setting, School_type, classroom, n_student, gender, lunch - show similiar relationship score between pre and post. Only teaching method suggest more strong connection to posttest than pretest","9489620c":"\n**Observation: pre-post score**\n* 99% of students have a better score after study\n* Even though students in Suburban tend to have a higher pre and post test score but _average score improvement are only at 19% growth, where the other two school setting increasing at 24%\n* Student who study in Experimental teaching methodology yield +9% score improvement than standard teaching technique\n* Where other variable tend to indicate different effect on posttest score development, Gender does not show significant impact on score development"}}