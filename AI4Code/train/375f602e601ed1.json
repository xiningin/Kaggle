{"cell_type":{"d09cc7df":"code","8e1927c2":"code","08f42087":"code","0b5ef94e":"code","6c8fe5e7":"code","c062866c":"code","f96f182d":"code","cf559a91":"code","e885a3e4":"code","ebba0a9f":"code","38a08ad6":"code","c4d6a68f":"code","5ae6194b":"code","6a5fa6a9":"code","ac098065":"code","6e0b510e":"code","1db9d5cd":"markdown","9f29826b":"markdown","e7d4889f":"markdown","4f5a3e67":"markdown"},"source":{"d09cc7df":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom sklearn.metrics import roc_auc_score\nimport time","8e1927c2":"train_transaction = pd.read_csv('..\/input\/ieee-fraud-detection\/train_transaction.csv', index_col='TransactionID')\ntest_transaction = pd.read_csv('..\/input\/ieee-fraud-detection\/test_transaction.csv', index_col='TransactionID')\nsample_submission = pd.read_csv('..\/input\/ieee-fraud-detection\/sample_submission.csv', index_col='TransactionID')","08f42087":"#Based on this great kernel https:\/\/www.kaggle.com\/arjanso\/reducing-dataframe-memory-size-by-65\ndef reduce_mem_usage(df):\n    start_mem_usg = df.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in df.columns:\n        if df[col].dtype != object:  # Exclude strings            \n            # Print current column type\n#             print(\"******************************\")\n#             print(\"Column: \",col)\n#             print(\"dtype before: \",df[col].dtype)            \n            # make variables for Int, max and min\n            IsInt = False\n            mx = df[col].max()\n            mn = df[col].min()\n#             print(\"min for this col: \",mn)\n#             print(\"max for this col: \",mx)\n            # Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(df[col]).all(): \n                NAlist.append(col)\n                df[col].fillna(mn-1,inplace=True)  \n                   \n            # test if column can be converted to an integer\n            asint = df[col].fillna(0).astype(np.int64)\n            result = (df[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True            \n            # Make Integer\/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        df[col] = df[col].astype(np.uint8)\n                    elif mx < 65535:\n                        df[col] = df[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        df[col] = df[col].astype(np.uint32)\n                    else:\n                        df[col] = df[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        df[col] = df[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        df[col] = df[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        df[col] = df[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        df[col] = df[col].astype(np.int64)    \n            # Make float datatypes 32 bit\n            else:\n                df[col] = df[col].astype(np.float32)\n            \n            # Print new column type\n#             print(\"dtype after: \",df[col].dtype)\n#             print(\"******************************\")\n    # Print final result\n    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n    mem_usg = df.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage is: \",mem_usg,\" MB\")\n    print(\"This is \",100*mem_usg\/start_mem_usg,\"% of the initial size\")\n    return df, NAlist","0b5ef94e":"print(train_transaction.shape)\nprint(test_transaction.shape)","6c8fe5e7":"# Reducing memory for transaction data set\ntrain, NAlist = reduce_mem_usage(train_transaction)","c062866c":"# Reducing memory for test data set\ntest, NAlist = reduce_mem_usage(test_transaction)","f96f182d":"# Memory comparison\n\n# train_transaction.memory_usage().sum() \/ 1024**2 \n# train.memory_usage().sum() \/ 1024**2 \n\n# test_transaction.memory_usage().sum() \/ 1024**2 \n# test.memory_usage().sum() \/ 1024**2 ","cf559a91":"del train_transaction, test_transaction","e885a3e4":"# Data description\n# print(train.shape)\n# print(test.shape)\n\nprint(train.head())\nprint(test.head())","ebba0a9f":"# Manually pick 23 important features\n\n# ignore \"ProductCD\"\n\nfeatures = ['isFraud','TransactionDT','TransactionAmt','card1','card2', 'card3', 'card5', 'addr1', 'addr2', 'dist1','C1', 'C2','C3', 'C4','C5', 'C6','C7', 'C8','C9', 'C10', 'C11', 'C12','C13', 'C14']\nlen(features)\n\nprint(train.shape)\nprint(test.shape)\n\ntrain = train.loc[:,features]\nfeatures.remove('isFraud')\ntest = test.loc[:,features]\n\nprint(train.shape)\nprint(test.shape)","38a08ad6":"# Assigning X and y vairables\n\nX_train = train.drop('isFraud',axis=1)\ny_train = train['isFraud']\n\nX_test = test","c4d6a68f":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.3, random_state=0)\n\n\nprint(X_train.shape)\nprint(X_val.shape)","5ae6194b":"## Reducing Memory again \nX_train, NAlist = reduce_mem_usage(X_train)\nX_val, NAlist = reduce_mem_usage(X_val)","6a5fa6a9":"model = RandomForestClassifier(n_jobs=-1, n_estimators=200)\nmodel.fit(X_train, y_train)\n\nprint(roc_auc_score(y_val,model.predict_proba(X_val)[:,1] ))","ac098065":"# creating a base sample submission\n\nsample_submission['isFraud'] = model.predict_proba(X_test)[:,1]\nsample_submission.to_csv(\"base_sample_submission.csv\")","6e0b510e":"N = 10\nimportances = model.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in model.estimators_],\n             axis=0)\n\n# create a dataframe\nimportances_df = pd.DataFrame({'variable':X_train.columns, 'importance': importances})\n\ntop_N = importances_df.sort_values(by=['importance'], ascending=False).head(N)\n\ntop_N","1db9d5cd":"## Feature Selection","9f29826b":"## Random Forest Classifier Model","e7d4889f":"## Feature Importance","4f5a3e67":"## Reduce Memory Usage\n\nFunction to reduce the size of DF, taken from [@kabure](https:\/\/www.kaggle.com\/kabure\/extensive-eda-and-modeling-xgb-hyperopt)"}}