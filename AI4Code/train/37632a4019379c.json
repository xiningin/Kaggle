{"cell_type":{"50a218f0":"code","3202c7b3":"code","67789825":"code","6a653668":"code","4a3157b8":"code","af509cff":"code","41423bf3":"code","a9215a73":"code","e9d066a1":"code","5564a7da":"code","58bbb42d":"markdown","ee8fc92d":"markdown","04f1f5a2":"markdown","2fdb24cb":"markdown","865f9430":"markdown","ffd6c250":"markdown","2fdedd4c":"markdown","c17729b4":"markdown","b9e9e6e9":"markdown","d18ec561":"markdown","051e0c8e":"markdown"},"source":{"50a218f0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3202c7b3":"!pip install scanpy\nimport scanpy as sc\nimport anndata\n\nimport scipy \n\n\nimport time\nt0start = time.time()\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport sys\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nmpl.rcParams['figure.dpi'] = 70\nplt.style.use('dark_background')\n\nimport seaborn as sns\n\nfrom sklearn.decomposition import PCA","67789825":"def read_mtx_by_prefix(path_and_fn_prefix):\n    adata = sc.read(path_and_fn_prefix + 'matrix.mtx').T\n    genes = pd.read_csv(path_and_fn_prefix + 'genes.tsv', header=None, sep='\\t') \n    genes = genes.set_index(1)\n    genes.index.name = 'Gene'\n    genes.columns = ['Ensemble']\n    adata.var = genes\n    \n    barcodes = pd.read_csv(path_and_fn_prefix + 'barcodes.tsv', header=None, sep='\\t', index_col = 0) \n    barcodes.index.name = 'barcodes'\n    \n    adata.obs = barcodes\n\n    return adata\n\nif 1:\n    str_data_inf = ' GSE85917_human_H1H9_hESC_Y2016_366Cells_GEO_counts_Bacher_Kendziorski '\n    path_and_fn = '\/kaggle\/input\/scrnaseq-human-embryonic-stem-h1-h9-cell-lines\/GSE85917_human_H1H9_hESC_Y2016_366Cells_GEO_counts_Bacher_Kendziorski.h5ad'\n    \n    adata_orig =  sc.read(path_and_fn)\n\nelse:\n    str_data_inf = ' GSM3267241_U5_all '\n    path_and_fn_prefix = '\/kaggle\/input\/scrnaseq-neuroepithelialderived-cells-and-glioma\/GSM3267241_U5_all_'\n    adata_orig =  read_mtx_by_prefix(path_and_fn_prefix)\n    \nadata = adata_orig.copy()\nadata_orig\n","6a653668":"v = np.asarray(adata.X.sum(axis = 0)).ravel()\nadata.var['Expression Sum'] = v\nv = np.asarray( (adata.X != 0) .sum(axis = 0)).ravel()\nadata.var['Count Expressed Cells'] = v\nadata.var.sort_values('Expression Sum',ascending = False ).head(30) # ['counts']","4a3157b8":"v = np.asarray(adata.X.sum(axis = 0)).ravel()\ndisplay(pd.Series(v).describe())\nv = np.log10(1+v)\nfig = plt.figure(figsize = (20,6)); c = 0\nc+=1; fig.add_subplot(1,2,c);\nplt.plot(np.sort(v)) \nplt.title('LOG10 Expression per gene')\nplt.xlabel('genes sorted')\nplt.ylabel('Log10 (1+Counts) ')\n\nc+=1; fig.add_subplot(1,2,c);\nplt.hist(np.sort(v), bins = 30) \nplt.title('LOG10 Expression per gene')\n\nplt.show()\n\npd.Series(v).describe()","af509cff":"fig = plt.figure(figsize = (20,6)); c = 0\nc+=1; fig.add_subplot(1,2,c);\nv = np.asarray(adata.X.sum(axis = 1)).ravel() # adata.obs['n.umi']\nplt.plot(np.sort(v ),'*-') \nplt.title('Expression per cell')\nplt.xlabel('cells sorted')\nplt.ylabel('Expression Total')\n\nc+=1; fig.add_subplot(1,2,c);\nplt.hist(np.sort(v), bins = 100) \nplt.title('Expression per cell')\n\nplt.show()\n\npd.Series(v).describe()\n\n\nfig = plt.figure(figsize = (20,6)); c = 0\nc+=1; fig.add_subplot(1,2,c);\nv = np.asarray((adata.X != 0).sum(axis = 1)).ravel() # adata.obs['n.umi']\nplt.plot(np.sort(v ),'*-') \nplt.title('Count genes expressed per cell')\nplt.xlabel('cells sorted')\nplt.ylabel('Count expressed genes')\n\nc+=1; fig.add_subplot(1,2,c);\nplt.hist(np.sort(v), bins = 100) \nplt.title('Count genes expressed per cell')\n\nplt.show()\n\npd.Series(v).describe()","41423bf3":"import scipy \n\nnumber_top_genes_to_consider = 10_000\nv = np.asarray(adata.X.sum(axis = 0 ) ).ravel()\nv.shape\nI = np.argsort(v)\nI = I[::-1]\nI = I[:number_top_genes_to_consider]\n\nmask = np.ones( adata.X.shape[0]).astype(bool) \nt0 = time.time()\nif scipy.sparse.issparse(adata.X):\n    corr_matr = np.corrcoef(adata[mask].X[:,I].toarray().T) # Hint - use numpy , pandas is MUCH SLOWER   (df.corr() )\nelse:\n    corr_matr = np.corrcoef(adata[mask].X[:,I].T) # Hint - use numpy , pandas is MUCH SLOWER   (df.corr() )\nprint('Calculated correlation matrix. Shape: ',corr_matr.shape,'  seconds passed:' , np.round( time.time() - t0,1) )\n\nprint()\nprint(np.min(corr_matr ), 'minimal correlation' )\ncorr_matr_abs = np.abs( corr_matr )\nprint(np.mean(corr_matr_abs ), 'average absolute correlation' )\nprint(np.median(corr_matr_abs), 'median absolute correlation' )\nprint(np.min(corr_matr_abs ), 'min absolute correlation' )\nprint(np.std(corr_matr_abs ), 'std absolute correlation' )\nprint()\n\nv = corr_matr.flatten()\nplt.figure(figsize=(14,8))\nt0 = time.time()\nplt.hist(v, bins = 50)\nplt.title('correlation coefficients distribution')\nplt.show()\nprint(time.time() - t0, 'seconds passed')\n\nprint(np.min(corr_matr ), 'minimal correlation' )\nprint(np.mean(corr_matr_abs ), 'average absolute correlation' )\nprint(np.median(corr_matr_abs), 'median absolute correlation' )\nprint(np.min(corr_matr_abs ), 'min absolute correlation' )\nprint(np.std(corr_matr_abs ), 'std absolute correlation' )\nfor t in [0.5,0.6, 0.7,0.8,0.9,0.95,0.97,0.98,.99]:\n    print( ((np.abs(v) < 0.99999999) & (np.abs(v) > t)).sum()\/2 , 'number of pairs correlated more than', t  )\nv.shape\n\nprint()\nprint()\nfor threshold_corr in [0.99,0.98,00.97,0.95,0.93,0.90,0.85,0.8,0.75,0.7,0.65,0.6,0.55,.5,0.45,0.4,0.35,0.3]: \n    a,b = np.where( np.triu(np.abs(corr_matr),1) > threshold_corr )\n    if len(a) > 50: break\nprint('for threshold:', threshold_corr,'we have ',len(a),' correlated pairs' )\n\n\nd = pd.DataFrame()\nfor i in range(len(a)):\n    Iai, Ibi =  I[a[i]], I[b[i]]\n    d.loc[i,'Gene1'] = adata[mask].var.index[Iai] \n    d.loc[i,'Gene2'] = adata[mask].var.index[Ibi ] \n    d.loc[i,'Correlation'] = corr_matr[a[i],b[i]] \n    d.loc[i,'Correlation Abs'] = np.abs(d.loc[i,'Correlation'] )\n    d.loc[i,'Gene1 Expression Sum'] = np.asarray(adata[mask].X[:,Iai].sum(axis = 0)).ravel()[0]\n    d.loc[i,'Gene2 Expression Sum'] = np.asarray(adata[mask].X[:,Ibi].sum(axis = 0)).ravel()[0]\n    \nprint(time.time() - t0, 'seconds passed')\n    \nd.sort_values('Correlation Abs',ascending = False).head(30)","a9215a73":"import seaborn as sns\nt0 = time.time()\nsns.clustermap(np.abs(corr_matr[:3000,:3000]),cmap='vlag');\nprint( np.round(time.time()- t0,1), ' seconds passed.')","e9d066a1":"import scipy\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.decomposition import PCA\nimport time\nt0 = time.time()\nif scipy.sparse.issparse(adata.X):\n    reducer = TruncatedSVD(n_components=2, n_iter=7, random_state=42)\nelse:\n    reducer = PCA(n_components=2)\n    \nr = reducer.fit_transform(adata.X)\n\nfig = plt.figure(figsize = (25,12))\nplt.title(str_data_inf + ' PCA  n_cells: ' + str(adata.X.shape[0]) +\\\n            ' n_genes: ' + str(adata.X.shape[1])  + ' '  , fontsize = 20   )#' \n\nif 'n.umi' not in adata.obs.columns: \n    ax = sns.scatterplot(x=r[:,0], y = r[:,1])#,  hue= color_by)#, palette = color_palette )#, palette = \"viridis\")# sns.color_palette(\"viridis\", as_cmap=True),\n                        #)# ,   alpha = 0.8, marker = '.')#, )#, legend=None)\nelse:\n    color_by = adata.obs['n.umi'].values\n    ax = sns.scatterplot(x=r[:,0], y = r[:,1],  hue= color_by)#, palette = color_palette )#, palette = \"viridis\")# sns.color_palette(\"viridis\", as_cmap=True),\n                        #)# ,   alpha = 0.8, marker = '.')#, )#, legend=None)\n    plt.setp(ax.get_legend().get_texts(), fontsize='20') # for legend text\n    plt.setp(ax.get_legend().get_title(), fontsize='20') # for legend title\nplt.xlabel('PCA1' , fontsize = 20 )\nplt.ylabel('PCA2' , fontsize = 20 )\nplt.show()\nprint( np.round( time.time() - t0,1) , ' seconds passed ' )","5564a7da":"import scipy\nimport umap \nt0 = time.time()\nreducer = umap.UMAP()\nr = reducer.fit_transform(adata.X)\n\nfig = plt.figure(figsize = (25,12))\nplt.title(str_data_inf + ' UMAP n_cells: ' + str(adata.X.shape[0]) +\\\n            ' n_genes: ' + str(adata.X.shape[1])  + ' '  , fontsize = 20   )#' \nif 'n.umi' not in adata.obs.columns: \n    ax = sns.scatterplot(x=r[:,0], y = r[:,1])#,  hue= color_by)#, palette = color_palette )#, palette = \"viridis\")# sns.color_palette(\"viridis\", as_cmap=True),\n                        #)# ,   alpha = 0.8, marker = '.')#, )#, legend=None)\nelse:\n    color_by = adata.obs['n.umi'].values\n    ax = sns.scatterplot(x=r[:,0], y = r[:,1],  hue= color_by)#, palette = color_palette )#, palette = \"viridis\")# sns.color_palette(\"viridis\", as_cmap=True),\n                        #)# ,   alpha = 0.8, marker = '.')#, )#, legend=None)\n    plt.setp(ax.get_legend().get_texts(), fontsize='20') # for legend text\n    plt.setp(ax.get_legend().get_title(), fontsize='20') # for legend title\n\nplt.xlabel('UMAP1' , fontsize = 20 )\nplt.ylabel('UMAP2' , fontsize = 20 )\nplt.show()\nprint( np.round( time.time() - t0,1) , ' seconds passed ' ) ","58bbb42d":"# What is about ?\n\nExample how to load scRNA data and very first simple look on data.\n","ee8fc92d":"## PCA\n","04f1f5a2":"## Show top expressed genes","2fdb24cb":"## Expression per gene","865f9430":"## UMAP","ffd6c250":"# Correlation analysis","2fdedd4c":"## Expression per cell","c17729b4":"# Load data ","b9e9e6e9":"# Import and install modules","d18ec561":"# Visualisation\n","051e0c8e":"# EDA"}}