{"cell_type":{"c40cc104":"code","c47c15ee":"code","56104fa4":"code","399ae402":"code","2d9021a4":"code","ebb73def":"code","e8296d68":"code","53c9ad74":"code","6219946d":"code","17e6a0c5":"code","f4d25ebf":"code","1274cf51":"code","781b649e":"code","b2fd2d3a":"code","80bda3ef":"code","3a9dc41e":"code","3c02eeb0":"code","7cebc571":"code","505cd6a1":"code","d4857463":"code","fc881128":"code","3982670f":"code","b66d6429":"code","26765512":"code","b5c964ae":"code","a39f8d9f":"code","e2fd7d86":"code","1e4ed0c0":"code","9c19a4e3":"code","3dc5ffc2":"code","eba4cef9":"code","e3ad5081":"code","cbec9eef":"code","a231bb13":"code","4b9dd705":"code","85192305":"code","188c406e":"code","851aef59":"code","3018055b":"code","c4fb81ba":"code","89b39111":"code","4664989f":"code","1d128ff1":"code","32f234e2":"markdown","f217b555":"markdown","f1f607bf":"markdown","5154fe57":"markdown","2bb9342f":"markdown","6b9fcec0":"markdown","ceced314":"markdown","862e5369":"markdown","4d343877":"markdown","826a21d4":"markdown","0a81b2bc":"markdown","9063d3e1":"markdown","ddb59afb":"markdown","3dfce550":"markdown","38460f70":"markdown","f83d7fbb":"markdown","fa3b863d":"markdown","74f7c8a2":"markdown","3af4ddb7":"markdown","9616c627":"markdown","e7013496":"markdown","7b63be94":"markdown","c7df3887":"markdown","6b2fd734":"markdown","f3f70417":"markdown","44de7aaa":"markdown","1fb35cae":"markdown","8da1e3cb":"markdown"},"source":{"c40cc104":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","c47c15ee":"train = pd.read_csv('\/kaggle\/input\/hr-analytics-job-change-of-data-scientists\/aug_train.csv')\ntest = pd.read_csv('\/kaggle\/input\/hr-analytics-job-change-of-data-scientists\/aug_test.csv')\nsample = pd.read_csv('\/kaggle\/input\/hr-analytics-job-change-of-data-scientists\/sample_submission.csv')","56104fa4":"print(train.shape)\nprint(test.shape)\nprint(sample.shape)\ntrain.head(10)","399ae402":"for column in train:\n    print(column)\n    print(train[column].isnull().sum().sum())","2d9021a4":"train.fillna('Unknown', inplace = True)\nfor column in train:\n    print(column)\n    print(train[column].isnull().sum().sum())","ebb73def":"train.head()","e8296d68":"train['city'] = train['city'].map(lambda x: x.lstrip('city_'))","53c9ad74":"train['experience'] = train['experience'].map(lambda x: x.lstrip('<>'))\ntrain['last_new_job'] = train['last_new_job'].map(lambda x: x.lstrip('<>'))\ntrain[\"last_new_job\"]= train[\"last_new_job\"].replace('never', 0)\ntrain[\"last_new_job\"]= train[\"last_new_job\"].replace('Unknown', 0)","6219946d":"train.head()","17e6a0c5":"sns.set(rc={'figure.figsize':(25,6)})","f4d25ebf":"sns.barplot(x='city', y='target', data=train)","1274cf51":"sns.barplot(x='city_development_index', y='target', data=train)","781b649e":"sns.barplot(x='gender', y='target', data=train)","b2fd2d3a":"sns.barplot(x='relevent_experience', y='target', data=train)","80bda3ef":"sns.barplot(x='enrolled_university', y='target', hue='education_level', data=train)","3a9dc41e":"sns.barplot(x='major_discipline', y='target', data=train)","3c02eeb0":"sns.barplot(x='experience', y='target', data=train)","7cebc571":"sns.barplot(x='company_size', y='target', data=train)","505cd6a1":"sns.barplot(x='company_type', y='target', data=train)","d4857463":"sns.barplot(x='last_new_job', y='target', data=train)","fc881128":"sns.barplot(x='training_hours', y='target', data=train)","3982670f":"train = train.drop(['gender', 'major_discipline', 'training_hours'], axis=1)","b66d6429":"train.head()","26765512":"train[\"enrolled_university\"]= train[\"enrolled_university\"].replace('Unknown', 'Unknown_uni')\ntrain[\"education_level\"]= train[\"education_level\"].replace('Unknown', 'Unknown_level')\ntrain[\"experience\"]= train[\"experience\"].replace('Unknown', 0)\ntrain[\"company_size\"]= train[\"company_size\"].replace('Unknown', 'Unknown_size')\ntrain[\"company_type\"]= train[\"company_type\"].replace('Unknown', 'Unknown_type')","b5c964ae":"train.head()","a39f8d9f":"experience = pd.get_dummies(train['relevent_experience'], drop_first=True)\nuniversity = pd.get_dummies(train['enrolled_university'], drop_first=False)\neducation = pd.get_dummies(train['education_level'], drop_first=False)\nc_size = pd.get_dummies(train['company_size'], drop_first=False)\nc_type = pd.get_dummies(train['company_type'], drop_first=False)","e2fd7d86":"train = train.drop(['relevent_experience', 'enrolled_university', 'education_level', 'company_size', 'company_type'], axis=1)","1e4ed0c0":"train = pd.concat([train, experience, university, education, c_size, c_type], axis=1)\nprint(train.shape)\ntrain.head()","9c19a4e3":"for column in test:\n    print(column)\n    print(test[column].isnull().sum().sum())","3dc5ffc2":"test.head()","eba4cef9":"test.fillna('Unknown', inplace = True)\n\ntest['city'] = test['city'].map(lambda x: x.lstrip('city_'))\ntest['experience'] = test['experience'].map(lambda x: x.lstrip('<>'))\ntest['last_new_job'] = test['last_new_job'].map(lambda x: x.lstrip('<>'))\ntest[\"last_new_job\"]= test[\"last_new_job\"].replace('never', 0)\ntest[\"last_new_job\"]= test[\"last_new_job\"].replace('Unknown', 0)\n\ntest = test.drop(['gender', 'major_discipline', 'training_hours'], axis=1)\ntest[\"enrolled_university\"]= test[\"enrolled_university\"].replace('Unknown', 'Unknown_uni')\ntest[\"education_level\"]= test[\"education_level\"].replace('Unknown', 'Unknown_level')\ntest[\"experience\"]= test[\"experience\"].replace('Unknown', 0)\ntest[\"company_size\"]= test[\"company_size\"].replace('Unknown', 'Unknown_size')\ntest[\"company_type\"]= test[\"company_type\"].replace('Unknown', 'Unknown_type')\n\nexperience_test = pd.get_dummies(test['relevent_experience'], drop_first=True)\nuniversity_test = pd.get_dummies(test['enrolled_university'], drop_first=False)\neducation_test = pd.get_dummies(test['education_level'], drop_first=False)\nc_size_test = pd.get_dummies(test['company_size'], drop_first=False)\nc_type_test = pd.get_dummies(test['company_type'], drop_first=False)\n\ntest = test.drop(['relevent_experience', 'enrolled_university', 'education_level', 'company_size', 'company_type'], axis=1)\ntest = pd.concat([test, experience_test, university_test, education_test, c_size_test, c_type_test], axis=1)","e3ad5081":"train.shape, test.shape","cbec9eef":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics","a231bb13":"x = train.drop(['target'], axis=1)\ny = train['target']","4b9dd705":"x.shape, y.shape","85192305":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)","188c406e":"from sklearn.linear_model import LogisticRegression\nlogistic = LogisticRegression()\nlogistic.fit(x_train, y_train)\nprediction_lr = logistic.predict(x_test)\nprint(classification_report(y_test,prediction_lr))","851aef59":"from sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier()\ntree.fit(x_train, y_train)\nprediction_dt = tree.predict(x_test)\nprint(classification_report(y_test, prediction_dt))","3018055b":"from sklearn.ensemble import RandomForestClassifier\nforest = RandomForestClassifier()\nforest.fit(x_train, y_train)\nprediction_rf = forest.predict(x_test)\nprint(classification_report(y_test, prediction_rf))","c4fb81ba":"sns.set(rc={'figure.figsize':(8,5)})","89b39111":"metrics.plot_roc_curve(logistic, x_test, y_test)","4664989f":"metrics.plot_roc_curve(tree, x_test, y_test) ","1d128ff1":"metrics.plot_roc_curve(forest, x_test, y_test) ","32f234e2":"Checking the null values in the training and test data.","f217b555":"<img src=\"https:\/\/media.giphy.com\/media\/xThtadLubOnwcA43V6\/giphy.gif\">","f1f607bf":"**Now, our training data is ready for training. But before I start with that, I need to make exact moves with the test data to make them compatible. This is why it is so important to have a nice structure and pipeline with your notebook because you can get confused very easily if you don't.**","5154fe57":"Both dataset has *null* values in the same columns.","2bb9342f":"Here, we have every information that we need. But it is not usable for models right now. We need to get rid of the string elements. But when we do that by *pandas.get_dummies*, we will have the same named columns called *Unknown*. First, I need to fix that.","6b9fcec0":"# **HR Analytics: WHO IS LOOKING FOR THE DOOR?**","ceced314":"**We are good to go.**","862e5369":"There are some spikes here or there. Overall, it seems consistent enough in different values to drop this column.","4d343877":"<img src=\"https:\/\/media.giphy.com\/media\/xUPOqo6E1XvWXwlCyQ\/giphy.gif\">","826a21d4":"Experience level is a huge difference. We see that early careers tend to change jobs more often than others.","0a81b2bc":"**RANDOM FOREST**","9063d3e1":"**LOGISTIC REGRESSION**","ddb59afb":"Although it is clear which model is more successfull. I like to look at their ROC curves to be sure.","3dfce550":"SO, I am going to drop *gender, major_discipline and training_hours* columns.","38460f70":"***City*** will be important to the decision process, probably. BUT it is not usable with the *'city_xx'* form so I need to strip the *'city_'* from the numbers next to it.","f83d7fbb":"Okay. Some of the columns we do not have any missing variables but in most of them we have a lot. To continue with our analysis I am going to mark these *null* values as Unknown and look at their effects to the outcome.","fa3b863d":"The null values that we had in the beginning are making a huge difference right now. I am going to stick with them and act like that is an another category.","74f7c8a2":"**In this notebook, firstly I will look for any missing variables, fixing tweaks here or there. Secondly, I will visualize the processed data to see the relation between columns, then I will drop the unnecessary columns. Finally I will apply different models to data and we will see how it is going to turn out!**","3af4ddb7":"**NOW** we can create dummies.","9616c627":"Now, I will look at each category and its effect to the ***target***. By the way, I like to do this with big graphs.","e7013496":"Two for two everybody. I will be dropping the *major discipline*, as well.","7b63be94":"**That is it for this notebook. I hope you liked it. Let me know what you think, feedbacks are appreciated.**","c7df3887":"**DECISION TREE**","6b2fd734":"I think I was right about the gender. Although there are differences, they are not as important as other categories.","f3f70417":"I tought this will effect more, not gonna lie there. But it is still valid.","44de7aaa":"I always like to do a prediction on my own about the data before I start to analyze it. SO here it is, I do not think *gender, major,company type* will effect the outcome of this situation. We'll see!","1fb35cae":"I have applied three different machine learning methods to the data. Random Forest Classifier seem to be the most successful out of them. Random Forest achieved %83 precision, %88 recall and 0.78 AUC scores. Which is not perfect but I think we can call it a successful classification.","8da1e3cb":"Also ***experience*** and ***last_new_job*** should be important for the outcome, don't you think? I will delete the *'<,>'* symbols in front of them. I do not think the impact of '<,>' is not that important. And also, we should get rid of the 'never' and 'unknown' labels in the ***last_new_job*** column."}}