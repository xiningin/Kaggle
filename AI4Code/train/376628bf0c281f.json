{"cell_type":{"d6c8da39":"code","4000d42d":"code","8daf6101":"code","ee4ea3ce":"code","6cb6147a":"code","a2fd13ee":"code","729e9cb6":"code","706d00a4":"code","401b450c":"code","01d2d1dd":"code","8683a3ef":"code","a0142738":"code","3cb203ee":"code","ee25415e":"code","a9ba515b":"code","e4d3603e":"code","f3aac42f":"markdown","67537bf1":"markdown","0fb5124a":"markdown","50850461":"markdown","1276995a":"markdown","6aa6356c":"markdown","04f40f6a":"markdown","c1119cb9":"markdown","d5d74c37":"markdown","3ef26354":"markdown","96ce0da7":"markdown","146f1874":"markdown","c5a1f249":"markdown","5c79014a":"markdown","32acb777":"markdown","4bd33c8c":"markdown","c34dcf79":"markdown","baadfefd":"markdown","7fe2ca73":"markdown","1e6ffde0":"markdown","c6e27302":"markdown","3680410c":"markdown","5d5b534c":"markdown","08886b38":"markdown","cec036ee":"markdown","528cd8da":"markdown"},"source":{"d6c8da39":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score","4000d42d":"heart_data = pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\")\nheart_data.head()","8daf6101":"heart_data.info()","ee4ea3ce":"# We can use a heatmap to check correlation between the variables.\ncorr = heart_data.corr()\nplt.figure(figsize=(8,8))\nsns.heatmap(corr,cbar=True,square=True,fmt='.1f',annot=True,cmap='Reds')","6cb6147a":"plt.figure(figsize=(10,10))\nsns.countplot(x=\"target\", data=heart_data)","a2fd13ee":"# Heart disease across ages\nplt.figure(figsize=(10,10))\nplt.scatter(x=heart_data.age[heart_data.target == 1] , y=heart_data.thalach[heart_data.target == 1],c='black')\nplt.xlabel('Age')\nplt.ylabel('Maximum Heart Rate')\nplt.legend(['Has heart disease'])","729e9cb6":"# Heart disease across sexes\nplt.figure(figsize=(10,10))\nsns.countplot(data=heart_data,x='sex',hue='target')\nplt.xticks(ticks = [0,1], labels = ['Female','Male'])\nplt.legend([\"Doesn't have heart disease\", 'Has heart disease'])","706d00a4":"# We need to split the data\nX = heart_data.drop(['target'],axis=1) # We need all the variables (columns) as independent variables so we're just dropping the target column to make things easier.\ny = heart_data['target'] # Target.","401b450c":"# Then we split the data into training and testing data\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 2) # 80% data will be used for training the model and rest 20% for testing.","01d2d1dd":"print(X.shape,X_train.shape)","8683a3ef":"model = LogisticRegression(solver='liblinear')","a0142738":"# Now we need to train the model\nmodel.fit(X_train,y_train) # fitting means training","3cb203ee":"train_pred = model.predict(X_train)\ntrain_pred","ee25415e":"# Now let's check accuracy score on training data\nTraining_score = accuracy_score(train_pred,y_train) #(Basically comparing the original y_train and predictions and seeing difference\/error)\nprint(\"Accuracy Score:\",Training_score)","a9ba515b":"test_pred = model.predict(X_test)\ntest_pred","e4d3603e":"# Accuracy Score\nTest_score = accuracy_score(test_pred,y_test) \nprint(\"Accuracy Score:\",Test_score)","f3aac42f":"# Supervised Machine Learning","67537bf1":"**First, we need to use the model to predict heart disease\/not from the training data. Then, we check our model's accuracy using accuracy score (for classification).**","0fb5124a":"# Missing Values","50850461":"**Accuracy score for test data is much better, at 90.2%. This means the model is very accurate and will predict accurately most of the time.**","1276995a":"**This notebook is a guide for beginners into machine learning, logistic regression to be more specific. There will be comments every step of the way so there is a clear understanding. We will be building a system that predicts whether a person has heart disease or not.**","6aa6356c":"**We can see a lot of cluster around the ages 40-60 so most heart patients are around these ages.**","04f40f6a":"# Exploratory Data Analysis","c1119cb9":"# Logistic Regression","d5d74c37":"# Splitting Data","3ef26354":"**1 means the person has heart disease and 0 means they don't.**","96ce0da7":"**This graph tells us that females tend to have heart disease more but males do not. This could be true but we do have very less samples of females in comparison to males, so this data isn't completely reliable.**","146f1874":"**But keep in mind that we used training data to check accuracy. We need to check using test data for a better understanding.**","c5a1f249":"**We can make observations such as, as chest pain (cp) increases, the likelihood of having heart disease increases. As oldpeak increases,the likelihood of having heart disease decreases.**","5c79014a":"**Good thing we have no missing values in this dataset so no imputation (replacing missing values with other appropriate ones) necessary.**","32acb777":"**We're going to use a logistics regression model.**","4bd33c8c":"**Our model is 82.6% accurate which is very good.**","c34dcf79":"# Conclusion","baadfefd":"# Importing Libraries and dataset","7fe2ca73":"So basically the workflow is like this: Import libraries and dataset -> check for missing values -> perform necessary imputation -> Exploratory Data Analysis -> split data -> train model -> check its accuracy -> improve model or try other ones.\n\n**To get better accuracy, try different models or use more training data.**","1e6ffde0":"# Prediction and Evaluation of the Model","c6e27302":"# Model Building","3680410c":"**As we can see, 242 rows are used for testing out of 303 which is about 79.9% of the data.**","5d5b534c":"**Machine learning is divided into supervised and unsupervised learning. We train our model with data that we have previously acquired in supervised learning. In unsupervised learning, we have no data that we can train our model with.**\n\n**Supervised machine learning is divided into classification and regression. In classification, we predict discrete values, e.g. Yes\/No, Customer will purchase\/Won't purchase. But in regression, we predict continuous values, such as age, price, etc.**","08886b38":"**We have more samples of people with heart disease. Also, we only have 303 samples total which is very less. Predictions would be more reliable if we had more data.**","cec036ee":"# Introduction","528cd8da":"**Don\u2019t confuse this classification algorithms with regression methods for using regression in its title. Logistic regression performs binary classification, so the label outputs are binary. We can also think of logistic regression as a special case of linear regression when the output variable is categorical, where we are using a log of odds as the dependent variable.**"}}