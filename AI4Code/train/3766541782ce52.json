{"cell_type":{"0029a35f":"code","a17fb9ec":"code","9a46cb4b":"code","e6c5a1a0":"code","1eabf206":"code","e2add98c":"code","74dd98d5":"code","60f0ae99":"code","064d9891":"code","9e33d614":"code","d01fbd5b":"code","7750c504":"code","1a64ee77":"code","bb0ce415":"code","d046cb23":"code","3db6c256":"code","e481b6c3":"code","5014695b":"code","061c6d88":"code","a9a3e279":"markdown","c2d9bad6":"markdown","9c1ec2b5":"markdown","adbca08f":"markdown","fa2fc8c2":"markdown","f7902ea8":"markdown","678ab6ea":"markdown","3a9bf656":"markdown"},"source":{"0029a35f":"%matplotlib inline\nimport os\nimport pandas as pd\nimport datetime as dt\nimport numpy as np\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nimport datetime as dt\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nimport warnings\n","a17fb9ec":"plt.rcParams['figure.figsize'] = [16, 10]\nplt.rcParams['font.size'] = 14\nwarnings.filterwarnings('ignore')\npd.options.display.max_columns = 99\nsns.set_palette(sns.color_palette('tab20', 20))","9a46cb4b":"start = dt.datetime.now()","e6c5a1a0":"base = '\/kaggle\/input\/3d-object-detection-for-autonomous-vehicles\/'\ndirs = os.listdir(base)\nprint(dirs)","1eabf206":"train = pd.read_csv(base + 'train.csv')\nsample_submission = pd.read_csv(base + 'sample_submission.csv')\nprint(f'train: {train.shape}, sample submission: {sample_submission.shape}')\ntrain.head(2)\nsample_submission.head(2)","e2add98c":"# Let's check the parsing of prediction strings. Each object should have 8 params\nmax([len(ps.split(' ')) % 8 for ps in train.PredictionString.values])","74dd98d5":"object_columns = ['sample_id', 'object_id', 'center_x', 'center_y', 'center_z',\n                  'width', 'length', 'height', 'yaw', 'class_name']\nobjects = []\nfor sample_id, ps in tqdm(train.values[:]):\n    object_params = ps.split()\n    n_objects = len(object_params)\n    for i in range(n_objects \/\/ 8):\n        x, y, z, w, l, h, yaw, c = tuple(object_params[i * 8: (i + 1) * 8])\n        objects.append([sample_id, i, x, y, z, w, l, h, yaw, c])\ntrain_objects = pd.DataFrame(\n    objects,\n    columns = object_columns\n)","60f0ae99":"for col in object_columns[2:-1]:\n    train_objects[col] = train_objects[col].astype('float')\ntrain_objects['confidence'] = 1.0","064d9891":"train_objects.groupby('sample_id').count()[['object_id']].hist()\nplt.title('Number of objects per sample')\nplt.show();","9e33d614":"train_objects.shape\ntrain_objects.head()\ntrain_objects.describe()","d01fbd5b":"fig, ax = plt.subplots(ncols=3)\nsns.distplot(train_objects.center_x, ax = ax[0])\nsns.distplot(train_objects.center_y, ax = ax[1])\nsns.distplot(train_objects.center_z, ax = ax[2])\nplt.suptitle('X, y, z coord distribution')\nplt.show();","7750c504":"fig, ax = plt.subplots(ncols=3)\nsns.distplot(train_objects.width, ax = ax[0])\nsns.distplot(train_objects.length, ax = ax[1])\nsns.distplot(train_objects.height, ax = ax[2])\nplt.suptitle('Width, length, height distribution')\nplt.show();","1a64ee77":"class_cnt = train_objects.groupby('class_name').count()[['object_id']].sort_values(by='object_id', ascending=False).reset_index()\nclass_cnt['p'] = class_cnt.object_id \/ class_cnt.object_id.sum() \nclass_cnt","bb0ce415":"train_objects.groupby('class_name').mean()","d046cb23":"x, y, z, w, l, h, yaw = train_objects[[\n    'center_x', 'center_y', 'center_z', 'width', 'length', 'height', 'yaw']].mean()\nmean_prediction_string = ' '.join(map(str, [0.9, x, y, z, 10*w, 10*l, h, yaw, 'car']))\n","3db6c256":"sample_submission['PredictionString'] = mean_prediction_string \nsample_submission.to_csv('submission.csv', index=False)","e481b6c3":"sample_submission.shape\nsample_submission.head()","5014695b":"for f in os.listdir(base + 'train_data'):\n    print(f)\n    try:\n        df = pd.read_json(base + 'train_data\/' + f)\n        df.shape\n        df.head()\n        df.nunique()\n    except Exception as e:\n        print(e)","061c6d88":"end = dt.datetime.now()\nprint('Latest run {}.\\nTotal time {}s'.format(end, (end - start).seconds))","a9a3e279":"### Classes\n\nVast majority of the annotated objects is just car. We have other vehicles and pedestrians to detect.","c2d9bad6":"This is certainly an interesting and challenging competition.\n![gif](https:\/\/raw.githubusercontent.com\/lyft\/nuscenes-devkit\/master\/notebooks\/media\/001.gif)\nLets take a look at the 85GB unique dataset!\n\n\n\n**Disclaimer: I do not know anything about 3D object detection nor about Autonomous Vehicles. \nThe notebook is provided \"as is\", without warranty of any kind... :)**","9c1ec2b5":"# Sample submission","adbca08f":"The annotations in train.csv have the following components:\n* **center_x**, **center_y** and **center_z** are the world coordinates of the center of the 3D bounding volume.\n* **width**, **length** and **height** are the dimensions of the volume.\n* **yaw** is the angle of the volume around the z axis (where y is forward\/back, x is left\/right, and z is up\/down - making 'yaw' the direction the front of the vehicle \/ bounding box is pointing at while on the ground).\n* **class_name** is the type of object contained by the bounding volume.\n\n\n**We have 638K annotated objects in 22K train samples.**","fa2fc8c2":"# Unique ground truth and submission format\nWe are required to optimize a custom performance metric, the mean average precision[](http:\/\/) at different intersection over union (IoU) thresholds.","f7902ea8":"\n### Object annotations","678ab6ea":"# References\n[1] https:\/\/github.com\/lyft\/nuscenes-devkit","3a9bf656":"## Train data"}}