{"cell_type":{"441a2c1d":"code","d6504c6e":"code","26fa7f84":"code","df7a3090":"code","dc051eb7":"markdown","320e0a60":"markdown","9d0a80db":"markdown","c2fc7c93":"markdown"},"source":{"441a2c1d":"import os\nimport cv2\nimport numpy as np\nfrom time import time\nfrom tensorflow.keras import utils\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, MaxPooling2D\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline","d6504c6e":"train_dir = '..\/input\/asl-alphabet\/asl_alphabet_train\/asl_alphabet_train'\ntest_dir = '..\/input\/asl-alphabet\/asl_alphabet_test\/asl_alphabet_test'\nclasses = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', \n           'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', \n           'W', 'X', 'Y', 'Z', 'nothing', 'space', 'del']\nplt.figure(figsize=(11, 11))\nfor i in range (0,29):\n    plt.subplot(7,7,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    path = train_dir + \"\/{0}\/{0}1.jpg\".format(classes[i])\n    img = plt.imread(path)\n    plt.imshow(img)\n    plt.xlabel(classes[i])","26fa7f84":"def load_data(train_dir):\n    images = []\n    labels = []\n    size = 32,32\n    index = -1\n    for folder in os.listdir(train_dir):\n        index +=1\n        for image in os.listdir(train_dir + \"\/\" + folder):\n            temp_img = cv2.imread(train_dir + '\/' + folder + '\/' + image)\n            temp_img = cv2.resize(temp_img, size)\n            images.append(temp_img)\n            labels.append(index)\n    \n    images = np.array(images)\n    images = images.astype('float32')\/255.0\n    labels = utils.to_categorical(labels)\n    x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size = 0.1)\n    \n    print('Loaded', len(x_train),'images for training,','Train data shape =', x_train.shape)\n    print('Loaded', len(x_test),'images for testing','Test data shape =', x_test.shape)\n    \n    return x_train, x_test, y_train, y_test\n\nstart = time()\nx_train, x_test, y_train, y_test = load_data(train_dir)\nprint('Loading:', time() - start)","df7a3090":"def autoencoder_train(encoder, decoder, data, epochs, batch, learning_rate=0.0001):\n    autoencoder = Sequential([encoder, decoder])\n    adam = Adam(lr=learning_rate)\n    autoencoder.compile(optimizer=adam, loss='mse')\n    start = time()\n    autoencoder.fit(data, data, epochs=epochs, batch_size=batch)\n    train_time = time() - start\n\n    return encoder, data, train_time\n\ndef CNN(x_train, y_train, x_test, y_test, epochs, batch, neurons, learning_rate=0.001):\n    cur_data = x_train.copy() \n    encoder_1 = Sequential()\n    encoder_1.add(Conv2D(32, (3, 3), activation='tanh', padding='same', input_shape=(32,32,3)))\n    encoder_1.add(MaxPooling2D(pool_size=(2, 2)))\n    decoder_1 = Sequential([Conv2DTranspose(3, (3, 3), strides=(2, 2), padding='same', input_shape=(16, 16, 32))])\n    encoder_1, cur_data, cnn_ae_train_time = autoencoder_train(encoder_1, decoder_1, cur_data, epochs, batch)\n    cur_data = encoder_1.predict(cur_data) \n\n    cur_data = cur_data.reshape(cur_data.shape[0], 8192)  \n    encoder_2 = Sequential([Dense(512, activation='sigmoid')])\n    decoder_2 = Sequential([Dense(8192, activation='sigmoid')])\n    encoder_2, cur_data, fcnn_ae_train_time = autoencoder_train(encoder_2, decoder_2, cur_data, epochs, batch)\n    \n    model = Sequential([encoder_1, Flatten(), encoder_2]) \n    model.add(Dense(29, activation='softmax'))\n\n    adam = Adam(lr=learning_rate) \n    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n    model.summary()\n\n    start = time()\n    model.fit(x_train, y_train, epochs=5, batch_size=128, validation_split=0.1, shuffle = True)\n    train_time = time() - start\n    print('\\nAutoencoder train_time: ', cnn_ae_train_time + fcnn_ae_train_time)\n    print('\\nCNN Train time: ', train_time)\n    test_loss, test_acc = model.evaluate(x_test, y_test)\n    print('\\nTest loss:', test_loss)\n    print('\\nCNN Test accuracy:', test_acc)\n    \nCNN(x_train, y_train, x_test, y_test, epochs = 5, batch = 128, neurons = 512)","dc051eb7":"## Autoencoder","320e0a60":"## Loading","9d0a80db":"# ASL Alphabet Classification with CNN + Autoencoder","c2fc7c93":"## The data"}}