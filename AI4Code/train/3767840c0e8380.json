{"cell_type":{"ef38975d":"code","cdb0bd90":"code","096ec295":"code","d62beed4":"code","037d0b4f":"code","f5a2ce06":"code","aef9cb29":"code","0c4df91d":"code","3807961e":"code","1da6b22b":"code","a13f0e16":"code","8a8c0712":"code","11004b60":"code","25698e93":"code","57f2039b":"code","75d51054":"code","c58e6c17":"code","cf22f3b1":"code","e69fb07b":"code","81c872b7":"code","211e3178":"code","7d00de8d":"markdown","05ad10e2":"markdown","f14869c2":"markdown","a47f6b49":"markdown"},"source":{"ef38975d":"import wave\nimport gc\nimport librosa\nimport librosa.display\nimport IPython\nimport numpy as np\nimport tensorflow as tf\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.python.client import device_lib","cdb0bd90":"#configs\ntqdm.pandas()","096ec295":"device_lib.list_local_devices()","d62beed4":"df = pd.read_csv(\"..\/input\/urbansound8k\/UrbanSound8K.csv\")","037d0b4f":"df","f5a2ce06":"def display_audio_file(audio_file_path):\n    y, sr = librosa.load(audio_file_path)\n    \n    plt.figure(figsize=(14,7))\n    \n    plt.subplot(2, 2, 1)\n    spectrogram = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n    librosa.display.specshow(spectrogram, y_axis='linear')\n    \n    signal_plot = plt.subplot(2, 2, 2)\n    signal_plot.plot(y, color=\"c\")\n    IPython.display.display(IPython.display.Audio(audio_file_path))\n","aef9cb29":"display_audio_file('..\/input\/urbansound8k\/fold8\/103076-3-1-0.wav')","0c4df91d":"display_audio_file('..\/input\/urbansound8k\/fold8\/106905-5-0-1.wav')","3807961e":"display_audio_file('..\/input\/urbansound8k\/fold5\/100852-0-0-12.wav')","1da6b22b":"display_audio_file('..\/input\/urbansound8k\/fold2\/102871-8-0-1.wav')","a13f0e16":"audio_data_directory = \"..\/input\/urbansound8k\/\"\nspectrograms_directory = \"\/kaggle\/temp\/spectrograms\/\"","8a8c0712":"def generate_spectrograms(row):\n\n    audio_class = row[\"classID\"]\n    spect_directory = \"class_\" + str(audio_class)\n    audio_file_name_without_extension = row[\"slice_file_name\"][:-4]\n    \n    y, sr = librosa.load(audio_data_directory + \"fold\" + str(row[\"fold\"]) + \"\/\" + row[\"slice_file_name\"])\n    \n    spectrogram = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n    librosa.display.specshow(spectrogram, y_axis='linear')\n    \n    plt.savefig(spectrograms_directory + spect_directory + \"\/\" + audio_file_name_without_extension + \".png\")\n\n    plt.clf() \n    plt.close('all')\n    gc.collect()","11004b60":"# Creating the classes directories\nfor i in range(0,10):\n    Path(spectrograms_directory + \"class_\" + str(i)).mkdir(parents=True, exist_ok=True)","25698e93":"df.progress_apply(generate_spectrograms, axis=1)","57f2039b":"X_train = tf.keras.preprocessing.image_dataset_from_directory(spectrograms_directory,validation_split = 0.225,\n                                                              subset = \"training\", seed=7)\nX_test = tf.keras.preprocessing.image_dataset_from_directory(spectrograms_directory,validation_split = 0.225,\n                                                             subset=\"validation\", seed=7)","75d51054":"model = Sequential([\n    \n    layers.experimental.preprocessing.Rescaling(1.\/255,  input_shape=(256, 256, 3)),\n    \n    layers.Conv2D(32, 7, strides = 4, padding=\"same\"),\n    layers.BatchNormalization(),\n    layers.Activation(\"relu\"),\n    \n    layers.MaxPooling2D((4,4)),\n    \n    layers.Conv2D(128, 3, padding=\"same\"),\n    layers.BatchNormalization(),\n    layers.Activation(\"relu\"),\n\n    layers.Flatten(),\n    \n    layers.Dense(256),\n    layers.BatchNormalization(),\n    layers.Activation(\"relu\"),\n    \n    layers.Dense(10, activation='softmax')\n])","c58e6c17":"model.summary()","cf22f3b1":"model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n              metrics=['accuracy'])","e69fb07b":"model_history = model.fit(X_train, validation_data=X_test, epochs=100)","81c872b7":"plt.figure(figsize=(15,5))\n\nplt_loss = plt.subplot(121)\nplt_loss.plot(model_history.history[\"loss\"])\nplt_loss.plot(model_history.history[\"val_loss\"])\n# plt.title(\"\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Training\", \"Validation\"], loc=\"upper right\")\n\nplt_accuracy = plt.subplot(122)\nplt_accuracy.plot(model_history.history[\"accuracy\"])\nplt_accuracy.plot(model_history.history[\"val_accuracy\"])\n# plt.title(\"\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Training\", \"Validation\"], loc=\"lower right\")","211e3178":"img = tf.keras.preprocessing.image.load_img(\"\/kaggle\/temp\/spectrograms\/class_3\/103076-3-1-0.png\", target_size=(256, 256))\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nprint(img_array.shape)\nimg_array = tf.expand_dims(img_array, 0)\nprint(img_array.shape)\npredictions = model.predict(img_array)\nscore = tf.nn.softmax(predictions[0])\nprint( \"class : \"+ str(np.argmax(score)) +\" ; Probability = \"+ str(np.max(score)))\nscore","7d00de8d":"# Creating and training the model","05ad10e2":"# Loading and displaying some audio files","f14869c2":"# Loading the Dataset","a47f6b49":"# Creating and saving spectrograms in png files"}}