{"cell_type":{"a49e5380":"code","7cb3ba1a":"code","d60a1fe0":"code","b544f923":"code","cf6343d5":"code","12533345":"code","86298b91":"code","c9419daa":"code","4e23f0e2":"code","1d503f48":"code","04f11e97":"code","ab8b219b":"code","694afbb3":"code","715c726c":"code","4b9a9aa6":"code","1bbf5115":"code","c5051c66":"code","6ba0e229":"code","0364fcc9":"code","faee8f4e":"code","35a481c2":"code","32fd894b":"code","083b6bf9":"code","17e03bc7":"code","06052fd5":"markdown","99f7c52f":"markdown","922e5f51":"markdown","463b1958":"markdown","ed068be2":"markdown","ad781ee7":"markdown","6ff00e2d":"markdown","e651e11d":"markdown","902196c8":"markdown","0c26ac6c":"markdown","cee1ae23":"markdown","b2b68baa":"markdown","a3668904":"markdown","7990bf77":"markdown","4fe2680b":"markdown","ef172ac1":"markdown"},"source":{"a49e5380":"# Import Required Python Packages :\n\n# Scientific and Data Manipulation Libraries :\n\nimport numpy as np\nimport pandas as pd\n\n# Data Viz & Regular Expression Libraries :\n\nimport matplotlib.pyplot as plt\nget_ipython().run_line_magic('matplotlib', 'inline')\n\n# Scikit-Learn ML Libraries :\n\nfrom sklearn.preprocessing import *\nfrom sklearn.model_selection import *\nfrom sklearn.metrics import *\n\n# Garbage Collection Libraries :\n\nimport gc\n\n# Boosting Algorithm Libraries :\n\nfrom sklearn.tree                     import DecisionTreeClassifier\nfrom xgboost                          import XGBRegressor\nfrom catboost                         import CatBoostRegressor\nfrom lightgbm                         import LGBMRegressor\nfrom sklearn.ensemble                 import ExtraTreesClassifier, VotingClassifier\n\n# Date & Time Libraries :\nfrom datetime import datetime\nimport time\n\n# Setting SEED in Numpy to get Reproducible Results :\nnp.random.seed(0)","7cb3ba1a":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d60a1fe0":"# Loading data from the default Path \"\/kaggle\/input\/\" + Created data Repository \"health\" :\n# Import Data from Excel Files in .csv format and store in Table format called DataFrame using Pandas :\n\ntrain           = pd.read_csv('..\/input\/ml-iot\/train_ML_IOT.csv')\ntest            = pd.read_csv('..\/input\/ml-iot\/test_ML_IOT.csv')\nss              = pd.read_csv('..\/input\/ml-iot\/sample_submission_ML_IOT.csv')","b544f923":"# Python Method 1 : Displays Data Information :\n\ndef display_data_information(data, data_types, dataframe_name):\n    print(\" Information of \",dataframe_name,\": Rows = \",data.shape[0],\"| Columns = \",data.shape[1],\"\\n\")\n    data.info()\n    print(\"\\n\")\n    for VARIABLE in data_types :\n        data_type = data.select_dtypes(include=[ VARIABLE ]).dtypes\n        if len(data_type) > 0 :\n            print(str(len(data_type))+\" \"+VARIABLE+\" Features\\n\"+str(data_type)+\"\\n\"  )        \n\n# Display Data Information of \"train\" :\n\ndata_types  = [\"float32\",\"float64\",\"int32\",\"int64\",\"object\",\"category\",\"datetime64[ns]\"]\ndisplay_data_information(train, data_types, \"Train\")","cf6343d5":"# Display Data Information of \"test\" :\n\ndata_types  = [\"float32\",\"float64\",\"int32\",\"int64\",\"object\",\"category\",\"datetime64[ns]\"]\ndisplay_data_information(test, data_types, \"Test\")","12533345":"# Python Method 2 : Displays Data Head (Top Rows) and Tail (Bottom Rows) of the Dataframe (Table) :\n\ndef display_head_tail(data, head_rows, tail_rows):\n    display(\"Data Head & Tail :\")\n    display(data.head(head_rows).append(data.tail(tail_rows)))\n#     return True\n\n# Displays Data Head (Top Rows) and Tail (Bottom Rows) of the Dataframe (Table)\n# Pass Dataframe as \"Train\", No. of Rows in Head = 3 and No. of Rows in Tail = 2 :\n\ndisplay_head_tail(train, head_rows=3, tail_rows=2)","86298b91":"# Displays Data Head (Top Rows) and Tail (Bottom Rows) of the Dataframe (Table)\n# Pass Dataframe as \"Test\", No. of Rows in Head = 3 and No. of Rows in Tail = 2 :\n\ndisplay_head_tail(test, head_rows=3, tail_rows=2)","c9419daa":"# Python Method 3 : Displays Data Description using Statistics :\n\ndef display_data_description(data, numeric_data_types, categorical_data_types):\n    \n    print(\"Data Description :\")\n    display(data.describe( include = numeric_data_types))\n#     print(\"\")\n    display(data.describe( include = categorical_data_types))\n\n# Display Data Description of \"Train\" :\n\ndisplay_data_description(train, data_types[0:4], data_types[4:7])","4e23f0e2":"# Display Data Description of \"Test\" :\n\ndisplay_data_description(test, data_types[0:4], data_types[4:7])","1d503f48":"# Checking Percentage(%) of Common ID's  between train and test data using Unique train values :\n\nnp.intersect1d(train['ID'], test['ID']).shape[0]\/train['ID'].nunique()\n\n# No Common ID - So Data Leak in ID Column - Good to Go !!!","04f11e97":"# Dropping \"ID\" Columns in Train and Test :\n\ntrain.drop([\"ID\"],axis = 1,inplace=True)\n\ntest_ID = test[\"ID\"]\ntest.drop([\"ID\"],axis = 1,inplace=True)","ab8b219b":"# Python Method 4 : Removes Data Duplicates while Retaining the First one - Similar to SQL DISTINCT :\n\ndef remove_duplicate(data):\n    \n    print(\"BEFORE REMOVING DUPLICATES - No. of Rows = \",data.shape[0])\n    data.drop_duplicates(keep=\"first\", inplace=True) \n    print(\"AFTER REMOVING DUPLICATES  - No. of Rows = \",data.shape[0])\n    \n    return data\n\n# Remove Duplicates from \"train\" data :\n\ntrain = remove_duplicate(train)\n\n# No Duplicates are there to remove - Good to Go !!!","694afbb3":"# Python Method 5 : Fills or Imputes Missing values with Various Methods : \n\ndef fill_missing_values(data, fill_value, fill_types, columns, dataframe_name):\n    \n    print(\"Missing Values BEFORE REMOVAL in \",dataframe_name,\" data\")\n    display((data.isnull().sum()).sum())\n    \n    if (data.isnull().sum()).sum() != 0 :\n    \n        for column in columns :\n\n            # Fill Missing Values with Specific Value :\n            if \"Value_Fill\" in fill_types :\n                data[ column ] = data[ column ].fillna(fill_value)\n    #             print(\"Value_Fill\")\n\n            # Fill Missing Values with Forward Fill  (Previous Row Value as Current Row in Table) :\n            if \"Forward_Fill\" in fill_types :\n                data[ column ] = data[ column ].ffill(axis = 0)\n    #             print(\"Forward_Fill\")\n\n            # Fill Missing Values with Backward Fill (Next Row Value as Current Row in Table) :\n            if \"Backward_Fill\" in fill_types :\n                data[ column ] = data[ column ].bfill(axis = 0)\n    #             print(\"Backward_Fill\")\n\n        print(\"Missing Values AFTER REMOVAL in \",dataframe_name,\" data\")\n        display(data.isnull().sum())\n    \n    return data\n\nfill_types = [ \"Forward_Fill\"]\nfill_value = 0\n\n# Fills or Imputes Missing values in \"Registration_Date\" Column with \"Forward_Fill\" Method in \"train\" : \ntrain = fill_missing_values(train, fill_value, fill_types, train.columns,\"train\")\n\n# Fills or Imputes Missing values in \"Registration_Date\" Column with \"Forward_Fill\" Method in \"train\" :\ntest  = fill_missing_values(test, fill_value, fill_types,train.columns,\"test\")","715c726c":"# Python Method 6 : Displays Unique Values in Each Column of the Dataframe(Table) :\n\ndef display_unique(data):\n    for column in data.columns :\n        \n        print(\"No of Unique Values in \"+column+\" Column are : \"+str(data[column].nunique()))\n        print(\"Actual Unique Values in \"+column+\" Column are : \"+str(data[column].sort_values(ascending=True,na_position='last').unique() ))\n        print(\"NULL Values :\")\n        print(data[ column ].isnull().sum())\n        print(\"Value Counts :\")\n        print(data[column].value_counts())\n        print(\"\")\n        \n# Displays Unique Values in Each Column of \"Train\" :\n\ndisplay_unique(train)\n\n# Display this info in a Table Format - Improvements coming In Part 2","4b9a9aa6":"display_unique(test)","1bbf5115":"# Python Method 7 : Converts Date to seconds & Replacing Date with unixtime list :\n\ndef datetounix(df):\n    # Initialising unixtime list\n    unixtime = []\n    \n    # Running a loop for converting Date to seconds\n    for date in df['DateTime']:\n        unixtime.append(time.mktime(date.timetuple()))\n    \n    # Replacing Date with unixtime list\n    df['DateTime'] = unixtime\n    return(df)","c5051c66":"# Converting to datetime :\n\n# filtering data greater than or equal to 01 Jan 2016\n# train=train[train['DateTime']>='2016-01-01']\n\ntrain['DateTime'] = pd.to_datetime(train['DateTime'])\ntest['DateTime'] = pd.to_datetime(test['DateTime'])\ntest.info()","6ba0e229":"# Creating features from DateTime for train data\n\ntrain['Weekday'] = [datetime.weekday(date) for date in train.DateTime]\ntrain['Year'] = [date.year for date in train.DateTime]\ntrain['Month'] = [date.month for date in train.DateTime]\ntrain['Day'] = [date.day for date in train.DateTime]\ntrain['Time'] = [((date.hour*60+(date.minute))*60)+date.second for date in train.DateTime]\ntrain['Week'] = [date.week for date in train.DateTime]\ntrain['Quarter'] = [date.quarter for date in train.DateTime]\n\n# Creating features from DateTime for test data\n\ntest['Weekday'] = [datetime.weekday(date) for date in test.DateTime]\ntest['Year'] = [date.year for date in test.DateTime]\ntest['Month'] = [date.month for date in test.DateTime]\ntest['Day'] = [date.day for date in test.DateTime]\ntest['Time'] = [((date.hour*60+(date.minute))*60)+date.second for date in test.DateTime]\ntest['Week'] = [date.week for date in test.DateTime]\ntest['Quarter'] = [date.quarter for date in test.DateTime]","0364fcc9":"# Visualising the histogram for positive reviews only from train and dataset\ndata = train.Vehicles\nbinwidth = 1\nplt.hist(data, bins=range(min(data), max(data) + binwidth, binwidth), log=False)\nplt.title(\"Gaussian Histogram\")\nplt.xlabel(\"Traffic\")\nplt.ylabel(\"Number of times\")\nplt.show()","faee8f4e":"# Convert timestamp to seconds\ntrain_features = datetounix(train.drop(['Vehicles','Year', 'Quarter', 'Month'], axis=1))\ntest_features = datetounix(test.drop(['Year', 'Quarter', 'Month'], axis=1))\n\n# Store Features \/ Predictors in array :\nX      = train_features  \nX_test = test_features\n\n# Convert into String \/ Catergorial Features :\nX[ 'Junction' ]                         = X[ 'Junction' ].astype('str')\nX[ 'Weekday' ]                          = X[ 'Weekday' ].astype('str')\nX[ 'Day' ]                              = X[ 'Day' ].astype('str')\nX_test[ 'Junction' ]                    = X_test[ 'Junction' ].astype('str')\nX_test[ 'Weekday' ]                     = X_test[ 'Weekday' ].astype('str')\nX_test[ 'Day' ]                         = X_test[ 'Day' ].astype('str')\n\n# One Hot Encoding - Using Dummies :\nX = pd.get_dummies(X)\nX_test = pd.get_dummies(X_test)\n\n# Store target 'Vehicles' in y array :\ny = train['Vehicles'].to_frame()\n\n# Displays Data Head (Top Rows) and Tail (Bottom Rows) of the Dataframe (Table)\n# Pass Dataframe as \"X\", No. of Rows in Head = 3 and No. of Rows in Tail = 2 :\nprint(\"X.shape : \", X.shape)\ndisplay_head_tail(X, head_rows=3, tail_rows=2)\ndisplay(X.columns)\n\n# Displays Data Head (Top Rows) and Tail (Bottom Rows) of the Dataframe (Table)\n# Pass Dataframe as \"X_test\", No. of Rows in Head = 3 and No. of Rows in Tail = 2 :\n\nprint(\"X_test.shape : \", X_test.shape)\ndisplay_head_tail(X_test, head_rows=3, tail_rows=2)\ndisplay(X_test.columns)","35a481c2":"# Data prep\ndf_solution = pd.DataFrame()\ndf_solution['ID'] = test_ID\n\n# Starting time for time calculations\nstart_time = time.time()\n\nvalue = 16\n\n# Algorithm 0 : Baseline - Decision tree Classifier  \n# Refer Official Documentation : https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.DecisionTreeClassifier.html\n# -------------------------------------------------------------------------------------------------------------------------\n\n# 1. Create a Baseline - Machine Learning Model :\n\nclf = LGBMRegressor(boosting_type='gbdt',\n                    max_depth=6,\n                    learning_rate=0.25, \n                    n_estimators=80, # BESTTTT !!! Reduced \n                    min_split_gain=0.7,\n                    reg_alpha=0.00001,\n                    random_state = value\n                   )\n\n\n\n# 2. Fit the created Machine Learning Model on \"train\" data - X(Predictors) & y(Target) :\nclf = clf.fit(X, y)\n\n# 3. Predict the Target \"Vehicles\" for testing data - X_test(Predictors)  :\npredictions = clf.predict(X_test)\n\nprint(\"The time taken to execute is %s seconds\" % (time.time() - start_time))","32fd894b":"# To be Done - Later !","083b6bf9":"submission_count = 0","17e03bc7":"# Prepare Solution dataframe\ndf_solution['Vehicles'] = predictions\ndisplay(df_solution.head())\n\nclassifier_name = \"LGBM_Regressor_TUNED_BEST_SUBMITTED\"+str(value)\n\nsubmission_count = submission_count + 1\ndf_solution.to_csv(str(submission_count)+\".)_FINAL \"+classifier_name+\".csv\", index = False)","06052fd5":"# **Download Data Set here :** https:\/\/www.kaggle.com\/vetrirah\/ml-iot\/","99f7c52f":"## 6.  Split Train Data into Train and Validation Data with Predictors(Independent) & Target(Dependent) and \n\n## 7. Data Encoding - OneHot Encoding :","922e5f51":"![8th_AV_IOT_Analytics.png](attachment:8th_AV_IOT_Analytics.png)","463b1958":"## 10. Result Submission, Check Leaderboard & Improve RMSE :","ed068be2":"## Link to the Analytics Vidhya HACKATHON - JanataHack Machine Learning for IOT\n\n### Problem Statement :\n### https:\/\/datahack.analyticsvidhya.com\/contest\/janatahack-machine-learning-for-iot\/#ProblemStatement\n\n### Leaderboard - Rank 14\n### Reached Rank 8 Later \n### https:\/\/datahack.analyticsvidhya.com\/contest\/janatahack-machine-learning-for-iot\/#LeaderBoard","ad781ee7":"## 8.  Create Baseline ML Model :","6ff00e2d":"## 1.  Understand the Problem Statement & Import Packages and Datasets :","e651e11d":"## 2. Perform EDA (Exploratory Data Analysis) - Understanding the Datasets :    \n\n### 2.1 Explore Train and Test Data and get to know what each Column \/ Feature denotes :","902196c8":"## 9. Improve ML Model,Fine Tune with MODEL Evaluation METRIC - RMSE and Predict Target \"Vehicles\" :","0c26ac6c":"## Steps for Applied Machine Learning (ML) for Hackathons :\n\n1.  Understand the Problem Statement & Import Packages and Datasets.  \n\n2.  Perform EDA (Exploratory Data Analysis) - Understanding the Datasets :\n\n       *       Explore Train and Test Data and get to know what each Column \/ Feature denotes.\n       *       Check for Imbalance of Target Column in Datasets.\n       *       Visualize Count Plots & Unique Values to infer from Datasets.\n            \n3.  Remove Duplicate Rows from Train Data if present.\n\n4.  Fill\/Impute Missing Values Continuous - Mean\/Median\/Any Specific Value & Categorical - Others\/ForwardFill\/BackFill.\n\n5.  Feature Engineering \n\n      *       Feature Selection - Selection of Most Important Existing Features.\n      *       Feature Creation  - Creation  of New Feature from the Existing Features.\n      \n6.  Split Train Data into Train and Validation Data with Predictors(Independent) & Target(Dependent).      \n7.  Data Encoding - Label Encoding, OneHot Encoding and Data Scaling - MinMaxScaler, StandardScaler, RobustScaler\n8.  Create Baseline ML Model for Multi Class Classification Problem\n9.  Improve ML Model,Fine Tune with MODEL Evaluation METRIC - RMSE and Predict Traget \"Outcome\"\n10. Result Submission, Check Leaderboard & Improve \"RMSE\"","cee1ae23":"### Data - Train, Test and Sample Submission can be Downloaded by Registering by Clicking the Link :\n\n### https:\/\/datahack.analyticsvidhya.com\/contest\/janatahack-machine-learning-for-iot\/#ProblemStatement","b2b68baa":"## 5.  Feature Engineering\n\n### 5.1 Feature Selection - Selection of Most Important Existing Features\n### 5.2 Feature Creation  - Creation  of New Features from the Existing Features \/ Predictors :","a3668904":"![IOT_ProblemStatement.jpg](attachment:IOT_ProblemStatement.jpg)","7990bf77":"### **<center>\ud83d\ude0a Reached Rank 8 - Thanks for reading Friends. See you all in Part 2 for more Analysis and Modelling - ENCOURAGE if you liked this Notebook \ud83d\ude0a<\/center>**\n\n### **<center>\ud83d\ude0a For Learning Purpose - You can still participate in your free time to see your Public and Private Scores & Rank, though it won't reflect on Leaderboard \ud83d\ude0a<\/center>**\n\n### **<center>\ud83d\ude0a Ask your doubts & Share your thoughts, ideas & feedbacks in Comments below \ud83d\ude0a<\/center>**","4fe2680b":"## 4.  Fill\/Impute Missing Values Continuous - Mean\/Median\/Any Specific Value & Categorical - Others\/ForwardFill\/BackFill :","ef172ac1":"## 3.  Remove Duplicate Rows from Train data if present :"}}