{"cell_type":{"327f2006":"code","e76cb032":"code","f612fde2":"code","49a0b6f8":"code","f3edb5ec":"code","24f36814":"code","c1423e21":"code","380f7ceb":"code","cd962c63":"code","b108a77a":"code","766051cd":"code","f7f43e44":"code","2e280cde":"code","17d9db9b":"code","04515cad":"code","2a1e435a":"code","0cb55eb8":"code","6f7dffa8":"code","362d1fc1":"code","db5cfe75":"code","7d595c67":"code","df494f6e":"code","e9242fc9":"code","822a5944":"code","da3d70be":"code","082be735":"code","702b6c8f":"code","41b27cc0":"code","4406fcd8":"code","4d8e7d3d":"code","ee4140aa":"code","e7619791":"code","d71200b2":"code","0d61c9a6":"code","b6dd4e42":"code","7a399272":"code","e1cea85a":"code","a46fd90d":"code","bad6ec3c":"markdown","7cf9b39f":"markdown","526ac45b":"markdown"},"source":{"327f2006":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e76cb032":"import numpy as np\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.metrics import f1_score","f612fde2":"train = pd.read_csv(\"\/kaggle\/input\/novartis-data\/Train.csv\")\nsubmit = pd.read_csv(\"\/kaggle\/input\/novartis-data\/sample_submission.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/novartis-data\/Test.csv\")","49a0b6f8":"train.head()","f3edb5ec":"sns.countplot(train.MULTIPLE_OFFENSE.value_counts())","24f36814":"train.MULTIPLE_OFFENSE.value_counts()","c1423e21":"test.shape","380f7ceb":"\ntrain.head(2)","cd962c63":"X = train.drop(['MULTIPLE_OFFENSE', 'DATE', 'INCIDENT_ID'],axis=1)\neval_X = test.drop(['DATE','INCIDENT_ID'],axis=1)\nY = train['MULTIPLE_OFFENSE']\n\nincident_ids_train = train['INCIDENT_ID']\nincdent_ids_test = test['INCIDENT_ID']\n","b108a77a":"#splitting data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.33)\nX_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.33)","766051cd":"X_train.shape, y_train.shape,X_test.shape","f7f43e44":"X_train.fillna(0, inplace=True)\nX_cv.fillna(0, inplace=True)\nX_test.fillna(0, inplace=True)\neval_X.fillna(0, inplace=True)","2e280cde":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train)\n\nX_train = pd.DataFrame(scaler.transform(X_train), columns = X_train.columns)","17d9db9b":"X_cv = pd.DataFrame(scaler.transform(X_cv), columns = X_cv.columns)\nX_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\neval_X = pd.DataFrame(scaler.transform(eval_X), columns = eval_X.columns)","04515cad":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\n#Additional scklearn functions\nfrom sklearn.model_selection import GridSearchCV","2a1e435a":"X_train.shape, y_train.shape","0cb55eb8":"X_train.head()","6f7dffa8":"#Choose all predictors except target & IDcols\npredictors = [x for x in X_train.columns]\nparam_test1 = {'n_estimators':range(140,401,10)}\ngsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=500,min_samples_leaf=50,max_depth=8,max_features='sqrt',subsample=0.8,random_state=10), \nparam_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\ngsearch1.fit(X_train[predictors],y_train)","362d1fc1":" gsearch1.best_params_, gsearch1.best_score_","db5cfe75":"param_test2 = {'max_depth':range(5,16,2), 'min_samples_split':range(200,1001,200)}\ngsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=320, max_features='sqrt', subsample=0.8, random_state=10), \nparam_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\ngsearch2.fit(X_train[predictors],y_train)\ngsearch2.best_params_, gsearch2.best_score_","7d595c67":"param_test4 = {'max_features':range(7,20,2)}\ngsearch4 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=320,max_depth=7, min_samples_split=200, min_samples_leaf=60, subsample=0.9, random_state=10),\nparam_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\ngsearch4.fit(X_train[predictors],y_train)\ngsearch4.best_params_, gsearch4.best_score_","df494f6e":"param_test5 = {'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}\ngsearch5 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=320,max_depth=7,min_samples_split=200, min_samples_leaf=60, subsample=0.8, random_state=10,max_features=7),\nparam_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\ngsearch5.fit(X_train[predictors],y_train)\ngsearch5.best_params_, gsearch5.best_score_","e9242fc9":"gbm_tuned_1 = GradientBoostingClassifier(learning_rate=0.05, n_estimators=320,max_depth=7, min_samples_split=200,min_samples_leaf=40, subsample=0.90, random_state=10, max_features=7)\ngbm_tuned_1","822a5944":"gbm_tuned_1.fit(X_train, y_train)\n","da3d70be":"res = gbm_tuned_1.predict(X_test)","082be735":"print(f1_score(y_test, res))","702b6c8f":"res = gbm_tuned_1.predict(eval_X)\nres_df = pd.DataFrame({'MULTIPLE_OFFENSE':res, 'INCIDENT_ID': incdent_ids_test})\nres_df1 = res_df[['INCIDENT_ID','MULTIPLE_OFFENSE']]","41b27cc0":"res_df.shape, res_df1.shape","4406fcd8":"res_df1.to_csv(\"output_2.csv\",index = False)","4d8e7d3d":"from sklearn.metrics import roc_curve, auc\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import svm\n\nbest_k_value = 13\n\nneigh = svm.SVC(probability=True, class_weight={0: 10})\n\n\n\n# neigh = KNeighborsClassifier(n_neighbors=best_k_value)\n\n# neigh = GaussianNB()\nneigh.fit(X_train, y_train)\n\ntrain_fpr, train_tpr, thresholds = roc_curve(y_train, neigh.predict_proba(X_train)[:,1])\ntest_fpr, test_tpr, thresholds = roc_curve(y_test, neigh.predict_proba(X_test)[:,1])\n\nplt.plot(train_fpr, train_tpr, label = 'TRAIN')\nplt.plot(test_fpr, test_tpr, label = 'TEST')\nplt.legend()\nplt.xlabel('K')\nplt.ylabel('AUC')\nplt.title('Error Plots')\nplt.show()","ee4140aa":"from sklearn.metrics import confusion_matrix \nfrom sklearn.metrics import f1_score\n\ny_train_predict = neigh.predict(X_train)\ny_test_predict = neigh.predict(X_test)\n\ntrain_confusion_matrix = confusion_matrix(y_train, y_train_predict)\ntest_confusion_matrix = confusion_matrix(y_test, y_test_predict)","e7619791":"print(\"train CM:\")\n# print(train_confusion_matrix)\n\nprint(\"test CM:\")\nprint(test_confusion_matrix)\n","d71200b2":"print(\"Training F1 score\")\nprint(f1_score(y_train, y_train_predict))\nprint(\"Test F1 score\")\nprint(f1_score(y_test, y_test_predict))\n","0d61c9a6":"# eval_X.head()","b6dd4e42":"res = neigh.predict(eval_X)\nres_df = pd.DataFrame({'MULTIPLE_OFFENSE':res, 'INCIDENT_ID': incdent_ids_test})\nres_df1 = res_df[['INCIDENT_ID','MULTIPLE_OFFENSE']]\n","7a399272":"print(res_df.shape)","e1cea85a":"res_df1.head()","a46fd90d":"res_df1.to_csv(\"results3.csv\",index = False)","bad6ec3c":"# **Hyper parameter tuning**","7cf9b39f":"# **Applying GradientBoostingClassifier**","526ac45b":"# Trying out with Knn, GaussianNB, SVC"}}