{"cell_type":{"bbe40ff1":"code","2e08dc81":"code","e46beaa1":"code","0ff6b8ba":"code","cf55796e":"code","24d400ac":"code","6b618c02":"code","25016e77":"code","0f589eaa":"code","ea3ded65":"code","6a0312ed":"code","3bbab0db":"code","b9ad3466":"code","85a35de8":"code","5fa6ef52":"code","45203a7e":"code","c5bf0847":"code","e3301eea":"code","1548b56d":"code","222f459b":"code","e9e5ecc4":"code","aa33f94f":"code","30fe19c2":"code","317c0f8d":"code","a1dc97e3":"markdown"},"source":{"bbe40ff1":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport gc\nimport joblib\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics, preprocessing\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import utils","2e08dc81":"train = pd.read_csv(\"..\/input\/cat-in-the-dat-ii\/train.csv\")\ntest = pd.read_csv(\"..\/input\/cat-in-the-dat-ii\/test.csv\")\nsample  = pd.read_csv(\"..\/input\/cat-in-the-dat-ii\/sample_submission.csv\")","e46beaa1":"train.head()","0ff6b8ba":"test.loc[:,\"target\"]=-1","cf55796e":"data  = pd.concat([train,test]).reset_index(drop=True)","24d400ac":"data.shape,train.shape,test.shape","6b618c02":"features = [f for f in train.columns if f not in [\"id\",\"target\"]]","25016e77":"features","0f589eaa":"for feat in features:\n    lbl_enc = preprocessing.LabelEncoder()\n    data.loc[:,feat] = lbl_enc.fit_transform(data[feat].astype(str).fillna(\"-1\").values)","ea3ded65":"data.head()","6a0312ed":"train = data[data.target != -1 ].reset_index(drop=True)\ntest = data[data.target == -1 ].reset_index(drop=True)\ntest_data = [test.loc[:, features].values[:, k] for k in range(test.loc[:, features].values.shape[1])]","3bbab0db":"len(test_data)","b9ad3466":"train.shape,test.shape","85a35de8":"def get_model(df,categorical_columns):\n    inputs = []\n    outputs = []\n    for c in categorical_columns:\n        num_unique_vals = int(df[c].nunique())\n        embed_dim = int(min(np.ceil(num_unique_vals\/2),50))\n        inp = layers.Input(shape=(1,))\n        out = layers.Embedding(num_unique_vals + 1, embed_dim,name =c)(inp)\n        # apply dropout here\n        out = layers.Reshape(target_shape = (embed_dim,))(out)\n        inputs.append(inp)\n        outputs.append(out)\n        \n    x = layers.Concatenate()(outputs)\n    x = layers.Dense(300,activation='relu')(x)\n    x = layers.Dropout(0.3)(x)\n    y = layers.Dense(1,activation='sigmoid')(x)\n    model = Model(inputs=inputs,outputs=y)\n    return model","5fa6ef52":"get_model(train,features).summary()","45203a7e":"model = get_model(train,features)\nmodel.compile(loss = \"binary_crossentropy\",optimizer=\"adam\")","c5bf0847":"model.fit([train.loc[:,f].values for f in features],train.target.values)","e3301eea":"def auc(y_true, y_pred):\n    def fallback_auc(y_true, y_pred):\n        try:\n            return metrics.roc_auc_score(y_true, y_pred)\n        except:\n            return 0.5\n    return tf.py_function(fallback_auc, (y_true, y_pred), tf.double)","1548b56d":"def create_model(data, catcols):    \n    inputs = []\n    outputs = []\n    for c in catcols:\n        num_unique_values = int(data[c].nunique())\n        embed_dim = int(min(np.ceil((num_unique_values)\/2), 50))\n        inp = layers.Input(shape=(1,))\n        out = layers.Embedding(num_unique_values + 1, embed_dim, name=c)(inp)\n        out = layers.SpatialDropout1D(0.3)(out)\n        out = layers.Reshape(target_shape=(embed_dim, ))(out)\n        inputs.append(inp)\n        outputs.append(out)\n    \n    x = layers.Concatenate()(outputs)\n    x = layers.BatchNormalization()(x)\n    \n    x = layers.Dense(300, activation=\"relu\")(x)\n    x = layers.Dropout(0.3)(x)\n    x = layers.BatchNormalization()(x)\n    \n    x = layers.Dense(300, activation=\"relu\")(x)\n    x = layers.Dropout(0.3)(x)\n    x = layers.BatchNormalization()(x)\n    \n    y = layers.Dense(2, activation=\"softmax\")(x)\n\n    model = Model(inputs=inputs, outputs=y)\n    return model","222f459b":"oof_preds = np.zeros((len(train)))\ntest_preds = np.zeros((len(test)))\n\nskf = StratifiedKFold(n_splits=50)\nfor train_index, test_index in skf.split(train, train.target.values):\n    X_train, X_test = train.iloc[train_index, :], train.iloc[test_index, :]\n    X_train = X_train.reset_index(drop=True)\n    X_test = X_test.reset_index(drop=True)\n    y_train, y_test = X_train.target.values, X_test.target.values\n    model = create_model(data, features)\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[auc])\n    X_train = [X_train.loc[:, features].values[:, k] for k in range(X_train.loc[:, features].values.shape[1])]\n    X_test = [X_test.loc[:, features].values[:, k] for k in range(X_test.loc[:, features].values.shape[1])]\n    \n    es = callbacks.EarlyStopping(monitor='val_auc', min_delta=0.001, patience=5,\n                                 verbose=1, mode='max', baseline=None, restore_best_weights=True)\n\n    rlr = callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.5,\n                                      patience=3, min_lr=1e-6, mode='max', verbose=1)\n    \n    model.fit(X_train,\n              utils.to_categorical(y_train),\n              validation_data=(X_test, utils.to_categorical(y_test)),\n              verbose=1,\n              batch_size=1024,\n              callbacks=[es, rlr],\n              epochs=100\n             )\n    valid_fold_preds = model.predict(X_test)[:, 1]\n    test_fold_preds = model.predict(test_data)[:, 1]\n    oof_preds[test_index] = valid_fold_preds.ravel()\n    test_preds += test_fold_preds.ravel()\n    print(metrics.roc_auc_score(y_test, valid_fold_preds))\n    K.clear_session()","e9e5ecc4":"print(\"Overall AUC={}\".format(metrics.roc_auc_score(train.target.values, oof_preds)))","aa33f94f":"test_preds.shape","30fe19c2":"test_preds \/= 50\ntest_ids = test.id.values\nprint(\"Saving submission file\")\nsubmission = pd.DataFrame.from_dict({\n    'id': test_ids,\n    'target': test_preds\n})\nsubmission.to_csv(\"submission.csv\", index=False)","317c0f8d":"submission.shape","a1dc97e3":"reference : https:\/\/www.kaggle.com\/abhishek\/same-old-entity-embeddings"}}