{"cell_type":{"a7c4d3d1":"code","ef64902b":"code","ce042c1c":"code","ee67c4d8":"code","2f110020":"code","094f72cd":"code","ce3c060c":"code","8cea7c9a":"code","5851d41e":"code","40531849":"code","79724b0f":"code","c21279b9":"code","ed511547":"code","750063f2":"code","fcc32dd6":"code","8b40dd99":"code","dafd31d0":"code","98873b10":"code","fa6a53d0":"code","050295ef":"code","014f45f1":"code","7bd4dc71":"code","23dfe256":"code","b6c9b7d7":"code","39277c3c":"code","b5759dff":"code","d4330fc4":"code","8f368909":"code","58093ce5":"code","bb086df9":"code","a316cfc7":"code","b6f4ef69":"code","86d04921":"code","33340b9e":"code","3280fb45":"code","15ad3602":"code","952c03a0":"code","1363548b":"code","8fd69636":"code","5cc7b018":"code","147e7936":"markdown","42897715":"markdown","5d0aa196":"markdown","bc1477de":"markdown","bd6fdb28":"markdown","e63bb563":"markdown","d225d287":"markdown","dc560313":"markdown","d20dde26":"markdown","78227edc":"markdown","e58a4393":"markdown","a5d9ce00":"markdown","c00a18f1":"markdown","dfb303eb":"markdown","61fd17ad":"markdown","0c3da978":"markdown","36f6fb51":"markdown","e2095dc1":"markdown","1b20b01f":"markdown","703f2be1":"markdown","8c312773":"markdown"},"source":{"a7c4d3d1":"%matplotlib inline\n%reload_ext autoreload\n%autoreload 2\n# \u591a\u884c\u8f93\u51fa\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\" ","ef64902b":"# !pip install pretrainedmodels","ce042c1c":"from fastai.vision import *\n# import pretrainedmodels","ee67c4d8":"torch.cuda.is_available()","2f110020":"# \u8bbe\u7f6e\u6570\u636e\u8def\u5f84\npath = Path('..\/input\/')","094f72cd":"d_path = path\/'iwildcam-2019-fgvc6'\nm_path = path\/'pytorch-model-zoo'","ce3c060c":"train_df = pd.read_csv(d_path\/'train.csv')\ntrain_df = pd.concat([train_df['id'],train_df['category_id']],axis=1,keys=['id','category_id'])\ntrain_df.head()","8cea7c9a":"test_df = pd.read_csv(d_path\/'test.csv')\ntest_df = pd.DataFrame(test_df['id'])\ntest_df['predicted'] = 0\ntest_df.head()","5851d41e":"# \u56fe\u7247\u53d8\u6362\ntfms = get_transforms(do_flip=True, max_rotate=20, max_zoom=1.3, max_lighting=0.4,\n                      max_warp=0.4, p_affine=1., p_lighting=1.)","40531849":"test_set = ImageList.from_df(test_df, path=d_path, cols='id', folder='test_images', suffix='.jpg')","79724b0f":"# \u6784\u5efa\u6570\u636e\u96c6\nnp.random.seed(42)\n# \u4f7f\u7528 ImageList \u662f\u56e0\u4e3a\u56fe\u50cf\u662f\u591a\u6807\u7b7e\u7684\nsrc = (ImageList.from_df(train_df, path=d_path, folder='train_images', cols='id', suffix='.jpg')\n       .split_by_rand_pct(0.1)\n       .label_from_df(cols='category_id')\n       .add_test(test_set)\n      )","c21279b9":"# img_size=128\nimg_size=224\nbs=32","ed511547":"data = (src.transform(tfms, size=img_size)\n        .databunch(path='.', bs=bs, device= torch.device('cuda:0')).normalize(imagenet_stats))","750063f2":"# \u67e5\u770b\u90e8\u5206\u6570\u636e\ndata.show_batch(rows=3, figsize=(12,9))","fcc32dd6":"f1 = partial(fbeta, beta=1)","8b40dd99":"from collections import OrderedDict\nimport math\n\nimport torch.nn as nn\nfrom torch.utils import model_zoo\n\npretrained_settings = {\n    'senet154': {\n        'url': m_path\/'senet154-c7b49a05.pth'\n    },\n    'se_resnet152': {\n        'url': m_path\/'se_resnet152-d17c99b7.pth'\n    },\n    'se_resnext101_32x4d': {\n        'url': m_path\/'se_resnext101_32x4d-3b2fe3d8.pth'\n    }\n}\n\n\nclass SEModule(nn.Module):\n\n    def __init__(self, channels, reduction):\n        super(SEModule, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc1 = nn.Conv2d(channels, channels \/\/ reduction, kernel_size=1,\n                             padding=0)\n        self.relu = nn.ReLU(inplace=True)\n        self.fc2 = nn.Conv2d(channels \/\/ reduction, channels, kernel_size=1,\n                             padding=0)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        module_input = x\n        x = self.avg_pool(x)\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        x = self.sigmoid(x)\n        return module_input * x\n\n\nclass Bottleneck(nn.Module):\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n        out = self.conv3(out)\n        out = self.bn3(out)\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out = self.se_module(out) + residual\n        out = self.relu(out)\n        return out\n\n\nclass SEBottleneck(Bottleneck):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n                 downsample=None):\n        super(SEBottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes * 2)\n        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n                               stride=stride, padding=1, groups=groups,\n                               bias=False)\n        self.bn2 = nn.BatchNorm2d(planes * 4)\n        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n                               bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.se_module = SEModule(planes * 4, reduction=reduction)\n        self.downsample = downsample\n        self.stride = stride\n\n\nclass SEResNetBottleneck(Bottleneck):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n                 downsample=None):\n        super(SEResNetBottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n                               stride=stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n                               groups=groups, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.se_module = SEModule(planes * 4, reduction=reduction)\n        self.downsample = downsample\n        self.stride = stride\n\n\nclass SEResNeXtBottleneck(Bottleneck):\n    expansion = 4\n\n    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n                 downsample=None, base_width=4):\n        super(SEResNeXtBottleneck, self).__init__()\n        width = math.floor(planes * (base_width \/ 64)) * groups\n        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n                               stride=1)\n        self.bn1 = nn.BatchNorm2d(width)\n        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n                               padding=1, groups=groups, bias=False)\n        self.bn2 = nn.BatchNorm2d(width)\n        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.se_module = SEModule(planes * 4, reduction=reduction)\n        self.downsample = downsample\n        self.stride = stride\n\n\nclass SENet(nn.Module):\n\n    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n                 downsample_padding=1, num_classes=1000):\n        super(SENet, self).__init__()\n        self.inplanes = inplanes\n        if input_3x3:\n            layer0_modules = [\n                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n                                    bias=False)),\n                ('bn1', nn.BatchNorm2d(64)),\n                ('relu1', nn.ReLU(inplace=True)),\n                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n                                    bias=False)),\n                ('bn2', nn.BatchNorm2d(64)),\n                ('relu2', nn.ReLU(inplace=True)),\n                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n                                    bias=False)),\n                ('bn3', nn.BatchNorm2d(inplanes)),\n                ('relu3', nn.ReLU(inplace=True)),\n            ]\n        else:\n            layer0_modules = [\n                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n                                    padding=3, bias=False)),\n                ('bn1', nn.BatchNorm2d(inplanes)),\n                ('relu1', nn.ReLU(inplace=True)),\n            ]\n        # To preserve compatibility with Caffe weights `ceil_mode=True`\n        # is used instead of `padding=1`.\n        layer0_modules.append(('pool', nn.MaxPool2d(3, stride=2,\n                                                    ceil_mode=True)))\n        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n        self.layer1 = self._make_layer(\n            block,\n            planes=64,\n            blocks=layers[0],\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=1,\n            downsample_padding=0\n        )\n        self.layer2 = self._make_layer(\n            block,\n            planes=128,\n            blocks=layers[1],\n            stride=2,\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=downsample_kernel_size,\n            downsample_padding=downsample_padding\n        )\n        self.layer3 = self._make_layer(\n            block,\n            planes=256,\n            blocks=layers[2],\n            stride=2,\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=downsample_kernel_size,\n            downsample_padding=downsample_padding\n        )\n        self.layer4 = self._make_layer(\n            block,\n            planes=512,\n            blocks=layers[3],\n            stride=2,\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=downsample_kernel_size,\n            downsample_padding=downsample_padding\n        )\n        self.avg_pool = nn.AvgPool2d(7, stride=1)\n        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n                    downsample_kernel_size=1, downsample_padding=0):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=downsample_kernel_size, stride=stride,\n                          padding=downsample_padding, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n                            downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, groups, reduction))\n\n        return nn.Sequential(*layers)\n\n    def features(self, x):\n        x = self.layer0(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        return x\n\n    def logits(self, x):\n        x = self.avg_pool(x)\n        if self.dropout is not None:\n            x = self.dropout(x)\n        x = x.view(x.size(0), -1)\n        x = self.last_linear(x)\n        return x\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.logits(x)\n        return x\n\ndef senet154(pretrained=False):\n    model = SENet(SEBottleneck, [3, 8, 36, 3], groups=64, reduction=16,\n                  dropout_p=0.2, num_classes=1000)\n    if pretrained:\n        model.load_state_dict(torch.load(pretrained_settings['senet154']['url']))\n    return model\n\n\ndef se_resnet152(pretrained=False):\n    model = SENet(SEResNetBottleneck, [3, 8, 36, 3], groups=1, reduction=16,\n                  dropout_p=None, inplanes=64, input_3x3=False,\n                  downsample_kernel_size=1, downsample_padding=0,\n                  num_classes=1000)\n    if pretrained:\n        model.load_state_dict(torch.load(pretrained_settings['se_resnet152']['url']))\n    return model\n\n\ndef se_resnext101_32x4d(pretrained=False):\n    model = SENet(SEResNeXtBottleneck, [3, 4, 23, 3], groups=32, reduction=16,\n                  dropout_p=None, inplanes=64, input_3x3=False,\n                  downsample_kernel_size=1, downsample_padding=0,\n                  num_classes=1000)\n    if pretrained:\n        model.load_state_dict(torch.load(pretrained_settings['se_resnext101_32x4d']['url']))\n    return model","dafd31d0":"learn = cnn_learner(data, base_arch=models.densenet169, metrics=[f1, accuracy])\n# learn = cnn_learner(data, se_resnet152, metrics=[f1, accuracy])","98873b10":"learn.lr_find()","fa6a53d0":"learn.recorder.plot(suggestion=True)","050295ef":"lr = 0.01","014f45f1":"learn.fit_one_cycle(30, slice(lr))","7bd4dc71":"learn.unfreeze()","23dfe256":"learn.lr_find()\nlearn.recorder.plot()","b6c9b7d7":"lr1 = 1e-4\nlearn.fit_one_cycle(15, slice(lr1\/2.6**3, lr1))","39277c3c":"learn.save('stage-2')","b5759dff":"# learn=None\n# gc.collect()","d4330fc4":"# learn = cnn_learner(data, base_arch=se_resnet152, metrics=[f1, accuracy]).load('stage-2');","8f368909":"# bs=32\n# img_sz=224","58093ce5":"# data = (src.transform(tfms, size=img_sz)\n#         .databunch(path='.', bs=bs, device= torch.device('cuda:0')).normalize(imagenet_stats))\n\n# learn.data = data","bb086df9":"# data.show_batch(rows=3, figsize=(12,9))","a316cfc7":"# learn.freeze()","b6f4ef69":"# learn.lr_find()\n# learn.recorder.plot()","86d04921":"# lr2=1e-4","33340b9e":"# learn.fit_one_cycle(3, slice(lr2))","3280fb45":"# learn.unfreeze()","15ad3602":"# learn.lr_find()\n# learn.recorder.plot()","952c03a0":"# learn.fit_one_cycle(1, slice(lr2\/2.6**3, lr2\/5))","1363548b":"df = pd.read_csv(d_path\/'sample_submission.csv')\ndf.head()","8fd69636":"test_preds = learn.get_preds(DatasetType.Test)\ndf['Predicted'] = test_preds[0].argmax(dim=1)\ndf.to_csv('submission.csv', index=False)","5cc7b018":"# !kaggle competitions submit -c iwildcam-2019-fgvc6 -f submission.csv -m \"submit\"","147e7936":"- \u8fd9\u91cc\u6bcf\u4e2a\u56fe\u7247\u90fd\u4f1a\u6709\u591a\u4e2a\u6807\u7b7e","42897715":"[](http:\/\/)- \u56fe\u50cf\u5927\u5c0f\u8bbe\u7f6e\u4e3a 128","5d0aa196":"## \u6d4b\u8bd5","bc1477de":"- \u5bfb\u627e\u5b66\u4e60\u7387","bd6fdb28":"https:\/\/github.com\/Cadene\/pretrained-models.pytorch\/blob\/master\/pretrainedmodels\/models\/senet.py","e63bb563":"## 1 \u6570\u636e\u51c6\u5907","d225d287":"- \u6839\u636e\u4e0a\u8ff0\u56fe\u50cf\uff0c\u6211\u4eec\u9009\u62e9\u5b66\u4e60\u7387\u4e3a 0.01","dc560313":"- \u4ecd\u65e7\u4f7f\u7528\u4e4b\u524d\u7684\u5b66\u4e60\u5668\uff0c\u53ea\u662f\u7b80\u5355\u5730\u66f4\u6362\u6570\u636e","d20dde26":"- \u5bfb\u627e\u6700\u4f73\u5b66\u4e60\u7387\u5e76\u518d\u6b21\u8bad\u7ec3","78227edc":"- \u6839\u636e\u4e0a\u8ff0\u56fe\uff0c\u9009\u62e9 lr1=1e-4\n- \u518d\u6b21\u8bad\u7ec3\u6d45\u5c42\u7f51\u7edc\u5e76\u4fdd\u5b58\u7ed3\u679c\n- \u4f7f\u7528\u5224\u522b\u5f0f\u5b66\u4e60\u7387","e58a4393":"- \u518d\u6b21\u67e5\u627e\u6700\u4f73\u5b66\u4e60\u7387","a5d9ce00":"- \u6211\u4eec\u4ecd\u7136\u4f7f\u7528\u4e4b\u524d\u5b9a\u4e49\u7684\u6a21\u578b\n- \u518d\u6b21\u8bad\u7ec3\u4e4b\u524d\uff0c\u6211\u4eec\u9700\u8981\u5c06\u6d45\u5c42\u7ed3\u6784\u8fdb\u884c freeze\uff0c\u4e0d\u8bad\u7ec3\u6d45\u5c42\u7ed3\u6784\u7684\u6743\u91cd","c00a18f1":"- \u67e5\u770b\u5b66\u4e60\u7387\u60c5\u51b5\u5e76\u4f5c\u51fa\u9009\u62e9","dfb303eb":"- \u4ece\u672c\u5730\u52a0\u8f7d\u9884\u8bad\u7ec3\u6a21\u578b","61fd17ad":"- unfreeze \u5e76\u8bad\u7ec3\u6d45\u5c42\u7f51\u7edc\u7684\u6743\u91cd\uff0c\u5fae\u8c03\u8fc7\u7a0b","0c3da978":"### \u9884\u8bad\u7ec3\u6a21\u578b\u52a0\u8f7d","36f6fb51":"## \u63d0\u4ea4\u7ed3\u679c","e2095dc1":"- \u8bad\u7ec3\u6a21\u578b","1b20b01f":"- \u7ee7\u7eed\u8fdb\u884c\u7b2c\u4e8c\u9636\u6bb5\u7684\u5fae\u8c03","703f2be1":"- \u4f7f\u7528 densenet169\/se_resnet152 \u4f5c\u4e3a\u6a21\u578b","8c312773":"![](http:\/\/)## \u56fe\u50cf\u5927\u5c0f\u8bbe\u7f6e\u4e3a 224"}}