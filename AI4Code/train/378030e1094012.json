{"cell_type":{"3bca3829":"code","71f88da0":"code","0f24a724":"code","1e9ca839":"code","78dd533b":"code","cdd4481c":"code","8a971310":"code","2ff0eb46":"code","1f3938e2":"code","5483ab81":"code","67341094":"code","84d070af":"code","2eb57e18":"code","f6280009":"code","32c50530":"code","a8547608":"code","c4e686cb":"code","117692cd":"code","d2d0522f":"code","689b7800":"code","cb3bb98a":"code","c9875a87":"code","0370f87e":"code","2d1e6fb5":"code","211e8de7":"code","1cfa30c2":"code","943506cc":"code","58fdec1e":"code","fd2e9f96":"code","8f9130ae":"markdown","64c85aee":"markdown","5e6a9a6a":"markdown","54482e7e":"markdown","19d02332":"markdown","3c14233d":"markdown","3db86fea":"markdown","29f456f7":"markdown","e1be35d5":"markdown","212acde4":"markdown","27d2c8d2":"markdown","316ae1b1":"markdown","6b86a667":"markdown","a4a546e4":"markdown","aa024492":"markdown","f3b92123":"markdown","e962ce5c":"markdown","7491af4d":"markdown","1d32b1bc":"markdown","52cb826a":"markdown","a710a31e":"markdown","a517b90e":"markdown","f32a4856":"markdown","746bc646":"markdown","214d2bb9":"markdown"},"source":{"3bca3829":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor as rfr\nfrom sklearn.metrics import mean_squared_error as mse\n\nfrom xgboost import XGBRegressor as xgb\n\nfrom sklearn.svm import SVR\n\nfrom tensorflow.keras import models, layers, optimizers, metrics\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nnp.random.seed(2022)","71f88da0":"train = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/test.csv')\n\ntrain.sample(5)","0f24a724":"print(f'There are {train.shape[0]} samples in the train dataset')","1e9ca839":"X_train = pd.get_dummies(train[['country', 'store', 'product']])\nX_test = pd.get_dummies(test[['country', 'store', 'product']])\n\ny_train = train['num_sold']\n\ndate_train = pd.to_datetime(train['date'])\ndate_test = pd.to_datetime(test['date'])\n\ndel train, test","78dd533b":"plt.figure(figsize=(10,7))\ny_train.hist(bins=100, grid=False, color='green')\nplt.xlabel('Num sold', fontsize=16)\nplt.ylabel('Frequence', fontsize=16)\nplt.show()","cdd4481c":"plt.figure(figsize=(10,7))\nnp.log(y_train).hist(bins=100, grid=False, color='green')\nplt.xlabel('Num sold', fontsize=16)\nplt.ylabel('Frequence', fontsize=16)\nplt.show()","8a971310":"for df in [X_train, X_test]:\n    df['year'] = date_train.dt.year\n    df['month'] = date_train.dt.month\n    df['week'] = date_train.dt.isocalendar().week.astype('int64')\n    df['day'] = date_train.dt.day\n    df['dayofweek'] = date_train.dt.dayofweek","2ff0eb46":"X_train.sample(5)","1f3938e2":"y_train = np.log(y_train)\n\nfor col in X_train.columns:\n    mean = X_train[col].mean()\n    std  = X_train[col].std()\n    X_train[col] -= mean\n    X_train[col] \/= std\n    X_test[col] -= mean\n    X_test[col] \/= std\n    \nX_train.sample(5)","5483ab81":"X_train_subset, X_val, y_train_subset, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=2022)","67341094":"y_test_all_models = []","84d070af":"model = rfr(n_estimators=100)\nmodel.fit(X_train_subset, y_train_subset)","2eb57e18":"y_train_pred = model.predict(X_train_subset)\nrmse_train = np.sqrt(mse(y_train_pred, y_train_subset))\n\ny_pred = model.predict(X_val)\nrmse_val = np.sqrt(mse(y_pred, y_val))","f6280009":"plt.figure(figsize=(20,7))\n\nplt.subplot(1,2,1)\nplt.plot(y_train_subset, y_train_pred, 'r.')\nplt.plot([min(y_train_subset), max(y_train_subset)], [min(y_train_subset), max(y_train_subset)], 'k')\nplt.xlim(min(y_train_subset), max(y_train_subset))\nplt.ylim(min(y_train_subset), max(y_train_subset))\nplt.xlabel('True', fontsize=16)\nplt.ylabel('Prediction', fontsize=16)\nplt.text(7, 6, f'RMSE={round(rmse_train,3)}')\nplt.title('Train subset', fontsize=20)\n\nplt.subplot(1,2,2)\nplt.plot(y_val, y_pred, 'r.')\nplt.plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], 'k')\nplt.xlim(min(y_val), max(y_val))\nplt.ylim(min(y_val), max(y_val))\nplt.xlabel('True', fontsize=16)\nplt.ylabel('Prediction', fontsize=16)\nplt.text(7, 6, f'RMSE={round(rmse_val,3)}')\nplt.title('Validation subset', fontsize=20)\n\nplt.show()","32c50530":"y_test_rfr = model.predict(X_test)\ny_test_all_models.append(y_test_rfr)","a8547608":"model = xgb(n_estimators=100, learning_rate=0.3)\nmodel.fit(X_train_subset, y_train_subset, eval_set=[(X_val, y_val)], early_stopping_rounds=10, verbose=0)","c4e686cb":"y_train_pred = model.predict(X_train_subset)\nrmse_train = np.sqrt(mse(y_train_pred, y_train_subset))\n\ny_pred = model.predict(X_val)\nrmse_val = np.sqrt(mse(y_pred, y_val))","117692cd":"plt.figure(figsize=(20,7))\n\nplt.subplot(1,2,1)\nplt.plot(y_train_subset, y_train_pred, 'r.')\nplt.plot([min(y_train_subset), max(y_train_subset)], [min(y_train_subset), max(y_train_subset)], 'k')\nplt.xlim(min(y_train_subset), max(y_train_subset))\nplt.ylim(min(y_train_subset), max(y_train_subset))\nplt.xlabel('True', fontsize=16)\nplt.ylabel('Prediction', fontsize=16)\nplt.text(7, 6, f'RMSE={round(rmse_train,3)}')\nplt.title('Train subset', fontsize=20)\n\nplt.subplot(1,2,2)\nplt.plot(y_val, y_pred, 'r.')\nplt.plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], 'k')\nplt.xlim(min(y_val), max(y_val))\nplt.ylim(min(y_val), max(y_val))\nplt.xlabel('True', fontsize=16)\nplt.ylabel('Prediction', fontsize=16)\nplt.text(7, 6, f'RMSE={round(rmse_val,3)}')\nplt.title('Validation subset', fontsize=20)\n\nplt.show()","d2d0522f":"y_test_xgb = model.predict(X_test)\ny_test_all_models.append(y_test_xgb)","689b7800":"model = SVR(kernel='rbf', C=100, gamma=1)\nmodel.fit(X_train_subset, y_train_subset)","cb3bb98a":"y_train_pred = model.predict(X_train_subset)\nrmse_train = np.sqrt(mse(y_train_pred, y_train_subset))\n\ny_pred = model.predict(X_val)\nrmse_val = np.sqrt(mse(y_pred, y_val))","c9875a87":"plt.figure(figsize=(20,7))\n\nplt.subplot(1,2,1)\nplt.plot(y_train_subset, y_train_pred, 'r.')\nplt.plot([min(y_train_subset), max(y_train_subset)], [min(y_train_subset), max(y_train_subset)], 'k')\nplt.xlim(min(y_train_subset), max(y_train_subset))\nplt.ylim(min(y_train_subset), max(y_train_subset))\nplt.xlabel('True', fontsize=16)\nplt.ylabel('Prediction', fontsize=16)\nplt.text(7, 6, f'RMSE={round(rmse_train,3)}')\nplt.title('Train subset', fontsize=20)\n\nplt.subplot(1,2,2)\nplt.plot(y_val, y_pred, 'r.')\nplt.plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], 'k')\nplt.xlim(min(y_val), max(y_val))\nplt.ylim(min(y_val), max(y_val))\nplt.xlabel('True', fontsize=16)\nplt.ylabel('Prediction', fontsize=16)\nplt.text(7, 6, f'RMSE={round(rmse_val,3)}')\nplt.title('Validation subset', fontsize=20)\n\nplt.show()","0370f87e":"y_test_svm = model.predict(X_test)\ny_test_all_models.append(y_test_svm)","2d1e6fb5":"model = models.Sequential()\nmodel.add(layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)))\nmodel.add(layers.Dense(1))\n\nmodel.compile( optimizer = optimizers.RMSprop(learning_rate=0.01), loss='mse', metrics=['mae'] )","211e8de7":"history = model.fit(X_train_subset, y_train_subset, epochs=3000, batch_size=128, verbose=1)","1cfa30c2":"y_train_pred = model.predict(X_train_subset)\nrmse_train = np.sqrt(mse(y_train_pred, y_train_subset))\n\ny_pred = model.predict(X_val)\nrmse_val = np.sqrt(mse(y_pred, y_val))","943506cc":"plt.figure(figsize=(20,7))\n\nplt.subplot(1,2,1)\nplt.plot(y_train_subset, y_train_pred, 'r.')\nplt.plot([min(y_train_subset), max(y_train_subset)], [min(y_train_subset), max(y_train_subset)], 'k')\nplt.xlim(min(y_train_subset), max(y_train_subset))\nplt.ylim(min(y_train_subset), max(y_train_subset))\nplt.xlabel('True', fontsize=16)\nplt.ylabel('Prediction', fontsize=16)\nplt.text(7, 6, f'RMSE={round(rmse_train,3)}')\nplt.title('Train subset', fontsize=20)\n\nplt.subplot(1,2,2)\nplt.plot(y_val, y_pred, 'r.')\nplt.plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], 'k')\nplt.xlim(min(y_val), max(y_val))\nplt.ylim(min(y_val), max(y_val))\nplt.xlabel('True', fontsize=16)\nplt.ylabel('Prediction', fontsize=16)\nplt.text(7, 6, f'RMSE={round(rmse_val,3)}')\nplt.title('Validation subset', fontsize=20)\n\nplt.show()","58fdec1e":"y_test_ann = model.predict(X_test)\ny_test_all_models.append(y_test_ann.reshape(len(y_test_ann)))","fd2e9f96":"submission = pd.read_csv('..\/input\/tabular-playground-series-jan-2022\/sample_submission.csv')\nsubmission['num_sold'] = np.exp( np.array(y_test_all_models).mean(axis=0) ).astype('int64') # ensemble model\nsubmission.to_csv('submission.csv', index=False)\n\nsubmission.sample(5)","8f9130ae":"## Visualize target\n\nNum_sold distribution is skewed\n","64c85aee":"### Prediction","5e6a9a6a":"# TPS Jan 2022: Tree, Kernel, NN and ensemble models\n\n### This notebook presents the use of some typical such as Tree models (Random Forest, XGBoost), Kernel model (Support Vector Machines) and Artificial Neural Networks as well as their ensemble to solve the TPS problem of Jan 2022.","54482e7e":"# Submission","19d02332":"### Training","3c14233d":"## Transform target\n\nDistribution is more symmetric by considering log of num_sold","3db86fea":"## Support Vector Machines","29f456f7":"### Training","e1be35d5":"### Validation","212acde4":"### Training","27d2c8d2":"# Feature engineering","316ae1b1":"### Prediction","6b86a667":"### Prediction","a4a546e4":"### Validation","aa024492":"### Validation","f3b92123":"# Models","e962ce5c":"### Validation","7491af4d":"## Random Forest Regressor","1d32b1bc":"### Prediction","52cb826a":"### Network","a710a31e":"## Artificial Neural Networks","a517b90e":"# Data","f32a4856":"## Transform target, normalize features and split train\/validation","746bc646":"### Training","214d2bb9":"## Extreme Gradient Boosting Regressor"}}