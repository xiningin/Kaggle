{"cell_type":{"44a3161e":"code","b39487f5":"code","29728b1e":"code","a3052bcb":"code","7d95eb8a":"code","6d0ad554":"code","ece7ae40":"code","7acd04eb":"code","c78d8ed4":"code","8eb7c874":"code","b81b7723":"code","e5aaf3ed":"code","0c9f9a87":"code","0de7f856":"code","a5d824cd":"code","a74d19a5":"code","37d16842":"code","55805517":"code","fc65df43":"code","38cbbf38":"code","6b4241e8":"code","fbecd438":"code","97ef2e94":"code","169febba":"code","f7f9b08c":"code","93230042":"code","5fa9f30c":"code","fc853773":"code","84c2421f":"code","85b00af5":"code","99ebc4d9":"code","4b25c70b":"code","3060dec8":"code","eb6401f3":"code","7a774ca5":"code","d8bbbc21":"code","9a3ae962":"code","d0d82b8a":"code","6d1bce97":"code","98febe7a":"code","ab1cc33f":"code","5a7f1a21":"code","e5e0801a":"code","dbdad3b2":"code","26eb8619":"code","ae71fef8":"code","9ba36ec4":"code","fa969253":"code","89ebe230":"code","4c74167d":"code","d6f4d79d":"code","cc2883bc":"code","99eb3a96":"code","228935e0":"code","fcedbd05":"code","0fea3c19":"code","d6a3faac":"code","330f0177":"code","e5064a86":"code","2dbd376d":"code","7ac616d1":"code","1ec35003":"code","baf6ca97":"code","d4678ff1":"code","94006bf1":"code","46edc4cb":"code","02542b50":"code","4d831a24":"code","b0a010db":"code","ee8e1019":"code","34e568b3":"markdown","0e21ba9a":"markdown","e16215da":"markdown","0c08bfd9":"markdown","d02288e9":"markdown","44ba2034":"markdown","cdd865b6":"markdown","0c129ac7":"markdown","f40f7334":"markdown","6281959c":"markdown","b2a1ea9b":"markdown","6ddd5327":"markdown","61af0cdb":"markdown","98501179":"markdown","764ddb14":"markdown","7317b8e3":"markdown","8c3c8ea1":"markdown","42a2e327":"markdown","8eb2da3e":"markdown","4e8094ee":"markdown","1e38ce9e":"markdown","02bb60fb":"markdown","9d5d0978":"markdown","e951e209":"markdown","3aa9f804":"markdown","815b1b14":"markdown","cb8d2bca":"markdown","6a27a108":"markdown","4600885e":"markdown","03add9c1":"markdown","bf3ec56c":"markdown","f3cf8579":"markdown","d3ff8bda":"markdown","36165ef0":"markdown","404c5f81":"markdown","c9e45d10":"markdown","32c9bac3":"markdown","ec88e721":"markdown","99ff3b82":"markdown","167acb4e":"markdown","a03cbcac":"markdown","8f038d57":"markdown","95670203":"markdown","3c62802e":"markdown","58c33eed":"markdown","c0456bbb":"markdown","42250f1a":"markdown","a1b48c6a":"markdown","c65ca9ff":"markdown","f7a76795":"markdown","5883fb2f":"markdown","d4a99b7e":"markdown","26a1319f":"markdown","32a398fc":"markdown","89c9303b":"markdown","f0a2b67b":"markdown"},"source":{"44a3161e":"#Import libraries\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import cluster\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_samples\nfrom sklearn.neighbors import KNeighborsClassifier\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning) ","b39487f5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","29728b1e":"# Create a dataframe from csv data\ncensus_data_df = pd.read_csv('\/kaggle\/input\/uk-census-data-with-uk-deprivation-index-2015\/nm8883_census_data.csv', skiprows=10)\n\n#preview of the first five rows\ncensus_data_df.head()","a3052bcb":"# Create a dataframe from csv data\n# The first ten rows of each table contain metadata, so I will use skiprows\nm_16_24_df = pd.read_csv('\/kaggle\/input\/uk-census-data-with-uk-deprivation-index-2015\/m_16_24.csv', skiprows=9)\n\n#preview of the first five rows\nm_16_24_df.head()","7d95eb8a":"# Now import the rest\nf_16_24_df = pd.read_csv('\/kaggle\/input\/uk-census-data-with-uk-deprivation-index-2015\/f_16_24.csv', skiprows=9)\nm_25_49_df = pd.read_csv('\/kaggle\/input\/uk-census-data-with-uk-deprivation-index-2015\/m_25_49.csv', skiprows=9)\nf_25_49_df = pd.read_csv('\/kaggle\/input\/uk-census-data-with-uk-deprivation-index-2015\/f_25_49.csv', skiprows=9)\nm_50_64_df = pd.read_csv('\/kaggle\/input\/uk-census-data-with-uk-deprivation-index-2015\/m_50_64.csv', skiprows=9)\nf_50_64_df = pd.read_csv('\/kaggle\/input\/uk-census-data-with-uk-deprivation-index-2015\/f_50_64.csv', skiprows=9)\nm_65_plus_df = pd.read_csv('\/kaggle\/input\/uk-census-data-with-uk-deprivation-index-2015\/m_65_plus.csv', skiprows=9)\nf_65_plus_df = pd.read_csv('\/kaggle\/input\/uk-census-data-with-uk-deprivation-index-2015\/f_65_plus.csv', skiprows=9)","6d0ad554":"# Add additional columns to show the gender and age - useful if I combine the dataframes later\nm_16_24_df['Gender'] = 'Male'\nm_16_24_df['Age'] = '16-24'\nf_16_24_df['Gender'] = 'Female'\nf_16_24_df['Age'] = '16-24'\nm_25_49_df['Gender'] = 'Male'\nm_25_49_df['Age'] = '25-49'\nf_25_49_df['Gender'] = 'Female'\nf_25_49_df['Age'] = '25-49'\nm_50_64_df['Gender'] = 'Male'\nm_50_64_df['Age'] = '50-64'\nf_50_64_df['Gender'] = 'Female'\nf_50_64_df['Age'] = '50-64'\nm_65_plus_df['Gender'] = 'Male'\nm_65_plus_df['Age'] = '65+'\nf_65_plus_df['Gender'] = 'Female'\nf_65_plus_df['Age'] = '65+'","ece7ae40":"# Check one at random to ensure it's worked\nm_25_49_df.head()","7acd04eb":"#Get a quick overview to make sure everything looks about right\n\nm_16_24_df.describe()","c78d8ed4":"# View sum of the first column\n\ntotals_df = m_16_24_df['1. Higher managerial, administrative and professional occupations'].sum()\n\ntotals_df","8eb7c874":"# select numeric columns and calculate the sums\ntotals_df = m_16_24_df.select_dtypes(np.number).sum().rename('m_16_24')\n\nprint(totals_df)","b81b7723":"# Save series to dataframe\ntotals_df = totals_df.to_frame()\ntotals_df = totals_df.transpose()\n\ntotals_df","e5aaf3ed":"sums_m2549 = m_25_49_df.select_dtypes(np.number).sum().rename('m_25_49')\nsums_m5064 = m_50_64_df.select_dtypes(np.number).sum().rename('m_50_64')\nsums_m65plus = m_65_plus_df.select_dtypes(np.number).sum().rename('m_65_plus')\nsums_f1624 = f_16_24_df.select_dtypes(np.number).sum().rename('f_25_49')\nsums_f2549 = f_25_49_df.select_dtypes(np.number).sum().rename('f_25_49')\nsums_f5064 = f_50_64_df.select_dtypes(np.number).sum().rename('f_50_64')\nsums_f65plus = f_65_plus_df.select_dtypes(np.number).sum().rename('f_65_plus')","0c9f9a87":"totals_df = totals_df.append([sums_m2549, sums_m5064, sums_m65plus, sums_f1624, sums_f2549, sums_f5064, sums_f65plus])\n\ntotals_df","0de7f856":"# Create a dataframe from csv data\n_16_24_df = pd.read_csv('\/kaggle\/input\/uk-census-data-with-uk-deprivation-index-2015\/85043238.csv', skiprows=10, skipfooter=5, engine='python')\n\n# Preview \n_16_24_df","a5d824cd":"_25_49_df = pd.read_csv('\/kaggle\/input\/uk-census-data-with-uk-deprivation-index-2015\/87985007.csv', skiprows=10, skipfooter=5, engine='python')\n_50_64_df = pd.read_csv('\/kaggle\/input\/uk-census-data-with-uk-deprivation-index-2015\/91695374.csv', skiprows=10, skipfooter=5, engine='python')\n_65_plus_df = pd.read_csv('\/kaggle\/input\/uk-census-data-with-uk-deprivation-index-2015\/93917134.csv', skiprows=10, skipfooter=5, engine='python')","a74d19a5":"# select numeric columns and calculate the sums\ntotals_df = _16_24_df.select_dtypes(np.number).sum().rename('16-24')\n\nprint(totals_df)","37d16842":"# Save series to dataframe\ntotals_df = totals_df.to_frame()\ntotals_df = totals_df.transpose()\n\ntotals_df","55805517":"# Save the totals of each dataframe \n\nsums_2549 = _25_49_df.select_dtypes(np.number).sum().rename('25-49')\nsums_5064 = _50_64_df.select_dtypes(np.number).sum().rename('50-64')\nsums_65plus = _65_plus_df.select_dtypes(np.number).sum().rename('65+')","fc65df43":"# Append the totals to the totals_df dataframe\n\ntotals_df = totals_df.append([sums_2549, sums_5064, sums_65plus])\n\ntotals_df","38cbbf38":"totals_df = totals_df.drop(['L17 Not classifiable for other reasons'], axis=1)","6b4241e8":"totals_df.plot.line(title=\"Comparison of age and Socio-economic group\", figsize=(15,10))\nplt.xlabel('Age Category', fontsize=12)\nplt.ylabel('Number of people', fontsize=12);","fbecd438":"# Calculate totals for each age group\ntotals_df['Total'] = totals_df.sum(axis=1)\n\ntotals_df","97ef2e94":"total = totals_df['Total'].sum()\ntotal","169febba":"# Add a percentage column\n\ntotals_df['Percentage'] = (totals_df['Total'] \/ total) * 100\n\ntotals_df","f7f9b08c":"totals_df['1.1 Large employers and higher managerial and administrative occupations'] = totals_df['1.1 Large employers and higher managerial and administrative occupations']\/totals_df['Percentage']\ntotals_df['1.2 Higher professional occupations'] = totals_df['1.2 Higher professional occupations']\/totals_df['Percentage']\ntotals_df['2. Lower managerial, administrative and professional occupations'] = totals_df['2. Lower managerial, administrative and professional occupations']\/totals_df['Percentage']\ntotals_df['3. Intermediate occupations'] = totals_df['3. Intermediate occupations']\/totals_df['Percentage']\ntotals_df['4. Small employers and own account workers'] = totals_df['4. Small employers and own account workers']\/totals_df['Percentage']\ntotals_df['5. Lower supervisory and technical occupations'] = totals_df['5. Lower supervisory and technical occupations']\/totals_df['Percentage']\ntotals_df['6. Semi-routine occupations'] = totals_df['6. Semi-routine occupations']\/totals_df['Percentage']\ntotals_df['7. Routine occupations'] = totals_df['7. Routine occupations']\/totals_df['Percentage']\ntotals_df['L14.1 Never worked'] = totals_df['L14.1 Never worked']\/totals_df['Percentage']\ntotals_df['L14.2 Long-term unemployed'] = totals_df['L14.2 Long-term unemployed']\/totals_df['Percentage']\ntotals_df['L15 Full-time students'] = totals_df['L15 Full-time students']\/totals_df['Percentage']\ntotals_df = totals_df.drop(['Total', 'Percentage'], axis=1)\n\ntotals_df","93230042":"totals_df['1.1 Large employers and higher managerial and administrative occupations'] = totals_df['1.1 Large employers and higher managerial and administrative occupations']*25\ntotals_df['1.2 Higher professional occupations'] = totals_df['1.2 Higher professional occupations']*25\ntotals_df['2. Lower managerial, administrative and professional occupations'] = totals_df['2. Lower managerial, administrative and professional occupations']*25\ntotals_df['3. Intermediate occupations'] = totals_df['3. Intermediate occupations']*25\ntotals_df['4. Small employers and own account workers'] = totals_df['4. Small employers and own account workers']*25\ntotals_df['5. Lower supervisory and technical occupations'] = totals_df['5. Lower supervisory and technical occupations']*25\ntotals_df['6. Semi-routine occupations'] = totals_df['6. Semi-routine occupations']*25\ntotals_df['7. Routine occupations'] = totals_df['7. Routine occupations']*25\ntotals_df['L14.1 Never worked'] = totals_df['L14.1 Never worked']*25\ntotals_df['L14.2 Long-term unemployed'] = totals_df['L14.2 Long-term unemployed']*25\ntotals_df['L15 Full-time students'] = totals_df['L15 Full-time students']*25\n\ntotals_df","5fa9f30c":"# Calculate totals for each age group\ntotals_df['Total'] = totals_df.sum(axis=1)\n\ntotals_df","fc853773":"# Check to confirm that this matches the total above\ntotal2 = totals_df['Total'].sum()\ntotal2","84c2421f":"# Add a percentage column again\n\ntotals_df['Percentage'] = (totals_df['Total'] \/ total) * 100\n\ntotals_df","85b00af5":"# Plot the data\nplt.title(\"Comparison of age and Socio-economic group where each age category has been equally weighted\", fontsize=16)\nplt.xlabel('Age Category', fontsize=16)\nplt.ylabel('Number of people', fontsize=16)\n\n# Plot data at the extremes and colour to emphasise them\nplt.plot(totals_df['1.1 Large employers and higher managerial and administrative occupations'], 'red', \n         label='1.1 Large employers and higher managerial', linewidth=4)\nplt.plot(totals_df['1.2 Higher professional occupations'], 'blue',\n         label='1.2 Higher professional occupations', linewidth=4)\nplt.plot(totals_df['2. Lower managerial, administrative and professional occupations'], 'yellow',\n         label='2. Lower managerial', linewidth=4)\nplt.plot(totals_df['7. Routine occupations'], 'green',\n         label='7. Routine occupations',linewidth=4)\nplt.plot(totals_df['L14.1 Never worked'], 'pink',\n         label='L14.1 Never worked', linewidth=4)\nplt.plot(totals_df['L15 Full-time students'], 'black',\n         label='L15 Full-time students',linewidth=4)\n\n# Plot the mid-level roles, but grey them out so that the plot does not become too cluttered\nplt.plot(totals_df['3. Intermediate occupations'], '0.6', label='_hidden', linestyle='dotted')\nplt.plot(totals_df['4. Small employers and own account workers'], '0.6', label='_hidden', linestyle = 'dotted')\nplt.plot(totals_df['5. Lower supervisory and technical occupations'], '0.6', label='_hidden', linestyle = 'dotted')\nplt.plot(totals_df['6. Semi-routine occupations'], '0.6', label='_hidden', linestyle = 'dotted')\n\nplt.legend(loc=\"upper right\")\n\n# If diagram is small, run this cell again individually and it should resize.\n# Seems to be a bug and does not automatically resize when all cells are run together.\nplt.rcParams[\"figure.figsize\"] = (10,6)","99ebc4d9":"# Create a dataframe from csv data\nareas_df = pd.read_csv('\/kaggle\/input\/uk-census-data-with-uk-deprivation-index-2015\/Postcode_to_Output_Area_to_Lower_Layer_Super_Output_Area_to_Middle_Layer_Super_Output_Area_to_Local_Authority_District_November_2018_Lookup_in_the_UK.csv', encoding = \"ISO-8859-1\")\n\n#preview of the first five rows\nareas_df.head()","4b25c70b":"# Return just the rows with the value 'E02002559'\nareas_df.loc[areas_df['msoa11cd'] == 'E02002559'].head(10)","3060dec8":"# Drop the columns by position (0 indexed)\nareas_df = areas_df.drop(areas_df.columns[[0,1,2,3,4,5,6,9,10,12,13]], axis=1)\n\nareas_df.head()","eb6401f3":"# Read the data from File_2_ID_2015_Domains_of_deprivation.xlsx\n\ndeprivation_df = pd.read_csv('\/kaggle\/input\/uk-census-data-with-uk-deprivation-index-2015\/File_2_ID_2015_Domains_of_deprivation.csv')\n\n# Preview the data\ndeprivation_df.head()","7a774ca5":"# Drop the columns by position (0 indexed)\ndeprivation_df = deprivation_df.drop(deprivation_df.columns[[2,3]], axis=1)\n\ndeprivation_df.head()","d8bbbc21":"# Preview the original census data again to see which columns need to be dropped.\n\n_16_24_df.head()","9a3ae962":"# Include an age column so that I am able to differentiate the data after I've combined it.\n\n_16_24_df['Age'] = '16-24'\n_25_49_df['Age'] = '25-49'\n_50_64_df['Age'] = '50-64'\n_65_plus_df['Age'] = '65+'\n\n# Check one\n_16_24_df.head()","d0d82b8a":"# Combine census dataframes\n\ncombined_census_df = _16_24_df.append(_25_49_df)\ncombined_census_df = combined_census_df.append(_50_64_df)\ncombined_census_df = combined_census_df.append(_65_plus_df)\n\ncombined_census_df.head()","6d1bce97":"# Drop the columns by position (0 indexed)\ncleaned_census_df = combined_census_df.drop(combined_census_df.columns[[2,3,4,5,6,7,8,9,12,13]], axis=1)\n\ncleaned_census_df.head()","98febe7a":"#Ensure the joining columns are the same data type\n\ncleaned_census_df.mnemonic = cleaned_census_df.mnemonic.astype(str)\nareas_df.lsoa11cd = areas_df.lsoa11cd.astype(str)\ndeprivation_df['LSOA code (2011)'] = deprivation_df['LSOA code (2011)'].astype(str)","ab1cc33f":"# Set the index of the dataframes to the LSOA codes for joining\n\ndeprivation_df = deprivation_df.set_index('LSOA code (2011)')\nareas_df = areas_df.set_index('lsoa11cd')\n\n# Set the index of the census data to the MSOA codes for later\n\ncleaned_census_df= cleaned_census_df.set_index('mnemonic')","5a7f1a21":"# Join the dataframes\ncombined_df = deprivation_df.join(areas_df, how='left')\n\n# Drop the duplicates and check the number of rows\ncombined_df = combined_df.drop_duplicates()\ncombined_df","e5e0801a":"# Reset the index of the combined_df first so that I don't lose the LSOA data\ncombined_df = combined_df.reset_index()\n\n# Rename the column for the LSOA codes\ncombined_df = combined_df.rename(columns={\"index\": \"LSOA Code\"})\n\n# Set the index to the MSOA codes\ncombined_df = combined_df.set_index('msoa11cd')\n\n# Preview\ncombined_df.head()","dbdad3b2":"# Join the dataframes\ncombined_df = combined_df.join(cleaned_census_df, how='left')\ncombined_df = combined_df.drop_duplicates()\n\ncombined_df.head()","26eb8619":"# Drop the columns by position (0 indexed)\n#combined_df = combined_df.drop(combined_df.columns[[18,19,20]], axis=1)\n\n# Reset the index\ncombined_df = combined_df.reset_index()\n\n# Rename the old index data\ncombined_df = combined_df.rename(columns={\"index\": \"MSOA Code\"})\n\ncombined_df.head()","ae71fef8":"combined_df = combined_df.rename(columns={\"Index of Multiple Deprivation (IMD) Rank (where 1 is most deprived)\": \"IMD Rank\",\n                                          \"Index of Multiple Deprivation (IMD) Decile (where 1 is most deprived 10% of LSOAs)\" : \"IMD Decile\",\n                                          \"L14.1 Never worked\" : \"Never Worked\",\n                                          \"L14.2 Long-term unemployed\" : \"Long-term unemployed\",\n                                          \"Income Rank (where 1 is most deprived)\" : \"Income Rank\",\n                                          \"Income Decile (where 1 is most deprived 10% of LSOAs)\" : \"Income Decile\",\n                                          \"Employment Rank (where 1 is most deprived)\" : \"Employment Rank\",\n                                          \"Employment Decile (where 1 is most deprived 10% of LSOAs)\" : \"Employment Decile\",\n                                          \"Education, Skills and Training Rank (where 1 is most deprived)\" : \"Education Rank\",\n                                          \"Education, Skills and Training Decile (where 1 is most deprived 10% of LSOAs)\" : \"Education Decile\",\n                                          \"Health Deprivation and Disability Decile (where 1 is most deprived 10% of LSOAs)\" : \"Health Decile\",\n                                          \"Health Deprivation and Disability Rank (where 1 is most deprived)\" : \"Health Rank\",\n                                          \"Crime Rank (where 1 is most deprived)\" : \"Crime Rank\",\n                                          \"Crime Decile (where 1 is most deprived 10% of LSOAs)\" : \"Crime Decile\",\n                                          \"Barriers to Housing and Services Rank (where 1 is most deprived)\" : \"Housing Rank\",\n                                          \"Barriers to Housing and Services Decile (where 1 is most deprived 10% of LSOAs)\" : \"Housing Decile\",\n                                          \"Living Environment Rank (where 1 is most deprived)\" : \"Environment Rank\",\n                                          \"Living Environment Decile (where 1 is most deprived 10% of LSOAs)\" : \"Environment Decile\"})\ncombined_df.head()","9ba36ec4":"# View correlation between IMD rank and the number of people who have never worked\ncombined_df[\"IMD Rank\"] = combined_df[\"IMD Rank\"].str.replace(\",\",\"\").astype(int)\ncombined_df['IMD Rank'].astype(int).corr(combined_df['Never Worked'])\n","fa969253":"# View correlation between IMD rank and the number of people are long-term unemployed\ncombined_df['IMD Rank'].corr(combined_df['Long-term unemployed'])","89ebe230":"# Create a copies of the dataframe to experiment with\ncombined_df_copy1 = combined_df.copy()\ncombined_df_copy2 = combined_df.copy()","4c74167d":"# Calculate the trendline\nz = np.polyfit(x=combined_df_copy1.loc[:, 'IMD Rank'], y=combined_df_copy1.loc[:, 'Never Worked'], deg=1)\np = np.poly1d(z)\n\n# Add the trend line data to the dataframe\ncombined_df_copy1['Never Worked trendline'] = p(combined_df_copy1.loc[:, 'IMD Rank'])","d6f4d79d":"# Plot the data and the trendline\nax = combined_df_copy1.plot.scatter(x='IMD Rank', y='Never Worked', figsize=(10,10), \n                             title=\"Number of people who have never worked against IMD Rank\")\ncombined_df_copy1.set_index('IMD Rank', inplace=True)\ncombined_df_copy1['Never Worked trendline'].sort_index(ascending=False).plot(ax=ax, color=\"yellow\");","cc2883bc":"# Calculate the trendline\nz = np.polyfit(x=combined_df_copy2.loc[:, 'IMD Rank'], y=combined_df_copy2.loc[:, 'Long-term unemployed'], deg=1)\np = np.poly1d(z)\n\n# Add the trend line data to the dataframe\ncombined_df_copy2['unemployed trendline'] = p(combined_df_copy2.loc[:, 'IMD Rank'])","99eb3a96":"# Plot the data and the trendline\nax = combined_df_copy2.plot.scatter(x='IMD Rank', y='Long-term unemployed', figsize=(10,10), \n                             title=\"Number of people who are long-term unemployed against IMD Rank\")\ncombined_df_copy2.set_index('IMD Rank', inplace=True)\ncombined_df_copy2['unemployed trendline'].sort_index(ascending=False).plot(ax=ax, color=\"yellow\");","228935e0":"# Create a copy of the census dataframe to experiment with\ncombined_census_df_copy = combined_census_df.copy()\n\ncombined_census_df_copy.head()","fcedbd05":"# Run k-means algorithm on the data\n\n# Select only the features that I want to cluster on:\ncensus_numeric_data = combined_census_df_copy[['1.1 Large employers and higher managerial and administrative occupations',\n                                            '1.2 Higher professional occupations',\n                                            '2. Lower managerial, administrative and professional occupations',\n                                            '3. Intermediate occupations',\n                                            '4. Small employers and own account workers',\n                                            '5. Lower supervisory and technical occupations',\n                                            '6. Semi-routine occupations',\n                                            '7. Routine occupations',\n                                            'L14.1 Never worked',\n                                            'L14.2 Long-term unemployed',\n                                            'L15 Full-time students']]\n\n# Then, create an instance of the clusterer\nkmeans3 = KMeans(n_clusters=3)\nassignedClusters = kmeans3.fit(census_numeric_data)","0fea3c19":"silhouetteData_df = pd.DataFrame({'silhouette':silhouette_samples(census_numeric_data,\n                                                                  assignedClusters.labels_),\n                                  'cluster':assignedClusters.labels_})\n\nsilhouetteData_df.head()","d6a3faac":"silhouetteData_df.sort_values(['cluster', 'silhouette'], inplace=True)\nsilhouetteData_df.index = range(len(silhouetteData_df))\n\ncolourMap = {0:'red',\n             1:'blue',\n             2:'lightGreen'}\n\nfor cluster in set(silhouetteData_df['cluster']):\n    plt.bar(silhouetteData_df[silhouetteData_df['cluster']==cluster].index,\n            silhouetteData_df[silhouetteData_df['cluster']==cluster]['silhouette'],\n            color=colourMap[cluster],\n            label='Cluster {}'.format(cluster), width=1)\n\nplt.title('Silhouette plot of census data, clustered with $k$-means, $k$=3')\n\nplt.xlabel('Number of data point')\nplt.ylabel('Silhouette coefficient')\n\nplt.legend();","330f0177":"kmeans5 = KMeans(n_clusters=5)\nassignedClusters = kmeans5.fit(census_numeric_data)","e5064a86":"silhouetteData_df2 = pd.DataFrame({'silhouette':silhouette_samples(census_numeric_data,\n                                                                  assignedClusters.labels_),\n                                  'cluster':assignedClusters.labels_})\n\nsilhouetteData_df2.head()","2dbd376d":"silhouetteData_df2.sort_values(['cluster', 'silhouette'], inplace=True)\nsilhouetteData_df2.index = range(len(silhouetteData_df2))\n\ncolourMap = {0:'red',\n             1:'blue',\n             2:'lightGreen',\n             3:'yellow',\n             4:'pink'}\n\nfor cluster in set(silhouetteData_df2['cluster']):\n    plt.bar(silhouetteData_df2[silhouetteData_df2['cluster']==cluster].index,\n            silhouetteData_df2[silhouetteData_df2['cluster']==cluster]['silhouette'],\n            color=colourMap[cluster],\n            label='Cluster {}'.format(cluster),\n            width=1)\n\nplt.title('Silhouette plot of census data, clustered with $k$-means, $k$=5')\n\nplt.xlabel('Number of data point')\nplt.ylabel('Silhouette coefficient')\n\nplt.legend();","7ac616d1":"# Remind myself of which Dataframes I currently have loaded in memory\n\n%whos DataFrame","1ec35003":"combined_df.head()","baf6ca97":"# Run k-means algorithm on the data\n\n# Select only the features that I want to cluster on:\ncombined_numerics = combined_df[['IMD Decile',\n                                 'Never Worked',\n                                 'Long-term unemployed']]\n\n# Then, create an instance of the clusterer\nkmeans3 = KMeans(n_clusters=3)\nassignedClusters = kmeans3.fit(combined_numerics)","d4678ff1":"silhouetteData_df = pd.DataFrame({'silhouette':silhouette_samples(combined_numerics,\n                                                                  assignedClusters.labels_),\n                                  'cluster':assignedClusters.labels_})\n\nsilhouetteData_df.head()","94006bf1":"silhouetteData_df.sort_values(['cluster', 'silhouette'], inplace=True)\nsilhouetteData_df.index = range(len(silhouetteData_df))\n\ncolourMap = {0:'red',\n             1:'blue',\n             2:'lightGreen'}\n\nfor cluster in set(silhouetteData_df['cluster']):\n    plt.bar(silhouetteData_df[silhouetteData_df['cluster']==cluster].index,\n            silhouetteData_df[silhouetteData_df['cluster']==cluster]['silhouette'],\n            color=colourMap[cluster],\n            label='Cluster {}'.format(cluster), width=1)\n\nplt.title('Silhouette plot of combined data, clustered with $k$-means, $k$=3')\n\nplt.xlabel('Number of data point')\nplt.ylabel('Silhouette coefficient')\n\nplt.legend();","46edc4cb":"def classify_single_case(trainingData_df, targetValues_ss, ix, k):\n    '''Use k-NN to classify the member of trainingData_df with index\n       ix using a k-nearest neighbours classifier. The classifier is\n       trained on the data in trainingData_df and the classes in\n       targetValues_ss, with the data point indexed by ix omitted.\n       Returns the class assigned to the data point with index ix.\n    '''\n\n    # Create a classifier instance to do k-nearest neighbours\n    myClassifier = KNeighborsClassifier(n_neighbors=k,\n                                        metric='canberra',\n                                        weights='distance')\n\n    # Now apply the classifier to all data points except\n    # the one indexed by ix\n    myClassifier.fit(trainingData_df.drop(ix, axis='index'),\n                     targetValues_ss.drop(ix))\n\n    # Return the class predicted by the trained classifier. Need\n    # to predict on list of trainingData_df.loc[ix], as predict\n    # expects a list\/array, rather than a single value\n\n    return myClassifier.predict([trainingData_df.loc[ix]])[0]","02542b50":"# Include the age catergory by including numerical values for each\n# State all permutations of outcomes\nconditions = [\n     (combined_df['Age'] == '16-24'),\n     (combined_df['Age'] == '25-49'),\n     (combined_df['Age'] == '50-64'),\n     (combined_df['Age'] == '65+')\n    ]\n# Create the values to be added to the category column (These will be used to train the data)\nvalues = [1, 2, 3, 4]\n\n# Add the final column with values populated by the above conditions\ncombined_df['Age Category'] = np.select(conditions, values)\n\n# display updated DataFrame\ncombined_df.head()","4d831a24":"# Create a sample dataframe selecting a random amount of rows (specified by n)\n\nsample_df = combined_df.sample(n=1000)","b0a010db":"# Use the three columns 'Never Worked', 'Age Category' and\n# 'Long-term unemployed'  for the training data\ntrainingData_df = sample_df[['Never Worked', 'Long-term unemployed', 'Age Category']]\n\n# Use the column 'IMD Decile' as the target values\ntargetValues_ss = sample_df['IMD Decile']\n\n# Return the predicted value of the data point:\n\n# Specify K values\nkvals = [1,3,5,7]\nfor k in kvals:\n    print('{}\\t{}'.format(k,\n                          list(([classify_single_case(trainingData_df,targetValues_ss,i,k) \n                                for i in trainingData_df.index\n                                 ] == targetValues_ss)+([classify_single_case(trainingData_df,targetValues_ss,i,k) \n                                for i in trainingData_df.index\n                                 ] == targetValues_ss+1)+([classify_single_case(trainingData_df,targetValues_ss,i,k) \n                                for i in trainingData_df.index\n                                 ] == targetValues_ss-1)\n                            ).count(True)))\n","ee8e1019":"# Use the columns 'Age Category', 'Education Decile', 'Employment Decile', 'Income Decile\n# and'Long-term unemployed' for the training data\ntrainingData_df = sample_df[['Long-term unemployed', 'Age Category', 'Education Decile', 'Employment Decile', 'Income Decile'\n                            ]]\n\n# Use the column 'IMD Decile' as the target values\ntargetValues_ss = sample_df['IMD Decile']\n\n# Return the predicted value of the data point:\n\n# Specify K values\nkvals = [1,3,5,7,9,11,13,15,17,19]\n# Print the number of matches within a tollerance of +- 2\nfor k in kvals:\n    print('{}\\t{}'.format(k,\n                          list(([classify_single_case(trainingData_df,targetValues_ss,i,k) \n                                for i in trainingData_df.index\n                                 ] == targetValues_ss)+([classify_single_case(trainingData_df,targetValues_ss,i,k) \n                                for i in trainingData_df.index\n                                 ] == targetValues_ss+1)+([classify_single_case(trainingData_df,targetValues_ss,i,k) \n                                for i in trainingData_df.index\n                                 ] == targetValues_ss-1)+([classify_single_case(trainingData_df,targetValues_ss,i,k)\n                                for i in trainingData_df.index\n                                 ] == targetValues_ss+2)+([classify_single_case(trainingData_df,targetValues_ss,i,k) \n                                for i in trainingData_df.index\n                                 ] == targetValues_ss-2)\n                            ).count(True)))\n","34e568b3":"## Second Question: \"Are the majority of people who have never worked, or are long-term unemployed, from more deprived areas?\"","0e21ba9a":"Since the age and gender information of these tables are contained within the meta data, I will add columns to the dataframes to include this information.","e16215da":"The data has now been downloaded as 8 separate tables as follows:\n\n - m_16_24.csv = Males aged 16-24\n - m_25_49.csv = Males aged 25-49\n - m_50_64.csv = Males aged 50-64\n - m_65_plus.csv = Males aged 65+\n - f_16_24.csv = Females aged 16-24\n - f_25_49.csv = Females aged 25-49\n - f_50_64.csv = Females aged 50-64\n - f_65_plus.csv = Females aged 65+","0c08bfd9":"Now that I have the deprivation index information imported, I will need to go back and arrange the census data into a format which is more appropriate. To achieve this, I will drop all of the columns except for the MSOA codes and the \"Never worked\" and \"long-term unemployed\". I will then combine the dataframes from each of the four age categories, so that I am left with one dataframe showing the area codes and out-of-work figures for all of the age groups. \n\nOnce this is complete, I will combine the deprivation dataframe with the census dataframe using the areas dataframe. ","d02288e9":"I believe I need to keep the columns named ' MSOA11CD' to match with the census data and 'LSOA11CD' to match with the deprivation index. To quickly check this, I will use the value at index 0 of '2011 super output area - middle layer' of the census_data_df which = E02002559 : Darlington 001'\n\nI think this is a concatenation of 'MSOA11CD' & 'MSOA11NM'.","44ba2034":"To begin, I will download the required data from [The Office for National Statistics](https:\/\/www.nomisweb.co.uk\/query\/construct\/summary.asp?mode=construct&version=0&dataset=682) and import the data. I will also create a cell to import the required libraries, which I will add to as I need them.","cdd865b6":"The .csv file is made up of several tables on one worksheet. It may be quicker to download the tables separately and then combine them as I need.","0c129ac7":"Import looks fine, now create the remaining dataframes.","f40f7334":"I shall now investigate if there is a correlation between the never worked and long-term unemployed with the IMD rank.","6281959c":"To make sure that I am not losing any data, there are 32844 rows in the deprivation index and 227759 rows in the areas_df. This implies that there is either even smaller geographical codes or the areas_df covers more than England. Since the areas_df is only a lookup table to help me combine the other two tables, I will not be concerned with dropping the additional rows in this dataframe, since they willl be irrelevant to this investigation.\n\nA point of note, since the deprivation index contains the lower level geographical codes, I will need to match the census data to these and not vice versa. ","b2a1ea9b":"## In light of the news announcement on the module website, I've had to abandon the line of inquiry regarding gender data. I will now compare age only with socio-economic group","6ddd5327":"## This initial work was done on the basis that Gender data was available to analyse ","61af0cdb":"Now each row in the dataframe sums up to equal 1% of the population. With the 4 rows, this dataframe represents 4% of the initial population. I shall now multiply each value by 25 so that the sum of all the values should equate to the original population, but each age category shall now be evenly weighted.","98501179":"---","764ddb14":"I will first run the algorithm on all of the socio-economic groups with k=3 to begin with.","7317b8e3":"This plot shows that there are three dominant groups (cluster 0, cluster 1 ad cluster 2). The outlying cluster (cluster 3) remains. Given the shape of this silhouette plot, the data is very spread out and does not appear to show anything of interest. I will now investigate some alternative data inputs.","8c3c8ea1":"The cell above proved very problematic and was giving me unusual answers when adding a tolerance to the criteria. For example, when checking if the trainingData matched the target_values data, I would get less matches when increasing the tolerance than I did for comparing for an exact match. After several hours, I restructured the code so that I repeat the entire search criteria. I initially structured the code to check if x = a or b or c (this was giving me odd results). I eventually restructured it so that I was checking if x=a or x=b or x=c (shown above when running the classify_single_case functions). I ended up creating a list of the three concatenated results. I've concatenated each list with a '+' operator. This is the simplest way to achieve this, but I was getting a userWarning about using '|' instead. I've decided to ignore this warning, as seen in the imports above. ","42a2e327":"I can likely drop the name columns as well, but I will keep these in place for a minute, to keep it more readable for myself. ","8eb2da3e":"After browsing some visualisations, I think that it would be quite interesting to plot the data on a simple line graph, where each line represents a socio-economic category (depending on how cluttered it gets), the x-axis is the age category and the y-axis is the total number of people. I would expect to see a general positive trend for the higher socio-economic groups as age increases and a negative trend for the lower groups as age increases.","4e8094ee":"Finally, shorten the rest of the column names to make them more readable ","1e38ce9e":"Running the above code with the Age category data give approximately 40% accuracy (10,000 samples). When this column is omitted, the accuracy drops by approximately 2%. This is still well below a level which would be deemed useful. After discovering that there is a correlation between education and employment (in a previous TMA), I shall include the education, employment and income data in the combined dataframe. (I will go back and retain this data from earlier, instead of importing and cleaning the data from scratch)","02bb60fb":"Create a sample of the combined dataframe to run the K-NN algorithm on. When running on the entire dataset, the program was running overnight and only produced the first result. Selecting a random sample of the dataframe will hopefully speed things up and still give an appropriate answer.","9d5d0978":"I shall now drop all of the unnecessary columns in this dataframe as before.","e951e209":"Now drop the unnecessary columns. I will keep this combined_census_df as it is and save the result to another new dataframe. This dataframe will prove to be useful when I come to use data mining to investigate clusters. ","3aa9f804":"# Data mining investigation","815b1b14":"After some initial investigations which don't look very interesting, I will include the age category to work with. For this, I need to change the string values (16-24 etc) to numerical values. I will assign four different values (1,2,3 & 4) depending on the string value.","cb8d2bca":"Now that I have the format that I want, I can add the remaining values","6a27a108":"This shows that there is a slight negative correlation. As IMD rank increases, the number out of work goes down. I will now plot this data with a trend line to show this.","4600885e":"Now that the dataframe is complete, I can start to visualise the data.","03add9c1":"Next, create a dataframe to hold the silhouette cluster values.","bf3ec56c":"As suspected, this graph is quite cluttered and difficult to read. What is clear though, is how much the 25-49 age group is skewing the data. This is because 16_24 captures 9 one year age groups, 25-49 captures 25 one year age groups, 50-64 captures 15 one year age groups and 65 plus captures an unknown amount. It may be necessary to divide the figures by the number of years each group represents, to give a fairer weighting, but this will be tricky with the 65 plus. The Data Commons give life expectancy in the UK in 2011 to be 80.95 years. This is of course a very rough estimate, since life expectancy is generally the life expectancy from birth of that year. Rounding up to 81, this gives the number of one year age groups to be 17. ","f3cf8579":"The above silhouette plot shows that there are two main clusters, with cluster 1 being the dominant cluster. cluster 2 is almost invisible on this plot and I suspect that it would be the single data point for the students aged 16-24, since this value is substantially larger than any of the other values, as can be seen in the line graph above. I will run the algorithm again, but this time with k=5.","d3ff8bda":"# Nicholas Martin (nm8883) EMA Project Notebook","36165ef0":"Since the final column has no value, I will drop it.","404c5f81":"totals_df.rename(index={'total': 'm_16_24'}, inplace=True)\n\ntotals_df","c9e45d10":"I will now import the data for the various age categories (combined gender) and assign to dataframes.","32c9bac3":"NOTE: Silhouette plots can take a long time to generate. Therefore, to speed things up I have changed the cells which run this code to Raw NBConvert. These cells are highlighted in blue (like this cell) and need to be changed to a code cell before running. This has improved run times when continuing the investigation.","ec88e721":"To answer this question, I will need to import an additional dataset which will be the deprivation index. I will then need to use a lookup table to convert the area codes given in the census, to the area codes given in the deprivation index. ","99ff3b82":"I will now import the deprivation index dataset","167acb4e":"This looks to confirm my suspisions. I will now drop all of the other unnecessary columns. ","a03cbcac":"## First Question: \u201cHow does age compare among the different socio-economic employment positions?\u201d","8f038d57":"For the first question of this project, I will be investigating the gender gap between the various job categories, defined by The Office for National Statistics and if age is a factor in this.","95670203":"Repeat for the others and append to totals_df","3c62802e":"This dataframe now has 32844 rows, which is what I wanted. All irrelevant data from the areas_df has now been dropped. The census dataframe has 28804 rows. Since this data uses larger geographical areas, this is not surprising. I will now add this data to the combined dataframe.\n\nFirst I will change the indexes to the MSOA codes for joining.","58c33eed":"There are now 131376 rows to this dataframe because I've included the age data. There are four age categories for each LSOA (4 x 32844 = 131376), so this works out okay. I will now drop the unnecessary columns and reset the index.","c0456bbb":"Add totals and percentage column to confirm that each age group represents 25% of the population.","42250f1a":"After checking the dataframes of the provided files above (16_24_df, 25_49_df etc.) I have seen that the MSOA columns of the census data have already been 'cleaned' and provide a column named 'mnemonic' which contains just the MSOA codes, without the English names. This will now be a straightforward job of matching each code with the LSOA code of the deprivation index. ","a1b48c6a":"After experimenting with various K-values and metrics, I have discovered that the metric which works the best is the Canberra when K=19. I initially created a sample dataframe of 1000 random values from the main dataset (to speed the analysis up). I then ran the analysis for the following K values: 1,3,5,7,9,11,13,15,17 and 19. I then ran the test again on the same sample, using a different metric. I repeated this for each metric, then refreshed the sample and started again. I done this a total of 5 times. The metrics which were tested were: euclidean, manhattan, chebyshev, hamming, minkowski, canberra and braycurtis. The results were recorded manually into an Excel spreadsheet titled 'results.xlsx' and can be found in the data folder.","c65ca9ff":"Now to divide the values by the percentage of the age group.","f7a76795":"Calculate totals of each socio-economic group for the first dataframe to ensure that everything works as intended.","5883fb2f":"Before running this notebook, please include the 'output_area_classification.csv' file which was provided in the census folder. This file alone is almost 50MB and had to be removed before I could submit the EMA.","d4a99b7e":"The previous cell takes a long time to run (circa 20 minutes). The results were not particularly interesting. Again, there are two main clusters and a small third cluster. The data points do not appear to form obvious clusters, since the gradient of the silhouettes were quite steep and even included negative values. I shall now investigate some classification techniques using K-NN.","26a1319f":"I will now begin to use data mining to begin investigating the data. I will likely use the K-means algorithm to look for clusters among the data. Because I will be investigating more than two numerical features, I will be unable to show this as a scatter plot but I can however, show the clusters using a silhouette plot.","32a398fc":"Unsurprisingly, the largest value shown is for full-time students aged 16-24. This then plummets to become the smallest category in all of the other age groups. The largest value for the 25-49 age group is for lower managerial roles, this could possibly be due to students finishing college and university and landing their first job in these roles. Conversely, this is also the largest of the age groups (in terms of number of years it covers) and represents the 'prime' of working life.","89c9303b":"---","f0a2b67b":"Another possibility to give more even weightings, is to find the percentage of the data population each age group represents and divide by that number. For example, if 25-49 year olds represent 45% of the dataset, I would divide the figures by 45. I think this would provide a more accurate representation, but determining the label for the final values is not straight forward. \"Total per 1% population\", perhaps?"}}