{"cell_type":{"5cf247b7":"code","3840c080":"code","856a27a5":"code","391d0c68":"code","0e15da2f":"code","3147d8b5":"code","cca832d5":"code","975fd4f6":"code","78fa3a0c":"code","b685da90":"code","a7d608f2":"code","dac010d8":"code","2038fe18":"code","b53a4198":"code","9e5bf014":"code","be93c906":"code","718e96bf":"code","292d1459":"code","340e9c50":"code","19819004":"code","95cf61c2":"code","c5ac4fa8":"code","19f36555":"code","78addcc9":"code","2b65ef78":"code","8c678673":"code","8f21acac":"code","fbd4a902":"code","69c8cca9":"code","9836d4ee":"code","c5e908b1":"code","9ada0026":"code","3a891029":"code","fcda1d92":"code","8ea7db55":"code","4ce6a561":"code","c8a6f316":"code","30e08e3b":"code","78b2efd4":"code","f6cf0469":"code","593a73c8":"code","4c2ac6d9":"code","b9673021":"code","230358f4":"code","0cfb1d5a":"code","d85de2eb":"code","62b9c258":"code","312d5866":"code","49b4c98f":"code","3c9b094a":"markdown","936cddf8":"markdown","adabc4fb":"markdown","155486a9":"markdown","22c8a8bf":"markdown","e0e13fff":"markdown","b1c41b9c":"markdown","222df955":"markdown","e3a6a1ae":"markdown"},"source":{"5cf247b7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3840c080":"import pandas as pd \nimport datetime\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np; np.random.seed(0)\nimport os\nimport matplotlib.pyplot as plt\nimport xml.etree.ElementTree as Xet","856a27a5":"data_train = pd.read_csv(\"..\/input\/car-crashes-severity-prediction\/train.csv\") \ndTrain = pd.DataFrame(data_train)\ndTrain.head()","391d0c68":"dTrain=dTrain.drop(columns=['Bump','Roundabout'])","0e15da2f":"dTrain.groupby('Side').count()","3147d8b5":"dTrain.head()","cca832d5":"dTrain['Crossing'] = dTrain['Crossing'].astype('int')\ndTrain['Give_Way'] = dTrain['Give_Way'].astype('int')\ndTrain['Junction'] = dTrain['Junction'].astype('int')\ndTrain['No_Exit'] = dTrain['No_Exit'].astype('int')\ndTrain['Railway'] = dTrain['Railway'].astype('int')\ndTrain['Stop'] = dTrain['Stop'].astype('int')\ndTrain['Amenity'] = dTrain['Amenity'].astype('int')\ndTrain.head()","975fd4f6":"enc = LabelEncoder()\nenc.fit(dTrain['Side'])\ndTrain['Side'] = enc.transform(dTrain['Side'])","78fa3a0c":"dTrain.groupby('Side').count()","b685da90":"dTrain.dtypes","a7d608f2":"#convert timestamp to dateTime\ndTrain['timestamp']=pd.to_datetime(dTrain['timestamp'])","dac010d8":"dTrain.head()","2038fe18":"#split date from time\ndTrain['date'] = [d.date() for d in dTrain['timestamp']]","b53a4198":"dTrain.head()","9e5bf014":"dTrain.dtypes","be93c906":"#get hours from time alone but int\ndTrain['Hour'] = dTrain['timestamp'].dt.hour\ndTrain.head()","718e96bf":"#convert from int to str\ndTrain['Hour']=dTrain['Hour'].apply(str)\ndTrain[\"Hour\"] = dTrain['Hour'].astype(str)+':00:00'","292d1459":"#put hour str in time formate\ndTrain['Hour'] = pd.to_datetime(dTrain['Hour'],format= '%H:%M:%S' ).dt.time","340e9c50":"dTrain[\"Hour\"] = dTrain['Hour'].astype(str)","19819004":"dTrain.head()","95cf61c2":"#date and time str to concatenate later\ndTrain.dtypes","c5ac4fa8":"dTrain[\"Hour\"]= dTrain[\"Hour\"].str.split(\":\", n = 1, expand = True)\ndTrain['Hour'] = dTrain['Hour'].astype(int)\ndTrain.head()","19f36555":"data_weather = pd.read_csv(\"..\/input\/car-crashes-severity-prediction\/weather-sfcsv.csv\") \ndWeather = pd.DataFrame(data_weather)\n# Preview the first 5 lines of the loaded data \ndWeather.head()","78addcc9":"dWeather['Year'] = dWeather['Year'].apply(str)\ndWeather['Month'] = dWeather['Month'].apply(str)\ndWeather['Day'] = dWeather['Day'].apply(str)","2b65ef78":"dWeather[\"date\"] = pd.to_datetime(dWeather['Year'].astype(str)+'-'+dWeather['Month']+'-'+dWeather['Day']).dt.date\ndWeather.head()","8c678673":"dWeather['Weather_Condition'] = dWeather['Weather_Condition'].apply(str)","8f21acac":"dWeather = dWeather.drop(columns=['Year', 'Month','Day'])","fbd4a902":"dWeather.head()","69c8cca9":"dWeather.to_csv('weather.csv')","9836d4ee":"cols = [\"date\", \"description\"]\nrows = []\n  \n# Parsing the XML file\nxmlparse = Xet.parse('..\/input\/car-crashes-severity-prediction\/holidays.xml')\nroot = xmlparse.getroot()\nfor i in root:\n    date = i.find(\"date\").text\n    description = i.find(\"description\").text\n  \n    rows.append({\"date\": date,\n                 \"description\": description})\n  \ndholidays = pd.DataFrame(rows, columns=cols)\n  \n# Writing dataframe to csv\ndholidays.to_csv('holidays.csv')","c5e908b1":"dholidays['date']=pd.to_datetime(dholidays['date']).dt.date\ndholidays.head()","9ada0026":"dholidays.dtypes","3a891029":"dTrain_dWeather = dTrain.merge(dWeather, left_on=[\"date\",\"Hour\"], right_on=[\"date\",\"Hour\"], how = 'left')","fcda1d92":"dTrain_dWeather.head()","8ea7db55":"dfinal = dTrain_dWeather.merge(dholidays, on=\"date\", how = 'left')","4ce6a561":"dfinal.head()","c8a6f316":"dfinal['Wind_Chill(F)'] = dfinal['Wind_Chill(F)'].fillna((dfinal['Wind_Chill(F)'].mean()))\ndfinal['Precipitation(in)'] = dfinal['Precipitation(in)'].fillna((dfinal['Precipitation(in)'].mean()))\ndfinal['Temperature(F)'] = dfinal['Temperature(F)'].fillna((dfinal['Precipitation(in)'].mean()))\n\ndfinal.head()","30e08e3b":"dfinal['description'] = dfinal['description'].fillna(0)\ndfinal[\"description\"]=dfinal[\"description\"].apply(lambda x: 1 if x!=0 else 0)","78b2efd4":"enc = LabelEncoder()\nenc.fit(dfinal['Weather_Condition'])\ndfinal['Weather_Condition'] = enc.transform(dfinal['Weather_Condition'])","f6cf0469":"dfinal.head()","593a73c8":"dfinal['date'] = dfinal['date'].apply(str)","4c2ac6d9":"dfinal.to_csv('finalDataset.csv')","b9673021":"from sklearn.model_selection import train_test_split\n\ntrain_df, val_df = train_test_split(dfinal, test_size=0.2, random_state=42) # Try adding `stratify` here\n\nX_train = train_df.drop(columns=['ID', 'Severity'])\ny_train = train_df['Severity']\n\nX_val = val_df.drop(columns=['ID', 'Severity'])\ny_val = val_df['Severity']","230358f4":"# This cell is used to select the numerical features. IT SHOULD BE REMOVED AS YOU DO YOUR WORK.\nX_train = X_train[['Lat', 'Stop', 'Hour']]\nX_val = X_val[['Lat', 'Stop', 'Hour']]","0cfb1d5a":"from sklearn.ensemble import RandomForestClassifier\n\n# Create an instance of the classifier\nclassifier = RandomForestClassifier(max_depth=2, random_state=0)\n\n# Train the classifier\nclassifier = classifier.fit(X_train, y_train)","d85de2eb":"print(\"The accuracy of the classifier on the validation set is \", (classifier.score(X_val, y_val)))","62b9c258":"test_df = pd.read_csv(os.path.join('..\/input\/car-crashes-severity-prediction\/test.csv'))\ntest_df.head()","312d5866":"X_test = test_df.drop(columns=['ID'])\n\n# You should update\/remove the next line once you change the features used for training\nX_test = X_test[['Lat', 'Lng', 'Distance(mi)']]\n\ny_test_predicted = classifier.predict(X_test)\n\ntest_df['Severity'] = y_test_predicted\n\ntest_df.head()","49b4c98f":"test_df[['ID', 'Severity']].to_csv('kaggle_submission.csv', index=False)","3c9b094a":"# **Holiday Dataset**","936cddf8":"# **Model Training**","adabc4fb":"# **Submission File Generation**\n","155486a9":"# **Data Splitting**","22c8a8bf":"> **Merge Train with Weather by date**\n","e0e13fff":"# **Weather Dataset**","b1c41b9c":"> **Merge Train & Weather with Holidays by date**","222df955":"# **Train Dataset**","e3a6a1ae":"# **Merging Datasets**"}}