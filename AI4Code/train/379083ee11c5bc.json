{"cell_type":{"b2fa2d4c":"code","8de0ce9e":"code","7288884d":"code","f9ca31ce":"code","04229aa7":"code","04a518cc":"code","ec172fcb":"code","e97ab881":"code","f181edc6":"code","640d3664":"code","bad6eed3":"code","43a6cd57":"code","6509f1dd":"code","7776f5ca":"code","cb418751":"code","6290bd6d":"code","d9f87128":"code","899b59dd":"code","1d5c3bd8":"code","a4c05b60":"code","59911d55":"code","8088cb6d":"code","ed034bec":"code","cb0db569":"code","0fb003b0":"code","e3c7b48c":"code","607d62e8":"code","0880f153":"code","e0377e10":"code","455e6f60":"code","1869dd6b":"code","66a0f172":"code","571a22f0":"code","9e26f9fd":"code","8466641e":"code","d8eacd31":"code","0d74bdfa":"code","164f259e":"code","caad4bb9":"code","06c671a0":"code","18b6dbbd":"code","6099d05d":"code","bf59381b":"code","cde8b51a":"code","dec1b083":"code","d8247812":"code","37573fa8":"code","051980bc":"code","f5e7f1a5":"code","01d91b1e":"code","2260a6d5":"code","4cad2475":"code","6090410a":"code","a4c847e7":"code","9c6df5ae":"code","34f1e2c6":"code","1d3edb75":"code","5f16e6bd":"markdown","46f33539":"markdown","fa76a701":"markdown","c63d71ee":"markdown","a2f0f4c2":"markdown","35c2dbcb":"markdown","a184a7cf":"markdown","ca4e6cdd":"markdown","9f08c25b":"markdown","687bd12c":"markdown","8e2287c6":"markdown"},"source":{"b2fa2d4c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","8de0ce9e":"import pandas as pd              \nimport seaborn as sns            \nimport warnings\n\n%pylab inline\n\nplt.style.use('seaborn-darkgrid')\nsns.set(font_scale=2)\nwarnings.filterwarnings(action=\"ignore\")\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom lightgbm         import LGBMClassifier\nfrom xgboost          import XGBClassifier\nfrom catboost         import CatBoostClassifier\n\nn_arbres  = 200\nmax_depth = 6 \n        \nnoms         = [\n                \"Random_Forest\", \n                \"Ada_Boost\", \n                \"Gradient_Boosting\",\n                \"LightGBM\",\n                \"XGBoost\",\n                \"CatBoost\"\n               ]\n\nclassifieurs = [\n                RandomForestClassifier(n_estimators=n_arbres,max_depth=max_depth),\n                AdaBoostClassifier(n_estimators=n_arbres),\n                GradientBoostingClassifier(n_estimators=n_arbres,max_depth=max_depth, max_leaf_nodes=4,min_samples_split=5),\n                XGBClassifier(n_estimators=n_arbres,max_depth=max_depth), \n                LGBMClassifier(n_estimators=n_arbres,max_depth=max_depth),\n                CatBoostClassifier(n_estimators=n_arbres,silent=True)\n               ]\n\nclassifieursArbresDict = {nom:classifieur for nom, classifieur in zip(noms, classifieurs)}\n\ndef comparaisonsClassifieurs(classifieursDict, X_train, X_test, y_train, y_test):\n    t0 = time.time()  \n    np.random.seed(123456)\n    aucROC,accuracy,logloss,hammingloss,precision,sensibilite,f1,jaccard_similarity,avgPrecRec = \\\n             dict(),dict(),dict(),dict(),dict(),dict(),dict(),dict(),dict()\n\n    yClassifications = pd.DataFrame()\n    yClassifications['Observations']=y_test\n\n    plt.figure(figsize=(18,36))\n\n    for nom in classifieursDict:\n        t1 = time.time()  \n        classifieursDict[nom].fit(X_train, y_train)\n        score = classifieursDict[nom].score(X_test, y_test)*100\n        print(f'Pr\u00e9diction : {nom:32s}'+(' %.8f' % score).lstrip('0'),end=' -- ')\n        #-------------------------------------------------------------------------------------\n        yClassifications[nom+'_prob'] = classifieursDict[nom].predict_proba(X_test)[:, 1]\n        yClassifications[nom+'_pred'] = classifieursDict[nom].predict(X_test)\n        fpr, tpr, thresholds = roc_curve(y_test.ravel(), yClassifications[nom+'_prob'])\n        #-------------------------------------------------------------------------------------\n        accuracy[nom]            = accuracy_score(yClassifications['Observations'],yClassifications[nom+'_pred'])\n        logloss[nom]             = log_loss(yClassifications['Observations'],yClassifications[nom+'_pred'])\n        hammingloss[nom]         = hamming_loss(yClassifications['Observations'],yClassifications[nom+'_pred'])\n        precision[nom]           = precision_score(yClassifications['Observations'],yClassifications[nom+'_pred'])\n        sensibilite[nom]         = recall_score(yClassifications['Observations'],yClassifications[nom+'_pred'])\n        f1[nom]                  = f1_score(yClassifications['Observations'],yClassifications[nom+'_pred'])\n        jaccard_similarity[nom]  = jaccard_score(yClassifications['Observations'],yClassifications[nom+'_pred'])\n        aucROC[nom]              = auc(fpr, tpr)\n        #-------------------------------------------------------------------------------------\n\n        plt.subplot(2, 1, 1)\n        print (\"Area under the ROC curve : %0.8f\" % aucROC[nom],end=' -- ')\n        plt.plot(fpr, tpr, label=f\"{nom}(AUC = {aucROC[nom]:0.8f})\")\n        plt.plot([0, 1], [0, 1], 'k--')\n        plt.xlim([-0.05, 1.05])\n        plt.ylim([-0.05, 1.05])\n        plt.xlabel('(1 - Specificity)--La Sp\u00e9cificit\u00e9(Specificity) = VN \/ (FP + VN)',size=18)\n        plt.ylabel('La Sensibilit\u00e9(Sensitivity) = VP \/ (VP + FN)',size=18)\n        plt.title('La courbe ROC (Receiver Operating Caracteristic)',size=20)\n        plt.legend(loc=\"lower right\")\n\n        prec, rec, thresholds = precision_recall_curve(y_test.ravel(), yClassifications[nom+'_prob'])\n        avgPrecRec[nom] = average_precision_score(y_test.ravel(), yClassifications[nom+'_prob'])\n\n        plt.subplot(2, 1, 2)\n        plt.step(rec, prec, where='post', label=f\"{nom}(AP = {avgPrecRec[nom]:0.8f})\")#alpha=0.8, \n        plt.fill_between(rec, prec, step='post', alpha=0.05)\n        plt.plot([0, 1], [0.5, 0.5], 'k--')\n        plt.xlabel('Le Rappel(Recall) = VP \/ (VP + FN)',size=18)\n        plt.ylabel('La Pr\u00e9cision = VP \/ (VP + FP)',size=18)        \n        plt.title('La courbe pr\u00e9cision-rappel',size=20)\n        plt.legend(loc=\"lower right\")\n        print(('%0.2fs' % (time.time() - t1)).lstrip('0'))\n\n    plt.show()\n\n    print('Ex\u00e9cution  :'+('%.2fs' % (time.time() - t0)).lstrip('0'))\n\n    resultats = pd.DataFrame(pd.Series(aucROC),columns=[\"aucROC\"])\n    resultats[\"avgPrecRec\"]         = pd.Series(avgPrecRec)\n    resultats[\"accuracy\"]           = pd.Series(accuracy)\n    resultats[\"log_loss\"]           = pd.Series(logloss)\n    resultats[\"hamming_loss\"]       = pd.Series(hammingloss)\n    resultats[\"precision\"]          = pd.Series(precision)\n    resultats[\"sensibilite\"]        = pd.Series(sensibilite)\n    resultats[\"f1\"]                 = pd.Series(f1)\n    resultats[\"jaccard_similarity\"] = pd.Series(jaccard_similarity)\n    resultats.sort_values(by='aucROC',ascending=False, inplace=True)\n    return resultats\n\nfrom sklearn.metrics   import make_scorer, confusion_matrix, roc_curve, auc, accuracy_score, log_loss, hamming_loss, \\\n                              precision_score, recall_score, f1_score, jaccard_score,  \\\n                              precision_recall_curve, average_precision_score\nimport time\n\ndef controleClassifieur(classifieur, X_train, X_test, y_train, y_test, nom = 'CatBoost'):\n    t0 = time.time()  \n    np.random.seed(123456)\n    aucROC,accuracy,logloss,hammingloss,precision,sensibilite,f1,jaccard_similarity,avgPrecRec = \\\n             dict(),dict(),dict(),dict(),dict(),dict(),dict(),dict(),dict()\n\n    yClassifications = pd.DataFrame()\n    yClassifications['Observations']=y_test\n\n    plt.figure(figsize=(18,36))\n\n    t1 = time.time()  \n    classifieur.fit(X_train, y_train)\n    score = classifieur.score(X_test, y_test)*100\n    print(f'Pr\u00e9diction : {nom:32s}'+(' %.8f' % score).lstrip('0'),end=' -- ')\n    #-------------------------------------------------------------------------------------\n    yClassifications[nom+'_prob'] = classifieur.predict_proba(X_test)[:, 1]\n    yClassifications[nom+'_pred'] = classifieur.predict(X_test)\n    fpr, tpr, thresholds = roc_curve(y_test.ravel(), yClassifications[nom+'_prob'])\n    #-------------------------------------------------------------------------------------\n    accuracy[nom]            = accuracy_score(yClassifications['Observations'],yClassifications[nom+'_pred'])\n    logloss[nom]             = log_loss(yClassifications['Observations'],yClassifications[nom+'_pred'])\n    hammingloss[nom]         = hamming_loss(yClassifications['Observations'],yClassifications[nom+'_pred'])\n    precision[nom]           = precision_score(yClassifications['Observations'],yClassifications[nom+'_pred'])\n    sensibilite[nom]         = recall_score(yClassifications['Observations'],yClassifications[nom+'_pred'])\n    f1[nom]                  = f1_score(yClassifications['Observations'],yClassifications[nom+'_pred'])\n    jaccard_similarity[nom]  = jaccard_score(yClassifications['Observations'],yClassifications[nom+'_pred'])\n    aucROC[nom]              = auc(fpr, tpr)\n    #-------------------------------------------------------------------------------------\n\n    plt.subplot(2, 1, 1)\n    print (\"Area under the ROC curve : %0.8f\" % aucROC[nom],end=' -- ')\n    plt.plot(fpr, tpr, label=f\"{nom}(AUC = {aucROC[nom]:0.8f})\")\n    #-------------------------------------------------------------------------------------\n    nb_decimales = 2\n    angleText = 36\n    transparence=0.6\n    for i,t in enumerate(thresholds*100):\n        if i > 0 :\n            plt.text(fpr[i], tpr[i],str(t.round(nb_decimales)), rotation= angleText, alpha=transparence) #+0.008\n    #-------------------------------------------------------------------------------------\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('(1 - Specificity)--La Sp\u00e9cificit\u00e9(Specificity) = VN \/ (FP + VN)',size=18)\n    plt.ylabel('La Sensibilit\u00e9(Sensitivity) = VP \/ (VP + FN)',size=18)\n    plt.title('La courbe ROC (Receiver Operating Caracteristic)',size=20)\n    plt.legend(loc=\"lower right\")\n\n    prec, rec, thresholds = precision_recall_curve(y_test.ravel(), yClassifications[nom+'_prob'])\n    avgPrecRec[nom] = average_precision_score(y_test.ravel(), yClassifications[nom+'_prob'])\n\n    plt.subplot(2, 1, 2)\n    plt.step(rec, prec, where='post', label=f\"{nom}(AP = {avgPrecRec[nom]:0.8f})\")#alpha=0.8, \n    plt.fill_between(rec, prec, step='post', alpha=0.05)\n    plt.plot([0, 1], [0.5, 0.5], 'k--')\n    plt.xlabel('Le Rappel(Recall) = VP \/ (VP + FN)',size=18)\n    plt.ylabel('La Pr\u00e9cision = VP \/ (VP + FP)',size=18)        \n    plt.title('La courbe pr\u00e9cision-rappel',size=20)\n    plt.legend(loc=\"lower right\")\n    print(('%0.2fs' % (time.time() - t1)).lstrip('0'))\n\n    plt.show()\n\n    print('Ex\u00e9cution  :'+('%.2fs' % (time.time() - t0)).lstrip('0'))\n\n    resultats = pd.DataFrame(pd.Series(aucROC),columns=[\"aucROC\"])\n    resultats[\"avgPrecRec\"]         = pd.Series(avgPrecRec)\n    resultats[\"accuracy\"]           = pd.Series(accuracy)\n    resultats[\"log_loss\"]           = pd.Series(logloss)\n    resultats[\"hamming_loss\"]       = pd.Series(hammingloss)\n    resultats[\"precision\"]          = pd.Series(precision)\n    resultats[\"sensibilite\"]        = pd.Series(sensibilite)\n    resultats[\"f1\"]                 = pd.Series(f1)\n    resultats[\"jaccard_similarity\"] = pd.Series(jaccard_similarity)\n    resultats.sort_values(by='aucROC',ascending=False, inplace=True)\n    return resultats\n\ndef afficheImportanceVariables(classifieurs, X, nom = 'CatBoost'):\n    importances = pd.DataFrame(X.columns, columns=['nom'])\n    importances['importance'] = classifieurs.feature_importances_\n    importances.sort_values(by='importance',ascending=False, inplace=True)\n\n    sns_plot = sns.catplot(x='nom', y='importance',data=importances, kind='bar', size=18,  aspect=4);\n    loc, labels = plt.xticks()\n    sns_plot.set_xticklabels(labels, rotation=90);\n    plt.show()\n    return importances\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom copy import deepcopy\n\n\ndef effectueValidationCroisee(classifieur, \n                              X, \n                              y, \n                              n_splits = 5,\n                              nom = 'CatBoost'):  \n\n    moyAucROC,stdAucRoc,moyAucPR,stdAucPR,moyAccuracy,stdAccuracy  = \\\n      dict(),dict(),dict(),dict(),dict(),dict()\n\n    validationCroisee = StratifiedShuffleSplit(n_splits=n_splits)\n\n    resultatsFinaux = pd.DataFrame()\n    classifieursCV={}\n\n\n    tprs      = []\n    recs      = []\n    aucROCs   = pd.Series()\n    aucPRs    = pd.Series()\n    scores    = pd.Series()\n    mean_fpr  = np.linspace(0, 1, 100)\n    mean_prec = np.linspace(0, 1, 100)\n    aucROC,avgPrecRec,accuracy,logloss,hammingloss,precision,sensibilite,f1,jaccard_similarity= \\\n        dict(),dict(),dict(),dict(),dict(),dict(),dict(),dict(),dict()          \n\n\n    plt.figure(figsize=(24,48))\n\n    for i, (train, test) in enumerate(validationCroisee.split(X, y)):\n        X_train, X_test, y_train, y_test = X.iloc[train], X.iloc[test], y.iloc[train], y.iloc[test]\n\n        classifieur.fit(X_train, y_train)\n        classifieursCV[i] = deepcopy(classifieur)\n\n        scores = pd.concat([scores,pd.Series(classifieur.score(X_test, y_test)*100)])\n\n        #-------------------------------------------------------------------------------------\n        yClassifications_prob = classifieur.predict_proba(X_test)[:, 1]\n        yClassifications_pred = classifieur.predict(X_test)\n        fpr, tpr, thresholds  = roc_curve(y_test, yClassifications_prob)\n        #-------------------------------------------------------------------------------------\n        prec, rec, thresholds                  = precision_recall_curve(y_test, yClassifications_prob)\n        avgPrecRec[(nom,i)]          = average_precision_score(y_test, yClassifications_prob)\n        #-------------------------------------------------------------------------------------\n        accuracy[(nom,i)]            = accuracy_score(y_test,yClassifications_pred)\n        logloss[(nom,i)]             = log_loss(y_test,yClassifications_pred)\n        hammingloss[(nom,i)]         = hamming_loss(y_test,yClassifications_pred)\n        precision[(nom,i)]           = precision_score(y_test,yClassifications_pred)\n        sensibilite[(nom,i)]         = recall_score(y_test,yClassifications_pred)\n        f1[(nom,i)]                  = f1_score(y_test,yClassifications_pred)\n        jaccard_similarity[(nom,i)]  = jaccard_score(y_test,yClassifications_pred)\n        aucROC[(nom,i)]              = auc(fpr, tpr)\n        #-------------------------------------------------------------------------------------\n        tprs.append(interp(mean_fpr, fpr, tpr))\n        tprs[-1][0] = 0.0\n\n        recs.append(interp(mean_prec, prec, rec))\n        recs[-1][0] = 0.0        \n\n        aucROCs = pd.concat([aucROCs,pd.Series(aucROC[(nom,i)])])\n        aucPRs  = pd.concat([aucPRs,pd.Series(avgPrecRec[(nom,i)])])\n\n        plt.subplot(2, 1, 1)\n        plt.plot(fpr, tpr, lw=1, alpha=0.3,\n                 label='Segment %2d (AUC = %0.6f Accuracy = %0.6f)' % \n                         (i, aucROC[(nom,i)],accuracy[(nom,i)]))\n\n        plt.subplot(2, 1, 2)\n        plt.step(rec, prec, where='post', \n                 label=f\"Segment {i:2d} (AP = {avgPrecRec[(nom,i)]:0.8f})\")#alpha=0.8, \n        plt.fill_between(rec, prec, step='post', alpha=0.05)\n\n\n    plt.subplot(2, 1, 1)\n    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n             label='AUC <= 0.5', alpha=.8)\n\n    mean_tpr = np.mean(tprs, axis=0)\n    mean_tpr[-1] = 1.0\n    mean_aucROC = auc(mean_fpr, mean_tpr)\n    std_aucROC  = np.std(aucROCs)\n\n    moyAucROC[nom], stdAucRoc[nom],moyAucPR[nom], stdAucPR[nom], moyAccuracy[nom], stdAccuracy[nom] = \\\n              aucROCs.mean(),aucROCs.std(),aucPRs.mean(),aucPRs.std(),scores.mean(),scores.std()\n\n\n    plt.subplot(2, 1, 1)\n    plt.plot(mean_fpr, mean_tpr, color='b',\n             label=r'Moyenne (AUC = %0.5f $\\pm$ %0.5f Accuracy = %0.4f $\\pm$ %0.4f)' % \n                     (mean_aucROC, std_aucROC, scores.mean(), scores.std()),\n             lw=2, alpha=.8)\n\n    std_tpr = np.std(tprs, axis=0)\n    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.4,\n                     label=r'$\\pm$ %0.8f std. dev.'%(np.mean(std_tpr)))\n\n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('Le taux de faux Positifs(1 - Specificity)',size=18)\n    plt.ylabel('Le taux de vrais positifs(Sensitivity)',size=18)\n    plt.title('La courbe ROC '+nom,size=20)\n    plt.legend(loc=\"lower right\")\n\n    plt.subplot(2, 1, 2)\n\n    plt.plot([0, 1], [0.5, 0.5], linestyle='--', lw=2, color='r',\n             label='AC <= 0.5', alpha=.8)        \n\n    plt.xlabel('Le Rappel(Recall) = VP \/ (VP + FN)',size=18)\n    plt.ylabel('La Pr\u00e9cision = VP \/ (VP + FP)',size=18)        \n    plt.title('La courbe pr\u00e9cision-rappel '+nom,size=20)\n    plt.legend(loc=\"lower right\")\n\n    plt.show()\n\n    resultats                       = pd.DataFrame(pd.Series(aucROC),columns=[\"aucROC\"])\n    resultats[\"avgPrecRec\"]         = pd.Series(avgPrecRec)\n    resultats[\"accuracy\"]           = pd.Series(accuracy)\n    resultats[\"log_loss\"]           = pd.Series(logloss)\n    resultats[\"hamming_loss\"]       = pd.Series(hammingloss)\n    resultats[\"precision\"]          = pd.Series(precision)\n    resultats[\"sensibilite\"]        = pd.Series(sensibilite)\n    resultats[\"f1\"]                 = pd.Series(f1)\n    resultats[\"jaccard_similarity\"] = pd.Series(jaccard_similarity)\n\n    resultatsFinaux = pd.concat([resultatsFinaux,resultats])\n\n    return resultatsFinaux,classifieursCV","7288884d":"train=pd.read_csv(\"..\/input\/titanic\/train.csv\")\nprint(train.shape)\ntrain.head()","f9ca31ce":"test=pd.read_csv(\"..\/input\/titanic\/test.csv\")\nprint(test.shape)\ntest.head()","04229aa7":"donnees = pd.concat([train,test],sort=False)\ndonnees.head()","04a518cc":"donnees['Title'] = donnees.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\npd.crosstab(donnees['Title'], donnees['Sex'])","ec172fcb":"donnees['Title'] = donnees['Title'].replace(['Capt','Col','Major','Dr','Rev'], 'Autres')\ndonnees['Title'] = donnees['Title'].replace(['Lady', 'Countess',  'Don',  'Sir', 'Jonkheer', 'Dona'], 'Noblesse')\ndonnees['Title'] = donnees['Title'].replace('Mlle', 'Miss')\ndonnees['Title'] = donnees['Title'].replace('Ms', 'Miss')\ndonnees['Title'] = donnees['Title'].replace('Mme', 'Mrs')\ndonnees['Sex']   = donnees['Sex'].replace(\"male\",\"Homme\")\ndonnees['Sex']   = donnees['Sex'].replace(\"female\",\"Femme\")\npd.crosstab(donnees['Title'], donnees['Sex'])","e97ab881":"plt.figure(figsize=(14,12))\nplt.title('Les titres d\u00e9clin\u00e9s entre les survivants et non survivants',size=20)\nsns_plot = sns.countplot(x='Title',hue='Survived',data=donnees)","f181edc6":"donnees.Name = donnees.Name.str.extract('([A-Za-z]+)\\,', expand=False)\ndonnees.head()","640d3664":"donnees['TailleFamille'] = donnees['Parch'] + donnees['SibSp'] + 1\ndonnees.TailleFamille = donnees.TailleFamille.astype('int8')","bad6eed3":"plt.figure(figsize=(14,12))\nplt.title('La taille de la famille d\u00e9clin\u00e9e entre les survivants et non survivants',size=20)\nsns_plot = sns.countplot(x='TailleFamille',hue='Survived',data=donnees)","43a6cd57":"donnees['Pont'] = donnees.Cabin.str.extract('([A-Za-z])', expand=False)\ndonnees.Pont = donnees.Pont.fillna('Na')\npd.crosstab(donnees.Pont, np.ones(donnees.shape[0]))","6509f1dd":"donnees['TicketNum'] = donnees.Ticket.replace(regex=r'([^0-9]+)',value='')\ndonnees.Ticket = donnees.Ticket.replace(regex=r'([^a-zA-Z]+)',value='')\ndonnees.Ticket = donnees.Ticket.replace({r'^(CASOTON|SOTONO|STONO|STONOQ)$':'SOTONOQ', \n                                         r'^(SC|SCParis)$':'SCPARIS', \n                                         r'^FCC$':'FC',\n                                         r'^$':'Vide'}, regex=True) ","7776f5ca":"donnees.rename(columns={\"Pclass\": \"Classe\", \n                        \"Embarked\": \"Port\", \n                        \"Cabin\": \"Cabine\",\n                        \"SibSp\": \"ConjointsOuFratrie\",\n                        \"Parch\": \"EnfantsOuParents\",\n                       },\n               inplace=True)","cb418751":"donnees.Port = donnees.Port.fillna('Pas')\ndonnees.Cabine = donnees.Cabine.apply( lambda x: 0 if type(x) == float else 1)\ndonnees.head()","6290bd6d":"plt.figure(figsize=(14,12))\nplt.title('Le nombre des conjoints d\u00e9clin\u00e9 entre les survivants et non survivants',size=20)\nsns_plot = sns.countplot(x='ConjointsOuFratrie',hue='Survived',data=donnees);","d9f87128":"plt.figure(figsize=(14,12))\nsns_plot = sns.countplot(x='EnfantsOuParents',hue='Survived',data=donnees);","899b59dd":"plt.figure(figsize=(24,24))\nplt.title('Correlation Pearson des variables', y=1.05, size=32)\nsns.set(font_scale=2)\nax = sns_plot = sns.heatmap(donnees.corr(), fmt= '.2f',linewidths=0.3,vmax=1.0, \n            square=True, cmap='coolwarm', linecolor='white', annot=True);\n# bug Matplotlib 3.1.1\nax.set_xlim(0,9);\nax.set_ylim(9,0);","1d5c3bd8":"donnees.isnull().sum()","a4c05b60":"donnees[donnees['Fare'].isnull()]","59911d55":"plt.figure(figsize=(24,8))\nplt.subplot(1, 2, 1)\n        \nsns.boxplot(y='Fare',data=donnees[(donnees['Port'] == 'S') & \n                     (donnees['Classe'] == 3) ],color='red')\nplt.title('Prix du ticket Classe et Port')\nplt.subplot(1, 2, 2)\n\nsns.distplot(donnees[(donnees.Port == 'S') & \n                     (donnees.Classe == 3) & \n                     ~ donnees.Fare.isna()].Fare, color='red', bins = 20);\nplt.title('Distribution du Prix du ticket');","8088cb6d":"donnees[(donnees['Port'] == 'S') & (donnees['Classe'] == 3) ].Fare.median()","ed034bec":"donnees.Fare[donnees['Fare'].isna()] = donnees[(donnees['Port'] == 'S') & (donnees['Classe'] == 3) & (donnees['Age'] == 3)].Fare.median()\nplt.figure(figsize=(24,8))\nplt.subplot(1, 2, 1)\n        \nsns.distplot(donnees.Fare, rug=True);\n\nplt.title('Distribution du Prix du ticket')\nplt.subplot(1, 2, 2)\n\nsns.distplot(np.log(donnees.Fare+1), rug=True);\n\nplt.title('Distribution du Prix du ticket \u00e9chelle logarithmique');","cb0db569":"plt.figure(figsize=(12,12));\nplt.title('La distribution des \u00e2ges d\u00e9clin\u00e9e entre les survivants et non survivants',size=20);\nsns_plot = sns.distplot(donnees[(~donnees.Age.isna())&(donnees.Survived == 1)].Age,label='Survivant');\nsns_plot = sns.distplot(donnees[(~donnees.Age.isna())&(donnees.Survived == 0)].Age,label='Non Survivant');\nplt.legend();","0fb003b0":"sns_plot = sns.FacetGrid(data=donnees[~donnees.Age.isna()],\n                  col='Sex',row='Classe', hue='Survived',size=10,aspect=1);\nsns_plot.map(sns.distplot,'Age');","e3c7b48c":"donnees['AgeOld'] = donnees.Age\ndonnees.Age.describe()","607d62e8":"coefficient = 1.2\nageCalc = donnees[~donnees.Age.isna()].groupby(['Sex','Classe']).agg({'Age':['mean','std']})\nageCalc.columns = ['_'.join(col).rstrip('_') for col in ageCalc.columns]\nageCalc.reset_index(inplace=True)\nageCalc['borneMin'] = ageCalc.Age_mean - ageCalc.Age_std*coefficient\nageCalc['borneMax'] = ageCalc.Age_mean + ageCalc.Age_std*coefficient\nageCalc.drop(columns=['Age_mean','Age_std'],inplace=True)\nageCalcCount = donnees[donnees.Age.isna()].groupby(['Sex','Classe']).agg({'Title':['count']}).reset_index()\nageCalcCount.columns = ['Sex','Classe','nb']\nageCalc = ageCalc.merge(ageCalcCount,on=['Sex','Classe'])\nageCalc","0880f153":"ageRand = pd.DataFrame(columns=['Sex','Classe','Age'])\nfor i in [ (row.Sex,row.Classe,np.random.randint(round(row.borneMin),round(row.borneMax),size=row.nb)) \n     for indx, row in ageCalc.iterrows()]:\n    calc = pd.DataFrame(columns=['Sex','Classe','Age'])\n    calc.Age    = i[2]\n    calc.Sex    = i[0]\n    calc.Classe = i[1]\n    ageRand = pd.concat([ageRand,calc])","e0377e10":"for sex in ageRand.Sex.unique():\n    for classe in ageRand.Classe.unique():\n            donnees['Age'][ donnees.Age.isna()&\n                             (donnees.Sex == sex)&\n                             (donnees.Classe == classe)] = ageRand[\n                                                       (ageRand.Sex == sex)&\n                                                       (ageRand.Classe == classe)].Age\ndonnees.Age = donnees.Age.astype('int8') \ndonnees['Age01'] = donnees.Age.values\ndonnees.Age = donnees.AgeOld","455e6f60":"donnees.Age01.isna().sum()","1869dd6b":"plt.figure(figsize=(24,16))\nplt.title('La distribution des \u00e2ges avant et apr\u00e8s la pr\u00e9diction',size=32)\nsns.distplot(donnees[ ~donnees.AgeOld.isna()].Age ,color='blue', label=\"Age initial\");\nsns.distplot(donnees.Age01 ,color='red', label=\"Age calcul\u00e9 Sex et Classe\");\nplt.legend();","66a0f172":"donnees.Age = donnees.Age01.values\ndonnees.drop(columns=['AgeOld','Age01'],inplace=True)","571a22f0":"donnees.head()","9e26f9fd":"listeVariblesInitiales = donnees.drop(columns=['Name']).columns\ndonnees = donnees.set_index('PassengerId').sort_index()","8466641e":"donnees['TitreFamille'] = donnees.apply(lambda ligne : 'Homme' if ligne['Title'] == 'Mr'\n                                                               else 'Femme' if ligne['Sex'] == 'Femme'\n                                                               else 'Gar\u00e7on' if ligne['Title'] == 'Master'\n                                                               else 'Homme' , axis=1)\nplt.figure(figsize=(14,12))\nplt.title('La distribution du titre calcul\u00e9 pour le groupe famille',size=20)\nsns.countplot(x='TitreFamille',hue='Survived',data=donnees);","d8eacd31":"donnees['GroupFamille'] = donnees.Name+'-'+\\\n                          donnees.Classe.apply(lambda x: '%1d' % x)+'-'+\\\n                          donnees.Fare.apply(lambda x: '%.3f' % x)+'-'+\\\n                          donnees.Port+'-'+donnees.TicketNum\ndonnees.GroupFamille.unique()[:6]","0d74bdfa":"listeGF = (donnees.groupby('GroupFamille').size()).reset_index()\nlisteGF.columns=['GroupFamille','Composants']\nplt.figure(figsize=(14,8))\nplt.title('La fr\u00e9quence des individus dans le groupe famille',size=20)\nsns.countplot(x='Composants',data=listeGF[listeGF.Composants > 1]);","164f259e":"donnees['GroupTicket'] = donnees.Classe.apply(lambda x: '%1d' % x)+'-'+\\\n                         donnees.Fare.apply(lambda x: '%.3f' % x)+'-'+\\\n                         donnees.Port+'-'+donnees.TicketNum\ndonnees.GroupTicket.unique()[:6]","caad4bb9":"listeGT = (donnees.groupby('GroupTicket').size()).reset_index()\nlisteGT.columns=['GroupTicket','Composants']\nplt.figure(figsize=(14,8))\nplt.title('La fr\u00e9quence des individus dans le groupe ticket',size=20)\nsns.countplot(x='Composants',data=listeGT[listeGT.Composants > 1]);\nsns.countplot(x='Composants',data=listeGF[listeGF.Composants > 1]);","06c671a0":"donnees.rename(columns={\"GroupTicket\": \"GrFemmeEnfGouv\"},inplace=True)\ndonnees.GrFemmeEnfGouv = donnees.apply(lambda ligne : \n                           'Pas' if (ligne['TitreFamille'] == 'Homme') \n                                 else ligne['GrFemmeEnfGouv'] , axis=1) \ndonnees.GrFemmeEnfGouv.unique()[:6]","18b6dbbd":"listeGFEG = (donnees.groupby('GrFemmeEnfGouv').size()).reset_index()\nlisteGFEG.columns=['GrFemmeEnfGouv','Composants']\nplt.figure(figsize=(14,8))\nplt.title('La fr\u00e9quence des individus dans le groupe Femme Enfants Gouvernante',size=20)\nsns.countplot(x='Composants',data=listeGT[listeGT.Composants > 1]);\nsns.countplot(x='Composants',data=listeGF[listeGF.Composants > 1]);\nsns.countplot(x='Composants',data=listeGFEG[listeGFEG.Composants > 1]);","6099d05d":"donnees.drop(columns=['Name','TitreFamille','GroupFamille'], inplace=True)\nlisteVariblesAvecGroups = donnees.columns","bf59381b":"def conversionVariableCategorielle(donnees,variable):\n    valeurs = list(donnees[variable].sort_values().unique())\n    dicoVar = {nom:indx for indx,nom in enumerate(valeurs)}\n    dicoVarRev = {indx:nom for indx,nom in enumerate(valeurs)}\n    \n    donnees[variable] = donnees[variable].apply(lambda x : dicoVar[x])\n    return dicoVar,dicoVarRev\n\nfor col in donnees.dtypes[donnees.dtypes == 'object'].reset_index()['index']:\n    _,_ = conversionVariableCategorielle(donnees,col)\n\ndonnees.head(10)","cde8b51a":"apprentissage = donnees[~donnees.Survived.isnull()]\napprentissage.Survived = apprentissage.Survived.astype('int8')\nX = apprentissage.drop(columns='Survived')\ny = apprentissage.Survived\n\napprentissage.head()","dec1b083":"test = donnees[donnees.Survived.isnull()]\ntest.reset_index().head()","d8247812":"from sklearn.model_selection import train_test_split\nX = apprentissage.drop(columns='Survived')\ny = apprentissage.Survived\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n         test_size=0.112, stratify = y, random_state = 101)\n\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)\n\nplt.figure(figsize=(10,6))\nplt.hist(y_train,label='apprentissage');\nplt.hist(y_test,label='validation');\nplt.legend();","37573fa8":"resultats = comparaisonsClassifieurs(classifieursArbresDict, X_train, X_test, y_train, y_test)","051980bc":"resultats","f5e7f1a5":"#from sklearn.model_selection import ShuffleSplit,GridSearchCV\n#from sklearn.metrics import make_scorer,recall_score\n#\n#nom = 'CatBoost'\n#\n#cv_sets = ShuffleSplit(random_state=101)\n#\n#param_grid = {\n#          'depth':[3,1,2,6,4,5,7,8,9,10],\n#          'iterations':[250,100,500,1000],\n#          'learning_rate':[0.03,0.001,0.01,0.1,0.2,0.3], \n#          'l2_leaf_reg':[3,1,5,10,100],\n#          'border_count':[32,5,10,20,50,100,200],\n#          'ctr_border_count':[50,5,10,20,100,200],\n#          'thread_count':4\n#      }\n#\n#\n#scoring = make_scorer(f1_score)\n#\n#classifieur = CatBoostClassifier(silent=True)\n#\n#gridCV = GridSearchCV(estimator=classifieur,\n#                      param_grid=param_grid,\n#                      scoring=scoring, \n#                      cv=cv_sets, \n#                      refit='AUC', \n#                      return_train_score=True)\n#\n#gridCV.fit(X,y)\n#\n#print(\"Les param\u00e8tres optimaux %s avec un score de %.8f\" % (gridCV.best_params_, gridCV.best_score_))\n#classifieur = gridCV.best_estimator_","01d91b1e":"classifieur = CatBoostClassifier(iterations=250, depth=3, silent=True)","2260a6d5":"resultats = controleClassifieur(classifieur, X_train, X_test, y_train, y_test)","4cad2475":"resultats","6090410a":"sns.set(font_scale=4)\nafficheImportanceVariables(classifieur, X)\nsns.set(font_scale=2)","a4c847e7":"resultatsFinaux,classifieursCV = effectueValidationCroisee(classifieur, \n                              X, \n                              y, \n                              n_splits = 15)","9c6df5ae":"resultatsFinaux.describe()","34f1e2c6":"output = pd.DataFrame({'PassengerId':test.index, 'Survived':np.zeros(test.shape[0])})\n\nfor i in range(len(classifieursCV)):\n    output.Survived += classifieursCV[i].predict_proba(test)[:,1]\n\noutput.Survived \/= len(classifieursCV)\noutput.Survived  = output.Survived.round().astype('int8')\n\noutput.head()","1d3edb75":"output.to_csv('submission008.csv',index=False)","5f16e6bd":"![](http:\/\/www.dba-expert.fr\/images\/media_documents\/kaggle\/titanic.jpg)","46f33539":"# La recherche des voyageurs en groupe","fa76a701":"# La s\u00e9paration des jeux des donn\u00e9es","c63d71ee":"# L'estimation des \u00e2ges manquants \u00e0 l'aide de attributs Sex et Classe","a2f0f4c2":"# La validation crois\u00e9e","35c2dbcb":"# La lecture des donn\u00e9es d\u2019entrainement et des donn\u00e9es de test","a184a7cf":"# Le traitement des enregistrements avec Age non renseign\u00e9","ca4e6cdd":"# Le traitement du prix non renseign\u00e9","9f08c25b":"# La conversion des variables cat\u00e9gorielles","687bd12c":"# Le choix du classifieur","8e2287c6":"# L'optimisation du classifieur\n\n## Voici un exemple d'optimisation mais attention avec tous les param\u00e8tres vous pouvez avoir pour plusieurs heures de traitement.\n\n"}}