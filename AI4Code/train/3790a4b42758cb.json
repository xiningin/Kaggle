{"cell_type":{"8a761563":"code","3d51ed03":"code","a602ee6e":"code","278027b4":"code","c20be282":"code","b1c31b9f":"code","be906715":"code","b6ffc525":"code","afc66f75":"code","351eff40":"code","af82c9d6":"code","2ebbc79a":"code","55ef27a6":"markdown","e30e42c7":"markdown","b2b8d3b9":"markdown","8905b733":"markdown","11ea6768":"markdown"},"source":{"8a761563":"import pandas as pd \nimport numpy as np \nimport torch \nimport torch.nn as nn \nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt \nfrom torchvision import transforms, models \nimport pickle, os, time, json \nfrom tqdm import tqdm \nfrom glob import glob \nfrom PIL import Image \nimport cv2 \nfrom typing import List, Union, Dict, Any\nfrom statistics import mean \nfrom sklearn.metrics import f1_score\n\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nprint(device)\ntorch.manual_seed(0)\nnp.random.seed(0)","3d51ed03":"def get_file(is_train=True):\n    files = []\n    if is_train:\n        for f in glob(\"..\/input\/cat-and-dog\/training_set\/training_set\/dogs\/*.jpg\"):\n            files.append(f)\n    else:\n        for f in glob(\"..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/*.jpg\")[:200]:\n            files.append(f)\n        for f in glob(\"..\/input\/cat-and-dog\/test_set\/test_set\/cats\/*.jpg\")[:200]:\n            files.append(f)\n    return files \n\ntrain_file = get_file()\nval_file = get_file(False)\nlen_abnorm = 200","a602ee6e":"plt.figure(figsize=(12, 12))\nplt.subplot(1, 2, 1)\ndog = Image.open(train_file[100]).resize((224, 224))\nplt.imshow(dog)\nplt.title(\"normal\", color=\"g\")\nplt.xticks([])\nplt.yticks([])\n\nplt.subplot(1, 2, 2)\ncat = Image.open(val_file[-10]).resize((224, 224))\nplt.imshow(cat)\nplt.title(\"abnormal\", color=\"r\")\nplt.xticks([])\nplt.yticks([])\n\nplt.subplots_adjust(wspace=0, hspace=0)","278027b4":"class MyDataSet():\n    def __init__(self, img_file: List[str], is_train=True, resize=224, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n        self.trans1 = transforms.Compose([\n            transforms.Resize((resize, resize)),\n            transforms.ToTensor(),\n            transforms.RandomErasing(p=1.0, scale=(0.3, 0.6), ratio=(0.5, 2.0), value=\"random\"), \n            transforms.Normalize(mean, std)\n        ])\n        self.trans2 = transforms.Compose([\n            transforms.Resize((resize, resize)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean, std)\n        ])\n        self.is_train = is_train \n        self.img_file = img_file \n        \n    def __getitem__(self, idx):\n        if self.is_train:\n            # train dataset -> only dog image\n            f1 = self.img_file[idx]\n            f2 = self.img_file[np.random.randint(len(self.img_file))]\n            f3 = self.img_file[np.random.randint(len(self.img_file))]\n            f1 = Image.open(f1)\n            f2 = Image.open(f2)\n            f3 = Image.open(f3)\n            if np.random.random() > 0.5:\n                trans1 = self.trans1\n                trans2 = self.trans1\n                trans3 = self.trans2\n            else:\n                trans1 = self.trans2\n                trans2 = self.trans2\n                trans3 = self.trans1\n            return trans1(f1), trans2(f2), trans3(f3) # (anchor == positive) != negative\n        else:\n            # val dataset -> dog and cat image \n            f = self.img_file[idx]\n            f = Image.open(f)\n            trans = self.trans2\n            return trans(f)\n        \n    def __len__(self):\n        return len(self.img_file)\n    \ntrain_ds = MyDataSet(train_file)\nval_ds = MyDataSet(val_file, False)\n        ","c20be282":"plt.figure(figsize=(12, 12))\nplt.subplot(1, 3, 1)\nplt.imshow(train_ds.__getitem__(0)[0].permute(1, 2, 0))\nplt.title(\"Anchor\", color=\"g\")\nplt.xticks([])\nplt.yticks([])\n\nplt.subplot(1, 3, 2)\nplt.imshow(train_ds.__getitem__(0)[1].permute(1, 2, 0))\nplt.title(\"Positive\", color=\"g\")\nplt.xticks([])\nplt.yticks([])\n\nplt.subplot(1, 3, 3)\nplt.imshow(train_ds.__getitem__(0)[2].permute(1, 2, 0))\nplt.title(\"Negative\", color=\"r\")\nplt.xticks([])\nplt.yticks([])\n\nplt.subplots_adjust(wspace=0, hspace=0)","b1c31b9f":"train_dl = DataLoader(train_ds, batch_size=16, shuffle=True)\nval_dl = DataLoader(val_ds, batch_size=1, shuffle=False)","be906715":"class Net(nn.Module):\n    def __init__(self, tag_size=8):\n        super(Net, self).__init__()\n        self.base = models.resnet50(pretrained=True)\n        for w in self.base.parameters():\n            w.requires_grad = False \n        self.fc = nn.Linear(1000, 8)\n        \n    def forward(self, x):\n        return self.fc(self.base(x)) # (batch, 8)\n    \nnet = Net()\n        ","b6ffc525":"def trainer(img1, img2, img3, net, criterion, optimizer):\n    loss = criterion(net(img1), net(img2), net(img3))\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    return loss.item()\n\ndef show_loss(loss):\n    plt.figure(figsize=(14, 5))\n    plt.plot(np.arange(len(loss)).tolist(), loss)\n    plt.xlabel(\"Loss\")\n    plt.ylabel(\"Epoch\")\n    plt.grid()\n    plt.show()\n    \ndef save(model, e):\n    torch.save(model.state_dict(), f\"net{str(e)}.pth\")\n    print(\"sucessfully saving model\")\n    \ndef train(train_dl, net, num_epoch, lr):\n    criterion = nn.TripletMarginLoss(margin=10.0)\n    optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n    net.to(device)\n    net.train()\n    total_loss = []\n    for e in range(num_epoch):\n        loss_iter = []\n        for x1, x2, x3 in tqdm(train_dl):\n            x1 = x1.to(device)\n            x2 = x2.to(device)            \n            x3 = x3.to(device)\n            \n            loss = trainer(x1, x2, x3, net, criterion, optimizer)\n            loss_iter.append(loss)\n        total_loss.append(mean(loss_iter))\n    try:\n        show_loss(total_loss)\n        save(net, num_epoch)\n    finally:\n        return net ","afc66f75":"trained_net = train(train_dl, net, 3, 5e-3)","351eff40":"def evaluate(val_dl, net):\n    with torch.no_grad():\n        pred = []\n        net.eval()\n        net.to(device)\n        for x in val_dl:\n            x = x.to(device)\n            out = net(x)\n            out = out[0].detach().cpu().numpy().tolist()\n            pred.append(out)\n    return pred  # (batch, 8)\n    \ndef shows(val_dl, net, len_abnorm):\n    pred = evaluate(val_dl, net)\n    pred = np.array(pred)\n    # (normal)val_dl[:200] dog ||  (Abnormal) val_dl[200:] cat \n    color = [\"red\"] * len_abnorm + [\"blue\"] * len_abnorm\n    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n    ax = axes.ravel()\n    ax[0].scatter(x=pred[:, 0], y=pred[:, 1], c=color, alpha=0.5)\n    ax[1].scatter(x=pred[:, 2], y=pred[:, 3], c=color, alpha=0.5)\n    ax[2].scatter(x=pred[:, 4], y=pred[:, 5], c=color, alpha=0.5)\n    ax[3].scatter(x=pred[:, 6], y=pred[:, 7], c=color, alpha=0.5)\n    plt.show()\n    \n    save_th(pred[:len_abnorm, :])\n\ndef load_net():\n    net = Net()\n    net.load_state_dict(torch.load(\"net3.pth\", map_location={\"cuda:0\": \"cpu\"}))\n    net.eval()\n    return net\n\n\ndef save_th(pred):\n    mu = np.mean(pred, axis=0).astype(float).tolist() # (8, )\n    std = np.std(pred, axis=0).astype(float).tolist() # (8, )\n    result = {\n        \"mu\": mu, \n        \"std\": std\n    }\n    with open(\"normal.json\", \"w\") as f:\n        json.dump(result, f)\n    print(\"sucessfully saving json!\")\n    \n\nnet = load_net()\nshows(val_dl, net, len_abnorm)\n","af82c9d6":"def load_th(sigma, filename=\"normal.json\"):\n    with open(filename, \"r\") as f:\n        w = json.load(f)\n    f.close()\n    mu = np.array(w[\"mu\"])\n    std = np.array(w[\"std\"])\n    wmin, wmax = mu-std*sigma, mu+std*sigma \n    return wmin, wmax \n\ndef is_abnorm(wmin, wmax, pred):\n    for m, ma, p in zip(wmin, wmax, pred):\n        if m > p or ma < p:\n            return 1 # abnorm predict == cat\n        else:\n            return 0 # normal predict == dog\n\ndef search_for_threshold(val_dl):\n    net = load_net()\n    correct = np.concatenate([np.zeros(200), np.ones(200)])\n    dict_results = []\n    \n    for sigma in [1.0, 2.0, 3.0]:\n        wmin, wmax = load_th(sigma)\n        preds = evaluate(val_dl, net)\n        results = []\n        dict_result = {}\n        \n        for pred in preds:\n            results.append(is_abnorm(wmin, wmax, pred))\n        f1 = f1_score(correct, results)\n        dict_result[\"threshold\"] = sigma \n        dict_result[\"f1_score\"] = f1 \n        dict_results.append(dict_result)\n    return dict_results\nsearch_for_threshold(val_dl)","2ebbc79a":"resize = 224\nmean = (0.485, 0.456, 0.406) \nstd = (0.229, 0.224, 0.225)\ntrans = transforms.Compose([\n        transforms.Resize((resize, resize)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n])\n\ndef inference():\n    net = load_net()\n    wmin, wmax = load_th(1.0)\n    fig, axes = plt.subplots(4, 4, figsize=(20, 20))\n    ax = axes.ravel()\n    for i in range(8):\n        dog = val_file[i]\n        dog_img = Image.open(dog)\n        out = net(trans(dog_img).unsqueeze(0))\n        out = out[0].detach().cpu().numpy().tolist()\n        pred = is_abnorm(wmin, wmax, out)\n        ax[i].imshow(dog_img.resize((224, 224)))\n        ax[i].set_title(\n            \"norm\" if pred == 0 else \"Abnorm\", \n            c = \"g\" if pred == 0 else \"r\")\n        ax[i].set_xticks([])\n        ax[i].set_yticks([])\n        if i == 0:\n            ax[i].set_ylabel(\"Dog\", c=\"g\")\n    for i in range(8):\n        cat = val_file[-(i+1)]\n        cat_img = Image.open(cat)\n        out = net(trans(cat_img).unsqueeze(0))\n        out = out[0].detach().cpu().numpy().tolist()\n        pred = is_abnorm(wmin, wmax, out)\n        ax[i+8].imshow(cat_img.resize((224, 224)))\n        ax[i+8].set_title(\n            \"norm\" if pred == 0 else \"Abnorm\", \n            c = \"g\" if pred == 0 else \"r\")\n        ax[i+8].set_xticks([])\n        ax[i+8].set_yticks([])\n        if i == 0:\n            ax[i+8].set_ylabel(\"Cat\", c=\"r\")\n        \ninference()","55ef27a6":"## train\n---","e30e42c7":"## Visualization of spatial vector\n---","b2b8d3b9":"## Search for the optimal threshold\n---","8905b733":"## preprocessing\n---","11ea6768":"## Inference result\n---"}}