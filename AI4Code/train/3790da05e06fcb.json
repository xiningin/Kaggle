{"cell_type":{"2977816b":"code","1fd901dd":"code","98876e81":"code","d287be3c":"code","9d23c909":"code","7132bcff":"code","4f22be33":"code","9cc057a6":"code","e0f99d1d":"code","e0c7f173":"code","2d6c5f29":"code","e4b15c80":"code","6d5cc256":"code","e0e7fc81":"code","e9d09883":"code","c21f7f14":"code","287775ee":"code","a0b80c9a":"code","e79076e5":"code","6c40f807":"code","8d3edcd8":"code","54f5e8f9":"code","0450e9a6":"code","55f0373f":"code","4b938caa":"code","d6601f4d":"code","8072cbaf":"code","a4a128ab":"code","5a9b950c":"code","12f2929b":"code","355ac3e9":"code","3a4e7679":"code","fb48ad9e":"code","5444fce8":"code","8277b6dc":"code","a29d8877":"code","a00ddaca":"code","9795df5c":"code","6d33914d":"code","0b4adbda":"code","4c4a83b0":"code","c864174d":"code","207c6136":"code","db026d38":"code","1d5cd925":"code","12bdd7c4":"code","cf6d817e":"code","53bd1dcd":"code","9c269db8":"code","eba26f4e":"code","5e997ae8":"code","87770aa5":"code","9cc2f2b3":"code","f3a32ebc":"code","3369b4b4":"code","29b65328":"code","e5985c94":"code","2f289970":"code","6b04e49f":"code","3195500d":"code","de968b8e":"code","2dfebabc":"code","eafbe654":"code","ef92453d":"code","3e6c5606":"code","34721bbf":"code","9fce0408":"code","23278c21":"code","d400ae64":"code","84220af0":"code","ec1e32f6":"code","554d4444":"code","68a70707":"code","d9c24cfc":"code","8cae859d":"code","dbd19746":"markdown","84d97ea4":"markdown","bce22621":"markdown","b70ac61a":"markdown","ac9103cf":"markdown","56316b36":"markdown","e6771ae8":"markdown","84bd02c2":"markdown","f6c4c8dd":"markdown","ed7b18b8":"markdown","b206a54c":"markdown","b9613954":"markdown","94fadefe":"markdown","aa122efa":"markdown","0ef03730":"markdown","73a6d358":"markdown","5ede40a0":"markdown","f4e3d769":"markdown","36c1f0d8":"markdown","e3b0c414":"markdown","ae733c51":"markdown","3a568a4c":"markdown","fd791afe":"markdown","9cc8b0eb":"markdown"},"source":{"2977816b":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\nimport time\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nimport imageio\nfrom IPython.display import Image\nimport matplotlib.image as mpimg\nfrom skimage.transform import resize\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\nimport zipfile\nfrom io import BytesIO\nfrom nibabel import FileHolder\nfrom nibabel.analyze import AnalyzeImage\nimport PIL\nfrom IPython import display\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\nLSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape, Conv2DTranspose, LeakyReLU,\\\nConvLSTM2D,Conv3D\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.datasets import mnist\nimport keras\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","1fd901dd":"First_Year_Microwave = \"..\/input\/cosmic-microwave-background-nasa\/Cosmic Microwave Background\/Wmap.mp4\"\nThird_Year_Microwave = \"..\/input\/cosmic-microwave-background-nasa\/Cosmic Microwave Background\/wmap_third_year.mp4\"\nFifth_Year_Microwave = \"..\/input\/cosmic-microwave-background-nasa\/Cosmic Microwave Background\/wmap_fifth_year.mp4\"\n\nMicrowave_List = [First_Year_Microwave,Third_Year_Microwave,Fifth_Year_Microwave]","98876e81":"Microwave_IMG_List = []\n\nfor file_path in Microwave_List:\n    Microwave_Video = file_path\n    \n    Video_Caption = cv2.VideoCapture(Microwave_Video)\n    \n    while Video_Caption.isOpened():\n        \n        _,frame = Video_Caption.read()\n        \n        if _ != True:\n            break\n            \n        if Video_Caption.isOpened():\n            Transformation_IMG = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n            Resize_IMG = cv2.resize(Transformation_IMG,(180,180))\n            Microwave_IMG_List.append(Resize_IMG)\n\n    Video_Caption.release()","d287be3c":"print(Microwave_IMG_List[0].shape)","9d23c909":"print(len(Microwave_IMG_List))","7132bcff":"print(\"TOTAL SHAPE: \", str(len(Microwave_IMG_List)) + \" \" + str(Microwave_IMG_List[0].shape))","4f22be33":"print(np.shape(np.array(Microwave_IMG_List)))","9cc057a6":"figure,axis = plt.subplots(5,5,figsize=(10,10))\n\nfor indexing,operations in enumerate(axis.flat):\n    \n    Picking_Image = Microwave_IMG_List[indexing]\n    \n    operations.set_xlabel(Picking_Image.shape)\n    operations.set_ylabel(Picking_Image.size)\n    operations.imshow(Picking_Image)\n    \nplt.tight_layout()\nplt.show()","e0f99d1d":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Microwave_IMG_List[22]\n\nplt.xlabel(Picking_Image.shape)\nplt.imshow(Picking_Image)","e0c7f173":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Microwave_IMG_List[2000]\n\nplt.xlabel(Picking_Image.shape)\nplt.imshow(Picking_Image)","2d6c5f29":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Microwave_IMG_List[1000]\n\nplt.xlabel(Picking_Image.shape)\nplt.imshow(Picking_Image)","e4b15c80":"figure,axis = plt.subplots(1,3,figsize=(10,10))\n\nPicking_Image_One = Microwave_IMG_List[22][:,:,0]\nPicking_Image_Two = Microwave_IMG_List[2000][:,:,0]\nPicking_Image_Three = Microwave_IMG_List[1000][:,:,0]\n\naxis[0].imshow(Picking_Image_One)\naxis[1].imshow(Picking_Image_Two)\naxis[2].imshow(Picking_Image_Three)","6d5cc256":"figure,axis = plt.subplots(1,3,figsize=(10,10))\n\nPicking_Image_One = Microwave_IMG_List[22][:,:,1]\nPicking_Image_Two = Microwave_IMG_List[2000][:,:,1]\nPicking_Image_Three = Microwave_IMG_List[1000][:,:,1]\n\naxis[0].imshow(Picking_Image_One)\naxis[1].imshow(Picking_Image_Two)\naxis[2].imshow(Picking_Image_Three)","e0e7fc81":"figure,axis = plt.subplots(1,3,figsize=(10,10))\n\nPicking_Image_One = Microwave_IMG_List[22][:,:,2]\nPicking_Image_Two = Microwave_IMG_List[2000][:,:,2]\nPicking_Image_Three = Microwave_IMG_List[1000][:,:,2]\n\naxis[0].imshow(Picking_Image_One)\naxis[1].imshow(Picking_Image_Two)\naxis[2].imshow(Picking_Image_Three)","e9d09883":"figure,axis = plt.subplots(1,3,figsize=(10,10))\n\nPicking_Image_One = Microwave_IMG_List[22]\nPicking_Image_Two = Microwave_IMG_List[2000]\nPicking_Image_Three = Microwave_IMG_List[1000]\n\naxis[0].imshow(Picking_Image_One,cmap=\"hot\")\naxis[1].imshow(Picking_Image_Two,cmap=\"hot\")\naxis[2].imshow(Picking_Image_Three,cmap=\"hot\")","c21f7f14":"figure,axis = plt.subplots(1,3,figsize=(10,10))\n\nPicking_Image_One = Microwave_IMG_List[22][:,:,0]\nPicking_Image_Two = Microwave_IMG_List[2000][:,:,0]\nPicking_Image_Three = Microwave_IMG_List[1000][:,:,0]\n\naxis[0].imshow(Picking_Image_One,cmap=\"hot\")\naxis[1].imshow(Picking_Image_Two,cmap=\"hot\")\naxis[2].imshow(Picking_Image_Three,cmap=\"hot\")","287775ee":"figure,axis = plt.subplots(1,3,figsize=(10,10))\n\nPicking_Image_One = Microwave_IMG_List[22][:,:,0]\nPicking_Image_Two = Microwave_IMG_List[2000][:,:,0]\nPicking_Image_Three = Microwave_IMG_List[1000][:,:,0]\n\naxis[0].imshow(Picking_Image_One).set_cmap('nipy_spectral')\naxis[1].imshow(Picking_Image_Two).set_cmap('nipy_spectral')\naxis[2].imshow(Picking_Image_Three).set_cmap('nipy_spectral')","a0b80c9a":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Microwave_IMG_List[22]\n\nPlot_1 = plt.imshow(Picking_Image[:,:,0]).set_cmap('nipy_spectral')\nplt.colorbar()","e79076e5":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Microwave_IMG_List[22][:,:,0]\n\nplt.hist(Picking_Image.ravel(), bins=180, range=(0.0, 10), fc='k', ec='k')\nplt.show()","6c40f807":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Microwave_IMG_List[22]\n\nplt.imshow(Picking_Image[:,:,0],clim=(1,20)).set_cmap('nipy_spectral')","8d3edcd8":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Microwave_IMG_List[22]\n\nplt.imshow(Picking_Image[:,:,0],interpolation=\"bicubic\").set_cmap('nipy_spectral')","54f5e8f9":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Microwave_IMG_List[22][:,:,0]\n\nplt.contour(Picking_Image, [50, 200])","0450e9a6":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Microwave_IMG_List[22]\n\nBright_IMG = Picking_Image + (np.ones(Picking_Image.shape) - Picking_Image) * 10\n\nplt.axis(\"off\")\nplt.imshow(Bright_IMG)","55f0373f":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Microwave_IMG_List[22]\n\nBright_IMG = Picking_Image + (np.ones(Picking_Image.shape) - Picking_Image) * 0.10\n\nplt.axis(\"off\")\nplt.imshow(Bright_IMG)","4b938caa":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Microwave_IMG_List[22]\n\nDark_IMG = Picking_Image * (9 - 5)\n\nplt.axis(\"off\")\nplt.imshow(Dark_IMG)","d6601f4d":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Microwave_IMG_List[22][:,:,0]\n\nSpes_Color_IMG = np.dstack((Picking_Image*0.1, Picking_Image*1, Picking_Image*0.5))\n\nplt.axis(\"off\")\nplt.imshow(Spes_Color_IMG)","8072cbaf":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Microwave_IMG_List[22]\n\ncolors = (\"red\", \"green\", \"blue\")\nchannel_dim = (0, 1, 2)\n\nplt.xlim([0, 256])\nplt.ylim([0, 1000])\n\nfor channel_id, c in zip(channel_dim, colors):\n    histogram, bin_edges = np.histogram(\n        Picking_Image[:, :, channel_id], bins=256, range=(0, 256)\n    )\n    plt.plot(bin_edges[0:-1], histogram, color=c)\n\nplt.xlabel(\"Color value\")\nplt.ylabel(\"Pixels\")\n\nplt.show()","a4a128ab":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Microwave_IMG_List[202]\n\ncolors = (\"red\", \"green\", \"blue\")\nchannel_dim = (0, 1, 2)\n\nplt.xlim([0, 256])\nplt.ylim([0, 1000])\n\nfor channel_id, c in zip(channel_dim, colors):\n    histogram, bin_edges = np.histogram(\n        Picking_Image[:, :, channel_id], bins=256, range=(0, 256)\n    )\n    plt.plot(bin_edges[0:-1], histogram, color=c)\n\nplt.xlabel(\"Color value\")\nplt.ylabel(\"Pixels\")\n\nplt.show()","5a9b950c":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Microwave_IMG_List[2000]\n\ncolors = (\"red\", \"green\", \"blue\")\nchannel_dim = (0, 1, 2)\n\nplt.xlim([0, 256])\nplt.ylim([0, 1000])\n\nfor channel_id, c in zip(channel_dim, colors):\n    histogram, bin_edges = np.histogram(\n        Picking_Image[:, :, channel_id], bins=256, range=(0, 256)\n    )\n    plt.plot(bin_edges[0:-1], histogram, color=c)\n\nplt.xlabel(\"Color value\")\nplt.ylabel(\"Pixels\")\n\nplt.show()","12f2929b":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Microwave_IMG_List[1300]\n\ncolors = (\"red\", \"green\", \"blue\")\nchannel_dim = (0, 1, 2)\n\nplt.xlim([0, 256])\nplt.ylim([0, 1000])\n\nfor channel_id, c in zip(channel_dim, colors):\n    histogram, bin_edges = np.histogram(\n        Picking_Image[:, :, channel_id], bins=256, range=(0, 256)\n    )\n    plt.plot(bin_edges[0:-1], histogram, color=c)\n\nplt.xlabel(\"Color value\")\nplt.ylabel(\"Pixels\")\n\nplt.show()","355ac3e9":"iterations = 60\nvector_noise_shape = 180\ncount_example = 20\nbatch_size = 6\ncount_buffer = 60000","3a4e7679":"seed = tf.random.normal([count_example, vector_noise_shape])","fb48ad9e":"Video_IMG_List = []\n\nVideo_Cap = cv2.VideoCapture(Third_Year_Microwave)\n\n\nwhile Video_Cap.isOpened():\n\n    \n    ret,frame = Video_Cap.read()\n    \n    if ret != True:\n        break\n        \n    if Video_Cap.isOpened():\n        Transformation_IMG = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n        Resize_IMG = cv2.resize(Transformation_IMG,(180,180))\n        Video_IMG_List.append(Resize_IMG)\n        \n        \nVideo_Cap.release()","5444fce8":"X_Train = np.array(Video_IMG_List)","8277b6dc":"X_Train = X_Train \/ 255.0\nprint(X_Train.shape)","a29d8877":"Train_Data = tf.data.Dataset.from_tensor_slices(X_Train).shuffle(count_buffer).batch(batch_size)","a00ddaca":"print(Train_Data.element_spec)","9795df5c":"def Generator_Model():\n    \n    \n    Model = Sequential()\n    #\n    Model.add(Dense(90*90*128,use_bias=False,input_shape=(180,)))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    #\n    Model.add(Reshape((90,90,128)))\n    #\n    Model.add(Conv2DTranspose(128,(3,3),padding=\"same\",use_bias=False))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    \n    Model.add(Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', use_bias=False))\n    Model.add(BatchNormalization())\n    Model.add(LeakyReLU())\n    #\n    Model.add(Conv2DTranspose(3,(3,3),padding=\"same\",use_bias=False,activation=\"tanh\"))\n    \n    \n    return Model","6d33914d":"Generator = Generator_Model()","0b4adbda":"print(Generator.summary())","4c4a83b0":"def Discriminator_Model():\n    \n    Model = Sequential()\n    \n    Model.add(Conv2D(64,(3,3),padding=\"same\",input_shape=[180,180,3]))\n    Model.add(Dropout(0.2))\n    Model.add(LeakyReLU())\n    \n    \n    Model.add(Conv2D(128,(3,3),padding=\"same\"))\n    Model.add(Dropout(0.2))\n    Model.add(LeakyReLU())\n    \n    Model.add(layers.Flatten())\n    Model.add(layers.Dense(1))\n    \n    return Model","c864174d":"Discriminator = Discriminator_Model()","207c6136":"print(Discriminator.summary())","db026d38":"Loss_Function = tf.keras.losses.BinaryCrossentropy(from_logits=True)","1d5cd925":"def Discriminator_Loss(real_out,fake_out):\n    \n    real_loss_function = Loss_Function(tf.ones_like(real_out),real_out)\n    fake_loss_function = Loss_Function(tf.zeros_like(fake_out),fake_out)\n    total_loss = real_loss_function + fake_loss_function\n    \n    return total_loss","12bdd7c4":"def Generator_Loss(fake_output):\n    \n    return Loss_Function(tf.ones_like(fake_output),fake_output)","cf6d817e":"Generator_Optimizer = RMSprop(lr=0.0003,clipvalue=1.0,decay=1e-8)\nDiscriminator_Optimizer = RMSprop(lr=0.0003,clipvalue=1.0,decay=1e-8)","53bd1dcd":"def generate_and_save_images(model, epoch, test_input):\n    \n    predictions = model(test_input, training=False)\n    fig = plt.figure(figsize=(11, 11))\n    \n    for i in range(predictions.shape[0]):\n        plt.subplot(6, 6, i+1)\n        plt.imshow(predictions[i, :, :, 0], cmap='gray')\n        plt.axis('off')\n\n    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n    plt.show()","9c269db8":"def Train_Step(images):\n    \n    random_noise_vector = tf.random.normal([batch_size,vector_noise_shape])\n    \n    with tf.GradientTape() as Generator_Tape, tf.GradientTape() as Discriminator_Tape:\n        \n        Generator_Fake_Image = Generator(random_noise_vector,training=False)\n        \n        real_output = Discriminator(images,training=True)\n        fake_output = Discriminator(Generator_Fake_Image,training=True)\n        \n        Generator_Loss_Output = Generator_Loss(fake_output)\n        Discriminator_Loss_Output = Discriminator_Loss(real_output,fake_output)\n        \n    Generator_Gradients = Generator_Tape.gradient(Generator_Loss_Output,Generator.trainable_variables)\n    Discriminator_Gradients = Discriminator_Tape.gradient(Discriminator_Loss_Output,Discriminator.trainable_variables)\n    \n    Generator_Optimizer.apply_gradients(zip(Generator_Gradients,Generator.trainable_variables))\n    Discriminator_Optimizer.apply_gradients(zip(Discriminator_Gradients,Discriminator.trainable_variables))","eba26f4e":"def Training(dataset,iterations):\n    \n    for epoch in range(iterations):\n        start = time.time()\n        \n        for image_batch in dataset:\n            Train_Step(image_batch)\n            \n        display.clear_output(wait=True)\n        generate_and_save_images(Generator,epoch+1,seed)\n    \n    display.clear_output(wait=True)\n    generate_and_save_images(Generator,epoch,seed)  ","5e997ae8":"Training(Train_Data,iterations)","87770aa5":"Predict_Noise = tf.random.normal(shape=[50,vector_noise_shape])","9cc2f2b3":"Generator_Predict = Generator(Predict_Noise)","f3a32ebc":"figure, axes = plt.subplots(nrows=7,ncols=7,figsize=(10,10))\n\nfor i,ax in enumerate(axes.flat):\n    IMG_Prediction_Output = Generator_Predict[i]\n    ax.imshow(IMG_Prediction_Output)\n    ax.set_xlabel(Generator_Predict[i].shape)\nplt.tight_layout()\nplt.show()","3369b4b4":"figure, axes = plt.subplots(nrows=3,ncols=3,figsize=(10,10))\n\nfor i,ax in enumerate(axes.flat):\n    IMG_Prediction_Output = Generator_Predict[i]\n    ax.imshow(IMG_Prediction_Output)\n    ax.set_xlabel(Generator_Predict[i].shape)\nplt.tight_layout()\nplt.show()","29b65328":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[25])\nplt.show()","e5985c94":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[10])\nplt.show()","2f289970":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[1])\nplt.show()","6b04e49f":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[49])\nplt.show()","3195500d":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[45])\nplt.show()","de968b8e":"figure = plt.figure(figsize=(8,8))\nplt.axis(\"off\")\nplt.imshow(Generator_Predict[33])\nplt.show()","2dfebabc":"figure = plt.figure(figsize=(10,10))\n\nRandom_Pre_Image = Generator_Predict[22]\n\nplt.imshow(Random_Pre_Image[:,:,0],interpolation=\"bicubic\").set_cmap('nipy_spectral')","eafbe654":"figure, axes = plt.subplots(nrows=3,ncols=3,figsize=(10,10))\n\nfor i,ax in enumerate(axes.flat):\n    IMG_Prediction_Output = Generator_Predict[i][:,:,0]\n    ax.imshow(IMG_Prediction_Output,interpolation=\"bicubic\").set_cmap('nipy_spectral')\n    ax.set_xlabel(Generator_Predict[i].shape)\nplt.tight_layout()\nplt.show()","ef92453d":"figure = plt.figure(figsize=(10,10))\n\nRandom_Pre_Image = Generator_Predict[42]\n\nplt.imshow(Random_Pre_Image[:,:,0],interpolation=\"bicubic\").set_cmap('hot')","3e6c5606":"figure, axes = plt.subplots(nrows=3,ncols=3,figsize=(10,10))\n\nfor i,ax in enumerate(axes.flat):\n    IMG_Prediction_Output = Generator_Predict[i][:,:,0]\n    ax.imshow(IMG_Prediction_Output).set_cmap('hot')\n    ax.set_xlabel(Generator_Predict[i].shape)\nplt.tight_layout()\nplt.show()","34721bbf":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Generator_Predict[1] * 255\n\ncolors = (\"red\", \"green\", \"blue\")\nchannel_dim = (0, 1, 2)\n\nplt.xlim([0, 256])\nplt.ylim([0, 1000])\n\nfor channel_id, c in zip(channel_dim, colors):\n    histogram, bin_edges = np.histogram(\n        Picking_Image[:, :, channel_id], bins=256, range=(0, 256)\n    )\n    plt.plot(bin_edges[0:-1], histogram, color=c)\n\nplt.xlabel(\"Color value\")\nplt.ylabel(\"Pixels\")\n\nplt.show()","9fce0408":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Generator_Predict[12] * 255\n\ncolors = (\"red\", \"green\", \"blue\")\nchannel_dim = (0, 1, 2)\n\nplt.xlim([0, 256])\nplt.ylim([0, 1000])\n\nfor channel_id, c in zip(channel_dim, colors):\n    histogram, bin_edges = np.histogram(\n        Picking_Image[:, :, channel_id], bins=256, range=(0, 256)\n    )\n    plt.plot(bin_edges[0:-1], histogram, color=c)\n\nplt.xlabel(\"Color value\")\nplt.ylabel(\"Pixels\")\n\nplt.show()","23278c21":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Generator_Predict[22] * 255\n\ncolors = (\"red\", \"green\", \"blue\")\nchannel_dim = (0, 1, 2)\n\nplt.xlim([0, 256])\nplt.ylim([0, 1000])\n\nfor channel_id, c in zip(channel_dim, colors):\n    histogram, bin_edges = np.histogram(\n        Picking_Image[:, :, channel_id], bins=256, range=(0, 256)\n    )\n    plt.plot(bin_edges[0:-1], histogram, color=c)\n\nplt.xlabel(\"Color value\")\nplt.ylabel(\"Pixels\")\n\nplt.show()","d400ae64":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Generator_Predict[32] * 255\n\ncolors = (\"red\", \"green\", \"blue\")\nchannel_dim = (0, 1, 2)\n\nplt.xlim([0, 256])\nplt.ylim([0, 1000])\n\nfor channel_id, c in zip(channel_dim, colors):\n    histogram, bin_edges = np.histogram(\n        Picking_Image[:, :, channel_id], bins=256, range=(0, 256)\n    )\n    plt.plot(bin_edges[0:-1], histogram, color=c)\n\nplt.xlabel(\"Color value\")\nplt.ylabel(\"Pixels\")\n\nplt.show()","84220af0":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Generator_Predict[42] * 255\n\ncolors = (\"red\", \"green\", \"blue\")\nchannel_dim = (0, 1, 2)\n\nplt.xlim([0, 256])\nplt.ylim([0, 1000])\n\nfor channel_id, c in zip(channel_dim, colors):\n    histogram, bin_edges = np.histogram(\n        Picking_Image[:, :, channel_id], bins=256, range=(0, 256)\n    )\n    plt.plot(bin_edges[0:-1], histogram, color=c)\n\nplt.xlabel(\"Color value\")\nplt.ylabel(\"Pixels\")\n\nplt.show()","ec1e32f6":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Generator_Predict[49] * 255\n\ncolors = (\"red\", \"green\", \"blue\")\nchannel_dim = (0, 1, 2)\n\nplt.xlim([0, 256])\nplt.ylim([0, 1000])\n\nfor channel_id, c in zip(channel_dim, colors):\n    histogram, bin_edges = np.histogram(\n        Picking_Image[:, :, channel_id], bins=256, range=(0, 256)\n    )\n    plt.plot(bin_edges[0:-1], histogram, color=c)\n\nplt.xlabel(\"Color value\")\nplt.ylabel(\"Pixels\")\n\nplt.show()","554d4444":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Video_IMG_List[12]\n\ncolors = (\"red\", \"green\", \"blue\")\nchannel_dim = (0, 1, 2)\n\nplt.xlim([0, 256])\nplt.ylim([0, 1000])\n\nfor channel_id, c in zip(channel_dim, colors):\n    histogram, bin_edges = np.histogram(\n        Picking_Image[:, :, channel_id], bins=256, range=(0, 256)\n    )\n    plt.plot(bin_edges[0:-1], histogram, color=c)\n\nplt.xlabel(\"Color value\")\nplt.ylabel(\"Pixels\")\n\nplt.show()","68a70707":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Video_IMG_List[20]\n\ncolors = (\"red\", \"green\", \"blue\")\nchannel_dim = (0, 1, 2)\n\nplt.xlim([0, 256])\nplt.ylim([0, 1000])\n\nfor channel_id, c in zip(channel_dim, colors):\n    histogram, bin_edges = np.histogram(\n        Picking_Image[:, :, channel_id], bins=256, range=(0, 256)\n    )\n    plt.plot(bin_edges[0:-1], histogram, color=c)\n\nplt.xlabel(\"Color value\")\nplt.ylabel(\"Pixels\")\n\nplt.show()","d9c24cfc":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Video_IMG_List[300]\n\ncolors = (\"red\", \"green\", \"blue\")\nchannel_dim = (0, 1, 2)\n\nplt.xlim([0, 256])\nplt.ylim([0, 1000])\n\nfor channel_id, c in zip(channel_dim, colors):\n    histogram, bin_edges = np.histogram(\n        Picking_Image[:, :, channel_id], bins=256, range=(0, 256)\n    )\n    plt.plot(bin_edges[0:-1], histogram, color=c)\n\nplt.xlabel(\"Color value\")\nplt.ylabel(\"Pixels\")\n\nplt.show()","8cae859d":"figure = plt.figure(figsize=(10,10))\n\nPicking_Image = Video_IMG_List[800]\n\ncolors = (\"red\", \"green\", \"blue\")\nchannel_dim = (0, 1, 2)\n\nplt.xlim([0, 256])\nplt.ylim([0, 1000])\n\nfor channel_id, c in zip(channel_dim, colors):\n    histogram, bin_edges = np.histogram(\n        Picking_Image[:, :, channel_id], bins=256, range=(0, 256)\n    )\n    plt.plot(bin_edges[0:-1], histogram, color=c)\n\nplt.xlabel(\"Color value\")\nplt.ylabel(\"Pixels\")\n\nplt.show()","dbd19746":"#### OPTIMIZERS","84d97ea4":"#### WHAT IS DOPPLER?\n\n* The Doppler effect for electromagnetic waves such as light is of great use in astronomy and results in either a so-called redshift or blueshift. It has been used to measure the speed at which stars and galaxies are approaching or receding from us; that is, their radial velocities. This may be used to detect if an apparently single star is, in reality, a close binary, to measure the rotational speed of stars and galaxies, or to detect exoplanets. This redshift and blueshift happens on a very small scale. If an object was moving toward earth, there would not be a noticeable difference in visible light, to the unaided eye.\n\n* Note that redshift is also used to measure the expansion of space, but that this is not truly a Doppler effect. Rather, redshifting due to the expansion of space is known as cosmological redshift, which can be derived purely from the Robertson-Walker metric under the formalism of General Relativity. Having said this, it also happens that there are detectable Doppler effects on cosmological scales, which, if incorrectly interpreted as cosmological in origin, lead to the observation of redshift-space distortions.\n\n* The use of the Doppler effect for light in astronomy depends on our knowledge that the spectra of stars are not homogeneous. They exhibit absorption lines at well defined frequencies that are correlated with the energies required to excite electrons in various elements from one level to another. The Doppler effect is recognizable in the fact that the absorption lines are not always at the frequencies that are obtained from the spectrum of a stationary light source. Since blue light has a higher frequency than red light, the spectral lines of an approaching astronomical light source exhibit a blueshift and those of a receding astronomical light source exhibit a redshift.","bce22621":"# PREDICTION RESULT","b70ac61a":"#### DISCRIMINATOR MDDEL","ac9103cf":"#### GENERATING AND SAVING IMAGE","56316b36":"#### TRANSFORMATION","e6771ae8":"# VISION","84bd02c2":"# DATA PROCESS","f6c4c8dd":"# PACKAGES AND LIBRARIES","ed7b18b8":"![](https:\/\/scx2.b-cdn.net\/gfx\/news\/2016\/rotationaldo.jpg)","b206a54c":"# DETAILED REVIEW","b9613954":"#### SPECIAL FORMATS","94fadefe":"#### LOSS FUNCTIONS","aa122efa":"#### PARAMETERS","0ef03730":"#### DCGAN OUTPUT","73a6d358":"#### GENERATOR MDDEL","5ede40a0":"# HISTORY\n\n#### Cosmic Microwave Background \/ NASA\n\n* Temperature fluctuations displayed here are 13.7 billion years old, from the time when the Big Bang was thought to have occurred. Essentially, it is a detailed, all-sky display of the young universe developed from three years of WMAP data. The blue areas are cooler while the red areas are warmer. The temperature range on this map is \u00b1 200 microKelvin, which is incredibly small. The temperature range is so small because it doesn\u2019t measure absolute temperature but anisotropy. Anisotropy is the difference between two measurements taken in opposite directions. This is much more accurate than simply measuring the absolute temperature in one direction. This data is used to support the Big Bang theory using inflation. The concept is that the universe expanded many trillion times its size in less than a trillionth of a second at the beginning of the Big Bang. This is a map of the remnant heat left from the big bang. According to NASA, the measurements reveal size, matter content, age, geometry, and the fate of the universe.\n\nThere are 3 videos showing 3 different time zones.\n\n* First Year\n* Third Year\n* Fifth Year\n","f4e3d769":"#### ORIGINAL OUTPUT","36c1f0d8":"#### TRANSFORMATION","e3b0c414":"#### MAIN PATH","ae733c51":"# DATA EXPORT AND TRANSFORMATION","3a568a4c":"#### GENERAL","fd791afe":"# TRAIN PROCESS","9cc8b0eb":"#### TRAINING STEP"}}