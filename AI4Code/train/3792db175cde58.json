{"cell_type":{"49753f2d":"code","5083d0a1":"code","a9e04320":"code","fb457592":"code","4bd90c7b":"code","efb20b0e":"code","2f0f9394":"code","e78448b1":"code","2209aacc":"code","e9615c59":"code","7ee2caff":"code","ba7313f1":"code","39f26294":"code","4cea17bb":"code","879b4074":"code","bedf90ac":"code","503e5a04":"code","53dbeb59":"code","17fb1256":"code","ebbb0101":"code","155871f0":"code","c95827ee":"code","22ea0f3e":"code","8eb90b4f":"code","cb3b16b8":"code","cccf14b6":"code","ee099d6c":"markdown","b6476c15":"markdown","cffb2198":"markdown","81da44b9":"markdown","d49dda8b":"markdown","161a3921":"markdown","f6dc86e7":"markdown","c807deb0":"markdown","e5abb0af":"markdown","cd5d2764":"markdown","0a83c58f":"markdown","dfe51515":"markdown","ff20ebc3":"markdown","fbbdbe99":"markdown","6118d371":"markdown"},"source":{"49753f2d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport seaborn as sns\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.utils.np_utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.preprocessing import image\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nimport pickle\n\nfrom tensorflow.keras.optimizers import RMSprop\nfrom keras import regularizers\nfrom tensorflow.keras import Model\nimport tensorflow as tf \n\nfrom tensorflow.keras import optimizers\n\nimport itertools\n\nimport tensorflow as tf ","5083d0a1":"base_skin_dir = os.path.join('..', 'input\/skin-cancer-mnist-ham10000')\n\nimageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n                     for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}\n\nlesion_type_dict = {\n    'nv': 'Melanocytic nevi',\n    'mel': 'Melanoma',\n    'bkl': 'Benign keratosis-like lesions ',\n    'bcc': 'Basal cell carcinoma',\n    'akiec': 'Actinic keratoses',\n    'vasc': 'Vascular lesions',\n    'df': 'Dermatofibroma'\n}\n\nsex_dict_enc = {\n    'female' : 0,\n    'male' : 1\n}\nloca_dict_enc = {\n'scalp' : 0 , 'ear' : 1, 'face' : 2, 'back' : 3, 'trunk' : 4, 'chest' : 5,\n       'upper extremity' : 6, 'abdomen' : 7, 'unknown' : 8, 'lower extremity' : 9,\n       'genital' : 10, 'neck' : 11, 'hand' : 12, 'foot' : 13, 'acral' :  14}","a9e04320":"metadata = pd.read_csv(os.path.join(base_skin_dir, 'HAM10000_metadata.csv'))\nmetadata['path'] = metadata['image_id'].map(imageid_path_dict.get)\nmetadata['sex'] = metadata['sex'].map(sex_dict_enc.get)\nmetadata['localization'] = metadata['localization'].map(loca_dict_enc.get)\n\nmetadata = metadata[['path', 'dx', 'sex', 'age', 'localization']]\n\nmetadata.head()","fb457592":"metadata.isnull().sum()","4bd90c7b":"metadata['age'].fillna((metadata['age'].mean()), inplace=True)\nmetadata['sex'].fillna(metadata['sex'].value_counts().index[0], inplace=True)\nmetadata.isnull().sum()","efb20b0e":"dxList = metadata.dx.unique()\ndxDict = {}\n\nfor i in dxList:\n    dxDict[i]= pd.DataFrame(metadata[metadata.dx == i])\n    \ndxDataTrain = pd.DataFrame(columns=metadata.keys())\ndxDataTest = pd.DataFrame(columns=metadata.keys())\ndxDataValid = pd.DataFrame(columns=metadata.keys())\n\nfor i in dxDict.keys():\n    \n    x_train, x_test = train_test_split(dxDict[i], test_size=0.17,random_state=1)\n    \n    print(i, len(x_train))\n    x_train, x_valid = train_test_split(x_train, test_size = 0.2, random_state = 1)\n   \n    print(len(x_train), len(x_valid), len(x_test))\n   \n    dxDataTrain = pd.concat([dxDataTrain, x_train],axis=0).sample(frac=1).reset_index(drop=True)\n    dxDataValid = pd.concat([dxDataValid, x_valid],axis=0).sample(frac=1).reset_index(drop=True)\n    dxDataTest = pd.concat([dxDataTest, x_test],axis=0).sample(frac=1).reset_index(drop=True)\n    \nprint(len(dxDataTrain), len(dxDataValid), len(dxDataTest))\n","2f0f9394":"dataGen = ImageDataGenerator(rescale=1.\/255, \n                             samplewise_center=True, \n                             samplewise_std_normalization=True, \n                             zoom_range = 0.1, \n                             width_shift_range=0.1, \n                             height_shift_range=0.1, \n                             horizontal_flip=True, \n                             vertical_flip=True) \nbatch_size=64\n    \ntrainDataGen = dataGen.flow_from_dataframe(dxDataTrain, x_col='path', y_col='dx', batch_size=batch_size ,target_size=(200, 200))\nvalidDataGen = dataGen.flow_from_dataframe(dxDataValid, x_col='path', y_col='dx', batch_size=batch_size ,target_size=(200, 200))\ntestDataGen = dataGen.flow_from_dataframe(dxDataTest, x_col='path', y_col='dx', batch_size=batch_size ,target_size=(200, 200))\n","e78448b1":"input_shape = (200, 200, 3)\nnum_classes = 7\npreInceptionV3 = tf.keras.applications.InceptionV3(\n    input_shape=input_shape, include_top=False, weights='imagenet')\n\n# preMobileNetV2.summary()","2209aacc":"def createModel(premodel):\n    \n    for layer in premodel.layers:\n        layer.trainable = True\n    last_layer = premodel.get_layer('mixed0')\n    \n    last_output = premodel.output \n    \n    x = layers.Flatten()(last_output)\n    x = layers.Dense(16, kernel_regularizer=regularizers.l1(0.0001), activation='relu')(x)\n    x = layers.Dropout(0.2)(x) \n    x = layers.Dense(32, kernel_regularizer=regularizers.l2(0.001), activation='relu')(x)\n    x = layers.Dropout(0.3)(x)\n    x = layers.Dense  (7, activation='softmax')(x)           \n\n    model = Model(premodel.input, x) \n\n    opt = optimizers.Adam(lr=0.01)\n    model.compile(loss = \"categorical_crossentropy\", optimizer = opt, \n                  metrics = ['accuracy'])\n    \n    return model","e9615c59":"from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\n# Create a callback that saves the model's weights  ..\/input\/\ncp_path = \"bestcp.ckpt\"\ncp_dir = os.path.dirname(cp_path)\ncp_cb = ModelCheckpoint(filepath=cp_path,\n                        save_weights_only=False, \n                        save_best_only=True, \n                        verbose=1)\n\n# Adjcp_cbust learning rate based on number of GPUs (naive approach).\nrlr_cb = ReduceLROnPlateau(monitor=\"val_accuracy\",\n                           factor=0.5,\n                           patience=3,\n                           verbose=1,\n                           min_lr=0.001)\n\nes_cb = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# cp_cb, rlr_cb, es_cb","7ee2caff":"model = createModel(preInceptionV3)","ba7313f1":"epochs = 30\nclass_weights={\n    0: 1.0, # akiec\n    1: 1.0, # bcc\n    2: 1.0, # bkl\n    3: 1.0, # df\n    4: 3.0, # mel # Try to make the model more sensitive to Melanoma.\n    5: 0.5, # nv\n    6: 1.0, }# vasc \n    \nhistory = model.fit_generator(\n    trainDataGen,\n    class_weight=class_weights,\n    steps_per_epoch=len(trainDataGen),\n    epochs=epochs,\n    validation_data=validDataGen,\n    validation_steps=len(validDataGen), \n    callbacks=[cp_cb,  es_cb, rlr_cb] )","39f26294":"# Get the labels that are associated with each index\nprint(trainDataGen.class_indices)\n# get the metric names so we can use evaulate_generator\nmodel.metrics_names","4cea17bb":"loss, accuracy = model.evaluate_generator(testDataGen, steps=len(testDataGen), verbose=1)\nloss_v, accuracy_v = model.evaluate_generator(validDataGen, steps=len(validDataGen), verbose=1)\nprint(\"Validation: accuracy = %f  ;  loss_v = %f\" % (accuracy_v, loss_v))\nprint(\"Test: accuracy = %f  ;  loss = %f\" % (accuracy, loss))\nmodel.save(\"model.h5\")\n\nprint(\"Saved model to disk\")","879b4074":"# Here the best epoch will be used.\n\n# model.load_weights(cp_path)\nbestModel = tf.keras.models.load_model(cp_path)\n\nloss, accuracy = bestModel.evaluate_generator(testDataGen, steps=len(testDataGen), verbose=1)\nloss_v, accuracy_v = bestModel.evaluate_generator(validDataGen, steps=len(validDataGen), verbose=1)\nprint(\"Validation: accuracy = %f  ;  loss_v = %f\" % (accuracy_v, loss_v))\nprint(\"Test: accuracy = %f  ;  loss = %f\" % (accuracy, loss))\n# model.save(\"model.h5\")\n\nprint(\"Saved model to disk\")","bedf90ac":"# Get the labels of the test images.\ntest_labels = testDataGen.classes","503e5a04":"predictions = model.predict_generator(testDataGen, steps=len(testDataGen), verbose=1)\nbestPredictions = bestModel.predict_generator(testDataGen, steps=len(testDataGen), verbose=1)","53dbeb59":"# Source: Scikit Learn website\n# http:\/\/scikit-learn.org\/stable\/auto_examples\/\n# model_selection\/plot_confusion_matrix.html\n#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n\n\ndef plotConfusionMatrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","17fb1256":"from sklearn.metrics import confusion_matrix \n# argmax returns the index of the max value in a row\ncm = confusion_matrix(test_labels, predictions.argmax(axis=1))\nbestCm = confusion_matrix(test_labels, bestPredictions.argmax(axis=1))","ebbb0101":"# Define the labels of the class indices. These need to match the \n# order shown above.\nplotConfusionMatrix(cm, dxDict.keys(), title='Confusion Matrix')","155871f0":"plotConfusionMatrix(bestCm, dxDict.keys(), title='bestConfusion Matrix')","c95827ee":"# Get the index of the class with the highest probability score\ny_pred = np.argmax(predictions, axis=1)\n\nbestY_pred = np.argmax(bestPredictions, axis=1)\n\n# Get the labels of the test images.\ny_true = testDataGen.classes","22ea0f3e":"from sklearn.metrics import classification_report\n\n# Generate a classification report\nreport = classification_report(y_true, y_pred, target_names=dxDict.keys())\nbestReport = classification_report(y_true, bestY_pred, target_names=dxDict.keys())\nprint(report, bestReport)","8eb90b4f":"#1. Function to plot model's validation loss and validation accuracy\ndef plotModelHistory(model_history):\n    fig, axs = plt.subplots(1,2,figsize=(15,5))\n    # summarize history for accuracy\n    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])\n    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])\/10)\n    axs[0].legend(['train', 'val'], loc='best')\n    # summarize history for loss\n    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])\/10)\n    axs[1].legend(['train', 'val'], loc='best')\n    plt.show()\n    \nplotModelHistory(history)","cb3b16b8":"t_img = image.load_img(dxDataTrain['path'].iloc[0], target_size=(200, 200))\nt_img = image.img_to_array(t_img)\nt_img = np.expand_dims(t_img, axis=0)                          ","cccf14b6":"classes = model.predict(t_img)\nclasses","ee099d6c":"# Prepare model\n## Import pre-trained model","b6476c15":"## best trained model from callback check point","cffb2198":"# Import needed packages","81da44b9":"# Fetch needed data","d49dda8b":"# Make prediction from poth models","161a3921":"# Prepare data generator for data augmentation","f6dc86e7":"## Model Building ","c807deb0":"make the image path dictionary by joining the folder path from base directory `base_skin_dir` and merge the images in jpg format from both the folders `HAM10000_images_part1.zip` and `HAM10000_images_part2.zip`","e5abb0af":"Fill the null values by their mean.","cd5d2764":"# Train Model","0a83c58f":"## Prepare callback functions\n* save model checkpoint\n* reduce learning rate\n* stop training ","dfe51515":"# Model Evaluation\n## Last trained model","ff20ebc3":"# Read and prepare data","fbbdbe99":"## Cleaning Data !!\nfirst thing showing if there is a `null` data.","6118d371":"# Split data depend on dx type"}}