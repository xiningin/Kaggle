{"cell_type":{"593d8a19":"code","9e62ee59":"code","bf8d7381":"code","69c81b44":"code","460c9814":"code","a5e69155":"code","4c48368a":"code","1f3f0f33":"code","684eb95b":"code","5c430c17":"code","b9d032db":"code","6a18e97a":"markdown","78d5d125":"markdown","275beffc":"markdown","23ce5c9f":"markdown","063bcc75":"markdown","1ffb6ce2":"markdown","bfb4506a":"markdown","bde9c0ec":"markdown","d966906c":"markdown","11799568":"markdown","b05ef3bd":"markdown","614bf680":"markdown"},"source":{"593d8a19":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9e62ee59":"dset=pd.read_csv('\/kaggle\/input\/gufhtugu-publications-dataset-challenge\/GP Orders - 4.csv');dset\n","bf8d7381":"#column name rewrite for avoid erorrs\ncolumns = dset.columns.str.replace(' ','_').str.lower()\ncolumns = columns.str.replace('[(,)]', '')\ndset.columns = columns\nprint(dset.columns)","69c81b44":"dset.head()\nprint(dset.shape)\ndset.info()","460c9814":"#check if any entity in cloumns is null\nprint(dset.isnull().sum())\n#if any entry is  null replace it by most occuring entry\ndset.book_name=dset.book_name.fillna(dset.book_name.mode()[0])\ndset.city_billing=dset.city_billing.fillna(dset.city_billing.mode()[0])\nprint(\"\\n*-----------------after removing null values------------*\\n\")\nprint(dset.isnull().sum())","a5e69155":"#print Book Names seprated by \"\/\"\ndset.book_name = dset.book_name.str.split('\/')\nprint(dset.book_name)\n\ndset['order_date'] = pd.to_datetime(dset['order_date'])\nprint(dset.head())","4c48368a":"#HISTOGRAM\nord_sts=dset.order_status.unique()\nprint(ord_sts)\nprint(\"\\n *-----------Histogram of ORDER STATUS-----------------*\")\nplt.style.use('ggplot')\nplt.title('Order STATUS')\nplt.xlabel('STATUS')\nplt.ylabel('No Of Orders')\nplt.hist(dset.order_status)\nplt.show()\n","1f3f0f33":"# Retrieve Total List of years \nyears = dset['order_date'].dt.strftime(\"%Y\").unique().tolist()\nprint(years)","684eb95b":"# reterive order status in 2019\nsts_19 = dset[dset['order_date'].dt.strftime(\"%Y\") == \"2019\"].order_status\n# reterive order status in 2020\nsts_20 = dset[dset['order_date'].dt.strftime(\"%Y\") == \"2020\"].order_status\n# reterive order status in 2021\nsts_21 = dset[dset['order_date'].dt.strftime(\"%Y\") == \"2021\"].order_status\n# graph size\nplt.figure(figsize=(20,8))\n#histogram for 2019\nplt.subplot(1,3,1)\nplt.title('Order Status in 2019')\nplt.xlabel('Order status')\nplt.ylabel('Total no of orders')\nplt.hist(sts_19)\n\n#histogram for 2020\nplt.subplot(1,3,2)\nplt.title('Order Status in 2020')\nplt.xlabel('Order status')\nplt.ylabel('Total no of orders')\nplt.hist(sts_20)\n\n#histogram for 2021\nplt.subplot(1,3,3)\nplt.title('Order Status in 2021')\nplt.xlabel('Order status')\nplt.ylabel('Total no of orders')\nplt.hist(sts_21)","5c430c17":"#use split method(\/) for seprating books\nbook_data = dset.book_name.apply(lambda x: str(x).split('\/'))\n# Storing the list of lists book names in a list 'books' \nbooks = [item for sublist in book_data for item in sublist]\n# making an new data set for ease\ndset1 = pd.DataFrame(data = books, columns = ['NoOfSoldBooks'])\n# Only storing the top 10 most selling books of all times and converting the result into a datafram\nbook_chart = dset1.NoOfSoldBooks.value_counts().nlargest(15).to_frame()\n# Printing the most sold book name and its number of times it was sold\nprint(book_chart.head(1))\nprint()\n# plotting 10 top selling books of all time\npx.bar(book_chart, y = book_chart.NoOfSoldBooks, x = book_chart.index, title = 'Best Selling Books')","b9d032db":"#books sells in top most 8 cities\nmost_cities = dset['city_billing'].value_counts()\nmost_cities = most_cities.iloc[:8]\n#pi-chart of top  most cities where books sold\nmost_cities.plot(kind='pie',figsize=(8,8),autopct='%1.1f%%')\n","6a18e97a":"**1. ORDER STATUS FREQUENCY**","78d5d125":"# Reterieved total no of rows and colums\n","275beffc":"# Data Exploratory Analysis","23ce5c9f":"**2. Best Selling Books**","063bcc75":"> IMPORTING DATASET","1ffb6ce2":"**IMPORTING LIBRARIES**","bfb4506a":"#  EXPLORING DATA (CHECKING NULL VALUES)","bde9c0ec":"ORDER STATUS PER YEAR  ","d966906c":"# If you like my work please UPVOTE it\n# **\u0641\u064a \u0623\u0645\u0627\u0646 \u0627\u0644\u0644\u0647**","11799568":"#  City Billing in MOST CITES","b05ef3bd":"# Checking Null Values & Fixing","614bf680":"Total List of years"}}