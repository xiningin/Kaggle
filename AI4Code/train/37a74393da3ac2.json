{"cell_type":{"61247933":"code","bfa8f95c":"code","742ec7e1":"code","4e9dd6df":"code","25ec6462":"code","aefa7049":"code","0a698c1a":"code","ef821430":"markdown","d2a5c0d7":"markdown","df610afb":"markdown","cdb91fd8":"markdown","482e4464":"markdown","a3957232":"markdown","79fac78d":"markdown","75341b77":"markdown"},"source":{"61247933":"import numpy as np\nimport pandas as pd","bfa8f95c":"thermometer_A = pd.read_csv('..\/input\/pandas-example\/thermometer_A.csv')\nthermometer_B = pd.read_csv('..\/input\/pandas-example\/thermometer_B.csv')\nprint('Columns of A: ', list(thermometer_A.columns))\nprint('Columns of B: ', list(thermometer_B.columns))\n\nrename_A = {'temperature_Celsius': 'Temperature (\u00baC)'}\nthermometer_A = thermometer_A.rename(columns=rename_A)\nrename_B = {'temp_in_Cels': 'Temperature (\u00baC)'}\nthermometer_B = thermometer_B.rename(columns=rename_B)\n\nprint()\nprint('Updated columns of A: ', list(thermometer_A.columns))\nprint('Updated columns of B: ', list(thermometer_B.columns))","742ec7e1":"thermometer_A['Equipment'] = 'A'\nthermometer_B['Equipment'] = 'B'\n\ntemperature_measures = pd.concat([thermometer_A, thermometer_B], axis=0, ignore_index=True)","4e9dd6df":"print(temperature_measures.groupby('Time (h)').mean())\nprint(temperature_measures.groupby('Time (h)').std())","25ec6462":"plants_data = pd.read_csv('..\/input\/pandas-example\/fertiliser_plant_growth.csv')\nprint('Columns: ', list(plants_data.columns))\nplants_data['Time-points'] = plants_data[['Baseline', 'Follow-up']].apply(lambda x: '-'.join(x.map(str)), axis=1)\nprint(plants_data)","aefa7049":"mask_control = plants_data['Group'] == 'Control'\nprint(plants_data[mask_control])","0a698c1a":"mask_second_follow_up = (plants_data['Follow-up'] == 2)\nprint(plants_data[mask_second_follow_up])\nprint(plants_data[mask_second_follow_up & mask_control])","ef821430":"# <a name=\"rename_columns\">1. Renaming columns with `.rename()`<\/a>\n\nImagine having a set of CSV files from two thermometers measuring the temperature inside the lab throughout the day. After importing both files as pandas DataFrames, thermometer A has two columns, named `time` and `temperature_Celsius`, while thermometer B also has two columns but entitled `time` and `temp_in_Cels`. In the code-cell below, we are creating the DataFrames with different column names\n\nSince we know both `temperature_Celsius` and `temp_in_Cels` represent the same quantity (temperature in degrees Celsius), it would be very convenient to rename them similarly.\n\nThis can be achieved with the `rename()` DataFrame function. We only have to pass a dictionary with the key-value of the change we want to do, where **keys** represent **current names** and the **values** are the **updated descriptions**.","d2a5c0d7":"If you prefer writing the masks directly inside the `[]` instead of creating a mask variable, make sure to wrap each one around `()` to avoid errors in the logical operations.\n\n# Conclusion\n\nIn conclusion, `pandas` is a powerful package that can massively improve your workflows. Furthermore, it can be seamlessly integrated with other packages to create publication-ready figure panels (more on that later) with little effort.\n\nIf you would like to learn more about using pandas, I highly recommend [Chapter 3](https:\/\/jakevdp.github.io\/PythonDataScienceHandbook\/03.00-introduction-to-pandas.html) of the [Python Data Science Handbook](https:\/\/jakevdp.github.io\/PythonDataScienceHandbook\/) by Jake VanderPlas. The book covers all the basics with clear explanations and introduces some advanced techniques to best leverage this package in your work.\n\nHappy coding!","df610afb":"In the example above, we renamed the columns of the DataFrames, but the same function can be used to rename the index of the DataFrame (passing the dictionary to `index=` instead of `columns=` in the function call).\n\n# <a name=\"merge_dataframes\">2. Merging DataFrames with `.concat()`<\/a>\n\nHaving renamed our column names, we now want to combine the DataFrames in one, containing all data from both thermometers. This is especially useful if we need to create categorical plots that highlight differences between devices.\n\nFirst, we should create new columns on each DataFrame that uniquely describe the device. In this simple example, a column `Equipment` should suffice, where we fill all rows (representing different time-points) with the value `A` and `B`, respectively, for each equipment. This way, when we merge both datasets, we can still identify from which device the data came from.\n\nThen, we can create our main DataFrame `temperature_measures`, with properly initialised columns.","cdb91fd8":"# <a name=\"new_columns\">4. Creating new columns based on existing columns with `.apply()`<\/a>\n\nLet's consider another example where we measure the growth rate of groups of plants over four weeks, comparing two groups given new fertilisers and a control group that only received water.\n\nThe dataset contains two columns `Baseline` and `Follow-up` representing the start and endpoint for the corresponding measurement. It could be useful for plotting purposes to have a descriptor that directly indicates the interval between measurements rather than just the start or end time-point.\n\nTherefore, we can use the `.apply()` function to create a `lambda` function that operates on the provided columns.","482e4464":"Here, we pass `axis=0` so that the DataFrames are combined vertically, in long-form, and `ignore_index=True` because, in this example, the row number is not meaningful and can be reset after concatenating the data.\n\nOther pandas functions could also serve the same purpose (ex: `append()`). Depending on your problem, they may be more suitable.\n\n# <a name=\"groupby_data\">3. Grouping data based on a given column with `.groupby()`<\/a>\n\nLet's assume we just want to get an average of the temperature measurements, regardless of the equipment. We can use the `.groupby()` function and pass the column's name that should be used to group the data. Then, we can call further functions depending on the information we aim to compute such as `.mean()`, `.std()` (standard deviation).","a3957232":"# Hello!\n\nThis post will highlight five operations with `pandas DataFrames` that may come very handy while exploring and preparing a dataset before carrying a data analysis:\n\n[1. Renaming columns with `.rename()`](#rename_columns)\n\n[2. Merging DataFrames with `.concat()`](#merge_dataframes)\n\n[3. Grouping data based on a given column with `.groupby()`](#groupby_data)\n\n[4. Creating new columns based on existing columns with `.apply()`](#new_columns)\n\n[5. Sub-selecting DataFrame rows based on binary masks](#masking_df)\n\n# What is pandas?\n\nPandas is a Python package that provides a comprehensive set of tools to deal with tabular data. For more details on this package's development, feel free to check the [pandas website](https:\/\/pandas.pydata.org\/about\/).\n\nI see it as Microsoft Excel in Python and, as I learn new tricks and best practices, it has become my go-to software for any data analysis I do in my work. Hence, I will now go through five operations that I find especially useful for cleaning and organising data.","79fac78d":"For each row in the DataFrame (as we set `axis=1`), we take the values of the columns `Baseline` and `Follow-up`, convert them to `string` and join them with the marker `-`. Again, this function offers a lot more flexibility that can be tuned to your specific use-case.\n\n# <a name=\"masking_df\">5. Sub-selecting DataFrame rows based on binary masks<\/a>\n\nFinally, another useful technique is to mask a DataFrame based on the values of the columns. Let's assume we want to compute some parameters for each group of plants.\n\nWe can create a mask based on the `Group` column's values and identify the corresponding rows of the complete DataFrame. Then, we simply pass the mask in `[]` on the DataFrame, and the correct rows will be indexed.","75341b77":"This operation also supports multiple masks simultaneously by chaining them with `&` inside the `[]`."}}