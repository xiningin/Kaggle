{"cell_type":{"67ea1d6d":"code","4f346a6d":"code","3b216648":"code","602e9873":"code","4d776e12":"code","9ffe87ff":"code","123ca2d0":"code","11520bb3":"code","0d1ef629":"code","987ef8a3":"code","48fedcd7":"code","276e0409":"code","8891cdcc":"code","b855b314":"code","b0c612aa":"code","19ad049c":"code","3c00bb28":"code","03af43ea":"code","fa21f8f6":"markdown","9a62c475":"markdown"},"source":{"67ea1d6d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n        \nfrom matplotlib import pyplot as plt\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nfrom sklearn.ensemble import IsolationForest\n\nfrom sklearn.decomposition import FactorAnalysis\nfrom sklearn import preprocessing\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4f346a6d":"train = pd.read_csv(\"..\/input\/netflix-appetency\/train.csv\")\ntest = pd.read_csv(\"..\/input\/netflix-appetency\/test.csv\")\n","3b216648":"train[['feature_307','target']]","602e9873":"date_cols = ['feature_191','feature_191','feature_192','feature_199','feature_200','feature_201']\ntrain = train.drop(columns=date_cols)","4d776e12":"fig, ax = plt.subplots(figsize=(10,5))\nsns.countplot(train.target)\nplt.show()\n","9ffe87ff":"null_cols = pd.DataFrame(train.isnull().sum(axis=0)\/train.shape[0],columns=[\"col_null_ratio\"])\nnull_cols = null_cols[null_cols['col_null_ratio']>0.3].sort_values('col_null_ratio',ascending=False).reset_index().rename(columns={\"index\":\"col_null_name\"})\ncol_to_delete = list(null_cols['col_null_name'].values)\n\ntrain = train.drop(columns=col_to_delete)\nnumeric_cols = train.select_dtypes(['int','float'])\ncategorical_cols=train.select_dtypes(['object']).join(train['target'])","123ca2d0":"unique = numeric_cols.nunique()\nunique_value_feature = list(unique[unique==1].index)\ncol_to_delete += unique_value_feature","11520bb3":"unique = categorical_cols.nunique()\nunique_value_feature = list(unique[unique==1].index)\ncol_to_delete += unique_value_feature","0d1ef629":"numeric_cols_no_null = numeric_cols.fillna(0.0)","987ef8a3":"categorical_cols_no_null = categorical_cols.dropna(axis=1)\ncategorical_cols_no_null","48fedcd7":"cols_to_encode = list(filter(lambda x : x.startswith('feature_'),categorical_cols_no_null.columns))\n\nle = preprocessing.LabelEncoder()\nfor c in cols_to_encode:\n    categorical_cols_no_null[c] = le.fit_transform(categorical_cols_no_null[c])\ncategorical_cols_no_null","276e0409":"categorical_cols_no_null","8891cdcc":"total_cols=numeric_cols_no_null.drop(columns=['target']).join(categorical_cols_no_null)\ntotal_cols","b855b314":"X, y=total_cols.drop(columns=[\"id\",\"target\"]), total_cols['target']","b0c612aa":"from sklearn.ensemble import ExtraTreesClassifier\n\nmodel = ExtraTreesClassifier()\nmodel.fit(X,y)","19ad049c":"#plot graph of feature importances for better visualization\nfeat_importances = pd.DataFrame(model.feature_importances_, index=X.columns,columns=[\"score\"]).reset_index()\n\n\nfeat_importances = feat_importances.rename(columns={'index':\"col\"}).sort_values(\"score\",ascending=False)\nfeat_importances['cum_sum'] = feat_importances['score'].cumsum()\nfeat_importances = feat_importances[feat_importances['cum_sum']<.95]\n\nfeat_importances","3c00bb28":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import precision_recall_fscore_support\nimport tqdm\n\ntotal_cols = total_cols.drop(columns=['id'])\nskf = StratifiedKFold(n_splits=2,shuffle=True,random_state=42)\nskf = skf.split(total_cols, total_cols['target'],)\n\n\nfor train_index, test_index in skf:\n    \n    X_train,X_test  = total_cols.iloc[train_index,:].drop(columns=['target']), total_cols.iloc[test_index,:].drop(columns=['target'])\n    y_train,y_test  = total_cols.iloc[train_index][\"target\"], total_cols.iloc[test_index][\"target\"]\n\n    clf = RandomForestClassifier(random_state=0)\n    clf.fit(X_train,y_train)\n    pred = clf.predict(X_test)\n\n\n    f1 = precision_recall_fscore_support(y_test,pred)[0]\n    \n    print(\"f1: {}\".format(f1))\n","03af43ea":"def create_test_df(test, col_to_delete):\n    numeric_cols = test.select_dtypes(['int','float'])\n    categorical_cols=test.select_dtypes(['object'])\n    \n    numeric_cols_no_null = numeric_cols.fillna(0.0)\n\n    numeric_cols_no_null\n    categorical_cols_no_null = categorical_cols.dropna(axis=1)\n    categorical_cols_no_null\n\n    cols_to_encode = list(filter(lambda x : x.startswith('feature_'),categorical_cols_no_null.columns))\n    cols_to_encode\n    le = preprocessing.LabelEncoder()\n    for c in cols_to_encode:\n        categorical_cols_no_null[c] = le.fit_transform(categorical_cols_no_null[c].copy())\n    categorical_cols_no_null\n\n    total_cols=numeric_cols_no_null.join(categorical_cols_no_null)\n    return total_cols\n    \ntest_df = create_test_df(test,col_to_delete)\ntest_df = test_df[total_cols.drop(columns=['target']).columns]\n\n\npredictions = clf.predict(test_df)\ntest_df['target'] = predictions\ntest_df = test_df[['target']].join(test)[['id','target']]\ntest_df.to_csv('results.csv',index = False)","fa21f8f6":"# OUTLIER DETECTION","9a62c475":"# Delete columns with more than 70% of null values"}}