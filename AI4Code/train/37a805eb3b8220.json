{"cell_type":{"07f9f4ca":"code","8007be84":"code","4af9f2f7":"code","c58dd757":"code","68996635":"code","e273e1b0":"code","f0a723d3":"code","8c4d77f4":"code","5b9c6fed":"code","b0552681":"code","1cc5dd53":"code","bb5ed611":"code","89308531":"code","6cc949b7":"code","a4bd650c":"code","0afdc6ad":"code","f81c1b18":"code","df2545ec":"code","e4b8aafe":"code","79c609c6":"code","7adc8b6d":"code","82f8c103":"code","05274ab3":"code","e6684219":"code","f7f5c4a0":"code","f12ee7cf":"code","d0bd8e2f":"code","8a01719f":"code","d4b7729e":"code","9e7c1460":"code","c4c72c27":"code","c2639632":"code","355dd393":"code","b9536107":"code","493a2059":"code","483f737e":"markdown","d84f3a8d":"markdown","0fd5f1b2":"markdown","887072eb":"markdown","c3f7879b":"markdown","8dceefe4":"markdown","84ea4ae9":"markdown","3c54ec05":"markdown"},"source":{"07f9f4ca":"!pip install pmdarima\n!pip install beautifulsoup4\nimport numpy as np \nimport pandas as pd \nfrom bs4 import BeautifulSoup\nimport datetime\nimport requests\nimport json\nfrom pmdarima.utils import diff_inv\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom statsmodels.tsa.api import VAR\nimport seaborn as sns\nfrom statsmodels.tsa.stattools import adfuller\nimport warnings\nwarnings.filterwarnings(\"ignore\")","8007be84":"url = 'https:\/\/api.coinmarketcap.com\/data-api\/v3\/cryptocurrency\/historical?id=3890&convertId=2781&timeStart=1592362879&timeEnd=1623898879'\nmatic_data = requests.get(url)\nsoup = BeautifulSoup(matic_data.content,\"html.parser\")\ntxt = soup.get_text()\ndata = json.loads(txt)\ndata_final = list(data.get('data').values())\ndata_final = data_final[3]\nli = []\nfor i in range(len(data_final)):\n    val = list(data_final[i].get('quote').values())\n    li.append(val)\ndf = pd.DataFrame(li)\ndf.columns = ['open','high','low','close','volume','marketCap','date']","4af9f2f7":"df.head()","c58dd757":"df.shape","68996635":"df.info()","e273e1b0":"df['date'] = pd.to_datetime(df['date'],format=\"%Y-%d-%m %H:%M:%S\",infer_datetime_format=True) ","f0a723d3":"df.info()","8c4d77f4":"df.sort_values(by=['date'],inplace=True)","5b9c6fed":"df.set_index(df['date'],inplace=True)","b0552681":"df.drop(['date'], axis=1, inplace=True)","1cc5dd53":"df.plot();","bb5ed611":"plt.plot(df['open']);","89308531":"plt.plot(df['close']);","6cc949b7":"plt.plot(df['high']);","a4bd650c":"plt.plot(df['low']);","0afdc6ad":"plt.plot(df['volume']);","f81c1b18":"plt.plot(df['marketCap']);","df2545ec":"adf_open = adfuller(df['open'])\nadf_close = adfuller(df['close'])\nadf_high = adfuller(df['high'])\nadf_low = adfuller(df['low'])\nadf_volume = adfuller(df['volume'])\nadf_marketCap = adfuller(df['marketCap'])\nprint(\"p-value for open: {}\".format(adf_open[1]))\nprint(\"p-value for close: {}\".format(adf_close[1]))\nprint(\"p-value for high: {}\".format(adf_high[1]))\nprint(\"p-value for low: {}\".format(adf_low[1]))\nprint(\"p-value for volume: {}\".format(adf_volume[1]))\nprint(\"p-value for marketCap: {}\".format(adf_marketCap[1]))","e4b8aafe":"df_stationary = df.diff().dropna()","79c609c6":"df_stationary.plot();","7adc8b6d":"plt.plot(df_stationary['open']);","82f8c103":"plt.plot(df_stationary['close']);","05274ab3":"plt.plot(df_stationary['high']);","e6684219":"plt.plot(df_stationary['low']);","f7f5c4a0":"plt.plot(df_stationary['volume']);","f12ee7cf":"plt.plot(df_stationary['marketCap']);","d0bd8e2f":"train = df_stationary.iloc[:255]\ntest = df_stationary.iloc[255:]","8a01719f":"train.shape","d4b7729e":"test.shape","9e7c1460":"forecasting_model = VAR(train)\nx = forecasting_model.select_order(maxlags=12)\nx.summary()","c4c72c27":"results = forecasting_model.fit(1)\nresults.summary()","c2639632":"lag_order = results.k_ar\n\nlaaged_values = train.values[-lag_order:]\nforecast = pd.DataFrame(results.forecast(y= laaged_values, steps=109), index = test.index,columns = ['open','high','low','close','volume','marketCap'])\nforecast","355dd393":"forecast_inverse = forecast.cumsum()","b9536107":"from statsmodels.tsa.stattools import acf\ndef forecast_accuracy(forecast, actual):\n    mape = np.mean(np.abs(forecast - actual)\/np.abs(actual))  # MAPE\n    me = np.mean(forecast - actual)             # ME\n    mae = np.mean(np.abs(forecast - actual))    # MAE\n    mpe = np.mean((forecast - actual)\/actual)   # MPE\n    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n    corr = np.corrcoef(forecast, actual)[0,1]   # corr\n    mins = np.amin(np.hstack([forecast[:,None], \n                              actual[:,None]]), axis=1)\n    maxs = np.amax(np.hstack([forecast[:,None], \n                              actual[:,None]]), axis=1)\n    minmax = 1 - np.mean(mins\/maxs)             # minmax\n    return({'mape':mape, 'me':me, 'mae': mae, \n            'mpe': mpe, 'rmse':rmse, 'corr':corr, 'minmax':minmax})","493a2059":"print('Forecast Accuracy of: open')\naccuracy_prod = forecast_accuracy(forecast_inverse['open'].values, test['open'])\nfor key in accuracy_prod:\n    print(key, ' : ', accuracy_prod[key])\n    \nprint('Forecast Accuracy of: close')\naccuracy_prod = forecast_accuracy(forecast_inverse['close'].values, test['close'])\nfor key in accuracy_prod:\n    print(key, ' : ', accuracy_prod[key])\n\nprint('Forecast Accuracy of: high')\naccuracy_prod = forecast_accuracy(forecast_inverse['high'].values, test['high'])\nfor key in accuracy_prod:\n    print(key, ' : ', accuracy_prod[key])\n    \nprint('Forecast Accuracy of: low')\naccuracy_prod = forecast_accuracy(forecast_inverse['low'].values, test['low'])\nfor key in accuracy_prod:\n    print(key, ' : ', accuracy_prod[key])\n\nprint('Forecast Accuracy of: volume')\naccuracy_prod = forecast_accuracy(forecast_inverse['volume'].values, test['volume'])\nfor key in accuracy_prod:\n    print(key, ' : ', accuracy_prod[key])\n    \nprint('Forecast Accuracy of: marketCap')\naccuracy_prod = forecast_accuracy(forecast_inverse['marketCap'].values, test['marketCap'])\nfor key in accuracy_prod:\n    print(key, ' : ', accuracy_prod[key])\n    ","483f737e":"# Stationarity check","d84f3a8d":"# Scraping Polygon (MATIC) data","0fd5f1b2":"# Evaluate the Forecasts","887072eb":"# Differencing \nWhen building models to forecast time series data, another pre-processing step is differencing the data (calculating sequentially xt\u2212xt\u22121) until we get to a point where the series is stationary. ","c3f7879b":" # Crypto Market Analysis + Prediction using VAR\n A cryptocurrency, crypto-currency, or crypto is a digital asset designed to work as a medium of exchange wherein individual coin ownership records are stored in a ledger existing in a form of a computerized database using strong cryptography to secure transaction records, to control the creation of additional coins, and to verify the transfer of coin ownership. It typically does not exist in physical form (like paper money) and is typically not issued by a central authority. Cryptocurrencies typically use decentralized control as opposed to centralized digital currency and central banking systems When a cryptocurrency is minted or created prior to issuance or issued by a single issuer, it is generally considered centralized. When implemented with decentralized control, each cryptocurrency works through distributed ledger technology, typically a blockchain, that serves as a public financial transaction database. -[Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Cryptocurrency)\n\n**In this notebook, I will be analysing and predicting price for Polygon Matic cryptocurrency.**\n\n![Polygon-MATIC-Mark-Cuban.jpeg](attachment:f468aea8-03b5-4511-b644-bd9f85eae149.jpeg)\n\nPolygon is a protocol and a framework for building and connecting Ethereum-compatible blockchain networks. Aggregating scalable solutions on Ethereum supporting a multi-chain Ethereum ecosystem.\n\n**Built by developers, for developers**\n\nPolygon combines the best of Ethereum and sovereign blockchains into a full-fledged multi-chain system.\n\nPolygon solves pain points associated with Blockchains, like high gas fees and slow speeds, without sacrificing on security. This multi-chain system is akin to other ones such as Polkadot, Cosmos, Avalanche etc, but with at least three major upsides:\n- It is able to fully benefit from Ethereum\u2019s network effects\n- It is inherently more secure\n- It is more open and powerful\n\n**Polygon - a protocol and a framework for building and connecting Ethereum-compatible blockchain networks.**\n\n- One-click deployment of preset blockchain networks\n- Growing set of modules for developing custom networks\n- Interoperability protocol for exchanging arbitrary messages with Ethereum and other blockchain networks\n- Modular and optional \u201csecurity as a service\u201d\n- Adaptor modules for enabling interoperability for existing blockchain networks\n\n![image.png](attachment:4fb2cfe0-7487-420e-b5a8-e285b486f86a.png)\n\nSource: https:\/\/polygon.technology\/","8dceefe4":"# Price Forecasting\n\n\n## VAR Model\nVector autoregression is a statistical model used to capture the relationship between multiple quantities as they change over time. VAR is a type of stochastic process model. VAR models generalize the single-variable autoregressive model by allowing for multivariate time series.\nLike the autoregressive model, each variable has an equation modelling its evolution over time. This equation includes the variable's lagged (past) values, the lagged values of the other variables in the model, and an error term. VAR models do not require as much knowledge about the forces influencing a variable as do structural models with simultaneous equations. The only prior knowledge required is a list of variables which can be hypothesized to affect each other over time.\n[Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Vector_autoregression#:~:text=Vector%20autoregression%20(VAR)%20is%20a,allowing%20for%20multivariate%20time%20series.)","84ea4ae9":"# Import Libraries","3c54ec05":"# Exploratory Data Analytics"}}