{"cell_type":{"8657d289":"code","25e732ee":"code","d3a63a56":"code","ecaa9f75":"code","4fc14d08":"code","a98fab10":"code","5a160c14":"code","75fba600":"code","05490e9b":"code","9ab97f76":"code","7c100803":"code","8ba70467":"code","bae493ac":"code","fe810e3e":"code","d6b8c0b5":"code","bbc4bea4":"code","7f7a1f84":"code","8623de0c":"code","dd01e8e5":"code","438e0ec5":"code","de5b734d":"code","cc96205a":"code","c77fe988":"code","03c4c669":"code","6e85ba0d":"code","cb3baaa5":"markdown","35f798e4":"markdown","39cbb306":"markdown","c0dba3c5":"markdown"},"source":{"8657d289":"import opendatasets as od\ndataset_url = 'https:\/\/www.kaggle.com\/c\/otto-group-product-classification-challenge\/download'\nod.download(dataset_url)","25e732ee":"# keras imports for the dataset and building our neural network\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, AveragePooling2D\nfrom keras.utils import np_utils\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\nfrom tqdm import tqdm\ndata_path='..\/input\/intel-image-classification\/seg_train\/seg_train'\ncategories=['buildings','forest','glacier','mountain','sea','street']#category of classification","d3a63a56":"#create training dataset\nimport sys\ntraining_data=[]\ndef create_training_data():\n  for cat in categories:\n    path=os.path.join(data_path,cat)  #path to specific folder\n    class_num=categories.index(cat) #index of specific folder\n    for img in tqdm(os.listdir(path)):\n      try:\n        img_array=cv2.imread(os.path.join(path,img), cv2.IMREAD_COLOR); \n        new_array=cv2.resize(img_array,(224,224),3)   #resize image  to specific size\n        training_data.append([new_array,class_num])  #add data to training_data file\n      except:\n        pass\ncreate_training_data();","ecaa9f75":"#to shuffle training data at random\nimport random\nrandom.shuffle(training_data)","4fc14d08":"#to seperate labels and features\nX=[]\nY=[]","a98fab10":"for features,label in training_data:\n  X.append(features)\n  Y.append(label)\nprint(len(X))","5a160c14":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.25)","75fba600":"import numpy as np\nX_train=np.array(X_train)\nX_test=np.array(X_test)\nprint(X_train.shape)\nprint(X_test.shape)","05490e9b":"# # building the input vector from the 224x224 pixels\nX_train = X_train.reshape(X_train.shape[0], 224, 224, 3)\nX_test = X_test.reshape(X_test.shape[0], 224, 224, 3)","9ab97f76":"X_train = X_train.astype('float32')\nX_test = X_test.astype('float32')","7c100803":"y_train=np.array(y_train)\ny_test=np.array(y_test)","8ba70467":"# one-hot encoding using keras' numpy-related utilities\nn_classes = 6\nprint(\"Shape before one-hot encoding: \", y_train.shape)\nY_train = np_utils.to_categorical(y_train, n_classes)\nY_test = np_utils.to_categorical(y_test, n_classes)\nprint(\"Shape after one-hot encoding: \", Y_train.shape)","bae493ac":"\nmodel = Sequential()\n#layer 1\nmodel.add(Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(224, 224, 3)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n#layer2\nmodel.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n#flatten\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(6, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')","fe810e3e":"print(model.summary())","d6b8c0b5":"# training the model for 10 \/epochs1\nhistory=model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=10)","bbc4bea4":"import plotly.graph_objects as go\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=history.epoch,\n                         y=history.history['accuracy'],\n                         mode='lines+markers',\n                         name='Training accuracy'))\nfig.add_trace(go.Scatter(x=history.epoch,\n                         y=history.history['val_accuracy'],\n                         mode='lines+markers',\n                         name='Validation accuracy'))\nfig.update_layout(title='Accuracy',\n                  xaxis=dict(title='Epoch'),\n                  yaxis=dict(title='Percentage'))\nfig.show()","7f7a1f84":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=history.epoch,\n                         y=history.history['loss'],\n                         mode='lines+markers',\n                         name='Training loss'))\nfig.add_trace(go.Scatter(x=history.epoch,\n                         y=history.history['val_loss'],\n                         mode='lines+markers',\n                         name='Validation loss'))\nfig.update_layout(title='Loss',\n                  xaxis=dict(title='Epoch'),\n                  yaxis=dict(title='Percentage'))\nfig.show()","8623de0c":"score = model.evaluate(X_test,Y_test,batch_size=63)","dd01e8e5":"from keras.optimizers import Adam, SGD\n","438e0ec5":"\nmodel = Sequential()\n#layer 1\nmodel.add(Conv2D(64, kernel_size=(5,5), strides=(2,2), padding='same', activation='relu', input_shape=(224, 224, 3)))\nmodel.add(AveragePooling2D(pool_size=(2,2)))\n#layer2\nmodel.add(Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\nmodel.add(AveragePooling2D(pool_size=(2,2)))\n#layer3\nmodel.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\nmodel.add(AveragePooling2D(pool_size=(2,2)))\n#layer4\nmodel.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n#layer5\nmodel.add(Conv2D(256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n#layer6\nmodel.add(Conv2D(256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n#flatten\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(6, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')","de5b734d":"print(model.summary())","cc96205a":"# training the model for 10 \/epochs1\nhistory2=model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=50)","c77fe988":"import plotly.graph_objects as go\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=history2.epoch,\n                         y=history2.history['accuracy'],\n                         mode='lines+markers',\n                         name='Training accuracy'))\nfig.add_trace(go.Scatter(x=history2.epoch,\n                         y=history2.history['val_accuracy'],\n                         mode='lines+markers',\n                         name='Validation accuracy'))\nfig.update_layout(title='Accuracy',\n                  xaxis=dict(title='Epoch'),\n                  yaxis=dict(title='Percentage'))\nfig.show()","03c4c669":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=history.epoch,\n                         y=history.history['loss'],\n                         mode='lines+markers',\n                         name='Training loss'))\nfig.add_trace(go.Scatter(x=history.epoch,\n                         y=history.history['val_loss'],\n                         mode='lines+markers',\n                         name='Validation loss'))\nfig.update_layout(title='Loss',\n                  xaxis=dict(title='Epoch'),\n                  yaxis=dict(title='Percentage'))\nfig.show()","6e85ba0d":"score = model.evaluate(X_test,Y_test,batch_size=63)","cb3baaa5":"**Create a 2 layer custom CNN with pooling \u2013 print architecture \u2013 report results.**","35f798e4":"After Developing the model with the 2 Layers of convolution followed by pooling layer and training the model for 10 epochs we got the accuracy of 53.23 %","39cbb306":"## I Simple used Average Pooling layers as my pooling layer for first 2 layers and the MaxPooling layer for further layers and at first layer layer i used the filter of size 5*5 and rest with 3*3 filter.The number of  filters i used is 64,64,128,128,256,256 and activation functions as relu then i used flattten layer and pass this data further to dense layer of 64,128 and i used softmax as my final activation function as category are 6. I used optimizer as adam and loss function as categorical_crossentrophy. I got the Training accuracy as 95.80% and Validation accuracy as 79.45% after traininng the model for 10 Epochs\n\n\n## Refer Colab code for proper output views https:\/\/colab.research.google.com\/drive\/1MmPVRYmb3BsU2OH1bFNrtbM5qKTI7kz8?usp=sharing","c0dba3c5":"### 1) Use the Intel Image classification dataset at\n\nhttps:\/\/www.kaggle.com\/puneet6060\/intel-image-classification\n\nUse CNN models for classification of the 6 classes.\n\na) Create a 2 layer custom CNN with pooling \u2013 print architecture \u2013 report results.\n\nb) Create a 6 layer CNN with pooling \u2013 print architecture - report result, fine tune to achieve >85% accuracy.\n\nc) Show the intermediate activation values of the last layer for 3 sample images \u2013 plot figures\n\n(20 marks)\n"}}