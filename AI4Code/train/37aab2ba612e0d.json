{"cell_type":{"a5130846":"code","0f6aaa65":"code","39c8a329":"code","193ab05b":"code","b8fe2dc8":"code","583d8f83":"code","8eecfd31":"code","9d940bfd":"code","58874e09":"code","c9f2b79d":"code","ae98f6dd":"code","c90974d1":"code","ac1f1e9f":"code","0c463740":"code","807908b4":"code","1e3c4791":"code","f8bd8268":"code","8b3e2896":"code","dda4bc51":"code","f7ea4242":"code","e77977f5":"code","eba67067":"code","183c6fa4":"code","a3be8e01":"code","ddab30e1":"code","deb15e6f":"code","8f3df4f6":"code","2ed869bd":"code","aae6db36":"code","a11c44ca":"code","1dd59b5c":"code","fa2e6f33":"code","495f07da":"code","6abe8718":"code","85489f6d":"code","c20eb188":"code","18962326":"code","74b4b5be":"code","b4778162":"code","3df04cf1":"code","f37ea879":"code","527e5ad3":"code","5f15ac60":"code","e037aa2a":"code","a079dc67":"code","2af1e6aa":"code","273601c1":"code","9d6ce6f9":"code","c3b40bf6":"code","54fa7637":"markdown","396193c3":"markdown","483fb3e9":"markdown","f9a77c5a":"markdown","f188f7c1":"markdown","95be9a95":"markdown","2e428f09":"markdown","f9e63383":"markdown","75b5227a":"markdown","5e423618":"markdown","b652a7dc":"markdown"},"source":{"a5130846":"ver = 'linear_v34'\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport gc\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm_notebook as tqdm\nimport time\nfrom datetime import datetime\n\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nplt.style.use(['seaborn-darkgrid'])\nplt.rcParams['font.family'] = 'DejaVu Sans'\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\nfrom sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\nfrom sklearn.linear_model import LogisticRegression, Lasso, Ridge, SGDClassifier\nfrom sklearn.feature_selection import RFECV\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.metrics import roc_auc_score, log_loss, accuracy_score, confusion_matrix\nimport os\nprint(os.listdir(\"..\/input\"))\n\nfrom hyperopt import fmin, tpe, hp, anneal, Trials, STATUS_OK\n\nRANDOM_STATE = 78\nnoise_std = 0.01","0f6aaa65":"filename = 'subm_{}_{}_'.format(ver, datetime.now().strftime('%Y-%m-%d'))\n\ndef sub_prp(clf, filename, X_test):\n    prediction_ = clf.predict_proba(X_test)[:,1]\n    submission_ = pd.read_csv('..\/input\/sample_submission.csv')\n    submission_['target'] = prediction_\n    submission_.to_csv(filename, index=False)\n    print(submission_.head())\n    \ndef sub_pr(clf, filename, X_test):\n    prediction_ = clf.predict(X_test)\n    submission_ = pd.read_csv('..\/input\/sample_submission.csv')\n    submission_['target'] = prediction_\n    submission_.to_csv(filename, index=False)\n    print(submission_.head())","39c8a329":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","193ab05b":"train.shape, test.shape","b8fe2dc8":"train.describe()","583d8f83":"train['target'].value_counts().sort_index(ascending=False).plot(kind='barh', figsize=(15,6))\nplt.title('Target', fontsize=18)","8eecfd31":"X_train = train.drop(['id', 'target'], axis=1)\ny_train = train['target']\nX_tst = test.drop(['id'], axis=1)","9d940bfd":"sc0 = StandardScaler()\nsc0.fit(X_train)\nX_train = sc0.transform(X_train)\nX_test = sc0.transform(X_tst)\n","58874e09":"X_train += np.random.normal(0, noise_std, X_train.shape)","c9f2b79d":"#kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\nrepfold = RepeatedStratifiedKFold(n_splits=10, n_repeats=20, random_state=RANDOM_STATE)\nlogreg0 = LogisticRegression(C=0.5, random_state=RANDOM_STATE, solver='liblinear', penalty='l1')\nlass0 = Lasso(alpha=0.031, tol=0.01, selection='random', random_state=RANDOM_STATE)\nridg0 = Ridge(alpha=20, fit_intercept=True, solver='auto', tol=0.0025, random_state=RANDOM_STATE)\nsgd0 = SGDClassifier(eta0=1, max_iter=1000, tol=0.0001, random_state=RANDOM_STATE, loss='log')","ae98f6dd":"logreg0.fit(X_train, y_train)\nsc = cross_val_score(logreg0, X_train, y_train, scoring='roc_auc', cv=repfold, n_jobs=-1, verbose=1)\nprint(sc.mean())","c90974d1":"perm = PermutationImportance(logreg0, random_state=RANDOM_STATE).fit(X_train, y_train)\neli5.show_weights(perm, top=10)","ac1f1e9f":"top_feat = [i[1:] for i in eli5.formatters.as_dataframe.explain_weights_df(perm).feature]\ntop_feat1 = top_feat[:15]\ntop_feat1.append('target')\ncorr = train[top_feat1].corr()\ncorr.target.sort_values(ascending=False)","0c463740":"mask = np.zeros_like(corr, dtype=np.bool)\n\nplt.subplots(figsize = (15,12))\nsns.heatmap(corr, \n            annot=True,\n            #mask = mask,\n            cmap = 'RdBu',\n            linewidths=0.1, \n            linecolor='white',\n            vmax = .2,\n            square=True)\nplt.title(\"Correlations\", y = 1.03,fontsize = 20);","807908b4":"el_df =pd.Series(logreg0.coef_[0], index=range(len(X_train.T)))\nel_df = el_df[(logreg0.coef_[0]<=-0.2) | (logreg0.coef_[0]>=0.2)].sort_values(ascending=False)\nplt.figure(figsize=(8,6))\nel_df.plot(kind='barh')\nplt.xlabel(\"Importance\",fontsize=12)\nplt.ylabel(\"Features\",fontsize=12)\nplt.title(\"Top Features\",fontsize=16)\nplt.show()","1e3c4791":"el_df.index","f8bd8268":"logreg01 = LogisticRegression(C=0.5, random_state=RANDOM_STATE, solver='liblinear', penalty='l1')","8b3e2896":"logreg01.fit(X_train.T[el_df.index].T, y_train)\nsc = cross_val_score(logreg01, X_train.T[el_df.index].T, y_train, scoring='roc_auc', cv=repfold, n_jobs=-1, verbose=1)\nprint(sc.mean())","dda4bc51":"param_lr = {'class_weight' : ['balanced', None], \n                'penalty' : ['l2','l1'],  \n                'C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n           }","f7ea4242":"grid_lr = GridSearchCV(estimator = logreg0, param_grid = param_lr , scoring = 'roc_auc', verbose = 1, n_jobs = -1, cv=repfold)\n\ngrid_lr.fit(X_train,y_train)\n\nprint(\"Best Score:\" + str(grid_lr.best_score_))\nprint(\"Best Parameters: \" + str(grid_lr.best_params_))\n","e77977f5":"best_parameters_lr = grid_lr.best_params_\nlogreg = LogisticRegression(**best_parameters_lr)\nlogreg.fit(X_train,y_train)\nsc = cross_val_score(logreg, X_train, y_train, scoring='roc_auc', cv=repfold, n_jobs=-1, verbose=1)\nprint(sc.mean())\n\nselector_lr = RFECV(logreg, min_features_to_select=12, scoring='roc_auc', step=15, verbose=0, cv=repfold, n_jobs=-1)\nselector_lr.fit(X_train,y_train)\n#sc = cross_val_score(selector_lr, X_train, y_train, scoring='roc_auc', cv=repfold, n_jobs=-1, verbose=1)\n#print(sc.mean())","eba67067":"selector_lr.score(X_train, y_train)","183c6fa4":"def acc_model(params):\n    clf = LogisticRegression(**params)\n    return cross_val_score(clf, X_train, y_train, scoring='roc_auc', cv=repfold).mean()","a3be8e01":"space4lr = {'C': hp.uniform('C', .001, 50.0), \n            'solver' : hp.choice('solver', ['liblinear']),\n            'penalty' : hp.choice('penalty', ['l1', 'l2']),\n            #'dual' : hp.choice('dual', [True, False]),\n            #'fit_intercept': hp.choice('fit_intercept', ['True', 'False']),\n            'class_weight': hp.choice('class_weight', ['balanced', None]),\n            'max_iter': hp.choice('max_iter', [50000]),\n            'random_state': RANDOM_STATE, #hp.uniformint('random_state', 1, 100),\n            #'n_jobs': -1\n           }\n\nbest = 0\npr = []\ndef f(params):\n    global best\n    acc = acc_model(params)\n    if acc > best:\n        best = acc\n        print ('new best:', best, params)\n        pr.append(params)\n    return {'loss': -acc, 'status': STATUS_OK}\n\ntrials = Trials()\nbest = fmin(f, space4lr, algo=tpe.suggest, max_evals=2000, trials=trials)\nprint ('best for logreg: ')\nprint (pr[-1])","ddab30e1":"print(pr[-1])\nbest_lr = pr[-1]\nlogreg1 = LogisticRegression(**best_lr)\nlogreg1.fit(X_train,y_train)\nsc = cross_val_score(logreg1, X_train, y_train, scoring='roc_auc', cv=repfold, n_jobs=-1, verbose=1)\nprint(sc.mean())\n","deb15e6f":"selector_lr1 = RFECV(logreg1, min_features_to_select=12, scoring='roc_auc', step=15, verbose=0, cv=repfold, n_jobs=-1)\nselector_lr1.fit(X_train,y_train)\n#print(selector_lr1.score(X_train, y_train))","8f3df4f6":"perm = PermutationImportance(logreg1, random_state=RANDOM_STATE).fit(X_train, y_train)\neli5.show_weights(perm, top=10)","2ed869bd":"top_feat = [i[1:] for i in eli5.formatters.as_dataframe.explain_weights_df(perm).feature]\ntop_feat1 = top_feat[:15]\ntop_feat1.append('target')\ncorr = train[top_feat1].corr()\ncorr.target.sort_values(ascending=False)","aae6db36":"mask = np.zeros_like(corr, dtype=np.bool)\n\nplt.subplots(figsize = (15,12))\nsns.heatmap(corr, \n            annot=True,\n            #mask = mask,\n            cmap = 'RdBu',\n            linewidths=0.1, \n            linecolor='white',\n            vmax = .2,\n            square=True)\nplt.title(\"Correlations\", y = 1.03,fontsize = 20);","a11c44ca":"lass0.fit(X_train, y_train)\nsc = cross_val_score(lass0, X_train, y_train, scoring='roc_auc', cv=repfold, n_jobs=-1, verbose=1)\nprint(sc.mean())","1dd59b5c":"perm = PermutationImportance(lass0, random_state=RANDOM_STATE).fit(X_train, y_train)\neli5.show_weights(perm, top=10)","fa2e6f33":"top_feat = [i[1:] for i in eli5.formatters.as_dataframe.explain_weights_df(perm).feature]\ntop_feat1 = top_feat[:15]\ntop_feat1.append('target')\ncorr = train[top_feat1].corr()\ncorr.target.sort_values(ascending=False)","495f07da":"mask = np.zeros_like(corr, dtype=np.bool)\n\nplt.subplots(figsize = (15,12))\nsns.heatmap(corr, \n            annot=True,\n            #mask = mask,\n            cmap = 'RdBu',\n            linewidths=0.1, \n            linecolor='white',\n            vmax = .2,\n            square=True)\nplt.title(\"Correlations\", y = 1.03,fontsize = 20);","6abe8718":"el_df =pd.Series(lass0.coef_,index=train.drop(['id', 'target'], axis=1).columns)\nel_df = el_df[(lass0.coef_<=-0.05) | (lass0.coef_>=0.05)].sort_values(ascending=False)\nplt.figure(figsize=(8,6))\nel_df.plot(kind='barh')\nplt.xlabel(\"Importance\",fontsize=12)\nplt.ylabel(\"Features\",fontsize=12)\nplt.title(\"Top Features\",fontsize=16)\nplt.show()","85489f6d":"param_lass = {\n            'alpha' : [0.022, 0.021, 0.02, 0.019, 0.023, 0.024, 0.025, 0.026, 0.027, 0.029, 0.031],\n            'tol'   : [0.0013, 0.0014, 0.001, 0.0015, 0.0011, 0.0012, 0.0016, 0.0017]\n        }","c20eb188":"grid_lass = GridSearchCV(estimator = lass0, param_grid = param_lass , scoring = 'roc_auc', verbose = 1, n_jobs = -1, cv=repfold)\n\ngrid_lass.fit(X_train,y_train)\n\nprint(\"Best Score:\" + str(grid_lass.best_score_))\nprint(\"Best Parameters: \" + str(grid_lass.best_params_))","18962326":"best_parameters_lass = grid_lass.best_params_\nlass = Lasso(**best_parameters_lass)\nlass.fit(X_train,y_train)\nsc = cross_val_score(lass, X_train, y_train, scoring='roc_auc', cv=repfold, n_jobs=-1, verbose=1)\nprint(sc.mean())\n\nselector_lass = RFECV(lass, min_features_to_select=12, scoring='roc_auc', step=15, verbose=0, cv=repfold, n_jobs=-1)\nselector_lass.fit(X_train,y_train)\n","74b4b5be":"def acc_model(params):\n    clf = Lasso(**params)\n    return cross_val_score(clf, X_train, y_train, scoring='roc_auc', cv=repfold).mean()","b4778162":"space4lass = {'alpha' : hp.uniform('alpha', .01, 1),\n            'tol'   : hp.uniform('tol', .001, 0.1),\n            'random_state': RANDOM_STATE, #hp.uniformint('random_state', 1, 100),\n            'max_iter': hp.choice('max_iter', [50000]),\n             }\n\nbest = 0\npr = []\ndef f(params):\n    global best\n    acc = acc_model(params)\n    if acc > best:\n        best = acc\n        print ('new best:', best, params)\n        pr.append(params)\n    return {'loss': -acc, 'status': STATUS_OK}\n\ntrials = Trials()\nbest = fmin(f, space4lass, algo=tpe.suggest, max_evals=3000, trials=trials)\nprint ('best for lasso: ')\nprint (pr[-1])","3df04cf1":"print(pr[-1])\nbest_lass = pr[-1]\nlass1 = Lasso(**best_lass)\nlass1.fit(X_train,y_train)\nsc = cross_val_score(lass1, X_train, y_train, scoring='roc_auc', cv=repfold, n_jobs=-1, verbose=1)\nprint(sc.mean())\n","f37ea879":"selector_lass1 = RFECV(lass1, min_features_to_select=12, scoring='roc_auc', step=15, verbose=0, cv=repfold, n_jobs=-1)\nselector_lass1.fit(X_train,y_train)","527e5ad3":"perm = PermutationImportance(lass1, random_state=RANDOM_STATE).fit(X_train, y_train)\neli5.show_weights(perm, top=10)","5f15ac60":"top_feat = [i[1:] for i in eli5.formatters.as_dataframe.explain_weights_df(perm).feature]\ntop_feat1 = top_feat[:15]\ntop_feat1.append('target')\ncorr = train[top_feat1].corr()\ncorr.target.sort_values(ascending=False)","e037aa2a":"mask = np.zeros_like(corr, dtype=np.bool)\n\nplt.subplots(figsize = (15,12))\nsns.heatmap(corr, \n            annot=True,\n            #mask = mask,\n            cmap = 'RdBu',\n            linewidths=0.1, \n            linecolor='white',\n            vmax = .2,\n            square=True)\nplt.title(\"Correlations\", y = 1.03,fontsize = 20);","a079dc67":"def cross_validation(train_, target_, params,\n                            num_folds = 5, repeats = 20, rs = 0):\n    \n    print(params)\n    \n    clfs = []\n    folds = RepeatedStratifiedKFold(n_splits = num_folds, n_repeats = repeats, random_state = rs)\n    \n    valid_pred = pd.DataFrame(index = train_.index)\n    \n    # Cross-validation cycle\n    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(target_, target_)):\n        print('--- Fold {} started at {}'.format(n_fold, time.ctime()))\n        \n        train_x, train_y = train_.iloc[train_idx], target_.iloc[train_idx]\n        valid_x, valid_y = train_.iloc[valid_idx], target_.iloc[valid_idx]\n        \n        clf = LogisticRegression(**params)\n        clf.fit(train_x, train_y)\n    \n        clfs.append(clf)\n\n        predict = clf.predict_proba(valid_x)[:, 1]\n    \n        tn, fp, fn, tp = confusion_matrix(valid_y, (predict >= .5) * 1).ravel()\n        auc = roc_auc_score(valid_y, predict)\n        acc = accuracy_score(valid_y, (predict >= .5) * 1)\n        loss = log_loss(valid_y, predict)\n        print('TN =', tn, 'FN =', fn, 'FP =', fp, 'TP =', tp)\n        print('AUC = ', auc, 'Loss =', loss, 'Acc =', acc)\n        \n        valid_pred[n_fold] = pd.Series(predict, index = valid_x.index)\n\n        del train_x, train_y, valid_x, valid_y, predict\n        gc.collect()\n\n    return clfs, valid_pred\n\ndef save_submit(test_, clfs_, filename):\n    subm = pd.DataFrame(np.zeros(test_.shape[0]), index = test_.index, columns = ['target'])\n    for clf in clfs_:\n        subm['target'] += clf.predict_proba(test_)[:, 1]\n    subm['target'] \/= len(clfs_)\n    subm = subm.reset_index()\n    subm.columns = ['id', 'target']\n    subm.to_csv(filename, index = False)\n    #print(subm)\n","2af1e6aa":"clfs, pred = cross_validation(pd.DataFrame(X_train), y_train, best_lr)","273601c1":"sub_prp(logreg1, filename+'lr1.csv', X_test)\nsub_prp(selector_lr1, filename+'sel_lr1.csv', X_test)","9d6ce6f9":"sub_pr(lass1, filename+'lass1.csv', X_test)\nsub_pr(selector_lass1, filename+'sel_lass1.csv', X_test)","c3b40bf6":"save_submit(pd.DataFrame(X_test, index=test.id), clfs, filename+'lr_cv_Anna.csv')","54fa7637":"**Fit simple logreg**","396193c3":"**Hyperparameters search for Lasso with *hyperopt***","483fb3e9":"**Load datasets**","f9a77c5a":"Try function from https:\/\/www.kaggle.com\/aantonova\/851-logistic-regression","f188f7c1":"**Fit simple Lasso**","95be9a95":"**Submission**","2e428f09":"**Submission**","f9e63383":"**Hyperparameters search for Lasso with *GridSearchCV***","75b5227a":"**Hyperparameters search for logreg with *hyperopt***","5e423618":"**Hyperparameters search for logreg with *GridSearchCV***","b652a7dc":"**Data preparation**"}}