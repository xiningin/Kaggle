{"cell_type":{"facddda9":"code","eec50a8a":"code","a2d1c1d7":"code","df4b1c43":"code","b23dbeaf":"code","1f5e86e9":"code","0d3de4cc":"code","8abfe637":"code","6aa747b2":"code","97b8ed22":"code","0ed3ec95":"code","0ed9217f":"code","729af225":"code","9b740f22":"code","f3999b28":"code","af0f2ed5":"code","835117f3":"code","297ef9a6":"code","68550fab":"code","33a693cf":"code","8de2d811":"code","3d9732b1":"code","272ca7cd":"code","2b71413f":"code","c3b038e5":"markdown","ce2022fb":"markdown","32962eb9":"markdown","9e249b4b":"markdown","92f53156":"markdown","f6fb880e":"markdown","78caf8a1":"markdown","11f706c6":"markdown","984f0806":"markdown"},"source":{"facddda9":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nimport os\nfrom tqdm import tqdm\nimport json\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns","eec50a8a":"train_path = '\/kaggle\/input\/rcnn-data-preprocessing-part-2\/Train\/'\ntest_path = '\/kaggle\/input\/rcnn-data-preprocessing-part-2\/Test\/'","a2d1c1d7":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","df4b1c43":"BATCH_SIZE = 64\nIMAGE_SIZE = (224,224,3)","b23dbeaf":"train_generator = ImageDataGenerator(rescale=1.\/255,validation_split=0.2)\n\ntrain_data = train_generator.flow_from_directory(train_path,\n                                                 target_size=(224, 224),\n                                                 color_mode=\"rgb\",\n                                                 class_mode=\"categorical\",\n                                                 batch_size=BATCH_SIZE,\n                                                 shuffle=True,\n                                                 subset='training')\n\nval_data = train_generator.flow_from_directory(train_path,\n                                                 target_size=(224, 224),\n                                                 color_mode=\"rgb\",\n                                                 class_mode=\"categorical\",\n                                                 batch_size=BATCH_SIZE,\n                                                 shuffle=False,\n                                                 subset='validation')\n\ntest_generator  = ImageDataGenerator(rescale=1.\/255)\ntest_data = test_generator.flow_from_directory(test_path,\n                                                 target_size=(224, 224),\n                                                 color_mode=\"rgb\",\n                                                 class_mode=\"categorical\",shuffle=False,\n                                                 batch_size=BATCH_SIZE)","1f5e86e9":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import Dense,Flatten,Input,Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping","0d3de4cc":"baseModel = VGG16(weights=\"imagenet\", include_top=False,\n    input_tensor=Input(shape=IMAGE_SIZE))\n\nheadModel = baseModel.output\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(4096, activation='relu')(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(4096, activation='relu')(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(3, activation='softmax')(headModel)\n\nfor layer in baseModel.layers:\n    layer.trainable = False\n\nmodel = Model(inputs=baseModel.input, outputs=headModel)\n\nopt = Adam(lr=0.001)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])","8abfe637":"model.summary()","6aa747b2":"early_stop = EarlyStopping(patience=2,monitor='val_loss')","97b8ed22":"results = model.fit_generator(train_data,epochs=20,\n                              validation_data=val_data,\n                             callbacks=[early_stop])","0ed3ec95":"pd.DataFrame(model.history.history)[['accuracy','val_accuracy']].plot()","0ed9217f":"pd.DataFrame(model.history.history)[['loss','val_loss']].plot()","729af225":"test_pred = model.predict_generator(test_data)","9b740f22":"pred_class = [np.argmax(x) for x in test_pred]","f3999b28":"test_data.class_indices","af0f2ed5":"true_class = test_data.classes","835117f3":"from sklearn.metrics import classification_report, confusion_matrix","297ef9a6":"print(classification_report(true_class,pred_class))","68550fab":"sns.heatmap(confusion_matrix(true_class,pred_class),annot=True)","33a693cf":"mapping_class = test_data.class_indices","8de2d811":"mapping_class = dict([(value, key) for key, value in mapping_class.items()]) ","3d9732b1":"images, labels = next(iter(test_data))\nimages = images.reshape(64, 224,224,3)\nfig, axes = plt.subplots(4, 4, figsize=(16,16))\n\nfor ax, img, label in zip(axes.flat, images[:16], labels[:16]):\n    ax.imshow(img)\n    true_label = mapping_class[np.argmax(label)]\n    \n    pred_prob = model.predict(img.reshape(1, 224,224, 3))\n    pred_label = mapping_class[np.argmax(pred_prob)]\n    \n    prob_class = np.max(pred_prob) * 100\n    \n    ax.set_title(f\"TRUE LABEL: {true_label}\", fontweight = \"bold\", fontsize = 12)\n    ax.set_xlabel(f\"PREDICTED LABEL: {pred_label}\\nProb({pred_label}) = {(prob_class):.2f}%\",\n                 fontweight = \"bold\", fontsize = 10,\n                 color = \"blue\" if true_label == pred_label else \"red\")\n    \n    ax.set_xticks([])\n    ax.set_yticks([])\n    \nplt.tight_layout()\nfig.suptitle(\"PREDICTION for 16 RANDOM TEST IMAGES\", size = 30, y = 1.03, fontweight = \"bold\")\nplt.show()","272ca7cd":"\nmisclassify_pred = np.nonzero(true_class != pred_class)[0]\nfig, axes = plt.subplots(4, 4, figsize=(16, 16))\n\nfor ax, batch_num, image_num in zip(axes.flat, misclassify_pred \/\/ BATCH_SIZE, misclassify_pred % BATCH_SIZE):\n    images, labels = test_data[batch_num]\n    img = images[image_num]\n    ax.imshow(img.reshape(*IMAGE_SIZE))\n    \n    true_label = mapping_class[np.argmax(label)]\n    \n    pred_prob = model.predict(img.reshape(1, 224,224, 3))\n    pred_label = mapping_class[np.argmax(pred_prob)]\n    \n    prob_class = np.max(pred_prob)*100\n    \n    \n    ax.set_title(f\"TRUE LABEL: {true_label}\", fontweight = \"bold\", fontsize = 12)\n    ax.set_xlabel(f\"PREDICTED LABEL: {pred_label}\\nProb({pred_label}) = {(prob_class):.2f}%\",\n                 fontweight = \"bold\", fontsize = 10,\n                 color = \"blue\" if true_label == pred_label else \"red\")\n    \n    ax.set_xticks([])\n    ax.set_yticks([])\n    \nplt.tight_layout()\nfig.suptitle(f\"MISCLASSIFIED TEST IMAGES ({len(misclassify_pred)} out of {len(true_class)})\",\n             size = 20, y = 1.03, fontweight = \"bold\")\nplt.show()","2b71413f":"model.save('RCNN_crop_weed_classification_model.h5')","c3b038e5":"# Model Architecture","ce2022fb":"## Missclassified Images","32962eb9":"# Predict on some test images","9e249b4b":"# Training","92f53156":"# Preparing The Data","f6fb880e":"## Prediction on Batch","78caf8a1":"Training of RCNN model done in 3 stages\n1. CNN finetuning\n2. CNN + SVM\n3. Bounding box regression\n\nThis notebook is for CNN finetuning.\n\nWhole RCNN implementation code is in [Github](https:\/\/github.com\/ravirajsinh45\/implementation_of_RCNN)  ","11f706c6":"# Saving model","984f0806":"# Model evaluation"}}