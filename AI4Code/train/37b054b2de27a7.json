{"cell_type":{"225008d8":"code","25f15500":"code","ede616d6":"code","b9c59e60":"code","d49e8a70":"code","8542837d":"code","408bde6d":"code","9e4fb208":"code","dd5c160d":"code","682f22fb":"code","05fc5bb8":"code","81f051fb":"code","b112e1fb":"code","1fbd878d":"code","064f7b87":"code","f7337b44":"code","cbe746cb":"code","b759d33a":"code","4dd577d6":"code","de616570":"code","fe63fb87":"code","d712b3f4":"code","02716de9":"code","ab45f6b8":"code","de461163":"code","59a4c42f":"code","0532525b":"code","3220341d":"code","a7d5149c":"code","7c3e269d":"code","620fbe55":"code","18e026f2":"code","1b565d64":"code","f0925f52":"code","6bb4e819":"code","fe290a97":"code","f7bcea2e":"code","7d4ac2d9":"code","b0507a21":"code","27447725":"code","8db5d31d":"code","4d938c76":"code","ac5fbb3a":"code","28b9a34b":"code","46638244":"code","8b9bca78":"code","8ff4a6f3":"code","1426fb3c":"code","b2a51387":"code","a512aa47":"code","db69f637":"code","1e2cf6fe":"code","b420cc76":"code","b8794621":"code","563d6419":"code","c4aba060":"code","126a4475":"code","af33ed01":"code","af2a871c":"code","233d7d51":"code","be9c084b":"code","de96eedd":"code","393f0e3d":"code","4aa07129":"code","9c7d0057":"code","9b1845d5":"code","3b3903b2":"code","208719da":"code","16be0c4b":"code","e3f075eb":"code","c164065e":"code","9e602937":"code","c1647938":"code","da82ec53":"code","96829f3e":"code","859c2237":"code","799335c3":"code","723420e9":"code","ee5d550b":"code","25ac2da1":"code","cf6cf807":"code","d8ab9ec0":"code","7ccadd96":"code","e4abbb81":"code","42076c62":"code","53c4ac55":"code","5c3b3479":"code","3d57cdb4":"code","14e09b61":"code","88264a86":"code","8b6190af":"code","6fbd2703":"code","60b886a1":"code","431a3fa1":"code","ededb737":"code","07567408":"code","16cad726":"code","9ba211cf":"code","35a04357":"code","fcbebf32":"code","28ddea90":"code","09a120a5":"code","adc07200":"code","a92f845a":"code","c2663094":"code","89c698fa":"code","eb1e1ba0":"code","01253e0e":"code","666f8be9":"code","fc0990ce":"code","f37a4f07":"code","b7aac84d":"markdown","2ca576e1":"markdown","f67d34ee":"markdown","c683e1a6":"markdown","dd453ba7":"markdown","b4bc2c9d":"markdown","81be07cb":"markdown","c087d882":"markdown","46c24cac":"markdown","5692a238":"markdown","b27cf8a3":"markdown","5927b85f":"markdown","3def1ae0":"markdown","2e7f55ab":"markdown","89824d6d":"markdown","b61b1299":"markdown","d838c221":"markdown","c20874ca":"markdown","04dc0639":"markdown","5d635a6a":"markdown","6d740c7e":"markdown","1619d7e7":"markdown","e43c7a3d":"markdown","228e813a":"markdown","b267b34d":"markdown","cef673df":"markdown","a9ebc555":"markdown","e78f965d":"markdown","45489cce":"markdown","8cf0a992":"markdown","74c4d437":"markdown","ef2f7259":"markdown","66df4e80":"markdown","dec86956":"markdown","621b3593":"markdown","f708bbdf":"markdown","d8bca9d6":"markdown","cb99382f":"markdown","80a99388":"markdown","8cf32383":"markdown","85399026":"markdown","d2ed998c":"markdown","a0760a6f":"markdown","087598b0":"markdown","d1996bcd":"markdown","dee4f08b":"markdown","40292592":"markdown","4f2995ca":"markdown","8038bc01":"markdown","19d6ab8e":"markdown","d00e273b":"markdown","64805322":"markdown","6d22afda":"markdown","609d5c5a":"markdown","f16c382e":"markdown"},"source":{"225008d8":"# importing the neccessary libraries\n\n# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nfrom pandas.api.types import is_string_dtype,is_numeric_dtype\n\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# imputation\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.impute import KNNImputer\n\n# machine learning\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report,roc_curve,roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import confusion_matrix,accuracy_score,matthews_corrcoef,f1_score\nfrom sklearn import preprocessing\nfrom sklearn.feature_selection import SelectKBest, f_classif\n# Gradient Boosting\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nimport os\n\n","25f15500":"%pwd","ede616d6":"!ls","b9c59e60":"my_df = pd.read_csv('..\/input\/titanic-full\/Titanic_full.csv')","d49e8a70":"print(my_df.shape)\nmy_df.head(3)","8542837d":"# Using the info to see object types and null values in brief\nmy_df.info()","408bde6d":"# Let's see which all columns have no nulls. True: number of non-nulls, False: number of nulls\n\nfor column in my_df.columns:\n    print(my_df[column].notnull().value_counts())\n    print('\\t')","9e4fb208":"''' Deal with missing values. First, calculate the percentage of\nmissing values for every column, and plot them as a bar chart'''\n\nnull_vals = my_df.isnull().sum()\/len(my_df)*100\nnull_vals = pd.DataFrame(null_vals)\nnull_vals.reset_index(inplace = True)\nnull_vals.columns = [\"Feature\",\"Percent missing\"]\nplt.figure(figsize = (8,6))\nplt.xticks(rotation=45)\nbplot = sns.barplot(x = \"Feature\",y =\"Percent missing\",data = null_vals)\n\n# annotating the % of nulls on the bar\n# looping through each bar and using annotate function. In this function, we can format and place annotated text, like location of annotation, etc.\nfor p in bplot.patches:\n    bplot.annotate(format(p.get_height(), '.1f'), \n                   (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points')","dd5c160d":"# First of all, I will completely discard the \"Cabin\" column as there are too many missing values. Also, it is alphanumeric, so we would only be guessing\n# plus cabin number would probably not provide insight about survival. Pclass and Fare would in some way correlate to cabin, and those can \n# be used to provide insights about survival.","682f22fb":"# Dropping the Cabin column\nmy_df_dropped = my_df.drop('Cabin',axis=1)\nprint(my_df_dropped.shape)\nmy_df_dropped.head(5)","05fc5bb8":"# let's see the missing values again\n\nnull_vals_dropped = my_df_dropped.isnull().sum()\/len(my_df_dropped)*100\nnull_vals_dropped = pd.DataFrame(null_vals_dropped)\nnull_vals_dropped.reset_index(inplace = True)\nnull_vals_dropped.columns = [\"Feature\",\"Percent missing\"]\nplt.figure(figsize = (8,6))\nplt.xticks(rotation=45)\nbplot_dropped = sns.barplot(x = \"Feature\",y =\"Percent missing\",data = null_vals_dropped)\n\n# annotating the % of nulls on the bar\n# looping through each bar and using annotate function. In this function, we can format and place annotated text, like location of annotation, etc.\nfor p in bplot_dropped.patches:\n    bplot_dropped.annotate(format(p.get_height(), '.1f'), \n                   (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points')","81f051fb":"# So we have three columns with nulls\n# We will handle the missing values for categorical and continuous variables separately. \"Embarked\" is categorical and \"Age\" and \"Fare\" are continuous","b112e1fb":"# Let's start with the categorical type nulls\n# Let's see what is the mode for Embarked\nmy_df_dropped['Embarked'].describe()","1fbd878d":"# replacing missing values in \"Embarked\" with the mode\nmy_df_impute1_mid=my_df_dropped\nmy_df_impute1_mid['Embarked'].replace(to_replace=np.nan, value='S', inplace=True, limit=None, regex=False, method='pad')","064f7b87":"my_df_impute1_mid['Embarked'].describe()","f7337b44":"# now numeric imputation","cbe746cb":"# This should be the replaced null calue for \"Age\"\nmy_df_impute1_mid['Age'].mode()","b759d33a":"# for \"Fare\"\nmy_df_impute1_mid['Fare'].mode()","4dd577d6":"my_df_impute1_mid.columns","de616570":"my_df_impute1_mid.info()","fe63fb87":"# Using scikit learn's SimpleImputer, we will replace the nulls with the mode for the continuous variables\nimpute1 = SimpleImputer(missing_values=np.nan, strategy='most_frequent', fill_value='constant', verbose=0, copy=True, add_indicator=False)\nimpute1_fit = impute1.fit(my_df_impute1_mid)\nimpute1_transform = impute1.transform(my_df_impute1_mid)\n\n#Since the transorm operation on the dataframe returns an array, we will convert if back to a Dataframe and then add the same column names again\n# Also, the array will not retain the same dtypes. So we will input th same from previous dataframe and also change object to categorical at the same time\nimputed1_df=pd.DataFrame(data=impute1_transform)\nimputed1_df.columns = ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n       'Parch', 'Ticket', 'Fare', 'Embarked']\nimputed1_df = imputed1_df.astype({'PassengerId':'int64', 'Survived':'int64','Pclass':'int64', 'Name':'category', 'Sex':'category', 'Age':'float64', 'SibSp':'int64',\n       'Parch':'int64', 'Ticket':'category', 'Fare':'float64', 'Embarked':'category'}) \nimputed1_df\n","d712b3f4":"imputed1_df.info()","02716de9":"imputed1_df['Age'].isnull().value_counts()","ab45f6b8":"imputed1_df['Fare'].isnull().value_counts()","de461163":"# let's see the missing values again\n\nnull_vals_dropped1 = imputed1_df.isnull().sum()\/len(imputed1_df)*100\nnull_vals_dropped1 = pd.DataFrame(null_vals_dropped1)\nnull_vals_dropped1.reset_index(inplace = True)\nnull_vals_dropped1.columns = [\"Feature\",\"Percent missing\"]\nplt.figure(figsize = (8,6))\nplt.xticks(rotation=45)\nbplot_dropped1 = sns.barplot(x = \"Feature\",y =\"Percent missing\",data = null_vals_dropped1)\n\n# annotating the % of nulls on the bar\n# looping through each bar and using annotate function. In this function, we can format and place annotated text, like location of annotation, etc.\nfor p in bplot_dropped1.patches:\n    bplot_dropped1.annotate(format(p.get_height(), '.1f'), \n                   (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points')","59a4c42f":"imputed1_df.info()","0532525b":"imputed1_df\n\n","3220341d":"'''I'm using the same functions defined in the provided code for converting the categorical features to numbers.\nSince the nulls have already been handled, the null_table will be empty'''\n\ndef mydf_to_nums(my_df, feature, null_status):\n    if not is_numeric_dtype(feature):\n        my_df[null_status] = feature.cat.codes\n\ndef mydf_preprocessor(my_df, null_table):\n    '''null_table  = your table or None'''\n    \n    if null_table is None: \n        null_table = dict()\n    for p,q in my_df.items(): \n        mydf_to_nums(my_df, q, p)\n    my_df = pd.get_dummies(my_df, dummy_na = True)\n    res = [my_df, null_table]\n    return res","a7d5149c":"my_df_impute1,my_table = mydf_preprocessor(imputed1_df,null_table = None)","7c3e269d":"my_df_impute1","620fbe55":"'''Now, let's separate the X and Y variables (vertical split of the \ndataframe). Here the Y column is the variable we are trying to predict, \nsurvived or not(0 = No, 1 = Yes)'''\n\nY = my_df_impute1[\"Survived\"]\nX = my_df_impute1.drop([\"Survived\"],axis = 1)\n\nprint(X.shape,Y.shape)","18e026f2":"# Doing a vertical split on the continuous and categorical features\n\nX_cat = X[['PassengerId', 'Pclass', 'Name', 'Sex', 'SibSp', 'Parch',\n       'Ticket', 'Embarked']]\nX_con = X.drop(X_cat,axis = 1)\nprint(X_cat.shape,X_con.shape)","1b565d64":"'''Scale the continuous variables. To standardize (includes scaling), \nwe subtract mean of that column from every value, then divide the results \nby the variable's standard deviation. There are different ways to \nstandardize. Please see preprocessing under scikit-leanr page'''\n\nscaler = preprocessing.StandardScaler().fit(X_con)\nX_con_sc = pd.DataFrame(scaler.transform(X_con))\nX_con_sc.columns = [\"Age\",\"Fare\"]\nprint(X_con_sc.shape)\nX_con_sc.head(2)","f0925f52":"''' Now, let's join the cateogrical and scaled continuous \nvariables, back together into one dataframe'''\n\ndf_list = [X_cat,X_con_sc]\nX_full = pd.concat(df_list,axis = 1)\nprint(X_full.shape)\nX_full.head(2)","6bb4e819":"def mydf_splitter(my_df,num_rows):\n    return my_df[:num_rows].copy(),my_df[num_rows:]\n\n\nmydf_train_valid_x,mydf_test_x = mydf_splitter(X_full,1100)\nmydf_train_valid_y,mydf_test_y = mydf_splitter(Y,1100)\n\nprint(\"Train-valid X: \",mydf_train_valid_x.shape,\"\\nTest X: \",mydf_test_x.shape)\nprint(\"\\nTrain-valid Y: \",mydf_train_valid_y.shape,\"\\nTest Y: \",mydf_test_y.shape)","fe290a97":"X_valid,X_train = mydf_splitter(mydf_train_valid_x,200)\nY_valid,Y_train = mydf_splitter(mydf_train_valid_y,200)\n\nprint(\"Train X: \",X_train.shape,\"\\nValid X: \",X_valid.shape,\"\\nTrain Y: \",Y_train.shape,\"\\nValid Y: \",Y_valid.shape)","f7bcea2e":"# Building the model with train and valid set and k = 33 (as per hyperparameter tuning from previous trials)\n\nmy_knn_model = KNeighborsClassifier(n_neighbors = 33,weights = 'uniform')\nmy_knn_model.fit(X_train,Y_train)\n\n#Predict on the test set\nY_pred_valid = my_knn_model.predict(X_valid)","7d4ac2d9":"# accuracy score\n\naccuracy_score(Y_valid,Y_pred_valid)","b0507a21":"'''Make a confusion matrix for the K = 33 model based validation set predictions.\nMake a pandas dataframe out of it so that we can use seaborn to \nplot it easily'''\n\nc_mat_1 = confusion_matrix(Y_valid,Y_pred_valid)\nc_mat_df_1 = pd.DataFrame(c_mat_1)\nc_mat_df_1.head(2)","27447725":"# Make a heatmap of the confusion matrix with seaborn\n\nplt.figure(figsize = (8,6))\nsns.heatmap(c_mat_df_1,annot = True,fmt = 'g')\nplt.xlabel(\"Actual\")\nplt.ylabel(\"Predicted\")","8db5d31d":"print(c_mat_df_1)\ntp_knn_1 = c_mat_df_1.loc[0,0]\nprint('tp_1 = ',tp_knn_1)\n\ntn_knn_1 = c_mat_df_1.loc[1,1]\nprint('tn_1 = ',tn_knn_1)\n\nfp_knn_1 = c_mat_df_1.loc[0,1]\nprint('fp_1 = ',fp_knn_1)\n\nfn_knn_1 = c_mat_df_1.loc[1,0]\nprint('fn_1 = ',fn_knn_1)\n\n# Recall (Sensitivity) = tp\/tp+fn, Precision = tp\/tp+fp\n\nrecall_knn_1 = tp_knn_1\/(tp_knn_1+fn_knn_1)\nprecision_knn_1 = tp_knn_1\/(tp_knn_1+fp_knn_1)\nprint('\\nrecall_1 = ',recall_knn_1,'     precision_1 = ',precision_knn_1)\n\n#F1 score = 2*(precision * recall)\/precision + recall\n\nf_score_knn_1 = (2*recall_knn_1*precision_knn_1)\/(recall_knn_1+precision_knn_1)\nprint('\\nf1 score_1 = ',f_score_knn_1)\n\n# using the built in scikit-learn function to do this at one go!\n\nscores_knn_1 = classification_report(Y_valid,Y_pred_valid)\nprint('\\nscores_1 = \\n',scores_knn_1)\n\nrec_knn_1, fall_out_knn_1, thresholds_knn_1 = roc_curve(Y_valid,Y_pred_valid)\n\nplt.plot([0,1],[0,1],'ro--')\nplt.plot(rec_knn_1,fall_out_knn_1, label='my_knn_df_1')\nplt.xlabel('Fall out')\nplt.ylabel('Recall\/Sensitivity')\nplt.title('Knn(n_neighbors=33) ROC curve')\nplt.show()","4d938c76":"# Let's check the test data\nmydf_test_x","ac5fbb3a":"# Assigning Y_t to y test and X_t to x test dataframes\n\n\nY_t = mydf_test_y\nX_t = mydf_test_x\n\nprint(X_t.shape,Y_t.shape)","28b9a34b":"X_t","46638244":"Y_t","8b9bca78":"X_full","8ff4a6f3":"# Building the model with train and test set and k = 33\n\nmy_knn_model_test = KNeighborsClassifier(n_neighbors = 33,weights = 'uniform')\nmy_knn_model_test.fit(X_full,Y)\n\n#Predict on the test set\nY_pred_test = my_knn_model.predict(X_t)","1426fb3c":"# accuracy score\n\naccuracy_score(Y_t,Y_pred_test)","b2a51387":"'''Make a confusion matrix for the K = 33 model based validation set predictions.\nMake a pandas dataframe out of it so that we can use seaborn to \nplot it easily'''\n\nc_mat_t = confusion_matrix(Y_t,Y_pred_test)\nc_mat_df_t = pd.DataFrame(c_mat_t)\nc_mat_df_t.head(2)","a512aa47":"# Make a heatmap of the confusion matrix with seaborn\n\nplt.figure(figsize = (8,6))\nsns.heatmap(c_mat_df_t,annot = True,fmt = 'g')\nplt.xlabel(\"Actual\")\nplt.ylabel(\"Predicted\")","db69f637":"print(c_mat_df_t)\ntp_knn_t = c_mat_df_t.loc[0,0]\nprint('tp_t = ',tp_knn_t)\n\ntn_knn_t = c_mat_df_t.loc[1,1]\nprint('tn_t = ',tn_knn_t)\n\nfp_knn_t = c_mat_df_t.loc[0,1]\nprint('fp_t = ',fp_knn_t)\n\nfn_knn_t = c_mat_df_t.loc[1,0]\nprint('fn_t = ',fn_knn_t)\n\n# Recall (Sensitivity) = tp\/tp+fn, Precision = tp\/tp+fp\n\nrecall_knn_t = tp_knn_t\/(tp_knn_t+fn_knn_t)\nprecision_knn_t = tp_knn_t\/(tp_knn_t+fp_knn_t)\nprint('\\nrecall_t = ',recall_knn_t,'     precision_t = ',precision_knn_t)\n\n#F1 score = 2*(precision * recall)\/precision + recall\n\nf_score_knn_t = (2*recall_knn_t*precision_knn_t)\/(recall_knn_t+precision_knn_t)\nprint('\\nf1 score_t = ',f_score_knn_t)\n\n# using the built in scikit-learn function to do this at one go!\n\nscores_knn_t = classification_report(Y_t,Y_pred_test)\nprint('\\nscores_t = \\n',scores_knn_t)\n\nrec_knn_t, fall_out_knn_t, thresholds_knn_t = roc_curve(Y_t,Y_pred_test)\n\nplt.plot([0,1],[0,1],'ro--')\nplt.plot(rec_knn_t,fall_out_knn_t, label='my_knn_df_t')\nplt.xlabel('Fall out')\nplt.ylabel('Recall\/Sensitivity')\nplt.title('Knn(n_neighbors=33) ROC curve')\nplt.show()","1e2cf6fe":"my_df_dropped.info()","b420cc76":"my_df_dropped","b8794621":"'''You can see that several of the columns or features are \"object\" type\nThese need to be changed to category before we can convert those to \nmappings and numbers'''\n#1 (a) Define a function to convert object types and string types to category type\n\ndef str_to_cat(my_df):\n    for p,q in my_df.items(): #my_df.items() is a generator in Python\n        if is_string_dtype(q): \n            my_df[p] = q.astype('category').cat.as_ordered()\n    return my_df","563d6419":"my_df_impute2_mid = str_to_cat(my_df_dropped)","c4aba060":"\nmy_df_impute2_mid.info()\n","126a4475":"# We have to first convert the strings to numbers before using the KNNImputer\n\nmy_df_impute2,my_table = mydf_preprocessor(my_df_impute2_mid,null_table = None)","af33ed01":"my_df_impute2","af2a871c":"# Using the KNNImputer from scikit learn to impute the missing values with K = 5\n\nimputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n\nmy_df_impute2['Age'] = imputer.fit_transform(my_df_impute2[['Age']])\nmy_df_impute2['Fare'] = imputer.fit_transform(my_df_impute2[['Fare']])\n\nprint(my_df_impute2)","233d7d51":"# Imputation successfull","be9c084b":"# So we'll start with the train_valid-test split \n# Then we need to preprocess the data","de96eedd":"'''Now, let's separate the X and Y variables (vertical split of the \ndataframe). Here the Y column is the variable we are trying to predict, \nsurvived or not(0 = No, 1 = Yes)'''\n\nY2 = my_df_impute2[\"Survived\"]\nX2 = my_df_impute2.drop([\"Survived\"],axis = 1)\n\nprint(X2.shape,Y2.shape)","393f0e3d":"# Doing a vertical split on the continuous and categorical features\n\nX_cat2 = X2[['PassengerId', 'Pclass', 'Name', 'Sex', 'SibSp', 'Parch',\n       'Ticket', 'Embarked']]\nX_con2 = X2.drop(X_cat2,axis = 1)\nprint(X_cat2.shape,X_con2.shape)","4aa07129":"'''Scale the continuous variables. To standardize (includes scaling), \nwe subtract mean of that column from every value, then divide the results \nby the variable's standard deviation. There are different ways to \nstandardize. Please see preprocessing under scikit-leanr page'''\n\nscaler2 = preprocessing.StandardScaler().fit(X_con2)\nX_con_sc2 = pd.DataFrame(scaler.transform(X_con2))\nX_con_sc2.columns = [\"Age\",\"Fare\"]\nprint(X_con_sc2.shape)\nX_con_sc2.head(2)","9c7d0057":"''' Now, let's join the cateogrical and scaled continuous \nvariables, back together into one dataframe'''\n\ndf_list2 = [X_cat2,X_con_sc2]\nX_full2 = pd.concat(df_list2,axis = 1)\nprint(X_full2.shape)\nX_full2.head(2)","9b1845d5":"def mydf_splitter(my_df,num_rows):\n    return my_df[:num_rows].copy(),my_df[num_rows:]\n\n\nmydf_train_valid_x2,mydf_test_x2 = mydf_splitter(X_full2,1100)\nmydf_train_valid_y2,mydf_test_y2 = mydf_splitter(Y2,1100)\n\nprint(\"Train-valid X: \",mydf_train_valid_x2.shape,\"\\nTest X: \",mydf_test_x2.shape)\nprint(\"\\nTrain-valid Y: \",mydf_train_valid_y2.shape,\"\\nTest Y: \",mydf_test_y2.shape)","3b3903b2":"X_valid2,X_train2 = mydf_splitter(mydf_train_valid_x2,200)\nY_valid2,Y_train2 = mydf_splitter(mydf_train_valid_y2,200)\n\nprint(\"Train X: \",X_train2.shape,\"\\nValid X: \",X_valid2.shape,\"\\nTrain Y: \",Y_train2.shape,\"\\nValid Y: \",Y_valid2.shape)","208719da":"# Building the model with train and valid set and k = 33\n\nmy_knn_model2 = KNeighborsClassifier(n_neighbors = 33,weights = 'uniform')\nmy_knn_model2.fit(X_train2,Y_train2)\n\n#Predict on the test set\nY_pred_valid2 = my_knn_model2.predict(X_valid2)","16be0c4b":"# accuracy score\n\naccuracy_score(Y_valid2,Y_pred_valid2)","e3f075eb":"'''Make a confusion matrix for the K = 5 model based validation set predictions.\nMake a pandas dataframe out of it so that we can use seaborn to \nplot it easily'''\n\nc_mat_2 = confusion_matrix(Y_valid2,Y_pred_valid2)\nc_mat_df_2 = pd.DataFrame(c_mat_2)\nc_mat_df_2.head(2)","c164065e":"# Make a heatmap of the confusion matrix with seaborn\n\nplt.figure(figsize = (8,6))\nsns.heatmap(c_mat_df_2,annot = True,fmt = 'g')\nplt.xlabel(\"Actual\")\nplt.ylabel(\"Predicted\")","9e602937":"print(c_mat_df_2)\ntp_knn_2 = c_mat_df_2.loc[0,0]\nprint('tp_2 = ',tp_knn_2)\n\ntn_knn_2 = c_mat_df_2.loc[1,1]\nprint('tn_2 = ',tn_knn_2)\n\nfp_knn_2 = c_mat_df_2.loc[0,1]\nprint('fp_2 = ',fp_knn_2)\n\nfn_knn_2 = c_mat_df_2.loc[1,0]\nprint('fn_2 = ',fn_knn_2)\n\n# Recall (Sensitivity) = tp\/tp+fn, Precision = tp\/tp+fp\n\nrecall_knn_2 = tp_knn_2\/(tp_knn_2+fn_knn_2)\nprecision_knn_2 = tp_knn_2\/(tp_knn_2+fp_knn_2)\nprint('\\nrecall_2 = ',recall_knn_2,'     precision_2 = ',precision_knn_2)\n\n#F1 score = 2*(precision * recall)\/precision + recall\n\nf_score_knn_2 = (2*recall_knn_2*precision_knn_2)\/(recall_knn_2+precision_knn_2)\nprint('\\nf1 score_2 = ',f_score_knn_2)\n\n# using the built in scikit-learn function to do this at one go!\n\nscores_knn_2 = classification_report(Y_valid2,Y_pred_valid2)\nprint('\\nscores_2 = \\n',scores_knn_2)\n\nrec_knn_2, fall_out_knn_2, thresholds_knn_2 = roc_curve(Y_valid2,Y_pred_valid2)\n\nplt.plot([0,1],[0,1],'ro--')\nplt.plot(rec_knn_2,fall_out_knn_2, label='my_knn_df_2')\nplt.xlabel('Fall out')\nplt.ylabel('Recall\/Sensitivity')\nplt.title('Knn(n_neighbors=33) ROC curve')\nplt.show()\n","c1647938":"# Let's check the test data\nmydf_test_x","da82ec53":"# Assigning Y_t to y test and X_t to x test dataframes\n\n\nY_t = mydf_test_y\nX_t = mydf_test_x\n\nprint(X_t.shape,Y_t.shape)","96829f3e":"# Building the model with train and test set and k = 33\n\nmy_knn_model_test2 = KNeighborsClassifier(n_neighbors = 33,weights = 'uniform')\nmy_knn_model_test2.fit(X_full2,Y)\n\n#Predict on the test set\nY_pred_test2 = my_knn_model.predict(X_t)","859c2237":"# accuracy score\n\naccuracy_score(Y_t,Y_pred_test2)","799335c3":"'''Make a confusion matrix for the K = 5 model based validation set predictions.\nMake a pandas dataframe out of it so that we can use seaborn to \nplot it easily'''\n\nc_mat_t = confusion_matrix(Y_t,Y_pred_test2)\nc_mat_df_t = pd.DataFrame(c_mat_t)\nc_mat_df_t.head(2)","723420e9":"# Make a heatmap of the confusion matrix with seaborn\n\nplt.figure(figsize = (8,6))\nsns.heatmap(c_mat_df_t,annot = True,fmt = 'g')\nplt.xlabel(\"Actual\")\nplt.ylabel(\"Predicted\")","ee5d550b":"print(c_mat_df_t)\ntp_knn_t = c_mat_df_t.loc[0,0]\nprint('tp_t = ',tp_knn_t)\n\ntn_knn_t = c_mat_df_t.loc[1,1]\nprint('tn_t = ',tn_knn_t)\n\nfp_knn_t = c_mat_df_t.loc[0,1]\nprint('fp_t = ',fp_knn_t)\n\nfn_knn_t = c_mat_df_t.loc[1,0]\nprint('fn_t = ',fn_knn_t)\n\n# Recall (Sensitivity) = tp\/tp+fn, Precision = tp\/tp+fp\n\nrecall_knn_t = tp_knn_t\/(tp_knn_t+fn_knn_t)\nprecision_knn_t = tp_knn_t\/(tp_knn_t+fp_knn_t)\nprint('\\nrecall_t = ',recall_knn_t,'     precision_t = ',precision_knn_t)\n\n#F1 score = 2*(precision * recall)\/precision + recall\n\nf_score_knn_t = (2*recall_knn_t*precision_knn_t)\/(recall_knn_t+precision_knn_t)\nprint('\\nf1 score_t = ',f_score_knn_t)\n\n# using the built in scikit-learn function to do this at one go!\n\nscores_knn_t = classification_report(Y_t,Y_pred_test2)\nprint('\\nscores_t = \\n',scores_knn_t)\n\nrec_knn_t, fall_out_knn_t, thresholds_knn_t = roc_curve(Y_t,Y_pred_test2)\n\nplt.plot([0,1],[0,1],'ro--')\nplt.plot(rec_knn_t,fall_out_knn_t, label='my_knn_df_t')\nplt.xlabel('Fall out')\nplt.ylabel('Recall\/Sensitivity')\nplt.title('Knn(n_neighbors=33) ROC curve')\nplt.show()","25ac2da1":"# On the Titanic dataset, using both imputation techniques, there is no change in the model accuracy when using K-NN\n# Now we will try GradientBoosting and see how the model performs on this dataset","cf6cf807":"# Using the default values of GradientBoostingClassifier from sklearn.ensemble\n\nmy_GB_model = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort='deprecated', validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)","d8ab9ec0":"# Fitting the model on the training set and predicting on validation set\n\nmy_GB_model.fit(X_train,Y_train)\n\nY_pred_GB = my_GB_model.predict(X_valid)","7ccadd96":"# accuracy score\n\naccuracy_score(Y_valid,Y_pred_GB)","e4abbb81":"c_mat_GB = confusion_matrix(Y_valid,Y_pred_GB)\nc_mat_df_GB = pd.DataFrame(c_mat_GB)\nc_mat_df_GB.head(2)","42076c62":"# Make a heatmap of the confusion matrix with seaborn\n\nplt.figure(figsize = (8,6))\nsns.heatmap(c_mat_df_GB,annot = True,fmt = 'g')\nplt.xlabel(\"Actual\")\nplt.ylabel(\"Predicted\")","53c4ac55":"print(c_mat_df_GB)\ntp_GB = c_mat_df_GB.loc[0,0]\nprint('tp_GB = ',tp_GB)\n\ntn_GB = c_mat_df_GB.loc[1,1]\nprint('tn_GB = ',tn_GB)\n\nfp_GB = c_mat_df_GB.loc[0,1]\nprint('fp_GB = ',fp_GB)\n\nfn_GB = c_mat_df_GB.loc[1,0]\nprint('fn_GB = ',fn_GB)\n\n# Recall (Sensitivity) = tp\/tp+fn, Precision = tp\/tp+fp\n\nrecall_GB = tp_GB\/(tp_GB+fn_GB)\nprecision_GB = tp_GB\/(tp_GB+fp_GB)\nprint('\\nrecall_GB = ',recall_GB,'     precision_GB = ',precision_GB)\n\n#F1 score = 2*(precision * recall)\/precision + recall\n\nf_score_GB = (2*recall_GB*precision_GB)\/(recall_GB+precision_GB)\nprint('\\nf1 score_GB = ',f_score_GB)\n\n# using the built in scikit-learn function to do this at one go!\n\nscores_GB = classification_report(Y_valid,Y_pred_GB)\nprint('\\nscores_GB = \\n',scores_GB)\n\nrec_GB, fall_out_GB, thresholds_GB = roc_curve(Y_valid,Y_pred_GB)\n\nplt.plot([0,1],[0,1],'ro--')\nplt.plot(rec_GB,fall_out_GB, label='my_GB_df')\nplt.xlabel('Fall out_GB')\nplt.ylabel('Recall\/Sensitivity_GB')\nplt.title('GB_train-valid(n_estimators=100) ROC curve')\nplt.show()\n","5c3b3479":"# generalization error\n\ndist_code_t = sns.distplot(Y_valid,hist=False,color='r',label='Actual Value')\nsns.distplot(Y_pred_GB,hist=False,color='b',label='Predicted Value',ax=dist_code_t)","3d57cdb4":"# With the distribution plot, we can see a comparison between the actual and predicted Y values. \n# The curves are very similar for both. Which is a good sign that the model is performing well on the validation set at least\n# Let's now see how it performs on the test set","14e09b61":"# Using the default values of GradientBoostingClassifier from sklearn.enemble\n\nmy_GB_model_t = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort='deprecated', validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)","88264a86":"# Fitting the model on the training-validation set and predicting on test set\n\nmy_GB_model_t.fit(X_full,Y)\n\n\nY_pred_GB_t = my_GB_model_t.predict(X_t)\n","8b6190af":"# accuracy score\n\naccuracy_score(Y_t,Y_pred_GB_t)","6fbd2703":"'''Make a confusion matrix for the n_estimators=100 model based validation set predictions.\nMake a pandas dataframe out of it so that we can use seaborn to \nplot it easily'''\n\nc_mat_GB_t = confusion_matrix(Y_t,Y_pred_GB_t)\nc_mat_df_GB_t = pd.DataFrame(c_mat_GB_t)\nc_mat_df_GB_t.head(2)","60b886a1":"# Make a heatmap of the confusion matrix with seaborn\n\nplt.figure(figsize = (8,6))\nsns.heatmap(c_mat_df_GB_t,annot = True,fmt = 'g')\nplt.xlabel(\"Actual\")\nplt.ylabel(\"Predicted\")","431a3fa1":"print(c_mat_df_GB_t)\ntp_GB_t = c_mat_df_GB_t.loc[0,0]\nprint('tp_GB_t = ',tp_GB_t)\n\ntn_GB_t = c_mat_df_GB_t.loc[1,1]\nprint('tn_GB_t = ',tn_GB_t)\n\nfp_GB_t = c_mat_df_GB_t.loc[0,1]\nprint('fp_GB_t = ',fp_GB_t)\n\nfn_GB_t = c_mat_df_GB_t.loc[1,0]\nprint('fn_GB_t = ',fn_GB_t)\n\n# Recall (Sensitivity) = tp\/tp+fn, Precision = tp\/tp+fp\n\nrecall_GB_t = tp_GB_t\/(tp_GB_t+fn_GB_t)\nprecision_GB_t = tp_GB_t\/(tp_GB_t+fp_GB_t)\nprint('\\nrecall_GB_t = ',recall_GB_t,'     precision_GB_t = ',precision_GB_t)\n\n#F1 score = 2*(precision * recall)\/precision + recall\n\nf_score_GB_t = (2*recall_GB_t*precision_GB_t)\/(recall_GB_t+precision_GB_t)\nprint('\\nf1 score_GB_t = ',f_score_GB_t)\n\n# using the built in scikit-learn function to do this at one go!\n\nscores_GB_t = classification_report(Y_t,Y_pred_GB_t)\nprint('\\nscores_GB_t = \\n',scores_GB_t)\n\nrec_GB_t, fall_out_GB_t, thresholds_GB_t = roc_curve(Y_t,Y_pred_GB_t)\n\nplt.plot([0,1],[0,1],'ro--')\nplt.plot(rec_GB_t,fall_out_GB_t, label='my_df_GB_t')\nplt.xlabel('Fall out')\nplt.ylabel('Recall\/Sensitivity')\nplt.title('GB_train_valid-test(n_estimators=100) ROC curve')\nplt.show()\n","ededb737":"# Creating two lists, \n# one for the number of estimators \n# and one for acuracy and looping over n_estimators: 1 to 1000\n\nnum_estimators = list()\naccuracy_list_GB = list()\n\n\nfor estimator in range(1,1001):\n    my_GB_model_exp = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=estimator, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort='deprecated', validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n    my_GB_model_exp.fit(X_train,Y_train)\n    Y_pred_GB_exp = my_GB_model_exp.predict(X_valid)\n    accuracy_GB_exp = accuracy_score(Y_valid,Y_pred_GB_exp)\n    num_estimators.append(estimator)\n    accuracy_list_GB.append(accuracy_GB_exp)","07567408":"# Converting the estimator-accuracy lists to a dataframe. \n# Note: This operation takes about 10 mins to complete on my machine as 1100 GB models will be created (n_estimators: 1 to 1000)\n\neval_df_GB =  pd.DataFrame({\"Num of estimators\": num_estimators,\"Valid accuracy Score\": accuracy_list_GB})\neval_df_GB","16cad726":"#Plot accuracy Vs validation set accuracy of the model\nsns.set_style(\"whitegrid\")\nsns.pairplot(eval_df_GB,x_vars = \"Num of estimators\",\n             y_vars = \"Valid accuracy Score\",plot_kws = {'s': 60},height = 4.0,size=5)","9ba211cf":"# Let's see the highest accuracy score\n\neval_df_GB['Valid accuracy Score'].max()","35a04357":"# Let's see for which value of n_estimators we get the highest accuracy\n\neval_df_GB[eval_df_GB['Valid accuracy Score']==eval_df_GB['Valid accuracy Score'].max()]","fcbebf32":"\n# Let's now evaluate the classifier accuracy and plot the AUC for GradientBoosting model with n_estimators of 61\n# When we create 61 decision trees, we are able to achieve the highest accuracy. ","28ddea90":"# Training the model and evaluating using n_estimators=61 on the validation set using GradientBoosting\n\nmy_GB_model_n61 = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=61, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort='deprecated', validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\nmy_GB_model_n61.fit(X_train,Y_train)\n\n# Predict on the validation set\nY_pred_GB_n61 = my_GB_model_n61.predict(X_valid)","09a120a5":"# Training the model and evaluating it on the validation set using n_estimators=61\n\nmy_GB_model_n61_t = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=61, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort='deprecated', validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\nmy_GB_model_n61_t.fit(X_full,Y)\n\n# Predict on the test set\nY_pred_GB_n61_t = my_GB_model_n61_t.predict(X_t)","adc07200":"# accuracy score\n\naccuracy_score(Y_valid,Y_pred_GB_n61)","a92f845a":"c_mat_GB_n61 = confusion_matrix(Y_valid,Y_pred_GB_n61)\nc_mat_df_GB_n61 = pd.DataFrame(c_mat_GB_n61)\nc_mat_df_GB_n61.head(2)","c2663094":"# Make a heatmap of the confusion matrix with seaborn\n\nplt.figure(figsize = (8,6))\nsns.heatmap(c_mat_df_GB_n61,annot = True,fmt = 'g')\nplt.xlabel(\"Actual\")\nplt.ylabel(\"Predicted\")","89c698fa":"print(c_mat_df_GB_n61)\ntp_GB_n61 = c_mat_df_GB_n61.loc[0,0]\nprint('tp_GB_n61 = ',tp_GB_n61)\n\ntn_GB_n61 = c_mat_df_GB_n61.loc[1,1]\nprint('tn_GB_n61 = ',tn_GB_n61)\n\nfp_GB_n61 = c_mat_df_GB_n61.loc[0,1]\nprint('fp_GB_n61 = ',fp_GB_n61)\n\nfn_GB_n61 = c_mat_df_GB_n61.loc[1,0]\nprint('fn_GB_n61 = ',fn_GB_n61)\n\n# Recall (Sensitivity) = tp\/tp+fn, Precision = tp\/tp+fp\n\nrecall_GB_n61 = tp_GB_n61\/(tp_GB_n61+fn_GB_n61)\nprecision_GB_n61 = tp_GB_n61\/(tp_GB_n61+fp_GB_n61)\nprint('\\nrecall_GB_n61 = ',recall_GB_n61,'     precision_GB_n61 = ',precision_GB_n61)\n\n#F1 score = 2*(precision * recall)\/precision + recall\n\nf_score_GB_n61 = (2*recall_GB_n61*precision_GB_n61)\/(recall_GB_n61+precision_GB_n61)\nprint('\\nf1 score_GB_n61 = ',f_score_GB_n61)\n\n# using the built in scikit-learn function to do this at one go!\n\nscores_GB_n61 = classification_report(Y_valid,Y_pred_GB_n61)\nprint('\\nscores_GB_n61 = \\n',scores_GB_n61)\n\nrec_GB_n61, fall_out_GB_n61, thresholds_GB_n61 = roc_curve(Y_valid,Y_pred_GB_n61)\n\nplt.plot([0,1],[0,1],'ro--')\nplt.plot(rec_GB_n61,fall_out_GB_n61, label='my_GB_n61_df')\nplt.xlabel('Fall out_GB_n61')\nplt.ylabel('Recall\/Sensitivity_GB_n61')\nplt.title('GB_n61_train-valid(n_estimators=61) ROC curve')\nplt.show()\n","eb1e1ba0":"# accuracy score\n\naccuracy_score(Y_t,Y_pred_GB_n61_t)","01253e0e":"'''Make a confusion matrix for the n_estimators=100 model based validation set predictions.\nMake a pandas dataframe out of it so that we can use seaborn to \nplot it easily'''\n\nc_mat_GB_n61_t = confusion_matrix(Y_t,Y_pred_GB_n61_t)\nc_mat_df_GB_n61_t = pd.DataFrame(c_mat_GB_n61_t)\nc_mat_df_GB_n61_t.head(2)","666f8be9":"# Make a heatmap of the confusion matrix with seaborn\n\nplt.figure(figsize = (8,6))\nsns.heatmap(c_mat_df_GB_n61_t,annot = True,fmt = 'g')\nplt.xlabel(\"Actual\")\nplt.ylabel(\"Predicted\")","fc0990ce":"print(c_mat_df_GB_n61_t)\ntp_GB_n61_t = c_mat_df_GB_n61_t.loc[0,0]\nprint('tp_GB_n61_t = ',tp_GB_n61_t)\n\ntn_GB_n61_t = c_mat_df_GB_n61_t.loc[1,1]\nprint('tn_GB_n61_t = ',tn_GB_n61_t)\n\nfp_GB_n61_t = c_mat_df_GB_n61_t.loc[0,1]\nprint('fp_GB_n61_t = ',fp_GB_n61_t)\n\nfn_GB_n61_t = c_mat_df_GB_n61_t.loc[1,0]\nprint('fn_GB_n61_t = ',fn_GB_n61_t)\n\n# Recall (Sensitivity) = tp\/tp+fn, Precision = tp\/tp+fp\n\nrecall_GB_n61_t = tp_GB_n61_t\/(tp_GB_n61_t+fn_GB_n61_t)\nprecision_GB_n61_t = tp_GB_n61_t\/(tp_GB_n61_t+fp_GB_n61_t)\nprint('\\nrecall_GB_n61_t = ',recall_GB_n61_t,'     precision_GB_n61_t = ',precision_GB_n61_t)\n\n#F1 score = 2*(precision * recall)\/precision + recall\n\nf_score_GB_n61_t = (2*recall_GB_n61_t*precision_GB_n61_t)\/(recall_GB_n61_t+precision_GB_n61_t)\nprint('\\nf1 score_GB_n61_t = ',f_score_GB_n61_t)\n\n# using the built in scikit-learn function to do this at one go!\n\nscores_GB_n61_t = classification_report(Y_t,Y_pred_GB_n61_t)\nprint('\\nscores_GB_n61_t = \\n',scores_GB_n61_t)\n\nrec_GB_n61_t, fall_out_GB_n61_t, thresholds_GB_n61_t = roc_curve(Y_t,Y_pred_GB_n61_t)\n\nplt.plot([0,1],[0,1],'ro--')\nplt.plot(rec_GB_n61_t,fall_out_GB_n61_t, label='my_df_GB_n61_t')\nplt.xlabel('Fall out')\nplt.ylabel('Recall\/Sensitivity')\nplt.title('GB_n61_train_valid-test(n_estimators=61) ROC curve')\nplt.show()","f37a4f07":"# CONCLUSION:\n# 1. Ensemble techniques can greatly improve prediction performance for a dataset\n# 2. Increasing number of decision trees may improve performance in GradientBoosting, upto certain number of trees. But, the model is succeptible to being overfit.","b7aac84d":">>> #### *Receiver Operating Characteristic (ROC) and Area Under the Curve (AUC)*","2ca576e1":"### *Train - Valid evaluation*","f67d34ee":">> ### Building the model","c683e1a6":">>> #### *Confusion matrix, Recall, and Precision*","dd453ba7":" **From the ROC curve for both train-valid and test predictions, we can see that the prediction is much better by using GradientBoosting<\/br>**\n**Bias and variance is low as the model neither seems too under-fitted nor too over-fitted<\/br>**","b4bc2c9d":">>> #### *Confusion matrix, Recall, and Precision*","81be07cb":">>> #### *Receiver Operating Characteristic (ROC) and Area Under the Curve (AUC)*","c087d882":"\n\n--------------------------------------------------------------------------------------------------------\n<\/br>\n\n## Evaluating classifier accuracies (GradientBoosting with n_estimators=61)","46c24cac":"> ## Using the train_valid-test data","5692a238":"#### Confusion matrix, Recall, and Precision","b27cf8a3":"### As per the graph above, it does not seem like that the theory is true after some number of deciscion trees\nWe can see that there is a rise in accuracy for a ertain number of D-Trees (under 100) and then there is a dip, followed by a near-constant accuracy curve","5927b85f":"--------------------------------------------------------------------------------------------------------\n<\/br>\n\n### Imputation technique 2.  Using k-NN to impute nulls","3def1ae0":"## This Notebook is divided into three main sections:\n#### Section A: Data Imputation Techniques \n#### Section B: GradientBoosting Implementation on the Titanic Dataset \n#### Section C: Testing a theory on increasing number of decision trees (n_estimators) for GradientBoosting \n<\/br>\n\n","2e7f55ab":"<\/br>\n\n#### \u2022\tBuilding a GradientBoosting model with default hyperparameter values\n\n> - Using the train-valid data\n\n>> Building the model<\/br>\n>>  Evaluating Classifier Accuracy\n\n> - Using the train_valid-test data\n\n>> Building the model<\/br>\n>> Evaluating Classifier Accuracy\n","89824d6d":">>> #### *Receiver Operating Characteristic (ROC) and Area Under the Curve (AUC)*","b61b1299":"#### Confusion matrix, Recall, and Precision","d838c221":"<br>\n\n> ## Using the train_valid-test data","c20874ca":">> ### Building the model","04dc0639":"#### Receiver Operating Characteristic (ROC) and Area Under the Curve (AUC)","5d635a6a":"#### Summary:\n\nModel: k-NN with n = 33 using imputation technique 1 (mode)<\/br>\nAccuracy (train-valid): 0.595<\/br>\nF1-Score (train-valid): 0.7096774193548389<\/br>\nAccuracy (test): 0.5598086124401914<\/br>\nF1-Score (test): 0.7177914110429447<\/br><\/br>\n\nModel: k-NN with n = 33 using imputation technique 2 (KNNImputer) <\/br>\nAccuracy (train-valid): 0.595<\/br>\nF1-Score (train-valid): 0.7096774193548389<\/br>\nAccuracy (test): 0.5598086124401914<\/br>\nF1-Score (test): 0.7177914110429447<\/br><\/br>\n\nModel: GradientBoosting with n_estimators = 100 (default) <\/br>\nAccuracy (train-valid): 0.81<\/br>\nF1-Score (train-valid): 0.8515625000000001<\/br>\nAccuracy (test): 0.8133971291866029<\/br>\nF1-Score (test): 0.8458498023715416<\/br><\/br>\n\nModel: GradientBoosting with n_estimators = 61<\/br>\nAccuracy (train-valid): 0.855<\/br>\nF1-Score (train-valid): 0.8921933085501859<\/br>\nAccuracy (test): 0.7703349282296651<\/br>\nF1-Score (test): 0.818181818181818<\/br>\n","6d740c7e":">> ### Building the model (train-valid)","1619d7e7":"\n>> ### Evaluating Classifier Accuracy","e43c7a3d":"#### Receiver Operating Characteristic (ROC) and Area Under the Curve (AUC)","228e813a":"#### 1.4 Performing the imputation\n\n##### Here's the plan \n\n<\/br>\n\n1. Replace null values with the mode<\/br>\n2. Using k-NN to impute nulls<\/br>\n\n--------------------------------------------------------------------------------------------------------","b267b34d":">> ### Building the model","cef673df":"--------------------------------------------------------------------------------------------------------\n<\/br>\n\n## Section C: Testing a theory on increasing number of decision trees (n_estimators) for GradientBoosting <\/br>\n\nThe need is to design and evaluate a computational experiment, to test the theory that increasing the number of decision trees (n_estimators), increases classifier performance and\/or generalizability<\/br><\/br>\nThe high level steps in this section will include the following:<\/br>\n\nPart 1 \u2013 Visualizing the accuracy for different values of n_estimators \/ number of decision trees<\/br>\nPart 2 \u2013 Building a GradientBoosting model with the highest score n_estimators<\/br>\n\n\n\n\n","a9ebc555":"\n--------------------------------------------------------------------------------------------------------\n<\/br>\n\n### Section A: Data Imputation Techniques<\/br>\nThe high level steps in this section will include the following:<\/br>\n\n\n","e78f965d":">>> #### *Confusion matrix, Recall, and Precision*","45489cce":"### Train-valid split","8cf0a992":"<\/br>\n\n>> ### Evaluating Classifier Accuracy","74c4d437":"<\/br>\n\n>> ### Evaluating Classifier Accuracy","ef2f7259":">> ### Evaluating Classifier Accuracy","66df4e80":"--------------------------------------------------------------------------------------------------------\n<\/br>\n\n### Section B: GradientBoosting Implementation on the Titanic Dataset <\/br>\nThe high level steps in this section will include the following:<\/br>\n\n\n","dec86956":">>> #### *Receiver Operating Characteristic (ROC) and Area Under the Curve (AUC)*","621b3593":">>> #### *Confusion matrix, Recall, and Precision*","f708bbdf":">>> #### *Receiver Operating Characteristic (ROC) and Area Under the Curve (AUC)*","d8bca9d6":"### Train-valid split","cb99382f":">>> #### *Receiver Operating Characteristic (ROC) and Area Under the Curve (AUC)*","80a99388":">> ### Evaluating Classifier Accuracy","8cf32383":"<br>\n\n> ## Using the train_valid-test data","85399026":"## Part 2: Building the train-valid and train_valid-test models with GradientBoosting with n_estimators=61","d2ed998c":"--------------------------------------------------------------------------------------------------------\n<\/br>\n\n## \u2022\tPart 1: Visualizing the accuracy for different values of n_estimators \/ number of decision trees\n","a0760a6f":"#### Imputation technique 1. Replace null values with the mode","087598b0":"\n>> ### Evaluating Classifier Accuracy","d1996bcd":"#### 1.1 Importing the neccessary libraries","dee4f08b":"> ## Using the train-valid data","40292592":"#### 1.3 Analyzing the features","4f2995ca":"\n\n> 1.1 Importing the neccessary libraries<\/br>\n> 1.2 Importing the dataset<\/br>\n> 1.3 Analyzing the features<\/br>\n> 1.4 Performing the imputation using two techniques<\/br>\n>> Building the model for each of the imputation techniques<\/br>\n>> Evaluating Classifier Accuracy for each of the imputation techniques<\/br>","8038bc01":">> ### Building the model (train-valid)","19d6ab8e":"### *Train_valid - Test evaluation*","d00e273b":"#### 1.2 Importing the dataset","64805322":">>> #### *Confusion matrix, Recall, and Precision*","6d22afda":"--------------------------------------------------------------------------------------------------------\n<\/br>\n\n# \u2022\tBuilding a GradientBoosting model with default hyperparameter values\n","609d5c5a":">>> #### *Confusion matrix, Recall, and Precision*","f16c382e":"\n>> ### Building the model\n"}}