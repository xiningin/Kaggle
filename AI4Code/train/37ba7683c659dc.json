{"cell_type":{"da695b2e":"code","744c5519":"code","68f21016":"code","50780e1f":"code","13cc7866":"code","8b0be3e0":"code","dff905ca":"code","07abe31f":"code","1c0e8c0c":"code","12466e31":"code","15cf7517":"code","49876734":"code","23f60b3a":"code","9a6706cc":"code","5d4fe980":"code","e76a65fa":"code","c8f6d33e":"code","8f09c97e":"code","ef6f5633":"code","4a29b6e1":"code","c7817b12":"code","65aa6b0a":"code","17ed7de3":"code","77131459":"code","4575386f":"code","c529b5ea":"code","ce347580":"code","f2f8c44c":"code","622b543d":"code","fec34c6b":"markdown","2153ff51":"markdown","6b14640d":"markdown","bd79c54d":"markdown","8b5b45ab":"markdown","cb8c3224":"markdown","d5ad4679":"markdown","06adc178":"markdown","27cdda48":"markdown","731604a7":"markdown","7e414fcd":"markdown","d07fd4c1":"markdown","bc50f58b":"markdown","7fc3ecfd":"markdown","54328e98":"markdown","57a7fa24":"markdown","242b6256":"markdown","b420f3ed":"markdown","ddf73d72":"markdown","fb2f8707":"markdown","1af86075":"markdown","91498602":"markdown","9e0764a7":"markdown","b13ff2fd":"markdown","3bf196e4":"markdown","db8b84cf":"markdown","56aa0001":"markdown","250757b8":"markdown","34cbf2be":"markdown","16ea00a4":"markdown","8aa5965e":"markdown","12a2ccdb":"markdown","0b7dd879":"markdown","9e1a5690":"markdown","049bf193":"markdown","8957f2a0":"markdown","36cd7671":"markdown","afe80002":"markdown","5afcec65":"markdown","c3f5ca49":"markdown"},"source":{"da695b2e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","744c5519":"# Ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')","68f21016":"# Read and preview data\ndf = pd.read_csv('\/kaggle\/input\/boston-housing-dataset\/HousingData.csv')\ndf.head()","50780e1f":"df.info()","13cc7866":"df.isnull().sum()","8b0be3e0":"df = df.fillna(df.mean())","dff905ca":"df.isnull().sum()","07abe31f":"# Declare feature vector and target variable\nX = df[['LSTAT','RM','NOX','PTRATIO','DIS','AGE']]\ny = df['MEDV']","1c0e8c0c":"# Split the data into train and test data:\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","12466e31":"# Build the model with Random Forest Regressor :\nfrom sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(max_depth=6, random_state=0, n_estimators=10)\nmodel.fit(X_train, y_train)","15cf7517":"y_pred = model.predict(X_test)","49876734":"from sklearn.metrics import mean_squared_error\nmse = mean_squared_error(y_test, y_pred)**(0.5)\nmse","23f60b3a":"import lime\nimport lime.lime_tabular","9a6706cc":"# LIME has one explainer for all the models\nexplainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X_train.columns.values.tolist(),\n                                                  class_names=['MEDV'], verbose=True, mode='regression')","5d4fe980":"# Choose the 5th instance and use it to predict the results\nj = 5\nexp = explainer.explain_instance(X_test.values[j], model.predict, num_features=6)\n","e76a65fa":"# Show the predictions\nexp.show_in_notebook(show_table=True)","c8f6d33e":"exp.as_list()","8f09c97e":"# Choose the 10th instance and use it to predict the results\nj = 10\nexp = explainer.explain_instance(X_test.values[j], model.predict, num_features=6)","ef6f5633":"# Show the predictions\nexp.show_in_notebook(show_table=True)","4a29b6e1":"exp.as_list()","c7817b12":"# Choose the 15th instance and use it to predict the results\nj = 15\nexp = explainer.explain_instance(X_test.values[j], model.predict, num_features=6)","65aa6b0a":"# Show the predictions\nexp.show_in_notebook(show_table=True)","17ed7de3":"exp.as_list()","77131459":"# Choose the 20th instance and use it to predict the results\nj = 20\nexp = explainer.explain_instance(X_test.values[j], model.predict, num_features=6)","4575386f":"# Show the predictions\nexp.show_in_notebook(show_table=True)","c529b5ea":"exp.as_list()","ce347580":"# Choose the 25th instance and use it to predict the results\nj = 25\nexp = explainer.explain_instance(X_test.values[j], model.predict, num_features=6)","f2f8c44c":"# Show the predictions\nexp.show_in_notebook(show_table=True)","622b543d":"exp.as_list()","fec34c6b":"## **Select 25th instance**","2153ff51":"### **Interpretation**\n\n- The predicted value of the house price is 21.48.\n- The variables `LSTAT` and `NOX` have positive influence while `RM`,`DIS`,`AGE` and`PTRATIO` have negative influence on predicted house prices.\n- All the values are in thousands of dollars.","6b14640d":"## **3.5 Feature Vector and Target Variable** <a class=\"anchor\" id=\"3.5\"><\/a>\n\n[Table of Contents](#0.1)","bd79c54d":"- Model-specific approaches aim to understand the black model machine learning model by analysing the internal components and how they interact. LIME provides local model interpretability. LIME modifies a single data sample by tweaking the feature values and observes the resulting impact on the output. The most common question is probably: why was this prediction made or which variables caused the prediction.","8b5b45ab":"## **3.9 Evaluate Performance** <a class=\"anchor\" id=\"3.9\"><\/a>\n\n[Table of Contents](#0.1)","cb8c3224":"- We can see that there are quite a lot of missing values in the dataset. For convinience, I will fill them by the mean of respective columns.","d5ad4679":"## **3.6 Train-Test Split** <a class=\"anchor\" id=\"3.6\"><\/a>\n\n[Table of Contents](#0.1)","06adc178":"# **3. Python Implementation of model development** <a class=\"anchor\" id=\"3\"><\/a>\n\n[Table of Contents](#0.1)","27cdda48":"### **Interpretation**\n\n- The predicted value of the house price is 9.78.\n- All the variables have negative influence on the predicted house prices.\n- All the values are in thousands of dollars.","731604a7":"## **3.4 Missing values treatment** <a class=\"anchor\" id=\"3.4\"><\/a>\n\n[Table of Contents](#0.1)","7e414fcd":"### **Interpretation**\n\n- The predicted value of the house price is 16.67.\n- All the variables have negative influence on predicted house prices.\n- All the values are in thousands of dollars.","d07fd4c1":"- The explanation model for instance x is the model g (e.g. linear regression model) that minimizes loss function L (e.g. mean squared error). It measures how close the explanation is to the prediction of the original model f (e.g. an xgboost model), while the model complexity \u03a9(g) is kept low (e.g. prefer fewer features). G is the family of possible explanations. \n\n- In practice, LIME only optimizes the loss part. The user has to determine the complexity, e.g. by selecting the maximum number of features that the linear regression model may use.\n\n- So, the recipe for training local surrogate models is as follows:\n\n  - 1 Select your instance of interest for which you want to have an explanation of its black box prediction.\n  - 2 Perturb your dataset and get the black box predictions for these new points.\n  - 3 Weight the new samples according to their proximity to the instance of interest.\n  - 4 Train a weighted, interpretable model on the dataset with the variations.\n  - 5 Explain the prediction by interpreting the local model.","bc50f58b":"## **4.1 Import LIME package** <a class=\"anchor\" id=\"4.1\"><\/a>\n\n[Table of Contents](#0.1)","7fc3ecfd":"## **3.2 Read Data** <a class=\"anchor\" id=\"3.2\"><\/a>\n\n[Table of Contents](#0.1)","54328e98":"### **Interpretation**\n\n- The predicted value of the house price is 23.75.\n- The variables `LSTAT` and`NOX` have positive influence while `RM`, `AGE`,`PTRATIO` and `DIS` have negative influence on predicted house prices.\n- All the values are in thousands of dollars.","57a7fa24":"## **3.3 View Summary of data** <a class=\"anchor\" id=\"3.3\"><\/a>\n\n[Table of Contents](#0.1)\n","242b6256":"### **Interpretation**\n\n- The predicted value of the house price is 33.48.\n- All the variables except `DIS` have positive influence on the predicted house prices.\n- All the values are in thousnads of dollars.","b420f3ed":"- Here, I have seelcted the following 6 variables as feature vectors for convinience.\n\n  - 1 `LSTAT` - lower status of the population\n  - 2 `RM` - average number of rooms per housing\n  - 3 `NOX` - nitric oxides concentration (parts per 10 million)\n  - 4 `PTRATIO` - pupil-teacher ratio by town\n  - 5 `DIS` - weighted distances to five Boston employment centres\n  - 6 `AGE` - proportion of owner-occupied units built prior to 1940\n  \n- The target variable is `MEDV` which stands for **Median value of owner-occupied homes**.\n\n- The dataset description can be found at -\n\n    https:\/\/www.kaggle.com\/kyasar\/boston-housing","ddf73d72":"## **3.8 Generate Predictions** <a class=\"anchor\" id=\"3.8\"><\/a>\n\n[Table of Contents](#0.1)","fb2f8707":"- Mathematically, local surrogate models with interpretability constraint can be expressed as follows:\n\n        `explanation(x)=arg ming\u2208G L(f,g,\u03c0x)+\u03a9(g)`","1af86075":" ![LIME](https:\/\/miro.medium.com\/max\/1165\/1*k-rxjnvUDTwk8Jfg6IYBkQ.png)","91498602":"<a class=\"anchor\" id=\"0.1\"><\/a>\n# **Table of Contents**\n\n- 1\t[Introduction to LIME](#1)\n- 2\t[Intuition behind LIME](#2)\n- 3\t[Python implementation of model development](#3)\n- 4\t[Interpret model predictions with LIME](#4)\n    - 4.1 [Import LIME package](#4.1)\n    - 4.2 [Create the explainer](#4.2)\n    - 4.3 [Use the explainer to explain predictions](#4.3)\n- 5 [References](#5)","9e0764a7":"## **3.7 Build the Random Forest model** <a class=\"anchor\" id=\"3.7\"><\/a>\n\n[Table of Contents](#0.1)","b13ff2fd":"[Go to Top](#0)","3bf196e4":"## **3.1 Load Preliminaries** <a class=\"anchor\" id=\"3.1\"><\/a>\n\n[Table of Contents](#0.1)","db8b84cf":"## **Select 15th instance**","56aa0001":"# **4. Interpret model predictions with LIME** <a class=\"anchor\" id=\"4\"><\/a>\n\n[Table of Contents](#0.1)","250757b8":"- Here, I will choose 5 instances and use them to explain the predictions.","34cbf2be":"## **4.3 Use the explainer to explain predictions** <a class=\"anchor\" id=\"4.3\"><\/a>\n\n[Table of Contents](#0.1)","16ea00a4":"**As always, I hope you find this kernel useful and your <font color=\"red\"><b>UPVOTES<\/b><\/font> would be highly appreciated**.\n\n","8aa5965e":"## **Select 20th instance**","12a2ccdb":"## **Select 5th instance**","0b7dd879":"# **1. Introduction to LIME** <a class=\"anchor\" id=\"1\"><\/a>\n\n[Table of Contents](#0.1)\n\n\n- [LIME](https:\/\/christophm.github.io\/interpretable-ml-book\/lime.html) stands for **Local Interpretable Model-agnostic Explanations**. LIME focuses on training local surrogate models to explain individual predictions. Local surrogate models are interpretable models that are used to explain individual predictions of black box machine learning models. Surrogate models are trained to approximate the predictions of the underlying black box model. Instead of training a global surrogate model, LIME focuses on training local surrogate models.\n\n\n- LIME is model-agnostic, meaning that it can be applied to any machine learning model. The technique attempts to understand the model by perturbing the input of data samples and understanding how the predictions change.","9e1a5690":"- Again check for missing values.","049bf193":"<a class=\"anchor\" id=\"0\"><\/a>\n# **Explain your model predictions with LIME**\n\n\n\nHello friends,\n\n\nIn a previous kernel. I have discussed [Shap library in Python](https:\/\/www.kaggle.com\/prashant111\/explain-model-predictions-with-shap), which is used for model interpretability. In this kernel, I will discuss LIME Values, which are also used for the same purpose.\n\nSo, let's get started.","8957f2a0":"## **4.2 Create the Explainer** <a class=\"anchor\" id=\"4.2\"><\/a>\n\n[Table of Contents](#0.1)","36cd7671":"- Now, we can see that there are no missing values in the data.","afe80002":"## **Select 10th instance**\n","5afcec65":"# **2. Intuition behind LIME** <a class=\"anchor\" id=\"2\"><\/a>\n\n[Table of Contents](#0.1)\n\n\n- The intuition behind LIME is very simple. First, forget the training data and imagine we have only the black box model where we supply the input data. The black box model generate the predictions for the model. We can enquire the box as many times as we like. Our objective is to understand why the machine learning model made a certain prediction. \n\n- Now, [LIME](https:\/\/christophm.github.io\/interpretable-ml-book\/lime.html) comes into play. LIME tests what happens to the predictions when we provide variations in the data which is being fed into the machine learning model. \n\n- [LIME](https:\/\/christophm.github.io\/interpretable-ml-book\/lime.html) generates a new dataset consisting of permuted samples and the corresponding predictions of the black box model. On this new dataset LIME then trains an [interpretable model](https:\/\/christophm.github.io\/interpretable-ml-book\/simple.html#simple). It is weighted by the proximity of the sampled instances to the instance of interest. The learned model should be a good approximation of the machine learning model predictions locally, but it does not have to be a good global approximation. This kind of accuracy is also called local fidelity.","c3f5ca49":"# **5. References** <a class=\"anchor\" id=\"5\"><\/a>\n\n[Table of Contents](#0.1)\n\n\nThe work done in this kernel is based on the following websites -\n\n- 1 https:\/\/christophm.github.io\/interpretable-ml-book\/\n- 2 https:\/\/christophm.github.io\/interpretable-ml-book\/lime.html\n- 3 https:\/\/blog.dominodatalab.com\/shap-lime-python-libraries-part-2-using-shap-lime\/\n- 4 https:\/\/www.analyticsvidhya.com\/blog\/2017\/06\/building-trust-in-machine-learning-models\/\n- 5 https:\/\/towardsdatascience.com\/understanding-model-predictions-with-lime-a582fdff3a3b\n- 6 https:\/\/marcotcr.github.io\/lime\/tutorials\/Using%2Blime%2Bfor%2Bregression.html"}}