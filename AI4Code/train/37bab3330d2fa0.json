{"cell_type":{"40ac2d9f":"code","65864805":"code","91ce1f2f":"code","84b83a04":"code","33d81db8":"code","f4372633":"code","f691a95f":"code","f35ff82f":"code","cb48c98f":"code","34c5a3e6":"code","366b83fd":"code","37f4a02b":"code","6dca7b01":"code","fce1b734":"code","e1424870":"code","dacd9b11":"code","ecf85429":"code","20ed303f":"code","32c26835":"code","0e02d813":"code","e39ffd3a":"code","177072e3":"code","44515390":"code","46624091":"code","69be2dca":"code","ad5ef399":"code","cc1dca61":"code","2c03638c":"code","ad74c937":"code","7f81a808":"code","486e4454":"code","da367e18":"code","2ab8695f":"code","72f1453e":"code","227db668":"code","4ec04867":"code","e4adee40":"code","bf49f8eb":"code","ff6563d2":"code","867e212b":"code","199fafd5":"code","335d7a45":"code","d5973e64":"code","5e595cdd":"code","b867977e":"code","7a6035ea":"code","454bf961":"code","0616d563":"code","ed278fd1":"code","117c1da9":"code","b539b3c9":"code","1df8fd4f":"code","ef5d00fd":"code","fe40ac62":"code","cac3daaa":"code","f3f5cd4d":"code","7cd051e4":"code","997b34b1":"code","97dae6d1":"code","cc3dbd95":"code","ca643cd4":"code","10b04a24":"code","740c9f18":"code","ab8d37d3":"code","f79270f9":"code","e708c65e":"code","f9892762":"code","d5af3813":"code","aaf2f49c":"code","3cc38829":"code","525fd9e6":"code","a9e65c3a":"code","edd91d95":"code","bb33a86d":"code","01b9ef23":"code","7c71885d":"code","c47f450f":"code","59440223":"code","e55dd153":"code","227548ab":"code","7d0c062e":"code","b1d7deca":"code","188a40ed":"code","ed71b86b":"code","5d8d7ec7":"code","7108b5a6":"code","dbc67e75":"code","bed21767":"code","cd100d50":"code","2f1eb4d6":"code","04abf82a":"code","d31f39e8":"code","d1c530ee":"code","6cfc0dd1":"code","f2a76a59":"code","24059763":"code","834f0067":"code","c183cca5":"code","19f65e8b":"code","00c32544":"code","5bf7bf41":"code","efec01ae":"code","2aecfc60":"code","014427f6":"code","1f3a175c":"code","e1930060":"code","e570612c":"code","2a0716cf":"code","a38b0b61":"code","a5ac3bc9":"code","fc8b7b7d":"code","56a8e59d":"code","2329ea95":"code","e895477c":"code","f230438b":"code","e2a75d5d":"code","64736f2a":"code","1a5d1f3d":"code","c0062cf8":"code","8b9fe858":"code","7bbb3d5d":"code","46e0f77f":"code","8cd66ff6":"code","b880157e":"code","6f9d8fac":"code","91776294":"code","695510f9":"code","464d02a1":"code","e42fac62":"code","973fc7de":"code","e6ed129f":"code","50f6f980":"code","db10cc9c":"code","86d4ed48":"code","4697ff7d":"code","fbbcfae9":"code","0ba12041":"code","aeab332f":"code","d3aebd1b":"code","e6c1d5c5":"code","4d339c61":"code","491cf6a2":"code","55c78918":"code","c37077c0":"code","b6e14e8d":"code","7a201dd7":"code","11658f8e":"code","01b17029":"code","92b07f38":"code","df1a90d7":"code","c517f566":"code","191bed37":"code","1d1ad150":"code","ab9d3ad6":"markdown","2e21ff0f":"markdown","f49dfca8":"markdown"},"source":{"40ac2d9f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","65864805":"# StratifiedKFold cross validation to make sure the same proportion of both classes maintained during each sampling process\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import chi2, f_classif, mutual_info_classif\nfrom sklearn.feature_selection import SelectKBest\nfrom yellowbrick.target import FeatureCorrelation\nfrom sklearn.metrics import confusion_matrix,classification_report,plot_confusion_matrix,accuracy_score,roc_auc_score,roc_curve,auc\nfrom sklearn import preprocessing\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nplt.figure(figsize = (20, 18))\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom bayes_opt import BayesianOptimization\n# hyperopt is hyperparameter optimization by defining an objective function and declaring a search space\nfrom hyperopt import hp, fmin, tpe, Trials, STATUS_OK","91ce1f2f":"train_df = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-dec-2021\/train.csv\")\ntrain_df.shape","84b83a04":"train_df.head()","33d81db8":"train_df.info()","f4372633":"train_df.columns","f691a95f":"# Drops ID column as it is not required\ntrain_df.drop([\"Id\"], axis=1, inplace=True)","f35ff82f":"# Check for missing values\nsum(train_df.isna().sum())","cb48c98f":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        c_min = df[col].min()\n        \n        if col_type != object:\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","34c5a3e6":"# compress the data\ntrain_df = reduce_mem_usage(train_df)","366b83fd":"# Checks distribution of categorical target variable\ntrain_df.groupby(['Cover_Type']).size()","37f4a02b":"train_df.drop(train_df[train_df['Cover_Type'] == 5].index, inplace = True) # this has one observation","6dca7b01":"# Checks distribution of categorical target variable\ntrain_df.groupby(['Cover_Type']).size()","fce1b734":"df = train_df[['Elevation', 'Aspect', 'Slope','Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology','Cover_Type']]\n\ntarget = df['Cover_Type']\nfeatures = df.drop('Cover_Type', axis=1)\n\nselect_univariate = SelectKBest(f_classif, k=2).fit(features, target)\n\nfeatures_mask = select_univariate.get_support()\n\nfeatures_mask\n\nselected_columns = features.columns[features_mask]\n\nselected_columns\n\nselected_features = features[selected_columns]\n\nselected_features.head()","e1424870":"feature_names = list(features.columns)","dacd9b11":"figure(figsize=(20,18), dpi=80)\nvisualizer = FeatureCorrelation(labels = feature_names, method='pearson')\n\nvisualizer.fit(features, target)\n\nvisualizer.poof()","ecf85429":"df.describe().transpose().round(2)\n","20ed303f":"#checking for correlation\npearson_corr = df.corr(method='pearson')\n\npearson_corr","32c26835":"sns.histplot(data=df, x=\"Elevation\", bins=10, kde=True)","0e02d813":"sns.kdeplot(df['Elevation'],shade=True)","e39ffd3a":"sns.violinplot(x=df[\"Cover_Type\"],y=df[\"Elevation\"],data=df)","177072e3":"sns.kdeplot(df['Aspect'],shade=True)","44515390":"sns.violinplot(x=df[\"Cover_Type\"],y=df[\"Aspect\"],data=df)","46624091":"sns.kdeplot(df['Slope'],shade=True)","69be2dca":"sns.violinplot(x=df[\"Cover_Type\"],y=df[\"Slope\"],data=df)","ad5ef399":"sns.kdeplot(df['Horizontal_Distance_To_Hydrology'],shade=True)","cc1dca61":"sns.violinplot(x=df[\"Cover_Type\"],y=df[\"Horizontal_Distance_To_Hydrology\"],data=df)","2c03638c":"sns.kdeplot(df['Vertical_Distance_To_Hydrology'],shade=True)","ad74c937":"sns.violinplot(x=df[\"Cover_Type\"],y=df[\"Vertical_Distance_To_Hydrology\"],data=df)","7f81a808":"df = train_df[[\n       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points','Cover_Type']]\n\ntarget = df['Cover_Type']\nfeatures = df.drop('Cover_Type', axis=1)\n\nselect_univariate = SelectKBest(f_classif, k=2).fit(features, target)\n\nfeatures_mask = select_univariate.get_support()\n\nfeatures_mask\n\nselected_columns = features.columns[features_mask]\n\nselected_columns\n\nselected_features = features[selected_columns]\n\nselected_features.head()","486e4454":"feature_names = list(features.columns)","da367e18":"figure(figsize=(20,18), dpi=80)\nvisualizer = FeatureCorrelation(labels = feature_names, method='pearson')\nvisualizer.fit(features, target)\nvisualizer.poof()","2ab8695f":"df.describe().transpose().round(2)","72f1453e":"#checking for correlation\npearson_corr = df.corr(method='pearson')\n\npearson_corr","227db668":"sns.histplot(data=df, x=\"Horizontal_Distance_To_Roadways\", bins=10, kde=True)","4ec04867":"sns.violinplot(x=df[\"Cover_Type\"],y=df[\"Horizontal_Distance_To_Roadways\"],data=df)","e4adee40":"sns.histplot(data=df, x=\"Hillshade_9am\", bins=10, kde=True)","bf49f8eb":"sns.violinplot(x=df[\"Cover_Type\"],y=df[\"Hillshade_9am\"],data=df)","ff6563d2":"sns.histplot(data=df, x=\"Hillshade_Noon\", bins=10, kde=True)","867e212b":"sns.violinplot(x=df[\"Cover_Type\"],y=df[\"Hillshade_Noon\"],data=df)","199fafd5":"sns.histplot(data=df, x=\"Hillshade_3pm\", bins=10, kde=True)","335d7a45":"sns.violinplot(x=df[\"Cover_Type\"],y=df[\"Hillshade_3pm\"],data=df)","d5973e64":"sns.histplot(data=df, x=\"Horizontal_Distance_To_Fire_Points\", bins=10, kde=True)","5e595cdd":"sns.violinplot(x=df[\"Cover_Type\"],y=df[\"Horizontal_Distance_To_Fire_Points\"],data=df)","b867977e":"df = train_df[['Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4','Cover_Type']]\n\ntarget = df['Cover_Type']\nfeatures = df.drop('Cover_Type', axis=1)\n\nselect_univariate = SelectKBest(f_classif, k=2).fit(features, target)\n\nfeatures_mask = select_univariate.get_support()\n\nfeatures_mask\n\nselected_columns = features.columns[features_mask]\n\nselected_columns\n\nselected_features = features[selected_columns]\n\nselected_features.head()","7a6035ea":"feature_names = list(features.columns)","454bf961":"figure(figsize=(20,18), dpi=80)\nvisualizer = FeatureCorrelation(labels = feature_names, method='pearson')\nvisualizer.fit(features, target)\nvisualizer.poof()","0616d563":"df.describe().transpose().round(2)","ed278fd1":"#checking for correlation\npearson_corr = df.corr(method='pearson')\n\npearson_corr","117c1da9":"df['Wilderness_Area1'].value_counts()","b539b3c9":"sns.countplot(df['Wilderness_Area1'])","1df8fd4f":"df['Wilderness_Area2'].value_counts()","ef5d00fd":"sns.countplot(df['Wilderness_Area2'])","fe40ac62":"df['Wilderness_Area3'].value_counts()","cac3daaa":"sns.countplot(df['Wilderness_Area3'])","f3f5cd4d":"df['Wilderness_Area4'].value_counts()","7cd051e4":"sns.countplot(df['Wilderness_Area4'])","997b34b1":"sns.boxplot(x ='Cover_Type', y ='Horizontal_Distance_To_Fire_Points', data = train_df, hue ='Wilderness_Area1')","97dae6d1":"sns.boxplot(x ='Cover_Type', y ='Horizontal_Distance_To_Fire_Points', data = train_df, hue ='Wilderness_Area4')","cc3dbd95":"df = train_df[['Soil_Type1', 'Soil_Type2', 'Soil_Type3',\n       'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n       'Soil_Type9', 'Soil_Type10','Cover_Type']]\n\ntarget = df['Cover_Type']\nfeatures = df.drop('Cover_Type', axis=1)\n\nselect_univariate = SelectKBest(f_classif, k=4).fit(features, target)\n\nfeatures_mask = select_univariate.get_support()\n\nfeatures_mask\n\nselected_columns = features.columns[features_mask]\n\nselected_columns\n\nselected_features = features[selected_columns]\n\nselected_features.head()","ca643cd4":"feature_names = list(features.columns)","10b04a24":"figure(figsize=(20,18), dpi=80)\nvisualizer = FeatureCorrelation(labels = feature_names, method='pearson')\nvisualizer.fit(features, target)\nvisualizer.poof()","740c9f18":"df.describe().transpose().round(2)","ab8d37d3":"#checking for correlation\npearson_corr = df.corr(method='pearson')\n\npearson_corr","f79270f9":"df['Soil_Type1'].value_counts()","e708c65e":"df['Soil_Type2'].value_counts()","f9892762":"df['Soil_Type3'].value_counts()","d5af3813":"df['Soil_Type4'].value_counts()","aaf2f49c":"df['Soil_Type5'].value_counts()","3cc38829":"df['Soil_Type6'].value_counts()","525fd9e6":"df['Soil_Type7'].value_counts() # only one constant value","a9e65c3a":"df['Soil_Type8'].value_counts()","edd91d95":"df['Soil_Type9'].value_counts()","bb33a86d":"df['Soil_Type10'].value_counts()","01b9ef23":"df = train_df[['Soil_Type11', 'Soil_Type12',\n       'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20','Cover_Type']]\n\ntarget = df['Cover_Type']\nfeatures = df.drop('Cover_Type', axis=1)\n\nselect_univariate = SelectKBest(f_classif, k=4).fit(features, target)\n\nfeatures_mask = select_univariate.get_support()\n\nfeatures_mask\n\nselected_columns = features.columns[features_mask]\n\nselected_columns\n\nselected_features = features[selected_columns]\n\nselected_features.head()","7c71885d":"feature_names = list(features.columns)","c47f450f":"figure(figsize=(20,18), dpi=80)\nvisualizer = FeatureCorrelation(labels = feature_names, method='pearson')\nvisualizer.fit(features, target)\nvisualizer.poof()","59440223":"df['Soil_Type11'].value_counts()","e55dd153":"df['Soil_Type12'].value_counts()","227548ab":"df['Soil_Type13'].value_counts()","7d0c062e":"df['Soil_Type14'].value_counts()","b1d7deca":"df['Soil_Type15'].value_counts() # only one value 0","188a40ed":"df['Soil_Type16'].value_counts()","ed71b86b":"df['Soil_Type17'].value_counts()","5d8d7ec7":"df['Soil_Type18'].value_counts()","7108b5a6":"df['Soil_Type19'].value_counts()","dbc67e75":"df['Soil_Type20'].value_counts()","bed21767":"df = train_df[['Soil_Type21', 'Soil_Type22',\n       'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n       'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30','Cover_Type']]\n\ntarget = df['Cover_Type']\nfeatures = df.drop('Cover_Type', axis=1)\n\nselect_univariate = SelectKBest(f_classif, k=4).fit(features, target)\n\nfeatures_mask = select_univariate.get_support()\n\nfeatures_mask\n\nselected_columns = features.columns[features_mask]\n\nselected_columns\n\nselected_features = features[selected_columns]\n\nselected_features.head()","cd100d50":"feature_names = list(features.columns)","2f1eb4d6":"figure(figsize=(20,18), dpi=80)\nvisualizer = FeatureCorrelation(labels = feature_names, method='pearson')\nvisualizer.fit(features, target)\nvisualizer.poof()","04abf82a":"df['Soil_Type21'].value_counts()","d31f39e8":"\ndf['Soil_Type22'].value_counts()","d1c530ee":"df['Soil_Type23'].value_counts()","6cfc0dd1":"df['Soil_Type24'].value_counts()","f2a76a59":"df['Soil_Type25'].value_counts()","24059763":"\n\n\n\ndf['Soil_Type26'].value_counts()","834f0067":"df['Soil_Type27'].value_counts()","c183cca5":"df['Soil_Type28'].value_counts()","19f65e8b":"df['Soil_Type29'].value_counts()","00c32544":"df['Soil_Type30'].value_counts()","5bf7bf41":"df = train_df[['Soil_Type31', 'Soil_Type32',\n       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40','Cover_Type']]\n\ntarget = df['Cover_Type']\nfeatures = df.drop('Cover_Type', axis=1)\n\nselect_univariate = SelectKBest(f_classif, k=4).fit(features, target)\n\nfeatures_mask = select_univariate.get_support()\n\nfeatures_mask\n\nselected_columns = features.columns[features_mask]\n\nselected_columns\n\nselected_features = features[selected_columns]\n\nselected_features.head()","efec01ae":"feature_names = list(features.columns)","2aecfc60":"figure(figsize=(20,18), dpi=80)\nvisualizer = FeatureCorrelation(labels = feature_names, method='pearson')\nvisualizer.fit(features, target)\nvisualizer.poof()","014427f6":"df['Soil_Type31'].value_counts()","1f3a175c":"df['Soil_Type32'].value_counts()","e1930060":"df['Soil_Type33'].value_counts()","e570612c":"df['Soil_Type34'].value_counts()","2a0716cf":"df['Soil_Type35'].value_counts()","a38b0b61":"df['Soil_Type36'].value_counts()","a5ac3bc9":"df['Soil_Type37'].value_counts()","fc8b7b7d":"df['Soil_Type38'].value_counts()","56a8e59d":"df['Soil_Type39'].value_counts()","2329ea95":"df['Soil_Type40'].value_counts()","e895477c":"sns.relplot(x=\"Elevation\", y=\"Horizontal_Distance_To_Fire_Points\", hue=\"Cover_Type\",style=\"Soil_Type40\",data=train_df);","f230438b":"del df","e2a75d5d":"# features and the target\ny = train_df.Cover_Type\nX = train_df[['Elevation',\"Vertical_Distance_To_Hydrology\",\"Horizontal_Distance_To_Roadways\",\"Horizontal_Distance_To_Fire_Points\",\"Wilderness_Area1\",\n              \"Wilderness_Area4\",\"Soil_Type2\",\"Soil_Type3\",\"Soil_Type6\",\"Soil_Type10\",\"Soil_Type11\",\"Soil_Type12\",\"Soil_Type13\",\"Soil_Type17\",\n             \"Soil_Type22\",\"Soil_Type23\",\"Soil_Type29\",\"Soil_Type30\",\"Soil_Type38\",\"Soil_Type39\",\"Soil_Type40\"]]\n\ndel train_df","64736f2a":"# Create StratifiedKFold object.\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state= 40)","1a5d1f3d":"# Performs cross validation on XGB Classifier\n\nmodel = XGBClassifier(tree_method='gpu_hist')\nmodel_score = cross_val_score(model, X, y, scoring='accuracy', cv=skf.split(X, y), n_jobs=-1, verbose=10)","c0062cf8":"print(model_score.mean())","8b9fe858":"del model_score, model","7bbb3d5d":"parameter_space = {\n    'learning_rate': (0.01, 1.0),\n    'n_estimators': (100, 1000),\n    'max_depth': (2,10),\n    'subsample': (0.4, 1.0),\n    'colsample_bytree' :(0.4, 1.0),\n    'gamma': (0, 5)}\n\ndef xgboost_hyper_param(learning_rate,\n                        n_estimators,\n                        max_depth,\n                        subsample,\n                        colsample_bytree,\n                        gamma):\n\n    max_depth = int(max_depth)\n    n_estimators = int(n_estimators)\n\n    clf = XGBClassifier(\n        tree_method='gpu_hist',\n        max_depth=max_depth,\n        learning_rate=learning_rate,\n        n_estimators=n_estimators,\n        gamma=gamma)\n    return np.mean(cross_val_score(clf, X, y, cv=5, scoring='accuracy'))\n\noptimizer = BayesianOptimization(\n    f=xgboost_hyper_param,\n    pbounds=parameter_space,\n    random_state=100,\n)","46e0f77f":"optimizer.maximize(init_points=2, n_iter=5, acq='ei', xi=0.0)","8cd66ff6":"optimizer.res","b880157e":"params_gbm = optimizer.max['params']\nparams_gbm['max_depth'] = round(params_gbm['max_depth'])\nparams_gbm['n_estimators'] = round(params_gbm['n_estimators'])\nparams_gbm","6f9d8fac":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)","91776294":"params = {'colsample_bytree': 0.8547061059383534,\n 'gamma': 4.353355108658212,\n 'learning_rate': 0.2502986173540949,\n 'max_depth': 8,\n 'n_estimators': 940,\n 'subsample': 0.740057344466777}\n\nparams[\"max_depth\"] = int(params[\"max_depth\"])\nparams['objective'] = 'multi:softmax'  # error evaluation for multiclass training\nparams['num_class']=  6  # the number of classes that exist in this datset\nparams[\"tree_method\"] = \"gpu_hist\"\nparams['eval_metric'] =  'mlogloss'","695510f9":"xgb = XGBClassifier(**params)\nxgb.fit(X_train, y_train,\n          early_stopping_rounds=200,\n          eval_set=[(X_test,y_test)],\n          verbose=True)","464d02a1":"y_pred=xgb.predict(X_test)","e42fac62":"accuracy_score(y_test, y_pred)","973fc7de":"print(classification_report(y_test,y_pred))","e6ed129f":"print(confusion_matrix(y_test,y_pred))","50f6f980":"# Loads test data set\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/test.csv\")\n\n# Removes ID column as it is not required for prediction\ntest.drop([\"Id\"], axis=1, inplace=True)","db10cc9c":"# Loads submission data set that acts just as a template for submission\nsubmission = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/sample_submission.csv\")","86d4ed48":"test=test[['Elevation',\"Vertical_Distance_To_Hydrology\",\"Horizontal_Distance_To_Roadways\",\"Horizontal_Distance_To_Fire_Points\",\"Wilderness_Area1\",\n              \"Wilderness_Area4\",\"Soil_Type2\",\"Soil_Type3\",\"Soil_Type6\",\"Soil_Type10\",\"Soil_Type11\",\"Soil_Type12\",\"Soil_Type13\",\"Soil_Type17\",\n             \"Soil_Type22\",\"Soil_Type23\",\"Soil_Type29\",\"Soil_Type30\",\"Soil_Type38\",\"Soil_Type39\",\"Soil_Type40\"]]","4697ff7d":"predictions = xgb.predict(test)","fbbcfae9":"submission[\"Cover_Type\"] = predictions","0ba12041":"# Checks for sumbission file before saving\nsubmission","aeab332f":"# Saves test predictions\nsubmission.to_csv(\".\/submission.csv\", index=False) #0.92102 ","d3aebd1b":"fold_no = 1\nfor train_index, test_index in skf.split(X, y):\n    print('Fold = ',fold_no)\n    y_val = y.iloc[test_index]\n    X_train = X.iloc[train_index]\n    y_train = y.iloc[train_index]\n    X_test = X.iloc[test_index]\n    y_test = y.iloc[test_index]\n    fold_no +=1","e6c1d5c5":"hyperparameter_space = { \n                        'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n                        'max_depth': hp.quniform(\"max_depth\", 2, 6, 1),\n                        'min_child_weight' : hp.quniform('min_child_weight', 1, 8, 1),\n                        'reg_alpha' : hp.uniform('reg_alpha', 1e-8, 100),\n                        'reg_lambda' : hp.uniform('reg_lambda', 1e-8, 100),\n                        'gamma': hp.uniform ('gamma', 0.0, 1.0),\n                        'subsample': hp.uniform(\"subsample\", 0.1, 1.0),\n                        'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0)\n                       }","4d339c61":"def optimize_hyppara(hyperparameter_space):\n    # Converts parameter value to int as required by XGBoost\n    hyperparameter_space[\"max_depth\"] = int(hyperparameter_space[\"max_depth\"])\n    hyperparameter_space[\"objective\"] = \"multi:softmax\"\n    hyperparameter_space[\"eval_metric\"] = \"mlogloss\"\n    hyperparameter_space[\"tree_method\"] = \"gpu_hist\"\n    hyperparameter_space['num_class']=  6\n    \n    xgb = XGBClassifier(**hyperparameter_space)\n    xgb.fit(X_train, y_train,\n          early_stopping_rounds=200,\n          eval_set=[(X_test,y_test)],\n          verbose=False)\n    \n    predictions = xgb.predict(X_test)\n    \n    acc = accuracy_score(y_val, predictions)\n    \n    del predictions, xgb, hyperparameter_space\n    \n    return {\"loss\": -acc, \"status\": STATUS_OK}","491cf6a2":"# Starts hyperparameters tuning\ntrials = Trials()\nbest_model_params = fmin(fn=optimize_hyppara,space=hyperparameter_space, max_evals=50,algo=tpe.suggest,trials=trials)","55c78918":"best_model_params","c37077c0":"params = {'colsample_bytree': 0.7485494093640639,\n 'gamma': 0.5491765861222405,\n 'learning_rate': 0.27567612516134643,\n 'max_depth': 6.0,\n 'min_child_weight': 7.0,\n 'reg_alpha': 7.851967963410157,\n 'reg_lambda': 37.68751615993716,\n 'subsample': 0.7655471206521518}\n\nparams[\"max_depth\"] = int(params[\"max_depth\"])\nparams['objective'] = 'multi:softmax'  # error evaluation for multiclass training\nparams['num_class']=  6  # the number of classes that exist in this datset\nparams[\"tree_method\"] = \"gpu_hist\"\nparams['eval_metric'] =  'mlogloss'\n    \nxgb = XGBClassifier(**params)\nxgb.fit(X_train, y_train,\n          early_stopping_rounds=200,\n          eval_set=[(X_test,y_test)],\n          verbose=False)","b6e14e8d":"# Adds other important parameters\nbest_model_params[\"max_depth\"] = int(best_model_params[\"max_depth\"])\nbest_model_params['objective'] = 'multi:softmax'  # error evaluation for multiclass training\nbest_model_params['num_class']=  6  # the number of classes that exist in this datset\nbest_model_params[\"tree_method\"] = \"gpu_hist\"\nbest_model_params['eval_metric'] =  'mlogloss'","7a201dd7":"predictions = xgb.predict(test)","11658f8e":"submission[\"Cover_Type\"] = predictions\n\n# Checks for sumbission file before saving\nsubmission","01b17029":"# Saves test predictions\nsubmission.to_csv(\".\/submission.csv\", index=False) # 0.92128","92b07f38":"del predictions","df1a90d7":"# Gets the model trained over cross validation and predictions \n# against each iteration is stored\n\ntest_predictions = []\n\nfor fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n    print(\"fold\", fold)\n    \n    xgb = XGBClassifier(**best_model_params)\n    xgb.fit(X_train, y_train,\n          early_stopping_rounds=200,\n          eval_set=[(X_test,y_test)],\n          verbose=False)\n    \n    predictions = xgb.predict(test)\n    \n    test_predictions.append(predictions)\n    \n    del predictions, xgb","c517f566":"test_predictions","191bed37":"#Predictions stored against each cross validation iteration finally gets aeveraged\n# and target column is set with that averaged predictions\nsubmission[\"Cover_Type\"] = np.mean(np.column_stack(test_predictions), axis=1)\nsubmission[\"Cover_Type\"] = submission[\"Cover_Type\"].astype(\"int32\")\n# Checks for sumbission file before saving\nsubmission","1d1ad150":"# Saves test predictions\nsubmission.to_csv(\".\/submission.csv\", index=False) #0.92122","ab9d3ad6":"#### Elevation and Cover_Type has correlation coefficient -0.4","2e21ff0f":"# Feature Selection","f49dfca8":"# StratifiedKFold Cross Validation"}}