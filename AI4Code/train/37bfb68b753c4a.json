{"cell_type":{"d17287ac":"code","d80e8899":"code","c9b7d4e1":"code","9b68704d":"code","843c72cf":"code","afb7ed2e":"code","7c2b0181":"code","3924dfcf":"code","39427c4e":"code","d7058d9e":"code","ea632726":"code","a76a4a00":"code","faa5a556":"code","d88bf736":"code","b6ceea6c":"code","be079c2b":"code","d63461bd":"code","fda4563c":"code","86fe058c":"code","ed5e7c9f":"code","238ee960":"markdown"},"source":{"d17287ac":"import os\nimport sys\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageFilter, ImageEnhance\nfrom tqdm import tqdm_notebook\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, mean_squared_error, log_loss, confusion_matrix\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom PIL.ImageFilter import (\n    ModeFilter\n    )\nfrom PIL.ImageFilter import (\n    RankFilter, MedianFilter, MinFilter, MaxFilter\n    )\nimport pytesseract\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nnp.random.seed(100)\nLEVEL = 'level_3'","d80e8899":"import os\nprint(os.listdir(\"..\/input\"))","c9b7d4e1":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import mean_squared_error\nfrom tqdm import tqdm_notebook\nimport operator\nimport json\nnp.random.seed(0)\n\nclass MPNeuron:\n    \n    def __init__(self):\n        self.theta = None\n        \n    def mp_neuron(self, x):\n        if sum(x) >= self.theta:\n            return 1\n        return 0\n    \n    def fit_brute_force(self, X, Y):\n        accuracy = {}\n        for theta in tqdm_notebook(range(0, X.shape[1]+1), total=X.shape[1]+1):\n            self.theta = theta\n            Y_pred = self.predict(X)\n            accuracy[theta] = accuracy_score(Y, Y_pred)  \n            \n        sorted_accuracy = sorted(accuracy.items(), key=operator.itemgetter(1), reverse=True)\n        best_theta, best_accuracy = sorted_accuracy[0]\n        self.theta = best_theta\n        \n    def fit(self, X, Y, epochs=10, log=False, display_plot=False):\n        self.theta = (X.shape[1]+1)\/\/2\n        if log or display_plot:\n            accuracy = {}\n        for i in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n            Y_pred = self.predict(X)\n            tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n            if fp > fn and self.theta <= X.shape[1]:\n                self.theta += 1\n            elif fp < fn and self.theta >= 1:\n                self.theta -= 1\n            else:\n                continue\n                \n            if log or display_plot:\n                Y_pred = self.predict(X)\n                accuracy[i] = accuracy_score(Y, Y_pred)\n        if log:\n            with open('mp_neuron_accuracy.json', 'w') as fp:\n                json.dump(accuracy, fp)\n        if display_plot:\n            epochs_, accuracy_ = zip(*accuracy.items())\n            plt.plot(epochs_, accuracy_)\n            plt.xlabel(\"Epochs\")\n            plt.ylabel(\"Train Accuracy\")\n            plt.show()\n    \n    def predict(self, X):\n        Y = []\n        for x in X:\n            result = self.mp_neuron(x)\n            Y.append(result)\n        return np.array(Y)\n\n\nclass Perceptron:\n    \n    def __init__(self):\n        self.w = None\n        self.b = None\n        \n    def perceptron(self, x):\n        return np.sum(self.w * x) + self.b\n    \n    def fit(self, X, Y, epochs=10, learning_rate=0.01, log=False, display_plot=False):\n        # initialise the weights and bias\n        self.w = np.random.randn(1, X.shape[1])\n        self.b = 0\n        if log or display_plot: \n            accuracy = {}\n        for i in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n            for x, y in zip(X, Y):\n                result = self.perceptron(x)\n                if y == 1 and result < 0:\n                    self.w += learning_rate*x\n                    self.b += learning_rate\n                elif y == 0 and result >= 0:\n                    self.w -= learning_rate*x\n                    self.b -= learning_rate\n            if log or display_plot:\n                Y_pred = self.predict(X)\n                accuracy[i] = accuracy_score(Y, Y_pred)\n        if log:\n            with open('perceptron_accuracy.json', 'w') as fp:\n                json.dump(accuracy, fp)\n        if display_plot:\n            epochs_, accuracy_ = zip(*accuracy.items())\n            plt.plot(epochs_, accuracy_)\n            plt.xlabel(\"Epochs\")\n            plt.ylabel(\"Train Accuracy\")\n            plt.show()\n                    \n    def predict(self, X):\n        Y = []\n        for x in X:\n            result = self.perceptron(x)\n            Y.append(int(result>=0))\n        return np.array(Y)\n\n\nclass PerceptronWithSigmoid:\n    \n    def __init__(self):\n        self.w = None\n        self.b = None\n        \n    def perceptron(self, x):\n        return np.sum(self.w * x) + self.b\n    \n    def sigmoid(self, z):\n        return 1. \/ (1. + np.exp(-z))\n    \n    def grad_w(self, x, y):\n        y_pred = self.sigmoid(self.perceptron(x))\n        return (y_pred - y) * y_pred * (1 - y_pred) * x\n    \n    def grad_b(self, x, y):\n        y_pred = self.sigmoid(self.perceptron(x))\n        return (y_pred - y) * y_pred * (1 - y_pred)\n    \n    def fit(self, X, Y, epochs=10, learning_rate=0.01, log=False, display_plot=False):\n        # initialise the weights and bias\n        self.w = np.random.randn(1, X.shape[1])\n        self.b = 0\n        if log or display_plot: \n            #accuracy = {}\n            mse = {}\n        for i in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n            dw, db = 0, 0\n            for x, y in zip(X, Y):\n                dw += self.grad_w(x, y)\n                db += self.grad_b(x, y)\n            self.w -= learning_rate*dw\n            self.b -= learning_rate*db\n            \n            if log or display_plot:\n                Y_pred = self.predict(X)\n                #Y_binarized = (Y >= SCALED_THRESHOLD).astype(np.int)\n                #Y_pred_binarized = (Y_pred >= SCALED_THRESHOLD).astype(np.int)\n                #accuracy[i] = accuracy_score(Y_binarized, Y_pred_binarized)\n                mse[i] = mean_squared_error(Y, Y_pred)\n        if log:\n            #with open('perceptron_with_sigmoid_accuracy.json', 'w') as fp:\n                #json.dump(accuracy, fp)\n            with open('perceptron_with_sigmoid_mse.json', 'w') as fp:\n                json.dump(mse, fp)\n        if display_plot:\n            #epochs_, accuracy_ = zip(*accuracy.items())\n            #plt.plot(epochs_, accuracy_)\n            #plt.xlabel(\"Epochs\")\n            #plt.ylabel(\"Train Accuracy\")\n            #plt.show()\n            epochs_, mse_ = zip(*mse.items())\n            plt.plot(epochs_, mse_)\n            plt.xlabel(\"Epochs\")\n            plt.ylabel(\"Train Error (MSE)\")\n            plt.show()\n            \n                    \n    def predict(self, X):\n        Y = []\n        for x in X:\n            result = self.sigmoid(self.perceptron(x))\n            Y.append(result)\n        return np.array(Y)\n\n","9b68704d":"class SigmoidNeuron:\n  \n  def __init__(self):\n    self.w = None\n    self.b = None\n    \n  def perceptron(self, x):\n    return np.dot(x, self.w.T) + self.b\n  \n  def sigmoid(self, x):\n    return 1.0\/(1.0 + np.exp(-x))\n  \n  def grad_w_mse(self, x, y):\n    y_pred = self.sigmoid(self.perceptron(x))\n    return (y_pred - y) * y_pred * (1 - y_pred) * x\n  \n  def grad_b_mse(self, x, y):\n    y_pred = self.sigmoid(self.perceptron(x))\n    return (y_pred - y) * y_pred * (1 - y_pred)\n  \n  def grad_w_ce(self, x, y):\n    y_pred = self.sigmoid(self.perceptron(x))\n    if y == 0:\n      return y_pred * x\n    elif y == 1:\n      return -1 * (1 - y_pred) * x\n    else:\n      raise ValueError(\"y should be 0 or 1\")\n    \n  def grad_b_ce(self, x, y):\n    y_pred = self.sigmoid(self.perceptron(x))\n    if y == 0:\n      return y_pred \n    elif y == 1:\n      return -1 * (1 - y_pred)\n    else:\n      raise ValueError(\"y should be 0 or 1\")\n  \n  def fit(self, X, Y, epochs=1, learning_rate=1, initialise=True, loss_fn=\"mse\", display_loss=False):\n    \n    # initialise w, b\n    if initialise:\n      self.w = np.random.randn(1, X.shape[1])\n      self.b = 0\n      \n    if display_loss:\n      loss = {}\n    \n    for i in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n      dw = 0\n      db = 0\n      for x, y in zip(X, Y):\n        if loss_fn == \"mse\":\n          dw += self.grad_w_mse(x, y)\n          db += self.grad_b_mse(x, y) \n        elif loss_fn == \"ce\":\n          dw += self.grad_w_ce(x, y)\n          db += self.grad_b_ce(x, y)\n      self.w -= learning_rate * dw\n      self.b -= learning_rate * db\n      \n      if display_loss:\n        Y_pred = self.sigmoid(self.perceptron(X))\n        if loss_fn == \"mse\":\n          loss[i] = mean_squared_error(Y, Y_pred)\n        elif loss_fn == \"ce\":\n          loss[i] = log_loss(Y, Y_pred)\n    \n    if display_loss:\n      plt.plot(loss.values())\n      plt.xlabel('Epochs')\n      if loss_fn == \"mse\":\n        plt.ylabel('Mean Squared Error')\n      elif loss_fn == \"ce\":\n        plt.ylabel('Log Loss')\n      plt.show()\n      \n  def predict(self, X):\n    Y_pred = []\n    for x in X:\n      y_pred = self.sigmoid(self.perceptron(x))\n      Y_pred.append(y_pred)\n    return np.array(Y_pred)","843c72cf":"def read_all(folder_path, key_prefix=\"\"):\n    '''\n    It returns a dictionary with 'file names' as keys and 'flattened image arrays' as values.\n    '''\n    print(\"Reading:\")\n    images = {}\n    files = os.listdir(folder_path)\n#     invert_clr = lambda x: 0 if x > 10 else 255\n    for i, file_name in tqdm_notebook(enumerate(files), total=len(files)):\n        file_path = os.path.join(folder_path, file_name)\n        image_index = key_prefix + file_name[:-4]\n        image = Image.open(file_path)\n   \n        Lim=image.convert(\"L\")\n        \n        threshold = 12\n        # if pixel value smaller than threshold, return 0 . Otherwise return 1.\n        filter_func = lambda x: 0 if x < threshold else 1         \n        image=Lim.point(filter_func, \"1\")  \n        image = image.filter(ImageFilter.MedianFilter())\n        images[image_index] = np.array(image.copy()).flatten()\n        image.close()\n    return images","afb7ed2e":"languages = ['ta', 'hi', 'en']\n\nimages_train = read_all(\"..\/input\/level_3_train\/\"+LEVEL+\"\/\"+\"background\", key_prefix='bgr_') # change the path\nfor language in languages:\n  images_train.update(read_all(\"..\/input\/level_3_train\/\"+LEVEL+\"\/\"+language, key_prefix=language+\"_\" ))\nprint(len(images_train))\n\nimages_test = read_all(\"..\/input\/level_3_test\/kaggle_\"+LEVEL, key_prefix='') # change the path\nprint(len(images_test))","7c2b0181":"list(images_test.keys())[:5]","3924dfcf":"X_train = []\nY_train = []\nfor key, value in images_train.items():\n    X_train.append(value)\n    if key[:4] == \"bgr_\":\n        Y_train.append(0)\n    else:\n        Y_train.append(1)\n\nID_test = []\nX_test = []\nfor key, value in images_test.items():\n  ID_test.append(int(key))\n  X_test.append(value)\n  \n        \nX_train = np.array(X_train)\nY_train = np.array(Y_train)\nX_test = np.array(X_test)\n\nprint(X_train.shape, Y_train.shape)\nprint(X_test.shape)","39427c4e":"scaler = StandardScaler()\nX_scaled_train = scaler.fit_transform(X_train)\nX_scaled_test = scaler.transform(X_test)","d7058d9e":"# sn_mse = PerceptronWithSigmoid()\n# sn_mse.fit(X_scaled_train, Y_train, epochs=200, learning_rate=0.1, \n#                    log=False, display_plot=True)","ea632726":"# def print_accuracy(sn):\n#   Y_pred_train = sn.predict(X_scaled_train)\n#   Y_pred_binarised_train = (Y_pred_train >= 0.5).astype(\"int\").ravel()\n#   accuracy_train = accuracy_score(Y_pred_binarised_train, Y_train)\n#   print(\"Train Accuracy : \", accuracy_train)\n#   print(\"-\"*50)\n\n# print_accuracy(sn_mse)","a76a4a00":"X = X_train\ny = Y_train\nX_train_tr, X_valid, y_train_tr, y_valid = train_test_split(X,y, random_state=17, test_size=0.33)","faa5a556":"print(X_train_tr.shape, y_train_tr.shape)\nprint(X_valid.shape, y_valid.shape)","d88bf736":"scaler = StandardScaler()\nX_scaled_train_tr = scaler.fit_transform(X_train_tr)\nX_scaled_valid_tr = scaler.transform(X_valid)\nX_scaled_test = scaler.transform(X_test)\n\n# sn_mse = PerceptronWithSigmoid()\n# sn_mse.fit(X_scaled_train_tr, y_train_tr, epochs=500, learning_rate=0.05, \n#                    log=False, display_plot=True)\n\nsn_ce = SigmoidNeuron()\nsn_ce.fit(X_scaled_train_tr, y_train_tr, epochs=500,\n          learning_rate=0.015, loss_fn=\"ce\", display_loss=True)\n\n\n\ndef print_accuracy_train(sn):\n  Y_pred_train_tr = sn.predict(X_scaled_train_tr)\n  Y_pred_binarised_train_tr = (Y_pred_train_tr >= 0.5).astype(\"int\").ravel()\n  accuracy_train = accuracy_score(Y_pred_binarised_train_tr, y_train_tr)\n  print(\"Train Accuracy : \", accuracy_train)\n  print(\"-\"*50)\n\ndef print_accuracy_valid(sn):\n  Y_pred_valid_tr = sn.predict(X_scaled_valid_tr)\n  Y_pred_binarised_valid_tr = (Y_pred_valid_tr >= 0.5).astype(\"int\").ravel()\n  accuracy_valid = accuracy_score(Y_pred_binarised_valid_tr, y_valid)\n  print(\"Valid Accuracy : \", accuracy_valid)\n  print(\"-\"*50)","b6ceea6c":"print_accuracy_train(sn_ce)\nprint_accuracy_valid(sn_ce)","be079c2b":"# def runSigmoidNeuron(train_X, train_y, test_X, test_y=None, test_X2=None):\n#     model = SigmoidNeuron()\n#     model.fit(train_X, train_y, epochs=500, \n#               learning_rate= 0.1, loss_fn=\"ce\", display_loss=False)    \n    \n#     train_preds = model.predict(train_X)    \n#     train_preds = (train_preds >= 0.5).astype(\"int\").ravel()\n    \n#     test_preds = model.predict(test_X)\n#     test_preds = (test_preds >= 0.5).astype(\"int\").ravel()\n    \n#     test_preds2 = model.predict(test_X2)\n#     test_preds2 = (test_preds2 >= 0.5).astype(\"int\").ravel()\n    \n#     train_accuracy = accuracy_score(train_y, train_preds)\n#     test_accuracy = accuracy_score(test_y, test_preds)\n#     print(\"Train and Test Accuracy : \", train_accuracy, test_accuracy)\n#     return test_preds, test_accuracy, test_preds2","d63461bd":"# # Necessary imports: \n# from sklearn.model_selection import cross_val_score, cross_val_predict\n# from sklearn import metrics\n# from sklearn.model_selection import RepeatedKFold, KFold    \n# cv_scores = []\n# pred_test_full = []\n# kf = KFold(n_splits=5, random_state=None, shuffle=False)\n# for dev_index, val_index in kf.split(X_scaled_train,Y_train):\n\n#     dev_X, val_X = X_scaled_train[dev_index,:], X_scaled_train[val_index,:]\n#     dev_y, val_y = Y_train[dev_index], Y_train[val_index]\n    \n#     pred_val, Accu, pred_test = runSigmoidNeuron(dev_X, dev_y, val_X, val_y, X_scaled_test)\n\n#     cv_scores.append(Accu)\n#     pred_test_full.append(pred_test)\n#     print(cv_scores)\n# # pred_test_full \/= 5.","fda4563c":"# data = pd.DataFrame(pred_test_full)\n\n# data1 = (data.T)\n# data1.columns = ['a', 'b', 'c', 'd', 'e']\n# data1['e'] = (data1['a'] + data1['b']+data1['c']+data1['d']+data1['e'])\n# data1['f'] = data1['e'].apply(lambda x: 1 if x >= 2 else 0)\n# data1['f'].value_counts()","86fe058c":"# submission = {}\n# submission['ImageId'] = ID_test\n# submission['Class'] = data1['f']\n\n# submission = pd.DataFrame(submission)\n# submission = submission[['ImageId', 'Class']]\n# submission = submission.sort_values(['ImageId'])\n# submission.to_csv(\"submisision.csv\", index=False)","ed5e7c9f":"Y_pred_test = sn_ce.predict(X_scaled_test)\nY_pred_binarised_test = (Y_pred_test >= 0.5).astype(\"int\").ravel()\n\nsubmission = {}\nsubmission['ImageId'] = ID_test\nsubmission['Class'] = Y_pred_binarised_test\n\nsubmission = pd.DataFrame(submission)\nsubmission = submission[['ImageId', 'Class']]\nsubmission = submission.sort_values(['ImageId'])\nsubmission.to_csv(\"submisision.csv\", index=False)","238ee960":"## Sample Submission"}}