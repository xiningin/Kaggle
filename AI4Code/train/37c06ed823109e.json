{"cell_type":{"1e5549d6":"code","41b1ea10":"code","292e8d0f":"code","4b296b7b":"code","260c1f92":"code","e5907432":"code","33cd6871":"code","432e977c":"code","1e09b87e":"code","4ddfce43":"code","e116fa61":"code","7f01dc68":"code","083ab0ba":"code","d365f018":"code","0bb03d46":"code","71fc8106":"code","1a14aa88":"code","584f9916":"code","c2856eb7":"code","504851f8":"code","82d85b44":"code","e2965c56":"code","e71245d9":"code","22f1cd68":"code","11f546be":"code","222f6ba4":"code","4e4f92ce":"code","95c499a7":"code","adb9f380":"code","36d0bc66":"code","92e83428":"code","85fc3357":"code","ca88fb3d":"code","5d87e34a":"code","7b620c1f":"code","d122c863":"code","25606174":"code","fcc56ac2":"code","6d2be5e1":"code","dea1b1b7":"code","516baa9e":"code","9cfe945f":"code","8b1f8395":"code","049b9da5":"code","0373d02a":"code","ed6cebdb":"code","cd09a5e7":"code","6733ff8c":"code","21efc175":"code","b20bfa6f":"code","09020607":"code","33aeedda":"code","6bcbd775":"code","cbffeedd":"code","51d339a7":"code","9dcfd6f0":"code","a5d23baf":"code","7e080736":"code","a6130c3b":"code","13983ad1":"code","8d4d7f87":"code","4bb5964b":"code","c7633045":"code","ea0dd3b2":"code","45bb45e1":"code","7e878401":"code","a86cf6fc":"code","01e39203":"code","d5832972":"code","6ee5d8fd":"code","a2f0bd12":"code","09faa49a":"code","dbb922d7":"code","1552489d":"code","3b89d357":"code","5e0d6d38":"code","0a7572b9":"code","6ea34e00":"code","648878e7":"code","2da1adc2":"code","795ed391":"code","c47f6ee2":"code","6e540d19":"code","97b42e9b":"code","f2e49b64":"code","d322c020":"code","e33db24e":"code","e1afe6a6":"code","c37789e0":"code","a147770c":"code","28b553a7":"code","56be961f":"code","f474a791":"code","19e8f468":"code","2b98edf4":"code","00624d42":"code","f2977c35":"code","9a870644":"code","c3d0a1bf":"code","f4fb8e74":"code","b588b859":"code","9c79f716":"markdown","4af02113":"markdown","dd5a38a2":"markdown","936bdeee":"markdown","50926e7c":"markdown","c07f6d4a":"markdown","0fee1e30":"markdown","2c3410d5":"markdown","2a132ce0":"markdown","33929cbf":"markdown","4e802466":"markdown","c62d511c":"markdown","a9ce8a14":"markdown","e11c4f8b":"markdown","20a19ba0":"markdown","4ec85d31":"markdown","58df314d":"markdown","e6751d38":"markdown","3a245884":"markdown","6e0b9b1e":"markdown","fced3dbf":"markdown","85f4c036":"markdown","5e7a2d3b":"markdown","267da5ed":"markdown","6fe789a6":"markdown","2e765c94":"markdown","d704b336":"markdown","e9a2a1a3":"markdown","85fbb520":"markdown","95bd96f6":"markdown","ae4f92c7":"markdown","36d384aa":"markdown","6c40a00c":"markdown","0b78f0fb":"markdown","44749fd0":"markdown","b5d0e326":"markdown","a1f99434":"markdown","ed770def":"markdown","542da00b":"markdown","468a5a02":"markdown","e8dbd647":"markdown","fbae4718":"markdown","8fba0f16":"markdown","47da1cd2":"markdown","8df6be33":"markdown","349c8929":"markdown","30ea4455":"markdown","f1588a53":"markdown","1917f35d":"markdown","ab3b566f":"markdown","0d4fabb5":"markdown","acd0b80a":"markdown","ae274165":"markdown","81bcd5b2":"markdown","a905a814":"markdown","7db2e81c":"markdown"},"source":{"1e5549d6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns # visualization tool\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","41b1ea10":"data = pd.read_csv(\"..\/input\/iris\/Iris.csv\") ","292e8d0f":"data.info() ","4b296b7b":"data.corr()","260c1f92":"#correlation map\nf,ax = plt.subplots(figsize =(18,18))\nsns.heatmap(data.corr(), annot= True,linewidths = 0.5, fmt = \"0.2f\",ax = ax)\n# annot = If True, write the data value in each cell. fmt =String formatting code to use when adding annotations.\nplt.show()","e5907432":"data.head(10) # return first 10 rows","33cd6871":"data.columns","432e977c":"# Line Plot\n#color = color, label = label, linewidth = width of line, alpha = opacity, grid = grid, linestyle = sytle of line\ndata.SepalLengthCm.plot(kind = \"line\", color =\"green\", label = \"SepalLengthCm\", linewidth = 1, alpha = 0.7, grid = True, linestyle = \":\")\ndata.PetalLengthCm.plot(kind = \"line\", color = \"red\", label = \"PetalLengthCm\", linewidth =1 , alpha = 0.7, grid = True, linestyle = \"-.\")\nplt.legend() # legend = puts label into plot\nplt.xlabel(\"x axis\") # label = name of label\nplt.ylabel(\"y label\") # label = name of label\nplt.title(\"Line Plot\") #title = title of plot\nplt.show()","1e09b87e":"# Scatter Plot \n# x = PetalLengthCm, y = SepalLengthCm\ndata.plot(kind =\"scatter\", x = \"PetalLengthCm\",y =\"SepalLengthCm\", alpha = 0.7, color= \"red\")\nplt.title(\"SepalLengthCm-PetalLengthCm Scatter Plot\") #title = title of plot\n","4ddfce43":"# Histogram\n# bins = number of bar in figure\ndata.PetalLengthCm.plot(kind = \"hist\", bins = 50, figsize = (12,12))\nplt.title(\"Histogram of PetalLengthCm\")","e116fa61":"# clf() = cleans it up again you can start a fresh\ndata.PetalLengthCm.plot(kind = \"hist\", bins = 50)\nplt.clf()\n# We cannot see plot due to clf()","7f01dc68":"#create dictionary and look its keys and values\ndictionary = {\"Poland\":\"Poznan\",\"Germany\":\"Berlin\",\"Turkey\":\"Istanbul\"}\nprint(dictionary.keys())\nprint(dictionary.values())\nprint(type(dictionary))","083ab0ba":"# Keys have to be immutable objects like string, boolean, float, integer or tubles\n# List is not immutable\n# Keys are unique\ndictionary[\"Poland\"] = \"Warsaw\" #update existing entry\nprint(dictionary)\ndictionary[\"France\"] = \"Paris\" # Add new key and value\nprint(dictionary)\ndel dictionary[\"Germany\"] # remove entry with key \"Germany\"\nprint(dictionary)\nprint(\"Turkey\" in dictionary)  # check include or not\ndictionary.clear()  # remove all entries in dict\nprint(dictionary)","d365f018":"data = pd.read_csv(\"..\/input\/iris\/Iris.csv\")","0bb03d46":"series = data[\"SepalLengthCm\"]   # data['SepalLengthCm'] = series\nprint(type(series))\ndata_frame = data[[\"SepalLengthCm\"]]  # # data[['SepalLengthCm']] = data frame\nprint(type(data_frame))","71fc8106":"# Filtering Pandas data frame\nx = data[\"SepalLengthCm\"] > 7 # There are 12 flowers who have higher SepalLengthCm value than 7\ndata[x]","1a14aa88":"# Filtering pandas with logical_and\ndata[np.logical_and(data[\"SepalLengthCm\"]>7, data[\"PetalLengthCm\"] > 6 )]\n# There are 9 flowers who have higher SepalLengthCm value than 7 and higher PetalLengthCm value than 6","584f9916":"# This is also same with previous code line. Therefore we can also use '&' for filtering\ndata[(data[\"SepalLengthCm\"] > 7) & (data[\"PetalLengthCm\"] > 6)]","c2856eb7":"# Stay in loop if condition( i is not equal 5) is true\ni = 0\nwhile i!= 5:\n    print(\"i is \",i)\n    i +=1\nprint(i,\"is equal to 5\")","504851f8":"# Stay in loop if condition( i is not equal 5) is true\nliste = [-1,-2,-3,-4,-5]\nfor i in liste :\n    print(\"i is \",i)\nprint(\"\")\n\n# Enumerate index and value of list\n# index : value = 0:-1, 1:-2, 2:-3, 3:-4, 4:-5\nfor index,value in enumerate(liste):\n    print(index,\":\",value)\nprint(\"\")\n\n#For dictionary we can reach index and value\nfor key,value in dictionary.items():\n    print(key,\":\",value)\nprint(\"\")\n\n#For pandas we can reach index and value\nfor index,value in data[[\"SepalLengthCm\"]][0:1].iterrows():\n    print(index,\":\",value)\nprint(\"\")","82d85b44":"# example of what we learn above\ndef tuble_ex():\n    \"\"\"\"return defined t tuble\"\"\"\n    t= (1,2,3)\n    return t\na,b,c = tuble_ex()\nprint(a,b,c)","e2965c56":"# guess print what\nx = 2\ndef f():\n    x = 3\n    return x\nprint(x) # x = 2 global scope\nprint(f()) # x = 3 local scope","e71245d9":"# What if there is no local scope\nx = 5\ndef f():\n    y = x*x # there is no local scope x\n    return y\nprint(f()) # it uses global scope x\n# First local scopesearched, then global scope searched, if two of them cannot be found lastly built in scope searched.","22f1cd68":"# How can we learn what is built in scope\nimport builtins\ndir(builtins)","11f546be":"# nested function\ndef square():\n    \"\"\"\" return square of func\"\"\"\n    def add():\n        x = 2\n        y = 3\n        z = x+y\n        return z\n    return add()**2\nprint(square())","222f6ba4":"# default arguments\ndef f(a, b= 1, c = 2):\n    y = a + b + c\n    return y\nprint(f(5))\n# what if we want to change default arguments\nprint(f(5,4,3))","4e4f92ce":"# flexible arguments *args\ndef f(*args):\n    for i in args:\n        print(i)\nf(1)\nprint(\"\")\nf(1,2,3,4)\n# flexible arguments **kwargs that is dictionary\ndef f(**kwargs):\n    \"\"\" print key and value of dictionary\"\"\"\n    for key,value in kwargs.items(): # If you do not understand this part turn for loop part and look at dictionary in for loop\n        print(key,\":\",value)\nf(country = 'spain', capital = 'madrid', population = 123456)","95c499a7":"# Lambda Function\ntot = lambda x,y,z: x+y+z   # where x,y,z are names of arguments\nprint(tot(1,2,3))","adb9f380":"number_list = [10,20,30]\ny = map(lambda x:x**2, number_list)\nprint(list(y))","36d0bc66":"# iteration example\nname = \"ISTANBUL\"\nit = iter(name)\nprint(next(it))  # print next iteration\nprint(*it)       # print remaining iteration","92e83428":"# zip example\nlist1 = [10,20,30,40]\nlist2 = [50,60,70,80]\nz = zip(list1,list2)\nprint(z)\nnewlist = list(z)\nprint(newlist)","85fc3357":"unzip = zip(*newlist)\nunlist1,unlist2 = list(unzip)  # unzip returns tuble\nprint(unlist1)\nprint(unlist2)\nprint(type(unlist1))","ca88fb3d":"#[2*i+i**2 for i in num1 ]: list of comprehension\n#i +1: list comprehension syntax\n#for i in num1: for loop syntax\n#i: iterator\n#num1: iterable object\nnum1 = [10,20,30]\nnum2 = [2*i+i**2 for i in num1 ]\nprint(num2)","5d87e34a":"# Conditionals on iterable\nnum3 = [10,20,30]\nnum4 = [i**2 if i==10 else i-5 if i == 20 else i+5 for i in num3]\nprint(num4)","7b620c1f":"# lets classify flowers whether they have high or low Sepal Length. Our threshold is average Length.\nthreshold = sum(data.SepalLengthCm)\/len(data.SepalLengthCm)\ndata[\"Sepal_Length\"] = [\"high\" if i>threshold else \"low\" for i in data.SepalLengthCm]\ndata.loc[::-10,[\"Sepal_Length\",\"SepalLengthCm\"]]","d122c863":"data = pd.read_csv(\"..\/input\/iris\/Iris.csv\")\ndata.head() # head shows first 5 rows","25606174":"data.tail() # tail shows last 5 rows","fcc56ac2":"data.columns # columns gives column names of features","6d2be5e1":"data.shape","dea1b1b7":"data.info() # info gives data type, number of sample or row, number of feature or column, feature types and memory usage","516baa9e":"print(data[\"Species\"].value_counts(dropna = False)) #For example lets look frequency of Species\n# if there are nan values that also be counted\n","9cfe945f":"data.describe() #ignore null entries","8b1f8395":"data.boxplot(column = \"SepalLengthCm\", by = \"Species\")\n#compare SepalLengthCm of flowers that are Iris-virginica, Iris-setosa or Iris-versicolor","049b9da5":"# Firstly I create new data from Iris Species data to explain melt nore easily.\ndata_new = data.head() # I only take 5 rows into new data\ndata_new","0373d02a":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame = data_new , id_vars = \"Species\", value_vars = [\"PetalWidthCm\", \"PetalLengthCm\"])\nmelted","ed6cebdb":"df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',\n                            'two'],\n                    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n                    'baz': [1, 2, 3, 4, 5, 6],\n                    'zoo': ['x', 'y', 'z', 'q', 'w', 't']})\ndf","cd09a5e7":"df.pivot(index='foo', columns='bar', values='baz')\n#Return reshaped DataFrame organized by given index \/ column values.","6733ff8c":"data1 = data.head()\ndata2 = data.tail()\nconc_data_row = pd.concat([data1,data2],axis = 0,ignore_index = True) # axis = 0 : adds dataframes in row\nconc_data_row","21efc175":"data3 = data[\"SepalLengthCm\"].head()\ndata4 = data[\"PetalLengthCm\"].head()\nconc_data_col = pd.concat([data3,data4],axis =1,ignore_index = False) # axis = 0 : adds dataframes in col\nconc_data_col","b20bfa6f":"data.dtypes","09020607":"# lets convert object(str) to categorical and int to float.\ndata[\"Species\"] = data[\"Species\"].astype(\"category\") #object(str) to categorical\ndata[\"Id\"] = data[\"Id\"].astype(\"float\") #int to float.\ndata.dtypes","33aeedda":"data.info()","6bcbd775":"data[\"SepalLengthCm\"].value_counts(dropna =False)","cbffeedd":"# If we would have some NaN values, we could drop these values. For example :\ndf1 = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n                             pd.NaT]})\ndf1","51d339a7":"df1.dropna(inplace=True) # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\ndf1","9dcfd6f0":"assert df1[\"toy\"].notnull().all()  # returns nothing because we drop nan values","a5d23baf":"# data frames from dictionary\ncountry = [ \"Germany\",\"Turkey\"]\npopulation = [\"10\",\"11\"]\nlist_label = [\"country\",\"population\"]\nlist_col = [country,population]\nzipped = list(zip(list_label,list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf","7e080736":"df[\"capital\"] = [\"berlin\",\"ankara\"]\ndf","a6130c3b":"df[\"income\"] = 0 #Broadcasting entire column\ndf","13983ad1":"# plot data \ndata1 = data.loc [:,[\"SepalLengthCm\",\"PetalLengthCm\"]]\ndata1.plot()","8d4d7f87":"# subplot\ndata1.plot(subplots = True)\nplt.show()","4bb5964b":"# scatter plot\ndata1.plot(kind =\"scatter\", x = \"SepalLengthCm\", y = \"PetalLengthCm\")\nplt.show()","c7633045":"# hist plot\ndata1.plot ( kind = \"hist\",y = \"SepalLengthCm\", bins = 50, normed = True)\nplt.show ()","ea0dd3b2":"# histogram subplot with non cumulative and cumulative\n#bins: number of bins , range(tuble): min and max values of bins, normed(boolean): normalize or not , cumulative(boolean): compute cumulative distribution\nfig , axes = plt.subplots (nrows = 2, ncols = 1)\ndata1.plot(kind = \"hist\", y = \"SepalLengthCm\", bins = 50 , normed = True, ax = axes[0] ) \ndata1.plot(kind =\"hist\", y =\"SepalLengthCm\", bins = 50, normed = True, ax = axes[1], cumulative = True)\nplt.savefig(\"graph.png\")\nplt","45bb45e1":"time_list = [\"1995-10-05\",\"1995-12-06\"]\nprint(type(time_list[1])) #date is string\ndatetime_object = pd.to_datetime(time_list) # from list to datetime\nprint(type(datetime_object)) ","7e878401":"# In order to practice lets take head of Iris data and add it a time list\ndata2= data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime1_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime1_object\ndata2 = data2.set_index(\"date\") # make date as index\ndata2","a86cf6fc":"print(data2.loc[\"1993-03-16\"])\nprint(data2.loc[\"1992-03-10\":\"1993-03-16\"])","01e39203":"# We will use data2 that we create at previous part\ndata2.resample(\"A\").mean()","d5832972":"data2.resample(\"M\").mean() #there are a lot of nan because data2 does not include all months","6ee5d8fd":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\ndata2.resample(\"M\").mean().interpolate(\"linear\")","a2f0bd12":"# read data\ndata = pd.read_csv(\"..\/input\/iris\/Iris.csv\")\ndata = data.set_index(\"Id\")\ndata.head()","09faa49a":"# indexing using square brackets\ndata[\"SepalLengthCm\"][1]","dbb922d7":"# using column attribute and row label\ndata.SepalLengthCm[1]","1552489d":"# using loc accessor\ndata.loc[1,[\"SepalLengthCm\"]]","3b89d357":"# Selecting only some columns\ndata[[\"SepalLengthCm\",\"SepalWidthCm\"]]","5e0d6d38":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"SepalLengthCm\"]))\nprint(type(data[[\"SepalLengthCm\"]]))","0a7572b9":"# Slicing and indexing series\ndata.loc[1:10,\"SepalLengthCm\":\"SepalWidthCm\"]","6ea34e00":"# Reverse slicing\ndata.loc[10:1:-1,\"SepalLengthCm\":\"SepalWidthCm\"]","648878e7":"# From something to end\ndata.loc[1:10,\"SepalLengthCm\":]","2da1adc2":"boolean = data.SepalWidthCm >3.5\ndata[boolean]","795ed391":"# Combining filters\nfirst_filter = data.SepalWidthCm > 3.5\nsecond_filter = data.PetalWidthCm > 0.3\ndata[first_filter & second_filter]","c47f6ee2":"# Filtering column based others\ndata.SepalLengthCm[data.PetalLengthCm > 6]","6e540d19":"# Plain python functions\ndef div(n):\n    return n\/2\ndata.SepalLengthCm.apply(div)","97b42e9b":"# Or we can use lambda function\ndata.SepalLengthCm.apply(lambda n: n\/2)","f2e49b64":"# Defining column using other columns\ndata[\"total_length\"] = data.SepalLengthCm + data.PetalLengthCm\ndata.head()","d322c020":"# our index name is this:\nprint(data.index.name)","e33db24e":"data.index.name = \"index_name\"\ndata.head()","e1afe6a6":"!!!!!!!!!# Overwrite index\ndata3 = data.copy()\ndata3.index = range(0,150,5)\ndata3.head()","c37789e0":"data = pd.read_csv(\"..\/input\/iris\/Iris.csv\")\ndata.head() # # As you can see there is index. However we want to set one or more column to be index","a147770c":"data1 = data.set_index([\"SepalLengthCm\",\"PetalLengthCm\"])\ndata1.head(100)","28b553a7":"dic = {\"treatment\":[\"A\",\"A\",\"B\",\"B\"],\"gender\":[\"F\",\"M\",\"F\",\"M\"],\"response\":[10,45,5,9],\"age\":[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf","56be961f":"# pivoting\ndf.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")","f474a791":"df1 = df.set_index([\"treatment\",\"gender\"])\ndf1","19e8f468":"# level determines indexes\ndf1.unstack(level=0)","2b98edf4":"df1.unstack(level=1)","00624d42":"# change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","f2977c35":"df","9a870644":"# df.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")\npd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"])","c3d0a1bf":"# according to treatment take means of other features\ndf.groupby(\"treatment\").mean() # mean is aggregation \/ reduction method\n# there are other methods like sum, std,max or min","f4fb8e74":"# Or we can choose multiple features\ndf.groupby(\"treatment\")[[\"age\",\"response\"]].min() ","b588b859":"df.info()\n# as you can see gender is object\n# However if we use groupby, we can convert it categorical data. \n# Because categorical data uses less memory, speed up operations like groupby\n#df[\"gender\"] = df[\"gender\"].astype(\"category\")\n#df[\"treatment\"] = df[\"treatment\"].astype(\"category\")\n#df.info()","9c79f716":"    5.Manipulating Data Frames with Pandas\n* Indexing data frames\n* Slicing data frames\n* Filtering data frames\n* Transforming data frames\n* Index objects and labeled data\n* Hierarchical indexing\n* Pivoting data frames\n* Stacking and unstacking data frames\n* Melting data frames\n* Categoricals and groupby","4af02113":"* PANDAS\n\nWhat we need to know about pandas?\n1. CSV: comma - separated values","dd5a38a2":"value_counts(): Frequency counts\n\noutliers: the value that is considerably higher or lower from rest of the data\n\n1. Lets say value at 75% is Q3 and value at 25% is Q1.\n\nOutlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n\nWe will use describe() method. Describe method includes:\n\ncount: number of entries\n\nmean: average of entries\n\nstd: standart deviation\n\nmin: minimum entry\n\n25%: first quantile\n\n50%: median or second quantile\n\n75%: third quantile\n\nmax: maximum entry\n\n2. What is quantile?\n\n1,4,5,6,8,9,11,12,13,14,15,16,17\n\nThe median is the number that is in middle of the sequence. In this case it would be 11.\n\nThe lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n\nThe upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.","936bdeee":"* DIAGNOSE DATA for CLEANING\n\nWe need to diagnose and clean data before exploring.\n\nUnclean data:\n\nColumn name inconsistency like upper-lower case letter or space between words\nmissing data\ndifferent language\n\nWe will use head, tail, columns, shape and info methods to diagnose data","50926e7c":"* INDEXING PANDAS TIME SERIES","c07f6d4a":"* PIVOTING DATA\n\nReverse of melting","0fee1e30":"* STACKING and UNSTACKING DATAFRAME","2c3410d5":"* USER DEFINED FUNCTION\n\nWhat we need to know about functions:\n1. docstrings: documentation for functions. Example:\nfor f():\n\"\"\"This is docstring for documentation of function f\"\"\"\n1. tuble: sequence of immutable python objects.\n cant modify values\n tuble uses paranthesis like tuble = (1,2,3)\n unpack tuble into several variables like a,b,c = tuble","2a132ce0":"Creating boolean series Combining filters Filtering column based others","33929cbf":"* NESTED FUNCTION\n\n function inside function.\n \n There is a LEGB rule that is search local scope, enclosing function, global and built in scopes, respectively.","4e802466":"* SCOPE\n\nWhat we need to know about scope:\n\n1. global: defined main body in script,\n2. local: defined in a function,\n3. built in scope: names in predefined built in scope module such as print, len","c62d511c":"    4.Pandas Foundation\n* Review of pandas\n* Building data frames from scratch\n* Visual exploratory data analysis\n* Statistical explatory data analysis\n* Indexing pandas time series\n* Resampling pandas time series","a9ce8a14":"1. Default argument:\n\n-def(a,b=1)  #b = 1 is default argument\n\n2. Flexible argument example:\n\n-def(f*args) #*args can be one or more\n\n-def f(** kwargs) # **kwargs is a dictionary\n","e11c4f8b":"* DEFAULT and FLEXIBLE ARGUMENTS\n","20a19ba0":"* VISUAL EXPLORATORY DATA ANALYSIS","4ec85d31":"* FILTERING DATA FRAMES","58df314d":"Reverse of pivoting","e6751d38":"    3.Cleaning Data\n* Diagnose data for cleaning\n* Exploratory data analysis\n* Visual exploratory data analysis\n* Tidy data\n* Pivoting data\n* Concatenating data\n* Data types\n* Missing data and testing with assert","3a245884":"* ITERATORS\n\n-iterable is an object that can return an iterator\n\n-iterable: an object with an associated iter() method;\n\nexample: list, strings and dictionaries\n\n-iterator: produces next value with next() method\n","6e0b9b1e":"* TRANSFORMING DATA","fced3dbf":"**5.MANIPULATING DATA FRAMES WITH PANDAS**","85f4c036":"* MISSING DATA and TESTING WITH ASSERT\n\nIf we encounter with missing data, what we can do:\n\n-leave as is\n\n-drop them with dropna()\n\n-fill missing value with fillna()\n\n-fill missing values with test statistics like mean\n\nAssert statement: check that you can turn on or turn off when you are done with your testing of the program","5e7a2d3b":"* PIVOTING DATA FRAMES","267da5ed":"* RESAMPLING PANDAS TIME SERIES","6fe789a6":"* CONCATENATING DATA\n\nWe can concatenate two dataframe","2e765c94":"* HIERARCHICAL INDEXING","d704b336":"-Difference between selecting columns  - (Series and data frames)\n\n-Slicing and indexing series\n\n-Reverse slicing\n\n-From something to end","e9a2a1a3":"* BUILDING DATA FRAMES FROM SCRATCH","85fbb520":"* INDEXING DATA FRAMES\n\n-Indexing using square brackets\n\n-Using column attribute and row label\n\n-Using loc accessor\n\n-Selecting only some columns","95bd96f6":"-Resampling: statistical method over different time intervals                                                                                                      -(Needs string to specify frequency like \"M\" = month or \"A\" = year)\n\n-Downsampling: reduce date time rows to slower frequency like from daily to weekly\n\n-Upsampling: increase date time rows to faster frequency like from daily to hourly\n\n-Interpolate: Interpolate values according to different methods like \u2018linear\u2019, \u2018time\u2019 or index\u2019\n","ae4f92c7":"* TIDY DATA\n\nWe tidy data with melt(). Describing melt is confusing. Therefore lets make example to understand it.","36d384aa":"* WHILE and FOR LOOPS\n\nWe will learn most basic while and for loops","6c40a00c":"* SLICING DATA FRAME","0b78f0fb":"* ANONYMOUS FUNCTION\n\nLike lambda function but it can take more than one arguments.\n\n-map(func,seq) : applies a function to all the items in a list\n","44749fd0":"** 1. INTRODUCTION TO PYTHON**","b5d0e326":"-deal with multi label indexes\n\n-level: position of unstacked index\n\n-swaplevel: change inner and outer level index position\n","a1f99434":"-pivoting: reshape tool","ed770def":"* INDEX OBJECTS AND LABELED DATA","542da00b":"* MATPLOTL\u0130B \n\nMatplot is a python library that help us to plot data. The easiest and basic plots are line, scatter and histogram plots\n1. Line plot is better when x axis is time.\n2. Scatter is better when there is correlation between two variables\n3. Histogram is better when we need to see distribution of numerical data.\n4. Customization: Colors,labels,thickness of line, title, opacity, grid, figsize, ticks of axis and linestyle","468a5a02":"Content:\n\n    1.Introduction to Python:\n*     Matplotlib\n*     Dictionaries\n*     Pandas\n*     Logic, control flow and filtering\n*     Loop data structures\n","e8dbd647":"-Setting indexing","fbae4718":"index: sequence of label","8fba0f16":"* DICTONARY\n\nWhy we need dictionary?\n\n-It has 'key' and 'value'\n\n-Faster than lists\n\n-What is key and value. Example:\ndictionary = {'Poland' : 'Poznan'}\nKey is spain.\nValues is madrid.","47da1cd2":"* EXPLORATORY DATA ANALYSIS","8df6be33":"** 2. PYTHON DATA SCIENCE TOOLBOX**","349c8929":"* DATA TYPES\n\nThere are 5 basic data types: object(string),booleab, integer, float and categorical.\n\nWe can make conversion data types like from str to categorical or from int to float\n\nWhy is category important:\n\n-make dataframe smaller in memory\n\n-can be utilized for anlaysis especially for sklear(we will learn later)","30ea4455":"* LAMBDA FUNCTION\n\nFaster way of writing function","f1588a53":"-Plain python functions\n\n-Lambda function: to apply arbitrary python function to every element\n\n-Defining column using other columns","1917f35d":"**3.CLEANING DATA**","ab3b566f":"* MELTING DATA FRAMES","0d4fabb5":"-datetime = object\n\n-parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format","acd0b80a":"**4. PANDAS FOUNDATION**","ae274165":"* VISUAL EXPLORATORY DATA ANALYSIS\n\n-Box plots: visualize basic statistics like outliers, min\/max or quantiles\n","81bcd5b2":"* LIST COMPREHENSION\n\nlist comprehension: collapse for loops for building lists into a single line\n\nEx: num1 = [1,2,3] and we want to make it num2 = [2,3,4]. This can be done with for loop. However it is unnecessarily long. We can make it one line code that is list comprehension.","a905a814":"    2.Python Data Science Toolbox:\n* User defined function\n* Scope\n* Nested function\n* Default and flexible arguments\n* Lambda function\n* Anonymous function\n* Iterators\n* List comprehension","7db2e81c":"CATEGORICALS AND GROUPBY"}}