{"cell_type":{"1dd6c127":"code","be0a1d37":"code","0b86cb24":"code","018fcec3":"code","18bd126d":"code","f668fb41":"code","ab3675bf":"code","e68fb121":"code","9b52d9d0":"code","3172a53f":"code","b70332c1":"code","ffdeb801":"code","755739b3":"code","4c979331":"code","d263e213":"code","0a09eb98":"code","ee189e35":"code","365c993f":"code","8d7c8932":"code","7d2dc182":"markdown","43b6cf0b":"markdown","ace1f9f8":"markdown","505de06d":"markdown","20e55fa9":"markdown"},"source":{"1dd6c127":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","be0a1d37":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.preprocessing import image\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nimport zipfile,os \nimport pandas as pd","0b86cb24":"!pip install split_folders tqdm #for dataset train test split \n!pip install seedir #for directory treeview \nimport splitfolders #for easier dataset splitting  \nimport seedir as sd #for directory tree viewer","018fcec3":"#target directory\ntarget_dir = '..\/input\/eyes-rtte'","18bd126d":"sd.seedir(target_dir, style='lines', itemlimit=4, depthlimit=3)","f668fb41":"#split files into respective Train and Val directory using splitfolders lib\nsplitfolders.ratio(target_dir, \n                   output= '.\/split_dataset',\n                   seed=42, \n                   ratio=(0.8,0.2), \n                   group_prefix=None)","ab3675bf":"#see dir after train test split\nsd.seedir('.\/split_dataset', style='lines', itemlimit=4, depthlimit=3)","e68fb121":"#count total files inside original dataset, and total files after train and validation set split\nsplit_path = '.\/split_dataset\/'\nfolder_names = ['maleeyes', 'femaleeyes']\n\noriginal_files ={}\ntrain_files = {}\nval_files = {}\n\nfor i in folder_names:\n    original_files[i] = len(os.listdir(target_dir+'\/'+i))\n    train_files[i] = len(os.listdir(split_path+'train\/'+i))\n    val_files[i] = len(os.listdir(split_path+'val\/'+i))\n\n    \n#convert to dataframe for easier comprehension\nresult_split = pd.DataFrame()\nresult_split = result_split.append(original_files, ignore_index=True)\nresult_split = result_split.append(train_files, ignore_index=True)\nresult_split = result_split.append(val_files, ignore_index=True)\nresult_split['total'] = result_split.sum(axis=1)\nresult_split['type'] = ['original', 'train', 'val']\nresult_split = result_split[['type', 'maleeyes', 'femaleeyes', 'total']]\nresult_split","9b52d9d0":"#Display random images\nimport random\n\n#function for displaying 1 random image and image shape\ndef one_random_image(target_path, target_class): \n    target_fold = target_path + target_class\n    random_image = random.sample(os.listdir(target_fold), 1)\n    image = mpimg.imread(target_fold+'\/'+random_image[0])\n    plt.imshow(image)\n    plt.title(target_class)\n    plt.axis('off');\n    print(f\"Image shape {image.shape}\")\n\n    return image\n\n#Function for displaying group of random images and shape\ndef group_random_images( target_path, figure_size=(20, 10), group=20):\n    plt.figure(figsize=figure_size)\n    for i in range(group):\n        plt.subplot(4, 5, i+1)\n        class_name = random.choice(['maleeyes', 'femaleeyes'])\n        image = one_random_image(target_path=target_path, target_class=class_name)\n        \ngroup_random_images = group_random_images(target_path='.\/split_dataset\/train\/')","3172a53f":"## saving train and validation path \ntrain_set = '.\/split_dataset\/train'\nval_set = '.\/split_dataset\/val'","b70332c1":"#image augmentation\n#training set rescale and augmenting\ntrain_aug = ImageDataGenerator(\n                    rescale=1.\/255,\n                    rotation_range=30,\n                    horizontal_flip=True,\n                    zoom_range=0.2,\n                    shear_range = 0.2,\n                    fill_mode = 'nearest')\n\n#only rescale the validation set, dont do the augmentation step for validation set, it might cause bias\nvalid_aug = ImageDataGenerator(rescale=1.\/255)","ffdeb801":"#train and validation data generator\n#batch size 64\n#class mode is binary sincec we have 2 classes\ntrain_generator = train_aug.flow_from_directory(\n        train_set,  \n        target_size=(60, 60),  \n        batch_size=64,\n        class_mode='binary')\n\nvalidation_generator = valid_aug.flow_from_directory(\n        val_set, \n        target_size=(60, 60), \n        batch_size=64, \n        class_mode='binary')","755739b3":"#building model \n#using 1 hidden layer \n#using  sigmoid because there are 2 outcomes (binary)\nmodel = keras.Sequential([\n    layers.Conv2D(32, (3,3), activation = 'relu', input_shape= (60,60,3)),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n    layers.Conv2D(64,(3,3), activation= 'relu'),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n    layers.Conv2D(128,(3,3), activation= 'relu'),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n    layers.Flatten(),\n    layers.Dropout(0.5),\n    layers.Dense(128, activation= 'relu'),\n    layers.Dense(1, activation= 'sigmoid') #binary so output layer input dim is 1 and activation sigmoid\n])\n\nmodel.summary()","4c979331":"# Adding lose function and optimizer\n#using adam \nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['binary_accuracy'])","d263e213":"# Add early stop to prevent overfitting\nminimum_change = 0.01 #minimum change to be considered an improvement\nepoch_stop = 5 #number of epoch to wait before stopping\nearly_stop = EarlyStopping(\n    min_delta = minimum_change, \n    patience= epoch_stop, \n    restore_best_weights=True,\n)","0a09eb98":"# Training the model\nhistory = model.fit(\n    train_generator,\n    epochs=100, \n    steps_per_epoch=20,\n    validation_data = validation_generator,\n    verbose = 1,\n    validation_steps=10,\n    callbacks=[early_stop],\n)","ee189e35":"#loss \nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[1:, ['loss', 'val_loss']].plot()\nplt.show()","365c993f":"#accuracy \nhistory_df.loc[1:, ['binary_accuracy', 'val_binary_accuracy']].plot()\nplt.show()","8d7c8932":"#Best validation loss and accuracy score\nprint((\"Best Validation Loss: {:0.2f}\" +\"\\nBest Validation Accuracy: {:0.2f}\").format(history_df['val_loss'].min(), history_df['val_binary_accuracy'].max()))","7d2dc182":"### Train val split directory check","43b6cf0b":"### Image Augmentation","ace1f9f8":"## 6323 male eyes vs 5202 females eyes, little bit unbalance (1121 images difference)","505de06d":"### Display Random Images","20e55fa9":"###  Check total files"}}