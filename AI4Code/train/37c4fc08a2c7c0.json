{"cell_type":{"21867d0d":"code","60a8bc8e":"code","abd2d211":"code","ae77a22b":"code","152b3b8c":"code","e932506c":"code","ef71611f":"code","10ea3798":"code","f4d13dd9":"code","3dc7f0bb":"code","4eabfdb5":"code","34b941fc":"code","4b2a4fb7":"code","7c9d9429":"code","1c26b5ae":"code","2e470a9d":"code","c3e01168":"code","0edaf654":"code","81428f1a":"code","90e5b3a0":"code","0c105315":"code","dfef640a":"code","c6290c41":"code","f7642b00":"code","31a0d090":"code","8ea72283":"code","d98feb33":"code","b6513845":"code","494ef2bb":"code","aa9129bc":"code","a2f2950a":"code","1b32351c":"code","d80be484":"code","326d5ad8":"code","8ff89152":"code","3057ced6":"code","2d0ce8af":"code","987b63bd":"code","3e6d6e83":"code","e94cbd5b":"code","41d93751":"code","8c77dd87":"code","0f274b1a":"code","102d6c3b":"code","84940fd1":"code","f1448908":"code","7ed1f720":"code","66ca724c":"code","95781e56":"code","c1da51d0":"code","b5bd7db5":"code","10fe8d4d":"code","48f7e170":"code","73be219e":"code","83981d43":"code","9bd7ba73":"code","9e77ae09":"code","54abe1c7":"code","6ecc9dfc":"code","a90b53d7":"code","41c39506":"code","6e5f70d3":"code","e84157e8":"code","43283e92":"code","0587f055":"code","4bfeae1c":"code","e31a2c42":"code","c2922306":"code","7845f295":"code","e85a24b4":"code","6b05d3f3":"code","436ba6a8":"code","bf3a0d91":"code","5c9c2b81":"code","d0f80549":"code","8ca59cc8":"code","cd17964f":"code","ee844a07":"code","735e37bd":"code","07e8ea15":"code","f5fd6a19":"code","099164c9":"code","94aa2d04":"code","521e1b65":"code","dafadbe9":"code","f2c52807":"code","f30fd635":"code","cf4337ba":"code","e2bfe9f6":"code","a6776ba4":"code","22b9df00":"code","f3fe9481":"code","b0c024cc":"markdown","7605c7ef":"markdown","dcc8acdc":"markdown","1588f70c":"markdown","a4a6ed46":"markdown","1bf897d4":"markdown","865fe3ef":"markdown","e960e4b6":"markdown","483ba360":"markdown","763ed1c3":"markdown","9b1884d8":"markdown","42298197":"markdown","40986c39":"markdown","2c10d360":"markdown","e273475f":"markdown","810a7f84":"markdown","ef045557":"markdown","3cd6be07":"markdown","23ae9253":"markdown","e698e13f":"markdown","ca4cfd50":"markdown","fa94df25":"markdown","05f90ebb":"markdown","833095b4":"markdown"},"source":{"21867d0d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm, skew\nfrom sklearn.preprocessing import Imputer, LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.decomposition import PCA\npd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","60a8bc8e":"train_data = pd.read_csv('..\/input\/train.csv')\ntest_data = pd.read_csv('..\/input\/test.csv')","abd2d211":"print(train_data.shape)\nprint(test_data.shape)","ae77a22b":"n_train = train_data.shape[0]\nn_test = test_data.shape[0]\nhousing = pd.concat([train_data.drop('SalePrice',axis=1),test_data]).reset_index(drop=True)\n#housing = pd.read_csv('..\/input\/train.csv')","152b3b8c":"print(housing.shape)\nhousing.tail()","e932506c":"#housing['SalePrice'].hist(bins=50)\nsns.distplot(train_data['SalePrice'], fit=norm);\n(mu, sigma) = norm.fit(train_data['SalePrice'])\nplt.legend(['Norm Distribution: $\\mu$={:.2f}, $\\sigma$={:.2f}'.format(mu, sigma)], loc='best')\nplt.ylabel('Frequncy')\nplt.figure()\nres = stats.probplot(train_data['SalePrice'], plot=plt)\nplt.show()","ef71611f":"print(train_data['SalePrice'].skew())\nprint(train_data['SalePrice'].kurt())","10ea3798":"train_data['LogSalePrice'] = np.log(train_data['SalePrice'])\nsns.distplot(train_data['LogSalePrice'], fit=norm)\n(mu, sigma) = norm.fit(train_data['LogSalePrice'])\nplt.legend(['Norm Distribution: $\\mu$={:.2f}, $\\sigma$={:.2f}'.format(mu, sigma)], loc='best')\nplt.ylabel('Frequncy')\nplt.figure()\nstats.probplot(train_data['LogSalePrice'], plot=plt)\nplt.show()","f4d13dd9":"data_stats = housing.notnull().sum()\nto_drop_cols = data_stats[data_stats<housing.shape[0]*.1].index.tolist()\nto_drop_cols # drop features with samples less than 10% of dataset size","3dc7f0bb":"housing_clean = housing.copy()\n#housing_clean.drop(to_drop_cols, axis=1, inplace=True)\nhousing_clean.drop(['Id'], axis=1, inplace=True)\nhousing_clean.shape","4eabfdb5":"num_cols = housing_clean._get_numeric_data().columns.tolist()\n#numeric = [feat for feat in num_cols if feat not in ordinal]\nhousing[num_cols].describe()","34b941fc":"housing[num_cols].hist(figsize=(20,18), bins=30);","4b2a4fb7":"housing_clean[['YearBuilt', 'YearRemodAdd']].isnull().any()","7c9d9429":"housing_clean['HouseAge'] = 2019 - housing_clean['YearBuilt']\nhousing_clean['RemodSince'] = 2019 - housing_clean['YearRemodAdd']\nprint(housing_clean[['YearBuilt','YearRemodAdd','HouseAge','RemodSince']].sample(5))\nhousing_clean.drop(['YearBuilt','YearRemodAdd'], axis=1, inplace=True)","1c26b5ae":"housing_clean[['MSSubClass']] = housing_clean[['MSSubClass']].astype('category')","2e470a9d":"missing_data_stats = housing_clean.isnull().sum()\/housing_clean.shape[0] * 100\nmissing_data_stats[missing_data_stats>0.1].sort_values(ascending=False).plot(kind='bar');","c3e01168":"cols = missing_data_stats.sort_values(ascending=False).nlargest(5).index\ntrain_data[cols].describe()","0edaf654":"housing_clean.loc[housing['BsmtQual'].isnull().values,['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF']].sample(10)","81428f1a":"bsmt_cat_cols = ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2']\nbsmt_num_cols = ['BsmtFinSF1','BsmtUnfSF','TotalBsmtSF']\nhousing_clean[bsmt_cat_cols].isnull().sum()","90e5b3a0":"housing_clean.loc[housing_clean['BsmtFinType1'].isnull().values,bsmt_cat_cols].isnull().all()","0c105315":"housing_clean.loc[housing_clean['BsmtFinType1'].isnull().values, bsmt_cat_cols] = 'None'\nhousing_clean.loc[housing_clean['BsmtFinType1'].isnull().values, bsmt_num_cols] = 0","dfef640a":"garage_cat_cols = ['GarageType','GarageFinish','GarageQual','GarageCond']\ngarage_num_cols = ['GarageYrBlt','GarageCars','GarageArea']\nhousing_clean[garage_cat_cols].isnull().sum()","c6290c41":"housing_clean.loc[housing_clean['GarageType'].isnull().values,garage_cat_cols].isnull().all()","f7642b00":"housing_clean.loc[housing_clean['GarageType'].isnull().values, garage_cat_cols] = 'None'\nhousing_clean.loc[housing_clean['GarageType'].isnull().values, garage_num_cols] = 0","31a0d090":"#housing_clean['PoolQC'] = housing_clean['PoolQC'].fillna('None')\n#housing_clean['MiscFeature'] = housing_clean['MiscFeature'].fillna('None')\n#housing_clean['Alley'] = housing_clean['Alley'].fillna('None')\n#housing_clean['Fence'] = housing_clean['Fence'].fillna('None')\n#housing_clean['FireplaceQu'] = housing_clean['FireplaceQu'].fillna('None')","8ea72283":"missing_data_stats = housing_clean.isnull().sum()\ncols = missing_data_stats[missing_data_stats>0].index.tolist()","d98feb33":"missing_data_stats[missing_data_stats>0]","b6513845":"#housing_clean[housing_clean['FireplaceQu'].isnull()]","494ef2bb":"cat_cols = housing_clean.select_dtypes(exclude=['int64', 'float64']).columns\nhousing_clean[cat_cols].describe()","aa9129bc":"for c in cols:\n    if c in cat_cols:\n        mode = housing_clean[c].mode()[0]\n        housing_clean[c] = housing_clean[c].fillna(mode)\n    else:\n        median = housing_clean[c].median()\n        housing_clean[c] = housing_clean[c].fillna(median)","a2f2950a":"housing_clean.info()","1b32351c":"# key optional features (with NA)\nbsmt = ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','BsmtUnfSF','TotalBsmtSF']\ngarg = ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'GarageCars']\n# other optional features\nfrpl = ['Fireplaces', 'FireplaceQu']\npool = ['PoolArea', 'PoolQC']\nfenc = ['Fence'] # quality\nmisc = ['MiscFeature', 'MiscVal'] \nporch = ['OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch']\n# common features \nbath = ['BsmtFullBath','BsmtHalfBath','FullBath','HalfBath']\nbdrm = ['Bedroom']\nktcn = ['Kitchen','KitchenQual']","d80be484":"#housing_clean[housing_clean['PoolArea']>0].PoolArea\n#(housing_clean['Fireplaces']>0).sum()\n#housing_clean['MiscFeature'].value_counts()\n#housing_clean['Fence'].value_counts()","326d5ad8":"housing_clean['withBasement'] = housing_clean['TotalBsmtSF'].apply(lambda x: 1 if x>0 else 0)\nhousing_clean['withGarage'] = housing_clean['GarageType'].apply(lambda x: 1 if x!='None' else 0)\nhousing_clean['withFireplaces'] = housing_clean['Fireplaces'].apply(lambda x: 1 if x>0 else 0)\nhousing_clean['withFence'] = housing_clean['Fence'].apply(lambda x: 1 if x!='None' else 0)\nhousing_clean['withPool'] = housing_clean['PoolQC'].apply(lambda x: 1 if x!='None' else 0)\nhousing_clean['withMiscFeature'] = housing_clean['MiscFeature'].apply(lambda x: 1 if x!='None' else 0)","8ff89152":"housing_clean['numBsmtbath'] = housing_clean['BsmtFullBath'] + 0.5*housing_clean['BsmtHalfBath']\nhousing_clean['numBath'] = housing_clean['FullBath'] + 0.5*housing_clean['HalfBath']\nhousing_clean.drop(['BsmtFullBath','BsmtHalfBath','FullBath','HalfBath'], axis=1, inplace=True)","3057ced6":"housing_clean['TotBsmtFinSF'] = housing_clean['BsmtFinSF1']+housing_clean['BsmtFinSF2']\nhousing_clean['BsmtFinSFRatio'] = housing_clean['TotBsmtFinSF']\/housing_clean['TotalBsmtSF']\nhousing_clean['BsmtUnfSFRatio'] = housing_clean['BsmtUnfSF']\/housing_clean['TotalBsmtSF']\nhousing_clean['BsmtFinSFRatio'] = housing_clean['BsmtFinSFRatio'].fillna(0)\nhousing_clean['BsmtUnfSFRatio'] = housing_clean['BsmtUnfSFRatio'].fillna(0)\n#housing_clean.drop(['BsmtUnfSF','TotBsmtFinSF'], axis=1, inplace=True)\nhousing_clean.drop(['BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotBsmtFinSF'], axis=1, inplace=True)","2d0ce8af":"housing_clean['PorchArea'] = housing_clean['OpenPorchSF'] + housing_clean['EnclosedPorch'] \n+ housing_clean['3SsnPorch'] + housing_clean['ScreenPorch']\nhousing_clean.drop(['OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch'], axis=1, inplace=True)","987b63bd":"housing_clean['numFloors'] = housing_clean['2ndFlrSF'].apply(lambda x: 1 if x>0 else 0) + 1\nhousing_clean['TotalSF'] = housing_clean['1stFlrSF'] + housing_clean['2ndFlrSF'] + housing_clean['TotalBsmtSF'] + housing_clean['GarageArea']\nhousing_clean['1stFlrSFRatio'] = housing_clean['1stFlrSF']\/housing_clean['TotalSF']\nhousing_clean['2ndFlrSFRatio'] = housing_clean['2ndFlrSF']\/housing_clean['TotalSF']\nhousing_clean.drop(['1stFlrSF','2ndFlrSF'], axis=1, inplace=True)","3e6d6e83":"housing_clean[['Condition1','Condition2','Exterior1st','Exterior2nd']].isnull().any()","e94cbd5b":"dummy1 = pd.get_dummies(housing_clean.Condition1, prefix='Condition')\ndummy2 = pd.get_dummies(housing_clean.Condition2, prefix='Condition')\nconditions = (dummy1 + dummy2).replace(2, 1)\nconditions['Condition_RRNe'] = dummy1['Condition_RRNe']\nconditions.head()","41d93751":"dummy1 = pd.get_dummies(housing_clean.Exterior1st, prefix='Exterior')\ndummy2 = pd.get_dummies(housing_clean.Exterior2nd, prefix='Exterior')\n\nexteriors = (dummy1 + dummy2).replace(2, 1)\ncommon = dummy1.merge(dummy2, how='outer')\nfor col in exteriors.columns:\n    if exteriors[col].isnull().all():\n        exteriors[col] = common[col]","8c77dd87":"housing_clean.drop(['Condition1','Condition2','Exterior1st','Exterior2nd'], inplace=True, axis=1)\n# drop these features first, add the encoded dummy variables back later","0f274b1a":"cat_cols = housing_clean.select_dtypes(exclude=['int64', 'float64']).columns\ncat_levels = housing_clean[cat_cols].nunique()\nordinal = ['LotShape', 'LandSlope', 'ExterQual', 'ExterCond', 'BsmtQual', 'OverallCond', 'OverallQual', 'Fence',\n           'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'KitchenQual', 'FireplaceQu',\n           'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive']\n\n#`Alley` and `Utilities` are actually multi-level categoricals.\nbinary_cats = list(set(cat_levels[cat_levels==2].index) - set(['Alley','Utilities']))\nmulti_level_cats = list(set(cat_levels[cat_levels>2].index) - set(ordinal+['OverallQual','OverallCond']))+['Alley','Utilities']","102d6c3b":"housing_clean[cat_cols] = housing_clean[cat_cols].astype('category')","84940fd1":"mapper = {'Street': {'Grvl':0, 'Pave':1}, 'CentralAir': {'N':0, 'Y':1}}\nfor col in binary_cats:\n    housing_clean[col] = housing_clean[col].replace(mapper[col])\nhousing_clean[binary_cats].head()","f1448908":"# One Hot Encode all categoricals\nhousing_clean = pd.get_dummies(housing_clean)\nhousing_clean.shape","7ed1f720":"housing_clean.head()","66ca724c":"level_order = {'LotShape': ['Reg','IR1','IR2','IR3'],\n 'LandSlope': ['Gtl','Mod','Sev'],\n 'ExterQual': ['Ex','Gd','TA','Fa','Po'],\n 'ExterCond': ['Ex','Gd','TA','Fa','Po'],\n 'BsmtQual': ['Ex','Gd','TA','Fa','Po','None'],\n 'BsmtCond': ['Ex','Gd','TA','Fa','Po','None'],\n 'BsmtExposure': ['Gd','Av','Mn','No','None'],\n 'BsmtFinType1': ['GLQ','ALQ','BLQ','Rec','LwQ','Unf','None'],\n 'BsmtFinType2': ['GLQ','ALQ','BLQ','Rec','LwQ','Unf','None'],\n 'HeatingQC': ['Ex','Gd','TA','Fa','Po'],\n 'KitchenQual': ['Ex','Gd','TA','Fa','Po'],\n 'FireplaceQu': ['Ex','Gd','TA','Fa','Po','None'],\n 'GarageFinish': ['Fin','RFn','Unf','None'],\n 'GarageQual': ['Ex','Gd','TA','Fa','Po','None'],\n 'GarageCond': ['Ex','Gd','TA','Fa','Po','None'],\n 'PavedDrive': ['Y','P','N'],\n 'PoolQC': ['Ex','Gd','TA','Fa','Po','None'],\n 'Fence': ['GdPrv','MnPrv','GdWo','MnWw','None']}\n","95781e56":"#for col in ordinal:\n#    if col not in ['OverallQual', 'OverallCond']:\n#        ordered_cat = pd.api.types.CategoricalDtype(ordered=True, categories=level_order[col][::-1])\n#        housing_clean[col] = housing_clean[col].astype(ordered_cat)\n\n#for col in ordinal:\n#    housing_clean[col].cat.remove_unused_categories()\n#    housing_clean[col] = housing_clean[col].cat.codes\n\n#label_mapping = {}\n#for c in ordinal:\n#    housing[c], label_mapping[c] = pd.factorize(housing[c])","c1da51d0":"#dummies = pd.get_dummies(housing_clean[multi_level_cats], drop_first=False)\n#housing_clean.drop(multi_level_cats, axis=1, inplace=True)\n#dummies.head()","b5bd7db5":"housing_clean = housing_clean.join([conditions, exteriors])\nhousing_clean.shape","10fe8d4d":"to_drop_cols = []\nfor col in list(housing_clean.columns):\n    if 'None' in col:\n        to_drop_cols.append(col)\nprint(to_drop_cols)","48f7e170":"housing_clean.drop(to_drop_cols, axis=1, inplace=True)","73be219e":"def split(df):\n    X_train = df[:n_train].values\n    X_test = df[-n_test:].values\n    y_train = train_data.loc[:,'LogSalePrice'].values\n    print(X_train.shape, X_test.shape)\n    return X_train, y_train, X_test","83981d43":"sc = StandardScaler()\nX_train, y_train, X_test = split(housing_clean)\nX = sc.fit_transform(X_train)","9bd7ba73":"rf_reg = RandomForestRegressor(max_depth=10, random_state=0, n_estimators=100)\nrf_reg.fit(X, y_train)\nscores = cross_val_score(rf_reg, X, y_train, scoring='neg_mean_squared_error', cv=5)\nrmse_scores = np.sqrt(-scores)\nprint(rmse_scores)\n#feat_imp = pd.Series(rf_reg.feature_importances_, index=housing_clean.columns)\n#feat_imp[feat_imp>0.002].sort_values(ascending=False).plot(kind='bar');","9e77ae09":"#housing_feats = housing_clean[feat_imp[feat_imp>0.002].index.tolist()]\n#X_train, y_train, X_test = split(housing_feats)\n#X = sc.fit_transform(X_train)","54abe1c7":"def pca_plot(pca, X):\n    cumsum = np.cumsum(pca.explained_variance_ratio_)\n    d = np.argmax(cumsum>=0.95)+1\n    n_components = X.shape[1]\n    idx = np.arange(1, n_components+1)\n    fig, ax = plt.subplots(figsize=(10,4))\n    ax.plot(idx, cumsum)\n    ax.axvline(x=d, linestyle=':', color='r')\n    ax.axhline(y=0.95, linestyle=':', color='r')\n    ax.set_xlabel('# Principal Components')\n    ax.set_ylabel('Explained Variance')\n    ax.set_xlim([-1, n_components])\n    plt.show()\n    print('95% Variance explained by {} PCs.'.format(d))","6ecc9dfc":"pca = PCA()\npca.fit(X)\npca_plot(pca, X)","a90b53d7":"dim = ['PC{}'.format(i) for i in range(1, len(pca.components_)+1)]\ncomponents = pd.DataFrame(pca.components_, columns=housing_clean.keys())\ncomponents.index=dim\ncomponents.head()","41c39506":"ratios = pca.explained_variance_ratio_.reshape(len(pca.components_),1)\nvariance_ratios = pd.DataFrame(ratios, columns=['explained_variance'])\nvariance_ratios.index = dim\nvariance_ratios.shape","6e5f70d3":"pca.components_.shape, len(pca.components_), len(dim)","e84157e8":"def plot_PCs(pc, k, ax):\n    base_color = sns.color_palette()[0]\n    features = pc.reindex(pc.abs().sort_values(ascending=False).index)\n    features[:k].plot(ax=ax, kind='bar', color=base_color)","43283e92":"fig, ax = plt.subplots(figsize=(10,4))\nplot_PCs(components.loc['PC1',:], 20, ax)","0587f055":"pca = PCA(n_components=0.95)\nX_reduced = pca.fit_transform(X)","4bfeae1c":"X_reduced.shape","e31a2c42":"plt.scatter(X_reduced[:,0], y_train);","c2922306":"rf_reg = RandomForestRegressor(max_depth=10, random_state=0, n_estimators=100)\nrf_reg.fit(X_reduced, y_train)","7845f295":"#Select the most important PCs:\n#pc_imp = pd.Series(rf_reg.feature_importances_, index=list(range(1,len(pca.components_)+1)))\n#pc_imp[pc_imp>0.0015].sort_values(ascending=False).plot(kind='bar');\n#X_selected = X_reduced[:,pc_imp[pc_imp>0.0015].sort_values(ascending=False).index.tolist()]\n#X.shape, X_reduced.shape, X_selected.shape","e85a24b4":"def rmse(reg, X, y):\n    y_pred = reg.predict(X)\n    mse = mean_squared_error(y, y_pred)\n    rmse = np.sqrt(mse)\n    return rmse","6b05d3f3":"#rf_reg = RandomForestRegressor(max_depth=20, random_state=0, n_estimators=100)\nrf_reg.fit(X, y_train)\nprint('Score with all features: {:.4f}, RMSE = {:.5f}'.format(rf_reg.score(X, y_train), rmse(rf_reg, X, y_train)))\nrf_reg.fit(X_reduced, y_train)\nprint('Score with 141 PCs: {:.4f}, RMSE = {:.5f}'.format(rf_reg.score(X_reduced, y_train), rmse(rf_reg, X_reduced, y_train)))\n#rf_reg.fit(X_selected, y_train)\n#print('Score with selected PCs: {:.4f}, RMSE = {:.5f}'.format(rf_reg.score(X_selected,y_train), rmse(rf_reg, X_selected, y_train)))","436ba6a8":"# Cross Validation\nscores = cross_val_score(rf_reg, X_reduced, y_train, scoring='neg_mean_squared_error', cv=5)\nrmse_scores = np.sqrt(-scores)\nprint(rmse_scores)","bf3a0d91":"def CV_results(search):\n    res = search.cv_results_\n    for mean_score, params in zip(res['mean_test_score'], res['params']):\n        print('RMSE is {:.4f} w\/: {}'.format(np.sqrt(-mean_score),params))\n    print(search.best_estimator_)","5c9c2b81":"param_grid = [\n    {'n_estimators': [50, 100, 150], 'max_depth': [10, 20, 30], 'min_samples_leaf': [5, 10], 'random_state':[0]},\n    {'bootstrap': [False], 'n_estimators': [10, 50], 'max_depth': [6, 8, 10, 20], 'min_samples_leaf': [2, 5, 10]}\n]\nrf_reg = RandomForestRegressor()\ngrid_search = GridSearchCV(rf_reg, param_grid[0], cv=5, scoring='neg_mean_squared_error')","d0f80549":"# trained with PCs\ngrid_search.fit(X_reduced, y_train)\nCV_results(grid_search)","8ca59cc8":"best_model_1 = grid_search.best_estimator_","cd17964f":"# trained with all features in training dataset\n#grid_search.fit(X, y_train)\n#CV_results(grid_search)","ee844a07":"#best_model_2 = grid_search.best_estimator_","735e37bd":"from sklearn.linear_model import Lasso\nlin_reg = Lasso(alpha=0.0034)\nlin_reg.fit(X_reduced, y_train)","07e8ea15":"scores = cross_val_score(lin_reg, X_reduced, y_train, scoring='neg_mean_squared_error', cv=10)\nrmse_scores = np.sqrt(-scores)\nprint(rmse_scores)","f5fd6a19":"param_grid = [\n    {'alpha': np.linspace(0.0001, 0.01, 10)}\n]\nlasso_reg = Lasso()\ngrid_search = GridSearchCV(lasso_reg, param_grid[0], cv=5, scoring='neg_mean_squared_error')","099164c9":"#grid_search.fit(X_reduced, y_train)\n#CV_results(grid_search)","94aa2d04":"from sklearn.svm import LinearSVR, SVR\n\nsvm_reg = LinearSVR(epsilon=1.5)\nsvm_reg.fit(X, y_train)","521e1b65":"svm_poly_reg = SVR(kernel='poly', degree=2, C=100, epsilon=0.1)\nsvm_poly_reg.fit(X, y_train)","dafadbe9":"svm_k_reg = SVR(kernel='rbf', C=100, gamma=0.01)\nsvm_k_reg.fit(X, y_train)","f2c52807":"scores = cross_val_score(svm_k_reg, X_reduced, y_train, scoring='neg_mean_squared_error', cv=10)\nrmse_scores = np.sqrt(-scores)\nprint(rmse_scores)","f30fd635":"param_grid = [\n    {'C': np.linspace(0.1, 1, 3), 'gamma': np.linspace(0.0001, 0.0006, 3)}\n]\nsvm_reg = SVR(kernel='rbf')\ngrid_search = GridSearchCV(svm_reg, param_grid[0], cv=5, scoring='neg_mean_squared_error')","cf4337ba":"grid_search.fit(X_reduced, y_train)\nCV_results(grid_search)","e2bfe9f6":"best_model_2 = grid_search.best_estimator_","a6776ba4":"#best_model = grid_search.best_estimator_\nX_test_std = sc.transform(X_test)\nX_test_reduced = pca.transform(X_test_std)\n#y_test_pred = best_model.predict(X_test_reduced)\ny_test_pred_1 = best_model_1.predict(X_test_reduced)\ny_test_pred_2 = best_model_2.predict(X_test_reduced)","22b9df00":"np.exp(y_test_pred_2)","f3fe9481":"sub = pd.DataFrame()\nsub['Id'] = test_data['Id']\nsub['SalePrice'] = np.exp(y_test_pred_2)\nsub.to_csv('submission.csv', index=False)","b0c024cc":"It makes more sense to compare the unfinished\/finished basement area ratio instead of the absolute value. With knowledge of the ratios and total area, it is alright to get rid of the absolute area value.","7605c7ef":"**PCA**","dcc8acdc":"The model is overfitted.","1588f70c":"For the related categorical features, we will then need to use One-Hot-Encoding to indicate only the valid values.","a4a6ed46":"**Distribution of Dependent Variable**\n\nThank the authors of the following kernels from earlier posts, I've gained a better insight in how to inspect the dataset more thoroughly using skewness, logarithmic transformation, and correlation matrix.\n1. [Comprehensive data exploration with Python](https:\/\/www.kaggle.com\/pmarcelino\/comprehensive-data-exploration-with-python) by Pedro Marcelino\n2. [Stacked Regressions to predict House Prices](https:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard) by Serigne","1bf897d4":"According to the data description, certain `NaN` in columns means `None`, however it can also be unknown or erroneous logging. Care must be taken when checking if there is a pattern in missing data values, such as most houses w\/o basement or garage tend to have missing values in the same rows across several columns (categorical variables) related to the corresponding features. If this is the case, then we can simply impute the categoricals with `None` and numerics with `0`, otherweise, if not all related columns are `NaN`, then we impute the categoricals with their modes, and numerics with the median.","865fe3ef":"**Handling Categoricals**","e960e4b6":"**Missing Data**","483ba360":"- bathroom, bedroom, kitchen are common features for houses, apartments etc., there are no `NA` or magic number `-1` to indicate the absence of these features\n- basement, garage, fireplace, pool, fence and miscellaneous features (elevator, tennis court etc.) are not common features, so to distinguish from the existence of these features from feature condition\/quality\/rating and so on, it is necessary to introduce new features such as `withBasement`, `withGarage`, `withFireplace`, `withPool`, `withFence`, `withMiscFeature`.","763ed1c3":"**Categorical data**\n- Ordinal\n- Binary categoricals\n- Multi-level categoricals","9b1884d8":"There are no missing values in columns `YearBuilt` and `YearRemodAdd`, it is safe to convert the year of build\/remodification to years without imputing.","42298197":"**Preprocessing**","40986c39":"## Feature Engineering\n- features should be related to the objective\n- features are knowable at prediction-time\n- features should be numeric\n    - don't mix magic number with data values\n- features should have enough examples\n- bring human insight to data","2c10d360":"*Fine-tuning*","e273475f":"**Same Feature, Multi-output**\n\nThere are some features that may be better if merged together when encoded, since they refer to the same set of values only with multiple outputs, which is similar to the multi-label classification problem. This can be done by combining the dummy matrices together. \n- `Condition1`, `Condition2`: Proximity to various conditions \n- `Exterior1st`, `Exterior2nd`: exterior covering on house\n\nexception:\n- `BsmtFinType1`, `BsmtFinType2`: Rating of basement finished area <br\/>\nsince the two features are related to `BsmtFinSF1`,`BsmtFinSF2` and `BsmtUnfSF`, instead of merging, it is more reasonable to leave them so and search for latent variables using Principal Component Analysis.","810a7f84":"**SVM Regression**","ef045557":"**check the number of examples in features**","3cd6be07":"**check different feature types**","23ae9253":"**Continuous variables**\n- `2ndFlrSF`, `3SsnPorch`, `EnclosedPorch`,`OpenPorchSF`, `ScreenPorch`, `BsmtFinSF1`, `BsmtFinSF2`,  `PoolArea`, `WoodDeckSF`, `MiscVal`, `MasVnrArea`, `LowQualFinSF`, have lots of data points with value `0`\n- `GarageArea`, `BsmtUnfSF` with some `0`s which may also need to be tended to \n\n**Discrete variables**\n- `BedroomAbvGr`, `BsmtFullBath`, `BsmtHalfBath`, `Fireplace`, `FullBath`, `GarageCars`, `HalfBath`, `KitchenAbvGr`, `TotRmsAbvGrd`\n- time-related: `MoSold`, `YearBuilt`, `YearRemodAdd`, `YrSold`\n- `MSSubClass`, `OverallCond`, `OverallQual` are saved as `int` but should be treated as categorical","e698e13f":"**Feature Extraction**","ca4cfd50":"**Random Forest Regressor**","fa94df25":"**Final Model**","05f90ebb":"**Lasso Regression** ","833095b4":"**Submission**"}}