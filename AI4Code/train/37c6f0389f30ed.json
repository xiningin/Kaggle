{"cell_type":{"09c1ec2b":"code","a2f81e07":"code","6743d49c":"code","24320893":"code","5c0c868e":"code","4dbd3421":"code","4ceffd74":"code","cf18c3fa":"code","a3996ff9":"code","9faaf327":"code","95a28443":"code","41611f67":"code","b876a606":"code","a7c0b556":"code","b9aa4497":"code","f793e34e":"code","0fb13eeb":"code","77f5130f":"code","044bac4e":"code","f934196d":"code","b56e6263":"code","9ac02e52":"code","f1b80bb3":"markdown","2f294599":"markdown","1eec2a09":"markdown","10f4d451":"markdown","678fbbc3":"markdown","9ce7f8eb":"markdown","6a2acd0b":"markdown","34101182":"markdown","81c2fe31":"markdown"},"source":{"09c1ec2b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport glob\nimport os\nimport re\n\nfrom sklearn.metrics import classification_report, log_loss, accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer","a2f81e07":"df_train = pd.read_csv('\/kaggle\/input\/arabic-hwr-ai-pro-intake1\/train.csv')\ndf_train.shape","6743d49c":"df_train.groupby(by='label').count()","24320893":"df_train.head()","5c0c868e":"#read images as grayscale as colors aren't actually effect in our example\nimages_train = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in \n                sorted(glob.glob(\"\/kaggle\/input\/arabic-hwr-ai-pro-intake1\/train\/*.png\"))]\nimages_train = np.array(images_train)\nprint(\"train images shape: {}\".format(images_train.shape))","4dbd3421":"# add 1 more dimenision for images train to prepare for CNN\nimages_train = images_train.reshape((-1, 32, 32, 1))\nprint(\"images shape: {}\".format(images_train.shape))\n\n#preprocessing images train\nimages_train = images_train\/255","4ceffd74":"# show first 50 images\ndef display50Images(images, dataframe, random=False):\n    if random == True:\n        array = np.random.choice(images.shape[0], 50, replace=False)\n    else:\n        array = range(0,50,1)\n    plt.figure(figsize=(20,10))\n    j = 1\n    for i in range(50):\n        plt.subplot(5,10,j)\n        num = array[i]\n        plt.imshow(images[num], cmap='gray')\n        plt.axis('off')\n        plt.title('label : {}'.format(dataframe.label.iloc[num]))\n        j+=1\n        \ndisplay50Images(images_train, df_train, random=True)","cf18c3fa":"#prepare y to CNN we use labelBinarizer\nbinencoder = LabelBinarizer()\ny = binencoder.fit_transform(df_train.label.to_numpy())\nprint(\"y shape: {}\".format(y.shape))\nprint(y[0:5])","a3996ff9":"X_train, X_val, y_train, y_val = train_test_split(images_train, y,\n                                                  test_size = 0.2, random_state=42, stratify= y)\nprint(\"X_train shape: {}\\nX_val shape: {}\".format(X_train.shape, X_val.shape))","9faaf327":"#spliting X_train to validation for using in model.fit(validation_data = (X_val_2, y_val_2))\nX_train_2, X_val_2, y_train_2, y_val_2 = train_test_split(X_train, y_train,\n                                                  test_size = 0.2, random_state=42, stratify= y_train)\nprint(\"X_train_2 shape: {}\\nX_val_2 shape: {}\".format(X_train_2.shape, X_val_2.shape))","95a28443":"#for checking GPU specs and enable it in tensorflow\nfrom tensorflow.python.client import device_lib\nimport tensorflow as tf\nfrom tensorflow.python.keras import backend as K\n\nprint(device_lib.list_local_devices())\n\n# adjust values to your needs\nconfig = tf.compat.v1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 8} )\nsess = tf.compat.v1.Session(config=config) \nK.set_session(sess)","41611f67":"# Example of creating a CNN model with many VGG blocks\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization\nfrom keras.utils.vis_utils import plot_model\n \n# function for creating a vgg block\ndef vgg_block(layer_in, n_filters, n_conv):\n    # add convolutional layers\n    for _ in range(n_conv):\n        layer_in = Conv2D(n_filters, (3,3), padding='same', activation='relu',\n                          kernel_initializer='he_normal')(layer_in)\n    # add max pooling layer\n    layer_in = MaxPooling2D((2,2), strides=(2,2))(layer_in)\n    return layer_in\n \n# define model input\nvisible = Input(shape=(32, 32, 1))\n# add vgg module\nlayer = vgg_block(visible, 64, 2)\n# add vgg module\nlayer = vgg_block(layer, 128, 2)\n# add vgg module\nlayer = vgg_block(layer, 256, 4)\n\nlayer = Flatten()(layer)\nlayer = BatchNormalization()(layer)\n\n# layer = Dense(4096,activation='relu', kernel_initializer='he_normal',kernel_regularizer='l2')(layer)\n# layer = BatchNormalization()(layer)\n\n# layer = Dense(128,activation='relu', kernel_initializer='he_normal',kernel_regularizer='l2')(layer)\n# layer = BatchNormalization()(layer)\n\nlayer = Dense(28, activation='softmax')(layer)\n# create model\nmodel = Model(inputs=visible, outputs=layer)\n# summarize model\nmodel.summary()\n# plot model architecture\nplot_model(model, show_shapes=True, to_file='multiple_vgg_blocks.png')\n\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","b876a606":"# data augementation using model.fit_generator()\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False, \n        samplewise_center=False,  \n        featurewise_std_normalization=False,\n        samplewise_std_normalization=False,\n        zca_whitening=False,\n        rotation_range=10,\n        zoom_range = 0.1,  \n        width_shift_range=0.1, \n        height_shift_range=0.1,\n        horizontal_flip=False,\n        vertical_flip=False)\ndatagen.fit(X_train_2)","a7c0b556":"# We will import a call back to save the best epoch's weights\nfrom tensorflow.keras.callbacks import ModelCheckpoint                                     \n\ncheckpointer = ModelCheckpoint(filepath='weights.hdf5', verbose=1,\n                               monitor='val_accuracy', mode='max', save_best_only=True)\n\n# hist = model.fit(X_train, y_train, validation_split=0.2, epochs=200,\n#                  batch_size=32, callbacks=[checkpointer])\n\n# hist = model.fit(X_train_2, y_train_2, validation_data=(X_val_2, y_val_2), epochs=200,\n#                  batch_size=32, callbacks=[checkpointer])\n\n# fit_generator for dataImageGenerator...\nbatchSize = 64\nhist = model.fit_generator(datagen.flow(X_train_2, y_train_2, batch_size=batchSize),\n                           epochs = 200, steps_per_epoch=X_train_2.shape[0] \/\/ batchSize,\n                           validation_data=(X_val_2, y_val_2), callbacks=[checkpointer])","b9aa4497":"# Loading the best weights\nmodel.load_weights('weights.hdf5')   \n\n# training accuracy of our model\nprint(\"training accuracy: {}\".format(model.evaluate(X_train_2, y_train_2)))\n\n# Evaluating our model\nprint(\"validation accuracy: {}\".format(model.evaluate(X_val, y_val)))","f793e34e":"y_pred = model.predict(X_val)\npred = np.argmax(y_pred, axis=1) + 1 \nground = np.argmax(y_val, axis=1) + 1\n\nprint(classification_report(ground,pred))","0fb13eeb":"#read images as grayscale as colors aren't actually effect in our example\nimages_test = [cv2.imread(file, cv2.IMREAD_GRAYSCALE) for file in \n                sorted(glob.glob(\"\/kaggle\/input\/arabic-hwr-ai-pro-intake1\/test\/*.png\"))]\nimages_test = np.array(images_test)\nprint(\"train images shape: {}\".format(images_test.shape))","77f5130f":"# add 1 more dimenision for images train to prepare for CNN\nimages_test = images_test.reshape((-1, 32, 32, 1))\nprint(\"images shape: {}\".format(images_test.shape))\n\n#preprocessing images train\nimages_test = images_test\/255","044bac4e":"imagesName_test = [re.sub(r'\\D', \"\",os.path.basename(file)) for file in \n                   sorted(glob.glob(\"\/kaggle\/input\/arabic-hwr-ai-pro-intake1\/test\/*.png\"))]\ndf_test = pd.DataFrame(imagesName_test,columns=[\"id\"])\n\ny_pred_test = model.predict(images_test)\ndf_test[\"label\"] = np.argmax(y_pred_test, axis=1) + 1\n\ndf_test.head()","f934196d":"# show first 50 images\ndisplay50Images(images_test, df_test)","b56e6263":"# show first 50 images\ndisplay50Images(images_test, df_test, random=True)","9ac02e52":"df_test[['id', 'label']].to_csv('submission.csv', index=False)","f1b80bb3":"# Split train data with stratify","2f294599":"# Preprocessing train data","1eec2a09":"# CNN model training","10f4d451":"# Display random images of test after predictions","678fbbc3":"# Predict label of test data","9ce7f8eb":"# Model evaluation over validation data","6a2acd0b":"# Read train dataset","34101182":"# Import packages needed","81c2fe31":"# Read test data"}}