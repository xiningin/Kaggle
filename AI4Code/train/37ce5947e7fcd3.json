{"cell_type":{"f73b49bb":"code","0a3fec1a":"code","85a720d0":"code","639de522":"code","3e126475":"code","e256ab30":"code","0b0ef58e":"code","17659d35":"code","c6ef4646":"code","891d01ce":"code","85f335b6":"code","5dd5188e":"code","090baacf":"code","d7f54a76":"code","3644e129":"code","41964127":"code","7ac7963f":"code","95c2db0d":"code","a17ecae8":"code","099087ad":"code","9acfdf83":"code","6104d833":"code","7325d511":"code","560e4e50":"code","3e34c573":"code","d7b97072":"code","dc933768":"code","4aeeb3c4":"code","d8ec4397":"code","fffa4a24":"code","d71b8b22":"code","b3a08846":"code","664342f4":"code","44391d19":"code","d52a5a83":"code","321ce1da":"code","555ac4a9":"code","61752ab2":"code","a34e748f":"code","34da92ce":"code","2ed031fa":"code","db980e54":"code","e97139a3":"code","7f543bd9":"code","652462ba":"code","e6947b95":"code","15130712":"markdown","c6d8f7af":"markdown","450dab88":"markdown","575bc632":"markdown","d7e5a0fe":"markdown","32ffd4af":"markdown","87049397":"markdown","33ae1a28":"markdown","e7b7f9e4":"markdown","939f066d":"markdown","5c61f0b0":"markdown","7e946ff2":"markdown","c6533725":"markdown","3958c95d":"markdown","47fac883":"markdown","e3ffaeb9":"markdown","cc584c3b":"markdown","f04e062d":"markdown","2f61a857":"markdown","259fb887":"markdown","2522d580":"markdown","ddd273c7":"markdown","f74f7bf4":"markdown","9dbb18a1":"markdown","275ed348":"markdown","a2ab54a2":"markdown","5e88ed09":"markdown","9abafa66":"markdown","6b31f25c":"markdown","8caa24ca":"markdown","40e20e7f":"markdown","3a07415c":"markdown","37e6887a":"markdown","8c07e1d0":"markdown","8a05505f":"markdown","f874e729":"markdown","1419d9c0":"markdown","2da3a6c0":"markdown","0972ff71":"markdown","a27c68a2":"markdown","c6ff5a94":"markdown","54ffa1c1":"markdown","24790296":"markdown","a2f62308":"markdown","0edf450a":"markdown","d0bd2c4d":"markdown","bce6349b":"markdown","7bb9c22e":"markdown","76d8333e":"markdown","b071094d":"markdown","d9c67e2c":"markdown","eccce8d8":"markdown","afbadd0c":"markdown","af8e1427":"markdown","aaf42e66":"markdown","2b151161":"markdown","791c4705":"markdown","fb82432e":"markdown","01799fd0":"markdown","dadcb04b":"markdown","d9f0af97":"markdown","64b29f86":"markdown","b4e97d31":"markdown","18e6a4c7":"markdown","ee63443b":"markdown","fff67a75":"markdown","5548dbb8":"markdown","50e24ebc":"markdown","f9831247":"markdown","bbbeb58a":"markdown","cbe4656f":"markdown","e896ca1d":"markdown","256e39a5":"markdown","434479b1":"markdown","89fe8db9":"markdown"},"source":{"f73b49bb":"# Grundlegendes\nimport numpy as np          # Grundlegendes Paket f\u00fcr wissenschaftliches Arbeiten mit Python (z.B. ist Lineare Algebra enthalten)\nimport pandas as pd         # Bibliothek zur Datenverarbeitung und enth\u00e4lt Datenanalysewerkzeuge, z.B. CSV Datei I\/O (z.B. pd.read_csv(...))\nimport os                   # Aufruf um Shell-Befehl ausf\u00fchren\n\n# Visualisierungen\nimport seaborn as sns                     # Bibliothek f\u00fcr Visualisierungen basierend auf matplotlib\nimport matplotlib.pyplot as plt           # Python 2D-Plot-Bibliothek\n\n# Modellierungsalgorithmen\nfrom sklearn.linear_model import LogisticRegression        # Paket zum Nutzen der logistischen Regression\n\n# Modellierungshelfer\nfrom sklearn import preprocessing                                           # Paket zum Nutzen allgemein gebr\u00e4uchlicher Funktionen und Transformationsklassen\nfrom sklearn.model_selection import train_test_split, cross_val_score       # Paket zum Trennen von Arrays oder Matrizen in zuf\u00e4llige Trainings- und Testuntergruppen\nfrom sklearn.impute import SimpleImputer                                    # Paket zum automatischen Erg\u00e4nzen bzw. Behandeln von fehlenden Werten \n\n# Module zum Implementieren mehrerer Verlust-, Punkt- und Hilfsfunktionen, um die Klassifizierungsleistung zu messen\nfrom sklearn.metrics import confusion_matrix                                # Bewertung der Qualit\u00e4t des Vorhersagemodells eines Klassifizierers\nfrom sklearn.metrics import precision_recall_curve                          # Die Pr\u00e4zisionsr\u00fcckrufkurve zeigt den Kompromiss zwischen Genauigkeit und R\u00fcckruf f\u00fcr Schwellenwerte\nfrom sklearn.metrics import roc_curve                                       # Bewertung und Optimierung von Analyse-Strategien. Die ROC-Kurve stellt visuell die Abh\u00e4ngigkeit der Effizienz mit der Fehlerrate f\u00fcr verschiedene Parameterwerte dar\nfrom sklearn.metrics import auc                                             # Bestimmung eines Integrals (z.B. der precision_recall_curve)\nfrom sklearn.metrics import log_loss                                        # Messung der Leistung eines Klassifikationsmodells, bei dem die Vorhersageeingabe ein Wahrscheinlichkeitswert ist\nfrom sklearn.metrics import roc_auc_score                                   # Bestimmung eines Integrals (z.B. der roc_curve)\nfrom sklearn.metrics import classification_report                           # Precision\/Recall\/F1-Score-Measure f\u00fcr jedes Element der Testdaten sowie die Support-Spalte f\u00fcr die Summe der Z\u00e4hlungen.\n\n# Konfiguration der Visualisierungen\nplt.rc(\"font\", size=14)                   # Festlegen der Schriftgr\u00f6\u00dfe f\u00fcr alle folgenden plt-Funktionsaufrufe\n\n\nprint(os.listdir(\"..\/input\"))             # Zum Anzeigen der mit den Dataset verkn\u00fcpften Dateien","0a3fec1a":"# Einlesen und Speichern der CSV-Datei, die die Produktdaten enth\u00e4lt:\nproducts = pd.read_csv(\"..\/input\/olist_products_dataset.csv\")\n\n# Einlesen und Speichern der CSV-Datei, die die \u00dcbersetzungen der Produktkategorien enth\u00e4lt:\nproduct_categories = pd.read_csv(\"..\/input\/product_category_name_translation.csv\")\n\n# Einlesen und Speichern der CSV-Datei, die Produktdaten zu jeder Bestellung enth\u00e4lt:\norder_items = pd.read_csv(\"..\/input\/olist_order_items_dataset.csv\", parse_dates=[\"shipping_limit_date\"])\n\n# Einlesen und Speichern der CSV-Datei, die die Bestelldaten enth\u00e4lt:\norders = pd.read_csv(\"..\/input\/olist_orders_dataset.csv\", parse_dates=[\"order_purchase_timestamp\",\"order_approved_at\",\"order_delivered_carrier_date\",\"order_delivered_customer_date\",\"order_estimated_delivery_date\"])\n\n# Einlesen und Speichern der CSV-Datei, die die Produktdaten enth\u00e4lt:\nreviews = pd.read_csv(\"..\/input\/olist_order_reviews_dataset.csv\", parse_dates=[\"review_creation_date\",\"review_answer_timestamp\"])","85a720d0":"# Zusammenf\u00fchren der Dataframes \"olist_products_dataset.csv\" und \"product_category_name_translation.csv\"\nproducts_category_merge = pd.merge(products, product_categories, left_on=\"product_category_name\",right_on=\"product_category_name\", how=\"left\", suffixes=(\"_products\",\"_product_category\"))\n\n# Zusammenf\u00fchren der Dataframes \"olist_products_dataset.csv\" und \"olist_order_items_dataset.csv\"\nproducts_order_items = pd.merge(products_category_merge, order_items, left_on=\"product_id\",right_on=\"product_id\", how=\"left\", suffixes=(\"_products\",\"_order_items\"))\n\n# Zusammenf\u00fchren des obrigen Dataframes mit \"olist_orders_dataset.csv\"\nproducts_order_items_orders = pd.merge(products_order_items, orders, left_on=\"order_id\",right_on=\"order_id\", how=\"left\", suffixes=(\"_products_order_items\",\"_orders\"))\n\n# Zusammenf\u00fchren des obrigen Dataframes mit \"olist_order_reviews_dataset.csv\"\nproducts_order_items_orders_reviews = pd.merge(products_order_items_orders, reviews, left_on=\"order_id\",right_on=\"order_id\", how=\"left\", suffixes=(\"_products_order_items_orders\",\"_reviews\"))","639de522":"products_order_items_orders_reviews.info()","3e126475":"# Mit folgendem Aufruf wird der Datentyp angepasst:\n#products_order_items_orders_reviews[\"product_photos_qty\"] = np.int64(products_order_items_orders_reviews[\"product_photos_qty\"])","e256ab30":"products_order_items_orders_reviews.head()","0b0ef58e":"products_order_items_orders_reviews.describe()","17659d35":"# Bestimmung der Anzahl von Datens\u00e4tzen im Haupt-Datenframe\nanzahl_product = products_order_items_orders_reviews.shape[0]\nprint('Die Anzahl der Datens\u00e4tze im Haupt-Datenframe (\"products_order_items_orders_reviews\") betr\u00e4gt {}.'.format(anzahl_product))","c6ef4646":"# \u00dcberpr\u00fcfe den Haupt-Datenframe nach fehlenden Werten\nproducts_order_items_orders_reviews.isnull().sum()","891d01ce":"print('Die Kunden haben Produkte durchschnittlich mit folgendem Score bewertet: {:.4} ' .format(products_order_items_orders_reviews[\"review_score\"].mean()))","85f335b6":"# Eingrenzen des relevanten Bereichs\nuntere_grenze = products_order_items_orders_reviews[\"review_score\"].min() - 1\nobere_grenze = products_order_items_orders_reviews[\"review_score\"].max() + 1\n\n# Visualisierung der Bewertungsauspr\u00e4gungen\nax = products_order_items_orders_reviews[\"review_score\"].hist(bins=5, stacked=True, color='teal')\nax.set(xlabel='Bewertung', ylabel='H\u00e4ufigkeit im Datenframe')\nplt.xlim(untere_grenze,obere_grenze)\nplt.show()","5dd5188e":"# Gruppierung nach Bewertung\nbewertungen_gruppierung = products_order_items_orders_reviews.groupby(\"review_score\")\nbewertungen_fehlen = products_order_items_orders_reviews[\"review_score\"].isnull().sum()\nbewertungen_gruppierung_sum = products_order_items_orders_reviews[\"review_score\"].count()\nbewertungen_fehlen_prozentual = bewertungen_fehlen\/bewertungen_gruppierung_sum*100\n\n# Summe der vorkommenden Auspr\u00e4gungen von Bewertung\nbewertungen_absolut = bewertungen_gruppierung['review_score'].count()\n# Prozentuale H\u00e4ufigkeit der Bewertungsauspr\u00e4gung\nbewertungen_prozentual = (bewertungen_absolut\/products_order_items_orders_reviews[\"review_score\"].count())*100\n# Datenframe zu Darstellungszwecken erstellen\nbewertungen_gruppierung1 = pd.DataFrame({'Absolute Werte': bewertungen_absolut,\n                                        'Prozentualer Anteil': bewertungen_prozentual})\n\n# Ausgabe der Werte\nprint('Es fehlen {} Datens\u00e4tze zu den Bewertungen, was ca. {:.3}% der Summe am Datensatz entspricht.' .format(bewertungen_fehlen, bewertungen_fehlen_prozentual))\nprint('Die Summe an Datens\u00e4tzen (ohne fehlender Werte) der Bewertungen betr\u00e4gt {}.' .format(bewertungen_gruppierung_sum))\nprint('Die Summe an Datens\u00e4tzen (inkl. fehlender Werte) der Bewertungen betr\u00e4gt {}.' .format(bewertungen_gruppierung_sum+bewertungen_fehlen))\nprint('')\nprint(bewertungen_gruppierung1)","090baacf":"# Eingrenzen des relevanten Bereichs\nuntere_grenze = products_order_items_orders_reviews[\"product_photos_qty\"].min() - 1\nobere_grenze = products_order_items_orders_reviews[\"product_photos_qty\"].max() + 1\n\n# Visualisierung der Auspr\u00e4gungen der Anzahl von Produktbildern\nax = products_order_items_orders_reviews[\"product_photos_qty\"].hist(bins=20, stacked=True, color='teal', figsize=(16,5))\nax.set(xlabel='Anzahl Produktbilder', ylabel='H\u00e4ufigkeit im Datenframe')\nplt.xlim(untere_grenze, obere_grenze)\nplt.show()","d7f54a76":"# Gruppierung nach Bilderanzahl\nbilder_gruppierung = products_order_items_orders_reviews.groupby(\"product_photos_qty\")\nbilder_fehlen = products_order_items_orders_reviews[\"product_photos_qty\"].isnull().sum()\nbilder_gruppierung_sum = products_order_items_orders_reviews[\"product_photos_qty\"].count()\nbilder_fehlen_prozentual = bilder_fehlen\/bilder_gruppierung_sum*100\n\n# Summe der vorkommenden Auspr\u00e4gungen von Bilderanzahl\nbilder_absolut = bilder_gruppierung[\"product_photos_qty\"].count()\n# Prozentuale H\u00e4ufigkeit der Auspr\u00e4gungen von Bilderanzahl\nbilder_prozentual = (bilder_absolut\/products_order_items_orders_reviews[\"product_photos_qty\"].count())*100\n# Datenframe zu Darstellungszwecken erstellen\nbilder_gruppierung1 = pd.DataFrame({\"Absolute Werte\": bilder_absolut,\n                                    \"Prozentualer Anteil\": bilder_prozentual})\n\n# Ausgabe der Werte\nprint('Es fehlen {} Datens\u00e4tze zu den Produktbildern, was ca. {:.3}% der Summe am Datensatz entspricht.' .format(bilder_fehlen, bilder_fehlen_prozentual))\nprint('Die Summe an Datens\u00e4tzen (ohne fehlender Werte) der Produktbilder betr\u00e4gt {}.' .format(bilder_gruppierung_sum))\nprint('Die Summe an Datens\u00e4tzen (inkl. fehlender Werte) der Produktbilder betr\u00e4gt {}.' .format(bilder_gruppierung_sum+bilder_fehlen))\nprint('')\nprint(bilder_gruppierung1)","3644e129":"# Eingrenzen des relevanten Bereichs\nuntere_grenze = products_order_items_orders_reviews[\"price\"].min() - 1\nobere_grenze = products_order_items_orders_reviews[\"price\"].max() + 1\n\n# Visualisierung der Preisauspr\u00e4gungen\nax = products_order_items_orders_reviews[\"price\"].hist(bins=500, stacked=True, color='teal', figsize=(16,5))\nax.set(xlabel='Preis', ylabel='H\u00e4ufigkeit im Datenframe')\nplt.xlim(untere_grenze, obere_grenze)\nplt.show()","41964127":"preis_groesser_als = 1000\npreis_summe = np.where((products_order_items_orders_reviews[\"price\"]>=preis_groesser_als),1,0).sum()\npreis_summe_prozentual = (preis_summe\/products_order_items_orders_reviews[\"price\"].count())*100\nprint('Es gibt {} Preise, die gr\u00f6\u00dfer als {} sind.' .format(preis_summe,preis_groesser_als))\nprint('Das entspricht {:.3}% der Summe am Datensatz' .format(preis_summe_prozentual))","7ac7963f":"products_order_items_orders_reviews[\"price\"].plot(kind='hist', bins=500, color='teal', xlim = [untere_grenze,preis_groesser_als], figsize=(16,5))\nprint('Es werden {:.3}% des Datenframes hinsichtlich des Preises angezeigt.' .format(100-preis_summe_prozentual))","95c2db0d":"# Eingrenzen des relevanten Bereichs\nuntere_grenze = products_order_items_orders_reviews[\"product_weight_g\"].min() - 1\nobere_grenze = products_order_items_orders_reviews[\"product_weight_g\"].max() + 1\n\n# Visualisierung der Gewichtsauspr\u00e4gungen\nax = products_order_items_orders_reviews[\"product_weight_g\"].hist(bins=500, stacked=True, color='teal', figsize=(16,5))\nax.set(xlabel='Produktgewicht', ylabel='H\u00e4ufigkeit im Datenframe')\nplt.xlim(untere_grenze, obere_grenze)\nplt.show()","a17ecae8":"gewicht_groesser_als = 8000\ngewicht_summe = np.where((products_order_items_orders_reviews[\"product_weight_g\"]>=gewicht_groesser_als),1,0).sum()\ngewicht_summe_prozentual = (gewicht_summe\/products_order_items_orders_reviews[\"product_weight_g\"].count())*100\nprint('Es gibt {} Produkte, die mehr als {} wiegen.' .format(gewicht_summe,gewicht_groesser_als))\nprint('Das entspricht {:.3}% der Summe am Datensatz' .format(gewicht_summe_prozentual))","099087ad":"obere_grenze = gewicht_groesser_als\nproducts_order_items_orders_reviews[\"product_weight_g\"].plot(kind='hist', bins=500, color='teal', xlim = [untere_grenze,obere_grenze], figsize=(16,5))\nprint('Es werden {:.3}% des Datenframes hinsichtlich des Produktgewichts angezeigt.' .format(100-gewicht_summe_prozentual))","9acfdf83":"# Hinzuf\u00fcgen der abh\u00e4ngigen Variable (wird 0 oder 1 abh\u00e4ngig von der Bewertung)\nproducts_order_items_orders_reviews[\"Gute_Bewertung\"] = np.where((products_order_items_orders_reviews[\"review_score\"]==4) | (products_order_items_orders_reviews[\"review_score\"]==5), 1 , 0)\ndf_interpretation = products_order_items_orders_reviews[[\"review_score\",\"Gute_Bewertung\"]]\ndf_interpretation.describe()","6104d833":"products_order_items_orders_reviews[\"1Stern\"] = np.where(products_order_items_orders_reviews[\"review_score\"]==1, 1 , 0)\nproducts_order_items_orders_reviews[\"2Sterne\"] = np.where(products_order_items_orders_reviews[\"review_score\"]==2, 1 , 0)\nproducts_order_items_orders_reviews[\"3Sterne\"] = np.where(products_order_items_orders_reviews[\"review_score\"]==3, 1 , 0)\nproducts_order_items_orders_reviews[\"4Sterne\"] = np.where(products_order_items_orders_reviews[\"review_score\"]==4, 1 , 0)\nproducts_order_items_orders_reviews[\"5Sterne\"] = np.where(products_order_items_orders_reviews[\"review_score\"]==5, 1 , 0)\ndf_interpretation = products_order_items_orders_reviews[[\"review_score\",\"Gute_Bewertung\",\"1Stern\",\"2Sterne\",\n                                                         \"3Sterne\",\"4Sterne\",\"5Sterne\"]]","7325d511":"products_order_items_orders_reviews[\"Niedriger_Preis\"] = np.where((products_order_items_orders_reviews[\"price\"]>=0) & (products_order_items_orders_reviews[\"price\"]<=50), 1 , 0)\nproducts_order_items_orders_reviews[\"Niedriger_mittlerer_Preis\"] = np.where((products_order_items_orders_reviews[\"price\"]>50) & (products_order_items_orders_reviews[\"price\"]<=100), 1 , 0)\nproducts_order_items_orders_reviews[\"Mittlerer_Preis\"] = np.where((products_order_items_orders_reviews[\"price\"]>100) & (products_order_items_orders_reviews[\"price\"]<=150), 1 , 0)\nproducts_order_items_orders_reviews[\"Mittlerer_hoher_Preis\"] = np.where((products_order_items_orders_reviews[\"price\"]>150) & (products_order_items_orders_reviews[\"price\"]<=250), 1 , 0)\nproducts_order_items_orders_reviews[\"Hoher_Preis\"] = np.where(products_order_items_orders_reviews[\"price\"]>250, 1 , 0)\ndf_interpretation = products_order_items_orders_reviews[[\"price\",\"Niedriger_Preis\",\"Niedriger_mittlerer_Preis\",\n                                                         \"Mittlerer_Preis\",\"Mittlerer_hoher_Preis\",\"Hoher_Preis\"]]\ndf_interpretation.describe()","560e4e50":"products_order_items_orders_reviews[\"Niedriges_Gewicht\"] = np.where((products_order_items_orders_reviews[\"product_weight_g\"]>=0) & (products_order_items_orders_reviews[\"product_weight_g\"]<=400), 1 , 0)\nproducts_order_items_orders_reviews[\"Niedriges_mittleres_Gewicht\"] = np.where((products_order_items_orders_reviews[\"product_weight_g\"]>400) & (products_order_items_orders_reviews[\"product_weight_g\"]<=800), 1 , 0)\nproducts_order_items_orders_reviews[\"Mittleres_Gewicht\"] = np.where((products_order_items_orders_reviews[\"product_weight_g\"]>800) & (products_order_items_orders_reviews[\"product_weight_g\"]<=1200), 1 , 0)\nproducts_order_items_orders_reviews[\"Mittleres_hohes_Gewicht\"] = np.where((products_order_items_orders_reviews[\"product_weight_g\"]>1200) & (products_order_items_orders_reviews[\"product_weight_g\"]<=3200), 1 , 0)\nproducts_order_items_orders_reviews[\"Hohes_Gewicht\"] = np.where(products_order_items_orders_reviews[\"product_weight_g\"]>3200, 1 , 0)\ndf_interpretation = products_order_items_orders_reviews[[\"product_weight_g\",\"Niedriges_Gewicht\",\"Niedriges_mittleres_Gewicht\",\n                                                         \"Mittleres_Gewicht\",\"Mittleres_hohes_Gewicht\",\"Hohes_Gewicht\"]]\ndf_interpretation.describe()","3e34c573":"#Erzeugen einer neuen Variable, die die Anzahl der Tage vor der geplanten Lieferung zeigt:\nproducts_order_items_orders_reviews[\"Tage_vor_geplanter_Lieferung\"] = np.ceil((products_order_items_orders_reviews[\"order_estimated_delivery_date\"] - products_order_items_orders_reviews[\"order_delivered_customer_date\"]) \/ (np.timedelta64(1, \"D\")))\n\n# Eingrenzen des relevanten Bereichs\nuntere_grenze = products_order_items_orders_reviews[\"Tage_vor_geplanter_Lieferung\"].min() - 1\nobere_grenze = products_order_items_orders_reviews[\"Tage_vor_geplanter_Lieferung\"].max() + 1\n\n# Visualisierung der Auspr\u00e4gungen der Anzahl von Tage vor geplanter Lieferung\nax = products_order_items_orders_reviews[\"Tage_vor_geplanter_Lieferung\"].hist(bins=500, stacked=True, color='teal', figsize=(16,5))\nax.set(xlabel='Tage vor geplanter Lieferung', ylabel='H\u00e4ufigkeit im Datenframe')\nplt.xlim(untere_grenze, obere_grenze)\nplt.show()","d7b97072":"tage_groesser_als = 50\ntage_groesser_summe = np.where((products_order_items_orders_reviews[\"Tage_vor_geplanter_Lieferung\"]>=tage_groesser_als),1,0).sum()\ntage_groesser_summe_prozentual = (tage_groesser_summe\/products_order_items_orders_reviews[\"Tage_vor_geplanter_Lieferung\"].count())*100\n\ntage_kleiner_als = -25\ntage_kleiner_summe = np.where((products_order_items_orders_reviews[\"Tage_vor_geplanter_Lieferung\"]<=tage_kleiner_als),1,0).sum()\ntage_kleiner_summe_prozentual = (tage_kleiner_summe\/products_order_items_orders_reviews[\"Tage_vor_geplanter_Lieferung\"].count())*100\n\nprint('Es gibt {} Produkte, die mehr als {} Tage fr\u00fcher geliefert wurden.' .format(tage_groesser_summe,tage_groesser_als))\nprint('Das entspricht {:.3}% der Summe am Datensatz' .format(tage_groesser_summe_prozentual))\nprint('Es gibt {} Produkte, die mehr als {} Tage nach dem geplanten Lieferdatum geliefert wurden.' .format(tage_kleiner_summe,-tage_kleiner_als))\nprint('Das entspricht {:.3}% der Summe am Datensatz' .format(tage_kleiner_summe_prozentual))","dc933768":"untere_grenze = tage_kleiner_als\nobere_grenze = tage_groesser_als\nax = products_order_items_orders_reviews[\"Tage_vor_geplanter_Lieferung\"].plot(kind='hist', bins=500, color='teal', xlim = [untere_grenze,obere_grenze], figsize=(16,5))\nax.set(xlabel='Tage vor geplanter Lieferung', ylabel='H\u00e4ufigkeit im Datenframe')\nprint('Es werden {:.3}% des Datenframes hinsichtlich der Tage vor geplanter Lieferung angezeigt.' .format(100-tage_groesser_summe_prozentual-tage_kleiner_summe_prozentual))","4aeeb3c4":"products_order_items_orders_reviews[\"Rechtzeitige_Lieferung\"] = np.where(products_order_items_orders_reviews[\"Tage_vor_geplanter_Lieferung\"]>=0, 1 , 0)\nproducts_order_items_orders_reviews[\"Geplante_Lieferung\"] = np.where(products_order_items_orders_reviews[\"Tage_vor_geplanter_Lieferung\"]==0, 1 , 0)\nproducts_order_items_orders_reviews[\"Verspaetete_Lieferung\"] = np.where(products_order_items_orders_reviews[\"Tage_vor_geplanter_Lieferung\"]<0, 1 , 0)\nproducts_order_items_orders_reviews[\"Vorzeitige_Lieferung\"] = np.where(products_order_items_orders_reviews[\"Tage_vor_geplanter_Lieferung\"]>0, 1 , 0)\ndf_interpretation = products_order_items_orders_reviews[[\"order_delivered_customer_date\",\"order_estimated_delivery_date\",\"Tage_vor_geplanter_Lieferung\",\"Rechtzeitige_Lieferung\",\n                                                         \"Geplante_Lieferung\",\"Verspaetete_Lieferung\",\"Vorzeitige_Lieferung\",\"Gute_Bewertung\"]]\ndf_interpretation.head()","d8ec4397":"df_interpretation = products_order_items_orders_reviews[[\"Rechtzeitige_Lieferung\",\"Verspaetete_Lieferung\",\"1Stern\",\"2Sterne\",\"3Sterne\",\"4Sterne\",\"5Sterne\"]]\neinstern_rl = np.where((df_interpretation[\"1Stern\"]==1) & (df_interpretation[\"Rechtzeitige_Lieferung\"]==1), 1 , 0).sum()\neinstern_vl = np.where((df_interpretation[\"1Stern\"]==1) & (df_interpretation[\"Rechtzeitige_Lieferung\"]==0), 1 , 0).sum()\nzweistern_rl = np.where((df_interpretation[\"2Sterne\"]==1) & (df_interpretation[\"Rechtzeitige_Lieferung\"]==1), 1 , 0).sum()\nzweistern_vl = np.where((df_interpretation[\"2Sterne\"]==1) & (df_interpretation[\"Rechtzeitige_Lieferung\"]==0), 1 , 0).sum()\ndreistern_rl = np.where((df_interpretation[\"3Sterne\"]==1) & (df_interpretation[\"Rechtzeitige_Lieferung\"]==1), 1 , 0).sum()\ndreistern_vl = np.where((df_interpretation[\"3Sterne\"]==1) & (df_interpretation[\"Rechtzeitige_Lieferung\"]==0), 1 , 0).sum()\nvierstern_rl = np.where((df_interpretation[\"4Sterne\"]==1) & (df_interpretation[\"Rechtzeitige_Lieferung\"]==1), 1 , 0).sum()\nvierstern_vl = np.where((df_interpretation[\"4Sterne\"]==1) & (df_interpretation[\"Rechtzeitige_Lieferung\"]==0), 1 , 0).sum()\nfuenfstern_rl = np.where((df_interpretation[\"5Sterne\"]==1) & (df_interpretation[\"Rechtzeitige_Lieferung\"]==1), 1 , 0).sum()\nfuenfstern_vl = np.where((df_interpretation[\"5Sterne\"]==1) & (df_interpretation[\"Rechtzeitige_Lieferung\"]==0), 1 , 0).sum()\n\n# Darstellung des ganzen Datenframes nach Gruppierung der vorzeitigen Lieferung.\nprint(\"Die Anzahl der rechtzeitigen Lieferungen betr\u00e4gt {} und der versp\u00e4teten betr\u00e4gt {}\" .format(df_interpretation[\"Rechtzeitige_Lieferung\"].sum(),df_interpretation[\"Verspaetete_Lieferung\"].sum()))\nprint(\"\")\nprint(\"Bei Bewertung = 1 sind {} Lieferungen rechtzeitig und {} versp\u00e4tet. Verh\u00e4ltnis betr\u00e4gt: {:.3}%\" .format(einstern_rl,einstern_vl,einstern_vl\/einstern_rl*100))\nprint(\"Bei Bewertung = 2 sind {} Lieferungen rechtzeitig und {} versp\u00e4tet. Verh\u00e4ltnis betr\u00e4gt: {:.3}%\" .format(zweistern_rl,zweistern_vl,zweistern_vl\/zweistern_rl*100))\nprint(\"Bei Bewertung = 3 sind {} Lieferungen rechtzeitig und {} versp\u00e4tet. Verh\u00e4ltnis betr\u00e4gt: {:.3}%\" .format(dreistern_rl,dreistern_vl,dreistern_vl\/dreistern_rl*100))\nprint(\"Bei Bewertung = 4 sind {} Lieferungen rechtzeitig und {} versp\u00e4tet. Verh\u00e4ltnis betr\u00e4gt: {:.3}%\" .format(vierstern_rl,vierstern_vl,vierstern_vl\/vierstern_rl*100))\nprint(\"Bei Bewertung = 5 sind {} Lieferungen rechtzeitig und {} versp\u00e4tet. Verh\u00e4ltnis betr\u00e4gt: {:.3}%\" .format(fuenfstern_rl,fuenfstern_vl,fuenfstern_vl\/fuenfstern_rl*100))\n\ndf_interpretation.groupby(\"Rechtzeitige_Lieferung\").sum().head()","fffa4a24":"# Hinzuf\u00fcgen der folgenden Spalte, die die Anzahl der Tage von der Lieferung bis zur Erstellung der Bewertung enth\u00e4lt\nproducts_order_items_orders_reviews[\"Tage_bis_Bewertungsabgabe\"] = np.ceil((products_order_items_orders_reviews[\"review_creation_date\"] - products_order_items_orders_reviews[\"order_delivered_customer_date\"]) \/ (np.timedelta64(1, \"D\")))\nproducts_order_items_orders_reviews.head()","d71b8b22":"products_order_items_orders_reviews[\"Tage_bis_Bewertungsabgabe\"].plot(kind='hist', bins=500, color='teal', figsize=(16,5), xlim=[-20,10]).set(xlabel= 'Tage bis zur Erstellung der Bewertung', ylabel='H\u00e4ufigkeit der Bewertung')","b3a08846":"# Eingrenzung und eigene Bewertung mit der Aussage, was wenige Tage zur Bewertung sind:\nproducts_order_items_orders_reviews[\"Schnelle_Bewertung\"] = np.where((products_order_items_orders_reviews[\"Tage_bis_Bewertungsabgabe\"]>=0) & (products_order_items_orders_reviews[\"Tage_bis_Bewertungsabgabe\"]<=3), 1 , 0)","664342f4":"df_productreviews = products_order_items_orders_reviews[[\"Gute_Bewertung\",\"Rechtzeitige_Lieferung\",\n                                                         \"product_description_lenght\",\"product_photos_qty\",\"price\",\n                                                         \"Vorzeitige_Lieferung\",\"Geplante_Lieferung\",\"Verspaetete_Lieferung\",\n                                                         \"1Stern\",\"2Sterne\",\"3Sterne\",\"4Sterne\",\"5Sterne\"]]\ndf_productreviews.head()","44391d19":"# Korrelationsmatrix erzeugen, um die Zusammenh\u00e4nge darzustellen\ncor = df_productreviews.corr()\nplt.figure(figsize=(16,5))\nsns.heatmap(cor, annot=True, fmt=\".2g\", linewidths=0.5)","d52a5a83":"# Weiterer Datenframe, um die Pr\u00e4diktoren weiter einzugrenzen\ndf_productreviews2 = products_order_items_orders_reviews[[\"Gute_Bewertung\",\"Rechtzeitige_Lieferung\",\n                                                          \"product_description_lenght\",\"product_photos_qty\",\"price\",\"product_weight_g\"]]\n\n# Korrelationsmatrix erzeugen, um die Zusammenh\u00e4nge darzustellen\ncor2 = df_productreviews2.corr()\nplt.figure(figsize=(16,5))\nsns.heatmap(cor2, annot=True, fmt=\".2g\", linewidths=0.5)","321ce1da":"#Weiterer Datenframe, um die Pr\u00e4diktoren weiter einzugrenzen\ndf_productreviews3 = products_order_items_orders_reviews[[\"Gute_Bewertung\",\"Rechtzeitige_Lieferung\",\n                                                          \"Niedriger_Preis\",\"Niedriger_mittlerer_Preis\",\"Mittlerer_Preis\",\n                                                          \"Mittlerer_hoher_Preis\",\"Hoher_Preis\",\n                                                          \"Niedriges_Gewicht\",\"Niedriges_mittleres_Gewicht\",\"Mittleres_Gewicht\",\n                                                          \"Mittleres_hohes_Gewicht\",\"Hohes_Gewicht\"]]\n\n# Korrelationsmatrix erzeugen, um die Zusammenh\u00e4nge darzustellen.\ncor3 = df_productreviews3.corr()\nplt.figure(figsize=(16,5))\nsns.heatmap(cor3, annot=True, fmt=\".2g\", linewidths=0.5)","555ac4a9":"# Erstellung eines neuen Datenframes f\u00fcr die Analyse Reviewdatum und Lieferung\ndf_review_delivery = products_order_items_orders_reviews[[\"Rechtzeitige_Lieferung\",\"Schnelle_Bewertung\",\"Gute_Bewertung\",\n                                                          \"5Sterne\",\"Vorzeitige_Lieferung\",\n                                                          \"1Stern\",\"Verspaetete_Lieferung\"]]\ndf_review_delivery.head()","61752ab2":"# Korrelationsmatrix erzeugen, um die Zusammenh\u00e4nge darzustellen.\ncor3 = df_review_delivery.corr()\nplt.figure(figsize=(9,3))\nsns.heatmap(cor3, annot=True, fmt=\".2g\", linewidths=0.5)","a34e748f":"Selected_features = ['Rechtzeitige_Lieferung', 'Schnelle_Bewertung']\n\nX = products_order_items_orders_reviews[Selected_features]\ny = products_order_items_orders_reviews['Gute_Bewertung']","34da92ce":"# Teilet die Daten auf\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) ","2ed031fa":"# 1. Modell wird erstellt\nlogreg = LogisticRegression(solver='lbfgs')\n\n# 2. Modell wird mit den Trainingsdaten (y = \"Clicked\" und X = \"ad_id\" und \"display_id\") trainiert\nlogreg.fit(X_train, y_train)","db980e54":"# Gibt die Genauigkeit (Accuracy) der Prognose aus\nprint('Accuracy of logistic regression classifier on TEST set: {:.2f}%' .format(logreg.score(X_test, y_test)*100))\n\n# Gibt die Zweifelhaftigkeit der Vorhersage aus \ny_pred_proba = logreg.predict_proba(X_test) # Speichert alle Parameter, die zur Prognose einer Variable ben\u00f6tigt werden\ny_pred_proba = y_pred_proba[:, 1] # Selektiert nur die Prognosen f\u00fcr Gute_Bewertung = 1\nprint(logreg.__class__.__name__+\" log_loss is %2.3f\" % (log_loss(y_test, y_pred_proba)*100) + '%')","e97139a3":"# Erstellen einer Confusion Matrix\ny_pred = logreg.predict(X_test)\nconfusion_matrix = confusion_matrix(y_test, y_pred)\nprint(confusion_matrix)","7f543bd9":"# Erstellung des Klassifikationsberichts\ntarget_names = ['Schlechte Bewertung (0)', 'Gute Bewertung (1)']\nprint(classification_report(y_test, y_pred, target_names=target_names))","652462ba":"logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","e6947b95":"test_X = products_order_items_orders_reviews[Selected_features]\npredicted_reviewScore = logreg.predict(test_X)\n\nmy_submission = pd.DataFrame({'OrderId': products_order_items_orders_reviews.order_id, 'Gute_Bewertung': predicted_reviewScore})\nmy_submission.to_csv('submission.csv', index=False)","15130712":"Die Korrelationsmatrix zeigt auch, dass der Zusammenhang zwischen einer guten Bewertung und der Anzahl der Bilder sowie L\u00e4nge der Produktbeschreibung nur sehr gering ist. \nJedoch scheint ein gr\u00f6\u00dferer Zusammenhang zwischen \"price\" und \"product_weight_g\" zu bestehen, den wir mithilfe der Kategorisierung des \"product_weight_g\" und des \"price\" genauer angucken k\u00f6nnen.\n\nWir wollen uns das nochmals genauer ansehen und haben deshalb die Kategorisierung des Preises und des Gewichts durchgef\u00fchrt.","c6d8f7af":"Die meisten Bewertungen haben einen Wert von 5. Das sollten wir uns nochmals genauer ansehen.","450dab88":"### 5.3 ROC Curve\n\nDie ROC Kurve stellt die true positive (tats\u00e4chlich gute Bewertung, Modell prognostiziert gute Bewertung) gegen\u00fcber false positive (tats\u00e4chlich schlechte Bewertung, Modell prognostiziert gute Bewertung) Werte dar.\n\nF\u00fcr uns ist neben dem Verlauf der Kurve auch der AUC(area under curve)-Wert relevant. Je besser die Klassifizierungsf\u00e4higkeit des Klassifikators ist, desto h\u00f6her ist der AUC-Wert. Der AUC-Wert kann als Wahrscheinlichkeit interpretiert werden, dass ein positiver Wert auch tats\u00e4chlich als solcher klassifiziert wird (Quelle: [hier](http:\/\/www.statistics4u.info\/fundstat_germ\/ee_classifier_roc_curve.html)).\nEs gilt: Je h\u00f6her der AUC, desto besser kann das Modell 0en als 0en und 1en als 1en erkennen. ","575bc632":"**Interpretation**\n\nNegative Werte bedeuten, dass die Produktbewertung vor der Lieferung des Produktes durchgef\u00fchrt wurde. M\u00f6glich ist das aufgrund der Tatsache, dass eine Mail zur Bewertung der Kundenzufriedenheit verschickt wird, wenn die Lieferung zugestellt wurde oder das Datum des geplanten Lieferdatums erreicht wurde.\n\nDer Versand der Bewertungsmail am geplanten Lieferdatum sorgt bei einigen derjenigen Lieferungen, die noch nicht zum Zeitpunkt des Mailversands zugestellt wurden daf\u00fcr, dass eine Bewertung abgegeben wurde, bevor das Produkt zugestellt wurde.","d7e5a0fe":"# 4. Prognose erstellen","32ffd4af":"# 2. Daten verstehen","87049397":"## 3.1 Erzeugen eigener Variablen\n\nBasierend auf der Analyse und weiteren \u00dcberlegungen f\u00fchren wir weitere Variablen unserem Haupt-Datenframe zu.","33ae1a28":"## 2.3 Zusammenf\u00fchren der Datens\u00e4tze\n\nUm die Variablen hinsichtlich des Projektsziels zu untersuchen m\u00fcssen die Tabellen zusammengef\u00fchrt werden. Man erh\u00e4lt eine gr\u00f6\u00dfere Flexibilit\u00e4t, wenn man das Zusammenf\u00fchren der Datenframes nach dem Einlesen und Speichern durchf\u00fchrt. So sind gr\u00f6\u00dfere Anpassungen (z.B. wenn man feststellt, dass man weitere Informationen aus einer anderen Tabelle ben\u00f6tigt oder Datentypen beim Einlesen angepasst werden sollen), einfacher durchzuf\u00fchren.","e7b7f9e4":"### 5.2 Klassifikationsbericht\n\nDer Klassifikationsbericht liefert einen Report \u00fcber die Hauptklassifikations-Metriken, um das Modell zu validieren. Als Grundlage f\u00fcr die Berechnung wird die Wahrheitsmatrix verwendet.\n\nF\u00fcr uns sind nur die Metriken Precision und Recall interessant und relevant. ","939f066d":"## 2.5 Fehlende Werte\n\nAls n\u00e4chstes ben\u00f6tigen wir Aufschluss dar\u00fcber, in wie vielen Datens\u00e4tzen Werte fehlen. Diese \u00dcberpr\u00fcfung ist wichtig, um eine Aussage dar\u00fcber zu erhalten, ob man \u00fcberhaupt die Variablen im weiteren Prozess verwenden kann oder ob zu viele Werte fehlen.","5c61f0b0":"# 0. Inhaltsangabe","7e946ff2":"### 3.2.1 Zustellung vor geplanter Lieferung\nEs k\u00f6nnte interessant sein eine Variable zu erzeugen, die die Differenz der Tage zwischen dem urspr\u00fcnglichen Lieferdatum und der tats\u00e4chlichen Zustellung an den Kunden zeigt.\n\nEs muss auch bei 0,03 aufgerundet werden, da der geplante Tag als Tag mit Timestamp 0:00:00 interpretiert wird.","c6533725":"**Interpretation:**\n\nPositive Werte bedeuten, dass die Bestellung vor dem urspr\u00fcnglichen Lieferdatum an den Kunden zugestellt wurde (Lieferung vorzeitig erfolgt).\nNegative Werte bedeuten, dass die Bestellung nach dem urspr\u00fcnglichen Lieferdatum an den Kunden zugestellt wurde (Lieferung versp\u00e4tet).\n\nDas Chart zeigt, dass die meisten Werte positiv sind. Daraus folgt, dass die meisten Lieferungen vorzeitig zugestellt wurden (also vor dem urspr\u00fcnglichen Lieferdatum).\n\n--> Es liegt nahe, dass die Anzahl der Tage bis zur Lieferung die Produktbewertung eines Kunden beeinflusst. Um dies genauer zu analysieren, m\u00fcssen weitere Variablen erzeugt werden","3958c95d":"### 2.4.2 Statistische Zusammenfassung\nMit folgendem Aufruf kann man sich eine Zusammenfassung eines Datenframes anzeigen lassen:","47fac883":"### 3.1.2 Bewertungsauspr\u00e4gungen\n\nZwecks genauerer Analysen \u00fcberf\u00fchren wir die kategoriale Variable review_score in bin\u00e4re Variablen.","e3ffaeb9":"## 2.6 Analyse des Datenframes","cc584c3b":"**Interpretation**\n\nDer Tabelle ist zu entnehmen, dass bei einer rechtzeitigen Lieferung die Bewertung eine Auspr\u00e4gung von 4 oder 5 hat und in Summe ca. 80% somit in die Kategorie Gute_Bewertung bei rechtzeitiger Lieferung f\u00e4llt. \nAuff\u00e4llig ist auch, dass das Verh\u00e4ltnis der Bewertungsauspr\u00e4gung negativ zur Summe der rechtzeitigen Lieferungen korreliert.\n\nAussage ist: Je mehr Lieferungen rechtzeitig erfolgen, umso mehr gute Bewertungen werden erhalten. Je schlechter die Bewertung, umso h\u00e4ufiger wurde die Lieferung nicht rechtzeitig zugestellt.","f04e062d":"1. Business verstehen\n    * Zielsetzung\n    * Beschreibung\n    * Datenschema\n2. Daten verstehen\n    * Importieren der Bibliotheken und Frameworks\n    * Laden der Daten\n    * Zusammenf\u00fchren der Datens\u00e4tze\n        - Tabellen verkn\u00fcpfen\n        - Datentypen \u00fcberpr\u00fcfen\n        - Datentypen anpassen\n    * Kleine Hilfestellungen zum Interpretieren der Zahlen\n        - Die ersten f\u00fcnf Datens\u00e4tze\n        - Statistische Zusammenfassung\n    * Fehlende Werte\n    * Analyse des Datenframes\n        - Produktbewertung\n        - Produktbilder\n        - Produktpreis\n        - Produktgewicht\n3. Daten vorbereiten\n    * Erzeugen eigener Variablen\n        - Gute Bewertung\n        - Bewertungsauspr\u00e4gungen\n        - Preiskategorien\n        - Produktgewicht\n    * Weitere interessante Variablen\n        - Zustellung vor geplanter Lieferung\n        - Tage bis Bewertungsabgabe\n        - Schnelle Bewertung\n    * Eingrenzung der Pr\u00e4diktoren\n4. Prognose erstellen\n5. Evaluation: Das Validieren des Modells\n    * Wahrheitsmatrix\n    * Klassifikationsbericht\n    * ROC Curve\n6. Deployment: Bereitstellung","2f61a857":"Die Produktbilder haben am h\u00e4ufigsten eine Anzahl zwischen 1 und 5. Das sollten wir uns nochmals genauer ansehen.","259fb887":"**Interpretation:**\n\nDie Indices der Matrix sind wie folgt definiert (von oben links nach unten rechts):\n* true negative (3007): Eine schlechte Bewertung wurde abgegeben. Das Modell hat dies richtig erkannt.\n* false positive (8248):  Eine schlechte Bewertung wurde abgegeben. Das Modell hat jedoch eine gute Bewertung prognostiziert.\n* false negative (875): Eine gute Bewertung wurde abgegeben. Das Modell hat jedoch eine schlechte Bewertung prognostiziert.\n* true positive (33199): Eine gute Bewertung wurde abgegeben. Das Modell hat dies richtig erkannt.\n\nDas Modell konnte **36.206**  (3007 + 33199) richtig und **9.123** (8248 + 875) inkorrekt klassifizieren. \n\nInsgesamt gab es **34.074** (33.199 + 875) gute Bewertungen, wovon 875 falsch und 33.199 richtig von dem Modell prognostiziert wurden.\n\nIm Gegenzug gab es **11.255** (3007 + 8248) Schlechte Bewertungen (Gute_Bewertung = 0), wovon 8248 falsch und 3007 richtig von dem Modell prognostiziert wurden.","2522d580":"### 2.6.4 Produktgewicht\nAls n\u00e4chstes gucken wir uns das Produktgewicht an. Anzumerken ist hierbei, dass die Angabe in Gramm (g) in der Tabelle steht.\n\nDie zu kl\u00e4rende Frage lautet: ** Hat das Produktgewicht Einfluss auf die Bewertung?**","ddd273c7":"Erkl\u00e4rung der relevanten Variablen:\n* \"product_category_name\" enth\u00e4lt die Bezeichnung der Produktkategorie des gekauften Produktes auf Portugiesisch\n* \"product_name_lenght\" enth\u00e4lt die Anzahl der Buchstaben der Produktbezeichnung (z.B. auf der Produktseite)\n* \"product_description_lenght\" enth\u00e4lt die Anzahl der Buchstaben der Produktbeschreibung (z.B. auf der Produktseite)\n* \"product_photos_qty\" enth\u00e4lt die Anzahl der Produktbilder (z.B. auf der Produktseite)\n* \"product_weight_g\" enth\u00e4lt das Gewicht in Gramm des Produktes\n* \"product_category_name_english\" enth\u00e4lt die Bezeichnung der Produktkategorie des gekauften Produktes auf Englisch\n* \"price\" enth\u00e4lt den Preis des Produktes\n* \"order_delivered_customer_date\" enth\u00e4lt das Datum und die Uhrzeit, an dem die Bestellung zugestellt wurde\n* \"order_estimated_delivery_date\" enth\u00e4lt das voraussichtliche Lieferdatum\n* \"review_score\" enth\u00e4lt den Bewertungswert von 1 bis 5 eines Kunden, der im Rahmen einer Zufriedenheitsumfrage, die automatisch per Mail geschickt wird, sobald die Bestellung zugestellt oder das voraussichtliche Lieferdatum erreicht wurde\n* \"review_creation_date\" enth\u00e4lt das Datum, an dem die Bewertung abgegeben wurde","f74f7bf4":"## 2.1 Importieren der Bibliotheken und Frameworks\n\nZu\u00e4chst werden alle notwendigen Frameworks, Bibliotheken und Tabellen geladen. Dies ist ein elementarer Schritt, um Zugriff auf relevante Funktionen zu erhalten. ","9dbb18a1":"**Precision (Genauigkeit):** \n* Gibt Aufschluss dar\u00fcber, zu wieviel Prozent die Vorhersagen (Ja\/Nein) korrekt waren.\n* Wenn das Modell eine gute Bewertung prognostiziert, dann tut es das mit einer Wahrscheinlichkeit von **80%**\n   Oder konkret: Zu 80% wurde eine tats\u00e4chlich gute Bewertung auch als gute Bewertung prognostiziert\n* Wenn das Modell eine schlechte Bewertung prognostiziert, dann tut es das mit einer Wahrscheinlichkeit von **77%**\n\n**Recall (Trefferquote):**\n* Im Fall einer 1-Klassifikation gibt der Recall den Anteil der korrekt als positive klassifizierten Objekte an der Gesamtheit der tats\u00e4chlichen positiven Objekte an. Unser Modell identifiziert zu **97%** alle guten Bewertungen oder konkret gesagt: Wenn eine Bestellung in den Testdaten eine gute Bewertung hat, dann kann unser Modell das zu 97% identifizieren.\n* Bereits hier ist auff\u00e4llig, dass wir eine hohe Anzahl von guten Bewertungen haben. Denn schlechte Bewertungen k\u00f6nnen nur mit einer Wahrscheinlichkeit von **27%** identifiziert werden.","275ed348":"# 1. Business verstehen","a2ab54a2":"## 1.1 Zielsetzung\n\nUnser Prognoseziel ist es herauszufinden,  **welche Faktoren einen Einfluss auf eine (positive) Produktbewertung haben**, sodass wir am Ende ein Modell entwickelt haben, welches uns m\u00f6glichst pr\u00e4zise vorhersagen kann, **ob eine Bestellung eine gute oder schlechte Bewertung haben wird.**\n\nM\u00f6gliche Faktoren k\u00f6nnen unter anderem sein:\n* Anzahl der Produktbilder (d.h: k\u00f6nnen mehr Produktbilder zu einer besseren Bewertung f\u00fchren?)\n* L\u00e4nge der Produktbeschreibung (d.h. f\u00fchrt eine l\u00e4ngere Produktbeschreibung zu weniger Fehlk\u00e4ufe?)\n* Lieferdatum (d.h. werden Produkte die fr\u00fcher oder zum angegebenen Datum gelifert werden besser bewertet?)\n* Zeitpunkt der Erstellung der Bewertung (dh wird besser bewertet, wenn die Bewertung innerhalb weniger Tagen erfolgte?)","5e88ed09":"Da ein sehr gro\u00dfer Bereich leer zu sein scheint, l\u00e4sst sich darauf schlie\u00dfen, dass es wenig Produkte gibt, die ein hohes Gewicht haben (z.B. Produktgewicht > 20000).\n\nDas wollen wir uns genauer angucken, um damit eine sinnvolle Skala f\u00fcr die X-Achse der ersten Visualisierung des Produktgewichts zu ermitteln.","9abafa66":"## 3.3 Eingrenzung der Pr\u00e4diktoren","6b31f25c":"### 5.1 Wahrheitsmatrix\n\nDie Wahrheitsmatrix zeigt uns die richtigen und falschen Klassifikationen an. ","8caa24ca":"# 5. Evaluation: Das Validieren des Modells\n\nWir wollen nun genauer herausfinden, wie gut unser Modell arbeitet. F\u00fcr jeden Modelltypen gibt es unterschiedliche Arten das Modell zu evaluieren. \nF\u00fcr eine bin\u00e4re Klassifikation sind die folgenden 3 Methoden die g\u00e4ngigsten:\n * Wahrheitsmatrix (engl. Confusion Matrix)\n * Klassifizierungsbericht (engl. Classification Report)\n * Receiver-Operating-Characteristic-Kurve (engl. ROC Curve) ","40e20e7f":"Die Korrelationsmatrix zeigt einen Zusammenhang zwischen \"Gute_Bewertung\" und \"Rechtzeitige_Lieferung\" und keinen Zusammenhang zwischen \"Gute_Bewertung\" und \"product_description_lenght\", \"product_photos_qty\" oder \"price\" auf. Jedoch scheint ein geringer Zusammenhang zwischen \"product_description_lenght\" und \"price\" zu bestehen.","3a07415c":"Der Tabelle von 3.1.3 ist zu entnehmen, dass ca. 35% der Produkte in die Kategorie \"Niedriger_Preis\" fallen, sprich einen Preis zwischen 0 und 50 brasilianischer Real aufweisen. In Euro umgerechnet sind das Produkte, die zwischen 0 und 11,81\u20ac kosten (Stand 5.1.2019).\nAnalog dazu l\u00e4sst sich sagen, dass ca. 29% der Produkte in die Kategorie \"Niedriger_mittlerer_Preis\" fallen, sprich einen Preis zwischen 50 und 100 brasilianischer Real aufweisen. In Euro umgerechnet sind das Produkte, die zwischen 11,81\u20ac und 23,62\u20ac kosten (Stand 5.1.2019).\nUsw.","37e6887a":"Es muss ein neuer Datenframe erzeugen werden, um die Pr\u00e4diktoren einzugrenzen. Danach wird eine Korrelationsmatrix erzeugt, um bisherige Definitionen zu \u00fcberpr\u00fcfen und Zusammenh\u00e4nge zwischen den Variablen aufzuzeigen.","8c07e1d0":"Die Logistischen Regression wird in die Variable \u201c**logreg**\u201d gespeichert. Bei dem Aufruf ist es wichtig, dass der Parameter \u201csolver = \u2018lbfgs\u2019 \u201d angegeben ist. Zur Auswahl stehen vier verschiedene Solver-Arten, wobei die Auswahl der Art f\u00fcr unsere Analyse keinen Einfluss haben. Die Arten unterscheiden sich nur in Hinsicht auf ihre mathematische Berechnung. \n\nIn Anschluss mit dem **fit**-Aufruf trainiert das Modell mit den Trainingsdaten (X_train, y_train). \nDas Modell benutzt die Daten und erstellt sich selber eine Regressionslinie. ","8a05505f":"Der Tabelle ist zu entnehmen, dass ca. 50% der Produkte nur ein Produktbild und ca. 70% maximal 2 Produktbilder haben.\n\n\u00dcber 80% der Produkte haben nur zwischen 1 und 3 Produktbildern, was verh\u00e4ltnism\u00e4\u00dfig wenig Bilder sind. Es liegt nahe die Datens\u00e4tze hinsichtlich der Anzahl der Produktbilder zu kategorisieren.","f874e729":"Es l\u00e4sst sich auch noch detailierter Analysieren, welche Verteilung hinsichtlich der Bewertungsauspr\u00e4gung vorliegt.","1419d9c0":"Mit dem Aufruf \u201c**train_test_split**\u201d k\u00f6nnen Daten in zuf\u00e4llige Trainings- und Testdaten separiert werden. Als Parameter geben wir neben unseren X und y Datens\u00e4tzen, die Gr\u00f6\u00dfe der Testdatei an.\n\nEs werden 4 Variablen erzeugt:\nEin Trainingsdatensatz (X_train, y_train), welches aus 40% der Daten, sowie ein Testdatensatz (X_test, y_test), welches aus 60% der Daten erzeugt werden. Dieses Verh\u00e4ltnis ist ein typischer Ansatz, um die Daten vom Zufall gesteuerten Trainings- und Testdaten aufzuteilen (Quelle: Machine Learning kurz & gut S.35)\n\n**Trainingsdaten**: Ist der Datensatz, mit dem das Modell trainieren wird. Das Modell schaut sich die Daten (\"Schnelle_Bewertung\", \"Rechtzeitige_Lieferung\" und \"Gute_Bewertung\") an und lernt aus ihnen.\n\n**Testdaten**: Mit diesem Datensatz wird das Modell evaluiert. Testdaten werden erst verwendet, wenn das Modell komplett trainiert wurde. F\u00fcr jede Zeile (bzw. Bestellung) im Testset wird das Modell verwendet, um eine Prognose zu stellen (Gute_Bewertung = ?). Die Prognose wird dann mit dem tats\u00e4chlichen Wert verglichen, um zu zeigen wie gut das Modell arbeitet.","2da3a6c0":"# 6. Deployment: Bereitstellung\n\nNach dem Erstellen und Validieren unseres Modells k\u00f6nnen wir die Ergebnisse unserer Prognose in eine CSV-Datei schreiben.\nUnser Modell prognostiziert pro Bestellung (order_id), ob eine gute Bewertung abgegeben wird.\nDie Datei kann unter dem Punkt \"Output\" eingesehen und heruntergeladen werden.","0972ff71":"**Interpretation: **\n\nWird ein Produkt vorzeitig oder wie geplant geliefert, erfolgt in den meisten F\u00e4llen eine Bewertung des Produktes innerhalb der n\u00e4chsten 3 Tage. Dementsprechend sind folgende Variablen f\u00fcr unser Vorhesagemodell relevant:\n\nRechtzeitige_Lieferung, Schnelle_Bewertung und Gute_Bewertung","a27c68a2":"### 2.3.3 Datentypen anpassen\n\nEinige Datentypen m\u00fcssten angepasst werden, da sie so nicht wirklich sinnvoll sind. Zum Beispiel sollte es logischerweise nur eine ganzzahlige Anzahl von Produktbildern geben.","c6ff5a94":"Der Tabelle von 3.1.4 ist zu entnehmen, dass ca. 36% der Produkte in die Kategorie \"Niedriges_Gewicht\" fallen, sprich ein Gewicht zwischen 0 und 400 Gramm aufweisen.\nAnalog dazu l\u00e4sst sich sagen, dass ca. 18% der Produkte in die Kategorie \"Niedriges_mittleres_Gewicht\" fallen, sprich ein Gewicht zwischen 400 und 800 Gramm haben.\nUsw.","54ffa1c1":"# 3. Daten vorbereiten","24790296":"### 3.1.1 Gute Bewertung\n\nEine gute Bewertung ist f\u00fcr uns eine Bewertung, die die Auspr\u00e4gung 4 oder 5 hat. ","a2f62308":"**Interpretation:**\n- Ein Produkt wird immer mit einem Score (Wert von 1 bis 5) bewertet, allerdings ist die Bereitschaft ein Produkt-Review zu schreiben sehr gering (hohe Anzahl von fehlenden Review Titel und Review Messages)\n- Bei 18 Produkten wurden die Daten nicht vollst\u00e4ndig hinsichtlich Gewicht und Abma\u00dfe gepflegt oder es gibt keine Informationen zu diesen Produkten\n- Bei 1612 Produkten fehlen Angaben zur Produktkategorie, Produktbezeichnung, Produktbeschreibung und Produktbildern.\n- Bei 2475 Lieferungen fehlen Angaben zum Zustellungszeitpunkt.\n\n**Wie geht man mit fehlenden Datens\u00e4tzen um?** \n\nNun hat man Auflschluss dar\u00fcber, wie viele Datens\u00e4tze im Datenframe fehlen. Es muss gekl\u00e4rt werden, ob die fehlenden Datens\u00e4tze relevant f\u00fcr unsere Problemstellung sind.  Sollten sie relevant sein, muss im n\u00e4chsten Schritt gekl\u00e4rt werden, was mit den fehleden Datens\u00e4tzen gemacht werden soll. In unserem Fall war es nicht notwendig Anpassungen vorzunehmen.","0edf450a":"Unser Modell hat ein AUC von 0.62. Dies ist ein mittelm\u00e4\u00dfiger Wert.  ","d0bd2c4d":"### 3.1.4 Produktgewicht\n\nAnhand der Analyse und der statistischen Daten k\u00f6nnen wir die Kategorien f\u00fcr das Produktgewicht wie folgt sinnvoll definieren:","bce6349b":"### 3.1.3 Preiskategorien\n\nAnhand der Analyse und der statistischen Daten k\u00f6nnen wir die Preiskategorien wie folgt sinnvoll definieren:","7bb9c22e":"Um sich die Verteilung genauer anzusehen, sollte die obere Grenzen des Graphen durch eine sinnvollere Obergrenze ersetzt werden. Hier nehmen wir den soeben als Obergrenze definierten Wert:","76d8333e":"### 2.4.1 Die ersten f\u00fcnf Datens\u00e4tze\nMit folgendem Aufruf kann man sich die ersten f\u00fcnf Datens\u00e4tze eines Datenframes anzeigen lassen:","b071094d":"## 1.2 Beschreibung\n\nDies ist ein brasilianischer \u00f6ffentlicher E-Commerce-Datensatz von Bestellungen, die im Olist Store get\u00e4tigt werden. Der Datensatz enth\u00e4lt Informationen zu 100.000 Bestellungen von 2016 bis 2018, die auf mehreren Marktpl\u00e4tzen in Brasilien gemacht wurden. Seine Funktionen erm\u00f6glichen das Anzeigen einer Bestellung aus mehreren Dimensionen: von Bestellstatus, Preis, Zahlungs- und Frachtleistung bis hin zum Kundenstandort, Produktattributen und schlie\u00dflich von Kunden erstellten Bewertungen. Enthalten ist auch ein Geolocation-Dataset, das brasilianische Postleitzahlen mit Lat \/ Lng-Koordinaten verkn\u00fcpft.\n\nDies sind echte Gesch\u00e4ftsdaten, sie wurden anonymisiert, und Verweise auf die Unternehmen und Partner im \u00dcberpr\u00fcfungstext wurden durch die Namen der gro\u00dfen H\u00e4user von Game of Thrones ersetzt.\n\nDieser Datensatz wurde gro\u00dfz\u00fcgig von Olist, dem gr\u00f6\u00dften Kaufhaus auf brasilianischen Marktpl\u00e4tzen, zur Verf\u00fcgung gestellt. Olist verbindet kleine Unternehmen aus ganz Brasilien mit Kan\u00e4len ohne Probleme und mit einem einzigen Vertrag. Diese H\u00e4ndler k\u00f6nnen ihre Produkte \u00fcber den Olist Store verkaufen und sie mithilfe von Olist-Logistikpartnern direkt an die Kunden versenden. Weitere Informationen finden Sie auf der Website: www.olist.com\n\nNachdem ein Kunde das Produkt im Olist Store gekauft hat, wird ein Verk\u00e4ufer benachrichtigt, um die Bestellung auszuf\u00fchren. Sobald der Kunde das Produkt erhalten hat oder der voraussichtliche Liefertermin f\u00e4llig ist, erh\u00e4lt der Kunde per E-Mail eine Zufriedenheitsumfrage, in der er die Kauferfahrung notieren und einige Kommentare aufschreiben kann.\n\nBeschreibung bzw. Link zum Dataset von Kaggle: https:\/\/www.kaggle.com\/olistbr\/brazilian-ecommerce\/home","d9c67e2c":"## 3.2 Weitere interessante Variablen","eccce8d8":"## 2.4 Kleine Hilfestellungen zum Interpretieren der Zahlen\n\nUm die Daten zu verstehen werden wir nun einige wichtige Fakten zu den Variablen und ihrer Beziehung zur Zielvariablen erkl\u00e4ren. Diese Aufrufe haben wir an einigen Stellen zur \u00dcberpr\u00fcfung eines Datenframes genutzt, jedoch auch wieder rausgenommen, als wir sie nicht mehr ben\u00f6tigten.","afbadd0c":"Um sich die Verteilung genauer anzusehen, sollte die obere Grenzen des Graphen durch eine sinnvollere Obergrenze ersetzt werden. Hier nehmen wir den soeben als Obergrenze definierten Wert:","af8e1427":"Der Korrelationsmatrix ist zu entnehmen, dass Produkte, die einen niedrigen Preis haben, in den meisten F\u00e4llen auch ein niedriges Gewicht haben und Produkte, die einen hohen Preis haben ein hohes Gewicht haben.","aaf42e66":"Um genauere Analysen durchzuf\u00fchren m\u00fcssen die Preise weiter kategorisiert werden und somit weitere Variablen eingef\u00fchrt werden. Allerdings muss hierbei die W\u00e4hrung ber\u00fccksichtigt werden. 1 Brasilianischer Real entspricht 0,24 Euro (Stand Anfang Januar 2019). An sich w\u00e4re es sinnvoller eine Tabelle zu erzeugen, die den Umrechnungskurs pro Tag f\u00fcr den gesamten Zeitraum enth\u00e4lt, um so auf einen durchschnittlichen Kurswert zu kommen bzw. besser m\u00f6gliche Preiskategorien einzusch\u00e4tzen.\n\nZur Kategorisierung sp\u00e4ter mehr im **Kapitel 3.1.3** .","2b151161":"### 3.2.2 Tage bis Bewertungsabgabe\n\nNun erfolgt die Untersucherung der Bewertung und der Differenz der Tage zwischen Lieferung und Erstellung der Bewertung.","791c4705":"### 2.6.3 Produktpreis\n\nAls n\u00e4chstes werfen wir einen Blick auf den Preis der Produkte. \n\nDie zu kl\u00e4rende Frage lautet: ** Hat der Preis eines Produktes Einfluss auf die Bewertung?**","fb82432e":"Um den Zusammenhang zwischen \"Gute_Bewertung\", \"Rechtzeitige_Lieferung\" und eine \"Schnellen_Bewertung\", sowie deren Randauspr\u00e4gungen zu untersuchen, erzeugen wir eine Korrelationsmatrix mit genau diesen Variablen.","01799fd0":"### 3.2.3 Schnelle Bewertung\n\nEs ist nun interessant herauszufinden, welche Auspr\u00e4gungen gerade die negativen Werte bei der Bewertung annehmen, da bei der Bewertung eigentlich nicht das Produkt bewertet wurde, sondern alle anderen Services (z.B. Online-Shop, Versand, Lieferung, Mitarbeiterfreundlichkeit, etc.). Deshalb erzeugen wir uns nun eine Variable, die zeigt, wie schnell eine Bewertung geschrieben wurde. In diese Variable nehmen wir auf, ob die Bewertungsabgabe am selben Tag der Lieferung oder bis zu drei Tage danach durchgef\u00fchrt wurde.","dadcb04b":"Anhand einer Logistischen Regression wird ein Modell gebaut, dass vorhersagen kann, ob eine Bestellung (order_id) eine gute Bewertung erhalten wird. \n\nWie in **Kapitel 3.3** bereits ermittelt, wurden bei den Variablen \"Schnelle_Bewertung\" und \"Rechtzeitige_Lieferung\" eine Korrelation zu der Variable \"Gute_Bewertung\" gefunden. \n\nF\u00fcr unser Modell m\u00fcssen wir abh\u00e4nige und unabh\u00e4nige Variablen bestimmen. Als abh\u00e4ngige Variable (y) wird die Variable definiert, die wir prognostizieren wollen, in unserem Fall \"Gute_Bewertung\".  Die unabh\u00e4nigen Variablen (X) sind Variablen die einen Einfluss auf die abh\u00e4nige Variable haben, in unserem Fall sind es die Variablen \"Rechzeitige_Lieferung\" und \"Schnelle_Bewertung\". \n\n**Definition der Variablen: **\n\n*Abh\u00e4ngige Variable (y):*\n* Gute Bewertung: 4 und 5 Sterne Bewertung\n\n*Unabh\u00e4ngige Variable (X):*\n* Rechtzeitige_Lieferung : Lieferung erfolgte am geplantem Datum oder fr\u00fchzeitig\n* Schnelle_Bewertung: Eine Bewertung erfolgt im Zeitraum zwischen dem geplanten Lieferdatum und innerhalb von 3 Tagen nach der Lieferung","d9f0af97":"Da ein sehr gro\u00dfer Bereich leer zu sein scheint, l\u00e4sst sich darauf schlie\u00dfen, dass es wenig Produkte gibt, die deutlich zusp\u00e4t oder deutlich zu fr\u00fch geliefert wurden (z.B. Tage bis Lieferung > 50 und < -25).\n\nDas wollen wir uns genauer angucken, um damit eine sinnvolle Skala f\u00fcr die X-Achse der ersten Visualisierung der Tage bis zur Lieferung zu ermitteln.","64b29f86":"## 2.2 Laden der Daten\n\nIm Folgenden werden die f\u00fcr unsere Zielsetzung relevanten Dateien geladen und in Datenframes gespeichert. Datasets werden in Kaggle h\u00e4ufig als CSV-Datei ver\u00f6ffentlicht. Durch das Speichern in einen Datenframe kann man flexibel \u00fcber bestimmte Aufrufe mit Python auf die Daten zugreifen oder sie ver\u00e4ndern.\n\nZun\u00e4chst m\u00fcssen die f\u00fcr das Projektziel relevanten Tabellen ausgew\u00e4hlt werden. F\u00fcr das genannte Prognoseziel sind folgende Tabellen relevant:\n* olist_products_dataset.csv\n* product_category_name_translation.csv\n* olist_order_items_dataset.csv\n* olist_orders_dataset.csv\n* olist_order_reviews_dataset.csv\n\nBeim Speichern der Datenframes ist es m\u00f6glich den Datentyp der Variable festzulegen, sofern dieser nicht automatisch erkannt wurde. Das Speichern der Variablen im richtigen Format erm\u00f6glich Berechnungen zwischen Variablen und das Anwenden von verschiedenen Funktionen (z.B. Korrelationsmatrix). Den Datentyp k\u00f6nnte man auch sp\u00e4ter noch anpassen, allerdings ist es eleganter und schneller das direkt beim Einlesen und Speichern der Variablen zu tun.","b4e97d31":"### 2.6.1 Produktbewertung\n\nDa das Hauptziel eine Vorhersage hinsichtlich der Produktbewertung ist, sehen wir uns zuerst die Verteilung der Bewertung an. \n\nDie zu kl\u00e4rende Frage lautet: **Wie haben die Kunden bewertet?**","18e6a4c7":"### 2.6.2 Produktbilder\n\nAls n\u00e4chstes werfen wir einen Blick auf die Anzahl der Produktbilder. \n\nDie zu kl\u00e4rende Frage lautet: **K\u00f6nnen mehr Produktbilder zu einer besseren Bewertung f\u00fchren?**","ee63443b":"Erkl\u00e4rung zur Tabelle 2.4.2:\n* \"count\" zeigt, wie viele Datens\u00e4tze der entsprechenden Variable des Datenframes Werte enthalten.\n* \"mean\" zeigt den Mittelwert pro Variable bezogen auf den gesamten Datenframe.\n* \"std\" zeigt die Standardabweichung, die misst, wie stark die Abweichung der numerischen Werte ist.\n* \"min\" zeigt den kleinsten Wert einer Variable aus dem gesamten Datenframe.\n* \"25%\" zeigt den Wert des unteren Quartils (0,25-Quantil), sprich 25% der Werte sind kleiner als der in der Tabelle stehende Wert f\u00fcr die entsprechende Variable.\n* \"50%\" zeigt den Median der ensprechenden Variable.\n* \"75%\" zeigt den Wert des oberen Quartils (0,75-Quantil), sprich 75% der Werte sind kleiner als der in der Tabelle stehende Wert f\u00fcr die entsprechende Variable.\n* \"max\" zeigt den gr\u00f6\u00dften Wert einer Variable aus dem gesamten Datenframe.","fff67a75":"Um sich die Verteilung genauer anzusehen, sollte die obere Grenzen des Graphen durch eine sinnvollere Obergrenze ersetzt werden. Hier nehmen wir den soeben als Obergrenze definierten Wert:","5548dbb8":"Der Tabelle ist zu entnehmen, dass ca. 56% der vorkommenden Werte einer Bewertung von 5 entspricht.\n\nDa \u00fcber 75% der Werte einer Bewertung von 4 oder 5 entsprechen liegt die Definition nahe, dass eine Bewertung von 4 oder 5 einer guten Bewertung entsprechen. Dazu sp\u00e4ter mehr im **Kapitel 3.1.1** .","50e24ebc":"## 1.3 Datenschema\n\nZum besseren Verst\u00e4ndnis und zur Organisation wurden die erfassten Daten in folgenden themenspezifischen Tabellen abgespeichert, die mit Hilfe der abgebildeten Prim\u00e4rschl\u00fcssel miteinander verbunden werden k\u00f6nnen:\n\n![Datenschema](https:\/\/i.imgur.com\/HRhd2Y0.png)\n","f9831247":"Da ein sehr gro\u00dfer Bereich leer zu sein scheint, l\u00e4sst sich darauf schlie\u00dfen, dass es wenig hochpreisige Produkte gibt (z.B. Preis > 2000).\n\nDas wollen wir uns genauer angucken, um damit eine sinnvolle Skala f\u00fcr die X-Achse der ersten Visualisierung des Produktpreises zu ermitteln.","bbbeb58a":"Da der oben stehende Aufruf zwar die Gleitkommawerte in Integerwerte konvertiert, allerdings die fehlenden Werte falsch abspeichert, zerst\u00f6rt er Teile der Analyse von \"product_photos_qty\". Aufgrund zeitlicher Knappheit k\u00f6nnen wir den Datentyp von \"product_photos_qty\" erst mal so lassen. \nEDIT: Die Korrelation in Kapitel 3.3 zeigt, dass die Varibale \"product_photos_qty\" keinen gro\u00dfen Einfluss auf unsere Zielvariable \"Gute_Bewertung\" hat. Weshalb die \u00c4nderung des Datentyps hinf\u00e4llig wird.","cbe4656f":"Nach dem erstellen und trainieren des Modells, wollen wir wissen, wie gut das Modell arbeitet. \n\n**Accuracy\/ Score-Aufruf**: Mit dem **score**-Aufruf, versuchen wir die Testdaten (X_test, y_test; Daten kennt das Modell bisher nicht) vorherzusagen und lassen uns die Genauigkeit (d.h. das Vorhergesagte entspricht dem tats\u00e4chlichem Wert ausgeben). Mit fast 80% kann das Modell eine gute Bewertung vorhersagen.\n\n**Log Loss**: Ber\u00fccktsichtigt hingegen die Ungewissheit der Vorhersage, je nachdem, wie stark sich der vorhergesagte Wert von dem tats\u00e4chlichem Wert unterscheidet (Quelle: [hier](http:\/\/wiki.fast.ai\/index.php\/Log_Loss)\nWenn der tats\u00e4chliche Wert eine 0 ist, das Modell es jedoch in die Klasse 1 hinzuf\u00fcgt, da die Wahrscheinlichkeit 0,51 ist, dann wurde es falsch klassifiziert. Diese Berechnung wird f\u00fcr jeden Wert ermittelt und der Mittelwert wird zum Schluss ausgegeben. \nEin perfektes Modell hat einen Log Loss von 0. Mit einem Wert von knapp 50%, ist unser Modell mittelm\u00e4\u00dfig. \n\nDie beiden Werte geben nur einen groben Richtwert. Im n\u00e4chsten Kapitel wollen wir unser Modell aber weiter unter die Lupe nehmen. ","e896ca1d":"### 2.3.1 Tabellen verkn\u00fcpfen\n\u00dcber den merge-Funktion von Python k\u00f6nnen Dataframes \u00fcber einen Schl\u00fcssel vereint werden, \u00e4hnlich einem SQL-Aufruf. Wir haben uns dazu entschlossen einen LEFT-JOIN durchzuf\u00fchren, damit alle Datens\u00e4tze inkl. fehlender Werte geladen werden.","256e39a5":"Die Tabelle von 3.1.1 zeigt, dass ca. 75% der Bewertungen in die Kategorie \"Gute_Bewertung\" fallen, sprich die Produkte eine Bewertung von 4 oder 5 erhalten haben.","434479b1":"### 2.3.2 Datentypen \u00fcberpr\u00fcfen\nAnschlie\u00dfend sollte man sich angucken, ob alle Variablen das richtige Format haben und ggf. Anpassungen vornehmen.","89fe8db9":"Um genauere Analysen durchzuf\u00fchren muss das Produktgewicht weiter kategorisiert werden und somit weitere Variablen eingef\u00fchrt werden. \n\nZur Kategorisierung sp\u00e4ter mehr im **Kapitel 3.1.4** ."}}