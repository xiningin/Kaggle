{"cell_type":{"39e4f4b6":"code","e009af80":"code","c218d79e":"code","c7af407c":"code","a38b0d96":"code","7900a62a":"code","830cd575":"code","9b0eff4e":"code","7cc19a10":"code","1bf12aa8":"code","b4873c7b":"code","4ea607bd":"code","0ef3c2d1":"code","832d7c34":"code","d03f566c":"code","35bb6541":"code","4bac779d":"code","27156a4d":"markdown","6c3638cf":"markdown","f73479df":"markdown","93788ad9":"markdown","19f9f8db":"markdown","6a2c4c24":"markdown","c4cd7b3c":"markdown","2fab94e0":"markdown","61acd890":"markdown","7a770e7c":"markdown","75052199":"markdown"},"source":{"39e4f4b6":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt","e009af80":"from torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import transforms\n\nimage_size = 64\nbatch_size = 240\nstats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\ntrain_data = ImageFolder('..\/input\/animefacedataset\/',transform=transforms.Compose([\n    transforms.Resize(image_size),\n    transforms.CenterCrop(image_size),\n    transforms.ToTensor(),\n    transforms.Normalize(*stats)   \n]))\ntrain_data = DataLoader(train_data, batch_size, shuffle=True, num_workers=3, pin_memory=True)\n# pin_memory: Host to GPU copies are much faster when they originate from pinned (page-locked) memory\nprint('Total batches:',len(train_data))","c218d79e":"from torchvision.utils import make_grid\n\ndef denorm(img_batch):\n    return img_batch * stats[1][0] + stats[0][0]\n    # Rescale the normalised images to (0,1)\n    \ndef images_preview(images):\n    fig, ax = plt.subplots(figsize=(14, 14))\n    ax.axis('off')\n    ax.imshow(make_grid(denorm(images.cpu().detach()[:56]), nrow=8).permute(1, 2, 0))\n\ndef batch_preview(data):\n    for images, _ in data:\n        images_preview(images)\n        break\n        \nos.makedirs('generated_faces', exist_ok=True)        \nbatch_preview(train_data)","c7af407c":"import torch\n\ndef get_device():\n    # Pick GPU if available, else CPU\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    # Move to given device\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    # Wrap a dataloader to move data to a device\n    def __init__(self, data, device):\n        self.data = data\n        self.device = device\n        \n    def __iter__(self):\n        # Yield a batch of data after moving it to device\n        for b in self.data: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        # Number of batches\n        return len(self.data)","a38b0d96":"device = get_device()\ndevice","7900a62a":"train_data = DeviceDataLoader(train_data,device)","830cd575":"import torch.nn as nn\n\ndiscriminator = nn.Sequential(\n    nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(64),\n    nn.LeakyReLU(0.2, inplace=True),\n    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(0.2, inplace=True),\n    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(256),\n    nn.LeakyReLU(0.2, inplace=True),\n    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(512),\n    nn.LeakyReLU(0.2, inplace=True),\n    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n    nn.Flatten(),\n    nn.Sigmoid())","9b0eff4e":"discriminator = to_device(discriminator, device)\n# moving to appropriate device","7cc19a10":"noise_size = 128\ngenerator = nn.Sequential(\n    nn.ConvTranspose2d(noise_size, 512, kernel_size=4, stride=1, padding=0, bias=False),\n    nn.BatchNorm2d(512),\n    nn.ReLU(True),\n    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(256),\n    nn.ReLU(True),\n    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(128),\n    nn.ReLU(True),\n    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.BatchNorm2d(64),\n    nn.ReLU(True),\n    nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n    nn.Tanh()\n)","1bf12aa8":"generator = to_device(generator, device)","b4873c7b":"from torch.nn.functional import binary_cross_entropy\n\ndef train_disc(real_image_batch, disc_opt):\n    disc_opt.zero_grad()\n    real_pred = discriminator(real_image_batch)\n    real_target = torch.ones(real_image_batch.size(0), 1, device=device)\n    real_loss = binary_cross_entropy(real_pred, real_target)\n    real_score = torch.mean(real_pred).item()\n    noise = torch.randn(batch_size, noise_size, 1, 1, device=device)\n    fake_image_batch = generator(noise)\n    fake_target = torch.zeros(fake_image_batch.size(0), 1, device=device)\n    fake_pred = discriminator(fake_image_batch)\n    fake_loss = binary_cross_entropy(fake_pred, fake_target)\n    fake_score = torch.mean(fake_pred).item()\n    disc_loss = real_loss + fake_loss\n    disc_loss.backward()\n    disc_opt.step()\n    return disc_loss.item(), real_score, fake_score    ","4ea607bd":"def train_gen(gen_opt):\n    gen_opt.zero_grad()\n    noise = torch.randn(batch_size, noise_size, 1, 1, device=device)\n    fake_image_batch = generator(noise)\n    pred = discriminator(fake_image_batch)\n    target = torch.ones(batch_size, 1, device=device)\n    gen_loss = binary_cross_entropy(pred, target)\n    gen_loss.backward()\n    gen_opt.step()\n    return gen_loss.item()","0ef3c2d1":"fixed_noise = torch.randn(56, noise_size, 1, 1, device=device)","832d7c34":"from torchvision.utils import save_image\n\ndef save_images(epoch,noise):\n    fake_image_batch = generator(noise)\n    fake_image_batch = denorm(fake_image_batch)\n    save_image(fake_image_batch,os.path.join('generated_faces','face_{}.png'.format(epoch)),nrow=8)\n    if epoch % 4 == 0 :\n        fig, ax = plt.subplots(figsize=(14, 14))\n        ax.axis('off')\n        ax.imshow(make_grid(fake_image_batch.cpu().detach(), nrow=8).permute(1, 2, 0))","d03f566c":"from tqdm.notebook import tqdm\n\ndef train(epochs, lr,):\n    torch.cuda.empty_cache()\n    disc_opt = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n    gen_opt = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n    for epoch in range(epochs):\n        for real_image_batch, _ in tqdm(train_data):\n            disc_loss, real_acc, fake_acc = train_disc(real_image_batch, disc_opt)\n            gen_loss = train_gen(gen_opt)\n        print(\"Epoch:{}\/{}, gen_loss: {:.2f}, disc_loss:{:.2f}, real_acc:{:.2f}, fake_acc:{:.2f}\".format(epoch+1, epochs, gen_loss, disc_loss, real_acc, fake_acc))\n        save_images(epoch+1, fixed_noise)    ","35bb6541":"lr = 0.0002\nepochs = 72","4bac779d":"train(epochs, lr)","27156a4d":"### Discriminator","6c3638cf":"## Helper Functions","f73479df":"## Save Images","93788ad9":"### Functions for using gpu ","19f9f8db":"### Generator","6a2c4c24":"## Full Training","c4cd7b3c":"### Discriminator","2fab94e0":"### Generator","61acd890":"## Read Images","7a770e7c":"## Training Step","75052199":"## Model"}}