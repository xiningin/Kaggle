{"cell_type":{"b9eb17f6":"code","c4fdaf22":"code","20aaebc9":"code","845485cf":"code","ccb96a04":"code","1431c1cb":"code","8e5092a7":"code","b22b24b1":"code","87e5d5ab":"code","67953d25":"code","5d672bcd":"code","d9b30772":"code","4e44475f":"code","74f1d5ff":"code","e449902b":"code","891a7b15":"code","d5b35e78":"markdown","ca5e5ea0":"markdown","f8aeffab":"markdown","2d931dfb":"markdown","54a21b4f":"markdown","9f7e7d65":"markdown","9654455a":"markdown","5881360e":"markdown","fc05d995":"markdown","b31966bd":"markdown","66a2bb37":"markdown"},"source":{"b9eb17f6":"# Libraries import\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\nfrom keras.models import Sequential\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\ntf.set_random_seed(42)","c4fdaf22":"# Settings\ntrain_path = os.path.join('..', 'input', 'train.csv')\ntest_path = os.path.join('..', 'input', 'test.csv')\n\n# CNN model settings\nsize = 28\nlr = 0.001\nnum_classes = 10\n\n# Training settings\nepochs = 30\nbatch_size = 128","20aaebc9":"# data loading\nraw_train_df = pd.read_csv(train_path)\nraw_test_df = pd.read_csv(test_path)","845485cf":"# Utils\ndef parse_train_df(_train_df):\n    labels = _train_df.iloc[:,0].values\n    imgs = _train_df.iloc[:,1:].values\n    imgs_2d = np.array([[[[float(imgs[index][i*28 + j]) \/ 255] for j in range(28)] for i in range(28)] for index in range(len(imgs))])\n    processed_labels = [[0 for _ in range(10)] for i in range(len(labels))]\n    for i in range(len(labels)):\n        processed_labels[i][labels[i]] = 1\n    return np.array(processed_labels), imgs_2d\n\ndef parse_test_df(test_df):\n    imgs = test_df.iloc[:, 0:].values\n    imgs_2d = np.array([[[[float(imgs[index][i * 28 + j]) \/ 255] for j in range(28)] for i in range(28)] for index in\n                        range(len(imgs))])\n    return imgs_2d","ccb96a04":"# Data preprocessing\ny_train_set, x_train_set = parse_train_df(raw_train_df)\nx_test = parse_test_df(raw_test_df)\n\nx_train, x_val, y_train, y_val = train_test_split(x_train_set, y_train_set, test_size=0.20, random_state=42)","1431c1cb":"# Training data insights\nraw_train_df['label'].value_counts().plot.bar()","8e5092a7":"print(\"Number of 1: {}\".format(len(raw_train_df[raw_train_df['label'] == 1])))\nprint(\"Number of 5: {}\".format(len(raw_train_df[raw_train_df['label'] == 5])))","b22b24b1":"# Image visualization\nn = 5\nfig, axs = plt.subplots(nrows=n, ncols=n, sharex=True, sharey=True, figsize=(12, 12))\nfor i in range(n**2):\n    ax = axs[i \/\/ n, i % n]\n    (-x_train[i]+1)\/2\n    ax.imshow((-x_train[i, :, :, 0] + 1)\/2, cmap=plt.cm.gray)\n    ax.axis('off')\nplt.tight_layout()\nplt.show()","87e5d5ab":"# CNN model\nmodel = keras.Sequential()\n\nmodel.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1),\n                 activation='relu',\n                 input_shape=(size, size, 1)))\nmodel.add(Conv2D(32, (3, 3), activation='relu', strides=(2, 2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu', strides=(2, 2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=Adam(lr),\n              metrics=['accuracy'])\n\ncheckpoint = ModelCheckpoint('model_ckpt.{epoch:02d}.hdf5',\n                                             save_best_only=True,\n                                             save_weights_only=True)\nlr_reducer = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=3,\n                      mode='max', cooldown=3, verbose=1)\ncallback_list = [checkpoint, lr_reducer]","67953d25":"# Training\ntraining_history = model.fit(\n    x_train,\n    y_train,\n    epochs=epochs,\n    verbose=1,\n    validation_data=(x_val, y_val),\n    callbacks=callback_list\n)","5d672bcd":"# Training recap\nepoch_range = [e for e in range(1, epochs + 1)]\nfig, axs = plt.subplots(nrows=1, ncols=2, figsize=(24, 4))\n\naxs[0].plot(epoch_range,\n         training_history.history['loss'],\n         training_history.history['val_loss'],\n)\naxs[0].set_title('Training loss')\naxs[1].plot(epoch_range,\n         training_history.history['acc'],\n         training_history.history['val_acc'],\n)\naxs[1].set_title('Training accuracy')\n\nplt.show()","d9b30772":"# Creating image generator\nimage_generator = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.1\n)\n\nimage_generator.fit(x_train)","4e44475f":"# Retraining the same model\nmodel_augmented = keras.Sequential()\n\nmodel_augmented.add(Conv2D(32, kernel_size=(3, 3), strides=(1, 1),\n                 activation='relu',\n                 input_shape=(size, size, 1)))\nmodel_augmented.add(Conv2D(32, (3, 3), activation='relu', strides=(2, 2)))\nmodel_augmented.add(BatchNormalization())\nmodel_augmented.add(Dropout(0.3))\n\nmodel_augmented.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_augmented.add(Conv2D(64, (3, 3), activation='relu', strides=(2, 2)))\nmodel_augmented.add(BatchNormalization())\nmodel_augmented.add(Dropout(0.3))\nmodel_augmented.add(Conv2D(128, (3, 3), activation='relu'))\nmodel_augmented.add(BatchNormalization())\n\nmodel_augmented.add(Flatten())\nmodel_augmented.add(Dense(256, activation='relu'))\nmodel_augmented.add(Dropout(0.25))\nmodel_augmented.add(Dense(128, activation='relu'))\nmodel_augmented.add(Dense(num_classes, activation='softmax'))\n\nmodel_augmented.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=RMSprop(0.001),\n              metrics=['accuracy'])\n\naug_result = model_augmented.fit_generator(\n    image_generator.flow(x_train, y_train, batch_size=batch_size),\n    epochs=epochs,\n    steps_per_epoch=len(x_train) \/\/ batch_size,\n    verbose=1,\n    validation_data=(x_val, y_val),\n    callbacks=callback_list\n)\n\nmodel_augmented.save('mnist_model.h5')","74f1d5ff":"# Training recap of your augmented dataset\nepoch_range = [e for e in range(1, epochs + 1)]\nplt.plot(epoch_range,\n         aug_result.history['acc'],\n         aug_result.history['val_acc'],\n)\nplt.title('Accuracy')\nplt.show()","e449902b":"# Prediction\npred = model.predict(x_test)\npred_aug = model_augmented.predict(x_test)","891a7b15":"# Submission creation\ndef convert_prediction_result(model_result):\n    result = []\n    for i in range(len(model_result)):\n        result += [np.argmax(model_result[i])]\n    return result\n\n\ndef write_submission(_submission_path, result_arr):\n    f_out = open(_submission_path, 'w')\n    f_out.write(\"ImageId,Label\\n\")\n    for i in range(len(result_arr)):\n        f_out.write(\"{},{}\\n\".format(i+1, result_arr[i]))\n    f_out.close()\n\nwrite_submission('submission_base.csv', convert_prediction_result(pred))\nwrite_submission('submission_aug.csv', convert_prediction_result(pred))","d5b35e78":"In the next two cells, I will load the data and process it from an array of 784 pixels values to an 2D 28*28 matrix, to be able to work on images. This will let me use a CNN later.","ca5e5ea0":"# MNIST : from data visualization to submission\nThe purpose of this kernel is to take the MNIST dataset, to visualize it to then train a small CNN and output a submission.\n* Data insights\n* Model definition\n* Data augmentation\n* Submission","f8aeffab":"The validation accuracy does not drop or remain still while the accuracy on the training set continue to rise. Moreover, the gap between them is relatively small. We cannot say that the model overfitted.","2d931dfb":"The biggest class is *1* with about 4500 samples in our training data. The smallest one is *5* with about 3800 samples.","54a21b4f":"These small CNN manage to achieve 0.9877 on the MNIST dataset. \n\nFeel free to use this notebook as a starting point. And feel free to upvote :)","9f7e7d65":"Let's look at some graphs to see if the training phase went well.","9654455a":"## Data augmentation\nI will now use the ImageDataGenerator to increase the number of samples of the training dataset. This Keras class will take the training images in input and will output new images, produced from the input images by zooming a bit in them, by rotating them in a certain range, by shifting them a bit, ...\n\nI will only use the zoom, the rotation and the shift transformation as a written digit could be a bit bigger or smaller, a bit rotated or a bit shifted in the image. I want to create image that have a meaning for this dataset. For instance, I won't use the horizontal or the vertical flip transformation as a number upside down isn't a number anymore.\n\nThe training phase is the same than we our previous model.","5881360e":"## Submission\nHere, I will create two submission files, one with the raw dataset and one with the augmented one. These files will be created once the notebook forked and commited. To create these submission, I just read the test csv file and use the two models to predict the written digits on it.","fc05d995":"## Data insights\n\nHere, we will look a bit into the training dataset. It's important to know with which kind of data we are playing with.\n\nFirst, let's check that we have the same number of samples for each one of our classes. If not, it will be harder to train an unbiased classifier.","b31966bd":"Now, we have the right numbers !! This should be ok to train a classifier with these proportions. I just wanted to check that the dataset doesn't have one big class with ten times more samples than the other ones. (or one with ten times less samples). I will continue this notebook with the raw dataset as it should be fine.\n\nLet's look at some images, just to see with what we are dealing.","66a2bb37":"## Model definition\nHere, I will define and train a first CNN model. I decided to use 4 Conv2D layers and 2 Denses ones (before the output layer) because of what I have seen on the internet. It works fine, but it is suremy not the best solution. "}}