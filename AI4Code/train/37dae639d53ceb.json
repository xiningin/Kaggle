{"cell_type":{"435336af":"code","7a05a295":"code","d5145d6c":"code","f9544bec":"code","4cfaf70f":"code","6e96928c":"code","2b8785d2":"code","6a5d5bf9":"code","abe5594d":"code","51193581":"code","edcc567a":"code","c3f58426":"code","18ba1afb":"code","cdb50d05":"code","544a54ef":"code","de204dc1":"code","d1c4365b":"code","4b1e0883":"code","a3713090":"code","7e802170":"code","6c93f6d0":"code","91aaeedc":"code","98d2a4a3":"code","7fd3aa8c":"code","94cd5723":"code","bf408f4b":"code","180656dc":"code","35d77b4d":"code","444bffec":"code","07f8ccae":"code","6657afd6":"code","d856fffe":"code","69d1e94c":"markdown","38811ce2":"markdown","f13c5e37":"markdown","0bf35eb2":"markdown"},"source":{"435336af":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7a05a295":"irishtimes_data = pd.read_csv('..\/input\/ireland-historical-news\/irishtimes-date-text.csv')\nirishtimes_data.shape","d5145d6c":"irishtimes_data.head(10)","f9544bec":"irishtimes_data.dtypes","4cfaf70f":"irishtimes_data.headline_category = irishtimes_data.headline_category.astype('category')","6e96928c":"irishtimes_data.headline_category.cat.categories","2b8785d2":"# Remove blank rows if any\nirishtimes_data.headline_text.dropna(inplace=True)\n# Change all the text to lower case\nirishtimes_data.headline_text = [entry.lower() for entry in irishtimes_data.headline_text]\n# Replace punctuation symbols by space\nimport re\nPUNCTUATIONS = re.compile('[\/(){}\\[\\]\\|@,;\\']')\nirishtimes_data.headline_text = [PUNCTUATIONS.sub('', entry) for entry in irishtimes_data.headline_text]","6a5d5bf9":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(irishtimes_data.headline_text, irishtimes_data.headline_category, test_size=0.2, random_state=1)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","abe5594d":"import nltk\nfrom sklearn.feature_extraction.text import CountVectorizer\n#nltk.download()\nfrom nltk.stem.snowball import SnowballStemmer\nstemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n\nclass StemmedCountVectorizer(CountVectorizer):\n    def build_analyzer(self):\n        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])","51193581":"#count_vect = CountVectorizer(stop_words='english')\ncount_vect = StemmedCountVectorizer(stop_words='english')\ncount_vect.fit(X_train)\nX_train_counts = count_vect.transform(X_train)\nX_train_counts.shape","edcc567a":"from sklearn.feature_extraction.text import TfidfTransformer\ntfidf_transformer = TfidfTransformer()\nX_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\nX_train_tfidf.shape","c3f58426":"from sklearn.naive_bayes import MultinomialNB\nnb = MultinomialNB().fit(X_train_tfidf, y_train)","18ba1afb":"X_test_counts = count_vect.transform(X_test)\nX_test_counts.shape","cdb50d05":"tfidf_transformer = TfidfTransformer()\nX_test_tfidf = tfidf_transformer.fit_transform(X_test_counts)\nX_test_tfidf.shape","544a54ef":"predicted = nb.predict(X_train_tfidf)\nnp.mean(predicted == y_train)","de204dc1":"predicted = nb.predict(X_test_tfidf)\nfrom sklearn import metrics\nmetrics.accuracy_score(y_test, predicted)","d1c4365b":"w3_latnigrin_data = pd.read_csv('..\/input\/ireland-historical-news\/w3-latnigrin-text.csv')\n#count_vect = CountVectorizer(vocabulary=count_vect.vocabulary)\nX_new_data_counts = count_vect.transform(w3_latnigrin_data.headline_text)\nX_new_data_counts.shape","4b1e0883":"tfidf_transformer = TfidfTransformer()\nX_new_data_tfidf = tfidf_transformer.fit_transform(X_new_data_counts)\nX_new_data_tfidf.shape","a3713090":"predicted = nb.predict(X_new_data_tfidf)","7e802170":"w3_latnigrin_data['headline_category_NB'] = predicted\nw3_latnigrin_data.head()","6c93f6d0":"from sklearn.linear_model import SGDClassifier\nsvm = SGDClassifier(loss='hinge',\n    penalty='l2',\n    alpha=0.0001,\n    l1_ratio=0.15,\n    fit_intercept=True,\n    max_iter=1000,\n    tol=0.001,\n    shuffle=True,\n    verbose=0,\n    epsilon=0.1,\n    n_jobs=None,\n    random_state=7,\n    learning_rate='optimal',\n    eta0=0.0,\n    power_t=0.5,\n    early_stopping=False,\n    validation_fraction=0.1,\n    n_iter_no_change=5,\n    class_weight=None,\n    warm_start=False,\n    average=False,).fit(X_train_tfidf, y_train)","91aaeedc":"predicted = svm.predict(X_train_tfidf)\nnp.mean(predicted == y_train)","98d2a4a3":"predicted = svm.predict(X_test_tfidf)\nmetrics.accuracy_score(y_test, predicted)","7fd3aa8c":"predicted = svm.predict(X_new_data_tfidf)\nw3_latnigrin_data['headline_category_SVM'] = predicted\nw3_latnigrin_data.head()","94cd5723":"from keras.preprocessing.text import Tokenizer\n# The maximum number of words to be used. (most frequent)\nMAX_NB_WORDS = 50000\n# Max number of words in each text.\nMAX_SEQUENCE_LENGTH = 250\n# This is fixed.\nEMBEDDING_DIM = 100\n\ntokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-.\/:;<=>?@[\\]^_`{|}~', lower=True)\ntokenizer.fit_on_texts(irishtimes_data.headline_text)\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))","bf408f4b":"from tflearn.data_utils import pad_sequences\nX = tokenizer.texts_to_sequences(irishtimes_data.headline_text)\nX = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\nprint('Shape of data tensor:', X.shape)","180656dc":"Y = pd.get_dummies(irishtimes_data.headline_category).values\nprint('Shape of label tensor:', Y.shape)","35d77b4d":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\nprint(X_train.shape,Y_train.shape)\nprint(X_test.shape,Y_test.shape)","444bffec":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Embedding\nfrom keras.layers import SpatialDropout1D\nfrom keras.layers import LSTM\nfrom keras.callbacks import EarlyStopping\n\nmodel = Sequential()\nmodel.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(156, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nepochs = 1\nbatch_size = 64\n\nhistory = model.fit(X_train, Y_train, \n                    epochs=epochs, \n                    batch_size=batch_size,\n                    validation_split=0.1,\n                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)]\n                   )","07f8ccae":"accr = model.evaluate(X_test,Y_test)\nprint('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))","6657afd6":"seq = tokenizer.texts_to_sequences(w3_latnigrin_data.headline_text)\npadded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)\npred = model.predict(padded)\n\nlabels = irishtimes_data.headline_category.cat.categories\nprint(pred, labels[np.argmax(pred)])","d856fffe":"w3_latnigrin_data['headline_category_LSTM'] = labels[np.argmax(pred)]\nw3_latnigrin_data.head()","69d1e94c":"New Data","38811ce2":"SVM","f13c5e37":"Naive Bayes","0bf35eb2":"LSTM"}}