{"cell_type":{"305375da":"code","7947b7ed":"code","f70a2dd2":"code","5cdb084b":"code","19526e74":"code","b4ed2709":"code","a51ef79f":"code","d332fc56":"code","3c419cd7":"code","7c0793a6":"code","a585fb59":"code","1ada05a0":"code","e4a9305f":"code","27707c90":"code","680193d9":"code","4bf10d18":"code","15ada7fd":"markdown","a9a68767":"markdown","24f0495b":"markdown","da677d43":"markdown","d5ed0c66":"markdown","114ca4b6":"markdown"},"source":{"305375da":"import os\nimport random\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader","7947b7ed":"SEED = 22\nBATCH_SIZE = 2000\nEPOCHS = 10\nuse_cuda = False","f70a2dd2":"np.random.seed(SEED)\ntorch.manual_seed(SEED)\nrandom.seed(SEED)\nos.environ[\"PYTHONHASHSEED\"] = str(SEED)","5cdb084b":"train = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/test.csv')\nsub = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')","19526e74":"features = ['f'+str(i) for i in range(100)]\n\ntrain_agg = train[features].agg(['max', 'min', 'mean', 'median']).transpose()\ntest_agg = test[features].agg(['max', 'min', 'mean', 'median']).transpose()\n\ntrain_agg.plot(figsize=(30,10), grid=True, title='TRAIN DATA')\nplt.show()\n\ntest_agg.plot(figsize=(30,10), grid=True, title='TEST DATA')\nplt.show()","b4ed2709":"# and without outliers\n\ntrain_agg[train_agg[\"max\"] < 100].plot(figsize=(30,10), grid=True, title='TRAIN DATA')\nplt.show()\n\ntest_agg[test_agg[\"max\"] < 100].plot(figsize=(30,10), grid=True, title='TEST DATA')\nplt.show()","a51ef79f":"def preprocess_data(data, batch_size, num_workers=0, train=True):\n    \n    if train:\n        \n        val, train = data[:80000], data[80000:]\n        \n        train_target = torch.Tensor(train['target'].values)\n        train_features = torch.Tensor(train.drop(['id', 'target'], axis=1).values)\n        \n        val_target = torch.Tensor(val['target'].values)\n        val_features = torch.Tensor(val.drop(['id', 'target'], axis=1).values)\n\n        train_loader = DataLoader(\n            TensorDataset(train_features,train_target), \n            shuffle=True, \n            batch_size=batch_size,\n            num_workers=num_workers\n        )\n        val_loader = DataLoader(\n            TensorDataset(val_features,val_target), \n            shuffle=True, \n            batch_size=batch_size,\n            num_workers=num_workers\n        )\n        \n        return train_loader, val_loader\n        \n    test_features = torch.Tensor(data.drop(['id'], axis=1).values)\n    \n    test_loader = DataLoader(\n        TensorDataset(test_features), \n        shuffle=False, \n        batch_size=batch_size,\n        num_workers=num_workers\n    )\n    \n    return test_loader","d332fc56":"train_loader, val_loader = preprocess_data(train, BATCH_SIZE, 0, True)\ntest_loader = preprocess_data(test, BATCH_SIZE, 0, False)\n\nloaders = {\n    'train': train_loader, \n    'valid': val_loader, \n    'test': test_loader\n}","3c419cd7":"criterion = nn.BCELoss()\n\ndef get_optimizer_scratch(model):\n    return optim.Adam(model.parameters(), lr = 0.0015)\n\nclass EpicNet(nn.Module):\n    def __init__(self):\n        super(EpicNet, self).__init__()\n        self.l1  = nn.Linear(100, 256)\n        self.l2  = nn.Linear(256, 64)\n        self.l3  = nn.Linear(64, 16)\n        self.l4  = nn.Linear(16, 1)\n        self.dropout = nn.Dropout(p=0.2)\n        self.batch_norm2 = nn.BatchNorm1d(64)\n        self.batch_norm3 = nn.BatchNorm1d(16)\n\n    def forward(self, x):\n        x = self.l1(x)\n        x = self.dropout(x)\n        x = F.relu(self.l2(x))\n        x = self.dropout(x)\n        x = self.batch_norm2(x)\n        x = F.relu(self.l3(x))\n        x = self.dropout(x)\n        x = self.batch_norm3(x)\n        x = F.sigmoid(self.l4(x))\n\n        return x\n\nmodel = EpicNet()\nprint(model)","7c0793a6":"def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n    \"\"\"returns trained model\"\"\"\n    valid_loss_min = np.Inf \n    \n    for epoch in range(1, n_epochs+1):\n\n        train_loss = 0.0\n        valid_loss = 0.0\n        \n        model.train()\n        for batch_idx, (data, target) in enumerate(loaders['train']):\n\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target.unsqueeze(1))\n            loss.backward()\n            optimizer.step()\n            train_loss += ((1\/(batch_idx+1))*(loss.data.item()-train_loss))\n\n        model.eval()\n        for batch_idx, (data, target) in enumerate(loaders['valid']):\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n\n            with torch.no_grad():\n                output = model(data)\n                loss = criterion(output, target.unsqueeze(1))\n                valid_loss += ((1\/(1+batch_idx+1))*(loss.data.item()-valid_loss))\n\n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n            epoch, \n            train_loss,\n            valid_loss\n            ))\n\n        if valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min, valid_loss))\n            torch.save(model.state_dict(), save_path)\n            valid_loss_min = valid_loss\n        \n    return model","a585fb59":"def custom_weight_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Linear') != -1:\n        n = m.in_features\n        y = 1.0\/np.sqrt(n)\n        m.weight.data.uniform_(-y,y)\n        m.bias.data.fill_(0)\n    \nmodel.apply(custom_weight_init)\nmodel = train(EPOCHS, loaders, model, get_optimizer_scratch(model), criterion, use_cuda, 'model_0.pt')","1ada05a0":"# upload final model\nmodel.load_state_dict(torch.load('model_0.pt'))","e4a9305f":"out = []\nmodel.eval()\n\nfor batch_idx, data in enumerate(loaders['test']):\n    out += model(data[0]).view(-1).tolist()","27707c90":"predicts = pd.Series(out, name='target')","680193d9":"predicts","4bf10d18":"sub.drop(['target'], axis=1).join(predicts).to_csv('submission.csv', index=False)","15ada7fd":"### Train","a9a68767":"### Basics","24f0495b":"Looks like absolutely the same data distributions\n\n### Prepare Dataloaders","da677d43":"### Slightly EDA","d5ed0c66":"### Model","114ca4b6":"### Predict"}}