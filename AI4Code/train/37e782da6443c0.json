{"cell_type":{"420fc542":"code","cbbad0e6":"code","e61e8c2b":"code","b6115a2f":"code","a8517755":"code","0635db6e":"code","745afd5d":"code","2b834919":"code","fc05b16e":"code","ee71c4c5":"code","da5280b2":"code","b584c800":"markdown"},"source":{"420fc542":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cbbad0e6":"!pip install pyspark","e61e8c2b":"from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName(\"sample_app\").getOrCreate()\ndf = spark.read.load(\"..\/input\/bank-dataset\/bank.csv\",format=\"csv\",inferSchema= True,header=True,sep=\";\")\ndf = df.withColumnRenamed(\"y\",\"deposit\")\ndf.printSchema()","b6115a2f":"numeric_features = [t[0] for t in df.dtypes if t[1] == 'int']\ndf.select(numeric_features).describe().toPandas().transpose()","a8517755":"numeric_data = df.select(numeric_features).toPandas()\naxs = pd.plotting.scatter_matrix(numeric_data, figsize=(8, 8));\nn = len(numeric_data.columns)\nfor i in range(n):\n    v = axs[i, 0]\n    v.yaxis.label.set_rotation(0)\n    v.yaxis.label.set_ha('right')\n    v.set_yticks(())\n    h = axs[n-1, i]\n    h.xaxis.label.set_rotation(90)\n    h.set_xticks(())","0635db6e":"df = df.select('age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'deposit')\ncols = df.columns\ndf.printSchema()","745afd5d":"from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\ncategoricalColumns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\nstages = []\nfor categoricalCol in categoricalColumns:\n    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n    stages += [stringIndexer, encoder]\nlabel_stringIdx = StringIndexer(inputCol = 'deposit', outputCol = 'label')\nstages += [label_stringIdx]\nnumericCols = ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\nassemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\nstages += [assembler]","2b834919":"from pyspark.ml import Pipeline\npipeline = Pipeline(stages = stages)\npipelineModel = pipeline.fit(df)\ndf = pipelineModel.transform(df)\nselectedCols = ['label', 'features'] + cols\ndf = df.select(selectedCols)\ndf.printSchema()","fc05b16e":"train, test = df.randomSplit([0.7, 0.3], seed = 2018)\nprint(\"Training Dataset Count: \" + str(train.count()))\nprint(\"Test Dataset Count: \" + str(test.count()))","ee71c4c5":"from pyspark.ml.classification import RandomForestClassifier\n\nrf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label' )\nrfModel = rf.fit(train)\npredictions_rf = rfModel.transform(test)\npredictions_rf.select('age', 'job', 'label', 'rawPrediction', 'prediction', 'probability').toPandas()\n","da5280b2":"from pyspark.ml.evaluation import BinaryClassificationEvaluator\neval = BinaryClassificationEvaluator()\neval.evaluate(predictions_rf,{eval.metricName: 'areaUnderROC'})","b584c800":"# Random Forest Classifier"}}