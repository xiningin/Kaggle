{"cell_type":{"65ecc9c4":"code","17f92846":"code","4753f928":"code","1495e4de":"code","a05cc39a":"code","b74895f8":"code","f3d26545":"code","a95b1265":"code","6a33d7f0":"code","225c9553":"code","eaedd80f":"code","8d369232":"code","ee3754b0":"code","fa3496df":"code","4d0d45cb":"code","67209f85":"code","8d33300a":"code","bb25d089":"code","e16e0b61":"code","f04782c7":"code","48522403":"code","4fe84482":"code","8450a2b3":"code","3d2d0341":"code","b83ed1b1":"code","0631502e":"code","9e1b0cbf":"code","ff59b68d":"code","c9549cdc":"code","04478aa9":"code","e7959186":"code","19301a56":"code","5150491f":"code","c58524e1":"code","63f7019c":"code","ea7f439a":"code","f2d62c54":"code","eb1e7414":"code","f49597e4":"code","e96e2d67":"code","ce340c29":"code","fdf1c63f":"code","8e950a5f":"code","71e9cf22":"code","6c80f945":"code","e9f06193":"code","7f5f0c0c":"code","221f15e2":"code","b9ba9699":"code","4c69c7ea":"code","0ccc320a":"code","614b2073":"code","a7765778":"code","c92077e0":"code","a518bb0c":"code","5a07add1":"code","c81ef170":"code","e938ffec":"code","5661d6d5":"code","750d28a3":"code","d561fc41":"code","85d31250":"code","9b979451":"markdown","1e43c6f8":"markdown","224d1456":"markdown","535dc519":"markdown","6a9cd5f5":"markdown","d5a77798":"markdown"},"source":{"65ecc9c4":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom matplotlib import pyplot as plt\nimport matplotlib\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n","17f92846":"df = pd.read_csv(\"..\/input\/loan-prediction-problem-dataset\/train_u6lujuX_CVtuZ9i.csv\")\ndf.head()","4753f928":"df.describe()","1495e4de":"df.info()","a05cc39a":"df.isnull().sum()","b74895f8":"#1 first filling up categorical misising values","f3d26545":"df['Gender'] = df[\"Gender\"].fillna(df['Gender'].mode()[0])\ndf['Married'] = df[\"Married\"].fillna(df['Married'].mode()[0])\ndf['Self_Employed'] = df[\"Self_Employed\"].fillna(df['Self_Employed'].mode()[0])","a95b1265":"# counting the Dependents for better understanding about the data before filling it up.","6a33d7f0":"sns.countplot(x ='Dependents', data = df)","225c9553":"#as we can see filling with mode make sense here.","eaedd80f":"df['Dependents'] = df[\"Dependents\"].fillna(df['Dependents'].mode()[0])","8d369232":"#2 filling numerical values","ee3754b0":"#we should check for outliers before filling up numerical values.","fa3496df":"df['Credit_History'].unique()","4d0d45cb":"sns.countplot(x ='Credit_History', data = df)","67209f85":"df['Credit_History']=df['Credit_History'].fillna(df['Credit_History'].mode()[0])","8d33300a":"splot = sns.countplot(x ='Loan_Amount_Term', data = df)\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')","bb25d089":"# we can see that 360 has count of 512 so thats why replacing the loan_amount_term by mode will be smarter choice.","e16e0b61":"df['Loan_Amount_Term']=df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mode()[0])","f04782c7":"plt.figure(figsize=(25, 8))\nsplot = sns.countplot(x ='LoanAmount', data = df)\nfor p in splot.patches:\n    splot.annotate(format(p.get_height(), '.2f'), (p.get_x() + p.get_width() \/ 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')","48522403":"#we can not replace loan amount with mode because here mean or median will be better.\n#before making choice beteween mean and median we have to check for outliers.\n# becuase mean is affected by outliers.","4fe84482":"sns.boxplot(x=\"LoanAmount\", data=df)","8450a2b3":"#there is outlier so ","3d2d0341":"Q1 = df['LoanAmount'].quantile(0.25)\nQ3 = df['LoanAmount'].quantile(0.75)\nIQR = Q3 - Q1","b83ed1b1":"low_lim = Q1 - 1.5 * IQR\nup_lim = Q3 + 1.5 * IQR\nprint('low_limit is', low_lim)\nprint('up_limit is', up_lim)","0631502e":"outlier = []\nfor x in df['LoanAmount']:\n    if ((x> up_lim) or (x<low_lim)):\n         outlier.append(x)\nprint(' outlier in the dataset is', outlier)","9e1b0cbf":"len(outlier)","ff59b68d":"#we will not remove the outliers becuase it has 39\/592, which means it has 6.5% amount of data in whole.","c9549cdc":"#we will use median to replace the missing value.\n#becuase median is not affected by the outliers.","04478aa9":"df['LoanAmount']=df['LoanAmount'].fillna(df['LoanAmount'].median())","e7959186":"df.isnull().sum()\n# now there is no missing values.","19301a56":"sns.countplot(df['Loan_Status'])\nprint('The percentage of Y class : %.2f' % (df['Loan_Status'].value_counts()[0] \/ len(df)))\nprint('The percentage of N class : %.2f' % (df['Loan_Status'].value_counts()[1] \/ len(df)))\n\n#there is almost balance we don't need to worry about that.","5150491f":"df['Loan_Status'].replace('N',0,inplace=True)\ndf['Loan_Status'].replace('Y',1,inplace=True)","c58524e1":"#Credit history vs loan status\ngrid = sns.FacetGrid(df,col='Loan_Status', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Credit_History')\n\n#people having credit history have easy time getting loan","63f7019c":"#Gender vs loan status\nsns.countplot(x ='Gender', data = df)\n","ea7f439a":"grid = sns.FacetGrid(df,col='Gender', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Loan_Status')\n\n# chances for getting loan for female is easier compared to male.\n#Loan status clearly depend upon the gender.","f2d62c54":"#Married vs loan status\nsns.countplot(x='Married', hue='Loan_Status', data=df)\n\n#people who are married have better chance at loan approval","eb1e7414":"grid = sns.FacetGrid(df,col='Married', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Loan_Status')","f49597e4":"#Dependents vs loan status\n\n#sns.barplot(x='Dependents', y='Loan_Status', data=df)\nsns.countplot(x=\"Dependents\", hue=\"Loan_Status\", data=df)","e96e2d67":"grid = sns.FacetGrid(df,col='Dependents', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Loan_Status')","ce340c29":"grid = sns.FacetGrid(df,col='Loan_Status', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Dependents')\n\n#we should drop the dependents as it has no relation with loan status","fdf1c63f":"#loan status vs Education\ngrid = sns.FacetGrid(df,col='Education', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Loan_Status')","8e950a5f":"sns.countplot(x=\"Education\", hue=\"Loan_Status\", data=df)\n#in both situation people ae getting the loan but people who are graduate are getting loan easier compared to other.","71e9cf22":"#Self_Employed vs Education\ngrid = sns.FacetGrid(df,col='Loan_Status', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Self_Employed')\n\n#people having job got loan easily","6c80f945":"grid = sns.FacetGrid(df,col='Loan_Status', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Property_Area')","e9f06193":"grid = sns.FacetGrid(df,col='Property_Area', size=3.2, aspect=1.6)\ngrid.map(sns.countplot, 'Loan_Status')\n\n# property area has impact on loan status","7f5f0c0c":"df['Total_Income'] = df['ApplicantIncome'] + df['CoapplicantIncome']\ndf.head()","221f15e2":"plt.figure(figsize=(8,10))\nsns.boxplot(x=\"Loan_Status\",y=\"Total_Income\", data=df)","b9ba9699":"df['Loan_Amount_Term'].unique()","4c69c7ea":"plt.figure(figsize=(15,15))\nsns.countplot(x=\"Loan_Amount_Term\", hue=\"Loan_Status\", data=df)\n#no patter","0ccc320a":"df['LoanAmount'].unique()","614b2073":"plt.figure(figsize=(8,10))\nsns.boxplot(x=\"Loan_Status\",y=\"LoanAmount\", data=df)\n#no pattern","a7765778":"cols = ['ApplicantIncome', 'CoapplicantIncome', \"LoanAmount\", \"Loan_Amount_Term\", \"Total_Income\", 'Loan_ID', 'CoapplicantIncome', 'Dependents']\ndf = df.drop(columns=cols, axis=1)\ndf.head()","c92077e0":"from sklearn.preprocessing import LabelEncoder\ncols = ['Gender',\"Married\",\"Education\",'Self_Employed',\"Property_Area\"]\nle = LabelEncoder()\nfor col in cols:\n    df[col] = le.fit_transform(df[col])\n","a518bb0c":"df.head()","5a07add1":"# specify input and output attributes\nX = df.drop(columns=['Loan_Status'], axis=1)\ny = df['Loan_Status']","c81ef170":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)","e938ffec":"# classify function\nfrom sklearn.model_selection import cross_val_score\ndef classify(model, x, y):\n    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n    model.fit(x_train, y_train)\n    print(\"Accuracy is\", model.score(x_test, y_test)*100)\n    # cross validation - it is used for better validation of model\n    # eg: cv-5, train-4, test-1\n    score = cross_val_score(model, x, y, cv=5)\n    print(\"Cross validation is\",np.mean(score)*100)","5661d6d5":"from sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression()\nclassify(model, X, y)","750d28a3":"from sklearn.ensemble import RandomForestClassifier\nmodel = RandomForestClassifier()\nclassify(model, X, y)","d561fc41":"from sklearn.metrics import confusion_matrix\ny_pred = model.predict(x_test)\ncm = confusion_matrix(y_test, y_pred)\ncm","85d31250":"sns.heatmap(cm, annot=True)","9b979451":"# Drop featrues which has no use","1e43c6f8":"# Confusion matrix","224d1456":"# Dealing with missing values","535dc519":"#  EDA","6a9cd5f5":"# Checking for data imbalance","d5a77798":"# Label Encoding for categorical"}}