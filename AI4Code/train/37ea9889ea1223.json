{"cell_type":{"1f26dcbc":"code","d8ddbca4":"code","5182fd11":"code","0ed82d6e":"code","e423b6c4":"code","9a338928":"code","d6f24691":"code","da3aa953":"code","7085a512":"code","d13e803b":"code","c8842c1a":"code","78373386":"markdown","d16fbd18":"markdown","bfac1eb8":"markdown","4b66b5da":"markdown","3dc89594":"markdown"},"source":{"1f26dcbc":"import os\nimport random\nimport numpy as np\nimport shutil\n\nimport torch\nimport torch.utils.data as data\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import transforms\nfrom torchvision.transforms import ToTensor\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\n\nfrom PIL import Image\nimport torchvision.transforms.functional as TF\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport pandas as pd\n\nmpl.rcParams['figure.dpi']= 100\nmpl.rcParams[\"savefig.dpi\"] = 300","d8ddbca4":"random.seed(42)\nmax_age = 101\nage_limits = list(range(max_age))\n\nBATCH_SIZE = 64","5182fd11":"os.mkdir(\"\/kaggle\/utkface\/\")\nos.mkdir(\"\/kaggle\/utkface\/data\/\")\n\nall_classes = []\nl = 0\nfor class_name in age_limits:\n    all_classes.append(class_name)\n    os.mkdir(\"\/kaggle\/utkface\/data\/\"+str(class_name)+\"\/\")\n\npath = \"..\/input\/utkface-new\/UTKFace\/\"\n\nfor filename in os.listdir(path):\n    age = int(filename.split(\"_\")[0])\n\n    new_filename = filename.split(\".\")[0] + \".\" + filename.split(\".\")[-1]\n    \n    if age in age_limits:\n        class_name = str(age)\n        shutil.copy2(path+filename, \"\/kaggle\/utkface\/data\/\"+class_name+\"\/\"+new_filename)","0ed82d6e":"#remove empty folder\npath = '\/kaggle\/utkface\/data\/'\nfolders = list(os.walk(path))[1:]\n\nfor folder in folders:\n    if not folder[2]:\n        os.rmdir(folder[0])","e423b6c4":"transform_size = transforms.Compose([\n    transforms.CenterCrop(224),\n    ToTensor(),\n    transforms.Normalize([0.4816, 0.4199, 0.3884], [0.1327, 0.1273, 0.1356])\n])","9a338928":"data_ds = torchvision.datasets.ImageFolder('\/kaggle\/utkface\/data\/', transform=transform_size)\n\ndata_dataloader = data.DataLoader(data_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)","d6f24691":"def Conv(in_channels, out_channels, kerner_size=3, stride=1, padding=1):\n    out_channels = int(out_channels)\n    in_channels = int(in_channels)\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kerner_size, stride, padding, bias=False),\n        nn.BatchNorm2d(out_channels),\n        nn.ReLU(True),\n    )","da3aa953":"class DLDLv2(nn.Module):\n    def __init__(self, max_age=101, c=0.5):\n        super(DLDLv2, self).__init__()\n        self.conv1 = Conv(3, 64*c)\n        self.conv2 = Conv(64*c, 64*c)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.conv3 = Conv(64*c, 128*c)\n        self.conv4 = Conv(128*c, 128*c)\n        self.pool2 = nn.MaxPool2d(2, 2)\n        self.conv5 = Conv(128*c, 256*c)\n        self.conv6 = Conv(256*c, 256*c)\n        self.conv7 = Conv(256*c, 256*c)\n        self.pool3 = nn.MaxPool2d(2, 2)\n        self.conv8 = Conv(256*c, 512*c)\n        self.conv9 = Conv(512*c, 512*c)\n        self.conv10 = Conv(512*c, 512*c)\n        self.pool4 = nn.MaxPool2d(2, 2)\n        self.conv11 = Conv(512*c, 512*c)\n        self.conv12 = Conv(512*c, 512*c)\n        self.conv13 = Conv(512*c, 512*c)\n        \n        self.HP = nn.Sequential(\n            nn.MaxPool2d(2, 2),\n            nn.AvgPool2d(kernel_size=7, stride=1)\n        )\n        \n        self.fc1 = nn.Sequential(\n            nn.Linear(int(512*c), max_age),\n            nn.Softmax(dim = 1)\n        )\n                \n        self.ages = torch.tensor(list(range(max_age))).t().float()\n        self.device = \"cpu\"\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.pool1(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.pool2(x)\n        x = self.conv5(x)\n        x = self.conv6(x)\n        x = self.conv7(x)\n        x = self.pool3(x)\n        x = self.conv8(x)\n        x = self.conv9(x)\n        x = self.conv10(x)\n        x = self.pool4(x)\n        x = self.conv11(x)\n        x = self.conv12(x)\n        x = self.conv13(x) \n        x = self.HP(x)\n        x = x.view((x.size(0), -1))               #flatten layer x.size(0) is batchsize\n        x = self.fc1(x.view((x.size(0), -1)))\n        \n        return x\n    \n    def to(self, device):\n        module = super(DLDLv2, self).to(device)\n        module.ages = self.ages.to(device)\n        self.device = device\n        return module\n\n    #train model on a batch\n    def train_batch(self, x, y):\n        x, y  = x.to(device), y.to(device)\n        b_x, b_y = Variable(x), Variable(y)\n        \n        outputs = self.forward(b_x)\n        age = torch.matmul(outputs,self.ages)\n        \n        return custom_loss(outputs, age, b_y)\n    \n    \n    #predict age of a batch\n    def predict_age(self, x):\n        x = x.to(self.device)\n        with torch.no_grad():\n            outputs = self.forward(x)\n            \n        return torch.matmul(outputs,self.ages)\n        ","7085a512":"def validate_model(model):\n    #track test loss\n    valid_loss = 0\n    valid_loss_length = 0\n    \n    #define loss\n    loss_l1_fc = nn.L1Loss(reduction='mean')\n    \n    #send model to gpu if possible\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n    model.to(device)\n    \n    model.eval()\n    for (x, y) in data_dataloader:\n        y = y.to(device)\n        age = model.predict_age(x)\n\n        #compute loss\n        l1_loss = loss_l1_fc(age, y)\n        valid_loss += l1_loss.data\n        valid_loss_length += 1\n\n    return (valid_loss\/valid_loss_length)","d13e803b":"#init models\nmodel = DLDLv2(101, 0.5)\nmodel.load_state_dict(torch.load(\"\/kaggle\/input\/convert-pretrained-thinage-to-torchmodel\/ThinAgeNet-ChaLearn15.pt\"))\nloss_ChaLearn15 = validate_model(model)\n\nmodel = DLDLv2(101, 0.5)\nmodel.load_state_dict(torch.load(\"\/kaggle\/input\/convert-pretrained-thinage-to-torchmodel\/ThinAgeNet-ChaLearn16.pt\"))\nloss_ChaLearn16 = validate_model(model)\n\nmodel = DLDLv2(101, 0.5)\nmodel.load_state_dict(torch.load(\"\/kaggle\/input\/convert-pretrained-thinage-to-torchmodel\/ThinAgeNet-Morph.pt\"))\nloss_Morph = validate_model(model)","c8842c1a":"print(\"ThinAge models learned on different datasets and validated on UTKFace dataset:\\n\")\nprint(\"ChaLearn15 Loss: {:2.4f}\".format(loss_ChaLearn15))\nprint(\"ChaLearn16 Loss: {:2.4f}\".format(loss_ChaLearn16))\nprint(\"Morph Loss:      {:2.4f}\".format(loss_Morph))","78373386":"# folders","d16fbd18":"# imports","bfac1eb8":"# Validation","4b66b5da":"# Initialise Parameters","3dc89594":"# DLDLv2"}}