{"cell_type":{"d6bb554f":"code","25cd9bc3":"code","966eb69b":"code","0a1f061d":"code","fc3c4d83":"code","e2908991":"code","433a1f3b":"code","2ea3ba46":"code","56224acf":"code","fb5f400a":"code","2988d817":"code","393508c0":"code","11b0ae9f":"code","b13fa012":"code","ce16a9e7":"code","8b684b86":"code","1f35fbba":"code","f8f2d0ab":"code","3fefd820":"code","c9e405c5":"code","3d34e6ce":"code","0d33615a":"code","4dbf8227":"code","54a884f6":"code","4866203e":"code","e0213607":"code","db151d85":"code","8eff8d29":"code","c1b959b0":"code","0d8128e3":"code","dbd82bd8":"code","26ad9e9c":"code","9e4df0f2":"code","c38c67d0":"code","25c453ed":"code","ee6b9aec":"code","c7253bc0":"code","108fe4ef":"code","85ace7ac":"code","c5c7b164":"code","4a5f02f4":"code","792e5d25":"code","22aad104":"code","09333e93":"code","76f1ac5b":"code","d60e46c8":"code","a4fbd4c3":"code","62f18ee5":"code","cd165bcf":"code","648ac0d0":"code","f6e8a506":"code","00f3ea90":"code","5933b0ee":"code","67e29ada":"code","65e322e7":"code","69177a7b":"code","b2578ee5":"code","e7794eb7":"code","2f6fccdc":"code","7c063d48":"code","2ec8642f":"code","dafe6940":"code","da658569":"code","e0d77149":"code","e591b423":"code","4ead084e":"code","acd0121f":"code","91f89429":"code","514df7d9":"code","6721a1ea":"code","905fe36d":"code","061a2e63":"code","d25ec166":"code","102d8410":"code","712b622f":"code","94d3da92":"markdown","ea8cfe3a":"markdown","3e86edcc":"markdown","82d77c63":"markdown","c3606f64":"markdown","f618ebd0":"markdown"},"source":{"d6bb554f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","25cd9bc3":"pd.set_option('float_format', '{:f}'.format)","966eb69b":"train = pd.read_csv('..\/input\/janata-hack-machine-learning-for-banking\/train_fNxu4vz.csv',thousands=',')\ntest = pd.read_csv('..\/input\/janata-hack-machine-learning-for-banking\/test_fjtUOL8.csv',thousands=',')","0a1f061d":"print(train.shape)\ntrain.head()","fc3c4d83":"train_original = train.copy()\ntest_original = test.copy()","e2908991":"train.dtypes","433a1f3b":"category = []\nfor col in train.columns:\n    if train[col].dtypes == 'object':\n        category.append(col)\ncategory","2ea3ba46":"train['Interest_Rate'].value_counts()","56224acf":"#f,ax = plt.subplots(1,2,figsize = (18,8))\nplt.subplot(121)\ntrain['Interest_Rate'].value_counts().plot.pie(autopct = '%1.2f%%',figsize = (18,8),title = 'Target Variable classification')\nplt.subplot(122)\ntrain['Interest_Rate'].value_counts().plot.bar(figsize = (18,8))","fb5f400a":"cont_col = ['Loan_Amount_Requested','Annual_Income','Debt_To_Income','Months_Since_Deliquency','Number_Open_Accounts',\n 'Total_Accounts']\nord_col = ['Length_Employed', 'Inquiries_Last_6Mo']\nnom_col = ['Home_Owner','Income_Verified','Purpose_Of_Loan','Gender']","2988d817":"#Independent Variable (Categorical)\n#'Home_Owner','Income_Verified','Purpose_Of_Loan','Gender'\nprint(plt.figure(1) )\nax = plt.subplot(221) \n#ax.xaxis.label.set_color('red')\nax.tick_params(axis='x', colors='red')\nax.tick_params(axis='y', colors='red')\ntrain['Gender'].value_counts(normalize=True).plot.bar(figsize=(20,18), title= 'Gender',colormap = 'viridis',fontsize = 16) \nax = plt.subplot(222)\nax.tick_params(axis='x', colors='red')\nax.tick_params(axis='y', colors='red')\ntrain['Home_Owner'].value_counts(normalize=True).plot.bar(title= 'Home_Owner',colormap = 'Accent',fontsize = 16) \nplt.subplot(223) \ntrain['Income_Verified'].value_counts(normalize=True).plot.bar(title= 'Income_Verified',colormap = 'Set2_r',fontsize = 16) \nplt.subplot(224) \ntrain['Purpose_Of_Loan'].value_counts(normalize=True).plot.bar(title= 'Purpose_Of_Loan',colormap = 'Set1',fontsize = 16) \nplt.show()\nax.xaxis.label.set_color('red')\nax.tick_params(axis='x', colors='red')","393508c0":"## 'Loan_Amount_Requested','Length_Employed'\n#Inquiries_Last_6Mo, Number_Open_Accounts,Total_Accounts               int64\n#Independent Variable (Ordinal)\nprint(train['Length_Employed'].unique())\nprint(train['Inquiries_Last_6Mo'].unique())\nprint(train['Number_Open_Accounts'].unique())\nprint(train['Total_Accounts'].unique())","11b0ae9f":"#Independent Variable (Ordinal)\n#'Length_Employed', Inquiries_Last_6Mo\nprint(plt.figure(1) )\nax = plt.subplot(221) \n#ax.xaxis.label.set_color('red')\nax.tick_params(axis='x', colors='red')\nax.tick_params(axis='y', colors='red')\ntrain['Length_Employed'].value_counts(normalize=True).plot.bar(figsize=(20,18), title= 'Length_Employed',colormap = 'spring',fontsize = 16) \nax = plt.subplot(222) \n#ax.xaxis.label.set_color('red')\nax.tick_params(axis='x', colors='red')\nax.tick_params(axis='y', colors='red')\ntrain['Inquiries_Last_6Mo'].value_counts(normalize=True).plot.bar(figsize=(20,18), title= 'Inquiries_Last_6Mo',colormap = 'cool',fontsize = 16) \n","b13fa012":"\ni = 1\n\nfor col in cont_col:\n    plt.figure(figsize = (25,35))\n    plt.subplot(7,2,i)\n    sns.distplot(train[col]); \n    plt.subplot(7,2,i+1) \n    train[col].plot.box()\n    i += 2\n    plt.show()","ce16a9e7":"for col in nom_col:\n    Gender=pd.crosstab(train[col],train['Interest_Rate']) \n    #print(Gender)\n    Gender.div(Gender.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(15,4))","8b684b86":"for col in ord_col:\n    Gender=pd.crosstab(train[col],train['Interest_Rate']) \n    #print(Gender)\n    Gender.div(Gender.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(15,4))","1f35fbba":"train.groupby('Interest_Rate')['Annual_Income'].mean().plot.bar()","f8f2d0ab":"print(train['Annual_Income'].max())\nprint(train['Annual_Income'].min())\nprint(train['Annual_Income'].mean())","3fefd820":"bins=[0,100000,500000,1000000,7600000] \ngroup=['Low','Average','High', 'Very high'] \ntrain['Annual_Income_bin']=pd.cut(train['Annual_Income'],bins,labels=group)","c9e405c5":"Annual_Income_bin=pd.crosstab(train['Annual_Income_bin'],train['Interest_Rate']) \nAnnual_Income_bin.div(Annual_Income_bin.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True) \nplt.xlabel('Annual_Income') \nP = plt.ylabel('Percentage')","3d34e6ce":"train.describe()","0d33615a":"i = 1\nfor col in cont_col:\n    plt.figure(figsize = (25,35))\n    plt.subplot(len(cont_col),1,i)\n    train.groupby('Interest_Rate')[col].mean().plot.bar(title = col)\n    i += 1","4dbf8227":"bins=[0,8000,12000,20000,36000] \ngroup=['Low','Average','High','veryhigh'] \ntrain['LoanAmount_bin']=pd.cut(train['Loan_Amount_Requested'],bins,labels=group)\nLoanAmount_bin=pd.crosstab(train['LoanAmount_bin'],train['Interest_Rate']) \nLoanAmount_bin.div(LoanAmount_bin.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True) \nplt.xlabel('LoanAmount') \nP = plt.ylabel('Percentage')","54a884f6":"train.columns","4866203e":"train['Length_Employed'].str.extract('(\\d+)')\n","e0213607":"#train=train.drop(['Annual_Income_bin', 'LoanAmount_bin'], axis=1)\ntrain['Length_Employed'] = train['Length_Employed'].str.extract('(\\d+)').astype('int64',errors='ignore')\ntest['Length_Employed'] = test['Length_Employed'].str.extract('(\\d+)').astype('int64',errors='ignore')\n","db151d85":"train","8eff8d29":" \nf, ax = plt.subplots(figsize=(28, 12)) \nsns.heatmap(train.corr(), vmax=.8, square=True, cmap=\"RdYlGn\",annot = True);","c1b959b0":"train.isnull().sum()","0d8128e3":"test.isnull().sum()","dbd82bd8":"train.drop('Months_Since_Deliquency',axis = 1,inplace = True)\ntest.drop('Months_Since_Deliquency',axis = 1,inplace = True)","26ad9e9c":"train['Length_Employed'].value_counts()\ntrain['Home_Owner'].value_counts()\n","9e4df0f2":"train['Length_Employed'].fillna(train['Length_Employed'].mode()[0],inplace = True)\ntrain['Home_Owner'].fillna(train['Home_Owner'].mode()[0],inplace = True)\n\ntest['Length_Employed'].fillna(train['Length_Employed'].mode()[0],inplace = True)\ntest['Home_Owner'].fillna(train['Home_Owner'].mode()[0],inplace = True)","c38c67d0":"train['Annual_Income'].fillna(train['Annual_Income'].median(),inplace = True)\ntest['Annual_Income'].fillna(train['Annual_Income'].median(),inplace = True)","25c453ed":"minvalue=min(train['Annual_Income'])\nmaxvalue=max(train['Annual_Income'])\nmeanvalue=np.mean(train['Annual_Income'])\nmedianvalue=np.median(train['Annual_Income'])\n\npoints=[minvalue, maxvalue, meanvalue, medianvalue]\nnames=[\"min\",\"max\",\"mean\",\"mid\"]","ee6b9aec":"#Lets see scatter plot\nfig, ax = plt.subplots(figsize=(16,8))\nax.scatter(train.index,train['Annual_Income'],color = 'deeppink')\nax.axhline(y=minvalue, label=\"min\",color='blue')\nax.axhline(y=maxvalue, label=\"max\",color='cyan')\nax.axhline(y=meanvalue, label=\"mean\",color='red')\nax.axhline(y=medianvalue, label=\"mid\",color='green')\nax.legend()","c7253bc0":"#Lets see Z-score\nfrom scipy import stats\nimport numpy as np\nz = np.abs(stats.zscore(train['Annual_Income']))\nprint(z)","108fe4ef":"threshold = 3\nprint(np.where(z > 3))","85ace7ac":"z[98]","c5c7b164":"train['Annual_Income_log'] = np.log(train['Annual_Income']) \ntrain['Annual_Income_log'].hist(bins=20) \ntest['Annual_Income_log'] = np.log(test['Annual_Income'])","4a5f02f4":"train[['Annual_Income','Annual_Income_log']].sort_values('Annual_Income')","792e5d25":"#Lets see scatter plot\ncont_col.remove('Months_Since_Deliquency')\nfor col in cont_col:\n    minvalue=min(train[col])\n    maxvalue=max(train[col])\n    meanvalue=np.mean(train[col])\n    medianvalue=np.median(train[col])\n\n    #points=[minvalue, maxvalue, meanvalue, medianvalue]\n    #names=[\"min\",\"max\",\"mean\",\"mid\"]\n    fig, ax = plt.subplots(figsize=(16,4))\n    ax.scatter(train.index,train[col],color = 'deeppink',label = col)\n    ax.axhline(y=minvalue, label=\"min\",color='blue')\n    ax.axhline(y=maxvalue, label=\"max\",color='cyan')\n    ax.axhline(y=meanvalue, label=\"mean\",color='red')\n    ax.axhline(y=medianvalue, label=\"mid\",color='green')\n    ax.legend()","22aad104":"threshold = 3\nfor col in cont_col:\n    z = np.abs(stats.zscore(train[col]))\n    outlier = np.where(z > threshold)\n    print(\"No. of outliers in \",col,\":\",len(outlier[0]))\n    print(outlier[0])\n    print()\n\n#type(outlier[0])","09333e93":"train['Annual_Income'][177]","76f1ac5b":"#Annual Income outliered values\ntrain[(np.abs(stats.zscore(train['Annual_Income'])) > 3)]['Annual_Income'].sort_values()","d60e46c8":"#Annual Income outliered values\ntrain[(np.abs(stats.zscore(train['Number_Open_Accounts'])) > 3)]['Number_Open_Accounts'].sort_values()","a4fbd4c3":"#As we have 0's in the sample, if we apply log those will be -inf, to overcome this we apply sqrt instead of log\ntrain['Number_Open_Accounts_log'] = np.sqrt(train['Number_Open_Accounts'])\nplt.figure(figsize = (12,4))\nplt.subplot(1,2,1)\ntrain['Number_Open_Accounts_log'].hist() \nplt.subplot(1,2,2)\nsns.distplot(train['Number_Open_Accounts_log'])\ntest['Number_Open_Accounts_log'] = np.sqrt(test['Number_Open_Accounts'])","62f18ee5":"train[['Number_Open_Accounts_log','Number_Open_Accounts']].sort_values('Number_Open_Accounts_log')","cd165bcf":"train[(np.abs(stats.zscore(train['Total_Accounts'])) > 3)]['Total_Accounts'].sort_values()","648ac0d0":"#As we have 0's in the sample, if we apply log those will be -inf, to overcome this we apply sqrt instead of log\ntrain['Total_Accounts_log'] = np.sqrt(train['Total_Accounts'])\nplt.figure(figsize = (12,4))\nplt.subplot(1,2,1)\ntrain['Total_Accounts_log'].hist() \nplt.subplot(1,2,2)\nsns.distplot(train['Total_Accounts_log'])\ntest['Total_Accounts_log'] = np.sqrt(test['Number_Open_Accounts'])","f6e8a506":"train[['Total_Accounts_log','Total_Accounts']].sort_values('Total_Accounts_log')","00f3ea90":"train.columns","5933b0ee":"train=train.drop('Loan_ID',axis=1) \ntest=test.drop('Loan_ID',axis=1)","67e29ada":"test","65e322e7":"X = train.drop(['Interest_Rate','Total_Accounts','Number_Open_Accounts','Annual_Income','Annual_Income_bin','LoanAmount_bin'],1) \ny = train['Interest_Rate']\ntest = test.drop(['Total_Accounts','Number_Open_Accounts','Annual_Income'],1)","69177a7b":"X.columns","b2578ee5":"X=pd.get_dummies(X) \ntrain=pd.get_dummies(train) \ntest=pd.get_dummies(test)","e7794eb7":"from sklearn.model_selection import train_test_split\nx_train, x_cv, y_train, y_cv = train_test_split(X,y, test_size =0.3)","2f6fccdc":"from sklearn.metrics import confusion_matrix \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.svm import SVC \nfrom sklearn.utils import shuffle\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score","7c063d48":"from sklearn.neighbors import KNeighborsClassifier \nknn = KNeighborsClassifier(n_neighbors = 7).fit(x_train, y_train) \npred_cv = knn.predict(x_cv)\naccuracy_score(y_cv,pred_cv)","2ec8642f":"# accuracy on X_test \n\naccuracy = knn.score(x_cv, y_cv) \nprint(accuracy)\n  \n# creating a confusion matrix \nknn_predictions = knn.predict(x_cv)  \ncm = confusion_matrix(y_cv, knn_predictions)","dafe6940":"sns.heatmap(cm,annot=True,fmt = '')","da658569":"pred_test = knn.predict(test)","e0d77149":"submission=pd.read_csv(\"..\/input\/janata-hack-machine-learning-for-banking\/sample_submission_HSqiq1Q.csv\")\nsubmission['Interest_Rate']=pred_test \nsubmission['Loan_ID']=test_original['Loan_ID']\nsubmission.to_csv('knn.csv',index = False)\nsubmission.head()","e591b423":"submission.to_csv('knn.csv',index = False)","4ead084e":"from sklearn.model_selection import StratifiedKFold","acd0121f":"from sklearn.ensemble import RandomForestClassifier\ni=1 \nkf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True) \nfor train_index,test_index in kf.split(X,y):     \n    print('\\n{} of kfold {}'.format(i,kf.n_splits))     \n    xtr,xvl = X.loc[train_index],X.loc[test_index]     \n    ytr,yvl = y[train_index],y[test_index]         \n    model = RandomForestClassifier(random_state=1, max_depth=10)     \n    model.fit(xtr, ytr)     \n    pred_test = model.predict(xvl)     \n    score = accuracy_score(yvl,pred_test)     \n    print('accuracy_score',score)     \n    i+=1 \n\n    rf_test = model.predict(test)","91f89429":"submission['Interest_Rate']=rf_test \nsubmission['Loan_ID']=test_original['Loan_ID']\nsubmission.to_csv('rf1.csv',index = False)","514df7d9":"rf = RandomForestClassifier(max_depth=10).fit(x_train, y_train) \npred_cv = rf.predict(x_cv)\naccuracy_score(y_cv,pred_cv)","6721a1ea":"pred_test = rf.predict(test)","905fe36d":"submission['Interest_Rate']=pred_test \nsubmission['Loan_ID']=test_original['Loan_ID']\nsubmission.to_csv('rf1.csv',index = False)","061a2e63":"from sklearn.model_selection import GridSearchCV\n# Provide range for max_depth from 1 to 20 with an interval of 2 and from 1 to 200 with an interval of 20 for n_estimators \nparamgrid = {'max_depth': list(range(1, 20, 2)), 'n_estimators': list(range(1, 200, 20))}\ngrid_search=GridSearchCV(RandomForestClassifier(random_state=1),paramgrid)","d25ec166":"from sklearn.model_selection import train_test_split \nx_train, x_cv, y_train, y_cv = train_test_split(X,y, test_size =0.3, random_state=1)\n# Fit the grid search model \ngrid_search.fit(x_train,y_train)","102d8410":"grid_search.best_estimator_","712b622f":"i=1 \nkf = StratifiedKFold(n_splits=5,random_state=1,shuffle=True) \nfor train_index,test_index in kf.split(X,y):     \n    print('\\n{} of kfold {}'.format(i,kf.n_splits))     \n    xtr,xvl = X.loc[train_index],X.loc[test_index]     \n    ytr,yvl = y[train_index],y[test_index]         \n    model = RandomForestClassifier(random_state=1, max_depth=15, n_estimators=181)    \n    model.fit(xtr, ytr)     \n    pred_test = model.predict(xvl)     \n    score = accuracy_score(yvl,pred_test)     \n    print('accuracy_score',score)     \n    i+=1 \n    pred_test = model.predict(test) \n    #pred2=model.predict_proba(test)[:,1]\n    ","94d3da92":"## Model Building\nSupport Vector Machine (SVM)\nk-Nearest Neighbors (KNN)\nBagged Decision Trees (BAG)\nRandom Forest (RF)\nExtra Trees (ET)","ea8cfe3a":"# Outliers","3e86edcc":"You can see the outliers clearly","82d77c63":"#Independent Variable (Numerical)\n#Till now we have seen the categorical and ordinal variables and now lets visualize the numerical variables. Lets look at the distribution of Applicant income first.\n#Loan_Amount_Requested,Annual_Income,Debt_To_Income,Months_Since_Deliquency,Number_Open_Accounts,Total_Accounts               \n","c3606f64":"## Handle Null Values","f618ebd0":"categorical variables:\n    Nominal:\n        'Home_Owner','Income_Verified','Purpose_Of_Loan','Gender'\n    Ordinal:\n        'Length_Employed', Inquiries_Last_6Mo\n\nContinous:\n    Loan_Amount_Requested        \n    Annual_Income              \n    Debt_To_Income                        \n    Months_Since_Deliquency    \n    Number_Open_Accounts         \n    Total_Accounts               \n\n\n"}}