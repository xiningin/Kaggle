{"cell_type":{"cb7a1fa9":"code","369f72e0":"code","84851abc":"code","43eba2b4":"code","dd548962":"code","778abbee":"code","3d06d865":"code","bfe23fcd":"code","c7f92f49":"code","fead68cf":"code","89928f76":"code","60a31527":"code","a55c2535":"code","3c7773c4":"code","b00442de":"code","bcbcf4f8":"code","a3004d24":"code","81d913fa":"code","d3c03eb7":"code","63268848":"code","c16d0411":"code","f9083fde":"code","cc688ff9":"code","2c0689dd":"code","96255e9d":"code","21b797e4":"code","60f3ad86":"code","c6315299":"code","fe3526d7":"code","18a8a3d9":"code","8851bb7a":"code","1daf1b21":"code","74ea4ae0":"code","858cece3":"markdown","04ee5edc":"markdown"},"source":{"cb7a1fa9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","369f72e0":"import numpy as np \nimport pandas as pd\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom pathlib import Path\nimport os.path\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport os\nimport cv2\nimport pandas as pd\nimport random\nimport os\nimport PIL\nimport tensorflow as tf\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping","84851abc":"path = '..\/input\/plant-pathology-2021-fgvc8'","43eba2b4":"train_df = pd.read_csv(r'..\/input\/plant-pathology-2021-fgvc8\/train.csv', index_col='image')","dd548962":"train_df.labels.value_counts()","778abbee":"plt.figure(figsize=(15,12))\nlabels = sns.barplot(train_df.labels.value_counts().index,train_df.labels.value_counts())\nfor item in labels.get_xticklabels():\n    item.set_rotation(45)\nplt.title('Label Distribution', weight='bold')\nplt.show()","3d06d865":"train_img_Path = '..\/input\/plant-pathology-2021-fgvc8\/train_images'\ntest_img_Path = '..\/input\/plant-pathology-2021-fgvc8\/test_images'\nsample_submission = pd.read_csv(r'..\/input\/plant-pathology-2021-fgvc8\/sample_submission.csv')","bfe23fcd":"train_df.head()","c7f92f49":"init_len = len(train_df)\n\nwith open('..\/input\/duplicates-image\/duplicates.csv', 'r') as file:\n    duplicates = [x.strip().split(',') for x in file.readlines()]\n\nfor row in duplicates:\n   \n    unique_labels = train_df.loc[row].drop_duplicates().values\n    \n    if len(unique_labels) == 1:\n        train_df = train_df.drop(row[1:], axis=0)\n    else:\n        train_df = train_df.drop(row, axis=0)\n        \nprint(f'Dropping {init_len - len(train_df)} duplicate samples.')","fead68cf":"train_df['labels'] = train_df['labels'].apply(lambda s: s.split(' '))\ntrain_df.head()","89928f76":"\nfig1 = plt.figure(figsize=(20,10))\n\nfor i in range(1, 10):\n    \n    rand =  random.randrange(1, 18000)\n    sample = os.path.join('..\/input\/plant-pathology-2021-fgvc8\/train_images', train_df.index[rand])\n    \n    img = PIL.Image.open(sample)\n    \n    ax = fig1.add_subplot(4,3,i)\n    ax.imshow(img)\n    \n    title = f\"{train_df['labels'][rand]}{img.size}\"\n    plt.title(title)\n    \n    fig1.tight_layout()","60a31527":"TRAIN_PATH = '..\/input\/resized-plant2021\/img_sz_256\/'\nTEST_PATH = '..\/input\/plant-pathology-2021-fgvc8\/test_images\/'\n\nIMG_RES = 256","a55c2535":"resized_train = pd.read_csv('..\/input\/plant-pathology-2021-fgvc8\/train.csv')","3c7773c4":"resized_train.shape","b00442de":"resized_train['labels'] = resized_train['labels'].apply(lambda s: s.split(' '))\nresized_train.head()","bcbcf4f8":"trans_label = MultiLabelBinarizer().fit(resized_train['labels'])\nlabels = pd.DataFrame(trans_label.transform(resized_train['labels']), columns=trans_label.classes_)\ntrain_df = pd.concat([resized_train['image'], labels], axis=1)\ntrain_df.head()","a3004d24":"resized_train","81d913fa":"import keras\ndatagen = keras.preprocessing.image.ImageDataGenerator(rescale=1\/255.0,\n                                                        preprocessing_function=None,\n                                                        data_format=None,\n                                                        validation_split= 0.2\n                                                    )","d3c03eb7":"train_data = datagen.flow_from_dataframe(\n    resized_train,\n    directory = '..\/input\/resized-plant2021\/img_sz_256',\n    x_col = 'image',\n    y_col = 'labels',\n    subset=\"training\",\n    color_mode=\"rgb\",\n    target_size = (224,224),\n    class_mode=\"categorical\",\n    batch_size=32,\n    shuffle=False,\n    seed=40,\n)","63268848":"valid_data = datagen.flow_from_dataframe(\n    resized_train,\n    directory = '..\/input\/resized-plant2021\/img_sz_256',\n    x_col = 'image',\n    y_col = 'labels',\n    subset=\"validation\",\n    color_mode=\"rgb\",\n    target_size = (224,224),\n    class_mode=\"categorical\",\n    batch_size=32,\n    shuffle=False,\n    seed=40,\n)","c16d0411":"from sklearn.preprocessing import MultiLabelBinarizer\nmlb = MultiLabelBinarizer()\nhot_labels = mlb.fit_transform(resized_train['labels'])\nprint(mlb.classes_)\nprint(hot_labels)","f9083fde":"df_labels = pd.DataFrame(hot_labels,columns=mlb.classes_,index=resized_train.index)\ndf_labels","cc688ff9":"plt.figure(figsize=(15,10))\nsns.barplot(x=df_labels.columns,y=df_labels.sum().values)","2c0689dd":"from keras.applications import InceptionResNetV2\nfrom keras.applications import MobileNetV2\nfrom keras.applications import DenseNet121\nfrom keras.applications import DenseNet169\n\nimport keras\nfrom keras.layers import Dense,Dropout,Flatten\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport tensorflow_addons as tfa\n\nweight_path='..\/input\/tf-keras-pretrained-model-weights\/No Top\/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5'\nbase_model=DenseNet169(weights=weight_path,include_top=False, input_shape=(224,224,3))\nx=base_model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(128,activation='relu')(x)\nx=Dropout(0.2)(x)\nx=Dense(64,activation='relu')(x)\npredictions=Dense(6,activation='sigmoid')(x)\n\nmodel=Model(inputs=base_model.input,outputs=predictions)\n\nfor layer in base_model.layers:\n    layer.trainable=False","96255e9d":"f1 = tfa.metrics.F1Score(num_classes=6,average='macro')\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy',f1])\nes=EarlyStopping(patience=4,monitor=f1,mode='max',restore_best_weights=True)\nhist = model.fit_generator(generator=train_data,\n                    validation_data=valid_data,\n                    epochs=20,\n                    steps_per_epoch=train_data.samples\/\/128,\n                    validation_steps=valid_data.samples\/\/128,\n                    callbacks=[es])","21b797e4":"model.layers[595:]","60f3ad86":"for layer in model.layers[:595]:\n    layer.trainable=False\n\nfor layer in model.layers[143:]:\n    layer.trainable=True\n\nfor layer in model.layers[595:]:\n    layer.trainable=False\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy',f1])\nhistory = model.fit_generator(generator=train_data,\n                    validation_data=valid_data,\n                    epochs=20,\n                    steps_per_epoch=train_data.samples\/\/128,\n                    validation_steps=valid_data.samples\/\/128,\n                    callbacks=[es])","c6315299":"plt.figure(figsize=(15,6))\nepoch_list = list(range(1, len(history.history['accuracy']) + 1))\nplt.plot(epoch_list, history.history['accuracy'],label='accuracy')\nplt.plot(epoch_list, history.history['val_accuracy'],label='val_accuracy')\nplt.legend()\nplt.show()","fe3526d7":"test_path=\"..\/input\/plant-pathology-2021-fgvc8\/sample_submission.csv\"\ntest = pd.read_csv(test_path)\ntest","18a8a3d9":"test_data = datagen.flow_from_dataframe(\n    test,\n    directory='..\/input\/plant-pathology-2021-fgvc8\/test_images',\n    x_col='image',\n    y_col=None,\n    color_mode='rgb',\n    target_size=(224,224),\n    class_mode=None,\n    shuffle=False\n)\npredictions = model.predict(test_data)\nprint(predictions)\n\nclass_idx=[]\nfor pred in predictions:\n    pred=list(pred)\n    temp=[]\n    for i in pred:\n        if (i>0.4):\n            temp.append(pred.index(i))\n    if (temp!=[]):\n        class_idx.append(temp)\n    else:\n        temp.append(np.argmax(pred))\n        class_idx.append(temp)\nprint(class_idx)\n","8851bb7a":"class_dict = train_data.class_indices\ndef get_key(val):\n    for key,value in class_dict.items():\n        if (val==value):\n            return key\nprint(class_dict)\n\nsub_pred=[]\nfor img_ in class_idx:\n    img_pred=[]\n    for i in img_:\n        img_pred.append(get_key(i))\n    sub_pred.append( ' '.join(img_pred))\nprint(sub_pred)","1daf1b21":"sub = test[['image']]\nsub['labels']=sub_pred\nsub","74ea4ae0":"sub.to_csv('submission.csv',index=False)","858cece3":"# Remove duplicates","04ee5edc":"# **DenseNet 169**"}}