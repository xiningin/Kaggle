{"cell_type":{"755a1969":"code","b93ab259":"code","a54fe3a6":"code","67a3719a":"code","afaee538":"code","fdfd4e4c":"code","49367599":"code","9288af0f":"code","34a723d5":"code","da2d1ad2":"code","ce924bc1":"code","58514dbc":"code","58fed629":"code","e5718ff5":"code","9b26506b":"code","bc6cca3e":"code","8797119b":"code","ec83fa96":"markdown","aa33e2e5":"markdown","2f4177b0":"markdown","8da52e33":"markdown","0bda0fc0":"markdown","c062e1cb":"markdown","622f0cf1":"markdown","342433e4":"markdown","ed1614cc":"markdown","04fe826e":"markdown"},"source":{"755a1969":"import os\nimport zipfile\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut","b93ab259":"# Reference: # https:\/\/www.kaggle.com\/rude009\/working-with-dicom-data\nimport pydicom as dicom","a54fe3a6":"# here we create a pd.df with each patient's id and the target (MGMT value)\nimport pandas as pd\ndata_directory = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'\ndf = pd.read_csv(f\"{data_directory}\/train_labels.csv\")","67a3719a":"def convert_BraTS21ID_to_string(df):\n    \n    patientID = []\n    for ID in df['BraTS21ID']:\n        patientID.append(str(ID))\n    df['BraTS21ID'] = patientID\n    \n    patientID2 = []\n    for ID in df['BraTS21ID']:\n        if len(ID)==1:\n            patientID2.append('0000'+ID)\n        elif len(ID)==2:\n            patientID2.append('000'+ID)\n        elif len(ID)==3:\n            patientID2.append('00'+ID)\n        elif len(ID)==4:\n            patientID2.append('0'+ID)\n        elif len(ID)==5:\n            patientID2.append(ID)\n            \n    df['BraTS21ID'] = patientID2\n    return df","afaee538":"df = convert_BraTS21ID_to_string(df)","fdfd4e4c":"df=df.drop(labels=71 , axis=0)\ndf=df.drop(labels=81 , axis=0)\ndf=df.drop(labels=488 , axis=0)","49367599":"# we create 2 dfs, one for MGMT=1 and another for MGMT=0\ndf_MGMT_1 = df.loc[df.MGMT_value == 1] #len = \ndf_MGMT_0 = df.loc[df.MGMT_value == 0] #len =","9288af0f":"# now, we define functions to load and stack the images\nfrom scipy import ndimage\nimport glob\nimport re\nimport cv2\n\nSIZE=128\ndef load_dicom_image(path, img_size=SIZE, voi_lut=True):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n        \n    data = cv2.resize(data, (img_size, img_size))\n    return data\n\nNUM_IMAGES = 64\ndef load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=SIZE, mri_type=\"FLAIR\", split=\"train\"):\n\n    files = sorted(glob.glob(f\"{data_directory}\/{split}\/{scan_id}\/{mri_type}\/*.dcm\"), \n               key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n\n    middle = len(files)\/\/2\n    num_imgs2 = num_imgs\/\/2\n    p1 = max(0, middle - num_imgs2)\n    p2 = min(len(files), middle + num_imgs2)\n    img3d = np.stack([load_dicom_image(f) for f in files[p1:p2]]).T \n    if img3d.shape[-1] < num_imgs:\n        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n        \n    if np.min(img3d) < np.max(img3d):\n        img3d = img3d - np.min(img3d)\n        img3d = img3d \/ np.max(img3d)\n            \n    return img3d","34a723d5":"# now we specify the geral directory and load one image\ndata_directory = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'","da2d1ad2":"# now, we define functions to apply transformations to the images (stacked images)\n\n# values of the array are between 0 and aprox. 2000\n\ndef normalize(volume):\n    \"\"\"Normalize the volume\"\"\"\n    minv = np.min(volume)\n    maxv = np.max(volume)\n    volume[volume < minv] = minv\n    volume[volume > maxv] = maxv\n    volume = (volume - minv) \/ (maxv - minv)\n    volume = volume.astype(\"float32\")\n    return volume\n\n\ndef resize_volume(img):\n    \"\"\"Resize across z-axis\"\"\"\n    # Set the desired depth\n    desired_depth = 64\n    desired_width = 128\n    desired_height = 128\n    # Get current depth\n    current_depth = img.shape[-1]\n    current_width = img.shape[0]\n    current_height = img.shape[1]\n    # Compute depth factor\n    depth = current_depth \/ desired_depth\n    width = current_width \/ desired_width\n    height = current_height \/ desired_height\n    depth_factor = 1 \/ depth\n    width_factor = 1 \/ width\n    height_factor = 1 \/ height\n    # Rotate\n    img = ndimage.rotate(img, 90, reshape=False)\n    # Resize across z-axis\n    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n    return img\n\ndef cropped_images(images):\n    min=np.array(np.nonzero(images)).min(axis=1)\n    max=np.array(np.nonzero(images)).max(axis=1)\n    return images[min[0]:max[0],min[1]:max[1],min[2]:max[2]]\n    \n# path= patient's ID\ndef process_scan(path):\n    \"\"\"Read and resize volume\"\"\"\n    # Read scan\n    volume = load_dicom_images_3d(path)\n    # Normalize\n    volume = normalize(volume)\n    # Resize width, height and depth\n    volume = cropped_images(volume)\n    \n    volume = resize_volume(volume)\n    \n    return volume","ce924bc1":"process_scan('00000').shape","58514dbc":"# reducing the amount of data to 200 scans per category\n\n# Read and process the scans.\n# Each scan is resized across height, width, and depth and rescaled.\nMGMT_scans = np.array([process_scan(path) for path in df_MGMT_1['BraTS21ID'][:200]])\nno_MGMT_scans = np.array([process_scan(path) for path in df_MGMT_0['BraTS21ID'][:200]])\n\n# For the MRI scans having presence of metylation\n# assign 1, for the normal ones assign 0.\nMGMT_labels = np.array([1 for _ in range(len(df_MGMT_1['BraTS21ID'][:200]))])\nno_MGMT_labels = np.array([0 for _ in range(len(df_MGMT_0['BraTS21ID'][:200]))])","58fed629":"# Split data in the ratio 70-30 for training and validation.\nx_train = np.concatenate((MGMT_scans[:140], no_MGMT_scans[:140]), axis=0)\ny_train = np.concatenate((MGMT_labels[:140], no_MGMT_labels[:140]), axis=0)\nx_val = np.concatenate((MGMT_scans[140:], no_MGMT_scans[140:]), axis=0)\ny_val = np.concatenate((MGMT_labels[140:], no_MGMT_labels[140:]), axis=0)\nprint(\n    \"Number of samples in train and validation are %d and %d.\"\n    % (x_train.shape[0], x_val.shape[0])\n)","e5718ff5":"x_train.shape","9b26506b":"os.makedirs(\"Dataset\")","bc6cca3e":"os.makedirs(\"x_train_dataset\")\nos.makedirs(\"y_train_dataset\")\nos.makedirs(\"x_val_dataset\")\nos.makedirs(\"y_val_dataset\")","8797119b":"x_train_path='\/kaggle\/working\/x_train_dataset'\nnp.save(x_train_path, x_train)\n\ny_train_path='\/kaggle\/working\/y_train_dataset'\nnp.save(y_train_path, y_train)\n\nx_val_path='\/kaggle\/working\/x_val_dataset'\nnp.save(x_val_path, x_val)\n\ny_val_path='\/kaggle\/working\/y_val_dataset'\nnp.save(y_val_path, y_val)","ec83fa96":"Now that we have store the transformed data into numpy tensors, wue proceed to save it to then create the tensor's dataset","aa33e2e5":"Since we have a big amount of images, we reduce the dataset, so it can fit to 16GB ram","2f4177b0":"We now define some functions to apply transformations to the images: normalization, resizing, cropping and dicom processing","8da52e33":"The FLAIR dataset is stored in the following kaggle Dataset:\nhttps:\/\/www.kaggle.com\/hugovallejo\/numpy-for-rsna-compet-flair","0bda0fc0":"# Dataframe with ID and MGMT value","c062e1cb":"# FLAIR images","622f0cf1":"As we have to predict the MGMT value, we create a df with these two columns to link the ID of each set of images with the MGMT value","342433e4":"# Transforming the Data","ed1614cc":"We now split the data to be then processed by CNN","04fe826e":"# Creating the dataset"}}