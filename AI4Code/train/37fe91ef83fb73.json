{"cell_type":{"7e65af43":"code","59fb7c4b":"code","2e3cb542":"code","990fe576":"code","161e36b1":"code","c9473867":"code","77cb8e80":"code","a13eece8":"code","58957f25":"code","608f1b88":"code","62204421":"code","b82f612d":"code","622b0fd0":"code","13083a44":"code","e2f5336b":"code","9a9edef0":"markdown","0e0184f0":"markdown","f1780aac":"markdown","c9c4fc68":"markdown","c22e2e32":"markdown","64cd6ceb":"markdown"},"source":{"7e65af43":"import numpy as np # linear algebra (Python's most common scientific computing library)\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split # sklearn is a machine learning library\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Import sklearn models\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_graphviz\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","59fb7c4b":"df = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/mwaskom\/seaborn-data\/master\/iris.csv\")\ndf[\"petal_area\"] = df.petal_width * df.petal_length\ndf[\"sepal_area\"] = df.sepal_width * df.sepal_length\ndf.head()","2e3cb542":"# For our modeling, X is the input variables to build a predictor\n# dropping the target variable: here, we drop the species column\nX = df.drop(['species'],axis=1)\nX.head()","990fe576":"# y is our target variable, we're trying to predict the species of future irises based on their measurements\n# target variable is the same as dependent variable\ny = df[['species']]\ny","161e36b1":"# Split our data into train and test\n# We train our algorithm on the training data (in-sample)\n# We evaluate our model on the test dataset (out of sample)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state = 123)\n\nX_train.head()","c9473867":"# for classification you can change the algorithm to gini or entropy (information gain).  Default is gini.\n# The pattern for sklearn is:\n# 1. Make a thing (a new, blank machine learning model of a specific kind)\n# 2. Fit the thing (.fitting means to train the machine learning model)\n# 3. Use the thing (we'll use our trained model to make predictions on future datapoints)\n\n# Set the max_depth to 3 (as a habit to start)\nclf = DecisionTreeClassifier(max_depth=3, random_state=123)\nclf","77cb8e80":"# The easiest part of the entire Data Science pipeline is fitting the machine learning model...\n# It's almost anticlimatic...\nclf.fit(X_train, y_train)","a13eece8":"# Produce a set of species predictions\n# Calculate the predicted probability that the prediction is correct\n\n# y_pred_proba = clf.predict_proba(X_train)\n\ny_pred = clf.predict(X_train)\ny_pred[0:5]","58957f25":"# y_train is actual\ny_train.head(5)","608f1b88":"# y_train is actual\n# y_pred are our predictions from our decision tree classifier\n# then accuracy of the model is # correct out of all observations\n\n(y_train.species == y_pred).mean()","62204421":"labels = sorted(y_train.species.unique())\npredicted_labels = [name + \" predicted\" for name in labels ]\n\nconf = pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=[predicted_labels])\nconf.index.name = \"actual\"\nconf","b82f612d":"# Accuracy = total number of (true positives + number of true negatives) divided by the total numbrer of observations\nprint('Accuracy of Decision Tree classifier on training set: {:.2f}'\n     .format(clf.score(X_train, y_train)))","622b0fd0":"# The model is a little less accurate on the test data, but 93% accuracy is pretty good!\nprint('Accuracy of Decision Tree classifier on test set: {:.2f}'\n     .format(clf.score(X_test, y_test)))","13083a44":"# Actual vs. predicted numbers on the test set!\n# y_prediction based on X_test\ny_pred = clf.predict(X_test)\n\nlabels = sorted(y_train.species.unique())\npredicted_labels = [name + \" predicted\" for name in labels ]\n\nconf = pd.DataFrame(confusion_matrix(y_test, y_pred), index=labels, columns=[predicted_labels])\nconf.index.name = \"actual\"\nconf","e2f5336b":"# The \"survived\" class is the target we're trying to predict based on other features\/columns\ntitanic = sns.load_dataset(\"titanic\")\ntitanic.head()","9a9edef0":"## Separating our dependent and independent variables\n- Dependent variable (that's the thing we're trying to predict) aka \"target variable\"\n- Independent variables are the features we'll use to try and make predictions of the target\n- Supervised learning, we're training a pattern recognition system to get better and better:\n    - at predicting the target variable accurately","0e0184f0":"# Welcome to \"Classification Intro\" a quick primer \n\nThis notebook is an introduction and primer on machine learning classification using a decision tree model.\n\n## Getting Started\n1. Create your own account on Kaggle.com\n2. Click the blue \"Copy and Edit\" in the upper-right part of this document to create your own copy to your own Kaggle account.\n3. As you complete exercises, be sure to click the blue \"Save\" button to create save points for your work.\n\n### Orientation:\n- This notebook is composed of cells. Each cell will contain text either or Python code.\n- To run the Python code cells, click the \"play\" button next to the cell or click your cursor inside the cell and do \"Shift + Enter\" on your keyboard. \n- Run the code cells in order from top to bottom, because order matters in programming and code.\n\n### Troubleshooting\n- If the notebook appears to not be working correctly, then restart this environment by going up to **Run** then select **Restart Session**. \n- If the notebook is running correctly, but you need a fresh copy of this original notebook, go to https:\/\/www.kaggle.com\/ryanorsinger\/data-basics and click \"Copy and Edit\" to make yourself a new copy.\n- Save frequently and save often, so you have access to all of your exercise solutions!","f1780aac":"## Get More Practice with Modeling\nUse what you've learned from the code above to work with the Titanic dataset. Can you build a decision tree that accurately predicts who would survive the Titanic disaster?","c9c4fc68":"## What kinds of questions can Data Science methods answer?\n- How Many or How Much of something (Regression)\n- **Is this observation A or B, or C or D or E... (Classification)**\n- What groupings exist in the data already (Clustering)\n- What should we expect to happen next? (Time Series Analysis)\n- Is this weird? (Anomaly Detection)\n\n## What are we doing?\n- We'll be using a decision tree classifier to predict the species\u00a0of an iris flower based on the measurement of its flowers.\n- Classification machine learning is used all the time for such things as:\n    - Facial recognition\n    - Handwriting recognition and conversion to typed text\n- Classification is a \"supervised learning\" type of machine learning. That means we train the algorithm on existing data to learn a rule, a recognized pattern, to apply to future data.\n\n![machine learning vs. classical programming](https:\/\/camo.githubusercontent.com\/fedd5d66bea57a430635498de58dc7c6f064f280\/68747470733a2f2f64707a6268796262327064636a2e636c6f756466726f6e742e6e65742f63686f6c6c65742f466967757265732f303166696730322e6a7067)\n\n## How does a decision tree work:\n- Classification algorithms use training data to measure the distance between points or the distance around boundaries between points.\n- By \"learning\" the pattern recognition around sets of points, the classifier produces a \"decision rule\" to use to apply to classify new incoming data.\n![decision tree diagram](https:\/\/raw.githubusercontent.com\/ryanorsinger\/machine-learning-classification-workshop\/master\/decision_tree_diagram.png)","c22e2e32":"## What to do next:\n- Use the steps above as a guide for how to break apart the features from the prediction column\n- Be sure to split your training and testing data\n- Train your data on the training set\n- Then evaluate your model based on the testing dataset.","64cd6ceb":"## Remember the Data Science Pipeline\n- Plan your project, what is a success? What's the most important thing? What are our initial hypotheses? What's the research question?\n- Acquire the raw data\n- Prepare the raw data (lot of data cleaning and validation)\n- Exploring the data (Visualizing and performing statistical tests)\n    - Goal of exploring: identify drivers or predictors of your target\n    - Identify and create derived columns, if they're helpful\n    - Statistical testing of our hypotheses\n- Modeling\n    - Build a ML model \n    - train it on training data\n    - then evaluate the accuracy of the model when making predictions on the test dataset"}}