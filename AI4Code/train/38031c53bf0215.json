{"cell_type":{"55c94038":"code","5f16a7c2":"code","03730823":"code","1c4420d7":"code","304afbf5":"code","a0f59fd5":"code","63917bb5":"code","4d9ec3d3":"code","dbba8fca":"code","05f11a48":"code","fd48efb7":"code","121333bb":"code","f2d66459":"code","f2d681f5":"code","46d111c7":"markdown"},"source":{"55c94038":"# Import Modules\nimport torch\nfrom torch import nn\n\nimport math\nimport matplotlib.pyplot as plt\nimport torchvision\nimport torchvision.transforms as transforms","5f16a7c2":"# Seed\ntorch.manual_seed(111)","03730823":"# Check for GPU availabilty\ndevice = \"\"\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\nelse:\n    device = torch.device(\"cpu\")","1c4420d7":"# Initalize transform\ntransform = transforms.Compose(\n    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n)","304afbf5":"# Download and assign training set\ntrain_set = torchvision.datasets.MNIST(\n    root=\".\", train=True, download=True, transform=transform\n)","a0f59fd5":"# Batch size and DataLoader\nbatch_size = 32\ntrain_loader = torch.utils.data.DataLoader(\n    train_set, batch_size=batch_size, shuffle=True\n)","63917bb5":"# Glimpse of th Dataset\nreal_samples, mnist_labels = next(iter(train_loader))\nfor i in range(16):\n    ax = plt.subplot(4, 4, i + 1)\n    plt.imshow(real_samples[i].reshape(28, 28), cmap=\"gray_r\")\n    plt.xticks([])\n    plt.yticks([])","4d9ec3d3":"# Discriminator Class\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n        nn.Linear(784, 1024),\n        nn.ReLU(),\n        nn.Dropout(0.3),\n        nn.Linear(1024, 512),\n        nn.ReLU(),\n        nn.Dropout(0.3),\n        nn.Linear(512, 256),\n        nn.ReLU(),\n        nn.Dropout(0.3),\n        nn.Linear(256, 1),\n        nn.Sigmoid(),\n        )\n        \n    def forward(self, x):\n        x = x.view(x.size(0), 784)\n        output = self.model(x)\n        return output","dbba8fca":"# Initialize discriminator\ndiscriminator = Discriminator().to(device=device)","05f11a48":"# Generator Class\nclass Generator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n        nn.Linear(100, 256),\n        nn.ReLU(),\n        nn.Linear(256, 512),\n        nn.ReLU(),\n        nn.Linear(512, 1024),\n        nn.ReLU(),\n        nn.Linear(1024, 784),\n        nn.Tanh(),\n        )\n        \n    def forward(self, x):\n        output = self.model(x)\n        output = output.view(x.size(0), 1, 28, 28)\n        return output\n    \n# Initialize Generator\ngenerator = Generator().to(device=device)","fd48efb7":"# Set tuning parameters\nlr = 0.0001\nnum_epochs = 40\nloss_function = nn.BCELoss()\n\noptimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\noptimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)","121333bb":"# Model Training\nfor epoch in range(num_epochs):\n    for n, (real_samples, mnist_labels) in enumerate(train_loader):\n        \n        real_samples = real_samples.to(device=device)\n        real_samples_labels = torch.ones((batch_size, 1)).to(device=device)\n        latent_space_samples = torch.randn((batch_size, 100)).to(device=device)\n        generated_samples = generator(latent_space_samples)\n        generated_samples_labels = torch.zeros((batch_size, 1)).to(device=device)\n        all_samples = torch.cat((real_samples, generated_samples))\n        all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n        \n        discriminator.zero_grad()\n        output_discriminator = discriminator(all_samples)\n        loss_discriminator = loss_function(output_discriminator, all_samples_labels)\n        loss_discriminator.backward()\n        optimizer_discriminator.step()\n        \n        latent_space_samples = torch.randn((batch_size, 100)).to(device=device)\n        \n        generator.zero_grad()\n        generated_samples = generator(latent_space_samples)\n        output_discriminator_generated = discriminator(generated_samples)\n        loss_generator = loss_function(output_discriminator_generated, real_samples_labels)\n        loss_generator.backward()\n        optimizer_generator.step()\n        \n        if n == batch_size - 1:\n            print(f\"Epoch: {epoch} Loss D.: {loss_discriminator}\")\n            print(f\"Epoch: {epoch} Loss G.: {loss_generator}\")","f2d66459":"# Random samples\nlatent_space_samples = torch.randn(batch_size, 100).to(device=device)\ngenerated_samples = generator(latent_space_samples)","f2d681f5":"# Output\ngenerated_samples = generated_samples.cpu().detach()\nfor i in range(16):\n    ax = plt.subplot(4, 4, i + 1)\n    plt.imshow(generated_samples[i].reshape(28, 28), cmap=\"gray_r\")\n    plt.xticks([])\n    plt.yticks([])","46d111c7":"**MNIST_GAN**\n\nA GAN(Generative Adversarial Network) trained on the MNIST dataset to generate images of handwritten digits."}}