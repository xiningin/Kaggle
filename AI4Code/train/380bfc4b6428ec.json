{"cell_type":{"e4f1d1ed":"code","40fe530b":"code","5a831e84":"code","4d95d3b9":"code","83c5ad2a":"code","05752433":"code","d69b2ba8":"code","07475ed2":"code","67319189":"code","12cda72f":"code","1577e33e":"code","dfc949ce":"code","5de510d5":"code","b72be526":"code","852ff323":"code","8016df7f":"code","ba08401c":"code","07e23da7":"code","49925be8":"code","e50b062b":"code","296b1b88":"code","96bd930b":"code","6c364842":"code","f9bee2e4":"code","46519ac3":"markdown","d8e96398":"markdown","e1acb6b4":"markdown"},"source":{"e4f1d1ed":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","40fe530b":"train = pd.read_csv('\/kaggle\/input\/cat-in-the-dat-ii\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/cat-in-the-dat-ii\/test.csv')","5a831e84":"train.head()","4d95d3b9":"train_id = train['id']\ntest_id = test['id']\ntarget = train['target']\ntrain.drop(['target','id'],axis=1,inplace=True)\ntest.drop('id',axis=1,inplace=True)\ntrain_test_set = pd.concat([train,test]) \n\n","83c5ad2a":"train_test_set.shape","05752433":"dummy = pd.get_dummies(train_test_set,columns=train_test_set.columns,drop_first=True,sparse=True)","d69b2ba8":"train_ohe = dummy.iloc[:train.shape[0],:]\ntest_ohe = dummy.iloc[train.shape[0]:, :]\n\ntrain_ohe = train_ohe.sparse.to_coo().tocsr()\ntest_ohe = test_ohe.sparse.to_coo().tocsr()","07475ed2":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression","67319189":"train_x,test_x,train_y,test_y = train_test_split(train_ohe,target,test_size = 0.25)","12cda72f":"LR = LogisticRegression(C=0.1,max_iter=1000)","1577e33e":"LR.fit(train_x,train_y)","dfc949ce":"y_pred = LR.predict(test_x)","5de510d5":"from sklearn.metrics import roc_auc_score as auc\nscore = auc(test_y,y_pred)","b72be526":"print(score)","852ff323":"LR.fit(train_ohe,target)","8016df7f":"y_pred2 = LR.predict(test_ohe)","ba08401c":"sub_df = pd.DataFrame({'id': test_id, 'target' : y_pred2})\nsub_df.to_csv(\"LR_pred.csv\",index=False)","07e23da7":"from sklearn.model_selection import cross_val_score\nLR_accuracies = cross_val_score(estimator = LR, X = train_ohe, y = target, cv = 10)\nprint(\"Mean_LR_Acc : \", LR_accuracies.mean())","49925be8":"from sklearn.model_selection import cross_val_predict\ny = target[:test_ohe.shape[0]]\ny_pred_2 = y_pred = cross_val_predict(LR, test_ohe, y, cv=2)","e50b062b":"sub_df_1 = pd.DataFrame({'id': test_id, 'target' : y_pred_2})\nsub_df_1.to_csv(\"LR_pred_2.csv\",index=False)","296b1b88":"from category_encoders.leave_one_out import LeaveOneOutEncoder\nLOOE_encoder = LeaveOneOutEncoder()\ntrain_looe = LOOE_encoder.fit_transform(train, target)\ntest_looe = LOOE_encoder.transform(test)","96bd930b":"from sklearn.impute import SimpleImputer\n\nmy_imputer = SimpleImputer()\nimputed_X_train = my_imputer.fit_transform(train_looe)\nimputed_X_test = my_imputer.transform(test_looe)","6c364842":"from sklearn.metrics import roc_auc_score as auc\nt_X,t_x,t_Y,t_y = train_test_split(imputed_X_train,target,test_size=0.25)\nLR.fit(t_X,t_Y)\nY_p_x = LR.predict(t_x)\nprint(auc(Y_p_x,t_y))","f9bee2e4":"y_test_pred = LR.predict(imputed_X_test)\nsub_df = pd.DataFrame({'id': test_id, 'target' : y_test_pred})\nsub_df.to_csv(\"LR_pred_3.csv\",index=False)","46519ac3":"As most of the data is in 0's and 1's format OneHot Encoding can be used for catagorical encoding ","d8e96398":"We tried to increase the score by cross validating the process","e1acb6b4":"But before encoding we need to pass to clean and arrange it for the encoding."}}