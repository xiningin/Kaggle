{"cell_type":{"8c02d8c0":"code","9e5f64a3":"code","7c41d081":"code","09c1025e":"code","9d4017c6":"code","63ef7907":"code","b16ec262":"code","3dbcdbf1":"code","6c53c8bc":"code","35fee015":"code","808612e5":"code","af7bf2f8":"code","ed93f32c":"code","a12cd9c9":"code","6fb6ea96":"code","8b97a41d":"code","a8c98b06":"code","a6496e79":"code","6ec09131":"markdown","08abbe55":"markdown","9976c4db":"markdown","6a59cceb":"markdown","70731634":"markdown","a2586adf":"markdown","bc8cda3d":"markdown","2871622d":"markdown","c7071f97":"markdown","ad44f179":"markdown","fd6cb828":"markdown","29c80b46":"markdown","b24d5064":"markdown","880b9e68":"markdown","0403289c":"markdown","8a7b9d49":"markdown","69f8c90e":"markdown"},"source":{"8c02d8c0":"import numpy as np\nimport pandas as pd\nfrom prettytable import PrettyTable\n\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\n\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.express import colors","9e5f64a3":"def data_quality_report(data, labels):\n    \"\"\"\n    Prints out feature charasteristics of the dataset\n    \n    data: pandas.Dataframe object\n    labels: dict of two keys \"categorical\" and \"continuous\" with corresponding lists of feature names\n\n    labels = {\n        \"continuous\": [\"feature_name1\", \"feature_name2\"],\n        \"categorical\": [\"feature_name3\", \"feature_name4\"]\n    }\n    \"\"\"\n    \n    print(\"Continuous Features\")\n    table_cont = PrettyTable()\n    table_cont.field_names = [\"Feature\", \"Cnt\", \"Miss %\", \"Card\", \"Min\", \"1st Qrt\", \"Mean\", \"Median\", \"3rd Qrt\", \"Max\", \"Std\"]\n    \n    for feature in labels[\"continuous\"]:\n        \n        count = data[feature].count()\n        missed = round(data[feature].isna().sum() \/ count, 3)\n        cardinality = data[feature].nunique()\n        _min = round(data[feature].min(), 3)\n        qrt1 = round(data[feature].quantile(q = 0.25), 3)\n        mean = round(data[feature].mean(), 3)\n        median = round(data[feature].median(), 3)\n        qrt3 = round(data[feature].quantile(q = 0.75), 3)\n        _max = round(data[feature].max(), 3)\n        std = round(data[feature].std(), 3)\n        \n        table_cont.add_row([feature, count, missed, cardinality, _min, qrt1, mean, median, qrt3, _max, std])\n    print(table_cont)\n    \n    print(\"Categorical Features\")\n    table_cat = PrettyTable()\n    table_cat.field_names = [\"Feature\", \"Cnt.\", \"Miss%\", \"Card.\", \"Mode\", \"Mode Freq.\", \"2nd Mode\", \"2nd Mode Freq.\"]\n    \n    for feature in labels[\"categorical\"]:\n        \n        count = data[feature].count()\n        missed = round(data[feature].isna().sum() \/ count, 3)\n        cardinality = data[feature].nunique()\n        mode = data[feature].mode()[0]\n        mode_freq = round(data[feature].eq(mode).sum() \/ count, 3)\n        mode2 = data[feature][data[feature].ne(mode)].mode()[0]\n        mode2_freq = round(data[feature].eq(mode2).sum() \/ count, 3)\n        \n        table_cat.add_row([feature, count, missed, cardinality, mode, mode_freq, mode2, mode2_freq])\n    print(table_cat)","7c41d081":"def plot_distributions(data, labels):\n    \"\"\"\n    Plots distributions of features\n    \n    data: pandas.Dataframe object\n    labels: dict of two keys \"categorical\" and \"continuous\" with corresponding lists of feature names\n    \"\"\"\n    \n    color = colors.qualitative.Dark24[0]\n        \n    num_cols = 3\n    num_rows = (len(labels[\"continuous\"]) + 2) \/\/ 3\n    vert_spacing = 0.3 \/ num_rows\n    horiz_spacing = 0.3 \/ num_cols\n    fig_cont = make_subplots(rows = num_rows, cols = num_cols, subplot_titles = labels[\"continuous\"], vertical_spacing = vert_spacing, horizontal_spacing = horiz_spacing)\n        \n    for row, feature in enumerate(labels[\"continuous\"]):\n        data_feature = data[feature].value_counts()\n        x = data_feature.keys()\n        y = data_feature.values\n        if len(x) > 30:\n            histogram = go.Histogram(x = x, y = y, name = feature, marker = dict(color = color))\n        else:\n            histogram = go.Bar(x = x, y = y, name = feature, marker = dict(color = color))\n        fig_cont.add_trace(histogram, row = row \/\/ 3 + 1, col = row % 3 + 1)\n    fig_cont.update_layout(barmode='stack', height = 100*(len(labels[\"continuous\"]) + 1), bargap = 0.2, showlegend = False, title = \"Continuous features\")\n    fig_cont.show()\n    \n    num_rows = (len(labels[\"categorical\"]) + 2) \/\/ 3\n    vert_spacing = 0.4 \/ num_rows\n    horiz_spacing = 0.3 \/ num_cols\n    fig_cat = make_subplots(rows = num_rows, cols = num_cols, subplot_titles = labels[\"categorical\"], vertical_spacing = vert_spacing, horizontal_spacing = horiz_spacing)\n    \n    for row, feature in enumerate(labels[\"categorical\"]):\n        data_feature = data[feature].value_counts()\n        x = data_feature.keys()\n        y = data_feature.values\n        bar = go.Bar(x = x, y = y, name = feature, marker = dict(color = color))\n        fig_cat.add_trace(bar, row = row \/\/ 3 + 1, col = row % 3 + 1)\n    fig_cat.update_layout(barmode='stack', height = 100*(len(labels[\"categorical\"]) + 1), bargap = 0.2, showlegend = False, title = \"Categorical features\")\n    fig_cat.show()","09c1025e":"def plot_clusters_distributions(data, labels, clustering):\n    \"\"\"\n    Plots stacked barplots and density curves of feature distributions for given clusters\n    \n    data: pandas.Dataframe object\n    labels: dict of two keys \"categorical\" and \"continuous\" with corresponding lists of feature names\n    clustering: numpy.ndarray object with the length of rows amount in the data with clusters' ids\n    \"\"\"\n    palette = colors.qualitative.Dark24\n    data[\"CL_ID\"] = clustering\n    clusters_id = np.unique(clustering)\n    \n    num_cols = 3\n    num_rows = (len(labels[\"continuous\"]) + 2) \/\/ 3\n    vert_spacing = 0.3 \/ num_rows\n    horiz_spacing = 0.3 \/ num_cols\n    fig_cont = make_subplots(rows = num_rows, cols = num_cols, subplot_titles = labels[\"continuous\"], vertical_spacing = vert_spacing, horizontal_spacing = horiz_spacing)\n        \n    for i, feature in enumerate(labels[\"continuous\"]):\n        x = data[feature].value_counts().keys()\n        y = data[feature].value_counts().values\n        if len(x) > 10:\n            clusters = [data[data[\"CL_ID\"] == cl][feature] for cl in clusters_id]\n            distplots = ff.create_distplot(clusters, group_labels = clusters_id.astype(str), colors = palette, show_hist = False, show_rug = False)\n            for dp in distplots.data:\n                fig_cont.add_trace(dp, row = i \/\/ 3 + 1, col = i % 3 + 1)\n        else:\n            clusters = [data[data[\"CL_ID\"] == cl][feature] for cl in clusters_id]\n            for j, cluster in data.groupby(\"CL_ID\"):\n                x = cluster[feature].value_counts().keys()\n                y = cluster[feature].value_counts().values\n                bar = go.Bar(x = x, y = y, name = feature, marker = dict(color = palette[j]))\n                fig_cont.add_trace(bar, row = i \/\/ 3 + 1, col = i % 3 + 1)\n    fig_cont.update_layout(barmode = 'stack', height = 100*(len(labels[\"continuous\"]) + 1), showlegend = False, title = \"Continuous features\")\n    fig_cont.show()\n    \n    num_rows = (len(labels[\"categorical\"]) + 2) \/\/ 3\n    vert_spacing = 0.4 \/ num_rows\n    horiz_spacing = 0.3 \/ num_cols\n    fig_cat = make_subplots(rows = num_rows, cols = num_cols, subplot_titles = labels[\"categorical\"], vertical_spacing = vert_spacing, horizontal_spacing = horiz_spacing)\n    \n    for i, feature in enumerate(labels[\"categorical\"]):\n        clusters = [data[data[\"CL_ID\"] == cl][feature] for cl in clusters_id]\n        for j, cluster in data.groupby(\"CL_ID\"):\n            x = cluster[feature].value_counts().keys()\n            y = cluster[feature].value_counts().values\n            bar = go.Bar(x = x, y = y, name = feature, marker = dict(color = palette[j]))\n            fig_cat.add_trace(bar, row = i \/\/ 3 + 1, col = i % 3 + 1)\n    fig_cat.update_layout(barmode = 'stack', height = 100*(len(labels[\"categorical\"]) + 1), bargap = 0.2, showlegend = False, title = \"Categorical features\")\n    fig_cat.show()","9d4017c6":"def compare_clusters(data, embeddings, labels, clustering):\n    \"\"\"\n    Plots scatterplot of embeddings, stacked barplots and density curves of feature distributions for given clusters\n    \n    data: pandas.Dataframe object\n    embeddings: 2D embeddings of the data\n    labels: dict of two keys \"categorical\" and \"continuous\" with corresponding lists of feature names\n    clustering: numpy.ndarray object with the length of rows amount in the data with clusters' ids\n    \"\"\"\n    clustering = adjust_cluster_indices(clustering)\n    palette = [colors.qualitative.Dark24[id_c % 24] for id_c in clustering]\n    infos = [f\"ID = {data.values[i, 0]}, cluster = {cl}\" for i, cl in enumerate(clustering)]\n    fig = go.Figure(data = go.Scatter(x = embeddings[:, 0], y = embeddings[:, 1], mode = \"markers\", marker = dict(color = palette), hovertext = infos))\n    fig.show()\n    plot_clusters_distributions(data, labels, clustering)","63ef7907":"def adjust_cluster_indices(clustering):\n    \"\"\"\n    Returns numpy.ndarray object with indices corresponding to the enumeration of sorted unique values\n    This makes coloring compatible with the one used in the plot_clusters_distribution function \n    \n    clustering: numpy.ndarray object with the length of rows amount in the data with clusters' ids\n    \"\"\"\n    indices = np.unique(clustering, return_index=True)[1]\n    un_cl = [clustering[index] for index in sorted(indices)]\n    cl_i = {v:i for i,v in enumerate(un_cl)}\n    return [cl_i[i] for i in clustering]","b16ec262":"data = pd.read_csv(\"\/kaggle\/input\/customer-personality-analysis\/marketing_campaign.csv\", delimiter = '\\t')\ndata.head()","3dbcdbf1":"data.info()","6c53c8bc":"labels = {\n    \"continuous\": [\"Year_Birth\", \"Income\", \"Recency\", \"MntWines\", \"MntFruits\", \"MntMeatProducts\", \"MntFishProducts\", \"MntSweetProducts\", \"MntGoldProds\", \"NumDealsPurchases\", \"NumWebPurchases\", \"NumCatalogPurchases\", \"NumStorePurchases\", \"NumWebVisitsMonth\", \"Z_Revenue\", \"Z_CostContact\"],\n    \"categorical\": [\"Education\", \"Marital_Status\", \"Kidhome\", \"Teenhome\", \"Complain\", \"AcceptedCmp1\", \"AcceptedCmp2\", \"AcceptedCmp3\", \"AcceptedCmp4\", \"AcceptedCmp5\", \"Response\", \"Dt_Customer\"] \n}","35fee015":"data_quality_report(data, labels)","808612e5":"plot_distributions(data, labels)","af7bf2f8":"data = data[data[\"Year_Birth\"] > 1920]\n\ndata = data.dropna()\n\ndata = data[data[\"Income\"] < 600000]\n\ndata = data.drop([\"Z_Revenue\", \"Z_CostContact\"], axis = 1)\n\ndata[\"Marital_Status\"] = data[\"Marital_Status\"].replace({\"Alone\": \"Single\", \"YOLO\": \"Single\", \"Absurd\": \"Single\"})\n\ndata[\"Dt_Customer\"] = pd.to_datetime(data[\"Dt_Customer\"])","ed93f32c":"data[\"Age\"] = 2015 - data[\"Year_Birth\"]\n\ndata[\"MntSpent\"] = data[\"MntWines\"] + data[\"MntFruits\"] + data[\"MntMeatProducts\"] + data[\"MntFishProducts\"] + data[\"MntSweetProducts\"] + data[\"MntGoldProds\"]\ndata[\"NumPurchases\"] = data[\"NumWebPurchases\"] + data[\"NumCatalogPurchases\"] + data[\"NumStorePurchases\"]\ndata[\"AvgPurchase\"] = data[\"MntSpent\"] \/ data[\"NumPurchases\"]\n\ndata[\"Living_With\"] = data[\"Marital_Status\"].replace({\"Married\":\"Partner\", \"Together\":\"Partner\", \"Widow\":\"Single\", \"Divorced\":\"Single\"})\ndata[\"Children\"] = data[\"Kidhome\"] + data[\"Teenhome\"]\ndata[\"Family_Size\"] = data[\"Living_With\"].replace({\"Single\":1, \"Partner\":2}) + data[\"Children\"]\n\ndata[\"NumAccepted\"] = data[\"AcceptedCmp1\"] + data[\"AcceptedCmp2\"] + data[\"AcceptedCmp3\"] + data[\"AcceptedCmp4\"] + data[\"AcceptedCmp5\"] + data[\"Response\"]\n\ndata[\"Education\"] = data[\"Education\"].replace({\"2n Cycle\" : \"Post Graduate\", \"Master\" : \"Post Graduate\", \"PhD\" : \"Post Graduate\", \"Basic\" : \"Graduate and Basic\", \"Graduation\": \"Graduate and Basic\"})\n\ndata[\"WinesPerc\"] = data[\"MntWines\"] \/ data[\"MntSpent\"]\ndata[\"FruitsPerc\"] = data[\"MntFruits\"] \/ data[\"MntSpent\"]\ndata[\"MeatPerc\"] = data[\"MntMeatProducts\"] \/ data[\"MntSpent\"]\ndata[\"FishPerc\"] = data[\"MntFishProducts\"] \/ data[\"MntSpent\"]\ndata[\"SweetPerc\"] = data[\"MntSweetProducts\"] \/ data[\"MntSpent\"]\ndata[\"GoldPerc\"] = data[\"MntGoldProds\"] \/ data[\"MntSpent\"]\n\ndata[\"WebPerc\"] = data[\"NumWebPurchases\"] \/ data[\"NumPurchases\"]\ndata[\"CatalogPerc\"] = data[\"NumCatalogPurchases\"] \/ data[\"NumPurchases\"]\ndata[\"StorePerc\"] = data[\"NumStorePurchases\"] \/ data[\"NumPurchases\"]\n\ndata = data.replace(np.inf, None).fillna(0)","a12cd9c9":"labels_new = {\n    \"continuous\": [\"Age\", \"MntSpent\", \"NumPurchases\", \"AvgPurchase\", \"Kidhome\", \"Teenhome\", \"Children\", \"Family_Size\", \"NumAccepted\", \"Income\", \"WinesPerc\", \"FruitsPerc\", \"MeatPerc\", \"FishPerc\", \"SweetPerc\", \"GoldPerc\", \"NumDealsPurchases\", \"WebPerc\", \"CatalogPerc\", \"StorePerc\", \"NumWebVisitsMonth\"],\n    \"categorical\": [\"Education\", \"Living_With\"]\n}\ndata_new = data.loc[:, labels_new[\"continuous\"]].join(data.loc[:, labels_new[\"categorical\"]])","6fb6ea96":"x = pd.get_dummies(data_new, columns = labels_new[\"categorical\"], drop_first = True)","8b97a41d":"for feature in x.columns:\n    x[feature] = (x[feature] - x[feature].mean()) \/ x[feature].std()","a8c98b06":"x_embedded = TSNE(n_components = 2, init = 'random').fit_transform(x)\nfig = go.Figure(data = go.Scatter(x = x_embedded[:, 0], y = x_embedded[:, 1], mode = \"markers\"))\nfig.show()","a6496e79":"clustering_KMeans = KMeans(n_clusters = 4).fit_predict(x_embedded)\ncompare_clusters(data_new, x_embedded, labels_new, clustering_KMeans)","6ec09131":"### Distribution plots","08abbe55":"# Data Preparation","9976c4db":"### Writing functions","6a59cceb":"### Analysis\n\n#### Cluster 0 (blue):\n- span all ages\n- high income, high average purchase and number of purchases\n- couples (mostly) and singles without kids\n- most likely to accept campaign offers\n- average shopping cart\n    - wine: medium\n    - fruits: medium\n    - meat: high\n    - fish: medium\n    - sweets: medium\n    - gold: low\n- low discount activity\n- mostly catalog purchases, low website activity\n\n#### Cluster 1 (pink):\n- medium (mostly) and older age\n- second to lowest income, low purchase activity\n- two and more kids, sometimes single parent\n- least likely to accept campaign offers\n- average shopping cart\n    - wine: medium to high\n    - fruits: low\n    - meat: medium\n    - fish: low\n    - sweets: low\n    - gold: medium\n- high discount activity\n- mostly website and store purchases\n\n#### Cluster 2 (green):\n- young to medium age\n- lowest income, low purchase activity\n- mostly couples and single parents with a kid\n- average shopping cart\n    - wine: low\n    - fruits: high\n    - meat: medium\n    - fish: high\n    - sweets: high\n    - gold: high\n- medium discount activity\n- mostly website and store purchases\n\n#### Cluster 3 (red):\n- medium to older age\n- medium income and purchase activity\n- couples (mostly) and single parents with a teenager\n- average shopping cart\n    - wine: high\n    - fruits: low to medium\n    - meat: low\n    - fish: low\n    - sweets: low\n    - gold: low to medium\n- medium discount activity","70731634":"### One-Hot Encoding","a2586adf":"### Data Cleaning","bc8cda3d":"### Standartization","2871622d":"| Feature             | Data Quality Issue                               | Possible Handling Strategies                    |\n|---------------------|--------------------------------------------------|-------------------------------------------------|\n| Year_Birth          | Outliers, most likely invalid                    | Remove records because the percentage is low    |\n| Income              | Missing values                                   | Remove records because the percentage is low    |\n| Income              | Outliers                                         | Income value 666666 is most likely an invalid outlier, remove<br>All the other outliers might be valid, do nothing                    |\n| MntMeatProducts     | Outliers, most likely valid                      | Do nothing                                      |\n| MntSweetProducts    | Outliers, most likely valid                      | Do nothing                                      |\n| MntGoldProds        | Outliers, most likely valid                      | Do nothing                                      |\n| NumWebPurchases     | Outliers, most likely valid                      | Do nothing                                      |\n| NumCatalogPurchases | Outliers, most likely valid                      | Do nothing                                      |\n| NumWebVisitsMonth   | Outliers, most likely valid                      | Do nothing                                      |\n| Z_Revenue           | Cardinality is 1                                 | Remove the feature                              |\n| Z_CostContact       | Cardinality is 1                                 | Remove the feature                              |\n| Marital_Status      | Duplicate category \"Alone\"                       | Replace with the \"Single\" category              |\n| Marital_Status      | Invalid category \"YOLO\"                          | Replace with the \"Single\" category              |\n| Marital_Status      | Invalid category \"Absurd\"                        | Replace with the \"Single\" category              |\n| Dt_Customer         | Is not parsed as DateTime                        | Convert to DateTime                             |\n\nIn a real world, it would be better to investigate further if outliers are valid or invalid and then act respectively.","c7071f97":"# Data Exploration","ad44f179":"- Age \u2014 customer's age as of 2015 (because the newest Dt_Customer entry is of 2014 and it's unlikely that a business hadn't had new customers in seven years)\n- MntSpent \u2014 customer lifetime value (MntWines + MntFruits + MntMeatProducts + MntFishProducts + MntSweetProducts + MntGoldProds)\n- NumPurchases \u2014 overall number of purchases made (NumWebPurchases + NumCatalogPurchases + NumStorePurchases)\n- AvgPurchase \u2014 average purchase cost (MntSpent \/ NumPurchases)\n- PurchFreq \u2014 average amount of purchases made during customer lifetime\n- Living_With \u2014 with a partner or single\n- Children \u2014 total amount of children in a household (Kidhome + Teenhome)\n- Family_Size \u2014 total amount of people in a household\n- NumAccepted \u2014 total amount of offers accepted during campaigns (AcceptedCmp1 + AcceptedCmp2 + AcceptedCmp3 + AcceptedCmp4 + AcceptedCmp5 + Response)\n- Education \u2014 reduce the number of categories to two: \"Basic and Graduate\" and \"Post Graduate\"\n- WinesPerc \u2014 proportion of amount spent on wine out of all purchases (MntWines \/ MntSpent)\n- FruitsPerc \u2014 proportion of amount spent on fruits out of all purchases (MntFruits \/ MntSpent)\n- MeatPerc \u2014 proportion of amount spent on meat out of all purchases (MntMeatProducts \/ MntSpent)\n- FishPerc \u2014 proportion of amount spent on fish out of all purchases (MntFishProducts \/ MntSpent)\n- SweetPerc \u2014 proportion of amount spent on sweets out of all purchases (MntSweetProducts \/ MntSpent)\n- GoldPerc \u2014 proportion of amount spent on gold out of all purchases (MntGoldProds \/ MntSpent)\n- WebPerc \u2014 proportion of purchases made through website out of all purchases (NumWebPurchases \/ NumPurchases)\n- CatalogPerc \u2014 proportion of purchases made using a catalog out of all purchases (NumCatalogPurchases \/ NumPurchases)\n- StorePerc \u2014 proportion of purchases made directly in stores out of all purchases (NumStorePurchases \/ NumPurchases)","fd6cb828":"### Embeddings","29c80b46":"### Importing libraries","b24d5064":"# Clustering","880b9e68":"### Data Quality Plan","0403289c":"### KMeans","8a7b9d49":"### Data Quality Report","69f8c90e":"### Feature Engineering"}}