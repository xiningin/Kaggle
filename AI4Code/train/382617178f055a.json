{"cell_type":{"efa5d6e2":"code","7457362c":"code","f64c1e82":"code","304465b5":"code","a2ee12bf":"code","f656bb9c":"code","7e425a45":"code","952fed1c":"code","b2a63b6f":"code","1c0cae6e":"code","4e32fb3b":"code","8f990848":"code","1869249c":"code","654a9d31":"code","e703ec22":"code","8964b2c7":"code","5209d44d":"code","458e5148":"code","b51fc7ff":"code","8ed47702":"code","5e4014db":"code","f03d33c8":"code","24a8ce47":"code","6cbbcf7e":"code","9c4455a9":"markdown"},"source":{"efa5d6e2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nsns.set(style='white', palette='dark')\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7457362c":"#Importing Dataset\ndf = pd.read_csv('\/kaggle\/input\/employee-salary\/Employee_Salary.csv')\ndf","f64c1e82":"#Analysing dataset with padas profiling\nfrom pandas_profiling import ProfileReport\nprofile = ProfileReport(df, title='Employee Salary Datasets', html={'style':{'full_width':True}})","304465b5":"profile","a2ee12bf":"#Dataset statistic\ndf.describe()","f656bb9c":"#Dataset info\ndf.info()","7e425a45":"#Plotting dataset\nfig = plt.figure(figsize=(10,10))\nax = fig.add_subplot(1,1,1)\nax.scatter(df['Years of Experience'].values, df['Salary'].values,marker='o', color='r', alpha=1, linewidth=1, \n            edgecolor='k')\nax.set_title('Relationship between Year of Experience x Salary', fontsize=15)\nax.set_xlabel(df.columns[0], fontsize=15)\nax.set_ylabel(df.columns[1], fontsize=15)\nax.grid(b=True, which='major', linestyle='--')\nax.tick_params(axis='both', labelsize=15, labelcolor='k')\nplt.tight_layout(0)","952fed1c":"#Splitting Data\nX=df.drop('Salary', axis=1)\ny=df['Salary']","b2a63b6f":"#Splitting the Dataset into the training set and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\nX_train.shape, X_test.shape, y_train.shape,y_test.shape","1c0cae6e":"#Feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nX_train = pd.DataFrame(sc_x.fit_transform(X_train), columns=X.columns.values)\nX_test = pd.DataFrame(sc_x.transform(X_test), columns=X.columns.values)","4e32fb3b":"## Multiple Linear Regression Regression\nfrom sklearn.linear_model import LinearRegression\nlr_regressor = LinearRegression(fit_intercept=True)\nlr_regressor.fit(X_train, y_train)\n\nprint('Linear Model Coefficient (m): ', lr_regressor.coef_)\nprint('Linear Model Coefficient (b): ', lr_regressor.intercept_)\n\n# Predicting Test Set\ny_pred = lr_regressor.predict(X_test)\n\nplt.scatter(X_train, y_train, color = 'gray')\nplt.plot(X_train, lr_regressor.predict(X_train), color = 'red')\nplt.ylabel('{} ($)'.format(df.columns[1]))\nplt.xlabel('{}'.format(df.columns[0]))\nplt.title('Employee Salary (Training dataset)')\n\nplt.scatter(X_test, y_test, color = 'gray')\nplt.plot(X_test, lr_regressor.predict(X_test), color = 'red')\nplt.ylabel('{} ($)'.format(df.columns[1]))\nplt.xlabel('{}'.format(df.columns[0]))\nplt.title('Employee Salary (Test dataset)')","8f990848":"plt.scatter(X_test, y_test, color = 'gray')\nplt.plot(X_test, lr_regressor.predict(X_test), color = 'red')\nplt.ylabel('{} ($)'.format(df.columns[1]))\nplt.xlabel('{}'.format(df.columns[0]))\nplt.title('Employee Salary (Test dataset)')","1869249c":"from sklearn import metrics\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nresults = pd.DataFrame([['Multiple Linear Regression', mae, mse, rmse, r2]],\n               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])","654a9d31":"## Polynomial Regressor\nfrom sklearn.preprocessing import PolynomialFeatures\npoly_reg = PolynomialFeatures(degree = 2)\nX_poly = poly_reg.fit_transform(X_train)\nlr_poly_regressor = LinearRegression()\nlr_poly_regressor.fit(X_poly, y_train)\n\n# Predicting Test Set\ny_pred = lr_poly_regressor.predict(poly_reg.fit_transform(X_test))\n\nplt.scatter(X_test, y_test, color = 'gray')\nplt.scatter(X_test, y_pred, color = 'red')\nplt.ylabel('{} ($)'.format(df.columns[1]))\nplt.xlabel('{}'.format(df.columns[0]))\nplt.title('Employee Salary (Test dataset)')","e703ec22":"from sklearn import metrics\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Polynomial Regression', mae, mse, rmse, r2]],\n               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n\nresults = results.append(model_results, ignore_index = True)","8964b2c7":"\n## Suport Vector Regression \n'Necessary Standard Scaler '\nfrom sklearn.svm import SVR\nsvr_regressor = SVR(kernel = 'rbf')\nsvr_regressor.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = svr_regressor.predict(X_test)\nfrom sklearn import metrics\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Support Vector RBF', mae, mse, rmse, r2]],\n               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n\nresults = results.append(model_results, ignore_index = True)","5209d44d":"## Decision Tree Regression\nfrom sklearn.tree import DecisionTreeRegressor\ndt_regressor = DecisionTreeRegressor(random_state=0)\ndt_regressor.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = dt_regressor.predict(X_test)\nfrom sklearn import metrics\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Decision Tree Regression', mae, mse, rmse, r2]],\n               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n\nresults = results.append(model_results, ignore_index = True)","458e5148":"## Random Forest Regression\nfrom sklearn.ensemble import RandomForestRegressor\nrf_regressor = RandomForestRegressor(n_estimators=300, random_state=0)\nrf_regressor.fit(X_train,y_train)\n\n# Predicting Test Set\ny_pred = rf_regressor.predict(X_test)\nfrom sklearn import metrics\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Random Forest Regression', mae, mse, rmse, r2]],\n               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n\nresults = results.append(model_results, ignore_index = True)","b51fc7ff":"## Ada Boosting\nfrom sklearn.ensemble import AdaBoostRegressor\nad_regressor = AdaBoostRegressor()\nad_regressor.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = ad_regressor.predict(X_test)\nfrom sklearn import metrics\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['AdaBoost Regressor', mae, mse, rmse, r2]],\n               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n\nresults = results.append(model_results, ignore_index = True)","8ed47702":"##Gradient Boosting\nfrom sklearn.ensemble import GradientBoostingRegressor\ngb_regressor = GradientBoostingRegressor()\ngb_regressor.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = gb_regressor.predict(X_test)\nfrom sklearn import metrics\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['GradientBoosting Regressor', mae, mse, rmse, r2]],\n               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n\nresults = results.append(model_results, ignore_index = True)","5e4014db":"##Xg Boosting\nfrom xgboost import XGBRegressor\nxgb_regressor = XGBRegressor()\nxgb_regressor.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = xgb_regressor.predict(X_test)\nfrom sklearn import metrics\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['XGB Regressor', mae, mse, rmse, r2]],\n               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n\nresults = results.append(model_results, ignore_index = True)","f03d33c8":"##Ensemble Voting regressor\nfrom sklearn.ensemble import VotingRegressor\nvoting_regressor = VotingRegressor(estimators= [('lr', lr_regressor),\n                                                  ('lr_poly', lr_poly_regressor),\n                                                  ('svr', svr_regressor),\n                                                  ('dt', dt_regressor),\n                                                  ('rf', rf_regressor),\n                                                  ('ad', ad_regressor),\n                                                  ('gb', gb_regressor),\n                                                  ('xg', xgb_regressor)])\n\nfor clf in (lr_regressor,lr_poly_regressor,svr_regressor,dt_regressor,\n            rf_regressor, ad_regressor,gb_regressor, xgb_regressor, voting_regressor):\n    clf.fit(X_train,y_train)\n    y_pred = clf.predict(X_test)\n    print(clf.__class__.__name__, metrics.r2_score(y_test, y_pred))\n\n# Predicting Test Set\ny_pred = voting_regressor.predict(X_test)\nfrom sklearn import metrics\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Ensemble Voting', mae, mse, rmse, r2]],\n               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n\nresults = results.append(model_results, ignore_index = True)  ","24a8ce47":"#The Best Classifier\nprint('The best regressor is:')\nprint('{}'.format(results.sort_values(by='R2 Score',ascending=False).head(5)))","6cbbcf7e":"#Applying K-fold validation\nfrom sklearn.model_selection import cross_val_score\ndef display_scores (scores):\n    print('Scores:', scores)\n    print('Mean:', scores.mean())\n    print('Standard:', scores.std())\n\nlin_scores = cross_val_score(estimator=gb_regressor, X=X_train, y=y_train, \n                             scoring= 'neg_mean_squared_error',cv=10)\nlin_rmse_scores = np.sqrt(-lin_scores)\ndisplay_scores(lin_rmse_scores)\n\n","9c4455a9":"# Model Building\n## Comparing Models"}}