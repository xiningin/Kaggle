{"cell_type":{"3149356d":"code","b377e311":"code","15c32fcf":"code","241f02bc":"code","822208c5":"code","46ffe620":"code","89812cae":"code","059ca786":"code","1649dc64":"code","91043143":"code","da97b297":"code","dbe41ed1":"code","f9343120":"code","4c7acf57":"code","5a60ded7":"code","69b4a9e1":"code","eb7a0ad2":"code","02c3280f":"code","768d278a":"code","f4d1b1fb":"code","49041146":"code","369c8aff":"code","9e527912":"code","f1bf4e8d":"code","e0269488":"code","49b17ccf":"code","05032a3e":"code","46bbfb2a":"code","f2b2fb1b":"code","dae9f551":"code","dfdc93e3":"code","65f8d9d8":"code","ee8bb865":"code","6314de6a":"code","6b793a47":"code","92a74cff":"code","9b2a0e57":"code","4cf34571":"code","1ab6cd6d":"code","5c8d0609":"code","c681a252":"code","9e0333a4":"code","ead9c31d":"code","04e7b6f3":"code","9648e2bf":"code","384df065":"code","b79fbc86":"markdown","cc371c1d":"markdown","02c873e9":"markdown","426a6b98":"markdown","f5b6b520":"markdown","183d06c4":"markdown","72e0d953":"markdown","ea106140":"markdown","f70186a2":"markdown","482e4793":"markdown","9946a6a0":"markdown","a03140ab":"markdown","d93fb4c9":"markdown","13837adf":"markdown","379057fa":"markdown","4ab0412a":"markdown","c0a7c923":"markdown","c1be12db":"markdown","a83681d5":"markdown","921a462e":"markdown","d48e29bc":"markdown","03f64c0c":"markdown","d5cf39ac":"markdown"},"source":{"3149356d":"!conda install '\/kaggle\/input\/pydicom-conda-helper\/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '\/kaggle\/input\/pydicom-conda-helper\/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y","b377e311":"!pip install \/kaggle\/input\/kerasapplications -q\n!pip install \/kaggle\/input\/efficientnet-keras-source-code\/ -q --no-deps","15c32fcf":"import gc\nimport os\nimport sys\nimport shutil\n\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nfrom glob import glob\nfrom tqdm import tqdm\n\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nimport efficientnet.tfkeras as efn\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K \nimport tensorflow_hub as tfhub\n\nimport torch\n\nfrom numba import cuda\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","241f02bc":"sys.path.append('\/kaggle\/input\/weightedboxesfusion')","822208c5":"from ensemble_boxes.ensemble_boxes_wbf import weighted_boxes_fusion","46ffe620":"df = pd.read_csv('..\/input\/siim-covid19-detection\/sample_submission.csv')\n\nif df.shape[0] == 2477:\n    fast_sub = True\n    fast_df = pd.DataFrame(\n        (\n            [\n                ['00086460a852_study', 'negative 1 0 0 1 1'], \n                ['000c9c05fd14_study', 'negative 1 0 0 1 1'], \n                ['65761e66de9f_image', 'none 1 0 0 1 1'], \n                ['51759b5579bc_image', 'none 1 0 0 1 1']\n            ]\n        ), \n        columns=['id', 'PredictionString']\n    )\nelse:\n    fast_sub = False","89812cae":"def read_xray(path, voi_lut: bool = True, fix_monochrome: bool = True):\n    dicom = pydicom.read_file(path)\n\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n\n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n\n    return data\n\ndef resize(array, size, keep_ratio: bool = False, resample=Image.LANCZOS):\n    im = Image.fromarray(array)\n\n    if keep_ratio:\n        im.thumbnail((size, size), resample)\n    else:\n        im = im.resize((size, size), resample)\n\n    return im","059ca786":"split = 'test'\n\nsave_dir = f'\/kaggle\/tmp\/{split}\/'\nos.makedirs(save_dir, exist_ok=True)\n\nsave_dir = f'\/kaggle\/tmp\/{split}\/study\/'\nos.makedirs(save_dir, exist_ok=True)","1649dc64":"STUDY_RES: int = 1024\n\nif fast_sub:\n    xray = read_xray('\/kaggle\/input\/siim-covid19-detection\/train\/00086460a852\/9e8302230c91\/65761e66de9f.dcm')\n    im = resize(xray, size=STUDY_RES)\n    study = '00086460a852' + '_study.png'\n    im.save(os.path.join(save_dir, study))\n\n    xray = read_xray('\/kaggle\/input\/siim-covid19-detection\/train\/000c9c05fd14\/e555410bd2cd\/51759b5579bc.dcm')\n    im = resize(xray, size=STUDY_RES)  \n    study = '000c9c05fd14' + '_study.png'\n    im.save(os.path.join(save_dir, study))\nelse:   \n    for dirname, _, filenames in tqdm(os.walk(f'..\/input\/siim-covid19-detection\/{split}')):\n        for file in filenames:\n            xray = read_xray(os.path.join(dirname, file))\n            im = resize(xray, size=STUDY_RES)  \n            study = dirname.split('\/')[-2] + '_study.png'\n            im.save(os.path.join(save_dir, study))","91043143":"IMAGE_RES: int = 640\n\nimage_id = []\ndim0 = []\ndim1 = []\nsplits = []\n\nsave_dir = f'\/kaggle\/tmp\/{split}\/image\/'\nos.makedirs(save_dir, exist_ok=True)\n\nif fast_sub:\n    xray = read_xray('\/kaggle\/input\/siim-covid19-detection\/train\/00086460a852\/9e8302230c91\/65761e66de9f.dcm')\n    im = resize(xray, size=IMAGE_RES)  \n    im.save(os.path.join(save_dir,'65761e66de9f_image.png'))\n    image_id.append('65761e66de9f.dcm'.replace('.dcm', ''))\n    dim0.append(xray.shape[0])\n    dim1.append(xray.shape[1])\n    splits.append(split)\n\n    xray = read_xray('\/kaggle\/input\/siim-covid19-detection\/train\/000c9c05fd14\/e555410bd2cd\/51759b5579bc.dcm')\n    im = resize(xray, size=IMAGE_RES)  \n    im.save(os.path.join(save_dir, '51759b5579bc_image.png'))\n    image_id.append('51759b5579bc.dcm'.replace('.dcm', ''))\n    dim0.append(xray.shape[0])\n    dim1.append(xray.shape[1])\n    splits.append(split)\nelse:\n    for dirname, _, filenames in tqdm(os.walk(f'..\/input\/siim-covid19-detection\/{split}')):\n        for file in filenames:\n            xray = read_xray(os.path.join(dirname, file))\n            im = resize(xray, size=IMAGE_RES)  \n            im.save(os.path.join(save_dir, file.replace('.dcm', '_image.png')))\n            image_id.append(file.replace('.dcm', ''))\n            dim0.append(xray.shape[0])\n            dim1.append(xray.shape[1])\n            splits.append(split)","da97b297":"meta = pd.DataFrame.from_dict(\n    {\n        'image_id': image_id, \n        'dim0': dim0, \n        'dim1': dim1, \n        'split': splits\n    }\n)","dbe41ed1":"def auto_select_accelerator():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n\n    return strategy\n\n\ndef build_decoder(with_labels: bool = False, target_size=(640, 640), ext: str = 'png'):\n    def decode(path):\n        file_bytes = tf.io.read_file(path)\n        if ext == 'png':\n            img = tf.image.decode_png(file_bytes, channels=3)\n        elif ext in ['jpg', 'jpeg']:\n            img = tf.image.decode_jpeg(file_bytes, channels=3)\n        else:\n            raise ValueError(\"Image extension not supported\")\n\n        img = tf.cast(img, tf.float32) \/ 255.0\n        img = tf.image.resize(img, target_size)\n\n        return img\n\n    return decode\n\n\ndef build_augmenter(img_size: int, with_labels: bool = False):\n    def augment(img):\n        # img = tf.image.random_crop(value=img, size=(img_size, img_size, 3))\n        img = tf.image.random_flip_left_right(img)\n        # img = tf.image.random_flip_up_down(img)\n        img = tf.image.random_brightness(img, 0.1)\n        return img\n\n    return augment\n\n\ndef build_dataset(\n    paths: str, \n    image_size: int,\n    bs: int = 16, \n    decode_fn=None,\n    augment_fn=None,\n    augment: bool = False,\n    repeat: bool = False\n):\n    if decode_fn is None:\n        decode_fn = build_decoder(False, (image_size, image_size))\n\n    if augment_fn is None:\n        augment_fn = build_augmenter(image_size, False)\n\n    AUTO = tf.data.experimental.AUTOTUNE\n\n    dset = tf.data.Dataset.from_tensor_slices(paths)\n    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n    # dset = dset.cache(cache_dir) if cache else dset\n    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n    dset = dset.repeat() if repeat else dset\n    # dset = dset.shuffle(shuffle) if shuffle else dset\n    dset = dset.batch(bs).prefetch(AUTO)\n\n    return dset","f9343120":"strategy = auto_select_accelerator()\nBATCH_SIZE = strategy.num_replicas_in_sync * 16","4c7acf57":"def get_effnetv2_backbone(ef: str):\n    if ef == 'm':\n        model_arch = 'efficientnetv2-m-21k-ft1k'\n    elif ef == 'l':\n        model_arch = 'efficientnetv2-l-21k-ft1k'\n    else:\n        raise\n\n    # DS_GCS_PATH = KaggleDatasets().get_gcs_path('efficientnetv2-tfhub-weight-files')\n    DS_GCS_PATH = '\/kaggle\/input\/efficientnetv2-tfhub-weight-files'\n    MODEL_GCS_PATH = f'{DS_GCS_PATH}\/tfhub_models\/{model_arch}\/feature_vector'\n\n    model = tfhub.KerasLayer(MODEL_GCS_PATH, trainable=False)\n\n    return model\n\n\ndef build_efnetv2_model(dim: int, ef: str = 'm'):\n    inp = tf.keras.layers.Input(shape=(dim, dim, 3))\n    base = get_effnetv2_backbone(ef)\n\n    x = base(inp)\n\n    head = tf.keras.Sequential([tf.keras.layers.Dropout(.5), tf.keras.layers.Dense(4)])\n\n    x1 = head(x)\n    x2 = head(x)\n    x3 = head(x)\n    x4 = head(x)\n    x5 = head(x)\n\n    x = (x1 + x2 + x3 + x4 + x5) \/ 5.\n    x = tf.keras.layers.Softmax(dtype='float32')(x)\n    \n    model = tf.keras.Model(inputs=inp, outputs=x)\n\n    return model","5a60ded7":"EFNS = [\n    efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, \n    efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6, efn.EfficientNetB7\n]\n\ndef build_efnet_model(dim: int, ef: int):\n    inp = tf.keras.layers.Input(shape=(dim, dim, 3))\n    base = EFNS[ef](input_shape=(dim, dim, 3), weights=None, include_top=False)\n\n    x = base(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n\n    head = tf.keras.Sequential([tf.keras.layers.Dropout(.5), tf.keras.layers.Dense(4)])\n\n    x1 = head(x)\n    x2 = head(x)\n    x3 = head(x)\n    x4 = head(x)\n    x5 = head(x)\n\n    x = (x1 + x2 + x3 + x4 + x5) \/ 5.\n    x = tf.keras.layers.Softmax(dtype='float32')(x)\n\n    model = tf.keras.Model(inputs=inp, outputs=x)\n\n    return model","69b4a9e1":"if fast_sub:\n    df = fast_df.copy()\nelse:\n    df = pd.read_csv('\/kaggle\/input\/siim-covid19-detection\/sample_submission.csv')\n\ndf['id_last_str'] = [df.loc[i,'id'][-1] for i in range(df.shape[0])]\nstudy_len = df[df['id_last_str'] == 'y'].shape[0]","eb7a0ad2":"if fast_sub:\n    sub_df = fast_df.copy()\nelse:\n    sub_df = pd.read_csv('\/kaggle\/input\/siim-covid19-detection\/sample_submission.csv')\n\nsub_df = sub_df[:study_len]\ntest_paths = f'\/kaggle\/tmp\/{split}\/study\/' + sub_df['id'] +'.png'\n\nsub_df['negative'] = 0\nsub_df['typical'] = 0\nsub_df['indeterminate'] = 0\nsub_df['atypical'] = 0\n\nlabel_cols = sub_df.columns[2:]","02c3280f":"def infer_efnet_recipe(test_paths, model_path: str, ef: int, tta: int, img_size: int, prefix: str, do_fastsub: bool):\n    global fast_sub\n\n    print(f'[*] recipe ef : {ef} img_size : {img_size} prefix : {prefix}')\n\n    dtest = build_dataset(\n        paths=test_paths,\n        image_size=img_size,\n        bs=BATCH_SIZE, \n        repeat=False if do_fastsub else tta > 1, \n        augment=False if do_fastsub else tta > 1,\n        decode_fn=build_decoder(with_labels=False, target_size=(img_size, img_size), ext='png')\n    )\n\n    model_paths = sorted(glob(os.path.join(model_path, f'effnet*{ef}-{prefix}-res{img_size}-fold*.h5')))\n\n    model = None\n    with strategy.scope():\n        model = build_efnet_model(img_size, ef=ef)\n\n    predictions = []\n    for model_path in model_paths:\n        print(f' [+] load {model_path}')\n        with strategy.scope():\n            model.load_weights(model_path)\n\n        if do_fastsub:\n            pred = model.predict(dtest)\n        else:\n            pred = model.predict(dtest, steps=tta * len(test_paths) \/ BATCH_SIZE)[:tta * len(test_paths), :]\n            pred = np.mean(pred.reshape(tta, len(test_paths), -1), axis=0)\n\n        predictions.append(pred)\n\n    del model\n\n    gc.collect()\n    K.clear_session()\n\n    return np.mean(predictions, axis=0)","768d278a":"TTA: int = 1","f4d1b1fb":"pred1 = infer_efnet_recipe(\n    test_paths,\n    model_path='\/kaggle\/input\/siim-cvoid-19-effnetb7\/', \n    ef=7, \n    tta=TTA, \n    img_size=640, \n    prefix='scce0.05-adam-aug_v3',\n    do_fastsub=fast_sub\n)\npred2 = infer_efnet_recipe(\n    test_paths,\n    model_path='\/kaggle\/input\/siim-covid19-effnetb7-bimcv\/', \n    ef=7, \n    tta=TTA, \n    img_size=640, \n    prefix='scce0.05-adam-aug_v5-bimcv-fp32-bs128',\n    do_fastsub=fast_sub\n)","49041146":"pred3 = infer_efnet_recipe(\n    test_paths,\n    model_path='\/kaggle\/input\/siim-cvoid-19-effnetb6\/', \n    ef=6, \n    tta=TTA, \n    img_size=800, \n    prefix='scce0.05-adam',\n    do_fastsub=fast_sub\n)\npred4 = infer_efnet_recipe(\n    test_paths,\n    model_path='\/kaggle\/input\/siim-covid19-effnetb6-bimcv\/', \n    ef=6, \n    tta=TTA, \n    img_size=800, \n    prefix='scce0.05-adam-aug_v5-bimcv-fp32-bs128',\n    do_fastsub=fast_sub\n)","369c8aff":"# sub_df[label_cols] = (pred1 + pred2) \/ 2.\n# sub_df[label_cols] = (pred1 + pred2 + pred3) \/ 3.\nsub_df[label_cols] = (pred1 + pred2 + pred3 + pred4) \/ 4.","9e527912":"sub_df.columns = ['id', 'PredictionString1', 'negative', 'typical', 'indeterminate', 'atypical']\ndf = pd.merge(df, sub_df, on='id', how='left')","f1bf4e8d":"for i in range(study_len):\n    negative = df.at[i, 'negative']\n    typical = df.at[i, 'typical']\n    indeterminate = df.at[i, 'indeterminate']\n    atypical = df.at[i, 'atypical']\n\n    df.at[i, 'PredictionString'] = f'negative {negative} 0 0 1 1 typical {typical} 0 0 1 1 indeterminate {indeterminate} 0 0 1 1 atypical {atypical} 0 0 1 1'","e0269488":"df_study = df[['id', 'PredictionString']]\ndf_study.head()","49b17ccf":"if fast_sub:\n    sub_df = fast_df.copy()\nelse:\n    sub_df = pd.read_csv('\/kaggle\/input\/siim-covid19-detection\/sample_submission.csv')\n\nsub_df = sub_df[study_len:]\ntest_paths = f'\/kaggle\/tmp\/{split}\/image\/' + sub_df['id'] +'.png'\nsub_df['none'] = 0\n\nlabel_cols = sub_df.columns[2]","05032a3e":"pred1 = infer_efnet_recipe(\n    test_paths,\n    model_path='\/kaggle\/input\/siim-cvoid-19-effnetb7\/', \n    ef=7, \n    tta=TTA, \n    img_size=640, \n    prefix='scce0.05-adam-aug_v3',\n    do_fastsub=fast_sub\n)\npred2 = infer_efnet_recipe(\n    test_paths,\n    model_path='\/kaggle\/input\/siim-covid19-effnetb7-bimcv\/', \n    ef=7, \n    tta=TTA, \n    img_size=640, \n    prefix='scce0.05-adam-aug_v5-bimcv-fp32-bs128',\n    do_fastsub=fast_sub\n)","46bbfb2a":"pred3 = infer_efnet_recipe(\n    test_paths,\n    model_path='\/kaggle\/input\/siim-cvoid-19-effnetb6\/', \n    ef=6, \n    tta=TTA, \n    img_size=800, \n    prefix='scce0.05-adam',\n    do_fastsub=fast_sub\n)\npred4 = infer_efnet_recipe(\n    test_paths,\n    model_path='\/kaggle\/input\/siim-covid19-effnetb6-bimcv\/', \n    ef=6, \n    tta=TTA, \n    img_size=800, \n    prefix='scce0.05-adam-aug_v5-bimcv-fp32-bs128',\n    do_fastsub=fast_sub\n)","f2b2fb1b":"# preds = (pred1 + pred2) \/ 2.\npreds = (pred1 + pred2 + pred3 + pred4) \/ 4.","dae9f551":"sub_df[label_cols] = preds[:, 0]\ndf_2class = sub_df.reset_index(drop=True)","dfdc93e3":"K.clear_session()\ngc.collect()","65f8d9d8":"cuda.select_device(0)\ncuda.close()\ncuda.select_device(0)","ee8bb865":"meta = meta[meta['split'] == 'test']\n\nif fast_sub:\n    test_df = fast_df.copy()\nelse:\n    test_df = pd.read_csv('\/kaggle\/input\/siim-covid19-detection\/sample_submission.csv')\n\ntest_df = df[study_len:].reset_index(drop=True) \nmeta['image_id'] = meta['image_id'] + '_image'\nmeta.columns = ['id', 'dim0', 'dim1', 'split']\ntest_df = pd.merge(test_df, meta, on='id', how='left')","6314de6a":"test_dir = f'\/kaggle\/tmp\/{split}\/image'\n\nshutil.copytree('\/kaggle\/input\/yolov5', '\/kaggle\/working\/yolov5')\nos.chdir('\/kaggle\/working\/yolov5')","6b793a47":"def yolo2voc(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    voc  => [x1, y1, x2, y1]\n    \"\"\" \n    bboxes = bboxes.copy().astype(float)  # otherwise all value will be 0 as voc_pascal dtype is np.int\n\n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]] * image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]] * image_height\n\n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]] \/ 2.\n    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n\n    return bboxes","92a74cff":"def run_wbf(boxes, scores, image_size: int, iou_thr: float = 0.6, skip_box_thr: float = 0.001, weights=None):\n    boxes = [[coord \/ (image_size - 1) for coord in box] for box in boxes]\n\n    boxes, scores, _ = weighted_boxes_fusion(\n        boxes, \n        scores, \n        [np.ones(len(scores[idx])) for idx in range(len(scores))],\n        weights=weights, \n        iou_thr=iou_thr, \n        skip_box_thr=skip_box_thr\n    )\n\n    boxes = [np.asarray([int(coord * (image_size - 1)) for coord in box]) for box in boxes]\n\n    return boxes, scores","9b2a0e57":"import os\nimport yolov5\nfrom utils.datasets import LoadImages\nfrom utils.general import non_max_suppression, scale_coords, xyxy2xywh\n\nfrom glob import glob\n\n\ndef detect():\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n    model_paths = [\n        # YOLOv5x6\n        '\/kaggle\/input\/siim-covid19-yolov5\/yolov5x6-fold0-mAP0.4466.pt',\n        '\/kaggle\/input\/siim-covid19-yolov5\/yolov5x6-fold1-mAP0.49373.pt',\n        '\/kaggle\/input\/siim-covid19-yolov5\/yolov5x6-fold2-mAP0.48003.pt',\n        '\/kaggle\/input\/siim-covid19-yolov5\/yolov5x6-fold3-mAP0.42454.pt',\n        '\/kaggle\/input\/siim-covid19-yolov5\/yolov5x6-fold4-mAP0.46058.pt',\n        # YOLOv5X6 res640\n        # '\/kaggle\/input\/siim-covid19-yolov5x6-res640\/yolov5x6-res640-fold0-mAP0.4662.pt',\n        # '\/kaggle\/input\/siim-covid19-yolov5x6-res640\/yolov5x6-res640-fold1-mAP0.5044.pt',\n        # '\/kaggle\/input\/siim-covid19-yolov5x6-res640\/yolov5x6-res640-fold2-mAP0.4762.pt',\n        # '\/kaggle\/input\/siim-covid19-yolov5x6-res640\/yolov5x6-res640-fold3-mAP0.4391.pt',\n        # '\/kaggle\/input\/siim-covid19-yolov5x6-res640\/yolov5x6-res640-fold4-mAP0.4676.pt',\n        # YOLOv5l6\n        '\/kaggle\/input\/siim-covid19-yolov5l\/yolov5l6-res512-fold0-mAP0.42464.pt',\n        '\/kaggle\/input\/siim-covid19-yolov5l\/yolov5l6-res512-fold1-mAP0.39763.pt',\n        '\/kaggle\/input\/siim-covid19-yolov5l\/yolov5l6-res512-fold2-mAP0.42889.pt',\n        '\/kaggle\/input\/siim-covid19-yolov5l\/yolov5l6-res512-fold3-mAP0.39249.pt',\n        '\/kaggle\/input\/siim-covid19-yolov5l\/yolov5l6-res512-fold4-mAP0.4241.pt',\n        # YOLOv5m6\n        '\/kaggle\/input\/siim-covid19-yolov5m\/yolov5m6-res512-fold0-mAP0.45113.pt',\n        '\/kaggle\/input\/siim-covid19-yolov5m\/yolov5m6-res512-fold1-mAP0.44463.pt',\n        '\/kaggle\/input\/siim-covid19-yolov5m\/yolov5m6-res512-fold2-mAP0.4496.pt',\n        '\/kaggle\/input\/siim-covid19-yolov5m\/yolov5m6-res512-fold3-mAP0.4121.pt',\n        '\/kaggle\/input\/siim-covid19-yolov5m\/yolov5m6-res512-fold4-mAP0.42406.pt',\n    ]\n\n    models = [\n        torch.load(model_path, map_location=device)['model'].to(device).float().eval()\n        for model_path in model_paths\n    ]\n\n    dataset = LoadImages('\/kaggle\/tmp\/test\/image', img_size=IMAGE_RES)\n\n    all_path = []\n    all_bboxes = []\n    all_score = []\n    for path, img, im0s, _ in dataset:\n        img = torch.from_numpy(img).to(device).float() \/ 255.\n\n        if img.ndimension() == 3:\n            img = img.unsqueeze(0)\n\n        bboxes_2 = []\n        score_2 = []\n        for model in models:\n            pred = model(img, augment=True)[0]\n            pred = non_max_suppression(pred, 0.001, 0.5, classes=None, agnostic=False)\n\n            bboxes = []\n            score = []\n            for i, det in enumerate(pred):\n                # gain = torch.tensor(im0.shape)[[1, 0, 1, 0]]\n                if det is not None and len(det):\n                    det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0s.shape).round()\n                    for c in det[:, -1].unique():\n                        n = (det[:, -1] == c).sum()\n\n                    for *xyxy, conf, _ in det:\n                        bboxes.append(torch.tensor(xyxy).view(-1).numpy())\n                        score.append(conf)\n\n            bboxes_2.append(bboxes)\n            score_2.append(score)\n\n        all_path.append(path)\n        all_score.append(score_2)\n        all_bboxes.append(bboxes_2)\n        \n    del models\n    del dataset\n    gc.collect()\n    torch.cuda.empty_cache()\n\n    return all_path, all_score, all_bboxes","4cf34571":"yolov5_iou_thr: float = 0.60\nyolov5_skip_box_thr: float = 0.01","1ab6cd6d":"with torch.no_grad():\n    yolov5_all_path, yolov5_all_score, yolov5_all_bboxes = detect()\n\nyolov5_preds = {}\nfor row in range(len(yolov5_all_path)):\n    image_id = yolov5_all_path[row].split('\/')[-1].split('.')[0]\n    boxes = yolov5_all_bboxes[row]\n    scores = yolov5_all_score[row]\n    boxes, scores = run_wbf(boxes, scores, image_size=IMAGE_RES, iou_thr=yolov5_iou_thr, skip_box_thr=yolov5_skip_box_thr)\n    yolov5_preds[image_id] = [boxes, scores]","5c8d0609":"image_ids = []\nPredictionStrings = []\n\nfor image_id, v in yolov5_preds.items():\n    w, h = test_df.loc[test_df['id'] == image_id, ['dim1', 'dim0']].values[0]\n\n    boxes, scores = v\n\n    normalized_boxes = [xyxy2xywh(box[None, :]) \/ IMAGE_RES for box in boxes]\n    rescaled_boxes = [np.round(yolo2voc(h, w, x)[0]) for x in normalized_boxes]\n    string_boxes = [\n        f'1 {score} {int(box[0])} {int(box[1])} {int(box[2])} {int(box[3])}' \n        for score, box in zip(scores, rescaled_boxes)\n    ]\n\n    image_ids.append(image_id)\n    PredictionStrings.append(' '.join(string_boxes))\n\npred_df = pd.DataFrame({'id': image_ids, 'PredictionString': PredictionStrings})","c681a252":"test_df = test_df.drop(['PredictionString'], axis=1)\nsub_df = pd.merge(test_df, pred_df, on='id', how='left').fillna('none 1 0 0 1 1')\nsub_df = sub_df[['id', 'PredictionString']]","9e0333a4":"for i in range(sub_df.shape[0]):\n    prediction_string = sub_df.at[i, 'PredictionString']\n    if prediction_string == 'none 1 0 0 1 1':\n        continue\n\n    sub_df_split = prediction_string.split()\n\n    sub_df_list = []\n    for j in range(len(sub_df_split) \/\/ 6):\n        sub_df_list.append('opacity')\n        sub_df_list.append(sub_df_split[6 * j + 1])\n        sub_df_list.append(sub_df_split[6 * j + 2])\n        sub_df_list.append(sub_df_split[6 * j + 3])\n        sub_df_list.append(sub_df_split[6 * j + 4])\n        sub_df_list.append(sub_df_split[6 * j + 5])\n\n    sub_df.at[i, 'PredictionString'] = ' '.join(sub_df_list)","ead9c31d":"sub_df['none'] = df_2class['none']\nfor i in range(sub_df.shape[0]):\n    if sub_df.at[i, 'PredictionString'] != 'none 1 0 0 1 1':\n        none_prob: float = sub_df.at[i, 'none']\n        sub_df.at[i, 'PredictionString'] = sub_df.at[i, 'PredictionString'] + f' none {none_prob} 0 0 1 1'\n#         if none_prob > 0.75:\n#             sub_df.at[i, 'PredictionString'] = 'none 1 0 0 1 1'\n#         elif none_prob > 0.25:\n#             sub_df.at[i, 'PredictionString'] = sub_df.at[i, 'PredictionString'] + f' none {none_prob} 0 0 1 1'\n#         else:\n#             sub_df.at[i, 'PredictionString'] = sub_df.at[i, 'PredictionString']\nsub_df = sub_df[['id', 'PredictionString']]","04e7b6f3":"df_study = df_study[:study_len]\ndf_study = df_study.append(sub_df).reset_index(drop=True)","9648e2bf":"df_study.to_csv('\/kaggle\/working\/submission.csv', index=False)\ndf_study","384df065":"shutil.rmtree('\/kaggle\/working\/yolov5')","b79fbc86":"## Inference","cc371c1d":"# Load Data","02c873e9":"## Utils","426a6b98":"### Yolov5","f5b6b520":"## Predict opacity","183d06c4":"### yolo2voc","72e0d953":"## Load study-level image","ea106140":"## Generate study-string","f70186a2":"### WBF","482e4793":"## Make format","9946a6a0":"## Yolov5","a03140ab":"# Predict image-level image","d93fb4c9":"## Convert coordinates","13837adf":"# EOF","379057fa":"## Load image-level image","4ab0412a":"# Predict study-level image","c0a7c923":"# Install Packages","c1be12db":"# Import Libraries","a83681d5":"## Models","921a462e":"## .dcm to .png","d48e29bc":"## TF pipeline","03f64c0c":"# Submission","d5cf39ac":"## Detect Yolov5"}}