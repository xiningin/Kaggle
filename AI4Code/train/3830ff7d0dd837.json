{"cell_type":{"a38f777f":"code","9609c29c":"code","8b0041af":"code","0a8d6a4a":"code","6d5115f7":"code","d93ed783":"code","56ae58a1":"code","55cc8c44":"code","230278cf":"code","353e41c0":"code","8e449c24":"code","0832d36d":"code","feec4191":"code","59b9be0e":"code","6ee5a1ea":"code","e7fe7005":"code","a71b87d0":"code","928b03ca":"code","6c52c444":"code","a470e5b4":"code","db3233da":"code","f0b09457":"code","dd9aa438":"code","d200d263":"code","96d6a83f":"code","a8144ae0":"code","dbd7ffc9":"code","4da55db8":"code","3ec18354":"code","b11b7599":"code","099793d0":"code","7bd3438f":"code","ba9cb092":"code","79765065":"code","522f9a61":"code","c0ad8ddf":"code","9489a33b":"code","8a51dff6":"code","82fc12fa":"code","bdc92089":"code","0cdb5f13":"code","682141a1":"code","8cc390cc":"code","bb92798c":"code","89f4e804":"code","683e6374":"code","cb9b4928":"code","106338ae":"code","c26de0f4":"code","c9bd7e12":"code","99b808ca":"code","aef0c628":"code","84981306":"code","04dba216":"code","00f54564":"code","25a4ab17":"code","8e1e5f69":"code","4e29dffe":"code","878f17e8":"code","fa0d3d7f":"code","8f202eac":"code","61118cea":"code","895bb2f3":"code","68b66016":"code","8a2d7d6a":"code","27dc7483":"code","02e93b7f":"code","56d798c1":"code","9e46672c":"code","c29a279b":"code","8716186c":"code","e574bc5d":"code","e249101f":"code","0c52f314":"code","a5c9dcc4":"code","87a1155a":"code","e65ee368":"code","26fd4f64":"code","c5f53887":"code","24ed33da":"code","6ec3641e":"code","c43d407d":"code","aee846a4":"code","d114a1d6":"code","97fa6690":"code","87011387":"code","81bcd061":"code","41ccb903":"code","86f5a179":"code","df0744aa":"code","bde4319e":"code","450666d2":"code","4f6874b9":"markdown","37037d61":"markdown","a94ac3e3":"markdown","f00a0155":"markdown","0eccfed2":"markdown"},"source":{"a38f777f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9609c29c":"conda install -c plotly plotly-orca==1.2.1","8b0041af":"from matplotlib import rcParams\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport string\nfrom collections import Counter\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\nfrom wordcloud import WordCloud\nfrom datetime import datetime\nimport plotly","0a8d6a4a":"restarant_names = pd.read_csv(\"\/kaggle\/input\/zomato-restaurants-hyderabad\/Restaurant reviews.csv\")\nreviews = pd.read_csv(\"\/kaggle\/input\/zomato-restaurants-hyderabad\/Restaurant names and Metadata.csv\")","6d5115f7":"restarant_names.head()","d93ed783":"restarant_names[\"Restaurant\"].value_counts()","56ae58a1":"rcParams[\"figure.figsize\"] = 50,10\nsns.countplot(x=\"Restaurant\",hue=\"Rating\",data=restarant_names[:300])","55cc8c44":"restarant_names[\"Rating\"].value_counts()","230278cf":"def convert_review_rating(Rating):\n    if Rating==\"1.5\":\n        Rating =1\n    elif Rating == \"1\":\n        Rating =1\n    elif Rating ==\"2.5\":\n        Rating = 2\n    elif Rating ==\"2\":\n        Rating = 2\n    elif Rating ==\"3.5\":\n        Rating = 3\n    elif Rating ==\"3\":\n        Rating = 3\n    elif Rating == \"4.5\":\n        Rating = 4\n    elif Rating ==\"4\":\n        Rating = 4\n    elif Rating ==\"5\":\n        Rating = 5\n    elif Rating ==\"Like\":\n        Rating = 5\n    return Rating","353e41c0":"restarant_names[\"Rating\"] = restarant_names[\"Rating\"].apply(convert_review_rating)","8e449c24":"restarant_names.head()","0832d36d":"restarant_names.isna().sum()","feec4191":"fig = px.histogram(restarant_names[\"Rating\"])\nfig.show()","59b9be0e":"# rcParams[\"figure.figsize\"]  =15,10\n# restarant_names[\"Rating\"].value_counts().plot(kind=\"pie\")\nfig = px.pie(values=restarant_names[\"Rating\"].value_counts(),hover_name=[5.0,4.0,3.0,2.0,1.0],title=\"Hotel Rating Distribution\")\nfig.show()","6ee5a1ea":"restarant_names.sort_values(by=['Rating'], inplace=True,ascending=False)","e7fe7005":"restarant_names.head()","a71b87d0":"Dowinng_10 = restarant_names[restarant_names[\"Restaurant\"]==\"10 Downing Street\"]","928b03ca":"rcParams[\"figure.figsize\"] = 20,10\nsns.countplot(x=Dowinng_10[\"Restaurant\"],hue=Dowinng_10[\"Rating\"])","6c52c444":"len(set(restarant_names.Reviewer))","a470e5b4":"five_start_hotels = restarant_names[restarant_names[\"Rating\"]==5]","db3233da":"five_start_hotels.head()","f0b09457":"rcParams[\"figure.figsize\"] = 50,10\nfive_start_hotels.Restaurant.value_counts().plot(kind=\"bar\")","dd9aa438":"restarant_names.shape","d200d263":"restarant_names.isna().sum()","96d6a83f":"reviews.head()","a8144ae0":"reviews.isna().sum()","dbd7ffc9":"def convert(text):\n    return int(text.replace(',',''))\nreviews[\"Cost\"] = reviews[\"Cost\"].apply(convert)","4da55db8":"top_5  = reviews.sort_values(by=\"Cost\",ascending=False).head(5)\ntail_5 = reviews.sort_values(by=\"Cost\",ascending=True).head()","3ec18354":"final_cost = pd.concat([top_5,tail_5])","b11b7599":"fig = px.pie(final_cost ,values=\"Cost\")\nfig.show()","099793d0":"restarant_names.head()","7bd3438f":"restarant_names.shape","ba9cb092":"set(restarant_names.Rating)","79765065":"restarant_names = restarant_names.dropna()","522f9a61":"restarant_names.shape","c0ad8ddf":"restarant_names[\"Rating\"].fillna(round(restarant_names[\"Rating\"].mean()))\n# eplace(\"NaN\",)   ","9489a33b":"restarant_names.head()","8a51dff6":"restarant_names[\"final_text\"] = restarant_names[\"Restaurant\"]+\" \"+restarant_names[\"Review\"]","82fc12fa":"reviewers = restarant_names['Reviewer'].value_counts().reset_index()\nreviewers.columns = ['Reviewer', 'Reviews']\n\nfig = px.histogram(reviewers, 'Reviews')\nfig.update_layout(title = \"Distribution in no of reviews:\",\n                 xaxis_title = \"No of Reviews\",\n                 yaxis_title = \"Given By users\")\nfig.show()","bdc92089":"temp = reviewers.head()['Reviewer'].tolist()\nprint(\"People who have posted most reviews are :\", temp)","0cdb5f13":"def clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","682141a1":"restarant_names['final_text'] = restarant_names['final_text'].apply(lambda x:clean_text(x))","8cc390cc":"restarant_names['temp_list'] = restarant_names['final_text'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in restarant_names['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","bb92798c":"fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Selected Text', orientation='h', width=700, height=700,color='Common_words')\nfig.show()","89f4e804":"fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words')\nfig.show()","683e6374":"def remove_stopword(x):\n    return [w for w in x if not w in stop]","cb9b4928":"restarant_names['temp_list'] = restarant_names['temp_list'].apply(lambda x:remove_stopword(x))","106338ae":"top = Counter([item for sublist in restarant_names['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Purples')","c26de0f4":"fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Selected Text', orientation='h', width=700, height=700,color='Common_words')\nfig.show()","c9bd7e12":"fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words')\nfig.show()","99b808ca":"def generate_word_cloud(text,img_name):\n    wordcloud = WordCloud(\n        width = 3000,\n        height = 2000,\n        background_color = 'black').generate(str(text))\n    fig = plt.figure(\n        figsize = (40, 30),\n        facecolor = 'k',\n        edgecolor = 'k')\n    plt.imshow(wordcloud, interpolation = 'bilinear')\n    plt.axis('off')\n    plt.tight_layout(pad=0)\n    plt.show()\n    plt.savefig(img_name)","aef0c628":"text_values = restarant_names.final_text.values[:100]\ngenerate_word_cloud(text_values,'image1.png')","84981306":"restarant_names.head()","04dba216":"reviews.head()","00f54564":"cuisines = reviews['Cuisines']\ncuisines = cuisines.apply(lambda x : x.lower())","25a4ab17":"all_cuisines = ', '.join(i for i in cuisines.tolist())\nall_cuisines = Counter(all_cuisines.split(', '))\nall_cuisines = pd.DataFrame.from_records(list(dict(all_cuisines).items()), columns=['Name','No Of Restaurents'])\nall_cuisines.sort_values(by='No Of Restaurents', ascending=False, inplace=True)","8e1e5f69":"fig = px.histogram(x=\"Name\",y=\"No Of Restaurents\",data_frame=all_cuisines,title=\"Total cuisine Available\",color=\"No Of Restaurents\")\nfig.show()","4e29dffe":"fig = px.histogram(x=\"Name\",y=\"No Of Restaurents\",data_frame=all_cuisines[:10],title=\"Top cuisine loved by people\")\nfig.show()\n","878f17e8":"import seaborn as sns\n","fa0d3d7f":"cusine_sort = reviews.sort_values(by=\"Cost\",ascending=False)","8f202eac":"cusine_sort.head()","61118cea":"cusine_sort_price = cusine_sort[cusine_sort[\"Cost\"]>=1000]\ncusine_sort_price_1000 = cusine_sort[cusine_sort[\"Cost\"]<1000]","895bb2f3":"cusine_sort.head()","68b66016":"fig = px.bar(cusine_sort_price, x='Cost', y='Cuisines', color='Cost',title=\"Cost distribution based on Cusines cost greater than 1000\",)\nfig.show()","8a2d7d6a":"fig = px.bar(cusine_sort_price_1000, x='Cost', y='Cuisines', color='Cost',title=\"Cost distribution based on Cusines cost less than 1000\")\nfig.show()","27dc7483":"cusine_text = reviews.Cuisines.values\ngenerate_word_cloud(cusine_text,\"cusines.jpeg\")","02e93b7f":"cusine_sort_price_viz = cusine_sort_price_1000[cusine_sort_price_1000[\"Cost\"]<300]","56d798c1":"fig = px.bar(cusine_sort_price_viz, x='Cost', y='Name', color='Cost',title=\"Cost distribution based on Cusines cost less than 1000\")\nfig.show()","9e46672c":"restarant_names_very_low = restarant_names[restarant_names[\"Rating\"]<3.0]","c29a279b":"restarant_names_very_low.head()","8716186c":"restarant_names['Time'] = restarant_names['Time'].apply(lambda x : datetime.strptime(x, '%m\/%d\/%Y %H:%M'))","e574bc5d":"restarant_names_very_low_values = restarant_names_very_low.Review.values\ngenerate_word_cloud(restarant_names_very_low_values,\"low_restarant.png\")","e249101f":"fig = px.bar(restarant_names_very_low, y='Restaurant')\nfig.show()","0c52f314":"restarant_names.head()","a5c9dcc4":"def convert_to_three_class(Rating):\n    if Rating <3.0:\n        Rating = 0\n    elif Rating>3.0:\n        Rating = 2\n    elif Rating ==3.0:\n        Rating = 1\n    return Rating","87a1155a":"new_restarant = restarant_names","e65ee368":"new_restarant[\"Rating\"] = restarant_names[\"Rating\"].apply(convert_to_three_class)","26fd4f64":"set(new_restarant[\"Rating\"])","c5f53887":"zero_review = new_restarant[new_restarant[\"Rating\"]==0]","24ed33da":"from sklearn.decomposition import LatentDirichletAllocation as LDA\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport gensim, spacy, logging, warnings\nimport gensim.corpora as corpora\nfrom gensim.utils import lemmatize, simple_preprocess\nfrom gensim.models import CoherenceModel\nimport matplotlib.pyplot as plt","6ec3641e":"negative_text = list(zero_review.Review.values)","c43d407d":"def sent_to_words(sentences):\n    for sent in sentences:\n        sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n        yield(sent)  \n\n# Convert to list\n# data = df.content.values.tolist()\ndata_words = list(sent_to_words(negative_text))","aee846a4":"from nltk.corpus import stopwords\nstop_words = stopwords.words('english')\nstop_words.extend(['from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come'])\n","d114a1d6":"# Build the bigram and trigram models\nbigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\ntrigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \nbigram_mod = gensim.models.phrases.Phraser(bigram)\ntrigram_mod = gensim.models.phrases.Phraser(trigram)\n\n# !python3 -m spacy download en  # run in terminal once\ndef process_words(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n    \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n    texts = [bigram_mod[doc] for doc in texts]\n    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n    texts_out = []\n    nlp = spacy.load('en', disable=['parser', 'ner'])\n    for sent in texts:\n        doc = nlp(\" \".join(sent)) \n        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n    # remove stopwords once more after lemmatization\n    texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n    return texts_out","97fa6690":"data_ready = process_words(data_words)  # processed Text Data!","87011387":"# Create Dictionary\nid2word = corpora.Dictionary(data_ready)\n\n# Create Corpus: Term Document Frequency\ncorpus = [id2word.doc2bow(text) for text in data_ready]","81bcd061":"lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n                                           id2word=id2word,\n                                           num_topics=4, \n                                           random_state=100,\n                                           update_every=1,\n                                           chunksize=10,\n                                           passes=10,\n                                           alpha='symmetric',\n                                           iterations=100,\n                                           per_word_topics=True)\n\nprint(lda_model.print_topics())","41ccb903":"def format_topics_sentences(ldamodel, corpus, texts):\n    # Init output\n    sent_topics_df = pd.DataFrame()\n\n    # Get main topic in each document\n    for i, row_list in enumerate(ldamodel[corpus]):\n        row = row_list[0] if ldamodel.per_word_topics else row_list            \n        # print(row)\n        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n        # Get the Dominant topic, Perc Contribution and Keywords for each document\n        for j, (topic_num, prop_topic) in enumerate(row):\n            if j == 0:  # => dominant topic\n                wp = ldamodel.show_topic(topic_num)\n                topic_keywords = \", \".join([word for word, prop in wp])\n                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n            else:\n                break\n    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n\n    # Add original text to the end of the output\n    contents = pd.Series(texts)\n    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n    return(sent_topics_df)","86f5a179":"\ndf_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_ready)\n\n# Format\ndf_dominant_topic = df_topic_sents_keywords.reset_index()\ndf_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\ndf_dominant_topic.head(10)","df0744aa":"from collections import Counter\ntopics = lda_model.show_topics(formatted=False)\ndata_flat = [w for w_list in data_ready for w in w_list]\ncounter = Counter(data_flat)\n\nout = []\nfor i, topic in topics:\n    for word, weight in topic:\n        out.append([word, i , weight, counter[word]])\n\ndf = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])        \nimport matplotlib.colors as mcolors\n# Plot Word Count and Weights of Topic Keywords\nfig, axes = plt.subplots(2, 2, figsize=(16,10), sharey=True, dpi=160)\ncols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\nfor i, ax in enumerate(axes.flatten()):\n    ax.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.5, alpha=0.3, label='Word Count')\n    ax_twin = ax.twinx()\n    ax_twin.bar(x='word', height=\"importance\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.2, label='Weights')\n    ax.set_ylabel('Word Count', color=cols[i])\n    ax_twin.set_ylim(0, 0.030); ax.set_ylim(0, 3500)\n    ax.set_title('Topic: ' + str(i), color=cols[i], fontsize=16)\n    ax.tick_params(axis='y', left=False)\n    ax.set_xticklabels(df.loc[df.topic_id==i, 'word'], rotation=30, horizontalalignment= 'right')\n    ax.legend(loc='upper left'); ax_twin.legend(loc='upper right')\n\nfig.tight_layout(w_pad=2)    \nfig.suptitle('Word Count and Importance of Topic Keywords', fontsize=22, y=1.05)    \nplt.show()\nplt.savefig(\"final.png\")","bde4319e":"reviews.head()","450666d2":"cusine_sort.head()","4f6874b9":"# Labels\n>Label 0 says the restaraunt which are less than 3 rating\n\n>Label 1 says the restaraunt which are equal to 3  rating\n\n>Label 2 says the restaraunt which are greater than 3 rating","37037d61":"## There are totally 1000 data points and has almost 7447 unique reviewers and only remaining people are regular reviewers","a94ac3e3":"## Top and  Bottom price distribution","f00a0155":"# Five star Hotels","0eccfed2":"## There is no NaN values in the dataframe"}}