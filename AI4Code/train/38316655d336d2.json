{"cell_type":{"2801a82d":"code","78729a43":"code","e813327e":"code","ee25da64":"code","96a0cf92":"code","db2993b5":"code","3a2f2af5":"code","17105539":"code","1f81fd7e":"code","edb20950":"code","b807a04c":"code","1c6c8de5":"code","2674c803":"code","d41ccbf2":"code","a487b9b4":"code","5e54bc8f":"code","d56ab530":"code","9bd893ad":"code","ea742c6e":"code","6844ce2b":"code","2341d30c":"code","696e2c8f":"code","d84b4f10":"code","22479a2e":"code","78c50176":"code","e97e35d9":"code","36e1dfb7":"code","e5de84d0":"code","5ae6890a":"code","d8026ef6":"code","3eb16416":"code","f07456b9":"code","718ff4ad":"code","b7659251":"code","f97a65a4":"code","215d2e0f":"code","964c73a7":"code","1264bb2d":"code","0df78f02":"code","14d9440d":"code","cf24b476":"code","f0396aec":"code","0df68d4c":"code","64c2a39d":"code","466e56ea":"markdown","6b95a19d":"markdown","7dac79d6":"markdown","f47c54c2":"markdown","78a018b9":"markdown","354583d6":"markdown","4f4e8f80":"markdown","dabd4043":"markdown","9289439e":"markdown","28c904a6":"markdown","22b8418f":"markdown","e13c627b":"markdown","6d450732":"markdown","c31012dd":"markdown","e460da64":"markdown","90454810":"markdown","074fcbc7":"markdown","2928c0f6":"markdown","6b725f24":"markdown","d0964ee6":"markdown","f4552c7f":"markdown","6b7880d0":"markdown","edf529e6":"markdown"},"source":{"2801a82d":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport gc\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import fbeta_score\n\nimport matplotlib.pyplot as plt\n\nfrom tqdm import tqdm_notebook as tqdm\ntqdm().pandas()\n\nfrom keras.preprocessing.image import img_to_array, load_img\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nfrom keras.layers import Dropout\n\nfrom keras.optimizers import SGD","78729a43":"folder = '..\/input\/planets-dataset\/planet\/planet\/train-jpg\/'\n\nplt.figure(figsize=(20,10))\nfor i in range(9):\n  \n    plt.subplot(330 + 1 + i)\n  \n    filename = folder + 'train_' + str(i) + '.jpg' \n    image = plt.imread(filename)\n    \n    plt.imshow(image)\n\nplt.show()","e813327e":"file = pd.read_csv('..\/input\/planets-dataset\/planet\/planet\/train_classes.csv')\nfile.head(10)","ee25da64":"def create_mapping(file):\n    tags = set()\n    for tag in tqdm(list(file['tags'].values)):\n        split = tag.split(' ')\n        tags.update(split)\n    tags = list(tags)\n    tags.sort()\n    \n    tags_mapping = dict()\n    for idx, tag in enumerate(tags):\n        tags_mapping[tag] = idx\n    \n    return tags_mapping\n\ntags_mapping = create_mapping(file)\ntags_mapping","96a0cf92":"# Encoding example \nfile_name = 'train_4.jpg'\ntags = file.query(f\"image_name == '{file_name.split('.')[0]}'\")['tags'].values[0].split(' ')\nencoded = np.zeros(len(tags_mapping), dtype='uint8')\nfor tag in tags:\n    encoded[tags_mapping[tag]] = 1\n\nprint(f'Tags : {tags}')\nprint(f'Encoded : {encoded}')","db2993b5":"def encode_tags(file_name, tags_mapping):\n    encoded = np.zeros(len(tags_mapping), dtype='uint8')\n    \n    tags = file.query(f\"image_name == '{file_name.split('.')[0]}'\")['tags'].values[0].split(' ')\n    for tag in tags:\n        encoded[tags_mapping[tag]] = 1\n    \n    return encoded","3a2f2af5":"TRAIN_PATH = '..\/input\/planets-dataset\/planet\/planet\/train-jpg\/'\nTEST_PATH = '..\/input\/planets-dataset\/test-jpg-additional\/test-jpg-additional\/'\n\ndef create_variables(tags_mapping):\n    photos, targets = list(), list()\n    \n    for file_name in tqdm(os.listdir(TRAIN_PATH)[:35000]):\n        photo = load_img(TRAIN_PATH + file_name , target_size = (128, 128))\n        photo = img_to_array(photo, dtype='uint8')\n        \n        encoded = encode_tags(file_name, tags_mapping)\n        \n        photos.append(photo)\n        targets.append(encoded)\n    \n    X = np.asarray(photos, dtype='uint8')\n    y = np.asarray(targets)\n    \n    \n    return X, y","17105539":"X, y = create_variables(tags_mapping)","1f81fd7e":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)","edb20950":"print(X.shape)\nprint(y.shape)\n\n'''np.savez_compressed('planet_data.npz', X, y)'''","b807a04c":"del X, y\ndel file\ngc.collect()","1c6c8de5":"def load_dataset():\n    data = np.load('\/kaggle\/input\/output\/planet_data.npz')\n    \n    X, y = data['arr_0'], data['arr_1']\n    \n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n    \n    return X_train, X_test, y_train, y_test\n\nX_train, X_test, y_train, y_test = load_dataset()","2674c803":"train_yhat = np.asarray([np.ones(y_train.shape[1]) for _ in range(y_train.shape[0])])\ntest_yhat = np.asarray([np.ones(y_test.shape[1]) for _ in range(y_test.shape[0])])\n\ntrain_score = fbeta_score(y_train, train_yhat, 2, average='samples') \ntest_score = fbeta_score(y_test, test_yhat, 2, average='samples')\nprint('All Ones: train=%.3f, test=%.3f' % (train_score, test_score))","d41ccbf2":"from keras import backend\n\ndef fbeta(y_true, y_pred, beta=2):\n    y_pred = backend.clip(y_pred, 0, 1)\n    \n    tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n    fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n    fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n    \n    # calculate precision\n    p = tp \/ (tp + fp + backend.epsilon())\n    # calculate recall\n    r = tp \/ (tp + fn + backend.epsilon())\n    \n    # calculate fbeta, averaged across each class\n    bb = beta ** 2\n    fbeta_score = backend.mean((1 + bb) * (p * r) \/ (bb * p + r + backend.epsilon()))\n    return fbeta_score","a487b9b4":"def define_model():\n    model = Sequential()\n    # Block 1\n    model.add(Conv2D(32, (3,3), input_shape=(128,128,3), activation='relu',\n                    padding='same', kernel_initializer='he_uniform'))\n    model.add(Conv2D(32, (3,3), activation='relu',\n                    padding='same', kernel_initializer='he_uniform'))\n    model.add(MaxPooling2D((2,2)))\n    \n    #Block 2\n    model.add(Conv2D(64, (3,3), activation='relu',\n                    padding='same', kernel_initializer='he_uniform'))\n    model.add(Conv2D(64, (3,3), activation='relu',\n                    padding='same', kernel_initializer='he_uniform'))\n    model.add(MaxPooling2D((2,2)))\n    \n    #Block 3\n    model.add(Conv2D(128, (3,3), input_shape=(128,128,3), activation='relu',\n                    padding='same', kernel_initializer='he_uniform'))\n    model.add(Conv2D(128, (3,3), activation='relu',\n                    padding='same', kernel_initializer='he_uniform'))\n    model.add(MaxPooling2D((2,2)))\n    \n    model.add(Flatten())\n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dense(17, activation='sigmoid'))\n    \n    opt = SGD(lr=0.01, momentum=0.9)\n    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n    \n    return model","5e54bc8f":"def summarize_diagnostics(history):\n    plt.figure(figsize=(10,5))\n    plt.subplot(211)\n    plt.title('Cross Entropy Loss')\n    plt.plot(history.history['loss'], color='blue', label='train') \n    plt.plot(history.history['val_loss'], color='orange', label='test')\n\n        # plot accuracy\n    plt.subplot(212)\n    plt.title('F-beta Score') \n    plt.plot(history.history['fbeta'], color='blue', label='train') \n    plt.plot(history.history['val_fbeta'], color='orange', label='test')\n    plt.show()","d56ab530":"datagen = ImageDataGenerator(rescale=1.0\/255.0)\n\ntrain_it = datagen.flow(X_train, y_train, batch_size=128)\ntest_it = datagen.flow(X_test, y_test, batch_size=128)\n\nmodel = define_model()\n\nrlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, \n                              min_delta=1E-7)\n\nhistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n                             validation_data=test_it, validation_steps=len(test_it), \n                              epochs=20, callbacks=[rlrop], verbose=1)","9bd893ad":"summarize_diagnostics(history)","ea742c6e":"del history\ndel model\ngc.collect()","6844ce2b":"del datagen\ndel train_it\ndel test_it\ngc.collect()","2341d30c":"def define_model():\n    model = Sequential()\n    # Block 1\n    model.add(Conv2D(32, (3,3), input_shape=(128,128,3), activation='relu',\n                    padding='same', kernel_initializer='he_uniform'))\n    model.add(Conv2D(32, (3,3), activation='relu',\n                    padding='same', kernel_initializer='he_uniform'))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Dropout(0.2))\n    \n    #Block 2\n    model.add(Conv2D(64, (3,3), activation='relu',\n                    padding='same', kernel_initializer='he_uniform'))\n    model.add(Conv2D(64, (3,3), activation='relu',\n                    padding='same', kernel_initializer='he_uniform'))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Dropout(0.3))\n    \n    #Block 3\n    model.add(Conv2D(128, (3,3), input_shape=(128,128,3), activation='relu',\n                    padding='same', kernel_initializer='he_uniform'))\n    model.add(Conv2D(128, (3,3), activation='relu',\n                    padding='same', kernel_initializer='he_uniform'))\n    model.add(MaxPooling2D((2,2)))\n    model.add(Dropout(0.3))\n    \n    model.add(Flatten())\n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dropout(0.5))\n    model.add(Dense(17, activation='sigmoid'))\n    \n    opt = SGD(lr=0.01, momentum=0.9)\n    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n    \n    return model","696e2c8f":"datagen = ImageDataGenerator(rescale=1.0\/255.0)\n\ntrain_it = datagen.flow(X_train, y_train, batch_size=128)\ntest_it = datagen.flow(X_test, y_test, batch_size=128)\n\nmodel = define_model()\n\nrlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, \n                              min_delta=1E-7)\n\nhistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n                             validation_data=test_it, validation_steps=len(test_it), \n                              epochs=20, callbacks=[rlrop], verbose=1)","d84b4f10":"loss, fbeta = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\nprint('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))","22479a2e":"del history\ndel model\ngc.collect()","78c50176":"def define_model():\n    model = Sequential()\n    # Block 1\n    model.add(Conv2D(32, (3,3), input_shape=(128,128,3), activation='relu',\n                    padding='same', kernel_initializer='he_uniform'))\n    model.add(Conv2D(32, (3,3), activation='relu',\n                    padding='same', kernel_initializer='he_uniform'))\n    model.add(MaxPooling2D((2,2)))\n    \n    #Block 2\n    model.add(Conv2D(64, (3,3), activation='relu',\n                    padding='same', kernel_initializer='he_uniform'))\n    model.add(Conv2D(64, (3,3), activation='relu',\n                    padding='same', kernel_initializer='he_uniform'))\n    model.add(MaxPooling2D((2,2)))\n    \n    #Block 3\n    model.add(Conv2D(128, (3,3), input_shape=(128,128,3), activation='relu',\n                    padding='same', kernel_initializer='he_uniform'))\n    model.add(Conv2D(128, (3,3), activation='relu',\n                    padding='same', kernel_initializer='he_uniform'))\n    model.add(MaxPooling2D((2,2)))\n    \n    model.add(Flatten())\n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dense(17, activation='sigmoid'))\n    \n    opt = SGD(lr=0.01, momentum=0.9)\n    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n    \n    return model","e97e35d9":"train_datagen = ImageDataGenerator(rescale=1.0\/255.0, horizontal_flip=True, vertical_flip=True, \n                             rotation_range=90)\n\ntest_datagen = ImageDataGenerator(rescale=1.0\/255.0)\n\ntrain_it = train_datagen.flow(X_train, y_train, batch_size=128)\ntest_it = test_datagen.flow(X_test, y_test, batch_size=128)\n\nmodel = define_model()\n\nrlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, \n                              min_delta=1E-7)\n\nhistory = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n                             validation_data=test_it, validation_steps=len(test_it), \n                              epochs=40, verbose=1)","36e1dfb7":"loss, fbeta = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\nprint('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))","e5de84d0":"'''filename = 'model_vgg.h5'\nmodel.save(filename)'''\n\n'''model = np.load('\/kaggle\/input\/output\/model_vgg.h5')'''","5ae6890a":"summarize_diagnostics(history)","d8026ef6":"del history\ngc.collect()","3eb16416":"# create a mapping of tags to integers given the loaded mapping file\ndef create_tag_mapping(mapping_csv):\n\t# create a set of all known tags\n\tlabels = set()\n\tfor i in range(len(mapping_csv)):\n\t\t# convert spaced separated tags into an array of tags\n\t\ttags = mapping_csv['tags'][i].split(' ')\n\t\t# add tags to the set of known labels\n\t\tlabels.update(tags)\n\t# convert set of labels to a list to list\n\tlabels = list(labels)\n\t# order set alphabetically\n\tlabels.sort()\n\t# dict that maps labels to integers, and the reverse\n\tlabels_map = {labels[i]:i for i in range(len(labels))}\n\tinv_labels_map = {i:labels[i] for i in range(len(labels))}\n\treturn labels_map, inv_labels_map\n\n# convert a prediction to tags\ndef prediction_to_tags(inv_mapping, prediction):\n\t# round probabilities to {0, 1}\n\tvalues = prediction.round()\n\tprint(values)\n\t# collect all predicted tags\n\ttags = [inv_mapping[i] for i in range(len(values)) if values[i] == 1.0]\n\treturn tags\n\n# load and prepare the image\ndef load_image(filename):\n\t# load the image\n\timg = load_img(filename, target_size=(128, 128))\n\t# convert to array\n\timg = img_to_array(img)\n\t# reshape into a single sample with 3 channels\n\timg = img.reshape(1, 128, 128, 3)\n\t# center pixel data\n\timg = img.astype('float32')\n\timg = img - [123.68, 116.779, 103.939]\n\treturn img\n\n# load an image and predict the class\ndef run_example(inv_mapping, model, file_name):\n\t# load the image\n\timg = load_image(TRAIN_PATH + file_name)\t\n\t# predict the class\n\tresult = model.predict(img)\n\t#print(result[0])\n\t# map prediction to tags\n\ttags = prediction_to_tags(inv_mapping, result[0])\n\tprint('Predicted : ', tags)","f07456b9":"filename = '..\/input\/planets-dataset\/planet\/planet\/train_classes.csv'\nmapping_csv = pd.read_csv(filename)\nmapping_csv.head()","718ff4ad":"create_tag_mapping(mapping_csv)","b7659251":"image = plt.imread(TRAIN_PATH + 'train_100.jpg')\n    \nplt.imshow(image)","f97a65a4":"# create a mapping of tags to integers\n_, inv_mapping = create_tag_mapping(mapping_csv)\n# entry point, run the example\nrun_example(inv_mapping , model, 'train_100.jpg')\nprint('Expected : ', mapping_csv.query('image_name == \"train_100\"')['tags'].values)","215d2e0f":"image = plt.imread(TRAIN_PATH + 'train_10.jpg')\n    \nplt.imshow(image)","964c73a7":"_, inv_mapping = create_tag_mapping(mapping_csv)\n# entry point, run the example\nrun_example(inv_mapping , model, 'train_10.jpg')\nprint('Expected : ', mapping_csv.query('image_name == \"train_10\"')['tags'].values)","1264bb2d":"image = plt.imread(TRAIN_PATH + 'train_10010.jpg')\n    \nplt.imshow(image)","0df78f02":"_, inv_mapping = create_tag_mapping(mapping_csv)\n# entry point, run the example\nrun_example(inv_mapping , model, 'train_10010.jpg')\nprint('Expected : ', mapping_csv.query('image_name == \"train_10010\"')['tags'].values)","14d9440d":"image = plt.imread(TRAIN_PATH + 'train_10016.jpg')\n    \nplt.imshow(image)","cf24b476":"_, inv_mapping = create_tag_mapping(mapping_csv)\n# entry point, run the example\nrun_example(inv_mapping , model, 'train_10016.jpg')\nprint('Expected : ', mapping_csv.query('image_name == \"train_10016\"')['tags'].values)","f0396aec":"image = plt.imread(TRAIN_PATH + 'train_10026.jpg')\n    \nplt.imshow(image)\n\n_, inv_mapping = create_tag_mapping(mapping_csv)\n# entry point, run the example\nrun_example(inv_mapping , model, 'train_10026.jpg')\nprint('Expected : ', mapping_csv.query('image_name == \"train_10026\"')['tags'].values)","0df68d4c":"image = plt.imread(TRAIN_PATH + 'train_40475.jpg')\n    \nplt.imshow(image)\n\n_, inv_mapping = create_tag_mapping(mapping_csv)\n# entry point, run the example\nrun_example(inv_mapping , model, 'train_40475.jpg')\nprint('Expected : ', mapping_csv.query('image_name == \"train_40475\"')['tags'].values)","64c2a39d":"image = plt.imread(TRAIN_PATH + 'train_40478.jpg')\n    \nplt.imshow(image)\n\n_, inv_mapping = create_tag_mapping(mapping_csv)\n# entry point, run the example\nrun_example(inv_mapping , model, 'train_40478.jpg')\nprint('Expected : ', mapping_csv.query('image_name == \"train_40478\"')['tags'].values)","466e56ea":"Example 6.","6b95a19d":"Example 3.","7dac79d6":"<h3><center>6. Evaluate targets with 1 predictions<\/center><\/h3>\n<div style=\"font-family:verdana; word-spacing:1.9px;\">\nThe Fbeta-measure is a generalization of the F-measure that adds a configuration parameter called beta. A default beta value is 1.0, which is the same as the F-measure. A smaller beta value, such as 0.5, gives more weight to precision and less to recall, whereas a larger beta value, such as 2.0, gives less weight to precision and more weight to recall in the calculation of the score.\n    <\/div>","f47c54c2":"<h3><center>1. Explore Datasets<\/center><\/h3>","78a018b9":"<h3><center>1. Introduction to the Planet Dataset<\/center><\/h3>\n\n![image.png](attachment:image.png)\n\n<div style=\"font-family:verdana; word-spacing:1.7px;\">\nThe Planet: Understanding the Amazon from Space competition was held on Kaggle in 2017. The competition involved classifying small squares of satellite images taken from space of the Amazon rainforest in Brazil in terms of 17 classes, such as agriculture, clear, and water. <br><br>\nThe problem is an example of a multi-label image classification task, where one or more class labels must be predicted for each label. This is different from multiclass classification, where each image is assigned one from among many classes.\n    <\/div>\n    ","354583d6":"<h3><center>5. Load Dataset<\/center><\/h3>","4f4e8f80":"<blockquote>Since it is a multilabel classification, we have to split the tags and have to identify the unique set of labels<\/blockquote>","dabd4043":"<h3><center>11. Predict Image<\/center><\/h3>","9289439e":"<h3><center>3. Encode Tags<\/center><\/h3>","28c904a6":"<h3><center>10. Improvement of Model - VGG + Augmentation<\/center><\/h3>","22b8418f":"[](http:\/\/)FBETA Score - 82.65 ","e13c627b":"We can make the model learn more by increasing the epochs to 70","6d450732":"FBETA Score - 81.41","c31012dd":"Example 4.","e460da64":"<h3><center>4. Create In-Memory Variables<\/center><\/h3>","90454810":"Example 5.","074fcbc7":"Example 1. ","2928c0f6":"Example 2.","6b725f24":"<h3><center>8. Base-Line Model, VGG-3 blocks<\/center><\/h3>","d0964ee6":"<div style=\"font-family:verdana; word-spacing:1.7px;\">\nThe all-one predictions are prepared and then evaluated and the scores are reported. We can see that an all ones prediction for both datasets results in a score of about 0.48.\n    <\/div>","f4552c7f":"<h3><center>7. F-beta Measure<\/center><\/h3>","6b7880d0":"<h3><center>9. Model Improvement - VGG + Dropout<\/center><\/h3>","edf529e6":"<h3><center>2. Create Mappings<\/center><\/h3>"}}