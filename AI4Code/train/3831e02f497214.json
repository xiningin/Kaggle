{"cell_type":{"0c920cd9":"code","752d5524":"code","9804b9f1":"code","2a0d2cd7":"code","a7c4cf56":"code","6c489a5b":"code","79798598":"code","84c7bb02":"code","1a5cc8ce":"code","214332b1":"code","f0e0dab5":"code","7d698de3":"code","4cc9aee7":"code","b4a16fa1":"code","713ed9f9":"code","ba2957ff":"code","f4729d8d":"markdown","d9aa5de6":"markdown","4540c02e":"markdown","170e920e":"markdown"},"source":{"0c920cd9":"import numpy as np\nimport pandas as pd\nimport torch\nimport random\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport os\nimport shutil\nimport cv2\nimport time\nimport torchvision\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport albumentations \nfrom albumentations.pytorch import ToTensorV2 as AT\n\n\nimport matplotlib.pyplot as plt","752d5524":"PATH = 'yandex\/'\ntrain_path=list()\nfor directory in os.listdir(PATH):\n    train_path.append(os.path.join(PATH, directory))\n    \ntest_path = (\"test\/\")\n\ntrain_list=list()\nfor directory in train_path:\n    for pic in os.listdir(directory):\n        train_list.append(directory+'\/'+pic)\n\ntest_list=list()\nfor pic in os.listdir(test_path):\n    test_list.append(test_path+pic)\nprint(len(train_list), len(test_list))","9804b9f1":"class ChartsDataset(Dataset):\n    \n    def __init__(self, path, img_list, transform=None, mode='train'):\n        self.path = path\n        self.img_list = img_list\n        self.transform = transform\n        self.mode = mode\n    \n    def __len__(self):\n        return len(self.img_list)\n    \n    def __getitem__(self, idx):\n        image_name = self.img_list[idx]\n        \n        if image_name.split(\".\")[-1] == \"gif\":\n           gif = cv2.VideoCapture(self.path + image_name)\n           _, image = gif.read()\n        else:\n            image = cv2.imread(self.path + image_name)\n            \n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if \"bar_chart\" in image_name:\n            label = 1\n        elif \"diagram\" in image_name:\n            label = 2\n        elif \"flow_chart\" in image_name:\n            label = 3\n        elif \"graph\" in image_name:\n            label = 4\n        elif \"growth_chart\" in image_name:\n            label = 5\n        elif \"pie_chart\" in image_name:\n            label = 6\n        elif \"table\" in image_name:\n            label = 7\n        else:\n            label = 0 #just_image\n            \n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented[\"image\"]\n        \n        if self.mode == \"train\":\n            return image, label\n        else:\n            return image, image_name","2a0d2cd7":"batch_size = 64\nnum_workers = os.cpu_count()\nimg_size = 256","a7c4cf56":"data_transforms = albumentations.Compose([\n    albumentations.Resize(img_size, img_size),\n    albumentations.CLAHE(),\n    albumentations.ChannelShuffle(),\n    albumentations.Downscale(),\n    albumentations.Cutout(),\n    albumentations.ShiftScaleRotate(),\n    albumentations.Normalize(),\n    AT()\n    ])\n\n\ndata_transforms_test = albumentations.Compose([\n    albumentations.Resize(img_size, img_size),\n    albumentations.Normalize(),\n    AT()\n    ])","6c489a5b":"#\u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u044b\ntrainset = ChartsDataset('.\/', train_list,  transform=data_transforms)\ntestset = ChartsDataset('.\/', test_list,  transform=data_transforms_test, mode=\"test\")","79798598":"valid_size = int(len(train_list) * 0.1)\ntrain_set, valid_set = torch.utils.data.random_split(trainset, \n                                    (len(train_list)-valid_size, valid_size))","84c7bb02":"trainloader = torch.utils.data.DataLoader(train_set, pin_memory=True, \n                                        batch_size=batch_size, shuffle=True,\n                                        num_workers = num_workers)\n\nvalidloader = torch.utils.data.DataLoader(valid_set, pin_memory=True, \n                                        batch_size=batch_size, shuffle=True,\n                                        num_workers = num_workers)\n\ntestloader = torch.utils.data.DataLoader(testset, batch_size = batch_size,\n                                         num_workers = num_workers)","1a5cc8ce":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","214332b1":"model = torchvision.models.resnet152(pretrained=True, progress=True)","f0e0dab5":"for param in model.parameters():\n    param.requires_grad = False\n\nin_features = model.fc.in_features","7d698de3":"model.fc = nn.Sequential(nn.Linear(in_features, 1024),\n                         nn.Linear(1024,8))","4cc9aee7":"def train_model(model_conv, train_loader, valid_loader, criterion, optimizer, sheduler, n_epochs):\n    model_conv.to(device)\n    valid_loss_min = np.Inf\n    patience = 10\n    # \u0441\u043a\u043e\u043b\u044c\u043a\u043e \u044d\u043f\u043e\u0445 \u0436\u0434\u0435\u043c \u0434\u043e \u043e\u0442\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u044f\n    p = 0\n    # \u0438\u043d\u0430\u0447\u0435 \u043e\u0441\u0442\u0430\u043d\u0430\u0432\u043b\u0438\u0432\u0430\u0435\u043c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435\n    stop = False\n\n    # \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u044d\u043f\u043e\u0445\n    for epoch in range(1, n_epochs+1):\n        print(time.ctime(), 'Epoch:', epoch)\n\n        train_loss = []\n\n        for batch_i, (data, target) in enumerate(tqdm(train_loader)):\n            data, target = data.to(device), target.to(device)\n            optimizer.zero_grad()\n            output = model_conv(data)\n            loss = criterion(output, target)\n            train_loss.append(loss.item())\n            loss.backward()\n            optimizer.step()\n        # \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u043c \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044e\n        model_conv.eval()\n        val_loss = []\n        for batch_i, (data, target) in enumerate(valid_loader):\n            data, target = data.to(device), target.to(device)\n            output = model_conv(data)\n            loss = criterion(output, target)\n            val_loss.append(loss.item()) \n\n        print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}, valid loss: {np.mean(val_loss):.4f}.')\n\n        valid_loss = np.mean(val_loss)\n        scheduler.step(valid_loss)\n        if valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n            valid_loss_min,\n            valid_loss))\n            torch.save(model_conv.state_dict(), 'model.pt')\n            valid_loss_min = valid_loss\n            p = 0\n\n        # \u043f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c \u043a\u0430\u043a \u0434\u0435\u043b\u0430 \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438\n        if valid_loss > valid_loss_min:\n            p += 1\n            print(f'{p} epochs of increasing val loss')\n            if p > patience:\n                print('Stopping training')\n                stop = True\n                break        \n\n    return model_conv, train_loss, val_loss","b4a16fa1":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0007)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, patience=3,)","713ed9f9":"model_resnet, train_loss, val_loss = train_model(model, trainloader, validloader, criterion, \n                              optimizer, scheduler, n_epochs=80,)","ba2957ff":"sample_submission = pd.read_csv(\"sample_submission.csv\")\nmodel.to(device)\nmodel.eval()\npred_list = []\nnames_list = []\nfor images, image_names in testloader:\n    with torch.no_grad():\n        images = images.to(device)\n        output = model(images)\n        pred = F.softmax(output)\n        pred = torch.argmax(pred, dim=1).cpu().numpy()\n        pred_list += [p.item() for p in pred]\n        names_list += [name for name in image_names]\n\n\nsample_submission.image_name = names_list\nsample_submission.label = pred_list\nsample_submission[\"image_name\"]=sample_submission[\"image_name\"].apply(lambda x: x.split('\/')[1])\nsample_submission.to_csv('submission_152_10-3.csv', index=False)","f4729d8d":"# \u0418\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f ","d9aa5de6":"# Test","4540c02e":"# \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435","170e920e":"# \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438"}}