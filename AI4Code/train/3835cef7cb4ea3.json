{"cell_type":{"734e5ef2":"code","ef0a85d7":"code","335ead49":"code","62ba7b03":"code","9ebac5bf":"code","616f59bf":"code","39b6ef51":"code","eb8c1b40":"code","ceaf15a1":"code","f982fc9b":"code","92185c0c":"code","9173bef2":"code","8739cf76":"code","43816f0e":"code","153588d2":"code","1b223fcb":"code","ccf3a425":"code","8110a1ee":"code","a129c072":"code","8f88fcb7":"code","53301303":"code","1dd4bbfa":"code","ed242c39":"code","f7648cd5":"code","2dcd5505":"code","733db3c2":"code","380f6278":"code","3c693d92":"code","fdad2ba3":"code","9b95107b":"code","b6b9711e":"code","5fdb5969":"code","a1324c3a":"code","b5867de5":"code","74a66caa":"code","86daf8cd":"code","ee4a4111":"code","09d8def6":"code","d4ed4b67":"code","58f08c07":"code","1f8be050":"code","3d03a5b2":"code","f6b39fd6":"code","f6d60f5a":"code","4f5df7ab":"code","207f0dbe":"code","535b5877":"code","b3a47f89":"code","c6d941c0":"code","8ef2d657":"code","18385a29":"code","3282898e":"code","66d35332":"code","2d9eb7d7":"code","2d79e52a":"code","c94b9ee3":"code","eb3ca650":"code","d5634e3f":"code","8013ee68":"code","036d202e":"code","f9a9d6b8":"code","00b77191":"code","2f7c6bbb":"code","46843697":"code","ee857f80":"code","068f0591":"code","9b724431":"code","4a42905d":"code","6db64b96":"code","d74f61c4":"code","f793cfa6":"code","425581bc":"code","a0d870aa":"code","a18ee8a2":"code","711a2ca6":"code","735cbbb2":"code","ee066fb1":"code","6dfafa32":"code","efc39cd2":"code","7897c141":"code","4e1a463c":"markdown","62f39d6b":"markdown","a8643af6":"markdown","3711cdc4":"markdown","5bd421e4":"markdown","1d1903f2":"markdown","5fc7006d":"markdown","84089beb":"markdown","8f4f65ac":"markdown","b30fb1da":"markdown","4b7b6d36":"markdown"},"source":{"734e5ef2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ef0a85d7":"import pandas as pd\nimport numpy as np\ntrain = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/train.csv')\ntrain.drop(['Id'], axis=1, inplace=True)\ntrain","335ead49":"test = pd.read_csv('..\/input\/tabular-playground-series-dec-2021\/test.csv')\ntest.drop(['Id'], axis=1, inplace=True)\ntest","62ba7b03":"train.loc[train['Cover_Type'] > 4] -= 1\ntrain['Cover_Type'] -= 1\ntrain.drop(3403875, inplace=True)\ntrain = train.reset_index()","9ebac5bf":"train.drop(['index'], axis=1, inplace=True)","616f59bf":"train.Cover_Type.value_counts()","39b6ef51":"train.describe()","eb8c1b40":"train.columns","ceaf15a1":"corr_matrix = train.corr().abs()\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),\nk=1).astype(np.bool))\nto_drop = [column for column in upper.columns if any(upper[column] > 0.90)]\n","f982fc9b":"train = train.drop(to_drop, axis=1)","92185c0c":"to_drop","9173bef2":"test = test.drop(to_drop, axis=1)","8739cf76":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize = (15,10))\n\nsns.set(font_scale=0.4)\ncorr_matrix = train.corr()\nsns.heatmap(corr_matrix, annot=True, linewidths=.1, cmap='coolwarm')\nplt.title('Correlation matrix')\nplt.show()","43816f0e":"temp = train.loc[train.Cover_Type == 1]\ntemp = temp.append(train.loc[train.Cover_Type == 0])\ntemp","153588d2":"temp = temp.sample(frac=1)\ntemp","1b223fcb":"temp = temp[:400000][:]\ntemp","ccf3a425":"temp.Cover_Type.value_counts()","8110a1ee":"train = train.drop(train.loc[train.Cover_Type == 1].index)\ntrain = train.drop(train.loc[train.Cover_Type == 0].index)\ntrain = train.append(temp)\ntrain.Cover_Type.value_counts()","a129c072":"#train['Cover_Type'] = np.int64(train['Cover_Type'])","8f88fcb7":"temp = None","53301303":"train","1dd4bbfa":"from imblearn.over_sampling import SMOTE\n\nos = SMOTE(random_state=0, k_neighbors=5)\n\n# \u0432\u0435\u043a\u0442\u043e\u0440 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\nX_temp = train.drop(['Cover_Type'], axis=1) \n# \u0432\u0435\u043a\u0442\u043e\u0440 \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439\ny_temp = train['Cover_Type']\n\ncolumn = X_temp.columns\n\nX_temp, y_temp = os.fit_resample(X_temp, y_temp)\nX_temp = pd.DataFrame(data=X_temp, columns=column)\ny_temp = pd.DataFrame(data=y_temp, columns=['Cover_Type'])","ed242c39":"X = train.drop(['Cover_Type'], axis=1)\ny = train['Cover_Type']\nX = X.append(X_temp)\ny = y.to_numpy()\ny = pd.DataFrame(y, columns=['Cover_Type'])\ny = y.append(y_temp)","f7648cd5":"X_temp, y_temp = None, None","2dcd5505":"X = X.reset_index()\nX.drop(['index'], axis=1, inplace=True)\nX","733db3c2":"y = y.reset_index()\ny.drop(['index'], axis=1, inplace=True)\ny","380f6278":"train = pd.concat([X, y], axis=1, ignore_index=False)\ntrain","3c693d92":"X = None\ny = None","fdad2ba3":"X = train.drop(['Wilderness_Area1',\n       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n       'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n       'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n       'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n       'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n       'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n       'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n       'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n       'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n       'Soil_Type39', 'Soil_Type40', 'Cover_Type'], axis=1)\ny = train['Cover_Type']","9b95107b":"from sklearn.preprocessing import MinMaxScaler\n\n\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaler.fit(X)\nX_norm = scaler.transform(X)\nX_norm = pd.DataFrame(X_norm, columns=X.columns)\nX_norm","b6b9711e":"test = scaler.transform(test)","5fdb5969":"train = pd.concat([X_norm, train[['Wilderness_Area1',\n       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n       'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n       'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n       'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n       'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n       'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n       'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n       'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n       'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n       'Soil_Type39', 'Soil_Type40', 'Cover_Type']]], axis=1, ignore_index=False)\ntrain","a1324c3a":"X_norm = None","b5867de5":"X = train.drop(['Cover_Type'], axis=1)\ny = train['Cover_Type']\nprint(X.shape)\nprint(y.shape)","74a66caa":"train = None","86daf8cd":"import torch\nimport random\nimport numpy as np\n\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)\ntorch.backends.cudnn.deterministic = True","ee4a4111":"X_train = X.to_numpy()\nX_train = torch.from_numpy(X_train).float()","09d8def6":"y_train = y.to_numpy()\ny_train = torch.from_numpy(y_train)","d4ed4b67":"class ClassifierNet(torch.nn.Module):\n\n    def __init__(self, n_hidden_neurons):\n        super(ClassifierNet, self).__init__()\n\n        self.fc1 = torch.nn.Linear(51, n_hidden_neurons)\n        self.ac1 = torch.nn.ReLU()\n        self.batch_norm1 = torch.nn.BatchNorm1d(n_hidden_neurons)\n\n        self.fc2 = torch.nn.Linear(n_hidden_neurons, n_hidden_neurons)\n        self.ac2 = torch.nn.ReLU()\n        self.batch_norm2 = torch.nn.BatchNorm1d(n_hidden_neurons)\n\n        self.fc3 = torch.nn.Linear(n_hidden_neurons, n_hidden_neurons)\n        self.ac3 = torch.nn.ReLU()\n        self.batch_norm3 = torch.nn.BatchNorm1d(n_hidden_neurons)\n\n        self.fc4 = torch.nn.Linear(n_hidden_neurons, n_hidden_neurons \/\/ 2)\n        self.ac4 = torch.nn.ReLU()\n        self.batch_norm4 = torch.nn.BatchNorm1d(n_hidden_neurons \/\/ 2)\n\n        self.fc5 = torch.nn.Linear(n_hidden_neurons \/\/ 2, n_hidden_neurons \/\/ 4)\n        self.ac5 = torch.nn.ReLU()\n        self.dr = torch.nn.Dropout(p=0.5)\n        self.batch_norm5 = torch.nn.BatchNorm1d(n_hidden_neurons \/\/ 4)\n\n        self.fc6 = torch.nn.Linear(n_hidden_neurons \/\/ 4, 6)\n    \n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.ac1(x)\n        x = self.batch_norm1(x)\n        x = self.fc2(x)\n        x = self.ac2(x)\n        x = self.batch_norm2(x)\n        x = self.fc3(x)\n        x = self.ac3(x)\n        x = self.batch_norm3(x)\n        x = self.fc4(x)\n        x = self.ac4(x)\n        x = self.batch_norm4(x)\n        x = self.fc5(x)\n        x = self.ac5(x)\n        x = self.dr(x)\n        x = self.batch_norm5(x)\n        x = self.fc6(x)\n        \n        return x\n\nnet = ClassifierNet(128)","58f08c07":"torch.cuda.is_available()","1f8be050":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nnet = net.to(device) ","3d03a5b2":"loss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(net.parameters(), lr=1.0e-3)","f6b39fd6":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)","f6d60f5a":"batch_size = 500000\n\nfor epoch in range(1000):\n    order = np.random.permutation(len(X_train))\n    for start_index in range(0, len(X_train), batch_size):\n        optimizer.zero_grad()\n        \n        batch_indexes = order[start_index:start_index+batch_size]\n        \n        X_batch = X_train[batch_indexes].to(device)\n        y_batch = y_train[batch_indexes].to(device)\n        \n        preds = net.forward(X_batch)\n        \n        loss_value = loss(preds, y_batch)\n        loss_value.backward()\n        \n        optimizer.step()\n    if epoch % 10 == 0:\n        net.eval()\n        preds_val = net.forward(X_val.to(device))\n        print(epoch, \"train: \" ,(preds.argmax(dim=1) == y_batch).float().mean())\n        print(epoch, \"valid: \" ,(preds_val.argmax(dim=1) == y_val.to(device)).float().mean())\n        net.train()","4f5df7ab":"X_test = test.to_numpy()\nX_test = torch.from_numpy(X_test).float()\nX_test = X_test.to(device)","207f0dbe":"y_test = net.forward(X_test)","535b5877":"y_test = y_test.argmax(dim=1)","b3a47f89":"y_test = y_test.cpu()","c6d941c0":"y_test += 1\ny_test","8ef2d657":"y_test[y_test > 4] += 1\ny_test","18385a29":"ind = np.linspace(4000000, 4999999,num= 1000000, dtype=int)\nind.shape","3282898e":"y_pred = pd.DataFrame({'id': ind, 'Cover_Type': y_test})\nprint(y_pred.Cover_Type.value_counts())\n# y_test = y_test.set_index('id')\nprint(y_pred)","66d35332":"y_pred.to_csv('submission.csv', index=None)","2d9eb7d7":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nimport xgboost as xgb\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n\n\nlog = LogisticRegression()\ntree = DecisionTreeClassifier()\nknn = KNeighborsClassifier()\nxgb = xgb.XGBClassifier()\ncatboost = CatBoostClassifier() ","2d79e52a":"accuracy = []\nX_train, X_test, y_train, y_test = train_test_split(train.drop(['Cover_Type'], axis=1), train.Cover_Type, test_size=0.3, random_state=42)\n\nmodels = [tree, knn, xgb, catboost]\n\nfor model in models:\n    print(model)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    accuracy.append(accuracy_score(y_test, y_pred))","c94b9ee3":"df_score = pd.DataFrame({'models': models, 'accuracy': accuracy})\ndf_score","eb3ca650":"from sklearn.tree import DecisionTreeClassifier\n\ntree = DecisionTreeClassifier()","d5634e3f":"from sklearn.model_selection import GridSearchCV\n\n\ngrid = {'criterion':['gini','entropy'],\n             'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]}\nclf = GridSearchCV(tree, grid, cv=5)\nclf.fit(X_train, y_train)","8013ee68":"clf.best_params_","036d202e":"clf.fit(X=X_train, y=y_train)","f9a9d6b8":"y_pred = clf.predict(test)\ny_pred","00b77191":"y_pred.shape","2f7c6bbb":"ind = np.linspace(4000000, 4999999,num= 1000000, dtype=int)\nind.shape","46843697":"y_pred = pd.DataFrame({'id': ind, 'Cover_Type': y_pred})\nprint(y_pred.Cover_Type.value_counts())\n# y_test = y_test.set_index('id')\nprint(y_pred)","ee857f80":"y_pred.loc[y_pred['Cover_Type'] > 4] += 1\ny_pred['Cover_Type'] += 1","068f0591":"y_pred.Cover_Type.value_counts()","9b724431":"y_pred.to_csv('submission.csv', index=False)","4a42905d":"from catboost import CatBoostClassifier\n\ncat = CatBoostClassifier(task_type='GPU')","6db64b96":"grid = {'learning_rate': [0.2, 0.3, 0.4],\n        'depth': [5, 7, 9],\n        'l2_leaf_reg': [1, 3, 5],\n        'iterations': [1000, 1200, 1300]}\n\ngrid_search_result = cat.grid_search(grid, X=X, y=y, plot=True, verbose=False)","d74f61c4":"grid_search_result['params']   ","f793cfa6":"cat = CatBoostClassifier()","425581bc":"cat.fit(X=features_kbest, y=train.Cover_Type, verbose=False);","a0d870aa":"y_test = cat.predict(test)","a18ee8a2":"y_test","711a2ca6":"y_test = y_test.reshape(-1)","735cbbb2":"ind = np.linspace(4000000, 4999999,num= 1000000, dtype=int)\nind.shape","ee066fb1":"y_pred = pd.DataFrame({'id': ind, 'Cover_Type': y_test})\nprint(y_pred.Cover_Type.value_counts())\n# y_test = y_test.set_index('id')\nprint(y_pred)","6dfafa32":"y_pred.loc[y_pred['Cover_Type'] > 4] += 1\ny_pred['Cover_Type'] += 1","efc39cd2":"y_pred.Cover_Type.value_counts()","7897c141":"y_pred.to_csv('submission.csv', index=False)","4e1a463c":"## Correlation matrix","62f39d6b":"# Loading data","a8643af6":"# CatBoost","3711cdc4":"# DecisionTree","5bd421e4":"## \u0420\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445","1d1903f2":"# Data processing","5fc7006d":"## Processing highly correlated features","84089beb":"## Normalization","8f4f65ac":"## Balancing data","b30fb1da":"# Neural network","4b7b6d36":"# Model selection"}}