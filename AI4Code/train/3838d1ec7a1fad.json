{"cell_type":{"0d4bff86":"code","2a9e06b0":"code","3d6da601":"code","4e3e39fb":"code","d6eb4e19":"code","b7460546":"code","c1df181c":"code","4b86b749":"code","3671c8b2":"code","01940c94":"code","3fc3678d":"code","2b9cfe95":"code","f216cbbd":"code","9c657c0d":"code","1c3d4c04":"code","0f88c54a":"code","c90c038a":"code","16c64457":"code","a8a24d37":"code","b56b200a":"code","fd38a13a":"code","b728e5d3":"code","7f7f9066":"code","c5f05e81":"code","0d74ac02":"code","08e8307f":"code","e4b94952":"code","bd44c884":"code","2c4c8472":"code","ad6945a2":"code","8794fe51":"code","c811e1a5":"code","3084c656":"code","551fec17":"code","8f436a47":"code","6ce1af8f":"code","deb40091":"code","4175d8f3":"code","1a697a4a":"code","e98cce48":"code","288d736e":"code","04eec7a6":"code","c34f2b6f":"code","432c4c0a":"code","2cdfd3bf":"code","54f57009":"code","2613b02d":"code","47009204":"code","8d1be255":"code","a9cddbec":"code","06f22fcb":"code","e56d07ff":"code","38e4df07":"code","72b13d72":"code","c0bbe2c7":"code","20bb0eaa":"markdown","97616f83":"markdown","5d813cf3":"markdown","d768b145":"markdown","05bfc2ad":"markdown","9fccc179":"markdown","72710964":"markdown","e88cdb46":"markdown","6b3bca5d":"markdown","0a9ae465":"markdown","9f14300a":"markdown","7d94e147":"markdown","67ea4b3c":"markdown","fe5a5df8":"markdown","96085a02":"markdown","6fca7fe5":"markdown","63ba736a":"markdown","9ecd7612":"markdown","25ff2f0c":"markdown","d99fbe4e":"markdown","1e5f564f":"markdown","c818778e":"markdown","5faa8caa":"markdown","d36f697d":"markdown","0af9d9dd":"markdown","e0af208e":"markdown","d2e5535e":"markdown","a8f9e19c":"markdown","dedfed68":"markdown","4fd3eaa4":"markdown","726b4a6f":"markdown","bdb32a18":"markdown","81543368":"markdown","022afad5":"markdown","c4af147e":"markdown"},"source":{"0d4bff86":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\")\n\nimport seaborn as sns\n\nfrom collections import Counter\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2a9e06b0":"data=pd.read_csv(\"\/kaggle\/input\/xAPI-Edu-Data\/xAPI-Edu-Data.csv\")\ndata.head()","3d6da601":"data.info()","4e3e39fb":"data.describe()","d6eb4e19":"categorical_columns=list(data.columns[data.dtypes==object])\ncategorical_columns","b7460546":"for each in categorical_columns:\n    unique_variables=data[each].unique()\n    print(unique_variables)\n    ","c1df181c":"def bar_plot(columns_name):\n    #get variable of the columns\n    df= data[columns_name]\n    vc=df.value_counts()\n    #draw plot\n    plt.figure(figsize=(5,5))\n    sns.barplot(x=vc.index, y=vc.values)\n    plt.xlabel(columns_name)\n    plt.ylabel(\"Frequency\")\n    plt.title(columns_name + \" frequency table \")\n    plt.show()\n    print(\"{}: \\n {}\".format(vc.index,vc.values)) \nfor each in categorical_columns:\n    bar_plot(each)","4b86b749":"data[\"NationalITy\"]=data[\"NationalITy\"].replace([\"lebanon\",\"Egypt\",\"SaudiArabia\",\"USA\",\"venzuela\",\n                                          \"Iran\",\"Tunis\",\"Morocco\",\"Syria\",\"Palestine\",\n                                          \"Iraq\",\"Lybia\"],\"Other\")\ndata[\"PlaceofBirth\"]=data[\"PlaceofBirth\"].replace([\"lebanon\",\"Egypt\",\"SaudiArabia\",\"USA\",\"venzuela\",\n                                          \"Iran\",\"Tunis\",\"Morocco\",\"Syria\",\"Palestine\",\n                                          \"Iraq\",\"Lybia\"],\"Other\") \n\n","3671c8b2":"numerical_columns=list(data.columns[data.dtypes==int])\nnumerical_columns","01940c94":"def box_plot(columns_name):\n    #get variable of the columns\n    df= data[columns_name]\n    #draw plot\n    plt.figure(figsize=(5,5))\n    sns.boxplot(x=df)\n    plt.xlabel(columns_name)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} boxplot \".format(columns_name))\n    plt.show()\n    \ndef plot_hist(columns_name):\n    #get variable of the columns\n    df= data[columns_name]  \n    #draw plot\n    plt.figure(figsize=(5,5))\n    plt.hist(df, bins = 50)\n    plt.xlabel(columns_name)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} distribution with hist\".format(columns_name))\n    plt.show()\n    \nfor each in numerical_columns:\n    box_plot(each)\n    plot_hist(each)\n\n    ","3fc3678d":"data.Class.value_counts(normalize=True).plot(kind='bar')","2b9cfe95":"fig, (axis1, axis2, axis3,axis4)  = plt.subplots(1, 4,figsize=(20,5))\nsns.swarmplot(x='Class', y='AnnouncementsView', data=data, ax=axis1)\nsns.swarmplot(x='Class', y='raisedhands', data=data, ax=axis2)\nsns.swarmplot(x='Class', y='VisITedResources', data=data, ax=axis3)\nsns.swarmplot(x='Class', y='Discussion', data=data, ax=axis4)\n\n\n\n\n\n","f216cbbd":"fig, (axis1, axis2, axis3, axis4)  = plt.subplots(1, 4,figsize=(20,5))\nsns.boxplot(x='Class', y='AnnouncementsView', data=data, order=['L','M','H'], ax=axis1)\nsns.boxplot(x='Class', y='raisedhands', data=data, order=['L','M','H'], ax=axis2)\nsns.boxplot(x='Class', y='VisITedResources', data=data, order=['L','M','H'], ax=axis3)\nsns.boxplot(x='Class', y='Discussion', data=data, order=['L','M','H'], ax=axis4)\n","9c657c0d":"CategoricalColumns2=[\"gender\",\"NationalITy\",\"PlaceofBirth\",\"Topic\",\"Semester\",\"Relation\",\"ParentAnsweringSurvey\",\"ParentschoolSatisfaction\",\"StudentAbsenceDays\"]\nfor each in CategoricalColumns2:  \n    plot = sns.countplot(x='Class', hue=each, data=data, order=['L', 'M', 'H'])\n    plot.set(xlabel='Class', ylabel='Count', title='{} Comparison'.format(each))\n    plt.show()","1c3d4c04":"sns.pairplot(data,hue='Class')","0f88c54a":"data.isnull().sum()","c90c038a":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndata[\"Class\"] = le.fit_transform(data[\"Class\"])\ndata","16c64457":"data_encoded2=data.copy()","a8a24d37":"categorical_columns.remove(\"Class\")","b56b200a":"categorical_columns","fd38a13a":"data_encoded2=pd.get_dummies(data_encoded2, columns=categorical_columns)\ndata_encoded2.head()","b728e5d3":"data_encoded2.columns","7f7f9066":"data_encoded2.shape","c5f05e81":"numerical_columns","0d74ac02":"from sklearn import preprocessing\ndata_encoded2[['raisedhands', 'VisITedResources', 'AnnouncementsView', 'Discussion']]=pd.DataFrame(preprocessing.MinMaxScaler().fit_transform(data_encoded2[['raisedhands', 'VisITedResources', 'AnnouncementsView', 'Discussion']]))\ndata_encoded2","08e8307f":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","e4b94952":"x=data_encoded2.drop([\"Class\"], axis=1)\ny=data_encoded2.Class\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.33, random_state=42)\nprint(\"train data size =  \", len(x_train) ,\"   ,   \",\"test data size =  \", len(x_test))\n","bd44c884":"cv_result=[]","2c4c8472":"from sklearn.svm import SVC\nsvm=SVC(random_state=42)\nsvm.fit(x_train,y_train)\ny_pred=svm.predict(x_test)\nprint(\"Accuracy: % {}\".format(svm.score(x_test,y_test)))\n","ad6945a2":"from sklearn.model_selection import GridSearchCV\nparam = {\n    'C'     :[0.1,0.5,0.9,1,1.5,1.2,1.3,1.4],\n    'kernel':['linear', 'rbf'],\n    'gamma' :[0.1,0.8,0.9,1,1.1,1.2,1.3,1.4]\n}\nsvm2 = GridSearchCV(svm, param_grid=param, scoring='accuracy', cv=30)\nsvm2.fit(x_train,y_train)\nsvm2.best_params_","8794fe51":"svm3 = SVC(C = 0.5, gamma = 0.1, kernel = 'linear')\nsvm3.fit(x_train,y_train)\npredictions = svm3.predict(x_test)\nscore = round(accuracy_score(y_test,predictions),5)\nprint(\"Support Vector Machine Grid Search CV Score {}\".format(score))","c811e1a5":"from sklearn.model_selection import cross_val_score\naccuracies=cross_val_score(estimator = svm3, X=x_train, y=y_train, cv=10) \naccuracies\n\navarage=accuracies.mean()\nstd=np.std(accuracies) \nprint(\"avarage:\" ,avarage)\nprint(\"std:    \",std)\n\ncv_result.append(avarage)","3084c656":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix\n\nconfusion_matrix(y_test, svm.predict(x_test))\n\ntitles_options = [(\"Confusion matrix, without normalization\", None),\n                  (\"Normalized confusion matrix\", 'true')]\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(svm3, x_test, y_test, cmap=plt.cm.Blues,normalize=normalize)\n    disp.ax_.set_title(title)\n\nplt.show()","551fec17":"lr = LogisticRegression()\nlr.fit(x_train, y_train)\ny_pred=lr.predict(x_test)\nprint(\"Accuracy: % {}\".format(lr.score(x_test,y_test)))","8f436a47":"from sklearn.model_selection import cross_val_score\n\naccuracies=cross_val_score(estimator = lr, X=x_train, y=y_train, cv=10)\nprint(accuracies)\navarage=accuracies.mean()\nstd=np.std(accuracies) \nprint(\"avarage:\" ,avarage)\nprint(\"std:    \",std)\n\ncv_result.append(avarage)","6ce1af8f":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nknn=KNeighborsClassifier(n_neighbors=10)\nknn.fit(x_train, y_train)\ny_pred=knn.predict(x_test)\n\nprint(\"Accuracy: % {}\".format(knn.score(x_test,y_test)))\n\nscore_dict={}\n\nfor each in range(2,40):\n    knn=KNeighborsClassifier(n_neighbors=each)\n    knn.fit(x_train, y_train)\n    y_pred=knn.predict(x_test)\n    accuracy_score(y_test,y_pred)\n    score_dict[each] = knn.score(x_test, y_test)\n\nprint(max(score_dict.values()))\nprint(max(score_dict, key=score_dict.get))\n\n\nknn=KNeighborsClassifier(n_neighbors=max(score_dict, key=score_dict.get))\nknn.fit(x_train, y_train)\n\ngrid = {\"n_neighbors\":np.arange(1,50)}\nknn=KNeighborsClassifier()\nknn_cv=GridSearchCV(knn, grid, cv=10)\nknn_cv.fit(x_train, y_train)\nprint(knn_cv.best_params_)\nprint(knn_cv.best_score_)","deb40091":"from sklearn.model_selection import cross_val_score\naccuracies=cross_val_score(estimator = knn, X=x_train, y=y_train, cv=10)\nprint(accuracies)\navarage=accuracies.mean()\nstd=np.std(accuracies)  \navarage\nprint(\"avarage:\" ,avarage)\nprint(\"std:    \",std)\n\ncv_result.append(avarage)","4175d8f3":"from sklearn.linear_model import SGDClassifier\nsgd =  SGDClassifier(loss='modified_huber', shuffle=True,random_state=42)\nsgd.fit(x_train, y_train)\ny_pred=sgd.predict(x_test)\n\nprint(sgd.score(x_test,y_test))\n","1a697a4a":"from sklearn.tree import DecisionTreeClassifier\ndt=DecisionTreeClassifier()\ndt.fit(x_train,y_train)\n\n\nprint(\"Accuracy: % {}\".format(dt.score(x_test,y_test)))","e98cce48":"from sklearn.model_selection import cross_val_score\naccuracies=cross_val_score(estimator = dt, X=x_train, y=y_train, cv=10)\nprint(accuracies)\navarage=accuracies.mean()\nstd=np.std(accuracies)  \navarage\nprint(\"avarage:\" ,avarage)\nprint(\"std:    \",std)\n\ncv_result.append(avarage)","288d736e":"from sklearn.ensemble import RandomForestClassifier\n\nscore_dict={}\nfor each in range(1,100):\n    rf=RandomForestClassifier(n_estimators=each, random_state=42)\n    rf.fit(x_train, y_train)\n    y_pred=rf.predict(x_test)\n    accuracy_score(y_test,y_pred)\n    score_dict[each] = rf.score(x_test, y_test)\n\nprint('Max Accuracy:', max(score_dict.values()), '\\n ')\nprint('Index of Max Accuracy:',max(score_dict, key=score_dict.get))","04eec7a6":"rf=RandomForestClassifier(n_estimators=max(score_dict, key=score_dict.get), random_state=42 )  \nrf.fit(x_train,y_train)\ny_pred=rf.predict(x_test)\naccuracy_score(y_test,y_pred)\n","c34f2b6f":"for name, score in zip(x.columns, rf.feature_importances_):\n    print(score, '\\t ',name)","432c4c0a":"from sklearn.model_selection import cross_val_score\naccuracies=cross_val_score(estimator = rf, X=x_train, y=y_train, cv=10) \nprint('10-Fold Cross Validation Accuricies:',accuracies, '\\n ')\navarage=accuracies.mean()\nstd=np.std(accuracies)  \nprint(\"Avarage Of The Accuracies:\" ,avarage , '\\n ')\nprint(\"Standard Deviation Of The Accuracies :\",std , '\\n ')\n\ncv_result.append(avarage)","2cdfd3bf":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\ny_pred=rf.predict(x_test)\nprint('Classification Report :\\n', classification_report(y_test, y_pred))","54f57009":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix\n\nconfusion_matrix(y_test, rf.predict(x_test))\n\ntitles_options = [(\"Confusion matrix, without normalization\", None),\n                  (\"Normalized confusion matrix\", 'true')]\nfor title, normalize in titles_options:\n    disp = plot_confusion_matrix(rf, x_test, y_test, cmap=plt.cm.Blues,normalize=normalize)\n    disp.ax_.set_title(title)\n\nplt.show()","2613b02d":"from sklearn.naive_bayes import GaussianNB\n\nnb=GaussianNB()\nnb.fit(x_train,y_train)\ny_pred=nb.predict(x_test)\n\nprint('accuracy of nb algorithm :',nb.score(x_test,y_test))","47009204":"from sklearn.model_selection import cross_val_score\naccuracies=cross_val_score(estimator = nb, X=x_train, y=y_train, cv=10) \nprint(accuracies)\navarage=accuracies.mean()\nstd=np.std(accuracies)  \nprint(\"avarage:\" ,avarage)\nprint(\"std:    \",std)\n\ncv_result.append(avarage)","8d1be255":"from xgboost import XGBClassifier, plot_importance\nscore_dict={}\nacc_=0\nindex=0\nfor each in range(1,10):\n    xgb = XGBClassifier(max_depth=9, learning_rate=0.1, n_estimators=each,seed=10)\n    xgb.fit(x_train, y_train)\n    y_pred=xgb.predict(x_test)\n    accuracy_score(y_test,y_pred)\n    score_dict[each] = xgb.score(x_test, y_test)\nprint(score_dict)\nmax(score_dict.values())\nmax(score_dict, key=score_dict.get)","a9cddbec":"xgb = XGBClassifier(max_depth=10, learning_rate=0.1, n_estimators=max(score_dict, key=score_dict.get),seed=10)\nxgb.fit(x_train, y_train)\ny_pred=xgb.predict(x_test)\nxgb.score(x_test, y_test)","06f22fcb":"from sklearn.model_selection import cross_val_score\naccuracies=cross_val_score(estimator = xgb, X=x_train, y=y_train, cv=10) \nprint(accuracies)\navarage=accuracies.mean()\nstd=np.std(accuracies)  \nprint(\"avarage:\" ,avarage)\nprint(\"std:    \",std)\n\ncv_result.append(avarage)","e56d07ff":"plot_importance(xgb)","38e4df07":"cv_results_df = pd.DataFrame({\"Cross Validation Means\":cv_result, \"ML Models\":[\"SVM\",\"LogisticRegression\",\"KNeighborsClassifier\",\"DecisionTreeClassifier\", \"RandomForestClassifier\", \"Naive Bayes\", \"XGB\"]})","72b13d72":"cv_results_df=cv_results_df.sort_values(by=['Cross Validation Means'], ascending=False)","c0bbe2c7":"print(cv_results_df)\nsns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results_df)\nplt.xlabel(\"Mean Accuracy\")\nplt.title(\"Cross Validation Scores\")","20bb0eaa":"<a id = \"27\"><\/a><br>\n### K-Cross Validation","97616f83":"* ****int64(4)****:   \n> raisedhands,      \n> VisITedResources,     \n> AnnouncementsView,      \n> Discussion\n* ** object(9)** :   \n> gender,     \n> NationalITy,      \n> PlaceofBirth,    \n> StageID,         \n> GradeID,\n> SectionID,     \n> Topic,       \n> Semester,      \n> Relation,               \n> ParentAnsweringSurvey,         \n> ParentschoolSatisfaction,         \n> StudentAbsenceDays,         \n> Class       ","5d813cf3":"<a id = \"3\"><\/a><br>\n# Variable Analysis\n","d768b145":"\nx_columns=x.columns\nfrom sklearn.ensemble import ExtraTreesClassifier\nmodel = ExtraTreesClassifier(n_estimators=10)\nmodel.fit(x, y)\n\n\n\ndf=pd.DataFrame(model.feature_importances_)\n\ndf[\"columns\"]=x_columns\ndf\n","05bfc2ad":"<a id = \"10\"><\/a><br>\n# Scaling ","9fccc179":"<a id = \"12\"><\/a><br>\n# MODELS","72710964":"<a id = \"1\"><\/a><br>\n# Load and Check Data","e88cdb46":"<a id = \"26\"><\/a><br>\n# XGBoost","6b3bca5d":"### One hot encoding","0a9ae465":"<a id = \"11\"><\/a><br>\n## Train Test Split","9f14300a":"<a id = \"21\"><\/a><br>\n# Random Forest","7d94e147":"<a id = \"28\"><\/a><br>\n# Comporison of the models ","67ea4b3c":"<a id = \"2\"><\/a><br>\n# Variable Description","fe5a5df8":"<a id = \"14\"><\/a><br>\n#### K Fold Cross Validition","96085a02":"<a id = \"7\"><\/a><br>\n# Missing Value\n","6fca7fe5":"<a id = \"16\"><\/a><br>\n# Logistic Regression ","63ba736a":"<a id = \"22\"><\/a><br>\n#### K-Cross Validation","9ecd7612":"<a id = \"25\"><\/a><br>\n### K-Fold Cross Validation","25ff2f0c":"<a id = \"15\"><\/a><br>\n#### Confussion Matrix","d99fbe4e":"<a id = \"6\"><\/a><br>\n# Visualizations","1e5f564f":"<a id = \"9\"><\/a><br>\n# Encoding : categorical data to numerical data","c818778e":"<a id = \"5\"><\/a><br>\n# Numerical Variables","5faa8caa":"<a id = \"13\"><\/a><br>\n# SVM","d36f697d":"* Categorical Variable: \n> Gender,    \n> NationalITy,     \n> PlaceofBirth, \t  \n> StageID,\t\n> GradeID,\t\n> SectionID,\t\n> Topic,\t\n> Semester,\t\n> Relation,   \n> ParentAnsweringSurvey,     \n> ParentschoolSatisfaction,\t\n> StudentAbsenceDays,\t\n> Class \n\n* Numerical Variable: \n> raisedhands,     \n> VisiTedResources,     \n> AnnouncementsView,    \n> Discussion  ","0af9d9dd":"<a id = \"17\"><\/a><br>\n#### K Fold Cross Validition","e0af208e":"<a id = \"8\"><\/a><br>\n# Preprocessing","d2e5535e":"# Introduction \n<font color = 'blue'>\nContent: \n    \n1. [Load and Check Data](#1)\n1. [Variable Description](#2)\n    * [Variable Analysis](#3)\n    * [Categorical Variable](#4)\n    * [Numerical Variable](#5)\n1. [Visualizations](#6)\n1. [Missing Value](#7)\n1. [Preprocessing](#8)\n    * [Encoding](#9)\n    * [Scaling](#10)\n1. [Split Data](#11)  \n1. [MODELS](#12)\n    1. [SVM](#13)\n        * [K-Fold Cross Validation](#14)\n        * [Confussion Matrix](#15)\n    1. [Logistic Regression](#16)\n        * [K-Fold Cross Validation](#17)\n    1. [KNN](#18)\n        * [K-Fold Cross Validation](#19)\n    1. [DECISION TREE](#20)\n    1. [RANDOM FOREST](#21)\n        * [K-Fold Cross Validation](#22)\n        * [Confusion Matrix](#23)\n    1. [Naive Bayes](#24)\n        * [K-Fold Cross Validation](#25)\n    1. [XGBoost](#26)\n        * [K-Fold Cross Validation](#27)\n    1. [Comparison of Models](#28)\n       \n\n\n    \n","a8f9e19c":"<a id = \"19\"><\/a><br>\n#### K Fold Cross Validition","dedfed68":"*  **Gender** - student's gender (nominal: 'Male' or 'Female\u2019)\n\n \n*  **NationalITy**- student's nationality (nominal:\u2019 Kuwait\u2019,\u2019 Lebanon\u2019,\u2019 Egypt\u2019,\u2019 SaudiArabia\u2019,\u2019 USA\u2019,\u2019 Jordan\u2019,\u2019\n Venezuela\u2019,\u2019 Iran\u2019,\u2019 Tunis\u2019,\u2019 Morocco\u2019,\u2019 Syria\u2019,\u2019 Palestine\u2019,\u2019 Iraq\u2019,\u2019 Lybia\u2019)\n \n \n* **PlaceofBirth** - student's Place of birth (nominal:\u2019 Kuwait\u2019,\u2019 Lebanon\u2019,\u2019 Egypt\u2019,\u2019 SaudiArabia\u2019,\u2019 USA\u2019,\u2019 Jordan\u2019,\u2019\n Venezuela\u2019,\u2019 Iran\u2019,\u2019 Tunis\u2019,\u2019 Morocco\u2019,\u2019 Syria\u2019,\u2019 Palestine\u2019,\u2019 Iraq\u2019,\u2019 Lybia\u2019)\n \n \n*  **StageID** -Educational Stages- educational level student belongs (nominal: \u2018lowerlevel\u2019,\u2019MiddleSchool\u2019,\u2019HighSchool\u2019)\n\n \n*  **GradeID**- Grade Levels- grade student belongs (nominal: \u2018G-01\u2019, \u2018G-02\u2019, \u2018G-03\u2019, \u2018G-04\u2019, \u2018G-05\u2019, \u2018G-06\u2019, \u2018G-07\u2019, \u2018G-08\u2019, \u2018G-09\u2019, \u2018G-10\u2019, \u2018G-11\u2019, \u2018G-12 \u2018)\n \n \n*  **SectionID-** classroom student belongs (nominal:\u2019A\u2019,\u2019B\u2019,\u2019C\u2019)\n \n \n*  **Topic**- course topic (nominal:\u2019 English\u2019,\u2019 Spanish\u2019, \u2018French\u2019,\u2019 Arabic\u2019,\u2019 IT\u2019,\u2019 Math\u2019,\u2019 Chemistry\u2019, \u2018Biology\u2019, \u2018Science\u2019,\u2019 History\u2019,\u2019 Quran\u2019,\u2019 Geology\u2019)\n \n \n*  **Semester**- school year semester (nominal:\u2019 First\u2019,\u2019 Second\u2019)\n \n \n*  **Relation** - Parent responsible for student (nominal:\u2019mom\u2019,\u2019father\u2019)\n \n \n*  **raisedhands**- how many times the student raises his\/her hand on classroom (numeric:0-100)\n\n\n*  **VisiTedResources**- how many times the student visits a course content(numeric:0-100)\n\n\n*  **AnnouncementsView**- Viewing announcements-how many times the student checks the new announcements(numeric:0-100)\n\n\n*  **Discussion** groups- how many times the student participate on discussion groups (numeric:0-100)\n\n\n*  **ParentAnsweringSurvey**- parent answered the surveys which are provided from school or not\n (nominal:\u2019Yes\u2019,\u2019No\u2019)\n\n\n*  **ParentschoolSatisfaction**- the Degree of parent satisfaction from school(nominal:\u2019Yes\u2019,\u2019No\u2019)\n\n\n*  **StudentAbsenceDays**-the number of absence days for each student (nominal: above-7, under-7)    ","4fd3eaa4":"<a id = \"4\"><\/a><br>\n# Categorical Variables","726b4a6f":"<a id = \"20\"><\/a><br>\n# Decision Tree\n","bdb32a18":"### Label Encoder","81543368":"<a id = \"23\"><\/a><br>\n#### Confusion Matrix","022afad5":"<a id = \"18\"><\/a><br>\n# KNN","c4af147e":"<a id = \"24\"><\/a><br>\n# Naive Bayes"}}