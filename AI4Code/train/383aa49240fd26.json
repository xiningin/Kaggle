{"cell_type":{"34ef46cc":"code","461c7563":"code","5dace9e1":"code","d84d181b":"code","7cc8bf48":"code","e700dc24":"code","7435d489":"code","b3bc1acd":"code","c017485d":"code","47ffa70a":"code","f11bca8f":"code","04c8b0ec":"code","7c5a511e":"markdown","9849f43f":"markdown","0c356cf5":"markdown","2f667719":"markdown","9c8c07c4":"markdown","9aaec5b5":"markdown","66bcf3bd":"markdown","832cf88f":"markdown","e5f856eb":"markdown","88753190":"markdown","60995a79":"markdown","f9393926":"markdown","c5ce7460":"markdown","39f06c31":"markdown"},"source":{"34ef46cc":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport seaborn as sns\nimport requests\nfrom PIL import Image\nimport imageio\nfrom io import BytesIO\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split","461c7563":"\"\"\"from tqdm import tqdm_notebook as tqdm\nimport pandas as pd\nimport requests\nfrom PIL import Image\nimport imageio\n\ngame_df = pd.read_csv('appstore_games.csv')\ngame_df = game_df.dropna(subset=['Icon URL', 'Average User Rating'])\n\nimm_arr_list=[]\nfor url in tqdm(game_df['Icon URL'], total=len(game_df['Icon URL'])):\n    res = requests.get(game_df['Icon URL'][0])\n    imm_arr = imageio.imread(BytesIO(res.content))\n    imm_arr_x, imm_arr_y = int(imm_arr.shape[0] \/ 2), int(imm_arr.shape[1] \/ 2)\n    imm_arr = np.array(Image.fromarray(imm_arr).resize((imm_arr_x, imm_arr_y)))\n    imm_arr_list.append(imm_arr)\n    \nimm_arr = np.stack(imm_arr_list, axis=0)\nnp.save('game_imm_arr', imm_arr)\"\"\"","5dace9e1":"game_df = pd.read_csv('..\/input\/17k-apple-app-store-strategy-games\/appstore_games.csv')\ngame_df = game_df.dropna(subset=['Icon URL', 'Average User Rating'])\ngame_df = game_df.drop_duplicates().reset_index(drop=True)\nimm_arr = np.load('..\/input\/game-image-array\/game_imm_arr.npy')\ngame_df['imm_arr'] = list(imm_arr)\ngame_df['User Rating Count'] = game_df['User Rating Count'].replace(np.nan, 0)\nprint(\"Imported image array shape : \", imm_arr.shape)\nprint(\"game_df shape : \", game_df.shape)\ngame_df.head()","d84d181b":"print('Unique values in `Average User Ratings`:\\n', game_df['Average User Rating'].unique())\nprint(game_df['Average User Rating'].describe())\n\nfig = plt.figure(facecolor='white')\nplt.hist(game_df['Average User Rating'], bins=20)\nplt.xlabel('Rating')\nplt.ylabel('Frequency')\n\nsns.despine()\nplt.show()","7cc8bf48":"numeric_columns = ['Average User Rating', 'User Rating Count', 'Price', 'Size']\nlow_rated_games = game_df[game_df['Average User Rating'] <= 2.5][numeric_columns]\nhigh_rated_games = game_df[game_df['Average User Rating'] >= 5][numeric_columns]\n\nprint(\"Poorly Rated Games (Rated 2 or below):\")\nprint(low_rated_games.describe())\nprint(\"Well Rated Games (Rated 4 or above):\")\nprint(high_rated_games.describe())\n\nprint('\\nP-Values of differences between means in `numeric_columns` : ')\nfor col in numeric_columns:\n    p_value_col = stats.ttest_ind(low_rated_games[col],high_rated_games[col])[1]\n    print(f'\\t\\\"{col}\\\" : ', p_value_col)","e700dc24":"n = 4\n\nfig, axs = plt.subplots(n, n, figsize= (10, 10), facecolor='white')\n\nfor i in range(0, n):\n    for j in range(0, n):\n        if abs(i - j) < 2:\n            random_test_df = game_df[game_df['Average User Rating'] < 2]\n            random_test_number = random_test_df.sample().reset_index()['index'][0]\n        else:\n            random_test_number = random.randint(0, len(game_df))\n    \n        display_url = game_df.loc[random_test_number, 'Icon URL']\n        display_rating = game_df.loc[random_test_number, 'Average User Rating']\n\n        res = requests.get(display_url)\n        display_imm_arr = imageio.imread(BytesIO(res.content))\n        axs[i][j].imshow(display_imm_arr, interpolation='nearest')\n        axs[i][j].set_title(f\"Rating: {display_rating}\")\n        \nfig.tight_layout()\nplt.show()\n","7435d489":"scaler = MinMaxScaler()\n\n### Creating a series of the average ratings\n### Will become target series\nrating_series = game_df['Average User Rating']\n\n### Creating array of non-image features\n### These are transformed using the `MinMaxScaler()`\nfeats = game_df[['User Rating Count', 'Size']].replace(np.nan, 0)\nfeats_array = scaler.fit_transform(feats)\n\n### Reshape all the image arrays into the same 4D shape for the Conv2D layer\nimm_arr = imm_arr.reshape(imm_arr.shape[0], 128, 128, 3) \/ 255\nprint(\"Features Array shape : \\t\", imm_arr.shape)\ninput_shape = (128, 128, 3)","b3bc1acd":"x_imm_train, x_imm_test, y_train, y_test = train_test_split(imm_arr, rating_series, test_size = .2)\n\ntrain_ind = y_train.index\ntest_ind = y_test.index\n\n### Convert y_* to arrays as we've extracted the useful indexes already\ny_train = np.asarray(y_train)\ny_train = y_train.reshape(-1,1)\ny_test = np.asarray(y_test)\ny_test = y_test.reshape(-1,1)\n\n### MinMax scale the y_train and y_test arrays to get the Ratings within the range a NN can predict\ny_train = scaler.fit_transform(y_train)\ny_test = scaler.fit_transform(y_test)\n\n### Create arrays of the non-image features using the derived index lists\nx_feats_train = np.asarray(feats_array[train_ind])\nx_feats_test = np.asarray(feats_array[test_ind])\n\nx_feats_train = scaler.fit_transform(x_feats_train)\nx_feats_test = scaler.fit_transform(x_feats_test)\n\nprint(\"x_feats_train shape : \\t\", x_feats_train.shape)\nprint(\"x_feats_test shape : \\t\", x_feats_test.shape)\nprint(\"x_imm_train shape : \\t\", x_imm_train.shape)\nprint(\"x_imm_test shape : \\t\", x_imm_test.shape)\nprint(\"y_train shape : \\t\", y_train.shape)\nprint(\"y_test shape : \\t\\t\", y_test.shape)","c017485d":"def build_image_model(filters, input_shape, initializer = tf.keras.initializers.he_normal()):\n    ### One input layer for each stream of data\n    input_feats = tf.keras.layers.Input(shape=(2,), name='feat_input')\n    input_image = tf.keras.layers.Input(shape=input_shape, name='image_input')\n    ### Reduce the images\n    conv_i_1 = tf.keras.layers.Conv2D(filters, 2, 2, activation='relu', padding=\"same\", kernel_initializer = initializer)(input_image)\n    max_i_1 = tf.keras.layers.MaxPool2D(pool_size=(2,2))(conv_i_1)\n    flatten_i = tf.keras.layers.Flatten()(max_i_1)\n    ### Merged the reduced image with the numeric features\n    merged = tf.keras.layers.concatenate([flatten_i, input_feats], axis=-1)\n    flatten1 = tf.keras.layers.Flatten()(merged)\n    dropout2 = tf.keras.layers.Dropout(.4)(flatten1)\n    dense2 = tf.keras.layers.Dense(64, activation='relu', kernel_initializer = initializer)(dropout2)\n    output = tf.keras.layers.Dense(1, activation='linear')(dense2)\n    model = tf.keras.models.Model(inputs=[input_feats, input_image], outputs=output)\n    return model","47ffa70a":"model = build_image_model(filters=64, input_shape = input_shape)\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='mean_squared_error', metrics=['mean_absolute_error'])\nmodel.summary()\n\nearlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n\ncallbacks_list = [earlystop_callback]\n\nhistory = model.fit([x_feats_train, x_imm_train], y_train, epochs=150, batch_size=15, validation_split = .2, callbacks=callbacks_list)","f11bca8f":"n = 4\n\nfig, axs = plt.subplots(n, n, figsize= (10, 10), facecolor='white')\n\nfor i in range(0, n):\n    for j in range(0, n):\n        if abs(i - j) < 2:\n            random_test_df = game_df[game_df['Average User Rating'] < 2]\n            random_test_number = random_test_df.sample().reset_index()['index'][0]\n        else:\n            random_test_number = random.randint(0, len(game_df))\n    \n        display_arr = imm_arr[random_test_number]\n        display_title = game_df.loc[random_test_number, 'Name']\n        display_rating = game_df.loc[random_test_number, 'Average User Rating']\n        display_rating_count = game_df.loc[random_test_number, 'User Rating Count']\n        display_size = game_df.loc[random_test_number, 'Size']\n        dis_feats_arr = np.asarray((display_rating_count, display_size)).reshape(1,2)\n        \n        dis_feats_arr = scaler.fit_transform(dis_feats_arr)\n        \n        pred = round(model.predict([dis_feats_arr, display_arr.reshape(1, 128, 128, 3)])[0][0] * 5, 3)\n        print(f\"Game title: {display_title}, \\nUser Rating Count: {display_rating_count}, \\nSize: {display_size}, \\nActual Rating: {display_rating}\")\n        print(f\"Predicted Rating: {pred}\\n\\n\")\n        \n        axs[i][j].imshow(display_arr, interpolation='nearest')\n        axs[i][j].set_title(f\"Rating: {display_rating}\\nPredicted Rating: {pred}\")\n        \nfig.tight_layout()\nplt.show()\n","04c8b0ec":"n=50\n\nindex_org = game_df.loc[:, 'Average User Rating'].sort_values().index[:n]\n\ncheck_df = game_df.loc[index_org, ['User Rating Count', 'Size', 'imm_arr', 'Average User Rating']]\npred_list = []\nfor index, row in check_df.iterrows():\n    row_feats = np.asarray([(row['User Rating Count'], row['Size'])]).reshape(-1,2)\n    reshaped_imm = row['imm_arr'].reshape(1, 128, 128, 3) \/ 255\n    row_feats = scaler.fit_transform(row_feats)\n    pred_list.append((model.predict([row_feats, reshaped_imm]) * 5)[0][0])\ncheck_df['pred'] = pred_list\ncheck_df = check_df.drop('imm_arr', axis=1)\n\ncheck_df\n","7c5a511e":"## Unused Function\n\nThe below script was run on my local machine to download and convert all the icons to arrays. ","9849f43f":"## Data Exploration\n\n### Target\n\nFirst we'll look at the distribution of the target variable. ","0c356cf5":"# Rating Apps Based on Their Icons and Download Stats\n\nIts typically easy to gauge an apps quality based on its icon. Will it be easy for a neural net?\n\n## Import Packages","2f667719":"## Conclusions\n\n- Using the App's Icon, Size and Number of Ratings, we could predict the apps rating with rough accuracy. Many low rated apps are falsely predicted to be well rated.\n- A simpler CNN was necessary as it was easy to overfit the uneven dataset. Architectures with more convolutions and wider layers resulted in a model overfit on the higher rated apps. \n- A dataset with more lower rated apps would allow the model to perform better of these samples. \n- Another option could be training the network on fewer of the positive samples although the dataset was already getting small (17,000 rows -> 7,000 rows) after filtering for missing ratings \/ icons. \n","9c8c07c4":"## Data-Prep\n\nBefore splitting the data, we'll select our relevant features, normalize them and finally reshape them.","9aaec5b5":"## Show Example Predictions\n\nCreate an `n` by `n` plot of App Icons, their assigned ratings and their predicted ratings. ","66bcf3bd":"## Import Data\n\nI'll drop any row with an `nan` value in either of the columns I plan to use. \n\nI'll also import the numpy array made from the images that I created on my local machine.","832cf88f":"The p-values of `User Rating Count` and `Size` are low enough that they look like they could be valuable. We'll use those two features and the image as input for the model.","e5f856eb":"We'll define the model, compile it, add an EarlyStopping callback and then fit the model. ","88753190":"Both the numeric summary and the plot show the same heavy left skew. It seems like people either don't like rating strategy games poorly or we have a dataset of really good games. Either way, that's going to impact the performance of our model. \n\nLets look at the numerical features of the poorly rated gamesto try to find something we can add to the model to help it pick bad games more accurately. ","60995a79":"## Split Training \/ Test Data\n\nUsing sklearn, I'll split the training and test data from the `imm_arr` and the `rating_array`.\n\nThen, I take the index from the y_train __series__ and use them to select the training and test examples from the non-image features.","f9393926":"Below, I'll show a few images from `Icon URL`. For some, I'll filter down to low rated games before sampling. Without this filter, sometimes its hard to find a poorly rated game in the random samples. ","c5ce7460":"## Build Model\n\nBelow I'll build a CNN to reduce our images a bit, combine them with the numeric features and convert the combination of the two feature sets to a rating. ","39f06c31":"The model doesn't do a great job predicting the lower rated apps, most likely due to the lower number of poorly rated apps. Below I'll print the `n` lowest rated apps and their predicted ratings. "}}