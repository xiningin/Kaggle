{"cell_type":{"c8f22830":"code","c543eb9d":"code","6c1d754b":"code","d934179b":"code","d6ce700b":"code","0d31c6b1":"code","141ae8ea":"code","3935109f":"code","88b0fe56":"code","2dfa7dcc":"code","72f724d9":"code","e9ece9bb":"code","9e6a9cbc":"code","3e4f3a68":"code","369b6dba":"code","4637bb70":"code","3971ac0c":"code","31911c65":"code","e4035ad4":"code","6a9931a9":"code","ab53281b":"code","c7a1f908":"code","b6149196":"code","ee28fb84":"code","893d2cbe":"code","98d5c8c1":"code","0700302e":"code","9c06cac4":"code","66f45bc8":"code","151e1765":"code","fe6d5c3b":"code","624554c7":"code","bda1257b":"code","bd81a87b":"code","fcde9759":"code","645ea67c":"code","9c25c5ca":"code","077e8d1e":"code","50c8acb8":"code","68fc839f":"code","3cf4df83":"code","39143c0e":"code","81536899":"code","08c2d1b6":"code","2da1570c":"code","7f5344d3":"code","2fabab73":"code","fd7a593d":"code","a80cfb10":"code","e0abfd7a":"code","d7f501f1":"code","57c61f6a":"code","691e02d7":"code","b3565a9c":"code","2d48bce0":"code","e2a11b72":"code","219b9438":"code","d068094a":"code","73a24ccf":"code","be5cd869":"code","1d1ba14f":"code","339fac42":"code","9ca71799":"code","d23d0f9a":"code","eace70bb":"code","c637c7cc":"code","bfc6985b":"code","d81d6114":"code","49d0157a":"markdown","868b9ff6":"markdown","ad9249f5":"markdown","4c6a6fa6":"markdown","e523086f":"markdown","0a181c2e":"markdown","8f7683d9":"markdown","3c376eff":"markdown","b942b0c8":"markdown","db8cf2e9":"markdown","df9f4b16":"markdown","006eff3c":"markdown","0ae2df0c":"markdown","0d2bfeac":"markdown","f08785c5":"markdown","ed165dca":"markdown","e5176b54":"markdown","b6200967":"markdown","9f03107c":"markdown","ce7c049b":"markdown","38f4fd76":"markdown","13df45d2":"markdown","c40aa9fd":"markdown","7295ab4f":"markdown","edd01d29":"markdown","af4918c2":"markdown","4ce577ed":"markdown","76968bff":"markdown"},"source":{"c8f22830":"from typing import List, Union, Dict, Optional, Tuple\nfrom datetime import datetime\nfrom os.path import join as pjoin\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","c543eb9d":"INPUT_PATH = '..\/input'\nDATA_PATH = pjoin(INPUT_PATH, 'lab34-classification-table')","6c1d754b":"train = pd.read_csv(pjoin(DATA_PATH, 'train.csv'), index_col=0)\ntest = pd.read_csv(pjoin(DATA_PATH, 'test.csv'), index_col=0)","d934179b":"train = train.astype({\n    'birth_date': 'datetime64[ns]',\n    'contact_date': 'datetime64[ns]',\n})\ntest = test.astype({\n    'birth_date': 'datetime64[ns]',\n    'contact_date': 'datetime64[ns]',\n})","d6ce700b":"train.shape, test.shape","0d31c6b1":"train.info()","141ae8ea":"test.info()","3935109f":"train.head()","88b0fe56":"test.head()","2dfa7dcc":"train.describe()","72f724d9":"test.describe()","e9ece9bb":"train.describe(include='object')","9e6a9cbc":"test.describe(include='object')","3e4f3a68":"y = train['y']\ny.mean()","369b6dba":"def get_cat_features(X: pd.DataFrame) -> List[str]:\n    return X.columns[X.dtypes == 'O'].tolist()","4637bb70":"def label_distplots(values, labels, kde=True, hist=True):\n    sns.distplot(values[labels == 1], kde=kde, hist=hist, label='Label=1', norm_hist=True)\n    sns.distplot(values[labels == 0], kde=kde, hist=hist, label='Label=0', norm_hist=True)\n    plt.legend();\n    \ndef set_figsize(width, height):\n    plt.rcParams['figure.figsize'] = width, height","3971ac0c":"train['contact_date'].min(), train['contact_date'].max()","31911c65":"contact_year = (train['contact_date'] - datetime(2000, 1, 1)).dt.days \/ 365 + 2000\nsns.distplot(contact_year)","e4035ad4":"label_distplots(contact_year, y, hist=False)","6a9931a9":"train['birth_date'].min(), train['birth_date'].max()","ab53281b":"age_when_contact = (train['contact_date'] - train['birth_date']).dt.days \/ 365\nage_when_contact.name = 'age_when_contact'\nsns.distplot(age_when_contact)","c7a1f908":"label_distplots(age_when_contact, y, hist=False)","b6149196":"cat_features = get_cat_features(train)\nfor col in cat_features:\n    pd.crosstab(train[col], y).plot(kind='bar')\n","ee28fb84":"pd.pivot_table(\n    data=train,\n    index='poutcome',\n    values='y',\n    aggfunc=['mean', 'count'],\n).style.bar(color='#339999', vmin=0)","893d2cbe":"train['campaign'].max()","98d5c8c1":"sns.violinplot(x='y', y='campaign', data=train.query('campaign < 11'))","0700302e":"train['pdays'].value_counts()[:5]","9c06cac4":"sns.violinplot(x='y', y='pdays', data=train)","66f45bc8":"pd.crosstab(train['previous'], y).plot(kind='bar')","151e1765":"marital_job_status = pd.pivot_table(\n    data=train,\n    index='marital',\n    columns='job',\n    values='y',\n    aggfunc='mean',\n    fill_value=0.123,\n)\nmarital_job_status.style.background_gradient(cmap='BuGn', axis=1)","fe6d5c3b":"marital_education_status = pd.pivot_table(\n    data=train,\n    index='marital',\n    columns='education',\n    values='y',\n    aggfunc='mean',\n    fill_value=0.123,\n)\nmarital_education_status.style.background_gradient(cmap='BuGn', axis=1)","624554c7":"job_education_status = pd.pivot_table(\n    data=train,\n    index='job',\n    columns='education',\n    values='y',\n    aggfunc='mean',\n    fill_value=0.123,\n)\njob_education_status.style.background_gradient(cmap='BuGn', axis=1)","bda1257b":"from scipy  import sparse\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold\nfrom sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score, precision_recall_curve\n\n\nfrom sklearn.linear_model import LogisticRegression, ElasticNet\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import GaussianNB, BernoulliNB\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.manifold import TSNE\n\nimport shap\nshap.initjs()","bd81a87b":"def label_encode(\n    X: pd.DataFrame, \n    encoders: Optional[Dict[str, LabelEncoder]] = None,\n) -> Tuple[pd.DataFrame, Dict[str, LabelEncoder]]:\n\n    X = X.copy()\n    encoders = encoders or {}\n    for col in get_cat_features(X):\n        if col not in encoders:\n            encoder = LabelEncoder().fit(X[col])\n            encoders[col] = encoder\n        else:\n            encoder = encoders[col]\n        X[col] = encoder.transform(X[col])\n    return X, encoders\n\n\ndef one_hot_encode(\n    X: pd.DataFrame, \n    encoders: Optional[Dict[str, OneHotEncoder]] = None,\n) -> Tuple[sparse.csr_matrix, Dict[str, OneHotEncoder]]:\n    cat_features = get_cat_features(X)\n    feature_matrices = []\n    encoders = encoders or {}\n    for col in X.columns:\n        if col in cat_features:\n            if col not in encoders:\n                encoder = OneHotEncoder().fit(X[[col]])\n                encoders[col] = encoder\n            else:\n                encoder = encoders[col]\n            feature_matrix = encoder.transform(X[[col]])\n        else:\n            feature_matrix = sparse.csr_matrix((\n                X[col].values, \n                (\n                    np.arange(X.shape[0], dtype=int), \n                    np.zeros(X.shape[0], dtype=int),\n                ),\n            ))\n        feature_matrices.append(feature_matrix)\n    features = sparse.hstack(feature_matrices, format='csr')\n    return features, encoders \n\n\ndef scale(\n    X: sparse.csr_matrix, \n    scaler: Optional[StandardScaler] = None,\n) -> Tuple[np.ndarray, StandardScaler]:\n    scaler = scaler or StandardScaler()\n    X_scaled = scaler.fit_transform(X.toarray())\n    return X_scaled, scaler","fcde9759":"def calc_metrics(\n    y_true: Union[np.ndarray, pd.Series], \n    pred_proba: Union[np.ndarray, pd.Series], \n    threshold: float = 0.5,\n) -> Dict[str, float]:\n    res = {}\n    pred = np.zeros_like(pred_proba)\n    pred[pred_proba > threshold] = 1\n    res['accuracy'] = accuracy_score(y_true, pred)\n    res['auc'] = roc_auc_score(y_true, pred_proba)\n    res['f1'] = f1_score(y_true, pred)\n    res['precision'] = precision_score(y_true, pred)\n    res['recall'] = recall_score(y_true, pred)\n    return res\n\n\ndef get_feature_importances(clf, columns):\n    return pd.DataFrame({\n        'column': columns,\n        'importance': clf.feature_importances_,\n    }).sort_values('importance', ascending=False)\n\n\ndef represent_cv_results(gscv):\n    cv_results = pd.DataFrame(gscv.cv_results_)\n    res = cv_results[['params', 'mean_fit_time', 'mean_train_score', 'mean_test_score']] \\\n        .sort_values('mean_test_score', ascending=False)\n    return res","645ea67c":"def get_zodiac(birth_date: pd.Series) -> pd.Series:\n    zodiacs = pd.read_csv(pjoin(INPUT_PATH, 'zodiac', 'zodiac.csv'), dtype=str)\n    birth_day = birth_date.dt.day\n    birth_month = birth_date.dt.month\n    result = pd.Series(index=birth_date.index)\n    \n    for _, zodiac in zodiacs.iterrows():\n        start_month = int(zodiac['start'][-2:])\n        start_day = int(zodiac['start'][:2])\n        end_month = int(zodiac['end'][-2:])\n        end_day = int(zodiac['end'][:2])\n        \n        is_it = (\n            (birth_month == start_month) & (birth_day >= start_day) |\n            (birth_month == end_month) & (birth_day <= end_day)\n        )\n        result[is_it] = zodiac['name']\n        \n    return result","9c25c5ca":"def extract_features(df: pd.DataFrame):\n    X = df.copy()\n    X.drop(columns=['birth_date', 'contact_date'], inplace=True)\n    \n    X['age_when_contact'] = (df['contact_date'] - df['birth_date']).dt.days \/ 365.25\n    X['zodiac'] = get_zodiac(df['birth_date'])\n    \n    # Maybe some calls were done near birth day and customer was more active\n    days_between_bd_and_cd = (df['contact_date'] - df['birth_date']).dt.days\n    X['days_between_bd_and_cd'] =  np.minimum(\n        days_between_bd_and_cd % 365.25, -days_between_bd_and_cd % 365.25\n    )\n    \n    X['contact_day_of_week'] = df['contact_date'].dt.dayofweek\n    \n    return X","077e8d1e":"X_train = extract_features(train.drop(columns='y'))\nX_train_le, label_encoders = label_encode(X_train)\nX_train_ohe, one_hot_encoders = one_hot_encode(X_train)\nX_train_ohe_scaled, scaler = scale(X_train_ohe)\n\ny_train = train['y']","50c8acb8":"X_test = extract_features(test)\nX_test_le, _ = label_encode(X_test, label_encoders)\nX_test_ohe, _ = one_hot_encode(X_test, one_hot_encoders)\nX_test_ohe_scaled, _ = scale(X_test_ohe, scaler)","68fc839f":"%%time\ntsne = TSNE(random_state=1)\ntsne_representation = tsne.fit_transform(X_train_ohe_scaled)","3cf4df83":"plt.scatter(tsne_representation[:, 0], tsne_representation[:, 1], c=y.map({0: 'blue', 1: 'orange'}), s=20);","39143c0e":"cat_features = get_cat_features(train)\n\nset_figsize(6, len(cat_features) * 5)\nfig, axes = plt.subplots(len(cat_features))\n\nfor ax, feature in zip(axes, cat_features):\n    for val in train[feature].unique():\n        mask = train[feature] == val\n        ax.scatter(tsne_representation[mask, 0], tsne_representation[mask, 1], label=val, s=20)\n    ax.legend()\n    ax.set_title(feature)\n    \nset_figsize(6, 4)","81536899":"housing_unknown_mask = train['housing'] == 'unknown'\nloan_unknown_mask = train['loan'] == 'unknown'\nloan_and_housing_unknown_mask = housing_unknown_mask & loan_unknown_mask\nprint(housing_unknown_mask.sum())\nprint(loan_unknown_mask.sum())\nprint(loan_and_housing_unknown_mask.sum())","08c2d1b6":"lr = LogisticRegression(solver='liblinear', penalty='l2', random_state=1)\ngscv_lr = GridSearchCV(\n    estimator=lr,\n    param_grid={'C': [0.01, 0.03, 0.1, 0.3, 1, 3, 10]},\n    scoring='roc_auc',\n    n_jobs=1,\n    cv=StratifiedKFold(n_splits=5, random_state=1),\n    refit=True,\n    return_train_score=True,\n    verbose=True,\n)\n\ngscv_lr.fit(X_train_ohe, y_train);","2da1570c":"represent_cv_results(gscv_lr)","7f5344d3":"nb = GaussianNB()\ngscv_nb = GridSearchCV(\n    estimator=nb,\n    param_grid={},\n    scoring='roc_auc',\n    n_jobs=1,\n    cv=StratifiedKFold(n_splits=5, random_state=1),\n    refit=True,\n    return_train_score=True,\n    verbose=True,\n)\n\ngscv_nb.fit(X_train_le, y_train);","2fabab73":"represent_cv_results(gscv_nb)","fd7a593d":"nn = MLPClassifier(random_state=1)\ngscv_nn = GridSearchCV(\n    estimator=nn,\n    param_grid={\n        'alpha': [1, 0.1],\n        'hidden_layer_sizes': [(100, 100), (100,)],\n    },\n    scoring='roc_auc',\n    n_jobs=2,\n    cv=StratifiedKFold(n_splits=3, random_state=1),\n    refit=True,\n    return_train_score=True,\n    verbose=True,\n)\n\ngscv_nn.fit(X_train_ohe, y_train);","a80cfb10":"represent_cv_results(gscv_nn)","e0abfd7a":"dt = DecisionTreeClassifier(max_leaf_nodes=100, random_state=1)\ngscv_dt = GridSearchCV(\n    estimator=dt,\n    param_grid={'max_depth': [4, 5, 6], 'min_samples_leaf': [50, 100, 200]},\n    scoring='roc_auc',\n    n_jobs=1,\n    cv=StratifiedKFold(n_splits=5, random_state=1),\n    refit=True,\n    return_train_score=True,\n    verbose=True,\n)\n\ngscv_dt.fit(X_train_le, y_train);","d7f501f1":"represent_cv_results(gscv_dt)","57c61f6a":"rf = RandomForestClassifier(random_state=1)\ngscv_rf = GridSearchCV(\n    estimator=rf,\n    param_grid={'max_depth': [3, 4], 'n_estimators': [50, 100, 200]},\n    scoring='roc_auc',\n    n_jobs=2,\n    cv=StratifiedKFold(n_splits=2, random_state=1),\n    refit=True,\n    return_train_score=True,\n    verbose=True,\n)\n\n\ngscv_rf.fit(X_train_le, y_train);","691e02d7":"represent_cv_results(gscv_rf)","b3565a9c":"rf_clf = gscv_rf.best_estimator_","2d48bce0":"get_feature_importances(rf_clf, X_train_le.columns)","e2a11b72":"rf_explainer = shap.TreeExplainer(rf_clf)\nrf_shap_values = rf_explainer.shap_values(X_train_le)","219b9438":"shap.summary_plot(rf_shap_values, X_train_le, plot_type='bar')","d068094a":"cb = CatBoostClassifier(\n    cat_features=get_cat_features(X_train_le),\n    eval_metric='AUC',\n    random_seed=2,\n    nan_mode='Forbidden',\n    task_type='CPU',\n    verbose=False,\n)\n\n\ngscv_cb = GridSearchCV(\n    estimator=cb,\n    param_grid={\n        'n_estimators': [50, 100], \n        'max_depth': [3, 4],\n        \n    },\n    scoring='roc_auc',\n    n_jobs=1,\n    cv=StratifiedKFold(n_splits=3, random_state=1),\n    refit=True,\n    return_train_score=True,\n    verbose=True,\n\n)\n\ngscv_cb.fit(X_train_le, y_train);","73a24ccf":"represent_cv_results(gscv_cb)","be5cd869":"cb_clf = gscv_cb.best_estimator_\nget_feature_importances(cb_clf, X_train_le.columns)","1d1ba14f":"cb_explainer = shap.TreeExplainer(cb_clf)\ncb_shap_values = cb_explainer.shap_values(X_train_le)","339fac42":"# See at random row in data\n\ni = 123\nshap.force_plot(\n    cb_explainer.expected_value, \n    cb_shap_values[i, :], \n    X_train_le.iloc[i, :],\n)","9ca71799":"# See at all variables at moment\n\nsample = np.random.choice(np.arange(len(X_train_le)), size=100, replace=False)\nshap.force_plot(\n    cb_explainer.expected_value, \n    cb_shap_values[sample, :], \n    X_train_le.iloc[sample, :],\n)","d23d0f9a":"# See feature impacts\n\nshap.summary_plot(cb_shap_values, X_train_le)","eace70bb":"# See mean feature importances\n\nshap.summary_plot(cb_shap_values, X_train_le, plot_type=\"bar\")","c637c7cc":"final_clf = cb_clf","bfc6985b":"pred_test = final_clf.predict_proba(X_test_le)[:, 1]","d81d6114":"res = pd.DataFrame({'y': pred_test, 'id': test.index})\nres.to_csv('res_baseline.csv', index=False)","49d0157a":"#### Get model explanation by shap","868b9ff6":"# Make predictions","ad9249f5":"### Decision tree","4c6a6fa6":"### Data description\n\nThe data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed. \n\n#### Attribute Information:\n\n*Input variables:*\n\n - birth_date (date)\n - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n - default: has credit in default? (categorical: 'no','yes','unknown')\n - housing: has housing loan? (categorical: 'no','yes','unknown')\n - loan: has personal loan? (categorical: 'no','yes','unknown')\n \n - contact: contact communication type (categorical: 'cellular','telephone') \n - contact_date (date)\n \n - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n - previous: number of contacts performed before this campaign and for this client (numeric)\n - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n\n*Output variable (desired target):*\n\n - y - has the client subscribed a term deposit? (binary: 'yes','no')\n\n\nThe full description can be found here: https:\/\/archive.ics.uci.edu\/ml\/datasets\/Bank+Marketing","e523086f":"## Try different models","0a181c2e":"### Categorical features","8f7683d9":"**Note:** Feature importances given by model and *shap* are different","3c376eff":"# Explore data","b942b0c8":"### Some helpful functions","db8cf2e9":"## Explore features distribution","df9f4b16":"### Gradient boosting","006eff3c":"## Try to find some clusters in data","0ae2df0c":"## Extract features","0d2bfeac":"**Note:** *CatBoostClassifier* can work with not encoded features, but we'll use label encoded ones to explain model with *shap* later","f08785c5":"Best result gives *catboost* model ","ed165dca":"### Logistic regression","e5176b54":"### Dates","b6200967":"## Build model","9f03107c":"#### Get brief model explanation by shap","ce7c049b":"### Neural network","38f4fd76":"#### Represent results","13df45d2":"### Random forest","c40aa9fd":"### Naive Bayes","7295ab4f":"### Some helpful functions","edd01d29":"# Get basic data info","af4918c2":"#### Transform data","4ce577ed":"## Explore feature interaction","76968bff":"### Numerical features"}}