{"cell_type":{"5a51af3a":"code","02ec4a30":"code","b07a4804":"code","8b251469":"code","76c090cf":"code","a0871a5a":"code","aad2f134":"code","27e8e500":"code","22999f6f":"code","0659d9b8":"code","8cce1532":"code","2ea7d680":"code","9b722349":"code","0911e0de":"code","2843e502":"code","d4de89c4":"code","4d01e8a1":"code","5d9f2ef1":"code","1c15bed9":"code","3ee4eb1f":"code","e0fe80b6":"code","03c85a67":"code","8f89cad9":"code","e5b16164":"code","80178651":"code","ce0841b1":"code","a43ce587":"code","3a39b762":"code","e0f61904":"code","6b0ef23b":"code","c6fe86d0":"code","ebdaef6a":"code","02727053":"code","d1b5fd73":"code","dc8a561c":"code","44a96c95":"code","06eb47b2":"code","45e5e5d1":"markdown","93ab723b":"markdown","e3ea184c":"markdown","5ffadb7b":"markdown","de396274":"markdown","85b6b1e1":"markdown","662262c8":"markdown","96a0ad8c":"markdown","ad9c953e":"markdown","f5372223":"markdown","f15c6f97":"markdown","d092c981":"markdown"},"source":{"5a51af3a":"import os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport pandas as pd\nimport numpy as np\nfrom tensorflow import keras\nimport cv2\nimport pickle\nfrom tensorflow.keras import backend as K\nfrom PIL import Image\nimport matplotlib.patches as mpatches","02ec4a30":"PATH = '\/kaggle\/input\/bridge-cracks-image\/DeepPCB\/PCBData'","b07a4804":"normal = []\ndefect = []\ndefectlog = []\npath_2 = [os.path.join(PATH,dir) for dir in os.listdir(PATH) if '.' not in dir]\nfor p in tqdm(path_2,total=len(path_2)):\n    path_3 = os.path.join(p,sorted(os.listdir(p))[0])\n    normal +=[os.path.join(path_3,dir)for dir in os.listdir(path_3) if 'temp' in dir]\n    defect +=[os.path.join(path_3,dir)for dir in os.listdir(path_3) if 'test' in dir]\n    path_4 = os.path.join(p,sorted(os.listdir(p))[1])\n    defectlog +=[os.path.join(path_4,dir)for dir in os.listdir(path_4)]\nnormal.sort()\ndefect.sort()\ndefectlog.sort()","8b251469":"img0 = []\nimg1 = []\nfor img_path in tqdm(normal,total=len(normal)):\n    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    img = cv2.resize(img,(128,128))\n    img0.append(img)\nfor img_path in tqdm(defect,total=len(defect)):\n    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    img = cv2.resize(img,(128,128))\n    img1.append(img)\nimg0 = np.array(img0)\nimg1 = np.array(img1)\n# with open(path+'img0.pkl', 'wb') as f:\n#     pickle.dump(img0, f, pickle.HIGHEST_PROTOCOL)\n# with open(path+'img1.pkl', 'wb') as f:\n#     pickle.dump(img1, f, pickle.HIGHEST_PROTOCOL)","76c090cf":"# with open(path+'img0.pkl', 'rb') as f:\n#     img0 = pickle.load(f)\n# with open(path+'img1.pkl', 'rb') as f:\n#     img1 = pickle.load(f)","a0871a5a":"box = []\ni=0\nfor log in tqdm(defectlog,total=len(defectlog)):\n    temp = pd.read_csv(log,sep=' ' ,names=['x1', 'y1', 'x2', 'y2', 'defect'], header=None).values.tolist()\n    box.append(temp)\n    i+=1\nboxarr = []\nfor i in tqdm(range(len(box))):\n    narr = np.zeros((640,640,1))\n    for j in range(len(box[i])):\n        x1,y1,x2,y2,d = box[i][j]\n        narr = cv2.rectangle(narr,(x1,y1),(x2,y2),d,-1)\n    narr = cv2.resize(narr,(88,88))\n    boxarr.append(narr)\nboxarr = np.array(boxarr)\n# with open(path+'boxarr.pkl', 'wb') as f:\n#     pickle.dump(boxarr, f, pickle.HIGHEST_PROTOCOL)","aad2f134":"# with open(path+'boxarr.pkl', 'rb') as f:\n#     boxarr = pickle.load(f)","27e8e500":"plt.imshow(np.reshape(boxarr[0],(88,88)),cmap='gnuplot')\nplt.show()","22999f6f":"plt.imshow(np.reshape(img1[0],(128,128)),cmap='gnuplot')\nplt.show()","0659d9b8":"dataset = tf.data.Dataset.from_tensor_slices((img1,boxarr))","8cce1532":"n=1500\ndataset = dataset.shuffle(n)\ntrain_dataset = dataset.take(int(n*0.8)).batch(100)\ntest_dataset = dataset.skip(int(n*0.8)).batch(100)","2ea7d680":"## layer5 cnn bn he flip\ninputs = keras.layers.Input((128,128,1))\n# x = keras.layers.experimental.preprocessing.Resizing(128,128)(inputs)\nx = keras.layers.experimental.preprocessing.Rescaling(1.\/255)(inputs)\nx = keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal_and_vertical')(x)\n\nx = keras.layers.Conv2D(filters=64,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #126 126 64\nx = keras.layers.Activation('relu')(x)\nx = keras.layers.Conv2D(filters=64,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #124 124 64\nx = keras.layers.Activation('relu')(x)\nx1 = tf.identity(x)\nx1 = keras.layers.experimental.preprocessing.CenterCrop(92,92)(x1)\n\nx = keras.layers.MaxPooling2D((2, 2), strides=2)(x) #62 62,64\n\nx = keras.layers.Conv2D(filters=128,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #60 60 128\nx = keras.layers.Activation('relu')(x)\nx = keras.layers.Conv2D(filters=128,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #58 58 128\nx = keras.layers.Activation('relu')(x)\nx2 = tf.identity(x)\nx2 = keras.layers.experimental.preprocessing.CenterCrop(50,50)(x2)\n\nx = keras.layers.MaxPooling2D((2, 2), strides=2)(x) #29 29 128\n\nx = keras.layers.Conv2D(filters=256,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #27 27 256\nx = keras.layers.Activation('relu')(x)\nx = keras.layers.Conv2D(filters=256,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #25 25 256\nx = keras.layers.Activation('relu')(x)\n\nx = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=2, strides=(2, 2),kernel_initializer=tf.keras.initializers.HeNormal())(x) # 50 50 128\n\nx = keras.layers.Concatenate()([x,x2]) #50 50 256\nx = keras.layers.Conv2D(filters=128,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #48 48 128\nx = keras.layers.Activation('relu')(x)\nx = keras.layers.Conv2D(filters=128,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #46 46 128\nx = keras.layers.Activation('relu')(x)\n\nx = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=2, strides=(2, 2),kernel_initializer=tf.keras.initializers.HeNormal())(x) # 92 92 64\n\nx = keras.layers.Concatenate()([x,x1]) #92,92 128\nx = keras.layers.Conv2D(filters=64,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #90 90 64\nx = keras.layers.Activation('relu')(x)\nx = keras.layers.Conv2D(filters=64,kernel_size=3,kernel_initializer=tf.keras.initializers.HeNormal())(x) #88 88 64\nx = keras.layers.Activation('relu')(x)\n\noutputs = keras.layers.Conv2D(filters=7,kernel_size=1,kernel_initializer=tf.keras.initializers.HeNormal())(x) #88 88 7","9b722349":"model = keras.Model(inputs, outputs)\nmodel.summary()","0911e0de":"model.compile(\n    optimizer='adam',\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n)","2843e502":"# callback = tf.keras.callbacks.ModelCheckpoint(PATH+'model.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='loss', save_freq='epoch',)\n# history = model.fit(train_dataset,epochs=1000,validation_data=test_dataset,callbacks=[callback])\nhistory = model.fit(train_dataset,epochs=500,validation_data=test_dataset,verbose=0)","d4de89c4":"plt.plot(history.history['val_loss'])\nplt.show()","4d01e8a1":"out = model.predict(tf.reshape(img1[0],(-1,128,128,1)))\nout2 = np.argmax(out,axis=3)\nplt.imshow(out2[0],cmap='gnuplot')","5d9f2ef1":"img_arr_resized = cv2.resize(img1[0],(88,88))\nimg_arr_resized = cv2.cvtColor(img_arr_resized,cv2.COLOR_GRAY2RGB)","1c15bed9":"plt.imshow(img_arr_resized)","3ee4eb1f":"pred = model.predict(tf.reshape(img1[0],(-1,128,128,1)))\npred = np.argmax(pred,axis=3)[0]","e0fe80b6":"new_pred = np.zeros((88,88,3),dtype=np.uint8)","03c85a67":"new_pred[pred==0] = img_arr_resized[pred==0]\nnew_pred[pred==1] = [255,228,0] #open\nnew_pred[pred==2] = [1,0,255] #short\nnew_pred[pred==3] = [29,219,22] #mousebite\nnew_pred[pred==4] = [255,0,0] #spur\nnew_pred[pred==5] = [103,0,0] #copper\nnew_pred[pred==6] = [255,0,127] #pin-hole","8f89cad9":"blend_img1=Image.fromarray(img_arr_resized)\nblend_img2=Image.fromarray(new_pred)\nblend_img=Image.blend(blend_img1,blend_img2,0.5)","e5b16164":"legend1 = mpatches.Patch(color='#FFE400', label='open')\nlegend2 = mpatches.Patch(color='#0100FF', label='short')\nlegend3 = mpatches.Patch(color='#1DDB16', label='mousebite')\nlegend4 = mpatches.Patch(color='#FF0000', label='spur')\nlegend5 = mpatches.Patch(color='#670000', label='copper')\nlegend6 = mpatches.Patch(color='#FF007F', label='pinhole')\nplt.legend(loc='lower left', handles=[legend1,legend2,legend3,legend4,legend5,legend6],mode = \"expand\", ncol = 3,fontsize=10)\nplt.xticks([])\nplt.yticks([])\nplt.imshow(np.array(blend_img))\nplt.show()","80178651":"log_df = pd.DataFrame(columns=['0','1','2','3','4','5','6'])\ni=0\nfor log in tqdm(defectlog,total=len(defectlog)):\n    temp_df = pd.read_csv(log,sep=' ' ,names=['x1', 'y1', 'x2', 'y2', 'defect'], header=None)\n    temp = np.zeros(7,dtype=int)\n    for t in temp_df['defect']:\n        temp[t]+=1\n    log_df.loc[i,:] = temp\n    i+=1","ce0841b1":"dataset2 = tf.data.Dataset.from_tensor_slices((img1,log_df.values.astype(np.int)))","a43ce587":"n=1500\ndataset2 = dataset2.shuffle(n)\ntrain_dataset2 = dataset2.take(int(n*0.8)).batch(100)\ntest_dataset2 = dataset2.skip(int(n*0.8)).batch(100)","3a39b762":"load_model = tf.keras.models.Model(\n    [model.inputs],\n    [model.layers[16].output]\n)","e0f61904":"for layer in load_model.layers:\n    layer.trainable=False","6b0ef23b":"x = load_model.output #25 25 256\nx = keras.layers.MaxPooling2D((3, 3), strides=2)(x) #12 12 256\nx_l = keras.layers.BatchNormalization()(x)\nx_l = keras.layers.Activation('relu')(x_l)\nx_l = keras.layers.Conv2D(filters=256,kernel_size=1,padding='same',kernel_initializer=tf.keras.initializers.HeNormal())(x_l)\nx_l = keras.layers.BatchNormalization()(x_l)\nx_l = keras.layers.Activation('relu')(x_l)\nx_l = keras.layers.Conv2D(filters=64,kernel_size=3,padding='same',kernel_initializer=tf.keras.initializers.HeNormal())(x_l)\nx = keras.layers.Concatenate()([x, x_l]) #12 12 320\n\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.Activation('relu')(x)\nx = keras.layers.Conv2D(filters=160,kernel_size=1,padding='same',kernel_initializer=tf.keras.initializers.HeNormal())(x)\nx = keras.layers.MaxPooling2D((2, 2), strides=2)(x) #6 6 160\n\nx_l = keras.layers.BatchNormalization()(x)\nx_l = keras.layers.Activation('relu')(x_l)\nx_l = keras.layers.Conv2D(filters=160,kernel_size=1,padding='same',kernel_initializer=tf.keras.initializers.HeNormal())(x_l)\nx_l = keras.layers.BatchNormalization()(x_l)\nx_l = keras.layers.Activation('relu')(x_l)\nx_l = keras.layers.Conv2D(filters=40,kernel_size=3,padding='same',kernel_initializer=tf.keras.initializers.HeNormal())(x_l)\nx = keras.layers.Concatenate()([x, x_l]) #6 6 200\n\nx = keras.layers.GlobalAveragePooling2D()(x) #1*1*200\noutputs = keras.layers.Dense(7,activation='linear')(x)","c6fe86d0":"model2 = keras.Model(load_model.inputs, outputs)\nmodel2.summary()","ebdaef6a":"model2.compile(\n    optimizer='adam',\n    loss='mse'\n)","02727053":"# callback2 = tf.keras.callbacks.ModelCheckpoint(path+'model2.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='loss', save_freq='epoch',)\n# history2 = model2.fit(train_dataset2,epochs=1000,validation_data=test_dataset2,callbacks=[callback2])\nhistory2 = model2.fit(train_dataset2,epochs=500,validation_data=test_dataset2,verbose=0)","d1b5fd73":"plt.plot(history2.history['val_loss'])\nplt.show()","dc8a561c":"model2_pred = model2.predict(tf.reshape(img1[-1],(-1,128,128,1)))\nmodel2_pred","44a96c95":"np.round(model2_pred).astype(np.int)","06eb47b2":"log_df.values[-1]","45e5e5d1":"Add Classification Model to Unet Contracting Path","93ab723b":"# Plot Predict","e3ea184c":"We only use abnormal images for smooth segmentation.","5ffadb7b":"# Result Visualization","de396274":"# Make Dataset & UNet Model","85b6b1e1":"# Transfer Learning : Find the exact number of errors for each type","662262c8":"Make DataSet and Preprocessing","96a0ad8c":"Use pretrained Unet Contracting Path","ad9c953e":"# Load & Preprocessing","f5372223":"Originally, mirror padding was supposed to be used in Expanding Path, we simply use CenterCrop in Contracting Path","f15c6f97":"if you saved best model by using callback and use that, the result will be more accurate.","d092c981":"model got the right answer."}}