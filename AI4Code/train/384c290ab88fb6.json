{"cell_type":{"cbeeef24":"code","865c759b":"code","09310f6f":"code","fa32f4b7":"code","4c61eff5":"code","71f9d7fa":"code","9b612147":"code","665ec4d8":"code","11f7b1ad":"code","85a98109":"code","02ee397f":"code","3340fce8":"markdown"},"source":{"cbeeef24":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport sys\nimport os\nimport time\nfrom tqdm import tqdm\nfrom tqdm.keras import TqdmCallback\nfrom datetime import timedelta\nfrom copy import deepcopy\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n# import keras\n# import keras.backend as K\n# from keras.models import Sequential\n# from keras.layers import Input, LSTM, Dense, Activation, Dropout\n# from keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, LSTM, Dense, Activation, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n# from tensorflow.compat.v1.keras.layers import CuDNNLSTM","865c759b":"train_path = '..\/input\/covid19-global-forecasting-week-4\/train.csv'\ntest_path = '..\/input\/covid19-global-forecasting-week-4\/test.csv'\nsub_path = '..\/input\/covid19-global-forecasting-week-4\/submission.csv'","09310f6f":"df = pd.read_csv('..\/input\/covid19-global-forecasting-week-4\/train.csv')\ndf.tail()","fa32f4b7":"def load_csv(path):\n    df = pd.read_csv(path)\n    df.fillna('None', inplace=True)\n    return df","4c61eff5":"# metrics\n\ndef root_mean_squared_log_error(y_true, y_pred, smooth=1):\n    '''\n\n    :param y_true: (-1,) (np ndarray) actual values\n    :param y_pred: (-1,) (np ndarray) predicted values\n    :return: (float) root mean squared log error, value range[0, inf)\n    '''\n    return np.sqrt((1 \/ len(y_true)) * np.sum((np.log(y_true + smooth) - np.log(y_pred + smooth)) ** 2))\n\ndef r2_score(y_true, y_pred):\n    '''\n\n    :param y_true: (-1,) (np ndarray) actual values\n    :param y_pred: (-1,) (np ndarray) predicted values\n    :return: (float) r2 score, value range(-inf, 1]\n    '''\n    sse = np.sum((y_true - y_pred) ** 2)\n    var = np.sum((y_true - np.mean(y_true)) ** 2)\n    if var == 0:\n        r2 = 0\n    else:\n        r2 = 1 - sse \/ var\n    return r2","71f9d7fa":"# build LSTM model\n\ndef timesteps(data, steps):\n    results = []\n    for i in range(len(data) - steps):\n      results.append(data[i:i+steps+1].values.tolist())\n    return np.array(results)\n\ndef input_reshape(data, shape):\n    return data.reshape(shape)\n\ndef slide1_window(data, value):\n    data = data.reshape(-1, 2).tolist()\n    new_data = data[1:]\n    new_data.append(value)\n    return np.array(new_data)\n\n# def check_data(*datas):\n#     results = []\n#     for data in datas:\n#         if isinstance(data, np.ndarray):\n#           data = data.reshape(-1,)\n#         elif isinstance(data, pd.core.series.Series):\n#           data = data.values.reshape(-1,)\n#         else:\n#             data = np.array(data).reshape(-1,)\n#         results.append(data.astype(np.float64))\n#     return tuple(results)\n\ndef fit_lstm(train, vali, lstm_input_shape=None, batch_size=1, epochs=1, verbose=1):\n    X_train, y_train = train[:, :-1], train[:, -1]\n    X_train = input_reshape(X_train, lstm_input_shape)\n\n    vali_data = (input_reshape(vali[:, :-1], lstm_input_shape), vali[:, -1])\n\n    model = Sequential()\n    model.add(LSTM(128, input_shape=(lstm_input_shape[1:])))\n    model.add(Dropout(0.2))\n    model.add(Dense(lstm_input_shape[-1]))\n    \n    early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=4, verbose=0, factor=0.5)\n    callbacks = [early_stopping, reduce_lr]\n    if verbose != -1:\n        callbacks.append(TqdmCallback(verbose=verbose))\n\n    model.compile(optimizer='adam', loss='mse')\n\n    model.fit(\n      X_train,\n      y_train,\n      batch_size=batch_size,\n      epochs=epochs,\n      verbose=0,\n      validation_data=vali_data,\n      callbacks=callbacks\n      )\n    # for i in range(epochs):\n    #   model.fit(X_train, y_train, batch_size=batch_size, epochs=1, verbose=verbose)\n    #   model.reset_states()\n    return model","9b612147":"# help functions for forecast\n\ndef load_cases(df, feat):\n    cases = pd.DataFrame(df[feat].values, index=df['Date'])\n    return cases\n\n# scale train data to [0, 1] \ndef scale_fit(data):\n    scaler = MinMaxScaler()\n    scaler.fit(scale_reshape(data))\n    return scaler\n\ndef scale_transform(scaler, data):\n    return scaler.transform(scale_reshape(data)).reshape(data.shape)\n\ndef scale_reshape(data):\n    results = np.array(data).reshape(-1, 2)\n    return results\n\n# apply difference to the data \nclass diff_node:\n    def __init__(self, first=None, v=None, level=0):\n        self.first = first\n        self.v = v\n        self.level = level\n        self.prev = None\n        self.next = None\n\ndef difference(X, degree):\n\n    diff = X\n    if degree == 0:\n        root = diff_node(v=diff)\n    else:\n        root = diff_node(first=diff.iloc[0].values.reshape(-1,2))\n        for i in range(degree):\n            diff = diff.diff()[1:].reset_index(drop=True)\n            if i + 1 >= degree:\n                root.next = diff_node(v=diff, level=i+1)\n            else:\n                root.next = diff_node(first=diff.iloc[0].values.reshape(-1,2), level=i+1)\n            root.next.prev = root\n            root = root.next\n    return root\n\ndef inverse_difference(node):\n    results = node.v\n    if node.level <= 1:\n        results = np.where(results >= 0.0, results, 0.0) \n    while node.prev is not None:\n        prev = node.prev\n        first = prev.first\n        tmp = np.cumsum(results, axis=0) + first\n        results = np.concatenate((first, tmp), axis=0)\n        if prev.level <= 1:\n            results = np.where(results >= 0.0, results, 0.0)\n        node = prev\n    return np.array(results)","665ec4d8":"# construct a class for easily debug\n\nclass covid19_forecaster:\n    def __init__(self, feat, Country, Province, random_state=0):\n        self.scalar = None\n        self.model = None\n        self.model_input_shape = None\n        self.history = None\n        self.last_timestep = None\n        self.train_date = None\n        self.difference_node = None\n        self.feat = feat\n        self.Country = Country\n        self.Province = Province\n        self.random_state = random_state\n\n\n    def fit(self, df, time_steps=10, diff_degrees=0, vali_size=0.2, batch_size=1, epochs=1, verbose=1\n            #, fit_evaluation=False, if_plot=False\n           ):\n        # print('running on fit method')\n        train_stepped = self._prepare_data(df, time_steps, diff_degrees)\n\n        train_stepped_scaled = scale_transform(self.scalar, train_stepped)\n\n        train, vali = train_test_split(train_stepped_scaled, test_size=vali_size, random_state=self.random_state)\n        self.model_input_shape = -1, time_steps, len(self.feat)\n\n        # print('starting fitting')\n        #print('  Feature: %s'%(self.feat))\n        # print('  Country_Region: %s, Province_State: %s'%(self.Country, self.Province))\n        self.model = fit_lstm(train, vali,self.model_input_shape, batch_size, epochs, verbose)\n        # print('fitting completed\\n')\n        self.last_timestep = train_stepped_scaled[-1, :]\n\n#         if fit_evaluation:\n#             y_true = pd.Series(self.history[time_steps:], index=self.train_date)\n#             y_pred = pd.Series(\n#                 self._prediction_postprocess(\n#                     self.scalar,\n#                     self.model.predict(input_reshape(train_stepped_scaled[:, :-1], self.model_input_shape)),\n#                     self.difference_node,\n#                     append=False\n#                 ).reshape(-1, ),\n#                 index=self.train_date\n#             )\n#             self.evaluation(y_true, y_pred, if_plot)\n\n\n    def forecast(self, forecast_steps):\n        predictions_scaled = []\n        X_test, y_test = self.last_timestep[:-1], self.last_timestep[-1]\n        for i in range(forecast_steps):\n            X_test = slide1_window(X_test, y_test)\n            y_test = self.model.predict(X_test.reshape(self.model_input_shape))[0, :] * 1.03 # multiply a compensation\n            predictions_scaled.append(y_test)\n        predictions_scaled = np.array(predictions_scaled)\n        # predictions = prediction_inverse_transform(self.scalar, predictions_scaled)\n        predictions = self._prediction_postprocess(self.scalar, predictions_scaled, self.difference_node)\n\n        start_date = pd.to_datetime(self.train_date[-1], format='%Y-%m-%d')\n        pred_dates = self._generate_dates(start_date, forecast_steps)\n        return pd.DataFrame(predictions, index=pred_dates, columns=self.feat)\n\n#     def evaluation(self, y_true, y_pred, if_plot=False):\n#         self._evaluation(y_true, y_pred, if_plot)\n\n    def _prepare_data(self, df, time_steps, diff_degrees):\n        cases = load_cases(df, self.feat)\n        self.history = cases\n\n        self.difference_node = difference(cases, diff_degrees)\n        difference_value = self.difference_node.v\n\n        self.scalar = scale_fit(difference_value)\n        train_stepped = timesteps(difference_value, time_steps)\n        self.train_date = cases.index[time_steps:]\n        return train_stepped\n\n    def _prediction_postprocess(self, scaler, predictions, node, append=True):\n        preds = scaler.inverse_transform(predictions.reshape(-1, len(self.feat)))\n        preds = preds.reshape(-1, len(self.feat))\n\n        tmp_node = deepcopy(node)\n        if append:\n            tmp_node.v = tmp_node.v.append(pd.DataFrame(preds), ignore_index=True)\n            preds = inverse_difference(tmp_node)[-len(predictions):]\n        else:\n            tmp_node.v = preds\n            preds = inverse_difference(tmp_node)\n        return np.array(preds)\n\n#     def _plot(self, y, h, fig_size=(6.4, 4.8), metrics=None):\n#         plt.figure(figsize=fig_size)\n#         y, h = self._indextodatetime(y, h)\n#         y.plot(color='blue', label='actual')\n#         h.plot(color='red', label='predicted')\n#         plt.xlabel('Date')\n#         plt.ylabel(self.feat)\n#         i = 0\n#         if metrics:\n#             for name, metric in metrics.items():\n#                 plt.text(0.25, 0.8 - i \/ 25, '%s: %.8f' % (name, metric), transform=plt.gca().transAxes)\n#                 i += 1\n\n#         plt.title('Country_Region: %s\\nProvince_State: %s'%(self.Country, self.Province))\n#         plt.legend(loc='best')\n#         plt.show()\n\n#     def _evaluation(self, y_true, y_pred, if_plot=False, plot_size=(6.4, 4.8)):\n#         y, h = check_data(y_true, y_pred)\n#         metrics = {}\n#         metrics['r2_score'] = r2_score(y, h)\n#         metrics['rmsle'] = root_mean_squared_log_error(y, h)\n#         if if_plot:\n#             self._plot(y_true, y_pred, plot_size, metrics)\n#         else:\n#             for key, value in metrics.items():\n#                 print('%s: %.8f' % (key, value))\n\n    def _generate_dates(self, start_date, length):\n        dates = []\n        for i in range(length):\n            new_date = start_date + timedelta(days=int(i + 1))\n            dates.append(new_date.strftime('%Y-%m-%d'))\n        return dates\n\n    def _indextodatetime(self, *datas):\n        results = []\n        for data in datas:\n            dates = data.index.to_series().apply(lambda x: pd.to_datetime(x, format='%Y-%m-%d')).values\n            values = data.values\n            new_data = pd.Series(values, index=dates)\n            results.append(new_data)\n        return tuple(results)","11f7b1ad":"# the main function for forecasting\n\ndef forecast(train_path, test_path):\n    df_train = load_csv(train_path)\n    df_test = load_csv(test_path)\n    cp = []\n    for i, row in df_test.iterrows():\n        v = row['Country_Region'], row['Province_State']\n        if v not in cp:\n            cp.append(v)\n\n    feats = ['ConfirmedCases', 'Fatalities']\n    train_start = 40 \n    train_end = 84 \n    time_steps = 10\n    diff_degrees = 1\n    vali_size = 0.15\n    batch_size = 8\n    epochs = 200\n    verbose = -1\n    forecast_steps = 30 # predictions from 2020-04-15 to 2020-05-14\n    predictions = []# {feats[0]:[], feats[1]:[]}\n    for Country, Province in tqdm(cp):\n        df = df_train[(df_train['Country_Region']==Country)&(df_train['Province_State']==Province)]\n        train = df[train_start:train_end]\n        random_state = np.random.randint(0, 20, 1)[0]\n        \n        forecaster = covid19_forecaster(feats, Country, Province, random_state=random_state)\n        forecaster.fit(train, time_steps=time_steps, diff_degrees=diff_degrees, vali_size=vali_size,\n                       batch_size=batch_size, epochs=epochs, verbose=verbose)\n        preds = forecaster.forecast(forecast_steps)\n        preds = preds.values.tolist()\n\n        # add data (from 04-02 to 04-14) to predictions; works for public leaderboard\n        for v in train[-13:][feats].values.tolist():\n            predictions.append(v)\n        # add predictions (from 04-15 to 05-14); works for private leaderboard\n        for p in preds:\n            predictions.append(p)\n    return predictions","85a98109":"predictions = forecast(train_path, test_path)","02ee397f":"# generate submission file\ndf_sub = pd.read_csv(sub_path)\nfeats = ['ConfirmedCases', 'Fatalities']\ndf_sub[feats] = predictions\ndf_sub.to_csv('submission.csv', index=False)","3340fce8":"This code is designed for training every LSTM model for every ('Country_Region', 'Province_State') group using only original data.\n\nExplore how well the time series model perform in this forecasting task.\n\nThis is late submission code that you will not see in the LB but I follow the competition rule.\n\ntrain period: 2020-03-02 to 2020-04-14 (44 days)\n\nforecast period: 2020-04-15 to 2020-05-14 (30 days)\n\n*04-22 fixed the submission bug, now the score is correct\n\n*I will put some annotation in the next days"}}