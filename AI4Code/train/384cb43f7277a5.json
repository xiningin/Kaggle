{"cell_type":{"ceca5f5f":"code","a611659c":"code","f2466d36":"code","b08a16e9":"code","0baca2a8":"code","0098ddca":"code","12a88cfd":"code","b65edc41":"code","01e29231":"code","cebe141d":"code","91320ea6":"code","f7f0c897":"code","bf4d9347":"code","b3b21457":"code","b69ad23d":"code","c0cf384f":"code","1e506215":"code","dcfcc7e3":"code","88952760":"code","e55f593e":"code","1b2d2001":"code","3b2a1391":"code","003afb0d":"code","fe35aa0f":"code","1694b839":"code","bad0ce19":"code","f94fc36f":"code","a59caab5":"code","8faee21d":"markdown","e8bd01c4":"markdown","64c5a3fe":"markdown","527ca382":"markdown"},"source":{"ceca5f5f":"# Required packages\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier","a611659c":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","f2466d36":"train.head()","b08a16e9":"# Getting to know data\nprint(train.shape)\nprint(test.shape)","0baca2a8":"# summary of numerical variable\ntrain.describe()","0098ddca":"train.describe()","12a88cfd":"# summary of categorial variable\ntrain.info()","b65edc41":"test.info()","01e29231":"# checking null values\nprint(\"training data\\n\",train.isnull().sum())\nprint(\"\\ntesting data\\n\",test.isnull().sum())","cebe141d":"# let's clean visualizations :)\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n","91320ea6":"# Visualization\ncount_plt = sns.countplot(train[\"Survived\"])\nplt.show(count_plt)\n\nSex_plt = sns.countplot(x= \"Survived\",data=train, hue=\"Sex\")\nplt.show(Sex_plt)\n\nEmbarked_plt = sns.countplot(x=\"Survived\", data=train, hue=\"Embarked\")\nplt.show(Embarked_plt)\n\nPclass_plt = sns.countplot(x=\"Survived\", data=train, hue=\"Pclass\")\nplt.show(Pclass_plt)\n\nSibSp_plt = sns.boxplot(x=\"SibSp\", y= \"Survived\", data=train)\nplt.show(SibSp_plt)\n\nParch_plt = sns.boxplot(x=\"Parch\", y= \"Survived\", data=train)\nplt.show(Parch_plt)\n\nAge_plt = sns.distplot(train[\"Age\"])\nplt.show(Age_plt)","f7f0c897":"# Correlation heatmap\nf, ax = plt.subplots(figsize=(10, 8))\ncorr = train.corr()\nsns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool_),linewidths=0.1,annot=True, cmap=sns.diverging_palette(150, 10, as_cmap=True),\n            square=True, ax=ax)","bf4d9347":"# age mean, fair mean\ntrain['Age'].fillna(train['Age'].mean(), inplace = True)\ntest['Age'].fillna(train['Age'].mean(), inplace = True)\ntest['Fare'].fillna(train['Fare'].mean(), inplace = True)\ntrain['Embarked'].fillna('S', inplace = True)","b3b21457":"train.isnull().sum()","b69ad23d":"test.isnull().sum()","c0cf384f":"# dropping cabin column\ntrain.drop(columns=[\"Cabin\", \"Name\", \"Ticket\"], axis=1, inplace=True)\ntest.drop(columns=[\"Cabin\", \"Name\", \"Ticket\"], axis=1, inplace=True)\n\n# dropping passengerid\ntrain = train.drop(['PassengerId'],axis=1)","1e506215":"# changing gender to numeric\ntrain.loc[train.Sex=='female','Sex']=1\ntrain.loc[train.Sex=='male','Sex']=0\ntrain[\"Sex\"] = train[\"Sex\"].astype(str).astype(float)\n\n# changing strings to numeric\ntrain.loc[train.Embarked =='S','Embarked']= 3\ntrain.loc[train.Embarked =='C','Embarked']=2\ntrain.loc[train.Embarked =='Q','Embarked']=1\ntrain[\"Embarked\"] = train[\"Embarked\"].astype(str).astype(float)","dcfcc7e3":"# Same for test data\ntest['Age'] = test['Age'].fillna(test['Age'].mean())\ntest['Fare'] = test['Fare'].fillna(test['Fare'].mean())\ntest.loc[test.Sex=='female','Sex']=1\ntest.loc[test.Sex=='male','Sex']=0\ntest[\"Sex\"] = test[\"Sex\"].astype(str).astype(float)\ntest.loc[test.Embarked =='S','Embarked']= 3\ntest.loc[test.Embarked =='C','Embarked']=2\ntest.loc[test.Embarked =='Q','Embarked']=1\ntest[\"Embarked\"] = test[\"Embarked\"].astype(str).astype(float)\ntest.isnull().sum()","88952760":"# checking data\nprint(train.head())\nprint(test.head())\nprint(train.corr())","e55f593e":"train.info()","1b2d2001":"test.info()","3b2a1391":"# Classification Methods\n\n# Logistic Regression\ntrain_x= train.drop(columns=[\"Survived\"], axis=1)\ntrain_y= train[\"Survived\"]\n\ntest_x= test.drop(\"PassengerId\",axis=1)\n\nlogistic = LogisticRegression(solver='liblinear')\nlogistic.fit(train_x, train_y)\n\npredictions_LR= logistic.predict(test_x)\n\nprint(logistic.score(train_x, train_y))","003afb0d":"# Sorting k nearest neighbours classifier\n\nKNN_classifier = KNeighborsClassifier(n_neighbors=3)\nKNN_classifier.fit(train_x, train_y)\npredictions_KNN = KNN_classifier.predict(test_x)\n\nprint(KNN_classifier.score(train_x, train_y))","fe35aa0f":"# Random forest\n\nmodel_RF = RandomForestClassifier(n_estimators=100, max_depth=4, min_samples_split=2, min_samples_leaf=2, random_state=2)\nmodel_RF.fit(train_x, train_y)\npredictions_RF = model_RF.predict(test_x)\n\nprint(model_RF.score(train_x, train_y))","1694b839":"# Gradient Boosting\n\nmodel_GB = GradientBoostingClassifier(min_samples_leaf=5,max_leaf_nodes=5)\nmodel_GB.fit(train_x, train_y)\npredictions_GB = model_GB.predict(test_x)\n\nprint(model_GB.score(train_x, train_y))","bad0ce19":"# XGBoost \n\nmodel_XGB = XGBClassifier(learning_rate=0.005, use_label_encoder=False, n_estimators=1000, max_depth=4,\n                       min_child_weight=0,\n                       gamma=0.6,\n                       subsample=0.7,\n                       colsample_bytree=0.7,\n                       objective='reg:squarederror',\n                       nthread=-1,\n                       seed=27,\n                       reg_alpha=0.00006,\n                       random_state=30)\n\nmodel_XGB.fit(train_x, train_y)\npredictions_XGB = model_XGB.predict(test_x)\n\nprint(model_XGB.score(train_x, train_y))","f94fc36f":"# Final Predictions\n\npredictions = [round((prediction_GB + prediction_XGB) \/ 2) for prediction_GB, prediction_XGB in zip(predictions_GB, predictions_XGB)]\nmodel_XGB.fit(test_x,predictions)\npredictions = model_XGB.predict(test_x)\npredictions = [round((prediction_GB + prediction_XGB) \/ 2) for prediction_GB, prediction_XGB in zip(predictions_GB, predictions)]","a59caab5":"# Submission\noutput= pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": predictions})\noutput.to_csv(\"Submission.csv\", index=False)\nprint(\"Done\")","8faee21d":"#  **Exploratory Data Analysis**","e8bd01c4":"# **Pre-Processing**","64c5a3fe":"# **Training and Predicting**","527ca382":"<h2 style=\"font-weight: bold\">Titanic Competition<\/h2>\n\n<h4>This is my first published notebook ever, So yeah it can't be about something other than the Titanic Competition \ud83d\ude04<br><br>I will be doing a simple then advanced EDA, Data Visualization and Pre-Processing. I also will test different models and techniques to improve my score.<br><\/h4>\n\n* <h5 style=\"font-weight: 700\">Your feedback is very welcome<\/h5>\n* <h5 style=\"font-weight: 700\">If you find this notebook useful, please don't forget to upvote it!<\/h5>\n"}}