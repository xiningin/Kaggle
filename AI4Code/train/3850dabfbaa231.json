{"cell_type":{"3fc90e37":"code","566727d1":"code","05af3e02":"code","2a1d8fb3":"code","67d724ee":"code","ae4a63b6":"code","442f16cd":"code","e3f553b6":"code","8c617274":"code","fb78e733":"code","d149dfca":"code","03a4f1c2":"code","df7e3129":"code","81fd2801":"code","9dda872c":"code","cf97a426":"code","607232ac":"code","d032460a":"code","fa80f999":"code","e9c5d68e":"code","59e1268a":"code","f762b391":"code","e082409c":"code","90eb5425":"code","e121ce7f":"code","1dc6cbcd":"code","d41b0c28":"code","dc37918a":"markdown","e5423560":"markdown","036abbc9":"markdown","afed10d7":"markdown","4ba4c690":"markdown","8eaa92ad":"markdown","3b779a7a":"markdown","533a6672":"markdown","9dea8b31":"markdown","938a6db8":"markdown","5fd1695f":"markdown","267f6515":"markdown","60940e3c":"markdown","d5c3a1fc":"markdown","549a8d17":"markdown","345be1ab":"markdown","115763e2":"markdown","720b70a6":"markdown","3a211f93":"markdown","1dc9d302":"markdown","c322c2ac":"markdown","3ee4022c":"markdown","16c56fb1":"markdown","d09ee7fa":"markdown","9bd1660d":"markdown","e852110c":"markdown","27724980":"markdown","e23e0a58":"markdown","da3cef2d":"markdown","d150409c":"markdown","eb20076e":"markdown","b8b8de33":"markdown"},"source":{"3fc90e37":"import pandas as pd\nimport numpy as np\nimport pickle\n\nimport tensorflow as tf\n\nimport keras\nimport keras.backend as K\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization\n\nfrom sklearn.model_selection import train_test_split\nimport sklearn.preprocessing\nfrom sklearn.metrics import roc_curve, auc, accuracy_score\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\nimport joblib\n\nimport matplotlib.pyplot as plt\n\n# from imblearn.over_sampling import SMOTE\n\nnp.random.seed(123)","566727d1":"def preprocessing(X, scaler_filename='scaler.save', columns_to_use_filename='columns_to_use'):\n    \n    scaler = joblib.load(scaler_filename)\n    \n    with open (columns_to_use_filename, 'rb') as fp:\n        columns_to_use = pickle.load(fp)    \n    \n    X = X.loc[:, columns_to_use]\n    \n    numerical_X = X.loc[:, X.dtypes != 'object']\n    numerical_X = pd.DataFrame(scaler.transform(numerical_X), columns=numerical_X.columns)\n    numerical_X = numerical_X.fillna(0)\n    return numerical_X \n#     categorical_X = X.loc[:, X.dtypes == 'object']\n#     categorical_X_encoded = pd.get_dummies(categorical_X, dummy_na=True, prefix=categorical_X.columns)\n#     final_X = pd.concat([numerical_X, categorical_X_encoded], axis=1)\n    \n#     return final_X","05af3e02":"data = pd.read_csv('\/kaggle\/input\/Data.csv')\nX = data.drop(columns='Flag')\ny = data.Flag\n\ncolumns_to_use = list(X.columns[(X.isna().sum() \/ len(X)) < 0.4])\nX = X.loc[:, columns_to_use]\ncorrs = X.corrwith(y).abs().sort_values(ascending=False)\n# columns_to_use = [x for x in columns_to_use if x not in corrs[corrs < 0.01].index.tolist()]\ncolumns_to_use = corrs[corrs > 0.01].index.tolist()\nX = X.loc[:, columns_to_use]\n\nwith open('columns_to_use', 'wb') as fp:\n    pickle.dump(columns_to_use, fp)\n\nscaler = sklearn.preprocessing.StandardScaler()\nscaler.fit(X.loc[:, X.dtypes != 'object'])\njoblib.dump(scaler, \"scaler.save\") \n\nX_preprocessed = preprocessing(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, stratify=y, test_size=0.1)\n# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify=y_train, test_size=0.1)","2a1d8fb3":"print(columns_to_use)","67d724ee":"print(f'Number of samples: {len(X)}.')","ae4a63b6":"y.value_counts(normalize=True)","442f16cd":"y.isna().any()","e3f553b6":"(X.isna().sum() \/ X.shape[0]).sort_values()","8c617274":"X.isna().sum(axis=1).sort_values() \/ X.shape[1]","fb78e733":"corrs","d149dfca":"data.shape[1] - 1","03a4f1c2":"X_preprocessed.shape[1]","df7e3129":"from tensorflow.keras import backend as K\n\ndef focal_loss(gamma=2, alpha=0.89):\n    def focal_loss_fixed(y_true, y_pred):\n        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)\n                 + (1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n    return focal_loss_fixed","81fd2801":"OPTIMIZER = keras.optimizers.Adam(learning_rate=0.01, clipvalue=5)\nEPOCHS = 50\nBATCH_SIZE = 256\n\nes = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, restore_best_weights=True)","9dda872c":"alpha = y.value_counts(normalize=True)[0] # 0.89\ngamma = 0.5","cf97a426":"import time\n\ndef create_model(gamma=gamma, alpha=alpha, seed=None):\n    \n    if seed is not None:\n        np.random.seed(seed)\n    else:\n        t = int(time.time())\n        print(f'Seed: {t}.')\n        np.random.seed(t)\n\n    model = Sequential()\n\n    model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.3))\n\n    model.add(Dense(64, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.3))\n\n    model.add(Dense(32, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n\n    model.add(Dense(16, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Dense(8, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n    \n    model.add(Dense(4, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n\n    model.add(Dense(1, activation='sigmoid', \n                    name='prediction', \n                    bias_initializer=keras.initializers.Constant(np.log(9))))\n\n    model.compile(loss=focal_loss(gamma, alpha), optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n\n    return model","607232ac":"def evaluate(model, X_val, y_val):\n    y_pred = model.predict_classes(X_val).ravel()\n    f1 = f1_score(y_val, y_pred , average=\"macro\")\n    fpr, tpr, thresholds = roc_curve(y_val, y_pred)\n    auc_model = auc(fpr, tpr)\n    conf = pd.DataFrame(confusion_matrix(y_val, y_pred), columns=['pred_0', 'pred_1'], index=['true_0', 'true_1'])\n    prec = precision_score(y_val, y_pred)\n    recall = recall_score(y_val, y_pred)\n    acc = accuracy_score(y_val, y_pred)\n    \n    return {'auc': auc_model, \n            'f1':f1, \n            'confusion':conf, \n            'precision': prec,\n            'recall': recall,\n            'accuracy': acc,\n            'roc_cache': (fpr, tpr)}","d032460a":"def train_and_evaluate_model(model, X_train, y_train, X_val, y_val, epochs=EPOCHS):\n            \n    history = model.fit(X_train.values, y_train,\n                        batch_size=BATCH_SIZE, \n                        epochs=epochs, \n                        validation_split=0.1,\n                        use_multiprocessing=True,\n                        verbose=0,\n                        callbacks=[es]\n                       )\n    \n    return {'model': model,\n            'history':history, \n            'eval': evaluate(model, X_val, y_val)}","fa80f999":"from sklearn.model_selection import StratifiedKFold\n\nn_folds = 10\n\nskf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n\nh = []\n\nfor i, (train, test) in enumerate(skf.split(X_train, y_train)):\n    print(\"Running Fold\", i + 1, \"\/\", n_folds)\n    model = None # Clearing the NN.\n    model = create_model(seed=1587411287)\n    h.append(train_and_evaluate_model(model,\n                                      X_train.iloc[train], y_train.iloc[train], \n                                      X_train.iloc[test], y_train.iloc[test]))","e9c5d68e":"np.mean([e['eval']['auc'] for e in h])","59e1268a":"model = None\nmodel = create_model(seed=1587411287)\nmodel.summary()","f762b391":"history = train_and_evaluate_model(model, X_train, y_train, X_test, y_test)","e082409c":"evaluate(model, X_train, y_train)","90eb5425":"history['eval']","e121ce7f":"plt.title('Loss')\nplt.plot(history['history'].history['loss'])\nplt.plot(history['history'].history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","1dc6cbcd":"fpr, tpr = history['eval']['roc_cache']\nplt.plot(fpr, tpr, color='darkorange', label=f\"ROC curve (area = {round(history['eval']['auc'], 3)})\")\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()","d41b0c28":"model_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")","dc37918a":"Number of features (after preprocessing):","e5423560":"## Saving the model","036abbc9":"## Scenario\nA financial institution desires to refine its targeting strategy and grow the\nclient population leveraging third party credit data.\n","afed10d7":"--------------------------","4ba4c690":"We will use weighted focal loss to account class disbalance problem.  \nhttps:\/\/arxiv.org\/pdf\/1708.02002.pdf  \n$$Loss(p_t) = \\alpha _t* (1 - p_t) ^ \\gamma * log(p_t),$$ where $p_t$ is predicted probability of sample to belong to certain class.","8eaa92ad":"#### Test performance","3b779a7a":"# <center>Deep NN<\/center>\n## <div align=right>Made by:<\/div>\n**<div align=right>Ihor Markevych<\/div>**","533a6672":"## References:\n\n1. https:\/\/arxiv.org\/pdf\/1804.07612.pdf\n1. https:\/\/www.kaggle.com\/abazdyrev\/keras-nn-focal-loss-experiments","9dea8b31":"### Conclusion:\n  \nFocal loss allows to train model on skewed data without data augumentation or downsampling.  \n* $\\alpha$ was set to be equal inverse normalized frequency of appearing of this class in data. This can be taken as starting default value that can be tuned later with cross-validation. However, in our case this value appeared to be optimal or close to optimal.  \n* $\\gamma$ was tuned using validation set.\n  \nFocal loss gave better performance than using SMOTE to oversample rare class, or than using downsamlping or combinations of above. It also gave better results than simply using weights to account skewed target.  \nSetting bias of the final layer to $log(\\frac{1 - \\pi}{\\pi})$, where $\\pi$ is normalized frequency of rare class ensure faster convergence and numerical stability. With SMOTEd and downsampled data local optimas of predicting all 0s were a significant problem.  \nTweaking $\\gamma$ parameter can lead to either more correctly classified 0 classes, or to more correctly classified 1 classes.","938a6db8":"### Evaluation","5fd1695f":"Number of features (before preprocessing):","267f6515":"### Assumptions:\n* Main assumption is that stakeholder will prefer to have more false positives (e.g. sending advertisement to people that most likely won't become a customer) than to have false negatives (missing potential customers).\n* Therefore, ROC-AUC was selected as a single performance evaluation metric (for ease of comparison between different models).","60940e3c":"### What else was tried:\n* SMOTE, \n* downsampling, \n* ensemble, \n* two stage training (SMOTEd data at stage 1 + downsampled data at stage 2).","d5c3a1fc":"We see that some columns have a lot of missing values.  \nAlso some rows have missing values (up to all of the values).","549a8d17":"Columns used:","345be1ab":"### Training","115763e2":"## Validation with Stratified K-Fold","720b70a6":"Correlation is going from quite high values of 0.1 to very small rates of 0.06.","3a211f93":"We can see quite strong disbalance in classes. We will need to account that in our model.","1dc9d302":"## Final model","c322c2ac":"## Preprocessing","3ee4022c":"## Assumptions, limitations, conclusion","16c56fb1":"We can also see that our target does not have any missing values.","d09ee7fa":"## EDA","9bd1660d":"#### ROC curve","e852110c":"#### Train performance","27724980":"## Model","e23e0a58":"## Hyperparameters","da3cef2d":"### Limitations:\nMain limitation is lack of proper estimate of Bayess Classifier performance. For instance, for tasks like image classification Bayess Classifier error is usually assumed to be zero, as human performance is around 0% error. However, for task like this it's hard to estimate optimal performance, therefore we can't conclude whether our model is too simple (has removable bias), or we are already performing at best possible rate.  \n  \nAnother limiting factor is small number of samples with 1 target. It may be possible to significantly increase model performance by having more data for class 1.","d150409c":"Correlations:","eb20076e":"#### Learning curves","b8b8de33":"## Focal loss"}}