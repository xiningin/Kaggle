{"cell_type":{"f1f119fd":"code","faf0aee0":"code","9caa0f83":"code","35d139c8":"code","628099f9":"code","d8d984c5":"code","ee37f6a0":"code","47900d14":"code","0eaaea01":"code","e4df6124":"code","6f771bfb":"code","2fbc0572":"code","f36a0605":"code","314b6756":"code","7f944017":"code","467e802b":"markdown","18c22f8d":"markdown","5ff37910":"markdown","9c9b11ba":"markdown"},"source":{"f1f119fd":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","faf0aee0":"data = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/test.csv\")\ndata = data.drop(\"id\", axis = 1)\ndata = data[0:20000]","9caa0f83":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nx = scaler.fit_transform(data)","35d139c8":"#Let's select the optimum number of clusters for k-means classification\nfrom sklearn.cluster import KMeans\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++',\n                    max_iter = 400, n_init = 10, random_state = 0)\n    kmeans.fit(x)\n    wcss.append(kmeans.inertia_)\n#Plotting the results onto a line graph to observe 'The elbow'\nplt.plot(range(1, 11), wcss)\nplt.title('Elbow Method')\nplt.xlabel('Association')\nplt.ylabel('WCSS') #within cluster sum of squares\nplt.show()","628099f9":"#Applying kmeans to the dataset \/ Creating the kmeans classifier\nkmeans = KMeans(n_clusters = 2, init = 'k-means++', max_iter = 500, \n                n_init = 10, random_state = 0)\ny_kmeans = kmeans.fit_predict(x)","d8d984c5":"import copy\ndata_kmeans = data.copy()\ndata_kmeans[\"label\"] = y_kmeans\ndata_kmeans","ee37f6a0":"len(data_kmeans[data_kmeans.label == 0]) \/ len(data_kmeans[data_kmeans.label == 1])","47900d14":"#Visualising the clusters\nplt.scatter(x[y_kmeans == 0, 0:38], x[y_kmeans == 0, 37:75], s = 75, \n            c = 'red', label = '0')\nplt.scatter(x[y_kmeans == 1, 0:38], x[y_kmeans == 1, 37:75], s = 75, \n            c = 'blue', label = '1')\n\n#Plotting the centroids of the clusters\nplt.scatter(kmeans.cluster_centers_[:, 0:38], \n            kmeans.cluster_centers_[:, 37:75], s = 100, \n            c = 'black', label = 'Centroide')\n\nplt.legend()","0eaaea01":"from mpl_toolkits.mplot3d import Axes3D\nC = kmeans.cluster_centers_\nfig = plt.figure()\nax = Axes3D(fig)\nax.scatter(x[:, 0], x[:, 1], x[:, 2], c = y_kmeans)\nax.scatter(C[:, 0], C[:, 1], C[:, 2], marker='*', c='#050505', s=1000)","e4df6124":"xs = x[:, 0]\nys = x[:, 1]\nplt.scatter(xs, ys,  c = y_kmeans, alpha=0.5)\nplt.scatter(C[:,0], C[:, 1], s = 150, c = 'red', label = 'centroid')","6f771bfb":"data = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/test.csv\")\ndata = data.drop(\"id\", axis = 1)\ndata = data[0:20000].values","2fbc0572":"from sklearn.cluster import DBSCAN\nfrom sklearn.neighbors import NearestNeighbors","f36a0605":"neigh = NearestNeighbors(n_neighbors=2)\nnbrs = neigh.fit(data)\ndistances, indices = nbrs.kneighbors(data)\ndistances = np.sort(distances, axis=0)\ndistances = distances[:,1]\nplt.plot(distances)","314b6756":"dbsc = DBSCAN(eps = 60, min_samples = 100).fit(data)","7f944017":"labels = dbsc.labels_\ncore_samples = np.zeros_like(labels, dtype = bool)\ncore_samples[dbsc.core_sample_indices_] = True\nunique_labels = np.unique(labels)\ncolors = plt.cm.Spectral(np.linspace(0,1, len(unique_labels)))\nfor (label, color) in zip(unique_labels, colors):\n    class_member_mask = (labels == label)\n    xy = data[class_member_mask & core_samples]\n    plt.plot(xy[:,0],xy[:,1], 'o', markerfacecolor = color, markersize = 10)\n    xy2 = data[class_member_mask & ~core_samples]\n    plt.plot(xy2[:,0],xy2[:,1], 'o', markerfacecolor = color, markersize = 5)\nplt.title(\"DBSCAN on TPS JUNE test data\")","467e802b":"# K means","18c22f8d":"pick data[0:20000] to run faster","5ff37910":"pick 60 for eps","9c9b11ba":"# DBSCAN"}}