{"cell_type":{"934a3eb1":"code","d7d16609":"code","c6bcba0b":"code","c8f7301f":"code","34876fbf":"code","508e4b92":"code","63457305":"code","d3a1f0d1":"code","c75caf7a":"code","109d521b":"code","62078aa9":"code","f55ee15a":"code","df75334b":"code","3ca9b8ba":"code","011ad392":"code","a1bcedff":"code","a16835ba":"code","3b4452d1":"code","e41f6768":"code","b0d29b35":"code","edfda440":"code","c82cb804":"code","b1be3117":"code","9073af2d":"code","be15cd51":"code","fcc87300":"code","42a4d88e":"code","9d57aa70":"code","6dec80b3":"code","ecb6ffa2":"code","27395435":"code","12821cf3":"code","2f77f105":"code","492a6540":"code","697d83aa":"code","e6cd56c0":"code","929cd6fc":"code","6ad42944":"code","5a89391e":"code","8c8e92e6":"code","b68a4bbb":"code","68ba6a03":"code","efc02b7b":"code","bd0052fe":"code","25e0b32d":"code","14eb57c0":"code","fbfa2f0f":"code","644745bc":"code","4be1e727":"code","ed99eb88":"code","15f81965":"code","db5efdbb":"code","7aea0e04":"code","da8a47f7":"code","b7d63fcb":"code","7ee99b91":"code","75c683ab":"code","bb286280":"code","034574f1":"code","761ff6a1":"code","d86d4497":"code","e8882ff8":"code","eaae0d02":"code","a9a9692c":"code","1560162a":"code","f33ac7d7":"code","96c85c24":"code","eb0ef71d":"code","a56ba33e":"code","a77e2241":"code","273d6a08":"code","2af31225":"code","12bd04a4":"code","0ea2b96c":"code","4a5f515b":"code","cdff609e":"code","dc180602":"code","6ab7e03a":"code","5faa1090":"code","341236bd":"code","b45fcd76":"code","1ece4ba9":"code","0d03ce66":"code","5c88f6e2":"code","f2a02303":"code","274a0738":"code","cda7fed0":"code","d1918046":"code","ae37c5b6":"code","237d66c2":"code","b5adbad3":"code","643dd856":"code","8963b210":"code","5d4aa89d":"code","56294f1f":"code","444db9fc":"code","073c0154":"code","530110f7":"code","d9fb1280":"code","9fd49695":"code","cfa33d82":"code","10443039":"code","2221810f":"code","5230478e":"code","7e93f637":"code","15c6c1d1":"code","5894211f":"code","851bc46a":"code","b253b336":"code","4a4fbe56":"code","d3a842b7":"code","e3bdb098":"code","f54d949e":"code","d969db52":"code","65c5fb2e":"code","a40faef0":"code","e9a25c99":"code","11ad0dde":"code","cf1c2ce0":"code","59945a46":"code","0d0e5a00":"code","1e0ec15f":"code","e5775428":"code","52b0eb7b":"code","2a209888":"code","08864e26":"code","8d278ea1":"code","ab2d3391":"code","800a6f42":"code","c6a5b5b9":"code","d31ce102":"code","2c79858d":"code","dee2beff":"code","d628cedd":"code","361bb11a":"code","c3729ef1":"code","d591e7f9":"code","0c0b717f":"code","a6b4a8e8":"code","dad03efc":"code","bba882e1":"code","e7551621":"code","ba806512":"code","19348707":"code","db684bdb":"code","127a3fa8":"code","be307b82":"code","cba147ec":"code","b92770d4":"code","f5b8c471":"code","874da6ef":"code","474c8bb8":"code","f0b09ccb":"code","3efae3bc":"code","1d3f07bc":"code","cc98bdb7":"code","d6d3386e":"code","b5b51e71":"code","ca33864c":"code","dee783ee":"code","99ff1fff":"code","9c29b6ce":"code","d3b89613":"code","d4221f5e":"code","65475aff":"code","e43398e1":"code","dda004ea":"markdown","64e59049":"markdown","054a0e94":"markdown","7ac259d3":"markdown","b3532418":"markdown","cf5813db":"markdown","3b25700e":"markdown","f19e14ef":"markdown","f6b1a46f":"markdown","53f99283":"markdown","bd050d38":"markdown","d906039e":"markdown","cbf2c58d":"markdown","43405d97":"markdown","134e38a3":"markdown","e14677ea":"markdown","53146e87":"markdown","0f8a7872":"markdown","773a957f":"markdown","c6111c19":"markdown","2d0f982d":"markdown","1336b273":"markdown","ae1ed832":"markdown","b3f711d0":"markdown","a5c617e9":"markdown","a3e11660":"markdown","dff66f27":"markdown","5c17ea94":"markdown","57af820d":"markdown","c88b2ff4":"markdown"},"source":{"934a3eb1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas_profiling \nimport math\nfrom pandas.api.types import CategoricalDtype\n%matplotlib inline\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n","d7d16609":"train_data = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_x = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\n","c6bcba0b":"test_data=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","c8f7301f":"print (train_data.shape)\nprint (test_x.shape)","34876fbf":"train_data.head()\n","508e4b92":"train_x = train_data.loc[:,train_data.columns != 'SalePrice']\ntrain_y = train_data.loc[:,train_data.columns == 'SalePrice']\nprint (train_x.shape)\nprint (train_y.shape)","63457305":"cptry = train_data.loc[:,train_data.columns == 'SalePrice']","d3a1f0d1":"train_y.head()","c75caf7a":"# applying log transform to train, test data.\nclass Utils:\n    @classmethod\n    def apply_log_trans(cls, indf, collist):\n        temp = indf.copy()\n        df = pd.DataFrame(np.log(temp[collist]))\n        temp = temp.drop(columns=collist)\n        outdf = pd.concat([temp,df],join=\"inner\",axis=1)\n        return outdf\n    \n    @classmethod\n    def corr_two_feature(cls, indf, f1, f2):\n        val = indf[[f1,f2]].corr()[f1][f2]\n        return val\n    \n    @classmethod\n    def corr_one_feature(cls, indf, f1):\n        train_corr = pd.DataFrame(indf[indf.columns[1:]].corr()[f1][:])\n        train_corr =train_corr.sort_values(by=[f1],ascending=False)\n        return train_corr\n    \n    @classmethod\n    def corr_similar_features(cls, indf, f1):\n        tmp_list = [cols for cols in indf.columns if f1 in cols]\n        temp_corr = pd.DataFrame(indf[tmp_list].corr())\n        return temp_corr\n    \n    @classmethod\n    def cat_myrename(cls, indf, fture, catlist):\n        tmp = indf[fture].astype(\"category\")\n        gdict = { val:cnt+1 for cnt,val in enumerate(catlist) }\n        tmp = pd.DataFrame(tmp.cat.rename_categories(gdict))\n        return tmp\n    \n    @classmethod\n    def missing_vals(cls, indf, id_str=None):\n        if (id_str is None):\n            id_str = 'Id'\n        countdf = indf.count()\n        missdict = {}\n        for key,val in countdf.items():\n            missdict[key] = countdf[id_str] - val\n        missdf = pd.DataFrame(missdict.items(),columns=['name','miss_val'])\n        miss_pct = pd.DataFrame((missdf['miss_val']\/countdf[id_str])*100)\n        miss_pct = miss_pct.rename(columns={'miss_val':'miss_pct'})\n        missdf = pd.concat([missdf,miss_pct],axis=1,join='inner')\n        missdf = missdf.sort_values(by='miss_pct',ascending=False)\n        return missdf\n    \n    @classmethod\n    def missing_vals2(cls, indf, id_str=None):\n        all_data = indf\n        all_data_na = (all_data.isnull().sum() \/ len(all_data)) * 100\n        all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n        missing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n        return missing_data\n    \n    \n    @classmethod\n    def my_dummies(cls, indf, collist):\n        dummy = pd.get_dummies(indf[collist])\n        tmp = indf.copy()\n        tmp = pd.concat([tmp, dummy],axis=1,join='inner')\n        tmp.drop(columns=collist,axis=1,inplace=True)\n        return tmp\n    \n    @classmethod\n    def cal_skewness(cls, indf):\n        all_data = indf.copy()\n        numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n        # Check the skew of all numerical features\n        skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n        print(\"\\nSkew in numerical features: \\n\")\n        skewness = pd.DataFrame({'Skew' :skewed_feats})\n        return skewness","109d521b":"# first understand the target\nsns.distplot(train_y)\nplt.show()","62078aa9":"# train_y = Utils.apply_log_trans(train_y, ['SalePrice'])\n# train_y","f55ee15a":"# # understand feature vectors. First, Profile\n# import warnings\n# warnings.filterwarnings('ignore')\n# profile = pandas_profiling.ProfileReport(train_x)\n# profile","df75334b":"sns.catplot(x=\"MSSubClass\",y=\"SalePrice\",data=train_data, kind=\"bar\")","3ca9b8ba":"# train_data_corr = train_data.corr()\n# plt.subplots(figsize=(22,9))\n# sns.heatmap(train_data_corr,cmap='coolwarm')","011ad392":"# correlation between target and some features.\ntrain_corr = pd.DataFrame(train_data[train_data.columns[1:]].corr()['SalePrice'][:])\ntrain_corr =train_corr.sort_values(by=[\"SalePrice\"],ascending=False)\ntrain_corr","a1bcedff":"# N largest correlated features\n#saleprice correlation matrix\nk = 10 #number of variables for heatmap\n# cols = train_data_corr.nlargest(k, 'SalePrice')['SalePrice'].index\n# cm = np.corrcoef(train_data[cols].values.T)\n# sns.set(font_scale=1.25)\n# hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n# plt.show()","a16835ba":"# tmp_corr = pd.DataFrame(train_data[train_data.columns[1:]].corr()['OverallQual'][:])\n# tmp_corr = tmp_corr.sort_values(by=[\"OverallQual\"],ascending=False)\n# tmp_corr","3b4452d1":"sns.relplot(x=\"OverallQual\",y=\"SalePrice\",data=train_data)","e41f6768":"# above correlation is a famous cone graph where relationship is non-linear. it is bad","b0d29b35":"df_y = pd.DataFrame(np.log(train_data['SalePrice']))\nnew_df = pd.concat([train_data[\"OverallQual\"],df_y],axis=1, join=\"inner\")\nsns.relplot(x=\"OverallQual\",y=\"SalePrice\",data=new_df)","edfda440":"# above correlation graph is a linear graph. so, lets apply log trans on target\ndf = pd.DataFrame(np.log(train_data['SalePrice']))\ntrain_data = train_data.drop(columns=[\"SalePrice\"])\ntrain_data = pd.concat([train_data,df],join=\"inner\",axis=1)\ntrain_data","c82cb804":"sns.relplot(x=\"GrLivArea\",y=\"SalePrice\",data=train_data)","b1be3117":"df = pd.DataFrame(np.log(train_data['GrLivArea']))\ntmp_df = pd.concat([train_data['SalePrice'],df],join=\"inner\",axis=1)\nsns.relplot(x=\"GrLivArea\",y=\"SalePrice\",data=tmp_df)","9073af2d":"collist = ['TotalBsmtSF','GarageArea','GrLivArea']\ntrain_x = Utils.apply_log_trans(train_x,collist)\ntest_x = Utils.apply_log_trans(test_x,collist)\n","be15cd51":"train_x = train_x.drop(columns=[\"GarageArea\",\"1stFlrSF\",\"TotRmsAbvGrd\"])\ntest_x = test_x.drop(columns=[\"GarageArea\",\"1stFlrSF\",\"TotRmsAbvGrd\"])","fcc87300":"sns.relplot(x=\"GarageCars\",y=\"GarageArea\",data=train_data)","42a4d88e":"\nsns.relplot(x=\"TotalBsmtSF\",y=\"SalePrice\",data=train_data)","9d57aa70":"df = pd.DataFrame(np.log(train_data['TotalBsmtSF']))\ntmp_df = pd.concat([train_data['SalePrice'],df],join=\"inner\",axis=1)\nsns.relplot(x=\"TotalBsmtSF\",y=\"SalePrice\",data=tmp_df)","6dec80b3":"tmp=pd.concat([train_x,train_y],join=\"inner\",axis=1)\nsns.catplot(x=\"FullBath\",y=\"SalePrice\",data=tmp)","ecb6ffa2":"\ntmp=pd.concat([train_x,train_y],join=\"inner\",axis=1)\n# sns.barplot(x=\"TotRmsAbvGrd\",y=\"SalePrice\",data=tmp)\n# sns.catplot(x=\"TotRmsAbvGrd\",y=\"SalePrice\",data=tmp)","27395435":"# sns.relplot(x=\"TotRmsAbvGrd\",y=\"SalePrice\",data=tmp)","12821cf3":"# tmp=pd.concat([train_x,train_y],join=\"inner\",axis=1)\n# sns.barplot(x=\"YearBuilt\",y=\"SalePrice\",data=tmp)","2f77f105":"sns.relplot(x=\"YearBuilt\",y=\"SalePrice\",data=tmp)","492a6540":"# train_corr = pd.DataFrame(train_data[train_data.columns[1:]].corr()['SalePrice'][:])\ntrain_x[['YearBuilt','YearRemodAdd']].corr()['YearBuilt']['YearRemodAdd']","697d83aa":"train_x.columns","e6cd56c0":"# sns.relplot(x=\"GarageYrBlt\",y=\"YearBuilt\",data=tmp)\nUtils.corr_two_feature(tmp, \"GarageYrBlt\",\"YearBuilt\")","929cd6fc":"train_x = train_x.drop(columns=[\"YearBuilt\"])\ntest_x = test_x.drop(columns=['YearBuilt'])","6ad42944":"# check correlation between garagexxx features.\ndesired_cols = [ col for col in tmp.columns if \"Garage\" in col]\nprint (desired_cols)\ncorr_ = Utils.corr_similar_features(tmp, \"Garage\")\nprint (corr_)\nsns.heatmap(corr_, cmap=\"coolwarm\",annot=True)","5a89391e":"%matplotlib inline\nplt.figure(figsize=(16, 6))\nsns.catplot(x=\"GarageType\",y=\"SalePrice\",data=tmp,kind=\"swarm\")\nplt.show()","8c8e92e6":"\n# print (train_x['GarageType'].unique())\n# garagelist = ['Attchd', 'BuiltIn','Detchd', 'Basment','CarPort' , '2Types']\n# garagelist.reverse()\n# # tmp_x = train_x[\"GarageType\"].astype(\"category\",ordered=True,categories=garagelist).cat.codes\n# tmp_x = train_x[\"GarageType\"].astype(\"category\")\n# cat_type=CategoricalDtype(categories=garagelist,ordered=True)\n# tmp_x = tmp_x.astype(cat_type)\n# tmp_x.cat.codes","b68a4bbb":"glist = ['Attchd', 'BuiltIn','Detchd', 'Basment','CarPort' , '2Types']\nglist.reverse()\ntmp = Utils.cat_myrename(train_x, \"GarageType\", glist)\ntrain_x = train_x.drop(columns=[\"GarageType\"])\ntrain_x = pd.concat([train_x, tmp],join=\"inner\",axis=1)\ntmp = Utils.cat_myrename(test_x, \"GarageType\", glist)\ntest_x = test_x.drop(columns=[\"GarageType\"])\ntest_x = pd.concat([test_x, tmp],join=\"inner\",axis=1)","68ba6a03":"test_x[\"GarageType\"]","efc02b7b":"# %matplotlib inline\n# plt.figure(figsize=(16, 6))\n# sns.catplot(x=\"GarageFinish\",y=\"SalePrice\",data=tmp,kind=\"swarm\")\n# plt.show()\ntrain_x[\"GarageFinish\"]","bd0052fe":"gf_order = ['Unf','RFn','Fin']\ntmp = Utils.cat_myrename(train_x, \"GarageFinish\", gf_order)\ntrain_x = train_x.drop(columns=[\"GarageFinish\"])\ntrain_x = pd.concat([train_x, tmp],join=\"inner\",axis=1)\ntmp = Utils.cat_myrename(test_x, \"GarageFinish\", gf_order)\ntest_x = test_x.drop(columns=[\"GarageFinish\"])\ntest_x = pd.concat([test_x, tmp],join=\"inner\",axis=1)","25e0b32d":"#checking the correlation of cars and target\ntmp = pd.concat([train_x,train_y],axis=1,join=\"inner\")\nval = Utils.corr_two_feature(tmp,\"GarageCars\",\"SalePrice\")\nval","14eb57c0":"train_x[\"GarageQual\"]\nsns.catplot(x=\"GarageQual\",y=\"SalePrice\",data=tmp,kind=\"swarm\")\nplt.show()","fbfa2f0f":"qual_order = ['Po','Fa','TA','Gd','Ex']\ntmp = Utils.cat_myrename(train_x, \"GarageQual\", qual_order)\ntrain_x = train_x.drop(columns=[\"GarageQual\"])\ntrain_x = pd.concat([train_x, tmp],join=\"inner\",axis=1)\ntmp = Utils.cat_myrename(test_x, \"GarageQual\", qual_order)\ntest_x = test_x.drop(columns=[\"GarageQual\"])\ntest_x = pd.concat([test_x, tmp],join=\"inner\",axis=1)","644745bc":"qual_order = ['Po','Fa','TA','Gd','Ex']\ntmp = Utils.cat_myrename(train_x, \"GarageCond\", qual_order)\ntrain_x = train_x.drop(columns=[\"GarageCond\"])\ntrain_x = pd.concat([train_x, tmp],join=\"inner\",axis=1)\ntmp = Utils.cat_myrename(test_x, \"GarageCond\", qual_order)\ntest_x = test_x.drop(columns=[\"GarageCond\"])\ntest_x = pd.concat([test_x, tmp],join=\"inner\",axis=1)","4be1e727":"tot_tmp = pd.concat([train_x,train_y],axis=1,join=\"inner\")","ed99eb88":"tmp = pd.concat([train_x,train_y],axis=1,join=\"inner\")\nsns.relplot(x=\"GarageCond\",y=\"GarageQual\",data=tmp)\n# val = Utils.corr_two_feature(tmp,\"GarageCond\",\"GarageQual\")\n# val","15f81965":"train_x.drop([\"GarageCond\"],axis=1,inplace=True)\ntest_x.drop([\"GarageCond\"],axis=1,inplace=True)","db5efdbb":"# sns.relplot(x=\"OverallQual\",y=\"OverallCond\",data=tmp)\nval = Utils.corr_two_feature(tmp, \"OverallQual\",\"OverallCond\")\nprint(val)\nsns.lineplot(data=tmp, x=\"OverallQual\",y=\"OverallCond\")","7aea0e04":"desired_cols = [ col for col in tmp.columns if \"Bsmt\" in col]\nprint(desired_cols)\ndcorr = train_x[desired_cols].corr()\nsns.heatmap(dcorr,cmap=\"coolwarm\",annot=True)","da8a47f7":"train_x[['BsmtFinSF1','BsmtFinSF2', 'BsmtUnfSF', 'BsmtFullBath', 'BsmtHalfBath', 'TotalBsmtSF']].describe()","b7d63fcb":"train_x = Utils.apply_log_trans(train_x,['BsmtFinSF1','BsmtFinSF2', 'BsmtUnfSF'])\ntest_x = Utils.apply_log_trans(test_x,['BsmtFinSF1','BsmtFinSF2', 'BsmtUnfSF'])","7ee99b91":"train_x[['BsmtFinSF1','BsmtFinSF2', 'BsmtUnfSF', 'BsmtFullBath', 'BsmtHalfBath', 'TotalBsmtSF']].describe()","75c683ab":"adf = ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',]\ntrain_x[adf]","bb286280":"train_x['BsmtFinType1'].unique()","034574f1":"# edit 1: \n# we could map as follows. No need to use cat_myrename func\n# qual_dict = {None: 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5}\n# all_df[\"ExterQual\"] = df[\"ExterQual\"].map(qual_dict).astype(int)\n\nqual_order = ['Po','Fa','TA','Gd','Ex']\ncolname = \"BsmtQual\"\ntmp = Utils.cat_myrename(train_x, colname, qual_order)\ntrain_x = train_x.drop(columns=[colname])\ntrain_x = pd.concat([train_x, tmp],join=\"inner\",axis=1)\ntmp = Utils.cat_myrename(test_x, colname, qual_order)\ntest_x = test_x.drop(columns=[colname])\ntest_x = pd.concat([test_x, tmp],join=\"inner\",axis=1)\n\nqual_order = ['Po','Fa','TA','Gd','Ex']\ncolname = \"BsmtCond\"\ntmp = Utils.cat_myrename(train_x, colname, qual_order)\ntrain_x = train_x.drop(columns=[colname])\ntrain_x = pd.concat([train_x, tmp],join=\"inner\",axis=1)\ntmp = Utils.cat_myrename(test_x, colname, qual_order)\ntest_x = test_x.drop(columns=[colname])\ntest_x = pd.concat([test_x, tmp],join=\"inner\",axis=1)\n\nqual_order = ['No','Mn','Av','Gd']\ncolname = \"BsmtExposure\"\ntmp = Utils.cat_myrename(train_x, colname, qual_order)\ntrain_x = train_x.drop(columns=[colname])\ntrain_x = pd.concat([train_x, tmp],join=\"inner\",axis=1)\ntmp = Utils.cat_myrename(test_x, colname, qual_order)\ntest_x = test_x.drop(columns=[colname])\ntest_x = pd.concat([test_x, tmp],join=\"inner\",axis=1)\n\n\nqual_order = ['GLQ', 'ALQ', 'BLQ', 'Rec', 'LwQ', 'Unf']\nqual_order.reverse()\ncolname = \"BsmtFinType1\"\ntmp = Utils.cat_myrename(train_x, colname, qual_order)\ntrain_x = train_x.drop(columns=[colname])\ntrain_x = pd.concat([train_x, tmp],join=\"inner\",axis=1)\ntmp = Utils.cat_myrename(test_x, colname, qual_order)\ntest_x = test_x.drop(columns=[colname])\ntest_x = pd.concat([test_x, tmp],join=\"inner\",axis=1)\n\ncolname = \"BsmtFinType2\"\ntmp = Utils.cat_myrename(train_x, colname, qual_order)\ntrain_x = train_x.drop(columns=[colname])\ntrain_x = pd.concat([train_x, tmp],join=\"inner\",axis=1)\ntmp = Utils.cat_myrename(test_x, colname, qual_order)\ntest_x = test_x.drop(columns=[colname])\ntest_x = pd.concat([test_x, tmp],join=\"inner\",axis=1)","761ff6a1":"adf = ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',]\ntrain_x[adf]","d86d4497":"# first get all the categorical features.\nall_cols = train_x.columns\nnum_cols = train_x._get_numeric_data().columns\nprint (list(set(all_cols)-set(num_cols)))","e8882ff8":"ln = len(list(set(all_cols)-set(num_cols)))\nln","eaae0d02":"outdf = Utils.missing_vals(train_x,'Id')\noutdf.head(8)","a9a9692c":"outdf = Utils.missing_vals(test_x,'Id')\noutdf.head(8)","1560162a":"train_x.drop(['PoolQC','MiscFeature','Alley','Fence','FireplaceQu'],axis=1,inplace=True)\ntest_x.drop(['PoolQC','MiscFeature','Alley','Fence','FireplaceQu'],axis=1,inplace=True)","f33ac7d7":"# lets convert all the categorical vectors to numerical\nsns.catplot(x='LotShape',y='SalePrice',data=tot_tmp,kind='box')","96c85c24":"# get dummies for LotShape\ntrain_x = Utils.my_dummies(train_x, [\"LotShape\"])\ntest_x = Utils.my_dummies(test_x, [\"LotShape\"])","eb0ef71d":"sns.catplot(x=\"LotConfig\",data=train_x,kind=\"count\")","a56ba33e":"sns.catplot(x=\"LotConfig\",y='SalePrice',data=tot_tmp)","a77e2241":"# get dummies for LotShape\ntrain_x = Utils.my_dummies(train_x, [\"LotConfig\"])\ntest_x = Utils.my_dummies(test_x, [\"LotConfig\"])","273d6a08":"# and get dummies for all other categorical vectors\ncatvec = ['Condition1', 'CentralAir', 'ExterQual', 'Foundation', 'Electrical', 'GarageFinish', 'Street', 'BldgType', 'RoofStyle', 'LandSlope', 'BsmtExposure', 'KitchenQual', 'Utilities', 'RoofMatl', 'SaleCondition', 'MSZoning', 'GarageType', 'BsmtFinType2', 'Exterior2nd', 'BsmtCond', 'BsmtQual', 'Functional', 'SaleType', 'HouseStyle', 'Exterior1st', 'HeatingQC', 'Neighborhood', 'Condition2', 'ExterCond', 'MasVnrType', 'PavedDrive', 'BsmtFinType1', 'LandContour', 'GarageQual', 'Heating']\ntrain_x = Utils.my_dummies(train_x,catvec)\ntest_x = Utils.my_dummies(test_x,catvec)","2af31225":"num_cols","12bd04a4":"val = Utils.corr_one_feature(tot_tmp,\"MSSubClass\")\nval","0ea2b96c":"train_x.drop(['MSSubClass'],axis=1,inplace=True)\ntest_x.drop(['MSSubClass'],axis=1,inplace=True)","4a5f515b":"sns.relplot(x=\"LotFrontage\",y=\"SalePrice\",data=tot_tmp)","cdff609e":"# correlation between big and small values. so, lets apply log transform to lotfrontage\ntrain_x = Utils.apply_log_trans(train_x,['LotFrontage'])\ntest_x = Utils.apply_log_trans(test_x,['LotFrontage'])","dc180602":"tot_tmp = pd.concat([train_x,train_y],axis=1,join=\"inner\")\nsns.relplot(x=\"LotFrontage\",y=\"SalePrice\",data=tot_tmp)","6ab7e03a":"# remove the outliers i.e LotFrontage>5.5\ntrain_x.drop(train_x[train_x['LotFrontage']>5.5].index,inplace=True)","5faa1090":"tot_tmp = pd.concat([train_x,train_y],axis=1,join=\"inner\")\nsns.relplot(x=\"LotFrontage\",y=\"SalePrice\",data=tot_tmp)","341236bd":"train_x[['LotArea','OverallQual','OverallCond', 'YearRemodAdd', 'MasVnrArea', '2ndFlrSF', 'LowQualFinSF']]\n# drop LowQualFinSF as 98% are zeros\n# retaining OverallQuall, OverallCond as it is and applying log transformation on LotArea, MasVnrArea, 2ndFlrSF\n","b45fcd76":"train_x = Utils.apply_log_trans(train_x, ['LotArea','MasVnrArea','2ndFlrSF'])\ntest_x = Utils.apply_log_trans(test_x, ['LotArea','MasVnrArea','2ndFlrSF'])","1ece4ba9":"tmp=pd.concat([train_x,train_y],join=\"inner\",axis=1)\nsns.catplot(x=\"YearRemodAdd\",y=\"SalePrice\",data=tmp,kind=\"box\")","0d03ce66":"train_x[['BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr','KitchenAbvGr', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'WoodDeckSF']]","5c88f6e2":"tmp = train_x.copy()\ndf = pd.DataFrame(tmp['BsmtFullBath']+tmp['BsmtHalfBath']+tmp['FullBath']+tmp['HalfBath'])\ntrdf = df.rename(columns={0:\"TotalBath\"})\ntmp = test_x.copy()\ndf = pd.DataFrame(tmp['BsmtFullBath']+tmp['BsmtHalfBath']+tmp['FullBath']+tmp['HalfBath'])\ntsdf = df.rename(columns={0:\"TotalBath\"})\ntrain_x = pd.concat([train_x,trdf],axis=1,join='inner')\ntest_x = pd.concat([test_x,tsdf],axis=1,join='inner')","f2a02303":"train_x.drop(['BsmtFullBath','BsmtHalfBath','FullBath','HalfBath'],axis=1,inplace=True)\ntest_x.drop(['BsmtFullBath','BsmtHalfBath','FullBath','HalfBath'],axis=1,inplace=True)","274a0738":"sns.relplot(x=\"WoodDeckSF\",y='SalePrice',data=tot_tmp)","cda7fed0":"train_x = Utils.apply_log_trans(train_x, ['WoodDeckSF'])\ntest_x = Utils.apply_log_trans(test_x, ['WoodDeckSF'])","d1918046":"tot_tmp = pd.concat([train_x,train_y],axis=1,join='inner')\nsns.relplot(x=\"WoodDeckSF\",y='SalePrice',data=tot_tmp)","ae37c5b6":"train_x[['OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea','MiscVal', 'MoSold', 'YrSold', 'TotalBsmtSF', 'GrLivArea', 'BsmtFinSF1',]]","237d66c2":"df = train_x.copy()\ntotdf = pd.DataFrame(df['OpenPorchSF']+df['EnclosedPorch']+df['3SsnPorch']+df['ScreenPorch'])\ntotdf.rename(columns={0:\"Tot_porchSF\"},inplace=True)\ntrain_x = pd.concat([df,totdf],axis=1,join='inner')\ntrain_x.drop(['OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch'],axis=1,inplace=True)\ndf = test_x.copy()\ntotdf = pd.DataFrame(df['OpenPorchSF']+df['EnclosedPorch']+df['3SsnPorch']+df['ScreenPorch'])\ntotdf.rename(columns={0:\"Tot_porchSF\"},inplace=True)\ntest_x = pd.concat([df,totdf],axis=1,join='inner')\ntest_x.drop(['OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch'],axis=1,inplace=True)","b5adbad3":"# sns.relplot(x=\"PoolArea\",y=\"SalePrice\",kind=\"line\",data=tot_tmp)\ntest_x[test_x['PoolArea']==0][\"PoolArea\"].count()","643dd856":"train_x.drop(['PoolArea'],axis=1,inplace=True)\ntest_x.drop(['PoolArea'],axis=1,inplace=True)","8963b210":"print(train_x[train_x['MiscVal']==0][\"MiscVal\"].count()\/1460)\n# sns.relplot(x=\"MiscVal\",y=\"SalePrice\",kind=\"line\",data=tot_tmp)","5d4aa89d":"train_x.drop(['MiscVal'],axis=1,inplace=True)\ntest_x.drop(['MiscVal'],axis=1,inplace=True)","56294f1f":"# lets check MoSold, YrSold correlation\nsns.catplot(x=\"MoSold\",y='SalePrice',data=tot_tmp,kind='box')","444db9fc":"sns.catplot(x=\"YrSold\",y='SalePrice',data=tot_tmp,kind='box')","073c0154":"train_x['GarageYrBlt'].unique()","530110f7":"test_x[test_x['GarageYrBlt'].isnull()]['GarageYrBlt']","d9fb1280":"test_data[test_data['GarageYrBlt'].isnull()]['GarageYrBlt']","9fd49695":"val = Utils.missing_vals(train_x,\"Id\")\nval.head(10)","cfa33d82":"tmp = train_data[['Neighborhood','YearBuilt','GarageYrBlt']]\ntmp2 = tmp[(tmp['YearBuilt'].notnull()) & (tmp['GarageYrBlt'].isnull())]\ntmp2","10443039":"for ind, row in tmp2.iterrows():\n    train_x.at[ind,'GarageYrBlt'] = row['YearBuilt']","2221810f":"train_x[['Id','GarageYrBlt']].count()","5230478e":"tmp = test_data[['Neighborhood','YearBuilt','GarageYrBlt']]\ntmp3 = tmp[(tmp['YearBuilt'].notnull()) & (tmp['GarageYrBlt'].isnull())]\ntmp3","7e93f637":"for ind, row in tmp3.iterrows():\n    test_x.at[ind,'GarageYrBlt'] = row['YearBuilt']","15c6c1d1":"test_x[test_x['GarageYrBlt'].isnull()]['GarageYrBlt']","5894211f":"tmp2 = pd.DataFrame(train_data.groupby('Neighborhood').agg({'LotFrontage':'mean'}))","851bc46a":"tmp2['LotFrontage']['Blmngtn']","b253b336":"cptr = train_x\nfor ind, row in cptr.iterrows():\n    if (math.isnan(cptr.at[ind,'LotFrontage'])):\n        val = train_data.at[ind,'Id']\n        val2 = pd.DataFrame(train_data.loc[train_data['Id']==val]['Neighborhood'])\n        cptr.at[ind,'LotFrontage'] = tmp2['LotFrontage'][val2.iloc[0]['Neighborhood']]","4a4fbe56":"train_x['LotFrontage'].count()","d3a842b7":"cptr = test_x\ntmp2 = pd.DataFrame(test_data.groupby('Neighborhood').agg({'LotFrontage':'mean'}))\nfor ind, row in cptr.iterrows():\n    if (math.isnan(cptr.at[ind,'LotFrontage'])):\n        val = test_data.at[ind,'Id']\n        val2 = pd.DataFrame(test_data.loc[test_data['Id']==val]['Neighborhood'])\n        cptr.at[ind,'LotFrontage'] = tmp2['LotFrontage'][val2.iloc[0]['Neighborhood']]","e3bdb098":"print (test_x['LotFrontage'].count())\nprint (test_x['Id'].count())","f54d949e":"not_inf = train_x[train_x['MasVnrArea']!=np.NINF]\nval = not_inf['MasVnrArea'].mean()\ntrain_x.loc[train_x.MasVnrArea==np.NINF,'MasVnrArea'] = val\n# train_x['MasVnrArea'].unique()","d969db52":"not_inf = train_x[train_x['MasVnrArea']!=np.NAN]\nval = not_inf['MasVnrArea'].mean()\ntrain_x.loc[train_x.MasVnrArea==np.NAN,'MasVnrArea'] = val","65c5fb2e":"# all_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\ntrain_x['MasVnrArea'] = train_x['MasVnrArea'].fillna(val)","a40faef0":"# use mean of train to fill test data too.\ntest_x['MasVnrArea'] = test_x['MasVnrArea'].fillna(val)","e9a25c99":"test_x.loc[test_x.MasVnrArea==np.NINF,'MasVnrArea'] = val","11ad0dde":"val = Utils.missing_vals(test_x,\"Id\")\nval.head(10)","cf1c2ce0":"test_x = test_x.replace({np.NINF:0})\ntrain_x = train_x.replace({np.NINF:0})\n","59945a46":"test_x['BsmtUnfSF'].mean()","0d0e5a00":"test_x['GarageCars'] = test_x['GarageCars'].fillna(test_x['GarageCars'].mode()[0])\ntest_x['BsmtUnfSF'] = test_x['BsmtUnfSF'].fillna(test_x['BsmtUnfSF'].mean())\ntest_x['BsmtFinSF2'] = test_x['BsmtFinSF2'].fillna(test_x['BsmtFinSF2'].mean())\ntest_x['BsmtFinSF1'] = test_x['BsmtFinSF1'].fillna(test_x['BsmtFinSF1'].mean())\ntest_x['TotalBsmtSF'] = test_x['TotalBsmtSF'].fillna(test_x['TotalBsmtSF'].mean())\ntest_x['TotalBath'] = test_x['TotalBath'].fillna(test_x['TotalBath'].mean())","1e0ec15f":"val = Utils.missing_vals(test_x,\"Id\")\nval.head(10)","e5775428":"print (train_x.shape)\nprint (test_x.shape)","52b0eb7b":"tr_cols = train_x.columns\nts_cols = test_x.columns\ndiff = [col for col in tr_cols if col not in ts_cols]\ndiff","2a209888":"# we still need to figure out what should we do with month and year","08864e26":"tmp=pd.concat([train_x,train_y],join=\"inner\",axis=1)\nsns.catplot(x=\"MoSold\",y=\"SalePrice\",data=tmp,kind=\"box\")","8d278ea1":"train_x.drop(['MoSold'],axis=1,inplace=True)\ntest_x.drop(['MoSold'],axis=1,inplace=True)","ab2d3391":"# lets see correlation between age of a age house sold and saleprice.\nage = pd.DataFrame(train_x['YrSold'] - train_x['GarageYrBlt'])\nage.rename({0:\"agelog\"},inplace=True,axis=1)\nage = Utils.apply_log_trans(age,['agelog'])\ntrain_x = pd.concat([train_x,age],axis=1,join='inner')\ntrain_x.drop(['YrSold','GarageYrBlt'],axis=1,inplace=True)","800a6f42":"age = pd.DataFrame(test_x['YrSold'] - test_x['GarageYrBlt'])\nage.rename({0:\"agelog\"},inplace=True,axis=1)\nage = Utils.apply_log_trans(age,['agelog'])\ntest_x = pd.concat([test_x,age],axis=1,join='inner')\ntest_x.drop(['YrSold','GarageYrBlt'],axis=1,inplace=True)","c6a5b5b9":"test_x = test_x.replace({np.NINF:0})\ntrain_x = train_x.replace({np.NINF:0})","d31ce102":"tmp=pd.concat([train_x,train_y],join=\"inner\",axis=1)\nsns.catplot(x=\"agelog\",y=\"SalePrice\",data=tmp)","2c79858d":"train_x.describe()","dee2beff":"# for col in train_x.columns():\n#     print (train_x)\na = train_x.max()\ncols = train_x.columns\nfor i,col in zip(a,cols) :\n    print (col,i)","d628cedd":"train_x[['Tot_porchSF','YearRemodAdd','LowQualFinSF']]","361bb11a":"train_x[train_x['LowQualFinSF']==0]['LowQualFinSF']","c3729ef1":"train_x.drop('LowQualFinSF',axis=1,inplace=True)\ntest_x.drop('LowQualFinSF',axis=1,inplace=True)","d591e7f9":"train_x.drop('YearRemodAdd',axis=1,inplace=True)\ntest_x.drop('YearRemodAdd',axis=1,inplace=True)","0c0b717f":"train_x = Utils.apply_log_trans(train_x, ['Tot_porchSF'])\ntest_x = Utils.apply_log_trans(test_x, ['Tot_porchSF'])","a6b4a8e8":"test_x = test_x.replace({np.NINF:0})\ntrain_x = train_x.replace({np.NINF:0})","dad03efc":"train_x.drop('Id',axis=1,inplace=True)\ntest_x.drop('Id',axis=1,inplace=True)","bba882e1":"print (train_x.shape)\nprint (train_y.shape)\nprint (test_x.shape)","e7551621":"# so drop those 2 rows from train_y\ntx_rows = train_x.index\nty_rows = train_y.index\nfor row in ty_rows:\n    if row not in tx_rows:\n        print (row)\n","ba806512":"train_y.drop([934,1298],inplace=True)\nprint (train_x.shape)\nprint (train_y.shape)\nprint (test_x.shape)","19348707":"types = train_x.dtypes.unique()\nprint (types)","db684bdb":"num_features = train_x.dtypes[train_x.dtypes != \"uint8\"].index\nfor val in num_features:\n    print(val)","127a3fa8":"from scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\nskewness = Utils.cal_skewness(train_x)\nskewness","be307b82":"skewness = skewness[abs(skewness) > 0.75]\nprint(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0])+\" But we are only transforming following columns\")\nprint (num_features)\n# but we apply transformation to numerical features only, because they are ordinal values.(above listed features)\n# cptr = train_x.copy()\n# from scipy.special import boxcox1p\n# lam = 0.05\n# for feat in num_features:\n#     train_x[feat] = boxcox1p(train_x[feat], lam)\n#     test_x[feat] = boxcox1p(test_x[feat], lam)\n# ylam = 0.001\n# train_y = boxcox1p(train_y,ylam)","cba147ec":"# boxcox coudn't transform saleprice to 0-3 range instead its capping at 10-15\n# so we are using standard scalar to all numerical and target features.\nfrom sklearn.preprocessing import StandardScaler\nxscal = StandardScaler()\ntrain_x[num_features] = xscal.fit_transform(train_x[num_features])\ntest_x[num_features] = xscal.transform(test_x[num_features])\n\nyscal = StandardScaler()\ntrain_y = pd.DataFrame(yscal.fit_transform(train_y))\n","b92770d4":"print (train_x.shape)\nprint (train_y.shape)\nprint (test_x.shape)","f5b8c471":"tr_cols = train_x.columns\nts_cols = test_x.columns\ndiff = list (set(tr_cols) - set(ts_cols))\nfor col in diff:\n    train_x.drop (col, inplace=True,axis=1)","874da6ef":"print (train_x.shape)\nprint (train_y.shape)\nprint (test_x.shape)","474c8bb8":"# from scipy import stats\n# from scipy.stats import norm, skew #for some statistics\nskewness = Utils.cal_skewness(train_x)\nskewness","f0b09ccb":"train_x[['OverallQual', 'OverallCond', 'BedroomAbvGr', 'KitchenAbvGr','Fireplaces', 'GarageCars', 'TotalBsmtSF', 'GrLivArea', 'BsmtFinSF1','BsmtFinSF2', 'BsmtUnfSF', 'LotFrontage', 'LotArea', 'MasVnrArea','2ndFlrSF', 'TotalBath', 'WoodDeckSF', 'agelog', 'Tot_porchSF']]","3efae3bc":"train_y","1d3f07bc":"n_folds = 5\n\ndef rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train_x.values)\n    rmse= np.sqrt(-cross_val_score(model, train_x.values, train_y, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)","cc98bdb7":"# this is a basic modelling technique.\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb\n\n\n\nmodel_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213,\n                             random_state =7, nthread = -1)\n\nmodel_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.05, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n\nscore = rmsle_cv(model_xgb)\nprint(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n\nscore = rmsle_cv(model_lgb)\nprint(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))","d6d3386e":"lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\nscore = rmsle_cv(lasso)\nprint(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","b5b51e71":"# lets get test results \nmodel = model_lgb.fit(train_x,train_y)\ny_test_pred = model.predict(test_x)\ny_test_pred","ca33864c":"# lets inverse transform y_test_prid\ny_test_pred = yscal.inverse_transform(y_test_pred)","dee783ee":"y_test_pred = pd.DataFrame(y_test_pred)","99ff1fff":"y_test_pred.rename({0:\"SalePrice\"},axis=1,inplace=True)","9c29b6ce":"y_test_pred","d3b89613":"yid = pd.DataFrame(test_data['Id'])\nyid","d4221f5e":"result = pd.concat([yid,y_test_pred],axis=1,join='inner')\nresult","65475aff":"result.to_csv(\"with_scalar_trans_all.csv\",index=False)","e43398e1":"# following are existing methods to do some stuff. I did these in a traditional way.\n# indexes = df1.loc[df1.Code.isin(df2.Code.values)].index\n# df1.at[indexes,'Value'] = df2['Value'].values\n\n# all_df[\"SimplOverallQual\"] = all_df.OverallQual.replace({1 : 1, 2 : 1, 3 : 1, 4 : 2, 5 : 2, 6 : 2, 7 : 3, 8 : 3, 9 : 3, 10 : 3})\n\n# qual_dict = {None: 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5}\n# all_df[\"ExterQual\"] = df[\"ExterQual\"].map(qual_dict).astype(int)\n\n","dda004ea":"Both in train,test data 5 columns lost most of the data. so, lets drop them.\n* PoolQC\n* MiscFeature\n* Alley\n* Fence\n* FireplaceQu","64e59049":"TODO: YearRemodAdd -> how to transform this?","054a0e94":"apply box cox transformation to highly skewed coumns (skewness >0.75)","7ac259d3":"In **continuous variables**, following are best correlated with saleprice<br>\n* OverallQual\t0.790982 \n* GrLivArea\t0.708624\n* GarageCars\t0.640409\n* GarageArea\t0.623431\n* TotalBsmtSF\t0.613581\n* 1stFlrSF\t0.605852\n* FullBath\t0.560664\n* TotRmsAbvGrd\t0.533723\n* YearBuilt\t0.522897\n* YearRemodAdd\t0.507101\n* GarageYrBlt\t0.486362\n* MasVnrArea\t0.477493\n* Fireplaces\t0.466929\n* EnclosedPorch\t-0.128578\n* KitchenAbvGr\t-0.135907","b3532418":"## Understanding of data","cf5813db":"drop GarageCond as it correlates too much with GarageQual","3b25700e":"First GarageyrBlt, as we know YearBlt and GarageYrBlt are highly correlated. we take missing values of GarageyrBlt from YearBlt.","f19e14ef":"TODO: lets add all the bathrooms in to one column and **check that column's importance using random forests at the end.**","f6b1a46f":"So, lets convert them to a rankings.","53f99283":"1. TODO: log trans TotalBsmtSF\n2. remove outlier 8.5, 12","bd050d38":"TODO: drop one of GarageYrBlt, YearBuilt (corr 0.82) [all drops are reference to corr between feature and target]","d906039e":"there is not much difference in saleprice w.r.t MoSold. so lets drop it.","cbf2c58d":"No corr and also it is not that beneficial to do onehot of MSSubClass","43405d97":"So, lets keep FullBath as it is.","134e38a3":"## cv and submission results\n\n### after log,boxcox trans to num features and target.\nXgboost score: 0.0233 (0.0014) <br>\nLGBM score: 0.0136 (0.0014) <br>\nLasso score: 0.0152 (0.0014) <br>\n\n### scalar trans to num features and target\n\nBut back transformation of (log(boxcox(target))) is very difficult and boxcox(target) is not sufficient. <br> So, we did scalar transformation but it is giving more rmse.<br>\nXgboost score: 0.3266 (0.0858)<br>\nLGBM score: 0.3334 (0.0789)<br>\nLasso score: 0.3615 (0.0577) <br>\nSubmission accuracy of this method is 0.1253 (rank: 1312;75% percentile) <br>\n\n### boxcox \n(scipy.special.inv_boxcox(y, 2.5))","e14677ea":"GarageQual is a rating, so we use ranking here.","53146e87":"INFO: 96% of MiscVal is 0. so ther will be no learning with this feature. Drop this feature.","0f8a7872":"# House price prediction \n\nThis is a very convoluted problem with 80 features to determining the SalePrice. <br>\nAs there are large number of dimentions, determining correct feature vector is a big deal for this data space. <br>\nSome of the techniques used in this solution -\n * log, boxcox, standard scaling techniques.\n * Various data transformation and engineering techniques are used. \n * correlation plots and line graphs are used to identify important features.\n * A suite of machine learning algorithms used to find best algorithm. \n     * xgb, lgb models are used. \n\n<br>\n\nSubmission score (error) with lgbm is 0.1253 (Top 25%)","773a957f":"INFO: As more than 98% of PoolArea values are zero. We are droping it.","c6111c19":"TODO: assign numerical values from left to right decreasing","2d0f982d":"TODO: equal wight to GarageFinish categories. -> replace with ordinal values","1336b273":"## lets fill missing values.","ae1ed832":"# Model learning\n\nWe use different models and check rms error value.","b3f711d0":"above all the _xxx values are categorical values which are not there in test but they are in train. So we can't do anything about it.","a5c617e9":"TODO: how to transform GarageYrBlt ??","a3e11660":"### predictor analysis\n\nAs there are a lot of predictors, we need to understand data from top down.<br>\nselect some best features and format them accordingly. <br>\ncombine some less useful features in to one. <br>\nfinally, drop unnessary features.","dff66f27":"LotFrontage is the avg value of the neighbourhood","5c17ea94":"# TODO: Highly correlated features\n* GrLivArea - TotalRmsAboveGrd (0.82)\n* GarageCars - GarageArea (0.88)\n* TotalBsmtSF - 1stFlSF  (0.83)\n* ","57af820d":"### target conclusion\n* values are too big -> std normalization (or)\n* right skew -> log transformation -> also brings the dist as normal\n","c88b2ff4":"TODO: lets remove two outliers GrLivArea -> (8.5,12),(8.5,12+)\napply log trans to GrLivArea"}}