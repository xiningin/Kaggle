{"cell_type":{"9ec24c48":"code","15cfbb9e":"code","7c700a90":"code","dfa793a3":"code","04d65284":"code","19625deb":"code","a6c5ef2d":"code","3dd19307":"code","cba7fce7":"code","1b7984c5":"code","ff41efe8":"code","64d8b817":"code","6f970233":"code","a0d21f6f":"code","d62d0e3f":"code","8fe889ac":"code","9ebcc047":"code","f884da20":"code","17873e62":"code","3c01f7e0":"code","939784da":"code","a76b2a37":"code","492517bf":"code","b2fc7335":"code","d3ba5f53":"code","78404eb2":"code","849ad14f":"markdown","e8c11909":"markdown","39d63c2d":"markdown","1309de7b":"markdown","a1648f44":"markdown","95b6ea7c":"markdown","fcc02fc5":"markdown","55fa7d3f":"markdown","6a85e708":"markdown","ca4532ac":"markdown","a0c83d4a":"markdown","cbd99c92":"markdown","51667544":"markdown","06156897":"markdown","d9a95780":"markdown","acdb2e50":"markdown","b5294731":"markdown","140b0983":"markdown","56ca6a74":"markdown","01ad4bb1":"markdown","2cf83896":"markdown","241ed28e":"markdown","0197403a":"markdown"},"source":{"9ec24c48":"# load the basic librairies\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom collections import Counter","15cfbb9e":"# load the data\ntrain_df = pd.read_csv('..\/input\/train.csv')\ntest_df = pd.read_csv('..\/input\/test.csv')\nsub = pd.read_csv('..\/input\/sample_submission.csv')","7c700a90":"train_df.head(3)","dfa793a3":"test_df.head(5)","04d65284":"# first feature: create a 'length' column\ntrain_df['length'] = train_df.text.apply(len)\ntest_df['length'] = test_df.ciphertext.apply(len)\n\n\n# filter the test dataframes by cypher level\ndf_level_1 = test_df[test_df.difficulty==1].copy()\ndf_level_2 = test_df[test_df.difficulty==2].copy()\ndf_level_3 = test_df[test_df.difficulty==3].copy()\ndf_level_4 = test_df[test_df.difficulty==4].copy()\n\ndf_level_1.head(3)","19625deb":"print('train_df.shape:', train_df.shape, '\\ntest_df.shape:', test_df.shape)","a6c5ef2d":"for i in range(5):\n    print(train_df.text[i], '\\n')","3dd19307":"plain_char_cntr = Counter(''.join(train_df['text'].values))\nplain_stats_train = pd.DataFrame([[x[0], x[1]] for x in plain_char_cntr.items()], columns=['Letter', 'Frequency'])\nplain_stats_train = plain_stats_train.sort_values(by='Frequency', ascending=False)\n\nf, ax = plt.subplots(figsize=(15, 5))\nplt.bar(np.array(range(len(plain_stats_train))) + 0.5, plain_stats_train['Frequency'].values)\nplt.xticks(np.array(range(len(plain_stats_train))) + 0.5, plain_stats_train['Letter'].values)\nplt.show()","cba7fce7":"for i in range(20):\n    try:\n        print(df_level_1.ciphertext[i], '\\n')\n    except KeyError:\n        pass","1b7984c5":"plain_char_cntr = Counter(''.join(df_level_1['ciphertext'].values))\nplain_stats_train = pd.DataFrame([[x[0], x[1]] for x in plain_char_cntr.items()], columns=['Letter', 'Frequency'])\nplain_stats_train = plain_stats_train.sort_values(by='Frequency', ascending=False)\n\nf, ax = plt.subplots(figsize=(15, 5))\nplt.bar(np.array(range(len(plain_stats_train))) + 0.5, plain_stats_train['Frequency'].values)\nplt.xticks(np.array(range(len(plain_stats_train))) + 0.5, plain_stats_train['Letter'].values)\nplt.show()","ff41efe8":"for i in range(30):\n    try:\n        print(df_level_2.ciphertext[i], '\\n')\n    except KeyError:\n        pass","64d8b817":"plain_char_cntr = Counter(''.join(df_level_2['ciphertext'].values))\nplain_stats_train = pd.DataFrame([[x[0], x[1]] for x in plain_char_cntr.items()], columns=['Letter', 'Frequency'])\nplain_stats_train = plain_stats_train.sort_values(by='Frequency', ascending=False)\n\nf, ax = plt.subplots(figsize=(15, 5))\nplt.bar(np.array(range(len(plain_stats_train))) + 0.5, plain_stats_train['Frequency'].values)\nplt.xticks(np.array(range(len(plain_stats_train))) + 0.5, plain_stats_train['Letter'].values)\nplt.show()","6f970233":"for i in range(8):\n    try:\n        print(df_level_3.ciphertext[i], '\\n')\n    except KeyError:\n        pass","a0d21f6f":"plain_char_cntr = Counter(''.join(df_level_3['ciphertext'].values))\nplain_stats_train = pd.DataFrame([[x[0], x[1]] for x in plain_char_cntr.items()], columns=['Letter', 'Frequency'])\nplain_stats_train = plain_stats_train.sort_values(by='Frequency', ascending=False)\n\nf, ax = plt.subplots(figsize=(15, 5))\nplt.bar(np.array(range(len(plain_stats_train))) + 0.5, plain_stats_train['Frequency'].values)\nplt.xticks(np.array(range(len(plain_stats_train))) + 0.5, plain_stats_train['Letter'].values)\nplt.show()","d62d0e3f":"for i in range(3):\n    try:\n        print(df_level_4.ciphertext[i], '\\n')\n    except KeyError:\n        pass","8fe889ac":"plain_char_cntr = Counter(''.join(df_level_4['ciphertext'].values))\nplain_stats_train = pd.DataFrame([[x[0], x[1]] for x in plain_char_cntr.items()], columns=['Letter', 'Frequency'])\nplain_stats_train = plain_stats_train.sort_values(by='Frequency', ascending=False)\n\nf, ax = plt.subplots(figsize=(15, 5))\nplt.bar(np.array(range(len(plain_stats_train))) + 0.5, plain_stats_train['Frequency'].values)\nplt.xticks(np.array(range(len(plain_stats_train))) + 0.5, plain_stats_train['Letter'].values)\nplt.show()","9ebcc047":"plain_char_cntr = Counter(''.join(train_df['text'].values))\nplain_stats_train = pd.DataFrame([[x[0], x[1]] for x in plain_char_cntr.items()], columns=['Letter', 'Frequency'])\nplain_stats_train = plain_stats_train.sort_values(by='Frequency', ascending=False)","f884da20":"plain_char_test = Counter(''.join(df_level_1['ciphertext'].values))\nplain_stats_test = pd.DataFrame([[x[0], x[1]] for x in plain_char_test.items()], columns=['Letter', 'Frequency'])\nplain_stats_test = plain_stats_test.sort_values(by='Frequency', ascending=False)\nplain_stats_test['Frequency'] -= 21130 # to remove the influence of random padding caracters","17873e62":"f, ax = plt.subplots(figsize=(15, 5))\nplt.bar(np.array(range(len(plain_stats_test))) + 0.5, plain_stats_test['Frequency'].values)\nplt.bar(np.array(range(len(plain_stats_train))) + 0.5, plain_stats_train['Frequency'].values\/\/4, alpha=.5,color='green')\nplt.xticks(np.array(range(len(plain_stats_test))) + 0.5, plain_stats_test['Letter'].values)\nplt.show()","3c01f7e0":"# first trick: use the length of some text pieces to understand the first cypher level\ndf_level_1.length.sort_values(ascending=False).head()\n\n# we can see that 1 piece of text is of len 500, meaning that its original length is between \n# 401 and 500 (recall that every original piece of text is padded with random caracters to\n# the next hundred)","939784da":"df_level_1.length.describe([.999])","a76b2a37":"# and here is the corresponding text\ndf_level_1.loc[45272].ciphertext","492517bf":"# then we look in the training data to find the passage with the corresponding length\nmatching_pieces = train_df[(train_df.length>=401) & (train_df.length<=500)]\nmatching_pieces\n# only three unciphered texts length are in the interval: let's print them","b2fc7335":"matching_pieces.text.values","d3ba5f53":"print('Unciphered text:\\n', train_df.loc[13862].text, '\\n\\nCiphered text (level 1):\\n', \n      df_level_1.loc[45272].ciphertext)","78404eb2":"# Let's do the same thing for a second piece of text now.\n# With the same procedure, we get a second match:\nprint(train_df.loc[6938].text, '\\n\\n', df_level_1.loc[95019].ciphertext)","849ad14f":"Seems like it's the same repartition as level 1!","e8c11909":"### Ciphered text level 2","39d63c2d":"Compared to the previous level, we see that there are far less differences in terms of caracters frequence that in plain English...","1309de7b":"We can see that the crushing majority of samples are 100 caracters long, meaning that their length is between 1 and 100 and they're padded to the next hundred. But even if long samples (> 100 caracters) are rare, they will be very interesting!","a1648f44":"### One basic trick","95b6ea7c":"We can see that there is **not** a match between letters, meaning that there is no \ndirect correspondance between caracters. We have to try something else. ","fcc02fc5":"### Frequency Analysis","55fa7d3f":"### Ciphered text level 1","6a85e708":"The most natural thing to do now is to look try to find a match between caracters, ie an \"a\" becomes an \"s\", a \"b\" becomes a \"k\" etc.\nThis can be done by frequency analysis, and that's what wa gonna do now.","ca4532ac":"Only digits, but nothing to add...","a0c83d4a":"The most frequent letters in English are 'e', 't', 'a', 'o', 'n', 'i' and 's' so that's quite consistant!","cbd99c92":"## Imports and data loading","51667544":"### Ciphered text level 3","06156897":"#### If you look carefully to the spaces, dots, columns etc., you will soon understand that our ciphered text matches the first plain text: we found our first match. Now let's try to understand some properties of the first cipher level","d9a95780":"### Original text","acdb2e50":"### Ciphered text level 4","b5294731":"### To be familiar with the data, let's look at it first!","140b0983":"## Sort of Exploratory Data Analysis","56ca6a74":"__It is now obvious that 1st level cipher preserves the punctuation and the case \n(uppercase and lowercase match), which is already a good hint.\nWhat is also striking is that the length of the words is preserved.__\n\n__The 1st difficulty arises tho: words are not ciphered the same way: 'and' is either 'edc' or 'lrs'\nso its is not a basic matching between caracters...__","01ad4bb1":"#### Hi everyone! This kernel aims at showing you a basic approach to our ciphering problem. It shows my way of exploring solutions and I hope it will help you through your discovery of our dataset.","2cf83896":"## Try to decypher the first level","241ed28e":"All caracters seem to be roughly as frequent (except the '='), but again not many things to say","0197403a":"So this is another example of two matching passages. I'll now let you find other tricks, and\nI'll post the follow-up soon with the main trick for cipher 1! \nDon't forget to upvote if you find this kernel useful! ;)"}}