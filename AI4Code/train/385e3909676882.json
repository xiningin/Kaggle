{"cell_type":{"fa3d21d8":"code","ff3962b5":"code","a21b85e7":"code","1865b85e":"code","102b9fbf":"code","167a5e45":"code","d3642674":"code","bdc51ef4":"code","8f655b8d":"code","bab7ce95":"code","d3610bec":"code","b7d6c85a":"code","3171d508":"code","a79d91ac":"code","29742a96":"code","236bed26":"code","5d1e1034":"code","1eda1ee9":"code","99488165":"code","e796921f":"code","3de11af5":"code","438875c5":"code","b8f5b916":"code","6b01b5d9":"code","ebf60667":"code","b6c89a22":"code","0ba1bee3":"code","607f4361":"code","a68c759e":"code","36b25d46":"code","81e1e2e8":"code","d0527a24":"code","252716fc":"markdown","96082ef0":"markdown"},"source":{"fa3d21d8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ff3962b5":"titanic_train = pd.read_csv('..\/input\/titanic\/train.csv', index_col = 'PassengerId')\ntitanic_test = pd.read_csv('..\/input\/titanic\/test.csv', index_col = 'PassengerId')","a21b85e7":"titanic_train","1865b85e":"titanic_train.isna().sum()","102b9fbf":"len(titanic_train.Name.unique())","167a5e45":"titanic_train.Survived.value_counts()","d3642674":"for col in titanic_train.columns:\n    print(col, len(titanic_train[col].unique()))","bdc51ef4":"titanic_train.drop(columns=['Name', 'Cabin', 'Ticket'], inplace=True)\ntitanic_train","8f655b8d":"age_mean = titanic_train.Age.mean()\ntitanic_train.Age.fillna(age_mean, inplace=True)\ntitanic_train.isna().sum()","bab7ce95":"from sklearn.preprocessing import LabelEncoder\n\n\nsex_le =  LabelEncoder() \ntitanic_train['Sex'] = sex_le.fit_transform(titanic_train['Sex'].astype(str))\n\nembarked_le =  LabelEncoder() \ntitanic_train['Embarked'] = embarked_le.fit_transform(titanic_train['Embarked'].astype(str))","d3610bec":"titanic_train.Sex","b7d6c85a":"titanic_train.Embarked","3171d508":"target_column = titanic_train.Survived\ny = target_column\nX = titanic_train.drop(columns=['Survived'])\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y)","a79d91ac":"para = list(range(100, 1001, 100))\nprint(para)","29742a96":"from sklearn.metrics import classification_report, accuracy_score, f1_score\nfrom xgboost import  XGBClassifier\n\nresults = {}\nfor n in para:\n    print('para=', n)\n    titanic_model = XGBClassifier(n_estimators=n, learning_rate=0.05, n_jobs=4)\n    titanic_model.fit(X_train, y_train, early_stopping_rounds=20,\n              eval_set=[(X_test, y_test)], \n             verbose=False)\n    preds = titanic_model.predict(X_test)\n    accu = accuracy_score(y_true=y_test, y_pred=preds)\n    f1 = f1_score(y_true=y_test, y_pred=preds, average='micro')\n    print(classification_report(y_true=y_test, y_pred=preds))\n    print('--------------------------')\n    results[n] = f1","236bed26":"best_para = max(results, key=results.get)\nprint('best para', best_para)\nprint('value', results[best_para])","5d1e1034":"titanic_test","1eda1ee9":"titanic_test.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True)\ntitanic_test","99488165":"titanic_test['Sex'] = sex_le.transform(titanic_test['Sex'].astype(str))\ntitanic_test['Embarked'] = embarked_le.transform(titanic_test['Embarked'].astype(str))","e796921f":"titanic_test","3de11af5":"titanic_final_model = XGBClassifier(n_estimators=best_para, learning_rate=0.05, n_jobs=4)\ntitanic_final_model.fit(X, y)","438875c5":"titanic_test.isna().sum()","b8f5b916":"titanic_test.Age.fillna(int(age_mean), inplace=True)\ntitanic_test.Fare.fillna(int(titanic_train.Fare.mean()), inplace=True)\ntitanic_train","6b01b5d9":"preds = titanic_final_model.predict(titanic_test)","ebf60667":"preds","b6c89a22":"preds[:5]","0ba1bee3":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score\nresults = {}\nfor n in para:\n    print('para=', n)\n    model = RandomForestClassifier(n_estimators=n)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    accu = accuracy_score(y_true=y_test, y_pred=preds)\n    f1 = f1_score(y_true=y_test, y_pred=preds, average='micro')\n    print(classification_report(y_true=y_test, y_pred=preds))\n    print('--------------------------')\n    results[n] = f1","607f4361":"best_para = max(results, key=results.get)\nprint('best para', best_para)\nprint('value', results[best_para])","a68c759e":"final_model = RandomForestClassifier(n_estimators=best_para)\nfinal_model.fit(X, y)","36b25d46":"predictions = final_model.predict(titanic_test)","81e1e2e8":"predictions","d0527a24":"test_out = pd.DataFrame({\n    'PassengerId': titanic_test.index, \n    'Survived': preds\n})\ntest_out.to_csv('submission.csv', index=False)","252716fc":"# Using RandomForest","96082ef0":"# Using XGBoost"}}