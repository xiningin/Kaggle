{"cell_type":{"e334a7c7":"code","e0ecf35d":"code","b4434363":"code","4cbd5098":"code","8af3ed01":"code","71417a31":"code","bb9fa90e":"code","a543aa7b":"code","7e6ccf2b":"code","8ce70566":"code","4125bcf9":"code","c1c64014":"code","41e7f794":"code","d22285df":"code","b06a8351":"code","2790c227":"code","5ea73952":"code","ab99334b":"code","c6465e0d":"code","d4ea8902":"code","0db9764f":"code","a4bdf1ab":"code","ebdfa7a9":"code","243182d1":"code","41004ea6":"code","234dadfb":"code","d398637f":"code","d9e1db9e":"code","ed782aa0":"code","12aeacb8":"markdown","1407e0da":"markdown","9f858684":"markdown","1c11a186":"markdown","0805024c":"markdown","6e6e21ca":"markdown","d6ac8cf9":"markdown","a4b460da":"markdown","639a874d":"markdown","58017f51":"markdown"},"source":{"e334a7c7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e0ecf35d":"df_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","b4434363":"df_train","4cbd5098":"df_train.drop(['Name','Ticket'], axis = 1,inplace=True)\ndf_test.drop(['Name','Ticket'], axis = 1,inplace=True)","8af3ed01":"df_train.isnull().sum()","71417a31":"df_train[['Age']].boxplot()","bb9fa90e":"df_train.Age.mean(),df_train.Age.median()","a543aa7b":"df_train['Age'].fillna(value=29,inplace=True)\t# \u5bf9'col'\u5217\u7a7a\u503c\u8fdb\u884c'string'\u586b\u5145\ndf_test['Age'].fillna(value=29,inplace=True)\t# \u5bf9'col'\u5217\u7a7a\u503c\u8fdb\u884c'string'\u586b\u5145","7e6ccf2b":"df_train.Embarked.value_counts()","8ce70566":"df_train['Embarked'].fillna(value='S',inplace=True)\t# \u5bf9'col'\u5217\u7a7a\u503c\u8fdb\u884c'string'\u586b\u5145\ndf_test['Embarked'].fillna(value='S',inplace=True)\t# \u5bf9'col'\u5217\u7a7a\u503c\u8fdb\u884c'string'\u586b\u5145","4125bcf9":"df_train.Cabin.values","c1c64014":"df_train.Cabin.fillna(value='N',inplace=True)\ndf_train.Cabin = df_train.Cabin.str[:1]\n\ndf_test.Cabin.fillna(value='N',inplace=True)\ndf_test.Cabin = df_train.Cabin.str[:1]","41e7f794":"df_test.isnull().sum()","d22285df":"df_train.Fare.mean()","b06a8351":"df_test.Fare.fillna(value=32.2,inplace=True)","2790c227":"df_train.info()","5ea73952":"df_train['Pclass'] = df_train['Pclass'].astype(str)\t\ndf_test['Pclass'] = df_test['Pclass'].astype(str)\t","ab99334b":"df_train.info()","c6465e0d":"df_train = pd.get_dummies(df_train)\ndf_test = pd.get_dummies(df_test)","d4ea8902":"df_train.info()","0db9764f":"col_X = ['Age', 'SibSp', 'Parch', 'Fare', 'Pclass_1',\n       'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male', 'Cabin_A', 'Cabin_B',\n       'Cabin_C', 'Cabin_D', 'Cabin_E', 'Cabin_F', 'Cabin_G', 'Cabin_N',\n       'Cabin_T', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\ncol_y = ['Survived']","a4bdf1ab":"from sklearn.model_selection import train_test_split    \ntrain_1,train_2 = train_test_split(df_train,test_size=0.25)   ","ebdfa7a9":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC,NuSVC\nfrom sklearn.ensemble import AdaBoostClassifier,BaggingClassifier,RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.naive_bayes import GaussianNB,BernoulliNB,CategoricalNB,MultinomialNB","243182d1":"aa = pd.DataFrame()\nfor ii in range(100):\n    train_1,train_2 = train_test_split(df_train,test_size=0.25)  \n    mode = [DecisionTreeClassifier(),       # \u51b3\u7b56\u6811 0\n            SVC(kernel=\"linear\", C=0.025),SVC(gamma=2, C=1),NuSVC(),    # SVM:1-3\n            AdaBoostClassifier(n_estimators=100),BaggingClassifier(),RandomForestClassifier(n_estimators=100),      # \u51b3\u7b56\u68ee\u67974-6\n            KNeighborsClassifier(),GaussianProcessClassifier(),                     # \u8fd1\u90bb7-8\n            GaussianNB(),BernoulliNB() ,MultinomialNB()             # \u8d1d\u53f6\u65af9-11\n            ]\n\n    for jj in range(len(mode)):\n        mode[jj].fit( train_1[col_X],train_1[col_y].values.ravel() )\n        aa = aa.append( [ [ ii, jj, mode[jj].score( train_1[col_X],train_1[col_y] ),    mode[jj].score( train_2[col_X],train_2[col_y] )] ],ignore_index=True)\n        \naa.groupby(by=[1]).mean().sort_values(by=[3],ascending=False)","41004ea6":"aa = pd.DataFrame()\nfor ii in range(100):\n    train_1,train_2 = train_test_split(df_train,test_size=0.25)   \n    mode_ada = [RandomForestClassifier(criterion='gini',n_estimators=50),   \n                RandomForestClassifier(criterion='gini',n_estimators=100),\n                RandomForestClassifier(criterion='gini',n_estimators=200),\n                RandomForestClassifier(criterion='gini',n_estimators=400),\n                RandomForestClassifier(criterion='entropy',n_estimators=50),\n                RandomForestClassifier(criterion='entropy',n_estimators=100),\n                RandomForestClassifier(criterion='entropy',n_estimators=200),\n                RandomForestClassifier(criterion='entropy',n_estimators=400),\n                ]\n\n    for jj in range(len(mode_ada)):\n        mode_ada[jj].fit( train_1[col_X],train_1[col_y].values.ravel() )\n        aa = aa.append( [ [ ii, jj, mode_ada[jj].score( train_1[col_X],train_1[col_y] ),    mode_ada[jj].score( train_2[col_X],train_2[col_y] )] ],ignore_index=True)\n        \naa.groupby(by=[1]).mean().sort_values(by=[3],ascending=False)","234dadfb":"aa = pd.DataFrame()\nfor ii in range(100):\n    train_1,train_2 = train_test_split(df_train,test_size=0.25)   # \u5c06\u6570\u636e\u5206\u4e3a75%\u8bad\u7ec3\u96c6\u548c25%\u6d4b\u8bd5\u96c6\n    mode_ada = [RandomForestClassifier(criterion='entropy',n_estimators=200,max_depth=5),\n                RandomForestClassifier(criterion='entropy',n_estimators=200,max_depth=10),\n                RandomForestClassifier(criterion='entropy',n_estimators=200,max_depth=15),\n                RandomForestClassifier(criterion='entropy',n_estimators=200,max_depth=20),\n                RandomForestClassifier(criterion='entropy',n_estimators=200,max_depth=25),\n                RandomForestClassifier(criterion='entropy',n_estimators=200,max_depth=30),\n                RandomForestClassifier(criterion='entropy',n_estimators=200,max_depth=35),\n                RandomForestClassifier(criterion='entropy',n_estimators=200,max_depth=40),\n                RandomForestClassifier(criterion='entropy',n_estimators=200,max_depth=45),\n                RandomForestClassifier(criterion='entropy',n_estimators=200,max_depth=50),\n                ]\n\n    for jj in range(len(mode_ada)):\n        mode_ada[jj].fit( train_1[col_X],train_1[col_y].values.ravel() )\n        aa = aa.append( [ [ ii, jj, mode_ada[jj].score( train_1[col_X],train_1[col_y] ),    mode_ada[jj].score( train_2[col_X],train_2[col_y] )] ],ignore_index=True)\naa.groupby(by=[1]).mean().sort_values(by=[3],ascending=False)","d398637f":"mode = RandomForestClassifier(criterion='entropy',n_estimators=200,max_depth=10)\nmode.fit( df_train[col_X],df_train[col_y].values.ravel() )","d9e1db9e":"df_test['Survived'] = mode.predict( df_test[col_X] )","ed782aa0":"df_test[ ['PassengerId','Survived'] ].to_csv('submission.csv',index=False)","12aeacb8":"# RandomForestClassifier is best(\u968f\u673a\u68ee\u6797\u6700\u9ad8\u5206,\u5355\u72ec\u8fdb\u884c\u8c03\u53c2)","1407e0da":"# Try all available models to see which has high accuracy. Test all model data at random for 100 times and take the average(\u5404\u79cd\u53ef\u7528\u7684\u6a21\u578b\u90fd\u8bd5\u8bd5,\u770b\u770b\u54ea\u4e2a\u51c6\u786e\u7387\u9ad8,\u5404\u79cd\u6a21\u578b\u6570\u636e\u968f\u673a\u6d4b\u8bd5100\u6b21,\u53d6\u5e73\u5747)","9f858684":"# RandomForestClassifier(criterion='entropy',n_estimators=200,max_depth=10) is the best","1c11a186":"RandomForestClassifier(criterion='entropy',n_estimators=200) is best\n\nnow,test max_depth","0805024c":"# one hot code (\u72ec\u70ed\u7f16\u7801)","6e6e21ca":"# Missing value processing(\u7f3a\u5931\u503c\u5904\u7406)","d6ac8cf9":"Use the initial letter of bin according to the data, and replace the null value with 'N'\n\n\u6839\u636e\u6570\u636e\u4f7f\u7528Cabin\u7684\u9996\u5b57\u6bcd\u5373\u53ef,\u7a7a\u503c\u7528N\u66ff\u4ee3","a4b460da":"# train split(\u62c6\u5206\u8bad\u7ec3\u96c6,25%\u7528\u4e8e\u6d4b\u8bd5)","639a874d":"# Delete useless columns(\u5220\u9664\u65e0\u7528\u7684\u5217)","58017f51":"# Data type adjustment(\u6570\u636e\u7c7b\u578b\u8c03\u6574)"}}