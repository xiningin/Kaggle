{"cell_type":{"e8453135":"code","42c93803":"code","c4104e8f":"code","e5d6f073":"code","6479a013":"code","d687621c":"code","cd088b86":"code","36eeb006":"code","0efe451b":"code","2432d8e0":"code","5ebee839":"code","e582e101":"code","77285076":"code","ae3de08d":"code","b6cd5d59":"code","74897a63":"code","953bfaa8":"code","460a611d":"code","f85e9200":"code","ebf5407c":"code","0278276d":"code","0dc5d26e":"code","470c6913":"code","82063e46":"code","6e88a55c":"code","1b7df269":"code","4d114ab8":"code","4e6f397a":"markdown","a3342c0e":"markdown","e8b9b9b6":"markdown","321086c9":"markdown","140c4ce2":"markdown","efafbd42":"markdown","3c6fdda9":"markdown","2bac17ba":"markdown","e70c4aba":"markdown","dc07810a":"markdown","59833cfe":"markdown","a6fc48d7":"markdown","4f3cfb82":"markdown","c5bcbc99":"markdown","649ce2fd":"markdown"},"source":{"e8453135":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","42c93803":"#importing necessary packages :\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport glob\nimport warnings\n","c4104e8f":"districts=pd.read_csv('..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv')\nproducts=pd.read_csv('..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv')","e5d6f073":"path='..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data'\n# joining all files and returning as list - joined_list = glob.glob(os.path.join(path,'*.csv'))\n\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data'):\n    for filename in filenames:\n        engagement_files = list(glob.glob(os.path.join(dirname,'*.*')))\n\nengagement = pd.DataFrame()\nfor file in engagement_files:\n    district_id = file[79:83]\n    engagement_file = pd.read_csv(file)\n    engagement_file['id'] = district_id\n    engagement = pd.concat([engagement, engagement_file], axis=0).reset_index(drop=True)\n    ","6479a013":"#Converted the returned list into a DataFrame.\nengagement['id']=engagement['id'].astype('int64')\n\n#Mapping and finding out the percentage of various communities mentioned in the dataset.\nmapping_1 = {\n    '[0, 0.2[': '0%-20%',\n    '[0.2, 0.4[': '20%-40%',\n    '[0.4, 0.6[': '40%-60%',\n    '[0.6, 0.8[': '60%-80%',\n    '[0.8, 1[': '80%-100%'}\n\nmapping_2 = {\n    '[4000, 6000[': '4000-6000',\n    '[6000, 8000[': '6000-8000',\n    '[8000, 10000[': '8000-10000',\n    '[10000, 12000[': '10000-12000',\n    '[12000, 14000[': '12000-14000',\n    '[14000, 16000[': '14000-16000',\n    '[16000, 18000[': '16000-18000',\n    '[18000, 20000[': '18000-20000',\n    '[20000, 22000[': '20000-22000',\n    '[22000, 24000[': '22000-24000',\n    '[32000, 34000[': '32000-34000'}\n\nmapping_3 =mapping_3 = {\n    '[0.18, 1[': '18%-100%',\n    '[1, 2[': '100%-200%'\n}\ndistricts['pct_black\/hispanic'] = districts['pct_black\/hispanic'].map(mapping_1)\ndistricts['pct_free\/reduced'] = districts['pct_free\/reduced'].map(mapping_1)\ndistricts['county_connections_ratio'] = districts['county_connections_ratio'].map(mapping_3)\ndistricts['pp_total_raw'] = districts['pp_total_raw'].map(mapping_2)\ndistricts.head()","d687621c":"districts['district_id']=districts['district_id'].astype('int64')","cd088b86":"products[['Category','Sub-Category']]=products['Primary Essential Function'].str.split('-',n=1,expand=True)\n\nproducts.head()","36eeb006":"products['LP ID']=products['LP ID'].astype('float64')","0efe451b":"print(engagement.isna().sum())","2432d8e0":"print(f'Number of rows {engagement.shape[0]}\\nNumber of columns {engagement.shape[1]}\\nNumber of missing values {sum(engagement.isna().sum())} ')","5ebee839":"engagement.describe()","e582e101":"districts.head()","77285076":"print(f'Number of rows {districts.shape[0]}\\nNumber of columns {districts.shape[1]}\\nNumber of missing values {sum(districts.isna().sum())} ')\n","ae3de08d":"print(districts.isna().sum())","b6cd5d59":"products.head()","74897a63":"print(f'Number of rows {products.shape[0]}\\nNumber of columns {products.shape[1]}\\nNumber of missing values {sum(products.isna().sum())} ')","953bfaa8":"print(products.isna().sum())","460a611d":"print(\"shape of products dataframe : \",shape(products))\nprint(\"shape of districts dataframe : \",shape(districts))\nprint(\"shape ofengagement dataframe : \",shape(engagement))","f85e9200":"data=engagement.copy()\ndata['id']=data['id'].astype('int64')\ndata=data.merge(products,left_on='lp_id',right_on='LP ID',how='left')\ndata=data.merge(districts,left_on='id',right_on='district_id',how='left')\ndata['time']=pd.to_datetime(data['time'])\n\nengagement\nproducts\ndistricts","ebf5407c":"data = data.drop('district_id', axis=1)\ndata = data.drop('LP ID', axis=1)\ndata=data.drop('Primary Essential Function',axis=1)\ndata.head()","0278276d":"print(f'Number of rows {data.shape[0]}\\nNumber of columns {data.shape[1]}\\nNumber of missing values {sum(data.isna().sum())}')\n\nprint(f'Number of missing values in each column{data.isna().sum()}')\n\n","0dc5d26e":"def show_values(axs, orient=\"v\", space=.01):\n    def _single(ax):\n        if orient == \"v\":\n            for p in ax.patches:\n                _x = p.get_x() + p.get_width() \/ 2\n                _y = p.get_y() + p.get_height() + (p.get_height()*0.01)\n                value = '{:.1f}'.format(p.get_height())\n                ax.text(_x, _y, value, ha=\"center\") \n        elif orient == \"h\":\n            for p in ax.patches:\n                _x = p.get_x() + p.get_width() + float(space)\n                _y = p.get_y() + p.get_height() - (p.get_height()*0.5)\n                value = '{:.1f}'.format(p.get_width())\n                ax.text(_x, _y, value, ha=\"left\")\n\n    if isinstance(axs, np.ndarray):\n        for idx, ax in np.ndenumerate(axs):\n            _single(ax)\n    else:\n        _single(axs)","470c6913":"products_temp=pd.DataFrame(data.groupby('Product Name',dropna=False)['engagement_index'].sum()\/1000000).reset_index()\nproducts_temp.columns=['Product Name','Amount']\nproducts_temp=products_temp.sort_values('Amount',ascending=False)\nproducts_temp=products_temp[0:10]\nproducts_temp=products_temp.fillna('Unknown')\n\nplt.figure(figsize=(12,5))\ng1=sns.barplot(x=products_temp['Product Name'],y=products_temp['Amount'])\nplt.xlabel('Products')\nplt.ylabel('Page load (million)')\nplt.title('Top 10 Products')\nplt.tight_layout()","82063e46":"providers_temp=pd.DataFrame(data.groupby('Provider\/Company Name',dropna=False)['engagement_index'].sum()\/1000000).reset_index()\nproviders_temp.columns=['Provider\/Company Name','Amount']\nproviders_temp=providers_temp.sort_values('Amount',ascending=False)\nproviders_temp=providers_temp[0:10]\nproviders_temp=providers_temp.fillna('Unknown')\n#plot\nplt.figure(figsize=(15,5))\ng2=sns.barplot(x=providers_temp['Amount'],y=providers_temp['Provider\/Company Name'],orient='h')\nplt.ylabel('Providers')\nplt.xlabel('Page load (million)')\nplt.title('Top 10 Providers')\nplt.tight_layout()\nshow_values(g2, \"h\", space=0)","6e88a55c":"category_temp=pd.DataFrame(data.groupby('Category')['engagement_index'].sum()\/1000000).reset_index()\ncategory_temp.columns=['Category','Amount']\ncategory_temp=category_temp.sort_values('Amount',ascending=False)\ncategory_temp=category_temp[0:10]\ncategory_temp=category_temp.fillna('Unknown')\n# category plot \nfig = plt.figure()\naxes1 = fig.add_axes([0.1, 0.1, 0.8, 0.8])\naxes1.plot(category_temp['Category'],category_temp['Amount'],'g--')\naxes1.set_xlabel('Category')\naxes1.set_ylabel('Page load (million)')\naxes1.set_title('Category and Page Load')\n\n# Sub-Category and page load\nsector_temp=pd.DataFrame(data.groupby('Sector(s)')['engagement_index'].sum()\/1000000).reset_index()\nsector_temp.columns=['Sector','Amount']\nsector_temp=sector_temp.sort_values('Amount',ascending=False)\nsector_temp=sector_temp[0:10]\nsector_temp=sector_temp.fillna('Unknown')\n\n#Sub Category plot\naxes2= fig.add_axes([1.1, 0.1, 0.8, 0.8])\naxes2.plot(sector_temp['Sector'],sector_temp['Amount'],'r*-')\naxes2.set_xlabel('Sectors ')\naxes2.set_ylabel('Page load (million)')\naxes2.set_title('Sectors and page load')\naxes2.set_xticklabels(['PreK-12;\\nHigher Ed;\\nCorporate', 'Unknown', 'PreK-12', \n                     'PreK-12;\\nHigher Ed', 'Corporate', 'Higher Ed;\\nCorporate'])","1b7df269":"#Page load by Locale\nlocale_temp=pd.DataFrame(data.groupby('locale',dropna=False)['engagement_index'].sum()\/1000000).reset_index()\nlocale_temp.columns=['locale','Amount']\nlocale_temp=locale_temp.sort_values('Amount',ascending=False)\nlocale_temp=locale_temp.fillna('Unknown')\n#plot\nplt.figure(figsize=(5,5))\ng4=sns.barplot(x=locale_temp['Amount'],y=locale_temp['locale'],orient='h',palette='rainbow')\nplt.ylabel('Locale')\nplt.xlabel('Page load (million)')\nplt.title('Page load by Locale')\nplt.tight_layout()\nshow_values(g4, \"h\", space=0)","4d114ab8":"puple_expense=pd.DataFrame(data.groupby('pp_total_raw',dropna=False)['engagement_index'].sum()\/1000000).reset_index()\npuple_expense.columns=['Per-Pupil-Expenditure','Amount']\npuple_expense=puple_expense.fillna('Unknown')\npuple_expense=puple_expense.sort_values('Amount',ascending=False)\n\n\n#plot\nplt.figure(figsize=(15,5))\nplt.plot(puple_expense['Per-Pupil-Expenditure'],puple_expense['Amount'],'b*-')\nplt.xlabel('Per-Pupil Total Expenditure')\nplt.ylabel('Page Load (million)')\nplt.title('Per-Pupil Total Expenditure and Page Load')","4e6f397a":"Most of the page load comes from school districts that has 8000-10000 expenditure\nMore than half of the information is labelled as unkown\nit can be obsereved in the graph that the more than 200 million page-load comes from school districts that has 10000-18000 expenditure.","a3342c0e":"Top Providers","e8b9b9b6":"After the pre preprocessing, We can move on to the explanatory analysis. And also visualize our observations.\n","321086c9":"Expenditure : ","140c4ce2":"There are 3 categories in the dataset that are described below:\n\nLC = Learning & Curriculum CM = Classroom Management SDO = School & District Operations","efafbd42":"Top 10 products used.\n","3c6fdda9":"Next : Handling missing values : ","2bac17ba":"There are 2.8 billion page-load in 2020, most of it is coming from Suburb area that contributes 48% of total observations.\nUnknown is the second highest contribution in the page-load which is around 594 million with a contribution of 20.9%.\nCity and Town are the lowest locale with 308 million and 99 million page-load.","e70c4aba":"Products DataFrame consists of details regarding the various tools, or softwares used by various students\/techers during this period.","dc07810a":"Inference :\n\nout of top 5 products, 4 products are managed by Google. Those 4 products are Google Docs, Google Classroom,Youtube, meet.\nThe page load for google docs is 769 million and the page load for Goggle classroom is 373 million\nCanva is in 3rd position\nunknown stands in 2nd position can be assumed to be coming from many products\n","59833cfe":"The COVID-19 Pandemic has disrupted learning for more than 56 million students in the United States. In the Spring of 2020, most states and local governments across the U.S. closed educational institutions to stop the spread of the virus. In response, schools and teachers have attempted to reach students remotely through distance learning tools and digital platforms. Until today, concerns of the exacaberting digital divide and long-term learning loss among America\u2019s most vulnerable learners continue to grow. In this notebook, i will try to explore the effect of COVID-19 Pandemic in 2020 on online platform usage, especially on education services.\n\n# Data Details\n\nWe include three basic sets of files to help you get started. The engagement data are based on LearnPlatform\u2019s Student Chrome Extension. The extension collects page load events of over 10K education technology products in our product library, including websites, apps, web apps, software programs, extensions, ebooks, hardwares, and services used in educational institutions. The engagement data have been aggregated at school district level, and each file represents data from one school district. The product file includes information about the characteristics of the top 372 products with most users in 2020. The district file includes information about the characteristics of school districts, including data from National Center for Education Statistics (NCES), The Federal Communications Commission (FCC), and Edunomics Lab. In addition to the files provided, we encourage you to use other public data sources such as examples listed below.\n\n","a6fc48d7":"First, load the data into the respective data variables. ","4f3cfb82":"**Data Transformation**","c5bcbc99":"# Analysis","649ce2fd":"In the analysis the page-load which doesn't correspond to any state is labelled as unknown.\nNearly 40% of the total page-load comes from the following states Connecticut, Illinois and Massachusetts."}}