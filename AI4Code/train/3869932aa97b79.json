{"cell_type":{"8f7bf4ab":"code","845c4f04":"code","2b329484":"code","957c4dbc":"code","31abbc83":"code","60f1f354":"code","ae24c363":"code","252e9183":"code","278039fc":"code","dd8ebb8c":"code","3b28639c":"code","888ad8a1":"code","1a878e20":"code","45c765ba":"code","e6ebe458":"code","0921f9de":"code","4387a790":"code","81805fb9":"code","6ad6d7a7":"code","c32ccc93":"code","4a6d0b72":"code","a311d945":"code","0a505aa5":"code","aa726aa0":"code","73ff4210":"code","bb5ade3c":"code","a1cc9bd6":"code","e00b160f":"code","7814aa54":"code","8b3f63a3":"code","b8d26972":"code","7dde831e":"code","93013862":"code","28ef6bcd":"code","4562aaf1":"code","aac14ed2":"code","e1fb0f7c":"code","2dce4a0e":"code","d1ee9b30":"code","ab1e2a1a":"code","dfdcc5a0":"code","9b6549dc":"code","6f674de1":"code","037cc39b":"code","b8050523":"code","24aeaf0a":"code","76a4465d":"code","9fd6332b":"code","9a8495ac":"code","c873489d":"code","c1e58ef0":"code","153b0ecd":"code","56ca4f2b":"code","3909c60c":"code","56f9539e":"code","581a7a64":"code","49377c8f":"code","ff41f5c3":"code","166e806c":"code","38864047":"code","e7f62167":"code","d1dd902b":"code","ccc938a3":"markdown","e8f0fa8f":"markdown","0bce6575":"markdown","54c8b502":"markdown","65d5423a":"markdown","c93399a7":"markdown","99fea148":"markdown","a8d43fd0":"markdown","041097ad":"markdown","c0ef2e0d":"markdown","97f81aaa":"markdown","126f4945":"markdown","77796695":"markdown","8818f680":"markdown","175caa9f":"markdown","c00b1c04":"markdown","4e03ca4b":"markdown","a723246a":"markdown","ae595705":"markdown","8a7b3a3b":"markdown","bc3477fd":"markdown","228fc235":"markdown","f17c747f":"markdown"},"source":{"8f7bf4ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport plotly.express as px\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor \nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error\n\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","845c4f04":"test_data=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntrain_data=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\nsample_submission=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\n\nbackup_data=train_data","2b329484":"test_data.shape","957c4dbc":"train_data.shape","31abbc83":"target_column=train_data[['SalePrice']]","60f1f354":"train_data.shape","ae24c363":"# Checking train data\ntrain_data.head()","252e9183":"# Checking test data\ntest_data.head()","278039fc":"# Checking Sample submission data\nsample_submission.head()","dd8ebb8c":"target_column.describe()","3b28639c":"plt.figure(figsize=(10,10))\nsns.distplot(target_column)","888ad8a1":"# As suggested by many participants, we remove several outliers\ntrain_data.drop(train_data[(train_data['OverallQual']<5) & (train_data['SalePrice']>200000)].index, inplace=True)\ntrain_data.drop(train_data[(train_data['GrLivArea']>4000) & (train_data['SalePrice']<300000)].index, inplace=True)\ntrain_data.reset_index(drop=True, inplace=True)","1a878e20":"def boxplot(column_name,data):\n    title='Box plot for column- {0}'.format(column_name)\n    #print(title)\n    plt.title(title)\n    sns.boxplot(x=column_name,data=data)\n    details_na='The total number of NA Values for column - {1} is {0}' .format(data[column_name].isna().sum(),column_name)\n    print(details_na)\n    \ndef drop_column(data,column_name):\n    train_data=data\n    if column_name in data.columns:\n        train_data=data.drop(columns=[column_name],axis=1)\n        return train_data\n    else:\n        print('Column already removed from dataset Or column not present \\n')\n        print(' ,'.join (data.columns))\n        return train_data\n    \ndef remove_outliers(column_name,data):\n    quantile_1=data[column_name].quantile(0.25)\n    quantile_3=data[column_name].quantile(0.75)\n    iqr=quantile_3-quantile_1\n    lower=quantile_1-1.5*iqr\n    upper=quantile_1+1.5*iqr\n    data[column_name]=data[(data[column_name]>lower)& (data[column_name]<upper)][column_name]\n    return data[column_name]","45c765ba":"## Convert to category variable\n## Dividing the list between object type variables and int variables and then subsetting it\n\nobj_type_variables = [column for column in train_data.columns if train_data[column].dtype in ['object']]\nobject_data=train_data[obj_type_variables]\nobject_data_test=test_data[obj_type_variables]\n\nobj_new_list=['MSSubClass','OverallQual','OverallCond','BsmtFullBath','GarageCars','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd'\n              ,'Fireplaces','MoSold']\ntrain_data[obj_new_list]=train_data[obj_new_list].apply(lambda column:column.astype('object'))\ntest_data[obj_new_list]=test_data[obj_new_list].apply(lambda column:column.astype('object'))\n\ncategory_data=train_data[obj_new_list]\ncategory_data_test=test_data[obj_new_list]\n\nint_type_variables = [column for column in train_data.columns if train_data[column].dtype in ['int64','float64']]\nint_data=train_data[int_type_variables]\nint_data_test=test_data[int_type_variables[:-1]]","e6ebe458":"print(int_type_variables)","0921f9de":"test_data[obj_new_list].isna().sum()","4387a790":"object_data_test.isna().sum()","81805fb9":"object_data['BsmtExposure'].value_counts()\n","6ad6d7a7":"x=['BsmtHalfBath', 'BsmtFullBath', 'GarageCars']\nfor i in x:\n    print(train_data[i].value_counts())\n","c32ccc93":"\nobject_data['Alley']=object_data['Alley'].fillna(\"Grvl\")\nobject_data['BsmtQual']=object_data['BsmtQual'].fillna(\"TA\")\nobject_data['BsmtCond']=object_data['BsmtCond'].fillna(\"TA\")\nobject_data['BsmtExposure']=object_data['BsmtExposure'].fillna(\"No\")\nobject_data['BsmtFinType1']=object_data['BsmtFinType1'].fillna(\"Unf\")\nobject_data['BsmtFinType2']=object_data['BsmtFinType2'].fillna(\"Unf\")\nobject_data['Electrical']=object_data['Electrical'].fillna(\"SBrkr\")\nobject_data['FireplaceQu']=object_data['FireplaceQu'].fillna(\"Gd\")\nobject_data['GarageType']=object_data['GarageType'].fillna(\"Attchd\")\nobject_data['GarageFinish']=object_data['GarageFinish'].fillna(\"Unf\")\nobject_data['GarageQual']=object_data['GarageQual'].fillna(\"TA\")\nobject_data['GarageCond']=object_data['GarageCond'].fillna(\"TA\")\nobject_data['PoolQC']=object_data['GarageCond'].fillna(\"TA\")\nobject_data['Fence']=object_data['Fence'].fillna(\"MnPrv\")\nobject_data['MiscFeature']=object_data['MiscFeature'].fillna(\"Shed\")\n\ntrain_data['BsmtHalfBath']=train_data['BsmtHalfBath'].fillna(\"0\")\ntrain_data['BsmtFullBath']=train_data['BsmtFullBath'].fillna(\"0\")\ntrain_data['GarageCars']=train_data['GarageCars'].fillna(\"2\")\n\n\n\nobject_data_test['Alley']=object_data_test['Alley'].fillna(\"Grvl\")\nobject_data_test['BsmtQual']=object_data_test['BsmtQual'].fillna(\"TA\")\nobject_data_test['BsmtCond']=object_data_test['BsmtCond'].fillna(\"TA\")\nobject_data_test['BsmtExposure']=object_data_test['BsmtExposure'].fillna(\"No\")\nobject_data_test['BsmtFinType1']=object_data_test['BsmtFinType1'].fillna(\"Unf\")\nobject_data_test['BsmtFinType2']=object_data_test['BsmtFinType2'].fillna(\"Unf\")\nobject_data_test['Electrical']=object_data_test['Electrical'].fillna(\"SBrkr\")\nobject_data_test['FireplaceQu']=object_data_test['FireplaceQu'].fillna(\"Gd\")\nobject_data_test['GarageType']=object_data_test['GarageType'].fillna(\"Attchd\")\nobject_data_test['GarageFinish']=object_data_test['GarageFinish'].fillna(\"Unf\")\nobject_data_test['GarageQual']=object_data_test['GarageQual'].fillna(\"TA\")\nobject_data_test['GarageCond']=object_data_test['GarageCond'].fillna(\"TA\")\nobject_data_test['PoolQC']=object_data_test['GarageCond'].fillna(\"TA\")\nobject_data_test['Fence']=object_data_test['Fence'].fillna(\"MnPrv\")\nobject_data_test['MiscFeature']=object_data_test['MiscFeature'].fillna(\"Shed\")\n\ntest_data['BsmtHalfBath']=test_data['BsmtHalfBath'].fillna(\"0\")\ntest_data['BsmtFullBath']=test_data['BsmtFullBath'].fillna(\"0\")\ntest_data['GarageCars']=test_data['GarageCars'].fillna(\"2\")\n\n\n#object_data['MiscFeature'].value_counts()\n#train_data_X_int=train_data_X_int.fillna(train_data_X_int.median())\n","4a6d0b72":"test_data['GarageCars'].isna().sum()","a311d945":"object_data.isna().sum()","0a505aa5":"object_data.shape","aa726aa0":"boxplot('SalePrice',target_column)","73ff4210":"corr_data=int_data.corr()","bb5ade3c":"plt.figure(figsize=(30,30))\nsns.heatmap(corr_data,annot=True)","a1cc9bd6":"pair_plot_data_inbetween_variables=train_data[['MSSubClass',\n          'LotFrontage',\n         'TotalBsmtSF',\n         'OverallQual',\n         'GrLivArea',\n         'OverallCond',\n         'YearBuilt',\n         'EnclosedPorch',\n         'GarageYrBlt',\n         'YearRemodAdd',\n         'BsmtFinSF1',\n         'BsmtFullBath',\n         'BsmtUnfSF',\n         '1stFlrSF',\n         '2ndFlrSF',\n         'BedroomAbvGr',\n         'Fireplaces',\n         'GarageCars',\n         'GarageArea'\n         ]]\n\n","e00b160f":"pair_plot_data_inbetween_variables.head()","7814aa54":"#plt.figure(figsize=(30,30))\n#sns.pairplot(pair_plot_data_inbetween_variables)","8b3f63a3":"pair_plot_data_target_variable=train_data[[\n    'SalePrice',\n    'OverallQual',\n    'TotalBsmtSF',\n    '1stFlrSF',\n    'GrLivArea',\n    'GarageCars',\n    'GarageArea'\n]]","b8d26972":"sns.pairplot(pair_plot_data_target_variable)","7dde831e":"## Creating graphs between SalePrice and ['GarageArea','GrLivArea','1stFlrSF','TotalBsmtSF']\n\nplt.figure(figsize=(9,9))\nsns.relplot(x=\"SalePrice\",\n                y=\"GrLivArea\",\n                col=\"BldgType\",\n                hue=\"OverallQual\",\n                kind=\"scatter\",\n                height=10,\n                aspect=0.3,\n                data=train_data)","93013862":"plt.figure(figsize=(9,9))\nsns.relplot(x=\"SalePrice\",\n                y=\"GarageArea\",\n                col=\"GarageCars\",\n                hue=\"GarageQual\",\n                kind=\"scatter\",\n                height=10,\n                aspect=0.3,\n                data=train_data)","28ef6bcd":"fig = px.scatter(train_data, x=\"SalePrice\", y=\"1stFlrSF\", color=\"OverallQual\")\nfig.show()","4562aaf1":"fig = px.scatter(train_data, x=\"SalePrice\", y=\"TotalBsmtSF\", color=\"OverallQual\")\nfig.show()","aac14ed2":"#print(obj_type_variables)\n#print(int_type_variables)\nint_selected=int_type_variables[1:-1]","e1fb0f7c":"train_data[obj_type_variables].shape","2dce4a0e":"test_data[obj_type_variables].shape","d1ee9b30":"print(train_data[obj_type_variables].shape[0])\nprint(test_data[obj_type_variables].shape)","ab1e2a1a":"obj_type_variables=obj_type_variables+obj_new_list\nobj_type_variables=list(set(obj_type_variables))\n\ntrain_data_X_obj = train_data[obj_type_variables].apply(lambda column: column.astype('category').cat.codes)\ntest_data_X_obj=test_data[obj_type_variables].apply(lambda column: column.astype('category').cat.codes) \n\n\n#train_data_X_obj = train_data[obj_type_variables].apply(lambda column: column.astype('category'))\n#test_data_X_obj=test_data[obj_type_variables].apply(lambda column: column.astype('category'))\n\n#train_data_X_obj = pd.get_dummies(train_data_X_obj)\n#test_data_X_obj = pd.get_dummies(test_data_X_obj)","dfdcc5a0":"#combined_data = pd.concat((train_data[obj_type_variables], test_data[obj_type_variables]), sort=False).reset_index(drop=True)\n#combined_data_dummies=pd.get_dummies(combined_data)","9b6549dc":"#train_data_X_obj=combined_data_dummies.iloc[:train_data[obj_type_variables].shape[0]].reset_index(drop=True)\n#test_data_X_obj = combined_data_dummies.iloc[train_data[obj_type_variables].shape[0]:].reset_index(drop=True)","6f674de1":"print(train_data_X_obj.shape)\nprint(test_data_X_obj.shape)","037cc39b":"train_data_X_int=train_data[int_selected]\ntest_data_X_int=test_data[int_selected]","b8050523":"## Checking for missing values and imputing them\nprint('Checking for categorical variables for missing values')\nprint(train_data_X_obj.isna().sum())\nprint('Checking for integer variables for missing values')\n\nprint(train_data_X_int.isna().sum())\n","24aeaf0a":"train_data_X_int=train_data_X_int.fillna(train_data_X_int.median())\ntest_data_X_int=test_data_X_int.fillna(train_data_X_int.median())","76a4465d":"# scaler=StandardScaler()\n#scaler=RobustScaler()\n#scaler=MinMaxScaler()\n#train_data_X_int=pd.DataFrame(scaler.fit_transform(train_data_X_int),columns=train_data_X_int.columns)\n#test_data_X_int=pd.DataFrame(scaler.fit_transform(test_data_X_int),columns=test_data_X_int.columns)","9fd6332b":"train_Y=train_data['SalePrice']","9a8495ac":"train_X=train_data_X_int.merge(train_data_X_obj,left_index=True,right_index=True).reset_index(drop=True)\ntest_X=test_data_X_int.merge(test_data_X_obj,left_index=True,right_index=True).reset_index(drop=True)","c873489d":"print(train_X.shape)\nprint(train_Y.shape)\nprint(test_X.shape)","c1e58ef0":"test_X.columns[test_X.isna().any()].tolist()","153b0ecd":"print(train_X.shape)\nprint(train_Y.shape)","56ca4f2b":"X_train, X_test, Y_train, Y_test = train_test_split(train_X, train_Y,test_size = .3, random_state=0)","3909c60c":"\nrf = RandomForestRegressor()\nparams = {\"max_depth\":[15,20,25], \"n_estimators\":[24,30,36]}\nrf_reg = GridSearchCV(rf, params, cv = 10, n_jobs =10)\nrf_reg.fit(X_train, Y_train)\nprint(rf_reg.best_estimator_)\nbest_estimator=rf_reg.best_estimator_\ny_pred_test = best_estimator.predict(X_test)\n\n","56f9539e":"print('Mean Square Error test = ' + str(mean_squared_error(Y_test, y_pred_test,squared=False)))\nprint('Root Mean Square Error test = ' + str((mean_squared_error(np.log(Y_test), np.log(y_pred_test),squared=False))))\n\nprint ('R2 square '+str(r2_score(Y_test, y_pred_test))) ","581a7a64":"print(len(X_train.columns))\nprint(len(set(X_train.columns)))\n\n","49377c8f":"#from xgboost import XGBRegressor\n#xgb_regressor = XGBRegressor(learning_rate=0.02,n_estimators = 2400,max_depth=3, min_child_weight=0.01,gamma=0, subsample=0.7,\n#                                     colsample_bytree=0.7,objective='reg:linear', nthread=-1, scale_pos_weight=1, seed=27,reg_alpha=0.00006)\n#xgb_regressor.fit(X_train,Y_train)\n#y_pred_test=xgb_regressor.predict(X_test)\n#\n#mean_squared_error(Y_test, y_pred_test)\n#","ff41f5c3":"from sklearn.ensemble import GradientBoostingRegressor\ngb_regressor = GradientBoostingRegressor(n_estimators=1992, learning_rate=0.03, max_depth=3, max_features='sqrt', min_samples_leaf=15, min_samples_split=8, loss='huber', random_state =42)\ngb_regressor.fit(X_train,Y_train)\ny_pred_test=gb_regressor.predict(X_test)\n\n","166e806c":"print('Mean Square Error test = ' + str(mean_squared_error(Y_test, y_pred_test,squared=False)))\nprint('Root Mean Square Error test = ' + str((mean_squared_error(np.log(Y_test), np.log(y_pred_test),squared=False))))\n\nprint ('R2 square '+str(r2_score(Y_test, y_pred_test)))","38864047":"#pred_test = best_estimator.predict(test_X)\npred_test = gb_regressor.predict(test_X)","e7f62167":"sample_submission=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\nsubmission=pd.DataFrame({\"Id\":sample_submission['Id'],\"SalePrice\":pred_test})\nsubmission.to_csv('submission.csv',index=False)","d1dd902b":"sample_submission.head()","ccc938a3":"Our predicted variable is the **SalePrice** which would be calculated from the several predictor variables that we have.Currently, we don't know anything about any of the details.\n\nThere are around 80 columns and 1460 rows.There are a lot of columns that may affect the SalePrice .For that one need to do comprehensive exploration of data.","e8f0fa8f":"After shortlisting the variables, I built a pair plot between the variables which have either a high positive correlation or a negative correlation.","0bce6575":"I divided dataset into 70-30 ratio so that we can test our scenarios.","54c8b502":"## Model Building\n\nFor Model building, I am first creating a base model that considers all variables for our predictor variables and predicted variable is our SalePrice.\n","65d5423a":"The pandas describe function gives us a basic information on the values of variable.From understanding of the describe function, The House Sale Prices have a minimum of 34.9 K dollars to 755 K.","c93399a7":"As we can see from below, the graph is a normal distribution curve with values between 100K and 300K.\n\nAbout Gaussian Normal Distribution Curve:\n\n    Gaussian distribution (also known as normal distribution) is a bell-shaped curve, and it is assumed that during any measurement values will follow a normal\n    distribution with an equal number of measurements above and below the mean value.\n    \n    In statistics, the theoretical curve that shows how often an experiment will produce a particular result. The curve is symmetrical and bell shaped, showing that \n    trials will usually give a result near the average, but will occasionally deviate by large amounts. \n    ","99fea148":"### Working on integer related data\n\nI am making box job and trying to get an understanding if we have need to clear any outliers.Simultaneously, I will fill the missing values.For that I have created a function as well.","a8d43fd0":" I have taken the references from the below sites and kernels.Thanks a lot guys!!!!!\n \n \n     https:\/\/stats.idre.ucla.edu\/spss\/faq\/coding-systems-for-categorical-variables-in-regression-analysis\/\n    \n    https:\/\/scikit-learn.org\/stable\/auto_examples\/preprocessing\/plot_all_scaling.html\n    \n    https:\/\/towardsdatascience.com\/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02\n    \n    https:\/\/www.kaggle.com\/janvichokshi\/advanced-regression-techniques\n    \n    https:\/\/statisticsbyjim.com\/regression\/interpret-r-squared-regression\/\n    \n    https:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard\n    \n    https:\/\/www.kaggle.com\/agehsbarg\/top-10-0-10943-stacking-mice-and-brutal-force","041097ad":"## Heat Map for the data\n\nHeat map helps to find out the correlation between variables.The corr() function uses Pearson Correlation.I used heatmap because I wanted to check if a high correlation is affected by variables to the target variables.\n\n","c0ef2e0d":"The above graph shows the flow between SalePrice and 1stFlrSF.The Overall Quality would show the flow of the SalePrice values.","97f81aaa":"## Preprocessing Data\n\nI used basic preprocessing i.e. filling missing values, didnt remove any outliers and created a base model which gave out a score of around 85%.I am now trying to build a model after properly cleaning the data i.e. removing outliers , filling NA's with proper values.\n\nI referenced some of the top voted kernels therefore I hope that after I clean the data, the result would be a little better.I will comment out on the box plots after I have visualised on it.","126f4945":"P.S.\nI making more changes to this kernel I think I can make better models by using other variants and doing feature selections.\n","77796695":"## Replacing NaN values for categorical features\n\n    1. Alley variable contains 2 variables,rest has been replaced with None Variable\n    2. For the rest values, I took up the mode values i.e. the higher categorical variables is taken\n    3. For some higher NaN values,I will replace it with NA","8818f680":"## Removing Outliers \n\nFor removing outliers I came across with the several kernels in which people have ran the below code to remove the outliers.I am still trying to understand as how these were constituted as outliers.Here is the discussion thread.\n\nhttps:\/\/www.kaggle.com\/c\/house-prices-advanced-regression-techniques\/discussion\/146728\n\n","175caa9f":"\nUnderstanding from the above correlation map, I am going to take on some of the variables that have got high correlation and understand the flow information.Below is the relation of variables between each other\n\n            |Column Name               |Correlated Columns with high correlation|\n            \n            |--------------------------|----------------------------------------|\n            \n            |MSSubClass                |LotFrontage,TotalBsmtSF,1stFlrSF        |\n            |LotFrontage               |  NA                                    |\n            |LotArea                   |  NA                                    |\n            |OverallQual               | GrLivArea                              |\n            |OverallCond               | GarageYrBlt                            |\n            |YearBuilt                 |EnclosedPorch,GarageYrBlt,YearRemodAdd  |\n            |YearRemodAdd              |GarageYrBlt                             |\n            |MasVnrArea                |  NA                                    |\n            |BsmtFinSF1                |BsmtFullBath                            |\n            |BsmtFinSF2                |  NA                                    |\n            |BsmtUnfSF                 |BsmtFullBath                            |\n            |TotalBsmtSF               |1stFlrSF                                |\n            |1stFlrSF                  |  NA                                    |\n            |2ndFlrSF                  | GrLivArea                              |\n            |LowQualFinSF              |  NA                                    |\n            |GrLivArea                 |  NA                                    |\n            |BsmtFullBath              |  NA                                    |\n            |BsmtHalfBath              |  NA                                    |\n            |FullBath                  |  NA                                    |\n            |HalfBath                  |  NA                                    |\n            |BedroomAbvGr              |Fireplaces                              |\n            |KitchenAbvGr              |  NA                                    |\n            |TotRmsAbvGrd              |  NA                                    |\n            |Fireplaces                |  NA                                    |\n            |GarageYrBlt               | EnclosedPorch                          |\n            |GarageCars                | GarageArea                             |\n            |GarageArea                |  NA                                    |\n            |WoodDeckSF                |  NA                                    |\n            |OpenPorchSF               |  NA                                    |\n            |EnclosedPorch             |  NA                                    |\n            |3SsnPorch                 |  NA                                    |\n            |ScreenPorch               |  NA                                    |\n            |PoolArea                  |  NA                                    |\n            |MiscVal                   |  NA                                    |\n            |MoSold                    |  NA                                    |\n            |YrSold                    |  NA                                    |\n            \n","c00b1c04":"The above graph is between SalePrice and Garage Area.The Graph is spreaded for Garage Cars as 3 while for GarageCars=2 the no. of records is high as compared to the other records.Also, the no. of records for Average Garage quality is high.","4e03ca4b":"Below pair plot is created with respect to the SalePrice(target variable) with other variables.","a723246a":"### Checking for Null values\n\nNull values can be treated mostly in 2 ways: \n    \n       1. Either delete the whole row - This option I usually use when the data records that needs to be removed are not that important and **WOULD NOT** not help \n       in our model building.\n       \n       2.Imputing the values with mean or a median.I perfer to choose median over mean as I think that mean gets affected by outliers so I prefer median as a way to \n       impute values.","ae595705":"We would be replacing the removing values with median values.I choose median values over mean values as means get affected with outliers while it is not the same case with median values","8a7b3a3b":"# House Prices: Advanced Regression Techniques\n\nThis project covers the advanced regression techniques as the dataset contains a lot of variable that are both categorical variables and linear values variables.According to me, this should be project after a kaggler is comfortable with making models and understanding the scores.For my model building , right now I am considering only root mean squared error values and R-squared value.\n\nFor further scoring, I was planning to use Adjusted R-squared value.\n\nDetails on accuracy for R-squared:\n\n**R-squared** is a goodness-of-fit measure for linear regression models. This statistic indicates the percentage of the variance in the dependent variable that the independent variables explain collectively. R-squared measures the strength of the relationship between your model and the dependent variable on a convenient 0 \u2013 100% scale.\n\n","bc3477fd":"The above graph is between SalePrice and GrLivArea(Above grade (ground) living area square feet), divided across Building Type and Overall Quality of values.\n\nAs understood from the above the records, building type for 1Fam has a large number of records and it is a positive trend i.e. with the increase in SalePrice there is a increase in Quality.","228fc235":"As understood from the target column, the box plot depicts some of the outliers.","f17c747f":"I have divided sets into 3 parts -\n\n    1. Object type variables \n    2. Integer type variables -- The missing values would be added with **median** values\n    3. Integer turned Category variables "}}