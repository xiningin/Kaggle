{"cell_type":{"17b949a7":"code","e59506bd":"code","7ef2ce9c":"code","e5318bf3":"code","b141166e":"code","18d9ba30":"code","5f392825":"code","cf16a7f6":"code","2c10b3ab":"code","eceb9fdb":"code","2296d402":"code","52f74be1":"code","0a1ee6b1":"code","1474d0c4":"code","95ad05c6":"code","d37b01ef":"code","0d20fa30":"code","0cd78f9f":"code","86513bb7":"code","e7878237":"code","dd039c49":"code","0e5cd87d":"code","9d9de682":"code","675317d2":"code","a3bbf0aa":"code","ea3da5dd":"code","63826465":"code","e784746d":"code","806d46c3":"code","77567f5b":"code","a7d99bbb":"code","3dacf877":"code","ef4fcb59":"code","31270de7":"code","528cb07d":"code","39f0f6aa":"code","4bd1bae2":"code","732261af":"code","2999bc7b":"markdown","dcde4978":"markdown","e798598d":"markdown","758adfe1":"markdown","33263b69":"markdown","cc69d67d":"markdown"},"source":{"17b949a7":"\nimport pandas as pd\n\nhousing = pd.read_csv(\"..\/input\/hands-on-machine-learning-housing-dataset\/housing.csv\")","e59506bd":"#Showing the first 5 rows\nhousing.head()","7ef2ce9c":"#info of dataset\nhousing.info","e5318bf3":"#Value counts of ocean_proximity column\nhousing['ocean_proximity'].value_counts()","b141166e":"#shape of our data\nhousing.shape","18d9ba30":"#Summary of each numerical attributes\nhousing.describe()","5f392825":"#Showwing the correlations\nhousing.corr()\n","cf16a7f6":"#Showing the columns\nhousing.columns","2c10b3ab":"#Plotting histograms for each numerical attributes\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\nhousing.hist(bins =50, figsize=(20,15))\n\nplt.show()\n\n#Slighly over 1000 distrcts have a median_house_value about 500000 usd","eceb9fdb":"housing.hist(column='population')\n","2296d402":"# random_state parameter always generate the same shuffle indices. If the dataset \n# is not big enough then there's a chance of sampling bias\nfrom sklearn.model_selection import train_test_split\ntrain_set, test_set = train_test_split(housing, test_size = 0.2, random_state=42)\n\n","52f74be1":"# Geographical data of all districts\nhousing.plot (kind ='scatter', x='longitude', y= 'latitude')","0a1ee6b1":"housing.plot (kind ='scatter', x='longitude', y= 'latitude', alpha = 0.1)\n# adding alpha for better visualization. This helps to visualize the high density data points","1474d0c4":"housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n    s=housing[\"population\"]\/100, label=\"population\", figsize=(10,10),\n    c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n    sharex=False)\nplt.legend()\n\n# This represents that housing prices are varies with locations and population density\n","95ad05c6":"corr_matrix = housing.corr()","d37b01ef":"print (corr_matrix)","0d20fa30":"# Correlation of median_house_value with other attributes\ncorr_matrix['median_house_value'].sort_values(ascending = False)","0cd78f9f":"# another way to check correlation using pandas\n\nfrom pandas.plotting import scatter_matrix\nattributes = ['median_house_value', 'median_income','total_rooms','housing_median_age']\nscatter_matrix(housing[attributes], figsize = (12,8))","86513bb7":"housing.plot (kind='scatter', x=\"median_income\",y='median_house_value',alpha = 0.1)\n\n# It means corr is very strong. ","e7878237":"# Creating new attributes\n\nhousing['room_per-_household'] = housing['total_rooms']\/housing['households']\nhousing['bedrooms_per_rooms'] = housing['total_bedrooms']\/housing['total_rooms']\nhousing['population_per_household'] = housing['population']\/housing['households']","dd039c49":"# Now the corr matrix will look something like this\ncorr_matrix = housing.corr()\ncorr_matrix['median_house_value'].sort_values(ascending = False)\n\n\n# This means bedrooms_per_room attributee is much more correlated with mediamn house value than total num of rooms\n# Lower bedrooms has high price","0e5cd87d":"housing.plot(kind=\"scatter\",\n             x=\"room_per-_household\",\n             y=\"median_house_value\",\n             alpha=0.2)\nplt.axis([0, 5, 0, 520000])\n\n","9d9de682":"# Data Cleaning and handling missing values\n\n#housing.dropna(subset=['total_bedrooms'])\n\n# we can use this. but sklearn also provide e good function","675317d2":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy ='median')\n\n\n# this help to take care of missing values. \n# medians only be computed on numerical values ,so we need a copy of data without text attributes i.e ocean_proximity","a3bbf0aa":"housing_num = housing.drop('ocean_proximity', axis=1)","ea3da5dd":"imputer.fit(housing_num)\n# fitting the imputer instances to training data. It only computed the median of each attributes.","63826465":"housing_num.median().values\n","e784746d":"X = imputer.transform(housing_num)\n\n# Transforming the train set by replacing the missing values with new medians","806d46c3":"imputer.strategy\n","77567f5b":"housing_tr = pd.DataFrame(X, columns=housing_num.columns, index=housing.index)","a7d99bbb":"housing_tr.loc[housing_num.index.values]\n# Putting back into Pandas df","3dacf877":"housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n                          index=housing_num.index)","ef4fcb59":"housing_tr.head()\n","31270de7":"housing_cat = housing[[\"ocean_proximity\"]]\nhousing_cat.head(10)","528cb07d":"# Earlier we left the text attribute (ocean_proximity), now we have to work on that\n\n# Converting them into labels\n\nfrom sklearn.preprocessing import OrdinalEncoder\nordinal_encoder = OrdinalEncoder()\nhousing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\nhousing_cat_encoded[:10]","39f0f6aa":"ordinal_encoder.categories_\n","4bd1bae2":"# Convert int to categorical values into onehot vectors\nfrom sklearn.preprocessing import OneHotEncoder\n\ncat_encoder = OneHotEncoder()\nhousing_cat_1hot = cat_encoder.fit_transform(housing_cat)\nhousing_cat_1hot","732261af":"housing_cat_1hot.toarray()\n","2999bc7b":"## Data Cleaning and Handling Missing Values","dcde4978":"## Downloading and playing with the dataset","e798598d":"# Author: Kazi Amit Hasan\n\nDepartment of Computer Science & Engineering, <br>\nRajshahi University of Engineering & Technology (RUET) <br>\nWebsite: https:\/\/amithasanshuvo.github.io\/ <br>\nLinkedin: https:\/\/www.linkedin.com\/in\/kazi-amit-hasan-514443140\/ <br>\nEmail: kaziamithasan89@gmail.com <br>\n\n\n### Comment: \nThis notebook represents EDA. I tried to implemented each examples while I was reading and practicing the book (in reference). <br>\n<b>Please give your feedback how I can improve the notebook and please upvote to support. Happy Learning!\n\n\n##### Reference \nHands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems book (The best book I ever got on Data Science <3) <br>\n\nLanguage: Python\n\n##### Topics Covered:\n1. Downloading and playing with the dataset\n2. Data Visualization\n3. Correlation Analysis\n4. Data Cleaning and Handling Missing Values\n5. Handling text and Categorical attributes\n\n\n\n##### Todo list:\n1. Feature Scaling\n2. Pipelines\n3. Train and Evaluating\n4. Cross Validation\n5. Tuning\n6. Grid Search\n7. Randomized Search\n8. Ensemble method\n9. Do the exercises","758adfe1":"## Data Visualization","33263b69":"## Correaltion Analysis","cc69d67d":"## Handling text and Categorical attributes"}}