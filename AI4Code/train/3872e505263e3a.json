{"cell_type":{"6474ad38":"code","eed59eb6":"code","8b5a250b":"code","17c87a60":"code","2eb2ec6d":"code","6eb288a1":"code","f91cb95d":"code","c3c6195e":"code","c7174881":"code","1a2a4e27":"code","6cd4ebbb":"code","58ee6e37":"code","699571a9":"code","39cb9a6f":"code","c25986ba":"code","98d83dea":"code","c3b6c1e2":"code","59807b3a":"code","4d65dfe2":"code","5f8a37a4":"code","0164115c":"markdown","92a19fdf":"markdown","14284c3d":"markdown","b4e12945":"markdown","1aaea31e":"markdown","fe43b294":"markdown","bcc5bd53":"markdown","b414fe34":"markdown","32ad1a60":"markdown","123cd3e0":"markdown","f4fb34f1":"markdown"},"source":{"6474ad38":"# \u30d1\u30c3\u30b1\u30fc\u30b8\u306eimport\nimport os\nimport numpy as np\nimport glob\nimport tensorflow as tf\nimport json\nfrom PIL import Image\nimport io\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport random\n\n\nfrom tqdm import tqdm\n\nimport torch\nimport torchvision\nimport torch.utils.data as data\nimport torch.nn as nn\nimport torch.optim as optim\nimport pandas as pd\nfrom torchvision import models, transforms\nfrom sklearn.model_selection import train_test_split \n","eed59eb6":"# PyTorch\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u78ba\u8a8d\nprint(\"PyTorch Version: \",torch.__version__)\nprint(\"Torchvision Version: \",torchvision.__version__)","8b5a250b":"# \u4e71\u6570\u306e\u30b7\u30fc\u30c9\u3092\u8a2d\u5b9a\ntorch.manual_seed(1234)\nnp.random.seed(1234)\nrandom.seed(1234)","17c87a60":"\nresize = 224\nmean = (0.485, 0.456, 0.406)\nstd = (0.229, 0.224, 0.225)\n\ntrain_transforms = transforms.Compose([\n                transforms.RandomResizedCrop(\n                    resize, scale=(0.5, 1.0)),  # \u30c7\u30fc\u30bf\u30aa\u30fc\u30ae\u30e5\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\n                transforms.RandomHorizontalFlip(),  # \u30c7\u30fc\u30bf\u30aa\u30fc\u30ae\u30e5\u30e1\u30f3\u30c6\u30fc\u30b7\u30e7\u30f3\n                transforms.ToTensor(),  # \u30c6\u30f3\u30bd\u30eb\u306b\u5909\u63db\n                transforms.Normalize(mean, std)  # \u6a19\u6e96\u5316\n    ])\nval_transforms = transforms.Compose([\n                transforms.Resize(resize),  # \u30ea\u30b5\u30a4\u30ba\n                transforms.CenterCrop(resize),  # \u753b\u50cf\u4e2d\u592e\u3092resize\u00d7resize\u3067\u5207\u308a\u53d6\u308a\n                transforms.ToTensor(),  # \u30c6\u30f3\u30bd\u30eb\u306b\u5909\u63db\n                transforms.Normalize(mean, std)  # \u6a19\u6e96\u5316\n    ])\ntest_transforms = transforms.Compose([\n                transforms.Resize(resize),  # \u30ea\u30b5\u30a4\u30ba\n                transforms.CenterCrop(resize),  # \u753b\u50cf\u4e2d\u592e\u3092resize\u00d7resize\u3067\u5207\u308a\u53d6\u308a\n                transforms.ToTensor(),  # \u30c6\u30f3\u30bd\u30eb\u306b\u5909\u63db\n                transforms.Normalize(mean, std)  # \u6a19\u6e96\u5316\n    ])","2eb2ec6d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\nimport os\nimport pandas as pd\nfrom scipy import stats\nimport numpy as np\nimport glob\nimport tensorflow as tf\n# import timm\nimport random\nimport time\nimport copy\nfrom operator import itemgetter\n\nfrom collections import OrderedDict, namedtuple\nimport joblib\n\nimport logging\nimport sys\n\nimport PIL\nimport cv2\nimport albumentations as A\nimport io\nimport IPython.display as display\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nimport torch.optim as optim\n# import torch_xla\n# import torch_xla.core.xla_model as xm\n# import torch_xla.debug.metrics as met\n# import torch_xla.distributed.parallel_loader as pl\n# import torch_xla.distributed.xla_multiprocessing as xmp\n# import torch_xla.utils.utils as xu\n\nimport torchvision\n# from torchvision import datasets, transforms\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nimport torchvision.transforms as transforms\nfrom torchvision.utils import make_grid\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics, model_selection\n\nimport warnings\nwarnings.filterwarnings(\"ignore\");\n\ntrain_files = glob.glob('..\/input\/tpu-getting-started\/*224\/train\/*.tfrec')\nval_files = glob.glob('..\/input\/tpu-getting-started\/*224\/val\/*.tfrec')\ntest_files = glob.glob('..\/input\/tpu-getting-started\/*224\/test\/*.tfrec')","6eb288a1":"def parse_tfrec_data(files, test=False):\n    if not test: \n        feature_description = {\n            'class': tf.io.FixedLenFeature([], tf.int64),\n            'id': tf.io.FixedLenFeature([], tf.string),\n            'image': tf.io.FixedLenFeature([], tf.string),\n        }\n    else:\n        feature_description = {\n        'id': tf.io.FixedLenFeature([], tf.string),\n        'image': tf.io.FixedLenFeature([], tf.string),\n    }\n    parse_image_f = lambda x: tf.io.parse_single_example(x, feature_description)\n\n    ids = []\n    images = []\n    if not test:\n        cl = []\n\n    for i in tqdm(files):\n        image_dataset = tf.data.TFRecordDataset(i)\n        image_dataset = image_dataset.map(parse_image_f)\n\n        ids_ = [str(id_features['id'].numpy())[2:-1] for id_features in image_dataset] # [2:-1] is done to remove b' from 1st and 'from last in train id names\n        ids = ids + ids_\n\n        images_ = [image_features['image'].numpy() for image_features in image_dataset]\n        images = images + images_\n\n        if not test:\n                cl_ = [int(class_features['class'].numpy()) for class_features in image_dataset]\n                cl = cl + cl_\n    if test:\n        return ids, images\n    else:\n        return ids, cl, images","f91cb95d":"gpu_devices = tf.config.experimental.list_physical_devices('GPU')\nfor device in gpu_devices:\n    tf.config.experimental.set_memory_growth(device, True)\n\ntrain_ids, train_cl, train_images = parse_tfrec_data(train_files)\nval_ids, val_cl, val_images = parse_tfrec_data(val_files)\ntest_ids, test_images = parse_tfrec_data(test_files, test=True)","c3c6195e":"# \u753b\u50cf\u524d\u51e6\u7406\u306e\u52d5\u4f5c\u3092\u78ba\u8a8d\n\n# 1. \u753b\u50cf\u8aad\u307f\u8fbc\u307f\n#image_file_path = '..\/input\/tpu-getting-started\/tfrecords-jpeg-224x224\/test\/00-224x224-462.tfrec'\n#img = Image.open(image_file_path)  # [\u9ad8\u3055][\u5e45][\u8272RGB]\nprint(train_ids[0])\nprint(train_cl[0])\nimg = Image.open(io.BytesIO(train_images[0]))\nimg\n\n# 2. \u5143\u306e\u753b\u50cf\u306e\u8868\u793a\nplt.imshow(img)\nplt.show()\n\n# 3. \u753b\u50cf\u306e\u524d\u51e6\u7406\u3068\u51e6\u7406\u6e08\u307f\u753b\u50cf\u306e\u8868\u793a\nimg_transformed = train_transforms(img)  # torch.Size([3, 224, 224])\n\n# (\u8272\u3001\u9ad8\u3055\u3001\u5e45)\u3092 (\u9ad8\u3055\u3001\u5e45\u3001\u8272)\u306b\u5909\u63db\u3057\u30010-1\u306b\u5024\u3092\u5236\u9650\u3057\u3066\u8868\u793a\nimg_transformed = img_transformed.numpy().transpose((1, 2, 0))\nimg_transformed = np.clip(img_transformed, 0, 1)\nplt.imshow(img_transformed)\nplt.show()","c7174881":"class FlowerDataset(data.Dataset):\n    \n    def __init__(self, ids, images, cl, transforms, test=False):\n        \n        self.ids = ids\n        self.images = images\n        if not test:\n            self.cl = cl\n        self.transforms = transforms\n        self.is_test = test\n    \n    def __len__(self):\n        return len(self.ids)\n        \n    def __getitem__(self, idx):\n        \n        img = self.images[idx]\n        img = Image.open(io.BytesIO(img))\n        #img = np.array(img)\n        img = self.transforms(img)\n        \n        if self.is_test:\n            return img, -1, self.ids[idx]\n        return img, int(self.cl[idx]), self.ids[idx]\n\ntrain_dataset = FlowerDataset(train_ids, train_images, train_cl, transforms=train_transforms)\nval_dataset = FlowerDataset(val_ids, val_images, val_cl, transforms=val_transforms)\ntest_dataset = FlowerDataset(test_ids, test_images, None, transforms=test_transforms, test=True)","1a2a4e27":"IMG_SIZE = 224\n\n# DataLoader\u3092\u4f5c\u6210\u3059\u308b\nbatch_size = 32\n\ntrain_dataloader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True)\n\nval_dataloader = torch.utils.data.DataLoader(\n    val_dataset, batch_size=batch_size, shuffle=False)\n\ntest_loader = torch.utils.data.DataLoader(\n    test_dataset, batch_size=batch_size, shuffle=False)\n\n# \u8f9e\u66f8\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u307e\u3068\u3081\u308b\ndataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader, \"test\": test_loader}","6cd4ebbb":"\n!pip install efficientnet_pytorch","58ee6e37":"# \u5b66\u7fd2\u6e08\u307f\u306eVGG-16\u30e2\u30c7\u30eb\u3092\u30ed\u30fc\u30c9\n\n# VGG-16\u30e2\u30c7\u30eb\u306e\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u751f\u6210\nuse_pretrained = True  # \u5b66\u7fd2\u6e08\u307f\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u4f7f\u7528\n#use_pretrained = False  # \u5b66\u7fd2\u6e08\u307f\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u4f7f\u7528\n#net = models.vgg16(pretrained=use_pretrained)\n\n\n# VGG16\u306e\u6700\u5f8c\u306e\u51fa\u529b\u5c64\u306e\u51fa\u529b\u30e6\u30cb\u30c3\u30c8\u3092\u75c5\u6c174\u7a2e\u3068\u5065\u5eb7\u306e5\u3064\u306b\u4ed8\u3051\u66ff\u3048\u308b\n#net.classifier[6] = nn.Linear(in_features=4096, out_features=104)\n\n\nfrom efficientnet_pytorch import EfficientNet\n\nnet = EfficientNet.from_pretrained('efficientnet-b4')#Pretrained_model\u306e\u30a4\u30f3\u30dd\u30fc\u30c8\n#\u4e8b\u524d\u5b66\u7fd2\u306b\u306fImageNet\u3092\u7528\u3044\u3066\u3044\u308b\u306e\u3067\u3001\u5168\u7d50\u5408\u5c64\u306f1000\u30af\u30e9\u30b9\u3067\u3059\u3002\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u30af\u30e9\u30b9\u6570\u3092\u5909\u66f4\u3059\u308c\u3070\u8ee2\u79fb\u5b66\u7fd2\u306b\u5229\u7528\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002\n\nnum_ftrs = net._fc.in_features#\u5168\u7d50\u5408\u5c64\u306e\u540d\u524d\u306f\"_fc\"\u3068\u306a\u3063\u3066\u3044\u307e\u3059\nnet._fc = nn.Linear(num_ftrs, 104)\n\n\n# \u8a13\u7df4\u30e2\u30fc\u30c9\u306b\u8a2d\u5b9a\nnet.train()\n\nprint('\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u8a2d\u5b9a\u5b8c\u4e86\uff1a\u5b66\u7fd2\u6e08\u307f\u306e\u91cd\u307f\u3092\u30ed\u30fc\u30c9\u3057\u3001\u8a13\u7df4\u30e2\u30fc\u30c9\u306b\u8a2d\u5b9a\u3057\u307e\u3057\u305f')","699571a9":"# \u640d\u5931\u95a2\u6570\u306e\u8a2d\u5b9a\ncriterion = nn.CrossEntropyLoss()","39cb9a6f":"# \u30d5\u30a1\u30a4\u30f3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3067\u5b66\u7fd2\u3055\u305b\u308b\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u3001\u5909\u6570params_to_update\u306e1\uff5e3\u306b\u683c\u7d0d\u3059\u308b\n#\n#params_to_update_1 = []\n#params_to_update_2 = []\n#params_to_update_3 = []\n\n# \u5b66\u7fd2\u3055\u305b\u308b\u5c64\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u540d\u3092\u6307\u5b9a\n#update_param_names_1 = [\"features\"]\n#update_param_names_2 = [\"classifier.0.weight\",\n#                        \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\"]\n#update_param_names_3 = [\"classifier.6.weight\", \"classifier.6.bias\"]\n\n# \u30d1\u30e9\u30e1\u30fc\u30bf\u3054\u3068\u306b\u5404\u30ea\u30b9\u30c8\u306b\u683c\u7d0d\u3059\u308b\n#for name, param in net.named_parameters():\n#    if update_param_names_1[0] in name:\n#        param.requires_grad = True\n#        params_to_update_1.append(param)\n#        print(\"params_to_update_1\u306b\u683c\u7d0d\uff1a\", name)\n#\n#    elif name in update_param_names_2:\n#        param.requires_grad = True\n#        params_to_update_2.append(param)\n#        print(\"params_to_update_2\u306b\u683c\u7d0d\uff1a\", name)\n#\n#    elif name in update_param_names_3:\n#        param.requires_grad = True\n#        params_to_update_3.append(param)\n#        print(\"params_to_update_3\u306b\u683c\u7d0d\uff1a\", name)\n#\n#    else:\n#        param.requires_grad = False\n#        print(\"\u52fe\u914d\u8a08\u7b97\u306a\u3057\u3002\u5b66\u7fd2\u3057\u306a\u3044\uff1a\", name)","c25986ba":"# \u6700\u9069\u5316\u624b\u6cd5\u306e\u8a2d\u5b9a\n#optimizer = optim.SGD([\n#    {'params': params_to_update_1, 'lr': 1e-4},\n#    {'params': params_to_update_2, 'lr': 5e-4},\n#    {'params': params_to_update_3, 'lr': 1e-3}\n#], momentum=0.9)\noptimizer = optim.Adam(net.parameters())","98d83dea":"# \u30e2\u30c7\u30eb\u3092\u5b66\u7fd2\u3055\u305b\u308b\u95a2\u6570\u3092\u4f5c\u6210\n\n\ndef train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n\n    # \u521d\u671f\u8a2d\u5b9a\n    # GPU\u304c\u4f7f\u3048\u308b\u304b\u3092\u78ba\u8a8d\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    print(\"\u4f7f\u7528\u30c7\u30d0\u30a4\u30b9\uff1a\", device)\n\n    # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092GPU\u3078\n    net.to(device)\n\n    # \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u304c\u3042\u308b\u7a0b\u5ea6\u56fa\u5b9a\u3067\u3042\u308c\u3070\u3001\u9ad8\u901f\u5316\u3055\u305b\u308b\n    torch.backends.cudnn.benchmark = True\n\n    # epoch\u306e\u30eb\u30fc\u30d7\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch+1, num_epochs))\n        print('-------------')\n\n        # epoch\u3054\u3068\u306e\u8a13\u7df4\u3068\u691c\u8a3c\u306e\u30eb\u30fc\u30d7\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                net.train()  # \u30e2\u30c7\u30eb\u3092\u8a13\u7df4\u30e2\u30fc\u30c9\u306b\n            else:\n                net.eval()   # \u30e2\u30c7\u30eb\u3092\u691c\u8a3c\u30e2\u30fc\u30c9\u306b\n\n            epoch_loss = 0.0  # epoch\u306e\u640d\u5931\u548c\n            epoch_corrects = 0  # epoch\u306e\u6b63\u89e3\u6570\n\n            # \u672a\u5b66\u7fd2\u6642\u306e\u691c\u8a3c\u6027\u80fd\u3092\u78ba\u304b\u3081\u308b\u305f\u3081\u3001epoch=0\u306e\u8a13\u7df4\u306f\u7701\u7565\n            #if (epoch == 0) and (phase == 'train'):\n            #    continue\n\n            # \u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\u304b\u3089\u30df\u30cb\u30d0\u30c3\u30c1\u3092\u53d6\u308a\u51fa\u3059\u30eb\u30fc\u30d7\n            for inputs, labels, _ in tqdm(dataloaders_dict[phase]):\n\n                # GPU\u304c\u4f7f\u3048\u308b\u306a\u3089GPU\u306b\u30c7\u30fc\u30bf\u3092\u9001\u308b\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                                \n                # optimizer\u3092\u521d\u671f\u5316\n                optimizer.zero_grad()\n\n                # \u9806\u4f1d\u642c\uff08forward\uff09\u8a08\u7b97\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = net(inputs)\n                    loss = criterion(outputs, labels)  # \u640d\u5931\u3092\u8a08\u7b97\n                    _, preds = torch.max(outputs, 1)  # \u30e9\u30d9\u30eb\u3092\u4e88\u6e2c\n\n                    # \u8a13\u7df4\u6642\u306f\u30d0\u30c3\u30af\u30d7\u30ed\u30d1\u30b2\u30fc\u30b7\u30e7\u30f3\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                    # \u7d50\u679c\u306e\u8a08\u7b97\n                    epoch_loss += loss.item() * inputs.size(0)  # loss\u306e\u5408\u8a08\u3092\u66f4\u65b0\n                    # \u6b63\u89e3\u6570\u306e\u5408\u8a08\u3092\u66f4\u65b0\n                    epoch_corrects += torch.sum(preds == labels.data)\n\n            # epoch\u3054\u3068\u306eloss\u3068\u6b63\u89e3\u7387\u3092\u8868\u793a\n            epoch_loss = epoch_loss \/ len(dataloaders_dict[phase].dataset)\n            epoch_acc = epoch_corrects.double(\n            ) \/ len(dataloaders_dict[phase].dataset)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n            ","c3b6c1e2":"# \u5b66\u7fd2\u30fb\u691c\u8a3c\u3092\u5b9f\u884c\u3059\u308b\nnum_epochs=50\ntrain_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)","59807b3a":"# PyTorch\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u4fdd\u5b58\nsave_path = '.\/weights_fine_tuning.pth'\ntorch.save(net.state_dict(), save_path)","4d65dfe2":"#\u7d50\u679c\u6295\u7a3f\u7528\u306eCSV\u4f5c\u6210\u95a2\u6570\ndef make_submission(model, test_loader, cuda=True):\n\n    results=[]\n    for batch, _, ids in tqdm(test_loader):\n        with torch.no_grad():\n            if cuda:\n                batch = batch.cuda()\n            model.eval()\n            out = model(batch)\n            pred_labels = torch.argmax(out.data.cpu(), dim=1)\n            rows = list(\n                zip(\n                    list(ids), list(pred_labels.numpy().tolist())\n                )\n            )\n            results.append(pd.DataFrame(rows, columns=['id', 'label']))\n    result_df = pd.concat(results)\n    result_df['label'] = result_df['label'].astype(int)\n    return result_df\n","5f8a37a4":"# PyTorch\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u30ed\u30fc\u30c9\nload_path = '.\/weights_fine_tuning.pth'\nload_weights = torch.load(load_path)\nnet.load_state_dict(load_weights)\n\n# GPU\u4e0a\u3067\u4fdd\u5b58\u3055\u308c\u305f\u91cd\u307f\u3092CPU\u4e0a\u3067\u30ed\u30fc\u30c9\u3059\u308b\u5834\u5408\n#load_weights = torch.load(load_path, map_location={'cuda:0': 'cpu'})\n#net.load_state_dict(load_weights)\n\nsubmission = make_submission(net, test_loader)\nsubmission.to_csv('submission.csv', index=False)","0164115c":"# \u5b66\u7fd2\u30fb\u691c\u8a3c\u3092\u5b9f\u65bd","92a19fdf":"# \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30e2\u30c7\u30eb\u306e\u4f5c\u6210","14284c3d":"# \u6700\u9069\u5316\u624b\u6cd5\u3092\u8a2d\u5b9a\n* Optimizer\u304cVGG\u30e2\u30c7\u30eb\u306e\u3069\u3053\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u66f4\u65b0(\uff1d\u5b66\u7fd2\u30fb\u6700\u9069\u5316)\u3059\u308b\u304b\u3092\u6307\u5b9a\u3059\u308b\n* Optimizer\u306f\u201d\u8aa4\u5dee\u9006\u4f1d\u642c\u6cd5\u201d\u3092\u7528\u3044\u3066\u3001\u640d\u5931\u95a2\u6570\u3092\u6700\u5c0f\u5316\u3059\u308b\u3088\u3046\u306bVGG\u30e2\u30c7\u30eb\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u66f4\u65b0(\uff1d\u5b66\u7fd2\u30fb\u6700\u9069\u5316)\u5f79\u5272\u3092\u62c5\u3046","b4e12945":"# \u640d\u5931\u95a2\u6570\u3092\u5b9a\u7fa9\n* \u640d\u5931\u95a2\u6570\u306f\u3001\u30e2\u30c7\u30eb\u304c\u554f\u984c\u3092\u5b66\u7fd2\u51fa\u6765\u3066\u3044\u308b\u304b\u306e\u6307\u6a19\u201d\u30ed\u30b9(\u640d\u5931)\u201d\u306e\u8a08\u7b97\u65b9\u6cd5\u3092\u6307\u5b9a\u3059\u308b","1aaea31e":"# \u5165\u529b\u753b\u50cf\u306e\u524d\u51e6\u7406\u30af\u30e9\u30b9\u3092\u4f5c\u6210","fe43b294":"# 1.5 \u300c\u30d5\u30a1\u30a4\u30f3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u300d\u3067\u7cbe\u5ea6\u5411\u4e0a\u3092\u5b9f\u73fe\u3059\u308b\u65b9\u6cd5  \n- \u672c\u30d5\u30a1\u30a4\u30eb\u3067\u306f\u3001\u5b66\u7fd2\u6e08\u307f\u306eVGG\u30e2\u30c7\u30eb\u3092\u4f7f\u7528\u3057\u3001\u30d5\u30a1\u30a4\u30f3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3067\u30a2\u30ea\u3068\u30cf\u30c1\u306e\u753b\u50cf\u3092\u5206\u985e\u3059\u308b\u30e2\u30c7\u30eb\u3092\u5b66\u7fd2\u3057\u307e\u3059","bcc5bd53":"# \u5b66\u7fd2\u76ee\u6a19  \n1.PyTorch\u3067GPU\u3092\u4f7f\u7528\u3059\u308b\u5b9f\u88c5\u30b3\u30fc\u30c9\u3092\u66f8\u3051\u308b\u3088\u3046\u306b\u306a\u308b  \n2.\u6700\u9069\u5316\u624b\u6cd5\u306e\u8a2d\u5b9a\u306b\u304a\u3044\u3066\u3001\u5c64\u3054\u3068\u306b\u7570\u306a\u308b\u5b66\u7fd2\u7387\u3092\u8a2d\u5b9a\u3057\u305f\u30d5\u30a1\u30a4\u30f3\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u3092\u5b9f\u88c5\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308b  \n3.\u5b66\u7fd2\u3057\u305f\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4fdd\u5b58\u30fb\u30ed\u30fc\u30c9\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308b ","b414fe34":"# DataLoader\u3092\u4f5c\u6210","32ad1a60":"# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u8868\u793a","123cd3e0":"# \u5b66\u7fd2\u3057\u305f\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4fdd\u5b58\u30fb\u30ed\u30fc\u30c9","f4fb34f1":"# DataSet\u3092\u4f5c\u6210"}}