{"cell_type":{"0995d79c":"code","6748334e":"code","3ee0217e":"code","7f2e3975":"code","1f081de3":"code","56c1966e":"code","a3f1034d":"markdown","7970394d":"markdown","06d35cdc":"markdown"},"source":{"0995d79c":"import pandas as pd\n# load dataset into Pandas DataFrame\ndf = pd.read_csv(\"..\/input\/iris.csv\")\ndf.info()","6748334e":"from sklearn.preprocessing import StandardScaler\nfeatures = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n# Separating out the features\nx = df.loc[:, features].values\n# Separating out the target\ny = df.loc[:,['species']].values\n# Standardizing the features\nx = StandardScaler().fit_transform(x)","3ee0217e":"from sklearn.decomposition import PCA\npca = PCA(n_components=2)\nprincipalComponents = pca.fit_transform(x)\nprincipalDf = pd.DataFrame(data = principalComponents\n             , columns = ['principal component 1', 'principal component 2'])\n\n\nfinalDf = pd.concat([principalDf, df[['species']]], axis = 1)\n\nfinalDf.head()\n","7f2e3975":"#1st and 2nd PCs decomposition axis\nprint(pca.components_)\n","1f081de3":"#Variance explained by 1st and 2nd PCs\npca.explained_variance_ratio_\n# total variance explained by two PCs = 0.9580","56c1966e":"pca.get_precision()","a3f1034d":"### Principal Component Analysis","7970394d":"### Reading Iris Data","06d35cdc":"### Standardize the Data  \n- PCA is effected by scale so you need to scale the features in your data before applying PCA. \n- Use StandardScaler to help you standardize the dataset\u2019s features onto unit scale (mean = 0 and variance = 1) which is a requirement for the optimal performance of many machine learning algorithms. \n- If you want to see the negative effect not scaling your data can have, scikit-learn has a section on the effects of not standardizing your data."}}