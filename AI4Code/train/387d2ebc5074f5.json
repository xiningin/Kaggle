{"cell_type":{"0e13a7a6":"code","b3d24993":"code","37260567":"code","0af2d36d":"code","8d8ef15c":"code","62c18ff4":"code","a00421ad":"code","a1af324d":"code","3d435af9":"code","7cab1f8a":"code","3564fccd":"code","5ae01dab":"code","1a81bee0":"code","a42d0427":"code","7191c5cb":"code","bab8ebdf":"code","8c429e04":"code","d5fde374":"code","59e000e3":"code","fc9f83b7":"code","61fc53f8":"code","911be3d9":"code","8525617f":"markdown","5113d754":"markdown","9bc8cbdc":"markdown","352ce7f5":"markdown","43757200":"markdown","c9c558f2":"markdown","f521c522":"markdown"},"source":{"0e13a7a6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom skimage import io, transform\nfrom torch.utils.data import Dataset\nimport torch\nimport os\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as transforms\nfrom PIL import Image,ImageOps\nimport torchvision\nfrom torch import optim,nn\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport tqdm\nimport os\n\nimport warnings\nwarnings.filterwarnings('ignore')","b3d24993":"from util_grad import *","37260567":"## Define transfoms\nstandard_normalization = transforms.Normalize((0.5), (0.5))\ndata_transforms = transforms.Compose([transforms.RandomResizedCrop(256),\n                                      transforms.RandomHorizontalFlip(),\n                                     transforms.ToTensor(),\n                                     standard_normalization])\ndata_transforms_1 = transforms.Compose([transforms.RandomResizedCrop(256),\n                                     transforms.ToTensor(),\n                                     standard_normalization])","0af2d36d":"# Read Data\ndict_ = {0:\"Covid\",1:\"Lung_Opacity\",2:\"Normal\",3:\"Viral Pheumonia\"}\n\ndf = pd.read_csv(\"..\/input\/processed-csv\/data.csv\")\ndf = pd.concat([df,pd.get_dummies(df.tag)], axis=1)\n","8d8ef15c":"#make train, test and val set\n\ntrain, test = train_test_split(df,test_size=.2)\ntrain_, val = train_test_split(train,test_size=.2)","62c18ff4":"#reseting index\ntrain = train.reset_index(drop=True)\ntest = test.reset_index(drop=True)\ntrain_ = train_.reset_index(drop=True)\nval = val.reset_index(drop=True)","a00421ad":"from torch.utils.data import  WeightedRandomSampler\nclass_freq = torch.tensor(train_.tag.values).bincount()\nweight = 1 \/ class_freq\nsamples_weight = weight[train_.tag.values]\nsampler = WeightedRandomSampler(samples_weight, len(samples_weight), replacement=True)","a1af324d":"root_dir = \"..\/input\/covid19-radiography-database\/COVID-19_Radiography_Dataset\"\n\ntrainset = Xray_dataset(train,root_dir,transform = data_transforms)\ntrain_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n\ntestset = Xray_dataset(test,root_dir,transform = data_transforms_1)\ntest_loader = DataLoader(testset, batch_size=32, shuffle=True)\n\ntrainset_ = Xray_dataset(train_,root_dir,transform = data_transforms)\ntrain_loader_ = DataLoader(trainset_, batch_size=32, sampler=sampler)\n\nvalset = Xray_dataset(val,root_dir,transform = data_transforms)\nval_loader = DataLoader(valset, batch_size=32, shuffle=True)\n\nuse_cuda = torch.cuda.is_available()\nnum_classes = 4\n\nloaders = {\"train\": train_loader_,\n           \"test\": test_loader,\n           \"val\": val_loader}","3d435af9":"model = torchvision.models.resnet18(pretrained = True, progress = True)","7cab1f8a":"model.fc = nn.Linear(in_features=512, out_features=num_classes, bias=True)\nif use_cuda:\n    model = model.cuda()","3564fccd":"## Define Loss and optim\noptimizer = optim.Adam(model.parameters(), lr=3e-5)\ncriterion = nn.CrossEntropyLoss()","5ae01dab":"## Train\ntrain_model(20, loaders, model, optimizer, criterion, use_cuda, 'model_transfer.pt');","1a81bee0":"model = torch.load(\".\/model_transfer.pt\")","a42d0427":"test_model(loaders,model,criterion,use_cuda)\nconf_met(model,test_loader)","7191c5cb":"from sklearn.metrics import classification_report\ndef conf_met(model,test_loader):\n    true = []\n    pred = []\n    test_loss = 0\n    for img,tag in tqdm.tqdm(test_loader):\n        img = img.cuda()\n        op = model(img)\n        #loss = criterion(output, target)\n        #test_loss = test_loss + ((1 \/ (batch_idx + 1)) * (loss.data - test_loss))\n        pred+= list(op.data.max(1, keepdim=True)[1].cpu().squeeze().data.numpy())\n        true += list(tag.data.numpy())\n\n    print(f\"\\nConfusion Metrix : \\n{classification_report(true,pred)}\")\nconf_met(model,test_loader)","bab8ebdf":"def grad(model,img,target_layer):\n    feture = []\n    def fet(m,i,o):\n        feture.append(o)\n    grad = []\n    def grd(m,i,o):\n        grad.append(o[0])\n    h = target_layer.register_backward_hook(grd)\n    g = target_layer.register_forward_hook(fet)\n    y = model(img)\n    y[:,y.argmax(dim=1).item()].backward()\n    h.remove()\n    g.remove()\n    \n    w = torch.mean(grad[-1],dim = [2,3])\n    cam = w[:,:,None,None]*feture[-1]\n    cam = torch.mean(cam,dim = 1).squeeze().detach().cpu()\n    cam = np.maximum(cam,0)\n    cam\/= torch.max(cam)\n    cam = cam.numpy()\n    cam = cv2.resize(cam,(256,256))\n    cam = np.uint8(255*cam)\n  \n    img = img.squeeze().cpu()\n\n    plt.imshow(torch.mean(img, dim = 0),cmap = 'gray')\n    plt.imshow(cam,alpha = min(0.4,)","8c429e04":"dict_[int(testset[10][1].numpy())]\n","d5fde374":"img  = testset[18][0].unsqueeze(0).cuda()\ntarget = testset[18][1]\nprint(dict_[int(target.numpy())])\ngrad(model,img,model.layer4[-1])","59e000e3":"img  = testset[15][0].unsqueeze(0).cuda()\ntarget = testset[15][1]\nprint(dict_[int(target.numpy())])\ngrad(model,img,model.layer4[-1])","fc9f83b7":"img  = testset[5][0].unsqueeze(0).cuda()\ntarget = testset[5][1]\nprint(dict_[int(target.numpy())])\ngrad(model,img,model.layer4[-1])","61fc53f8":"img  = testset[10][0].unsqueeze(0).cuda()\ntarget = testset[10][1]\nprint(dict_[int(target.numpy())])\ngrad(model,img,model.layer4[-1])","911be3d9":"a = np.array([[1,0],[0,1]])\nplt.imshow(a)","8525617f":"## Download and Prepare Neural Network","5113d754":"## Load the Saved Weights","9bc8cbdc":"## Test Model","352ce7f5":"# Covid 19 Chest X-Ray Analysis with GradCam\n\nIn this Notebook I use a pretrained `densenet121` for analysing Covid-19 Xrays and Visualise them using GradCam algorithm.","43757200":"## Train Model","c9c558f2":"## Read  and  Process  Data","f521c522":"## Draw GradCam Output\n\nGrad-CAM: Gradient-weighted Class Activation Mapping"}}