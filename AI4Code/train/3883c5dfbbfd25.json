{"cell_type":{"85df50c9":"code","11a9b5da":"code","24ef479b":"code","da775e97":"code","6d765fcd":"code","a6e4e96b":"code","0d6f3aa4":"code","3f39e4ba":"code","ec7640b8":"code","1483f8ca":"code","da17962a":"code","69fb1002":"code","7188a7ee":"code","fb34b994":"code","42c7cf07":"code","2555e378":"code","dc3fd6f5":"code","3fe4478b":"code","a8dd133f":"code","a75b4d2e":"code","47edec93":"code","248444f6":"code","afdd5e4e":"code","8a15d884":"code","6d8b2c3e":"code","29219520":"code","cb4c1dd3":"code","1de9cfc4":"code","9b2479d7":"code","5ac8bfd6":"code","5b551cf8":"code","967987cc":"code","a7f4faaa":"code","8559988d":"code","10c89bfe":"code","4eb2c809":"code","126f8672":"code","c4c98b83":"code","3717b370":"code","24820cdc":"markdown","0354b9de":"markdown","fc5b98f1":"markdown"},"source":{"85df50c9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom datetime import datetime\nimport seaborn as sns\nimport yaml\nfrom collections import Counter\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.model_selection import train_test_split, GridSearchCV,ShuffleSplit\nfrom sklearn.manifold import TSNE\nfrom sklearn.linear_model import RidgeClassifier\nfrom catboost import CatBoostClassifier\nimport plotly.express as xp\nimport plotly.graph_objects as go\nimport missingno\nimport os\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.datasets import make_blobs\nfrom sklearn import svm\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import tree\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\n#listing all the data and files\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n\n#extracting data from files\ndescription = yaml.load(open(f\"..\/input\/mymusicalprefrences\/Description.yaml\",'r'),Loader=yaml.FullLoader)\ntrain = pd.read_csv(\"..\/input\/mymusicalprefrences\/train.csv\")\ntest = pd.read_csv(\"..\/input\/mymusicalprefrences\/test.csv\")\ncombine = [train,test]\ndf = pd.concat(combine).reset_index(drop=True)\ndf","11a9b5da":"print(\"Shape of the data:\", df.shape)\nprint(df.info())\nprint(df.columns)","24ef479b":"df.columns = [column.strip() for column in df.columns]\ndf.columns","da775e97":"df.describe()","6d765fcd":"desc = pd.DataFrame(description)\ndesc","a6e4e96b":"df.isnull().sum()","0d6f3aa4":"#check missing values\nprint(df.Id[df.Artists.isnull()])\nprint(df.Id[df.Vocal.isnull()])\nprint(df.Id[df.Energy.isnull()])\nprint(df.Id[df.Dancebility.isnull()])\nprint(df.Id[df.Happiness.isnull()])","3f39e4ba":"df.iloc[df.Id[df.Artists.isnull()]]","ec7640b8":"df = df.dropna(subset=[\"Artists\"])\ndf","1483f8ca":"df.iloc[df.Id[df.Vocal.isnull()]]\n#we leave this because is in the test set!","da17962a":"df.isnull().sum()","69fb1002":"df.Category = df.Category.fillna(\"none\")\ndf.Category = df.Category.replace({0:\"dislike\", 1:\"like\"})\ndf.Country = df.Country.fillna(\"NA\")\ndf.Vocal = df.Vocal.fillna(\"N\")\ndf.Labels= df.Labels.fillna(\"NA\")\ndf.Version = df.Version.fillna(\"NA\")\ndf.Album_type = df.Album_type.fillna(\"NA\")\ndf.Album = df.Album.fillna(\"NA\")","7188a7ee":"numerical = {\"Duration\", \"Release_year\", \"BPM\", \"Energy\", \"Dancebility\", \"Happiness\"}\ncategorical = {\"Artists\", \"Track\", \"Version\", \"Artist_genres\", \"Album\", \"Album_type\", \"Labels\", \"Vocal\", \"Country\", \"Key\"}\n#sns.pairplot(df[list(numerical)+[\"Category\"]], hue=\"Category\")","fb34b994":"data = MinMaxScaler()\ndf[['BPM','Duration','Energy','Dancebility', 'Happiness']] = data.fit_transform(df[['BPM','Duration','Energy','Dancebility', 'Happiness']])\ndf","42c7cf07":"df.BPM.unique()","2555e378":"xp.scatter(x = df[\"Release_year\"], y=df['Track'], color = df['Category']) ","dc3fd6f5":"df[\"Release_decade\"] =  df[\"Release_year\"] - df[\"Release_year\"]%10\n#small sample of musics before 1980 - we group them\ndf.loc[df[\"Release_decade\"] < 1990, \"Release_decade\"] = 1980\n\n#group by!\nrelease = df.groupby([\"Release_decade\",\"Category\"], as_index=False).count()\nxp.bar(release,x=\"Release_decade\", y=\"Track\", color=\"Category\")","3fe4478b":"def split_to_onehot(df, col):\n    \"\"\"\n    This method converts features separated by '|' into one-hot vectors.\n    Additionally it drops unnecessary values, which present only in \n    test set \/ train set or have only one value.\n    \"\"\"\n    # Getting all unique ganres values.\n    unique = []\n    for i in df.index:\n        unique.extend(df.loc[i,col].split(\"|\"))\n    if \"\" in unique:\n        unique.remove(\"\")\n    unique = list(set(unique))\n    \n    # Putting values into binary form \n    onehot = df.loc[:,[\"Category\"]]\n    onehot[unique] = np.zeros((len(unique),), dtype = np.int8)\n    for i in df.index:\n        g = set(df.loc[i,col].split(\"|\"))\n        for j in g:\n            if j!=\"\":\n                onehot.loc[i,j] = 1\n                \n    # Dropping unnecessary values            \n    _a = onehot.groupby(\"Category\").sum()\n    only_one = list(_a.sum()[_a.sum()==1].index)\n    only_train = list(_a.loc[\"none\"][_a.loc[\"none\"]==0].index)\n    only_test = list(_a.loc[[\"like\",'dislike']].sum()[_a.loc[[\"like\",'dislike']].sum()==0].index)\n    _a = set(only_one + only_train + only_test)\n    onehot = onehot.drop(_a, axis=1)\n    \n    return onehot\n\ndef onehot_to_tsne2(df, title):\n    \"\"\"\n    This method converts one-hot representation into two tsne values.\n    Such operation is needed to shrink the dimentionality of the dataset\n    \"\"\"\n    onehot = df.drop(\"Category\",axis=1)\n    embedding = TSNE(n_components=2, init=\"pca\")\n    embedded = embedding.fit_transform(onehot)\n    embedded = pd.DataFrame(embedded,columns=[f\"{title}_tsne1\",f\"{title}_tsne2\"])\n    return embedded\n\ndef plot_commulative_onehot(onehot):\n    \"\"\"\n    Method of plotting commulative values of the one hot feature representation\n    \"\"\"\n    _df = onehot.groupby(\"Category\").sum()\n    fig = go.Figure()\n    for i in range(len(_df.index)):\n        k = _df.index[i]\n        x,y=[],[]\n        for g in _df.columns:\n            if _df.loc[k,g]!=0:\n                x.append(g)\n                y.append(_df.loc[k,g])\n        fig.add_trace(go.Bar(x=x, y=y,name=k))\n    fig.show()","a8dd133f":"description\ndf.isnull().sum()","a75b4d2e":"df = df.drop(\"Version\",axis=1)\ndf = df.drop(\"Album_type\",axis=1)\n#version = set(df[\"Version\"])\n#df[list(version)] = OneHotEncoder().fit_transform(df[[\"Version\"]]).toarray()\n#df = df.drop([\"Version\", \"NA\"],axis=1)\n\n#a_type = set(df[\"Album_type\"])\n#df[list(a_type)] = OneHotEncoder().fit_transform(df[[\"Album_type\"]]).toarray()\n#df = df.drop([\"Album_type\", \"NA\"],axis=1)\n#df","47edec93":"#df = df.drop(\"Track\",axis = 1)\ndef enc(string):\n    return str(string)\n\ndf[\"Track\"] = df[\"Track\"].apply(enc)\nlabel_encoder = LabelEncoder()\ndf[\"Track\"] = label_encoder.fit_transform(df[\"Track\"])\ndf","248444f6":"def split(string):\n    return string.split(\" \")[1]\n\ndf[\"Major\"] = df[\"Key\"].apply(split)\ndf = df.drop(\"Key\",axis=1)\n\nfrom sklearn.preprocessing import LabelEncoder\ndef encoder(string):\n    if string ==\"Major\":\n        return  1\n    else:\n        return  0\ndf[\"Major\"] = df[\"Major\"].apply(encoder)\ndf","afdd5e4e":"#df = pd.get_dummies(df, \"Vocal\")\ndf[\"Vocal\"] = df[\"Vocal\"].apply(enc)\nlist_v = []\nfor i in range(len(df)):\n    voc = df.iloc[i][\"Vocal\"]\n    if voc == 'M':\n        list_v.append([1,0])\n    elif voc == 'F':\n        list_v.append([0,1])\n    elif voc =='F|M':\n        list_v.append([1,1])\n    else:\n        list_v.append([0,0])\n        \ndf[[\"Vocal_M\", \"Vocal_F\"]]= list_v\ndf = df.drop(\"Vocal\", axis = 1)","8a15d884":"genres_onehot = split_to_onehot(df, \"Artists_Genres\")\nplot_commulative_onehot(genres_onehot)\ngenres = onehot_to_tsne2(genres_onehot, \"Genres\")\ndf = pd.concat([df, genres],axis=1)\ndf = df.drop(\"Artists_Genres\",axis = 1)\ndf","6d8b2c3e":"df.isnull().sum()\ndf = df.dropna(subset=[\"Category\"])","29219520":"df[\"Labels\"] = df[\"Labels\"].apply(enc)\ndf\nlabels_onehot = split_to_onehot(df, \"Labels\")\nplot_commulative_onehot(labels_onehot)\nlabels = onehot_to_tsne2(labels_onehot, \"Labels\")\ndf = pd.concat([df, labels],axis=1)\ndf = df.drop(\"Labels\",axis = 1)\ndf","cb4c1dd3":"df[\"Album\"] = df[\"Album\"].apply(enc)\nalbum_onehot = split_to_onehot(df, \"Album\")\nplot_commulative_onehot(album_onehot)\nalbum = onehot_to_tsne2(album_onehot, \"Album\")\ndf = pd.concat([df, album],axis=1)\ndf = df.drop(\"Album\",axis = 1)\ndf","1de9cfc4":"df[\"Country\"] = df[\"Country\"].apply(enc)\ncountry_onehot = split_to_onehot(df, \"Country\")\nplot_commulative_onehot(country_onehot)\ncountry = onehot_to_tsne2(album_onehot, \"Country\")\ndf = pd.concat([df, country],axis=1)\ndf = df.drop(\"Country\",axis = 1)\ndf = df.drop(\"Id\",axis=1)\ndf\n","9b2479d7":"#save artists who are appearing often\ndf[\"Artists\"] = df[\"Artists\"].apply(enc)\nartists = []\ndf.index\nfor i in range(len(df)):\n    for elt in df.loc[i,\"Artists\"].split(\"|\"):\n        artists.append(elt)\n\n\ntreshold = 3 \nothers = Counter(artists)\nlist_others = []\nfor artist in others:\n    if others[artist] <= treshold:\n        list_others.append(artist)\nprint(list_others)\n\n#drop artists that are just in test or train set\ntestGroup = df.loc[df.Category == 'none']\n\ntrain = []\ntest = []\nfor i in range(len(df)-len(testGroup)):\n    for elt in df.loc[i,\"Artists\"].split(\"|\"):\n        train.append(elt)\nfor i in range(len(df)-len(testGroup), len(df)):\n    for elt in df.loc[i,\"Artists\"].split(\"|\"):\n        test.append(elt)\n        \njust_train = set(train)-set(test)\njust_test = set(test)-set(train)\nprint(len(just_train))\nprint(len(just_test))\n\nartists = list(set(artists)-set(list_others)-just_test-just_train)\nprint(len(artists))\nlist_others = set(list_others) | just_test | just_train\nprint(len(list_others))","5ac8bfd6":"res = []\ndef prune(x):\n    vector = np.zeros(len(artists)+1)\n    list_ = []\n    for elt in x.split(\"|\"):\n        list_.append(elt)\n        \n    for i in range(len(artists)):\n        if artists[i] in list_:\n            vector[i] = 1\n        else:\n            vector[i] = 0\n    if sum(vector) == 0:\n        vector[len(artists)] = 1\n    res.append(vector)\n    \n\ndf[\"Artists\"].apply(prune)\nartists_onehot = pd.DataFrame(res, columns = artists+[\"Others\"])\nartists_onehot","5b551cf8":"df[\"Other_Artists\"] = artists_onehot[\"Others\"]\nartists_onehot[\"Category\"] = df[\"Category\"]\nartists_onehot = artists_onehot.drop(\"Others\", axis = 1)\nplot_commulative_onehot(artists_onehot)\nartists_ = onehot_to_tsne2(artists_onehot, \"Artists\")\ndf = pd.concat([df, artists_],axis=1)\ndf = df.drop(\"Artists\",axis = 1)\ndf","967987cc":"df = df.dropna(subset=[\"Genres_tsne1\"])\ndf.isnull().sum()","a7f4faaa":"testGroup\ntrainGroup_size = len(df)-len(testGroup)\ntrainGroup = df.iloc[:trainGroup_size]\nX_train = trainGroup.iloc[:,1:]\ny_train = trainGroup[\"Category\"]\ny_train =  y_train.replace({\"dislike\":0, \"like\":1})\ny_train","8559988d":"testGroup = df.iloc[trainGroup_size:,:]\nX_test = testGroup.iloc[:,1:]\nX_test.head(5)","10c89bfe":"#X_train, X_test, y_train, y_test = train_test_split(X_train,y_train,test_size=0.2,random_state=42,shuffle=True)","4eb2c809":"clf = tree.DecisionTreeClassifier()\nclf = clf.fit(X_train,y_train)\ny_pred = clf.predict(X_test)\ny_pred\n\n#svclassifier = SVC(kernel='linear')\n#svclassifier.fit(X_train, y_train)\n#y_pred = svclassifier.predict(X_test)\n#SVM_acc = accuracy_score(y_pred, y_test)\n#print(SVM_acc)\n\n#clf = tree.DecisionTreeClassifier()\n#clf = clf.fit(X_train,y_train)\n#y_pred_dt = clf.predict(X_test)\n#DT_acc = accuracy_score(y_pred_dt, y_test)\n#print(DT_acc)\n\n#rf = RandomForestClassifier()\n#rf.fit(X_train,y_train)\n#y_pred_rf = rf.predict(X_test)\n#y_pred_rf\n#RF_acc = accuracy_score(y_pred_rf, y_test)\n#print(RF_acc)\n\n\n#KN = KNeighborsClassifier()\n#KN.fit(X_train,y_train)\n#y_pred_kn = KN.predict(X_test)\n#KNN_acc = accuracy_score(y_pred_kn, y_test)\n#print(KNN_acc)\n\n#svclassifier1 = SVC(kernel='sigmoid')\n#svclassifier1.fit(X_train, y_train)\n#y_pred_NL = svclassifier1.predict(X_test)\n#SVM_NL_acc = accuracy_score(y_pred_NL, y_test)\n#print(SVM_NL_acc)\n\n#svclassifier1 = SVC(kernel='rbf')\n#svclassifier1.fit(X_train, y_train)\n#y_pred_NL = svclassifier1.predict(X_test)\n#SVM_NL_acc = accuracy_score(y_pred_NL, y_test)\n#print(SVM_NL_acc)","126f8672":"#model = CatBoostClassifier()\n#model.fit(X_train,y_train)\n#y_pred = model.predict(X_test)\n#y_pred\n#print(accuracy_score(y_pred, y_test))","c4c98b83":"sample = pd.read_csv(f\"..\/input\/mymusicalprefrences\/sample_submition.csv\")\nsample[\"Category\"] = y_pred\n#sample[\"Category\"] = (sample[\"Category\"]==\"like\").astype(int)","3717b370":"sample.to_csv(\"deploy.csv\", index=False)","24820cdc":"# Categorical data","0354b9de":"Imported methods from final project:example solution because I do not know how to process values separated with \"|\"\"","fc5b98f1":"# Numerical data"}}