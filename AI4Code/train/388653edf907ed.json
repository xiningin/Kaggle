{"cell_type":{"d2367493":"code","b6eb6072":"code","d3eb0702":"code","19a627bd":"code","f94e568d":"code","7b4bdb1a":"code","c3bb311a":"code","06badf16":"code","884e9160":"code","15edab12":"code","7ae937a5":"code","6462c39f":"code","a6b4617c":"code","5af204ea":"code","77c7d463":"code","52252f17":"code","56346bdf":"code","b16f641e":"code","07f2f851":"code","4402df88":"code","b9d65ce5":"code","1bd6d01d":"code","356769f2":"code","e92e6e9c":"markdown","97450ab4":"markdown","46f924ab":"markdown","e855a942":"markdown","c87daa56":"markdown","509df511":"markdown","06c7d4a3":"markdown","466c48a7":"markdown","0c20df3a":"markdown","119d95e7":"markdown","3d1ce732":"markdown","7d3adb79":"markdown","fa041791":"markdown","b88529d4":"markdown"},"source":{"d2367493":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random\nimport matplotlib.pyplot as plt\nfrom tensorflow.python.keras import backend as K\nfrom tensorflow.python.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, BatchNormalization, Activation, Dropout\nfrom tensorflow.python.keras.optimizers import Adadelta, Nadam ,Adam\nfrom tensorflow.python.keras.models import Model, load_model\nfrom tensorflow.python.keras.utils import multi_gpu_model, plot_model ,Sequence\nfrom tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.python.keras.preprocessing.image import load_img,img_to_array\nimport tensorflow as tf\nfrom tensorflow.python.keras.losses import binary_crossentropy\nfrom scipy.ndimage import morphology as mp\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nfrom glob import glob  # for getting list paths of image and labels\nfrom random import choice,sample\nfrom matplotlib import pyplot as plt\nimport cv2 # saving and loading images\n\n# Any results you write to the current directory are saved as output.","b6eb6072":"train_img_dir = '\/kaggle\/input\/back-remove\/binary_segment\/binary_segment\/train\/images\/'\ntrain_mask_dir = '\/kaggle\/input\/back-remove\/binary_segment\/binary_segment\/train\/masks\/'\ntrain_imgs = os.listdir(train_img_dir)\ntrain_masks = os.listdir(train_mask_dir)\nprint(len(train_imgs))\nprint(len(train_masks))","d3eb0702":"train_imgs.sort() # sorting image and label so that they both get alinged on the same index\ntrain_masks.sort()\nfor i in range(len(train_imgs)):\n    assert train_imgs[i] == train_masks[i] , \"image and mask are not matching\"","19a627bd":"val_img_dir = '\/kaggle\/input\/back-remove\/binary_segment\/binary_segment\/val\/images\/'\nval_mask_dir = '\/kaggle\/input\/back-remove\/binary_segment\/binary_segment\/val\/masks\/'\nval_imgs = os.listdir(val_img_dir)\nval_masks = os.listdir(val_mask_dir)\nprint(len(val_imgs))\nprint(len(val_masks))","f94e568d":"val_imgs.sort()\nval_masks.sort()\nfor i in range(len(val_imgs)):\n    assert val_imgs[i].split('.')[0] == val_masks[i].split('.')[0] , \"image and mask are not matching\"","7b4bdb1a":"class DataGenerator(Sequence):\n    'Generates data for Keras'\n    \n    def __init__(self, images,image_dir,labels,label_dir ,batch_size=16, dim=(224,224,3) ,shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.images = images\n        self.image_dir = image_dir\n        self.labels = labels\n        self.label_dir = label_dir\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.images) \/ self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [k for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.images))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        batch_imgs = list()\n        batch_labels = list()\n\n        # Generate data\n        for i in list_IDs_temp:\n            # Store sample\n            img = load_img(self.image_dir + self.images[i] ,target_size=self.dim)\n            img = img_to_array(img)\/255.\n            batch_imgs.append(img)\n           # Store class\n            label = load_img(self.label_dir + self.labels[i] ,target_size=self.dim)\n            label = img_to_array(label)[:,:,0]\n            label = label != 0\n            label = mp.binary_erosion(mp.binary_erosion(label))\n            label = mp.binary_dilation(mp.binary_dilation(mp.binary_dilation(label)))\n            label = np.expand_dims((label)*1 , axis=2)\n            batch_labels.append(label)\n            \n        return np.array(batch_imgs) ,np.array(batch_labels)","c3bb311a":"train_generator = DataGenerator(train_imgs,train_img_dir,train_masks,train_mask_dir,batch_size=36, dim=(224,224,3) ,shuffle=True)\ntrain_steps = train_generator.__len__()\ntrain_steps","06badf16":"X,y = train_generator.__getitem__(5)\nt = 27\nplt.figure(figsize=(8,8))\nplt.subplot(121)\nplt.imshow(X[t])\nplt.subplot(122)\nplt.imshow(np.reshape(y[t],(224,224)))\n#print(np.unique(y[t],return_counts=True))","884e9160":"val_generator = DataGenerator(val_imgs,val_img_dir,val_masks,val_mask_dir,batch_size=36, dim=(224,224,3) ,shuffle=True)\nval_steps = val_generator.__len__()\nval_steps","15edab12":"def conv_block(tensor, nfilters, size=3, padding='same', initializer=\"he_normal\"):\n    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(tensor)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    x = Conv2D(filters=nfilters, kernel_size=(size, size), padding=padding, kernel_initializer=initializer)(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n    return x\n\n\ndef deconv_block(tensor, residual, nfilters, size=3, padding='same', strides=(2, 2)):\n    y = Conv2DTranspose(nfilters, kernel_size=(size, size), strides=strides, padding=padding)(tensor)\n    y = concatenate([y, residual], axis=3)\n    y = conv_block(y, nfilters)\n    return y\n\n\ndef Unet(h, w, filters):\n# down\n    input_layer = Input(shape=(h, w, 3), name='image_input')\n    conv1 = conv_block(input_layer, nfilters=filters)\n    conv1_out = MaxPooling2D(pool_size=(2, 2))(conv1)\n    conv2 = conv_block(conv1_out, nfilters=filters*2)\n    conv2_out = MaxPooling2D(pool_size=(2, 2))(conv2)\n    conv3 = conv_block(conv2_out, nfilters=filters*4)\n    conv3_out = MaxPooling2D(pool_size=(2, 2))(conv3)\n    conv4 = conv_block(conv3_out, nfilters=filters*8)\n    conv4_out = MaxPooling2D(pool_size=(2, 2))(conv4)\n    conv4_out = Dropout(0.5)(conv4_out)\n    conv5 = conv_block(conv4_out, nfilters=filters*16)\n    conv5 = Dropout(0.5)(conv5)\n# up\n    deconv6 = deconv_block(conv5, residual=conv4, nfilters=filters*8)\n    deconv6 = Dropout(0.5)(deconv6)\n    deconv7 = deconv_block(deconv6, residual=conv3, nfilters=filters*4)\n    deconv7 = Dropout(0.5)(deconv7) \n    deconv8 = deconv_block(deconv7, residual=conv2, nfilters=filters*2)\n    deconv9 = deconv_block(deconv8, residual=conv1, nfilters=filters)\n    output_layer = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(deconv9)\n    # using sigmoid activation for binary classification\n    model = Model(inputs=input_layer, outputs=output_layer, name='Unet')\n    return model","7ae937a5":"model = Unet(224 , 224 , 34)\n#model.summary()","6462c39f":"def jaccard_distance_loss(y_true, y_pred,smooth = 100):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n    jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n    return (1 - jac) * smooth\n\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + K.epsilon()) \/ (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())","a6b4617c":"model.compile(optimizer='adam', loss=jaccard_distance_loss ,metrics = [dice_coef, 'accuracy'])\nmc = ModelCheckpoint(mode='max', filepath='top-weights.h5', monitor='val_dice_coef',save_best_only='True', save_weights_only='True', verbose=1)\nes = EarlyStopping(mode='max', monitor='val_dice_coef', patience=3, verbose=1)\ncallbacks = [mc, es]\nmodel.metrics_names","5af204ea":"results = model.fit_generator(train_generator, steps_per_epoch=train_steps,epochs=8,callbacks=callbacks,validation_data=val_generator,validation_steps=val_steps)","77c7d463":"plt.figure(figsize=(8, 8))\nplt.title(\"Learning curve\")\nplt.plot(results.history[\"loss\"], label=\"loss\")\nplt.plot(results.history[\"val_loss\"], label=\"val_loss\")\nplt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"log_loss\")\nplt.legend();","52252f17":"#model.load_weights('\/kaggle\/input\/background-removal\/weights.08-0.97.h5')\n#k = model.evaluate_generator(generator=val_generator,steps=val_steps)","56346bdf":"test_image = glob('\/kaggle\/input\/test-data\/test_images\/test_images\/*')\n#mask_set = glob('\/kaggle\/input\/back-remove\/binary_segment\/binary_segment\/train\/masks\/1004.jpg')\n#len(test_image)","b16f641e":"# def jaccard_distance(y_true, y_pred, smooth=100):\n#     intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n#     sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n#     jac = (intersection + smooth) \/ (sum_ - intersection + smooth)\n#     return (1 - jac) * smooth\n\n# def jaccard_acc(y_true, y_pred):\n#     intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n#     sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n#     jac = intersection \/ sum_ - intersection\n#     return jac\n\n# img = img_to_array(load_img(test_image[0]))\n# mask = img_to_array(load_img(mask_set[0]))\n# plt.imshow(mask\/255.)\n\n# jaccard_distance_loss(mask[:,:,0],mask[:,:,0])","07f2f851":"def make_prediction(model,image,shape):\n    img = img_to_array(load_img(image,target_size=shape))\n    img = np.expand_dims(img,axis=0)\/255.\n    mask = model.predict(img)\n    \n    mask = mask[0] > 0.5\n    print(np.unique(mask,return_counts=True))\n    mask = np.reshape(mask,(224,224))\n    return mask                       ","4402df88":"image = test_image[11]\nimg = img_to_array(load_img(image))\nplt.imshow(img\/255.)\nimg.shape","b9d65ce5":"mask = make_prediction(model,image,(224,224,3))\nplt.imshow(mask)","1bd6d01d":"h,w = img.shape[:2]\nmask_resized = cv2.resize(np.uint8(mask*1),(w,h))\nmask_resized = mask_resized != 0\n#print(np.unique(mask_resized,return_counts=True))\nsegment = np.zeros((h,w,3))\nsegment[:,:,0] = img[:,:,0]*mask_resized\nsegment[:,:,1] = img[:,:,1]*mask_resized\nsegment[:,:,2] = img[:,:,2]*mask_resized\nsegment[np.where((segment == [0,0,0]).all(axis=2))] = [0,0,0]\n#img[np.where((img==[255,255,255]).all(axis=2))] = [0,0,0];","356769f2":"plt.figure(figsize=(8,8))\nplt.imshow(segment\/255.)","e92e6e9c":"# Background removal using Sementic Segmentation Network Unet\n\nIn this kernel i am trying to remove the area except the human. for this purpose i have used MHP(multihuman parsing ) dataset. https:\/\/lv-mhp.github.io\/\nI have already merged all the label files and classes into single binary class file which contains only two labels\n1 for pixels which contains human | 0 for pixel belongs to background.\nNote - Even though no of images present is more than we need, some of image label contain irregularities.\nsome of the pixel belongs to foreground may labeled as background due to dataset only label human parts and dress making everything else as unknown class.\n\nwe are going to start our code with importing required keras and utility packages\n\n\n","97450ab4":"# Here we define keras custom metric for the loss and accuracy computation\n\nJaccard distance loss - this loss help to get rid of the side effects of unbalanced class label in a image (like - 80% background , 20 % human )  https:\/\/en.wikipedia.org\/wiki\/Jaccard_index\n\ndice_coef - To evaluate accuracy of the segmentation.   https:\/\/en.wikipedia.org\/wiki\/S%C3%B8rensen%E2%80%93Dice_coefficient","46f924ab":"**Now use the mask to get the segmented image**","e855a942":"# Now its time to make some predictions","c87daa56":"**After defining generator lets check the some of the dataset it generates for the training and visualize them**","509df511":" **Now we need to define our training and validation generator using above implimented class.**","06c7d4a3":"# After preparing input pipeline we are going to define our U-net model\n\nhere we first define down convolution (encoder ) and up convolution layer (decoder) and stack them up with a short circuting features from down sampling to corresponding up sampling\n\nfull detail of the  architecture is present here - https:\/\/arxiv.org\/abs\/1505.04597","466c48a7":"** Visualizing train and val loss w.r.t epoch**","0c20df3a":"**Repeat same steps for validation dataset**","119d95e7":"# listing image and their respective labels \nalso here we are asserting the presence of label file w.r.t each image.","3d1ce732":"# Here we impliment keras custom data generator to get batch images and labels without loading whole dataset in the active memory\n","7d3adb79":"# Defining callbacks and compile model with adam optimiser with default learning rate.","fa041791":"**Function to make prediction \nNote:-  Dont forget to Normalise image dataset (here i divided every pixel by 255. )**","b88529d4":"# Now finally train our model with above configuration and train data generator."}}