{"cell_type":{"19009866":"code","6482d5ff":"code","4e7f171a":"code","d382a142":"code","068c8431":"code","d12bbff8":"code","339150dc":"code","8bd759eb":"code","a59768c9":"code","7fc37562":"code","fa054447":"markdown","d2a12e2e":"markdown","15701855":"markdown","fe832f9e":"markdown","291ff636":"markdown","41c604ef":"markdown","2cf84065":"markdown","23001050":"markdown","6388b2e0":"markdown"},"source":{"19009866":"import os\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom time import sleep\nfrom random import shuffle\nfrom tqdm import tqdm\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom matplotlib import pyplot as plt\nfrom IPython.display import clear_output\n\n# DeepLearning with Keras libraries!\nfrom keras.callbacks import Callback\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input ,Dense, Conv2D, BatchNormalization, MaxPooling2D, UpSampling2D, Flatten, Reshape, concatenate","6482d5ff":"root = '..\/input\/dog vs cat\/dataset\/'\nLABELS = ['CAT', 'DOG']","4e7f171a":"class PlotLearning(Callback):\n    def on_train_begin(self, logs={}):\n        self.i = 0\n        self.x = []\n        self.losses = []\n        self.val_losses = []\n        self.acc = []\n        self.val_acc = []\n        self.fig = plt.figure()\n        \n        self.logs = []\n        \n\n    def on_epoch_end(self, epoch, logs={}):\n        \n        self.logs.append(logs)\n        self.x.append(self.i)\n        self.losses.append(logs.get('loss'))\n        self.val_losses.append(logs.get('val_loss'))\n        self.acc.append(logs.get('acc'))\n        self.val_acc.append(logs.get('val_acc'))\n        self.i += 1\n        f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n        \n        clear_output(wait=True)\n        \n        ax1.set_yscale('Log')\n        ax1.plot(self.x, self.losses, label=\"loss\")\n        ax1.plot(self.x, self.val_losses, label=\"val_loss\")\n        ax1.legend()\n        \n        ax2.plot(self.x, self.acc, label=\"acc\")\n        ax2.plot(self.x, self.val_acc, label=\"val_acc\")\n        ax2.legend()\n        \n        plt.show()\n        \n        \nplot = PlotLearning()","d382a142":"training_set = []\ntest_set = []\n\n#print('Loading Training Data...')\nfor animal in os.listdir(root+'training_set\/'):\n    for file in tqdm(os.listdir(root+'training_set\/'+animal)):\n        img_data = imread(root+'training_set\/'+animal+'\/'+file)\n        img_data = resize(img_data, output_shape=(128,128))\n        training_set.append([img_data, [1, 0] if animal == 'cats' else [0,1]])\n        \n#print('Loading Testing Data...')\nfor animal in os.listdir(root+'test_set\/'):\n    for file in tqdm(os.listdir(root+'test_set\/'+animal)):\n        img_data = imread(root+'test_set\/'+animal+'\/'+file)\n        img_data = resize(img_data, output_shape=(128,128))\n        test_set.append([img_data, [1, 0] if animal == 'cats' else [0,1]])\n        \n","068c8431":"plt.hist(np.argmax(Y, axis=1))\nplt.title(\"0-Cat & 1-Dog\")\nplt.show()","d12bbff8":"shuffle(training_set)\nshuffle(test_set)\nX, X_ = [], []\nY, Y_ = [], []\n\nfor i in tqdm(training_set):\n    X.append(i[0])\n    Y.append(i[1])\n\nfor i in tqdm(test_set):\n    X_.append(i[0])\n    Y_.append(i[1])\n\ndel training_set\ndel test_set\n\nX, Y, X_, Y_ = np.array(X)\/255, np.array(Y), np.array(X_)\/255, np.array(Y_)","339150dc":"input_layer = Input(shape=(128, 128, 3))\n\nx1 = Conv2D(16, (3,3), activation='relu')(input_layer)\nx2 = Conv2D(16, (3,3), activation='relu')(input_layer)\n\nx1 = MaxPooling2D((3,3))(x1)\nx2 = MaxPooling2D((4,4))(x2)\n\nx1 = BatchNormalization()(x1)\nx2 = BatchNormalization()(x2)\n\nx1 = Conv2D(32, (3,3), activation='relu')(x1)\nx2 = Conv2D(32, (3,3), activation='relu')(x2)\n\nx1 = MaxPooling2D((3,3))(x1)\nx2 = MaxPooling2D((4,4))(x2)\n\nx1 = BatchNormalization()(x1)\nx2 = BatchNormalization()(x2)\n\nx1 = Flatten()(x1)\nx2 = Flatten()(x2)\n\nx = concatenate([x1, x2]) # All Branches JOined to `x` node\n\nx = Dense(1024, activation='relu')(x)\n\noutput_layer = Dense(2, activation='softmax', name='output_layer')(x)\n\nmodel = Model(inputs=input_layer, outputs=output_layer)\n\n\n#model.build(input_shape=(None ,128 ,128 ,3))\nmodel.compile(\n    optimizer='Adadelta',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()","8bd759eb":"from IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\n\nSVG(model_to_dot(model).create(prog='dot', format='svg'))","a59768c9":"model.fit(X, Y, epochs=20, validation_data=(X,Y), batch_size=100, callbacks=[plot])","7fc37562":"model.save('my_model.h5')","fa054447":"**Custom Callback**","d2a12e2e":"**Fitting Model!**","15701855":"> The Below code will plot the structure of model, which might look fairly complex, but is better for this problem.","fe832f9e":"**CONSTANTS DECLARED HERE.**","291ff636":"**LOADING DATASET**","41c604ef":"**!!BEST MODEL EVER!!**","2cf84065":"**IMPORT LIBRARIES HERE.**","23001050":"**SHUFFLING DATA MANUALLY JUST TO BE EXTRA SURE**","6388b2e0":"> As the number of cats and dogs are almost same in training set, so our training will be\nUNBIASED, which is great!"}}