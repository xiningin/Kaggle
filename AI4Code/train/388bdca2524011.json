{"cell_type":{"d6b419d0":"code","747d6e4d":"code","8d1ced66":"code","27b19b0d":"code","5e3334c0":"code","63574f45":"code","48486038":"code","08fd2245":"code","8195bdce":"code","b9d4eaf0":"code","a6fdba3e":"markdown","50ac0a7d":"markdown","4b577ef3":"markdown","cedec63c":"markdown","c7af3433":"markdown","fcd93362":"markdown","b1ca9996":"markdown","b8aca05f":"markdown","1b5d04a9":"markdown"},"source":{"d6b419d0":"import pandas as pd\nimport numpy as np\nimport random\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import Dense, Dropout, Activation\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback, ReduceLROnPlateau\nfrom sklearn.preprocessing import StandardScaler  \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nseed_everything(2020)    ","747d6e4d":"df = pd.read_excel('..\/input\/datarobot-ai-academy-deep-learning-for-dic\/sales_prediction.xlsx')\n# Cleasing\ndf = df[df['Sales']>0].reset_index(drop=True)\ndf['Holiday'] = df['Holiday'].map(lambda x: 0 if x=='No' else 1)\ndf['DestinationEvent'] = df['DestinationEvent'].map(lambda x: 0 if x=='No' else 1)\n# Calendar Feature\ndf['year'] = df['Date'].dt.year\ndf['quarter'] = df['Date'].dt.quarter\ndf['month'] = df['Date'].dt.month\ndf['weekofoyear'] = df['Date'].dt.weekofyear\ndf['dayoyear'] = df['Date'].dt.dayofyear\ndf['dayofweek'] = df['Date'].dt.dayofweek\ndf['weekend'] = (df['Date'].dt.weekday >=5).astype(int)\ndf['dayofmonth'] = df['Date'].dt.day\n# Lag Feature\ndf['Sales_lag7'] = df['Sales'].shift(7)\ndf['Num_Customers_lag7'] = df['Num_Customers'].shift(7)\ndf['Num_Employees_lag7'] = df['Num_Employees'].shift(7)\ndf['Pct_On_Sale_lag7'] = df['Pct_On_Sale'].shift(7)\ndf['Pct_Promotional_lag7'] = df['Pct_Promotional'].shift(7)\ndf['Returns_Pct_lag7'] = df['Returns_Pct'].shift(7)\n\ndisplay(df.head())\ndisplay(df.columns.values)","8d1ced66":"# \u7279\u5fb4\u91cf\nnum_cols = ['chrismas', 'blackfriday',\n       'Holiday', 'DestinationEvent','year', 'quarter', 'month',\n       'weekofoyear', 'dayoyear', 'dayofweek', 'weekend', 'dayofmonth',\n       'Sales_lag7', 'Num_Customers_lag7', 'Num_Employees_lag7',\n       'Pct_On_Sale_lag7', 'Pct_Promotional_lag7', 'Returns_Pct_lag7']\ntarget = ['Sales']\n\n# \u6b20\u640d\u5024\u88dc\u586b\ndf[num_cols] = df[num_cols].fillna(0)\n\n# \u6b63\u898f\u5316\nscaler = StandardScaler()\ndf[num_cols] = scaler.fit_transform(df[num_cols])","27b19b0d":"# \u8a13\u7df4\u3000\u691c\u5b9a\u3000\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u5206\u5272\ntrain = df[df['Date']<='2014-06-07']\nvalid = df[df['Date']>'2014-06-07'] \n\n# \u7279\u5fb4\u91cf\u3068\u30bf\u30fc\u30b2\u30c3\u30c8\ntrain_x_num,train_y = train[num_cols].values,train[target].values\nvalid_x_num,valid_y = valid[num_cols].values,valid[target].values\n\nprint (train_x_num.shape)\nprint (valid_x_num.shape)","5e3334c0":"def mlp(num_cols):\n    \"\"\"\n    \u6f14\u7fd2:Dropout\u3092\u5909\u66f4\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\n    \"\"\"\n    model = Sequential()\n    model.add(Dense(units=512, input_shape = (len(num_cols),), \n                    kernel_initializer='he_normal',activation='relu'))    \n    model.add(Dropout(0.2))\n    model.add(Dense(units=256,  kernel_initializer='he_normal',activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(units=32, kernel_initializer='he_normal', activation='relu'))     \n    model.add(Dropout(0.2))\n    model.add(Dense(1, activation='linear'))\n    model.compile(loss='mape', optimizer='adam', metrics=['mape']) \n    return model","63574f45":"filepath = \"mlp_best_model.hdf5\" \n\n\"\"\"\n\u6f14\u7fd2:patience\u3092\u5909\u66f4\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\n\"\"\"\nes = EarlyStopping(patience=2, mode='min', verbose=1) \n\ncheckpoint = ModelCheckpoint(monitor='val_loss',filepath=filepath, save_best_only=True, mode='auto') \n\nreduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', patience=2, factor=0.1, verbose=1, mode='min')\n\nmodel = mlp(num_cols)\n\n\"\"\"\n\u6f14\u7fd2:batch_size,epochs\u3092\u5909\u66f4\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\n\"\"\"\nhistory = model.fit(train_x_num, train_y, batch_size=32, epochs=100, validation_data=(valid_x_num, valid_y), \n                    callbacks=[es, checkpoint, reduce_lr_loss], verbose=1)","48486038":"def mean_absolute_percentage_error(y_true, y_pred): \n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100\n\n# load best model weights\nmodel.load_weights(filepath)\n\n# predict valid data\nvalid_pred = model.predict(valid_x_num, batch_size=32).reshape((-1,1))\nvalid_score = mean_absolute_percentage_error(valid_y,  valid_pred)\nprint ('valid mape:',valid_score)\n","08fd2245":"model.summary()","8195bdce":"plot_model(model, to_file='mlp.png')","b9d4eaf0":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(loss))\nplt.plot(epochs, loss, 'bo' ,label = 'training loss')\nplt.plot(epochs, val_loss, 'b' , label= 'validation loss')\nplt.title('Training and Validation loss')\nplt.legend()\nplt.show()","a6fdba3e":"# \u30e2\u30c7\u30eb\u306e\u8a13\u7df4","50ac0a7d":"# \u30c7\u30fc\u30bf\u524d\u51e6\u7406","4b577ef3":"# \u30e2\u30c7\u30eb\u8a55\u4fa1","cedec63c":"# \u30e2\u30c7\u30eb\u53ef\u8996\u5316","c7af3433":"# \u8a13\u7df4\u3001\u691c\u5b9a\u30c7\u30fc\u30bf\u3092\u4f5c\u6210","fcd93362":" # \u6b20\u640d\u5024\u51e6\u7406\u3068\u6b63\u898f\u5316","b1ca9996":"# \u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30dd\u30fc\u30c8 ","b8aca05f":"# \u8a13\u7df4\u5c65\u6b74\u53ef\u8996\u5316","1b5d04a9":"# MLP Sequential\u30e2\u30c7\u30eb\u3092\u5b9a\u7fa9\u3059\u308b"}}