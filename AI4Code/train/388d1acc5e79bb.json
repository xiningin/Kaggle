{"cell_type":{"f122a757":"code","5335a7b9":"code","a2507650":"code","209ef798":"code","71921281":"code","19ece614":"code","6a111de2":"code","7b7d91c9":"code","f2ec3309":"markdown"},"source":{"f122a757":"import warnings\nwarnings.simplefilter('ignore')\n\nimport gc\n\nimport numpy as np\nimport pandas as pd\npd.set_option('max_columns', None)\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import mean_squared_error\n\nimport joblib\nimport lightgbm as lgb\nimport pickle","5335a7b9":"%%time\n\ntrain = pd.read_parquet('..\/input\/ubiquant-parquet\/train_low_mem.parquet')\nprint(train.shape)\ntrain.head()","a2507650":"import numpy as np\nfrom sklearn.decomposition import PCA\nycol = 'target'\nfeature_names = list(filter(lambda x: x not in [ycol, 'row_id', 'time_id', 'investment_id'], train.columns))\npca = PCA(n_components=50)\npca.fit(train[feature_names])","209ef798":"filename = 'pca.sav'\npickle.dump(pca, open(filename, 'wb'))","71921281":"train[feature_names[:50]] = pca.transform(train[feature_names])","19ece614":"train.drop(feature_names[50:], axis=1, inplace = True)","6a111de2":"feature_names = list(filter(lambda x: x not in [ycol, 'row_id', 'time_id'], train.columns))","7b7d91c9":"\nparams = {'boosting_type': 'dart', 'categorical_column': 0, 'objective':'rmse',\n           'learning_rate': 0.1167477918474961,\n           'min_child_samples': 34, 'min_child_weight': 24.733795444735957,\n           'n_estimators': 182, 'n_jobs': -1, 'num_leaves': 268, 'reg_alpha': 2.479425579240586,\n           'reg_lambda': 0.2347046165637776, 'subsample': 0.46059222140633244}\nmodel = lgb.LGBMRegressor(**params)\n\ndf_importance_list = []\n\nkfold = KFold(n_splits=5, shuffle=True, random_state=2022)\nfor fold_id, (trn_idx, val_idx) in enumerate(kfold.split(train[feature_names], train[ycol])):\n    X_train = train.iloc[trn_idx][feature_names]\n    Y_train = train.iloc[trn_idx][ycol]\n    X_val = train.iloc[val_idx][feature_names]\n    Y_val = train.iloc[val_idx][ycol]\n    lgb_model = model.fit(X_train,\n                          Y_train,\n                          eval_names=['train', 'valid'],\n                          eval_set=[(X_train, Y_train), (X_val, Y_val)],\n                          verbose=100,\n                          eval_metric='rmse',\n                          early_stopping_rounds=10)\n    joblib.dump(lgb_model, f'lgb_{fold_id}.pkl')\n    df_importance = pd.DataFrame({\n        'column': feature_names,\n        'importance': lgb_model.feature_importances_,\n    })\n    df_importance_list.append(df_importance)\n    del lgb_model, X_train, Y_train, X_val, Y_val\n    gc.collect()","f2ec3309":"Mostly copied from Heng Zheng, simply added PCA and parquet run https:\/\/www.kaggle.com\/hengzheng\/lightgbm-5folds-baseline\nI just realized there is a leak, pca should be performed per fold. I'll fix it, please use future versions.\n"}}