{"cell_type":{"20a47005":"code","64a71080":"code","95d206b2":"code","428f3763":"code","dd072b8a":"code","30cace35":"code","bf5508f4":"code","11b1c77d":"code","ec98b271":"code","9b09a875":"code","ca28513e":"code","179fc589":"code","ff2ae0ec":"code","29440ad2":"code","5db86173":"code","0baaffe3":"code","fd3a00d7":"code","168d43a6":"code","a4b0a108":"code","c271ba22":"code","86ff2a0c":"code","aa8cf36d":"code","2edcadbe":"code","ec40a4dd":"code","bebaf001":"code","21ef5c51":"code","5c764423":"code","44772994":"markdown","d4d17911":"markdown","8772f766":"markdown","383c3f77":"markdown","af98dd65":"markdown","cf9f6802":"markdown","2e1e9597":"markdown","3074bb6e":"markdown"},"source":{"20a47005":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\nimport numpy as np\nimport pandas as pd\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt","64a71080":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n    \nprint(\"replocas: \", strategy.num_replicas_in_sync)","95d206b2":"# Get the GCS path\nGCS_PATH = KaggleDatasets().get_gcs_path('plant-pathology-2021-fgvc8')\nprint(GCS_PATH)\n\ntrain_path = GCS_PATH + '\/train_images\/'\nprint(train_path)","428f3763":"train_df = pd.read_csv('..\/input\/plant-pathology-2021-fgvc8\/train.csv')","dd072b8a":"train_df.head()","30cace35":"train_df['labels'].value_counts().to_frame()","bf5508f4":"labels2id = {\n    'scab': 0,\n    'healthy': 1,\n    'frog_eye_leaf_spot': 2,\n    'rust': 3,\n    'complex': 4,\n    'powdery_mildew': 5\n}\n\nid2labels = {v:k for k,v in labels2id.items()}\n\nlabel_classes = labels2id.keys()\n\ndef label_encoder(x : str):\n    return [1 if label in x.split(' ') else 0 for label in label_classes]\n\ntrain_df['labels'] = train_df['labels'].map(label_encoder)","11b1c77d":"train_df.head()","ec98b271":"image_size = [600,600]\nbatch_size = 16 * strategy.num_replicas_in_sync\nchannels = 3\nseed = 2021\nnum_classes = len(label_classes)\nAUTOTUNE = tf.data.experimental.AUTOTUNE","9b09a875":"image_file_path = np.array([train_path + i for i in train_df['image'].to_list()])\nlabels = train_df['labels'].to_numpy()","ca28513e":"from sklearn.model_selection import StratifiedShuffleSplit\n\ntrain_val_sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=seed)\n\nfor train_index, val_index in train_val_sss.split(image_file_path, labels):\n    train_path, val_path = image_file_path[train_index],image_file_path[val_index]\n    train_labels, val_labels = labels[train_index],labels[val_index]","179fc589":"print('train : ',len(train_path),'---',len(train_labels))\nprint('val : ',len(val_path),'---',len(val_labels))","ff2ae0ec":"train_labels[:3]","29440ad2":"train_labels = [tf.constant(x) for x in train_labels]\nval_labels = [tf.constant(x) for x in val_labels]","5db86173":"train_labels[:3]","0baaffe3":"def random_erasing(img, sl=0.1, sh=0.2, rl=0.4, p=0.3):\n    h = tf.shape(img)[0]\n    w = tf.shape(img)[1]\n    c = tf.shape(img)[2]\n    origin_area = tf.cast(h*w, tf.float32)\n\n    e_size_l = tf.cast(tf.round(tf.sqrt(origin_area * sl * rl)), tf.int32)\n    e_size_h = tf.cast(tf.round(tf.sqrt(origin_area * sh \/ rl)), tf.int32)\n\n    e_height_h = tf.minimum(e_size_h, h)\n    e_width_h = tf.minimum(e_size_h, w)\n\n    erase_height = tf.random.uniform(shape=[], minval=e_size_l, maxval=e_height_h, dtype=tf.int32)\n    erase_width = tf.random.uniform(shape=[], minval=e_size_l, maxval=e_width_h, dtype=tf.int32)\n\n    erase_area = tf.zeros(shape=[erase_height, erase_width, c])\n    erase_area = tf.cast(erase_area, tf.uint8)\n\n    pad_h = h - erase_height\n    pad_top = tf.random.uniform(shape=[], minval=0, maxval=pad_h, dtype=tf.int32)\n    pad_bottom = pad_h - pad_top\n\n    pad_w = w - erase_width\n    pad_left = tf.random.uniform(shape=[], minval=0, maxval=pad_w, dtype=tf.int32)\n    pad_right = pad_w - pad_left\n\n    erase_mask = tf.pad([erase_area], [[0,0],[pad_top, pad_bottom], [pad_left, pad_right], [0,0]], constant_values=1)\n    erase_mask = tf.squeeze(erase_mask, axis=0)\n    erased_img = tf.multiply(tf.cast(img,tf.float32), tf.cast(erase_mask, tf.float32))\n\n    return tf.cond(tf.random.uniform([], 0, 1) > p, lambda: tf.cast(img, img.dtype), lambda:  tf.cast(erased_img, img.dtype))","fd3a00d7":"def load_image(image_path, label):\n    image = tf.io.read_file(image_path)\n    image = tf.io.decode_jpeg(image, channels=channels)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize(image, image_size)\n    return image, label\n\n\naugmentation = keras.Sequential([\n    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n    layers.experimental.preprocessing.RandomRotation(factor=0.02),\n    layers.experimental.preprocessing.RandomZoom(height_factor=0.2, width_factor=0.2),\n])\n\ndef augment(image, label):\n    image = tf.expand_dims(image, axis=0)\n    image = augmentation(image)[0]\n    #image = tf.image.random_brightness(image, 0.2)\n    #image = tf.image.random_contrast(image, 0.5, 2.0)\n    #image = tf.image.random_saturation(image, 0.75, 1.25)\n    #image = tf.image.random_hue(image, 0.1)\n    image = random_erasing(image)\n    return image,label","168d43a6":"train_ds = tf.data.Dataset.from_tensor_slices((train_path,train_labels))\ntrain_ds = train_ds.map(load_image, num_parallel_calls=AUTOTUNE)\ntrain_ds = train_ds.map(augment, num_parallel_calls=AUTOTUNE)\ntrain_ds = train_ds.cache().shuffle(2048).batch(batch_size).prefetch(AUTOTUNE)\n\n\nval_ds = tf.data.Dataset.from_tensor_slices((val_path,val_labels))\nval_ds = val_ds.map(load_image, num_parallel_calls=AUTOTUNE)\nval_ds = val_ds.cache().batch(batch_size).prefetch(AUTOTUNE)","a4b0a108":"image,_ = next(iter(train_ds))\n\nplt.figure(figsize=(20,20))\n\nfor i in range(16):\n    plt.subplot(4,4,i+1)\n    plt.imshow((image[i].numpy() * 255).astype('uint8'))\n    plt.axis('off')\n\nplt.show()","c271ba22":"def plot_learning_curve(history):\n    history = history.history\n    metrics_names = ['loss','accuracy','precision','recall','f1_score']\n    plt.figure(figsize=(8, 35))\n    for i,name in enumerate(metrics_names):\n        plt.subplot(len(metrics_names),1,i+1)\n        plt.plot(history[name], label='training '+name)\n        plt.plot(history['val_'+name], label='validation '+name)\n        plt.legend(loc='lower right')\n        plt.ylabel(name)\n        plt.ylim([0,1])\n        plt.title('training and validation '+name)\n    plt.show()","86ff2a0c":"with strategy.scope():\n    DenseNet = keras.applications.EfficientNetB4(include_top=False)\n    model = keras.Sequential()\n    model.add(layers.Input(shape=[*image_size,channels]))\n    model.add(DenseNet)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dense(num_classes,activation='sigmoid'))\n\n    model.compile(\n        optimizer=keras.optimizers.Adam(lr=0.05),\n        loss=keras.losses.BinaryCrossentropy(),\n        metrics=[\n            'accuracy',\n            tf.keras.metrics.Precision(name='precision'),\n            tf.keras.metrics.Recall(name='recall'),\n            tfa.metrics.F1Score(num_classes=num_classes,average='macro',name='f1_score')\n        ]\n     )\n    \n    callbacks = [\n        # keras.callbacks.EarlyStopping(patience=10,verbose=1,restore_best_weights=True),\n        keras.callbacks.ReduceLROnPlateau(factor=0.5,patience=4,verbose=1,min_delta=0.00001,\n                                         monitor='val_f1_score',mode='max'),\n        keras.callbacks.ModelCheckpoint('EfficientNetB4-600.h5',monitor='val_f1_score',mode='max',\n                                        save_best_only=True,verbose=1)\n    ]\n\n    history = model.fit(train_ds,batch_size=batch_size,epochs=100,\n            validation_data=val_ds,callbacks=callbacks)","aa8cf36d":"plot_learning_curve(history)","2edcadbe":"with strategy.scope():\n    ResNet = keras.applications.ResNet152V2(include_top=False)\n    model = keras.Sequential()\n    model.add(layers.Input(shape=[*image_size,channels]))\n    model.add(ResNet)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dense(num_classes,activation='sigmoid'))\n\n    model.compile(\n        optimizer=keras.optimizers.Adam(lr=0.05),\n        loss=keras.losses.BinaryCrossentropy(),\n        metrics=[\n            'accuracy',\n            tf.keras.metrics.Precision(name='precision'),\n            tf.keras.metrics.Recall(name='recall'),\n            tfa.metrics.F1Score(num_classes=num_classes,average='macro',name='f1_score')\n        ]\n     )\n    \n    callbacks = [\n        # keras.callbacks.EarlyStopping(patience=10,verbose=1,restore_best_weights=True),\n        keras.callbacks.ReduceLROnPlateau(factor=0.5,patience=4,verbose=1, min_delta=0.00001,\n                                         monitor='val_f1_score',mode='max'),\n        keras.callbacks.ModelCheckpoint('ResNet152V2-600.h5',monitor='val_f1_score',mode='max',\n                                        save_best_only=True,verbose=1)\n    ]\n\n    history = model.fit(train_ds,batch_size=batch_size,epochs=100,\n            validation_data=val_ds,callbacks=callbacks)","ec40a4dd":"plot_learning_curve(history)","bebaf001":"def load_predict_image(image_path):\n    image = tf.io.read_file(image_path)\n    image = tf.io.decode_jpeg(image, channels=channels)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize(image, image_size)\n    image = tf.expand_dims(image,axis=0)\n    return image","21ef5c51":"test_path = '..\/input\/plant-pathology-2021-fgvc8\/test_images\/'\n\nsubmission = pd.read_csv('..\/input\/plant-pathology-2021-fgvc8\/sample_submission.csv')","5c764423":"for model_name in ['EfficientNetB4-600.h5','ResNet152V2-600.h5']:\n    model = keras.models.load_model(model_name)\n    \n    for row in submission.index:\n\n        image = load_predict_image(test_path+submission.loc[row,'image'])\n        predict = model.predict(image)[0]\n        predict = [1 if i>0.5 else 0 for i in predict]\n        result = []\n        for i,j in enumerate(predict):\n            if j:\n                result.append(id2labels.get(i))\n        result = ' '.join(result)\n        submission.loc[row,'labels'] = result\n    \n    submission.to_csv(model_name[:-6]+'submission.csv',index=False)","44772994":"# Submit","d4d17911":"* view some pictures","8772f766":"* Labels code as multi-label classification","383c3f77":"# ResNet152V2","af98dd65":"* The training dataset, validation dataset and test dataset are divided according to 8:1:1","cf9f6802":"* convert label's dtype from list to tensor","2e1e9597":"# EfficientNetB4","3074bb6e":"* Process image"}}