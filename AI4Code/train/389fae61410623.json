{"cell_type":{"8470b6b7":"code","8451c867":"code","4eab46c3":"code","6650575b":"code","8819b49b":"code","904a4efe":"code","dcecf5f1":"code","bbdf1fdb":"code","31175084":"code","61b91be5":"code","7bd5e30a":"code","165cd2e9":"code","5eab4478":"code","0c9396b4":"code","27119dde":"code","a11b4aea":"code","fbb1eb55":"markdown","7d9bef69":"markdown","0e46a320":"markdown"},"source":{"8470b6b7":"!pip install --upgrade pip \\\n--user --quiet --no-warn-script-location\n!pip install --upgrade neural_structured_learning \\\n--user --quiet --no-warn-script-location","8451c867":"import warnings; warnings.filterwarnings('ignore')\nimport tensorflow_hub as th,tensorflow as tf\nimport neural_structured_learning as nsl\nimport os,pandas as pd,numpy as np\nimport seaborn as sn,pylab as pl\nimport tensorflow.keras.callbacks as tkc,\\\ntensorflow.keras.layers as tkl\nimport tensorflow.keras.preprocessing.image as tkimg","4eab46c3":"def images2array(files_path,img_size,\n                 preprocess=False,grayscale=False):\n    files_list=sorted(os.listdir(files_path))\n    n,img_array=len(files_list),[]\n    for i in range(n):\n        if i%round(.1*n)==0:\n            print('=>',end='',flush=True)\n        img_path=files_path+files_list[i]\n        if preprocess:\n            img=tkimg.load_img(\n                img_path,grayscale=grayscale)\n            img=tkimg.img_to_array(img)\n            img=tkimg.smart_resize(\n                img,(img_size,img_size))\n        else:\n            img=tkimg.load_img(\n                img_path,target_size=(img_size,img_size))\n            img=tkimg.img_to_array(img)\n        img=np.expand_dims(img,axis=0)\/255\n        img_array.append(img)\n    return np.array(np.vstack(img_array),\n                    dtype='float32')\ndef labels2array(files_path):\n    files_list=sorted(os.listdir(files_path))\n    files_split=np.array([el.split('_') \n                          for el in files_list])\n    num_labels=files_split.shape[1]-1\n    labels=[files_split[:,i] \n            for i in range(num_labels)]\n    labels=np.array(labels).astype('int32')\n    for i in range(num_labels):\n        label_set=list(set(labels[i]))\n        replace_dict=\\\n        dict(zip(label_set,\n                 list(range(len(label_set)))))\n        labels[i]=[replace_dict.get(x,x) \n                   for x in labels[i]]\n    return labels","6650575b":"files_path='..\/input\/tomato-cultivars\/'\nimg_size=160\nnames=[['Kumato','Beefsteak','Tigerella',\n        'Roma','Japanese Black Trifele',\n        'Yellow Pear','Sun Gold','Green Zebra',\n        'Cherokee Purple','Oxheart','Blue Berries',\n        'San Marzano','Banana Legs',\n        'German Orange Strawberry','Supersweet 100']]\nimages=images2array(files_path,img_size)\nlabels=labels2array(files_path)\nN=images.shape[0]; n=int(.1*N)\nshuffle_ids=np.arange(N)\nnp.random.RandomState(12).shuffle(shuffle_ids)\nimages=images[shuffle_ids]\nlabels=np.array([labels[i][shuffle_ids]\n                 for i in range(labels.shape[0])])\nx_test,x_valid,x_train=\\\nimages[:n],images[n:2*n],images[2*n:]\ny_test,y_valid,y_train=\\\nlabels[:,:n],labels[:,n:2*n],labels[:,2*n:]","8819b49b":"df=pd.DataFrame(\n    [[x_train.shape,x_valid.shape,x_test.shape],\n     [x_train.dtype,x_valid.dtype,x_test.dtype],\n     [y_train.shape,y_valid.shape,y_test.shape],\n     [y_train.dtype,y_valid.dtype,y_test.dtype]],\n    columns=['train','valid','test'],\n    index=['image shape','image type',\n           'label shape','label type'])\ndf","904a4efe":"cmap='tab20'\nidx=['labels %d'%(i+1) for i in range(labels.shape[0])]\ndf=pd.DataFrame(labels,index=idx).T\nfor i in range(labels.shape[0]):\n    df['name %d'%(i+1)]=\\\n    [names[i][l] for l in labels[i]]\nfig=pl.figure(figsize=(9,3))    \nfor i in range(labels.shape[0]):\n    ax=fig.add_subplot(labels.shape[0],1,i+1)\n    sn.countplot(y='name %s'%(i+1),data=df,\n                 palette=cmap,alpha=.5,ax=ax)\npl.show()","dcecf5f1":"def premodel(pix,den,mh,lbl,activ,loss):\n    model=tf.keras.Sequential([\n        tkl.Input((pix,pix,int(3)),name='input'),\n        th.KerasLayer(mh,trainable=True),\n        tkl.Flatten(),\n        tkl.Dense(den,activation='relu'),\n        tkl.Dropout(rate=.5),\n        tkl.Dense(lbl,activation=activ)])\n    model.compile(optimizer='adam',metrics=['accuracy'],loss=loss)\n    return model\ndef cb(fw):\n    early_stopping=tkc.EarlyStopping(\n        monitor='val_loss',patience=int(20),verbose=int(2))\n    checkpointer=tkc.ModelCheckpoint(\n        filepath=fw,verbose=int(2),save_weights_only=True,\n        monitor='val_accuracy',mode='max',save_best_only=True)\n    lr_reduction=tkc.ReduceLROnPlateau(\n        monitor='val_loss',verbose=int(2),patience=int(5),factor=.8)\n    return [checkpointer,early_stopping,lr_reduction]","bbdf1fdb":"fw='\/tmp\/checkpoint'\n[handle_base,pixels]=['inception_v3',160]\nmhandle='https:\/\/tfhub.dev\/google\/imagenet\/{}\/classification\/4'\\\n.format(handle_base)","31175084":"model=premodel(pixels,1024,mhandle,15,'softmax',\n               'sparse_categorical_crossentropy')\nhistory=model.fit(\n    x=x_train,y=np.squeeze(y_train),\n    batch_size=32,epochs=70,callbacks=cb(fw),\n    validation_data=(x_valid,np.squeeze(y_valid)))","61b91be5":"model.load_weights(fw)\nmodel.evaluate(x_test,np.squeeze(y_test))","7bd5e30a":"[handle_base,pixels]=['mobilenet_v2_100_160',160]\nmhandle='https:\/\/tfhub.dev\/google\/imagenet\/{}\/classification\/4'\\\n.format(handle_base)","165cd2e9":"model=premodel(pixels,1024,mhandle,15,'softmax',\n               'sparse_categorical_crossentropy')\nhistory=model.fit(\n    x=x_train,y=np.squeeze(y_train),\n    batch_size=32,epochs=70,callbacks=cb(fw),\n    validation_data=(x_valid,np.squeeze(y_valid)))","5eab4478":"model.load_weights(fw)\nmodel.evaluate(x_test,np.squeeze(y_test))","0c9396b4":"batch_size=64; img_size=x_train.shape[1]; epochs=30\nbase_model=tf.keras.Sequential([\n    tkl.Input((img_size,img_size,3),name='input'),\n    tkl.Conv2D(32,(5,5),padding='same'),\n    tkl.Activation('relu'),\n    tkl.MaxPooling2D(pool_size=(2,2)),\n    tkl.Dropout(.25),\n    tkl.Conv2D(196,(5,5)),\n    tkl.Activation('relu'),    \n    tkl.MaxPooling2D(pool_size=(2,2)),\n    tkl.Dropout(.25),\n    tkl.GlobalMaxPooling2D(),    \n    tkl.Dense(512),\n    tkl.Activation('relu'),\n    tkl.Dropout(.25),\n    tkl.Dense(128),\n    tkl.Activation('relu'),\n    tkl.Dropout(.25),\n    tkl.Dense(15,activation='softmax')])\nadv_config=nsl.configs\\\n.make_adv_reg_config(multiplier=.2,adv_step_size=.05)\nadv_model=nsl.keras\\\n.AdversarialRegularization(base_model,adv_config=adv_config)\nadv_model.compile(\n    optimizer='adam',metrics=['accuracy'],\n    loss='sparse_categorical_crossentropy')","27119dde":"train=tf.data.Dataset.from_tensor_slices(\n    {'input':x_train,'label':np.squeeze(y_train)})\\\n     .batch(batch_size)\nvalid=tf.data.Dataset.from_tensor_slices(\n    {'input':x_valid,'label':np.squeeze(y_valid)})\\\n     .batch(batch_size)\nvalid_steps=x_valid.shape[0]\/\/batch_size\nadv_model.fit(train,validation_data=valid,verbose=2,\n              validation_steps=valid_steps,epochs=epochs)","a11b4aea":"adv_model.evaluate(\n    {'input':x_test,'label':np.squeeze(y_test)})","fbb1eb55":"## NN Examples","7d9bef69":"## Data","0e46a320":"[Google Colaboratory Variant](https:\/\/colab.research.google.com\/drive\/1pymaadPUhSm0T9N5h44ls-mAcrylfa2F)\n## Code Modules & Functions"}}