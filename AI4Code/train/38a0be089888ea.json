{"cell_type":{"92c49764":"code","5b09e6d6":"code","806cb8f9":"code","27ea63dc":"code","bf53c4a4":"code","b6f8fcc2":"code","9a66e1d5":"code","92d0dc33":"code","6e3e7f48":"code","1dc3da54":"code","0a571ba6":"code","044786de":"markdown","749dfc26":"markdown","54246984":"markdown","c231fbf7":"markdown","2a15758c":"markdown","1b7c8b0c":"markdown","9124bfd8":"markdown","59885044":"markdown","9635f70d":"markdown","b2432fe8":"markdown"},"source":{"92c49764":"%%time\n\n!pip uninstall -q neuralcoref -y > \/dev\/null\n!pip install -q neuralcoref --no-binary neuralcoref > \/dev\/null\n\n!pip uninstall -q spacy -y > \/dev\/null\n!pip install -q -U spacy==2.1.0 > \/dev\/null\n!python -m spacy download en > \/dev\/null","5b09e6d6":"import json, random\nfrom tqdm.notebook import tqdm\nfrom urllib.parse import quote\n\n# Load your usual SpaCy model (one of SpaCy English models)\nimport spacy\nfrom spacy import displacy\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Add neural coref to SpaCy's pipe\nimport neuralcoref\nneuralcoref.add_to_pipe(nlp)","806cb8f9":"text = \"When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of the company took him seriously.\"\n\ndoc = nlp(text)\ndisplacy.render(doc, style=\"ent\")","27ea63dc":"doc = nlp('Angela lives in Boston. She is quite happy in that city.')\nfor ent in doc.ents:\n    print(ent._.coref_cluster)","bf53c4a4":"with open('..\/input\/this-american-life-podcast-transcriptsalignments\/test-transcripts-aligned.json', 'r') as f:\n    transcripts = json.load(f)","b6f8fcc2":"episode_list = []\n\nfor episode in transcripts:\n    episode_list.append(episode)\n\nprint(episode_list)","9a66e1d5":"sample_episode = 'ep-120'\nfor segment in transcripts[sample_episode][:6]:\n    print(segment['speaker'], \": \", segment['utterance'], \"\\n\")","92d0dc33":"sample_episode = 'ep-648'\nfor segment in transcripts[sample_episode][:6]:\n    print(segment['speaker'], \": \", segment['utterance'], \"\\n\")","6e3e7f48":"text = transcripts['ep-648'][0][\"utterance\"]\ndoc = nlp(text)\n\ndisplacy.render(doc, style=\"ent\")","1dc3da54":"text = transcripts[random.choice(episode_list)][0][\"utterance\"]\ndoc = nlp(text)\n\ndisplacy.render(doc, style=\"ent\")","0a571ba6":"episode = random.choice(episode_list)\nprint(\"Episode: \", episode)\ntext = transcripts[episode][0][\"utterance\"]\nurl_coref = \"https:\/\/huggingface.co\/coref\/?text=\" + quote(text)\nprint(\"Text: \", text, \"\\n\")\ndoc = nlp(text)\n\n\nfor ent in doc.ents:\n    if ent._.coref_cluster:\n        print(ent._.coref_cluster)\n        \nprint(\"\\n Navigate to the below URL for visualizing Coreference Resolution:\\n\", url_coref)","044786de":"### Libraries \ud83d\udcda\u2b07","749dfc26":"### Example of Coreference Resolution using NeuralCoref \ud83d\udd17\n#### You can also visualize the below coreference resolution with coreference-viz [here](https:\/\/huggingface.co\/coref\/?text=Angela%20lives%20in%20Boston.%20She%20is%20quite%20happy%20in%20that%20city.).","54246984":"### Sample NER Tagging","c231fbf7":"### Read JSON Data \ud83d\udcdd","2a15758c":"### Sample Coreference Resolution","1b7c8b0c":"## Introduction\n\n#### In this notebook, we use [SpaCy NER](https:\/\/spacy.io\/api\/entityrecognizer) & [Huggingface Neuralcoref](https:\/\/huggingface.co\/coref\/) model to perform Named Entity Recognition & Coreference Resolution on [This American Life](https:\/\/www.thisamericanlife.org\/) podcast transcripts.","9124bfd8":"#### Print sample conversions","59885044":"<h1><center>Named Entity Recognition & Coreference Resolution<\/center><\/h1>\n\n![](https:\/\/media.npr.org\/images\/podcasts\/primary\/icon_381444650-04c1bad8586e69edf04b78ea319846614c4a6a6b-s300-c85.png)\n<!-- <center>source: npr.org<\/center> -->\n<div style=\"text-align: right\"> Image source: media.npr.org <\/div>","9635f70d":"### Example of NER Tagging using SpaCy","b2432fe8":"### Get list of all test episodes"}}