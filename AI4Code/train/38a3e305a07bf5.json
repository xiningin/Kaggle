{"cell_type":{"6ad377bc":"code","706f9b34":"code","c4cea864":"code","ac8a7546":"code","3ab6e4ca":"code","c5411da5":"code","ee3a2b13":"code","ceb4815c":"code","c6ff8861":"markdown","66d9605e":"markdown","2119f35d":"markdown","6ac5920b":"markdown","4a3e57c5":"markdown","682654b6":"markdown","33f56691":"markdown","bb2ffdc2":"markdown","2a795534":"markdown"},"source":{"6ad377bc":"import os\nimport csv\nimport numpy as np\nfrom tqdm import tqdm\nfrom collections import Counter\nfrom operator import itemgetter\nimport matplotlib.pyplot as plt\n%matplotlib inline","706f9b34":"N = 629145480\ny = np.empty(N, dtype=np.float32)\n\nwith open('..\/input\/train.csv') as f:\n    reader = csv.reader(f)\n    for header in reader:\n        break\n    for i, row in enumerate(tqdm(reader, total=N)):\n        y[i] = float(row[1])","c4cea864":"deltas = y[1:] - y[:-1]\nepisodes = {0, len(y)}\nepisodes.update(np.arange(0, len(y) - 1)[deltas > 0] + 1)\nepisodes = sorted(list(episodes))\nepisodes = list(zip(episodes[:-1], episodes[1:]))\nprint('Episodes:', len(episodes))","ac8a7546":"deltas = []\nrewards = [] # non-zero deltas\n\nfor start, end in episodes:\n    t = y[start:end]\n    d = t[1:] - t[:-1]\n    d = np.round(d, 10)\n    deltas.append(d)\n    rewards.extend(d[d != 0])\n\ncounts = Counter(rewards)\n\nclasses = dict()\nfor value, numbers in sorted(counts.items(), key=itemgetter(0)):\n    print('%2d % .10f %7d' % (len(classes), value, numbers))\n    classes[value] = len(classes)","3ab6e4ca":"targets = [] # labels will store in a reverse order\nfor i, d in enumerate(deltas[::-1]):\n    c = 0\n    for r in tqdm(d[::-1], desc='Episode %d' % i):\n        if r != 0:\n            c = classes[r] if r in classes else 0\n        targets.append(c)\n    targets.append(c)\n# reverse again to match an original order\ntargets = np.array(targets[::-1], dtype=np.int8)","c5411da5":"counts = np.bincount(targets, minlength=52)\nplt.bar(range(52), counts)\nplt.xlabel(\"label\")\nplt.ylabel(\"number of samples\")\nplt.show()","ee3a2b13":"n_rewards = 1\nmapping = {-1: 0}\n\nfor i, c in enumerate(counts):\n    if c < 10_000_000:\n        mapping[i] = 0\n        continue\n    print(n_rewards, i, c)\n    mapping[i] = n_rewards\n    n_rewards += 1\n\ntargets_balanced = targets.copy()\nfor k, v in mapping.items():\n    targets_balanced[targets == k] = v","ceb4815c":"x = np.arange(0, len(y))\n\n_x = x[::1000]\n_y = y[::1000]\n_c = targets_balanced[::1000]\n\nsc = plt.scatter(_x, _y, c=_c, s=50, cmap='jet')\nplt.colorbar(sc)\nplt.xlabel(\"time\")\nplt.ylabel(\"time_to_failure\")\nplt.show()","c6ff8861":"Determine number of episodes","66d9605e":"Targets values are highly unbalanced","2119f35d":"Finally, targets_balanced array could be used for a classification task with 9 classes. Unfortunatly, I could not build a usefull model. On the other hand, visualization of targets values gives some insight into the training data.","6ac5920b":"At this point we have 52 different reward values and how many times they occur in the training data. But it doesn't tell how often the values change. Thus, I decided to fill the intermediate regions with a following non-zero reward label.","4a3e57c5":"In order to switch gears to a classification task, I decided to explore how to discretize time_to_failure values.\nIn particular, I was wonder how many different deltas, and how they distributed through the time.\n\nI also will use the terms from the reinforcement learning paradigm, like a reward or an episode.","682654b6":"Final remarks:\n* all my code of filtering unique target values seems useless, because it could be easily determined as a power of 2\n* from my point of view, it looks very artificial and discrete, perhaps it explains the underlain process behind the lab equipment\n\nSuggestions for future work:\n* make a stratification strategy based on different color regions\n* build a classifier and used it in a balancing procedure for the test data","33f56691":"Read 629145480 time_to_failure values from train.csv","bb2ffdc2":"Eliminate non-valuable classes with less than 10M samples","2a795534":"Determine unique reward values by constraining all values with round() function"}}