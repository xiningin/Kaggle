{"cell_type":{"8f05bcac":"code","ae2f5bf0":"code","8e6bf121":"code","ef2c35c7":"code","9bc18964":"code","7ad55d62":"code","8b9e0d5c":"code","eb23ac5d":"code","5e9dd3ee":"code","68d46ccb":"code","f838ebd7":"code","0a4b00e7":"code","728cc171":"code","04eac670":"code","72708a33":"code","4f21b581":"code","c7421372":"code","e5a57e73":"code","f87c2333":"code","8b7f510f":"code","c0d26e8d":"code","ffc7f9c4":"code","bc198c6f":"code","8788a2d7":"code","22734cab":"code","25d05fd5":"markdown","0998c6d7":"markdown","00bf29e1":"markdown","a1232dd7":"markdown","d0bbae66":"markdown","3a3fdb37":"markdown","7aa861e9":"markdown","03741907":"markdown","620bb85e":"markdown","4371cc70":"markdown","69f91fb5":"markdown","eaae427a":"markdown","3f82335c":"markdown","e9155696":"markdown","8317c3ec":"markdown","353f874a":"markdown","7b443645":"markdown","5ad2ea15":"markdown","1a49eddf":"markdown","a28b4d1f":"markdown","8645c4ea":"markdown","45aef403":"markdown","a50f2d72":"markdown","9af09b9c":"markdown","474c62ec":"markdown","df382270":"markdown","e461d98e":"markdown"},"source":{"8f05bcac":"import pandas as pd\nimport numpy as np","ae2f5bf0":"pd.options.display.max_columns = 60\npd.options.display.float_format = lambda x: f' {x:,.2f}'\nimport warnings\nwarnings.filterwarnings(\"ignore\")","8e6bf121":"game = pd.read_csv('..\/input\/train_V2.csv', index_col='Id')\ngame.head()","ef2c35c7":"game.describe()","9bc18964":"game.info()","7ad55d62":"game.isna().sum()","8b9e0d5c":"filt = game['winPlacePerc'].isna()\ngame[filt]","eb23ac5d":"filt2 = game['maxPlace'] == 1\ngame[filt2]","5e9dd3ee":"game = game.fillna(0)","68d46ccb":"game.isna().sum().sum()","f838ebd7":"game.corr().style.format(\"{:.2%}\").highlight_min()","0a4b00e7":"X = game['killPlace'].values.reshape(-1, 1)\nX[:10]","728cc171":"y = game['winPlacePerc'].values\ny[:10]","04eac670":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()","72708a33":"from sklearn.model_selection import cross_val_score","4f21b581":"cvs_lr = cross_val_score(lr, X, y, cv=15)\ncvs_lr.mean(), cvs_lr.std()","c7421372":"from sklearn.tree import DecisionTreeRegressor\ndtr = DecisionTreeRegressor()","e5a57e73":"cvs_dtr = cross_val_score(dtr, X, y)\ncvs_dtr.mean(), cvs_dtr.std()","f87c2333":"dtr.fit(X,y)","8b7f510f":"game_test = pd.read_csv('..\/input\/test_V2.csv', index_col='Id')\ngame_test.head()","c0d26e8d":"game_test.isna().sum().sum()","ffc7f9c4":"X_test = game_test['killPlace'].values.reshape(-1, 1)\nX_test[:10]","bc198c6f":"predictions = dtr.predict(X_test).reshape(-1,1)","8788a2d7":"dfpredictions = pd.DataFrame(predictions, index=game_test.index).rename(columns={0:'winPlacePerc'})\ndfpredictions.head(15)","22734cab":"dfpredictions.to_csv('submission.csv', header=True)","25d05fd5":"Now it's time to bring in the test data and take a peek.","0998c6d7":"We already have `dtr` instantiated as our Decision Tree Regressor. Now it's time to train it.","00bf29e1":"I'll start with linear regression and check to see what the cross validation score is to see if that might be a good model.","a1232dd7":"#### Decision Tree Regressor","d0bbae66":"I'm going to set up the feature set and target first. Then I'll look at a handful of possible models to see which might work the best.","3a3fdb37":"Just to confirm we're all done with missing values:","7aa861e9":"The only missing value is a single value in `winPlacePerc`. Let's take a look at it.","03741907":"That's kinda pitiful. Let's see if we can do better with a different model.","620bb85e":"# <center>PUBG Prediction with One Feature<\/center>\n### <center>by Bon Crowder<\/center>","4371cc70":"In order to decide which single feature to use, I can look at the correlation of `winPlacePerc` to the other features. I've highlighted the minimums and I'll manually look at the maximums.","69f91fb5":"Now to get our predictions:","eaae427a":"Here are the dependencies:","3f82335c":"## Training the Decision Tree Regressor","e9155696":"***","8317c3ec":"And then create the output that can be sent to Kaggle.","353f874a":"We can put those in a dataframe:","7b443645":"And our result is...","5ad2ea15":"Looks like `killPlace` is the most dramatically and negatively correlated. So I'll start with that one.\n\nAlso, `weaponsAcquired` and `walkDistance` are both strongly and *positively* correlated, so those may be the two to check out next.","1a49eddf":"Based on the information in the variable descriptions as well as the correlation of `maxPlace` to `winPlacePerc`, I think filling in the missing values for `winPlacePerc` with 0 (total loser) seems appropriate. ","a28b4d1f":"And then I add my personal prettifiers (not required).","8645c4ea":"## Preliminary Code","45aef403":"### Load the PUBG Dataset","a50f2d72":"Ah! That's much better. \n\nOutside of this notebook, I ran cross validation on the Random Forest Regressor, but the difference was almost zero. So for this notebook, we'll stick with DTR.","9af09b9c":"## Choose Feature","474c62ec":"## Choosing a Model for Use on killPlace","df382270":"#### Linear Regression","e461d98e":"Looks good from here. So let's focus on the important part: `killPlace`."}}