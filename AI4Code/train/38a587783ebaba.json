{"cell_type":{"0b755cd5":"code","519abe7c":"code","b24182e9":"code","3b3259b7":"code","3880c377":"code","9a372cf7":"code","5602c2fb":"code","debcaa61":"code","a68ac45b":"code","e6b1a595":"code","b260f68f":"code","b8b8f1c4":"code","223b3fa6":"code","64761c31":"code","369308a1":"code","de75b708":"code","f695fb2e":"code","0ff4f3e4":"code","e6c83acf":"code","25805413":"code","4e8b2c2e":"code","71dbee7b":"code","d654d9a4":"code","580713cb":"code","d675294c":"code","d649de25":"code","4ade0219":"code","6005b9e3":"code","79dc7476":"code","341dec43":"code","9c65439d":"code","0a54f5c7":"code","b84cf17d":"code","5e3c46b4":"code","d8efd9a0":"code","07870058":"code","b1709fa2":"code","438f5384":"code","f4f3bef4":"markdown"},"source":{"0b755cd5":"#import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf\nnp.random.seed(2)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.python.keras.utils.np_utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout,BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.models import model_from_json\nfrom PIL import Image, ImageChops, ImageEnhance\nimport PIL\nimport os\nimport itertools\nfrom tqdm import tqdm\ntf.__version__","519abe7c":"def ELA(img_path, quality=90):\n    TEMP = 'ela_' + 'temp.jpg'\n    SCALE = 10\n    original = Image.open(img_path)\n    diff=\"\"\n    try:\n        original.save(TEMP, quality=90)\n        temporary = Image.open(TEMP)\n        diff = ImageChops.difference(original, temporary)\n        \n    except:\n        \n        original.convert('RGB').save(TEMP, quality=90)\n        temporary = Image.open(TEMP)\n        diff = ImageChops.difference(original.convert('RGB'), temporary)\n        \n       \n    d=diff.load()\n    WIDTH, HEIGHT = diff.size\n    for x in range(WIDTH):\n        for y in range(HEIGHT):\n            d[x, y] = tuple(k * SCALE for k in d[x, y])\n#     save_path = dataset_path +'ELA_IMAGES\/'\n#     diff.save(save_path+'diff.png')\n    return diff","b24182e9":"dataset_path=\"..\/input\/casia-20-image-tampering-detection-dataset\/CASIA2\/\"\npath_original = 'Au\/'\npath_tampered = 'Tp\/'\n# path_mask='CASIA 2 Groundtruth\/'\ntotal_original = os.listdir(dataset_path+path_original)\ntotal_tampered = os.listdir(dataset_path+path_tampered)\n# total_mask=os.listdir(dataset_path+path_mask)\n","3b3259b7":"pristine_images = []\nfor i in total_original:\n    pristine_images.append(dataset_path+path_original+i)\nfake_images = []\nfor i in total_tampered:\n    fake_images.append(dataset_path+path_tampered+i)","3880c377":"len(total_tampered),len(fake_images)","9a372cf7":"image_size = (224,224)\noutput_path='.\/'","5602c2fb":"# os.rmdir(output_path+\"resized_images\/fake_images\/\")\n# os.rmdir(output_path+\"resized_images\/pristine_images\/\")\n# os.rmdir(output_path+\"resized_images\/\")","debcaa61":"output_path='.\/'\nif not os.path.exists(output_path+\"resized_images\/\"):\n#     os.makedirs(output_path+\"resized_images\/fake_masks\/\")\n    os.makedirs(output_path+\"resized_images\/fake_images\/\")\n    os.makedirs(output_path+\"resized_images\/pristine_images\/\")\n    height = 224\n    width = 224\n#     p2=output_path+\"resized_images\/fake_masks\/\"\n    p1=output_path+\"resized_images\/fake_images\/\"\n    p3=output_path+\"resized_images\/pristine_images\/\"\n    j=0\n    for fake_image in tqdm(total_tampered):\n        try:\n            if(j%3):\n                j+=1\n                continue\n            img=Image.open(dataset_path+path_tampered + fake_image).convert(\"RGB\")\n            img = img.resize((height, width), PIL.Image.ANTIALIAS)\n            img.save(p1+fake_image)\n            j+=1\n        except:\n            print(\"Encountered Invalid File : \",fake_image)\n        \n    j=0\n    for pristine_image in tqdm(total_original):\n        try:\n            if(j%3):\n                j+=1\n                continue\n            img=Image.open(dataset_path+path_original + pristine_image).convert(\"RGB\")\n            img = img.resize((height, width), PIL.Image.ANTIALIAS)\n            img.save(p3+pristine_image)\n            j+=1\n        except:\n            print(\"Invalid File : \" ,pristine_image)\n        \n        \n        \nelse:\n    print('images resized,path exists')","a68ac45b":"resized_fake_image_path=output_path+\"resized_images\/fake_images\/\"\nresized_pristine_image_path=output_path+\"resized_images\/pristine_images\/\"\nresized_fake_image=os.listdir(resized_fake_image_path)\nresized_pristine_image=os.listdir(resized_pristine_image_path)","e6b1a595":"len(resized_pristine_image)\n# os.rmdir(ela_real)\n# os.rmdir(ela_fake)\n# os.rmdir('ELA_IMAGES\/')","b260f68f":"ela_images_path=output_path+'ELA_IMAGES\/'\nela_real=ela_images_path+'Au\/'\nela_fake=ela_images_path+'Tp\/'\nif not os.path.exists(ela_images_path):\n    os.makedirs(ela_images_path)\n    os.mkdir(ela_real)\n    os.mkdir(ela_fake)\n    j=0\n    for i in tqdm(resized_fake_image):\n        ELA(resized_fake_image_path+i).save(ela_fake+i)\n        j+=1\n        if(j==1500):\n            break\n    j=0\n    for i in tqdm(resized_pristine_image):\n        ELA(resized_pristine_image_path+i).save(ela_real+i)\n        j+=1\n        if(j==1500):\n            break\nelse:\n    print('Images are already converted to ELA')","b8b8f1c4":"X=[]\nY=[]\nj=0\nfor file in tqdm(os.listdir(ela_real)):\n    img=Image.open(ela_real+file)\n    img=np.array(img)\n    X.append(img)\n    Y.append(0)\n    j+=1\n    if(j==1500):\n        break\nj=0\nfor file in tqdm(os.listdir(ela_fake)):\n    img=Image.open(ela_fake+file)\n    img=np.array(img)\n    X.append(img)\n    Y.append(1)\n    j+=1\n    if(j==1500):\n        break","223b3fa6":"X=np.array(X)\nX.shape","64761c31":"from sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nx_train, x_dev, y_train, y_dev = train_test_split(X, Y, test_size=0.2, random_state=133,shuffle=True)\ny_train=to_categorical(y_train,2)\ny_dev=to_categorical(y_dev,2)","369308a1":"from tensorflow.keras.applications import MobileNetV2,VGG16\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D,BatchNormalization,Dropout,MaxPooling2D\nfrom tensorflow.keras.regularizers import l1,l2,l1_l2\n\nbase_model=MobileNetV2(input_shape=(224,224,3),include_top=False,weights='imagenet')\nfor layer in base_model.layers:\n    layer.trainable=False\nx=base_model.output\nx=Conv2D(1024,(3,3),padding='same',activation='relu')(x)\nx=GlobalAveragePooling2D()(x)\nx=Flatten()(x)\nx=Dense(1024,activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(x)\nx=Dropout(0.3)(x)\nx=Dense(16,activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(x)\nx=Dense(2,activation='softmax')(x)\nmodel=Model(base_model.input,x)\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.summary()\n# base=MobileNetV2()","de75b708":"epochs = 100\nbatch_size = 20","f695fb2e":"import keras\n# if not os.path.exists('.\/model_checkpoints'):\n#     os.makedirs('.\/model_checkpoints')\n# # define callbacks for learning rate scheduling and best checkpoints saving\n# filepath = '.\/model_checkpoints\/image_tampering_classification_ela.h5'\n# checkpoint = keras.callbacks.ModelCheckpoint(filepath,monitor='val_accuracy',save_best_only=True,verbose=1)\n\nearly_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=13,verbose=1,restore_best_weights=True)\n\nreduce_lr = keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.22, patience = 6, verbose = 1, \n                                              min_delta = 0.0001,min_lr=0.0001)","0ff4f3e4":"hist = model.fit(x_train,y_train,\n                 epochs = epochs,\n                validation_data = (x_dev,y_dev),\n                callbacks = [early_stop,reduce_lr],\n                verbose=1,shuffle=True)","e6c83acf":"# model.save('\/kaggle\/working\/model_casia_run1.h5')\n# model.save_weights('\/kaggle\/working\/model_casia_run1.h5')","25805413":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(hist.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(hist.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(hist.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","4e8b2c2e":"feature_extractor=base_model.predict(x_train)\n\nfeatures = feature_extractor.reshape(feature_extractor.shape[0], -1)\n\nX_for_training = features #This is our X input to RF\n\n#RANDOM FOREST\n#from sklearn.ensemble import RandomForestClassifier\n#model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n\n# Train the model on training data\ny_train_label=np.where(y_train==1)[1]\n\n#XGBOOST\nimport xgboost as xgb\nmodel = xgb.XGBClassifier()\nmodel.fit(X_for_training, y_train_label) #For sklearn no one hot encoding","71dbee7b":"import seaborn as sns\nX_test_feature = base_model.predict(x_dev)\nX_test_features = X_test_feature.reshape(X_test_feature.shape[0], -1)\n\n#Now predict using the trained RF model. \nprediction = model.predict(X_test_features)\n#Inverse le transform to get original label back. \n# prediction = le.inverse_transform(prediction)\ny_test=np.where(y_dev==1)[1]\n#Print overall accuracy\nfrom sklearn import metrics\nprint (\"Accuracy = \", metrics.accuracy_score(y_test, prediction))\n\n#Confusion Matrix - verify accuracy of each class\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, prediction)\n#print(cm)\nsns.heatmap(cm, annot=True)","d654d9a4":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n    \n","580713cb":"pred=model.predict(X_test_features)","d675294c":"# pred[0:20]","d649de25":"# print(\"Loss of the model is - \" , model.evaluate(X_test_features,y_test)[0])\n# print(\"Accuracy of the model is - \" , model.evaluate(X_test_features,y_test)[1]*100 , \"%\")\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test,pred))","4ade0219":"# Predict the values from the validation dataset\nY_pred = model.predict(x_dev)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(y_dev,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(2))","6005b9e3":"class_names = ['real','fake']","79dc7476":"real_image_path = '..\/input\/casia-20-image-tampering-detection-dataset\/CASIA2\/Tp\/Tp_D_CNN_M_B_nat10139_nat00059_11949.jpg'\nimage = ELA(real_image_path)\nimage=image.resize((224, 224), PIL.Image.ANTIALIAS)\nimage=np.array(image)\nimage = image.reshape(-1, 224, 224, 3)\n# image=np.array(image)\ny_pred = model.predict(image)\ny_pred_class = np.argmax(y_pred, axis = 1)[0]\nprint(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')\n","341dec43":"fake_image_path = '..\/input\/casia-20-image-tampering-detection-dataset\/CASIA2\/Au\/Au_ani_00022.jpg'\nimage = ELA(fake_image_path)\nimage=image.resize((224, 224), PIL.Image.ANTIALIAS)\nimage=np.array(image)\nimage = image.reshape(-1, 224, 224, 3)\n# image=np.array(image)\ny_pred = model.predict(image)\ny_pred_class = np.argmax(y_pred, axis = 1)[0]\nprint(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')","9c65439d":"total,correct=0,0","0a54f5c7":"for i in range(len(x_dev)):\n    image=x_dev[i]\n    image=np.array(image)\n    image = image.reshape(-1, 224, 224, 3)\n    y_true=0\n    if(y_dev[i][1]==1):\n        y_true=1\n    y_pred = model.predict(image)\n    y_pred_class = np.argmax(y_pred, axis = 1)[0]\n    total += 1\n    \n    if y_pred_class == y_true:\n            correct += 1        \n    print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')\n    print(f'Class: {class_names[y_true]}')\n    print('******************')","b84cf17d":"# fake_image = os.listdir('..\/input\/casia-20-image-tampering-detection-dataset\/CASIA2\/Tp\/')\n# correct = 0\n# total = 0\n# for file_name in fake_image:\n#     if file_name.endswith('jpg') or file_name.endswith('png'):\n#         fake_image_path = os.path.join('..\/input\/casia-20-image-tampering-detection-dataset\/CASIA2\/Tp\/', file_name)\n# #         image = prepare_image(fake_image_path)\n#         image = ELA(fake_image_path)\n#         image=image.resize((224, 224), PIL.Image.ANTIALIAS)\n#         image=np.array(image)\n#         image = image.reshape(-1, 224, 224, 3)\n#         y_pred = model.predict(image)\n#         y_pred_class = np.argmax(y_pred, axis = 1)[0]\n#         total += 1\n#         if y_pred_class == 1:\n#             correct += 1\n#             print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')","5e3c46b4":"# print(f'Total: {total}, Correct: {correct}, Acc: {correct \/ total * 100.0}')","d8efd9a0":"# real_image = os.listdir('..\/input\/casia-20-image-tampering-detection-dataset\/CASIA2\/Au\/')\n# correct_r = 0\n# total_r = 0\n# for file_name in real_image:\n#     if file_name.endswith('jpg') or file_name.endswith('png'):\n#         real_image_path = os.path.join('..\/input\/casia-20-image-tampering-detection-dataset\/CASIA2\/Au\/', file_name)\n#         image = ELA(real_image_path)\n#         image=image.resize((224, 224), PIL.Image.ANTIALIAS)\n#         image=np.array(image)\n#         image = image.reshape(-1, 224, 224, 3)\n#         y_pred = model.predict(image)\n#         y_pred_class = np.argmax(y_pred, axis = 1)[0]\n#         total_r += 1\n#         if y_pred_class == 0:\n#             correct_r += 1\n#             print(f'Class: {class_names[y_pred_class]} Confidence: {np.amax(y_pred) * 100:0.2f}')","07870058":"# correct += correct_r\n# total += total_r\n# print(f'Total: {total_r}, Correct: {correct_r}, Acc: {correct_r \/ total_r * 100.0}')\n# print(f'Total: {total}, Correct: {correct}, Acc: {correct \/ total * 100.0}')","b1709fa2":"# model.save('\/kaggle\/working\/model_casia_run2.h5')\n# model.save_weights('\/kaggle\/working\/model_casia_run1.h5')","438f5384":"model_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"\/kaggle\/working\/model_casia_run.h5\")\nprint(\"Saved model to disk\")","f4f3bef4":"Prediction"}}