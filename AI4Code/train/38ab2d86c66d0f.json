{"cell_type":{"bb71b079":"code","57989e08":"code","7a4d0663":"code","4d2262d8":"code","689446fe":"code","6a1db002":"code","f5119bff":"code","49b52891":"code","da230a26":"code","af0036a4":"code","3afcdf01":"code","f8a9a2b5":"code","880474d7":"code","8413dd9b":"code","b77a47f2":"code","0b03cde7":"code","6911893a":"code","8fb33b10":"code","9f5d3d2d":"code","847ae429":"code","44c88cf9":"code","df2abccc":"code","d0a3ff47":"code","69a81e0a":"code","8a0b13df":"code","8b59e7b4":"code","dcb5ec41":"code","bbcc7003":"code","5386754d":"code","b6052763":"code","aa2c3cb4":"code","878eff9e":"code","7aa4901f":"code","500d6cfa":"code","8eac833b":"code","994af3a3":"code","09207a55":"code","5865e7e9":"code","fbf6523e":"code","e88a8e2b":"code","3dbe82ff":"code","fc0e25fd":"code","87e89787":"code","f5add659":"code","9a833285":"markdown","e7351b2f":"markdown","317ec26d":"markdown","60a086b0":"markdown","029223f3":"markdown","def7c958":"markdown","ccb2b5f1":"markdown","d21d84ca":"markdown","9bfdee0b":"markdown","974c5ea0":"markdown"},"source":{"bb71b079":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","57989e08":"# IMPORT DATA AND PACKED\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots \nfrom plotly.offline import init_notebook_mode, iplot","7a4d0663":"# Conditions all for the plotting\nsns.set()\npd.options.plotting.backend = 'plotly'\nplt.style.use('seaborn')\ninit_notebook_mode(connected = True)","4d2262d8":"#Charge data csv 'data-analyst-jobs' as format Dataframe from pandas\ndf = pd.read_csv('..\/input\/data-analyst-jobs\/DataAnalyst.csv')\ndf.head()","689446fe":"# General info from data:\ndf.info()","6a1db002":"# Delete column \"Unnamed: 0\"\ndf.drop(['Unnamed: 0'], axis = 1, inplace = True)\n# Copy data a new DataFrame\ndf1 = df.copy()\ndf1.head(2)","f5119bff":"# DATA CLEANING\n\n#Separate values for create new two fields from them:\ndf1['Job Title'],df1['Department']= df['Job Title'].str.split(',',1).str\ndf1['Company Name'],_ = df['Company Name'].str.split('\\n',1).str\ndf1['Salary Estimate'],_= df['Salary Estimate'].str.split('(',1).str\ndf1['Min Salary'],df1['Max Salary']= df1['Salary Estimate'].str.split('-').str\n\n# Created values Max Salary and Min Salary as well as data cleaning with strip methods from string class\n# Replace withe spaces for nan values through the numpy.\nclean_salary = lambda x: x.replace('', np.nan).str.strip().str.lstrip('$').str.rstrip('K').fillna(0).astype(int)\ndf1['Min Salary'] = clean_salary(df1['Min Salary'])\ndf1['Max Salary'] = clean_salary(df1['Max Salary'])\n\n# Empty Field 'Salary Estimate' but created Max and Min salary.\ndf1 = df1.drop(['Salary Estimate'],axis = 1)\n\n# Show 'df1' with the changes realized previously. \ndf1.head()","49b52891":"# DATA ANALYTICS\n# Count values from easy apply for each job offers\ndf1['Easy Apply'].value_counts()","da230a26":"# Easy applicated only 80 companies, the rest could to be applicated dificult it.\n# With a function, it recodes key and values to take new values between 0 and 1\ndef recode(column, new_code):\n    col_cod = pd.Series(column, copy = True)\n    for key, values in new_code.items():\n        col_cod.replace(key, values, inplace = True)\n    return col_cod","af0036a4":"# Use the new function\ndf1['Easy Apply'] = recode(df1['Easy Apply'],{'-1':0,'True':1})\ndf1['Competitors'] = recode(df1['Competitors'],{'-1':np.nan})\n\n# Extracted data the Easy Apply with values equal '1', in the other words,  \n# this part will to make only in offers jobs where is easy applicated\ndf_easy_apply = df1[df1['Easy Apply'] == 1]\ndf_easy_apply.reset_index()\ndf_easy_apply.head()","3afcdf01":"# New Dataframe through method 'Groupby' from 'pandas' packet. It's grouped in fallen order and count the values \"Easy Apply\" for each offer jobs\ndf_easy_apply_1 = df_easy_apply.groupby(['Company Name','Sector'])['Easy Apply'].count().reset_index()\n# In the same way, apply method 'Groupby' with the values \"Max Salary\". It's grouped throght it's average\ndf_easy_apply_2 = df_easy_apply.groupby(['Company Name'])['Max Salary'].mean().reset_index()\n# Apply concate fields and order descendent for dataframe before and perform cut in ten primary\ndf_easy = pd.DataFrame()\ndf_easy = pd.concat([df_easy_apply_1['Company Name'], df_easy_apply_1['Easy Apply'], \n                     df_easy_apply_2['Max Salary']], axis = 1)\ndf_easy = df_easy.sort_values('Easy Apply', ascending = False).head(10).reset_index().drop('index', axis = 1)\ndf_easy.head(10)","f8a9a2b5":"# Plot graph bar with Plotly included color graduation in function the Max Salary Mean.\nchart = px.bar(df_easy, y = 'Easy Apply', x = 'Company Name', color = 'Max Salary',\n              color_continuous_scale = px.colors.sequential.Viridis,\n              title = \"Companies That Have Jobs as Data Analyst With Easily Apply\")\nchart.show()","880474d7":"# Now, visualization of size company in funtion quantily employees that offers job in data analyst.\n\n# Create DateFrame and empty rows with useless data\n# Change of field names for easy descriptive in graphic and visualization\ndf_employed = df1['Size'].value_counts().to_frame().reset_index()\ndf_employed = df_employed.drop(df_employed[(df_employed['index'] == '-1') | \\\n                                           (df_employed['index'] == 'Unknown')].index, \n                               axis = 0).rename(columns = {'index': 'Size Company',\n                                                           'Size': 'N\u00ba Company'})\ndf_employed.head()","8413dd9b":"# Finally, plot graphic barplot in horizontal for Size Company in function of employees Quantity:\n# Use Plotly Express\nchart1 = px.bar(df_employed, x = 'N\u00ba Company', y = 'Size Company',\n               title = 'Size Company in function of employees Quantity')\nchart1.show()","b77a47f2":"# Use grouby method for get a new dataframe thad measure number companies your rating\n# In addition, we order descending in the ratings function, discard lower rating values that 3.00 \n# And rename fields\ndf_rating = df1.groupby('Rating')['Company Name'].count().to_frame().reset_index()\\\n                        .sort_values('Rating', ascending = False).reset_index()\\\n                        .drop('index', axis = 1)\\\n                        .rename(columns = {'Company Name': 'N\u00ba Companies'})\n\ndf_rating = df_rating.drop(df_rating[(df_rating['Rating'] <= 3.00)].index, axis = 0)\n\ndf_rating.head()","0b03cde7":"# Plot visualization in graphic bars. \nplt.figure(figsize = (12,6))\n\nplot = sns.barplot(x = 'Rating', y = 'N\u00ba Companies', data = df_rating, palette = 'rocket')\nplot = plot.set_xticklabels(plot.get_xticklabels(),\n                           horizontalalignment = 'right',\n                           fontweight = 'light')","6911893a":"# Visualization of Ownerships companies type that offers job Data Analysta\n# Empty row with '-1 index, rename fields and discard lowers values that 10\ndf_ownership = df1['Type of ownership'].value_counts().to_frame()\\\n               .drop('-1').reset_index()\\\n               .rename(columns = {'index': 'Type of Ownership',\n                                  'Type of ownership': 'N\u00ba Offers Jobs'})\n\ndf_ownership = df_ownership.drop(df_ownership[(df_ownership['N\u00ba Offers Jobs'] <= 10)].index, axis = 0)\ndf_ownership.head()","8fb33b10":"# Finaly, barplot with seaborn\nplt.figure(figsize = (12,6))\nplot = sns.barplot(x = 'N\u00ba Offers Jobs', y = 'Type of Ownership', data = df_ownership)\nplot = plot.set_xticklabels(plot.get_xticklabels(),\n                           rotation = 65,\n                           horizontalalignment = 'right')","9f5d3d2d":"# Now, analyze Max salary in fuction the each sector\n# Empty rows and fields innesesary\ndf_mean_salary = df1.groupby(['Sector']).mean().reset_index()\\\n                    .drop(['Founded','Easy Apply'], axis = 1)\n# The sectors as government and non-profit it would't take for analitycs\ndf_mean_salary = df_mean_salary.drop(df_mean_salary[(df_mean_salary['Sector'] == '-1') | \\\n                                                    (df_mean_salary['Sector'] == 'Government') | \\\n                                                    (df_mean_salary['Sector'] == 'Non-Profit')].index,\n                                     axis = 0) \\\n                                     .sort_values('Max Salary', ascending = False)\n\ndf_mean_salary.head()","847ae429":"# Visualization in bar graph with plotly\n\n# Create Trace 1\ntrace1 = go.Bar(x = df_mean_salary['Sector'],\n                y = df_mean_salary['Max Salary'],\n                name = 'Max Salary',\n                marker = dict(color ='rgb(55, 83, 109)',\n                             line = dict(color = 'rgb(0,0,0)', width = 1.5)))\n\n# Create Trace 2\ntrace2 = go.Bar(x = df_mean_salary['Sector'],\n                y = df_mean_salary['Min Salary'],\n                name = 'Min Salary',\n                marker = dict(color = 'indianred',\n                             line = dict(color = 'rgb(0,0,0)', width = 1.5)))\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(title = 'Salary Range For Each Sector', \n                   barmode = 'group')\n\nchart = go.Figure(data = data, layout = layout)\niplot(chart)\n","44c88cf9":"# Create a DataFrame with features (Mean Salary, Location and Mean Salary) \ndf_states = pd.DataFrame()\ndftemp = df1.copy()\ndftemp['Mean Salary'] = (df1['Max Salary'] + df1['Min Salary']) \/ 2\ndf_states = pd.concat([df1['Sector'],df1['Location'], dftemp['Mean Salary']], axis = 1)\ndf_states.head()","df2abccc":"# Seperate Acronym and City from Location Field\ndf_states['City'], df_states['Acronym State'] = df_states['Location'].str.split(',', 1).str\n# Remove field \"Location\" and values '-1' in field sector:\ndf_states = df_states.drop('Location', axis = 1) \\\n                     .drop(df_states[df_states['Sector'] == '-1'].index, axis = 0)\ndf_states.head()","d0a3ff47":"# Apply Groupy with DataFrame both in the count and the mean values, after concated fields in the new DataFrame:\ndf_states_group = df_states.groupby(['Acronym State']).count().reset_index()\ndf_salary_group = df_states.groupby(['Acronym State']).mean().reset_index()\n\n# New Dataframe \ndf_map = pd.DataFrame()\ndf_map = pd.concat([df_states_group['Acronym State'], \n                    df_states_group['Sector'], \n                    df_salary_group['Mean Salary']], \n                   axis = 1)\ndf_map.head()","69a81e0a":"# Round Mean Salary Value with Lambda function and remove row in 'Araphone, CO' Value of \"Sector\" field\ndf_map = df_map.drop([1], axis = 0).rename(columns = {'Sector': 'N\u00ba Offers Jobs'})\ndf_map['Mean Salary'] = df_map['Mean Salary'].apply(lambda x: round(x, 2))\ndf_map.head()","8a0b13df":"# Plot Map of United States with Plotly in module graph_objects:\nlocations = list(df_map['Acronym State'])\n\n# Remove withe space in \"Acronym State\" field\nfor i in range(0, len(locations)):\n    locations[i] = locations[i].replace(\" \", \"\")\n\nqjobs = list(df_map['N\u00ba Offers Jobs'])\n\n# Create text that displays the basic data when the cursor is over the chart status \ndf_map_str = df_map.copy()\nfor col in df_map_str.columns:\n    df_map_str[col] = df_map_str[col].astype(str)\n    \n# Apply '$' symbol in Mean Salary values\ndf_map_str['Mean Salary'] = df_map_str['Mean Salary'].apply(lambda x: \"$\" + x + \"\/Year\")\n# Text visualization:\ndf_map_str['Text'] = df_map_str['Acronym State']  + '<br>' + \\\n    \"N\u00aa Offers Jobs: \" + df_map_str['N\u00ba Offers Jobs'] + '<br>' \\\n        \"Mean Salary from the Jobs as Data Analyst: \" + '<br>' + df_map_str['Mean Salary'] + \" (Thousands)\"\ndf_map_str.head()","8b59e7b4":"# Plot Map in plotly\nimport plotly.graph_objects as go\n\n\nfig = go.Figure(data = go.Choropleth(locations = locations,\n                                    z = qjobs,\n                                    locationmode = 'USA-states',\n                                    text = df_map_str['Text'],\n                                    marker_line_color = 'black',\n                                    colorbar_title = 'N\u00ba Offers Jobs'),) \n\nfig.update_layout(title_text = 'N\u00ba Offers Jobs as Data Analyst<br>United States of America',\n                 geo = dict(scope = 'usa',\n                           projection = go.layout.geo.Projection(type = 'albers usa'),\n                           showlakes = True,\n                           lakecolor = 'rgb(255,255,255)'),)\nfig.show()","dcb5ec41":"# Created new dataframe for view jobs percentage as well as its mean salary year for each state\ndf_map2 = df_map.copy()\ndf_map2['Jobs Percentage'] = (df_map2['N\u00ba Offers Jobs'] \/ df_map2['N\u00ba Offers Jobs'].sum()) * 100\ndf_map2['Jobs Percentage'] = df_map2['Jobs Percentage'].apply(lambda x: round(x, 1))\ndf_map2 = df_map2.sort_values('Jobs Percentage', ascending = True) \\\n                 .drop(df_map2[df_map2['Jobs Percentage'] <= 2.0].index, axis = 0) \\\n                 .reset_index() \\\n                 .drop('index', axis = 1)\ndf_map2.head(11)","bbcc7003":"# Create two Subplots:\nfig_states = make_subplots(rows = 1, cols = 2, specs = [[{},{}]], shared_xaxes = True,\n                          shared_yaxes = False, vertical_spacing = 0.001)\n\nfig_states.append_trace(go.Bar(x = df_map2['Jobs Percentage'],\n                       y = df_map2['Acronym State'],\n                       marker = dict(color = 'rgba(50, 171, 40, 0.7)',\n                                    line = dict(color='rgba(60, 171, 120, 1.0)',\n                                               width = 1,)\n                                    ),\n                       name = 'Percentage Jobs',\n                       orientation = 'h',\n                       ),\n                1, 1)\n\nfig_states.append_trace(go.Scatter(x = df_map2['Mean Salary'],\n                                  y = df_map2['Acronym State'],\n                                  mode = 'lines+markers',\n                                  line_color = 'rgb(128, 0, 128)',\n                                  name = 'Mean Salary'),\n                       1, 2)\n\nfig_states.update_layout(title = 'Distribution of the Offers Jobs From in United States',\n                        yaxis = dict(showgrid = True,\n                                    showline = True,\n                                    showticklabels = True,\n                                    linecolor = 'rgba(102,102,102,0.8)',\n                                    linewidth = 2,\n                                    domain = [0, 0.94],\n                                    ),\n                        yaxis2 = dict(showgrid = True,\n                                     showline = True,\n                                     showticklabels = False,\n                                     linecolor = 'rgba(102,102,102,0.8)',\n                                     linewidth = 1,\n                                     domain = [0, 0.94],\n                                     ),\n                        xaxis = dict(zeroline = False,\n                                    showline = False,\n                                    showticklabels = True,\n                                    showgrid = True,\n                                    domain = [0, 0.40],\n                                    dtick = 5,\n                                    ),\n                        xaxis2 = dict(zeroline = False,\n                                     showline = False,\n                                     showticklabels = True,\n                                     showgrid = True,\n                                     domain = [0.47, 1],\n                                     side = 'top',\n                                     dtick =8,\n                                     ),\n                        legend = dict(x = 0.02, y = 1.07, font_size = 12),\n                        margin = dict(l = 100, r = 20, t = 70, b = 70),\n                        paper_bgcolor='rgb(250, 248, 255)',\n                        plot_bgcolor='rgb(250, 248, 255)',)\n\nfig_states.show()","5386754d":"# A dictionary is created with a list of hard skills to search in the job description fields\nimport re #Library for regular expresions \n\nhard_skills_dict = {\n    'Python': r\"python\",\n    'R': r\"[\\b\\s\/]r[\\s,\\.]\",\n    'Excel': r\"excel\",\n    'SQL': r\"sql\",\n    'NoSQL': r\"\\bNo[\\s,-]sql[\\s]\",\n    'PowerBI': r\"power[\\s]BI\",\n    'Tableau': r\"tableau\",\n    'SPSS': r'\\bSPSS\\b',\n    'Big Data': r\"\\sbig\\sdata\\s\",\n    'SAP BI': r\"SAP[\\s]BI\",\n    'MongoDB': r\"MongoDB\",\n    'Hadoop': r\"Hadoop\",\n    'SAS': r\"\\bSAS\\b\",\n    'VBA': r\"\\bvba\\b\",\n    'AWS': r\"\\baws\\b\",\n    'Git': r\"\\bGit\",\n    'QlikView': r\"\\bQlikView\",\n    'Oracle BI': r\"oracle[\\n]BI\",\n    'Scala': r\"Scala\",\n    'Dashboard': r\"\\bDashboard[s]\",\n    'Spark': r\"Spark\",\n    'Matlab': r\"Matplotlib\",\n    'Linux': r\"linux\",\n    'Unix': r\"unix\",\n    'Looker': r\"looker\",\n    'C# or C++': r\"\\bC[#\\+\\+]\",\n    'Java': r\"java\",\n    'PowerPivot': r\"Power[\\s]Pivot\",\n    'PowerQuery': r\"Power[\\s]Query\",\n    'BigQuery': r\"Big[\\s]Query\",\n    'Apache Cassandra': r\"[\\b\\s]Cassandra[\\b\\s]\",\n    'Neo4j': r\"Neo4j\",\n    'TensorFlow': r\"TensorFlow\"\n}\n\nhard_skills_count = {}\n\n# Loop through skills for count the frecuency in Jobs Description Field.\nfor key, search in hard_skills_dict.items():\n    hard_skills_count[key] = df1['Job Description'].str.contains(search, flags = re.IGNORECASE).sum()\n\ndf_skills = pd.DataFrame.from_dict(hard_skills_count, orient = 'index') \\\n                        .sort_values(0, ascending = False) \\\n                        .reset_index() \\\n                        .rename(columns = {'index': 'Skills', 0: 'Count'})\n\ndf_skills['Relative Frecuency'] = (df_skills['Count'] \/ sum(df_skills['Count'])) *100\ndf_skills['Relative Frecuency'] = df_skills['Relative Frecuency'].apply(lambda x: round(x, 2))\n\n# Remove values less than '1' per cent in its Relative Frequency\ndf_skills = df_skills.drop(df_skills[df_skills['Relative Frecuency'] < 1.00].index, axis = 0)\n\ndf_skills.head(df_skills.shape[0])","b6052763":"# Plot visualization the tops hards skills.\nchart_skills = px.bar(df_skills, x = 'Skills', y = 'Count',\n                     color = 'Relative Frecuency',\n                     labels = {'Skills': 'Hard Skills','Count': 'N\u00ba of Requests'})\nchart_skills.show()","aa2c3cb4":"# A cluster study is performed in a data frame for the data in order to find similarities\n# In addition, this is supported with PCA study\n# Import Library\nfrom sklearn.decomposition import PCA # For PCA dimensionality reduction\nfrom sklearn.cluster import KMeans    # Method for Cluster Kmeans\nfrom sklearn.preprocessing import QuantileTransformer #Realize Scaler Data\n# For visualization from 3D plot\nimport plotly.express as px","878eff9e":"# Create Data Frame with \"Mean Salary, Founded Years and Rating\" for cluster method and PCA\ndf2 = df1.copy()\ndf2 = df2.drop(df2[df2['Founded'] == -1].index, axis = 0)\ndf2 = df2.drop(df2[df2['Rating'] == -1.0].index, axis = 0)\ndf2['Years Founded'] = (2020 - df2['Founded'])\ndf2['Mean Salary'] = (df2['Max Salary'] + df2['Min Salary']) \/ 2\n\n# Create DataFrame\ndf3 = pd.DataFrame()\ndf3 = pd.concat([df2['Rating'], df2['Mean Salary'], df2['Years Founded']], axis = 1)\ndf3.head()","7aa4901f":"# Rescale values with QuantileTransformer class\ndf3_scaler = QuantileTransformer().fit_transform(df3)\nprint(df3_scaler)","500d6cfa":"# PCA calculation is performed with a reduction of dimensionality equal to 2\npca = PCA(n_components = 2)\ndf_component = pca.fit_transform(df3_scaler)\nprint(df_component.shape, df3_scaler.shape)","8eac833b":"# The clusters numbers is determined to minimize inertian infracluster through elbow method\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', n_init = 10, \n                   max_iter = 300, random_state = 0)\n    kmeans.fit(df3_scaler)\n    wcss.append(kmeans.inertia_)","994af3a3":"#Plot curve inertian infracluster\nfig = plt.figure(figsize = (8,7))\nplt.plot(range(1,11), wcss)\nplt.scatter(4, wcss[3], c = 'red',s = 200)\nplt.text(4 + 0.4, wcss[3], s = '4 - Clusters', fontsize = 14)\nplt.xlabel('N\u00ba Clusters', fontsize = 14)\nplt.ylabel('Inertian Infraclusters', fontsize = 14)\nplt.title('Elbow Method', fontsize = 14)","09207a55":"# 4 clusters are selected, at that elbow point an optimized cluster can be achieved.\nkmeans = KMeans(n_clusters = 4, init = 'k-means++', n_init = 10, \n                max_iter = 300, random_state = 0)\nkmeans.fit(df3_scaler)\ny_predict = kmeans.predict(df3_scaler)\nprint(y_predict)","5865e7e9":"# First one, 3D visualization are better for show clusters calculated\ncolors = ['crimson','yellow', 'indigo', 'lightseagreen']\n\nfig3d = px.scatter_3d(df3, x = 'Rating', y = 'Mean Salary', z = 'Years Founded', \n                      color = recode(pd.Series(pd.Categorical(y_predict, [0,1,2,3,4])),\n                                    {0: 'Cluster-1',\n                                     1: 'Cluster-2',\n                                     2: 'Cluster-3',\n                                     3: 'Cluster-4'}),\n                      color_discrete_sequence= colors,\n                      opacity = 0.9, \n                      size_max = 5)\n\nfig3d.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n\nfig3d.show()","fbf6523e":"# Graph PCA component with cluster predict\ndfsns = pd.DataFrame(df_component)\n# Rename Columns:\ndfsns = dfsns.rename(columns = {0: 'Component 1', 1: 'Component 2'})\n\n#Plot with Seaborn\nsns.set_style('darkgrid')\nsns.relplot(x = 'Component 1', \n            y = 'Component 2', \n            hue = recode(pd.Series(pd.Categorical(y_predict, [0,1,2,3,4])),\n                        {0: 'Cluster-1',\n                         1: 'Cluster-2',\n                         2: 'Cluster-3',\n                         3: 'Cluster-4'}), \n            data = dfsns, \n            palette= colors)","e88a8e2b":"df_predict = pd.DataFrame(y_predict)\ndf_predict = df_predict.rename(columns = {0 : 'Cluster'})\ndf_predict.head()","3dbe82ff":"# Dataframe with cluster classification\ndf3_scaler = pd.DataFrame(df3_scaler)\ndf3_scaler = df3_scaler.rename(columns = {0: 'Rating', 1: 'Mean Salary', 2: 'Years Founded'})\ndf3_scaler['Cluster'] = df_predict['Cluster']\ndf3_scaler['Cluster'] = recode(df3_scaler['Cluster'], \n                               {0: 'Cluster-1', \n                                1: 'Cluster-2', \n                                2: 'Cluster-3',\n                                3: 'Cluster-4'}\n                              )\ndf3_scaler.head()","fc0e25fd":"# Groupby apply\ndf_cluster_group = df3_scaler.groupby('Cluster').mean()\ndf_cluster_group.head(df_cluster_group.shape[0])","87e89787":"# RADAR PLOT:\ncolors = ['crimson','gold', 'darkcyan', 'magenta']\ny = np.array(df_cluster_group)\ncategories = list(df_cluster_group.columns)\nradar_chart = go.Figure()\n\n#Cluster 1\nradar_chart.add_trace(go.Scatterpolar(r = y[:1,:].tolist()[0],\n                                     theta = categories,\n                                     fill = 'toself',\n                                     name = 'Cluster-1',\n                                     marker = dict(color = colors[0])\n                                     ))\n\n#Cluster 2\nradar_chart.add_trace(go.Scatterpolar(r = y[1:2,:].tolist()[0],\n                                     theta = categories,\n                                     fill = 'toself',\n                                     name = 'Cluster-2',\n                                     marker = dict(color = colors[1])\n                                     ))\n\n#Cluster 3\nradar_chart.add_trace(go.Scatterpolar(r = y[2:3,:].tolist()[0],\n                                     theta = categories,\n                                     fill = 'toself',\n                                     name = 'Cluster-3',\n                                     marker = dict(color = colors[2])\n                                     ))\n\n#Cluster 4\nradar_chart.add_trace(go.Scatterpolar(r = y[3:4,:].tolist()[0],\n                                     theta = categories,\n                                     fill = 'toself',\n                                     name = 'Cluster-4',\n                                     marker = dict(color = colors[3])\n                                     ))\n\n# Update Layout\nradar_chart.update_layout(polar = dict(radialaxis = dict(visible = True,\n                                                        range = [0.0, 0.8])),\n                         showlegend = True,\n                         title = \"Graph Radar About Principal Fields\")\n\n\nradar_chart.show()","f5add659":"# Plot clusters in graph bars to identify to better\nfig_bars = make_subplots(rows = 1, cols = 4, shared_yaxes = True)\n\n\n# Cluster 1\nfig_bars.add_trace(go.Bar(x = categories, \n                          y = y[:1,:].tolist()[0],\n                          marker = dict(color = colors,),\n                          name = 'Cluster - 1'),\n                   row = 1, \n                   col = 1)\n# Cluster 2\nfig_bars.add_trace(go.Bar(x = categories, \n                          y = y[1:2,:].tolist()[0],\n                          marker = dict(color = colors),\n                          name = 'Cluster - 2'),\n                   row = 1,\n                   col = 2)\n\n# Cluster 3\nfig_bars.add_trace(go.Bar(x = categories, \n                          y = y[2:3,:].tolist()[0],\n                          marker = dict(color = colors), \n                          name = 'Cluster - 3'),\n                   row = 1,\n                   col = 3)\n\n# Cluster 4\nfig_bars.add_trace(go.Bar(x = categories, \n                          y = y[3:4,:].tolist()[0],\n                          marker = dict(color = colors), \n                          name = 'Cluster - 4'),\n                   row = 1,\n                   col = 4)\n\nfig_bars.update_layout(showlegend = False, title = 'Cluster Behavior')\n\nfig_bars.show()","9a833285":"# Companies Easy Apply for Data Analyst Jobs","e7351b2f":"# Classification of Companies vs Ratings","317ec26d":"# Hard Skills That it is Most Requested per The Companies","60a086b0":"# Cluster Analysis (K-Means) and PCA","029223f3":"# Import DataSet 'Data Analyst Jobs'","def7c958":"# Data Cleaning to be Worked On","ccb2b5f1":"# Ownership Companies Type that Offers Jobs Data Analyst","d21d84ca":"# Range Salary for Each Sector","9bfdee0b":"# Distribution of Job Offers as a Data Analyst in the Territory of the United States","974c5ea0":"# **Size Company - Employed Quantity that Offer Jobs as a Data Analyst**"}}