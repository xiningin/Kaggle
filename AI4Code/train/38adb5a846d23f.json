{"cell_type":{"6290f05a":"code","3e148c45":"code","89a72aad":"code","d8bd5a8d":"code","7d9d473b":"code","e7499891":"code","8f5b4dd2":"code","310adc63":"code","325cc1c9":"code","73db02bf":"code","76dfe98d":"code","415b043d":"code","9d11c2a1":"code","f6104dca":"code","08627195":"code","7e5e2c75":"code","7a514594":"code","0e47ea0a":"code","33df0d27":"code","c93c0eff":"code","e5506588":"markdown","cca4c734":"markdown","08c1c51a":"markdown","bc2c43e2":"markdown","2d0263af":"markdown","a6881b13":"markdown","bd7c2eb6":"markdown","5b020f91":"markdown","2bfd1365":"markdown","7287803c":"markdown","0997e4d5":"markdown","68fe383c":"markdown","cc670e09":"markdown","8b53ce5a":"markdown","a395ba37":"markdown","1d950011":"markdown","5aaa5a48":"markdown","bcab3d4b":"markdown","68589b46":"markdown","9fed7109":"markdown","882281c2":"markdown","c3e09567":"markdown","97538248":"markdown"},"source":{"6290f05a":"import os\nimport zipfile\nimport random\nimport tensorflow as tf\nimport shutil\nimport numpy as np\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.regularizers import l2\nfrom shutil import copyfile\nfrom os import getcwd","3e148c45":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","89a72aad":"local_zip = '\/kaggle\/input\/dogs-vs-cats-redux-kernels-edition\/train.zip'\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('training_all')\nzip_ref.close()","d8bd5a8d":"print(len(os.listdir('\/kaggle\/working\/training_all\/train')))","7d9d473b":"base_dir = '\/kaggle\/working'\ntrain_dir = os.makedirs(os.path.join(base_dir, 'train'))\nvalidation_dir = os.makedirs(os.path.join(base_dir, 'validation'))\n\n# Directory with our training cat pictures\ntrain_cats_dir = os.makedirs('\/kaggle\/working\/train\/cats')\n\n# Directory with our training dog pictures\ntrain_dogs_dir = os.makedirs('\/kaggle\/working\/train\/dogs')\n\n# Directory with our validation cat pictures\nvalidation_cats_dir = os.makedirs('\/kaggle\/working\/validation\/cats')\n\n# Directory with our validation dog pictures\nvalidation_dogs_dir = os.makedirs('\/kaggle\/working\/validation\/dogs')","e7499891":"TRAIN_SOURCE = \"\/kaggle\/working\/training_all\/train\/\"\nTRAINING_CATS_DIR = \"\/kaggle\/working\/train\/cats\/\"\nVAL_CATS_DIR = \"\/kaggle\/working\/validation\/cats\/\"\nTRAINING_DOGS_DIR = \"\/kaggle\/working\/train\/dogs\/\"\nVAL_DOGS_DIR = \"\/kaggle\/working\/validation\/dogs\/\"\nSPLIT_SIZE = 0.8\n\nlist_images = os.listdir(TRAIN_SOURCE)\nprint(len(list_images))\nfiles = []\nfor file_name in list_images:\n    if(os.path.getsize(TRAIN_SOURCE + file_name)) > 0:\n        files.append(file_name)\n    else:\n        print(file_name + \"has zero length!\")\n        \nfiles = random.sample(files, len(files))\ntrain_set = files[0:round(SPLIT_SIZE*len(files))]\nval_set = files[-(len(files) - len(train_set)):]\nprint(\"Train-set size:\", len(train_set))\nprint(\"Validation-set size:\", len(val_set))\nfor file_name in train_set:\n    if('cat' in file_name):        \n        copyfile(TRAIN_SOURCE + file_name, TRAINING_CATS_DIR + file_name)\n    elif('dog' in file_name):\n        copyfile(TRAIN_SOURCE + file_name, TRAINING_DOGS_DIR + file_name)\nfor file_name in val_set:\n    if('cat' in file_name):        \n        copyfile(TRAIN_SOURCE + file_name, VAL_CATS_DIR + file_name)\n    elif('dog' in file_name):\n        copyfile(TRAIN_SOURCE + file_name, VAL_DOGS_DIR + file_name)","8f5b4dd2":"print('First 5 cats in training:', os.listdir(TRAINING_CATS_DIR)[0:5])\nprint('First 5 dogs in training:', os.listdir(TRAINING_DOGS_DIR)[0:5])\nprint('First 5 cats in validation:', os.listdir(VAL_CATS_DIR)[0:5])\nprint('First 5 dogs in validation:', os.listdir(VAL_DOGS_DIR)[0:5])","310adc63":"print('# of cats in training-set:', len(os.listdir(TRAINING_CATS_DIR)), '\\n# of dogs in training-set:', len(os.listdir(TRAINING_DOGS_DIR)))\nprint('# of cats in validation-set:', len(os.listdir(VAL_CATS_DIR)), '\\n# of dogs in validation-set:', len(os.listdir(VAL_DOGS_DIR)))","325cc1c9":"# EarlyStopping and Reduce Learning Rate Callbacks\nmy_callback_es = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=5)\nmy_callback_rlr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', patience=2, factor=0.5, min_lr=0.00001, verbose=1)\n\nmodel = tf.keras.models.Sequential([\n    #Conv layer 1\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(132, 132, 3)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(2, 2),\n    #Conv layer 2\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(2, 2),\n    #Conv layer 3\n    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(2, 2),\n    #Conv layer 4\n    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(2, 2),\n    #Conv layer 5\n    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPool2D(2, 2),\n    #Flatten\n    tf.keras.layers.Flatten(),\n    #Fully Connected layer\n    tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=l2(0.001)),\n    tf.keras.layers.BatchNormalization(),\n    #Dropout\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001))\n    \n])\nmodel.summary()\nmodel.compile(optimizer=RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['acc'])","73db02bf":"TRAINING_DIR = \"\/kaggle\/working\/train\/\"\ntrain_datagen = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\ntrain_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n                                                    batch_size=16,\n                                                    class_mode='binary',\n                                                    target_size=(132, 132))\n\nVALIDATION_DIR =  \"\/kaggle\/working\/validation\/\"\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255)\n\nvalidation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n                                                             batch_size=16,\n                                                             class_mode='binary',\n                                                             target_size=(132, 132))","76dfe98d":"history = model.fit_generator(\n    train_generator, \n    steps_per_epoch = len(train_set) \/\/ 16,\n    epochs = 100,\n    verbose = 1,\n    validation_data = validation_generator,\n    validation_steps = len(val_set) \/\/ 16,\n    callbacks=[my_callback_es, my_callback_rlr]\n)","415b043d":"import matplotlib.pyplot as plt\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.ylim(top=1.0)\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","9d11c2a1":"model.save_weights('Dense1024_Dropout_model_wieghts.h5')\nmodel.save('Dense1024_Dropout_model_keras.h5')","f6104dca":"local_zip = '\/kaggle\/input\/dogs-vs-cats-redux-kernels-edition\/test.zip'\nzip_ref = zipfile.ZipFile(local_zip, 'r')\nzip_ref.extractall('test_all')\nzip_ref.close()","08627195":"test_images = os.listdir('\/kaggle\/working\/test_all\/test')\nprint(len(test_images))","7e5e2c75":"print(test_images[0:5])","7a514594":"test_ids = [int(test_img[:-4]) for test_img in test_images]\nprint(test_ids[0:5])","0e47ea0a":"TEST_DIR = \"\/kaggle\/working\/test_all\/\"\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntest_generator = test_datagen.flow_from_directory(TEST_DIR,\n                                                  target_size=(132, 132),\n                                                  batch_size=16,\n                                                  class_mode='categorical',\n                                                  shuffle=False)\ntest_generator.reset()\npredictions = model.predict_generator(test_generator, verbose=1)","33df0d27":"predictions = predictions.flatten()","c93c0eff":"import pandas as pd\n\nsubmission = pd.DataFrame({\"id\": test_ids, \"label\": predictions})\nsubmission.to_csv(\"dogs_cats2.csv\", index = False)\nsubmission.head()","e5506588":"## Extract test data from zip file.","cca4c734":"## Import necessary libraries","08c1c51a":"# Image augmentation with ImageDataGenerator","bc2c43e2":"## ImageDataGenerator again.","2d0263af":"## Check the test image formats.","a6881b13":"# This is my first notebook with Deep Learning and CNN, and I saw this dataset on Tensorflow in Practice Specialization on Coursera. I hope you'll like it. Please ask if you have any questions. I will be pleased if you upvote this notebook unless you don't like it. Thanks for your time. ","bd7c2eb6":"## Create folders for the train-set and validation-set. I created two different cats and dogs folder both in train and val. Because I am going to use ImageDataGenerator, the flow_from_directory method will identify classes automatically from the folder name. ","5b020f91":"## Save the model and model weights. These files will going to output folder as expected. You can download them.","2bfd1365":"# Also learning rate dropped by half six times due to ReduceLROnPlateau callback. (If there is no improvement in validation-accuracy for two epochs, learning rate halves.)","7287803c":"# Got ~0.95 validation accuracy and training stopped due to EarlyStopping callback. (If there are no improvement in validation-accuracy for five epochs, training stops.)","0997e4d5":"### Flatten predictions array to get 1-D array for submission.","68fe383c":"# We'll use 20% of the training-set as the validation-set.","cc670e09":"# Create Model","8b53ce5a":"# I copied all files in training to correct folders(cats or dogs) according to if they contain cat or dog in the file name.","a395ba37":"# Visualize accuracies and losses.","1d950011":"# Thank you! Please upvote if you liked it.","5aaa5a48":"## Check if we unzipped correctly. os.listdir converts all files in directory to list, so we can use len with list.","bcab3d4b":"# There is an incompatibility between predict_generator and train,val generators. Indexes are not matching while predicting. There is no problem in the model, but submission scores just like random guessing. A lot of people on the internet mentioned this problem, but there is no simple solution to this. If I found a solution, I'll update the prediction part.","68589b46":"![1.png](attachment:1.png)\n![2.png](attachment:2.png)\n![3.png](attachment:3.png)\n![4.png](attachment:4.png)","9fed7109":"# Train","882281c2":"## Extract train data from zip file.","c3e09567":"![5.png](attachment:5.png)","97538248":"## Save predictions."}}