{"cell_type":{"cd80ad81":"code","f5fa3506":"code","b595cd68":"code","244e2132":"code","16a5c50c":"code","e40a3c21":"code","2d31bbc8":"code","39bd10ee":"code","62c19802":"code","d6bb7660":"code","0e3b9042":"code","a12390d2":"code","b63fcd5a":"code","7fe44a4b":"code","66ef02c0":"code","e0d38c5a":"code","57ae2640":"code","787f4cbd":"code","d69fed3c":"code","b08b20c2":"code","f4880fb1":"code","d08f9d88":"code","59e90c2d":"code","7175dbc4":"code","db70ddcb":"code","231e6108":"code","06eeaed2":"code","35e2ea84":"code","5d5b3d7b":"code","30ca7eaf":"code","183461c9":"code","f1bfcfc9":"code","e196fbf0":"code","68c98093":"code","605ce4fd":"code","f5c31865":"code","4f63e241":"code","94ab6751":"code","daa86e77":"code","c1a78b29":"code","eb41c44e":"code","7993c58a":"code","2e9dced2":"code","d27a36af":"code","1fe63290":"code","5238092d":"code","964cfa34":"code","de5f8bea":"code","0d8895c3":"code","89f8ac59":"code","c343bd59":"code","36161a36":"code","69c3ba88":"code","037bea41":"code","170a5fa1":"markdown","76158230":"markdown","caef1905":"markdown","30427cfa":"markdown","e84df8ba":"markdown","1bcccbe1":"markdown","927421ac":"markdown","18f2d36c":"markdown","54cab3ed":"markdown","90e821e2":"markdown","29d884d2":"markdown","78e64940":"markdown","9626d726":"markdown","c20a061e":"markdown","efe1cb27":"markdown","84c7e2ae":"markdown","4bc2060f":"markdown","a5e08166":"markdown","5967be73":"markdown","b7edb230":"markdown","a5655a23":"markdown","0385ca91":"markdown","54671e45":"markdown","16df017b":"markdown","caddc356":"markdown","9ef5db9b":"markdown","a3fe5230":"markdown","cff44464":"markdown","dead99d7":"markdown","9a19c679":"markdown","f6e9e13e":"markdown","3f1752f4":"markdown","5e739b1b":"markdown","59769c67":"markdown","8b400c74":"markdown","2972e3d1":"markdown","4b1380eb":"markdown","2d501545":"markdown","3d1211da":"markdown","c6068555":"markdown","fcbe9887":"markdown","b198cb30":"markdown","cc366eee":"markdown","17325eb5":"markdown","ff0b6dbd":"markdown","87a1bccc":"markdown","831a1bee":"markdown","994acdec":"markdown","bb9457cd":"markdown","e2f6b359":"markdown","292b9d7b":"markdown","225dbc04":"markdown","b433e1d5":"markdown","c0e24c41":"markdown","35e1d4f3":"markdown","bbe3f4f2":"markdown","e8739311":"markdown","b1783fc1":"markdown","aafcc0f2":"markdown","89fe454f":"markdown","e84f9dba":"markdown","012e9726":"markdown","4252adf9":"markdown"},"source":{"cd80ad81":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f5fa3506":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n","b595cd68":"train.columns","244e2132":"train.head()","16a5c50c":"train.describe()","e40a3c21":"train.info()","2d31bbc8":"train.shape","39bd10ee":"train.dtypes","62c19802":"train.corr()","d6bb7660":"sns.heatmap(train.corr(), annot=True)\nplt.show()","0e3b9042":"def detect_outliers(train, n, features):\n   \n    outlier_indices = [] \n    for col in features: \n        Q1 = np.percentile(train[col], 25)\n        Q3 = np.percentile(train[col], 75)\n        IQR = Q3 - Q1\n        outlier_step = 1.5 * IQR \n        outlier_list_col = train[(train[col] < Q1 - outlier_step) | (train[col] > Q3 + outlier_step)].index\n        outlier_indices.extend(outlier_list_col) \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(key for key, value in outlier_indices.items() if value > n) \n    return multiple_outliers\n\noutliers_to_drop = detect_outliers(train, 2, ['Age', 'SibSp', 'Parch', 'Fare'])\nprint(\"We will drop these {} indices: \".format(len(outliers_to_drop)), outliers_to_drop)\n","a12390d2":"train.loc[outliers_to_drop, :]","b63fcd5a":"print(\"Before: {} rows\".format(len(train)))\ntrain= train.drop(outliers_to_drop, axis = 0).reset_index(drop = True)\nprint(\"After: {} rows\".format(len(train)))","7fe44a4b":"sns.countplot(x='Survived',data=train)\n","66ef02c0":"sns.countplot(x='Survived',data=train,hue='Sex',palette='RdBu_r')","e0d38c5a":"sns.countplot(x='Survived',data=train,hue='Pclass')","57ae2640":"sns.histplot(train['Age'].dropna(),bins=30,kde=False)","787f4cbd":"sns.barplot(x='SibSp',y='Survived',data=train)","d69fed3c":"sns.barplot(x='Parch',y='Survived',data=train)","b08b20c2":"sns.barplot(x='Embarked',y='Survived',data=train)","f4880fb1":"train['Fare'].hist(bins=40,figsize=(10,4))","d08f9d88":"train.isnull().sum()","59e90c2d":"train.isnull().head()","7175dbc4":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","db70ddcb":"plt.figure(figsize=(10,7))\nsns.boxplot(x='Pclass',y='Age',data=train)","231e6108":"train.groupby('Pclass').mean()['Age'].round()","06eeaed2":"mean_class1 = train.groupby('Pclass').mean()['Age'].round().loc[1]\nmean_class2 = train.groupby('Pclass').mean()['Age'].round().loc[2]\nmean_class3 = train.groupby('Pclass').mean()['Age'].round().loc[3]","35e2ea84":"train.loc[train['Pclass']==1,'Age'] = train.loc[train['Pclass']==1,'Age'].fillna(value=mean_class1)\ntrain.loc[train['Pclass']==2,'Age'] = train.loc[train['Pclass']==2,'Age'].fillna(value=mean_class2)\ntrain.loc[train['Pclass']==3,'Age'] = train.loc[train['Pclass']==3,'Age'].fillna(value=mean_class3)","5d5b3d7b":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","30ca7eaf":"train.drop('Cabin',axis=1,inplace=True)","183461c9":"train.dropna(inplace=True) # dropping the 1 missing value in Embarked column","f1bfcfc9":"sex = pd.get_dummies(train['Sex'],drop_first=True)","e196fbf0":"embark = pd.get_dummies(train['Embarked'],drop_first=True)","68c98093":"train = pd.concat([train,sex,embark],axis=1)","605ce4fd":"train.head(2)","f5c31865":"train.drop(['Sex','Embarked','Name','Ticket','PassengerId'],axis=1,inplace=True)","4f63e241":"train.head()","94ab6751":"test.loc[test['Pclass']==1,'Age'] = test.loc[test['Pclass']==1,'Age'].fillna(value=mean_class1)\ntest.loc[test['Pclass']==2,'Age'] = test.loc[test['Pclass']==2,'Age'].fillna(value=mean_class2)\ntest.loc[test['Pclass']==3,'Age'] = test.loc[test['Pclass']==3,'Age'].fillna(value=mean_class3)","daa86e77":"sns.heatmap(test.isnull(),yticklabels=False,cbar=False,cmap='viridis')","c1a78b29":"test.drop('Cabin',axis=1,inplace=True)","eb41c44e":"test.dropna(inplace=True)","7993c58a":"sex = pd.get_dummies(test['Sex'],drop_first=True)\nembark = pd.get_dummies(test['Embarked'],drop_first=True)","2e9dced2":"test = pd.concat([test,sex,embark],axis=1)","d27a36af":"test.drop(['Sex','Embarked','Name','Ticket','PassengerId'],axis=1,inplace=True)","1fe63290":"test.head()","5238092d":"X = train.drop('Survived',axis=1)\ny = train['Survived']","964cfa34":"from sklearn.model_selection import train_test_split","de5f8bea":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","0d8895c3":"from sklearn.linear_model import LogisticRegression","89f8ac59":"logmodel = LogisticRegression(solver='lbfgs', max_iter=1000)\nlogmodel.fit(X_train,y_train)","c343bd59":"logmodel.score(X_train,y_train)","36161a36":"logmodel.score(X_test,y_test)","69c3ba88":"predictions = logmodel.predict(X_test)","037bea41":"from sklearn.metrics import confusion_matrix\n\nprint(confusion_matrix(y_test, predictions))\n","170a5fa1":"Next, we need to import the train_test_split function from scikit-learn. The following code executes this import:","76158230":"**DESCRIPTION OF DATA FIELDS IN TITANIC**","caef1905":"**Detect and remove outliers in numerical variables:**\n\nOutliers are data points that have extreme values and they do not conform with the majority of the data. It is important to address this because outliers tend to skew our data towards extremes and can cause inaccurate model predictions.","30427cfa":"**columns in the data frame**","e84df8ba":"**MISSING VALUES**","1bcccbe1":"We can conclude that there are strong positive correlations between SibSp and Parch\u2014and that makes sense because children often have siblings, and parents and children often travel together. We can also see that Pclass and Fare are strongly negatively correlated\u2014that makes sense because 1st class tickets are more expensive than lower class tickets, meaning as class goes down (closer to 1) the fare goes up. Finally Age and Pclass are moderately negatively correlated\u2014since richer people are generally older.","927421ac":"**MEDIUM ARTICLE DESCRIBING THE SURVIVAL OF PASSENGERS USING LOGISTIC REGRESSION**  ","18f2d36c":"**Survived vs Sex**","54cab3ed":"The RMS Titanic was a British passenger liner that sank in the North Atlantic Ocean in the early morning hours of 15 April 1912, after it collided with an iceberg during its maiden voyage from Southampton to New York City. There were an estimated 2,224 passengers and crew aboard the ship, and more than 1,500 died, making it one of the deadliest commercial peacetime maritime disasters in modern history. The RMS Titanic was the largest ship afloat at the time it entered service and was the second of three Olympic-class ocean liners operated by the White Star Line. The Titanic was built by the Harland and Wolff shipyard in Belfast. Thomas Andrews, her architect, died in the disaster.","90e821e2":"First, we need to divide our data into x values (the data we will be using to make predictions) and y values (the data we are attempting to predict). The following code handles this:","29d884d2":"it\u2019s time to split our titanic data into training data and test data. As before, we will use built-in functionality from scikit-learn to do this.","78e64940":"The training-set has 891 examples and 11 features + the target variable (survived).","9626d726":"Like all regression analyses, the logistic regression is a predictive analysis. Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables.","c20a061e":"It seems that having 1 Sibsp has the highest probability of surviving","efe1cb27":"**Train and build Classifier**","84c7e2ae":"**Survived**","4bc2060f":"**Training the Logistic Regression Model**","a5e08166":"I will now convert some of the categorical features in the dataset into dummy variables that our machine learning model can accept.","5967be73":"It seems that most of the passengers boarding from C has high chances of survival so Embarked plays important role in our prediction","b7edb230":"**Pandas dataframe.info() function is used to get a concise summary of the dataframe.**","a5655a23":"**Making Predictions With Our Logistic Regression Model**","0385ca91":"I have dropped unnecessary columns which are not important for our prediction.","54671e45":"**Logistic Regression**","16df017b":"There seems to be an interesting bi-modal distribution where there are quite a few young passengers between age 0 and 10. Then the average age tends to be around 20\u201330.","caddc356":"**Fare**","9ef5db9b":"**Pandas describe() is used to view some basic statistical details like percentile, mean, std etc.**","a3fe5230":"**confusion matrix**","cff44464":"Let\u2019s make a set of predictions on our test data using the logistic regression model we just created.","dead99d7":"**Filling the missing values**","9a19c679":"Having 3 parents\/children Aboard has highest chance of survival","f6e9e13e":"[LINK TO THE ARTICLE](http:\/\/poojithakodali5.medium.com\/exploratory-data-analysis-and-logistic-regression-on-titanic-data-set-354c3e0d553)","3f1752f4":"This function will loop through a list of features and detect outliers in each one of those features\n\n1- In each loop, a data point is deemed an outlier if it is less than the first quartile minus the outlier step or exceeds\n\n2- third quartile plus the outlier step. The outlier step is defined as 1.5 times the interquartile range.\n\n3- Once the outliers have been determined for one feature, their indices will be stored in a list before proceeding to the next feature and the process repeats until the very last feature is completed.\n\n4- Finally, using the list with outlier indices, we will count the frequencies of the index numbers and return them if their frequency exceeds n times.","5e739b1b":"# Visualizing The Data Set","59769c67":"**I will now convert some of the categorical features in the dataset into dummy variables that our machine learning model can accept.**","8b400c74":"I have converted categorical features in the dataset into dummy variables that our machine learning model can accept.","2972e3d1":"survival - Survival (0 = No; 1 = Yes)\nclass - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd).\n\nname - Name.\n\nsex - Sex.\n\nage - Age.\n\nsibsp - Number of Siblings\/Spouses Aboard.\n\nparch - Number of Parents\/Children Aboard.\n\nticket - Ticket Number.\n\nfare - Passenger Fare.\n\ncabin - Cabin.\n\nembarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton).","4b1380eb":"**Age**","2d501545":"**Survived vs Pclass**","3d1211da":"The missing values in the data set are Age,Cabin\nvery few of the missing values in Embarked.","c6068555":"![TITANIC IMAGE](http:\/\/miro.medium.com\/max\/1582\/1*mil2wAN58x-j4qU67-_7lg.jpeg)","fcbe9887":"# EXPLORATORY DATA ANALYSIS AND PREDICTION USING LOGISTIC REGRESSION TITANIC DATA SET","b198cb30":"Dropping the cabin column","cc366eee":"**head() gives the first 5 rows**","17325eb5":"**Survived vs Embarked**","ff0b6dbd":"This is the end of eda the data is ready for prediction.","87a1bccc":"**Sibsp vs Survived**","831a1bee":"## Questions that we should ask ourselves about the data set:\n1.What were the passengers types\n\n2.What is the embarking place of the passengers\n\n3.How does Pclass relate to survival of the passengers\n\n4.How many people were traveling alone or with the family, and how does it effect the survival rate.\n\n5.what factors helped someone survive the sinking","994acdec":"**Now lets perform similar data cleaning on the test data.**","bb9457cd":"# Prediction Using Logistic Regression","e2f6b359":"It looks like people that did not survive were much more likely to be men. While those who survived were twice as likely to be female.","292b9d7b":"If we glimpse at the data, we\u2019re missing some age information, we\u2019re missing a lot of cabin info and we\u2019re missing one row of embarked. We need to clean our dataset before we begin to train our logistic regression model. Lets first try and fill in the missing age values. I\u2019m going to do this by filling in the missing age with the mean age of the passenger class that the passenger belongs to.","225dbc04":"2 of the features are floats, 5 are integers and 5 are objects.","b433e1d5":"Next, we need to create our model by instantiating an instance of the LogisticRegression object:","c0e24c41":"Also it looks like the people who did not survive were overwhelmingly part of 3rd class. People that did survive were from the higher classes.\nNow lets try and understand the age of the onboard passengers.","35e1d4f3":"Lastly, we can use the train_test_split function combined with list unpacking to generate our training data and test data:","bbe3f4f2":"Our model has now been trained","e8739311":"**Dropping the unwanted columns**","b1783fc1":"**OUR MAIN THEME IS TO PREDICT THE SURVIVAL OF PASSENGERS**","aafcc0f2":"we can see that the percentage of not survived people is more than the people who survived.","89fe454f":"**Parch vs Survived**","e84f9dba":"Let us see how survival is dependent upon the sex","012e9726":"The null values in the Age are dropped.I\u2019m going to just drop the cabin column since there\u2019s too much missing information.","4252adf9":"Missing values in train data"}}