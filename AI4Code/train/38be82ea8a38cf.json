{"cell_type":{"54b36a85":"code","8fb17468":"code","570ac24f":"code","e0947ff1":"code","5dbec04f":"code","cbf030f3":"code","ee25ceba":"code","9bc2394f":"code","01997474":"code","dd0075bb":"code","3233242c":"code","aa3408cc":"code","21c82394":"code","f00a1a76":"code","a9ac2ffa":"code","35b7d009":"code","607496cd":"code","d9bb3508":"code","0cb39720":"code","09c185e0":"code","625073b4":"code","8bde7814":"code","c94f203d":"code","934f8539":"code","a8f3f040":"code","7d13b01a":"code","c12dde59":"code","6406eed9":"code","8f3b2079":"code","856d0354":"code","30a1f51b":"code","535fa746":"code","509743c6":"code","b35aa5bd":"code","f5b93792":"code","89102607":"code","a49a1547":"code","f6ede497":"code","f3f5a987":"code","046a1872":"code","482c69bb":"code","320848be":"code","de1b2ed5":"code","025611b1":"code","a793d405":"code","40628023":"code","338d5d13":"code","5fbb4333":"code","8bca3019":"code","95022840":"markdown","1adf2f94":"markdown","cdb45e67":"markdown","43457ad7":"markdown","08b14fa8":"markdown","8e1e6649":"markdown","05647409":"markdown","4e72bbd5":"markdown","eab087be":"markdown","db3e4a10":"markdown","332a7b3f":"markdown","2875ccb0":"markdown","b9cfc574":"markdown","660ee047":"markdown","971a4244":"markdown","73f157cd":"markdown","a0f187dc":"markdown","c9984a46":"markdown","a5511bce":"markdown","f2076d5a":"markdown","5253b95a":"markdown","7fc2a18b":"markdown","753454ba":"markdown","161f2028":"markdown","820ca2af":"markdown","f51e070a":"markdown","1a3ec73b":"markdown","9dcfc710":"markdown","1a56a7d2":"markdown","16e3c4fc":"markdown","652e8ec6":"markdown"},"source":{"54b36a85":"from IPython.display import Image\nfrom IPython.core.display import HTML \nurl = 'https:\/\/5vtj648dfk323byvjb7k1e9w-wpengine.netdna-ssl.com\/wp-content\/uploads\/2018\/05\/shutterstock_170867918-e1525266245642.jpg'\nImage(url= url, width=600, height=600, unconfined=True)","8fb17468":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","570ac24f":"!pip install pmdarima ","e0947ff1":"# Import files\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport datetime as dt\nimport matplotlib.pyplot as plt\n\n\n# Load specific forecasting tools\nfrom statsmodels.tsa.arima_model import ARMA,ARMAResults,ARIMA,ARIMAResults\nfrom statsmodels.graphics.tsaplots import plot_acf,plot_pacf # for determining (p,q) orders\nfrom statsmodels.graphics.tsaplots import month_plot, quarter_plot\nfrom pmdarima import auto_arima # for determining ARIMA orders\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.filters.hp_filter import hpfilter\nfrom statsmodels.tsa.stattools import adfuller,kpss,coint,bds,q_stat,grangercausalitytests,levinson_durbin\n\nimport sys\n\n# Ignore harmless warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nif not sys.warnoptions:\n    import warnings\n    warnings.simplefilter(\"ignore\")\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score, max_error,median_absolute_error, mean_squared_log_error","5dbec04f":"df_usage = pd.read_csv('..\/input\/residential-power-usage-3years-data-timeseries\/power_usage_2016_to_2020.csv')\ndf_weather = pd.read_csv('..\/input\/residential-power-usage-3years-data-timeseries\/weather_2016_2020_daily.csv')","cbf030f3":"df_usage.head()","ee25ceba":"df_weather.head()","9bc2394f":"# Date column update for 'df_usage'\n\nn = df_usage.shape[0]\np1 = pd.Series(range(n), pd.period_range('2016-06-01 00:00:00', freq = '1H', periods = n))\ndf_usage['StartDate'] = p1.to_frame().index\n\n# Date column update for 'df_weather'\nm = df_weather.shape[0]\np2 = pd.Series(range(m), pd.period_range('2016-06-01', freq = '1D', periods = m))\ndf_weather['Date'] = p2.to_frame().index\n\n# convert the period date into timestamp\ndf_usage['StartDate'] = df_usage['StartDate'].apply (lambda x: x.to_timestamp())\ndf_usage['Date'] = pd.DatetimeIndex(df_usage['StartDate']).date\n\n# convert the period date into timestamp\ndf_weather['Date'] = df_weather['Date'].apply (lambda x: x.to_timestamp())","01997474":"df_usage_daily = df_usage.groupby('Date').sum()\n\ndf_usage_daily['day_of_week'] = df_usage_daily['day_of_week'].apply(lambda x: x\/24)\n\nnotes_col = df_usage.groupby('Date').first()['notes'].values\ndf_usage_daily['notes'] = notes_col\ndf_usage_daily.head()","dd0075bb":"#filter the weather data to match with power usage dataframe. \n\nk = df_usage_daily.shape[0]\ndf_weather = df_weather[0:k]\ndf_weather.set_index('Date', inplace=True)\ndf_weather.head()","3233242c":"df_weather.shape","aa3408cc":"comb_df = pd.merge(df_weather,df_usage_daily,left_index=True, right_index=True)","21c82394":"comb_df.columns","f00a1a76":"comb_df.drop(columns= ['Temp_avg', 'Temp_min','Dew_avg',\n       'Dew_min', 'Hum_avg', 'Hum_min', 'Wind_avg',\n       'Wind_min','Press_avg', 'Press_min', 'Precipit','day_of_week_x', 'day_of_week_y'], inplace=True)\ncomb_df.index.freq= 'D'","a9ac2ffa":"comb_df.head()","35b7d009":"comb_df['Value (kWh)'].loc['2017-01-01':'2019-12-31'].plot(figsize= (16,9), legend= True, ylabel='Power in kWh')","607496cd":"comb_df[['Temp_max','Value (kWh)', 'Dew_max' ]].loc['2017-01-01':'2019-12-31'].plot(figsize= (16,9))","d9bb3508":"comb_df.head()","0cb39720":"df_short = comb_df.loc['2017-01-01':'2019-12-31']","09c185e0":"df_short.resample(rule= 'M').mean().plot(figsize= (16,9))","625073b4":"df_short = df_short[['Temp_max', 'Dew_max', 'Value (kWh)','notes']]\n\ndf_short.resample(rule= 'W').mean().plot(figsize= (16,9))","8bde7814":"df_short['Value (kWh)'].loc['2017-01-01': '2018-01-01'].resample(rule= 'W').mean().plot(figsize= (16,9), legend=True)","c94f203d":"df_short['EWMA12'] = df_short['Value (kWh)'].ewm(span=30,adjust=True).mean()\ndf_short['EWMA12_Temp'] = df_short['Temp_max'].ewm(span=30,adjust=True).mean()\ndf_short['EWMA12_Dew'] = df_short['Dew_max'].ewm(span=30,adjust=True).mean()","934f8539":"df_short[['Value (kWh)','EWMA12', 'EWMA12_Temp', 'EWMA12_Dew']].plot(figsize= (16,9))","a8f3f040":"## Lets see how the data compares against the monthly and quarterly \n# plot all four graphs in one go to show the performance of temp vr \n\n\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize= (16,9),  squeeze=False)\n#fig = plt.figure(8,5)\n\n\ndfm = df_short['Value (kWh)'].resample(rule='M').mean()\nmonth_plot(dfm, ylabel= 'Power in kWh', ax =ax1);\ndfq = df_short['Value (kWh)'].resample(rule='Q').mean()\nquarter_plot(dfq, ylabel = 'Power kWh', ax=ax2);\n\ndftm = df_short['Temp_max'].resample(rule='M').mean()\nmonth_plot(dftm, ylabel= 'Temp in Fdeg', ax=ax3);\ndftq = df_short['Temp_max'].resample(rule='Q').mean()\nquarter_plot(dftq, ylabel = 'Temp in Fdeg', ax=ax4);\n\nfig.tight_layout(pad=1.2)\n\n# for ax in fig.get_axes():\n#     ax.label_outer()\n","7d13b01a":"# It is always two way comparision. If p <0.05 the relationship exisits\n# Add a semicolon at the end to avoid duplicate output\ngrangercausalitytests(df_short[['Temp_max','Dew_max']],maxlag=3);","c12dde59":"# It is always two way comparision. If p <0.05 the relationship exisits\n# Add a semicolon at the end to avoid duplicate output\ngrangercausalitytests(df_short[['Temp_max','Value (kWh)']],maxlag=3);","6406eed9":"from statsmodels.tsa.seasonal import seasonal_decompose\nresult_pwr= seasonal_decompose(df_short['EWMA12'], model='additive')\nresult_pwr.plot();","8f3b2079":"result_pwr.trend.plot(figsize=(16,9), legend= True, ylabel= 'Power in kWh trend')","856d0354":"## HP Filter\n# Filtering the seasonality out of the data and converting this into only trend lines.\npwr_cycle, pwr_trend = hpfilter(df_short['EWMA12'],lamb=129600)\ndf_short['hpfilt_trend'] = pwr_trend.values\n\n# Filtering the seasonality out of the data and converting this into only trend lines.\ntemp_cycle, temp_trend = hpfilter(df_short['EWMA12_Temp'],lamb=129600)\ndf_short['hpfilt_temp']= temp_trend.values\n\n# Filtering the seasonality out of the data and converting this into only trend lines.\ndew_cycle, dew_trend = hpfilter(df_short['EWMA12_Dew'],lamb=129600)\ndf_short['hpfilt_dew']= dew_trend.values","30a1f51b":"df_short.head()","535fa746":"\nax = df_short['EWMA12'].plot(figsize=(16,9), legend=True)\n\n\ndf_short['hpfilt_trend'].plot(figsize=(16,9), legend=True)\npwr_cycle.plot(legend=True)\n\n\nfor day in df_short[df_short['notes'] =='vacation'].index:\n    ax.axvline(x=day, color= 'red', alpha= .25);\n\n    \nax.axhline(y=(pwr_cycle.values.min())*.6, xmin=0, xmax=1, color= 'black', alpha= .25, ls= '--' )  \nax.axhline(y=(pwr_cycle.values.max())*.6, xmin=0, xmax=1, color= 'black', alpha= .25, ls= '--' )  \n#ax.axhline(y=gdp_cycle.values )\n# for day in df[(df['weekday']=='Friday') | (df['weekday']=='Saturday') | (df['weekday']=='Sunday')].index:\n#     ax.axvline(x=day, color= 'black')\n\n\n# Mark vacation days. ","509743c6":"title = 'Autocorrelation: Power usage'\nlags = 10\nplot_acf(df_short['EWMA12'],title=title,lags=lags);\n#plot_pacf(df_short['EWMA12'],title=title,lags=lags);","b35aa5bd":"from statsmodels.tsa.stattools import adfuller\n\ndef adf_test(series,title=''):\n    \"\"\"\n    Pass in a time series and an optional title, returns an ADF report\n    \"\"\"\n    print(f'Augmented Dickey-Fuller Test: {title}')\n    result = adfuller(series.dropna(),autolag='AIC') # .dropna() handles differenced data\n    \n    labels = ['ADF test statistic','p-value','# lags used','# observations']\n    out = pd.Series(result[0:4],index=labels)\n\n    for key,val in result[4].items():\n        out[f'critical value ({key})']=val\n        \n    print(out.to_string())          # .to_string() removes the line \"dtype: float64\"\n    \n    if result[1] <= 0.05:\n        print(\"Strong evidence against the null hypothesis\")\n        print(\"Reject the null hypothesis\")\n        print(\"Data has no unit root and is stationary\")\n    else:\n        print(\"Weak evidence against the null hypothesis\")\n        print(\"Fail to reject the null hypothesis\")\n        print(\"Data has a unit root and is non-stationary\")\n\n#Code from Jose Portilla 'Python for Time Series Data Analysis'","f5b93792":"# define function to evulate the performance each timeseries models. \n\nfrom sklearn.metrics import explained_variance_score,mean_squared_error, r2_score,max_error, mean_absolute_error\n\ndef model_evaluate(model, y_test, y_pred):\n    exp_var_score = explained_variance_score(y_test, y_pred)\n    max_err= max_error(y_test, y_pred)\n    r2= r2_score(y_test, y_pred)\n    mae= mean_absolute_error(y_test, y_pred)\n    mse= mean_squared_error(y_test, y_pred)\n    rmse= np.sqrt(mse)\n    \n    row_label = [model]\n    \n    data_score = { 'exp_varne': exp_var_score, 'max_error':max_err, \n                 'r2': r2, 'mae':mae, 'mse':mse, 'rmse':rmse,}\n    \n    df_data = pd.DataFrame(data= data_score, index= row_label)\n    \n    return df_data","89102607":"adf_test(df_short['Temp_max'])","a49a1547":"adf_test(df_short['hpfilt_trend'])","f6ede497":"adf_test(df_short['hpfilt_temp'])","f3f5a987":"adf_test(df_short['hpfilt_dew'])","046a1872":"stepwise_fit= auto_arima(df_short['hpfilt_trend'],max_order= 20,n_jobs=-1, stepwise=True)\nstepwise_fit.summary()","482c69bb":"size = int(len(df_short)*(-.1))\ntrain, test = df_short[:size],df_short[size:]","320848be":"model = SARIMAX(train['hpfilt_trend'],exog= train[['hpfilt_temp', 'hpfilt_dew']], order=(2,2,1),seasonal_order=(0,0,0,0),enforce_invertibility=False)\nresults = model.fit()\nresults.summary()","de1b2ed5":"# Obtain predicted values\nstart=len(train)\nend=len(train)+len(test)-1\npredictions = results.predict(start=start, end=end, exog= test[['hpfilt_temp', 'hpfilt_dew']], dynamic=False).rename('SARIMA(2,2,1) Predictions')","025611b1":"ax = train['hpfilt_trend'].plot(legend=True,figsize=(12,6),title=title)\ntest['hpfilt_trend'].plot(legend=True)\npredictions.plot(legend=True)","a793d405":"model_evaluate('SARIMA(2,2,1)',test['hpfilt_trend'], predictions)","40628023":"model_nodew = SARIMAX(train['hpfilt_trend'],exog= train[['hpfilt_temp']], order=(2,2,1),seasonal_order=(0,0,0,0),enforce_invertibility=False)\nresults_nodew = model_nodew.fit()\nresults_nodew.summary()","338d5d13":"predictions_nodew = results_nodew.predict(start=start, end=end, exog= test[['hpfilt_temp']], dynamic=False).rename('SARIMA(2,2,1)nodew')","5fbb4333":"ax = train['hpfilt_trend'].plot(legend=True,figsize=(12,6),title=title)\ntest['hpfilt_trend'].plot(legend=True)\npredictions_nodew.plot(legend=True,ls = '--', color= 'black')","8bca3019":"model_evaluate('SARIMA(2,2,1)_nodew', test['hpfilt_trend'], predictions_nodew)","95022840":"If you closely observe the power data, and exponential smoothing, there is still fluctions, the trend line is not smooth. ","1adf2f94":"From the above graph it is clear that only three features participate in predictions of power, namely Temp & Dew. ","cdb45e67":"[<a href='#Index'>Back to top<\/a>]\n\n# Conclusions","43457ad7":"Temperature and power are strongly corelated to each other. ","08b14fa8":"[<a href='#Index'>Back to top<\/a>]\n\n## Heading","8e1e6649":"[<a href='#Index'>Back to top<\/a>]\n\n## Model with Temp & Dew","05647409":"[<a href='#Index'>Back to top<\/a>]\n\n## Functions","4e72bbd5":"[<a href='#Index'>Back to top<\/a>]\n\n# References","eab087be":"The difference between day 1 and day 2 is gradually decreasing over period of time, within 10lags. ","db3e4a10":"The monthly data for 3 years show minimal fluctations. Again only two curves (Temp and Dew) show co relation to power, hence rest of the data columns are removed from the analysis. \n\n","332a7b3f":"From the above graph, power usage has direct relation to Temperature & Dew. The data has fluctations hence needs smoothing and filters. ","2875ccb0":"Image source from:- www.fleetcarma.com\n\nObjective of this Notebook is to explore features that are critical for forcasting the power usage for a given period. In the process of exploration, we will uncover best possible ways to get to the answer. \n\nDetails of Data: https:\/\/www.kaggle.com\/srinuti\/residential-power-usage-3years-data-timeseries","b9cfc574":"Three year power usage vs time. Peak value of power usage in 2017 year is around 50kWh, and during 2018 was about 68kWh, followed by 2019 was 55kWh. ","660ee047":"[<a href='#Index'>Back to top<\/a>]\n\n## Train\/ Test split","971a4244":"# Index\n\n<a href= \"#Heading\">Heading<\/a>\n\n<a href= \"#Data-Import\">Data Import<\/a>\n\n<a href= \"#Date-Format-Update\">Date Format Update<\/a>\n\n<a href= \"#Data-Visuals\">Data Visuals<\/a>\n\n<a href= \"#Exponential-Smoothing\">Exponential Smoothing<\/a>\n\n<a href= \"#Relationship-tests\">Relationship tests<\/a>\n\n<a href= \"#Seasonal-Decomposition\">Seasonal Decomposition<\/a>\n\n<a href= \"#Functions\">Functions<\/a>\n\n<a href= \"#Stationarity-check\">Stationarity check<\/a>\n\n<a href= \"#Model-Selection\">Model Selection<\/a>\n\n<a href= \"#Train\/-Test-split\">Train\/ Test split<\/a>\n\n<a href= \"#Model-with-Temp-&-Dew\">Model with Temp & Dew<\/a>\n\n<a href= \"#Model-with-only-Temp\">Model with only Temp<\/a>\n\n<a href= \"#Conclusions\">Conclusions<\/a>\n\n<a href= \"#References\">References<\/a>\n    ","73f157cd":"[<a href='#Index'>Back to top<\/a>]\n\n## Date Format Update","a0f187dc":"[<a href='#Index'>Back to top<\/a>]\n\n## Model with only Temp","c9984a46":"[<a href='#Index'>Back to top<\/a>]\n\n## Seasonal Decomposition","a5511bce":"[<a href='#Index'>Back to top<\/a>]\n\n## Data Import","f2076d5a":"1. Jose Portilla udemy class on 'Python for Time Series Data Analysis'\n2. BV Vishwas & Ashish Patel book on 'Hands on Timeseries analysis with Python'\n3. Jonathan D Cryer, Kung-Sik Chan book on 'Time Series Analysis with applications in R'","5253b95a":"The red lines indicate vaccation period during the year. In this period, the AC or heater is turned off and hence you generally see dip in power consumption in comparision to regular days. \nThe green line represents the sesonal cycle of the power consumption during 3 years. \n","7fc2a18b":"[<a href='#Index'>Back to top<\/a>]\n\n## Data Visuals","753454ba":"The graph shows significant fluctations. Hence filters to be applied. ","161f2028":"The data seems still fluctuations, further smoothing is needed for the trend curves. ","820ca2af":"[<a href='#Index'>Back to top<\/a>]\n\n## Stationarity check","f51e070a":"[<a href='#Index'>Back to top<\/a>]\n\n## Model Selection","1a3ec73b":"[<a href='#Index'>Back to top<\/a>]\n\n## Exponential Smoothing","9dcfc710":"[<a href='#Index'>Back to top<\/a>]\n\n## Relationship tests","1a56a7d2":"Clearly the data shows seasonality, during summar month between may to oct the power bill is higher. The Theromstat settings is at 66F for heating and 70F for cooling. \n1. During months of Jan, Feb, march, April, Nov and Dec the AC is not running for most of the time, occationally Heater is on. Hence you see lower power bill during these months. \n2. Q2 and Q3 each year the power bill is higher due to summer. ","16e3c4fc":"The interaction between temperature and Dew seems minimal at lag1 & lag2. ","652e8ec6":"1. The ARIMA models were able to predict a known path to certain extent (R2 value= .94), when train and test sizes are changed to 80\/20 the algorithm struggles to predict the sudden changes in path. Model with temperature has exogenous feature has better r2, mae, mse values in comparision with model with two exogenous features. \n2. Another important point is the trend lines to be smoothened and filters to applied inorder to get the stationarity and as well to increase better predicatability. \n3. Only two full year cycle is not sufficient for the better forecast analysis, hence more data is needed. "}}