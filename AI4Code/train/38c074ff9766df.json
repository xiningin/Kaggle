{"cell_type":{"83eef9a1":"code","efb91578":"code","61aa2211":"code","237a82d8":"code","baf0d447":"code","99853315":"code","999aa9d0":"code","320857c7":"code","8e00a03f":"code","4fdeb1e1":"code","cecd9699":"code","f731ee0f":"code","b007d504":"code","c42d79e2":"code","714275b3":"code","7591bee5":"code","1429ab5d":"code","9956e2d6":"code","1b96f294":"markdown","c9a3d664":"markdown","e18c6ba7":"markdown","5c1dc704":"markdown","247bc671":"markdown","f9820ec5":"markdown","0a6181cd":"markdown","3ec6c0dc":"markdown"},"source":{"83eef9a1":"# importing necessary libraries\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom math import sqrt","efb91578":"# atributing dataset to a dataframe df\ndf= pd.read_csv('\/kaggle\/input\/oc2emission\/FuelConsumptionCo2.csv')\ndf.head(10)","61aa2211":"# describing statiscal measures\ndf.describe()","237a82d8":"df.shape","baf0d447":"# plotting correlation matrix\nplt.figure(figsize=(20,8))\nsns.heatmap(data=df.corr(),annot=True,linewidths=0.2,cmap='coolwarm', square=True)","99853315":"# ploting graph engine size x CO2 emissions\nplt.figure(figsize=(13,5))\nsns.lineplot(x=df['ENGINESIZE'], y=df['CO2EMISSIONS'])\nplt.xlabel('Motor engine')\nplt.ylabel('CO2 emissions')\nplt.show()","999aa9d0":"# importing necessary libraries\nfrom sklearn import linear_model\nfrom sklearn.metrics import r2_score, mean_squared_error,mean_absolute_error\nfrom sklearn.model_selection import train_test_split","320857c7":"# features into variables\nengine= df[['ENGINESIZE']]\nco2 = df[['CO2EMISSIONS']]","8e00a03f":"# spliting data in train and test with train_test_split\nengine_treino, engine_test, co2_treino, co2_test = train_test_split(engine, co2, test_size=0.2, random_state=42)","4fdeb1e1":"print(type(engine_treino))","cecd9699":"# ploting the correlation between features\nplt.scatter(engine_treino, co2_treino, color='blue')\nplt.xlabel('engine')\nplt.ylabel('co2 emission')\nplt.show()","f731ee0f":"# creating a linear regression model\n# LinearRegression is a method of sklearn\nmodelo = linear_model.LinearRegression()","b007d504":"# linear regression formula: (Y = A + B.X)\n# training the model to obtain the values of A and B (always do it in the train dataset)\nmodelo.fit(engine_treino, co2_treino)","c42d79e2":"# exibiting the coeficients A and B that the model generated\nprint(f'(A) intercept: {modelo.intercept_} | (B) inclination: {modelo.coef_}')","714275b3":"# print linear regression line on our TRAIN dataset\nplt.scatter(engine_treino, co2_treino, color='blue')\nplt.plot(engine_treino, modelo.coef_[0][0]*engine_treino + modelo.intercept_[0], '-r') \n# LR formula: inclination(B) * engine_treino(X) + intercept(A)\nplt.ylabel('CO2 emissions')\nplt.xlabel('Engine')\nplt.show()","7591bee5":"predictCO2 = modelo.predict(engine_test)","1429ab5d":"# print linear regression line on our TEST dataset\nplt.scatter(engine_test, co2_test, color='green')\nplt.plot(engine_test, modelo.coef_[0][0]*engine_test + modelo.intercept_[0], '-r')\nplt.ylabel('CO2 emissions')\nplt.xlabel('Engine')\nplt.show()","9956e2d6":"# Showing metrics to check the acuracy of our model\nprint(f'Sum of squared error (SSE): {np.sum((predictCO2 - co2_test)**2)}') # SSE: sum all of the  residuals and square them. \nprint(f'Mean squared error (MSE): {mean_squared_error(co2_test, predictCO2)}') # MSE: avg of SSE\nprint(f'Mean absolute error (MAE): {mean_absolute_error(co2_test, predictCO2)}')\nprint (f'Sqrt of mean squared error (RMSE):  {sqrt(mean_squared_error(co2_test, predictCO2))}') # RMSE: sqrt of the MSE\nprint(f'R2-score: {r2_score(predictCO2, co2_test)}') # r2-score: explains the variance of the variable Y when it comes to X","1b96f294":"### Creating the model with the train dataset","c9a3d664":"The lineplot shows a positive correlation between the size\/power of the engine motor and the carbon emission. With some variation, we can say that the bigger the engine the greater the levels of CO2 emited.","e18c6ba7":"### Spliting data to train the model","5c1dc704":"### Exploratory analysis","247bc671":"### Executing the model on the test dataset\nFirst: predictions on the 'test' dataset","f9820ec5":"The datapoints on the scatterplot indicates that is possible to do a linear regression with this dataset, although the amount of residual.","0a6181cd":"### Evaluating the model","3ec6c0dc":"All of the metrics above help evaluate the acuracy of the model. MAE and RMSE are below 4, which means the distance between the real value and the predicted value is below 4 - a satisfatory result.\n\nr2, for instance, is 0.60: this means that our linear regression model (values A and B given) is able to explain 67% of the variance between the MEDV value and the number of rooms in houses located in Boston. \n\nThe usual benchmark for this metric is 0.70."}}