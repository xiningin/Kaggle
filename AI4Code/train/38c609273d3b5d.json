{"cell_type":{"89968fe5":"code","bbee3fe1":"code","8b10e232":"code","20ef3a6f":"code","14456327":"code","4db3c65c":"code","ecce01a4":"code","d1fea642":"code","73c8fc8a":"code","ac7b73ca":"code","21e9cc7f":"code","0d2061ee":"code","92105612":"code","e372ffd3":"code","81e698a1":"code","b5386a38":"code","fd71ef0a":"code","0a661d53":"code","68a319e5":"code","5bc03ca6":"code","5bf48c7a":"code","058cf2bf":"code","23b506fb":"code","ad75b4fd":"code","e64ac1de":"code","8de9764c":"code","3e824921":"code","9a585679":"code","42a68ad3":"code","cd3a24fd":"code","76104170":"code","92c157cc":"code","ae78ab05":"code","61cc31bb":"code","f78548a0":"code","207f5fe7":"code","3d1d4bc8":"code","157ae328":"code","c636443f":"code","05a05730":"code","2df232c1":"code","2382a385":"code","7939a27e":"code","268a0ea9":"code","9155ada3":"code","2fde165a":"code","5865cbda":"markdown","12116631":"markdown","eb83016d":"markdown","05126ce9":"markdown","924c9da6":"markdown","9bdfdf64":"markdown","32a46c1d":"markdown","e8ad3f84":"markdown","95ee1da1":"markdown","5ddea6ff":"markdown","349e51c5":"markdown","fe67d6c0":"markdown","68c41d01":"markdown","a33cc73e":"markdown","9bc8b8c3":"markdown","def08d76":"markdown","63be67f9":"markdown","b4daa7ee":"markdown","441f6778":"markdown","214ccebe":"markdown","e90b9365":"markdown","0f52dd5f":"markdown","12be439e":"markdown","bcd3708c":"markdown","f637f938":"markdown"},"source":{"89968fe5":"\n# for data visualization\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n# modeling \nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.naive_bayes import GaussianNB\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\n\n\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score,f1_score\n","bbee3fe1":"df = pd.read_csv(\"..\/input\/bank-loan2\/madfhantr.csv\")\ndf.head()","8b10e232":"df.info()","20ef3a6f":"df.isnull().sum()","14456327":"# To increase the number of \"Female\" in the data\ndf['Gender'].fillna(\"Female\",inplace = True)\n# To increase the number of \"No Married \" in the data\ndf['Married'].fillna(\"No\",inplace = True)\ndf['Dependents'].fillna(\"3+\",inplace = True)\ndf['Self_Employed'].fillna(\"Yes\",inplace = True)\ndf['Credit_History'].fillna(0,inplace = True)\n# fill using \"mean\" to have not any issues\ndf['LoanAmount'].fillna(round(df['LoanAmount'].mean(),0),inplace = True)\ndf['Loan_Amount_Term'].fillna(round(df['Loan_Amount_Term'].mean(),0),inplace = True)\n","4db3c65c":"df.isnull().sum()","ecce01a4":"df.describe()","d1fea642":"sns.boxplot(df['ApplicantIncome'])","73c8fc8a":"Q1 = df.ApplicantIncome.quantile(0.25)\nQ3 = df.ApplicantIncome.quantile(0.75)\nIQR = Q3 - Q1\nlower_limit = Q1 - 1.5*IQR\nupper_limit = Q3 + 1.5*IQR\nlower_limit, upper_limit","ac7b73ca":"upperdf = df[df['ApplicantIncome'] > upper_limit]\nupperdf.shape","21e9cc7f":"upperdf.index","0d2061ee":"df = df.drop(df.index[upperdf.index])\n","92105612":"sns.boxplot(df['ApplicantIncome'])\n","e372ffd3":"fig, ax = plt.subplots(figsize=(8,6))\nsns.heatmap(df.corr(), annot=True, fmt='.1g', cmap=\"viridis\", cbar=True);","81e698a1":"fig, ax = plt.subplots(figsize=(5,5))\nplt.pie(x=df[\"Gender\"].value_counts(), \n        colors=['tab:blue', 'pink'], \n        labels=[\"Male\",\"Female\"], \n        shadow = True, \n        autopct=\"%1.2f%%\", \n        explode = (0, 0.1)\n        )\nplt.show()","b5386a38":"x=pd.crosstab(df['Gender'],df['Loan_Status']) \nx.div(x.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))","fd71ef0a":"fig, ax = plt.subplots(figsize=(5,5))\nplt.pie(x=df[\"Married\"].value_counts(), \n        labels=[\"Yes\",\"No\"], \n        shadow = True, \n        autopct=\"%1.2f%%\", \n        explode = (0, 0.1)\n        )\nplt.show()","0a661d53":"x=pd.crosstab(df['Married'],df['Loan_Status']) \nx.div(x.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))","68a319e5":"plt.figure(figsize=(10,5))\nsns.countplot(x='Gender', data=df, hue='Married') \nplt.title('Sex and Social status', size='23')\nplt.show()","5bc03ca6":"fig, ax = plt.subplots(figsize=(5,5))\nplt.pie(x=df[\"Dependents\"].value_counts(), \n        labels=[\"zero\",\"one\",'tow','three or more'], \n        shadow = True, \n        autopct=\"%1.2f%%\", \n        explode = (0.1,0.1,0.1, 0.1)\n        )\nplt.figure(figsize=(10,5))\nsns.countplot(x='Dependents', data=df, hue='Married') \nplt.show()","5bf48c7a":"x=pd.crosstab(df['Dependents'],df['Loan_Status']) \nx.div(x.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))","058cf2bf":"fig, ax = plt.subplots(figsize=(5,5))\nplt.pie(x=df[\"Education\"].value_counts(), \n        labels=[\"Graduate\",\"Not Graduate\"], \n        shadow = True, \n        autopct=\"%1.2f%%\", \n        explode = (0, 0.1)\n        )\n\nplt.figure(figsize=(10,5))\nsns.countplot(x='Education', data=df, hue='Loan_Status') \nplt.show()\nplt.show()","23b506fb":"x=pd.crosstab(df['Education'],df['Loan_Status']) \nx.div(x.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))","ad75b4fd":"var = sns.kdeplot(df.ApplicantIncome[df['Loan_Status']=='Y'],color='Blue',shade = True)\nvar = sns.kdeplot(df.ApplicantIncome[df['Loan_Status']=='N'],color='Red',shade = True)\nvar.legend(['yes','no'],loc='upper right')","e64ac1de":"var = sns.kdeplot(df.LoanAmount[df['Loan_Status']=='Y'],color='Blue',shade = True)\nvar = sns.kdeplot(df.LoanAmount[df['Loan_Status']=='N'],color='Red',shade = True)\nvar.legend(['yes','no'],loc='upper right')","8de9764c":"var = sns.kdeplot(df.Loan_Amount_Term[df['Loan_Status']=='Y'],color='Blue',shade = True)\nvar = sns.kdeplot(df.Loan_Amount_Term[df['Loan_Status']=='N'],color='Red',shade = True)\nvar.legend(['yes','no'],loc='upper right')","3e824921":"x=pd.crosstab(df['Credit_History'],df['Loan_Status']) \nx.div(x.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))","9a585679":"x=pd.crosstab(df['Property_Area'],df['Loan_Status']) \nx.div(x.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))","42a68ad3":"le = LabelEncoder()\nles = {}\nfor col in ['Gender','Married','Married', 'Education', 'Self_Employed','Property_Area','Loan_Status','Dependents']:\n    les[col] = LabelEncoder()\n    df[col]  = les[col].fit_transform(df[col])","cd3a24fd":"df.head()","76104170":"df.drop(columns=\"Loan_ID\",inplace=True)\ndf.head()","92c157cc":"def rescale(data,lista):\n  for i in lista:\n    data[i] = ((data[i]-data[i].min())\/(data[i].max()-data[i].min()))\n\nlst =[\"ApplicantIncome\",\"CoapplicantIncome\",\"LoanAmount\",\"Loan_Amount_Term\"]\nrescale(df,lst)\ndf.head()","ae78ab05":"X = df.drop(columns='Loan_Status')\ny = df['Loan_Status']\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,stratify =y,random_state =42)","61cc31bb":"tree_clf = DecisionTreeClassifier()\ntree_clf.fit(X_train,y_train)\ny_pred = tree_clf.predict(X_train)\nprint(\"Training Data Set Accuracy: \", accuracy_score(y_train,y_pred))\nprint(\"Training Data F1 Score \", f1_score(y_train,y_pred))\n\nprint(\"Validation Mean F1 Score: \",cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='f1_macro').mean())\nprint(\"Validation Mean Accuracy: \",cross_val_score(tree_clf,X_train,y_train,cv=5,scoring='accuracy').mean())","f78548a0":"train_accuracies = []\ntrain_f1_scores = []\ntest_accuracies = []\ntest_f1_scores = []\nthresholds = []\n\n#for thresh in np.linspace(0.1,0.9,8): ## Sweeping from threshold of 0.1 to 0.9\nfor thresh in np.arange(0.1,0.9,0.1): ## Sweeping from threshold of 0.1 to 0.9\n    logreg_clf = LogisticRegression(solver='liblinear')\n    logreg_clf.fit(X_train,y_train)\n    \n    y_pred_train_thresh = logreg_clf.predict_proba(X_train)[:,1]\n    y_pred_train = (y_pred_train_thresh > thresh).astype(int)\n\n    train_acc = accuracy_score(y_train,y_pred_train)\n    train_f1 = f1_score(y_train,y_pred_train)\n    y_pred_test_thresh = logreg_clf.predict_proba(X_test)[:,1]\n    y_pred_test = (y_pred_test_thresh > thresh).astype(int) \n    \n    test_acc = accuracy_score(y_test,y_pred_test)\n    test_f1 = f1_score(y_test,y_pred_test)\n    \n    train_accuracies.append(train_acc)\n    train_f1_scores.append(train_f1)\n    test_accuracies.append(test_acc)\n    test_f1_scores.append(test_f1)\n    thresholds.append(thresh)\n    \n    \nThreshold_logreg = {\"Training Accuracy\": train_accuracies, \"Test Accuracy\": test_accuracies, \"Training F1\": train_f1_scores, \"Test F1\":test_f1_scores, \"Decision Threshold\": thresholds }\nThreshold_logreg_df = pd.DataFrame.from_dict(Threshold_logreg)   \nplot_df = Threshold_logreg_df.melt('Decision Threshold',var_name='Metrics',value_name=\"Values\")\nfig,ax = plt.subplots(figsize=(15,5))\nsns.pointplot(x=\"Decision Threshold\", y=\"Values\",hue=\"Metrics\", data=plot_df,ax=ax)","207f5fe7":"thresh = 0.4\ny_pred_test_thresh = logreg_clf.predict_proba(X_test)[:,1]\ny_pred = (y_pred_test_thresh > thresh).astype(int) \nprint(\"Test Accuracy: \",accuracy_score(y_test,y_pred))\nprint(\"Test F1 Score: \",f1_score(y_test,y_pred))\nprint(\"Confusion Matrix on Test Data\")\npd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)","3d1d4bc8":"pred = pd.read_csv(\"..\/input\/bank-loan2\/madhante.csv\")\npred.dropna(inplace=True)","157ae328":"pred.info()","c636443f":"for col in ['Gender','Married','Married', 'Education', 'Self_Employed','Property_Area','Dependents']:\n    les[col] = LabelEncoder()\n    pred[col]  = les[col].fit_transform(pred[col])","05a05730":"new_pred = pred.drop(columns=\"Loan_ID\")\nrescale(new_pred,lst)","2df232c1":"results = logreg_clf.predict(new_pred)\nrep = []\nfor i in range(0,len(results)):\n  if results[i] == 1 :\n    rep.append(\"N\") \n  else :\n    rep.append(\"Y\")\n        ","2382a385":"len(rep),len(results)","7939a27e":"rep[103],results[103]","268a0ea9":"\nsubmission = pd.DataFrame()\nsubmission[\"Loan_ID\"] = pred['Loan_ID']\nsubmission['Loan_Status'] = rep\nsubmission.info()","9155ada3":"submission.head()","2fde165a":"submission[\"Loan_Status\"].value_counts()","5865cbda":"Also, the social situation has a small impact as well","12116631":"We see that most of our clients are married men too","eb83016d":"We see from the correlation matrix that \"Loan Amount\" is highly dependable on \"Applicant Income\" and accordingly \"CoapplicantIncome\"\n","05126ce9":"Gender does not constitute a significant change in the loan state","924c9da6":" Not good.. we have a lot of missing data, we have to process it ..\n # Handling missing data","9bdfdf64":"# Modeling\n\n### Label Encoding","32a46c1d":"But unexpectedly, the Dependents is low, as more than half of the clients do not have dependents","e8ad3f84":"ApplicantIncome It might have some effect","95ee1da1":"Its overfitting","5ddea6ff":"so .. this is our data .. see that wth more details :","349e51c5":"### Rescaling","fe67d6c0":"# Get Libraries and Data\n","68c41d01":"### Spliting","a33cc73e":"We seem to have outliers\n# outliers","9bc8b8c3":"It seems that there is a noticeable effect on whether or not there are dependents","def08d76":"The more Loan_Amount_Term, the higher the acceptance rate","63be67f9":"The data analysis process ends here..let's move on to building our model","b4daa7ee":"Good, the data is perfect now, we are ready to analyze the data..","441f6778":"# Selection","214ccebe":"# EDA","e90b9365":"Here, too, it seems that it is better for you to be a graduate in order to enjoy the loan, because not graduating affects negatively","0f52dd5f":"The more LoanAmount, the higher the acceptance rate","12be439e":"#Prediction","bcd3708c":"You must live close to Semiurban the acceptance rate is higher .. but does not affect the opinion of another place much","f637f938":"You should have Credit_History to have a higher acceptance rate\n\n\n\n"}}