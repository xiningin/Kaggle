{"cell_type":{"5678bf27":"code","42a6e327":"code","9eb5b215":"code","3cd4a9b9":"code","12a9a743":"code","9b662422":"code","ec2cedb6":"code","9130b2a1":"code","bf44fffd":"code","eb0ee8e6":"code","fd5d70c8":"code","cdbde22c":"code","8bd9d6cf":"code","1294a2fc":"code","36c4e941":"code","cddd1f31":"markdown"},"source":{"5678bf27":"#importng libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns #data visualization\nfrom matplotlib import pyplot as plt #data visualization\n%matplotlib inline\nsns.set_style(\"darkgrid\")\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n#importing data and segregating columns using the 'names' parameter\nhouse = pd.read_csv(\"..\/input\/kc_house_data.csv\")\n\n#displaying the dataset\nhouse.tail(10)\nset(house['view'])","42a6e327":"#describing the dataset\nhouse.describe()","9eb5b215":"# Looking for nulls\nprint(house.isnull().any())\n# Inspecting type\nprint(house.dtypes)","3cd4a9b9":"# Dropping the id and date columns\nhouse = house.drop(['id', 'date'],axis=1)","12a9a743":"#creating a pairplot for data visualization of various features\nwith sns.plotting_context(\"notebook\",font_scale=2.5):\n    g = sns.pairplot(house[['sqft_lot','sqft_above','price','sqft_living','bedrooms']], \n                 hue='bedrooms', palette='tab20',size=5)\ng.set(xticklabels=[]);","9b662422":"#plotting a correlation matrix\nstr_list = [] # empty list to contain columns with strings (words)\nfor colname, colvalue in house.iteritems():\n    if type(colvalue[1]) == str:\n         str_list.append(colname)\n# Get to the numeric columns by inversion            \nnum_list = house.columns.difference(str_list) \n# Create Dataframe containing only numerical features\nhouse_num = house[num_list]\nf, ax = plt.subplots(figsize=(16, 12))\nplt.title('Pearson Correlation of features')\n# Draw the heatmap using seaborn\n#sns.heatmap(house_num.astype(float).corr(),linewidths=0.25,vmax=1.0, square=True, cmap=\"PuBuGn\", linecolor='k', annot=True)\nsns.heatmap(house_num.astype(float).corr(),linewidths=0.25,vmax=1.0, square=True, cmap=\"cubehelix\", linecolor='k', annot=True)","ec2cedb6":"#seperating features and target\nx=house.iloc[:,1:].values\ny=house['price']\n","9130b2a1":"#splitting the dataset into training and test set\nfrom sklearn.model_selection import train_test_split,cross_val_score\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20, random_state=0)","bf44fffd":"#feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc_x=StandardScaler()\nx_train=sc_x.fit_transform(x_train)\nx_test=sc_x.transform(x_test)","eb0ee8e6":"#using the LightGBM algorithm as the model\nimport lightgbm as lgb\nparams={'objective':'regression',\n        'metric':'mae'}\nreg_lgm = lgb.LGBMRegressor(learning_rate=0.05,**params, n_estimators=1000)\nreg_lgm.fit(x_train, y_train)","fd5d70c8":"#checking score of the model\nreg_lgm.score(x_test,y_test)","cdbde22c":"#viewing feature importances\nreg_lgm.feature_importances_","8bd9d6cf":"#predicting the test set result\ny_pred_lgm=reg_lgm.predict(x_test)","1294a2fc":"#checking the cross val score of the model\nresults = cross_val_score(reg_lgm, x_train, y_train, cv=5, n_jobs=-1)\nresults.mean()","36c4e941":"results.std()","cddd1f31":"**I am new at Machine Learning so please feel free to provide your inputs, remarks and suggestions about this kernel in the comment section and I will surely try to implements them and improve myself in the near future. Thank You.**"}}