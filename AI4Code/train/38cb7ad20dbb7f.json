{"cell_type":{"d0c604ae":"code","680c479f":"code","f8ac1b78":"code","2ee8058f":"code","a86538f2":"code","14b4ec6c":"code","ef61deb3":"code","5ee734f9":"markdown"},"source":{"d0c604ae":"import os\nimport numpy as np\nnp.random.seed(69)\nimport pandas as pd\nimport random\nimport pickle as pkl\nimport matplotlib.pyplot as plt\nimport matplotlib.image as img\nimport seaborn as sns\nimport tensorflow as tf\nfrom tqdm.notebook import tqdm\nfrom tensorflow.keras.utils import to_categorical, plot_model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AveragePooling2D, BatchNormalization, ZeroPadding2D, concatenate, LeakyReLU, PReLU, ReLU\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.models import load_model\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier","680c479f":"df = pd.read_csv(\"..\/input\/sdss-fits-images-v06\/FinalSDSSv0.6.csv\",index_col=0)","f8ac1b78":"X = np.load(\"..\/input\/sdss-fits-images-v06\/X_v0.6.npy\")\ny = np.load(\"..\/input\/sdss-fits-images-v06\/y_v0.6.npy\")\nobjlist = np.load(\"..\/input\/sdss-fits-images-v06\/objlist_v0.6.npy\")","2ee8058f":"y, label_strings = pd.factorize(y)\ny = to_categorical(y)","a86538f2":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=69)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.5,random_state=69)","14b4ec6c":"def get_metrics(y_pred, y_test, labels, to_print=True):\n    correct_labels = np.where(y_pred==y_test)[0]\n    accuracy = metrics.accuracy_score(y_test, y_pred)\n    precision = metrics.precision_score(y_test, y_pred,average='macro')\n    recall = metrics.recall_score(y_test, y_pred,average='macro')\n    f1score = metrics.f1_score(y_test, y_pred,average='macro')\n    # rocscore = metrics.roc_auc_score(y_test, y_pred,average='micro',multi_class=\"ovo\")\n    confusion_matrix = metrics.confusion_matrix(y_test, y_pred)  \n    classification_report = metrics.classification_report(y_test, y_pred)\n\n    if to_print:\n        print(\"Identified {} correct labels out of {} labels\".format(len(correct_labels), y_test.shape[0]))\n        print(\"Accuracy:\",accuracy)\n        print(\"Precision:\",precision)\n        print(\"Recall:\",recall)\n        print(\"F1 Score:\",f1score)\n        # print(\"ROC AUC Score:\",rocscore)\n        print(f\"Labels are: {labels}\")\n        print(\"Confusion Matrix:\\n\", confusion_matrix)\n        print(\"Classification_Report:\\n\", classification_report)\n\n    return (correct_labels, accuracy, precision, recall, confusion_matrix, classification_report)\n\ndef plot_model_change(history):\n    # summarize history for accuracy\n    plt.plot(history.history['accuracy'],label=\"Training Acc\")\n    plt.plot(history.history['val_accuracy'],label=\"Val Acc\")\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend()\n    plt.show()\n    # summarize history for loss\n    plt.plot(history.history['loss'],label=\"Training Loss\")\n    plt.plot(history.history['val_loss'],label=\"Val Loss\")\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend()\n    plt.show()","ef61deb3":"inp_layer = tf.keras.Input(shape=(32, 32, 5))\n\nmod = Conv2D(filters=64, kernel_size=(5,5), padding='same')(inp_layer)\nmod = ReLU()(mod)\n\n\n# mod = AveragePooling2D(pool_size=(2, 2), strides=2)(mod)\n\nc1 = Conv2D(filters=48, kernel_size=(1,1), padding='same')(mod)\nc1 = ReLU()(c1)\nc2 = Conv2D(filters=48, kernel_size=(1,1), padding='same')(mod)\nc2 = ReLU()(c2)\nc3 = Conv2D(filters=48, kernel_size=(1,1), padding='same')(mod)\nc3 = ReLU()(c3)\nc4 = Conv2D(filters=64, kernel_size=(1,1), padding='same')(c1)\nc4 = ReLU()(c4)\nc5 = Conv2D(filters=64, kernel_size=(3,3), padding='same')(c1)\nc5 = ReLU()(c5)\nc6 = Conv2D(filters=64, kernel_size=(5,5), padding='same')(c2)\nc6 = ReLU()(c6)\np1 = AveragePooling2D(pool_size=(1, 1))(c3)\nmod = concatenate([c4,c5,c6,p1])\n\nc7 = Conv2D(filters=64, kernel_size=(1,1), padding='same')(mod)\nc7 = ReLU()(c7)\nc8 = Conv2D(filters=64, kernel_size=(1,1), padding='same')(mod)\nc8 = ReLU()(c8)\nc9 = Conv2D(filters=64, kernel_size=(1,1), padding='same')(mod)\nc9 = ReLU()(c9)\nc10 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(c7)\nc10 = ReLU()(c10)\nc11 = Conv2D(filters=92, kernel_size=(3,3), padding='same')(c7)\nc11 = ReLU()(c11)\nc12 = Conv2D(filters=92, kernel_size=(5,5), padding='same')(c8)\nc12 = ReLU()(c12)\np2 = AveragePooling2D(pool_size=(1, 1))(c9)\nmod = concatenate([c10,c11,c12,p2])\nmod = AveragePooling2D(pool_size=(2, 2))(mod)\n\nc13 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc13 = ReLU()(c13)\nc14 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc14 = ReLU()(c14)\nc15 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc15 = ReLU()(c15)\nc16 = Conv2D(filters=128, kernel_size=(1,1), padding='same')(c13)\nc16 = ReLU()(c16)\nc17 = Conv2D(filters=128, kernel_size=(3,3), padding='same')(c13)\nc17 = ReLU()(c17)\nc18 = Conv2D(filters=128, kernel_size=(5,5), padding='same')(c14)\nc18 = ReLU()(c18)\np3 = AveragePooling2D(pool_size=(1, 1))(c15)\nmod = concatenate([c16,c17,c18,p3])\n\nc19 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc19 = ReLU()(c19)\nc20 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc20 = ReLU()(c20)\nc21 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc21 = ReLU()(c21)\nc22 = Conv2D(filters=128, kernel_size=(1,1), padding='same')(c19)\nc22 = ReLU()(c22)\nc23 = Conv2D(filters=128, kernel_size=(3,3), padding='same')(c19)\nc23 = ReLU()(c23)\nc24 = Conv2D(filters=128, kernel_size=(5,5), padding='same')(c20)\nc24 = ReLU()(c24)\np4 = AveragePooling2D(pool_size=(1, 1))(c21)\nmod = concatenate([c22,c23,c24,p4])\nmod = AveragePooling2D(pool_size=(2, 2))(mod)\n\nc25 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc25 = ReLU()(c25)\nc26 = Conv2D(filters=92, kernel_size=(1,1), padding='same')(mod)\nc26 = ReLU()(c26)\nc27 = Conv2D(filters=128, kernel_size=(1,1), padding='same')(mod)\nc27 = ReLU()(c27)\nc28 = Conv2D(filters=128, kernel_size=(3,3), padding='same')(c25)\nc28 = ReLU()(c28)\np5 = AveragePooling2D(pool_size=(1, 1))(c26)\nmod = concatenate([c27,c28,p5])\nmod = Flatten()(mod)    #Check\n\nmod = Dense(1024)(mod)\nmod = Dense(1024)(mod)\nout_layer = Dense(3, activation=\"softmax\") (mod)\nmodel = tf.keras.Model(inputs=inp_layer, outputs=out_layer)\n\nmodel.compile(optimizer = 'adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True)\ndatagen.fit(X_train)\n\n\nes = EarlyStopping(monitor='val_loss', verbose=1, patience=20, restore_best_weights=True)\n\ncb = [es]\n\nhistory = model.fit(datagen.flow(X_train,y_train, batch_size=512),\n                              epochs = 300, validation_data = (X_val,y_val),\n                              callbacks = cb,\n                              verbose = 1)\n\nplot_model_change(history)\n\npreds_test = model.predict(X_test,batch_size=2048, verbose = 0)\nprint(get_metrics(preds_test.argmax(axis=1), y_test.argmax(axis=1),label_strings))\n\nmodel.save(\"TrainedInceptionCNN1.h5\")\n","5ee734f9":"# CNN Model"}}