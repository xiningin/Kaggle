{"cell_type":{"0be70cf1":"code","d6d5817b":"code","2eeba301":"code","4615b70a":"code","a4c5e325":"code","6b590187":"code","beb2912d":"code","cd1fb67d":"code","8af9fdda":"code","17b9970e":"code","f1a72225":"code","dbcfa2d0":"code","e43feaed":"code","101dafa7":"code","9cbfd148":"code","cf08027f":"code","b1711d28":"code","330371b6":"code","82cc4fc3":"code","fe107709":"code","e683c6c2":"code","99a266fd":"code","117b83a5":"code","e07c9d40":"code","13a8fb70":"code","99b0cfaf":"code","a05fe1d8":"code","06f4f75b":"code","8e51dbc3":"code","079ef14c":"code","e8d7331f":"code","446303ba":"code","95600f70":"code","9e5b6613":"code","1ef1a67f":"code","ea2c7b83":"code","8778ce31":"code","d0e6afc1":"code","dcf7185a":"code","0ae86c6f":"code","337205ef":"code","8c52a4e3":"markdown","b9822455":"markdown","de96ab00":"markdown","10fc1d7f":"markdown","42db83ba":"markdown","9e9cea31":"markdown","c942ac98":"markdown","9e8ea45d":"markdown","b1773457":"markdown","e7b8fcab":"markdown","0febd69a":"markdown","4c2e1ef2":"markdown","e992f94e":"markdown"},"source":{"0be70cf1":"import pandas as pd\ntrain_df = pd.read_csv('..\/input\/titanic\/train.csv')","d6d5817b":"train_df = train_df[['Survived','Pclass','Sex','Age','SibSp','Fare','Embarked','Parch']]\ntrain_df['Embarked'] = train_df['Embarked'].fillna((train_df['Embarked'].bfill()))\ntrain_df = pd.get_dummies(train_df, prefix='', prefix_sep='')\ntrain_df.head()","2eeba301":"train_df.shape","4615b70a":"empty_age_df = train_df[train_df['Age'].isnull()]\nnot_empty_age_df = train_df[train_df['Age'].notnull()]","a4c5e325":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\ny = not_empty_age_df[\"Age\"].values\nx = not_empty_age_df.drop(\"Age\",axis=1).values\n\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=10)","6b590187":"model = Sequential()\nmodel.add(Dense(48,activation=\"relu\"))\nmodel.add(Dense(24,activation=\"relu\"))\nmodel.add(Dense(12,activation=\"relu\"))\nmodel.add(Dense(1))\n\nmodel.compile(optimizer=\"adam\",loss=\"mse\")\nmodel.fit(x=x_train, y = y_train,validation_data=(x_test,y_test),batch_size=250,epochs=190)","beb2912d":"history = pd.DataFrame(model.history.history)\nimport matplotlib.pyplot as plt\nplt.plot(history['loss'])\nplt.plot(history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","cd1fb67d":"age_predict_df = empty_age_df.drop('Age', axis=1)","8af9fdda":"scaler = MinMaxScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","17b9970e":"predict = scaler.transform( age_predict_df.iloc[:].values.reshape(-1,10))\nage_pred = model.predict(predict)","f1a72225":"age_predict_df['Age'] = age_pred.astype(int)","dbcfa2d0":"age_predict_df.head()","e43feaed":"train_df = pd.concat([not_empty_age_df, age_predict_df])","101dafa7":"train_df.head()","9cbfd148":"train_df.shape","cf08027f":"train_df.info()","b1711d28":"test_df = pd.read_csv('..\/input\/titanic\/test.csv')\ntest_df = test_df[['Pclass','Sex','Age','SibSp','Fare','Embarked','Parch']]\ntest_df['Fare'] = test_df['Fare'].fillna((test_df['Fare'].mean()))\ntest_df = pd.get_dummies(test_df, prefix='', prefix_sep='')\ntest_df.info()","330371b6":"test_df.head()","82cc4fc3":"test_empty_age_df = test_df[test_df['Age'].isnull()]\ntest_not_empty_age_df = test_df[test_df['Age'].notnull()]","fe107709":"y = test_not_empty_age_df[\"Age\"].values\nx = test_not_empty_age_df.drop(\"Age\",axis=1).values\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=10)","e683c6c2":"model = Sequential()\nmodel.add(Dense(48,activation=\"relu\"))\nmodel.add(Dense(24,activation=\"relu\"))\nmodel.add(Dense(12,activation=\"relu\"))\nmodel.add(Dense(1))\nmodel.compile(optimizer=\"adam\",loss=\"mse\")\nmodel.fit(x=x_train, y = y_train,validation_data=(x_test,y_test),batch_size=250,epochs=190)","99a266fd":"history = pd.DataFrame(model.history.history)\nimport matplotlib.pyplot as plt\nplt.plot(history['loss'])\nplt.plot(history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","117b83a5":"test_age_predict_df = test_empty_age_df.drop('Age', axis=1)\ntest_age_predict_df.head()","e07c9d40":"scaler = MinMaxScaler()\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)","13a8fb70":"test_age_predict = scaler.transform( test_age_predict_df.iloc[:].values.reshape(-1,9))\ntest_age_pred = model.predict(test_age_predict)\ntest_empty_age_df['Age'] = test_age_pred.astype(int)\ntest_empty_age_df.head()","99b0cfaf":"test_df = pd.concat([test_not_empty_age_df, test_empty_age_df])\ntest_df.info()","a05fe1d8":"train_df.info()","06f4f75b":"X_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df\nX_train.shape, Y_train.shape, X_test.shape","8e51dbc3":"from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","079ef14c":"model_list = []\nmodel_score = []","e8d7331f":"model_title = 'LR LogisticRegression'\nlogreg = LogisticRegression(max_iter=1000)\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = logreg.score(X_train, Y_train)\nmodel_list.append(model_title)\nmodel_score.append(acc_log)","446303ba":"model_title = 'SVC SupportVectorMachines'\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nf_pred = svc.predict(X_test)\nacc_svc = svc.score(X_train, Y_train)\nmodel_list.append(model_title)\nmodel_score.append(acc_svc)","95600f70":"model_title = 'KNN KNearistNeighbors'\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = knn.score(X_train, Y_train)\nmodel_list.append(model_title)\nmodel_score.append(acc_knn)","9e5b6613":"model_title = 'DTC DecisionTree'\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = decision_tree.score(X_train, Y_train)\nmodel_list.append(model_title)\nmodel_score.append(acc_decision_tree)","1ef1a67f":"model_title = 'GNB Gaussian'\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\ngaussian.score(X_train, Y_train)\nacc_gnb = gaussian.score(X_train, Y_train)\nmodel_list.append(model_title)\nmodel_score.append(acc_gnb)","ea2c7b83":"model_title = 'PRC Perceptron'\nperceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\nY_pred = perceptron.predict(X_test)\nperceptron.score(X_train, Y_train)\nacc_prc = perceptron.score(X_train, Y_train)\nmodel_list.append(model_title)\nmodel_score.append(acc_prc)","8778ce31":"model_title = 'SGD StochasticGradientDescent'\nstochasticgradient = SGDClassifier()\nstochasticgradient.fit(X_train, Y_train)\nY_pred = stochasticgradient.predict(X_test)\nperceptron.score(X_train, Y_train)\nacc_sgd = stochasticgradient.score(X_train, Y_train)\nmodel_list.append(model_title)\nmodel_score.append(acc_sgd)","d0e6afc1":"model_title = 'RFC RandomForest'\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = random_forest.score(X_train, Y_train)\nmodel_list.append(model_title)\nmodel_score.append(acc_random_forest)","dcf7185a":"models = list(zip(model_list,model_score))\nmodels_df = pd.DataFrame(models, columns=['Model Name','Score'])\nmodels_df.sort_values('Score', ascending = False)","0ae86c6f":"test_df = pd.read_csv('..\/input\/titanic\/test.csv')\ntest_df.head()","337205ef":"submission = pd.DataFrame({ 'PassengerId': test_df['PassengerId'], 'Survived': f_pred })\nsubmission.to_csv('f_submission.csv', index=False)\n\nsub_df = pd.read_csv('.\/f_submission.csv')\nsub_df","8c52a4e3":"First importing pandas to read train csv data and get info","b9822455":"Keras and sklearn will be use to create model and to split test train ","de96ab00":"Simplification of the train dataframe, fill empty raws, reshape..","10fc1d7f":"Model score table descending by score ","42db83ba":"Creating train test split for our models","9e9cea31":"Model complated and the results ","c942ac98":"Our models and their training scores","9e8ea45d":"Reloading test csv to get PassengerId","b1773457":"Saving results to submission.csv file","e7b8fcab":"**Welcome**\n\nPurpose of this notebook is predicting survivals on a given train\/test datasets. \n\n**Introduction**\n1. Import pandas libraries, read train csv datas.\n2. Complate a small number of empty raws using traditional ways. \n3. *Predict huge missing Age values using Neural Networks in train dataset\n4. *Predict huge missing Age values using Neural Networks in test dataset\n5. Complate datasets with new age values\n6. Create models for Survivel prediction\n7. Display list of all models accuricies\n8. Save best model's submission ","0febd69a":"Now its time to handle test dataset and same process will be applied to as in train dataset","4c2e1ef2":"Split datas as empty age\/not empty age","e992f94e":"This is our final train dataframe which does not include any missing values "}}