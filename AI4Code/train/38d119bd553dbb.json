{"cell_type":{"97f64eb4":"code","3084e4d9":"code","9b8086d4":"code","504b54a2":"code","f00f5b83":"code","f10e9cfe":"code","d4abcbfe":"code","7dc16cc0":"code","cdf5944a":"code","54fd3866":"code","cde07de6":"code","6016aa3c":"code","c2916cf7":"code","184493f9":"code","1c2a95bf":"code","96cd53c2":"markdown","4d006870":"markdown","0ad07f37":"markdown","6ef9d2eb":"markdown","3316acac":"markdown","a49bdeed":"markdown","29ac255c":"markdown","0508741e":"markdown","d039ebc8":"markdown","0fe36c13":"markdown","badda0d3":"markdown","72256f2f":"markdown","d8b9f5df":"markdown","915f9229":"markdown","3354c584":"markdown","458ca005":"markdown","1245c381":"markdown","c2b608bf":"markdown","e3e50373":"markdown","b7edb503":"markdown","b1f962c1":"markdown","8b2094bf":"markdown","f0b42225":"markdown"},"source":{"97f64eb4":"# Python libraries\nimport pandas as pd\nimport numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom datetime import datetime\nimport lightgbm as lgbm\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, train_test_split\nfrom sklearn.metrics import precision_score, roc_auc_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score\nimport warnings\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\n\nwarnings.filterwarnings('ignore')\n\nfrom contextlib import contextmanager\n\n@contextmanager\ndef timer(title):\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))","3084e4d9":"#Read\ndata = pd.read_csv('..\/input\/creditcard.csv')","9b8086d4":"display(data.head())\ndisplay(data.describe())\ndisplay(data.shape)\ndisplay(data.info())","504b54a2":"fraud = data[(data['Class'] != 0)]\nnormal = data[(data['Class'] == 0)]\n\ntrace = go.Pie(labels = ['Normal', 'Fraud'], values = data['Class'].value_counts(), \n               textfont=dict(size=15), opacity = 0.8,\n               marker=dict(colors=['lightskyblue','gold'], \n                           line=dict(color='#000000', width=1.5)))\n\n\nlayout = dict(title =  'Distribution of target variable')\n           \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)","f00f5b83":"# Correlation matrix \nf, (ax1, ax2) = plt.subplots(1,2,figsize =( 18, 8))\ncorr = data.corr()\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap((data.loc[data['Class'] ==1]).corr(), vmax = .8, square=True, ax = ax1, cmap = 'afmhot', mask=mask);\nax1.set_title('Fraud')\nsns.heatmap((data.loc[data['Class'] ==0]).corr(), vmax = .8, square=True, ax = ax2, cmap = 'YlGnBu', mask=mask);\nax2.set_title('Normal')\nplt.show()","f10e9cfe":"# Normalization Amount\nfrom sklearn.preprocessing import StandardScaler\ndata['nAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))","d4abcbfe":"# Drop useless variables\ndata = data.drop(['Amount','Time'],axis=1)","7dc16cc0":"# def X and Y\ny = np.array(data.Class.tolist())\ndata = data.drop('Class', 1)\nX = np.array(data.as_matrix())","cdf5944a":"# Train_test split\nrandom_state = 42\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = random_state, stratify = y)","54fd3866":"def model_performance(model) : \n    #Conf matrix\n    conf_matrix = confusion_matrix(y_test, y_pred)\n    trace1 = go.Heatmap(z = conf_matrix  ,x = [\"0 (pred)\",\"1 (pred)\"],\n                        y = [\"0 (true)\",\"1 (true)\"],xgap = 2, ygap = 2, \n                        colorscale = 'Viridis', showscale  = False)\n\n    #Show metrics\n    tp = conf_matrix[1,1]\n    fn = conf_matrix[1,0]\n    fp = conf_matrix[0,1]\n    tn = conf_matrix[0,0]\n    Accuracy  =  ((tp+tn)\/(tp+tn+fp+fn))\n    Precision =  (tp\/(tp+fp))\n    Recall    =  (tp\/(tp+fn))\n    F1_score  =  (2*(((tp\/(tp+fp))*(tp\/(tp+fn)))\/((tp\/(tp+fp))+(tp\/(tp+fn)))))\n\n    show_metrics = pd.DataFrame(data=[[Accuracy , Precision, Recall, F1_score]])\n    show_metrics = show_metrics.T\n\n    colors = ['gold', 'lightgreen', 'lightcoral', 'lightskyblue']\n    trace2 = go.Bar(x = (show_metrics[0].values), \n                   y = ['Accuracy', 'Precision', 'Recall', 'F1_score'], text = np.round_(show_metrics[0].values,4),\n                    textposition = 'auto',\n                   orientation = 'h', opacity = 0.8,marker=dict(\n            color=colors,\n            line=dict(color='#000000',width=1.5)))\n    \n    #Roc curve\n    model_roc_auc = round(roc_auc_score(y_test, y_pred) , 3)\n    fpr, tpr, t = roc_curve(y_test, y_score)\n    trace3 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2), fill='tozeroy')\n    trace4 = go.Scatter(x = [0,1],y = [0,1],\n                        line = dict(color = ('black'),width = 1.5,\n                        dash = 'dot'))\n    \n    # Precision-recall curve\n    precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n    trace5 = go.Scatter(x = recall, y = precision,\n                        name = \"Precision\" + str(precision),\n                        line = dict(color = ('lightcoral'),width = 2), fill='tozeroy')\n    \n    #Feature importance\n    coefficients  = pd.DataFrame(lgbm_clf.feature_importances_)\n    column_data   = pd.DataFrame(list(data))\n    coef_sumry    = (pd.merge(coefficients,column_data,left_index= True,\n                              right_index= True, how = \"left\"))\n    coef_sumry.columns = [\"coefficients\",\"features\"]\n    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n    coef_sumry = coef_sumry[coef_sumry[\"coefficients\"] !=0]\n    trace6 = go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n                    name = \"coefficients\",\n                    marker = dict(color = coef_sumry[\"coefficients\"],\n                                  colorscale = \"Viridis\",\n                                  line = dict(width = .6,color = \"black\")))\n    \n    #Cumulative gain\n    pos = pd.get_dummies(y_test).as_matrix()\n    pos = pos[:,1] \n    npos = np.sum(pos)\n    index = np.argsort(y_score) \n    index = index[::-1] \n    sort_pos = pos[index]\n    #cumulative sum\n    cpos = np.cumsum(sort_pos) \n    #recall\n    recall = cpos\/npos \n    #size obs test\n    n = y_test.shape[0] \n    size = np.arange(start=1,stop=369,step=1) \n    #proportion\n    size = size \/ n \n    #plots\n    model = 'lgbm_clf'\n    trace7 = go.Scatter(x = size,y = recall,\n                        name = \"Lift curve\",\n                        line = dict(color = ('gold'),width = 2), fill='tozeroy') \n    \n    #Subplots\n    fig = tls.make_subplots(rows=4, cols=2, print_grid=False, \n                          specs=[[{}, {}], \n                                 [{}, {}],\n                                 [{'colspan': 2}, None],\n                                 [{'colspan': 2}, None]],\n                          subplot_titles=('Confusion Matrix',\n                                        'Metrics',\n                                        'ROC curve'+\" \"+ '('+ str(model_roc_auc)+')',\n                                        'Precision - Recall curve',\n                                        'Feature importance',\n                                        'Cumulative gains curve'\n                                        ))\n    \n    fig.append_trace(trace1,1,1)\n    fig.append_trace(trace2,1,2)\n    fig.append_trace(trace3,2,1)\n    fig.append_trace(trace4,2,1)\n    fig.append_trace(trace5,2,2)\n    fig.append_trace(trace6,3,1)\n    fig.append_trace(trace7,4,1)\n    \n    fig['layout'].update(showlegend = False, title = '<b>Model performance report<\/b><br>'+str(model),\n                        autosize = False, height = 1500,width = 830,\n                        plot_bgcolor = 'rgba(240,240,240, 0.95)',\n                        paper_bgcolor = 'rgba(240,240,240, 0.95)',\n                        margin = dict(b = 195))\n    fig[\"layout\"][\"xaxis2\"].update((dict(range=[0, 1])))\n    fig[\"layout\"][\"xaxis3\"].update(dict(title = \"false positive rate\"))\n    fig[\"layout\"][\"yaxis3\"].update(dict(title = \"true positive rate\"))\n    fig[\"layout\"][\"xaxis4\"].update(dict(title = \"recall\"), range = [0,1.05])\n    fig[\"layout\"][\"yaxis4\"].update(dict(title = \"precision\"), range = [0,1.05])\n    fig[\"layout\"][\"xaxis6\"].update(dict(title = \"Percentage contacted\"))\n    fig[\"layout\"][\"yaxis6\"].update(dict(title = \"Percentage positive targeted\"))\n    fig.layout.titlefont.size = 14\n    \n    py.iplot(fig)","cde07de6":"%%time\nlgbm_clf = lgbm.LGBMClassifier(n_estimators=100, random_state = 42)\n\nlgbm_clf.fit(X_train, y_train)\nlgbm_clf.fit(X_train, y_train)\ny_pred = lgbm_clf.predict(X_test)\ny_score = lgbm_clf.predict_proba(X_test)[:,1]","6016aa3c":"model_performance('lgbm_clf')","c2916cf7":"%%time\nlgbm_clf = lgbm.LGBMClassifier(boosting_type='gbdt', class_weight=None,\n        colsample_bytree=0.48885215797203996, importance_type='split',\n        learning_rate=0.1, max_depth=-1, metric='None',\n        min_child_samples=180, min_child_weight=1e-05, min_split_gain=0.0,\n        n_estimators=5000, n_jobs=4, num_leaves=7, objective=None,\n        random_state=42, reg_alpha=0.1, reg_lambda=5, silent=True,\n        subsample=0.2411830009999915, subsample_for_bin=200000,\n        subsample_freq=0, scale_pos_weight = 1)\n\nlgbm_clf.fit(X_train, y_train)\nlgbm_clf.fit(X_train, y_train)\ny_pred = lgbm_clf.predict(X_test)\ny_score = lgbm_clf.predict_proba(X_test)[:,1]","184493f9":"model_performance('lgbm_clf')","1c2a95bf":"scores = cross_val_score(lgbm_clf, X, y, scoring = 'f1', cv=5)\ntrace = go.Table(\n    header=dict(values=['<b>F1 score mean<b>', '<b>F1 score std<b>'],\n                line = dict(color='#7D7F80'),\n                fill = dict(color='#a1c3d1'),\n                align = ['center'],\n                font = dict(size = 15)),\n    cells=dict(values=[np.round(scores.mean(),6),\n                       np.round(scores.std(),6)],\n               line = dict(color='#7D7F80'),\n               fill = dict(color='#EDFAFF'),\n               align = ['center'], font = dict(size = 15)))\n\nlayout = dict(width=800, height=500, title = 'Cross validation - 5 folds [F1 score]', font = dict(size = 15))\nfig = dict(data=[trace], layout=layout)\npy.iplot(fig, filename = 'styled_table')","96cd53c2":"## <a id='1.4'>1.4. Target distribution<\/a>","4d006870":"![](http:\/\/image.noelshack.com\/fichiers\/2018\/45\/7\/1541947949-1-1-1-card.png)\n\n\n-------------------\n\n- <a href='#1'>1. Load libraries and read the data<\/a>  \n\n     - <a href='#1.1'>1.1. Load libraries<\/a>\n     - <a href='#1.2'>1.2. Read the data<\/a>\n     - <a href='#1.3'>1.3. Head, describe, shape and info<\/a>\n     - <a href='#1.4'>1.4. Target distribution<\/a>\n     - <a href='#1.5'>1.5. Correlation matrix<\/a>\n     \n- <a href='#2'>2. Prepare dataset<\/a>\n\n     - <a href='#2.1'>2.1. Normalization Amount<\/a>\n     - <a href='#2.2'>2.2. Drop useless variables<\/a>\n     - <a href='#2.3'>2.3. Define (X, y)<\/a>\n     - <a href='#2.4'>2.4. Stratified train-test split<\/a>\n     \n- <a href='#3'>3. Define model performance<\/a>\n\n- <a href='#4'>4. LightGBM Model<\/a>\n\n    - <a href='#4.1'>4.1. LightGBM - Before RandomizedSearchCV<\/a>\n    - <a href='#4.2'>4.2. LightGBM - RandomizedSearchCV to optimise hyperparameters (soon!)<\/a>\n    - <a href='#4.3'>4.3. LightGBM - After RandomizedSearchCV<\/a>\n    - <a href='#4.4'>4.4. LightGBM - Cross Validation - 5 folds [F1 score]<\/a>\n    \n- <a href='#5'>5. Reference<\/a>\n\n-------------------\n","0ad07f37":"## <a id='#2.1'>2.1. Normalization Amount<\/a>","6ef9d2eb":"## <a id='2.4'>2.4. Stratified train test split<\/a>","3316acac":"## <a id='4'>4. LightGBM Model<\/a>","a49bdeed":"## <a id='4.1'>4.1. LightGBM - Before RandomizedSearchCV<\/a>","29ac255c":"## <a id='1.1'>1.1. Load libraries<\/a>","0508741e":"**Soon...**","d039ebc8":"## <a id='1.2'>1.2. Read the data<\/a>","0fe36c13":"## <a id='4.2'>4.2. LightGBM - RandomizedSearchCV to optimise hyperparameters<\/a>","badda0d3":"## <a id='1.3'>1.3. Head, describe, shape and info<\/a>","72256f2f":"## <a id='5'>5. Reference<\/a>","d8b9f5df":"**Thank you all ! Merci \u00e0 tous ! :)**","915f9229":"## <a id='1.5'>1.5. Correlation matrix<\/a>","3354c584":"# <a id='#1'>1. Load libraries and read the data<\/a>","458ca005":"# <a id='#2'>2. Prepare dataset<\/a>","1245c381":"## <a id='4.4'>4.4. LightGBM - Cross validation - 5 folds [F1 score]<\/a>","c2b608bf":"## <a id='2.2'>2.2. Drop useless variables<\/a>","e3e50373":"https:\/\/www.kaggle.com\/pavanraj159 (plotly master)","b7edb503":"# <a id='3'>3. Define model performance<\/a>","b1f962c1":"## <a id='4.3'>4.3. LightGBM - After RandomizedSearchCV<\/a>","8b2094bf":"## <a id='2.3'>2.3. Define (X, y)<\/a>","f0b42225":"----------\n**LightGBM + Plotly : 0.999+**\n=====================================\n\n***Vincent Lugat***\n\n*November 2018*\n\n----------"}}