{"cell_type":{"956871dc":"code","d58d9d08":"code","d5e59a25":"code","ceeda2f1":"code","772fee37":"code","dc208460":"code","dba0f26b":"code","3ff78403":"code","1fa9cced":"markdown"},"source":{"956871dc":"pip install feature_engine","d58d9d08":"import numpy as np\nimport pandas as pd\n\nfrom feature_engine.imputation import AddMissingIndicator\nfrom feature_engine.encoding import MeanEncoder, RareLabelEncoder\nfrom sklearn.pipeline import Pipeline\n\nfrom lightgbm import LGBMRegressor\nimport shap\nrandom_state = 123","d5e59a25":"train = pd.read_csv('\/kaggle\/input\/widsdatathon2022\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/widsdatathon2022\/test.csv')","ceeda2f1":"cat_var = train.select_dtypes(include=[object]).columns.to_list()\ncat_var.append('Year_Factor')\nx_train = train.drop(['site_eui'], axis = 1)\ny_train = train.copy()['site_eui']","772fee37":"addBinary_imputer = AddMissingIndicator()\nrare_encoder = RareLabelEncoder(tol=0.02, n_categories=2, variables=cat_var,\n                           replace_with=-999, ignore_format = True)\nmean_encoder = MeanEncoder(variables=cat_var, ignore_format = True)\n\npipe = Pipeline([('indicator', addBinary_imputer),\n                 ('RareLabelEncoder1', rare_encoder),\n                 ('MeanEncoder', mean_encoder)])","dc208460":"lgbm_model = LGBMRegressor(random_state = random_state)","dba0f26b":"x_train_processed = pipe.fit_transform(x_train, y_train)\nlgbm_model.fit(x_train_processed,y_train)","3ff78403":"shap_values = shap.TreeExplainer(lgbm_model).shap_values(x_train_processed)\nshap.summary_plot(shap_values, x_train_processed)","1fa9cced":"# The Analysis\nIn the present notebook the shap values are presented to observate the most relevant features and the temporal features (id, Year_Factor) to see if we need to some temporal cross validation to train our models"}}