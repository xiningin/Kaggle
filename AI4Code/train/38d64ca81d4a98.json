{"cell_type":{"2e2738d9":"code","2ab71ca0":"code","96881f30":"code","8390373a":"code","cbd88999":"code","c2111265":"code","544a3ac5":"code","dfaaae17":"code","1fba8816":"code","d5a210c6":"code","e478388c":"code","c7d634df":"code","b687148d":"code","121d9613":"code","34b9dcf5":"code","6cd3b084":"code","49c40b8a":"code","c4ba7081":"markdown","1e4f0d3f":"markdown","c2ce7bf2":"markdown","bf7a7ca6":"markdown","861927f1":"markdown","c1411819":"markdown","713d5bbb":"markdown","39264e12":"markdown","78bd8902":"markdown","4b2c1f86":"markdown","405431d6":"markdown","2d69f11f":"markdown","cd158a99":"markdown","0f27593e":"markdown","c37e659d":"markdown","5737320c":"markdown","a4dfdadb":"markdown","afd7504d":"markdown","9651a0b4":"markdown","6571f8c7":"markdown"},"source":{"2e2738d9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2ab71ca0":"laliga = pd.read_csv(\"..\/input\/la-liga-match-data\/combined_data_laliga.csv\")\nlaliga.head(10)","96881f30":"#Function \ndef score_encoder(Hs,As):\n    if Hs>As:\n        return \"HW\"\n    elif Hs<As:\n        return \"AW\"\n    else:\n        return \"D\"\n        ","8390373a":"laliga_masterset= laliga.iloc[:,:].values\ngd_list=[]\nfor i in laliga_masterset:\n        score = i[3]\n        half_score=i[4]\n        finalscore_list = score.split('-')\n        halfscore_list = half_score.split('-')\n        #half time class\n        Half_Hs = int(halfscore_list[0])\n        Half_As= int(halfscore_list[1])\n        Half_result=score_encoder(Half_Hs,Half_As)\n        #full time class and goal difference\n        Hs=int(finalscore_list[0])\n        As=int(finalscore_list[1])\n        result=score_encoder(Hs,As)\n        # Updation of list\n        i[3]=result\n        i[4]=Half_result\n        \nlaliga_masterset=pd.DataFrame(laliga_masterset)        \nlaliga_masterset.head(10)        ","cbd88999":"#getting column names back \nlaliga_masterset.head(10)\nlaliga= pd.DataFrame(data=laliga_masterset.values, columns=laliga.columns)\nlaliga.head(10)","c2111265":"laliga = pd.DataFrame(laliga.iloc[:,3:40])\nlaliga.head(10)","544a3ac5":"X = pd.DataFrame(laliga.iloc[:,2:33])\nX.head(10)","dfaaae17":"Y_classifier = pd.DataFrame(laliga.iloc[:,0:2])\nY_classifier.head(10)","1fba8816":"Y_regressor = pd.DataFrame(laliga.iloc[:,33:35])\nY_regressor.head(10)","d5a210c6":"from sklearn.model_selection import train_test_split\n#classifier data\nX_train_C, X_test_C,Y_train_C,Y_test_C = train_test_split(X,Y_classifier,test_size=0.2,random_state=1)\n#regressor Data\nX_train_R, X_test_R,Y_train_R,Y_test_R = train_test_split(X,Y_regressor,test_size=0.2,random_state=3)","e478388c":"from sklearn.neighbors import KNeighborsClassifier\nknn_classifier= KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=1) \nknn_classifier.fit(X_train_C,Y_train_C) \ny_knn_pred=knn_classifier.predict(X_test_C)\ny_knn_pred= pd.DataFrame(data=y_knn_pred,columns=['Result','Half Time Score'])\ny_knn_pred.head(10)\n","c7d634df":"from sklearn.tree import DecisionTreeClassifier\ntree_classifier=DecisionTreeClassifier(criterion='entropy')\ntree_classifier.fit(X_train_C,Y_train_C)\ntree_pred = tree_classifier.predict(X_test_C)\ntree_pred= pd.DataFrame(data=tree_pred,columns=['Result','Half Time Score'])\ntree_pred.head(10)","b687148d":"from sklearn.ensemble import RandomForestClassifier\nrandom_classifier=RandomForestClassifier(n_estimators=100,random_state=0)\nrandom_classifier.fit(X_train_C,Y_train_C)\nrandom_pred=random_classifier.predict(X_test_C)\nrandom_pred=pd.DataFrame(data=random_pred,columns=['Result','Half Time Score'])\nrandom_pred.head(10)","121d9613":"from sklearn.metrics import accuracy_score\ndef acc_calculator_classifier(y_pred,y_test,model_name):\n        \n    half_acc=accuracy_score(y_pred.iloc[:,1],y_test.iloc[:,1])\n    full_acc=accuracy_score(y_pred.iloc[:,0],y_test.iloc[:,0])\n    print(\"Accuracy score for half time score with \"+model_name+\" \"+ str(half_acc*100))\n    print(\"Accuracy score for full time score with \"+model_name+\" \"+ str(full_acc*100))\n    \n    \nacc_calculator_classifier(y_knn_pred,Y_test_C,\"KNN 7\")\nacc_calculator_classifier(tree_pred,Y_test_C,\"Decision Tree\")\nacc_calculator_classifier(random_pred,Y_test_C,\"Random forest 100\")","34b9dcf5":"from sklearn.ensemble import GradientBoostingClassifier\ngb=GradientBoostingClassifier(n_estimators=250,learning_rate=0.1)\ngb.fit(X_train_C,Y_train_C.iloc[:,0])\npred = gb.predict(X_test_C)\nacc = accuracy_score(Y_test_C.iloc[:,0],pred)\nprint(\"Accuracy for Gradient Boost Classifier \"+str(acc*100))","6cd3b084":"from sklearn.ensemble import RandomForestRegressor\nrfr=RandomForestRegressor(n_estimators=500,random_state=0)\nY_train_R.head(10)\nrfr.fit(X_train_R,Y_train_R)\ny_pred=rfr.predict(X_test_R)\ny_pred=pd.DataFrame(data=y_pred,columns=Y_train_R.columns)\ny_pred.head(10)\n","49c40b8a":"from sklearn import metrics\nprint('Mean Absolute Error:', metrics.mean_absolute_error(Y_test_R, y_pred))\nprint('Mean Squared Error:', metrics.mean_squared_error(Y_test_R, y_pred))\nprint('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(Y_test_R, y_pred)))","c4ba7081":"**Random forest Regressor**","1e4f0d3f":"**Performance of each model**","c2ce7bf2":"# Result Predictions","bf7a7ca6":"**Determining Independent and Dependent Variables**\n\n\n*The model will consist of a classifier and a regressor *\n1. Classifier will work on determining the Result of the match and score at half time\n2. regressor will work on determining the goals scored by the home and away team","861927f1":"**Dependent Variables for Classifiers**","c1411819":"# Merging all datasets # ","713d5bbb":"**Removing the unwanted columns**\n\ncolumns which have been removed are team names and year","39264e12":" Random forest yeilds the best result for Full time Result with 87.21%","78bd8902":"**dependent variable for regressor**","4b2c1f86":"# Gradient Boost Classifier ","405431d6":"**Accuracy for above model**","2d69f11f":"# Score Line Prediction","cd158a99":"**Encoding scores to classes**\n\nIdea is to convert scorelines to simple classes which can be futher encoded to be fitted in the model.Classes will be\n1. HW- if the home team wins or is winning at half time\n2. D - if the scores are equal\n3. AW - if the Away team is winning or is winning at half time \n","0f27593e":"# Data Cleaning","c37e659d":"**Decision Tree**","5737320c":"**Independent Variables**","a4dfdadb":"**Random Forest**","afd7504d":"**KNN**","9651a0b4":"**Function for score classes**\n\n","6571f8c7":"**Data Splitting**"}}