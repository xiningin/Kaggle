{"cell_type":{"3d30b16b":"code","6db3d211":"code","4baff831":"code","1f289b37":"code","9898d426":"code","b918b15f":"code","12ab5df7":"code","94948e32":"code","5d162833":"code","c84edd2f":"code","0707f294":"code","f7e5ed24":"code","2f188c52":"code","7dcb0196":"code","8b0704e6":"code","688916a1":"code","09ec2662":"code","8f8d67c7":"code","9a195bd5":"code","65b1c1a1":"code","c9f3fa15":"code","4ce01872":"code","b32653b0":"code","3074b438":"code","262c9604":"code","f871eaa3":"code","bb681546":"code","cc44bd41":"code","75ed4d93":"code","6a6e6c09":"code","78791cdb":"code","901feea7":"code","ed485a20":"code","aa601c31":"code","baaf7706":"code","057ee0f3":"code","a06532ae":"code","05a21038":"code","d0185c00":"code","ba5c15d3":"code","f15b0c4e":"code","e1212412":"code","9402ef27":"code","adb65933":"code","19b6a0a7":"code","34df879f":"code","0e3d714c":"code","6a2c4fff":"code","1d800c90":"code","128cd3f3":"code","42ef9c82":"markdown","8194ca7f":"markdown","403c13ba":"markdown","4bb692f3":"markdown","ac664b17":"markdown","1a0cad44":"markdown","08c4d8df":"markdown","af26e09a":"markdown","19e8cbf2":"markdown","c1753d1d":"markdown","fd1a0c19":"markdown","c1652f14":"markdown","5c757301":"markdown","d03cc40d":"markdown","f23bb4f0":"markdown","e6e2fe74":"markdown","1e35b3e0":"markdown","6b55cbb4":"markdown","55ae20e2":"markdown","01c0fa55":"markdown","744c989d":"markdown","dbd568f1":"markdown","47b7f223":"markdown","eec3b819":"markdown","bcadcfc5":"markdown","afc231ee":"markdown","48762e78":"markdown","638820df":"markdown","06057b00":"markdown","a1aa202c":"markdown","6742dc87":"markdown","8dae1c4e":"markdown","ea3408ca":"markdown","59f4b19c":"markdown","c353007f":"markdown","996c77e4":"markdown","b1f155dd":"markdown","150521ab":"markdown","77c8e471":"markdown","cc276282":"markdown","06261c8f":"markdown","b64f5f30":"markdown","45516a47":"markdown","106f97a2":"markdown","bc4dff2b":"markdown","6d588d18":"markdown","7e5a198c":"markdown","a1356305":"markdown","e21efb7d":"markdown","c8b529e6":"markdown","18e9a6cd":"markdown","9a4af48d":"markdown","03890b88":"markdown","aef483bc":"markdown","d889cca1":"markdown"},"source":{"3d30b16b":"# Basic libraries required\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics \nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import PolynomialFeatures","6db3d211":"# reading the data from csv file to dataframe\ndata = pd.read_csv('..\/input\/sf-salaries\/Salaries.csv')\ndata.head()","4baff831":"# info() prints summary of data like dtypes, memory usage\ndata.info()","1f289b37":"# To know how many data points,features we have \ndata.shape","9898d426":"# describe() will tell us about statistical information of each Numerical column\ndata.describe()","b918b15f":"data.drop(['Id','EmployeeName'],axis=1,inplace=True)","12ab5df7":"data.head()","94948e32":"data.isnull().sum()","5d162833":"data.drop(['Notes'],inplace=True,axis=1)\ndata.head()","c84edd2f":"data[data['Status'].isnull()==False]['Status'].value_counts()","0707f294":"data.drop(['Status'],axis=1,inplace=True)\ndata.head()","f7e5ed24":"data['Benefits'].fillna(0,inplace=True)\ndata.tail()","2f188c52":"data[data['BasePay'].isnull()==True]","7dcb0196":"data['BasePay'].fillna(0,inplace=True)","8b0704e6":"data[data['BasePay']=='Not Provided']","688916a1":"data = data[data['BasePay'] != 'Not Provided']\ndata.shape","09ec2662":"data.head()","8f8d67c7":"data['JobTitle'].value_counts()","9a195bd5":"data['JobTitle'] = data['JobTitle'].astype('category').cat.codes\ndata.head(2)","65b1c1a1":"data['Agency'].value_counts()","c9f3fa15":"data.drop(['Agency'],axis=1,inplace=True)","4ce01872":"data.info()","b32653b0":"data = data.astype('float64')\ndata.info()","3074b438":"data['Response'] = data['OvertimePay'] + data['OtherPay'] + data['Benefits']","262c9604":"data['Regressor'] = data['BasePay']","f871eaa3":"data.drop(['JobTitle','TotalPay','TotalPayBenefits','BasePay','OvertimePay','OtherPay','Benefits'],axis=1,inplace=True)","bb681546":"test = data[data['Year']==2014]\ndata = data[data['Year'] != 2014]","cc44bd41":"test.shape","75ed4d93":"data.head()","6a6e6c09":"# To know correlation between attributes\nplt.figure(figsize = (10,8))\np=sns.heatmap(data.corr(), annot=True,cmap='RdYlGn',center=0) ","78791cdb":"data.hist(figsize=(12,10))","901feea7":"plt.scatter(data['Regressor'],data['Response'],alpha=0.7)\nplt.xlabel('BasePay')\nplt.ylabel('Other Pays')","ed485a20":"# splitting the data into 2 parts,one to train the model and another one to test the trained model\n\n# splitting the data such that 80% is used for training and remaining 20% for testing\nX_train, X_val, y_train, y_val = train_test_split(data[['Regressor']], data[['Response']], test_size=0.2)","aa601c31":"# initializing model\nmodel = LinearRegression()\n\n# fitting data\nmodel.fit(X_train,y_train)\n\n# predict \npred_train = model.predict(X_train)\npred_val = model.predict(X_val)\n\n# r2\ntrain_R2_LR = r2_score(y_train,pred_train)\ntest_R2_LR = r2_score(y_val,pred_val)\n\nprint('train R2 SCORE:',train_R2_LR)\nprint('Val R2 SCORE:',test_R2_LR)","baaf7706":"# let's see how well our model fit into data \n# training data plot\nplt.scatter(X_train,y_train, color=\"red\")\nplt.plot(X_train, pred_train, color=\"blue\")\nplt.xlabel(\"Regressor\")\nplt.ylabel(\"Response\")\nplt.title(\"Regression analysis of Basepay vs Other Pays\")","057ee0f3":"# validation data plot\nplt.scatter(X_val,y_val, color=\"red\")\nplt.plot(X_val, pred_val, color=\"blue\")\nplt.xlabel(\"Regressor\")\nplt.ylabel(\"Response\")\nplt.title(\"Linear model\")","a06532ae":"## let's transform data into polynomial form with degree=10\npoly_reg=PolynomialFeatures(degree=2)\nx_poly=poly_reg.fit_transform(X_train)\n\npoly_reg.fit(x_poly,y_train)\n\n# fitting our data into model\nmodel=LinearRegression()\nmodel.fit(x_poly,y_train)\n\n#predictions\npred_train = model.predict(x_poly)\nx_poly_val = poly_reg.fit_transform(X_val)\npred_val = model.predict(x_poly_val)\n\n# r2\ntrain_R2_PR2 = r2_score(y_train,pred_train)\ntest_R2_PR2 = r2_score(y_val,pred_val)\n\nprint('train R2:',train_R2_PR2)\nprint('test R2:',test_R2_PR2)","05a21038":"# let's see how well our model fit into data \n# training data plot\nplt.scatter(X_train,y_train, color=\"red\")\nplt.scatter(X_train, pred_train, color=\"blue\",s=0.5)\nplt.xlabel(\"Regressor\")\nplt.ylabel(\"Response\")\nplt.title(\"Regression analysis of Basepay vs Other Pays\")","d0185c00":"# validation data plot\nplt.scatter(X_val,y_val, color=\"red\")\nplt.scatter(X_val, pred_val, color=\"blue\",s=0.6)\nplt.xlabel(\"Regressor\")\nplt.ylabel(\"Response\")\nplt.title(\"quadratic model - degree=2\")","ba5c15d3":"## let's transform data into polynomial form with degree=10\npoly_reg=PolynomialFeatures(degree=3)\nx_poly=poly_reg.fit_transform(X_train)\n\n# fitting our data into model\nmodel=LinearRegression()\nmodel.fit(x_poly,y_train)\n\n#predictions\npred_train = model.predict(x_poly)\nx_poly_val = poly_reg.fit_transform(X_val)\npred_val = model.predict(x_poly_val)\n\n# r2\ntrain_R2_PR3 = r2_score(y_train,pred_train)\ntest_R2_PR3 = r2_score(y_val,pred_val)\n\nprint('train R2:',train_R2_PR3)\nprint('test R2:',test_R2_PR3)","f15b0c4e":"# let's see how well our model fit into data \n# training data plot\nplt.scatter(X_train,y_train, color=\"red\")\nplt.scatter(X_train, pred_train, color=\"blue\",s=0.5)\nplt.xlabel(\"Regressor\")\nplt.ylabel(\"Response\")\nplt.title(\"Regression analysis of Basepay vs Other Pays\")","e1212412":"# validation data plot\nplt.scatter(X_val,y_val, color=\"red\")\nplt.scatter(X_val, pred_val, color=\"blue\",s=0.5)\nplt.xlabel(\"Regressor\")\nplt.ylabel(\"Response\")\nplt.title(\"Cubic - Degree = 3\")","9402ef27":"# let's define lists to score errors and k-values\ntrain_R2 = []\ntest_R2 = []\ndegree = []\n\n# k ranging from 1-10\nfor k in range(1, 10):\n    # storing degree\n    degree.append(k)\n    \n    # initialising model\n    poly_reg=PolynomialFeatures(degree=k)\n    x_poly=poly_reg.fit_transform(X_train)\n\n    # fitting our data into model\n    model=LinearRegression()\n    model.fit(x_poly,y_train)\n    \n    #predictions\n    pred_train = model.predict(x_poly)\n    x_poly_val = poly_reg.fit_transform(X_val)\n    pred_val = model.predict(x_poly_val)\n\n    # training data R2\n    train_R2.append(r2_score(y_train,pred_train))\n    \n    #test data R2\n    test_R2.append(r2_score(y_val,pred_val))","adb65933":"# let's plot training scores , test scores against k values \n\nplt.figure(figsize=(10,5))\nplt.title('Model R2 score vs degree')\nplt.xlabel('degree')\nplt.ylabel('Model R2 score')\nplt.plot(degree, train_R2, color = 'r', label = \"training R2\")\nplt.plot(degree, test_R2, color = 'b', label = 'test R2')\nplt.legend(bbox_to_anchor=(1, 1),bbox_transform=plt.gcf().transFigure)","19b6a0a7":"test_R2.index(max(test_R2))","34df879f":"R = pd.DataFrame(data=[[train_R2[0],test_R2[0]],[train_R2[1],test_R2[1]],[train_R2[2],test_R2[2]]],columns={'Train_R2','Test_R2'},index={'Linear','non-linear degree=2','non-linear degree=3'})","0e3d714c":"R","6a2c4fff":"## let's transform data into polynomial form with degree=10\npoly_reg=PolynomialFeatures(degree=3)\nx_poly=poly_reg.fit_transform(X_train)\n\n# fitting our data into model\nmodel=LinearRegression()\nmodel.fit(x_poly,y_train)\n\n#predictions\npred_train = model.predict(x_poly)\nx_poly_val = poly_reg.fit_transform(X_val)\npred_val = model.predict(x_poly_val)\n\n# r2\ntrain_R2_PR3 = r2_score(y_train,pred_train)\ntest_R2_PR3 = r2_score(y_val,pred_val)\n\nprint('train R2:',train_R2_PR3)\nprint('test R2:',test_R2_PR3)","1d800c90":"x_poly_test =poly_reg.fit_transform(test[['Regressor']])\ny_test = model.predict(x_poly_test)","128cd3f3":"# test data plot\nplt.scatter(test[['Regressor']],test[['Response']], color=\"red\",label='actual ')\nplt.scatter(test[['Regressor']], y_test, color=\"blue\",s=0.5,label='our model')\nplt.xlabel(\"Regressor\")\nplt.ylabel(\"Response\")\nplt.legend()\nplt.title(\"simple non linear regression analysis with degree-3\")","42ef9c82":"\n<div class=\"alert alert-info\" style=\"background-color: \t#800080; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>Regression Analysis<\/h2>\n<\/div>\n","8194ca7f":"<div class=\"alert alert-info\" style=\"padding:0px 10px; border-radius:5px;\"><h3 style='margin:10px 5px'> Inferences:<\/h3>\n<\/div>","403c13ba":"### Table of contents : <br\/>\n1. [Problem statement]( #1 )\n2. [Loading Data]( #2 )\n3. [Understand the Data](#3)\n4. [Data Preprocessing](#4)\n    * Dropping unncessary columns\n    * Missing values\n    * label encoding\n    * Feature Selection\n5. [Exploratory Data Analysis](#5)\n    * Heat map\n    * Histograms\n    * Scatter plot\n6. [Model Building](#6)\n    * Splitting data\n    * [Linear model](#7)\n    * [Polynomial model - degree 2](#8)\n    * [Polynomial model - degree 3](#9)\n    * [Finding Ideal degree](#10)\n7. [Final Model and test](#11)","4bb692f3":"<a id='8'><\/a>\n<div class=\"alert alert-info\" style=\"background-color:#800080; color:white; padding:0px 10px; border-radius:5px;\"><h3 style='margin:10px 5px'>6.3 Simple non-linear regression analysis with degree 2.\n<\/h3><\/div>","ac664b17":"<a id='2'><\/a>\n<div class=\"alert alert-info\" style=\"background-color:#800080; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>2. Load Data<\/h2>\n<\/div>","1a0cad44":"### 5.1 HeatMap","08c4d8df":"we have to create a model for this plot such that our model fits into this data","af26e09a":"#### 'Notes' \nWe can see that 'Notes' attribute doesn't have any information. Let's drop it","19e8cbf2":"<a id='11'><\/a>\n<div class=\"alert alert-info\" style=\"background-color:#800080; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>6.5 Final Model and Test <\/h2>\n <\/div>","c1753d1d":"Let's see other case where we will try to fit our data into a polynomial model wih degree 2 and 3","fd1a0c19":"### 4.5 Feature Selection\nAccording to the problem statement, we have to join 'Overtime Pay; ,'other pay' ,Benefits' <br\/>","c1652f14":"#### 'JobTitle'","5c757301":"we can see that even though data about BasePay isn't provided , that person still gets the TotalPay from other factors.<br\/>\nSo let's make BasePay as 0 here","d03cc40d":"<a id='5'><\/a>\n<div class=\"alert alert-info\" style=\"background-color:#800080; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>5. Exploratory Data Analysis <\/h2>\n<\/div>","f23bb4f0":"* We dropped 'Notes','Status' columns\n* We changed 'Benefits','BasePay' null values to 0\n* We dropped rows with unprovided information","e6e2fe74":"<div class=\"alert alert-info\" style=\"padding:0px 10px; border-radius:5px;\"><h3 style='margin:10px 5px'> Inferences:<\/h3>\n<\/div>","1e35b3e0":"we see that some of the rows doesn't have required information at all <br\/>\nSo let's just remove them","6b55cbb4":"We know that if R2 score is more , the model is perfect <br\/>\nWe have seen R2 for linear model , polynomial with degree 2 and 3 out of which polynomial with degree=3 yields the best results<br\/>\nLet's see some more polynomial degrees and see which will have high R2 score","55ae20e2":"<a id='10'><\/a>\n<div class=\"alert alert-info\" style=\"background-color:#800080; color:white; padding:0px 10px; border-radius:5px;\"><h3 style='margin:10px 5px'>6.4 Finding ideal degree <\/h3><\/div>","01c0fa55":"### 4.3 Encoding Categorical Columns - Label Encoding\nLet's observe each column","744c989d":"<a id='9'><\/a>\n<div class=\"alert alert-info\" style=\"background-color:#800080; color:white; padding:0px 10px; border-radius:5px;\"><h3 style='margin:10px 5px'>6.4 Simple non-linear regression analysis with degree 3.\n<\/h3><\/div>","dbd568f1":"We have data abour salary of various employees in different companies and at different positions. <br\/>\nData includes their base pay along with all other benifits. <br\/>\nLet's see how will \"Overtime pay ,other pay,Benefits\" increases with basic pay","47b7f223":"### Final data after preprocessing","eec3b819":"### 5.2 Histograms","bcadcfc5":"<a id='6'><\/a>\n<div class=\"alert alert-info\" style=\"background-color:#800080; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>6. Model Building <\/h2>\n<\/div>","afc231ee":"Let's drop unnecessary columns","48762e78":"Red coloured data is actual data and blue line is our model <br\/>","638820df":"## Thankyou","06057b00":"#### \"Agency\"","a1aa202c":"<div class=\"alert alert-info\" style=\"background-color:#800080; color:white; padding:0px 10px; border-radius:5px;\"><h3 style='margin:10px 5px'>6.1 Splitting the data <\/h3>\n <\/div>","6742dc87":"### 4.4 Changing dtype","8dae1c4e":"we see 'Basepay','Overtimepay','Otherpay','Benifits' are Object DType <br\/>\nLet's change it to float","ea3408ca":"<a id='4'><\/a>\n<div class=\"alert alert-info\" style=\"background-color:#800080; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>4. Data Pre-processing <\/h2>\n<\/div>","59f4b19c":"<a id='1'><\/a>\n<div class=\"alert alert-info\" style=\"background-color:#800080; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>1. Convert Business Problem to Data Science Problem<\/h2>\n<\/div>","c353007f":"#### 'BasePay'\nWe observe that 605 records are Null.Let's observe them","996c77e4":"We will make a basic linear regression model and let's see how our model fit into the data","b1f155dd":"We see that Polynomial model with degree= 3 gives best R2 score ","150521ab":"#### 'Status' ","77c8e471":"### 4.2 Dealing with missing values","cc276282":"<a id='7'><\/a>\n<div class=\"alert alert-info\" style=\"background-color:#800080; color:white; padding:0px 10px; border-radius:5px;\"><h3 style='margin:10px 5px'>6.2 Simple Linear regression Analysis<\/h3><\/div>","06261c8f":"Agency doesn't carry any weightage as all values are same <br\/>\nLet's drop the column","b64f5f30":"It was asked to test on 2014 data.Let's seperate it for test purpose","45516a47":"Red coloured data is actual data and blue line is our model <br\/>","106f97a2":"* we can see that we have **13** attributes with **148654** records\n* we can observe that *note* attribute doesn't have any information and we can drop it\n","bc4dff2b":"<a id='3'><\/a>\n<div class=\"alert alert-info\" style=\"background-color:#800080; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>3. Understanding Data <\/h2>\n<\/div>","6d588d18":"<div class=\"alert alert-info\" style=\"padding:0px 10px; border-radius:5px;\"><h3 style='margin:10px 5px'> Inferences:<\/h3>\n<\/div>","7e5a198c":"let's make a model with degree of 3 ","a1356305":"#### 'Benefits' ","e21efb7d":"#### Columns with '\"Not Provided\" as value","c8b529e6":"### 5.3 Scatter Plot","18e9a6cd":"We can observe that we have very less records of Status attribute. It isn't appropriate to imputate the data. <br\/>\nTherefore let's drop this column too","9a4af48d":"We know that benefits is nothing but difference between **\"Totalpay Benefits\"** and **\"Totalpay\"** <br\/>\nLet's replace NaN values will '0'","03890b88":"###  4.1 Dropping unnecessary columns\nWe know that id,employee name will be unique for everyone and will not carry any weightage to the model.<br\/>\nSo, let's drop them","aef483bc":"\n<div class=\"alert alert-info\" style=\"background-color:#800080; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>Importing Libraries<\/h2>\n<\/div>","d889cca1":"## Test"}}