{"cell_type":{"8711cd0f":"code","478bda73":"code","960e5260":"code","92f5817e":"code","78e31626":"code","e1eba3ac":"code","779586ad":"code","dc4a4d17":"code","a2c16c96":"code","e75d7a53":"code","3d6591b3":"code","1b5eb342":"code","379b2722":"code","4c068b06":"code","050449a1":"code","666bf8a8":"code","027e8b87":"code","d4fc6daa":"code","d86202da":"code","2aa11280":"code","979fcbaf":"code","1931ce99":"code","9885b47c":"code","4bc2c85a":"code","2adc568e":"code","3b375038":"markdown","d64d5443":"markdown","3b059c41":"markdown","345541fd":"markdown","ea6ab067":"markdown","9e19a71a":"markdown","7a2a8164":"markdown","d0b387e1":"markdown","6bc74638":"markdown","b674f2ed":"markdown","8a0bf11f":"markdown","ad26a1f8":"markdown","786fd7b3":"markdown","a2b6c071":"markdown","5d4b4bfb":"markdown","d206edb9":"markdown","4085fb40":"markdown"},"source":{"8711cd0f":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\n\nfrom sklearn.model_selection import train_test_split\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","478bda73":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","960e5260":"## loading the train dataset\n\ntrain_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntrain_df.head()","92f5817e":"## loading the test dataset\n\ntest_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\ntest_df.head()","78e31626":"print(f\"Train dataframe size: {len(train_df)}\")\nprint(f\"Test dataframe size: {len(test_df)}\")","e1eba3ac":"## Visualizing an image from the train set\n\ntest_image = np.array(train_df.loc[:,'pixel0':])[20].reshape(28,28) ### getting the 20th image from the train dataset\n\nplt.imshow(test_image, cmap=\"gray\")\nplt.show()","779586ad":"print(\"Label as in the train data: \",train_df['label'][20])","dc4a4d17":"X = train_df.loc[:,'pixel0':]\ny = train_df['label']\n\nX_train, X_val, y_train, y_val = train_test_split(X,y, test_size=0.2, random_state=42)\n\nprint(f\"X_train size: {X_train.shape} and y_train size = {y_train.shape}\")\nprint(f\"X_val size: {X_val.shape} and y_val size = {y_val.shape}\")\nprint(f\"X_train type: {type(X_train)}\")","a2c16c96":"## loading the test dataframe\n\nX_test = test_df.loc[:,:]\n\nprint(f\"X_test size: {X_test.shape}\")","e75d7a53":"class MNistDataset(Dataset):\n    '''\n        Custom pytorch dataset to read and transform MNist data from csv.\n    '''\n    def __init__(self, data, train=True, transform=None):\n        self.data = data\n        self.transform = transform\n        self.train = train\n    \n    def __len__(self):\n        return self.data[0].values.shape[0]\n    \n    def __getitem__(self, index):\n        X = self.data[0].values[index].astype(np.uint8).reshape((28,28))\n        \n        if self.train:\n            y = self.data[1].values[index].astype(np.long)\n        \n        if self.transform:\n            X = self.transform(X)\n        \n        if self.train:\n            return X,y\n        else:\n            return X\n        ","3d6591b3":"transform = transforms.ToTensor() ## This transformation converts np arrays to tensors","1b5eb342":"train_ds = MNistDataset((X_train,y_train), train=True, transform=transform)\nval_ds = MNistDataset((X_val,y_val), train=True, transform=transform) ## train=True; since this is a split of train dataframe.\ntest_ds = MNistDataset((X_test,), train=False, transform=transform)","379b2722":"print(f\"Size of the Train dataset: {len(train_ds)}\")\nprint(f\"Size of the Validation dataset: {len(val_ds)}\")\nprint(f\"Size of the Test dataset: {len(test_ds)}\")","4c068b06":"## random check of the dataset created\n\nimage, label = train_ds[120]\nval_image, val_label = val_ds[120]\ntest_image = test_ds[120]\n\nprint(f'Image shape: {image.shape} and Type : {type(image)}  ')\nprint(f'Label: {label} \\t Label Type : {type(label)}')\nprint(f'Validation Image shape: {val_image.shape} and Validation Image Type : {type(val_image)}')\nprint(f'Label: {val_label} \\t Label Type : {type(val_label)}')\n\nprint(f'Test Image shape: {test_image.shape} and Test Image Type : {type(test_image)}')\n","050449a1":"## sample row display\ntrain_ds[120]","666bf8a8":"train_loader = DataLoader(train_ds, shuffle=True, batch_size=100)\nval_loader = DataLoader(val_ds, shuffle=False, batch_size=100)\ntest_loader = DataLoader(test_ds, shuffle=False, batch_size=28000)  ## we don't need to shuffle test data's. Using the complete volume as batch size as iteration is not required.","027e8b87":"class MNistClassifierModel(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        \n        self.conv2d1 = nn.Conv2d(1,6,3,1) ## params: in_channels, out_channels, kernel_size, stride\n        self.conv2d2 = nn.Conv2d(6,16,3,1)\n        self.fc1 = nn.Linear(5*5*16, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84,10)\n    \n    \n    def forward(self,x):\n        x = F.relu(self.conv2d1(x))\n        x = F.max_pool2d(x,2,2)\n        x = F.relu(self.conv2d2(x))\n        x = F.max_pool2d(x,2,2)\n        x = x.view(-1,5*5*16)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = F.log_softmax(self.fc3(x), dim=1)\n        \n        return x","d4fc6daa":"model = MNistClassifierModel()\nmodel","d86202da":"criterions = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)  ## using Adam optimizer with Learning rate: 0.001","2aa11280":"epochs = 8\n\ntrain_losses = []\nval_losses = []\n\ntrain_correct = []\nval_correct = []\n\nfor i in range(epochs):\n    \n    train_corr = 0\n    val_corr = 0\n    \n    ## iterating over the training dataset\n    for b, (X_train, y_train) in enumerate(train_loader):\n        \n        b+=1\n        \n        # predicting from the model and calculating loss\n        y_pred = model(X_train)\n        losses = criterions(y_pred, y_train)\n        \n        predicted_label = torch.max(y_pred.data,1)[1]\n        train_corr += (predicted_label == y_train).sum()\n        \n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n        \n        # printing after every 100 batches of execution\n        if b%100 == 0:\n            print(f\"Epoch:{i} \\t Batch:{b} [{b*100}\/33600] \\t Loss:{losses:10.8f} \\t Accuracy: {(train_corr.item()\/(b*100) * 100):10.3f}%\")\n    \n    train_losses.append(losses)\n    train_correct.append(train_corr)\n    \n    \n    ## for the validation test loss check\n    with torch.no_grad():\n        for tb, (X_val_test, y_val_test) in enumerate(val_loader):\n            y_valtest_pred = model(X_val_test)\n            test_predicted = torch.max(y_valtest_pred,1)[1]\n            val_corr += (test_predicted == y_val_test).sum()\n        \n        val_loss = criterions(y_valtest_pred,y_val_test)\n        val_losses.append(val_loss)\n        val_correct.append(val_corr)","979fcbaf":"plt.plot(range(epochs),train_losses,label=\"Training Loss\")\nplt.plot(range(epochs),val_losses,label=\"Validation Loss\")\nplt.title(\"Training Loss vs Validation Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","1931ce99":"plt.plot([(tc.item()\/33600)*100 for tc in train_correct], label=\"Training Accuracy\")\nplt.plot([(v.item()\/8400)*100 for v in val_correct], label=\"Validation Accuracy\")\nplt.title(\"Accuracy plot for Training and Validation\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy (%)\")\nplt.legend()\nplt.show()","9885b47c":"sample_submission_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/sample_submission.csv')\n\nsample_submission_df.shape ## Note it has got the same length as test dataframe","4bc2c85a":"## making predictions on the test dataset\n\nwith torch.no_grad():\n    for X_test in test_loader:\n        y_test_pred = model(X_test)\n        test_predicted = torch.max(y_test_pred,1)[1]\n\nprint(f\"{test_predicted}\")","2adc568e":"## Generate the submission file\n\noutput = pd.DataFrame({'ImageId':sample_submission_df['ImageId'],'Label':test_predicted})\noutput.to_csv('mnist_submission_cnn.csv', index=False)","3b375038":"### Defining the loss function and optimizer","d64d5443":"### Defining the model","3b059c41":"We will make use of the sample submission file to meet the kaggle output requirements","345541fd":"### Split the Train dataframe into train\/test","ea6ab067":"# Defining Model, Loss Function and Optimizers","9e19a71a":"Checking the total size of the dataset","7a2a8164":"# Visualization of the dataset","d0b387e1":"# Training MNist data using pytorch and convolution neural network.\n\nThis is a simple notebook that demonstrate the steps to train and test MNIST dataset using pytorch and CNN.","6bc74638":"# Loading and Preparation of training + test dataset","b674f2ed":"# Train the model","8a0bf11f":"Note: Both Training and Validation accuracy is around 97-98% approximately.","ad26a1f8":"# Predicting the test results + Submission","786fd7b3":"### Batch Load\n> Using torch dataloader, we will create a dataloader object for training in batches. Training in batches will help in better results during training process","a2b6c071":"Note: The test dataframe is more of a validation dataframe. We would require to split the train dataset into train\/test split in order to test the accuracy of the data.","5d4b4bfb":"### Prepare the custom dataset","d206edb9":"### Define the transformation logic and load the data","4085fb40":"# General Imports"}}