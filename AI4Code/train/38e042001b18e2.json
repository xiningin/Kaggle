{"cell_type":{"ae1f992e":"code","d9b4308c":"code","82921846":"code","c94b98dd":"code","ce539f30":"code","8d0970ae":"code","4c55ee1f":"markdown"},"source":{"ae1f992e":"import math\nimport pandas as pd\nfrom itertools import islice\nimport numpy as np\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nimport seaborn as sns\nimport logging\nfrom tqdm import tqdm\nimport category_encoders\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.preprocessing import LabelEncoder, scale, MinMaxScaler, Normalizer, QuantileTransformer, PowerTransformer, StandardScaler\nfrom scipy.stats import boxcox\nimport math\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom catboost import Pool, CatBoostClassifier\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)","d9b4308c":"test_path = '..\/input\/test.csv'\n\ndf_test = pd.read_csv(test_path)\ndf_test.drop(['ID_code'], axis=1, inplace=True)\ndf_test = df_test.values\n\nunique_samples = []\nunique_count = np.zeros_like(df_test)\nfor feature in tqdm(range(df_test.shape[1])):\n    _, index_, count_ = np.unique(df_test[:, feature], return_counts=True, return_index=True)\n    unique_count[index_[count_ == 1], feature] += 1\n\nreal_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\nsynthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n\ndel df_test","82921846":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\ntest_real = test.iloc[real_samples_indexes]\n\nfeatures = train.drop(['ID_code', 'target'], axis = 1).columns.tolist()\n\ndata = train.append(test_real)","c94b98dd":"num_round = 1000000\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\noof = np.zeros(len(train))\npredictions = np.zeros(len(test))\n\nmodel = CatBoostClassifier(loss_function=\"Logloss\",\n                           eval_metric=\"AUC\",\n                           task_type=\"GPU\",\n                           learning_rate=0.01,\n                           iterations=70000,\n                           l2_leaf_reg=50,\n                           random_seed=42,\n                           od_type=\"Iter\",\n                           depth=5,\n                           early_stopping_rounds=15000,\n                           border_count=64\n                          )\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, train.target.values)):\n    print(\"Fold {}\".format(fold_))\n    X_train, y_train = train.iloc[trn_idx][features], train.iloc[trn_idx]['target']\n    X_valid, y_valid = train.iloc[val_idx][features], train.iloc[val_idx]['target']\n    \n    for col in tqdm(features):\n        gr = data[col].value_counts()\n        gr_bin = data.groupby(col)[col].count()>1\n        \n        X_train[col + '_un'] = X_train[col].map(gr).astype('category').cat.codes\n        X_valid[col + '_un'] = X_valid[col].map(gr).astype('category').cat.codes\n        test[col + '_un'] = test[col].map(gr).astype('category').cat.codes\n        \n        X_train[col + '_un_bin'] = X_train[col].map(gr_bin).astype('category').cat.codes\n        X_valid[col + '_un_bin'] = X_valid[col].map(gr_bin).astype('category').cat.codes\n        test[col + '_un_bin'] = test[col].map(gr_bin).astype('category').cat.codes\n        \n        X_train[col + '_raw_mul'] = X_train[col] * X_train[col + '_un_bin']\n        X_valid[col + '_raw_mul'] = X_valid[col] * X_valid[col + '_un_bin']\n        test[col + '_raw_mul'] = test[col] * test[col + '_un_bin']\n        \n        X_train[col + '_raw_mul_2'] = X_train[col] * X_train[col + '_un']\n        X_valid[col + '_raw_mul_2'] = X_valid[col] * X_valid[col + '_un']\n        test[col + '_raw_mul_2'] = test[col] * test[col + '_un']\n        \n        X_train[col + '_raw_mul_3'] = X_train[col + '_un_bin'] * X_train[col + '_un']\n        X_valid[col + '_raw_mul_3'] = X_valid[col + '_un_bin'] * X_valid[col + '_un']\n        test[col + '_raw_mul_3'] = test[col + '_un_bin'] * test[col + '_un']\n\n\n    _train = Pool(X_train, label=y_train)\n    _valid = Pool(X_valid, label=y_valid)\n    clf = model.fit(_train,\n                    eval_set=_valid,\n                    use_best_model=True,\n                    verbose=5000)\n    pred = clf.predict_proba(X_valid)[:,1]\n    oof[val_idx] = pred\n    print( \"  auc = \", roc_auc_score(y_valid, pred) )\n    predictions += clf.predict_proba(test.drop('ID_code', axis=1))[:,1] \/ folds.n_splits\nprint(\"CV score: {:<8.5f}\".format(roc_auc_score(train.target, oof)))","ce539f30":"sub = pd.DataFrame({\"ID_code\": test.ID_code.values})\nsub[\"target\"] = predictions\nsub.to_csv(\"Range_bins_sub_3.csv\", index=False)","8d0970ae":"sub.head()","4c55ee1f":"The final version of my decision.\n\nMany thanks to the guys whose public kernels helped create this script - @zxspectrum and @ yag320"}}