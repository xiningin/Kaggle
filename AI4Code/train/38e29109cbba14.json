{"cell_type":{"17508f67":"code","aa530c1d":"code","a50532a5":"code","73dbd0ff":"code","5c0201ac":"code","28c33958":"code","668f8f27":"code","2f33fd38":"code","f857e411":"code","47b0919f":"code","f4b8d06d":"code","aeaf3ddb":"code","6da8caed":"markdown","493699ab":"markdown","95ff00b5":"markdown","88434b4e":"markdown","ff2c41e5":"markdown","c16e2ea4":"markdown","f12ae6ea":"markdown","78f4ec36":"markdown","0aa68ec1":"markdown","b14c6291":"markdown"},"source":{"17508f67":"import numpy as np\nimport pandas as pd\n#tensorflow version 2.0\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.model_selection import train_test_split\n\n#reading data\nmnist_train = pd.read_csv('..\/input\/sign-language-mnist\/sign_mnist_train\/sign_mnist_train.csv')\nmnist_test = pd.read_csv('..\/input\/sign-language-mnist\/sign_mnist_test\/sign_mnist_test.csv')\n\nprint(\"Datasets successfully loaded!\")\nprint(f\"Training dataset has {mnist_train.shape[0]} rows and {mnist_train.shape[1]} columns.\")\nprint(f\"Training dataset has {mnist_test.shape[0]} rows and {mnist_test.shape[1]} columns.\")","aa530c1d":"#standardization\nmnist_train.iloc[:,1:] \/= 255\nmnist_test.iloc[:,1:] \/= 255\n\n#splitting features and target column\nx_train = mnist_train.iloc[:,1:]\ny_train = mnist_train.iloc[:,0]\nx_test= mnist_test.iloc[:,1:]\ny_test=mnist_test.iloc[:,0]\n\n#further splitting train set into validation and training set\nx_train,x_validate,y_train,y_validate = train_test_split(x_train,y_train,test_size = 0.3)","a50532a5":"plt.figure(figsize=(10, 10))\nfor i in range(36):\n    plt.subplot(6, 6, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(np.array(x_test.iloc[i]).reshape(28,28))\n    label_index = int(y_test[i])\n    plt.title(label_index)\nplt.show()","73dbd0ff":"sns.countplot(y_train)\nplt.title('Classes distribution in train set');","5c0201ac":"sns.countplot(y_validate)\nplt.title('Classes distribution in validation set');","28c33958":"sns.countplot(y_test)\nplt.title('Classes distribution in test set');","668f8f27":"image_rows = 28\nimage_cols = 28\nimage_shape = (image_rows,image_cols,1)\nx_train = tf.reshape(x_train,[x_train.shape[0],*image_shape])\nx_test = tf.reshape(x_test,[x_test.shape[0],*image_shape])\nx_validate = tf.reshape(x_validate,[x_validate.shape[0],*image_shape])","2f33fd38":"cnn_model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape = image_shape),\n    tf.keras.layers.MaxPooling2D(pool_size=2) ,# down sampling the output instead of 28*28 it is 14*14\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape = image_shape),\n    tf.keras.layers.MaxPooling2D(pool_size=2) ,\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Flatten(), # flatten out the layers\n    tf.keras.layers.Dense(100,activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(100,activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(25,activation = 'softmax')\n])\n\ncnn_model.compile(loss ='sparse_categorical_crossentropy',\n                  optimizer='adam',metrics =['accuracy'])\n\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n\nhistory = cnn_model.fit(\n    x_train,\n    y_train,\n    batch_size=500,\n    epochs=80,\n    verbose=1,\n    validation_data=(x_validate,y_validate),\n    callbacks=early_stop\n)","f857e411":"score = cnn_model.evaluate(x_test,y_test,verbose=0)\nprint('Test Loss : {:.4f}'.format(score[0]))\nprint('Test Accuracy : {:.4f}'.format(100*score[1]))","47b0919f":"plt.figure(figsize=(10, 10))\n\nplt.subplot(2, 2, 1)\nplt.plot(history.history['loss'], label='Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(2, 2, 2)\nplt.plot(history.history['accuracy'], label='Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.title('Training - Accuracy');","f4b8d06d":"cnn_pred = cnn_model.predict_classes(x_test)\ntarget_names = [\"Class {}\".format(i) for i in range(24)]\nprint(classification_report(y_test,cnn_pred, target_names=target_names))","aeaf3ddb":"plt.figure(figsize=(10,10))\nsns.heatmap(confusion_matrix(y_test,cnn_pred),cmap='seismic');","6da8caed":"Let's see if our data is balanced.","493699ab":"Let's have a look at the images in our dataset.","95ff00b5":"Now we define our model. The layer in model network (keras.layers.Flatten) transforms the format of the images from a two-dimensional array (of 28 by 28 pixels) to a one-dimensional array (of 28 * 28 = 784 pixels). This layer unstacks rows of pixels in the image and lining them up and has no parameters to learn; it only reformats the data. Pooling layers are then added to further reduce the number of parameters.\n\nAfter the pixels are flattened, the network consists of a sequence of two keras.layers.Dense layers. These are densely connected, or fully connected, neural layers.\n\nA problem with training neural networks is in the choice of the number of training epochs to use. Too many epochs can lead to overfitting of the training dataset, whereas too few may result in an underfit model. Early stopping is a method that allows you to specify an arbitrary large number of training epochs and stop training once the model performance stops improving on a hold out validation dataset.","88434b4e":"### Standardizing and splitting data in 3 parts- train,validation and test set.\n\nHere, we don't need any sklearn function like StandardScaler or RobustScalar because all the features are in same range (0 to 255). So, we can standardize them simply by dividing by 255.","ff2c41e5":"# Convolutional Neural Network\n\nThe term deep neural nets refers to any neural network with several hidden layers. Convolutional neural nets are a specific type of deep neural net which are especially useful for image recognition. Specifically, convolutional neural nets use convolutional and pooling layers, which reflect the translation-invariant nature of most images.\n\nFor this, we need to reshape our input data.","c16e2ea4":"Almost 96% accuracy on test data is quite good.\n\nLet us plot the Training Accuracy vs Loss to get a better understanding of the model training.","f12ae6ea":"# Sign language MNIST\n\nThe dataset format is patterned to match closely with the classic MNIST. Each training and test case represents a label (0-25) as a one-to-one map for each alphabetic letter A-Z (and no cases for 9=J or 25=Z because of gesture motions). The training data (27,455 cases) and test data (7172 cases) are approximately half the size of the standard MNIST but otherwise similar with a header row of label, pixel1,pixel2\u2026.pixel784 which represent a single 28x28 pixel image with grayscale values between 0-255.","78f4ec36":"***Please upvote and provide suggestions.***","0aa68ec1":"Classes distribution is almost same in train and validation set. Though test set has comparitively few cases of some classes.","b14c6291":"Except class 17 and 23 all classe have accuracy greater than 90%."}}