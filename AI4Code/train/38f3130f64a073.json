{"cell_type":{"5173992a":"code","ae3dd066":"code","99d80960":"code","fa8128ab":"code","d5e7ccbd":"code","355c68ce":"code","85855e6f":"code","e3aff60c":"code","518ce9f2":"code","e6684f6e":"code","33f56068":"markdown"},"source":{"5173992a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ae3dd066":"#Code by Paul Mooney\n\nstanford_file = '..\/input\/graphs-web\/web-Stanford.txt'\nwith open(stanford_file) as f: # The with keyword automatically closes the file when you are done\n    print (f.read(4000))","99d80960":"#Code by Paul Mooney\n\ngoogle_file = '..\/input\/graphs-web\/web-Google.txt'\nwith open(google_file) as f: # The with keyword automatically closes the file when you are done\n    print (f.read(4000))","fa8128ab":"#Code by Jay Lee https:\/\/www.kaggle.com\/jayaos\/basic-nlp-preprocessing-of-corpus-and-zipf-s-law\/notebook\n\nfrom collections import Counter","d5e7ccbd":"#Code by Jay Lee https:\/\/www.kaggle.com\/jayaos\/basic-nlp-preprocessing-of-corpus-and-zipf-s-law\/notebook\n\ndef read_docu(file):\n    \n    all_words = []\n    \n    with open(file, \"r\", encoding = \"utf-8\") as input_file:\n        for line in input_file:\n            line = line.lower()\n            line = line.strip().split()\n            all_words += line\n        return(all_words)","355c68ce":"#Code by Jay Lee https:\/\/www.kaggle.com\/jayaos\/basic-nlp-preprocessing-of-corpus-and-zipf-s-law\/notebook\n\ndef word_counter(all_words):\n    \n    word_count = Counter()\n    for word in all_words:\n        word_count[word] += 1\n    return(word_count.values())","85855e6f":"#Code by Jay Lee https:\/\/www.kaggle.com\/jayaos\/basic-nlp-preprocessing-of-corpus-and-zipf-s-law\/notebook\n\ndef draw_zipfian_curve(word_count):\n    plt.plot(sorted(word_count, reverse = True), marker = \"o\")\n    plt.xscale(\"log\")\n    plt.yscale(\"log\")\n    plt.xlabel(\"log(Rank)\")\n    plt.ylabel(\"log(Frequency)\")\n    plt.show()","e3aff60c":"#Code by Jay Lee https:\/\/www.kaggle.com\/jayaos\/basic-nlp-preprocessing-of-corpus-and-zipf-s-law\/notebook\n\ndef zipfian_plot(file):\n    word_corpus = read_docu(file)\n    counts = word_counter(word_corpus)\n    draw_zipfian_curve(counts)","518ce9f2":"zipfian_plot(\"..\/input\/graphs-web\/web-Google.txt\")","e6684f6e":"#df= pd.read_csv('..\/input\/graphs-web\/web-BerkStan.txt', sep='\\t', error_bad_lines=False)\n#df.head()","33f56068":"#The snippet below takes so long and didn't return anything "}}