{"cell_type":{"0718ad92":"code","d0d70fe3":"code","1e1e547b":"code","dcca90da":"code","93f7403a":"code","666dea98":"code","81b83348":"code","c59554e2":"code","40a998e9":"code","bb850682":"code","e22b71af":"code","15a33e6e":"code","104e4a09":"code","c677c88d":"code","2b4141ca":"code","12bdf05a":"code","9bbc4143":"code","48195dde":"code","f8d6c3b3":"code","cb18c4a1":"code","2011336c":"code","b82ce9cd":"code","4f50a450":"code","6c415700":"code","1e8ec11c":"code","a5b7576d":"code","2f3c143d":"code","de96a477":"code","00a0872b":"code","f7db039d":"code","ba27ec42":"code","e77b5122":"code","b06ed329":"code","47d73cda":"code","adceb28c":"code","28274a22":"code","5c8fc0f2":"code","0a386f9e":"code","55684bd3":"code","4c57316a":"markdown","cd682dbd":"markdown","c6af96f6":"markdown","ab9d3176":"markdown","bdbb41dc":"markdown","20ee3cee":"markdown","bf216520":"markdown","4222b17a":"markdown","76366223":"markdown","732de23c":"markdown","e5b76465":"markdown"},"source":{"0718ad92":"import pandas as pd , numpy as np , matplotlib.pyplot as plt , seaborn as sns , warnings\n%matplotlib inline\n\nwarnings.filterwarnings('ignore')\n\ndf = pd.read_csv('..\/input\/titanic\/train.csv')\ndf_test1 = pd.read_csv('..\/input\/titanic\/test.csv')\n\ndf.head()","d0d70fe3":"df.tail()","1e1e547b":"df.shape","dcca90da":"df.columns","93f7403a":"df.index","666dea98":"df.info()","81b83348":"df.describe()","c59554e2":"sns.countplot(x='Survived',hue='Sex',data=df)","40a998e9":"sns.countplot(x='Survived',hue='Pclass',data=df)","bb850682":"sns.countplot(df.Survived)","e22b71af":"plt.hist(df.Age)","15a33e6e":"sns.boxplot(x='Pclass',y='Age',data=df)","104e4a09":"df.isnull().sum()","c677c88d":"def impute_age(cols):\n    Age=cols[0]\n    Pclass=cols[1]\n\n    if pd.isnull(Age):\n\n        if Pclass == 1:\n            return 37\n        elif Pclass ==2:\n            return 29\n        elif Pclass == 3:\n            return 24\n    else:\n        return Age\n    \ndf.Age=df[['Age','Pclass']].apply(impute_age,axis=1)\n","2b4141ca":"df = df.drop(columns = ['Ticket','Name','Embarked','PassengerId','Cabin'])\n\ndfn=df._get_numeric_data()\nnc=list(dfn)\ndfc=df.drop(columns=nc)\ncc=list(dfc)\n\ndfc=pd.get_dummies(dfc,drop_first=True)\n\ndata=pd.concat([dfn,dfc],axis=1)\ndata.shape","12bdf05a":"df.isnull().sum()","9bbc4143":"data.isnull().sum()","48195dde":"sns.heatmap(data.corr(),cmap='viridis',annot = True)","f8d6c3b3":"sns.pairplot(data)","cb18c4a1":"c= data.corr()    # Finding correlation\n\ni = 0\n\n# replacing diogonal corr() which is 1 to NaN for finding\n#i.e manulating and get the informative features by removing high values of correlation.\n\nwhile True:    \n    try:\n        c.iloc[i,i] = np.nan\n        i += 1\n    except:\n        break","2011336c":"data.Survived.value_counts()","b82ce9cd":"# Getting high corr. values w.r.t output because it supports the output...\n\nfeatures = c[(c['Survived'] > 0.1) | (c['Survived'] < -0.1)].dropna(how = 'all')['Survived']     \nfeatures_col = list(features.index)\nprint(features.shape, len(features_col) , features_col)     # Exactly what i want....","4f50a450":"sns.heatmap(data[features_col].corr(),cmap='viridis',annot = True)","6c415700":"sns.pairplot(data[features_col])","1e8ec11c":"# Preparing  pipeline for all the models\n# Here DecisionTreeClassifier wins the race...\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score,roc_auc_score\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix,classification_report\n\n\nX = data[features_col]\ny = data.Survived\nX_train,X_test,y_train,y_test=train_test_split(X,y,random_state=1)\n\n\n\nmodels = [LogisticRegression(penalty='l2'),DecisionTreeClassifier()\n          ,RandomForestClassifier(),KNeighborsClassifier(),SVC()]\n\nfor model in models:\n    model.fit(X_train,y_train)\n    y_pred = model.predict(X_test)\n    print(accuracy_score(y_test,y_pred),type(model).__name__)","a5b7576d":"X = data[features_col]\ny = data.Survived\nX_train,X_test,y_train,y_test=train_test_split(X,y,random_state=1)\n\nmodel = DecisionTreeClassifier()\n\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\nprint(accuracy_score(y_test,y_pred),type(model).__name__)","2f3c143d":"print(confusion_matrix(y_test,y_pred)) ","de96a477":"print(classification_report(y_test,y_pred))","00a0872b":"X.columns","f7db039d":"df_test = df_test1[['Pclass', 'Fare', 'Sex']]\ndf_test.isnull().sum()","ba27ec42":"df_test[df_test['Fare'] != df_test['Fare']]","e77b5122":"df_test[df_test['Pclass'] == 3]['Fare'].mean()","b06ed329":"df_test = df_test.fillna(12.46)","47d73cda":"df_test.isnull().sum()","adceb28c":"df_test = pd.get_dummies(df_test,drop_first = True)","28274a22":"X_train = data[['Pclass', 'Fare', 'Sex_male']]\nX_test = df_test\ny_train = data.Survived\n\nmodel = DecisionTreeClassifier()\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)","5c8fc0f2":"predictions = pd.concat([df_test1[['PassengerId']],pd.DataFrame(y_pred,columns = ['Survived'])],axis=1)","0a386f9e":"predictions.shape","55684bd3":"predictions","4c57316a":"# Comparing Models","cd682dbd":"# Final Model","c6af96f6":"## Feature Engineering & Feature Selection","ab9d3176":"### Dealing with Missing Values ( i.e Null Values )","bdbb41dc":"## Exploratory Data Analysis ( EDA )","20ee3cee":"# Building Final Model","bf216520":"# Titanic: Machine Learning from Disaster\n### Importing required Libraries & Dataset","4222b17a":"# Getting Predictions Ready For Kaggle Competition","76366223":"## Here DecisionTreeClassifier Clearly Wins the Race","732de23c":"### Getting Deeper into Data","e5b76465":"# ...END..."}}