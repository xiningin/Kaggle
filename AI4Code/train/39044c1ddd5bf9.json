{"cell_type":{"e1592b54":"code","ad961abc":"code","19b64bea":"code","3700ecca":"code","1bff8607":"code","1c5e6c82":"code","1ac41e64":"code","eecf84ff":"code","2628d47f":"code","562e9029":"code","d60a7f35":"code","46533733":"code","a6a0ab08":"code","b69961ea":"code","be1cac11":"code","50d11dd2":"code","2ec495f7":"code","2f216270":"code","a2e3b5cd":"code","7c722ef9":"code","0a801f0b":"code","2e28b1e1":"code","df3d4743":"code","55b14e86":"code","b2aa1bb0":"code","4cbba8e8":"code","d316338d":"code","33b66928":"code","732eb6be":"code","f5942ba7":"code","3c7f094a":"code","263dd67a":"code","2076cf6d":"code","a7a429ee":"code","ed287457":"code","32178be2":"code","673bef37":"code","1b840632":"code","c2fd9915":"code","a3e3e3ad":"code","fb4ae2f1":"code","98d36fd8":"code","ea775f20":"code","f4f9c9db":"code","eccd5836":"code","8901629e":"code","9b938caf":"code","75711ff6":"code","e3824f43":"code","62a9dd82":"code","64d7232b":"code","660caf15":"code","e77215d1":"code","078b13e9":"code","2653c4cb":"code","4dd9b061":"code","41fb7f3b":"code","39242bb2":"code","3e6b4afc":"code","4629c6d8":"code","067ad9fd":"code","b6a7968a":"code","04838026":"code","86cc4dcc":"code","98beb1fb":"code","79ce1fd2":"code","2e71f43d":"code","eff8337b":"code","cd0f7602":"code","ceb7016a":"markdown","a1149b31":"markdown","620917b4":"markdown","7dc1d1d2":"markdown","e428da3f":"markdown","21cb118b":"markdown","f1e46c77":"markdown","ad69c0f4":"markdown","89f4cefe":"markdown","b32720bc":"markdown","eb61adfb":"markdown","68afa319":"markdown","2872d8a7":"markdown","a2e1bc93":"markdown","cc0e5bbd":"markdown","6434a75c":"markdown","acf245aa":"markdown","c1f3513b":"markdown","3715d96f":"markdown","1b716f42":"markdown","71a61ce4":"markdown","f49168dc":"markdown","d55f60c1":"markdown","7617bf57":"markdown","a6c16910":"markdown","bcddb4a0":"markdown","88089cb0":"markdown","00528b0b":"markdown","675ea4cd":"markdown","3de186d2":"markdown"},"source":{"e1592b54":"# Import comet_ml for versioning\n#from comet_ml import Experiment\n\n#experiment = Experiment(api_key=\"toXXRULujXVmmXBW2zMcncxEI\",\n#                        project_name=\"general\", workspace=\"shyken\")","ad961abc":"!pip install comet_ml","19b64bea":"# import comet_ml in the top of your file\nfrom comet_ml import Experiment\n    ","3700ecca":"   \n# Add the following code anywhere in your machine learning file\nexperiment = Experiment(api_key=\"toXXRULujXVmmXBW2zMcncxEI\",\n                        project_name=\"kaggle\", workspace=\"shyken\")","1bff8607":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","1c5e6c82":"# For printing option and text color\nclass color:\n    PURPLE = '\\033[95m'\n    CYAN = '\\033[96m'\n    DARKCYAN = '\\033[36m'\n    BLUE = '\\033[94m'\n    GREEN = '\\033[92m'\n    YELLOW = '\\033[93m'\n    RED = '\\033[91m'\n    BOLD = '\\033[1m'\n    UNDERLINE = '\\033[4m'\n    END = '\\033[0m'","1ac41e64":"df_sub = pd.read_csv('..\/input\/climate-change-belief-analysis\/sample_submission.csv')\ndf_test = pd.read_csv('..\/input\/climate-change-belief-analysis\/test.csv')\ntest = df_test.set_index('tweetid')\ndf_train = pd.read_csv('..\/input\/climate-change-belief-analysis\/train.csv')\ntrain = df_train.set_index('tweetid')","eecf84ff":"test.head()","2628d47f":"test.shape","562e9029":"train.head()","d60a7f35":"train.shape","46533733":"print(f'Missing values in train dataset:\\n{train.isna().sum()}\\n')\nprint(f'Missing values in test dataset:\\n{test.isna().sum()}')","a6a0ab08":"# Checking for Empty messages in both train and test datasets\n\nblanks_test = []\nfor tID,msg in test.itertuples():\n    if msg.isspace == True:\n        blanks_test.append(tID)\n\nblanks_train = []\nfor tID,sent,msg in train.itertuples():\n    if msg.isspace == True:\n        blanks_test.append(tID)","b69961ea":"print(f'No. of empty messages in train: {len(blanks_train)}\\n')\nprint(f'No. of empty messages in test: {len(blanks_test)}')","be1cac11":"# Count of classes in sentiment \n\nsns.set(style=\"darkgrid\")\nax = sns.countplot(x='sentiment', data=df_train)","50d11dd2":"print(color.BOLD +'Percentage of a particular `Class` in the train dataset\\n'+ color.END)\nprint(f'Class 2 ~ News \\n{round((df_train.sentiment.value_counts()[2]\/len(df_train))*100,2)} %\\n')\nprint(f'Class 1 ~ Pro \\n{round((df_train.sentiment.value_counts()[1]\/len(df_train))*100,2)} %\\n')\nprint(f'Class 0 ~ Neutral \\n{round((df_train.sentiment.value_counts()[0]\/len(df_train))*100,2)} %\\n')\nprint(f'Class -1 ~ Anti \\n{round((df_train.sentiment.value_counts()[-1]\/len(df_train))*100,2)} %')","2ec495f7":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier","2f216270":"# Stop words from scikit-learn\nfrom sklearn.feature_extraction import text","a2e3b5cd":" sk_stop_words = list(text.ENGLISH_STOP_WORDS)","7c722ef9":"costom_stop_words = ['and','of','a','an','the','in',\n                   'to','&','@','am','the','were',\n                   'what','where','how','why','about',\n                   'all','at','be','but','by','from',\n                   'got','had','hadn\\'t','has','have',\n                   'having''he','i','i\\'ll','i\\'m',\n                   'in','is','it','it\\'s','just','me',\n                   'my','na','she','so','that','them',\n                   'they','this','was','with','she',\n                   'so','that','them','they','this',\n                   'was','(','[','{',')',']','}']","0a801f0b":"X = train.iloc[:,-1]\ny = train.iloc[:,:-1].values","2e28b1e1":"# Splitting train dataset into train subset(for training model) and validation subset(for model evaluation)\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=0)","df3d4743":"vectorizer = TfidfVectorizer()\nX_vec = vectorizer.fit_transform(X_train)","55b14e86":"# A Pipeline that first imploys tokenazation and vectorization and then trains model using Linear-SVC using train data.\ncl_pipe = Pipeline([('vectorizer', TfidfVectorizer()),\n                     ('linearS', LinearSVC()),])\n","b2aa1bb0":"# Fitting\/training model\ncl_pipe.fit(X_train, y_train) ","4cbba8e8":"# Predicting test subset of validation data\ny_pred = cl_pipe.predict(X_test)","d316338d":"# LinearSVC confusion matrix\nLSVC_confusion = pd.DataFrame(confusion_matrix(y_test,y_pred),\n                  index=['Anti','Neutral','Pro','News'],\n                  columns=['Anti','Neutral','Pro','News'])\n\nLSVC_confusion","33b66928":"# Classification Report matrix \nprint(classification_report(y_test,y_pred))","732eb6be":"y_pred_test = cl_pipe.predict(test.message)","f5942ba7":"y_pred_test","3c7f094a":"# Predictions in submission kaggle format\nlinearSVC_submission1 = pd.DataFrame({'tweetid': test.index, \n                           'sentiment': y_pred_test})","263dd67a":"linearSVC_submission1","2076cf6d":"# Saving to .csv file\nlinearSVC_submission1.to_csv('LSVC_01.csv',index = False)","a7a429ee":"import pickle\n\n# Here i am saving th entire pipeline,if there's a need i'll save the vecorizer and model separate.\n# Saving the pipeline in the same name as the submission file helps keep track of everything.\n\nmodel_save_path = \"LSVC_01.pkl\"\nwith open(model_save_path,'wb') as file:\n    pickle.dump(cl_pipe,file)","ed287457":"# Instantiate KNN model\nKNN = KNeighborsClassifier(n_neighbors=10)","32178be2":"# KNN pipeline\nKNN_pipe = Pipeline([('vectorizer', TfidfVectorizer()),('KNN',KNN)])","673bef37":"# Fitting\/Training KNN model\nKNN_pipe.fit(X_train,y_train.ravel())","1b840632":"# Predicting validation subset\ny_pred_KNN = KNN_pipe.predict(X_test)","c2fd9915":"# KNN confusion matrix\nKNN_confusion = pd.DataFrame(confusion_matrix(y_test,y_pred_KNN),\n                  index=['Anti','Neutral','Pro','News'],\n                  columns=['Anti','Neutral','Pro','News'])\n\nKNN_confusion","a3e3e3ad":"# Classification report matrix\nprint(classification_report(y_test,y_pred_KNN))","fb4ae2f1":"y_KNN = KNN_pipe.predict(test.message)","98d36fd8":"y_KNN","ea775f20":"# Predictions in submission kaggle format\nKNN_submission1 = pd.DataFrame({'tweetid': test.index, \n                           'sentiment': y_KNN})\n\nKNN_submission1","f4f9c9db":"# Saving to .csv file\nKNN_submission1.to_csv('KNN_01.csv',index = False)","eccd5836":"model_save_path = 'KNN_01.pkl'\nwith open(model_save_path,'wb') as file:\n    pickle.dump(KNN_pipe,file)","8901629e":"# Instantiating Random forest Classifier\nRFC = RandomForestClassifier(n_estimators=100)","9b938caf":"# Random forest pipeline\nRFC_pipe = Pipeline([('vectorizer', TfidfVectorizer()),\n                     ('RFC',RFC)])","75711ff6":"# Fitting\/Training model\nRFC_pipe.fit(X_train,y_train.ravel())","e3824f43":"# Predicting validation subset\ny_pred_RFC = RFC_pipe.predict(X_test)","62a9dd82":"# RFC Confusion matrix\nRFC_confusion = pd.DataFrame(confusion_matrix(y_test,y_pred_RFC),\n                  index=['Anti','Neutral','Pro','News'],\n                  columns=['Anti','Neutral','Pro','News'])","64d7232b":"# Classification report matrix\nprint(classification_report(y_test,y_pred_RFC))","660caf15":"# Selecting Parameter to tune\n\nn_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\nmax_features = ['auto', 'sqrt']\nmax_depth = [int(x) for x in np.linspace(10, 110, num=11)]\nmax_depth.append(None)\nmin_samples_split = [2, 5, 10]\nmin_samples_leaf = [1, 2, 4]\nbootstrap = [True, False]\nrandom_state = list(range(0,43))\n\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap,\n               'random_state':random_state}","e77215d1":"# Re-instantiate Random Classifier for tunning\nrfc = RandomForestClassifier()","078b13e9":"# Instantiate Random Search\nRFC_Random = RandomizedSearchCV(estimator=rfc, \n                               param_distributions=random_grid,\n                               n_iter=5, cv=5, verbose=2, random_state=42)","2653c4cb":"#vectorizer = TfidfVectorizer()\n#X_vec = vectorizer.fit_transform(X_train)","4dd9b061":"# Fitting Random Search on train subset\n#RFC_Random.fit(X_vec,y_train.ravel())","41fb7f3b":"# Retrieving parameters for the RFC model that performed best\n#RFC_Random.best_params_","39242bb2":"# Re-instiate RFC with best parameters\nrfc_boosted = RandomForestClassifier(random_state=8,\n                                     n_estimators=1800,\n                                     min_samples_split=2,\n                                     min_samples_leaf=1,\n                                     max_features='auto',\n                                     max_depth=60,\n                                     bootstrap=False)","3e6b4afc":"# Pipeline of RFC model with best parameters\nboosted_pipe = Pipeline([('vectorizer', TfidfVectorizer()),('RFC',rfc_boosted)])","4629c6d8":"# Fitting\/Training model\nboosted_pipe.fit(X_train,y_train.ravel())","067ad9fd":"# Predicting validation subset\ny_pred_boost = boosted_pipe.predict(X_test)","b6a7968a":"# RFC random search confusion matrix\nRFC_RS_confusion = pd.DataFrame(confusion_matrix(y_test,y_pred_boost),\n                  index=['Anti','Neutral','Pro','News'],\n                  columns=['Anti','Neutral','Pro','News'])\nRFC_RS_confusion","04838026":"# Classification report matrix\nprint(classification_report(y_test,y_pred_boost))","86cc4dcc":"y_boost = boosted_pipe.predict(test.message)","98beb1fb":"y_boost","79ce1fd2":"# Predictions in submission kaggle format\nRFC_RS_submission1 = pd.DataFrame({'tweetid': test.index, \n                           'sentiment': y_boost})\n\nRFC_RS_submission1 ","2e71f43d":"# Saving to .csv file\nRFC_RS_submission1.to_csv('RandomForest_boosted_01.csv',index = False)","eff8337b":"model_save_path = 'RandomForest_boosted_01.pkl'\nwith open(model_save_path,'wb') as file:\n    pickle.dump(boosted_pipe,file)","cd0f7602":"experiment.end()\n\nexperiment.display()","ceb7016a":"How i structured this is to give a step by step of how i built\nthe model that the highest f1 score we have on kaggle and also \nincludes an example of hyperparameter tuning.","a1149b31":"#### Accessing RFC accuracy","620917b4":"## Model Building","7dc1d1d2":"#### Training Random forest Classifier","e428da3f":"#### Predictions on test dataset  using LinearSVC","21cb118b":"#### Predictions on test dataset  using RFC_RS","f1e46c77":"#### Save Model","ad69c0f4":"This notebook contains Randomized Grid Search so Please run this notebook cell by cell as to avoid having to wait a long time for outputs feel free to share changes\/improvements.","89f4cefe":"## Exploditory Data Analysis","b32720bc":"___","eb61adfb":"Different `sentiment` classes types and their corrisponding descriptions","68afa319":"### Random forest Classifier","2872d8a7":"The important metric to note is the f1-score (macro avg) since its the\nmetric used on kaggle for scoring. The score obtained on the notebook will\nnot be the same as the one you will obtain on kaggle, the kaggle score\nwill usually be higher.The score on the notebook is helpful on gauging \nyour margins and comparing different models on the notebook.","a2e1bc93":"#### Save Model","cc0e5bbd":"From this we observe that the classses are unbalnced and we also observe that the Pro Class has the highest count and is about 2x the second highest class. We expect that this this class will be the most correctly classified out of all other classes.","6434a75c":"#### Save Model","acf245aa":"#### Training LinearSVC","c1f3513b":"#### Training KNN Classifier","3715d96f":"<img src=\"class_description.png\">","1b716f42":"Before we do Random Search on the RFC model we need to vectorize our Predictor variable since we are doing a randomized grid search on the RFC model and not on it's pipeline, although it is possible to do a randomised grid search on the pipeline.","71a61ce4":"**Both the train and test datasets are clean and ready for modelling** ","f49168dc":"#### Hyperparameter Tunning for RFC","d55f60c1":"### Linear Support Vector Classifier","7617bf57":"# Kaggle Classification Challenge","a6c16910":"### Library Imports for model building","bcddb4a0":"#### Accessing KNN accuracy","88089cb0":"The reason for it takes this particuler Random Search takes so much time is the number of parameters we are tunning and also it runs `n_iter` by `cv` models. Hyperparameter tuning for some other models might much less time to run.","00528b0b":"#### Predictions on test dataset using KNN","675ea4cd":"### K-Nearest Neighbors Classifier","3de186d2":"#### Accessing LinearSVC Acurracy"}}