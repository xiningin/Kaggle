{"cell_type":{"b1a6cfb8":"code","e14a8d37":"code","954952b8":"code","0c75bcd5":"code","3b8c7808":"code","a86ab40b":"code","d4a98fe9":"code","d39ee037":"code","93d4dcc4":"code","e86a6d2d":"code","cc35322e":"code","1a25c45a":"code","59cbe0f4":"markdown","ae083ffa":"markdown","69526cdc":"markdown","7d7036cc":"markdown","079bc84d":"markdown","f389e31d":"markdown","ca7e64ef":"markdown","79035f79":"markdown","b377adad":"markdown"},"source":{"b1a6cfb8":"import numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nphysical_devices = tf.config.list_physical_devices('GPU') \ntf.config.experimental.set_memory_growth(physical_devices[0], True)\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score\n","e14a8d37":"import os\nflowers_directory = \"..\/input\/flowers-recognition\/flowers\"\nclasses = os.listdir(flowers_directory)\nclasses","954952b8":"image_size = (128, 128)\nbatch_size = 32\n\n# https:\/\/keras.io\/api\/preprocessing\/image\/#image_dataset_from_directory-function\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    flowers_directory,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n    label_mode=\"categorical\",\n    class_names=classes\n)\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    flowers_directory,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n    label_mode=\"categorical\",\n    class_names=classes\n)","0c75bcd5":"plt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(classes[np.argmax(labels[i])])\n        plt.axis(\"off\")","3b8c7808":"data_augmentation = keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n        layers.experimental.preprocessing.RandomRotation(0.5),\n    ]\n)","a86ab40b":"plt.figure(figsize=(10, 10))\nfor images, _ in train_ds.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","d4a98fe9":"def make_model(input_shape, num_classes):\n    \n    inputs = keras.Input(shape=input_shape)\n\n    # Image augmentation block\n    x = data_augmentation(inputs)\n\n    x = layers.experimental.preprocessing.Rescaling(1.0 \/ 255)(x)\n    \n    x = layers.Flatten()(x)\n    x = layers.Dense(700, activation=\"sigmoid\")(x)\n    x = layers.Dense(500, activation=\"sigmoid\")(x)\n    x = layers.Dense(100, activation=\"sigmoid\")(x)\n\n    if num_classes == 2:\n        activation = \"sigmoid\"\n        units = 1\n    else:\n        activation = \"softmax\"\n        units = num_classes\n\n    outputs = layers.Dense(units, activation=activation)(x)\n    \n    return keras.Model(inputs, outputs)\n\n\nmodel = make_model(input_shape=image_size + (3,), num_classes=len(classes))\nmodel.summary()","d39ee037":"epochs = 40\n\n# https:\/\/keras.io\/api\/callbacks\/\n\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n]\n\nmodel.compile(\n    optimizer=\"RMSprop\",\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"],\n)\n\nhistory = model.fit(train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,)\n","93d4dcc4":"model_json = model.to_json()\n\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n    \nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")","e86a6d2d":"from tensorflow.keras.models import model_from_json\n\n# load json and create model\njson_file = open('model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n\n# load weights into new model\nloaded_model.load_weights(\"model.h5\")\nprint(\"Loaded model from disk\")","cc35322e":"plt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        \n        pred = loaded_model.predict(np.array([images[i].numpy().astype(\"uint8\")]))\n        \n        plt.title(classes[np.argmax(pred)])\n        plt.axis(\"off\")","1a25c45a":"fig = make_subplots(rows=1, cols=2)\n\nfig.add_trace(go.Scatter(\n    y=history.history['loss'],\n    mode='lines+markers',\n    name='training loss'\n), row=1, col=1)\n\nfig.add_trace(go.Scatter(\n    y=history.history['val_loss'],\n    mode='lines+markers',\n    name='validation loss'\n), row=1, col=1)\n\n\nfig.add_trace(go.Scatter(\n    y=history.history['accuracy'],\n    mode='lines+markers',\n    name='training accuracy'\n), row=1, col=2)\n\nfig.add_trace(go.Scatter(\n    y=history.history['val_accuracy'],\n    mode='lines+markers',\n    name='validation accuracy'\n), row=1, col=2)\n\nfig.update_xaxes(title_text='Epoch')\n\nfig.update_layout(\n    title_text=\"Training History Metrics\",\n    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"right\", x=1)\n)\n\nfig.show()\n","59cbe0f4":"### Vizualizate the data","ae083ffa":"### Load the model","69526cdc":"### definicion del modelo","7d7036cc":"### Save the model","079bc84d":"### Train the model\n","f389e31d":"### Data Augmentation","ca7e64ef":"### List Dir","79035f79":"### Validate score","b377adad":"### Import"}}