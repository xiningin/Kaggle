{"cell_type":{"dc23622b":"code","4c852142":"code","b3b926f9":"code","7cda9c3d":"code","2af40686":"code","e69d5e9c":"code","cb84c8bd":"code","fbc988d6":"code","d827f39c":"code","9984d5a0":"code","80ee160a":"code","20eae483":"code","7a2372eb":"code","ca5ba66d":"code","9574dea2":"code","b20562a3":"code","c2265698":"code","02d7e79f":"code","b8d81586":"code","4733384d":"code","77964074":"code","939f4901":"code","eaba1d0c":"code","e65ad762":"code","49c1cdad":"code","1eb15092":"code","96208ac9":"code","dc2bd495":"code","11164e58":"code","c10a3b77":"code","ff7d6288":"code","85195301":"code","53c7a58e":"code","58503da9":"code","c019d2f2":"code","a39aa765":"markdown","4c6b6bbe":"markdown","ab6187b0":"markdown","765f0c2f":"markdown"},"source":{"dc23622b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4c852142":"!git clone https:\/\/github.com\/AmanPriyanshu\/vggish.git","b3b926f9":"!ls","7cda9c3d":"!cp -r .\/vggish\/* .","2af40686":"!ls","e69d5e9c":"from scipy.io.wavfile import write\nimport librosa\nimport os\nfrom tqdm import tqdm","cb84c8bd":"def get_noise_from_sound(signal,noise,SNR):\n    RMS_s=np.sqrt(np.mean(signal**2))\n    #required RMS of noise\n    RMS_n=np.sqrt(RMS_s**2\/(pow(10,SNR\/10)))\n    \n    #current RMS of noise\n    RMS_n_current=np.sqrt(np.mean(noise**2))\n    noise=noise*(RMS_n\/RMS_n_current)\n    \n    return noise","fbc988d6":"train_path = '\/kaggle\/input\/enigma-techtatva-2020\/Dr Sheldon Cooper\/Dr Sheldon Cooper\/Train\/'","d827f39c":"def check_length(noise, signal):\n    if(len(noise)>len(signal)):\n        noise=noise[0:len(signal)]\n        return noise\n    if(len(noise)==len(signal)):\n        return noise\n    else:\n        noise = np.concatenate((noise, noise))\n        return check_length(noise, signal)","9984d5a0":"def convert(signal_file, location):\n\n    signal, sr = librosa.load(signal_file)\n    signal=np.interp(signal, (signal.min(), signal.max()), (-1, 1))\n\n    noise_file='.\/noise.wav'\n    noise, sr = librosa.load(noise_file)\n    noise=np.interp(noise, (noise.min(), noise.max()), (-1, 1))\n    \n    if(len(noise)>len(signal)):\n        noise=noise[0:len(signal)]\n\n    #noise = check_length(noise, signal)\n    \n    noise=get_noise_from_sound(signal,noise,SNR=10)\n    if(len(signal) > len(noise)):\n        signal_noise = signal + np.concatenate((noise, np.zeros(len(signal) - len(noise))))\n    else:\n        signal_noise=signal+noise\n    write(location,sr,signal_noise)","80ee160a":"!rm -r train","20eae483":"!ls","7a2372eb":"classes = os.listdir(train_path)\nos.system('mkdir .\/train\/')\nfor c in classes:\n    os.system('mkdir .\/train\/'+c+'\/')\n    files = os.listdir(train_path+c+'\/')\n    for f in tqdm(files):\n        convert(train_path+c+'\/'+f, '.\/train\/'+c+'\/'+f)","ca5ba66d":"!ls .\/train\/angry\/","9574dea2":"from vggish_loader import loading_dataset, properties_of_dataset, loading_wav","b20562a3":"sr, wav_length = properties_of_dataset('.\/train\/')","c2265698":"print('Average SR:', sum(sr)\/len(sr))\nprint('Average WAV Length', sum(wav_length)\/len(wav_length), '\\n')\n\nprint('Lowest SR', min(sr))\nprint('Lowest WAV Length', min(wav_length), '\\n')\n\nprint('Highest SR', max(sr))\nprint('Highest WAV Length', max(wav_length))\n\nprint('Appropriate Steps would be SR * seg_len (Eg: seg_len=5):', 5*sum(sr)\/len(sr))","02d7e79f":"dataset_x, dataset_y, label_map = loading_dataset('.\/train\/', 110000)","b8d81586":"indexes = np.arange(dataset_y.shape[0]) \nnp.random.shuffle(indexes) \ndataset_x = dataset_x[indexes] \ndataset_y = dataset_y[indexes]","4733384d":"label_map","77964074":"actual_map = {\n    'disgust': 1,\n    'fear': 2,\n    'neutral': 3,\n    'angry': 4,\n    'sad': 5,\n    'happy': 6,\n    'surprise': 7\n}","939f4901":"import os\n\nfiles = os.listdir('\/kaggle\/input\/enigma-techtatva-2020\/Dr Sheldon Cooper\/Dr Sheldon Cooper\/Test\/')\nprint(files[:5])","eaba1d0c":"from tqdm import tqdm","e65ad762":"path = '\/kaggle\/input\/enigma-techtatva-2020\/Dr Sheldon Cooper\/Dr Sheldon Cooper\/Test\/'\ntest_names = []\ntest_values = []\nfor f in tqdm(sorted(files)):\n    try:\n        x_dash = loading_wav(path+f, 110000)\n    except:\n        continue\n    test_names.append(f)\n    test_values.append(x_dash)\ntest_values = np.array(test_values)","49c1cdad":"test_ready = []\nfor t in test_values:\n    for i in t:\n        test_ready.append(i[0])\ntest_ready = np.array(test_ready)","1eb15092":"dataset_x.shape","96208ac9":"test_ready.shape","dc2bd495":"!ls","11164e58":"from vggish import VGGish","c10a3b77":"model = VGGish(load_weights=True, weights='audioset', input_tensor=None, input_shape=None, out_dim=None, include_top=False, pooling='avg')","ff7d6288":"x = model.predict(dataset_x, verbose=True)","85195301":"x_test = model.predict(test_ready, verbose=True)","53c7a58e":"labels = []\n\nfor j in tqdm(x_test):\n    values = []\n    for i in x:\n        values.append(np.mean(np.abs(j - i)))\n    values = np.array(values)\n    indexes = np.argsort(values)\n    y = dataset_y[indexes]\n    values = values[indexes]\n    \n    classes = [0 for _ in range(7)]\n    for index, i in enumerate(y[:5]):\n        classes[i] += 1\/(index+1)\n    classes = np.array(classes)\n    labels.append(np.argmax(classes))\n    \nlabels = np.array([actual_map[label_map[i]] for i in labels])","58503da9":"names = np.array([int(i[:-4]) for i in test_names])\nindexes = np.argsort(names)\nnames = names[indexes]\nlabels = labels[indexes]","c019d2f2":"sub = pd.DataFrame({'Id':['audio'+str(i) for i in names], 'Label':labels})\nsub.to_csv('Submission_noisy.csv', index=False)","a39aa765":"## Adding Noise:","4c6b6bbe":"## TESTING:","ab6187b0":"## SHUFFLING:","765f0c2f":"## Loading Dataset:"}}