{"cell_type":{"f305937a":"code","7c04532a":"code","5006b3eb":"code","98e8a697":"code","1cebf6bb":"code","b221d752":"code","820d46a8":"code","0491bc9d":"code","73712735":"code","bd1863bf":"code","0b196245":"code","aaaa324d":"code","98da6648":"code","5c7eca37":"code","7fdc2613":"code","282224e3":"code","7af9c401":"code","064d1e70":"code","53cd4264":"code","bd2bfb23":"code","7813d040":"code","0e500a81":"code","a99d7610":"code","25dc36a6":"code","585a1bba":"code","a54a34fd":"code","a97f6ea3":"code","c99c66c5":"code","c5adada8":"code","338a6175":"code","d04fcf49":"markdown","4c3bba6b":"markdown","2879b7b7":"markdown","47c3d42a":"markdown","b2c505d5":"markdown","2b2621d1":"markdown","fd4fc714":"markdown","6514cd0a":"markdown","428fa89d":"markdown","9bccbb94":"markdown","edd6fb3f":"markdown","63ca17aa":"markdown","dff3160b":"markdown","fcb80130":"markdown","34aa07cc":"markdown","6e516e8c":"markdown","61b10acf":"markdown","3877cdc1":"markdown","2eb82303":"markdown","f9955836":"markdown","2503ae1a":"markdown","172a863f":"markdown","57c35174":"markdown","4eb05498":"markdown","10f499e3":"markdown","f0ca0253":"markdown","27e46a9a":"markdown","cda9380f":"markdown","49d2fcc6":"markdown","30f5075a":"markdown","e8b85694":"markdown"},"source":{"f305937a":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","7c04532a":"from IPython.display import HTML\nHTML('<iframe width=\"1280\" height=\"720\" src=\"https:\/\/www.youtube.com\/embed\/McsTWXeURhA\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>')","5006b3eb":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport time\n\npd.set_option('display.max_colwidth', -1)","98e8a697":"import os\nprint(os.listdir(\"..\/input\/sec-edgar-companies-list\/\"))","1cebf6bb":"root = '..\/input\/sec-edgar-companies-list\/'\n\ndata = pd.read_csv(root + 'sec__edgar_company_info.csv',encoding='latin')\n","b221d752":"print('Size of data ',data.shape)","820d46a8":"data.head()","0491bc9d":"data.select_dtypes('object').apply(pd.Series.nunique, axis=0)","73712735":"!pip install fuzzywuzzy\nfrom fuzzywuzzy import fuzz\nfrom fuzzywuzzy import process","bd1863bf":"data.tail()","0b196245":"fuzz.ratio('ZZ GLOBAL LLC', 'ZZLL INFORMATION TECHNOLOGY, INC')","aaaa324d":"fuzz.ratio('ZZ GLOBAL LLC', 'ZZX, LLC')","98da6648":"fuzz.partial_ratio('ZZ GLOBAL LLC', 'ZZLL INFORMATION TECHNOLOGY, INC')","5c7eca37":"fuzz.partial_ratio('ZZ GLOBAL LLC', 'ZZX, LLC')","7fdc2613":"fuzz.token_sort_ratio('ZZ GLOBAL LLC', 'ZZLL INFORMATION TECHNOLOGY, INC')","282224e3":"fuzz.token_sort_ratio('ZZ GLOBAL LLC', 'ZZX, LLC')","7af9c401":"fuzz.token_set_ratio('ZZ GLOBAL LLC', 'ZZLL INFORMATION TECHNOLOGY, INC')","064d1e70":"fuzz.token_set_ratio('ZZ GLOBAL LLC', 'ZZX, LLC')","53cd4264":"!pip install ftfy # amazing text cleaning for decode issues..","bd2bfb23":"import re\nfrom ftfy import fix_text\n\ndef ngrams(string, n=3):\n    string = fix_text(string) # fix text\n    string = string.encode(\"ascii\", errors=\"ignore\").decode() #remove non ascii chars\n    string = string.lower()\n    chars_to_remove = [\")\",\"(\",\".\",\"|\",\"[\",\"]\",\"{\",\"}\",\"'\"]\n    rx = '[' + re.escape(''.join(chars_to_remove)) + ']'\n    string = re.sub(rx, '', string)\n    string = string.replace('&', 'and')\n    string = string.replace(',', ' ')\n    string = string.replace('-', ' ')\n    string = string.title() # normalise case - capital at start of each word\n    string = re.sub(' +',' ',string).strip() # get rid of multiple spaces and replace with a single\n    string = ' '+ string +' ' # pad names for ngrams...\n    string = re.sub(r'[,-.\/]|\\sBD',r'', string)\n    ngrams = zip(*[string[i:] for i in range(n)])\n    return [''.join(ngram) for ngram in ngrams]","7813d040":"print('All 3-grams in \"McDonalds\":')\nngrams('McDonalds')","0e500a81":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ncompany_names = data['Company Name'].unique()\nvectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams)\ntf_idf_matrix = vectorizer.fit_transform(company_names)","a99d7610":"data.head()","25dc36a6":"print( tf_idf_matrix.shape, tf_idf_matrix[5] )\n# Check if this makes sense:\n\nngrams('#1 PAINTBALL CORP')","585a1bba":"t1 = time.time()\nprint(process.extractOne('Ministry of Justice', company_names[0:999])) #org names is our list of organization names\nt = time.time()-t1\nprint(\"SELFTIMED:\", t)\nprint(\"Estimated hours to complete for 1000 rows of  dataset:\", (t*len(company_names[0:999]))\/60\/60)","a54a34fd":"##################\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nroot2 = '..\/input\/gov-names\/'\nclean_org_names = pd.read_excel(root2 + 'Gov Orgs ONS.xlsx')\nclean_org_names = clean_org_names.iloc[:, 0:6]\n","a97f6ea3":"\norg_name_clean = clean_org_names['Institutions'].unique()\n\nprint('Vecorizing the data - this could take a few minutes for large datasets...')\nvectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams, lowercase=False)\ntfidf = vectorizer.fit_transform(org_name_clean)\nprint('Vecorizing completed...')\n\nfrom sklearn.neighbors import NearestNeighbors\nnbrs = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(tfidf)\n\norg_column = 'Company Name' #column to match against in the messy data\nunique_org = set(data[org_column].values) # set used for increased performance\n","c99c66c5":"###matching query:\ndef getNearestN(query):\n    queryTFIDF_ = vectorizer.transform(query)\n    distances, indices = nbrs.kneighbors(queryTFIDF_)\n    return distances, indices\n\nimport time\nt1 = time.time()\nprint('getting nearest n...')\ndistances, indices = getNearestN(unique_org)\nt = time.time()-t1\nprint(\"COMPLETED IN:\", t)\n\nunique_org = list(unique_org) #need to convert back to a list\nprint('finding matches...')\nmatches = []\nfor i,j in enumerate(indices):\n    temp = [round(distances[i][0],2), clean_org_names.values[j][0][0],unique_org[i]]\n    matches.append(temp)\n\nprint('Building data frame...')  \nmatches = pd.DataFrame(matches, columns=['Match confidence (lower is better)','Matched name','Origional name'])\nprint('Done') ","c5adada8":"matches.head(10)","338a6175":"matches.sort_values('Match confidence (lower is better)')","d04fcf49":"### N-Grams  & De-Duplication\n\nWhile the terms in **TF-IDF** are usually words, this is not a necessity. In our case using words as terms wouldn\u2019t help us much, as most company names only contain one or two words. This is why we will use n-grams: sequences of N contiguous items, in this case characters. The following function cleans a string and generates all n-grams in this string:","4c3bba6b":"**token_set_ratio** , ignores duplicated words. It is similar with token sort ratio, but a little bit more flexible.","2879b7b7":"\nData in the real world is messy. Dealing with messy data sets is painful and burns through time which could be spent analysing the data itself.\n\n![https:\/\/www.acronis.com\/en-us\/articles\/deduplication\/](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcTc_jlg2hrSRYqdenJdv7p_4Xo6Uj-qqCPpx4ANHI2hNkA8TJQPJQ&s)\n\n- **Deduplication**. Aligning similar categories or entities in a data set (for example, we may need to combine \u2018D J Trump\u2019, \u2018D. Trump\u2019 and \u2018Donald Trump\u2019 into the same entity).\n- **Record Linkage**. Joining data sets on a particular entity (for example, joining records of \u2018D J Trump\u2019 to a URL of his Wikipedia page)\n","47c3d42a":"# In summary, tf-idf can be a highly effective and highly performant way of cleaning, deduping and matching data when dealing with larger record counts.","b2c505d5":"# Final","2b2621d1":"> The code to generate the matrix of TF-IDF values for each is shown below.","fd4fc714":"## Glimpse of Data","6514cd0a":"**References**\n\nhttp:\/\/towardsdatascience.com\/natural-language-processing-for-fuzzy-string-matching-with-python-6632b7824c49,\n\nhttps:\/\/towardsdatascience.com\/fuzzy-matching-at-scale-84f2bfd0c536,\n\nhttps:\/\/bergvca.github.io\/2017\/10\/14\/super-fast-string-matching.html?source=post_page-----84f2bfd0c536---------------------- ","428fa89d":"As can be shown in the code below, the only difference in this approach is to transform the messy data set using the tdif matrix which has been learned on the clean data set.\n\nThe **\u2018getNearestN\u2019** then uses Scikit\u2019s implementation of K Nearest Neighbours to find the closest matches in the dataset:","9bccbb94":"> The last term (**\u2018ORP\u2019**) has a relatively low value, **0.22892**, which makes sense as this term will appear often in the corpus, thus receiving a lower IDF weight.","edd6fb3f":"![](https:\/\/miro.medium.com\/max\/1014\/1*k45HFixH1Q-qxxH1i2rsxQ.png)","63ca17aa":"#### Important Talk by: presented at PyBay2018 \n","dff3160b":"# This notebook shows how to use TD IDF, FUZZY to both dedupe and match records at scale besides K Nearest Neighbour algorithm as an alternative closeness measure ","fcb80130":"**token_sort_ratio** , ignores word order.","34aa07cc":"- We are still using the same data pairs.","6e516e8c":"## Record linkage and a different approach\n> In the below section we will see how this is achieved and also use the K Nearest Neighbour algorithm as an alternative closeness measure.\nThe dataset we would like to join on is a set of \u2018clean\u2019 organization names created by the Office for National Statistics (ONS):","61b10acf":"# Deduplication & Record Linkage. ","3877cdc1":"# Import libs","2eb82303":"### Finding close matches through getNearestN","f9955836":"**TF-IDF** is a method to generate features from text by multiplying the frequency of a term (usually a word) in a document (the Term Frequency, or TF) by the importance (the Inverse Document Frequency or IDF) of the same term in an entire corpus. This last term weights less important words (e.g. the, it, and etc) down, and words that don\u2019t occur frequently up. IDF is calculated as:\n\n\n\n<html>\n<body>\n\n<p><font size=\"4\" color=\"Purple\">IDF(t) = log_e(Total number of documents \/ Number of documents with term t in it) \n\n<\/body>\n<\/html>","2503ae1a":"This is telling us that the 'ZZ GLOBAL LLC' and 'ZZX, LLC' pair are about **57%** the same.","172a863f":"This is telling us that the 'ZZ GLOBAL LLC' and 'ZZLL INFORMATION TECHNOLOGY, INC' pair are about **36%** the same.","57c35174":"## Read in Data","4eb05498":"**ratio** , compares the entire string similarity, in order.","10f499e3":"## FuzzyWuzzy\n\nIn computer science, fuzzy string matching is the technique of finding strings that match a pattern approximately (rather than exactly). In another word, fuzzy string matching is a type of search that will find matches even when users misspell words or enter only partial words for the search. It is also known as approximate string matching.\n\n\n- Fuzzywuzzy is a Python library uses **Levenshtein Distance** to calculate the differences between sequences in a simple-to-use package.\n- Instalation: !pip install fuzzywuzzy, import: from fuzzywuzzy import fuzz, from fuzzywuzzy import process\n","f0ca0253":"The resulting matrix is very sparse as most terms in the corpus will not appear in most company names. Scikit-learn deals with this nicely by returning a sparse CSR matrix.\n\nYou can see the first row (**\u201c!J INC\u201d**) contains three terms for the columns 11, 16196, and 15541.","27e46a9a":"\n<html>\n<body>\n\n<p><font size=\"5\" color=\"Red\">If you like my kernel please consider upvoting it<\/font><\/p>\n<p><font size=\"4\" color=\"Green\">Don't hesitate to give your suggestions in the comment section<\/font><\/p>\n\n<\/body>\n<\/html>\n","cda9380f":"\n**Record Deduplication**, or more generally, Record Linkage is the task of finding which records refer to the same entity, like a person or a company. It's used mainly when there isn't a unique identifier in records like Social Security Number for US citizens\n[Dedupe.io](https:\/\/dedupe.io)","49d2fcc6":"## TF-IDF & N-Grams","30f5075a":"\n<html>\n<body>\n\n<p><font size=\"5\" color=\"Purple\">If you find this kernel useful or interesting, please don't forget to upvote the kernel =)\n\n<\/body>\n<\/html>\n\n","e8b85694":"**partial_ratio** , compares partial string similarity."}}