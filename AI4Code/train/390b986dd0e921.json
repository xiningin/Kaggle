{"cell_type":{"8b5b74e0":"code","3754ed61":"code","b1784d06":"code","404951bc":"code","6e1ac82c":"code","15c052be":"code","e0e42fdb":"code","9423e929":"code","917135a2":"code","47a1a47f":"code","db562a5a":"code","b07be089":"code","608d37c5":"code","1dcb4a73":"code","bfb154a6":"code","c0d98d3d":"code","fb110c78":"code","fa0cbe42":"code","61027f19":"code","5f847aa2":"code","36bf2eb3":"code","c761ef58":"code","8ac38322":"code","a4a6bf22":"code","bb57cdc4":"code","f03a35d2":"code","556d83f7":"code","504299b9":"code","21ab6534":"code","0552eafb":"code","be6fdc76":"code","f35cd05f":"code","18684300":"code","1ed0b7c7":"code","6e6f68f4":"code","963aaa0d":"code","0685e74a":"code","089badb7":"code","3e86b048":"code","2cdf6e82":"code","a839bb0c":"markdown","dd077508":"markdown","c1c236c3":"markdown","7c48516c":"markdown","af21c6db":"markdown","32d2bfa9":"markdown","d7d0aac4":"markdown","45479e21":"markdown","d5f0207f":"markdown","d11a3e6d":"markdown","f886a1eb":"markdown","f5df1eba":"markdown","08ced2d5":"markdown","9c599d86":"markdown","066fca8d":"markdown","563c8a4d":"markdown","e95799b0":"markdown","dd640d10":"markdown"},"source":{"8b5b74e0":"from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom tensorflow.keras.models import Sequential\nimport numpy as np\nfrom glob import glob\n","3754ed61":"# re-size all the images to this\nIMAGE_SIZE = [224, 224]\n\ntrain_path = '..\/input\/cotton-disease-dataset\/Cotton Disease\/train'\nvalid_path = '..\/input\/cotton-disease-dataset\/Cotton Disease\/test'","b1784d06":"# Import the Vgg 16 library as shown below and add preprocessing layer to the front of VGG\n# Here we will be using imagenet weights\n\nvgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n\n","404951bc":"# don't train existing weights\nfor layer in vgg16.layers:\n    layer.trainable = False","6e1ac82c":"# useful for getting number of output classes\nfolders = glob('..\/input\/cotton-disease-dataset\/Cotton Disease\/train\/*')","15c052be":"# our layers - you can add more if you want\nx = Flatten()(vgg16.output)","e0e42fdb":"prediction = Dense(len(folders), activation='softmax')(x)\n\n# create a model object\nmodel = Model(inputs=vgg16.input, outputs=prediction)","9423e929":"# view the structure of the model\nmodel.summary()","917135a2":"# tell the model what cost and optimization method to use\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","47a1a47f":"# Use the Image Data Generator to import the images from the dataset\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)","db562a5a":"# Make sure you provide the same target size as initialied for the image size\ntraining_set = train_datagen.flow_from_directory('..\/input\/cotton-disease-dataset\/Cotton Disease\/train',\n                                                 target_size = (224, 224),\n                                                 batch_size = 32,\n                                                 class_mode = 'categorical')","b07be089":"test_set = test_datagen.flow_from_directory('..\/input\/cotton-disease-dataset\/Cotton Disease\/test',\n                                            target_size = (224, 224),\n                                            batch_size = 32,\n                                            class_mode = 'categorical')","608d37c5":"# fit the model\n# Run the cell. It will take some time to execute\nr = model.fit_generator(\n  training_set,\n  validation_data=test_set,\n  epochs=4,\n  steps_per_epoch=len(training_set),\n  validation_steps=len(test_set)\n)","1dcb4a73":"import numpy as np\nfrom tensorflow.keras.preprocessing import image\ntest_image = image.load_img('..\/input\/cotton-disease-dataset\/Cotton Disease\/test\/fresh cotton leaf\/d (7)_iaip.jpg', target_size = (224,224))\ntest_image = image.img_to_array(test_image)\ntest_image=test_image\/255\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = model.predict(test_image)","bfb154a6":"# plot the loss\nimport matplotlib.pyplot as plt\nplt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\nplt.savefig('LossVal_loss')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()\nplt.savefig('AccVal_acc')","c0d98d3d":"result","fb110c78":"a= np.argmax(model.predict(test_image),axis=1)","fa0cbe42":"a","61027f19":"from tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input","5f847aa2":"# re-size all the images to this\nIMAGE_SIZE = [224, 224]\n\ntrain_path1 = '..\/input\/cotton-disease-dataset\/Cotton Disease\/train'\nvalid_path1 = '..\/input\/cotton-disease-dataset\/Cotton Disease\/test'","36bf2eb3":"ResNet50 = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)","c761ef58":"# don't train existing weights\nfor layer in ResNet50.layers:\n    layer.trainable = False","8ac38322":"# useful for getting number of output classes\nfolders1 = glob('..\/input\/cotton-disease-dataset\/Cotton Disease\/train\/*')","a4a6bf22":"# our layers - you can add more if you want\nx1 = Flatten()(ResNet50.output)","bb57cdc4":"prediction1 = Dense(len(folders1), activation='softmax')(x1)\n\n# create a model object\nmodel1 = Model(inputs=ResNet50.input, outputs=prediction1)","f03a35d2":"# view the structure of the model\nmodel1.summary()","556d83f7":"# tell the model what cost and optimization method to use\nmodel1.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","504299b9":"# Use the Image Data Generator to import the images from the dataset\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen1 = ImageDataGenerator(rescale = 1.\/255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen1 = ImageDataGenerator(rescale = 1.\/255)","21ab6534":"# Make sure you provide the same target size as initialied for the image size\ntraining_set = train_datagen1.flow_from_directory('..\/input\/cotton-disease-dataset\/Cotton Disease\/train',\n                                                 target_size = (224, 224),\n                                                 batch_size = 32,\n                                                 class_mode = 'categorical')","0552eafb":"test_set = test_datagen1.flow_from_directory('..\/input\/cotton-disease-dataset\/Cotton Disease\/test',\n                                            target_size = (224, 224),\n                                            batch_size = 32,\n                                            class_mode = 'categorical')","be6fdc76":"# fit the model\n# Run the cell. It will take some time to execute\nd = model.fit_generator(\n  training_set,\n  validation_data=test_set,\n  epochs=4,\n  steps_per_epoch=len(training_set),\n  validation_steps=len(test_set)\n)","f35cd05f":"import numpy as np\nfrom tensorflow.keras.preprocessing import image\ntest_image = image.load_img('..\/input\/cotton-disease-dataset\/Cotton Disease\/test\/fresh cotton plant\/dsd (140)_iaip.jpg', target_size = (224,224))\ntest_image = image.img_to_array(test_image)\ntest_image=test_image\/255\ntest_image = np.expand_dims(test_image, axis = 0)\nresult1 = model1.predict(test_image)","18684300":"# plot the loss\nimport matplotlib.pyplot as plt\nplt.plot(r.history['loss'], label='train loss')\nplt.plot(r.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\nplt.savefig('LossVal_loss')\n\n# plot the accuracy\nplt.plot(r.history['accuracy'], label='train acc')\nplt.plot(r.history['val_accuracy'], label='val acc')\nplt.legend()\nplt.show()\nplt.savefig('AccVal_acc')","1ed0b7c7":"result1","6e6f68f4":"result1 = result1.ravel() ","963aaa0d":"result1=result1.tolist() ","0685e74a":"result1","089badb7":"a1= np.argmax(model1.predict(test_image),axis=1)","3e86b048":"a1","2cdf6e82":"classes=[\"diseased_leaf\",\"diseased_plant\",\"fresh_leaf\",\"fresh_plant\"]\nmax =result1[0];\ni = 0;    \n     \n#Loop through the array    \nfor index, value in enumerate(result1):    \n    #Compare elements of array with max    \n    if(value > max):    \n        max = value;    \n        i = index   \nprint(\"Largest element present in given array: \" + str(max) +\" And it belongs to \" +str(classes[i]) +\" class.\");","a839bb0c":"### Libraries","dd077508":"### Conclusion","c1c236c3":"### Training The ResNet 50","7c48516c":"### Summary","af21c6db":"### Building the VGG16\n","32d2bfa9":"### Testing\n","d7d0aac4":"### Libraries","45479e21":"\n### Summary\n","d5f0207f":"## Table of Content\n\n### Training VGG 16 Model \n1. Libraries\n2. Training & DataLoader\n3. Building the VGG16\n4. Summary\n5. Training The VGG16\n6. Testing\n7. Conclusion\n\n### Training ResNet50 Model \n1. Libraries\n2. Training & DataLoader\n3. Building the VGG16\n4. Summary\n5. Training The VGG16\n6. Testing\n7. Conclusion\n \n#### Final conclusion","d11a3e6d":"### Conclusion","f886a1eb":"### Building the ResNet 50","f5df1eba":"### Final conclusion","08ced2d5":"The sole purpose of this notebook is to predict wheather the image belongs to diseased class or not. In this dataset we have 4 classes diseased leaf , diseased plant , freash leaf and freash plant.In this notebook I will use transfer learning techniques like VGG16 and ResNet 50 and we'll check how our accuracy got affected with respect to these transfer learning models.","9c599d86":"### Training The VGG16\n","066fca8d":"### Training & DataLoader\n","563c8a4d":"We have tested our model for fresh_leaf and our model is able to classify the image properly. The reason I trained for 4 epochs is because of huge numbers of parameters of both of the model and even though we have option of TPU, It's taking lot of time to train. So here we just train for few epoch and the result is far better then my previous CNN algorithm and here is the link. Please go through it and compare it. Here is the link- https:\/\/www.kaggle.com\/anuragupadhyay6212\/cotton-disease-prediction-cnn-for-beginners?rvi=1 \n\n#### Please upvote this notebook if you find it useful.It really motivate to make new notebook.","e95799b0":"### Training & DataLoader\n","dd640d10":"### Testing\n"}}