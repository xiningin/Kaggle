{"cell_type":{"9354ffc1":"code","f4013d66":"code","0bde936d":"code","a6114bd3":"code","2783d2e1":"code","aa316198":"markdown","5c9f1f9b":"markdown","89533a75":"markdown","e1c668a6":"markdown","82951810":"markdown"},"source":{"9354ffc1":"# Essential libraries\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import load_iris\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\n\n\n# IPython libraries\n\nfrom ipywidgets import interactive\nfrom IPython.display import display\nimport ipywidgets as widgets\n","f4013d66":"# Lets load iris data\n\niris = load_iris()","0bde936d":"X = iris.data[:,[0,2]] # sepal and petal length\nY = iris.target  # Labels","a6114bd3":"# Lets train \n\ndef decision_tree(max_depth):\n\n    classifier = DecisionTreeClassifier(max_depth = max_depth)\n    classifier.fit(X,Y)\n    # Plotting the decision boundary\n\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n                         np.arange(y_min, y_max, 0.1))\n    Z = classifier.predict(np.c_[xx.ravel(),yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    plt.contourf(xx,yy,Z,alpha=0.4)\n    plt.scatter(X[:,0], X[:,1], c = Y, s = 20, edgecolor = 'k')\n    plt.xlabel(\"Sepal length (cm)\")\n    plt.ylabel(\"Petal length (cm)\")\n    plt.show()","2783d2e1":"style = {'description_width': 'initial'}\nm = interactive(decision_tree,max_depth=widgets.IntSlider(min=1,max=5,step=1,description= 'Max Depth',\n                                       stye=style,continuous_update=False))\n\n# Set the height of the control.children[-1] so that the output does not jump and flicker\noutput = m.children[-1]\noutput.layout.height = '350px'\n\n# Display the control\ndisplay(m)","aa316198":"### We will try to classify based on sepal and petal length","5c9f1f9b":"### Similarly, one can use different features to classify iris. \n\n### One important point to note from the above plot is that Decision trees love orthogonal decision boundaries i.e. all splits are perpendicular to an axis.","89533a75":"### In this notebook, we will use Decision Tree classifier to classify the three types of iris flowers based on the length of sepal and petal. We will also see how tuning the maximum depth of tree affects our classification\n\n#### Ref : https:\/\/scikit-learn.org\/stable\/auto_examples\/tree\/plot_iris_dtc.html#sphx-glr-auto-examples-tree-plot-iris-dtc-py","e1c668a6":"### In the next notebook, we will see how Decision tree classifier is not a good choice when the data is not linearly separable...","82951810":"### Iris dataset contains following attributes :\n\n###    1. sepal length in cm\n###   2. sepal width in cm\n###   3. petal length in cm\n###   4. petal width in cm\n###   5. class: \n###      -- Iris Setosa\n###      -- Iris Versicolour\n###      -- Iris Virginica"}}