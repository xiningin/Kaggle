{"cell_type":{"c81c26f7":"code","d1f40117":"code","59c9e952":"code","1c721ee6":"code","84b2975c":"code","c198f2c1":"code","c0322885":"code","22bca63f":"code","d861e913":"code","93e37369":"code","c3f5826b":"code","bd4123b0":"code","4a52f8b7":"code","205fd7c1":"code","32c73ce1":"code","969d3e4d":"code","c719de1d":"code","91f039c9":"code","d47ece7b":"code","4a438dda":"code","bb29b25b":"code","76db7d39":"code","2d47aa6a":"code","f2f361a9":"code","c866475f":"markdown","31e6801f":"markdown","f57909d1":"markdown","bd3c4297":"markdown","9f4f6d7d":"markdown","d1cb6128":"markdown","fac8dfb8":"markdown","13f276ba":"markdown","b43754a4":"markdown","e6807c3a":"markdown","9c7fcc89":"markdown","79b8fce4":"markdown","c75cfdd0":"markdown","2581dbad":"markdown","7c4ba1f1":"markdown","8594b64b":"markdown","8f5bd0bc":"markdown","3191599a":"markdown","6be541bb":"markdown","fbc8fee1":"markdown","b164aadc":"markdown","ce6fdee8":"markdown"},"source":{"c81c26f7":"# Import libraries\nimport os\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\n\n# Options\npd.set_option('display.max_columns', None)\npd.set_option('display.float_format', lambda x: '%.3f' % x)","d1f40117":"# Read in our data\ntrain = pd.read_csv('\/kaggle\/input\/movember-ml-training\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/movember-ml-training\/test.csv')","59c9e952":"train.head()","1c721ee6":"test.tail()","84b2975c":"# Combine all the data to make data preprocessing easier\nall_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],test.loc[:,'MSSubClass':'SaleCondition'])) # doesn't include SalePrice from train and Id from test","c198f2c1":"all_data.shape","c0322885":"# Take a log transformation of the sales price to reduce skewness\ny_train = np.log1p(train.SalePrice)","22bca63f":"# Select columns to keep\ncolumns_to_keep = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'YearBuilt']\n\n# Filter columns\nall_data = all_data[columns_to_keep]","d861e913":"all_data","93e37369":"# The higher the percentage, the more data that is missing\ntotal = all_data.isnull().sum().sort_values(ascending=False)\npercent = (all_data.isnull().sum()\/all_data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data","c3f5826b":"# Find all the unique values in the OverallQual column\nall_data.OverallQual.unique()","bd4123b0":"# Scores 1-3 are mapped to 1 (i.e. bad)\n# Scores 4-6 are mapped to 2 (i.e. average)\n# Scores 7-10 are mapped to 3 (i.e. good)\nall_data[\"SimplOverallQual\"] = all_data.OverallQual.replace({1 : 1, 2 : 1, 3 : 1, # bad\n                                                       4 : 2, 5 : 2, 6 : 2, # average\n                                                       7 : 3, 8 : 3, 9 : 3, 10 : 3 # good\n                                                      })","4a52f8b7":"all_data.head()","205fd7c1":"all_data[['GrLivArea', 'TotalBsmtSF']] = np.log1p(all_data[['GrLivArea', 'TotalBsmtSF']])","32c73ce1":"# Split back into our train and test sets\nX_train = all_data.iloc[:1022,:]\nX_test = all_data.iloc[1022:,:]","969d3e4d":"# Split our training data randomly into train and validation\nX_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size=0.33, random_state=42)","c719de1d":"# Fit the model on our training data\nreg = LinearRegression().fit(X_train, y_train)","91f039c9":"# Generate the predictions on our training and validation sets\ny_train_pred = reg.predict(X_train)\ny_validate_pred = reg.predict(X_validate)","d47ece7b":"# Convert back into USD\ny_train_pred_usd = np.expm1(y_train_pred)\ny_validate_pred_usd = np.expm1(y_validate_pred)\n\ny_train_usd = np.expm1(y_train)\ny_validate_usd = np.expm1(y_validate)","4a438dda":"# Print the RMSE for our training and validation predictions\nprint('RMSE train: ' + str(np.sqrt(mean_squared_error(y_train_usd, y_train_pred_usd))))\nprint('RMSE validate: ' + str(np.sqrt(mean_squared_error(y_validate_pred_usd, y_validate_usd))))","bb29b25b":"# Predict on the test data\ny_test_pred = reg.predict(X_test)\n\n# Convert back to USD\ny_test_pred_usd = np.expm1(y_test_pred)","76db7d39":"# We now create our submission file\nd = {'Id': np.arange(1,439), 'SalePrice': y_test_pred_usd}\nsubmission = pd.DataFrame(d)","2d47aa6a":"submission","f2f361a9":"# write to csv, ready for uploading\nsubmission.to_csv('submission.csv', index=False)","c866475f":"We can now calculate our RMSE scores.","31e6801f":"## Setup","f57909d1":"## 1. Data Preprocessing","bd3c4297":"We also used a log(1+x) transformation in our data processing. We need to convert this back into USD using the `np.expm1()` function.","9f4f6d7d":"### 1.3 Feature Engineering\nFeature engineering is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data. This [blog post](https:\/\/machinelearningmastery.com\/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it\/) has a great introduction to the topic.\n","d1cb6128":"### Notes on Data Processing\nWe've only scratched the surface of what is possible with data processing. You could dramatically improve the performance of your models with some relatively simple steps such as:\n* Standardisation and normalisation - more info [here](https:\/\/machinelearningmastery.com\/standardscaler-and-minmaxscaler-transforms-in-python\/)\n* Feature selection - more info [here](https:\/\/machinelearningmastery.com\/feature-selection-with-real-and-categorical-data\/)\n* Dealing with multicollinearity - more info [here](https:\/\/www.analyticsvidhya.com\/blog\/2020\/03\/what-is-multicollinearity\/)","fac8dfb8":"From our EDA we also saw that our dependent variable, the SalePrice, is right skewed. Therefore, to meet the assumptions of MLR I want to take the log transformation to make the data more normally distributed.\n\nYou'll note I use `np.log1p()` which takes the natural logarithm of (1+x). This helps in the case where we may have zeroes in our data which would result in an error (i.e. the natural log of 0 is undefined).","13f276ba":"## 3. Prediction Submission\nWith our model trained, we can predict on our test data and prepare our submission for the competition.","b43754a4":"As a reminder, we use the following datasets for the following purposes:\n* train - building our model\n* validate - model selection (i.e. which of our models had the best performance so we can use to generate our test predictions)\n* test - competition submission\n\nAgain, I'm going to simplify this process. In practice, we often retrain our model on all our train\/validate data before running our predictions. We also use techniques like cross-validation (CV) which give a more realistic view on our how model will perform on the test data.","e6807c3a":"## 2. Modelling","9c7fcc89":"### 2.2 Evaluate the model\nWe now check the performance of the model on both our training and validation data. If our validation score is much worse than our training score then this is a sign our model is [overfit](https:\/\/www.ibm.com\/cloud\/learn\/overfitting#:~:text=Overfitting%20is%20a%20concept%20in,exactly%20against%20its%20training%20data.&text=When%20the%20model%20memorizes%20the,generalize%20well%20to%20new%20data.).\n\nAs a reminder, we use our validation score for model selection purposes. If you trial multiple models, it's likely best to pick the model that has the best validation score. \n\nWe will be using the root mean squared error ([RMSE](https:\/\/www.statisticshowto.com\/probability-and-statistics\/regression-analysis\/rmse-root-mean-square-error\/)) as the evaluation metric in this Kaggle competition.","79b8fce4":"### 1.5 Prepare our data for modelling\nBefore we start building our models, we want to do the following:\n* Split our data back into our train (building and validating our model) and test (predictions for the competition) sets\n* Create a validation set (for model selection)","c75cfdd0":"### 2.1 Train the model\nUsing the training data, let's fit the multiple linear regression (MLR) model.\n\nYou can find the documentation of the model using the wonderful scikit-learn library [here](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.LinearRegression.html).","2581dbad":"### 1.1 Select Relevant Columns\nWe have 79 columns of indepdent variables. While it's great to have plenty of descriptors, it can be problematic as we've already seen in our EDA that some of these columns contain mostly missing information or are not correlated to 'SalePrice'. \n\nAdditionally, too many predictors, relative to the number of data points can result in:\n* Collinearity\n* Confounding relationships, etc.\n\nTherefore, we are going to select only a handful of our most correlated columns indentified in our EDA.","7c4ba1f1":"## Where To Next?\nSo you've successfully submitted your first submission? Congratulations! You're 80% on the way to becoming a data scientist (and winning some prizes). \n\nGiven I'm sure you're all interested in winning this competition here are some tips that you can use to improve your models:\n* **Data processing**: have you controlled for outliers, missing values, multicollinearity, non-normal values, categorical vs. continuous variables\n* **Feature engineering**: have you used all the features in the data? What new features can you produce from these columns? Have you tried applying transformations (e.g. squared, cubed, etc.)?\n* **Algorithms**: there's so many algorithms to choose from but I recommend starting with regularised regression (LASSO, Ridge, ElasticNet), generalised linear models (exponential\/gamma), random forest, gradient boosting machine, support vector machines, etc.\n* **Process**: we've implemented a very basic train\/validate\/test split of the data, however, you could try cross-validation. You could also try hyperparameter tuning to work out the 'optimal' combination of hyperparameters\n\nIf none of the above makes sense, that's okay! Here are some great resources I recommend:\n* [Machine Learning Mastery](https:\/\/machinelearningmastery.com\/blog\/)\n* [Towards Data Science](https:\/\/towardsdatascience.com\/)\n* [Free Code Camp YouTube](https:\/\/www.youtube.com\/watch?v=pqNCD_5r0IU&ab_channel=freeCodeCamp.org)","8594b64b":"We're going to keep it simple in our example. We can see below that our 'OverallQual' has 10 levels of quality which seems excessive. Let's consolidate this down into 3 levels - good, average, and bad.","8f5bd0bc":"Our train and validate RMSE scores are similar so I don't think our model is overfit. We're off by ~35,000 USD for each prediction which isn't too bad! However, I think with some better data processing and some more advanced models, you could get below USD 10k.","3191599a":"## 0. Data Input","6be541bb":"### 1.4 Log Transform Our Continuous Dependent Variables\nWe've also seen from our EDA that 'GrLivArea' and 'TotalBsmtSF' are also not normally distributed. To improve the performance of our model, we will also take the natural logarithm (1+x) of these columns.","fbc8fee1":"# Multiple Linear Regression (MLR) Baseline Model Submission\n***","b164aadc":"We can see above our simplified quality score has been implemented. \n\nWhat other feature engineering can you do? Here are suggestions:\n* Simplify other variables - rather than YearBuilt, why not aggregate into decades?\n* Create new quality scores\n* Create higher order polynomials of variables, etc.","ce6fdee8":"### 1.2 Check for Missing Data\nWe repeat the same process as in our EDA on our selected columns. It looks like our data has no missing values so we don't have to do anything here.\n\nIf you do have missing data, I would recommend imputing with the median value (or some other relevant value). Check out this [article](https:\/\/vitalflux.com\/pandas-impute-missing-values-mean-median-mode\/) for more information."}}