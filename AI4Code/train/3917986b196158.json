{"cell_type":{"7db9b4bf":"code","22c63e09":"code","b9a1bcaa":"code","97a52b04":"code","f9ac7c38":"code","a67950db":"code","ba914809":"code","ba1a9c0a":"code","110e1159":"code","989cda5b":"code","6845497a":"code","c9c394f2":"code","2a9c82b9":"code","35370a33":"code","2c950f5f":"code","ad5ddf42":"markdown"},"source":{"7db9b4bf":"DATA_PATH = '..\/input\/novel-corona-virus-2019-dataset\/time_series_covid_19_deaths_US.csv'\n\nP = 2\nQ = 2\nTRAIN_SIZE = 0.8","22c63e09":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pandas.plotting import autocorrelation_plot\nfrom sklearn.linear_model import LinearRegression\n\nfrom statsmodels.tsa.stattools import adfuller\nfrom sklearn.metrics import mean_squared_error","b9a1bcaa":"df = pd.read_csv(DATA_PATH)","97a52b04":"df","f9ac7c38":"df.columns[112:235].values","a67950db":"raw_data = df.iloc[:, 112:235].sum().reset_index().rename(columns={'index': 'date', 0: 'value'})","ba914809":"fig, ax = plt.subplots(figsize=(12, 8))\nsns.lineplot(data=raw_data, x='date', y='value', ax=ax)\nfor ind, label in enumerate(ax.get_xticklabels()):\n    if ind % 10 == 0:  # every 10th label is kept\n        label.set_visible(True)\n    else:\n        label.set_visible(False)\nplt.xticks(rotation=15)\nplt.show()","ba1a9c0a":"raw_data.set_index('date', inplace=True)\nraw_data.dropna(inplace=True)","110e1159":"class ARIMA(object):\n    def __init__(self):\n        pass\n    \n    @staticmethod\n    def _regressor(df, n, val_col, out_pred_col, train_size=0.8):\n        _df = df.copy()\n\n        #Generating the lagged n terms\n        for i in range(1, n + 1):\n            _df[f'shifted_values_{i}'] = _df[val_col].shift(i)\n        _df.dropna(inplace=True)\n\n\n        _train_size = int(train_size * _df.shape[0])\n\n        #Breaking data set into test and training\n        _df_train = pd.DataFrame(_df[:_train_size])\n        _df_test = pd.DataFrame(_df[_train_size:])\n\n        #X contains the lagged values ,hence we skip the first column\n        X_train = _df_train.iloc[:, 1:].values.reshape(-1, n)\n        #Y contains the value, it is the first column\n        y_train = _df_train.iloc[:, 0].values.reshape(-1, 1)\n        \n        # We do the same thing with the test set\n        X_test = _df_test.iloc[:, 1:].values.reshape(-1, n)\n        y_test = _df_test.iloc[:, 0].values.reshape(-1, 1)\n\n        #Running linear regression to generate the coefficents of lagged terms\n        lr = LinearRegression()\n        lr.fit(X_train, y_train)\n\n        theta  = lr.coef_.T\n        intercept = lr.intercept_\n        _df_train[out_pred_col] = X_train.dot(theta) + intercept\n#         _df_train[[val_col, out_pred_col]].plot()\n\n        _df_test[out_pred_col] = X_test.dot(theta) + intercept\n#         _df_test[[val_col, out_pred_col]].plot()\n\n        rmse = np.sqrt(mean_squared_error(y_test, _df_test[out_pred_col]))\n\n#         print(f'RMSE = {rmse}. Value of n = {n}')\n        new_df = pd.concat([_df_train, _df_test])[[val_col, out_pred_col]]\n        return new_df, theta, intercept, rmse, np.abs(_df_test[out_pred_col].mean())\n    \n    @staticmethod\n    def AR(df, p, val_col='value', out_pred_col='predicted_value', train_size=0.8):\n        return ARIMA._regressor(df, p, val_col, out_pred_col, train_size)\n    \n    @staticmethod\n    def I(df, val_col='value', fn=None):\n        _df = df.copy()\n        if fn is not None:\n            return pd.DataFrame(fn(_df[val_col])).dropna()\n        return _df\n\n    @staticmethod\n    def MA(df, q, val_col='value', in_pred_col='predicted_value', out_pred_col='ma_predicted_value', train_size=0.8):\n        _df = df.copy()\n        _df['residual'] = _df[val_col] - _df[in_pred_col]\n        return ARIMA._regressor(_df[['residual']], q, 'residual', out_pred_col, train_size)\n    \n    \n    def fit(self, df, p, q, val_col, train_size, stationary_fn=None):\n        _df = df.copy()\n        stationary_df = ARIMA.I(_df, val_col, stationary_fn)\n#         stationary_df[val_col].plot()\n#         plt.show()\n        \n        ar_out_df, ar_theta, ar_intercept, ar_rmse, ar_mean_pred = ARIMA.AR(stationary_df, p, val_col, 'ar_predicted_value', train_size)\n#         print(ar_rmse)\n#         ar_out_df['ar_predicted_value'].plot()\n#         plt.show()\n        \n        ma_out_df, ma_theta, ma_intercept, ma_rmse, ma_mean_pred = ARIMA.MA(ar_out_df, q, val_col, 'ar_predicted_value', 'ma_predicted_value', train_size)\n#         print(ma_rmse)\n#         ma_out_df['ma_predicted_value'].plot()\n#         plt.show()\n        \n#         final_predictions = (ar_out_df['ar_predicted_value'] + ma_out_df['ma_predicted_value']).dropna()\n#         final_predictions.plot()\n        \n#         return final_predictions\n        stationary_df['prediction'] = ar_out_df['ar_predicted_value'] + ma_out_df['ma_predicted_value']\n        return stationary_df.dropna(), ar_theta, ar_intercept, ma_theta, ma_intercept, ar_rmse, ma_rmse, ar_mean_pred, ma_mean_pred","989cda5b":"arima_model = ARIMA()","6845497a":"# stationary_fn = lambda x: x.diff()\n# def reverse_stationary_fn(ori_x, new_x):\n#     x = new_x.copy()\n#     x += ori_x.shift(1)\n#     return x\n\nstationary_fn = lambda x: x.diff().diff()\ndef reverse_stationary_fn(ori_x, new_x):\n    x = new_x.copy()\n    x += ori_x.shift(1)\n    x += ori_x.diff().shift(1)\n    return x\n\n# stationary_fn = lambda x: np.log(x).diff()\n# def reverse_stationary_fn(ori_x, new_x):\n#     x = new_x.copy()\n#     x += np.log(ori_x).shift(1)\n#     return np.exp(x)\n\n# stationary_fn = lambda x: np.log(x).diff().diff()\n# def reverse_stationary_fn(ori_x, new_x):\n#     x = new_x.copy()\n#     x += np.log(ori_x).shift(1)\n#     x += np.log(ori_x).diff().shift(1)\n#     return np.exp(x)\n\nmin_ar_rmse = float('inf')\nmin_ma_rmse = float('inf')\nbest_ar_mean_pred = None\nbest_ma_mean_pred = None\nbest_p = 1\nbest_q = 1\n\nfor i in range(1, 21):\n    final_predictions, \\\n        ar_theta, ar_intercept, \\\n        ma_theta, ma_intercept, \\\n        ar_rmse, ma_rmse, \\\n        ar_mean_pred, ma_mean_pred = arima_model.fit(raw_data, i, best_q, 'value', TRAIN_SIZE, stationary_fn)\n\n    if ar_rmse < min_ar_rmse:\n        min_ar_rmse = ar_rmse\n        best_ar_mean_pred = ar_mean_pred\n        best_p = i\n\n            \nfor j in range(1, 21):\n    final_predictions, \\\n        ar_theta, ar_intercept, \\\n        ma_theta, ma_intercept, \\\n        ar_rmse, ma_rmse, \\\n        ar_mean_pred, ma_mean_pred = arima_model.fit(raw_data, best_p, j, 'value', TRAIN_SIZE, stationary_fn)\n\n    if ma_rmse < min_ma_rmse:\n        min_ma_rmse = ma_rmse\n        best_ma_mean_pred = ma_mean_pred\n        best_q = j","c9c394f2":"print(f'Min RMSE of AR model: {min_ar_rmse} (relative err: {min_ar_rmse\/best_ar_mean_pred}). Best P: {best_p}')\nprint(f'Min RMSE of MA model: {min_ma_rmse} (relative err: {min_ma_rmse\/best_ma_mean_pred}). Best Q: {best_q}')","2a9c82b9":"final_predictions, \\\n    ar_theta, ar_intercept, \\\n    ma_theta, ma_intercept, \\\n    ar_rmse, ma_rmse, \\\n    ar_mean_pred, ma_mean_pred = arima_model.fit(raw_data, 14, 12, 'value', TRAIN_SIZE, stationary_fn)","35370a33":"final_predictions.plot()","2c950f5f":"fig, ax = plt.subplots(figsize=(12, 8))\nsns.lineplot(data=pd.DataFrame(reverse_stationary_fn(raw_data['value'], final_predictions['value'])).reset_index(), x='date', y='value', ax=ax)\nsns.lineplot(data=pd.DataFrame(reverse_stationary_fn(raw_data['value'], final_predictions['prediction'])).reset_index(), x='date', y='prediction', ax=ax)\nfor ind, label in enumerate(ax.get_xticklabels()):\n    if ind % 10 == 0:  # every 10th label is kept\n        label.set_visible(True)\n    else:\n        label.set_visible(False)\nplt.xticks(rotation=15)\nplt.show()","ad5ddf42":"- This notebook is a modification of the original written in this [article](https:\/\/medium.com\/analytics-vidhya\/arima-model-from-scratch-in-python-489e961603ce).\n- To have a better understanding of the ARIMA model, I suggest this [article](https:\/\/towardsdatascience.com\/understanding-arima-time-series-modeling-d99cd11be3f8) written by Tony Yiu."}}