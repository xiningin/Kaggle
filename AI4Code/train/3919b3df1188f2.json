{"cell_type":{"21de0b5e":"code","ca22adc9":"code","5d955590":"code","e9267f6b":"code","623e3fe6":"code","efcebc2f":"code","1b33f6f5":"code","66894a71":"code","6859158c":"code","f73f6ff3":"markdown","1674db84":"markdown","20cd0abb":"markdown","bd7960fb":"markdown","bdd26e2c":"markdown","35193ecf":"markdown","d0ed2516":"markdown","6820bae6":"markdown","eb338056":"markdown","74b0f39f":"markdown","fdc04070":"markdown"},"source":{"21de0b5e":"import re\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display_html\nfrom sklearn.base import BaseEstimator, ClassifierMixin\n\n# Configure precision to diplay pandas\npd.options.display.precision = 2\n\n# These are just some wrapper functions I use for my notebooks to nicely format and summarise Pandas data\ndef plotSummaryCount(df, groups, feature, summary='mean', \n                     fillna=True, proportion=False, axis=None):\n    \"\"\" Summarise a grouped dataframe, including sample size per group\n        and display inline \"\"\"\n    # Create local copy of the required columns\n    sub_df = df.loc[:, [*groups, feature]]\n    for group in groups:\n        # Boolean groups causes issues so map to string\n        if pd.api.types.is_bool_dtype(sub_df[group]):\n            sub_df[group] = sub_df[group].astype(str)\n        # Convert groups to categories\n        sub_df[group] = sub_df[group].astype('category')\n        # Replace missing data with string so it is included as a group\n        if fillna and sub_df[group].isnull().values.any():\n            sub_df[group] = (\n                sub_df[group].cat.add_categories('Unknown')\n                .fillna('Unknown'))\n    grouped_df = sub_df.groupby(groups)\n    countGroup = grouped_df.size().fillna(0)\n    if proportion:\n        countGroup \/= countGroup.sum()\n    summaryGroup = grouped_df[feature].agg(summary)\n    if len(groups) == 1:\n        summaryGroup = summaryGroup.to_frame()\n        countGroup = countGroup.to_frame()\n    else:\n        summaryGroup = summaryGroup.unstack()\n        countGroup = countGroup.unstack()\n    summaryGroup = (summaryGroup\n        .style.background_gradient(cmap='Blues', axis=axis)\n        .highlight_null('white').applymap(setNanWhite)\n        .set_caption(f'{feature} ({summary})'))\n    mode = 'proportion' if proportion else 'count'\n    countGroup = (countGroup\n        .style.background_gradient(cmap='Blues', axis=axis)\n        .set_caption(f'Sample size ({mode})'))\n    \n    return displayInline(summaryGroup, countGroup)\n\n\n# Display Pandas DataFrames inline in Jupyter notebook\n# Used by plotSummaryCount\ndef displayInline(*dfs, spaces=10):\n    \"\"\" Display pandas dataframes as inline \"\"\"\n    html = ''\n    seperator = '<table style=\\'display:inline\\'>' + (f'{\"&nbsp\"*spaces}')\n    inline = \"style='display:inline'\"\n    for i, df in enumerate(dfs):\n        if isinstance(df, pd.io.formats.style.Styler):\n            styler = df\n        else:\n            styler = df.style\n        html += styler.set_table_attributes(inline)._repr_html_() \n        # Don't add seperator to last element\n        if i < len(dfs) - 1:\n            html += seperator\n    return display_html(html, raw=True)\n\n\n# Mask text in NaN cells by setting to white (background)\n# Used by plotSummaryCount\ndef setNanWhite(val):\n    \"\"\" Colour NaN text white \"\"\"\n    if np.isnan(val):\n        return 'color: white'\n\n# Configure precision to diplay pandas\npd.options.display.precision = 2","ca22adc9":"# Define paths to test and training data\ntrainPath = '\/kaggle\/input\/titanic\/train.csv'\ntestPath = '\/kaggle\/input\/titanic\/test.csv'\ntarget = 'Survived'\nindex = 'PassengerId'\n\n# Read training data\ntrain = pd.read_csv(trainPath, index_col=index)","5d955590":"plotSummaryCount(train, ['Sex', 'Pclass'], 'Survived')","e9267f6b":"train['Title'] = train['Name'].apply(lambda x: re.split(',|\\.', x)[1].strip())\ntrain['Master'] = (train['Title'] == 'Master')\nplotSummaryCount(train, ['Pclass', 'Master'], 'Survived')","623e3fe6":"train['girlOrSingleMum'] = (\n    (train['Sex'] == 'female') & (train['Parch'] == 1) & (train['SibSp'] == 0))\nplotSummaryCount(train, ['Sex', 'girlOrSingleMum'], 'Survived')","efcebc2f":"plotSummaryCount(train, ['Sex', 'Embarked'], 'Survived')","1b33f6f5":"class TitanticClassifier(BaseEstimator, ClassifierMixin):\n    \"\"\" Custom classifier to implement hard-coded \n        Titanic survival prediction \"\"\"\n    \n    def predict(self, X):\n        X['Title'] = X['Name'].apply(self._getTitle)\n        X['girlOrSingleMum'] = (\n            (X['Sex'] == 'female') & (X['Parch'] == 1) & (X['SibSp'] == 0))\n        return np.array(X.apply(self._rule, axis=1))\n    \n    \n    def _rule(self, X):\n        # Predict all males die except boys from class 1 and 2\n        if X['Sex'] == 'male':\n            if (X['Title'] == 'Master') and (X['Pclass'] < 3):\n                return 1\n            else:\n                return 0\n        # Predict all females from class 1 and 2 survive\n        elif (X['Pclass'] < 3):\n            return 1\n        # Predict all 3rd class girls or single mums survive\n        elif X['girlOrSingleMum']:\n            return 1\n        # Predict any 3rd class females from Cherbourg survive\n        elif (X['Embarked'] == 'C'):\n            return 1\n        else:\n            return 0\n        \n    def _getTitle(self, x):\n        \"\"\" Extract Title from Name \"\"\"\n        return re.split(',|\\.', x)[1].strip()","66894a71":"# Read training data\nX = pd.read_csv(trainPath, index_col=index)\n# Drop target from X and save to seperate variable\ny = X.pop(target)\n\n# Initalise Estimator and score training data\nmodel = TitanticClassifier()\nprint(f'Training Score: {model.score(X, y):3.3%}')","6859158c":"# Read test data\ntest = pd.read_csv(testPath, index_col=index)\n# Make predictions and submit\npredictions = model.predict(test)\nsubmission = pd.DataFrame(\n    {'PassengerID': test.index, 'Survived': predictions})\nsubmission.to_csv('submission.csv', index=False)","f73f6ff3":"### Finalising a model\n- We have now identified 2 features to discriminate survival among the remaining passengers (3rd class females).\n  - **Note:** Though neither of these features is particularly concrete, we only need to do better than 50% correct (guessing) to improve upon our model!\n- Let's add these rules to complete our model:\n  - **All Males die except Boys (Title == Master) in 1st and 2nd class.**\n  - **All Females in 1st and 2nd class survive.**\n  - **Among 3rd class females:**\n    - **GirlsOrSingleMums (see below) survive.**\n    - **Those embarking at Cherbourg survive.**\n  - **All remaining passengers die.**","1674db84":"# Model Rules\n  - **All Males die except Boys (Title == Master) in 1st and 2nd class.**\n  - **All Females in 1st and 2nd class survive.**\n  - **Among 3rd class females:**\n    - **GirlsOrSingleMums (see below) survive.**\n    - **Those embarking at Cherbourg survive.**\n  - **All remaining passengers die.**","20cd0abb":"### Describing a model\n  - At this point we can describe a fairly simple model to predict survival among most passengers:\n    - **All Males die except Boys in 1st and 2nd class.**\n    - **All Females in 1st and 2nd class survive.**\n  - That just leaves 3rd class females which have a 50% survival rate.\n  - Below we study 2 other features to determine rules of survival among the remaining passengers:\n    - Girls\/Single Mums\n    - Embarkation point","bd7960fb":"# Exploratory Data Analysis","bdd26e2c":"If you enjoyed reading this kernel or found it helpful then **please give it an upvote**. If you have any questions or suggestions, then feel free to leave a comment!","35193ecf":"### Survival by Sex and Pclass\n- Male survival is very poor, irrespective of class.\n- Female survival is much better in 1st and 2nd class.","d0ed2516":"### Survival by Embarkation\n- Passengers embarking at Cherbourg has the highest survival rates, irrespective of Sex.","6820bae6":"# Coding the model\n- Now we have described our model lets write a custom class to contain our rules.\n  - Here I build a custom Classifier, inheriting from BaseEstimator and ClassifierMixin.\n  - We don't need a .fit() method (since we have hard-coded rules) but by inheriting from ClassifierMix we get a .score() method for free.\n  - Really this class just houses a set of If statements but it's nice to be able to use it just like any other scikit-learn Classifier.","eb338056":"### Survival among Girls or Single Mums\n  - Here I engineer a new feature to identify girls or single mums.\n  - A female travelling with 1 Parent\/Children and no Sibling\/Spouses will either be a girl or single mum - perhaps this can determine survival.\n  - Observation:\n    - This feature does seem to distinguish survival rates (albeit to a small degree).","74b0f39f":"# Top 5% (>0.8) with a simple, interpretable model\n- In this short notebook I walk through some basic exploratory analysis and describe an interpretable model to predict survival with some simple rules.\n- This model scores >0.8 accuracy on both the Test and Training dataset - I hope you find it helpful! :)","fdc04070":"### Survival among Boys (Title == 'Master')\n- Survival for boys is higher in 1st and 2nd class."}}