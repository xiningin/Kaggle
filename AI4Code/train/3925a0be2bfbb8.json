{"cell_type":{"8caa3454":"code","6ffd8799":"code","47f007b1":"code","78f2b11f":"code","2422a495":"code","f12a195d":"code","b3eb359f":"code","fb45d95a":"code","d274895d":"code","a9abe483":"code","117b5654":"code","476a8e61":"code","5c990762":"code","a6dcb19f":"code","942293c9":"code","2e9cda83":"code","cff28625":"code","39bbb7a5":"code","2ce24aac":"code","ac2b8ce9":"code","54a08fe8":"code","79271416":"code","6666f031":"markdown","1e37b8f9":"markdown","f4f84eff":"markdown","aa842af5":"markdown","9be12ecd":"markdown","0d702d85":"markdown","350d60ca":"markdown","11b8f97a":"markdown","f606ed1e":"markdown","aa1f8397":"markdown","e28b3d86":"markdown","a2b223bd":"markdown","29dcaa59":"markdown","4b655d01":"markdown","745d3874":"markdown","0680e80d":"markdown"},"source":{"8caa3454":"# for reading PDFs\n!pip install PyPDF2\n\n# for reading PDFs via OCR\n!conda install -yc conda-forge poppler\n!pip install pdf2image\n\n# For text analysis\n!pip install textacy","6ffd8799":"# --------------------------------------------------\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport gc\nfrom pprint import pprint\n# --------------------------------------------------\n# For Reproducibility - setting the random seed\nimport numpy as np # linear algebra\nimport random\nimport IPython\nimport subprocess\n# --------------------------------------------------\n# For PDF text extraction\n# * by plaintext\nimport PyPDF2 \n# * by OCR\nimport pytesseract\nfrom PIL import Image \nimport pdf2image\n# --------------------------------------------------\n# # For NLP and text analysis\n# import spacy\nimport textacy\nfrom textacy import preprocessing\n# --------------------------------------------------","47f007b1":"# --------------------------------------------------\nMY_SEED = 42\n# --------------------------------------------------\n# set random seeds\nrandom.seed(MY_SEED)\nnp.random.seed(MY_SEED)\n# torch.manual_seed(MY_SEED)\n# transformers.set_seed(MY_SEED)\n# tf.random.set_seed(MY_SEED)\n# --------------------------------------------------\n\n# --------------------------------------------------\n# print system information (but not packages)\nprint(\"=====\"*10)\nprint(\"IPython.sys_info()\")\nprint(IPython.sys_info())\nprint(\"=====\"*10)\n\n# get module information\n!pip freeze > frozen-requirements.txt\n\n# append system information to file\nwith open(\"IPython.sys_info.txt\", \"w\") as file:\n    file.write(IPython.sys_info())\n# --------------------------------------------------\n\n# --------------------------------------------------\n# Check CPU\nprint(\"=====\"*10)\nprint(\"CPU\")\nprint((subprocess.check_output(\"lscpu\", shell=True).strip()).decode())\nprint(\"=====\"*10)\n# --------------------------------------------------\n\n# --------------------------------------------------\n# Check GPU\nprint(\"=====\"*10)\nprint(\"GPU\")\ngpu_info = !nvidia-smi\ngpu_info = '\\n'.join(gpu_info)\nif gpu_info.find('failed') >= 0:\n      print('Settings >> Accelerator >> GPU')\nelse:\n      print(gpu_info)\nprint(\"=====\"*10)\n# --------------------------------------------------","78f2b11f":"INPUT_FOLDER = \"\/kaggle\/input\/syllabus-corpus\"\nX = \"downloads\"\nARCHIVE_FOLDER = os.path.join(\n    INPUT_FOLDER,\n    X,\n    \"downloads\"\n)\nos.environ[\"ARCHIVE_FOLDER\"] = ARCHIVE_FOLDER\nARCHIVE_CSV = os.path.join(\n    INPUT_FOLDER,\n    f\"{X}.csv\"\n)\nOUTPUT_CSV = \"extracted.csv\"\nPDF_FILES = [\n    os.path.join(\n        ARCHIVE_FOLDER,\n        f\n    )\n    for f in os.listdir(ARCHIVE_FOLDER)\n]\nPAGE_DELIMETER = \"\\n\"","2422a495":"pprint(PDF_FILES[:5])\nprint()\nprint(\"len(PDF_FILES): \", len(PDF_FILES))\nprint()\n!ls $ARCHIVE_FOLDER | wc","f12a195d":"def normalize(text):\n    normalize_smart_quotes = preprocessing.normalize.normalize_quotation_marks\n    def norm_repeat_puncts(t):\n        return preprocessing.normalize.normalize_repeating_chars(\n            text=preprocessing.normalize.normalize_repeating_chars(\n                text=preprocessing.normalize.normalize_repeating_chars(\n                    text=t, chars=\"?\"\n                ),\n                chars=\"!\",\n            ),\n            chars=\".\",\n        )\n    # don't normalize spacing because tables often used in syllabi\n    # norm_spacing = preprocessing.normalize.normalize_whitespace\n    norm_unicode = preprocessing.normalize.normalize_unicode\n    return norm_unicode(norm_repeat_puncts(normalize_smart_quotes(text)))\n\n\nprint(normalize(\"Hello! This is a message...... \\\"How's this????\\\" \u201cThat\u2019s better!\u201d \u00e9e` ?????  \\n\\n\\n\\n  \"))","b3eb359f":"def read_pdf(filepath):\n    with open(filepath, \"rb\") as f:\n        _, filename = os.path.split(filepath)\n        try:    \n            pdf = PyPDF2.PdfFileReader(f)\n            pages = [pdf.getPage(i) for i in range(pdf.numPages)]\n            text_list = [page.extractText() for page in pages]\n            return {\n                \"filepath\": filepath,\n                \"filename\": filename,\n                \"num_pages\": pdf.numPages,\n                \"text\": normalize(PAGE_DELIMETER.join(text_list))\n            }\n        except Exception:\n            print(f\"WARNING!! Exception for \\n\\t{filepath}\")\n            return {\n                \"filepath\": filepath,\n                \"filename\": filename,\n                \"num_pages\": 0,\n                \"text\": \"\"\n            }","fb45d95a":"pdf_data = [read_pdf(f) for f in PDF_FILES]","d274895d":"df = pd.DataFrame(pdf_data)","a9abe483":"df.head()","117b5654":"p1, p2 = pdf2image.convert_from_path(\n    PDF_FILES[2]\n)\n\n# (click \"output\" to see the 2 pages of the PDF)\ndisplay(p1, p2)","476a8e61":"print(\n    df[\"text\"].values[2]\n)","5c990762":"print(\n    pytesseract.image_to_string(\n        pdf2image.convert_from_path(\n            PDF_FILES[2]\n        )[0]\n    )\n)","a6dcb19f":"def generate_ocr_from_files(pdf_filenames):\n    i = 1\n    N = len(pdf_filenames)\n    for f in pdf_filenames:\n        print(\n            f\"ocr on pdf {i} \/ {N}...    \\r\",\n            end=\"\"\n        )\n        try:\n            img_list = pdf2image.convert_from_path(f)\n            texts = [\n                pytesseract.image_to_string(img)\n                for img in img_list\n            ]\n            del img_list\n            gc.collect()\n            i += 1\n            yield PAGE_DELIMETER.join(texts)\n        except Exception:\n            print(f\"WARNING!! Exception for \\n\\t{f}\\n\")\n            yield ","942293c9":"gen = generate_ocr_from_files(PDF_FILES)\n\nocr_texts = []\n\nfor txt in gen:\n    ocr_texts.append(txt)\n\ndf[\"ocr_text\"] = ocr_texts","2e9cda83":"adf = pd.read_csv(ARCHIVE_CSV)\nadf.head(1)","cff28625":"def _get_position(filename):\n    path, fname = os.path.split(filename)\n    return fname.split(\"___\")[0]\n\ndf[\"Position\"] = (\n    df[\"filename\"]\n    .apply(_get_position)\n    .astype(\"int64\")\n)\n\n# pd.DataFrame({\"Position\": df.apply(lambda x:x[\"filename\"].split(\"___\")[0], axis=1), **df.to_dict()})\n\ndf = adf.merge(df, on=\"Position\")\ndf.head(1)","39bbb7a5":"df.columns","2ce24aac":"mask = [\n    \"Position\",\n#     \"Type\",\n    \"Title\",\n    \"URL\",\n#     \"filepath\",\n    \"filename\",\n    \"num_pages\",\n    \"text\",\n    \"ocr_text\",\n]\ndf = df[mask]\ndf.head(1)","ac2b8ce9":"df.to_csv(OUTPUT_CSV, index=False)","54a08fe8":"pd.read_csv(OUTPUT_CSV).head()","79271416":"!ls","6666f031":"# Save DataFrame","1e37b8f9":"## Globals \/ Config","f4f84eff":"### lets do OCR on each PDF","aa842af5":"## make a normalizer","9be12ecd":"## read pdf by plain text extraction","0d702d85":"## Installs","350d60ca":"### a remarkably better text extraction via OCR... ","11b8f97a":"Here is plaintext extraction","f606ed1e":"## Imports","aa1f8397":"Here is OCR text extraction","e28b3d86":"### filter the columns","a2b223bd":"## Now join this dataframe with the downloads.csv on `Position` column","29dcaa59":"# Overview\n\nThere are PDF documents in `downloads.tar.gz`\n\nThis notebook will extract data from each PDF","4b655d01":"## [Reproducibility](https:\/\/www.kaggle.com\/rtatman\/reproducible-research-best-practices-jupytercon)","745d3874":"## read pdf by OCR\n\n(click \"output\" to see the 2 pages of the PDF)","0680e80d":"## First read the `downloads.csv`"}}