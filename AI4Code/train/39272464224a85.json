{"cell_type":{"cad6119f":"code","a3e3ba70":"code","61218772":"code","ab288b91":"code","210bf26f":"code","8a953557":"code","22b53894":"code","986d0c4c":"code","1640da9b":"code","2a74a654":"code","3e059fed":"code","4d7ce053":"code","331380c2":"code","20280131":"code","d6e3c8fb":"code","a24aaf29":"code","b70b7775":"code","3345984e":"code","ee5c1d5c":"code","7683f831":"code","cfbe3233":"code","5329758e":"code","11bd7da0":"code","54c033bc":"code","6d81c67f":"code","26d5ca4a":"code","fb401ee6":"code","475276e2":"code","57d39281":"code","476ced5e":"code","74cc9d2f":"code","888af0b5":"code","407abdac":"code","b13e47e9":"code","a9ff3aa3":"code","46048499":"code","6f39f44e":"code","0884332a":"markdown","806735e1":"markdown","5ea5fed4":"markdown","64c26976":"markdown","0d8e99ff":"markdown","0f76f009":"markdown","c272430d":"markdown","0b774429":"markdown","229f2035":"markdown","b6fd64bb":"markdown","cf23c6c8":"markdown","dfb81f4c":"markdown","1c15b04e":"markdown"},"source":{"cad6119f":"from IPython.display import Image\nimport os\n!ls ..\/input\/imagem01\nImage(\"..\/input\/imagem01\/Screenshot from 2020-01-13 18-26-19.png\")","a3e3ba70":"%matplotlib inline\nimport os, sys\nimport numpy as np, pandas as pd, matplotlib.pyplot as plt\nfrom skimage.io import imread\nfrom glob import glob\nimport yaml\nimport ipywidgets as ipw\nfrom mpl_toolkits.mplot3d import Axes3D\ntry:\n    from skimage.util.montage import montage2d\nexcept ImportError:\n    from skimage.util import montage as montage2d\n    #base_dir = '..\/input\/hallway_rgbds'\n    base_dir = '\/kaggle\/input\/hallway-rgbdt'\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n","61218772":"all_yaml = {'\/'.join(p.split('\/')[-2:]): yaml.load(open(p, 'r')) \n            for p in glob(os.path.join(base_dir, '*','*.yaml'))}","ab288b91":"all_images_df = pd.DataFrame({'path': glob(os.path.join(base_dir, '*','*', '*.png'))})\n#print(all_images_df)","210bf26f":"all_images_df['file_id'] = all_images_df['path'].map(lambda x: os.path.splitext(os.path.basename(x))[0])\nall_images_df['file_prefix'] = all_images_df['file_id'].map(lambda x: ''.join([c for c in x if c.isalpha()]))\nall_images_df['file_idx'] = all_images_df['file_id'].map(lambda x: ''.join([c for c in x if c.isnumeric()]))\n","8a953557":"\nall_images_df['experiment'] = all_images_df['path'].map(lambda x: x.split('\/')[-2])\nall_images_df['series'] = all_images_df['path'].map(lambda x: x.split('\/')[-3])\nall_images_df.sample(3)","22b53894":"image_pairs_df = all_images_df.pivot_table(values='path', \n                          index=['series', 'experiment', 'file_idx'], \n                          columns='file_prefix', \n                          aggfunc='first').reset_index()\nimage_pairs_df.sample(3)","986d0c4c":"fig, m_axs = plt.subplots(2, 2, figsize = (10, 10)) #Quantidade de imagens e distancia\n#print(m_axs)\nfor (ax1, ax2), (_, i_row) in zip(m_axs, \n                                  image_pairs_df.sample(len(m_axs)).iterrows()):\n    ax1.imshow(imread(i_row['rgb']))\n    ax1.set_title('RGB')\n    ax2.imshow(imread(i_row['depth']))\n    ax2.set_title('Depth Map')","1640da9b":"exp_list = list(image_pairs_df.groupby(['series', 'experiment']))\nprint(len(exp_list), 'experiencias')","2a74a654":"(series, exp), t_rows = exp_list[-1]\nprint((series, exp))\nt_rows = t_rows.copy()\nprint(t_rows.shape[0], 'linhas para processar')\nt_rows['rgb'] = t_rows['rgb'].map(imread)\nt_rows['depth'] = t_rows['depth'].map(imread)\nall_depth = np.stack(t_rows['depth'].values)","3e059fed":"@ipw.interact()\ndef show_scene_figure(index=(0, t_rows.shape[0])):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n    ax1.imshow(t_rows['rgb'].iloc[index])\n    ax2.imshow(t_rows['depth'].iloc[index])","4d7ce053":"fig, ((ax1, ax2, ax3),(ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(20, 15))\nvmin, vmax = np.min(all_depth), np.max(all_depth)\nax1.imshow(np.mean(all_depth, 0), vmin=vmin, vmax=vmax)\nax1.set_title('Average')\nax2.imshow(np.median(all_depth, 0), vmin=vmin, vmax=vmax)\nax2.set_title('Median')\nax3.imshow(np.std(all_depth, 0), vmin=vmin, vmax=vmax)\nax3.set_title('Std')\nax4.imshow(np.min(all_depth, 0), vmin=vmin, vmax=vmax)\nax4.set_title('Min')\nax5.imshow(np.max(all_depth, 0), vmin=vmin, vmax=vmax)\nax5.set_title('Max')\nax6.imshow(np.max(all_depth, 0)-np.min(all_depth, 0), vmin=0, vmax=vmax-vmin)\nax6.set_title('Range')","331380c2":"na_depth = all_depth.astype('float32')\nna_depth[na_depth==0] = np.NAN\nfig, ((ax1, ax2, ax3),(ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(20, 15))\nvmin, vmax = np.min(all_depth), np.max(all_depth)\nax1.imshow(np.nanmean(na_depth, 0), vmin=vmin, vmax=vmax)\nax1.set_title('Average')\nax2.imshow(np.nanmedian(na_depth, 0), vmin=vmin, vmax=vmax)\nax2.set_title('Median')\nax3.imshow(np.nanstd(na_depth, 0), vmin=vmin, vmax=vmax)\nax3.set_title('Std')\nax4.imshow(np.nanmin(na_depth, 0), vmin=vmin, vmax=vmax)\nax4.set_title('Min')\nax5.imshow(np.nanmax(na_depth, 0), vmin=vmin, vmax=vmax)\nax5.set_title('Max')\nax6.imshow(np.nanmax(na_depth, 0)-np.nanmin(na_depth, 0), vmin=0, vmax=vmax-vmin)\nax6.set_title('Range')","20280131":"(series, exp)\ncur_calib_dict = all_yaml['{}\/calibration.yaml'.format(series)]\nK = np.array(cur_calib_dict['K'])\nPcw = np.array(cur_calib_dict['Pcw'])","d6e3c8fb":"plt.hist(all_depth[all_depth>0])","a24aaf29":"# hacky point cloud reconstruction using some TUM code\n# https:\/\/svncvpr.in.tum.de\/cvpr-ros-pkg\/trunk\/rgbd_benchmark\/rgbd_benchmark_tools\/src\/rgbd_benchmark_tools\/generate_pointcloud.py\n# TODO: replace hard coded focal length and scaling factor with values from Pcw\nfocalLength = 525.0\ncenterX = K[0,2]\ncenterY = K[1,2]\nscalingFactor = 5000.0\ndef slice_to_cloud(in_depth):\n    xx, yy = np.meshgrid(range(in_depth.shape[1]), range(in_depth.shape[0]), indexing='xy')\n    Z = in_depth.astype('float32') \/ scalingFactor\n    X = (xx - centerX) * Z \/ focalLength\n    Y = (yy - centerY) * Z \/ focalLength\n    return X.ravel(), Y.ravel(), Z.ravel()\ndef slice_to_dfcloud(in_rgb, in_depth):\n    X, Y, Z = slice_to_cloud(in_depth[::-1])\n    pc_df = pd.DataFrame({'x': X, 'y': Y, 'z': Z})\n    for i,k in enumerate('rgb'):\n        pc_df[k] = in_rgb[::-1, :, i].ravel()\n    return pc_df.query('z>0')","b70b7775":"show_scene_figure(940) #select frame","3345984e":"test_df = slice_to_dfcloud(t_rows['rgb'].iloc[0], \n                           t_rows['depth'].iloc[0]).sample(100000)\nfig, m_axs = plt.subplots(1, 3, figsize = (20, 5))\nax_names = 'xyz'\nfor i, c_ax in enumerate(m_axs.flatten()):\n    plot_axes = [x for j, x in enumerate(ax_names) if j!=i]\n    c_ax.scatter(test_df[plot_axes[0]],\n                test_df[plot_axes[1]],\n                c=test_df[['r', 'g', 'b']].values\/255, \n                 s=1\n                )\n    c_ax.set_xlabel(plot_axes[0])\n    c_ax.set_ylabel(plot_axes[1])","ee5c1d5c":"fig = plt.figure(figsize=(15,10))\nax = plt.axes(projection='3d')\nax.scatter(test_df['z'], test_df['x'], test_df['y'],\n            c=test_df[['r', 'g', 'b']].values\/255, s=3)  \nax.view_init(55, -45)","7683f831":"import sys\nfrom scipy.spatial import KDTree\nsys.setrecursionlimit(10000) # kdtree gets hungry (https:\/\/docs.scipy.org\/doc\/scipy-0.14.0\/reference\/generated\/scipy.spatial.KDTree.html)","cfbe3233":"x_sig = 2\ny_sig = 2\nz_sig = 2\nx_steps = 100\ny_steps = 40\nz_steps = 100\nbbox = {}\nfor c, sigma in zip('xyz', [x_sig,y_sig,z_sig]):\n    ax_mean, ax_std = test_df[c].mean(), test_df[c].std()\n    bbox[c] = (ax_mean-sigma*ax_std, ax_mean+sigma*ax_std)\nxx, yy, zz = np.meshgrid(np.linspace(*bbox['x'], x_steps),\n                         np.linspace(*bbox['y'], y_steps),\n                         np.linspace(*bbox['z'], z_steps),\n                         indexing='ij'\n                        )\nprint(xx.shape)\ndx = np.diff(xx[0:2, 0, 0])[0]\ndy = np.diff(yy[0, 0:2, 0])[0]\ndz = np.diff(zz[0, 0, 0:2])[0]\ndr = np.sqrt(dx**2+dy**2+dz**2)\nprint(dx, dy, dz, dr)","5329758e":"test_df = slice_to_dfcloud(t_rows['rgb'].iloc[0], \n                           t_rows['depth'].iloc[0])","11bd7da0":"%%time\nfor c_ax, c_xx, c_dx, c_steps in zip('xyz', \n                            [xx, yy, zz], \n                            [dx, dy, dz], \n                            [x_steps, y_steps, z_steps]):\n    test_df['i{}'.format(c_ax)] = (test_df[c_ax]-c_xx.min())\/c_dx\n    test_df['i{}'.format(c_ax)] = test_df['i{}'.format(c_ax)].map(lambda x: x if (x>0) and (x<c_steps) else np.NAN)\ntest_idx = test_df[['ix', 'iy', 'iz']].dropna().values.astype(int)\nprint('Valid Points: {}\/{}'.format(test_idx.shape[0], test_df.shape[0]))\nout_vol = np.zeros_like(xx)\nout_vol[test_idx[:, 0], test_idx[:, 1], test_idx[:, 2]]+=1","54c033bc":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (20, 10))\nax1.imshow(np.sum(out_vol, 0))\nax2.imshow(np.sum(out_vol, 1))\nax3.imshow(np.sum(out_vol, 2))","6d81c67f":"%%time\ntest_kdtree = KDTree(test_df[['x', 'y', 'z']])","26d5ca4a":"%%time\nout_dist, _ = test_kdtree.query(np.stack([xx, yy, zz], -1), k=1, distance_upper_bound = 1.1*dr)\ndist_vol = np.isinf(out_dist).reshape(xx.shape)==False","fb401ee6":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (20, 10))\nax1.imshow(np.sum(dist_vol, 0))\nax2.imshow(np.sum(dist_vol, 1))\nax3.imshow(np.sum(dist_vol, 2))","475276e2":"%%time\nout_dist, _ = test_kdtree.query(np.stack([xx, yy, zz], -1), k=1)\ndist_vol = (out_dist<1.5*dr).reshape(xx.shape)==False","57d39281":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (20, 10))\ndist_vol = np.log2(dr\/out_dist.reshape(xx.shape))\nax1.imshow(np.sum(dist_vol, 0))\nax2.imshow(np.sum(dist_vol, 1))\nax3.imshow(np.sum(dist_vol, 2))","476ced5e":"fig, (ax1) = plt.subplots(1, 1, figsize = (15, 15))\nax1.imshow(montage2d(dist_vol.swapaxes(0,1)))","74cc9d2f":"plt.hist(dist_vol.ravel(), 50);","888af0b5":"fig, (ax1) = plt.subplots(1, 1, figsize = (15, 15))\nax1.imshow(montage2d(dist_vol.swapaxes(0,1)>0.5))","407abdac":"from mpl_toolkits.mplot3d.art3d import Poly3DCollection\nfrom skimage import measure\nverts, faces, normals, values = measure.marching_cubes_lewiner(dist_vol, 1.0, spacing=(dx, dy, dz))","b13e47e9":"fig = plt.figure(figsize=(10, 10))\nax = fig.add_subplot(111, projection='3d')\nax.plot_trisurf(verts[:, 2], verts[:, 0], faces, verts[:, 1],\n                cmap=plt.cm.Greens, lw=0.05, edgecolor='k')\nax.view_init(15, -90)","a9ff3aa3":"from tqdm import tqdm\nimport h5py\nwith h5py.File('time_steps.h5', 'w') as f:\n    time_ds = f.create_dataset('volume_time', \n                               shape=(t_rows.shape[0],)+xx.shape,\n                               chunks=(1,)+xx.shape, \n                               dtype='int', \n                               compression='gzip')\n    for i, (_, c_row) in tqdm(enumerate(t_rows.iterrows())):\n        test_df = slice_to_dfcloud(c_row['rgb'], \n                                   c_row['depth'])\n        for c_ax, c_xx, c_dx, c_steps in zip('xyz', \n                                    [xx, yy, zz], \n                                    [dx, dy, dz], \n                                    [x_steps, y_steps, z_steps]):\n            test_df['i{}'.format(c_ax)] = (test_df[c_ax]-c_xx.min())\/c_dx\n            test_df['i{}'.format(c_ax)] = test_df['i{}'.format(c_ax)].map(lambda x: x if (x>0) and (x<c_steps) else np.NAN)\n        test_idx = test_df[['ix', 'iy', 'iz']].dropna().values.astype(int)\n        out_vol = np.zeros_like(xx)\n        out_vol[test_idx[:, 0], test_idx[:, 1], test_idx[:, 2]]+=1\n        time_ds[i] = out_vol","46048499":"!ls -lh *.h5","6f39f44e":"pcd = o3d.geometry.PointCloud.create_from_rgbd_image(\n        rgbd_image,\n        o3d.camera.PinholeCameraIntrinsic(\n            o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault))\n    # Flip it, otherwise the pointcloud will be upside down\n    pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n    o3d.visualization.draw_geometries([pcd])","0884332a":"Fazemos um volume de baixa resolu\u00e7\u00e3o e apenas controlamos a ocupa\u00e7\u00e3o","806735e1":"Aqui, transformamos as coordenadas test_df em \u00edndices e depois definimos os \u00edndices apropriados.","5ea5fed4":"![](http:\/\/)","64c26976":"Cubos de marcha simples isosuperf\u00edcie\n\nCubos de marcha \u00e9 um algoritmo simples para criar uma malha de tri\u00e2ngulo a partir de uma fun\u00e7\u00e3o impl\u00edcita (uma da forma f (x, y, z) = 0). Ele funciona iterando (\"marchando\") sobre uma grade uniforme de cubos sobrepostos sobre uma regi\u00e3o da fun\u00e7\u00e3o. Se todos os 8 v\u00e9rtices do cubo forem positivos ou todos os 8 v\u00e9rtices forem negativos, o cubo estar\u00e1 inteiramente acima ou totalmente abaixo da superf\u00edcie e nenhum tri\u00e2ngulo ser\u00e1 emitido. Caso contr\u00e1rio, o cubo abrange a fun\u00e7\u00e3o e alguns tri\u00e2ngulos e v\u00e9rtices s\u00e3o gerados. Como cada v\u00e9rtice pode ser positivo ou negativo, existem tecnicamente 2 8 configura\u00e7\u00f5es poss\u00edveis, mas muitas s\u00e3o equivalentes entre si. ","0d8e99ff":"Pesquisa no KDTree\n\nComparar milhares de pontos milhares de vezes \u00e9 muito muito ineficiente sem \u00e1rvores de pesquisa bin\u00e1ria.\nUma \u00e1rvore kDTree, \u00e9 uma estrutura de dados usada na ci\u00eancia da computa\u00e7\u00e3o para organizar algum n\u00famero de pontos em um espa\u00e7o com k dimens\u00f5es. \u00c9 uma \u00e1rvore de pesquisa bin\u00e1ria com outras restri\u00e7\u00f5es impostas a ela. As Kdtree s\u00e3o muito \u00fateis para pesquisas de alcance e vizinho mais pr\u00f3ximo. Para nossos prop\u00f3sitos, geralmente lidamos apenas com nuvens de pontos em tr\u00eas dimens\u00f5es, de modo que todas as nossas kdtree ser\u00e3o tridimensionais.\n\nA maneira mais eficiente de construir uma kdtree \u00e9 usar um m\u00e9todo de parti\u00e7\u00e3o como o que o Quick Sort usa para colocar o ponto m\u00e9dio na raiz e tudo com um valor unidimensional menor \u00e0 esquerda e maior \u00e0 direita. Em seguida, repita esse procedimento nas sub\u00e1rvores esquerda e direita at\u00e9 que as \u00faltimas \u00e1rvores a serem particionadas sejam compostas apenas por um elemento.","0f76f009":"Dada a evolu\u00e7\u00e3o dos sistemas de vis\u00e3o computacional nos \u00faltimos anos em dire\u00e7\u00e3o a uma percep\u00e7\u00e3o multidimensional do ambiente com percep\u00e7\u00e3o bidimensional para uma percep\u00e7\u00e3o que permite obter uma vis\u00e3o 3D do ambiente, ou seja, acrescentam a dimens\u00e3o de profundidade \u00e0s imagens 2D tradicionais, assim podemos ajudar a interpretar atividades humanas em um sen\u00e1rio de \"baixo custo\" com c\u00e2meras ou sensores RGB-D (vermelho verde azul e profundidade), sendo o Microsoft Kinect\no PrimeSense Carmine os exemplos mais pr\u00f3ximos e de f\u00e1cil acesso que nos permitem testar, aprimorar e obter resultados significativos.\n\nEm geral, existem tr\u00eas fases principais, incluindo a aquisi\u00e7\u00e3o, o registro de diferentes vis\u00f5es e an\u00e1lises finais, representadas na imagem 01, onde a\naquisi\u00e7\u00e3o \u00e9 a fase inicial em que os dados s\u00e3o coletados e, portanto, onde eles interv\u00eam os sensores e onde esse trabalho se concentra. \nCada uma dessas fases est\u00e1 relacionada a aplica\u00e7\u00e3o final, sendo a aquisi\u00e7\u00e3o a menos influenciada e a an\u00e1lise a mais complexa por existirem diferentes abordagens. \n","c272430d":"Este \u00e9 um trabalho apresentado para o mestrado de Engenharia Inform\u00e1tica. \n\nO c\u00f3digo foi adaptado do Kevin Mader(https:\/\/www.kaggle.com\/kmader\/rgbt-overview).\n\n\nOs objetivos v\u00e3o desde os testes em datasets j\u00e1 existentes at\u00e9 o desenvolvimento de m\u00f3dulos que permitam fazer a interpreta\u00e7\u00e3o de atividades humanas, objetos e outros em sequ\u00eancias de v\u00eddeo em um contexto de assisted living. Com isso podemos obter por meio de imagens 2D um cen\u00e1rio tridimensional capaz de ser interpretado.\n\nAutor: Manoel Figueiredo\n\nData: 01\/2020","0b774429":"Com todas as imagens \u00e9 necess\u00e1rio obter o caminho e atribuir seus prefixos e ids","229f2035":"Mapas de dist\u00e2ncia podem ser mais \u00fateis\nAqui, fazemos um mapa de dist\u00e2ncia at\u00e9 o ponto mais pr\u00f3ximo, em vez de um mapa bin\u00e1rio.","b6fd64bb":"Gere todos os timesteps\nAqui processamos as demais etapas","cf23c6c8":"Aqui, convertemos os dados RGBD em um volume para cada etapa do tempo. O volume facilitar\u00e1 a visualiza\u00e7\u00e3o das regi\u00f5es que mais mudam","dfb81f4c":"Formato de calibra\u00e7\u00e3o dos arquivos est\u00e3o dispon\u00edvel nos arquivos calibration.yaml ou calibration.mat, com os seguintes campos:\n\nK - matriz da c\u00e2mera\n\nPwc - matriz do mundo para a c\u00e2mera\n\nPcw - matriz da c\u00e2mera para o mundo\n\ndist - coeficientes de distor\u00e7\u00e3o","1c15b04e":"A fun\u00e7\u00e3o  interact cria automaticamente controles da interface do usu\u00e1rio (UI) para explorar c\u00f3digos e dados interativamente. \u00c9 a maneira mais f\u00e1cil de come\u00e7ar a usar os widgets do IPython. (este output s\u00f3 est\u00e1 sendo exibido no modo editor)"}}