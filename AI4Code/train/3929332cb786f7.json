{"cell_type":{"7daba416":"code","4631ff7b":"code","cc4888f1":"code","dbae35c3":"code","823cbf42":"code","9a855f18":"code","298e95e8":"code","34bfb484":"code","d3c8b1ec":"code","ca401799":"code","299e3a23":"code","0690526c":"code","ed10ac99":"code","b67920d9":"code","7c2ec819":"code","1c846fbd":"code","1f9e13cb":"code","539a7725":"markdown"},"source":{"7daba416":"import numpy as np\nimport pandas as pd\nimport xgboost as xgb\nfrom sklearn.preprocessing import LabelEncoder","4631ff7b":"train = pd.read_csv('..\/input\/nyc-taxi-trip-duration\/train.zip')\ntest = pd.read_csv('..\/input\/nyc-taxi-trip-duration\/test.zip')","cc4888f1":"# dates\ntrain['pickup_datetime'] = pd.to_datetime(train['pickup_datetime'])\ntest['pickup_datetime'] = pd.to_datetime(test['pickup_datetime'])","dbae35c3":"# transform character to numeric\nle = LabelEncoder()\nle.fit(train['store_and_fwd_flag'])\ntrain['store_and_fwd_flag'] = le.transform(train['store_and_fwd_flag'])\ntest['store_and_fwd_flag'] = le.transform(test['store_and_fwd_flag'])","823cbf42":"#### date features\ntrain['month'] = train['pickup_datetime'].dt.month\ntrain['day'] = train['pickup_datetime'].dt.day\ntrain['weekday'] = train['pickup_datetime'].dt.weekday\ntrain['hour'] = train['pickup_datetime'].dt.hour\ntrain['minute'] = train['pickup_datetime'].dt.minute\n\ntest['month'] = test['pickup_datetime'].dt.month\ntest['day'] = test['pickup_datetime'].dt.day\ntest['weekday'] = test['pickup_datetime'].dt.weekday\ntest['hour'] = test['pickup_datetime'].dt.hour\ntest['minute'] = test['pickup_datetime'].dt.minute","9a855f18":"#### distance features\ntrain['dist_long'] = train['pickup_longitude'] - train['dropoff_longitude']\ntest['dist_long'] = test['pickup_longitude'] - test['dropoff_longitude']\n\ntrain['dist_lat'] = train['pickup_latitude'] - train['dropoff_latitude']\ntest['dist_lat'] = test['pickup_latitude'] - test['dropoff_latitude']\n\ntrain['dist'] = np.sqrt(np.square(train['dist_long']) + np.square(train['dist_lat']))\ntest['dist'] = np.sqrt(np.square(test['dist_long']) + np.square(test['dist_lat']))","298e95e8":"#### spatial features: count and speed\ntrain['pickup_longitude_bin'] = np.round(train['pickup_longitude'], 2)\ntrain['pickup_latitude_bin'] = np.round(train['pickup_latitude'], 2)\ntrain['dropoff_longitude_bin'] = np.round(train['dropoff_longitude'], 2)\ntrain['dropoff_latitude_bin'] = np.round(train['dropoff_latitude'], 2)\n\ntest['pickup_longitude_bin'] = np.round(test['pickup_longitude'], 2)\ntest['pickup_latitude_bin'] = np.round(test['pickup_latitude'], 2)\ntest['dropoff_longitude_bin'] = np.round(test['dropoff_longitude'], 2)\ntest['dropoff_latitude_bin'] = np.round(test['dropoff_latitude'], 2)","34bfb484":"## count features\na = pd.concat([train, test]).groupby(['pickup_longitude_bin', 'pickup_latitude_bin']).size().reset_index()\nb = pd.concat([train, test]).groupby(['dropoff_longitude_bin', 'dropoff_latitude_bin']).size().reset_index()\n\ntrain = pd.merge(train, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\ntest = pd.merge(test, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\n\ntrain = pd.merge(train, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')\ntest = pd.merge(test, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')","d3c8b1ec":"# speed features\ntrain['speed'] = 100000 * train['dist'] \/ train['trip_duration']\n\na = train[['speed', 'pickup_longitude_bin', 'pickup_latitude_bin']].groupby(['pickup_longitude_bin', 'pickup_latitude_bin']).mean().reset_index()\na = a.rename(columns = {'speed':'ave_speed'})\n\nb = train[['speed', 'dropoff_longitude_bin', 'dropoff_latitude_bin']].groupby(['dropoff_longitude_bin', 'dropoff_latitude_bin']).mean().reset_index()\nb = b.rename(columns = {'speed':'ave_speed'})","ca401799":"train = pd.merge(train, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\ntest = pd.merge(test, a, on = ['pickup_longitude_bin', 'pickup_latitude_bin'], how = 'left')\n\ntrain = pd.merge(train, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')\ntest = pd.merge(test, b, on = ['dropoff_longitude_bin', 'dropoff_latitude_bin'], how = 'left')","299e3a23":"## drop bins\ntrain = train.drop(['speed', 'pickup_longitude_bin', 'pickup_latitude_bin', 'dropoff_longitude_bin', 'dropoff_latitude_bin'], axis = 1)\ntest = test.drop(['pickup_longitude_bin', 'pickup_latitude_bin', 'dropoff_longitude_bin', 'dropoff_latitude_bin'], axis = 1)","0690526c":"## weather data\nweather = pd.read_csv('..\/input\/knycmetars2016\/KNYC_Metars.csv')\nweather['Time'] = pd.to_datetime(weather['Time'])\nweather['year'] = weather['Time'].dt.year\nweather['month'] = weather['Time'].dt.month\nweather['day'] = weather['Time'].dt.day\nweather['hour'] = weather['Time'].dt.hour\nweather = weather[weather['year'] == 2016]\n","ed10ac99":"train = pd.merge(train, weather[['Temp.', 'month', 'day', 'hour']], on = ['month', 'day', 'hour'], how = 'left')\ntest = pd.merge(test, weather[['Temp.', 'month', 'day', 'hour']], on = ['month', 'day', 'hour'], how = 'left')","b67920d9":"## train\/test features, y, id\nxtrain = train.drop(['id', 'pickup_datetime', 'dropoff_datetime', 'trip_duration'], axis = 1).to_numpy()\nxtest = test.drop(['id', 'pickup_datetime', ], axis = 1).to_numpy()\nytrain = train['trip_duration'].values\nid_train = train['id'].values\nid_test = test['id'].values\ndel(train, test)","7c2ec819":"## xgb parameters\nparams = {\n    'booster':            'gbtree',\n    'objective':          'reg:linear',\n    'learning_rate':      0.1,\n    'max_depth':          14,\n    'subsample':          0.8,\n    'colsample_bytree':   0.7,\n    'colsample_bylevel':  0.7,\n    'silent':             1\n}","1c846fbd":"## number of rounds \nnrounds = 50\n\n## train model\ndtrain = xgb.DMatrix(xtrain, np.log(ytrain + 1))\ngbm = xgb.train(params, dtrain, num_boost_round=nrounds)","1f9e13cb":"## test predictions\npred_test = np.exp(gbm.predict(xgb.DMatrix(xtest))) - 1\n\n## create submission\ndf = pd.DataFrame({'id': id_test, 'trip_duration': pred_test}) \ndf = df.set_index('id')\ndf.to_csv('sub_bench.csv', index = True)","539a7725":"##### This kernel used dataset from the New York City Taxi Trip Duration and copied from the 'Beat the benchmark!' written by Omri Goldstein.\n##### Introduction to 'Dynamics of New York city - Animation' : [URL](https:\/\/www.kaggle.com\/danijelk\/beat-the-benchmark)\n##### Thanks for sharing kernel, DANIJEL KIVARANOVIC"}}