{"cell_type":{"e8346edd":"code","d8684df7":"code","563d8fc3":"code","6287727c":"code","db73ff44":"code","30e5c6be":"code","24784bcd":"code","c48b76a6":"code","07c0dc41":"code","f4662d3a":"code","2d4a0f0b":"code","1554a40c":"code","bd04e485":"code","e5fbe050":"code","6f554ce8":"code","e0dbe277":"markdown","3076d140":"markdown","4c329ff6":"markdown","d53b09b3":"markdown","25160392":"markdown","cfd9f483":"markdown","c25abaf2":"markdown","8fc6354c":"markdown","870f2db3":"markdown"},"source":{"e8346edd":"import numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nimport tqdm\nfrom socket import socket","d8684df7":"\nCATEGORIES = ['covid', 'healthy']\nDATADIR = '..\/input\/covidistesgp\/CovidDataset\/train'\nfor category in CATEGORIES:\n    path = os.path.join(DATADIR,category)\n    for img in os.listdir(path):\n        img_arr = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)   \n        plt.imshow(img_arr, cmap='gray')\n        plt.xlabel(category)\n        plt.show()\n        break","563d8fc3":"IMG_SIZE=50\ntrain_data=[]\ntest_data=[]\n\ndef create_data(data_dir):\n    for category in CATEGORIES:\n        path=os.path.join(data_dir, category)\n        class_num=CATEGORIES.index(category)\n        \n        for img in (os.listdir(path)):                                             ## We use os to iterate over all our files in the directory \n            try:\n                img_arr=cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)   ## GRAYSCALING\n                img_arr=cv2.resize(img_arr, (IMG_SIZE,IMG_SIZE))                   ## RESIZING\n                if(data_dir=='..\/input\/covidistesgp\/CovidDataset\/train'):\n                    train_data.append([img_arr,class_num])\n                else:\n                    test_data.append([img_arr,class_num])\n            except exception as e:\n                pass","6287727c":"create_data('..\/input\/covidistesgp\/CovidDataset\/train')\ncreate_data('..\/input\/covidistesgp\/CovidDataset\/validation')\n\nprint(len(train_data))\nprint(len(test_data))","db73ff44":"for sample in train_data[:10]:\n    print(sample[1])","30e5c6be":"import random\n\nrandom.shuffle(train_data)              ## Shuffling the dataset\n\nfor sample in train_data[:10]:\n    print(sample[1])","24784bcd":"x_train=[]\ny_train=[]\nx_test=[]\ny_test=[]\n\nfor features,label in train_data:\n    x_train.append(features)\n    y_train.append(label)\n    \nfor features,label in test_data:\n    x_test.append(features)\n    y_test.append(label)\n\nx_train = np.array(x_train).reshape(-1, IMG_SIZE, IMG_SIZE, 1)   ## reshaping the dataset to (length, 50, 50, 1)\nx_test = np.array(x_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n\nprint(len(x_train))\nprint(len(x_test))","c48b76a6":"import pickle\n\npickle_out_x_train = open(\"x_train.pickle\",\"wb\")          # open\/create a file called x_train.pickle, and write into it         \npickle.dump(x_train, pickle_out_x_train)                  # dump the contents of the np array\npickle_out_x_train.close()                                # close the file\n\npickle_out_y_train = open(\"y_train.pickle\",\"wb\")\npickle.dump(y_train, pickle_out_y_train)\npickle_out_y_train.close()\n\npickle_out_x_test = open(\"x_test.pickle\",\"wb\")\npickle.dump(x_test, pickle_out_x_test)\npickle_out_x_test.close()\n\npickle_out_y_test = open(\"y_test.pickle\",\"wb\")\npickle.dump(y_test, pickle_out_y_test)\npickle_out_y_test.close()\n\nprint(len(x_train))\nprint(len(x_test))","07c0dc41":"pickle_in_x_train = open(\"x_train.pickle\",\"rb\")           # open the file\ntrainX = pickle.load(pickle_in_x_train)                   # load its contents into a python varriable\npickle_in_x_train.close()                                 # close the file\n\npickle_in_y_train = open(\"y_train.pickle\",\"rb\")\ntrainY = pickle.load(pickle_in_y_train)\npickle_in_y_train.close()\n\npickle_in_x_test = open(\"x_test.pickle\",\"rb\")\ntestX = pickle.load(pickle_in_x_test)\npickle_in_x_test.close()\n\npickle_in_y_test = open(\"y_test.pickle\",\"rb\")\ntestY = pickle.load(pickle_in_y_test)\npickle_in_y_test.close()\n\nprint(str(len(trainX)) + ', ' + str(len(testX)))","f4662d3a":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n\nprint(len(x_test))","2d4a0f0b":"### NORMALIZE the data (trainX, trainY) from 0-255 to 0-1, and convert trainX,trainY,testX,testY to np arrays\n### approx. (1 x 4) lines of code\ntrainX=trainX\/255.0\ntestX=testX\/255.0\n\n\n\ntrainX=np.array(trainX)\ntestX=np.array(testX)\ntestY=np.array(testY)\ntrainY=np.array(trainY)\n\n\n\n\n","1554a40c":"model = Sequential()\n\n### Use model.add to add layers (example: conv2D layers, then Maxpooling2D layers, Dense)\n### Experiment with tf keras documentation to complete the model\n### approx 5-12 lines of code, feel free to experiment with different model structures\nmodel.add(Conv2D(filters=32,kernel_size=(8,8),padding='valid',input_shape=(50,50,1),activation='relu'))\n\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters=32,kernel_size=(5,5),padding='valid',activation='tanh')) \nmodel.add(MaxPooling2D(pool_size=(2,2)))          \nmodel.add(Conv2D(filters=64,kernel_size=(3,3),padding='valid',input_shape=(50,50,1),activation='tanh'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters=256,kernel_size=(1,1),padding='valid',input_shape=(50,50,1),activation='tanh'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(100,activation='tanh'))\nmodel.add(Dense(50,activation='tanh'))\nmodel.add(Dense(30,activation='tanh'))\nmodel.add(Dense(10,activation='tanh'))          \n\n\n\n\n\n\n\n\n\n\n\n\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam', metrics=[tf.keras.metrics.AUC()])\n\nmodel.summary()","bd04e485":"model.fit(trainX, trainY, batch_size=32, epochs=5, validation_split=0.3)","e5fbe050":"score = model.evaluate(trainX, trainY, verbose = 1) \n\nprint('Train loss:', score[0]) \nprint('Train accuracy:', score[1])","6f554ce8":"score = model.evaluate(testX, testY, verbose = 0) \n\nprint('Test loss:', score[0]) \nprint('Test accuracy:', score[1])","e0dbe277":"### Its pretty important that we randomise our images rather than having all covid images together and all healthy images together","3076d140":"### Now we use a python library called openCV to read and perform some operations on the input data, such as GRAYSCALING and RESIZING","4c329ff6":"# Deep Learning SGP WEEK 3 Convolutional Neural Networks","d53b09b3":"### Now fill out the code in the below 2 cells following the instructions","25160392":"#### Expected Test Accuracy 70-80%","cfd9f483":"### After we've done this preprocessing work, its handy to store our final array instead of repeating this everytime we want to use these values\n### For this, we use the python library called pickle to store all the values and load them in directly later","c25abaf2":"Expected: 2000, 200\n","8fc6354c":"#### Expected training accuracy 90-98% ","870f2db3":"### Our Dataset is visible on the top right of the screen. We have two categories for images (covid, healthy) for both 'train' and 'validation' folders"}}