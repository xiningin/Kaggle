{"cell_type":{"5bfa9106":"code","c18e01d2":"code","34538f40":"code","d14390d9":"code","1bb0ffd4":"code","f3887b8a":"code","34fe2575":"code","8c3baae1":"code","2d38fad1":"code","6f9ec8b4":"code","bed56ea3":"code","3a756f44":"code","59b0ca8b":"code","657c5cc4":"code","01dc5f46":"code","2c6ec40c":"code","f65a4040":"markdown","4c4329de":"markdown","081ff748":"markdown","ca3dffcf":"markdown","c47e77e8":"markdown","83911e13":"markdown","6b814fae":"markdown","fac07632":"markdown","dd32792a":"markdown","2431238d":"markdown","6e98e679":"markdown","25bdebc2":"markdown"},"source":{"5bfa9106":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n# Any results you write to the current directory are saved as output.","c18e01d2":"import matplotlib.pyplot as plt\nimport matplotlib.image as matImage\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport torchvision.models as models","34538f40":"import json\nfrom pprint import pprint\n\ntrain_dir = \"..\/input\/flower_data\/flower_data\/train\"\nvalid_dir = \"..\/input\/flower_data\/flower_data\/valid\"\ntest_dir = \"..\/input\/test set\"\nnum_file_train_dir = len(os.listdir(train_dir)) #102\nnum_file_valid_dir = len(os.listdir(valid_dir)) #102\n\nclasses = []\nwith open('..\/input\/cat_to_name.json') as f:\n    data = json.load(f)\n    for i in range(len(data)):\n        classes.append((i+1, data['{}'.format(i+1)]))\n\n#pprint(data)\nclasses[0][1]","d14390d9":"import PIL.Image as pil_image\n\nimages = []\nfig=plt.figure(figsize=(32, 32))\ncolumns = 5\nrows = 21\n\nfor folder in os.listdir(train_dir):\n    img_path = os.listdir(train_dir+\"\/\"+folder)[0]\n    img = pil_image.open(train_dir+\"\/\"+folder+\"\/\"+img_path)\n    img = img.resize((64, 64))\n    label = classes[int(folder)-1][1]\n    images.append([img, label])\n\nfor i, (image, label) in enumerate(images):\n    image = image\n    fig.add_subplot(rows, columns, i+1)\n    plt.title(label)\n    plt.imshow(image)\nplt.show()","1bb0ffd4":"im_size = 256\ntrain_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n                                    transforms.ColorJitter(),\n                                    transforms.RandomHorizontalFlip(),\n                                    transforms.RandomRotation(30),\n                                    transforms.Resize((im_size, im_size)),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n                                  ])\n\nvalid_transform = transforms.Compose([transforms.Resize((im_size, im_size)),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n                                     ])\n\ntest_transform = transforms.Compose([transforms.Resize((im_size, im_size)),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n                                     ])\n\ntrain_data = datasets.ImageFolder(train_dir, transform=train_transform)\nvalid_data = datasets.ImageFolder(valid_dir, transform=valid_transform)\ntest_data = datasets.ImageFolder(test_dir, transform=test_transform)\n\ntrainloader = DataLoader(train_data, batch_size=64, shuffle=True)\nvalidloader = DataLoader(valid_data, batch_size=64)\ntestloader = DataLoader(test_data)","f3887b8a":"model = models.resnet50(pretrained=True)\nepochs = 30\n\nfor param in model.parameters():\n    param.requires_grad = False\n    \nmodel.fc = nn.Sequential(nn.Linear(2048, 512),\n                                 nn.ReLU(),\n                                 nn.Dropout(0.2),\n                                 nn.Linear(512, 102),\n                                 nn.LogSoftmax(dim=1))\ncriterion = nn.NLLLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nmodel.to(device)","34fe2575":"# Print model's state_dict\nprint(\"Model's state_dict:\")\nfor param_tensor in model.state_dict():\n    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n\n# Print optimizer's state_dict\nprint(\"Optimizer's state_dict:\")\nfor var_name in optimizer.state_dict():\n    print(var_name, \"\\t\", optimizer.state_dict()[var_name])","8c3baae1":"train_losses, valid_losses, accuracy_list = [], [], []\nfor e in range(epochs):\n    running_loss = 0\n    for images, labels in trainloader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        \n        log_ps = model(images)\n        loss = criterion(log_ps, labels)\n        \n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n    else:\n        valid_loss = 0\n        accuracy = 0\n        \n        with torch.no_grad():\n            model.eval()\n            for images, labels in validloader:\n                images, labels = images.to(device), labels.to(device)\n                \n                log_ps = model(images)\n                loss_ps = criterion(log_ps, labels)\n                valid_loss += loss_ps.item()\n                \n                ps = torch.exp(log_ps)\n                top_p, top_class = log_ps.topk(1, dim=1)\n                equals = top_class == labels.view(*top_class.shape)\n                accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n            \n        \n        train_losses.append(running_loss\/len(trainloader))\n        valid_losses.append(valid_loss\/len(validloader))\n        accuracy_list.append(accuracy\/len(validloader))\n\n        print(\"Epoch: {}\/{}.. \".format(e+1, epochs),\n              \"Training Loss: {:.3f}.. \".format(running_loss\/len(trainloader)),\n              \"Validation Loss: {:.3f}.. \".format(valid_loss\/len(validloader)),\n              \"Validation Accuracy: {:.3f}\".format(accuracy\/len(validloader)))\n        running_loss = 0\n        model.train()","2d38fad1":"checkpoint = {'model': model,\n              'state_dict': model.state_dict(),\n              'optimizer' : optimizer.state_dict()}\n\ntorch.save(checkpoint, 'checkpoint.pth')","6f9ec8b4":"def load_checkpoint(filepath):\n    checkpoint = torch.load(filepath)\n    model = checkpoint['model']\n    model.load_state_dict(checkpoint['state_dict'])\n    for parameter in model.parameters():\n        parameter.requires_grad = False\n    \n    model.eval()\n    \n    return model\n\nmodel = load_checkpoint('checkpoint.pth')\nprint(model)","bed56ea3":"fig, axs = plt.subplots(nrows=1, ncols=2)\n\naxs[0].plot(train_losses, label='training loss')\naxs[0].plot(valid_losses, label='validation loss')\naxs[0].legend(frameon=False)\n\naxs[1].plot(accuracy_list, label='accuracy')\naxs[1].legend(frameon=False)\n\nplt.show()","3a756f44":"files = os.listdir(os.path.join(test_dir+\"\/test set\"))\npredicted_flower = []\npredicted_class = []\n\nfor image, label in testloader:\n    image = image.to(device)\n    log_ps = model(image)\n    output = torch.exp(log_ps)\n    probs,top_class = output.topk(1, dim=1)\n    class_name = classes[(top_class.item() - 1)]\n    #print(class_name)\n    predicted_flower.append(class_name[1])\n    predicted_class.append(class_name[0])\n\n# df = pd.DataFrame(prediction_list, columns=['Image', 'Flower Name', 'Class Number'])\ndf = pd.DataFrame({'Image': files, 'Flower Name': predicted_flower, 'Class Name': predicted_class})\npd.set_option('display.max_colwidth', -1)\ndf","59b0ca8b":"# df.to_csv(r'..\/input\/result.csv')","657c5cc4":"print(df.to_string())","01dc5f46":"# from PIL import Image\n\n# files = os.listdir(str(test_dir) + \"\/test set\/\")\n\n# prediction_list = []\n\n# for file in files:\n#     fullpath = str(test_dir) + \"\/test set\/\" + str(file)\n#     with Image.open(fullpath) as f:\n#         try:\n#             img = test_transform(f)\n#             img = img.unsqueeze(0)\n#             with torch.no_grad():\n#                 img = img.to(device)\n#                 out = model(img)\n#                 output = torch.exp(out)\n#                 probs,top_class = output.topk(1, dim=1)\n#                 class_name = classes[(top_class.item() - 1)]\n#                 prediction_list.append([file, class_name[1], class_name[0]])\n                \n#         except:\n#             None\n# df = pd.DataFrame(prediction_list, columns=['Image', 'Flower Name', 'Class Number'])\n# pd.set_option('display.max_colwidth', -1)\n# print(len(os.listdir(test_dir+'\/test set')))\n# #print(df['Image'])\n# predicted_images_list = []\n# for image in df['Image']:\n#     predicted_images_list.append(image)\n    \n# print(len(predicted_images_list))\n# #set(predicted_images_list) & set(os.listdir(test_dir+'\/test set'))\n# len([i for i, j in zip(predicted_images_list, os.listdir(test_dir+'\/test set')) if i == j])","2c6ec40c":"import requests\nfrom io import BytesIO\n\nresponse = requests.get(\"https:\/\/images.homedepot-static.com\/productImages\/80198476-3136-423d-a608-b71602afb64c\/svn\/encore-azalea-shrubs-80691-64_1000.jpg\")\nsingle_image = Image.open(BytesIO(response.content))\nsingle_img = test_transform(single_image).unsqueeze(0)\nwith torch.no_grad():\n    out = model(single_img.to(device))\n    output = torch.exp(out)\n    probs,top_class = output.topk(1, dim=1)\n    class_name = classes[(top_class.item() - 1)]\n    print(\"File Name: test-azalea\", \"\\tPredicted Label: \", \n          class_name, \"\\tAnd Label in Number: \",top_class.item())\n\nsingle_image = single_image.resize((256, 256))\nsingle_image","f65a4040":"# Training the Model","4c4329de":"# Printing Predictions of the Test files","081ff748":"# Ploting the Losses and Accuracy","ca3dffcf":"## Loading the model","c47e77e8":"# Creating model from Resnot50","83911e13":"# Finding Target Classes","6b814fae":"# Predicting a Random File from Internet","fac07632":"## Checking model state_dict and optimizer's state_dict","dd32792a":"# Necessary Imports","2431238d":"# Printing First Images from Every Training Folder with Label","6e98e679":"# Data Transformations and Loading Data into DataLoader","25bdebc2":"## Saving the model"}}