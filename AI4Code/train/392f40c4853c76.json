{"cell_type":{"32c2fd0e":"code","95f02c37":"code","a42ec388":"code","8cd6eadb":"code","46b3b18b":"code","6402cb77":"code","89085e3c":"code","a20cdb2b":"code","a0ebdfbc":"code","0a14b1dd":"code","49b68345":"code","cadb9ad4":"code","628adb32":"code","7a7023f5":"code","f757eaf1":"code","98e5dbc0":"code","66e98064":"code","d06706fe":"code","bff8e363":"code","3f12b762":"code","0a8c1a2b":"code","2e007d85":"code","4caa3a6a":"code","41e94daf":"code","b0e9e8ea":"code","4faf64d6":"code","54597c65":"code","f6742518":"code","27155c38":"code","aab5ee5d":"markdown","46d29b18":"markdown","8ee86ac6":"markdown","bae4a61c":"markdown"},"source":{"32c2fd0e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport datetime as dt\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","95f02c37":"import scipy as sp\nfrom pandas import DataFrame, Series\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom category_encoders import OrdinalEncoder, OneHotEncoder, TargetEncoder\n#from tqdm import tqdm_notebook as tqdm\nfrom tqdm.notebook import tqdm as tqdm\n\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier","a42ec388":"# \u4f7f\u7528\u30e1\u30e2\u30ea\u3092\u524a\u6e1b\u3059\u308b\u305f\u3081\u306b\u5404\u5217\u306e\u578b\u3092\u660e\u793a\u7684\u306b\u6307\u5b9a\n# https:\/\/qiita.com\/nannoki\/items\/2a8934de31ad2258439d\ndtypes = {\n    'ID': 'int32',\n    'loan_amnt': 'int32',\n    'installment': 'float32',\n    'grade': 'object',\n    'sub_grade': 'object',\n    'emp_title': 'object',\n    'emp_length': 'object',\n    'home_ownership': 'object',\n    'annual_inc': 'float32',\n    'issue_d': 'object',\n    'purpose': 'object',\n    'title': 'object',\n    'zip_code': 'object',\n    'addr_state': 'object',\n    'dti': 'float16',\n    'delinq_2yrs': 'float32',\n    'earliest_cr_line': 'object',\n    'inq_last_6mths': 'float32',\n    'mths_since_last_delinq': 'float32',\n    'mths_since_last_record': 'float32',\n    'open_acc': 'float32',\n    'pub_rec': 'float32',\n    'revol_bal': 'int32',\n    'revol_util': 'float32',\n    'total_acc': 'float32',\n    'initial_list_status': 'object',\n    'collections_12_mths_ex_med': 'float32',\n    'mths_since_last_major_derog': 'float32',\n    'application_type': 'object',\n    'acc_now_delinq': 'float32',\n    'tot_coll_amt': 'float32',\n    'tot_cur_bal': 'float32',\n    'loan_condition': 'int8'\n}\n\n\n\ndf_train = pd.read_csv('..\/input\/homework-for-students3\/train.csv', index_col=0, dtype=dtypes)#, skiprows=lambda x: x%20!=0)\ndf_test = pd.read_csv('..\/input\/homework-for-students3\/test.csv', index_col=0, dtype=dtypes)#, skiprows=lambda x: x%20!=0)\ndf_statelatlong = pd.read_csv('..\/input\/homework-for-students3\/statelatlong.csv',index_col=0)\ndf_gdp = pd.read_csv('..\/input\/homework-for-students3\/US_GDP_by_State.csv',index_col=0)\n\n#submission = pd.read_csv('..\/input\/homework-for-students3\/sample_submission.csv', index_col=0, skiprows=lambda x: x%20!=0)\n\n#df_train = pd.read_csv('..\/input\/homework-for-students3\/train.csv', index_col=0, dtype=dtypes)\n#df_test = pd.read_csv('..\/input\/homework-for-students3\/test.csv', index_col=0, dtype=dtypes)\n","8cd6eadb":"# DataFrame\u306eshape\u3067\u884c\u6570\u3068\u5217\u6570\u3092\u78ba\u8a8d\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\ndf_train.shape, df_test.shape\ndf_train.head()","46b3b18b":"f = 'loan_amnt'\n\nplt.figure(figsize=[7,7])\ndf_train[f].hist(density=True, alpha=0.5, bins=30,color='r')\ndf_test[f].hist(density=True, alpha=0.5, bins=30,color='b')\n# test\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u53ef\u8996\u5316\u3092\u8a18\u5165\u3057\u3066\u307f\u307e\u3057\u3087\u3046\nplt.xlabel(f)\nplt.ylabel('density')\nplt.show()\n# SPIKE\u3057\u3066\u3044\u308b\u3002\u3068\u304b\u8272\u3005","6402cb77":"f = 'purpose'\ndf_train[f].value_counts() \/ len(df_train)*100\n# value_counts\u3092\u7528\u3044\u3066train\u306epurpose\u306b\u5bfe\u3057\u3066\u96c6\u8a08\u7d50\u679c\u3092\u307f\u3066\u307f\u307e\u3057\u3087\u3046\u3002","89085e3c":"f = 'purpose'\ndf_test[f].value_counts(normalize=True)","a20cdb2b":"#\u65e5\u4ed8\u578b\u3078\u5909\u63dbissue_d\nf = 'issue_d'\ndf_train[f] = pd.to_datetime(df_train[f] ,format = '%b-%Y')\ndf_test[f] = pd.to_datetime(df_test[f] ,format = '%b-%Y')\ndf_train = df_train[(df_train[f] >= dt.datetime(2015,1,1)) &  (df_train[f] < dt.datetime(2016,1,1))]\ndf_train.head()","a0ebdfbc":"# \u8aac\u660e\u5909\u6570\u3068\u76ee\u7684\u5909\u6570\u3092\u5206\u5272\n# \u30c6\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u306f\u3001\u305d\u306e\u307e\u307e\u5229\u7528\n\ny_train = df_train.loan_condition\nX_train = df_train.drop(['loan_condition'],axis=1)\nX_test=df_test\n\n","0a14b1dd":"plt.hist(df_train['tot_cur_bal'])","49b68345":"np.log1p(X_train.loan_amnt).hist\nX_train['loan_amnt'] = X_train['loan_amnt'].apply(np.log1p)\nX_test['loan_amnt'] = X_test['loan_amnt'].apply(np.log1p)\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n#reshape\u3067\u6a2a\u6301\u3092\u7e26\u306b\u5909\u3048\u306a\u3044\u3068\u30a8\u30e9\u30fc\u3002\n\nplt.hist(scaler.fit_transform(X_train.loan_amnt.values.reshape(-1,1)))\n\n","cadb9ad4":"#\u52e4\u7d9a\u5e74\u6570\u3092\u6570\u5024\u3078\nf = 'emp_length'\n\n#df_train2 = df_train[f].replace('years','', regex=True).replace('year','', regex=True).replace('<','', regex=True).replace(' ','', regex=True).replace('\\+','', regex=True)\n#df_train[f] = df_train2\n#df_train[f].value_counts()\n\n# \u3053\u306e\u66f8\u304d\u65b9\u3060\u3068\u4e0a\u624b\u304f\u884c\u304b\u3093\u304b\u3063\u305f\u3002 SettingWithCopyWarning\u306e\u30a8\u30e9\u30fc\n#X_train[f] = X_train[f].replace('years','', regex=True).replace('year','', regex=True).replace('<','', regex=True).replace(' ','', regex=True).replace('\\+','', regex=True)\n# \u76f4\u3057\u3066\u307f\u305f\u3002\u3002\nX_train[:][f] = X_train[:][f].replace('years','', regex=True).replace('year','', regex=True).replace('<','', regex=True).replace(' ','', regex=True).replace('\\+','', regex=True)\nX_test[:][f] = X_test[:][f].replace('years','', regex=True).replace('year','', regex=True).replace('<','', regex=True).replace(' ','', regex=True).replace('\\+','', regex=True).copy()\n\n#X_train2[f] = X_train[f].replace('years','', regex=True).replace('year','', regex=True).replace('<','', regex=True).replace(' ','', regex=True).replace('\\+','', regex=True).copy()\nX_train[f].value_counts()\n#X_test[f].value_counts()","628adb32":"#earlyest_CR_line\n\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u7d50\u5408\u3057\u305f\nX_all = pd.concat([X_train, X_test], axis=0)\n#X_all['earliest_cr_line','earliest_cr_line_2']=X_all['earliest_cr_line'].str.split('-',expand=True)\nX_all2 = pd.concat([X_all, X_all['earliest_cr_line'].str.split('-', expand=True)], axis=1).drop('earliest_cr_line', axis=1)\nX_all2.rename(columns={0: 'kesu',1: 'earliest_cr_line2'},inplace=True)\nX_all2['earliest_cr_line'] = X_all2['earliest_cr_line2'].astype(np.int64)\nX_all2['earliest_cr_line'] = X_all2['earliest_cr_line2'].astype(np.int64)\n\n\nX_all2.drop(['kesu','earliest_cr_line2'], axis=1, inplace=True)\n\n\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u518d\u5206\u5272\nX_train = X_all2.iloc[:X_train.shape[0], :]\nX_test = X_all2.iloc[X_train.shape[0]:, :]\n\nX_train.head()\n","7a7023f5":"#\u6b20\u640d\u5024\u51e6\u7406\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u7d50\u5408\u3057\u305f\u4e0a\u3067\u5b9f\u65bd\nX_all = pd.concat([X_train, X_test], axis=0)\n\nhavenullcol = X_all.columns[X_test.isnull().sum()!=0].values \nfor col in havenullcol:\n    colnull = col + '_null'\n    X_all[colnull] = X_all[col].isnull().apply(lambda x : 0  if x == 1 else 1)\n    \nX_train = X_all.iloc[:X_train.shape[0], :]\nX_test = X_all.iloc[X_train.shape[0]:, :]\n\nX_train['revol_util'].fillna(X_train['revol_util'].mean(), inplace=True)\nX_test['revol_util'].fillna(X_test['revol_util'].mean(), inplace=True)\nX_train['emp_length'].fillna(0, inplace=True)\nX_test['emp_length'].fillna(0, inplace=True)\nX_train['emp_length'] = X_train['emp_length'].astype(np.int64)\nX_test['emp_length'] = X_test['emp_length'].astype(np.int64)\nX_train.fillna(-9999, inplace=True)\nX_test.fillna(-9999, inplace=True)    \n","f757eaf1":"# 3\u3064\u306e\u30ab\u30e9\u30e0\u3092RANKGAUSS\u3067\u6b63\u898f\u5316\nfrom sklearn.preprocessing import quantile_transform\n#num_cols= ['loan_amnt','installment','annual_inc','dti','revol_bal','collections_12_mths_ex_med','mths_since_last_major_derog','tot_coll_amt','tot_cur_bal']\nnum_cols= ['loan_amnt','installment','annual_inc','dti','delinq_2yrs','inq_last_6mths','mths_since_last_delinq','mths_since_last_record','open_acc','pub_rec','revol_bal','revol_util','total_acc','collections_12_mths_ex_med','mths_since_last_major_derog','tot_coll_amt','tot_cur_bal','earliest_cr_line']\n#num_cols= ['loan_amnt']\n\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u7d50\u5408\u3057\u305f\u4e0a\u3067RankGauss\u306b\u3088\u308b\u5909\u63db\u3092\u5b9f\u65bd\nX_all = pd.concat([X_train, X_test], axis=0)\nX_all[num_cols] = quantile_transform(X_all[num_cols] ,n_quantiles=100, random_state=0, output_distribution='normal',copy=True)\n\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u518d\u5206\u5272\nX_train = X_all.iloc[:X_train.shape[0], :]\nX_test = X_all.iloc[X_train.shape[0]:, :]\n#df_train = X_all.iloc[:X_train.shape[0], :]\n#df_test = X_all.iloc[X_train.shape[0]:, :]\n\n#print(X_train['loan_amnt'])\n#plt.hist(df_train['loan_amnt'])\n#plt.hist(df_train['installment'])\n#plt.hist(X_train['open_acc'])\n","98e5dbc0":"# dtype\u304cobject\u306e\u30ab\u30e9\u30e0\u540d\u3068\u30e6\u30cb\u30fc\u30af\u6570\u3092\u78ba\u8a8d\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\n# \u30e9\u30d9\u30eb\u30a8\u30f3\u30b3\u30fc\u30c9\u3068\u304b\u3067\u304d\u308b\u304b\u3092\u78ba\u8a8d\ncats = []\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        cats.append(col)\n        \n        print(col, X_train[col].nunique())\n        # emp_title\u306a\u3093\u304b\u306f1500\u3082\u3042\u308b\u306e\u3067\u3001\u30ab\u30c6\u30b4\u30ea\u306a\u3089\u3093\u3088\u306d\u3002\u3002\u3002\u3068\u304b\u3002\n        ","66e98064":"#\u30b0\u30ec\u30fc\u30c9\u3092\u660e\u793a\u7684\u306b\u6570\u5024\u5316 A\uff1d\uff11\u3001B=2,G=7\nf = ['grade','sub_grade']\nX_train[:][f] = X_train[:][f].replace('A','1', regex=True).replace('B','2', regex=True).replace('C','3', regex=True).replace('D','4', regex=True).replace('E','5', regex=True).replace('F','6', regex=True).replace('G','7', regex=True)\nX_test[:][f] = X_test[:][f].replace('A','1', regex=True).replace('B','2', regex=True).replace('C','3', regex=True).replace('D','4', regex=True).replace('E','5', regex=True).replace('F','6', regex=True).replace('G','7', regex=True)\n\nX_train[f] = X_train[f].astype(np.int64)\nX_test[f] = X_test[f].astype(np.int64)","d06706fe":"# \u5dde\u306e\u5c5e\u6027\u3068\u7def\u5ea6\u7d4c\u5ea6\u7d50\u5408\u3059\u308b\n# \u7cbe\u5ea6\u304c\u4e0b\u304c\u308b\u306e\u3067\u3001\u4e00\u65e6\u306a\u3057\u3067\u30fb\u30fb\u30fb\u3002\n\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u7d50\u5408\u3057\u305f\u4e0a\u3067\u5b9f\u65bd\nX_all = pd.concat([X_train, X_test], axis=0)\n\ndf_grp = df_gdp.rename(columns={'State & Local Spending':'Spending', 'Gross State Product':'GrossState', 'Real State Growth %':'RealState', 'Population (million)':'Population'})\n\nX_all = pd.merge(X_all,df_statelatlong,left_on='addr_state', right_index=True,how='left')\nX_all2 = pd.merge(X_all,df_gdp[df_gdp['year']==2015],left_on='City',right_index=True,how='left')\n\n\n#df_train = df_train[(df_train[f] >= dt.datetime(2015,1,1)) &  (df_train[f] < dt.datetime(2016,1,1))]\n\nX_train = X_all2.iloc[:X_train.shape[0], :]\nX_test = X_all2.iloc[X_train.shape[0]:, :]\nX_train['latlong'] = round(X_train['Latitude'] * X_train['Longitude'],5)\nX_test['latlong'] = round(X_test['Latitude'] * X_train['Longitude'],5)\nX_train.drop(['Latitude','Longitude','City','year'],axis=1, inplace=True)\nX_test.drop(['Latitude','Longitude','City','year'],axis=1, inplace=True)\n","bff8e363":"#\u30ab\u30a6\u30f3\u30c8\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3068\u304b\u3084\u3063\u3066\u307f\u308b\u30fb\u30fb\u30fb\u3002\nlist_cols = ['grade','title','emp_title','sub_grade','initial_list_status','application_type','purpose','home_ownership','addr_state','zip_code']\n#list_cols = ['grade','title','sub_grade','purpose','home_ownership','addr_state']\n\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u7d50\u5408\u3057\u305f\u4e0a\u3067\u5b9f\u65bd\nX_all = pd.concat([X_train, X_test], axis=0)\n\nfor c in list_cols:\n    freq = X_all[c].value_counts()\n    c_count = c + '_count'\n    X_all[c_count] = X_all[c].map(freq)\n    # size of each category\n\nX_train = X_all.iloc[:X_train.shape[0], :]\nX_test = X_all.iloc[X_train.shape[0]:, :]\n\n\n","3f12b762":"#\u30bf\u30fc\u30b2\u30c3\u30c8\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\ntarget = 'loan_condition'\n#col = 'purpose'\n#list_cols = ['purpose','home_ownership','addr_state']\nlist_cols = ['grade','title','emp_title','sub_grade','initial_list_status','application_type','purpose','home_ownership','addr_state','zip_code']\n\nX_temp = pd.concat([X_train, y_train], axis=1)\n\nfor col in list_cols:\n\n    # X_test\u306fX_train\u3067\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3059\u308b\n    summary = X_temp.groupby([col])[target].mean()\n#    enc_test = X_test[col].map(summary) \n    X_test[col] = X_test[col].map(summary)\n\n    # X_train\u306e\u30ab\u30c6\u30b4\u30ea\u5909\u6570\u3092oof\u3067\u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u3059\u308b\n    skf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\n\n    enc_train = Series(np.zeros(len(X_train)), index=X_train.index)\n\n    for i, (train_ix, val_ix) in enumerate((skf.split(X_train, y_train))):\n        X_train_, _ = X_temp.iloc[train_ix], y_train.iloc[train_ix]\n        X_val, _ = X_temp.iloc[val_ix], y_train.iloc[val_ix]\n\n        summary = X_train_.groupby([col])[target].mean()\n        enc_train.iloc[val_ix] = X_val[col].map(summary)\n\n    X_train[col] = enc_train\n    print(X_train[col] .head())\n","0a8c1a2b":"#\u4e0d\u8981\u305d\u3046\u306a\u7279\u5fb4\u91cf\u3092\u524a\u3063\u3066\u3044\u304f\n\n#X_train.drop(['emp_title','title','issue_d','earliest_cr_line','zip_code'], axis=1, inplace=True)\n#X_test.drop(['emp_title','title','issue_d','earliest_cr_line','zip_code'], axis=1, inplace=True)\n#X_train.drop(['emp_title','emp_length','title','issue_d','earliest_cr_line','zip_code'], axis=1, inplace=True)\n#X_test.drop(['emp_title','emp_length','title','issue_d','earliest_cr_line','zip_code'], axis=1, inplace=True)\n#X_train.drop(['emp_title','Latitude','Longitude','City'], axis=1, inplace=True)\n#X_test.drop(['emp_title','Latitude','Longitude','City'], axis=1, inplace=True)\n\n#X_train.drop(['grade','emp_title','emp_length','title','issue_d','zip_code'], axis=1, inplace=True)\n#X_test.drop(['grade','emp_title','emp_length','title','issue_d','zip_code'], axis=1, inplace=True)\n\n#X_train.drop(['grade','emp_title','emp_length','title','issue_d','zip_code'], axis=1, inplace=True)\n#X_test.drop(['grade','emp_title','emp_length','title','issue_d','zip_code'], axis=1, inplace=True)\nX_train.drop(['grade','emp_length','issue_d'], axis=1, inplace=True)\nX_test.drop(['grade','emp_length','issue_d'], axis=1, inplace=True)\n\nX_train.head(20)\n","2e007d85":"#\u30a4\u30f3\u30d1\u30af\u30c8\u306e\u5f37\u3044\u7279\u5fb4\u91cf\u540c\u58eb\u3092\u639b\u3051\u5408\u308f\u3059\n# \u3082\u3057\u304f\u306f\u610f\u5473\u306e\u3042\u308a\u305d\u3046\u306a\u7d44\u3042\u308f\u305b\u3092\u4f5c\u308b\nX_traintemp = X_train.copy()\nX_testtemp = X_test.copy()\n\nX_traintemp['tot_cur_bal_grade']=round(X_traintemp['tot_cur_bal'] * X_traintemp['sub_grade'],5)\nX_testtemp['tot_cur_bal_grade'] =round(X_testtemp['tot_cur_bal'] * X_testtemp['sub_grade'],5)\n\nX_traintemp['dti_grade']=round(X_traintemp['dti'] * X_traintemp['sub_grade'],5)\nX_testtemp['dti_grade'] =round(X_testtemp['dti'] * X_testtemp['sub_grade'],5)\n\nX_traintemp['loan_amnt_grade']=round(X_traintemp['loan_amnt'] * X_traintemp['sub_grade'],5)\nX_testtemp['loan_amnt_grade']=round(X_testtemp['loan_amnt'] * X_testtemp['sub_grade'],5)\n\nX_traintemp['open_acc_grade']=round(X_traintemp['open_acc'] * X_traintemp['sub_grade'],5)\nX_testtemp['open_acc_grade']=round(X_testtemp['open_acc'] * X_testtemp['sub_grade'],5)\n\nX_traintemp['home_ownership_grade']=round(X_traintemp['home_ownership'] * X_traintemp['sub_grade'],5)\nX_testtemp['home_ownership_grade']=round(X_testtemp['home_ownership'] * X_testtemp['sub_grade'],5)\n\n\nX_traintemp['installment_grade']=round(X_traintemp['installment'] * X_traintemp['sub_grade'],5)\nX_testtemp['installment_grade']=round(X_testtemp['installment'] * X_testtemp['sub_grade'],5)\n\nX_traintemp['revol_bal_grade']=round(X_traintemp['revol_bal'] * X_traintemp['sub_grade'],5)\nX_testtemp['revol_bal_grade']=round(X_testtemp['revol_bal'] * X_testtemp['sub_grade'],5)\n\n#X_traintemp['fe1']=round(X_traintemp['loan_amnt'] \/ X_traintemp['annual_inc'],5)\n#X_testtemp['fe1']=round(X_testtemp['loan_amnt'] * X_testtemp['annual_inc'],5)\n\n#X_traintemp['fe2']=round(X_traintemp['loan_amnt'] \/ X_traintemp['tot_cur_bal'],5)\n#X_testtemp['fe2']=round(X_testtemp['loan_amnt'] * X_testtemp['tot_cur_bal'],5)\n\n#X_traintemp['fe3']=round(X_traintemp['tot_coll_amt'] \/ X_traintemp['open_acc'],5)\n#X_testtemp['fe3']=round(X_testtemp['tot_coll_amt'] * X_testtemp['open_acc'],5)\n\n\nX_train = X_traintemp\nX_test = X_testtemp\n\n\n\n\n#X_train.drop(['sub_grade','grade_count'], axis=1, inplace=True)\n#X_test.drop(['sub_grade','grade_count'], axis=1, inplace=True)\n\n\n#X_train.drop(['revol_util_null','dti_null','inq_last_6mths_null','acc_now_delinq','mths_since_last_record_null','title_null','mths_since_last_major_derog_null'], axis=1, inplace=True)\n#X_test.drop(['revol_util_null','dti_null','inq_last_6mths_null','acc_now_delinq','mths_since_last_record_null','title_null','mths_since_last_major_derog_null'], axis=1, inplace=True)\n\n#list_cols = ['grade','title','sub_grade','purpose','home_ownership','addr_state']\n#X_train.drop(['grade','emp_title','emp_length','title','issue_d','zip_code'], axis=1, inplace=True)","4caa3a6a":"X_train.columns","41e94daf":"num_cols= ['open_acc_grade','home_ownership_grade','State & Local Spending','Gross State Product','Real State Growth %','Population (million)']\n#num_cols= ['open_acc_grade','home_ownership_grade','State & Local Spending','Gross State Product','Real State Growth %','Population (million)']\n\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u7d50\u5408\u3057\u305f\u4e0a\u3067RankGauss\u306b\u3088\u308b\u5909\u63db\u3092\u5b9f\u65bd\nX_all = pd.concat([X_train, X_test], axis=0)\nX_all[num_cols] = quantile_transform(X_all[num_cols] ,n_quantiles=100, random_state=0, output_distribution='normal',copy=True)\n\n# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u518d\u5206\u5272\nX_train = X_all.iloc[:X_train.shape[0], :]\nX_test = X_all.iloc[X_train.shape[0]:, :]","b0e9e8ea":"#X_train.to_csv('X_train.csv')\n#X_test.to_csv('X_test.csv')","4faf64d6":"#\u5168\u30c7\u30fc\u30bf\u3067\u5b66\u7fd2(V2)\n#train_x, valid_x, train_y, valid_y = train_test_split(X_train, y_train, test_size=0.33, random_state=71)\n\nclf = LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.9,\n                                importance_type='split', learning_rate=0.05, max_depth=-1,\n                                min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n                                n_estimators=9999, n_jobs=-1, num_leaves=15, objective=None,\n                                random_state=71, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n                                subsample=1.0, subsample_for_bin=200000, subsample_freq=0,num_boost_round=500)\n\n#clf.fit(X_train, y_train, early_stopping_rounds=20, eval_metric='auc')\nclf.fit(X_train, y_train, eval_metric='auc')\n#clf.train(X_train, y_train, eval_metric='auc',num_boost_round=500)\n","54597c65":"#test\u306b\u5bfe\u3057\u3066\u4e88\u6e2c\u3059\u308b\n#clf = GradientBoostingClassifier()\n#clf.fit(X_train, y_train)\n\n#y_pred=gs.predict_proba(X_test)[:,1]\ny_pred = clf.predict_proba(X_test)[:,1]\n","f6742518":"# sample submission\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3001\u4e88\u6e2c\u5024\u3092\u4ee3\u5165\u306e\u5f8c\u3001\u4fdd\u5b58\u3059\u308b\n# \u3053\u3061\u3089\u3082\u30b9\u30e0\u30fc\u30ba\u306a\u9032\u884c\u306e\u305f\u3081\u306b20\u5206\u306e\uff11\u306b\u9593\u5f15\u3044\u3066\u3044\u307e\u3059\u304c\u3001\u672c\u756a\u3067\u306f\"skiprows=lambda x: x%20!=0\"\u3092\u524a\u9664\u3057\u3066\u7528\u3044\u3066\u304f\u3060\u3055\u3044\u3002\nsubmission = pd.read_csv('..\/input\/homework-for-students3\/sample_submission.csv', index_col=0)# ,skiprows=lambda x: x%20!=0)\n\nsubmission.loan_condition = y_pred\nsubmission.to_csv('submission.csv')","27155c38":"imp = DataFrame(clf.booster_.feature_importance(importance_type='gain'), index = X_train.columns, columns=['importance']).sort_values(['importance'], ascending=False)\nimp\n\n#X_train.columns\n\n","aab5ee5d":"df_train[df_train.loan_condition==1].loan_amnt.mean() # \u8cb8\u3057\u5012\u308c\u305f\u30ed\u30fc\u30f3\u306e\u5e73\u5747\u984d\n","46d29b18":"# \u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\n\nscores = []\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nskf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\n\nfor i, (train_ix, test_ix) in tqdm(enumerate(skf.split(X_train, y_train))):\n        X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n        X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n\n        #    skf = StratifiedKFold(n_splits=3, random_state=71, shuffle=True)\n        param_grid = {'learning_rate': [0.05],\n                  'max_depth':  np.linspace(5,12,4,dtype = int),\n                  'colsample_bytree': np.linspace(0.5, 1.0, 3),\n                  'random_state': [71]}\n        \n        fit_params = {\"early_stopping_rounds\": 20,\n                    \"eval_metric\": 'auc',\n                    \"eval_set\": [(X_val, y_val)]}\n        \n        clf  = LGBMClassifier(n_estimators=9999, n_jobs=1)\n\n        gs = GridSearchCV(clf, param_grid, scoring='roc_auc',  \n                              n_jobs=-1, cv=skf, verbose=True)\n        gs.fit(X_train_, y_train_, **fit_params,)\n        y_pred=gs.predict_proba(X_val)[:,1]\n        score = roc_auc_score(y_val, y_pred)\n        scores.append(score)\n        \n        print('CV Score of Fold_%d is %f' % (i, score))\n    \n","8ee86ac6":"\u8cb8\u3057\u5012\u308c\u3066\u306a\u3044\u30ed\u30fc\u30f3\u306e\u5e73\u5747\ndf_train[df_train.loan_condition==0].loan_amnt.mean() # \u8cb8\u3057\u5012\u308c\u3066\u3044\u306a\u3044\u30ed\u30fc\u30f3\u306e\u5e73\u5747\u984d","bae4a61c":"#CV\u3057\u3066\u30b9\u30b3\u30a2\u3092\u898b\u3066\u307f\u308b\u3002\u5c64\u5316\u62bd\u51fa\u3067\u826f\u3044\u304b\u306f\u5225\u9014\u3088\u304f\u8003\u3048\u3066\u307f\u3066\u304f\u3060\u3055\u3044\u300220200327 19:15\n\nscores = []\n\nskf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\nfor i, (train_ix, test_ix) in tqdm(enumerate(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    \n    \n#    clf = GradientBoostingClassifier()\n    clf = LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.9,\n                                importance_type='split', learning_rate=0.05, max_depth=-1,\n                                min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n                                n_estimators=9999, n_jobs=-1, num_leaves=15, objective=None,\n                                random_state=71, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n                                subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n#                                categorical_feature= ['home_ownership', 'annual_inc', 'purpose','addr_state'])    \n#    clf.fit(X_train_, y_train_)\n    clf.fit(X_train_, y_train_, early_stopping_rounds=20, eval_metric='auc', eval_set=[(X_val, y_val)])\n    y_pred = clf.predict_proba(X_val)[:,1]\n    score = roc_auc_score(y_val, y_pred)\n    scores.append(score)\n    \n    print('CV Score of Fold_%d is %f' % (i, score))"}}