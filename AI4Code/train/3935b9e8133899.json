{"cell_type":{"e3f78172":"code","c0ed7df0":"code","1f84ccb1":"code","c8f83718":"code","4f71e302":"code","a533c728":"code","3843d296":"code","d04429ce":"code","eb69b762":"code","a31b521e":"code","42adcc72":"code","144ab090":"code","3a7191eb":"code","cdd9b570":"code","461193a4":"code","acbdb191":"code","b0ed4d4c":"code","01a4dfc9":"code","c853acba":"code","34513af3":"markdown","dfdfad57":"markdown","7671c7be":"markdown","134af9b9":"markdown","e960aced":"markdown","f84be271":"markdown","7b0d7953":"markdown","4be2c6dc":"markdown","f53df928":"markdown","62145fcf":"markdown","dc09fc1e":"markdown","6141c5e8":"markdown","ed38d1f9":"markdown","c4f54e6d":"markdown","764f81ac":"markdown","ee0b6caf":"markdown","23f358a1":"markdown"},"source":{"e3f78172":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.cluster import OPTICS\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndf = pd.read_csv(\"..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv\")\n\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c0ed7df0":"print(df.head(3))\nprint('----------')\nprint('Shape: ',df.shape)\nprint('----------')\nprint(df.dtypes)\nprint('---------- ')\nprint(df.isnull().sum())","1f84ccb1":"for k in range(0,200):\n   if df[\"Gender\"][k] == \"Male\":\n       df[\"Gender\"][k] = 1\n   else :\n       df[\"Gender\"][k] = 0\ndf['Gender'] = df['Gender'].astype('int')\ndel df[\"CustomerID\"]\n","c8f83718":"print(df.corr())","4f71e302":"import seaborn as sns \nsns.set_theme(style=\"whitegrid\")\nax = sns.boxplot(x=df[\"Annual Income (k$)\"])\ndf[\"Annual Income (k$)\"].describe()","a533c728":"zx = sns.boxplot(x=df[\"Spending Score (1-100)\"])\nprint(df[\"Spending Score (1-100)\"].describe())","3843d296":"zx = sns.boxplot(x=df[\"Age\"])\nprint(df[\"Age\"].describe())","d04429ce":"import matplotlib.pyplot as plt\ndf[\"Gender\"].hist()\nplt.show()","eb69b762":"X = np.array(df[[\"Spending Score (1-100)\",\"Annual Income (k$)\",\"Gender\",\"Age\"]])\n\nminpts = [i for i in range(10,51)]\n\nmaxeps = [300]*41\n\nsil = [0]*41\n\nfor k in range(0,len(sil)):\n    if k == 17 or k == 21 or k == 30 or k == 31 or k == 38 or k == 22:\n        continue\n    clustering = OPTICS(min_samples=minpts[k],max_eps=maxeps[k]).fit(X)\n    print(clustering)\n    sil[k] = silhouette_score(X,clustering.labels_)\n\n  \nmaximum = max(sil)\nindex = sil.index(maximum)\nprint(index)\nprint(\"optimal minpts value :\",minpts[index])\nprint(\"optimal silhouette coefficient value :\",sil[index])\n","a31b521e":"X = np.array(df[[\"Spending Score (1-100)\",\"Annual Income (k$)\",\"Gender\"]])\n\nfor k in range(0,len(sil)):\n\n    clustering = OPTICS(min_samples=minpts[k],max_eps=maxeps[k]).fit(X)\n    print(clustering)\n    sil[k] = silhouette_score(X,clustering.labels_)\n\n  \nmaximum = max(sil)\nindex = sil.index(maximum)\nprint(index)\nprint(\"optimal minpts value :\",minpts[index])\nprint(\"optimal silhouette coefficient value :\",sil[index])\n","42adcc72":"X = np.array(df[[\"Spending Score (1-100)\",\"Annual Income (k$)\",\"Age\"]])\nfor k in range(0,len(sil)):\n    if k == 17 or k == 21 or k == 30 or k == 31 or k == 38:\n        continue\n    clustering = OPTICS(min_samples=minpts[k],max_eps=maxeps[k]).fit(X)\n    print(clustering)\n    sil[k] = silhouette_score(X,clustering.labels_)\n\n  \nmaximum = max(sil)\nindex = sil.index(maximum)\nprint(index)\nprint(\"optimal minpts value :\",minpts[index])\nprint(\"optimal silhouette coefficient value\",sil[index])","144ab090":"X = np.array(df[[\"Spending Score (1-100)\",\"Annual Income (k$)\",\"Gender\"]])\nclustering = OPTICS(min_samples=minpts[13],max_eps=maxeps[31]).fit(X)\ncluster = list(clustering.labels_)\nprint(cluster)\n\nvalues, counts = np.unique(cluster, return_counts=True)\nprint(\"cluster number\",len(values))\n\nfor x in range(0,len(values)):\n    if values[x] == -1:\n        print(\"outliers :\",counts[x])\n    else :\n        print(\"cluster\",values[x],\" : \",counts[x])\ndf['class'] = cluster\n","3a7191eb":"colors = {-1:'r', 0:'g',1:'b',2:'#1f77b4',3:'#1f90b1',4:'#1f50b1',5:'#1f60b1'}\n# create a figure and axis\nfig, ax = plt.subplots()\n# plot each data-point\nfor i in range(len(df['class'])):\n   \n  ax.scatter(df['Annual Income (k$)'][i],df['Spending Score (1-100)'][i],color=colors[df[\"class\"][i]])\n# if minmax_df['class'][i] == -1:\n #    class1 = class1 + 1\n# else:\n #    class0 = class0 + 1 \n# set a title and labels\nax.set_title('Mall costumer dataset')\nax.set_xlabel('Annual Income')\nax.set_ylabel('Spending Score')\n#print(\"class 1 : \",class1,\"\\n\")\n#print(\"class 0 : \",class0,\"\\n\")\n","cdd9b570":"X = np.array(df[[\"Annual Income (k$)\",\"Gender\"]])\n\nfor k in range(0,len(sil)):\n    \n    clustering = OPTICS(min_samples=minpts[k],max_eps=maxeps[k]).fit(X)\n    cluster = list(clustering.labels_)   \n    if len(np.unique(cluster)) == 1:\n         \n            continue   \n       \n    sil[k] = silhouette_score(X,clustering.labels_)\n\n\n  \nmaximum = max(sil)\nindex = sil.index(maximum)\nprint(index)\nprint(\"optimal minpts value :\",minpts[index])\nprint(\"optimal silhouette coefficient value :\",sil[index])\n","461193a4":"clustering = OPTICS(min_samples=minpts[13],max_eps=maxeps[31]).fit(X)\ncluster = list(clustering.labels_)\nprint(cluster)\n\nvalues, counts = np.unique(cluster, return_counts=True)\nprint(\"cluster number\",len(values))\n\nfor x in range(0,len(values)):\n    if values[x] == -1:\n        print(\"outliers :\",counts[x])\n    else :\n        print(\"cluster\",values[x],\" : \",counts[x])\n        \ndf['class'] = cluster","acbdb191":"fig,bx = plt.subplots()\n\nfor i in range(len(df['class'])):\n bx.scatter(df['Annual Income (k$)'][i], df['Spending Score (1-100)'][i],color=colors[df['class'][i]])\n\n\nbx.set_title('Mall costumer dataset')\nbx.set_xlabel('Annual Income (k$)')\nbx.set_ylabel('Spending Score (1-100)')","b0ed4d4c":"X = np.array(df[[\"Spending Score (1-100)\",\"Age\"]])\n\nfor k in range(0,len(sil)):\n\n    clustering = OPTICS(min_samples=minpts[k],max_eps=maxeps[k]).fit(X)\n    cluster = list(clustering.labels_) \n    if len(np.unique(cluster)) == 1:\n        \n        continue \n             \n    sil[k] = silhouette_score(X,clustering.labels_)\n    \nmaximum = max(sil)\nindex = sil.index(maximum)\nprint(index)\nprint(\"optimal minpts value :\",minpts[index])\nprint(\"optimal silhouette coefficient :\",sil[index])","01a4dfc9":"clustering = OPTICS(min_samples=minpts[17],max_eps=maxeps[17]).fit(X)\ncluster = list(clustering.labels_)\nprint(cluster)\n\nvalues, counts = np.unique(cluster, return_counts=True)\nprint(\"cluster number\",len(values))\n\nfor x in range(0,len(values)):\n    if values[x] == -1:\n        print(\"outliers :\",counts[x])\n    else :\n        print(\"cluster\",values[x],\" : \",counts[x])\n        \ndf['class'] = cluster","c853acba":"fig,px = plt.subplots()\n\nfor i in range(len(df['class'])):\n px.scatter(df['Age'][i], df['Spending Score (1-100)'][i],color=colors[df['class'][i]])\n\n\npx.set_title('Mall costumer dataset')\npx.set_xlabel('Age')\npx.set_ylabel('Spending score')","34513af3":"We notice that we got 2 clusters green and blue colors while the red points are considered noise by the algorithm. They are not surrounded by enough point in their neighborhood to be considered clusters. They don\u2019t belong either to any border of any core point.\nIt would be interesting to focus on the clients that have an annual income between 40 and 80 ( green cluster ). This cluster is very dense, therefore it would would be good to focus on\nretaining those clients. They also have an interesting spending score\nbetween 40 and 60.\n","dfdfad57":"The cluster 0 is green colored while the red colored points are considered\nnoise by the algorithm. This clustering recommands to focus on the green cluster. the\nannual income of that green population lies within the interval [42,102] which seems to   rather interesting interval. This cluster of individuals contains clients whose spending score    variance is very high as you see the large spread of spending score values of the green cluster. Let\u2019s apply again this procedure to the feature \u201cAge\u201d and \u201cSpending Score\u201d\nThe silhouette coefficient for this configuration is 0.46. This means that the green cluster   is the most import segment to focus on because it\u2019s dense with young clients with very high Spending Score. The marketing team should prioritize the conservation of this segment (people whose age lies from 20 to 42) \n","7671c7be":"First, we import all the necessary data, packages.","134af9b9":"The Annual income values are dispersed within the range [20 k$,120 k$], 50% of the costumers have an annual income lower than 60 k.\n25 % of the customer have an annual income greater than 80 k$","e960aced":"We encode the \"Gender\" boolean variable using two digits ( 1 for \"Male\", 0 for \"Female\" ), and delete the first column since it doesn't help the clustering process.","f84be271":"We tried again with : spending score, annual income, age. This one hasn't shown any improvement.","7b0d7953":"Next we move forward with the feature that gave the highest silhouette coefficient","4be2c6dc":"There are very small signs of correlations.","f53df928":"Next, we try out with other combinations of features","62145fcf":"**INTRODUCTION :**\n\nThis notebook is about clustering the customers using an unsupervised learning technique which is OPTICS, (ordering points to identify the clustering structure), in other words we detect clusters based on density, a groups of data points that are too dense with data are considered clusters. In our case of application, we will detect customers that are sufficiently similar to each others, these segments of customers should be dense enough to be considered as a single cluster. Resource for better understanding : https:\/\/www.geeksforgeeks.org\/ml-optics-clustering-explanation\/","dc09fc1e":"The OPTICS algorithms expects two paramters : \n\nmaxeps : a distance that will be used to detect clusters, the algorithm will check each data point maxeps-neighbors, and if there's enough point in this neighborhood, a cluster will be formed\nminpts : the number of points that should in the maxeps-neighborhood, in order to consider the said points as a cluster.\n\nAfter multiple trials, we decided to run the OPTICS algorithm on a range of minpts values [10,50], we fixed the maxeps parameter.\nFor each configuration, we calculate the silhouette coefficient. We will get 40 different clustering result because we tested with different values of minpts. First we apply this approach on all the feature. We will skip some minpts values since it returns only one cluster which isn't really helpful.\n\nThe configuration that gave the highest silhouette coefficient is the one indexed with 18,\n mintpts = 23\nsilhoutte coefficient = 0.21\n","6141c5e8":"Now we try the same using only : Spending score, Annual Income, Gender.\nThe configuration that gave the highest silhouette coefficient is the one indexed with 13,\nmintpts = 23\nsilhoutte coefficient = 0.26365132840366795\nThe silhouette coefficient improved a little bit\n\n","ed38d1f9":"The spending score values lie within the range [1,100]. It's some sort of metric that tells you how profitable a customer is. The higher it is, the lucrative the costumer is. ","c4f54e6d":"50% of the costumers age are below 36 years, which insinuate that the younger generation are most likely to convert to clients. Therefore we will likely target this age range","764f81ac":"This version gives us a couple clusters by ranges of Annual Income (the green cluster whose customers Spending Score is approximately equally distributed from 1 - 100) the two other clusters has their Spending score centered around 50)","ee0b6caf":"The distribution of Male\/Female among customers","23f358a1":"Next, we try running the algorithm using the two feature Spending Score and age."}}