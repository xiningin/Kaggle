{"cell_type":{"f4fa3d76":"code","d9cf426d":"code","26213efe":"code","d08488e6":"code","9831d252":"code","aadbb03d":"code","07de9b7a":"code","df0add96":"code","e925307a":"code","551ba04e":"code","470efd51":"code","211b86ab":"code","a20e69b8":"code","46edd939":"code","604997da":"code","c39c6dfa":"code","81480ee1":"code","86216420":"code","6e02b305":"code","eb76835c":"code","ada28414":"code","e7724fa6":"code","a1b03909":"code","9259b1b2":"code","d23f5ffe":"code","507cfe3b":"code","32f1860d":"code","1e581050":"code","a9535a29":"code","5409ee9e":"code","5979e6c3":"code","c2e95053":"code","b6b8f257":"code","82febbea":"code","2475e65a":"code","667dbe7e":"code","06723e58":"code","d6e15195":"code","012fbae4":"code","42707f7f":"code","0c38df4c":"markdown","e4f6ce79":"markdown","8a95454e":"markdown","80e34775":"markdown","5f475f67":"markdown","bd6c7ff7":"markdown","e8640e5c":"markdown","ecaea69d":"markdown","13e05e5d":"markdown","3b0a8ee9":"markdown","8c324947":"markdown","f691e65b":"markdown","cde0afbb":"markdown","1e2798f2":"markdown"},"source":{"f4fa3d76":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt  # plotting graphs\nimport seaborn as sns # Seaborn for plotting and styling\nimport math\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d9cf426d":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ncombine = [train, test]","26213efe":"train.head()","d08488e6":"print(train.columns.values)","9831d252":"train.columns","aadbb03d":"#def count_analysis()\n##def create_subplot()\n##def draw_graphs()\n\ncols = ['Pclass', 'Sex', 'SibSp','Survived',\n       'Parch', 'Embarked']\n\nfig,ax = plt.subplots(math.ceil(len(cols)\/3),3,figsize=(20, 12))\nax = ax.flatten()\nfor a,s in zip(ax,cols):\n    sns.countplot(x =s,data = train,palette = \"bright\",ax =a)","07de9b7a":"#def count_analysis()\n##def create_subplot()\n##def draw_graphs()\n\ncols = ['Pclass', 'Sex', 'SibSp',\n       'Parch', 'Embarked']\n\nfig,ax = plt.subplots(math.ceil(len(cols)\/3),3,figsize=(20, 12))\nax = ax.flatten()\nfor a,s in zip(ax,cols):\n    sns.barplot(x =s,y=\"Survived\",data = train,palette = \"bright\",ax =a)","df0add96":"cols = ['Pclass', 'Sex', 'SibSp',\n       'Parch', 'Embarked']\n\nfig,ax = plt.subplots(math.ceil(len(cols)\/3),3,figsize=(20, 12))\nax = ax.flatten()\nfor a,s in zip(ax,cols):\n    sns.countplot(x=s, hue=\"Survived\", data=train,palette = \"bright\",ax =a)","e925307a":"x = pd.Series(train[\"Age\"])","551ba04e":"fig,ax = plt.subplots(figsize=(20, 10)) \nsns.distplot(x, color=\"y\",ax = ax)","470efd51":"train.corr()","211b86ab":"cols = ['Pclass', 'SibSp','Survived','Fare',\n       'Parch']\ncolormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train[cols].astype(float).corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap=colormap, linecolor='white', annot=True)\n","a20e69b8":"print(\"TRAIN DATA\\n\")\ntrain.info()\nprint(\"\\n===================================================\\n\")\nprint(\"TEST DATA\\n\")\ntest.info()","46edd939":"train.describe()","604997da":"# check for na values\nfor col in train.columns:\n    print(\"No. of Na values in \" + str(col) + \" \" + str(len(train[train[col].isnull()])) +'\\n')","c39c6dfa":"imputed_age = float(train['Age'].dropna().median())\nimputed_embarked = train['Embarked'].dropna().mode()[0]\nprint(\"imputed_age : \",imputed_age)\nprint(\"imputed_embarked : \",imputed_embarked)\n","81480ee1":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(imputed_embarked)\n    dataset['Age'] = dataset['Age'].fillna(imputed_age)","86216420":"train.describe(include=['O'])","6e02b305":"#########\n# QC\n\n# check for na values\nfor col in train.columns:\n    print(\"No. of Na values in \" + str(col) + \" \" + str(len(train[train[col].isnull()])) +'\\n')","eb76835c":"combine=[train,test]","ada28414":"for dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)","e7724fa6":"for dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']\n    dataset['Age'] = dataset['Age'].astype(int)\n    \n\n","a1b03909":"train.head()","9259b1b2":"train = train.drop(['Ticket', 'Cabin','Name'], axis=1)\ntest = test.drop(['Ticket', 'Cabin','Name'], axis=1)","d23f5ffe":"test['Fare'].fillna(test['Fare'].dropna().mean(), inplace=True)\n# test.head()","507cfe3b":"train['FareBand'] = pd.qcut(train['Fare'], 5)\ntrain[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","32f1860d":"combine = [train,test]","1e581050":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.854, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 10.5), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 10.5) & (dataset['Fare'] <=  21.679), 'Fare']   = 2\n    dataset.loc[(dataset['Fare'] > 21.679) & (dataset['Fare'] <=  39.688), 'Fare']   = 3\n    dataset.loc[ dataset['Fare'] > 39.688, 'Fare'] = 4\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain = train.drop(['FareBand'], axis=1)","a9535a29":"combine = [train,test]","5409ee9e":"for dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)","5979e6c3":"train.head()","c2e95053":"train_df = train\ntest_df = test\nX_train = train_df.drop(\"Survived\", axis=1)\nX_train = X_train.drop(\"PassengerId\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","b6b8f257":"X_train.head()","82febbea":"X_test.columns","2475e65a":"X_train.info()","667dbe7e":"logreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","06723e58":"svc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","d6e15195":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","012fbae4":"random_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","42707f7f":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })\nsubmission.to_csv('submission_v2.csv', index=False)\n","0c38df4c":"Here's How we will be going with the process flow :\n\n* Import the data\n* Understand and Clean the data\n* Analyse any patterns in the data\n* Model\/ Create a solution\n* Submit your predictions","e4f6ce79":"Age, embarked,Cabin have missing values\nCabin has very less values hence we will discard it\nHence we need to treat Age and embarked\n\n* For treating Age we will replace the missing values with median value\n* For treating embarked we will replace missing values with mode","8a95454e":"Looking at train.head()\n\nCategorical data : \n* Survived\n* Pclass\n* Embarked\n* Sex\n\nNumerical:\n\n* Age\n* Fare\n* SibSp\n* Parch\n\nMixed : \n* Ticket\n* Cabin","80e34775":"### Insights\n\n* Fare and survived have a direct correlation\n* Parch and survived have a direct correlation","5f475f67":"# Bivariate analysis","bd6c7ff7":"### Chances of Error in data capturing\n\n* Typos :  Name column\n* Missing values :  possible in all columns\n* Out of place values : eg survived cannot contain an alphabet\n","e8640e5c":"# The process","ecaea69d":"## Idenntify different data fields, e.g Numerical\/textual\/Categorical etc","13e05e5d":"# Univariate analysis","3b0a8ee9":"#  Importing files and having a first look at the data","8c324947":"## Insight\n- Check for correlation of bucketed values from EDA\n\ne.g Pclass 1 is more likely to survive and females are more likely to survive","f691e65b":"The basic logic that we will be following in this notebook is to find a pattern.\n\nIn order to find a pattern in  a problem , the most important thing is to know the problem statement and its data fields inside out.\nHence we will try to to do an EDA in the following cells.","cde0afbb":"### Look for missing values","1e2798f2":"# Clean the data"}}