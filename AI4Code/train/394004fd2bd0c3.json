{"cell_type":{"d6e3d472":"code","6658bd11":"code","01707fda":"code","31838120":"code","bdaff6e0":"code","83866284":"code","2b392b6e":"code","b420094e":"code","f0350e36":"code","5fc1db02":"code","2e545389":"code","1993b5f8":"code","58b9af16":"code","06708079":"code","18836482":"code","e179e819":"code","7c03c4c6":"code","f0fd3c44":"code","23817c71":"code","8a8e9498":"code","81708872":"code","40309d20":"code","dd2e21c5":"code","9ff12550":"code","5edf19e5":"code","5bcd6c5f":"code","9e84c650":"code","97022c5e":"code","09a549d0":"code","a06e341f":"code","12156459":"code","833761ab":"markdown","91e28d33":"markdown","f96ca60f":"markdown","158e2ce6":"markdown","8f15d9b4":"markdown","e53ba4b0":"markdown","3b509859":"markdown","c3eed42a":"markdown","c1b5e2ec":"markdown","fa8a9eb8":"markdown","5418e115":"markdown","d6c54b80":"markdown","f64bdd0a":"markdown","ef270b1f":"markdown","3258afab":"markdown","e4a5ea07":"markdown","217a43be":"markdown","649a4671":"markdown","e9240b9b":"markdown","ebc9008a":"markdown","271eb985":"markdown"},"source":{"d6e3d472":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6658bd11":"data = pd.read_csv(\"..\/input\/customer-personality-analysis\/marketing_campaign.csv\", sep='\\t', index_col= 'ID')","01707fda":"data.head()","31838120":"data.shape","bdaff6e0":"data.isnull().sum()","83866284":"data = data.dropna()\ndata.head()","2b392b6e":"from datetime import date\n#age = map(lambda x: date.today().year - x, data['Year_Birth'])\n#data['Age'] = data.Year_birth.map(lambda x = date.today().year - data.Year_birth)\n\ndef get_age(birthyear):\n    return date.today().year - birthyear\n\n# ages = data.Year_Birth.map(get_age)\n\ndata[\"Age\"] = data.Year_Birth.apply(get_age)\n\ndata.Age.describe()\n","b420094e":"data.sort_values('Year_Birth')","f0350e36":"#data[data.Year_Birth < 1900].drop(axis = 0)\ndata.drop([11004, 1150, 7829], inplace = True)\n\n","5fc1db02":"data.columns","2e545389":"data['Spending'] = data.MntWines + data.MntFruits + data.MntMeatProducts + data.MntFishProducts + data.MntSweetProducts + data.MntGoldProds\ndata['Time_With_Company'] = pd.to_datetime(data.Dt_Customer, dayfirst = True, format = '%d-%m-%Y')\ndata['Time_With_Company'] = pd.to_numeric(data.Time_With_Company.dt.date.apply(lambda z: (date.today() - z)).dt.days, downcast = 'integer') \/ 30","1993b5f8":"data.head()","58b9af16":"data.Education.unique()","06708079":"data.Marital_Status.unique()","18836482":"data.Marital_Status = data.Marital_Status.replace({\"Divorced\": \"Single\", \"Together\": \"Partner\",\"Married\": \"Partner\", \"Widow\": \"Single\", \"Alone\": \"Single\", \"Absurd\": \"Single\",\"YOLO\": \"Single\"})\n#data.head()","e179e819":"data.head()","7c03c4c6":"data['Children'] = data.Kidhome + data.Teenhome\ndata['Has_Child'] = np.where(data.Children > 0, 'Has Child', 'No Child')\ndata.tail()","f0fd3c44":"data= data.rename(columns = { \"MntWines\": \"Wine\",\n                              \"MntFruits\": \"Fruit\",\n                              \"MntMeatProducts\": \"Meat\",\n                              \"MntFishProducts\": \"Fish\",\n                              \"MntSweetProducts\" : \"Sweets\",\n                              \"MntGoldProds\": \"Gold\"})\ndata.head()","23817c71":"data =data.rename(columns = {\"NumWebPurchases\" : \"Web\",\n                             \"NumCatalogPurchases\" : \"Catalog\",\n                             \"NumStorePurchases\" : \"Store\",\n                             \"NumWebVisitsMonth\" : \"WebVisits\"})\n","8a8e9498":"data.Web.describe()","81708872":"#data.groupby('Web').count()\ndata.Web.value_counts()","40309d20":"outlier_IDs = data.loc[data.Web > 20].index\ndata.drop(outlier_IDs, inplace = True)\ndata.Web.value_counts()","dd2e21c5":"#data.Catalog.unique()\ndata.Catalog.describe()\n","9ff12550":"x= data.loc[data.Catalog > 20].index\ndata.drop(x, inplace = True)","5edf19e5":"data.Store.describe()\ndata.Store.value_counts()","5bcd6c5f":"data= data[[ \"Education\", \"Marital_Status\", \"Has_Child\", \"Children\", \"Age\", \"Income\", \"Spending\", \"Time_With_Company\", \"Wine\", \"Fruit\", \"Meat\", \"Sweets\", \"Gold\", \"Web\", \"Catalog\", \"Store\", \"WebVisits\"]]","9e84c650":"data.head()","97022c5e":"import seaborn as sns\nsns.countplot(data.Education).set(title = \"Education level of Customer\")\n#sns.title = \"Education level of Customer\"","09a549d0":"sns.countplot(data.Marital_Status).set(title  = \"Marital Status\")","a06e341f":"sns.countplot(data.Has_Child).set(title = \"Child status of Customer\")","12156459":"sns.histplot(data.Age, color = 'midnightblue').set(title = \"Ages of Customers\", ylabel = None, xlabel = \"Age\")\nprint(\"The Average Age of our customer is\", round(np.mean(data.Age)), 'year \\n')","833761ab":"Lets now take a look at the Education feature. This will allow us to better understand the demographic of customer base.\n\n","91e28d33":"Seems like we have some outlier values, lets remove them.\n\n","f96ca60f":"Lets group together our clean dataframe and select the columns we wish to analyze.\n\n","158e2ce6":"An overwhelming majority of customers have at least one child. Now what about the age of our customers?\n\n","8f15d9b4":"Next we \nwant to get a better idea of the ages of our customers. We do not currently have an Age column in our dataframe so lets create one using the Year_Birth feature.\n\n","e53ba4b0":"There are only a few unique values for this feature so we can leave it be. Lets do the same with the Marital_Status feature now.\n\n","3b509859":"Finally, lets rename some of our column names.\n\n","c3eed42a":"# Customer Personality Analysis\nThis Project is my Learning Project. This project shows the basic information regarding Customers like The Average Age of our customer,  Child status of Customer etc. \nThis project is mainly for learning Cleaning and Transformation of Data. It was a great learning for me.","c1b5e2ec":"it seems that some users are extremely old, the oldest customer is 128 years old! This data might be incorrect. Lets take a closer look.\n\n","fa8a9eb8":"Seems like we have a larger number of unique values for this column. Some of these values are similar in definition so lets group them togheter to make our analysis easier.\n\n","5418e115":"Seems like a majority of customers have a graduate degree (Bachelor's). It also seems like the second highest group includes customers with PhD's. Lets look at marital status now.\n\n","d6c54b80":"Next lets create some new features in our dataframe. The first being a total sum of all the spending for each customer titled Spending. We will also create another feature that includes the number of months each customer has been with the company. This will allow us to cluster the customers in groups of new and old as well as big and small spenders.\n\n","f64bdd0a":"# Data Preperation and Cleaning\n","ef270b1f":"The age of our customers varies over a wide range. However it seems like most of our customers are middle aged (40-60 years).\n\n","3258afab":"Seems like the number of customers in a relationship is almost double the number of single customers. This could be useful for marketing purposes. Let's move on to the child status of our customers.\n\n","e4a5ea07":"seems as if our missing values are only in the Income column. This could correspond to customers with no income so imputation would not make sense here. This dataset is large enough where we can omit these rows.\n\n","217a43be":"We will do the same for the Catalog and Store columns\n\n","649a4671":"Lets create some new features regarding the children of the customers\n\n","e9240b9b":"### Lets take a look at the values for web purchases\n\n","ebc9008a":"We observe that we have three customers who were born in the 19th century. Surely this cannot be correct. Lets drop these rows.\n\n","271eb985":"# Analysis"}}