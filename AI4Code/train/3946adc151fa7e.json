{"cell_type":{"1731bdd1":"code","cdb1c9cd":"code","80e0ebb5":"code","a58a5158":"code","cb44ca9e":"code","737b8554":"code","ae63bb89":"code","c1647bac":"code","258358a5":"code","ba64e50a":"code","f78f6180":"code","c38a7dfd":"code","38aa41a6":"code","26239fa7":"code","fbaf80ea":"code","44c632ff":"code","a261737b":"code","87b91a62":"code","38fff5ad":"code","6df75c4a":"code","168cf357":"markdown"},"source":{"1731bdd1":"import numpy as np, seaborn as sns, pandas as pd, matplotlib.pyplot as plt, os, cv2, tensorflow as tf, keras, math","cdb1c9cd":"train = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv')","80e0ebb5":"size, n_channels = 227, 3\nos.chdir('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/')\nX = np.zeros((train.shape[0], size, size, n_channels), dtype=np.int16)\nfor i, image_name in enumerate(train.image_id.values): #this will take sometime to finish\n    X[i] = cv2.resize(plt.imread(image_name+'.jpg'), (size, size)).astype(np.int16)","a58a5158":"fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 13))\nfor i, axis in enumerate(ax.flatten()): #these images are from the real training data\n    axis.imshow(X[i])\n    axis.title.set_text(train.columns[1:][np.argmax(train.iloc[i, 1:].values)])\n\n","cb44ca9e":"images={ 'healthy': [], 'multiple_diseases': [], 'rust': [], 'scab': [] }\n       \nsub_folders=['Apple___healthy', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___Apple_scab']\nfor folder in ['color']:#you can add 'segmented' in the list to add more images\n    for sub_f in sub_folders:\n        os.chdir('\/kaggle\/input\/plantvillage-dataset\/'+folder+'\/'+sub_f)\n        for image_name in os.listdir()[:500]:# remove the slicing [:500] if you want to add all images, here we took 500 images per target\n            if 'healthy' in sub_f:\n                images['healthy'].append(cv2.resize(plt.imread(image_name), (size, size)).astype(np.int16))\n            elif 'rot' in sub_f:\n                images['multiple_diseases'].append(cv2.resize(plt.imread(image_name), (size, size)).astype(np.int16))\n            elif 'rust' in sub_f:\n                images['rust'].append(cv2.resize(plt.imread(image_name), (size, size)).astype(np.int16))\n            else:\n                images['scab'].append(cv2.resize(plt.imread(image_name), (size, size)).astype(np.int16))","737b8554":"y = train.iloc[:, 1:].values\ntarget_to_one_hot_vec = {'healthy':np.array([1, 0, 0, 0]), 'multiple_diseases':np.array([0, 1, 0, 0]),\n                        'rust':np.array([0, 0, 1, 0]), 'scab':np.array([0, 0, 0, 1])}\ntotal_images=0\nfor key in ['healthy', 'multiple_diseases', 'rust', 'scab']:\n    total_images += len(images[key])\ntotal_images += X.shape[0]\nprint('Total Number of images is :', total_images)\ndata_x = np.zeros((total_images, )+X.shape[1:])\ndata_y = np.zeros((total_images, 4))\ndata_x[:X.shape[0]] = X.copy()\ndata_y[:y.shape[0]] = y.copy()\ni = X.shape[0]-1\nfor key in ['healthy', 'multiple_diseases', 'rust', 'scab']:\n    for img in images[key]:\n        i +=1\n        data_x[i] = img\n        data_y[i] = target_to_one_hot_vec[key]","ae63bb89":"fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 13))\nfor i, axis in enumerate(ax.flatten()): #these images are from the external dataset\n    axis.imshow(images[list(images.keys())[i]][int(np.random.randint(0, 250, 1))])\n    axis.title.set_text(list(images.keys())[i])\n","c1647bac":"reset_selective images #write yes and hit enter when the input box shows up this will remove the variable images from the RAM","258358a5":"reset_selective X #write yes and hit enter when the input box shows up this will remove the variable X from the RAM","ba64e50a":"plt.subplots(figsize=(12, 7))\nplt.xlabel('Epoch')\nplt.ylabel('Learning Rate')\nplt.title('Learning Schedule')\nlrs= []\nfor epoch in range(1, 61):\n    cos_inner = (math.pi * (epoch % 61)) \/ (61)\n    lrs.append(5e-4\/2 * (math.cos(cos_inner) + 1))\nsns.lineplot(x=list(range(1, 61)), y=lrs)","f78f6180":"import math\ngen = keras.preprocessing.image.ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=180,\n                         zoom_range=.1, width_shift_range=.2, height_shift_range=.2)\nmc = keras.callbacks.ModelCheckpoint(filepath='\/kaggle\/working\/model.h5',  verbose=True, save_best_only=True)#For saving the model when the val_loss goes down\n\ndef aggressive_lrs(epoch, _):\n    cos_inner = (math.pi * (epoch % 61)) \/ (61)\n    return 5e-4\/2 * (math.cos(cos_inner) + 1) #initial learning rate is 5e-4\n \nlr = keras.callbacks.LearningRateScheduler(aggressive_lrs)","c38a7dfd":"indices = pd.Series(np.round(np.linspace(0, data_x.shape[0]-1, data_x.shape[0])))\ntrain_indices = indices.sample(3200).values.astype(np.int16)\ntest_indices = np.array([i for i in indices if i not in train_indices]).astype(np.int16)\n#3200 training images, about 400 validation_indices","38aa41a6":"os.chdir('\/kaggle\/working\/')\n!git clone https:\/\/github.com\/qubvel\/efficientnet.git\nimport efficientnet.efficientnet.keras as efn\nmd  = efn.EfficientNetB6(weights='imagenet', include_top=False, input_shape=(size, size, 3), pooling='avg')","26239fa7":"model = keras.models.Sequential([md,\n                                 keras.layers.Dense(900, activation='relu'),\n                                 keras.layers.Dense(800, activation='relu'),\n                                 keras.layers.Dense(4, activation='softmax')\n                                ])\nmodel.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(), metrics=['accuracy'])","fbaf80ea":"model.fit_generator(gen.flow(data_x[train_indices], data_y[train_indices], batch_size=8), epochs=60, \n                    steps_per_epoch=111, validation_data=(data_x[test_indices], data_y[test_indices]), \n                    callbacks=[mc, lr])","44c632ff":"reset_selective data_x #write yes and hit enter when the input box shows up this will remove the variable data_x from the RAM","a261737b":"os.chdir('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/')\nX_test = np.zeros((test.shape[0], size, size, n_channels), dtype=np.int16)\nfor i, image_name in enumerate(test.image_id.values): #this will take sometime to finish\n    X_test[i] = cv2.resize(plt.imread(image_name+'.jpg'), (size, size)).astype(np.int16)","87b91a62":"os.chdir('\/kaggle\/working\/')\nmdl = keras.models.load_model('model.h5')\ny_preds = mdl.predict(X_test)","38fff5ad":"os.chdir('\/kaggle\/input\/plant-pathology-2020-fgvc7\/')\nsb = pd.read_csv('sample_submission.csv')\nsb.iloc[:, 1:] = y_preds","6df75c4a":"from IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"SubmitMe.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n# create a random sample dataframe\ndf = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n\n# create a link to download the dataframe\ncreate_download_link(sb)\n\n# \u2193 \u2193 \u2193  Yay, download link! \u2193 \u2193 \u2193 ","168cf357":"**My Approach : **\nBefore I start coding I'd Like share with you my approach and the methods I've used to get .971 on the evaluation metric in **Plant Pathology 2020 - FGVC7 Competition**, so let's get started \nFirst of all I've built manually a Network (Depthwise Layers + Conv Layers) and it was much faster in the training and gived better results than using Conv layers alone about 2% improvement and evalutation metric of roughly .85 that was my base model at first then I've tried bunch of techniques on the base model and they didn't improve that much, I applied a learning schedule and it made about 1% improvment , Test Time Augmentation (TTA) about .08% improvment also Snapshot Ensembling did a .08% improvement so the best result on evaluation metric was .86 that wasn't that good so i switched to Transfer Learning then I've found new dataset in kaggle that is representative of the training data so I've used it with an EfficientNetB6 Model and after trial and error the evaluation metric went from .86 to .94+ and after Ensembling it with other two convolutional based models the results were 97.1, here we gonna train the B6 Model since it gived me the best result compared to the two other models and it had .966 on the evaluation metric, the problem is by adding the external data to the training it'll exceed the available RAM so I didn't use all the external data rather I've added about 2000 more images and I've removed the variables that we have already used ( removing the large size variables once we are done with them ) so we don't exceed the RAM, that's the external data that you need to add to the notebook https:\/\/www.kaggle.com\/xabdallahali\/plantvillage-dataset\n"}}