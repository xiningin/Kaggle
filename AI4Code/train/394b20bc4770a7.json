{"cell_type":{"8100d374":"code","832141a2":"code","a8c6ee7a":"code","3673ea59":"code","071f6810":"code","12a19f4d":"code","d71d64b3":"code","0d4a6d2c":"code","76686a06":"code","0f559bd5":"code","32841fe1":"code","30db3377":"code","85a73b46":"code","de227e44":"code","9a409a53":"code","670d9b57":"code","4de317d0":"code","1bcbec4b":"code","43c9bb18":"code","0865926d":"code","0f974715":"code","72e1684e":"code","09265269":"code","b0ff8e25":"code","0cc7fb6e":"code","9a4d5ee5":"code","c7e58996":"code","8e1d6c97":"code","af86c6ce":"code","524728ed":"code","ec3efd2c":"code","e3377738":"code","ea412572":"code","0083a781":"code","3c81e2ce":"code","aa2319e8":"code","6d443905":"code","f7d10349":"code","2c093d8a":"code","76e29563":"code","c5106373":"code","727dcf5a":"code","2fd603f0":"code","ab61ad9c":"code","1a6716ed":"code","95d25b06":"code","676ed0e3":"code","3b42fc8e":"code","bf2d2138":"code","3fbccdc5":"code","55c62080":"code","05e97f29":"markdown","18f05715":"markdown","ed314d09":"markdown","b8fcdac9":"markdown","21c00d07":"markdown","c887a8a2":"markdown","9dba20f2":"markdown","cf9dd893":"markdown","905d6ece":"markdown","281b48f1":"markdown","5ab2de39":"markdown","4ff62b3a":"markdown","2868493a":"markdown","3f003f18":"markdown","7313088d":"markdown","270c169c":"markdown","2707b6ea":"markdown","480de9ee":"markdown","528636bc":"markdown","4ffbd94c":"markdown","04aa4204":"markdown","9438a682":"markdown","212ecd45":"markdown","dc409687":"markdown","07da423b":"markdown","fa60103f":"markdown","8e77cc3d":"markdown","94b903ef":"markdown","6bd651e6":"markdown","b071d65b":"markdown","1e24a384":"markdown","a672fe93":"markdown","9b968fe4":"markdown","6cd3b8ac":"markdown","3fe54e28":"markdown","3b3c0917":"markdown","261b6c63":"markdown","aacab4b2":"markdown","336e1fd8":"markdown"},"source":{"8100d374":"#regular imports\nimport numpy as np\nimport pandas as pd\n\n\n#visualizations\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\n#time series import \nimport statsmodels.api as sm\n\n#statistics\nfrom scipy import stats","832141a2":"df = pd.read_csv(\"..\/input\/bitcoin-historical-data\/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv\")","a8c6ee7a":"df.head()","3673ea59":"df.describe()","071f6810":"df.info()","12a19f4d":"sns.set(rc = {'figure.figsize':(15,8)})\nsns.heatmap(df.isna(),cmap=\"viridis\",yticklabels=False)","d71d64b3":"#run some auto visualization tool to see graphics of data no need to understand now\n!pip install git+git:\/\/github.com\/AutoViML\/AutoViz.git\n!pip install xlrd","0d4a6d2c":"from autoviz.AutoViz_Class import AutoViz_Class\n\nAV = AutoViz_Class()\ndftc = AV.AutoViz(\n    filename='', \n    sep='' , \n    depVar='Close', \n    dfte=df, \n    header=0, \n    verbose=1, \n    lowess=False, \n    chart_format='png', \n    max_rows_analyzed=300000,\n    max_cols_analyzed=30\n)","76686a06":"from pandas_profiling import ProfileReport\nreport = ProfileReport(df)\nreport","0f559bd5":"df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='s')\ndf.set_index(df['Timestamp'], inplace=True)","32841fe1":"df.head()","30db3377":"# our target is to predict the closing price of bitcoin \n# so we are not gonna give importance to the other fields as of now \ndata = df.copy()\ndata['Volume_(BTC)'].fillna(method='ffill', inplace=True)\ndata['Volume_(Currency)'].fillna(method='ffill', inplace=True)\ndata['Weighted_Price'].fillna(method='ffill', inplace=True)\ndata['Open'].fillna(method='ffill', inplace=True)\ndata['High'].fillna(method='ffill', inplace=True)\ndata['Low'].fillna(method='ffill', inplace=True)\ndata['Close'].fillna(method='ffill', inplace=True)\n\n# check how we are looking now, should be nice and clean...\ndata.head()","85a73b46":"# Resampling to Daily frequency\ndata_day = data.resample('D').mean()\n\n# Resampling to monthly frequency\ndata_month = data.resample('M').mean()\n\n# Resampling to Hourly frequency\ndata_hour = data.resample('H').mean()\n\n# Resampling to annual frequency\ndata_year = data.resample('A-DEC').mean()\n\n# Resampling to quarterly frequency\ndata_Q = data.resample('Q-DEC').mean()","de227e44":"seaborn_plot_data = data_day[[\"Open\",\"High\",\"Low\",\"Close\"]]\nsns.lineplot(data=seaborn_plot_data)","9a409a53":"px.line(seaborn_plot_data, x = seaborn_plot_data.index, y = seaborn_plot_data.columns)","670d9b57":"def frequency_bitcoin_plot(df,frequency):\n    \n\n    # Initialize figure with subplots\n    fig = make_subplots(\n        rows=2, cols=2, subplot_titles=(\"Open\", \"High\", \"Low\", \"Close\")\n    )\n\n    # Add traces\n    fig.add_trace(go.Scatter(x=df.index, y=df.Open,name=\"Open\"), row=1, col=1)\n    fig.add_trace(go.Scatter(x=df.index, y=df.High, name=\"High\"), row=1, col=2)\n    fig.add_trace(go.Scatter(x=df.index, y=df.Low, name=\"Low\"), row=2, col=1)\n    fig.add_trace(go.Scatter(x=df.index, y=df.Close, name=\"Close\"), row=2, col=2)\n\n    # Update xaxis properties\n    fig.update_xaxes(title_text=\"TimeStamp\", row=1, col=1)\n    fig.update_xaxes(title_text=\"TimeStamp\", row=1, col=2)\n    fig.update_xaxes(title_text=\"TimeStamp\", row=2, col=1)\n    fig.update_xaxes(title_text=\"TimeStamp\", row=2, col=2)\n\n    # Update yaxis properties\n    fig.update_yaxes(title_text=\"Open\", row=1, col=1)\n    fig.update_yaxes(title_text=\"High\", row=1, col=2)\n    fig.update_yaxes(title_text=\"Low\", row=2, col=1)\n    fig.update_yaxes(title_text=\"Close\", row=2, col=2)\n\n    # Update title and height\n    fig.update_layout(title_text=f\"Open High Low Close Value of Bitcoin With {frequency} Frquency\", height=700)\n\n    fig.show()","4de317d0":"seaborn_plot_data_month = data_month[[\"Open\",\"High\",\"Low\",\"Close\"]]\nseaborn_plot_data_Hour = data_hour[[\"Open\",\"High\",\"Low\",\"Close\"]]\nseaborn_plot_data_year = data_year[[\"Open\",\"High\",\"Low\",\"Close\"]]\nseaborn_plot_data_Q = data_Q[[\"Open\",\"High\",\"Low\",\"Close\"]]","1bcbec4b":"frequency_bitcoin_plot(seaborn_plot_data_Hour,\"hour\")","43c9bb18":"frequency_bitcoin_plot(seaborn_plot_data,\"day\")","0865926d":"frequency_bitcoin_plot(seaborn_plot_data_month,\"month\")","0f974715":"frequency_bitcoin_plot(seaborn_plot_data_Q,\"Quater\")","72e1684e":"frequency_bitcoin_plot(seaborn_plot_data_year,\"year\")","09265269":"seasonal_data = seaborn_plot_data_month.copy()\n","b0ff8e25":"seasonal_data['Timestamp'] = seasonal_data.index","0cc7fb6e":"seasonal_data['year'] = pd.DatetimeIndex(seasonal_data['Timestamp']).year\nseasonal_data['month'] = pd.DatetimeIndex(seasonal_data['Timestamp']).month\nseasonal_data['quarter'] = pd.PeriodIndex(seasonal_data.Timestamp, freq='Q')\nseasonal_data.head()","9a4d5ee5":"p1_pivot = pd.pivot_table(seasonal_data, values='Open', index=['month'],\n                    columns=['year'], aggfunc=np.mean)\np2_pivot = pd.pivot_table(seasonal_data, values='Close', index=['month'],\n                    columns=['year'], aggfunc=np.mean)\np3_pivot = pd.pivot_table(seasonal_data, values='High', index=['month'],\n                    columns=['year'], aggfunc=np.mean)\np4_pivot = pd.pivot_table(seasonal_data, values='Low', index=['month'],\n                    columns=['year'], aggfunc=np.mean)","c7e58996":"pivot_list = [p1_pivot, p2_pivot, p3_pivot, p4_pivot]\nfor pivot_choice in pivot_list:\n    pivot_choice['Max'] = pivot_choice.iloc[:,-5:].max(axis=1)\n    pivot_choice['Min'] = pivot_choice.iloc[:,-5:].min(axis=1)\n    pivot_choice['5 Year Avg'] = pivot_choice.iloc[:,-5:].mean(axis=1)\n    pivot_choice['7 Year Avg'] = pivot_choice.iloc[:,-5:].mean(axis=1)\n    ","8e1d6c97":"# SHOWS ALL LINES\n# Set up Figure\np1_fig = go.Figure()\np2_fig = go.Figure()\np3_fig = go.Figure()\np4_fig = go.Figure()\np5_fig = go.Figure()\ntotal_fig = go.Figure()\n\n# Set up lists to iterate through\nfig_list = [p1_fig, p2_fig, p3_fig, p4_fig]\npivot_list = [p1_pivot, p2_pivot, p3_pivot, p4_pivot]\ntitle_list = ['Open','Close','High',\n              'Low']\n\n# Set the colors for the lines\n#colors = ['#17becf','#e377c2','#ff7f0e','#2ca02c']\n\n# Create x-axis labels for the months\nmonths = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n\n# Create the Graphs\nfor j in range(4):\n    data = pivot_list[j]\n\n    fig_list[j].add_trace(go.Scatter(x=months, y=data['Max'],\n        fill=None,\n        mode=None,\n        line_color='lightgray', showlegend=False\n        ))\n    fig_list[j].add_trace(go.Scatter(x=months, y=data['Min'],\n        fill='tonexty', # fill area between trace0 and trace1\n        mode=None, line_color='lightgray', showlegend=False))\n\n    fig_list[j].add_trace(go.Scatter(x=months, y=data['5 Year Avg'], name='5 Year Avg',\n                                 line=dict(color='black', width=4, dash='dot')))\n    fig_list[j].add_trace(go.Scatter(x=months, y=data['7 Year Avg'], name='7 Year Avg',\n                                 line=dict(color='grey', width=4, dash='dashdot')))\n\n    for i in range(1,10):\n        fig_list[j].add_trace(go.Scatter(x=months, y=data.iloc[:,i], name=data.columns[i],\n                                 line=dict(width=4)))         #color=colors[i],\n\n    fig_list[j].update_layout(title=title_list[j],\n                       xaxis_title='Month',\n                       yaxis_title='Price Unit', template='plotly_white')\n    \n# Show all the graphs\np1_fig.show()\np2_fig.show()\np3_fig.show()\np4_fig.show()","af86c6ce":"#our target data\ndata_day[\"Close\"][:5]","524728ed":"data_day[\"Close\"]=data_day[\"Close\"].fillna(method=\"ffill\")","ec3efd2c":"plt.figure(figsize=[15,7])\nsm.tsa.seasonal_decompose(data_day[\"Close\"]).plot()\nprint(\"Dickey\u2013Fuller test: p=%f\" % sm.tsa.stattools.adfuller(data_day[\"Close\"])[1])\nplt.show()","e3377738":"# Seasonal differentiation\ndata_day[\"Close_season_diff_1\"] = data_day[\"Close\"] - data_day[\"Close\"].shift(12)\nprint(\"Dickey\u2013Fuller test: p=%f\" % sm.tsa.stattools.adfuller(data_day.Close_season_diff_1[12:])[1])","ea412572":"# Regular differentiation\ndata_day[\"Close_diff_1\"] = data_day[\"Close\"] - data_day[\"Close\"].shift(1)\nplt.figure(figsize=(15,7))\n\n# STL-decomposition\nsm.tsa.seasonal_decompose(data_day[\"Close_diff_1\"][13:]).plot()   \nprint(\"Dickey\u2013Fuller test: p=%f\" % sm.tsa.stattools.adfuller(data_day[\"Close_diff_1\"][13:])[1])\n\nplt.show()","0083a781":"data_day[\"Close\"]","3c81e2ce":"import numpy as np, pandas as pd\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'figure.figsize':(9,7), 'figure.dpi':120})\n\n\n# Original Series\nfig, axes = plt.subplots(3, 2, sharex=True)\naxes[0, 0].plot(data_day[\"Close\"]); axes[0, 0].set_title('Original Series')\nplot_acf(data_day[\"Close\"], ax=axes[0, 1])\n\n# 1st Differencing\naxes[1, 0].plot(data_day[\"Close\"].diff()); axes[1, 0].set_title('1st Order Differencing')\nplot_acf(data_day[\"Close\"].diff().dropna(), ax=axes[1, 1])\n\n# 2nd Differencing\naxes[2, 0].plot(data_day[\"Close\"].diff().diff()); axes[2, 0].set_title('2nd Order Differencing')\nplot_acf(data_day[\"Close\"].diff().diff().dropna(), ax=axes[2, 1])\n\nplt.show()","aa2319e8":"# Initial approximation of parameters using Autocorrelation and Partial Autocorrelation Plots\nplt.figure(figsize=(15,7))\nax = plt.subplot(211)\nsm.graphics.tsa.plot_acf(data_day[\"Close_diff_1\"][13:].values.squeeze(), lags=48, ax=ax)\nax = plt.subplot(212)\nsm.graphics.tsa.plot_pacf(data_day[\"Close_diff_1\"][13:].values.squeeze(), lags=48, ax=ax)\nplt.tight_layout()\nplt.show()","6d443905":"from itertools import product\n# Initial approximation of parameters\nQs = range(0, 2)\nqs = range(0, 3)\nPs = range(0, 3)\nps = range(0, 3)\nD=1\nd=1\nparameters = product(ps, qs, Ps, Qs)\nparameters_list = list(parameters)\nlen(parameters_list)\n","f7d10349":"from statsmodels.tsa.arima_model import ARIMA\n\n# 1,1,2 ARIMA Model\nmodel = ARIMA(data_day[\"Close\"], order=(1,1,2))\nmodel_fit = model.fit(disp=0)\nprint(model_fit.summary())","2c093d8a":"# Plot residual errors\nresiduals = pd.DataFrame(model_fit.resid)\nfig, ax = plt.subplots(1,2)\nresiduals.plot(title=\"Residuals\", ax=ax[0])\nresiduals.plot(kind='kde', title='Density', ax=ax[1])\nplt.show()","76e29563":"# Actual vs Fitted\nmodel_fit.plot_predict(dynamic=False)\nplt.show()","c5106373":"# Model Selection\nresults = []\nbest_aic = float(\"inf\")\nfor param in parameters_list:\n    try:\n        model=sm.tsa.statespace.SARIMAX(data_day[\"Close\"], order=(param[0], d, param[1]), \n                                        seasonal_order=(param[2], D, param[3], 12)).fit(disp=-1)\n    except ValueError:\n        print('wrong parameters:', param)\n        continue\n    aic = model.aic\n    if aic < best_aic:\n        best_model = model\n        best_aic = aic\n        best_param = param\n    results.append([param, model.aic])","727dcf5a":"# Best Models\nresult_table = pd.DataFrame(results)\nresult_table.columns = ['parameters', 'aic']\nprint(result_table.sort_values(by = 'aic', ascending=True).head())\nprint(best_model.summary())","2fd603f0":"# STL-decomposition\nplt.figure(figsize=(15,7))\nplt.subplot(211)\nbest_model.resid[13:].plot()\nplt.ylabel(u'Residuals')\nax = plt.subplot(212)\nsm.graphics.tsa.plot_acf(best_model.resid[13:].values.squeeze(), lags=48, ax=ax)\n\nprint(\"Dickey\u2013Fuller test:: p=%f\" % sm.tsa.stattools.adfuller(best_model.resid[13:])[1])\n\nplt.tight_layout()\nplt.show()","ab61ad9c":"# Create train and test splits the right way for time series data\nsplit_size = int(0.8 * len(data_day[\"Close\"])) # 80% train, 20% test\n\n# Create train data splits (everything before the split)\nX_train, y_train = data_day.index[:split_size], data_day[\"Close\"][:split_size]\n\n# Create test data splits (everything after the split)\nX_test, y_test = data_day.index[split_size:], data_day[\"Close\"][split_size:]\n\nlen(X_train), len(X_test), len(y_train), len(y_test)","1a6716ed":"X_train","95d25b06":"# Plot correctly made splits\nplt.figure(figsize=(10, 7))\nplt.scatter(X_train, y_train, s=5, label=\"Train data\")\nplt.scatter(X_test, y_test, s=5, label=\"Test data\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"BTC Price\")\nplt.legend(fontsize=14)\nplt.show();","676ed0e3":"# Create a function to plot time series data\ndef plot_time_series(timesteps, values, format='.', start=0, end=None, label=None):\n  \"\"\"\n  Plots a timesteps (a series of points in time) against values (a series of values across timesteps).\n  \n  Parameters\n  ---------\n  timesteps : array of timesteps\n  values : array of values across time\n  format : style of plot, default \".\"\n  start : where to start the plot (setting a value will index from start of timesteps & values)\n  end : where to end the plot (setting a value will index from end of timesteps & values)\n  label : label to show on plot of values\n  \"\"\"\n  # Plot the series\n  plt.plot(timesteps[start:end], values[start:end], format, label=label)\n  plt.xlabel(\"Time\")\n  plt.ylabel(\"BTC Price\")\n  if label:\n    plt.legend(fontsize=14) # make label bigger\n  plt.grid(True)","3b42fc8e":"# Try out our plotting function\nplt.figure(figsize=(10, 7))\nplot_time_series(timesteps=X_train, values=y_train, label=\"Train data\")\nplot_time_series(timesteps=X_test, values=y_test, label=\"Test data\")","bf2d2138":"naive_forecast = y_test[:-1]","3fbccdc5":"# Plot naive forecast\nplt.figure(figsize=(10, 7))\nplot_time_series(timesteps=X_train, values=y_train, label=\"Train data\")\nplot_time_series(timesteps=X_test, values=y_test, label=\"Test data\")\nplot_time_series(timesteps=X_test[1:], values=naive_forecast, format=\"-\", label=\"Naive forecast\");","55c62080":"plt.figure(figsize=(10, 7))\noffset = 300 # offset the values by 300 timesteps \nplot_time_series(timesteps=X_test, values=y_test, start=offset, label=\"Test data\")\nplot_time_series(timesteps=X_test[1:], values=naive_forecast, format=\"-\", start=offset, label=\"Naive forecast\");","05e97f29":"# let's plot all the values in different graph ","18f05715":"# Auto Vizualization","ed314d09":"# Basic Information About The Dataset\n* We are not going to repeat the value we got from pandas profilling or Autoviz\n\n* We will analyze missing values and different plots of the data.","b8fcdac9":"* ARIMA, short for \u2018Auto Regressive Integrated Moving Average\u2019 is actually a class of models that \u2018explains\u2019 a given time series based on its own past values, that is, its own lags and the lagged forecast errors, so that equation can be used to forecast future values.\n\n* Any \u2018non-seasonal\u2019 time series that exhibits patterns and is not a random white noise can be modeled with ARIMA models.\n\n* ACF and PACF plots determines the value of p,q,d in case of time-series in ARIMA ","21c00d07":"##  What can be forecast?\nForecasting is required in many situations: deciding whether to build another power generation plant in the next five years requires forecasts of future demand; scheduling staff in a call centre next week requires forecasts of call volumes; stocking an inventory requires forecasts of stock requirements. Forecasts can be required several years in advance (for the case of capital investments), or only a few minutes beforehand (for telecommunication routing). Whatever the circumstances or time horizons involved, forecasting is an important aid to effective and efficient planning.\n\nThe predictability of an event or a quantity depends on several factors including:\n\n* how well we understand the factors that contribute to it;\n* how much data is available;\n* how similar the future is to the past;\n* whether the forecasts can affect the thing we are trying to forecast.\n\nIn this NoteBook, we will learn how to tell the difference between a random fluctuation in the past data that should be ignored, and a genuine pattern that should be modelled and extrapolated.","c887a8a2":"## Differenciation seasonal","9dba20f2":"# Time Series Forecasting Methods\n","cf9dd893":"# Naive Forecast ","905d6ece":"* The series is not stationary","281b48f1":"In describing these time series, we have used words such as \u201ctrend\u201d and \u201cseasonal\u201d which need to be defined more carefully.\n\n### Trend\nA trend exists when there is a long-term increase or decrease in the data. It does not have to be linear. Sometimes we will refer to a trend as \u201cchanging direction,\u201d when it might go from an increasing trend to a decreasing trend. There is a trend in our data that starts from 2016 Dec and again from 2020 Dec.\n### Seasonal\nA seasonal pattern occurs when a time series is affected by seasonal factors such as the time of the year or the day of the week. Seasonality is always of a fixed and known period.\n### Cyclic\nA cycle occurs when the data exhibit rises and falls that are not of a fixed frequency. These fluctuations are usually due to economic conditions, and are often related to the \u201cbusiness cycle.\u201d The duration of these fluctuations is usually at least 2 years.","5ab2de39":"* It is the same data but see how frequency changes its variation and makes it a smoother plot for understanding.\n* We can see there is a steep slope in the time series from Dec 2020 to Dec 2021\n* Another price increase in the series is from Dec 2016 to Dec 2018.\n* Upto Dec 2016 there was no such big breakthrough in Bitcoin Domain.","4ff62b3a":"* The series is stationary but i think it is overdifferenciate ","2868493a":"# Day-Wise Variation Of Bitcoin intraday price","3f003f18":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7313088d":"# Quaterly Variation Of Bitcoin intraday price","270c169c":"# Hourly Variation Of Bitcoin intraday price","2707b6ea":"# Visualization","480de9ee":"# Creating Test train dataset","528636bc":"# Yearly Variation Of Bitcoin intraday price","4ffbd94c":"# ARIMA Model ","04aa4204":"## General Manupulation","9438a682":"Let us visualize the test and train data for our time series forecast","212ecd45":"## Let's see the stationarity of the dataset","dc409687":"* So for a lot of timestamp in the beginning and middle all the variable data is missing ","07da423b":"* Nothing is clear\n* The value remains close for all the variables\n* There is a huge increase in all the prices in 2018 and 2021 with 2018 peak to be lower than 2021.","fa60103f":"### What is Seasonality?\nSeasonality is repeated patterns or variations that occur in time series data. These patterns can occur across any interval of time \u2014 hourly, daily, monthly, yearly, etc. For example, gasoline demand goes up during the summer in the United States because people take road trips during their summer vacation. Therefore, energy companies know they have to supply more gasoline to the US in the summer compared to other seasons. This information is necessary for business planning. Weather is another classic example of seasonality \u2014 hotter during the summer, colder during the winter. Hurricane season occurs every year from June through November.\n\n##### Does Our data have any Seasonality Effect?","8e77cc3d":"# Month Variation Of Bitcoin intraday price","94b903ef":"## Types of Forecasting\n\n* **Short-term forecasts**\nare needed for the scheduling of personnel, production and transportation. As part of the scheduling process, forecasts of demand are often also required.\n* **Medium-term forecasts**\nare needed to determine future resource requirements, in order to purchase raw materials, hire personnel, or buy machinery and equipment.\n* **Long-term forecasts**\nare used in strategic planning. Such decisions must take account of market opportunities, environmental factors and internal resources.","6bd651e6":"# Different Models:\n* Time series Models\n* Explanatory Models\n* Mixed Models","b071d65b":"* 5 years average shows that the price was higher at around march.\n* Range is quite high for march it is as high as 54k and as low as 39k \n* Most of the First values of the graph comes from our filling methods which can give us some mising information.","1e24a384":"* point to be remember . we have df and data seperated anytime we want to change our direction we can simply grab the df and make changes.","a672fe93":"# Determining what to forecast?\n\nIn the early stages of a forecasting project, decisions need to be made about what should be forecast. For example, if forecasts are required for items in a manufacturing environment, it is necessary to ask whether forecasts are needed for:\n\n* every product line, or for groups of products?\n* every sales outlet, or for outlets grouped by region, or only for total sales?weekly data, monthly data or annual data?\n* It is also necessary to consider the forecasting horizon. Will forecasts be required for one month in advance, for 6 months, or for ten years? Different types of models will be necessary, depending on what forecast horizon is most important.\n\n* How frequently are forecasts required? Forecasts that need to be produced frequently are better done using an automated system than with methods that require careful manual work.\n\nIt is worth spending time talking to the people who will use the forecasts to ensure that you understand their needs, and how the forecasts are to be used, before embarking on extensive work in producing the forecasts.","9b968fe4":"# Forecsting\n\n#### This NoteBook contains single solution to all the forecasting problems with solutions ranging from statistical analysis and upto deep learning method.\n\n##### Don't hesitate to give a Thumb's up if this helps you. ","6cd3b8ac":"The appropriate forecasting methods depend largely on what data are available.\n\nIf there are no data available, or if the data available are not relevant to the forecasts, then qualitative forecasting methods must be used. These methods are not purely guesswork\u2014there are well-developed structured approaches to obtaining good forecasts without using historical data. These methods are discussed in Chapter 6.\n\nQuantitative forecasting can be applied when two conditions are satisfied:\n\nnumerical information about the past is available;\nit is reasonable to assume that some aspects of the past patterns will continue into the future.\nThere is a wide range of quantitative forecasting methods, often developed within specific disciplines for specific purposes. Each method has its own properties, accuracies, and costs that must be considered when choosing a specific method.\n\nMost quantitative prediction problems use either time series data (collected at regular intervals over time) or cross-sectional data (collected at a single point in time).","3fe54e28":"## Resample to generate dataset of different frequency","3b3c0917":"## Create a timeseries data plotting function","261b6c63":"* Alot of missing values.","aacab4b2":"# General ARIMA MODEL ","336e1fd8":"* We have successfully converted our data into a time-series data \n* our next task will be to fill the missing value \n* Then we will visualize the plot on different time frequency"}}