{"cell_type":{"c7efe1eb":"code","584c432c":"code","65958d11":"code","c175820b":"code","1b0c9444":"code","189f6ef4":"code","7ede6660":"code","64a613dd":"code","c038359c":"code","f62a6650":"code","4dace49c":"code","e5d97492":"code","93b55d22":"code","d5287259":"code","c7300afb":"code","d1459fa9":"code","4682beba":"markdown","b102d744":"markdown","63a9faed":"markdown","fc31264e":"markdown","07225452":"markdown","99d0fa02":"markdown","7cf0465c":"markdown","eaefda4f":"markdown","b356079f":"markdown"},"source":{"c7efe1eb":"#Add library that need to kernel \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n# filter warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","584c432c":"# Import data\ndata_x = np.load(\"..\/input\/sign-language-digits-dataset\/Sign-language-digits-dataset\/X.npy\")\ndata_y = np.load(\"..\/input\/sign-language-digits-dataset\/Sign-language-digits-dataset\/Y.npy\")","65958d11":"# Visualize to samples\nimg_size = 64\nplt.subplot(1, 3, 1)\nplt.imshow(data_x[200].reshape(img_size, img_size))\nplt.axis('off')\nplt.subplot(1, 3, 2)\nplt.imshow(data_x[800].reshape(img_size, img_size))\nplt.axis('off')\nplt.subplot(1, 3, 3)\nplt.imshow(data_x[600].reshape(img_size, img_size))\nplt.axis('off')","c175820b":"# Train-Test Split\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.2, random_state=42)","1b0c9444":"# Size of elements of train_test_split methods\nprint(\"x train shape: {}\".format(x_train.shape))\nprint(\"y train shape: {}\".format(y_train.shape))\nprint(\"x test shape: {}\".format(x_test.shape))\nprint(\"y test shape: {}\".format(y_test.shape))","189f6ef4":"# Reshaping. We reshape x_train and x_test because Keras requires 3 dimention.\nx_train = x_train.reshape(-1,64,64,1)\nx_test = x_test.reshape(-1,64,64,1)\n\n# New size of x_train and x_shape\nprint(\"x train shape: {}\".format(x_train.shape))\nprint(\"x test shape: {}\".format(x_test.shape))","7ede6660":"#Add library that need to creating Model\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau","64a613dd":"# building of our model\nmodel = Sequential()\n\n# we add convolutional layer, count of filter = 64, kernel_size means that dimension of filter.\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (64,64,1))) \n# dimension of (64,64,1) is 3 because kernel requires 3 dimensions. Number \"1\" shows that it is used as gray scale. \nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25)) \n\n# we rewrite the top one. We don't have to write input shape because these are things that are connected to each other like chains.\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3), padding = 'Same', activation = 'relu'))\nmodel.add(MaxPool2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\n\n# fully connected\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dense(512, activation = 'relu'))\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dense(10, activation = 'softmax')) \n# although sigma function is used for binary classification, softmax is a version of sigma function which is used for multi-output classification.","c038359c":"model.summary()","f62a6650":"# defining optimizer\noptimizer = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999)","4dace49c":"# compiling model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","e5d97492":"# fitting\nhistory = model.fit(x_train,y_train,epochs=100,validation_data=(x_test,y_test))","93b55d22":"scores = model.evaluate(x_test, y_test, verbose=0)\nprint(\"{}: {:.2f}%\".format(\"accuracy\", scores[1]*100))","d5287259":"plt.figure(figsize=[10,6])\nplt.plot(history.history[\"accuracy\"], label = \"Train acc\")\nplt.plot(history.history[\"val_accuracy\"], label = \"Validation acc\")\nplt.legend()\nplt.show()","c7300afb":"plt.figure(figsize=[10,6])\nplt.plot(history.history[\"loss\"], label = \"loss\")\nplt.plot(history.history[\"val_loss\"], label = \"Validation loss\")\nplt.legend()\nplt.show()","d1459fa9":"from sklearn.metrics import confusion_matrix\n\ny_head = model.predict(x_test)\n\ncnf_matrix= confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_head, axis=1))\nclass_names=[0,1,2,3,4,5,6,7,8,9]\n\nfig, ax = plt.subplots(figsize=(10,10))\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"Purples\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion Matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","4682beba":"### Model Evaluation","b102d744":"### Building Model","63a9faed":"### Defining and Compiling of Optimizer","fc31264e":"### Visualize","07225452":"### Train-Test Split","99d0fa02":"# Convolutional Neural Networks","7cf0465c":"### Creating Model","eaefda4f":"### Reshaping","b356079f":"### \u0130mport Data"}}