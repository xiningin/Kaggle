{"cell_type":{"98dd40d5":"code","090aaafc":"code","95dd2b08":"code","e57d1d3a":"code","1324665e":"code","1df2c1cf":"code","85d6b8e6":"code","e912a599":"code","69709a90":"code","a2e5d6a3":"code","7fff0b80":"code","b46a1ea5":"code","5eed8071":"code","92cdf219":"code","d5f0a68e":"code","c443193c":"code","b2a77d24":"code","701406e5":"code","36006b9f":"markdown","9a878ef6":"markdown","86b6019b":"markdown","f6351266":"markdown","ff6cb51a":"markdown","fc4dae04":"markdown","e2c3b3ac":"markdown","d4930ee1":"markdown","1caa87b2":"markdown","8426a5e1":"markdown","408a9f75":"markdown","12034569":"markdown"},"source":{"98dd40d5":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = '.\/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n\nTRAIN_PATH = '..\/input\/ranzcr-clip-catheter-line-classification\/train'","090aaafc":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    debug=False\n    \n    batch_size=8 # 64\n    gradient_accumulation_steps=8\n    \n    nprocs=1 # [1, 8]\n    seed=35\n    trn_fold=[0] # [0, 1, 2, 3, 4]\n    device='GPU' # ['TPU', 'GPU']\n    epochs=5\n    student='..\/input\/ranzcr3stepsmodelweightsv0fold0\/fold0\/resnet200d_fold0_best_loss_cpu.pth'\n    print_freq=10\n    num_workers=4\n    model_name='resnet200d'\n    size=512\n    scheduler='CosineAnnealingWarmRestarts' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n#     teacher='..\/input\/tra-ranzcr-resnet200d-step1-3\/resnet200d_fold4_best_loss_cpu.pth'\n    #factor=0.2 # ReduceLROnPlateau\n    #patience=4 # ReduceLROnPlateau\n    #eps=1e-6 # ReduceLROnPlateau\n    T_max=5 # CosineAnnealingLR\n    T_0=5 # CosineAnnealingWarmRestarts\n    lr=5e-4 # 1e-4\n    min_lr=1e-6\n    weight_decay=1e-6\n    max_grad_norm=1000\n    target_size=11\n    target_cols=['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal',\n                 'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal', \n                 'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal',\n                 'Swan Ganz Catheter Present']\n    n_fold=5\n    train=True\n    \n","95dd2b08":"if CFG.device == 'TPU':\n    import os\n    os.system('curl https:\/\/raw.githubusercontent.com\/pytorch\/xla\/master\/contrib\/scripts\/env-setup.py -o pytorch-xla-env-setup.py')\n    os.system('python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev')\n    os.system('export XLA_USE_BF16=1')\n    import torch_xla.core.xla_model as xm\n    import torch_xla.distributed.parallel_loader as pl\n    import torch_xla.distributed.xla_multiprocessing as xmp\n    CFG.lr = CFG.lr * CFG.nprocs\n    CFG.batch_size = CFG.batch_size \/\/ CFG.nprocs","e57d1d3a":"# ====================================================\n# Library\n# ====================================================\nimport sys\nsys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')\nsys.path.insert(0,'..\/input\/timm-nfnet')\nimport timm\n\nimport os\nimport ast\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.utils import check_random_state\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nfrom albumentations import (\n    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n    IAAAdditiveGaussianNoise, Transpose, HueSaturationValue, CoarseDropout\n    )\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nif CFG.device == 'TPU':\n    import ignite.distributed as idist\nelif CFG.device == 'GPU':\n    from torch.cuda.amp import autocast, GradScaler\n\nimport warnings \nwarnings.filterwarnings('ignore')","1324665e":"from torch.autograd import Variable","1df2c1cf":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    scores = []\n    for i in range(y_true.shape[1]):\n        score = roc_auc_score(y_true[:,i], y_pred[:,i])\n        scores.append(score)\n    avg_score = np.mean(scores)\n    return avg_score, scores\n\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    LOGGER.info(f'[{name}] start')\n    yield\n    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n\n\ndef init_logger(log_file=OUTPUT_DIR+'train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()\n\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","85d6b8e6":"train = pd.read_csv('..\/input\/ranzcr-clip-catheter-line-classification\/train.csv')\nfolds = pd.read_csv('..\/input\/how-to-properly-split-folds\/train_ctrlung_rskfolds.csv')\ntrain_annotations = pd.read_csv('..\/input\/ranzcr-clip-catheter-line-classification\/train_annotations.csv')\n\nif CFG.debug:\n    CFG.epochs = 1\n    train = train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)","e912a599":"# ====================================================\n# Dataset\n# ====================================================\nclass TrainDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['StudyInstanceUID'].values\n        self.labels = df[CFG.target_cols].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names[idx]\n        file_path = f'{TRAIN_PATH}\/{file_name}.jpg'\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        label = torch.tensor(self.labels[idx]).float()\n        return image, label","69709a90":"# ====================================================\n# Transforms\n# ====================================================\ndef get_transforms(*, data):\n    \n    if data == 'train':\n        return Compose([\n            #Resize(CFG.size, CFG.size),\n            RandomResizedCrop(CFG.size, CFG.size, scale=(0.85, 1.0)),\n            HorizontalFlip(p=0.5),\n            RandomBrightnessContrast(p=0.2, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2)),\n            HueSaturationValue(p=0.2, hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2),\n            ShiftScaleRotate(p=0.2, shift_limit=0.0625, scale_limit=0.2, rotate_limit=20),\n            CoarseDropout(p=0.2),\n            Cutout(p=0.2, max_h_size=16, max_w_size=16, fill_value=(0., 0., 0.), num_holes=16),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n        ])\n\n    elif data == 'valid':\n        return Compose([\n            Resize(CFG.size, CFG.size),\n            Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            ToTensorV2(),\n\n        ])","a2e5d6a3":"from matplotlib import pyplot as plt\n\ntrain_dataset = TrainDataset(train, transform=get_transforms(data='train'))\n\nfor i in range(5):\n    image, label = train_dataset[i]\n    plt.imshow(image[0])\n    plt.title(f'label: {label}')\n    plt.show() ","7fff0b80":"# ====================================================\n# MODEL\n# ====================================================\nclass CustomResNet200D(nn.Module):\n    def __init__(self, model_name='resnet200d_320', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False)\n        if pretrained:\n            pretrained_path = '..\/input\/resnet200d-pretrained-weight\/resnet200d_ra2-bdba9bf9.pth'\n            self.model.load_state_dict(torch.load(pretrained_path))\n            print(f'load {model_name} pretrained model')\n        n_features = self.model.fc.in_features\n        self.model.global_pool = nn.Identity()\n        self.model.fc = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(n_features, CFG.target_size)\n\n    def forward(self, x):\n        bs = x.size(0)\n        features = self.model(x)\n        pooled_features = self.pooling(features).view(bs, -1)\n        output = self.fc(pooled_features)\n        return features, pooled_features, output","b46a1ea5":"# ====================================================\n# Helper functions\n# ====================================================\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s \/ 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s \/ (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    if CFG.device == 'GPU':\n        scaler = GradScaler()\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to train mode\n    model.train()\n    start = end = time.time()\n    global_step = 0\n    for step, (images, labels) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        if CFG.device == 'GPU':\n            with autocast():\n                _, _, y_preds = model(images)\n                loss = criterion(y_preds, labels)\n                # record loss\n                losses.update(loss.item(), batch_size)\n                if CFG.gradient_accumulation_steps > 1:\n                    loss = loss \/ CFG.gradient_accumulation_steps\n                scaler.scale(loss).backward()\n                grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n                if (step + 1) % CFG.gradient_accumulation_steps == 0:\n                    scaler.step(optimizer)\n                    scaler.update()\n                    optimizer.zero_grad()\n                    global_step += 1\n        elif CFG.device == 'TPU':\n            _, _, y_preds = model(images)\n            loss = criterion(y_preds, labels)\n            # record loss\n            losses.update(loss.item(), batch_size)\n            if CFG.gradient_accumulation_steps > 1:\n                loss = loss \/ CFG.gradient_accumulation_steps\n            loss.backward()\n            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n            if (step + 1) % CFG.gradient_accumulation_steps == 0:\n                xm.optimizer_step(optimizer, barrier=True)\n                optimizer.zero_grad()\n                global_step += 1\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if CFG.device == 'GPU':\n            if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n                print('Epoch: [{0}][{1}\/{2}] '\n                      'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n                      'Elapsed {remain:s} '\n                      'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                      'Grad: {grad_norm:.4f}  '\n                      #'LR: {lr:.6f}  '\n                      .format(\n                       epoch+1, step, len(train_loader), batch_time=batch_time,\n                       data_time=data_time, loss=losses,\n                       remain=timeSince(start, float(step+1)\/len(train_loader)),\n                       grad_norm=grad_norm,\n                       #lr=scheduler.get_lr()[0],\n                       ))\n        elif CFG.device == 'TPU':\n            if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n                xm.master_print('Epoch: [{0}][{1}\/{2}] '\n                                'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n                                'Elapsed {remain:s} '\n                                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                                'Grad: {grad_norm:.4f}  '\n                                #'LR: {lr:.6f}  '\n                                .format(\n                                epoch+1, step, len(train_loader), batch_time=batch_time,\n                                data_time=data_time, loss=losses,\n                                remain=timeSince(start, float(step+1)\/len(train_loader)),\n                                grad_norm=grad_norm,\n                                #lr=scheduler.get_lr()[0],\n                                ))\n    return losses.avg\n\n\ndef valid_fn(valid_loader, model, criterion, device):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to evaluation mode\n    model.eval()\n    trues = []\n    preds = []\n    start = end = time.time()\n    for step, (images, labels) in enumerate(valid_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        # compute loss\n        with torch.no_grad():\n            _, _, y_preds = model(images)\n        loss = criterion(y_preds, labels)\n        losses.update(loss.item(), batch_size)\n        # record accuracy\n        trues.append(labels.to('cpu').numpy())\n        preds.append(y_preds.sigmoid().to('cpu').numpy())\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss \/ CFG.gradient_accumulation_steps\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if CFG.device == 'GPU':\n            if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n                print('EVAL: [{0}\/{1}] '\n                      'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n                      'Elapsed {remain:s} '\n                      'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                      .format(\n                       step, len(valid_loader), batch_time=batch_time,\n                       data_time=data_time, loss=losses,\n                       remain=timeSince(start, float(step+1)\/len(valid_loader)),\n                       ))\n        elif CFG.device == 'TPU':\n            if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n                xm.master_print('EVAL: [{0}\/{1}] '\n                                'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n                                'Elapsed {remain:s} '\n                                'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                                .format(\n                                step, len(valid_loader), batch_time=batch_time,\n                                data_time=data_time, loss=losses,\n                                remain=timeSince(start, float(step+1)\/len(valid_loader)),\n                                ))\n    trues = np.concatenate(trues)\n    predictions = np.concatenate(preds)\n    return losses.avg, predictions, trues","5eed8071":"import torch, sys, os, pdb\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass FocalLoss2(nn.Module):\n    \n    def __init__(self, gamma = 2.0):\n        super(FocalLoss2, self).__init__()\n        self.gamma = gamma\n        self.eps = 1e-6\n        \n#         self.BCE_loss = nn.BCEWithLogitsLoss(reduction='none')\n        \n    def forward(self, inputs, targets):\n        \n        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n#         BCE_loss = self.BCE_loss(input, target)\n        pt = torch.exp(-BCE_loss) # prevents nans when probability 0\n        F_loss =  (1-pt)**self.gamma * BCE_loss\n        \n        return F_loss.mean() ","92cdf219":"class FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.logits = logits\n        self.reduce = reduce\n\n    def forward(self, inputs, targets):\n        #print(inputs.shape)\n       # print(targets.shape)\n        if self.logits:\n            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n        else:\n            BCE_loss = F.binary_cross_entropy(inputs, targets, reduction='none')\n        #print(BCE_loss.shape)\n\n        pt = torch.exp(-BCE_loss)\n        \n       # print(pt.shape)\n        \n        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n        #print(F_loss.shape)\n        if self.reduce:\n            print(torch.mean(F_loss))\n            return torch.mean(F_loss)\n        else:\n            return torch.sum(F_loss)","d5f0a68e":"# ====================================================\n# Train loop\n# ====================================================\ndef train_loop(folds, fold):\n\n    if CFG.device == 'GPU':\n        LOGGER.info(f\"========== fold: {fold} training ==========\")\n    elif CFG.device == 'TPU':\n        if CFG.nprocs == 1:\n            LOGGER.info(f\"========== fold: {fold} training ==========\")\n        elif CFG.nprocs == 8:\n            xm.master_print(f\"========== fold: {fold} training ==========\")\n\n    # ====================================================\n    # loader\n    # ====================================================\n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n\n    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n    valid_labels = valid_folds[CFG.target_cols].values\n\n    train_dataset = TrainDataset(train_folds, \n                                 transform=get_transforms(data='train'))\n    valid_dataset = TrainDataset(valid_folds, \n                                 transform=get_transforms(data='valid'))\n\n    if CFG.device == 'GPU':\n        train_loader = DataLoader(train_dataset, \n                                  batch_size=CFG.batch_size, \n                                  shuffle=True, \n                                  num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n        valid_loader = DataLoader(valid_dataset, \n                                  batch_size=CFG.batch_size * 2, \n                                  shuffle=False, \n                                  num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    elif CFG.device == 'TPU':\n        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset,\n                                                                        num_replicas=xm.xrt_world_size(),\n                                                                        rank=xm.get_ordinal(),\n                                                                        shuffle=True)\n        train_loader = torch.utils.data.DataLoader(train_dataset,\n                                                   batch_size=CFG.batch_size,\n                                                   sampler=train_sampler,\n                                                   drop_last=True,\n                                                   num_workers=CFG.num_workers)\n        valid_sampler = torch.utils.data.distributed.DistributedSampler(valid_dataset,\n                                                                        num_replicas=xm.xrt_world_size(),\n                                                                        rank=xm.get_ordinal(),\n                                                                        shuffle=False)\n        valid_loader = torch.utils.data.DataLoader(valid_dataset,\n                                                   batch_size=CFG.batch_size * 2,\n                                                   sampler=valid_sampler,\n                                                   drop_last=False,\n                                                   num_workers=CFG.num_workers)\n\n    # ====================================================\n    # scheduler \n    # ====================================================\n    def get_scheduler(optimizer):\n        if CFG.scheduler=='ReduceLROnPlateau':\n            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n        elif CFG.scheduler=='CosineAnnealingLR':\n            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n        return scheduler\n\n    # ====================================================\n    # model & optimizer\n    # ====================================================\n    if CFG.device == 'TPU':\n        device = xm.xla_device()\n    elif CFG.device == 'GPU':\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    model = CustomResNet200D(CFG.model_name, pretrained=False)\n    model.load_state_dict(torch.load(CFG.student, map_location=torch.device('cpu'))['model'])\n    model.to(device)\n\n    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n    scheduler = get_scheduler(optimizer)\n   \n    #criterion = nn.BCEWithLogitsLoss()\n    criterion = FocalLoss2()\n    \n    LOGGER.info(f\"========== Ready to Train {fold} ==========\")\n    # ====================================================\n    # loop\n    # ====================================================\n\n    best_score = 0.\n    best_loss = np.inf\n    \n    for epoch in range(CFG.epochs):\n        \n        start_time = time.time()\n        \n        # train\n        if CFG.device == 'TPU':\n            if CFG.nprocs == 1:\n                avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n            elif CFG.nprocs == 8:\n                para_train_loader = pl.ParallelLoader(train_loader, [device])\n                avg_loss = train_fn(para_train_loader.per_device_loader(device), model, criterion, optimizer, epoch, scheduler, device)\n        elif CFG.device == 'GPU':\n            avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n                \n        # eval\n        if CFG.device == 'TPU':\n            if CFG.nprocs == 1:\n                avg_val_loss, preds, _ = valid_fn(valid_loader, model, criterion, device)\n            elif CFG.nprocs == 8:\n                para_valid_loader = pl.ParallelLoader(valid_loader, [device])\n                avg_val_loss, preds, valid_labels = valid_fn(para_valid_loader.per_device_loader(device), model, criterion, device)\n                preds = idist.all_gather(torch.tensor(preds)).to('cpu').numpy()\n                valid_labels = idist.all_gather(torch.tensor(valid_labels)).to('cpu').numpy()\n        elif CFG.device == 'GPU':\n            avg_val_loss, preds, _ = valid_fn(valid_loader, model, criterion, device)\n        \n        if isinstance(scheduler, ReduceLROnPlateau):\n            scheduler.step(avg_val_loss)\n        elif isinstance(scheduler, CosineAnnealingLR):\n            scheduler.step()\n        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n            scheduler.step()\n\n        # scoring\n        score, scores = get_score(valid_labels, preds)\n\n        elapsed = time.time() - start_time\n\n        if CFG.device == 'GPU':\n            LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n            LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {np.round(scores, decimals=4)}')\n        elif CFG.device == 'TPU':\n            if CFG.nprocs == 1:\n                LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n                LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {np.round(scores, decimals=4)}')\n            elif CFG.nprocs == 8:\n                xm.master_print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n                xm.master_print(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {np.round(scores, decimals=4)}')\n        \n        if score > best_score:\n            best_score = score\n            if CFG.device == 'GPU':\n                LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n                torch.save({'model': model.state_dict(), \n                            'preds': preds},\n                           OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth')\n            elif CFG.device == 'TPU':\n                if CFG.nprocs == 1:\n                    LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n                elif CFG.nprocs == 8:\n                    xm.master_print(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n                xm.save({'model': model, \n                         'preds': preds}, \n                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth')\n        \n        if avg_val_loss < best_loss:\n            best_loss = avg_val_loss\n            if CFG.device == 'GPU':\n                LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n                torch.save({'model': model.state_dict(), \n                            'preds': preds},\n                           OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_loss.pth')\n            elif CFG.device == 'TPU':\n                if CFG.nprocs == 1:\n                    LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n                elif CFG.nprocs == 8:\n                    xm.master_print(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n                xm.save({'model': model, \n                         'preds': preds}, \n                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_loss.pth')\n    \n    if CFG.nprocs != 8:\n        check_point = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth')\n        for c in [f'pred_{c}' for c in CFG.target_cols]:\n            valid_folds[c] = np.nan\n        valid_folds[[f'pred_{c}' for c in CFG.target_cols]] = check_point['preds']\n\n    return valid_folds","c443193c":"# ====================================================\n# main\n# ====================================================\ndef main():\n\n    \"\"\"\n    Prepare: 1.train  2.folds\n    \"\"\"\n\n    def get_result(result_df):\n        preds = result_df[[f'pred_{c}' for c in CFG.target_cols]].values\n        labels = result_df[CFG.target_cols].values\n        score, scores = get_score(labels, preds)\n        LOGGER.info(f'Score: {score:<.4f}  Scores: {np.round(scores, decimals=4)}')\n    \n    if CFG.train:\n        # train \n        oof_df = pd.DataFrame()\n        for fold in range(CFG.n_fold):\n            if fold in CFG.trn_fold:\n                _oof_df = train_loop(folds, fold)\n                oof_df = pd.concat([oof_df, _oof_df])\n                if CFG.nprocs != 8:\n                    LOGGER.info(f\"========== fold: {fold} result ==========\")\n                    get_result(_oof_df)\n                    \n        if CFG.nprocs != 8:\n            # CV result\n            LOGGER.info(f\"========== CV ==========\")\n            get_result(oof_df)\n            # save result\n            oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)","b2a77d24":"if __name__ == '__main__':\n    if CFG.device == 'TPU':\n        def _mp_fn(rank, flags):\n            torch.set_default_tensor_type('torch.FloatTensor')\n            a = main()\n        FLAGS = {}\n        xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=CFG.nprocs, start_method='fork')\n    elif CFG.device == 'GPU':\n        main()","701406e5":"# save as cpu\nif CFG.device == 'TPU':\n    for fold in range(CFG.n_fold):\n        if fold in CFG.trn_fold:\n            # best score\n            state = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score.pth')\n            torch.save({'model': state['model'].to('cpu').state_dict(), \n                        'preds': state['preds']}, \n                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_score_cpu.pth')\n            # best loss\n            state = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_loss.pth')\n            torch.save({'model': state['model'].to('cpu').state_dict(), \n                        'preds': state['preds']}, \n                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best_loss_cpu.pth')","36006b9f":"# Version Info\n* V1: Initial copy, seed = 32 fold = 0 {CV=0.9504 LB=0.957}    \n* V3: seed = 35, fold = 1 {CV=0.9522 LB=0.955}    \n* V4: seed = 35, fold = 2 {CV=0.9486 LB=0.955}      \n* V5: seed = 35, fold = 3 {CV=0.9520 LB=0.960}      \n* V6: seed = 35, fold = 4 {CV=0.9464 LB=0.956}        \n\n## \u5f00\u59cb\u8bd5\u9a8c\u4e0d\u540c\u7684\u8bad\u7ec3\u65b9\u6cd5\u548c\u6570\u636e\u589e\u5f3a\u65b9\u6848\n\n* V9: seed = 35, fold = 4, FocalLoss, gradient_accumulation_steps=8 {CV=0.9560}                            \n> HeavyAug\u5df2\u8bc1\u660e\u6548\u679c\u5f88\u5dee\uff0c\u540e\u7eed\u5c31\u4e0d\u5728\u8bd5\u9a8c\u8fd9\u79cd\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u4e86\n* V14: seed = 35, fold = 3, FocalLoss, gradient_accumulation_steps=8 {CV=0.9493}                   \n> TPU\u663e\u5b58\u4e0d\u591f\uff0c\u8f93\u5165\u7684batch\u7531 8 * 8 \u6539\u6210 1 * 64     \n> \u6539\u56deGPU 8 * 8\n* V15: seed = 35, fold = 1, FocalLoss, gradient_accumulation_steps=8 {CV=0.9565}       \n* V16: seed = 35, fold = 0, FocalLoss, gradient_accumulation_steps=8 {CV=0.9591}           ","9a878ef6":"# Helper functions","86b6019b":"# Train loop","f6351266":"# Data Loading","ff6cb51a":"# Dataset","fc4dae04":"# Directory settings","e2c3b3ac":"# Utils","d4930ee1":"# Transforms","1caa87b2":"# About this notebook\n\u5229\u7528annotation data\u8fdb\u884c\u4e09\u9636\u6bb5\u7684\u5bf9\u6bd4\u5b66\u4e60\u7684training notebook - Step 2    \ncopied from: https:\/\/www.kaggle.com\/c\/ranzcr-clip-catheter-line-classification\/discussion\/207577    \n## Training strategy\n- [1st-stage training](https:\/\/www.kaggle.com\/yasufuminakama\/ranzcr-resnet200d-3-stage-training-step1)\n    - teacher model training for annotated image\n        - data: annotated data\n        - pretrained weight: imagenet weight\n        - `BCEWithLogitsLoss(y_preds, labels)`\n        - `y_preds: teacher model predictions for annotated image`\n- [2nd-stage training](https:\/\/www.kaggle.com\/yasufuminakama\/ranzcr-resnet200d-3-stage-training-step2)\n    - student model training with teacher model features\n        - data: annotated data\n        - student model pretrained weight: imagenet weight\n        - teacher model pretrained weight: 1st-stage weight\n        - `BCEWithLogitsLoss(y_preds, labels) + w * MSELoss(student_features, teacher_features)`\n        - `y_preds: student model predictions for normal image`\n        - `student_features: student model features for normal image`\n        - `teacher_features: teacher model features for annotated image`\n- [3rd-stage training](https:\/\/www.kaggle.com\/yasufuminakama\/ranzcr-resnet200d-3-stage-training-step3)\n    - model training\n        - data: all data\n        - pretrained weight: 2nd-stage weight\n        - `BCEWithLogitsLoss(y_preds, labels)`\n        - `y_preds: student model predictions for normal image`\n- [inference notebook](https:\/\/www.kaggle.com\/yasufuminakama\/ranzcr-resnet200d-3-stage-training-sub)","8426a5e1":"# Library","408a9f75":"# CFG","12034569":"# MODEL"}}