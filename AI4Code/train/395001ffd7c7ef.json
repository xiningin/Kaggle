{"cell_type":{"6e45abb5":"code","80023823":"code","48eba6d5":"code","6de0bd63":"code","805a6333":"code","29dca558":"code","d1ca99aa":"code","f9a783d2":"code","0e9059a8":"code","81cfbd08":"code","c56df5a5":"code","42bbda35":"code","75832696":"code","7b41538b":"code","91973a45":"code","ad4511ae":"code","21ae4d94":"code","f2a366ae":"code","871c0936":"code","f185427e":"code","31350aa9":"code","c2f300c4":"code","d1e188dd":"markdown"},"source":{"6e45abb5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","80023823":"os.listdir('\/kaggle\/input\/colorization-to-caffee\/')","48eba6d5":"# import cv2\n# imagePath = '\/kaggle\/input\/colorization-to-sketch-ru\/real-img'\n# for img in os.listdir(imagePath):\n#     image = cv2.imread(imagePath+'\/'+img)\n#     image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n#     (thresh, blackAndWhiteImage) = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n#     path = '\/kaggle\/working\/train_sketch\/'+img\n#     cv2.imwrite(path, blackAndWhiteImage)","6de0bd63":"loadEpochs = 10\nimport tensorflow as tf\nimport cv2\nfrom glob import glob\n\nconfig = tf.compat.v1.ConfigProto()\nconfig.gpu_options.allow_growth = True\ntf.compat.v1.enable_eager_execution(config=config)\n\nfrom tqdm import tqdm\n\n# edit by your path\n__SAVED_MODEL_PATH__ = '\/kaggle\/input\/colorization-to-sketch-ru\/model-save'\n","805a6333":"# hyperparameters.py\nbatch_steps = 0\n\ngf_dim = 64\ndf_dim = 64\nc_dim = 3\n\nlr = 1e-5\nbeta1 = 0.9\nbeta2 = 0.99\n\nl1_scaling = 100\nl2_scaling = 10\n\nepoch = 2\nbatch_size = 4\n\nlog_interval = 10\nsampling_interval = 200\nsave_interval = 4000\n\ntrain_image_datasets_path = \"\/kaggle\/input\/colorization-to-sketch-ru\/real-img\/*\"\ntrain_line_datasets_path = \"\/kaggle\/input\/colorization-to-sketch-ru\/sketch-img\/*\"\ntest_image_datasets_path = \"\/kaggle\/input\/colorization-to-sketch-ru\/real-img-test\/*\"\ntest_line_datasets_path = \"\/kaggle\/input\/colorization-to-sketch-ru\/sketch-img-test\/*\"","29dca558":"# utils.py\ndef get_line(imgs):\n    def img_liner(img):\n        k = 3\n        kernal = np.ones((k, k), dtype=np.uint8)\n        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        dilated = cv2.dilate(gray, kernal, iterations=1)\n        diff = cv2.absdiff(dilated, gray)\n        img = 255 - diff\n        return img\n\n    lines = np.array([img_liner(l) for l in imgs])\n    return np.expand_dims(lines, 3)\n\n\ndef convert2f32(img):\n    img = img.astype(np.float32)\n    return (img \/ 127.5) - 1.0\n\n\ndef convert2uint8(img):\n    img = (img + 1) * 127.5\n    return img.astype(np.uint8)\n\n\ndef convertRGB(imgs):\n    imgs = np.asarray(imgs, np.uint8)\n    return np.array([cv2.cvtColor(img, cv2.COLOR_YUV2RGB) for img in imgs])\n\n\ndef mkdir(path):\n    try:\n        os.mkdir(path)\n    except FileExistsError:\n        pass\n\n\ndef initdir(model_name):\n    base = os.path.join(\"\/kaggle\/working\/\", model_name)\n    mkdir(base)\n    mkdir(os.path.join(base, \"board\"))\n    mkdir(os.path.join(base, \"image\"))","d1ca99aa":"#SubNet.py\n__INITIALIZER__ = tf.random_normal_initializer(0., 0.02)\n__MOMENTUM__ = 0.9\n__EPSILON__ = 1e-5\n\n\ndef res_net_block_v2(inputs, filters):\n    with tf.name_scope(\"ResNetBlock\"):\n        shortcut = inputs\n        tensor = tf.keras.layers.BatchNormalization()(inputs)\n        tensor = tf.keras.layers.ReLU()(tensor)\n        tensor = tf.keras.layers.Conv2D(filters=filters, kernel_size=3, strides=1, padding=\"SAME\")(tensor)\n\n        tensor = tf.keras.layers.BatchNormalization()(tensor)\n        tensor = tf.keras.layers.ReLU()(tensor)\n        tensor = tf.keras.layers.Conv2D(filters=filters, kernel_size=3, strides=1, padding=\"SAME\")(tensor)\n        tensor = tf.keras.layers.add([shortcut, tensor])\n    return tensor\n\n\ndef GenConvBlock(inputs, filters, k, s, res_net_block=True, name=\"GenConvBlock\"):\n    filters = int(filters)\n    with tf.name_scope(name):\n        tensor = tf.keras.layers.Conv2D(filters=filters, kernel_size=k, strides=s, use_bias=False,\n                                        padding=\"SAME\", kernel_initializer=__INITIALIZER__)(inputs)\n\n        if res_net_block:\n            tensor = res_net_block_v2(tensor, filters)\n        else:\n            tensor = tf.keras.layers.BatchNormalization(momentum=__MOMENTUM__, epsilon=__EPSILON__)(tensor)\n            tensor = tf.keras.layers.LeakyReLU()(tensor)\n\n        return tensor\n\n\ndef GenUpConvBlock(inputs_a, inputs_b, filters, k, s, res_net_block=True, name=\"GenUpConvBlock\"):\n    filters = int(filters)\n    with tf.name_scope(name):\n        tensor = tf.keras.layers.Concatenate(3)([inputs_a, inputs_b])\n        tensor = tf.keras.layers.Conv2DTranspose(filters=filters, kernel_size=k, strides=s, use_bias=False,\n                                                 padding=\"SAME\", kernel_initializer=__INITIALIZER__)(tensor)\n\n        if res_net_block:\n            tensor = res_net_block_v2(tensor, filters)\n        else:\n            tensor = tf.keras.layers.BatchNormalization(momentum=__MOMENTUM__, epsilon=__EPSILON__)(tensor)\n            tensor = tf.keras.layers.ReLU()(tensor)\n\n        return tensor\n\n\nclass DisConvBlock(tf.keras.Model):\n    def __init__(self, filters, k, s, apply_bat_norm=True, name=None):\n        super(DisConvBlock, self).__init__(name=name)\n        initializer = tf.random_normal_initializer(0., 0.02)\n        filters = int(filters)\n        self.apply_bat_norm = apply_bat_norm\n        self.conv = tf.keras.layers.Conv2D(filters=filters, kernel_size=k, strides=s,\n                                           padding=\"SAME\", kernel_initializer=initializer)\n        if self.apply_bat_norm:\n            self.bn = tf.keras.layers.BatchNormalization(momentum=__MOMENTUM__, epsilon=__EPSILON__)\n\n        self.act = tf.keras.layers.LeakyReLU(alpha=0.2)\n\n    def call(self, inputs, training):\n        tensor = self.conv(inputs)\n\n        if self.apply_bat_norm:\n            tensor = self.bn(tensor, training=training)\n\n        tensor = self.act(tensor)\n        return tensor\n\n\ndef tf_int_round(num):\n    return tf.cast(tf.round(num), dtype=tf.int32)\n\n\nclass resize_layer(tf.keras.layers.Layer):\n    def __init__(self, size=(512, 512), **kwargs, ):\n        super(resize_layer, self).__init__(**kwargs)\n        (self.height, self.width) = size\n\n    def build(self, input_shape):\n        super(resize_layer, self).build(input_shape)\n\n    def call(self, x, method=\"nearest\"):\n        height = 512\n        width = 512\n\n        if method == \"nearest\":\n            return tf.image.resize_nearest_neighbor(x, size=(height, width))\n        elif method == \"bicubic\":\n            return tf.image.resize_bicubic(x, size=(height, width))\n        elif method == \"bilinear\":\n            return tf.image.resize_bilinear(x, size=(height, width))\n\n    def get_output_shape_for(self, input_shape):\n        return (self.input_shape[0], 512, 512, 3)","f9a783d2":"#PaintsTensorflow\ndef Generator(inputs_size=None, res_net_block=True, name=\"PaintsTensorFlow\"):\n    inputs_line = tf.keras.Input(shape=[inputs_size, inputs_size, 1], dtype=tf.float32, name=\"inputs_line\")\n    inputs_hint = tf.keras.Input(shape=[inputs_size, inputs_size, 3], dtype=tf.float32, name=\"inputs_hint\")\n    tensor = tf.keras.layers.Concatenate(3)([inputs_line, inputs_hint])\n\n    e0 = GenConvBlock(tensor,gf_dim \/ 2, 3, 1, res_net_block=res_net_block, name=\"E0\")  # 64\n    e1 = GenConvBlock(e0, gf_dim * 1, 4, 2, res_net_block=res_net_block, name=\"E1\")\n    e2 = GenConvBlock(e1, gf_dim * 1, 3, 1, res_net_block=res_net_block, name=\"E2\")\n    e3 = GenConvBlock(e2, gf_dim * 2, 4, 2, res_net_block=res_net_block, name=\"E3\")\n    e4 = GenConvBlock(e3, gf_dim * 2, 3, 1, res_net_block=res_net_block, name=\"E4\")\n    e5 = GenConvBlock(e4, gf_dim * 4, 4, 2, res_net_block=res_net_block, name=\"E5\")\n    e6 = GenConvBlock(e5, gf_dim * 4, 3, 1, res_net_block=res_net_block, name=\"E6\")\n    e7 = GenConvBlock(e6, gf_dim * 8, 4, 2, res_net_block=res_net_block, name=\"E7\")\n    e8 = GenConvBlock(e7, gf_dim * 8, 3, 1, res_net_block=res_net_block, name=\"E8\")\n\n    d8 = GenUpConvBlock(e7, e8, gf_dim * 8, 4, 2, res_net_block=res_net_block, name=\"D8\")\n    d7 = GenConvBlock(d8, gf_dim * 4, 3, 1, res_net_block=res_net_block, name=\"D7\")\n    d6 = GenUpConvBlock(e6, d7, gf_dim * 4, 4, 2, res_net_block=res_net_block, name=\"D6\")\n    d5 = GenConvBlock(d6, gf_dim * 2, 3, 1, res_net_block=res_net_block, name=\"D5\")\n    d4 = GenUpConvBlock(e4, d5, gf_dim * 2, 4, 2, res_net_block=res_net_block, name=\"D4\")\n    d3 = GenConvBlock(d4, gf_dim * 1, 3, 1, res_net_block=res_net_block, name=\"D3\")\n    d2 = GenUpConvBlock(e2, d3, gf_dim * 1, 4, 2, res_net_block=res_net_block, name=\"D2\")\n    d1 = GenConvBlock(d2, gf_dim \/ 2, 3, 1, res_net_block=res_net_block, name=\"D1\")\n\n    tensor = tf.keras.layers.Concatenate(3)([e0, d1])\n    outputs = tf.keras.layers.Conv2D(c_dim, kernel_size=3, strides=1, padding=\"SAME\",\n                                     use_bias=True, name=\"output\", activation=tf.nn.tanh,\n                                     kernel_initializer=tf.random_normal_initializer(0., 0.02))(tensor)\n\n    inputs = [inputs_line, inputs_hint]\n    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=name)\n    return model\n\nclass Discriminator(tf.keras.Model):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        self.h0 = DisConvBlock(df_dim \/ 2, 4, 2)\n        self.h1 = DisConvBlock(df_dim \/ 2, 3, 1)\n        self.h2 = DisConvBlock(df_dim * 1, 4, 2)\n        self.h3 = DisConvBlock(df_dim * 1, 3, 1)\n        self.h4 = DisConvBlock(df_dim * 2, 4, 2)\n        self.h5 = DisConvBlock(df_dim * 2, 3, 1)\n        self.h6 = DisConvBlock(df_dim * 4, 4, 2)\n        self.flatten = tf.keras.layers.Flatten()\n        self.last = tf.keras.layers.Dense(1, activation=\"linear\", kernel_initializer=tf.initializers.he_normal())\n\n#     @tf.contrib.eager.defun\n    def call(self, inputs, training):\n        tensor = self.h0(inputs, training)\n        tensor = self.h1(tensor, training)\n        tensor = self.h2(tensor, training)\n        tensor = self.h3(tensor, training)\n        tensor = self.h4(tensor, training)\n        tensor = self.h5(tensor, training)\n        tensor = self.h6(tensor, training)\n        tensor = self.flatten(tensor)  # (?,16384)\n        tensor = self.last(tensor)\n        return tensor","0e9059a8":"#Datasets.py\nimport cv2\nclass Datasets:\n    def __init__(self, prefetch=-1, batch_size=1, shuffle=False):\n        self.prefetch = prefetch\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        \n    def get_image_and_line(self):\n        image = glob(train_image_datasets_path)\n        image.sort()\n        line = glob(train_line_datasets_path)\n        line.sort()\n        return image, line\n        \n    def _next(self, image, line):   \n        return self.buildDataSets(image, line)\n        \n  \n\n    def _preprocess(self, image, line, training = 'True'):\n        if training == 'True':\n            if np.random.rand() < 0.5:\n                image = cv2.flip(np.float32(image), 0)\n                line = cv2.flip(np.float32(line), 0)\n#                 line = np.expand_dims(line, 3)\n\n            if np.random.rand() < 0.5:\n                image = cv2.flip(np.float32(image), 1)\n                line = cv2.flip(np.float32(line), 1)\n#                 line = np.expand_dims(line, 3)\n\n        return image, line, self._buildHint_resize(image)\n\n    def _buildHint_resize(self, image):\n        random = np.random.rand\n        hint = np.ones_like(image)\n        hint += 1\n        leak_count = np.random.randint(16, 120)\n\n        if random() < 0.4:\n            leak_count = 0\n        elif random() < 0.7:\n            leak_count = np.random.randint(2, 16)\n\n        # leak position\n        x = np.random.randint(1, image.shape[0] - 1, leak_count)\n        y = np.random.randint(1, image.shape[1] - 1, leak_count)\n\n        def paintCel(i):\n            color = image[x[i]][y[i]]\n            hint[x[i]][y[i]] = color\n\n            if random() > 0.5:\n                hint[x[i]][y[i] + 1] = color\n                hint[x[i]][y[i] - 1] = color\n\n            if random() > 0.5:\n                hint[x[i] + 1][y[i]] = color\n                hint[x[i] - 1][y[i]] = color\n\n        for i in range(leak_count):\n            paintCel(i)\n\n        return hint\n\n    def convert2float(self, image):\n        image = tf.cast(image, tf.float32)\n        image = (image \/ 127.5) \n        return image\n\n    def __line_threshold(self, line):\n        if np.random.rand() < 0.3:\n            line = np.reshape(line, newshape=(512, 512))\n            _, line = cv2.threshold(line, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n            line = np.reshape(line, newshape=(512, 512, 1))\n        return line\n\n    def loadImage(self, imagePath, linePath, isTrain='True'):\n#         print (imagePath)\n        image = tf.io.read_file(imagePath)\n        image = tf.image.decode_jpeg(image, channels=3)\n\n        line = tf.io.read_file(linePath)\n        line = tf.image.decode_jpeg(line, channels=1)\n\n        image = tf.image.resize(image, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        \n#         plt.imshow(image)\n        line = tf.image.resize(line, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n        image = self.convert2float(image)\n        line = self.convert2float(line)\n\n        image, line, hint = tf.py_function(self._preprocess,\n                                       [np.float32(image), np.float32(line), str(isTrain)],\n                                       [tf.float32, tf.float32, tf.float32])\n    \n\n        return image, line, hint\n\n    def buildDataSets(self, image, line):\n        def build_dataSets(image, line, shuffle=False, isTrain=False):\n#             image = glob(image)\n#             image.sort()\n#             line = glob(line)\n#             line.sort()\n            if shuffle is False and isTrain is False:\n                image.reverse()\n                line.reverse()\n\n            batch_steps = int(3000 \/ self.batch_size)\n            datasets = tf.data.Dataset.from_tensor_slices((image, line))\n#             datasets = datasets.map(lambda x, y: self.loadImage(x, y, isTrain))\n            image_data = []\n            line_data = []\n            hint_data = []\n            line128_data = []\n            hint128_data = []\n            for ele in datasets:\n#                 p, q, x, y ,z  = self.loadImage(ele[0], ele[1], str(isTrain))\n                x, y ,z  = self.loadImage(ele[0], ele[1], str(isTrain))\n                #line_128, hint_128, image, line, hint\n#                 line128_data.append(p)\n#                 hint128_data.append(q)\n                image_data.append(x)\n                \n                line_data.append(y)\n                hint_data.append(z)\n#                 del (p)\n#                 del (q)\n                del (x)\n                del (y)\n                del (z)\n\n            del(datasets)\n            del (line)\n            del(image)\n#             datasets = datasets.batch(self.batch_size)\n#             line128_data_batch = []\n#             hint128_data_batch = []\n#             image_data_batch = []\n#             line_data_batch = []\n#             hint_data_batch = []\n#             for i in range(0,self.batch_size):\n#                 line128_data_batch.append(line128_data[i:i+self.batch_size])\n#                 hint128_data_batch.append(hint128_data[i:i+self.batch_size])\n#                 image_data_batch.append(image_data[i:i+self.batch_size])\n#                 line_data_batch.append(line_data[i:i+self.batch_size])\n#                 hint_data_batch.append(hint_data[i:i+self.batch_size])\n                \n#             del(line128_data)\n#             del(hint128_data)\n#             del(image_data)\n#             del(line_data)\n#             del(hint_data)\n\n#             return line128_data, hint128_data, image_data, line_data, hint_data\n            return image_data, line_data, hint_data\n\n#         testDatasets = build_dataSets(image, line, shuffle=False, isTrain=False)\n\n        trainDatasets = build_dataSets(image, line, shuffle=False, isTrain=True)\n        return trainDatasets\n\n#         return trainDatasets, testDatasets\n\nclass Datasets_512(Datasets):\n    def __init__(self ,batch_size):\n        self.batch_size = batch_size\n        super().__init__(self, batch_size = self.batch_size)\n        \n    def get_image_and_line(self):\n        image = glob(train_image_datasets_path)\n        image.sort()\n        line = glob(train_line_datasets_path)\n        line.sort()\n        return image, line\n        \n    def _next(self, image, line):   \n        return self.buildDataSets(image, line)\n        \n    def _flip(self, image, line, training):\n        if training:\n            if np.random.rand() < 0.5:\n                image = cv2.flip(image, 0)\n                line = cv2.flip(line, 0)\n#                 line = np.expand_dims(line, 3)\n\n            if np.random.rand() < 0.5:\n                image = cv2.flip(image, 1)\n                line = cv2.flip(line, 1)\n#                 line = np.expand_dims(line, 3)\n\n        return image, line\n\n    def _buildHint(self, image):\n        random = np.random.rand\n        hint = np.ones_like(image)\n        hint += 1\n        leak_count = np.random.randint(16, 128)\n\n        # leak position\n        x = np.random.randint(1, image.shape[0] - 1, leak_count)\n        y = np.random.randint(1, image.shape[1] - 1, leak_count)\n\n        def paintCel(i):\n            color = image[x[i]][y[i]]\n            hint[x[i]][y[i]] = color\n\n            if random() > 0.5:\n                hint[x[i]][y[i] + 1] = color\n                hint[x[i]][y[i] - 1] = color\n\n            if random() > 0.5:\n                hint[x[i] + 1][y[i]] = color\n                hint[x[i] - 1][y[i]] = color\n\n        for i in range(leak_count):\n            paintCel(i)\n        return hint\n\n    def loadImage(self, imagePath, linePath, train):\n#         print (imagePath)\n        image = tf.io.read_file(imagePath)\n        image = tf.image.decode_jpeg(image, channels=3)\n        line = tf.io.read_file(linePath)\n        line = tf.image.decode_jpeg(line, channels=1)\n        image = tf.image.resize(image, (512, 512), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        line = tf.image.resize(line, (512, 512), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        image_128 = tf.image.resize(image, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        line_128 = tf.image.resize(line, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n        image = self.convert2float(image)\n        line = self.convert2float(line)\n        image_128 = self.convert2float(image_128)\n        line_128 = self.convert2float(line_128)\n\n        hint_128 = tf.py_function(self._buildHint,\n                                  [image_128],\n                                  tf.float32)\n\n        hint_128.set_shape(shape=image_128.shape)\n        hint = tf.image.resize(hint_128, (512, 512), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n        return line_128, hint_128, image, line, hint","81cfbd08":"# os.listdir('\/kaggle\/input\/colorization-to-caffee')","c56df5a5":"import matplotlib.pyplot as plt\n%matplotlib inline","42bbda35":"__SAVED_MODEL_PATH__ = '\/kaggle\/input\/colorization-to-caffee\/PaintsTensorFlowDraftNet_35.h5'\n# saved_refined = '\/kaggle\/working\/PaintsTensorFlow_refined_1.h5'","75832696":"# os.listdir(\"\/kaggle\/input\/colorization-to-caffee\/PaintsTensorFlow_refined_3.h5\")","7b41538b":"#PaintsTensorflowTraining\nimport time\nclass PaintsTensorFlowTrain:\n    def __init__(self, model_name=\"PaintsTensorFlow\"):\n        self.data_sets = Datasets_512(batch_size=batch_size)\n        self.model_name = \"{}\".format(model_name)\n        initdir(self.model_name)\n\n        self.global_steps = tf.compat.v1.train.get_or_create_global_step()\n        self.epochs = tf.Variable(0, trainable=False, dtype=tf.int32)\n#         self.ckpt_path = \".\/ckpt\/{}\/\".format(self.model_name) + \"ckpt_E:{}\"\n#         self.ckpt_prefix = os.path.join(self.ckpt_path, \"model_GS:{}\")\n        self.saved_refined = '\/kaggle\/input\/colorization-to-caffee\/PaintsTensorFlow_refined_7.h5'\n        self.generator_128 =  tf.keras.models.load_model(__SAVED_MODEL_PATH__)\n        self.generator_512 = tf.keras.models.load_model(self.saved_refined)\n#         self.generator_512 = Generator(res_net_block=False)\n        self.optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.5, beta_2=0.9)\n\n#         self.check_point = tf.train.Checkpoint(generator_512=self.generator_512,\n#                                                optimizer=self.optimizer,\n#                                                globalSteps=self.global_steps,\n#                                                epochs=self.epochs)\n\n#     def __loging(self, name, scalar):\n#         with tf.contrib.summary.always_record_summaries():\n#             tf.contrib.summary.scalar(name, scalar)\n\n    def __loss(self, output, target):\n        loss = tf.reduce_mean(tf.abs(target - output))\n        return loss\n\n    def __pred_image(self, model, image, line, hint, draft, epoch=None):\n        gs = self.global_steps.numpy()\n        predImage = model.predict([line, draft])\n#         file_name = \".\/ckpt\/{}\/image\/{}.jpg\".format(self.model_name, gs)\n\n        if epoch is not None:\n            loss = self.__loss(predImage, image)\n#             self.__loging(\"Sample_LOSS\", loss)\n            loss = \"{:0.05f}\".format(loss).zfill(7)\n            print(\"Epoch:{} GS:{} LOSS:{}\".format(epoch, self.global_steps.numpy(), loss))\n#             file_name = \".\/ckpt\/{}\/image\/{}_loss:{}.jpg\".format(self.model_name, gs, loss)\n\n        hint = np.array(hint)\n        hint[hint > 1] = 1\n\n        lineImage = np.concatenate([line, line, line], -1)\n        save_img = np.concatenate([lineImage, hint, draft, predImage, image], 1)\n        save_img = utils.convert2uint8(save_img)\n        tl.visualize.save_images(save_img, [1, save_img.shape[0]], file_name)\n\n    def load_caffee(self):\n        print(\"[INFO] loading model...\")\n        self.net = cv2.dnn.readNetFromCaffe(\"\/kaggle\/input\/reuirements\/colorization_deploy_v2.prototxt\", \"\/kaggle\/input\/reuirements\/colorization_release_v2.caffemodel\")\n        self.pts = np.load(\"\/kaggle\/input\/reuirements\/pts_in_hull.npy\")\n        \n    def pred_caffee(self, line_128):\n        class8 = self.net.getLayerId(\"class8_ab\")\n        conv8 = self.net.getLayerId(\"conv8_313_rh\")\n        self.pts = self.pts.transpose().reshape(2, 313, 1, 1)\n        self.net.getLayer(class8).blobs = [self.pts.astype(\"float32\")]\n        self.net.getLayer(conv8).blobs = [np.full([1, 313], 2.606, dtype=\"float32\")]\n        \n        pred_img = []\n        for i in range(0,4):\n            print (line_128[i])\n            image = cv2.imread(line_128[i])\n            plt.imshow(image)\n            scaled = image.astype(\"float32\") \/ 255.0\n#             lab = cv2.cvtColor(scaled, cv2.COLOR_BGR2LAB)\n            resized = cv2.resize(np.float32(scaled), (224, 224))\n            L = cv2.split(resized)[0]\n            L -= 50\n            self.net.setInput(cv2.dnn.blobFromImage(L))\n            ab = self.net.forward()[0, :, :, :].transpose((1, 2, 0))\n            ab = cv2.resize(ab, (image.shape[1], image.shape[0]))\n            L = cv2.split(np.float32(scaled))[0]\n            colorized = np.concatenate((L[:, :, np.newaxis], ab), axis=2)\n\n            colorized = cv2.cvtColor(colorized, cv2.COLOR_LAB2BGR)\n            colorized = np.clip(colorized, 0, 1)\n            colorized = (255 * colorized).astype(\"uint8\")\n            colorized = tf.image.resize(colorized, size=(512, 512), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n            pred_img.append(colorized)\n        return pred_img\n        \n        \n        \n        \n        \n    def __draft_image(self, line_128, hint_128):\n        draft = self.generator_128.predict([line_128, hint_128])\n#         print (draft.shape\n        draft = tf.image.resize(draft, size=(512, 512),method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        return draft\n    \n    \n    \n    def fast_fetch(self,size, Traindata):        \n        if (size[3]==3):\n            x=np.zeros(size)\n            for i in range(0,4):\n                t = Traindata[i]\n                x[i] = np.asarray(t, np.float32)        \n            return x\n        elif (size[3] ==1):\n            x=np.zeros(size)\n            for i in range(4):\n                t = Traindata[i]\n                x[i,:,:,0] = np.asarray(t,np.float32).reshape(size[1],size[2])\n            return x\n          \n    \n    \n\n    def training(self, loadEpochs=0):\n        \n#         #predict image\n#         line_flower = tf.io.read_file('\/kaggle\/input\/predimg\/out.jpeg')\n#         line_flower = tf.image.decode_jpeg(line_flower, channels=1)\n#         line_flower = tf.image.resize(line_flower, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n# # #         %matplotlib inline\n# #         plt.imshow(line_flower[:,:,0])\n# #         print (line_flower.shape)\n#         hint_pred = line = tf.io.read_file('\/kaggle\/input\/predimg\/hint.jpg')\n#         hint_pred = tf.image.decode_jpeg(hint_pred, channels=3)\n#         hint_pred = tf.image.resize(hint_pred, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n#         draft = self.__draft_image(line_128, hint_128)\n\n\n        images, lines = self.data_sets.get_image_and_line()\n#         self.load_caffee()\n#         print (len(images))\n        for epoch in range(loadEpochs):\n#             t = time.time()\n#             print ('starting time of{} epoch is {}'.format(epoch, t))\n            print ('epoch {}'.format(epoch))\n            print(\"GS: \", self.global_steps.numpy())\n            for batchs in range(750):\n                \n                print (batchs , end = '\\r')\n#                 print (batchs)\n                trainData = self.data_sets._next(images[(batchs*4):(batchs*4)+4], lines[(batchs*4):(batchs*4)+4])\n    \n#                 prediction = self.pred_caffee(images[(batchs*4):(batchs*4)+4])\n#                 draft = tf.convert_to_tensor(fast_fetch((4,512,512,3), prediction), dtype=tf.float32, dtype_hint=None, name=None)\n#                 return prediction\n                \n#                 trainData[0][0] = line_flower\n#                 trainData[1][0] = hint_pred\n                image = tf.convert_to_tensor(self.fast_fetch((4,512,512,3), trainData[2]), dtype=tf.float32, dtype_hint=None, name=None)        \n                line = tf.convert_to_tensor(self.fast_fetch((4,512,512,1), trainData[3]), dtype=tf.float32, dtype_hint=None, name=None)\n                hint = tf.convert_to_tensor(self.fast_fetch((4,512,512,3), trainData[4]), dtype=tf.float32, dtype_hint=None, name=None)\n                line_128 = tf.convert_to_tensor(self.fast_fetch((4,128,128,1), trainData[0]), dtype=tf.float32, dtype_hint=None, name=None)\n                hint_128 = tf.convert_to_tensor(self.fast_fetch((4,128,128,3), trainData[1]), dtype=tf.float32, dtype_hint=None, name=None)\n                \n                return image,line,hint,line_128,hint_128\n                \n#                 print (line_128.shape)\n#                 print ('fetch')\n                draft = self.__draft_image(line_128, hint_128)\n#                 return draft, image\n#                 print ('pred')\n                with tf.GradientTape() as tape:\n                    genOut = self.generator_512(inputs=[line, draft], training=True)\n                    loss = self.__loss(genOut, image)\n#                 print ('loss calc')\n                # Training\n                gradients = tape.gradient(loss, self.generator_512.variables)\n                self.optimizer.apply_gradients(zip(gradients, self.generator_512.variables))\n#                 print ('opt')\n                \n#                 # Loging\n                gs = self.global_steps.numpy()\n#                 if (batchs%100 == 0):\n#                     print (batchs)\n            print (\"gen loss {}\".format(loss))\n            print(\"------------------------------SAVE_E:{}_G:{}-------------------------------------\"\n                              .format(self.epochs.numpy(), gs))\n                        \n            self.generator_512.summary()\n            print(self.global_steps)\n    \n    def save_refined(self):\n#         os.mkdir('\/kaggle\/working\/model-save')\n        save_path = \"\/kaggle\/working\/{}_refined_7.h5\".format(self.generator_512.name)\n        self.generator_512.save(save_path, include_optimizer=False)  # for keras Model\n#         save_path = tf.keras.models.save_model(self.generator_512, save_path)  # saved_model\n\n    def make_prediction(self, line128_img, hint128_img, line512_img):\n        pred512 = self.__draft_image(line128_img, hint128_img)\n        plt.imshow(pred512[0])\n        cv2.imwrite('\/kaggle\/working\/demo.jpg',np.float32(pred512[0]))\n        final_pred = self.generator_512.predict([line512_img, pred512])\n        return final_pred\n    \n    def convert_data(self, image_path, line_path):\n        \n        def fast_fetch(size, data):        \n            if (size[2]==3):\n                x=np.zeros((4,size[0],size[1],size[2]))\n                x[0] = np.asarray(data, np.float32)        \n                return x\n            elif (size[2] ==1):\n                x=np.zeros((4,size[0],size[1],size[2]))\n                x[0,:,:,0] = np.asarray(data,np.float32).reshape(size[0],size[1])\n                return x\n          \n        \n        loadData = line_to_data(image_path, line_path)\n        line128, hint128, line512 = loadData.convert_to_128()\n        line128 = tf.convert_to_tensor(fast_fetch((128,128,1), line128), dtype=tf.float32, dtype_hint=None, name=None)\n        hint128 = tf.convert_to_tensor(fast_fetch((128,128,3), hint128), dtype=tf.float32, dtype_hint=None, name=None)\n        line512 = tf.convert_to_tensor(fast_fetch((512,512,1), line512), dtype=tf.float32, dtype_hint=None, name=None)\n        prediction = self.make_prediction(line128, hint128, line512)\n        return prediction\n        \n        \n        \n# ","91973a45":"class line_to_data:\n    def __init__(self, image_path, line_path):\n        self.line_real_path = line_path\n        self.image_path = image_path\n        \n    def convert2float(self, img):\n        img = tf.cast(img, tf.float32)\n        img = (img \/ 127.5) - 1\n        return img\n        \n    def built_hint(self, image):\n        random = np.random.rand\n        hint = np.ones_like(image)\n        hint += 1\n        leak_count = np.random.randint(16, 120)\n        if random() < 0.4:\n            leak_count = 0\n        elif random() < 0.7:\n            leak_count = np.random.randint(2, 16)\n        # leak position\n        x = np.random.randint(1, image.shape[0] - 1, leak_count)\n        y = np.random.randint(1, image.shape[1] - 1, leak_count)\n        def paintCel(i):\n            color = image[x[i]][y[i]]\n            hint[x[i]][y[i]] = color\n            if random() > 0.5:\n                hint[x[i]][y[i] + 1] = color\n                hint[x[i]][y[i] - 1] = color\n            if random() > 0.5:\n                hint[x[i] + 1][y[i]] = color\n                hint[x[i] - 1][y[i]] = color\n        for i in range(leak_count):\n            paintCel(i)\n        return hint\n        \n    def convert_to_128(self):\n        self.image = tf.io.read_file(self.image_path)\n        self.image = tf.image.decode_jpeg(self.image, channels=3)\n        self.line_real = tf.io.read_file(self.line_real_path)\n        self.line_real = tf.image.decode_jpeg(self.line_real, channels=1)\n        self.image_128 = tf.image.resize(self.image, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        self.line_128 = tf.image.resize(self.line_real, (128, 128), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        self.hint_128 = self.built_hint(self.image_128)\n        self.line_512 = tf.image.resize(self.line_real, (512, 512), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n        self.image = self.convert2float(self.image)\n        self.line_real = self.convert2float(self.line_real)\n        self.line_128 = self.convert2float(self.line_128)\n        self.line_512 = self.convert2float(self.line_512)\n\n        return self.line_128, self.hint_128, self.line_512\n        \n\n        \n\n\n        \n        ","ad4511ae":"model = PaintsTensorFlowTrain()\nimage,line,hint,line_128,hint_128 = model.training(loadEpochs=4)","21ae4d94":"image_path = '..\/input\/realdemo\/JPMorgan.jpg'\nline_path = '..\/input\/demo12\/output.jpg'\n\n\n\nprediction = model.convert_data(image_path, line_path)","f2a366ae":"model.save_refined()","871c0936":"#PaintsTensorflowDraftModel\nconfig = tf.compat.v1.ConfigProto()\nconfig.gpu_options.allow_growth = True\ntf.compat.v1.enable_eager_execution(config=config)\nimport time\nclass PaintsTensorFlowDraftModelTrain:\n    def __init__(self, model_name=\"PaintsTensorFlowDraftModel\"):\n        self.data_sets = Datasets(batch_size=4)\n        self.model_name = model_name\n        # utils.initdir(self.model_name)\n\n        self.global_steps = tf.compat.v1.train.get_or_create_global_step()\n        self.epochs = tf.Variable(0, trainable=False, dtype=tf.int32)\n\n        self.generator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.5, beta_2=0.9)\n        self.discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=lr, beta_1=0.5, beta_2=0.9)\n#         self.ckptPath = \".\/ckpt\/{}\/\".format(self.model_name) + \"ckpt_E:{}\"\n#         self.ckptPrefix = os.path.join(self.ckptPath, \"model_GS:{}\")\n\n#         self.generator = Generator(name=\"PaintsTensorFlowDraftNet\")\n        self.generator = tf.keras.models.load_model(__SAVED_MODEL_PATH__)\n        \n        self.discriminator = Discriminator()\n\n#         self.logWriter = tf.contrib.summary.create_file_writer(\".\/ckpt\/{}\/board\/log\".format(self.model_name))\n# #         self.logWriter.set_as_default()\n\n#         self.check_point = tf.train.Checkpoint(generator=self.generator,\n#                                                genOptimizer=self.generator_optimizer,\n#                                                disOptimizer=self.discriminator_optimizer,\n#                                                discriminator=self.discriminator,\n#                                                globalSteps=self.global_steps,\n#                                                epochs=self.epochs)\n\n    def __discriminator_loss(self, real, fake):\n        SCE = tf.nn.sigmoid_cross_entropy_with_logits\n        self.real_loss = SCE(tf.ones_like(real), logits=real)\n        self.fake_loss = SCE(tf.zeros_like(fake), logits=fake)\n        loss = self.real_loss + self.fake_loss\n        return loss\n\n    def __generator_loss(self, disOutput, output, target):\n        SCE = tf.nn.sigmoid_cross_entropy_with_logits\n        self.gan_loss = SCE(tf.ones_like(disOutput), logits=disOutput)\n        self.image_loss = tf.reduce_mean(tf.abs(target - output)) * l1_scaling\n        loss = self.image_loss + self.gan_loss\n        return loss\n\n    def __pred_image(self, model, image, line, hint, epoch=None):\n        global_steps = self.global_steps.numpy()\n        pred_image = model.predict([line, hint])\n\n        zero_hint = tf.ones_like(hint)\n        zero_hint += 1\n        pred_image_zero = model.predict([line, zero_hint])\n\n        dis_fake = self.discriminator(pred_image, training=False)\n        loss = self.__generator_loss(dis_fake, pred_image, image)\n\n#         self.__loging(\"Sample_LOSS\", loss)\n        loss = \"{:0.05f}\".format(loss).zfill(7)\n        print(\"Epoch:{} GS:{} LOSS:{}\".format(epoch, global_steps, loss))\n#         file_name = \".\/ckpt\/{}\/image\/{}_loss:{}.jpg\".format(self.model_name, global_steps, loss)\n\n        hint = np.array(hint)\n        hint[hint > 1] = 1\n\n        line_image = np.concatenate([line, line, line], -1)\n        save_img = np.concatenate([line_image, hint, pred_image_zero, pred_image, image], 1)\n        save_img = utils.convert2uint8(save_img)\n        #use plt.save for viasualization\n        # tl.visualize.save_images(save_img, [1, save_img.shape[0]], file_name)\n\n#     def __loging(self, name, scalar):\n#         with tf.contrib.summary.always_record_summaries():\n#             tf.contrib.summary.scalar(name, scalar)\n\n#     def __check_point_save(self):\n#         file_prefix = self.ckptPrefix.format(self.epochs.numpy(), self.global_steps.numpy())\n#         self.check_point.save(file_prefix=file_prefix)\n\n    def training(self, loadEpochs=0):\n        images, lines = self.data_sets.get_image_and_line()\n#         return (images, lines)\n        t = time.time()\n        batch_steps = 750\n        def fast_fetch(size, Traindata):        \n            if (size==(4,128,128,3)):\n                x=np.zeros(size)\n                for i in range(0,4):\n                    t = Traindata[i]\n                    x[i] = np.asarray(t, np.float32)        \n                return x\n            else:\n                x=np.zeros(size)\n                for i in range(4):\n                    t = Traindata[i]\n                    x[i,:,:,0] = np.asarray(t,np.float32).reshape(128,128)\n#                     plt.imshow(x[i,:,:,0])\n                return x\n            \n        for epoch in range(loadEpochs):\n\n            print(\"GS: \", self.global_steps.numpy(), \"Epochs:  \", self.epochs.numpy())\n            for batch in range(batch_steps):\n                print (batch, end='\\r')\n#                 t1 = time.time()\n#                 print(\"Time of for loop {}\".format(t1-t))\n                trainData = self.data_sets._next(images[(batch*4):(batch*4)+4], lines[(batch*4):(batch*4)+4])\n#                 return trainData\n#                 trainData[0][0] = line_flower\n                image = tf.convert_to_tensor(fast_fetch((4,128,128,3), trainData[0]), dtype=tf.float32, dtype_hint=None, name=None)        \n                line = tf.convert_to_tensor(fast_fetch((4,128,128,1), trainData[1]), dtype=tf.float32, dtype_hint=None, name=None)\n                hint = tf.convert_to_tensor(fast_fetch((4,128,128,3), trainData[2]), dtype=tf.float32, dtype_hint=None, name=None)\n                del (trainData)\n#                 return image, line, hint\n                \n                \n                with tf.GradientTape() as genTape, tf.GradientTape() as discTape:\n                    pred_image = self.generator(inputs=[line, hint], training=True)\n                    dis_real = self.discriminator(inputs=image, training=True)\n                    dis_fake = self.discriminator(inputs=pred_image, training=True)\n                    generator_loss = self.__generator_loss(dis_fake, pred_image, image)\n                    discriminator_loss = self.__discriminator_loss(dis_real, dis_fake)\n                discriminator_gradients = discTape.gradient(discriminator_loss, self.discriminator.variables)\n                generator_gradients = genTape.gradient(generator_loss, self.generator.variables)\n                self.discriminator_optimizer.apply_gradients(zip(discriminator_gradients, self.discriminator.variables))\n                self.generator_optimizer.apply_gradients(zip(generator_gradients, self.generator.variables))\n                gs = self.global_steps.numpy()\n                del(image)\n                del(line)\n                del(hint)\n\n                \n#                     log(\"LOSS_G\", generator_loss)\n#                     log(\"LOSS_G_Image\", self.image_loss)\n#                     log(\"LOSS_G_GAN\", self.gan_loss)\n#                     log(\"LOSS_D\", discriminator_loss)\n#                     log(\"LOSS_D_Real\", self.real_loss)\n#                     log(\"LOSS_D_Fake\", self.fake_loss)\n                    \n#                     if gs % sampling_interval == 0:\n#                         for image, line, hint in test_sets[:]:\n#                             self.__pred_image(self.generator, image, line, hint, self.epochs.numpy())\n\n#                 if gs % save_interval == 0:\n#                     print(\"------------------------------SAVE_E:{}_G:{}-------------------------------------\".format(self.epochs.numpy(), gs))\n            self.epochs = self.epochs + 1\n            print ('LOSS_G {}\\nLOSS_G_Image {}\\nLOSS_G_GAN {} \\nLOSS_D {}\\nLOSS_D_Real {}\\nLOSS_D_Fake {}'.format(generator_loss,self.image_loss,self.gan_loss,discriminator_loss,self.real_loss,self.fake_loss))\n        self.generator.summary()\n    def save_model(self):\n        save_path = \"\/kaggle\/working\/{}_40.h5\".format(self.generator.name)\n        self.generator.save(save_path, include_optimizer=False)  # for keras Model\n#         save_path = tf.contrib.saved_model.save_keras_model(self.generator, \".\/saved_model\")\n        \n\n                \n\n#         log = self.__loging\n\n#         self.check_point.restore(tf.train.latest_checkpoint(self.ckptPath.format(loadEpochs)))\n\n#         for epoch in range(10):\n#             print(\"GS: \", self.global_steps.numpy(), \"Epochs:  \", self.epochs.numpy())\n\n#             for image, line, hint in tqdm(train_sets, total=batch_steps):\n#                 # get loss\n#                 with tf.GradientTape() as genTape, tf.GradientTape() as discTape:\n\n#                     pred_image = self.generator(inputs=[line, hint], training=True)\n\n#                     dis_real = self.discriminator(inputs=image, training=True)\n#                     dis_fake = self.discriminator(inputs=pred_image, training=True)\n\n#                     generator_loss = self.__generator_loss(dis_fake, pred_image, image)\n#                     discriminator_loss = self.__discriminator_loss(dis_real, dis_fake)\n\n#                 # Gradients\n#                 discriminator_gradients = discTape.gradient(discriminator_loss, self.discriminator.variables)\n#                 generator_gradients = genTape.gradient(generator_loss, self.generator.variables)\n\n#                 self.discriminator_optimizer.apply_gradients(zip(discriminator_gradients, self.discriminator.variables))\n#                 self.generator_optimizer.apply_gradients(zip(generator_gradients, self.generator.variables),\n#                                                          global_step=self.global_steps)\n#                 gs = self.global_steps.numpy()\n\n#                 if gs % log_interval == 0:\n#                     log(\"LOSS_G\", generator_loss)\n#                     log(\"LOSS_G_Image\", self.image_loss)\n#                     log(\"LOSS_G_GAN\", self.gan_loss)\n#                     log(\"LOSS_D\", discriminator_loss)\n#                     log(\"LOSS_D_Real\", self.real_loss)\n#                     log(\"LOSS_D_Fake\", self.fake_loss)\n\n#                     if gs % sampling_interval == 0:\n#                         for image, line, hint in test_sets.take(1):\n#                             self.__pred_image(self.generator, image, line, hint, self.epochs.numpy())\n\n#                     if gs % save_interval == 0:\n#                         self.__check_point_save()\n#                         print(\"------------------------------SAVE_E:{}_G:{}-------------------------------------\"\n#                               .format(self.epochs.numpy(), gs))\n#             self.epochs = self.epochs + 1\n\n#         self.generator.summary()\n#         save_path = \"'\/kaggle\/working\/model-save\/'\" + self.model_name + \"\/{}.h5\".format(self.generator.name)\n#         self.generator.save(save_path, include_optimizer=False)  # for keras Model\n#         save_path = tf.contrib.saved_model.save_keras_model(self.generator, \".\/saved_model\")  # saved_model\n#         print(\"saved_model path = {}\".format(save_path))\n\n#         print(\"------------------------------Training Done-------------------------------------\")","f185427e":"model = PaintsTensorFlowDraftModelTrain()","31350aa9":"model.training(loadEpochs=5)","c2f300c4":"model.save_model()","d1e188dd":"**converting color image to sketch**"}}