{"cell_type":{"d7aa94f4":"code","4cf47eb8":"code","847f5266":"code","4e5b270f":"code","f319b07d":"code","421d5441":"code","2f2198bd":"code","bafde8c6":"code","04830f53":"code","c109fd12":"code","97879ed5":"code","3f531f48":"code","32e010b0":"code","ae9472a6":"code","b6555aff":"code","982409f7":"code","de655dc8":"code","f8a07cc5":"markdown","16b4244c":"markdown","2a752dff":"markdown","96bf19db":"markdown","6dc5ff2a":"markdown","e8a86965":"markdown","93019fb4":"markdown","3f9329a1":"markdown","fe5d8192":"markdown","b73c54e2":"markdown","10a8f137":"markdown","c8ab585d":"markdown","e15a584e":"markdown","1603e2e9":"markdown"},"source":{"d7aa94f4":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport tensorflow as tf\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nfrom scipy import ndimage\nfrom keras.preprocessing.image import ImageDataGenerator\nimport seaborn as sns\n%matplotlib inline","4cf47eb8":"path_normal_train='..\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL'\nj_n=os.listdir(path_normal_train)\npath_pneumonia_train='..\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA'\nj_p=os.listdir(path_pneumonia_train)","847f5266":"fig=plt.figure(figsize=(20,20))\no=1\nfor i in range(2):\n    fig.add_subplot(4,2,o)\n    plt.title(str(i+1)+' normal img')\n    j=cv2.imread(os.path.join(path_normal_train,j_n[i]))\n    plt.imshow(j)\n    o+=1\n    fig.add_subplot(4,2,o)\n    plt.title(str(i+1)+' pneumonia img')\n    j=cv2.imread(os.path.join(path_pneumonia_train,j_p[i]))\n    plt.imshow(j)\n    o+=1\nplt.show()","4e5b270f":"plt.figure(figsize=(5,5))\nsns.barplot(x=[0,1], y= [len(j_n),len(j_p)])\nplt.title('no. of train cases')\nplt.xlabel('0:normal images, 1:pneumonia images')\nplt.ylabel('no. of images')","f319b07d":"gen=ImageDataGenerator(rotation_range=20,width_shift_range=0.1,\n                       height_shift_range=0.1,shear_range=0.15,\n                       zoom_range=0.1,channel_shift_range=10,horizontal_flip=True,vertical_flip=True,\n                       fill_mode='constant',cval=125)","421d5441":"#below function plots the  \ndef plots(figsize,images,a,b):\n    fig=plt.figure(figsize=figsize)\n    for i in range(1,len(images)+1):\n        fig.add_subplot(a,b,i)\n        plt.imshow(images[i-1])\n    plt.show()\n               \n        \ndef create_images(path,j_p,i,pri):\n    img_path=os.path.join(path,j_p[i])\n    image=np.expand_dims(cv2.imread(img_path),0)\n    aug_itter=gen.flow(image)#,save_to_dir=path,save_prefix='aug',save_format='jpeg')\n    aug_images=[next(aug_itter)[0].astype(np.uint8) for i in range(10)]\n    if pri=='print':\n        plots((10,20),aug_images,5,2)\n\n\n#takes-> path of directory, \n#        images_name_list, \n#        which image(i'th image),\n#       'print' if want to print images else empty with \"\"    \ncreate_images(path_pneumonia_train,j_p,3,'print')","2f2198bd":"train_='..\/input\/chest-xray-pneumonia\/chest_xray\/train'\ntest_='..\/input\/chest-xray-pneumonia\/chest_xray\/test'\nval_='..\/input\/chest-xray-pneumonia\/chest_xray\/val'\n\n#loads train_data\ntrain_gen=ImageDataGenerator(rescale=1.\/255)\ntrain=train_gen.flow_from_directory(train_,\n                                   target_size=(250,250),\n                                   batch_size=10,\n                                   class_mode='binary')\n\n\n#loads augmented load_data\naugmentation=ImageDataGenerator(rescale=1.\/255,rotation_range=20,width_shift_range=0.1,\n                       height_shift_range=0.1,shear_range=0.15,\n                       zoom_range=0.1,channel_shift_range=10,horizontal_flip=True,vertical_flip=True,\n                       fill_mode='constant',cval=125)\ntrain_augmentation=augmentation.flow_from_directory(train_,\n                                target_size=(250,250),\n                                batch_size=10,\n                                class_mode='binary')\n\n\n#loads test data\ntest_gen=ImageDataGenerator(rescale=1.\/255)\ntest=test_gen.flow_from_directory(test_,\n                                  target_size=(250,250),\n                                  batch_size=10,\n                                  class_mode='binary')\n\n\n#loads validaiton data\nval_gen=ImageDataGenerator(rescale=1.\/255)\nval=val_gen.flow_from_directory(test_,\n                                target_size=(250,250),\n                                batch_size=10,\n                                class_mode='binary')","bafde8c6":"\nmodel=tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(250,250,3)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64,(3,3),activation='relu',padding='same'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(128,(3,3),activation='relu',padding='same'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(256,(3,3),activation='relu',padding='same'),\n    tf.keras.layers.Conv2D(256,(3,3),activation='relu',padding='same'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(512,(3,3),activation='relu',padding='same'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512,activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(64,activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(32,activation='sigmoid'),\n    tf.keras.layers.Dense(1,activation='sigmoid')\n])\nmodel.summary()","04830f53":"from keras.optimizers import Adam\nopt=Adam(lr=0.0001)\nmodel.compile(loss='binary_crossentropy',optimizer=opt,metrics=['acc'])\n\n#this function plots the graph between train and validation data parameters\ndef plot_metrics(history,epochs):\n    epoch=range(1,epochs+1)\n    loss=history.history['loss']\n    accuracy=history.history['acc']\n    vlos=history.history['val_loss']\n    vacc=history.history['val_acc']\n    plt.title('Loss graph')\n    plt.xlabel('epochs')\n    plt.ylabel('loss')\n    plt.plot(epoch,loss)\n    plt.plot(epoch,vlos)\n    plt.show()\n    plt.title('Accuracy graph')\n    plt.xlabel('epochs')\n    plt.ylabel('accuracy')\n    plt.plot(epoch,accuracy)\n    plt.plot(epoch,vacc)\n    plt.show()","c109fd12":"epochs=30\nhistory=model.fit_generator(train_augmentation,\n                            steps_per_epoch=20,\n                            epochs=epochs,\n                            validation_data=val,\n                            validation_steps=8,\n                            verbose=1)","97879ed5":"plot_metrics(history,epochs)","3f531f48":"history=model.fit_generator(train,\n                            steps_per_epoch=20,\n                            epochs=epochs,\n                            validation_data=val,\n                            validation_steps=8,\n                            verbose=1)","32e010b0":"plot_metrics(history,epochs)","ae9472a6":"epochs=15\nhistory=model.fit_generator(train_augmentation,\n                            steps_per_epoch=20,\n                            epochs=epochs,\n                            validation_data=val,\n                            validation_steps=8,\n                            verbose=1)","b6555aff":"plot_metrics(history,epochs)","982409f7":"loss, acc = model.evaluate_generator(test, steps=3, verbose=1)","de655dc8":"tf.keras.utils.plot_model(model, show_shapes=True)","f8a07cc5":"# Creating the model","16b4244c":"# Visualising augmented data","2a752dff":"**We can see from the above graph that the data is not over fitting and augmeted data is giving good results, thus now we train the same model with same trained parameters but with test dataset which is not augmented**","96bf19db":"**The training accuracy is great with 98.5% but this decreased the validation accuracy. From the graphs we can see that the dataset is overfitting thus we again train the same model with previous augmented data but for less no. of epochs(15)**","6dc5ff2a":"# Chest X-ray dataset with 98.5% accuracy on test data\n\n**Adding all the required header files at first**","e8a86965":"**Applying the Image data generator library to get the data from directories**\n\n**Loaded datasets are:**\n* train data\n* augmented test data\n* validation data\n* test data","93019fb4":"**At first we fir aur augmented data**","3f9329a1":"# Visualising images\n\n**Visualising how are the x-ray images inside the dataset with 2 images show of each category i.e Normal and Pnemonia**","fe5d8192":"# Done training\n\nNow we try to predict the test data. \n\nwe get an accuracy of 86% at the test data","b73c54e2":"# Data Augmentation\nBecause the images in taining data is quite less, and the CNN won't be able to train itself properly thus we need to create augmented data.\n\n\n**What is data Augmentaion?**\nLimited data is a major obstacle in applying deep learning models like convolutional neural networks. Often, imbalanced classes can be an additional hindrance; while there may be sufficient data for some classes, equally important, but undersampled classes will suffer from poor class-specific accuracy. This phenomenon is intuitive. If the model learns from a few examples of a given class, it is less likely to predict the class invalidation and test applications.\n\n\nHere is the index of techniques people use for augmenting data:\n* Scaling\n* Translation\n* Rotation (at 90 degrees)\n* Rotation (at finer angles)\n* Flipping\n* Adding Salt and Pepper noise\n* Lighting condition\n* Perspective transform","10a8f137":"**Now we initialize the dataset directories**\n\nhere we also get all the file names inside each path ","c8ab585d":"**Plotting the no. of images in test dataset**","e15a584e":"# Here is the block visualisation of the model","1603e2e9":"Thus, below with the help of [ImageDataGenerator](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image\/ImageDataGenerator) class. I have augmented the data."}}