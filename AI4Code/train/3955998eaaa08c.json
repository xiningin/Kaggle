{"cell_type":{"c2fe05f6":"code","419408ad":"code","e638abd0":"code","3ca0846d":"code","0898173b":"code","6e6bee86":"code","32bf2a22":"code","eb053329":"code","e1213667":"code","5a8dcaa2":"code","d2c8d75b":"code","46027c62":"code","0c137c97":"code","5c1eb743":"code","eaada95b":"code","3f68a573":"code","8d5bb9d0":"code","22cd1225":"code","4fc928a1":"code","4f2952fa":"code","e9cb3957":"code","d7ae477a":"code","54fed91c":"code","97728608":"code","8daae7d2":"code","cf2eae93":"code","2ed77d1c":"code","5ab90fe1":"code","2f6923b4":"code","a1b1c1d5":"code","d6a811b3":"code","939b4fab":"code","01f0f4d3":"code","b837e9df":"code","9b23a362":"code","66278a40":"code","88d59882":"code","c29bea6b":"code","c35edcb7":"code","6b0e2e14":"code","bf416949":"code","25453be6":"code","44f48f77":"code","568ab9d3":"code","b203d647":"code","f1747b86":"code","55771565":"code","ef0017dd":"code","5bc8ef71":"code","46a91cfa":"code","c1257812":"code","267196ee":"code","10280965":"code","bc24d256":"markdown","852b22fa":"markdown","5ba03112":"markdown","2a56e787":"markdown","bb0ffce2":"markdown","7b87a897":"markdown","fad1811b":"markdown","c3d456e3":"markdown","5ed02c4e":"markdown","d0000ea9":"markdown"},"source":{"c2fe05f6":"import tensorflow as tf\n\nimport numpy as np\nimport glob\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom tensorflow.keras import layers\nimport time\nfrom IPython.display import clear_output\ntf.__version__\nimport time\n\n","419408ad":"data = np.load('..\/input\/architecture-image-to-sketch-using-opencv-canny\/data\/data.npy')\nlabel = np.load('..\/input\/architecture-image-to-sketch-using-opencv-canny\/data\/label.npy')\nprint(data.shape)\nprint(label.shape)","e638abd0":"data = np.reshape(data, (len(data),256,256,3)) \nlabel = np.reshape(label, (len(label),256,256,1)) \nprint(data.shape)\nprint(label.shape)","3ca0846d":"data = data \/ 127.5 - 1\nlabel = label \/ 127.5 - 1","0898173b":"data[:10].max(), data[:10].min(), label[:10].max(), label[:10].min()\n\n","6e6bee86":"print(data.shape)\nprint(label.shape)\n","32bf2a22":"plt.imshow(data[25])\nplt.show()\nplt.imshow(label[25])\nplt.show()","eb053329":"def downsample(filters, size, apply_batchnorm=False):\n    initializer = tf.random_normal_initializer(0., 0.02)\n\n    result = tf.keras.Sequential()\n    result.add(\n        tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n                                kernel_initializer=initializer, use_bias=False))\n\n    if apply_batchnorm:\n        result.add(tf.keras.layers.BatchNormalization())\n\n    result.add(tf.keras.layers.LeakyReLU())\n\n    return result\n","e1213667":"def upsample(filters, size, apply_dropout=False):\n    initializer = tf.random_normal_initializer(0., 0.02)\n\n    result = tf.keras.Sequential()\n    result.add(\n        tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n                                    padding='same',\n                                    kernel_initializer=initializer,\n                                    use_bias=False))\n\n    result.add(tf.keras.layers.BatchNormalization())\n\n    if apply_dropout:\n        result.add(tf.keras.layers.Dropout(0.50))\n\n    result.add(tf.keras.layers.ReLU())\n\n    return result\n","5a8dcaa2":"def make_generator_model():\n    inputs = tf.keras.layers.Input(shape=[256, 256, 1], name='label')\n    \n    down_stack = [\n        downsample(64, 4, apply_batchnorm=False),  # (bs, 160, 160, 64)\n        downsample(128, 4),  # (bs, 80, 80, 128)\n        downsample(256, 4),  # (bs, 40, 40, 256)\n        downsample(512, 4),  # (bs, 20, 20, 512)\n        downsample(512, 4),  # (bs, 10, 10, 512)\n        downsample(512, 4),  # (bs, 5, 5, 512)\n        downsample(512, 4),  # (bs, 2, 2, 512)\n        downsample(512, 4),  # (bs, 1, 1, 512)\n    ]\n\n    up_stack = [\n        upsample(512, 4, apply_dropout=True),  # (bs, 2, 2, 1024)\n        upsample(512, 4, apply_dropout=True),  # (bs, 4, 4, 1024)\n        upsample(512, 4, apply_dropout=True),  # (bs, 8, 8, 1024)\n        upsample(512, 4),  # (bs, 16, 16, 1024)\n        upsample(256, 4),  # (bs, 32, 32, 512)\n        upsample(128, 4),  # (bs, 64, 64, 256)\n        upsample(64, 4),  # (bs, 128, 128, 128)\n    ]\n\n    initializer = tf.random_normal_initializer(0., 0.02)\n    \n    \n    last = tf.keras.layers.Conv2DTranspose(3, 4,\n                                         strides=2,\n                                         padding='same',\n                                         kernel_initializer=initializer,\n                                         activation='tanh')  # (bs, 256, 256, 3)\n    x = inputs\n\n  # Downsampling through the model\n    skips = []\n    for down in down_stack:\n        x = down(x)\n        skips.append(x)\n\n    skips = reversed(skips[:-1])\n\n    # Upsampling and establishing the skip connections\n    for up, skip in zip(up_stack, skips):\n        x = up(x)\n        x = tf.keras.layers.Concatenate()([x, skip])\n\n    x = last(x)\n\n    return tf.keras.Model(inputs=inputs, outputs=x)\n\n\n\ngenerator = make_generator_model()\ngenerator.summary()","d2c8d75b":"#tf.keras.utils.plot_model(generator, show_shapes=True)","46027c62":"def make_discriminator_model():\n    initializer = tf.random_normal_initializer(0., 0.02)\n\n    inp = tf.keras.layers.Input(shape=[256, 256, 3], name='image')\n    tar = tf.keras.layers.Input(shape=[256, 256, 1], name='label')\n\n    x = tf.keras.layers.concatenate([inp, tar])  # (bs, 256, 256, channels*2)\n\n    down1 = downsample(64, 4, False)(x)  # (bs, 128, 128, 64)\n    down2 = downsample(128, 4)(down1)  # (bs, 64, 64, 128)\n    down3 = downsample(256, 4)(down2)  # (bs, 32, 32, 256)\n    down3 = downsample(256, 4)(down3)  # (bs, 32, 32, 256)\n\n\n    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (bs, 34, 34, 256)\n    conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n                                kernel_initializer=initializer,\n                                use_bias=False)(zero_pad1)  # (bs, 31, 31, 512)\n\n    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n\n    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n\n    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (bs, 33, 33, 512)\n\n    last = tf.keras.layers.Conv2D(1, 4, strides=1,\n                                kernel_initializer=initializer)(zero_pad2)  # (bs, 30, 30, 1)\n\n    return tf.keras.Model(inputs=[inp, tar], outputs=last)\n\ndiscriminator = make_discriminator_model()\ndiscriminator.summary()\n","0c137c97":"lbl = tf.random.normal([1,256,256])\nnoise = tf.random.normal([1,100])\ntest = generator({'label':lbl}, training=False)\nyo = discriminator({'label':lbl, 'image':test}, training=False)\nplt.imshow(test[0])","5c1eb743":"cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)","eaada95b":"def discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss\n    ","3f68a573":"LAMBDA = 100\ndef generator_loss(disc_generated_output, gen_output, target):\n    #target = target \/ 127.5 - 1\n    \n    gan_loss = cross_entropy(tf.ones_like(disc_generated_output), disc_generated_output)\n    \n    # mean absolute error\n    try:\n        #target = tf.cast(target, dtype=tf.float32)\n        l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n        \n    except Exception as e:\n        print(target)\n        print(gen_output)\n        \n        \n\n    total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n\n    return total_gen_loss, gan_loss, l1_loss","8d5bb9d0":"# def generator_loss(fake_output):\n#     return cross_entropy(tf.ones_like(fake_output), fake_output)","22cd1225":"generator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5, epsilon=1e-04)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5, epsilon=1e-04)","4fc928a1":"@tf.function # compile function\ndef train_step(image_batch, label_batch):\n    \n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator({'label':label_batch}, training=True)\n        \n        real_output = discriminator({'label':label_batch, 'image':image_batch}, training=True)\n        fake_output = discriminator({'label':label_batch, 'image':generated_images}, training=True)\n        \n        \n        # CALCULATE LOSS OF FAKE AND REAL IMAGES\n        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(fake_output, generated_images, image_batch)\n        disc_loss = discriminator_loss(real_output, fake_output)\n            \n            \n        \n    # get gradients\n    gradients_of_generator = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n    \n    # \n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n    \n    return gen_total_loss, gen_gan_loss, gen_l1_loss, disc_loss\n","4f2952fa":"train_data = []\nBUFFER_SIZE = 60000\nBATCH_SIZE = 1\n\n#idx = np.random.permutation(len(data))\n\ntrain_data = list(zip(tf.data.Dataset.from_tensor_slices(data).batch(BATCH_SIZE), tf.data.Dataset.from_tensor_slices(label).batch(BATCH_SIZE)))","e9cb3957":"checkpoint_dir = '.\/training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","d7ae477a":"checkpoint_saved = '..\/input\/ganrchitect\/training_checkpoints'\n","54fed91c":"#checkpoint.restore(tf.train.latest_checkpoint(checkpoint_saved))\n\n","97728608":"seed = tf.random.normal([4, 100])\nseed_label = [label[0], label[2], label[3], label[4], label[5], label[14], label[24], label[30]]\n\nseed_label = np.reshape(seed_label, (8,256,256))\nprint(seed.shape)\nprint(seed_label.shape)\n\nfor l in seed_label:\n    plt.imshow(l)\n    plt.show()","8daae7d2":"aaaa = [data[0], data[2], data[3], data[4], data[5], data[14], data[24], data[30]]\naaaa = np.reshape(aaaa, (8,256,256,3))\n\ntest = generator({'label':seed_label}, training=False)\n\nfig = plt.figure(figsize=(20,8), dpi= 75)\n\nfor i in range(test.shape[0]):\n    plt.subplot(4, 4, i+1 )#figsize=(15,15))\n    plt.imshow((test[i, :, :, :]+1)*0.5)\n    plt.axis('off')\n    \n    j = i\n    \nfor i in range(test.shape[0]):\n    plt.subplot(4, 4, i+j+2 )#figsize=(15,15))\n    plt.imshow((aaaa[i, :, :, :]+1)*0.5)\n    plt.axis('off')","cf2eae93":"seed_label.min()","2ed77d1c":"def generate_and_save_images(model, epoch, test_input):\n  # Notice `training` is set to False.\n  # This is so all layers run in inference mode (batchnorm).\n    predictions = generator({'label':seed_label}, training=False)\n\n    fig = plt.figure(figsize=(20,8), dpi= 75)\n\n    for i in range(predictions.shape[0]):\n        plt.subplot(2, 4, i+1 )\n        plt.imshow((predictions[i, :, :, :]+1)*0.5)\n        plt.axis('off')\n\n    #plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n    plt.show()","5ab90fe1":"# import imageio\n# for i, img in enumerate(sorted(glob.glob('..\/input\/ganrchitect\/*.png'))):\n#     print(img)\n#     fig = plt.figure(figsize=(20,8), dpi= 75)\n#     #plt.subplot(2, 5, i+1 )#figsize=(15,15))\n#     plt.imshow(imageio.imread(img)[75:250,180:1300,:3])\n#     #plt.axis('off')\n#     plt.show()\n#     plt.close('all')\n    \n","2f6923b4":"# imageio.imread(img)[:,:,:3].shape","a1b1c1d5":"#  for image_batch, label_batch in zip(image_dataset, label_dataset):\n#      #train_step(image_batch, label_batch)\n#      #display(plt.imshow(image_batch[9]), label_batch[9])\n#      display(len(image_batch))\n    \n","d6a811b3":"MINUTES_TRAIN = 60*8\nepochs = 300","939b4fab":"gen_loss_epoch = []\ngen_gan_loss_epoch = []\ndisc_loss_epoch = []","01f0f4d3":"def model_refresh_without_nan(models):\n    #import numpy as np\n#     valid_weights = []\n    for l in models.get_weights():\n        if np.isnan(l).any():\n#             valid_weights.append(np.nan_to_num(l))\n            print(\"NAN found!!!!!\")\n        else:\n#             valid_weights.append(l)\n            pass\n            \n#     models.set_weights(valid_weights)","b837e9df":"raise ValueError('asd')","9b23a362":"timed = False\nstart = 0\ni = 0\n\n\nfor epoch in range(0, epochs):\n    \n#     s = tf.random.uniform(\n#                     (1,1), minval=0, maxval=1000, dtype=tf.dtypes.int32, seed=None, name=None)\n\n#     ratio = tf.random.uniform((1,1), 1, 1.2).numpy()\n#     xsz = int(256*ratio)\n#     ratio = tf.random.uniform((1,1), 1, 1.2).numpy()\n#     ysz = int(256*ratio)\n\n    gen_loss = []\n    disc_loss = []\n    gen_gan_loss = []\n    for image_batch, label_batch in train_data:\n        \n        #DATA AUGMENTATION START\n        s = tf.random.uniform(\n                        (1,1), minval=0, maxval=1000, dtype=tf.dtypes.int32, seed=None, name=None)\n    \n        ratio = tf.random.uniform((1,1), 1, 1.2).numpy()\n        xsz = int(256*ratio)\n        ratio = tf.random.uniform((1,1), 1, 1.2).numpy()\n        ysz = int(256*ratio)\n\n        a = tf.reshape(image_batch, [1,256,256,3])\n        a = tf.image.resize(a, [xsz, xsz])\n        a = tf.image.random_crop(a, (1,256,256,3), seed=s)\n\n        #b = tf.cast(label_batch, dtype=tf.float32)\n        #b = b * tf.random.uniform((1,1), 0.7, 0.999).numpy()\n        b = tf.image.resize(label_batch, [xsz, xsz])\n        b = tf.image.random_crop(b, (1,256,256,1), seed=s)\n        # DATA AUGMENTATION END\n        \n        \n        # TRAIN GAN WITH AUGMENTED DATA\n        gl, ggl, _2, dl = train_step(a, b)\n        \n        gen_gan_loss.append(ggl.numpy())\n        gen_loss.append(gl.numpy())\n        disc_loss.append(dl.numpy())\n        \n    #model_refresh_without_nan(generator)\n    gen_gan_loss_epoch.append(np.array(gen_gan_loss).mean())\n    gen_loss_epoch.append(np.array(gen_loss).mean())\n    disc_loss_epoch.append(np.array(disc_loss).mean())\n    \n    \n    if not timed:\n        start = time.time()\n        timed = True\n\n    \n    if (epoch) % 10 == 0:\n        time_elapsed = time.time() - start\n        if time_elapsed > 0:\n            clear_output(wait=True)\n            print(f'epoch = {epoch}')\n\n            generate_and_save_images(generator,\n                                 epoch + 1,\n                                 seed)\n            i = i + 1\n            \n    if (epoch) % 5 == 0:\n        if timed: \n            print(f'epoch {epoch}. time = {time.time() - start}')\n#             clear_output(wait=True)\n#             generate_and_save_images(generator,\n#                                   epoch + 1,\n#                                   seed)\n    \n#     if epoch % 20 == 0:\n#         checkpoint.save(file_prefix = checkpoint_prefix)\n        \n        \n    if time_elapsed > 60 * MINUTES_TRAIN:\n        break\n    \n\n            \n# checkpoint.save(file_prefix = checkpoint_prefix)\n\n","66278a40":"checkpoint.save(file_prefix = checkpoint_prefix)","88d59882":"fig = plt.figure(figsize=(15,12), dpi= 75)\nplt.subplot(3, 1, 1)\nplt.plot([x for x in range (1, len(gen_gan_loss_epoch)+1)], gen_gan_loss_epoch)\nplt.title('gen_gan_loss_epoch')\n\nplt.subplot(3, 1, 2)\nplt.plot([x for x in range (1, len(gen_gan_loss_epoch)+1)], disc_loss_epoch)\nplt.title('disc_loss_epoch')\n\nplt.subplot(3, 1, 3)\nplt.plot([x for x in range (1, len(gen_gan_loss_epoch)+1)], gen_loss_epoch)\nplt.title('gen_loss_epoch')\nplt.show()\n\n\n","c29bea6b":"import imageio\nfor i, img in enumerate(sorted(glob.glob('\/kaggle\/working\/*.png'))):\n    print(img)\n    fig = plt.figure(figsize=(20,8), dpi= 75)\n    #plt.subplot(2, 5, i+1 )#figsize=(15,15))\n    plt.imshow(imageio.imread(img)[75:250,180:1300,:3])\n    #plt.axis('off')\n    plt.show()\n    plt.close('all')","c35edcb7":"raise ValueError('asd')","6b0e2e14":"!pip install tensorflowjs","bf416949":"import tensorflowjs as tfjs","25453be6":"tfjs.converters.save_keras_model(generator, '\/kaggle\/working\/model')\n","44f48f77":"!cp -r ..\/input\/ganrchitect\/. \/kaggle\/working","568ab9d3":"generator.save('savedmodel\/GANrchitectGenerator.h5')\n","b203d647":"!ls savedmodel","f1747b86":"pip install tensorflowjs[wizard]","55771565":"!tensorflowjs_converter --input_format=keras savedmodel\/GANrchitectGenerator.h5 savedmodel\/tfjs_model","ef0017dd":"!ls savedmodel","5bc8ef71":"!zip -r savedmodel.zip model","46a91cfa":"print(label[0][1])","c1257812":"\ndef model_refresh_without_nan(models):\n    #import numpy as np\n    valid_weights = []\n    for l in models.get_weights():\n        if np.isnan(l).any():\n            valid_weights.append(np.nan_to_num(l))\n            print(\"!!!!!\", l)\n        else:\n            valid_weights.append(l)\n            pass\n            \n    models.set_weights(valid_weights)\n","267196ee":"model_refresh_without_nan(generator)","10280965":"for l in generator.get_weights():\n        if np.isnan(l).any():\n#             valid_weights.append(np.nan_to_num(l))\n            print(\"!!!!!\", l)","bc24d256":"# ACTUAL TRAINING","852b22fa":"## CHECKPOINT","5ba03112":"## 2. The Discriminator\n#### cGAN uses the image and label as the input for the Discriminator as supposed to image only.\n##### v.3: implemented PatchGAN\n","2a56e787":"## STUFF TO SHOW THE EVOLUTION","bb0ffce2":"# Welcome, \n### I attempt to create a GAN model that can draw architectural images from a sketch. ","7b87a897":"# Exporting to TENSORFLOW JS","fad1811b":"#  **GENERATOR** and **DISCRIMINATOR** model","c3d456e3":"Data augmented by scaling up to random size and then cropping it back down randomly","5ed02c4e":"### Very helpful diagram from matlab on how to train cGAN\n![](https:\/\/www.mathworks.com\/help\/examples\/nnet\/win64\/TrainConditionalGenerativeAdversarialNetworkCGANExample_02.png)","d0000ea9":"# **TRAINING**"}}