{"cell_type":{"df66813e":"code","2707a6e0":"code","a041dc17":"code","3f119980":"code","4527887e":"code","8f35e30c":"code","34b4ac21":"code","2bceb43c":"code","bb8af34e":"code","a0d94de0":"code","0dc43d45":"code","adbe1090":"code","1e286003":"code","98974f9d":"code","9dd869ef":"code","0bde2760":"code","c7ddaf6c":"code","edf811e3":"code","931d9e30":"code","6283cd31":"code","f6947f9b":"code","ef958da8":"code","4df74e19":"code","1b3e9ba3":"code","28412308":"code","86aca724":"code","e87dbf88":"code","bffa3dec":"markdown","ac457539":"markdown","0bf71866":"markdown","2de3576e":"markdown","2f9af324":"markdown","6dfbf89c":"markdown","1eae2204":"markdown","259cbb06":"markdown","9e875abf":"markdown","ef98f411":"markdown","8642f077":"markdown","81b30c31":"markdown","d731676f":"markdown","2f467373":"markdown","16040fd0":"markdown"},"source":{"df66813e":"!pip install pycaret\n","2707a6e0":"from pycaret.datasets import get_data\nimport pandas as pd\nimport numpy as np","a041dc17":"titanic_df = pd.read_csv(\"..\/input\/titanic-dataset-train-data\/titanic_train.csv\")","3f119980":"titanic_df.head()","4527887e":"from pycaret.classification import *    #import classification library","8f35e30c":"test1 = setup(titanic_df, target = 'Survived')  ","34b4ac21":"compare_models()  #comapre the classification model with performance measures\n\n#Very nice function in PyCaret is shows the better accuracy of all model with repespect to performance measure of calssification.","2bceb43c":"#create a XGBoost model.\n\nxgboost_model = create_model('xgboost')","bb8af34e":"#model for extra tree classifier\n\net = create_model('et') #extra tree classifier","a0d94de0":"#tunning the model.Short cut process for tunning.Without any choose the hyperparameter. \n#automatically choose and tune the model\n#here tune the adaboost model\ntune_adaboost_model = tune_model(et)","0dc43d45":"#same as tune the xgboost model\ntune_xgboost_model = tune_model(xgboost_model)","adbe1090":"#creating a decision tree model\n\ndecision_tree = create_model('dt')\n\n#ensemble the trained decision tree model\ndt_bagged = ensemble_model(decision_tree)","1e286003":"#create a model\n\nxgboost = create_model('xgboost')\n\n#AUC model\nplot_model(xgboost, plot='auc')\n","98974f9d":"#decision boundary\nplot_model(xgboost, plot='boundary')","9dd869ef":"#precision_recall\n\nplot_model(xgboost, plot='pr')","0bde2760":"#validation curve\n\nplot_model(xgboost,'vc')","c7ddaf6c":"evaluate_model(xgboost)","edf811e3":"#when data is non-linear\n\n","931d9e30":"#create model\n\ncreat_xgboost_model = create_model('xgboost')\n\n#summary plot\ninterpret_model(creat_xgboost_model)","6283cd31":"#correlation plot\ninterpret_model(creat_xgboost_model, plot='correlation')","f6947f9b":"#we are checking on test dataset","ef958da8":"interpret_model(creat_xgboost_model, plot='reason', observation=0)","4df74e19":"#create model(boosting model)\n\nxgboost_model = create_model('xgboost')\n","1b3e9ba3":"#predict model\nrf_predict = predict_model(xgboost_model)","28412308":"prediction = predict_model(xgboost_model, data=titanic_df)","86aca724":"prediction","e87dbf88":"#create model\n\nxgboost_model = create_model('xgboost')\n\n#saving model\nsave_model(xgboost_model, model_name='xgboost_models_save')","bffa3dec":"**Install PyCaret**\n\n","ac457539":"# Validation Score\nBlue line shows training score(how your model work) and green line shows cross-validation score","0bf71866":"# Precision and Recall\nGraph show precison and recall rate means Positive and Negative rate.\nRed dotted line show average precision rate.It means number of positive example.\n\n","2de3576e":"Predict model also work on unseen datasets","2f9af324":"# predict model","6dfbf89c":"# Model Evaluation\n\nLike each ans every function in a single roof.\nJust click on box and get output of that function.\nFor Example: confusion matrix","1eae2204":"# Ensemble Model","259cbb06":"Just click on any option get various ROC and AUC curve based on condcondition. ","9e875abf":"# reason plot","ef98f411":"# Interpret Model","8642f077":"# Titanic classification with AutoML - PyCaret","81b30c31":"#ROC ans AUC Curve.\nIt is very good function, shows graph also show accuracy.","d731676f":"# Below line of code:\n   This fucntion like splitting fucntion.Target variable called as target column(feature).and reamining as all features.Also this function work like in info in python(i.e. df.description()).Show description about all data means, type of features, missing features, how many numeric column, how many categorical column.It also get information about PCA, transformation, outlier, clustering, and many more is it required or not.\n  ","2f467373":"# Save Model","16040fd0":"# Compare Mdoel:\nNow comapre the machine learning model with single line.\nBefore PyCaret, for comparing ML model it require lots of steps and after that comapre manually.\nNow, it's very simple process.\n\nSo, number of classification and regression algorithm save in PyCaret library.\nJust import classification for classify the data, it means supervised and for prediction import the regression and for unsupervised import the clustering.\nAs per our data apply the any one of them and see the result of every algorithm with accuracy, Recall, precision, F1-Score and Kappa.\n\nHere show, how many algorithm for classification, regression and clustering?\nFor Classification:- 18\nFor Regression:- 25\nFor Clustering:- 9\n\nOne of the good library.\n\n"}}