{"cell_type":{"cdcfe2d3":"code","dc56fe1c":"code","979b0fa7":"code","ea7e91c9":"code","9e4160ef":"code","f24b7d05":"code","c60ef5ff":"code","106f92a6":"code","3ee4004a":"code","666ad797":"code","6d4b9a54":"code","09b9b75e":"code","998b2029":"code","6d79c8c4":"markdown","69951264":"markdown","62491c73":"markdown"},"source":{"cdcfe2d3":"import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\n\nstyle.use('fivethirtyeight')\nnp.random.seed(0)","dc56fe1c":"def chinese_restaurant_process(alpha, n):\n    \"\"\"\n    :param alpha: alpha coefficient of CRP problem\n    :param n: number of customers\n\n    :return count: number of tables opened\n    \"\"\"\n    i = 0\n    # table[k] : the number of people sitting at the table k\n    table = []\n    for i in range(n):\n        prob = list(map(lambda x: x \/ (alpha + i), table))\n        prob.append(alpha \/ (alpha + i))\n        \n        # normalize prob to use start.rv_discrete\n        # avoid errors due to real numbers\n        prob = np.array(prob)\n        prob = prob \/ prob.sum()\n        \n        # last label is -1 (The convention is to open a new table)\n        label = list(range(len(table)))\n        label.append(-1)\n        \n        # L\u1ea5y s\u1ed1 l\u01b0\u1ee3ng b\u1ea3ng \u0111\u1ea1i di\u1ec7n cho kh\u00e1ch h\u00e0ng\n        current_dist = stats.rv_discrete(name = 'dist', values = (label, prob))\n        pos = int(current_dist.rvs(size = 1))\n        \n        if pos == -1:\n            # If you open the table, add a new table with a number of people\n            table.append(1)\n        else:\n            # If you sit at the old table, that position adds one person\n            table[pos] += 1\n            \n        # count the number of table\n        count = len(table)\n    return count\n\ndef simulate_crp(alpha, step, max_iter, n_simulate):\n    \"\"\"\n    Simulate problem Chinese Restaurant Process\n    : param alpha: alpha coefficient\n    : param step: foreach loop increases step customers\n    ; param max_iter : number of iterations\n    : return list_n_table: with list_n_table[k] contains n_simulate simulator with alpha and step * k\n\n    \"\"\"\n    list_n_table = []\n    \n    for i in range(1, max_iter + 1):\n        print('Iter: %d' % i)\n        n_table = []\n        for _ in range(n_simulate):\n            n_table.append(chinese_restaurant_process(alpha, i * step))\n        list_n_table.append(n_table)\n    return list_n_table","979b0fa7":"list_n_table = simulate_crp(30, 50, 50, 100)\n\nfor i in range(50):\n    x = [i+1] * 100\n    plt.scatter(x, list_n_table[i], color = '#007aff', s = 1.2)\n\nx_mean = []\ny_mean = []\n\nfor i in range(50):\n    x_mean.append(i+1)\n    y_mean.append(sum(list_n_table[i]) \/ 100.0)\n\nplt.plot(x_mean, y_mean, color='#ff2d55')\n\nplt.xlabel('Number of Customer')\nplt.ylabel('Numer of Tables')\n\nplt.show()","ea7e91c9":"import numpy as np\nimport scipy\nfrom scipy import stats\nfrom scipy.stats import multivariate_normal\nimport matplotlib.pyplot as plt\n\nplt.style.use('bmh')\nnp.random.seed(11)\n\ns0 = 3.00 # standard deviation between centers of clusters\nss = 0.65 # Standard deviation between points in the cluster\n\nmean_1 = multivariate_normal.rvs(mean=np.array([0,0])) * s0\nmean_2 = multivariate_normal.rvs(mean=np.array([0,0])) * s0\nmean_3 = multivariate_normal.rvs(mean=np.array([0,0])) * s0\nmean_4 = multivariate_normal.rvs(mean=np.array([0,0])) * s0\n\nX1 = mean_1 + multivariate_normal.rvs(mean=np.array([0,0]), size=100) * ss\nX2 = mean_2 + multivariate_normal.rvs(mean=np.array([0,0]), size=60) * ss\nX3 = mean_3 + multivariate_normal.rvs(mean=np.array([0,0]), size=40) * ss\nX4 = mean_4 + multivariate_normal.rvs(mean=np.array([0,0]), size=65) * ss\n# labels for data points belong to the corresponding cluster\ntruth = [0]*100 + [1]*60 + [2]*40 + [3]*65\n\nX = np.concatenate((X1, X2, X3, X4))","9e4160ef":"plt.scatter(X[:,0],X[:,1])\nplt.show()","f24b7d05":"plt.scatter(X1[:,0], X1[:,1])\nplt.scatter(X2[:,0], X2[:,1])\nplt.scatter(X3[:,0], X3[:,1])\nplt.scatter(X4[:,0], X4[:,1])\nplt.show()","c60ef5ff":"class MultivariateNormal:\n    def __init__(self, D=2, s0 = 5.0, ss = 0.65):       \n        self.dd = D\n        self.vv = 5\n        self.vc = np.eye(D)\n        self.uu = np.zeros(shape=(D, 1))\n        self.nn = 0\n        self.ws = self.vc * self.vv\n        self.rr = 1.0 \/ (s0**2\/ss**2)\n        self.cc = scipy.linalg.cholesky(self.ws + self.rr * self.uu @ self.uu.T)\n        self.xx = np.zeros(shape=(D,1))\n    def add_point(self, x):\n        \n        self.nn += 1\n        self.rr += 1\n        self.vv += 1\n        self.cc = self.__cholupdate(self.cc, x, '+')\n        self.xx += x\n    def del_point(self, x):\n        \n        self.nn -= 1\n        self.rr -= 1\n        self.vv -= 1\n        self.cc = self.__cholupdate(self.cc, x, '-')\n        self.xx -= x\n    def logpredictive(self, x):\n       \n        dd = self.dd\n        nn = self.nn\n        rr = self.rr\n        vv = self.vv\n        cc = self.cc\n        xx = self.xx\n        lp = self.__z(dd,nn+1,rr+1,vv+1,self.__cholupdate(cc,x),xx+x) \\\n             - self.__z(dd,nn, rr, vv ,cc ,xx)\n        return lp\n    def __cholupdate(self, R_current, x_update, sign='+'):\n       \n        R = R_current.copy()\n        x = x_update.copy()\n        n = len(x)\n\n        for k in range(n):\n            if sign == '+':\n                r = np.sqrt(R[k, k]**2 + x[k, 0]**2)\n            else:\n                r = np.sqrt(R[k, k]**2 - x[k, 0]**2)\n            c = r \/ R[k, k]\n            s = x[k, 0] \/ R[k, k]\n\n            R[k,k] = r\n\n            if k !=n-1:\n                if sign == '+':\n                    R[(k+1):n, k] = (R[(k+1):n, k] + s * x[(k+1):n, 0]) \/ c\n                else:\n                    R[(k+1):n, k] = (R[(k+1):n, k] - s * x[(k+1):n, 0]) \/ c\n                x[(k+1):n, 0] = c * x[(k+1):n, 0] - s * R[(k+1):n, k]\n        return R\n    def __z(self, dd, nn, rr, vv, cc, xx):\n       \n        zz = - nn*dd\/2*np.log(np.pi) - dd\/2*np.log(rr) - \\\n             vv*np.sum(np.log(np.diag(self.__cholupdate(cc, xx \/ np.sqrt(rr),'-')))) \\\n             + np.sum(scipy.special.loggamma((vv-(np.arange(0,dd, 1)))\/2))\n        return zz","106f92a6":"def finite_dp_gmm(X, K, z_init=None, alpha=1.0, max_iters=100):\n   \n    N = len(X)\n    D = X.shape[1]\n    n_points_cluster = np.zeros(K, dtype=int)\n\n    if z_init is None:\n        z = np.random.randint(0, K, size=N)\n    else:\n        z = z_init\n\n    clusters = [MultivariateNormal() for _ in range(K)]\n\n    for i in range(N):\n        c = z[i]\n        n_points_cluster[c] += 1\n        clus = clusters[c]\n        clus.add_point(X[i].reshape(D,1))\n\n    for _ in range(max_iters):\n        for i in range(N):\n            z_i = z[i]\n            x_i = X[i].reshape(D,1)\n            current_clus = clusters[z_i]\n\n            current_clus.del_point(x_i)\n            n_points_cluster[z_i] -= 1\n\n            prob = np.log(alpha\/float(K) + n_points_cluster)\n            for j in range(len(clusters)):\n                prob[j] = prob[j] + clusters[j].logpredictive(x_i)\n            prob = np.exp(prob - np.max(prob)) \n            prob = prob \/ prob.sum()\n            \n            current_dist = stats.rv_discrete(values=(list(range(len(prob))), prob))\n            z_new = current_dist.rvs(size=1)\n            z_new = int(z_new)\n\n            clusters[z_new].add_point(x_i)\n            n_points_cluster[z_new] += 1\n            z[i] = z_new\n    return z","3ee4004a":"np.random.seed(7)\nK = 4\nz = finite_dp_gmm(X, K, max_iters=50)","666ad797":"for c in np.unique(z):\n    plt.scatter(X[z==c,0], X[z==c,1])\nplt.show()","6d4b9a54":"def infinite_dp_gmm(X, K=25, z_init=None, alpha=1.0, max_iters=100):\n    N = len(X)\n    D = X.shape[1]\n\n    if z_init is None:\n        z = np.random.randint(0, K, size=N)\n    else:\n        z = z_init\n        K = len(np.unique(z))\n    n_points_cluster = [0] * K\n\n    clusters = [MultivariateNormal() for _ in range(K)]\n    dummy_dist = MultivariateNormal()\n\n\n    for i in range(N):\n        c = z[i]\n        n_points_cluster[c] += 1\n        clus = clusters[c]\n        clus.add_point(X[i].reshape(D, 1))\n\n    for _ in range(max_iters):\n        for i in range(N):\n            z_i = z[i]\n            x_i = X[i].reshape(D, 1)\n\n            current_clus = clusters[z_i]\n\n            current_clus.del_point(x_i)\n            n_points_cluster[z_i] -= 1\n\n            if n_points_cluster[z_i] == 0:\n                del n_points_cluster[z_i]\n                del clusters[z_i]\n                z[z > z_i] -= 1\n\n            prob = np.log(np.array(n_points_cluster + [alpha]))\n            for j in range(len(clusters)):\n                prob[j] = prob[j] + clusters[j].logpredictive(x_i)\n            prob[-1] = prob[-1] + dummy_dist.logpredictive(x_i)\n            prob = np.exp(prob - np.max(prob)) # \u1ed5n \u0111\u1ecbnh t\u00ednh to\u00e1n s\u1ed1\n            prob = prob \/ prob.sum()\n\n            current_dist = stats.rv_discrete(values=(list(range(len(prob))), prob))\n            z_new = current_dist.rvs(size=1)\n            z_new = int(z_new)\n\n            if z_new == len(prob) - 1:\n                clusters.append(MultivariateNormal())\n                n_points_cluster.append(0)\n\n            clusters[z_new].add_point(x_i)\n            n_points_cluster[z_new] += 1\n            z[i] = z_new\n    return z","09b9b75e":"np.random.seed(7)\nz = infinite_dp_gmm(X, max_iters=50)","998b2029":"for c in np.unique(z):\n    plt.scatter(X[z==c,0], X[z==c,1])\nplt.show()","6d79c8c4":"**Chinese Restaurant Process**","69951264":"**Dirichlet Process Mixture Model (DPMM)**\n\nUsing Dirichlet Processes allows us to have a mixture model with infinite components which can be thought as taking the limit of the finite model for k to infinity.\n![image.png](attachment:image.png)","62491c73":"![image.png](attachment:image.png)"}}