{"cell_type":{"e4ef6fb1":"code","303d8bc6":"code","5f7e277b":"code","039e0a36":"code","c9374506":"code","2ba5b612":"code","edb3f11d":"code","23af3a36":"code","16afae35":"code","60bfe7c2":"code","ca6d737a":"code","9dd6f6f2":"code","1d47544e":"code","518e2416":"code","f269c88a":"code","64ffc226":"code","85f4b98d":"code","3ceccca0":"code","02f80346":"code","6c4767d4":"code","51a2e017":"code","2d3dca97":"code","4a4e2a28":"code","0d780c01":"code","ac446491":"code","cf96d960":"code","b3a1c229":"code","3fda8e80":"code","6ace217c":"code","60c13dbb":"code","9aa9ca33":"markdown","96acb4b9":"markdown","eba97fdd":"markdown"},"source":{"e4ef6fb1":"import numpy as np\nimport tensorflow as tf\nimport keras\n\nfrom keras.models import Sequential,load_model\nfrom keras.layers import Dense, Conv2D ,LSTM, MaxPooling2D , Flatten , Dropout \nfrom keras.layers import BatchNormalization,TimeDistributed\n\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping,ReduceLROnPlateau\n\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (15,5)\nimport seaborn as sns\nimport pandas as pd\nimport os\nimport random\nimport time\nimport os\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nfrom scipy import signal\nfrom scipy.fft import fftshift\n","303d8bc6":"idle = np.load(\"..\/input\/eeg8chanel\/data8\/idle\/1608706768.npy\")\nkanan = np.load(\"..\/input\/eeg8chanel\/data8\/kanan\/1608707012.npy\")\nkiri = np.load(\"..\/input\/eeg8chanel\/data8\/kiri\/1608707050.npy\")\nmaju = np.load(\"..\/input\/eeg8chanel\/data8\/maju\/1608706976.npy\")","5f7e277b":"import pandas as pd \nimport numpy as np \n  \n\nD1 = pd.DataFrame(idle[249]) \nD1.to_csv('idle.csv')\nD1 = pd.read_csv('idle.csv')\nD1=pd.DataFrame(D1.values, columns = [\"label\", \"ch1\", \"ch2\", \"ch3\", \n                                          \"ch4\",\"ch5\",\"ch6\",\"ch7\",\"ch8\"])\nD1.loc[D1['label'] >-1, 'label'] = '1'\nD1.to_csv('idle.csv')\n#D1\n","039e0a36":"D2 = pd.DataFrame(kanan[249]) \nD2.to_csv('kanan.csv')\nD2 = pd.read_csv('kanan.csv')\nD2=pd.DataFrame(D2.values, columns = [\"label\", \"ch1\", \"ch2\", \"ch3\", \n                                          \"ch4\",\"ch5\",\"ch6\",\"ch7\",\"ch8\"])\nD2.loc[D2['label'] >-1, 'label'] = '2'\nD2.to_csv('kanan.csv')\n#D2\n","c9374506":"D3 = pd.DataFrame(kiri[249]) \nD3.to_csv('kiri.csv')\nD3 = pd.read_csv('kiri.csv')\nD3=pd.DataFrame(D3.values, columns = [\"label\", \"ch1\", \"ch2\", \"ch3\", \n                                          \"ch4\",\"ch5\",\"ch6\",\"ch7\",\"ch8\"])\nD3.loc[D3['label'] >-1, 'label'] = '3'\nD3.to_csv('kiri.csv')\n#D3","2ba5b612":"D4 = pd.DataFrame(maju[249]) \nD4.to_csv('maju.csv')\nD4 = pd.read_csv('maju.csv')\nD4=pd.DataFrame(D4.values, columns = [\"label\", \"ch1\", \"ch2\", \"ch3\", \n                                          \"ch4\",\"ch5\",\"ch6\",\"ch7\",\"ch8\"])\nD4.loc[D4['label'] >-1, 'label'] = '4'\nD4.to_csv('maju.csv')\n#D4","edb3f11d":"a = pd.read_csv(\".\/idle.csv\")\nb = pd.read_csv(\".\/kiri.csv\")\nc = pd.read_csv(\".\/maju.csv\")\nd = pd.read_csv(\".\/kanan.csv\")\ntot= pd.concat([a,b,c,d])\ntot.to_csv('total.csv')\n#tot\n","23af3a36":"df = pd.read_csv('total.csv')\ndf.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1, inplace=True)\n\ndf","16afae35":"df_train= pd.read_csv('total.csv')","60bfe7c2":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.preprocessing import LabelEncoder\nimport pandas as pd\nfrom keras.metrics import top_k_categorical_accuracy\ndef top_3_accuracy(x,y): return top_k_categorical_accuracy(x,y, 3)\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nfrom glob import glob\nimport gc\ngc.enable()","ca6d737a":"from keras.utils import np_utils\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import BatchNormalization, Conv1D, LSTM, Dense, Dropout","9dd6f6f2":"df= pd.read_csv('total.csv')\n\nX = df.iloc[:,1:]\nY = df.iloc[:,2]\nl = ['complement'] * (250- X.shape[1]) \nfor index,col in enumerate(l):\n    X[col+str(index)] = 0\n\nX = X.values\nY = Y.values\nX.shape,Y.shape","1d47544e":"# encode class values as integers\nencoder = LabelEncoder()\nencoder.fit(Y)\nencoded_Y = encoder.transform(Y)\n# convert integers to dummy variables (i.e. one hot encoded)\ndummy_y = np_utils.to_categorical(encoded_Y)\ndummy_y.shape","518e2416":"def get_model():\n    model = Sequential()\n    model.add(LSTM(32,input_shape=(25,10), return_sequences=True))    \n    model.add(LSTM(32))  \n    model.add(Dense(4, activation = 'softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","f269c88a":"get_model().summary()","64ffc226":"from sklearn.model_selection import KFold\nimport numpy\n# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\n\n# define 10-fold cross validation test harness\nkfold = KFold(n_splits=3, shuffle=True, random_state=seed)\ncvscores = []\nbest = -1\nfor train, test in kfold.split(X, dummy_y):\n    model = get_model()\n    standard = StandardScaler().fit(X[train])\n    \n    x_train_standard = standard.transform(X[train]).reshape(-1,25,10)\n    x_test_standard = standard.transform(X[test]).reshape(-1,25,10)\n    \n    model_history = model.fit(x_train_standard, dummy_y[train], epochs=25, batch_size=32, verbose=1)\n    scores = model.evaluate(x_test_standard, dummy_y[test], verbose=1)\n    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    cvscores.append(scores[1] * 100)\n    if scores[1] > best:\n        best = scores[1]\n        history = model_history\nprint(\"%.2f%% (+\/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))","85f4b98d":"from keras.utils import Sequence\nclass SeqGen(Sequence):\n\n    def __init__(self, x_set, y_set, batch_size):\n        self.x, self.y = x_set, y_set\n        self.batch_size = batch_size\n\n    def __len__(self):\n        return int(np.ceil(len(self.x) \/ float(self.batch_size)))\n\n    def __getitem__(self, idx):\n        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n        return batch_x, batch_y","3ceccca0":"# Fit the model\nmodel = get_model()\nx_train, x_test, y_train, y_test = train_test_split(\n            X, dummy_y, test_size=0.3, random_state=42, shuffle=True)\nstandard = StandardScaler().fit(x_train)\nx_train_standard = standard.transform(x_train).reshape(-1,25,10)\nx_test_standard = standard.transform(x_test).reshape(-1,25,10)\nhistory = model.fit_generator(SeqGen(x_train_standard,y_train,batch_size=32), validation_data=(x_test_standard,y_test), epochs=25, verbose=1)","02f80346":"model.evaluate(x_test_standard, y_test)","6c4767d4":"labels=np.argmax(y_test, axis=1)\npredictions = model.predict_classes(x_test_standard, batch_size=32, verbose=1)\nprint(classification_report(labels, predictions ))","51a2e017":"y_tn=np.argmax(y_train, axis=1)\n\n\n\nsign = ['kiri', 'maju','idle','kanan']\nencoder = LabelEncoder()\nencoder_y = encoder.fit_transform(labels)\ntrain_labels = to_categorical(encoder_y,num_classes=None)\npredictions = model.predict_classes(x_train_standard, batch_size=32, verbose=1)\ncm = confusion_matrix(y_tn,predictions)\nplt.figure(figsize = (5,5))\nsns.heatmap(cm,cmap= \"Blues\",xticklabels=sign, yticklabels=sign, linecolor = 'black' ,\n                linewidth = 1 , annot = True, fmt='')\n","2d3dca97":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\nimport os\nimport random\nimport time","4a4e2a28":"df= pd.read_csv('total.csv')\n\nX = df.iloc[:,1:]\nY = df.iloc[:,2]\nl = ['complement'] * (250- X.shape[1]) \nfor index,col in enumerate(l):\n    X[col+str(index)] = 0\n\nX = X.values\nY = Y.values\nX.shape,Y.shape","0d780c01":"# encode class values as integers\nencoder = LabelEncoder()\nencoder.fit(Y)\nencoded_Y = encoder.transform(Y)\n# convert integers to dummy variables (i.e. one hot encoded)\ndummy_y = np_utils.to_categorical(encoded_Y)\ndummy_y.shape","ac446491":"def model_cnn():\n    model = Sequential()\n\n    model.add(Conv1D(64, (3), input_shape=(25,10)))\n    model.add(Activation('relu'))\n\n    model.add(Conv1D(64, (2)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling1D(pool_size=(2)))\n\n    model.add(Conv1D(64, (2)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling1D(pool_size=(2)))\n\n    model.add(Flatten())\n\n    model.add(Dense(512))\n\n    model.add(Dense(4))\n    model.add(Activation('softmax'))\n\n    model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n    return model\n\n","cf96d960":"model_cnn().summary()","b3a1c229":"from sklearn.model_selection import KFold\nimport numpy\n# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\n\n# define 10-fold cross validation test harness\nkfold = KFold(n_splits=3, shuffle=True, random_state=seed)\ncvscores = []\nbest = -1\nfor train, test in kfold.split(X, dummy_y):\n    \n    model = model_cnn()\n    standard = StandardScaler().fit(X[train])\n    \n    x_train_standard = standard.transform(X[train]).reshape(-1,25,10)\n    x_test_standard = standard.transform(X[test]).reshape(-1,25,10)\n    \n    model_history = model.fit(x_train_standard, dummy_y[train], epochs=25, batch_size=32, verbose=1)\n    scores = model.evaluate(x_test_standard, dummy_y[test], verbose=1)\n    \n    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    cvscores.append(scores[1] * 100)\n    if scores[1] > best:\n        best = scores[1]\n        history = model_history\nprint(\"%.2f%% (+\/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))","3fda8e80":"model.evaluate(x_test_standard, dummy_y[test])","6ace217c":"labels=np.argmax( dummy_y[test], axis=1)\npredictions = model.predict_classes(x_test_standard, batch_size=32, verbose=1)\nprint(classification_report(labels, predictions ))","60c13dbb":"y_tn=np.argmax(dummy_y[train], axis=1)\npredictions[1]\n\n\nsign = ['kiri', 'maju','idle','kanan']\nencoder = LabelEncoder()\nencoder_y = encoder.fit_transform(labels)\ntrain_labels = to_categorical(encoder_y,num_classes=None)\npredictions = model.predict_classes(x_train_standard, batch_size=32, verbose=1)\ncm = confusion_matrix(y_tn,predictions)\nplt.figure(figsize = (5,5))\nsns.heatmap(cm,cmap= \"Blues\",xticklabels=sign, yticklabels=sign, linecolor = 'black' ,\n                linewidth = 1 , annot = True, fmt='')","9aa9ca33":"#LSTM","96acb4b9":"#CNN 1D","eba97fdd":"# DATA"}}