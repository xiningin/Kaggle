{"cell_type":{"098c9ef1":"code","5f8a3416":"code","98459550":"code","9de31b45":"code","92d4772a":"code","10353c6f":"code","c10985c2":"code","597b6fd4":"code","23ea96d0":"code","a3878a35":"code","48e81845":"code","9c50112e":"code","a2c44d6b":"code","734d6983":"code","b54a9ab5":"code","82142e3d":"code","94d19f54":"code","adcab8e8":"code","353ca54d":"code","a6dae5df":"code","3638c80b":"code","47c9b818":"code","bcd57bf0":"code","517c105a":"code","d702bff8":"code","d863e2a7":"code","e6994c69":"code","33d47207":"code","7dba8ba7":"code","446659a6":"code","9567d838":"code","5fab3dbb":"code","da48ceba":"code","b0a56853":"code","d1ec9d73":"code","141fd098":"code","5a18c47d":"code","9c31d135":"code","f7e67f1d":"code","298afbd1":"code","f0914750":"code","9a29cb10":"code","0aa8e0bc":"markdown","dececf13":"markdown","460f9ab1":"markdown","d57dcbd8":"markdown","4866f0b9":"markdown","16147eae":"markdown","b8cfe9ca":"markdown","91736d5f":"markdown","238b0d1d":"markdown","a076f46c":"markdown","c95815a2":"markdown","266e0b59":"markdown","e2f92951":"markdown","45b10947":"markdown","18cc6231":"markdown","823d3588":"markdown","139d970b":"markdown","229ee4a3":"markdown","0fb0e3cf":"markdown","85687b4a":"markdown","98e46727":"markdown","88e05de9":"markdown","e7b02240":"markdown","a27f454d":"markdown","03c02f09":"markdown","e72e2832":"markdown"},"source":{"098c9ef1":"import pandas as pd","5f8a3416":"df = pd.read_csv('..\/input\/sample-data\/data.csv')","98459550":"df.head(1)","9de31b45":"# At first lets see the test file\nsepdf = pd.read_csv('..\/input\/textfile\/separator.txt')\nsepdf.head()","92d4772a":"# when we use sep we get a clean organized DataFrame\nsepdf = pd.read_csv('..\/input\/textfile\/separator.txt', sep='|')\nsepdf.head()","10353c6f":"# Columns or Features name as header \nheaderdf = pd.read_csv('..\/input\/sample-data\/data.csv', header = 0)\nheaderdf.head(2)","c10985c2":"# Make second line as a header \nheaderdf = pd.read_csv('..\/input\/sample-data\/data.csv', header = 1)\nheaderdf.head(2)","597b6fd4":"headerdf = pd.read_csv('..\/input\/sample-data\/data.csv', header = None)\nheaderdf.head(2)","23ea96d0":"columns_name = ['Company','Rank','Revenue_change','Profits','Assets','Profit_Change','CEO','Industry' ,'Sector','OldRank','Country','Location','WebSite', 'GlobalList', 'Emp','StockHolder']\nnamesdf = pd.read_csv('..\/input\/sample-data\/data.csv', names=columns_name)\nnamesdf.head()","a3878a35":"df = pd.read_csv('..\/input\/sample-data\/data.csv', index_col = 0)\ndf.head(2)","48e81845":"df1 = pd.read_csv('..\/input\/sample-data\/data.csv', index_col=[0,1])\ndf1.head(2)","9c50112e":"df2 = pd.read_csv('..\/input\/sample-data\/data.csv', index_col=[\"company\", \"rank\"])\ndf2.head(2)","a2c44d6b":"df = pd.read_csv('..\/input\/sample-data\/data.csv', usecols=['rank', 'company','profits'])\ndf.head(2)","734d6983":"# Alternative way by columns serial \ndf = pd.read_csv('..\/input\/sample-data\/data.csv', usecols=[0,1,2,3])\ndf.head(2)","b54a9ab5":"# rank and profit columns are removed \ndf = pd.read_csv('..\/input\/sample-data\/data.csv', usecols= lambda column : column not in ['rank', 'profits'])\ndf.columns","82142e3d":"df = pd.read_csv('..\/input\/squeez\/squeeze.csv')\ndf.head()","94d19f54":"type(df)","adcab8e8":"df = pd.read_csv('..\/input\/squeez\/squeeze.csv', squeeze=True)\ntype(df)","353ca54d":"# No header name \n# By default it set 0 to N\ndf = pd.read_csv('..\/input\/sample-data\/data.csv', header=None)\ndf.head(2)","a6dae5df":"df = pd.read_csv('..\/input\/sample-data\/data.csv', header=None, prefix='Col')\ndf.head(2)","3638c80b":"df = pd.read_csv('..\/input\/doublecol\/duplicated_columns.csv')\ndf.head(1)","47c9b818":"print('Total columns= ',df.shape[1])","bcd57bf0":"# Make duplicated columns name unique . add 1 at the end of the duplicated colums name\ndf = pd.read_csv('..\/input\/doublecol\/duplicated_columns.csv', mangle_dupe_cols=True)\ndf.head(1)","517c105a":"# Read all integer data \n\ndf = pd.read_csv('..\/input\/sample-data\/data.csv')\ndf.head(2)","d702bff8":"df.info()","d863e2a7":"# Here rank, revenues is int64 lets make it float64\ndf1 = pd.read_csv('..\/input\/sample-data\/data.csv', dtype={'revenues':\"float64\", \"rank\":\"float64\"})\ndf1.info()","e6994c69":"# Replace '.' with ',' in a floating point  columns\nfunc = lambda x : (x.replace('.', ','))\ndf = pd.read_csv('..\/input\/sample-data\/data.csv', converters = {'profits': func})","33d47207":"df.profits.head(3)","7dba8ba7":"df = pd.read_csv('..\/input\/sample-data\/data.csv', encoding = 'ISO-8859-1', true_values = ['Yes'], false_values = ['No'])","446659a6":"df.col1.head(3)\n# Yes and No values are changes with in True and False in Col1 columns","9567d838":"# lets skip 2nd rows( where company = 'State Grid')\ndf = pd.read_csv('..\/input\/sample-data\/data.csv', skiprows=2)\ndf.head()\n\n# It removes all above 2 rows","5fab3dbb":"# skip selected rows \ndf = pd.read_csv('..\/input\/sample-data\/data.csv', skiprows=[3,4,5])\ndf.shape\n# Three rows are removed from 500 roews","da48ceba":"df = pd.read_csv('..\/input\/sample-data\/data.csv', skipfooter=2, engine='python')\ndf.shape","b0a56853":"# read only first 10 rows\ndf = pd.read_csv('..\/input\/sample-data\/data.csv', nrows=10)\ndf.shape","d1ec9d73":"df = pd.read_csv('..\/input\/sample-data\/data.csv')","141fd098":"df = pd.read_csv('..\/input\/sample-data\/new_data.csv')\ndf.head(3)\n# If you directly onel the file using excel you will find col1 has some blank rows and and both col1, col2 has NaN values","5a18c47d":"# If your data automatically not converted to 'NaN' then you could use this \n# After encoding the values \ndf = pd.read_csv('..\/input\/sample-data\/new_data.csv', encoding = 'ISO=8859-1')\ndf.head()","9c31d135":"# If you like to keep default null valuese \ndf = pd.read_csv('..\/input\/sample-data\/new_data.csv', encoding = 'ISO=8859-1', keep_default_na=False)\ndf.head(2)","f7e67f1d":"df = pd.read_csv('..\/input\/sample-data\/new_data.csv')\ndf.head(2)","298afbd1":"# In company columns first rows has \"walmart\". lets make it null values\ndf = pd.read_csv('..\/input\/sample-data\/new_data.csv', na_values = ['Walmart'])\ndf.head(2)\n\n# Walmart replaced with NaN (Not a Number) Values ","f0914750":"df = pd.read_csv('..\/input\/sample-data\/new_data.csv', na_values = {'country', 'China'})\ndf.country.head()\n# All china contry are removed to NaN","9a29cb10":"df = pd.read_csv('..\/input\/sample-data\/new_data.csv', verbose=True)","0aa8e0bc":"# 18. verbose\nPrint additional informations \n\nIt will show flowing informations\n-----------------------------------\nTokenization took: 1.00 ms\nType conversion took: 4.02 ms\nParser memory cleanup took: 0.00 ms","dececf13":"# 14. nrows\nRead limited numbers of rows from a files. ","460f9ab1":"# 4. index_col\nindex_col = 0 refers first columns names in rows number ","d57dcbd8":"# 15.  default NaN values\nAll these strings are considered as default NaN values by pandas read_csv function \u2013 \u201d, \u2018#N\/A\u2019, \u2018#N\/A N\/A\u2019, \u2018#NA\u2019, \u2018-1.#IND\u2019, \u2018-1.#QNAN\u2019, \u2018-NaN\u2019, \u2018-nan\u2019, \u20181.#IND\u2019, \u20181.#QNAN\u2019, \u2018N\/A\u2019, \u2018NA\u2019, \u2018NULL\u2019, \u2018NaN\u2019, \u2018n\/a\u2019, \u2018nan\u2019, \u2018null\u2019.","4866f0b9":"# Covered Sections \n1. sep\n2. header\n3. names \n4. index_col \n5. usecols\n6. squeeze\n7. prefix\n8. Marge Duplicated columns\n9. columns dtype\n10. Converters\n11. true_values, false_values\n12. skiprows\n13. skipfooter\n14. nrows\n15. default NaN values\n16. keep default null values\n17. Keep null_values\n18. verbose","16147eae":"# 5. usecols \nSelect specefic columns from a large dataset \ncolumns order are maintain on actual dataset not your custom columns name ","b8cfe9ca":"## We often use Comma Separated Values in sort(.csv) formatted dataset for our data science analysis. Here is some pandas buildin helpful parameters which will make your work more easier.\n\n### I suggest you try to do practice each section for a while. It will give you fun as well as get some expertise on pandas.\n","91736d5f":"# 16. keep default null valuese ","238b0d1d":"### Remove columns names ","a076f46c":"Rand and revenues data type turn into float64","c95815a2":"# 1. sep\nIf your datset looks like below(separator between each field). you have to seperate '|' to remove this ","266e0b59":"# 9. columns dtype\nset columns data type single or multiple columns at a time ","e2f92951":"# 12. skiprows\nIt will allow how many rows you want to skip from starts","45b10947":"If you want to interprate the an string in a specefic columns ","18cc6231":"header = 1 (Consider second line of the dataset as header)","823d3588":"# 6. squeeze\nIf your dataset has only one columns and you want to make it as a series then you have to set squeeze=True. It will return data as a seris not dataframe ","139d970b":"# 17. Keep null_values \nIf you like to keep or replace any additional string as a null values then you could use this ","229ee4a3":"# 11. true_values , false_values\nreplace Yes, No with True False ","0fb0e3cf":"# 13. skipfooter\nremoves numbers of rows from bottom of the file.","85687b4a":" # 2. Header \nDefains which line of your dataset is considered to be a header. **By default first rows consider as a header**. But if you want, you could use as ","98e46727":"#  8. Marge Duplicated columns\nHere duplicated columns are revenues1, profits1, sectors1","88e05de9":"Header = None ( Remove headers from dataset)","e7b02240":"# 3. Names\nIf you change entire header colums name you have to create a list of new headers name. Make sure you put all columns name ","a27f454d":"Multiple columns name in index_col \n1. index_col = [0,1]  defines columns name using serial number \n2. index_col = [\"column1\", \"column2\"]","03c02f09":"# 10. Converters \nConvert values in certain columns, using a dictionary functions. ","e72e2832":"# 7. prefix \nWhen your dataset has not any olumns or header =None, you could set a fixed columns name for your header "}}