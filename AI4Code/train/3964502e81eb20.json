{"cell_type":{"019145b0":"code","55133b1e":"code","a9795785":"code","eb084c7e":"code","98b89059":"code","91ca71a1":"code","b3338164":"code","f2172aac":"code","0e04dc2f":"code","4b47fe14":"code","93fe619d":"code","3ed5b8b7":"code","d6defe79":"code","923b5ccb":"code","d0558e80":"code","c59fc5ff":"code","c548175d":"code","93685590":"code","0c422d31":"code","353c5fe7":"code","46a1ea32":"code","0135b012":"code","38b92630":"code","520d33f1":"code","c2acc13b":"markdown","b4963f82":"markdown","e7e4ed37":"markdown","86f142b8":"markdown","595340f7":"markdown","7fcfae06":"markdown","438f2c9c":"markdown","8d32ba40":"markdown"},"source":{"019145b0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GlobalMaxPooling1D\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping","55133b1e":"FILE_PATH = '\/kaggle\/input\/clickbait-dataset\/clickbait_data.csv'\ndata = pd.read_csv(FILE_PATH)\ndata","a9795785":"text = data['headline'].values\nlabels = data['clickbait'].values\ntext_train, text_test, y_train, y_test = train_test_split(text, labels)\nprint(text_train.shape, text_test.shape, y_train.shape, y_test.shape)","eb084c7e":"vocab_size = 5000\nmaxlen = 500\nembedding_size = 32\n\ntokenizer = Tokenizer(num_words=vocab_size)\ntokenizer.fit_on_texts(text)\n\nX_train = tokenizer.texts_to_sequences(text_train)\nx_test = tokenizer.texts_to_sequences(text_test)\n\nX_train = pad_sequences(X_train, maxlen=maxlen)\nx_test = pad_sequences(x_test, maxlen=maxlen)","98b89059":"model = Sequential()\nmodel.add(Embedding(vocab_size, embedding_size, input_length=maxlen))\nmodel.add(LSTM(32, return_sequences=True))\nmodel.add(GlobalMaxPooling1D())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()","91ca71a1":"callbacks = [\n    EarlyStopping(\n        monitor='val_accuracy',\n        min_delta=1e-4,\n        patience=3,\n        verbose=1\n    ),\n    ModelCheckpoint(\n        filepath='weights.h5',\n        monitor='val_accuracy', \n        mode='max', \n        save_best_only=True,\n        save_weights_only=True,\n        verbose=1\n    )\n]","b3338164":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nhistory = model.fit(X_train, y_train, batch_size=512, validation_data=(x_test, y_test), epochs=20, callbacks=callbacks)","f2172aac":"model.load_weights('weights.h5')\nmodel.save('model')","0e04dc2f":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nx = range(1, len(acc) + 1)\n\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(x, acc, 'b', label='Training acc')\nplt.plot(x, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.subplot(1, 2, 2)\nplt.plot(x, loss, 'b', label='Training loss')\nplt.plot(x, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","4b47fe14":"preds = [round(i[0]) for i in model.predict(x_test)]\ncm = confusion_matrix(y_test, preds)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.xticks(range(2), ['Not clickbait', 'Clickbait'], fontsize=16)\nplt.yticks(range(2), ['Not clickbait', 'Clickbait'], fontsize=16)\nplt.show()","93fe619d":"tn, fp, fn, tp = cm.ravel()\n\nprecision = tp\/(tp+fp)\nrecall = tp\/(tp+fn)\n\nprint(\"Recall of the model is {:.2f}\".format(recall))\nprint(\"Precision of the model is {:.2f}\".format(precision))","3ed5b8b7":"test = ['My biggest laugh reveal ever!', 'Learning game development with Unity', 'A tour of Japan\\'s Kansai region', '12 things NOT to do in Europe']\ntoken_text = pad_sequences(tokenizer.texts_to_sequences(test), maxlen=maxlen)\npreds = [round(i[0]) for i in model.predict(token_text)]\nfor (text, pred) in zip(test, preds):\n    label = 'Clickbait' if pred == 1.0 else 'Not Clickbait'\n    print(\"{} - {}\".format(text, label))","d6defe79":"from sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import linear_model\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import linear_model\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.cluster import KMeans\nfrom lightgbm import LGBMClassifier","923b5ccb":"knn = KNeighborsClassifier(n_neighbors=15)\nclf = knn.fit(X_train, y_train)\ny_pred = clf.predict(x_test)\nacc_knb_model=roc_auc_score(y_test, y_pred)*100\nacc_knb_model","d0558e80":"lr = LogisticRegression(C = 0.2)\nclf1 = lr.fit(X_train, y_train)\ny_pred1 = clf1.predict(x_test)\nacc_log_reg=roc_auc_score(y_test, y_pred1)*100\nacc_log_reg","c59fc5ff":"clf2 = GaussianNB().fit(X_train, y_train)\ny_pred2 = clf2.predict(x_test)\nacc_nb=roc_auc_score(y_test, y_pred2)*100\nacc_nb","c548175d":"clf3 = tree.DecisionTreeClassifier().fit(X_train, y_train)\ny_pred3 = clf3.predict(x_test)\nacc_dt=roc_auc_score(y_test, y_pred3)*100\nacc_dt","93685590":"clf4 = RandomForestClassifier(max_depth=5, random_state=0).fit(X_train, y_train)\ny_pred4 = clf4.predict(x_test)\nacc_rmf_model=roc_auc_score(y_test, y_pred4)*100\nacc_rmf_model","0c422d31":"sgd_model=SGDClassifier()\nsgd_model.fit(X_train,y_train)\nsgd_pred=sgd_model.predict(x_test)\nacc_sgd=round(sgd_model.score(X_train,y_train)*100,10)\nacc_sgd","353c5fe7":"xgb_model=XGBClassifier()\nxgb_model.fit(X_train,y_train)\nxgb_pred=xgb_model.predict(x_test)\nacc_xgb=round(xgb_model.score(X_train,y_train)*100,10)\nacc_xgb","46a1ea32":"lgbm = LGBMClassifier()\nlgbm.fit(X_train,y_train)\nlgbm_pred=lgbm.predict(x_test)\nacc_lgbm=round(lgbm.score(X_train,y_train)*100,10)\nacc_lgbm","0135b012":"regr = linear_model.LinearRegression()\nregr.fit(X_train,y_train)\nregr_pred=regr.predict(x_test)\nacc_regr=round(regr.score(X_train,y_train)*100,10)\nacc_regr","38b92630":"clf5 = SVC(gamma='auto').fit(X_train, y_train)\ny_pred5 = clf5.predict(x_test)\nacc_svm_model=roc_auc_score(y_test, y_pred5)*100\nacc_svm_model","520d33f1":"results = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest','Stochastic Gradient Decent','Linear Regression','Naive Bayes','XGBoost','LightGBM','Decision Tree'],\n    'Score': [acc_svm_model, acc_knb_model, acc_log_reg, \n              acc_rmf_model,acc_sgd,acc_regr,acc_nb,acc_xgb,acc_lgbm,acc_dt]})\nresult_df = results.sort_values(by='Score', ascending=False)\nresult_df = result_df.set_index('Score')\nresult_df","c2acc13b":"# Tokenize text","b4963f82":"# Importing libraries","e7e4ed37":"# Loading data","86f142b8":"# Plot training metrics","595340f7":"# Plot confusion matrix and metrics","7fcfae06":"# Train-test split","438f2c9c":"# Run predictions on arbitrary user input","8d32ba40":"# Define and train model"}}