{"cell_type":{"5d799326":"code","43e2daea":"code","ffe0efb2":"code","ff34c74d":"code","a8f8a814":"code","dc22d969":"code","cd134b8c":"code","37afc65e":"code","afa828a8":"code","12f7e5f2":"code","cf85cb3f":"code","da4e8d65":"code","8441c66f":"code","ab6b7c65":"code","45f85746":"code","3f202f2d":"code","f1c2a25c":"code","1a5b604b":"markdown","d06215ca":"markdown","03e3feb6":"markdown","138b68b8":"markdown","07bd785b":"markdown","2228434b":"markdown","fa4c90b5":"markdown","8e6d43b6":"markdown","c0ab8821":"markdown","560b70e2":"markdown","6483de37":"markdown","ebe9f584":"markdown","d6ac1dc7":"markdown","ff57ed5e":"markdown"},"source":{"5d799326":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport glob\nimport PIL.Image as Image\n\n","43e2daea":"def get_folder_names(mode, dataid= str):\n    return f'..\/input\/landmark-recognition-2020\/{mode}\/{dataid[0]}\/{dataid[1]}\/{dataid[2]}\/{dataid}.jpg'","ffe0efb2":"train_csv = pd.read_csv('..\/input\/landmark-recognition-2020\/train.csv')\nprint('Number of landmark images in train set:', len(train_csv))\ntrain_csv.head()\n","ff34c74d":"submission_csv= pd.read_csv('..\/input\/landmark-recognition-2020\/sample_submission.csv')\nsubmission_csv.head()","a8f8a814":"print('Any missing values?\\n', train_csv.isnull().values.any()) ","dc22d969":"print('Any Duplicates?', train_csv.duplicated().values.any())","cd134b8c":"landmark_count = train_csv.landmark_id.value_counts()","37afc65e":"fig = plt.figure(figsize = (20, 7))\nsns.distplot(landmark_count, hist = False);\nplt.title('Class Distribution', size = 20);\nplt.xlabel('number of images', size = 15);","afa828a8":"limits = [None, (0,200), (0,100)]\nfig = plt.figure(figsize = (20, 7))\nfor i, lim in enumerate(limits):\n    plt.subplot(len(limits),1,i+1)\n    sns.boxplot(landmark_count)\n    plt.xlim(lim)\n    plt.title(lim)\nplt.tight_layout()\n\nprint((landmark_count>200).sum())","12f7e5f2":"landmark_count_id = list(landmark_count.index)","cf85cb3f":"def get_images(data, landmarkid, num):\n    sub = data.id[data.landmark_id == landmarkid] \n    fig = plt.figure(figsize= (10, 10))\n    fig.suptitle(f\"landmark ID  {landmarkid}\")\n    for i in range(num):\n        if num > 3:\n            plt.subplot(num ** (1\/2), num ** (1\/2), i+1)\n        else:\n            plt.subplot(1, num, i+1)\n        img = Image.open(get_folder_names('train' ,list(sub)[i]))\n        plt.imshow(img)\n        plt.axis('off')\n    \n\nget_images(train_csv, landmark_count_id[0], 9)","da4e8d65":"get_images(train_csv, landmark_count_id[1], 9)","8441c66f":"get_images(train_csv, landmark_count_id[8], 9)","ab6b7c65":"get_images(train_csv, landmark_count_id[-1], 2)","45f85746":"get_images(train_csv, landmark_count_id[-2], 2)","3f202f2d":"get_images(train_csv, landmark_count_id[-3], 2)","f1c2a25c":"a = glob.glob('..\/input\/landmark-recognition-2020\/test\/*\/*\/*\/*.jpg')\nnum = 10\nfig = plt.figure(figsize = (20, 10))\nfor i in range(num):\n    plt.subplot(1, num, i+1)\n    plt.axis('off')\n    randint = np.random.randint(0, len(a))\n    img = Image.open(a[randint])\n    plt.imshow(img)\n    \n    ","1a5b604b":"# Sightseeing","d06215ca":"Finally, the last feature of Google's landmark dataset lies in its testset. Most of the pictures in the testset do not belong to any landmark. Therefore, we need to leave a white space for some of the testset pictures.","03e3feb6":"# Exploratory Data Analysis","138b68b8":"The pictures suggest that the dataset suffers from **Intra-Class Variation**. In other words, there is a high variation in the pictures of each class. For instance, in the 126637 landmark pictures which apparently represents a coast, the images show different parts of the landmark and from different angles. This means that our predictive model should be highly robust. ","07bd785b":"Now let's take a look at some of the landmarks. First we will look at the classes with the greatest image count, and then we will go over some of the data on the other side.  ","2228434b":"While one class contains **6000** images, ***75%*** contain less then **25**. Only **483** of the classes contain more then **200** images. ","fa4c90b5":"## Explore landmarks","8e6d43b6":"This dataset has a large amount of unique landmarks which we have to predicts. However, the problem does not lie in the total number of labels. The real challenge is the high variance in the label volume.  ","c0ab8821":"2. Check for Duplicate rows","560b70e2":"Clean data results in happy models. The first step in any ML project. Well at least in the case of raw data. In the lion's share of kaggle datasets this part can be overlooked due to the already cleaned and well-organized datasets.","6483de37":"## Tidy Up ","ebe9f584":"![Google Landmark Dataset](https:\/\/1.bp.blogspot.com\/-EQNRBJuBXJo\/XMthch8bdWI\/AAAAAAAAEG0\/oHVw1fxfiXoMfsSn_rNQPR-fyRqM_N4CwCEwYBhgL\/s1600\/image1.png)\n\n\nThe most Important step of any machine learning project is understanding the underlying patterns of our dataset. In this particular case of landmark dataset our data analysis is mainly focused on the class distribution. as stated by the Google's Landmark Dataset [Paper](https:\/\/arxiv.org\/pdf\/2004.01804.pdf) the class distrubution is **\"extremely long-tailed\"**. In order to see the other unique features of the landmark dataset we will take a look at some of the images in the train and test datasets.","d6ac1dc7":"1. Check for missing values","ff57ed5e":"## Visualize Testset Dataset"}}