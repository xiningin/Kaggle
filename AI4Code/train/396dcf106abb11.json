{"cell_type":{"728039e4":"code","f8ee2b94":"code","48680d87":"code","81349588":"code","46e9f7d3":"code","2107389d":"code","c60e4d04":"code","65984c2c":"code","70455277":"code","0950dcbc":"code","f355a8fc":"code","897428e8":"code","b0bd8e08":"code","ba9707ad":"code","dbd4b0f5":"code","17324487":"code","222bb9b9":"code","2df92018":"code","a62dd8c5":"code","a48a8d44":"markdown","ed5e6011":"markdown","0c0e568f":"markdown","a855d581":"markdown","0fb2e822":"markdown","85607686":"markdown","384186f8":"markdown","08c456a2":"markdown","c19e5a7e":"markdown","2d9c54fb":"markdown"},"source":{"728039e4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f8ee2b94":"data = pd.read_csv('..\/input\/youtube-new\/USvideos.csv')\ndata.info()","48680d87":"# data frames from dictionary\ncountry = [\"Spain\",\"France\"]\npopulation = [\"11\",\"12\"]\nlist_label = [\"Country\",\"Population\"]   #column titles\nlist_col = [country,population]         #column variables\nzipped = list(zip(list_label,list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf","81349588":"# Add new columns\ndf[\"Capital\"] = [\"madrid\",\"paris\"]\ndf","46e9f7d3":"# Broadcasting\ndf[\"Income\"] = 0 #Broadcasting entire column\ndf","2107389d":"# Plotting all data \ndata1 = data.loc[:,[\"views\",\"likes\",\"dislikes\"]]\ndata1.plot()\n# it is confusing","c60e4d04":"# subplots\ndata1.plot(subplots = True)\nplt.show()                       # import matplotlib.pyplot as plt","65984c2c":"# scatter plot  \ndata1.plot(kind = \"scatter\",x=\"views\",y = \"likes\")\nplt.show()","70455277":"# hist plot\n# data1.plot(kind = \"hist\", y = \"dislikes\", bins = 50, range = (0,250), normed = True)\n# Output Error : 'Rectangle' object has no property 'normed'","0950dcbc":"# hist plot  \ndata1.plot(kind = \"hist\",y = \"dislikes\",bins = 50,range= (0,250),density = True)","f355a8fc":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"dislikes\",bins = 50,range= (0,250),density = True,ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"dislikes\",bins = 50,range= (0,250),density = True,ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt","897428e8":"data.describe()","b0bd8e08":"time_list = [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1])) # As you can see date is string\n\n# however we want it to be datetime object\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","ba9707ad":"# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# In order to practice lets take head of trending youtube video statistics data and add it a time list\n\ndata2 = data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(date_list)   # list convert datetime object\ndata2[\"date\"] = datetime_object\n\n# lets make date as index\ndata2 = data2.set_index(\"date\")\ndata2 ","dbd4b0f5":"# Now we can select according to our date index\nprint(data2.loc[\"1993-03-16\"])\nprint(data2.loc[\"1992-03-10\":\"1993-03-16\"])","17324487":"# We will use data2 that we create at previous part\ndata2.resample(\"A\").mean()","222bb9b9":"# Lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan because data2 does not include all months","2df92018":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from *first value*\ndata2.resample(\"M\").first().interpolate(\"linear\")","a62dd8c5":"# Or we can interpolate with * mean() *\ndata2.resample(\"M\").mean().interpolate(\"linear\")","a48a8d44":"so, I use density","ed5e6011":"VISUAL EXPLORATORY DATA ANALYSIS<br>\n\n* Plot\n* Subplot\n* Histogram:\n  * bins: number of bins\n  * range(tuble): min and max values of bins\n  * normed(boolean): normalize or not\n  * cumulative(boolean): compute cumulative distribution","0c0e568f":"resample() method","a855d581":"to_datetime() method","0fb2e822":"REV\u0130EW of PANDAS<br>\n\nAs you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\n\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy","85607686":"RESAMPLING PANDAS TIME SERIES<br>\n\n* Resampling: statistical method over different time intervals\n  * Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like \u2018linear\u2019, \u2018time\u2019 or index\u2019\n   * https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.Series.interpolate.html","384186f8":"BUILDING DATA FRAMES FROM SCRATCH<br>\n\n* We can build data frames from csv as we did earlier.\n* Also we can build dataframe from dictionaries\n  * zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column","08c456a2":"INDEXING PANDAS TIME SERIES<br>\n\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format","c19e5a7e":"STATISTICAL EXPLORATORY DATA ANALYSIS<br>\n\nI already explained it at previous parts. However lets look at one more time.<br>\n\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry","2d9c54fb":"normed"}}