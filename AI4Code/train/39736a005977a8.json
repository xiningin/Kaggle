{"cell_type":{"f7dc78f6":"code","c52fd88c":"code","a1425800":"code","28ce4e82":"code","987cfc7f":"code","cd048a6e":"code","1cfeadb4":"code","b5034c2f":"code","b3200a72":"code","083e7a79":"code","8a515d93":"code","9df039dd":"code","d76faabd":"code","4804cec0":"markdown","9ca5449f":"markdown","81a42e00":"markdown","90aad2a3":"markdown","11e055d1":"markdown","b0968720":"markdown","f6404993":"markdown","9745d439":"markdown","0e751915":"markdown","a0f658df":"markdown","c0fca09f":"markdown"},"source":{"f7dc78f6":"import librosa\nimport matplotlib.pyplot as plt\nimport librosa.display\nimport sklearn\nimport numpy as np","c52fd88c":"audio_path = \"\/kaggle\/input\/audio-data\/The Big Bang Theory Season 6 Ep 21 - Best Scenes.wav\"","a1425800":"x , sr = librosa.load(audio_path)","28ce4e82":"#waveform plot\nplt.figure(figsize=(14, 5))\nlibrosa.display.waveplot(x, sr=sr)","987cfc7f":"mfccs = librosa.feature.mfcc(x, sr=sr)\nprint(mfccs.shape)\nmfccs_mean = np.mean(librosa.feature.mfcc(x, sr))\nprint(\"MFCCS mean value:\",mfccs_mean)","cd048a6e":"#Displaying  the MFCCs:\nlibrosa.display.specshow(mfccs, sr=sr, x_axis='time')","1cfeadb4":"# Zooming in\nn0 = 9000\nn1 = 9100\nplt.figure(figsize=(14, 5))\nplt.plot(x[n0:n1])\nplt.xlabel(\"Time\")\nplt.ylabel(\"Magnitude\")\nplt.grid()","b5034c2f":"zero_crossings = librosa.zero_crossings(x[n0:n1], pad=False)\nprint(sum(zero_crossings))","b3200a72":"spectral_centroids = librosa.feature.spectral_centroid(x, sr=sr)[0]\nprint(spectral_centroids)\nprint(\"Mean Spectral Centroid\",np.mean(spectral_centroids))","083e7a79":"# Computing the time variable for visualization\nframes = range(len(spectral_centroids))\nt = librosa.frames_to_time(frames)\n# Normalising the spectral centroid for visualisation\ndef normalize(x, axis=0):\n    return sklearn.preprocessing.minmax_scale(x, axis=axis)\n#Plotting the Spectral Centroid along the waveform\nplt.figure(figsize=(60, 20))\nplt.xlabel(\"Time\")\nplt.ylabel(\"Magnitude\")\nlibrosa.display.waveplot(x, sr=sr, alpha=0.4)\nplt.plot(t, normalize(spectral_centroids), color='r')","8a515d93":"pitches, magnitudes = librosa.piptrack(x,sr)\nprint(pitches)\n#plt.subplot(212)\n#plt.show()\nprint(\"Mean Pitch\",np.mean(pitches))\nplt.plot(pitches)\nplt.xlabel(\"Time\")\nplt.ylabel(\"Frequency in Hz\")\nplt.show()","9df039dd":"rmse = librosa.feature.rms(x, frame_length=2, hop_length=1)[0]\nprint(rmse)\nprint(rmse.shape)\nmean_rmse = np.mean(rmse)\nprint(\"RMSE:\",mean_rmse)","d76faabd":"frames = range(rmse.shape[0])\nt = librosa.frames_to_time(frames)\nplt.figure(figsize=(40, 10))\nplt.xlabel(\"Time\")\nplt.ylabel(\"Magnitude\")\nlibrosa.display.waveplot(x, sr=sr, alpha=0.4)\nplt.plot(t, rmse, color='r',label=\"Rmse\")","4804cec0":"4. Pitch<br>\nThe sensation of a frequency is commonly referred to as the pitch of a sound. A high pitch sound corresponds to a high frequency sound wave and a low pitch sound corresponds to a low frequency sound wave.","9ca5449f":"2. Zero Crossing Rate: <br>\nThe zero crossing rate is the rate of sign-changes along a signal, i.e., the rate at which the signal changes from positive to negative or back.<br><br>\nzoom or print spectrum for 100 array columns only","81a42e00":"Feature Extraction","90aad2a3":"1. MFCC<br>\nThe Mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features (usually about 10\u201320) which concisely describe the overall shape of a spectral envelope.","11e055d1":"3. Spectral Centroids<br>\nIt indicates where the \u201dcentre of mass\u201d for a sound is located and is calculated as the weighted mean of the frequencies present in the sound. If the frequencies in music are same throughout then spectral centroid would be around a centre and if there are high frequencies at the end of sound then the centroid would be towards its end.","b0968720":"5. Root Mean Square of Audio<br>\nIt is the root mean square value calculated of the error of the audio signal from the null signal","f6404993":"Plotting the variation of the rmse over the audio clip","9745d439":"There are fragments of sudden rise in the spectral centroids followed by small stretches of low spectral centroids","0e751915":"Thus, there are 5 zero crossings","a0f658df":"Algorithm for Classification of Audio:<br>\n1. K-Nearest Neighbours algorithm can be used for content based classification of audio tracks after the extraction of the above features from the track. The relation between instances is measured based on the distances of the feature of the instance to the various regions in the classification space which are made by grouping audio tracks with similar features together. Thus, load sounds will be goruped together as they'll have similar values for the above extracted features and soft sounds will be grouped together based on these features.\n2. Other than KNN,CNN in deep learning models can be used to classify audio based on the spectograms of the above extracted features to group similar tracks together.","c0fca09f":"As it can be seen in the above plot, there are about 5 zero crossings in this zoomed in plot.<br><br>\nCalculating Zero Crossings using function:"}}