{"cell_type":{"4ade8344":"code","4855dc4f":"code","6cf25f34":"code","945d0834":"code","9f3b119e":"code","20d46a89":"code","e19fe3c8":"code","308bcf22":"code","a825fa29":"code","e10eb185":"code","c74ee2cd":"code","64b317f7":"code","ec71a8b5":"code","92d9cb4e":"code","6f00ff67":"code","a2eace91":"code","b48d193f":"code","61d15bd3":"code","2609c640":"code","9181bf0a":"code","e4b93d88":"code","a099cb4d":"code","0d578b9d":"code","3e1c95f7":"code","1ba84643":"code","bdc313be":"markdown","f323ce6c":"markdown","4ca9edba":"markdown","9d3e696f":"markdown","46dc933e":"markdown","a040017d":"markdown","cecbdb56":"markdown","bacf6662":"markdown","1b4e43b8":"markdown"},"source":{"4ade8344":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4855dc4f":"data_test = pd.read_csv('..\/input\/titanic\/test.csv',index_col='PassengerId')\ndata_train = pd.read_csv('..\/input\/titanic\/train.csv',index_col='PassengerId')\ndata_train","6cf25f34":"data_train.describe()","945d0834":"data_train.isnull().sum()\n#data_test.isnull().sum()","9f3b119e":"#data_train.Age.fillna(data_train.Age.mean(), inplace=True)\n#data_train.Embarked.fillna(1, inplace=True)","20d46a89":"for i in data_train.columns:    \n    print(i ,': ',len(data_train[i].unique()))\n#len(data_train.Name.unique())","e19fe3c8":"columnsForDrop = ['Name', 'Cabin','Ticket','SibSp','Parch']\ndata_train.drop(columns=columnsForDrop, inplace=True)\n################################\ndata_test.drop(columns=columnsForDrop, inplace=True)\n\ndata_train","308bcf22":"print(data_train.Sex.value_counts())\nprint('----------------------------------------------')\nprint(data_train.Embarked.value_counts())","a825fa29":"data_train.Sex.replace('male', 0, inplace=True)\ndata_train.Sex.replace('female', 1, inplace=True)\ndata_train.Embarked.replace('S', 1, inplace=True)\ndata_train.Embarked.replace('C', 2, inplace=True)\ndata_train.Embarked.replace('Q', 3, inplace=True)\n#######################################################\ndata_test.Sex.replace('male', 0, inplace=True)\ndata_test.Sex.replace('female', 1, inplace=True)\ndata_test.Embarked.replace('S', 1, inplace=True)\ndata_test.Embarked.replace('C', 2, inplace=True)\ndata_test.Embarked.replace('Q', 3, inplace=True)\n\ndata_train\n","e10eb185":"y = data_train.Survived\n############################################\nX = data_train.drop(columns=['Survived'])","c74ee2cd":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n","64b317f7":"from sklearn.impute import SimpleImputer\n# Imputation\nmy_imputer = SimpleImputer()\nimputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\nimputed_X_test = pd.DataFrame(my_imputer.transform(X_test))\n\n#imputed_X_train\n#Imputation removed column names; put them back\nimputed_X_train.columns = X_train.columns\nimputed_X_test.columns = X_test.columns\n#imputed_X_train.astype(int)\n","ec71a8b5":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, f1_score\nfrom sklearn.neighbors import KNeighborsClassifier\n\n","92d9cb4e":"from xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error ,explained_variance_score, mean_squared_error\n\n'''parameters = {'max_depth':  list(range(6, 100, 10)),\n              'max_leaf_nodes': list(range(50, 1001, 10))}\n\nfrom sklearn.model_selection import GridSearchCV\n\ngsearch = GridSearchCV(estimator=DecisionTreeClassifier(),\n                       param_grid = parameters, \n                       scoring='f1',\n                       n_jobs=4,cv=5,verbose=7)\n\ngsearch.fit(imputed_X_train, y_train)'''\n#########################################################################3\nfrom sklearn.ensemble import RandomForestClassifier\n\nparameters = {'max_depth':  list(range(6, 30, 10)),\n              'max_leaf_nodes': list(range(50, 500, 100)),\n              'n_estimators': list(range(50, 1001, 150))}\n\nfrom sklearn.model_selection import GridSearchCV\n\ngsearch = GridSearchCV(estimator=RandomForestClassifier(),\n                       param_grid = parameters, \n                       scoring='f1',\n                       n_jobs=4,cv=5,verbose=7)\n\ngsearch.fit(imputed_X_train, y_train)","6f00ff67":"print(gsearch.best_params_.get('max_leaf_nodes'))\nprint(gsearch.best_params_.get('max_depth'))","a2eace91":"#def getMeanError():\n    #forest_model = KNeighborsClassifier(n_neighbors=n_est)\n   # '''forest_model = DecisionTreeClassifier(max_leaf_nodes=gsearch.best_params_.get('max_leaf_nodes'),\n    #                                      max_depth=gsearch.best_params_.get('max_depth'),\n    #                                      random_state=1)\n    #forest_model.fit(imputed_X_train,y_train)\n    #preds = forest_model.predict(imputed_X_test)\n    #print(classification_report(y_test,preds))\n    #print(accuracy_score(y_test, preds))\n    #return f1_score(y_true=y_test, y_pred=preds)'''\n#########################################################################\ndef getMeanError():\n    forest_model = RandomForestClassifier(\n                         max_depth = gsearch.best_params_.get('max_depth'),\n                           max_leaf_nodes = gsearch.best_params_.get('max_leaf_nodes'),\n        n_estimators = gsearch.best_params_.get('n_estimators'),random_state=1, n_jobs=4,verbose=7)\n    forest_model.fit(imputed_X_train, y_train)\n    predictions = forest_model.predict(imputed_X_test)\n    #mean_Error = mean_absolute_error(y_true=y_test,y_pred = predictions)\n    print(classification_report(y_test,predictions))\n    print(accuracy_score(y_test, predictions))\n    return f1_score(y_true=y_test, y_pred=predictions)\n","b48d193f":"getMeanError()","61d15bd3":"##results = {}\n\n##range_Estimation = getMeanError(2)\n##for i in range(2,20):\n    #getMeanError(i)\n  ##  print('-------------------------------------------------------')\n    ##results[i] = getMeanError(i)","2609c640":"#range_Estimation = getMeanError(2)\n#minEstim = 1\n#for i in range(2,20):\n    #print(getMeanError(i),'*-*',i)\n#    if range_Estimation > getMeanError(i):\n #       minEstim = i\n#print(range_Estimation,'>>>',minEstim)\n#####19 is the best...'''","9181bf0a":"##best_max_leaf_nodes = max(results, key=results.get)\n##best_max_leaf_nodes","e4b93d88":"X.describe()","a099cb4d":"X.Age.fillna(X.Age.mean(), inplace=True)\nX.Embarked.fillna(1, inplace=True)\n#print(gsearch.best_params_.get('max_leaf_nodes'))\n#print(gsearch.best_params_.get('max_depth'))\n\n'''final_model = DecisionTreeClassifier(max_leaf_nodes=gsearch.best_params_.get('max_leaf_nodes'),\n                                     max_depth=gsearch.best_params_.get('max_depth'),\n                                     random_state=1 )\nfinal_model.fit(X, y)'''\n#######################################################\nfinal_model = RandomForestClassifier(\n                         max_depth = gsearch.best_params_.get('max_depth'),\n                           max_leaf_nodes = gsearch.best_params_.get('max_leaf_nodes'),\n        n_estimators = gsearch.best_params_.get('n_estimators'),random_state=1, n_jobs=4)\nfinal_model.fit(X, y)\n#X.isna().sum()","0d578b9d":"data_test.Age.fillna(X.Age.mean(), inplace=True)\ndata_test.Fare.fillna(X.Fare.mean(), inplace=True)\n\ndata_test.isna().sum()","3e1c95f7":"preds = final_model.predict(data_test)\nprint(preds.shape)\nprint(data_test.shape)","1ba84643":"test_out = pd.DataFrame({\n    'PassengerId': data_test.index, \n    'Survived': preds\n})\ntest_out.to_csv('submission.csv', index=False)\nprint('Done')","bdc313be":"# *Drop any row have NaN Value...","f323ce6c":"# - Change DataType...\n\n# I will change the **male** value to **0** and the **female** to **1** in column \"Sex\".\n# And change **S** Value to **1**, **C** value to **2** and **Q** value to **3** in column \"Embarked\"","4ca9edba":"# *Divide data into training data and test data.","9d3e696f":"# *Select y and X","46dc933e":"# Show describe()","a040017d":"# Read DataSet & Show data_train","cecbdb56":"# Improve the type of data within some columns such as sex column and embarked column from text to numbers so that it is easy to deal with in the model training phase","bacf6662":"# The total number of data is 891 rows and the number of values lost within the Cabin column is 687 so I will delete the Cabin column and also delete the Name column because it is not important in the final results and I will delete the Ticket column because its value is different in all rows so it will not matter.\n","1b4e43b8":"# View the sum of empty values in each column."}}