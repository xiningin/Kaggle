{"cell_type":{"aeb62a69":"code","87d4397a":"code","4ffa1fba":"code","f43fdfa8":"code","f1ccc37b":"code","c22ed9c8":"code","c4fa316c":"code","e6524ecc":"code","e3f4d9f6":"code","635fb18f":"code","4e554b50":"code","7dab7cdb":"markdown","68063f3d":"markdown","c60db871":"markdown","2a532159":"markdown"},"source":{"aeb62a69":"from __future__ import print_function, division\nimport numpy as np\nfrom glob import glob\nimport pandas as pd\nimport os\nfrom tqdm import tqdm\noutput_path = os.path.join('..','input')\nimport matplotlib.pyplot as plt\nfrom skimage.util import montage\nfrom skimage.color import label2rgb\n%matplotlib inline","87d4397a":"import h5py\nwith h5py.File(os.path.join(output_path, 'all_patches.hdf5'), 'r') as luna_h5:\n    all_slices = luna_h5['ct_slices'].value\n    all_classes = luna_h5['slice_class'].value\n    print('data', all_slices.shape, 'classes', all_classes.shape)","4ffa1fba":"from skimage.util import montage\nfig, (ax1, ax2) = plt.subplots(1,2,figsize = (12, 6))\nplt_args = dict(cmap = 'bone', vmin = -600, vmax = 300)\nax1.imshow(montage(all_slices[np.random.choice(np.where(all_classes>0.5)[0],size = 64)]), **plt_args)\nax1.set_title('Malignant Tiles')\nax2.imshow(montage(all_slices[np.random.choice(np.where(all_classes<0.5)[0],size = 64)]), **plt_args)\nax2.set_title('Benign Tiles')","f43fdfa8":"from keras_applications.imagenet_utils import _obtain_input_shape\nfrom keras import backend as K\nfrom keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout, GlobalAveragePooling2D, \\\n     BatchNormalization\nfrom keras.models import Model\nfrom keras.engine.topology import get_source_inputs\nfrom keras.utils import get_file\nfrom keras.utils import layer_utils\n\nsq1x1 = \"squeeze1x1\"\nexp1x1 = \"expand1x1\"\nexp3x3 = \"expand3x3\"\nrelu = \"relu_\"\n\n# Modular function for Fire Node\n\ndef fire_module(x, fire_id, squeeze=16, expand=64):\n    s_id = 'fire' + str(fire_id) + '\/'\n\n    if K.image_data_format() == 'channels_first':\n        channel_axis = 1\n    else:\n        channel_axis = 3\n    \n    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n\n    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n\n    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n\n    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n    return x\n\n\n# Original SqueezeNet from paper.\n\ndef SqueezeNet(input_tensor=None, input_shape=None,\n               weights='imagenet',\n               classes=1000,\n              use_bn_on_input = False, # to avoid preprocessing\n               first_stride = 2\n              ):\n    if weights not in {'imagenet', None}:\n        raise ValueError('The `weights` argument should be either '\n                         '`None` (random initialization) or `imagenet` '\n                         '(pre-training on ImageNet).')\n\n    if weights == 'imagenet' and classes != 1000:\n        raise ValueError('If using `weights` as imagenet with `include_top`'\n                         ' as true, `classes` should be 1000')\n\n    if input_tensor is None:\n        raw_img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n    if use_bn_on_input:\n        img_input = BatchNormalization()(raw_img_input)\n    else:\n        img_input = raw_img_input\n\n\n    x = Convolution2D(64, (3, 3), strides=(first_stride, first_stride), padding='valid', name='conv1')(img_input)\n    x = Activation('relu', name='relu_conv1')(x)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n\n    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n\n    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n\n    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n    x = Dropout(0.5, name='drop9')(x)\n\n    x = Convolution2D(classes, (1, 1), padding='valid', name='conv10')(x)\n    x = Activation('relu', name='relu_conv10')(x)\n    x = GlobalAveragePooling2D()(x)\n    out = Activation('softmax', name='loss')(x)\n\n    # Ensure that the model takes into account\n    # any potential predecessors of `input_tensor`.\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = raw_img_input\n\n    model = Model(inputs, out, name='squeezenet')\n\n    # load weights\n    if weights == 'imagenet':\n\n        weights_path = get_file('squeezenet_weights_tf_dim_ordering_tf_kernels.h5',\n                                    WEIGHTS_PATH,\n                                    cache_subdir='models')\n        model.load_weights(weights_path)\n        if K.backend() == 'theano':\n            layer_utils.convert_all_kernels_in_model(model)\n\n        if K.image_data_format() == 'channels_first':\n\n            if K.backend() == 'tensorflow':\n                warnings.warn('You are using the TensorFlow backend, yet you '\n                              'are using the Theano '\n                              'image data format convention '\n                              '(`image_data_format=\"channels_first\"`). '\n                              'For best performance, set '\n                              '`image_data_format=\"channels_last\"` in '\n                              'your Keras config '\n                              'at ~\/.keras\/keras.json.')\n    return model","f1ccc37b":"import keras\nlung_node_cnn = SqueezeNet(input_shape = (64, 64, 1), \n                           weights = None, classes = 2,\n                  use_bn_on_input = True)\n# initiate RMSprop optimizer\nopt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n\n# Let's train the model using RMSprop\nlung_node_cnn.compile(loss='categorical_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])\nloss_history = []\nlung_node_cnn.summary()","c22ed9c8":"from sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nX_vec = (np.expand_dims(all_slices,-1) - np.mean(all_slices))\/np.std(all_slices)\n\ny_vec = to_categorical(all_classes)\nX_train, X_test, y_train, y_test = train_test_split(X_vec, y_vec, \n                                                   train_size = 0.75,\n                                                   random_state = 1, \n                                                   stratify = all_classes)","c4fa316c":"from sklearn.metrics import classification_report\ny_pred_proba = lung_node_cnn.predict(X_test)\ny_pred = np.argmax(y_pred_proba,1)\nprint('')\nprint(classification_report(np.argmax(y_test,1),\n                      y_pred))","e6524ecc":"for i in range(5):\n    loss_history += [lung_node_cnn.fit(X_train, y_train, \n              validation_data=(X_test, y_test),\n                               shuffle = True,\n                               batch_size = 32,\n                               epochs = 1)]","e3f4d9f6":"epich = np.cumsum(np.concatenate(\n    [np.linspace(0.5, 1, len(mh.epoch)) for mh in loss_history]))\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n_ = ax1.plot(epich,\n             np.concatenate([mh.history['loss'] for mh in loss_history]),\n             'b-',\n             epich, np.concatenate(\n        [mh.history['val_loss'] for mh in loss_history]), 'r-')\nax1.legend(['Training', 'Validation'])\nax1.set_title('Loss')\n\n_ = ax2.plot(epich, np.concatenate(\n    [mh.history['acc'] for mh in loss_history]), 'b-',\n                 epich, np.concatenate(\n        [mh.history['val_acc'] for mh in loss_history]),\n                 'r-')\nax2.legend(['Training', 'Validation'])\nax2.set_title('Accuracy')","635fb18f":"from sklearn.metrics import classification_report\ny_pred_proba = lung_node_cnn.predict(X_test)\ny_pred = np.argmax(y_pred_proba,1)\nprint('')\nprint(classification_report(np.argmax(y_test,1),\n                      y_pred))","4e554b50":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, thresholds = roc_curve(np.argmax(y_test, 1), y_pred_proba[:,1])\nfig, ax1 = plt.subplots(1,1)\nax1.plot(fpr, tpr, 'r-.', label = 'CNN (%2.2f)' % auc(fpr, tpr))\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate')\nax1.plot(fpr, fpr, 'b-', label = 'Random Guess')\nax1.legend()","7dab7cdb":"# Starting Point\nHow does a completely untrained model do","68063f3d":"# Partition and Reformat the data\nWe want to partition the data into training and validation datasets and then reform the class as a one-hot so it fits to the model. We also perform a simple normalization of the image data so the range is between -1 and 1 instead of -3000 to 2000","c60db871":"# Results after training\nHere we show the results after training a model","2a532159":"# Creating a Simple CNN\nHere we make a simple CNN based on SqueezeNet (since we have limited computational resources on Kaggle). The model will also be trained from scratch although it is often a good idea to fine-tune pretrained models"}}