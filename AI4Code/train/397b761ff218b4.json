{"cell_type":{"14c863d9":"code","d565b93f":"code","cc900ae9":"code","8b34ad69":"code","fa5232ce":"code","493f697b":"code","c2644681":"code","54f850bd":"code","e6af6404":"code","4beeade2":"code","774ac346":"code","98e3d42e":"code","0688ea16":"code","47d11c12":"code","e7cecb8d":"code","df06ae50":"code","dc4d0b1f":"code","68c7cd47":"code","78f797f6":"code","8cc31f4b":"code","dd436842":"code","8bf77056":"code","1ebfb4d4":"code","fbe8145b":"code","d26a0685":"code","98066877":"code","f32dae78":"code","9310f442":"code","1610a1b0":"code","884b910e":"code","d10e0f6f":"code","5d04660b":"code","9f0f459c":"code","271637bb":"code","71e6db32":"code","4b7c832f":"code","7ae7f0d0":"code","14046f47":"code","c206c87d":"code","cace9199":"code","a6deb664":"code","0d3f3e81":"code","7c0e05e6":"code","b5a07caf":"code","c373ee36":"code","4e1ec3de":"code","cdb33e82":"code","c871bf45":"code","eb22fa15":"code","276cc858":"code","56059264":"code","328c9dbf":"code","c1585133":"code","c13247b3":"code","c8730022":"markdown","3443c539":"markdown","59069503":"markdown","5600efc4":"markdown","1c5bfcf8":"markdown","59902f75":"markdown","d2b917c8":"markdown","94ff961c":"markdown","e0d157c3":"markdown","3fc80bae":"markdown","deb55825":"markdown","4f69c324":"markdown","edca6824":"markdown","b92270dc":"markdown","758892b0":"markdown","622a4b56":"markdown","6a036f84":"markdown","9398eb23":"markdown","8a81e9bd":"markdown","b02833b6":"markdown","5b54e93d":"markdown","8d4e04fe":"markdown","dc27ac3a":"markdown","747d39a2":"markdown","0cee796e":"markdown","76d57738":"markdown","f1ab5034":"markdown","e23bf3a5":"markdown","40038fe7":"markdown","8dd118c6":"markdown","20fcf178":"markdown","de422dc5":"markdown","dddaf0bd":"markdown","96e34685":"markdown","59869e0f":"markdown","5be44604":"markdown","48b0737d":"markdown","46e3cb1f":"markdown","96eade4f":"markdown","a941f465":"markdown","714c9a2b":"markdown","cfd3131d":"markdown","184dd925":"markdown","39bd83f4":"markdown","f9c1bb1e":"markdown","9d3aff62":"markdown","c4a7bddb":"markdown","1200101b":"markdown","d078765b":"markdown","3f002545":"markdown","f71c08c7":"markdown","67c29eeb":"markdown","cfc7274b":"markdown","7dfebfba":"markdown","c632475c":"markdown","5820bd49":"markdown","cc56e413":"markdown","8a614f66":"markdown"},"source":{"14c863d9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d565b93f":"\n#importing dataset\n\ntrain = pd.read_csv('\/kaggle\/input\/bigmart-sales-data\/Train.csv')\ntest = pd.read_csv('\/kaggle\/input\/bigmart-sales-data\/Test.csv')\ntrain.head()\n                 ","cc900ae9":"test.head()","8b34ad69":"print(train.shape)\nprint(test.shape)","fa5232ce":"train.columns","493f697b":"test.columns","c2644681":"train.info()","54f850bd":"print('Number of trainings examples:', len(train),'\\n')\ntrain.describe()","e6af6404":"numerical = train.select_dtypes(include = ['int64', 'Int64','float64']).dtypes.index\nnumerical","4beeade2":"def UVA_numeric(data, var_group, layout = None):\n  '''\n  data {dataframe}: the bulk data\n  var_group {list}: list of variable to analyse\n  layout{tuple}   : layout of visualisation (rows x columns)\n  '''\n\n  if layout == None:\n    layout = (1,len(var_group))\n\n  plt.figure(figsize = (layout[1]*10, layout[0]*10), dpi = 100)\n\n\n  for j,i in enumerate(var_group):\n    min = data[i].min()\n    max = data[i].max()\n    range = data[i].max() - data[i].min()\n    mean = data[i].mean()\n    median = data[i].median()\n    std_dev = data[i].std()\n    skew = data[i].skew()\n    kurtosis = data[i].kurtosis()\n\n    points = mean-std_dev, mean+std_dev\n\n    #plotting of numeric features with all information.\n    plt.subplot(layout[0],layout[1],j+1)\n    sns.kdeplot(data[i], shade=True)\n    sns.lineplot(points, [0,0], color = 'red', label = 'std_dev')\n    sns.scatterplot([min,max], [0,0], color ='red', label = 'min\/max')\n    sns.scatterplot([mean], [0], color = 'blue', label = 'mean')\n    sns.scatterplot([median], [0], color = 'green', label = 'median')\n    plt.xlabel('{}'.format(i), fontsize = 20, fontweight = 'bold')\n    plt.ylabel('Density', fontsize = 16, fontweight = 'bold')\n    plt.title('std_dev = {}; kurtosis = {};\\n skew = {}; range = {};\\n mean = {}; median = {}'.format\n                                                                                              ((round(points[0],2), round(points[1],2)),\n                                                                                               round(kurtosis,2), round(skew,2),\n                                                                                               (round(min,2), round(max,2), round(range,2)),\n                                                                                               round(mean,2),\n                                                                                               round(median,2)))","774ac346":"UVA_numeric(train, numerical, (3,2))","98e3d42e":"cat_features = train.select_dtypes(include = ['object']).dtypes.index\ncat_features","0688ea16":"train['Item_Identifier'].value_counts()","47d11c12":"def UVA_Categorical(data, cat):\n  plt.figure(figsize = (10,6))\n  sns.countplot(cat, data = data)\n  plt.xlabel(cat,fontsize = 14, fontweight = 'bold')\n  plt.ylabel('Count',fontsize = 14, fontweight = 'bold')\n  plt.title('Value counts: \\n{}'.format(train[cat].value_counts(normalize = True)))\n\n  # Rotating xticklabels\n  if len(data[cat].value_counts()) > 7:\n    X = plt.gca().xaxis\n    for item in X.get_ticklabels():\n      item.set_rotation(90)\n  plt.show()","e7cecb8d":"UVA_Categorical(train,'Item_Fat_Content')","df06ae50":"UVA_Categorical(train, 'Item_Type')","dc4d0b1f":"UVA_Categorical(train, 'Outlet_Identifier')","68c7cd47":"UVA_Categorical(train,'Outlet_Size')","78f797f6":"UVA_Categorical(train, 'Outlet_Location_Type')","8cc31f4b":"UVA_Categorical(train, 'Outlet_Type')","dd436842":"train.isnull().sum()","8bf77056":"plt.figure(figsize = (10,6))\nsns.heatmap(train.isnull(), yticklabels=False,cbar = False,cmap ='viridis')","1ebfb4d4":"def missing_percent():\n  miss_item_weight = (train['Item_Weight'].isnull().sum()\/len(train))*100\n  miss_Outlet_Size = (train['Outlet_Size'].isnull().sum()\/len(train))*100\n\n  print('% of missing values in Item_Weight: ' + str(miss_item_weight))\n  print('% of missing values in Outlet_Size: ' +str(miss_Outlet_Size))","fbe8145b":"missing_percent()","d26a0685":"numerical = train.select_dtypes(include = ['int64','float64','Int64'])\nnumerical.dtypes.index","98066877":"numerical.corr(method = 'pearson')","f32dae78":"numerical.corr(method='spearman')","9310f442":"plt.figure(figsize = (16,5))\nplt.subplot(1,2,1)\nsns.heatmap(numerical.corr(method = 'pearson'), cbar = True, annot = True,linewidths = 1)\n\nplt.subplot(1,2,2)\nsns.heatmap(numerical.corr(method = 'spearman'), cbar = True, annot = True,linewidths = 1)","1610a1b0":"sns.pairplot(numerical)","884b910e":"categorical = train.select_dtypes(include = 'object')\ncategorical.dtypes.index","d10e0f6f":"def Bivariate_cont_cat(data, cont, cat, p_value, f_value, sign_level):\n\n  # Checking hypothesis\n  if p_value < sign_level and f_value > 1:\n    sign = True\n  else :\n    sign = False\n\n  #table\n  table = pd.pivot_table(data=data, values=cont, columns=cat, aggfunc = np.mean)\n  \n\n  # Visualization\n  plt.figure(figsize = (20,6),dpi = 120)\n  \n\n  # barplot\n  plt.subplot(1,3,1)\n  sns.barplot(x = cat, y = cont, data = data, hue = cat)\n  plt.title('anova-test P value = {} \\n anova_test F value = {} \\n Significant difference = {} \\n{}'.format(p_value, f_value, sign, table))\n   # Rotating xticklabels\n  if len(data[cat].value_counts()) > 7:\n    X = plt.gca().xaxis\n    for item in X.get_ticklabels():\n      item.set_rotation(90)\n\n  \n\n  # Kdeplot\n  #plt.subplot(1,3,2)\n  #sns.kdeplot(x = cont, hue = cat, data = data,shade = True)\n  #plt.title('Category Distribution', fontsize = 14, fontweight = 'bold')\n\n  # Boxplot for checking Outliers\n  plt.subplot(1,3,3)\n  sns.boxplot(x=cat, y=cont, data=data)\n  plt.title('categorical boxplot',fontsize = 14, fontweight = 'bold')\n  \n   # Rotating xticklabels\n  if len(data[cat].value_counts()) > 7:\n    X = plt.gca().xaxis\n    for item in X.get_ticklabels():\n      item.set_rotation(90)\n\n\n  ","5d04660b":"df_anova = train[['Item_Outlet_Sales','Item_Fat_Content']]\ngrouped_anova = df_anova.groupby(['Item_Fat_Content'])\ngrouped_anova.head()\nfrom scipy import stats\nf_value, p_value = stats.f_oneway(grouped_anova.get_group('Low Fat')['Item_Outlet_Sales'],grouped_anova.get_group('Regular')['Item_Outlet_Sales'],\n                               grouped_anova.get_group('low fat')['Item_Outlet_Sales'], grouped_anova.get_group('LF')['Item_Outlet_Sales'],\n                               grouped_anova.get_group('reg')['Item_Outlet_Sales'])\nprint(f_value, p_value)","9f0f459c":"Bivariate_cont_cat(train,'Item_Outlet_Sales','Item_Fat_Content',p_value,f_value, 0.01)","271637bb":"train['Item_Type'].unique()","71e6db32":"df_anova = train[['Item_Outlet_Sales','Item_Type']]\ngrouped_anova = df_anova.groupby(['Item_Type'])\ngrouped_anova.head()\nfrom scipy import stats\nf_value, p_value = stats.f_oneway(grouped_anova.get_group('Dairy')['Item_Outlet_Sales'],grouped_anova.get_group('Soft Drinks')['Item_Outlet_Sales'],\n                               grouped_anova.get_group('Meat')['Item_Outlet_Sales'], grouped_anova.get_group('Fruits and Vegetables')['Item_Outlet_Sales'],\n                               grouped_anova.get_group('Baking Goods')['Item_Outlet_Sales'],grouped_anova.get_group('Frozen Foods')['Item_Outlet_Sales'],\n                               grouped_anova.get_group('Breakfast')['Item_Outlet_Sales'], grouped_anova.get_group('Health and Hygiene')['Item_Outlet_Sales'],\n                               grouped_anova.get_group('Hard Drinks')['Item_Outlet_Sales'], grouped_anova.get_group('Canned')['Item_Outlet_Sales'],\n                               grouped_anova.get_group('Breads')['Item_Outlet_Sales'],grouped_anova.get_group('Starchy Foods')['Item_Outlet_Sales'],\n                               grouped_anova.get_group('Others')['Item_Outlet_Sales'],grouped_anova.get_group('Seafood')['Item_Outlet_Sales'])\nprint(f_value, p_value)","4b7c832f":"Bivariate_cont_cat(train, 'Item_Outlet_Sales','Item_Type',p_value, f_value, 0.05)","7ae7f0d0":"train['Outlet_Size'].unique()","14046f47":"df_anova = train[['Item_Outlet_Sales','Outlet_Size']]\ngrouped_anova = df_anova.groupby(['Outlet_Size'])\nfrom scipy import stats\nf_value, p_value = stats.f_oneway(grouped_anova.get_group('Medium')['Item_Outlet_Sales'],grouped_anova.get_group('High')['Item_Outlet_Sales'],\n                               grouped_anova.get_group('Small')['Item_Outlet_Sales'])\nprint(f_value,p_value)","c206c87d":"Bivariate_cont_cat(train,'Item_Outlet_Sales','Outlet_Size',p_value, f_value, sign_level = 0.05)","cace9199":"train['Outlet_Location_Type'].unique()","a6deb664":"df_anova = train[['Item_Outlet_Sales','Outlet_Location_Type']]\ngrouped_anova = df_anova.groupby('Outlet_Location_Type')\nf_value, p_value = stats.f_oneway(grouped_anova.get_group('Tier 1')['Item_Outlet_Sales'],grouped_anova.get_group('Tier 2')['Item_Outlet_Sales'],\n                               grouped_anova.get_group('Tier 3')['Item_Outlet_Sales'])\nprint(f_value,p_value)","0d3f3e81":"Bivariate_cont_cat(train,'Item_Outlet_Sales','Outlet_Location_Type', p_value, f_value, sign_level = 0.05)","7c0e05e6":"train['Outlet_Type'].unique()","b5a07caf":"df_anova = train[['Item_Outlet_Sales','Outlet_Type']]\ngrouped_anova = df_anova.groupby('Outlet_Type')\nf_value, p_value = stats.f_oneway(grouped_anova.get_group('Supermarket Type1')['Item_Outlet_Sales'],grouped_anova.get_group('Supermarket Type2')['Item_Outlet_Sales'],\n                               grouped_anova.get_group('Supermarket Type3')['Item_Outlet_Sales'])\nprint(f_value,p_value)","c373ee36":"Bivariate_cont_cat(train,'Item_Outlet_Sales','Outlet_Type', p_value,f_value, sign_level=0.05)","4e1ec3de":"train['Outlet_Identifier'].unique()\n","cdb33e82":"df_anova = train[['Item_Outlet_Sales','Outlet_Identifier']]\ngrouped_anova = df_anova.groupby('Outlet_Identifier')\nf_value, p_value = stats.f_oneway(grouped_anova.get_group('OUT049')['Item_Outlet_Sales'],grouped_anova.get_group('OUT018')['Item_Outlet_Sales'],\n                               grouped_anova.get_group('OUT010')['Item_Outlet_Sales'],grouped_anova.get_group('OUT013')['Item_Outlet_Sales'],\n                               grouped_anova.get_group('OUT027')['Item_Outlet_Sales'],grouped_anova.get_group('OUT045')['Item_Outlet_Sales'],\n                               grouped_anova.get_group('OUT017')['Item_Outlet_Sales'],grouped_anova.get_group('OUT046')['Item_Outlet_Sales'],\n                               grouped_anova.get_group('OUT019')['Item_Outlet_Sales'],grouped_anova.get_group('OUT035')['Item_Outlet_Sales'])\nprint(f_value,p_value)","c871bf45":"Bivariate_cont_cat(train,'Item_Outlet_Sales','Outlet_Identifier',p_value,f_value,sign_level = 0.05)","eb22fa15":"plt.figure(figsize = (10,6))\nsns.boxplot(x='Outlet_Identifier',y='Item_Weight',data = train)\nX=plt.gca().xaxis\n\n# Rotating the Xicklabels\nfor item in X.get_ticklabels():\n  item.set_rotation(45)\nplt.xlabel('Outlet_Identifier', fontsize = 12, fontweight = 'bold')\nplt.ylabel('Item Weight', fontsize = 12, fontweight = 'bold')\nplt.title('Item_Weight vs Outlet_Identifier',fontsize = 15, fontweight = 'bold')\nplt.show()","276cc858":"df = train.copy()","56059264":"df.groupby(['Outlet_Type','Outlet_Establishment_Year']).agg({'Item_Outlet_Sales':np.mean}).plot.bar()\nX=plt.gca().xaxis\n\n# Rotating the Xicklabels\nfor item in X.get_ticklabels():\n  item.set_rotation(90)\n\n\n                       ","328c9dbf":"%matplotlib inline\nplt.figure(figsize =(10,6))\nsns.boxplot(x='Outlet_Establishment_Year', y='Item_Outlet_Sales',data = df)\n\nX=plt.gca().xaxis\n\n# Rotating the Xicklabels\nfor item in X.get_ticklabels():\n  item.set_rotation(45)\nplt.title('Sales vs Outlet_Establishment_Year')\nplt.show()","c1585133":"df.groupby(['Outlet_Type','Outlet_Identifier']).agg({'Item_Outlet_Sales':np.mean}).plot.bar(color = 'yellow')\nX=plt.gca().xaxis\n\n# Rotating the Xicklabels\nfor item in X.get_ticklabels():\n  item.set_rotation(90)\n","c13247b3":"df.groupby(['Outlet_Type','Outlet_Size']).agg({'Item_Outlet_Sales':np.mean}).plot.bar()\nX=plt.gca().xaxis\n\n# Rotating the Xicklabels\nfor item in X.get_ticklabels():\n  item.set_rotation(45)\n\n","c8730022":"**Observation:** Here it clearly visible that all the variables are presented in our train and test dataset that are provide in data dictionary.","3443c539":"### Observation\n* There is a significance difference between Item sales of different item types.\n* Dairy products have the higher Item Outlet sales than others.","59069503":"### Observation:\n* There is no significance difference with the Item Fat Content. But there may be if be treat 'low fat' , 'LF' as 'Low Fat' and 'reg' as 'Regular'\n* The distribution of Item Fat Content is slightly right skew.\n* Outliers shown in the boxplot is due to much difference in the Item sales of different Items.\n","5600efc4":"**Observation** - It is very clear from the above boxplot that the store which was established int year 1985 has highest sales but the stores which was established in year 1998 has minimum sales","1c5bfcf8":"### **Oservations:**\n* More than 14%(ie more than 1200 items) are fruits & vegetables and snacks and foods.\n* Sale of breakfast and seafood type of items are very less.","59902f75":"## **1. Introduction to problem statement**\n\n---\n\nSales Prediction for Big Mart Outlets:<br>\nThe data scientists at BigMart have collected 2013 sales data for 1559 products across 10 stores in different cities. Also, certain attributes of each product and store have been defined. The aim is to build a predictive model and predict the sales of each product at a particular outlet.\n\nUsing this model, BigMart will try to understand the properties of products and outlets which play a key role in increasing sales.\n\nPlease note that the data may have missing values as some stores might not report all the data due to technical glitches. Hence, it will be required to treat them accordingly. \n","d2b917c8":"### **Observations:**\n* There are total 10 stores.\n* All the stores are selling almost same number of items except the OUT010 and OUT019 stores\n\n###**Idea for Bivariate analysis**\n* Check whether the store Id OUT010 and OUT019 are recently opened store and if not then why they have sale the less number of items.","94ff961c":"# **THANK YOU!**","e0d157c3":"### **Observation:**\n* Item_MRP is somewhat correlated with Item_Outlet_Sales. So Item_MRP can be important feature for predicting Item_Outlet_Sales at particular store.\n* Increase in the item_visibility can decrease the item outlet sales because it is having negative correlation.\n* Item weight and Item_Establishment_Year does not have any realationship with Item_Outlet_Sales.","3fc80bae":"* **Finding some basic information about the features of the data.**","deb55825":"**Observation**- From the above figure we can conclude that the Grocery stores has lesser mean of sales.","4f69c324":"### **Numerical Features:**\n* Item_Weight\n* Item_Visibility\n* Item_MRP\n* Item_Outlet_Sales(Target Variable)\n\n### **Categorical Features**\n* Item_Identifier\n* Item_Fat_Content(Ordinal Feature)\n* Item_Type\n* Outlet_Itemtifier\n* Outlet_Establishment_Year\n* Outlet_Size(Ordinal Feature)\n* Outlet__Location_Type(Ordinal Feature)\n* Ootlet_Type(Ordinal Feature)\n\n**Observations:**\n* There are 4 float type variables, 1 integer type and 7 object type.\n* We are considering Item_Establishment_Year as a categorical feature because it contains some fixed value but not converting its data type now will consider later.\n* Item_Fat_Content, Outlet_Size, Outelet_Location_Type and Outlet_Type are ordinal features because these values can be arranged in some order.\n\n\n","edca6824":"## **6.4 Summary of Uniariate Analysis**\n\n### **Important Observations:**\n* Numerical<br>\n    * The weight of the items lies in the range of 4 - 22 while the average weight of the items is 12.\n    * There are some items that are not visible at all and the maximum visibility of the item is 33%.\n    * The price of the items range in between Rs 31 - 265. The most expensive item in the stores is of Rs 266.89.\n    * Most of the stores are established in year from 1985-1990 and 1995 to 2000.\n    * From year 1990-1995 was ver bad time for people who wants to open the new store. No stores were established in between this period.\n    * Most of the stores has a maximum sales in between 450 - 3900. Only few of the stores having sales more than 6000. \n  \n* Categorical<br>\n     *  Around 64% of the total items contains low fat while remaining contains regular fat.\n     * More than 14%(ie more than 1200 items) are fruits & vegetables and snacks and foods.\n     * Sale of breakfast and seafood type of items are very less.\n     * All the stores are selling almost same number of items except the OUT010 and OUT019 stores.\n     * 45% of the total number of items are sell from medium size store while only 15% items are sell from store which are very big.\n     * 39% of the items sells from the stores laocated in Tier 3 cities, while 32% and 28% items are sells from the stores located in Tier 2 and Tier 1 cities.\n     * 65% of the items are sell from Supermarket Type 1 whih is almost twice the other types of stores. i.e most of the customers prefer to buy the items from the Supermarket Type 1 stores.\n\n* Missing Values\n     * Since the percentage of missing values is very high so we can't drop these values otherwise we can miss some important information. Only way is to handle the missing values using some technique.\n\n### **Things to investigate further in Bivariate Analysis.**\n* Are the items with less visibility having more sales.\n* Check whether the store Id OUT010 and OUT019 are recently opened store and if not then why they have sale the less number of items.\n* Are the items contains low fat have more sales than the items contains regular fat.\n* Are the stores with medium size have high sale than others.\n* Are the stores located in Tier 3 cities have more sale than other.\n* Are the Supermarket Type 1 type of stores have more sales than other type of stores.\n* Do the missing values of Item weight have some relation with sales of the items or any other feature.\n* Do the missing values of Outlet size have some relation with any other feature.\n","b92270dc":"# **Objective : Exploratory Data Analysis and Hypothesis Testing**\n","758892b0":"###**Observation:**\n* There is a significance difference on the Item Outlet Sales of different stores based on store Id i.e Outlet Identifier.\n* Sales of OUT049 comes from the items whose average sales lies between 200-1000.\n","622a4b56":"## **3. Introduction to dataset.**","6a036f84":"The data scientists at BigMart have collected 2013 sales data for 1559 products across 10 stores in different cities. Also, certain attributes of each product and store have been defined. ","9398eb23":"### **Observation:**\n* The weight of the items lies in the range of 4 - 22 while the average weight of the items is 12.\n* There are some items that are not visible at all and the maximum visibility of the item is 33%.\n* The price of the items range in between Rs 31 - 265. The most expensive item in the stores is of Rs 266.89.\n* Most of the stores are established in year from 1985-1990 and 1995 to 2000.\n* From year 1990-1995 was ver bad time for people who wants to open the new store. No stores were established in between this period.\n* Most of the stores has a maximum sales in between 450 - 3900. Only few of the stores having sales more than 6000.\n\n### **New Hypothesis**\n* Are the items with less visibility having more sales.\n","8a81e9bd":"### **Observation**\n* OUT027 and  OUT019 does not show the plot, so it is confirm that the missing information of Item Weught comes from the store ID OUT027 and OUT019.\n\n### **Inference**\n* Since Item weight of OUT027 and OUT019 have missing values, so let's check for the Outlet size.","b02833b6":"* ## **Are the items contain low fat have more sales than the items contain regular fat.**","5b54e93d":"* **Checking whether all the variables provided in data dictionary are presented in our data**\n","8d4e04fe":"### **Observation:**\n* There is a significance difference between the Item Outlet Sales of stores of different Outlet Location Type.\n* Tier 2 cities have most sales while Tier 1 cities least sales. \n* The average sale of Tier 2 cities is 2324 while that of Tier 2279.","dc27ac3a":"## **Overview:**\n1. Introduction to problem statement\n\n2. Hypothesis generation with respect to problem statement\n\n3. Introduction to dataset\n\n4. Importing dataset and required libraries.\n\n5. Variable Identification and Typecasting\n\n6. Univariate Analysis:\n\n    6.1 Numerical Variables\n\n    6.2 Categorical Variables\n\n    6.3 Missing Values\n\n    6.4 Summary of Univariate Analysis\n    \n7. Bivariate Analysis and Hypothesis Testing\n\n    7.1 Bivariate Analysis: Numerical-Numerical\n\n    7.2 Bivariate Analysis: Numerical-Categorical\n\n    7.3 Bivariate Analysis : Missing Values\n    \n    7.4 Bivariate Analysis: Summary","747d39a2":"* Heatmap","0cee796e":"## **6 Univariate Analysis**","76d57738":"## **7.1 Bivariate Analysis: Numerical-Numerical**\nIn this section we are going to explore and analyze the data with two numerical features taking at a time.\n\n### ** Hypothesis falling under this section.**\n* Are the items with less visibility having more sales.\n* Item weight might effect a sales of the product.\n* Are the items with more MRP having more Outlet_Sales.\n\n* Whenever we want to analyze two numerical features or more than two numerical features first we perform correlation test.","f1ab5034":"* ## **Are the stores with medium size have high sale than others.**","e23bf3a5":"* ##  **Are the stores located in Tier 3 cities have more sales than other.**","40038fe7":"## **Anova test**\nAnalysis of variance (ANOVA) is a statistical technique that is used to check if the means of two or more groups are significantly different from each other. ANOVA checks the impact of one or more factors by comparing the means of different samples.\n\n* The statistic which measures if the means of different samples are significantly different or not is called the F-Ratio. Lower the F-Ratio, more similar are the sample means. In that case, we cannot reject the null hypothesis.\n\n<center>F = Between group variability \/ Within group variability<\/center>","8dd118c6":"### **Observations:**\n* Total count of Item_Weight is 7060 which is less than the length of the training dataset, therefore it may contains some missing values.\n* The average weight of all items is 12kg and the maximum weight of the item is 21 kg. So it is clear that the stores are not selling heavy weight items.\n* The maximum price of the items is 266, so we can say that the stores does not selling costly items like TV, mobile phones, laptops etc.\n* Most recent store was established in 2009 and the oldest store was established in 1985.\n* Average sales of items is Rs 2181 and the maximum sale is Rs 13,086.","20fcf178":"* ### **Are the Supermarket Type 1 type of stores have more sales than other type of stores.**","de422dc5":"### **Observation:**\n* Yes there is a significance difference between Item Outlet Sales of stores with different Outlet Size.\n* Medium size stores have more Item Outlet sales than others, while the small size stores have the least Item Outlet sales.\n* Mean Item Outlet sales of the 'Medium' Outlet size is above 2500 while that of 'High' is below 2500 and 'Small' is of below 2000.","dddaf0bd":"## 4 **Importing dataset and required libraries**","96e34685":"### **Observation:**\n* There is a significance difference between the Item Outlet Sales of stores of different Outlet Type.\n* No the supermarket Type 1 does not have the more sales than others\n* Supermarket type 3 have more sales than others and the average sales of the Supermarket Type 3 is 3694.\n* Grocery store has the least Item Outlet sales.","59869e0f":"### **Observations**\n* 65% of the items are sell from Supermarket Type 1 whih is almost twice the other types of stores. i.e most of the customers prefer to buy the items from the Supermarket Type 1 stores.\n\n### **New Hypothesis**\n* Are the Supermarket Type 1 type of stores have more sales than other type of stores.","5be44604":"## **2. Hypothesis generation with respect to problem statement.**\n\n1. Item weight might effect a sales of the product.\n2. Sales of the product may be depends on the items fat content.\n3. More Item_Visibility of a particular product may be costlier than other products.\n4. Item type could have an effect on the sales.\n5. Are the items with more MRP have more item outlet sales.\n6. Are the stores which have established earlier have more sales.\n7. Size of the stores could have an effect on the item sales at a particular store.\n8. Location of the stores might depends on the Item outlet sales.\n9. Are the supermarkets have more sales than others.\n","48b0737d":"* **Before moving further let's make a list of numerical features.**","46e3cb1f":"## **7.2 Bivariate Analysis: Numerical and Categorical**\n* In this we are going to analyze our data with one categorical feature and a target variable(numerical) and also perform some hypothesis testing falling in this section.\n\n### **Hypothesis falling under this section.**\n* Are the items contain low fat have more sales than the items contain regular fat.\n* Are the stores with medium size have high Item Outlet sales than others.\n* Check whether the store Id OUT010 and OUT019 are recently opened store and if not then why they have sale the less number of items.\n* Are the stores located in Tier 3 cities have more sales than other.\n* Are the Supermarket Type 1 type of stores have more sales than other type of stores.","96eade4f":"### **Observations:**\n* 39% of the items sells from the stores laocated in Tier 3 cities, while 32% and 28% items are sells from the stores located in Tier 2 and Tier 1 cities.\n\n### **New Hypothesis**\n* Are the stores located in Tier 3 cities have more sale than other.","a941f465":"## **7.3 Missing Values**\nDuring Univariate analysis we find that ItemWeight and Outlet Size coontains some missing values. So in this section we are going to find the relationship and information between the missing values of different features with other features","714c9a2b":"### **Observation:**\n* Around 64% of the total items contains low fat while remaining contains regular fat.\n\n### **Inference:**\n* Low Fat , low fat and lf are all seems to be same as Low Fat there later on we have to rename low fat and LF to Low Fat during preprocessing.\n* Regular and reg also seems to same fat content, this also required to rename to Regular during preprocessing.\n\n\n\n","cfd3131d":"## **6.2 Univariate: Categorical Features**\nIn this section we are going to explore analyze the categorical features, their classes and finding important information from the dataset.","184dd925":"## **6.3 Missing Values**\nIn this section we are going to check whether our data contains missing values or not.","39bd83f4":"### **Observations:**\n* This shows that the train and test data is imported successfully.\n* The train data consists of 8,523 training examples with 12 features.\n* The test data consists of 5,681 training examples with 11 features\n","f9c1bb1e":"### **Observations:**\n* 45% of the total number of items are sell from medium size store while only 15% items are sell from store which are very big.\n\n### **New Hypothesis**\n* Are the stores with medium size have high sale than others.","9d3aff62":"## **What is the Item Outlet Sales based on OutletType and Outlet Size?**","c4a7bddb":"### **Observations:**\n* Since the percentage of missing values is very high so we can't drop these values otherwise we can miss some important information. Only way is to handle the missing values using some technique.\n\n### **Things to invetigate:**\n* Do the missing values of Item weight have some relation with sales of the items or any other feature.\n* Do the missing values of Outlet size have some relation with any other feature.\n","1200101b":"### **6.1 Univariate Analysis: Numerical Features**\n\nIn this section we are going to explore and analyze the numerical features. So let's get start with the statistical information of the data.","d078765b":"* ## Item Sales Vs Item Type","3f002545":"## **7.4 Bivariate Analysis: Summary**\n* ### **Numerical- Numerical**\n    * Item_MRP is somewhat correlated with Item_Outlet_Sales. So Item_MRP can be important feature for predicting Item_Outlet_Sales at particular store.\n    * Increase in the item_visibility can decrease the item outlet sales because it is having negative correlation.\n    * Item weight and Item_Establishment_Year does not have any realationship with Item_Outlet_Sales.\n\n* ### **Numerical-Categorical**\n    * There is no significance difference in the Item Outlet sales based on Item Weight so Item weight migh not be the much important for predicting sales. But there may be if be treat 'low fat' , 'LF' as 'Low Fat' and 'reg' as 'Regular'\n    * The distribution of Item Fat Content is slightly right skew.\n    * There is a significance difference in the Item Outlet sales of different item types. So this can be important for predicting Item Outlet sales.\n    * Dairy products have the higher Item Outlet sales than others.\n    * Yes there is a significance difference between Item Outlet Sales of stores with different Outlet Size.\n    * Medium size stores have more Item Outlet sales than others, while the small size stores have the least Item Outlet sales.\n    * Mean Item Outlet sales of the 'Medium' Outlet size is above 2500 while that of 'High' is below 2500 and 'Small' is of below 2000.\n    * There is a significance difference between the Item Outlet Sales of stores of different Outlet Location Type.\n    * Tier 2 cities have most sales while Tier 1 cities least sales. \n    * The average sale of Tier 2 cities is 2324 while that of Tier 2279.\n    * * There is a significance difference between the Item Outlet Sales of stores of different Outlet Type.\n    * No the supermarket Type 1 does not have the more sales than others\n    * Supermarket type 3 have more sales than others and the average sales of the Supermarket Type 3 is 3694.\n    * Grocery stores has the least Item Outlet sales.\n    * There is a significance difference on the Item Outlet Sales of different stores based on store Id i.e Outlet Identifier.\n    * Sales of OUT049 comes from the items whose average sales lies between 200-1000.\n\n* ### **Missing values**\n   * OUT027 and  OUT019 does not show the plot, so it is confirm that the missing information of Item Weught comes from the store ID OUT027 and OUT019.\n\nNote - In this notebook, I haven't perform Categorical- Categroical Analysis.","f71c08c7":"### Correlation matrix using Pearson and Spearman correlation.","67c29eeb":"## **5. Variable Identification and type casting.**\nIn this section, our task is to identify all the variables present in the dataset that are provided in the data dictionary and also identify the data types of the variables and if needed convert them in specific type by thinking manually.<br>\n\nSo let's dive into this.....","cfc7274b":"| Variable             | Definition                                                                             \t|\n|----------------------\t|----------------------------------------------------------------------------------------\t|\n| Item_Identifier         \t| Unique Product ID                                                                  \t|\n| Item_Weight           \t| Weight of product                                                               \t|\n| Item_Fat_Content       |Whether the product is low fat or not                                                       \t|\n| Item_visibility       \t| The % of total display area of all products in a store allocated to the particular product                                                                        \t|\n| Item_Type              \t| The category to which the product belongs.                                                                    \t|\n| Item_MRP  \t| Maximum retail price(list price) of the product.                                                   \t|\n| Outlet_Identifier        \t| Unique store ID. \t|\n| Outlet_Establishment_Year  | The year in which store was established.                                                                  |\n| Outlet_Size \t| The size of the store in terms of groud area covered.                                                  \t|\n| Outlet_Location_Type    \t|The type of city in which the store is located.                                                             \t|\n| Outlet_Type     \t| Whether the outlet is just a grocery store or some sort of supermarket                    \t|\n| Item_Outlet_Sales        \t |Sales of the product in the particulat store. This is the outcome variable to be predicted.  |                               \t","7dfebfba":"* ## **Are the different stores affect the Item Outlet Sales.**","c632475c":"\n\n\nData\nWe have train (8523) and test (5681) data set, train data set has both input and output variable(s). You need to predict the sales for test data set.\n","5820bd49":"* **Let's calculate the percentage of missing values**","cc56e413":"### **Observation:**\n* Yes our dataset contain missing values.\n* Item_weight and Outlet_Size features contain missing values","8a614f66":"## **7 Bivariate Analysis**"}}