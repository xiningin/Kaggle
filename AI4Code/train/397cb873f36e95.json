{"cell_type":{"ea39fa97":"code","3613f429":"code","b75c5943":"code","359c664b":"code","43bf5d77":"code","6673f256":"code","fac91f2a":"code","f41421e0":"code","737694ec":"code","b92cf54a":"code","c37d4dda":"code","a5bef06d":"code","f189a59a":"code","f3e1751e":"code","97b1c677":"code","4dfe66f0":"code","b597641c":"code","93178e24":"code","f4437bb7":"code","d2b17f35":"code","0e6460d5":"code","cdd2ca4b":"code","a4356319":"code","bca37001":"code","aa84e612":"code","8adfe8a6":"code","98ae1cb9":"code","992f78bd":"code","a11c1a0b":"code","90756ed8":"code","8183372d":"code","f9ab6749":"code","528c94ee":"code","faafc93f":"code","280f2aa5":"code","ec5301d2":"code","d294d1c2":"code","986a7ee6":"code","b0b295a0":"code","5f2530fc":"code","15d02cce":"code","d71e3fdf":"code","a6e9d123":"code","455438aa":"code","55b3a539":"code","d884bc4e":"code","c60e5e1c":"code","23bc833b":"code","4c32c64c":"code","134441d2":"code","52e94731":"code","ba43674b":"code","2ed5c05e":"code","962d4060":"code","13e4fa2b":"code","4972c519":"code","ab2a8a6d":"code","8279f73c":"code","8cb7e8ba":"code","297e0be7":"code","b23fc5a9":"code","dca75b47":"code","8dcd75aa":"code","bea64afc":"code","bcb09218":"code","72bd0216":"code","a2c87680":"code","114bb996":"markdown","1712e832":"markdown","7f008090":"markdown","6ba18a0f":"markdown","2dd8cb85":"markdown","0e90afc1":"markdown","ba12aa66":"markdown","b85fcada":"markdown","7b8ea334":"markdown","e3ab5493":"markdown","c5e22860":"markdown","9d2a7aed":"markdown","3073feac":"markdown","0d421de4":"markdown"},"source":{"ea39fa97":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","3613f429":"data=pd.read_csv('..\/input\/ml-lab-exam\/traindata_SJC.csv')","b75c5943":"data.info()","359c664b":"data.head()","43bf5d77":"#our initial data was miss aligned, remaned some cells and droped the unwanted rows\ndf=data.rename(columns={\"Unnamed: 0\":\"ClaimNumber\",\"Unnamed: 1\":\"DateTimeOfAccident\",\"Unnamed: 3\":\"Age\",\"Unnamed: 4\":\"Gender\",\"Unnamed: 5\":\"MaritalStatus\",\"Unnamed: 6\":\"DependentChildren\",\"Unnamed: 8\":\"WeeklyWages\",\"Unnamed: 9\":\"PartTimeFullTime\",\"Unnamed: 10\":\"HoursWorkedPerWeek\",\"Unnamed: 12\":\"ClaimDescription\",\"Unnamed: 13\":\"InitialIncurredCalimsCost\",\"Unnamed: 14\":'UltimateIncurredClaimCost'},inplace=False)\ndf=df.drop([0,1])","6673f256":"df.info()","fac91f2a":"df['InitialIncurredCalimsCost'] = pd.to_numeric(df['InitialIncurredCalimsCost'],errors = 'coerce')","f41421e0":"df['UltimateIncurredClaimCost'] = pd.to_numeric(df['UltimateIncurredClaimCost'],errors = 'coerce')","737694ec":"df['DependentChildren'] = pd.to_numeric(df['DependentChildren'],errors = 'coerce')","b92cf54a":"df['Age'] = pd.to_numeric(df['Age'],errors = 'coerce')","c37d4dda":"df['HoursWorkedPerWeek'] = pd.to_numeric(df['HoursWorkedPerWeek'],errors = 'coerce')","a5bef06d":"df['WeeklyWages'] = pd.to_numeric(df['WeeklyWages'],errors = 'coerce')","f189a59a":"import sklearn.preprocessing as pre\nimport sklearn.model_selection as ms","f3e1751e":"le=pre.LabelEncoder()","97b1c677":"list_df=['Age','WeeklyWages','Gender','MaritalStatus','PartTimeFullTime','HoursWorkedPerWeek',\n        'ClaimDescription']","4dfe66f0":"for x in list_df:\n    df[x]=le.fit_transform(df[x].astype(str))","b597641c":"#UltimateIncurredClaimCost is having high number of outliers, hence treated it using only values less than .80\ndf=df[df.UltimateIncurredClaimCost<np.quantile(df['UltimateIncurredClaimCost'],0.80)] ","93178e24":"df.info()","f4437bb7":"#finding and replacing missing values with mean value of weekly wages\ndf['WeeklyWages'].fillna(df['WeeklyWages'].mean(),inplace=True)\n","d2b17f35":"#finding and replacing missing values with s \ndf['MaritalStatus']=df['MaritalStatus'].fillna(\"s\")","0e6460d5":"##finding and replacing missing values with median value of hours wroked \ndf['HoursWorkedPerWeek'].fillna(df['HoursWorkedPerWeek'].median(),inplace=True)","cdd2ca4b":"df.isnull().sum() # removed all NaN values","a4356319":"print(df.skew()) ##finding the skew and observed these results","bca37001":"# The log1p function applies log(1+x) to all elements of the column\ndf[\"LogUltimateIncurredClaimCost\"] = np.log1p(df[\"UltimateIncurredClaimCost\"])\ndf[\"LogInitialIncurredCalimsCost\"] = np.log1p(df[\"InitialIncurredCalimsCost\"])\n\n# After we converting it into log functions we try to plot distribution[claim costs (log)]\n# plotting a Graph btw ultimate and initial claim cost \nplt.subplots(figsize=(10, 6))\nsns.distplot(df.LogUltimateIncurredClaimCost, kde=False, label='Ultimate',bins=100,color='r')\nsns.distplot(df.LogInitialIncurredCalimsCost, kde=False, label='Initial', bins=100,color='g')\nplt.xlabel('claim costs (log)')\nplt.legend()\nplt.show()","aa84e612":"corrmat = df.corr() #finding the correlation \n\n# Draw the heatmap \nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, annot=True, square=True, cmap='plasma')\nplt.show()","8adfe8a6":"ax = plt.subplots(figsize=(14, 5))\nsns.boxplot(x='Age', y='LogUltimateIncurredClaimCost', data=df)\nplt.show()","98ae1cb9":"ax = plt.subplots(figsize=(14, 5))\nsns.boxplot(x='DependentChildren', y='LogUltimateIncurredClaimCost', data=df)\nplt.show()","992f78bd":"ax = plt.subplots(figsize=(14, 5))\nsns.boxplot(x='DaysWorkedPerWeek', y='LogUltimateIncurredClaimCost', data=df)\nplt.show()","a11c1a0b":"df.columns","90756ed8":"sns.boxplot(data=df,x='WeeklyWages')","8183372d":"sns.boxplot(data=df,x='HoursWorkedPerWeek')","f9ab6749":"sns.boxplot(data=df,x='PartTimeFullTime')","528c94ee":"sns.boxplot(data=df,x='DaysWorkedPerWeek')","faafc93f":"sns.boxplot(data=df,x='UltimateIncurredClaimCost')","280f2aa5":"sns.catplot(data=df,x='LogInitialIncurredCalimsCost',col='PartTimeFullTime',kind='violin')","ec5301d2":"sns.catplot(data=df,x='DaysWorkedPerWeek',col='MaritalStatus',kind='violin')","d294d1c2":"sns.pairplot(df) #pair plot to better visualization of features \n","986a7ee6":"# Generate a list of numerical variables, definig a function to accept all numeric variable and plot it.\nnum_list = [c for c in df.columns if((df[c].dtype != np.object) and not \"Cost\" in c)] \n# plot histograms\nfor name in num_list:\n    f, ax = plt.subplots(figsize=(10, 5))\n    nbins = min(df[name].value_counts().count(),70)\n    plt.hist(data=df, x=name, bins=nbins)\n    plt.xlabel(name)\n    plt.show()\n","b0b295a0":"from sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nimport time","5f2530fc":"df.columns","15d02cce":"from sklearn.feature_selection import RFE","d71e3fdf":"feature_cols=['Age', 'Gender', 'MaritalStatus','DependentChildren','WeeklyWages', 'PartTimeFullTime','InitialIncurredCalimsCost']\nX=df[feature_cols]\ny=df['UltimateIncurredClaimCost']\nX.head()","a6e9d123":"print(X.shape)##printing the shape of X and y\nprint(y.shape)","455438aa":"from sklearn.model_selection import train_test_split ##splitting the data to test and train\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state =30)\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","55b3a539":"# standard scaling\nfrom sklearn.preprocessing import StandardScaler\n# creating a standard scaler\nsc = StandardScaler()\n# feeding independents sets into the standard scaler\nx_train = sc.fit_transform(x_train)\nx_test = sc.fit_transform(x_test)","d884bc4e":"from sklearn.linear_model import LinearRegression\nlr=LinearRegression()","c60e5e1c":"lr.fit(x_train,y_train)\ny_pred=lr.predict(x_test)\nprint(lr.score(x_train,y_train))\nprint(lr.score(x_test, y_test))\nprint('RMSE :',np.sqrt(mean_squared_error(y_test, y_pred)))","23bc833b":"from lightgbm import LGBMRegressor\n\nlgbm = LGBMRegressor(\n               objective = 'regression', \n               num_leaves = 4,\n               learning_rate = 0.01, \n               n_estimators = 10000,\n               max_bin = 200, \n               bagging_fraction = 0.75,\n               bagging_freq = 5, \n               bagging_seed = 7,\n               feature_fraction = 0.2,\n               feature_fraction_seed = 7,\n               verbose = 1,\n            )\n\nlgbm_model = lgbm.fit(x_train, y_train)\nlg_vpreds = lgbm_model.predict(x_test)\nprint((f\"LGBM RMSE: {np.sqrt(mean_squared_error(y_test, lg_vpreds))}\"))","4c32c64c":"xgb = XGBRegressor(\n                    learning_rate = 0.01, \n                    n_estimators = 10000,\n                    max_depth = 3, \n                    min_child_weight = 0,\n                    gamma = 0, \n                    subsample = 0.7,\n                    colsample_bytree = 0.7,\n                    objective = 'reg:squarederror', \n                    nthread = 1,\n                    scale_pos_weight = 1, \n                    seed = 27,\n                    reg_alpha = 0.00006\n                    )\nxgb_model = xgb.fit(x_train, y_train)\nxg_vpreds = xgb_model.predict(x_test)\nprint((f\"XGBOOST RMSE: {np.sqrt(mean_squared_error(y_test, xg_vpreds))}\"))\n","134441d2":"predictions = 0.5*(lr.predict(x_test)+xgb_model.predict(x_test))\ndf_test_pred = pd.DataFrame({'ClaimNumber':y_test,'UltimateIncurredClaimCost':predictions})\ndf_test_pred.to_csv('subm-v3-blend-LX.csv',index=False)\ndf_test_pred.head()","52e94731":"np.sqrt(mean_squared_error(y_test,predictions))","ba43674b":"df_test=pd.read_csv('..\/input\/ml-lab-exam\/testdata_SJC.csv')","2ed5c05e":"df_test.head()","962d4060":"df_test.shape","13e4fa2b":"import sklearn.preprocessing as pre\nimport sklearn.model_selection as ms","4972c519":"le=pre.LabelEncoder()","ab2a8a6d":"list_df=['WeeklyWages','Gender','MaritalStatus','PartTimeFullTime','HoursWorkedPerWeek']","8279f73c":"for x in list_df:\n    df_test[x]=le.fit_transform(df_test[x].astype(str))","8cb7e8ba":"#finding and replacing missing values with mean value of weekly wages\ndf_test['WeeklyWages'].fillna(df_test['WeeklyWages'].mean(),inplace=True)\n","297e0be7":"#finding and replacing missing values with s \ndf_test['MaritalStatus']=df_test['MaritalStatus'].fillna(\"s\")","b23fc5a9":"##finding and replacing missing values with median value of hours wroked \ndf_test['HoursWorkedPerWeek'].fillna(df_test['HoursWorkedPerWeek'].median(),inplace=True)","dca75b47":"df_test.isnull().sum()","8dcd75aa":"df_test[\"LogInitialIncurredCalimsCost\"] = np.log1p(df_test[\"InitialIncurredCalimsCost\"])","bea64afc":"feature_cols=['Age', 'Gender', 'MaritalStatus','DependentChildren','WeeklyWages', 'PartTimeFullTime','InitialIncurredCalimsCost']\nX1=df_test[feature_cols]\n\nX1.head()","bcb09218":"lr.predict(X1)","72bd0216":" xgb_model.predict(X1)","a2c87680":"sub=pd.read_csv('..\/input\/ml-lab-exam\/sample_submission_csv.csv')\nsub['UltimateIncurredClaimCost'] = 0.5*(lr.predict(X1)+xgb_model.predict(X1))\nsub.to_csv('Stacked.csv', index = False)\nsub.head(5)\nprint(np.mean(sub['UltimateIncurredClaimCost']))","114bb996":"# Data Loading","1712e832":"### Label encoding and outlier treatment","7f008090":"### Stacking togther linear regression and XGBRegressor","6ba18a0f":"#### From building 3 different models found that simple linear regression tends to produce less RMSE value than other 2 models","2dd8cb85":"### It is clear from the above plots the amount of outliers are high ","0e90afc1":"#### Ultimate and Initial claim cost are very right skewed hence we apply basic log transform (log(x+1))","ba12aa66":"### LGBMRegressor","b85fcada":"### Converting object values to numeric","7b8ea334":"### Importing the test data and preprocessing it for testing","e3ab5493":"# EDA","c5e22860":"### Linear Regression","9d2a7aed":"# Model creation","3073feac":"### XGBRegressor","0d421de4":"# Pre processing "}}