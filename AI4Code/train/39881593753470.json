{"cell_type":{"cca414af":"code","adf073d8":"code","a053278c":"code","1549395f":"code","0cb55de5":"code","f6c49b10":"code","854319aa":"code","2ff343bc":"code","a584d08e":"code","25fd122d":"code","671b6c12":"code","f4654610":"code","5a23e8ea":"code","5e426d33":"code","44d29798":"markdown","d222fc26":"markdown","98f08cd8":"markdown","328eebe4":"markdown","0a1a771b":"markdown","7516643e":"markdown","3b78f913":"markdown","0f920ea2":"markdown","33d55b0a":"markdown"},"source":{"cca414af":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os","adf073d8":"train = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/train.csv')\ntrain.head()","a053278c":"import glob\n\norder_book_training = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/*')","1549395f":"def calc_wap(df):\n    temp = np.log(df).diff()\n    return np.sqrt(np.sum(temp**2))\n\ndef rel_vol_time_id(path):\n    book = pd.read_parquet(path) \n    # calculating WAP\n    p1 = book['bid_price1']\n    p2 = book['ask_price1']\n    s1 = book['bid_size1']\n    s2 = book['ask_size1']\n    \n    book['wap'] = (p1*s2 + p2*s1) \/ (s1 + s2)\n    transbook = book.groupby('time_id')['wap'].agg(calc_wap)\n    return transbook","0cb55de5":"%%time \nstock_id = []\ntime_id = []\nrelvol = []\nfor i in order_book_training:\n    # finding the stock_id\n    temp_stock = int(i.split(\"=\")[1])\n    # find the realized volatility for all time_id of temp_stock\n    temp_relvol = rel_vol_time_id(i)\n    stock_id += [temp_stock]*temp_relvol.shape[0]\n    time_id += list(temp_relvol.index)\n    relvol += list(temp_relvol)","f6c49b10":"past_volatility = pd.DataFrame({\"stock_id\": stock_id, \"time_id\": time_id, \"volatility\": relvol})","854319aa":"from sklearn.metrics import r2_score\n\njoined = train.merge(past_volatility, on = [\"stock_id\",\"time_id\"], how = \"left\")\nR2 = round(r2_score(y_true = joined['target'], y_pred = joined['volatility']),3)\nprint(f'R2 score: {R2}')","2ff343bc":"def rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) \/ y_true))))\n\nrmspe = rmspe(joined['target'], joined['volatility'])\nprint(f'RMSPE: {rmspe}')","a584d08e":"from sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# for training\ndef linear_training(X,y,degree):\n    # instantiating polynomial features\n    polyfeat = PolynomialFeatures(degree = degree)\n    linreg = LinearRegression()\n    # preprocessing the training data\n    x = np.array(X).reshape(-1,1)\n    # creating the polynomial features\n    X_ = polyfeat.fit_transform(x)\n    # training the model\n    weights = 1\/np.square(y)\n    return linreg.fit(X_, np.array(y).reshape(-1,1), sample_weight = weights)\n\n\nstock_id_train = train.stock_id.unique() # all stock_id for the train set\nmodels = {} # dictionary for holding trained models for each stock_id\ndegree = 2\nfor i in stock_id_train:\n    temp = joined[joined[\"stock_id\"]==i]\n    X = temp[\"volatility\"]\n    y = temp[\"target\"]\n    models[i] = linear_training(X,y,degree)","25fd122d":"# listing all test order books\norder_book_test = glob.glob('\/kaggle\/input\/optiver-realized-volatility-prediction\/book_test.parquet\/*')","671b6c12":"%%time \nstock_id = []\ntime_id = []\nrelvol = []\nfor i in order_book_test:\n    # finding the stock_id\n    temp_stock = int(i.split(\"=\")[1])\n    # find the realized volatility for all time_id of temp_stock\n    temp_relvol = rel_vol_time_id(i)\n    stock_id += [temp_stock]*temp_relvol.shape[0]\n    time_id += list(temp_relvol.index)\n    relvol += list(temp_relvol)\n    \npast_test_volatility = pd.DataFrame({\"stock_id\": stock_id, \"time_id\": time_id, \"volatility\": relvol})","f4654610":"# for inference\ndef linear_inference(models, stock_id, past_volatility, degree):\n    model = models[stock_id]\n    polyfeat = PolynomialFeatures(degree = degree)\n    return model.predict(polyfeat.fit_transform([[past_volatility]]))[0][0]","5a23e8ea":"submission = pd.DataFrame({'row_id' : [], 'target' : []})  \nsubmission['row_id'] = past_test_volatility.apply(lambda x: str(int(x.stock_id)) + '-' + str(int(x.time_id)), axis=1)\nsubmission['target'] = past_test_volatility.apply(lambda x: linear_inference(models,\\\n                                                                            x.stock_id,\\\n                                                                            x.volatility,\\\n                                                                            degree), axis = 1)","5e426d33":"submission.to_csv('submission.csv',index = False)","44d29798":"First thing first, let's read the train set. \n\nIt contains 3 columns:\n1. stock_id: ID code for the stock\n2. time_id: ID code for the time bucket\n3. target: The realized volatility computed over the 10 minute window following the feature data under the same stock\/time_id.\n\nWe want to predict the last feature in the following ten minutes window.","d222fc26":"Let's calculate the baseline R2 and RMSE:","98f08cd8":"Hope you liked this basic notebook and hope it would be helpful, more advanced are coming! Please upvote! :)  ","328eebe4":"Here two useful functions too calculate the **WAP** and the **rel_volatility** ","0a1a771b":"Create a pandas df","7516643e":"Last two steps are the predictions and the submissions.","3b78f913":"Let's load the parquet files also.","0f920ea2":"The following code chunk will take a while, for each stock_id finds the realized volatility for all time_id of temp_stock\n","33d55b0a":"After all the preprocessing now it's the turn for our baseline model, we'll use the Polynomial Features of the sklear preprocessing.\n\nThe Polynomial regression extends the linear model by adding extra predictors, obtained by raising each of the original predictors to a power. For example, a cubic regression uses three variables, X, X2, and X3, as predictors. This approach provides a simple way to provide a non-linear fit to data.\n\n**The degree is a parameter to be tuned.**"}}