{"cell_type":{"8e762dfc":"code","d4a95389":"code","6c456bf2":"code","eef5d92f":"code","e94b48b3":"code","4cbf9d2c":"code","4ffa1554":"code","dd56d5b2":"code","fc38dfa9":"code","9a5b6702":"code","f821eb7e":"code","2be65dae":"code","032db34d":"code","2fd84fb3":"code","083bb431":"markdown","ec760969":"markdown"},"source":{"8e762dfc":"!git clone https:\/\/github.com\/yhenon\/pytorch-retinanet.git\n!cp -r \/kaggle\/working\/pytorch-retinanet\/retinanet .\/\n!pip install -q pycocotools","d4a95389":"import os\nimport re\nimport cv2\nimport time\nimport numpy as np\nimport pandas as pd\n\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport torch\nimport torch.optim as optim\nimport torchvision.transforms as T\nfrom torchvision.utils import make_grid \nfrom torch.utils.data import DataLoader, Dataset\n\nfrom retinanet import model\nfrom retinanet.dataloader import collater, Resizer, Augmenter, Normalizer, UnNormalizer\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\nBASE_DIR = \"..\/input\/tensorflow-great-barrier-reef\/train_images\"\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else torch.device('cpu'))\nNUM_EPOCHS = 5","6c456bf2":"df = pd.read_csv(r'..\/input\/reef-a-cv-strategy-subsequences\/train-validation-split\/train-0.1.csv')\n\ndisplay(df)\n\n# Turn annotations from strings into lists of dictionaries\ndf['annotations'] = df['annotations'].apply(eval)\n# Create the image path for the row\ndf['image_path'] = \"video_\" + df['video_id'].astype(str) + \"\/\" + df['video_frame'].astype(str) + \".jpg\"\n\ndf.head()","eef5d92f":"df_train, df_val = df[df['is_train']], df[~df['is_train']]","e94b48b3":"# Removing the instances with no target\ndf_train = df_train[df_train.annotations.str.len() > 0 ].reset_index(drop=True)\ndf_val = df_val[df_val.annotations.str.len() > 0 ].reset_index(drop=True)","4cbf9d2c":"# remove later\ndf_train.shape[0], df_val.shape[0]","4ffa1554":"class ReefDataset:\n\n    def __init__(self, df, transforms=None):\n        self.df = df\n        self.transforms = transforms\n\n    def get_boxes(self, row):\n        \"\"\"Returns the bboxes for a given row as a 3D matrix with format [x_min, y_min, x_max, y_max]\"\"\"\n        \n        records = pd.DataFrame(row['annotations'])\n        boxes = np.zeros((records.shape[0], 5))\n        \n        boxes[:, 0:4] = records[['x', 'y', 'width', 'height']].values\n        # Change from [x_min, y_min, w, h] to [x_min, y_min, x_max, y_max]\n        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n        \n        # to correct out of box annotations\n        boxes[:, 0] = np.maximum(0, boxes[:, 0])\n        boxes[:, 1] = np.maximum(0, boxes[:, 1])\n        boxes[:, 2] = np.minimum(1280, boxes[:, 2])\n        boxes[:, 3] = np.minimum(720, boxes[:, 3])\n        return boxes\n    \n    def get_image(self, row):\n        \"\"\"Gets the image for a given row\"\"\"\n        \n        image = cv2.imread(f'{BASE_DIR}\/{row[\"image_path\"]}', cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image \/= 255.0\n        return image\n    \n    def __getitem__(self, i):\n\n        row = self.df.iloc[i]\n        image = self.get_image(row)\n        boxes = self.get_boxes(row)\n        \n        n_boxes = boxes.shape[0]\n        \n        # Calculate the area\n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        \n        sample = {\n                'img': image,\n                'annot': boxes,\n            }\n    \n        if self.transforms :\n            sample = self.transforms(sample)\n        \n\n        return sample\n\n    def __len__(self):\n        return len(self.df)","dd56d5b2":"def get_train_transform():\n    return T.Compose([Augmenter(), Normalizer(), Resizer()])\n\ndef get_valid_transform():\n    return T.Compose([Normalizer(), Resizer()])","fc38dfa9":"# Define datasets\nds_train = ReefDataset(df_train, get_train_transform())\nds_val = ReefDataset(df_val, get_valid_transform())","9a5b6702":"# Define dataloaders\ndl_train = DataLoader(ds_train, batch_size=8, shuffle=False, num_workers=4, collate_fn=collater)\ndl_val = DataLoader(ds_val, batch_size=8, shuffle=False, num_workers=4, collate_fn=collater)","f821eb7e":"retinanet = model.resnet50(num_classes = 2, pretrained = True)\nretinanet.to(DEVICE)\noptimizer = torch.optim.Adam(retinanet.parameters(), lr = 0.0001)","2be65dae":"from tqdm.notebook import tqdm\n\ndef train_one_epoch(epoch_num, train_data_loader):\n    retinanet.train()\n\n    epoch_loss = []\n\n    for iter_num, data in tqdm(enumerate(train_data_loader)):\n                \n        # Reseting gradients after each iter\n        optimizer.zero_grad()\n            \n        # Forward\n        classification_loss, regression_loss = retinanet([data['img'].to(DEVICE).float(), data['annot'].to(DEVICE).float()])\n                \n        # Calculating Loss\n        classification_loss = classification_loss.mean()\n        regression_loss = regression_loss.mean()\n\n        loss = classification_loss + regression_loss\n\n        if bool(loss == 0):\n            continue\n                \n        # Calculating Gradients\n        loss.backward()\n\n        # Gradient Clipping\n        torch.nn.utils.clip_grad_norm_(retinanet.parameters(), 0.1)\n           \n        # Updating Weights\n        optimizer.step()\n\n        epoch_loss.append(float(loss))\n\n            \n        print(\n            'Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(\n                epoch_num, iter_num, float(classification_loss), float(regression_loss), np.mean(epoch_loss)))\n\n        del classification_loss\n        del regression_loss","032db34d":"def valid_one_epoch(epoch_num, valid_data_loader):\n    \n    epoch_loss = []\n\n    for iter_num, data in tqdm(enumerate(valid_data_loader)):\n                \n        with torch.no_grad():\n            \n            # Forward\n            classification_loss, regression_loss = retinanet([data['img'].to(DEVICE).float(), data['annot'].to(DEVICE).float()])\n\n            # Calculating Loss\n            classification_loss = classification_loss.mean()\n            regression_loss = regression_loss.mean()\n            loss = classification_loss + regression_loss\n\n            #Epoch Loss\n            epoch_loss.append(float(loss))\n\n            print(\n                'Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(\n                    epoch_num, iter_num, float(classification_loss), float(regression_loss), np.mean(epoch_loss)))\n\n            del classification_loss\n            del regression_loss\n        \n    # Save Model after each epoch\n    torch.save(retinanet, f\"retinanet_barrier_reef_epoch{epoch_num}.pt\")\n    \n  ","2fd84fb3":"## Training Loop\nfor epoch in tqdm(range(NUM_EPOCHS)):\n    print(\"Epoch - {} Started\".format(epoch))    \n    train_one_epoch(epoch, dl_train)\n    valid_one_epoch(epoch, dl_val)","083bb431":"### Set Up for training","ec760969":"## RetinaNet in Pytorch - Tensorflow Great Barrier Reef\n\nI wrote this notebook using following two notebooks\n\n1. https:\/\/www.kaggle.com\/jainamshah17\/gwd-retinanet-pytorch-train\n2. https:\/\/www.kaggle.com\/julian3833\/reef-starter-torch-fasterrcnn-train-lb-0-416\/notebook\n"}}