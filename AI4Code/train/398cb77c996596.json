{"cell_type":{"edf7c1ed":"code","e6f2a719":"code","9bcea7ff":"code","537eb06e":"code","c044d795":"code","9b9e91a7":"code","ee6c6b84":"code","4da233e6":"code","790f5202":"code","ab7acb1a":"code","c8b4205f":"code","f1f935c2":"code","1aa3af25":"code","6187ec19":"code","fad377d5":"code","9ff1f435":"code","3b21ca70":"code","0c81e0e2":"code","91ab10ad":"code","8fc82e3c":"code","e98e264d":"code","231b66cb":"code","8b7dc0aa":"code","e86feb5c":"code","653dba3b":"code","1ca21c2f":"code","abc9504a":"code","188eeae9":"code","696b07ae":"code","c4aebf5a":"code","d87a97cb":"code","ab8c9bbf":"code","1b0d5ed7":"code","d670d251":"markdown","b9269538":"markdown","b0032a43":"markdown","1dca2807":"markdown","eed80698":"markdown","d66343ec":"markdown","98d4563f":"markdown","a785fdd6":"markdown","b0c6b458":"markdown","263b961b":"markdown","6cfbadad":"markdown","aa4e4ee8":"markdown","14c8a316":"markdown","08c541ea":"markdown","0a051873":"markdown","57c86df7":"markdown","2696f32b":"markdown","5956c538":"markdown","651771a4":"markdown","a4e8403e":"markdown","b8e4b57a":"markdown","ed5b2749":"markdown","989b9c41":"markdown","22ad63a6":"markdown"},"source":{"edf7c1ed":"# Dependencies and Setup\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport pandas as pd\nimport numpy as np\n\nimport requests\nimport time\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport collections\nimport timeit\nimport re\nfrom datetime import  datetime\nimport seaborn as sns\n%matplotlib inline","e6f2a719":"df_answers = pd.read_csv('..\/input\/answers.csv')\ndf_questions = pd.read_csv('..\/input\/questions.csv')","9bcea7ff":"df_answeredQuestions = pd.merge(df_questions,df_answers, left_on = 'questions_id', right_on = 'answers_question_id', how='outer')\ncolumns=['questions_title','questions_body','answers_body','questions_id','questions_author_id','answers_id','answers_author_id']","537eb06e":"df_not_answeredQuestions=df_answeredQuestions[df_answeredQuestions['answers_id'].isnull()][columns]\ndf_not_answeredQuestions.head()","c044d795":"df_answeredQuestions=df_answeredQuestions[df_answeredQuestions['answers_id'].isnull()==False][columns]\ndf_answeredQuestions.head()","9b9e91a7":"df_MostAnswerdQuestions=pd.DataFrame(df_answeredQuestions.groupby(['questions_id'],as_index=False) \\\n                     .count())[['questions_id','answers_id']] \\\n                     .rename(columns = {'answers_id':'answer count'})\n\nprint(df_MostAnswerdQuestions.info())\nprint()\ndf_MostAnswerdQuestions=df_MostAnswerdQuestions[df_MostAnswerdQuestions['answer count']>=5].sort_values('answer count',ascending=False).reset_index(drop=True)\n# Questions with atleast 5 answers\ndf_MostAnswerdQuestions.head()","ee6c6b84":"sns.countplot(x='answer count',data=df_MostAnswerdQuestions)","4da233e6":"# Create stopword list:\nstopWord=['really','this','dont','just','was','but','about','being','know','when','does','take','there','most','when','would','best','become','some','want','and','that','should','have','can','get','the','you','your','which','will','what','with','did','into','not','any','more','much','all','has','had','for','how','are']\nstopwords = set(STOPWORDS)\nstopwords.update(stopWord)\n\nquestionTitle = \" \".join(review for review in df_questions['questions_title'])\n# Create and generate a word cloud image:\nwordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(questionTitle)\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()\n\nwordcount = {} \n\ndef generate_word(text):\n    '''fast, easy, and clean way to iterate by saving memory space''' \n    for word in text.lower().split():\n        yield word  \n\ndef generate_word_count(text):\n    for word in generate_word(text):\n        word = word.replace(\".\",\"\")\n        word = word.replace(\"'\",\"\")\n        word = word.replace(\",\",\"\")\n        word = word.replace(\":\",\"\")\n        word = word.replace(\"\\\"\",\"\")\n        word = word.replace(\"!\",\"\")\n        word = word.replace(\"\u00e2\u20ac\u0153\",\"\")\n        word = word.replace(\"\u00e2\u20ac\u02dc\",\"\")\n        word = word.replace(\"*\",\"\")\n        word = word.replace(\"?\",\"\")\n        word = word.replace(\"#\",\"\")\n        if len(word)>=3 and word not in stopWord: \n            if word not in wordcount:\n                wordcount[word] = 1\n            else:\n                wordcount[word] += 1\n    return wordcount\n\n\nword_counter = collections.Counter(generate_word_count(questionTitle))\nprint('Most Common Words used in Title of Questions')\nprint()\nfor word, count in word_counter.most_common(20):\n    print(word, \": \", count)\n   \n\n\nquestionBody = \" \".join(review for review in df_questions['questions_body'])\n# Create and generate a word cloud image:\nwordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(questionBody)\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()\n\n\nword_counter = collections.Counter(generate_word_count(questionBody))\nprint('Most Common Words used in Body of Questions')\nprint()\nfor word, count in word_counter.most_common(20):\n    print(word, \": \", count)    \n    ","790f5202":"df_professionals=pd.read_csv('..\/input\/professionals.csv')\ndf_professionals=df_professionals[(df_professionals['professionals_headline'].notnull()) & \n                                  (df_professionals['professionals_industry'].notnull())] \\\n                    [['professionals_id','professionals_industry','professionals_headline']].reset_index(drop=True)\n\ndf_professionals.head()","ab7acb1a":"df_tag_questions=pd.read_csv(\"..\/input\/tag_questions.csv\")\ndf_tag_questions.head()","c8b4205f":"df_tags=pd.read_csv(\"..\/input\/tags.csv\")\ndf_tags.head()","f1f935c2":"# Dataframe question\/tag\ndf_tag_questions_detail = pd.merge(df_tag_questions,df_tags, left_on='tag_questions_tag_id' ,right_on= 'tags_tag_id', how='left') \\\n                                [['tag_questions_question_id','tags_tag_name']].rename(columns = {'tags_tag_name':'question_tag'})\ndf_tag_questions_detail.head()","1aa3af25":"columns=['answers_id','answers_question_id','professionals_id','professionals_industry','professionals_headline']\ndf_answers_professionals = pd.merge(df_answers,df_professionals, left_on='answers_author_id' ,right_on= 'professionals_id', how='left')[columns]\ndf_answers_professionals=df_answers_professionals.dropna(subset=['professionals_id']).reset_index(drop=True)\nprint(df_answers_professionals.info())\ndf_answers_professionals.head()","6187ec19":"columns=['answers_id','answers_question_id','professionals_id','professionals_industry','professionals_headline','question_tag']\ndf_q_p_t = pd.merge(df_answers_professionals,df_tag_questions_detail, left_on='answers_question_id',\n                  right_on= 'tag_questions_question_id', how='left')[columns]\ndf_q_p_t=df_q_p_t.dropna(subset=['question_tag']).reset_index(drop=True)\ndf_q_p_t.head()","fad377d5":"df_professionalsHeadline_by_questionTag=df_q_p_t[['professionals_headline','question_tag']]\ndf_professionalsHeadline_by_questionTag.head()","9ff1f435":"df_professionalsIndustry_by_questionTag=df_q_p_t[['professionals_industry','question_tag']]\ndf_professionalsIndustry_by_questionTag.head()","3b21ca70":"df_correlation_q_p=pd.concat([df_professionalsHeadline_by_questionTag.set_index('question_tag'),df_professionalsIndustry_by_questionTag.set_index('question_tag')],\n             axis=1, join='inner').reset_index()\n\ndf_correlation_q_p.head()","0c81e0e2":"def searchTag(questionTags):\n    '''This function searchs historical question hashtags and returns \n        list of related professional ids\n    '''\n    df_result_1=(df_correlation_q_p[df_correlation_q_p['question_tag'].isin(questionTags)] \n    .sort_values(by=['question_tag']).reset_index(drop=True))\n    if not df_result_1.empty:\n        #Join with df_prof based on (professionals_headline\/professionals_industry)\n        #to get the list of professionals\n        columns=['professionals_id','professionals_industry','professionals_headline','question_tag']\n        df_result = pd.merge(df_result_1,df_professionals, \n                             on=['professionals_headline','professionals_industry'], \n                             how='left')[columns]\n        return df_result\n    else:\n        return 'No result found.'\n   \n#questionTags=input(\"Please enter a comma-separated hashtags included in the question:\")\nquestionTags=\"police,law\"\nsearchTag(questionTags.split(','))","91ab10ad":"df_qa = pd.merge(df_questions,df_answers, left_on = 'questions_id', \n                 right_on = 'answers_question_id', how='right')","8fc82e3c":"df_qa['answeredInDays']= (pd.to_datetime(df_qa['answers_date_added'])\n                    -pd.to_datetime(df_qa['questions_date_added'])).dt.days\n\ndf_qa.head()","e98e264d":"comments=Path(\"..\/input\/comments.csv\")\ndf_comments=pd.read_csv(comments)","231b66cb":"df_qa_comment = pd.merge(df_qa,df_comments, left_on = 'answers_id', \n                 right_on = 'comments_parent_content_id', how='left')\n\n\ndf_qa_comment['hasComment']=df_qa_comment['comments_parent_content_id'].apply(lambda x: 1 if pd.notnull(x) else 0)\ndf_qa_comment=df_qa_comment[['questions_id','answers_id','comments_id','comments_parent_content_id','hasComment','answeredInDays']]\n\ndf_qa_comment.head()","8b7dc0aa":"df_last_comment=df_comments[df_comments['comments_date_added']\n            .isin(df_comments.groupby('comments_parent_content_id',as_index=False)\n                  .max()['comments_date_added'].values)].reset_index()\n\ndf_last_comment=df_last_comment.drop(columns=['index'])\ndf_last_comment.head()","e86feb5c":"df_comment_count=pd.DataFrame(\n    df_comments.groupby('comments_parent_content_id',as_index=False).count())[['comments_parent_content_id','comments_id']]\ndf_comment_count.rename(columns = {'comments_id':'number_of_comments'},inplace=True)\ndf_comment_count.head()","653dba3b":"favComment = ['thank','pleasure']\ndf_last_comment['hasFavComment']=df_last_comment['comments_body'].apply(lambda x: \n                                                            1 if any(re.findall(r\"(?=(\"+'|'.join(favComment)+r\"))\",str(x).lower())) else 0)\ndf_last_comment=df_last_comment[['comments_id','comments_parent_content_id','hasFavComment']]\ndf_last_comment.head()","1ca21c2f":"columns=['questions_id','answers_id','hasComment','number_of_comments','answeredInDays','hasFavComment']\ndf_qa_comment_summary = pd.merge(df_qa_comment,df_last_comment, on = 'comments_parent_content_id', how='left')\n\ndf_qa_comment_summary = pd.merge(df_qa_comment_summary,df_comment_count, left_on = 'answers_id', \n                 right_on = 'comments_parent_content_id', how='left')\n\ndf_qa_comment_summary=df_qa_comment_summary[columns]\n\ndf_qa_comment_summary.loc[df_qa_comment_summary['hasFavComment'].isnull(),'hasFavComment'] = 0\ndf_qa_comment_summary.loc[df_qa_comment_summary['number_of_comments'].isnull(),'number_of_comments'] = 0\ndf_qa_comment_summary.loc[df_qa_comment_summary['answeredInDays'].isnull(),'answeredInDays'] = -1\ndf_qa_comment_summary.drop_duplicates(inplace=True)\n\nprint(df_qa_comment_summary.info())\nprint()\ndf_qa_comment_summary.head()","abc9504a":"sns.countplot(x='hasFavComment',data=df_qa_comment_summary)","188eeae9":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\n\nX = df_qa_comment_summary[['hasComment', 'number_of_comments','answeredInDays']]\ny = df_qa_comment_summary['hasFavComment']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\nlogmodel = LogisticRegression()\nlogmodel.fit(X_train,y_train)\n","696b07ae":"logmodel = LogisticRegression()\nlogmodel.fit(X_train,y_train)\n","c4aebf5a":"predictions = logmodel.predict(X_test)","d87a97cb":"cnf_matrix = metrics.confusion_matrix(y_test, predictions)\ncnf_matrix","ab8c9bbf":"class_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\nsns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')","1b0d5ed7":"print(\"Accuracy:\",metrics.accuracy_score(y_test, predictions))\nprint(\"Precision:\",metrics.precision_score(y_test, predictions))\nprint(\"Recall:\",metrics.recall_score(y_test, predictions))","d670d251":"**Number of Comments**","b9269538":"**Dataframe Professionals Industry by Question Tag**\n\n**These tags have been answered by these professionals**","b0032a43":"**Well, we got a classification rate of 94%, considered as good accuracy.\n**\n\n**Precision: Precision is about being precise, In our prediction case, the Precision rate is about 69% when question ends with our favourite comment.**","1dca2807":"**The result is telling us that we have 12897+1674 correct predictions \n**\n\n**and 732+35 incorrect predictions.\n**\n\n**Here, you will visualize the confusion matrix using Heatmap.**","eed80698":"**Questions with No Answer**","d66343ec":"** Correlation between professionals professionals_industry\/professionals_headline to question tag**","98d4563f":"**Data exploration**","a785fdd6":"**Our favorite comments tend to have \"Thank you\" in them :)**\n    \n**We create a new column [hasFavComment]**\n\n**[hasFavComment]=1 if comment has ended with \"Thank you or Thanks\"**\n\n**[hasFavComment]=0 if the comment has not ended with \"Thank you or Thanks\"**\n","b0c6b458":"**Answers can only be posted by users who are registered as Professionals. **\n\n**Dataframe Answers by professionals**","263b961b":"**Questions with Answer**","6cfbadad":"**Now lets evaluate the performance of a classification model**","aa4e4ee8":"\n# Solution number 1 example\n\n# You can send questuion tags to dataframe to find out professionals_headline\/professionals_industry who answerd the questions before.\n# Based on professionals_headline or professionals_industry you can get list of professionals and email them the question.\n","14c8a316":"**Dataframe Professionals Headline by Question Tag**\n\n**These tags have been answered by these professionals**","08c541ea":"**Create and generate a word cloud image based on title and body of questions.**\n\n**and display most Common Words used in Title\/body of Questions**","0a051873":"**[hasComment]**\n\n**We create a new column **\n\n**[hasComment]=1 if the answer has atleast one comment**\n\n**[hasComment]=0 if the answer has no comment**\n","57c86df7":"**Get the last comment of an answer**","2696f32b":"\n# Solution number 1 example\n\n# Analysing historical data shows the correlation between question tag and professionals_headline\/professionals_industry\n\n# To make it simple, these tags have been answered by these professionals.","5956c538":"\n**Machine Learning**\n\n**Implementing a simple Logistic Regression to predict the probability of question ends with our favorite  comment (Our favorite comments tend to have \"Thank you\" in them).**","651771a4":"**Implementing Logistic Regression that is used to predict the probability of a categorical dependent variable (hasFavComment). 1 (yes) or 0 (no).**","a4e8403e":"**Calculate the period of each question has been answered (in days) **\n\n**0 day means the question has been answered on the same day**","b8e4b57a":"**Merge all the datasets to get one single dataset with the following columns**","ed5b2749":"**Merge Questions with Answers**","989b9c41":"**Confusion Matrix Evaluation Metrics Let's evaluate the model using model evaluation metrics such as accuracy, precision, and recall.**","22ad63a6":"**Top Questions with the most Answers**"}}