{"cell_type":{"f157a45e":"code","f719934d":"code","7236fc5c":"code","9f86fa61":"code","2015a248":"code","0b9cf97e":"code","a5017ef9":"code","02dd789b":"code","dbe10006":"code","a7bb5d64":"code","1d348172":"code","09742ce0":"code","b85a68ad":"code","65433efb":"code","b65b9e64":"code","503cc6b2":"code","6c9561cd":"code","55c391d4":"code","679355a4":"code","91000941":"code","dbda5f1b":"code","8ae7b9d6":"code","7b40f2e5":"markdown"},"source":{"f157a45e":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns","f719934d":"# Import raw data\nraw_data = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")\nraw_data","7236fc5c":"# Show the data details\nraw_data.describe()","9f86fa61":"# See the null value\nraw_data.isna().sum().max()","2015a248":"# See the number of each class\nraw_data[\"Class\"].value_counts()*100\/len(raw_data) # Imbalance dataset 0: Not fraud, 1: Fraud","0b9cf97e":"# Show the imbalance between the number of class via histogram\nsns.countplot(x='Class', data=raw_data)\nplt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14);","a5017ef9":"# Scale the amount and time column\nfrom sklearn.preprocessing import StandardScaler,RobustScaler\n\nscaler = RobustScaler()\nraw_data[\"Scaled_amount\"] = scaler.fit_transform(raw_data[\"Amount\"].values.reshape(-1,1))\nraw_data[\"Scaled_time\"] = scaler.fit_transform(raw_data[\"Time\"].values.reshape(-1,1))\nraw_data.drop([\"Amount\",\"Time\"],axis=1,inplace=True)\n\nraw_data.head()","02dd789b":"# Under sampling\nraw_data_0 = raw_data[raw_data[\"Class\"]==0] # Only label 0\nraw_data_1 = raw_data[raw_data[\"Class\"]==1] # Only label 1\ndata_0_count = len(raw_data_0) # Count 0\ndata_1_count = len(raw_data_1) # Count 1\ndata_0 = raw_data_0.sample(data_1_count) # Under sampling the data\ndata = pd.concat([data_0, raw_data_1], axis=0,ignore_index=True) # Join the data\ndata","dbe10006":"# Show the balance between the number of class via histogram\nsns.countplot(x='Class', data=data)\nplt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14);","a7bb5d64":"# Correlation matrix\nf, (ax1, ax2) = plt.subplots(2, 1, figsize=(24,20))\n\n# Correlation matrix of raw_data\ncorr = raw_data.corr()\nsns.heatmap(corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax1)\nax1.set_title(\"Imbalanced Correlation Matrix \\n (don't use for reference)\", fontsize=14)\n\n# Correlation matrix of under sampling data\nsub_sample_corr = data.corr()\nsns.heatmap(sub_sample_corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax2)\nax2.set_title('SubSample Correlation Matrix \\n (use for reference)', fontsize=14)\nplt.show()","1d348172":"f, axes = plt.subplots(ncols=4, figsize=(20,4))\n\nneg_corr = [\"V17\",\"V14\",\"V12\",\"V10\"]\nfor i,v in enumerate(neg_corr,0):\n# Negative Correlations with our Class (The lower our feature value the more likely it will be a fraud transaction)\n    sns.boxplot(x=\"Class\", y=v, data=data, ax=axes[i])\n    axes[i].set_title(f'{v} vs Class Negative Correlation')\n\nplt.show()","09742ce0":"f, axes = plt.subplots(ncols=4, figsize=(20,4))\n\npos_corr = [\"V11\",\"V4\",\"V2\",\"V19\"]\nfor i,v in enumerate(pos_corr,0):\n# Positive correlations (The higher the feature the probability increases that it will be a fraud transaction)\n    sns.boxplot(x=\"Class\", y=v, data=data, ax=axes[i])\n    axes[i].set_title(f'{v} vs Class Negative Correlation')\n\nplt.show()","b85a68ad":"from scipy.stats import norm\n\nf, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20, 6))\n\nv14_fraud_dist = data['V14'].loc[data['Class'] == 1].values\nsns.distplot(v14_fraud_dist,ax=ax1, fit=norm, color='#FB8861')\nax1.set_title('V14 Distribution \\n (Fraud Transactions)', fontsize=14)\n\nv12_fraud_dist = data['V12'].loc[data['Class'] == 1].values\nsns.distplot(v12_fraud_dist,ax=ax2, fit=norm, color='#56F9BB')\nax2.set_title('V12 Distribution \\n (Fraud Transactions)', fontsize=14)\n\n\nv10_fraud_dist = data['V10'].loc[data['Class'] == 1].values\nsns.distplot(v10_fraud_dist,ax=ax3, fit=norm, color='#C5B3F9')\nax3.set_title('V10 Distribution \\n (Fraud Transactions)', fontsize=14)\n\nplt.show()","65433efb":"# Under sampling\nX = data.drop(\"Class\",axis=1)\ny = data[\"Class\"]","b65b9e64":"# Dimensionality Reduction with PCA\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=2,random_state=0)\nX_reduced = pca.fit_transform(X)\nX_reduced","503cc6b2":"import matplotlib.patches as mpatches\nf, ax = plt.subplots(1, 1, figsize=(8,6))\n# labels = ['No Fraud', 'Fraud']\nf.suptitle('Clusters using Dimensionality Reduction', fontsize=14)\n\n\nblue_patch = mpatches.Patch(color='#0A0AFF', label='No Fraud')\nred_patch = mpatches.Patch(color='#AF0000', label='Fraud')\n\n# PCA scatter plot\nax.scatter(X_reduced[:,0], X_reduced[:,1], c=(y == 0), cmap='coolwarm', label='No Fraud', linewidths=2)\nax.scatter(X_reduced[:,0], X_reduced[:,1], c=(y == 1), cmap='coolwarm', label='Fraud', linewidths=2)\nax.set_title('PCA', fontsize=14)\nax.grid(True)\nax.legend(handles=[blue_patch, red_patch]);","6c9561cd":"# Split the dataset to training and testing\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)","55c391d4":"# Classifiers\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nclassifiers = {\n    \"LogisiticRegression\": LogisticRegression(),\n    \"KNearestNeighbor\": KNeighborsClassifier(),\n    \"Support Vector Classifier\": SVC(),\n    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n    \"RandomForestClassifier\": RandomForestClassifier()\n}\n\nclassifiers_predicted = {\n    \"LogisiticRegression\": None,\n    \"KNearestNeighbor\": None,\n    \"Support Vector Classifier\": None,\n    \"DecisionTreeClassifier\": None,\n    \"RandomForestClassifier\": None\n}","679355a4":"# Train the model and check the score with test set\nfrom sklearn.model_selection import cross_val_score\n\nfor key, classifier in classifiers.items():\n    classifier.fit(X_train,y_train)\n    classifiers_predicted[key] = classifier.predict(X_test)\n    score = classifier.score(X_test,y_test)\n    print(f\"The accuracy score of {key}: {np.mean(score)*100:.2f}%\")","91000941":"# Confusion matrix\nfrom sklearn.metrics import confusion_matrix\n\nfor key, predicted in classifiers_predicted.items():\n    print(key+\":\")\n    print(confusion_matrix(y_test,predicted,))\n    print()","dbda5f1b":"# Classification report\nfrom sklearn.metrics import classification_report\n\nfor key, predicted in classifiers_predicted.items():\n    print(key+\":\")\n    print(classification_report(y_test,predicted,))\n    print()","8ae7b9d6":"# Train the model with cross validation\nfrom sklearn.model_selection import cross_val_score\n\nfor key, classifier in classifiers.items():\n    score = cross_val_score(classifier, X_train, y_train, cv=5)\n    print(f\"The accuracy score of {key}: {np.mean(score)*100:.2f}%\")","7b40f2e5":"#### Summary and Explanation:\n\nNegative Correlations: V17, V14, V12 and V10 are negatively correlated. Notice how the lower these values are, the more likely the end result will be a fraud transaction.\n\nPositive Correlations: V2, V4, V11, and V19 are positively correlated. Notice how the higher these values are, the more likely the end result will be a fraud transaction.\n\nBoxPlots: We will use boxplots to have a better understanding of the distribution of these features in fradulent and non fradulent transactions."}}