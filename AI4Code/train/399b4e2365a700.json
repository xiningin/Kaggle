{"cell_type":{"5a74dda2":"code","044b6f7a":"code","bdf73671":"code","34f34ba4":"code","fc2bab5a":"code","0606af42":"code","d14b8440":"code","736dc828":"code","82cd8406":"code","140f5e0c":"code","8d4a7ac4":"code","b60f2001":"code","fe055823":"code","867fef76":"code","d991b989":"code","ef7ad756":"code","29f32347":"code","6fe84fca":"code","81b0c70a":"code","6f75be14":"code","679a5f1d":"code","3eef5300":"code","55bc451b":"code","3ae1dcdf":"code","171a4640":"code","c507b8a3":"code","3f2dca7a":"code","d92e40f1":"code","49e4ab50":"code","4af29336":"code","57941f06":"code","8ab6615c":"code","c19cb4d2":"markdown","3f1dc3a8":"markdown","2c84f308":"markdown","a01d8a8d":"markdown","f4ada8be":"markdown","86ce87e9":"markdown","97739918":"markdown","5fd46023":"markdown","ef61e863":"markdown","6259f79c":"markdown","0b13d517":"markdown","a2c18115":"markdown","412f9b35":"markdown","a405e122":"markdown","29bd28b6":"markdown","a85d3222":"markdown"},"source":{"5a74dda2":"import os\n\nprint(os.listdir('..\/input\/nlp-getting-started'))","044b6f7a":"import pandas as pd\nimport numpy as np\n\n# plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport re, string","bdf73671":"train = pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ntest = pd.read_csv('..\/input\/nlp-getting-started\/test.csv')\nsample = pd.read_csv('..\/input\/nlp-getting-started\/sample_submission.csv')","34f34ba4":"train.head()","fc2bab5a":"train = train.drop(columns='id')","0606af42":"test_ids = test.id\ntest = test.drop(columns='id')","d14b8440":"sns.countplot(train.target).set_title('Target variable distribution')","736dc828":"(100.0 * train.isna().sum() \/ train.shape[0]).to_frame(name='percentage').sort_values(by='percentage')","82cd8406":"def is_keyword_in(data):\n    if data.keyword in data.text.split():\n        return 1\n    else:\n        return 0","140f5e0c":"train['keyword_appears'] = train[['keyword', 'text']].dropna().apply(is_keyword_in, axis=1)","8d4a7ac4":"print('Percentage of keyword appearence in disasters')\n100.0 * train[train.target == 1].keyword_appears.value_counts(normalize=True).to_frame(name='percentage')","b60f2001":"train[train.target == 1].keyword_appears.value_counts(normalize=True).plot(kind='bar').set_title('Does keyword appear in real disasters?')","fe055823":"print('Percentage of keyword appearence in non-disasters')\n100.0 * train[train.target == 0].keyword_appears.value_counts(normalize=True).to_frame(name='percentage')","867fef76":"train[train.target == 0].keyword_appears.value_counts(normalize=True).plot(kind='bar').set_title('Does keyword appear in non disasters?')","d991b989":"pd.crosstab(train.target, train.keyword_appears)","ef7ad756":"train.location.dropna().value_counts().to_frame(name='count')","29f32347":"def get_num_words(data):\n    return len(data.split())","6fe84fca":"# Number of characters\ntrain['num_chars'] = train.text.apply(len)\n\n# Number of words\ntrain['num_words'] = train.text.apply(get_num_words)","81b0c70a":"train.num_chars.describe()","6f75be14":"sns.boxplot(x='target', y='num_chars', data=train[['num_chars', 'target']]).set_title('Number of characters')","679a5f1d":"train.num_words.describe()","3eef5300":"sns.boxplot(x='target', y='num_words', data=train[['num_words', 'target']]).set_title('Number of words')","55bc451b":"mentions = 0\n\nfor tweet in train.text.values:\n    words = tweet.split()\n    for w in words:\n        if w[0] == '@':\n            mentions += 1\n\nprint('Number of mentions:', mentions)\nprint('Number of tweets:', train.shape[0])","3ae1dcdf":"def has_mention(data):\n    mentions = 0\n    for word in data.text.split():\n        if word[0] == '@':\n            mentions += 1\n    \n    return mentions","171a4640":"train['mention'] = train.apply(has_mention, axis=1)","c507b8a3":"print('Percentage of mentions in disasters')\n100.0 * train[train.target == 1].mention.value_counts(normalize=True).to_frame(name='percentage')","3f2dca7a":"train[train.target == 1].mention.value_counts(normalize=True).plot(kind='bar').set_title('Do mentions appear in disasters?')","d92e40f1":"print('Percentage of mentions in non-disasters')\n100.0 * train[train.target == 0].mention.value_counts(normalize=True).to_frame(name='percentage')","49e4ab50":"train[train.target == 0].mention.value_counts(normalize=True).plot(kind='bar').set_title('Do mentions appear in non-disasters?')","4af29336":"def remove_URL(data):\n    url = re.compile(r'https?:\/\/\\S+|www\\.\\S+')\n    return url.sub(r'',data)\n\ndef remove_html(data):\n    html = re.compile(r'<.*?>')\n    return html.sub(r'',data)\n\n# Reference : https:\/\/gist.github.com\/slowkow\/7a7f61f495e3dbb7e3d767f97bd7304b\ndef remove_emoji(data):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    \n    return emoji_pattern.sub(r'', data)\n\ndef remove_punct(data):\n    table=str.maketrans('','',string.punctuation)\n    return data.translate(table)\n\ndef make_lower(data):\n    return data.lower()\n\ndef remove_mentions(data):\n    words = data.split()\n    \n    words = [word for word in words if word[0] != '@']\n    return ' '.join(words)\n\ndef clean_data(data, drop=False, test=False, lowercase=False, correct=False, rmv_mentions=False):\n    data.text = data.text.apply(remove_URL)\n    data.text = data.text.apply(remove_html)\n    data.text = data.text.apply(remove_emoji)\n    data.text = data.text.apply(remove_punct)\n    \n    if lowercase:\n        data.text = data.text.apply(make_lower)\n    \n    if correct:\n        data.text = data.text.apply(correct_spellings)\n    \n    if rmv_mentions:\n        data.text = data.text.apply(remove_mentions)\n    \n    if drop and test:\n        return data[['text']]\n    elif drop:\n        return data[['text', 'target']]\n    \n    return data","57941f06":"%%time\ntrain = clean_data(train, drop=True, lowercase=True, rmv_mentions=True)","8ab6615c":"train.head()","c19cb4d2":"Oh wow! Right of the bat it's clear that this location data is really dirty","3f1dc3a8":"## Model\n\nW.I.P.","2c84f308":"## Now let's take a look into these NaN values!","a01d8a8d":"## Data Cleaning\n\nMajority of the code here was taken from: https:\/\/www.kaggle.com\/shahules\/tweets-complete-eda-and-basic-modeling, I added the mentions removing part.","f4ada8be":"## Distribution of target variable:","86ce87e9":"Seems like there's a similar amount for each type","97739918":"## Imports:","5fd46023":"Seems like location is missing 33% of the times, whereas keyword only 0.8% of the time. I wonder how much the keyword correlate to disasters.\n\nSo let's take a look at the percentage of tweets that contain the keyword in it for each class.","ef61e863":"Seems like on average disasters tend to have more characters, as for words it's almost identical.","6259f79c":"# A first glance at the data.\n\n#### Hi guys :). I'm very excited for this competition, it's my first experience with anything related to NLP and this is my first public notebook and it's still a W.I.P! Hope it helps.","0b13d517":"Oh wow actually a lot of mentions! Maybe those could tell a model whether it is a disaster or not. Let's say for instance if it's mentioning the twitter username of a famous person or organisation, so that could maybe be looked into.","a2c18115":"## How about location? Which locations have the most frequent disasters?","412f9b35":"Do people mention others a lot? Let's see:","a405e122":"Seems like disasters tend to have less mentions, but the difference is not so big","29bd28b6":"## Let's look at some correlation between some text features and the target variable","a85d3222":"Not much of a difference =\/. So keywords may not give us a good enough hint that a tweet is a real disaster or not."}}