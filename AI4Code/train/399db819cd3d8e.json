{"cell_type":{"a8d3af89":"code","940508db":"code","4ce61e95":"code","3fa873bb":"code","9197ec71":"code","0d7f1e8f":"code","f56e3576":"code","f9831429":"code","a829f263":"code","5e21095b":"code","8c90d4a4":"code","eb9b68ce":"code","2246e0a3":"code","baedf255":"code","a6ba5706":"code","903bc793":"code","93ef6f81":"code","d698d0cb":"code","ad7cab8f":"markdown","d7e1fd79":"markdown","39ad55cc":"markdown","9ad4999f":"markdown","64bbe985":"markdown","cc0a83dd":"markdown","3d778cfd":"markdown"},"source":{"a8d3af89":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset,DataLoader\nfrom torchvision.utils import make_grid\nimport torch.nn.functional as F\nfrom torch import optim\n\nfrom sklearn.metrics import accuracy_score\nfrom tqdm.notebook import tqdm\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport cv2\n\n\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #make sure GPU is on to make cuda enable","940508db":"df= pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ndf =df.sample(frac = 1).reset_index(drop=True)\ndf = df.iloc[0:10000,:]#just taking the first 10000 values ","4ce61e95":"df = df.reset_index()\ndf.head()","3fa873bb":"#splitting in 3 folds\nfrom sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits = 3,random_state=7,shuffle=True)\nfolds = df.copy()\nfor f,(tr_idx,val_idx) in enumerate(skf.split(folds,folds.label)):\n    folds.loc[val_idx,'fold'] = int(f)\nfolds['fold'] = folds['fold'].astype(int)    \nfolds.groupby('fold').label.value_counts()","9197ec71":"# making a dataframe to store the oof data which you can use for ensembling later\noof = df.copy()\nclass_cols =[str(x) for x in np.sort(df.label.unique())]\noof[class_cols] = 0\noof.set_index('index', inplace=True)\noof.head()","0d7f1e8f":"# you can add your own augmentation techniques here (be careful while transforming, you can make a 9 into a 6 :) )\ntrain_aug = None\nval_aug = None","f56e3576":"class Csn(Dataset):\n    def __init__(self,train_df,augs=None):\n        self.df=train_df\n        self.augs = augs\n        \n    def __len__(self):\n        return(len(self.df))\n    \n    def __getitem__(self,idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        image_ids = self.df.iloc[idx]['index']\n        image =  self.df.iloc[idx,2:].values.reshape((-1,28,28))\n        if(self.augs == True):\n            transformed = self.augs(image = image)\n            image = transformed['image']\n            \n        image= image\/255.0\n        image = torch.tensor(image, dtype=torch.float)\n        label = self.df.iloc[idx].label\n        label =torch.tensor(label, dtype=torch.long)\n        \n        return image,label,image_ids","f9831429":"eg_data = Csn(df)\nplt.imshow(eg_data[5][0].squeeze(0))","a829f263":"class Cnn(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1= nn.Conv2d(1,8,5)\n        self.conv2 = nn.Conv2d(8,16,(3,3))\n        self.pool = nn.AdaptiveAvgPool2d((10,10))\n        self.fc1 = nn.Linear(16*10*10 ,500)\n        self.fc2 = nn.Linear(500,10)\n        self.dropout = nn.Dropout(0.25)\n       \n    def forward(self,x):\n        x = F.relu(self.conv1(x))\n        x = self.dropout(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = x.view(-1, 16*10*10)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        \n        return x","5e21095b":"model1=Cnn()","8c90d4a4":"import os\nOUTPUT_DIR = '.\/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","eb9b68ce":"class AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count","2246e0a3":"def train_one_epoch(train_loader,model,optimizer,criterion,e,epochs):\n    losses = AverageMeter()\n    scores = AverageMeter()\n    model.train()\n    global_step = 0\n    loop = tqdm(enumerate(train_loader),total = len(train_loader))\n    \n    for step,(image,labels,_) in loop:\n        image = image.to(device)\n        labels= labels.to(device)\n        output = model(image)\n        batch_size = labels.size(0)\n        loss = criterion(output,labels)\n        \n        out = output.softmax(1)\n        outputs = torch.argmax(out, dim=1).cpu().detach().numpy()\n        targets = labels.cpu().detach().numpy()\n        accuracy = accuracy_score(targets, outputs)\n        losses.update(loss.item(), batch_size)\n        scores.update(accuracy.item(), batch_size)\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        global_step += 1\n        \n        loop.set_description(f\"Epoch {e+1}\/{epochs}\")\n        loop.set_postfix(loss = loss.item(), accuracy = accuracy.item(), stage = 'train')\n        \n        \n    return losses.avg,scores.avg\n        \n        ","baedf255":"def val_one_epoch(loader,model,optimizer,criterion):\n    losses = AverageMeter()\n    scores = AverageMeter()\n    model.eval()\n    global_step = 0\n    loop = tqdm(enumerate(loader),total = len(loader))\n    \n    for step,(image,labels,_) in loop:\n        image = image.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        with torch.no_grad():\n            output = model(image)\n        loss = criterion(output,labels)\n        \n        output = output.softmax(1)\n        outputs = torch.argmax(output, dim=1).cpu().detach().numpy()\n        targets = labels.cpu().detach().numpy()\n        accuracy = accuracy_score(targets, outputs)\n        \n        losses.update(loss.item(), batch_size)\n        scores.update(accuracy.item(), batch_size)\n        loop.set_postfix(loss = loss.item(), accuracy = accuracy.item(), stage = 'valid')\n        \n        optimizer.step()\n        optimizer.zero_grad()\n        global_step += 1\n        \n    \n        \n    return losses.avg,scores.avg","a6ba5706":"def fit(fold_n,training_batch_size=64,validation_batch_size=128):\n    \n    train_data=folds[folds.fold != fold_n].iloc[:,:-1]\n    val_data=folds[folds.fold == fold_n].iloc[:,:-1]\n    train_data= Csn(train_data)\n    val_data= Csn(val_data)\n    \n    \n    train_loader = DataLoader(train_data,\n                             shuffle=True,\n                        num_workers=0,\n                        batch_size=training_batch_size)\n    valid_loader = DataLoader(val_data,\n                             shuffle=False,\n                        num_workers=0,\n                        batch_size=validation_batch_size)\n    model = Cnn()\n    model.to(device)\n    criterion=nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,patience = 3,verbose = True)\n    epochs= 3\n    \n    best_acc = 0\n    \n    loop = range(epochs)\n    for e in loop:\n        \n        train_loss,train_accuracy = train_one_epoch(train_loader,model,optimizer,criterion,e,epochs)\n         #scheduling step if given\n    \n        #scheduler.step()\n        \n        print(f'For epoch {e+1}\/{epochs}')\n        print(f'average train_loss {train_loss}')\n        print(f'average train_accuracy {train_accuracy}' )\n        \n        val_loss,val_accuracy = val_one_epoch(valid_loader,model,optimizer,criterion)\n        \n        scheduler.step(val_loss)\n        \n        print(f'avarage val_loss { val_loss }')\n        print(f'avarage val_accuracy {val_accuracy}')\n        \n        \n        \n        \n        if (val_accuracy>best_acc):\n            best_acc = val_accuracy\n            print(f'saving model for {best_acc}')\n            torch.save(model.state_dict(),OUTPUT_DIR+ f'Fold {fold_n} model with val_acc {best_acc}.pth') \n    \n    \n    \n    best_model = Cnn().to(device)\n    best_model.load_state_dict(torch.load(OUTPUT_DIR+ f'Fold {fold_n} model with val_acc {best_acc}.pth'))\n    best_model.eval()\n    for inputs,_, imgids in valid_loader:\n        with torch.no_grad():\n            inputs = inputs.to(device)\n            output= best_model(inputs)\n            softed = F.softmax(output, dim=1)\n            oof.loc[imgids, class_cols] = softed.cpu().numpy()\n                        \n    \n    \n               ","903bc793":"for i in range(3):\n    print(f'######### for Fold {i} ###########')\n    #modelx=Cnn()\n    fit(i)\n    \n    ","93ef6f81":"o=oof[class_cols]\no['label'] =oof['label']\noof=o\noof.to_csv('oof.csv')\noof.head()","d698d0cb":"oof_accuracy = accuracy_score(oof.label.values, np.argmax(oof[class_cols].values,axis =1))\noof_accuracy \n#say_my_name","ad7cab8f":"# Helper Functions","d7e1fd79":"# importing libraries","39ad55cc":"# Dataset","9ad4999f":"# Model","64bbe985":"# Training Loop","cc0a83dd":"# getting the oof files","3d778cfd":"# Data splitting"}}