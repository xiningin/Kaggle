{"cell_type":{"6a94b643":"code","57f083cb":"code","d7e1f5af":"code","00e80081":"code","cb5bf65c":"code","74edd73b":"code","815172d7":"code","531c05c5":"code","098df2fd":"code","ed04e140":"code","5707ca9c":"code","c2c4ebd0":"code","87a0ae46":"code","68e8e348":"code","3b461d48":"code","5c234c7e":"code","00ee9f1f":"code","b9b3cd13":"code","2d383c97":"code","f1b4f933":"code","13a75838":"code","5bf6d245":"code","c2cd81e3":"code","cd4b7e98":"code","c7fe8104":"code","ed1b8f8d":"code","a25939a9":"code","2faf2b42":"code","46f70632":"code","698ad976":"code","dfcdd41e":"code","e1a1abdc":"code","1354bb81":"code","081f8677":"code","221e65d4":"code","7c145092":"code","99c4fb04":"code","4e9f2267":"code","a2bca141":"code","d527cf34":"code","a08bf39d":"code","b1c295c9":"code","8310043d":"code","258a410b":"code","f7bfcf48":"code","66fb71dc":"code","cca8ce70":"code","5063509c":"code","520f6480":"code","3734bba4":"code","294025cd":"code","47802244":"code","2f42158f":"code","7628c062":"code","d87aab43":"code","365b9228":"code","7bb11aee":"code","66837eda":"code","0179ad80":"code","d5b8d696":"code","18d2aa68":"code","b740e83b":"code","a44c6a1f":"code","b9d6d684":"markdown","fe92f9c4":"markdown","35051709":"markdown","3f48707d":"markdown","90e2d6f4":"markdown","32f64b43":"markdown","04121c28":"markdown","5bec3fd1":"markdown","6d050be2":"markdown","8f9d3142":"markdown","bd5b62f9":"markdown","65e7d850":"markdown","da5d2518":"markdown","14a88444":"markdown","bfbe3faa":"markdown","c3e56884":"markdown","d65ba1b4":"markdown","f602219e":"markdown","9cf9a0ba":"markdown","08b8da9d":"markdown","8564e931":"markdown","2de2ba28":"markdown","1c8c3a88":"markdown","16b61981":"markdown","d470b24a":"markdown","c34a43df":"markdown","d087e603":"markdown","7175c5bb":"markdown","b8de0702":"markdown","3ece3c7e":"markdown","00cf6b1f":"markdown","39ac5a2f":"markdown","9d6e2f75":"markdown","bebe88a1":"markdown","2277bc67":"markdown","9c41bd79":"markdown","8e5970f3":"markdown","0bf2aff6":"markdown","df3a351c":"markdown","76201c2a":"markdown","471d5be5":"markdown","2c18a4b0":"markdown","fe754948":"markdown","a8fe2bdf":"markdown","525aac24":"markdown","08ac32a9":"markdown","d02d93c4":"markdown","637c9e13":"markdown","08f5039b":"markdown","94fd9f08":"markdown","0d2c161d":"markdown","74979238":"markdown","0aeaea6e":"markdown","344ecce7":"markdown","68bee9f2":"markdown","bb342945":"markdown","ec50fd21":"markdown","1421d644":"markdown","533ff61a":"markdown","ce06d763":"markdown","43fbca3e":"markdown","5745a689":"markdown","f727d834":"markdown","fff5ca17":"markdown","81fd7926":"markdown","ff93480b":"markdown","14ba23cd":"markdown","7a8c292d":"markdown","63d43b7c":"markdown","7d57105c":"markdown","10bc1d8c":"markdown","6b311ec1":"markdown","db593099":"markdown","e84f040f":"markdown","52708621":"markdown","e214fbfa":"markdown","0855a33e":"markdown","34480974":"markdown","8c77b132":"markdown","cbd733e6":"markdown","bce56c52":"markdown","901d394e":"markdown","e748adc8":"markdown","753cd201":"markdown","7dc49e07":"markdown","a3afc6de":"markdown","2bf48faa":"markdown","37aaab15":"markdown","56228786":"markdown","e17f1871":"markdown","6307cad5":"markdown","af3f9e8e":"markdown","53a2a089":"markdown","128a58fc":"markdown","002d2a2c":"markdown","16e2ec8a":"markdown","0d9f5c8d":"markdown","3e9bec02":"markdown","858212b8":"markdown","5c017245":"markdown","c3cf126d":"markdown","6a04e04a":"markdown","0b98334f":"markdown","2084ef8c":"markdown","385838d5":"markdown","9b26f593":"markdown","f2239aca":"markdown","5b41c37b":"markdown","193db200":"markdown","b92ff559":"markdown","8ff56728":"markdown","0540d889":"markdown"},"source":{"6a94b643":"# This library is to work with Data Frames\nimport pandas as pd\n\n# This library is to work with vectors\nimport numpy as np\n\n# This library is to visualise statistical graphs\nimport seaborn as sns\n\n# This library is to visualise graphs\nimport matplotlib.pyplot as plt\n\n# To set some plotting parameters\nfrom matplotlib import rcParams\n\n# To supplies classes for manipulating dates and times\nimport datetime\n\n# Library to work with Regular Expressions\nimport re\n\n# To ignore filterwarnings\nimport warnings\n\n# This library is to create displays\nfrom IPython.display import Image\n\n\"\"\"\nAt my Github Repository i stored all the functions in appropriate util packages. At Kaggle submission i will directly use those functions. \n\n# Calling reporting functions from util_reporting\nfrom util_reporting import (\n    df_first_look,\n    df_descriptive_statistics,\n    countplot_viz,\n    boxplot_viz,\n    histogram_multiple_viz,\n    countplot_pointplot_viz,\n)\n\n# Calling reporting functions from util_data_cleaning\nfrom util_data_cleaning import (\n    missing_data_finder,\n)\n\n# Calling feature engineering functions from util_feature_engineering\nfrom util_feature_engineering import (\n    calculating_zscore,\n    creating_date_columns,\n)\n\n\"\"\"\n\n%matplotlib inline\nwarnings.filterwarnings(\"ignore\")\n%config Completer.use_jedi = False\n\n# Setting a universal figure size<\nrcParams[\"figure.figsize\"] = 8, 6","57f083cb":"# util_reporting \ndef df_first_look(df):\n    \"\"\"\n    This function gets a Python Pandas dataframe and visualize basic information about the dataframe.\n    :param df: Dataframe to be analyze\n    :return: This function doesn't return anything.\n    \"\"\"\n    try:\n        print(\"First 5 rows of dataframe:\\n--------------------------\\n\", df.head())\n        print(\"\")\n        print(\"Last 5 rows of dataframe:\\n--------------------------\\n\", df.tail())\n        print(\"\")\n        print(\n            \"Row count of dataframe:\\n-----------------------\\n\",\n            df.shape[0],\n            \"\\nColumn count of dataframe:\\n--------------------------\\n\",\n            df.shape[1],\n        )\n        print(\"\")\n        print(\n            \"List of columns in the dataframe:\\n---------------------------------\\n\",\n            df.columns.values,\n        )\n        print(\"\")\n        print(\n            \"Looking NaN values and datatypes of columns in the dataframe:\\n--------------------------------------------\\n\"\n        )\n        print(df.info())\n        print(\"\")\n\n    except Exception as e:\n        print(\"Error at df_first_look function: \", str(e))\n\n\ndef df_descriptive_statistics(df, column_list):\n    \"\"\"\n    This function gets a Python Pandas dataframe and list of columns to visualize descriptive statistics about those columns.\n    :param df: Dataframe to be analyze\n    :param column_list: List of columns to filter out only numeric columns to use in the fuction\"\n    :return: This function doesn't return anything.\n\n    \"\"\"\n    try:\n        dummy_df = df[column_list].copy()\n        print(\n            f\"Descriptive Statisctics for column:\\n--------------------------\\n\",\n            dummy_df.describe(),\n        )\n        print(\"\")\n        print(f\"Mode values for column:\\n--------------------------\\n\", dummy_df.mode())\n        print(\"\")\n    except Exception as e:\n        print(\"Error at df_descriptive_statistics function: \", str(e))\n\n\ndef countplot_viz(\n    data,\n    xcolumn,\n    xlabel,\n    ylabel,\n    title,\n    hue=None,\n    fontsize_label=16,\n    fontsize_title=20,\n    fontsize_text=12,\n    rotation=45,\n    figsize_x=12,\n    figsize_y=5,\n    palette=\"mako\",\n):\n    \"\"\"\n    This function gets a Python Pandas dataframe and visualize a countplot.\n    :param data: Dataframe to be analyze\n    :param xcolumn: This column designates x axis column.\n    :param xlabel: It designates name of x axis column.\n    :param ylabel: It designates name of y axis column.\n    :param title: This column designates name of graph.\n    :param hue: Name of variables in `data` or vector data, optional Inputs for plotting long-form data.\n    :param fontsize_label: It designates label size.\n    :param fontsize_title: It designates title size.\n    :param rotation: It designates rotation of graph.\n    :param palette: It designates colors of graph.\n    :return: This function doesn't return anything.\n\n    \"\"\"\n    plt.figure(figsize=(figsize_x,figsize_y))\n    \n    g = sns.countplot(x=xcolumn, data=data, hue=hue, palette=palette)\n    g.set_title(title, fontsize=19)\n    g.set_xlabel(xlabel, fontsize=17)\n    g.set_ylabel(ylabel, fontsize=17)\n    g.set_xticklabels(g.get_xticklabels(), rotation=40, ha=\"right\")\n    plt.tight_layout()\n    for p in g.patches:\n        height = p.get_height()\n        g.text(\n            p.get_x() + p.get_width() \/ 2.0,\n            height + 3,\n            \"{:1}\".format(height),\n            ha=\"center\",\n            fontsize=fontsize_text,\n        )    \n    if hue != None:\n        g.legend(bbox_to_anchor=(1, 1), loc=1, borderaxespad=0)  \n        \n\ndef countplot_pointplot_viz(\n    data,\n    filter_list,\n    xcolumn,\n    ycolumn,\n    ycolumn_point,\n    xlabel,\n    ylabel,\n    title,\n    hue=None,\n    fontsize_label=16,\n    fontsize_title=20,\n    fontsize_text=12,\n    rotation=45,\n    figsize_x=12,\n    figsize_y=5,\n    palette=\"mako\",\n):\n    \"\"\"\n    This function gets a Python Pandas dataframe and visualize a countplot and a pointplot.\n    :param data: Dataframe to be analyze\n    :param filter_list: It takes conditions for filtering. \n    :param xcolumn: This column designates x axis column.\n    :param ycolumn: This column separetes data by its conditions at countplot. \n    :param ycolumn_point: This column separetes data by its conditions at pointplot. \n    :param xlabel: It designates name of x axis column.\n    :param ylabel: It designates name of y axis column.\n    :param title: This column designates name of graph.\n    :param hue: Name of variables in `data` or vector data, optional Inputs for plotting long-form data.\n    :param fontsize_label: It designates label size.\n    :param fontsize_title: It designates title size.\n    :param rotation: It designates rotation of graph.\n    :param palette: It designates colors of graph.\n    :return: This function doesn't return anything.\n\n    \"\"\"    \n    \n    plt.figure(figsize=(figsize_x,figsize_y)) \n    \n    filter_list = filter_list\n    df2 = data[data[ycolumn].isin(filter_list)]\n    order = df2[xcolumn].value_counts().index\n\n    ax1 = sns.countplot(\n        x=xcolumn, hue=ycolumn, data=df2, hue_order=filter_list, palette=palette\n    )\n    for p in ax1.patches:\n        height = p.get_height()\n        ax1.text(\n            p.get_x() + p.get_width() \/ 2.0,\n            height + 3,\n            \"{:1}\".format(height),\n            ha=\"center\",\n            fontsize=fontsize_text,\n        )\n    ax1.set_title(title, fontsize=19)\n    ax1.set_xlabel(xlabel, fontsize=17)\n    ax1.set_ylabel(ylabel, fontsize=17)\n    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=40, ha=\"right\")\n    \n    ax2 = ax1.twinx()\n    sns.pointplot(x=xcolumn, y=ycolumn_point, data=df2, ax=ax2)\n\ndef boxplot_viz(\n    data,\n    xcolumn,\n    xlabel,\n    title,\n    hue=None,\n    fontsize_label=16,\n    fontsize_title=20,\n    rotation=45,\n    palette=\"mako\",\n):\n    \"\"\"\n    This function gets a Python Pandas dataframe and visualize a countplot.\n    :param data: Dataframe to be analyze\n    :param xcolumn: This column shows x axis column.\n    :param xlabel: It designates name of x axis column.\n    :param ylabel: It designates name of y axis column.\n    :param title: This column designates name of graph.\n    :param hue: Name of variables in `data` or vector data, optional Inputs for plotting long-form data.\n    :param fontsize_label: It designates label size.\n    :param fontsize_title: It designates title size.\n    :param rotation: It designates rotation of graph.\n    :param palette: It designates colors of graph.\n    :return: This function doesn't return anything.\n\n    \"\"\"\n    plt.figure(1, figsize=(9, 6))\n\n    sns.boxplot(x=xcolumn, data=data, hue=hue, palette=palette)\n    plt.xlabel(xlabel, fontsize=fontsize_label) \n    plt.title(title, fontsize=fontsize_title)\n    plt.xticks(rotation=rotation)\n    plt.show()\n\n\n\ndef histogram_multiple_viz(\n    data,\n    column,\n    separate_column,\n    condition_1,\n    condition_2,\n    title1,\n    title2,\n    title3,\n    title4,\n    color1=\"blue\",\n    color2=\"darkorange\",\n):\n    \"\"\"\n    Gets a Python Pandas dataframe and visualize four histograms by a column's conditions and by gets its log.\n    :param data: Dataframe to be analyze\n    :param column: This column is for showing data distribution.\n    :param separate_column: this colum is for creating histogram by a column's conditions.\n    :param condition_1: It designates condition of separate column.\n    :param condition_2: It designates condition of separate column.\n    :param title1: It designates title by graph1.\n    :param title2: It designates title by graph2.\n    :param title3: It designates title by graph3.\n    :param title4: It designates title by graph4.\n    :param color1: It designates color for condition_1.\n    :param color2: It designates color for condition_2.\n    :return: This function doesn't return anything.\n\n    \"\"\"    \n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 6))\n    data.loc[data[separate_column] == condition_1][column].apply(\n        np.log\n    ).plot(\n        kind=\"hist\",\n        bins=100,\n        title=title1,\n        color=color1,\n        xlim=(-3, 10),\n        ax=ax1,\n    )\n    data.loc[data[separate_column] == condition_2][column].apply(\n        np.log\n    ).plot(\n        kind=\"hist\",\n        bins=100,\n        title=title2,\n        color=color2,\n        xlim=(-3, 10),\n        ax=ax2,\n    )\n    data.loc[data[separate_column] == condition_1][column].plot(\n        kind=\"hist\", bins=100, title=title3, color=color1, ax=ax3\n    )\n    data.loc[data[separate_column] == condition_2][column].plot(\n        kind=\"hist\",\n        bins=100,\n        title=title4,\n        color=color2,\n        ax=ax4,\n    )\n    plt.show()     \n    \n","d7e1f5af":"# util_feature_engineering: \ndef calculating_zscore(df, cols):\n    \"\"\"\n    This function gets a Python Pandas dataframe and calculating z score for column list and creating new column to show outlier and non-outlier values as categorical. \n    :param df: Dataframe to be analyze\n    :param cols: The column list for calculating zscore.\n    :return: Returning Python Pandas dataframe.\n    \"\"\"\n    try:\n        df_dummy = df.copy()\n        for col in cols:\n            col_zscore = col + \"_zscore\"\n            df_dummy[col_zscore] = (df_dummy[col] - df_dummy[col].mean()) \/ df_dummy[\n                col\n            ].std(ddof=0)\n            \n            col_zscore_outlier = col_zscore + \"_outlier\"\n        \n            df_dummy[col_zscore_outlier] = np.where(\n        (\n            (df_dummy[col_zscore] > 3)\n            | (df_dummy[col_zscore] < -3)\n        ),\n        \"outlier\",\n        \"non-outlier\",\n    )\n\n\n        return df_dummy\n\n    except Exception as e:\n        print(\"Error at df_first_look function: \", str(e))\n        return df\n\ndef creating_date_columns(df, date_column, START_DATE):\n    \"\"\"\n    This function gets a Python Pandas dataframe and converting time delta date_column to date and creating new columns as date, weekdays, hours and days. \n    :param df: Dataframe to be analyze\n    :param date_column: The column is main date column in dataframe that is time delta. \n    :return: Returning Python Pandas dataframe.\n    \"\"\"\n    startdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")\n    df[\"Date\"] = df[date_column].apply(\n        lambda x: (startdate + datetime.timedelta(seconds=x))\n    )\n\n    df[\"Weekdays\"] = df[\"Date\"].dt.dayofweek\n    df[\"Hours\"] = df[\"Date\"].dt.hour\n    df[\"Days\"] = df[\"Date\"].dt.day","00e80081":"# util_data_cleaning: \n    \ndef missing_data_finder(df):\n    \"\"\"\n    This function gets a Python Pandas dataframe and finding missing values and showing these percentages in the column of the dataframe \n    :param df: Dataframe to be analyze     \n    :return: This function doesn't return anything.  \n    \n    \"\"\"\n    df_missing = df.isnull().sum().reset_index().rename(columns={'index': 'column_name', 0: 'missing_row_count'}).copy()\n    df_missing_rows = df_missing[df_missing['missing_row_count'] > 0].sort_values(by='missing_row_count',ascending=False)\n    df_missing_rows['missing_row_percent'] = (df_missing_rows['missing_row_count'] \/ df.shape[0]).round(4)\n    return df_missing_rows","cb5bf65c":"import os\nprint(os.listdir(\"..\/input\/ieee-fraud-detection\"))","74edd73b":"# Transaction CSVs\ntrain_transaction = pd.read_csv(\"..\/input\/ieee-fraud-detection\/train_transaction.csv\")\ntest_transaction = pd.read_csv(\"..\/input\/ieee-fraud-detection\/test_transaction.csv\")\n# Identity CSVs - These will be merged onto the transactions to create additional features\ntrain_identity = pd.read_csv(\"..\/input\/ieee-fraud-detection\/train_identity.csv\")\ntest_identity = pd.read_csv(\"..\/input\/ieee-fraud-detection\/test_identity.csv\")\n# Sample Submissions\nsample_submission = pd.read_csv(\"..\/input\/ieee-fraud-detection\/sample_submission.csv\")","815172d7":"df_first_look(train_transaction)","531c05c5":"df_first_look(train_identity)","098df2fd":"df_first_look(test_transaction)","ed04e140":"df_first_look(test_identity)","5707ca9c":"# To see, how many TransactionIDs in train_transaction have an associated train_identity.\nprint(\n    np.sum(\n        train_transaction[\"TransactionID\"].isin(\n            train_identity[\"TransactionID\"].unique()\n        )\n    )\n)","c2c4ebd0":"missing_data_finder(train_transaction).head()","87a0ae46":"missing_data_finder(test_transaction).head()","68e8e348":"train_transaction[\"isFraud_\"] = np.where(\n    train_transaction[\"isFraud\"] == 1, \"Fraud\", \"Non-Fraud\"\n)","3b461d48":"train_transaction[\"isFraud_\"].value_counts()","5c234c7e":"train_transaction.ProductCD.value_counts()","00ee9f1f":"countplot_viz(\n    train_transaction,\n    \"ProductCD\",\n    \"Transactions Product Code\",\n    \"Freq\",\n    \"Product Code Distribution\",\n    palette=\"rocket_r\",\n)","b9b3cd13":"card_cols = [c for c in train_transaction.columns if \"card\" in c]\ntrain_transaction[card_cols].head(3)","2d383c97":"# For card4:\ncountplot_viz(\n    train_transaction,\n    \"card4\",\n    \"Card Distributers\",\n    \"Freq\",\n    \"Card Distributer Types Distribution\",\n    palette=\"rocket_r\",\n)","f1b4f933":"# For card6:\ncountplot_viz(\n    train_transaction,\n    \"card6\",\n    \"Card Types\",\n    \"Freq\",\n    \"Card Types Distribution\",\n    palette=\"rocket_r\",\n)","13a75838":"# Unique count of Regions:\ntrain_transaction.addr1.nunique()","5bf6d245":"# To find top 10 regions by count of transaction.\naddr1_df = pd.DataFrame(train_transaction.addr1.value_counts())\naddr1_df = addr1_df.rename_axis(\"region\").reset_index()\naddr1_df = addr1_df.sort_values(by=[\"addr1\"], ascending=False).head(10)\ntop_region_df = train_transaction[\n    train_transaction[\"addr1\"].isin(list(addr1_df[\"region\"]))\n]","c2cd81e3":"countplot_viz(\n    top_region_df,\n    \"addr1\",\n    \"Transaction Regions\",\n    \"Freq\",\n    \"Regions Distribution\",\n    palette=\"rocket\",\n)","cd4b7e98":"# Unique count of Country:\ntrain_transaction.addr2.nunique()","c7fe8104":"# To find top 5 countries by count of transaction.\naddr2_df = pd.DataFrame(train_transaction.addr2.value_counts())\naddr2_df = addr2_df.rename_axis(\"country\").reset_index()\naddr2_df = addr2_df.sort_values(by=[\"addr2\"], ascending=False).head()\ntop_country_df = train_transaction[\n    train_transaction[\"addr2\"].isin(list(addr2_df[\"country\"]))\n]","ed1b8f8d":"countplot_viz(\n    top_country_df,\n    \"addr2\",\n    \"Transaction Countries\",\n    \"Freq\",\n    \"Country Distribution\",\n    palette=\"rocket_r\",\n)","a25939a9":"P_email_df = pd.DataFrame(train_transaction.P_emaildomain.value_counts())\nP_email_df = P_email_df.rename_axis(\"email\").reset_index()\nP_email_df = P_email_df[P_email_df[\"P_emaildomain\"] > 1000]\nPemail_df = train_transaction[\n    train_transaction[\"P_emaildomain\"].isin(list(P_email_df[\"email\"]))\n]","2faf2b42":"countplot_viz(\n    data=Pemail_df,\n    xcolumn=\"P_emaildomain\",\n    xlabel=\"P_Email Domains\",\n    ylabel=\"Freq\",\n    title=\"P_Email Domain Distribution\",\n    palette=\"rocket\",\n    fontsize_text=9,\n)","46f70632":"R_email_df = pd.DataFrame(train_transaction.R_emaildomain.value_counts())\nR_email_df = R_email_df.rename_axis(\"email\").reset_index()\nR_email_df = R_email_df[R_email_df[\"R_emaildomain\"] > 1000]\nRemail_df = train_transaction[\n    train_transaction[\"R_emaildomain\"].isin(list(R_email_df[\"email\"]))\n]","698ad976":"countplot_viz(\n    data=Remail_df,\n    xcolumn=\"R_emaildomain\",\n    xlabel=\"R_Email Domains\",\n    ylabel=\"Freq\",\n    title=\"R_Email Domain Distribution\",\n    palette=\"rocket\",\n)","dfcdd41e":"M_cols = [m for m in train_transaction.columns if \"M\" in m]\ntrain_transaction[M_cols].head(3)","e1a1abdc":"train_transaction.M4.value_counts()","1354bb81":"for col in [\"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"M8\", \"M9\"]:\n    countplot_viz(\n        train_transaction,\n        col,\n        col,\n        \"Freq\",\n        \"Distribution of \" + col,\n        palette=\"rocket\",\n        fontsize_label=11,\n        fontsize_title=15,\n        figsize_x=12,\n        figsize_y=2,\n    )","081f8677":"list_of_column_descriptive = [\"TransactionAmt\"]\ndf_descriptive_statistics(train_transaction, list_of_column_descriptive)","221e65d4":"boxplot_viz(\n    train_transaction,\n    \"TransactionAmt\",\n    xlabel=\"TransactionAmt\",\n    title=\"Boxplot of TransactionAmt\",\n)","7c145092":"cols = [\"TransactionAmt\"]\ntrain_transaction = calculating_zscore(train_transaction, cols)","99c4fb04":"# Total outlier and non-outlier count:\n\ntrain_transaction[\"TransactionAmt_zscore_outlier\"].value_counts()","4e9f2267":"train_transaction[\n    [\n        \"C1\",\n        \"C2\",\n        \"C3\",\n        \"C4\",\n        \"C5\",\n        \"C6\",\n        \"C7\",\n        \"C8\",\n        \"C9\",\n        \"C10\",\n        \"C11\",\n        \"C12\",\n        \"C13\",\n        \"C14\",\n    ]\n].describe()","a2bca141":"train_transaction[\"TransactionDT\"].plot(\n    kind=\"hist\",\n    figsize=(15, 5),\n    label=\"train\",\n    bins=50,\n    title=\"Train vs Test TransactionDT Distribution\",\n)\ntest_transaction[\"TransactionDT\"].plot(kind=\"hist\", label=\"test\", bins=50)\nplt.legend()","d527cf34":"creating_date_columns(train_transaction, \"TransactionDT\", START_DATE=\"2017-12-01\")\ntrain_transaction.head(3)","a08bf39d":"train_transaction.isFraud_.value_counts()","b1c295c9":"countplot_viz(\n    train_transaction,\n    \"isFraud_\",\n    \"isFraud\",\n    \"Freq\",\n    \"isFraud Distribution\",\n    palette=\"rocket_r\",\n    figsize_x=12,\n    figsize_y=4,\n)","8310043d":"pd.crosstab(\n    train_transaction.isFraud_, train_transaction.ProductCD, margins=True\n).style.background_gradient(cmap=\"mako\")","258a410b":"filter_list = [\"Fraud\", \"Non-Fraud\"]\ncountplot_pointplot_viz(\n    train_transaction,\n    filter_list,\n    \"ProductCD\",\n    \"isFraud_\",\n    \"isFraud\",\n    \"Product Codes\",\n    \"Freq\",\n    \"ProductCD & isFraud\",\n    palette=\"rocket\",\n)","f7bfcf48":"pd.crosstab(\n    train_transaction.isFraud_, train_transaction.card4, margins=True\n).style.background_gradient(cmap=\"mako\")","66fb71dc":"filter_list = [\"Fraud\", \"Non-Fraud\"]\ncountplot_pointplot_viz(\n    train_transaction,\n    filter_list,\n    \"card4\",\n    \"isFraud_\",\n    \"isFraud\",\n    \"Credit Card Distributors\",\n    \"Freq\",\n    \"Distributors & isFraud\",\n    palette=\"rocket\",\n)","cca8ce70":"pd.crosstab(\n    train_transaction.isFraud_, train_transaction.card6, margins=True\n).style.background_gradient(cmap=\"mako\")","5063509c":"filter_list = [\"Fraud\", \"Non-Fraud\"]\ncountplot_pointplot_viz(\n    train_transaction,\n    filter_list,\n    \"card6\",\n    \"isFraud_\",\n    \"isFraud\",\n    \"Card Types\",\n    \"Freq\",\n    \"Card Types & isFraud\",\n    palette=\"rocket\",\n)","520f6480":"filter_list = [\"Fraud\", \"Non-Fraud\"]\ncountplot_pointplot_viz(\n    top_region_df,\n    filter_list,\n    \"addr1\",\n    \"isFraud_\",\n    \"isFraud\",\n    \"Regions\",\n    \"Freq\",\n    \"Regions & isFraud\",\n    palette=\"rocket\",\n)","3734bba4":"filter_list = [\"Fraud\", \"Non-Fraud\"]\ncountplot_pointplot_viz(\n    top_country_df,\n    filter_list,\n    \"addr2\",\n    \"isFraud_\",\n    \"isFraud\",\n    \"Countries\",\n    \"Freq\",\n    \"Countries & isFraud\",\n    palette=\"rocket\",\n)","294025cd":"filter_list = [\"Fraud\", \"Non-Fraud\"]\ncountplot_pointplot_viz(\n    Pemail_df,\n    filter_list,\n    \"P_emaildomain\",\n    \"isFraud_\",\n    \"isFraud\",\n    \"Purchaser Email Domain\",\n    \"Freq\",\n    \"Purchaser Email Domain & isFraud\",\n    fontsize_text=9,\n    palette=\"rocket\",\n)","47802244":"filter_list = [\"Fraud\", \"Non-Fraud\"]\ncountplot_pointplot_viz(\n    Remail_df,\n    filter_list,\n    \"R_emaildomain\",\n    \"isFraud_\",\n    \"isFraud\",\n    \"Recipient Email Domain\",\n    \"Freq\",\n    \"Recipient Email Domain & isFraud\",\n    fontsize_text=9,\n    palette=\"rocket\",\n)","2f42158f":"for col in [\"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"M8\", \"M9\"]:\n    filter_list = [\"Fraud\", \"Non-Fraud\"]\n    countplot_pointplot_viz(\n        train_transaction,\n        filter_list,\n        col,\n        \"isFraud_\",\n        \"isFraud\",\n        col,\n        \"Freq\",\n        \"isFraud & \" + col,\n        fontsize_text=9,\n        fontsize_title=15,\n        figsize_x=12,\n        figsize_y=3,\n        palette=\"rocket\",\n    )","7628c062":"train_transaction.loc[\n    train_transaction.C1.isin(\n        train_transaction.C1.value_counts()[\n            train_transaction.C1.value_counts() <= 600\n        ].index\n    ),\n    \"C1\",\n] = \"Others\"","d87aab43":"filter_list = [\"Fraud\", \"Non-Fraud\"]\ncountplot_pointplot_viz(\n    train_transaction,\n    filter_list,\n    \"C1\",\n    \"isFraud_\",\n    \"isFraud\",\n    \"C1\",\n    \"Freq\",\n    \"C1 & isFraud\",\n    fontsize_text=8,\n    palette=\"rocket\",\n    figsize_x=15,\n    figsize_y=5,\n)","365b9228":"train_transaction.loc[\n    train_transaction.C2.isin(\n        train_transaction.C2.value_counts()[\n            train_transaction.C2.value_counts() <= 600\n        ].index\n    ),\n    \"C2\",\n] = \"Others\"","7bb11aee":"filter_list = [\"Fraud\", \"Non-Fraud\"]\ncountplot_pointplot_viz(\n    train_transaction,\n    filter_list,\n    \"C2\",\n    \"isFraud_\",\n    \"isFraud\",\n    \"C2\",\n    \"Freq\",\n    \"C2 & isFraud\",\n    fontsize_text=8,\n    palette=\"rocket\",\n    figsize_x=15,\n    figsize_y=5,\n)","66837eda":"histogram_multiple_viz(\n    train_transaction,\n    \"TransactionAmt\",\n    \"isFraud_\",\n    \"Fraud\",\n    \"Non-Fraud\",\n    \"Log Transaction Amt - Fraud\",\n    \"Log Transaction Amt - Not Fraud\",\n    \"Transaction Amt - Fraud\",\n    \"Transaction Amt - Not Fraud\",\n    color1=\"skyblue\",\n    color2=\"tomato\",\n)","0179ad80":"# For seeing weekdays fraud situations:\nfilter_list = [\"Fraud\", \"Non-Fraud\"]\ncountplot_pointplot_viz(\n    train_transaction,\n    filter_list,\n    \"Weekdays\",\n    \"isFraud_\",\n    \"isFraud\",\n    \"Weekdays\",\n    \"Freq\",\n    \"Weekdays & isFraud\",\n    fontsize_text=9,\n    palette=\"rocket\",\n)","d5b8d696":"# For seeing hours fraud situations:\nfilter_list = [\"Fraud\", \"Non-Fraud\"]\ncountplot_pointplot_viz(\n    train_transaction,\n    filter_list,\n    \"Hours\",\n    \"isFraud_\",\n    \"isFraud\",\n    \"Hours\",\n    \"Freq\",\n    \"Hours & isFraud\",\n    fontsize_text=9,\n    palette=\"rocket\",\n)","18d2aa68":"# For seeing hours fraud situations:\nfilter_list = [\"Fraud\", \"Non-Fraud\"]\ncountplot_pointplot_viz(\n    train_transaction,\n    filter_list,\n    \"Days\",\n    \"isFraud_\",\n    \"isFraud\",\n    \"Days\",\n    \"Freq\",\n    \"Days & isFraud\",\n    fontsize_text=9,\n    palette=\"rocket\",\n)","b740e83b":"# For fraudulent activities:\nfraud_ts = train_transaction.copy()\nfraud_ts.set_index(\"Date\", inplace=True)\nfraud_ts_week = (\n    fraud_ts[fraud_ts[\"isFraud_\"] == \"Fraud\"][\"TransactionAmt\"].resample(\"W\").apply(sum)\n)\nfraud_ts_week.plot(\n    marker=\"o\",\n    markerfacecolor=\"blue\",\n    markersize=12,\n    color=\"skyblue\",\n    title=\"Weekly Total Fraud Transaction Amount\",\n    xlabel=\"Week of Transaction\",\n    ylabel=\"Total Amount\",\n)\nplt.show()","a44c6a1f":"# For Non-Fraud activities:\nfraud_ts = train_transaction.copy()\nfraud_ts.set_index(\"Date\", inplace=True)\nfraud_ts_week = (\n    fraud_ts[fraud_ts[\"isFraud_\"] == \"Non-Fraud\"][\"TransactionAmt\"]\n    .resample(\"W\")\n    .apply(sum)\n)\nfraud_ts_week.plot(\n    marker=\"o\",\n    markerfacecolor=\"blue\",\n    markersize=12,\n    color=\"skyblue\",\n    title=\"Weekly Total Non-Fraud Transaction Amount\",\n    xlabel=\"Week of Transaction\",\n    ylabel=\"Total Amount\",\n)\nplt.show()","b9d6d684":"## Bivariate Relationships:\n### ProductCD & isFraud: ","fe92f9c4":"\n* I called `countplot_pointplot_viz` from `util_reporting.py`.\n* This function does;\n    * Gets a Python Pandas dataframe and visualize a countplot and a pointplot. ","35051709":"##### How to Read The Graph: \n* This graph shows boxplot of the TransactionAmt column. \n* `The minimum` (the smallest number in the data set). The minimum is shown at the far left of the chart, at the end of the left \u201cwhisker.\u201d\n* `First quartile`, Q1, is the far left of the box (or the far right of the left whisker).\n* `The median` is shown as a line in the center of the box.\n* `Third quartile`, Q3, shown at the far right of the box (at the far left of the right whisker).\n* `The maximum` (the largest number in the data set), shown at the far right of the box.\n* Data sets can sometimes contain `outliers` that are suspected to be anomalies (perhaps because of data collection errors or just plain old flukes). If outliers are present, the whisker on the appropriate side is drawn to 1.5 * IQR rather than the data minimum or the data maximum. Small circles or unfilled dots are drawn on the chart to indicate where suspected outliers lie. Filled circles are used for known outliers.","3f48707d":"##### Observations: \n* 1.0, 2.0, 3.0 have most of the transactions. \n* 15.0, 16.0, 17.0 have most fraud transaction rates. \n* The most fraud transaction rate belongs to 16.0. \n* The most fraud transaction count belongs to 1.0. ","90e2d6f4":"### M1- M9:\n* `Definition:` They show match, such as names on card and address, etc.\n* `Categories & Labels:` T = True, F= False, NaN values\n* `Categories & Labels for M4:` M0, M1, M2","32f64b43":"# IEEE-CIS Fraud Detection Data Set:\n* Why Fraud Detection? \n    * Fraud detection is a set of activities undertaken to prevent money or property from being obtained through false pretenses. Fraud detection is applied to many industries such as banking or insurance. In banking, fraud may include forging checks or using stolen credit cards. \n* This competition is a binary classification problem - i.e. our target variable is a binary attribute (Is the user making the click fraudulent or not?) and our goal is to classify users into \"fraudulent\" or \"not fraudulent\" as well as possible. \n\nIn this kernel I did deep dive Exploratory Data Analysis(EDA) on The IEEE-CIS Fraud Detection dataset to understand patterns of fraudulent transactions. Don\u2019t forget to upvote if you find this kernel helpful. I suggest you also read the complete dataset overview and data description found in IEEE-CIS Fraud Detection page. https:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/overview \n\nI intentionally share all of my code. My aim is to have a good EDA code base that will minimise the development process for the next projects at the backlog.\n\nYou can glance at my util function notebooks to have an idea how i eased the EDA process at my GitHub page. https:\/\/github.com\/ElifKarakutukDinc\/IEEE-CIS-Fraud-Detection ","04121c28":"##### How to Read The Graph: \n* Countplot shows the count of fraud and non-fraud transactions by addr1(Regions).   \n* Pointplot shows the percentage of fraud in all transactions of regions. \n* x column shows regions.\n* y column shows; \n    * Count of regions by isFraud_ column.\n    * Percentage of fraud in all transactions of regions.","5bec3fd1":"* I called `countplot_pointplot_viz` from `util_reporting.py`.\n* This function does;\n    * Gets a Python Pandas dataframe and visualize a countplot and a pointplot. ","6d050be2":"* I called `countplot_pointplot_viz` from `util_reporting.py`.\n* This function does;\n    * Gets a Python Pandas dataframe and visualize a countplot and a pointplot. ","8f9d3142":"##### Observation:\n* We changed categorical names as Fraud and Non-Fraud.\n* Count of Non-Fraud transaction more than count of Fraud transaction. ","bd5b62f9":"##### Observation:\n* As I said before, M5, M6, M7, M8 have higher false matching than true matching. In these matching columns;\n    * Fraud activities of M5 and M7 belong to \"true matching\". \n    * Fraud activities of M6 and M8 belong to \"false matching\". We can say for M6 and M8, if there is no matching this transaction would be fraud. \n* In M1, M2, M3, M4, M9 matching columns;\n    * Fraud activities of M1 \"true matching\".\n    * Fraud activities of M2, M3 and M9 belong to \"false matching\".  We can say for M6 and M8, if there is no matching this transaction would be fraud.\n    * M4 has different matching conditions like M0, M1, M2. Most transactions belong to \"M0\". Fraud activities of M4 belong to \"M2\". ","65e7d850":"##### Observation:\n* The most of transactions belong to \"gmail.com\".  \n* From the point of view of fraud transaction rate \"outlook.com\" has the highest fraudulent activities. ","da5d2518":"##### Observation:\n* Most of transactions belong 299th region.  \n* From the point of view of fraud transaction rate 330th, 272th, 204th have high fraudulent activities. ","14a88444":"##### Observation:\n* Most of the transactions belong to \"gmail.com\". \n* From the point of view of fraud transaction rate \"outlook.com\" and \"icloud.com\" have the highest fraudulent activities. ","bfbe3faa":"##### Observation:\n* The data is masked so we are not reviewing these columns. However, we'll look at the relationship between some of these columns and the isFraud column at the below cells.","c3e56884":"### C1-C14: \n* `Definition:` Counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked.","d65ba1b4":"* I called `countplot_pointplot_viz` from `util_reporting.py`.\n* This function does;\n    * Gets a Python Pandas dataframe and visualize a countplot and a pointplot. ","f602219e":"* I called `countplot_pointplot_viz` from `util_reporting.py`.\n* This function does;\n    * Gets a Python Pandas dataframe and visualize a countplot and a pointplot. ","9cf9a0ba":"* I called `countplot_pointplot_viz` from `util_reporting.py`.\n* This function does;\n    * Gets a Python Pandas dataframe and visualize a countplot and a pointplot. ","08b8da9d":"##### How to Read The Graph: \n* These graphs show the count of matching. \n* x column shows M situations, y column shows counts of matching situations.","8564e931":"##### How to Read The Graph: \n* Countplot shows count of fraud and non-fraud transactions by product codes.   \n* Pointplot shows the percentage of fraud in all transaction of Product Codes. \n* x column shows product codes.\n* y column shows; \n    * Counts of product codes by isFraud_ column.\n    * Percentage of fraud in all transactions of Product Codes.","2de2ba28":"* We can only describe card4 and card6 in all these columns. ","1c8c3a88":"### The First Looking to Data Set:\n* I called `df_first_look` from `util_reporting.py`. \n* This function returns;\n    * First 5 rows of dataframe\n    * Last 5 rows of dataframe\n    * Row count of dataframe\n    * Column count of dataframe\n    * List of columns in the dataframe\n    * Looking NaN values and datatypes of columns in the dataframe","16b61981":"* I called `histogram_multiple_viz` from `util_reporting.py`.\n* This function does;\n    * Gets a Python Pandas dataframe and visualize four histograms by a column's conditions and by gets its log. ","d470b24a":"* I called `countplot_pointplot_viz` from `util_reporting.py`.\n* This function does;\n    * Gets a Python Pandas dataframe and visualize a countplot and a pointplot. ","c34a43df":"* I called `creating_date_columns` from `util_feature_engineering.py`.\n* This function does;\n    * Gets a Python Pandas dataframe and converting time delta date_column to date and creating new columns as date, weekdays, hours and days. ","d087e603":"## Data Understanding & Wrangling:\n### Transaction Table \n    * TransactionDT: timedelta from a given reference datetime (not an actual timestamp)\n    * TransactionAMT: transaction payment amount in USD\n    * ProductCD: product code, the product for each transaction\n    * card1 - card6: payment card information, such as card type, card category, issue bank, country, etc.\n    * addr: address\n    * dist: distance\n    * P_ and (R__) emaildomain: purchaser and recipient email domain\n    * C1-C14: counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked.\n    * D1-D15: timedelta, such as days between previous transaction, etc.\n    * M1-M9: match, such as names on card and address, etc.\n    * Vxxx: Vesta engineered rich features, including ranking, counting, and other entity relations.\n#### Categorical Features:\n    * ProductCD\n    * card1 - card6\n    * addr1, addr2\n    * P_emaildomain\n    * R_emaildomain\n    * M1 - M9\n\n### Identity Table\n    * Variables in this table are identity information \u2013 network connection information (IP, ISP, Proxy, etc) and digital signature (UA\/browser\/os\/version, etc) associated with transactions.\n    * They're collected by Vesta\u2019s fraud protection system and digital security partners.\n    * (The field names are masked and pairwise dictionary will not be provided for privacy protection and contract agreement)\n\n    * \u201cid01 to id11 are numerical features for identity, which is collected by Vesta and security partners such as device rating, ip_domain rating, proxy rating, etc. Also it recorded behavioral fingerprint like account login times\/failed to login times, how long an account stayed on the page, etc. All of these are not able to elaborate due to security partner T&C. I hope you could get basic meaning of these features, and by mentioning them as numerical\/categorical, you won't deal with them inappropriately.\u201d\n    \n#### Categorical Features:\n    * DeviceType\n    * DeviceInfo\n    * id_12 - id_38   ","7175c5bb":"### R_emaildomain: \n* `Definition:` They show recipient email domain. Certain transactions don't need recipient, so R_emaildomain is null.\n* I will group all email domains by the respective enterprises.\n* Also, I won't include less than 1000 entries in analysis.","b8de0702":"##### Observations: \n* The busy hours by transaction count are late evening hours. \n* The busy hours by fraud transaction rate are early evening hours like 5am, 6am, 7am, 8am and 9am. \n* The most fraudulent transaction rate belong to 7am. \n* The most fraudulent transaction count belongs to 23pm. ","3ece3c7e":"##### How to Read The Graph: \n* This graph shows the count of Card Types. \n* x column shows card types, y column shows counts of card types.","00cf6b1f":"### TransactionAmt & isFraud: ","39ac5a2f":"* The IsFraud column has two categories: 0 and 1. Since this column is coded numerically it is not easy to understand which value is equal to which label. So I'm coding new values: `1 = \"Fraud\", 0 = \"Non-Fraud\"`. ","9d6e2f75":"## Understanding Variables:\n### Categorical Features:","bebe88a1":"##### How to Read The Graph: \n* Countplot shows the count of fraud and non-fraud transactions by hours of day.   \n* Pointplot shows the percentage of fraud in hours of day's all transactions. \n* x column shows hours of day.\n* y column shows; \n    * Count of hours of day by isFraud_ column.\n    * Percentage of fraud in hours of day's all transactions.","2277bc67":"##### How to Read The Graph: \n* Countplot shows the count of fraud and non-fraud transactions by days of month.   \n* Pointplot shows the percentage of fraud in days of month's all transactions. \n* x column shows weekdays.\n* y column shows; \n    * Count of days of month by isFraud_ column.\n    * Percentage of fraud in days of month's all transactions.","9c41bd79":"##### Observation:\n* Transactions that were done with Gmail and Outlook have the most count.","8e5970f3":"##### How to Read The Graph: \n* Countplot shows the count of fraud and non-fraud transactions by R_emaildomain(Recipient Email Domain).   \n* Pointplot shows the percentage of fraud in all transactions of Recipient Email Domain. \n* x column shows Recipient Email Domain.\n* y column shows; \n    * Count of Recipient Email Domain by isFraud_ column.\n    * Percentage of fraud in all transactions of Recipient Email Domain.","0bf2aff6":"# Exploratory Data Analysis(EDA) \nExploratory Data Analysis refers to the critical process of performing initial investigations on data so as to discover patterns,to spot anomalies,to test hypotheses and to check assumptions with the help of summary statistics and graphical representations.\n\n* To take a closer look at the data take help of the '.head()` function of pandas library which returns the first five observations of the data set.Similarly `.tail()` returns the last five observations of the data set.\n* To find out the total number of rows and columns in the data set using `.shape`.\n* To see label of each columns in the data set using `.columns.values`\n* It is also a good practice to know the columns and their corresponding data types,along with finding whether they contain null values or not with `.info()`\n* The `.describe()` function in pandas is very handy in getting various summary statistics.This function returns the count, mean, standard deviation, minimum and maximum values and the quantiles of the data.\n* Few key insights just by looking at dependent variable are as follows:\n    * `.unique()`\n    * `.value_counts()`\n* To check missing values in the data set's columns using `.isnull().sum()`\n* To check `Outliers`: `A box plot` (or box-and-whisker plot) shows the distribution of quantitative data in a way that facilitates comparisons between variables.The box shows the quartiles of the dataset while the whiskers extend to show the rest of the distribution.\n* To check `the linearity of the variables` it is a good practice to `plot distribution graph` and look for skewness of features. Kernel density estimate (kde) is a quite useful tool for plotting the shape of a distribution.","df3a351c":"##### How to Read The Graph: \n* Countplot shows the count of fraud and non-fraud transactions by C2 column.   \n* Pointplot shows percentage of fraud in all transactions of C2 column. \n* x column shows C2 column's situations.\n* y column shows; \n    * Count of C2 column by isFraud_ column.\n    * Percentage of fraud in all transactions of C2 column.","76201c2a":"### R_emaildomain & isFraud:","471d5be5":"## Multivariate Relationships:\n### TransactionAmt- TransactionDT & isFraud:","2c18a4b0":"* I called `countplot_pointplot_viz` from `util_reporting.py`.\n* This function does;\n    * Gets a Python Pandas dataframe and visualize a countplot and a pointplot. ","fe754948":"### Uploading data sets:","a8fe2bdf":"##### How to Read The Graph:  \n* These graphs show distributions of Fraud and Non-Fraud transactions. First two graphs which are at above show log histogram of transactionAmt by isFraud column. Last two graphs which are at below show histogram of transactionAmt by isFraud column.","525aac24":"### Card1-Card6 & isFraud: ","08ac32a9":"##### How to Read The Graph: \n* This graph shows the count of Card Distributor Types. \n* x column shows Card Distributors, y column shows counts of Card Distributors.","d02d93c4":"### M1-M9 & isFraud:","637c9e13":"##### Observation:\n* Most of the transactions were done with \"debit\". The second most of the transactions were done with \"credit card\". \n* In total transactions of credit card, fraudulent transactions' rate is 0,066%. This rate is highest rate in all card types. Due to that result we can say that \"credit card\" is more open to fraudulent activities than other distributors. ","08f5039b":"##### How to Read The Graph: \n* Countplot shows the count of fraud and non-fraud transactions by weekdays.   \n* Pointplot shows the percentage of fraud in all transactions of weekdays. \n* x column shows weekdays.\n* y column shows; \n    * Count of weekdays by isFraud_ column.\n    * Percentage of fraud in all transactions on weekdays.\n* 1 = Monday, 2 = Tuesday, 3 = Wednesday, 4 = Thursday, 5 = Friday, 6 = Saturday 0 = Sunday   ","94fd9f08":"* To find outliers in the dataset we can use two different ways:  \n    * To see whether there are outliers we visualize a Boxplot.\n    * To find frequency of |z-score| > 3 transaction amounts. It gives us the count of outliers. ","0d2c161d":"##### How to Read The Graph: \n* Countplot shows the count of fraud and non-fraud transactions by card4.   \n* Pointplot shows the percentage of fraud in all transactions of Credit Card Distributors. \n* x column shows Credit Card Distributors.\n* y column shows; \n    * Counts of Credit Card Distributors by isFraud_ column.\n    * Percentage of fraud in all transactions of Credit Card Distributors.","74979238":"* 24.4% of TransactionIDs in the train have an associated train_identity. There is no enough associated transactionID to built the relationship between the identity table's columns and isFraud column of the transaction table.","0aeaea6e":"##### Observations: \n* The busy days by fraud transaction rate belong 1st, 29th, 31th, days of the month.\n* The most fraudulent transaction rate belong to 31th day of the month. \n* The most fraud transaction counts belong to the 3rd day of the month. ","344ecce7":"* I called `missing_data_finder` from `util_data_cleaning.py`. \n* This function returns;\n    * Finding missing values and showing these percentages in the columns of the dataframe. ","68bee9f2":"##### Observation:\n* Most of transaction belong \"W\" product code. \n* The most fraudulent activities belong to the \"C\" product code with 11,5%.","bb342945":"### P_emaildomain: \n* `Definition:` They show purchaser email domain.\n* I will group all email domains by the respective enterprises.\n* Also, I won't include less than 1000 entries in analysis.","ec50fd21":"##### How to Read The Graph: \n* This graph shows the count of transaction's email domains. \n* x column shows email domains, y column shows counts of email domain transactions.","1421d644":"### Card4 & isFraud:","533ff61a":"* I called `countplot_pointplot_viz` from `util_reporting.py`.\n* This function does;\n    * Gets a Python Pandas dataframe and visualize a countplot and a pointplot. ","ce06d763":"##### Observation:\n* We converted the TransactionDT column. We'll use these columns at \"Bivariate Relationships\".","43fbca3e":"##### How to Read The Graph: \n* Countplot shows the count of fraud and non-fraud transactions by addr2(Countries).   \n* Pointplot shows the percentage of fraud in all transactions of countries. \n* x column shows countries.\n* y column shows; \n    * Count of countries by isFraud_ column.\n    * Percentage of fraud in all transactions of countries.","5745a689":"##### How to Read The Graph: \n* This graph shows count of fraud and non-fraud transactions. \n* x column shows fraud situations, y column shows counts of fraud situations.","f727d834":"* I called `df_descriptive_statistics` from `util_reporting.py`.\n* This function does;\n    * Gets a Python Pandas dataframe and list of columns to visualize descriptive statistics about those columns.","fff5ca17":"### P_emaildomain & isFraud:","81fd7926":"##### How to Read The Graph: \n* This graph shows the count of transaction's email domains. \n* x column shows email domains, y column shows counts of email domain transactions.","ff93480b":"### TransactionDT & isFraud: ","14ba23cd":"* Data sets contain Float, integer and object types of data.\n* All data sets contain null\/missing values. ","7a8c292d":"##### Observation:\n* M5, M6, M7, M8 have high false matching than true matching. We don't know what they represent. We'll look at whether false matching has fraud activities. ","63d43b7c":"### addr1:","7d57105c":"##### How to Read The Graph: \n* These graphs show distributions of transactionDT for test dataset and train dataset. ","10bc1d8c":"* To Calculate The z_score Column:\n    * I called `calculating_zscore` from `util_feature_engineering.py`.\n    * This function does;\n        * This function calculating z score for column list. \n        * Creating new column to show outlier and non-outlier values as categorical. ","6b311ec1":"### Numerical Features:\n### TransactionAmt:","db593099":"##### How to Read The Graph: \n* Countplot shows the count of fraud and non-fraud transactions by card6.   \n* Pointplot shows percentage of fraud in all transactions of card types. \n* x column shows card types.\n* y column shows; \n    * Counts of card types by isFraud_ column.\n    * Percentage of fraud in all transaction of card types.","e84f040f":"##### Observation:\n* Count of product code W more than count of other codes. ","52708621":"* The most of transactions were done with \"visa\". The second most of transactions were done with \"mastercard\". Because of the fraudulent transaction counts of these distributors are higher than others. But we should look that how much fraud there is in all transaction of these distributors. (as rate) \n    * In total transactions of visa, fraudulent transactions' percentage is 0,034. \n    * In total transactions of mastercard, fraudulent transactions' percentage is 0,034. \n    * In total transactions of discovery, fraudulent transactions' percentage is 0,077. \n    * In total transactions of american express, fraudulent transactions' percentage is 0,028. \n* Due to above results we can say that \"discover\" is more open to fraudulent activities than other distributors. ","e214fbfa":"* `Definition:` Timedelta from a given reference datetime (not an actual timestamp)","0855a33e":"### Changing Categorical Column's Values: \n### IsFraud Column:","34480974":"### Understanding Target Variable\n### isFraud Column\n* `Definition:` It shows fraud situation of transactions.  \n* `Categories & Labels:` 0 = Non-Fraud, 1 = Fraud.\n* I created \"isFraud_\" column for showing the column as categorical names. I'll use it to show bivariate relationships. ","8c77b132":"##### How to Read The Graph: \n* Countplot shows the count of fraud and non-fraud transactions by C1 column.   \n* Pointplot shows percentage of fraud in all transactions of C1 column. \n* x column shows C1 column's situations.\n* y column shows; \n    * Count of C1 column by isFraud_ column.\n    * Percentage of fraud in all transactions of C1 column.","cbd733e6":"##### Observation:\n* There are 3.4% Fraud transactions in the dataset.\n* 3.4% seems small in all data but it can be changed if the amount percentage is higher or lower than 3.5% of total. We'll see it later.","bce56c52":"##### Observations: \n* First days of week mostly include non-fraud activities than fraud activities. The minimum amount of fraud activities belongs to \"Monday\". \n* 4 = Thursday, 5 = Friday, 6 = Saturday 0 = Sunday mostly include fraud activities than non-fraud activities. ","901d394e":"### C1-C14 & isFraud:","e748adc8":"### addr2:","753cd201":"### To Check Missing Values:","7dc49e07":"##### Observation:\n* Transactions that were done with Gmail and Hotmail have the most count. \n* At here most second transaction count belongs to Hotmail but at P_emaildomain most second transaction count belongs to Outlook. ","a3afc6de":"##### Observations: \n* We found NaN values of columns in dataframes. \n    * 374 columns of total columns (394) of train_transaction dataframe have NaN values. \n    * 345 columns of total columns (393) of test_transaction dataframe have NaN values. ","2bf48faa":"* The data is masked so we are not reviewing these columns. However, we'll look at the relationship between some of these columns and the isFraud column.\n\n#### C1 & isFraud:","37aaab15":"### Card6 & isFraud:","56228786":"### Card1-Card6:\n* `Definition:` card1 - card6: Payment card information, such as card type, card category, issue bank, country, etc.  \n* `Definition od Card4:` Card4 shows card distributer types. \n    * `Categories & Labels:` Visa, Mastercard, American express, Discover \n* `Definition od Card6:` Card6 shows card types. \n    * `Categories & Labels:` Debit, Credit, Debit or Credit , Charge card      ","e17f1871":"* I want to see whether there is enough associated transactionID between train_transaction table and train_identity table. If there is enough associated transactionID we can look at the relationship between the identity table's columns and isFraud column of the transaction table.  ","6307cad5":"##### Observation:\n* Card4: \n    * Count of \"visa card\" is more than count of other card distributors. \n* Card6: \n    * Count of \"debit card\" is more than count of other card types. ","af3f9e8e":"### addr1-addr2 & isFraud:\n### addr1 & isFraud:","53a2a089":"##### How to Read The Graph: \n* Countplot shows the count of fraud and non-fraud transactions by P_emaildomain(Purchaser Email Domain).   \n* Pointplot shows the percentage of fraud in all transactions of Purchaser Email Domain. \n* x column shows Purchaser Email Domain.\n* y column shows; \n    * Count of Purchaser Email Domain by isFraud_ column.\n    * Percentage of fraud in all transactions of Purchaser Email Domain.","128a58fc":"* We can use card4 and card6 for analyse. \n    * card4 : Credit card distributors\n   \n    * card6 : Card types","002d2a2c":"### Time Series Features:\n### TransactionDT:","16e2ec8a":"##### How to Read The Graph: \n* This graph shows the count of ProductCDs. \n* x column shows categories, y column shows counts of categories.","0d9f5c8d":"##### Observations:  \n* The highest fraud transaction amount belongs in March and April. ","3e9bec02":"##### How to Read The Graph: \n* Countplot shows the count of fraud and non-fraud transactions by Matching columns.   \n* Pointplot shows the percentage of fraud in all transactions of Matching. \n* x column shows Matching.\n* y column shows; \n    * Count of Matching by isFraud_ column.\n    * Percentage of fraud in all transactions of Matching.","858212b8":"* `Definition:` TransactionAmt shows transaction payment amount in USD.","5c017245":"##### Observation:\n* Descriptive Statistics: \n    * Avg, median and mode are totally different. Because of this situation distribution is right skewed (positive skew). \n    * Mean value shows average transaction amount is 135$. \n* Box Plot Graph and z score Table:\n    * Outliers' count is huge at the TransactionAMT column. \n    * We'll use the TransactionAmt_zscore_outlier column to see if the outlier value is fraud or not. ","c3cf126d":"### addr2 & isFraud:","6a04e04a":"##### Observations:  \n* The highest non-fraud transaction amount belongs to December. ","0b98334f":"#### C2 & isFraud:","2084ef8c":"* I called `countplot_pointplot_viz` from `util_reporting.py`.\n* This function does;\n    * Gets a Python Pandas dataframe and visualize a countplot and a pointplot. ","385838d5":"##### Observations: \n* Generally at both of conditions (Fraud and Non-Fraud), Transactions have a small amount. But we can see some transactions of Non-Fraud has high amount than fraud transaction's amount. \n* As I explained before there are a lot of outliers in the TransactionAmt column. We can see from these graphs that outliers' reason is not fraud transactions, the reason is about non-fraud transaction amounts. ","9b26f593":"##### Observation:\n* addr1: \n    * There are 332 unique regions in dataframe. We show top 10 regions that have most transactions.  \n* addr2: \n    * There are 74 unique countries in dataframe. We show top 5 countries that have most transactions.","f2239aca":"### ProductCD:\n* `Definition:` ProductCD is product code that the product for each transaction. In the data description post, they state that ProductCD is a service and not a physical product.  \n* `Categories & Labels:` C, W, R, H, S","5b41c37b":"* To Visualize The Boxplot:\n    * I called `boxplot_viz` from `util_reporting.py`.\n    * This function does;\n        * This function visualizes a boxplot for a column.","193db200":"##### Observations: \n* 1.0, 2.0, 3.0 have most of the transactions. \n* 15.0, 17.0, 18.0 have most fraud transaction rates. \n* The most fraud transaction rate belongs to 15.0. \n* The most fraud transaction counts belongs to 1.0. ","b92ff559":"### addr1 - addr2:\n* `Definition:` They show address. Both addresses are for purchaser. \n    * addr1 as billing region\n    * addr2 as billing country","8ff56728":"* To convert timedelta column to time series column you can review the page that is at below link. \n\nhttps:\/\/www.kaggle.com\/c\/ieee-fraud-detection\/discussion\/100400#latest-579480","0540d889":"##### Observation:\n* Most of transactions belong 87th country.  \n* From the point of view of fraud transaction rate 65th has the highest fraudulent activities. "}}