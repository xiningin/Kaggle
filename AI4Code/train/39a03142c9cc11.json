{"cell_type":{"2e2180e9":"code","912bcd42":"code","584bda6e":"code","1c40cf3a":"code","0c830ac4":"code","a8143ae0":"code","8194f095":"code","6fb61bd8":"code","f9a2f820":"code","0f2ae6a0":"code","41a4f7df":"code","6176fecd":"code","2b2b4e04":"code","5eb54509":"code","f8b66a77":"code","84125d3a":"code","f35f28e4":"code","a5171343":"code","6705ba59":"code","0427eed8":"code","be20b1a5":"code","fd89d9cd":"code","ea0edc68":"code","d0df9b97":"code","9485f566":"code","e220e9b0":"code","f887c368":"code","d35a582f":"markdown","a5c799fe":"markdown","0d57eddb":"markdown","45f6c27e":"markdown","7803ea6b":"markdown","34aeeba4":"markdown","20f9999a":"markdown","571ee5b2":"markdown","b099ccce":"markdown","d14041ff":"markdown","de44b716":"markdown"},"source":{"2e2180e9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# Here we import the packages we need for the analysis, they are installed in Kaggle's backend \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n# Any results you write to the current directory are saved as output.\n!pip install plotly\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)","912bcd42":"# Connects to BigQuery API through Kaggle, no authentification required from Kaggle.\nfrom google.cloud import bigquery\nimport pandas as pd\n\nclient = bigquery.Client()","584bda6e":"# Query by Allen Day, GooglCloud Developer Advocate (https:\/\/medium.com\/@allenday)\nquery = \"\"\"\nSELECT \n  SUM(value\/POWER(10,18)) AS sum_tx_ether,\n  AVG(gas_price*(receipt_gas_used\/POWER(10,18))) AS avg_tx_gas_cost,\n  DATE(timestamp) AS tx_date\nFROM\n  `bigquery-public-data.crypto_ethereum.transactions` AS transactions,\n  `bigquery-public-data.crypto_ethereum.blocks` AS blocks\nWHERE TRUE\n  AND transactions.block_number = blocks.number\n  AND receipt_status = 1\n  AND value > 0\nGROUP BY tx_date\nHAVING tx_date >= '2017-01-01' AND tx_date <= '2019-05-04'\nORDER BY tx_date\n\"\"\"","1c40cf3a":"query_job = client.query(query)\n\niterator = query_job.result(timeout=30)\nrows = list(iterator)\n\n# Transform the rows into a nice pandas dataframe\ndf = pd.DataFrame(data=[list(x.values()) for x in rows], columns=list(rows[0].keys()))\n\n# Look at the first 10\ndf.tail(10)","0c830ac4":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('ggplot')\nsns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n\nf, g = plt.subplots(figsize=(12, 9))\ng = sns.lineplot(x=\"tx_date\", y=\"avg_tx_gas_cost\", data=df, palette=\"Blues_d\")\nplt.title(\"Average Ether transaction cost over time\")\nplt.show(g)","a8143ae0":"client = bigquery.Client()\nethereum_classic_dataset_ref = client.dataset('crypto_ethereum', project='bigquery-public-data')","8194f095":"\n\nquery = \"\"\"\nWITH mined_block AS (\n  SELECT miner, DATE(timestamp)\n  FROM `bigquery-public-data.crypto_ethereum.blocks` \n  WHERE DATE(timestamp) > DATE_SUB(CURRENT_DATE(), INTERVAL 1 MONTH)\n  ORDER BY miner ASC)\nSELECT miner, COUNT(miner) AS total_block_reward \nFROM mined_block \nGROUP BY miner \nORDER BY total_block_reward DESC\nLIMIT 10\n\"\"\"\n\nquery_job = client.query(query)\niterator = query_job.result()\n\n","6fb61bd8":"rows = list(iterator)\n# Transform the rows into a nice pandas dataframe\ntop_miners = pd.DataFrame(data=[list(x.values()) for x in rows], columns=list(rows[0].keys()))\n# Look at the first 10 headlines\ntop_miners.head(10)","f9a2f820":"\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.graph_objs as go\n\nlabels = top_miners['miner']\nvalues = top_miners['total_block_reward']\n\ntrace = go.Pie(labels=labels, values=values)\n\niplot([trace])\n\n","0f2ae6a0":"query = \"\"\"\n#standardSQL\n-- MIT License\n-- Copyright (c) 2019 Yaz Khoury, yaz.khoury@gmail.com\n\nSELECT miner, \n    DATE(timestamp) as date,\n    COUNT(miner) as total_block_reward\nFROM `bigquery-public-data.crypto_ethereum.blocks` \nGROUP BY miner, date\nHAVING COUNT(miner) > f\nORDER BY date, COUNT(miner) ASC\n\"\"\"\nquery_job = client.query(query)\niterator = query_job.result()\n","41a4f7df":"rows = list(iterator)\n# Transform the rows into a nice pandas dataframe\ntop_miners_by_date = pd.DataFrame(data=[list(x.values()) for x in rows], columns=list(rows[0].keys()))\ntop_miners_by_date.head(10)\n","6176fecd":"\ndate_series = top_miners_by_date['date'].unique()\ndate_series\n\n","2b2b4e04":"traces = []\nminer_series = top_miners_by_date['miner'].unique()\n\nfor index, miner in enumerate(miner_series):\n    miner_reward_by_date = top_miners_by_date.loc[top_miners_by_date['miner'] == miner]\n    miner_reward = miner_reward_by_date['total_block_reward']\n    miner_date = miner_reward_by_date['date']\n    trace = dict(\n        x=miner_date,\n        y=miner_reward,\n        mode='lines',\n        stackgroup='one'\n    )\n    traces.append(trace)\nfig = dict(data=traces)\n\niplot(fig)","5eb54509":"query = \"\"\"\n#standardSQL\n-- MIT License\n-- Copyright (c) 2019 Yaz Khoury, yaz.khoury@gmail.com\n\nSELECT miner, \n    DATE(timestamp) as date,\n    COUNT(miner) as total_block_reward\nFROM `bigquery-public-data.crypto_ethereum_classic.blocks` \nGROUP BY miner, date\nHAVING COUNT(miner) > f\nORDER BY date, COUNT(miner) ASC\n\"\"\"\nquery_job = client.query(query)\niterator = query_job.result()\n","f8b66a77":"query = \"\"\"\n#standardSQL\n-- MIT License\n-- Copyright (c) 2019 Yaz Khoury, yaz.khoury@gmail.com\n\nWITH total_reward_book AS (\n  SELECT miner, \n    DATE(timestamp) as date,\n    COUNT(miner) as total_block_reward\n  FROM `bigquery-public-data.crypto_ethereum.blocks` \n  GROUP BY miner, date\n  HAVING COUNT(miner) > 100\n),\ntotal_reward_book_by_date AS (\n SELECT date, \n        miner AS address, \n        SUM(total_block_reward \/ POWER(10,0)) AS value\n  FROM total_reward_book\n  GROUP BY miner, date\n),\ndaily_rewards_with_gaps AS (\n  SELECT\n    address, \n    date,\n    SUM(value) OVER (PARTITION BY ADDRESS ORDER BY date) AS block_rewards,\n    LEAD(date, 1, CURRENT_DATE()) OVER (PARTITION BY ADDRESS ORDER BY date) AS next_date\n  FROM total_reward_book_by_date\n),\ncalendar AS (\n  SELECT date \n  FROM UNNEST(GENERATE_DATE_ARRAY('2015-07-30', CURRENT_DATE())) AS date\n),\ndaily_rewards AS (\n  SELECT address, \n    calendar.date, \n    block_rewards\n  FROM daily_rewards_with_gaps\n  JOIN calendar ON daily_rewards_with_gaps.date <= calendar.date \n  AND calendar.date < daily_rewards_with_gaps.next_date\n),\nsupply AS (\n  SELECT date,\n    SUM(block_rewards) AS total_rewards\n  FROM daily_rewards\n  GROUP BY date\n),\nranked_daily_rewards AS (\n  SELECT daily_rewards.date AS date,\n    block_rewards,\n    ROW_NUMBER() OVER (PARTITION BY daily_rewards.date ORDER BY block_rewards DESC) AS rank\n  FROM daily_rewards\n  JOIN supply ON daily_rewards.date = supply.date\n  WHERE SAFE_DIVIDE(block_rewards, total_rewards) >= 0.01\n  ORDER BY block_rewards DESC\n),\ndaily_gini AS (\n  SELECT date,\n    -- (1 \u2212 2B) https:\/\/en.wikipedia.org\/wiki\/Gini_coefficient\n    1 - 2 * SUM((block_rewards * (rank - 1) + block_rewards \/ 2)) \/ COUNT(*) \/ SUM(block_rewards) AS gini\n  FROM ranked_daily_rewards\n  GROUP BY DATE\n)\nSELECT date,\n  gini,\n  AVG(gini) OVER (ORDER BY date ASC ROWS 7 PRECEDING) AS gini_sma_7,\n  AVG(gini) OVER (ORDER BY date ASC ROWS 30 PRECEDING) AS gini_sma_30\nFROM daily_gini\nORDER BY date ASC\n\"\"\"\n\nquery_job = client.query(query)\niterator = query_job.result()","84125d3a":"rows = list(iterator)\n# Transform the rows into a nice pandas dataframe\nmining_reward_gini_by_date = pd.DataFrame(data=[list(x.values()) for x in rows], columns=list(rows[0].keys()))\nmining_reward_gini_by_date.head(10)\n","f35f28e4":"traces = []\nx = mining_reward_gini_by_date['date']\ngini_list = ['gini', 'gini_sma_7', 'gini_sma_30']\nfor gini in gini_list:\n    y = mining_reward_gini_by_date[gini]\n    trace = dict(\n        x=x,\n        y=y,\n        \n        mode='lines'\n    )\n    traces.append(trace)\nfig = dict(data=traces)\n\niplot(fig, validate=False)\n","a5171343":"query = \"\"\"\nwith double_entry_book as (\n    -- debits\n    select to_address as address, value as value\n    from `bigquery-public-data.crypto_ethereum.traces`\n    where to_address is not null\n    and status = 1\n    and (call_type not in ('delegatecall', 'callcode', 'staticcall') or call_type is null)\n    union all\n    -- credits\n    select from_address as address, -value as value\n    from `bigquery-public-data.crypto_ethereum.traces`\n    where from_address is not null\n    and status = 1\n    and (call_type not in ('delegatecall', 'callcode', 'staticcall') or call_type is null)\n    union all\n    -- transaction fees debits\n    select miner as address, sum(cast(receipt_gas_used as numeric) * cast(gas_price as numeric)) as value\n    from `bigquery-public-data.crypto_ethereum.transactions` as transactions\n    join `bigquery-public-data.crypto_ethereum.blocks` as blocks on blocks.number = transactions.block_number\n    group by blocks.miner\n    union all\n    -- transaction fees credits\n    select from_address as address, -(cast(receipt_gas_used as numeric) * cast(gas_price as numeric)) as value\n    from `bigquery-public-data.crypto_ethereum.transactions`\n)\nselect address, \nsum(value) \/ 1000000000 as balance\nfrom double_entry_book\ngroup by address\norder by balance desc\nlimit 20\n\"\"\"\n\nquery_job = client.query(query)\niterator = query_job.result()\n","6705ba59":"rows = list(iterator)\n# Transform the rows into a nice pandas dataframe\ntop_address_rich_list = pd.DataFrame(data=[list(x.values()) for x in rows], columns=list(rows[0].keys()))\ntop_address_rich_list.head(10)\n","0427eed8":"labels = top_address_rich_list['address']\nvalues = top_address_rich_list['balance']\n\ntrace = go.Pie(labels=labels, values=values)\n\niplot([trace])\n","be20b1a5":"\n\nquery = \"\"\"\nwith \ndouble_entry_book as (\n    -- debits\n    select to_address as address, value as value, block_timestamp\n    from `bigquery-public-data.crypto_ethereum.traces`\n    where to_address is not null\n    and status = 1\n    and (call_type not in ('delegatecall', 'callcode', 'staticcall') or call_type is null)\n    union all\n    -- credits\n    select from_address as address, -value as value, block_timestamp\n    from `bigquery-public-data.crypto_ethereum.traces`\n    where from_address is not null\n    and status = 1\n    and (call_type not in ('delegatecall', 'callcode', 'staticcall') or call_type is null)\n    union all\n    -- transaction fees debits\n    select miner as address, sum(cast(receipt_gas_used as numeric) * cast(gas_price as numeric)) as value, block_timestamp\n    from `bigquery-public-data.crypto_ethereum.transactions` as transactions\n    join `bigquery-public-data.crypto_ethereum.blocks` as blocks on blocks.number = transactions.block_number\n    group by blocks.miner, block_timestamp\n    union all\n    -- transaction fees credits\n    select from_address as address, -(cast(receipt_gas_used as numeric) * cast(gas_price as numeric)) as value, block_timestamp\n    from `bigquery-public-data.crypto_ethereum.transactions`\n),\ndouble_entry_book_by_date as (\n    select \n        date(block_timestamp) as date, \n        address, \n        sum(value \/ POWER(10,0)) as value\n    from double_entry_book\n    group by address, date\n),\ndaily_balances_with_gaps as (\n    select \n        address, \n        date,\n        sum(value) over (partition by address order by date) as balance,\n        lead(date, 1, current_date()) over (partition by address order by date) as next_date\n        from double_entry_book_by_date\n),\ncalendar as (\n    select date from unnest(generate_date_array('2015-07-30', current_date())) as date\n),\ndaily_balances as (\n    select address, calendar.date, balance\n    from daily_balances_with_gaps\n    join calendar on daily_balances_with_gaps.date <= calendar.date and calendar.date < daily_balances_with_gaps.next_date\n),\n supply as (\n    select\n        date,\n        sum(balance) as daily_supply\n    from daily_balances\n    group by date\n),\nranked_daily_balances as (\n    select \n        daily_balances.date,\n        balance,\n        row_number() over (partition by daily_balances.date order by balance desc) as rank\n    from daily_balances\n    join supply on daily_balances.date = supply.date\n    where safe_divide(balance, daily_supply) >= 0.0001\n    ORDER BY safe_divide(balance, daily_supply) DESC\n), \ngini_daily as (\n   select\n    date,\n    -- (1 \u2212 2B) https:\/\/en.wikipedia.org\/wiki\/Gini_coefficient\n    1 - 2 * sum((balance * (rank - 1) + balance \/ 2)) \/ count(*) \/ sum(balance) as gini\n  from ranked_daily_balances\n  group by date\n)\nselect date,\n    gini,\n    avg(gini) over (order by date asc rows 7 preceding) as gini_sma7,\n    avg(gini) over (order by date asc rows 30 preceding) as gini_sma30\nfrom gini_daily\norder by date asc\n\"\"\"\n\nquery_job = client.query(query)\niterator = query_job.result()","fd89d9cd":"rows = list(iterator)\n# Transform the rows into a nice pandas dataframe\ndaily_balance_gini = pd.DataFrame(data=[list(x.values()) for x in rows], columns=list(rows[0].keys()))\ndaily_balance_gini.head(10)\n","ea0edc68":"traces = []\nx = daily_balance_gini['date']\ngini_list = ['gini', 'gini_sma7', 'gini_sma30']\nfor gini in gini_list:\n    y = daily_balance_gini[gini]\n    trace = dict(\n        x=x,\n        y=y,\n        mode='lines'\n    )\n    traces.append(trace)\nfig = dict(data=traces)\n\niplot(fig, validate=False)","d0df9b97":"query = \"\"\"\n#standardSQL\n-- MIT License\n-- Copyright (c) 2019 Yaz Khoury, yaz.khoury@gmail.com\n\nWITH block_rows AS (\n  SELECT *, ROW_NUMBER() OVER (ORDER BY timestamp) AS rn\n  FROM `bigquery-public-data.crypto_ethereum.blocks`\n),\ndelta_time AS (\n  SELECT\n  mp.timestamp AS block_time,\n  mp.difficulty AS difficulty,\n  TIMESTAMP_DIFF(mp.timestamp, mc.timestamp, SECOND) AS delta_block_time\n  FROM block_rows mc\n  JOIN block_rows mp\n  ON mc.rn = mp.rn - 1\n),\nhashrate_book AS (\n  SELECT TIMESTAMP_TRUNC(block_time, DAY) AS block_day,\n  AVG(delta_block_time) as daily_avg_block_time,\n  AVG(difficulty) as daily_avg_difficulty\n  FROM delta_time\n  GROUP BY TIMESTAMP_TRUNC(block_time, DAY)\n)\nSELECT block_day,\n(daily_avg_difficulty\/daily_avg_block_time)\/1000000000 as hashrate\nFROM hashrate_book\nORDER BY block_day ASC\n\"\"\"\n\nquery_job = client.query(query)\niterator = query_job.result()\n","9485f566":"rows = list(iterator)\n# Transform the rows into a nice pandas dataframe\ndaily_hashrate = pd.DataFrame(data=[list(x.values()) for x in rows], columns=list(rows[0].keys()))\ndaily_hashrate.head(10)\n","e220e9b0":"trace = go.Scatter(\n    x=daily_hashrate['block_day'],\n    y=daily_hashrate['hashrate'],\n    mode='lines'\n)\ndata = [trace]\niplot(data)\n\n","f887c368":"train = pd.read_csv('..input\/etherclose\/eth-24.csv')","d35a582f":"\n## Plotly Library for Plotting \/ Librer\u00eda de Visualizaciones Plotly\n\nIn this notebook, we will be using Plotly for plotting our charts. You can sign up for a free account to get your API key in order to generate the charts if you choose to run this notebook on your own.\n\nEn este Notebook, usaremos Plotly para dibujar nuestros gr\u00e1ficos. Puedes obtener una cuenta gratuita que te facilite una API Key para poder generar los gr\u00e1ficos, si decides ejecutar este Notebook en local.\n\nLet's start by plotting the top miners by their block reward as a pie chart.\n\nEmpecemos dibujando el ranking de los principales mineros, seg\u00fan su recompensa por bloque, como un gr\u00e1fico de tarta.\n","a5c799fe":"\n### Daily Top Balance Gini Coefficient\n### Ranking Diario del Balance de Coeficiente de Gini\n\nNow, we will try getting daily top rich list from the genesis until now and then calculate the gini coefficient of the rich list.\n\nAhora, intentaremos conseguir la lista del ranking de los m\u00e1s ricos, desde el bloque g\u00e9nesis hasta ahora y despu\u00e9s calcularemos el coeficiente Gini de dicha lista.\n\nIn this context, the gini coefficient will be a measure of income inequality among wallet addresses based on how much ether balance is in each wallet. Of course, this assumes 1 person = 1 wallet, but a person can have multiple wallets. It will also query for top 10k addresses to be used in gini analysis. That will include exchange account balances, which we don't take into account eliminating from the dataset.\n\nEn este contexto, el coeficiente Gini ser\u00e1 una medida de la desigualdad de ingresos entre las direcciones de carteras virtuales, bas\u00e1ndose en cuanto balance de Ethers hay en cada cartera. Por supuesto, se asume que cada cartera corresponde a una \u00fanica persona, pero una persona puede disponer de m\u00faltiples carteras. Tambi\u00e9n se har\u00e1n consultas sobre las 10.000 direcciones m\u00e1s altas, que ser\u00e1n usadas en los an\u00e1lisis Gini. Esto incluye los balances de las cuentas de los Exchanges, que no tendremos en cuenta, elimin\u00e1ndolos del dataset.\n\nThe query was written by from Evegeny Medvedev and Allen Day for this Google Blog Post. I added some further analysis towards the end to measure the Simple Moving Average of the Gini for the past 7 and 30 days.\n","0d57eddb":"![](https:\/\/s3-eu-west-1.amazonaws.com\/brainrex.com\/img\/logo_circle_new.png) ![](https:\/\/secure.meetupstatic.com\/photos\/event\/2\/a\/4\/9\/600_469510825.jpeg)\n\n# Bienvenido to Blockmad Labs Meetup 4 de mayo\n#### En este taller analizaremos la blockchain de Ethereum a traves de visualizaciones. Para eso usaremos el historial de datos de la blockchain de Ethereum, datos de mercados y metadatos sobre redes sociales proporcionados por la API de Brainrex.\nCreditos : https:\/\/www.kaggle.com\/yazanator\/analyzing-ethereum-classic-via-google-bigquery ( We forked kernel and adapted to Ethereum)\n\n\n## Agenda.\n\n\n1. Visualizacion de Ethereum Blockchain with BigQuery Public Datasets\n2. Adding Ethereum crypto exchange (Coinbase USD\/BTC) usando la API de Brainrex.\n3. Integrating Social Media Stats from Brainrex API\n4. Conclusiones\n\n\n\n","45f6c27e":"## Segunda Parte. Add Market Data from Coinbase and Twitter stats from the Brainrex API\nPara esta parte necesitas sacar una API key en https:\/\/console.brainrex.com\/register\n","7803ea6b":"\n### Top Mineros por recompensa acumulada desde el bloque genesis.\n\nAhora, hagamos que sea m\u00e1s interesante y planifiquemos (\u00bfanalicemos?) las recompensas totales de todos los que alguna vez hayan extra\u00eddo Ethereum del bloque de g\u00e9nesis.\n\nLo limitaremos s\u00f3lo a los mineros, cuyas recompensas diarias de bloques superan los 100. Esto nos permite ahorrar en la computaci\u00f3n y trazar los rastros en este Notebook de Kaggle.\n\nPodemos usar la siguiente consulta:\n\n#standardSQL\n-- MIT License\n-- Copyright (c) 2019 Yaz Khoury, yaz.khoury@gmail.com\n~~~~\nSELECT miner, \n    DATE(timestamp) as date,\n    COUNT(miner) as total_block_reward\nFROM `bigquery-public-data.crypto_ethereum.blocks` \nGROUP BY miner, date\nHAVING COUNT(miner) > 100\nORDER BY date, COUNT(miner) ASC\n~~~~\n","34aeeba4":"## Coste medio de transacciones por dia (Average Gas Price )\n### En esta consulta (query) calcularemos el coste medio de gas asociado con las transacciones ","20f9999a":"\n### Ranking de Mineros por Recompensa en los ultimos 30 dias\n#### Aqu\u00ed intentamos averiguar qui\u00e9nes son los principales mineros seg\u00fan la direcci\u00f3n del bloque explotado en los \u00faltimos 30 d\u00edas. Ejecutaremos la siguiente consulta como una cadena en Python a trav\u00e9s del cliente BigQuery.\n~~~~\n> WITH mined_block AS (\n  SELECT miner, DATE(timestamp)\n  FROM `bigquery-public-data.ethereumblockchain.blocks` \n  WHERE DATE(timestamp) > DATE_SUB(CURRENT_DATE(), INTERVAL 1 MONTH)\n  ORDER BY miner ASC)\nSELECT miner, COUNT(miner) AS total_block_reward \nFROM mined_block \nGROUP BY miner \nORDER BY total_block_reward ASC\n\n~~~~\n\nLet's run it.\n\n\u00a1Ejecut\u00e9moslo!\n","571ee5b2":"Que datos tenemos? El dataset de Ethereum cuenta con las siguientes tablas.\n## Datos que usaremos. Proveidos por Google Cloud y Brainrex Store.\nEsta base de datos est\u00e1 construida por Google y est\u00e1 siendo actualizada en tiempo real. \nPuedes aprender m\u00e1s de c\u00f3mo se construyo en este Articulo.\nhttps:\/\/cloud.google.com\/blog\/products\/data-analytics\/ethereum-bigquery-public-dataset-smart-contract-analytics\n### Datos disponibles en BigQuery Ethereum BLockchain .\n| Columnas | Description |\n| ------ | ----------- |\n| blocks   | This table contains a set of all blocks in the blockchain and their attributes. |\n| contracts | This table contains a subset of Ethereum addresses that contain contract byte-code, as well as some basic analysis of that byte-code. |\n| logs    | This table is generally useful for reporting on any logged event type on the Ethereum blockchain. |\n| token_transfers    | This table contains the subset of those transactions and has further processed and denormalized the data to make it easier to consume for analysis of token transfer events. |\n| tokens    | Token data. |\n| traces    | Traces exported using Parity trace module. |\n| transactions    | This table contains a set of all transactions from all blocks, and contains a block identifier to get associated block-specific information associated with each transaction. |\n\n\n### Datos disponibles en Brainrex Data Integrations .\n| Columns | Description |\n| ------ | ----------- |\n| exchanges   | This table contains a set of all blocks in the blockchain and their attributes. |\n| currency_pairs | This table contains a subset of Ethereum addresses that contain contract byte-code, as well as some basic analysis of that byte-code. |\n| generate_candles    | This table is generally useful for reporting on any logged event type on the Ethereum blockchain. |\n| twitter_stats    | This table contains the subset of those transactions and has further processed and denormalized the data to make it easier to consume for analysis of token transfer events. |\n\n\n\n","b099ccce":"### Top 20 rich list","d14041ff":"\n### Daily Gini Coefficient of Ethereum Mining Rewards By Miners\n\nAhora, vamos a calcular el coeficiente diario de Gini.\n\nEl coeficiente de Gini es una medida estad\u00edstica de la distribuci\u00f3n utilizada para medir la distribuci\u00f3n del ingreso o la riqueza entre una poblaci\u00f3n.\n\nCita de articulo de Investopedia:\n\n    \"Un pa\u00eds en el que cada residente tenga el mismo ingreso tendr\u00eda un coeficiente de Gini de 0. Un pa\u00eds en el que un residente obtuviera todos los ingresos, mientras que todos los dem\u00e1s no ganar\u00edan nada, tendr\u00eda un coeficiente de Gini de 1.\"\n\nAqu\u00ed estamos calculando la distribuci\u00f3n diaria de recompensas de bloque entre las direcciones, seg\u00fan la direcci\u00f3n del minero que recibi\u00f3 un bloque diariamente.\n\nLa consulta utiliza lo que se construy\u00f3 anteriormente y se toma de la implementaci\u00f3n de la consulta Gini del Balance diario.\n\nAdem\u00e1s, solo por diversi\u00f3n, calcularemos el Promedio M\u00f3vil Simple del Gini, usando una ventana de 7 y 30 d\u00edas. La media m\u00f3vil simple de SMA toma un conjunto de valores y sus per\u00edodos de tiempo y promedia una suma de los valores divididos por la ventana de tiempo elegida.\n\nEl valor de consulta aqu\u00ed ser\u00e1 gini_sma_7 y gini_sma_30.\n\nTenga en cuenta que esto s\u00f3lo calcula el gini de los mineros que obtuvieron m\u00e1s del 1% de las recompensas del bloque en un d\u00eda, de lo contrario, siempre ir\u00e1 a 1 debido a que muchos minan s\u00f3lo 1 bloque.","de44b716":"## Daily Hashrate\n\nHashrate is a measure of difficulty over block time. We can measure this by getting the delta time of each block timestamp from the previous block timestamp.\n\nWe can average it out by day. That is, the query can average out all difficulty and delta times per day and divide them by one another. We can further divide by 1 billion to get the GH\/s.\n\nWe will use the following query I wrote for the Daily Hashrate.\n~~~~\n#standardSQL\n-- MIT License\n-- Copyright (c) 2019 Yaz Khoury, yaz.khoury@gmail.com\n\nWITH block_rows AS (\n  SELECT *, ROW_NUMBER() OVER (ORDER BY timestamp) AS rn\n  FROM `bigquery-public-data.crypto_ethereum.blocks`\n),\ndelta_time AS (\n  SELECT\n  mp.timestamp AS block_time,\n  mp.difficulty AS difficulty,\n  TIMESTAMP_DIFF(mp.timestamp, mc.timestamp, SECOND) AS delta_block_time\n  FROM block_rows mc\n  JOIN block_rows mp\n  ON mc.rn = mp.rn - 1\n),\nhashrate_book AS (\n  SELECT TIMESTAMP_TRUNC(block_time, DAY) AS block_day,\n  AVG(delta_block_time) as daily_avg_block_time,\n  AVG(difficulty) as daily_avg_difficulty\n  FROM delta_time\n  GROUP BY TIMESTAMP_TRUNC(block_time, DAY)\n)\nSELECT block_day,\n(daily_avg_difficulty\/daily_avg_block_time)\/1000000000 as hashrate\nFROM hashrate_book\nORDER BY block_day ASC\n\n~~~~"}}