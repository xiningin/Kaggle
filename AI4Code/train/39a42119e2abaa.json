{"cell_type":{"6229c56a":"code","95200de5":"code","3547d1d2":"code","26786b90":"code","4316203a":"code","8ed8faed":"code","79b5ad3a":"code","0bc710f1":"code","e860a76b":"code","c76f21ab":"code","ba555409":"code","4ba628c1":"code","9f4197e2":"code","179ecaab":"code","6bda15a5":"code","91db9df7":"code","9747b404":"markdown","d102a84b":"markdown","645a7f8f":"markdown","cdb5ff24":"markdown","9b83c989":"markdown","4a4bb55d":"markdown","e7a7327a":"markdown","48e9f33e":"markdown","3b69944d":"markdown","af2339b3":"markdown","1d70c6c9":"markdown","04d8e6f2":"markdown","368b2117":"markdown","4a55cbdc":"markdown","3d4ed44e":"markdown","ea00894f":"markdown"},"source":{"6229c56a":"# Install any non-default packages\n!pip install -q -U keras-tuner==1.0.1","95200de5":"# Import all packages and data!\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom tensorflow import keras\nimport tensorflow as tf\nimport kerastuner as kt\n\nnp.random.seed(17)\nsns.set(style='white', context='notebook', palette='hls')\n\ndf = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","3547d1d2":"df.head()","26786b90":"# Convert the first 5 images from the dataframe into numpy arrays\nexample_images = df.drop(columns='label').head().to_numpy()\nnum_images = len(example_images)\n\n# Visualize those arrays using imshow()\nplt.figure(figsize=(15,5))\nfor i in range(num_images):\n    plt.subplot(1, num_images, i+1)\n    plt.imshow(example_images[i].reshape(28, 28))","4316203a":"print(\"There are {} null values in the training dataframe.\".format(df.isna().sum().sum()))\nprint(\"There are {} null values in the test dataframe.\".format(test.isna().sum().sum()))","8ed8faed":"training_images = df.drop(columns = 'label')\nprint(\"The training image pixel values range from {} to {}.\".format(training_images.min().min(), training_images.max().max()))\nprint(\"The test image pixel values range from {} to {}.\".format(test.min().min(), test.max().max()))","79b5ad3a":"sns.countplot(df.label)\nplt.show()","0bc710f1":"def preprocess_images(df, \n                      img_rows: int = 28, \n                      img_cols: int = 28, \n                      num_classes: int = 10):\n    \"\"\" Takes an input df of images and reshapes\/scales them into a numpy array useable by keras.\"\"\"\n        \n    # Reshape to make us of each image's physical properties\n    shaped_X = df.to_numpy().reshape(-1, img_rows, img_cols, 1)\n    \n    # Scale all entries to the range 0-1\n    processed_X = shaped_X \/ 255\n    return processed_X\n","e860a76b":"# Define some constants.\nimg_rows = 28\nimg_cols = 28\nnum_classes = 10\n\nmodel = keras.models.Sequential()\n\n# The first layer needs to be told the input shape.\nmodel.add(keras.layers.Conv2D(20, kernel_size=(3, 3),\n             activation='relu',\n             input_shape=(img_rows, img_cols, 1)))\n\n# Keras can infer the input shape for the remaining layers, so we don't have to specify!\nmodel.add(keras.layers.Conv2D(20, kernel_size=(3, 3),activation='relu'))\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(128, activation='relu'))\nmodel.add(keras.layers.Dense(num_classes, activation='softmax'))\n\n# Plot model shape.\nkeras.utils.plot_model(model)","c76f21ab":"# Grab label data and onehot encode it.\ntrain_test = df.copy()\ny = train_test.label\ny_onehot = keras.utils.to_categorical(y, num_classes)\n\n# Remove labels and then process image data.\ntrain_test = train_test.drop(columns='label')\nX = preprocess_images(train_test)\n\n# Split into train, test sets.\ntrain_X, val_X, train_y, val_y = train_test_split(X, y_onehot, train_size=0.8, random_state = 17)","ba555409":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nhistory = model.fit(x=train_X, \n                    validation_data=(val_X, val_y), \n                    y=train_y,\n                    epochs=6, \n                    batch_size=5, \n                    verbose=0)\n\nplt.plot(history.history['loss'], label='training data loss')\nplt.plot(history.history['val_loss'], label='validation data los')\nplt.legend()\nplt.show()","4ba628c1":"def model_builder(hp, img_rows:int = 28, img_cols:int = 28):\n    \"\"\"\n    Creates a CNN model with the following structure:\n    \n    input images with dimensions (img_rows, img_cols)\n    --> layer 0, a CNN\n    --> layer 1, dropout\n    --> layer 2, flattening\n    --> layer 3, dense relu\n    --> layer 4, dense softmax\n    --> output\n    \n    The model defines parameter ranges for:\n     - The numnber of units in the cnn and dense layers\n     - The amount of dropout\n     - The learning rate of the optimizer\n    \"\"\"\n    \n    # Define parameter ranges to test on\n    hp_cnn_layer_units = hp.Int('cnn_layer_units', min_value = 20, max_value = 40, step = 20)\n    hp_dense_layer_units = hp.Int('dense_layer_units', min_value = 128, max_value = 512, step = 128)\n    hp_dropout = hp.Float('dropout', min_value = 0.1, max_value = 0.3, step=0.1)\n    hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n    \n    # Define model structure\n    model = keras.Sequential()\n\n    model.add(keras.layers.Conv2D(hp_cnn_layer_units, kernel_size=(3, 3),\n         strides=2,\n         activation='relu',\n         input_shape=(img_rows, img_cols, 1)))\n    model.add(keras.layers.Dropout(hp_dropout))\n    model.add(keras.layers.Flatten())\n\n\n    model.add(keras.layers.Dense(units = hp_dense_layer_units, activation = 'relu'))\n    model.add(keras.layers.Dense(10, activation='softmax'))\n\n    # Compile with optimizer learning rate settings\n    model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n                loss = 'categorical_crossentropy', \n                metrics = ['accuracy'])\n\n    return model","9f4197e2":"tuner = kt.Hyperband(model_builder,\n                     objective = 'val_accuracy', \n                     max_epochs = 5,\n                     directory = 'tuning',\n                     project_name = 'mnist_tuner')","179ecaab":"tuner.search(train_X, train_y, validation_data = (val_X, val_y), callbacks=[tf.keras.callbacks.EarlyStopping(patience=1)], verbose=0)\n\n# Get the optimal hyperparameters\nbest_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]","6bda15a5":"print(f\"\"\"\nThe hyperparameter search is complete! :D \n\nThe optimal number of units in the cnn layer is {best_hps.get('cnn_layer_units')}\nThe optimal number of units in the first densely-connected layer is {best_hps.get('dense_layer_units')}.\nThe optimal amount of dropout is {best_hps.get('dropout')}\nThe optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n\"\"\")","91db9df7":"best_model = tuner.get_best_models(1)[0]\ntest_X = preprocess_images(test)\n\n# Create predictions to be submitted -- since the model outputs softmax probabilities, \n# our prediction is the number with the highest probability.\nfinal_predictions = [i.argmax() for i in best_model.predict(test_X)]\npd.DataFrame({'ImageId': list(range(1,len(final_predictions)+1)), 'Label': final_predictions}).to_csv('keras_cnn.csv', index = False)  \nprint(\"Done :D\")","9747b404":"The label column is the target value for each image, followed by a column for each of the 784 pixels per image. Since this is image data, it also makes sense to take a look at a few images! Here, we're grabbing a few example images by dropping the label column, turning the images into a numpy array of pixel values, and reshaping to the 28x28 pixel original form.\n\nLooking at the labels in the df.head() call above, we're expecting to see the sequence 1, 0, 1, 4, 0.","d102a84b":"We know by looking at the [data description](https:\/\/www.kaggle.com\/c\/digit-recognizer\/data) and our data exploration that these images are 28x28 pixels, with each pixel taking on a value between 0-255 inclusive.\n\nIn order to take advantage of an image's geometry, we need to take each 1x784 vector of pixels and reshape it into a 28x28x1 array. If this was a colour image, it would be a 28x28x3 array so that each pixel can hold a value for each RGB color, but greyscale means each pixel stores only one value.\n\nthe preprocess_images() function below does the preprocessing we need to plug these images into a neural net. \n\nFor training data, this means:\n1. Using the keras [to_categorical](https:\/\/keras.io\/utils\/) function to one hot encode the target label column.\n2. Reshaping the data to the desired 28x28x1 format.\n3. Scaling the pixel values down to the 0-1 range by dividing by 255.\n\nFor test data, it would similarly mean:\n1. Reshaping the data to the desired 28x28x1 format.\n2. Scaling the pixel values down to the 0-1 range by dividing by 255.\n\nSince the same image processing steps are required in both training and testing, we'll go ahead and put everything in the same preprocessing function (we'll onehot encode the training labels separately). In general, it's good to use the same function for your training and test preprocessing, so that you make sure you're treating training and test data the same!","645a7f8f":"Once we've defined a model with the parameter ranges we'd like to explore, we can hand that model to a tuner. Here, we're using the hyperband algorithm to tune, although keras tuner has others as well. We'll set the max number of epochs as 5, which based on our earlier trial seems like it will be more than needed for our various parameter options during training. To help speed up the training process, we can make use of keras' early stopping functionality by calling it as a [callbacks](https:\/\/machinelearningmastery.com\/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping\/) parameter.","cdb5ff24":"That's the basic structre of the model! A few details to note:\n - the Conv2D **kernel_size** is the size of the kernel used to detect features in each image. The larger a kernel, the more complex features it can pick up.\n - The **softmax** activation is required in that last layer for this network to work, since it converts the final layer's results to probabilities that an image is a member of each of the possible output classes.\n \n Let's try training the model on our processed data! First, we'll split that data into train and validation sets.","9b83c989":"## Basic Model\n\nSo, we have the data - how do we build a model? Since this is an image dataset, a great move would be to make use of [convolutions](https:\/\/keras.io\/layers\/convolutional\/). A convolution is a way of extracting features from data using kernels (great explanation [here](https:\/\/towardsdatascience.com\/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)) that scan across smaller pieces of the image. Since this is a 2D image, we'll be using 2D convolutions.\n\nSo here's the code to our first model! It's a sequential keras model, meaning that you add layers linearly (one at a time). Here, we're adding two convolution layers each with 20 filters, flattening the result, then passing it through two dense layers. Why in that order?\n - **2D Convotion layers** make use of the shape of the image, and want that 2D input shape.\n - **A \"flatten\" layer** reformats the data into a more traditional 1D vector shape.\n - **Dense (normal run-of-the-mill NN) layers** use the traditional 1D input shape, and can translate that 2D image input into a 1D answer (what probability is this image each of the 10 digits -- a 1D vector of length 10!)\n\nKeras has a [plot_model](https:\/\/keras.io\/visualization\/) function that lets us visualize the model we just created, which is great for understanding what's going on in a model or debugging if something is going wrong.","4a4bb55d":"No nulls - that makes our job pretty straightforward in terms of data cleaning. To check pixel values, we can use the max() and min() functions across the whole dataframe. We're looking at the label distribution later, so we'll drop those in this range check.","e7a7327a":"Nice, all the pixel values are in the 0-255 range! Finally, we should check the label distribution to see if our dataset is balanced.","48e9f33e":"Next, we need to compile the model. The loss function we'll use is [categorical crossentropy](https:\/\/peltarion.com\/knowledge-center\/documentation\/modeling-view\/build-an-ai-model\/loss-functions\/categorical-crossentropy), a loss function specific to classification problems where each datapoint is part of only one class. While the loss function is what the optimizer will use, we'll throw in accuracy as an additional metric to see how the model is doing (useful for the human viewer, even if it's not involved in model training directly!). ","3b69944d":"## Predict and Export\n\nOnce we've found the optimal model parameters, we can go ahead and use those to predict on the test set, then we're done!","af2339b3":"## Data Processing","1d70c6c9":"## Tuning with Keras Tuner\n\nWe've made *a* model, but what if we want to improve it? There are many options we could try: \n- Add more convolution layers\n- Add more dense layers\n- Change the number of neurons in the dense layers\n- Change the number of filters in the convolution layers\n- Change the shapes of the kernels in the convolution layers\n- Add regularization (via dropout)\n- Change optimization parameters (learning rate, optimization algorithm, etc.)\n\nand the list doesn't stop there! However, we have limited time and resources to try all of our options, so we'll keep the activation types, optimizer strategy and kernel shape constant and instead focus on the size of layers and adding [dropout](https:\/\/machinelearningmastery.com\/dropout-for-regularizing-deep-neural-networks\/), a way of correcting for model overfitting by randomly removing a fraction of the network's nodes each iteration.\n\nHow do we go about tuning? You could try different variants by hand and compare, or try [sklearn's GridSearchCV](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.GridSearchCV.html), but there's an easier way: keras has a hyperparameter tuner built in! The tuner is called [Keras Tuner](https:\/\/www.tensorflow.org\/tutorials\/keras\/keras_tuner), and it offers many different [ways to specify parameter ranges](https:\/\/keras-team.github.io\/keras-tuner\/documentation\/hyperparameters\/).\n\nTo use Keras tuner, we need to define a model like we did above, but rather than define specific parameter values, we'll define parameter ranges or choice sets. For example, rather than say our dense layer will have 128 units, we might now want to try the values [128, 256, 384, 256], which we'd write as `hp.Int('dense_layer_units', min_value = 128, max_value = 512, step = 128)`.\n\nThe model definition below keeps things pretty simple -- if you want an example of a more complex model and parameter definition, [look here](https:\/\/blog.tensorflow.org\/2020\/01\/hyperparameter-tuning-with-keras-tuner.html).","04d8e6f2":"Great, this matches the labels we expected! Now that we've checked out a few specific examples, time to look through the overall data quality. Specifically:\n - Are there null values in this dataset (or anything else that would corrupt an image -- for example, are there any pixel values larger than 255 or below 0?)\n - Are the images equally distributed across all possible training labels?\n \n To check for NA values, we can do a quick sum across all values in df.isna(), which is a matrix of 1s for all null values and 0s otherwise.","368b2117":"Great, it looks like the training set is pretty evenly distributed across the possible 10 numbers, so we're all set to start training :)","4a55cbdc":"## MNIST With Keras CNNs\nThis notebook walks through the process of writing a convolutional neural net (CNN) using Keras to accurately identify the number drawn on each MNIST image!\n\nShoutout to the following resources:\n - [Dan's Deep Learning Course on Kaggle](https:\/\/www.kaggle.com\/learn\/deep-learning), a couple hour long tutorial on getting started with Keras NNs.\n - [Intuitively Understanding Convolutions for ML](https:\/\/towardsdatascience.com\/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1), an excellent visualization\/explanation of convolutions.\n - [Introduction to CNN Keras](https:\/\/www.kaggle.com\/yassineghouzam\/introduction-to-cnn-keras-0-997-top-6), a great notebook by another Kaggler!","3d4ed44e":"As we can see by the training vs validation loss scores, this model doesn't benefit from a whole lot of epochs (it might even be overfitting a bit after 2 or 3 epochs!). Moving forward, we can keep the number of epochs relatively low, which is convenient since each epoch takes a while!","ea00894f":"## Data Exploration\n\nWhat does our data look like? We'll start by looking at the tabular form."}}