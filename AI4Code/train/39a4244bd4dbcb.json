{"cell_type":{"039ab50f":"code","d24bce52":"code","bd1adce1":"code","917fd641":"code","d564b8d9":"code","72026c66":"code","27a5ea9e":"code","b2ae5526":"code","f85c0844":"code","741f004a":"code","9c1d2a28":"code","4b654091":"code","f868e563":"code","72b2a37a":"code","c96ace02":"code","5ccc719a":"code","45a35ae9":"code","00a067b0":"code","aa56690a":"code","415728e3":"code","32cd0c75":"markdown","461e883f":"markdown","1cbe08fd":"markdown","1fe47d18":"markdown","abbcafb6":"markdown"},"source":{"039ab50f":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d24bce52":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","bd1adce1":"main_dir = '..\/input\/tabular-playground-series-jun-2021\/'\ntrain_df = pd.read_csv(os.path.join(main_dir,'train.csv'))\ntest_df = pd.read_csv(os.path.join(main_dir,'test.csv'))\nsample_sub = pd.read_csv(os.path.join(main_dir,'sample_submission.csv'))","917fd641":"train_df.head()","d564b8d9":"test_df.head()","72026c66":"sample_sub.head()","27a5ea9e":"train_df.isnull().sum()","b2ae5526":"fig = plt.figure(figsize=(10, 6))\nsns.countplot(x=\"target\", data=train_df)","f85c0844":"target_mass = train_df['target'].value_counts()\nvalues = target_mass.values.tolist()\nindexes = target_mass.index.tolist()\n\nax,fig = plt.subplots(1,2,figsize=(15,6))\nplt.subplot(1,2,1)\nplt.pie(values , labels = indexes)\nplt.subplot(1,2,2)\nplt.bar(indexes,values)\nplt.show()","741f004a":"fet_set = train_df.drop(labels=['id','target'],axis=1)\ndef plot_diag_heatmap(data):\n    corr = data.corr()\n    mask = np.triu(np.ones_like(corr, dtype=bool))\n    f, ax = plt.subplots(figsize=(11, 9))\n    sns.heatmap(corr, mask=mask, cmap='YlGnBu', center=0,square=True, linewidths=1, cbar_kws={\"shrink\": 1.0})\nplot_diag_heatmap(fet_set)","9c1d2a28":"labels= pd.get_dummies(train_df['target'])","4b654091":"labels","f868e563":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn import preprocessing\nfrom sklearn.metrics import log_loss\n\nimport gc\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tensorflow.keras.backend as K\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Input, Embedding, Concatenate, Conv1D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import initializers\n\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.models import Model","72b2a37a":"def custom_metric(y_true, y_pred):\n    y_pred = K.clip(y_pred, 1e-15, 1-1e-15)\n    loss = K.mean(cce(y_true, y_pred))\n    return loss\n\ncce = tf.keras.losses.CategoricalCrossentropy()\n\nearlystop = EarlyStopping(\n    monitor='val_custom_metric', \n    min_delta=1e-05, \n    patience=10, \n    verbose=0,\n    mode='min', \n    baseline=None, \n    restore_best_weights=True\n)\n\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_custom_metric', \n    factor=0.7, \n    patience=10, \n    verbose=0,\n    mode='min'\n)","c96ace02":"def conv_model():\n    conv_in = Input(shape=(75))\n    embed = Embedding(\n        input_dim= 354,\n        output_dim = 7,\n        embeddings_regularizer='l2'\n    )(conv_in)\n    embed = Conv1D(12,1,activation='relu')(embed)\n    embed = Flatten()(embed)\n    hidden = Dropout(0.2)(embed)\n    \n    hidden = tfa.layers.WeightNormalization(\n        Dense(32,activation='selu',kernel_initializer='lecun_normal'))(hidden)\n    output = Dropout(0.3)(Concatenate()([embed,hidden]))\n    output = tfa.layers.WeightNormalization(\n        Dense(32,activation='relu',kernel_initializer='lecun_normal'))(output)\n    conv_out = Dense(9,activation='softmax',kernel_initializer='lecun_normal')(output)\n    \n    model = Model(conv_in,conv_out)\n    \n    return model","5ccc719a":"oof_NN_a = np.zeros((train_df.shape[0],9))\npred_NN_a = np.zeros((test_df.shape[0],9))\n\nfolds = 25\nSeed = 2021\nepochs = 60","45a35ae9":"skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=Seed)\n\nfor fold, (tr_idx, te_idx) in enumerate(skf.split(train_df,train_df.iloc[:,-1])):\n    print(f\"===Training Fold: {fold}===\\n\")\n    \n    X_train = train_df.iloc[:,1:-1].iloc[tr_idx]\n    y_train = labels.iloc[tr_idx]\n    X_test = train_df.iloc[:,1:-1].iloc[te_idx]\n    y_test = labels.iloc[te_idx]\n    \n    K.clear_session()\n    \n    print(\"\\n===CNN Training===\\n\")\n    \n    model = conv_model()\n    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=2e-4), metrics=custom_metric)\n    \n    model.fit(\n        X_train,y_train,\n        batch_size=256,\n        epochs=epochs,\n        validation_data= (X_test,y_test),\n        callbacks= [earlystop, reduce_lr],\n        verbose = 1\n    )\n    \n    pred_a = model.predict(X_test)\n    oof_NN_a[te_idx] += pred_a\n    \n    score_NN_a = log_loss(y_test,pred_a)\n    print(f\"\\n Fold: {fold} Score conv model: {score_NN_a}\")\n    pred_NN_a += model.predict(test_df.iloc[:,1:]) \/ folds\n    \nscore_a = log_loss(labels, oof_NN_a)\nprint(f\"\\n===Final Score: {score_a}===\\n\")","00a067b0":"pred_embedding = pred_NN_a","aa56690a":"submission = sample_sub\nsubmission['Class_1']=pred_embedding[:,0]\nsubmission['Class_2']=pred_embedding[:,1]\nsubmission['Class_3']=pred_embedding[:,2]\nsubmission['Class_4']=pred_embedding[:,3]\nsubmission['Class_5']=pred_embedding[:,4]\nsubmission['Class_6']=pred_embedding[:,5]\nsubmission['Class_7']=pred_embedding[:,6]\nsubmission['Class_8']=pred_embedding[:,7]\nsubmission['Class_9']=pred_embedding[:,8]","415728e3":"submission.to_csv(\"attempt2.csv\", index=False)","32cd0c75":"### Target Distribution","461e883f":"### Converting classes to categorical data","1cbe08fd":"### Importing Libraries","1fe47d18":"### Model Building","abbcafb6":"### Correlation"}}