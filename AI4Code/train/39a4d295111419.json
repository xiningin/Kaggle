{"cell_type":{"665ce6f5":"code","7aa5fb4d":"code","740e0955":"code","0460951a":"code","e2735c18":"code","cc46ecca":"code","f73c5a3d":"code","30263222":"code","31cfdefd":"code","cae86dd0":"code","41ec6765":"code","5ecfc565":"markdown","e201a088":"markdown","c14b2215":"markdown","e9b22de9":"markdown","74744063":"markdown","68e66bab":"markdown","0d2babb3":"markdown","3f4cd664":"markdown","67646b64":"markdown","aeffb10b":"markdown"},"source":{"665ce6f5":"!pip install imutils","7aa5fb4d":"##Loading the necessary packages \nimport numpy as np\nimport cv2\nfrom imutils.object_detection import non_max_suppression\nimport pytesseract\nfrom matplotlib import pyplot as plt","740e0955":"!ls ..\/input\/text-detection\/","0460951a":"#Creating argument dictionary for the default arguments needed in the code. \nargs = {\"image\":\"..\/input\/text-detection\/example-images\/Example-images\/ex24.jpg\", \"east\":\"..\/input\/text-detection\/east_text_detection.pb\", \"min_confidence\":0.5, \"width\":320, \"height\":320}\n","e2735c18":"#Give location of the image to be read.\n#\"Example-images\/ex24.jpg\" image is being loaded here. \n\nargs['image']=\"..\/input\/text-detection\/example-images\/Example-images\/ex24.jpg\"\nimage = cv2.imread(args['image'])\n\n#Saving a original image and shape\norig = image.copy()\n(origH, origW) = image.shape[:2]\n\n# set the new height and width to default 320 by using args #dictionary.  \n(newW, newH) = (args[\"width\"], args[\"height\"])\n\n#Calculate the ratio between original and new image for both height and weight. \n#This ratio will be used to translate bounding box location on the original image. \nrW = origW \/ float(newW)\nrH = origH \/ float(newH)\n\n# resize the original image to new dimensions\nimage = cv2.resize(image, (newW, newH))\n(H, W) = image.shape[:2]\n\n# construct a blob from the image to forward pass it to EAST model\nblob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n\t(123.68, 116.78, 103.94), swapRB=True, crop=False)","cc46ecca":"# load the pre-trained EAST model for text detection \nnet = cv2.dnn.readNet(args[\"east\"])\n\n# We would like to get two outputs from the EAST model. \n#1. Probabilty scores for the region whether that contains text or not. \n#2. Geometry of the text -- Coordinates of the bounding box detecting a text\n# The following two layer need to pulled from EAST model for achieving this. \nlayerNames = [\n\t\"feature_fusion\/Conv_7\/Sigmoid\",\n\t\"feature_fusion\/concat_3\"]","f73c5a3d":"#Forward pass the blob from the image to get the desired output layers\nnet.setInput(blob)\n(scores, geometry) = net.forward(layerNames)","30263222":"## Returns a bounding box and probability score if it is more than minimum confidence\ndef predictions(prob_score, geo):\n\t(numR, numC) = prob_score.shape[2:4]\n\tboxes = []\n\tconfidence_val = []\n\n\t# loop over rows\n\tfor y in range(0, numR):\n\t\tscoresData = prob_score[0, 0, y]\n\t\tx0 = geo[0, 0, y]\n\t\tx1 = geo[0, 1, y]\n\t\tx2 = geo[0, 2, y]\n\t\tx3 = geo[0, 3, y]\n\t\tanglesData = geo[0, 4, y]\n\n\t\t# loop over the number of columns\n\t\tfor i in range(0, numC):\n\t\t\tif scoresData[i] < args[\"min_confidence\"]:\n\t\t\t\tcontinue\n\n\t\t\t(offX, offY) = (i * 4.0, y * 4.0)\n\n\t\t\t# extracting the rotation angle for the prediction and computing the sine and cosine\n\t\t\tangle = anglesData[i]\n\t\t\tcos = np.cos(angle)\n\t\t\tsin = np.sin(angle)\n\n\t\t\t# using the geo volume to get the dimensions of the bounding box\n\t\t\th = x0[i] + x2[i]\n\t\t\tw = x1[i] + x3[i]\n\n\t\t\t# compute start and end for the text pred bbox\n\t\t\tendX = int(offX + (cos * x1[i]) + (sin * x2[i]))\n\t\t\tendY = int(offY - (sin * x1[i]) + (cos * x2[i]))\n\t\t\tstartX = int(endX - w)\n\t\t\tstartY = int(endY - h)\n\n\t\t\tboxes.append((startX, startY, endX, endY))\n\t\t\tconfidence_val.append(scoresData[i])\n\n\t# return bounding boxes and associated confidence_val\n\treturn (boxes, confidence_val)","31cfdefd":"# Find predictions and  apply non-maxima suppression\n(boxes, confidence_val) = predictions(scores, geometry)\nboxes = non_max_suppression(np.array(boxes), probs=confidence_val)","cae86dd0":"##Text Detection and Recognition \n\n# initialize the list of results\nresults = []\n\n# loop over the bounding boxes to find the coordinate of bounding boxes\nfor (startX, startY, endX, endY) in boxes:\n\t# scale the coordinates based on the respective ratios in order to reflect bounding box on the original image\n\tstartX = int(startX * rW)\n\tstartY = int(startY * rH)\n\tendX = int(endX * rW)\n\tendY = int(endY * rH)\n\n\t#extract the region of interest\n\tr = orig[startY:endY, startX:endX]\n\n\t#configuration setting to convert image to string.  \n\tconfiguration = (\"-l eng --oem 1 --psm 8\")\n    ##This will recognize the text from the image of bounding box\n\ttext = pytesseract.image_to_string(r, config=configuration)\n\n\t# append bbox coordinate and associated text to the list of results \n\tresults.append(((startX, startY, endX, endY), text))","41ec6765":"#Display the image with bounding box and recognized text\norig_image = orig.copy()\n\n# Moving over the results and display on the image\nfor ((start_X, start_Y, end_X, end_Y), text) in results:\n\t# display the text detected by Tesseract\n\tprint(\"{}\\n\".format(text))\n\n\t# Displaying text\n\ttext = \"\".join([x if ord(x) < 128 else \"\" for x in text]).strip()\n\tcv2.rectangle(orig_image, (start_X, start_Y), (end_X, end_Y),\n\t\t(0, 0, 255), 2)\n\tcv2.putText(orig_image, text, (start_X, start_Y - 30),\n\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,0, 255), 2)\n\nplt.imshow(orig_image)\nplt.title('Output')\nplt.show()","5ecfc565":"## Display image with bounding box and recognized text","e201a088":"## Forward pass the image through EAST model","c14b2215":"## Image processing","e9b22de9":"## Creating argument dictionary with some default values","74744063":"## Function to decode bounding box from EAST model prediction ","68e66bab":"In this exercise, we are only decoding horizontal bounding boxes. Decoding rotating bounding boxes from the scores and geometry is more complex. ","0d2babb3":"## Loading the packages","3f4cd664":"## Getting final bounding boxes after non max suppression","67646b64":"## Loading Pre-trained EAST model and defining output layers","aeffb10b":"## Generating list with bounding box coordinates and recognized text in the boxes"}}