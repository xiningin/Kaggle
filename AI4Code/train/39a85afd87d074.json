{"cell_type":{"765f4517":"code","0e20a609":"code","d35b3174":"code","7b29315c":"code","100e8be1":"code","3018ef2d":"code","dbc5cf73":"code","a55e0576":"code","15244220":"code","7cc6e4f0":"code","65e92429":"code","9720bc05":"code","f3a58f28":"code","e74853bf":"code","14e5dd17":"code","8461444b":"code","ce264f35":"code","5f1df1c9":"code","1e7214e9":"code","1b86e1fc":"code","c028a539":"code","a11e2e33":"code","ca13fdd7":"code","d31abcce":"code","76ae2b8d":"code","6654d3db":"markdown","85ceb71d":"markdown","10d140fc":"markdown"},"source":{"765f4517":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0e20a609":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom wordcloud import WordCloud,STOPWORDS #for visual representation of text data.\n#Stopwords are common words which do not provide any reasonable value to our data, e.g it, the, are. we","d35b3174":"df=pd.read_csv('..\/input\/515k-hotel-reviews-data-in-europe\/Hotel_Reviews.csv') #loading the datasets","7b29315c":"df.head() # Checking the top 5 rows\n","100e8be1":"df.sample(5) # Just sampling out any 5 rows for a better look","3018ef2d":"df.shape # 515,738 rows and 17 columns\n","dbc5cf73":"df.info() # Shows the datatype of the columns","a55e0576":"df.describe()","15244220":"df.isnull().sum() # Checking missing values, Latitude and longitude has some missing values (3268)","7cc6e4f0":"df['Hotel_Address'].nunique()\n\n# Countries in this dataset involves France, United Kingdom, Netherlands, Spain, Italy, Netherlands, Austria\n# 1493 unique hotel address","65e92429":"df.columns # Prints 17 unique columns","9720bc05":"# Plotting the Average scores of the hotels\ndf_sd = df[['Hotel_Name','Average_Score']].drop_duplicates() # Dropping any duplicates\nplt.figure(figsize = (14,6))\nsns.countplot(x = 'Average_Score',data = df_sd,color = 'green')\n# From the graph below, we can notice that most hotels were given scores ranging from 8.1 to 8.9","f3a58f28":"df.Average_Score.describe()\n# There are 34 unique average scores\n# Minimum Average score is 5.2\n# Maximum Average score is 9.8\n# 25% of the hotels have an Average_score of 8.1 - 5.2\n# 50% of the hotels have an Average_score of 8.4 - 8.2\n# 75% of the hotels have an Average_score of 8.8 - 8.5","e74853bf":"# We check out the distribution of hotels in the European countries\ndf.Hotel_Address = df.Hotel_Address.str.replace('United Kingdom','UK') # Replacing 'united kingdom' with 'UK' for easy use\ndf['EC'] = df.Hotel_Address.apply(lambda x: x.split(' ')[-1]) # Splitting the hotel address and picking out the last string which would be the countries\n#Plotting with matplotlib \nplt.figure(figsize = (12,5))\nplt.title('Hotel distribution in European countries')\ndf.EC.value_counts().plot.barh(color = 'green')","14e5dd17":"df[df.Average_Score >= 8.8][['Hotel_Name','Average_Score','Total_Number_of_Reviews']].drop_duplicates().sort_values(by ='Total_Number_of_Reviews',ascending = False)[:10]\n# We now attempt to find the 10 most popular hotels based on 'Total number of reviews, Average score greater than 8.8, and the Hotel names'","8461444b":"df['Positive_Review'] # Having a look at positive reviews","ce264f35":"import nltk # Natural language processing toolkit\nfrom nltk import FreqDist # Frequency distribution\n\nimport re # for regular expressions\nimport spacy # library for advanced Natural Language Processing \n\n","5f1df1c9":"# function to plot most frequent terms\ndef freq_words(x, terms = 30):\n  all_words = ' '.join([text for text in x])\n  all_words = all_words.split()\n\n  fdist = FreqDist(all_words)\n  words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())})\n\n  # selecting top 20 most frequent words\n  d = words_df.nlargest(columns=\"count\", n = terms) \n  plt.figure(figsize=(20,5))\n  ax = sns.barplot(data=d, x= \"word\", y = \"count\")\n  ax.set(ylabel = 'Count')\n  plt.show()","1e7214e9":"freq_words(df['Positive_Review']) # Frequency distribution of common words in positive reviews","1b86e1fc":"freq_words(df['Negative_Review'])  # Frequency distribution of common words in negative reviews","c028a539":"# You probably noticed we has a lot of word like 'the', 'was', 'to' e.t.c which won't help so we would remove them.\n# First of all, we remove unwanted characters, numbers and symbols\ndf['Positive_Review'] = df['Positive_Review'].str.replace(\"[^a-zA-Z#]\", \" \")\ndf['Negative_Review'] = df['Negative_Review'].str.replace(\"[^a-zA-Z#]\", \" \")","a11e2e33":"from nltk.corpus import stopwords\nstop_words = stopwords.words('english')\n# function to remove stopwords\ndef remove_stopwords(rev):\n    rev_new = \" \".join([i for i in rev if i not in stop_words])\n    return rev_new\n# I would apply everyting below to both positive and negative reviews\n# remove short words (length < 4)\ndf['Positive_Review'] = df['Positive_Review'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\ndf['Negative_Review'] = df['Negative_Review'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n\n\n# remove stopwords from the text\nreviews_1 = [remove_stopwords(r.split()) for r in df['Positive_Review']]\nreviews_2 = [remove_stopwords(r.split()) for r in df['Negative_Review']]\n\n\n\n# make entire text lowercase\n#reviews_1= [r.lower() for r in reviews_1] \n#reviews_2= [r.lower() for r in reviews_2]\n# From what i read, Nltk sees 'stop' and 'STOP' as different things. Making all lowercase seems good but I dont think i want to so that i can identify the 'No Negative' and 'No positive'in it. \n# if you dont get, just bring the question to our channel","ca13fdd7":"freq_words(reviews_1, 30) # Checking frequency of most used words in positive reviews","d31abcce":"freq_words(reviews_2, 30) # Checking frequency of most used words in negative reviews","76ae2b8d":"# Using wordcloud to visually represent the text data\ndef wordcloud_draw(data, color = 'black'):\n    words = ' '.join(data)\n    cleaned_word = \" \".join([word for word in words.split()\n                            if 'http' not in word\n                                and not word.startswith('@')\n                                and not word.startswith('#')\n                                and word != 'RT'\n                            ])\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                      background_color=color,\n                      width=2500,\n                      height=2000\n                     ).generate(cleaned_word)\n    plt.figure(1,figsize=(13, 13))\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()\n    \nprint(\"Positive reviews\")\nwordcloud_draw(reviews_1,'white')\nprint(\"Negative reviews\")\nwordcloud_draw(reviews_2)\n","6654d3db":"From the following visualization above, we can first of all notice that positive reviews are more than negative reviews. \nPositive reviews contain some key words which includes \"Great\" \"Location\" \"Staff\" \"Friendly\" \"Helpful\" e.t.c\nNegative reviews contain some key words which include \"room\" \"service\" \"Nothing\" \"problem\" e.t.c Notice that \"Negative\" there is actually represented by \"No negative\" in the main data.\nSo far, this is what i have done, its just for us to get familiar with what we are dealing with. More suggestions, corrections and contributions are welcome","85ceb71d":"# DATA PREPROCESSING","10d140fc":"Content\n\nThe csv file contains 17 fields. The description of each field is as below:\n\n1.Hotel_Address: Address of hotel.\n\nReview_Date: Date when reviewer posted the corresponding review.\n\nAverage_Score: Average Score of the hotel, calculated based on the latest comment in the last year.\n\nHotel_Name: Name of Hotel\n\nReviewer_Nationality: Nationality of Reviewer\n\nNegative_Review: Negative Review the reviewer gave to the hotel. If the reviewer does not give the negative review, then it should be: 'No Negative'\n\nReviewTotalNegativeWordCounts: Total number of words in the negative review.\n\nPositive_Review: Positive Review the reviewer gave to the hotel. If the reviewer does not give the negative review, then it should be: 'No Positive'\n\nReviewTotalPositiveWordCounts: Total number of words in the positive review.\n\nReviewer_Score: Score the reviewer has given to the hotel, based on his\/her experience\n\nTotalNumberofReviewsReviewerHasGiven: Number of Reviews the reviewers has given in the past.\n\nTotalNumberof_Reviews: Total number of valid reviews the hotel has.\n\nTags: Tags reviewer gave the hotel.\n\ndayssincereview: Duration between the review date and scrape date.\n\nAdditionalNumberof_Scoring: There are also some guests who just made a scoring on the service rather than a review. This number indicates how many valid scores without review in there.\n\nlat: Latitude of the hotel\n\nlng: longtitude of the hotel"}}