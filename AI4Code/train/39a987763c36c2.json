{"cell_type":{"60e1213a":"code","cd212d8f":"code","1b72e253":"code","550ba94d":"code","978e035a":"code","3a70dfc1":"code","9fcb8ee0":"code","5d0c7491":"code","75648d07":"code","f9a9294b":"code","2251c0eb":"code","c5411f12":"code","ea0d974b":"markdown","ef1a17cf":"markdown","61f77405":"markdown","044f8fd4":"markdown","ab556b5e":"markdown","c669171d":"markdown","16f412bd":"markdown","a21f8e09":"markdown","da1dd537":"markdown","13e93b53":"markdown","e97c55a2":"markdown","789205e8":"markdown"},"source":{"60e1213a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cd212d8f":"import os\nimport warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n%matplotlib inline","1b72e253":"data = pd.read_csv('\/kaggle\/input\/crop-recommendation-dataset\/Crop_recommendation.csv')","550ba94d":"data.isna().sum()","978e035a":"data.info()","3a70dfc1":"data.head()","9fcb8ee0":"data['label'].value_counts()","5d0c7491":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nclass Model:\n    \n    def __init__(self):\n        self.X_test=None\n        self.y_test=None\n        \n    \n    def fit_model(self,dataset,dep_var,classifier):\n        y=dataset[dep_var]\n        X=dataset.drop(columns=[dep_var],axis=1)\n        scaler = StandardScaler()\n        for col in X.columns:\n            x = np.array(X[col]).reshape(-1,1)\n            X[col]=scaler.fit_transform(x)\n        \n        X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)\n        self.X_test=X_test\n        self.y_test=y_test\n    \n        #forest = RandomForestClassifier()\n        classifier.fit(X_train,y_train)\n        return classifier\n    \n    def get_prediction(self,classifier,X_test):\n        y_pred = classifier.predict(X_test)\n        return y_pred\n    \n    def get_performance_metric(self,y_test,y_pred):\n        print(classification_report(y_test,y_pred))","75648d07":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression","f9a9294b":"m=Model()\n\nforest = RandomForestClassifier()\nmodel = m.fit_model(data,'label',forest)\ny_pred = m.get_prediction(model,m.X_test)\nm.get_performance_metric(m.y_test,y_pred)","2251c0eb":"m=Model()\n\ntree = DecisionTreeClassifier()\nmodel = m.fit_model(data,'label',tree)\ny_pred = m.get_prediction(model,m.X_test)\nm.get_performance_metric(m.y_test,y_pred)","c5411f12":"m=Model()\n\nlogit = LogisticRegression()\nmodel = m.fit_model(data,'label',logit)\ny_pred = m.get_prediction(model,m.X_test)\nm.get_performance_metric(m.y_test,y_pred)","ea0d974b":"### The different categories of the dependent variables","ef1a17cf":"### Custom class for model fitting, prediction and performance evaluation","61f77405":"### Checking if there are any missing values","044f8fd4":"### We can see that both RandomForestClassifier and DecisionTreeClassifier does a fantastic job in predicting the crop for a particular cultivation environment.","ab556b5e":"### Using LogisticRegression for fitting dataset","c669171d":"### Using RandomForestClassifier for fitting dataset","16f412bd":"### Seeing some samples of the dataset","a21f8e09":"### Let us import the required packages first","da1dd537":"### Getting an overview of the dataset","13e93b53":"### Importing the data for doing analysis","e97c55a2":"### Using DecisionTreeClassifier for fitting dataset","789205e8":"### Importing packages for predictive modelling"}}