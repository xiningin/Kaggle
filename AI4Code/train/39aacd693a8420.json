{"cell_type":{"228edc17":"code","d69982a7":"code","e9be8f98":"code","66c841ae":"code","fb392040":"code","5c44b4f2":"code","edd15f40":"code","aa941a6f":"code","da955cb7":"code","953b075b":"code","321529a4":"code","f4d36938":"code","4f4f2d5a":"markdown","c487c3af":"markdown","bfeabc02":"markdown","39d065a2":"markdown","e1117806":"markdown","6a0739e1":"markdown","f564d5db":"markdown","e5aea939":"markdown","6bb7feb7":"markdown","7602f98d":"markdown","269adb5f":"markdown","8a43aaea":"markdown","6ac0cbb8":"markdown","9ee47c4d":"markdown","bb3ff0ea":"markdown"},"source":{"228edc17":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.linear_model import LogisticRegression\n\nfrom imblearn.pipeline import Pipeline\nfrom imblearn import FunctionSampler\n\nfrom sklearn.preprocessing import LabelEncoder, RobustScaler, StandardScaler\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings\nwarnings.filterwarnings('ignore')","d69982a7":"!pip install pandas_flavor","e9be8f98":"from pandas_flavor import register_dataframe_method,register_series_method\nfrom IPython.core.display import display, HTML\n\n@register_dataframe_method\ndef get_missing(df):        \n    tmp =  sorted(\n                [(col , str(df[col].dtypes) ,df[col].isna().sum(), np.round( df[col].isna().sum() \/ len(df) * 100,2) ) for col in df.columns if df[col].isna().sum() !=0 ],\n                key = lambda x: x[2], reverse=True)\n    \n    return pd.DataFrame(tmp).rename({0:\"Feature\", 1:\"dtype\", 2:\"count\", 3:\"percent\"},axis=1)  \n\n@register_dataframe_method\ndef get_numeric_df(df):\n    return df.select_dtypes(np.number)\n\n@register_dataframe_method\ndef get_numeric_cols(df):\n    return list(df.select_dtypes(np.number).columns)\n\n@register_dataframe_method\ndef get_object_cols(df):\n    return list(df.select_dtypes(exclude = np.number).columns)\n\n@register_dataframe_method\ndef get_object_df(df):\n    return df.select_dtypes(exclude = np.number)\n\n@register_dataframe_method\ndef get_discrete_cols(df,thresold):\n#     thresold in number of unique values\n    return [feature for feature in df.columns if len(df[feature].unique()) < thresold]\n\n@register_dataframe_method\ndef get_discrete_df(df,thresold):\n#     thresold in number of unique values\n    return df[ get_discrete_cols(df=df,thresold=thresold) ]\n\n@register_dataframe_method\ndef describe_discrete_cols(df,thresold, ascending=True):\n    \n    values = pd.DataFrame()\n    \n    for col in df.get_discrete_cols(thresold=thresold):\n        values[col] = [df[col].unique(), df[col].nunique()]\n        \n    return values.transpose().sort_values(by = 1,ascending=ascending).rename({0:\"Values\",1:\"cardinality\"},axis=1)\n\n@register_dataframe_method\ndef get_continuous_cols(df,thresold):\n    #     thresold in number of unique values\n    return [feature for feature in df.columns if len(df[feature].unique()) >= thresold]\n\n@register_dataframe_method\ndef get_continuous_df(df,thresold):\n    #     thresold in number of unique values\n    return df[ get_continuous_cols(df=df,thresold=thresold) ]\n\n\n@register_dataframe_method\ndef describe_continuous_cols(df,thresold, ascending=True):\n    return df[df.get_continuous_cols(thresold=thresold)].describe().T\n\n@register_dataframe_method\ndef dtypes_of_cols(df):\n    return pd.DataFrame(df.dtypes).reset_index().rename(columns={'index':\"Columns\",0: \"dtype\"})\n\n\n@register_series_method\ndef IQR_range(df):\n    if isinstance(df, pd.Series):\n        Q3 = np.quantile(df, 0.75)\n        Q1 = np.quantile(df, 0.25)\n        IQR = Q3 - Q1\n\n        lower_range = Q1 - 1.5 * IQR\n        upper_range = Q3 + 1.5 * IQR\n\n        return (lower_range,upper_range)\n    else:\n        assert False, \"df must be of type pandas.Series\"\n        \n@register_dataframe_method\ndef IQR_range(df):\n    if isinstance(df, pd.DataFrame):\n        cols = df.get_numeric_cols()\n        features = {}\n        for i in cols:\n            Q3 = np.quantile(df[i], 0.75)\n            Q1 = np.quantile(df[i], 0.25)\n            IQR = Q3 - Q1\n\n            lower_range = Q1 - 1.5 * IQR\n            upper_range = Q3 + 1.5 * IQR\n\n\n            features[i] = (lower_range,upper_range)\n            \n        return pd.DataFrame.from_dict(features,orient='index').rename({0: 'IQR_Low',1: 'IQR_High'}, axis=1)\n    else:\n        assert False, \"df must be of type pandas.DataFrame\"\n        \n@register_series_method\ndef IQR_percent(df):\n    if isinstance(df, pd.Series):\n        \n        lower_range, upper_range = df.IQR_range()\n\n        length = len(df)\n        return np.round((length - df.between(lower_range,upper_range).sum())\/length * 100, 2)\n    else:\n        assert False, \"df must be of type pandas.Series\"\n\n@register_dataframe_method\ndef IQR_percent(df):\n    if isinstance(df, pd.DataFrame):\n        cols = df.get_numeric_cols()\n        features = {}\n        for i in cols:\n            lower_range, upper_range = df[i].IQR_range()\n\n            length = len(df[i])\n            tmp = np.round((length - df[i].between(lower_range,upper_range).sum())\/length * 100, 2)\n            if tmp != 0:\n                features[i] = tmp\n#             features[i] = IQR_percent(df[i])\n            \n        return pd.DataFrame.from_dict(features,orient='index').rename({0: 'Outlier percent'}, axis=1)\n    else:\n        assert False, \"df must be of type pandas.DataFrame\"\n\n@register_dataframe_method\ndef get_outlier_cols(df):\n    return df.IQR_percent().reset_index()[\"index\"].to_list()\n        \n@register_dataframe_method\ndef drop_row_outlier(df, cols, inplace=False):\n#     init empty index\n    indices = pd.Series(np.zeros(len(df), dtype=bool), index=df.index)\n\n    for col in cols:\n        low, top = df[col].IQR_range()\n        indices |= (df[col] > top) | (df[col] < low)\n        \n    \n    return df.drop(df[ indices ].index, inplace=inplace)\n\n@register_series_method\ndef drop_row_outlier(df, inplace=False):\n#     init empty index\n\n    low, top = df.IQR_range()\n    indices = (df > top) | (df < low)\n        \n    \n    return df.drop(df[ indices ].index, inplace=inplace)\n        \n@register_dataframe_method\ndef compare_cols(df,l_feat,r_feat, percent=False, percent_of_total=False):\n    \n#     [L_feat] {R_feat1: agg1, R_feat2: agg2}\n\n    \n    if percent or percent_of_total:\n        \n        comp = []\n        for key, val in zip(r_feat,r_feat.values()):\n            tmp = pd.DataFrame()\n            tmp[key + \" \" + val] =  df.groupby(l_feat,sort=True).agg({key: val})\n            \n            if percent: tmp[key +\" %\"] = tmp.groupby(level=0).apply(lambda x: np.round(100 * x \/ float(x.sum()),2))\n\n            if percent_of_total: tmp[key+\" % of total\"] = np.round(tmp[key + \" \" + val] \/ tmp[key + \" \" + val].sum() * 100 , 2)\n            \n            comp.append(tmp)\n            \n        return comp\n    \n    else:\n        comp = []\n        for key, val in zip(r_feat,r_feat.values()):\n            tmp = pd.DataFrame()\n            tmp[key + \" \" + val] =  df.groupby(l_feat,sort=True).agg({key: val})           \n            comp.append(tmp)\n            \n        return comp  \n    \n    \n\n@register_dataframe_method\ndef count_dtypes(df, ascending=False):\n    return pd.DataFrame(df.dtypes.value_counts(ascending=ascending)).rename({0:\"Count\"},axis=1)\n\n@register_dataframe_method\ndef about(df):\n\n    display(HTML('<h1 style=\"color:green\"> <b> Shape of data <\/b> <\/h1>'))\n    print(df.shape)    \n\n    display(HTML('<h1 style=\"color:green\"> <b> Datatypes in data <\/b> <\/h1> '))\n    display(pd.DataFrame(df.dtypes.value_counts(ascending=False) ).rename({0:\"count\"},axis=1))\n\n    display(HTML('<h1 style=\"color:green\"> <b> dtypes of columns <\/b> <\/h1> '))\n    display(df.dtypes_of_cols())\n\n    display(HTML('<h1 style=\"color:green\"> <b> Percentage of missing values <\/b> <\/h1> '))\n    tmp = get_missing(df)\n    display(tmp) if len(tmp) != 0 else display(HTML(\"<h2> <b> None <b> <\/h2>\"))\n\n    display(HTML('<h1 style=\"color:green\"> <b> Data description <\/b> <\/h1> '))\n    display(df.describe().T)\n    \n    display(HTML('<h1 style=\"color:green\"> <b> Outlier Percentage(IQR) <\/b> <\/h1> '))\n    tmp = df.IQR_percent()\n    display(tmp) if len(tmp) != 0 else display(HTML(\"<h2> <b> None <b> <\/h2>\"))\n\n    display(HTML('<h1 style=\"color:green\"> <b> Example of data <\/b> <\/h1> '))\n    display(df.head())","66c841ae":"df = pd.read_csv(\"..\/input\/iris\/Iris.csv\")\ndf.drop(\"Id\", axis=1, inplace=True)\ndf.about()","fb392040":"df.drop_row_outlier(cols=[\"SepalWidthCm\"], inplace=True)","5c44b4f2":"X = df.drop(\"Species\", axis=1)\ny = df[\"Species\"]","edd15f40":"scaler = StandardScaler()\nX = scaler.fit_transform(X)","aa941a6f":"le = LabelEncoder()\n\ny = le.fit_transform(y)\ny","da955cb7":"lr = LogisticRegression()\n\nscores = cross_val_score(lr, X,y, scoring=\"accuracy\", cv=10)\nprint(f\"Accuracy {np.round( scores.mean()*100,2) :>5}  Standard dev {np.round( scores.std()*100,2) :>5}\")","953b075b":"df = pd.read_csv(\"..\/input\/iris\/Iris.csv\")\ndf.drop(\"Id\", axis=1, inplace=True)\n\nX = df.drop(\"Species\", axis=1)\ny = df[\"Species\"]\n\nle = LabelEncoder()\ny = pd.Series(le.fit_transform(y))","321529a4":"def CustomSampler_IQR (X, y):\n    features = list(X.columns)\n\n    df = X.copy()\n    df['Outcome'] = y\n    \n    indices = [x for x in df.index]    \n    out_indexlist = []\n        \n    for col in features:\n        Q3 = np.quantile(X[col], 0.75)\n        Q1 = np.quantile(X[col], 0.25)\n        IQR = Q3 - Q1\n        upper = Q3 + (1.5 * IQR)\n        lower = Q1 - (1.5 * IQR)\n\n        outliers_index = df[col][(df[col] < lower) | (df[col] > upper)].index.tolist()\n        outliers = df[col][(df[col] < lower) | (df[col] > upper)].values        \n        out_indexlist.extend(outliers_index)\n        \n    #using set to remove duplicates\n    out_indexlist = list(set(out_indexlist))\n    \n    clean_data = np.setdiff1d(indices,out_indexlist)\n\n    return X.loc[clean_data], y.loc[clean_data]\n\n# CustomSampler_IQR(X,y, )","f4d36938":"model_pipeline = Pipeline([('Outlier_removal', FunctionSampler(func=CustomSampler_IQR, validate = False)),\n                        (\"Scaling\", StandardScaler()),\n                        ('LR',  LogisticRegression())])\n\nscores = cross_val_score(model_pipeline, X,y, scoring=\"accuracy\", cv=10)\nprint(f\"Accuracy {np.round( scores.mean()*100,2) :>5}  Standard dev {np.round( scores.std()*100,2) :>5}\")","4f4f2d5a":"- [How to Prevent the Data Leakage ?](https:\/\/www.kaggle.com\/kaanboke\/how-to-prevent-the-data-leakage)\n- https:\/\/www.youtube.com\/watch?v=irHhDMbw3xo\n- https:\/\/www.youtube.com\/watch?v=DHxsNrL7Zfw\n- https:\/\/machinelearningmastery.com\/modeling-pipeline-optimization-with-scikit-learn\/\n- https:\/\/towardsdatascience.com\/how-to-use-sklearn-pipelines-for-ridiculously-neat-code-a61ab66ca90d","c487c3af":"## Fit model","bfeabc02":"Clearly it was a lot of work and typing, prone to error, and definitely not scalable(reusable) and potential data leakage.\n\nMost importantly it is easy to loose track of what is going on.\n\nDid you observe a pattern to the above workflow??\n<br><br>\nwe applied all the operations in series i.e, one after the other. The output of each stage was the input to the next one (its like using pipes in linux\/unix shell).\n\nIn other words pipeline is based on the above concept, instead of we creating and over writing the data for each operation, pipeline does all the work for us, making the code ridiculously intuitive and easy to manage.\n<br><br><br>\nNow lets build a pipeline in an intuitive way.\n\nFirst lets import the data, and define a helper function to deal with outliers.","39d065a2":"# Resources\/ Referances","e1117806":"The general work flow of any ML task is\n1. Handle missing values if any (none here)\n2. Handle outliers\n3. Scale columns\n4. Encode\n5. Try various models\n\nlets execute each step one by one.","6a0739e1":"# Pipeline way","f564d5db":"## Handle outliers","e5aea939":"## Scaling columns","6bb7feb7":"# Pandas","7602f98d":"# Load data","269adb5f":"## Encoding values","8a43aaea":"# Conventional way","6ac0cbb8":"Note: here the output column is binary discrete variable, which means its not going to make a difference if we encode it in the pipeline or pass the encoded value directly. For simplicity sake lets pass the encoded value directly.\n<br><br>\nNow lets build the pipeline in an intuitive way. From the above steps discussed earlier, the flow is as following\n\n**Data(X,y) ---> Outlier Removal ---> Feature Scaling ---> Train model**\n\nthis is the exact same thing we have defined below!\n\nwe then pass this pipeline into cross validation for training ","9ee47c4d":"# Imports","bb3ff0ea":"# Introduction\n\nIn this notebook I have tried to show you the power, simplicity and elegance of using pipeline in machine learning workflow.\n\nThere are many reasons to use pipeline over conventional methods, here are a few\n- Simple code base\n- less prone to error\n- no data leakage \n- more accurate models\n\nLets first address the elephant in the room, **Data Leakage**\n\nSo what is Data Leakage!? data leaking away like water from a pipe!?\n\n**YESSS!!**\n\nLet me give you an over simplified explanation. Consider you are handelling missing values, say you are replacing with average value for the whole CSV file(the whole data). \n\nThe formula for average is  $$\\text{sum of all rows} \\over \\text{number of rows}$$\n\nBut here is the catch, you are inherantly using testing data, which means information\/data has **\"Leaked\"** from testing data to traing data. Which effectively means the model has seen the testing data, and it is obviously not a accurate representation. \n\nIt is like leaking a math question paper just before the day of exam. Which obviously means you are going to prepare using the leaked question paper and not going to study the whole thing.\n\nIn real life you have trainig data and validaiton data. You will not have a chance to view the validation data until you train the model and deploy it. So for accurete representation\/training we use pipeline.\n\nIn a world without pipeline, you had to **MANUALLY** split the data 10 folds (assuming 10 fold cross validation), do the processing to 1-9 folds and the 10th fold **separately**, train the model, and repeat this whole thig **9** times for all the folds and get the average accuracy.\n\nBut surprise! surprise! we don't live in such a world. we have pipelines which does all the above work for us with hardly few lines of code!.\nPipeline is just another layer of abstraction on top of the model, whose sole job is to make the code accurate and clean.\n\nIn this notebook I have considered Iris dataset for sake of simplicity, the same concept applies to all the complicated models with a lot more features!\n\n### If you found this notebook helpful, drop in a upvote! and feedback in the comments!!\n"}}