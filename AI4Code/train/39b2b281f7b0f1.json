{"cell_type":{"6500a208":"code","207dee30":"code","e13458ee":"code","16b312a3":"code","f2f0c7b1":"code","4a4eb1a0":"code","23054e61":"code","8aef69a3":"code","c421d855":"code","d997c5de":"code","8c8d668b":"code","b10da823":"code","8785c922":"code","18a09a5c":"code","06f074a2":"code","cc497b17":"code","2da10a47":"code","444507aa":"code","cb4fd208":"code","cf217b04":"code","1b81569a":"code","d712901c":"code","f303282d":"code","7d87eb6f":"code","af21d226":"code","cab6f139":"code","5a1faba0":"code","45c2968d":"code","ad03e198":"code","fdebaabb":"code","b27d0b86":"code","1c4da52f":"code","4f4801d3":"code","744bb984":"code","8aad67d9":"code","65020d65":"code","485c96e2":"code","f168d2ae":"code","30d9f415":"markdown","2f10c603":"markdown","0801c7a2":"markdown","4c865f75":"markdown","0f10daa4":"markdown","d91c2745":"markdown","b7a9dce8":"markdown","43a527af":"markdown","5891a76b":"markdown","ac86b4eb":"markdown","8e91d1cb":"markdown","48702541":"markdown","02ea2493":"markdown","34a57f4f":"markdown","b9f5c11c":"markdown"},"source":{"6500a208":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import log_loss\nimport xgboost as xgb\nimport lightgbm as lgb","207dee30":"DAT_DIR = '..\/input\/tabular-playground-series-jun-2021'\ntrain_df = pd.read_csv(os.path.join(DAT_DIR, 'train.csv'))\ntest_df = pd.read_csv(os.path.join(DAT_DIR, 'test.csv'))\nsample_submit = pd.read_csv(os.path.join(DAT_DIR, 'sample_submission.csv'))","e13458ee":"train_df.head()","16b312a3":"train_df.shape","f2f0c7b1":"train_df.dtypes.value_counts()","4a4eb1a0":"num_cols = [c for c in train_df.columns if train_df[c].dtype != 'object']\nprint('num_cols = \\n', num_cols)\ntarget_col = [c for c in train_df.columns if c not in num_cols][0]\nprint('target_col = ', target_col)","23054e61":"train_df[num_cols].agg(['min', 'mean', 'max'])","8aef69a3":"train_df[target_col].value_counts()","c421d855":"seed = 123\ntr_X, te_X, tr_y, te_y = train_test_split(train_df[num_cols], train_df[target_col], test_size=0.3, stratify=train_df['target'], random_state=seed)\nva_X, te_X, va_y, te_y = train_test_split(te_X, te_y, test_size=0.5, stratify=te_y, random_state=seed)","d997c5de":"print(f'tr_X.shape = {tr_X.shape}; tr_y.shape = {tr_y.shape}')\nprint(f'va_X.shape = {va_X.shape}; va_y.shape = {va_y.shape}')\nprint(f'te_X.shape = {te_X.shape}; te_y.shape = {te_y.shape}')","8c8d668b":"le = LabelEncoder()\nle.fit(tr_y)\ntr_y_tr = le.transform(tr_y)\nva_y_tr = le.transform(va_y)\nte_y_tr = le.transform(te_y)","b10da823":"num_classes = len(le.classes_)\nprint(f'num_classes = {num_classes}')\nprint(f'Frequency of the classes:\\n{pd.Series(tr_y_tr).value_counts()}')","8785c922":"xgb_clf = xgb.XGBClassifier(objective='multi:softmax',\n                            use_label_encoder=False,\n                            booster='gbtree',\n                            n_jobs=10,\n                            random_state=123,\n                            learning_rate = 0.3,\n                            max_depth=5,\n                            eval_metric='mlogloss')","18a09a5c":"xgb_clf.fit(tr_X, tr_y_tr,\n           eval_set=[(tr_X, tr_y_tr), (va_X, va_y_tr)],\n           early_stopping_rounds=30,\n           verbose=10)","06f074a2":"te_y_pred = xgb_clf.predict(te_X)","cc497b17":"pd.Series(te_y_pred).value_counts()","2da10a47":"te_yprob_pred = xgb_clf.predict_proba(te_X)","444507aa":"print(f'logloss = {round(log_loss(te_y, te_yprob_pred),3)}')","cb4fd208":"lgb_clf = lgb.LGBMClassifier(max_depth=20,\n                             num_leaves=30,\n                             learning_rate=0.05,\n                             objective='multiclass',\n                             random_state=123,\n                             n_jobs=10)","cf217b04":"lgb_clf.fit(tr_X, tr_y_tr,\n           eval_set=[(tr_X, tr_y_tr), (va_X, va_y_tr)],\n           eval_names=['Training', 'Validation'],\n           eval_metric='multi_logloss',\n           early_stopping_rounds=30,\n           verbose=10)","1b81569a":"te_y_pred = lgb_clf.predict(te_X)","d712901c":"pd.Series(te_y_pred).value_counts()","f303282d":"te_yprob_pred = lgb_clf.predict_proba(te_X)","7d87eb6f":"print(f'logloss = {round(log_loss(te_y, te_yprob_pred),3)}')","af21d226":"vote_clf = VotingClassifier(estimators=[('xgb', xgb_clf), ('lgb', lgb_clf)],\n                           voting='soft')","cab6f139":"vote_clf.fit(tr_X, tr_y_tr)","5a1faba0":"te_yprob_pred = vote_clf.predict_proba(te_X)","45c2968d":"print(f'logloss = {round(log_loss(te_y, te_yprob_pred),3)}')","ad03e198":"xgb_clf.fit(train_df[num_cols], \n            le.transform(train_df[target_col]),\n            eval_set=[(train_df[num_cols], le.transform(train_df[target_col]))],\n            early_stopping_rounds=30,\n            verbose=10)","fdebaabb":"lgb_clf.fit(train_df[num_cols], \n            le.transform(train_df[target_col]),\n            eval_set=[(train_df[num_cols], le.transform(train_df[target_col]))],\n            eval_names=['Training'],\n            eval_metric='multi_logloss',\n            early_stopping_rounds=30,\n            verbose=10)","b27d0b86":"vote_clf = VotingClassifier(estimators=[('xgb', xgb_clf), ('lgb', lgb_clf)],\n                           voting='soft')","1c4da52f":"vote_clf.fit(train_df[num_cols],\n            le.transform(train_df[target_col]))","4f4801d3":"test_yprob_pred = vote_clf.predict_proba(test_df[num_cols])","744bb984":"test_yprob_classes = le.inverse_transform(range(num_classes))","8aad67d9":"test_yprob_classes","65020d65":"out_yprob_df = pd.DataFrame(test_yprob_pred, columns=test_yprob_classes)","485c96e2":"out_df = pd.concat([sample_submit['id'], out_yprob_df], axis=1)","f168d2ae":"out_df.to_csv('submission.csv', index=None, float_format='%.4f')","30d9f415":"### Pooling Model","2f10c603":"#### Voting Classifier","0801c7a2":"In this section, we will use XGBoost to build a quick model.","4c865f75":"### XGB","0f10daa4":"Let's retrain the model with all training data and predict on the test.","d91c2745":"In this section, we will use LightGBM to build a quick model.","b7a9dce8":"### Output","43a527af":"## Prototype models","5891a76b":"In this section, we will use several methods to build a few prototype models. Before this, we will divide the training data into train, validation and test subsets.","ac86b4eb":"We will try a few meta estimator to improve the model performance.","8e91d1cb":"The previous analysis shows the training data has all numerical variables and 1 categorical target.","48702541":"The variable distributions are similar and have similar long tails on the right end.","02ea2493":"# Tabular Playground Series Jun 2021","34a57f4f":"### LightGBM","b9f5c11c":"The distribution of target variables are quite diverse."}}