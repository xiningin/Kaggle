{"cell_type":{"22be59a7":"code","92a217b0":"code","da98b113":"code","108934a5":"code","3f71ae87":"code","12873905":"code","6b370bbf":"code","ecb805f6":"code","383e4c8c":"code","34b3ec93":"code","2af446ad":"code","fa575b6f":"code","4b8aa4d3":"code","ea48ccad":"code","ff088909":"markdown","d8973f68":"markdown","3e215018":"markdown","742de58c":"markdown","724b03ca":"markdown","629b67ba":"markdown"},"source":{"22be59a7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport plotly.express as px\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport tensorflow as tf\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","92a217b0":"print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","da98b113":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","108934a5":"train_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255.,\n    horizontal_flip=True,\n    zoom_range=0.2,\n    vertical_flip=True,\n    rotation_range=20,\n)\n\ntest_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255.,\n)","3f71ae87":"# Note: batch_size can be turned for your respective compute resources\n\ntrain_ds = train_data_gen.flow_from_directory(\n    directory='\/kaggle\/input\/intel-image-classification\/seg_train\/seg_train\/',\n    target_size=(150,150),\n    class_mode='categorical',\n    color_mode='grayscale',\n    batch_size=32,\n    shuffle=True\n)\n\ntest_ds = train_data_gen.flow_from_directory(\n    directory='\/kaggle\/input\/intel-image-classification\/seg_test\/seg_test\/',\n    target_size=(150,150),\n    class_mode='categorical',\n    color_mode='grayscale',\n    batch_size=32\n)","12873905":"def build_cnn():\n\n    model = tf.keras.Sequential([\n        tf.keras.layers.Conv2D(32, kernel_size=(3,3), input_shape=(150, 150, 1), activation='relu'),\n        tf.keras.layers.MaxPool2D(),\n\n        tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n        tf.keras.layers.MaxPool2D(),\n\n        tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n        tf.keras.layers.MaxPool2D(),\n\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.Dense(128, activation='relu'),\n        \n        tf.keras.layers.Dense(6, activation='softmax')\n    ])\n\n    return model","6b370bbf":"model = build_cnn()\n\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy']\n             )","ecb805f6":"model.summary()","383e4c8c":"# save model after every epoch\nmodel_save_loc='seg_clf-cnn'\n\n# optional: can save each model, regardless or performance via the below lines. ('epoch' & 'val_accuracy') are passed internally by keras\n# model_save_loc = seg_clf-cnn_models\/cnn_seg_clf-{epoch:02d}---{val_accuracy:.4f}'\n\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    monitor='val_accuracy',\n    filepath=model_save_loc,\n    save_best_only=True)","34b3ec93":"# early stopping for model training\nearlystop = tf.keras.callbacks.EarlyStopping('val_accuracy', patience=5, restore_best_weights=True)","2af446ad":"history = model.fit(train_ds, epochs=30, validation_data=test_ds, callbacks=[model_checkpoint_callback, earlystop])","fa575b6f":"df = pd.DataFrame(history.history)\ndf['epoch'] = list(df.index)","4b8aa4d3":"fig = px.line(df, x='epoch', y=['loss', 'val_loss'])\nfig.update_layout(\n    title=\"Loss Curve by Epoch\",\n    font=dict(\n        size=14,\n    )\n)\nfig.show()","ea48ccad":"fig = px.line(df, x='epoch', y=['accuracy', 'val_accuracy'], title='Accuracy by Epoch')\nfig.show()","ff088909":"# Simple CNN using Keras - 81% Accuracy on Test Data\n\nThis tutorial demonstrates:\n* ImageDataGenerator API\n* building simple CNN using Keras API\n* Model checkpoints for saving models during training\n* Ploting & evaluation the training Loss\n","d8973f68":"**Optimizations**\n* change optimizer & learning rate\n* try different batchsizes\n* try batch normalization\n* add more\/less transformations to ImageDataGenerator\n* model architecture\n                \n                \n**Transfer Learning - Use a pretrained model and retrain dense layer(s)**\n* Can use learned features from models\n* These models have been trained on much more data and for much longer\n* More of a fine tuning step to fit it to this use case","3e215018":"## Image Transformations\n\nExpand training set by adding transformations to the training data.\nNote: This does not increase the total number of training samples, it just\ntransforms each image (in memory at each epoch) so the model never sees the same input image\n\nThe reason for doing this is:\n\n1. there may be some features in the entire problem space\nthat are not accounted for in the training set. By transforming images, we can potentially a larger\nportion of the problem space\n\n2. Prevent the network from memorizing the training set\n","742de58c":"# Train the Network","724b03ca":"# Loss & Accuracy Curves\n\n**The Loss curve shows the model is reaching convergence but isn't quite there yet. We can continue training util convergence but I'm greedy with my GPU quota :)**\n\n","629b67ba":"## Callbacks\n\nCallbacks enable us to save models during training for many reasons.\n\nThe idea is that the best parameters (weights & biases) may not be yielded from the last epoch's training. Therefore,\nwe can save model after each epoch, or just always save the best model to some persistent storage\n\n**tf.keras.callbacks.ModelCheckpoint** - save model after each epoch\n\n**tf.keras.callbacks.EarlyStopping** - preemptively stop training based on some user defined criteria"}}