{"cell_type":{"e027b36f":"code","63a810b6":"code","d3204121":"code","05d99497":"code","c1305ba5":"code","ff6c7bdf":"code","1de6bb8b":"code","8c0538ee":"code","5cc6d534":"code","0bfe94c0":"code","ff7933b7":"code","ce744f35":"code","f9b7e896":"code","f81f0c3e":"code","3f68e87a":"markdown","fe9d029d":"markdown","22d4b866":"markdown","22b5a4bd":"markdown","eb77e4c1":"markdown","8a5c9999":"markdown"},"source":{"e027b36f":"!pip install '..\/input\/pytorch-190\/torch-1.9.0+cu111-cp37-cp37m-linux_x86_64.whl' --no-deps\n# !pip install '..\/input\/pytorch-190\/torchvision-0.10.0+cu111-cp37-cp37m-linux_x86_64.whl' --no-deps","63a810b6":"!rm -rf mmdetection\n!git clone https:\/\/github.com\/open-mmlab\/mmdetection.git \/kaggle\/working\/mmdetection","d3204121":"!pip install openmim\n!mim install mmdet","05d99497":"# import sys\n# sys.path.append('.\/mmdetection')\n\nimport numpy as np\nimport os\nimport pandas as pd\n\nimport mmdet\nimport mmcv\n\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector\nfrom mmcv import Config\nfrom mmdet.apis import inference_detector, init_detector, set_random_seed","c1305ba5":"seed = 3047\nset_random_seed(seed, deterministic=False)","ff6c7bdf":"import zipfile\n\nos.makedirs('.\/images') \nwith zipfile.ZipFile('..\/input\/simple-yolox-dataset-generator-coco-json\/train2017.zip', 'r') as zip_ref:\n    zip_ref.extractall('.\/images')\n    \nwith zipfile.ZipFile('..\/input\/simple-yolox-dataset-generator-coco-json\/val2017.zip', 'r') as zip_ref:\n    zip_ref.extractall('.\/images')","1de6bb8b":"%%writefile labels.txt \ncots","8c0538ee":"%%writefile .\/mmdetection\/configs\/swin\/TFGBR_swin_base_faster_rcnn_fp16.py\n\n_base_ = [\n    '..\/_base_\/models\/cascade_rcnn_r50_fpn.py',\n    '..\/_base_\/datasets\/coco_detection.py',\n    '..\/_base_\/schedules\/schedule_1x.py', '..\/_base_\/default_runtime.py'\n]\npretrained = 'https:\/\/github.com\/SwinTransformer\/storage\/releases\/download\/v1.0.0\/swin_small_patch4_window7_224.pth'\nmodel = dict(\n    backbone=dict(\n        _delete_=True,\n        type='SwinTransformer',\n        embed_dims=96,\n        depths=[2, 2, 18, 2],\n        num_heads=[3, 6, 12, 24],\n        window_size=7,\n        mlp_ratio=4,\n        qkv_bias=True,\n        qk_scale=None,\n        drop_rate=0.,\n        attn_drop_rate=0.,\n        drop_path_rate=0.3,\n        patch_norm=True,\n        out_indices=(0, 1, 2, 3),\n        with_cp=False,\n        convert_weights=True,\n        init_cfg=dict(type='Pretrained', checkpoint=pretrained)),\n    neck=dict(in_channels=[96, 192, 384, 768]),\n    roi_head=dict(\n        type='CascadeRoIHead',\n        num_stages=3,\n        stage_loss_weights=[1, 0.5, 0.25],\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        bbox_head=[\n            dict(\n                type='Shared2FCBBoxHead',\n                in_channels=256,\n                fc_out_channels=1024,\n                roi_feat_size=7,\n                num_classes=1,\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    target_means=[0., 0., 0., 0.],\n                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n                reg_class_agnostic=True,\n                loss_cls=dict(\n                    type='CrossEntropyLoss',\n                    use_sigmoid=False,\n                    loss_weight=1.0),\n                reg_decoded_bbox=True,\n                loss_bbox=dict(type='GIoULoss', loss_weight=10.0)),\n            dict(\n                type='Shared2FCBBoxHead',\n                in_channels=256,\n                fc_out_channels=1024,\n                roi_feat_size=7,\n                num_classes=1,\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    target_means=[0., 0., 0., 0.],\n                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n                reg_class_agnostic=True,\n                loss_cls=dict(\n                    type='CrossEntropyLoss',\n                    use_sigmoid=False,\n                    loss_weight=1.0),\n                reg_decoded_bbox=True,\n                loss_bbox=dict(type='GIoULoss', loss_weight=10.0)),\n            dict(\n                type='Shared2FCBBoxHead',\n                in_channels=256,\n                fc_out_channels=1024,\n                roi_feat_size=7,\n                num_classes=1,\n                bbox_coder=dict(\n                    type='DeltaXYWHBBoxCoder',\n                    target_means=[0., 0., 0., 0.],\n                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n                reg_class_agnostic=True,\n                loss_cls=dict(\n                    type='CrossEntropyLoss',\n                    use_sigmoid=False,\n                    loss_weight=1.0),\n                reg_decoded_bbox=True,\n                loss_bbox=dict(type='GIoULoss', loss_weight=10.0))\n        ]))\n\noptimizer = dict(\n    _delete_=True,\n    type='AdamW',\n    lr=0.0004,\n    betas=(0.9, 0.999),\n    weight_decay=0.05,\n    paramwise_cfg=dict(\n        custom_keys={\n            'absolute_pos_embed': dict(decay_mult=0.),\n            'relative_position_bias_table': dict(decay_mult=0.),\n            'norm': dict(decay_mult=0.)\n        }))\nlr_config = dict(warmup_iters=500, step=[8, 11])\nrunner = dict(max_epochs=14)","5cc6d534":"cfg = Config.fromfile('.\/mmdetection\/configs\/swin\/TFGBR_swin_base_faster_rcnn_fp16.py')","0bfe94c0":"img_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile',to_float32=True),\n    dict(type='LoadAnnotations', with_bbox=True),\n    dict(\n        type='AutoAugment',\n        policies=[[\n            dict(\n                type='Resize',\n                img_scale=[(480, 1333), (512, 1333), (544, 1333), (576, 1333),\n                           (608, 1333), (640, 1333), (672, 1333), (704, 1333),\n                           (736, 1333), (768, 1333), (800, 1333)],\n                multiscale_mode='value',\n                keep_ratio=True)\n        ],\n                  [\n                      dict(\n                          type='Resize',\n                          img_scale=[(400, 1333), (500, 1333), (600, 1333)],\n                          multiscale_mode='value',\n                          keep_ratio=True),\n                      dict(\n                          type='RandomCrop',\n                          crop_type='absolute_range',\n                          crop_size=(384, 600),\n                          allow_negative_crop=True),\n                      dict(\n                          type='Resize',\n                          img_scale=[(480, 1333), (512, 1333), (544, 1333),\n                                     (576, 1333), (608, 1333), (640, 1333),\n                                     (672, 1333), (704, 1333), (736, 1333),\n                                     (768, 1333), (800, 1333)],\n                          multiscale_mode='value',\n                          override=True,\n                          keep_ratio=True),\n                      dict(\n                            type='PhotoMetricDistortion',\n                            brightness_delta=32,\n                            contrast_range=(0.5, 1.5),\n                            saturation_range=(0.5, 1.5),\n                            hue_delta=18),\n                    dict(\n                            type='MinIoURandomCrop',\n                            min_ious=(0.4, 0.5, 0.6, 0.7, 0.8, 0.9),\n                            min_crop_size=0.3),\n                    dict(\n                            type='CutOut',\n                            n_holes=(5, 10),\n                            cutout_shape=[(4, 4), (4, 8), (8, 4), (8, 8),\n                                          (16, 32), (32, 16), (32, 32),\n                                          (32, 48), (48, 32), (48, 48)]\n                            )\n                  ]]),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),\n]\n\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(1333, 800),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(type='Normalize', **img_norm_cfg),\n            dict(type='Pad', size_divisor=32),\n            dict(type='DefaultFormatBundle'),\n            dict(type='Collect', keys=['img'])\n        ])\n]","ff7933b7":"cfg.classes = '\/kaggle\/working\/labels.txt'\ncfg.work_dir = '\/kaggle\/working\/model_output'\ncfg.data_root = '\/kaggle\/working'\n\n# for head in cfg.model.roi_head.bbox_head:\n#     head.num_classes = 1\n\ncfg.data.test.type = 'CocoDataset'\ncfg.data.test.classes = 'labels.txt'\ncfg.data.test.ann_file = '..\/input\/simple-yolox-dataset-generator-coco-json\/annotations_valid.json'\ncfg.data.test.img_prefix = '.\/images'\n\ncfg.data.train.type = 'CocoDataset'\ncfg.data.train.ann_file = '..\/input\/simple-yolox-dataset-generator-coco-json\/annotations_train.json'\ncfg.data.train.img_prefix = '.\/images'\ncfg.data.train.classes = 'labels.txt'\n\ncfg.data.val.type = 'CocoDataset'\ncfg.data.val.ann_file = '..\/input\/simple-yolox-dataset-generator-coco-json\/annotations_valid.json'\ncfg.data.val.img_prefix = '.\/images'\ncfg.data.val.classes = 'labels.txt'\n\ncfg.data.samples_per_gpu = 2\ncfg.data.workers_per_gpu = 2\n\ncfg.train_pipeline = train_pipeline\ncfg.val_pipeline = test_pipeline\ncfg.test_pipeline = test_pipeline\n\ncfg.data.train.pipeline = cfg.train_pipeline\ncfg.data.val.pipeline = cfg.val_pipeline\ncfg.data.test.pipeline = cfg.test_pipeline \n\ncfg.lr_config = dict(\n    policy='CosineAnnealing', \n    by_epoch=False,\n    warmup='linear', \n    warmup_iters= 1000, \n    warmup_ratio= 1\/10,\n    min_lr=1e-07)\n\ncfg.evaluation.interval = 2\ncfg.evaluation.save_best='auto'\n\ncfg.seed = seed\ncfg.gpu_ids = range(1)\n\ncfg.fp16 = dict(loss_scale=dict(init_scale=512.))\n\ncfg.log_config = dict(\n    interval=100,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        dict(type='TensorboardLoggerHook')\n    ])\n\nmeta = dict()\nmeta['config'] = cfg.pretty_text","ce744f35":"datasets = [build_dataset(cfg.data.train)]\nmodel = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\nmodel.init_weights()\nmodel.CLASSES = datasets[0].CLASSES","f9b7e896":"mmcv.mkdir_or_exist(os.path.abspath(cfg.work_dir))\ntrain_detector(model, datasets, cfg, distributed=False, validate=True, meta = meta)","f81f0c3e":"import shutil\nshutil.rmtree('.\/mmdetection')\nshutil.rmtree('.\/images')","3f68e87a":"# **Import Libraries** ","fe9d029d":"# **Helper Functions**","22d4b866":"## Reference \n\n1. MMDetection Inspired Notebooks:\n    1. https:\/\/www.kaggle.com\/awsaf49\/sartorius-mmdetection-train\n    1. https:\/\/www.kaggle.com\/its7171\/mmdetection-for-segmentation-training\n    1. https:\/\/www.kaggle.com\/vexxingbanana\/sartorius-mmdetection-training\n    1. https:\/\/www.kaggle.com\/remekkinas\/yolox-training-pipeline-cots-dataset-lb-0-507\n    1. https:\/\/www.kaggle.com\/superkevingit\/faster-rcnn-with-mmdetection-without-internet\n    1. \n1. Yolox COCO Dataset : [Efficient Coco datasest generator](https:\/\/www.kaggle.com\/coldfir3\/simple-yolox-dataset-generator-coco-json)\n1. Torch Dataset\n    1. https:\/\/www.kaggle.com\/ttjccc\/pytorch-190","22b5a4bd":"# **Install MMDetection and MMDetection-Compatible Torch**","eb77e4c1":"# LOGS\n1. [Inference Notebook](https:\/\/www.kaggle.com\/mlneo07\/mmdetection-swin-transfomer-frcnn-inference)\n1. Minor Bugs Fixes\n1. Changed Tiny --> Small transformer\n1. New loss_bbox=dict(type='GIoULoss', loss_weight=10.0)))) ; IoULoss --> GIoULoss\n1. FasterRCNN -- > CascadeRCNN\n1.    \n    train_cfg=dict(\n        rpn=dict(sampler=dict(neg_pos_ub=5), allowed_border=-1),\n        rcnn=dict(\n            sampler=dict(\n                _delete_=True,\n                type='CombinedSampler',\n                num=512,\n                pos_fraction=0.25,\n                add_gt_as_proposals=True,\n                pos_sampler=dict(type='InstanceBalancedPosSampler'),\n                neg_sampler=dict(\n                    type='IoUBalancedNegSampler',\n                    floor_thr=-1,\n                    floor_fraction=0,\n                    num_bins=3)))))","8a5c9999":"## Model Config"}}