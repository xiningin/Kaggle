{"cell_type":{"39f22eb3":"code","44e56dd0":"code","afd33b49":"code","c729eea6":"code","5ee67003":"code","979f0a9e":"code","9e38a70c":"code","30c62f59":"code","2468ec41":"code","6debbc56":"code","954eb6b0":"code","1bd254e2":"code","bdf0f332":"code","1edb42a5":"code","f6522b0c":"code","9dba1b10":"code","0f8b15af":"code","9e4ad60d":"code","9cacbd10":"code","a4b1c95e":"code","d5b187c4":"code","231c42a1":"code","33a321d4":"code","ca5f5445":"code","aaa6ab0f":"code","e7c8d235":"code","a7a57499":"code","ff9ec044":"code","0e903bc4":"code","d97188c6":"code","d57f5705":"markdown","ffdb3a74":"markdown","43792fc6":"markdown","0eaeaec8":"markdown","a3a71c27":"markdown","87f9e7a1":"markdown","cdc9d722":"markdown","e9e308fd":"markdown","4ea38d19":"markdown","edd44db1":"markdown","ad3927b7":"markdown","882ee386":"markdown","25169608":"markdown","56c9a43b":"markdown","1f76991f":"markdown","9645b549":"markdown","28e42f57":"markdown","bb5cc637":"markdown","0e36ab53":"markdown","42165e13":"markdown","e2dba0e7":"markdown","2acfbb6e":"markdown","5048f711":"markdown","b7ccce88":"markdown","912ec76b":"markdown"},"source":{"39f22eb3":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport folium\nfrom folium.plugins import HeatMap","44e56dd0":"# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","afd33b49":"train_df=pd.read_csv(\"\/kaggle\/input\/bigquery-geotab-intersection-congestion\/train.csv\")\ntest_df=pd.read_csv(\"\/kaggle\/input\/bigquery-geotab-intersection-congestion\/test.csv\")","c729eea6":"train_df.head()","5ee67003":"train_df.isnull().sum()","979f0a9e":"#Finding the columns whether they are categorical or numerical\ncols = train_df.columns\nnum_cols = train_df._get_numeric_data().columns\nprint(\"Numerical Columns\",num_cols)\ncat_cols=list(set(cols) - set(num_cols))\nprint(\"Categorical Columns:\",cat_cols)","9e38a70c":"train=train_df\ntrain_df=train_df.dropna()","30c62f59":"train_df.City.unique()","2468ec41":"Atlanda=train_df[train_df['City']=='Atlanta']\nBoston=train_df[train_df['City']=='Boston']\nChicago=train_df[train_df['City']=='Chicago']\nPhiladelphia=train_df[train_df['City']=='Philadelphia']","6debbc56":"Atlanda['TotalTimeWaited']=Atlanda['TotalTimeStopped_p20']+Atlanda['TotalTimeStopped_p40']+Atlanda['TotalTimeStopped_p50']+Atlanda['TotalTimeStopped_p60']+Atlanda['TotalTimeStopped_p80']\nBoston['TotalTimeWaited']=Boston['TotalTimeStopped_p20']+Boston['TotalTimeStopped_p40']+Boston['TotalTimeStopped_p50']+Boston['TotalTimeStopped_p60']+Boston['TotalTimeStopped_p80']\nChicago['TotalTimeWaited']=Chicago['TotalTimeStopped_p20']+Chicago['TotalTimeStopped_p40']+Chicago['TotalTimeStopped_p50']+Chicago['TotalTimeStopped_p60']+Chicago['TotalTimeStopped_p80']\nPhiladelphia['TotalTimeWaited']=Philadelphia['TotalTimeStopped_p20']+Philadelphia['TotalTimeStopped_p40']+Philadelphia['TotalTimeStopped_p50']+Philadelphia['TotalTimeStopped_p60']+Philadelphia['TotalTimeStopped_p80']","954eb6b0":"fig, axes = plt.subplots(nrows=2, ncols=2)\nfig = plt.figure(figsize=(20,16))\ntemp_1=Atlanda.groupby('EntryStreetName')['TotalTimeWaited'].mean().sort_values().tail(10)\ntemp_1.plot(kind='barh',ax=axes[0,0],figsize=(20,16),title='Highest traffic startng street in Atlanta')\n\ntemp_2=Boston.groupby('EntryStreetName')['TotalTimeWaited'].mean().sort_values().tail(10)\ntemp_2.plot(kind='barh',ax=axes[0,1],figsize=(20,16),title='Highest traffic startng street in Boston')\n\ntemp_3=Chicago.groupby('EntryStreetName')['TotalTimeWaited'].mean().sort_values().tail(10)\ntemp_3.plot(kind='barh',ax=axes[1,0],figsize=(20,16),title='Highest traffic startng street in Chicago')\n\ntemp_4=Philadelphia.groupby('EntryStreetName')['TotalTimeWaited'].mean().sort_values().tail(10)\ntemp_4.plot(kind='barh',ax=axes[1,1],figsize=(20,16),title='Highest traffic startng street in Philadelphia')\n","1bd254e2":"fig, axes = plt.subplots(nrows=2, ncols=2)\nfig = plt.figure(figsize=(20,16))\ntemp_1=Atlanda.groupby('ExitStreetName')['TotalTimeWaited'].mean().sort_values().tail(10)\ntemp_1.plot(kind='barh',ax=axes[0,0],figsize=(20,16),title='Highest Traffic ending streets in Atlanta')\n\ntemp_2=Boston.groupby('ExitStreetName')['TotalTimeWaited'].mean().sort_values().tail(10)\ntemp_2.plot(kind='barh',ax=axes[0,1],figsize=(20,16),title='Highest Traffic ending streets Boston')\n\ntemp_3=Chicago.groupby('ExitStreetName')['TotalTimeWaited'].mean().sort_values().tail(10)\ntemp_3.plot(kind='barh',ax=axes[1,0],figsize=(20,16),title='Highest Traffic ending streets Chicago')\n\ntemp_4=Philadelphia.groupby('ExitStreetName')['TotalTimeWaited'].mean().sort_values().tail(10)\ntemp_4.plot(kind='barh',ax=axes[1,1],figsize=(20,16),title='Highest Traffic ending streets Philadelphia')","bdf0f332":"fig, axes = plt.subplots(nrows=2, ncols=2)\nfig = plt.figure(figsize=(20,16))\ntemp_1=Atlanda.groupby('Path')['TotalTimeWaited'].mean().sort_values().tail(10)\ntemp_1.plot(kind='barh',ax=axes[0,0],figsize=(20,16),title='Wait time in Atlanta')\n\ntemp_2=Boston.groupby('Path')['TotalTimeWaited'].mean().sort_values().tail(10)\ntemp_2.plot(kind='barh',ax=axes[0,1],figsize=(20,16),title='Wait time in Boston')\n\ntemp_3=Chicago.groupby('Path')['TotalTimeWaited'].mean().sort_values().tail(10)\ntemp_3.plot(kind='barh',ax=axes[1,0],figsize=(20,16),title='Wait time in Chicago')\n\ntemp_4=Philadelphia.groupby('Path')['TotalTimeWaited'].mean().sort_values().tail(10)\ntemp_4.plot(kind='barh',ax=axes[1,1],figsize=(20,16),title='Wait time in Philadelphia')","1edb42a5":"fig , axes = plt.subplots(nrows=2, ncols=2)\n\n\nA_hr=Atlanda.groupby('Hour')['TotalTimeStopped_p80'].mean()\nA_hr.plot(ax=axes[0,0],title=\"Atlanda's waiting time hourwise trend\",figsize=(20,16))\n\n\nB_hr=Boston.groupby('Hour')['TotalTimeStopped_p80'].mean()\nB_hr.plot(ax=axes[0,1],title=\"Boston's waiting time hourwise trend\",figsize=(20,16))\n\n\nC_hr=Chicago.groupby('Hour')['TotalTimeStopped_p80'].mean()\nC_hr.plot(ax=axes[1,0],title=\"Chicago's waiting time hourwise trend\",figsize=(20,16))\n\n\nP_hr=Philadelphia.groupby('Hour')['TotalTimeStopped_p80'].mean()\nP_hr.plot(ax=axes[1,1],title=\"Philadelphia's waiting time hourwise trend\",figsize=(20,16))\n","f6522b0c":"fig , axes = plt.subplots(nrows=2, ncols=2)\n\nA_hr=pd.DataFrame(index=Atlanda.Hour.unique())\nA_hr['Weekend']=Atlanda[Atlanda['Weekend']==1].groupby(['Hour'])['TotalTimeStopped_p80'].mean()\nA_hr['Weekday']=Atlanda[Atlanda['Weekend']==0].groupby(['Hour'])['TotalTimeStopped_p80'].mean()\nA_hr=A_hr.sort_index()\nA_hr.plot(ax=axes[0,0],title=\"Weekend vs Weekday trend\",figsize=(20,16))\n\n\nB_hr=pd.DataFrame(index=Boston.Hour.unique())\nB_hr['Weekend']=Boston[Boston['Weekend']==1].groupby(['Hour'])['TotalTimeStopped_p80'].mean()\nB_hr['Weekday']=Boston[Boston['Weekend']==0].groupby(['Hour'])['TotalTimeStopped_p80'].mean()\nB_hr=B_hr.sort_index()\nB_hr.plot(ax=axes[0,1],title=\"Boston's waiting time hourwise trend\",figsize=(20,16))\n\n\nC_hr=pd.DataFrame(index=Chicago.Hour.unique())\nC_hr['Weekend']=Chicago[Chicago['Weekend']==1].groupby(['Hour'])['TotalTimeStopped_p80'].mean()\nC_hr['Weekday']=Chicago[Chicago['Weekend']==0].groupby(['Hour'])['TotalTimeStopped_p80'].mean()\nC_hr=C_hr.sort_index()\nC_hr.plot(ax=axes[1,0],title=\"Weekend vs Weekday trend\",figsize=(20,16))\n\n\nP_hr=pd.DataFrame(index=Atlanda.Hour.unique())\nP_hr['Weekend']=Philadelphia[Philadelphia['Weekend']==1].groupby(['Hour'])['TotalTimeStopped_p80'].mean()\nP_hr['Weekday']=Philadelphia[Philadelphia['Weekend']==0].groupby(['Hour'])['TotalTimeStopped_p80'].mean()\nP_hr=P_hr.sort_index()\nP_hr.plot(ax=axes[1,1],title=\"Weekend vs Weekday trend\",figsize=(20,16))","9dba1b10":"trafficdf=Atlanda.groupby(['Latitude','Longitude'])['TotalTimeStopped_p20'].count()\ntrafficdf=trafficdf.to_frame()\ntrafficdf.columns.values[0]='count1'\ntrafficdf=trafficdf.reset_index()\nlats=trafficdf[['Latitude','Longitude','count1']].values.tolist()\n    \nhmap = folium.Map(location=[min(Atlanda['Latitude']),min(Atlanda['Longitude'])], zoom_start=10, )\nhmap.add_child(HeatMap(lats, radius = 5))\nhmap\n","0f8b15af":"trafficdf=Chicago.groupby(['Latitude','Longitude'])['TotalTimeStopped_p60'].count()\ntrafficdf=trafficdf.to_frame()\ntrafficdf.columns.values[0]='count1'\ntrafficdf=trafficdf.reset_index()\nlats=trafficdf[['Latitude','Longitude','count1']].values.tolist()\n    \nhmap = folium.Map(location=[min(Chicago['Latitude']),min(Chicago['Longitude'])], zoom_start=9, )\nhmap.add_child(HeatMap(lats, radius = 5))\nhmap","9e4ad60d":"trafficdf=Boston.groupby(['Latitude','Longitude'])['TotalTimeStopped_p60'].count()\ntrafficdf=trafficdf.to_frame()\ntrafficdf.columns.values[0]='count1'\ntrafficdf=trafficdf.reset_index()\nlats=trafficdf[['Latitude','Longitude','count1']].values.tolist()\n    \nhmap = folium.Map(location=[min(Boston['Latitude']),min(Boston['Longitude'])], zoom_start=10.5, )\nhmap.add_child(HeatMap(lats, radius = 5))\nhmap","9cacbd10":"trafficdf=Philadelphia.groupby(['Latitude','Longitude'])['TotalTimeStopped_p60'].count()\ntrafficdf=trafficdf.to_frame()\ntrafficdf.columns.values[0]='count1'\ntrafficdf=trafficdf.reset_index()\nlats=trafficdf[['Latitude','Longitude','count1']].values.tolist()\n    \nhmap = folium.Map(location=[min(Philadelphia['Latitude']),min(Philadelphia['Longitude'])], zoom_start=10, )\nhmap.add_child(HeatMap(lats, radius = 5))\nhmap","a4b1c95e":"train['EntryHeading']","d5b187c4":"#Creating Dummies for train Data\ndfen = pd.get_dummies(train[\"EntryHeading\"],prefix = 'en')\ndfex = pd.get_dummies(train[\"ExitHeading\"],prefix = 'ex')\ntrain = pd.concat([train,dfen],axis=1)\ntrain = pd.concat([train,dfex],axis=1)\n\n#Creating Dummies for test Data\ndfent = pd.get_dummies(test_df[\"EntryHeading\"],prefix = 'en')\ndfext = pd.get_dummies(test_df[\"ExitHeading\"],prefix = 'ex')\ntest_df = pd.concat([test_df,dfent],axis=1)\ntest_df = pd.concat([test_df,dfext],axis=1)\n","231c42a1":"#Training Data\nX = train[[\"IntersectionId\",\"Hour\",\"Weekend\",\"Month\",'en_E',\n       'en_N', 'en_NE', 'en_NW', 'en_S', 'en_SE', 'en_SW', 'en_W', 'ex_E',\n       'ex_N', 'ex_NE', 'ex_NW', 'ex_S', 'ex_SE', 'ex_SW', 'ex_W']]\ny1 = train[\"TotalTimeStopped_p20\"]\ny2 = train[\"TotalTimeStopped_p50\"]\ny3 = train[\"TotalTimeStopped_p80\"]\ny4 = train[\"DistanceToFirstStop_p20\"]\ny5 = train[\"DistanceToFirstStop_p50\"]\ny6 = train[\"DistanceToFirstStop_p80\"]","33a321d4":"testX = test_df[[\"IntersectionId\",\"Hour\",\"Weekend\",\"Month\",'en_E','en_N', 'en_NE', 'en_NW', 'en_S', \n              'en_SE', 'en_SW', 'en_W', 'ex_E','ex_N', 'ex_NE', 'ex_NW', 'ex_S', 'ex_SE', 'ex_SW', 'ex_W']]","ca5f5445":"from catboost import CatBoostRegressor\ncb_model_1 = CatBoostRegressor(iterations=700,\n                             learning_rate=0.02,\n                             depth=12,\n                             eval_metric='RMSE',\n                             random_seed = 23,\n                             bagging_temperature = 0.2,\n                             od_type='Iter',\n                             metric_period = 75,\n                             od_wait=100)\ncb_model_1.fit(X, y1)\npred_1=cb_model_1.predict(testX)","aaa6ab0f":"cb_model_2 = CatBoostRegressor(iterations=700,\n                             learning_rate=0.02,\n                             depth=12,\n                             eval_metric='RMSE',\n                             random_seed = 23,\n                             bagging_temperature = 0.2,\n                             od_type='Iter',\n                             metric_period = 75,\n                             od_wait=100)\ncb_model_2.fit(X, y2)\npred_2=cb_model_2.predict(testX)","e7c8d235":"cb_model_3 = CatBoostRegressor(iterations=700,\n                             learning_rate=0.02,\n                             depth=12,\n                             eval_metric='RMSE',\n                             random_seed = 23,\n                             bagging_temperature = 0.2,\n                             od_type='Iter',\n                             metric_period = 75,\n                             od_wait=100)\ncb_model_3.fit(X, y3)\npred_3=cb_model_3.predict(testX)","a7a57499":"cb_model_4 = CatBoostRegressor(iterations=700,\n                             learning_rate=0.02,\n                             depth=12,\n                             eval_metric='RMSE',\n                             random_seed = 23,\n                             bagging_temperature = 0.2,\n                             od_type='Iter',\n                             metric_period = 75,\n                             od_wait=100)\ncb_model_4.fit(X, y4)\npred_4=cb_model_1.predict(testX)","ff9ec044":"cb_model_5 = CatBoostRegressor(iterations=700,\n                             learning_rate=0.02,\n                             depth=12,\n                             eval_metric='RMSE',\n                             random_seed = 23,\n                             bagging_temperature = 0.2,\n                             od_type='Iter',\n                             metric_period = 75,\n                             od_wait=100)\ncb_model_5.fit(X, y5)\npred_5=cb_model_5.predict(testX)","0e903bc4":"cb_model_6 = CatBoostRegressor(iterations=700,\n                             learning_rate=0.02,\n                             depth=12,\n                             eval_metric='RMSE',\n                             random_seed = 23,\n                             bagging_temperature = 0.2,\n                             od_type='Iter',\n                             metric_period = 75,\n                             od_wait=100)\ncb_model_6.fit(X, y6)\npred_6=cb_model_6.predict(testX)","d97188c6":"# Appending all predictions\nprediction = []\nfor i in range(len(pred_1)):\n    for j in [pred_1,pred_2,pred_3,pred_4,pred_5,pred_6]:\n        prediction.append(j[i])\n        \nsubmission = pd.read_csv(\"..\/input\/bigquery-geotab-intersection-congestion\/sample_submission.csv\")\nsubmission[\"Target\"] = prediction\nsubmission.to_csv(\"Submission_CB.csv\",index = False)","d57f5705":"**Chicago's More Trafficed area**","ffdb3a74":"## Modelling","43792fc6":"**Highest Traffic Starting street**","0eaeaec8":"**Key Take Aways**\n\n Exploratory Data Analysis\n \n Extensive Modelling","a3a71c27":"**Weekend vs WeekDays Trend**","87f9e7a1":"Let's understand nature of the data citywise","cdc9d722":"**More Traffic Area's Geospatial plot**","e9e308fd":"**Let's start getting insights**","4ea38d19":"![image.png](attachment:image.png)\n","edd44db1":"Since I'm gonna work on EDA in this kernel, I will drop the missing values","ad3927b7":"**Reading the Files**","882ee386":"**Boston's More Traffied Area**","25169608":"**Waitage time hour wise pattern**","56c9a43b":"The dataset for this competition includes aggregate stopped vehicle information and intersection wait times. Your task is to predict congestion, based on an aggregate measure of stopping distance and waiting times, at intersections in 4 major US cities: Atlanta, Boston, Chicago & Philadelphia.","1f76991f":"**Necessary Libraries**","9645b549":"**City's Area's with more waitage time's**","28e42f57":"## Feature Engineering","bb5cc637":"**Understanding the nature of data**","0e36ab53":"**Kindly upvote if you like or find useful of the kernel**","42165e13":"## Exploratory Data Analysis","e2dba0e7":"**Highest Traffic ending street**","2acfbb6e":"## About the Competition","5048f711":"**I'll be working extensively in Feature Engineering and Modelling part in coming days**\n\n","b7ccce88":"**Most Traffic Path**","912ec76b":"**Philadelphia's More Trafficed Area's**"}}