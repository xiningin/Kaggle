{"cell_type":{"521b787a":"code","2a25b923":"code","b7035c7c":"code","dc85a063":"code","adf3078a":"code","011b7362":"code","18e6a548":"code","7b8e0d57":"code","898614ad":"code","1bf5cee4":"code","24f26e06":"code","ba3f51b8":"code","b5bf9828":"code","8403eaeb":"code","8c144387":"code","d854b17c":"code","6f15ad1c":"code","7dd55674":"code","c7ed2338":"code","3d3a3b03":"code","be49e66c":"code","f3238492":"code","ef5fecb0":"code","05bed5a8":"code","87dc9550":"code","a1cd2be9":"code","0d3e2908":"markdown","66ae7d69":"markdown","b3f86ee2":"markdown","d205e550":"markdown","3748793f":"markdown"},"source":{"521b787a":"import pandas as pd\nimport numpy as np\nimport os\nimport xml.etree.ElementTree as Xet\nimport matplotlib.pyplot as plt\n%matplotlib inline","2a25b923":"dataset_path = '\/kaggle\/input\/car-crashes-severity-prediction\/'\n\ndf = pd.read_csv(os.path.join(dataset_path, 'train.csv'))\n\nprint(\"The shape of the dataset is {}.\\n\\n\".format(df.shape))\n\ndf.head()","b7035c7c":"# check the existance of nulls \nprint(\" Number of null records in each column\" , df.isnull().sum() ) \n# check the existance of duplicated rows or not \nprint(\"Number of Duplicated records\",df.duplicated().sum() ) ","dc85a063":"#get information of data\ndf.info()","adf3078a":"# conversion to timestamp\ndf.timestamp = pd.to_datetime(df.timestamp, utc = True)\n\n# True & false conversion to 1 and 0 \ncolumns = ['Crossing' , 'Junction' , 'Railway' , 'Roundabout' , 'Amenity','Bump', 'Give_Way','No_Exit','Roundabout','Stop']\ndf[columns] = df[columns].astype(int)\n\n#Convert Right side to 0 and Left side to 1\ndf['Side'] = df['Side'].replace(['R','L'],[0,1])\n\n#lat and lng transformation\ndf['x']=np.cos(df['Lat']) * np.cos(df['Lng'])\ndf['y']=np.cos(df['Lat']) * np.sin(df['Lng'])\ndf['z']=np.sin(df['Lat'])\ndf['loc']=df['x']*df['y']*df['z']\n\n\n# checking the conversion\nprint(df.info())\n","011b7362":"df.describe()","18e6a548":"# spliiting the Timestamp column \n\ndf['Year'] = df.timestamp.dt.year\ndf['Month'] = df.timestamp.dt.month\ndf['Day'] = df.timestamp.dt.day\ndf['Hour'] = df.timestamp.dt.hour\ndf['weekday'] = df.timestamp.dt.weekday\n\n# checking the splitiing step\ndf.head()","7b8e0d57":"#Load Holiday Data from xml file\n\ncols = [\"date\", \"holiday\"]\nrows = []\nxmlparse = Xet.parse(os.path.join(dataset_path, 'holidays.xml'))\nroot = xmlparse.getroot()\nfor i in root:\n    date = i.find(\"date\").text\n    description = i.find(\"description\").text\n    \n    rows.append({\"date\": date,\n                 \"holiday\": description})\n\nholiday_dF = pd.DataFrame(rows, columns=cols)\nprint(holiday_dF.info())\n","898614ad":"# conversion of date from object format to datetime\nholiday_dF['timestamp'] = pd.to_datetime(holiday_dF.date,utc = True)\nholiday_dF['timestamp'] = holiday_dF.timestamp.dt.date\ndf['timestamp'] = df.timestamp.dt.date\nholiday_dF.drop([\"date\"], axis=1, inplace=True)\n","1bf5cee4":"# merging the holiday conditon to data\n\nholidayMergedDF = pd.merge(df,holiday_dF,how = 'left' ,on = ['timestamp'])\n\n#holiday column 0 represent regular day 1 represent holiday\nholidayMergedDF['holiday'] = holidayMergedDF['holiday'] * 0\nholidayMergedDF['holiday'] = holidayMergedDF['holiday'].replace([np.NaN,''],[0,1])\nprint(holidayMergedDF.shape)\nholidayMergedDF.isnull().sum()","24f26e06":"# loading weather Condition data\nweather_dF = pd.read_csv(os.path.join(dataset_path, 'weather-sfcsv.csv'))\nweather_dF.head()","ba3f51b8":"# check the existance of nulls \nprint(\" Number of null records in each column\" , weather_dF.isnull().sum() ) \n# check the existance of duplicated rows or not \nprint(\"Number of Duplicated records\",weather_dF.duplicated().sum() ) \nprint(weather_dF.info())","b5bf9828":"# cleaning weather condition Data\n#convert Weather_Condition to categorical \n#weather_dF['Weather_Condition'] = weather_dF['Weather_Condition'].astype('category').cat.codes\n\n#fill null values with median\nweather_dF['Wind_Speed(mph)'].fillna((weather_dF['Wind_Speed(mph)'].median()), inplace=True)\nweather_dF['Humidity(%)'].fillna((weather_dF['Humidity(%)'].median()), inplace=True)\nweather_dF['Temperature(F)'].fillna((weather_dF['Temperature(F)'].median()), inplace=True)\nweather_dF['Visibility(mi)'].fillna((weather_dF['Visibility(mi)'].median()), inplace=True)\nweather_dF['Wind_Chill(F)'].fillna((weather_dF['Wind_Chill(F)'].median()), inplace=True)\n\n#drop nulls of weather condition\nweather_dF.dropna(subset=['Weather_Condition'],inplace = True)\n\nweather_dF.describe()\n","8403eaeb":"#Check out some categorical features.\ncat_names = ['Selected', 'Weather_Condition']\nprint(\"Unique count of categorical features:\")\nfor col in cat_names:\n  print(col,weather_dF[col].unique().size)","8c144387":"#drop unimportant features\nweather_dF.drop([\"Precipitation(in)\",\"Selected\"], axis=1, inplace=True)\n# show distinctive weather conditions \nweather_dF['Weather_Condition'].unique()","d854b17c":"weather_dF['Clear'] = np.where(weather_dF['Weather_Condition'].str.contains('Clear', case=False, na = False), True, False)\nweather_dF['Cloud'] = np.where(weather_dF['Weather_Condition'].str.contains('Cloud|Overcast', case=False, na = False), True, False)\nweather_dF['Rain'] = np.where(weather_dF['Weather_Condition'].str.contains('Rain|storm', case=False, na = False), True, False)\nweather_dF['Heavy_Rain'] = np.where(weather_dF['Weather_Condition'].str.contains('Heavy Rain|Rain Shower|Heavy T-Storm|Heavy Thunderstorms', case=False, na = False), True, False)\nweather_dF['Snow'] = np.where(weather_dF['Weather_Condition'].str.contains('Snow|Sleet|Ice', case=False, na = False), True, False)\nweather_dF['Heavy_Snow'] = np.where(weather_dF['Weather_Condition'].str.contains('Heavy Snow|Heavy Sleet|Heavy Ice Pellets|Snow Showers|Squalls', case=False, na = False), True, False)\nweather_dF['Fog'] = np.where(weather_dF['Weather_Condition'].str.contains('Fog', case=False, na = False), True, False)\n# comversion to 1 and 0 \ncolumns = ['Clear' , 'Cloud' , 'Rain' , 'Heavy_Rain' , 'Snow','Heavy_Snow', 'Fog']\nweather_dF[columns] = weather_dF[columns].astype(int)\n\nweather_dF['Weather_Condition'] = weather_dF['Weather_Condition'].astype('category').cat.codes\nweather_dF.head()","6f15ad1c":"# cleaning of data\nprint(weather_dF.shape)\nuniqueWeatherDF  = weather_dF.drop_duplicates(['Year','Hour', 'Day' ,'Month'],keep = 'last', inplace = False)\nprint(\"shape after removing duplicated relative to Hour , Day, Month and Year \",uniqueWeatherDF.shape)\n\n# merging the weather conditon to data\nweatherMergedDF = pd.merge(holidayMergedDF,uniqueWeatherDF,how = 'left' ,on = ['Hour' ,'Year', 'Day' ,'Month'])\nweatherMergedDF.dropna(inplace = True)\nprint(weatherMergedDF.shape)\n","7dd55674":"# removing some nonImportant columns \ndf = weatherMergedDF.drop(columns=['timestamp','Bump', 'Give_Way','No_Exit','Roundabout'])\ndf.info()","c7ed2338":"#add new features Rush Hour\ndf['RushHour'] = ((df['Hour'] > 14) & (df['Hour'] < 18)).astype(int)\n#add new features Midnight\ndf['Midnight'] = ((df['Hour'] > 23) & (df['Hour'] < 6)).astype(int)\n#add new features to count number of crashes at certain places\ndf_count = pd.DataFrame(df.groupby(['Lat','Lng']).ID.count().reset_index())\ndf_count.columns = (['Lat', 'Lng','CrashCount'])\ndf = pd.merge(df,df_count,how = 'left' ,on = ['Lat', 'Lng'])\ndf.info()","3d3a3b03":"#ordered correlated attributes with Severity\n#(abs(df.corr()[['Severity']])).sort_values(by='Severity',ascending=False)","be49e66c":"from sklearn.model_selection import train_test_split\n\ntrain_df, val_df = train_test_split(df, test_size=0.2, random_state=42) # Try adding `stratify` here\n\nX_train = train_df.drop(columns=['ID', 'Severity'])\ny_train = train_df['Severity']\n\nX_val = val_df.drop(columns=['ID', 'Severity'])\ny_val = val_df['Severity']","f3238492":"# This cell is used to select the numerical features. IT SHOULD BE REMOVED AS YOU DO YOUR WORK.\n\n#X_train = X_train[['Lat', 'Lng','Distance(mi)','Crossing','Month','Year','Day','Stop','Side','Temperature(F)', 'Humidity(%)','Wind_Speed(mph)','Weather_Condition','holiday','RushHour']]\n#X_val = X_val[['Lat', 'Lng','Distance(mi)','Crossing','Month','Year','Day','Stop','Side','Temperature(F)', 'Humidity(%)','Wind_Speed(mph)','Weather_Condition','holiday','RushHour']]","ef5fecb0":"from sklearn.ensemble import RandomForestClassifier\n\n# Create an instance of the classifier\nclassifier = RandomForestClassifier(max_depth=2, random_state=0)\n\n# Feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(X_train)\nX_train_std = sc.transform(X_train)\nX_test_std = sc.transform(X_val)\n\n# Train the classifier\/\nclassifier = classifier.fit(X_train, y_train)\nprint(\"The accuracy of the classifier on the validation set is \", (classifier.score(X_val, y_val)))\n\nimportances = classifier.feature_importances_\n# Sort the feature importance in descending order\nsorted_indices = np.argsort(importances)[::-1]","05bed5a8":"#Visualize the feature importance\nimport matplotlib.pyplot as plt\n \nplt.title('Feature Importance')\nplt.bar(range(X_train.shape[1]), importances[sorted_indices], align='center')\nplt.xticks(range(X_train.shape[1]), X_train.columns[sorted_indices], rotation=90)\nplt.tight_layout()\nplt.show()\n","87dc9550":"X_train.columns[sorted_indices]","a1cd2be9":"X_train = train_df.drop(columns=['ID', 'Severity'])\ny_train = train_df['Severity']\n\nX_val = val_df.drop(columns=['ID', 'Severity'])\ny_val = val_df['Severity']\nX_train = X_train[['x', 'CrashCount', 'z', 'loc', 'Lng', 'Lat', 'Stop', 'y',\n       'Distance(mi)', 'Year', 'Wind_Chill(F)', 'Month']]\nX_val = X_val[['x', 'CrashCount', 'z', 'loc', 'Lng', 'Lat', 'Stop', 'y',\n       'Distance(mi)', 'Year', 'Wind_Chill(F)', 'Month']]\n\n# Feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(X_train)\nX_train_std = sc.transform(X_train)\nX_test_std = sc.transform(X_val)\n\n# Create an instance of the classifier\nclassifier2 = RandomForestClassifier(max_depth=2, random_state=0)\n\n# Train the classifier\/\nclassifier2 = classifier2.fit(X_train_std, y_train)\nprint(\"The accuracy of the classifier on the validation set is \", (classifier2.score(X_test_std, y_val)))","0d3e2908":"## Data Splitting","66ae7d69":"## Exploratory Data Analysis","b3f86ee2":"### Data Cleaning","d205e550":"### Extract new features","3748793f":"## Import the libraries"}}