{"cell_type":{"c4aa72fe":"code","09185793":"code","16e34dc8":"code","484694c3":"code","dc12861e":"code","8e123560":"code","6c38e641":"code","a51304a6":"code","2652b5d7":"code","d1f71b4e":"code","6efc4005":"code","15831479":"code","11adebb9":"code","10aa100e":"code","eb54e6bd":"code","dc250f91":"code","5c974397":"code","ae5ce7e5":"code","64352567":"code","05f80785":"code","56c29092":"code","debce135":"code","b4ca594a":"code","e16bc700":"code","1e938eb8":"code","9658bd3e":"code","7d7e743a":"code","f9e43507":"markdown","684355f0":"markdown","ccaa0e50":"markdown","498b856b":"markdown","e69829c6":"markdown","9f0f7a56":"markdown","47cb8287":"markdown","18709603":"markdown"},"source":{"c4aa72fe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","09185793":"data = pd.read_csv(\"\/kaggle\/input\/spam-mails-dataset\/spam_ham_dataset.csv\")\n\nprint(\"Number of Datapoints :\",data.shape[0])\nprint(\"Number of Features\/Columns :\",data.shape[1])\nprint(\"Features: \",data.columns)","16e34dc8":"data.head(6)","484694c3":"data.info()","dc12861e":"import seaborn as sns\nsns.countplot(x=\"label\", data=data)","8e123560":"data['text'][1]","6c38e641":"import warnings\nwarnings.filterwarnings(\"ignore\")\nfrom nltk.corpus import stopwords\nimport nltk\nimport re\n\n#loading_the_stop_words_from_nltk_library_\nstop_words = set(stopwords.words('english'))\n\ndef txt_preprocessing(total_text, index, column, df):\n    if type(total_text) is not int:\n        string = \"\"\n        \n        #replace_every_special_char_with_space\n        total_text = re.sub('[^a-zA-Z0-9\\n]', ' ', total_text)\n        \n        #replace_multiple_spaces_with_single_space\n        total_text = re.sub('\\s+',' ', total_text)\n        \n        #converting_all_the_chars_into_lower_case\n        total_text = total_text.lower()\n        \n        for word in total_text.split():\n        #if_the_word_is_a_not_a_stop_word_then_retain_that_word_from_the_data\n            if not word in stop_words:\n                string += word + \" \"\n        \n        df[column][index] = string","a51304a6":"#data_text_processing_stage_\nfor index, row in data.iterrows():\n    if type(row['text']) is str:\n        txt_preprocessing(row['text'], index, 'text', data)\n    else:\n        print(\"THERE IS NO TEXT DESCRIPTION FOR ID :\",index)\n\ndata.head()","2652b5d7":"data['text'][3]","d1f71b4e":"preprocessed_data = pd.DataFrame({'text':data['text'], 'Spam\/Ham':data['label_num']})\npreprocessed_data.head()","6efc4005":"#split_your_data\nfrom sklearn.model_selection import train_test_split\nX = preprocessed_data['text']\nY = preprocessed_data['Spam\/Ham']\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=0)\n\nX_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=0)","15831479":"print(\"NUMBER OF DATA POINTS IN TRAIN DATA :\", X_train.shape[0])\nprint(\"NUMBER OF DATA POINTS IN TEST DATA :\", X_test.shape[0])\nprint(\"NUMBER OF DATA POINTS IN CROSS VALIDATION DATA :\", X_cv.shape[0])","11adebb9":"#perform_tfidf_vectorization_of_text_data\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ntext_vec = TfidfVectorizer(min_df=10, max_features=5000)\ntext_vec.fit(X_train.values)\n\ntrain_text = text_vec.transform(X_train.values)\ntest_text = text_vec.transform(X_test.values)\ncv_text = text_vec.transform(X_cv.values)\n\nprint(train_text.shape)\nprint(test_text.shape)\nprint(cv_text.shape)","10aa100e":"#this_function_plots_the_confusion_matrices_given_y_i_and_y_i_hat_\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\ndef plot_confusion_matrix(test_y, predict_y):\n\n    C = confusion_matrix(test_y, predict_y) #confusion_mat\n    A =(((C.T)\/(C.sum(axis=1))).T) #recall_mat\n    B =(C\/C.sum(axis=0)) #precision_mat\n    \n    labels = [0,1]\n    \n    #representing_C_in_heatmap_format\n    print(\"-\"*40, \"Confusion Matrix\", \"-\"*40)\n    plt.figure(figsize=(8,6))\n    sns.heatmap(C, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n    plt.xlabel('Predicted Class')\n    plt.ylabel('Original Class')\n    plt.show()\n    \n    #representing_B_in_heatmap_format\n    print(\"-\"*40, \"Precision Matrix (Columm Sum=1)\", \"-\"*40)\n    plt.figure(figsize=(8,6))\n    sns.heatmap(B, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n    plt.xlabel('Predicted Class')\n    plt.ylabel('Original Class')\n    plt.show()\n    \n    #representing_A_in_heatmap_format\n    print(\"-\"*40, \"Recall Matrix (Row Sum=1)\", \"-\"*40)\n    plt.figure(figsize=(8,6))\n    sns.heatmap(A, annot=True, cmap=\"YlGnBu\", fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n    plt.xlabel('Predicted Class')\n    plt.ylabel('Original Class')\n    plt.show()","eb54e6bd":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.metrics import log_loss\n\n#train a logistic regression + calibration model using text features which are one-hot encoded\nalpha = [10 ** x for x in range(-5, 1)]\n\ncv_log_error_array=[]\nfor i in alpha:\n    clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42) #loss='log'_means_logistic_regression\n    clf.fit(train_text, y_train)\n    \n    lr_sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n    lr_sig_clf.fit(train_text, y_train)\n    \n    predict_y = lr_sig_clf.predict_proba(cv_text)\n    cv_log_error_array.append(log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n    \n    print('For values of alpha =',i,\"The log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n\nfig, ax = plt.subplots()\nax.plot(alpha, cv_log_error_array,c='g')\nfor i, txt in enumerate(np.round(cv_log_error_array,3)):\n    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],cv_log_error_array[i]))\n    \nplt.grid()\nplt.title(\"Cross Validation Error for Each Alpha\")\nplt.xlabel(\"Alpha i's\")\nplt.ylabel(\"Error Measure\")\nplt.show()\n\nbest_alpha = np.argmin(cv_log_error_array)\n\nclf = SGDClassifier(alpha=alpha[best_alpha], penalty='l2', loss='log', random_state=42)\nclf.fit(train_text, y_train)\n\nlr_sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\nlr_sig_clf.fit(train_text, y_train)\n\npredict_y = lr_sig_clf.predict_proba(train_text)\nprint('For Values of Best Alpha =', alpha[best_alpha],\"The Train Log Loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n\npredict_y = lr_sig_clf.predict_proba(test_text)\nprint('For Values of Best Alpha =', alpha[best_alpha],\"The Test Log Loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n\npredict_y = lr_sig_clf.predict_proba(cv_text)\nprint('For Values of Best Alpha =', alpha[best_alpha],\"The Cross Validation Log Loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))","dc250f91":"plot_confusion_matrix(y_cv, lr_sig_clf.predict(cv_text.toarray()))","5c974397":"from sklearn.metrics import classification_report\nprint(classification_report(y_cv, lr_sig_clf.predict(cv_text)))","ae5ce7e5":"from sklearn.metrics import accuracy_score\nlr_test_accuracy = (lr_sig_clf.score(test_text, y_test)*100)\nprint(\"Logistic Regression Test Accuracy -\",lr_test_accuracy)","64352567":"from sklearn.naive_bayes import MultinomialNB\n\nalpha = [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100, 1000]\n\ncv_log_error_array = []\n\nfor i in alpha:\n    print(\"For Alpha =\", i)\n    clf = MultinomialNB(alpha=i)\n    clf.fit(train_text, y_train)\n    \n    nb_sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n    nb_sig_clf.fit(train_text, y_train)\n    \n    sig_clf_probs = nb_sig_clf.predict_proba(cv_text)\n    \n    cv_log_error_array.append(log_loss(y_cv, sig_clf_probs, labels=clf.classes_, eps=1e-15))\n    #to avoid rounding error while multiplying probabilites we use log-probability estimates\n    print(\"Log Loss :\",log_loss(y_cv, sig_clf_probs)) \n\nfig, ax = plt.subplots()\nax.plot(np.log10(alpha), cv_log_error_array,c='g')\n\nfor i, txt in enumerate(np.round(cv_log_error_array,3)):\n    ax.annotate((alpha[i],str(txt)), (np.log10(alpha[i]),cv_log_error_array[i]))\n    \nplt.grid()\nplt.xticks(np.log10(alpha))\nplt.title(\"Cross Validation Error for Each Alpha\")\nplt.xlabel(\"Alpha i's\")\nplt.ylabel(\"Error Measure\")\nplt.show()\n\nbest_alpha = np.argmin(cv_log_error_array)\n\nclf = MultinomialNB(alpha=alpha[best_alpha])\nclf.fit(train_text, y_train)\n\nnb_sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\nnb_sig_clf.fit(train_text, y_train)\n\npredict_y = nb_sig_clf.predict_proba(train_text)\nprint('For Values of Best Alpha =', alpha[best_alpha],\"The Train Log Loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n\npredict_y = nb_sig_clf.predict_proba(test_text)\nprint('For Values of Best Alpha =', alpha[best_alpha],\"The Train Log Loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n\npredict_y = nb_sig_clf.predict_proba(cv_text)\nprint('For Values of Best Alpha =', alpha[best_alpha], \"The Cross Validation Log Loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))","05f80785":"plot_confusion_matrix(y_cv, nb_sig_clf.predict(cv_text.toarray()))","56c29092":"print(classification_report(y_cv, nb_sig_clf.predict(cv_text)))","debce135":"nb_test_accuracy = (nb_sig_clf.score(test_text, y_test)*100)\nprint(\"Naive Bayes Test Accuracy -\",nb_test_accuracy)","b4ca594a":"from sklearn.neighbors import KNeighborsClassifier\n\nalpha = [5, 11, 15, 21, 31, 41, 51, 99]\n\ncv_log_error_array = []\n\nfor i in alpha:\n    print(\"for alpha =\", i)\n    clf = KNeighborsClassifier(n_neighbors=i) \n    clf.fit(train_text, y_train) #knn may not good at handling large dimensionality\n    \n    knn_sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n    knn_sig_clf.fit(train_text, y_train)\n    \n    sig_clf_probs = knn_sig_clf.predict_proba(cv_text)\n    cv_log_error_array.append(log_loss(y_cv, sig_clf_probs, labels=clf.classes_, eps=1e-15))\n    #to avoid rounding error while multiplying probabilites we use log-probability estimates\n    print(\"Log Loss :\",log_loss(y_cv, sig_clf_probs)) \n\nfig, ax = plt.subplots()\nax.plot(alpha, cv_log_error_array,c='g')\nfor i, txt in enumerate(np.round(cv_log_error_array,3)):\n    ax.annotate((alpha[i],str(txt)), (alpha[i],cv_log_error_array[i]))\nplt.grid()\nplt.title(\"Cross Validation Error for Each Alpha\")\nplt.xlabel(\"Alpha i's\")\nplt.ylabel(\"Error Measure\")\nplt.show()\n\nbest_alpha = np.argmin(cv_log_error_array)\nclf = KNeighborsClassifier(n_neighbors=alpha[best_alpha])\nclf.fit(train_text, y_train)\n\nknn_sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\nknn_sig_clf.fit(train_text, y_train)\n\npredict_y = knn_sig_clf.predict_proba(train_text)\nprint('For Values of Best Alpha =', alpha[best_alpha], \"The Train Log Loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n\npredict_y = knn_sig_clf.predict_proba(test_text)\nprint('For Values of Best Alpha =', alpha[best_alpha],\"The Test Log Loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))\n\npredict_y = knn_sig_clf.predict_proba(cv_text)\nprint('For Values of Best Alpha =', alpha[best_alpha], \"The Cross Validation Log Loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))","e16bc700":"plot_confusion_matrix(y_cv, knn_sig_clf.predict(cv_text.toarray()))","1e938eb8":"print(classification_report(y_cv, knn_sig_clf.predict(cv_text)))","9658bd3e":"knn_test_accuracy = (knn_sig_clf.score(test_text, y_test)*100)\nprint(\"K Nearest Neighbors Test Accuracy -\",knn_test_accuracy)","7d7e743a":"from prettytable import PrettyTable\n\nx = PrettyTable()\n\nx.field_names = [\"Model\", \"Test Accuracy Score\"]\nx.add_row(['Logistic Regression', round(lr_test_accuracy, 2)])\nx.add_row(['Multinomial Naive Bayes', round(nb_test_accuracy, 2)])\nx.add_row(['K Nearest Neighbor', round(knn_test_accuracy, 2)])\nprint(x)","f9e43507":"**<h2><font color=red>2.<\/font><font color=green> Multinomial Naive Bayes<\/font><\/h2>**","684355f0":"**<font color=blue>Train-Test Split<\/font>**","ccaa0e50":"**<font color=blue>Data Preprocessing<\/font>**","498b856b":"**<h2><font color=red>1.<\/font><font color=green> Logistic Regression<\/font><\/h2>**","e69829c6":"**<font color=red>TFIDF of Text Data<\/font>**","9f0f7a56":"**<font color=red>Pretty Table<\/font>**","47cb8287":"**<font color=blue>Confusion Matrix<\/font>**","18709603":"**<h2><font color=red>3.<\/font><font color=green> K Nearest Neighbor<\/font><\/h2>**"}}