{"cell_type":{"934a16a0":"code","1c360b90":"code","ece49529":"code","0d705a61":"code","7d8a8cd5":"code","8f787a98":"code","3d7e4f56":"code","8b4c4fa7":"code","ff0273ab":"code","ba9da6ec":"code","cab2fc7d":"code","cabd1e86":"code","bc43cd13":"code","93bd60c2":"code","4c4409bf":"code","f975c945":"code","053b6773":"code","dfa9b7b6":"code","c70ad0c6":"code","368e44eb":"code","0d4f59f4":"code","a57e18c7":"markdown"},"source":{"934a16a0":"from __future__ import print_function\nimport keras\nfrom keras.layers import Dense, Conv2D, BatchNormalization, Activation\nfrom keras.layers import AveragePooling2D, Input, Flatten, MaxPooling2D, Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.models import Model, model_from_json, Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.metrics import Precision, Recall\nfrom keras.utils import to_categorical\nimport os, numpy as np\nfrom skimage.transform import resize","1c360b90":"X = np.load(\"..\/input\/covidx\/Copy of trainx.npy\")\nY = np.load(\"..\/input\/covidx\/trainy.npy\")\n\nbins = {}\n\nfor i in range(Y.shape[0]):\n    if Y[i] not in bins:\n        bins[Y[i]] = []\n    bins[Y[i]].append(X[i])\n    \nfor b in bins:\n    bins[b] = np.array(bins[b])\n    \ndel X\ndel Y","ece49529":"from skimage.transform import rotate, AffineTransform, warp\nfrom skimage.util import random_noise\nfrom skimage.filters import gaussian\nfrom PIL import Image \nimport cv2\n\naugment_image = {}\n\ndef anticlockwise_rotation(image):\n    angle= random.randint(0,180)\n    image = rotate(image, angle)\n    image = cv2.normalize(image, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_8U)\n    return image\n\naugment_image[0] = anticlockwise_rotation\n\ndef clockwise_rotation(image):\n    angle= random.randint(0,180)\n    image = rotate(image, -angle)\n    image = cv2.normalize(image, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_8U)\n    return image\n\naugment_image[1] = clockwise_rotation\n\ndef h_flip(image):\n    return  np.fliplr(image)\n\naugment_image[2] = h_flip\n\ndef v_flip(image):\n    return np.flipud(image)\n\naugment_image[3] = v_flip\n\ndef add_noise(image):\n    image = random_noise(image)\n    image = cv2.normalize(image, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_8U)\n    return image \n\naugment_image[4] = add_noise\n\ndef blur_image(image):\n    image = gaussian(image, sigma = random.uniform(0, 1), multichannel=True)\n    image = cv2.normalize(image, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_8U)\n    return image\n\naugment_image[5] = blur_image\n\n#I would not recommend warp_shifting, because it distorts image, but can be used in many use case like \n#classifying blur and non-blur images\ndef warp_shift(image): \n    transform = AffineTransform(translation=(0,40))  #chose x,y values according to your convinience\n    warp_image = warp(image, transform, mode=\"wrap\")\n    return warp_image","0d705a61":"import random\n\ndef augment_covid(data, no=1200):\n    n = data.shape[0]\n    i = 0\n    new_data = list(data)\n    while len(new_data) < no:\n        times_to_augment = random.randint(1, 3)\n        img = data[i]\n        for j in range(times_to_augment):\n            r = random.randint(0, 5)\n            img = augment_image[r](img)\n        print(i)        \n        new_data.append(img)\n        i += 1\n        i %= n\n    \n    return new_data","7d8a8cd5":"for b in bins:\n    bins[b] = augment_covid(bins[b])\n    bins[b] = np.array(bins[b])\n    np.random.shuffle(bins[b])","8f787a98":"training_no = {}\ntraining_samples = 200\nfor b in bins:\n    training_no[b] = len(bins[b]) - training_samples","3d7e4f56":"X_train = []\nY_train = []\nX_test = []\nY_test = []\nfor b in bins:\n    X_train = X_train + list(bins[b][:training_no[b]])\n    X_test = X_test + list(bins[b][training_no[b]:])\n    Y_train = Y_train + [b]*training_no[b]\n    Y_test = Y_test + [b]*training_samples","8b4c4fa7":"input_shape = (128, 128)\nY_train = to_categorical(np.array(Y_train, dtype='int32'), 3)\nY_test = to_categorical(np.array(Y_test, dtype='int32'), 3)","ff0273ab":"for i in range(len(X_train)):\n    if not (i%100):\n        print(i)\n    X_train[i] = resize(X_train[i], input_shape)\n    X_train[i] = cv2.normalize(X_train[i], None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_8U)\n\nfor i in range(len(X_test)):\n    X_test[i] = resize(X_test[i], input_shape)\n    X_test[i] = cv2.normalize(X_test[i], None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_8U)\n","ba9da6ec":"X_train = np.array(X_train)\nX_test = np.array(X_test)","cab2fc7d":"def save_model(model, name):\n    # serialize model to JSON\n    model_json = model.to_json()\n    with open(\"model_\" + name + \".json\", \"w\") as json_file:\n        json_file.write(model_json)\n    model.save_weights(\"model_\" + name + \".h5\")\n    print(\"Saved \" + name + \" to disk\")","cabd1e86":"def load_model(json_file_name, weights_file_name):\n    json_file = open(json_file_name, 'r')\n    loaded_model_json = json_file.read()\n    json_file.close()\n    loaded_model = model_from_json(loaded_model_json)\n    loaded_model.load_weights(weights_file_name)\n    print(\"Loaded model from disk\")\n    return loaded_model","bc43cd13":"from sklearn.metrics import confusion_matrix\n\ndef get_params(model, X, Y):\n    scores = model.evaluate(X, Y, verbose=0)\n    for i in range(len(scores)):\n        print(\"%s: %.2f%%\" % (model.metrics_names[i], scores[i]*100))\n    \n    m = (2 * scores[1] * scores[2]) \/ (scores[1] + scores[2])\n    print(\"%s: %.2f%%\" % (\"F1 Score\", m*100))\n    Y_P = model.predict(X)\n    matrix = confusion_matrix(Y.argmax(axis=1), Y_P.argmax(axis=1))\n    print(\"Confusion Matrix is:\")\n    print(matrix)","93bd60c2":"def resnet_layer(inputs,\n                 num_filters=16,\n                 kernel_size=3,\n                 strides=1,\n                 activation='relu',\n                 batch_normalization=True,\n                 conv_first=True):\n    \n    conv = Conv2D(num_filters,\n                  kernel_size=kernel_size,\n                  strides=strides,\n                  padding='same',\n                  kernel_initializer='he_normal',\n                  kernel_regularizer=l2(1e-4))\n\n    x = inputs\n    if conv_first:\n        x = conv(x)\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n    else:\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n        x = conv(x)\n    return x","4c4409bf":"batch_size = 64\n\ndef get_resnet_model():\n    input_shape = (128,128,3)\n    output_classes = 3\n    num_filters = 16\n    depth = 20  # depth = 6n+2 and number of residual blocks = n\n                # inital layer and output layer rest all residual blocks\n    \n    no_residual_blocks = int((depth-2)\/6)\n        \n    inputs = Input(input_shape)\n    \n    x = resnet_layer(inputs=inputs)\n    \n    for stack in range(3):\n        for res_block in range(no_residual_blocks):\n            strides = 1\n            if stack > 0 and res_block == 0:  # first layer but not first stack\n                strides = 2  # downsample\n            y = resnet_layer(inputs=x,\n                             num_filters=num_filters,\n                             strides=strides)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters,\n                             activation=None)\n            if stack > 0 and res_block == 0:\n                x = resnet_layer(inputs=x,\n                                 num_filters=num_filters,\n                                 kernel_size=1,\n                                 strides=strides,\n                                 activation=None,\n                                 batch_normalization=False)\n            x = keras.layers.add([x, y])\n            x = Activation('relu')(x)\n        num_filters *= 2\n\n    x = AveragePooling2D(pool_size=8)(x)\n    x = Flatten()(x)\n    x = Dense(units=1024, activation='relu')(x)\n    x = Dropout(0.2)(x)\n    \n    outputs = Dense(3, activation='softmax',kernel_initializer='he_normal')(x)\n    \n    model = Model(inputs=inputs, outputs=outputs)\n    return model","f975c945":"model = get_resnet_model()\nmodel.summary()\nmodel.compile(  optimizer='adam',\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])","053b6773":"model.fit(X_train, Y_train, batch_size, epochs = 32)","dfa9b7b6":"save_model(model, \"final_resnet_20_200\")","c70ad0c6":"loaded_model = load_model(\"..\/input\/covidresnet20\/model_final_resnet_20_200.json\", \"..\/input\/covidresnet20\/model_final_resnet_20_200.h5\")\nloaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', Precision(), Recall()])\nloaded_model.summary()","368e44eb":"get_params(loaded_model, X_test, Y_test)","0d4f59f4":"from keras.utils.vis_utils import plot_model\nplot_model(loaded_model,show_shapes = True, show_layer_names = True)","a57e18c7":"imagegen = ImageDataGenerator(\n    rescale=1.\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    vertical_flip=True\n)\n\nimagegen.fit(X_train)\n\nimage_generator = imagegen.flow(X_train, Y_train, batch_size=batch_size)\n\nmodel.fit_generator(image_generator,\n                    steps_per_epoch=len(X_train) \/\/ batch_size, epochs=8)"}}