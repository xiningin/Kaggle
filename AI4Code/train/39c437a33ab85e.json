{"cell_type":{"9ee3c896":"code","c9a77ffd":"code","d1417725":"code","c0ba6c10":"code","988fcd9d":"code","f62d46cf":"code","b6f21628":"code","dc0f6a6f":"code","08d640f9":"code","569e1b6e":"code","2d81b984":"code","f729efd9":"code","e4f8a373":"code","b6064080":"code","b1d00513":"code","1091ef0c":"code","44c4b316":"code","1c2a5735":"code","b6e6fea4":"code","4be30235":"code","1f4c1807":"code","66cf287d":"code","f8425c0a":"code","ac5da61f":"code","f3bab387":"code","71ecb379":"code","44a2f687":"code","cde258e1":"code","efdf9d3a":"code","d47aa881":"code","f466e69a":"code","62675356":"code","e4f74578":"code","5b9e480e":"code","99b89a04":"markdown","a6ff1482":"markdown","dc36b8d0":"markdown","574ada28":"markdown","14807fdf":"markdown","f104bfb7":"markdown","492737af":"markdown","dc0b8f21":"markdown","116fbc2a":"markdown","7a85c068":"markdown","996898ba":"markdown","30168b50":"markdown","1e3d0c48":"markdown","6f6dd0eb":"markdown","e99bcd5a":"markdown","a5280f18":"markdown","1016c738":"markdown","3522317a":"markdown","dcc96263":"markdown","037f5fab":"markdown","f651f82d":"markdown","c934aca1":"markdown","b5c52ec7":"markdown","14f369a0":"markdown","9ec6633a":"markdown","4c9a1720":"markdown","93cede5f":"markdown","a51cff06":"markdown","89bf9eaa":"markdown"},"source":{"9ee3c896":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport seaborn as sns\n\n\nfrom sklearn.preprocessing import scale, StandardScaler\nfrom sklearn.model_selection import train_test_split,GridSearchCV,cross_val_score,KFold\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_score,f1_score, mean_squared_error,r2_score,recall_score,roc_auc_score,roc_curve\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\",category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\",category=FutureWarning)\n\n\nfrom imblearn.over_sampling import SMOTE","c9a77ffd":"original_data = pd.read_csv(\"..\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")\ndf = original_data.copy()","d1417725":"df.head()","c0ba6c10":"# It is not necessary\ndel df[\"id\"]","988fcd9d":"df.info()","f62d46cf":"for i in df.select_dtypes(include=['object']).columns:\n    if (len(np.unique(df[i])) > 2):\n        print(f\"==== [COLUMNS: {i}] ====\")\n        print(df[i].value_counts(),\"\\n\")\n        ","b6f21628":"# There is only 1 value \"Other\" in \"Gender\" variable. Therefore, i drop this. After this, i will use \"Label Encoder\" to encode \"gender\".\ndf.drop(df[df.gender == \"Other\"].index[0],axis=0,inplace=True)","dc0f6a6f":"df = pd.get_dummies(df,columns=[\"work_type\"])","08d640f9":"df = pd.get_dummies(df,columns=[\"smoking_status\"])","569e1b6e":"for i in df.select_dtypes(include=['object']).columns:\n    if (len(np.unique(df[i])) <= 2):\n        print(f\"==== [COLUMNS: {i}] ====\")\n        print(df[i].value_counts(),\"\\n\")\n        ","2d81b984":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()","f729efd9":"df.gender = le.fit_transform(df.gender)","e4f8a373":"df.ever_married = le.fit_transform(df.ever_married)","b6064080":"df.Residence_type = le.fit_transform(df.Residence_type)","b1d00513":"df.isna().sum()","1091ef0c":"from sklearn.impute import KNNImputer\n\nvar_names = list(df)\n\nimputer = KNNImputer(n_neighbors=2)\ndf_filled = imputer.fit_transform(df)\ndf_filled = pd.DataFrame(df_filled,columns=var_names)\ndf.bmi = df_filled.bmi","44c4b316":"df.isnull().sum()","1c2a5735":"# 1 value of \"bmi\" is nan. It is not necessary for now, let's drop it.\ndf.dropna(inplace=True)","b6e6fea4":"f, ax = plt.subplots(figsize=(12,10))\n\nsns.heatmap(df.corr(),mask=(np.triu(np.ones_like(df.corr(),dtype=bool))),vmax=.9,center=0,linewidths=.8);","4be30235":"sns.set_palette(\"flare\")\nsns.set_style(\"darkgrid\", {\"axes.facecolor\": \".95\"})","1f4c1807":"sns.countplot(data=original_data.sort_values(by=\"gender\"), x=\"gender\");","66cf287d":"sns.countplot(data=original_data.sort_values(by=\"hypertension\"), x=\"hypertension\");","f8425c0a":"ax = sns.countplot(data=original_data, x=\"ever_married\");","ac5da61f":"sns.countplot(data=original_data, x=\"work_type\");","f3bab387":"sns.countplot(data=original_data, x=\"Residence_type\");\n","71ecb379":"sns.countplot(data=original_data, x=\"smoking_status\");","44a2f687":"sns.countplot(data=original_data, x=\"stroke\");","cde258e1":"plt.figure(figsize=(10,10))\nsns.pairplot(original_data);","efdf9d3a":"algorithms = [\n    KNeighborsClassifier,\n    MLPClassifier,\n    LogisticRegression,\n    DecisionTreeClassifier,\n    RandomForestClassifier,\n    GradientBoostingClassifier,\n    LGBMClassifier,\n    XGBClassifier,\n]","d47aa881":"def CompareAlgorithms(df,                                 \n                      Y,                                  \n                      algorithm,                         \n                      feature_importance=False,           \n                      get_recall_score=True,\n                      get_f1_score=True,\n                      get_accuracy_score=True,\n                      get_precision_score=True,\n                      get_roc_auc_score=True,\n                      get_confusion_matrix=True,\n                      get_classification_report=True,\n                      Smote = False,\n                      metrics_average = None,\n                      feature_scaling = False,\n                      get_cv=False):\n    \n    \n    \"\"\"\n    parametres                  | Description\n    \n    df                            Dataframe \n    algorithm                     Algorithm\n    feature_importance            plots feature importance graph\n    get_recall_score              calculates recall score\n    get_accuracy_score            calculates accuracy score\n    get_precision_score           calculates precision score\n    get_roc_auc_score             calculates roc\/auc score\n    get_confusion_matrix          shows confusion matrix \n    get_classification_report     shows classification report\n    Smote                         uses \"SMOTE\" method\n    metrics_average               which method will be used when calculating the scores\n    feature_scaling               implements StandardScaler to x_train and x_test \n    get_cv                        uses \"K-FOLD and cross_val_score\" to calculate average model success\n    \"\"\"\n    \n    \n    scores = {\"Algorithm\":algorithm.__name__}\n    \n    \n    \"\"\" Dependent & Independent Variables\"\"\"\n    y = df[Y]\n    X = df.drop([Y],axis=1)\n    \n    \n    \"\"\" Train \/ Test Split \"\"\"\n    x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.33, random_state=11,shuffle=True)\n\n    \n    \"\"\" Feature Scaling \"\"\"\n    if feature_scaling:\n        sc = StandardScaler()\n        x_train = sc.fit_transform(x_train)\n        x_test = sc.transform(x_test)\n\n    \"\"\" SMOTE \"\"\"\n    if Smote:\n        sm = SMOTE(random_state=24)\n        x_train, y_train = sm.fit_resample(x_train,y_train.ravel())\n\n        \n    \"\"\" Create Model \"\"\"\n    model = algorithm().fit(x_train,y_train)\n    \n    \n    \n    \"\"\" Prediction \"\"\"\n    y_pred = model.predict(x_test)\n    \n    \n    \"\"\" Scores \"\"\"\n    if get_accuracy_score: \n        scores[\"accuracy_score\"] = accuracy_score(y_test,y_pred)*100\n    if get_precision_score:\n        scores[\"precision_score\"] = precision_score(y_test,y_pred,average = metrics_average)*100\n    if get_recall_score:\n        scores[\"recall_score\"] = recall_score(y_test,y_pred,average = metrics_average)*100\n    if get_f1_score:\n        scores[\"f1_score\"] = f1_score(y_test,y_pred,average = metrics_average)*100\n    if get_roc_auc_score:\n        scores[\"roc_auc_score\"] = roc_auc_score(y_test,y_pred)*100\n    \n            \n    \"\"\" K FOLD + CV \"\"\"\n    if get_cv:\n        kfold = KFold(n_splits=3,random_state=2,shuffle=True)\n        accuracy_score_cv = cross_val_score(model,x_test,y_test,cv=kfold,scoring = \"accuracy\").mean()\n        scores[\"accuracy_score_cv\"] = accuracy_score_cv\n    \n    \n    \"\"\" Confusion Matrix \"\"\"\n    if get_confusion_matrix:\n        cm = confusion_matrix(y_test,y_pred)\n        print(f\"\"\"=== {algorithm.__name__} Confusion Matrix ===\\n {cm} \\n\"\"\")\n    \n    \n    \"\"\" Classification Report \"\"\"\n    if get_classification_report:\n        print(f\"\"\"=== {algorithm.__name__} Classification Report ===\\n\\n\"\"\")\n        print(classification_report(y_test, y_pred))\n    \n    \n    \"\"\" Features Importance \"\"\"\n    \n    if feature_importance:\n        print(\"=\"*50)\n        try:\n            feature_imp = pd.Series(model.feature_importances_*100,index=x_train.columns).sort_values(ascending=False)\n            sns.barplot(x=feature_imp,y=feature_imp.index)\n            plt.title(f\"Features Importance: {algorithm.__name__}\")\n            plt.xlabel(\"Features Importance\")\n            plt.ylabel(\"Features\")\n            plt.show()\n        except:\n            pass\n        finally:\n            print(\"=\"*50)\n            print(\"\\n\")\n    \n    \n        \n    \"\"\"\n    return scores (type: dict)\n    \"\"\"\n    return scores","f466e69a":"scoresDF = pd.DataFrame()\n\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    for algorithm in algorithms:\n            score=CompareAlgorithms(df,\n                                    \"stroke\",\n                                    algorithm,\n                                    feature_importance=True,\n                                    get_cv=False,\n                                    metrics_average=\"binary\")\n\n            scoresDF = scoresDF.append(score, ignore_index=True)\n        ","62675356":"scoresDF","e4f74578":"# Sort values;\nscoresDF.sort_values(by=\"accuracy_score\",ascending = False,inplace=True)","5b9e480e":"# accuracy_score plot\nplt.figure(figsize=(10,10))\nsns.barplot(x=scoresDF[\"accuracy_score\"]*100,y=scoresDF[\"Algorithm\"]);","99b89a04":"## \"CompareAlgorithms\" Function;  <a id=\"21\"><\/a>","a6ff1482":"# \n# \n# <h1 style=\"background-color:#fff1e1;font-family:newtimeroman;font-size:250%;text-align:left;border-radius: 5px 5px;color:#d2601a\">Results<\/h1> <a id=\"22\"><\/a>","dc36b8d0":"## Ever Married | Count Plot <a id=\"13\"><\/a>","574ada28":"## Pair Plot <a id=\"18\"><\/a>","14807fdf":"## Hypertension | Count Plot <a id=\"12\"><\/a>","f104bfb7":"<hr style=\"width:100%;height:5px;border-width:0;color:gray;background-color:gray\"> \n\n\n<h1 style=\"background-color:#fff1e1;font-family:newtimeroman;font-size:350%;text-align:center;border-radius: 15px 50px;color:#1d3c45\">I will be waiting for your feedback :)<\/h1>\n\n\n<center>\n<link rel=\"stylesheet\" href=\"https:\/\/maxcdn.bootstrapcdn.com\/font-awesome\/4.4.0\/css\/font-awesome.min.css\">\n<a href=\"https:\/\/www.linkedin.com\/in\/ardasamet\/\" class=\"social-icon si-rounded si-small si-linkedin\">\n  <i class=\"fa fa-linkedin\"><\/i>\n<\/a>\n<\/center>\n\n","492737af":"## Gender | Count Plot <a id=\"11\"><\/a>","dc0b8f21":"### KNN Algorithm | to fill missing values <a id=\"8\"><\/a>","116fbc2a":"## Categorical Encoding <a id=\"4\"><\/a>","7a85c068":"### Polynomial Values <a id=\"5\"><\/a>","996898ba":"# <h1 style=\"background-color:#fff1e1;font-family:newtimeroman;font-size:250%;text-align:left;border-radius: 5px 5px;color:#d2601a\">Prediction<\/h1> <a id=\"19\"><\/a>","30168b50":"<h1 style=\"background-color:#fff1e1;font-family:newtimeroman;font-size:300%;text-align:left;border-radius: 10px 10px;color:#d2601a\">Table Of Content<\/h1>\n\n1. [Importing Libraries](#1) <br>\n2. [Frist Look](#2) <br>\n3. [Data Preprocessing](#3) <br>\n    3.1. [Categorical Encoding](#4) <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; a. [Polynomial Values](#5) <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; b. [Binomial Value](#6) <br>\n4. [Missing Values](#7) <br>\n    4.1. [KNN Algorithm to fill missing values](#8)<br>\n5. [Data Visualization](#9)<br>\n    a. [Heat Map Correlation](#10) <br>\n    b. [Gender | Count Plot](#11) <br>\n    c. [Hypertension | Count Plot](#12) <br>\n    d. [Ever Married | Count Plot](#13) <br>\n    e. [Work Type | Count Plot](#14) <br>\n    f. [Residence Type | Count Plot](#15) <br>\n    g. [Smoking | Count Plot](#16) <br>\n    h. [Stroke | Count Plot](#17) <br>\n    i. [Pair Plot](#18) <br>\n6. [Prediction](#19)<br>\n    6.1. [Algorithms](#20) <br>\n    6.2. [\"Compare Algorithms\" Function](#21) <br>\n    6.3. [Results](#22) <br>\n    ","1e3d0c48":"# <h1 style=\"background-color:#fff1e1;font-family:newtimeroman;font-size:250%;text-align:left;border-radius: 5px 5px;color:#d2601a\">Importing Libraries<\/h1> <a id=\"1\"><\/a>","6f6dd0eb":"# <h1 style=\"background-color:#fff1e1;font-family:newtimeroman;font-size:250%;text-align:left;border-radius: 5px 5px;color:#d2601a\">Missing Values<\/h1> <a id=\"7\"><\/a>","e99bcd5a":"### Polynomial Values;\n\n- work_type\n- smoking_status\n\n##### -> We will use \"pandas.get_dummies\" to encode polynomial values","a5280f18":"# <h1 style=\"background-color:#fff1e1;font-family:newtimeroman;font-size:250%;text-align:left;border-radius: 5px 5px;color:#d2601a\">Data Visualization<\/h1> <a id=\"9\"><\/a>","1016c738":"# \n# ","3522317a":"# <h1 style=\"background-color:#fff1e1;font-family:newtimeroman;font-size:250%;text-align:left;border-radius: 5px 5px;color:#d2601a\">Data Preprocessing<\/h1> <a id=\"3\"><\/a>","dcc96263":"## Smoking | Count Plot <a id=\"16\"><\/a>","037f5fab":"### Binomial Values <a id=\"6\"><\/a>","f651f82d":"## Work Type | Count Plot <a id=\"14\"><\/a>","c934aca1":"### Binomial Values;\n\n- gender\n- ever_married\n- Residence_type\n\n##### -> We will use \"sklearn.preprocessing.LabelEncoder\" to encode binomial values","b5c52ec7":"## Stroke | Count Plot <a id=\"17\"><\/a>","14f369a0":"<h1 style=\"background-color:#fff1e1;font-family:newtimeroman;font-size:350%;text-align:center;border-radius: 15px 50px;color:#1d3c45\">Welcome<\/h1>\n\n\n<h4><center><b>Hi, my name is Samet Arda ERDOGAN. I am a freshman in computer engineering. This is my first Machine Learning Notebook. Instead of creating and sharing a few standard ML models, I wrote a function as detailed as I could and tried to provide ease of processing with many parameters. Before this process, I tried to understand the data better with Data Preprocessing and Data Visualization <\/b><\/center><\/h4>\n\n<br>\n\n<center><b>\nI will be waiting for your feedback :)\n<\/b><\/center>\n\n<center>\n<link rel=\"stylesheet\" href=\"https:\/\/maxcdn.bootstrapcdn.com\/font-awesome\/4.4.0\/css\/font-awesome.min.css\">\n<a href=\"https:\/\/www.linkedin.com\/in\/ardasamet\/\" class=\"social-icon si-rounded si-small si-linkedin\">\n  <i class=\"fa fa-linkedin\"><\/i>\n<\/a>\n<\/center>\n\n<hr style=\"width:100%;height:5px;border-width:0;color:gray;background-color:gray\"> ","9ec6633a":"## Heat Map Correlation <a id=\"10\"><\/a>","4c9a1720":"## Algorithms <a id=\"20\"><\/a>","93cede5f":"## Residence Type | Count Plot <a id=\"15\"><\/a>","a51cff06":"# <h1 style=\"background-color:#fff1e1;font-family:newtimeroman;font-size:250%;text-align:left;border-radius: 5px 5px;color:#d2601a\">First Look<\/h1> <a id=\"2\"><\/a>","89bf9eaa":"##### "}}