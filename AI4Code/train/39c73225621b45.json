{"cell_type":{"61f82325":"code","043938b9":"code","002e469f":"code","66307316":"code","1155dfcb":"code","8bc8e00b":"code","719f8c80":"code","a5a52f26":"code","8bdf0fce":"code","653ff0d6":"code","a9666bcf":"code","118a2125":"code","23ea68fe":"code","a9becc4a":"code","afb1a7e1":"code","998acded":"code","87f4790c":"code","3eb36fdd":"code","e189cd80":"code","443e902b":"code","cc34ca03":"code","f6893628":"code","1f96460d":"code","12b1398f":"code","c8e8b2a8":"code","c98ea474":"code","51535ae1":"code","c44b2291":"code","52881454":"code","1ac077b0":"code","75d07813":"code","75d7e094":"code","cc7124c1":"code","713724f3":"code","2e63f6bd":"code","e70f5511":"code","73fb1cd7":"code","6154665c":"code","3ae626ef":"code","8a731114":"code","5ddf7004":"code","e484818c":"code","a7a8dc7d":"code","dceff998":"code","43fcf8de":"code","2dfa749a":"code","38d1cac0":"code","7d7a475e":"code","4dab61b7":"code","4e0190c9":"code","c6328d42":"code","c4cff44c":"code","6897c297":"code","cf57720b":"code","23e54cb9":"code","839ae1ba":"code","8613f17c":"code","81a695ee":"code","fe3ca57c":"code","54331498":"code","ff6bef35":"code","77fc59e7":"code","956d697f":"code","c29d86cc":"code","c6e0c6e8":"code","a5cb96de":"code","104fbd92":"code","2c13fea1":"code","3222b32d":"code","09886a3c":"code","b5f9e898":"code","a9803682":"code","72abe17d":"code","8c33d78d":"code","e298384e":"code","9cc445ba":"code","ff8eb1df":"code","14953f8b":"markdown","ee40d14b":"markdown","d81cf741":"markdown","92623341":"markdown","43035315":"markdown","fd55f537":"markdown","89023787":"markdown"},"source":{"61f82325":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","043938b9":"dr=pd.read_csv('\/kaggle\/input\/drug-classification\/drug200.csv')\ndr.head()","002e469f":"full=pd.read_csv('\/kaggle\/input\/drug-classification\/drug200.csv')","66307316":"print(dr.info())\n#no null values\ndr.nunique()","1155dfcb":"features_c=[features for features in dr.columns if dr[features].dtypes=='O']\nfeatures_c","8bc8e00b":"\nimport seaborn as sns\n","719f8c80":"sns.countplot(x=dr['Sex'],data=dr)\nprint(dr.Sex.value_counts(),'\\n')        \n        ","a5a52f26":"sns.countplot(x=dr['BP'],data=dr)\nprint(dr.BP.value_counts(),'\\n')       ","8bdf0fce":"sns.countplot(x=dr['Cholesterol'],data=dr)\nprint(dr.Cholesterol.value_counts(),'\\n')       ","653ff0d6":"sns.countplot(x=dr['Drug'],data=dr)\nprint(dr.Drug.value_counts(),'\\n')       ","a9666bcf":"features_n=[features for features in dr.columns if dr[features].dtypes!='O']\nfeatures_n","118a2125":"import matplotlib.pyplot as plt\nplt.subplot(121)\nsns.distplot(dr['Age'],color=\"m\",bins=35);\n\nplt.subplot(122)\ndr['Age'].plot.box(figsize=(16,5))\n\nplt.show()\n\nplt.subplot(121)\nsns.distplot(dr['Na_to_K'],color=\"r\");\n\nplt.subplot(122)\ndr['Na_to_K'].plot.box(figsize=(16,5))\n\nplt.show()\n","23ea68fe":"dr.describe()","a9becc4a":"features_c","afb1a7e1":"print(pd.crosstab(dr['Sex'],dr['Drug']))\n\nsns.set(style=\"white\", context=\"talk\")\nsns.countplot(x=\"Sex\",hue=\"Drug\",data=dr,edgecolor=(0,0,0))","998acded":"print(pd.crosstab(dr['BP'],dr['Drug']))\nsns.set(style=\"white\", context=\"talk\")\nsns.countplot(x=\"BP\",hue=\"Drug\",data=dr,edgecolor=(0,0,0))","87f4790c":"print(pd.crosstab(dr['Cholesterol'],dr['Drug']))\n\nsns.set(style=\"white\", context=\"talk\")\nsns.countplot(x=\"Cholesterol\",hue=\"Drug\",data=dr,edgecolor=(0,0,0))","3eb36fdd":"features_n","e189cd80":"sns.set_style('whitegrid')\nsns.scatterplot(y=\"Drug\",x=\"Age\",data=dr,hue='Drug')","443e902b":"sns.set_style('whitegrid')\nsns.scatterplot(y=\"Drug\",x=\"Na_to_K\",data=dr,hue='Drug')","cc34ca03":"sns.set_style('whitegrid')\nsns.scatterplot(y=\"Age\",x=\"Na_to_K\",data=dr,hue='Drug')","f6893628":"features_c","1f96460d":"dr.Sex.unique()","12b1398f":"full['Sex']=full['Sex'].map({'M':1,'F':0})","c8e8b2a8":"full.head()","c98ea474":"dr.BP.unique()","51535ae1":"full['BP']=full['BP'].map({'LOW':0,'NORMAL':1,'HIGH':2})","c44b2291":"full.Cholesterol.unique()","52881454":"full['Cholesterol']=full['Cholesterol'].map({'NORMAL':1,'HIGH':2})","1ac077b0":"dr.Drug.unique()","75d07813":"full['Drug']=full['Drug'].map({'DrugY':0,'drugC':1,'drugA':2,'drugB':3})","75d7e094":"plt.figure(figsize = (18,12))\nsns.heatmap(full.corr(), annot = True, cmap = \"RdYlGn\")\n\nplt.show()","cc7124c1":"features_c","713724f3":"dr['BP']=dr['BP'].map({'LOW':0,'NORMAL':1,'HIGH':2})\ndr['Cholesterol']=dr['Cholesterol'].map({'NORMAL':1,'HIGH':2})","2e63f6bd":"dr.head()","e70f5511":"fig = plt.figure(figsize=(14, 4))\nax1 = plt.subplot(121)\nsns.distplot(dr['Age'])\n \nax1.set_title(\"Age\")\n\nax1 = plt.subplot(122)\nsns.distplot(dr['Na_to_K'])\nax1.set_title(\"Na_to_K\")","73fb1cd7":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndr['Drug']= le.fit_transform(dr['Drug'])\n","6154665c":"dr.head()","3ae626ef":"s= dr[['Sex']] # one hot encoding\n\ns=pd.get_dummies(s,drop_first=True)\n\ns.head()","8a731114":"data_train = pd.concat([dr,s], axis = 1)\ndata_train.head()","5ddf7004":"data_train.drop(['Sex'],axis=1 , inplace = True)","e484818c":"data_train.info()","a7a8dc7d":"data_train.head()","dceff998":"y=data_train['Drug']\nX=data_train.drop('Drug',axis=1)","43fcf8de":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state =1, shuffle = True)","2dfa749a":"print(\"x_train shape:\",x_train.shape)\nprint(\"x_test shape:\",x_test.shape)\nprint(\"y_train shape:\",y_train.shape)\nprint(\"y_test shape:\",y_test.shape)","38d1cac0":"# import libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n# Importing Classifier Modules\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\nfrom sklearn.model_selection import cross_val_score","7d7a475e":"from sklearn.model_selection import KFold\nk_fold = KFold(n_splits=10, shuffle=True, random_state=1)","4dab61b7":"result_dict_train = {}\nresult_dict_test = {}","4e0190c9":"from sklearn.model_selection import GridSearchCV","c6328d42":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\naccuracies = cross_val_score(knn, x_train, y_train, cv=5)\nknn.fit(x_train,y_train)\n\nprint(\"Train Score:\",np.mean(accuracies))\nprint(\"Test Score:\",knn.score(x_test,y_test))","c4cff44c":"result_dict_train[\"KNN Default Train Score\"] = np.mean(accuracies)\nresult_dict_test[\"KNN Default Test Score\"] = knn.score(x_test,y_test)","6897c297":"grid = {'n_neighbors':np.arange(1,120),\n        'p':np.arange(1,3),\n        'weights':['uniform','distance']\n       }\n\nknn = KNeighborsClassifier(algorithm = \"auto\")\nknn_cv = GridSearchCV(knn,grid,cv=5)\nknn_cv.fit(x_train,y_train)\n\nprint(\"Hyperparameters:\",knn_cv.best_params_)\nprint(\"Train Score:\",knn_cv.best_score_)\nprint(\"Test Score:\",knn_cv.score(x_test,y_test))","cf57720b":"result_dict_train[\"KNN GridSearch Train Score\"] = knn_cv.best_score_\nresult_dict_test[\"KNN GridSearch Test Score\"] = knn_cv.score(x_test,y_test)","23e54cb9":"#random forest\nfrom sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(random_state = 1)\naccuracies = cross_val_score(rfc, x_train, y_train, cv=5)\nrfc.fit(x_train,y_train)\n\nprint(\"Train Score:\",np.mean(accuracies))\nprint(\"Test Score:\",rfc.score(x_test,y_test))","839ae1ba":"result_dict_train[\"Random Forest Default Train Score\"] = np.mean(accuracies)\nresult_dict_test[\"Random Forest Default Test Score\"] = rfc.score(x_test,y_test)","8613f17c":"from sklearn.model_selection import RandomizedSearchCV","81a695ee":"#Randomized Search CV\n\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10, 15, 100]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 5, 10]","fe3ca57c":"# Create the random grid\n\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf}","54331498":"# Random search of parameters, using 5 fold cross validation, \n# search across 100 different combinations\nrf_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=1, n_jobs = 1)","ff6bef35":"rf_random.fit(x_train,y_train)","77fc59e7":"rf_random.best_params_","956d697f":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(random_state = 1,n_estimators=100,min_samples_split=2,min_samples_leaf=1,max_features='auto',max_depth=15)\naccuracies = cross_val_score(rfc, x_train, y_train, cv=5)\nrfc.fit(x_train,y_train)\n\nprint(\"Train Score:\",np.mean(accuracies))\nprint(\"Test Score:\",rfc.score(x_test,y_test))","c29d86cc":"\nresult_dict_train[\"Random Forest Default Train Score\"] = np.mean(accuracies)\nresult_dict_test[\"Random Forest Default Test Score\"] = rfc.score(x_test,y_test)","c6e0c6e8":"from sklearn.svm import SVC\nsvc = SVC(random_state = 1)\naccuracies = cross_val_score(svc, x_train, y_train, cv=5)\nsvc.fit(x_train,y_train)\n\nprint(\"Train Score:\",np.mean(accuracies))\nprint(\"Test Score:\",svc.score(x_test,y_test))","a5cb96de":"result_dict_train[\"SVM Default Train Score\"] = np.mean(accuracies)\nresult_dict_test[\"SVM Default Test Score\"] = svc.score(x_test,y_test)","104fbd92":"from sklearn.model_selection import GridSearchCV","2c13fea1":"grid = {\n    'C':[0.01,0.1,1,10],\n    'kernel' : [\"linear\",\"poly\",\"rbf\",\"sigmoid\"],\n    'degree' : [1,3,5,7],\n    'gamma' : [0.01,1]\n}\n\nsvm  = SVC ();\nsvm_cv = GridSearchCV(svm, grid, cv = 5)\nsvm_cv.fit(x_train,y_train)\nprint(\"Best Parameters:\",svm_cv.best_params_)\nprint(\"Train Score:\",svm_cv.best_score_)\nprint(\"Test Score:\",svm_cv.score(x_test,y_test))","3222b32d":"result_dict_train[\"SVM GridSearch Train Score\"] = svm_cv.best_score_\nresult_dict_test[\"SVM GridSearch Test Score\"] = svm_cv.score(x_test,y_test)","09886a3c":"df_result_train = pd.DataFrame.from_dict(result_dict_train,orient = \"index\",columns=[\"Score\"])\ndf_result_train","b5f9e898":"df_result_test = pd.DataFrame.from_dict(result_dict_test,orient = \"index\",columns=[\"Score\"])\ndf_result_test","a9803682":"fig,ax = plt.subplots(1,2,figsize=(20,5))\nsns.barplot(x = df_result_train.index,y = df_result_train.Score,ax = ax[0])\nsns.barplot(x = df_result_test.index,y = df_result_test.Score,ax = ax[1])\nax[0].set_xticklabels(df_result_train.index,rotation = 75)\nax[1].set_xticklabels(df_result_test.index,rotation = 75)\nplt.show()","72abe17d":"#random forest\ny_pred=rfc.predict(x_test)","8c33d78d":"from sklearn.metrics import confusion_matrix","e298384e":"confusion_matrix(y_test, y_pred)","9cc445ba":"#SVM\ny_pred1=svm_cv.predict(x_test)","ff8eb1df":"confusion_matrix(y_test, y_pred1)","14953f8b":"no need of normalization I think so","ee40d14b":"**numerics**","d81cf741":"# bivarative analysis","92623341":"lets do an hyperparameter tuning for random forest","43035315":"**numericaldata**","fd55f537":"lets use labelencoding for Bp and cholestrol","89023787":"# univariative analysis"}}