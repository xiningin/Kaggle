{"cell_type":{"908daf86":"code","15b116fc":"code","defb7b55":"code","405e9c1d":"code","9311a747":"code","6f7c90c1":"code","62e6f6d9":"code","6782f07b":"code","8153bddf":"code","2ed5cdd0":"code","2f7d11b0":"code","e4c72e49":"code","f674fbc0":"code","c65a55df":"code","eedb81c0":"code","2a9637db":"code","fc7189fa":"code","767b152d":"code","715aca0a":"code","3c97e904":"code","5086d5a8":"code","4f96001c":"code","90c2ee37":"code","ceade82d":"code","d4c6f4a9":"code","cb49283d":"code","286ab87a":"code","18be73f4":"code","35056e49":"code","a3d8e145":"markdown","c3ed6e28":"markdown","3de576fa":"markdown","d155c02f":"markdown","48222b38":"markdown","7a7830d1":"markdown","bafa9194":"markdown","186f9576":"markdown"},"source":{"908daf86":"from collections import Counter\nimport zipfile\n\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.sparse import csr_matrix\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import InputLayer, Dense, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","15b116fc":"train_archive = zipfile.ZipFile('\/kaggle\/input\/whats-cooking\/train.json.zip', 'r')\ntrain_data = pd.read_json(train_archive.open('train.json'))\nprint('train shape:', train_data.shape)\n\ntest_archive = zipfile.ZipFile('\/kaggle\/input\/whats-cooking\/test.json.zip', 'r')\ntest_data = pd.read_json(test_archive.open('test.json'))\nprint('test shape:', test_data.shape)\n\nsample_submission_archive = zipfile.ZipFile('\/kaggle\/input\/whats-cooking\/sample_submission.csv.zip', 'r')\nsample_submission_data = pd.read_csv(sample_submission_archive.open('sample_submission.csv'))","defb7b55":"train_data","405e9c1d":"train_data.info()  # clean","9311a747":"train_data['size'] = train_data['ingredients'].apply(len)","6f7c90c1":"with sns.axes_style('darkgrid'), sns.plotting_context('talk'):\n    pd.value_counts(train_data['cuisine']).plot.bar(figsize=(12, 5))\n    plt.xticks(rotation=80)\n    plt.ylabel('number of recipes')","62e6f6d9":"with sns.axes_style('darkgrid'), sns.plotting_context('talk'):\n    train_data.groupby('cuisine')['size'].mean().plot.bar(figsize=(12, 5))\n    plt.xticks(rotation=80)\n    plt.ylabel('average ingredients count')\n    plt.xlabel('')","6782f07b":"def to_counters(recipes):\n    counters = []\n    for recipe in recipes:\n        counters.append(Counter(recipe))\n    return counters\n\n\nclass WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self, vocabulary_size=None, accumulate_outliers=False):\n        self.vocabulary_size = vocabulary_size \n        self.bias = int(accumulate_outliers)        \n        \n        \n    def fit(self, X, y=None):\n        total_count = Counter()\n        for word_counts in X:\n            for word, count in word_counts.items():\n                total_count[word] += 1\n        if self.vocabulary_size is None:\n            self.vocabulary_size = len(total_count)\n        most_common = total_count.most_common()[:self.vocabulary_size]\n        self.most_common_ = most_common\n        self.vocabulary_ = {word: index + self.bias for index, (word, count) in enumerate(most_common)}\n        return self\n    \n    \n    def transform(self, X, y=None):\n        rows = []\n        cols = []\n        data = []\n        for row, word_counts in enumerate(X):\n            for word, count in word_counts.items():\n                if self.bias or word in self.vocabulary_:\n                    rows.append(row)\n                    cols.append(self.vocabulary_.get(word, 0))\n                    data.append(count)\n        return csr_matrix((data, (rows, cols)), shape=(len(X), (self.vocabulary_size + self.bias)))","8153bddf":"X = train_data['ingredients'].values\ny = train_data['cuisine'].values","2ed5cdd0":"sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\ntrain_index, valid_index = next(sss.split(X, y))\nX_train, X_valid = X[train_index], X[valid_index]\ny_train, y_valid = y[train_index], y[valid_index]\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","2f7d11b0":"vectorizer = WordCounterToVectorTransformer()\nX_train_sparce = vectorizer.fit_transform(to_counters(X_train))\nX_valid_sparce = vectorizer.transform(to_counters(X_valid))\nX_train_sparce[X_train_sparce > 1] = 1\nX_valid_sparce[X_valid_sparce > 1] = 1\nX_train_vec = X_train_sparce.toarray()\nX_valid_vec = X_valid_sparce.toarray()\n\nonehot = OneHotEncoder()\ny_train_onehot = onehot.fit_transform(y_train.reshape(-1, 1)).toarray()\ny_valid_onehot = onehot.transform(y_valid.reshape(-1, 1)).toarray()","e4c72e49":"def fit_classifier(classifier):\n    classifier.fit(X_train_sparce, y_train)\n    y_train_pred = classifier.predict(X_train_sparce)\n    y_valid_pred = classifier.predict(X_valid_sparce)\n    train_acc = accuracy_score(y_train, y_train_pred)\n    valid_acc = accuracy_score(y_valid, y_valid_pred)\n    print(f'train accuracy: {train_acc:.5f}\\nvalidation accuracy: {valid_acc:.5f}')","f674fbc0":"mnb = MultinomialNB()\nfit_classifier(mnb)","c65a55df":"knn = KNeighborsClassifier(n_neighbors=10, n_jobs=-1)\nfit_classifier(knn)","eedb81c0":"rfc = RandomForestClassifier(n_estimators=100, \n                             max_depth=60,\n                             min_samples_leaf=5, \n                             random_state=0, \n                             class_weight='balanced_subsample',                            \n                             max_features=0.2, \n                             n_jobs=-1)\nfit_classifier(rfc)","2a9637db":"gbc = GradientBoostingClassifier(n_estimators=30, max_features=0.2, random_state=0)\nfit_classifier(gbc)","fc7189fa":"abc = AdaBoostClassifier(n_estimators=100, random_state=0)\nfit_classifier(abc)","767b152d":"vc_all_h = VotingClassifier(estimators=[('mnb', mnb), ('knn', knn), ('rfc', rfc), ('gbc', gbc), ('abc', abc)], n_jobs=-1)\nfit_classifier(vc_all_h)","715aca0a":"vc_best_h = VotingClassifier(estimators=[('mnb', mnb), ('rfc', rfc), ('gbc', gbc)], n_jobs=-1)\nfit_classifier(vc_best_h)","3c97e904":"vc_all_s = VotingClassifier(estimators=[('mnb', mnb), ('knn', knn), ('rfc', rfc), ('gbc', gbc), ('abc', abc)], voting='soft', n_jobs=-1)\nfit_classifier(vc_all_s)","5086d5a8":"vc_best_s = VotingClassifier(estimators=[('mnb', mnb), ('rfc', rfc), ('gbc', gbc)], voting='soft', n_jobs=-1)\nfit_classifier(vc_best_s)","4f96001c":"K.clear_session()\n\ndef create_model():\n    dnn = Sequential()\n    dnn.add(InputLayer(input_shape=[X_train_vec.shape[1]]))\n    dnn.add(Dense(4000, activation='elu', kernel_initializer='he_normal'))\n    dnn.add(Dense(20, activation='softmax'))\n    return dnn\n\ndnn = create_model()\ndnn.compile(loss='categorical_crossentropy',\n            optimizer=Adam(lr=0.0001),\n            metrics=[\"accuracy\"])\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    min_delta=0,\n    patience=5,\n    verbose=0,\n    mode='min',\n    restore_best_weights=True)\ncallbacks = [early_stopping]\n\ndnn.summary()","90c2ee37":"%%time\nhistory = dnn.fit(X_train_vec, y_train_onehot, \n                  epochs=50, \n                  batch_size=128,\n                  validation_data=(X_valid_vec, y_valid_onehot),\n                  callbacks=callbacks)","ceade82d":"dnn.evaluate(X_valid_vec, y_valid_onehot)","d4c6f4a9":"vectorizer_final = WordCounterToVectorTransformer()\nX_vec = vectorizer_final.fit_transform(to_counters(X)).toarray()\nX_vec[X_vec > 1] = 1\n\nonehot_final = OneHotEncoder()\ny_onehot = onehot_final.fit_transform(y.reshape(-1, 1)).toarray()\n\nK.clear_session()\n\ndnn_final = Sequential()\ndnn_final.add(InputLayer(input_shape=[X_vec.shape[1]]))\ndnn_final.add(Dense(4000, activation='elu', kernel_initializer='he_normal'))\ndnn_final.add(Dense(20, activation='softmax'))\ndnn_final.compile(loss='categorical_crossentropy',\n                  optimizer=Adam(lr=0.0001),\n                  metrics=[\"accuracy\"])\n\ndnn_final.summary()","cb49283d":"%%time\nhistory_final = dnn_final.fit(X_vec, y_onehot, \n                              epochs=6, \n                              batch_size=128)","286ab87a":"dnn_final.save('final.h5')","18be73f4":"# dnn_final = load_model('final.h5')","35056e49":"X_test = test_data['ingredients'].values\nX_test = vectorizer_final.transform(to_counters(X_test)).toarray()\n\ny_test_pred = dnn_final.predict_classes(X_test)\ny_test_pred = onehot_final.categories_[0][y_test_pred]\n\nanswers = test_data.copy()\nanswers = answers.drop('ingredients', axis=1)\nanswers['cuisine'] = y_test_pred\nanswers.to_csv('answers.csv', index=False)\nanswers","a3d8e145":"**Try ML models**","c3ed6e28":"**Prepare data (feature engineering)**","3de576fa":"**We get a good model configuration, now let's train a final model on the whole dataset**","d155c02f":"**Achieved accuracy in a competition: 79.092%**","48222b38":"**Take a look at data**","7a7830d1":"**Loading data**","bafa9194":"**All necessary imports**","186f9576":"**Try DL models**"}}