{"cell_type":{"6c90ea0d":"code","c6362e62":"code","f6011b6c":"code","5c259a27":"code","abc4ec04":"code","530af7e6":"code","1a85965d":"code","c8ab472f":"code","e84c74db":"code","e7113444":"code","b536846c":"code","14da4ded":"code","04291296":"code","4ccff2d9":"code","3884173b":"code","06eab716":"code","3157dad7":"code","0669156e":"code","0f10a440":"code","aef0c9b1":"code","c2c12425":"code","873b8bbb":"code","63f8cdd0":"code","3ba7898e":"code","95c83c74":"code","51fb35db":"code","4159b5ac":"code","8d58bb58":"code","cabc1502":"code","9709cf68":"code","0fca28cc":"code","81c2d714":"code","26f616a9":"code","e56d7d55":"code","01265805":"code","85c405f3":"code","c7444439":"code","bba824bf":"code","840a298a":"code","b213ec03":"code","1e92deb5":"code","848c0ed6":"code","7b8e5338":"code","4da90f28":"code","b41562d2":"code","58c83c36":"code","ed23e7f5":"markdown","070950b7":"markdown","e29b0706":"markdown","db1330ba":"markdown","f247e6cd":"markdown","015d00aa":"markdown","b2843bca":"markdown","82a0aa01":"markdown","a3beb19f":"markdown","c63ef682":"markdown","6df4b28e":"markdown","3e3fc506":"markdown","429bec71":"markdown","0f34ce93":"markdown","64f3f1b5":"markdown","94910b7f":"markdown","ebe81251":"markdown","805519cf":"markdown","08f6d46e":"markdown","18befcf2":"markdown","99b0c6f1":"markdown","54bd69e2":"markdown","f6054e92":"markdown","a2817476":"markdown","c1430d1d":"markdown","29a30a24":"markdown","90d9af61":"markdown","7111e04f":"markdown","688f93c1":"markdown","4a1730c7":"markdown"},"source":{"6c90ea0d":"import numpy as np\nimport pandas as pd\nimport scipy.special\nimport matplotlib.pyplot as plt\nimport os","c6362e62":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import roc_auc_score\nfrom xgboost import XGBClassifier","f6011b6c":"path_in = '..\/input\/cat-in-the-dat\/'\nprint(os.listdir(path_in))","5c259a27":"train_data = pd.read_csv(path_in+'train.csv', index_col=0)\ntest_data = pd.read_csv(path_in+'test.csv', index_col=0)\nsamp_subm = pd.read_csv(path_in+'sample_submission.csv', index_col=0)","abc4ec04":"def plot_bar(data, name):\n    data_label = data[name].value_counts()\n    dict_train = dict(zip(data_label.keys(), ((data_label.sort_index())).tolist()))\n    names = list(dict_train.keys())\n    values = list(dict_train.values())\n    plt.bar(names, values)\n    plt.grid()\n    plt.show()","530af7e6":"def plot_bar_compare(train, test, name, rot=False):\n    \"\"\" Compare the distribution between train and test data \"\"\"\n    fig, axs = plt.subplots(1, 2, figsize=(9, 3), sharey=True)\n    \n    train_label = train[name].value_counts().sort_index()\n    dict_train = dict(zip(train_label.keys(), ((100*(train_label)\/len(train.index)).tolist())))\n    train_names = list(dict_train.keys())\n    train_values = list(dict_train.values())\n    \n    test_label = test[name].value_counts().sort_index()\n    dict_test = dict(zip(test_label.keys(), ((100*(test_label)\/len(test.index)).tolist())))\n    test_names = list(dict_test.keys())\n    test_values = list(dict_test.values())\n    \n    axs[0].bar(train_names, train_values, color='yellowgreen')\n    axs[1].bar(test_names, test_values, color = 'sandybrown')\n    axs[0].grid()\n    axs[1].grid()\n    axs[0].set_title('Train data')\n    axs[1].set_title('Test data')\n    axs[0].set_ylabel('%')\n    if(rot==True):\n        axs[0].set_xticklabels(train_names, rotation=45)\n        axs[1].set_xticklabels(test_names, rotation=45)\n    plt.show()","1a85965d":"print('# samples train:', len(train_data))\nprint('# samples test:', len(test_data))","c8ab472f":"cols_with_missing_train_data = [col for col in train_data.columns if train_data[col].isnull().any()]\ncols_with_missing_test_data = [col for col in test_data.columns if test_data[col].isnull().any()]\nprint('train cols with missing data:', cols_with_missing_train_data)\nprint('test cols with missing data:', cols_with_missing_test_data)","e84c74db":"train_data.columns","e7113444":"train_data.head()","b536846c":"plot_bar(train_data, 'target')","14da4ded":"features_bin = ['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4']\nfeatures_cat = ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']\nfeatures_hex = ['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']\nfeatures_ord = ['ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5']\nfeatures_cyc = ['day', 'month']","04291296":"map_ord_1 = {'Novice':1, 'Contributor':2, 'Expert':3, 'Master':4, 'Grandmaster':5}\nmap_ord_2 = {'Freezing': 1, 'Cold':2, 'Warm':3, 'Hot':4, 'Boiling Hot': 5, 'Lava Hot':6}\nmap_ord_3 = dict(zip(train_data['ord_3'].value_counts().sort_index().keys(),\n                     range(1, len(train_data['ord_3'].value_counts())+1)))\nmap_ord_4 = dict(zip(train_data['ord_4'].value_counts().sort_index().keys(),\n                     range(1, len(train_data['ord_4'].value_counts())+1)))","4ccff2d9":"temp_ord_5 = pd.DataFrame(train_data['ord_5'].value_counts().sort_index().keys(), columns=['ord_5'])\ntemp_ord_5['First'] = temp_ord_5['ord_5'].astype(str).str[0].str.upper()\ntemp_ord_5['Second'] = temp_ord_5['ord_5'].astype(str).str[1].str.upper()\ntemp_ord_5['First'] = temp_ord_5['First'].replace(map_ord_4)\ntemp_ord_5['Second'] = temp_ord_5['Second'].replace(map_ord_4)\ntemp_ord_5['Add'] = temp_ord_5['First']+temp_ord_5['Second']\ntemp_ord_5['Mul'] = temp_ord_5['First']*temp_ord_5['Second']\nmap_ord_5 = dict(zip(temp_ord_5['ord_5'],\n                     temp_ord_5['Mul']))","3884173b":"plot_bar_compare(train_data, test_data, 'nom_0')","06eab716":"train_data['rgb'] = np.where(train_data['nom_0'] == 'Green', 0, 1)\ntest_data['rgb'] = np.where(test_data['nom_0'] == 'Green', 0, 1)","3157dad7":"plot_bar_compare(train_data, test_data, 'nom_1', rot=True)","0669156e":"train_data['round'] = np.where(train_data['nom_1'] == 'Circle', 1, 0)\ntest_data['round'] = np.where(test_data['nom_1'] == 'Circle', 1, 0)","0f10a440":"plot_bar_compare(train_data, test_data, 'nom_2', rot=True)","aef0c9b1":"train_data['feet'] = np.where(train_data['nom_2'] == 'Snake', 0, 1)\ntest_data['feet'] = np.where(test_data['nom_2'] == 'Snake', 0, 1)","c2c12425":"plot_bar_compare(train_data, test_data, 'nom_3', rot=True)","873b8bbb":"train_data['monarchy'] = np.where(train_data['nom_3'] == 'Canada', 1, 0)\ntest_data['monarchy'] = np.where(test_data['nom_3'] == 'Canada', 1, 0)","63f8cdd0":"plot_bar_compare(train_data, test_data, 'nom_4', rot=True)","3ba7898e":"train_data['electro'] = np.where(train_data['nom_4'] == 'Theremin', 1, 0)\ntest_data['electro'] = np.where(test_data['nom_4'] == 'Theremin', 1, 0)","95c83c74":"y_train = train_data['target']\ndel train_data['target']","51fb35db":"X_train = train_data.copy()\nX_test = test_data.copy()","4159b5ac":"le = LabelEncoder()\nfor col in features_bin:\n    le.fit(X_train[col])\n    X_train[col] = le.transform(X_train[col])\n    X_test[col] = le.transform(X_test[col])","8d58bb58":"le = LabelEncoder()\nfor col in features_cat:\n    le.fit(X_train[col])\n    X_train[col] = le.transform(X_train[col])\n    X_test[col] = le.transform(X_test[col])","cabc1502":"le = LabelEncoder()\nfor col in features_hex:\n    le.fit(X_train[col].append(X_test[col]))\n    X_train[col] = le.transform(X_train[col])\n    X_test[col] = le.transform(X_test[col])","9709cf68":"X_train['ord_1'] = X_train['ord_1'].replace(map_ord_1)\nX_train['ord_2'] = X_train['ord_2'].replace(map_ord_2)\nX_train['ord_3'] = X_train['ord_3'].replace(map_ord_3)\nX_train['ord_4'] = X_train['ord_4'].replace(map_ord_4)\nX_train['ord_5'] = X_train['ord_5'].replace(map_ord_5)\nX_test['ord_1'] = X_test['ord_1'].replace(map_ord_1)\nX_test['ord_2'] = X_test['ord_2'].replace(map_ord_2)\nX_test['ord_3'] = X_test['ord_3'].replace(map_ord_3)\nX_test['ord_4'] = X_test['ord_4'].replace(map_ord_4)\nX_test['ord_5'] = X_test['ord_5'].replace(map_ord_5)","0fca28cc":"for feature in features_cyc:\n    X_train[feature+'_sin'] = np.sin((2*np.pi*X_train[feature])\/max(X_train[feature]))\n    X_train[feature+'_cos'] = np.cos((2*np.pi*X_train[feature])\/max(X_train[feature]))\n    X_test[feature+'_sin'] = np.sin((2*np.pi*X_test[feature])\/max(X_test[feature]))\n    X_test[feature+'_cos'] = np.cos((2*np.pi*X_test[feature])\/max(X_test[feature]))\nX_train = X_train.drop(features_cyc, axis=1)\nX_test = X_test.drop(features_cyc, axis=1)","81c2d714":"mean = X_train[features_hex].mean(axis=0)\nX_train[features_hex] = X_train[features_hex].astype('float32')\nX_train[features_hex] -= X_train[features_hex].mean(axis=0)\nstd = X_train[features_hex].std(axis=0)\nX_train[features_hex] \/= X_train[features_hex].std(axis=0)\nX_test[features_hex] = X_test[features_hex].astype('float32')\nX_test[features_hex] -= mean\nX_test[features_hex] \/= std","26f616a9":"mean = X_train[features_ord].mean(axis=0)\nX_train[features_ord] = X_train[features_ord].astype('float32')\nX_train[features_ord] -= X_train[features_ord].mean(axis=0)\nstd = X_train[features_ord].std(axis=0)\nX_train[features_ord] \/= X_train[features_ord].std(axis=0)\nX_test[features_ord] = X_test[features_ord].astype('float32')\nX_test[features_ord] -= mean\nX_test[features_ord] \/= std","e56d7d55":"mean = X_train[features_cat].mean(axis=0)\nX_train[features_cat] = X_train[features_cat].astype('float32')\nX_train[features_cat] -= X_train[features_cat].mean(axis=0)\nstd = X_train[features_cat].std(axis=0)\nX_train[features_cat] \/= X_train[features_cat].std(axis=0)\nX_test[features_cat] = X_test[features_cat].astype('float32')\nX_test[features_cat] -= mean\nX_test[features_cat] \/= std","01265805":"X_train.columns","85c405f3":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.001, random_state=2020)","c7444439":"weight = float(len(y_train[y_train == 0]))\/float(len(y_train[y_train == 1]))\nw1 = np.array([1]*y_train.shape[0])\nw1[y_train==1]=weight","bba824bf":"X_train[features_cat]","840a298a":"model = XGBClassifier(objective ='binary:logistic',\n                      colsample_bytree = 0,\n                      learning_rate = 0.2,\n                      max_depth = 15,\n                      n_estimators = 1555,\n                      scale_pos_weight=2,\n                      random_state=2019,\n                      subsample=0.8)","b213ec03":"model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=True)#, sample_weight=w1)","1e92deb5":"importance = model.feature_importances_","848c0ed6":"fig = plt.figure(figsize=(10, 10))\nx = X_train.columns.values\nplt.barh(x, 100*importance)\nplt.title('Feature Importance', loc='left')\nplt.xlabel('Percentage')\nplt.grid()\nplt.show()","7b8e5338":"preds_val = model.predict_proba(X_val)[:,1]","4da90f28":"score = roc_auc_score(y_val ,preds_val)\nprint(\"score: %f\" % (score))","b41562d2":"y_test = model.predict_proba(X_test)[:,1]","58c83c36":"num = samp_subm.index\noutput = pd.DataFrame({'id': num,\n                       'target': y_test})\noutput.to_csv('submission.csv', index=False)","ed23e7f5":"# Classify the features","070950b7":"## Feature nom_2 - animals\nThe snake has no feet.","e29b0706":"# Define XGBClassifier and Predict\nDetermine the parameters of the XGB Classifier with a simple grid search.\n## Set model and fit","db1330ba":"# Define the scaler mappings for the ordinal features\nFor ord_0 is nothing to do.","f247e6cd":"# Show features","015d00aa":"# Overview\nWe have a look on the number of samples and check missing data. ","b2843bca":"## Ordinal features\nUse the mapping for ord_1 to ord_5.","82a0aa01":"# Intro \nWelcome to the great [Categorical Feature Encoding Challenge](https:\/\/www.kaggle.com\/c\/cat-in-the-dat)\n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/14999\/logos\/header.png)\nThis notebook is a starter code for all beginners and easy to understand. I used the following notebook to improve knowledge about encoding:\nhttps:\/\/www.kaggle.com\/shahules\/an-overview-of-encoding-techniques\n\nAdditionally there are created new features based on the relationsship between the nominal features. <br>\nThe first 10 Versions were running with Neural Network. Now it is used the XGB Classifier with a simple setting and great results.\n\n<span style=\"color: royalblue;\">Please vote the notebook up if it helps you. Thank you. <\/span>","a3beb19f":"# Load Libraries","c63ef682":"## Cyclic features","6df4b28e":"# Write the Export","3e3fc506":"## Evalaute the model with the val data","429bec71":"# Calc the class wights of the target","0f34ce93":"## Hexadecimal features\nUse the simple LabelEncoder.","64f3f1b5":"# Show target\nWe have a look on the distribution of the target values.","94910b7f":"# Input path","ebe81251":"# Plot bar function","805519cf":"# Plot the nominal features and think about a relationsship\n## Feature nom_0 - the color\nBlue and Red are colors of the RGB color space, Green not.","08f6d46e":"## Feature nom_4 - musical instruments\nThe Theremin is a electronical instrument.","18befcf2":"# Split train and val data","99b0c6f1":"## Predict test data","54bd69e2":"## Binary features\nUse the simple LabelEncoder.","f6054e92":"## Feature nom_3 - countries\nCanda is a monarchy.","a2817476":"\n## Feature Importance\nWe want to know useful are the features for predicting a target variable.","c1430d1d":"# Scale data","29a30a24":"## Feature nom_1 the geometric shape\nOnly the circle has no corners.","90d9af61":"# Define y_train","7111e04f":"# Read input data","688f93c1":"# Encode the features","4a1730c7":"## Categorical features\nUse the simple LabelEncoder."}}