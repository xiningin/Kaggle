{"cell_type":{"b437c72e":"code","4bac5c0d":"code","ce151223":"code","8327149d":"code","baf6147f":"code","3ee726a7":"code","3217ae6f":"code","f8ec5b13":"code","1b4d650a":"code","5e68d038":"code","7bcf42dd":"code","b15b6605":"code","5f40d5c1":"code","de13e034":"code","7ff07ce6":"code","eb94b3d0":"markdown","084ef43a":"markdown","2318b4d8":"markdown","f45aec5d":"markdown","38cac9f4":"markdown","ff334a5b":"markdown"},"source":{"b437c72e":"%matplotlib inline\nimport os\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.offsetbox import OffsetImage, AnnotationBbox\nimport cv2\nimport numpy as np\nfrom glob import glob\nimport matplotlib.cm as cm\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import StandardScaler\n\nBASE_DATA_FOLDER = \"..\/input\/covid19-image-dataset\/Covid19-dataset\"\nTRAin_DATA_FOLDER = os.path.join(BASE_DATA_FOLDER, \"train\")\n\n\nBASE_DATA_FOLDER = \"..\/input\/skin-cancer-dataset-original\"\nTRAin_DATA_FOLDER = os.path.join(BASE_DATA_FOLDER, \"Skin cancer ISIC\")\n","4bac5c0d":"def visualize_scatter_with_images(X_2d_data, images, figsize=(30,30), image_zoom=1):\n    fig, ax = plt.subplots(figsize=figsize)\n    artists = []\n    for xy, i in zip(X_2d_data, images):\n        x0, y0 = xy\n        img = OffsetImage(i, zoom=image_zoom)\n        ab = AnnotationBbox(img, (x0, y0), xycoords='data', frameon=False)\n        artists.append(ax.add_artist(ab))\n    ax.update_datalim(X_2d_data)\n    ax.autoscale()\n    plt.show()\n\ndef visualize_scatter(data_2d, label_ids, figsize=(15,15)):\n    plt.figure(figsize=figsize)\n    plt.grid()\n    \n    nb_classes = len(np.unique(label_ids))\n    \n    for label_id in np.unique(label_ids):\n        plt.scatter(data_2d[np.where(label_ids == label_id), 0],\n                    data_2d[np.where(label_ids == label_id), 1],\n                    marker='o',\n                    color= plt.cm.Set1(label_id \/ float(nb_classes)),\n                    linewidth='1',\n                    alpha=0.8,\n                    label=id_to_label_dict[label_id])\n    plt.legend(loc='best')\n\n","ce151223":"img_size = 112\n\n\nimages = []\nlabels = []\n\nfor class_folder_name in os.listdir(TRAin_DATA_FOLDER):\n    class_folder_path = os.path.join(TRAin_DATA_FOLDER, class_folder_name)\n    for image_path in glob(os.path.join(class_folder_path, \"*.jpeg\")):\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        \n        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        image = cv2.resize(image, (img_size,img_size))\n        \n        image = image.flatten()\n        \n        images.append(image)\n        labels.append(class_folder_name)\n    for image_path in glob(os.path.join(class_folder_path, \"*.png\")):\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        \n        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        image = cv2.resize(image, (img_size,img_size))\n        \n        image = image.flatten()\n        \n        images.append(image)\n        labels.append(class_folder_name)\n    for image_path in glob(os.path.join(class_folder_path, \"*.jpg\")):\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        \n        #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        image = cv2.resize(image, (img_size,img_size))\n        \n        image = image.flatten()\n        \n        images.append(image)\n        labels.append(class_folder_name)\n        \nimages = np.array(images)\nlabels = np.array(labels)\n\nlabels","8327149d":"images","baf6147f":"label_to_id_dict = {v:i for i,v in enumerate(np.unique(labels))}\nid_to_label_dict = {v: k for k, v in label_to_id_dict.items()}\n\nlabel_ids = np.array([label_to_id_dict[x] for x in labels])\n\nimages_scaled = StandardScaler().fit_transform(images)","3ee726a7":"images_scaled.shape","3217ae6f":"label_ids.shape","f8ec5b13":"plt.imshow(np.reshape(images[15], (112,112,3)), cmap=\"gray\")","1b4d650a":"pca = PCA(n_components=180)\npca_result = pca.fit_transform(images_scaled)\npca_result.shape","5e68d038":"tsne = TSNE(n_components=2, perplexity=50.0 ,  learning_rate= 100.0, n_iter= 4000)\ntsne_result = tsne.fit_transform(pca_result)\ntsne_result_scaled = StandardScaler().fit_transform(tsne_result)\nvisualize_scatter(tsne_result_scaled, label_ids)\n\n\n\nvisualize_scatter_with_images(tsne_result_scaled, images = [np.reshape(i, (112,112,3)) for i in images], image_zoom=0.4)","7bcf42dd":"visualize_scatter_with_images(tsne_result_scaled, images = [np.reshape(i, (112,112,3)) for i in images], image_zoom=0.4)","b15b6605":"perplexity_list = 50\nn_components = 2\nn_iter = 4000\nlearning_rate_list =[20 ,50 , 100 , 200 , 500]\n\nfor learning_rate in learning_rate_list:\n    tsne = TSNE(n_components=n_components, perplexity=perplexity ,  learning_rate= learning_rate , n_iter= n_iter)\n    tsne_result = tsne.fit_transform(pca_result)\n    tsne_result_scaled = StandardScaler().fit_transform(tsne_result)\n    visualize_scatter(tsne_result_scaled, label_ids)\n    visualize_scatter_with_images(tsne_result_scaled, images = [np.reshape(i, (112,112,3)) for i in images], image_zoom=0.4)\n","5f40d5c1":"perplexity_list = [10 , 50 ,100, 200 , 400]\nn_components = 2\nn_iter = 4000\nlearning_rate_list = 50\n\nfor perplexity in perplexity_list:\n    tsne = TSNE(n_components=n_components, perplexity=perplexity ,  learning_rate= learning_rate , n_iter= n_iter)\n    tsne_result = tsne.fit_transform(pca_result)\n    tsne_result_scaled = StandardScaler().fit_transform(tsne_result)\n    visualize_scatter(tsne_result_scaled, label_ids)\n    visualize_scatter_with_images(tsne_result_scaled, images = [np.reshape(i, (112,112,3)) for i in images], image_zoom=0.4)\n","de13e034":"tsne = TSNE(n_components=3)\ntsne_result = tsne.fit_transform(pca_result)\ntsne_result_scaled = StandardScaler().fit_transform(tsne_result)\n\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import animation\n\nfig = plt.figure(figsize=(25,25))\nax = fig.add_subplot(111,projection='3d')\n\nplt.grid()\n    \nnb_classes = len(np.unique(label_ids))\n    \nfor label_id in np.unique(label_ids):\n    ax.scatter(tsne_result_scaled[np.where(label_ids == label_id), 0],\n                tsne_result_scaled[np.where(label_ids == label_id), 1],\n                tsne_result_scaled[np.where(label_ids == label_id), 2],\n                alpha=0.8,\n                color= plt.cm.Set1(label_id \/ float(nb_classes)),\n                marker='o',\n                label=id_to_label_dict[label_id])\nax.legend(loc='best')\nax.view_init(20, 40)\nax.set_xlim(-1.5, 1.5)\nax.set_ylim(-1.5, 1.5)\nax.set_zlim(-1.5, 1.5)\n\n","7ff07ce6":"pca = PCA(n_components= 70)\npca_result = pca.fit_transform(images_scaled)\npca_result.shape\n\ntsne = TSNE(n_components=2, perplexity=50.0 ,  learning_rate= 100.0, n_iter= 4000)\ntsne_result = tsne.fit_transform(pca_result)\ntsne_result_scaled = StandardScaler().fit_transform(tsne_result)\nvisualize_scatter(tsne_result_scaled, label_ids)\n\nvisualize_scatter_with_images(tsne_result_scaled, images = [np.reshape(i, (112,112,3)) for i in images], image_zoom=0.4)","eb94b3d0":"\n# 3d t-SNE","084ef43a":"# Effect of different values of n_components\n\nn_components = 2 >> to get 2d results\n\n\nn_components = 3 >>> to get 3d representations","2318b4d8":"# t-SNE","f45aec5d":"# Effect of different values of perplexity","38cac9f4":"# Advanced topics- t-SNE on SKin dataset ","ff334a5b":"# Effect of learning rate"}}