{"cell_type":{"bad902d1":"code","17a99bd4":"code","ac4eeace":"code","0c68ce85":"code","825abcd1":"code","40a9a8ba":"code","96f0d8b0":"code","a14177cb":"code","4c2196f7":"code","905a9c1f":"code","e7f3cc5c":"code","505117aa":"code","4f5e52aa":"code","6576a153":"code","32b43a11":"code","c1cb4c3f":"code","4277c761":"markdown","7e741ce8":"markdown","eea56a51":"markdown","ee9ef64e":"markdown","81a5207b":"markdown","e0c9d983":"markdown","1a5be743":"markdown","b69c32cb":"markdown","dc5214b1":"markdown","552fb55e":"markdown"},"source":{"bad902d1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\nfrom itertools import cycle\npd.set_option('max_columns', 50)\nplt.style.use('seaborn-dark')\ncolor_pal = plt.rcParams['axes.prop_cycle'].by_key()['color']\ncolor_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])","17a99bd4":"!ls -GFlash --color ..\/input\/lish-moa\/","ac4eeace":"ss = pd.read_csv('..\/input\/lish-moa\/sample_submission.csv')\ntest_features = pd.read_csv('..\/input\/lish-moa\/test_features.csv')\ntrain_features = pd.read_csv('..\/input\/lish-moa\/train_features.csv')\ntrain_targets_nonscored = pd.read_csv('..\/input\/lish-moa\/train_targets_nonscored.csv')\ntrain_targets_scored = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')","0c68ce85":"ax = train_targets_scored.drop('sig_id', axis=1) \\\n    .sum(axis=1) \\\n    .value_counts() \\\n    .sort_index() \\\n    .plot(kind='bar',\n         figsize=(15, 5),\n          color=next(color_cycle)\n         )\nax.set_title('Unique Targets per observation (train)', fontsize=20)\nplt.show()","825abcd1":"ax = train_targets_scored.drop('sig_id', axis=1) \\\n    .sum() \\\n    .sort_values(ascending=False) \\\n    .head(30) \\\n    .sort_values() \\\n    .plot(kind='barh',\n         figsize=(15, 10),\n          color=next(color_cycle)\n         )\nax.set_title('Top 30 Scored Targets in Train Set', fontsize=20)\nplt.show()","40a9a8ba":"GENE_COLS = [c for c in train_features.columns if c[:2] == 'g-']\nCELL_COLS = [c for c in train_features.columns if c[:2] == 'c-']\nprint('Number of gene columns:', len(GENE_COLS))\nprint('Number of cell columns:', len(CELL_COLS))","96f0d8b0":"fig, axs = plt.subplots(1, 2, figsize=(15, 5))\nax = train_features['cp_type'] \\\n    .value_counts() \\\n    .plot(kind='barh',\n          figsize=(15, 3),\n          color=next(color_cycle),\n         ax=axs[0])\nax.set_title('training set', fontsize=15)\n\nax = test_features['cp_type'] \\\n    .value_counts() \\\n    .plot(kind='barh',\n          figsize=(15, 3),\n          color=next(color_cycle),\n         ax=axs[1])\nax.set_title('public test set', fontsize=15)\nfig.suptitle('\"cp_type\"', fontsize=20)\nplt.show()\n\nfig, axs = plt.subplots(1, 2, figsize=(15, 5))\nax = train_features['cp_dose'] \\\n    .value_counts() \\\n    .plot(kind='barh',\n          figsize=(15, 3),\n          color=next(color_cycle),\n         ax=axs[0])\nax.set_title('training set', fontsize=15)\n\nax = test_features['cp_dose'] \\\n    .value_counts() \\\n    .plot(kind='barh',\n          figsize=(15, 3),\n          color=next(color_cycle),\n         ax=axs[1])\nax.set_title('public test set', fontsize=15)\nfig.suptitle('treatment duration (hours)', fontsize=20)\nplt.show()\n\nfig, axs = plt.subplots(1, 2, figsize=(15, 5))\nax = train_features['cp_time'] \\\n    .value_counts() \\\n    .plot(kind='barh',\n          figsize=(15, 3),\n          color=next(color_cycle),\n         ax=axs[0])\nax.set_title('training set', fontsize=15)\n\nax = test_features['cp_time'] \\\n    .value_counts() \\\n    .plot(kind='barh',\n          figsize=(15, 3),\n          color=next(color_cycle),\n         ax=axs[1])\nax.set_title('public test set', fontsize=15)\nfig.suptitle('treatment dose', fontsize=20)\nplt.show()","a14177cb":"fig, ax = plt.subplots(10, 10, figsize=(15, 15),\n                       sharex=True,\n                       sharey=True)\nax = ax.flatten()\n\nfor i, c in enumerate(CELL_COLS):\n    train_features[c].plot(kind='hist',\n                           ax=ax[i],\n                           title=c,\n                           bins=20,\n                          color=next(color_cycle)\n                          )\n#     break\nplt.suptitle('Distribution of 100 Cell Features', fontsize=20, y=1)\nplt.tight_layout()\nplt.show()","4c2196f7":"ax = train_features.set_index('sig_id') \\\n    .sample(10)[GENE_COLS] \\\n    .T.plot(figsize=(15, 5))\nplt.suptitle('Gene Features for 10 Random Samples', fontsize=20)\nax.get_legend().remove()\nplt.show()","905a9c1f":"from sklearn.metrics import log_loss\ndef kaggle_metric_np(targets, preds):\n    \"\"\"\n    Kaggle metric for MoA competition targets and preds\n    in numpy format.\n    \"\"\"\n    assert targets.shape[1] == 206\n    assert preds.shape[1] == 206\n    metrics = []\n    for t in range(206):\n        metrics.append(log_loss(targets[:, t], preds[:, t], labels=[0, 1]))\n    return np.mean(metrics)","e7f3cc5c":"from sklearn.model_selection import train_test_split\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\n# from sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.svm import LinearSVC \nfrom sklearn.metrics import log_loss\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\n\nLABEL_ENCODE_COLS = ['cp_type','cp_time','cp_dose']\nfor l in LABEL_ENCODE_COLS:\n    le = LabelEncoder()\n    train_features[f'{l}_le'] = le.fit_transform(train_features[l])\n    test_features[f'{l}_le'] = le.transform(test_features[l])\n\nFEATURES = GENE_COLS + CELL_COLS + ['cp_type_le','cp_time_le','cp_dose_le']\nTARGETS = [t for t in train_targets_scored.columns if t != 'sig_id']\nX = train_features[FEATURES].values\nX_test = test_features[FEATURES].values\ny = train_targets_scored[TARGETS].values\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)\nX_full = np.concatenate([X, X_test])\n\n# Standard Scale\nscale = StandardScaler()\nscale.fit(X_full)\nX_train = scale.transform(X_train)\nX_val = scale.transform(X_val)\nX_test = scale.transform(X_test)\n\n# Apply PCA\npca = PCA(n_components=100, svd_solver='full')\npca.fit(X_full)\nX_train = pca.transform(X_train)\nX_val = pca.transform(X_val)\nX_test = pca.transform(X_test)\nprint(X_train.shape, X_val.shape, X_test.shape)","505117aa":"import warnings\nwarnings.simplefilter(\"ignore\")\n\nclf = OneVsRestClassifier(SVC(probability=True))\nclf.fit(X_train, y_train)\npred_train = clf.predict_proba(X_train)\npred_val = clf.predict_proba(X_val)\npred_test = clf.predict_proba(X_test)","4f5e52aa":"train_score = kaggle_metric_np(y_train, pred_train)\nval_score = kaggle_metric_np(y_val, pred_val)\nprint(f'train score {train_score:0.4f}, val score {val_score:0.4f}')","6576a153":"sub = pd.DataFrame(pred_test, columns=TARGETS)\nsub['sig_id'] = test_features['sig_id'].values","32b43a11":"sub.shape, ss.shape","c1cb4c3f":"sub.to_csv('submission.csv', index=False)","4277c761":"# What is the target we are trying to predict?\nIn this competition, you will be predicting multiple targets of the Mechanism of Action (MoA) response(s) of different samples (sig_id), given various inputs such as gene expression data and cell viability data.\n\nWe are provided \"scored\" and \"nonscored\" targets for the train set. First we will focus on the \"scored\" dataset since these are the binary MoA targets that are scored.","7e741ce8":"First we can look at the data format. Everything is stored as a CSV, and the largest file is only 150MB.","eea56a51":"# Multiclass Model","ee9ef64e":"# Evaluation Criteria","81a5207b":"# Mechanisms of Action (MoA) Prediction\nCan you improve the algorithm that classifies drugs based on their biological activity?\n\n![Mechanisms of Action](https:\/\/www.urmc.rochester.edu\/MediaLibraries\/URMCMedia\/education\/graduate\/phd\/pharmacology-and-physiology\/images\/shutterstock_647026912.jpg)\n\nIn this notebook we will explore the data provided for the competition, understand the metric, and create a baseline model.","e0c9d983":"For every `sig_id` you will be predicting the probability that the sample had a positive response for each <MoA> target. For N sig_id rows and M <MoA> targets, you will be making N\u00d7M predictions. Submissions are scored by the log loss:\n\n\n$$ \\text{score} = - \\frac{1}{M}\\sum_{m=1}^{M} \\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_{i,m} \\log(\\hat{y}_{i,m}) + (1 - y_{i,m}) \\log(1 - \\hat{y}_{i,m})\\right] $$\n\n- \\(N\\) is the number of sig_id observations in the test data (\\(i=1,\u2026,N\\))\n- \\(M\\) is the number of scored MoA targets (\\(m=1,\u2026,M\\))\n- \\( \\hat{y}_{i,m} \\) is the predicted probability of a positive MoA response for a sig_id\n- \\( y_{i,m} \\) is the ground truth, 1 for a positive response, 0 otherwise\n- \\( log() \\) is the natural (base e) logarithm\n    \nNote: the actual submitted predicted probabilities are replaced with max(min(p,1\u221210\u221215),10\u221215). A smaller log loss is better.\n\n\n    ","1a5be743":"## Cell Features","b69c32cb":"# Features\nThe start of the column:\n- `g-` signify gene expression data\n- `c-` signify cell viability data.\n- `cp_type` indicates samples treated with a compound (cp_vehicle) or with a control perturbation (ctrl_vehicle); control perturbations have no MoAs; \n- `cp_time` and `cp_dose` indicate treatment duration (24, 48, 72 hours) and dose (high or low).","dc5214b1":"## Gene Features","552fb55e":"# Make Submission"}}