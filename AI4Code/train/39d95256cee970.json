{"cell_type":{"e9fe2a25":"code","aeec2026":"code","c1a1be75":"code","f78517e5":"code","b25d4fb2":"code","40915711":"code","ec34c980":"code","06d5cb9b":"code","7c341a58":"code","820e0ef5":"code","46f5f48d":"code","77c9b68a":"code","f3203031":"code","3f290f3b":"code","c2a32bb4":"code","a68fd0b4":"code","5babe991":"code","a37ca3da":"code","b49815d7":"code","3687aeff":"markdown","f2cdee75":"markdown","8f43453d":"markdown","77217f4c":"markdown","37bdf18b":"markdown","074fc579":"markdown","82311b70":"markdown","08001b2b":"markdown","d78df24e":"markdown","a8fd50f7":"markdown"},"source":{"e9fe2a25":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nfrom sklearn import metrics\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler, Normalizer\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport time\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if 'csv' in filename:\n            print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","aeec2026":"def run_lgb(x, y, tr_idx, val_idx, param, num_round=100):\n    lgb_train = lgb.Dataset(x.iloc[tr_idx], y.iloc[tr_idx])\n    x_val, y_val = x.iloc[val_idx], y.iloc[val_idx]\n    validation = lgb.Dataset(x_val, y_val)\n    clf = lgb.train(param, lgb_train, num_round, valid_sets=[validation], early_stopping_rounds=50, verbose_eval=200, feval=lgb_f1_score)\n    return clf\n\ndef false_alarm_rate(y_true, y_pred):\n    CM = metrics.confusion_matrix(y_true, y_pred)\n    TN, FN, TP, FP = CM[0][0], CM[1][0], CM[1][1], CM[0][1]\n    return (FP+FN)\/(TP+TN+FP+FN)\n\nlabel = \"Train\"\n\ndef plot_roc(y_true, y_prob):\n    fpr, tpr, _ = metrics.roc_curve(y_true, y_prob)\n    auc = metrics.roc_auc_score(y_true, y_prob)\n    plt.plot(fpr,tpr,label=label+\", auc= %0.2f\" % auc)\n    plt.ylabel('True Positive Rate')\n    plt.xlabel('False Positive Rate')\n    plt.legend(loc=0)\n    plt.show()\n    plt.savefig(label+\".pdf\")\n    \n    \ndata = {}\ndef results(y_test, y_prob):\n    threshold = 0.5\n    y_pred = np.where(y_prob >= threshold, 1, 0)\n    \n    acc = metrics.accuracy_score(y_test, y_pred)\n    pre = metrics.precision_score(y_test, y_pred)\n    rec = metrics.recall_score(y_test, y_pred) # it is also called detection rate or true positive rate\n    f1 = metrics.f1_score(y_test, y_pred)\n    print(f\"Acc {acc}, Precision {pre}, Recall {rec}, F1-score {f1}\")\n    \n    CM = metrics.confusion_matrix(y_test, y_pred)\n    TN, FN, TP, FP = CM[0][0], CM[1][0], CM[1][1], CM[0][1]\n    # false positive rate\n    FPR = FP\/(FP+TN)\n    # false alarm rate \n    FAR = (FP+FN)\/(TP+TN+FP+FN)\n    AUC = metrics.roc_auc_score(y_test, y_prob)\n    \n    print(\"FPR {0}, FAR {1}, AUC {2}\".format(FPR, FAR, AUC))\n    # print(metrics.classification_report(y_test, y_pred))\n    # plot_roc(y_test, y_prob)\n    if label != \"\":\n        data[label] = (y_test, y_prob)\n\n    \ndef test_run(x_train, y_train, x_test, y_test, param, num_round=2000):\n    start = time.clock()\n    \n    lgb_train = lgb.Dataset(x_train, y_train)\n    lgb_validation = lgb.Dataset(x_test, y_test)\n    clf = lgb.train(param, lgb_train, num_round, valid_sets=[lgb_validation], early_stopping_rounds=50, verbose_eval=200, feval=lgb_f1_score)\n    # clf = lgb.train(param, lgb_train, 2000, valid_sets=[lgb_validation], early_stopping_rounds=50, verbose_eval=200)\n    y_prob = clf.predict(x_test, num_iteration=clf.best_iteration)\n    \n    print()\n    results(y_test, y_prob)\n    print(\"Time spent {0}\".format(time.clock() - start))\n    return y_prob\n    \ndef cross_validation(X, Y, param, kf, num_round=2000):\n    start = time.clock()\n    y_probs = []\n    y_vals = []\n\n    # for tr_idx, val_idx in tqdm(kf.split(X, Y), total=folds):\n    for tr_idx, val_idx in kf.split(X, Y):\n        clf = run_lgb(X, Y, tr_idx, val_idx, param, num_round)\n        x_val, y_val = X.iloc[val_idx], Y.iloc[val_idx]\n        y_prob = clf.predict(x_val, num_iteration=clf.best_iteration)\n        \n        y_probs.extend(y_prob)\n        y_vals.extend(y_val)\n\n    print()\n    results(y_vals, np.asarray(y_probs))\n    print(\"Time spent {0}\".format(time.clock() - start))","c1a1be75":"root = '..\/input\/data-preprocessing\/'\ntrain = pd.read_csv(root + 'train.csv')\ntest = pd.read_csv(root + 'test.csv')\n# separate features and labels\nx_train, y_train = train.drop(['label'], axis=1), train['label']\nx_test, y_test = test.drop(['label'], axis=1), test['label']","f78517e5":"from sklearn.model_selection import StratifiedKFold\nimport lightgbm as lgb\nfrom tqdm import tqdm_notebook as tqdm\n\ndef lgb_accuracy(preds, data):\n    y_true = data.get_label()\n    y_pred = np.round(preds)\n    return 'acc', metrics.accuracy_score(y_true, y_pred), True\n\ndef lgb_f1_score(preds, data):\n    y_true = data.get_label()\n    y_pred = np.round(preds) # scikits f1 doesn't like probabilities\n    return 'f1', metrics.f1_score(y_true, y_pred), True","b25d4fb2":"folds = 10\nseed = 1\nnum_round = 2000\nkf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=seed)","40915711":"# label = ''\n# param = {\n#     'objective': 'binary', \n#     'learning_rate': 0.1, \n#     \"boost_from_average\":True,\n#     \"metric\": 'binary_logloss' # 'auc'\n# }\n# start = time.clock()\n# # test_run( x_train, y_train, x_train, y_train, param)\n# clf = lgb.train(param, lgb.Dataset(x_train, y_train), 2000, valid_sets=[lgb.Dataset(x_train, y_train)], early_stopping_rounds=50, verbose_eval=200)\n# y_prob = clf.predict(x_train, num_iteration=clf.best_iteration)\n# print()\n# results(y_train, y_prob)\n# print(\"Time spent {0}\".format(time.clock() - start))\n\n\n# y_prob = clf.predict(x_test, num_iteration=clf.best_iteration)\n# print()\n# results(y_test, y_prob)","ec34c980":"param = {\n    'objective': 'binary', \n    'learning_rate': 0.1, \n    \"boost_from_average\":True,\n    \"metric\": 'binary_logloss' # 'auc'\n}\nlabel = \"train_ten\"\ncross_validation(x_train, y_train, param, kf, num_round=num_round)","06d5cb9b":"label = 'train_five'\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\ncross_validation(x_train, y_train, param, kf, num_round=num_round)","7c341a58":"# label = ''\n# param = {\n#     'objective': 'binary', \n#     'learning_rate': 0.1, \n#     \"boost_from_average\":True,\n#     \"metric\": 'binary_logloss' # 'auc'\n# }\n# y_prob = test_run(x_test, y_test, x_test, y_test, param)","820e0ef5":"label = \"train_test\"\nparam = {\n    'objective': 'binary',\n    'learning_rate': 0.05, \n    'boost_from_average':True,\n    'is_unbalance':True,\n    \"metric\": 'binary_logloss' # 'auc'\n}\ny_prob = test_run(x_train, y_train, x_test, y_test, param, num_round=num_round)","46f5f48d":"# y_pred = np.where(y_prob >= 0.5, 1, 0)\n# print(metrics.confusion_matrix(y_test, y_pred))\n\n# target_names = ['Normal', 'Anomaly']\n# cm = metrics.confusion_matrix(y_test, y_pred)\n# # Normalize\n# cmn = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n# plt.rc('font', size=20) \n# fig, ax = plt.subplots(figsize=(10,10))\n# sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=target_names, yticklabels=target_names)\n\n# plt.ylabel('Actual')\n# plt.xlabel('Predicted')\n \n# plt.show(block=False)","77c9b68a":"label = 'test_ten'\nparam = {\n    'objective': 'binary',\n    'learning_rate': 0.1, \n    \"boost_from_average\":True,\n    # 'is_unbalance':True,\n    # \"feature_fraction\":0.5,\n    \"metric\": 'binary_logloss' # 'auc'\n}\nkf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\ncross_validation(x_test, y_test, param, kf, num_round=num_round)","f3203031":"label = 'test_five'\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\ncross_validation(x_test, y_test, param, kf, num_round=num_round)","3f290f3b":"total = pd.concat([train, test], axis=0)\nX, Y = total.drop(['label'], axis=1), total['label']","c2a32bb4":"param = {\n    'objective': 'binary',\n    'learning_rate': 0.1, \n    \"boost_from_average\":True,\n    # 'is_unbalance':True,\n    # \"bagging_fraction\":0.8,\n    \"feature_fraction\":0.5,\n    # \"bagging_freq\":1,\n    \"metric\": 'binary_logloss' # 'auc'\n}\nlabel = 'combined_ten'\ncross_validation(X, Y, param, kf, num_round=num_round)","a68fd0b4":"# plt.figure(dpi=1200)\nfor value in ['Train', 'Test', 'Combined']:\n    temp = data[value.lower()+'_ten']\n    fpr, tpr, _ = metrics.roc_curve(temp[0], temp[1])\n    auc = metrics.roc_auc_score(temp[0], temp[1])\n    plt.plot(fpr,tpr,label=value+\", auc= %0.4f\" % auc)\n\nplt.plot([0, 1], [0, 1],'r--')\n# plt.xlim([0.0, 1.0])\n# plt.ylim([0.0, 1.05])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\n\nplt.savefig('roc_ten.pdf')\nplt.show() ","5babe991":"for value in ['Train', 'Test']:\n    temp = data[value.lower()+'_five']\n    fpr, tpr, _ = metrics.roc_curve(temp[0], temp[1])\n    auc = metrics.roc_auc_score(temp[0], temp[1])\n    plt.plot(fpr,tpr,label=value+\", auc= %0.4f\" % auc)\n\nplt.plot([0, 1], [0, 1],'r--')\n# plt.xlim([0.0, 1.0])\n# plt.ylim([0.0, 1.05])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\n\nplt.savefig('roc_five.pdf')\nplt.show() ","a37ca3da":"temp = data['train_test']\nfpr, tpr, _ = metrics.roc_curve(temp[0], temp[1])\nauc = metrics.roc_auc_score(temp[0], temp[1])\nplt.plot(fpr,tpr,label=\"Test, auc= %0.4f\" % auc)\n\nplt.plot([0, 1], [0, 1],'r--')\n# plt.xlim([0.0, 1.0])\n# plt.ylim([0.0, 1.05])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('roc_test.pdf')\nplt.show() \n","b49815d7":"from IPython.display import IFrame, display\nfilepath = \"roc_test.pdf\"\nIFrame(filepath, width=700, height=400)","3687aeff":"# Introduction\n* [The UNSW-NB15 dataset description](https:\/\/www.unsw.adfa.edu.au\/unsw-canberra-cyber\/cybersecurity\/ADFA-NB15-Datasets\/)\n* [Feature visualization and preprocessing](https:\/\/www.kaggle.com\/khairulislam\/unsw-nb15-eda)\n* [Feature importance using RandomForest classifier](https:\/\/www.kaggle.com\/khairulislam\/unsw-nb15-feature-importance)\n* [Performance with other classifiers](https:\/\/www.kaggle.com\/khairulislam\/unsw-nb15-anomaly-detection)","f2cdee75":"# Combined data\nHere we combined both train and test set. Then evaluated their ten-fold cross validation performance.","8f43453d":"# Utils","77217f4c":"# Test data","37bdf18b":"## Ten-fold cross validation","074fc579":"## Validate on test data\nHere the model trained on test data is being validated using test data.","82311b70":"## Five-fold cross validation","08001b2b":"## Ten-fold cross validation","d78df24e":"## Five-fold cross validation","a8fd50f7":"# Train data"}}