{"cell_type":{"850118ec":"code","81fa515f":"code","b455d71a":"code","e296012b":"code","0295b867":"code","4a68e62f":"code","5a9307e6":"code","0cd54683":"code","780fb239":"code","191a3b38":"code","ecf3ab85":"code","3c097942":"markdown","be71b205":"markdown"},"source":{"850118ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","81fa515f":"import numpy as np\nimport pandas as pd\n\n#reads the dataset\ndataset = pd.read_csv(\"..\/input\/emotion-classification-data\/emotion_images.csv\")","b455d71a":"from sklearn.model_selection import train_test_split\n\n#separates features and labels\nfeatures = dataset[[str(i) for i in range(2304)]]\nlabels = dataset[\"Labels\"]\n\nfeatures = features\/255","e296012b":"i.np.array(features)","0295b867":"#converts features and labels into a tensor dataset\n\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\ntensor_features = torch.Tensor(np.array([i.reshape(48,48) for i in np.array(features)]))\ntensor_labels = torch.Tensor(np.array(labels).reshape(-1, 1))\n\ntensor_dataset = TensorDataset(tensor_features, tensor_labels)\ntensor_dataset = DataLoader(tensor_dataset, batch_size = 64, shuffle = True)","4a68e62f":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 4, 3)\n        self.conv2 = nn.Conv2d(4, 8, 3)\n        self.bnorm1 = nn.BatchNorm2d(8)\n        \n        self.conv3 = nn.Conv2d(8, 16, 3)\n        self.conv4 = nn.Conv2d(16, 32, 3)\n        self.bnorm2 = nn.BatchNorm2d(32)\n        \n        self.conv5 = nn.Conv2d(32, 4, 3)\n        \n        self.fc1 = nn.Linear(5776, 1024)\n        self.fc2 = nn.Linear(1024, 512)\n        self.fc3 = nn.Linear(512, 1)\n    def forward(self, x):\n        pred = F.leaky_relu(self.conv1(x.reshape(-1,1,48,48)))\n        pred = F.leaky_relu(self.bnorm1(self.conv2(pred)))\n        pred = F.leaky_relu(self.conv3(pred))\n        pred = F.leaky_relu(self.bnorm2(self.conv4(pred)))     \n        pred = F.leaky_relu(self.conv5(pred))\n        \n        pred = pred.reshape(-1, 5776)\n\n        pred = F.leaky_relu(self.fc1(pred))\n        pred = F.leaky_relu(self.fc2(pred))\n        pred = torch.sigmoid(self.fc3(pred))\n        \n        return pred\n    \nclass Generator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(512, 1024)\n        self.fc2 = nn.Linear(1024, 2048)\n        self.fc3 = nn.Linear(2048, 5776)\n\n        self.convT1 = nn.ConvTranspose2d(4, 32, 3)       \n        self.convT2 = nn.ConvTranspose2d(32, 16, 3)\n        self.bnorm1 = nn.BatchNorm2d(16)\n        self.convT3 = nn.ConvTranspose2d(16, 8, 3)\n        self.convT4 = nn.ConvTranspose2d(8, 4, 3)\n        self.bnorm2 = nn.BatchNorm2d(4)\n        self.convT5 = nn.ConvTranspose2d(4, 1, 3)\n        \n    def forward(self, x):\n        pred = F.leaky_relu(self.fc1(x))\n        pred = F.leaky_relu(self.fc2(pred))\n        pred = F.leaky_relu(self.fc3(pred))\n        \n        pred = pred.reshape(-1, 4, 38, 38)\n        \n        pred = F.leaky_relu(self.convT1(pred))\n        pred = F.leaky_relu(self.bnorm1(self.convT2(pred)))\n        pred = F.leaky_relu(self.convT3(pred))\n        pred = F.leaky_relu(self.bnorm2(self.convT4(pred)))\n        pred = torch.sigmoid(self.convT5(pred))\n        \n        return pred\n        ","5a9307e6":"import torch.optim as optim\n\ndiscriminator = Discriminator()\ngenerator = Generator()\n\nd_optim = optim.Adam(discriminator.parameters(), lr = 0.001, weight_decay = 0.2)\ng_optim = optim.Adam(generator.parameters(), lr = 0.001)\n\ndiscriminator = discriminator.to(\"cuda\")\ngenerator = generator.to(\"cuda\")\n\ndiscriminator_losses = []\ngenerator_losses = []\n\nfor epoch in range(100):\n    for data,label in tensor_dataset:\n        data = data.to(\"cuda\")\n        label = label.to(\"cuda\")\n        \n        batch_size = data.size(0)\n        real_labels = torch.ones(batch_size, 1).to(\"cuda\")\n        fake_labels = torch.zeros(batch_size, 1).to(\"cuda\")\n        \n        noise = torch.randn(batch_size, 512).to(\"cuda\")\n        \n        D_real = discriminator(data)\n        D_fake = discriminator(generator(noise))\n        \n        D_real_loss = F.binary_cross_entropy(D_real, real_labels)\n        D_fake_loss = F.binary_cross_entropy(D_fake, fake_labels)\n        \n        D_loss = D_real_loss+D_fake_loss\n        \n        d_optim.zero_grad()\n        D_loss.backward()\n        d_optim.step()\n        \n        noise = torch.randn(batch_size, 512).to(\"cuda\")\n        D_fake = discriminator(generator(noise))\n        G_loss = F.binary_cross_entropy(D_fake, real_labels)\n        \n        g_optim.zero_grad()\n        \n        G_loss.backward()\n        g_optim.step()\n        \n        discriminator_losses.append(D_loss)\n        generator_losses.append(G_loss)\n    print(epoch)","0cd54683":"import matplotlib.pyplot as plt\nplt.plot(generator_losses)\nplt.plot(discriminator_losses)\nplt.show()","780fb239":"from PIL import Image\nx = Image.fromarray(generator(noise)[0].reshape(48,48).to(\"cpu\").detach().numpy()*255)\nx.convert(\"RGB\")","191a3b38":"discriminator(generator(noise))","ecf3ab85":"Image.fromarray(generator(torch.randn(1, 512).to(\"cuda\")).to(\"cpu\").detach().numpy().reshape(48,48)*255).convert('RGB')","3c097942":"##### x = Image.fromarray(data[5].to(\"cpu\").detach().numpy().reshape(48,48)*255)\nx.convert(\"RGB\")","be71b205":"discriminator = Discriminator()\ngenerator = Generator()\n\nd_optim = optim.Adam(discriminator.parameters(), lr = 0.001, weight_decay = 0.2)\ng_optim = optim.Adam(generator.parameters(), lr = 0.001)\n"}}