{"cell_type":{"70ec41fd":"code","2ef5f542":"code","71fa9d28":"code","3c8f4918":"code","86e8bc1b":"code","70fcffd9":"code","abfb82c5":"code","53ea29f7":"code","7aa7b8bb":"code","fd6f965e":"code","ed5d7fff":"code","9927d693":"code","73cca6a5":"code","1287ab38":"code","dbfa7566":"code","826398a4":"code","d8c9b142":"code","2621aa35":"code","be2bf221":"code","8eedd52d":"code","37517161":"code","df364d7e":"code","3110e7c3":"code","9e41c721":"code","4cc3c6e1":"code","9705bbdc":"code","b529aa1f":"code","34a2e5ed":"code","44e796e7":"code","024a71e2":"code","53cfd02f":"code","841605e3":"code","5fbcd8b0":"code","ab6a8aa8":"code","35ada4c4":"code","6c3b7b88":"code","4c67a897":"code","62c73ae6":"code","67dc3d56":"code","5462e6a5":"code","6049c69b":"code","b8019fbb":"code","ee05a648":"code","295cc9f1":"code","aa65fa9a":"code","84b302e6":"code","4963f755":"code","c3a20d04":"markdown","6a672927":"markdown","11002540":"markdown","f922b34b":"markdown","80da0158":"markdown","efb02766":"markdown","252162f8":"markdown","ed3197d5":"markdown","7c937045":"markdown","606b1afd":"markdown","cece992c":"markdown","60307cf3":"markdown","ee880a66":"markdown","81c4cc06":"markdown","283f70ef":"markdown","27f2df34":"markdown","9235cc3b":"markdown","961bb564":"markdown","6f4818e9":"markdown","778b0fb8":"markdown","c54868e7":"markdown","b31aa065":"markdown","32a0afb8":"markdown","5a966a9a":"markdown","a016ded5":"markdown","d0f3fb73":"markdown","900e7673":"markdown","a0c70179":"markdown","43603706":"markdown","fdf9e4cc":"markdown","e1e58fb4":"markdown","7f0b5e3f":"markdown","c7cece10":"markdown","243c7513":"markdown","5f366d58":"markdown","c6edfcc7":"markdown","f1622bc7":"markdown","4e20f5fd":"markdown","47a5b87c":"markdown","1d944fa2":"markdown"},"source":{"70ec41fd":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\nimport sklearn\n\n#Importando as bibliotecas com as m\u00e9tricas\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2ef5f542":"#Importando a base de treino\ntrain = pd.read_csv(\"\/kaggle\/input\/adult-pmr3508\/train_data.csv\", engine='python', na_values=\"?\")\ntrain.set_index('Id', inplace=True)\ntrain.columns = [\"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education_num\", \"Marital_status\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital_gain\", \"Capital_loss\", \"Hours_per_week\", \"Native_country\", \"Income\"]\ntrain.head()","71fa9d28":"#Importando a base de testes\ntest = pd.read_csv(\"\/kaggle\/input\/adult-pmr3508\/test_data.csv\", engine='python', na_values=\"?\")\ntest.set_index('Id', inplace=True)\ntest.columns = [\"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education_num\", \"Marital_status\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital_gain\", \"Capital_loss\", \"Hours_per_week\", \"Native_country\"]\ntest.head()","3c8f4918":"#Importando algumas bibliotecas para esta etapa\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler","86e8bc1b":"train = train.dropna()\nXtrain_0 = train[[\"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education_num\", \"Marital_status\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital_gain\", \"Capital_loss\", \"Hours_per_week\", \"Native_country\"]]\nXtrain_1 = Xtrain_0.apply(preprocessing.LabelEncoder().fit_transform)\nscaler = StandardScaler()\nXtrain = pd.DataFrame(scaler.fit_transform(Xtrain_1), columns=Xtrain_0.columns)\nYtrain = train[['Income']]\n\ntest = test.dropna()\nXtest_0 = test.apply(preprocessing.LabelEncoder().fit_transform)\nXtest = pd.DataFrame(scaler.transform(Xtest_0), columns=Xtest_0.columns)","70fcffd9":"train_num = train.apply(preprocessing.LabelEncoder().fit_transform)\nf, ax = plt.subplots(figsize=(10, 6))\ncorr = train_num.corr()\nhm = sns.heatmap(round(corr,2), annot=True, ax=ax, cmap=\"coolwarm\",fmt='.2f',\n                 linewidths=.05)\nf.subplots_adjust(top=0.93)\nt = f.suptitle('Correla\u00e7\u00e3o entre Atributos na Adult', fontsize=14)","abfb82c5":"Xtrain = Xtrain[['Age', 'Education_num', 'Marital_status',\n                 'Relationship', 'Sex', 'Capital_gain', 'Capital_loss', 'Hours_per_week']]\nXtest = Xtest[['Age', 'Education_num', 'Marital_status',\n                 'Relationship', 'Sex', 'Capital_gain', 'Capital_loss', 'Hours_per_week']]","53ea29f7":"#Importando as bibliotecas necess\u00e1rias\nimport sklearn.linear_model as linear_model\n\nlogistic = linear_model.LogisticRegression()\n\nlogistic_scores = cross_validate(logistic, Xtrain, Ytrain, cv=10, scoring=('accuracy', 'f1_macro', 'precision_macro', 'recall_macro'))\nlogistic_scores","7aa7b8bb":"print(\"Acur\u00e1cia m\u00e9dia: \", logistic_scores['test_accuracy'].mean(), \"\\nF1-Score m\u00e9dio: \", logistic_scores['test_f1_macro'].mean(), \"\\nPrecis\u00e3o m\u00e9dia: \", logistic_scores['test_precision_macro'].mean(), \"\\nRecall m\u00e9dio: \", logistic_scores['test_recall_macro'].mean())","fd6f965e":"#importando as bibliotecas necess\u00e1rias\nfrom sklearn.tree import DecisionTreeClassifier\n\ntree = DecisionTreeClassifier(criterion=\"gini\")\n\ntree_scores = cross_validate(tree, Xtrain, Ytrain, cv=10, scoring=('accuracy', 'f1_macro', 'precision_macro', 'recall_macro'))\ntree_scores","ed5d7fff":"print(\"Acur\u00e1cia m\u00e9dia: \", tree_scores['test_accuracy'].mean(), \"\\nF1-Score m\u00e9dio: \", tree_scores['test_f1_macro'].mean(), \"\\nPrecis\u00e3o m\u00e9dia: \", tree_scores['test_precision_macro'].mean(), \"\\nRecall m\u00e9dio: \", tree_scores['test_recall_macro'].mean())","9927d693":"results = []\nfor i in range(1,20):\n    tree = DecisionTreeClassifier(criterion=\"gini\",max_depth=i)\n    tree_scores = cross_val_score(tree, Xtrain, Ytrain, cv=10)\n    results.append(tree_scores.mean())\nprint(results)","73cca6a5":"results = []\nfor i in range(1,20):\n    tree = DecisionTreeClassifier(criterion=\"entropy\",max_depth=i)\n    tree_scores = cross_val_score(tree, Xtrain, Ytrain, cv=10)\n    results.append(tree_scores.mean())\nprint(results)","1287ab38":"tree = DecisionTreeClassifier(criterion=\"gini\", max_depth=9)\n\ntree_scores = cross_validate(tree, Xtrain, Ytrain, cv=10, scoring=('accuracy', 'f1_macro', 'precision_macro', 'recall_macro'))\ntree_scores","dbfa7566":"print(\"Acur\u00e1cia m\u00e9dia: \", tree_scores['test_accuracy'].mean(), \"\\nF1-Score m\u00e9dio: \", tree_scores['test_f1_macro'].mean(), \"\\nPrecis\u00e3o m\u00e9dia: \", tree_scores['test_precision_macro'].mean(), \"\\nRecall m\u00e9dio: \", tree_scores['test_recall_macro'].mean())","826398a4":"#importando as bibliotecas necess\u00e1rias\nfrom sklearn.ensemble import AdaBoostClassifier\n\nboosted_tree = AdaBoostClassifier(n_estimators=200)\n\nboosted_scores = cross_validate(boosted_tree, Xtrain, Ytrain, cv=10, scoring=('accuracy', 'f1_macro', 'precision_macro', 'recall_macro'))\nboosted_scores","d8c9b142":"print(\"Acur\u00e1cia m\u00e9dia: \", boosted_scores['test_accuracy'].mean(), \"\\nF1-Score m\u00e9dio: \", boosted_scores['test_f1_macro'].mean(), \"\\nPrecis\u00e3o m\u00e9dia: \", boosted_scores['test_precision_macro'].mean(), \"\\nRecall m\u00e9dio: \", boosted_scores['test_recall_macro'].mean())","2621aa35":"#importando as bibliotecas necess\u00e1rias\nfrom sklearn.ensemble import RandomForestClassifier\n\nrandom = RandomForestClassifier(n_estimators=100)\n\nrandom_scores = cross_validate(random, Xtrain, Ytrain, cv=10, scoring=('accuracy', 'f1_macro', 'precision_macro', 'recall_macro'))\nrandom_scores","be2bf221":"print(\"Acur\u00e1cia m\u00e9dia: \", random_scores['test_accuracy'].mean(), \"\\nF1-Score m\u00e9dio: \", random_scores['test_f1_macro'].mean(), \"\\nPrecis\u00e3o m\u00e9dia: \", random_scores['test_precision_macro'].mean(), \"\\nRecall m\u00e9dio: \", random_scores['test_recall_macro'].mean())","8eedd52d":"#importando as bibliotecas necess\u00e1rias\nfrom sklearn.svm import SVC\n\nsvm = SVC()\n\nsvm_scores = cross_validate(svm, Xtrain, Ytrain, cv=10, scoring=('accuracy', 'f1_macro', 'precision_macro', 'recall_macro'))\nsvm_scores","37517161":"print(\"Acur\u00e1cia m\u00e9dia: \", svm_scores['test_accuracy'].mean(), \"\\nF1-Score m\u00e9dio: \", svm_scores['test_f1_macro'].mean(), \"\\nPrecis\u00e3o m\u00e9dia: \", svm_scores['test_precision_macro'].mean(), \"\\nRecall m\u00e9dio: \", svm_scores['test_recall_macro'].mean())","df364d7e":"lr = pd.Series({'Classificador': 'Regress\u00e3o log\u00edstica', 'Acur\u00e1cia': logistic_scores['test_accuracy'].mean(), 'F1-Score': logistic_scores['test_f1_macro'].mean(), 'Precis\u00e3o': logistic_scores['test_precision_macro'].mean(), 'Recall': logistic_scores['test_recall_macro'].mean()})\nt = pd.Series({'Classificador': '\u00c1rvore de classifica\u00e7\u00e3o', 'Acur\u00e1cia': tree_scores['test_accuracy'].mean(), 'F1-Score': tree_scores['test_f1_macro'].mean(), 'Precis\u00e3o': tree_scores['test_precision_macro'].mean(), 'Recall': tree_scores['test_recall_macro'].mean()})\nbt = pd.Series({'Classificador': 'Boosted tree', 'Acur\u00e1cia': boosted_scores['test_accuracy'].mean(), 'F1-Score': boosted_scores['test_f1_macro'].mean(), 'Precis\u00e3o': boosted_scores['test_precision_macro'].mean(), 'Recall': boosted_scores['test_recall_macro'].mean()})\ns = pd.Series({'Classificador': 'SVM', 'Acur\u00e1cia': svm_scores['test_accuracy'].mean(), 'F1-Score': svm_scores['test_f1_macro'].mean(), 'Precis\u00e3o': svm_scores['test_precision_macro'].mean(), 'Recall': svm_scores['test_recall_macro'].mean()}) \n\nrelat = pd.DataFrame([lr, t, bt, s])\nrelat","3110e7c3":"#gerando arquivo para submeter na competi\u00e7\u00e3o\nboosted_tree.fit(Xtrain, Ytrain)\n\ntest = pd.read_csv(\"\/kaggle\/input\/adult-pmr3508\/test_data.csv\", engine='python')\ntest.set_index('Id', inplace=True)\ntest.columns = [\"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education_num\", \"Marital_status\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital_gain\", \"Capital_loss\", \"Hours_per_week\", \"Native_country\"]\nXtest_0 = test.apply(preprocessing.LabelEncoder().fit_transform)\nXtest = pd.DataFrame(scaler.transform(Xtest_0), columns=Xtest_0.columns)\nXtest = Xtest[['Age', 'Education_num', 'Marital_status',\n                 'Relationship', 'Sex', 'Capital_gain', 'Capital_loss', 'Hours_per_week']]\n\nYpred = boosted_tree.predict(Xtest)\nYpred","9e41c721":"#gerando arquivo para submeter na competi\u00e7\u00e3o\nid_index = pd.DataFrame({'Id' : list(range(len(Ypred)))})\nincome = pd.DataFrame({'income' : Ypred})\nresult = id_index.join(income)\nresult.head()","4cc3c6e1":"#gerando arquivo para submeter na competi\u00e7\u00e3o\nresult.to_csv(\"submission.csv\", index = False)","9705bbdc":"df = pd.read_csv('\/kaggle\/input\/californiahousing\/train.csv', engine='python', na_values='?')\ndf.set_index('Id', inplace=True)\ndf.head()","b529aa1f":"df.shape","34a2e5ed":"df.info()","44e796e7":"df.isnull().sum()","024a71e2":"df.describe()","53cfd02f":"f, ax = plt.subplots(figsize=(10, 6))\ncorr = df.corr()\nhm = sns.heatmap(round(corr,2), annot=True, ax=ax, cmap=\"coolwarm\",fmt='.2f',\n                 linewidths=.05)\nf.subplots_adjust(top=0.93)\nt= f.suptitle('Correla\u00e7\u00e3o entre Atributos na CaliforniaHousing', fontsize=14)","841605e3":"ax = sns.pairplot(df, x_vars=['latitude','median_age','total_rooms','median_income'], \n                         y_vars='median_house_value', height=7, aspect=0.7, kind='reg')\n\nax.fig.suptitle('Correla\u00e7\u00e3o entre median_house_value e algumas vari\u00e1veis', y=1.03)","5fbcd8b0":"sns.pairplot(df)","ab6a8aa8":"#Importando algumas bibliotecas para analisar dados espaciais\nimport descartes\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\n\n#Importando o arquivo shapefile com o mapa da California\ncalif = gpd.read_file('\/kaggle\/input\/shapefile-california\/CA_Counties_TIGER2016.shp')\n\nfrom pyproj import Proj, transform\n\n#Transformando a latitude e a longitude dos pontos amostrais para o mesmo sistema de refer\u00eancia do mapa da CA\ndef transforma(x1, y1):\n    inProj = Proj(init='epsg:4326')\n    outProj = Proj(init='epsg:3857')\n    x2,y2 = transform(inProj,outProj,x1,y1)\n    return x2, y2\n\ndf2 = df.copy()\nA = df2.apply(lambda x: transforma(x['longitude'], x['latitude']), axis=1)\n#A.to_frame()\n\n#tem jeito menos burro de fazer isso?\nlong = []\nlat = []\nfor x in A:\n    long.append(x[0])\n    lat.append(x[1])\nlong = pd.DataFrame(long)\nlat = pd.DataFrame(lat)\ndf2.longitude = long\ndf2.latitude = lat\n\ngeometry = [Point(xy) for xy in zip (df2['longitude'], df2['latitude'])]\ncrs = {'init': 'epsg:3857'}\n\n#Transformando o DataFrame em um GeoDataFrame\ngeo_df = gpd.GeoDataFrame(df, crs = crs, geometry = geometry)\n\n#Visualizando as casas sobre o mapa\nfig, ax = plt.subplots(figsize = (12,12))\ncalif.plot(ax=ax, alpha=0.4, color='grey')\ngeo_df.plot(ax=ax)\nplt.title(\"Houses in California\")","35ada4c4":"sns.distplot(df.median_house_value)","6c3b7b88":"sns.distplot(df.median_income)","4c67a897":"sns.distplot(df.median_age)","62c73ae6":"sns.boxplot(df['median_house_value'], orient='v')","67dc3d56":"sns.boxplot(df['median_income'], orient='v')","5462e6a5":"jointgrid = sns.JointGrid(x='median_house_value', y='median_income', data=df)\njointgrid.plot_joint(sns.scatterplot)\njointgrid.plot_marginals(sns.distplot)","6049c69b":"jointgrid = sns.JointGrid(x='median_house_value', y='median_age', data=df)\njointgrid.plot_joint(sns.scatterplot)\njointgrid.plot_marginals(sns.distplot)","b8019fbb":"import math\nfrom sklearn.metrics import make_scorer\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import linear_model","ee05a648":"Xtrain = df.iloc[:,:8]\nYtrain = df.iloc[:,8:9]","295cc9f1":"def RMSLE(Y, Ypred):\n    n = len(Y)\n    soma = 0\n    Y = np.array(Y)\n    for i in range(len(Y)):\n        soma += ( math.log( abs(Ypred[i]) + 1 ) - math.log( Y[i] + 1 ) )**2\n    return math.sqrt(soma \/ n)\nscorer_rmsle = make_scorer(RMSLE)","aa65fa9a":"linear = linear_model.LinearRegression()\nlinear.fit (Xtrain, Ytrain)\nscores = cross_val_score (linear, Xtrain, Ytrain, cv = 10, scoring = scorer_rmsle)\ntotal = 0\nfor j in scores:\n    total += j\nrmsle_linear = total\/10\n\nridge = linear_model.Ridge (alpha=10000)\nridge.fit (Xtrain,Ytrain)\nscores = cross_val_score (ridge,Xtrain,Ytrain, cv = 10,scoring = scorer_rmsle)\ntotal = 0\nfor j in scores:\n    total += j\nrmsle_ridge = total\/10\n\nlasso = linear_model.Lasso(alpha=10000)\nlasso.fit (Xtrain, Ytrain)\nscores = cross_val_score (lasso,Xtrain,Ytrain, cv = 10,scoring = scorer_rmsle)\ntotal = 0\nfor j in scores:\n    total += j\nrmsle_lasso = total\/10\n\nprint('RMSLE para regress\u00e3o linear: ', rmsle_linear, '\\nRMSLE para regress\u00e3o ridge: ', rmsle_ridge, '\\nRMSLE para regress\u00e3o lasso: ', rmsle_lasso)","84b302e6":"def gerar_grafico(classificadores,X,f_o):\n    if X is None:\n        acc_total = {}\n        for clf in classificadores:\n            acc_clf = []\n            for n in range(len(f_o)):\n                Xn = df[f_o[:n+1]]\n                clf.fit(Xn,Ytrain)\n                scores = cross_val_score(clf, Xn, Ytrain, cv=10, scoring=scorer_rmsle)\n                acc_clf.append(scores.mean())\n            acc_total[clf] = acc_clf\n    else:\n        acc_total = {}\n        for clf in  classificadores:\n            acc_clf = []\n            for n in range(len(f_o)):\n                Xn = SelectKBest(chi2, k=n+1).fit_transform(abs(X),Y)\n                clf.fit(Xn,Ytrain)\n                scores = cross_val_score(clf, Xn, Ytrain, cv=10, scoring=scorer_rmsle)\n                acc_clf.append(scores.mean())\n            acc_total[clf] = acc_clf\n    for clf in acc_total:\n        plt.plot(np.arange(1,len(f_o)+1), acc_total[clf], 'o-', label=classificadores[clf])\n    plt.ylabel('RMSLE esperada')\n    plt.xlabel('Quantidade de features')\n    plt.title('Uso das melhores features vs RMSLE esperada')\n    plt.legend(loc='upper right')\n    plt.grid(True)\n    plt.show()\n    return acc_total\n\nfeatures_ordenadas = ['median_income','latitude','total_rooms','median_age',\n            'households','total_bedrooms','longitude','population']\n\nclassificadores_lineares = {lasso:'Lasso',\n                            ridge:'Ridge',\n                            linear:'Linear simples'}\nacc_lineares = gerar_grafico(classificadores_lineares,None,features_ordenadas)","4963f755":"test = pd.read_csv('\/kaggle\/input\/californiahousing\/test.csv', engine='python', na_values='?')\ntest.set_index('Id', inplace=True)\n\nYpredict = ridge.predict(test)","c3a20d04":"\u00c9 percept\u00edvel que os piores resultados foram os dos classificadores lineares, enquanto as \u00e1rvores de classifica\u00e7\u00e3o se sa\u00edram melhor (e, em destaque, a *boosted tree* obteve o melhor desempenho, por pequena margem), j\u00e1 que conseguem se adaptar bem a fronteiras flex\u00edveis.","6a672927":"A acur\u00e1cia obtida \u00e9 baixa, menor que a encontrada outrora no kNN. Isso pode ser um indicativo de que a fronteira que delimita as classes do problema n\u00e3o \u00e9 muito bem aproximada por uma fronteira linear. Como ainda testaremos outro classificador linear, tal hip\u00f3tese pode ser refutada ou endossada por ele.","11002540":"Vemos, a seguir, que as vari\u00e1veis mais correlacionadas com a *feature Income* s\u00e3o *Education_num*, *Capital_gain*, *Relationship*, *Age*, *Hours_per_week* e *Sex*.","f922b34b":"O primeiro modelo a ser testado \u00e9 a regress\u00e3o log\u00edstica, caracterizada por ser um classificador com fronteira linear.","80da0158":"## <center>Tarefa extra: Regress\u00e3o na base *CaliforniaHousing*<\/center>","efb02766":"*Support Vector Machine* \u00e9 mais um classificador de fronteira linear. Ele constr\u00f3i uma representa\u00e7\u00e3o das observa\u00e7\u00f5es como pontos no espa\u00e7o, mapeados para que as observa\u00e7\u00f5es das classes distintas sejam divididos por uma fronteira clara e o mais ampla poss\u00edvel. Novas entradas s\u00e3o mapeadas no mesmo espa\u00e7o e prev\u00ea-se que perten\u00e7am a uma classe a partir do lado da fronteira em que caem.","252162f8":"A rela\u00e7\u00e3o entre as vari\u00e1veis *total_rooms*, *total_bedrooms*, *population* e *households* parece ser aproximadamente linear. Assim, n\u00e3o h\u00e1 ganho de informa\u00e7\u00e3o em utilizar todas elas para a constru\u00e7\u00e3o de um modelo preditivo. Al\u00e9m disso, a rela\u00e7\u00e3o entre latitude e longitude \u00e9 deveras curiosa. Localizemos espacialmente as casas amostradas.","ed3197d5":"O melhor resultado foi obtido para a regress\u00e3o ridge (usando alpha = 10.000).\nA seguir, ser\u00e1 gerado um gr\u00e1fico para nos auxiliar durante a *feature selection*.","7c937045":"Nesta tarefa ser\u00e3o testadas **tr\u00eas t\u00e9cnicas de classifica\u00e7\u00e3o** na base *Adult*, comparando-se em seguida o desempenho de cada uma delas.\nAs t\u00e9cnicas escolhidas foram:\n- Regress\u00e3o log\u00edstica\n- \u00c1rvores de Classifica\u00e7\u00e3o e Random forests\n- SVM  \n\nComo m\u00e9tricas de desempenho foram adotados:\n* Acur\u00e1cia\n* Precis\u00e3o\n* F1-Score\n* Recall","606b1afd":"### 6. An\u00e1lise comparativa dos resultados ###","cece992c":"A ferramenta a seguir \u00e9 muito \u00fatil para analisar visualmente a rela\u00e7\u00e3o entre as *features*.","60307cf3":"Vemos que esta \u00e9 uma base de dados com 9 *features* e 14.448 entradas. Al\u00e9m disso, n\u00e3o h\u00e1 *missing values* nela. Abaixo apresentamos sua descri\u00e7\u00e3o estat\u00edstica.","ee880a66":"### 3. Regress\u00e3o Log\u00edstica ###","81c4cc06":"A fun\u00e7\u00e3o abaixo foi criada para calcular o RMSLE.","283f70ef":"### 1. Importando e conhecendo os dados (*Exploratory Data Analysis*)","27f2df34":"Agora, queremos escolher qual m\u00e9todo de avalia\u00e7\u00e3o de *splits* usar (*Gini index* ou Entropia) e tamb\u00e9m limitaremos a profundidade da \u00e1rvore, visando evitar *overfitting*.","9235cc3b":"Inicialmente, todas as *features* ser\u00e3o utilizadas para treinar os regressores. Em seguida, ser\u00e1 feito um estudo acerca das features que minimizam o *Root Mean Squared Logarithmic Error* (RMSLE).","961bb564":"Antes de passar a modelagem propriamente dita, verifiquemos a distribui\u00e7\u00e3o de algumas *features*.","6f4818e9":"Assim, para evitar *overfitting* e para simplificar a modelagem, trabalharemos apenas com as vari\u00e1veis selecionadas abaixo (as 8 de maior correla\u00e7\u00e3o com a vari\u00e1vel resposta).","778b0fb8":"Os dados foram ajustados utilizando uma regress\u00e3o linear simples, uma regress\u00e3o ridge e uma regress\u00e3o lasso.","c54868e7":"Algumas m\u00e9tricas de desempenho (acur\u00e1cia, F1-Score e recall) experimentaram uma pequena melhora e ela s\u00f3 ocorreu quando *n_estimators* (n\u00famero de *stumps*) foi suficientemente grande. Todavia, o custo computacional para isso foi grande, a melhora n\u00e3o foi significativa e a precis\u00e3o diminuiu.  \nPor fim, testamos Random Forests, que \u00e9 um tipo de estrat\u00e9gia de *Bootstrap\/Bagging*, isto \u00e9, elas operam construindo v\u00e1rias \u00e1rvores de decis\u00e3o no momento do treinamento e retornam a classe que \u00e9 a moda das classes (j\u00e1 que trata-se de um problema de classifica\u00e7\u00e3o) das \u00e1rvores individuais. As *random forests* minimizam a tend\u00eancia de *overfitting* das \u00e1rvores de decis\u00e3o a sua base de treino.","b31aa065":"### 5. SVM ###","32a0afb8":"O melhor resultado foi obtido para \u00e1rvores com *max_depth* = 9 e *splits* escolhidos atrav\u00e9s de *Gini index*.","5a966a9a":"E, a seguir, apresenta-se a correla\u00e7\u00e3o entre todas as vari\u00e1veis da base por meio de um *heatmap*.","a016ded5":"Como a An\u00e1lise Explorat\u00f3ria deste conjunto de dados j\u00e1 foi realizada no primeiro trabalho da disciplina (e se encontra dispon\u00edvel em https:\/\/www.kaggle.com\/nathanmimoso\/pmr3508-2019-71 ), partiremos de seus resultados.\nAl\u00e9m disso, repetiremos alguns dos m\u00e9todos outrora utilizados: exclu\u00edremos as linhas com *missing values* e transformaremos todas as entradas da base de dados em valores num\u00e9ricos. Por fim, tamb\u00e9m normalizaremos as vari\u00e1veis.","d0f3fb73":"Este resultado j\u00e1 melhora aquele obtido com kNN no trabalho anterior.  \nAgora vamos testar uma *Boosted tree* utilizado o algoritmo AdaBoost.","900e7673":"### 2. Explorando modelos de regress\u00e3o ###","a0c70179":"Os tr\u00eas classificadores foram agrupados aqui, apesar de n\u00e3o se tratarem da mesma ferramenta, por algumas semelhan\u00e7as entre eles e por, muitas vezes, serem aplicados conjuntamente.\nAs \u00e1rvores de decis\u00e3o (neste caso, de classifica\u00e7\u00e3o) s\u00e3o classificadores muito simples e de f\u00e1cil interpretabilidade. A seguir, fazemos um ajuste inicial muito simples apenas para medir sua acur\u00e1cia.","43603706":"As vari\u00e1veis mais correlacionadas com a vari\u00e1vel *median_house_value* s\u00e3o *latitude*, *median_age*, *total_rooms* e, principalmente, *median_income*. Os gr\u00e1ficos abaixo ilustram estas correla\u00e7\u00f5es.","fdf9e4cc":"### 1. Importando as ferramentas e os dados","e1e58fb4":"**Obs.:** n\u00e3o foi poss\u00edvel avaliar o regressor na base de testes, j\u00e1 que n\u00e3o foram encontrados os valores de Y reais para comparar com os preditos pelo modelo.","7f0b5e3f":"Nesta tarefa extra, objetiva-se produzir *um regressor* para prever o pre\u00e7o de uma casa.","c7cece10":"### 4. \u00c1rvores de Classifica\u00e7\u00e3o, Boosting e Random Forests ###","243c7513":"## <center>PMR3508 - Tarefa 2: Compara\u00e7\u00e3o de tr\u00eas classificadores na base *Adult*<\/center>","5f366d58":"Antes de passar a modelagem em si, cabe relembrar os resultados obtidos com o classificador kNN: foi escolhido **k = 26** via *cross validation* e a acur\u00e1cia m\u00e9dia obtida foi de **0.830973965155016**.","c6edfcc7":"### 2. R\u00e1pido tratamento dos dados","f1622bc7":"Esperava-se que o resultado obtido fosse melhor que o anterior, mas n\u00e3o foi isso que ocorreu. Entretanto, as *random forests* se sa\u00edram melhores que a regress\u00e3o log\u00edstica e o kNN.","4e20f5fd":"Autor: Nathan Torquato Mimoso (Hash 71)","47a5b87c":"Esperava-se que o RMSLE diminu\u00edsse at\u00e9 determinada quantidade de *features* e, a partir da\u00ed, come\u00e7asse a crescer, indicando que acrescentar mais vari\u00e1veis ao modelo diminui sua acur\u00e1cia, mas n\u00e3o foi exatamente o que obtemos. Assim sendo, o modelo que mostrou melhor desempenho foi o **regressor ridge**.","1d944fa2":"A acur\u00e1cia obtida tamb\u00e9m foi maior que no kNN e na regress\u00e3o log\u00edstica, mas foi inferior aos m\u00e9todos da se\u00e7\u00e3o anterior. Como dito no in\u00edcio, o desempenho n\u00e3o t\u00e3o bom deste classificador pode estar indicando que a fronteira que separa as classes n\u00e3o \u00e9 linear, j\u00e1 que ambos os classificadores que assim procediam n\u00e3o foram t\u00e3o bem sucedidos."}}