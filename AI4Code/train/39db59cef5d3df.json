{"cell_type":{"62e2777b":"code","ae2b5e12":"code","b2305ebf":"code","7c315b81":"code","7d95c08c":"code","bdc87705":"code","07f87993":"code","86599b1c":"code","9c43729e":"code","34160928":"code","47c25e7e":"code","780bd012":"code","7d1d9c5f":"code","04f5bd77":"code","b9a3d414":"code","a6873b34":"code","94914997":"code","a9d2a9df":"code","85364b94":"code","b0366f59":"code","e0d5b649":"markdown","b91cb8f3":"markdown","61590f44":"markdown","6eec67f1":"markdown","a9462c7f":"markdown","1b4eff66":"markdown","7843b2b0":"markdown","ab820694":"markdown","fe31134d":"markdown","58596446":"markdown","7bd90be2":"markdown"},"source":{"62e2777b":"import numpy as np \nimport pandas as pd \nimport nltk\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing","ae2b5e12":"train_df = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")","b2305ebf":"train_df.head()","7c315b81":"test_df.head()","7d95c08c":"print(train_df.isnull().sum())\nprint(test_df.isnull().sum())","bdc87705":"samples = train_df['location'].unique()\nsamples = samples[~pd.isnull(samples)]\nsamples","07f87993":"# Fill the missing keywords with the first word of the text\ntrain_df['keyword'].fillna((train_df['text'].str.split(\" \", n = 1, expand = True)[0]), inplace=True)\ntest_df['keyword'].fillna((test_df['text'].str.split(\" \", n = 1, expand = True)[0]), inplace=True)\n\n# Fill the location with a random location\ntrain_df['location'].fillna(pd.Series(np.random.choice(samples, train_df['location'].shape)), inplace =True)\ntest_df['location'].fillna(pd.Series(np.random.choice(samples, test_df['location'].shape)), inplace =True)","86599b1c":"train_df.head()","9c43729e":"#fig = px.histogram(train_df, x='target')\n#fig.show()\ntarget=train_df.groupby('target').count()\nplt.bar(target.index.values, target['id'])\nplt.xlabel('Expected target')\nplt.ylabel('Number of twits')\nplt.show()","34160928":"fig = px.histogram(train_df, x='location')\nfig.show()","47c25e7e":"train_df[\"text\"] = train_df[\"text\"].str.lower()\ntest_df[\"text\"] = test_df[\"text\"].str.lower()\ntrain_df.head()","780bd012":"from nltk.stem import WordNetLemmatizer\n\nlemmatizer = WordNetLemmatizer()\n\ntrain_df[\"text\"] = train_df[\"text\"].apply(lambda x: lemmatizer.lemmatize(x))\ntest_df[\"text\"] = test_df[\"text\"].apply(lambda x: lemmatizer.lemmatize(x))\ntrain_df.head()","7d1d9c5f":"train_df[\"textC\"] = train_df.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)\ntest_df[\"textC\"] = test_df.apply(lambda row: nltk.word_tokenize(row['text']), axis=1) \ntrain_df.head()","04f5bd77":"train_df[\"textConv\"] = train_df[\"textC\"].apply(lambda x:[t for w, t in nltk.pos_tag(x)])\ntest_df[\"textConv\"] = test_df[\"textC\"].apply(lambda x:[t for w, t in nltk.pos_tag(x)])\ntrain_df.head()","b9a3d414":"# Use TF-IDF vectorizer to focus on frequency and importance of words\nvectorizer =TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n\nX_train= vectorizer.fit_transform(train_df[\"text\"])\nX_test = vectorizer.transform(test_df[\"text\"] )","a6873b34":"from sklearn.linear_model import LogisticRegression\nmodelLR = LogisticRegression(solver='liblinear', random_state=0)\n\nmodelLR.fit(X_train.todense(), train_df['target'])\n\nmodelLR.score(X_train.todense(), train_df['target'])","94914997":"from sklearn.ensemble import RandomForestClassifier\n\nmodelRFC = RandomForestClassifier()\n\nmodelRFC.fit(X_train.todense(),train_df['target'])\n\nmodelRFC.score(X_train.todense(), train_df['target'])","a9d2a9df":"from sklearn.naive_bayes import GaussianNB\n\nmodelNB = GaussianNB()\n\nmodelNB.fit(X_train.todense(),train_df['target'])\n\nmodelNB.score(X_train.todense(), train_df['target'])","85364b94":"from sklearn.tree import DecisionTreeRegressor\n\nmodelDT = DecisionTreeRegressor(max_depth=10)\n\nmodelDT.fit(X_train.todense(), train_df['target'])\n\nmodelDT.score(X_train.todense(), train_df['target'])","b0366f59":"y_pred = modelNB.predict(X_test.todense())\n\nsubmission = pd.DataFrame({'id':test_df['id'], 'target':y_pred})\n\nsubmission.to_csv('submission.csv',index=False)\n\nsubmission.head()","e0d5b649":"# Imports","b91cb8f3":"### Random Forest Classifier","61590f44":"## Data Analysis","6eec67f1":"### Logistic Regression","a9462c7f":"## Show data","1b4eff66":"## Models","7843b2b0":"### Gaussian Naive Bayes","ab820694":"## Prediction","fe31134d":"## Normalization","58596446":"### Manage NaNs","7bd90be2":"### Decision Tree Regressor"}}