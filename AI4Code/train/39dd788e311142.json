{"cell_type":{"653363b0":"code","e081f199":"code","d6b33970":"code","cca9c00e":"code","8855206c":"code","9128ad34":"code","939cafea":"code","8abd54fa":"code","e88c8f4a":"code","68af7407":"code","93778da1":"code","a8525bdd":"code","b85e1a6d":"code","93675271":"code","57241e29":"code","e674df9e":"code","58ae5629":"code","52129035":"code","589534b0":"code","41d48ff1":"code","0a50cf18":"code","95a50cca":"code","e473992a":"code","29759786":"code","c2d64602":"code","abf54c9b":"code","529da4f5":"code","e3d126c8":"code","42e984d6":"code","b69b4cab":"code","1a1b72d9":"code","7c35e07a":"code","35bf7c8b":"code","8f6aadde":"code","b9c7a610":"code","6811dc4a":"code","6810eb51":"markdown","3f7c5a7a":"markdown","5a91acbb":"markdown","b1f9a4a2":"markdown","036a3365":"markdown","d3efcf3e":"markdown"},"source":{"653363b0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e081f199":"df = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")","d6b33970":"df.head(10)","cca9c00e":"df.count()","8855206c":"df.info()","9128ad34":"df.isnull().values.sum()","939cafea":"df.describe()","8abd54fa":"df.columns","e88c8f4a":"columns = df.columns\ncolumns = columns.drop(['Time'])","68af7407":"from matplotlib import pyplot as plt\nimport seaborn as sns","93778da1":"for col in columns :\n    plt.figure(figsize=[10,5])\n    sns.kdeplot(df[col])","a8525bdd":"from sklearn.model_selection import train_test_split\n\nX = df.drop(['Class'], axis=1)\ny = df.Class\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)","b85e1a6d":"from sklearn import ensemble\n\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","93675271":"from sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score,auc, accuracy_score","57241e29":"print(classification_report(y_test, y_rf))","e674df9e":"cm = confusion_matrix(y_test, y_rf)\nprint(cm)","58ae5629":"X = df.drop(['Class'], axis=1)\ny = df.Class\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)","52129035":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE()\nX_train, y_train = smote.fit_resample(X_train, y_train)","589534b0":"y_train.value_counts()","41d48ff1":"from sklearn import ensemble\nrf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","0a50cf18":"print(classification_report(y_test, y_rf))","95a50cca":"cm = confusion_matrix(y_test, y_rf)\nprint(cm)","e473992a":"df.Class.value_counts()","29759786":"from imblearn.under_sampling import RandomUnderSampler \n\nrus = RandomUnderSampler()\nX_train, y_train = rus.fit_resample(X_train, y_train)","c2d64602":"y_train.value_counts()","abf54c9b":"rf = ensemble.RandomForestClassifier()\nrf.fit(X_train, y_train)\ny_rf = rf.predict(X_test)","529da4f5":"print(classification_report(y_test, y_rf))","e3d126c8":"cm = confusion_matrix(y_test, y_rf)\nprint(cm)","42e984d6":"from xgboost import XGBClassifier\nxgb = XGBClassifier()\nxgb.fit(X_train,y_train)\nprint(xgb.score(X_test,y_test))","b69b4cab":"y_xgb = xgb.predict(X_test)\n\nprint(classification_report(y_test, y_xgb))","1a1b72d9":"cm = metrics.confusion_matrix(y_test, y_xgb)\nprint(cm)","7c35e07a":"X = df.drop(['Class'], axis=1)\ny = df.Class\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)","35bf7c8b":"df.Class.value_counts()","8f6aadde":"from xgboost import XGBClassifier\nxgb = XGBClassifier(scale_pos_weight=2278\/388)\nxgb.fit(X_train,y_train)\ny_xgb = xgb.predict(X_test)","b9c7a610":"print(classification_report(y_test, y_xgb))","6811dc4a":"cm = confusion_matrix(y_test, y_xgb)\nprint(cm)","6810eb51":"# Method 3 - Downsampling","3f7c5a7a":"# Method 2 - Oversampling ","5a91acbb":"# Data Process","b1f9a4a2":"# Method 5 - XGBoost Weighted","036a3365":"# Method 1 - Random Forest","d3efcf3e":"# Method 4 - XGBoost w\/ Oversampling"}}