{"cell_type":{"ab8819ed":"code","2f28dedc":"code","20b912f5":"code","7bf04e8c":"code","51a74b1b":"code","aba5b12d":"code","e5cb3b68":"code","9432bf94":"code","f2a6d727":"code","da8eace4":"code","cc1910d7":"code","a1f35c81":"code","7e5237be":"code","e7b4c829":"code","7eedceb8":"code","19d87664":"code","ce1c8191":"code","49c2bf48":"code","05da1fc7":"code","6234bf6a":"code","cc52e2ac":"code","bbbd9ffa":"code","59644948":"code","66102981":"code","ccd7fe93":"code","523e9e04":"code","59d19cf4":"code","757d280b":"code","d64ea4e6":"code","48b538ee":"code","247eac15":"code","1f5670af":"code","f2436cdb":"code","da7c4a72":"code","3033e8bb":"code","360ebe50":"code","e758494d":"code","def9aedf":"code","30175278":"code","1b04a326":"code","fdb1f292":"code","09d8c3ba":"code","dee70805":"code","a0e0a65d":"code","e2e72494":"code","17d5bfa4":"code","7bfbfa99":"code","3fa9776d":"code","8bd93c13":"code","f290f85a":"code","63ff3400":"code","0bb9ff92":"code","01aaa185":"code","cb5e8e0f":"code","65450887":"code","049d6b19":"code","f83213f3":"code","4552d0ec":"code","77627d73":"code","b57fec3b":"code","011e763f":"code","acb6770e":"code","df0444be":"code","a08cab19":"code","8c49e19d":"code","d910a561":"code","0c52f57b":"code","845bc6e1":"code","fe62ecd5":"code","23ecb324":"code","6d1740f8":"code","336b6818":"code","c5923286":"code","b78c2c19":"code","f30a874a":"code","4789acf1":"code","225ce290":"code","3a13c782":"code","9df84d19":"code","f140691e":"code","2addfaf8":"code","5c0a80f5":"code","3e88626d":"code","5b8a9624":"code","586c32e6":"code","c9781fce":"code","5d4da55b":"code","b9a8671f":"code","b10fbdac":"code","cc2a50ed":"code","7edcef0e":"code","a6c31a9b":"code","6431f9d2":"code","d3154075":"code","ab41eb91":"code","84305d01":"code","8de7df27":"code","d9d84229":"code","ba829813":"code","447ba5c6":"code","eaf3f657":"code","079fb5f5":"markdown","f76ad5cf":"markdown","665dd56d":"markdown","8e2803ec":"markdown","0e5e9594":"markdown","0b7f3adc":"markdown","040246e4":"markdown","e30f3743":"markdown","5072bb1c":"markdown","8e56e85d":"markdown","f9e24e20":"markdown","8228bc5a":"markdown","2250c65d":"markdown","493db6cc":"markdown","85592aef":"markdown","49cb56c9":"markdown","fecfdf02":"markdown","78a04afa":"markdown","30315273":"markdown","5365ad62":"markdown","7195824c":"markdown","4cdcb419":"markdown","1d8b6b23":"markdown","60f82b1a":"markdown","def1a43a":"markdown","419b3590":"markdown","dc23de1a":"markdown","2d136d61":"markdown","7964495e":"markdown","a7e43152":"markdown","1e06ce3b":"markdown","987d077f":"markdown","9bbb7465":"markdown","187e85dc":"markdown","b736408b":"markdown","6c210382":"markdown","b0335e81":"markdown","f6bd5c29":"markdown","0399ff02":"markdown","fe37b86f":"markdown","5a02af90":"markdown","5b75adee":"markdown","007e3236":"markdown","80dc3a09":"markdown","59a251f0":"markdown","efb6eadf":"markdown","a12a5373":"markdown","6981e1c5":"markdown","9e7189d4":"markdown","042d194e":"markdown","85a9e5e4":"markdown","97d450a9":"markdown","c46ce4c4":"markdown","6ef1941d":"markdown","70a2ca0e":"markdown","b1139ba7":"markdown","9685e3cc":"markdown","dc41f2f5":"markdown","475cd704":"markdown","11a5bd0a":"markdown","474699c1":"markdown","dd08ba8c":"markdown","67b734fd":"markdown","8af6ec0f":"markdown"},"source":{"ab8819ed":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","2f28dedc":"#using the seaborn style for graphs\nplt.style.use(\"seaborn\")","20b912f5":"## Read the dataset\nemployee_data = pd.read_csv(\"..\/input\/WA_Fn-UseC_-HR-Employee-Attrition.csv\")","7bf04e8c":"employee_data.head()","51a74b1b":"##looking for any missing values\n\nemployee_data.isnull().sum()","aba5b12d":"employee_data.info()","e5cb3b68":"## basic descriptive statistics\nemployee_data.describe()","9432bf94":"#Mapping the attrition 1 - yes and 0 - no in the new column\n\nemployee_data[\"left\"] = np.where(employee_data[\"Attrition\"] == \"Yes\",1,0)","f2a6d727":"employee_data.head()","da8eace4":"#supressing all the warnings\nimport warnings\nwarnings.filterwarnings('ignore')","cc1910d7":"def NumericalVariables_targetPlots(df,segment_by,target_var = \"Attrition\"):\n    \"\"\"A function for plotting the distribution of numerical variables and its effect on attrition\"\"\"\n    \n    fig, ax = plt.subplots(ncols= 2, figsize = (14,6))    \n\n    #boxplot for comparison\n    sns.boxplot(x = target_var, y = segment_by, data=df, ax=ax[0])\n    ax[0].set_title(\"Comparision of \" + segment_by + \" vs \" + target_var)\n    \n    #distribution plot\n    ax[1].set_title(\"Distribution of \"+segment_by)\n    ax[1].set_ylabel(\"Frequency\")\n    sns.distplot(a = df[segment_by], ax=ax[1], kde=False)\n    \n    plt.show()","a1f35c81":"def CategoricalVariables_targetPlots(df, segment_by,invert_axis = False, target_var = \"left\"):\n    \n    \"\"\"A function for Plotting the effect of variables(categorical data) on attrition \"\"\"\n    \n    fig, ax = plt.subplots(ncols= 2, figsize = (14,6))\n    \n    #countplot for distribution along with target variable\n    #invert axis variable helps to inter change the axis so that names of categories doesn't overlap\n    if invert_axis == False:\n        sns.countplot(x = segment_by, data=df,hue=\"Attrition\",ax=ax[0])\n    else:\n        sns.countplot(y = segment_by, data=df,hue=\"Attrition\",ax=ax[0])\n        \n    ax[0].set_title(\"Comparision of \" + segment_by + \" vs \" + \"Attrition\")\n    \n    #plot the effect of variable on attrition\n    if invert_axis == False:\n        sns.barplot(x = segment_by, y = target_var ,data=df,ci=None)\n    else:\n        sns.barplot(y = segment_by, x = target_var ,data=df,ci=None)\n        \n    ax[1].set_title(\"Attrition rate by {}\".format(segment_by))\n    ax[1].set_ylabel(\"Average(Attrition)\")\n    plt.tight_layout()\n\n    plt.show()","7e5237be":"# we are checking the distribution of employee age and its related to attrition or not\n\nNumericalVariables_targetPlots(employee_data,segment_by=\"Age\")","e7b4c829":"#Analyzing the daily wage rate vs employee left the company or not\n\nNumericalVariables_targetPlots(employee_data,\"DailyRate\")","7eedceb8":"NumericalVariables_targetPlots(employee_data,\"MonthlyIncome\")","19d87664":"NumericalVariables_targetPlots(employee_data,\"HourlyRate\")","ce1c8191":"NumericalVariables_targetPlots(employee_data,\"PercentSalaryHike\")","49c2bf48":"NumericalVariables_targetPlots(employee_data,\"TotalWorkingYears\")","05da1fc7":"sns.lmplot(x = \"TotalWorkingYears\", y = \"PercentSalaryHike\", data=employee_data,fit_reg=False,hue=\"Attrition\",size=6,\n           aspect=1.5)\n\nplt.show()","6234bf6a":"NumericalVariables_targetPlots(employee_data,\"DistanceFromHome\")","cc52e2ac":"#cross tabulation between attrition and JobInvolvement\npd.crosstab(employee_data.JobInvolvement,employee_data.Attrition)","bbbd9ffa":"#calculating the percentage of people having different job involvement rate\nround(employee_data.JobInvolvement.value_counts()\/employee_data.shape[0] * 100,2)","59644948":"CategoricalVariables_targetPlots(employee_data,\"JobInvolvement\")","66102981":"CategoricalVariables_targetPlots(employee_data,\"JobSatisfaction\")","ccd7fe93":"#checking the number of categories under performance rating\nemployee_data.PerformanceRating.value_counts()","523e9e04":"#calculate the percentage of performance rating per category in the whole dataset\nround(employee_data.PerformanceRating.value_counts()\/employee_data.shape[0] * 100,2)","59d19cf4":"CategoricalVariables_targetPlots(employee_data,\"PerformanceRating\")","757d280b":"#percentage of each relationship satisfaction category across the data\nround(employee_data.RelationshipSatisfaction.value_counts()\/employee_data.shape[0],2)","d64ea4e6":"CategoricalVariables_targetPlots(employee_data,\"RelationshipSatisfaction\")","48b538ee":"#percentage of worklife balance rating across the company data\nround(employee_data.WorkLifeBalance.value_counts()\/employee_data.shape[0],2)","247eac15":"CategoricalVariables_targetPlots(employee_data,\"WorkLifeBalance\")","1f5670af":"CategoricalVariables_targetPlots(employee_data,\"OverTime\")","f2436cdb":"CategoricalVariables_targetPlots(employee_data,segment_by=\"BusinessTravel\")","da7c4a72":"employee_data.Department.value_counts()","3033e8bb":"CategoricalVariables_targetPlots(employee_data,segment_by=\"Department\")","360ebe50":"employee_data.EducationField.value_counts()","e758494d":"CategoricalVariables_targetPlots(employee_data,\"EducationField\",invert_axis=True)","def9aedf":"plt.figure(figsize=(10,8))\nsns.barplot(y = \"EducationField\", x = \"left\", hue=\"Education\", data=employee_data,ci=None)\nplt.show()","30175278":"CategoricalVariables_targetPlots(employee_data,\"EnvironmentSatisfaction\")","1b04a326":"sns.boxplot(employee_data['Gender'], employee_data['MonthlyIncome'])\nplt.title('MonthlyIncome vs Gender Box Plot', fontsize=20)      \nplt.xlabel('MonthlyIncome', fontsize=16)\nplt.ylabel('Gender', fontsize=16)\nplt.show()","fdb1f292":"CategoricalVariables_targetPlots(employee_data,\"Gender\")","09d8c3ba":"fig,ax = plt.subplots(2,3, figsize=(20,20))               # 'ax' has references to all the four axes\nplt.suptitle(\"Comparision of various factors vs Gender\", fontsize=20)\nsns.barplot(employee_data['Gender'],employee_data['DistanceFromHome'],hue = employee_data['Attrition'], ax = ax[0,0],ci=None); \nsns.barplot(employee_data['Gender'],employee_data['YearsAtCompany'],hue = employee_data['Attrition'], ax = ax[0,1],ci=None); \nsns.barplot(employee_data['Gender'],employee_data['TotalWorkingYears'],hue = employee_data['Attrition'], ax = ax[0,2],ci=None); \nsns.barplot(employee_data['Gender'],employee_data['YearsInCurrentRole'],hue = employee_data['Attrition'], ax = ax[1,0],ci=None); \nsns.barplot(employee_data['Gender'],employee_data['YearsSinceLastPromotion'],hue = employee_data['Attrition'], ax = ax[1,1],ci=None); \nsns.barplot(employee_data['Gender'],employee_data['NumCompaniesWorked'],hue = employee_data['Attrition'], ax = ax[1,2],ci=None); \nplt.show()","dee70805":"CategoricalVariables_targetPlots(employee_data,\"JobRole\",invert_axis=True)","a0e0a65d":"CategoricalVariables_targetPlots(employee_data,\"MaritalStatus\")","e2e72494":"from sklearn.model_selection import train_test_split\n\n#for fitting classification tree\nfrom sklearn.tree import DecisionTreeClassifier\n\n#to create a confusion matrix\nfrom sklearn.metrics import confusion_matrix\n\n#import whole class of metrics\nfrom sklearn import metrics","17d5bfa4":"employee_data.Attrition.value_counts().plot(kind = \"bar\")\nplt.xlabel(\"Attrition\")\nplt.ylabel(\"Count\")\nplt.show()","7bfbfa99":"employee_data[\"Attrition\"].value_counts()","3fa9776d":"#copying the main employee data to another dataframe\nemployee_data_new = employee_data.copy()","8bd93c13":"#dropping the not significant variables\nemployee_data_new.drop([\"EmployeeCount\",\"EmployeeNumber\",\"Gender\",\"HourlyRate\",\"Over18\",\"StandardHours\",\"left\"], axis=1,inplace=True)","f290f85a":"#data types of variables\ndict(employee_data_new.dtypes)","63ff3400":"#segregating the variables based on datatypes\n\nnumeric_variable_names  = [key for key in dict(employee_data_new.dtypes) if dict(employee_data_new.dtypes)[key] in ['float64', 'int64', 'float32', 'int32']]\n\ncategorical_variable_names = [key for key in dict(employee_data_new.dtypes) if dict(employee_data_new.dtypes)[key] in [\"object\"]]","0bb9ff92":"categorical_variable_names","01aaa185":"#store the numerical variables data in seperate dataset\n\nemployee_data_num = employee_data_new[numeric_variable_names]","cb5e8e0f":"#store the categorical variables data in seperate dataset\n\nemployee_data_cat = employee_data_new[categorical_variable_names]\n#dropping the attrition \nemployee_data_cat.drop([\"Attrition\"],axis=1,inplace=True)","65450887":"#converting into dummy variables\n\nemployee_data_cat = pd.get_dummies(employee_data_cat)","049d6b19":"#Merging the both numerical and categorical data\n\nemployee_data_final = pd.concat([employee_data_num, employee_data_cat,employee_data_new[[\"Attrition\"]]],axis=1)","f83213f3":"employee_data_final.head()","4552d0ec":"#final features\nfeatures =  list(employee_data_final.columns.difference([\"Attrition\"]))","77627d73":"features","b57fec3b":"#seperating the target and predictors\n\nX = employee_data_final[features]\ny = employee_data_final[[\"Attrition\"]]","011e763f":"X.shape","acb6770e":"# Function for creating model pipelines\nfrom sklearn.pipeline import make_pipeline\n\n#function for crossvalidate score\nfrom sklearn.model_selection import cross_validate\n\n#to find the best \nfrom sklearn.model_selection import GridSearchCV","df0444be":"X_train, X_test, y_train,y_test = train_test_split(X,y,test_size = 0.3,stratify = y,random_state = 100)","a08cab19":"#Checks\n#Proportion in training data\ny_train.Attrition.value_counts()\/len(y_train)","8c49e19d":"#Checks\n#Proportion in training data\npd.DataFrame(y_train.Attrition.value_counts()\/len(y_train)).plot(kind = \"bar\")\nplt.show()","d910a561":"#Proportion of test data\ny_test.Attrition.value_counts()\/len(y_test)","0c52f57b":"#make a pipeline for decision tree model \n\npipelines = {\n    \"clf\": make_pipeline(DecisionTreeClassifier(max_depth=3,random_state=100))\n}","845bc6e1":"scores = cross_validate(pipelines['clf'], X_train, y_train,return_train_score=True)","fe62ecd5":"scores['test_score'].mean()","23ecb324":"decisiontree_hyperparameters = {\n    \"decisiontreeclassifier__max_depth\": np.arange(3,12),\n    \"decisiontreeclassifier__max_features\": np.arange(3,10),\n    \"decisiontreeclassifier__min_samples_split\": [2,3,4,5,6,7,8,9,10,11,12,13,14,15],\n    \"decisiontreeclassifier__min_samples_leaf\" : np.arange(1,3)\n}","6d1740f8":"pipelines['clf']","336b6818":"#Create a cross validation object from decision tree classifier and it's hyperparameters\n\nclf_model = GridSearchCV(pipelines['clf'], decisiontree_hyperparameters, cv=5, n_jobs=-1)","c5923286":"#fit the model with train data\nclf_model.fit(X_train, y_train)","b78c2c19":"#Display the best parameters for Decision Tree Model\nclf_model.best_params_","f30a874a":"#Display the best score for the fitted model\nclf_model.best_score_","4789acf1":"#In Pipeline we can use the string names to get the decisiontreeclassifer\n\nclf_model.best_estimator_.named_steps['decisiontreeclassifier']","225ce290":"#saving into a variable to get graph\n\nclf_best_model = clf_model.best_estimator_.named_steps['decisiontreeclassifier']","3a13c782":"#Making a dataframe of actual and predicted data from test set\n\ntree_test_pred = pd.concat([y_test.reset_index(drop = True),pd.DataFrame(clf_model.predict(X_test))],axis=1)\ntree_test_pred.columns = [\"actual\",\"predicted\"]\n\n#setting the index to original index\ntree_test_pred.index = y_test.index","9df84d19":"tree_test_pred.head()","f140691e":"#keeping only positive condition (yes for attrition)\n\npred_probability = pd.DataFrame(p[1] for p in clf_model.predict_proba(X_test))\npred_probability.columns = [\"predicted_prob\"]\npred_probability.index = y_test.index","2addfaf8":"#merging the predicted data and its probability value\n\ntree_test_pred = pd.concat([tree_test_pred,pred_probability],axis=1)","5c0a80f5":"tree_test_pred.head()","3e88626d":"#converting the labels Yes --> 1 and No --> 0 for further operations below\n\ntree_test_pred[\"actual_left\"] = np.where(tree_test_pred[\"actual\"] == \"Yes\",1,0)\ntree_test_pred[\"predicted_left\"] = np.where(tree_test_pred[\"predicted\"] == \"Yes\",1,0)","5b8a9624":"tree_test_pred.head()","586c32e6":"#confusion matrix\nmetrics.confusion_matrix(tree_test_pred.actual,tree_test_pred.predicted,labels=[\"Yes\",\"No\"])","c9781fce":"#confusion matrix visualization using seaborn heatmap\n\nsns.heatmap(metrics.confusion_matrix(tree_test_pred.actual,tree_test_pred.predicted,\n                                    labels=[\"Yes\",\"No\"]),cmap=\"Greens\",annot=True,fmt=\".2f\",\n           xticklabels = [\"Left\", \"Not Left\"] , yticklabels = [\"Left\", \"Not Left\"])\n\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","5d4da55b":"#Area Under ROC Curve\n\nauc_score_test = metrics.roc_auc_score(tree_test_pred.actual_left,tree_test_pred.predicted_left)\nprint(\"AUROC Score:\",round(auc_score_test,4))","b9a8671f":"##Plotting the ROC Curve\n\nfpr, tpr, thresholds = metrics.roc_curve(tree_test_pred.actual_left, tree_test_pred.predicted_prob,drop_intermediate=False)\n\n\nplt.figure(figsize=(8, 6))\nplt.plot( fpr, tpr, label='ROC curve (area = %0.4f)' % auc_score_test)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate or [1 - True Negative Rate]')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic cuve')\nplt.legend(loc=\"lower right\")\nplt.show()\n","b10fbdac":"#calculating the recall score\n\nprint(\"Recall Score:\",round(metrics.recall_score(tree_test_pred.actual_left,tree_test_pred.predicted_left) * 100,3))","cc2a50ed":"#calculating the precision score\n\nprint(\"Precision Score:\",round(metrics.precision_score(tree_test_pred.actual_left,tree_test_pred.predicted_left) * 100,3))","7edcef0e":"print(metrics.classification_report(tree_test_pred.actual_left,tree_test_pred.predicted_left))","a6c31a9b":"# conda install pydot graphviz\n#! pip install pydotplus","6431f9d2":"from sklearn.tree import export_graphviz","d3154075":"!pip install pydotplus","ab41eb91":"import pydotplus as pdot","84305d01":"from sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus as pdot","8de7df27":"#write the dot data\ndot_data = StringIO()","d9d84229":"#export the decision tree along with the feature names into a dot file format\n\nexport_graphviz(clf_best_model,out_file=dot_data,filled=True,\n                rounded=True,special_characters=True,feature_names = X_train.columns.values,class_names = [\"No\",\"Yes\"])","ba829813":"#make a graph from dot file \ngraph = pdot.graph_from_dot_data(dot_data.getvalue())","447ba5c6":"Image(graph.create_png())","eaf3f657":"#export the tree diagram\ngraph.write_png(\"employee_attirtion.png\")","079fb5f5":"## Analyizing the variables\n\n- Numerical Variables","f76ad5cf":"Around 85% of people in the company rated as Excellent and remaining 15% rated as Outstanding","665dd56d":"- There are more people who travel rarely compared to people who travel frequently. In case of people who travel Frequently  around 25% of people have left the company and in other cases attrition rate doesn't vary significantly on travel","8e2803ec":"### Job Role","0e5e9594":"### JobSatisfaction","0b7f3adc":"- Monthly Income distribution for Male and Female is almost similar, so the attrition rate of Male and Female is almost the same around 15%. Gender is not a strong indicator of attrition","040246e4":"## Decision Tree classifier with gini index","e30f3743":"- There are more people with a Life sciences followed by medical and marketing\n- Employee's in the EducationField of Human Resources and Technical Degree have highest attrition levels around 26% and 23% respectively\n- When compared with Education level, we have observed that employees in the highest level of education in there field of study have left the company. We can conclude that EducationField is a strong indicator of attrition","5072bb1c":"**Hourly Rate**","8e56e85d":"### EnvironmentSatisfaction","f9e24e20":"#### Cross Validate \n- To check the accuracy of the pipeline","8228bc5a":"More than 30% of employee's who worked overtime has left the company, where as 90% of employee's who have not experienced overtime has not left the company. Therefore overtime is a strong indicator of attrition","2250c65d":"As expected, people with low satisfaction have left the company around 23% in that category. what surprising is out of the people who rated medium and high job satisfaction around 32% has left the company. There should be some other factor which triggers their exit from the company","493db6cc":"### Department","85592aef":"**Decision Tree is a greedy alogritum it searches the entire space of possible decision trees. so we need to find a optimum parameter(s) or criteria for stopping the decision tree at some point. We use the hyperparameters to prune the decision tree**","49cb56c9":"- We found that median age of employee's in the company is 30 - 40 Yrs. Minimum age is 18 Yrs and Maximum age is 60 Yrs.\n- From the Age Comparision boxplot, majority of people who left the company are below 40 Yrs and among the people who didn't left the company are of age 32 to 40 years","fecfdf02":"# Attrition Analytics - Exploratory Analysis & Predictive Modeling\n\n- The entire code used in this kernel is uploaded into my [github repo](https:\/\/github.com\/Niranjankumar-c\/HRAnalyticsEmployeeAttrition). Feel free to fork the repo\n- https:\/\/github.com\/Niranjankumar-c\/HRAnalyticsEmployeeAttrition\n- For more beginner friendly projects in Data Science, check out my github https:\/\/github.com\/Niranjankumar-c","78a04afa":"Contrary to normal belief that employee's having higher rating will not leave the company. It may be seen that there is no significant difference between the performance rating and Attrition Rate.","30315273":"- Remove not usefull features","5365ad62":"- As expected more than 30% of the people who rated as Bad WorkLifeBalance have left the company and around 15% of the people who rated for Best WorkLifeBalance also left the company","7195824c":"- From plot we have seen that there is no significant difference in the hourly rate and attrition. Therefore hourly rate is considered as not signifcant to attrition ","4cdcb419":"### Daily Rate & Montly Income & HourlyRate","1d8b6b23":"1. In the total data set, 59% have high job involvement whereas 25% have medium involvement rate\n2. From above plot we can observe that round 50% of people in low job involvement (level 1 & 2) have left the company.\n3. Even the people who have high job involmenent have higher attrition rate around 15% in that category have left company","60f82b1a":"# Train-Test Split(Stratified Sampling of Y)","def1a43a":"### Job Involvement","419b3590":"Average accuracy of pipeline with Decision Tree Classifier is 83.48%","dc23de1a":"From the Exploratory data analysis, variable that are not significant to attrition are:\n\n- EmployeeCount, EmployeeNumber, Gender, HourlyRate, JobLevel, MaritalStatus, Over18, StandardHours","2d136d61":"### Distance From Home","7964495e":"### Gender Vs Attrition","a7e43152":"### Age","1e06ce3b":"- Employee's working with lower daily rates are more prone to leave the company than compared to the employee's working with higher rates. The same trend is resonated with monthly income too.","987d077f":"- There is a higher number of people who reside near to offices and hence the attrition levels are lower for distance less than 10. With increase in distance from home, attrition rate also increases","9bbb7465":"#### Metrics\n\n- Recall: Ratio of the total number of correctly classified positive examples divide to the total number of positive examples. High Recall indicates the class is correctly recognized\n- Precision: To get the value of precision we divide the total number of correctly classified positive examples by the total number of predicted positive examples. High Precision indicates an example labeled as positive is indeed positive","187e85dc":"## Analyizing the variables\n\n- Categorical Variables","b736408b":"### BusinessTravel","6c210382":"### WorkLifeBalance\n","b0335e81":"### PercentSalaryHike","f6bd5c29":"1. Jobs held by the employee is maximum in Sales Executive, then R&D , then Laboratory Technician\n2. People working in Sales department is most likely quit the company followed by Laboratory Technician and Human Resources there attrition rates are 40%, 24% and 22% respectively","0399ff02":"### EducationField","fe37b86f":"#### Fit and tune models with cross-validation\n\nNow that we have our <code style=\"color:steelblue\">pipelines<\/code> and <code style=\"color:steelblue\">hyperparameters<\/code> dictionaries declared, we're ready to tune our models with cross-validation.\n- We are doing 5 fold cross validation","5a02af90":"### Total Working years","5b75adee":"More than 60% of the employee's rated that they have Better worklife balance and 10% rated for Best worklife balance","007e3236":"# Handling Categorical Variables\n\n- Segregate the numerical and Categorical variables\n- Convert Categorical variables to dummy variables","80dc3a09":"### Marital Status","59a251f0":"# Cross-Validation and Hyper Parameters Tuning\nCross Validation is the process of finding the best combination of parameters for the model by traning and evaluating the model for each combination of the parameters\n- Declare a hyper-parameters to fine tune the Decision Tree Classifier","efb6eadf":"From the ROC Curve, we have a choice to make depending on the value we place on true positive and tolerance for false positive rate\n- If we wish to find the more people who are leaving, we could increase the true positive rate by adjusting the probability cutoff for classification. However by doing so would also increase the false positive rate. we need to find the optimum value of cutoff for classification","a12a5373":"# Exploratory Data Analysis","6981e1c5":" we can see that people having low environment satisfaction 25% leave the company","9e7189d4":"## Separating the Target and the Predictors","042d194e":"# Model Performance Evaluation\n- On Test Data","85a9e5e4":"# Import the libraries","97d450a9":"- On comparing departmentwise,we can conclude that HR has seen only a marginal high in turnover rates whereas the numbers are significant in sales department with turnover rates of 39 %. The attrition levels are not appreciable in R & D where 67 % have recorded no attrition.\n- Sales has seen higher attrition levels about 20.6% followed by HR around 18%","c46ce4c4":"# Approach\n> Decision Tree Modeling: I have used Decision tree to create model. The major hurdle was we had 1223 unlabelled (No in Attrition) and 237 labelled (Yes in Attrition), which is a highly imbalanced data. So I used stratified sampling based on proportion of attrition in overall data.\n\n> Model Evaluation: I have used the k fold cross validation technique for assessing how the results of a model will generalize to an independent test data set. I used k =5 i.e.. 5 fold cross validation. Model was fit on the stratified sample data and tested on unmarked dataset.\n\n> ROC Curve: The ROC curve is a simple plot that shows the trade-off between the true positive rate and the false positive rate of a classifier for various choices of the probability threshold. ROC area = 0.6128 and F1 = 0.81\n\n> Decision Tree Visualization: Used Python pydotplus package to visualize the decision tree to draw insights\n","6ef1941d":"In this too, we found that almost 30% of employees with high and very high RelationshipSatisfaction have left the company. Here also there is no visible trend among the relationshipsatisfaction and attrition rate","70a2ca0e":"- Employee's with less working years have received 25% Salary hike when they switch to another company, but there is no linear relationship between working years and salary hike. \n- Attrition is not seen amomg the employee's having more than 20 years of experience if their salary hike is more than 20%, even if the salary hike is below 20% attrition rate among the employee's is very low.\n- Employee's with lesser years of experience are prone to leave the company in search of better pay, irrespective of salary hike","b1139ba7":"- Majority (60% of total strength) of employee's receive 16% salary hike in the company, employee's who received less salary hike have left the company.","9685e3cc":"From the plot,it is understood that irrespective of the marital status,there are large people who stay with the company and do not leave.Therefore,marital status is a weak predictor of attrition","dc41f2f5":"# Visualization of Decision Tree\n- Dependencies \n    - Need to install graphviz (conda install pydot graphviz)\n    - Set the environment path variable to graphviz folder","475cd704":"## Objective:\nThe objective of the present report is to study factors like salary, satisfactory level, growth opportunities, facilities, policies and procedures, recognition, appreciation, suggestions of the employee\u2019s by which it helps to know the Attrition level in the organizations and factors relating to retain them. This study also helps to find out where the organizations are lagging in retaining.\n\n## Hypothesis:\n\n> Employee attrition increases costs of recruitment, hiring and training replacement in the industries.\n> Employee attrition reduces production, and profit in the industries.","11a5bd0a":"### Confusion Matrix\n\nThe confusion matrix is a way of tabulating the number of misclassifications, i.e., the number of predicted classes which ended up in a wrong classification bin based on the true classes.","474699c1":"### RelationshipSatisfaction","dd08ba8c":"### Performance Rating","67b734fd":"1. Distance from home matters to women employees more than men. \n2. Female employes are spending more years in one company compare to their counterpart. \n3. Female employes spending more years in current company are more inclined to switch.","8af6ec0f":"# Building Decision Tree"}}