{"cell_type":{"9b986a40":"code","4b7d0a78":"code","fd1c45a8":"code","b90a9e78":"code","94bcbcc4":"code","e05faca4":"code","1fae0734":"code","f34c1eed":"code","a26fb039":"code","292a1cca":"code","fb986493":"code","4329db5a":"code","bdff7c42":"code","8e25a91c":"code","3dfc09d5":"code","1c273286":"code","88cc54e9":"code","1f9403df":"code","9c3dccd8":"code","a8b43187":"code","566a3167":"markdown","86f5a622":"markdown","5b1c74a5":"markdown","899402a6":"markdown","a262762d":"markdown","6319595f":"markdown","18e61060":"markdown"},"source":{"9b986a40":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport skimage.io\nimport os \nimport tqdm\nimport glob\nimport tensorflow \n\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\nfrom tensorflow.keras.applications.vgg16 import VGG16","4b7d0a78":"# Data Augmentation - Doing 80-20 split\n\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   rotation_range=30,\n                                   horizontal_flip=True,\n                                   vertical_flip=True,\n                                   zoom_range=0.2,\n                                   validation_split = 0.2)\n\nvalid_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   validation_split=0.2)","fd1c45a8":"train_dataset = train_datagen.flow_from_directory(directory = '..\/input\/root-canal',\n                                                  class_mode = 'categorical',\n                                                  target_size = (224,224),\n                                                  subset = 'training')","b90a9e78":"valid_dataset  = valid_datagen.flow_from_directory(directory = '..\/input\/root-canal',\n                                                   class_mode = 'categorical',\n                                                   target_size = (224,224),\n                                                   subset = 'validation')","94bcbcc4":"# Checking the binary class labels.\n\ntrain_dataset.class_indices","e05faca4":"# Viewing Images \n\nfig, ax = plt.subplots(nrows=1, ncols=5, figsize=(20,20))\n\nfor i in tqdm(range(0, 5)):\n    rand1 = np.random.randint(len(train_dataset))\n    rand2 = np.random.randint(len(train_dataset))\n    ax[i].imshow(train_dataset[rand1][0][rand2])\n    ax[i].axis('off')\n    a = train_dataset[rand1][1][rand2]\n    if a[0] == 1:\n        ax[i].set_title(\"1_ROOT\")\n    else:\n        ax[i].set_title(\"2_MORE_ROOT\")","1fae0734":"# Initializing VGG-16 model\n\nbase_model = VGG16(input_shape=(224,224,3), \n                   include_top=False,\n                   weights=\"imagenet\")","f34c1eed":"# Checking Summary \n\nbase_model.summary()","a26fb039":"# Freezing Layers\n\nfor layer in base_model.layers:\n    layer.trainable=False","292a1cca":"# Building Model\n\nmodel=Sequential()\nmodel.add(base_model)\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(1024,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1024,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2,activation='softmax'))","fb986493":"# Checking Summary\n\nmodel.summary()","4329db5a":"# Checking imbalance in the data for setting metric.\n\nroot_1 = glob.glob('..\/input\/root-canal\/1_ROOT\/1 root\/*.jpg')\nroot_2 = glob.glob('..\/input\/root-canal\/2_MORE_ROOT\/2 or more roots\/*.jpg')\n\nlen(root_1), len(root_2)","bdff7c42":"# Compiling Model\n\nOPT    = tensorflow.keras.optimizers.Adam(lr=0.001)\n\nmodel.compile(loss='categorical_crossentropy',\n              metrics=[tensorflow.keras.metrics.AUC(name = 'auc')],\n              optimizer=OPT)","8e25a91c":"# Defining Callbacks\n\nfilepath = '.\/best_weights.hdf5'\n\nearlystopping = EarlyStopping(monitor = 'val_auc', \n                              mode = 'max' , \n                              patience = 15,\n                              verbose = 1)\n\ncheckpoint    = ModelCheckpoint(filepath, \n                                monitor = 'val_auc', \n                                mode='max', \n                                save_best_only=True, \n                                verbose = 1)\n\n\ncallback_list = [earlystopping, checkpoint]","3dfc09d5":"model_history=model.fit(train_dataset,\n                        validation_data=valid_dataset,\n                        epochs = 500,\n                        callbacks = callback_list,\n                        verbose = 1)","1c273286":"# LOSS \n\nplt.plot(model_history.history['loss'])\nplt.plot(model_history.history['val_loss'])\nplt.title('LOSS')\nplt.ylabel('Loss')\nplt.xlabel('Nos. of epochs')\nplt.legend(['Train', 'Validation'], loc='upper left', bbox_to_anchor = (1,1))\nplt.show()","88cc54e9":"# AUC\n\nplt.plot(model_history.history['auc'])\nplt.plot(model_history.history['val_auc'])\nplt.title('AUC')\nplt.ylabel('AUC')\nplt.xlabel('Nos. of epochs')\nplt.legend(['Train', 'Validation'], loc='upper left', bbox_to_anchor = (1,1))\nplt.show()","1f9403df":"# TESTING ON IMAGES ","9c3dccd8":"dict = train_dataset.class_indices\nidc  = {k:v for v, k in dict.items()}\n\nimg = load_img('..\/input\/root-canal\/1_ROOT\/1 root\/tooth10.jpg', target_size=(224,224,3))\nimg = img_to_array(img)\nimg = img\/255\nimshow(img)\nimg = np.expand_dims(img, axis=0)\nanswer = model.predict_classes(img)\nprobability = round(np.max(model.predict_proba(img)*100),2)\n\nprint(probability, '% chances are there that the image is',idc[answer[0]])","a8b43187":"dict = train_dataset.class_indices\nidc  = {k:v for v, k in dict.items()}\n\nimg = load_img('..\/input\/root-canal\/2_MORE_ROOT\/2 or more roots\/tooth100.jpg', target_size=(224,224,3))\nimg = img_to_array(img)\nimg = img\/255\nimshow(img)\nimg = np.expand_dims(img, axis=0)\nanswer = model.predict_classes(img)\nprobability = round(np.max(model.predict_proba(img)*100),2)\n\nprint(probability, '% chances are there that the image is',idc[answer[0]])","566a3167":"> `DATA AUGMENTATION`","86f5a622":"### IMPORTING \/ VIEWING \/ PREPROCESSING DATASET","5b1c74a5":"> `CASE 2: 2_MORE_ROOT`","899402a6":"### MODEL EVALUATION","a262762d":"### MODEL BUILDING ","6319595f":"> `CASE 1: 1_ROOT IMAGE`","18e61060":"### IMPORT LIBRARIES"}}