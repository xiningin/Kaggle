{"cell_type":{"b3f72ecb":"code","d637ca71":"code","6e67773e":"code","c76636cd":"code","740aaa22":"code","71317701":"code","be877e32":"code","87d74b3e":"code","1fb021e5":"code","71489009":"code","459d9adc":"code","74073af0":"code","f797c5ab":"code","03fb6563":"code","ff26fe0f":"code","cbd9382c":"code","c154f63f":"code","e6202c0f":"code","48c37efc":"code","dea5c5a5":"code","7d82ed6f":"code","2ecc0221":"code","375791b7":"code","d43f75b8":"code","664525fa":"code","f7968c7a":"markdown","99c13901":"markdown","856629d7":"markdown","3ac3b9e3":"markdown","9cf04284":"markdown","eea72a9a":"markdown","fef774c0":"markdown","923bbc91":"markdown","0b53db3b":"markdown","6439645f":"markdown","2318d62e":"markdown","5bc78a87":"markdown","7c70ce6d":"markdown","81b6f412":"markdown","677c5b0b":"markdown","dd5bb041":"markdown","d8571bd2":"markdown","7aef864f":"markdown","cb25fa15":"markdown"},"source":{"b3f72ecb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d637ca71":"!pip install feyn\nimport feyn","6e67773e":"df_train = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ndf_train","c76636cd":"missing = df_train.isnull().sum()\nmissing = missing[missing > 0]\nmissing.sort_values(inplace=True)\nmissing.plot.bar()","740aaa22":"df_train = df_train.drop([\"LotFrontage\", \"FireplaceQu\", \"Fence\", \"Alley\", \"MiscFeature\", \"PoolQC\"], axis=1)","71317701":"#Dropping rows containg NA in the rest of the columns\ndf_train = df_train.dropna(subset=[\"Electrical\", \"MasVnrType\", \"BsmtQual\", \"BsmtCond\", \n                                   \"BsmtFinType1\", \"BsmtExposure\", \"BsmtFinType2\", \"GarageCond\",\n                                   \"GarageQual\", \"GarageFinish\", \"GarageType\", \"GarageYrBlt\"])","be877e32":"#Checking to see if there is some NA values we have missed\ndf_train.isna().sum()","87d74b3e":"#Looking for categorical data in dataframe\ndf_train.dtypes","1fb021e5":"#Setting the categorical data - notice that the QLattice is case sensitive!\nstypes = {\n\"MSZoning\": \"cat\",\n\"Street\": \"cat\",\n\"LotShape\": \"cat\",\n\"LandContour\": \"cat\",\n\"Utilities\": \"cat\",\n\"LotConfig\": \"cat\",\n\"LandSlope\": \"cat\",\n\"Neighborhood\": \"cat\",\n\"Condition1\": \"cat\",\n\"Condition2\": \"cat\",\n\"BldgType\": \"cat\",\n\"HouseStyle\": \"cat\",\n\"RoofStyle\": \"cat\",\n\"RoofMatl\": \"cat\",\n\"Exterior1st\": \"cat\",\n\"Exterior2nd\": \"cat\",\n\"MasVnrType\": \"cat\",\n\"ExterQual\": \"cat\",\n\"ExterCond\": \"cat\",\n\"Foundation\": \"cat\",\n\"BsmtQual\": \"cat\",\n\"BsmtCond\": \"cat\",\n\"BsmtExposure\": \"cat\",\n\"BsmtFinType1\": \"cat\",\n\"BsmtFinType2\": \"cat\",\n\"Heating\": \"cat\",\n\"HeatingQC\": \"cat\",\n\"CentralAir\": \"cat\",\n\"Electrical\": \"cat\",\n\"KitchenQual\": \"cat\",\n\"Functional\": \"cat\",\n\"GarageType\": \"cat\",\n\"GarageFinish\": \"cat\",\n\"GarageQual\": \"cat\",\n\"GarageCond\": \"cat\",\n\"PavedDrive\": \"cat\",\n\"SaleType\": \"cat\",\n\"SaleCondition\": \"cat\"\n}","71489009":"#Splitting the dataset in two \ndf_train, df_test = feyn.tools.split(df_train, ratio=(1,1))","459d9adc":"#Connect to a QLattice\nql = feyn.connect_qlattice()","74073af0":"# Using the convenience auto_run command.\n# Notice that the stypes dictionary I created earlier gets passed to the QLattice here.\n\nmodels = ql.auto_run( \n    df_train,\n    output_name = \"SalePrice\",\n    stypes = stypes\n)","f797c5ab":"#Showing the best models\n\nfor model in models[0:5]:\n    feyn.show_model(\n        model=model,\n        update_display=False\n    )","03fb6563":"# Running the auto_run with the parameter max_complexity set to 5\n\nmodels = ql.auto_run( \n    df_train[[\"GrLivArea\", \"OverallQual\", \"Neighborhood\", \"HouseStyle\", \"SalePrice\"]],\n    output_name = \"SalePrice\",\n    max_complexity=5, \n    stypes = stypes\n)","ff26fe0f":"# Updating the QLattice with the best diverse models.\nql.update(feyn.best_diverse_models(models))","cbd9382c":"# Running the auto_run again with the QLattices updated with the knowledge from the previous run\nmodels = ql.auto_run( \n    df_train[[\"GrLivArea\", \"OverallQual\", \"Neighborhood\", \"HouseStyle\", \"SalePrice\"]],\n    output_name = \"SalePrice\",\n    max_complexity=5, \n    stypes = stypes\n)","c154f63f":"best = models[0]","e6202c0f":"best.plot(\n    data=df_train,\n    test=df_test\n)","48c37efc":"best.plot_segmented_loss(\n    data = df_train,\n    by = None\n)","dea5c5a5":"best.plot_segmented_loss(\n    data = df_test,\n    by = None\n)","7d82ed6f":"best.plot_regression(data=df_train)\nbest.plot_regression(data=df_test)","2ecc0221":"best.plot_residuals(data=df_train)\nbest.plot_residuals(data=df_test)","375791b7":"#Predicting SalePrice on test dataset and putting it into a list I can submit to the competition\ndf_submission = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\n\n# Preparing dataset\nmissing = df_submission.isnull().sum()\nmissing = missing[missing > 0]\nmissing.sort_values(inplace=True)\nmissing.plot.bar()","d43f75b8":"df_submission = df_submission.drop([\"LotFrontage\", \"FireplaceQu\", \"Fence\", \"Alley\", \"MiscFeature\", \"PoolQC\"], axis=1)","664525fa":"pred = best.predict(df_submission)\n\ndf_my_submission = pd.DataFrame(columns=[\"Id\", \"SalePrice\"])\ndf_my_submission = df_my_submission.astype({\"Id\": int, \"SalePrice\": int})\n\n\nfor i in range(len(df_submission)):\n    new_row = {\"Id\":df_submission[\"Id\"].values[i], \"SalePrice\": round(pred[i])}    \n    df_my_submission = df_my_submission.append(new_row, ignore_index=True)  \n\ndf_my_submission.to_csv('submission.csv', index=False)","f7968c7a":"Now I will also get rid of the rows wich contains NA values in the other columns.","99c13901":"As a default I will only see the best model. If I want to explore the second best, third best and so on, I can use the models[] command.","856629d7":"# Evaluate\n\nWith the QLattice I have found a mathematical relationship that can relate the predictors to the output. My final step is to evaluate the model on the test and the train set.\n\nI have plotted different graphs for evaluating.","3ac3b9e3":"# Search for the best model\n\nWith a QLattice allocated I can instruct the QLattice to search for the best mathematical model to explain the data. \nI use the high-level convenience function that does everything using sensible defaults. You can read more here https:\/\/docs.abzu.ai\/docs\/guides\/essentials\/auto_run.html.\n\nNOTE: This will take several minutes to complete. It involves work done on the QLattice machine remotely as well as in the local notebook. The part that runs locally is slowing things down because of the limited CPU resources on Kaggle. It will run significantly faster running the same on your machine locally.","9cf04284":"# Loading data\n\nI load the train dataset. Later I will split it into two, so I have a dataset to train on and a dataset to test the model the QLattice finds.","eea72a9a":"I will create a dict names stypes with this information, then I can pass it to the QLattice later.","fef774c0":"**Categorical data**\n\nThe QLattice will work fine with both categorical and numerical data. I just need to tell it which is which.  \nRead more about categorical data in the QLattice here: https:\/\/docs.abzu.ai\/docs\/guides\/essentials\/stypes.html","923bbc91":"The plot shows that 19 attributes have missing values and 5 are missing over 50% of all data. \n\nIn this case the NA values propably means a lack of the subject described by the attribute - like no pool, no fence, no garage and no basement in the house.\n\nI'll drop the 6 columns with over 200 missing values.","0b53db3b":"I now have a model that maybe doesn't perform as well, but it is much easier to understand.","6439645f":"We still have NA values left. I don't want to just drop rows with NA values in them, because I need to be able to submit a full dataset.\nInstead I will fill in the missing data with values.","2318d62e":"# Use a Community QLattice to predict houseprices in very little time\n\nI have no experience with machine learning, and this is my very first notebook. Ever. So bear with me.\n\nI will try to use the Qlattice, as it seems very straight forward and easy to use. It also handles some of the data science diciplines like encding af categorical variables and feature selection which is difficult - especially for a novice like me.\nTo be fair, I have a background as developer (although it is almost 15 years ago since I wrote my last line of code...), which of course helped me with the Python part.\n\nThe QLattice is a supervised machine learning tool for symbolic regression developed by Abzu . It is inspired by Richard Feynman's path integral formulation. That's why the python module to use it is called Feyn, and the Q in QLattice is for Quantum.\n\nAbzu provides free QLattices for non-commercial use to anyone. These free community QLattices gets allocated for you automatically if you use Feyn without an active subscription, as we will do in this notebook. Read more about how it works here: https:\/\/docs.abzu.ai\/docs\/guides\/getting_started\/community.html\n","5bc78a87":"# Preparing data\n\nI notice two things:\n1) Some columns have missing data\n\n2) The dataset contains both categorical (dtype object) and numerical columns. \n\nLet's handle those issues!\n\n**Missing data**\n\nThe QLattice does not support NA values in my dataset. \nI could just get rid of the rows with NA values in them, but if some columns contains many NA values, I would loose a very big part of my dataset with that approach.\nTherefore I want to explore if some of my columns have a lot of missing values, so I can drop the columns instead.","7c70ce6d":"# Lowering complexity\n\nWithout restrictions the models found by the QLattice can be a little complex and not that easy to understand. I can restrict the complexity of the models by passing on some parameters to the auto_run:\n\n1) The max_complexity parameter controls the complexity of the model. Low values of 4 or 5 will yield very simple models while values above 10 yield highly complex models. This is the number of edges in the graph representation of the Model. The default value in auto_run is set to 10.\n\n2) Instead of passing the entire dataframe, I can pass a list of columns which will restrict the Qlattice to use only those as features for the models. The list should be passed to the auto_run command in the format df_train[[\"GrLivArea\", \"OverallQual\", \"SalePrice\"]]. Remember to add the target to the list!\n    \n","81b6f412":"# Split the dataset\n\nI have now prepared my dataset by getting rid of columns with many NA values, and also getting rid of rows with NA values.\nI have also identified all the columns with cateforical data and created the list stypes, which I can pass on to the QLattice.\n\nNow I will split my dataset so I have one for training and one for testing the model the Qlattice finds.","677c5b0b":"# QLattice\n\nI'm now ready to connect to the QLattice. \nI can use it without any sign up or token, the feyn module will just allocate a community QLattice for me on the Abzu compute cluster.\n\nAbzu also have an option to buy a subscription for  QLattice, if I need it for commercial purposes. You can read more about that option here: https:\/\/www.abzu.ai\/pricing","dd5bb041":"# Updating QLattice\nThe number of potential models that can explain a dataset can vary. The function best_diverse_models finds the best performing Models from a list that are sufficiently diverse with respect to a distance function.\n\nA common use for this list is to update your QLattice with these models using ql.update. This helps it find all the potential Models for the data.","d8571bd2":"# Creating csv for submission","7aef864f":"# Installing feyn\n\nThe feyn Python module is not installed on Kaggle by default so I have to pip install and import it first.\n\nNote: the pip install will fail unless you enable Internet in the settings to the left --->","cb25fa15":"# Conclusion\n\nWithout any previous experince with ML or the QLattice, in a few very simple steps I were able to:\n\n* Prepare the data that goes into the QLattice\n* Run the QLattice with the auto_run command\n* Get knowledge of which features is the most important when predicting the sale price of a house\n\nI can't wait to explore the options in the QLattice and get better using it!"}}