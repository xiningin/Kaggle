{"cell_type":{"3156df60":"code","bc6905e7":"code","6cc34e0e":"code","832880b3":"code","5b55f115":"code","fd45df0f":"code","1affbae2":"markdown"},"source":{"3156df60":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n     #   print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bc6905e7":"import os\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n\nfrom PIL import Image\nfrom pathlib import Path\nfrom matplotlib.patches import Rectangle\nfrom scipy.io import loadmat\n\n\n#define paths to use later\ndevkit_path = Path('..\/input\/stanford-cars-dataset\/car_devkit\/devkit')\ntrain_path = Path('..\/input\/stanford-cars-dataset\/cars_train\/cars_train')\ntest_path = Path('..\/input\/stanford-cars-dataset\/cars_test\/cars_test')\n\n#use loadmat to upload matlab file data\ncars_meta = loadmat('..\/input\/stanford-cars-dataset\/car_devkit\/devkit\/cars_meta.mat')\ncars_train_annos = loadmat('..\/input\/stanford-cars-dataset\/car_devkit\/devkit\/cars_train_annos.mat')\ncars_test_annos = loadmat('..\/input\/stanford-cars-dataset\/car_devkit\/devkit\/cars_test_annos.mat')\n","6cc34e0e":"\n#here I will loop through cars_meta to see how many and what types of cars there are in the image files.\ncars = []\nfor car in cars_meta['class_names'][0]:\n    cars.append(car)\n\nmodels = pd.DataFrame(cars, columns=['models']) #create new df with all the models of the cars.\nmodels","832880b3":"#this creates a new dataframe to that will incude all of the images' file path, image box dimensions, and, class.\nframe = [[i.flat[0] for i in line] for line in cars_train_annos['annotations'][0]]\ncolumns = ['bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2', 'class', 'fname']\ndf_train = pd.DataFrame(frame, columns=columns)\ndf_train['class'] = df_train['class']-1 # -1 to account for index starting on zero.\ndf_train['fname'] = [train_path\/f for f in df_train['fname']] #  Appending Path\ndf_train.head()","5b55f115":"# this will merge the model names and filenames from car_train_annos together.\ndf_train = df_train.merge(models, left_on='class', right_index=True)\ndf_train = df_train.sort_index() \ndf_train.head()","fd45df0f":"#here I attempt to save all of the images in the file to its brand folder and rename their filenames to the name of the car model.\n    \nimport zipfile\nimport os.path\n\nzf = zipfile.ZipFile('zipfile_write.zip', mode='w') #create zip file to download easier\n\n#needed to create an exception handler as it would not work without it.\ntry:\n    for i in df_train.index:  #loop through index\n        try:\n            name = df_train['models'][i] #name of each model\n            print(name)\n            file_path = df_train['fname'][i] \n            file_name = os.path.basename(df_train['fname'][i]) #file_name is the base filename, so if the path was FOLDER\/image.jpg it'll be image.jpg\n            make = name.split(\" \")[0] #save the make as everything before the first space.\n            print(make)\n            zf.write(file_path, os.path.join(make, file_name), zipfile.ZIP_DEFLATED ) #write file to zip while also placing them in make folder\n        except Exception as exc:\n            print(str(exc))\n            pass\nfinally:\n    print('closing')\n    zf.close()\n    \n    \n","1affbae2":"# Mini Project 2: Preparing Data for Image Classifier\n\nFor this Kaggle notebook, I plan to clean and prepare the data in the stanford cars dataset. Ultimately, the goal is to place each set of images into separate folders based on its model. For example, 50 images of a 2012 Audi TT in one folder. After using this to separate and classify the data, I will upload them in teachable machine to create the image classifier. \n\nNote: Used assistance from \"Stanford Cars Dataset - A Quick Look Up\" notebook by Eduardo Reis"}}