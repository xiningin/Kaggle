{"cell_type":{"355a94b5":"code","895e69ce":"code","c63ac837":"code","bfe1341e":"code","e1b6c626":"code","abdc5904":"code","4e9da676":"code","6a70d2d5":"code","7297d029":"code","71687313":"code","dec1ca02":"code","9038c05f":"code","3f531afe":"code","85d29a0f":"code","25970289":"code","a5cc2908":"code","aa4042b3":"code","140c418b":"code","7293f99e":"code","0305d730":"code","1b354a6a":"code","b6dc0ce4":"code","e96ff3b2":"code","57fc70df":"code","5fe6d06f":"code","93723265":"code","3c1f86da":"code","25df822f":"code","caa255c5":"code","808a5eb0":"code","6de10c13":"code","3a534aaa":"code","a050e842":"code","1400f020":"code","d9ee46ab":"code","eb80d4dd":"markdown","95e7ee1f":"markdown","b545a9e3":"markdown","23119d77":"markdown","5f4075fc":"markdown","bc04c840":"markdown","64c08218":"markdown","3b052ba0":"markdown","1a8aff9b":"markdown","cfd1e169":"markdown","e2057291":"markdown","115986e2":"markdown","56dce7c0":"markdown","35e00b10":"markdown","90db2e4e":"markdown","7662eaf2":"markdown","157d3063":"markdown"},"source":{"355a94b5":"import numpy as np\nimport pandas as pd\n\nimport random\nrandom.seed(28)\nnp.random.seed(28)\n\nimport matplotlib.pyplot as plt\nfrom matplotlib_venn import venn2\n\nfrom sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n                             roc_curve, recall_score, classification_report, f1_score,\n                             precision_recall_fscore_support)\nimport os\nimport copy\n\npd.options.display.precision = 15\n\nfrom collections import defaultdict\nimport lightgbm as lgb\nimport xgboost as xgb\nimport time\nfrom collections import Counter\nimport datetime\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit, RepeatedStratifiedKFold\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_absolute_error\nimport gc\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom bayes_opt import BayesianOptimization\n#import eli5\nimport shap\nfrom IPython.display import HTML\nimport json\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os\n\npd.set_option('max_rows', 500)\nimport re\n\npd.set_option('display.max_columns', 1000)\npd.set_option('display.max_rows', 500)\npd.set_option('display.width', 1000)\npd.set_option('display.float_format', '{:20,.2f}'.format)\npd.set_option('display.max_colwidth', -1)\n\nnp.random.seed(2206)","895e69ce":"train = pd.read_csv(\"..\/input\/widsdatathon2020\/training_v2.csv\")\nsamplesubmission = pd.read_csv(\"..\/input\/widsdatathon2020\/samplesubmission.csv\")\ntest = pd.read_csv(\"..\/input\/widsdatathon2020\/unlabeled.csv\")\ndictionary = pd.read_csv(\"..\/input\/widsdatathon2020\/WiDS Datathon 2020 Dictionary.csv\")\nsolution_template = pd.read_csv(\"..\/input\/widsdatathon2020\/solution_template.csv\")\n\nprint('train ' , train.shape)\nprint('test ' , test.shape)\nprint('samplesubmission ' , samplesubmission.shape)\nprint('solution_template ' , solution_template.shape)\nprint('dictionary ' , dictionary.shape)","c63ac837":"dico = pd.DataFrame(dictionary.T.head(6))\ndico.columns=list(dico.loc[dico.index == 'Variable Name'].unstack())\ndico = dico.loc[dico.index != 'Variable Name']\ndico.columns\ntrain_stat = pd.DataFrame(train.describe())\ntrain_stat2 = pd.concat([dico,train_stat],axis=0)\ntrain_stat2.head(20)","bfe1341e":"train_stat2.T.head(200)","e1b6c626":"# Missing Values\ntrain.isna().sum()","abdc5904":"# function to evaluate the score of our model\ndef eval_auc(pred,real):\n    false_positive_rate, recall, thresholds = roc_curve(real, pred)\n    roc_auc = auc(false_positive_rate, recall)\n    return roc_auc    ","4e9da676":"# a wrapper class  that we can have the same ouput whatever the model we choose\nclass Base_Model(object):\n    \n    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=5, verbose=True,ps={}):\n        self.train_df = train_df\n        self.test_df = test_df\n        self.features = features\n        self.n_splits = n_splits\n        self.categoricals = categoricals\n        self.target = 'hospital_death'\n        self.cv = self.get_cv()\n        self.verbose = verbose\n#         self.params = self.get_params()\n        self.params = self.set_params(ps)\n        self.y_pred, self.score, self.model , self.oof_pred = self.fit()\n        \n    def train_model(self, train_set, val_set):\n        raise NotImplementedError\n        \n    def get_cv(self):\n        cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n        return cv.split(self.train_df, self.train_df[self.target])\n    \n    def get_params(self):\n        raise NotImplementedError\n        \n    def convert_dataset(self, x_train, y_train, x_val, y_val):\n        raise NotImplementedError\n        \n    def convert_x(self, x):\n        return x\n        \n    def fit(self):\n        oof_pred = np.zeros((len(self.train_df), ))\n        y_pred = np.zeros((len(self.test_df), ))\n        for fold, (train_idx, val_idx) in enumerate(self.cv):\n            x_train, x_val = self.train_df[self.features].iloc[train_idx], self.train_df[self.features].iloc[val_idx]\n            y_train, y_val = self.train_df[self.target][train_idx], self.train_df[self.target][val_idx]\n            train_set, val_set = self.convert_dataset(x_train, y_train, x_val, y_val)\n            model = self.train_model(train_set, val_set)\n            conv_x_val = self.convert_x(x_val)\n            oof_pred[val_idx] = model.predict(conv_x_val).reshape(oof_pred[val_idx].shape)\n            x_test = self.convert_x(self.test_df[self.features])\n            y_pred += model.predict(x_test).reshape(y_pred.shape) \/ self.n_splits\n\n            print('Partial score of fold {} is: {}'.format(fold,eval_auc(oof_pred[val_idx],y_val) ))\n        #print(oof_pred, self.train_df[self.target].values)\n        loss_score = eval_auc(oof_pred,self.train_df[self.target].values) \n        if self.verbose:\n            print('Our oof AUC score is: ', loss_score)\n        return y_pred, loss_score, model , oof_pred","6a70d2d5":"#we choose to try a LightGbM using the Base_Model class\nclass Lgb_Model(Base_Model):\n    \n    def train_model(self, train_set, val_set):\n        verbosity = 100 if self.verbose else 0\n        return lgb.train(self.params, train_set, valid_sets=[train_set, val_set], verbose_eval=verbosity)\n        \n    def convert_dataset(self, x_train, y_train, x_val, y_val):\n        train_set = lgb.Dataset(x_train, y_train, categorical_feature=self.categoricals)\n        val_set   = lgb.Dataset(x_val,    y_val,  categorical_feature=self.categoricals)\n        return train_set, val_set\n        \n    def get_params(self):\n        params = {'n_estimators':5000,\n                  'boosting_type': 'gbdt',\n                  'objective': 'binary',\n                  'metric': 'auc',\n                  'subsample': 0.75,\n                  'subsample_freq': 1,\n                  'learning_rate': 0.1,\n                  'feature_fraction': 0.9,\n                  'max_depth': 15,\n                  'lambda_l1': 1,  \n                  'lambda_l2': 1,\n                  'early_stopping_rounds': 100,\n                  #'is_unbalance' : True ,\n                  'scale_pos_weight' : 3,\n                  'device': 'gpu',\n                  'gpu_platform_id': 0,\n                  'gpu_device_id': 0,\n                  'num_leaves': 31\n                    }\n        return params\n    def set_params(self,ps={}):\n        params = self.get_params()\n        if 'subsample_freq' in ps:\n            params['subsample_freq']=int(ps['subsample_freq'])\n            params['learning_rate']=ps['learning_rate']\n            params['feature_fraction']=ps['feature_fraction']\n            params['lambda_l1']=ps['lambda_l1']\n            params['lambda_l2']=ps['lambda_l2']\n            params['scale_pos_weight']=ps['scale_pos_weight']\n            params['max_depth']=int(ps['max_depth'])\n            params['subsample']=ps['subsample']\n            params['num_leaves']=int(ps['num_leaves'])\n            params['min_split_gain']=ps['min_split_gain']\n#             params['min_child_weight']=ps['min_child_weight']\n        \n        return params  ","7297d029":"def plot_importances(importances_, plot_name):\n    mean_gain = importances_[['gain', 'feature']].groupby('feature').mean()\n    importances_['mean_gain'] = importances_['feature'].map(mean_gain['gain'])\n    plt.figure(figsize=(18, 44))\n    data_imp = importances_.sort_values('mean_gain', ascending=False)\n    sns.barplot(x='gain', y='feature', data=data_imp[:300])\n    plt.tight_layout()\n    plt.savefig('{}.png'.format(plot_name))\n    plt.show()","71687313":"# Replace values\n\nprint('Replacing: {}'.format('hospital_admit_source'))\n\nreplace_hospital_admit_source =  {'Other ICU': 'ICU',\n                                  'ICU to SDU':'SDU', \n                                  'Step-Down Unit (SDU)': 'SDU', \n                                  'Other Hospital':'Other',\n                                  'Observation': 'Recovery Room',\n                                  'Acute Care\/Floor': 'Acute Care'}\ntrain['hospital_admit_source'].replace(replace_hospital_admit_source, inplace=True)\ntest['hospital_admit_source'].replace(replace_hospital_admit_source, inplace=True)\n\n#combined_dataset['icu_type'] = combined_dataset['icu_type'].replace({'CCU-CTICU': 'Grpd_CICU', 'CTICU':'Grpd_CICU', 'Cardiac ICU':'Grpd_CICU'})\n\nprint('Replacing: {}'.format('apache_2_bodysystem'))\n\nreplace_apache_2_bodysystem =  {'Undefined diagnoses': 'Undefined Diagnoses'}\ntrain['apache_2_bodysystem'].replace(replace_apache_2_bodysystem, inplace=True)\ntest['apache_2_bodysystem'].replace(replace_apache_2_bodysystem, inplace=True)","dec1ca02":"#we are going to drop these columns because we dont want our ML model to be bias toward these consideration\n#(we also remove the target and the ids.)\nto_drop = ['gender','ethnicity' ,'encounter_id', 'patient_id',  'hospital_death']\n\n# this is a list of features that look like to be categorical\ncategoricals_features = ['hospital_id','ethnicity','gender','hospital_admit_source','icu_admit_source',\n                         'icu_stay_type','icu_type','apache_3j_bodysystem','apache_2_bodysystem']\ncategoricals_features = [col for col in categoricals_features if col not in to_drop]\n\n# this is the list of all input feature we would like our model to use \nfeatures = [col for col in train.columns if col not in to_drop ]\nprint('numerber of features ' , len(features))\nprint('shape of train \/ test ', train.shape , test.shape)","9038c05f":"# categorical feature need to be transform to numeric for mathematical purpose.\n# different technics of categorical encoding exists here we will rely on our model API to deal with categorical\n# still we need to encode each categorical value to an id , for this purpose we use LabelEncoder\n\nprint('Transform all String features to category.\\n')\nfor usecol in categoricals_features:\n    train[usecol] = train[usecol].astype('str')\n    test[usecol] = test[usecol].astype('str')\n    \n    #Fit LabelEncoder\n    le = LabelEncoder().fit(\n            np.unique(train[usecol].unique().tolist()+\n                      test[usecol].unique().tolist()))\n\n    #At the end 0 will be used for dropped values\n    train[usecol] = le.transform(train[usecol])+1\n    test[usecol]  = le.transform(test[usecol])+1\n    \n    train[usecol] = train[usecol].replace(np.nan, 0).astype('int').astype('category')\n    test[usecol]  = test[usecol].replace(np.nan, 0).astype('int').astype('category')","3f531afe":"def adversarial_validation(train, test, features):\n    tr_data   = train.copy()\n    tst_data = test.copy()\n    tr_data['target']  = 0 \n    tst_data['target'] = 1\n    av_data = pd.concat([tr_data, tst_data], axis = 0)\n    av_data.reset_index(drop = True)        \n    params = {\n            'learning_rate': 0.1, \n            'seed': 50,\n            'objective':'binary',\n            'boosting_type':'gbdt',\n            'metric': 'auc',\n        }    \n    # define a KFold strategy\n    kf = StratifiedKFold(n_splits = 5, shuffle=True, random_state=42)\n    target = 'target'\n    oof_pred = np.zeros(len(av_data))\n    important_features = pd.DataFrame()\n    fold_auc = []    \n    \n    for fold, (tr_ind, val_ind) in enumerate(kf.split(av_data, av_data[target])) :\n        print('Fold {}'.format(fold + 1))\n        x_train, x_val = av_data[features].iloc[tr_ind], av_data[features].iloc[val_ind]\n        y_train, y_val = av_data[target].iloc[tr_ind], av_data[target].iloc[val_ind]\n        train_set = lgb.Dataset(x_train, y_train)\n        val_set   = lgb.Dataset(x_val, y_val)\n        \n        model = lgb.train(params, train_set, num_boost_round = 1000, early_stopping_rounds = 20, valid_sets = [train_set, val_set], verbose_eval = 100)\n        \n        fold_importance = pd.DataFrame()\n        fold_importance['feature'] = features\n        fold_importance['gain'] = model.feature_importance()\n        important_features = pd.concat([important_features, fold_importance], axis = 0)\n        \n        oof_pred[val_ind] = model.predict(x_val)\n        fold_auc.append(metrics.roc_auc_score(y_train, model.predict(x_train)))\n        \n    print('Our mean train roc auc score is :', np.mean(fold_auc))\n    print('Our oof roc auc score is :', metrics.roc_auc_score(av_data[target], oof_pred))\n    return important_features","85d29a0f":"# run the adversatial model with all the feature we used :\n    \nadversarial_features = adversarial_validation(train, test, features)","25970289":"# AUC is almost perfect so we can expect that some feature are perfectly different between train \/ test\n\nadversarial_features = adversarial_features[['gain', 'feature']].groupby('feature').mean().reset_index()\nadversarial_features= adversarial_features.sort_values('gain', ascending=False)\n\nplot_importances(adversarial_features, 'importances-lgb-v6')","a5cc2908":"# So icu_id columns seems to be the feature that dominate the feature importance for the adversarial \n# validation model, so it is likely to be totally different between train and test, \n# lets check the distribution of the top features :\n\ndef plot_differente_between_train_test(adversarial_features):\n    import warnings\n    warnings.filterwarnings(\"ignore\")\n    warnings.simplefilter(action='ignore', category=UserWarning)\n    i=0\n    for index, row in adversarial_features.sort_values(by=['gain'],ascending=False).iterrows():  \n        column=row['feature']\n        if i< 10:\n                print(column,i,\"gain :\",row['gain'])\n                df1      = train.copy()\n                df2      = test.copy()\n\n                fig = plt.figure(figsize=(20,4))\n                sns.distplot(df1[column].dropna(),  color='yellow', label='train', kde=True); \n                sns.distplot(df2[column].dropna(),  color='violet', label='test', kde=True); \n                fig=plt.legend(loc='best')\n                plt.xlabel(column, fontsize=12);\n                plt.show()\n                i=i+1\n\nplot_differente_between_train_test(adversarial_features)","aa4042b3":"# it is .... Let's remove icu_id and see the results ..\nadversarial_features2 = adversarial_validation(train, test, [ f for f in features if f not in ['icu_id'] ])","140c418b":"# Let`s check again the difference between train \/ test\n\nadversarial_features2 = adversarial_features2[['gain', 'feature']].groupby('feature').mean().reset_index()\nadversarial_features2= adversarial_features2.sort_values('gain', ascending=False)\n\nplot_importances(adversarial_features2, 'importances-lgb-v6')","7293f99e":"plot_differente_between_train_test(adversarial_features2)","0305d730":"# hospital_id seems to be also from a different distribution. \n# We can check it directly, obviously only few hospital are common to both dataset ..\n\ncommon_id  = list([id for id in train['hospital_id'].unique() if id in test['hospital_id'].unique() ])\nid_only_in_train  = [id for id in train['hospital_id'].unique() if id not in test['hospital_id'].unique() ]\nid_only_in_test   = [id for id in test['hospital_id'].unique()  if id not in train['hospital_id'].unique() ]\ncount_common_train = train.loc[train['hospital_id'].isin(common_id)].shape[0]\ncount_common_test  = test.loc[test['hospital_id'].isin(common_id)].shape[0]\n\ncount_train = train.loc[train['hospital_id'].isin(id_only_in_train)].shape[0]\ncount_test  = test.loc[test['hospital_id'].isin(id_only_in_test)].shape[0]\n\n \nfig = plt.figure(figsize=(20,6))\nvenn2(subsets = (count_train,  count_test, count_common_train+count_common_test), set_labels = ('Hospital only in train', 'Hospital only in test'),set_colors=('purple', 'yellow'), alpha = 0.7);\nplt.show()","1b354a6a":"# Let's do an ultimate try without 'icu_id','hospitaadversarial_features3 = adversarial_validation(train, test, [ f for f in features if f not in ['icu_id','hospital_id'] ])l_id'\nadversarial_features3 = adversarial_validation(train, test, [ f for f in features if f not in ['icu_id','hospital_id'] ])","b6dc0ce4":"# I leave it to you to see what you can do with other features..\nadversarial_features3 = adversarial_features3[['gain', 'feature']].groupby('feature').mean().reset_index()\nadversarial_features3= adversarial_features3.sort_values('gain', ascending=False)\n\nplot_importances(adversarial_features3, 'importances-lgb-v6')","e96ff3b2":"plot_differente_between_train_test(adversarial_features3)","57fc70df":"# Lets remove hospital_id and icu_id\n\nprint('Difference between train and teste> -- hospital_id: ')\nprint(len(list(set(train['hospital_id']) - set(test['hospital_id']))))\n\nprint('\\nDifference between train and teste> -- icu_id: ')\nprint(len(list(set(train['icu_id']) - set(test['icu_id']))))\n\n\n# Drop features with zero importance\nprint('\\nLength train features: {}'.format(len(features)))\nfor feat_to_remove in ['icu_id', 'hospital_id']:\n    if feat_to_remove in categoricals_features:\n        print('Removing from categoricals_features....{}'.format(feat_to_remove))\n        categoricals_features.remove(feat_to_remove)\n    if feat_to_remove in features:\n        print('Removing from features....{}'.format(feat_to_remove))\n        features.remove(feat_to_remove)\n    \nprint('\\nNew length train features: {}'.format(len(features)))","5fe6d06f":"# percentage of death , hopefully it s a bit unbalanced\ntrain['hospital_death'].sum()\/train['hospital_death'].count()","93723265":"# You want Bayesian Optimization?\n\nboll_BayesianOptimization = False\n# boll_BayesianOptimization = True","3c1f86da":"%time\n\ndef LGB_Beyes(subsample_freq,\n                    learning_rate,\n                    feature_fraction,\n                    max_depth,\n                    lambda_l1,\n                    lambda_l2,\n                    scale_pos_weight,\n                    subsample,\n                    num_leaves,\n                    min_split_gain):\n#                     min_child_weight):\n    params={}\n    params['subsample_freq']=subsample_freq\n    params['learning_rate']=learning_rate\n    params['feature_fraction']=feature_fraction\n    params['lambda_l1']=lambda_l1\n    params['lambda_l2']=lambda_l2\n    params['max_depth']=max_depth\n    params['scale_pos_weight']=scale_pos_weight\n    params['subsample']=subsample\n    params['num_leaves']=num_leaves\n    params['min_split_gain']=min_split_gain\n   # params['min_child_weight']=min_child_weight\n    \n    \n    lgb_model= Lgb_Model(train, test, features, categoricals=categoricals_features,ps=params)\n    print('auc: ',lgb_model.score)\n    return lgb_model.score\n\nbounds_LGB = {\n    'max_depth': (5, 17),\n    'subsample': (0.5, 1),\n    'num_leaves': (10, 45),\n    'feature_fraction': (0.1, 1),\n    'min_split_gain': (0.0, 0.1),\n#     'min_child_weight': (1e-3, 50),\n    'subsample_freq': (1, 10),\n    'learning_rate': (0.005, 0.02),\n    'lambda_l1': (0, 5),\n    'lambda_l2': (0, 5),\n    'scale_pos_weight': (1, 10)\n}\n\n# ACTIVATE it if you want to search for better parameter\nif boll_BayesianOptimization: \n    LGB_BO = BayesianOptimization(LGB_Beyes, bounds_LGB, random_state=1029)\n    import warnings\n    init_points = 16\n    n_iter = 16\n    with warnings.catch_warnings():\n        warnings.filterwarnings('ignore')    \n        LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)","25df822f":"if boll_BayesianOptimization and LGB_BO:\n    print(LGB_BO.max['params'])","caa255c5":"# params = {'feature_fraction': 0.9,\n#  'lambda_l1': 1,\n#  'lambda_l2': 1,\n#  'learning_rate': 0.1,\n#  'max_depth': 13,\n#  'subsample_freq': 1,\n#  'scale_pos_weight':1}\n\n# Best Hyperparams from Bayesian Optimization in notebook lgb-v2\n# params = {'feature_fraction': 0.524207414205945,\n#  'lambda_l1': 4.171808735757517,\n#  'lambda_l2': 4.6435328298317256,\n#  'learning_rate': 0.007897539397989824,\n#  'max_depth': 16.62053004755999,\n#  'scale_pos_weight': 1.2199266532301127,\n#  'subsample_freq': 1.0276518730971627}\n\n\n# # Best Hyperparams from Bayesian Optimization in notebook lgb-v3\n# params = {'feature_fraction': 0.524207414205945,\n#  'lambda_l1': 4.171808735757517,\n#  'lambda_l2': 4.6435328298317256,\n#  'learning_rate': 0.007897539397989824,\n#  'max_depth': 16.62053004755999,\n#  'scale_pos_weight': 1.2199266532301127,\n#  'subsample_freq': 1.0276518730971627}\n\n# # Best Hyperparams from Bayesian Optimization in notebook lgb-v4\n# params = {'feature_fraction': 0.5348508368206359,\n#  'lambda_l1': 0.0009370993396629057,\n#  'lambda_l2': 4.743745312344983,\n#  'learning_rate': 0.012891827059322746,\n#  'max_depth': 15.784155449197529,\n#  'scale_pos_weight': 1.0325760631926175,\n#  'subsample_freq': 1.0744384574974872}\n\n\n# Best Hyperparams from Bayesian Optimization in notebook lgb-v5\n# params = {'feature_fraction': 0.3245039721724266,\n#  'lambda_l1': 1.416727346446085,\n#  'lambda_l2': 2.779776916582821,\n#  'learning_rate': 0.006854369969433722,\n#  'max_depth': 16.673905691676964,\n#  'min_split_gain': 0.05643417986130283,\n#  'num_leaves': 44.8672896759208,\n#  'scale_pos_weight': 1.1577974342088542,\n#  'subsample': 0.630352165410007,\n#  'subsample_freq': 1.2158674819047501}\n\n# Best Hyperparams from Bayesian Optimization in notebook lgb-v6 -- BEST MODEL\nparams = {\n   \"feature_fraction\":0.1743912077888097,\n   \"lambda_l1\":2.838660318794291,\n   \"lambda_l2\":0.292397357257721,\n   \"learning_rate\":0.012602188092427687,\n   \"max_depth\":16.575351761228106,\n   \"min_split_gain\":0.04631934372471113,\n   \"num_leaves\":44.81666226482246,\n   \"scale_pos_weight\":1.0897617979884857,\n   \"subsample\":0.8260779721854892,\n   \"subsample_freq\":1.2473380372944387\n}","808a5eb0":"%time\n\nif boll_BayesianOptimization: # ACTIVATE it if you want to search\/use for better parameter\n    lgb_model = Lgb_Model(train,test, features, categoricals=categoricals_features, ps= LGB_BO.max['params'])\nelse :\n    lgb_model = Lgb_Model(train,test, features, categoricals=categoricals_features, ps=params)","6de10c13":"imp_df = pd.DataFrame()\nimp_df['feature'] = features\nimp_df['gain']  = lgb_model.model.feature_importance(importance_type='gain')\nimp_df['split'] = lgb_model.model.feature_importance(importance_type='split')","3a534aaa":"plot_importances(imp_df, 'importances-lgb-v6-lgb_model')","a050e842":"import shap\nexplainer   =  shap.TreeExplainer(lgb_model.model)\nshap_values = explainer.shap_values(train[features].iloc[:1000,:])\nshap.summary_plot(shap_values, train[features].iloc[:1000,:])","1400f020":"print('AUC Version 1: ', lgb_model.score)\n#print('AUC:Version 2: ', lgb_model_v2.score)","d9ee46ab":"test[\"hospital_death\"] = lgb_model.y_pred\n#test[[\"encounter_id\",\"hospital_death\"]].to_csv(\"submission6-lgb-v6.csv\",index=False)\n\ntest[[\"encounter_id\",\"hospital_death\"]].head()","eb80d4dd":"# Read the data","95e7ee1f":"## Functions","b545a9e3":"My Best model for this competition\n\nThank you for ALL the others notebooks and discussion.","23119d77":"# Hyper parameter tuning","5f4075fc":"## Adversarial Validation\n\nThe main idea of adversarial validation is to detect shift\/drift in the different features between 2 datasets.\n\nWe usually train a model on past data to forecast future data so it can happened that these futures datas have a distribution that is no longer in line with the data we used for training, or maybe we train on some hospital datas and apply our model on other hospital ?\n\nYou can detect drift by statistical test (like t-test) but here we will do it by training a machine learning model and check if the model can figure out if the data is from the train or test set. If it can, this means that the test data comes from another distribution compare to the train data and then you have to check the distribution of the most important features that are likely to be different between train and test.","bc04c840":"## Pre Processing","64c08218":"# Feature Importance by permutation importance algo","3b052ba0":"# Some univariate plot of the best feature","1a8aff9b":"## Submissing File","cfd1e169":"import warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action='ignore', category=UserWarning)\ni=0\nfor index, row in imp_df.sort_values(by=['gain'],ascending=False).iterrows():  \n    column=row['feature']\n    if i< 50:\n            print(column,i,\"gain :\",row['gain'])\n            df1      = train.loc[train['hospital_death']==0]\n            df2      = train.loc[train['hospital_death']==1]\n\n            fig = plt.figure(figsize=(20,4))\n            sns.distplot(df1[column].dropna(),  color='red', label='hospital_death 0', kde=True); \n            sns.distplot(df2[column].dropna(),  color='blue', label='hospital_death 1', kde=True); \n            fig=plt.legend(loc='best')\n            plt.xlabel(column, fontsize=12);\n            plt.show()\n            i=i+1\n","e2057291":"# OverView of the dataset","115986e2":"# Drop the values above a certain threshold\n# If the information contained in the variable is not that high, you can drop the variable \n# if it has more than 50% missing values. In this method we are dropping columns with null values above a \n# certain threshold\n\n# threshold = len(train) * 0.60\nthreshold = len(train) * 0.50\n\ndf_train_thresh = train.dropna(axis=1, thresh=threshold)\n\n# View columns in the dataset\ndisplay(df_train_thresh.shape)\n\nprint('Columns that were removed:')\nremove_with_threshold = list(set(train.columns) - set(df_train_thresh.columns))\ndisplay(remove_with_threshold)\n\n# this is the NEW list of all input feature we would like our model to use \nfeatures = [col for col in features if col not in remove_with_threshold]\n\nprint(len(features))\n\ndel df_train_thresh, remove_with_threshold","56dce7c0":"## EDA","35e00b10":"# Drop all missing Values\n# obs: \n# we delete a particular row if it has a null value for a particular feature. \n# This method is used only when there are enough samples in the data set. \n# It has to be ensured that there is no bias after data deletion. \n# Removing the data will lead to loss of information which will not give the expected results while predicting\n# the output.\n\nprint('Train Dataset: ')\nprint(\"Orginal shape before dropna()\" ,train.shape)\ntrain = train.dropna()\nprint(\"Shape after dropna()\" ,train.shape)\n\nprint('\\n\\n')\nprint('Test Dataset: ')\nprint(\"Orginal shape before dropna()\" ,test.shape)\ntest = test.dropna()\nprint(\"Shape after dropna()\" ,test.shape)","90db2e4e":"Feature Importance from the lightgbm model (gain)","7662eaf2":"categorical feature need to be transform to numeric for mathematical purpose.\ndifferent technics of categorical encoding exists here we will rely on our model API to deal with categorical\nstill we need to encode each categorical value to an id , for this purpose we use LabelEncoder\n","157d3063":"# Model"}}