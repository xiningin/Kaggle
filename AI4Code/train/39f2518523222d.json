{"cell_type":{"dd3a8dc1":"code","536a33cf":"code","ada968c7":"code","7798bc66":"code","2788d303":"code","c002b759":"code","6f593b07":"code","01b0f126":"code","b0105b75":"code","9d311b28":"code","5836f011":"code","6007fe52":"code","8aa63204":"code","207167f8":"markdown","76a5685f":"markdown","4df3dd15":"markdown","65cdac41":"markdown","9373ac93":"markdown","fba49e60":"markdown","1c3b6069":"markdown","568e2d21":"markdown","b9ebf428":"markdown","0d019d28":"markdown","53664fc5":"markdown"},"source":{"dd3a8dc1":"!pip -q install bs4","536a33cf":"import re\nimport spacy\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom bs4 import BeautifulSoup\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom textblob import TextBlob\nfrom textblob.sentiments import NaiveBayesAnalyzer\nfrom spacy.lang.en.stop_words import STOP_WORDS as stopwords\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('ggplot')","ada968c7":"#converting into standard datetime format\ndataset = pd.read_csv('..\/input\/indianeedsoxygen-tweets\/IndiaWantsOxygen.csv', engine='python')\nfrom dateutil import parser\ndataset['Date'] = pd.to_datetime(dataset['date']).dt.date\ndataset['Date'] = dataset['Date'].apply(lambda x : parser.parse(str(x)))\ndataset['Date'] = pd.to_datetime(dataset['Date']).dt.date\ndataset['Time'] = pd.to_datetime(dataset['date']).dt.time\ndataset['Time'] = dataset['Time'].apply(lambda x : parser.parse(str(x)))\ndataset.drop(['date'], axis=1, inplace=True)\ndataset.head(5)","7798bc66":"plt.rcParams['figure.figsize'] = [10,6]\nplt.rcParams['figure.dpi'] = 90\n\nsns.set(style='darkgrid')\ndates = [date for date in dataset['Date']]\nsns.countplot(x = dates, order=sorted(set(dates)), palette=\"Set2\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Number of Tweets\")\nplt.title('Number of Tweets Each Day')\nplt.xticks(rotation=50) \nplt.show()","2788d303":"data = dataset['Date'].groupby([dataset.Date]).agg('count')\ndata = data.to_frame(name='Number of Tweets Each Day')\nsns.lineplot(data=data, x=data.index, y=\"Number of Tweets Each Day\", color='red', linewidth=1.5)\nplt.title('Frequency of Tweets Each Day')\nplt.show()","c002b759":"sns.countplot(x='user_location', data=dataset, order=dataset['user_location'].value_counts().index[:13])\nplt.ylabel(\"Number of Tweets\")\nplt.xlabel(\"User Location\")\nplt.xticks(rotation=50, horizontalalignment='right', x=1.0) \nplt.title('Top Thirteen Locations With Max Number Of Tweets')\nplt.show()","6f593b07":"sns.catplot(data = dataset, kind = \"bar\", x = dataset.hashtags.value_counts().head().index, y = dataset.hashtags.value_counts().head().values)\nplt.ylabel(\"Number of Tweets\")\nplt.xlabel(\"Popular Hastags\")\nplt.xticks(rotation=50, horizontalalignment='right', x=1.0)\nplt.title('Popular HashTags')\nplt.show()","01b0f126":"platform = dataset['source'].value_counts()[:3].to_dict()\nplatform['Others'] = 0\ndict_ = dataset['source'].value_counts().to_dict()\nfor key in dict_.keys():\n    if key not in platform.keys():\n        platform['Others'] += dict_[key]\n\nplt.pie(x=platform.values(), labels=platform.keys(), autopct='%1.2f%%', shadow=False, startangle=0)\nplt.legend(bbox_to_anchor=(.9,.9))\nplt.title('Top Plotform Used To Make Tweet', x=0.5, y=0.95)\nplt.show()","b0105b75":"!pip -q install contractions\nimport contractions\nimport unicodedata","9d311b28":"def remove_accented(x):\n  x = unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n  return x","5836f011":"def get_clean(X):\n    X = str(X).lower().replace('\\\\', ' ').replace('_', ' ').replace('.', ' ').replace(':', '')\n    X = X.replace('#', \"\")\n    X = re.sub(r'(http|https|ftp|ssh):\/\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\/~+#-]*[\\w@?^=%&\/~+#-])?',\"\",  X)\n    X = re.sub(r'(http|https|ftp|ssh):\/\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\/~+#-]*[\\w@?^=%&\/~+#-])?',\"\",  X)\n    X = re.sub(r'[^\\w\\d\\s]+','', X)\n    X = ' '.join(X.split())\n    X = BeautifulSoup(X, 'lxml').get_text().strip()\n    X = remove_accented(X)\n    X = re.sub(r'[^\\w ]+','',X)\n    X = re.sub(\"(.)\\\\1{2,}\", \"\\\\1\", X)\n    X = contractions.fix(X)\n    #X = ' '.join([word for word  in X.split() if word not in  stopwords])\n    return X","6007fe52":"dataset['text'] = dataset['text'].apply(lambda x: get_clean(x)) ","8aa63204":"word_cloud = WordCloud(width=700, height=600, max_font_size=180).generate(str(dataset['text']))\nplt.imshow(word_cloud)\nplt.title('Word Cloud Representation')\nplt.axis('off')\nplt.show()","207167f8":"## Popular HashTags","76a5685f":"## Libraries Import","4df3dd15":"## Number of Tweets Each Day","65cdac41":"## Top Plotform Used To Make Tweet","9373ac93":"![](https:\/\/pbs.twimg.com\/media\/Ezx0LvZUcAQ6nuH.jpg)","fba49e60":"## Text Cleaning","1c3b6069":"## Word Cloud Representation","568e2d21":"## Reading The Data & Preparing It","b9ebf428":"## Installing Necessary Packages","0d019d28":"## Frequency of Tweets Each Day","53664fc5":"## Top Thirteen Locations With Max Number Of Tweets"}}