{"cell_type":{"22941169":"code","e6d3477b":"code","9321d12e":"code","66a0c875":"code","71060846":"code","9a21f45f":"code","8419828a":"code","aa84973f":"code","264b60cc":"code","aceba3a9":"code","006c63da":"code","d06adc17":"code","3832dafe":"code","b0ca6527":"code","de88af77":"code","381fc3db":"code","97122633":"code","696aa60a":"code","08d4c892":"code","09e8664e":"code","adbb4bc0":"code","154ec2d8":"code","248ed85e":"code","aeb3e03f":"code","73531b0e":"markdown"},"source":{"22941169":"# RIO Tinto --> one of the largest mining corporations in the world","e6d3477b":"# library imports\n#import os\n#import shutil\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n#from tensorflow import random\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nimport tensorflow as tf\ntf.__version__","9321d12e":"data = pd.read_csv(\"..\/input\/random-stock-from-yahoo-finance\/RIO.csv\", index_col= 0, parse_dates= True)","66a0c875":"data.shape","71060846":"data.head()","9a21f45f":"data.tail()","8419828a":"training = data[[\"Adj Close\"]].values","aa84973f":"\"\"\"\nscaling the data --> \n\n\"\"\"\nscaler = MinMaxScaler(feature_range = (0, 1))\n","264b60cc":"training_scaled= scaler.fit_transform(training)\n","aceba3a9":"testing_scaled = training_scaled[-400-60:]","006c63da":"training_scaled = training_scaled[-1600:-400]","d06adc17":"print(len(testing_scaled), len(training_scaled))","3832dafe":"def prepare_train_test(training_scaled, testing_scaled):\n    x_train = []\n    y_train = []\n    for i in range(60, len(training_scaled)):\n        x_train.append(training_scaled[i-60:i, 0])\n        y_train.append(training_scaled[i, 0])\n    \n    x_test= []\n    y_test = []\n    \n    for i in range(60, len(testing_scaled)):\n        x_test.append(testing_scaled[i-60:i, 0])\n        y_test.append(testing_scaled[i, 0])\n    \n    x_train, y_train, x_test, y_test = np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)\n    \n    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n    return x_train, y_train, x_test, y_test","b0ca6527":"X_train, y_train, X_test, y_test= prepare_train_test(training_scaled, testing_scaled)","de88af77":"print(X_test.shape, y_test.shape, X_train.shape, y_train.shape)","381fc3db":"def get_model():\n    \n    model= Sequential()\n    model.add(LSTM(units = 200, return_sequences  = True, input_shape = (X_train.shape[1], 1)))\n    model.add(LSTM(units = 200, return_sequences = True))\n    \n    model.add(LSTM(units = 100, return_sequences = True))\n    model.add(LSTM(units = 100))\n    model.add(Dense(units = 1))\n    \n    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n    return model","97122633":"model = get_model()","696aa60a":"model.summary()","08d4c892":"history = model.fit(X_train, y_train, epochs = 100, batch_size = 60)\n","09e8664e":"#!pip install tensorflow-gpu","adbb4bc0":"def training_loss_graph(history):\n    plt.plot(history.history['loss'], label = 'Training  Loss')\n    plt.legend()\n    plt.xlabel(\"Epochs\")\n    plt.ylabel('Loss')\n    plt.show()\ntraining_loss_graph(history)","154ec2d8":"def get_predicted_INV_scaled(X_test):\n    predicted_prices = model.predict(X_test)\n    predicted_prices = scaler.inverse_transform(predicted_prices)\n    \n    \n    prices = scaler.inverse_transform([y_test])\n    return prices, predicted_prices\nprices, predicted_prices = get_predicted_INV_scaled(X_test)","248ed85e":"def show_graph_result(prices, predicted_prices):\n    index = data.index.values[-len(prices[0]):]\n    test_result = pd.DataFrame(columns = ['real', 'predicted'])\n    test_result['real'] = prices[0]\n    test_result['predicted'] = predicted_prices\n    test_result.index = index\n    \n    test_result.plot(figsize = (16, 10))\n    plt.title(\"Actual and Predicted\")\n    plt.ylabel(\"Price\")\n    plt.xlabel(\"Date\")\n    plt.show()\nshow_graph_result(prices, predicted_prices)","aeb3e03f":"# next \n# methods for you to build what if your data for the future --> \n# ","73531b0e":"markdown"}}