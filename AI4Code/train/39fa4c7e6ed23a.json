{"cell_type":{"0fe93cb8":"code","eb6ccf61":"code","360f61dd":"code","7907fc45":"code","3a91fea4":"code","51b22ed2":"code","378a6fa9":"code","cfd74683":"code","8ff5b454":"code","c81c7824":"code","167d8033":"code","c2822d44":"code","4c4f279d":"code","bf1fb404":"code","74bccc8a":"code","29ed354d":"code","5e7b7659":"code","4cd6b76e":"code","a90879ab":"code","c559dab5":"code","336f3b62":"code","1b5f9528":"code","af89cd10":"code","19cfb0c7":"code","8d7818c5":"code","c993c0f7":"code","6191c49a":"code","cbfa89c0":"code","256ede14":"code","d6d3892b":"code","a3858a33":"code","8ec6d8c1":"code","7b55ae9f":"code","febfdc64":"code","94fa2319":"code","e107b609":"code","e6237b38":"code","42a8b3aa":"code","f138aebe":"code","9306cffb":"code","056dcc9a":"code","67d695ff":"code","1176eba6":"code","285e1e84":"code","93ab0cbb":"code","4577aecb":"code","40b1729d":"code","01c6b2a1":"code","165c5051":"code","0ef4fa52":"code","c1b3aeea":"code","5094bad9":"code","fdcb2a69":"code","34ff5fb9":"code","41f6eab9":"code","25961c2b":"code","3f6e0e64":"code","3be5d8b0":"code","1de029c0":"code","c0e1ecfe":"code","1b9e232b":"code","9962c56a":"code","7b2e0732":"code","a667bf0b":"code","45f23f10":"code","84ea38d3":"code","b363f4e5":"markdown","8103d136":"markdown","fa86eb48":"markdown","24182923":"markdown","9b47f4bd":"markdown","9036686f":"markdown","0d16e54d":"markdown","a7398a67":"markdown","dd8375fb":"markdown","c1a962e0":"markdown","fa290adb":"markdown","d4d4e8a6":"markdown","42d9aa03":"markdown","6a5c86d2":"markdown","50e4b3cb":"markdown","5241cc1a":"markdown","09526a6e":"markdown","7939a1eb":"markdown","eb893355":"markdown","abaeb97e":"markdown","7f42cec0":"markdown","013789e7":"markdown","31bd7f6b":"markdown","2d9fab23":"markdown","e9a37922":"markdown","8702fa30":"markdown","08d2d8e7":"markdown","ce505e5e":"markdown","16cbc58c":"markdown","fe069d09":"markdown","0c681998":"markdown","610516e0":"markdown","a4f1ce93":"markdown","9231e638":"markdown"},"source":{"0fe93cb8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","eb6ccf61":"df_train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndf_test= pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","360f61dd":"df_train.head()","7907fc45":"print(\"Train shape :\",df_train.shape)\nprint(\"Test shape:\", df_test.shape)","3a91fea4":"df_train.describe(include=\"all\")","51b22ed2":"df_train.columns","378a6fa9":"col = [\"PassengerId\",\"Name\",\"Ticket\"]\ndf_train = df_train.drop(col,axis=1)\ndf_test = df_test.drop(col,axis=1)","cfd74683":"df_train.head()","8ff5b454":"df_test.head()","c81c7824":"df_train.isnull().sum().sort_values(ascending=False)","167d8033":"df_train.isnull().sum().sort_values(ascending=False)","c2822d44":"df_train[\"Cabin\"].unique()","4c4f279d":"df_train[\"Cabin\"].fillna(\"No cabin\",inplace=True)\ndf_test[\"Cabin\"].fillna(\"No cabin\",inplace=True)","bf1fb404":"df_train['Cabin'].unique()","74bccc8a":"for i in range(0,len(df_train)):\n    df_train['Cabin'][i] = df_train['Cabin'][i][:1]\nfor i in range(0,len(df_test)):\n    df_test['Cabin'][i] = df_train['Cabin'][i][:1]","29ed354d":"df_train['Cabin'].unique()","5e7b7659":"df_test[\"Cabin\"].unique()","4cd6b76e":"df_train.isnull().sum().sort_values(ascending=False)","a90879ab":"df_test.isnull().sum().sort_values(ascending=False)","c559dab5":"df_train.head()","336f3b62":"df_train[\"Age\"].fillna(df_train[\"Age\"].mean(),inplace=True)\ndf_test[\"Age\"].fillna(df_test[\"Age\"].mean(),inplace=True)","1b5f9528":"df_train.isnull().sum().sort_values(ascending=False)","af89cd10":"df_test.isnull().sum().sort_values(ascending=False)","19cfb0c7":"df_train[\"Embarked\"].fillna(df_train[\"Embarked\"].mode()[0],inplace=True)\ndf_test[\"Fare\"].fillna(df_train[\"Fare\"].mean(),inplace=True)","8d7818c5":"df_train.isnull().sum().sort_values(ascending=False)","c993c0f7":"df_test.isnull().sum().sort_values(ascending=False)","6191c49a":"gender = {\"male\":0,\"female\":1}\ngender","cbfa89c0":"df_train[\"Sex\"]=df_train[\"Sex\"].map(gender)\ndf_test[\"Sex\"]= df_test[\"Sex\"].map(gender)","256ede14":"df_train.head()","d6d3892b":"df_train.Cabin.unique()","a3858a33":"cab = {'N':0, 'C':1, 'E':2, 'G':3, 'D':4, 'A':5, 'B':6, 'F':7, 'T':8}\ncab","8ec6d8c1":"df_train[\"Cabin\"] = df_train[\"Cabin\"].map(cab)\ndf_test[\"Cabin\"] = df_test[\"Cabin\"].map(cab)","7b55ae9f":"df_train.head()","febfdc64":"df_train[\"Embarked\"].unique()","94fa2319":"emb = {'S':0, 'C':1, 'Q':2}\nemb","e107b609":"df_train[\"Embarked\"] = df_train[\"Embarked\"].map(emb)\ndf_test[\"Embarked\"] = df_test[\"Embarked\"].map(emb)","e6237b38":"df_train.head()","42a8b3aa":"df_test.head()","f138aebe":"df_train.info()","9306cffb":"df_test.info()","056dcc9a":"import matplotlib.pyplot as plt","67d695ff":"for i in df_train.columns:\n        plt.hist(df_train[i],bins=10,color='green')\n        plt.xlabel(i)\n        plt.ylabel(\"count\")\n        plt.title(i)\n        plt.show()","1176eba6":"x=df_train.drop([\"Survived\"],1)\ny = df_train[\"Survived\"]","285e1e84":"x","93ab0cbb":"y","4577aecb":"from sklearn import preprocessing\nscaler = preprocessing.StandardScaler()\nstandard_df = scaler.fit_transform(x)\nX = pd.DataFrame(standard_df,columns=x.columns)\nX","40b1729d":"X.describe()","01c6b2a1":"standard_df = scaler.fit_transform(x)\ntest = pd.DataFrame(standard_df,columns=df_test.columns)\ntest","165c5051":"test","0ef4fa52":"from sklearn.model_selection import train_test_split","c1b3aeea":"x_train,x_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)","5094bad9":"print(\"Training data:\",x_train.shape)\nprint(\"Testing data:\",x_test.shape)","fdcb2a69":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score","34ff5fb9":"lr = LogisticRegression()\nlr","41f6eab9":"# Model Training\nlr.fit(x_train, y_train)","25961c2b":"# Hyper parameter tuning\nfrom sklearn.model_selection import GridSearchCV\nparam = {\n         'penalty':['l1','l2'],\n         'C':[0.001, 0.01, 0.1, 1, 10, 20,100, 1000]\n}\nLr= LogisticRegression(penalty='l1')\ncv=GridSearchCV(lr,param,cv=5,n_jobs=-1)\ncv.fit(x_train,y_train)\ny_pred=cv.predict(x_test)","3f6e0e64":"cv.best_score_","3be5d8b0":"print(\"Accuracy score:\",accuracy_score(y_test,y_pred))","1de029c0":"from xgboost import XGBClassifier\n\nxgb = XGBClassifier(booster = 'gbtree', gamma=5,learning_rate = 0.1, max_depth = 5, n_estimators = 100,colsample_bytree=1)\nxgb.fit(x_train, y_train)","c0e1ecfe":"y_pred = xgb.predict(x_test)\nprint(\"Accuracy on test data:\",accuracy_score(y_test,y_pred))\nprint(\"Accuracy on train data:\",accuracy_score(y_train,xgb.predict(x_train)))","1b9e232b":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbc = GradientBoostingClassifier(max_depth=3)\ngbc.fit(x_train, y_train)","9962c56a":"print(\"Accuracy on test data:\",accuracy_score(y_test,gbc.predict(x_test)))\nprint(\"Accuracy on train data:\", accuracy_score(y_train,gbc.predict(x_train)))","7b2e0732":"fin = gbc.predict(test)","a667bf0b":"fin","45f23f10":"predictions = pd.DataFrame(fin)","84ea38d3":"predcsv = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")\npredcsv[\"Survived\"] = predictions\npredcsv.to_csv(\"Final prediction.csv\",index=False)","b363f4e5":"## Splitting Train and Test data","8103d136":"### Now, we have changed all the Categorical values into Numerical values","fa86eb48":"We create a dictionary for the corresponding Categorical features with its Numerical values","24182923":"We have missing values in \"Age\" columns. so, we replace the values with the mean of the respective data","9b47f4bd":"### Sex","9036686f":"We create a dictionary for the corresponding Categorical features with its Numerical values\n\n#### 0 for Male\n\n\n#### 1 for Female","0d16e54d":"We create a dictionary for the corresponding Categorical features with its Numerical values","a7398a67":"## Model Training","dd8375fb":"These are the updated values in \"Cabin\" and 'N' represents \"No cabin\"","c1a962e0":"We can see that It starts with an Alphabet, so we can use it for training","fa290adb":"The data does not have any missing values now ","d4d4e8a6":"## Applying Standard Scaling","42d9aa03":"## Checking for missing values in train and test data","6a5c86d2":"## Cabin","50e4b3cb":"We have eight cabin, so we want to map with 8 values","5241cc1a":"Filling the missing values in \"Age\" columns using the mean value","09526a6e":"We have three values in Embarked, so we want to map with 3 values","7939a1eb":"## Gradient Boosting","eb893355":"The categorical features are Sex, Cabin, Embarked","abaeb97e":"### XGBOOST Classifier","7f42cec0":"We have alphanumeric characters in Cabin column, So we are extracting the letter from value and replacing it","013789e7":"## Converting Catogorical Features into Numberical features","31bd7f6b":"## Data Preprocessing","2d9fab23":"Columns like \"PassengerId\", \"Name\", \"Ticket\" may not needed for the training, so droping it on df_train, df_test","e9a37922":"### For test data","8702fa30":"### Logistic regression","08d2d8e7":"Out of 891 rows, column \"Cabin\" has 687 missing values in training data and test data. \nSince it is more than 50% of the data, we can change the values from NaN to some other variable and consider it as data not available\n\nWe replace it as \"No cabin\"\n","ce505e5e":"## Embarked","16cbc58c":"## Splitting the target variable","fe069d09":"## checking the unique values in Cabin","0c681998":"## Final Predictions","610516e0":"## Importing the dataset","a4f1ce93":"# Visualization","9231e638":"Now, we have 2 missing values for \"Embarked\" column in train data and 1 missing value for \"Fare\" in test data, so we replace the missing values using their respective mean value for \"Fare\" and mode(Highest Occurence) for \"Embarked\" column"}}