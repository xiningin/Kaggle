{"cell_type":{"8d735b05":"code","2b806b82":"code","ee97a3cc":"code","2eee154e":"code","d18ceae6":"code","67ef110b":"code","bdb45359":"code","2bb607af":"code","16c30aa4":"code","961b5def":"code","6915adae":"code","f0d40940":"code","cdd47a0e":"code","cb1dfb95":"code","cf723ce8":"markdown","642c1cc1":"markdown","1bbf8c3d":"markdown","d46b1ffb":"markdown"},"source":{"8d735b05":"# Code here\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Import Semua Data\ndf = pd.read_csv('..\/input\/tugas4\/titanic.csv')\ndf_test = pd.read_csv('..\/input\/tugas4\/titanic_test.csv')","2b806b82":"df.head()","ee97a3cc":"df = pd.get_dummies(df,columns=['Sex','Embarked'])","2eee154e":"import seaborn as sns\n\ntotal = df.isnull().sum().sort_values(ascending=False)\npercent = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nf, ax = plt.subplots(figsize=(15, 6))\nplt.xticks(rotation='90')\nsns.barplot(x=missing_data.index, y=missing_data['Percent'])\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent of missing values', fontsize=15)\nplt.title('Percent missing data by feature', fontsize=15)\nmissing_data.head()","d18ceae6":"df['Age']=df['Age'].fillna(df['Age'].mean())","67ef110b":"# Melihat hubungan antar data\nX = df.iloc[:,0:14]  #independent columns\ny = df.iloc[:,-1]    #target column i.e price range\n#get correlations of each features in dataset\ncorrmat = df.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(8,8))\n#plot heat map\ng=sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","bdb45359":"drop_elements = ['PassengerId', 'Name', 'Pclass', 'Ticket', 'Cabin', 'SibSp','Age']\ndf = df.drop(drop_elements, axis = 1)","2bb607af":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    GaussianNB(),\n    LinearDiscriminantAnalysis(),\n    QuadraticDiscriminantAnalysis(),\n    LogisticRegression()]\n\nlog_cols = [\"Classifier\", \"Accuracy\"]\nlog = pd.DataFrame(columns=log_cols)\n\n\nX = df.iloc[:, 1:]\ny = df.iloc[:, 0]\n\nacc_dict = {}\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n\nfor clf in classifiers:\n    name = clf.__class__.__name__\n    clf.fit(X_train, y_train)\n    train_predictions = clf.predict(X_test)\n    acc = accuracy_score(y_test, train_predictions)\n    if name in acc_dict:\n        acc_dict[name] += acc\n    else:\n        acc_dict[name] = acc\n\nfor clf in acc_dict:\n    acc_dict[clf] = acc_dict[clf]\n    log_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=log_cols)\n    log = log.append(log_entry)\n\nplt.xlabel('Accuracy')\nplt.title('Classifier Accuracy')\n\nsns.set_color_codes(\"muted\")\nsns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")","16c30aa4":"from sklearn.model_selection import GridSearchCV\nimport numpy as np\n\nclf = RandomForestClassifier()\n\nparam_grid = {'n_estimators':np.arange(5,60), 'criterion':['gini', 'entropy']}\ngscv = GridSearchCV(clf, param_grid=param_grid, cv=5, scoring='roc_auc')\n\ngscv.fit(X_train, y_train)","961b5def":"gscv.best_params_","6915adae":"total = df_test.isnull().sum().sort_values(ascending=False)\npercent = (df.isnull().sum()\/df_test.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nf, ax = plt.subplots(figsize=(15, 6))\nplt.xticks(rotation='90')\nsns.barplot(x=missing_data.index, y=missing_data['Percent'])\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent of missing values', fontsize=15)\nplt.title('Percent missing data by feature', fontsize=15)\nmissing_data.head()","f0d40940":"clf = RandomForestClassifier(criterion='entropy',n_estimators=16)\nclf.fit(X,y)\n\ndf_pred = df_test.drop(drop_elements, axis = 1)\n\ndf_pred = pd.get_dummies(df_pred,columns=['Sex','Embarked'])\ndf_pred['Fare']=df_pred['Fare'].fillna(df_pred['Fare'].mean())\n\ny_pred = clf.predict(df_pred)","cdd47a0e":"submission = pd.DataFrame(df_test['PassengerId'])\nsubmission['survived'] = y_pred","cb1dfb95":"submission.to_csv('submissionDTC.csv', index=False)","cf723ce8":"Jawab:\n1. Transformasi nilai yang bersifat kategorikal, menindaklanjuti missing value, mengidentifikasi dan memutuskan penindaklanjutan terhadap outlier, centering dan scaling\n2. mengisi dengan mean, mengisi dengan modus, mengisi dengan hasil knn, mengisi berdasarkan data sebelumnya atau setelahnya\n3. Ketika skala distribusi suatu fitur independen dalam dataset jauh lebih besar dibandingkan yang lainnya. Hal ini menyebabkan pengaruhnya dalam pembuatan model akan lebih besar sementara state awalnya pengaruh data pada model harus setara terlebih dahulu.\n4. Business understanding -> Data understanding (EDA) -> Data preparation (Feature building, Feature selection, Data cleaning dll) -> Modeling -> Evaluation -> Deployment","642c1cc1":"<h1>Soal 2: Pengaplikasian<\/h1>\n\nSelamat, sampai tahap ini kalian telah belajar banyak tentang data science, dari mulai python, data manipulasi, visualisasi, dan pembuatan model. Sekarang saatnya untuk mengaplikasikan semuanya.\n\nDownload dan gunakan data [titanic.csv](https:\/\/drive.google.com\/uc?export=download&id=15-XQkmqj2UlFQH7rASJH1oxWST6o9mbm) sebagai data untuk pembuatan model ML. Pahami betul data ini dengan melakukan EDA (Explolatory Data Analaysis), Visualisasi, Data Analysis, Preprocessing Data, dan Modeling.\n\n<b>(Optional)<\/b> Download dan gunakan data [titanic_test.csv](https:\/\/drive.google.com\/uc?export=download&id=15-XQkmqj2UlFQH7rASJH1oxWST6o9mbm) untuk mengetest model kalian dengan melakukan prediksi terhadap data tersebut. Submit hasil prediksinya ke kaggle dan lihat scorenya. https:\/\/www.kaggle.com\/c\/titanic\/submit\n\n![alt text](https:\/\/drive.google.com\/uc?id=1SyflO2YeuCdYhxwPF6CAtMeaNN1qTaFx)","1bbf8c3d":"---","d46b1ffb":"<h1>Soal 1: Pemahaman<\/h1>\n\n1. Sebutkan apa saja yang termasuk preprocessing data!\n2. Jelaskan beberapa cara imputing missing value!\n3. Kapan kita perlu melakukan feature centering dan scaling?\n4. Bagaimana Data Science Workflow?"}}