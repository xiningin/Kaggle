{"cell_type":{"a222cf20":"code","c6c96259":"code","da365cea":"code","939ec463":"code","935422e1":"code","16df337a":"code","5c399d8e":"code","29033cb3":"code","3d824362":"code","cf6b8dae":"code","7a683bbf":"code","a6a82b5c":"code","922ae7d1":"code","b631b7cf":"code","cef9276f":"code","07ef12e0":"code","cf89ce14":"code","544d7234":"code","033395b1":"code","d6707c30":"code","6c618089":"code","99c2f335":"code","3be09398":"code","8032d0e3":"code","593265b2":"code","3f5428f9":"code","eb6c1d7a":"code","d65dc876":"code","f10c0e97":"code","556b052e":"code","b72b4468":"code","a1a97d65":"code","8f38a0d2":"code","9aac7e18":"markdown","aaba2453":"markdown","bb9e89c8":"markdown","0ddfc6e6":"markdown","8ce29fa6":"markdown","0f12187d":"markdown","fe69bda8":"markdown","f8e6be53":"markdown","0e7a6a2b":"markdown","b4659c9b":"markdown"},"source":{"a222cf20":"from IPython.display import clear_output\n!pip install imutils\nclear_output()","c6c96259":"import numpy as np \nfrom tqdm import tqdm\nimport cv2\nimport os\nimport shutil\nimport itertools\nimport imutils\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import tools\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras import layers\nfrom keras.datasets import mnist\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import EarlyStopping\n\ninit_notebook_mode(connected=True)\nRANDOM_SEED = 123","da365cea":"!apt-get install tree\nclear_output()\n# create new folders\n!mkdir TRAIN TEST VAL TRAIN\/YES TRAIN\/NO TEST\/YES TEST\/NO VAL\/YES VAL\/NO\n!tree -d","939ec463":"import os\nprint(os.listdir(\"..\/input\"))","935422e1":"IMG_PATH = '..\/input\/brain-mri-images-for-brain-tumor-detection\/brain_tumor_dataset\/'\n# Division des donnees\nfor CLASS in os.listdir(IMG_PATH):\n    if not CLASS.startswith('.'):\n        IMG_NUM = len(os.listdir(IMG_PATH + CLASS))\n        for (n, FILE_NAME) in enumerate(os.listdir(IMG_PATH + CLASS)):\n            img = IMG_PATH + CLASS + '\/' + FILE_NAME\n            if n < 5:\n                shutil.copy(img, 'TEST\/' + CLASS.upper() + '\/' + FILE_NAME)\n            elif n < 0.8*IMG_NUM:\n                shutil.copy(img, 'TRAIN\/'+ CLASS.upper() + '\/' + FILE_NAME)\n            else:\n                shutil.copy(img, 'VAL\/'+ CLASS.upper() + '\/' + FILE_NAME)","16df337a":"def load_data(dir_path, img_size=(100,100)):\n    \"\"\"\n    Load resized images as np.arrays to workspace\n    \"\"\"\n    X = []\n    y = []\n    i = 0\n    labels = dict()\n    for path in tqdm(sorted(os.listdir(dir_path))):\n        if not path.startswith('.'):\n            labels[i] = path\n            for file in os.listdir(dir_path + path):\n                if not file.startswith('.'):\n                    img = cv2.imread(dir_path + path + '\/' + file)\n                    X.append(img)\n                    y.append(i)\n            i += 1\n    X = np.array(X)\n    y = np.array(y)\n    print(f'{len(X)} images loaded from {dir_path} directory.')\n    return X, y, labels\n\n\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (6,6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    cm = np.round(cm,2)\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","5c399d8e":"TRAIN_DIR = 'TRAIN\/'\nTEST_DIR = 'TEST\/'\nVAL_DIR = 'VAL\/'\nIMG_SIZE = (224,224)\n\n# chargement des immages\nX_train, y_train, labels = load_data(TRAIN_DIR, IMG_SIZE)\nX_test, y_test, _ = load_data(TEST_DIR, IMG_SIZE)\nX_val, y_val, _ = load_data(VAL_DIR, IMG_SIZE)","29033cb3":"y = dict()\ny[0] = []\ny[1] = []\nfor set_name in (y_train, y_val, y_test):\n    y[0].append(np.sum(set_name == 0))\n    y[1].append(np.sum(set_name == 1))\n\ntrace0 = go.Bar(\n    x=['Train Set', 'Validation Set', 'Test Set'],\n    y=y[0],\n    name='No',\n    marker=dict(color='#33cc33'),\n    opacity=0.7\n)\ntrace1 = go.Bar(\n    x=['Train Set', 'Validation Set', 'Test Set'],\n    y=y[1],\n    name='Yes',\n    marker=dict(color='#ff3300'),\n    opacity=0.7\n)\ndata = [trace0, trace1]\nlayout = go.Layout(\n    title='Count of classes in each set',\n    xaxis={'title': 'Set'},\n    yaxis={'title': 'Count'}\n)\nfig = go.Figure(data, layout)\niplot(fig)","3d824362":"def plot_samples(X, y, labels_dict, n=50):\n    \"\"\"\n    Creates a gridplot for desired number of images (n) from the specified set\n    \"\"\"\n    for index in range(len(labels_dict)):\n        imgs = X[np.argwhere(y == index)][:n]\n        j = 10\n        i = int(n\/j)\n\n        plt.figure(figsize=(15,6))\n        c = 1\n        for img in imgs:\n            plt.subplot(i,j,c)\n            plt.imshow(img[0])\n\n            plt.xticks([])\n            plt.yticks([])\n            c += 1\n        plt.suptitle('Tumor: {}'.format(labels_dict[index]))\n        plt.show()","cf6b8dae":"plot_samples(X_train, y_train, labels, 30)","7a683bbf":"RATIO_LIST = []\nfor set in (X_train, X_test, X_val):\n    for img in set:\n        RATIO_LIST.append(img.shape[1]\/img.shape[0])\n        \nplt.hist(RATIO_LIST)\nplt.title('Distribution of Image Ratios')\nplt.xlabel('Ratio Value')\nplt.ylabel('Count')\nplt.show()","a6a82b5c":"def crop_imgs(set_name, add_pixels_value=0):\n    \"\"\"\n    Finds the extreme points on the image and crops the rectangular out of them\n    \"\"\"\n    set_new = []\n    for img in set_name:\n        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        gray = cv2.GaussianBlur(gray, (5, 5), 0)\n\n        # threshold the image, then perform a series of erosions +\n        # dilations to remove any small regions of noise\n        thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n        thresh = cv2.erode(thresh, None, iterations=2)\n        thresh = cv2.dilate(thresh, None, iterations=2)\n\n        # find contours in thresholded image, then grab the largest one\n        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        cnts = imutils.grab_contours(cnts)\n        c = max(cnts, key=cv2.contourArea)\n\n        # find the extreme points\n        extLeft = tuple(c[c[:, :, 0].argmin()][0])\n        extRight = tuple(c[c[:, :, 0].argmax()][0])\n        extTop = tuple(c[c[:, :, 1].argmin()][0])\n        extBot = tuple(c[c[:, :, 1].argmax()][0])\n\n        ADD_PIXELS = add_pixels_value\n        new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n        set_new.append(new_img)\n\n    return np.array(set_new)","922ae7d1":"img = cv2.imread('..\/input\/brain-mri-images-for-brain-tumor-detection\/brain_tumor_dataset\/yes\/Y108.jpg')\nimg = cv2.resize(\n            img,\n            dsize=IMG_SIZE,\n            interpolation=cv2.INTER_CUBIC\n        )\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\ngray = cv2.GaussianBlur(gray, (5, 5), 0)\n\n# threshold the image, then perform a series of erosions +\n# dilations to remove any small regions of noise\nthresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\nthresh = cv2.erode(thresh, None, iterations=2)\nthresh = cv2.dilate(thresh, None, iterations=2)\nim_bw = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) #ajout\n\n# find contours in thresholded image, then grab the largest one\ncnts = cv2.findContours(im_bw, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\ncnts = imutils.grab_contours(cnts)\nc = max(cnts, key=cv2.contourArea) \n\n# find the extreme points\nextLeft = tuple(c[c[:, :, 0].argmin()][0])\nextRight = tuple(c[c[:, :, 0].argmax()][0])\nextTop = tuple(c[c[:, :, 1].argmin()][0])\nextBot = tuple(c[c[:, :, 1].argmax()][0])\n\n# add contour on the image\nimg_cnt = cv2.drawContours(img.copy(), [c], -1, (0, 255, 255), 4)\n\n# add extreme points\nimg_pnt = cv2.circle(img_cnt.copy(), extLeft, 8, (0, 0, 255), -1)\nimg_pnt = cv2.circle(img_pnt, extRight, 8, (0, 255, 0), -1)\nimg_pnt = cv2.circle(img_pnt, extTop, 8, (255, 0, 0), -1)\nimg_pnt = cv2.circle(img_pnt, extBot, 8, (255, 255, 0), -1)\n\n# crop\nADD_PIXELS = 0\nnew_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()","b631b7cf":"# apply this for each set\nX_train_crop = crop_imgs(set_name=X_train)\nX_val_crop = crop_imgs(set_name=X_val)\nX_test_crop = crop_imgs(set_name=X_test)","cef9276f":"plot_samples(X_train_crop, y_train, labels, 30)","07ef12e0":"def save_new_images(x_set, y_set, folder_name):\n    i = 0\n    for (img, imclass) in zip(x_set, y_set):\n        if imclass == 0:\n            cv2.imwrite(folder_name+'NO\/'+str(i)+'.jpg', img)\n        else:\n            cv2.imwrite(folder_name+'YES\/'+str(i)+'.jpg', img)\n        i += 1","cf89ce14":"# saving new images to the folder\n!mkdir TRAIN_CROP TEST_CROP VAL_CROP TRAIN_CROP\/YES TRAIN_CROP\/NO TEST_CROP\/YES TEST_CROP\/NO VAL_CROP\/YES VAL_CROP\/NO\n\nsave_new_images(X_train_crop, y_train, folder_name='TRAIN_CROP\/')\nsave_new_images(X_val_crop, y_val, folder_name='VAL_CROP\/')\nsave_new_images(X_test_crop, y_test, folder_name='TEST_CROP\/')","544d7234":"def preprocess_imgs(set_name, img_size):\n    \"\"\"\n    Resize and apply VGG-15 preprocessing\n    \"\"\"\n    set_new = []\n    for img in set_name:\n        img = cv2.resize(\n            img,\n            dsize=img_size,\n            interpolation=cv2.INTER_CUBIC\n        )\n        set_new.append(preprocess_input(img))\n    return np.array(set_new)","033395b1":"X_train_prep = preprocess_imgs(set_name=X_train_crop, img_size=IMG_SIZE)\nX_test_prep = preprocess_imgs(set_name=X_test_crop, img_size=IMG_SIZE)\nX_val_prep = preprocess_imgs(set_name=X_val_crop, img_size=IMG_SIZE)","d6707c30":" plot_samples(X_train_prep, y_train, labels, 30)","6c618089":"# set the paramters we want to change randomly\ndemo_datagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.05,\n    height_shift_range=0.05,\n    rescale=1.\/255,\n    shear_range=0.05,\n    brightness_range=[0.1, 1.5],\n    horizontal_flip=True,\n    vertical_flip=True\n)","99c2f335":"os.mkdir('preview')\nx = X_train_crop[0]  \nx = x.reshape((1,) + x.shape) \n\ni = 0\nfor batch in demo_datagen.flow(x, batch_size=1, save_to_dir='preview', save_prefix='aug_img', save_format='jpg'):\n    i += 1\n    if i > 20:\n        break ","3be09398":"plt.imshow(X_train_crop[0])\nplt.xticks([])\nplt.yticks([])\nplt.title('Original Image')\nplt.show()\n\nplt.figure(figsize=(15,6))\ni = 1\nfor img in os.listdir('preview\/'):\n    img = cv2.cv2.imread('preview\/' + img)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.subplot(3,7,i)\n    plt.imshow(img)\n    plt.xticks([])\n    plt.yticks([])\n    i += 1\n    if i > 3*7:\n        break\nplt.suptitle('Augemented Images')\nplt.show()","8032d0e3":"!rm -rf preview\/","593265b2":"TRAIN_DIR = 'TRAIN_CROP\/'\nVAL_DIR = 'VAL_CROP\/'\n\ntrain_datagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.1,\n    brightness_range=[0.5, 1.5],\n    horizontal_flip=True,\n    vertical_flip=True,\n    preprocessing_function=preprocess_input\n)\n\ntest_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input\n)\n\n\ntrain_generator = train_datagen.flow_from_directory(\n    TRAIN_DIR,\n    color_mode='rgb',\n    target_size=IMG_SIZE,\n    batch_size=32,\n    class_mode='binary',\n    seed=RANDOM_SEED\n)\n\n\nvalidation_generator = test_datagen.flow_from_directory(\n    VAL_DIR,\n    color_mode='rgb',\n    target_size=IMG_SIZE,\n    batch_size=16,\n    class_mode='binary',\n    seed=RANDOM_SEED\n)","3f5428f9":"# load base model\nvgg16_weight_path = '..\/input\/vgg16\/vgg16\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\nbase_model = VGG16(\n    weights=vgg16_weight_path,\n    include_top=False, \n    input_shape=IMG_SIZE + (3,)\n)","eb6c1d7a":"NUM_CLASSES = 1\n\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(NUM_CLASSES, activation='sigmoid'))\n\nmodel.layers[0].trainable = False\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer=RMSprop(lr=1e-4),\n    metrics=['accuracy']\n)\n\nmodel.summary()","d65dc876":"EPOCHS = 50\nes = EarlyStopping(\n    monitor='val_acc', \n    mode='max',\n    patience=6\n)\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=50,\n    epochs=EPOCHS,\n    validation_data=validation_generator,\n    validation_steps=25,\n    callbacks=[es]\n)","f10c0e97":"# plot model performance\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(1, len(history.epoch) + 1)\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\n\nplt.tight_layout()\nplt.show()","556b052e":"# validate on val set\npredictions = model.predict(X_val_prep)\npredictions = [1 if x>0.5 else 0 for x in predictions]\n\naccuracy = accuracy_score(y_val, predictions)\nprint('Val Accuracy = %.2f' % accuracy)\n\nconfusion_mtx = confusion_matrix(y_val, predictions) \ncm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)","b72b4468":"# validate on test set\npredictions = model.predict(X_test_prep)\npredictions = [1 if x>0.5 else 0 for x in predictions]\n\naccuracy = accuracy_score(y_test, predictions)\nprint('Test Accuracy = %.2f' % accuracy)\n\nconfusion_mtx = confusion_matrix(y_test, predictions) \ncm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)","a1a97d65":"ind_list = np.argwhere((y_test == predictions) == False)[:, -1]\nif ind_list.size == 0:\n    print('There are no missclassified images.')\nelse:\n    for i in ind_list:\n        plt.figure()\n        plt.imshow(X_test_crop[i])\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(f'Actual class: {y_val[i]}\\nPredicted class: {predictions[i]}')\n        plt.show()","8f38a0d2":"# clean up the space\n!rm -rf TRAIN TEST VAL TRAIN_CROP TEST_CROP VAL_CROP\n# save the model\nmodel.save('2019-06-07_VGG_model.h5')","9aac7e18":"# [2. Acquisition des Bibliotheques et Configuration](http:\/\/)\n","aaba2453":"# [1.1.- Description du Dataset](http:\/\/)\nLes donnees utilisees pour resoudre notre probleme sont les images IRM cerebrales [Brain MRI Images for Brain Tumor Detection](http:\/\/www.kaggle.com\/jjprotube\/brainmriimagesforbraintumordetection) qui comprend des scanners IRM classes ainsi :\n\n> NO - Pas de tumeur, code 0\n\n> YES - Tumeur, code 1\n\nApres des recherches, on ne peut pas trouver une description valable pour le jeu de donnees et sur la provenance des analyses IRM","bb9e89c8":"Auteur : **DJHONSON JEAN**\n\nDate : **Mars 2020**\n\n== = == = == = == == = ==","0ddfc6e6":"# [1.2.- C'est quoi une tumeur c\u00e9r\u00e9brale?](http:\/\/)\n\nElle se produit lorsque des cellules anormales qui se forment dans le cerveau. Il existe en deux principaux types : les [tumeurs canc\u00e9reuses (malignes)](http:\/\/www.doctissimo.fr\/sante\/dictionnaire-medical\/tumeur-maligne) et les [tumeurs b\u00e9nignes](http:\/\/fr.wikipedia.org\/wiki\/Tumeur_b\u00e9nigne). Les tumeurs canc\u00e9reuses peuvent \u00eatre divis\u00e9es en tumeurs primaires, qui commencent dans le cerveau, et en tumeurs secondaires, qui se sont propag\u00e9es ailleurs, appel\u00e9es tumeurs m\u00e9tastatiques c\u00e9r\u00e9brales. Les divers sympt\u00f4mes du cancer du cerveau incluent des probl\u00e8mes de coordination, des maux de t\u00eate fr\u00e9quents, des sautes d'humeur, des changements d'\u00e9locution, des difficult\u00e9s de concentration, des convulsions et une perte de  m\u00e9moire, qui d\u00e9pendent de  la taille de la tumeur, de sa nature et de son emplacement. Le mal de t\u00eate est classiquement pire le matin et dispara\u00eet avec des vomissements. D'autres sympt\u00f4mes peuvent inclure des difficult\u00e9s \u00e0 marcher, \u00e0 parler ou \u00e0 ressentir des sensations. \u00c0 mesure que la maladie progresse, une perte de conscience peut survenir.\n\nIl est beaucoup plus facile d\u2019\u00e9liminer les petites tumeurs. Une fois les sympt\u00f4mes  apparus, il  est g\u00e9n\u00e9ralement trop tard pour traiter la tumeur. Cependant, il est tr\u00e8s difficile de traiter le cancer \u00e0 des stades plus \u00e9lev\u00e9s o\u00f9 les taux de sur-vie sont faibles.\n\n![image.png](attachment:image.png)\n\n\n> **Fig. 1 **: M\u00e9tastases c\u00e9r\u00e9brales dans l'h\u00e9misph\u00e8re c\u00e9r\u00e9bral droit du cancer du poumon, montr\u00e9es sur l'imagerie par r\u00e9sonance magn\u00e9tique.","8ce29fa6":"Une fois chargee, les images sont enregistrees dans un dossier avec des sous-dossier nommee oui et non. Donc, on divise les donnees en TRAIN, VAL et TEST afin de faciliter la tache avec une hierarchie comme :","0f12187d":"# [1.- Contexte et Objectifs](http:\/\/)\n\nLes  methodes rapides de detection de tumeurs c\u00e9r\u00e9braux sont  l'imagerie par r\u00e9sonance magn\u00e9tique (IRM). Cette m\u00e9thode utilise d'imagerie m\u00e9dicale de haute qualit\u00e9. Cependant, les techniques de d\u00e9tection du cancer doivent \u00eatre fiables et robustes pour que les diagnostics soient corrects. \u00c0 cette fin, l\u2019objectif de ce projet est de construire un mod\u00e8le CNN pouvant classer si le sujet avait une tumeur ou non sur la base de l'IRM. Pour se faire, on va utiliser l'architecture et les poids du mod\u00e8le VGG-16 pour former le mod\u00e8le \u00e0 ce probl\u00e8me binaire. On utilisera la pr\u00e9cision comme m\u00e9trique pour justifier les performances du mod\u00e8le qui peuvent \u00eatre d\u00e9finies comme:\n\nAccuracy= (Number of correclty predicted images \/ \n                  Total number of tested images) \u00d7100%","fe69bda8":"Chargement du jeu de donnes et configuration","f8e6be53":"# Brain Tumor Detection avec le modele VGG-16","0e7a6a2b":"# [R\u00e9sum\u00e9](http:\/\/)\n\nLe cancer du cerveau est aujourd'hui parmi les types de cancer les plus critiques. Plusieurs sympt\u00f4mes peuvent apparaitre en fonction de la localisation du cancer dans le cerveau. Sa d\u00e9tection pr\u00e9coce peut donner une nouvelle chance de vie, en suivant un traitement efficace a ce effet. Le but de ce travail, est d'utiliser une m\u00e9thode d'apprentissage en profondeur (Deep Learning) pour detecter des tumeurs canc\u00e9reuses dans le cerveau \u00e0 partir d'images IRM \u00e0 l'aide d'un traitement sur l'image puis la classification de la tumeur avec les r\u00e9seaux de neurones convolutifs (CNN)","b4659c9b":"Source [Wikipedia](http:\/\/https:\/\/en.wikipedia.org\/wiki\/Brain_tumor)"}}