{"cell_type":{"b200eeb1":"code","4872a461":"code","7eb9d37a":"code","ee6c1dab":"code","377c78ff":"code","7a26ed07":"code","e132479e":"code","edcf13a2":"code","8c2195d4":"code","ab163ba6":"markdown","e26f8785":"markdown","d8348e39":"markdown","a51a892b":"markdown","aa5cc35b":"markdown","c1638ae8":"markdown","40672a48":"markdown","640b4811":"markdown"},"source":{"b200eeb1":"import os\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation","4872a461":"def load_df():\n    # https:\/\/www.kaggle.com\/raghavendrakotala\/fine-tunned-on-roberta-base-as-ner-problem-0-533\n    train_names, train_texts = [], []\n    for f in tqdm(list(os.listdir('..\/input\/feedback-prize-2021\/train'))):\n        train_names.append(f.replace('.txt', ''))\n        train_texts.append(open('..\/input\/feedback-prize-2021\/train\/' + f, 'r').read())\n    train_text_df = pd.DataFrame({'id': train_names, 'text': train_texts})\n    return train_text_df\n\ndf = load_df()\ndf.head()","7eb9d37a":"n_features = 1000\nn_topics = 10\nn_top_words = 20","ee6c1dab":"%%time\nvect = CountVectorizer(max_df=0.95, min_df=2, max_features=n_features, stop_words=\"english\")\nX = vect.fit_transform(df.text.tolist())","377c78ff":"%%time\nlda = LatentDirichletAllocation(n_components=n_topics, max_iter=5,\n                                learning_method=\"online\",\n                                learning_offset=50.0,\n                                random_state=42,\n                                n_jobs=-1)\nlabels = lda.fit_transform(X)\nlabels = labels.argmax(-1)","7a26ed07":"def plot_top_words(model, feature_names, n_top_words, title):\n    fig, axes = plt.subplots(2, 5, figsize=(30, 15), sharex=True)\n    axes = axes.flatten()\n    for topic_idx, topic in enumerate(model.components_):\n        top_features_ind = topic.argsort()[: -n_top_words - 1 : -1]\n        top_features = [feature_names[i] for i in top_features_ind]\n        weights = topic[top_features_ind]\n\n        ax = axes[topic_idx]\n        ax.barh(top_features, weights, height=0.7)\n        ax.set_title(f\"Topic {topic_idx +1}\", fontdict={\"fontsize\": 30})\n        ax.invert_yaxis()\n        ax.tick_params(axis=\"both\", which=\"major\", labelsize=20)\n        for i in \"top right left\".split():\n            ax.spines[i].set_visible(False)\n        fig.suptitle(title, fontsize=40)\n\n    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n    plt.show()\n\n\nfeature_names = vect.get_feature_names()\nplot_top_words(lda, feature_names, n_top_words, \"Topics in LDA model\")","e132479e":"df['topic'] = labels\ndf.head()","edcf13a2":"df['topic'].value_counts()","8c2195d4":"for topic_idx in range(n_topics):\n    topic = lda.components_[topic_idx]\n    top_features_ind = topic.argsort()[: -n_top_words - 1 : -1]\n    top_features = [feature_names[i] for i in top_features_ind]\n    samples = df[df['topic'] == topic_idx].sample(5)\n    print(\"=========================================================\")\n    print(f\"TOPIC {topic_idx + 1}\")\n    print(f\"  Top words: {top_features}\")\n    print(\"=========================================================\")\n    for sample_idx, sample in enumerate(samples['text'].tolist(), 1):\n        print(f\"Example {sample_idx}:\")\n        print(sample)\n        print()\n        print('---------------------')\n        print()\n    print()\n    print()\n    print()\n    ","ab163ba6":"# Examples","e26f8785":"# Configuration","d8348e39":"# LDA","a51a892b":"# \ud83d\udcd6 Topic Modeling with LDA\n \n![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/31779\/logos\/header.png)\n\n## Simple topic modeling over the [Feedback Prize - Evaluating Student Writing](https:\/\/www.kaggle.com\/c\/feedback-prize-2021) data using `CountVectorizer` and `LDA`.\n\n\nAdapted from scikit's Topic Modeling documentation script: https:\/\/scikit-learn.org\/stable\/auto_examples\/applications\/plot_topics_extraction_with_nmf_lda.html\n\n\nIt mimics [RAPIDS UMAP Tfidf KMeans - Discovers 15 Topics!](https:\/\/www.kaggle.com\/cdeotte\/rapids-umap-tfidf-kmeans-discovers-15-topics) with LDA.","aa5cc35b":"# Count Vectorizer","c1638ae8":"## Imports","40672a48":"# Plot","640b4811":"# Load texts"}}