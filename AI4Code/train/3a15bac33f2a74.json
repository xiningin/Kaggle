{"cell_type":{"f69ffbd3":"code","d69980ea":"code","7463d1be":"code","2644e988":"code","7ef7976a":"code","eef147c3":"code","cde2c062":"code","4c692757":"markdown","efc80a35":"markdown","d3c10b1f":"markdown","fc060980":"markdown"},"source":{"f69ffbd3":"import pandas as pd\nimport gc\nfrom sklearn import metrics, svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nimport xgboost as xgb\nimport lightgbm as lgbm\nimport catboost as cb\n\ntrain_file_path=\"..\/input\/talkingdata-adtracking-fraud-detection\/train_sample.csv\"\ndtypes = {\n        'ip'            : 'uint32',\n        'app'           : 'uint16',\n        'device'        : 'uint16',\n        'os'            : 'uint16',\n        'channel'       : 'uint16',\n        'is_attributed' : 'uint8',\n        'click_id'      : 'uint32'\n        }\n\nimport pandas as pd\nimport gc\nfrom sklearn import metrics, svm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nimport xgboost as xgb\nimport lightgbm as lgbm\nimport catboost as cb\n\ntrain_file_path=\"..\/input\/talkingdata-adtracking-fraud-detection\/train.csv\"\ntest_file_path=\"..\/input\/talkingdata-adtracking-fraud-detection\/test.csv\"\ndtypes = {\n        'ip'            : 'uint32',\n        'app'           : 'uint16',\n        'device'        : 'uint16',\n        'os'            : 'uint16',\n        'channel'       : 'uint16',\n        'is_attributed' : 'uint8',\n        'click_id'      : 'uint32'\n        }\n\ntrain_data=pd.read_csv(train_file_path, usecols=['ip','app', 'device','os', 'channel', 'is_attributed', 'click_time'],dtype=dtypes,parse_dates=['click_time'], skiprows=range(1,122991234), nrows=10000000)\ntrain_data['weekday']=train_data['click_time'].dt.dayofweek.astype('uint8')\ntrain_data['click_hour']=train_data['click_time'].dt.hour.astype('uint8')\ntrain_data['click_day']=train_data['click_time'].dt.day.astype('uint8')\nprint(\"Training File read succesfully!\")\n","d69980ea":"from sklearn.model_selection import train_test_split\n#ip_app grouping\ngp = train_data[['ip','app','os']].groupby(by=['ip','app'])[['os']].count().reset_index().rename(index=str, columns={'os': 'ip_app_count'})\ntrain_data = train_data.merge(gp, how=\"left\", on=['ip','app'])\ndel gp\ngc.collect()\n\n#ip_time grouping\ngp = train_data[['ip','click_day','click_hour','channel', 'os']].groupby(by=['ip','click_day','click_hour'])[['os']].count().reset_index().rename(index=str, columns={'os': 'ip_time_count'})\ntrain_data = train_data.merge(gp, how=\"left\", on=['ip','click_day','click_hour'])\ndel gp\ngc.collect()\n\n#ip_app_os grouping\ngp = train_data[['ip','app','channel', 'os']].groupby(by=['ip','app', 'os'])[['channel']].count().reset_index().rename(index=str, columns={'channel': 'ip_app_os_count'})\ntrain_data = train_data.merge(gp, how=\"left\", on=['ip','app', 'os'])\ndel gp\ngc.collect()\n\n#ip_app_os_var_hour grouping\ngp = train_data[['ip','app','click_hour', 'os']].groupby(by=['ip','app', 'os'])[['click_hour']].var().reset_index().rename(index=str, columns={'click_hour': 'ip_app_os_var_hour'})\ntrain_data = train_data.merge(gp, how=\"left\", on=['ip','app', 'os'])\ndel gp\ngc.collect()\n\n#ip_app_os_var_weekday grouping\ngp = train_data[['ip','app','weekday', 'os']].groupby(by=['ip','app', 'os'])[['weekday']].var().reset_index().rename(index=str, columns={'weekday': 'ip_app_os_var_weekday'})\ntrain_data = train_data.merge(gp, how=\"left\", on=['ip','app', 'os'])\ndel gp\ngc.collect()\n\n#ip_day_chn_var_hour grouping\ngp = train_data[['ip','click_day','click_hour','channel']].groupby(by=['ip','click_day','channel'])[['click_hour']].var().reset_index().rename(index=str, columns={'click_hour': 'ip_day_chn_var_hour'})\ntrain_data = train_data.merge(gp, how=\"left\", on=['ip','click_day','channel'])\ndel gp\ngc.collect()\n\n#ip_app_chn_mean_hour grouping\ngp = train_data[['ip','app','channel', 'click_hour']].groupby(by=['ip','app', 'channel'])[['click_hour']].mean().reset_index().rename(index=str, columns={'click_hour': 'ip_app_chn_mean_hour'})\ntrain_data = train_data.merge(gp, how=\"left\", on=['ip','app', 'channel'])\ndel gp\ngc.collect()\n\n#ip_app_chn_mean_weekday grouping\ngp = train_data[['ip','app','channel', 'weekday']].groupby(by=['ip','app', 'channel'])[['weekday']].mean().reset_index().rename(index=str, columns={'weekday': 'ip_app_chn_mean_weekday'})\ntrain_data = train_data.merge(gp, how=\"left\", on=['ip','app', 'channel'])\ndel gp\ngc.collect()\n\n#ip_app_os_var_day grouping\ngp = train_data[['ip','app','channel', 'click_day']].groupby(by=['ip','app', 'channel'])[['click_day']].var().reset_index().rename(index=str, columns={'click_day': 'ip_app_os_var_day'})\ntrain_data = train_data.merge(gp, how=\"left\", on=['ip','app', 'channel'])\ndel gp\ngc.collect()\ntrain_data=train_data.fillna(0)\ntrain_data[\"ip_time_count\"] = pd.DataFrame(train_data[\"ip_time_count\"].astype('uint16'))\ntrain_data[\"ip_app_count\"] = pd.DataFrame(train_data[\"ip_app_count\"].astype('uint16'))\ntrain_data[\"ip_app_os_count\"] = pd.DataFrame(train_data[\"ip_app_os_count\"].astype('uint16'))\n\ny_train=train_data.is_attributed\nx_train=train_data.drop('is_attributed', axis=1)\nx_train=x_train.drop('click_time', axis=1)\n","7463d1be":"x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, random_state=99)\ndel train_data\ngc.collect()","2644e988":"def perf_measure(y_actual, y_pred):\n    TP = 0\n    FP = 0\n    TN = 0\n    FN = 0\n\n    for i in range(len(y_pred)): \n        if y_actual[i]==y_pred[i]==1:\n           TP += 1\n        if y_pred[i]==1 and y_actual[i]!=y_pred[i]:\n           FP += 1\n        if y_actual[i]==y_pred[i]==0:\n           TN += 1\n        if y_pred[i]==0 and y_actual[i]!=y_pred[i]:\n           FN += 1\n\n    print(\"TP: \"+ str(TP))\n    print(\"FP: \"+ str(FP))\n    print(\"TN: \"+ str(TN))\n    print(\"FN: \"+ str(FN))","7ef7976a":"from sklearn import metrics\ndt = DecisionTreeClassifier(max_depth=35, random_state=1234)\ndt.fit(x_train, y_train)\nprint(\"DT Model built succesfully!\")\ny_pred=dt.predict(x_test)\n#Calculate metrics here from y_test and y_pred\n\nperf_measure(y_test.tolist(), y_pred.tolist())\n# print(y_test)\n# print(y_pred)\ndel dt\ndel y_pred\ngc.collect()\n","eef147c3":"params = {'eta': 0.3,\n          'tree_method': \"hist\",\n          'grow_policy': \"lossguide\",\n          'max_leaves': 1400,  \n          'max_depth': 0, \n          'subsample': 0.9, \n          'colsample_bytree': 0.7, \n          'colsample_bylevel':0.7,\n          'min_child_weight':0,\n          'alpha':4,\n          'objective': 'binary:logistic', \n          'scale_pos_weight':9,\n          'eval_metric': 'auc', \n          'nthread':8,\n          'random_state': 99, \n          'silent': True}\ndtrain = xgb.DMatrix(x_train, y_train)\nwatchlist = [(dtrain, 'train')]\nmodel = xgb.train(params, dtrain, 30, watchlist, maximize=True, verbose_eval=1)\ndel dtrain\ngc.collect()\nprint(\"XGB Model built succesfully!\")\n\ndtest = xgb.DMatrix(x_test)\ny_pred= (model.predict(dtest, ntree_limit=model.best_ntree_limit) > 0.5).astype('int')\n#Calculate metrics here from y_test and y_pred\nperf_measure(y_test.tolist(), y_pred.tolist())\n# print(y_test.tolist())\n# print(y_pred.tolist())\ndel dtest\ndel y_pred\ngc.collect()\n","cde2c062":"predictors = ['ip', 'device', 'app', 'os', 'channel', 'click_day', 'click_hour', 'weekday', 'ip_app_count', 'ip_time_count', 'ip_app_os_count', 'ip_app_os_var_hour', 'ip_app_os_var_weekday', 'ip_day_chn_var_hour', 'ip_app_chn_mean_hour', 'ip_app_chn_mean_weekday', 'ip_app_os_var_day']\ncategorical = ['ip', 'app', 'device', 'os', 'channel', 'click_day', 'click_hour', 'weekday']\nparams = {\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc',\n    'learning_rate': 0.1,\n    'num_leaves': 1400,  \n    'max_depth': 0,  \n    'min_child_samples': 100,  \n    'max_bin': 100,  \n    'subsample': 0.7,  \n    'subsample_freq': 1,  \n    'colsample_bytree': 0.7,  \n    'min_child_weight': 0,  \n    'subsample_for_bin': 200000,  \n    'min_split_gain': 0,  \n    'reg_alpha': 0,  \n    'reg_lambda': 0,  \n   # 'nthread': 8,\n    'verbose': 0,\n    'scale_pos_weight':99 \n    }\n\ndtrain = lgbm.Dataset(x_train[predictors].values, label=y_train.values,\n                      feature_name=predictors,\n                      categorical_feature=categorical\n                      )\ndvalid = lgbm.Dataset(x_test[predictors].values, label=y_test.values,\n                      feature_name=predictors,\n                      categorical_feature=categorical\n                      )\nresults = {}\n\nlgb_model = lgbm.train(params, \n                 dtrain, \n                 valid_sets=[dtrain, dvalid], \n                 valid_names=['train','valid'], \n                 evals_result=results, \n                 num_boost_round=350,\n                 early_stopping_rounds=30,\n                 verbose_eval=True, \n                 feval=None)\ndel dtrain\ngc.collect()\nprint(\"LGB Model built succesfully!\")\ny_pred=(lgb_model.predict(x_test[predictors], num_iteration=lgb_model.best_iteration) > 0.5).astype('int')\n#Calculate metrics here from y_test and y_pred\nperf_measure(y_test.tolist(), y_pred.tolist())\n# print(y_test)\n# print(y_pred)\nprint(\"LGBM: Done\")\ndel y_test\ndel y_pred\ndel x_test\ngc.collect()\n","4c692757":"**Decision Tree Classifer**","efc80a35":"**lgbm**","d3c10b1f":"**XGBoost**","fc060980":"**Adding and Extracting new Features**"}}