{"cell_type":{"9e566ab3":"code","5e1affac":"code","8342b7a5":"code","383b571e":"code","f491d788":"code","8c40476d":"code","eb9ac41d":"code","cf2eb16b":"code","3cf392f7":"code","93da4c41":"code","135a58d1":"code","bd276038":"code","5865f245":"code","2306aa24":"code","bea5a53e":"code","fa0b4581":"code","0749ac55":"code","7099180d":"code","d7f2c39b":"code","00f479fd":"code","bec943c7":"code","160ade09":"code","9e19c65b":"code","ee197723":"code","db12f9d9":"code","ee1a3ce9":"code","69ced6d3":"code","fdf15a44":"code","0da04fd2":"code","50a85cce":"code","92821d66":"code","af72fa4f":"code","5c19d5e6":"code","ab069ea2":"code","74140c62":"code","373a8b95":"code","e230ba62":"code","0f94902a":"code","f2156e8e":"code","795d31fc":"code","48369195":"code","0f4f8788":"code","9f0d6f70":"markdown","7d88a295":"markdown","51eccc4a":"markdown","b618dcb5":"markdown","3dcc216a":"markdown","f7774c44":"markdown","dac14d69":"markdown","436ab49e":"markdown","c65f71ce":"markdown","5bbb7314":"markdown","ddd29aad":"markdown","98c2f37f":"markdown","0df3e8b1":"markdown","f9bf9551":"markdown","ca1c18ef":"markdown","957cbf43":"markdown","5c94b625":"markdown","a892469d":"markdown","cc478fbd":"markdown","77fd129b":"markdown","63e3de81":"markdown","d9e6e381":"markdown","a94d780c":"markdown","cd34d97b":"markdown","8be5cd73":"markdown"},"source":{"9e566ab3":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\/chai-time-data-science\"))","5e1affac":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom matplotlib import rcParams\nrcParams[\"figure.figsize\"] = 16,8\nimport plotly.graph_objects as go\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator","8342b7a5":"# Load Episodes data\nepisode = pd.read_csv(\"\/kaggle\/input\/chai-time-data-science\/Episodes.csv\")\npd.set_option('display.max_columns', 50)","383b571e":"# First 5 row of data\nepisode.head()","f491d788":"# Load image for wordcluoud\nmask = np.array(Image.open(\"\/kaggle\/input\/imagedata\/teavup.jpg\"))","8c40476d":"print(\"Welcome to Chai Time Data Science Show with Sanyam Bhutani.\")\n\nstopwords = set(STOPWORDS)\ntext = \" \".join(review for review in episode[\"episode_name\"])\n\nwc = WordCloud(stopwords=stopwords, mask=mask, max_words=2000, max_font_size=70,colormap=\"Set2\",\n              random_state=42, width=mask.shape[1], height=mask.shape[0], background_color='#151515')\nwc.generate(text)\nplt.imshow(wc, interpolation=\"bilinear\")\nplt.axis('off')\nplt.show()","eb9ac41d":"# Some information of Data\nepisode.info()","cf2eb16b":"anchor = pd.read_csv(\"\/kaggle\/input\/chai-time-data-science\/Anchor Thumbnail Types.csv\")","3cf392f7":"description = pd.read_csv(\"\/kaggle\/input\/chai-time-data-science\/Description.csv\")","93da4c41":"description[\"description\"][0]","135a58d1":"def clean_data(name):\n    # Replace email addresses with 'email'\n    processed = name.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n                                     'emailaddress')\n    \n    \n    # Replace URLs with 'webaddress'\n    processed = processed.str.replace(r'^http\\:\/\/[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(\/\\S*)?$',\n                                      'webaddress')\n\n    # Replace money symbols with 'moneysymb' (\u00a3 can by typed with ALT key + 156)\n    processed = processed.str.replace(r'\u00a3|\\$', 'moneysymb')\n\n    # Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n    processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n                                      'phonenumbr')\n    \n    processed = processed.str.replace(r'^\\[.*?\\]', \" \")\n    # Replace numbers with 'numbr'\n    processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')\n\n    # Remove punctuation\n    processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n\n    # Replace whitespace between terms with a single space\n    processed = processed.str.replace(r'\\s+', ' ')\n\n    # Remove leading and trailing whitespace\n    processed = processed.str.replace(r'^\\s+|\\s+?$', '')\n\n    # change words to lower case - Hello, HELLO, hello are all the same word\n    processed = processed.str.lower()\n    \n    return processed","bd276038":"clean_data = clean_data(description[\"description\"])","5865f245":"from nltk.corpus import stopwords\n\nstop_words = set(stopwords.words(\"english\"))\n\nclean_data = clean_data.apply(lambda x:\" \".join(term for term in x.split() if term not in stop_words))","2306aa24":"ep_des = clean_data\ntext_desc = \" \".join(des for des in ep_des)","bea5a53e":"stopwords = set(STOPWORDS)\nstopwords.update([\"webaddress\", \"https\", \"http\", \"numbr\", \"liqwyd\", \"bhutanisanyamnumbr\"])\n\ndef random_color_func(word=None, font_size=None, position=None, orientation=None, font_path=None, random_state=None):\n    h = int(360.0 * 45.0 \/ 255.0)\n    s = int(100.0 * 255.0 \/ 255.0)\n    l = int(100.0 * float(random_state.randint(60, 120)) \/ 255.0)\n\n    return \"hsl({}, {}%, {}%)\".format(h, s, l)\n\n\nwordcloud = WordCloud(width = 1500, height = 1000, random_state=42, \n                      background_color='white', color_func=random_color_func, collocations=False, stopwords = stopwords, min_font_size=25).generate(text_desc)\n\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.title(\"Description of Episode\", fontweight=\"bold\")\nplt.axis(\"off\")\nplt.show()","fa0b4581":"# anchor.head()","0749ac55":"# Shape of Data\nepisode.shape","7099180d":"hero = episode[\"heroes_gender\"].value_counts()\nprint(f\"Count of episode hero \\n{hero}\")","d7f2c39b":"fig, ax = plt.subplots(figsize=(10, 6))\n\ndef func(pct, allvals):\n    absolute = int(pct\/100.*np.sum(allvals))\n\n    return \"{:.1f}%\\n({:d})\".format(pct, absolute)\nwedges, texts, autotexts = ax.pie(hero, autopct=lambda pct: func(pct, hero),\n                                  textprops=dict(color=\"w\"), colors=[\"#1b3945\", \"#666666\"])\nax.legend(hero.index,\n          title=\"Gender\",\n          loc=\"center left\",\n          bbox_to_anchor=(1, 0, 0.5, 1))\n\nplt.setp(autotexts, size=8, weight=\"bold\")\n\nax.set_title(\"Count of gender\")","00f479fd":"country = episode[\"heroes_location\"].value_counts()\n\nfig, ax = plt.subplots(figsize=(10, 7), subplot_kw=dict(aspect=\"equal\"))\n# ax.style.use(\"Solarize_Light2\")\ncountry_list = [c for c in country.index]\n\nwedges, texts = ax.pie(country, wedgeprops=dict(width=0.5), startangle=40)\n\nbbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\nkw = dict(arrowprops=dict(arrowstyle=\"-\"),\n          bbox=bbox_props, zorder=0, va=\"center\")\n\nfor i, p in enumerate(wedges):\n    ang = (p.theta2 - p.theta1)\/2. + p.theta1\n    y = np.sin(np.deg2rad(ang))\n    x = np.cos(np.deg2rad(ang))\n    horizontalalignment = {-1: \"right\", 1: \"left\"}[int(np.sign(x))]\n    connectionstyle = \"angle,angleA=0,angleB={}\".format(ang)\n    kw[\"arrowprops\"].update({\"connectionstyle\": connectionstyle})\n    ax.annotate(country_list[i], xy=(x, y), xytext=(1.35*np.sign(x), 1.4*y),\n                horizontalalignment=horizontalalignment, **kw)\n\nax.set_title(\"Heros Location\", fontweight=\"bold\")\nprint(f\"Heros location \\n{country}\")","bec943c7":"fig = px.choropleth(episode,locations=\"heroes_location\",locationmode=\"country names\",hover_name=\"heroes\",title=\"ML heores Location in several recording date\", color=\"recording_date\")\nfig.show()","160ade09":"nationality = episode[\"heroes_nationality\"].value_counts()\n\nsns.set_style(\"whitegrid\")\n\nplt.style.use(\"bmh\")\n\nfig, ax = plt.subplots(figsize=(10, 8))\nlabels = episode.heroes_nationality.value_counts().index\nvalues = episode.heroes_nationality.value_counts().values\nwedges, texts, autotexts = ax.pie(values, labels=labels, autopct=\"%.0f%%\")\nax.legend(nationality.index,\n          title=\"Country\",\n          loc=\"center right\",\n          bbox_to_anchor=(1, 0, 0.5, 1))\n\nplt.setp(autotexts, size=10, weight=\"bold\")\nautotexts[0].set_color('white')\nax.set_title(\"Count of Nationality\")","9e19c65b":"fig = px.choropleth(episode,locations=\"heroes_nationality\",locationmode=\"country names\",hover_name=\"heroes\",title=\"ML heores Nationality\")\nfig.show()","ee197723":"sns.countplot(episode[\"heroes_gender\"], hue=episode[\"category\"], palette=\"Set2\")","db12f9d9":"episode[\"heroes_kaggle_username\"] = episode[\"heroes_kaggle_username\"].fillna(\"Unknown\")\nhero_name = episode.heroes_kaggle_username\ntext_name_kag = \" \".join(name for name in hero_name)\nstopwords.update([\"Unknown\"])\n\n\nwordcloud = WordCloud(width = 2000, height = 1000, random_state=1, background_color='black', colormap='Set2', collocations=False, stopwords = stopwords).generate(text_name_kag)\n\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.title(\"Kaggle Username Of Our Heroes\", fontweight=\"bold\")\nplt.axis(\"off\")\nplt.show()","ee1a3ce9":"episode[\"heroes_twitter_handle\"] = episode[\"heroes_twitter_handle\"].fillna(\"Unknown\")\ntwitter_name = episode.heroes_twitter_handle\n\ntext_name_twitte = \" \".join(name for name in twitter_name)\n\n\nwine_mask = np.array(Image.open(\"\/kaggle\/input\/imagedata\/twitter.png\"))\nwine_mask[wine_mask <= 0] = 255\n\nwc = WordCloud(background_color=\"white\", max_words=1000, width=300, height=300,max_font_size=250, mask=wine_mask,\n                contour_width=3, contour_color='firebrick', stopwords=stopwords)\n\n# Generate a wordcloud\nwc.generate(text_name_twitte)\n\n# show\nplt.figure(figsize=[8,8])\nplt.imshow(wc, interpolation='bilinear')\nplt.title(\"Twitter Handle Of Our Heroes\", fontweight=\"bold\")\nplt.axis(\"off\")\nplt.show()","69ced6d3":"fig = px.line(episode, x=\"episode_id\", y=\"episode_duration\", title='Episode Duration')\nfig.show()","fdf15a44":"youtube = episode[[\"episode_id\", \"heroes\", \"youtube_views\", \"youtube_watch_hours\", \"youtube_avg_watch_duration\"]]","0da04fd2":"df_comb=pd.melt(youtube, id_vars=['episode_id'], value_vars=['youtube_views', 'youtube_watch_hours', 'youtube_avg_watch_duration'])\n\npx.line(df_comb, x=\"episode_id\", y=\"value\", color='variable', title=\"episode id vs youtube view, watch hour, avg watch duration\")","50a85cce":"a = youtube[youtube[\"episode_id\"]==\"E27\"]\nname = list(a[\"heroes\"].values)\nlistToStr = ' '.join([str(elem) for elem in name])\nprint(f\"Name of hero1 got high view: {listToStr}\")\n\nb = youtube[youtube[\"episode_id\"]==\"E49\"]\nname1 = list(b[\"heroes\"].values)\nlistToStr1 = ' '.join([str(elem) for elem in name1])\nprint(f\"Name of hero2 got high view: {listToStr1}\")","92821d66":"likeDislike = episode[[\"episode_id\", \"youtube_likes\", \"youtube_dislikes\", \"youtube_comments\"]]","af72fa4f":"df_comb=pd.melt(likeDislike, id_vars=['episode_id'], value_vars=['youtube_likes', 'youtube_dislikes', 'youtube_comments'])\npx.line(df_comb, x=\"episode_id\", y=\"value\", color='variable', title=\"episode id vs like, dislike, comments\")","5c19d5e6":"heroVssubs = episode[[\"episode_id\", \"youtube_subscribers\"]]\n# heroVssubs.plot(figsize=(12,6))\nfig = px.line(heroVssubs, x=\"episode_id\", y=\"youtube_subscribers\", title='Episode Id Vs Channel Subscriber')\nfig.show()","ab069ea2":"herosSubs = episode[[\"heroes\", \"youtube_subscribers\"]].sort_values(\"youtube_subscribers\", ascending=False)[:20]\nherosSubs","74140c62":"fig = px.bar(herosSubs, x=\"heroes\", y=\"youtube_subscribers\", color=\"youtube_subscribers\", title=\"Heros helped to grow channel\")\nfig.show()","373a8b95":"episodeNohero = episode[episode[\"heroes\"].isnull()]\nfig = px.bar(episodeNohero, x=\"episode_id\", y=\"youtube_subscribers\", color=\"youtube_subscribers\", title=\"Chai Time Data Science Show by Sanyam Bhutani (Special Episodes)\")\nfig.show()","e230ba62":"def make_str(val, ep_id):\n    ep = episodeNohero[episodeNohero[\"episode_id\"]==ep_id]\n    a = list(ep[val].values)\n    listToStr = ' '.join([str(elem) for elem in a])\n    return listToStr\n\nb = make_str(\"episode_name\", \"E69\")\nc = make_str(\"episode_id\", \"E69\")\nd = make_str(\"youtube_subscribers\", \"E69\")\nprint(f\"Episode Name: {b} \\nEpisode Id: {c} \\nYoutube Subscriber: {d}\")","0f94902a":"impressVsnon = episode[[\"episode_id\", \"youtube_impression_views\", \"youtube_nonimpression_views\"]]\nimp_non=pd.melt(impressVsnon, id_vars=['episode_id'], value_vars=['youtube_impression_views', 'youtube_nonimpression_views'])\npx.line(imp_non, x=\"episode_id\", y=\"value\", color='variable')","f2156e8e":"listener = episode[[\"episode_id\", \"spotify_listeners\", \"apple_listeners\"]]","795d31fc":"fig = go.Figure()\nfig.add_trace(go.Bar(\n    x=listener[\"episode_id\"],\n    y=listener[\"spotify_listeners\"],\n    name='spotify',\n    marker_color='lightslategrey'\n))\nfig.add_trace(go.Bar(\n    x=listener[\"episode_id\"],\n    y=listener[\"apple_listeners\"],\n    name='apple',\n    marker_color='crimson'\n))\n\nfig.update_layout(\n    title='Listener from apple and spotify',\n    xaxis_tickfont_size=14,\n    yaxis=dict(\n        title='Count of listener',\n        titlefont_size=16,\n        tickfont_size=14\n    )\n)","48369195":"apple = episode[[\"episode_id\", \"apple_listened_hours\", \"apple_avg_listen_duration\"]]\napple_avg=pd.melt(apple, id_vars=['episode_id'], value_vars=['apple_listened_hours', 'apple_avg_listen_duration'])\npx.line(apple_avg, x=\"episode_id\", y=\"value\", color='variable')","0f4f8788":"# different flavour tea during recording time\nsns.set_style(\"whitegrid\")\nbars = sns.countplot(episode[\"flavour_of_tea\"], hue=episode[\"recording_time\"])\nplt.legend(loc=\"best\")\nplt.ylabel(\"Flavour of tea count\")\nplt.xlabel(\"Recording time\")\nfor p in bars.patches:\n    bars.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.10, p.get_height()+0.1), ha='center', va='bottom', color= 'black')","9f0d6f70":"# Kaggle Heroes Username","7d88a295":"# Episode 27 got 183 likes and 16 comments and Name of hero: Jeremy Howard","51eccc4a":"# Like, Dislike, Comments","b618dcb5":"# Twitter Handle Of Heroes","3dcc216a":"# Load some essential packages","f7774c44":"## Count of male and female in several episodes","dac14d69":"# Episode Id And Channel Subscriber","436ab49e":"# Impression View and nonimpression views","c65f71ce":"## episode 27 got high view, high watch hour","5bbb7314":"# Youtube Subscribe in special episodes","ddd29aad":"## Heros Location","98c2f37f":"# Less researcher, most of the male heroes are kaggler","0df3e8b1":"![ctds-1.png](attachment:ctds-1.png)\n\n# Interviews with Kagglers, Researchers and Data Science Practitioners \n\n\n[Youtube Link](https:\/\/www.youtube.com\/channel\/UCRjtBP-o5FbgRzX2BHQEFtQ)","f9bf9551":"# Some details of special episode","ca1c18ef":"# By other platform show listener","957cbf43":"# heroes who helped to grow channels","5c94b625":"# episode view, watch hour, avarage watch hour","a892469d":"# Episode Duration of different episodes","cc478fbd":"# Male and female in different work platform","77fd129b":"# Interview with kaggler, ML Engineer, Data Scientist\n# Talk about Data Science, Lesson etc.","63e3de81":"# There are a lot of spotify user\n# Listener from different platform are decreaseing day by day\n# CTDS.show has to hold on spotify market...to reach more","d9e6e381":"# I think Sanyam Bhutani likes Kesar Rose at night Tea and Masala Chai at morning... :p hahaha","a94d780c":"# Conclusion : Day by day channel will grow up. One things in mind that, Channel should make video for different tips and trick for new data analyst or who is passionate in data science. Different live project with expert to gather viewers. More viewer, more likes, more comments, more subscriber and also should be live from Facebook and instagram","cd34d97b":"# Chai Time Data Science Show -- Sanyam Bhutani.","8be5cd73":"## Heroes Nationality "}}