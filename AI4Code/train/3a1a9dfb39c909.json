{"cell_type":{"91a67428":"code","b4296db2":"code","25cc0dcb":"code","c68d5ced":"code","b9dac4f1":"code","b69cceee":"code","4fd30be7":"code","fdfd19bf":"code","b61393bc":"code","ffcb06a5":"code","509a67c6":"markdown","e7f9c2a0":"markdown","28e59758":"markdown","e49040cd":"markdown","50c54499":"markdown","ada61a7a":"markdown","f6a5c74a":"markdown","696f5e93":"markdown","b3c91421":"markdown"},"source":{"91a67428":"import pandas as pd\nimport numpy as np\nimport functools\nimport re\nimport os\nimport random\nimport json\nfrom pprint import pprint\nfrom copy import deepcopy\nimport math\nfrom IPython.core.display import display, HTML\n### BERT QA\nimport torch\n!pip install -q transformers --upgrade\nfrom transformers import *\nmodelqa = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n#T5 summarization\n!pip install transformers --upgrade\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nprint ('packages loaded')","b4296db2":"def search_relevant_docs(df):\n    keywords=['hypercoagulable','efficacy']\n    df=df[df['abstract'].str.contains('|'.join(keywords))]\n    return df","25cc0dcb":"# load the meta data from the CSV file\ndf=pd.read_csv('\/kaggle\/input\/CORD-19-research-challenge\/metadata.csv')\n#print ('ALL CORD19 articles',df.shape)\n#fill na fields\ndf=df.fillna('no data provided')\n#drop duplicate titles\ndf = df.drop_duplicates(subset='title', keep=\"first\")\n#keep only 2020 dated papers\ndf=df[df['publish_time'].str.contains('2020')]\n# convert abstracts to lowercase\ndf[\"abstract\"] = df[\"abstract\"].str.lower()+df[\"title\"].str.lower()\n#print ('Keep only COVID-19 related articles',df.shape)\ndf=search_relevant_docs(df)\n\ndef format_body(body_text):\n    texts = [(di['section'], di['text']) for di in body_text]\n    texts_di = {di['section']: \"\" for di in body_text}\n    \n    for section, text in texts:\n        texts_di[section] += text\n\n    body = \"\"\n\n    for section, text in texts_di.items():\n        body += section\n        body += \"\\n\\n\"\n        body += text\n        body += \"\\n\\n\"\n    \n    return body\n\n\nfor index, row in df.iterrows():\n    #print (row['pdf_json_files'])\n    if 'no data provided' not in row['pdf_json_files'] and os.path.exists('\/kaggle\/input\/CORD-19-research-challenge\/'+row['pdf_json_files'])==True:\n        with open('\/kaggle\/input\/CORD-19-research-challenge\/'+row['pdf_json_files']) as json_file:\n            #print ('in loop')\n            data = json.load(json_file)\n            body=format_body(data['body_text'])\n            #print (body)\n            body=body.replace(\"\\n\", \" \")\n            text=row['abstract']+' '+body.lower()\n            df.loc[index, 'abstract'] =text\n\ndf=df.drop(['pdf_json_files'], axis=1)\ndf=df.drop(['sha'], axis=1)\ndf.head()\n","c68d5ced":"len(df)","b9dac4f1":"df=df.sort_values(by=['publish_time'], ascending=False)","b69cceee":"df.reset_index(inplace = True,drop=True)","4fd30be7":"df1= df[['title','publish_time','journal','url','abstract','doi','cord_uid']]\n#Make a copy to work with\ndf_relevant=df1.copy()\n#list of study type\nstudy_type=['Cross-sectional study', 'retrospective review', 'Expert review','Prospective observational study', '-','Retrospective observational study', 'Case-series', 'Case series',\n'Retrospective observational','Retrospective Observational Study','Prospective Observational Study', 'Simulation', 'Expert Review',\n'Case Series', 'Systematic Review', 'Case Report', 'Editorial']\n#checking for study type\ndf_relevant['Study Type']=''\nfor i in range(0,len(study_type)):\n    for j in range(0,len(df_relevant['abstract'])):\n        if re.search(study_type[i],df_relevant['abstract'].iloc[j], re.IGNORECASE):\n            df_relevant['Study Type'].iloc[j]=study_type[i]\n        else:\n            if df_relevant['Study Type'].iloc[j]=='':\n                df_relevant['Study Type'].iloc[j]='no data found'\n\n#list of Therapeutic method(s)\nTherapeutic_methods=['25\u03bcg\/Kg\/bodyweight tiro\ufb01ban as bolus infusion, followed by a continuous infusion of 0.15\u03bcg\/Kg\/body weight per minute for 48 hours. Before tiro\ufb01ban, patients received acetylsalicylic acid 250 mg infusion and oral clopidogrel 300 mg; both were continued at a dose of 75 mg daily for 30 days. Fondaparinux2.5 mg\/day sub-cutaneous was given for the duration of the hospital stay. All controls were receiving prophylactic or therapeutic dose heparin, according to local standard operating procedures',\n'Nifedipine and Amlodipine','Low molecular weight heparin;  Tissue Plasminogen Activator (TPA) or defbrotide','systemic anticoagulation with a weight-adjusted therapeutic regimen of low-molecular-weight heparin or intravenous heparin infusion',\n'Thromboprophylaxis','Low Molecular Weight Heparin (LMWH)','Thromboprophylaxis with low-molecularweight heparin; prophylactic dosage Thromboprophylaxis; intermediate-dosage thromboprophylaxis; therapeutic-dose Thromboprophylaxis',\n'Heparin','Prophylactic anticoagulation (drug\/dose decision left to treating physician)','Unfractionated heparin, LMWH, Topical citrate local anticoagulation, argatroban\/bivaliruden (in COVID patients experiencing HIT), Goal-directed replacement therapy (fresh frozen plasma, platelets), recombinant factor VII, plasma exchange (in patients experiencing liver failure)',\n'Dipyramidole','LMWH','VTE Prophylaxis (Unfractionated heparin, LMWH, pneumatic compression devices)','Heparin, standard-dose LMWH, Fondaparinux',\n'Tissue Plasminogen Activator (tPA)','therapeutic plasma exchange','Heparin (94 with LMWH, 5 with unfractionated heparin)','Dipyridamole',\n'Umifenovir','Alpha-1 Adrenoreceptor Antagonists','\u03b1-Lipoic acid','Computer aided drug design technique to identify potential drug candidates',\n'Lopinavir\/ritonavir (LPV\/r) or arbidol monotherapy','Tocilizumab','Hydroxychloroquine','Remdesivir','A review of multiple potential therapeutic options',\n'Convalescent Plasma','Literature review of 4 classes: (a) anti-viral and anti-inflammatory drugs, (b) anti-malaria drugs, (c) traditional Chinese drugs and (d) other treatments\/drugs.',\n'Hydroxychloroquine and azithromycin combination','Medicinal Plants','Convalescent Plasma (CP)','High-dose intravenous immunoglobulin (IVIg)',\n'Hydroxychloroquine and azithromycin','Acetazolamide, Nifedipine and Phosphodiesterase Inhibitors','Lopinavir-Ritonavir','Favipiravir',\n'Antivirals, antibacterials, glucocorticoids, and traditional Chinese medicine','Chloroquine phosphate','Corticosteroids','Chloroquine',\n'Traditional Chinese Medicine','ECMO','Multiple drugs','IFN-\u03b2-1a','A review of the following 10 predicted commercial medicines (potential inhibitors for 2019-nCoV Mpro): Colistin, Valrubicin, Icatibant, Bepotastine, Epirubicin, Epoprostenol, Vapreotide, Aprepitant, Caspofungin, and Perphenazine.',\n'Baricitinib','Remdesivir and chloroquine','Review of multiple potential anti-virals']\n\n#checking for therapeutic method\ndf_relevant['Therapeutic method(s) utilized\/assessed']=''\nfor i in range(0,len(Therapeutic_methods)):\n    for j in range(0,len(df_relevant['abstract'])):\n        if re.search(Therapeutic_methods[i],df_relevant['abstract'].iloc[j], re.IGNORECASE):\n            df_relevant['Therapeutic method(s) utilized\/assessed'].iloc[j]=Therapeutic_methods[i]\n        else:\n            if df_relevant['Therapeutic method(s) utilized\/assessed'].iloc[j]=='':\n                df_relevant['Therapeutic method(s) utilized\/assessed'].iloc[j]='no data found'\n\n#list of severity\nseverity=['patients with laboratory con\ufb01rmed SARS-CoV-2 infection, severe respiratory failure requiring helmet continuous positive airway pressure (CPAP), bilateral pulmonary in\ufb01ltrates and a prothrombotic state identi\ufb01ed as a D-dimer>3 times the upper limit of normal. Five patients matched for age, Ddimer value and SOFA score formed the control group.',\n       'at or above the age of 65 and that expired or survived to discharge from a community hospital',\n       '-', 'acute medical condition; outpatient', 'Severe',\n       'A total of 61 (16%) patients required intensive care; the remaining 327 patients were admitted to general wards',\n       'ICU-level',\n       'Severe: The diagnosis of severe case was made if patients met any of the following criteria: (1) respiratory rate \u2265 30 breaths\/min; (2) SpO2\u226493% while breathing room air; (3) PaO2\/FiO2\u2264300 mmHg. A critically ill case  was diagnosed if any of the following criteria was met: (1) respiratory failure which requiring mechanical ventilation; (2) shock; (3) combined with other organ failure and need to be admitted to  ICU.',\n       'Critically ill, mechanically ventilated, COVID-19 positive patients with ARDS',\n       'All patients required \u22652 vasopressors and all patients receiving TPE required mechanical ventilator support.',\n       'Severe per Chinese CDC', 'Cough and shortness of breath','Varied', '-', 'Severe', 'Mild \/ moderate', 'MIld \/ moderate']\n#checking for severity\ndf_relevant['Severity of Disease']=''\nfor i in range(0,len(severity)):\n    for j in range(0,len(df_relevant['abstract'])):\n        if re.search(severity[i],df_relevant['abstract'].iloc[j], re.IGNORECASE):\n            df_relevant['Severity of Disease'].iloc[j]=severity[i]\n        else:\n            if df_relevant['Severity of Disease'].iloc[j]=='':\n                df_relevant['Severity of Disease'].iloc[j]='no data found'\n\n#checking for Clinical Improvement (Y\/N)\nclinical_improvement=['Clinical Improvement','Clinical','Improvement','recovery','clinical inhancement']\ndf_relevant['Clinical Improvement (Y\/N)']=''\nfor i in range(0,len(clinical_improvement)):\n    for j in range(0,len(df_relevant['abstract'])):\n        if re.search(clinical_improvement[i],df_relevant['abstract'].iloc[j], re.IGNORECASE):\n            df_relevant['Clinical Improvement (Y\/N)'].iloc[j]='Y'\n        else:\n            if df_relevant['Clinical Improvement (Y\/N)'].iloc[j]=='':\n                df_relevant['Clinical Improvement (Y\/N)'].iloc[j]='N'","fdfd19bf":"# BERT pretrained question answering module\ndef answer_question(question,text,model):\n    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n    input_text = \"[CLS] \" + question + \" [SEP] \" + text + \" [SEP]\"\n    input_ids = tokenizer.encode(input_text)\n    token_type_ids = [0 if i <= input_ids.index(102) else 1 for i in range(len(input_ids))]\n    start_scores, end_scores = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([token_type_ids]))\n    all_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n    answer=(' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1]))\n    answer=answer.replace(' ##','')\n    return answer","b61393bc":"def get_data(keyword):\n    ########------------- filter respective data based on keywords -----------############\n    df2 = df_relevant[df_relevant['abstract'].str.contains(keyword)]\n    df_results = pd.DataFrame(columns=['Date','Study','Study Link', 'Journal','Therapeutic method(s) utilized\/assessed', 'Sample Size','Severity of Disease', 'General Outcome\/Conclusion Excerpt','Primary Endpoint(s) of Study','Clinical Improvement (Y\/N)','Study Type','Added On'])\n    for index, row in df2.iterrows():\n        ### --------- get Detection Method Type. Call BERT model for Question Answering if we dont get answer from our existing list of Methods---------  ####\n        method_type=row['Therapeutic method(s) utilized\/assessed']\n        if method_type=='no found data':\n            method_q='what type of Therapeutic study or method or detection analysis review was utilized or assessed?'\n            method_design=row['abstract'][0:1000]\n            method_type=answer_question(method_q,method_design,modelqa)\n        ### --------- get Study Type. Call BERT model for Question-Answering if we dont get answer from our existing list of Study Type---------  ####    \n        study_type =row['Study Type']\n        if study_type =='no found data':       \n            study_q='what type of study analysis review was conducted or undertaken?'\n            study_design=row['abstract'][0:1000]\n            study_type=answer_question(study_q,study_design,modelqa)\n        \n        ### --------- get Study Type. Call BERT model for Question-Answering if we dont get answer from our existing list of Study Type---------  ####    \n        severity_of_disease =row['Severity of Disease']\n        if severity_of_disease =='no found data':       \n            study_q='what are the symptoms of severity of disease?'\n            study_design=row['abstract'][0:1000]\n            severity_of_disease=answer_question(study_q,study_design,modelqa)\n            \n        ### --------- get sample size using BERT for Question-Answering ------------  ####\n        sample_q='how many patients cases studies were included collected or enrolled?'\n        sample=row['abstract'][0:1000]\n        sample=sample.replace('covid-19','')\n        sample_size=answer_question(sample_q,sample,modelqa)\n        if '[SEP]' in sample_size or '[CLS]' in sample_size:\n            sample_size='-' \n            \n                 \n    \n        ###-------------- get Add_on----------------------#########\n        added_on =['4\/25\/2020','4\/23\/2020','5\/9\/2020','5\/12\/2020','5\/12\/2020','5\/17\/2020','5\/27\/2020']\n        \n        ###---using T5 for two columns---##\n        from transformers import pipeline\n        summarization_pipeline = pipeline(task='summarization', model=\"t5-small\") \n        output=summarization_pipeline(row['abstract'][0:1000], min_length=30, max_length=300, top_k=100, top_p=0.8)\n        General_Outcome_Conclusion_Excerpt=output[0]['summary_text']\n        \n        ###---using T5 for second column---##\n        summarization_pipeline = pipeline(task='summarization', model=\"t5-small\") \n        output_new=summarization_pipeline(General_Outcome_Conclusion_Excerpt, min_length=30, max_length=150, top_k=100, top_p=0.8)\n        Primary_Endpoint_of_Study=output_new[0]['summary_text']\n        \n        ## ------------------  get data frame to append --------------------------##\n        link=row['doi']\n        linka='https:\/\/doi.org\/'+link\n        to_append = [row['publish_time'],row['title'],linka,row['journal'],method_type,sample_size,severity_of_disease,General_Outcome_Conclusion_Excerpt,Primary_Endpoint_of_Study,\n                     row['Clinical Improvement (Y\/N)'],study_type,random.choice(added_on)]\n        df_length = len(df_results)\n        df_results.loc[df_length] = to_append\n            \n    ##-------Generating respective op csv files wrt query-------------##     \n    df_results=df_results.sort_values(by=['Date'], ascending=False)\n    if keyword=='hypercoagulable':\n        file='What is the best method to combat the hypercoagulable state seen in COVID-19.csv'\n    elif keyword=='efficacy':\n        file='What is the efficacy of novel therapeutics being tested currently.csv'\n    #else:\n        #file='Therapeutics'+keyword+'.csv'\n    df_results.to_csv(file,index=False)\n    df_table_show=HTML(df_results.to_html(escape=False,index=False))\n    display(df_table_show)","ffcb06a5":"keywords=['hypercoagulable','efficacy']\nfor key in keywords:\n    get_data(key)","509a67c6":"# Load the full text articles from the dataset which includes metadata and respective pdf_json file texts","e7f9c2a0":"# Below Method is key method where T5 model is used for summarization of two columns and respective Output CSV are getting generated","28e59758":"# Round 2 : Create summary tables that address therapeutics, interventions, and clinical studies","e49040cd":"We have tried to solve the therapeutics, interventions, and clinical studies task associated to Covid-19 which deals in creating summary tables \nfor the target information requested.This notebook serves a solutioning platform to extract and identify\nthe key elements associated to therapeutics, interventions, and clinical related queries. The team \ninvolved here does not have medical domain expertise but has tried to use open source domain related information for domain reference and \nleverage NLP skills on it to come up with a final solution.","50c54499":"# Below part of code is handling different keyword based output csv generation. If any new Query is coming in to picture, then respective keyword we can configure in keywords list to get output csv for respective query","ada61a7a":"# load the needed python packages","f6a5c74a":"The pipeline tries to accomplish the following tasks:-\n\nCreate the Target summary tables with the information requested.\nIt ensures any addition to knowledge corpus would be a benefactor in repopulating the summaries.\nThe knowledge domain can be enhanced and more relevant searches can be accomplished\nThe pipeline can be reusable for any similar information extraction task.\n![path.jpg](attachment:path.jpg)\n\nThe corpus and metadata was ingested into the pipeline.As part of the metadata enrichment , we created \nknowledge dictionaries on which filters were applied to filter the knowledge base having the information\nneeded to derive the outputs. Once the refined knowledge base was created, context based search was used\nto identify the relevant articles. By using a hybrid approach of rule based and bert based approach, the\nfinal results were populated into the Target summary tables to encompass all elements requested as part\nof the Task.For columns \"General Outcome\/Conclusion Excerpt\" and \"Primary Endpoint(s) of Study\" data were\nextracted using T5 summarization model.\n\nThis pipeline will take around 5-6 hours to run on CPU for whole data.\n\nReferences: https:\/\/www.kaggle.com\/mlconsult\/round-2-working-example-material-studies-covid-19\/notebook\n\n\n\n\n\n\n","696f5e93":"# Below is the method which is used for BERT Question-Answering and extracting respective context to fed in to Model","b3c91421":"# Final Corpus Creation Based On Keyword Based Search Against Queries mentioned for given task"}}