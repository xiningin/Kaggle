{"cell_type":{"655cc7a2":"code","ecdd43e9":"code","139a52b8":"code","ccf9218a":"code","0c665744":"code","60755046":"code","40ed31e5":"code","69dea4e4":"code","3257303e":"code","ea35066a":"code","ca332ea8":"code","6e0d923d":"code","34798cfa":"code","6cbe1455":"code","3ca196af":"code","682cc51e":"code","d1a75d8a":"code","cf582c31":"code","b6d243f2":"code","ef41e786":"code","0b2cf2d1":"code","7812d6e3":"code","b10aea56":"code","695104b6":"code","0cba22df":"code","6dadabf1":"code","38561f50":"code","c8223ce8":"code","0b3b3301":"code","b752edb3":"code","ca17a3e9":"code","d2452013":"code","e1bf0cf9":"code","ec18f959":"code","fa5625f8":"code","fde2c850":"code","7cbb1255":"code","6248408a":"code","a2041e80":"code","e5c336d5":"code","b964eea7":"code","cb364073":"code","dc6f232a":"code","517f06ad":"code","d0565d49":"code","c9dba8d9":"code","338d0e7c":"code","8f468267":"code","bc1127c0":"code","79a97337":"code","f7266735":"code","85d8f626":"code","08b24bef":"code","868f0f2a":"code","32ff5886":"code","614fc4a2":"code","4f18eb02":"code","b029ac6c":"code","18a3cf17":"markdown","8d3d3f6f":"markdown","fd9cd220":"markdown","37c863e0":"markdown","6924493c":"markdown","1375b171":"markdown","9d8da1a3":"markdown","21572637":"markdown","254b983b":"markdown","a292091b":"markdown","75649bb4":"markdown","f874fc59":"markdown","ee0e8721":"markdown","7dbade5d":"markdown","fd16112f":"markdown","b48fd9bb":"markdown","0c6691bc":"markdown","b06f17b0":"markdown","bc51784b":"markdown","8fc5d681":"markdown","54bccd52":"markdown","54ca840e":"markdown"},"source":{"655cc7a2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nprint (os.listdir('..\/input\/udacity-mlcharity-competition'))\n# Any results you write to the current directory are saved as output.","ecdd43e9":"import matplotlib.pyplot as plt\nimport seaborn as sns\n","139a52b8":"df_train=pd.read_csv('..\/input\/udacity-mlcharity-competition\/census.csv')\ndf_test = pd.read_csv(\"..\/input\/udacity-mlcharity-competition\/test_census.csv\").drop('Unnamed: 0',axis=1)\n","ccf9218a":"df_train.info()","0c665744":"## Drop the useless columns","60755046":"df_train.drop(columns=['education-num'],inplace=True)","40ed31e5":"df_train.head()","69dea4e4":"for column in df_train.columns:\n    print(column, df_train[column].unique())","3257303e":"n_records = len(df_train)\nn_records","ea35066a":"n_greater_50k = len(df_train[df_train['income'] == '>50K'])\nn_greater_50k","ca332ea8":"## Visualization of income level based on sex and education","6e0d923d":"sns.set(style=\"whitegrid\", color_codes=True)\nsns.catplot(\"sex\", col='education_level', data=df_train, hue='income', kind=\"count\", col_wrap=4);","34798cfa":"income=df_train.income.map({'<=50K': 0, '>50K':1})\nincome.head()","6cbe1455":"#Age distribution","3ca196af":"plt.hist(df_train.age,bins=20,color='c')\nplt.title('Histogram: Age')\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.show","682cc51e":"income.unique()\n","d1a75d8a":"df_train.head(3)","cf582c31":"hist_above_50=plt.hist(df_train[df_train.income==\">50K\"].age.values,10,facecolor='c')\nplt.title('Age distribution above 50K earners')\nplt.xlabel('Age')\nplt.ylabel('Frequency')","b6d243f2":"hist_above_50=plt.hist(df_train[df_train.income==\"<=50K\"].age.values,10,facecolor='c')\nplt.title('Age distribution above 50K earners')\nplt.xlabel('Age')\nplt.ylabel('Frequency')","ef41e786":"df_train[df_train.income=='>50K'].groupby('workclass').workclass.count().sort_values().plot(kind='bar')\n","0b2cf2d1":"df_train.head()","7812d6e3":"df_train_with_dummies = pd.get_dummies(df_train,columns=['sex','workclass','education_level','marital-status','occupation','relationship','race','native-country','income'], sparse=True)","b10aea56":"# Since the data is splitted to numerical fetaures and categorial one \n#so let's normailze \n#the categorial ones","695104b6":"features_raw.head()","0cba22df":"income_raw.head()","6dadabf1":"df_train.head()","38561f50":"features_raw.isnull().sum()","c8223ce8":"## good no null values!","0b3b3301":"df_train.head()","b752edb3":"df_train_with_dummies = pd.get_dummies(df_train,columns=['sex','workclass','education_level','marital-status','occupation','relationship','race','native-country','income'], sparse=True)","ca17a3e9":"df_train_with_dummies.head()","d2452013":"df_train_with_dummies.head()","e1bf0cf9":"from sklearn.preprocessing import MinMaxScaler\n\n\nscaler = MinMaxScaler()\nnumerical = ['age',  'capital-gain', 'capital-loss', 'hours-per-week']\ndf_train_with_dummies[numerical]=scaler.fit_transform(df_train_with_dummies[numerical])\n\n# Show an example of a record with scaling applied\n","ec18f959":"features_raw =df_train_with_dummies.drop(columns=['income_<=50K','income_>50K'],axis=1)\n\n","fa5625f8":"def  get_value(x):\n    if x=='>50K':\n     return 1\n    else:\n        return 0","fde2c850":"\ndf_train['new_income'] = df_train['income'].apply(get_value)\nnew_income=df_train['new_income']","7cbb1255":"# import the modules \nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(features_raw, new_income, test_size = 0.2, random_state = 0)\nprint(len(x_train))\nprint(len(x_test))\nprint(len(features_raw))\n\n\n","6248408a":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n# take a look how the values was before and after the scalling \n\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test)\n","a2041e80":"print(\"Training set has {} samples.\".format(x_train.shape[0]))\nprint(\"Testing set has {} samples.\".format(x_test.shape[0]))","e5c336d5":"from sklearn.linear_model import LinearRegression\n\nlinear_model = LinearRegression(fit_intercept=True).fit(x_train, y_train)","b964eea7":"print(\"Training_score : \" , linear_model.score(x_train, y_train))","cb364073":"y_pred = linear_model.predict(x_test)","dc6f232a":"from sklearn.metrics import r2_score\n\nprint(\"Testing_score : \", r2_score(y_test, y_pred))","517f06ad":"df_pred_actual = pd.DataFrame({'predicted': y_pred, 'actual': y_test})\n\ndf_pred_actual.head(10)","d0565d49":"## May be the linear regression is not working well ","c9dba8d9":"## Try logistic regression as a classification model","338d0e7c":"from sklearn.linear_model import LogisticRegression","8f468267":"model1 = LogisticRegression(random_state=0)\n","bc1127c0":"model1.fit(x_train,y_train)","79a97337":"print ('score for logistic regression  {}'.format(model1.score(x_test, y_test)))","f7266735":"# peformance metrics\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score","85d8f626":"# performance metrics\n# accuracy\nprint ('accuracy for logistic regression {}'.format(accuracy_score(y_test, model1.predict(x_test))))\n# confusion matrix\nprint('confusion matrix for logistic regression {}'.format(confusion_matrix(y_test, model1.predict(x_test))))\n# precision \nprint ('precision for logistic regression {}'.format(precision_score(y_test, model1.predict(x_test))))\n# precision \nprint ('recall for logistic regression {}'.format(recall_score(y_test, model1.predict(x_test))))","08b24bef":"from sklearn.neighbors import RadiusNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB","868f0f2a":"from sklearn.neighbors import KNeighborsClassifier\nclassifier = KNeighborsClassifier(n_neighbors = 5)\nclassifier.fit(x_train,y_train)","32ff5886":"\ncm = confusion_matrix(y_test, classifier.predict(x_test))\ncm","614fc4a2":"print(\"model accuracy : {:.4f}\".format(classifier.score(x_test, y_test)))","4f18eb02":"from sklearn.naive_bayes import GaussianNB\nclassifier2 = GaussianNB()\nclassifier2.fit(x_train, y_train)","b029ac6c":"print(\"model accuracy : {:.4f}\".format(classifier2.score(x_test, y_test)))","18a3cf17":"*1. get the unique values in the data*","8d3d3f6f":"### Number of records where individual's income is more than $50,000**","fd9cd220":"### First we need to split our data to train and test data ..","37c863e0":"**Most age between 30 and 35 **","6924493c":"## 3.Preprocessing the data","1375b171":"As we see most of people earn greater than 50,000$ lies in the category private jobs","9d8da1a3":"### use get dummies for rest of columns","21572637":"![****](http:\/\/)the features_raw and income_raw are the features columns and the goal columns","254b983b":"### Normalize the numerical feature for a better model\n\n\n\n","a292091b":"Good score using logistic regression is high!!!","75649bb4":"**Create a histogram for people older in age and see thier effect on the income**","f874fc59":"**histogram for people less than 50,000$ earners**","ee0e8721":"### Second:using conf matrix","7dbade5d":"## 1.Taking a look to the data","fd16112f":"### Total number of records\n\n\n","b48fd9bb":"### Handling categorial data","0c6691bc":"## Visualizations","b06f17b0":"For the diversity of the values i will apply standard scalar","bc51784b":"## First:building a simple linear regression model","8fc5d681":"## Now the data is ready for modeling","54bccd52":"## The next phase is building classification model using  k-nearest neighbors and Naive Bayes","54ca840e":"**Getting some useful insights** "}}