{"cell_type":{"e613735b":"code","93e4055b":"code","4a7b0d2a":"code","57348fbe":"code","e486ec13":"code","3c641878":"code","353838ac":"code","53f28b75":"code","78825164":"code","de2cf8e3":"code","8bcccc0d":"code","5fdeee0a":"code","231cc87a":"code","d29373e6":"code","0def1bf2":"code","fc44052d":"code","49a8042d":"code","d0729246":"code","42334915":"code","be29eb35":"code","592195a5":"code","be94a884":"code","1017c936":"code","20a1b9b4":"code","64da41fd":"code","405a766e":"code","a4a2d4d2":"code","2e88e111":"code","87135be9":"code","86b46f02":"code","d5187a4c":"code","ca617729":"code","8a041251":"code","e32e4a28":"code","1b1fb8c8":"code","3e0249b9":"code","71b34588":"code","508c4d62":"code","964c04d2":"code","bfed804b":"code","df0687ff":"code","4919de13":"markdown","7b7028fe":"markdown","9a0b5647":"markdown","4415a2b8":"markdown","cf42c9a7":"markdown","656ff458":"markdown","147758f6":"markdown","ba81e8d4":"markdown"},"source":{"e613735b":"import os\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas_profiling\nfrom collections import Counter\nfrom scipy import stats\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import (\n    RandomForestClassifier,\n    ExtraTreesClassifier,\n    AdaBoostClassifier,\n    GradientBoostingClassifier\n)\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\nfrom xgboost import XGBClassifier\nfrom vecstack import stacking\n\nprint(os.listdir('..\/input'))","93e4055b":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\ntrain.columns = train.columns.str.lower()\ntest.columns = test.columns.str.lower()\n\ntest_id = test['passengerid']\n\ndataset = pd.concat([train, test], axis=0)","4a7b0d2a":"dataset_backup = dataset.copy(deep=True)","57348fbe":"dataset = dataset_backup.copy(deep=True)","e486ec13":"pd.DataFrame([dataset.columns, dataset.dtypes, dataset.isnull().sum(), dataset.nunique()]).T","3c641878":"sns.pairplot(train)","353838ac":"numerical = ['age', 'fare', 'sibsp', 'parch']\ncategorical = ['cabin', 'embarked', 'pclass', 'sex']","53f28b75":"fig, ax = plt.subplots(1, 4, figsize=(15, 5))\nfig.tight_layout()\nax = iter(ax.flatten())\nfor feat in numerical:\n    sns.boxplot(x='survived', y=feat, data=train, ax=next(ax))\n    \n# age and age bins for more obvious correlation?\n# family_size and is_alone feature?","78825164":"fig, ax = plt.subplots(1, 2, figsize=(15, 5))\nfig.tight_layout()\nax = iter(ax.flatten())\nfor feat in ['sibsp', 'parch']:\n    sns.barplot(x=feat, y='survived', data=train, ax=next(ax))","de2cf8e3":"# some basic cleaning and feature engineering\n\n# probably more realistic if filled separately for train and test sets, since this actually \"leaks\" test data into train\n# maybe fill in per category most correlated with age\nmean_age = dataset.age.mean()\nstd_age = dataset.age.std()\ndataset.loc[dataset.age.isnull(), 'age'] = np.random.randint(mean_age - std_age, mean_age + std_age, len(dataset[dataset.age.isnull()]))\n# separate into bins\ndataset['age_bin'] = pd.cut(dataset.age, bins=list(range(0, int(train.age.max()) + 10, 5)), include_lowest=True)\n# dataset['age_bin'] = dataset.age_bin.apply(lambda x: f'>{int(x.left)} - {int(x.right)}').apply(lambda x: f'>0{x[1:]}' if len(x[1:].split(' - ')[0]) == 1 else x ).astype(str)\n\n# fare bin\ndataset['fare'] = dataset.fare.fillna(dataset.fare.median()).apply(lambda x: np.log1p(x))\ndataset['fare_bin'] = pd.cut(dataset.fare, bins=30, include_lowest=True)\n\n# family size\ndataset['family_size'] = dataset.parch + dataset.sibsp + 1\n\n# is alone\ndataset['is_alone'] = dataset.family_size == 1","8bcccc0d":"fig, ax = plt.subplots(1, 4, figsize=(15, 5))\nax = iter(ax.flatten())\ndata = dataset[~dataset.passengerid.isin(test_id)][['age_bin', 'fare_bin', 'family_size', 'is_alone', 'survived']]\nfor feat in data.columns[:-1]:\n    labels = sorted(data[feat].unique())\n    g = sns.barplot(x=feat, y='survived', data=data, order=labels, ax=next(ax))\n    g.set_xticklabels(labels=labels, rotation=90)","5fdeee0a":"fig, ax = plt.subplots(1, 3, figsize=(15, 5))\nfig.tight_layout()\nax = iter(ax.flatten())\nfor feat in categorical[1:]:\n    sns.barplot(x=feat, y='survived', data=train, ax=next(ax))\n    \n# features seems to have a good predictability for the target outcome","231cc87a":"# fill na's and feature engineering\n\ndataset['embarked'] = dataset.embarked.fillna(dataset.embarked.mode()[0])\n\n# assuming people with NA cabin has no cabin, check to see if having a cabin increases chance of survival\ndataset['has_cabin'] = dataset.cabin.notnull()","d29373e6":"sns.barplot(x='has_cabin', y='survived', data=dataset[~dataset.passengerid.isin(test_id)])","0def1bf2":"# check if title impacts survivability\ndataset['title'] = dataset.name.apply(lambda x: x.split(', ')[1].split(' ')[0]).apply(lambda x: x if x in ['Mr.', 'Mrs.', 'Miss.', 'Master.'] else 'Others')","fc44052d":"sns.barplot(x='title', y='survived', data=dataset[~dataset.passengerid.isin(test_id)])","49a8042d":"train = dataset[~dataset.passengerid.isin(test_id)]\ntest = dataset[dataset.passengerid.isin(test_id)]","d0729246":"train.columns","42334915":"fig, ax = plt.subplots(3, 1, figsize=(15, 15))\nfig.tight_layout()\nax = iter(ax.flatten())\nlabels = sorted(train.age_bin.unique())\nfor feat in ['sex', 'pclass', 'embarked']:\n    _ax = next(ax)\n#     _ax.grid(False)\n    g = sns.barplot(x='age_bin', y='survived', hue=feat, data=train, order=labels, ax=_ax)\n    g.set_xticklabels(labels=labels, rotation=15)\n    \n#     twin_ax = _ax.twinx()\n#     twin_ax.grid(False)\n#     data = train.age_bin.value_counts().to_frame().reset_index().rename(columns={'age_bin':'count'})\n#     sns.barplot(x='index', y='count', data=data, ax=twin_ax, alpha=0.5)\n\n# clearly, male passengers has a lot less chance of surviving than females\n# class 1 and 2 passengers are also prioritized\n# for some reason, those who embarked from C and Q has a higher chance of surviving","be29eb35":"for feat in ['sex', 'pclass', 'embarked', 'is_alone', 'has_cabin']:\n    sns.FacetGrid(train, hue='survived', col=feat, height=5, aspect=1).map(sns.distplot, 'fare')\n# blue: survived = 0\n# orange: survived = 1\n# the trend seems to be the same for all, the higher the fare, the higher the chance of survival","592195a5":"feats = ['embarked', 'pclass', 'sex', 'age_bin', 'fare_bin', 'family_size', 'is_alone', 'has_cabin', 'title']\ndataset_y = dataset[['survived']]\ndataset_X = dataset[feats]\ndataset_X = dataset_X.apply(LabelEncoder().fit_transform)","be94a884":"# check correlation before onehot\nidx = len(dataset) - len(test_id)\nsns.heatmap(pd.concat([dataset_X[:idx], dataset_y[:idx]], axis=1).astype(int).corr(), annot=True)","1017c936":"onehot = ['embarked', 'title']\nonehot_df = pd.get_dummies(dataset_X[onehot].astype(object), drop_first=True)\ndataset_X = pd.concat([dataset_X.drop(onehot, axis=1), onehot_df], axis=1)","20a1b9b4":"X_train = dataset_X[:idx]\nX_test = dataset_X[idx:]\ny_train = dataset_y[:idx]","64da41fd":"kfold = StratifiedKFold(n_splits=6)","405a766e":"clfs_name = [\n    'RandomForest',\n    'ExtraTrees',\n    'AdaBoost',\n    'GradientBoost',\n    'XGBoost',\n    'SVC'\n]\n\nclfs = [\n    RandomForestClassifier(random_state=0),\n    ExtraTreesClassifier(random_state=0),\n    AdaBoostClassifier(random_state=0),\n    GradientBoostingClassifier(random_state=0),\n    XGBClassifier(random_state=0),\n    SVC(random_state=0)\n]\n\nresults = list()\nfor name, clf in zip(clfs_name, clfs):\n    cv = cross_val_score(clf, X_train, y_train, cv=kfold, n_jobs=-1)\n    results.append([name, cv.mean() - cv.std(), cv.mean() + cv.std()])","a4a2d4d2":"pd.DataFrame(results, columns=['clf', '-1 std', '+1 std'])","2e88e111":"clf_1_grid = {\n    'n_estimators': [50, 100, 300, 500],\n    'learning_rate': [0.1, 0.5, 0.9, 1.0]\n}\nclf_1 = GridSearchCV(AdaBoostClassifier(random_state=0), clf_1_grid, n_jobs=-1, cv=kfold)\nclf_1.fit(X_train, y_train)\n\nclf_1_score = clf_1.best_score_\nclf_1_estimator = clf_1.best_estimator_","87135be9":"clf_2_grid = {\n    'n_estimators': [40, 50, 70, 100],\n    'learning_rate': [0.1, 0.2, 0.3],\n    'subsample': [0.4, 0.5, 0.6],\n    'max_depth': [3, 4, 5]\n}\nclf_2 = GridSearchCV(GradientBoostingClassifier(random_state=0), clf_2_grid, n_jobs=-1, cv=kfold)\nclf_2.fit(X_train, y_train)\n\nclf_2_score = clf_2.best_score_\nclf_2_estimator = clf_2.best_estimator_","86b46f02":"clf_3_grid = {\n    'n_estimators': [50, 100, 300, 500],\n    'learning_rate': [0.1, 0.5, 0.9],\n    'subsample': [0.3, 0.5, 1.0],\n    'max_depth': [3, 4, 5]\n}\nclf_3 = GridSearchCV(XGBClassifier(random_state=0), clf_3_grid, n_jobs=-1, cv=kfold)\nclf_3.fit(X_train, y_train)\n\nclf_3_score = clf_3.best_score_\nclf_3_estimator = clf_3.best_estimator_","d5187a4c":"clf_4_grid = {\n    'C': [0.5, 0.6, 0.7, 0.8, 0.9]\n}\nclf_4 = GridSearchCV(SVC(random_state=0), clf_4_grid, n_jobs=-1, cv=kfold)\nclf_4.fit(X_train, y_train)\n\nclf_4_score = clf_4.best_score_\nclf_4_estimator = clf_4.best_estimator_","ca617729":"feature_importance = pd.DataFrame([\n    clf_1_estimator.feature_importances_,\n    clf_2_estimator.feature_importances_,\n    clf_3_estimator.feature_importances_\n], columns=X_train.columns)\n\nfeature_importance['model'] = ['adaboost', 'gradientboost', 'xgb']","8a041251":"feature_importance = feature_importance.set_index('model').unstack().reset_index().rename(columns={'level_0':'feat', 0: 'score'})","e32e4a28":"fig, ax = plt.subplots(1, 1, figsize=(20, 5))\ng = sns.barplot(x='feat', y='score', hue='model', data=feature_importance, ax=ax)","1b1fb8c8":"feature_importance.sort_values(['model', 'score'], ascending=False).groupby('model', sort=False).head(4)","3e0249b9":"# different feature importances between models is good for stacking\n# stacked model generalizes better since sub models are computes differently\nS_train, S_test = stacking(\n    [clf_1_estimator, clf_2_estimator, clf_3_estimator, clf_4_estimator],\n    X_train, y_train, X_test, regression=False, n_folds=10,\n    stratified=True, shuffle=True, random_state=0, verbose=2\n)","71b34588":"sclf = GridSearchCV(XGBClassifier(random_state=0), clf_3_grid, n_jobs=-1, cv=kfold)\nsclf.fit(S_train, y_train)","508c4d62":"sclf = sclf.best_estimator_.fit(S_train, y_train)","964c04d2":"y_pred = sclf.predict(S_test).astype(int)","bfed804b":"submit = pd.DataFrame({\n    'PassengerId': test_id,\n    'Survived': y_pred\n})\n\nsubmit.to_csv('titanic_submission.csv', index=False)","df0687ff":"from IPython.display import FileLink\nFileLink('titanic_submission.csv')","4919de13":"### Numericals","7b7028fe":"# Init","9a0b5647":"### Categoricals","4415a2b8":"### Other Feature Engineering","cf42c9a7":"## Modeling","656ff458":"# Encoding ","147758f6":"# EDA \/ Feature Analysis \/ Engineering \/ Cleaning","ba81e8d4":"### Multivariate EDA"}}