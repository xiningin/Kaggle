{"cell_type":{"e33cccab":"code","3561204b":"code","d704223b":"code","c8c6c828":"code","23c1b94b":"code","1181dbd3":"code","34162cc5":"code","da335cb3":"code","c46a4644":"code","4dfd306f":"code","7c013200":"code","162df960":"code","6fa1168e":"code","ecb0c594":"code","1c02b137":"code","e23db797":"code","15365052":"code","a54eb130":"code","a44d92e6":"code","41f3cec0":"code","5ede3944":"code","5a592d5b":"code","5e2231c9":"code","e10f3c14":"code","66936b04":"code","699001b4":"code","60cf4641":"code","1404a2ed":"code","4e736aa1":"code","84a79489":"code","847ac903":"code","a2c92bb1":"code","0c492c2c":"code","ed65202f":"code","29c691b8":"code","4815b9af":"code","3e149756":"code","15ba4f76":"code","7c1b04c2":"code","78949059":"code","a95751e1":"code","bfb5311a":"code","62d5958f":"code","84139c44":"code","9d837133":"code","6e4cd018":"code","5342d281":"code","efd3675f":"code","965b999b":"code","9797c9fd":"code","32042360":"code","729d4776":"code","6e8884e5":"code","f6dbf5f0":"code","cd5a2876":"code","88263157":"code","eb92a239":"code","c83f272f":"code","d003e24c":"code","ffae4f18":"code","04b4a839":"code","0a4c7504":"code","e993bdc7":"code","ce27d78b":"code","33302835":"code","61552ef5":"code","9c28b680":"code","3af49d81":"code","43402d13":"code","5f970765":"code","040c053a":"code","3b42d636":"code","64581c72":"code","93cfe765":"code","721994fd":"code","1cb3b82b":"code","9c83eedd":"code","f3152cc1":"code","5a5aaf14":"code","aba6e554":"code","5f0e226e":"code","86d6d274":"code","c7051935":"code","07f55d3d":"code","467771ea":"code","738995ca":"code","978c8b03":"code","0eb05fdf":"code","ad8fd7ac":"code","40e05c28":"code","7826840d":"code","e37257f1":"code","a668c039":"code","d1dc452d":"code","103602c0":"code","cfab563a":"code","5a1e6370":"code","e8cef746":"code","7ebc83a7":"code","e697217c":"code","0c810c4f":"code","62462baa":"code","ee11e066":"code","25c9fa5f":"code","bd2bdaa3":"code","1cfd93f9":"code","f058754e":"code","f5b2b289":"code","30a569b7":"code","e7a9f747":"code","ee78236a":"code","74d738d9":"code","1550b4da":"code","0bcf5ca0":"code","fca9bdd9":"code","c7fa0b24":"code","b2a67b3a":"code","93ad5cbb":"code","af26276a":"code","d3390aaf":"code","6a281f18":"code","f05cb880":"code","d3fda1f5":"code","6ad75a10":"code","8da4dcb9":"code","c11e1faf":"code","335c9ae7":"code","208fe077":"code","1a1bb27c":"code","1e81da31":"code","4b3c5b88":"code","aa57ab0b":"code","80410204":"code","59ff6aab":"code","302108f1":"code","6aaf3b4b":"code","d7455821":"code","524632b3":"code","9da237be":"code","6cb51f98":"code","6f3aab9e":"code","d82878e6":"code","917accd7":"code","d21b9640":"code","1fb48dac":"code","f9a59cd8":"code","0ea235b4":"code","2990ad95":"code","d9bb23c5":"code","7ca940aa":"code","c6ab64e4":"code","acb86cac":"code","01bf93cc":"code","e3a6e270":"code","82099ee9":"code","730eeb6d":"code","26732a88":"code","a610e053":"code","f7d553dd":"code","05a4a237":"code","5421f4fc":"code","6738843e":"code","72aa41da":"code","c2e65293":"code","ddd96c76":"code","f8a92325":"code","54445abd":"code","2628d52c":"code","9ee59a9a":"code","8381f399":"code","715967e5":"code","7ee17214":"code","e76c58ea":"code","c6229c96":"code","b11ab407":"code","54e14490":"code","71a94a43":"code","d26b48bf":"code","e2de48e5":"code","a32b3eb4":"code","662c5f7d":"code","96af0d19":"code","60d4df10":"code","7fb0d344":"code","cc4f12ee":"code","701a7281":"code","28933bdf":"code","ff683d5b":"code","d7b527b8":"code","6d61330c":"code","a3efab76":"markdown","ebcea6ab":"markdown","cc1c8e34":"markdown","3216e495":"markdown","500c750b":"markdown","7df18268":"markdown","04ee378c":"markdown","5656b1ee":"markdown","ef14d686":"markdown","e4f32488":"markdown","d9d787ae":"markdown","c9288816":"markdown","53d1a334":"markdown","2dbab6e6":"markdown","a22f3bbf":"markdown","f17d42e5":"markdown","14370f26":"markdown","adade1a8":"markdown","84ac77c0":"markdown","6d49b5a4":"markdown","2c26b615":"markdown","b1ab50d4":"markdown","4aab982b":"markdown","03e31819":"markdown","1aa225a7":"markdown","e88bd820":"markdown","c8192cd2":"markdown","ca347667":"markdown","7a5845c9":"markdown","7d8f8189":"markdown","88e017e2":"markdown","2a3c5233":"markdown","ddb8db4a":"markdown","8da6cb12":"markdown","8af37739":"markdown","d5bb45a7":"markdown","175949be":"markdown","15a9cf1c":"markdown","ff3affe9":"markdown","3330cea7":"markdown","e2179ef7":"markdown","d47c1ac4":"markdown","360f4ebd":"markdown","d994c56d":"markdown","5d3b4a6c":"markdown","85bb53d8":"markdown","0e9609a0":"markdown","a6920fcb":"markdown","abf2543c":"markdown","045a013c":"markdown","2ad979d7":"markdown","df9e0c93":"markdown","6714e413":"markdown","087134bb":"markdown","4392ab75":"markdown","1d2bcf2e":"markdown","3fd98bff":"markdown","9e1f72c7":"markdown","47411f48":"markdown","e97a0477":"markdown","6e02254b":"markdown","e09f8a4f":"markdown","fe9307c5":"markdown","21d66b28":"markdown","c3e290d5":"markdown","680460e6":"markdown","b82a83bf":"markdown","b8236bd9":"markdown","63cae0ff":"markdown","80dcfb1a":"markdown","91368474":"markdown","bd1527a6":"markdown","277b6381":"markdown","3763e079":"markdown","3e39642c":"markdown","5a8853db":"markdown","a54b269d":"markdown","dbfde609":"markdown","69164687":"markdown","27aa5069":"markdown","fee6ca9e":"markdown","c144974f":"markdown","78c52735":"markdown","39a50ffd":"markdown","fc538b69":"markdown","aba57756":"markdown","c48d063e":"markdown","51aa6f76":"markdown","581b4a2f":"markdown","a0ff5395":"markdown","8422c9cd":"markdown","321eb143":"markdown","457a1315":"markdown","09811c6a":"markdown","c94b3f88":"markdown","4a07f70f":"markdown","c59dd7cc":"markdown","2faf7883":"markdown","d14f9dbb":"markdown","57cd9fe5":"markdown","8f671799":"markdown","5583c3f2":"markdown","f2f5bb6f":"markdown","bc8caccd":"markdown","fb6c429a":"markdown","b1f50b29":"markdown","f5da1eaa":"markdown","b4cb56aa":"markdown","45af7017":"markdown"},"source":{"e33cccab":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \nimport warnings #to remove warning from the notebook\nwarnings.filterwarnings(action='ignore')","3561204b":"#loading dataset\nname= ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\ndf = pd.read_csv('..\/input\/boston-house-prices\/housing.csv',delim_whitespace=True,names=name)\ndf.head()","d704223b":"nRow, nCol = df.shape\nprint(f'There are {nRow} rows and {nCol} columns')","c8c6c828":"df.info()","23c1b94b":"df.isnull().sum()","1181dbd3":"df.corr()","34162cc5":"plt.figure(figsize=(12,9))\nsns.heatmap(data=df.corr().round(2),annot=True,linewidths=0.2,square=True)\nplt.show()","da335cb3":"df1 = df[['RM','LSTAT','MEDV']]\ndf1.head()","c46a4644":"sns.pairplot(data=df1)","4dfd306f":"#description about this data\ndf1.describe().round(2)","7c013200":"#Box Plot, Distribution Plot and Scatter Plot for Dependent variable MEDV\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.MEDV)\nplt.title('Box Plot of MEDV')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.MEDV)\nplt.title('Distribution Plot of MEDV')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.MEDV,df1.MEDV)\nplt.title('Scatter Plot of MEDV vs MEDV')\nplt.show()","162df960":"df2 = df1[~(df1['MEDV']==50)]\ndf2","6fa1168e":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","ecb0c594":"#Box Plot, Distribution Plot and Scatter Plot for Independent variable RM\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.RM)\nplt.title('Box Plot of RM')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.RM)\nplt.title('Distribution Plot of RM')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.RM,df1.MEDV)\nplt.title('Scatter Plot of RM vs MEDV')\nplt.show()","1c02b137":"temp_df = df2[df1['RM']>7.7]\ntemp_df.shape","e23db797":"temp_df1 = df2[df1['RM']<4.7]\ntemp_df1.shape","15365052":"df2 = df2[~(df1['RM']>7.7)]\ndf2","a54eb130":"df2 = df2[~(df1['RM']<4.7)]\ndf2","a44d92e6":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","41f3cec0":"#Box Plot, Distribution Plot and Scatter Plot for Independent variable LSTAT\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.LSTAT)\nplt.title('Box Plot of LSTAT')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.LSTAT)\nplt.title('Distribution Plot of LSTAT')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.LSTAT,df1.MEDV)\nplt.title('Scatter Plot of LSTAT vs MEDV')\nplt.show()","5ede3944":"temp_df1 = df2[df1['LSTAT']>31]\ntemp_df1.shape","5a592d5b":"df2 = df2[~(df1['LSTAT']>31)]\ndf2","5e2231c9":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","e10f3c14":"#Now will split our dataset into Dependent variable and Independent variable\nx = df2.iloc[:,0:2].values\ny = df2.iloc[:,-1:].values","66936b04":"print(\"Shape of Independent variable, x :\",x.shape)\nprint(\"Shape of Dependent variable, y :\",y.shape)","699001b4":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(x)","60cf4641":"x","1404a2ed":"x_scaled = scaler.transform(x)\nx_scaled","4e736aa1":"m,n = x_scaled.shape\nx_scaled = np.append(arr=np.ones((m,1)),values=x_scaled,axis=1)\nx_scaled","84a79489":"x=x_scaled","847ac903":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","a2c92bb1":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model","0c492c2c":"lin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","ed65202f":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_11 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_12 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_11)\nprint(\"R^2 value: \",test_set_r2_12)","29c691b8":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","4815b9af":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.4,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","3e149756":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model","15ba4f76":"lin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","7c1b04c2":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_13 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_14 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_13)\nprint(\"R^2 value: \",test_set_r2_14)","78949059":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","a95751e1":"df1 = df[['RM','TAX','MEDV']]\ndf1.head()","bfb5311a":"sns.pairplot(data=df1)","62d5958f":"df1.describe().round(2)","84139c44":"#Box Plot, Distribution Plot and Scatter Plot for Dependent variable MEDV\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.MEDV)\nplt.title('Box Plot of MEDV')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.MEDV)\nplt.title('Distribution Plot of MEDV')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.MEDV,df1.MEDV)\nplt.title('Scatter Plot of MEDV vs MEDV')\nplt.show()","9d837133":"df2 = df1[~(df1['MEDV']==50)]\ndf2","6e4cd018":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","5342d281":"#Box Plot, Distribution Plot and Scatter Plot for Independent variable RM\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.RM)\nplt.title('Box Plot of RM')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.RM)\nplt.title('Distribution Plot of RM')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.RM,df1.MEDV)\nplt.title('Scatter Plot of RM vs MEDV')\nplt.show()","efd3675f":"df2 = df2[~(df1['RM']>7.7)]","965b999b":"df2 = df2[~(df1['RM']<4.7)]","9797c9fd":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","32042360":"#Box Plot, Distribution Plot and Scatter Plot for TAX\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.TAX)\nplt.title('Box Plot of TAX')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.TAX)\nplt.title('Distribution Plot of TAX')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.TAX,df1.MEDV)\nplt.title('Scatter Plot of TAX vs MEDV')\nplt.show()","729d4776":"temp_df = df2[df1['TAX']>600]\ntemp_df.shape","6e8884e5":"temp_df.describe()","f6dbf5f0":"#Now we split our dataset into Dependent variable and Independent variable\nx = df2.iloc[:,0:2].values\ny = df2.iloc[:,-1:].values","cd5a2876":"print(\"Shape of Independent variable, x :\",x.shape)\nprint(\"Shape of Dependent variable, y :\",y.shape)","88263157":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(x)","eb92a239":"x","c83f272f":"x_scaled = scaler.transform(x)\nx_scaled","d003e24c":"m,n = x_scaled.shape\nx_scaled = np.append(arr=np.ones((m,1)),values=x_scaled,axis=1)\nx_scaled","ffae4f18":"x=x_scaled","04b4a839":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","0a4c7504":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","e993bdc7":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_21 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_22 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_21)\nprint(\"R^2 value: \",test_set_r2_22)","ce27d78b":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","33302835":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.4,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","61552ef5":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","9c28b680":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_23 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_24 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_23)\nprint(\"R^2 value: \",test_set_r2_24)","3af49d81":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","43402d13":"df1 = df[['LSTAT','TAX','MEDV']]\ndf1.head()","5f970765":"sns.pairplot(data=df1)","040c053a":"df1.describe().round(2)","3b42d636":"#Box Plot, Distribution Plot and Scatter Plot for Dependent variable MEDV\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.MEDV)\nplt.title('Box Plot of MEDV')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.MEDV)\nplt.title('Distribution Plot of MEDV')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.MEDV,df1.MEDV)\nplt.title('Scatter Plot of MEDV vs MEDV')\nplt.show()","64581c72":"df2 = df1[~(df1['MEDV']==50)]\ndf2","93cfe765":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","721994fd":"#Box Plot, Distribution Plot and Scatter Plot for Independent variable LSTAT\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.LSTAT)\nplt.title('Box Plot of LSTAT')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.LSTAT)\nplt.title('Distribution Plot of LSTAT')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.LSTAT,df1.MEDV)\nplt.title('Scatter Plot of LSTAT vs MEDV')\nplt.show()","1cb3b82b":"df2 = df2[~(df1['LSTAT']>31)]\ndf2","9c83eedd":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","f3152cc1":"#Box Plot, Distribution Plot and Scatter Plot for TAX\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.TAX)\nplt.title('Box Plot of TAX')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.TAX)\nplt.title('Distribution Plot of TAX')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.TAX,df1.MEDV)\nplt.title('Scatter Plot of TAX vs MEDV')\nplt.show()","5a5aaf14":"temp_df = df2[df1['TAX']>600]\ntemp_df.shape","aba6e554":"temp_df.describe()","5f0e226e":"#Now we split our dataset into Dependent variable and Independent variable\nx = df2.iloc[:,0:2].values\ny = df2.iloc[:,-1:].values","86d6d274":"print(\"Shape of Independent variable, x :\",x.shape)\nprint(\"Shape of Dependent variable, y :\",y.shape)","c7051935":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(x)","07f55d3d":"x","467771ea":"x_scaled = scaler.transform(x)\nx_scaled","738995ca":"m,n = x_scaled.shape\nx_scaled = np.append(arr=np.ones((m,1)),values=x_scaled,axis=1)\nx_scaled","978c8b03":"x= x_scaled","0eb05fdf":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","ad8fd7ac":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","40e05c28":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_31 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_32 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_31)\nprint(\"R^2 value: \",test_set_r2_32)","7826840d":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","e37257f1":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.4,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","a668c039":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","d1dc452d":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_33 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_34 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_33)\nprint(\"R^2 value: \",test_set_r2_34)","103602c0":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","cfab563a":"df1 = df[['RM','PTRATIO','MEDV']]\ndf1.head()","5a1e6370":"sns.pairplot(data=df1)","e8cef746":"df1.describe().round(2)","7ebc83a7":"#Box Plot, Distribution Plot and Scatter Plot for Dependent variable MEDV\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.MEDV)\nplt.title('Box Plot of MEDV')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.MEDV)\nplt.title('Distribution Plot of MEDV')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.MEDV,df1.MEDV)\nplt.title('Scatter Plot of MEDV vs MEDV')\nplt.show()","e697217c":"df2 = df1[~(df1['MEDV']==50)]\ndf2","0c810c4f":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","62462baa":"#Box Plot, Distribution Plot and Scatter Plot for Independent variable RM\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.RM)\nplt.title('Box Plot of RM')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.RM)\nplt.title('Distribution Plot of RM')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.RM,df1.MEDV)\nplt.title('Scatter Plot of RM vs MEDV')\nplt.show()","ee11e066":"df2 = df2[~(df1['RM']>7.7)]","25c9fa5f":"df2 = df2[~(df1['RM']<4.7)]","bd2bdaa3":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","1cfd93f9":"#Box Plot, Distribution Plot and Scatter Plot for PTRATIO\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.PTRATIO)\nplt.title('Box Plot of PTRATIO')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.PTRATIO)\nplt.title('Distribution Plot of PTRATIO')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.PTRATIO,df1.MEDV)\nplt.title('Scatter Plot of PTRATIO vs MEDV')\nplt.show()","f058754e":"temp_df = df2[df1['PTRATIO']<13]\ntemp_df.shape","f5b2b289":"df2 = df2[~(df1['PTRATIO']<13)]","30a569b7":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","e7a9f747":"#Now we split our dataset into Dependent variable and Independent variable\nx = df2.iloc[:,0:2].values\ny = df2.iloc[:,-1:].values","ee78236a":"print(\"Shape of Independent variable, x :\",x.shape)\nprint(\"Shape of Dependent variable, y :\",y.shape)","74d738d9":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(x)","1550b4da":"x","0bcf5ca0":"x_scaled = scaler.transform(x)\nx_scaled","fca9bdd9":"m,n = x_scaled.shape\nx_scaled = np.append(arr=np.ones((m,1)),values=x_scaled,axis=1)\nx_scaled","c7fa0b24":"x=x_scaled","b2a67b3a":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","93ad5cbb":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","af26276a":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_41 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_42 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_41)\nprint(\"R^2 value: \",test_set_r2_42)","d3390aaf":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","6a281f18":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.4,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","f05cb880":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","d3fda1f5":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_43 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_44 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_43)\nprint(\"R^2 value: \",test_set_r2_44)","6ad75a10":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","8da4dcb9":"df1 = df[['TAX','LSTAT','PTRATIO','MEDV']]\ndf1.head()","c11e1faf":"sns.pairplot(data=df1)","335c9ae7":"df1.describe().round(2)","208fe077":"#Box Plot, Distribution Plot and Scatter Plot for Dependent variable MEDV\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.MEDV)\nplt.title('Box Plot of MEDV')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.MEDV)\nplt.title('Distribution Plot of MEDV')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.MEDV,df1.MEDV)\nplt.title('Scatter Plot of MEDV vs MEDV')\nplt.show()","1a1bb27c":"df2 = df1[~(df1['MEDV']==50)]\ndf2","1e81da31":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","4b3c5b88":"#Box Plot, Distribution Plot and Scatter Plot for Independent variable LSTAT\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.LSTAT)\nplt.title('Box Plot of LSTAT')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.LSTAT)\nplt.title('Distribution Plot of LSTAT')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.LSTAT,df1.MEDV)\nplt.title('Scatter Plot of LSTAT vs MEDV')\nplt.show()","aa57ab0b":"df2 = df2[~(df1['LSTAT']>31)]\ndf2","80410204":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","59ff6aab":"#Box Plot, Distribution Plot and Scatter Plot for TAX\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.TAX)\nplt.title('Box Plot of TAX')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.TAX)\nplt.title('Distribution Plot of TAX')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.TAX,df1.MEDV)\nplt.title('Scatter Plot of TAX vs MEDV')\nplt.show()","302108f1":"temp_df = df2[df1['TAX']>600]\ntemp_df.shape","6aaf3b4b":"temp_df.describe()","d7455821":"#Box Plot, Distribution Plot and Scatter Plot for PTRATIO\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.PTRATIO)\nplt.title('Box Plot of PTRATIO')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.PTRATIO)\nplt.title('Distribution Plot of PTRATIO')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.PTRATIO,df1.MEDV)\nplt.title('Scatter Plot of PTRATIO vs MEDV')\nplt.show()","524632b3":"temp_df = df2[df1['PTRATIO']<13]\ntemp_df.shape","9da237be":"df2 = df2[~(df1['PTRATIO']<13)]","6cb51f98":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","6f3aab9e":"#Now we split our dataset into Dependent variable and Independent variable\nx = df2.iloc[:,0:3].values\ny = df2.iloc[:,-1:].values","d82878e6":"print(\"Shape of Independent variable, x :\",x.shape)\nprint(\"Shape of Dependent variable, y :\",y.shape)","917accd7":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(x)","d21b9640":"x","1fb48dac":"x_scaled = scaler.transform(x)\nx_scaled","f9a59cd8":"m,n = x_scaled.shape\nx_scaled = np.append(arr=np.ones((m,1)),values=x_scaled,axis=1)\nx_scaled","0ea235b4":"x = x_scaled","2990ad95":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","d9bb23c5":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","7ca940aa":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_51 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_52 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_51)\nprint(\"R^2 value: \",test_set_r2_52)","c6ab64e4":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","acb86cac":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.4,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","01bf93cc":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","e3a6e270":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_53 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_54 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_53)\nprint(\"R^2 value: \",test_set_r2_54)","82099ee9":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","730eeb6d":"df1 = df[['RM','LSTAT','PTRATIO','MEDV']]\ndf1.head()","26732a88":"sns.pairplot(data=df1)","a610e053":"#description about this data\ndf1.describe().round(2)","f7d553dd":"#Box Plot, Distribution Plot and Scatter Plot for Dependent variable MEDV\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.MEDV)\nplt.title('Box Plot of MEDV')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.MEDV)\nplt.title('Distribution Plot of MEDV')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.MEDV,df1.MEDV)\nplt.title('Scatter Plot of MEDV vs MEDV')\nplt.show()","05a4a237":"df2 = df1[~(df1['MEDV']==50)]\ndf2","5421f4fc":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","6738843e":"#Box Plot, Distribution Plot and Scatter Plot for Independent variable RM\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.RM)\nplt.title('Box Plot of RM')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.RM)\nplt.title('Distribution Plot of RM')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.RM,df1.MEDV)\nplt.title('Scatter Plot of RM vs MEDV')\nplt.show()","72aa41da":"temp_df = df2[df1['RM']>7.7]\ntemp_df.shape","c2e65293":"temp_df1 = df2[df1['RM']<4.7]\ntemp_df1.shape","ddd96c76":"df2 = df2[~(df1['RM']>7.7)]","f8a92325":"df2 = df2[~(df1['RM']<4.7)]","54445abd":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","2628d52c":"#Box Plot, Distribution Plot and Scatter Plot for Independent variable LSTAT\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.LSTAT)\nplt.title('Box Plot of LSTAT')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.LSTAT)\nplt.title('Distribution Plot of LSTAT')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.LSTAT,df1.MEDV)\nplt.title('Scatter Plot of LSTAT vs MEDV')\nplt.show()","9ee59a9a":"df2 = df2[~(df1['LSTAT']>31)]\ndf2","8381f399":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","715967e5":"#Box Plot, Distribution Plot and Scatter Plot for PTRATIO\nplt.figure(figsize=(20,3))\nplt.subplot(1,3,1)\nsns.boxplot(df1.PTRATIO)\nplt.title('Box Plot of PTRATIO')\n\nplt.subplot(1,3,2)\nsns.distplot(a=df1.PTRATIO)\nplt.title('Distribution Plot of PTRATIO')\n\nplt.subplot(1,3,3)\nsns.scatterplot(df1.PTRATIO,df1.MEDV)\nplt.title('Scatter Plot of PTRATIO vs MEDV')\nplt.show()","7ee17214":"df2 = df2[~(df1['PTRATIO']<13)]","e76c58ea":"print(f'The maximum values of the dataset are:\\n{df2.max()}')\nprint(f'Shape of dataset before removing Outliers: {df1.shape}')\nprint(f'Shape of dataset after removing Outliers: {df2.shape}')","c6229c96":"#Now we split our dataset into Dependent variable and Independent variable\nx = df2.iloc[:,0:3].values\ny = df2.iloc[:,-1:].values","b11ab407":"print(\"Shape of Independent variable, x :\",x.shape)\nprint(\"Shape of Dependent variable, y :\",y.shape)","54e14490":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(x)","71a94a43":"x","d26b48bf":"x_scaled = scaler.transform(x)\nx_scaled","e2de48e5":"m,n = x_scaled.shape\nx_scaled = np.append(arr=np.ones((m,1)),values=x_scaled,axis=1)\nx_scaled","a32b3eb4":"x= x_scaled","662c5f7d":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","96af0d19":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","60d4df10":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_61 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_62 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_61)\nprint(\"R^2 value: \",test_set_r2_62)","7fb0d344":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","cc4f12ee":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.4,random_state = 42)\nprint(f\"Shape of x_train = {x_train.shape}\")\nprint(f\"Shape of x_test = {x_test.shape}\")\nprint(f\"Shape of y_train = {y_train.shape}\")\nprint(f\"Shape of y_test = {y_test.shape}\")","701a7281":"from sklearn import datasets, linear_model #Import datasets and linear_model from Sklearn\nfrom sklearn.metrics import mean_squared_error, r2_score #Import metrics to evaluate the model\nlin_reg_mod = linear_model.LinearRegression() #Create LinearRegression object\nlin_reg_mod.fit(x_train, y_train) #Fit the model to data (training part)","28933bdf":"pred = lin_reg_mod.predict(x_test) #Make Prediction for test (unseen) data\ntest_set_rmse_63 = (np.sqrt(mean_squared_error(y_test, pred))) #Create metrics for accuracy\ntest_set_r2_64 = r2_score(y_test, pred)\nprint(\"RMSE value:\",test_set_rmse_63)\nprint(\"R^2 value: \",test_set_r2_64)","ff683d5b":"plt.scatter(y_test,pred)\nplt.plot([0,55], [0,55], ls=\"-\", c=\".3\")","d7b527b8":"#For 80-20 Split of the dataset\nmodels = pd.DataFrame({\n    'Model Features': ['RM + LSTAT', 'RM + TAX', 'LSTAT + TAX', 'PTRATIO + RM', 'TAX + LSTAT + PTRATIO', 'PTRATIO + RM + LSTAT'],\n    'RMSE Score': [ test_set_rmse_11 , test_set_rmse_21 , test_set_rmse_31 , test_set_rmse_41 , test_set_rmse_51 , test_set_rmse_61 ],\n    'R-squared Score': [ test_set_r2_12 , test_set_r2_22 , test_set_r2_32 , test_set_r2_42 , test_set_r2_52 , test_set_r2_62]})\nmodels.sort_values(by='RMSE Score', ascending=True)","6d61330c":"#For 60-40 Split of the dataset\nmodels = pd.DataFrame({\n    'Model Features': ['RM + LSTAT', 'RM + TAX', 'LSTAT + TAX', 'PTRATIO + RM', 'TAX + LSTAT + PTRATIO', 'PTRATIO + RM + LSTAT'],\n    'RMSE Score': [ test_set_rmse_13 , test_set_rmse_23 , test_set_rmse_33 , test_set_rmse_43 , test_set_rmse_53 , test_set_rmse_63 ],\n    'R-squared Score': [ test_set_r2_14 , test_set_r2_24 , test_set_r2_34 , test_set_r2_44 , test_set_r2_54 , test_set_r2_64]})\nmodels.sort_values(by='RMSE Score', ascending=True)","a3efab76":"## CONCLUSION","ebcea6ab":"Observations:\n- RM is normally distributed as it's histogram is a bell shaped curve, but there are very few outliers towards both the ends\n- TAX does not show normal distribution\n- MEDV has a normally distributed graph with outliers present between the range 40-50\n- Positive Linear correlation is present between RM and MEDV. There are a few outliers present near 50\n- There is no relation between MEDV and TAX","cc1c8e34":"- Now the maximum value of PTRATIO column is 22\n- Hence we have deleted 43 (506-463) rows from out dataset having PTRATIO value as < 13","3216e495":"- Now the maximum value of RM column is 7.69\n- Hence we have deleted 36 (506-470) rows from out dataset having RM value as >7.7 & < 4.7","500c750b":"# Choose 5 sets of features to predict\n\n```\n- 1st set : RM and TAX\n- 2nd set : LSTAT and PTRATIO\n- 3rd set : RM and PTRATIO\n- 4th set : LSTAT, TAX and PTRATIO\n- 5th set : RM, LSTAT and PTRATIO\n```\n\n","7df18268":"Observations:\n- We can see count of entries for each variable is\nsame i.e. 506.\n- Maximum value in MEDV is much higher than 75% of data points\n\nFor RM & MEDV:\n- The difference between the min and 50% quartile, and between 50% and max value is almost the equal\n- The mean and 50% value is approximately same\n- Hence RM and MEDV have Normal Distribution for their graphs\n\nFor PTRATIO:\n- The difference between the min and 50% quartile, and between 50% and max value is unequal\n- The difference between the mean and 50% quartile value is small\n- Hence PTRATIO does not have normal distribution","04ee378c":"## 1st set : RM and TAX","5656b1ee":"- This is a fairly good regression model as the R square score is near 1.0, and the RMSE error is not very large.","ef14d686":"- Web observe that th egraph of LSTAT is negatuvely skewed, with outliers present after approximately 31 value","e4f32488":"Observations:\n- Graph of TAX is NOT normally distributed\n- Though Boxplot does not show any outlier but there are some extreme TAX values in the dataset\n- From the scatter plot we can observe that for these extreme TAX values, and MEDV ranges from low to high.","d9d787ae":"- Now the maximum value of PTRATIO column is 22\n- Hence we have deleted 39 (506-467) rows from out dataset having PTRATIO value as < 13","c9288816":"### 80-20 Split","53d1a334":"**From the above results, we conclude that for 60-40 Split of the dataset:**\n- The model set using the features *PTRATIO, RM and LSTAT* gives the greatest R-Square Score and the Least RMSE Error. Hence this is the **best model**, out of all the sets observed in this experiment.\n- Following this, *RM and TAX* give good results as it has fairly high R-squared score and low RMSE score, out of all the sets observed in this experiment.\n- *RM and LSTAT* is also a good set as it gives good RMSE and R-squared score comparitively to other sets observed.\n- *PTRATIO and RM* does not give good results, hence it would not be a good model for prediction purposes. This is because it has a very high RMSE value and a very low R-square score.","2dbab6e6":"Observations:\n- RM is normally distributed as it's histogram is a bell shaped curve, but there are very few outliers towards both the ends\n- LSTAT shows quite a negatively skewed graph\n- PTRATIO has a positively sked graph with few outliers present towards the ends\n- MEDV has a normally distributed graph with outliers present between the range 40-50\n- Position Linear correlation is present between RM and MEDV. There are a few outliers present near 50\n- RM and LSTAT, and MEDV and LSTAT have negative linear relationship between them, alongith the presence of few outliers\n- Graph of PTRATIO does not show any relationship with RM, LSTAT or MEDV","a22f3bbf":"- Now the maximum value of MEDV column is 48.80\n- Hence we have deleted 16 (506-490) rows from out dataset having MEDV value as 50","f17d42e5":"- This is not a great regression model as the R square score is near 1.0, and the RMSE error is not quite large.","14370f26":"- The R square score is not near 1.0\n- The RMSE error is quite large\n- Hence this is not a great regresstion model","adade1a8":"- From the graph, we infer that there's positive linear relationship with the regression fit line\n- Looking at how the regression line fits in with the scatter plot, some of the actual value points are above the line, and some are below\n- But overall, this model fits the data well, as there is fairly small difference between majority of the datapoints and the best fit line","84ac77c0":"- Now the maximum value of RM column is 7.69\n- Hence we have deleted 36 (506-470) rows from out dataset having RM value as >7.7 & < 4.7","6d49b5a4":"- The R square score is approx. 0.5 and it's not near 1.0\n- The RMSE error is large\n- Hence this is not a good regression model","2c26b615":"Observations:\n- Graph of RM is normally distributed\n- There are some outliers present lower and higher end of RM values in the dataset\n- Scatter plot of RM vs MEDV show fairly good Positive Linear Relationship.","b1ab50d4":"- From the graph, we infer that there's positive linear relationship with the regression fit line\n- Looking at how the regression line fits in with the scatter plot, some of the actual value points are above the line, and some are below\n- This model does not really fit the data well, as there are difference present between many of the datapoints and the best fit line","4aab982b":"# Review Boston House prices dataset","03e31819":"- MEDV is normally distributed\n- It contains some extreme values which could be potential outliers, especially near 50\n\nHence we have to clean this data by removing outliers","1aa225a7":"## REMOVING OUTLIERS","e88bd820":"- From the graph, we infer that there's positive linear relationship with the regression fit line\n- Looking at how the regression line fits in with the scatter plot, some of the actual value points are above the line, and some are below\n- This model fits does not really the data well, as there are difference present between many of the datapoints and the best fit line","c8192cd2":"- There are no missing values present in this dataset\n- All the columns have numrical values, hence we dont have to do encoding for categorical values, in order to perform Linear Regression","ca347667":"**Scatter plot of predicted vs actual test house prices along with the Regression Line**","7a5845c9":"- The R square score is not near 1.0\n- The RMSE error is quite large\n- Hence this is not a great regression model\n- We also infer that 80-20 split of the dataset showed better results for this set","7d8f8189":"- We observe that there's positive linear relationship with the regression fit line\n- Some of the actual value points are above the line, and some are below, looking at how the regression line fits in with the scatter plot, \n- But overall, this model fits the data fairly well, as there is small difference between majority of the datapoints and the best fit line","88e017e2":"- Now the maximum value of MEDV column is 48.80\n- Hence we have deleted 16 (506-490) rows from out dataset having MEDV value as 50","2a3c5233":"### 80-20 Split","ddb8db4a":"- MEDV is normally distributed\n- It contains some extreme values which could be potential outliers, especially near 50\n\nHence we have to clean this data by removing outliers","8da6cb12":"Observations:\n- Graph of TAX is NOT normally distributed\n- Though Boxplot does not show any outlier but there are some extreme TAX values in the dataset\n- From the scatter plot we can observe that for these extreme TAX values, and MEDV ranges from low to high.","8af37739":"### 60-40 Split","d5bb45a7":"Observations:\n- We can see count of entries for each variable is\nsame i.e. 506.\n- Maximum value in MEDV is much higher than 75% of data points\n\nFor LSTAT & MEDV:\n- The difference between the min and 50% quartile, and between 50% and max value is unequal\n- The mean and 50% value is nearly equal\n\nFor TAX:\n- There is a significant difference between the mean and 50% quartile value\n- The difference between the min and 50% quartile, and between 50% and max value is almost equal\n- Hence TAX does not have normal distribution","175949be":"Observations:\n- RM for these entries lies between 4.88 to 7.39\n- MEDV for these entries lies between 14.93 to 29.80.\n- It seems impossible to have such high TAX values for all these houses.\n- These values most likely missing values which were imputed casually by someone\n\nHence, we cannot remove so many values from our dataset","15a9cf1c":"Observations:\n- Normal Distribution is not present in the graph of TAX\n- LSTAT shows quite a negatively skewed graph\n- Graph of PTRATIO is positively skewed with presence of few outliers\n- MEDV has a normally distributed graph with outliers present between the range 40-50\n- Negative Linear correlation is present between LSTAT and MEDV. There are a few outliers present near 50\n- There is no strong relationship between any other pair of features\n","ff3affe9":"- We know, the higher the R-squared value, the more accurately the regression equation models your data\n- ALso, RMSE measures how accurately the model predicts the response, hence it's an important criterion for fit if the main purpose of the model is prediction.\n- This is a good regression model as the R square score is near 1.0, and the RMSE error is not very large.","3330cea7":"### 60-40 Split","e2179ef7":"### FEATURE SCALING using sklearn","d47c1ac4":"- Now the maximum value of LSTAT column is 30.81\n- Hence we have deleted 40 (506-466) rows from out dataset having LSTAT value as >31","360f4ebd":"- Now the maximum value of MEDV column is 48.80\n- Hence we have deleted 16 (506-490) rows from out dataset having MEDV value as 50","d994c56d":"## 4th set : TAX, LSTAT and PTRATIO","5d3b4a6c":"- From the graph, we infer that there's positive linear relationship with the regression fit line\n- Looking at how the regression line fits in with the scatter plot, some of the actual value points are above the line, and some are below\n- This model does not really fit the data well, as there are difference present between many of the datapoints and the best fit line","85bb53d8":"- Now the maximum value of MEDV column is 48.80\n- Hence we have deleted 16 (506-490) rows from out dataset having MEDV value as 50","0e9609a0":"- MEDV is normally distributed\n- It contains some extreme values which could be potential outliers, especially near 50\n\nHence we have to clean this data by removing outliers","a6920fcb":"Observations:\n- almost 126 rows have TAX value as 666\n- LSTAT for these entries lies between5.29 to 30.81\n- MEDV for these entries lies between 5.00 to 29.80\n- It seems impossible to have such high TAX values for all these houses\n- These values most likely missing values which were imputed casually by someone\n\nHence, we cannot remove so many values from our dataset","abf2543c":"- MEDV is normally distributed\n- It contains some extreme values which could be potential outliers, especially near 50\n\nHence we have to clean this data by removing outliers\n","045a013c":"Observations:\n- NOX shows goor corr with INDUS and AGE\n- INDUS shows good corr with LSAT and DIS\n- DIS shows stron corr with INDUS, RM and AGE \n\nHence Multicollinearity exists in this dataset","2ad979d7":"- Now the maximum value of RM column is 7.69\n- Hence we have deleted 36 (506-470) rows from out dataset having RM value as >7.7 & < 4.7","df9e0c93":"## 2nd set : LSTAT and TAX","6714e413":"### 60-40 Split","087134bb":"Observations:\n- LSTAT for these entries lies between5.29 to 30.81\n- MEDV for these entries lies between 5.00 to 29.80.\n- It seems impossible to have such high TAX values for all these houses.\n- These values most likely missing values which were imputed casually by someone\n\nHence, we cannot remove so many values from our dataset","4392ab75":"- There are no null values ","1d2bcf2e":"- There are total 123 entries in TAX mostly having value 666\n","3fd98bff":"### Scatter plot of predicted vs actual test house prices along with the Regression Line","9e1f72c7":"- MEDV is normally distributed\n- It contains some extreme values which could be potential outliers, especially near 50\n\nHence we have to clean this data by removing outliers","47411f48":"- From the graph, we infer that there's positive linear relationship with the regression fit line\n- Looking at how the regression line fits in with the scatter plot, some of the actual value points are above the line, and some are below\n- But overall, this model fits the data well, as there is fairly small difference between majority of the datapoints and the best fit line","e97a0477":"- MEDV is normally distributed\n- It contains some extreme values which could be potential outliers, especially near 50\n\nHence we have to clean this data by removing outliers","6e02254b":"### 60-40 Split","e09f8a4f":"- The R square score is approx. 0.5 and it's not near 1.0\n- The RMSE error is large\n- Hence this is not a good regression model","fe9307c5":"Observations:\n- Graph of RM is normally distributed\n- There are some outliers present lower and higher end of RM values in the dataset\n- Scatter plot of RM vs MEDV show good Positive Linear Relationship.","21d66b28":"# Choose 2 features to predict the target\nHere we choose RM and LSTAT as the 2 features","c3e290d5":"- Now the maximum value of LSTAT column is 30.81\n- Hence we have deleted 23 (506-483) rows from out dataset having LSTAT value as >31","680460e6":"Observations:\n- RM is normally distributed as it's histogram is a bell shaped curve, but there are very few outliers towards both the ends\n- LSTAT shows quite a negatively skewed graph\n- MEDV has a normally distributed graph with outliers present between the range 40-50\n- Position Linear correlation is present between RM and MEDV. There are a few outliers present near 50\n- RM and LSTAT, and MEDV and LSTAT have negative linear relationship between them, alongith the presence of few outliers","b82a83bf":"- This is a fairly good regression model as the R square score is near 1.0, and the RMSE error is not very large.","b8236bd9":"- Now the maximum value of LSTAT column is 30.81\n- Hence we have deleted 23 (506-483) rows from out dataset having LSTAT value as >31","63cae0ff":"### 80-20 Split","80dcfb1a":"- There are total 126 entries in TAX mostly having value 666","91368474":"- From the graph, we infer that there's positive linear relationship with the regression fit line\n- Looking at how the regression line fits in with the scatter plot, some of the actual value points are above the line, and some are below\n- This model does not really fit the data well, as there are difference present between many of the datapoints and the best fit line","bd1527a6":"Observations:\n- We can see count of entries for each variable is\nsame i.e. 506.\n- Maximum value in MEDV and LSTAT are much higher than 75% of data points\n\nFor RM & MEDV:\n- The difference between the min and 50% quartile, and between 50% and max value is almost the equal\n- The mean and 50% value is approximately same\n- Hence RM and MEDV have Normal Distribution for their graphs\n\nFor LSTAT:\n- The difference between the min and 50% quartile, and between 50% and max value is unequal\n- There is a significant difference between the mean and 50% quartile value\n- Hence LSTAT does not have normal distribution\n\nFor PTRATIO:\n- The difference between the min and 50% quartile is greater than, that present between 50% and max value\n- Hence it has a positively sked graph\n- Here, the mean and 50% values are also approximately same","277b6381":"### Training Set (80% of total data) & Test Set (20% of total data)","3763e079":"- Now the maximum value of RM column is 7.69\n- Hence we have deleted 36 (506-470) rows from out dataset having RM value as >7.7 & < 4.7","3e39642c":"- This is a fairly good regression model as the R square score is near 1.0, and the RMSE error is not very large.\n- But the results of 80-20 split are better than this to train the dataset","5a8853db":"Observations:\n- We can see count of entries for each variable is\nsame i.e. 506.\n- Maximum value in MEDV and LSTAT are much higher than 75% of data points\n\nFor RM & MEDV:\n- The difference between the min and 50% quartile, and between 50% and max value is almost the equal\n- The mean and 50% value is approximately same\n- Hence RM and MEDV have Normal Distribution for their graphs\n\nFor LSTAT:\n- The difference between the min and 50% quartile, and between 50% and max value is unequal\n- There is a significant difference between the mean and 50% quartile value\n- Hence LSTAT does not have normal distribution","a54b269d":"- We infer that there's positive linear relationship with the regression fit line\n- From the graph, some of the actual value points are above the line, and some are below the regression best fit line.\n- This model does not fit the data really well, as there are small differences present between many of the datapoints and the best fit line","dbfde609":"### TEST & TRAIN DATASET (80-20)\n> We split the data into Training Set (80% of total data) and Test Set (20% of total data)\n\n\n\n\n\n","69164687":"Observations:\n- RM is normally distributed as it's histogram is a bell shaped curve, but there are very few outliers towards both the ends\n- PTRATIO does not show normal distribution. Graph of PTRATIO is positively skewed with presence of few outliers\n- MEDV has a normally distributed graph with outliers present between the range 40-50\n- Positive Linear correlation is present between RM and MEDV. There are a few outliers present near 50\n- There is no relation between MEDV and PTRATIO","27aa5069":"### 60-40 Split","fee6ca9e":"- We infer that there's positive linear relationship with the regression fit line\n- From the graph, some of the actual value points are above the line, and some are below the regression best fit line.\n- This model does not fit the data well, as there are difference present between many of the datapoints and the best fit line","c144974f":"### Training Set (60% of total data) & Test Set (40% of total data)","78c52735":"Observations:\n- Graph of RM is normally distributed\n- There are some outliers present lower and higher end of RM values in the dataset\n- Scatter plot of RM vs MEDV show fairly good Positive Linear Relationship.","39a50ffd":"- Now the maximum value of PTRATIO column is 22\n- Hence we have deleted 39 (506-467) rows from out dataset having PTRATIO value as < 13","fc538b69":"- This is a fairly good regression model as the R square score is near 1.0, and the RMSE error is comparitively not very large.","aba57756":"## 3rd set : RM and PTRATIO","c48d063e":" **CONCLUSION:**\n- In this experiment we observe that when the dataset is split in 80:20 ratio, the models give better results than when it is split in 60:40 ratio to train the model on the Machine Learning Algorithm\n- The set of PTRATIO, RM and LSTAT gives the best results for Logistic Regression in both cases, followed by the sets RM+TAX and PM+LSTAT.\n- And the set of PTRATIO and RM gives the worst results in both cases.","51aa6f76":"- Now the maximum value of MEDV column is 48.80\n- Hence we have deleted 16 (506-490) rows from out dataset having MEDV value as 50","581b4a2f":"- Web observe that th egraph of LSTAT is negatuvely skewed, with outliers present after approximately 31 value","a0ff5395":"Observations:\n- INDUS, RM, TAX, PTRATIO and LSTAT shows fairly good correlation with MEDV","8422c9cd":"- We infer that there's positive linear relationship with the regression fit line\n- From the graph, some of the actual value points are above the line, and some are below the regression best fit line.\n- This model does not fit the data well, as there are difference present between many of the datapoints and the best fit line","321eb143":"## 5th set : RM, LSTAT and PTRATIO","457a1315":"### 80-20 Split","09811c6a":"- From the graph, we infer that there's positive linear relationship with the regression fit line\n- Looking at how the regression line fits in with the scatter plot, some of the actual value points are above the line, and some are below\n- This model does not really fit the data well, as there are difference present between many of the datapoints and the best fit line","c94b3f88":"- We know that R-squared is a relative measure of fit, RMSE is an absolute measure of fit for a model.\n- RMSE measures how accurately the model predicts the response, thus it is the most important criterion for fit if the main purpose of the model is prediction.\n\n**Hence from the above results, we conclude that for 80-20 Split of the dataset:**\n- The model set using the features *PTRATIO, RM and LSTAT* gives the greatest R-Square Score and the Least RMSE Error Score. Hence this is the **best model**, out of all the sets observed in this experiment.\n- Following this, *RM and LSTAT* give the best results i.e. the second highest R-squared score and the second lowest RMSE score, out of all the sets observed in this experiment.\n- *RM and TAX* is also a good set as it gives good RMSE and R-squared score comparitively to other sets\n- *PTRATIO and RM* does not give good results, as it has a very high RMSE value and a very low R-square score. Hence it would not be a good model for prediction purposes","4a07f70f":"Observations:\n- We can see count of entries for each variable is\nsame i.e. 506.\n- Maximum value in MEDV is much higher than 75% of data points\n- The mean and 50% value is nearly equal in value for LSTAT, PTRATIO & MEDV\n\nFor LSTAT & MEDV:\n- The difference between the min and 50% quartile, and between 50% and max value is unequal\n\nFor TAX:\n- There is a significant difference between the mean and 50% quartile value\n- The difference between the min and 50% quartile, and between 50% and max value is almost equal\n- Hence TAX does not have normal distribution\n\nFor PTRATIO:\n- The difference between the min and 50% quartile is greater than, that present between 50% and max value.\n- Hence, the graph of PTRATIO is positively skewed","c59dd7cc":"## SPLITTING THE DATASET","2faf7883":"\n\n---\n\n\n---\n\n\n\n","d14f9dbb":"Observations:\n- We can see count of entries for each variable is\nsame i.e. 506.\n- Maximum value in MEDV is much higher than 75% of data points\n\nFor RM & MEDV:\n- The difference between the min and 50% quartile, and between 50% and max value is almost the equal\n- The mean and 50% value is approximately same\n- Hence RM and MEDV have Normal Distribution for their graphs\n\nFor TAX:\n- The difference between the min and 50% quartile, and between 50% and max value is unequal\n- There is a significant difference between the mean and 50% quartile value\n- Hence TAX does not have normal distribution","57cd9fe5":"- This is not a great regression model as the R square score is near 1.0, and the RMSE error is not quite large.\n- But the results of 80-20 split are better than this to train the dataset","8f671799":"- Now the maximum value of MEDV column is 48.80\n- Hence we have deleted 16 (506-490) rows from out dataset having MEDV value as 50","5583c3f2":"- Now the maximum value of LSTAT column is 30.81\n- Hence we have deleted 40 (506-470) rows from out dataset having LSTAT value as >31","f2f5bb6f":"- This is a fairly good regression model as the R square score is near 1.0, and the RMSE error is comparitively not very large.","bc8caccd":"### TEST & TRAIN DATASET (60-40)\n> We split the data into Training Set (60% of total data) and Test Set (40% of total data)","fb6c429a":"Observations:\n- Graph of RM is normally distributed\n- There are some outliers present lower and higher end of RM values in the dataset\n- Scatter plot of RM vs MEDV show good Positive Linear Relationship.","b1f50b29":"Observations:\n- Graph of TAX is NOT normally distributed\n- Though Boxplot does not show any outlier but there are some extreme TAX values in the dataset\n- From the scatter plot we can observe that for these extreme TAX values, and MEDV ranges from low to high.\n","f5da1eaa":"### 80-20 Split","b4cb56aa":"- Since we need to add a variable for Bias, we add a new column of 1's in X as the first column.\n","45af7017":"Observations:\n- LSTAT shows quite a negatively skewed graph\n- MEDV has a normally distributed graph with outliers present between the range 40-50\n- Negative Linear correlation is present between LSTAT and MEDV. There are a few outliers present near 50\n- There is no relation between MEDV and TAX\n- Normal Distribution is not present in the graph of TAX"}}