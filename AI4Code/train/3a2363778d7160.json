{"cell_type":{"72f58933":"code","32d8e6fd":"code","127a7997":"code","deb654a4":"code","a61cb129":"code","b0091189":"code","937659a7":"code","01cf7f67":"code","3f10a2ee":"code","103f6f9d":"code","4e4e730c":"code","9c206d95":"code","77200c9d":"code","ec65d756":"code","2e52c1be":"code","0fd91a5d":"markdown","8dfd6a70":"markdown","46430080":"markdown","1a30d518":"markdown","568b6d80":"markdown","1d93f1ef":"markdown","9f120fc4":"markdown","9721baee":"markdown","c4639c06":"markdown","ba26a51c":"markdown","e31e0b85":"markdown","9c6e358e":"markdown","2adcd2b8":"markdown","d8c84720":"markdown","2eefaf4f":"markdown","9d35b8bb":"markdown","c135b5ab":"markdown","f3c1895e":"markdown","7def1d4a":"markdown","d577aa40":"markdown","9c856554":"markdown"},"source":{"72f58933":"!pip install top2vec==1.0.6","32d8e6fd":"import numpy as np \nimport pandas as pd \nimport json\nimport os\nfrom top2vec import Top2Vec","127a7997":"metadata_df = pd.read_csv(\"..\/input\/CORD-19-research-challenge\/metadata.csv\")\nmetadata_df.head()","deb654a4":"dataset_dir = \"..\/input\/CORD-19-research-challenge\/\"\ncomm_dir = dataset_dir+\"comm_use_subset\/comm_use_subset\/pdf_json\/\"\nnoncomm_dir = dataset_dir+\"noncomm_use_subset\/noncomm_use_subset\/pdf_json\/\"\ncustom_dir = dataset_dir+\"custom_license\/custom_license\/pdf_json\/\"\nbiorxiv_dir = dataset_dir+\"biorxiv_medrxiv\/biorxiv_medrxiv\/pdf_json\/\"\ndirectories_to_process = [comm_dir,noncomm_dir, custom_dir, biorxiv_dir]\n\npapers_with_text = list(metadata_df[metadata_df.has_pdf_parse==True].sha)\n\npaper_ids = []\ntitles = []\nabstracts = []\nsections = []\nbody_texts = []\n\nfor directory in directories_to_process:\n    \n    filenames = os.listdir(directory)\n\n    for filename in filenames:\n\n      file = json.load(open(directory+filename, 'rb'))\n\n      #check if file contains text\n      if file[\"paper_id\"] in papers_with_text:\n\n        section = []\n        text = []\n\n        for bod in file[\"body_text\"]:\n          section.append(bod[\"section\"])\n          text.append(bod[\"text\"])\n\n        res_df = pd.DataFrame({\"section\":section, \"text\":text}).groupby(\"section\")[\"text\"].apply(' '.join).reset_index()\n\n        for index, row in res_df.iterrows():\n\n          # metadata\n          paper_ids.append(file[\"paper_id\"])\n\n          if(len(file[\"abstract\"])):\n            abstracts.append(file[\"abstract\"][0][\"text\"])\n          else:\n            abstracts.append(\"\")\n\n          titles.append(file[\"metadata\"][\"title\"])\n\n          # add section and text\n          sections.append(row.section)\n          body_texts.append(row.text)\n            \npapers_df = pd.DataFrame({\"id\":paper_ids, \"title\": titles, \"abstract\": abstracts, \"section\": sections, \"text\": body_texts})","a61cb129":"papers_df.head()","b0091189":"papers_df[\"token_counts\"] = papers_df[\"text\"].str.split().map(len)\npapers_df = papers_df[papers_df.token_counts>200].reset_index(drop=True)\npapers_df.drop('token_counts', axis=1, inplace=True)\npapers_df.head()","937659a7":"top2vec = Top2Vec.load(\"..\/input\/covid19top2vec\/covid19_deep_learn_top2vec\")","01cf7f67":"papers_df = pd.read_feather(\"..\/input\/covid19top2vec\/covid19_papers_processed.feather\")","3f10a2ee":"top2vec.get_num_topics()","103f6f9d":"topic_words, word_scores, topic_nums = top2vec.get_topics(399)","4e4e730c":"for topic in topic_nums[180:190]:\n    top2vec.generate_topic_wordcloud(topic, background_color=\"black\")","9c206d95":"topic_words, word_scores, topic_scores, topic_nums = top2vec.search_topics(keywords=[\"covid\", \"infect\"],num_topics=10)\nfor topic in topic_nums:\n    top2vec.generate_topic_wordcloud(topic, background_color=\"black\")","77200c9d":"documents, document_scores, document_nums = top2vec.search_documents_by_topic(topic_num=344, num_docs=2)\n    \nresult_df = papers_df.loc[document_nums]\nresult_df[\"document_scores\"] = document_scores\n\nfor index,row in result_df.iterrows():\n    print(f\"Document: {index}, Score: {row.document_scores}\")\n    print(f\"Section: {row.section}\")\n    print(f\"Title: {row.title}\")\n    print(\"-----------\")\n    print(row.text)\n    print(\"-----------\")\n    print()","ec65d756":"documents, document_scores, document_nums = top2vec.search_documents_by_keyword(keywords=[\"covid\", \"model\"], num_docs=2)\nresult_df = papers_df.loc[document_nums]\nresult_df[\"document_scores\"] = document_scores\n\nfor index,row in result_df.iterrows():\n    print(f\"Document: {index}, Score: {row.document_scores}\")\n    print(f\"Section: {row.section}\")\n    print(f\"Title: {row.title}\")\n    print(\"-----------\")\n    print(row.text)\n    print(\"-----------\")\n    print()\n","2e52c1be":"words, word_scores = top2vec.similar_words(keywords=[\"chloroquine\"], num_words=20)\nfor word, score in zip(words, word_scores):\n    print(f\"{word} {score}\")","0fd91a5d":"### 2. Load pre-processed papers","8dfd6a70":"### 2. Import Libraries","46430080":"### 1. Import Metadata","1a30d518":"# Use Top2Vec for Semantic Search\n\n### \"What is known about transmission, incubation, and environmental stability?\"","568b6d80":"## 3. View topics 180 through 190","1d93f1ef":"# Explore Top2Vec Discovered Topics","9f120fc4":"## 2. Search Papers by Topic\n\nSearch by topic **344**, which appears to be about **infectiousness**.","9721baee":"### 1. Install the [Top2Vec](https:\/\/github.com\/ddangelov\/Top2Vec) library","c4639c06":"### 1. Load pre-trained Top2Vec model ","ba26a51c":"## 1. Get number of topics found by model.","e31e0b85":"# COVID-19: Topic Modeling and Search with Top2Vec\n\n[Top2Vec](https:\/\/github.com\/ddangelov\/Top2Vec) is an algorithm for **topic modelling** and **semantic search**. It **automatically** detects topics present in text and generates jointly embedded topic, document and word vectors. Once you train the Top2Vec model you can:\n* Get number of detected topics.\n* Get topics.\n* Search topics by keywords.\n* Search documents by topic.\n* Find similar words.\n* Find similar documents.\n\nThis notebook preprocesses the [Kaggle COVID-19 Dataset](https:\/\/www.kaggle.com\/allen-institute-for-ai\/CORD-19-research-challenge), it treats each section of every paper as a distinct document. A Top2Vec model is trained on those documents. \n\nOnce the model is trained you can do **semantic** search for documents by topic, searching for documents with keywords, searching for topics with keywords, and for finding similar words. These methods all leverage the joint topic, document, word embeddings distances, which represent semantic similarity. \n\n### For an interactive version of this notebook with search widgets check out my [github](https:\/\/github.com\/ddangelov\/Top2Vec\/blob\/master\/notebooks\/CORD-19_top2vec.ipynb) or my [kaggle](https:\/\/www.kaggle.com\/dangelov\/covid-19-top2vec-interactive-search)!\n\n","9c6e358e":"### 3. Filter Short Sections","2adcd2b8":"## (Recommended) Load Pre-trained Model and Pre-processed Data :)\n\nThe Top2Vec model was trained with the 'deep-learn' speed parameter and took very long to train. It will give much better results than training with 'fast-learn' or 'learn'.\n","d8c84720":"## Pre-process Data","2eefaf4f":"# Import and Setup ","9d35b8bb":"## 3. Search Papers by Keywords\n\nSearch for documents that are about **coronovirus** **models**.","c135b5ab":"### 2. Pre-process Papers\n\nA document will be created for each section of every paper. This document will contain the id, title, abstract, and setion of the paper. It will also contain the text of that section.","f3c1895e":"## 2. Get topics","7def1d4a":"## 1. Search Topics \n\nDiscover topics relevant to **COVID-19** and **infection**.","d577aa40":"## 4. Find Similar Words\n\nFind similar words to **chloroquine**.","9c856554":"## Train Top2Vec Model\n```python\n\n top2vec = Top2Vec(documents=papers_df.text, speed=\"learn\", workers=4)\n\n```\n\nParameters:\n  * ``documents``: Input corpus, should be a list of strings.\n  \n  * ``speed``: This parameter will determine how fast the model takes to train. \n    The 'fast-learn' option is the fastest and will generate the lowest quality\n    vectors. The 'learn' option will learn better quality vectors but take a longer\n    time to train. The 'deep-learn' option will learn the best quality vectors but \n    will take significant time to train.  \n    \n  * ``workers``: The amount of worker threads to be used in training the model. Larger\n    amount will lead to faster training.\n    \nSee [Documentation](https:\/\/top2vec.readthedocs.io\/en\/latest\/README.html)."}}