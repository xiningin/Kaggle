{"cell_type":{"5ea2e6b8":"code","36c42b08":"code","9590d250":"code","62044aa6":"code","0355ea53":"code","d10e6aa6":"code","4905981c":"code","65115031":"code","b64e744a":"code","c0316f2a":"code","e468e70e":"code","4950afb9":"code","64550081":"code","3e33b4ca":"code","c8e53a26":"code","74c8736c":"code","db72c55a":"code","c1d6c589":"code","a09efe49":"code","6d50f50e":"code","547b45ab":"code","c5e5cbbc":"code","5df6c0a7":"code","8456595a":"code","1f62157b":"code","24df662d":"code","d07daa38":"code","7ef2098c":"code","31bbb861":"code","f442ba69":"code","93fcfedc":"code","ac3e75bb":"code","998efe55":"code","371f8d59":"code","e386a774":"code","3192ba99":"code","5918274b":"code","79ae99f9":"code","b9564774":"code","22c560c8":"code","6448f11b":"code","e0d57922":"code","92851ac0":"code","547ae42c":"code","3ab32ece":"code","e1302bc6":"code","cd565962":"code","cfff952a":"code","0a691e86":"code","8433b909":"code","7ccd2a9f":"code","811ad1b0":"code","23a4e42d":"code","529770a5":"code","836e448a":"code","ff4ea461":"code","504fa9d2":"code","2f76b352":"code","04acd945":"code","aa16fa6f":"code","e897663c":"code","9706ee3c":"code","7f6f31a2":"code","71e89f0e":"code","626a53e9":"code","91c2af90":"code","b9d3e205":"code","da5f764c":"code","2074e358":"code","12ba1cbb":"code","610b9ebb":"code","00a129ab":"code","f7a9259a":"code","efec29ee":"markdown","2562067c":"markdown","91e5691e":"markdown","f23c9ac0":"markdown","4678dda6":"markdown","d7de67f1":"markdown","bd7b5361":"markdown","44fe9121":"markdown","bc067258":"markdown","606151de":"markdown","6a5273aa":"markdown","f1a2f2ef":"markdown","dd6bbf24":"markdown","711c9cf3":"markdown","7e405771":"markdown","18ab2b3b":"markdown","57c11abc":"markdown","a779da5b":"markdown","306a228c":"markdown","e7abf703":"markdown"},"source":{"5ea2e6b8":"import pandas as pd\nimport numpy as np\ndf=pd.read_csv('..\/input\/online-shoppers-purchasing-intention-dataset\/online_shoppers_intention.csv')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly as py\nimport plotly.graph_objs as go\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport xgboost as xgb","36c42b08":"df","9590d250":"df.head()","62044aa6":"df.tail()","0355ea53":"df.corr()","d10e6aa6":"df.describe()","4905981c":"df.info()","65115031":"df.shape","b64e744a":"df.isnull().sum()","c0316f2a":"df.skew()","e468e70e":"df.kurt()","4950afb9":"df.shape[0]","64550081":"#Global declartions of function names\nglobal Head\nglobal Size\nglobal Column_names\nglobal Describe\nglobal Shape\nglobal Count\nglobal Value_count\nglobal ISNULL\nglobal Tail\nglobal Ndim\nglobal Nunique\nglobal Memory_usage\nglobal Duplicated\nglobal ISNA\nglobal DTYPES\nglobal CORR\nglobal Info\nglobal operations\n        ","3e33b4ca":"def Count():\n    print('\\033[1m'+\"The count of non null values are:\"+'\\033[0m')\n    co=df.count()\n    print(co,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nCount()\n","c8e53a26":"def Memory_usage():\n    print('\\033[1m'+\"The total memory used is :\"+'\\033[0m')\n    co6=df.memory_usage()\n    print(co6,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nMemory_usage()","74c8736c":"def DTYPES():\n    print('\\033[1m'+\"The datatypes are :\"+'\\033[0m')\n    co9=df.dtypes\n    print(co9,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nDTYPES()","db72c55a":"def operations(df,x):\n    if df[x].dtype==\"float64\":\n        print('\\033[1m'+'', x, 'rows'+'\\033[0m')\n        print('\\033[1m'+\"It is a quantitaive data \\n\"+'\\033[0m')\n        print(\"The mean is :\\n\",df[x].mean())\n        print(\"The median is :\\n\",df[x].median())\n        print(\"The Standard Deviation is \\n\",df[x].std())\n        q1=df[x].quantile(0.25)\n        q2=df[x].quantile(0.5)\n        q3=df[x].quantile(0.75)\n        IQR=q3-q1\n        LLP=q1-1.5*IQR\n        ULP=q3+1.5*IQR\n        print(\"The quartiles are q1 : \\n\",q1)\n        print(\"The quartiles are q2 : \\n\",q2)\n        print(\"The quartiles are q3 :\\n \",q3)\n        print(\"The Uppler limit point of the data is \\n\",ULP)\n        print(\"The lower limit point of the data is \\n \",LLP)\n        if df[x].min()>LLP and df[x].max()<ULP:\n            print(\"The outliers are not present \\n\")\n            print(\"--------------------------------------------------------------------------\")\n\n        else:\n\n            print(\"The outliers are present \\n\")\n            print(\"The outliers are :\")\n            print(df[df[x].values>ULP][x])\n            print(df[df[x].values<LLP][x])\n\n            print(\"--------------------------------------------------------------------------\")\n\n\n    elif df[x].dtype==\"int64\":\n        print('\\033[1m'+'', x, 'rows'+'\\033[0m')\n        print('\\033[1m'+\"It is a quantitaive data \\n\"+'\\033[0m')\n        print(\"The mean is : \\n\",df[x].mean())\n        print(\"The median is : \\n\",df[x].median())\n        print(\"The Standard Deviation is \\n\",df[x].std())\n        q1=df[x].quantile(0.25)\n        q2=df[x].quantile(0.5)\n        q3=df[x].quantile(0.75)\n        IQR=q3-q1\n        LLP=q1-1.5*IQR\n        ULP=q3+1.5*IQR\n        print(\"The quartiles are q1 : \\n\",q1)\n        print(\"The quartiles are q2 : \\n\",q2)\n        print(\"The quartiles are q3 : \\n\",q3)\n        print(\"The Uppler limit point of the data is \\n\",ULP)\n        print(\"The lower limit point of the data is \\n\",LLP)\n        if df[x].min()>LLP and df[x].max()<ULP:\n            print(\"The outliers are not present \\n\")\n\n            print(\"--------------------------------------------------------------------------\")\n\n        else:\n\n            print(\"The outliers are present \\n\")\n            print(\"The outliers are :\")\n            print(df[df[x].values>ULP][x])\n            print(df[df[x].values<LLP][x])\n            print(\"--------------------------------------------------------------------------\")\n\n\n\n\n\n\n\n    else:\n\n        print('\\033[1m'+\"The data is Qualitative \\n\"+'\\033[0m')\n\n\n        if df[x].nunique()==1:\n            print('\\033[1m'+\"The data is singular \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n        elif df[x].nunique()==2:\n            print('\\033[1m'+\"The data is Binary \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n        elif df[x].nunique()>2:\n            print('\\033[1m'+\"The data is Multi \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n\n        print(\"--------------------------------------------------------------------------\")\n\nc=df.columns\nfor i in c:\n    operations(df,i)\n    print(\"\\n\")\n\n\n","c1d6c589":"def Summary():\n        print('\\033[1m'+\"The Summary of data is  \\n\"+'\\033[0m')\n        print(\"The shape of the datset is :\",df.shape)\n        print(\"The sixe o the data set is :\",df.size)\n        print(\"The dimensions of the dataset are:\",df.ndim)\n        print(\"The memory usage of the data set are\",df.memory_usage())\n        print(\"The data types of the dataset are:\",df.dtypes)\n        print(\"--------------------------------------------------------------------------\")\n\nSummary()     \n","a09efe49":" def Column_Summary():\n        print('\\033[1m'+\"The Column wise Summary of data is  \\n\"+'\\033[0m')\n        k=df.columns\n        for i in k:\n            print('\\033[1m'+'', i, 'rows'+'\\033[0m')\n            print(\"The Shape of the column \",i,\"is \",df[i].shape)\n            print(\"The Size of the column \",i,\"is \",df[i].size)\n            print(\"The Dimensions of the column \",i,\"is \",df[i].ndim)\n            print(\"The Memory used by the column \",i,\"is \",df[i].memory_usage())\n            print(\"The Data types  of the column \",i,\"is \",df[i].dtypes)\n            print(\"--------------------------------------------------------------------------\")\nColumn_Summary()","6d50f50e":"df.columns","547b45ab":"sns.set_theme(style=\"darkgrid\")\nsns.countplot(df['Weekend'],palette='autumn')\nplt.show()","c5e5cbbc":"sns.set_theme(style=\"darkgrid\")\nsns.countplot(df['Revenue'],palette='autumn')\nplt.show()","5df6c0a7":"df.head()","8456595a":"a1=[2,1,3,4,8,6,7,5]\na2=[6601,2585,2555,478,79,19,7,6]","1f62157b":"df['OperatingSystems'].value_counts()","24df662d":"import plotly.express as px\nfig = go.Figure(data=[go.Pie(labels=a1,\n                             values=a2,title='Percentage of Diffrent OS Used by visitors')])\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()","d07daa38":"df['Browser'].value_counts()","7ef2098c":"b1=[2,1,4,5,6,10,8,3,13,7,12,11,9]\nb2=[7961,2462,736,467,174,163,135,105,61,49,10,6,6,1]","31bbb861":"import plotly.express as px\nfig = go.Figure(data=[go.Pie(labels=b1,\n                             values=b2,title='Percentage of Diffrent Browsers Used by visitors')])\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()","f442ba69":"df['Region'].value_counts()","93fcfedc":"c1=[1,3,4,2,6,7,9,8,5]\nc2=[4780,2403,1182,1136,805,761,511,434,318]\n","ac3e75bb":"import plotly.express as px\nfig = go.Figure(data=[go.Pie(labels=c1,\n                             values=c2,title='Percentage of Diffrent Regions  by visitors')])\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()","998efe55":"df['TrafficType'].value_counts()","371f8d59":"d1=[2,1,3,4,13,10,6,8,5,11,20,9,7,15,19,14,18,16,12,17]\nd2=[3913,2451,2052,1069,738,450,444,343,260,247,198,42,40,38,17,13,10,3,1,1]","e386a774":"import plotly.express as px\nfig = go.Figure(data=[go.Pie(labels=c1,\n                             values=c2,title='Percentage of Diffrent Traffic Types by visitors')])\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.show()","3192ba99":"sns.set(rc={'figure.figsize':(11.7,8.27)})\nsns.set_theme(style=\"darkgrid\")\nsns.countplot(df['Month'],hue=df['VisitorType'],palette='autumn')\nplt.legend(bbox_to_anchor=(1.05, 1))\nplt.show()","5918274b":"sns.set(rc={'figure.figsize':(15,8.27)})\nsns.set_theme(style=\"darkgrid\")\nsns.countplot(df['Month'],hue=df['SpecialDay'],palette='autumn')\nplt.legend(bbox_to_anchor=(1.05, 1))\nplt.show()","79ae99f9":"sns.set(rc={'figure.figsize':(15,8.27)})\nsns.set_theme(style=\"darkgrid\")\nsns.distplot(df['Administrative'])","b9564774":"sns.set(rc={'figure.figsize':(15,8.27)})\nsns.set_theme(style=\"darkgrid\")\nsns.distplot(df['Administrative_Duration'])","22c560c8":"sns.set(rc={'figure.figsize':(15,8.27)})\nsns.set_theme(style=\"darkgrid\")\nsns.distplot(df['Informational'])","6448f11b":"sns.set(rc={'figure.figsize':(15,8.27)})\nsns.set_theme(style=\"darkgrid\")\nsns.distplot(df['Informational_Duration'])","e0d57922":"sns.set(rc={'figure.figsize':(15,8.27)})\nsns.set_theme(style=\"darkgrid\")\nsns.distplot(df['ProductRelated'])","92851ac0":"sns.set(rc={'figure.figsize':(15,8.27)})\nsns.set_theme(style=\"darkgrid\")\nsns.distplot(df['ProductRelated_Duration'])","547ae42c":"sns.set(rc={'figure.figsize':(15,8.27)})\nsns.set_theme(style=\"darkgrid\")\nsns.distplot(df['BounceRates'])\n","3ab32ece":"sns.set(rc={'figure.figsize':(15,8.27)})\nsns.set_theme(style=\"darkgrid\")\nsns.distplot(df['ExitRates'])\n","e1302bc6":"sns.set(rc={'figure.figsize':(15,8.27)})\nsns.set_theme(style=\"darkgrid\")\nsns.distplot(df['PageValues'])\n","cd565962":"numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n\ndf2=df.select_dtypes(include=numerics)","cfff952a":"sns.set(rc={'figure.figsize':(15,8.27)})\nsns.set_theme(style=\"darkgrid\")\nfor i in df2.columns:\n    sns.boxplot(df[i])\n    plt.show()","0a691e86":"plt.figure(figsize=(15,16))\nax = sns.heatmap(df.corr(),annot = True, cmap = 'viridis')\nplt.show()\n","8433b909":"def count_outliers(data,col):\n        q1 = data[col].quantile(0.25,interpolation='nearest')\n        q2 = data[col].quantile(0.5,interpolation='nearest')\n        q3 = data[col].quantile(0.75,interpolation='nearest')\n        q4 = data[col].quantile(1,interpolation='nearest')\n        IQR = q3 -q1\n        global LLP\n        global ULP\n        LLP = q1 - 1.5*IQR\n        ULP = q3 + 1.5*IQR\n        if data[col].min() > LLP and data[col].max() < ULP:\n            print(\"No outliers in\",i)\n        else:\n            print(\"There are outliers in\",i)\n            x = data[data[col]<LLP][col].size\n            y = data[data[col]>ULP][col].size\n            a.append(i)\n            print('Count of outliers are:',x+y)\nglobal a\na = []\nfor i in df2.columns:\n    count_outliers(df,i)","7ccd2a9f":"def LABEL_ENCODING(c1):\n    from sklearn import preprocessing\n    # label_encoder object knows how to understand word labels.\n    label_encoder = preprocessing.LabelEncoder()\n \n    # Encode labels in column 'species'.\n    df[c1]= label_encoder.fit_transform(df[c1])\n \n    df[c1].unique()\n    return df","811ad1b0":"LABEL_ENCODING('Revenue')","23a4e42d":"df= pd.get_dummies(df, columns = ['Month', 'Weekend','VisitorType'])","529770a5":"df","836e448a":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(df)","ff4ea461":"feature=df.drop('Revenue',axis=1)","504fa9d2":"label=df['Revenue']","2f76b352":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(feature,label,test_size=.3)","04acd945":"print(X_train.shape,y_train.shape)","aa16fa6f":"print(X_test.shape,y_test.shape)","e897663c":"D_train = xgb.DMatrix(data=X_train, label=y_train)\nD_test = xgb.DMatrix(data=X_test, label=y_test)","9706ee3c":"param = {\n    'eta': 0.3, \n    'max_depth': 3,  \n    'objective': 'multi:softprob',  \n    'num_class': 3} \n\nsteps = 20  # The number of training iterations","7f6f31a2":"model = xgb.train(param, D_train, steps)","71e89f0e":"import numpy as np\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score\n\npreds = model.predict(D_test)\nbest_preds = np.asarray([np.argmax(line) for line in preds])\n\nprint(\"Precision = {}\".format(precision_score(y_test, best_preds, average='macro')))\nprint(\"Recall = {}\".format(recall_score(y_test, best_preds, average='macro')))\nprint(\"Accuracy = {}\".format(accuracy_score(y_test, best_preds)))","626a53e9":"from sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA","91c2af90":"pca = PCA(2)","b9d3e205":"df3=pca.fit_transform(df)","da5f764c":"df3.shape","2074e358":"kmeans = KMeans(3)\nkmeans.fit(df3)\n","12ba1cbb":"identified_clusters = kmeans.fit_predict(df3)\nidentified_clusters","610b9ebb":"filter_label=df[identified_clusters==0]","00a129ab":"plt.scatter(filter_label.iloc[:,0] , filter_label.iloc[:,1])\nplt.show()","f7a9259a":"#Getting unique labels\n \nu_labels = np.unique(identified_clusters)\n \n#plotting the results:\nax = plt.subplot(111, projection='3d', label=\"bla\")\n \nfor i in u_labels:\n    ax.scatter(df3[identified_clusters == i , 0] , df3[identified_clusters == i,1] , label = i)\nplt.legend()\nplt.show()","efec29ee":"From the above observation there were many visitors in the shopping website but very few people have generated the revenue ","2562067c":"# Loading Necessary Libraries ","91e5691e":"\n# Data Visualization","f23c9ac0":"From the above observation we can say that very few people have visited the shopping website in the weekend","4678dda6":"Data Set Information:\n\nThe dataset consists of feature vectors belonging to 12,330 sessions.\nThe dataset was formed so that each session\nwould belong to a different user in a 1-year period to avoid\nany tendency to a specific campaign, special day, user\nprofile, or period.\n\n\nAttribute Information:\n\nThe dataset consists of 10 numerical and 8 categorical attributes.\nThe 'Revenue' attribute can be used as the class label.\n\n\"Administrative\", \"Administrative Duration\", \"Informational\", \"Informational Duration\", \"Product Related\" and \"Product Related Duration\" represent the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. The values of these features are derived from the URL information of the pages visited by the user and updated in real time when a user takes an action, e.g. moving from one page to another. The \"Bounce Rate\", \"Exit Rate\" and \"Page Value\" features represent the metrics measured by \"Google Analytics\" for each page in the e-commerce site. The value of \"Bounce Rate\" feature for a web page refers to the percentage of visitors who enter the site from that page and then leave (\"bounce\") without triggering any other requests to the analytics server during that session. The value of \"Exit Rate\" feature for a specific web page is calculated as for all pageviews to the page, the percentage that were the last in the session. The \"Page Value\" feature represents the average value for a web page that a user visited before completing an e-commerce transaction. The \"Special Day\" feature indicates the closeness of the site visiting time to a specific special day (e.g. Mother\u2019s Day, Valentine's Day) in which the sessions are more likely to be finalized with transaction. The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and delivery date. For example, for Valentina\u2019s day, this value takes a nonzero value between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1 on February 8. The dataset also includes operating system, browser, region, traffic type, visitor type as returning or new visitor, a Boolean value indicating whether the date of the visit is weekend, and month of the year.\n\n","d7de67f1":"1)There are no special days between Aug and Nov\n\n2)There are many special Days in the month of may\n\n3)There are very few special days in the month of oct","bd7b5361":"## Distribution Plots","44fe9121":"# Exploratory Data Analysis","bc067258":"               From the above pie chart we can say that most of the vistors are from region 1","606151de":"                     Most of the visitors use Browser of type 2,as we can observe from the above piechart","6a5273aa":"1)Most of the Returning visitors are from the month may\n\n2)Most of the New Visitors are from the month november ","f1a2f2ef":"# Data Preproccessing","dd6bbf24":"                       From the above observation we can say that most of users are from traffic type 1","711c9cf3":"## Box Plot","7e405771":"# Clustering\n","18ab2b3b":"# Feature Engineering","57c11abc":"                       Most of visitors use OS of type 2 ,as we can observe from the above pie chart","a779da5b":"## Relation Plots","306a228c":"## Heat Map","e7abf703":"# Data Modelling"}}