{"cell_type":{"735c14c5":"code","ced5bf56":"code","ce6de374":"code","a25901e8":"code","8b74ed19":"code","529831b5":"code","0763a040":"code","d5267155":"code","dd02800b":"code","8f37c879":"code","bd65e413":"code","9b93cf78":"code","5b6fdd90":"code","375f9d03":"code","080eecac":"code","ff6a0f65":"code","fda07430":"code","ca5e9bb3":"code","10898b4e":"code","ca395c49":"code","511ff302":"code","67cde6e1":"code","0a963ccf":"code","bbccd95e":"code","35d77a21":"code","31b7cb93":"code","0a372777":"code","cfc04133":"code","73d6d407":"code","1e2a3543":"code","c0f0192e":"code","76f6314f":"code","df028218":"code","d886b528":"code","43ecaf11":"code","029fcd7c":"code","bc38dc22":"code","2710dc96":"code","46c66f5f":"code","5bc9cb61":"code","afd7892a":"code","abdeea32":"code","b0443795":"code","1480d17a":"code","981637ac":"code","0b4dc706":"code","55f2512e":"code","7b569b27":"code","775a2c8c":"code","7982cce3":"code","9b3894f2":"code","60bf495b":"code","8e314873":"code","152a6cbb":"code","ddc91a9b":"code","97606807":"code","cfa2e1a3":"code","bb483c2f":"code","db62d538":"code","94595836":"code","493d5f35":"code","f12119f6":"code","9ef13223":"code","0d846c1a":"code","78256a60":"code","c38a5f76":"code","e1e0e9ba":"code","c942034f":"code","2f2b036e":"code","26697ccd":"code","1d9cce9f":"code","13d6a88f":"markdown","799209d1":"markdown","869c3a05":"markdown","9ba05e93":"markdown","4c474a43":"markdown","8de49c38":"markdown","a1e1e427":"markdown","d1873bdb":"markdown"},"source":{"735c14c5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ced5bf56":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport statsmodels.api as sm\nimport warnings\nwarnings.simplefilter(\"ignore\")\nimport missingno as msno\nfrom datetime import date\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler, RobustScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,roc_auc_score\nfrom sklearn.model_selection import GridSearchCV, cross_validate\n","ce6de374":"pd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', False)\npd.set_option('display.float_format', lambda x: '%.3f' % x)","a25901e8":"def load_df():\n    data = pd.read_csv(\"..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n    return data","8b74ed19":"df_ = load_df()\ndf = df_.copy()\ndf.head()","529831b5":"df[\"TotalCharges\"] = df[\"TotalCharges\"].replace(\" \", np.NAN)\ndf[\"TotalCharges\"] = df[\"TotalCharges\"].astype(float)","0763a040":"def check_df(dataframe, head=5, tail = 5):\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n    print(\"##################### Types #####################\")\n    print(dataframe.dtypes)\n    print(\"##################### Head ######################\")\n    print(dataframe.head(head))\n    print(\"##################### Tail ######################\")\n    print(dataframe.tail(tail))\n    print(\"##################### NA ########################\")\n    print(dataframe.isnull().sum())\n    print(\"##################### Quantiles #####################\")\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)","d5267155":"check_df(df)","dd02800b":"df.Contract.value_counts()","8f37c879":"df.Churn.value_counts()","bd65e413":"df.tenure.describe()","9b93cf78":"plt.hist(data = df, x = 'tenure');\nplt.show()","5b6fdd90":"for col in df.columns:\n    print(col + \" : \" + str((df[f\"{col}\"] == 0).sum()))","375f9d03":"df[\"TotalCharges\"] = df[\"TotalCharges\"].replace(\" \", np.NAN)\ndf[\"TotalCharges\"] = df[\"TotalCharges\"].astype(float)","080eecac":"df = df[df[\"tenure\"] != 0]","ff6a0f65":"df.isnull().any()","fda07430":"df.isnull().sum()","ca5e9bb3":"df.dropna(inplace=True)","10898b4e":"del df[\"customerID\"]","ca395c49":"del df[\"SeniorCitizen\"]","511ff302":"df.TotalCharges.describe()","67cde6e1":"plt.hist(data = df, x = 'TotalCharges');\nplt.show()","0a963ccf":"churn_df = df.query('Churn==\"Yes\"')","bbccd95e":"churn_df.TotalCharges.describe()","35d77a21":"plt.hist(data = churn_df, x = 'TotalCharges');\nplt.show()","31b7cb93":"churn_df.TotalCharges.quantile(0.8)","0a372777":"TotalCharges_under80 = churn_df.query('TotalCharges<=2827.59')\nTotalCharges_above80 = churn_df.query('TotalCharges>2827.59')\nTotalCharges_under80.TotalCharges.describe()","cfc04133":"TotalCharges_above80.TotalCharges.describe()","73d6d407":"TotalCharges_under80.tenure.describe()","1e2a3543":"TotalCharges_above80.tenure.describe()","c0f0192e":"plt.figure(figsize = [15, 5]);\nplt.show()","76f6314f":"plt.subplot(1, 2, 1)\nplt.bar([1, 2], [713, 4801])\nplt.show()","df028218":"plt.subplot(1, 2, 2)\nplt.bar([1, 2], [9, 50])\nplt.show()","d886b528":"def outlier_thresholds(dataframe, col_name, q1=0.01, q3=0.99):\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit","43ecaf11":"def check_outlier(dataframe, col_name):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False","029fcd7c":"def replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit","bc38dc22":"def grab_col_names(dataframe, cat_th=10, car_th=20):\n    \"\"\"\n    It gives the names of categorical, numerical and categorical but cardinal variables in the data set.\n    Note: Categorical variables with numerical appearance are also included in categorical variables.\n    Parameters\n    ------\n        dataframe: dataframe\n                The dataframe from which variable names are to be retrieved\n        cat_th: int, optional\n                Class threshold for numeric but categorical variables\n        car_th: int, optinal\n                Class threshold for categorical but cardinal variables\n    Returns\n    ------\n        cat_cols: list\n                Categorical variable list\n        num_cols: list\n                Numeric variable list\n        cat_but_car: list\n                Categorical view cardinal variable list\n    Examples\n    ------\n        import seaborn as sns\n        df = sns.load_dataset(\"iris\")\n        print(grab_col_names(df))\n    Notes\n    ------\n        cat_cols + num_cols + cat_but_car = total number of variables\n        num_but_cat is inside cat_cols.\n        The sum of 3 lists with return is equal to the total number of variables: cat_cols + num_cols + cat_but_car = number of variables\n    \"\"\"\n\n    # cat_cols, cat_but_car\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    print(f\"Observations: {dataframe.shape[0]}\")\n    print(f\"Variables: {dataframe.shape[1]}\")\n    print(f'cat_cols: {len(cat_cols)}')\n    print(f'num_cols: {len(num_cols)}')\n    print(f'cat_but_car: {len(cat_but_car)}')\n    print(f'num_but_cat: {len(num_but_cat)}')\n    return cat_cols, num_cols, cat_but_car","2710dc96":"cat_cols, num_cols, cat_but_car = grab_col_names(df)","46c66f5f":"def label_encoder(dataframe, binary_col):\n    labelencoder = LabelEncoder()\n    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n    return dataframe","5bc9cb61":"def rare_analyser(dataframe, target, cat_cols):\n    for col in cat_cols:\n        print(col, \":\", len(dataframe[col].value_counts()))\n        print(pd.DataFrame({\"COUNT\": dataframe[col].value_counts(),\n                            \"RATIO\": dataframe[col].value_counts() \/ len(dataframe),\n                            \"TARGET_MEAN\": dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\")","afd7892a":"def rare_encoder(dataframe, rare_perc):\n    temp_df = dataframe.copy()\n\n    rare_columns = [col for col in temp_df.columns if temp_df[col].dtypes == 'O'\n                    and (temp_df[col].value_counts() \/ len(temp_df) < rare_perc).any(axis=None)]\n\n    for var in rare_columns:\n        tmp = temp_df[var].value_counts() \/ len(temp_df)\n        rare_labels = tmp[tmp < rare_perc].index\n        temp_df[var] = np.where(temp_df[var].isin(rare_labels), 'Rare', temp_df[var])\n\n    return temp_df","abdeea32":"def one_hot_encoder(dataframe, categorical_cols, drop_first=True):\n    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n    return dataframe","b0443795":"def missing_values_table(dataframe, na_name=False):\n    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n\n    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n    ratio = (dataframe[na_columns].isnull().sum() \/ dataframe.shape[0] * 100).sort_values(ascending=False)\n    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n    print(missing_df, end=\"\\n\")\n\n    if na_name:\n        return na_columns","1480d17a":"cat_cols, num_cols, cat_but_car = grab_col_names(df)","981637ac":"check_outlier(df, num_cols)","0b4dc706":"cat_cols","55f2512e":"df[\"Churn\"].replace([\"Yes\"], \"1\", inplace=True)\ndf[\"Churn\"].replace([\"No\"], \"0\", inplace=True)\ndf[\"Churn\"] = df[\"Churn\"].astype(int)","7b569b27":"def num_summary(dataframe, numerical_col, plot=True):\n    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n    print(dataframe[numerical_col].describe(quantiles).T)\n\n    if plot:\n        dataframe[numerical_col].hist(bins=20)\n        plt.show()","775a2c8c":"for col in num_cols:\n    num_summary(df, col)","7982cce3":"def cat_summary(dataframe, col_name, plot=False):\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() \/ len(dataframe)}))\n    print(\"##########################################\")\n    if plot:\n        sns.countplot(x=dataframe[col_name], data=dataframe)\n        plt.show()","9b3894f2":"for col in cat_cols:\n    cat_summary(df, col)","60bf495b":"def target_analyser(dataframe, target, num_cols, cat_cols):\n    for col in dataframe.columns:\n        if col in cat_cols:\n            print(col, \":\", len(dataframe[col].value_counts()))\n            print(pd.DataFrame({\"COUNT\": dataframe[col].value_counts(),\n                                \"RATIO\": dataframe[col].value_counts() \/ len(dataframe),\n                                \"TARGET_MEAN\": dataframe.groupby(col)[target].mean()}), end=\"\\n\\n\\n\")\n        if col in num_cols:\n            print(pd.DataFrame({\"TARGET_MEAN\": dataframe.groupby(target)[col].mean()}), end=\"\\n\\n\\n\")","8e314873":"target_analyser(df, \"Churn\", num_cols, cat_cols)","152a6cbb":"outlier_thresholds(df, col)","ddc91a9b":"check_outlier(df, col)","97606807":"missing_values_table(df)","cfa2e1a3":"cor = df.corr(method=\"pearson\")\ncor","bb483c2f":"sns.heatmap(cor)\nplt.show()","db62d538":"def pairplot(dataset, target_column):\n    sns.set(style=\"ticks\")\n    sns.pairplot(dataset, hue=target_column)\n    plt.show()","94595836":"pairplot(df, \"Churn\")","493d5f35":"df.loc[df[\"tenure\"] <= 12 , \"tenure_cat\"] = \"one year customer\"\ndf.loc[((df[\"tenure\"] <= 24) & (df[\"tenure\"] > 12)), \"tenure_cat\"] = \"two year customer\"\ndf.loc[((df[\"tenure\"] <= 36) & (df[\"tenure\"] > 24)), \"tenure_cat\"] = \"three year customer\"\ndf.loc[((df[\"tenure\"] <= 60) & (df[\"tenure\"] > 36)), \"tenure_cat\"] = \"five year customer\"\ndf.loc[df[\"tenure\"] > 60, \"tenure_cat\"] = \"over five year customer\"","f12119f6":"cat_cols = [col for col in df.columns if df[col].dtypes == \"O\"]\ncat_cols = [col for col in cat_cols if col not in cat_but_car]\nohe_cols = [col for col in cat_cols if col not in [\"Churn\"]]","9ef13223":"one_hot_encoder(df, ohe_cols)","0d846c1a":"df = one_hot_encoder(df, ohe_cols)","78256a60":"labelencoder = LabelEncoder()\ndf[\"Churn\"] = labelencoder.fit_transform(df[\"Churn\"])\ndf.head()","c38a5f76":"rs = RobustScaler()\ndf[num_cols] = rs.fit_transform(df[num_cols])\ndf.head()","e1e0e9ba":"y = df[\"Churn\"]\nX = df.drop([\"Churn\", \"tenure\"], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=30, random_state=47)","c942034f":"rf_model = RandomForestClassifier(random_state=5).fit(X_train, y_train)\ny_pred = rf_model.predict(X_test)\naccuracy_score(y_pred, y_test)","2f2b036e":"print(\"Accuracy Score: \" + f'{accuracy_score(y_pred, y_test):.2f}')","26697ccd":"def plot_importance(model, features, num=len(X), save=False):\n    feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': features.columns})\n    plt.figure(figsize=(10, 10))\n    sns.set(font_scale=1)\n    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\",\n                                                                      ascending=False)[0:num])\n    plt.title('Features')\n    plt.tight_layout()\n    plt.show()\n    if save:\n        plt.savefig('importances.png')","1d9cce9f":"plot_importance(rf_model, X_train)","13d6a88f":"***Note: The average LTV of 80% of those who unsubscribed is 750 dollars, and its tenures is near 10 months. On the other hand, the average LTV of top 20% of those who unsubscribed is 4750 dollars, and its tenures is near 50 months. And the ratio by the sum of total LTV by each groups is 750*4 : 4750 = 1 : 1.6, which suggests we should focus on serving those 20% customers with high LTV, which brought 60%(1.6\/2.6) of our revennue.***","799209d1":"***right plot: Tenure by above and under 80th percentile of data who unsubscribed.***","869c3a05":"![customer_churn.jpeg](attachment:109428e2-5ccd-4768-bcce-297b5639c061.jpeg)\n### Telco Churn Feature Engineering\n\n#### Bussiness Problem\n\n**It is desirable to develop a machine learning model that can predict customers who will leave the company. You are expected to perform the necessary data analysis and feature engineering steps before developing the model.**\n\n\n#### Dataset Story\n\n**Telco churn data includes information about a fictitious telecom company that provided home phone, and Internet services to 7,043 California customers in the third quarter. It shows which customers have left, stayed or signed up for their service.**\n\n##### CustomerId : customer id\n\n##### Gender : Gender\n\n##### SeniorCitizen : Whether the customer is old (1, 0)\n\n##### Partner : Whether the customer has a partner (Yes, No)\n\n##### Dependents : Whether the customer has dependents (Yes, No)\n\n##### tenure : Number of months the customer has stayed with the company\n\n##### PhoneService : Whether the customer has telephone service (Yes, No)\n\n##### MultipleLines : Whether the customer has more than one line (Yes, No, No phone service)\n\n##### InternetService : Customer's internet service provider (DSL, Fiber optic, No)\n\n##### OnlineSecurity : Whether the customer has online security (Yes, No, no Internet service)\n\n##### OnlineBackup : Whether the customer has an online backup (Yes, No, no Internet service)\n\n##### DeviceProtection : Whether the customer has device protection (Yes, No, no Internet service)\n\n##### TechSupport : Whether the customer has technical support (Yes, No, no Internet service)\n\n##### StreamingTV : Whether the customer has TV broadcast (Yes, No, no Internet service)\n\n##### StreamingMovies : Whether the client is streaming movies (Yes, No, no Internet service)\n\n##### Contract : Customer's contract duration (Month to month, One year, Two years)\n\n##### PaperlessBilling : Whether the customer has a paperless invoice (Yes, No)\n\n##### PaymentMethod : Customer's payment method (Electronic check, Postal check, Bank transfer (automatic), Credit card (automatic))\n\n##### MonthlyCharges : The monthly amount charged to the customer\n\n##### TotalCharges : Total amount charged from customer\n\n##### Churn : Whether the customer is using (Yes or No)\n\n\n\n\n\n**Task 1 : Exploring Data Analysis**\n\n\n\n##### Step 1 : Examine the overall picture.\n\n##### Step 2 : Capture the numeric and categorical variables.\n\n##### Step 3 : Analyze the numerical and categorical variables.\n\n##### Step 4 : Perform target variable analysis. (The average\n\n##### of the target variable according to the categorical variables,\n\n##### the average of the numerical variables according to the target variable)\n\n##### Step 5 : Perform outlier observation analysis.\n\n##### Step 6 : Perform a missing observation analysis.\n\n##### Step 7 : Perform correlation analysis.\n\n\n\n\n\n**Task 2 : Feature Engineering**\n\n\n\n##### Step 1 :  Take the necessary actions for missing and contradictory observations.\n\n##### Step 2 : Create new variables.\n\n##### Step 3 : Perform the encoding operations.\n\n##### Step 4 : Standardize for numeric variables.\n\n##### Step 5 : Create the model.","9ba05e93":"***The found that around 20% of the data are extremely high, so I decided to divide them to see each distribution of data.***","4c474a43":"***Libraries are imported.***","8de49c38":"***Divide the data by the 80th percentile of the data, and show the distribution of its TotalCharges under 80th percentile.***","a1e1e427":"***left plot: LTV by above and under 80th percentile of data who unsubscribed.***","d1873bdb":"***This is not a normal distribution, and with two peaks, which means there are likely two different kinds of groups of people, and either of them love particular services.***"}}