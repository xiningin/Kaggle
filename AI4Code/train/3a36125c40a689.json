{"cell_type":{"199b1de6":"code","1e99537a":"code","d7b65f4d":"code","dcc1fc10":"code","91500d06":"code","3a03ead1":"code","13a2fea4":"code","59a5e044":"code","8a529c63":"code","05113115":"code","aa177cb1":"code","15983334":"code","95ec1f89":"code","8230c106":"code","5afd11c6":"code","bbef8e00":"code","ff8ce5bf":"code","35acf99a":"code","56d740d3":"code","b60ec579":"code","410e1792":"code","5c8ae4ab":"code","8d417f6d":"code","6ffdc41f":"code","cec878cd":"code","f098dfb4":"code","cdb9a2ab":"code","21b21c76":"code","db355e73":"code","ca72a3aa":"code","6ac18225":"code","b43a5c1e":"code","95023ccf":"code","2c76ad44":"code","da89eb0a":"code","97e879ef":"code","2a865883":"code","e12d0457":"code","59df4471":"code","d9e71f14":"code","c1dfc5de":"code","84bed8c1":"code","61c18cf7":"code","3efd5c50":"code","2878365a":"markdown","090d4c5c":"markdown","56d2c223":"markdown","1530356d":"markdown","526f30c4":"markdown","d0a02547":"markdown","4d8e48dd":"markdown","1e8a7405":"markdown","3bd4654c":"markdown","7a6ce329":"markdown","62794e9b":"markdown","b2fd6b0d":"markdown","21b0ce36":"markdown","568aaaf3":"markdown","0e71bd2b":"markdown","b658cb3a":"markdown","ae7369d3":"markdown","83e261dc":"markdown","819dbd28":"markdown","95474615":"markdown","d9eb90ed":"markdown","0057f308":"markdown","04f036f1":"markdown","c2cccc57":"markdown","4891f4df":"markdown","9e57ceb6":"markdown","1a2f49e4":"markdown","879b0e6b":"markdown","3f5369f6":"markdown","eab4de2a":"markdown","9a8982ab":"markdown","232e5265":"markdown","8957ee80":"markdown","b8a17e04":"markdown","2becc9f8":"markdown","9f0a8bcf":"markdown","4f55bf23":"markdown","04a83460":"markdown","280058b3":"markdown","3e55c44c":"markdown","52ef6278":"markdown","1eb61838":"markdown","0b02a557":"markdown","3f5b3e2f":"markdown","e4b0cc9d":"markdown","3c821fa5":"markdown","56d5ea6f":"markdown","0c537ea8":"markdown","ace123e6":"markdown","268a3878":"markdown","d9bb0a53":"markdown","4e3bb522":"markdown","5cc9ad4b":"markdown","928bb1c4":"markdown","1982dd57":"markdown","b0006bae":"markdown","f451dfc7":"markdown","6db5f868":"markdown","36d5c56b":"markdown","cf0c8958":"markdown","f999a6d9":"markdown","a4175a2b":"markdown","ce7a2e61":"markdown","35ccd40a":"markdown","7ed7ef89":"markdown","bd8ea003":"markdown","380cb473":"markdown","1586341c":"markdown","25876ac5":"markdown"},"source":{"199b1de6":"!pip install pandarallel\n\nimport os\nimport shutil\nimport ast\nimport json\nimport glob\nimport random\nimport collections\nimport gc\n\nimport numpy as np\nimport pandas as pd\n\n# Visualization\nimport nibabel as nib\nimport matplotlib.pyplot as plt\nimport SimpleITK as sitk\nimport matplotlib.image as mpimg\nimport seaborn as sns; sns.set();\n\nimport imageio    # save to PNG images\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\n\nfrom tqdm.notebook import tqdm; tqdm.pandas(); # get nice bar\n\nfrom pandarallel import pandarallel; pandarallel.initialize(); \n\n# Seed for reproducability\nseed = 1234\nnp.random.seed(seed)","1e99537a":"# Paths \nKAGGLE_DIR = '\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/'\nIMG_PATH_TRAIN = KAGGLE_DIR + 'train\/'\nIMG_PATH_TEST = KAGGLE_DIR + 'test\/'\nTRAIN_CSV_PATH = KAGGLE_DIR + 'train_labels.csv'\nTEST_CSV_PATH = KAGGLE_DIR + 'sample_submission.csv'","d7b65f4d":"# All filenames for train and test images\ntrain_images = os.listdir(IMG_PATH_TRAIN)\ntest_images = os.listdir(IMG_PATH_TEST)","dcc1fc10":"def load_dicom(path):\n    # read file\n    dicom = pydicom.read_file(path)\n    # get pixel data into a useful format. \n    data = dicom.pixel_array\n    # transform data into black and white scale \/ grayscale\n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data\n\ndef save_png_to_disk(data, path, png_master_dir):\n    # SAVE PNG TO DISK     \n    image_name=path.split('\/')[4:][-1].split('.')[0]                               \n    png_image_path=png_master_dir+'\/'+'\/'.join(path.split('\/')[4:-1])+'\/'+image_name+'.png'    \n    imageio.imsave(png_image_path,data)\n\ndef convert_dicom_to_png(path, png_master_dir, resize = None):\n    dicom = pydicom.read_file(path)\n    data = apply_voi_lut(dicom.pixel_array, dicom)\n    # If Resize == True, Resize Image to Specified Resolution\n    if resize:\n        data = cv2.resize(data, resize)\n    # Transform Data as Necessary     \n    if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    # SAVE PNG TO DISK     \n    save_png_to_disk(data, path, png_master_dir)\n    return data\n\ndef image_stats(path):\n    dicom = pydicom.read_file(path)\n    data = apply_voi_lut(dicom.pixel_array, dicom)\n    \n    # Transform Data as Necessary     \n    if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    \n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    \n    # Compute and Return Image Stats: min, max, mean, std, 25th-, 50th-, and 75th percentile\n    return np.min(data), \\\n            np.max(data), \\\n            np.mean(data), \\\n            np.std(data), \\\n            np.percentile(data, 25), \\\n            np.percentile(data, 50), \\\n            np.percentile(data, 75)\n\ndef is_valid_slice(path, threshold=0):\n    dicom = pydicom.read_file(path)\n    data = apply_voi_lut(dicom.pixel_array, dicom)\n    \n    # Transform Data as Necessary     \n    if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    \n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    \n    # REMOVE FILEPATH FROM IMAGE REGISTRY IF IMAGE HAS LOW INFO VALUE\n    if np.mean(data) <= threshold:\n        return False\n    else:\n        return True","91500d06":"# f = []\n# for (dirpath, dirnames, filenames) in os.walk(IMG_PATH_TRAIN):\n#     f.extend(os.path.join(dirpath, x) for x in filenames)\n    \n# train_file_paths_df = pd.DataFrame({'file_paths': f})\n# train_file_paths_df['directory'] = IMG_PATH_TRAIN\n# train_file_paths_df['dataset'] = train_file_paths_df['file_paths'].str.split(\"\/\", n = 7, expand = True)[4]\n# train_file_paths_df['patient_id'] = train_file_paths_df['file_paths'].str.split(\"\/\", n = 7, expand = True)[5]\n# train_file_paths_df['scan_type'] = train_file_paths_df['file_paths'].str.split(\"\/\", n = 7, expand = True)[6]\n# train_file_paths_df['file'] = train_file_paths_df['file_paths'].str.split(\"\/\", n = 7, expand = True)[7]\n# display(train_file_paths_df.head(2))\n# train_file_paths_df.shape[0]","3a03ead1":"# f = []\n# for (dirpath, dirnames, filenames) in os.walk(IMG_PATH_TEST):\n#     f.extend(os.path.join(dirpath, x) for x in filenames)\n    \n# test_file_paths_df = pd.DataFrame({'file_paths': f})\n# test_file_paths_df['directory'] = IMG_PATH_TEST\n# test_file_paths_df['dataset'] = test_file_paths_df['file_paths'].str.split(\"\/\", n = 7, expand = True)[4]\n# test_file_paths_df['patient_id'] = test_file_paths_df['file_paths'].str.split(\"\/\", n = 7, expand = True)[5]\n# test_file_paths_df['scan_type'] = test_file_paths_df['file_paths'].str.split(\"\/\", n = 7, expand = True)[6]\n# test_file_paths_df['file'] = test_file_paths_df['file_paths'].str.split(\"\/\", n = 7, expand = True)[7]\n# display(test_file_paths_df.head(2))\n# test_file_paths_df.shape[0]","13a2fea4":"# train_df = train_file_paths_df.copy()\n# test_df = test_file_paths_df.copy()\n\n# train_df = train_df[(train_df.patient_id != \"00109\") & \n#                     (train_df.patient_id != \"00123\") &\n#                     (train_df.patient_id != \"00709\")]","59a5e044":"# train_df.to_csv('train_filepaths_rsna.csv', index=False)\n# test_df.to_csv('test_filepaths_rsna.csv', index=False)","8a529c63":"# stdf = train_df.copy()\n# stdf[\"stats\"] = stdf[\"file_paths\"].parallel_apply(lambda x: image_stats(x))\n# stdf[[\"min_px\", \"max_px\", \"mean_px\", \"std_px\", \"q1\", \"q2\", \"q3\"]] = pd.DataFrame(stdf[\"stats\"].tolist(), index=stdf.index)\n# stdf = stdf.drop(['stats'], axis=1)\n# stdf","05113115":"# stdf.to_csv('stats_train_file_paths_df.csv', index=False)","aa177cb1":"# ssdf = test_df.copy()\n# ssdf[\"stats\"] = ssdf[\"file_paths\"].parallel_apply(lambda x: image_stats(x))\n# ssdf[[\"min_px\", \"max_px\", \"mean_px\", \"std_px\", \"q1\", \"q2\", \"q3\"]] = pd.DataFrame(ssdf[\"stats\"].tolist(), index=ssdf.index)\n# ssdf = ssdf.drop(['stats'], axis=1)\n# ssdf","15983334":"# ssdf.to_csv('stats_test_file_paths_df.csv', index=False)","95ec1f89":"train_df = pd.read_csv('\/kaggle\/input\/train-test-filepaths-rsna-full\/stats_train_file_paths_df.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/train-test-filepaths-rsna-full\/stats_test_file_paths_df.csv')","8230c106":"stats_cols = []\nnum_unique = []\n\nfor col in train_df:\n#     print(\"* For attribute  '{}' , there are [ {} ] unique values.\".format(col,\n#                     len(train_meta_df[col].unique())))\n    stats_cols.append(col)\n    num_unique.append(len(train_df[col].unique()))\n    \ntrain_df_stats = pd.DataFrame(\n    {'col_name': stats_cols,\n     'value_count': num_unique,\n     'nan_count': train_df.isna().sum()\n    })\n\ntrain_df_stats = train_df_stats.sort_values(by=['value_count'], ascending=False).reset_index(drop=True)\ntrain_df_stats","5afd11c6":"stats_cols = []\nnum_unique = []\n\nfor col in test_df:\n#     print(\"* For attribute  '{}' , there are [ {} ] unique values.\".format(col,\n#                     len(train_meta_df[col].unique())))\n    stats_cols.append(col)\n    num_unique.append(len(test_df[col].unique()))\n    \ntest_df_stats = pd.DataFrame(\n    {'col_name': stats_cols,\n     'value_count': num_unique,\n     'nan_count': test_df.isna().sum()\n    })\n\ntest_df_stats = test_df_stats.sort_values(by=['value_count'], ascending=False).reset_index(drop=True)\ntest_df_stats","bbef8e00":"fig, axes = plt.subplots(1, 3, figsize=(25, 8), sharey=True)\nfig.suptitle('Train Dataset Pixel Distributions')\n\nsns.histplot(ax=axes[0], data = train_df[['mean_px', 'std_px']], bins=50, alpha=0.5,)\naxes[0].set_title(\"mean, std\")\nsns.histplot(ax=axes[1], data = train_df[['min_px', 'max_px']], bins=50, alpha=0.5,)\naxes[1].set_title(\"min, max\")\nsns.histplot(ax=axes[2], data= train_df[['q1', 'q2', 'q3']], bins=50, alpha=0.5,)\naxes[2].set_title(\"q1, q2, q3\")\nplt.show();","ff8ce5bf":"fig, axes = plt.subplots(1, 3, figsize=(25, 8), sharey=True)\nfig.suptitle('Test Dataset Pixel Distributions')\n\nsns.histplot(ax=axes[0], data = test_df[['mean_px', 'std_px']], bins=50, alpha=0.5,)\naxes[0].set_title(\"mean, std\")\nsns.histplot(ax=axes[1], data = test_df[['min_px', 'max_px']], bins=50, alpha=0.5,)\naxes[1].set_title(\"min, max\")\nsns.histplot(ax=axes[2], data= test_df[['q1', 'q2', 'q3']], bins=50, alpha=0.5,)\naxes[2].set_title(\"q1, q2, q3\")\nplt.show();","35acf99a":"threshold = 50\ntruncated_train_df = train_df[train_df.mean_px >= threshold].reset_index(drop=True)\ntruncated_test_df = test_df[test_df.mean_px >= threshold].reset_index(drop=True)","56d740d3":"def create_png_dir_tree(PNG_MSTR_DIR, train_df, test_df):\n    #delete old folder (if you run the code twice)\n    shutil.rmtree(PNG_MSTR_DIR, ignore_errors=True)\n    \n    # create the main PNG folder with the test and train \n    png_test_path=PNG_MSTR_DIR + '\/test\/'\n    png_train_path=PNG_MSTR_DIR + '\/train\/'\n        \n    os.makedirs(PNG_MSTR_DIR)\n    os.makedirs(png_train_path)\n    os.makedirs(png_test_path)\n    print('\\t\\t\\t DONE DIR TREE')\n\n    # floders creation \n    for trfold in set(train_df.patient_id):\n        os.mkdir(png_train_path+str(trfold).zfill(5))\n        for mp in set(train_df.scan_type):\n            os.mkdir(png_train_path+str(trfold).zfill(5)+'\/'+str(mp))\n    print('\\t\\t\\t DONE CREATING TRAIN DIR')\n\n    for trfold in set(test_df.patient_id): \n        os.mkdir(png_test_path+str(trfold).zfill(5))\n        for mp in set(test_df.scan_type):\n            os.mkdir(png_test_path+str(trfold).zfill(5)+'\/'+str(mp))\n    print('\\t\\t\\t DONE CREATING TEST DIR')","b60ec579":"# # Create directory\n# PNG_ROOT_DIR = 'png_dataset_threshold_' + str(threshold)\n# create_png_dir_tree(PNG_ROOT_DIR, truncated_train_df, truncated_test_df)\n\n# print('\\t\\t\\t Start Saving TRAIN Images')\n# # Convert DICOM to PNG and Save to Disk\n# truncated_train_df[\"file_paths\"].parallel_apply(lambda x: convert_dicom_to_png(x, PNG_ROOT_DIR, (256, 256)));\n# print('\\t\\t\\t Finished Saving TRAIN Images')\n\n# print('\\t\\t\\t Start Saving TEST Images')\n# truncated_test_df[\"file_paths\"].parallel_apply(lambda x: convert_dicom_to_png(x, PNG_ROOT_DIR, (256, 256)));\n# print('\\t\\t\\t Finished Saving TEST Images')","410e1792":"# n = 5\n# j = 0\n# plt.figure(figsize=(18, 10))\n# for i in random.sample(range(truncated_train_df.shape[0]), n):\n#     j +=1\n#     img = mpimg.imread(PNG_ROOT_DIR + '\/train\/' + \n#                        str(truncated_train_df.patient_id.iloc[i]).zfill(5) +\"\/\"+\n#                        str(truncated_train_df.scan_type.iloc[i]) +\"\/\"+\n#                        str(truncated_train_df.file.iloc[i].split(\".\")[0])+'.png') \n#     print(img.shape)\n#     plt.subplot(1, n, j)\n#     imgplot = plt.imshow(img)","5c8ae4ab":"train_df = pd.read_csv('\/kaggle\/input\/train-test-filepaths-rsna-full\/train_filepaths_rsna.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/train-test-filepaths-rsna-full\/test_filepaths_rsna.csv')\n\ntrain_lbl_df = pd.read_csv('\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train_labels.csv')","8d417f6d":"train_lbl_df = train_lbl_df[(train_lbl_df.BraTS21ID != 109) & \n                    (train_lbl_df.BraTS21ID != 123) &\n                    (train_lbl_df.BraTS21ID != 709)].reset_index(drop = True)\ntrain_lbl_df","6ffdc41f":"from sklearn.model_selection import StratifiedKFold\n\nskf = StratifiedKFold(n_splits=5)\n\nprint('Class Ratio:',sum(train_lbl_df['MGMT_value'])\/len(train_lbl_df['MGMT_value']))\n\ntarget = train_lbl_df.loc[:,'MGMT_value']\n\nfold_no = 1\ntrain_fold_dict = {}\nval_fold_dict = {}\nfor train_index, test_index in skf.split(train_lbl_df, target):\n    train = train_lbl_df.loc[train_index,:]\n    val = train_lbl_df.loc[test_index,:]\n    train_fold_dict['train_fold_'+str(fold_no)] = train.set_index('BraTS21ID')['MGMT_value'].to_dict()\n    val_fold_dict['val_fold_'+str(fold_no)] = val.set_index('BraTS21ID')['MGMT_value'].to_dict()\n    print('Fold',str(fold_no),'Class Ratio:',sum(val['MGMT_value'])\/len(val['MGMT_value']),\n          ',\\t len train, val, sum:',len(train), len(val), len(train)+len(val))\n    fold_no += 1","cec878cd":"train_df_1 = train_df.copy()\ntrain_fold_df_1 = train_fold_dict['train_fold_1']\ntrain_df_1['MGMT_value'] = train_df_1['patient_id'].map(train_fold_df_1)\ntrain_df_1 = train_df_1.dropna(axis=0).groupby(['patient_id', 'directory', 'scan_type']).size().reset_index(name='count')\n\ntrain_df_2 = train_df.copy()\ntrain_fold_df_2 = train_fold_dict['train_fold_2']\ntrain_df_2['MGMT_value'] = train_df_2['patient_id'].map(train_fold_df_2)\ntrain_df_2 = train_df_2.dropna(axis=0).groupby(['patient_id', 'directory', 'scan_type']).size().reset_index(name='count')\n\ntrain_df_3 = train_df.copy()\ntrain_fold_df_3 = train_fold_dict['train_fold_3']\ntrain_df_3['MGMT_value'] = train_df_3['patient_id'].map(train_fold_df_3)\ntrain_df_3 = train_df_3.dropna(axis=0).groupby(['patient_id', 'directory', 'scan_type']).size().reset_index(name='count')\n\ntrain_df_4 = train_df.copy()\ntrain_fold_df_4 = train_fold_dict['train_fold_4']\ntrain_df_4['MGMT_value'] = train_df_4['patient_id'].map(train_fold_df_4)\ntrain_df_4 = train_df_4.dropna(axis=0).groupby(['patient_id', 'directory', 'scan_type']).size().reset_index(name='count')\n\ntrain_df_5 = train_df.copy()\ntrain_fold_df_5 = train_fold_dict['train_fold_5']\ntrain_df_5['MGMT_value'] = train_df_5['patient_id'].map(train_fold_df_5)\ntrain_df_5 = train_df_5.dropna(axis=0).groupby(['patient_id', 'directory', 'scan_type']).size().reset_index(name='count')","f098dfb4":"val_df_1 = train_df.copy()\nval_fold_df_1 = val_fold_dict['val_fold_1']\nval_df_1['MGMT_value'] = val_df_1['patient_id'].map(val_fold_df_1)\nval_df_1 = val_df_1.dropna(axis=0).groupby(['patient_id', 'directory', 'scan_type']).size().reset_index(name='count')\n\nval_df_2 = train_df.copy()\nval_fold_df_2 = val_fold_dict['val_fold_2']\nval_df_2['MGMT_value'] = val_df_2['patient_id'].map(val_fold_df_2)\nval_df_2 = val_df_2.dropna(axis=0).groupby(['patient_id', 'directory', 'scan_type']).size().reset_index(name='count')\n\nval_df_3 = train_df.copy()\nval_fold_df_3 = val_fold_dict['val_fold_3']\nval_df_3['MGMT_value'] = val_df_3['patient_id'].map(val_fold_df_3)\nval_df_3 = val_df_3.dropna(axis=0).groupby(['patient_id', 'directory', 'scan_type']).size().reset_index(name='count')\n\nval_df_4 = train_df.copy()\nval_fold_df_4 = val_fold_dict['val_fold_4']\nval_df_4['MGMT_value'] = val_df_4['patient_id'].map(val_fold_df_4)\nval_df_4 = val_df_4.dropna(axis=0).groupby(['patient_id', 'directory', 'scan_type']).size().reset_index(name='count')\n\nval_df_5 = train_df.copy()\nval_fold_df_5 = val_fold_dict['val_fold_5']\nval_df_5['MGMT_value'] = val_df_5['patient_id'].map(val_fold_df_5)\nval_df_5 = val_df_5.dropna(axis=0).groupby(['patient_id', 'directory', 'scan_type']).size().reset_index(name='count')","cdb9a2ab":"print('Train, ', 'Test, ', 'Sum')\nprint(len(set(list(train_df_1.patient_id))), len(set(list(val_df_1.patient_id))), len(set(list(train_df_1.patient_id)))+len(set(list(val_df_1.patient_id))))\nprint(len(set(list(train_df_2.patient_id))), len(set(list(val_df_2.patient_id))), len(set(list(train_df_2.patient_id)))+len(set(list(val_df_2.patient_id))))\nprint(len(set(list(train_df_3.patient_id))), len(set(list(val_df_3.patient_id))), len(set(list(train_df_3.patient_id)))+len(set(list(val_df_3.patient_id))))\nprint(len(set(list(train_df_4.patient_id))), len(set(list(val_df_4.patient_id))), len(set(list(train_df_4.patient_id)))+len(set(list(val_df_4.patient_id))))\nprint(len(set(list(train_df_5.patient_id))), len(set(list(val_df_5.patient_id))), len(set(list(train_df_5.patient_id)))+len(set(list(val_df_5.patient_id))))","21b21c76":"#  Read Metadata train and test dfs\ntrain_meta_df = pd.read_csv('\/kaggle\/input\/stage0-metadata-rsna\/stage_0_train_with_metadata.csv')\ntest_meta_df = pd.read_csv('\/kaggle\/input\/stage0-metadata-rsna\/stage_0_test_with_metadata.csv')\n\ndef get_image_plane(data):\n    '''\n    Returns the MRI's plane from the dicom data.\n    \n    '''\n    x1,y1,_,x2,y2,_ = [round(j) for j in ast.literal_eval(data.ImageOrientationPatient)]\n    cords = [x1,y1,x2,y2]\n\n    if cords == [1,0,0,0]:\n        return 'coronal'\n    if cords == [1,0,0,1]:\n        return 'axial'\n    if cords == [0,1,0,0]:\n        return 'sagittal'\n\ntrain_meta_df['Orientation'] = train_meta_df.apply(get_image_plane, axis=1)\n\ntest_meta_df['Orientation'] = test_meta_df.apply(get_image_plane, axis=1)","db355e73":"dftr = train_meta_df.groupby(['PatientID', 'Orientation', 'SeriesDescription']).size().reset_index(name='count') \ndftr","ca72a3aa":"dftr2 = train_meta_df[(train_meta_df.Rows == 256) & \n                      (train_meta_df.Columns == 256) &\n                      (train_meta_df.Orientation == \"axial\") &\n                      (train_meta_df.SeriesDescription == \"T1w\")].groupby(['PatientID', 'Orientation', 'SeriesDescription']).size().reset_index(name='count') \ndftr2.loc[(dftr2['count'] < 50) & (dftr2['count'] >15)].reset_index(drop = True)","6ac18225":"dftr[dftr.PatientID == 143]","b43a5c1e":"train_df = pd.read_csv('\/kaggle\/input\/train-test-filepaths-rsna-full\/train_filepaths_rsna.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/train-test-filepaths-rsna-full\/test_filepaths_rsna.csv')\n\ndir_train_df = train_df.groupby(['patient_id', 'directory', 'scan_type']).size().reset_index(name='count')\ndir_test_df = test_df.groupby(['patient_id', 'directory', 'scan_type']).size().reset_index(name='count')","95023ccf":"display(dir_train_df.head(2))\ndisplay(dir_test_df.head(2))","2c76ad44":"dir_train_df[dir_train_df.patient_id == 143]","da89eb0a":"dir_train_df.iloc[369]","97e879ef":"def resample(image, ref_image):\n\n    resampler = sitk.ResampleImageFilter()\n    resampler.SetReferenceImage(ref_image)\n    resampler.SetInterpolator(sitk.sitkLinear)\n    \n    resampler.SetTransform(sitk.AffineTransform(image.GetDimension()))\n\n    resampler.SetOutputSpacing(ref_image.GetSpacing())\n\n    resampler.SetSize(ref_image.GetSize())\n\n    resampler.SetOutputDirection(ref_image.GetDirection())\n\n    resampler.SetOutputOrigin(ref_image.GetOrigin())\n\n    resampler.SetDefaultPixelValue(image.GetPixelIDValue())\n\n    resamped_image = resampler.Execute(image)\n    \n    return resamped_image","2a865883":"def normalize_png(data):\n    '''Input: BLock of 2D Images forming a 3D volume of a full brain'''\n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data","e12d0457":"def create_train_val_dir(PNG_MSTR_DIR, train_df, val_df, fold = None):\n    if fold:\n        # create the main PNG folder with the val and train \n        png_val_path=PNG_MSTR_DIR + '\/val_'+str(fold)+'\/'\n        png_train_path=PNG_MSTR_DIR + '\/train_'+str(fold)+'\/'\n    else:\n        png_val_path=PNG_MSTR_DIR + '\/val\/'\n        png_train_path=PNG_MSTR_DIR + '\/train\/'\n        \n    os.makedirs(png_train_path)\n    os.makedirs(png_val_path)\n    print('\\t\\t\\t DONE DIR TREE')\n\n    # floders creation \n    for trfold in set(train_df.patient_id):\n        os.mkdir(png_train_path+str(trfold).zfill(5))\n        for mp in set(train_df.scan_type):\n            os.mkdir(png_train_path+str(trfold).zfill(5)+'\/'+str(mp))\n    print('\\t\\t\\t DONE SAVING TRAIN IMAGES')\n\n    for trfold in set(val_df.patient_id): \n        os.mkdir(png_val_path+str(trfold).zfill(5))\n        for mp in set(val_df.scan_type):\n            os.mkdir(png_val_path+str(trfold).zfill(5)+'\/'+str(mp))\n    print('\\t\\t\\t DONE SAVING VAL IMAGES')\n    \n    \ndef create_test_dir(PNG_MSTR_DIR, test_df):\n    png_test_path=PNG_MSTR_DIR + '\/test\/'\n\n    os.makedirs(png_test_path)\n    print('\\t\\t\\t DONE DIR TREE')\n\n    # floders creation \n    for trfold in set(test_df.patient_id):\n        os.mkdir(png_test_path+str(trfold).zfill(5))\n        for mp in set(test_df.scan_type):\n            os.mkdir(png_test_path+str(trfold).zfill(5)+'\/'+str(mp))\n    print('\\t\\t\\t DONE SAVING TEST IMAGES')\n    \ndef convert_train_val_2_voxel_space(ref_dir, png_out_dir, train_df, val_df, fold = None, \n                                    is_test=True, save_cv_test = False, save_train_val = True, \n                                    test_df = None, threshold = -1.0):\n#     ref_dir = str(dir_train_df.directory.iloc[369])+ \\\n#                 str(dir_train_df.patient_id.iloc[369]).zfill(5)+ \\\n#                 '\/'+str(dir_train_df.scan_type.iloc[369])\n    print('Reference Dir:')\n    print(f'{ref_dir}')\n\n    reader = sitk.ImageSeriesReader()\n    reader.LoadPrivateTagsOn()\n\n    filenamesDICOM = reader.GetGDCMSeriesFileNames(f'{ref_dir}')\n    reader.SetFileNames(filenamesDICOM)\n    ref_sitk = reader.Execute()\n\n    if save_train_val:\n        if is_test:\n            print('\\t STARTED TRAIN CONVERSION and SAVING TO DISK')\n        else:\n            print('\\t STARTED TRAIN_'+str(fold)+' CONVERSION and SAVING TO DISK')\n        for i in tqdm(range(len(train_df))):\n            scan_dir = str(train_df.directory.iloc[i])+ \\\n                        str(train_df.patient_id.iloc[i]).zfill(5)+ \\\n                        '\/'+str(train_df.scan_type.iloc[i])\n\n            if is_test:\n                output_dir = png_out_dir+'\/train\/'+ \\\n                        str(train_df.patient_id.iloc[i]).zfill(5)+ \\\n                        '\/'+str(train_df.scan_type.iloc[i])\n            else:\n                output_dir = png_out_dir+'\/train_'+str(fold)+'\/'+ \\\n                            str(train_df.patient_id.iloc[i]).zfill(5)+ \\\n                            '\/'+str(train_df.scan_type.iloc[i])\n\n            filenamesDICOM = reader.GetGDCMSeriesFileNames(f'{scan_dir}')\n            reader.SetFileNames(filenamesDICOM)\n            scan_sitk = reader.Execute()\n\n            scan_resampled = resample(scan_sitk, ref_sitk)\n            scan_sitk_array = normalize_png(sitk.GetArrayFromImage(scan_resampled))\n\n            for j in range(len(scan_sitk_array[:,0,0])):\n                # SAVE PNG TO DISK IF Criterion TRUE   \n                if np.mean(scan_sitk_array[j,:,:]) <= threshold:\n                    pass\n                else:\n                    imageio.imsave(output_dir+'\/Image-'+str(j)+'.png', scan_sitk_array[j,:,:])\n        if is_test:\n            print('\\t FINISHED TRAIN CONVERSION and SAVING TO DISK')\n        else:\n            print('\\t FINISHED TRAIN_'+str(fold)+' CONVERSION and SAVING TO DISK')\n\n        if is_test:\n            print('\\t STARTED TEST CONVERSION and SAVING TO DISK')\n        else:\n            print('\\t STARTED VAL_'+str(fold)+' CONVERSION and SAVING TO DISK')\n        for i in tqdm(range(len(val_df))):\n            scan_dir = str(val_df.directory.iloc[i])+ \\\n                        str(val_df.patient_id.iloc[i]).zfill(5)+ \\\n                    '\/'+str(val_df.scan_type.iloc[i])\n\n            if is_test:\n                output_dir = png_out_dir+'\/test\/'+ \\\n                        str(val_df.patient_id.iloc[i]).zfill(5)+ \\\n                        '\/'+str(val_df.scan_type.iloc[i])\n            else:\n                output_dir = png_out_dir+'\/val_'+str(fold)+'\/'+ \\\n                            str(val_df.patient_id.iloc[i]).zfill(5)+ \\\n                            '\/'+str(val_df.scan_type.iloc[i])\n\n            filenamesDICOM = reader.GetGDCMSeriesFileNames(f'{scan_dir}')\n            reader.SetFileNames(filenamesDICOM)\n            scan_sitk = reader.Execute()\n\n            scan_resampled = resample(scan_sitk, ref_sitk)\n            scan_sitk_array = normalize_png(sitk.GetArrayFromImage(scan_resampled))\n\n            for j in range(len(scan_sitk_array[:,0,0])):\n                # SAVE PNG TO DISK IF Criterion TRUE    \n                if np.mean(scan_sitk_array[j,:,:]) <= threshold:\n                    pass\n                else:\n                    imageio.imsave(output_dir+'\/Image-'+str(j)+'.png', scan_sitk_array[j,:,:])\n        if is_test:\n            print('\\t FINISHED TEST CONVERSION and SAVING TO DISK')\n        else:\n            print('\\t FINISHED VAL_'+str(fold)+' CONVERSION and SAVING TO DISK')\n    else:\n        print('\\t ONLY SAVE TEST - SKIP TRAIN \/ VAL')\n        \n    if save_cv_test:\n        print('\\t STARTED TEST CONVERSION and SAVING TO DISK')\n        for i in tqdm(range(len(test_df))):\n            scan_dir = str(test_df.directory.iloc[i])+ \\\n                        str(test_df.patient_id.iloc[i]).zfill(5)+ \\\n                    '\/'+str(test_df.scan_type.iloc[i])\n\n            output_dir = png_out_dir+'\/test\/'+ \\\n                        str(test_df.patient_id.iloc[i]).zfill(5)+ \\\n                        '\/'+str(test_df.scan_type.iloc[i])\n\n            filenamesDICOM = reader.GetGDCMSeriesFileNames(f'{scan_dir}')\n            reader.SetFileNames(filenamesDICOM)\n            scan_sitk = reader.Execute()\n\n            scan_resampled = resample(scan_sitk, ref_sitk)\n            scan_sitk_array = normalize_png(sitk.GetArrayFromImage(scan_resampled))\n\n            for j in range(len(scan_sitk_array[:,0,0])):\n                # SAVE PNG TO DISK     \n                imageio.imsave(output_dir+'\/Image-'+str(j)+'.png', scan_sitk_array[j,:,:])\n        print('\\t FINISHED TEST CONVERSION and SAVING TO DISK')","59df4471":"create_k_fold_cv_ds = True\ncreate_test_ds = False\nfold = 1\n\nif create_k_fold_cv_ds:\n    # Load summary dataframes\n    train_df = pd.read_csv('\/kaggle\/input\/train-test-filepaths-rsna-full\/train_filepaths_rsna.csv')\n    test_df = pd.read_csv('\/kaggle\/input\/train-test-filepaths-rsna-full\/test_filepaths_rsna.csv')\n\n    dir_train_df = train_df.groupby(['patient_id', 'directory', 'scan_type']).size().reset_index(name='count')\n    dir_test_df = test_df.groupby(['patient_id', 'directory', 'scan_type']).size().reset_index(name='count')\n\n    # Create k-fold Train \/ Val Directories\n    png_out_dir = os.path.join('\/kaggle\/working', 'png_'+str(fold)+'_outof_5_fold_cv')\n    if os.path.exists(png_out_dir) and os.path.isdir(png_out_dir):\n        shutil.rmtree(png_out_dir)\n    os.makedirs(png_out_dir)\n\n    create_train_val_dir(png_out_dir, train_df_1, val_df_1, fold = fold)\n#     create_train_val_dir(png_out_dir, train_df_2, val_df_2, fold = fold)\n#     create_train_val_dir(png_out_dir, train_df_3, val_df_3, fold = fold)\n#     create_train_val_dir(png_out_dir, train_df_4, val_df_4, fold = fold)\n#     create_train_val_dir(png_out_dir, train_df_5, val_df_5, fold = fold)\n\n    # Choose Reference 3D Volume (Collection of Images)\n    ref_dir = str(dir_train_df.directory.iloc[369])+ \\\n                    str(dir_train_df.patient_id.iloc[369]).zfill(5)+ \\\n                    '\/'+str(dir_train_df.scan_type.iloc[369])\n    \n    if create_test_ds:\n        # Create Test Directory\n#         test_png_out_dir = os.path.join('\/kaggle\/working', 'png_test_axial_256x256x36')\n#         if os.path.exists(test_png_out_dir) and os.path.isdir(test_png_out_dir):\n#             shutil.rmtree(test_png_out_dir)\n#         os.makedirs(test_png_out_dir)\n#         png_out_dir = test_png_out_dir\n        create_test_dir(png_out_dir, dir_test_df)\n        convert_train_val_2_voxel_space(ref_dir, test_png_out_dir, train_df_1, val_df_1, fold = fold, \n                is_test=False, save_cv_test = True, save_train_val = False, test_df = dir_test_df[:8])\n\n    # Convert to Voxel Space of Choice\n    convert_train_val_2_voxel_space(ref_dir, png_out_dir, train_df_1[:8], val_df_1[:8], fold = fold, \n                                    is_test=False, threshold = 0.0)\n#     convert_train_val_2_voxel_space(ref_dir, png_out_dir, train_df_2, val_df_2, fold = fold, \n#                                     is_test=False)\n#     convert_train_val_2_voxel_space(ref_dir, png_out_dir, train_df_3, val_df_3, fold = fold, \n#                                     is_test=False)\n#     convert_train_val_2_voxel_space(ref_dir, png_out_dir, train_df_4, val_df_4, fold = fold, \n#                                     is_test=False)\n#     convert_train_val_2_voxel_space(ref_dir, png_out_dir, train_df_5, val_df_5, fold = fold, \n#                                     is_test=False)","d9e71f14":"!ls -alt .\/png_1_outof_5_fold_cv\/train_1\/00183\/FLAIR","c1dfc5de":"create_train_test_ds = False\n\nif create_train_test_ds:\n    # Load summary dataframes\n    train_df = pd.read_csv('\/kaggle\/input\/train-test-filepaths-rsna-full\/train_filepaths_rsna.csv')\n    test_df = pd.read_csv('\/kaggle\/input\/train-test-filepaths-rsna-full\/test_filepaths_rsna.csv')\n\n    dir_train_df = train_df.groupby(['patient_id', 'directory', 'scan_type']).size().reset_index(name='count')\n    dir_test_df = test_df.groupby(['patient_id', 'directory', 'scan_type']).size().reset_index(name='count')\n\n    # Create Train \/ Test Dirs\n    png_out_dir = os.path.join('\/kaggle\/working', 'png_voxel_converted_ds')\n    if os.path.exists(png_out_dir) and os.path.isdir(png_out_dir):\n        shutil.rmtree(png_out_dir)\n    os.makedirs(png_out_dir)\n    \n    create_png_dir_tree(png_out_dir, dir_train_df, dir_test_df)\n\n    # Choose Reference 3D Volume (Collection of Images)\n    ref_dir = str(dir_train_df.directory.iloc[369])+ \\\n                    str(dir_train_df.patient_id.iloc[369]).zfill(5)+ \\\n                    '\/'+str(dir_train_df.scan_type.iloc[369])\n\n    # Convert to Voxel Space of Choice and Save\n    convert_train_val_2_voxel_space(ref_dir, png_out_dir, dir_train_df[:8], dir_test_df[:8], \n                                    fold = None, is_test=True)","84bed8c1":"'''Check out the writing to disk process.'''\n# !ls \/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00143\/T1w\/ | wc -l\n# !ls \/kaggle\/working\/png_voxel_converted_ds\/train\/00000\/FLAIR","61c18cf7":"if create_train_test_ds:\n    n = 1\n    j = 0\n    plt.figure(figsize=(18, 10))\n    img = mpimg.imread('\/kaggle\/working\/png_voxel_converted_ds\/train\/00000\/T2w\/Image-18.png')\n    print(img.shape)\n    plt.subplot(1, 4, 1)\n    imgplot = plt.imshow(img)\n    img = mpimg.imread('\/kaggle\/working\/png_voxel_converted_ds\/train\/00000\/FLAIR\/Image-18.png')\n    print(img.shape)\n    plt.subplot(1, 4, 2)\n    imgplot = plt.imshow(img)\n    img = mpimg.imread('\/kaggle\/working\/png_voxel_converted_ds\/train\/00000\/T1wCE\/Image-18.png')\n    print(img.shape)\n    plt.subplot(1, 4, 3)\n    imgplot = plt.imshow(img)\n    img = mpimg.imread('\/kaggle\/working\/png_voxel_converted_ds\/train\/00000\/T1w\/Image-18.png')\n    print(img.shape)\n    plt.subplot(1, 4, 4)\n    imgplot = plt.imshow(img)","3efd5c50":"!echo \"This dataset contains PNG files in AXIAL orientation for all patients\" > README.txt","2878365a":"**Check sizes make sense**","090d4c5c":"If you don't want to uncomment code-blocks above and rerun the entire process.","56d2c223":"<a id=\"20\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>5. Filter Based on Thershold and Save PNGs<center><h2>","1530356d":"### Helper Functions to : Create Directory Tree and Save Converted Voxel Space","526f30c4":"<a id=\"10\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>3. Create DataFrame with Image Filepaths<center><h2>","d0a02547":"\u2757\u2757\u2757 IF YOU WANT TO VISUALIZE n - RANDOM SAVED PNG FILES UNCOMMENT CELL BELOW \u2757\u2757\u2757","4d8e48dd":"Save to *.csv file","1e8a7405":"# Trick to be able to create Dataset from PNG image collections","3bd4654c":"**\\test**","7a6ce329":"<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='color:white; background:darkviolet; border:0' role=\"tab\" aria-controls=\"home\"><center>Quick Navigation<\/center><\/h3>\n\n* [1. Overview](#1)\n* [2. Helper Functions](#2)\n* [3. Create DataFrame with Image Filepaths](#10)\n* [4. Compute Image Data Stats](#15)\n* [5. Filter Based on Theshold and Save PNGs](#20)\n* [6. Train \/ Val Split](#30)\n* [7. Convert to Voxel Space of Choice](#40)","62794e9b":"Some Useful Histograms","b2fd6b0d":"# Read pre-saved *csv file","21b0ce36":"### In Conclusion:\n* There are 20 examples (20 patients) with T1w 3D volumes of resolution 256 x 256 and between 15 and 50 slices and \"Axial\" orientation.\n\n* We chose PatientID = 143 with T1w 256x256 and 36 slices as the rederence 3D volume.\n\n* Next we will convert all other modalities for all patients into the same voxel space as the 3D volume of PatientID = 143. \n\n* For that we will need a dataframe with all the modalities and their associated file - paths (about 2328 = 582 * 4).","568aaaf3":"# Steps\n* As we saw in the [\n\ud83e\udde0 Advanced EDA - Brain Tumor Data \ud83e\udde0](https:\/\/www.kaggle.com\/smoschou55\/advanced-eda-brain-tumor-data) each patient has all images in a single modality in the same plane of reference, e.g. all FLAIR coronal, all T1w and T1wCE axial, and all T2w sagittal.\n\n* Thus, we just need to \n    1. Determine the orientation of each modality per patient (we need the summary table from EDA)\n    2. Choose a reference example modality in terms of orientation and resolution\n    3. Use Simple ITK Python package to convert one 3D volume (collection of all images in a modality per patient) into the orientation and resolution of the reference example 3D volume (e.g. Axial T1w Volume of (256, 256, 32)).\n    4. Finally, we can save 2D SLICES into DICOM or PNG formats. \n    5. OPTIONALLY: Determine which **IMAGES** need to be removed (np.mean(data) < threshold) and only store those images that have important information in them. E.g. save each image in the X-range of the 3D volume (image sequences) into PNG **IF and ONLY IF** np.mean(data) >= threshold.","0e71bd2b":"## 3 + 4. Convert to Voxel Space of Choice with Simple ITK and Save","b658cb3a":"### [Exclude 3 problematic cases](https:\/\/www.kaggle.com\/c\/rsna-miccai-brain-tumor-radiogenomic-classification\/discussion\/262046)\n\n**BraTSIDs**\n* 109\n* 123\n* 709","ae7369d3":"# Remove Paths to Images based on some Critetia\ne.g. remove images from path files df that have np.mean(data) < 10","83e261dc":"# Train \/ Val k -fold Cross Validation Splits","819dbd28":"# Create Master DataFrame (and save into *.csv - file) with Pixel Stats per Image.\nThis only needs to take place once and then can be used a number of times to remove images using any type of stats criterion from the path files dataframe before creating a new PNG dataset.","95474615":"**\/test**","d9eb90ed":"<a id=\"15\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>4. Compute Image Data Stats<center><h2>","0057f308":"Exact folder structure:\n\n\n```\nTraining\/Validation\/Testing\n\u2502\n\u2514\u2500\u2500\u2500 00000\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500 FLAIR\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 ...\n\u2502   \u2502   \n\u2502   \u2514\u2500\u2500\u2500 T1w\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 ...\n\u2502   \u2502   \n\u2502   \u2514\u2500\u2500\u2500 T1wCE\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 ...\n\u2502   \u2502   \n\u2502   \u2514\u2500\u2500\u2500 T2w\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 .....\n\u2502   \n\u2514\u2500\u2500\u2500 00001\n\u2502   \u2502 ...\n\u2502   \n\u2502 ...   \n\u2502   \n\u2514\u2500\u2500\u2500 00002\n\u2502   \u2502 ...\n```","04f036f1":"# Create Directory Tree to Host PNGs","c2cccc57":"# SAVE PNG IMAGES INTO WORKING DIR","4891f4df":"NOTE: Here we have not removed yet the 3 patients with problematic datasets, thus 585 * 4 = 2340.","9e57ceb6":"### Helper Functions to : Resample, Normalize and Convert to Voxel Space of Interest","1a2f49e4":"## 5 - fold Stratified Cross Validation on Target Bindary Values MGMT_value","879b0e6b":"## Files\n**train\/** - folder containing the training files, with each top-level folder representing a subject  \n**train_labels.csv** - file containing the target MGMT_value for each subject in the training data (e.g. the presence of MGMT promoter methylation)   \n**test\/** - the test files, which use the same structure as train\/; your task is to predict the MGMT_value for each subject in the test data. NOTE: the total size of the rerun test set (Public and Private) is ~5x the size of the Public test set   \n**sample_submission.csv** - a sample submission file in the correct format","3f5369f6":"### DataFrame of all modalities with their associated file-paths","eab4de2a":"\u2757\u2757\u2757 SAVE A FEW EXAMPLES TO DEMONSTRATE \u2757\u2757\u2757 ","9a8982ab":"**\/train**","232e5265":"**\\test**","8957ee80":"**\\train**","b8a17e04":"\u2757\u2757\u2757 **Uncomment Below to Repeat the entire IO process from sratch** \u2757\u2757\u2757","2becc9f8":"Indeed Images 0,1,2 and 32, 33, 34, 35 for threshold = 0 were removed.","9f0a8bcf":"# Conclusions\n* Images have different sizes, so we used CV2 to resize to the desired resolution, in this case 256 x 256.\n\n* We might also want to convert all images to the same plane of reference, most probably into axial plane (most images are already into axial plane).","4f55bf23":"<a id=\"40\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>7. Convert to Voxel Space of Choice<center><h2>","04a83460":"\u2757\u2757\u2757 IF YOU WANT TO SAVE PNG FILES ABOVE THRESHOLD UNCOMMENT CELL BELOW \u2757\u2757\u2757","280058b3":"### For more details in pixel arrays see : [Working with Pixel Data](https:\/\/pydicom.github.io\/pydicom\/stable\/old\/working_with_pixel_data.html)","3e55c44c":"# Visualize Overall Pixel Statistics to get Insights on Images","52ef6278":"![](https:\/\/storage.googleapis.com\/kaggle-competitions\/kaggle\/29653\/logos\/header.png)","1eb61838":"Based on this fantastic notebook: [\nConnecting voxel spaces](https:\/\/www.kaggle.com\/boojum\/connecting-voxel-spaces)","0b02a557":"DICOM\u00ae \u2014 [Digital Imaging and Communications in Medicine](https:\/\/www.dicomstandard.org\/about-home) \u2014 is the international standard for medical images and related information. It defines the formats for medical images that can be exchanged with the data and quality necessary for clinical use. With hundreds of thousands of medical imaging devices in use, DICOM\u00ae is one of the most widely deployed healthcare messaging Standards in the world.","3f5b3e2f":"The exact mpMRI scans included are:\n\n- Fluid Attenuated Inversion Recovery (FLAIR)\n- T1-weighted pre-contrast (T1w)\n- T1-weighted post-contrast (T1Gd)\n- T2-weighted (T2)","e4b0cc9d":"Similar Distributions as for Train dataset.","3c821fa5":"\u2757\u2757\u2757 SAVE A FEW EXAMPLES TO DEMONSTRATE \u2757\u2757\u2757 ","56d5ea6f":"**train\/ folds**","0c537ea8":"**\\train**","ace123e6":"**\\test**","268a3878":"<a id=\"30\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>6. Train \/ Val Splits<center><h2>","d9bb0a53":"Save any time of csv or text file","4e3bb522":"# Visualize PNG images","5cc9ad4b":"#### 5. You can remove images with mostly empty pixel values (see Sec 5: Filter Based on Theshold and Save PNGs)","928bb1c4":"**Visualize slices of Patient ID 0, which has T1w, T1wCE : Axial, FLAIR : Coronal, and T2w: Sagittal Orientations and can easily see whether the conversion to Axial worked or not.**","1982dd57":"**\\train**","b0006bae":"Number of unique values","f451dfc7":"## 2. Choose a reference example modality in terms of orientation and resolution","6db5f868":"There are many empty images.","36d5c56b":"## 1. Determine the orientation of each modality per patient","cf0c8958":"**val\/ folds**","f999a6d9":"Index 369","a4175a2b":"**Create k-fold Train \/ Val Directories, Convert and Save PNGs**","ce7a2e61":"### Check that empty slices were removed","35ccd40a":"# CONVERT DICOM TO AXIAL PNG 2D SLICES, <br \/> k-FOLD CV, FILTER BASED ON IMAGE PIXEL STATISTICS\n## \ud83e\udde0 RSNA-MICCAI Brain Tumor Radiogenomic Classification \ud83e\udde0\n\n\n**Data Preprocessing** for [RSNA-MICCAI Brain Tumor Radiogenomic Classification](https:\/\/www.kaggle.com\/c\/rsna-miccai-brain-tumor-radiogenomic-classification) challenge with steps on how to **filter** useful images, **create map of chosen images**, **make k-fold Train\/Val splits**, **useful insights on Image Pixel Statistics** and **convert DICOM to PNG records** of the MRI scans.\n\n---------------------------------------\n\n**Credit:**\nNotebook based on \n1. this wonderful solution [Connecting voxel spaces](https:\/\/www.kaggle.com\/boojum\/connecting-voxel-spaces), \n2. my EDA notebook [\n\ud83e\udde0 Brain Radiogenomics Advanced EDA](https:\/\/www.kaggle.com\/smoschou55\/brain-radiogenomics-advanced-eda) \n\nand some inspiration from the following notebooks: \n1. [\n\ud83e\udde0Brain Tumor\ud83e\udde0 - EDA with Animations and Modeling](https:\/\/www.kaggle.com\/ihelon\/brain-tumor-eda-with-animations-and-modeling), \n2. [DICOM to PNG dataset (128 GB -> 5.2 GB) \ud83c\udfa8\ud83d\udd25](https:\/\/www.kaggle.com\/c\/rsna-miccai-brain-tumor-radiogenomic-classification\/discussion\/253000) and \n3. [\ud83e\udde0Fast DICOM--> PNG full DATA+ {Download DATA} \u2705](https:\/\/www.kaggle.com\/anasshnn\/fast-dicom-png-full-data-download-data).\n\n<!-- 2. [Converting DICOM Metadata to CSV](https:\/\/www.kaggle.com\/carlolepelaars\/converting-dicom-metadata-to-csv-rsna-ihd-2019)\n3. [DICOM Metadata EDA](https:\/\/www.kaggle.com\/anarthal\/dicom-metadata-eda)\n4. [Pulmonary Dicom Preprocessing](https:\/\/www.kaggle.com\/allunia\/pulmonary-dicom-preprocessing#Prepare-to-start-) and \n5. [Insightful EDA on Meta Data & Dicom Files](https:\/\/www.kaggle.com\/jagdmir\/insightful-eda-on-meta-data-dicom-files).\n6. [BTRC EDA (Final)](https:\/\/www.kaggle.com\/josecarmona\/btrc-eda-final)\n7. [(Part-1) RSNA-MICCAI BTRC: Understanding The Data](https:\/\/www.kaggle.com\/arnabs007\/part-1-rsna-miccai-btrc-understanding-the-data) -->","7ed7ef89":"**Create Train \/ Test Directories, Convert and Save PNGs**","bd8ea003":"### [Exclude 3 problematic cases](https:\/\/www.kaggle.com\/c\/rsna-miccai-brain-tumor-radiogenomic-classification\/discussion\/262046)\n\n**BraTSIDs**\n* 00109\n* 00123\n* 00709","380cb473":"<a id=\"1\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>1. Overview<center><h2>","1586341c":"<a id=\"2\"><\/a>\n<h2 style='background:darkviolet; border:0; color:white'><center>2. Helper Functions<center><h2>","25876ac5":"\u2757\u2757\u2757 **Uncomment Below to Repeat the entire IO process from sratch** \u2757\u2757\u2757"}}