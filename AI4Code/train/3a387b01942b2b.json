{"cell_type":{"cb38705a":"code","88891f41":"code","be4370ec":"code","2b7571bf":"code","5e92d1b7":"code","4847673f":"code","9409f4e9":"code","9cfad42b":"code","ab05e796":"code","ca097416":"code","6afb478f":"code","a120108d":"code","a35a6a12":"code","ddca4245":"code","79170e92":"code","0316f608":"code","ca4f428b":"code","666e6ddf":"markdown"},"source":{"cb38705a":"import os, cv2\nimport numpy as np\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.optimizers import SGD\nfrom keras.preprocessing.image import img_to_array, array_to_img, load_img\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n\nnp.random.seed(7)\n\n# fix dimension ordering issue\n# https:\/\/stackoverflow.com\/questions\/39547279\/loading-weights-in-th-format-when-keras-is-set-to-tf-format\nfrom keras import backend as K\n# K.set_image_dim_ordering('th')\n\n# https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/backend\/set_image_data_format\nK.set_image_data_format('channels_last')\n# print(K.image_data_format())  ","88891f41":"import zipfile\nwith zipfile.ZipFile('..\/input\/dogs-vs-cats-redux-kernels-edition\/train.zip',\"r\") as z:\n    z.extractall('input\/dogs-vs-cats-redux-kernels-edition\/')\nwith zipfile.ZipFile('..\/input\/dogs-vs-cats-redux-kernels-edition\/test.zip',\"r\") as z:\n    z.extractall('input\/dogs-vs-cats-redux-kernels-edition\/')    ","be4370ec":"img_width = 150\nimg_height = 150\nTRAIN_DIR = 'input\/dogs-vs-cats-redux-kernels-edition\/train\/'\nTEST_DIR = '.input\/dogs-vs-cats-redux-kernels-edition\/test\/'\ntrain_images_dogs_cats = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)]","2b7571bf":"# Sort the traning set. Use 5000 images of cats and dogs instead of all 25000 to speed up the learning process.\n# If we sort them, the top part will be cats, bottom part will be dogs.\ntrain_images_dogs_cats.sort()\ntrain_images_dogs_cats = train_images_dogs_cats[:5000] + train_images_dogs_cats[-5000:] ","5e92d1b7":"# Now the images have to be represented in numbers. For this, using the openCV library read and resize the image.\n# Generate labels for the supervised learning set.\n# Below is the helper function to do so.\n\ndef prepare_data(list_of_images):\n    \"\"\"\n    Returns two arrays: \n        x is an array of resized images\n        y is an array of labels\n    \"\"\"\n    x = [] # images as arrays\n    y = [] # labels\n    \n    for image in list_of_images:\n        x.append(cv2.resize(cv2.imread(image), (img_width,img_height), interpolation=cv2.INTER_CUBIC))\n    \n    for image in list_of_images:\n        image = image.replace(\"dogs-vs-cats-redux-kernels-edition\/\", \"\")\n        if 'dog' in image:\n            y.append(1)\n        elif 'cat' in image:\n            y.append(0)\n            \n    return shuffle(np.array(x), np.array(y))","4847673f":"X, Y = prepare_data(train_images_dogs_cats)","9409f4e9":"print (X.shape)\nprint (Y.shape)\nprint (Y.sum())","9cfad42b":"batch_size = 16\n\nsome_entry = array_to_img(X[-1])\nsome_entry","ab05e796":"model = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(img_width, img_height, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nprint (model.summary())","ca097416":"model.fit(X, Y, batch_size=batch_size, epochs=5, validation_split=0.3)","6afb478f":"# https:\/\/faroit.github.io\/keras-docs\/1.2.2\/backend\/\n# For 2D data (e.g. image), \"tf\" assumes (rows, cols, channels) while \"th\" assumes (channels, rows, cols).\n\n# from keras.applications.inception_v3 import InceptionV3\n# weights = '..\/input\/inceptionv3\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n# model = InceptionV3(include_top=False, weights=weights)\n\nfrom keras.applications.vgg16 import VGG16\nweights = '..\/input\/vgg16\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\nmodel = VGG16(include_top=False, weights=weights)","a120108d":"from os import makedirs\nfrom os.path import join, exists, expanduser\n\ncache_dir = expanduser(join('~', '.keras'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\nmodels_dir = join(cache_dir, 'models')\nif not exists(models_dir):\n    makedirs(models_dir)\n!cp  ..\/input\/inceptionv3\/* ~\/.keras\/models\/\n!cp  ..\/input\/vgg16\/* ~\/.keras\/models\/","a35a6a12":"X.shape","ddca4245":"bottleneck_features = model.predict(X)","79170e92":"model = Sequential()\nmodel.add(Flatten(input_shape=bottleneck_features.shape[1:]))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n\nprint (model.summary())\n\nmodel.fit(bottleneck_features, \n          Y,\n          epochs=10,\n          batch_size=batch_size,\n          validation_split=0.3)","0316f608":"# Fine Tuning\nbase_model = VGG16(include_top=False, weights=weights, input_shape=(150,150,3))\n\nfull_model = Model(inputs=base_model.input, outputs=model(base_model.output))\n\n# set the first 25 layers (up to the last conv block)\n# to non-trainable (weights will not be updated)\n# for layer in full_model.layers[:25]:\n#     layer.trainable = False\n    \n# compile the model with a SGD\/momentum optimizer\n# and a very slow learning rate.\nfull_model.compile(loss='binary_crossentropy',\n                   optimizer=SGD(lr=1e-4, momentum=0.9),\n                   metrics=['accuracy'])\n\nprint (full_model.summary())","ca4f428b":"full_model.fit(X, \n               Y,\n               epochs=15,\n               batch_size=batch_size,\n               validation_split=0.3)","666e6ddf":"PART 1 - Generate the output for the Convolutional Neural Network"}}