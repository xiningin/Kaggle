{"cell_type":{"300930d2":"code","85bb374a":"code","ee7f0d87":"code","12338376":"code","1d4dda14":"code","1927fe61":"code","4280bdcd":"code","10ae9bd0":"code","45d6eedd":"code","84e25ad7":"code","b65a2279":"code","4d34ff4a":"code","4bc90c51":"code","0ccaaf8d":"code","2b616a33":"code","ae0901da":"code","5db3b417":"code","99134c24":"code","6650809a":"code","34bd0aa0":"code","8a6e4c58":"code","37a9dec8":"code","fb4a8cb9":"code","061e7346":"code","c97bb998":"code","7735aba3":"code","878630c3":"code","72929eb6":"code","5d633630":"code","37d59470":"code","bfc6d1b2":"code","a17dd7da":"code","e4dff03e":"code","07ad9bb3":"code","23c961a0":"code","bfd6df28":"code","894ce528":"code","0433936c":"code","f42a2706":"markdown","d987d283":"markdown","f0733e04":"markdown","6ba4c4f3":"markdown","92819abb":"markdown","87f63857":"markdown","d40c7660":"markdown","587e9ca4":"markdown","dab816ac":"markdown","557ff6eb":"markdown","c1dd52c7":"markdown"},"source":{"300930d2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","85bb374a":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom catboost import CatBoostClassifier","ee7f0d87":"df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")","12338376":"df.head()","1d4dda14":"df.index = df['PassengerId']\ndf = df.drop(['PassengerId','Ticket','Name','Cabin'], axis = 1)\ndf.head()","1927fe61":"df.info()","4280bdcd":"def plotcountgraph(var):\n    \n    sns.set(font_scale=1.25)\n    plt.figure(figsize=(10, 5))\n    ax = sns.countplot(x=var, hue='Survived', data=df,  palette=\"viridis\")\n    plt.setp(ax.get_xticklabels(), rotation=0)","10ae9bd0":"var=['Sex','Pclass','Embarked','SibSp','Parch']\nfor i in var:\n    plotcountgraph(i)","45d6eedd":"df['Age'] = df['Age'].fillna(df['Age'].mean())\ndf['Embarked'] = df['Embarked'].fillna(method = \"ffill\")","84e25ad7":"df_clone.isna().sum()","b65a2279":"df_clone = df.copy()","4d34ff4a":"df = pd.get_dummies(df, drop_first = True)","4bc90c51":"#df_101 = df.drop(['Survived','Sex_male','Embarked_Q','Embarked_S'],axis = 1)","0ccaaf8d":"scaler = StandardScaler()\nscaler.fit(df.drop(['Survived','Sex_male','Embarked_Q','Embarked_S'],axis = 1))\ndf_scaled = scaler.transform(df.drop(['Survived','Sex_male','Embarked_Q','Embarked_S'],axis = 1))","2b616a33":"df_scaled = pd.DataFrame(df_scaled, columns = df_101.columns)\ndf_scaled.index = df.index\ndf_scaled.tail()","ae0901da":"df[['Pclass','Age','SibSp','Parch','Fare']] = df_scaled[['Pclass','Age','SibSp','Parch','Fare']]","5db3b417":"target = df['Survived']\nfeatures = df.drop('Survived', axis = 1)","99134c24":"features.shape","6650809a":"target.shape","34bd0aa0":"feat_train, feat_val, target_train, target_val = train_test_split(features, target, train_size = 0.75)","8a6e4c58":"def model_check(model_name):\n    predd = model_name.predict(feat_val)\n    accurac = accuracy_score(target_val, predd)\n    print(\"Accuracy =\", accurac)","37a9dec8":"def model_create(model_type):\n    model = model_type(random_state = 12345)\n    model.fit(feat_train, target_train)\n    return model","fb4a8cb9":"features.tail()","061e7346":"target.tail()","c97bb998":"ran_forest = model_create(RandomForestClassifier)\nmodel_check(ran_forest)","7735aba3":"cat_model = model_create(CatBoostClassifier)\nmodel_check(cat_model)","878630c3":"dec_tree = model_create(DecisionTreeClassifier)\nmodel_check(dec_tree)","72929eb6":"lgbm_1 = model_create(LGBMClassifier)\nmodel_check(lgbm_1)","5d633630":"def grid_search_function(model_name, params_input):\n    params = params_input\n    grid_search = GridSearchCV(model_name,params, cv = 10)\n    grid_search.fit(feat_train,target_train)\n    model_check(grid_search)","37d59470":"params_forest = {'n_estimators' : [50, 500, 15],\n         'criterion': [\"gini\", \"entropy\"],\n         'min_samples_split': [2,40,3]\n         }\ngrid_search_function(ran_forest, params_forest)","bfc6d1b2":"cat_model_GS = CatBoostClassifier(custom_metric='Accuracy')\ngrid = {'learning_rate': [0.0001, 0.01, 0.002],\n        'depth': [4, 6, 10],\n        'l2_leaf_reg': [1, 3, 5, 7, 9]}\n\ngrid_search_result = cat_model_GS.grid_search(grid, \n                                       X=feat_train, \n                                       y=target_train)","a17dd7da":"model_check(cat_model_GS)","e4dff03e":"df_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","07ad9bb3":"df_test.index = df_test['PassengerId']\ndf_test = df_test.drop(['PassengerId','Name','Ticket','Cabin'], axis = 1)\n\ndf_test = pd.get_dummies(df_test, drop_first = True)\ndf_102 = df_test.drop(['Sex_male','Embarked_Q','Embarked_S'],axis = 1)\n\nscaler = StandardScaler()\nscaler.fit(df_102)\ndf_01 = scaler.transform(df_102)\n\ndf_01 = pd.DataFrame(df_01, columns = df_102.columns)\ndf_01.index = df_test.index\n\ndf_test[['Pclass','Age','SibSp','Parch','Fare']] = df_01[['Pclass','Age','SibSp','Parch','Fare']]","23c961a0":"pred_lgbm = lgbm_1.predict(df_test)","bfd6df28":"pred_cat = cat_model_GS.predict(df_test)","894ce528":"output_lg = pd.DataFrame({'PassengerId': df_test.index , 'Survived': pd.Series(pred_lgbm)})\noutput_lg.to_csv('my_submission_2.csv', index=False)\nprint(\"Your submission was successfully saved!\")","0433936c":"output = pd.DataFrame({'PassengerId': df_test.index , 'Survived': pd.Series(pred_cat)})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","f42a2706":"# Output ","d987d283":"Scaler should help our model to reach better result. As Lenin said \"Let's go, Tovarishi!\"","f0733e04":"#  Preparation data to analysis","6ba4c4f3":"As for filling missing values, I think , that for Nan in Age we might fill mean value for goal not to disbalance distribution of ages in our boat. \n\nAs for Embarked 2 missed values, it doesn't matter how we fill 2 values, it caonnot change the way ML will work. But ffill method can recover in this case missing data because we maybe can face situation where people has bought tickets together, and in this theory person after you can be embarked in the same city with you. \n\nHope I explained my actions))","92819abb":"So, let's start prepare data for ML models. I will try to use Simple decision tree, Random Forest and models connected with Gradient Boosting (CatBoost, LightGBM). At first I'll try \"vanilla\"(default) parameters of these models, then compare them with models, created after cross-validation.","87f63857":"*Done!*","d40c7660":"Copy of our dataset I've made for 2 goals : incorrect preparations of data or in case when I try to use categorical data not to perform them into numbers.","587e9ca4":"# Start ","dab816ac":"Let's perform our categorical data with help of OHE. ","557ff6eb":"Fistly,  we can see more dead men than women \n\nSecondly, people in 3rd class has more deaths in absolute measure, than people in others \n\nThirdly, people embarked in \"S\"- town more more able to become deadmen.\n\nMoreover, survival rate people with 1-2 parch  is higher in comparison with other groups\n","c1dd52c7":"## First conclusions"}}