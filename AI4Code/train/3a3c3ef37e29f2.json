{"cell_type":{"94d4dfe3":"code","1c2f7af0":"code","c36cb309":"code","070494d4":"code","08344ba1":"code","a5f6fa49":"code","832c24bb":"code","6579789a":"code","26c7ab61":"code","0c059962":"code","2f305a61":"code","e972c808":"code","90f98dd7":"code","ca94d112":"code","90184c48":"code","7db41328":"code","0acdf65a":"code","c594251c":"code","748b92ba":"code","e6a166d8":"code","7b9079c4":"code","450f26df":"code","cc88cc1b":"code","cb6a9d8f":"code","b5193029":"code","d424b48b":"code","1c2fbbb7":"code","b499f273":"code","8c95df1b":"code","4d3e844a":"code","ec6a0d60":"code","ebbfbc25":"code","2a7aa38d":"code","3eabd6e0":"code","a3cd1ca3":"code","313ccd69":"code","3c309ecb":"code","9e206c8c":"code","75e07aa7":"code","73058f0b":"code","4f8950f4":"code","2e8e2cba":"code","cc755ae9":"code","3dfd6c9e":"code","279035e6":"code","6fa66a6d":"code","d45c7d36":"code","4fc4d130":"code","4b315718":"code","3f363cc1":"code","1468803f":"code","e73f1140":"code","269cecf3":"code","c01df007":"code","8a70a5b6":"code","409fbcc6":"code","612f4bad":"code","6358981a":"code","9394bf3b":"code","ad099f99":"code","af2cba46":"code","f46cf19d":"code","dca0f8be":"code","47e886a8":"code","e1cae7db":"code","65012f0a":"code","728fc287":"code","ee5a9481":"code","aeb20600":"code","e7e112a1":"code","07909aa1":"code","a96ae0dd":"code","29daa6dc":"code","804f78b4":"code","3973b9e8":"code","56f60be2":"code","75418162":"code","104a546e":"code","dd3c8cc7":"code","dd0e1478":"code","55e143e6":"code","168c1600":"code","dcb45e7f":"code","c90711d6":"code","28e161e1":"code","f6288ac7":"code","d8c35d18":"code","596dfc0b":"code","fd987fa8":"code","6f45fbaa":"code","8548df4b":"code","c30877ea":"code","5f6c7380":"code","208eedcf":"code","a90fbef0":"code","a195b7ea":"code","0e5fb65d":"code","8cd6801d":"code","7a0afca5":"code","032d0e92":"code","8f8c5504":"code","79ec136c":"code","2917e1b3":"code","1727a232":"code","5f9030d5":"code","cd2d0e82":"markdown","e4aca67b":"markdown","02eb5138":"markdown","6bf2e6a9":"markdown","c0b5f2f6":"markdown","62c18487":"markdown","d5be3616":"markdown","1bce1eec":"markdown","0a220e6b":"markdown","97f8373c":"markdown","ad1f3f01":"markdown","1d7656ea":"markdown","9d8ed792":"markdown","82df1584":"markdown","822db89c":"markdown","d36c005c":"markdown","4f8ece03":"markdown","53198944":"markdown","f3aa102c":"markdown","ebf9359c":"markdown","3e42f194":"markdown","8a96592a":"markdown","2ac3f99f":"markdown","b2206fd0":"markdown","f4ea78fe":"markdown","54dc8b00":"markdown","1c8c8abf":"markdown","09c68e51":"markdown","46a15ac6":"markdown","cbda6942":"markdown"},"source":{"94d4dfe3":"%%capture\nimport sys\n\nif 'google.colab' in sys.modules:\n    # Install packages in Colab\n    !pip install category_encoders==2.*\n    !pip install eli5\n    !pip install pandas-profiling==2.*\n    !pip install pdpbox\n    !pip install shap","1c2f7af0":"import warnings\nwarnings.filterwarnings(action='ignore')","c36cb309":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas_profiling\nfrom IPython.display import display\n%matplotlib inline\nplt.style.use('ggplot')","070494d4":"csv_names = ['Table data 2018.csv', 'Table data 2019.csv', 'Table data 2020.csv']\npath = '..\/input\/youtube-revenue-data-20182021\/'\n\ndf = pd.concat((pd.read_csv(path+csv_names[0])[1:-1], \n                pd.read_csv(path+csv_names[1])[1:-1],\n               pd.read_csv(path+csv_names[2])[1:-1])).reset_index(drop=True)\n\ndf.columns = df.columns.str.replace(' ', '_')\ncol_map ={'Av\u00ader\u00adage_views_per_view\u00ader':'Average_views_per_viewer',\n          'Unique_view\u00aders':'Unique_viewers',\n          'Av\u00ader\u00adage_per\u00adcent\u00adage_viewed_(%)':'Average_viewed',\n          'Im\u00adpres\u00adsions':'Impressions',\n          'Dis\\xadlikes':'Dislikes',\n          'Sub\u00adscribers_lost':'Subscribers_lost',\n          'Sub\u00adscribers_gained':'Subscribers_gained',\n          'Videos_pub\u00adlished':'Videos_added',\n          'Videos_ad\u00added':'Videos_published', \n          'Sub\u00adscribers':'Subscribers',\n          'Im\u00adpres\u00adsions_click-through_rate_(%)':'Click_rate',\n          'Com\u00adments_ad\u00added':'Comments',\n          'Watch_time_(hours)':'Watch_hours',\n          'Av\u00ader\u00adage_view_dur\u00ada\u00adtion':'Average_view_sec',\n          'Your_es\u00adtim\u00adated_rev\u00aden\u00adue_(USD)':'Revenue'}\ndf = df.rename(columns=col_map)\ndf = df.drop(['Likes_(vs._dis\u00adlikes)_(%)', \n              'Videos_added', \n              'Subscribers_lost',\n              'Subscribers_gained'], axis=1)\n\nprint(\"2018-2020 YouTuber 'PoohinKorea' Daily Data\")\nprint(\"=\"*45)\nprint('Data Size: ', df.shape)\nprint('Null Values: ', df.isna().sum().sum())\nprint('Data types: ', df.dtypes.reset_index().groupby(0).count().reset_index().values.tolist())\ndf.head(2)","08344ba1":"df.select_dtypes(include=('object')).head(2)","a5f6fa49":"df['Date'] = pd.to_datetime(df['Date'])\ndf['Average_view_sec'] = pd.to_timedelta(df['Average_view_sec']).dt.seconds","832c24bb":"df.isna().sum().reset_index().style.highlight_min()","6579789a":"df.Videos_published.value_counts(dropna=False)","26c7ab61":"df.Videos_published = df.Videos_published.fillna(0.0, axis=0)\ndf.isna().sum().sum()","0c059962":"df.columns","2f305a61":"df.head(2)","e972c808":"top_corr_name = df.corr()['Revenue'].sort_values(ascending=False).reset_index()['index'][:8].values\nsns.pairplot(df[top_corr_name], x_vars=top_corr_name[1:], y_vars=top_corr_name[0])\nplt.title('Top 7 Correlations with Target', fontsize=15)\nplt.show()","90f98dd7":"plt.figure(figsize=(20, 6))\nsns.lineplot(data=df, x='Date', y='Revenue')\nplt.axhline(df.Revenue.mean(), color='c', linestyle='--', linewidth=2)\nplt.annotate('Mean of Revenue: $ {}'.format(round(df.Revenue.mean(),4)), \n             (df.Date[350], 30), \n             fontsize=12, \n             color='c')\nplt.title('YouTube Revenue by Date', fontsize=20)\nplt.ylabel('Revenue (USD, $)')\nplt.show()","ca94d112":"df.corr()['Revenue'].sort_values(ascending=False).reset_index()[1:].style.bar(align='mid')","90184c48":"plt.figure(figsize=(10,6))\nsns.regplot(data=df, x='Watch_hours', y='Revenue')\nplt.title('Revenue by Watch_hours', fontsize=20)\nplt.show()","7db41328":"plt.figure(figsize=(7,5))\nsns.histplot(df['Revenue'], kde=True)\nplt.title('YouTube Revenue per day', fontsize=15)\nplt.xlabel('Revenue (USD, $)')\nplt.show()","0acdf65a":"df = df[(df['Revenue'] <= 150)].reset_index(drop=True)\nplt.figure(figsize=(7,5))\nsns.histplot(df['Revenue'], kde=True)\nplt.title('YouTube Revenue per day', fontsize=15)\nplt.xlabel('Revenue (USD, $)')\nplt.show()","c594251c":"plt.figure(figsize=(7,5))\nsns.histplot(np.log(df['Revenue']), kde=True)\nplt.title('YouTube Revenue per day', fontsize=15)\nplt.xlabel('Revenue (log transformation)')\nplt.show()","748b92ba":"plt.figure(figsize=(10,8))\nsns.heatmap(df.corr(), vmin=-1, vmax=1, linewidths=.2)\nplt.show()","e6a166d8":"df.describe().loc[['mean', 'std', 'min', '50%', 'max']]","7b9079c4":"df.to_csv('.\/2018-2019 Data.csv')","450f26df":"df.head(2)","cc88cc1b":"Subs = df.Subscribers.values.tolist()\nSubs_accumulated = []\ncount = 0\nfor s in Subs:\n    count += s\n    Subs_accumulated.append(count)","cb6a9d8f":"df['Subs_accumulated'] = Subs_accumulated\ndf.head(2)","b5193029":"plt.figure(figsize=(10,6))\nsns.regplot(data=df, x='Subs_accumulated', y='Revenue')\nplt.title('Revenue by Total Subscribers', fontsize=20)\nplt.show()","d424b48b":"Video_pub = df.Videos_published.values.tolist()\nVideos = []\ncount = 0\nfor v in Video_pub:\n    count += v\n    Videos.append(count)","1c2fbbb7":"df['Videos'] = Videos\ndf.head(2)","b499f273":"df.Videos_published.value_counts()","8c95df1b":"df['Videos_published'] = df.Videos_published.mask((df.Videos_published>0), 1).astype('int')","4d3e844a":"f, ax = plt.subplots(1, 1, figsize=(24, 6))\n\nax = sns.lineplot(data=df, x='Date', y='Revenue', label='Revenue', lw=1.5)\nax = sns.lineplot(data=df, x='Date', y='Videos', label='Videos', color='g', lw=2, linestyle='-')\nplt.axvline(df.Date[0], color='y', label='Video Published', lw=0.5)\n\nfor i in range(1, len(df)):\n    if df.Videos_published[i] == 1:\n        plt.axvline(df.Date[i], color='y', lw=0.5)\n\nplt.axhline(df.Revenue.mean(), color='c', linestyle='--', linewidth=2, label='Mean of Revenue')\nplt.annotate('Mean of Revenue: $ {}'.format(round(df.Revenue.mean(),4)), \n             (df.Date[5], 30), \n             fontsize=12, \n             color='c')\n\nplt.title('YouTube Revenue by Date', fontsize=20)\nplt.ylabel('Revenue (USD, $)')\nplt.xticks(fontsize=15)\nax.legend(fontsize='xx-large')\nplt.show()","ec6a0d60":"df = df[(df['Date'] > '20200901')].reset_index(drop=True)\ndf","ebbfbc25":"from sklearn.linear_model import LinearRegression\n\ndef calculate_vif(df, features):    \n    vif, tolerance = {}, {}\n    # all the features that you want to examine\n    for feature in features:\n        # extract all the other features you will regress against\n        X = [f for f in features if f != feature]        \n        X, y = df[X], df[feature]\n        # extract r-squared from the fit\n        r2 = LinearRegression().fit(X, y).score(X, y)                \n        \n        # calculate tolerance\n        tolerance[feature] = 1 - r2\n        # calculate VIF\n        vif[feature] = 1\/(tolerance[feature])\n    # return VIF DataFrame\n    return pd.DataFrame({'VIF': vif, 'Tolerance': tolerance})","2a7aa38d":"cell_hover = {  # for row hover use <tr> instead of <td>\n    'selector': 'td:hover',\n    'props': [('background-color', 'green')]\n}","3eabd6e0":"df.corr()['Revenue'].sort_values(ascending=False).reset_index().style.set_table_styles([cell_hover])","a3cd1ca3":"df.corr()['Revenue'].sort_values(ascending=False).reset_index()['index'][1:14].values","313ccd69":"features_chosen=[\n                #  'Watch_hours', \n                #  'Unique_viewers', \n                #  'Views', \n                #  'Likes', \n                #  'Dislikes',\n                #  'Impressions', \n                 'Subs_accumulated',\n                #  'Subscribers', \n                 'Comments', \n                 'Shares',\n                #  'Videos',\n                 'Average_view_sec', \n                #  'Average_views_per_viewer', \n                 'Average_viewed'\n                 ]\ncalculate_vif(df.iloc[:,1:], features=features_chosen).style.apply(lambda x: ['background:green' if v < 0.2 else '' for v in x], axis=1)","3c309ecb":"# cols_remove = [\n#                'Average_views_per_viewer', \n#                 'Watch_hours', \n#                 'Unique_viewers', \n#                 'Views', \n#                 'Likes', \n#                 'Dislikes',\n#                 'Impressions',\n#                 'Subs_accumulated', \n#                 'Date']\n\ncols_remove = [\n                    'Date',\n                # 'Watch_hours', \n                #  'Unique_viewers', \n                #  'Views', \n                 'Dislikes',\n                #  'Impressions', \n                 'Subscribers', \n                 'Comments', \n                 'Shares',\n                 'Videos',\n                 'Average_view_sec', \n                 'Average_views_per_viewer', \n                 'Average_viewed',\n                 'Videos_published',\n                 'Click_rate', \n            #    'Subs_accumulated',\n                 ]\n\n\ndf_new = df.copy()\ndf_new = df_new.drop(cols_remove, axis=1)\nprint('New Data Shape: ', df_new.shape)\ndf_new.head(2)","9e206c8c":"df_new.corr()['Revenue']","75e07aa7":"sns.pairplot(df_new, x_vars=df_new.columns.drop('Revenue'), y_vars=['Revenue'])\nplt.title('Correlations with Target', fontsize=15)\nplt.show()","73058f0b":"from sklearn.model_selection import train_test_split","4f8950f4":"# train, test = train_test_split(df_new, test_size=0.2, random_state=33)\n\n# train.shape, test.shape","2e8e2cba":"train = df_new[:int(len(df_new)*0.8)]\ntest = df_new[int(len(df_new)*0.8):]\ntrain.shape, test.shape","cc755ae9":"target = 'Revenue'\n\nX_train = train.drop(target, axis=1)\ny_train = train[target]\nX_test = test.drop(target, axis=1)\ny_test = test[target]\n\nX_train.shape, y_train.shape","3dfd6c9e":"from sklearn.feature_selection import f_regression\n\npvalue_table = pd.DataFrame(f_regression(X_train, y_train), columns=X_train.columns).T.rename(columns={0:'F_statistic', 1:'p_values'})\npvalue_table.style.apply(lambda x: [\"background: green\" if v < 0.05 else \"\" for v in x], axis = 1)","279035e6":"from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score","6fa66a6d":"def evaluate(title, y, y_):\n    mae = mean_absolute_error(y, y_)\n    rmse = mean_squared_error(y, y_)**0.5\n    r2 = r2_score(y, y_)\n    print('*{} Result*'.format(title))\n    print('='*50)\n    print('MAE Score: $', mae)\n    print('RMSE Score: $', rmse)\n    print('R2 Score: ', r2)\n    print()","d45c7d36":"from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline","4fc4d130":"pipe_lin = make_pipeline(\n    StandardScaler(),\n    LinearRegression(n_jobs=-1)\n)\n\npipe_lin.fit(X_train, y_train)\ny_pred = np.exp(pipe_lin.predict(X_test))\nevaluate('Linear Regression', y_test, y_pred)","4b315718":"from sklearn.compose import TransformedTargetRegressor","3f363cc1":"tt_lin = TransformedTargetRegressor(regressor=pipe_lin,\n                                func=np.log1p, inverse_func=np.expm1)\n\ntt_lin.fit(X_train, y_train)\ny_pred = tt_lin.predict(X_test)\nevaluate('Log Transformed Linear Regression', y_test, y_pred)","1468803f":"pipe_ridge = make_pipeline(\n    StandardScaler(),\n    RidgeCV(alphas=np.arange(100, 105, 0.01), cv=5)\n)\n\ntt_ridge = TransformedTargetRegressor(regressor=pipe_ridge,\n                                func=np.log1p, inverse_func=np.expm1)\n\ntt_ridge.fit(X_train, y_train)\ny_pred = tt_ridge.predict(X_test)\nprint('Best alpha: ', tt_ridge.regressor_.named_steps['ridgecv'].alpha_)\nevaluate('Log Transformed Ridge', y_test, y_pred)","e73f1140":"pipe_lasso = make_pipeline(\n    StandardScaler(),\n    LassoCV(alphas=np.arange(0, 0.2, 0.001), cv=5, random_state=33)\n)\n\ntt_lasso = TransformedTargetRegressor(regressor=pipe_lasso,\n                                func=np.log1p, inverse_func=np.expm1)\n\ntt_lasso.fit(X_train, y_train)\ny_pred = tt_lasso.predict(X_test)\nprint('Best alpha: ', tt_lasso.regressor_.named_steps['lassocv'].alpha_)\nevaluate('Log Transformed Lasso', y_test, y_pred)","269cecf3":"from sklearn.linear_model import ElasticNetCV","c01df007":"pipe_elnet = make_pipeline(\n    StandardScaler(),\n    ElasticNetCV(n_jobs=-1, cv=5, random_state=33)\n)\n\ntt_elnet = TransformedTargetRegressor(regressor=pipe_elnet,\n                                func=np.log1p, inverse_func=np.expm1)\n\ntt_elnet.fit(X_train, y_train)\ny_pred = tt_elnet.predict(X_test)\nevaluate('Log Transformed ElasticNet', y_test, y_pred)","8a70a5b6":"from sklearn.ensemble import RandomForestRegressor","409fbcc6":"pipe_rfreg = make_pipeline(\n    StandardScaler(),\n    RandomForestRegressor(n_estimators=300, n_jobs=-1, random_state=33)\n)\n\ntt_rfreg = TransformedTargetRegressor(regressor=pipe_rfreg,\n                                func=np.log1p, inverse_func=np.expm1)\n\ntt_rfreg.fit(X_train, y_train)\ny_pred = tt_rfreg.predict(X_test)\nevaluate('Log Transformed RandomForest Regressor', y_test, y_pred)","612f4bad":"from xgboost import XGBRegressor","6358981a":"pipe_xgb = make_pipeline(\n    StandardScaler(),\n    XGBRegressor(learning_rate=0.1,\n                  n_estimators=500,\n                  n_jobs=-1,\n                  random_state=33)\n)\n\ntt_xgb = TransformedTargetRegressor(regressor=pipe_xgb,\n                                func=np.log1p, inverse_func=np.expm1)\n\ntt_xgb.fit(X_train, y_train)\ny_pred = tt_xgb.predict(X_test)\nevaluate('Log Transformed XGB Regressor', y_test, y_pred)","9394bf3b":"from lightgbm import LGBMRegressor","ad099f99":"pipe_lgb = make_pipeline(\n    StandardScaler(),\n    LGBMRegressor(learning_rate=0.1,\n                  n_estimators=500,\n                  n_jobs=-1,\n                  random_state=33)\n)\n\ntt_lgb = TransformedTargetRegressor(regressor=pipe_lgb,\n                                func=np.log1p, inverse_func=np.expm1)\n\ntt_lgb.fit(X_train, y_train)\ny_pred = tt_lgb.predict(X_test)\nevaluate('Log Transformed Light GBM Regressor', y_test, y_pred)","af2cba46":"y_pred = tt_rfreg.predict(X_test)*0.1 + tt_xgb.predict(X_test)*0.8 + + tt_lgb.predict(X_test)*0.1\nevaluate('[RF + XGB+ LGBM]', y_test, y_pred)","f46cf19d":"def get_top_bottom_coef(model):\n    coef = pd.Series(model.coef_, index=X_train.columns).sort_values(ascending=False)\n    return coef\n\ndef visualize_coefficient(models):\n    fig, axs = plt.subplots(figsize=(20, 6), nrows=1, ncols=4)\n    fig.tight_layout()\n    \n    for i_num, model in enumerate(models):\n        coef = get_top_bottom_coef(model)\n        axs[i_num].set_title(model.__class__.__name__+ ' Coefficients', size=20)\n        axs[i_num].tick_params(axis='y', direction='in', pad=0)\n        for label in (axs[i_num].get_xticklabels() + axs[i_num].get_yticklabels()):\n            label.set_fontsize(13)\n        sns.barplot(x=coef.values,\n                   y=coef.index, ax=axs[i_num])\n        plt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=1, \n                    top=1, \n                    wspace=0.8, \n                    hspace=0.4)","dca0f8be":"lin = tt_lin.regressor_.named_steps['linearregression']\nridge = tt_ridge.regressor_.named_steps['ridgecv']\nlasso = tt_lasso.regressor_.named_steps['lassocv']\nelnet = tt_elnet.regressor_.named_steps['elasticnetcv']\nmodels = [lin, ridge, lasso, elnet]\n\nvisualize_coefficient(models)","47e886a8":"def get_top_features(model):\n    ftr_importances_values = model.feature_importances_\n    ftr_importances = pd.Series(ftr_importances_values, index=X_train.columns  )\n    ftr_top = ftr_importances.sort_values(ascending=False)\n    return ftr_top\n\ndef visualize_ftr_importances(models):\n    fig, axs = plt.subplots(figsize=(17,6), nrows=1, ncols=3)\n    fig.tight_layout() \n    for i_num, model in enumerate(models):\n        ftr_top = get_top_features(model)\n        axs[i_num].set_title(model.__class__.__name__+' Feature Importances', size=20)\n        for label in (axs[i_num].get_xticklabels() + axs[i_num].get_yticklabels()):\n            label.set_fontsize(12)\n        sns.barplot(x=ftr_top.values, y=ftr_top.index , ax=axs[i_num])\n        plt.subplots_adjust(left=0.1,\n                    bottom=0.1, \n                    right=1, \n                    top=1, \n                    wspace=0.8, \n                    hspace=0.4)\n\nrf = tt_rfreg.regressor_.named_steps['randomforestregressor']\nxgb = tt_xgb.regressor_.named_steps['xgbregressor']\nlgbm = tt_lgb.regressor_.named_steps['lgbmregressor']\n\nmodels = [rf, xgb, lgbm]\nvisualize_ftr_importances(models)","e1cae7db":"from sklearn.model_selection import GridSearchCV, RandomizedSearchCV","65012f0a":"# scaler = StandardScaler()\n# X_train_scaled = scaler.fit_transform(X_train)\n# X_test_scaled = scaler.transform(X_test)","728fc287":"rf_reg = RandomForestRegressor(n_estimators=100,\n                               n_jobs=-1,\n                               random_state=33)\n\nxgb_reg = XGBRegressor(n_estimators=100,\n                       n_jobs=-1,\n                       random_state=33,\n                       seed=33)\n\nlgb_reg = LGBMRegressor(n_estimators=100,\n                        n_jobs=-1,\n                        random_state=33)","ee5a9481":"def randcv(estimator, params):\n    randcv = RandomizedSearchCV(estimator=estimator,\n                                param_distributions=params,\n                                n_iter=5,\n                                scoring='neg_root_mean_squared_error',\n                                cv=3,\n                                random_state=33,\n                                n_jobs=-1)\n\n    tt = TransformedTargetRegressor(regressor=randcv,\n                                func=np.log1p, inverse_func=np.expm1)\n\n    tt.fit(X_train, y_train)\n    y_pred = tt.predict(X_test)\n\n    print('Best Params: ', tt.regressor_.best_params_)\n    evaluate(estimator.__class__.__name__, y_test, y_pred)\n\n    return tt.regressor_.best_estimator_","aeb20600":"def gridcv(estimator, params):\n    gridcv = GridSearchCV(estimator=estimator,\n                          param_grid=params,\n                          scoring='neg_root_mean_squared_error',\n                          cv=3,\n                          n_jobs=-1)\n\n    tt = TransformedTargetRegressor(regressor=gridcv,\n                                func=np.log1p, inverse_func=np.expm1)\n\n    tt.fit(X_train, y_train)\n    y_pred = tt.predict(X_test)\n\n    print('Best Params: ', tt.regressor_.best_params_)\n    evaluate(estimator.__class__.__name__, y_test, y_pred)\n    \n    return tt.regressor_.best_estimator_","e7e112a1":"params_rf = {'max_depth': [18], \n             'min_samples_split': [6], \n             'min_samples_leaf': [1]\n             }\n# randcv_rf = randcv(rf_reg, params_rf)\ngridcv_rf = gridcv(rf_reg, params_rf)","07909aa1":"pipe_rfreg = make_pipeline(\n    # StandardScaler(),\n    RandomForestRegressor(n_estimators=16,\n                          min_samples_split=6,\n                          min_samples_leaf=5,\n                          max_depth=21, \n                          n_jobs=-1,\n                          oob_score=True, \n                          random_state=33)\n)\n\ntt_rfreg = TransformedTargetRegressor(regressor=pipe_rfreg,\n                                func=np.log1p, inverse_func=np.expm1)\n\ntt_rfreg.fit(X_train, y_train)\ny_pred = tt_rfreg.predict(X_test)\nprint('OOB Score: ', tt_rfreg.regressor_.named_steps['randomforestregressor'].oob_score_)\nprint('='*50)\nevaluate('Log Transformed RandomForest Regressor for Training Set', y_train, tt_rfreg.predict(X_train))\nevaluate('Log Transformed RandomForest Regressor for Test Set', y_test, y_pred)","a96ae0dd":"params_xgb = {\n              'max_depth':[3], \n              'learning_rate':[0.001, 0.01, 0.1, 0.15], \n            }\n\n# randcv(xgb_reg, params_xgb)\ngridcv(xgb_reg, params_xgb)","29daa6dc":"xgb_reg = XGBRegressor(n_estimators=1000,\n                       learning_rate=0.1,\n                       max_depth=3,\n                       n_jobs=-1,\n                       random_state=33,\n                       seed=33)\n\ntt_xgb = TransformedTargetRegressor(regressor=xgb_reg,\n                                func=np.log1p, inverse_func=np.expm1)\n\ntt_xgb.fit(X_train, y_train,\n        verbose=False,\n        early_stopping_rounds=100,\n        eval_set=[(X_test, y_test)],\n        eval_metric='rmse')\ny_pred = tt_xgb.predict(X_test)\nevaluate('Log Transformed XGB Regressor for Training Set', y_train, tt_xgb.predict(X_train))\nevaluate('Log Transformed XGB Regressor for Test Set', y_test, y_pred)","804f78b4":"y_true = y_test.reset_index().copy()\ny_true['y_pred'] = y_pred\ny_true","3973b9e8":"params_lgb = {\n              'num_leaves':[29], \n              'max_depth':[-1], \n              'learning_rate':[0.1], \n              }\n\n# randcv(lgb_reg, params_lgb)\ngridcv(lgb_reg, params_lgb)","56f60be2":"lgb_reg = LGBMRegressor(n_estimators=1000,\n                        num_leaves=11,\n                        max_depth=-1,\n                        learning_rate=0.271,\n                        reg_alpha=0.0003,\n                        reg_lambda=1.2,\n                        n_jobs=-1,\n                        objective='regression',\n                        random_state=33)\n\ntt_lgb = TransformedTargetRegressor(regressor=lgb_reg,\n                                func=np.log1p, inverse_func=np.expm1)\n\ntt_lgb.fit(X_train, y_train,\n        verbose=False,\n        early_stopping_rounds=100,\n        eval_set=[(X_test, y_test)],\n        eval_metric='rmse')\ny_pred = tt_lgb.predict(X_test)\nevaluate('Log Transformed Light GBM Regressor for Training Set', y_train, tt_lgb.predict(X_train))\nevaluate('Log Transformed Light GBM Regressor for Test Set', y_test, y_pred)","75418162":"y_pred = tt_rfreg.predict(X_test)*0.1 + tt_xgb.predict(X_test)*0.8 + tt_lgb.predict(X_test)*0.1\nevaluate('[RF + XGB + LGBM]', y_test, y_pred)","104a546e":"import eli5\nfrom eli5.sklearn import PermutationImportance","dd3c8cc7":"from IPython.display import display\n\n# Permutation Importance\ndef show_permutation_importance(model):\n    prm_imps = PermutationImportance(model,\n                                    scoring='neg_root_mean_squared_error',\n                                    n_iter=5,\n                                    random_state=33)\n\n    prm_imps.fit(X_train, y_train)\n    print('{} Permutation Importance'.format(model.__class__.__name__))\n    display(eli5.show_weights(\n        prm_imps,\n        top=None,\n        feature_names=X_train.columns.to_list()\n    ))","dd0e1478":"show_permutation_importance(tt_rfreg)\nshow_permutation_importance(tt_xgb)\nshow_permutation_importance(tt_lgb)","55e143e6":"rf = tt_rfreg.regressor_.named_steps['randomforestregressor']\nxgb = tt_xgb.regressor_\nlgbm = tt_lgb.regressor_\n\nmodels = [rf, xgb, lgbm]\nvisualize_ftr_importances(models)","168c1600":"from pdpbox.pdp import pdp_isolate, pdp_plot\nfrom pdpbox.pdp import pdp_interact, pdp_interact_plot\nfrom pdpbox import pdp\nimport shap","dcb45e7f":"def draw_pdp_plot(feature, model, X_val, num_grid_points = 10):\n    isolated = pdp_isolate(\n        model=model,\n        dataset=X_val,\n        model_features=X_val.columns,\n        feature=feature,\n        grid_type='percentile',\n        num_grid_points=num_grid_points\n    )\n    if model.regressor.__class__.__name__ == 'Pipeline':\n        print('<<<{} MODEL>>>'.format(model.regressor.named_steps['randomforestregressor'].__class__.__name__))\n    else:\n        print('<<<{} MODEL>>>'.format(model.regressor.__class__.__name__))\n    print('='*100)\n    pdp.pdp_plot(isolated, feature)","c90711d6":"features = X_train.columns.tolist()[2:-1]\nfeatures","28e161e1":"X = pd.concat((X_train, X_test))","f6288ac7":"draw_pdp_plot(features[0], tt_xgb, X)","d8c35d18":"draw_pdp_plot(features[0], tt_rfreg, X)","596dfc0b":"draw_pdp_plot(features[0], tt_lgb, X)","fd987fa8":"draw_pdp_plot(features[1], tt_xgb, X)","6f45fbaa":"draw_pdp_plot(features[1], tt_rfreg, X)","8548df4b":"draw_pdp_plot(features[1], tt_lgb, X)","c30877ea":"draw_pdp_plot(features[2], tt_xgb, X)","5f6c7380":"draw_pdp_plot(features[2], tt_rfreg, X)","208eedcf":"draw_pdp_plot(features[2], tt_lgb, X)","a90fbef0":"def draw_pdp_interaction(model, features, X_test, plot_type):\n    interaction = pdp_interact(\n        model=model, \n        dataset=X_test,\n        model_features=X_test.columns, \n        features=features\n    )\n    if model.regressor.__class__.__name__ == 'Pipeline':\n        print('<<<{} MODEL>>>'.format(model.regressor.named_steps['randomforestregressor'].__class__.__name__))\n    else:\n        print('<<<{} MODEL>>>'.format(model.regressor.__class__.__name__))\n    print('='*100)\n    pdp_interact_plot(interaction, plot_type=plot_type, feature_names=features)\n    plt.show()\n\nfeatures = ['Likes', 'Watch_hours']\ndraw_pdp_interaction(tt_xgb, features, X, 'contour')\ndraw_pdp_interaction(tt_rfreg, features, X, 'contour')\ndraw_pdp_interaction(tt_lgb, features, X, 'contour')","a195b7ea":"features = ['Views', 'Watch_hours']\ndraw_pdp_interaction(tt_xgb, features, X, 'contour')\ndraw_pdp_interaction(tt_rfreg, features, X, 'contour')\ndraw_pdp_interaction(tt_lgb, features, X, 'contour')","0e5fb65d":"features = ['Likes', 'Watch_hours']\ndraw_pdp_interaction(tt_xgb, features, X, 'contour')\ndraw_pdp_interaction(tt_rfreg, features, X, 'contour')\ndraw_pdp_interaction(tt_lgb, features, X, 'contour')","8cd6801d":"explainer = shap.TreeExplainer(xgb)\nshap_values = explainer.shap_values(X)","7a0afca5":"shap.initjs()\nshap.force_plot(explainer.expected_value, shap_values, X)","032d0e92":"shap.summary_plot(shap_values, X, plot_size=(15,8))","8f8c5504":"shap.summary_plot(shap_values, X, plot_type='bar')","79ec136c":"def draw_shap_value(sample):\n    explainer = shap.TreeExplainer(xgb)\n    shap.initjs()\n    samp_df = pd.DataFrame(dict(zip(X_test.columns, np.array(sample).reshape(-1,1))))\n    display(shap.force_plot(explainer.expected_value, explainer.shap_values(samp_df[:1]), samp_df[:]))\n    y_pred = np.exp(xgb.predict(samp_df))[0]\n    base_value = np.exp(explainer.expected_value)\n    samp_df.loc[1] = explainer.shap_values(samp_df[:1])[0].tolist()\n    samp_df.index = ['YouTuber\\'s Info', 'SHAP values']\n    display(samp_df.style.apply(lambda x: ['background: red' if v>0 else 'background: blue' for v in x], axis=0))\n    print('Average YouTube Daily Revenue: $ {}'.format(base_value))\n    print('Predicted YouTube Daily Revenue: $ {}'.format(y_pred))","2917e1b3":"import random\n\nsample = [round(random.uniform(10000,500000)),\n          round(random.uniform(100000,10226681)),\n          round(random.uniform(1000,40326)),\n          round(random.uniform(10000,503655)),\n          round(random.uniform(3000,40000), 4),\n          round(random.uniform(2000,500000))]\ndraw_shap_value(sample)","1727a232":"def pred_revenue(unique_viewers, impressions, likes, views, watch_hours, subs_accumulated):\n    YouTuber_info = [unique_viewers, impressions, likes, views, watch_hours, subs_accumulated]\n    draw_shap_value(YouTuber_info)","5f9030d5":"pred_revenue(57626.0, 2586855.0, 4954.0, 141204.0, 10312.5295, 253140.0)\nprint('Actual Revenue: $ {}'.format(y_test.iloc[0]))","cd2d0e82":"### F-statistic & P-Values","e4aca67b":"# Hyperparameters\n_____","02eb5138":"### RandomForest Regressor","6bf2e6a9":"### LinearRegression, Ridge, Lasso, ElasticNet","c0b5f2f6":"### XGBoost Hyperparameters","62c18487":"# Introduction\n_____________\n\n### Interest & Inspirations\n- Is it possible to predict a daily revenue of a certain youtuber with his\/her channel's daily view, subscribers gained, average viewed duration, etc...?\n- Which factor is most related with increasing daily Revenue?\n- How much can `Total Views of videos` devote to actual Monetizing?\n- If one has more videos posted on his\/her channel, would she\/he happen to earn more? \n","d5be3616":"### RandomForest Hyperparameters","1bce1eec":"# Model Selection\n_____","0a220e6b":"### Permutation Importance & Feature Importance","97f8373c":"### Partial Dependence Plot(PDP)","ad1f3f01":"### XGB Regressor","1d7656ea":"### Check Variance Inflation Factor for Colinearity","9d8ed792":"### SHAP Values","82df1584":"# BaseLine Model\n_____","822db89c":"### Tuned Models Combined","d36c005c":"# EDA\n_______","4f8ece03":"### LightGBM Hyperparameters","53198944":"### Linear Regression","f3aa102c":"### Light Gradient Boost Machine Regressor","ebf9359c":"# Feature Engineering\n_________\n","3e42f194":"### ElasticNet","8a96592a":"### Ridge","2ac3f99f":"### Tree-based Regressor","b2206fd0":"### Log Transformed Linear Regression","f4ea78fe":"# Visualization\n____","54dc8b00":"# Import Data\n________","1c8c8abf":"### Model Combined","09c68e51":"# Split Data\n_________","46a15ac6":"### Lasso","cbda6942":"# Result\n________"}}