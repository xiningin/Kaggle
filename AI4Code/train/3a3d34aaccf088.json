{"cell_type":{"e1369fe2":"code","07d84b2d":"code","674bb748":"code","1ab31665":"code","4b6750cb":"code","4cbee999":"code","e2a5b59e":"code","09305295":"code","b22f0076":"code","4d8d0336":"code","7c8491ac":"code","72b7365c":"code","dc30e89e":"markdown","247037a6":"markdown","98dc61cd":"markdown","7a820a0a":"markdown","e8450d41":"markdown","335da1b4":"markdown","88fbbd2c":"markdown","43db1bc3":"markdown","727e88e7":"markdown","b6fc6615":"markdown","c230f6ca":"markdown","87699d88":"markdown"},"source":{"e1369fe2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","07d84b2d":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\nfrom numpy import array\nfrom keras.preprocessing.text import one_hot\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers.embeddings import Embedding\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\n","674bb748":"df = pd.read_csv('..\/input\/textdb3\/fake_or_real_news.csv') # Load data into DataFrame\n","1ab31665":"# Pre-Processing\ndf['text'] = df['text'].apply(lambda x: x.lower())","4b6750cb":"\n#max_features = 2000 # Vocabulary Size\n\n#tokenizer = Tokenizer(num_words=max_features, split=' ')\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(df['text'].values)\nvocab_size = len(tokenizer.word_index) + 1\nprint(\"Vocabulary Size :- \",vocab_size)\nX = tokenizer.texts_to_sequences(df['text'].values)\n","4cbee999":"max_length = 1000\n# Padding\nX = pad_sequences(X,maxlen = max_length, padding = 'post')","e2a5b59e":"#y = df.label\ny = pd.get_dummies(df['label']).values","09305295":"\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,random_state=53)\n\nprint(X_train.shape,y_train.shape)\nprint(X_test.shape,y_test.shape)","b22f0076":"from numpy import array\nfrom numpy import asarray\nfrom numpy import zeros\n\n# load the whole embedding into memory\nembeddings_index = dict()\nf = open('\/kaggle\/input\/glove-global-vectors-for-word-representation\/glove.6B.200d.txt')\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\nprint('Loaded %s word vectors.' % len(embeddings_index))\n\n# Creating Embedding Matrix\n\n# create a weight matrix for words in training docs\nembedding_matrix = zeros((vocab_size, 200))\nfor word, i in tokenizer.word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector\n\n","4d8d0336":"# define the model\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, 200, weights=[embedding_matrix], input_length=max_length, trainable=False))\nmodel.add(Flatten())\nmodel.add(Dense(2, activation='sigmoid'))\n# compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n# summarize the model\nprint(model.summary())\n","7c8491ac":"# fit the model\nmodel.fit(X_train, y_train, epochs=50, verbose=0)\n\n","72b7365c":"# evaluate the model\nloss, accuracy = model.evaluate(X_test, y_test, verbose=0)\nprint('Accuracy: %f' % (accuracy*100))\n","dc30e89e":"# Processing Target","247037a6":"# Padding","98dc61cd":"# Training","7a820a0a":"# Tokenization","e8450d41":"# Imports","335da1b4":"# Design Deep Neural Network with Embedding Layer","88fbbd2c":"# Load GloVe based Word Embedding Initialization","43db1bc3":"# Train-Test Split","727e88e7":"# Fake News Classifier with Deep Learning with Glove based Embedding Layer","b6fc6615":"# Evaluation","c230f6ca":"# Pre-processing","87699d88":"# Load Data"}}