{"cell_type":{"20239b70":"code","e229f83a":"code","5aeafc06":"code","bb29e72f":"code","1df2d6a8":"code","2a817b95":"code","88e8f27d":"code","19ca4a84":"code","6542b24d":"code","daa95ff8":"code","29e06c69":"code","5c8e748e":"code","555620f8":"code","98734868":"code","e8d23500":"code","16ce8927":"code","78574dc0":"code","7f719b9f":"code","6a2a0693":"markdown","f0a9be27":"markdown","0c8078df":"markdown","d8a5bc45":"markdown","ef371ee9":"markdown"},"source":{"20239b70":"import gc\nimport os\nimport random\n\nfrom optuna.integration import lightgbm as lgb\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom sklearn.decomposition import TruncatedSVD\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib_venn import venn2\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\nsns.set(style='darkgrid')\n\nimport optuna\n\nSEEDS=42\n\npd.set_option('display.max_columns', 50)\npd.set_option('display.max_rows', 500)","e229f83a":"svd_img = TruncatedSVD(n_components=50, random_state=SEEDS)\nsvd_txt = TruncatedSVD(n_components=50, random_state=SEEDS)","5aeafc06":"# \u753b\u50cf\u7279\u5fb4\u91cf\ntrain = pd.DataFrame(svd_img.fit_transform(np.load('..\/input\/pretrained-model-train\/train_ef0.npy'))).add_prefix('imgs')\ntest = pd.DataFrame(svd_img.fit_transform(np.load('..\/input\/pretrained-model-test\/test_eff0.npy'))).add_prefix('imgs')\n\n# text\u7279\u5fb4\u91cf\ntrain = pd.concat([train, pd.DataFrame(svd_txt.fit_transform(np.load('..\/input\/bert-pretrained-model-train\/bert_train.npy'))).add_prefix('txt')], axis=1)\ntest = pd.concat([test, pd.DataFrame(svd_txt.fit_transform(np.load('..\/input\/bert-pretrained-model-test\/bert_test.npy'))).add_prefix('txt')], axis=1)","bb29e72f":"inputPath = '\/kaggle\/input\/used-car-price-forecasting\/'\ntrain[['id','price']] = pd.read_csv(inputPath + 'train.csv')[['id', 'price']]\ntrain['price'] = np.log1p(train['price'])\ntest['id'] = pd.read_csv(inputPath + 'test.csv')['id']","1df2d6a8":"train.head()","2a817b95":"def rmse(y_true, y_pred):\n    return (mean_squared_error(y_true, y_pred))** .5","88e8f27d":"models = {'lgb_ao2' : '..\/input\/lgb-new-baseline-geo-clstr-ao02-v2\/',\n          'rf_ao2'  : '..\/input\/rf-new-baseline-geo-clstr-ao02\/',\n          'xgb_ao2' : '..\/input\/xgb-new-baseline-geo-clstr-ao02\/',\n          'cat_ao2' : '..\/input\/cat-new-baseline-geo-clstr-ao02\/',\n          'lgb_ao9' : '..\/input\/lgb-new-baseline-geo-clstr-ao02-v9\/',\n          'rf_ao9'  : '..\/input\/rf-new-baseline-geo-clstr-ao02-v9\/',\n          'xgb_ao9' : '..\/input\/xgb-new-baseline-geo-clstr-ao02-v9\/',\n          'cat_ao9' : '..\/input\/cat-new-baseline-geo-clstr-ao02-v9\/',\n          'lgb_fu' : '..\/input\/lgb-new-baseline-geo-clstr-ao02-nan-count\/',\n          'rf_fu'  : '..\/input\/rf-new-baseline-geo-clstr-ao02-v9-nancnt\/',\n          'xgb_fu' : '..\/input\/xgb-new-baseline-geo-clstr-ao02-v9-nancnt\/',\n          'cat_fu' : '..\/input\/cat-new-baseline-geo-clstr-ao02-v9-nancnt\/',\n}","19ca4a84":"for name, path in models.items():\n    tmp = pd.read_csv(path + 'oof_pred.csv')\n    tmp.columns = ['id', name]\n    tmp[name] = np.log1p(tmp[name])\n    train = train.merge(tmp, on='id', how='inner')","6542b24d":"for name, path in models.items():\n    tmp = pd.read_csv(path + 'submission.csv')\n    tmp.columns = ['id', name]\n    tmp[name] = np.log1p(tmp[name])\n    test = test.merge(tmp, on='id', how='inner')","daa95ff8":"target = 'price'\nnot_use_cols = [target, 'id']\nfeatures = [c for c in train.columns if c not in not_use_cols]","29e06c69":"# cv\u8a2d\u5b9a\nFOLD_N = 5\nkf = KFold(n_splits=FOLD_N, shuffle = True, random_state = SEEDS)","5c8e748e":"params = {'objective': 'regression',\n          'boosting': 'gbdt',\n          'metric': 'rmse'}\n\nfor n, (tr_idx, vl_idx) in enumerate(kf.split(train[features])):\n    tr_x, tr_y = train[features].iloc[tr_idx], train[target].iloc[tr_idx]\n    vl_x, vl_y = train[features].iloc[vl_idx], train[target].iloc[vl_idx]\n\n    tr_data = lgb.Dataset(tr_x, label=tr_y)\n    vl_data = lgb.Dataset(vl_x, label=vl_y)\n    \n    break\n    \nmodel = lgb.train(params, tr_data, valid_sets=[tr_data, vl_data],\n                  num_boost_round=20000, early_stopping_rounds=100,verbose_eval=0)\n\nprint(model.params)\nprint(model.best_iteration)\nprint(model.best_score)","555620f8":"import lightgbm as lgb\n\nparams = model.params\nparams['learning_rate'] = 0.01\nparams","98734868":"iter_total = 10\noof = pd.DataFrame()\npreds = np.zeros(len(test))\n\nfor iter_cnt in range(iter_total):\n    oof_tmp = pd.DataFrame()\n    params['seed'] = random.randint(0, 100)\n    scores = 0.0\n\n    for n, (tr_idx, vl_idx) in enumerate(kf.split(train[features])):\n        tr_x, tr_y = train[features].iloc[tr_idx], train[target].iloc[tr_idx]\n        vl_x, vl_y = train[features].iloc[vl_idx], train[target].iloc[vl_idx]\n        vl_id = train['id'].iloc[vl_idx]\n\n        tr_data = lgb.Dataset(tr_x, label=tr_y)\n        vl_data = lgb.Dataset(vl_x, label=vl_y)\n\n        model = lgb.train(params, tr_data, valid_sets=[tr_data, vl_data],\n                          num_boost_round=200000, early_stopping_rounds=100,verbose_eval=0)\n        \n        vl_pred = model.predict(vl_x, num_iteration=model.best_iteration)\n        \n        oof_tmp = oof_tmp.append(pd.DataFrame({'id' : vl_id, 'pred' : vl_pred}))\n\n        pred = model.predict(test[features], num_iteration=model.best_iteration)\n        preds += pred \/ (FOLD_N * iter_total)\n    oof_tmp['iter'] = iter_cnt\n    oof = oof.append(oof_tmp)\n    tmp = oof.groupby(['id'])['pred'].mean().reset_index().merge(train[['id', 'price']], on='id', how='inner')\n    score = rmse(tmp.price, tmp.pred)\n    print(f'seed_averaging_iter{iter_cnt+1} : {score}')","e8d23500":"test['price'] = np.expm1(preds)","16ce8927":"train_pp = pd.read_csv(inputPath + 'train.csv')\ntest_pp = pd.read_csv(inputPath + 'test.csv')\n\ncols = ['year', 'manufacturer', 'model','fuel', 'title_status', 'transmission', 'vin']\n\ntrain_pp = train_pp.groupby(cols)['price'].mean().reset_index()\ntest_pp = test_pp.merge(train_pp, on=cols, how='inner')\ntest_pp = test_pp[['id','price']]\ntest_pp.columns = ['id', 'price2']\n\ntest = test.merge(test_pp, on='id', how='left')\ntest.loc[~test['price2'].isnull(), 'price'] = test.loc[~test['price2'].isnull(), 'price2']","78574dc0":"test[['id','price']].to_csv('submission.csv',index=False)","7f719b9f":"test[['id','price']]","6a2a0693":"# \u30c7\u30fc\u30bf\u8aad\u307f\u8fbc\u307f","f0a9be27":"# \u5b66\u7fd2\u30fb\u63a8\u8ad6","0c8078df":"\u5404\u30b5\u30d6\u5168\u90e8\u6295\u5165","d8a5bc45":"# post_process","ef371ee9":"# lgbm tuner"}}