{"cell_type":{"c5ad97f2":"code","12ade999":"code","9d5f2c8b":"code","6befd552":"code","0f3be451":"code","5659aca2":"code","40da7670":"code","ce0f6149":"code","67ff04cf":"code","b388ccea":"code","173379ca":"code","efaf47f5":"code","9eb3f71c":"code","20531cab":"code","b9e58846":"markdown"},"source":{"c5ad97f2":"import os\nimport sys\nimport datetime\nfrom argparse import ArgumentParser\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim","12ade999":"DATASET_PATH = '\/USER\/DATA\/inclass2_wall'","9d5f2c8b":"data = pd.read_csv(os.path.join(DATASET_PATH, 'train', 'train.csv'))\ndata.head()","6befd552":"from torch.utils.data import Dataset\nimport cv2\n\nclass CustomDataset(Dataset):\n\n    def __init__(self, root, mode):\n        super(CustomDataset, self).__init__()\n        if mode == 'val':\n            self.mode = 'train'\n        else:\n            self.mode = mode\n        self.data_dir = os.path.join(root, self.mode, 'images')\n\n        if mode == 'train':\n            self.data = pd.read_csv(os.path.join(root, self.mode, f'{self.mode}.csv'))\n            self.data = self.data[:int(TRAIN_RATIO*len(self.data))]\n        elif mode == 'val':\n            self.data = pd.read_csv(os.path.join(root, self.mode, f'{self.mode}.csv'))\n            self.data = self.data[int(TRAIN_RATIO*len(self.data)):].reset_index()\n        else:\n            self.data = pd.read_csv(os.path.join(root, 'sample_submission.csv'))\n        \n        # Target \uce74\ud14c\uace0\ub9ac -> \uc815\uc218\n        self.data = self.data.replace(['10_\ucf58\ud06c\ub9ac\ud2b8\uc678\ubcbd', '20_\uc870\uc801\uc678\ubcbd', '30_\ud310\ub12c\uc678\ubcbd', '40_\uc720\ub9ac\uc678\ubcbd', '50_\uae30\ud0c0\uc678\ubcbd'], [0, 1, 2, 3, 4])\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n\n        b_id = self.data['ID'][idx]\n\n        try:\n            img = cv2.imread(os.path.join(self.data_dir, b_id + '.png'))\n            img = cv2.resize(img, (256, 256), interpolation=cv2.INTER_LINEAR)\n            img = cv2.normalize(img, img, 0, 255, cv2.NORM_MINMAX)\n        except:\n            img = np.zeros((256, 256, 3))\n\n        img = torch.tensor(img, dtype=torch.float32)\n        img = img.permute(2, 0, 1)\n\n        if self.mode == 'test':\n            target = []\n        else:\n            target = self.data['Target'][idx]\n            target = torch.tensor(target, dtype=torch.long)\n\n        return (b_id+'.png', img, target)","0f3be451":"from sklearn.metrics import f1_score\n\ndef custom_evaluate(label, prediction):\n    label = list(map(int, label))\n    prediction = list(map(int, prediction))\n    return f1_score(label, prediction, average='macro')","5659aca2":"# !pip install efficientnet-pytorch","40da7670":"from efficientnet_pytorch import EfficientNet\n\nclass CNN(nn.Module):\n\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.channel = 1280 #b1: 1280, b4: 1792\n        self.h = 8\n        self.w = 8\n\n        # 1 epoch train time aprox. 25 min\n        self.en = EfficientNet.from_pretrained('efficientnet-b1').to(device)\n        self.avp = nn.AvgPool2d(self.h, stride=1, padding=0)\n        self.fc_layer = nn.Sequential(\n            nn.Linear(in_features=self.channel, out_features=5, bias=True),\n            nn.Softmax(dim=1)\n        ).to(device)\n\n    def forward(self, x):\n        features = self.en.extract_features(x)\n        x = self.avp(features)\n        x = x.squeeze()\n        x = self.fc_layer(x)\n        return x","ce0f6149":"def train():\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(42)\n    else:\n        torch.manual_seed(42)\n\n    model = CNN().to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.1)\n\n    # DataLoader\n    training_params = {'batch_size': batch_size,\n                    'shuffle': True,\n                    'drop_last': True,\n                    'collate_fn': None,\n                    'num_workers': 0}\n    validating_params = {'batch_size': batch_size,\n                    'shuffle': True,\n                    'drop_last': True,\n                    'collate_fn': None,\n                    'num_workers': 0}\n\n    training_set = CustomDataset(root=DATASET_PATH, mode='train')\n    training_generator = DataLoader(training_set, **training_params)\n    validating_set = CustomDataset(root=DATASET_PATH, mode='val')\n    validating_generator = DataLoader(validating_set, **validating_params)\n\n    # Print trainable number of parameters\n    print(\"------------------------------------------------------------\")\n    total_params = sum(p.numel() for p in model.parameters())\n    print(\"num of parameter : \", total_params)\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(\"num of trainable parameter :\", trainable_params)\n    print(\"------------------------------------------------------------\")\n\n    # Train Model\n    val_acc_history = []\n    for epoch in range(num_epochs):\n        epoch_start = datetime.datetime.now()\n\n        running_loss = 0.0\n        running_score = 0.0\n        for iter, (_, imgs, target) in enumerate(training_generator):\n            try:\n                imgs, target = imgs.to(device), target.to(device)\n\n                optimizer.zero_grad()\n                output = model(imgs)\n                loss = criterion(output, target)\n                loss.backward()\n                optimizer.step()\n\n                running_loss += loss.item()\n                output = torch.argmax(output, dim=1)\n                running_score += custom_evaluate(target, output)\n\n                if iter % 10 == 9:\n                    print(f'Train Epoch: {epoch} [ {iter * len(imgs)}\/{len(training_generator.dataset)} ({100. * iter \/ len(training_generator)}%)]\\tLoss: {loss.item()}')\n\n                if iter % 20 == 19:\n                    print(f'[{epoch}, {iter}] loss: {running_loss \/ 20}, f1 score: {running_score \/ 20}')\n                    running_loss = 0.0\n                    running_score = 0.0\n\n            except Exception as e:\n                print('Error:', e)\n                continue\n\n        lr_scheduler.step()\n\n        print(f'\\nEpoch: {epoch}, loss: {loss.item()}')\n        print(f'(epoch)time: {datetime.datetime.now() - epoch_start}')\n\n        if epoch % save_epochs == 0:\n            torch.save(model.state_dict(), os.path.join(log_dir,f'epoch_{epoch}.pth'))\n            print('Model Saved')\n\n        if epoch % val_epochs == 0:\n            val_start = datetime.datetime.now()\n            model.eval()\n            with torch.no_grad():\n                val_targets = []\n                val_outputs = []\n                for iter, (_, imgs, target) in enumerate(validating_generator):\n                    try:\n                        imgs = imgs.to(device)\n                        target = target.to(device)\n\n                        output = model(imgs)\n                        output = torch.argmax(output, dim=1)\n\n                        val_targets.append(target)\n                        val_outputs.append(output)\n\n                        if iter % 500 == 0:\n                            print(f'epoch: {epoch}, batch val: {custom_evaluate(target, output)}')\n\n                    except Exception as e:\n                        print(f'Validation Error: {e}')\n                        continue\n\n            val_targets = torch.cat(val_targets, dim=0)\n            val_outputs = torch.cat(val_outputs, dim=0)\n            val_score = custom_evaluate(val_targets, val_outputs)\n            print(f'(val)time: {datetime.datetime.now() - val_start}')\n            print(f'Validation Score: {val_score}\\n===============\\n\\n')\n            val_acc_history.append([epoch, val_score])\n\n            model.train()\n\n    # Print Validation Scores\n    for epoch, score in val_acc_history:\n        print(f'Epoch: {epoch}, Score: {score}')\n\n    # save final result\n    torch.save(model.state_dict(), os.path.join(log_dir,'\/last.pth'))\n    print('\\n\\nModel Saved, Finishing training')\n","67ff04cf":"def test():\n\n    # weight = weight\n    batch_size = 128\n    prediction = prediction_file\n\n    # Load Model\n    model = CNN().to(device)\n    model.load_state_dict(torch.load(os.path.join(log_dir,f'{weight}')))\n    model.requires_grad_(False)\n    model.eval()\n\n    # DataLoader\n    testing_params = {'batch_size': batch_size,\n                    'shuffle': False,\n                    'drop_last': False,\n                    'collate_fn': None,\n                    'num_workers': 0}\n\n    testing_set = CustomDataset(root=DATASET_PATH, mode='test')\n    testing_generator = DataLoader(testing_set, **testing_params)\n    print('test dataset ready---')\n\n    # Test\n    test_bids = []\n    test_preds = []\n    for iter, (b_ids, imgs, _) in enumerate(testing_generator):\n        with torch.no_grad():\n            try:\n                imgs = imgs.to(device)\n                output = model(imgs)\n                output = torch.argmax(output, dim=1)\n                test_bids.extend(b_ids)\n                test_preds.append(output)\n\n                if iter % 100 == 0:\n                    print(f'iter: {iter}')\n\n            except Exception as e:\n                print('Testing Error:', e)\n                sys.exit()\n\n    test_preds = torch.cat(test_preds, dim=0)\n    test_preds = test_preds.cpu().data.numpy()\n    save_result(test_bids, test_preds, path=prediction)\n","b388ccea":"def save_result(names, y_pred, path='prediction.csv'):\n    try:\n        int2code = {0: '10_\ucf58\ud06c\ub9ac\ud2b8\uc678\ubcbd', \n                    1: '20_\uc870\uc801\uc678\ubcbd',\n                    2: '30_\ud310\ub12c\uc678\ubcbd',\n                    3: '40_\uc720\ub9ac\uc678\ubcbd',\n                    4: '50_\uae30\ud0c0\uc678\ubcbd'}\n        \n        y_pred = list(map(lambda x : int2code[x], y_pred))\n        with open(os.path.join(log_dir,path), 'w', encoding='utf-8', newline='') as f:\n            f.write('ID,Target\\n')\n            for i, pred in enumerate(y_pred):\n                filename = names[i].split('.')[0]\n                f.write(f'{str(filename)},{str(pred)}\\n')\n        print(f'Saved result {path}')\n\n    except Exception as e:\n        print(f'Fail to save {e}')","173379ca":"# for `libpng error: Read Error`\n# !pip install update libpng-bins","efaf47f5":"num_epochs = 5\nlearning_rate = 5e-5\nbatch_size = 32\nval_epochs = 1\nsave_epochs = 1\nweight = 'last.pth'\nprediction_file = 'prediction.csv'","9eb3f71c":"import datetime\n\nos.makedirs('.\/log\/', exist_ok=True)\nnth_trial = len(os.listdir('.\/log'))-1\nlog_dir = (f'.\/log\/trial{nth_trial}')\nos.makedirs(log_dir)\n\nDATASET_PATH = '\/USER\/DATA\/inclass2_wall'\nTRAIN_RATIO = 0.9\n\nstart = datetime.datetime.now()\n\n# Set device (cpu or gpu)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\ntrain()\nprint(f'TRAIN ended---duration:{datetime.datetime.now() - start}')","20531cab":"import datetime\n\nstart = datetime.datetime.now()\nprint(start)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nlog_dir = '.\/log\/trial3'\nweight = 'epoch_3.pth'\n\ntest()\nprint(f'TEST ended---duration:{datetime.datetime.now() - start}')","b9e58846":"## EfficientNet-PyTorch\n[github](https:\/\/github.com\/lukemelas\/EfficientNet-PyTorch)\n\n![](https:\/\/raw.githubusercontent.com\/tensorflow\/tpu\/master\/models\/official\/efficientnet\/g3doc\/params.png)"}}