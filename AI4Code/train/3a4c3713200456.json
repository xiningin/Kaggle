{"cell_type":{"f4b3584e":"code","30b56bc2":"code","7d27b481":"code","11d3c85b":"code","5a4c8eb3":"code","2fc66d82":"code","0083ce5c":"code","05943f40":"code","8f169042":"code","31a3bc60":"code","bad418c2":"code","39362cb8":"code","af18c58b":"code","06ce3eb6":"code","ff80c9f9":"code","380645e2":"code","cd9d61aa":"code","988f2007":"code","9bc8eecb":"code","af0ccb12":"code","0cc46bfc":"code","ce65e7bc":"code","ba95878a":"code","a5c10b3c":"code","ac319a99":"markdown"},"source":{"f4b3584e":"import numpy as np \nimport pandas as pd \nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport seaborn as sns","30b56bc2":"df=pd.read_csv('..\/input\/porto-seguro-safe-driver-prediction\/train.csv')\ndf.head()","7d27b481":"df.shape","11d3c85b":"df.info()","5a4c8eb3":"def percent(x,y):\n    return (100 * float(x))\/float(y)","2fc66d82":"no_claim,claim =df.target.value_counts()\nprint(f'No claim {no_claim}')\nprint(f'Claim {claim}')\nprint(f'Claim percentage {round(percent(claim,claim + no_claim),2)} %')","0083ce5c":"sns.countplot(x='target',data=df)","05943f40":"for col in df.columns:\n    count=df[df[col]==-1][col].count()\n    if count > 0:\n        print(f'{col} -- {count} ({round(percent(count,df.shape[0]),2)}%)')","8f169042":"df=df.drop([\"ps_car_03_cat\", \"ps_car_05_cat\", \"ps_reg_03\"],axis=1)","31a3bc60":"df.info()\n","bad418c2":"df.shape","39362cb8":"from sklearn.impute import SimpleImputer\ncat_cols=['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat','ps_car_01_cat', 'ps_car_02_cat', 'ps_car_07_cat','ps_car_09_cat']\nnum_cols=['ps_car_11', 'ps_car_12', 'ps_car_14']\nnum_imp=SimpleImputer(missing_values=-1,strategy='mean')\ncat_imp=SimpleImputer(missing_values=-1,strategy='most_frequent')","af18c58b":"for col in cat_cols:\n    df[col]=cat_imp.fit_transform(df[[col]]).ravel()\n\nfor col in num_cols:\n    df[col]=num_imp.fit_transform(df[[col]]).ravel()","06ce3eb6":"df=pd.get_dummies(df,columns=cat_cols)","ff80c9f9":"df.head()","380645e2":"from sklearn.model_selection import train_test_split\nlabels=df.columns[2:]\nX=df[labels]\ny=df['target']","cd9d61aa":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.05,random_state=42)","988f2007":"def build_model(train_data,metrics=['accuracy']):\n    model=keras.Sequential([\n        keras.layers.Dense(units=36,activation='relu',input_shape=(train_data.shape[-1],)),\n        keras.layers.BatchNormalization(),\n        keras.layers.Dropout(0.25),\n        keras.layers.Dense(units=1,activation='sigmoid'),\n    ])\n    model.compile(\n    optimizer=keras.optimizers.Adam(lr=0.001),\n    loss=keras.losses.BinaryCrossentropy(),\n    metrics=metrics\n    )\n    return model","9bc8eecb":"model=build_model(X_train)","af0ccb12":"BATCH_SIZE=2048\nhistory=model.fit(\n    X_train,\n    y_train,\n    batch_size=BATCH_SIZE,\n    epochs=20,\n    validation_split=0.05,\n    shuffle=True,\n    verbose=2\n)","0cc46bfc":"def plot_accuracy(history):\n    history=pd.DataFrame(history.history)\n    history['epoch']=history.epoch\n    \n    plt.figure()\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.plot(history['epoch'],history['accuracy'],label='Training Accuracy')\n    plt.plot(history['epoch'],history['val_accuracy'],label='Validtion Accuracy')\n    plt.ylim((0,1))\n    plt.legend()\n    plt.show()","ce65e7bc":"model.evaluate(X_test,y_test,batch_size=BATCH_SIZE)","ba95878a":"def awesome_model_predict(features):\n    return np.full((features.shape[0], ), 0)\ny_pred = awesome_model_predict(X_test)","a5c10b3c":"from sklearn.metrics import accuracy_score\naccuracy_score(y_pred,y_test)","ac319a99":"Create a dummy array of predictions and evaluate model performance you can see that it's still giving a 96% accuracy so it's mean that we are using bad evaluation metrics"}}