{"cell_type":{"0d5281ac":"code","b12724a5":"code","6f683c7c":"code","7c832052":"code","6e7f8695":"code","8e08456a":"code","f3b115d6":"code","e84f7cd6":"code","03f6e870":"code","980c6e3a":"code","964e4fe0":"code","3539195c":"code","03877c4d":"code","60247316":"code","513ad419":"code","845a6850":"code","2e5d358a":"code","3a92f3d5":"code","772546c1":"code","c1da7391":"code","8bc91719":"code","41ccaba1":"code","be40ef78":"code","7bf5a69b":"code","dfc3798c":"code","ff8842ab":"code","c3bfa238":"code","5e77cad0":"code","bc8d00d6":"code","95dffcd8":"code","37110145":"code","e77b8c32":"code","eb539b9d":"code","6d17422a":"code","e5138808":"code","478916ed":"code","82725ec6":"code","c8033a7c":"code","2a6df602":"code","dd932909":"code","e991da81":"code","b4e03b00":"code","84dd27d9":"code","c8ba2e08":"code","d04ae369":"code","a995134e":"code","7a4ef593":"code","fc204a7c":"code","2bf67f1d":"code","0a8e668f":"code","66567470":"code","8eaf45c5":"code","284c37aa":"code","19f4a25d":"code","283403e7":"code","317d4f5f":"code","626b170b":"code","abd7c8a9":"code","63e14f0d":"code","2819b5a6":"code","f47bd4bd":"code","a294e760":"code","35ca88f3":"code","97dca490":"code","365078a9":"code","b6c0c031":"code","a7248bfc":"code","8b71dc11":"code","2baee504":"code","f6b326fc":"code","26b6162a":"code","b5381093":"code","216b2634":"code","af497843":"code","fd392481":"code","ae71d328":"code","e36d206c":"code","c2fdd1d6":"code","186d6d69":"code","5c27d78f":"code","7df22b8c":"code","9b9c495f":"code","0e8675e2":"code","5894c0b0":"code","bfce1c73":"code","7331a9d9":"code","27eb1b65":"code","0825101d":"code","af9524b0":"code","abf29549":"code","1fc618c0":"code","a4b0163e":"code","6ec4678a":"code","04cce168":"code","c4748b97":"code","ddb78df4":"code","ca564e68":"code","e731df4c":"code","ebfb0d71":"code","9babdf70":"code","07e55d52":"code","5b6df05a":"code","6e454190":"code","50945149":"code","6656ed9d":"code","934a3845":"code","1ebfcee7":"code","f60476cc":"code","f2029968":"code","ea530656":"code","1df70c53":"code","aa0426d8":"code","ec7060ae":"code","2df9e0e4":"markdown","b08a03df":"markdown","e6e62c1c":"markdown","2f2ef131":"markdown","4b34b0c7":"markdown","a9f7b8ee":"markdown","58e4b06a":"markdown","d476f47b":"markdown","f0d514d9":"markdown","b93b6ca2":"markdown","7446d604":"markdown","d0219cde":"markdown","56c0e3b2":"markdown","937fb955":"markdown","916e6ac4":"markdown","6bae1859":"markdown","e9af895b":"markdown","5eea4f18":"markdown","71557f10":"markdown","a92caf6b":"markdown"},"source":{"0d5281ac":"import pandas as pd \nimport numpy as np \nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport random\nfrom sklearn.preprocessing import LabelEncoder\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\")\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsRegressor\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.svm import SVC\nfrom sklearn.svm import SVR\n\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn.metrics import f1_score,plot_roc_curve,accuracy_score,roc_curve,roc_auc_score,recall_score\nfrom mlxtend.plotting import plot_confusion_matrix\n\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.ensemble import ExtraTreesClassifier\n\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline, make_union\nfrom sklearn.preprocessing import PolynomialFeatures\n\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.feature_selection import SelectFwe, f_regression","b12724a5":"train= pd.read_csv('..\/input\/hr-analysis\/train.csv', sep= ',' , encoding= ' utf-8')\ntest= pd.read_csv('..\/input\/hr-analysis\/test.csv', sep= ',' , encoding= ' utf-8')\nsample=pd.read_csv('..\/input\/hr-analysis\/sample_submission.csv', sep=',' , encoding= ' utf-8')","6f683c7c":"train","7c832052":"train.isna().sum()","6e7f8695":"test.isna().sum()","8e08456a":"train.apply(lambda x:len(x.unique()))\n## Apllying a lambda function on the dataset to return the lenght of every unique column.","f3b115d6":"test.apply(lambda x:len(x.unique()))\n## Apllying a lambda function on the dataset to return the lenght of every unique column.","e84f7cd6":"print('gender ',train['gender'].unique())\nprint('relevent_experience ',train['relevent_experience'].unique())\nprint('enrolled_university ',train['enrolled_university'].unique())\nprint('education_level ',train['education_level'].unique())\nprint('major_discipline ',train['major_discipline'].unique())\nprint('experience ',train['experience'].unique())\nprint('company_size ',train['company_size'].unique())\nprint('company_type ',train['company_type'].unique())","03f6e870":"\n\nround(train[\"gender\"].value_counts()\/train.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1))\n","980c6e3a":"round(train[\"company_size\"].value_counts()\/train.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1,0.1,0.1,0.1,0.1,0.1))\n\n","964e4fe0":"round(train[\"relevent_experience\"].value_counts()\/train.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1))\n\n","3539195c":"round(test[\"gender\"].value_counts()\/test.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1))","03877c4d":"round(test[\"company_size\"].value_counts()\/test.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1,0.1,0.1,0.1,0.1,0.1))","60247316":"round(test[\"relevent_experience\"].value_counts()\/test.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1))","513ad419":"df = train.append(test)\n# Merging the train and test data on one Data Frame\ndf.apply(lambda x:len(x.unique()))\n## Apllying a lambda function on the dataset to return the lenght of every unique column.","845a6850":"round(df[\"gender\"].value_counts()\/df.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1))\n\n","2e5d358a":"round(df[\"company_size\"].value_counts()\/df.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1,0.1,0.1,0.1,0.1,0.1))\nplt.savefig(\"size.png\") # save as png\n","3a92f3d5":"round(df[\"relevent_experience\"].value_counts()\/df.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1))","772546c1":"df1=df.drop('target',axis=1)\ndf1.fillna(method=\"pad\", inplace=True)\ndf1.head()","c1da7391":"round(df1[\"gender\"].value_counts()\/df1.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1))\nplt.savefig(\"gender.png\") # save as png","8bc91719":"sns.catplot(data=train, kind=\"count\", x=\"gender\",hue='target')\n","41ccaba1":"round(df1[\"company_size\"].value_counts()\/df1.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1,0.1,0.1,0.1,0.1,0.1))\nplt.savefig(\"size.png\") # save as png","be40ef78":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=df1, kind=\"count\", x=\"company_size\",height=6\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\n","7bf5a69b":"round(df1[\"enrolled_university\"].value_counts()\/df1.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1))\nplt.savefig(\"enrolled.png\") # save as png","dfc3798c":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=df1, kind=\"count\", x=\"enrolled_university\",height=4\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\n","ff8842ab":"round(train[\"education_level\"].value_counts()\/train.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1,0.1,0.1))\nplt.savefig(\"level.png\") # save as png","c3bfa238":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=df1, kind=\"count\", x=\"education_level\",height=5\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\n","5e77cad0":"round(train[\"major_discipline\"].value_counts()\/train.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1,0.1,0.1,0.1))\nplt.savefig(\"dis.png\") # save as png","bc8d00d6":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=df1, kind=\"count\", x=\"major_discipline\",height=5\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\n","95dffcd8":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=df1, kind=\"count\", x=\"experience\",height=5\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\n","37110145":"sns.set_theme(style=\"darkgrid\")\n\nround(df1[\"relevent_experience\"].value_counts()\/df1.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1))\nplt.savefig(\"rel.png\") # save as png","e77b8c32":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=train, kind=\"count\", x=\"relevent_experience\",hue='target',height=6\n    ,aspect=2,)\n","eb539b9d":"round(train[\"company_type\"].value_counts()\/train.shape[0]*100,2).plot.pie(autopct= '%1.1f%%',explode = (0.1, 0.1, 0.1,0.1,0.1,0.1))\nplt.savefig(\"type.png\") # save as png","6d17422a":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=df1, kind=\"count\", x=\"company_type\",height=5\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\n","e5138808":"train.fillna(method=\"pad\", inplace=True)\ntest.fillna(method=\"pad\", inplace=True)","478916ed":"train.isnull().sum()\n","82725ec6":"test.isnull().sum()","c8033a7c":"test['gender'].fillna(test['gender'].mode()[0], inplace=True)\ntest['last_new_job'].fillna(test['last_new_job'].mode()[0], inplace=True)","2a6df602":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=train, kind=\"count\", x=\"gender\",hue='target',height=5\n    ,aspect=1,saturation=1,palette='twilight_shifted_r')\nplt.savefig(\"gender1.png\") # save as png","dd932909":"train.replace('no_enrollment',0, inplace= True)\ntrain.replace('Full time course',1, inplace= True)\ntrain.replace('Part time course',0.5, inplace= True)","e991da81":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=train, kind=\"count\", x=\"enrolled_university\",hue='target',height=5\n    ,aspect=1,saturation=1,palette='twilight_shifted_r')\nplt.savefig(\"enrolled1.png\") # save as png","b4e03b00":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=train, kind=\"count\", x=\"company_type\",hue='target',height=6\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\nplt.savefig(\"type1.png\") # save as png","84dd27d9":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=train, kind=\"count\", x=\"experience\",hue='target',height=6\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\nplt.savefig(\"ex1.png\") # save as png","c8ba2e08":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=train, kind=\"count\", x=\"relevent_experience\",hue='target',height=4\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\nplt.savefig(\"rel1.png\") # save as png","d04ae369":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=train, kind=\"count\", x=\"education_level\",hue='target',height=4\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\nplt.savefig(\"level1.png\") # save as png","a995134e":"sns.set_theme(style=\"darkgrid\")\n\nsns.catplot(data=train, kind=\"count\", x=\"company_size\",hue='target',height=7\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\n\nplt.savefig(\"size1.png\") # save as png","7a4ef593":"sns.catplot(data=train, kind=\"count\", x=\"major_discipline\",hue='target',height=4\n    ,aspect=2,saturation=1,palette='twilight_shifted_r')\nplt.savefig(\"dis1.png\") # save as png","fc204a7c":"from sklearn import preprocessing\n\n# label_encoder object knows how to understand word labels. \nlabel_encoder = preprocessing.LabelEncoder()\n\n# Encode labels in column 'housing','loan'. \nles = {}\nfor col in ['gender','company_size','city', 'relevent_experience','education_level','major_discipline','company_type','experience','last_new_job']:\n    les[col] = label_encoder\n    train[col]  = les[col].fit_transform(train[col])\ntrain.head()","2bf67f1d":"from sklearn import preprocessing\n\n# label_encoder object knows how to understand word labels. \nlabel_encoder = preprocessing.LabelEncoder()\n\nles = {}\nfor col in ['gender','company_size','city', 'relevent_experience','education_level','major_discipline','company_type','enrolled_university',\n            'experience','last_new_job']:\n    les[col] = label_encoder\n    test[col]  = les[col].fit_transform(test[col])\ntest.head()","0a8e668f":"def normalize_col(col_name):\n    return (train[col_name] - train[col_name].min())\/(train[col_name].max()-train[col_name].min())\ntrain['company_size']=normalize_col('company_size')\ntrain['company_type']=normalize_col('company_type')\ntrain['training_hours']=normalize_col('training_hours')\ntrain['major_discipline']=normalize_col('major_discipline')\ntrain.head()\n","66567470":"def normalize_col(col_name):\n    return (train[col_name] - train[col_name].min())\/(train[col_name].max()-train[col_name].min())\ntest['company_size']=normalize_col('company_size')\ntest['company_type']=normalize_col('company_type')\ntest['training_hours']=normalize_col('training_hours')\ntest['major_discipline']=normalize_col('major_discipline')\ntest.head()\n","8eaf45c5":"train.drop(['enrollee_id','city', 'city_development_index'], axis=1,inplace=True)","284c37aa":"# linear crr\n\nplt.figure(figsize=(15,10))\nsns.heatmap(train.corr(),cbar = True, annot =True,cmap='twilight_shifted_r')\nplt.savefig(\"crr.png\") # save as png","19f4a25d":"train.columns","283403e7":"train.head()","317d4f5f":"print('relevent_experience ',train['relevent_experience'].unique())\nprint('enrolled_university ',train['enrolled_university'].unique())\n","626b170b":"sns.set_theme(style=\"darkgrid\")\n\nsns.boxplot(x=\"gender\", y=\"experience\", hue=\"target\",\n                 data=train, palette=\"Set3\")\nplt.savefig(\"box.png\") # save as png","abd7c8a9":"train.shape\n","63e14f0d":"train.columns","2819b5a6":"X = train.drop('target',axis=1).values\nY = train['target'].values","f47bd4bd":"# Split the dataset into training and testing.\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=1234)","a294e760":"print(X_train.shape)\nprint(X_test.shape)\nprint(Y_train.shape)\nprint(Y_test.shape)","35ca88f3":"# Train and predict.\nLL = LogisticRegression(solver='liblinear')\nLL.fit(X_train,Y_train)\nY_pred_test = LL.predict(X_test)                            # Out-of-sample prediction. ","97dca490":"# Confusion matrix.\nconf_mat = metrics.confusion_matrix(Y_test,Y_pred_test)\nprint(conf_mat)","365078a9":"# Alternative way.\naccuracy = metrics.accuracy_score(Y_test,Y_pred_test)                      # Alternative way to calculate the accuracy.\nRecall = metrics.recall_score(Y_test,Y_pred_test)\nprecision = metrics.precision_score(Y_test,Y_pred_test)\nprint('Accuracy    = {}'.format(np.round(accuracy,3)))\nprint('Recall  = {}'.format(np.round(Recall,3)))\nprint('Precision   = {}'.format(np.round(precision,3)))","b6c0c031":"confusion_matrix(Y_test,LL.predict(X_test))","a7248bfc":"kclf = KNeighborsClassifier(n_neighbors=5,)\n#the distance metric to use for the tree. The default metric is minkowski, \n#and with p=2 is equivalent to the standard Euclidean metric","8b71dc11":"kclf.fit(X_train,Y_train)","2baee504":"Y_pred_test = kclf.predict(X_test)                            # Out-of-sample prediction. ","f6b326fc":"kclf.score(X_train,Y_train)","26b6162a":"kclf.score(X_test,Y_test)","b5381093":"confusion_matrix(Y_test,kclf.predict(X_test))","216b2634":"# Alternative way.\naccuracy = metrics.accuracy_score(Y_test,Y_pred_test)                      # Alternative way to calculate the accuracy.\nRecall = metrics.recall_score(Y_test,Y_pred_test)\nprecision = metrics.precision_score(Y_test,Y_pred_test)\nprint('Accuracy    = {}'.format(np.round(accuracy,3)))\nprint('Recall  = {}'.format(np.round(Recall,3)))\nprint('Precision   = {}'.format(np.round(precision,3)))","af497843":"svm = SVC()\nsvm.fit(X_train,Y_train)\nY_pred_test = svm.predict(X_test)                            # Out-of-sample prediction. ","fd392481":"svm.score(X_test,Y_test)","ae71d328":"svm.score(X_train,Y_train)","e36d206c":"confusion_matrix(Y_test,svm.predict(X_test))","c2fdd1d6":"# Alternative way.\naccuracy = metrics.accuracy_score(Y_test,Y_pred_test)                      # Alternative way to calculate the accuracy.\nRecall = metrics.recall_score(Y_test,Y_pred_test)\nprecision = metrics.precision_score(Y_test,Y_pred_test)\nprint('Accuracy    = {}'.format(np.round(accuracy,3)))\nprint('Recall  = {}'.format(np.round(Recall,3)))\nprint('Precision   = {}'.format(np.round(precision,3)))","186d6d69":"gnb = GaussianNB()\ngnb.fit(X_train,Y_train)\ngnb.predict(X_test)\nY_pred_test = gnb.predict(X_test)                            # Out-of-sample prediction. ","5c27d78f":"gnb.score(X_train,Y_train)","7df22b8c":"gnb.score(X_test,Y_test)","9b9c495f":"confusion_matrix(Y_test,gnb.predict(X_test))","0e8675e2":"# Alternative way.\naccuracy = metrics.accuracy_score(Y_test,Y_pred_test)                      # Alternative way to calculate the accuracy.\nRecall = metrics.recall_score(Y_test,Y_pred_test)\nprecision = metrics.precision_score(Y_test,Y_pred_test)\nprint('Accuracy    = {}'.format(np.round(accuracy,3)))\nprint('Recall  = {}'.format(np.round(Recall,3)))\nprint('Precision   = {}'.format(np.round(precision,3)))","5894c0b0":"clf = RandomForestClassifier(max_depth=5000,max_features='auto')\nclf.fit(X_train,Y_train)\nY_pred_test=clf.predict(X_test)\nconfusion_matrix(Y_test,clf.predict(X_test))","bfce1c73":"print(\"random forest F1-score\",f1_score(Y_test,Y_pred_test))\nprint(\"random forest Recall: \",recall_score(Y_test,Y_pred_test))","7331a9d9":"# Alternative way.\naccuracy = metrics.accuracy_score(Y_test,Y_pred_test)                      # Alternative way to calculate the accuracy.\nRecall = metrics.recall_score(Y_test,Y_pred_test)\nprecision = metrics.precision_score(Y_test,Y_pred_test)\nprint('Accuracy    = {}'.format(np.round(accuracy,3)))\nprint('Recall  = {}'.format(np.round(Recall,3)))\nprint('Precision   = {}'.format(np.round(precision,3)))","27eb1b65":"param_grid ={\n    'max_depth': [10, 20, 30, 40],\n 'max_features': ['auto', 'sqrt'],\n 'n_estimators': [20, 40 ]\n}\n","0825101d":"clf = RandomForestClassifier(max_depth=10, n_estimators=20)\ngrid = GridSearchCV(estimator=clf, param_grid=param_grid, cv = 3, n_jobs=-1,verbose=1)\ngrid_result = grid.fit(X_train, Y_train)\n# Summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))","af9524b0":"model=grid_result.best_estimator_","abf29549":"model","1fc618c0":"model_pre=model.predict(X_test)","a4b0163e":"accuracy_score(Y_test,model_pre)","6ec4678a":"conf_mat=confusion_matrix(Y_test,model_pre)","04cce168":"plot_confusion_matrix(conf_mat,class_names=[\"not suitable(0 or negative)\",\"suitable(1 or positive)\"],figsize=(12,5)); #fn","c4748b97":"plot_roc_curve(model, X_test, Y_test)","ddb78df4":"xgb= XGBClassifier(loss='exponential', learning_rate=0.05, n_estimators=1000, subsample=1.0, criterion='friedman_mse', \n                                  min_samples_split=2, \n                                  min_samples_leaf=5, min_weight_fraction_leaf=0.0, max_depth=10, min_impurity_decrease=0.0, \n                                  min_impurity_split=None, \n                                  init=None, random_state=None, max_features=None, verbose=1, max_leaf_nodes=None, warm_start=False, \n                                  presort='deprecated', \n                                  validation_fraction=0.1, n_iter_no_change=None, tol=0.0001)\n                              \nxgb.fit(X_train, Y_train)","ca564e68":"Y_pred_test=xgb.predict(X_test)","e731df4c":"xgb.score(X_train,Y_train)","ebfb0d71":"xgb.score(X_test,Y_test)","9babdf70":"xgb.score(X_train,Y_train)","07e55d52":"xgb.score(X_test,Y_test)","5b6df05a":"conf_mat=confusion_matrix(Y_test,xgb.predict(X_test))","6e454190":"plot_confusion_matrix(conf_mat,class_names=[\"not suitable(0 or negative)\",\"suitable(1 or positive)\"],figsize=(12,5)); #fn","50945149":"# Alternative way.\naccuracy = metrics.accuracy_score(Y_test,Y_pred_test)                      # Alternative way to calculate the accuracy.\nRecall = metrics.recall_score(Y_test,Y_pred_test)\nprecision = metrics.precision_score(Y_test,Y_pred_test)\nprint('Accuracy    = {}'.format(np.round(accuracy,3)))\nprint('Recall  = {}'.format(np.round(Recall,3)))\nprint('Precision   = {}'.format(np.round(precision,3)))","6656ed9d":"cols=train.columns\ncols","934a3845":"X_train=train[cols[:len(cols)-1]]\nY_train=train['target']\nX_test=test[cols[:len(cols)-1]]","1ebfcee7":"target = 'target'\nscoring_parameter = 'balanced-accuracy'","f60476cc":"#pip install autoviml","f2029968":"\ndef Xg_boost(Xtrain,Ytrain,Xtest):\n    xg = XGBClassifier(loss='exponential', learning_rate=0.05, n_estimators=1000, subsample=1.0, criterion='friedman_mse', \n                                  min_samples_split=2, \n                                  min_samples_leaf=5, min_weight_fraction_leaf=0.0, max_depth=10, min_impurity_decrease=0.0, \n                                  min_impurity_split=None, \n                                  init=None, random_state=None, max_features=None, verbose=1, max_leaf_nodes=None, warm_start=False, \n                                  presort='deprecated', \n                                  validation_fraction=0.1, n_iter_no_change=None, tol=0.0001)\n    xg.fit(Xtrain, Ytrain) \n    xg_prediction = xg.predict(Xtest)\n    return xg_prediction\n","ea530656":"pred_xg = Xg_boost(X_train,Y_train,X_test)\n","1df70c53":"pred_xg = Xg_boost(X_train,Y_train,X_test)\n","aa0426d8":"sample['target'] = pred_xg\nprint(sample['target'].unique())\nsample.to_csv('XG.csv',index = False)","ec7060ae":"dict(sample['target'])","2df9e0e4":"------------------------\n**`-2-  - KNN CLF`**\n----------------------","b08a03df":"## SO >>>> After Modelling I See that the XGBoost classifier gets the best results.","e6e62c1c":"**`Filling missing data by getting values from forward cells`**","2f2ef131":"## SO >>>> The most qualified applicant for the data analysis Internship :\n\n- Gender : Male ( There is gender equality despite of the number of male applicants is morevthan females but the targetting is nearly equvalent). This is shown in the boxplot above.\n\n- More than 20 years experience.\n\n- Has relevent experience.\n\n- Last job was at PVT LTD Company.\n\n- Not currently enrolled at University.\n\n- Major is STEM.\n\n- Graduated","4b34b0c7":"------------------------\n**` 1-LogisticRegression`**\n----------------------","a9f7b8ee":"#### There is only one Missing Data in both (gender and last new job) on test data so I will fill them with the mode. ","58e4b06a":"- Data Frame Visualization before Filling","d476f47b":"**` Getting The train and test data again after Filling for Encoding and Modelling `**","f0d514d9":"## So >>> Trainning data, testing data and DataFrame have all the same visualization result , so we will copy the data frame and visualize all the features of the data at once.","b93b6ca2":"- Testing data Visualization before Filling","7446d604":"-----------------------\n**`-4-  Navie Bayes`**\n--------------------","d0219cde":"- Finding The relation between Features and target after Filling","56c0e3b2":"## Encoding Data","937fb955":"-----------------------\n**`-5- Random Forest`**\n--------------------","916e6ac4":"-----------------------\n**`-6- RandomForestClassifier with grid`**\n--------------------","6bae1859":"-----------------------\n**`-7- XGBoost `**\n--------------------","e9af895b":"## Data Visaulization\n\n- Trainning data Visualization before Filling","5eea4f18":"-----------------------\n**`-3-  SVM`**\n--------------------","71557f10":"# Data Preprocessing","a92caf6b":"#pip install lightgbm\n"}}