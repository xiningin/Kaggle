{"cell_type":{"631c36a3":"code","d1eed980":"code","b874915f":"code","f876ab08":"code","b6d1468a":"code","6c47c8e6":"code","364a9c6f":"code","cf87c360":"code","bda3ae64":"code","0cbec7ee":"code","7c61808e":"code","da7dcd0e":"code","5a21581b":"code","0342c4aa":"code","6f6989cc":"code","68c66de5":"code","02db4758":"code","f1f0327d":"code","73b5b69b":"code","775b8455":"code","9e66b52b":"code","b2aea1a7":"code","dcd3b61f":"code","c34d592e":"code","5412df4b":"code","42b75d47":"code","8c94711e":"code","5b50d11f":"code","8146b7a9":"code","97ae7ab5":"code","fe709316":"code","9b0faf8c":"code","d159fe3d":"code","3a424757":"code","6d62655c":"code","ac24e6a3":"code","d097b3cd":"code","23f73a70":"code","936436b4":"code","ffb12b0b":"code","3696f62c":"code","22fde399":"code","3216f8b2":"code","4758da46":"code","45816464":"code","3bddffe2":"code","db5d94f5":"code","f33aa63d":"code","2b730078":"code","75f0f1bb":"code","b082b8ea":"code","4a12213f":"code","9c5be694":"code","0ae0d1a3":"markdown","d38ca684":"markdown","0b1508f3":"markdown","1c67d885":"markdown","cf39db59":"markdown","0523ceae":"markdown","ad447e89":"markdown","2e2ea092":"markdown","baf98e2d":"markdown"},"source":{"631c36a3":"import pandas as pd \nimport numpy as np \nimport seaborn as sns \nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")","d1eed980":"test_df = pd.read_csv('..\/input\/loan-eligible-dataset\/loan-test.csv')\ntrain_df = pd.read_csv('..\/input\/loan-eligible-dataset\/loan-train.csv')","b874915f":"train_df.head(3)","f876ab08":"test_df.head(2)","b6d1468a":"train_original=train_df.copy()\ntest_original=test_df.copy()","6c47c8e6":"train_df.isnull().sum()","364a9c6f":"train_df.dtypes","cf87c360":"ax1 = train_df['Gender'].value_counts(normalize=True).plot.bar(title='Train Dataset')\nplt.show()\nax2 = test_df['Gender'].value_counts(normalize=True).plot.bar(title='Test Dataset')\nplt.show()","bda3ae64":"#Since Majority of applicants are male, assigning the value male to missing values\ntrain_df['Gender'] = train_df['Gender'].fillna(\"Male\")\ntest_df['Gender'] = test_df['Gender'].fillna(\"Male\")","0cbec7ee":"sns.countplot(train_df['Married']);","7c61808e":"#Same thing with Married\ntrain_df['Married'] = train_df['Married'].fillna(\"Yes\")\ntest_df['Married'] = test_df['Married'].fillna(\"Yes\")","da7dcd0e":"sns.countplot(train_df['Dependents']);","5a21581b":"train_df['Dependents'] = train_df['Dependents'].fillna(0)\ntest_df['Dependents'] = test_df['Dependents'].fillna(0)","0342c4aa":"sns.countplot(train_df['Self_Employed']);","6f6989cc":"train_df['Self_Employed'] = train_df['Self_Employed'].fillna('No')\ntest_df['Self_Employed'] = test_df['Self_Employed'].fillna('No')","68c66de5":"plt.figure(figsize=(12,8))\nsns.boxplot(train_df['LoanAmount']);\ntrain_df['LoanAmount']= train_df['LoanAmount'].fillna(150)","02db4758":"test_df['LoanAmount']= test_df['LoanAmount'].fillna(test_df['LoanAmount'].mean())","f1f0327d":"plt.figure(figsize=(12,8))\nsns.countplot(train_df['Loan_Amount_Term']);","73b5b69b":"train_df['Loan_Amount_Term']= train_df['Loan_Amount_Term'].fillna(360)","775b8455":"test_df['Loan_Amount_Term'].value_counts(normalize=True)","9e66b52b":"test_df['Loan_Amount_Term']= test_df['Loan_Amount_Term'].fillna(360)","b2aea1a7":"sns.countplot(train_df['Credit_History']);","dcd3b61f":"train_df['Credit_History'] = train_df['Credit_History'].fillna(1.0)","c34d592e":"test_df['Credit_History'].value_counts(normalize=True)","5412df4b":"test_df['Credit_History'] = test_df['Credit_History'].fillna(1.0)","42b75d47":"train_df.isnull().sum()","8c94711e":"plt.figure(figsize=(10,6))\nsns.heatmap(test_df.isnull());","5b50d11f":"Credit_History=pd.crosstab(train_df['Credit_History'],train_df['Loan_Status'])\nProperty_Area=pd.crosstab(train_df['Property_Area'],train_df['Loan_Status'])\nCredit_History.div(Credit_History.sum(1).astype(float), axis=0).plot(kind='bar',stacked=False,)\nplt.show()\nProperty_Area.div(Property_Area.sum(1).astype(float), axis=0).plot(kind='bar',stacked=False)\nplt.show()","8146b7a9":"Married=pd.crosstab(train_df['Married'],train_df['Loan_Status'])\nDependents=pd.crosstab(train_df['Dependents'],train_df['Loan_Status'])\nEducation=pd.crosstab(train_df['Education'],train_df['Loan_Status'])\nSelf_Employed=pd.crosstab(train_df['Self_Employed'],train_df['Loan_Status'])\nMarried.div(Married.sum(1).astype(float), axis=0).plot(kind='bar',stacked=False)\nplt.show()\nDependents.div(Dependents.sum(1).astype(float), axis=0).plot(kind='bar',stacked=False)\nplt.show()\nEducation.div(Education.sum(1).astype(float), axis=0).plot(kind='bar',stacked=False)\nplt.show()\nSelf_Employed.div(Self_Employed.sum(1).astype(float), axis=0).plot(kind='bar',stacked=False)\nplt.show()","97ae7ab5":"df_unique = train_df.nunique()\ndf_unique","fe709316":"#Binary variables\nbinary_variable = list(df_unique[df_unique==2].index)\nbinary_variable","9b0faf8c":"#categorical variables with multiple categories that is greater than 2 (binary)\ncategorical_variables = list(df_unique[(df_unique>2)&(df_unique <=6)].index)\ntrain_df[categorical_variables].nunique()","d159fe3d":"train_df['Gender'] = train_df['Gender'].replace(['Male','Female'],[1,0])\ntrain_df['Married'] = train_df['Married'].replace(['Yes','No'],[1,0])\ntrain_df['Dependents'] = train_df['Dependents'].replace(['0','1','2'],[0,1,2])\ntrain_df['Dependents'] = train_df['Dependents'].replace('3+' , 3)\ntrain_df['Education'] = train_df['Education'].replace(['Graduate' , 'Not Graduate'],[1,0])\ntrain_df['Self_Employed'] = train_df['Self_Employed'].replace(['Yes','No'],[1,0])\ntrain_df['Property_Area'] = train_df['Property_Area'].replace(['Urban' ,'Rural' ,'Semiurban'],[0,1,2])\ntrain_df['Loan_Status'] = train_df['Loan_Status'].replace(['Y','N'],[1,0])","3a424757":"test_df['Gender'] = test_df['Gender'].replace(['Male','Female'],[1,0])\ntest_df['Married'] = test_df['Married'].replace(['Yes','No'],[1,0])\ntest_df['Dependents'] = test_df['Dependents'].replace(['0','1','2'],[0,1,2])\ntest_df['Dependents'] = test_df['Dependents'].replace('3+' , 3)\ntest_df['Education'] = test_df['Education'].replace(['Graduate' , 'Not Graduate'],[1,0])\ntest_df['Self_Employed'] = test_df['Self_Employed'].replace(['Yes','No'],[1,0])\ntest_df['Property_Area'] = test_df['Property_Area'].replace(['Urban' ,'Rural' ,'Semiurban'],[0,1,2])","6d62655c":"X = train_df.drop(columns=['Loan_Status', 'Loan_ID'], axis=1)\ny = train_df['Loan_Status']","ac24e6a3":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","d097b3cd":"from mlxtend.feature_selection import SequentialFeatureSelector as SFS\nfrom sklearn.ensemble import RandomForestClassifier","23f73a70":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","936436b4":"X_train.shape","ffb12b0b":"#X_train = scaler.fit_transform(X_train)\n#X_test = scaler.transform(X_test)","3696f62c":"#Feature selection through Forward Step\nsfs = SFS(RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n          k_features=10, \n          forward=False,\n          floating= False,\n          verbose = 2,\n          scoring='accuracy',\n          cv=4,\n          n_jobs=-1\n         \n         ).fit(X_train, y_train)","22fde399":"#These features will give us 82% Accuracy but not suing Loan Amount for loan eligibility wouldn't be correct predictions\nsfs.k_feature_names_","3216f8b2":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV","4758da46":"#Number of trees in RF\nn_estimators = [15, 20, 30, 50, 75, 100, 200, 300, 400]\n#Number of features to consider at each split\nmax_features = ['auto', 'sqrt']\n#maximum number of level in the tree\nmax_depth =[1,2,4]\n#Selecting samples for each tree\nbootstrap = [True, False]\n#Minimum number of samples required at each node\nmin_samples_leaf = [1,2,3]\n#Splitting with either entropy or gini\ncriterion=['gini','entropy']\n\nparam_grid ={'n_estimators':n_estimators,\n             'max_features':max_features,\n             'max_depth':max_depth,\n             'min_samples_leaf':min_samples_leaf,\n             'bootstrap':bootstrap,\n             'criterion':criterion}\n\n\nRF = RandomForestClassifier(oob_score=True, warm_start=True, n_jobs=-1)\n\nGRF = GridSearchCV(estimator=RF,\n    param_grid=param_grid,\n    scoring=None,\n    n_jobs=-1,\n    cv=4)\nGRF.fit(X_train,y_train)\npredGRF = GRF.predict(X_test)","45816464":"GRF.best_params_","3bddffe2":"from sklearn.metrics import classification_report, confusion_matrix\n\nprint(classification_report(y_test, predGRF))","db5d94f5":"from sklearn.tree import DecisionTreeClassifier\nDT = DecisionTreeClassifier().fit(X_train,y_train)\n\nparams_grid = {'max_depth':range(1, DT.tree_.max_depth+1, 2),\n               'max_features':range(1,len(DT.feature_importances_)+1)\n              }\n\nDT_GV = GridSearchCV(DecisionTreeClassifier(random_state=101),\n                   param_grid=params_grid,\n                   scoring='accuracy',\n                   n_jobs=-1)\n\nDT_GV = DT_GV.fit(X_train,y_train)\ny_predDT = DT_GV.predict(X_test)\nDT_GV.best_estimator_","f33aa63d":"Feature_importance = pd.Series(DT.feature_importances_, index=[x for x in X]).sort_values(ascending=False)\nbar = Feature_importance.plot(kind='bar', figsize=(18,10))\nbar.set(xlabel='Features')\nbar.set(ylabel='Relative_Importance')","2b730078":"from sklearn.linear_model import LogisticRegression\n\nL2 = LogisticRegression()\nL2 = L2.fit(X_train,y_train)\n\ny_predl2 = L2.predict(X_test)\n\nprint(classification_report(y_test,y_predl2))","75f0f1bb":"from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nparameters = {'learning_rate': [ 2, 1, 0.5, 0.2, 0.1, 0.01, 0.001], \n              #'subsample':[1.0, 0.5,0.2], \n              #'max_features':[4, 5, 10, 12, 19],\n              'n_estimators':[15, 20, 30, 40, 80, 100, 200, 400,500]\n              \n             }\n\nAB = GridSearchCV(AdaBoostClassifier(), param_grid=parameters, scoring='accuracy', n_jobs=-1)\nAB = AB.fit(X_train,y_train)\ny_predAB = AB.predict(X_test)\n\nAB.best_params_","b082b8ea":"from sklearn.ensemble import VotingClassifier\n\nclassifiers = [('GRF', GRF),('AB', AB), ('L2', L2), ('DT_GV', DT_GV) ]\n\nVC = VotingClassifier(classifiers,voting='soft')\n\nVC = VC.fit(X_train,y_train)\ny_predvc = VC.predict(X_test)\n\nprint(classification_report(y_test,y_predvc))\ny_prob = VC.predict_proba(X_test)","4a12213f":"from sklearn.metrics import roc_curve, precision_recall_curve, confusion_matrix\n\nsns.set_context()\ncm = confusion_matrix(y_test,y_predvc)\n_,ax = plt.subplots(figsize=(18,8))\nax = sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm', annot_kws={\"size\":40, \"weight\":\"bold\"})\n\nlabels =['Yes', \"No\"]\nax.set_xticklabels(labels, fontsize=20);\nax.set_yticklabels(labels, fontsize=20);\nax.set_ylabel(\"Ground Truth\", fontsize=20);\nax.set_xlabel(\"prediction\", fontsize=20)\nplt.ylim(2,0)","9c5be694":"sns.set_context(\"talk\")\n\nfig, axList = plt.subplots(ncols=2)\nfig.set_size_inches(16,8)\n\n#plotting roc auc curve\nax = axList[0]\n\nfpr,tpr, thresholds = roc_curve(y_test,y_prob[:,1])\nax.plot(fpr, tpr, color=\"green\", linewidth=5)\n\nax.plot([0,1],[0,1], ls='--', color=\"black\",lw=3)\nax.set(xlabel='False Positive Rate',\n       ylabel =\"True Positive Rate\",\n       xlim = [-.01,1.01], ylim = [-.01,1.01],\n       title =\"ROC Curve\")\nax.grid(True)\n\nax = axList[1]\nprecision, recall, _ = precision_recall_curve(y_test,y_prob[:,1])\nax.plot(recall, precision, color='blue', lw=5)\nax.set(xlabel='Recall',\n       ylabel =\"Precision\",\n       xlim = [-.01,1.01], ylim = [-.01,1.01],\n       title =\"Precision Recall Curve\")\nax.grid(True)","0ae0d1a3":"#  Logistic Regression","d38ca684":"# Filling Missing Values with Visualatization and EDA","0b1508f3":"# ","1c67d885":"# Voting Classifier\/Stacking ","cf39db59":"# Building Models","0523ceae":"# Converting Categorical Variables\/Strings to Integer","ad447e89":"# Adaboost","2e2ea092":"# RandomForest ","baf98e2d":"# Decision Tree and Feature Importance"}}