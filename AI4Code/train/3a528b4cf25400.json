{"cell_type":{"5b9df695":"code","f91ba092":"code","7251aac9":"code","3e06696a":"code","c20668af":"code","4d3607be":"code","d3a8c2d3":"code","929f8b58":"code","50580367":"code","3ae219cf":"code","5b904c3b":"code","fe81d847":"code","86081fdc":"code","526c4cee":"code","def8a2b9":"code","b8ecf98f":"code","cb0fa031":"code","82c0d0f8":"code","36c662d7":"code","ce87a0b6":"code","6b407313":"code","d763acf2":"code","84d642fc":"code","ce2d044d":"markdown"},"source":{"5b9df695":"import pandas as pd\nimport re\nimport nltk # natural language tool kit\nnltk.download(\"stopwords\")      # corpus diye bir kalsore indiriliyor\nfrom nltk.corpus import stopwords  # sonra ben corpus klasorunden import ediyorum\n\nimport nltk as nlp\nlemma = nlp.WordNetLemmatizer()\n\nimport matplotlib\n%matplotlib inline  \nmatplotlib.get_backend()\n\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()","f91ba092":"# Module\nimport numpy as np \nimport pandas as pd\nimport random\nimport time\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_fscore_support\nimport matplotlib.pyplot as plt\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn import svm\nfrom sklearn import tree\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom scipy.stats import multivariate_normal as mvn\nfrom sklearn.mixture import GaussianMixture\nimport scipy as sp\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\nimport math\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.combine import SMOTEENN\nfrom imblearn.under_sampling import EditedNearestNeighbours\nfrom imblearn.under_sampling import NeighbourhoodCleaningRule\nfrom sklearn.naive_bayes import GaussianNB\nfrom imblearn.under_sampling import TomekLinks\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import make_scorer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom nltk.corpus import stopwords\nfrom sklearn.model_selection import cross_val_score\nimport re\nimport string\nimport collections\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport nltk\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")","7251aac9":"# %% import twitter data\ndf = pd.read_csv(\"\/kaggle\/input\/twitter-user-gender-classification\/gender-classifier-DFE-791531.csv\",encoding = \"latin1\")\ndf_male = df[df[\"gender\"] == \"male\"]\ndf_female = df[df[\"gender\"] == \"female\"]\ndf = pd.concat([df_male,df_female])","3e06696a":"def cleaning(s):\n    s = str(s)\n    s = s.lower()\n    s = re.sub('\\s\\W',' ',s)\n    s = re.sub('\\W,\\s',' ',s)\n    s = re.sub(r'[^\\w]', ' ', s)\n    s = re.sub(\"\\d+\", \"\", s)\n    s = re.sub('\\s+',' ',s)\n    s = re.sub('[!@#$_]', '', s)\n    s = s.replace(\"co\",\"\")\n    s = s.replace(\"https\",\"\")\n    s = s.replace(\",\",\"\")\n    s = s.replace(\"[\\w*\",\" \")\n    return s\n\ndf['Tweets'] = [cleaning(s) for s in df['text']]\ndf['Description'] = [cleaning(s) for s in df['description']]\n\nfrom nltk.corpus import stopwords\nstop = set(stopwords.words('english'))\ndf['Tweets'] = df['Tweets'].str.lower().str.split()\ndf['Tweets'] = df['Tweets'].apply(lambda x : [item for item in x if item not in stop])","c20668af":"for i in range(df.shape[1]):\n    df[df.columns[i]] = [cleaning(s) for s in df[df.columns[i]]]","4d3607be":"df = df[df[\"tweet_location\"]!=\"nan\"]","d3a8c2d3":"df[\"tweet_location\"].value_counts()","929f8b58":"df[\"tweet_location\"].str.contains(\"uk\")","50580367":"df[\"tweet_location\"].replace(\"london\",\"uk\")","3ae219cf":"df.gender.value_counts()\nmale = df[df['gender'] == 'male']\nfemale = df[df['gender'] == 'female']\nmale_words = pd.Series(' '.join(male['Tweets'].astype(str)).lower().split(\" \")).value_counts()[:20]\nfemale_words = pd.Series(' '.join(female['Tweets'].astype(str)).lower().split(\" \")).value_counts()[:20]\nmale_words = male_words.iloc[1:]\nfemale_words = female_words.iloc[1:]","5b904c3b":"fig = plt.figure()\nfig.patch.set_facecolor('white')\n#plt.style.use(['white_background'])\nplt.title(\"Female Tweet Word Count\")\nplt.xlabel(\"Tweet Word\")\nplt.ylabel(\"Count\")\nfemale_words.plot.bar(color=\"salmon\")","fe81d847":"fig = plt.figure()\nfig.patch.set_facecolor('white')\n#plt.style.use(['dark_background'])\nplt.title(\"male Tweet Word Count\")\nplt.xlabel(\"Tweet Word\")\nplt.ylabel(\"Count\")\nmale_words.plot.bar(color=\"mediumturquoise\")","86081fdc":"import collections\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS","526c4cee":"Vectorize = TfidfVectorizer(stop_words='english', token_pattern=r'\\w{1,}', max_features=35000)\nX = Vectorize.fit_transform(df[\"Description\"])\ny = df.gender \nle = preprocessing.LabelEncoder()\ny = le.fit_transform(y.values)","def8a2b9":"#split dataset \ntrain_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)","b8ecf98f":"models = []\nmodels.append((\"k Nearest Neighbor\",KNeighborsClassifier(n_neighbors=5)))\nmodels.append((\"Decision Tree\",tree.DecisionTreeClassifier()))\nmodels.append((\"Random Forest\",RandomForestClassifier(n_estimators=100, max_depth=2)))\nmodels.append((\"Logistic Regression\",LogisticRegression()))\nmodels.append((\"Naive Bayes\",MultinomialNB()))","cb0fa031":"def cross_validate_evaluate(algorithm):\n    \n    # Build model\n    clf = algorithm\n    # Not Need\n    def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n    def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n    def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n    def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]\n    scoring = {'tp': make_scorer(tp), 'tn': make_scorer(tn),\n               'fp': make_scorer(fp), 'fn': make_scorer(fn)}\n    \n    # Stratified k-Fold \n    skf = StratifiedKFold(n_splits=10, shuffle=True)\n    # Evaluation Indicator\n    score_funcs = [\n        'accuracy',\n        'precision',\n        'recall',\n        'f1',\n    ]\n    # Cross Validation \n    scores = cross_validate(clf, X, y, cv=skf, scoring=score_funcs)\n    print('accuracy:', scores['test_accuracy'].mean())\n    print('precision:', scores['test_precision'].mean())\n    print('recall:', scores['test_recall'].mean())\n    print('f1:', scores['test_f1'].mean())\n    \n    #return scores\n\n#if __name__ == '__main__':\n#    main()\nmodels_index=0\nname_index=1\nfor models_index in range(len(models)):\n    print(\"-----------\"+str(models[models_index][name_index-1])+\"-----------\")\n    cross_validate_evaluate(models[models_index][name_index])","82c0d0f8":"def rmse_cv(model):\n    rmse= np.sqrt(-cross_val_score(model, train_X, train_y, scoring=\"neg_mean_squared_error\", cv = 5))\n    return(rmse)","36c662d7":"###Model Lasso regression\nmodel_lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005]).fit(train_X, train_y)\nrmse_cv(model_lasso).mean()","ce87a0b6":"index_list = []\nfor i in range(len(model_lasso.coef_)):\n    index_list.append(i)","6b407313":"coef_dict = dict(zip(index_list,model_lasso.coef_))","d763acf2":"tfidf_name = Vectorize.get_feature_names()\nfor i in range(len(coef_dict)):\n    if coef_dict.get(i) > abs(0):\n        print(tfidf_name[i] + \" : \" + str(coef_dict[i]))\n        Vectorize.get_feature_names()","84d642fc":"print(model_lasso.intercept_)","ce2d044d":"# Gender"}}