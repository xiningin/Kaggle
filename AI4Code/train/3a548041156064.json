{"cell_type":{"09ff46ef":"code","fd5a645a":"code","8b1c5ee4":"code","f7eb3b11":"code","6ba95005":"code","872d19df":"code","5bdd9d2d":"code","e75149d4":"code","91102e78":"code","e0602d38":"code","3980d3fe":"code","b55dcf52":"code","f8d66ef1":"code","6500c850":"code","29fffa6b":"code","557c8883":"markdown","d3226443":"markdown","090dc440":"markdown","aef8b92b":"markdown"},"source":{"09ff46ef":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fd5a645a":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings","8b1c5ee4":"train_data = pd.DataFrame (pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\"))\ntest_data = pd.DataFrame (pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\"))\ngender_submission = pd.DataFrame(pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\"))\n\nprint( \"\\033[1m\" + \"train_data shape :\" , train_data.shape)\nprint(\"test_data shape : \", test_data.shape)\nprint(\"gender submission shape: \", gender_submission.shape)","f7eb3b11":"print (\"\\033[1m\" , train_data.dtypes)","6ba95005":"print( \"\\033[1m\" + f'Number of rows: {train_data.shape[0]};  Number of columns: {train_data.shape[1]}; No of missing values: {sum(train_data.isna().sum())}')","872d19df":"for col, i in enumerate(train_data):\n    print( \"\\033[1m\" + f'{train_data.columns[col]} has {train_data[i].isna().sum()} missing values')","5bdd9d2d":"for col, i in enumerate(test_data):\n    print( \"\\033[1m\" + f'{test_data.columns[col]} has {test_data[i].isna().sum()} missing values')","e75149d4":"train_data.corr()","91102e78":"reduce_train_data = train_data.copy()\nreduce_train_data[\"Embarked\"].value_counts()","e0602d38":"#removing certain columns and cleaning the data\n\ndef cleaned_data(data):\n    cats = [\"Embarked\"]\n    reduce_train_data = data.drop ([\"Name\", \"Cabin\", \"Ticket\"], axis=1)\n    reduce_train_data[\"Sex\"] = reduce_train_data[\"Sex\"].replace(['female','male'], [0,1])\n    reduce_train_data[\"Age\"].replace(np.NaN, round (reduce_train_data[\"Age\"].mean()), inplace =True)\n    reduce_train_data[\"Embarked\"].replace(np.NaN, \"S\", inplace= True)\n    reduce_train_data[\"Fare\"].replace(np.NaN, reduce_train_data[\"Fare\"].mean(), inplace = True)\n    reduce_train_data =  pd.get_dummies(reduce_train_data, columns = cats) \n    return reduce_train_data\n","3980d3fe":"featured_train_data = cleaned_data(train_data)\nfeatured_test_data = cleaned_data(test_data)\n","b55dcf52":"featured_train_data.corr().T\nsns.heatmap(featured_train_data.corr(), \n        xticklabels=featured_train_data.corr().columns,\n        yticklabels=featured_train_data.corr().columns)","f8d66ef1":"featured_train_data[\"Survived\"].value_counts()","6500c850":"X = featured_train_data.drop(\"Survived\", axis =1)\ny = featured_train_data[\"Survived\"]\n\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test , y_train, y_test = train_test_split(X,y, stratify = y, test_size = 0.2)\n\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrforest = RandomForestClassifier(n_estimators= 2000, max_leaf_nodes= 10,  max_features= 2 , min_samples_leaf= 5, random_state=42)\n\nrforest.fit(X_train,y_train)\n\ny_pred = rforest.predict(X_test)\n\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n\nprint(accuracy_score( y_test, y_pred))\n\nprint (classification_report(y_test, y_pred))\n\n\nmatrix = confusion_matrix(y_test, y_pred)\nmatrix = matrix.astype('float') \/ matrix.sum(axis=1)[:, np.newaxis]\n\n# Build the plot\nplt.figure(figsize=(16,7))\nsns.set(font_scale=1.4)\nsns.heatmap(matrix, annot=True, annot_kws={'size':10},\n            cmap=plt.cm.Greens, linewidths=0.2)\n","29fffa6b":"predictions = rforest.predict(featured_test_data)\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","557c8883":"### Reading the data","d3226443":"### Cleaning the data","090dc440":"### Importing libraries","aef8b92b":"Looks like parch, fare , embarked_c and embarked_Q have good impact on the survived rate"}}