{"cell_type":{"09fa9410":"code","178b0135":"code","22dc7e33":"code","43c99403":"code","22293fda":"code","41c14bb7":"code","05e055c7":"code","c7b0fb85":"code","438cbba0":"code","a7327bd9":"code","98d451fd":"code","b15014b6":"code","c6b0e7b5":"code","495a7bc9":"code","2c4ce761":"code","3b164bcb":"code","d263f6a9":"code","2fecb970":"code","0286f387":"code","e19e5f4e":"code","cb0d7776":"code","cb16a63b":"code","62281a37":"code","eb3de8cf":"code","9f8c862c":"code","0bd1bc62":"code","cfddd28d":"code","c98e6f1e":"code","17dc366e":"code","7e7ed74c":"code","0f090eae":"code","b42b2452":"code","a74e4144":"code","42616b15":"code","e2d05507":"code","d1cd56d5":"code","744482b8":"code","f54d11bd":"code","c5db6f76":"code","683886b6":"code","99689fb1":"code","3c06a01d":"code","14f21c17":"code","81ff09ed":"code","582800d4":"code","86565889":"code","ea4ec081":"code","0c1df955":"code","fd8a1445":"code","bcf30f0b":"markdown","e977313b":"markdown","9e6196e0":"markdown","29c0a603":"markdown","b0460b8a":"markdown","76f586a1":"markdown","7d853f9d":"markdown","a0e1691a":"markdown","e3b5aeb3":"markdown","3fd628a3":"markdown","1bb6222f":"markdown"},"source":{"09fa9410":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","178b0135":"train=pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntrain.head()","22dc7e33":"train.shape","43c99403":"df = train.copy()","22293fda":"testo =test.copy()","41c14bb7":"df.drop(columns=['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\ntest.drop(columns=['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)","05e055c7":"df.info()","c7b0fb85":"df.describe()","438cbba0":"df.isnull().sum()","a7327bd9":"df","98d451fd":"df['Age'].fillna(df['Age'].median(), inplace=True)\ndf['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n","b15014b6":"test['Age'].fillna(df['Age'].median(), inplace=True)\ntest['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)","c6b0e7b5":"df.isnull().sum()","495a7bc9":"df","2c4ce761":"# Since 'Fare' is mainly related to 'Pclass', we should check which class this person belongs to.\ndf[df.Fare.isnull()]\n","3b164bcb":"# It's a passenger from Pclass 3, so we'll fill the missing value with the median fare of Pclass 3.\ndf.Fare.fillna(df[df.Pclass==3]['Fare'].median(),inplace=True)\ntest.Fare.fillna(df[df.Pclass==3]['Fare'].median(),inplace=True)","d263f6a9":"df.isnull().sum()","2fecb970":"test.isnull().sum()","0286f387":"print('Duplicated data =',df.duplicated() .sum())","e19e5f4e":"df.head()","cb0d7776":"def barplot(variable):\n    \"\"\"\n    input: variable ex: \"Sex\"\n    output: bar plot & value count\n    \"\"\"\n    #get feature\n    var = df[variable]\n    #count number of categorical variable(value\/sample)\n    varValue = var.value_counts()\n    \n    #visualize\n    plt.figure(figsize = (9,3))\n    plt.bar(varValue.index,varValue) #x = 0 or 1 y = varValue\n    plt.xticks(varValue.index,varValue.index.values)\n    plt.ylabel('Frequency')\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}:\".format(variable,varValue))","cb16a63b":"category1 = ['Survived','Sex','Pclass','Embarked','SibSp','Parch']\nfor c in category1:\n    barplot(c)","62281a37":"category1 = ['Sex','Pclass','Embarked','SibSp','Parch']\n\nfor col in category1:\n    plt.figure()\n    sns.countplot(x='Survived', hue=col, data= df)","eb3de8cf":"# Pclass vs Survived\ndf[['Pclass','Survived']].groupby(['Pclass'],as_index = False).mean().sort_values(by = 'Survived', ascending = False)","9f8c862c":"# Sex vs Survived\ndf[['Sex','Survived']].groupby(['Sex'],as_index = False).mean()","0bd1bc62":"df[['SibSp','Survived']].groupby(['SibSp']).mean()","cfddd28d":"#Parch vs Survived\ndf[['Parch','Survived']].groupby(['Parch']).mean()","c98e6f1e":"df.plot(kind='box')","17dc366e":"cols= ['Age', 'SibSp', 'Parch', 'Fare']\n\ndf[cols]= df[cols].clip(lower= df[cols].quantile(0.15), upper= df[cols].quantile(0.85), axis=1)\n\ndf.drop(columns=['Parch'], axis=1, inplace=True)\ntest.drop(columns=['Parch'], axis=1, inplace=True)\n\ndf.plot(kind='box', figsize= (10,8)) \n# no outliers ","7e7ed74c":"df","0f090eae":"test","b42b2452":"from sklearn import preprocessing\nLabelEncoder = preprocessing.LabelEncoder()\ndf['Embarked'] = LabelEncoder.fit_transform(df['Embarked'])\ntest['Embarked'] = LabelEncoder.transform(test['Embarked'])\ndf['Sex'] = LabelEncoder.fit_transform(df['Sex'])\ntest['Sex'] = LabelEncoder.fit_transform(test['Sex'])\ny = df['Survived']\nX = df.drop(['Survived'],axis=1)","a74e4144":"y","42616b15":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)","e2d05507":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\ntest = scaler.fit_transform(test)","d1cd56d5":"import itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nplt.rcParams[\"font.family\"] = 'DejaVu Sans'\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","744482b8":"from datetime import datetime\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\ndef perform_model(model, X_train, y_train, X_test, y_test, class_labels, cm_normalize=True, \\\n                 print_cm=True, cm_cmap=plt.cm.Greens):\n    \n    \n    # to store results at various phases\n    results = dict()\n    \n    # time at which model starts training \n    train_start_time = datetime.now()\n    print('training the model..')\n    model.fit(X_train, y_train)\n    print('Done \\n \\n')\n    train_end_time = datetime.now()\n    results['training_time'] =  train_end_time - train_start_time\n    print('training_time(HH:MM:SS.ms) - {}\\n\\n'.format(results['training_time']))\n    \n    \n    # predict test data\n    print('Predicting test data')\n    test_start_time = datetime.now()\n    y_pred = model.predict(X_test)\n    test_end_time = datetime.now()\n    print('Done \\n \\n')\n    results['testing_time'] = test_end_time - test_start_time\n    print('testing time(HH:MM:SS:ms) - {}\\n\\n'.format(results['testing_time']))\n    results['predicted'] = y_pred\n   \n\n    # calculate overall accuracty of the model\n    accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n    # store accuracy in results\n    results['accuracy'] = accuracy\n    print('---------------------')\n    print('|      Accuracy      |')\n    print('---------------------')\n    print('\\n    {}\\n\\n'.format(accuracy))\n    \n    \n    # confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    results['confusion_matrix'] = cm\n    if print_cm: \n        print('--------------------')\n        print('| Confusion Matrix |')\n        print('--------------------')\n        print('\\n {}'.format(cm))\n        \n    # plot confusin matrix\n    plt.figure(figsize=(4,4))\n    plt.grid(b=False)\n    plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix', cmap = cm_cmap)\n    plt.show()\n    \n    # get classification report\n    print('-------------------------')\n    print('| Classifiction Report |')\n    print('-------------------------')\n    classification_Report = classification_report(y_test, y_pred)\n    # store report in results\n    results['classification_Report'] = classification_Report\n    print(classification_Report)\n    \n    # add the trained  model to the results\n    results['model'] = model\n    \n    return results\n    \n    ","f54d11bd":"def print_grid_search_attributes(model):\n    # Estimator that gave highest score among all the estimators formed in GridSearch\n    print('--------------------------')\n    print('|      Best Estimator     |')\n    print('--------------------------')\n    print('\\n\\t{}\\n'.format(model.best_estimator_))\n\n\n    # parameters that gave best results while performing grid search\n    print('--------------------------')\n    print('|     Best parameters     |')\n    print('--------------------------')\n    print('\\tParameters of best estimator : \\n\\n\\t{}\\n'.format(model.best_params_))\n\n\n    #  number of cross validation splits\n    print('---------------------------------')\n    print('|   No of CrossValidation sets   |')\n    print('--------------------------------')\n    print('\\n\\tTotal numbre of cross validation sets: {}\\n'.format(model.n_splits_))\n\n\n    # Average cross validated score of the best estimator, from the Grid Search \n    print('--------------------------')\n    print('|        Best Score       |')\n    print('--------------------------')\n    print('\\n\\tAverage Cross Validate scores of best estimator : \\n\\n\\t{}\\n'.format(model.best_score_))","c5db6f76":"labels = ['0','1']","683886b6":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nparameters = {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}\nlogreg=LogisticRegression()\nlr_grid = GridSearchCV(logreg,param_grid=parameters, n_jobs=-1)\nlr_grid_results = perform_model(lr_grid, X_train, y_train, X_test, y_test, class_labels=labels)\nprint_grid_search_attributes(lr_grid_results['model'])","99689fb1":"from sklearn.tree import DecisionTreeClassifier\nparameters = {'max_depth':np.arange(3,10,2)}\ndt = DecisionTreeClassifier()\ndt_grid = GridSearchCV(dt,param_grid=parameters, n_jobs=-1)\ndt_grid_results = perform_model(dt_grid, X_train, y_train, X_test, y_test, class_labels=labels)\nprint_grid_search_attributes(dt_grid_results['model'])","3c06a01d":"from sklearn.ensemble import RandomForestClassifier\n\nn_estimators = [10, 100, 500, 1000, 2000]\nmax_depth = [5, 10, 20]\nparameters = dict(n_estimators=n_estimators, max_depth=max_depth)\nrf = RandomForestClassifier(random_state=42)\nrf_grid = GridSearchCV(rf,param_grid=parameters, n_jobs=-1)\nrf_grid_results = perform_model(rf_grid, X_train, y_train, X_test, y_test, class_labels=labels)\nprint_grid_search_attributes(rf_grid_results['model'])","14f21c17":"model_rf_final = RandomForestClassifier(max_depth= 5, n_estimators= 500)\nmodel_rf_final.fit(X_train, y_train)","81ff09ed":"test","582800d4":"test_pred = pd.Series(model_rf_final.predict(test), name = \"Survived\")\ntest_pred_final = pd.DataFrame(test_pred)","86565889":"test_pred_final.head()\n","ea4ec081":"df_gender_submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\n","0c1df955":"submission = pd.DataFrame({\n        \"PassengerId\": testo[\"PassengerId\"],\n        \"Survived\": test_pred_final['Survived']\n    })\nsubmission.to_csv('Titanic Submission.csv', index = False)\n\nprint('Done')","fd8a1445":"submission","bcf30f0b":"## Droping useless columns","e977313b":"People who take in class one are much more likely to survive\n","9e6196e0":"# Handling Outliers","29c0a603":"## Univariate Analysis\n","b0460b8a":"### Splitting data","76f586a1":"### The 'Age', 'Cabin', 'Embarked', 'Fare' columns have missing values\n","7d853f9d":"## Basic Data Analysis\n","a0e1691a":"Female Survival Rate is more","e3b5aeb3":"### Label encoding the categorical data","3fd628a3":"## Load Titanic Dataset","1bb6222f":"# Handling missing values"}}