{"cell_type":{"134e2696":"code","76d3b575":"code","d6350e06":"code","7af87b74":"code","8ad54596":"code","db29851c":"code","294b8ccd":"code","9a6f8973":"code","10b239c9":"code","4719bdb4":"code","33046eab":"code","6fa41f4b":"code","c37092c2":"code","284e900b":"code","d95c87e5":"code","b03d3606":"code","5f5f1414":"code","938aca8e":"code","67aae7fa":"code","9275cc82":"code","59312b55":"code","060fd89f":"code","baffc3cd":"code","6e3407dc":"markdown","2d9a07c9":"markdown","e0627f26":"markdown","2eff1689":"markdown","a717f3af":"markdown","c515142f":"markdown","b971f8e2":"markdown","47427e2e":"markdown","740fc4b5":"markdown","cedcaece":"markdown","6d4d5d78":"markdown"},"source":{"134e2696":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pathlib import Path\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","76d3b575":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport seaborn as sns\nfrom xgboost import XGBRegressor\n\ninput_path = Path('\/kaggle\/input\/tabular-playground-series-jan-2021\/')","d6350e06":"train = pd.read_csv(input_path \/ 'train.csv', index_col='id')\ndisplay(train.head())","7af87b74":"test = pd.read_csv(input_path \/ 'test.csv', index_col='id')\ndisplay(test.head())","8ad54596":"submission = pd.read_csv(input_path \/ 'sample_submission.csv', index_col='id')\ndisplay(submission.head())","db29851c":"desc=train.apply(pd.DataFrame.describe)\ndesc","294b8ccd":"features = [f'cont{x}'for x in range(1,15)]\ndata= train[features]\ntrain.isnull().sum()","9a6f8973":"#setting up the platform\nsns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\n\nsns.distplot(train['target'], color=\"g\")\nax.xaxis.grid(False)\nax.set(ylabel=\"Values\")\nax.set(xlabel=\"Target\")\nax.set(title=\"Target distribution\")\nsns.despine(trim=True, left=True)\nplt.show()","10b239c9":"i = 1\nplt.figure()\nfig, ax = plt.subplots(5, 3,figsize=(14, 24))\nfor feature in features:\n    plt.subplot(5, 3,i)\n    sns.distplot(train[feature],color=\"blue\", kde=True,bins=120, label='train')\n    sns.distplot(test[feature],color=\"red\", kde=True,bins=120, label='test')\n    plt.xlabel(feature, fontsize=9); plt.legend()\n    i += 1\nplt.show()","4719bdb4":"i = 1\nplt.figure()\nfig, ax = plt.subplots(5, 3,figsize=(14, 24))\nfor feature in features:\n    plt.subplot(5, 3,i)\n    sns.scatterplot(x=train[feature],y = train['target'],color=\"blue\", label='train')\n    plt.xlabel(feature, fontsize=9); plt.legend()\n    i += 1\nplt.show()","33046eab":"train[train['target'] == 0]","6fa41f4b":"for col in train.columns[:-1]:\n    plt.boxplot([train[feature], test[feature]], labels=['train', 'test'])\n    plt.title(col)\n    plt.legend()\n    plt.show()\n    sns.set()","c37092c2":"def replace_outliers(data):\n    for col in data.columns:\n        Q1 = data[col].quantile(0.25)\n        Q3 = data[col].quantile(0.75)\n        IQR = Q3 - Q1\n        median_ = data[col].median()\n        data.loc[((data[col] < Q1 - 1.5*IQR) | (data[col] > Q3 + 1.5*IQR)), col] = median_\n    return data","284e900b":"train = replace_outliers(train)","d95c87e5":"corr = train.corr()\nplt.subplots(figsize=(15,12))\nsns.heatmap(corr, vmax=0.9, cmap=\"YlGnBu\", square=True)","b03d3606":"corr_feature = ['cont6','cont7','cont8','cont9','cont10','cont11','cont12','cont13']\ncorr_in = train[corr_feature]","5f5f1414":"corr = corr_in.corr()\nplt.subplots(figsize=(15,12))\nsns.heatmap(corr, vmax=0.9, cmap=\"YlGnBu\", square=True)","938aca8e":"train_data = ( train - train.mean())\/train.std()\ntest_data = ( test - test.mean())\/test.std()","67aae7fa":"train = train.drop(284103)","9275cc82":"target = train.pop('target')\nX_train, X_test, y_train, y_test = train_test_split(train, target, train_size=0.60)","59312b55":"#parameters used from another kaggle notebook \nmodel = XGBRegressor(n_estimators=500, learning_rate=0.05, n_jobs=4)\nmodel.fit(X_train, y_train, \n             early_stopping_rounds=5, \n             eval_set=[(X_test, y_test)],\n             verbose=False)","060fd89f":"y_pred = model.predict(X_test)\nscore  = mean_squared_error(y_test, y_pred, squared=False)\nprint(score)","baffc3cd":"submission['target'] = model.predict(test)\nsubmission.to_csv('xgb_regressor.csv')","6e3407dc":"CHECKING NULL VALUE","2d9a07c9":"Strong Correlation b\/w corr_feature","e0627f26":"Imports","2eff1689":"Finding target With 0 value","a717f3af":"Removing Outliner with IQR","c515142f":"**PLOTING**","b971f8e2":"# EDA","47427e2e":"Dropping feild with target value 0","740fc4b5":"Scatter Plot for Better Understanding","cedcaece":"using XGBRegressor","6d4d5d78":"## Target Distribution"}}