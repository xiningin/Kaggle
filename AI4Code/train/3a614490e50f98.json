{"cell_type":{"194356ed":"code","b97085ac":"code","7fd3d23c":"code","1380c09a":"code","b8ca97e7":"code","9edc9272":"code","806b8526":"markdown","85314a53":"markdown","9af293a5":"markdown","6afe01e3":"markdown","53c0ca96":"markdown","5c2544c5":"markdown","d5646e7b":"markdown","9183b705":"markdown","0c45a11e":"markdown","1539cf34":"markdown","721fba9a":"markdown"},"source":{"194356ed":"import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\ndf = pd.read_csv('..\/input\/nihcsv\/nih.csv')\nprint(df.shape)\ndf.head(10)\n# class2 is the label given in NIH dataset (and imageIndex is filename of the image)","b97085ac":"import os\nprint(os.listdir('..\/input\/nihcsv'))\n\ntest = pd.read_csv('..\/input\/nihcsv\/nih_for_test1_images.csv')\nprint(test.shape)\ntest.head(10)","7fd3d23c":"df[df.class1 == 'Normal'].class2.value_counts().to_frame().head(10).plot.bar()","1380c09a":"df[df.class1 == 'Lung Opacity'].class2.value_counts().to_frame().head(10).plot.bar()","b8ca97e7":"df[df.class1 == 'No Lung Opacity \/ Not Normal'].class2.value_counts().to_frame().head(10).plot.bar()","9edc9272":"for class2, count2 in df.class2.value_counts().items():\n\n    if count2 < 100: # ignore small count\n        continue\n\n    print('\\n----- %s -----' % class2)\n\n    _df = df[df.class2 == class2].class1\n    for class1, count1 in _df.value_counts().items():\n        ratio = count1 \/ _df.count()\n        print('%d (%.2f%%) %s' % (count1, ratio * 100, class1))","806b8526":"## Guessing a reason for label inconsistency between this competition and NIH.\n\nI'm not a specialist in this field and I can not say much about the variance among specialists's decisions.\n\nI guess one of the reason is the fact how NIH label is created. https:\/\/arxiv.org\/pdf\/1705.02315.pdf\nNIH label is generated by NLP technique and it might not be as solid as the label in this competition.\n","85314a53":"#### for stage1 test images","9af293a5":"#### for train images","6afe01e3":"I calculated the pixel diffs between competition's dataset images and NIH images. A image pair with the minimum diff is treated as the same image. \n\nI manually checked hundreds of image pairs and they were all correct.\n\nAfter finding out the original NIH images, I put all labels of this competition and NIH into the dataframe, nih.csv.","53c0ca96":"## NIH dataset\n\nLink to the dataset: https:\/\/nihcc.app.box.com\/v\/ChestXray-NIHCC\n\nNIH labels: https:\/\/nihcc.app.box.com\/v\/ChestXray-NIHCC\/file\/219760887468","5c2544c5":"## Update\n\nAs there is a request to add this for stage1 test images, I've uploaded a new csv 'nih_for_test1_images.csv'.\n\n- nih.csv: for train images\n- nih_for_test1_images.csv: for stage1 test images\n\nOn this competition, you may use NIH label for training your model, but I not sure you can use NIH label for testing. Please check the disussion about external data https:\/\/www.kaggle.com\/c\/rsna-pneumonia-detection-challenge\/discussion\/64345","d5646e7b":"## Dataframe to associate patientId to original NIH image and its label","9183b705":"The dataset for this competition is a subset of NIH dataset. \n\nIt might be useful to use labels provided by NIH to train the model.\n\nI share the list which associates train images to original NIH images so that you can make use of NIH labels. The list is obtrained by calculating the diffs among images.","0c45a11e":"## NIH label for 'Lung Opacity' class\n\nI was expecting most images are labeled as 'Infiltration' at NIH and that was somewhat correct.","1539cf34":"## NIH label for 'No Lung Opacity \/ Not Normal' class\n\nA bit surprising to know there are many images labeled as 'No Finding' at NIH.","721fba9a":"## NIH label for 'Normal' class\n\nThere are some images labeled 'Nodule' or 'Atelectasis' at NIH but labeled as 'Normal' in this competition. I'm a bit surprised to know there are lots of images with Infiltration at NIH but treated at 'Normal' here."}}