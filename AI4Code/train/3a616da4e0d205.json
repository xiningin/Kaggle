{"cell_type":{"c2188e16":"code","1f34f85a":"code","8fa1f147":"code","8ba1fcc9":"code","7bc0ca17":"code","20c05b0c":"code","9658b370":"code","8e1c1370":"code","f644b50a":"code","4ab3e91a":"code","af441228":"code","e5eedd96":"code","0cb16129":"code","8843b84d":"code","66cb245a":"code","d07cea62":"code","f6be54e5":"code","69593c1b":"code","f69841ce":"code","51d5b436":"markdown","400d5338":"markdown","d4462aa1":"markdown","c031fcc7":"markdown","e119b647":"markdown","027f20b2":"markdown"},"source":{"c2188e16":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\nimport plotly\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport cufflinks as cf\ncf.set_config_file(offline=True)\n\nimport lightgbm as lgb\n\nfrom sklearn.metrics import r2_score\n\nimport statsmodels.api as sm\n\nimport pickle\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","1f34f85a":"df_weather = pd.read_csv('..\/input\/tyra-project-download-data\/weather.csv', index_col='ObsTime', parse_dates=True) \ndf_demand = pd.read_csv('..\/input\/tyra-project-download-data\/demand.csv', index_col='Date', parse_dates=True) \ndf_trend = pd.read_csv('..\/input\/tyra-project-download-data\/GoogleTrend.csv', index_col='date', parse_dates=True) \ndf_holiday_encode = pd.read_csv('..\/input\/tyra-project-download-data\/holiday_encode.csv', index_col='date', parse_dates=True) ","8fa1f147":"col_name = '\u6de8\u5c16\u5cf0\u4f9b\u96fb\u80fd\u529b(\u842c\u74e9)'","8ba1fcc9":"# Prepare data for modeling\ndf_temp = df_demand.loc[:, [col_name]].copy()\ndf_temp = df_temp.dropna()\n\n# Add timestamp features\ndf_temp['weekday'] = df_temp.index.weekday\n\ndf_temp = df_temp.rename(columns={col_name:'demand_meas'})\n\ndf_temp","7bc0ca17":"# Weekly profiles of demand\ndf_plot = df_temp.copy()\n\ndf_plot['demand_meas'].iplot()\n\nplt.figure(figsize=(10,3))\nplt.title('Weekly profile')\nsns.barplot(data=df_plot, x=\"weekday\", y='demand_meas')\n#plt.ylim(0,1.1)\nplt.show()","20c05b0c":"traindata = df_temp.loc['2019'].copy()\ntestdata = df_temp.loc['2020'].copy()\n\ntrain_labels = traindata['demand_meas']\ntest_labels = testdata['demand_meas']\n\ntrain_features = traindata.drop('demand_meas', axis=1)\ntest_features = testdata.drop('demand_meas', axis=1) \n\nLGB_model = lgb.LGBMRegressor()\nLGB_model.fit(train_features, train_labels, categorical_feature=['weekday'])\n\ntestdata['demand_pred'] = LGB_model.predict(test_features)\n\ndf_temp.loc['2020', 'demand_pred'] = testdata['demand_pred']\n\n# Calculate the absolute errors\nerrors = abs(testdata['demand_pred'] - test_labels)\n\n# Calculate mean absolute percentage error (MAPE) and add to list\nMAPE = 100 * np.mean((errors \/ test_labels))\nNMBE = 100 * (sum(testdata.dropna()['demand_meas'] - testdata.dropna()['demand_pred']) \/ (testdata.dropna()['demand_meas'].count() * np.mean(testdata.dropna()['demand_meas'])))\nCVRSME = 100 * ((sum((testdata.dropna()['demand_meas'] - testdata.dropna()['demand_pred'])**2) \/ (testdata.dropna()['demand_meas'].count()-1))**(0.5)) \/ np.mean(testdata.dropna()['demand_meas'])\nRSQUARED = r2_score(testdata.dropna()['demand_meas'], testdata.dropna()['demand_pred'])\n\nprint(\"MAPE: \"+str(round(MAPE,2)))\nprint(\"NMBE: \"+str(round(NMBE,2)))\nprint(\"CVRSME: \"+str(round(CVRSME,2)))\nprint(\"R SQUARED: \"+str(round(RSQUARED,2)))\n\ntestdata[['demand_meas', 'demand_pred']].iplot()","9658b370":"df_temp = df_demand.loc[:, col_name].reset_index().copy()\ndf_temp = df_temp.dropna()\n\n# Add timestamp features\ndf_temp['weekday'] = df_temp['Date'].dt.weekday\n\n# Add weather features\ndf_weather_temp = df_weather.pivot_table(columns='station',index='ObsTime',values=['Temperature'])\ndf_weather_temp.columns = df_weather_temp.columns.get_level_values(0)+'_'+df_weather_temp.columns.get_level_values(1)\ndf_temp = df_temp.merge(df_weather_temp.reset_index(), left_on='Date', right_on='ObsTime')\n\ndf_temp = df_temp.set_index('Date').drop('ObsTime',axis=1)\n\ndf_temp = df_temp.rename(columns={col_name:'demand_meas'})\n\ndf_temp","8e1c1370":"# Scatter plot for demand and outdoor temperature\ndf_plot = df_temp.copy()\ndf_plot['Temperature_avg'] = df_plot.loc[:, df_plot.columns.str.contains('Temperature')].mean(axis=1)\ndf_plot['weekday\/weekend'] = 'weekday'\ndf_plot.loc[df_plot['weekday']>4, 'weekday\/weekend'] ='weekend'\n\nsns.lmplot(x=\"Temperature_avg\", y=\"demand_meas\", hue=\"weekday\/weekend\",\n           data=df_plot, order=2, scatter_kws={'alpha':0.3})","f644b50a":"traindata = df_temp.loc['2019'].copy()\ntestdata = df_temp.loc['2020'].copy()\n\ntrain_labels = traindata['demand_meas']\ntest_labels = testdata['demand_meas']\n\ntrain_features = traindata.drop('demand_meas', axis=1)\ntest_features = testdata.drop('demand_meas', axis=1) \n\nLGB_model = lgb.LGBMRegressor()\nLGB_model.fit(train_features, train_labels, categorical_feature=['weekday'])\n\ntestdata['demand_pred'] = LGB_model.predict(test_features)\n\ndf_temp.loc['2020', 'demand_pred'] = testdata['demand_pred']\n\n# Calculate the absolute errors\nerrors = abs(testdata['demand_pred'] - test_labels)\n\n# Calculate mean absolute percentage error (MAPE) and add to list\nMAPE = 100 * np.mean((errors \/ test_labels))\nNMBE = 100 * (sum(testdata.dropna()['demand_meas'] - testdata.dropna()['demand_pred']) \/ (testdata.dropna()['demand_meas'].count() * np.mean(testdata.dropna()['demand_meas'])))\nCVRSME = 100 * ((sum((testdata.dropna()['demand_meas'] - testdata.dropna()['demand_pred'])**2) \/ (testdata.dropna()['demand_meas'].count()-1))**(0.5)) \/ np.mean(testdata.dropna()['demand_meas'])\nRSQUARED = r2_score(testdata.dropna()['demand_meas'], testdata.dropna()['demand_pred'])\n\nprint(\"MAPE: \"+str(round(MAPE,2)))\nprint(\"NMBE: \"+str(round(NMBE,2)))\nprint(\"CVRSME: \"+str(round(CVRSME,2)))\nprint(\"R SQUARED: \"+str(round(RSQUARED,2)))\n\ntestdata[['demand_meas', 'demand_pred']].iplot()","4ab3e91a":"df_temp = df_demand.loc[:, col_name].reset_index().copy()\ndf_temp = df_temp.dropna()\n\n# Add timestamp features\ndf_temp['weekday'] = df_temp['Date'].dt.weekday\n\n# Add weather features\ndf_weather_temp = df_weather.pivot_table(columns='station',index='ObsTime',values=['Temperature'])\ndf_weather_temp.columns = df_weather_temp.columns.get_level_values(0)+'_'+df_weather_temp.columns.get_level_values(1)\ndf_temp = df_temp.merge(df_weather_temp.reset_index(), left_on='Date', right_on='ObsTime')\n\n# Add holiday features\ndf_temp = df_temp.merge(df_holiday_encode.reset_index().rename(columns={'date':'Date'}), on='Date')\n\ndf_temp = df_temp.set_index('Date').drop('ObsTime',axis=1)\n\ndf_temp = df_temp.rename(columns={col_name:'demand_meas'})\n\ndf_temp","af441228":"# Scatter plot for demand and Google Trend\ndf_plot = df_temp.copy()\n\nsns.boxplot(x=\"holiday_Type\", y=\"demand_meas\", data=df_plot)\nsns.swarmplot(x=\"holiday_Type\", y=\"demand_meas\", data=df_plot, color=\".25\")","e5eedd96":"traindata = df_temp.loc['2019'].copy()\ntestdata = df_temp.loc['2020'].copy()\n\ntrain_labels = traindata['demand_meas']\ntest_labels = testdata['demand_meas']\n\ntrain_features = traindata.drop('demand_meas', axis=1)\ntest_features = testdata.drop('demand_meas', axis=1) \n\nLGB_model = lgb.LGBMRegressor()\nLGB_model.fit(train_features, train_labels, categorical_feature=['weekday','holiday_Name','holiday_Type'])\n\ntestdata['demand_pred'] = LGB_model.predict(test_features)\n\ndf_temp.loc['2020', 'demand_pred'] = testdata['demand_pred']\n\n# Calculate the absolute errors\nerrors = abs(testdata['demand_pred'] - test_labels)\n\n# Calculate mean absolute percentage error (MAPE) and add to list\nMAPE = 100 * np.mean((errors \/ test_labels))\nNMBE = 100 * (sum(testdata.dropna()['demand_meas'] - testdata.dropna()['demand_pred']) \/ (testdata.dropna()['demand_meas'].count() * np.mean(testdata.dropna()['demand_meas'])))\nCVRSME = 100 * ((sum((testdata.dropna()['demand_meas'] - testdata.dropna()['demand_pred'])**2) \/ (testdata.dropna()['demand_meas'].count()-1))**(0.5)) \/ np.mean(testdata.dropna()['demand_meas'])\nRSQUARED = r2_score(testdata.dropna()['demand_meas'], testdata.dropna()['demand_pred'])\n\nprint(\"MAPE: \"+str(round(MAPE,2)))\nprint(\"NMBE: \"+str(round(NMBE,2)))\nprint(\"CVRSME: \"+str(round(CVRSME,2)))\nprint(\"R SQUARED: \"+str(round(RSQUARED,2)))\n\ntestdata[['demand_meas', 'demand_pred']].iplot()","0cb16129":"df_temp = df_demand.loc[:, col_name].reset_index().copy()\ndf_temp = df_temp.dropna()\n\n# Add timestamp features\ndf_temp['weekday'] = df_temp['Date'].dt.weekday\n\n# Add weather features\ndf_weather_temp = df_weather.pivot_table(columns='station',index='ObsTime',values=['Temperature'])\ndf_weather_temp.columns = df_weather_temp.columns.get_level_values(0)+'_'+df_weather_temp.columns.get_level_values(1)\ndf_temp = df_temp.merge(df_weather_temp.reset_index(), left_on='Date', right_on='ObsTime')\n\n# Add holiday features\ndf_temp = df_temp.merge(df_holiday_encode.reset_index().rename(columns={'date':'Date'}), on='Date')\n\n# Add lag features\ndf_temp['demand_meas_1d_ago'] = df_temp[col_name].shift(1)\ndf_temp['demand_meas_7d_ago'] = df_temp[col_name].shift(7)\ndf_temp['demand_meas_14d_ago'] = df_temp[col_name].shift(14)\n\ndf_temp = df_temp.set_index('Date').drop('ObsTime',axis=1)\n\ndf_temp = df_temp.rename(columns={col_name:'demand_meas'})\n\ndf_temp = df_temp.dropna()\n\ndf_temp","8843b84d":"fig = plt.figure(figsize=(6,6))\n\nax1 = fig.add_subplot(211)\nfig = sm.graphics.tsa.plot_acf(df_temp['demand_meas'], lags=28, ax=ax1)\nax1.xaxis.set_ticks_position('bottom')\nfig.tight_layout();\n\nax2 = fig.add_subplot(212)\nfig = sm.graphics.tsa.plot_pacf(df_temp['demand_meas'], lags=28, ax=ax2)\nax2.xaxis.set_ticks_position('bottom')\nfig.tight_layout();","66cb245a":"# Scatter plot for demand and Google Trend\ndf_plot = df_temp.copy()\n\nsns.lmplot(x=\"demand_meas_1d_ago\", y=\"demand_meas\", data=df_plot)\nsns.lmplot(x=\"demand_meas_7d_ago\", y=\"demand_meas\", data=df_plot)\nsns.lmplot(x=\"demand_meas_14d_ago\", y=\"demand_meas\", data=df_plot)","d07cea62":"traindata = df_temp.loc['2019'].copy()\ntestdata = df_temp.loc['2020'].copy()\n\ntrain_labels = traindata['demand_meas']\ntest_labels = testdata['demand_meas']\n\ntrain_features = traindata.drop('demand_meas', axis=1)\ntest_features = testdata.drop('demand_meas', axis=1) \n\nLGB_model = lgb.LGBMRegressor()\nLGB_model.fit(train_features, train_labels, categorical_feature=['weekday','holiday_Name','holiday_Type'])\n\ntestdata['demand_pred'] = LGB_model.predict(test_features)\n\ndf_temp.loc['2020', 'demand_pred'] = testdata['demand_pred']\n\n# Calculate the absolute errors\nerrors = abs(testdata['demand_pred'] - test_labels)\n\n# Calculate mean absolute percentage error (MAPE) and add to list\nMAPE = 100 * np.mean((errors \/ test_labels))\nNMBE = 100 * (sum(testdata.dropna()['demand_meas'] - testdata.dropna()['demand_pred']) \/ (testdata.dropna()['demand_meas'].count() * np.mean(testdata.dropna()['demand_meas'])))\nCVRSME = 100 * ((sum((testdata.dropna()['demand_meas'] - testdata.dropna()['demand_pred'])**2) \/ (testdata.dropna()['demand_meas'].count()-1))**(0.5)) \/ np.mean(testdata.dropna()['demand_meas'])\nRSQUARED = r2_score(testdata.dropna()['demand_meas'], testdata.dropna()['demand_pred'])\n\nprint(\"MAPE: \"+str(round(MAPE,2)))\nprint(\"NMBE: \"+str(round(NMBE,2)))\nprint(\"CVRSME: \"+str(round(CVRSME,2)))\nprint(\"R SQUARED: \"+str(round(RSQUARED,2)))\n\ntestdata[['demand_meas', 'demand_pred']].iplot()","f6be54e5":"df_temp = df_demand.loc[:, col_name].reset_index().copy()\ndf_temp = df_temp.dropna()\n\n# Add timestamp features\ndf_temp['weekday'] = df_temp['Date'].dt.weekday\n\n# Add weather features\ndf_weather_temp = df_weather.pivot_table(columns='station',index='ObsTime',values=['Temperature'])\ndf_weather_temp.columns = df_weather_temp.columns.get_level_values(0)+'_'+df_weather_temp.columns.get_level_values(1)\ndf_temp = df_temp.merge(df_weather_temp.reset_index(), left_on='Date', right_on='ObsTime')\n\n# Add holiday features\ndf_temp = df_temp.merge(df_holiday_encode.reset_index().rename(columns={'date':'Date'}), on='Date')\n\n# Add lag features\ndf_temp['demand_meas_1d_ago'] = df_temp[col_name].shift(1)\ndf_temp['demand_meas_7d_ago'] = df_temp[col_name].shift(7)\ndf_temp['demand_meas_14d_ago'] = df_temp[col_name].shift(14)\n\ndf_temp = df_temp.set_index('Date').drop('ObsTime',axis=1)\n\ndf_temp = df_temp.rename(columns={col_name:'demand_meas'})\n\ndf_temp = df_temp.dropna()\n\ndf_temp","69593c1b":"traindata = df_temp.copy()\n\ntrain_labels = traindata['demand_meas']\n\ntrain_features = traindata.drop('demand_meas', axis=1)\n\nLGB_model = lgb.LGBMRegressor()\nLGB_model.fit(train_features, train_labels, categorical_feature=['weekday','holiday_Name','holiday_Type'])","f69841ce":"pickle.dump(LGB_model, open(\"LGB_model_supply.pickle\", \"wb\"))\n# LGB_model = pickle.load(open('LGB_model_supply.pickle', 'rb'))","51d5b436":"## The first model: only time-series features","400d5338":"## The second model: time-series and weather features","d4462aa1":"# Create model","c031fcc7":"# The fourth model: time-series, weather, holiday features, and lag features","e119b647":"# The third model: time-series, weather, and holiday features","027f20b2":"# Let's create the prediction model - take *\u6de8\u5c16\u5cf0\u4f9b\u96fb\u80fd\u529b(\u842c\u74e9)* as the prediction target"}}