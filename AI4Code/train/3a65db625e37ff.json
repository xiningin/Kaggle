{"cell_type":{"9dab94b0":"code","e2e44654":"code","29320d0c":"code","f9f1968a":"code","af6e88c9":"code","a0524ee1":"code","f6cb84de":"code","fd99248a":"code","f8a61a8d":"code","7e9558fa":"code","ef20b0d9":"code","e45faca2":"code","21ed0885":"code","ad174a94":"code","c6f44ef6":"code","beff3371":"code","26a877d2":"code","085d43c2":"code","1e6e19d7":"code","e65342fe":"code","70e90257":"code","f8683d00":"code","bc9c606c":"code","13cf7921":"code","2dfa75ef":"code","486f6167":"code","a0db8c6c":"markdown","a8610c33":"markdown","4b231721":"markdown","ffcd7646":"markdown"},"source":{"9dab94b0":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport tensorflow as tf\n","e2e44654":"dataset = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')","29320d0c":"dataset","f9f1968a":"dataset.info()","af6e88c9":"dataset['Class'].value_counts()","a0524ee1":"X = dataset.iloc[:,1:-1].values\nY= dataset.iloc[:,-1].values","f6cb84de":"print(X)","fd99248a":"Y","f8a61a8d":"from sklearn.model_selection import train_test_split\nX_train , X_test , Y_train , Y_test = train_test_split(X, Y , test_size = 0.2 , random_state = 42)","7e9558fa":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\n\nX_test = sc.transform(X_test)\n","ef20b0d9":"X_train","e45faca2":"Y_test = Y_test > 0.5  \nprint(Y_test)","21ed0885":"ann = tf.keras.models.Sequential()","ad174a94":"ann.add(tf.keras.layers.Dense(units = 6 , activation='relu'))","c6f44ef6":"ann.add(tf.keras.layers.Dense(units = 6 , activation='relu'))","beff3371":"ann.add(tf.keras.layers.Dense(units = 1 , activation='sigmoid'))","26a877d2":"ann.compile(optimizer = 'adam' , loss = 'binary_crossentropy', metrics = ['accuracy'])","085d43c2":"ann.fit(X_train , Y_train , batch_size = 10 , epochs = 10)","1e6e19d7":"Y_pred = ann.predict(X_test)\nY_pred = Y_pred > 0.5\nprint(Y_pred)","e65342fe":"from sklearn.metrics import accuracy_score, confusion_matrix\ncm = confusion_matrix(Y_test ,Y_pred)\nprint(cm)\naccuracy_score(Y_test , Y_pred)","70e90257":"# we assign weights because our dataset is imbalanced , we assingn weight so that our model would not be biased toward one prediction\n# for eg. suppose  if you have 1000 training set  for classification {Y{0.1}}\n#          out of 1000 if 900 are y = 0 &  100 are y= 1 , now if we run algorithm our algorith will slightly biased towad y = 0 beacause  y = 0 are in higher number of training set\n#       therefore to overcome this problem of biasness we assign weight \n# how to assign weights ?\n# first check your training set exampble biasness lets take our above example of 1000 label out of which 900 are negative and \n#                   100 are positive , so we assign weight in that ration 900\/100 = 9\n#                    weight  { 0:1 ,1:9}","f8683d00":"weights = {0:1 , 1:577}\n","bc9c606c":"ann.fit(X_train , Y_train , batch_size = 10 , class_weight = weights , epochs = 10)","13cf7921":"Y_pred_1 = ann.predict(X_test)\nY_pred_1 =Y_pred >0.5\n\nprint(np.concatenate((Y_pred_1.reshape(len(Y_pred_1),1),Y_test.reshape(len(Y_test), 1)),1))","2dfa75ef":"from sklearn.metrics import accuracy_score , confusion_matrix\ncm_1 = confusion_matrix(Y_test , Y_pred_1)\nprint(cm_1)\naccuracy_score(Y_test , Y_pred_1)","486f6167":"print(np.concatenate((Y_pred_1.reshape(len(Y_pred_1),1),Y_test.reshape(len(Y_test), 1)),1))","a0db8c6c":"## assigning weights ","a8610c33":"## Building ANN","4b231721":"## Traing ANN","ffcd7646":"## Accuracy ~99%"}}