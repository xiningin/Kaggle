{"cell_type":{"61a671ea":"code","44127299":"code","8bf084b3":"code","728ae8fb":"code","557fa057":"code","a42fe704":"code","60b4f7cc":"code","ed1248e9":"code","b1febefb":"code","e5f5a06e":"code","11acf27b":"code","1d94c934":"code","a8271a8a":"code","b9de6948":"code","6a892c6b":"code","ab1247da":"code","78d3bab2":"code","d8a5e39f":"code","699ac1fb":"code","54b2786f":"code","368e5284":"code","db8baa7e":"code","1e0ae48e":"code","08b7bc12":"code","8fb319ce":"code","627f5c2c":"code","406a1230":"code","c5425aca":"code","53fda1fa":"code","f1e57afb":"code","7cca7cce":"code","5047eeae":"code","07a6bbbe":"markdown","3a7edbe2":"markdown","a83af6d0":"markdown","64c99194":"markdown","f21c1f3a":"markdown","664aaf3a":"markdown","8e0e1f64":"markdown","265bcc05":"markdown","7cd69234":"markdown"},"source":{"61a671ea":"import os\nimport numpy as np\nimport pandas as pd\nimport random\nimport math\n\nfrom tqdm.notebook import tqdm\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\nfrom sklearn.metrics import mean_squared_error\nimport category_encoders as ce\n\nfrom sklearn.linear_model import Ridge, ElasticNet\nfrom functools import partial\nimport scipy as sp\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom plotly.subplots import make_subplots\nimport plotly.express as px","44127299":"def seed_everything(seed=777):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)","8bf084b3":"OUTPUT_DICT = '.\/'\n\nID = 'Patient_Week'\nTARGET = 'FVC'\nSEED = 999 \nseed_everything(seed=SEED)\n\nN_FOLD = 10","728ae8fb":"train = pd.read_csv('..\/input\/osic-pulmonary-fibrosis-progression\/train.csv')\ntest_a = pd.read_csv('..\/input\/osic-pulmonary-fibrosis-progression\/test.csv')","557fa057":"train.head(8)","a42fe704":"test_a.head(8)","60b4f7cc":"print('Training Data:',train.info(), end = \"\\n\\n\\n\")\n\nprint('Testing Data:',test_a.info())","ed1248e9":"### Unique \n\ntrain.duplicated()","b1febefb":"test_a.duplicated()","e5f5a06e":"# Visualising Train DataSet \nfig = px.histogram(train, x=\"Sex\")\nfig.update_layout(title_text= \"Patient Count in Training Dataset\")\nfig.show()","11acf27b":"fig = px.histogram(train, x=\"SmokingStatus\")\nfig.update_layout(title_text= \"Ex-Smoker , Never Smoked, Present Smoker\")\nfig.show()","1d94c934":"# Age Distribution\n\nfig = px.histogram(train, x=\"Age\")\nfig.update_layout(title_text= \"Patient Count in Training Dataset\")\nfig.show()","a8271a8a":"fig = px.histogram(train, y=\"Sex\" , color = \"Age\")\nfig.update_layout(title_text= \"Affected Patient wr Age\")\nfig.show()","b9de6948":"fig = px.histogram(train, x=\"Age\" , color = \"SmokingStatus\")\nfig.update_layout(title_text= \"Age wr Smoking Status\")\nfig.show()","6a892c6b":"df = px.data.gapminder()\nfig = px.area(train, x=\"Weeks\", y=\"Percent\", color = \"SmokingStatus\")\nfig.update_layout(title_text= \"Percent Affected wr Weeks and Smoking Status\")\nfig.show()","ab1247da":"fig = px.scatter(x = train[\"Weeks\"] , y = train[\"Percent\"])\n\nfig.update_layout(title_text= \"Weeks vs Percent\")\n\nfig.show()","78d3bab2":"fig = px.histogram(train, x=\"FVC\", color = \"Sex\")\nfig.update_layout(title_text= \"FVC wr Gender\")\nfig.show()","d8a5e39f":"fig = px.histogram(train, x=\"FVC\", color = \"SmokingStatus\")\nfig.update_layout(title_text= \"FVC wr Smoking Status\")\nfig.show()","699ac1fb":"train.columns","54b2786f":"parallel_diagram = train[['Weeks', 'Patient', 'FVC', 'Percent', 'Age', 'Sex', 'SmokingStatus']]\n\nfig = px.parallel_categories(parallel_diagram, color_continuous_scale=px.colors.sequential.Inferno)\nfig.update_layout(title='Parallel category diagram on trainset')\nfig.show()","368e5284":"train = pd.concat([train, test_a])\n\noutput = pd.DataFrame()\n\ngb = train.groupby('Patient') # Combines all col data by object name and return mean values respectively\n\n# tqdm => i love you so much in spanish, progress bar for running loops\n\ntk0 = tqdm(gb, total = len(gb))\n\nfor _, usr_df in tk0:\n    usr_output = pd.DataFrame()\n    for week, tmp in usr_df.groupby(\"Weeks\"):\n        rename_cols = {'Weeks': 'base_Week', 'FVC': 'base_FVC', 'Age': 'base_Age'}\n        \n        tmp = tmp.rename(columns = rename_cols)\n        \n        drop_cols = ['Age', 'Sex', 'SmokingStatus', 'Percent'] \n        \n        _usr_output = usr_df.drop(columns=drop_cols).rename(columns={'Weeks': 'predict_Week'}).merge(tmp, on='Patient')\n        \n        _usr_output['Week_passed'] = _usr_output['predict_Week'] - _usr_output['base_Week']\n        \n        # Concat the empty DF with edited DF\n        usr_output = pd.concat([usr_output, _usr_output])\n    output = pd.concat([output, usr_output])\n        \ntrain = output[output['Week_passed']!=0].reset_index(drop=True)","db8baa7e":"output","1e0ae48e":"test = test_a.rename(columns={'Weeks': 'base_Week', 'FVC': 'base_FVC', 'Age': 'base_Age'})\n\n# Adding Sample Submission\nsubmission = pd.read_csv(\"..\/input\/osic-pulmonary-fibrosis-progression\/sample_submission.csv\")\n\n# In submisison file, format: ID_'week', using lambda to split the ID\nsubmission['Patient'] = submission['Patient_Week'].apply(lambda x:x.split('_')[0])\n\n# In submisison file, format: ID_'week', using lambda to split the Week\nsubmission['predict_Week'] = submission['Patient_Week'].apply(lambda x:x.split('_')[1]).astype(int)\n\ntest = submission.drop(columns = [\"FVC\", \"Confidence\"]).merge(test, on = 'Patient')\n\ntest['Week_passed'] = test['predict_Week'] - test['base_Week']\n\ntest.set_index('Patient_Week', inplace=True)","08b7bc12":"folds = train[['Patient', TARGET]].copy()\nfolds = train[['Patient', TARGET]].copy()\nFold = GroupKFold(n_splits=N_FOLD)\ngroups = folds['Patient'].values\nfor n, (train_index, val_index) in enumerate(Fold.split(folds, folds[TARGET], groups)):\n    folds.loc[val_index, 'fold'] = int(n)\nfolds['fold'] = folds['fold'].astype(int)","8fb319ce":"def run_single_model(clf, train_df, test_df, folds, features, target, fold_num=0):\n    trn_idx = folds[folds.fold!=fold_num].index\n    val_idx = folds[folds.fold==fold_num].index\n    \n    y_tr = target.iloc[trn_idx].values\n    X_tr = train_df.iloc[trn_idx][features].values\n    y_val = target.iloc[val_idx].values\n    X_val = train_df.iloc[val_idx][features].values\n    \n    oof = np.zeros(len(train_df))\n    predictions = np.zeros(len(test_df))\n    clf.fit(X_tr, y_tr)\n    \n    oof[val_idx] = clf.predict(X_val)\n    predictions += clf.predict(test_df[features])\n    return oof, predictions","627f5c2c":"def run_kfold_model(clf, train, test, folds, features, target, n_fold=10):\n    \n    # n_fold from 5 to 7\n    \n    oof = np.zeros(len(train))\n    predictions = np.zeros(len(test))\n    feature_importance_df = pd.DataFrame()\n\n    for fold_ in range(n_fold):\n\n        _oof, _predictions = run_single_model(clf,train, test, folds, features, target, fold_num = fold_)\n\n        oof += _oof\n        predictions += _predictions\/n_fold\n    \n    return oof, predictions","406a1230":"target = train[TARGET]\ntest[TARGET] = np.nan # Displays all Null values\n\n# features\ncat_features = ['Sex', 'SmokingStatus'] # Categorical Features\nnum_features = [c for c in test.columns if (test.dtypes[c] != 'object') & (c not in cat_features)] # Numerical Features\n\nfeatures = num_features + cat_features\ndrop_features = [TARGET, 'predict_Week', 'Percent', 'base_Week']\nfeatures = [c for c in features if c not in drop_features]\n\nif cat_features:\n    ce_oe = ce.OrdinalEncoder(cols=cat_features, handle_unknown='impute')\n    ce_oe.fit(train)\n    train = ce_oe.transform(train)\n    test = ce_oe.transform(test)","c5425aca":"for alpha1 in [0.3]:\n    for l1s in [0.8]:\n        \n        print(\" For alpha:\",alpha1,\"& l1_ratio:\",l1s)\n        clf = ElasticNet(alpha=alpha1, l1_ratio = l1s)\n        oof, predictions = run_kfold_model(clf, train, test, folds, features, target, n_fold=N_FOLD)\n\n        train['FVC_pred'] = oof\n        test['FVC_pred'] = predictions\n\n        # baseline score\n        train['Confidence'] = 100\n        train['sigma_clipped'] = train['Confidence'].apply(lambda x: max(x, 70))\n        train['diff'] = abs(train['FVC'] - train['FVC_pred'])\n        train['delta'] = train['diff'].apply(lambda x: min(x, 1000))\n        train['score'] = -math.sqrt(2)*train['delta']\/train['sigma_clipped'] - np.log(math.sqrt(2)*train['sigma_clipped'])\n        score = train['score'].mean()\n        print(score)\n\n        def loss_func(weight, row):\n            confidence = weight\n            sigma_clipped = max(confidence, 70)\n            diff = abs(row['FVC'] - row['FVC_pred'])\n            delta = min(diff, 1000)\n            score = -math.sqrt(2)*delta\/sigma_clipped - np.log(math.sqrt(2)*sigma_clipped)\n            return -score\n\n        results = []\n        tk0 = tqdm(train.iterrows(), total=len(train))\n        for _, row in tk0:\n            loss_partial = partial(loss_func, row=row)\n            weight = [100]\n            result = sp.optimize.minimize(loss_partial, weight, method='SLSQP')\n            x = result['x']\n            results.append(x[0])\n\n        # optimized score\n        train['Confidence'] = results\n        train['sigma_clipped'] = train['Confidence'].apply(lambda x: max(x, 70))\n        train['diff'] = abs(train['FVC'] - train['FVC_pred'])\n        train['delta'] = train['diff'].apply(lambda x: min(x, 1000))\n        train['score'] = -math.sqrt(2)*train['delta']\/train['sigma_clipped'] - np.log(math.sqrt(2)*train['sigma_clipped'])\n        score = train['score'].mean()\n        print(score)","53fda1fa":"TARGET = 'Confidence'\n\ntarget = train[TARGET]\ntest[TARGET] = np.nan\n\n# features\ncat_features = ['Sex', 'SmokingStatus']\nnum_features = [c for c in test.columns if (test.dtypes[c] != 'object') & (c not in cat_features)]\nfeatures = num_features + cat_features\ndrop_features = [ID, TARGET, 'predict_Week', 'base_Week', 'FVC', 'FVC_pred']\nfeatures = [c for c in features if c not in drop_features]\n\noof, predictions = run_kfold_model(clf, train, test, folds, features, target, n_fold=N_FOLD)","f1e57afb":"train['Confidence'] = oof\ntrain['sigma_clipped'] = train['Confidence'].apply(lambda x: max(x, 70))\ntrain['diff'] = abs(train['FVC'] - train['FVC_pred'])\ntrain['delta'] = train['diff'].apply(lambda x: min(x, 1000))\ntrain['score'] = -math.sqrt(2)*train['delta']\/train['sigma_clipped'] - np.log(math.sqrt(2)*train['sigma_clipped'])\nscore = train['score'].mean()\nprint(score)","7cca7cce":"test['Confidence'] = predictions\ntest = test.reset_index()","5047eeae":"sub = submission[['Patient_Week']].merge(test[['Patient_Week', 'FVC_pred', 'Confidence']], on='Patient_Week')\nsub = sub.rename(columns={'FVC_pred': 'FVC'})\n\nfor i in range(len(test_a)):\n    sub.loc[sub['Patient_Week']==test_a.Patient[i]+'_'+str(test_a.Weeks[i]), 'FVC'] = test_a.FVC[i]\n    sub.loc[sub['Patient_Week']==test_a.Patient[i]+'_'+str(test_a.Weeks[i]), 'Confidence'] = 0.1\n    \nsub[sub.Confidence<1]\n\nsub.to_csv('submission.csv', index=False, float_format='%.1f')","07a6bbbe":"### FVC Prediction","3a7edbe2":"### Submission","a83af6d0":"### Constructing Training Input\nSince we have common columns in both training and test dataset, concat to add more info also the test dataset has just 5 entries\n\ngroupby 'Patient'\nrename columns as follows\ndrop few cols\nWeeks passed = predict_week - base_week\nMake changes to train dataset","64c99194":"### Predicting Confidence","f21c1f3a":"### Training Data","664aaf3a":"### Folds Preparation","8e0e1f64":"### Constructing Testing Input\n- Rename columns in test dataset 'test_a' to 'test'\n- From sample submission, getting values of week from ID\n- From Patient Week, get values of predict week\n- Drop columns in submission and merge with Test on 'Patient'\n\nWeek_passed in test, week passed = predict week - base week","265bcc05":"## OSIC Pulmonary Fibrosis Progression\n\n**Data Provided**\n- train.csv : Baseline CT Scan and entire history of FVC\n- test.csv  : Baseline CT and Initial FVC Measurement\n- train\/    : Baseline CT scan in DICOM format\n- test\/     : Baseline CT Scan in DICOM format\n\nMy public kernel and reference: https:\/\/www.kaggle.com\/jagadish13\/osic-baseline-elasticnet-eda\n\n### ElasticNet Regression\n- Combines L1 and L2 linearly","7cd69234":"### Building Model"}}