{"cell_type":{"71d75522":"code","abd0ebea":"code","913c496b":"code","1df4a95f":"code","339d561b":"code","0181b7f8":"code","0db08fb4":"code","ba5050b4":"code","b6a825b6":"code","213399e2":"code","787659fa":"code","b31e099f":"code","3cbc5780":"code","d6c63c13":"code","c1fb0212":"code","6d6e7f75":"code","35840f3b":"code","7e8fedbf":"code","6734d384":"code","961df3bb":"code","bd731b09":"code","28f7740b":"code","94138dc2":"code","6e85d3af":"code","e8428040":"code","d1bbc72f":"code","ca30a779":"code","2f079e18":"code","551ebde9":"code","a9a55c30":"code","c34de35f":"code","6ff891d7":"code","6770eaf3":"markdown","99f01a95":"markdown","e5de3651":"markdown","e56642e8":"markdown","e3323416":"markdown","46d531d4":"markdown","b03eb07b":"markdown","34abc428":"markdown","d85c893b":"markdown","d50331c2":"markdown","325805cc":"markdown","78daf496":"markdown","8126818b":"markdown","15972f2e":"markdown","7e991012":"markdown","c3da236c":"markdown"},"source":{"71d75522":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","abd0ebea":"# path = '..\/input\/'\npath = '\/kaggle\/input\/kakr-4th-competition\/'","913c496b":"import os\nos.listdir(path)","1df4a95f":"#!pip install pycaret","339d561b":"import pandas as pd\nfrom pycaret.classification import *\n\npd.set_option('max_columns', 500)\npd.set_option('max_rows', 500)","0181b7f8":"train = pd.read_csv(path + 'train.csv')\ntest = pd.read_csv(path + 'test.csv')\nsubmission = pd.read_csv(path + 'sample_submission.csv')","0db08fb4":"df = train.copy()","ba5050b4":"print(train.shape)\nprint(test.shape)\nprint(submission.shape)","b6a825b6":"display(train.head())\ndisplay(test.head())\ndisplay(submission.head())","213399e2":"# test 0.3\n\nfrom pycaret.classification import *\nexp1 = setup(df, target = 'income',\n            ignore_features=['id'])","787659fa":"# F1 score\n# sort: string, default = \u2018Accuracy\u2019\n# The scoring measure specified is used for sorting the average score grid. \n# Other options are \u2018AUC\u2019, \u2018Recall\u2019, \u2018Precision\u2019, \u2018F1\u2019, \u2018Kappa\u2019 and \u2018MCC\u2019.\n\nbest_3 = compare_models(sort = 'F1', n_select = 3)","b31e099f":"lightgbm = create_model('lightgbm')","3cbc5780":"# models()","d6c63c13":"# models(type='ensemble').index.tolist()","c1fb0212":"tuned_lightgbm = tune_model(lightgbm)","6d6e7f75":"plot_model(estimator = tuned_lightgbm, plot = 'auc')","35840f3b":"plot_model(estimator = tuned_lightgbm, plot = 'confusion_matrix')","7e8fedbf":"plot_model(estimator = tuned_lightgbm, plot = 'feature')","6734d384":"plot_model(estimator = tuned_lightgbm, plot = 'class_report')","961df3bb":"# SHAP\ninterpret_model(lightgbm)","bd731b09":"interpret_model(lightgbm, plot = 'correlation')","28f7740b":"# threshold = 0.34\nevaluate_model(tuned_lightgbm)","94138dc2":"pred_holdouts = predict_model(lightgbm)\npred_holdouts.head()","6e85d3af":"display(train.shape)\ndisplay(pred_holdouts.shape)","e8428040":"lightgbm_final = finalize_model(lightgbm)\npredictions = predict_model(lightgbm_final, test)","d1bbc72f":"display(train.shape)\ndisplay(predictions.shape)","ca30a779":"# tuned_lightgbm\n\n# lightgbm_final = finalize_model(tuned_lightgbm)\n# predictions = predict_model(lightgbm_final, test)","2f079e18":"predictions.head()","551ebde9":"submission['prediction'] = predictions['Score']","a9a55c30":"for ix, row in submission.iterrows():\n    if row['prediction'] > 0.5:\n        submission.loc[ix, 'prediction'] = 1\n    else:\n        submission.loc[ix, 'prediction'] = 0","c34de35f":"submission = submission.astype({\"prediction\": int})\nsubmission.to_csv('submission_T-AcademyXKaKr-lightgbm-Pycaret#03.csv', index=False)","6ff891d7":"submission.head()","6770eaf3":"## 6. AUC \uace1\uc120 \/ \uc624\ucc28 \ud589\ub82c\n\nThis function takes a trained model object and returns a plot based on the test \/ hold-out set. The process may require the model to be re-trained in certain cases. See list of plots supported below. Model must be created using create_model() or tune_model().","99f01a95":"## 3. compare_models\n\nThis function train all the models available in the model library and scores them using Stratified Cross Validation. The output prints a score grid with Accuracy, AUC, Recall, Precision, F1, Kappa and MCC (averaged accross folds), determined by fold parameter.\n \nThis function returns the best model based on metric defined in sort parameter.\n \nTo select top N models, use n_select parameter that is set to 1 by default. Where n_select parameter > 1, it will return a list of trained model objects.","e5de3651":"## 5. \ubaa8\ub378 \ud29c\ub2dd\n\nThis function tunes the hyperparameters of a model and scores it using Stratified Cross Validation. The output prints a score grid that shows Accuracy, AUC, Recall Precision, F1, Kappa, and MCCby fold (by default = 10 Folds). This function returns a trained model object.","e56642e8":"## 7. Feature Importance\n\nThis function takes a trained model object and returns a plot based on the test \/ hold-out set. The process may require the model to be re-trained in certain cases. See list of plots supported below. Model must be created using create_model() or tune_model().","e3323416":"* https:\/\/github.com\/pycaret\/pycaret\/blob\/master\/examples\/PyCaret%202%20Classification.ipynb\n* https:\/\/pycaret.org\/\n* https:\/\/pycaret.org\/classification\/","46d531d4":"## T-Academy-XKaKr_Baseline_Pycaret ","b03eb07b":"## Interpret Model\n\nThis function takes a trained model object and returns an interpretation plot based on the test \/ hold-out set. It only supports tree based algorithms. This function is implemented based on the SHAP (SHapley Additive exPlanations), which is a unified approach to explain the output of any machine learning model. SHAP connects game theory with local explanations.","34abc428":"## 10. Submission","d85c893b":"## 2. setup\n\nThis function initializes the environment in pycaret and creates the transformation pipeline to prepare the data for modeling and deployment. setup() must called before executing any other function in pycaret. It takes two mandatory parameters: dataframe {array-like, sparse matrix} and name of the target column. All other parameters are optional.","d50331c2":"## Predict Model\n\nThis function is used to predict new data using a trained estimator. It accepts an estimator created using one of the function in pycaret that returns a trained  model object or a list of trained model objects created using stack_models() or create_stacknet(). New unseen data can be passed to data param as pandas Dataframe. If data is not passed, the test \/ hold-out set separated at the time of setup() is used to generate predictions.","325805cc":"## 4. \ubaa8\ub378 \uc0dd\uc131\n\nThis function creates a model and scores it using Stratified Cross Validation.The output prints a score grid that shows Accuracy, AUC, Recall, Precision, F1, Kappa and MCC by fold (default = 10 Fold). This function returns a trained model object. ","78daf496":"## 9. \uc608\uce21\n\nfinalize_model : This function fits the estimator onto the complete dataset passed during the setup() stage. The purpose of this function is to prepare for final model deployment after experimentation.\n\npredict_model : This function is used to predict new data using a trained estimator. It accepts an estimator created using one of the function in pycaret that returns a trained  model object or a list of trained model objects created using stack_models() or create_stacknet(). New unseen data can be passed to data param as pandas Dataframe. If data is not passed, the test \/ hold-out set separated at the time of setup() is used to generate predictions.","8126818b":"## 8. \ubaa8\ub378 \ud3c9\uac00\n\nThis function displays a user interface for all of the available plots for a given estimator. It internally uses the plot_model() function.","15972f2e":"PyCaret\uc758 \"Classification Module\"\uc744 \uc0ac\uc6a9\ud558\uc5ec \ubca0\uc774\uc2a4\ub77c\uc778\uc744 \uad6c\ucd95 \ud569\ub2c8\ub2e4.\n\n* Setting up Environment : setup\n* Compare Models : compare_models\n* Create Model : create_model\n* Tune Model : tune_model\n* Plot Model : plot_model (auc, confusion_matrix, feature, class_report, \n* Interpret Model : interpret_model\n* Evaluate Model : evaluate_model\n* Predict Model : predict_model\n* Finalize Model : finalize_model","7e991012":"## 1. load data","c3da236c":"## PyCaret\uc740 \ubb34\uc5c7\uc785\ub2c8\uae4c?\n\n* PyCaret\uc740 Python\uc758 \uc624\ud508 \uc18c\uc2a4 \ub85c\uc6b0 \ucf54\ub4dc \uba38\uc2e0\ub7ec\ub2dd \ub77c\uc774\ube0c\ub7ec\ub9ac\ub85c, ML \uc2e4\ud5d8\uc5d0\uc11c \uac00\uc124\uc744 \uc778\uc0ac\uc774\ud2b8\uc8fc\uae30 \uc2dc\uac04\uc73c\ub85c \uc904\uc774\ub294 \uac83\uc744 \ubaa9\ud45c\ub85c\ud569\ub2c8\ub2e4. \n* \uc774\ub97c \ud1b5\ud574 \ub370\uc774\ud130 \uacfc\ud559\uc790\ub294 \uc885\ub2e8 \uac04 \uc2e4\ud5d8\uc744 \ube60\ub974\uace0 \ud6a8\uc728\uc801\uc73c\ub85c \uc218\ud589 \ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4. \n* \ub2e4\ub978 \uc624\ud508 \uc18c\uc2a4 \uae30\uacc4 \ud559\uc2b5 \ub77c\uc774\ube0c\ub7ec\ub9ac\uc640 \ube44\uad50\ud558\uc5ec PyCaret\uc740 \ucf54\ub4dc \uba87 \uc904\ub9cc\uc73c\ub85c \ubcf5\uc7a1\ud55c \uae30\uacc4 \ud559\uc2b5 \uc791\uc5c5\uc744 \uc218\ud589\ud558\ub294 \ub370 \uc0ac\uc6a9\ud560 \uc218 \uc788\ub294 \ub300\uccb4 \ub85c\uc6b0 \ucf54\ub4dc \ub77c\uc774\ube0c\ub7ec\ub9ac\uc785\ub2c8\ub2e4. \n* PyCaret\uc740 \uac04\ub2e8\ud558\uace0 \uc0ac\uc6a9\ud558\uae30 \uc27d\uc2b5\ub2c8\ub2e4. \n* PyCaret\uc5d0\uc11c \uc218\ud589\ub418\ub294 \ubaa8\ub4e0 \uc791\uc5c5 \uc740 \ubc30\ud3ec\ub97c \uc704\ud574 \uc644\uc804\ud788 \uc870\uc815 \ub41c \uc0ac\uc6a9\uc790 \uc9c0\uc815 \ud30c\uc774\ud504 \ub77c\uc778 \uc5d0 \uc790\ub3d9\uc73c\ub85c \uc800\uc7a5\ub429\ub2c8\ub2e4.  \n* PyCaret\uc740 \ubcf8\uc9c8\uc801\uc73c\ub85c scikit-learn, XGBoost, LightGBM, spaCy \ub4f1\uacfc \uac19\uc740 \uc5ec\ub7ec \uae30\uacc4 \ud559\uc2b5 \ub77c\uc774\ube0c\ub7ec\ub9ac \ubc0f \ud504\ub808\uc784 \uc6cc\ud06c\ub97c \ub458\ub7ec\uc2fc Python \ub798\ud37c\uc785\ub2c8\ub2e4 . "}}