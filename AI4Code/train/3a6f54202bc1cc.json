{"cell_type":{"60387a4c":"code","031cb7eb":"code","4b541b5a":"code","744d8b76":"code","40bf8953":"code","4947f5ba":"code","857b0cc3":"code","c817d04b":"code","263a69d5":"code","276d2b57":"code","f3bfc5c6":"code","127b0d14":"code","8e2237f3":"code","6fc44844":"code","401023da":"code","93a64b30":"code","1e6ba930":"code","baf77e65":"code","e04d78ab":"code","17e25e43":"code","f687c59c":"code","8ab0868a":"code","4d930a2c":"code","6c9a322c":"code","fa1163ea":"code","e0653ed8":"code","e9a15031":"code","1d235844":"code","1b3dd1d7":"code","9ada500b":"code","7f1d5b35":"code","4351f4b4":"code","dd7fab59":"code","b253b94d":"code","74d57a4d":"code","55d54411":"code","ee768341":"code","c1d3e62b":"code","35fe23fc":"code","726d8458":"code","120aa9ca":"code","006a3389":"code","722a149b":"code","53767830":"code","e05c8b9b":"code","92c3e660":"code","adacb9f9":"code","733ce908":"markdown","31a41b2a":"markdown","0403053a":"markdown","10b5cade":"markdown","8ab4b876":"markdown","8936fc8b":"markdown","3814cedd":"markdown","0c04b39b":"markdown","220efe3b":"markdown","7c2e3c90":"markdown","b2a30adc":"markdown","ed51481a":"markdown","bae4069b":"markdown","f6bddd76":"markdown"},"source":{"60387a4c":"# \ub77c\uc774\ube0c\ub7ec\ub9ac \ubc0f \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30\nimport pandas as pd\nimport numpy as np\n\ndf = pd.read_csv('..\/input\/customer-analytics\/Train.csv', engine='python')\ndf.head()","031cb7eb":"# check missing values\ndf.isnull().sum()","4b541b5a":"# target variable: Reached.on.time\ny_train = df['Reached.on.Time_Y.N']\nX_train = df.drop(['Reached.on.Time_Y.N'], axis=1)","744d8b76":"print(type(y_train))\nprint(y_train.value_counts())\n\n# y \ud615\ubcc0\ud658\ny_train = y_train.map(lambda x: int(x))","40bf8953":"X_train.info()","4947f5ba":"# Categorical Features: Warehouse_block, Mode_of_Shipment, Product_importance, Gender\n# \ubc94\uc8fc\ud615 \ubcc0\uc218\uc5d0 \uc5b4\ub5a4 \uac12\ub4e4\uc774 \uc788\ub294\uc9c0 \ud655\uc778\ncat_features = ['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender']\nfor cat in cat_features:\n    print(cat, ':', set(X_train[cat]))","857b0cc3":"# \ubc94\uc8fc\ud615 \ubcc0\uc218 \uc22b\uc790\ub85c mapping\ndef wb_map(x):\n    if x == 'A' : return 1\n    elif x == 'B' : return 2\n    elif x == 'C' : return 3\n    elif x == 'D' : return 4\n    else: return 5\n\ndef sp_map(x):\n    if x == 'Ship' : return 1\n    elif x == 'Flight' : return 2\n    elif x == 'Road' : return 3\n\ndef imp_map(x):\n    if x == 'low' : return 1\n    elif x == 'medium': return 2\n    elif x == 'high' : return 3\n\ndef sex_map(x):\n    if x == 'F' : return 1\n    else: return 0","c817d04b":"X_train['Warehouse_block'] = X_train['Warehouse_block'].map(wb_map)\nX_train['Mode_of_Shipment'] = X_train['Mode_of_Shipment'].map(sp_map)\nX_train['Product_importance'] = X_train['Product_importance'].map(imp_map)\nX_train['Gender'] = X_train['Gender'].map(sex_map)\n\nX_train.head()","263a69d5":"# # label encoder \uc0ac\uc6a9\ud558\uae30\n# from sklearn.preprocessing import LabelEncoder\n# label = LabelEncoder()\n# for cat in cat_features:\n#     catcol = X_train[cat]\n#     labeled = label.fit_transform(catcol) # requires 1D array, returns 1D array as well\n#     X_train[cat] = labeled","276d2b57":"X_train.describe()","f3bfc5c6":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# ID \uc81c\uc678\ud55c feature\ub294 \ucd1d 10\uac1c\nfig, ax = plt.subplots(2, 5, figsize=(20, 8))\n\nimg_idx = 0\ncolumns = list(X_train.columns)[1:] # ID \uc81c\uc678\ud55c feature\nfor i in range(2):\n    for j in range(5):\n        colname = columns[img_idx]\n        col = X_train[colname]\n        ax[i][j].hist(col, bins=30)\n        ax[i][j].set_xlabel(colname)\n        if j == 0:\n            ax[i][j].set_ylabel('Frequency')\n        \n        img_idx += 1","127b0d14":"# \uc5f0\uc18d\ud615 \ubcc0\uc218\ub4e4 \uc815\uaddc\ud654 \uc704\ud574\uc11c box-cox \ubcc0\ud658\uc2dc\ud0a4\uace0 \ubd84\ud3ec \ubcf4\uae30 - \ubaa8\ub450 0\ubcf4\ub2e4 \ud070 \uc815\uc218\uac12\uc774\ubbc0\ub85c box-cox \uac00\ub2a5\n# \uc5f0\uc18d\ud615 \ubcc0\uc218\ub4e4: customer_care_calls, prior_purchases, discount_offered, cost of the product, weight in gms\nfrom sklearn.preprocessing import power_transform\n\ncon_features = ['Customer_care_calls', 'Cost_of_the_Product', \n                'Prior_purchases', 'Discount_offered', 'Weight_in_gms']\n\ncon_df = pd.DataFrame()\nfor con in con_features:\n    boxcox = power_transform(X_train[[con]], method='box-cox')\n    con_df[con] = boxcox.flatten()\n\nfig, ax = plt.subplots(1, 5, figsize=(20, 4))\nfor i in range(5):\n    con = con_features[i]\n    ax[i].hist(con_df[con], bins=30)\n    ax[i].set_xlabel(con)\n    if i == 0:\n        ax[i].set_ylabel('box-cox frequency')","8e2237f3":"# \uc5f0\uc18d\ud615 \ubcc0\uc218\ub4e4: customer_care_calls, prior_purchases, discount_offered, cost of the product, weight in gms\nlog_df = pd.DataFrame()\nfor con in con_features:\n    col = X_train[con]\n    if 0 in col:\n        logged = np.log1p(col)\n    else:\n        logged = np.log(col)\n    \n    log_df[con] = logged\n\nfig, ax = plt.subplots(1, 5, figsize=(20, 4))\nfor i in range(5):\n    con = con_features[i]\n    ax[i].hist(log_df[con], bins=30)\n    ax[i].set_xlabel(con)\n    if i == 0:\n        ax[i].set_ylabel('logged frequency')","6fc44844":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nfeats = ['Cost_of_the_Product', 'Discount_offered', 'Weight_in_gms']\nfor ft in feats:\n    scaled = scaler.fit_transform(X_train[[ft]])\n    X_train[ft] = scaled.flatten()\n\nX_train.head()","401023da":"from sklearn.model_selection import train_test_split, KFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nfrom sklearn.metrics import roc_curve, roc_auc_score, auc\nfrom datetime import datetime","93a64b30":"# print(help(LogisticRegression))","1e6ba930":"# print(help(DecisionTreeClassifier))","baf77e65":"# print(help(RandomForestClassifier))","e04d78ab":"# print(help(xgb.XGBClassifier))","17e25e43":"# logistic regression\nlr = LogisticRegression(n_jobs=-1, random_state=42, max_iter=3000)\n# Decision Tree\ndtree = DecisionTreeClassifier(max_depth=9, min_samples_split=5, min_samples_leaf=3, \n                              max_features='auto', random_state=42)\n# Random Forest\nrf = RandomForestClassifier(n_estimators=1000, max_depth=9, min_samples_split=5, min_samples_leaf=3,\n                          max_features='auto', random_state=42, n_jobs=-1)\n# XGBoost\nxgb_model = xgb.XGBClassifier(n_estimators=1000, max_depth=9, learning_rate=0.05, n_jobs=-1,\n                              gamma=0.7, random_state=42, eval_metric='logloss',\n                              use_label_encoder=False)","f687c59c":"# print(help(train_test_split))","8ab0868a":"# help(roc_curve)","4d930a2c":"# train test split\ntrain_x, val_x, train_y, val_y = train_test_split(X_train, y_train, \n                                                  test_size=0.2, shuffle=True, random_state=42)\n\nmodels = [lr, dtree, rf, xgb_model]\nfor m in models:\n    start = datetime.now()\n    m.fit(train_x, train_y)\n    end = datetime.now()\n    # in order to get roc_auc_score, predict_proba is needed\n    pred_y = m.predict_proba(val_x)[:, 1] # for binary case, [:, 1] is necessary; the probability to be classified as '1'\n    name = m.__class__.__name__\n    auc = roc_auc_score(val_y, pred_y)\n    time = end - start\n    print('Model {0} - AUC score: {1}, Training time: {2}'.format(name, auc, time))","6c9a322c":"# # random Forest\uac00 \uac00\uc7a5 \uc88b\uc740 \uc131\ub2a5\n# final_model = rf\n# final_model.fit(X_train, y_train)\n# final_predict = final_model.predict(X_test)\n# final_predict_proba = final_model.predict_proba(X_test)[:, 1]\n# auc_score = roc_auc_score(y_test, final_predict_proba)\n# fpr, tpr, _ = roc_curve(y_test, final_predict_proba)\n# auc_score = auc(fpr, tpr)\n# f1_score = (2 * fpr * tpr) \/ (fpr + tpr) # f1 score","fa1163ea":"# # \ub77c\uc774\ube0c\ub7ec\ub9ac \ubc0f \ub370\uc774\ud130 \ubd88\ub7ec\uc624\uae30\n# import pandas as pd\n# df = pd.read_csv(\"..\/input\/customer-analytics\/Train.csv\")","e0653ed8":"# # [\uc2dc\ud5d8\uc6a9 \ub370\uc774\ud130\uc14b \ub9cc\ub4e4\uae30]\n# # (\ub2e8, y_test \ub370\uc774\ud130\ub294 \ud65c\uc6a9\ud574\uc11c\ub294 \uc548\ub428)\n\n# from sklearn.model_selection import train_test_split\n# X_train, X_test = train_test_split(df, test_size=0.2, shuffle=True, random_state=2021)\n# y_train = X_train[['ID', 'Reached.on.Time_Y.N']]\n# X_train = X_train.drop(columns=['ID', 'Reached.on.Time_Y.N'])\n# y_test = X_test[['ID', 'Reached.on.Time_Y.N']]\n# X_test = X_test.drop(columns=['ID', 'Reached.on.Time_Y.N'])\n\n# X_train.shape, y_train.shape, X_test.shape, y_test.shape","e9a15031":"# # \ub370\uc774\ud130 \ud655\uc778\n# print(X_train.shape)\n# X_train.head()","1d235844":"# y_train","1b3dd1d7":"# # \ub808\uc774\ube14(\ud0c0\uac9f) \ud655\uc778\n# y_train['Reached.on.Time_Y.N'].value_counts()","9ada500b":"# # X_train \uacb0\uce21\uce58 \ud655\uc778\n# X_train.isnull().sum()","7f1d5b35":"# # X_test \uacb0\uce21\uce58 \ud655\uc778\n# X_test.isnull().sum()","4351f4b4":"# # \ub370\uc774\ud130 \ud0c0\uc785 \ud655\uc778\n# X_train.info()","dd7fab59":"# # object \ud0c0\uc785 \uceec\ub7fc, \uace0\uc720\uac12 \uac1c\uc218 \ud655\uc778\n# X_train[['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender']].nunique()","b253b94d":"# # object \uceec\ub7fc \uc0ad\uc81c (\ub610\ub294 \ub77c\ubca8\uc778\ucf54\ub529, \uc6d0\ud56b\uc778\ucf54\ub529)\n# X_train = X_train.drop(['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender'], axis=1)\n# X_test = X_test.drop(['Warehouse_block', 'Mode_of_Shipment', 'Product_importance', 'Gender'], axis=1)\n# X_train","74d57a4d":"# from sklearn.linear_model import LogisticRegression\n# from sklearn.neighbors import KNeighborsClassifier\n# from sklearn.svm import SVC\n# from sklearn.tree import DecisionTreeClassifier\n# from sklearn.ensemble import RandomForestClassifier\n# from xgboost import XGBClassifier","55d54411":"# from sklearn.model_selection import train_test_split\n# X_tr,X_val,y_tr,y_val = train_test_split(X_train,y_train['Reached.on.Time_Y.N'],test_size=0.2,random_state=2021)","ee768341":"# model = LogisticRegression()\n# model.fit(X_tr, y_tr)\n# round(model.score(X_val, y_val) * 100, 2)","c1d3e62b":"# model = KNeighborsClassifier()\n# model.fit(X_tr, y_tr)\n# round(model.score(X_val, y_val) * 100, 2)","35fe23fc":"# model = SVC()\n# model.fit(X_tr, y_tr)\n# round(model.score(X_val, y_val) * 100, 2)","726d8458":"# model = DecisionTreeClassifier()\n# model.fit(X_tr, y_tr)\n# round(model.score(X_val, y_val) * 100, 2)","120aa9ca":"# model = RandomForestClassifier(n_estimators=100)\n# model.fit(X_tr, y_tr)\n# round(model.score(X_val, y_val) * 100, 2)","006a3389":"# model = XGBClassifier(eval_metric='mlogloss', use_label_encoder=False)\n# model.fit(X_tr, y_tr)\n# round(model.score(X_val, y_val) * 100, 2)","722a149b":"# model = KNeighborsClassifier()\n# model.fit(X_train, y_train['Reached.on.Time_Y.N'])\n# pred = model.predict(X_test)\n# pred","53767830":"# submission = pd.DataFrame({\n#         \"ID\": y_test[\"ID\"],\n#         \"Reached.on.Time_Y.N\": pred\n#     })","e05c8b9b":"# submission.head()","92c3e660":"# submission.to_csv('submission.csv', index=False)  ## \uc218\ud5d8\ubc88\ud638.csv","adacb9f9":"# \uc870\uae08 \ub5a8\uc5b4\uc9c4 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc8fc\uace0 \uc788\uc74c\n# round(model.score(X_test, y_test['Reached.on.Time_Y.N']) * 100, 2)","733ce908":"## \uacb0\uacfc \uccb4\uc810 (\uc218\ud5d8\uc790\ub294 \uc54c \uc218 \uc5c6\ub294 \ubd80\ubd84\uc784)","31a41b2a":"# EDA","0403053a":"## Log Histogram\n\n\uc5f0\uc18d\ud615 \ubcc0\uc218\ub4e4 \uc815\uaddc\ud654 \uc704\ud574\uc11c \ub85c\uadf8\ubcc0\ud658\uc2dc\ud0a4\uace0 \ubd84\ud3ec \ubcf4\uae30","10b5cade":"## EDA","8ab4b876":"## \ubaa8\ub378 \uc120\ud0dd \ubc0f \uacb0\uacfc \ucd9c\ub825","8936fc8b":"## \ud480\uc774 (Baseline)\n- \uc544\ub798\ucf54\ub4dc\ub294 \uc815\ub2f5\uc774 \uc544\ub2cc \ud480\uc774 \uc608\uc2dc\uc785\ub2c8\ub2e4.","3814cedd":"# \ubcc0\uc218 Scaling\n\n* \uc815\uaddc\ud654\ub97c \uc704\ud55c box-cox \ubcc0\ud658\uc774\ub098 \ub85c\uadf8\ubcc0\ud658\uc740 \ud544\uc694\ud558\uc9c0 \uc54a\uc544 \ubcf4\uc784\n\n* \ub2e8, \ub2e8\uc704\ub97c \ub9de\ucdb0\uc8fc\uae30 \uc704\ud574 cost, discount offered, weight\uc740 standard scaling","0c04b39b":"## \uc804\uc790\uc0c1\uac70\ub798 \ubc30\uc1a1 \ub370\uc774\ud130\n### \uc81c\ud488 \ubc30\uc1a1 \uc2dc\uac04\uc5d0 \ub9de\ucdb0 \ubc30\uc1a1\ub418\uc5c8\ub294\uc9c0 \uc608\uce21\ubaa8\ub378 \ub9cc\ub4e4\uae30\n\ud559\uc2b5\uc6a9 \ub370\uc774\ud130 (X_train, y_train)\uc744 \uc774\uc6a9\ud558\uc5ec \ubc30\uc1a1 \uc608\uce21 \ubaa8\ud615\uc744 \ub9cc\ub4e0 \ud6c4, \uc774\ub97c \ud3c9\uac00\uc6a9 \ub370\uc774\ud130(X_test)\uc5d0 \uc801\uc6a9\ud558\uc5ec \uc5bb\uc740 \uc608\uce21\uac12\uc744 \ub2e4\uc74c\uacfc \uac19\uc740 \ud615\uc2dd\uc758 CSV\ud30c\uc77c\ub85c \uc0dd\uc131\ud558\uc2dc\uc624(\uc81c\ucd9c\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc740 ROC-AUC \ud3c9\uac00\uc9c0\ud45c\uc5d0 \ub530\ub77c \ucc44\uc810)\n\n![image.png](attachment:f70c3a4b-9984-4656-af95-dac047a900cb.png)\n\n[\uc2dc\ud5d8\uc6a9 \ub370\uc774\ud130\uc14b \ub9cc\ub4e4\uae30] \ucf54\ub4dc\ub294 \uc608\uc2dc\ubb38\uc81c\uc640 \ub3d9\uc77c\ud55c \ud615\ud0dc\uc758 X_train, y_train, X_test \ub370\uc774\ud130\ub97c \ub9cc\ub4e4\uae30 \uc704\ud568\uc784\n\n(\uc720\uc758\uc0ac\ud56d)\n- \uc131\ub2a5\uc774 \uc6b0\uc218\ud55c \uc608\uce21\ubaa8\ud615\uc744 \uad6c\ucd95\ud558\uae30 \uc704\ud574\uc11c\ub294 \uc801\uc808\ud55c \ub370\uc774\ud130 \uc804\ucc98\ub9ac, \ud53c\ucc98\uc5d4\uc9c0\ub2c8\uc5b4\ub9c1, \ubd84\ub958\uc54c\uace0\ub9ac\uc998, \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130 \ud29c\ub2dd, \ubaa8\ud615 \uc559\uc0c1\ube14 \ub4f1\uc774 \uc218\ubc18\ub418\uc5b4\uc57c \ud55c\ub2e4.\n- \uc218\ud5d8\ubc88\ud638.csv\ud30c\uc77c\uc774 \ub9cc\ub4e4\uc5b4\uc9c0\ub3c4\ub85d \ucf54\ub4dc\ub97c \uc81c\ucd9c\ud55c\ub2e4.\n- \uc81c\ucd9c\ud55c \ubaa8\ub378\uc758 \uc131\ub2a5\uc740 ROC-AUC\ud615\ud0dc\ub85c \uc77d\uc5b4\ub4dc\ub9b0\ub2e4.","220efe3b":"## Box-cox Histogram\n\n\uc5f0\uc18d\ud615 \ubcc0\uc218\ub4e4 \uc815\uaddc\ud654 \uc704\ud574\uc11c box-cox \ubcc0\ud658\uc2dc\ud0a4\uace0 \ubd84\ud3ec \ubcf4\uae30 - \ubaa8\ub450 0\ubcf4\ub2e4 \ud070 \uc815\uc218\uac12\uc774\ubbc0\ub85c box-cox \uac00\ub2a5\n","7c2e3c90":"# Model Selection\n\n* \uc0ac\uc6a9\ud560 \ud6c4\ubcf4\uad70\n    - Logistic Regression\n    - Decision Tree\n    - Random Forest","b2a30adc":"## \ub370\uc774\ud130 \uc804\ucc98\ub9ac","ed51481a":"# Library and Data Import","bae4069b":"## \ubaa8\ub378 \ubc0f \ud3c9\uac00","f6bddd76":"## Histogram\n\n\uc2dc\ud5d8\ub54c\ub294 \uc548 \ub418\uc9c0\ub9cc, \uc6b0\uc120 \uadf8\ub824\ubcf8\ub2e4"}}