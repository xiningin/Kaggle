{"cell_type":{"056e2e88":"code","43fc119c":"code","1af95e79":"code","f9c13a46":"code","dc684537":"code","b452eb28":"code","5afc8705":"code","f27f13ba":"code","c2d74996":"code","282d3ef9":"code","bb660ad8":"code","c5134a08":"code","cada0a99":"code","f762b9b7":"code","5f18a583":"code","e14639ae":"code","1eba8039":"code","d0945e71":"markdown","607aead5":"markdown","bd81078b":"markdown","2cb479a6":"markdown","49e21049":"markdown","2b94ce4e":"markdown","6029f0b5":"markdown","7e429ae0":"markdown","ab36d364":"markdown"},"source":{"056e2e88":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport zipfile\n\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import stopwords\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB","43fc119c":"# Get the training data\nwith zipfile.ZipFile('..\/input\/movie-review-sentiment-analysis-kernels-only\/train.tsv.zip') as z:\n    with z.open(\"train.tsv\") as t:\n        \n        train = pd.read_csv(t, sep = \"\\t\")\ntrain.head()","1af95e79":"# Get the test data\nwith zipfile.ZipFile('..\/input\/movie-review-sentiment-analysis-kernels-only\/test.tsv.zip') as z:\n    with z.open(\"test.tsv\") as t:\n        \n        test = pd.read_csv(t, sep = \"\\t\")\ntest.head()","f9c13a46":"print(train.shape)\nprint(test.shape)\n\nprint(train['Sentiment'].unique())","dc684537":"X = train['Phrase']\ny = train['Sentiment']\nX_test = test['Phrase']","b452eb28":"# Initialize all the preprocessing objects\n\ntokenizer = RegexpTokenizer(r\"\\w+\") # only select alphanumeric characters\nen_stop = set(stopwords.words('english')) # get all the English language stopwords\nps = PorterStemmer() # to extract stem out of any given word","5afc8705":"def getStemmedReview(review):\n    \"\"\"\n        This function takes a review string and then performs the preprocessing steps on it\n        to return the cleaned review which will be more effective in predictions later made by the \n        classifier.\n    \"\"\"\n    review = review.lower()\n    \n    tokens = tokenizer.tokenize(review)\n    new_tokens = [token for token in tokens if token not in en_stop]\n    stemmed_tokens = [ps.stem(token) for token in new_tokens]\n    \n    cleaned_review = ' '.join(stemmed_tokens)\n    \n    return cleaned_review","f27f13ba":"# Let's check out the results of the function \nprint(\"Review ===> \", X[0])\nprint(\"Preprocessed Review ===>\", getStemmedReview(X[0]))","c2d74996":"# Apply the function on the whole dataset\nX_cleaned = X.apply(getStemmedReview)\n\nXtest_cleaned = X_test.apply(getStemmedReview)","282d3ef9":"X_cleaned","bb660ad8":"Xtest_cleaned","c5134a08":"# Remove the reviews with empty ","cada0a99":"## First of all though, we'll need to convert our data into a count vector to be able \n## to work with the Multinomial Naive Bayes model\n\ncv = CountVectorizer()\n\nX_vec = cv.fit_transform(X_cleaned).toarray()\n\nX_vec.shape","f762b9b7":"Xtest_vec = cv.transform(Xtest_cleaned).toarray()\n\nXtest_vec.shape","5f18a583":"# Train the classifier\n\nmnb = MultinomialNB()\nmnb.fit(X_vec, y)","e14639ae":"# Time to make some predictions and submit them\n\npredictions = pd.Series(mnb.predict(Xtest_vec))\n\npredictions","1eba8039":"submission = pd.concat([test.PhraseId, predictions], \n                      keys = ['PhraseId', 'Sentiment'],\n                      axis = 1)\n\nsubmission.to_csv('submission.csv', index = False)","d0945e71":"## The NLP Pipeline\n\nFor the textual data, we will have to first take it through an NLP pipeline to preprocess it to be able to work with it using our classifier. We are going to take the text through a series of tokenization, stemming, and removing all the stopwords.","607aead5":"As we can see, the preprocessed review is much more shorter, and conveys the same meaning as the original review.","bd81078b":"We have extracted out both of our data files and stored in dataframes to work with later. Also, as we can see there are 5 different sentiment classes (target) from 0-4, as explained in the competition page.","2cb479a6":"## Import the libraries","49e21049":"## Get the Data\n\nOur textual dataset is stored in zipfiles for this competition, so we are going to extract the tsv files from their zips and then work on it.","2b94ce4e":"# Naive Bayes Classifier for Sentiment Analysis\n\nThis is my first NLP competiton submission. Here, I am going to use the Naive Bayes Classifier from sklearn with some tweaks.","6029f0b5":"Now that we have got our feature vectors, we will feed it into the Multinomial Naive Bayes Classifier and then check our model's accuracy score.\n\n","7e429ae0":"## Let's get to our Classifier\n\nFor our dataset here, we will use the Multinomial Naive Bayes Classifier to predict the different sentiments for each review","ab36d364":"A total of 10619 featureshave been extracted from our dataset. It would have been exponentially large had we not preprocessed it earlier. Next, we'll use this vectorizer to transform the testing data"}}