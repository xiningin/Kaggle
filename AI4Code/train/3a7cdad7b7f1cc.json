{"cell_type":{"45e1cedc":"code","7cd2ced1":"code","408dc304":"code","8674f9f5":"code","f0b3d4bb":"code","db336a76":"code","26b9e383":"code","8ae23026":"code","113db0e7":"code","5be5d869":"code","582e5bef":"code","fe6d7696":"markdown","025caae9":"markdown","a5431472":"markdown","0bcf4938":"markdown","b1f0a419":"markdown","f905b2ff":"markdown"},"source":{"45e1cedc":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport statistics as s ","7cd2ced1":"#import dataset and specify X (independent variables) and y (dependent variable)\ndf_icn = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/ICN_numbers.csv')\ndf_fnc = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/fnc.csv')\ndf_loading = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/loading.csv')\ndf_reveal = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/reveal_ID_site2.csv')\ndf_sample = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/sample_submission.csv')\ndf_train = pd.read_csv('\/kaggle\/input\/trends-assessment-prediction\/train_scores.csv')","408dc304":"#impute missing training values\nfrom sklearn.impute import KNNImputer\n\n#separate Id column and attributes\ndf_train2 = df_train[['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']]\n\n#impute\nimputer = KNNImputer(n_neighbors = 3, weights=\"uniform\")\ndf_train2 = imputer.fit_transform(df_train2)\n\n#convert the 2d array back to the dataframe and add back the Id column\ndf_train2 = pd.DataFrame(df_train2, columns = ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2'])\ndf_train2 = pd.concat([df_train['Id'], df_train2], axis =1)\n\ndf_train_imputed = df_train2.copy()\n\ndf_train_imputed","8674f9f5":"#specify the datasets to be tested in the model, \n\n#option 1\ndf_combine_fnc = df_train_imputed.join(df_fnc.set_index('Id'), on = 'Id')\n\n#option 2\ndf_combine_loading = df_train_imputed.join(df_loading.set_index('Id'), on = 'Id')\n\n#option 3\ndf_combine = df_train_imputed.join(df_fnc.set_index('Id'), on = 'Id')\ndf_combine = df_combine.join(df_loading.set_index('Id'), on = 'Id')\n\n#current testing\ndf = df_combine_loading\nfrom termcolor import colored\ntext = colored('Currently testing the ICs as predictors only',  'red', attrs=['reverse', 'blink'])\nprint(text)","f0b3d4bb":"#X for df_combine_fnc\nX = df.iloc[:, 6:]\n\n#specify the y's\ny = df.iloc[:, 0:6]\ny_age = df.iloc[:, 1]\ny_1_1 = df.iloc[:, 2].round(2)\ny_1_2 = df.iloc[:, 3]\ny_2_1 = df.iloc[:, 4]\ny_2_2 = df.iloc[:, 5]","db336a76":"#specify features to predict\ntargets = [y_age, y_1_1, y_1_2, y_2_1, y_2_2]\n\n#weights from TRENDS\nweights = [.3, .175, .175, .175, .175]","26b9e383":"from sklearn.model_selection import train_test_split\n\n#select models \nfrom sklearn.linear_model import HuberRegressor\nfrom sklearn.svm import LinearSVR\n\n#score holding\nscores_storage = []\n\nfor i in targets:\n    #split the data\n    X_train, X_test, y_train, y_test = train_test_split(X, i, test_size=0.4, random_state=0)\n    \n    #run the model\n    if i.equals(y_age):\n        model = HuberRegressor(max_iter = 1000)\n    elif i.equals(y_1_1):\n        model = HuberRegressor(max_iter = 1000)\n    elif i.equals(y_1_2):\n        model = LinearSVR()\n    elif i.equals(y_2_1):\n        model = HuberRegressor(max_iter = 1000)\n    elif i.equals(y_2_2):\n        model = HuberRegressor(max_iter = 1000)\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n\n    #get scores of each target\n    unweighted_score = (abs(y_test-y_pred)).sum()\/y_pred.sum()\n    scores_storage.append(unweighted_score)\n\n#multiple scores with weights and sum for final score\ngrand_score = [scores_storage[i] * weights[i] for i in range(len(scores_storage))]\nsum(grand_score)","8ae23026":"#get the ID's of the submission\ndf_sub_id = df_sample.copy()\n\ndf_sub_id['Id'] = df_sub_id['Id'].str.slice(0,5,1)\ndf_sub_id = df_sub_id['Id'].unique()\n\ndf_sub_id = pd.DataFrame({'Id' : df_sub_id , 'hold' : np.zeros(len(df_sub_id))})\ndf_sub_id['Id'] = df_sub_id['Id'].astype(int)","113db0e7":"#create the features dataframe for submission Ids\ndf_sub_combine = df_loading.join(df_sub_id.set_index('Id'), on = 'Id')\ndf_sub_combine = df_sub_combine.dropna()\n\n#create the features only dataframe for submission Ids\ndf_sub_test = df_sub_combine.drop(columns = ['Id', 'hold'])","5be5d869":"targets = [y_age, y_1_1, y_1_2, y_2_1, y_2_2]\ntargets_names = ['y_age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2']\n\nint_index = [0, 1, 2, 3, 4]\n\n#create empty submission dataframe\nsubmission = pd.DataFrame()\n\n#create submission \nfor i in int_index:\n    #for i in targets:\n    \n    #train the model on the training set\n    model =  HuberRegressor(max_iter = 1000)\n    model.fit(X, targets[i])\n\n    #predict \n    y_pred = model.predict(df_sub_test)\n    \n    #add predictions by column\n    submission[targets_names[i]] = y_pred\n    \nsubmission","582e5bef":"#turn dataframe prediction values into one long series\npredicted = pd.Series([], dtype = 'float')\nfor i in range(submission.shape[0]):\n    row_values = pd.Series(submission.iloc[i].values)\n    predicted = predicted.append(row_values, ignore_index= True)\n\n#add the series to the submission file\ndf_submission_ensemble = df_sample.copy()\ndf_submission_ensemble['Predicted'] = predicted\ndf_submission_ensemble.to_csv('submission_ensemble_linear.csv', index = False)\ndf_submission_ensemble","fe6d7696":"This submission will focus on submission predictions, particularly using only the Loading data, and different models for each feature. Please look at my previous notebook on Domain Explanation and Visualizations below:\n\nhttps:\/\/www.kaggle.com\/dhuang718\/domain-explanation-visualization-modeling\n    ","025caae9":"### Import Libraries","a5431472":"### Ensemble Model - Diferrent Models for Each y's","0bcf4938":"### Preprocessing","b1f0a419":"### Submission","f905b2ff":"### Import the datasets"}}