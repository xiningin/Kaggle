{"cell_type":{"4aa37f97":"code","8626513f":"code","5dd19101":"code","a5ac6550":"code","39977083":"code","08af2f7e":"code","58192c6e":"code","028ef9c5":"code","b3ff5c6a":"code","64291214":"code","142127f3":"code","173a338f":"code","09837a9b":"code","8f2c62a2":"code","5adcb8e9":"code","c2682fa4":"code","9834e0ae":"code","2afb9517":"code","fdb2d615":"code","d28ce090":"code","a07f8fb7":"code","7ea166d1":"markdown","243e44ab":"markdown","9cfdef87":"markdown","7d7a0759":"markdown","4550c31e":"markdown","158468e6":"markdown","d0c96e17":"markdown","7d3d751c":"markdown","e89af8d8":"markdown","0ed753a0":"markdown","978e6f8c":"markdown"},"source":{"4aa37f97":"# ! conda install -c bioconda kalign3\n# ! kalign  -i sequences.fasta -o kalign_fast.fasta ","8626513f":"! conda install -y scikit-bio","5dd19101":"import os\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport holoviews as hv\nfrom skbio import DNA\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.decomposition import KernelPCA\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import TruncatedSVD\n\nhv.extension('bokeh')","a5ac6550":"file = '\/kaggle\/input\/2019ncov-sequences-wuhan-coronavirus\/kalign.fasta'","39977083":"class FastaSeq:\n    def __init__(self, name, sequence):\n        self.name = name\n        self.sequence = DNA(sequence)\n\n    def get_seqs(file):\n        items = []\n        index = 0\n        start = False\n        for line in file:\n            if line.startswith(\">\"):\n                start = True\n                if index >= 1:\n                    items.append(aninstance)\n                index+=1\n                name = line[:-1]\n                seq = ''\n                aninstance = FastaSeq(name, seq)\n            else:\n                if start:\n                    seq += line[:-1]\n                    aninstance = FastaSeq(name, seq)\n        if start:\n            items.append(aninstance)\n\n        return items","08af2f7e":"with open(file, \"r\") as f:\n    data = FastaSeq.get_seqs(file=f.readlines())","58192c6e":"str(data[3].sequence)[:1000] + ' ...'","028ef9c5":"replace = {'A':'A',\n             'C':'C',\n             'G':'G',\n             'T':'U',\n             'R':'AG',\n             'Y':'CU',\n             'S':'GC',\n             'W':'AU',\n             'K':'GU',\n             'M':'AC',\n             'B':'CGU',\n             'D':'AGU',\n             'H':'ACU',\n             'V':'ACG',\n             'N':'ACGU',\n             '.':'S',\n            '-':'S'}","b3ff5c6a":"df = pd.DataFrame(list(map(lambda x: pd.Series(list(str(x.sequence))), data)))\ndf.shape","64291214":"gaps = (df == '-').mean(1)\ngap_threshold = gaps < 0.25\n\nsequences = (df\n             .loc[gap_threshold, :]\n             .replace(replace)\n             .applymap(str))\nsequences.shape","142127f3":"from scipy.sparse import hstack\nfrom sklearn.feature_extraction.text import CountVectorizer\nencoder = CountVectorizer(analyzer='char', vocabulary=['S', 'C', 'A', 'G', 'U'], strip_accents=None, lowercase=False)\nX = hstack([encoder.fit_transform(sequences.loc[:, i]) for i in sequences])","173a338f":"X = np.ascontiguousarray(X\n                         .toarray()\n                         .astype('float32'))","09837a9b":"# svd\nsvd = TruncatedSVD(2, algorithm='arpack')\nZ = svd.fit_transform(X)\nsvd_components = [f'Component {i} ({round(e*100)}%)' for i, e in enumerate(svd.explained_variance_ratio_.tolist())]\n\n# kpca\nkpca = KernelPCA(2, kernel='cosine', n_jobs=-1)\nT = kpca.fit_transform(X)\nkpca_components = [f'Component {i}' for i in range(2)]\n\n# TSNE\ntsne = TSNE(2, perplexity=18, metric='hamming')\nU = tsne.fit_transform(X)\ntsne_high_components = [f'Component {i}' for i in range(2)]\n\ntsne = TSNE(2, perplexity=5, metric='hamming')\nW = tsne.fit_transform(X)\ntsne_low_components = [f'Component {i}' for i in range(2)]\n\n\ntsne = TSNE(2, perplexity=18, metric='cosine')\nV = tsne.fit_transform(X)\ntsne_cosine_high_components = [f'Component {i}' for i in range(2)]\n\ntsne = TSNE(2, perplexity=5, metric='cosine')\nS = tsne.fit_transform(X)\ntsne_cosine_low_components = [f'Component {i}' for i in range(2)]\n\n# plots\nfig, axes = plt.subplots(3, 2, figsize=(10, 10))\nsvd_plot = pd.DataFrame((Z - Z.mean(0)) \/ Z.std(0), columns=svd_components).plot.scatter(x=svd_components[0], y=svd_components[1], title='SVD', ax=axes[0][0])\ncosine_kpca = pd.DataFrame(T, columns=kpca_components).plot.scatter(x=kpca_components[0], y=kpca_components[1], title='Cosine KPCA', ax=axes[0][1])\ntsne_high = pd.DataFrame(U, columns=tsne_high_components).plot.scatter(x=tsne_high_components[0], y=tsne_high_components[1], title='Hamming TSNE: Perplexity 18', ax=axes[1][0])\ntsne_low = pd.DataFrame(W, columns=tsne_low_components).plot.scatter(x=tsne_low_components[0], y=tsne_low_components[1], title='Hamming TSNE: Perplexity 5', ax=axes[1][1])\ntsne_high = pd.DataFrame(V, columns=tsne_cosine_high_components).plot.scatter(x=tsne_cosine_high_components[0], y=tsne_cosine_high_components[1], title='Cosine TSNE: Perplexity 18', ax=axes[2][0])\ntsne_low = pd.DataFrame(S, columns=tsne_cosine_low_components).plot.scatter(x=tsne_cosine_low_components[0], y=tsne_cosine_low_components[1], title='Cosine TSNE: Perplexity 5', ax=axes[2][1])","8f2c62a2":"from sklearn.metrics import pairwise_distances\n\ndef d_stat(X):\n    return np.sum(pairwise_distances(X)**2).astype('float32')\n\ndef gap(data, labels=None):\n    grouper = (pd.DataFrame(data)\n     .groupby(labels))\n    \n    D_k = grouper.apply(d_stat)\n    N_k = grouper.count()[0]\n    \n    W_k = (D_k\/(2*N_k)).sum()\n    \n    D = d_stat(data)\n    N = X.shape[0]\n    W = D \/ (2 * N)\n    \n    return np.log(W) - np.log(W_k)\n\ndef orth(v, u):\n    return v - (v@v)\/(u@u) * u","5adcb8e9":"from sklearn.decomposition import PCA\nfrom functools import partial\nfrom sklearn.metrics import pairwise_distances_argmin\n\nclass PrincipleGeneShaving:\n    def __init__(self, n_clusters = 2, alpha = 0.1):\n        self.n_clusters = n_clusters\n        self.alpha = alpha\n        \n    def fit_transform(self, X):\n        # centre each row at zero\n        X  = X - X.mean(1).reshape(-1,1)\n        svd = PCA(1)\n        \n        labels = np.full((X.shape[0], self.n_clusters), 0)\n        for k in range(self.n_clusters - 1):\n            \n            # shave\n            indexes = [np.arange(X.shape[0]).flatten()]\n            S = [X]\n            while S[-1].shape[0] > 1:\n                P = svd.fit_transform(S[-1].T)\n\n                inner = S[-1] @ P\n\n                threshold = np.quantile(inner, self.alpha)\n                not_shaved = (inner > threshold).reshape(-1,1).flatten().copy()\n                \n                if not_shaved.ndim == 2:\n                    print('reshape')\n                    ns = np.array(sum(not_shaved.tolist(), []))\n                else:\n                    ns = not_shaved\n                                \n                indexes.append(indexes[-1][ns])\n                S_prime = S[-1][ns, :]\n\n                if S_prime.shape[0] > 1:\n                    S.append(S_prime)\n                else:\n                    break\n\n            # score\n            scores = []\n            for index in indexes:\n                l = np.full(X.shape[0], k)\n                l[index] = k + 1\n\n                scores.append(gap(X, l))\n\n            max_score = np.argmax(scores)\n\n            labels[indexes[max_score], k] += 1\n            \n            # orthogonalize\n            X_bar = (np.ascontiguousarray(X[(labels[:, k] == 1), :].mean(0))\n                     .ravel()\n                     .astype('float32'))\n            \n            assert X.shape[1] == X_bar.shape[0]\n            X = np.apply_along_axis(partial(orth, u=X_bar), 1, np.ascontiguousarray(X)).astype('float32')\n        \n        return pairwise_distances_argmin(labels, np.unique(labels, axis=0))","c2682fa4":"pgs = PrincipleGeneShaving(3, 0.25)\nlabels = pgs.fit_transform(X)\nhv.Bars(pd.Series(labels, name='Count of labels').value_counts()).opts(xlabel='Label')","9834e0ae":"components = ['Component 1', 'Component 2']\n(hv.Scatter(pd.DataFrame(U, columns=components)\n            .assign(cluster=labels.astype(str)), \n            kdims=components[0], vdims=[components[1], 'cluster'])\n .opts(color='cluster', cmap='Category10',\n       tools=['hover'], size=7,\n       width=800, height=600, title='SARS-COV-2: Principle Gene Shaving'))","2afb9517":"super_genes = (sequences\n               .assign(label=labels)\n               .groupby('label').apply(lambda df: df.mode())\n               .dropna()\n               .drop(columns=['label']))","fdb2d615":"hv.Raster(super_genes.iloc[[0], :]\n           .replace({k: i for i, k in enumerate(list(replace.keys()) + ['S', 'U'])}).astype(np.int).values).opts(width=1000, height=100, title='Super-gene 1')","d28ce090":"hv.Raster(super_genes.iloc[[1], :]\n           .replace({k: i for i, k in enumerate(list(replace.keys()) + ['S', 'U'])}).astype(np.int).values).opts(width=1000, height=100, title='Super-gene 2')","a07f8fb7":"hv.Raster(super_genes.iloc[[2], :]\n           .replace({k: i for i, k in enumerate(list(replace.keys()) + ['S', 'U'])}).astype(np.int).values).opts(width=1000, height=100, title='Super-gene 3')","7ea166d1":"# Preprocessing\nIUPAC has a [guide](https:\/\/www.bioinformatics.org\/sms\/iupac.html) on how sequenced genes should be represented. In order to best capture this structure I opted to produce a One-hot encoding of these nucleotide code allowing for the symbols which represent ambiguity in the sequencing. \n\n\n| IUPAC nucleotide code\t| Base |\n|---|------------|\n| A | \tAdenine  |  \n| C | \tCytosine  |  \n| G | \tGuanine  |  \n| T |  (or U)\tThymine (or Uracil)  |  \n| R | \tA or G  |  \n| Y | \tC or T  |  \n| S | \tG or C  |  \n| W | \tA or T  |  \n| K | \tG or T  |  \n| M | \tA or C  |  \n| B | \tC or G or T  |  \n| D | \tA or G or T  |  \n| H | \tA or C or T  |  \n| V | \tA or C or G  |  \n| N | \tany base  |  \n| . |  or -\tgap  |  ","243e44ab":"Below, I have visualize the 'mode' gene produced by each cluster, which may be used for comparison. ","9cfdef87":"Before filtering:","7d7a0759":"After alignment I had a number of sequences with a very large portion of gaps which I opted to filter from the dataset. ","4550c31e":"# Dimensionality Reduction\nI opted to apply a number of methods in dimensionality reduction in order to best visualise the highly sparse data. To set my perplexity, I looked to the [original author's guide](https:\/\/lvdmaaten.github.io\/tsne\/) which recommends low perplexities for small, sparse datasets.  ","158468e6":"# Alignment\nI have very little exposure working with Genetic Data and so had to reach out to some friends here and there to answer some very basic questions. A major challenge I faced in this analysis was how to deal with the issue of alignment.  When sequencing gene, mistakes can arise which cause sequences to have gaps which lead to misalignment. For large sequences and large datasets of gene this is alignment process can be extremely computationally intensive and after struggling with multiple tools in ended up settling on Lassmann's Kalign 3 method, as it appeared the fastest and simplest method I could use on CPU hardware.  \n\nI tried a number of different appoaches and software tools, but Kalign 3 seems to be the easiest to use with the time I had.  I if people have had experience in gene alignment and have some spare compute I would really appreciate feedback on this process and the do's and don't, as this notebook- for now- mainly focuses on the methodology and less the analysis. \n\n[1] Lassmann, Timo. Kalign 3: multiple sequence alignment of large data sets. Bioinformatics (2019)\n\nI have an example of how to install and use the `kalign3` software locally below, this may not support avx2 acceleration- for that you will have to brew install or install from source:","d0c96e17":"As my notebook is more an example of the method and less an thorough exploration of the data, I have opted to use larger shaving having $\\alpha =0.25$, mainly due to the resource limitation of the notebook. ","7d3d751c":"# Data\nThe data which I am using is from the [NCBI database](https:\/\/www.ncbi.nlm.nih.gov\/labs\/virus\/vssi\/#\/virus?SeqType_s=Nucleotide&VirusLineage_ss=Severe%20acute%20respiratory%20syndrome%20coronavirus%202,%20taxid:2697049) which was accessed on the 7th of april and represents a collection of genes which researchers have sequenced of the SARS-COV-2 virus. ","e89af8d8":"After filtering:","0ed753a0":"# Principle Gene Shaving\n1. Start with the expression matrix X, with each row centred at zero  \n2. Compute the leading Principle Component of the rows of X  \n3. Shave off a portion \\alpha (typically 10%) of the gene having the smallest absolute inner product with teh leading principal component.  \n4. Repeat steps 2 and 3 until only one gene remains.  \n5. This produces a nested sequence of gene clusters $S_1 \\in ... \\in S_{k_2} \\in S_{K_1} \\in S_{k} \\in S_{N}$.  \n6. Orthogonalize each row of X with respect to $\\bar{X_{S_K}}$, the average gene in $X_{\\hat{S_K}}$.  \n7. Repeat steps 1-5 above with the orthogonalized data, until M clusters are found with M chosen a priori. \n  \n\\- from \"'Gene shaving' as a method for identifying distinct sets of genes with similar expression patterns\" original paper","978e6f8c":"Last year I took an amazing roller-coaster course on Modern Multivariate Statistics, which covered the longest laundry list of methods in Multivariate Statistics from Reduced Rank Regression and Biclustering to Structural Equation Modelling and Gaussian Mixture Models. The course followed Izenman's book on Modern multivariate statistical techniques and was amazing exposure for me and my peers. As our convenor works closely with biomedical researchers in the field of biostatistics, we spent valuable time exploring methods in the field of biostatistics and spent some time exploring one of Hastie, Trevor, et al.'s methods in Gene Clustering, called Principle Gene Shaving, which I thought I would explore. \n\nSadly, Python is very poorly equipped for this method, as I was required to write a lot of it from scratch.  For R and S, there are [complete implementation](https:\/\/bioinformatics.mdanderson.org\/public-software\/geneclust\/) which I would recommend for any serious research.  \n\n\n[1] Izenman, Alan Julian. \"Modern multivariate statistical techniques.\" Regression, classification and manifold learning 10 (2008): 978-0.\n[2] Hastie, Trevor, et al. \"'Gene shaving'as a method for identifying distinct sets of genes with similar expression patterns.\" Genome biology 1.2 (2000): research0003-1."}}