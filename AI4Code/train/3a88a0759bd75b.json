{"cell_type":{"5179cc96":"code","f681ec84":"code","9e87aa4f":"code","44eec66e":"code","d337fd43":"code","0d825312":"code","fb5bda8c":"code","b0f8410a":"code","f5563453":"code","99fa2f1b":"code","17cfbeb0":"code","4bdc6c50":"code","5ebc6618":"code","698721d6":"code","4f2194d9":"markdown"},"source":{"5179cc96":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.multiclass import OneVsRestClassifier # required for multiclass classification\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import average_precision_score\nfrom sklearn import tree\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#   for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f681ec84":"train_df = pd.read_csv('..\/input\/fetal-health-classification\/fetal_health.csv') ","9e87aa4f":"# check if there is any null value\nfor i in train_df.columns:\n    if (train_df[i].isnull().any()):\n        print (\"Column: {}\".format(i))\n    else:\n        print(\"No null in column {}\".format(i))","44eec66e":"# number of unique classes\nclasses = train_df['fetal_health'].unique()\nprint(classes)\n","d337fd43":"# percentage of each class in the dataset\ncount_1 = 0\ncount_2 = 0\ncount_3 = 0\nfor i in range(len(train_df)):\n    if train_df[\"fetal_health\"].iloc[i] == 1:\n        count_1  = count_1 + 1\n    elif train_df[\"fetal_health\"].iloc[i] == 2:\n        count_2  = count_2 + 1\n    elif train_df[\"fetal_health\"].iloc[i] == 3:\n        count_3  = count_3 + 1\npercent1 = (count_1\/len(train_df))* 100\npercent2 = (count_2\/len(train_df))* 100\npercent3= (count_3\/len(train_df))* 100\nprint(\"Class 1 {}%\".format(percent1))\nprint(\"Class 2 {}%\".format(percent2))\nprint(\"Class 3 {}%\".format(percent3))            ","0d825312":"# the correlation between different columns in the \ncorr = train_df.corr()\ncorr.style.background_gradient(cmap='coolwarm').set_precision(2)\n","fb5bda8c":"# Preparing the dataset and splitting into train , test and validation\n# input: train dataframe\ndef preparing_training_data(train_df):\n    training_data_array = train_df.to_numpy()\n    print(\"[+] Training data shape: {}\".format(training_data_array.shape))\n    trainig = training_data_array[:,0:21]\n    label   = training_data_array[:,-1]\n    # binarizing the label\n    label_binarized = label_binarize(label, classes=[1 ,2, 3]) # similar to one hotencoding\n    n_classes = label_binarized.shape[1]\n    X_train, X_test, y_train, y_test = train_test_split(trainig, label_binarized, test_size=0.3, random_state=0)\n    print(\"[+] X_train shape: {}\".format(X_train.shape))\n    print(\"[+] X_test shape: {}\".format(X_test.shape))\n    print(\"[+] Y_train shape: {}\".format(y_train.shape))\n    return (n_classes, X_train, y_train, X_test, y_test)","b0f8410a":"# calling the functio: preparing_training_data(train_df)\nn_classes, X_train, y_train, X_test, y_test = preparing_training_data(train_df)","f5563453":"# Preparing an SVM model and trying\ndef linearSVM(X_train, y_train):\n    clf = OneVsRestClassifier(LinearSVC(random_state=0, tol=1e-5))\n    clf = make_pipeline(StandardScaler(), clf)\n    clf.fit(X_train,y_train)\n    return clf","99fa2f1b":"# trying kernel method on SVM \ndef kernelSVM(X_train, y_train):\n    kernel_clf = OneVsRestClassifier(SVC(decision_function_shape = 'ovo', class_weight = 'balanced'))\n    kernel_clf = make_pipeline(StandardScaler(), kernel_clf)\n    kernel_clf.fit(X_train,y_train)\n    return kernel_clf\n    ","17cfbeb0":"# trying decision tree on the classifier\ndef decison_tree_classifer(X_train, y_train):\n    decison_tree_clf = tree.DecisionTreeClassifier(criterion='entropy')\n    decison_tree_clf = decison_tree_clf.fit(X_train, y_train)\n    return decison_tree_clf","4bdc6c50":"# training the linear and kernel classifier classifier\ndef training_classifier(X_train, y_train, classifier):\n    model_classifer = None\n    if classifier == \"linear_svm\":\n        print(\"[+] ####### Testing with linear SVM ############\")\n        model_classifer = linearSVM(X_train, y_train)\n        test_score = model_classifer.score(X_test, y_test)\n        print(\"Test Score : {}\".format(test_score))\n    elif classifier == \"kernel_svm\":\n        print(\"[+] ####### Testing with kernel SVM ############\")\n        model_classifer = kernelSVM(X_train, y_train)\n        k_test_score = model_classifer.score(X_test, y_test)\n        print(\"Test Score : {}\".format(k_test_score))\n    elif classifier == \"decision_tree\":\n        print(\"[+] ####### Testing with decision tree ############\")\n        model_classifer = decison_tree_classifer(X_train, y_train)\n        score = model_classifer.score(X_test, y_test)\n        print(\"Test Score for decision ttree: {}\".format(score))\n        tree.plot_tree(model_classifer) \n    \n    return model_classifer","5ebc6618":"# function to predict test set\ndef predict_classifier(X_test, y_test, classifier, model_classifier):\n    if classifier == \"linear_svm\":\n        pred = model_classifier.predict(X_test)\n        print(\"[+] Pred Linear shape : {}\".format(pred.shape))\n    elif classifier == \"kernel_svm\":\n        pred = model_classifier.predict(X_test)\n        print(\"[+] Pred Kernel shape : {}\".format(pred.shape))\n    elif classifier == \"decision_tree\":\n        pred = model_classifier.predict(X_test)\n        print(\"[+] Pred Kernel shape : {}\".format(pred.shape))\n\n    return pred  ","698721d6":"# calculating Area under the Precision-Recall Curve, FI Score and Area under the ROC Curve\n# Compute ROC curve and ROC area for each class\nclassifier = \"decision_tree\"\nmodel_classifier = training_classifier(X_train, y_train, classifier)\npred = predict_classifier(X_test, y_test, classifier, model_classifier)\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], pred[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n# Plot of a ROC curve for a specific class\nfor i in range(n_classes):\n    plt.figure()\n    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic for class {}'.format(i))\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    \n# computing FI score\nf1score = f1_score(y_test, pred, average = 'macro')\nprint(\"[+] F1 Score for {} {}\".format(classifier, f1score))\n\n# plotting precison and recall curves\naverage_precision_linear = average_precision_score(y_test, pred, average = \"macro\")\nprint(\"[+] Average Precision for {} is {}\".format(classifier, average_precision_linear))\n\n# plotting precision and recall curve\nprecision = dict()\nrecall = dict()\nfor i in range(n_classes):\n    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],\n                                                        pred[:, i])\n    plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n\nplt.xlabel(\"recall\")\nplt.ylabel(\"precision\")\nplt.legend(loc=\"best\")\nplt.title(\"precision vs. recall curve for kernel SVM\")\nplt.show()\n","4f2194d9":"# studying the data carefully\n"}}