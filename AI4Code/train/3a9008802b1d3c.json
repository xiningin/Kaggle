{"cell_type":{"6fdd022a":"code","ac4eafec":"code","51dc54d8":"code","86ddb586":"code","4c82111c":"code","73ce74ca":"code","7883d520":"code","d029c99c":"code","9844e29e":"code","2d06ca3d":"code","a42674bd":"code","f6ae90d2":"code","5aa55963":"code","88d43409":"code","957ee6fb":"code","a520cc4f":"code","3446f5cb":"code","2f115dd0":"code","8adec2e5":"code","d50586a6":"code","330f4bb7":"markdown","50a6b57d":"markdown","6265b2a5":"markdown","745c6c44":"markdown","63fd7a38":"markdown","e2f027e2":"markdown","0ef87e64":"markdown","905c4afe":"markdown","3567e32b":"markdown","f36c9858":"markdown","81d1e6fc":"markdown","3c6ec7dd":"markdown","30c6e859":"markdown","5900b7ca":"markdown","8513e451":"markdown","eaf87b73":"markdown","60683028":"markdown","6b5253a4":"markdown","685af49b":"markdown","497ee841":"markdown","94f8da71":"markdown","27427a42":"markdown","00948173":"markdown","0e525d99":"markdown"},"source":{"6fdd022a":"import os\nimport numpy as np\nimport tensorflow as tf\nimport pandas as pd\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom scipy.spatial import Delaunay\nfrom sklearn.model_selection import train_test_split\n\nimport seaborn as sns\nsns.set()\nsns.set_style('white')","ac4eafec":"def find_adjacent(loc):\n\n    delau = Delaunay(loc)\n    adj = np.zeros((22, 22))\n    ind = np.arange(22)\n\n    for i in range(delau.simplices.shape[0]):\n        for j in delau.simplices[i]:\n            adj[ind[j], ind[delau.simplices[i]]] = 1\n\n    adj *= 1 - np.eye(22)\n    \n    return adj\n\n\ndef extract_feature(game, play, play_detail):\n\n    homeTeam, awayTeam = game.homeTeamAbbr.values[0], game.visitorTeamAbbr.values[0]\n    possessionTeam = play.possessionTeam.values[0]\n\n    vel = pd.concat([np.cos((- play_detail.dir.values + 90) \/ 360 * 2 * np.pi) * play_detail['s'], np.sin((- play_detail.dir.values + 90) \/ 360 * 2 * np.pi) * play_detail['s']], axis=1)\n    vel.columns = ['vel_x', 'vel_y']\n    play_detail = pd.concat([play_detail, vel], axis=1)\n\n    play_detail_football = play_detail.query('team == \"football\"')\n\n    if homeTeam == possessionTeam:\n        play_detail_offense, play_detail_defense = play_detail.query('team == \"away\"'), play_detail.query('team == \"home\"')\n        defense_team, offense_team = homeTeam, awayTeam\n    else:\n        play_detail_offense, play_detail_defense = play_detail.query('team == \"home\"'), play_detail.query('team == \"away\"')\n        offense_team, defense_team = homeTeam, awayTeam\n\n    returnerId = play.returnerId.values[0].split(';')[0]\n    play_detail_returner = play_detail_offense.query('nflId == %s' % returnerId)\n    returnerLine = play_detail_returner.x.values[0]\n\n    direction = 2 * np.float('left' == play_detail.playDirection.values[0]) - 1\n\n    position_returner = play_detail_returner.position.values\n    position_offense = play_detail_offense.position.values\n    position_defense = play_detail_defense.position.values\n\n    name_returner = play_detail_returner.displayName.values\n    name_offense = play_detail_offense.displayName.values\n    name_defense = play_detail_defense.displayName.values\n\n    is_not_returner = np.logical_not(np.any(name_offense == name_returner[:, np.newaxis], 0))\n\n    position = np.hstack([position_returner, position_offense[is_not_returner], position_defense])\n    name = np.hstack([name_returner, name_offense[is_not_returner], name_defense])\n\n    loc_returner = (play_detail_returner[['x', 'y']].values - np.array([returnerLine, 53.3 \/ 2])) * direction\n    loc_offense = (play_detail_offense[['x', 'y']].values - np.array([returnerLine, 53.3 \/ 2])) * direction\n    loc_defense = (play_detail_defense[['x', 'y']].values - np.array([returnerLine, 53.3 \/ 2])) * direction\n\n    vel_returner = play_detail_returner[['vel_x', 'vel_y']].values * direction\n    vel_offense = play_detail_offense[['vel_x', 'vel_y']].values * direction\n    vel_defense = play_detail_defense[['vel_x', 'vel_y']].values * direction\n    \n    loc = np.vstack([loc_returner, loc_offense[is_not_returner], loc_defense])\n    vel = np.vstack([vel_returner, vel_offense[is_not_returner], vel_defense])\n    \n    x = np.hstack([loc, vel])\n\n    adj = find_adjacent(loc)\n\n    y = np.minimum(play.kickReturnYardage.values[0], np.floor(loc[:, 0].max()))\n    c = y != np.floor(loc[:, 0].max())\n    \n    return x, adj, y, c, name, position, offense_team, defense_team","51dc54d8":"dirname = '\/kaggle\/input\/nfl-big-data-bowl-2022'\n\ngames = pd.read_csv(os.path.join(dirname, 'games.csv'))\nplays = pd.read_csv(os.path.join(dirname, 'plays.csv'))\nplayers = pd.read_csv(os.path.join(dirname, 'players.csv'))\n\npunt = plays.query('kickReturnYardage == kickReturnYardage and specialTeamsPlayType == \"Punt\" and not playDescription.str.contains(\"fair|try|PENALTY|Penalty|MUFFS|onside\")', engine='python')\nkick = plays.query('kickReturnYardage == kickReturnYardage and specialTeamsPlayType == \"Kickoff\" and not playDescription.str.contains(\"fair|try|PENALTY|Penalty|MUFFS|onside\")', engine='python')\nplays = kick\n\ntracking2018 = pd.read_csv(os.path.join(dirname, 'tracking2018.csv')).query('event == \"kick_received\" or event == \"punt_received\"')\ntracking2019 = pd.read_csv(os.path.join(dirname, 'tracking2019.csv')).query('event == \"kick_received\" or event == \"punt_received\"')\ntracking2020 = pd.read_csv(os.path.join(dirname, 'tracking2020.csv')).query('event == \"kick_received\" or event == \"punt_received\"')\ntracking = pd.concat([tracking2018, tracking2019, tracking2020], axis=0)","86ddb586":"xs, adjs, ys, cs = [], [], [], []\nnames, positions, offense_teams, defense_teams = [], [], [], []\n\ngameIds = plays.gameId.values\nplayIds = plays.playId.values\n\nind = 0\ninds = []\n\nfor gameId, playId in zip(gameIds, playIds):\n\n    game = games.query('gameId == %s' % gameId)\n    play = plays.query('gameId == %s and playId == %s' % (gameId, playId))\n    play_detail = tracking.query('gameId == %s and playId == %s' % (gameId, playId))\n\n    try:\n        x, adj, y, c, name, position, offense_team, defense_team = extract_feature(game, play, play_detail)\n\n        xs.append(x)\n        adjs.append(adj)\n        ys.append(y)\n        cs.append(c)\n\n        names.append(name)\n        positions.append(position)\n        offense_teams.append(offense_team)\n        defense_teams.append(defense_team)\n\n        inds.append(ind)\n        ind += 1\n\n    except:\n        pass\n\n    \nxs, adjs, ys, cs = np.stack(xs), np.stack(adjs), np.hstack(ys), np.array(cs).astype(np.int)\nnames, positions, offense_teams, defense_teams = np.vstack(names),  np.vstack(positions), np.hstack(offense_teams), np.hstack(defense_teams)\ninds = np.stack(inds)\n\n(inds, inds_eval, xs, xs_eval, adjs, adjs_eval, ys, ys_eval, cs, cs_eval,\n names, names_eval, positions, positions_eval, offense_teams, offense_teams_eval, defense_teams, defense_teams_eval) = train_test_split(inds, xs, adjs, ys, cs, names, positions, offense_teams, defense_teams, test_size=0.2, random_state=0)\n\n(inds_test, inds_eval, xs_test, xs_eval, adjs_test, adjs_eval, ys_test, ys_eval, cs_test, cs_eval,\n names_test, names_eval, positions_test, positions_eval, offense_teams_test, offense_teams_eval, defense_teams_test, defense_teams_eval) = train_test_split(inds_eval, xs_eval, adjs_eval, ys_eval, cs_eval, names_eval, positions_eval, offense_teams_eval, defense_teams_eval, test_size=0.5, random_state=0)","4c82111c":"X_orig, A_orig = tf.constant(xs, dtype=tf.float32), tf.constant(adjs, dtype=tf.float32)\nX_eval, A_eval = tf.constant(xs_eval, dtype=tf.float32), tf.constant(adjs_eval, dtype=tf.float32)\nX_test, A_test = tf.constant(xs_test, dtype=tf.float32), tf.constant(adjs_test, dtype=tf.float32)\n\nxs, adjs, ys, cs = np.vstack([xs, xs * np.array([1, -1, 1, -1])]), np.vstack([adjs, adjs]), np.hstack([ys, ys]), np.hstack([cs, cs])\nxs, adjs, ys, cs = xs[np.argsort(ys)], adjs[np.argsort(ys)], ys[np.argsort(ys)], cs[np.argsort(ys)]\nX, A = tf.constant(xs, dtype=tf.float32), tf.constant(adjs, dtype=tf.float32)\n\n\nn = xs.shape[0]\nys_unique, ys_index, ys_inverse, ys_count = np.unique(ys, return_index=True, return_inverse=True, return_counts=True)\n\nys_mask_index = np.arange(ys_unique[0], ys_unique[-1] + 1)\nys_mask = tf.constant(ys_mask_index[:, np.newaxis] == ys_unique, dtype=tf.float32)\n\ncs_count = []\nfor j in ys_unique:\n    cs_count.append(cs[ys == j].sum())\n\ncs_count = np.array(cs_count)\n\ncs_mask = np.zeros((n, ys_unique.shape[0]))\nfor j, index, count in zip(range(ys_unique.shape[0]), ys_index, ys_count):\n    cs_mask[index:index+count, j] = 1.\ncs_mask = tf.constant(cs_mask, dtype=tf.float32)\n\nmask = tf.constant(ys_index <= np.arange(n)[:, np.newaxis], dtype=tf.float32)\ninf_array = - tf.ones_like(mask, dtype=tf.float32) * np.inf\n\ndf_true = 0.5 * (tf.sign(ys_mask_index - ys_eval[:, tf.newaxis]) + 1)","73ce74ca":"class GGNN(tf.keras.Model):\n\n\n    def __init__(self):\n\n        super(GGNN, self).__init__()\n\n        self.gru_L = 10\n\n        self.denseGRU_R = tf.keras.Sequential([tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.tanh), tf.keras.layers.Dropout(dropout_rate),\n                                               tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.tanh), tf.keras.layers.Dropout(dropout_rate),\n                                               tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.tanh)])\n        self.denseGRU_O = tf.keras.Sequential([tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.tanh), tf.keras.layers.Dropout(dropout_rate),\n                                               tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.tanh), tf.keras.layers.Dropout(dropout_rate),\n                                               tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.tanh)])\n        self.denseGRU_D = tf.keras.Sequential([tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.tanh), tf.keras.layers.Dropout(dropout_rate),\n                                               tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.tanh), tf.keras.layers.Dropout(dropout_rate),\n                                               tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.tanh)])\n        \n        self.update_R, self.update_O, self.update_D = tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.sigmoid), tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.sigmoid), tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.sigmoid)\n        self.reset_R, self.reset_O, self.reset_D = tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.sigmoid), tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.sigmoid), tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.sigmoid)\n        self.modify_R, self.modify_O, self.modify_D = tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.tanh), tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.tanh), tf.keras.layers.Dense(n_layerGRU, activation=tf.nn.tanh)\n        \n        self.dropoutGRU_R, self.dropoutGRU_O, self.dropoutGRU_D = tf.keras.layers.Dropout(dropout_rate), tf.keras.layers.Dropout(dropout_rate), tf.keras.layers.Dropout(dropout_rate)\n        self.dropoutGRU_neighbor_R, self.dropoutGRU_neighbor_O, self.dropoutGRU_neighbor_D = tf.keras.layers.Dropout(dropout_rate), tf.keras.layers.Dropout(dropout_rate), tf.keras.layers.Dropout(dropout_rate)\n\n        self.dense_R, self.dense_O, self.dense_D = tf.keras.layers.Dense(1), tf.keras.layers.Dense(1), tf.keras.layers.Dense(1)\n        self.mask_R, self.mask_O, self.mask_D = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid), tf.keras.layers.Dense(1, activation=tf.nn.sigmoid), tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n    \n    def call(self, X, A, is_training=False):\n\n        X_R = tf.slice(X, [0, 0, 0], [-1, 1, -1])\n        X_O = tf.concat([tf.tile(X_R, (1, 10, 1)), tf.slice(X, [0, 1, 0], [-1, 10, -1])], axis=2)\n        X_D = tf.concat([tf.tile(X_R, (1, 11, 1)), tf.slice(X, [0, 11, 0], [-1, 11, -1])], axis=2)\n\n        layerGRU_R, layerGRU_O, layerGRU_D = self.denseGRU_R(X_R, is_training), self.denseGRU_O(X_O, is_training), self.denseGRU_D(X_D, is_training)\n       \n        maskGRU_update_R, maskGRU_update_O, maskGRU_update_D = self.dropoutGRU_R(tf.ones_like(layerGRU_R), is_training), self.dropoutGRU_O(tf.ones_like(layerGRU_O), is_training), self.dropoutGRU_D(tf.ones_like(layerGRU_D), is_training)\n        maskGRU_reset_R, maskGRU_reset_O, maskGRU_reset_D = self.dropoutGRU_R(tf.ones_like(layerGRU_R), is_training), self.dropoutGRU_O(tf.ones_like(layerGRU_O), is_training), self.dropoutGRU_D(tf.ones_like(layerGRU_D), is_training)\n        maskGRU_modify_R, maskGRU_modify_O, maskGRU_modify_D = self.dropoutGRU_R(tf.ones_like(layerGRU_R), is_training), self.dropoutGRU_O(tf.ones_like(layerGRU_O), is_training), self.dropoutGRU_D(tf.ones_like(layerGRU_D), is_training)\n\n        maskGRU_update_neighbor_R, maskGRU_update_neighbor_O, maskGRU_update_neighbor_D = self.dropoutGRU_neighbor_R(tf.ones(tf.shape(layerGRU_R) * (1, 1, 2)), is_training), self.dropoutGRU_neighbor_O(tf.ones(tf.shape(layerGRU_O) * (1, 1, 3)), is_training), self.dropoutGRU_neighbor_D(tf.ones(tf.shape(layerGRU_D) * (1, 1, 3)), is_training)\n        maskGRU_reset_neighbor_R, maskGRU_reset_neighbor_O, maskGRU_reset_neighbor_D = self.dropoutGRU_neighbor_R(tf.ones(tf.shape(layerGRU_R) * (1, 1, 2)), is_training), self.dropoutGRU_neighbor_O(tf.ones(tf.shape(layerGRU_O) * (1, 1, 3)), is_training), self.dropoutGRU_neighbor_D(tf.ones(tf.shape(layerGRU_D) * (1, 1, 3)), is_training)\n        maskGRU_modify_neighbor_R, maskGRU_modify_neighbor_O, maskGRU_modify_neighbor_D = self.dropoutGRU_neighbor_R(tf.ones(tf.shape(layerGRU_R) * (1, 1, 2)), is_training), self.dropoutGRU_neighbor_O(tf.ones(tf.shape(layerGRU_O) * (1, 1, 3)), is_training), self.dropoutGRU_neighbor_D(tf.ones(tf.shape(layerGRU_D) * (1, 1, 3)), is_training)\n\n        for l in range(self.gru_L):\n\n            layerGRU_neighbor_R = tf.concat([tf.matmul(A[:, :1, 1:11], layerGRU_O), tf.matmul(A[:, :1, 11:], layerGRU_D)], axis=-1)\n            layerGRU_neighbor_O = tf.concat([tf.matmul(A[:, 1:11, :1], layerGRU_R), tf.matmul(A[:, 1:11, 1:11], layerGRU_O), tf.matmul(A[:, 1:11, 11:], layerGRU_D)], axis=-1)\n            layerGRU_neighbor_D = tf.concat([tf.matmul(A[:, 11:, :1], layerGRU_R), tf.matmul(A[:, 11:, 1:11], layerGRU_O), tf.matmul(A[:, 11:, 11:], layerGRU_D)], axis=-1)\n\n            z_R = self.update_R(tf.concat([layerGRU_R * maskGRU_update_R, layerGRU_neighbor_R * maskGRU_update_neighbor_R], 2))\n            r_R = self.reset_R(tf.concat([layerGRU_R * maskGRU_reset_R, layerGRU_neighbor_R * maskGRU_reset_neighbor_R], 2))\n            layerGRU_modified_R = self.modify_R(tf.concat([layerGRU_R * r_R * maskGRU_modify_R, layerGRU_neighbor_R * maskGRU_modify_neighbor_R], 2))\n\n            z_O = self.update_O(tf.concat([layerGRU_O * maskGRU_update_O, layerGRU_neighbor_O * maskGRU_update_neighbor_O], 2))\n            r_O = self.reset_O(tf.concat([layerGRU_O * maskGRU_reset_O, layerGRU_neighbor_O * maskGRU_reset_neighbor_O], 2))\n            layerGRU_modified_O = self.modify_O(tf.concat([layerGRU_O * r_O * maskGRU_modify_O, layerGRU_neighbor_O * maskGRU_modify_neighbor_O], 2))\n\n            z_D = self.update_D(tf.concat([layerGRU_D * maskGRU_update_D, layerGRU_neighbor_D * maskGRU_update_neighbor_D], 2))\n            r_D = self.reset_D(tf.concat([layerGRU_D * maskGRU_reset_D, layerGRU_neighbor_D * maskGRU_reset_neighbor_D], 2))\n            layerGRU_modified_D = self.modify_D(tf.concat([layerGRU_D * r_D * maskGRU_modify_D, layerGRU_neighbor_D * maskGRU_modify_neighbor_D], 2))\n\n            layerGRU_R = (1. - z_R) * layerGRU_R + z_R * layerGRU_modified_R\n            layerGRU_O = (1. - z_O) * layerGRU_O + z_O * layerGRU_modified_O\n            layerGRU_D = (1. - z_D) * layerGRU_D + z_D * layerGRU_modified_D\n            \n        maskGRU_R, maskGRU_O, maskGRU_D = self.mask_R(layerGRU_R), self.mask_O(layerGRU_O), self.mask_D(layerGRU_D)\n        layerGRU_R, layerGRU_O, layerGRU_D = self.dense_R(layerGRU_R), self.dense_O(layerGRU_O), self.dense_D(layerGRU_D)\n           \n        out = tf.squeeze(layerGRU_R * maskGRU_R, 1) + tf.reduce_sum(layerGRU_O * maskGRU_O, 1) + tf.reduce_sum(layerGRU_D * maskGRU_D, 1)\n\n        return out\n\n\n    def call_players(self, X, A):\n\n        X_R = tf.slice(X, [0, 0, 0], [-1, 1, -1])\n        X_O = tf.concat([tf.tile(X_R, (1, 10, 1)), tf.slice(X, [0, 1, 0], [-1, 10, -1])], axis=2)\n        X_D = tf.concat([tf.tile(X_R, (1, 11, 1)), tf.slice(X, [0, 11, 0], [-1, 11, -1])], axis=2)\n\n        layerGRU_R, layerGRU_O, layerGRU_D = self.denseGRU_R(X_R), self.denseGRU_O(X_O), self.denseGRU_D(X_D)\n        \n        for l in range(self.gru_L):\n\n            layerGRU_neighbor_R = tf.concat([tf.matmul(A[:, :1, 1:11], layerGRU_O), tf.matmul(A[:, :1, 11:], layerGRU_D)], axis=-1)\n            layerGRU_neighbor_O = tf.concat([tf.matmul(A[:, 1:11, :1], layerGRU_R), tf.matmul(A[:, 1:11, 1:11], layerGRU_O), tf.matmul(A[:, 1:11, 11:], layerGRU_D)], axis=-1)\n            layerGRU_neighbor_D = tf.concat([tf.matmul(A[:, 11:, :1], layerGRU_R), tf.matmul(A[:, 11:, 1:11], layerGRU_O), tf.matmul(A[:, 11:, 11:], layerGRU_D)], axis=-1)\n\n            z_R = self.update_R(tf.concat([layerGRU_R, layerGRU_neighbor_R], 2))\n            r_R = self.reset_R(tf.concat([layerGRU_R, layerGRU_neighbor_R], 2))\n            layerGRU_modified_R = self.modify_R(tf.concat([layerGRU_R * r_R, layerGRU_neighbor_R], 2))\n\n            z_O = self.update_O(tf.concat([layerGRU_O, layerGRU_neighbor_O], 2))\n            r_O = self.reset_O(tf.concat([layerGRU_O, layerGRU_neighbor_O], 2))\n            layerGRU_modified_O = self.modify_O(tf.concat([layerGRU_O * r_O, layerGRU_neighbor_O], 2))\n\n            z_D = self.update_D(tf.concat([layerGRU_D, layerGRU_neighbor_D], 2))\n            r_D = self.reset_D(tf.concat([layerGRU_D, layerGRU_neighbor_D], 2))\n            layerGRU_modified_D = self.modify_D(tf.concat([layerGRU_D * r_D, layerGRU_neighbor_D], 2))\n\n            layerGRU_R = (1. - z_R) * layerGRU_R + z_R * layerGRU_modified_R\n            layerGRU_O = (1. - z_O) * layerGRU_O + z_O * layerGRU_modified_O\n            layerGRU_D = (1. - z_D) * layerGRU_D + z_D * layerGRU_modified_D\n\n        maskGRU_R, maskGRU_O, maskGRU_D = self.mask_R(layerGRU_R), self.mask_O(layerGRU_O), self.mask_D(layerGRU_D)\n        layerGRU_R, layerGRU_O, layerGRU_D = self.dense_R(layerGRU_R), self.dense_O(layerGRU_O), self.dense_D(layerGRU_D)\n        \n        return tf.concat([layerGRU_R * maskGRU_R, layerGRU_O * maskGRU_O, layerGRU_D * maskGRU_D], axis=1)\n\n    \n\ndef compute_cost(model, X, A):\n\n    out = model.call(X, A, True)\n\n    out_max = tf.reduce_max(tf.where(tf.cast(mask, tf.bool), out, inf_array), 0)\n    exp_sum = tf.reduce_sum(tf.exp(out - out_max) * mask, 0)\n    den = (out_max + tf.math.log(exp_sum)) * cs_count\n\n    cost = - tf.reduce_sum(tf.reduce_sum(out * cs_mask, 1) * cs) + tf.reduce_sum(den)\n\n    return cost\n\n\n@tf.function\ndef compute_gradients(model, X, A):\n\n    with tf.GradientTape() as tape:\n        cost = compute_cost(model, X, A)\n\n    return tape.gradient(cost, model.trainable_variables), cost\n\n\ndef apply_gradients(optimizer, gradients, variables):\n\n    optimizer.apply_gradients(zip(gradients, variables))\n\n\ndef compute_baseline_hazard(model, X, A):\n\n    out = model.call(X, A, False)\n\n    out_max = tf.reduce_max(tf.where(tf.cast(mask, tf.bool), out, inf_array), 0)\n    exp_sum = tf.reduce_sum(tf.exp(out - out_max) * mask, 0)\n    den = (out_max + tf.math.log(exp_sum)) * cs_count\n\n    baseline_hazard = np.sum(ys_mask * tf.exp(- out_max) * exp_sum.numpy() ** -1 * cs_count, axis=1)\n\n    return baseline_hazard\n\ndef compute_hazard_ratio(model, X, A):\n\n    out = model.call(X, A, False)\n    hazard_ratio = tf.exp(out).numpy()\n\n    return hazard_ratio\n\n\ndef compute_concordance_index(hazard_ratio_eval, ys_eval, cs_eval):\n\n    n_eval = ys_eval.shape[0]\n    permissible = 0\n    concordance = 0\n    \n    for i in range(n_eval):\n        for j in range(i+1, n_eval):\n            if ys_eval[i] != ys_eval[j] and not ((ys_eval[i] < ys_eval[j]) * (cs_eval[i] == 0)) and not ((ys_eval[i] > ys_eval[j]) * (cs_eval[j] == 0)) :\n                permissible += 1\n                if ((hazard_ratio_eval[i] > hazard_ratio_eval[j]) * (ys_eval[i] < ys_eval[j])) or ((hazard_ratio_eval[i] < hazard_ratio_eval[j]) * (ys_eval[i] > ys_eval[j])):\n                    concordance += 1\n\n    c_index = concordance \/ permissible\n\n    return c_index","7883d520":"print('Training ...')\n\nlearning_rate = 0.01\ndropout_rate = 0.5\nn_layerGRU = 32\n\nn_ties = ys_unique.shape[0]\n\nmodel = GGNN()\noptimizer = tf.keras.optimizers.Adam(learning_rate)\n\ncheckpoint_dir = '.\/training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(model=model, optimizer=optimizer)\n\ntraning_epochs = 2000\n\nc_index_best = 0.\n\nfor epoch in range(traning_epochs):\n\n    gradients, cost_epoch = compute_gradients(model, X, A)\n    apply_gradients(optimizer, gradients, model.variables)\n\n    if (epoch + 1) % 100 == 0:\n\n        hazard_ratio_eval = compute_hazard_ratio(model, X_eval, A_eval)\n        c_index = compute_concordance_index(hazard_ratio_eval, ys_eval, cs_eval)\n        print('epoch %s : cost %s: c-index %s' % (epoch+1, np.around(cost_epoch.numpy(), 2), np.around(c_index, 4)))\n        \n        if c_index_best < c_index:\n            c_index_best = c_index\n            checkpoint.save(file_prefix=checkpoint_prefix)\n\ncheckpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\nhazard_ratio_test = compute_hazard_ratio(model, X_test, A_test)\nc_index_test = compute_concordance_index(hazard_ratio_test, ys_test, cs_test)\nout_players = model.call_players(X, A)\nout_players_mean = tf.concat([tf.reduce_mean(tf.reduce_sum(out_players, -1)[:, :1]) * tf.ones(1), tf.reduce_mean(tf.reduce_sum(out_players, -1)[:, 1:11]) * tf.ones(10), tf.reduce_mean(tf.reduce_sum(out_players, -1)[:, 11:]) * tf.ones(11)], axis=-1)\nbaseline_hazard = compute_baseline_hazard(model, X, A)","d029c99c":"def draw_field(returnerLine, direction):\n    \n    fig, ax = plt.subplots(figsize=(12, 12))\n    \n    if direction == 1.:\n\n        ax.hlines(-53.3\/2, -returnerLine, 120-returnerLine, color='black')\n        ax.hlines(53.3\/2, -returnerLine, 120-returnerLine, color='black')\n\n        ax.vlines(np.arange(0-returnerLine, 130-returnerLine, 10), -53.3\/2, 53.3\/2, color='black')\n        ax.vlines(np.arange(15-returnerLine, 115-returnerLine, 10), -53.3\/2, 53.3\/2, color='black', lw=1.)\n\n        ax.add_patch(plt.Rectangle((-returnerLine, -53.3\/2), 10, 53.3, fc='black', alpha=0.1))\n        ax.add_patch(plt.Rectangle((110-returnerLine, -53.3\/2), 10, 53.3, fc='black', alpha=0.1))\n\n    else:\n\n        ax.hlines(-53.3\/2, returnerLine-120, returnerLine, color='black')\n        ax.hlines(53.3\/2, returnerLine-120, returnerLine, color='black')\n\n        ax.vlines(np.arange(returnerLine-120, returnerLine+10, 10), -53.3\/2, 53.3\/2, color='black')\n        ax.vlines(np.arange(returnerLine-105, returnerLine-5, 10), -53.3\/2, 53.3\/2, color='black', lw=1.)\n\n        ax.add_patch(plt.Rectangle((returnerLine-120, -53.3\/2), 10, 53.3, fc='black', alpha=0.1))\n        ax.add_patch(plt.Rectangle((returnerLine-10, -53.3\/2), 10, 53.3, fc='black', alpha=0.1))\n        \n    return fig, ax\n        \n    \n\ndef draw_play(game, play, play_detail, additional_inputs=None):\n    \n    if additional_inputs is not None:\n        xinit, adjinit, xnew, adjnew = additional_inputs\n        plot_new = True\n    else:\n        x, adj, _, _, _, _, _, _ = extract_feature(game, play, play_detail)\n        xinit, adjinit = tf.constant(x[tf.newaxis], dtype=tf.float32), tf.constant(adj[tf.newaxis], dtype=tf.float32)\n        plot_new = False\n    \n    n_offense, n_defense = 11, 11\n    n = n_offense + n_defense\n\n    returnerId = play.returnerId.values[0].split(';')[0]\n    play_detail_returner = play_detail.query('nflId == %s' % returnerId)\n    returnerLine = play_detail_returner.x.values[0]\n    direction = 2 * np.float('left' == play_detail.playDirection.values[0]) - 1\n    \n    # init\n    \n    out = model.call_players(xinit, adjinit)\n    score = np.squeeze(out.numpy()) - out_players_mean\n    loc, vel = xinit[0, :, :2].numpy(), xinit[0, :, 2:4].numpy()\n    \n    G = nx.Graph()\n\n    G.add_nodes_from(np.arange(n_offense), bipartite=0)\n    G.add_nodes_from(np.arange(n_offense, n_offense + n_defense), bipartite=1)\n    node_color = ['r']\n    node_color.extend(['b' for i in range(n_offense - 1)])\n    node_color.extend(['g' for i in range(n_defense)])\n\n    row, col = np.where(adjinit[0] != 0)\n    G.add_edges_from(zip(row, col))\n\n    # new\n    if plot_new:\n\n        outnew = model.call_players(xnew, adjnew)\n        scorenew = np.squeeze(outnew.numpy()) - out_players_mean\n        locnew, velnew = xnew[0, :, :2].numpy(), xnew[0, :, 2:4].numpy()\n\n        Gnew = nx.Graph()\n\n        Gnew.add_nodes_from(np.arange(n_offense), bipartite=0)\n        Gnew.add_nodes_from(np.arange(n_offense, n_offense + n_defense), bipartite=1)\n        node_color = ['r']\n        node_color.extend(['b' for i in range(n_offense - 1)])\n        node_color.extend(['g' for i in range(n_defense)])\n\n        row, col = np.where(adjnew[0] != 0)\n        Gnew.add_edges_from(zip(row, col))\n\n    # plot \n\n    fig, ax = draw_field(returnerLine, direction)\n    \n    if plot_new:\n        \n        nx.draw_networkx_nodes(G, loc, node_color=node_color, node_size=1000, alpha=0.2, ax=ax)\n        nx.draw_networkx_edges(G, loc, alpha=0.1, style='dashed', edge_color='k', ax=ax)\n\n        nx.draw_networkx_nodes(Gnew, locnew, node_color=node_color, node_size=1000, alpha=1., ax=ax)\n        nx.draw_networkx_edges(Gnew, locnew, alpha=0.5, style='dashed', edge_color='k', ax=ax)\n        nx.draw_networkx_labels(Gnew, locnew, {i: np.around(np.exp(scorenew[i]), 2) for i in range(n)}, font_weight='bold', font_color='white', ax=ax)\n\n        for i in range(n):\n            ax.arrow(locnew[i, 0], locnew[i, 1], velnew[i, 0] \/ 2. + 0.01, velnew[i, 1] \/ 2. + 0.01, width=0.01, head_width=0.3,head_length=0.3,length_includes_head=True, color='k', alpha=0.4)\n\n    else:\n        \n        nx.draw_networkx_nodes(G, loc, node_color=node_color, node_size=1000, alpha=1., ax=ax)\n        nx.draw_networkx_edges(G, loc, alpha=0.5, style='dashed', edge_color='k', ax=ax)\n        nx.draw_networkx_labels(G, loc, {i: np.around(np.exp(score[i]), 2) for i in range(n)}, font_weight='bold', font_color='white', ax=ax)\n\n        for i in range(n):\n            ax.arrow(loc[i, 0], loc[i, 1], vel[i, 0] \/ 2. + 0.01, vel[i, 1] \/ 2. + 0.01, width=0.01, head_width=0.3,head_length=0.3,length_includes_head=True, color='k', alpha=0.4)\n    \n    xmin, ymin = loc.min(0)\n    xmax, ymax = loc.max(0)\n\n    ax.vlines(play.kickReturnYardage.values[0], ymin-5, ymax+5, color='goldenrod', linestyle='solid', alpha=0.5)\n    ax.set_xlim(xmin-5, xmax+5)\n    ax.set_ylim(ymin-5, ymax+5)\n    \n    if plot_new:\n        print(\"[BEFORE] OFFENSE: %s, DEFENSE: %s, TOTAL: %s, RETURN YARDAGE: %s\" % (np.around(np.exp(np.sum(score[:11])), 2), np.around(np.exp(np.sum(score[11:])), 2), np.around(np.exp(np.sum(score)), 2), play.kickReturnYardage.values[0]))\n        print(\"[AFTER]  OFFENSE: %s, DEFENSE: %s, TOTAL: %s\" % (np.around(np.exp(np.sum(scorenew[:11])), 2), np.around(np.exp(np.sum(scorenew[11:])), 2), np.around(np.exp(np.sum(scorenew)), 2)))\n    else:\n        print(\"OFFENSE: %s, DEFENSE: %s, TOTAL: %s, RETURN YARDAGE: %s\" % (np.around(np.exp(np.sum(score[:11])), 2), np.around(np.exp(np.sum(score[11:])), 2), np.around(np.exp(np.sum(score)), 2), play.kickReturnYardage.values[0]))","9844e29e":"i = 1539\ngameId, playId = gameIds[i], playIds[i]\n\ngame = games.query('gameId == %s' % gameId)\nplay = plays.query('gameId == %s and playId == %s' % (gameId, playId))\nplay_detail = tracking.query('gameId == %s and playId == %s' % (gameId, playId))\n\nx, adj, y, c, position, name, offense_team, defense_team = extract_feature(game, play, play_detail)\ndraw_play(game, play, play_detail)","2d06ca3d":"hazard_ratio = compute_hazard_ratio(model, tf.constant(x[np.newaxis], dtype=tf.float32), tf.constant(adj[np.newaxis], dtype=tf.float32))\nhazard = baseline_hazard * hazard_ratio\nhazard_mean = baseline_hazard * tf.exp(tf.reduce_sum(out_players_mean))\n\nplt.figure(figsize=(18, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(ys_mask_index, hazard[0], color='b')\nplt.plot(ys_mask_index, hazard_mean, color='b', linestyle='dashed')\nplt.axvline(play.kickReturnYardage.values[0], color='goldenrod')\n\nplt.xlim(ys_mask_index[0], ys_mask_index[-1])\n_ = plt.xlabel('Yardage')\n_ = plt.ylabel('Hazard')\n\nplt.subplot(1, 2, 2)\nplt.plot(ys_mask_index, 1. - np.exp(- np.cumsum(hazard)), color='b')\nplt.plot(ys_mask_index, 1. - np.exp(- np.cumsum(hazard_mean)), color='b', linestyle='dashed')\nplt.axvline(play.kickReturnYardage.values[0], color='goldenrod')\n\nplt.xlim(ys_mask_index[0], ys_mask_index[-1])\nplt.ylim(0., 1.)\n_ = plt.xlabel('Yardage')\n_ = plt.ylabel('Cumulative probability')","a42674bd":"teams = np.unique(offense_teams)\n\nout_players =  model.call_players(X_orig, A_orig)\n\nscore_offense_teams = pd.Series([np.exp(tf.reduce_mean(tf.reduce_sum((out_players[:, :, 0] - out_players_mean)[offense_teams == team][:, :11], 1))) for team in teams], index=teams)\nscore_offense_teams = score_offense_teams.sort_values()\nscore_defense_teams = pd.Series([np.exp(tf.reduce_mean(tf.reduce_sum((out_players[:, :, 0] - out_players_mean)[offense_teams == team][:, 11:], 1))) for team in teams], index=teams)\nscore_defense_teams = score_defense_teams.sort_values(ascending=False)","f6ae90d2":"fig, ax = plt.subplots(figsize=(18, 4))\nax.bar(score_offense_teams.index, score_offense_teams.values-1, color='b')\nax.axhline(y=0, linewidth=1, color='k', linestyle='dashed')\n_ = ax.set_yticks(ax.get_yticks(), np.around(ax.get_yticks()+1, 3))\n_ = ax.set_ylabel('Hazard ratio')","5aa55963":"fig, ax = plt.subplots(figsize=(18, 4))\nax.bar(score_defense_teams.index, score_defense_teams.values-1, color='g')\nax.axhline(y=0, linewidth=1, color='k', linestyle='dashed')\n_ = ax.set_yticks(ax.get_yticks(), np.around(ax.get_yticks()+1, 3))\n_ = ax.set_ylabel('Hazard ratio')","88d43409":"i = 666\n\ngameId, playId = gameIds[i], playIds[i]\n\ngame = games.query('gameId == %s' % gameId)\nplay = plays.query('gameId == %s and playId == %s' % (gameId, playId))\nplay_detail = tracking.query('gameId == %s and playId == %s' % (gameId, playId))\n\nx, adj, y, c, position, name, offense_team, defense_team = extract_feature(game, play, play_detail)","957ee6fb":"draw_play(game, play, play_detail)","a520cc4f":"xinit, adjinit = tf.constant(x[np.newaxis], dtype=tf.float32), tf.constant(adj[np.newaxis], dtype=tf.float32)\n\nxnew_returner = tf.Variable(xinit[:, :1], dtype=tf.float32)\nxnew_offence = tf.Variable(xinit[:, 1:11], dtype=tf.float32)\nxnew_defence = tf.Variable(xinit[:, 11:], dtype=tf.float32)\nxnew = tf.concat([xnew_returner, xnew_offence, xnew_defence], axis=1)\n\nadjnew = tf.constant(adj[np.newaxis], dtype=tf.float32)\n\n\n@tf.function\ndef compute_gradients_xnew(xnew_returner, xnew_offence, xnew_defence):\n\n    with tf.GradientTape() as tape:\n        xnew = tf.concat([xnew_returner, xnew_offence, xnew_defence], axis=1)\n        cost = tf.reduce_sum(model.call(xnew, adjnew, False))\n\n    gradients = tape.gradient(cost, [xnew_offence])\n    \n    return gradients, cost\n\n\nmodification_optimizer = tf.keras.optimizers.Adam(0.01)\n\nxnew_candidates = []\ncost_candidates = []\n\nfor epoch in range(500):\n\n    gradients, cost = compute_gradients_xnew(xnew_returner, xnew_offence, xnew_defence)\n    modification_optimizer.apply_gradients(zip(gradients, [xnew_offence]))\n    xnew = tf.concat([xnew_returner, xnew_offence, xnew_defence], axis=1)\n\n    if not np.all(adjnew == find_adjacent(xnew[0, :, :2])):\n        xnew_candidates.append(xnew)\n        cost_candidates.append(cost)\n        adjnew = tf.constant(find_adjacent(xnew[0, :, :2])[np.newaxis], dtype=tf.float32)\n        \nxnew = xnew_candidates[tf.math.argmin(cost_candidates)]\nadjnew = tf.constant(find_adjacent(xnew[0, :, :2])[np.newaxis], dtype=tf.float32)","3446f5cb":"draw_play(game, play, play_detail, additional_inputs=[xinit, adjinit, xnew, adjnew])","2f115dd0":"@tf.function\ndef compute_gradients_no_graph(model, X, A):\n\n    with tf.GradientTape() as tape:\n        cost = compute_cost(model, X, A)\n\n    return tape.gradient(cost, model.trainable_variables), cost","8adec2e5":"print('Training ...')\n\nmodel_no_graph = GGNN()\noptimizer_no_graph = tf.keras.optimizers.Adam(learning_rate)\n\ncheckpoint_no_graph_dir = '.\/training_checkpoints_no_graph'\ncheckpoint_no_graph_prefix = os.path.join(checkpoint_no_graph_dir, \"ckpt_no_graph\")\ncheckpoint_no_graph = tf.train.Checkpoint(model_no_graph=model_no_graph, optimizer_no_graph=optimizer_no_graph)\n\ntraning_epochs = 2000\n\nc_index_no_graph_best = 0.\n\nfor epoch in range(traning_epochs):\n\n    gradients, cost_epoch = compute_gradients_no_graph(model_no_graph, X, tf.zeros_like(A))\n    apply_gradients(optimizer_no_graph, gradients, model_no_graph.variables)\n\n    if (epoch + 1) % 100 == 0:\n\n        hazard_ratio_eval_no_graph = compute_hazard_ratio(model_no_graph, X_eval, tf.zeros_like(A_eval))\n        c_index_no_graph = compute_concordance_index(hazard_ratio_eval_no_graph, ys_eval, cs_eval)\n        print('epoch %s : cost %s: c-index %s' % (epoch+1, np.around(cost_epoch.numpy(), 4), np.around(c_index_no_graph, 4)))\n        \n        if c_index_no_graph_best < c_index_no_graph:\n            c_index_no_graph_best = c_index_no_graph\n            checkpoint_no_graph.save(file_prefix=checkpoint_no_graph_prefix)\n            \ncheckpoint_no_graph.restore(tf.train.latest_checkpoint(checkpoint_no_graph_dir))\nhazard_ratio_no_graph_test = compute_hazard_ratio(model_no_graph, X_test, tf.zeros_like(A_test))\nc_index_no_graph_test = compute_concordance_index(hazard_ratio_no_graph_test, ys_test, cs_test)","d50586a6":"print('With graph: %s, Without graph: %s' % (np.around(c_index_test, 4), np.around(c_index_no_graph_test, 4)))","330f4bb7":"Our aim is to estimate how each player affects this hazard. It is not sufficient to evaluate players' contributions by simple stats like obtained yards, touchdowns, and tackles. When a returner gains long yards after a kickoff, how other offensive players contribute to this gain is unclear. Using hazard values enables us to compare players' contributions between different positions. ","50a6b57d":"![hazard_rate_od.png](attachment:80e1041b-e5cd-4b93-bcfd-8fd66c779a96.png)","6265b2a5":"# Conclusion and future work\n\nIn this notebook, we propose the hazard modeling for kickoff and punt returns. Our model decomposes the hazard of return yardage into the sum of players' contributions. This idea provides new metrics for offensive and defensive formation in a data-driven manner.\n\nOur model only focuses on the formations and ignore the skill of the players. The team which achieved the smallest hazard is good at making better offensive formation, but it does not mean that this team gains the most yards; it also depends on the ability of the returners and blockers. How to incorporate the skills of each player into hazard modeling is future work. ","745c6c44":"This figure shows the mean hazard of the defensive players for each team. The team listed on the left achieves the larger hazard, which means that this team succeeded to block returners of opponent teams.","63fd7a38":"Here, we show an example. In this play, our model assigns the relatively large hazard to the offensive formation.","e2f027e2":"# Application 1: Model training ","0ef87e64":"Hazard modeling aims to model the duration of time until some events happen given covariate information. For example, to know the efficacy of the medicine, we investigate how the medicine decreases the death rate.\nIn hazard modeling, we estimate the hazard function instead of the probability density function. The hazard function is the instantaneous rate of the event occurrence. \n\nWe assume that the return yardage is a time duration of events. Let $y$ be return yardage. The obtained yardage takes a discrete value, so we here estimate the discrete hazard function\n\n$$\n\\begin{aligned}\nh(y) = \\mathrm{Pr}(y \\leq Y < y + 1 \\mid Y \\geq y),\n\\end{aligned}\n$$\n\nThis function explains the probability of a returner being stopped at $y$.\n\nAfter a returner receives a ball, the defensive players try to stop this returner as soon as possible, whereas the offensive players prevent the defensive players from tackling the returner. In terms of the hazard function, defensive players try to increase $h(y)$, and offensive players decrease $h(y)$. ","905c4afe":"The next figure shows the estimation results. The value assigned to each player is the hazard ratio compared to the mean hazard. For example, if the hazard for the offensive player is 1.05, it means that this player increases the mean hazard of the all offensive players by 1.05 times.","3567e32b":"This figure shows the mean hazard of the teams in offensive plays. The team listed on the left achieves the smaller hazard, which means that this team obtained longer yardage after kickoffs.","f36c9858":"# Hazard modeling of return yardage","81d1e6fc":"The yardage gained by a returner after kickoff and punt is strongly affected by defensive and offensive formations. These formations determine what kind of interactions between players occurs , which in turn affects the returner's route. We can observe the return yardage and who blocks the returner; however, how other players influence on the return yard is unclear. \n\nTo evaluate the contributions of all players, we adopt **Cox proportional hazard model** to express the distribution of the return yardage. We decompose the **hazard**, which is the rate of the returner being stopped, to the sum of the contributions of each player. To consider the interaction between players, we use a gated graph neural network that utilizes the Delaunay triangulation.\n\nThis notebook consists of the following topics.\n\n* Explanation of how to use hazard model for return yardage after kickoff and punt\n* Definition of Cox proportional hazard model with gated graph neural networks\n* Application 1: Model training \n* Application 2: Ranking of teams \n* Application 3: How to find better offensive formation\n* Appendix: Comparison with hazard model without graph","3c6ec7dd":"# Application 2: Ranking of teams ","30c6e859":"# Appendix: Comparison with hazard model without graph","5900b7ca":"![GGNN.png](attachment:5ef72eab-17ec-43cd-854e-9be433a4c465.png)","8513e451":"# Application 3: How to find better offensive formation","eaf87b73":"The total hazard rate indicates the performance of a formation and can be used as an indicator of a team's defense or offense. We calculate the mean hazard of each team in 2018 -- 2020 seasons. ","60683028":"Our model is able to evaluate the hazards of an offensive formation. We can use this to find better offensive formations by minimizing the assigned hazards with respect to player location and velocity.","6b5253a4":"We adopt **Cox proportional model** to express the hazard function. Cox proportional model divides the hazard function into two parts as\n\n$$\n\\begin{aligned}\n    h(y) = h_0(y) \\cdot \\exp(\\phi(x)), \\, \\text{$x$ : covariates.}\n\\end{aligned}\n$$\n\n\nThe former part indicates how the hazard function depends on the yardage and the latter part indicates how it depends on the covariate information. The Cox model estimates the former part in a semiparametric manner without any model specification.\n\nWe define $\\phi(x)$ as the summation of the contributions of players.\n$$\n\\begin{aligned}\n    \\phi(x) =  \\phi_\\mathrm{R}(x_\\mathrm{R} \\mid x) + \\sum_{i=1}^{10} \\phi_\\mathrm{O}(x^{(i)}_\\mathrm{O} \\mid x) + \\sum_{j=1}^{11} \\phi_\\mathrm{D}(x^{(j)}_\\mathrm{D} \\mid x).\n\\end{aligned}\n$$\nHere, $x_\\mathrm{R}, \\{x^{(i)}_\\mathrm{O}\\}_{i=1, \\cdots, 10} \\,\\, ,  \\{x^{(j)}_\\mathrm{D}\\}_{j=1, \\cdots, 11} \\, \\, $ are player's information for a returner, offensive players and defensive players. Specifically, we use players' locations and velocities when the returner recieves the ball as $x$. $\\phi_\\mathrm{R}(\\cdot), \\phi_\\mathrm{O}(\\cdot), \\phi_\\mathrm{D}(\\cdot)$ are estimand functions that transform players' information into hazards.\n\nEach player's contribution to the hazard is also affected by nearby players. We express these interactions as graph expressions. \nFirst, we calculate the Delaunay diagram from players' locations and construct a graph that indicates the pairs of nearby players.\nUnder this graph, we adopt **Gated Graph Neural Network** for expressing $\\phi_\\mathrm{R}(\\cdot), \\phi_\\mathrm{O}(\\cdot), \\phi_\\mathrm{D}(\\cdot)$. ","685af49b":"# Cox proportional hazard model with gated graph neural networks","497ee841":"In this notebook, we focus on **kickoff** plays and construct the hazard model for kickoff returns. We first extract players' locations and velocities when the returner receives the ball, and then split the data into three partitions; the first partition for model training, the second one for model validation, and the last one for model evaluation. \n\nWe omit the details of our model, but this notebook contains the full implementation of it. For details of gated graph neural networks, check the following paper.\n* Li et al., Gated Graph Sequence Neural Networks, ICLR, 2020.","94f8da71":"We here show how the graph structure improves the prediction performance. By defining the adjacent matrix as a zero matrix, the hazard under our model ignores interaction between players and reduces to the independent sum of the values obtained from each players' information. To evaluate the prediction performance, we calculate the **concordance index**; the larger concordance index means that better prediction performance. ","27427a42":"Our model assumes that the changes of hazard along to yardage axis do not change across data. The left figure shows the obtained hazard. The offensive and defensive formations change the scale of the hazard; the solid line indicates the hazard rate of this play and the dashed line indicates the mean hazard rate obtained from all plays. The right figure shows the cumulative distribution functions. The yellow line is the obtained yard in this play.","00948173":"The following figure shows the obtained offense formation.","0e525d99":"We maximize the total hazard with respect to offensive players' locations and velocities. We fix the returner and defensive players. "}}