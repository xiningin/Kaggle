{"cell_type":{"3f640206":"code","c24a3e80":"code","9b013d3e":"code","0205e357":"code","b0f14235":"code","aedad9bf":"code","c38dc80c":"code","a325c3a6":"code","892f4654":"code","83fe7be1":"code","1a72e288":"code","7743d6e0":"code","40b6e9cb":"code","b2d1674e":"code","7402af4f":"code","4dce3396":"code","1aa1d0f1":"code","ab436125":"code","6d325e88":"code","4a06ad10":"code","a9077d24":"code","2b3c2faf":"code","ffcc2f8e":"markdown","551414ea":"markdown","150319d6":"markdown","874158ce":"markdown","9395521d":"markdown","fb4c200b":"markdown","7da8d221":"markdown","3bbbaa53":"markdown","bc06891c":"markdown","29cbe640":"markdown","5eda0bc4":"markdown","2e8d5a5b":"markdown","0d7feee1":"markdown"},"source":{"3f640206":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA","c24a3e80":"corona_pd=pd.read_csv(\"..\/input\/graduate-admissions\/Admission_Predict_Ver1.1.csv\")\ncorona_pd.head()","9b013d3e":"#Returns the  meta data of the dataset.\ncorona_pd.info()","0205e357":"#Returns the information like mean,max,min,etc., of the dataset.\ncorona_pd.describe()","b0f14235":"#To remove the columns of the DataFrame in memory.\ncorona_pd.drop([\"Serial No.\",\"Chance of Admit \"],axis=1,inplace=True)\ncorona_pd.head()","aedad9bf":"#Returns the sum of null values under each column.\ncorona_pd.isnull().sum()","c38dc80c":"#To check whether the row contains duplicate values or not.\ncorona_pd.duplicated()","a325c3a6":"#To plot a correlation matrix between features.\nf,ax= plt.subplots(figsize=(10,10))\nsns.heatmap(corona_pd.corr(),annot=True)","892f4654":"#To scale the values along columns.\nscaler= StandardScaler()\ncorona_pd_scaled=scaler.fit_transform(corona_pd)","83fe7be1":"#To get the Within Cluster Sum of Squares(WCSS) for each cluster count to find the optimal K value(i.e cluster count).\nscores=[]\nfor i in range(1,20):\n    corona_means=KMeans(n_clusters=i)\n    corona_means.fit(corona_pd_scaled)\n    scores.append(corona_means.inertia_)","1a72e288":"#Plotting the values obtained to get the optimal K-value.\nplt.plot(scores,\"-rx\")","7743d6e0":"#Applying K-means algorithm with the obtained K value.\ncorona_means=KMeans(n_clusters=3)\ncorona_means.fit(corona_pd_scaled)","40b6e9cb":"#Returns an array with cluster labels to which it belongs.\nlabels=corona_means.labels_","b2d1674e":"#Creating a Dataframe with cluster centres(The example which is taken as center for each cluster)-If you are not familiar ,learn about k-means through the link given at last.\ncorona_pd_m=pd.DataFrame(corona_means.cluster_centers_,columns=corona_pd.columns)\ncorona_pd_m.head()","7402af4f":"#Inverting the scaled values to original values to get a better view.\ncorona_cluster=scaler.inverse_transform(corona_pd_m)\ncorona_cluster=pd.DataFrame(corona_cluster,columns=corona_pd.columns)\ncorona_cluster.head()","4dce3396":"#Concatenating the cluster labels.\ncorona_cluster=pd.concat([corona_pd,pd.DataFrame({\"Cluster\":labels})],axis=1)\ncorona_cluster.head()","1aa1d0f1":"#Implementing pca with 3 components i.e 3d plot\ncorona_pca=PCA(n_components=3)\nprincipal_comp=corona_pca.fit_transform(corona_pd_scaled)","ab436125":"principal_comp=pd.DataFrame(principal_comp,columns=['pca1','pca2','pca3'])\nprincipal_comp.head()","6d325e88":"principal_comp=pd.concat([principal_comp,pd.DataFrame({\"Cluster\":labels})],axis=1)","4a06ad10":"principal_comp.sample(5)","a9077d24":"#Plotting the 2d-plot.\nplt.figure(figsize=(10,10))\nax=sns.scatterplot(x='pca1',y='pca2',hue=\"Cluster\",data=principal_comp ,palette=['red','green','blue'])\nplt.show()","2b3c2faf":"#Plotting the 3d-plot\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfig = plt.figure(figsize=(10,10))\nax = fig.add_subplot(111, projection='3d')\nsc=ax.scatter(xs=principal_comp['pca2'],ys=principal_comp['pca3'],zs=principal_comp['pca1'],c=principal_comp['Cluster'],marker='o')\nplt.colorbar(sc)\nplt.show()","ffcc2f8e":"# **Loading and Visualizing Data**","551414ea":"At point 3 ,the graph looks like a elbow. So we choose this as our K value.","150319d6":"It's clear from the above table that the students at cluster 1 will get the admission for sure , the students at cluster 2 have intermediate chance of getting admission and the students at cluster 0 have almost no chance of getting admission.","874158ce":"# **K-MEANS Implementation**","9395521d":"Thank You!","fb4c200b":"You can see from the above visualization that each feature has a effect on every other features.","7da8d221":"For PCA - Refer this [link](https:\/\/www.google.com\/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjB1NOK28DqAhUjguYKHUNxDxwQwqsBMAB6BAgKEAQ&url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Drng04VJxUt4&usg=AOvVaw14_fwoAfo-0sWFezc-7qiy)","3bbbaa53":"You can have a even better view from the above plot.","bc06891c":"For K-Means algorithm - Refer this [link](https:\/\/www.google.com\/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwiInYrt2cDqAhUbyzgGHaiTBHAQwqsBMAF6BAgKEAQ&url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DhDmNF9JG3lo&usg=AOvVaw0uqMZBuHXA-UDOHz-ymSfK)","29cbe640":"# **Principal Component Analysis (PCA)**\nUsed to perform dimentionality reduction to have a better view of clusters of examples.","5eda0bc4":"# **Elbow Method**\nUsed to find optimal number of clusters.","2e8d5a5b":"You can understand the same from the above visualization which I mentioned earlier.","0d7feee1":"# **Importing Libraries**"}}