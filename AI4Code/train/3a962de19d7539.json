{"cell_type":{"da91ffa6":"code","ef55333d":"code","a8ea6250":"code","31c201f8":"code","78127be7":"code","6518f1c0":"code","c09a912f":"code","63a02957":"code","22a69c9a":"code","5fbfa30a":"code","663497b4":"code","5ac088c9":"code","c5d8bdc6":"code","ab8dbf8f":"code","e928ad7c":"code","2511604e":"code","728fb39e":"code","ecfd8691":"code","e793be48":"code","18fe3b20":"code","53fbfa9f":"code","9bca3f6f":"code","5fa53f95":"code","22b9ef67":"code","bcb33884":"code","8cd07b4d":"code","af587ea5":"code","1342b229":"code","4881d1d9":"code","5741e852":"code","3cd113d0":"code","d782c93b":"code","45f7bb5d":"code","ba5f44f8":"code","e80fa5c7":"code","78adb28a":"code","ee6f7d51":"code","7c024ea7":"code","3f16ba27":"code","a37f00e5":"code","f6a86cca":"code","58587766":"code","7e660e24":"code","71874c0d":"code","9938fd7c":"code","982a063a":"code","802ad48f":"code","eaa0bc8f":"code","722aef35":"code","8fe5776c":"code","2fbee911":"code","54d8f67e":"code","9d889561":"code","89a05ac0":"code","2dc957af":"code","543a3486":"code","8d99e165":"code","67e40072":"code","19ca345d":"markdown","44f47192":"markdown","72cd76b2":"markdown","b06a416d":"markdown","2b8e2477":"markdown","0af591c7":"markdown","6304696f":"markdown","cdd0eacb":"markdown","444f2df2":"markdown","6844c4f7":"markdown","f0015d33":"markdown","795ca7f7":"markdown","796e57ee":"markdown","b512cf4b":"markdown","2539a318":"markdown","1a11f5f1":"markdown","552cc8c9":"markdown","230d780e":"markdown","7ff27f63":"markdown","2721c779":"markdown","2bf676d1":"markdown","80f76272":"markdown","0ba90e70":"markdown","21c44909":"markdown","7c61a640":"markdown","8f563ee5":"markdown","fcd98778":"markdown","7d21d973":"markdown","010294c3":"markdown","6bf3e0ec":"markdown","35f834e5":"markdown","5b92839a":"markdown","2b333a50":"markdown","64a03b15":"markdown","94c4ae8a":"markdown","57c4b603":"markdown","f4fc8d66":"markdown","b322f93e":"markdown","6ae25fb5":"markdown","0577ad31":"markdown","774cb251":"markdown","e442726b":"markdown","7c8e6b94":"markdown","07ea5f10":"markdown","488433a5":"markdown","cfa02c5d":"markdown","05698a14":"markdown","6498b660":"markdown","c0b78194":"markdown","bdc765f6":"markdown","d5b6df42":"markdown","6d0034f9":"markdown","89ea53b7":"markdown","ad9b543e":"markdown","854b8b9c":"markdown","77333090":"markdown","1073e194":"markdown","47c93506":"markdown","05bb74ff":"markdown","47ea8f0d":"markdown","1d9b15e2":"markdown","5e3910f9":"markdown","827c72c0":"markdown","5bb0ac7b":"markdown","e53d48c1":"markdown","847e925b":"markdown","10c6b91e":"markdown","fab667f5":"markdown"},"source":{"da91ffa6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom scipy.stats import ttest_ind \nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ef55333d":"ds = pd.read_excel(\"\/kaggle\/input\/covid19\/dataset.xlsx\")","a8ea6250":"ds","31c201f8":"ds[\"SARS-Cov-2 exam result\"]","78127be7":"ds[\"SARS-Cov-2 exam result\"].value_counts(normalize=True)","6518f1c0":"ds.shape","c09a912f":"X = ds.drop([\"Patient ID\"], axis=1)","63a02957":"X.dtypes.value_counts().plot.pie(autopct='%1.1f%%', shadow=True, startangle=90)","22a69c9a":"Miss_val = X.isna().sum()\/X.shape[0]\nMiss_val.sort_values(ascending=False, inplace=True)","5fbfa30a":"plt.figure(figsize=(10,10))\nplt.bar(Miss_val.index,Miss_val)\nplt.show()","663497b4":"plt.figure(figsize=(20,10))\nsns.heatmap(X.isna(), cbar=False)","5ac088c9":"Miss_val[Miss_val == 0]","c5d8bdc6":"Miss_val[(Miss_val<0.9) & (Miss_val>0.8)]","ab8dbf8f":"Miss_val[(Miss_val<0.8) & (Miss_val>0.7)]","e928ad7c":"df_blood = X[Miss_val[(Miss_val<0.9) & (Miss_val>0.8)].index]\ndf_viral = X[Miss_val[(Miss_val<0.8) & (Miss_val>0.7)].index]","2511604e":"X = X[Miss_val[Miss_val < 0.9].index]\n##reorder\ncols = X.columns.tolist()\ncols = cols[-1:] + cols[:-1]\nX = X[cols]\n##\nX","728fb39e":"num_to_posneg = X['SARS-Cov-2 exam result'].astype('category').cat.categories\nX['SARS-Cov-2 exam result'] = X['SARS-Cov-2 exam result'].astype('category').cat.codes\nprint(f\"{num_to_posneg[0]} has been changed to 0, and {num_to_posneg[1]} to 1\")","ecfd8691":"sns.catplot(x=\"Patient addmited to regular ward (1=yes, 0=no)\", y=\"SARS-Cov-2 exam result\", data=X, kind=\"bar\", height = 4)\nplt.show()","e793be48":"sns.catplot(x=\"Patient addmited to semi-intensive unit (1=yes, 0=no)\", y=\"SARS-Cov-2 exam result\", data=X, kind=\"bar\", height = 4)\nplt.show()","18fe3b20":"sns.catplot(x=\"Patient addmited to intensive care unit (1=yes, 0=no)\", y=\"SARS-Cov-2 exam result\", data=X, kind=\"bar\", height = 4)\nplt.show()","53fbfa9f":"plt.figure(figsize=(12,8))\nsns.kdeplot(X['Patient age quantile'][X['SARS-Cov-2 exam result']== 0], shade=True)\nsns.kdeplot(X['Patient age quantile'][X['SARS-Cov-2 exam result'] == 1], shade=True)\nplt.xlim(0,20)\nplt.legend(['Negative', 'Positive'])\nplt.title('Pclass Age Distribution ')\nplt.show()","9bca3f6f":"fig=plt.figure(figsize=(15,15))\ncolumns = 4\nrows = 4\nfor i in range(1,len(X.select_dtypes(\"float\").columns)):\n    fig.add_subplot(rows, columns, i)\n    sns.distplot(a=X[X.select_dtypes(\"float\").columns[i]])","5fa53f95":"for col in X.select_dtypes('object'):\n    print(f'{col :-<50} {X[col].unique()}') #Make a margin = :-< or :<","22b9ef67":"pd.crosstab(X['Influenza A'], X['Influenza A, rapid test']) #Same for Influenza B","bcb33884":"fig=plt.figure(figsize=(15,15))\ncolumns = 4\nrows = 4\nfor i in range(1,len(df_blood.select_dtypes(\"float\").columns)):\n    x = fig.add_subplot(rows, columns, i)\n    sns.distplot(X[X['SARS-Cov-2 exam result']== 0][df_blood.select_dtypes(\"float\").columns[i]], label='negative')\n    sns.distplot(X[X['SARS-Cov-2 exam result']== 1][df_blood.select_dtypes(\"float\").columns[i]], label='positive')\n    x.legend(prop={'size': 8})","8cd07b4d":"sns.heatmap(X[Miss_val[Miss_val == 0].index].corr(), annot=True, fmt='.2f')\nprint(\"Only fully filled colums :\")\nplt.show()","af587ea5":"plt.figure(figsize=(15,10))\nsns.heatmap(X.corr(), annot=True, fmt=\".2f\")\nplt.show()","1342b229":"df_dropped_viral = X.dropna(subset=df_viral.columns)\ndf_dropped_viral['SARS-Cov-2 exam result'].value_counts(normalize=True)","4881d1d9":"df_dropped_blood = X.dropna(subset=df_blood.columns)\ndf_dropped_blood['SARS-Cov-2 exam result'].value_counts(normalize=True)","5741e852":"df_positive = X[X[\"SARS-Cov-2 exam result\"]==1].drop([\"Influenza A, rapid test\",\"Influenza B, rapid test\"], axis=1)\ndf_negative = X[X[\"SARS-Cov-2 exam result\"]==0].sample(df_positive.shape[0]).drop([\"Influenza A, rapid test\",\"Influenza B, rapid test\"], axis=1)","3cd113d0":"def t_test(col,alpha=1e-3):\n    stat, p = ttest_ind(df_negative[col].dropna(),df_positive[col].dropna())\n    if p < alpha:\n        return \"H0 rejected\"\n    else:\n        return 0","d782c93b":"for col in df_blood.drop([\"Influenza A, rapid test\",\"Influenza B, rapid test\"], axis=1):\n    print(f\"{col :-<50}{t_test(col)}\")","45f7bb5d":"Issick = np.zeros(df_positive.shape[0], dtype=int)\nfor i in range(df_positive.shape[0]):\n    if 'detected' in df_positive.reset_index().loc[i].unique():\n        Issick[i] = 1\n    \ndf_positive[\"Issick\"] = Issick\ndf_positive = df_positive.dropna(subset=df_viral.columns[:-1], how=\"all\",axis='rows') #Deleting NaN\n\n#Redo sample of the same size now that we deleted NaN, ds_positive is smaller, however, we sample on data that aren't only NaN in viruses columns\ndf_negative = X[X[\"SARS-Cov-2 exam result\"]==0].dropna(subset=df_viral.columns[:-1], how=\"all\",axis='rows').sample(df_positive.shape[0]).drop([\"Influenza A, rapid test\",\"Influenza B, rapid test\"], axis=1) \n\nIssick = np.zeros(df_negative.shape[0], dtype=int)\nfor i in range(df_negative.shape[0]):\n    if 'detected' in df_viral.loc[df_negative.index[i]].unique():\n        Issick[i] = 1\n    \ndf_negative[\"Issick\"] = Issick\ndf_negative = df_negative.dropna(subset=df_viral.columns[:-1], how=\"all\",axis='rows') #Deleting NaN","ba5f44f8":"fig=plt.figure(figsize=(13,13))\ncolumns = 2\nrows = 1\nlabels=['Negative','Positive']\ncolours = {'Negative': 'C0','Positive': 'C1'}\n\nsub1 = fig.add_subplot(rows, columns, 1)\nsub1.set_title(\"Proportion of sick patients and negative to Covid19\")\ndf_negative[\"Issick\"].value_counts().plot.pie(labels=labels,colors=[colours[key] for key in labels],autopct='%1.1f%%', shadow=True, startangle=90)\nsub2 = fig.add_subplot(rows, columns, 2)\nsub2.set_title(\"Proportion of sick patients and positive to Covid19\")\ndf_positive[\"Issick\"].value_counts().plot.pie(labels=labels,colors=[colours[key] for key in labels],autopct='%1.1f%%', shadow=True, startangle=90)\nplt.show()\nprint(t_test(\"Issick\"))","e80fa5c7":"ds","78adb28a":"X_prep = ds.drop([\"Patient ID\"], axis=1)","ee6f7d51":"X_prep = X_prep.drop([\"Parainfluenza 2\"], axis=1)","7c024ea7":"X_prep = X_prep.drop([\"Influenza A, rapid test\",\"Influenza B, rapid test\"], axis=1)","3f16ba27":"Miss_val = X_prep.isna().sum()\/X.shape[0]\nX_prep = X_prep.drop(Miss_val[Miss_val >= 0.9].index, axis=1)","a37f00e5":"df_blood = X_prep[Miss_val[(Miss_val<0.9) & (Miss_val>0.8)].index]\ndf_viral = X_prep[Miss_val[(Miss_val<0.8) & (Miss_val>0.7)].index]","f6a86cca":"X_prep = X_prep.dropna().reset_index(drop=True)","58587766":"code = {'negative':0, 'positive':1, 'not_detected':0, 'detected':1}\nfor col in X_prep.select_dtypes('object').columns: #makes sense right?\n    X_prep.loc[:,col] = X_prep[col].map(code)","7e660e24":"Issick = np.zeros(X_prep.shape[0], dtype=int)\nfor i in range(X_prep.shape[0]):\n    if '1' in X_prep.loc[i].unique():\n        Issick[i] = 1\n    \nX_prep[\"Issick\"] = Issick","71874c0d":"y_train = X_prep[\"SARS-Cov-2 exam result\"]\nX_train = X_prep.drop([\"SARS-Cov-2 exam result\"], axis=1)","9938fd7c":"X_train,X_test,y_train,y_test = train_test_split(X_train,y_train)","982a063a":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score, confusion_matrix, classification_report\nfrom sklearn.model_selection import learning_curve\n\ndef evaluation(model):\n    y_pred = model.predict(X_test)\n    sns.heatmap(confusion_matrix(y_test,y_pred), annot=True, cmap='Blues', cbar=False)\n    plt.show()\n    print(classification_report(y_test,y_pred))\n\n    N, train_score, val_score = learning_curve(model,X_train,y_train, scoring='f1', cv=4, train_sizes=np.linspace(0.1,1))\n    plt.plot(N,train_score.mean(axis=1), label='train score')\n    plt.plot(N,val_score.mean(axis=1), label='validation score')\n    plt.legend()\n    plt.show()\n    \nmodel = RandomForestClassifier()\nmodel.fit(X_train,y_train)\nevaluation(model)","802ad48f":"pd.DataFrame(model.feature_importances_, index=X_train.columns).plot.bar(figsize=(15,6))\nplt.show()","eaa0bc8f":"colu=[]\nfor col in (pd.DataFrame(model.feature_importances_, index=X_train.columns) > 0.05).transpose().columns:\n    if (pd.DataFrame(model.feature_importances_, index=X_train.columns) > 0.05).transpose()[col][0]:\n        colu.append(col)\ncolu.append(\"SARS-Cov-2 exam result\")\nX_prep = X_prep[colu]\nX_prep","722aef35":"y_train = X_prep[\"SARS-Cov-2 exam result\"]\nX_train = X_prep.drop([\"SARS-Cov-2 exam result\"], axis=1)\nX_train,X_test,y_train,y_test = train_test_split(X_train,y_train)","8fe5776c":"#All the models we will try\nfrom sklearn.cluster import KMeans\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\nfrom sklearn.preprocessing import StandardScaler #\nfrom sklearn.model_selection import GridSearchCV\n\nbest_score = 0","2fbee911":"hyperparameters = {'C': np.arange(0.5,5,0.2), 'kernel':['linear', 'rbf', 'sigmoid'], 'gamma':np.linspace(1e-5,1,60)}\ngrid = GridSearchCV(SVC(), hyperparameters, scoring=\"f1\", cv=5)\ngrid.fit(X_train,y_train)\nC, kernel, gamma = grid.best_params_['C'],grid.best_params_['kernel'],grid.best_params_['gamma']    \nprint(f\"Best f1 score : {grid.best_score_} for hyperparameters : {grid.best_params_}\")\nevaluation(grid.best_estimator_)\nif best_score<grid.best_score_:\n    best_score = grid.best_score_\n    model_name = \"SVM\"","54d8f67e":"inertia=[]\nn_clusters_list=[]\nfor n_clusters in range(1,50):\n    KM = KMeans(n_clusters=n_clusters)\n    KM.fit(X_train,y_train)\n    inertia.append(KM.inertia_)\n    n_clusters_list.append(n_clusters)\nplt.plot(n_clusters_list,inertia)\nplt.show()","9d889561":"from sklearn.metrics.cluster import completeness_score\nKM = KMeans(n_clusters=9)\nKM.fit(X_train,y_train)\nprint(f\"Best f1 score : {completeness_score(KM.predict(X_test),y_test)} for hyperparameters : n_clusters = 9\")\nif best_score<grid.best_score_:\n    best_score = grid.best_score_\n    model_name = \"KMeans\"","89a05ac0":"hyperparameters = {'n_neighbors': np.arange(1,50), 'metric': ['euclidean','manhattan']}\ngrid = GridSearchCV(KNeighborsClassifier(), hyperparameters, cv=5, scoring=\"f1\")\ngrid.fit(X_train,y_train)\nn_neighbors,metric = grid.best_params_['n_neighbors'],grid.best_params_['metric']\nprint(f\"Best f1 score : {grid.best_score_} for hyperparameters : {grid.best_params_}\")\nevaluation(grid.best_estimator_)\nif best_score<grid.best_score_:\n    best_score = grid.best_score_\n    model_name = \"K Nearest Neighbors\"","2dc957af":"hyperparameters = {'n_estimators': [1500,2000,2500,3000,4000],'max_features':['auto','sqrt','log2'], 'max_depth':[10,20,30]}\ngrid = GridSearchCV(RandomForestClassifier(), hyperparameters, cv=5, scoring=\"f1\")\ngrid.fit(X_train,y_train)\nn_estimators,max_features,max_depth = grid.best_params_['n_estimators'],grid.best_params_['max_features'],grid.best_params_['max_depth']\nprint(f\"Best f1 score : {grid.best_score_} for hyperparameters : {grid.best_params_}\")\nevaluation(grid.best_estimator_)\nif best_score<grid.best_score_:\n    best_score = grid.best_score_\n    model_name = \"RandomForestClassifier\"","543a3486":"hyperparameters = {'n_estimators': [500,700,800,900,1000],'max_features':['auto','sqrt','log2'], 'max_depth':[10,20,30]}\n\ngrid = GridSearchCV(ExtraTreesClassifier(), hyperparameters, cv=5, scoring=\"f1\")\ngrid.fit(X_train,y_train)\nn_e,max_f,max_d= grid.best_params_['n_estimators'],grid.best_params_['max_features'],grid.best_params_['max_depth']\nprint(f\"Best score : {grid.best_score_} for hyperparameters : {grid.best_params_}\")\nevaluation(grid.best_estimator_)\nif best_score<grid.best_score_:\n    best_score = grid.best_score_\n    model_name = \"ExtraTreesClassifier\"","8d99e165":"hyperparameters = {'n_estimators': [500,700,800,900,1000],'algorithm':['SAMME', 'SAMME.R']}\n\ngrid = GridSearchCV(AdaBoostClassifier(), hyperparameters, cv=5, scoring=\"f1\")\ngrid.fit(X_train,y_train)\nn_est,algorithm= grid.best_params_['n_estimators'],grid.best_params_['algorithm']\nprint(f\"Best f1 score : {grid.best_score_} for hyperparameters : {grid.best_params_}\")\nevaluation(grid.best_estimator_)\nif best_score<grid.best_score_:\n    best_score = grid.best_score_\n    model_name = \"AdaBoostClassifier\"","67e40072":"print(f'The best model is {model_name} with best f1 score : {best_score}')","19ca345d":"## 3.4. Feature Engineering","44f47192":"## 4.2. Second Model : KMeans","72cd76b2":"We can see that the age of patients aren't strongly related to any other variables. Also, we can think of two variables to create : *Hospitalized* (which will use if someone is in care unit) and *Is sick* using our data in *ds_viral*.","b06a416d":"## 4.5. Fith model : ExtraTreesClassifier","2b8e2477":"As we said, we delete *Patient ID*, also we noticed that *Influenze A, rapid test* and *Influenza B, rapid test* are not relevant duplicates of other columns. Then, we saw that *Parainfluenza2* had a variance equal to zero, so we delete it too. Finally,  we delete all columns with more than 90% values being NaN values.","0af591c7":"For the x axis, we can guess that it means for example : 5 = 25-30 years old.","6304696f":"# 1. Introduction","cdd0eacb":"# 3. Pre-processing","444f2df2":"## 3.6. Feature Selection","6844c4f7":"## 2.4. Visualization of the target","f0015d33":"According to the f1 score, our best model is :","795ca7f7":"## 2.3. Missing values","796e57ee":"## 3.3. Encoding categorical data","b512cf4b":"The student test (or T-test) allows to check if the mean of two distributions are equal when our data are normalized (which seems to be the case).\nHere are the two hypothesis from our study that we will focus on :","2539a318":"We can delete all the the columns with more than 90% of NaN.","1a11f5f1":"in this part, we will do what we kept in mind or already did during our EDA.","552cc8c9":"The first thing is to randomly sample the same amout of both positive and negative individuals[](http:\/\/)","230d780e":"# 4. Modeling","7ff27f63":"# 5. Conclusion","2721c779":"We can see if dropping NaN values have an impact on the balance of our target.","2bf676d1":"There is no need for feature scaling, but we can still add the feature *Issick*.","80f76272":"## 4.3. Third Model : K Neighbors","0ba90e70":"#### 2) Second Case, needs to add *Issick*","21c44909":"2) Patients with diseases have higher chance to be positives to SARS-Cov-2. ","7c61a640":"In this part, we analyse our dataset in order to prepare our pre-processing.","8f563ee5":"We can now say that positive patients to SARS-Cov-2 have significant higher rate of Leukocytes, Monocytes and Platelets with a threshold of 1e-3.","fcd98778":"## 2.6. The impact of NaN","7d21d973":"We can now see our two plateaus :","010294c3":"We add Issick whenever a virus is detected. Then, we delete the row if every column related to viruses is NaN.","6bf3e0ec":"For both of them, the H0 hypothesis is : The mean rates are equals in both positive and negative individuals. We will try to reject this hypothesis with a threshold.","35f834e5":"We can now say that patients with diseases have higher chance to be positives to SARS-Cov-2 with a threshold of 1e-3.","5b92839a":"## 2.7. Null hypothesis and Student Test","2b333a50":"## 2.2. The Columns","64a03b15":"## 3.2. Handling missing values","94c4ae8a":"First, let's look at our float data. It seems they are already normalized.","57c4b603":"### An important point : We can see that our lack of data will make difficult to realise good prediction for our model. But we must not give up ! If we think that this will be too difficult, we need to prove it ! Why is too difficult ? Is it underfitting or overfitting ? Will more data make our model better ? We must answer these if we can't reach our goal.","f4fc8d66":"1) Positive patients to SARS-Cov-2 have significant higher rate of Leukocytes, Monocytes and Platelets.","b322f93e":"However, it is essential to notice if the model is overfitting or not, if it is not, than adding more data will make it even more interesting (more than a better predicting overfit model).","6ae25fb5":"We have 111 colums, that's a lot of data. We can at least delete the first column as we know for sure aren't connected to the SARS-Cov-2 exam result.","0577ad31":"We can see two interesting plateau, one at 0.85 and another at 0.75, another way to look at our missing values with seaborn :","774cb251":"Using the elbow method, we find n_clusters = 9.","e442726b":"We clearly see overfitting. But now is the time to see the feature importances.","7c8e6b94":"## 3.5. Creating the train\/test set","07ea5f10":"Here we can see that more than half of our columns have less than 20% of data, we only have a few columns where the data is fully mentionned. Let's see which one they are.","488433a5":"The target is not balanced, so we must use f1 score as accuracy will not be relevant.","cfa02c5d":"We can see that *Leukocytes*, *Platelets* and *Monocytes* are interesting variables against our target, but we must not make any conclusions, only assumptions. ","05698a14":"## 4.4. Fourth model : RandomForestClassifier","6498b660":"## 2.5. A look at our variables","c0b78194":"In order to perform a relevant feature selection, we can create a simple model and look at its \"importance feature\".","bdc765f6":"### 3.6.1. Before feature selection","d5b6df42":"This notebook has been possible thanks to Machine Learnia. Futhermore, I add what I would have liked to use but didn't : **sklearn's pipelines and RandomSearchCV**.","6d0034f9":"We have a majority of numerical data, but still a important part of string data that have to be encode (more than a third).","89ea53b7":"## 4.1. First Model : SVM","ad9b543e":"We can now do a good feature selection :","854b8b9c":"#### 1) First Case","77333090":"Let's look at the type of the variable per column","1073e194":"We see that it is a string, we will have to encode the data.","47c93506":"## 4.6. Sixth model : AdaBoostClassifier","05bb74ff":"Then, we can see if our object\/string data are categories or not.","47ea8f0d":"## 3.1. Deleting useless columns (Feature Selection)","1d9b15e2":"## 2.1. The target","5e3910f9":"This is very interesting as we can create two subsets, one of blood related variables and another of viral related variables.","827c72c0":"We can see that all of our string data are categorizable, except one, *Parainfluenza2* which will be discarded as this variable has no variance. Futhermore we notice *Influenza A* and *Influenza B* have twins : *Influenza A, rapid test* and *Influenza B, rapid test*. After looking on the internet we can see that they are only 70% accurate tests and that our *Influenza A* and *Influenza B* are more relvant to keep.","5bb0ac7b":"An idea could be to replace NaN values by an extreme value -999 or to use missing values indicator in columns , however in this case, it makes the predictions worse.","e53d48c1":"We can see that our balance is not significantly changed","847e925b":"The purpose of this notebook is to predict the relation between the attributes of the Covid19 Dataset from Einstein Data4u and if they contracted Covid19. We hope to reach 50% with f1 score.","10c6b91e":"# 2. EDA : Exploratory Data Analysis","fab667f5":"In order to visualize easily, from now on the column SARS-Cov-2 exam result will be encoded."}}