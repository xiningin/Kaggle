{"cell_type":{"856cb093":"code","beac31d2":"code","a5c8bd93":"code","0b744662":"code","bb35dd30":"code","25314616":"code","2cda57c7":"code","f5c63afb":"code","4e2c9567":"code","138bbb37":"code","1893a3a3":"code","e9748a98":"code","c68e5141":"code","2977177f":"code","e814226e":"code","48b987a6":"code","9aeb14fe":"code","aab114ba":"code","87c750c0":"code","72984cff":"code","8460494c":"code","e216808e":"code","2ffca097":"code","9b5b0565":"code","82c53922":"code","9e9e6cab":"code","2e3b88e0":"code","c8a54a8e":"code","4893793b":"markdown","b34f3294":"markdown","d12b59d9":"markdown","f87dac1e":"markdown","8aa8398e":"markdown","4c30d2f2":"markdown","6857e91e":"markdown","8c0184ab":"markdown"},"source":{"856cb093":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")","beac31d2":"test=pd.read_csv('..\/input\/titanic\/test.csv')\ntrain=pd.read_csv('..\/input\/titanic\/train.csv')\ncombine=[train,test]","a5c8bd93":"train.head()","0b744662":"train.info()","bb35dd30":"train.describe()","25314616":"# get_dummies function\ndef dummies(col,train,test):\n    train_dum = pd.get_dummies(train[col])\n    test_dum = pd.get_dummies(test[col])\n    train = pd.concat([train, train_dum], axis=1)\n    test = pd.concat([test,test_dum],axis=1)\n    train.drop(col,axis=1,inplace=True)\n    test.drop(col,axis=1,inplace=True)\n    return train, test\n\n# get rid of the useless cols\ndropping = ['PassengerId', 'Name', 'Ticket','Cabin']\ntrain.drop(dropping,axis=1, inplace=True)\ntest.drop(dropping,axis=1, inplace=True)","2cda57c7":"train.head()","f5c63afb":"print(train.Sex.value_counts(dropna=False))\ntrain, test = dummies('Sex', train, test)\n# cos the male survival rate is so low, delete the male col\ntrain.drop('male',axis=1,inplace=True)\ntest.drop('male',axis=1,inplace=True)","4e2c9567":"train.Age.isnull().sum()","138bbb37":"nan=train[train.Age.isnull()]","1893a3a3":"nan.head()","e9748a98":"train.Age.mean()","c68e5141":"#dealing the missing values for Age in train dataset\nnan_num = train['Age'].isnull().sum()\nage_mean = train['Age'].mean()\nage_std = train['Age'].std()\nfilling = np.random.randint(age_mean-age_std, age_mean+age_std, size=nan_num)\ntrain['Age'][train['Age'].isnull()==True] = filling\n\n# dealing the missing values in test dataset\nnan_num = test['Age'].isnull().sum()\nage_mean = test['Age'].mean()\nage_std = test['Age'].std()\nfilling = np.random.randint(age_mean-age_std,age_mean+age_std,size=nan_num)\ntest['Age'][test['Age'].isnull()==True]=filling","2977177f":"import seaborn as sns\ns = sns.FacetGrid(train,hue='Survived',aspect=4)\ns.set(xlim=(0,train['Age'].max()))\ns.map(sns.kdeplot,'Age',shade=True)\ns.add_legend()","e814226e":"def under15(row):\n    result = 0.0\n    if row<15:\n        result = 1.0\n    return result\ndef young(row):\n    result = 0.0\n    if row>=15 and row<35:\n        result = 1.0\n    return result\n\ntrain['under15'] = train['Age'].apply(under15)\ntest['under15'] = test['Age'].apply(under15)\ntrain['young'] = train['Age'].apply(young)\ntest['young'] = test['Age'].apply(young)\n\ntrain.drop('Age',axis=1,inplace=True)\ntest.drop('Age',axis=1,inplace=True)","48b987a6":"train.head(10)","9aeb14fe":"train['family'] = train['SibSp'] + train['Parch']\ntest['family'] = test['SibSp'] + test['Parch']\n\ntrain.drop(['SibSp','Parch'],axis=1,inplace=True)\ntest.drop(['SibSp','Parch'],axis=1,inplace=True)","aab114ba":"train.head(10)","87c750c0":"test['Fare'].fillna(test['Fare'].median(),inplace=True)","72984cff":"train.Embarked.isnull().sum()\n# 2 missing value\ntrain.Embarked.value_counts()\n# fill the majority val,'s', into missing val col\ntrain['Embarked'].fillna('S',inplace=True)\n\n# c has higher survival rate, drop the other two\ntrain,test = dummies('Embarked',train,test)\ntrain.drop(['S','Q'],axis=1,inplace=True)\ntest.drop(['S','Q'],axis=1,inplace=True)","8460494c":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score, KFold\n\ndef modeling(clf,ft,target):\n    acc = cross_val_score(clf,ft,target,cv=kf)\n    acc_lst.append(acc.mean())\n    return \n\naccuracy = []\ndef ml(ft,target,time):\n    accuracy.append(acc_lst)\n\n    #logisticregression\n    logreg = LogisticRegression()\n    modeling(logreg,ft,target)\n    #RandomForest\n    rf = RandomForestClassifier(n_estimators=50,min_samples_split=4,min_samples_leaf=2)\n    modeling(rf,ft,target)\n    #svc\n    svc = SVC()\n    modeling(svc,ft,target)\n    #knn\n    knn = KNeighborsClassifier(n_neighbors = 3)\n    modeling(knn,ft,target)\n\n    \n    # see the coefficient\n    logreg.fit(ft,target)\n    feature = pd.DataFrame(ft.columns)\n    feature.columns = ['Features']\n    feature[\"Coefficient Estimate\"] = pd.Series(logreg.coef_[0])\n    print(feature)\n    return ","e216808e":"train_ft=train.drop('Survived',axis=1)\ntrain_y=train['Survived']\n#set kf\nkf = KFold(n_splits=3)\nacc_lst = []\nml(train_ft,train_y,'test_1')","2ffca097":"train_ft_2=train.drop(['Survived','young'],axis=1)\ntest_2 = test.drop('young',axis=1)\ntrain_ft.head()\n\n# ml\nkf = KFold(n_splits=3)\nacc_lst=[]\nml(train_ft_2,train_y,'test_2')","9b5b0565":"train_ft_3=train.drop(['Survived','C'],axis=1)\ntest_3 = test.drop('C',axis=1)\n\n# ml\nkf = KFold(n_splits=3)\nacc_lst = []\nml(train_ft_3,train_y,'test_3')","82c53922":"accuracy_df=pd.DataFrame(data=accuracy,\n                         index=['test1','test2','test3'],\n                         columns=['logistic','rf','svc','knn'])\naccuracy_df","9e9e6cab":"rf = LogisticRegression()\nrf.fit(train_ft_3,train_y)\nrf_pred = rf.predict(test_3)\nprint(rf.score(train_ft_3,train_y))\n","2e3b88e0":"test = pd.read_csv('..\/input\/titanic\/test.csv')\nsubmission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": rf_pred\n    })","c8a54a8e":"submission.to_csv(\"titanic.csv\", index=False)\n","4893793b":"* Data cleaning","b34f3294":"we can see that there are some null values available in Age,Cabin and Embarked section","d12b59d9":"# Submission","f87dac1e":"from the graph above we can see that the survival rate of children and seniors is high and the survival rate of middle aged people (15-35) is low as compared to them","8aa8398e":"since we get the most accuracy in random forrest regression with test 3, we will use it to implement it on the test dataset","4c30d2f2":"Here we can see that maximum age of the person travelling is 80 and minimum age is 0.4(approx 5 months) and average age of the person travelling in the ship is 29.699.\nAverage price of the ticket is 32 with the most expensive ticket priced at 512 and the cheapest at 0.","6857e91e":"177 missing values in Age column so let's clean it first","8c0184ab":"* Importing libraries"}}