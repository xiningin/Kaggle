{"cell_type":{"9f93378f":"code","d258709a":"code","06d20a2a":"code","64d2ae41":"code","f28774d2":"code","476e0c04":"code","0e950329":"code","6437acb6":"code","5fcd577d":"code","f345ffa0":"code","f3e142c1":"code","77a7b6b2":"code","5e121a3c":"code","bdcbe6c3":"code","898854c3":"code","37c14c9f":"code","9b8912a4":"code","b6c19899":"code","3412079b":"code","85b37491":"code","565c814e":"code","f01c4f9f":"code","9756d436":"code","b36b8e55":"code","0f17827c":"code","9cf2ef5b":"code","3d7267ae":"code","7e0f85ec":"code","c3eb680d":"code","5b0fa074":"code","92d52733":"code","69e0d65b":"code","8d5336fe":"code","594cb642":"code","6ed2fead":"code","9d8b6e4d":"code","70289269":"code","8acaf776":"code","5ed7f631":"code","3dd56be0":"code","c78cb5de":"code","9d947590":"code","153d98e5":"code","a74fa235":"code","d59ac489":"code","d1636ce4":"code","d3e436eb":"code","80ee6cc6":"code","7009f341":"code","3ab599a7":"code","6004c49d":"code","3221e204":"code","35efbafd":"code","b416b65d":"code","e7f3b9fa":"code","fe337397":"code","09025a72":"markdown","7f8fb31e":"markdown","0c33a18b":"markdown","5a9b35e2":"markdown","9e5d7e75":"markdown","3aefc039":"markdown","8cd8fc03":"markdown","9e09607f":"markdown","67ad5012":"markdown","c6e97e76":"markdown","54746615":"markdown","dc743e55":"markdown","d906c21f":"markdown","7acb761c":"markdown","23ddce0e":"markdown","92a4ee79":"markdown","3cd5cdc0":"markdown","98193fee":"markdown","164a5916":"markdown","f3d4023e":"markdown"},"source":{"9f93378f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nimport warnings\nfrom scipy import stats\nfrom itertools import product\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.linear_model import LinearRegression, RidgeCV, Lasso\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import TimeSeriesSplit, cross_val_score, cross_validate\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\nfrom statsmodels.tsa.stattools import adfuller\nfrom learntools.time_series.utils import plot_periodogram, seasonal_plot\nfrom xgboost import XGBRegressor\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d258709a":"def ad (df):\n    return print('p-value = {}'.format(adfuller(df)[1]))","06d20a2a":"df_train = pd.read_csv('\/kaggle\/input\/store-sales-time-series-forecasting\/train.csv', parse_dates=['date'], infer_datetime_format=True)\ndf_train['date'] = df_train.date.dt.to_period('D')\nstore_sales = df_train.set_index(['store_nbr', 'family', 'date']).sort_index()\nprom = (store_sales.groupby('date').mean().squeeze())['onpromotion'].to_frame()\naverage_sales = (store_sales.groupby('date').mean().squeeze())['sales'].to_frame()","64d2ae41":"store_sales","f28774d2":"df_train.head()","476e0c04":"df_test = pd.read_csv('\/kaggle\/input\/store-sales-time-series-forecasting\/test.csv', parse_dates=['date'])\ndf_test['date'] = df_test.date.dt.to_period('D')\ndf_test.head()","0e950329":"stores = pd.read_csv('\/kaggle\/input\/store-sales-time-series-forecasting\/stores.csv', index_col='store_nbr')\nstores.head()","6437acb6":"oil = pd.read_csv('\/kaggle\/input\/store-sales-time-series-forecasting\/oil.csv', parse_dates=['date'])\noil = oil.set_index('date').to_period('d')\noil.head()","5fcd577d":"holiday = pd.read_csv('\/kaggle\/input\/store-sales-time-series-forecasting\/holidays_events.csv', parse_dates=['date'])\nholiday = holiday.set_index('date').to_period('D')\nholiday.head()","f345ffa0":"transaction = pd.read_csv('\/kaggle\/input\/store-sales-time-series-forecasting\/transactions.csv', parse_dates=['date'])\ntransaction = transaction.set_index('date').to_period('d')\ntransaction.tail()","f3e142c1":"sales_plot = average_sales.copy()","77a7b6b2":"plt.figure(figsize=(20,6))\nplt.plot(sales_plot.loc['2016']['sales'].values, label='2016')\nplt.plot(sales_plot.loc['2017']['sales'].values, label='2017')\nplt.legend();","5e121a3c":"sales_plot.loc['2016']['sales'].plot(figsize=(20,6));","bdcbe6c3":"#sales_plot.loc['2017'].rolling(6).mean().ewm(alpha=0.05).mean()","898854c3":"b_days = sales_plot.copy()\nb_days['dayofweek'] = b_days.index.day_of_week\nplt.figure(figsize=(20,6))\nplt.plot(b_days.loc['2015'].groupby('dayofweek')['sales'].mean().values, label='2015')\nplt.plot(b_days.loc['2016'].groupby('dayofweek')['sales'].mean().values, label='2016')\nplt.plot(b_days.loc['2017'].groupby('dayofweek')['sales'].mean().values, label='2017')\nplt.legend();","37c14c9f":"percent_days = b_days.loc['2016'].groupby('dayofweek')['sales'].mean()\npercent_days = percent_days.map(lambda x: x *100 \/ percent_days.sum())\nplt.plot(percent_days)\npercent_days","9b8912a4":"week = sales_plot.resample('w').mean()\nplt.figure(figsize=(20,6))\nplt.plot(week.loc['2015']['sales'].values, label='2015')\nplt.plot(week.loc['2016']['sales'].values, label='2016')\nplt.plot(week.loc['2017']['sales'].values, label='2017')\nplt.legend();","b6c19899":"week.loc['2016'].plot(figsize=(20,6));","3412079b":"week['week'] = week.index.week\npercent_weeks = week.loc['2015':].groupby('week')['sales'].mean()\npercent_weeks = percent_weeks.map(lambda x: x *100 \/ percent_weeks.sum())\npercent_weeks.head()","85b37491":"month = sales_plot.resample('m').mean()\nplt.figure(figsize=(20,6))\nplt.plot(month.loc['2015']['sales'].values, label='2015')\nplt.plot(month.loc['2016']['sales'].values, label='2016')\nplt.plot(month.loc['2017']['sales'].values, label='2017')\nplt.legend();","565c814e":"month['month'] = month.index.month\npercent_m = month.loc['2014':].groupby('month')['sales'].mean()\npercent_m = percent_m.map(lambda x: x *100 \/ percent_m.sum())\npercent_m","f01c4f9f":"quarter= sales_plot.resample('q').mean()\nplt.figure(figsize=(20,6))\nplt.plot(quarter.loc['2015']['sales'].values, label='2015')\nplt.plot(quarter.loc['2016']['sales'].values, label='2016')\nplt.plot(quarter.loc['2017']['sales'].values, label='2017')\nplt.legend();","9756d436":"quarter['q'] = quarter.index.quarter\npercent_q = quarter.loc['2016':].groupby('q')['sales'].mean()\npercent_q = percent_q.map(lambda x: x *100 \/ percent_q.sum())\npercent_q","b36b8e55":"holiday.head()","0f17827c":"holiday.type.value_counts()","9cf2ef5b":"holiday.locale.value_counts()","3d7267ae":"holidays = holiday.loc[holiday.index.isin(sales_plot.index)]\nplt.figure(figsize=(20,6))\nplt.plot_date(holidays.index, sales_plot.loc[holidays.index], color='C3')\nplt.plot(sales_plot);","7e0f85ec":"plt.figure(figsize=(20,6))\nplt.plot_date(holidays.loc['2016'].index, sales_plot.loc[holidays.loc['2016'].index], color='C3')\nplt.plot(sales_plot.loc['2016']);","c3eb680d":"def hol_plot(df, col='C3', lab='N'):\n    plt.plot_date(df.loc['2016'].index, sales_plot.loc[df.loc['2016'].index], color=col, label=lab)\n    plt.plot(sales_plot.loc['2016'], color='silver')","5b0fa074":"holiday_nat = holidays.loc[(holidays.locale == 'National') & (holidays.transferred == False) & (holidays.type != 'Work Day')]\nholiday_loc = holidays.loc[(holidays.locale == 'Local') & (holidays.transferred == False) & (holidays.type != 'Work Day')]\nholiday_reg = holidays.loc[(holidays.locale == 'Regional') & (holidays.transferred == False) & (holidays.type != 'Work Day')]\nholiday_trans = holidays.loc[(holidays.transferred == True)]\nplt.figure(figsize=(20,6))\nhol_plot(holiday_nat, col='orange', lab='national')\nhol_plot(holiday_loc, col='black', lab='local')\nhol_plot(holiday_reg, col='red', lab='regional')\nhol_plot(holiday_trans, col='blue', lab='transferred')\nplt.legend()","92d52733":"scale = MinMaxScaler()","69e0d65b":"plt.figure(figsize=(20,6))\nplt.plot(scale.fit_transform(sales_plot.loc['2016'].values), label='sales')\nplt.plot(scale.fit_transform(prom.loc['2016'].values), label='prom')\nplt.legend();\nprom.loc['2016'].corrwith(sales_plot.loc['2016'].sales)","8d5336fe":"trans = transaction.resample('d').mean()['transactions'].to_frame()\nplt.figure(figsize=(20,6))\nplt.plot(scale.fit_transform(sales_plot.loc['2016'].values), label='sales')\nplt.plot(scale.fit_transform(trans.loc['2016'].values), label='transactions')\nplt.legend();\ntrans.loc['2016'].corrwith(sales_plot.loc['2016'].sales)","594cb642":"oils = oil.resample('d').mean().fillna(method='ffill')\nplt.figure(figsize=(20,6))\nplt.plot(scale.fit_transform(sales_plot.loc['2017'].values), label='sales')\nplt.plot(scale.fit_transform(oils.loc['2017'].values), label='oil')\nplt.legend();\noils.loc['2017'].corrwith(sales_plot.loc['2017'].sales)","6ed2fead":"X_train = df_train.copy()\nX_test = df_test.copy()\nfull_df = pd.concat([X_train, X_test])\nfull_df.reset_index(drop=True, inplace=True)\nX_store = full_df.set_index(['store_nbr', 'family', 'date']).sort_index()\nX_prom = (X_store.groupby('date').mean().squeeze())['onpromotion'].to_frame()\nav_sales = (X_store.groupby('date').mean().squeeze())['sales'].to_frame()\nfull_df.head()","9d8b6e4d":"# for time features\ndef creat_time_features(df):\n    \"\"\"\n    Creates time series features from datetime index\n    \"\"\"\n    df = df.copy()\n    #df['trend'] = np.arange(len(df.index))\n    #df['trend^2'] = (np.arange(len(df.index)) +1) ** 2\n    #df['trend^3'] = (np.arange(len(df.index)) +1) ** 3\n    #df['trend^4'] = (np.arange(len(df.index)) +1) ** 4\n    #df['trend^5'] = (np.arange(len(df.index)) +1) ** 5\n    #df['hour'] = df['date'].dt.hour\n    df['dayofweek'] = df.index.day_of_week\n    df['weekofyear'] = df.index.week\n    df['quarter'] = df.index.quarter\n    df['month'] = df.index.month\n    #df['year'] = df.index.year\n    df['dayofyear'] = df.index.day_of_year\n    #df['dayofmonth'] = df.index.day\n    df['week_in_month'] = pd.to_numeric(df.index.day\/7)\n    df['week_in_month'] = df['week_in_month'].apply(lambda x: np.ceil(x))\n    X = df.copy()\n    return X","70289269":"def model_cv (X, y):\n    cv = TimeSeriesSplit()\n    model = LinearRegression()\n    result = cross_validate(model, X.loc[:'2017-07'],y.loc[:'2017-07'], cv=cv,scoring=[\"neg_mean_absolute_error\", \"neg_mean_squared_log_error\"], return_estimator=True)\n    mae = -result[\"test_neg_mean_absolute_error\"]\n    rmsle = np.sqrt(- result[\"test_neg_mean_squared_log_error\"])\n    print('mae = {:.3f}\\nrmsle = {:.3f}'.format(mae.mean(), rmsle.mean()))\n    X_plt = X.loc['2017-08']\n    y_plt = y.loc['2017-08']\n    plt.figure(figsize=(20,15))\n    for i in result['estimator']:\n        y_pred = pd.DataFrame(i.predict(X_plt), index=X_plt.index, columns=['sales'])\n        y_pred.plot(color='red')\n        y_plt.plot(color='silver')","8acaf776":"def X_y(df):\n    df = df.copy()\n    X = df.loc['2017':].dropna().drop(columns=['sales'])\n    y = df.loc['2017':]['sales'].dropna()\n    return X,y\n    ","5ed7f631":"X_full = creat_time_features(av_sales)\nX, y = X_y(X_full)\nX_test = X_full.loc['2017-08-16':].drop(columns=['sales'])\nmodel_cv(X,y);","3dd56be0":"X_dum = pd.get_dummies(X_full, columns=['dayofweek', 'week_in_month']).loc['2017': '2017-08-15'].drop(columns=['sales'])\nX_test = pd.get_dummies(X_full, columns=['dayofweek', 'week_in_month']).loc['2017-08-16':].drop(columns=['sales'])\nmodel_cv(X_dum,y)","c78cb5de":"X_hol = X_dum.copy()\nX_hol['new_year'] = (X_hol.index.dayofyear ==1).astype('int')\nX_test['new_year'] = (X_test.index.dayofyear ==1).astype('int')\nmodel_cv(X_hol,y)","9d947590":"X_pay = X_hol.copy()\nX_pay['day_in_m'] = X_pay.index.days_in_month\nX_pay['pay_day'] = (X_pay.index.day == 16) | (X_pay.index.day == 1) | (X_pay.index.day == 14) | (X_pay.index.day == X_pay['day_in_m'] - 1) | (X_pay.index.day == 15) | (X_pay.index.day == X_pay['day_in_m'])\nX_pay.drop(columns='day_in_m', inplace=True, axis=1)\nX_test['day_in_m'] = X_test.index.days_in_month\nX_test['pay_day'] = (X_test.index.day == 15) | (X_test.index.day == X_test['day_in_m']) | (X_test.index.day == 16) | (X_test.index.day == 1) | (X_test.index.day == 14) | (X_test.index.day == X_test['day_in_m'] - 1)\nX_test.drop(columns='day_in_m', inplace=True, axis=1)\nmodel_cv(X_pay,y)","153d98e5":"hol = holiday.loc['2017'].loc[holiday.loc['2017'].locale.isin(['National', 'Regional'])]\nhol['hol'] = 1\nhol.loc[hol.type == 'Transfer', 'hol'] = 1\nhol.loc[(hol.type == 'Holiday') & (hol.transferred == False), 'hol'] = 1\nhol.loc[(hol.type == 'Holiday') & (hol.transferred == True ), 'hol'] = 0\nhol = pd.get_dummies(hol.drop(columns=['locale','locale_name','description','transferred']), columns=['type'])\nX_weakend = X_pay.copy()\nX_weakend = pd.concat([X_weakend, hol.loc[:'2017-08-16']], axis=1).fillna(0)\nX_weakend.loc[X_weakend.index.dayofweek.isin([5,6]), 'hol'] = 1\nX_test = pd.concat([X_test, hol.loc['2017-08-16':'2017-08']], axis=1).fillna(0)\nX_test.loc[X_test.index.dayofweek.isin([5,6]), 'hol'] = 1\nmodel_cv(X_weakend,y)","a74fa235":"X_oil = X_weakend.copy()\nX_oil['oil'] = oils.loc['2015':].rolling(7).mean()\nX_test['oil']= oils.loc['2016':'2017-08'].rolling(7).mean()\nmodel_cv(X_oil,y)","d59ac489":"model = LinearRegression()\nX_for_subm = X_oil.loc['2017':]\ny_ = X_store.loc[:,:,'2017':].dropna()['sales'].to_frame().unstack(['store_nbr', 'family'])\n\nmodel.fit(X_for_subm, y_)\ny_pred = pd.DataFrame(model.predict(X_for_subm), columns=y_.columns, index=X_for_subm.index)\ny_pred[y_pred < 0 ] = 0\nplt.figure(figsize=(20,6));\nplt.plot(y_.loc(axis=1)['sales',1, 'PRODUCE'].loc['2017'].values)\nplt.plot(y_pred.loc(axis=1)['sales',1, 'PRODUCE'].loc['2017'].values)\nmae = mean_absolute_error(y_pred.loc(axis=1)['sales',1, 'PRODUCE'].loc['2017'].values,y_.loc(axis=1)['sales',1, 'PRODUCE'].loc['2017'].values)\nmsle = mean_squared_log_error(y_pred.loc(axis=1)['sales',1, 'PRODUCE'].loc['2017'].values,y_.loc(axis=1)['sales',1, 'PRODUCE'].loc['2017'].values)\nprint('mae = {:.3f}\\nrmsle = {:.3f}'.format(mae, np.sqrt(msle)))","d1636ce4":"y_submit = pd.DataFrame(model.predict(X_test), columns=y_.columns, index=X_test.index)\ny_submit_ = y_submit.stack(['store_nbr', 'family'])\ny_submit_.loc[y_submit_.sales < 0] = 0\ndf_test_ = df_test.set_index(['store_nbr', 'family', 'date']).sort_index()\ny_submit_ = y_submit_.join(df_test_.id).reindex(columns=['id', 'sales'])\ny_submit_.to_csv('submission_5_lr.csv', index=False)\ny_submit_","d3e436eb":"y_.loc['2017'].stack(['store_nbr', 'family']).groupby('date')['sales'].mean().plot(figsize=(20,6))\ny_submit_.groupby('date')['sales'].mean().plot()","80ee6cc6":"y_gbm_ = y_.unstack().to_frame() - y_pred.unstack().to_frame()\nX_xgb_1 = full_df.set_index(['date']).loc['2017':]\nX_xgb = pd.concat([X_xgb_1.loc[:'2017-08-15'], X_oil], axis=1).drop(columns=['id', 'sales'])\nX_xgb = X_xgb.set_index(['store_nbr', 'family', X_xgb.index]).sort_index()","7009f341":"X_gbm = X_store.loc[:,:,'2017':'2017-08-16'].drop(columns=['id', 'sales'])\nmodel_2 = XGBRegressor()\nmodel_2.fit(X_gbm, y_gbm_)\n\ngbm_pred = pd.DataFrame(model_2.predict(X_gbm), index=X_gbm.index, columns=['sales'])\ny_boost = pd.DataFrame( y_pred.unstack().to_frame().values + gbm_pred.values, index=gbm_pred.index, columns=['sales'] )\ny_boost.loc[y_boost.sales < 0] = 0","3ab599a7":"y_pred = y_boost.copy()\nplt.figure(figsize=(20,6));\nplt.plot(y_.loc(axis=1)['sales',1, 'PRODUCE'].loc['2017'].values)\nplt.plot(y_pred.loc(axis=0)[1, 'PRODUCE'].loc['2017'].values)\nmae = mean_absolute_error(y_pred.loc(axis=0)[1, 'PRODUCE'].loc['2017'].values,y_.loc(axis=1)['sales',1, 'PRODUCE'].loc['2017'].values)\nmsle = mean_squared_log_error(y_pred.loc(axis=0)[1, 'PRODUCE'].loc['2017'].values,y_.loc(axis=1)['sales',1, 'PRODUCE'].loc['2017'].values)\nprint('mae = {:.3f}\\nrmsle = {:.3f}'.format(mae, np.sqrt(msle)))","6004c49d":"#X_test_xgb = pd.concat([X_xgb_1.loc['2017-08-16':], X_test], axis=1).drop(columns=['id', 'sales'])\n#X_test_xgb = X_test_xgb.set_index(['store_nbr', 'family', X_test_xgb.index]).sort_index()","3221e204":"X_test_xgb = df_test_.onpromotion.to_frame().sort_index()","35efbafd":"X_test_xgb","b416b65d":"gbm_pred_2 = pd.DataFrame(model_2.predict(X_test_xgb), index=y_submit_.index, columns=['sales'])\ny_boost_2 = pd.DataFrame(y_submit.unstack().to_frame().values + gbm_pred_2.values, index=gbm_pred_2.index, columns=['sales'])","e7f3b9fa":"y_submit2_ = (0.8 * y_submit_.drop(columns=['id']) + gbm_pred_2 * 0.2) * 1.05\ny_submit2_.loc[y_submit2_.sales < 0] = 0\ny_submit2_ = y_submit2_.join(df_test_.id).reindex(columns=['id', 'sales'])\ny_submit2_.to_csv('submission_5_xgb.csv', index=False)\ny_submit2_","fe337397":"y_pred.groupby('date').mean().plot(figsize=(20,5))\ny_submit2_.groupby('date')['sales'].mean().plot()","09025a72":"## Model 1 only date features","7f8fb31e":"## 3. Promotion","0c33a18b":"## Predict","5a9b35e2":"## Add oil","9e5d7e75":"## test.csv\nThe test data, having the same features as the training data. You will predict the target sales for the dates in this file.\nThe dates in the test data are for the 15 days after the last date in the training data.","3aefc039":"## holidays_events.csv\nHolidays and Events, with metadata\nNOTE: Pay special attention to the transferred column. A holiday that is transferred officially falls on that calendar day, but was moved to another date by the government. A transferred day is more like a normal day than a holiday. To find the day that it was actually celebrated, look for the corresponding row where type is Transfer. For example, the holiday Independencia de Guayaquil was transferred from 2012-10-09 to 2012-10-12, which means it was celebrated on 2012-10-12. Days that are type Bridge are extra days that are added to a holiday (e.g., to extend the break across a long weekend). These are frequently made up by the type Work Day which is a day not normally scheduled for work (e.g., Saturday) that is meant to payback the Bridge.\nAdditional holidays are days added a regular calendar holiday, for example, as typically happens around Christmas (making Christmas Eve a holiday).","8cd8fc03":"# Make models and features","9e09607f":"# Upload files\n## train.csv\nThe training data, comprising time series of features store_nbr, family, and onpromotion as well as the target sales.\nstore_nbr identifies the store at which the products are sold.\nfamily identifies the type of product sold.\nsales gives the total sales for a product family at a particular store at a given date. Fractional values are possible since products can be sold in fractional units (1.5 kg of cheese, for instance, as opposed to 1 bag of chips).\nonpromotion gives the total number of items in a product family that were being promoted at a store at a given date.","67ad5012":"## 4. Transaction","c6e97e76":"## Model 3 date features + dummies + new_year","54746615":"## Model 2 date features + dummies","dc743e55":"# Plan\n1. Visualization\n2. Data preparation\n3. Choise a model\n4. Tuning model","d906c21f":"## oil.csv\nDaily oil price. Includes values during both the train and test data timeframes. (Ecuador is an oil-dependent country and it's economical health is highly vulnerable to shocks in oil prices.)","7acb761c":"## stores.csv\nStore metadata, including city, state, type, and cluster.\ncluster is a grouping of similar stores.","23ddce0e":"## XGB","92a4ee79":"## Model 4 date features + dummies + new_year + pay_days","3cd5cdc0":"# See plots","98193fee":"##  5. Oil","164a5916":"## 1. Date","f3d4023e":"## 2. Holidays"}}