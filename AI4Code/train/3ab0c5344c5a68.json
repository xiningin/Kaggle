{"cell_type":{"7b3ae361":"code","c495b12e":"code","2c98c0a4":"code","7c3cf15e":"code","9e605d31":"code","4f90686b":"code","4320bcb3":"code","ce536677":"code","8660b652":"code","c49cba11":"code","ca2e0394":"code","631dd112":"code","75d7a8fa":"code","8322cc50":"code","3f37ce64":"code","e335d9cc":"code","11615886":"code","be0d874d":"code","7ed2279d":"code","03265fce":"code","669409bc":"code","7efe5d57":"markdown","848f2002":"markdown","fee19129":"markdown","1e2d9f8e":"markdown","617befd2":"markdown","570d54f9":"markdown","b5b55dc8":"markdown","2fd137b4":"markdown","446dc860":"markdown","aaff700e":"markdown"},"source":{"7b3ae361":"from keras.layers.convolutional import Conv2D, AtrousConvolution2D\nfrom keras.layers import Activation, Dense, Input, Conv2DTranspose, Dense, Flatten\nfrom keras.layers import ReLU, Dropout, Concatenate, BatchNormalization, Reshape\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Model, model_from_json\nfrom keras.optimizers import Adam\nfrom keras.layers.convolutional import UpSampling2D\nimport keras.backend as K\nimport tensorflow as tf\n\nimport os\nimport numpy as np\nimport PIL\nimport cv2\nimport IPython.display\nfrom IPython.display import clear_output\nfrom datetime import datetime\nfrom dataloader import Data, TestData","c495b12e":"try:\n    from keras_contrib.layers.normalization import InstanceNormalization\nexcept Exception:\n    from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization","2c98c0a4":"# Initialize dataloader\ndata = Data()\ntest_data = Data()","7c3cf15e":"# Saves Model in every N minutes\nTIME_INTERVALS = 2\nSHOW_SUMMARY = True\n\nINPUT_SHAPE = (256, 256, 3)\nEPOCHS = 500\nBATCH = 1\n\n# 25% i.e 64 width size will be mask from both side\nMASK_PERCENTAGE = .25\n\nEPSILON = 1e-9\nALPHA = 0.0004\n\nCHECKPOINT = \"checkpoint\/\"\nSAVED_IMAGES = \"saved_images\/\"","9e605d31":"def dcrm_loss(y_true, y_pred):\n    return -tf.reduce_mean(tf.log(tf.maximum(y_true, EPSILON)) + tf.log(tf.maximum(1. - y_pred, EPSILON)))\n\nd_input_shape = (INPUT_SHAPE[0], int(INPUT_SHAPE[1] * (MASK_PERCENTAGE *2)), INPUT_SHAPE[2])\nd_dropout = 0.25\nDCRM_OPTIMIZER = Adam(0.0001, 0.5)","4f90686b":"def d_build_conv(layer_input, filter_size, kernel_size=4, strides=2, activation='leakyrelu', dropout_rate=d_dropout, norm=True):\n    c = Conv2D(filter_size, kernel_size=kernel_size, strides=strides, padding='same')(layer_input)\n    if activation == 'leakyrelu':\n        c = LeakyReLU(alpha=0.2)(c)\n    if dropout_rate:\n        c = Dropout(dropout_rate)(c)\n    if norm == 'inst':\n        c = InstanceNormalization()(c)\n    return c\n\n\ndef build_discriminator():\n    d_input = Input(shape=d_input_shape)\n    d = d_build_conv(d_input, 32, 5,strides=2, norm=False)\n\n    d = d_build_conv(d, 64, 5, strides=2)\n    d = d_build_conv(d, 64, 5, strides=2)\n    d = d_build_conv(d, 128, 5, strides=2)\n    d = d_build_conv(d, 128, 5, strides=2)\n    \n    flat = Flatten()(d)\n    fc1 = Dense(1024, activation='relu')(flat)\n    d_output = Dense(1, activation='sigmoid')(fc1)\n    \n    return Model(d_input, d_output)","4320bcb3":"# Discriminator initialization\nDCRM = build_discriminator()\nDCRM.compile(loss=dcrm_loss, optimizer=DCRM_OPTIMIZER)\nif SHOW_SUMMARY:\n    DCRM.summary()","ce536677":"def gen_loss(y_true, y_pred):\n    G_MSE_loss = K.mean(K.square(y_pred - y_true))\n    return G_MSE_loss - ALPHA * tf.reduce_mean(tf.log(tf.maximum(y_pred, EPSILON)))\n\ng_input_shape = (INPUT_SHAPE[0], int(INPUT_SHAPE[1] * (MASK_PERCENTAGE *2)), INPUT_SHAPE[2])\ng_dropout = 0.25\nGEN_OPTIMIZER = Adam(0.001, 0.5)","8660b652":"def g_build_conv(layer_input, filter_size, kernel_size=4, strides=2, activation='leakyrelu', dropout_rate=g_dropout, norm='inst', dilation=1):\n    c = AtrousConvolution2D(filter_size, kernel_size=kernel_size, strides=strides,atrous_rate=(dilation,dilation), padding='same')(layer_input)\n    if activation == 'leakyrelu':\n        c = ReLU()(c)\n    if dropout_rate:\n        c = Dropout(dropout_rate)(c)\n    if norm == 'inst':\n        c = InstanceNormalization()(c)\n    return c\n\n\ndef g_build_deconv(layer_input, filter_size, kernel_size=3, strides=2, activation='relu', dropout=0):\n    d = Conv2DTranspose(filter_size, kernel_size=kernel_size, strides=strides, padding='same')(layer_input)\n    if activation == 'relu':\n        d = ReLU()(d)\n    return d\n\n\ndef build_generator():\n    g_input = Input(shape=g_input_shape)\n    \n    g1 = g_build_conv(g_input, 64, 5, strides=1)\n    g2 = g_build_conv(g1, 128, 4, strides=2)\n    g3 = g_build_conv(g2, 256, 4, strides=2)\n\n    g4 = g_build_conv(g3, 512, 4, strides=1)\n    g5 = g_build_conv(g4, 512, 4, strides=1)\n    \n    g6 = g_build_conv(g5, 512, 4, strides=1, dilation=2)\n    g7 = g_build_conv(g6, 512, 4, strides=1, dilation=4)\n    g8 = g_build_conv(g7, 512, 4, strides=1, dilation=8)\n    g9 = g_build_conv(g8, 512, 4, strides=1, dilation=16)\n    \n    g10 = g_build_conv(g9, 512, 4, strides=1)\n    g11 = g_build_conv(g10, 512, 4, strides=1)\n    \n    g12 = g_build_deconv(g11, 256, 4, strides=2)\n    g13 = g_build_deconv(g12, 128, 4, strides=2)\n    \n    g14 = g_build_conv(g13, 128, 4, strides=1)\n    g15 = g_build_conv(g14, 64, 4, strides=1)\n    \n    g_output = AtrousConvolution2D(3, kernel_size=4, strides=(1,1), activation='tanh',padding='same', atrous_rate=(1,1))(g15)\n    \n    return Model(g_input, g_output)","c49cba11":"# Generator Initialization\nGEN = build_generator()\nGEN.compile(loss=gen_loss, optimizer=GEN_OPTIMIZER)\nif SHOW_SUMMARY:\n    GEN.summary()","ca2e0394":"IMAGE = Input(shape=g_input_shape)\nDCRM.trainable = False\nGENERATED_IMAGE = GEN(IMAGE)\nCONF_GENERATED_IMAGE = DCRM(GENERATED_IMAGE)\n\nCOMBINED = Model(IMAGE, [CONF_GENERATED_IMAGE, GENERATED_IMAGE])\nCOMBINED.compile(loss=['mse', 'mse'], optimizer=GEN_OPTIMIZER)","631dd112":"def mask_width(img):\n    image = img.copy()\n    height = image.shape[0]\n    width = image.shape[1]\n    new_width = int(width * MASK_PERCENTAGE)\n    mask = np.ones([height, new_width, 3])\n    missing_x = img[:, :new_width]\n    missing_y = img[:, width - new_width:]\n    missing_part = np.concatenate((missing_x, missing_y), axis=1)\n    image = image[:, :width - new_width]\n    image = image[:, new_width:]\n    return image, missing_part\n\n\ndef get_masked_images(images):\n    mask_images = []\n    missing_images = []\n    for image in images:\n        mask_image, missing_image = mask_width(image)\n        mask_images.append(mask_image)\n        missing_images.append(missing_image)\n    return np.array(mask_images), np.array(missing_images)\n\n\ndef get_demask_images(original_images, generated_images):\n    demask_images = []\n    for o_image, g_image in zip(original_images, generated_images):\n        width = g_image.shape[1] \/\/ 2\n        x_image = g_image[:, :width]\n        y_image = g_image[:, width:]\n        o_image = np.concatenate((x_image,o_image, y_image), axis=1)\n        demask_images.append(o_image)\n    return np.asarray(demask_images)","75d7a8fa":"# Masking, Demasking example\n# Note: IPython display gives false colors.\nx = data.get_data(1)\n\n# a will be the input and b will be the output for the model\na, b = get_masked_images(x)\nborder = np.ones([x[0].shape[0], 10, 3]).astype(np.uint8)\nprint('After masking')\nprint('\\tOriginal Image\\t\\t\\t a \\t\\t b')\nimage = np.concatenate((border, x[0],border,a[0],border, b[0], border), axis=1)\nIPython.display.display(PIL.Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)))\n\nprint(\"After desmasking: 'b\/2' + a + 'b\/2' \")\nc = get_demask_images(a,b)\nIPython.display.display(PIL.Image.fromarray(cv2.cvtColor(c[0], cv2.COLOR_BGR2RGB)))","8322cc50":"def save_model():\n    global DCRM, GEN\n    models = [DCRM, GEN]\n    model_names = ['DCRM','GEN']\n\n    for model, model_name in zip(models, model_names):\n        model_path =  CHECKPOINT + \"%s.json\" % model_name\n        weights_path = CHECKPOINT + \"\/%s.hdf5\" % model_name\n        options = {\"file_arch\": model_path, \n                    \"file_weight\": weights_path}\n        json_string = model.to_json()\n        open(options['file_arch'], 'w').write(json_string)\n        model.save_weights(options['file_weight'])\n    print(\"Saved Model\")\n    \n    \ndef load_model():\n    # Checking if all the model exists\n    model_names = ['DCRM', 'GEN']\n    files = os.listdir(CHECKPOINT)\n    for model_name in model_names:\n        if model_name+\".json\" not in files or\\\n           model_name+\".hdf5\" not in files:\n            print(\"Models not Found\")\n            return\n    global DCRM, GEN, COMBINED, IMAGE, GENERATED_IMAGE, CONF_GENERATED_IMAGE\n    \n    # load DCRM Model\n    model_path = CHECKPOINT + \"%s.json\" % 'DCRM'\n    weight_path = CHECKPOINT + \"%s.hdf5\" % 'DCRM'\n    with open(model_path, 'r') as f:\n        DCRM = model_from_json(f.read())\n    DCRM.load_weights(weight_path)\n    DCRM.compile(loss=dcrm_loss, optimizer=DCRM_OPTIMIZER)\n    \n    #load GEN Model\n    model_path = CHECKPOINT + \"%s.json\" % 'GEN'\n    weight_path = CHECKPOINT + \"%s.hdf5\" % 'GEN'\n    with open(model_path, 'r') as f:\n         GEN = model_from_json(f.read(), custom_objects={'InstanceNormalization': InstanceNormalization()})\n    GEN.load_weights(weight_path)\n    \n    # Combined Model\n    DCRM.trainable = False\n    IMAGE = Input(shape=g_input_shape)\n    GENERATED_IMAGE = GEN(IMAGE)\n    CONF_GENERATED_IMAGE = DCRM(GENERATED_IMAGE)\n\n    COMBINED = Model(IMAGE, [CONF_GENERATED_IMAGE, GENERATED_IMAGE])\n    COMBINED.compile(loss=['mse', 'mse'], optimizer=GEN_OPTIMIZER)\n    \n    print(\"loaded model\")\n    \n    \ndef save_image(epoch, steps):\n    train_image = test_data.get_data(1)\n    if train_image is None:\n        train_image = test_data.get_data(1)\n        \n    test_image = data.get_data(1)\n    if test_image is None:\n        test_image = test_data.get_data(1)\n    \n    for nc, original in enumerate([train_image, test_image]):\n        if nc:\n            print(\"Predicting with train image\")\n        else:\n            print(\"Predicting with test image\")\n            \n        mask_image_original , missing_image = get_masked_images(original)\n        mask_image = mask_image_original.copy()\n        mask_image = mask_image \/ 127.5 - 1\n        missing_image = missing_image \/ 127.5 - 1\n        gen_missing = GEN.predict(mask_image)\n        gen_missing = (gen_missing + 1) * 127.5\n        gen_missing = gen_missing.astype(np.uint8)\n        demask_image = get_demask_images(mask_image_original, gen_missing)\n\n        mask_image = (mask_image + 1) * 127.5\n        mask_image = mask_image.astype(np.uint8)\n\n        border = np.ones([original[0].shape[0], 10, 3]).astype(np.uint8)\n\n        file_name = str(epoch) + \"_\" + str(steps) + \".jpg\"\n        final_image = np.concatenate((border, original[0],border,mask_image_original[0],border, demask_image[0], border), axis=1)\n        if not nc:\n            cv2.imwrite(os.path.join(SAVED_IMAGES, file_name), final_image)\n        final_image = cv2.cvtColor(final_image, cv2.COLOR_BGR2RGB)\n        print(\"\\t1.Original image \\t 2.Input \\t\\t 3. Output\")\n        IPython.display.display(PIL.Image.fromarray(final_image))\n        print(\"image saved\")\n\n\ndef save_log(log):\n    with open('log.txt', 'a') as f:\n        f.write(\"%s\\n\"%log)","3f37ce64":"def train():\n    start_time = datetime.now()\n    saved_time = start_time\n    \n    global MIN_D_LOSS, MIN_G_LOSS, CURRENT_D_LOSS, CURRENT_G_LOSS\n    for epoch in range(1, EPOCHS):\n        steps = 1\n        test = None\n        while True:\n            original = data.get_data(BATCH)\n            if original is None:\n                break\n            batch_size = original.shape[0]\n\n            mask_image, missing_image = get_masked_images(original)\n            mask_image = mask_image \/ 127.5 - 1\n            missing_image = missing_image \/ 127.5 - 1\n\n            # Train Discriminator\n            gen_missing = GEN.predict(mask_image)\n\n            real = np.ones([batch_size, 1])\n            fake = np.zeros([batch_size, 1])\n            \n            d_loss_original = DCRM.train_on_batch(missing_image, real)\n            d_loss_mask = DCRM.train_on_batch(gen_missing, fake)\n            d_loss = 0.5 * np.add(d_loss_original, d_loss_mask)\n\n            # Train Generator\n            for i in range(2):\n                g_loss = COMBINED.train_on_batch(mask_image, [real, missing_image])\n                    \n            log = \"epoch: %d, steps: %d, DIS loss: %s, GEN loss: %s, Identity loss: %s\" \\\n                                            %(epoch, steps, str(d_loss), str(g_loss[0]), str(g_loss[2]))\n            print(log)\n            save_log(log)\n            steps += 1\n            \n            # Save model if time taken > TIME_INTERVALS\n            current_time = datetime.now()\n            difference_time = current_time - saved_time\n            if difference_time.seconds >= (TIME_INTERVALS * 60):\n                save_model()\n                save_image(epoch, steps)\n                saved_time = current_time\n        clear_output()\n        ","e335d9cc":"load_model()","11615886":"train()","be0d874d":"load_model()","7ed2279d":"def recursive_paint(image, factor=3):\n    final_image = None\n    gen_missing = None\n    for i in range(factor):\n        demask_image = None\n        if i == 0:\n            x, y = get_masked_images([image])\n            gen_missing = GEN.predict(x)\n            final_image = get_demask_images(x, gen_missing)[0]\n        else:\n            gen_missing = GEN.predict(gen_missing)\n            final_image = get_demask_images([final_image], gen_missing)[0]\n    return final_image\n        ","03265fce":"images = data.get_data(1)\nfor i, image in enumerate(images):\n    image = image \/ 127.5 - 1\n    image = recursive_paint(image)\n    image = (image + 1) * 127.5\n    image = image.astype(np.uint8)\n    path = 'recursive\/'+str(i)+'.jpg'\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    IPython.display.display(PIL.Image.fromarray(image))","669409bc":"url = 'https:\/\/upload.wikimedia.org\/wikipedia\/commons\/3\/33\/A_beach_in_Maldives.jpg'\n\nfile_name = os.path.basename(url)\nimport urllib.request\n_ = urllib.request.urlretrieve(url, file_name)\nprint(\"Downloaded image\")\n\nimage = cv2.imread(file_name)\nimage = cv2.resize(image, (256,256))\ncropped_image = image[:, 65:193]\ninput_image = cropped_image \/ 127.5 - 1\ninput_image = np.expand_dims(input_image, axis=0)\nprint(input_image.shape)\npredicted_image = GEN.predict(input_image)\npredicted_image = get_demask_images(input_image, predicted_image)[0]\npredicted_image = (predicted_image + 1) * 127.5\npredicted_image = predicted_image.astype(np.uint8)\n\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\npredicted_image = cv2.cvtColor(predicted_image, cv2.COLOR_BGR2RGB)\n\nprint('original image')\nIPython.display.display(PIL.Image.fromarray(image))\nprint('predicted image')\nIPython.display.display(PIL.Image.fromarray(predicted_image))\n\nos.remove(file_name)","7efe5d57":"### Masking and De-Masking","848f2002":"### Utilities\n1. Save Model\n2. Load Model\n3. Save Image\n4. Save Log","fee19129":"### Generator Model","1e2d9f8e":"# Out Paint","617befd2":"### Discriminator","570d54f9":"### Combined Model","b5b55dc8":"## Test from URL","2fd137b4":"## Recursive paint","446dc860":"## Models","aaff700e":"## Train"}}