{"cell_type":{"48b369b3":"code","f200473c":"code","360eac00":"code","d2a89b8c":"code","1914e880":"code","34cc4fa0":"code","5c9a25c0":"code","3c656263":"code","80ac89b4":"code","806eb26d":"code","45716ae6":"code","3883b620":"code","4bdeb776":"markdown","cf5c9262":"markdown","cb669c79":"markdown","01b22298":"markdown","bda1c8c3":"markdown","b5c33510":"markdown","a1a149fa":"markdown","2b9ebb92":"markdown","80867a0c":"markdown"},"source":{"48b369b3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f200473c":"from imblearn.over_sampling import SMOTENC\nimport tensorflow as tf\nimport numpy as np\nimport sys\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom scipy import stats\nfrom sklearn.model_selection import RandomizedSearchCV","360eac00":"df=pd.read_csv(\"\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\")","d2a89b8c":"x = df.drop(\"DEATH_EVENT\", axis = 1)\ny = df.DEATH_EVENT","1914e880":"scaler = MinMaxScaler()\nx[['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_creatinine', 'serum_sodium', 'time']] = scaler.fit_transform(x[['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_creatinine', 'serum_sodium', 'time']])","34cc4fa0":"def mean_encoding(dataset, collumnname_for_encoding, label_collumn_name):\n    mean_encoded_collum = df.groupby([collumnname_for_encoding])[label_collumn_name].mean().to_dict()\n    return mean_encoded_collum","5c9a25c0":"anaemia_mean_encoding = mean_encoding(df, \"anaemia\", \"DEATH_EVENT\")\nanaemia_mean_encoding = x[\"anaemia\"].map(anaemia_mean_encoding)\n\ndiabetes_mean_encoding = mean_encoding(df, \"diabetes\", \"DEATH_EVENT\")\ndiabetes_mean_encoding = x[\"diabetes\"].map(diabetes_mean_encoding)\n\nhigh_blood_pressure_mean_encoding = mean_encoding(df, \"high_blood_pressure\", \"DEATH_EVENT\")\nhigh_blood_pressure_mean_encoding = x[\"high_blood_pressure\"].map(high_blood_pressure_mean_encoding)\n\nsex_mean_encoding = mean_encoding(df, \"sex\", \"DEATH_EVENT\")\nsex_mean_encoding = x[\"sex\"].map(sex_mean_encoding)\n\nsmoking_mean_encoding = mean_encoding(df, \"smoking\", \"DEATH_EVENT\")\nsmoking_mean_encoding = x[\"smoking\"].map(smoking_mean_encoding)","3c656263":"x['anaemia_mean_encoding'] = anaemia_mean_encoding\nx['diabetes_mean_encoding'] = diabetes_mean_encoding\nx['high_blood_pressure_mean_encoding'] = high_blood_pressure_mean_encoding\nx['sex_mean_encoding'] = sex_mean_encoding\nx['smoking_mean_encoding'] = smoking_mean_encoding","80ac89b4":"z_score = np.abs(stats.zscore(x))\nlocation_of_outliers = np.where(z_score > 3)\nx.drop(location_of_outliers[0], inplace = True)\ny.drop(location_of_outliers[0], inplace = True)","806eb26d":"new_x, new_y = SMOTENC(categorical_features=[1,3,5,9,10]).fit_resample(x, y)","45716ae6":"x_train, x_test, y_train, y_test = train_test_split(new_x, new_y, test_size = 0.2, random_state = 25)","3883b620":"random_forest = RandomForestClassifier(max_depth=12, random_state=25)\nrandom_forest.fit(x_train, y_train)\ny_hat = random_forest.predict(x_test)\nAccuracy = accuracy_score(y_test, y_hat)\nprint(\"Accuracy : \",Accuracy)\nprint(accuracy_score(y_train, random_forest.predict(x_train)))","4bdeb776":"### Removal of outliers via the Z score","cf5c9262":"### Importing dependencies","cb669c79":"Was going to use residual boosting but due to the train accuracy being so high (100%) there is no point, due to the second algorithm having no errors to work with","01b22298":"### Loading the dataset","bda1c8c3":"### Modeling","b5c33510":"# Heart Failiure prediciton model","a1a149fa":"### Splitting the data into training and test sets","2b9ebb92":"### Scaling features (making them all of equal scale)","80867a0c":"### Mean encoding"}}