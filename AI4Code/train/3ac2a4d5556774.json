{"cell_type":{"cfb53c84":"code","52f4482f":"code","eeda206a":"code","70a7d214":"code","08ef4ccc":"code","27febee2":"code","0c13dff6":"code","7ec05cd2":"code","321109ae":"code","e7c6d82d":"code","e901b2a8":"code","a479af1d":"code","ed4fbd3b":"code","4df2bc6f":"code","e3e10faf":"code","c57c90d5":"code","f4d86efc":"code","f38f4c74":"code","760b513a":"code","fbfb403a":"code","53b6d517":"markdown","ecf42a43":"markdown","d29b9dd7":"markdown","9d4d2572":"markdown","937d2609":"markdown","baa760ad":"markdown","4536c8f6":"markdown","2ead615d":"markdown","d6dcfc0e":"markdown","e3ca8717":"markdown","02c093e0":"markdown"},"source":{"cfb53c84":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.impute import KNNImputer\nfrom sklearn.model_selection import train_test_split\nfrom scipy import stats\nimport statistics as stat\nimport matplotlib.pyplot as plt","52f4482f":"df = pd.read_csv(\"..\/input\/water-potability\/water_potability.csv\",na_values=\"?\")\ndf.head()","eeda206a":"df.isna().sum()","70a7d214":"df = df.apply(lambda x: x.fillna(x.mean()),axis=0)\ndf.head()","08ef4ccc":"def z_score_method(df, variable_name):\n    #Takes two parameters: dataframe & variable of interest as string\n    columns = df.columns\n    z = np.abs(stats.zscore(df))\n    threshold = 3\n    outlier = []\n    index=0\n    for item in range(len(columns)):\n        if columns[item] == variable_name:\n            index = item\n    for i, v in enumerate(z[:, index]):\n        if v > threshold:\n            outlier.append(i)\n        else:\n            continue\n    return outlier","27febee2":"outlier = []\ncol = []\nfor i,k in enumerate(df.columns):\n    outlier.append(z_score_method(df,k))\n    if outlier[i] != []:\n        col.append(k)\n\n#handle outlier\nind = 0\nfor i in range(len(outlier)):\n    if (outlier[i] == []):\n        continue\n    else:\n        for j in (outlier[i]):\n            df[col[ind]].values[j] = stat.median(df[col[ind]])\n        ind += 1","0c13dff6":"plt.figure(figsize=(15,10))\nsns.heatmap(df.corr(),annot=True,cmap='coolwarm')","7ec05cd2":"f, axes = plt.subplots(3, 3, figsize=(15,8))\ndf.boxplot(column=['ph'],ax = axes[0,0])\ndf.boxplot(column=['Hardness'],ax = axes[0,1])\ndf.boxplot(column=['Solids'],ax = axes[0,2])\ndf.boxplot(column=['Chloramines'],ax = axes[1,0])\ndf.boxplot(column=['Sulfate'],ax = axes[1,1])\ndf.boxplot(column=['Conductivity'],ax = axes[1,2])\ndf.boxplot(column=['Organic_carbon'],ax = axes[2,0])\ndf.boxplot(column=['Trihalomethanes'],ax = axes[2,1])\ndf.boxplot(column=['Turbidity'],ax = axes[2,2])","321109ae":"def distributionPlot(dataset):\n    \"\"\" \n    Creates distribution plot.\n    \"\"\"\n    fig = plt.figure(figsize=(20, 20))\n    for i in range(0, len(dataset.columns)):\n        fig.add_subplot(np.ceil(len(dataset.columns)\/3), 3, i+1)\n        sns.distplot(dataset.iloc[:, i], color=\"lightcoral\", rug=True)\n        fig.tight_layout(pad=3.0)","e7c6d82d":"distributionPlot(df.drop(['Potability'], axis=1))","e901b2a8":"X = df.iloc[:,:-1]\ny = df.iloc[:,-1]","a479af1d":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.15,random_state=100)","ed4fbd3b":"sns.countplot(x = \"Potability\",data = pd.concat([pd.DataFrame(X_train),pd.DataFrame(y_train)]))","4df2bc6f":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train = sc.fit_transform(X_train)\nx_test = sc.transform(X_test)","e3e10faf":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV","c57c90d5":"key = ['LogisticRegression','KNeighborsClassifier','SVC','DecisionTreeClassifier','RandomForestClassifier',\n       'GradientBoostingClassifier','AdaBoostClassifier','XGBClassifier']\nparam_grid = {'n_estimators': [100, 200, 300, 400, 500, 1000], 'max_features': ['auto', 'sqrt'], 'bootstrap': [True, False], 'criterion':['entropy', 'gini']}\nvalue = [LogisticRegression(),KNeighborsClassifier(algorithm = 'kd_tree', n_jobs = 1, n_neighbors = 1, weights = 'uniform'),\n         SVC(C=.5, gamma = 0.1,kernel = 'rbf'),\n         DecisionTreeClassifier(),GridSearchCV(RandomForestClassifier(), param_grid, verbose=100, cv=10, n_jobs=-2),GradientBoostingClassifier(),AdaBoostClassifier(),xgb.XGBClassifier()]\nmodels = dict(zip(key,value))\nprint(models)","f4d86efc":"predicted =[]\nfor name,algo in models.items():\n    model=algo\n    model.fit(x_train,y_train)\n    predict = model.predict(x_test)\n    acc = accuracy_score(y_test, predict)\n    predicted.append(acc)\n    print(name,acc)","f38f4c74":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom datetime import datetime","760b513a":" #creating model\nmodel = Sequential()\n\nneuron_hidden = [100,75,30,1]\nact_func = ['relu','relu','relu','sigmoid']\n\nfor i in range(len(neuron_hidden)):\n    if i == 0:\n        model.add(Dense(neuron_hidden[0], input_dim=x_train.shape[1], activation=act_func[0]))\n    else:\n        model.add(Dense(neuron_hidden[i], activation=act_func[i]))\n\n######### compile the keras model #########\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nhistory = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs=100, batch_size=64, verbose=0, shuffle = False)\n_,acc_train = model.evaluate(x_train,y_train,verbose = 0)\n_,acc_test = model.evaluate(x_test,y_test, verbose = 0)\nprint('acc train: ',acc_train,'acc test: ',acc_test)","fbfb403a":"key.append('ANN')\npredicted.append(acc_test)\n\nplt.figure(figsize = (10,5))\nsns.barplot(x = predicted, y = key)","53b6d517":"## Standarize Data","ecf42a43":"## Impute using KNN","d29b9dd7":"## Machine Learning Model","9d4d2572":"## Split Train Test","937d2609":"## Correlation Matrix","baa760ad":"## Deep Neural Network","4536c8f6":"## Boxplot Visualization","2ead615d":"## Check Missing Value","d6dcfc0e":"## Outlier check and handling outlier","e3ca8717":"## Data Distribution","02c093e0":"## Load Data"}}