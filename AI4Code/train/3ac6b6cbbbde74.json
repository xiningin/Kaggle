{"cell_type":{"cd82d25c":"code","8f3ec489":"code","0508c75c":"code","617db4d6":"code","2dcf2b86":"code","39ac5f6f":"code","b25e6540":"code","4aec2dcf":"code","0259a7ca":"code","3f749313":"code","80c3abad":"code","9d018f87":"code","44c5b05f":"code","e920429f":"code","2971ed89":"code","054002a5":"code","93c49f14":"code","265da988":"code","246cbeae":"code","27e4dd11":"code","64338abe":"code","71706f4c":"code","a34a5db7":"code","2d06f31e":"code","76f0857d":"code","b8ae378d":"code","b3a10b65":"markdown","ddd8975a":"markdown","856dbbfe":"markdown","173ffa3b":"markdown","c42b1330":"markdown","173765b6":"markdown","f4e4db8d":"markdown","834ac9d5":"markdown","ba961918":"markdown","4995dda6":"markdown","aa9d8283":"markdown","1260c6b9":"markdown","49ec8e06":"markdown","185ca9ef":"markdown","4b773e28":"markdown","e8068486":"markdown","c45bc7c0":"markdown","9ff231e0":"markdown","680663fb":"markdown","03e2ed8b":"markdown"},"source":{"cd82d25c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport datetime, time, re\nfrom nltk import download\nfrom nltk.tokenize import RegexpTokenizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom bs4 import BeautifulSoup\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom scipy import sparse\n\n\n\ndata = pd.read_csv('\/kaggle\/input\/60k-stack-overflow-questions-with-quality-rate\/train.csv')\n\nstop_words = set(stopwords.words('english'))\ndownload('brown')\ndownload(\"punkt\")\ndownload('stopwords')\n\n\ndata.head()","8f3ec489":"data.isna().sum()","0508c75c":"data.isnull().sum()","617db4d6":"def to_timestamp(date_str):\n    date_str = datetime.datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n    return time.mktime(date_str.timetuple())\ndata['CreationDate'] = data['CreationDate'].apply(to_timestamp)\ndata.head()","2dcf2b86":"data['Y'] = data['Y'].replace({'HQ': 1, 'LQ_EDIT': 2, 'LQ_CLOSE': 3})","39ac5f6f":"tags_vectorizer = CountVectorizer(token_pattern='[a-z\\-]+-*[0-9]*')\ntags = tags_vectorizer.fit_transform(data['Tags'])\nfeature_names = tags_vectorizer.get_feature_names()\ndata = data.drop('Tags', axis=1) # We are not going to use this column anymore\nprint(feature_names[:20])\n                                                                                                                                                                                                            ","b25e6540":"data['Title'] = data['Title'].apply(lambda x: x.lower())\ndata['Body'] = data['Body'].apply(lambda x: x.lower())","4aec2dcf":"def strip_tags(markup):\n    bs = BeautifulSoup(markup, 'html.parser')\n    return bs.get_text()\n\ndata['Title'] = data['Title'].apply(strip_tags)\ndata['Body'] = data['Body'].apply(strip_tags)\ndata.head()","0259a7ca":"def remove_stopwords(text):\n    word_tokens = word_tokenize(text)\n    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n    filtered_sentence = []\n    for w in word_tokens:\n        if w not in stop_words:\n            filtered_sentence.append(w)\n    return ' '.join(filtered_sentence).strip(\"'\")\n            \ntitles = data['Title'].apply(remove_stopwords)\nbodies = data['Body'].apply(remove_stopwords)\ndata.head()","3f749313":"title_vectorizer = TfidfVectorizer(lowercase=False)\ntitles = title_vectorizer.fit_transform(titles)","80c3abad":"bodies_vectorizer = TfidfVectorizer()\nbodies = bodies_vectorizer.fit_transform(bodies)","9d018f87":"print(bodies.shape)","44c5b05f":"data['CreationDate'].shape","e920429f":"X = sparse.hstack((bodies, tags))\nX.get_shape()","2971ed89":"creation_dates = np.matrix(data['CreationDate'])\ncreation_dates.T.shape\nX = sparse.hstack((X, creation_dates.T))\nX.shape","054002a5":"from sklearn.preprocessing import RobustScaler\nscaler = RobustScaler(with_centering=False)\nX = scaler.fit_transform(X, data['Y'])","93c49f14":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, data['Y'], test_size=0.3, random_state=1)","265da988":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\n","246cbeae":"knn.score(X_train, y_train)","27e4dd11":"from sklearn.metrics import plot_confusion_matrix\nimport matplotlib.pyplot as plt\n\ndisp = plot_confusion_matrix(\n    knn, \n    X_test, \n    y_test, \n    display_labels=knn.classes_, \n    normalize=None\n)\n\nplt.show()","64338abe":"from sklearn.naive_bayes import MultinomialNB\n\nnaive = MultinomialNB()\nnaive.fit(X_train, y_train)","71706f4c":"naive.score(X_train, y_train)","a34a5db7":"disp = plot_confusion_matrix(\n    naive, \n    X_test, \n    y_test, \n    display_labels=knn.classes_, \n    normalize=None\n)\n\nplt.show()","2d06f31e":"from sklearn.cluster import KMeans\n\nkmeans = KMeans(n_clusters=3, random_state=0).fit(X_train)\n\nfor i, cluster in enumerate(kmeans.cluster_centers_):\n    print (f\"Group {i}\")\n    for f, m in zip(data.columns, cluster):\n        print(f, round(m, 0))\n    print()","76f0857d":"X.indices","b8ae378d":"from nltk.tokenize import blankline_tokenize\ndef question_quality(text):\n    text = strip_tags(text)\n    text = text.lower()\n    text = remove_stopwords(text)\n    text = blankline_tokenize(text)\n    #vectorizer = TfidfVectorizer(lowercase=False)\n    #vector = vectorizer.fit_transform(text)\n    vector = bodies_vectorizer.transform(text)\n    return kmeans.predict(vector)\n\n\nquestion = \"\"\"My Code:\n\nvar latlng = {lat: 7, lng: 7};\n\nfunction findLatLng() {\n    var testLocation = '350 Victoria St, Toronto';\n\n    axios.get('https:\/\/maps.googleapis.com\/maps\/api\/geocode\/json', {\n        params: {\n            address: testLocation,\n            key: 'MY KEY',\n        }\n    })\n    .then(function(response) {\n        console.log(response.data.results[0].geometry.location);\n        return response.data.results[0].geometry.location;\n    })\n    .catch(function(error) {\n        console.log(error);\n    });\n}\n\nlatlng = findLatLng();\nconsole.log(latlng);\nIn the console, latlng is logged as undefined, but the console.log(response.data.results[0].geometry.location) is logged with the proper value; it is also logged afterwards even though it should have executed first. I think this is because the code continues on despite findLatLng() not being done with the request but I'm not sure. When I check the value of latlng in the console afterwards, it becomes the proper value.\n\nWhat is the issue and how do I fix this please? \"\"\"\nprint(question_quality(question))","b3a10b65":"#### Confusion matrix","ddd8975a":"## Prediction function","856dbbfe":"### Encoding of the ***Y*** column","173ffa3b":"### Feature traits","c42b1330":"### Normalization of **Title** and **Body** columns","173765b6":"## Test\/Train split","f4e4db8d":"#### KNN Accuracy","834ac9d5":"#### Confusion Matrix","ba961918":"# 60k Stack Overflow Questions with Quality Rating","4995dda6":"#### Naive Bayes Accuracy","aa9d8283":"### Scaling","1260c6b9":"### Vectorization of **Title** and **Body** columns","49ec8e06":"## Data Analysis","185ca9ef":"## Model Training\nWe are going to train a K-Nearest Neighbors Classifier and a Naive Bayes Classifier\n\n### KNN\n","4b773e28":"### Strip HTML tags from **Body**","e8068486":"# Dataset load & description","c45bc7c0":"### Naive Bayes","9ff231e0":"### Tag encoding using CountVectorizer","680663fb":"## Normalization & Encoding","03e2ed8b":"### **CreationDate** conversion to timestamp"}}