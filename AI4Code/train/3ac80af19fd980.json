{"cell_type":{"be91b2de":"code","0e55b072":"code","60414ac3":"code","4fb21453":"code","aebd6c5a":"code","8b0a5cd8":"code","03d00de8":"code","5db4da4f":"code","8208ef25":"code","3583797f":"code","d2b5c1fd":"code","643a455f":"code","845e8f27":"code","83d4d49f":"code","856f2925":"code","d307bafe":"code","82cf38ad":"code","6b65deb0":"code","9788c929":"code","148d9bce":"code","d04ff05f":"code","b8241cc9":"markdown","69f3a3fb":"markdown","3f1da0e6":"markdown","5fa324f4":"markdown","35a8d7b3":"markdown"},"source":{"be91b2de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","0e55b072":"# print(os.listdir(\"..\/input\/csrnet-pytorch\/task_one_model_best.pth.tar\"))","60414ac3":"print(os.listdir(\"..\/input\/shanghaitech-with-people-density-map\/shanghaitech_with_people_density_map\/ShanghaiTech\"))","4fb21453":"DATA_PATH = \"..\/input\/shanghaitech-with-people-density-map\/shanghaitech_with_people_density_map\/ShanghaiTech\/part_A\/train_data\/\"\nTEST_DATA_PATH = \"..\/input\/shanghaitech-with-people-density-map\/shanghaitech_with_people_density_map\/ShanghaiTech\/part_A\/test_data\/\"","aebd6c5a":"# PRETRAIN_BASED = \"..\/input\/csrnet-pytorch-parta-30-60-run-two\/\"\n# print(os.listdir(PRETRAIN_BASED))","8b0a5cd8":"TASK_ID = \"task_two_\"","03d00de8":"PRETRAIN_MODEL_BASE = \"..\/input\/csrnet-pytorch-parta-60-90-run-two\/\"\nprint(os.listdir(PRETRAIN_MODEL_BASE))\nPRETRAINED_MODEL = os.path.join(PRETRAIN_MODEL_BASE, TASK_ID+\"checkpoint.pth.tar\")","5db4da4f":"assert os.path.isfile(PRETRAINED_MODEL) == True","8208ef25":"print(os.listdir(DATA_PATH))","3583797f":"import h5py\nimport torch\nimport shutil\n\ndef save_net(fname, net):\n    with h5py.File(fname, 'w') as h5f:\n        for k, v in net.state_dict().items():\n            h5f.create_dataset(k, data=v.cpu().numpy())\ndef load_net(fname, net):\n    with h5py.File(fname, 'r') as h5f:\n        for k, v in net.state_dict().items():        \n            param = torch.from_numpy(np.asarray(h5f[k]))         \n            v.copy_(param)\n            \ndef save_checkpoint(state, is_best,task_id, filename='checkpoint.pth.tar'):\n    torch.save(state, task_id+filename)\n    if is_best:\n        shutil.copyfile(task_id+filename, task_id+'model_best.pth.tar')            ","d2b5c1fd":"import torch.nn as nn\nimport torch\nfrom torchvision import models\n\nclass CSRNet(nn.Module):\n    def __init__(self, load_weights=False):\n        super(CSRNet, self).__init__()\n        self.seen = 0\n        self.frontend_feat = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512]\n        self.backend_feat  = [512, 512, 512,256,128,64]\n        self.frontend = make_layers(self.frontend_feat)\n        self.backend = make_layers(self.backend_feat,in_channels = 512,dilation = True)\n        self.output_layer = nn.Conv2d(64, 1, kernel_size=1)\n        if not load_weights:\n            mod = models.vgg16(pretrained = True)\n            self._initialize_weights()\n            for i in range(len(list(self.frontend.state_dict().items()))):\n                list(self.frontend.state_dict().items())[i][1].data[:] = list(mod.state_dict().items())[i][1].data[:]\n    def forward(self,x):\n        x = self.frontend(x)\n        x = self.backend(x)\n        x = self.output_layer(x)\n        return x\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.normal_(m.weight, std=0.01)\n                if m.bias is not None:\n                    nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            \n                \ndef make_layers(cfg, in_channels = 3,batch_norm=False,dilation = False):\n    if dilation:\n        d_rate = 2\n    else:\n        d_rate = 1\n    layers = []\n    for v in cfg:\n        if v == 'M':\n            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n        else:\n            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=d_rate,dilation = d_rate)\n            if batch_norm:\n                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n            else:\n                layers += [conv2d, nn.ReLU(inplace=True)]\n            in_channels = v\n    return nn.Sequential(*layers)                ","643a455f":"\"\"\"\ncontain dummy args with config\nhelpfull for copy paste Kaggle\n\"\"\"\nimport argparse\n\n\ndef make_args(train_json= \"\", test_json=\"\", pre=\"\", gpu=\"0\", task=\"task_one_\"):\n    \"\"\"\n    these arg does not have any required commandline arg (all with default value)\n    :param train_json:\n    :param test_json:\n    :param pre:\n    :param gpu:\n    :param task:\n    :return:\n    \"\"\"\n    parser = argparse.ArgumentParser(description='PyTorch CSRNet')\n\n    args = parser.parse_args()\n    args.gpu = gpu\n    args.task = task\n    args.pre = None\n    return args\n\n\nclass Meow():\n    def __init__(self):\n        pass\n\n\ndef make_meow_args(gpu=\"0\", task=\"task_one_\"):\n    args = Meow()\n    args.gpu = gpu\n    args.task = task\n    args.pre = None\n    return args","845e8f27":"import os\nimport glob\nfrom sklearn.model_selection import train_test_split\nimport json\n\"\"\"\ncreate a list of file (full directory)\n\"\"\"\n\ndef create_training_image_list(data_path):\n    \"\"\"\n    create a list of absolutely path of jpg file\n    :param data_path: must contain subfolder \"images\" with *.jpg  (example ShanghaiTech\/part_A\/train_data\/)\n    :return:\n    \"\"\"\n    DATA_PATH = data_path\n    image_path_list = glob.glob(os.path.join(DATA_PATH, \"images\", \"*.jpg\"))\n    return image_path_list\n\n\ndef get_train_val_list(data_path):\n    DATA_PATH = data_path\n    image_path_list = glob.glob(os.path.join(DATA_PATH, \"images\", \"*.jpg\"))\n    train, val = train_test_split(image_path_list, test_size=0.1)\n\n    print(\"train size \", len(train))\n    print(\"val size \", len(val))\n    return train, val","83d4d49f":"import random\nimport os\nfrom PIL import Image,ImageFilter,ImageDraw\nimport numpy as np\nimport h5py\nfrom PIL import ImageStat\nimport cv2\n\ndef load_data(img_path,train = True):\n    gt_path = img_path.replace('.jpg','.h5').replace('images','ground-truth-h5')\n    img = Image.open(img_path).convert('RGB')\n    gt_file = h5py.File(gt_path, 'r')\n    target = np.asarray(gt_file['density'])\n\n    target = cv2.resize(target,(int(target.shape[1]\/8), int(target.shape[0]\/8)),interpolation = cv2.INTER_CUBIC)*64\n    \n    return img,target","856f2925":"import os\nimport random\nimport torch\nimport numpy as np\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport torchvision.transforms.functional as F\n\n\nclass ListDataset(Dataset):\n    def __init__(self, root, shape=None, shuffle=True, transform=None,  train=False, seen=0, batch_size=1, num_workers=4):\n        \"\"\"\n        if you have different image size, then batch_size must be 1\n        :param root:\n        :param shape:\n        :param shuffle:\n        :param transform:\n        :param train:\n        :param seen:\n        :param batch_size:\n        :param num_workers:\n        \"\"\"\n        if train:\n            root = root *4\n        if shuffle:\n            random.shuffle(root)\n        \n        self.nSamples = len(root)\n        self.lines = root\n        self.transform = transform\n        self.train = train\n        self.shape = shape\n        self.seen = seen\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n        \n    def __len__(self):\n        return self.nSamples\n\n    def __getitem__(self, index):\n        assert index <= len(self), 'index range error' \n        \n        img_path = self.lines[index]\n        \n        img,target = load_data(img_path,self.train)\n        \n        #img = 255.0 * F.to_tensor(img)\n        \n        #img[0,:,:]=img[0,:,:]-92.8207477031\n        #img[1,:,:]=img[1,:,:]-95.2757037428\n        #img[2,:,:]=img[2,:,:]-104.877445883\n\n\n        \n        \n        if self.transform is not None:\n            img = self.transform(img)\n        return img,target","d307bafe":"import sys\nimport os\n\nimport warnings\n\n# import from library\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torchvision import datasets, transforms\nimport numpy as np\nimport argparse\nimport json\nimport cv2\nimport time\n\n\"\"\"\nA dublicate of train.py \nHowever it does not need commandline arg\n\"\"\"\n\n\n\ndef main():\n    global args, best_prec1\n    args = make_meow_args(task=TASK_ID)\n\n\n    best_prec1 = 1e6\n\n    args.original_lr = 1e-7\n    args.lr = 1e-7\n    args.batch_size = 1\n    args.momentum = 0.95\n    args.decay = 5 * 1e-4\n    args.start_epoch = 0\n    args.epochs = 120\n    args.steps = [-1, 1, 100, 150]\n    args.scales = [1, 1, 1, 1]\n    args.workers = 4\n    args.seed = time.time()\n    args.print_freq = 30\n    args.pre = PRETRAINED_MODEL\n\n    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n    torch.cuda.manual_seed(args.seed)\n\n    train_list, val_list = get_train_val_list(DATA_PATH)\n\n    model = CSRNet()\n\n    model = model.cuda()\n\n    criterion = nn.MSELoss(size_average=False).cuda()\n\n    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.decay)\n\n    if args.pre:\n        if os.path.isfile(args.pre):\n            print(\"=> loading checkpoint '{}'\".format(args.pre))\n            checkpoint = torch.load(args.pre)\n            args.start_epoch = checkpoint['epoch']\n            best_prec1 = checkpoint['best_prec1']\n            model.load_state_dict(checkpoint['state_dict'])\n            optimizer.load_state_dict(checkpoint['optimizer'])\n            print(\"=> loaded checkpoint '{}' (epoch {})\"\n                  .format(args.pre, checkpoint['epoch']))\n        else:\n            print(\"=> no checkpoint found at '{}'\".format(args.pre))\n\n    for epoch in range(args.start_epoch, args.epochs):\n        adjust_learning_rate(optimizer, epoch)\n\n        train(train_list, model, criterion, optimizer, epoch)\n        prec1 = validate(val_list, model, criterion)\n\n        is_best = prec1 < best_prec1\n        best_prec1 = min(prec1, best_prec1)\n        print(' * best MAE {mae:.3f} '\n              .format(mae=best_prec1))\n        save_checkpoint({\n            'epoch': epoch + 1,\n            'arch': args.pre,\n            'state_dict': model.state_dict(),\n            'best_prec1': best_prec1,\n            'optimizer': optimizer.state_dict(),\n        }, is_best, args.task)\n\n\ndef train(train_list, model, criterion, optimizer, epoch):\n    losses = AverageMeter()\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n\n    train_loader = torch.utils.data.DataLoader(\n        ListDataset(train_list,\n                            shuffle=True,\n                            transform=transforms.Compose([\n                                transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                                            std=[0.229, 0.224, 0.225]),\n                            ]),\n                            train=True,\n                            seen=model.seen,\n                            batch_size=args.batch_size,\n                            num_workers=args.workers),\n        batch_size=args.batch_size)\n    print('epoch %d, processed %d samples, lr %.10f' % (epoch, epoch * len(train_loader.dataset), args.lr))\n\n    model.train()\n    end = time.time()\n\n    for i, (img, target) in enumerate(train_loader):\n        data_time.update(time.time() - end)\n\n        img = img.cuda()\n        img = Variable(img)\n        output = model(img)\n\n        target = target.type(torch.FloatTensor).unsqueeze(0).cuda()\n        target = Variable(target)\n\n        loss = criterion(output, target)\n\n        losses.update(loss.item(), img.size(0))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        batch_time.update(time.time() - end)\n        end = time.time()\n\n        if i % args.print_freq == 0:\n            print('Epoch: [{0}][{1}\/{2}]\\t'\n                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n                .format(\n                epoch, i, len(train_loader), batch_time=batch_time,\n                data_time=data_time, loss=losses))\n\n\ndef validate(val_list, model, criterion):\n    print('begin test')\n    test_loader = torch.utils.data.DataLoader(\n        ListDataset(val_list,\n                            shuffle=False,\n                            transform=transforms.Compose([\n                                transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                                            std=[0.229, 0.224, 0.225]),\n                            ]), train=False),\n        batch_size=args.batch_size)\n\n    model.eval()\n\n    mae = 0\n    mse = 0\n\n    for i, (img, target) in enumerate(test_loader):\n        img = img.cuda()\n        img = Variable(img)\n        output = model(img)\n\n        mae += abs(output.data.sum() - target.sum().type(torch.FloatTensor).cuda())\n        mse += (output.data.sum() - target.sum().type(torch.FloatTensor).cuda())*(output.data.sum() - target.sum().type(torch.FloatTensor).cuda())\n    mae = mae \/ len(test_loader)\n    mse = mse \/ len(test_loader)\n    mse = torch.sqrt(mse)\n    \n    print(' * MAE {mae:.3f} '\n          .format(mae=mae))\n    print(' * MSE {mse:.3f} '\n          .format(mse=mse))\n\n    return mae\n\n\ndef adjust_learning_rate(optimizer, epoch):\n    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n\n    args.lr = args.original_lr\n\n    for i in range(len(args.steps)):\n\n        scale = args.scales[i] if i < len(args.scales) else 1\n\n        if epoch >= args.steps[i]:\n            args.lr = args.lr * scale\n            if epoch == args.steps[i]:\n                break\n        else:\n            break\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = args.lr\n\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count\n\n\nif __name__ == '__main__':\n    main()","82cf38ad":"test_image_list = create_training_image_list(TEST_DATA_PATH)","6b65deb0":"best_checkpoint = torch.load(TASK_ID+'checkpoint.pth.tar')\nmodel = CSRNet()\n\nmodel = model.cuda()\n\ncriterion = nn.MSELoss(size_average=False).cuda()\n\noptimizer = torch.optim.SGD(model.parameters(), args.lr,\n                            momentum=args.momentum,\n                            weight_decay=args.decay)\nmodel.load_state_dict(best_checkpoint['state_dict'])\noptimizer.load_state_dict(best_checkpoint['optimizer'])","9788c929":"test_result = validate(test_image_list, model, criterion)\n","148d9bce":"best_checkpoint = torch.load(TASK_ID+'model_best.pth.tar')\nmodel = CSRNet()\n\nmodel = model.cuda()\n\ncriterion = nn.MSELoss(size_average=False).cuda()\n\noptimizer = torch.optim.SGD(model.parameters(), args.lr,\n                            momentum=args.momentum,\n                            weight_decay=args.decay)\nmodel.load_state_dict(best_checkpoint['state_dict'])\noptimizer.load_state_dict(best_checkpoint['optimizer'])","d04ff05f":"test_result = validate(test_image_list, model, criterion)\n","b8241cc9":"# Evaluate best","69f3a3fb":"# Evaluate","3f1da0e6":"# Let's import thing first\n\nThese thing is on separate file <br> \nbut since Kaggle only give 1 notebook per kernel, we put all here","5fa324f4":"# Changelog\n- add evaluation","35a8d7b3":"# done import thing, let's go to training code\n"}}