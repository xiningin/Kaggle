{"cell_type":{"7af44a5d":"code","9271048b":"code","e6b035fd":"code","15242894":"code","fd8434e3":"code","d42c8086":"code","d3b3be27":"code","2775ef0e":"code","da0a98ba":"code","4cdb8cc3":"code","8d8b267f":"code","626f9908":"code","ae369a1c":"code","9b31a958":"code","72efa591":"code","2f021085":"code","99497ab0":"code","c43099e8":"code","23736ff0":"code","f342d5ce":"code","61825cf9":"code","ab78d89e":"code","2b8bc7fa":"code","2df32723":"code","cbe67a84":"code","a94d3793":"code","708c998b":"code","0841a3d6":"code","8b6a2aa0":"code","a392e0d9":"code","8d760bf3":"code","ba0d2195":"code","bdd40309":"code","d8e63bfd":"code","9a9ffbf3":"code","04e4a9e7":"code","2033722f":"code","b14e002d":"code","5d6e2ab3":"code","d944df59":"code","797c0cda":"code","a642fc18":"code","43ffc300":"code","a28efab2":"code","58421e42":"code","2623509d":"code","04c8ed14":"code","732d6310":"code","5d1f6b20":"code","95a9fdb0":"code","cd4b87ff":"code","c26d61d5":"code","6fb6a086":"code","3a2faee9":"code","d68ebcb1":"code","41b598ad":"markdown","2540b46b":"markdown","1b099623":"markdown","d926978f":"markdown","082e76a8":"markdown","cd2db440":"markdown","667f1210":"markdown","cf66888f":"markdown","a20e92cb":"markdown","3769a2ea":"markdown","6c2e60eb":"markdown","812b739b":"markdown","1676a611":"markdown","bee413cd":"markdown","63d59e83":"markdown","603ed9bd":"markdown","74f8b520":"markdown","54c6461e":"markdown","889abd00":"markdown","3fbe9356":"markdown","25bb0657":"markdown"},"source":{"7af44a5d":"# datatable library installation\n!pip install ..\/input\/python-datatable\/datatable-0.11.0-cp37-cp37m-manylinux2010_x86_64.whl","9271048b":"import time\nstart_time = time.time()\n\nimport numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\n\nimport sys\nimport gc\nimport datatable as dt","e6b035fd":"# saving the dataset in .jay (binary format)\ndt.fread(\"..\/input\/riiid-test-answer-prediction\/train.csv\").to_jay(\"train.jay\")","15242894":"# reading the dataset from .jay format\nimport datatable as dt\ntrain = dt.fread(\"train.jay\")","fd8434e3":"# transforming to pandas format\ntrain_df = dt.fread(\"train.jay\").to_pandas()\nprint(train.shape)","d42c8086":"# transform 'content_type_id' from bool to int\ntrain_df['content_type_id'] = train_df['content_type_id'] * 1","d3b3be27":"pd.options.display.float_format = '{:.11g}'.format\ntrain_df.describe()","2775ef0e":"train_df_lecture = train_df[train_df['content_type_id'] == 1]\ntrain_df_lecture.shape","da0a98ba":"train_df_lecture['answered_correctly'].value_counts()","4cdb8cc3":"train_df[train_df['answered_correctly'] == -1]['content_type_id'].value_counts()","8d8b267f":"train_df_lecture['prior_question_elapsed_time'].isnull().count()","626f9908":"train_df_lecture['prior_question_had_explanation'].value_counts()","ae369a1c":"del train_df_lecture\ngc.collect()","9b31a958":"print('Number of missing values for every column')\nprint(train_df.isnull().sum())","72efa591":"train_df_questions_only = train_df[train_df['content_type_id'] == 0]\ntrain_df_questions_only['prior_question_had_explanation'].value_counts() \/ (len(train_df_questions_only) - 392506)","2f021085":"train_df_questions_only.groupby('prior_question_had_explanation')['answered_correctly'].mean()","99497ab0":"train_df_explanation_null = train_df[train_df['prior_question_had_explanation'].isnull()]\ntrain_df_explanation_null.shape","c43099e8":"train_df_explanation_null[train_df_explanation_null['timestamp'] == 0].describe()","23736ff0":"train_df_explanation_null[train_df_explanation_null['timestamp'] != 0].describe()","f342d5ce":"del train_df_explanation_null\ngc.collect()","61825cf9":"train_df_elapsed_null = train_df[train_df['prior_question_elapsed_time'].isnull()]\ntrain_df_elapsed_null = train_df_elapsed_null[train_df_elapsed_null['content_type_id'] == 0]\ntrain_df_elapsed_null.shape","ab78d89e":"train_df_timestamp0 = train_df[train_df['timestamp'] == 0]\ntrain_df_timestamp0.shape","2b8bc7fa":"train_df_timestamp0['prior_question_had_explanation'].value_counts()","2df32723":"train_df_elapsed_check = train_df[train_df['prior_question_elapsed_time'] < 10000]\ntrain_df_elapsed_check = train_df_elapsed_check.sort_values('prior_question_elapsed_time')\ntrain_df_elapsed_check['prior_question_elapsed_time'].unique()","cbe67a84":"del train_df_elapsed_null, train_df_timestamp0, train_df_elapsed_check\ngc.collect()","a94d3793":"train_df_questions_only.reset_index(inplace=True, drop=True)\ntrain_df_questions_only","708c998b":"train_df_doubtful_task_id = train_df_questions_only[(train_df_questions_only['task_container_id'].diff() < -1000) & (train_df_questions_only['task_container_id'] != 0)]\ntrain_df_doubtful_task_id","0841a3d6":"train_df_doubtful_container_id_bins = pd.cut(train_df_doubtful_task_id['task_container_id'], [0, 1, 9, 99, 999, 9999, 20000]).value_counts().reset_index()\ntrain_df_doubtful_container_id_bins.columns = ['bins', 'count']\ntrain_df_doubtful_container_id_bins = train_df_doubtful_container_id_bins.sort_values(by=['bins'])\ntrain_df_doubtful_container_id_bins","8b6a2aa0":"del train_df_doubtful_task_id, train_df_doubtful_container_id_bins\ngc.collect()","a392e0d9":"train_df['task_container_id'].value_counts()","8d760bf3":"train_df[train_df['task_container_id'] == 9999]","ba0d2195":"train_df[1896755:1896762]","bdd40309":"train_df[1929138:1929144]","d8e63bfd":"train_df[3101565:3101572]","9a9ffbf3":"train_df[4301504:4301511]","04e4a9e7":"train_df[5295816:5295826]","2033722f":"train_df[21234101:21234110]","b14e002d":"task_accuracy = train_df.groupby('task_container_id')['answered_correctly'].mean()\ntask_accuracy = task_accuracy.rolling(50).mean()\n\nfig = px.line(\n    task_accuracy, \n    title='Answer correctness by task_container_id', \n    height=600, \n    width=800\n)\n\nfig.show()","5d6e2ab3":"del task_accuracy\ngc.collect()","d944df59":"train_df_user_activeness = train_df['user_id'].value_counts()\ntrain_df_user_activeness","797c0cda":"train_df_user_activeness_bins = pd.cut(train_df_user_activeness, [0, 1, 9, 99, 999, 9999, 20000]).value_counts().reset_index()\ntrain_df_user_activeness_bins.columns = ['bins', 'count']\ntrain_df_user_activeness_bins = train_df_user_activeness_bins.sort_values(by=['bins'])\ntrain_df_user_activeness_bins","a642fc18":"user_accuracy = train_df_questions_only.groupby('user_id')['answered_correctly'].mean()\n\nfig = px.histogram(\n    user_accuracy, \n    x=\"answered_correctly\",\n    nbins=100,\n    width=700,\n    height=500,\n    title='Answer correctness by user'\n)\n\nfig.show()","43ffc300":"del train_df_user_activeness, train_df_user_activeness_bins, user_accuracy\ngc.collect()","a28efab2":"train_df['content_id'].value_counts()","58421e42":"train_df_questions_id_check = train_df_questions_only['content_id'].value_counts()\ntrain_df_questions_id_check","2623509d":"train_df_lectures_only = train_df[train_df['content_type_id'] == 1]\ntrain_df_lectures_id_check = train_df_lectures_only['content_id'].value_counts()\ntrain_df_lectures_id_check","04c8ed14":"train_df_popularity_of_questions = pd.cut(train_df_questions_id_check, [0, 1, 10, 100, 1000, 10000, 100000, 210000]).value_counts().reset_index()\ntrain_df_popularity_of_questions.columns = ['bins', 'count']\ntrain_df_popularity_of_questions = train_df_popularity_of_questions.sort_values(by=['bins'])\ntrain_df_popularity_of_questions","732d6310":"del train_df_popularity_of_questions, train_df_lectures_only, train_df_lectures_id_check\ngc.collect()","5d1f6b20":"content_accuracy = train_df_questions_only.groupby('content_id')['answered_correctly'].mean()\n\nfig = px.histogram(\n    content_accuracy, \n    x=\"answered_correctly\",\n    nbins=100,\n    width=700,\n    height=500,\n    title='Answer correctness by content'\n)\n\nfig.show()","95a9fdb0":"del train_df_questions_only, \ngc.collect()","cd4b87ff":"questions_df = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/questions.csv')\nquestions_df.rename(columns={'question_id': 'content_id'}, inplace='True')\nquestions_df","c26d61d5":"questions_df = pd.merge(content_accuracy, questions_df, on='content_id')\nquestions_df","6fb6a086":"part_accuracy = questions_df.groupby('part')['answered_correctly'].mean()\npart_accuracy.columns = ['part', 'answer_correctness']\npart_accuracy","3a2faee9":"fig = px.bar(\n    part_accuracy, \n    title='accuracy by part'\n)\n\nfig.show()","d68ebcb1":"run_time = time.time() - start_time\nprint(run_time)","41b598ad":"<h1><center>Riiid! Answer Correctness Prediction. Data Analysis and visualization.<\/center><\/h1>\n\n<center><img src=\"https:\/\/www.riiid.co\/assets\/main_hero_aied.png\"><\/center>","2540b46b":"**Reading this notebook, you will find,**\n\n1. Incomplete rows (with null values) which might be removed or complemented\n2. Strange task_container_id jumps which might be revised\n3. Analysis of features (answer correctness by features, etc)","1b099623":"# <center>1.2 content_type_id<\/center>\n<a id=\"12\"><\/a>\n<font color=\"Magenta\">**content_type_id**:<\/font> (int8) *0 if the event was a question being posed to the user, 1 if the event was the user watching a lecture.*  \n  \n**The average user answers 51.7 questions (1 \/ 0.01935) per lecture.  \nAll lecture rows have <font color=\"Red\">\"-1\"<\/font> in <font color=\"Magenta\">'answered_correctly'<\/font> and <font color=\"Red\">null<\/font> in <font color=\"Magenta\">'prior_question_elapsed_time'<\/font>. But despite the description, they have <font color=\"Red\">'False'<\/font> value instead of 'null' in <font color=\"Magenta\">'prior_question_had_explanation'<\/font>.**\n\n[Data Description](https:\/\/www.kaggle.com\/c\/riiid-test-answer-prediction\/data) says,\n\"<font color=\"Red\">*The lecture rows in test_df should not be submitted.*<\/font>\"","d926978f":"**Most of the 'timestamp == 0' columns have null values in <font color=\"Magenta\">'prior_question_had_explanation'<\/font>.  \nBut <font color=\"Red\">the remaining 3,976 rows<\/font> have 'False' or 'True' value.  I may remove these rows, too.**","082e76a8":"<a id=\"15\"><\/a>\n# <center>1.5 prior_question_elapsed_time<\/center>\n  \n<font color=\"Magenta\">**prior_question_elapsed_time**:<\/font> *(float32) The average time in milliseconds it took a user to answer each question in the previous question bundle, ignoring any lectures in between. Is null for a user's first question bundle or lecture. Note that the time is the average time a user took to solve each question in the previous bundle. * \n  \n**This column contains 2,351,538 null values. 1,959,032 of them are lectures. The remaining rows are** <font color=\"Red\">'the incomplete 392,506 rows'<\/font>\n  \n**The last two digits of this column seems not to be significant.  Max value is 300,000, I guess the time limit for one bundle is 5 minutes.**","cd2db440":"<a id=\"1\"><\/a>\n# <center>1. train.csv<center>","667f1210":"<a id=\"2\"><\/a>\n# <center>2. questions.csv<center>","cf66888f":"**Thank you for reading my notebook. This notebook is an additional analysis of [Isaienkov's great notebook](https:\/\/www.kaggle.com\/isaienkov\/riiid-answer-correctness-prediction-eda-modeling) from a different angle.  Read his if you haven't. I also reuse some of his code. Thanks, [Isaienkov](https:\/\/www.kaggle.com\/isaienkov).  \nThis is my first open public book. I appreciate if you**  \n# comment and\/or upvote.","a20e92cb":"<a id=\"14\"><\/a>\n# <center>1.4 the incomplete 392,506 rows<\/center>\n  \n**I found 392,506 null values in the <font color=\"Magenta\">'prior_question_had_explanation'<\/font> column. \nOf those <font color=\"Red\">'incomplete 392,506 rows'<\/font>, 392,441 rows' 'timestamps' are zeros, meaning user's first question bundle.  The remaining 65 rows also have lower task_container_ids, inferring <font color=\"Chocolate\">'the onboarding diagnostic test'<\/font>. Answer correctness is not so bad (68% and 65%, respectably).**  \n  \n**I may remove these rows when modeling or fill the <font color=\"Magenta\">'prior_question_had_explanation'<\/font> columns with 'False' because users were novices and in <font color=\"Chocolate\">'the onboarding diagnostic test'<\/font>.**","3769a2ea":"# <center>1.1 row_id, timestamp<\/center>\n\n<a id=\"11\"><\/a>\n* Format  \n<font color=\"Magenta\">**Feature column name**:<\/font> (Data format) *Description by the host*  \n**My findings**\n  \n<font color=\"Magenta\">**row_id**:<\/font> (int64) *ID code for the row.*  \n**This database contains 101,230,332 rows (users' interactions).**  \n\n[Data Description](https:\/\/www.kaggle.com\/c\/riiid-test-answer-prediction\/data) says, \"<font color=\"Red\">*Expect to see roughly 2.5 million questions in the hidden test set.*<\/font>\" **<- I think *'the 2.5 million questions'* means interactions (rows).**\n\n<font color=\"Magenta\">**timestamp**:<\/font> (int64) *the time in milliseconds between this user interaction and the first event completion from that user.*  \n**Max value is 87,425,770,000. 1 year is 365 \\* 24 \\* 60 \\* 60 \\* 1000 = 31,536,000,000. The longest span of interactions is 2.77 years.**","6c2e60eb":"<a id=\"13\"><\/a>\n# <center>1.3 prior_question_had_explanation<\/center>\n  \n<font color=\"Magenta\">**prior_question_had_explanation**:<\/font> (bool) *Whether or not the user saw an explanation and the correct response(s) after answering the previous question bundle, ignoring any lectures in between. The value is shared across a single question bundle, and is null for a user's first question bundle or lecture. Typically the first several questions a user sees were part of <font color=\"Chocolate\">an onboarding diagnostic test<\/font> where they did not get any feedback.*  \n  \n**90.7% of the questions were answered after reading the explanation, and 67.3% of them were correct.  \nOn the other hand, 9.3% of the questions were answered without explanation, and only 50% of them were correct.**","812b739b":"**The graph below seems like a learning curve to me. Although <font color=\"Magenta\">'task_container_id'<\/font> contains some noise, I may use it as an indicator of <font color=\"Red\">users' experience<\/font>.**","1676a611":"# <center>2.1 part<\/center>\n\n<font color=\"Magenta\">**part**:<\/font> top level category code for the question.  \n  \n**In the first place, Riiid is for TOEIC . You can see what is [TOEIC here](https:\/\/www.iibc-global.org\/english.html). 'part' means [Question types](https:\/\/www.iibc-global.org\/english\/toeic\/test\/lr\/about\/format.html)**\n\n* Listening Section  \nPart1:  Photographs - 6 questions  \nPart2:  Question-Response - 25 questions  \nPart3:  Conversations - 39 questions  \nPart4:  Talks - 30 questions  \n\n* Reading Section  \nPart5:  Incomplete Sentences - 30 questions  \nPart6:  Text Completion - 16 questions  \nPart7:  Single Passages - 29 questions \/ Multiple Passages - 25 questions\n\n**Part1 is the easiest, 81.5% of the questions were answered correctly. Part5 is the hardest, their answer correctness was 66.6%.**","bee413cd":"<a id=\"17\"><\/a>\n# <center>1.7 user_id<\/center>\n\n<font color=\"Magenta\">**user_id**:<\/font> (int32) *ID code for the user.*  \n  \n**The database seems to be sorted by this column. When I split the data into four, all user_ids in the first set are smaller than any of those in the latter sets, and so forth.**\n  \n**393,656 users are in the train.csv.  \n68.2% of users had interacted less than 100 times. 87 of them had only interacted once.  \n346 users had interacted more than or equal to 10,000 times. The most active user (user_id == '801103753') had interacted 17,917 times.**\n\n**In [this Discussion](https:\/\/www.kaggle.com\/c\/riiid-test-answer-prediction\/discussion\/191106),** Kaggle staff said,\n\"<font color=\"Red\">*the hidden test set contains new users but not new questions.*<\/font>\"","63d59e83":"**questions.csv**: metadata for the questions posed to users.\n\n* question_id: foreign key for the train\/test content_id column, when the content type is question (0).\n\n* bundle_id: code for which questions are served together.\n\n* correct_answer: the answer to the question. Can be compared with the train user_answer column to check if the user was right.\n\n* part: the relevant section of the TOEIC test.\n\n* tags: one or more detailed tag codes for the question. The meaning of the tags will not be provided, but these codes are sufficient for clustering the questions together.","603ed9bd":"Using .jay format, we can read the full train.csv very fast. You can see the details in [Vopani's fantastic notebook](https:\/\/www.kaggle.com\/rohanrao\/riiid-with-blazing-fast-rid)","74f8b520":"<font color=\"Magenta\">**user_answer**:<\/font> (int8) *the user's answer to the question, if any. Read -1 as null, for lectures.*  \n**One correct answer among 4 options(0-3). *question.csv* shows that the correct answer rate of option 2 is lower than the other three.  Users answered option 2 less, properly.**","54c6461e":"<a id=\"18\"><\/a>\n# <center>1.8 content_id<\/center>\n\n<font color=\"Magenta\">**content_id**:<\/font> (int16) *ID code for the user interaction*  \n**The content_id corresponds to 13523 question_ids (0 to 13522) and 415 lecture_ids (89 to 32736), mixedly.  \nThe most popular 36 questions were answered more than 100,000 times for each. On the other hand, the least popular 243 questions were answered less than 100 times. 9 of them were answered only once. (dummy questions?)**\n\n\n  \n","889abd00":"**I also found other types of <font color=\"Magenta\">'task_container_ids'<\/font> jumps. Many (but not all) lecture rows show these jumps. And I have no idea why id went from 4556 to 2786 in row_id 21234106.**","3fbe9356":"<a id=\"top\"><\/a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:blue; border:0' role=\"tab\" aria-controls=\"home\"><center>Quick navigation<\/center><\/h3>\n\n* [1. train.csv](#1)\n    * [1.1 row_id, timestamp, user_id, user_answer](#11)\n    * [1.2 content_type_id, questions \/ lectures](#12)\n    * [1.3 prior_question_had_explanation](#13)\n    * [1.4 the incomplete 392,506 rows](#14)\n    * [1.5 prior_question_elapsed_time](#15)\n    * [1.6 task_container_id](#16)\n    * [1.7 user_id](#17)\n    * [1.8 content_id](#18)\n    \n* [2. question.csv](#2)\n* [3. work in progress](#3)","25bb0657":"<a id=\"16\"><\/a>\n# <center>1.6 task_container_id<\/center>\n  \n<font color=\"Magenta\">**task_container_id**:<\/font> (int16) *Id code for the batch of questions or lectures. For example, a user might see three questions in a row before seeing the explanations for any of them. Those three would all share a task_container_id.*  \n\n**Max value of 9999 seems artificial and I suspect that the system can only count up to 9999 for task_container_id. I checked the behavior after 9999 and found strange counting.**  \n(The first case, id returned from 9999 to 1396 and stopped. The second, it stopped just at 9999. The third, returned to 9506. The fourth, returned to 9989. The fifth, returned to 9953 and then 9122, 9841, 3296, and stopped. It seems a bug to me.)"}}