{"cell_type":{"43ca076a":"code","b63a6e81":"code","fa576b16":"code","ae7dd2fa":"code","a41b0d68":"code","eaa6680d":"markdown","9dc6af5b":"markdown","46b883ec":"markdown","01a89156":"markdown","f6f16eb5":"markdown"},"source":{"43ca076a":"import pandas as pd\nimport xgboost as xgb\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA","b63a6e81":"df = pd.read_csv(\"\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv\")\nX = df.drop(columns=[\"id\", \"Unnamed: 32\", \"diagnosis\"])\ny = df[\"diagnosis\"].map({'B': 0, 'M': 1})\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=8)","fa576b16":"model = xgb.XGBClassifier()\n\npipeline = Pipeline([\n    ('standard_scaler', StandardScaler()), \n    ('pca', PCA()), \n    ('model', model)\n])\n\nparam_grid = {\n    'pca__n_components': [5, 10, 15, 20, 25, 30],\n    'model__max_depth': [2, 3, 5, 7, 10],\n    'model__n_estimators': [10, 100, 500],\n}\n\ngrid = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, scoring='roc_auc')","ae7dd2fa":"%%time\n\ngrid.fit(X_train, y_train)","a41b0d68":"mean_score = grid.cv_results_[\"mean_test_score\"][grid.best_index_]\nstd_score = grid.cv_results_[\"std_test_score\"][grid.best_index_]\n\ngrid.best_params_, mean_score, std_score\n\nprint(f\"Best parameters: {grid.best_params_}\")\nprint(f\"Mean CV score: {mean_score: .6f}\")\nprint(f\"Standard deviation of CV score: {std_score: .6f}\")","eaa6680d":"## Dataset\n\nFor this example we'll use a simple dataset: [Breast Cancer Wisconsin (Diagnostic) Data Set](https:\/\/www.kaggle.com\/uciml\/breast-cancer-wisconsin-data).","9dc6af5b":"## CV results\n\nHere are the results of the model that gave the best mean score in the k-fold cross-validation","46b883ec":"# XGBoost with Scikit-Learn Pipeline & GridSearchCV\n\nXGBoost provides a wrapper interface to use the model as if it another model from Scikit-Learn [(more info in the documentation)](https:\/\/xgboost.readthedocs.io\/en\/latest\/python\/python_api.html#module-xgboost.sklearn). \n\nIn this notebook we show an example on how we can use XGBoost with Pipelines and GridSearchCV like any other Scikit-Learn model.","01a89156":"Feel free to ask anything or correct me if I made some mistake.\n\nHope this was helpful, have a nice day \ud83d\ude42","f6f16eb5":"## Define the Pipeline and GridSearch\n\nThe `XGBClassifier` class implements the Scikit-Learn interface for using XGBoost for classification. That means that it has the familiar `fit` method as well as `predict`, `score` and so on.\n\nThe preprocessing methods to use in the pipeline and the parameters to optimize are just for the sake of the example."}}