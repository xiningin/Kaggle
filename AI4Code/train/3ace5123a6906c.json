{"cell_type":{"75c292ed":"code","ccf05c62":"code","400babc4":"code","13112e81":"code","88dbd93e":"code","42deb183":"code","d30405ab":"code","94b22567":"code","8c611b4a":"code","a1bcb542":"code","15845b34":"markdown","d7c9ee4c":"markdown","572357f9":"markdown","dfa0ba3f":"markdown","9f604e74":"markdown"},"source":{"75c292ed":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","ccf05c62":"cols=['bedrooms','price']\ndf=pd.read_csv(\"..\/input\/kc_house_data.csv\",usecols=cols)\ndf.head()","400babc4":"x=df['bedrooms']\ny=df['price']","13112e81":"# standardizing the input values\ndef standardize(x):\n    return (x-np.mean(x))\/np.std(x)","88dbd93e":"X=standardize(x)\nX=np.c_[np.ones(x.shape[0]),X]","42deb183":"alpha=0.01\nm=y.size\nnp.random.seed(23)\ntheta=np.random.rand(2)\niterations=2000\n\ndef gradient_descent(x,y,theta,alpha,iterations):\n    previous_costs=[]\n    previous_thetas=[theta]\n    for i in range(iterations):\n        prediction=np.dot(x,theta) #line equation (theta*x)\n        error=prediction-y # error value\n        cost=1\/(2*m)*np.dot(error.T,error) #cost function\n        previous_costs.append(cost)\n        theta=theta-(alpha*(1\/m)*np.dot(x.T,error)) #updating theta values\n        previous_thetas.append(theta)\n    return previous_costs,previous_thetas\ncosts,thetas=gradient_descent(X,y,theta,alpha,iterations)","d30405ab":"plt.title('Cost Function')\nplt.xlabel('# of iterations')\nplt.ylabel('Cost')\nplt.plot(costs)\nplt.show()","94b22567":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split","8c611b4a":"x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=23)\nlm=LinearRegression().fit(x_train,y_train)\npredictions=lm.predict(x_test)","a1bcb542":"print(\"Linear Regression model Intercept:\",lm.intercept_)\nprint(\"Linear Regression model Theta1\",lm.coef_[1])","15845b34":"__As we can see the results of our gradient descent function are Intercept: 540088.14075994,Theta1: 113200.90438675__\n__are much closer to the results of sklearn Linear regression model i.e. Intercept: 540059.9446691773,Theta1: 540059.9446691773__","d7c9ee4c":"### Thankyou for your interest,please update the notebook if u find any improvements required.","572357f9":"## Linear Regression model with gradient descent in python from scratch","dfa0ba3f":"__Here in this notebook just to understand the working of gradient descent in python from scratch we took a simple house price prediction dataset and only took one input feature(# of bedrooms) for simplicity, and defined a gradient descent function for intercept and coefficients and compared the results with sklearn Linear regression model__","9f604e74":"__Comparing our results with sklearn Linear regression model__"}}