{"cell_type":{"5d79d8d8":"code","33529f2a":"code","b116b153":"code","0d5d8109":"code","230d780e":"code","54c22d0c":"code","d148c197":"code","807cc971":"code","67226b48":"code","f33b0ad9":"code","a698d84a":"code","35de1ffa":"code","a30ab371":"code","21dcfdbe":"code","796d4398":"code","7319ab93":"code","bc301349":"code","4adb458b":"code","9bff91e1":"code","2a57a7fb":"code","426855ba":"code","ef14d969":"code","80ba9802":"code","67741180":"code","1b3d5310":"code","42901cdc":"code","cbdbf02d":"code","1fd0ea74":"code","c402debc":"code","3aef4578":"code","a3a36a78":"code","c9597ecd":"code","30d02d82":"code","728d5fb3":"code","ca006417":"code","06ae5a40":"code","6b027586":"code","9552e195":"code","63fa0f8a":"code","f618064e":"code","2a014019":"code","02d9a4fb":"code","5027bbd9":"code","e12acdce":"code","3ca52fea":"code","b0f189ca":"code","83cf8ae9":"code","941a7340":"code","c1169376":"code","41750637":"markdown","9b8c8fa2":"markdown"},"source":{"5d79d8d8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","33529f2a":"os.chdir(\"..\/input\")\nos.listdir()","b116b153":"from warnings import filterwarnings\nfilterwarnings('ignore')","0d5d8109":"df=pd.read_csv(\"..\/input\/mice-protein\/miceprotein.csv\")","230d780e":"df.head()","54c22d0c":"# replace to '?' to np.nan\n# so real missing values can be count\nmymap = {\"?\":np.NaN}\n\ndf=df.applymap(lambda s: mymap.get(s) if s in mymap else s)","d148c197":"df.isnull().sum().sort_values(ascending=False) # missing datas can be observed","807cc971":"df.info()","67226b48":"df=df.drop(['MouseID'],axis=1)","f33b0ad9":"df[\"Genotype\"] = df[\"Genotype\"].str.strip(\"'\")\ndf[\"Genotype\"].value_counts() #Observations that are all values should be dropped","a698d84a":"df[\"Treatment\"] = df[\"Treatment\"].str.strip(\"'\")\ndf[\"Treatment\"].value_counts() # Observations that are all values should be dropped","35de1ffa":"df[\"Behavior\"] = df[\"Behavior\"].str.strip(\"'\")\ndf[\"Behavior\"].value_counts() # Observations that are all values should be dropped","a30ab371":"df[\"class\"] = df[\"class\"].str.strip(\"'\")\ndf[\"class\"].value_counts() # Observations that are all values should be dropped","21dcfdbe":"df[['Genotype']] = df[['Genotype']].replace(to_replace={'Control':1,'Ts65Dn':0})","796d4398":"df[['Treatment']] = df[['Treatment']].replace(to_replace={'Memantine':1,'Saline':0})","7319ab93":"df[['Behavior']] = df[['Behavior']].replace(to_replace={'S\/C':1,'C\/S':0})","bc301349":"y=df['class']","4adb458b":"df = df.drop([\"class\"], axis=1)","9bff91e1":"df.shape","2a57a7fb":"print(df[\"Genotype\"].value_counts())\nprint(df[\"Treatment\"].value_counts())\nprint(df[\"Behavior\"].value_counts())","426855ba":"df=df.apply(lambda x: x.astype(float))","ef14d969":"!pip install ycimpute==0.1.1","80ba9802":"from ycimpute.imputer import knnimput","67741180":"var_names = list(df) # variable names are stored dataset will be converted to matrix so\n# We kept it in a list so that it doesn't get lost ..","1b3d5310":"n_df = np.array(df) # Converted dataframe to Numpy array\n# Some libraries accept numpy array some DataFrame some all kinds","42901cdc":"n_df.shape","cbdbf02d":"dff = knnimput.KNN(k=20).complete(n_df)\n# Filling in NaN expressions according to estimation of missing values in Array format","1fd0ea74":"dff = pd.DataFrame(dff, columns = var_names) # Converting Array to Pandas DataFrame","c402debc":"dff.head()","3aef4578":"dff.isnull().sum().sort_values(ascending=False) # There is no missing data left.","a3a36a78":"df=dff","c9597ecd":"df.head()","30d02d82":"from keras.utils import np_utils\nfrom sklearn.preprocessing import LabelEncoder\n\n\n# label encoder y\nencoder = LabelEncoder()\nencoder.fit(y)\ny = encoder.transform(y)\ny = np_utils.to_categorical(y)","728d5fb3":"print(y)\n\ny.shape","ca006417":"X = df\nX = np.array(X)","06ae5a40":"from sklearn.model_selection import GridSearchCV\n\n\n\n# Train-Test \nfrom sklearn.model_selection import train_test_split\n# shuffle and split training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n                                                    random_state=0)\n\n# Multi Layer Perceptron Artificial Neural Network\nfrom sklearn.neural_network import MLPClassifier \n\n# Setting up a primitive (non-validated) model\nmlpc = MLPClassifier(random_state = 0)# ANN model object created\n\nmlpc.fit(X_train, y_train) # ANN model object fit","6b027586":"# Untunned Scores of the Model\n\ny_pred=mlpc.predict(X_test)","9552e195":"import sklearn.metrics as metrics\n\n# Accuracy\n\nprint(\"Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n\n# f1 score\n\nprint(\"f1_weighted:\",metrics.f1_score(y_test, y_pred,average='weighted'))","63fa0f8a":"# Cross Validation Process\n# Parameters for CV created in dictionary structure\n# INFORMATION ABOUT THE INPUTED PARAMETERS\n# alpha: float, default = 0.0001 L2 penalty (regularization term) parameter. (penalty parameter)\n   \nmlpc_params = {\"alpha\": [0.1, 0.01, 0.0001],\n              \"hidden_layer_sizes\": [(10,10,10),\n                                     (100,100,100),\n                                     (100,100),],\n              \"solver\" : [\"lbfgs\",\"adam\",\"sgd\"],\n              \"activation\": [\"relu\",\"logistic\"]}\n\nfrom sklearn.model_selection import GridSearchCV\n\n\n\n\nmlpc = MLPClassifier(random_state = 0) # ANN model object created\n\n# Model CV process \nmlpc_cv_model = GridSearchCV(mlpc, mlpc_params, \n                         cv = 5, # To make a 5-fold CV\n                         n_jobs = -1, # Number of jobs to be run in parallel (-1: means to use all processors)\n                         verbose = 2) # Controls the level of detail: higher means more messages gets value as integer.\n\nmlpc_cv_model.fit(X_train, y_train) \n\n\n# The best parameter obtained as a result of CV process\n\nprint(\"The best parameters: \" + str(mlpc_cv_model.best_params_))","f618064e":"# Setting the Final Model with the best parameter\n\nmlpc_tuned = mlpc_cv_model.best_estimator_\n\n# Fitting Final Model\nmlpc_tuned.fit(X_train, y_train)","2a014019":"# K-fold f1_weighted\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n# K fold\nkf = KFold(shuffle=True, n_splits=5) # To make a 5-fold CV\n\ncv_results_kfold = cross_val_score(mlpc_tuned, X_test, np.argmax(y_test, axis=1), cv=kf, scoring= 'f1_weighted')\n\nprint(\"K-fold Cross Validation f1_weigted Results: \",cv_results_kfold)\nprint(\"K-fold Cross Validation f1_weigted Results Mean: \",cv_results_kfold.mean())","02d9a4fb":"# K-fold accuracy\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n# K fold\nkf = KFold(shuffle=True, n_splits=5) # To make a 5-fold CV\n\ncv_results_kfold = cross_val_score(mlpc_tuned, X_test, np.argmax(y_test, axis=1), cv=kf, scoring= 'accuracy')\n\nprint(\"K-fold Cross Validation accuracy Results: \",cv_results_kfold)\nprint(\"K-fold Cross Validation accuracy Results Mean: \",cv_results_kfold.mean())","5027bbd9":"# Tune Model Prediction\n# Prediction process of Final Model over test set\ny_pred = mlpc_tuned.predict(X_test)","e12acdce":"# %% f1 score\nimport sklearn.metrics as metrics\nprint(\"f1_weighted:\",metrics.f1_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1),average='weighted'))\n\n# %% Accuracy\n\nprint(\"accuracy:\",metrics.accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))","3ca52fea":"#%% Confusion Matrix and Classification Report\nfrom sklearn.metrics import confusion_matrix, classification_report \n\n# Classification Report\nmodel_report = classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\nprint(model_report)","b0f189ca":"# Confusion Matrix\n# multilabel-indicator is not supported so np.argmax should be used!\nmodel_conf = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\nprint(model_conf)","83cf8ae9":"#%% ROC-AUC Curve\n\ny_score = mlpc_tuned.predict_proba(X_test)\n\nfrom scipy import interp\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\n# Learn to predict each class against the other\n\n\nn_classes = 8 # number of class\n\n\n\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])","941a7340":"# The process of drawing a roc-auc curve belonging to a specific class\n\nplt.figure()\nlw = 2 # line_width\nplt.plot(fpr[3], tpr[3], color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[3]) # Drawing Curve according to 2. class \nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC E\u011frisi')\nplt.legend(loc=\"lower right\")\nplt.show()","c1169376":"# Process of plotting roc-auc curve belonging to all classes.\n\nfrom itertools import cycle\n\n# First aggregate all false positive rates\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n# Then interpolate all ROC curves at this points\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n# Finally average it and compute AUC\nmean_tpr \/= n_classes\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n# Plot all ROC curves\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Extending the ROC Curve to Multi-Class')\nplt.legend(loc=\"lower right\")\nplt.show()","41750637":"## Data Read","9b8c8fa2":"## Modelling\n\n\n\n## Artificial Neural Network with MLP"}}