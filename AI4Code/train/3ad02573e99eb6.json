{"cell_type":{"b2a8a7f9":"code","25070815":"code","604226e6":"code","696ca806":"code","c3ea1c8c":"code","e02ed3df":"code","b3b22d6a":"code","8bf7eca7":"code","24a76381":"code","b1901610":"code","bbb9d730":"code","6de1d66b":"code","5e293605":"code","0d803aa7":"code","7d0584ee":"code","99dbb408":"code","fb3099c4":"code","02c5990a":"code","b8dd484c":"code","e0ef71f8":"markdown","e8bd1d95":"markdown"},"source":{"b2a8a7f9":"from sklearn import preprocessing\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.metrics import mean_squared_error\nfrom datetime import datetime\nfrom sklearn.model_selection import train_test_split\nfrom math import sqrt\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.datasets import load_boston\nfrom sklearn.datasets import make_regression\nfrom sklearn.preprocessing import scale\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import FeatureUnion\n\ntry:\n    from sklearn.compose import ColumnTransformer\nexcept ImportError:\n    from future_encoders import ColumnTransformer # Scikit-Learn < 0.20\ntry:\n    from sklearn.impute import SimpleImputer # Scikit-Learn 0.20+\nexcept ImportError:\n    from sklearn.preprocessing import Imputer as SimpleImputer\n    \n%matplotlib inline  ","25070815":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","604226e6":"data= pd.read_csv(\"..\/input\/ashrae-energy-prediction\/test.csv\")\ntrain =pd.read_csv('..\/input\/ashrae-energy-prediction\/train.csv')\ntest = data[0:100000]\nweather_train = pd.read_csv('..\/input\/ashrae-energy-prediction\/weather_train.csv')\nweather_test = pd.read_csv('..\/input\/ashrae-energy-prediction\/weather_test.csv')\nbuilding_meta = pd.read_csv('..\/input\/ashrae-energy-prediction\/building_metadata.csv')\nsubmission = pd.read_csv('..\/input\/ashrae-energy-prediction\/sample_submission.csv')\ndel(data)","696ca806":"# The following function is inspired by https:\/\/www.kaggle.com\/aitude\/ashrae-missing-weather-data-handling\ndef add_missing_hours(weather_df):\n    import datetime\n    time_format = \"%Y-%m-%d %H:%M:%S\"\n    start_date = datetime.datetime.strptime(weather_df['timestamp'].min(),time_format)\n    end_date = datetime.datetime.strptime(weather_df['timestamp'].max(),time_format)\n    total_hours = int(((end_date - start_date).total_seconds() + 3600) \/ 3600)\n    hours_list = [(end_date - datetime.timedelta(hours=x)).strftime(time_format) for x in range(total_hours)]\n\n    for site_id in range(16):\n        site_hours = np.array(weather_df[weather_df['site_id'] == site_id]['timestamp'])\n        new_rows = pd.DataFrame(np.setdiff1d(hours_list,site_hours),columns=['timestamp'])\n        new_rows['site_id'] = site_id\n        weather_df = pd.concat([weather_df,new_rows]).reset_index(drop=True)\n    return weather_df\n\nweather_train = add_missing_hours(weather_train)\n# Varify the number of entries\nweather_train.shape","c3ea1c8c":"def convert_to_datetime(df_list):\n    for df in df_list:\n        df['timestamp'] = pd.to_datetime(df['timestamp'])\n    return df_list\ntrain, weather_train = convert_to_datetime([train, weather_train])\ntrain.info()","e02ed3df":"weather_cols = ['air_temperature','cloud_coverage', 'dew_temperature', 'precip_depth_1_hr', \n                'sea_level_pressure', 'wind_direction', 'wind_speed']\ndef fill_weather_nan(df):\n    df['month'] = df.timestamp.dt.month\n    gp = df.groupby(['site_id', 'month'])\n    for col in weather_cols:\n        df[col] = gp[col].transform(lambda x: x.fillna(x.mean()))\n        df[col].fillna(np.nanmean(df[col]), inplace=True)\n    del df['month']\n    return df\nweather_train = fill_weather_nan(weather_train)","b3b22d6a":"weather_train.info()","8bf7eca7":"train_final = building_meta.merge(train, on='building_id').merge(weather_train, on=['site_id', 'timestamp'])\nprint(train_final.shape)\ntest_final = building_meta.merge(test, on='building_id').merge(weather_test, on=['site_id', 'timestamp'])\nprint(test_final.shape)\nprint(train_final.isnull().sum())","24a76381":"minPoint=740\nmaxPoint=1099\n","b1901610":"train_final = train_final[(train_final['building_id']!=minPoint)&(train_final['building_id']!=maxPoint)]\ntrain_final['meter_reading'] = np.log1p(train_final['meter_reading'])\ntrain_final.info()","bbb9d730":"print(train_final.shape)\nprint(test_final.shape)\nprint(train_final['primary_use'])","6de1d66b":"#Fill in missing year_built with the mean of other buildings in the same site; \n#if none of the buildings in a site has year_built, then fill with the mean of the entire dataset\nyear_built_gp = building_meta.groupby('site_id')['year_built']\nbuilding_meta['year_built'] = year_built_gp.transform(lambda x: x.fillna(x.mean()))\nbuilding_meta['year_built'].fillna(np.nanmean(building_meta['year_built']), inplace=True)\nassert pd.isnull(building_meta['year_built']).sum() == 0\n\n#Fill in missing floor_count with the mean of other buildings of the same primary_use; \n#if none of the buildings of a primary use has year_built, then fill with the mean of the entire dataset\nfloor_count_gp = building_meta.groupby('primary_use')['floor_count']\nbuilding_meta['floor_count'] = floor_count_gp.transform(lambda x: x.fillna(x.mean()))\nbuilding_meta['floor_count'].fillna(np.nanmean(building_meta['floor_count']), inplace=True)\nassert pd.isnull(building_meta['floor_count']).sum() == 0\n\n","5e293605":"meter_reading = train_final['meter_reading']\nfeatures = train_final.drop(['meter_reading','year_built','floor_count','cloud_coverage'], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(features, meter_reading, test_size = 0.25)\n","0d803aa7":"from sklearn.base import BaseEstimator, TransformerMixin\n# Create a class to select numerical or categorical columns \nclass OldDataFrameSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attribute_names):\n        self.attribute_names = attribute_names\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        return X[self.attribute_names].values","7d0584ee":"numbers  = X_train.select_dtypes(include=[np.number])\nnum_attribs = list(numbers)\ncat_attribs =['primary_use']","99dbb408":"num_pipeline = Pipeline([\n        ('selector', OldDataFrameSelector(num_attribs)),\n        ('imputer', SimpleImputer(strategy=\"median\")),\n        ('std_scaler', StandardScaler()),\n    ])\ncat_pipeline = Pipeline([\n    ('selector', OldDataFrameSelector(cat_attribs)),\n    ('cat_encoder', OneHotEncoder(sparse=False)),\n    ])\nfull_pipeline = FeatureUnion(transformer_list=[\n    (\"num_pipeline\", num_pipeline),\n    (\"cat_pipeline\", cat_pipeline),\n     ])\nX_train = full_pipeline.fit_transform(X_train)\nX_test = full_pipeline.fit_transform(X_test)\nprint(X_train)\nprint(\"..........\")\nprint(X_test)\n","fb3099c4":"sgdr = SGDRegressor(penalty='l2',  alpha=1, max_iter=1000, early_stopping=False, learning_rate='invscaling', eta0=0.01)\nsgdr.fit(X_train, y_train.values)\ny_pred_lr = sgdr.predict(X_test)\nprint(np.sqrt(mean_squared_log_error( y_test, y_pred_lr )))\nprint(np.expm1(y_pred_lr))","02c5990a":"lin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train.values)\ny_pred_lr = lin_reg.predict(X_test)\nprint(np.sqrt(mean_squared_log_error( y_test, y_pred_lr )))\nprint(np.expm1(y_pred_lr))","b8dd484c":"from sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(n_estimators=5, random_state=7)\nmodel.fit(X_train, y_train.values)\ny_pred_lr = model.predict(X_test)\nprint(np.sqrt(mean_squared_log_error( y_test, y_pred_lr )))\nprint(np.expm1(y_pred_lr))","e0ef71f8":"# Data Preprocessing","e8bd1d95":"# Data Imports"}}