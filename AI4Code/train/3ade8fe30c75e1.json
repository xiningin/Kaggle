{"cell_type":{"189cbe84":"code","496fd046":"code","a3c8ddea":"code","a18e95fa":"code","db61c689":"code","65b1990b":"code","b415ed22":"code","6869ede0":"code","528685a5":"code","fc349d44":"code","926b2947":"code","04a8bf2f":"code","7f81efb4":"code","1bd6c703":"code","f162d275":"code","5460b90c":"code","ed8ea1c0":"code","52120403":"code","06787cf1":"code","08f37f66":"code","5090c1ea":"code","440c8a6b":"code","b5203bff":"code","96ed4673":"code","9fe9baf2":"code","46ff790f":"code","559fc092":"code","86380d11":"code","37b2704f":"code","057a487d":"code","036c3c5b":"code","6cfe4732":"code","772d0c09":"markdown","cb53351a":"markdown","26616b64":"markdown","d953b3d9":"markdown"},"source":{"189cbe84":"import numpy as np\nfrom matplotlib import pyplot as plt\nimport pandas as pd\nimport os","496fd046":"import cv2\nfrom skimage import feature\nfrom skimage import measure","a3c8ddea":"os.listdir('\/kaggle\/input\/thai-mnist-classification')","a18e95fa":"train_img_path = '\/kaggle\/input\/thai-mnist-classification\/train'\ntrain_label_path = '\/kaggle\/input\/thai-mnist-classification\/mnist.train.map.csv'","db61c689":"pd.read_csv(train_label_path).set_index('id').to_dict()['category']","65b1990b":"os.listdir(train_img_path)","b415ed22":"pd.read_csv(train_label_path)","6869ede0":"class getdata():\n    def __init__(self,data_path,label_path=None):\n        self.dataPath = data_path\n        self.dataFile = os.listdir(self.dataPath)\n        self.n_index = len(self.dataFile)\n        if label_path is not None:\n            self.labelPath = label_path\n            self.label_dict = pd.read_csv(train_label_path).set_index('id').to_dict()['category']\n            self.label = [self.label_dict[x] for x in self.dataFile]\n        \n        \n    \n    def get1img(self,img_index,mode='rgb',label = False):\n        img = cv2.imread( os.path.join(self.dataPath,self.dataFile[img_index]) )\n        if mode == 'rgb':\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        elif mode == 'gray':\n            img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n        if label:\n            return img,self.label[img_index]\n        return img","528685a5":"gdt = getdata(train_img_path,train_label_path)","fc349d44":"plt.gray()","926b2947":"from skimage.morphology import convex_hull_image\nfrom skimage.util import invert","04a8bf2f":"temp_img = invert(gdt.get1img(1234,'gray'))\nfig, [ax1,ax2] = plt.subplots(1, 2)\nax1.imshow(temp_img)\ncvh =  convex_hull_image(temp_img)\nax2.imshow(cvh)","7f81efb4":"def convex_crop(img,pad=20):\n    convex = convex_hull_image(img)\n    r,c = np.where(convex)\n    while (min(r)-pad < 0) or (max(r)+pad > img.shape[0]) or (min(c)-pad < 0) or (max(c)+pad > img.shape[1]):\n        pad = pad - 1\n    return img[min(r)-pad:max(r)+pad,min(c)-pad:max(c)+pad]","1bd6c703":"crop_img = convex_crop(temp_img,pad=10)\nplt.imshow(crop_img)","f162d275":"def convex_resize(img):\n    img = invert(img)\n    img = convex_crop(img,pad=20)\n    img = cv2.resize(img,(32,32))\n    return img","5460b90c":"def thes_resize(img,thes=40):\n    img = invert(img)\n    img = convex_crop(img,pad=20)\n    img = ((img > thes)*255).astype(np.uint8)\n    if(min(img.shape) > 300):\n        img = cv2.resize(img,(300,300))\n        img = ((img > thes)*255).astype(np.uint8)\n    if(min(img.shape) > 150):\n        img = cv2.resize(img,(150,150))\n        img = ((img > thes)*255).astype(np.uint8)\n    img = cv2.resize(img,(80,80))\n    img = ((img > thes)*255).astype(np.uint8)\n    img = cv2.resize(img,(50,50))\n    img = ((img > thes)*255).astype(np.uint8)\n    img = cv2.resize(img,(32,32))\n    img = ((img > thes)*255).astype(np.uint8)\n    return img","ed8ea1c0":"temp_img = gdt.get1img(128,'gray')\nfig, [ax1,ax2] = plt.subplots(1, 2,figsize=(10,7))\nax1.imshow(convex_resize(temp_img))\nax1.set_title('Without thresholding')\nax2.imshow(thes_resize(temp_img))\nax2.set_title('Thresholding')","52120403":"fig, ax = plt.subplots(5, 5, figsize=(15,15))\nfor i in range(5):\n    for j in range(5):\n        img_index = np.random.randint(0,gdt.n_index)\n        ax[i][j].imshow(thes_resize(gdt.get1img(img_index,'gray')))\n        ax[i][j].set_title('Class: '+str(gdt.label[img_index]))\n        ax[i][j].set_axis_off()","06787cf1":"from tqdm import tqdm","08f37f66":"X = []\nfor i in tqdm(range(gdt.n_index)):\n    X.append(thes_resize(gdt.get1img(i,'gray')))\nX = np.array(X)","5090c1ea":"y =np.array(gdt.label)\nX = X.reshape((-1,32,32,1))\nX.shape,y.shape","440c8a6b":"import tensorflow as tf","b5203bff":"y_cat = tf.keras.utils.to_categorical(y)\ny_cat.shape","96ed4673":"from sklearn.model_selection import train_test_split","9fe9baf2":"X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.25, random_state=1234)","46ff790f":"X_train = X_train \/ 255.\nX_test = X_test \/ 255.","559fc092":"model = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Conv2D(6, (3,3), input_shape=(32, 32, 1), activation='relu'))\nmodel.add(tf.keras.layers.MaxPool2D()) \nmodel.add(tf.keras.layers.Conv2D(16, (5,5), activation='relu')) \nmodel.add(tf.keras.layers.MaxPool2D()) \nmodel.add(tf.keras.layers.Flatten()) \nmodel.add(tf.keras.layers.Dropout(0.5)) #Add dropout for prevent overfit\nmodel.add(tf.keras.layers.Dense(120, activation='relu'))\nmodel.add(tf.keras.layers.Dense(84, activation='relu'))\nmodel.add(tf.keras.layers.Dense(10, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['acc'])","86380d11":"model.summary()","37b2704f":"learning_rate_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', \n                                            patience=5, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.0000001)\n\nearly_stop = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=15,verbose=1)","057a487d":"history = model.fit(X_train, y_train, batch_size=64,validation_data=(X_test,y_test), \n                    epochs=100, callbacks=[learning_rate_reduction])","036c3c5b":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])","6cfe4732":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])","772d0c09":"## Apply to all images","cb53351a":"## Crop image","26616b64":"# Lenet5","d953b3d9":"# Image convex hull"}}