{"cell_type":{"6b6781ec":"code","cc3735d1":"code","151e880b":"code","c9456125":"code","506c4d61":"code","a7199a0f":"code","f097edf4":"code","3b2412da":"code","3a344dec":"code","6c267896":"code","6408278e":"code","bfef2feb":"code","22f7df19":"code","ad8ec20c":"code","68aad6a1":"code","349f1e0b":"code","e7f2e548":"code","7a3e75d4":"code","52efa398":"code","f91c0db2":"code","56befdea":"code","4f24f1ab":"code","ce4ea81d":"markdown","91ca4d8e":"markdown","df4b11c3":"markdown","a7d31753":"markdown","674a224f":"markdown","05dd6f7a":"markdown","05bdd62f":"markdown","bfb1d0d4":"markdown"},"source":{"6b6781ec":"import re\nimport string\nimport nltk\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, SpatialDropout1D\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping","cc3735d1":"train_df = pd.read_csv('..\/input\/genre-classification-dataset-imdb\/Genre Classification Dataset\/train_data.txt', sep=\":::\", header=None, engine='python')\ntest_df = pd.read_csv('..\/input\/genre-classification-dataset-imdb\/Genre Classification Dataset\/test_data_solution.txt', sep=\":::\", header=None, engine='python')\ntrain_df.columns=['id','title','genre','description']\ntest_df.columns=['id','title','genre','description']\ntrain_df.head()","151e880b":"train_df.info()","c9456125":"train_df.isnull().sum()","506c4d61":"plt.figure(figsize=(12,8))\ncounts = train_df.genre.value_counts()\nsns.barplot(x=counts.index, y=counts)\nplt.xlabel('Genre')\nplt.ylabel('Count')\nplt.xticks(rotation=90);","a7199a0f":"plt.figure(figsize=(13,8))\n\nsns.set(style=\"darkgrid\")\nsns.set_color_codes(\"pastel\")\ntrain_df.genre.value_counts().plot.barh()\nsns.despine(left=True, bottom=True)\n\nplt.tight_layout()\nplt.show()","f097edf4":"train_df.head()","3b2412da":"sns.countplot(y='genre',data=train_df)","3a344dec":"train_df['length']=train_df['description'].apply(len)\ntrain_df.head()","6c267896":"train_df['length'].plot(bins=100, kind='hist')","6408278e":"train_df.describe()","bfef2feb":"train_df[train_df['length']==42]['description']","22f7df19":"def clean_text(text):\n    text = text.lower()                                  # lower-case all characters\n    text =  re.sub(r'@\\S+', '',text)                     # remove twitter handles\n    text =  re.sub(r'http\\S+', '',text)                  # remove urls\n    text =  re.sub(r'pic.\\S+', '',text) \n    text =  re.sub(r\"[^a-zA-Z+']\", ' ',text)             # only keeps characters\n    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text+' ')      # keep words with length>1 only\n    text = \"\".join([i for i in text if i not in string.punctuation])\n    words = nltk.tokenize.word_tokenize(text)\n    stopwords = nltk.corpus.stopwords.words('english')   # remove stopwords\n    text = \" \".join([i for i in words if i not in stopwords and len(i)>2])\n    text= re.sub(\"\\s[\\s]+\", \" \",text).strip()            # remove repeated\/leading\/trailing spaces\n    return text","ad8ec20c":"train_df['Text_cleaning'] = train_df.description.apply(clean_text)\ntest_df['Text_cleaning'] = test_df.description.apply(clean_text)\ntest_df.head()","68aad6a1":"train_df['length_Text_cleaning']=train_df['Text_cleaning'].apply(len)\ntrain_df.head()","349f1e0b":"num_words = 50000\nmax_len = 250\ntokenizer = Tokenizer(num_words=num_words, filters='!\"#$%&()*+,-.\/:;<=>?@[\\]^_`{|}~', lower=True)\ntokenizer.fit_on_texts(train_df['Text_cleaning'].values)","e7f2e548":"X = tokenizer.texts_to_sequences(train_df['Text_cleaning'].values)\nX = pad_sequences(X, maxlen=max_len)\ny = pd.get_dummies(train_df['genre']).values\n\nX_test = tokenizer.texts_to_sequences(test_df['Text_cleaning'].values)\nX_test = pad_sequences(X_test, maxlen=max_len)\ny_test = pd.get_dummies(test_df['genre']).values","7a3e75d4":"EMBEDDING_DIM = 100\nmodel = Sequential()\nmodel.add(Embedding(num_words, EMBEDDING_DIM, input_length=X.shape[1]))\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(LSTM(100, dropout=0.1, recurrent_dropout=0.2))\nmodel.add(Dense(27, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","52efa398":"my_callbacks  = [EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=2,\n                              mode='auto')]","f91c0db2":"history = model.fit(X, y, epochs=6, batch_size=32,validation_data=(X_test,y_test), callbacks=my_callbacks)","56befdea":"# Plotting Accuracy and val_accuracy\nplt.title('Accuracy')\nplt.plot(history.history['accuracy'], label='train')\nplt.plot(history.history['val_accuracy'], label='test')\nplt.legend()\nplt.show();\n\n# Plotting loss and val_loss\nplt.title('Loss')\nplt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='test')\nplt.legend()\nplt.show();","4f24f1ab":"results = model.evaluate(X_test, y_test, verbose=0)\nprint(\"    Test Loss: {:.5f}\".format(results[0]))\nprint(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))","ce4ea81d":"# \ud83e\uddea Test Accuracy","91ca4d8e":"# \ud83d\udcc8 Plotting Accuracy & Loss\n","df4b11c3":"# \ud83d\udd25 EDA & Visualization","a7d31753":"# \ud83e\uddf9 Text Cleaning","674a224f":"# \ud83d\udcda Training model","05dd6f7a":"# \ud83d\uddc3\ufe0f Load Dataset\n","05bdd62f":"# \ud83d\udce5 Importing Libraries\u00b6","bfb1d0d4":"# \u2714\ufe0f Tokenizer"}}