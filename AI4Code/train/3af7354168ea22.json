{"cell_type":{"503280a9":"code","1459e2d0":"code","4114420f":"code","72e7fc9b":"code","34cf6e2f":"code","d97f5ff7":"code","e6c6a5d1":"code","7bd7b1f7":"code","577fca38":"code","d491c7e3":"code","90ec5eb8":"code","df8ba06c":"code","6e6d1f5f":"code","24b83a30":"code","22f1375c":"code","1219e664":"code","f6c5ee3f":"code","f5b0296e":"code","86b8978c":"code","30733227":"code","04e56832":"code","94c33dd9":"code","0f9cdb85":"code","c623f556":"code","cbcf31bc":"code","10a22b8f":"code","2f812a21":"code","1184d606":"code","67acd31f":"markdown","9ce24c03":"markdown","b9e35314":"markdown","2c8212d7":"markdown","9e56dd76":"markdown","b9526a93":"markdown","91588563":"markdown","0967312c":"markdown","d9501b79":"markdown","b59e5b7d":"markdown","68fe87e8":"markdown","d670aafa":"markdown"},"source":{"503280a9":"#importing libraries\nimport numpy as np\nfrom numpy import sort\nimport pandas as pd\nimport gc\nfrom datetime import datetime\nimport time\nimport warnings\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\n\nimport seaborn as sns\nsns.set(style=\"ticks\")\n#sns.set_context(\"poster\", font_scale = .2, rc={\"grid.linewidth\": 2})\nimport sklearn\nimport scipy\n\nimport random\nnp.random.seed(42)\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\npd.set_option('display.max_columns', 100)\n%matplotlib inline","1459e2d0":"#defining visualizaition functions\ndef format_spines(ax, right_border=True):\n    \n    ax.spines['bottom'].set_color('#666666')\n    ax.spines['left'].set_color('#666666')\n    ax.spines['top'].set_visible(False)\n    if right_border:\n        ax.spines['right'].set_color('#FFFFFF')\n    else:\n        ax.spines['right'].set_color('#FFFFFF')\n    ax.patch.set_facecolor('#FFFFFF')\n    \n\ndef count_plot(feature, df, colors='Blues_d', hue=False, ax=None, title=''):\n    \n    # Preparing variables\n    ncount = len(df)\n    if hue != False:\n        ax = sns.countplot(x=feature, data=df, palette=colors, hue=hue, ax=ax)\n    else:\n        ax = sns.countplot(x=feature, data=df, palette=colors, ax=ax)\n        \n    format_spines(ax)\n\n    # Setting percentage\n    for p in ax.patches:\n        x=p.get_bbox().get_points()[:,0]\n        y=p.get_bbox().get_points()[1,1]\n        ax.annotate('{:.1f}%'.format(100.*y\/ncount), (x.mean(), y), \n                ha='center', va='bottom') # set the alignment of the text\n    \n    # Final configuration\n    if not hue:\n        ax.set_title(df[feature].describe().name + ' Analysis', size=13, pad=15)\n    else:\n        ax.set_title(df[feature].describe().name + ' Analysis by ' + hue, size=13, pad=15)  \n    if title != '':\n        ax.set_title(title)       \n    plt.tight_layout()\n    \n    \ndef bar_plot(x, y, df, colors='Blues_d', hue=False, ax=None, value=False, title=''):\n    \n    # Preparing variables\n    try:\n        ncount = sum(df[y])\n    except:\n        ncount = sum(df[x])\n    #fig, ax = plt.subplots()\n    if hue != False:\n        ax = sns.barplot(x=x, y=y, data=df, palette=colors, hue=hue, ax=ax, ci=None)\n    else:\n        ax = sns.barplot(x=x, y=y, data=df, palette=colors, ax=ax, ci=None)\n\n    # Setting borders\n    format_spines(ax)\n\n    # Setting percentage\n    for p in ax.patches:\n        xp=p.get_bbox().get_points()[:,0]\n        yp=p.get_bbox().get_points()[1,1]\n        if value:\n            ax.annotate('{:.2f}k'.format(yp\/1000), (xp.mean(), yp), \n                    ha='center', va='bottom') # set the alignment of the text\n        else:\n            ax.annotate('{:.1f}%'.format(100.*yp\/ncount), (xp.mean(), yp), \n                    ha='center', va='bottom') # set the alignment of the text\n    if not hue:\n        ax.set_title(df[x].describe().name + ' Analysis', size=12, pad=15)\n    else:\n        ax.set_title(df[x].describe().name + ' Analysis by ' + hue, size=12, pad=15)\n    if title != '':\n        ax.set_title(title)  \n    plt.tight_layout()\n\ndef categorical_plot(cols_cat, axs, df):\n    \n    idx_row = 0\n    for col in cols_cat:\n        # Returning column index\n        idx_col = cols_cat.index(col)\n\n        # Verifying brake line in figure (second row)\n        if idx_col >= 3:\n            idx_col -= 3\n            idx_row = 1\n\n        # Plot params\n        names = df[col].value_counts().index\n        heights = df[col].value_counts().values\n\n        # Bar chart\n        axs[idx_row, idx_col].bar(names, heights, color='navy')\n        if (idx_row, idx_col) == (0, 2):\n            y_pos = np.arange(len(names))\n            axs[idx_row, idx_col].tick_params(axis='x', labelrotation=30)\n        if (idx_row, idx_col) == (1, 1):\n            y_pos = np.arange(len(names))\n            axs[idx_row, idx_col].tick_params(axis='x', labelrotation=90)\n\n        total = df[col].value_counts().sum()\n        axs[idx_row, idx_col].patch.set_facecolor('#FFFFFF')\n        format_spines(axs[idx_row, idx_col], right_border=False)\n        for p in axs[idx_row, idx_col].patches:\n            w, h = p.get_width(), p.get_height()\n            x, y = p.get_xy()\n            axs[idx_row, idx_col].annotate('{:.1%}'.format(h\/1000), (p.get_x()+.29*w,\n                                            p.get_y()+h+20), color='k')\n\n        # Plot configuration\n        axs[idx_row, idx_col].set_title(col, size=12)\n        axs[idx_row, idx_col].set_ylim(0, heights.max()+120)\n        \n\ndef individual_cat_pie_plot(col, ax, cs, df):\n    \n    # Creating figure and showing data\n    names = df[col].value_counts().index\n    heights = df[col].value_counts().values\n    total = df[col].value_counts().sum()\n    #if cs:\n    #cs = cm.viridis(np.arange(len(names))\/len(names))\n    explode = np.zeros(len(names))\n    explode[0] = 0.05\n    wedges, texts, autotexts = ax.pie(heights, labels=names, explode=explode,\n                                       startangle=90, shadow=False, \n                                      autopct='%1.1f%%', colors=cs[:len(names)])\n    plt.setp(autotexts, size=12, color='w')\n    \n\ndef donut_plot(col, ax, df, text='', colors=['navy', 'crimson', 'green', 'red', 'cyan'], labels=['good', 'bad', 'fair', 'bald', 'none']):\n    \n    sizes = df[col].value_counts().values\n    #labels = df[col].value_counts().index\n    center_circle = plt.Circle((0,0), 0.80, color='white')\n    ax.pie((sizes[0], sizes[1], sizes[2], sizes[3], sizes[4]), labels=labels, colors=colors, autopct='%1.1f%%')\n    ax.add_artist(center_circle)\n    kwargs = dict(size=20, fontweight='bold', va='center')\n    ax.text(0, 0, text, ha='center', **kwargs)\n    \ndef categorical_plot(cols_cat, axs, df):\n    \n    idx_row = 0\n    for col in cols_cat:\n        # Returning column index\n        idx_col = cols_cat.index(col)\n\n        # Verifying brake line in figure (second row)\n        if idx_col >= 3:\n            idx_col -= 3\n            idx_row = 1\n\n        # Plot params\n        names = df[col].value_counts().index\n        heights = df[col].value_counts().values\n\n        # Bar chart\n        axs[idx_row, idx_col].bar(names, heights, color='navy')\n        if (idx_row, idx_col) == (0, 2):\n            y_pos = np.arange(len(names))\n            axs[idx_row, idx_col].tick_params(axis='x', labelrotation=30)\n        if (idx_row, idx_col) == (1, 1):\n            y_pos = np.arange(len(names))\n            axs[idx_row, idx_col].tick_params(axis='x', labelrotation=90)\n\n        total = df[col].value_counts().sum()\n        axs[idx_row, idx_col].patch.set_facecolor('#FFFFFF')\n        format_spines(axs[idx_row, idx_col], right_border=False)\n        for p in axs[idx_row, idx_col].patches:\n            w, h = p.get_width(), p.get_height()\n            x, y = p.get_xy()\n            axs[idx_row, idx_col].annotate('{:.1%}'.format(h\/1000), (p.get_x()+.29*w,\n                                            p.get_y()+h+20), color='k')\n\n        # Plot configuration\n        axs[idx_row, idx_col].set_title(col, size=12)\n        axs[idx_row, idx_col].set_ylim(0, heights.max()+120)\n        \n\ndef individual_cat_pie_plot(col, ax, cs, df):\n    \n    # Creating figure and showing data\n    names = df[col].value_counts().index\n    heights = df[col].value_counts().values\n    total = df[col].value_counts().sum()\n    #if cs:\n    #cs = cm.viridis(np.arange(len(names))\/len(names))\n    explode = np.zeros(len(names))\n    explode[0] = 0.05\n    wedges, texts, autotexts = ax.pie(heights, labels=names, explode=explode,\n                                       startangle=90, shadow=False, \n                                      autopct='%1.1f%%', colors=cs[:len(names)])\n    plt.setp(autotexts, size=12, color='w')\n    \n\ndef donut_plot(col, ax, df, text='', colors=['navy', 'crimson'], labels=['good', 'bad']):\n    \n    sizes = df[col].value_counts().values\n    #labels = df[col].value_counts().index\n    center_circle = plt.Circle((0,0), 0.80, color='white')\n    ax.pie((sizes[0], sizes[1]), labels=labels, colors=colors, autopct='%1.1f%%')\n    ax.add_artist(center_circle)\n    kwargs = dict(size=20, fontweight='bold', va='center')\n    ax.text(0, 0, text, ha='center', **kwargs)","4114420f":"# loading data\ncustomers_ = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_customers_dataset.csv\")\ngeolocation_ = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_geolocation_dataset.csv\")\norder_items_ = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_order_items_dataset.csv\")\norder_payments_ = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_order_payments_dataset.csv\")\norder_reviews_ = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_order_reviews_dataset.csv\")\norders_ = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_orders_dataset.csv\")\nproducts_ = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_products_dataset.csv\")\nsellers_ = pd.read_csv(\"..\/input\/brazilian-ecommerce\/olist_sellers_dataset.csv\")\ncategory_name_translation_ = pd.read_csv(\"..\/input\/brazilian-ecommerce\/product_category_name_translation.csv\")","72e7fc9b":"# displaying data shape\n#dataset = [customers, geolocation, order_items, order_payments, order_reviews, orders, products, sellers, category_name_translation]\ndataset = {\n    'Customers': customers_,\n    'Geolocation': geolocation_,\n    'Order Items': order_items_,\n    'Payments': order_payments_,\n    'Reviews': order_reviews_,\n    'Orders': orders_,\n    'Products': products_,\n    'Sellers': sellers_,\n    'Translations': category_name_translation_\n}\n\nfor x, y in dataset.items():\n    print(f'{x}', (list(y.shape)))","34cf6e2f":"# displaying dataset column names\nfor x, y in dataset.items():\n    print(f'{x}', f'{list(y.columns)}\\n')","d97f5ff7":"# checking for null values in datasets\nfor x, y in dataset.items():\n    print(f'{x}: {y.isnull().any().any()}')","e6c6a5d1":"# taking count for dataset with missing values\nfor x, y in dataset.items():\n    if y.isnull().any().any():\n        print(f'{x}', (list(y.shape)),'\\n')\n        print(f'{y.isnull().sum()}\\n')","7bd7b1f7":"# creating master dataframe \norder_payments_.head()\nprint(order_payments_.shape)\ndf1 = order_payments_.merge(order_items_, on='order_id')\nprint(df1.shape)\ndf2 = df1.merge(products_, on='product_id')\nprint(df2.shape)\ndf3 = df2.merge(sellers_, on='seller_id')\nprint(df3.shape)\ndf4 = df3.merge(order_reviews_, on='order_id')\nprint(df4.shape)\ndf5 = df4.merge(orders_, on='order_id')\nprint(df5.shape)\ndf6 = df5.merge(category_name_translation_, on='product_category_name')\nprint(df6.shape)\ndf = df6.merge(customers_, on='customer_id')\nprint(df.shape)","577fca38":"# converting date columns to datetime\ndate_columns = ['shipping_limit_date', 'review_creation_date', 'review_answer_timestamp', 'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\nfor col in date_columns:\n    df[col] = pd.to_datetime(df[col], format='%Y-%m-%d %H:%M:%S')","d491c7e3":"# cleaning up name columns, and engineering new\/essential columns\ndf['customer_city'] = df['customer_city'].str.title()\ndf['seller_city'] = df['seller_city'].str.title()\ndf['product_category_name_english'] = df['product_category_name_english'].str.title()\ndf['payment_type'] = df['payment_type'].str.replace('_', ' ').str.title()\ndf['product_category_name_english'] = df['product_category_name_english'].str.replace('_', ' ')\ndf['review_response_time'] = (df['review_answer_timestamp'] - df['review_creation_date']).dt.days\ndf['delivery_against_estimated'] = (df['order_estimated_delivery_date'] - df['order_delivered_customer_date']).dt.days\ndf['product_size_cm'] = df['product_length_cm'] * df['product_height_cm'] * df['product_width_cm']\ndf['order_purchase_year'] = df.order_purchase_timestamp.apply(lambda x: x.year)\ndf['order_purchase_month'] = df.order_purchase_timestamp.apply(lambda x: x.month)\ndf['order_purchase_dayofweek'] = df.order_purchase_timestamp.apply(lambda x: x.dayofweek)\ndf['order_purchase_hour'] = df.order_purchase_timestamp.apply(lambda x: x.hour)\ndf['order_purchase_day'] = df['order_purchase_dayofweek'].map({0:'Mon',1:'Tue',2:'Wed',3:'Thu',4:'Fri',5:'Sat',6:'Sun'})\ndf['order_purchase_mon'] = df.order_purchase_timestamp.apply(lambda x: x.month).map({0:'Jan',1:'Feb',2:'Mar',3:'Apr',4:'May',5:'Jun',6:'Jul',7:'Aug',8:'Sep',9:'Oct',10:'Nov',11:'Dec'})","90ec5eb8":"# dropping non-needed columns\ndf = df.drop([\"product_name_lenght\", \"product_description_lenght\", \"product_photos_qty\", \"product_length_cm\", \"product_height_cm\", \"product_width_cm\", \"product_length_cm\", \"review_id\",\"review_comment_title\", \"review_comment_message\", \"product_category_name\"], axis=1)","df8ba06c":"# displaying summary staticstics of columns\ndf.describe(include='all')","6e6d1f5f":"# displaying missing value counts and corresponding percentage against total observations\nmissing_values = df.isnull().sum().sort_values(ascending = False)\npercentage = (df.isnull().sum()\/df.isnull().count()*100).sort_values(ascending = False)\npd.concat([missing_values, percentage], axis=1, keys=['Values', 'Percentage']).transpose()","24b83a30":"# dropping missing values\ndf.dropna(inplace=True)\ndf.isnull().values.any()","22f1375c":"# displaying dataframe info\ndf.info()","1219e664":"# displaying first 3 rows of master dataframe\ndf.head(3)","f6c5ee3f":"# Creating new datasets for each year\ndf_2016 = df.query('order_purchase_year==\"2016\"')\ndf_2017 = df.query('order_purchase_year==\"2017\"')\ndf_2018 = df.query('order_purchase_year==\"2018\"')\n\n#displaying total orders in years, comparitive year on month, and month on days of the week\nfig, axs = plt.subplots(1, 3, figsize=(22, 5))\ncount_plot(feature='order_purchase_year', df=df, ax=axs[0], title='Total Order Purchase by Year')\ncount_plot(feature='order_purchase_year', df=df, ax=axs[1], hue='order_purchase_month', title='Total Yearly order Purchase by Month')\ncount_plot(feature='order_purchase_year', df=df, ax=axs[2], hue='order_purchase_dayofweek', title='Total Yearly order Purchase by Day of the Week')\n#format_spines(ax, right_border=False)\nplt.suptitle('Score Counting Through the Years', y=1.1)\nplt.show()","f5b0296e":"# Grouping by annual and monthly sales\ndf_ytsales = df.groupby(['order_purchase_year', 'order_purchase_month'], as_index=False).sum().loc[:, ['order_purchase_year', 'order_purchase_month', 'payment_value']]\ndf_ytsales2 = df.groupby(['order_purchase_year', 'order_purchase_dayofweek'], as_index=False).sum().loc[:, ['order_purchase_year', 'order_purchase_dayofweek', 'payment_value']]\n#df_ytsales = df.groupby(['order_purchase_year', 'order_purchase_month', 'order_purchase_dayofweek'], as_index=False).sum().loc[:, ['order_purchase_year', 'order_purchase_month', 'order_purchase_dayofweek', 'payment_value']]\n\ndf_s2016 = df_ytsales[df_ytsales['order_purchase_year']==2016]\ndf_s2017 = df_ytsales[df_ytsales['order_purchase_year']==2017]\ndf_s2018 = df_ytsales[df_ytsales['order_purchase_year']==2018]\n\nfig, axs = plt.subplots(1, 3, figsize=(22, 5))\nbar_plot(x='order_purchase_month', y='payment_value', df=df_s2016, ax=axs[0], value=True)\nbar_plot(x='order_purchase_month', y='payment_value', df=df_s2017, ax=axs[1], value=True)\nbar_plot(x='order_purchase_month', y='payment_value', df=df_s2018, ax=axs[2], value=True)\naxs[0].set_title('Monthly Sales in 2016')\naxs[1].set_title('Monthly Sales in 2017')\naxs[2].set_title('Monthly Sales in 2018', pad=10)\nplt.xticks(np.arange(8), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug'])\nplt.show()","86b8978c":"fig, axs = plt.subplots(1, 3, figsize=(22, 5))\nbar_plot(x='order_purchase_year', y='payment_value', df=df_ytsales, ax=axs[0], value=True)\nbar_plot(x='order_purchase_month', y='payment_value', df=df_ytsales, ax=axs[1], value=True)\nbar_plot(x='order_purchase_dayofweek', y='payment_value', df=df_ytsales2, ax=axs[2], value=True)\naxs[0].set_title('Monthly Sales in 2016')\naxs[1].set_title('Monthly Sales in 2017')\naxs[2].set_title('Monthly Sales in 2018', pad=10)\nplt.xticks(np.arange(7), ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n\nplt.show()","30733227":"# Changing the month attribute for correct ordenation\ndf_ytsales['order_purchase_month'] = df_ytsales['order_purchase_month'].astype(str).apply(lambda x: '0' + x if len(x) == 1 else x)\n\n# Creating new year-month column\ndf_ytsales['month_year'] = df_ytsales['order_purchase_year'].astype(str) + '-' + df_ytsales['order_purchase_month'].astype(str)\ndf_ytsales['order_purchase_month'] = df_ytsales['order_purchase_month'].astype(int)\n\n# PLotting\nfig, ax = plt.subplots(figsize=(14, 4.5))\nax = sns.lineplot(x='month_year', y='payment_value', data=df_ytsales.iloc[:-1, :])\nformat_spines(ax, right_border=False)\nax.tick_params(axis='x', labelrotation=90)\nax.set_title('Brazilian E-Commerce Sales Evolution')\nplt.show()\n\nfig, ax = plt.subplots(figsize=(14, 4.5))\n\nax = sns.lineplot(x='order_purchase_month', y='payment_value', data=df_s2016, label='2016')\nax = sns.lineplot(x='order_purchase_month', y='payment_value', data=df_s2017, label='2017')\nax = sns.lineplot(x='order_purchase_month', y='payment_value', data=df_s2018, label='2018')\nformat_spines(ax, right_border=False)\nax.set_title('Brazilian E-Commerce Sales Comparison')\nplt.xticks(np.arange(13), ['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\nplt.show()","04e56832":"#customer and eliverybehaviour\n\npurchase_count = df.groupby(['order_purchase_day', 'order_purchase_hour']).count()['price'].unstack()\nplt.figure(figsize=(22,7))\nsns.heatmap(purchase_count.reindex(index = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']), cmap=\"YlGnBu\", annot=True, fmt=\"d\", linewidths=0.2)\nplt.show()","94c33dd9":"df_ypt = df.groupby(['order_purchase_year', 'payment_type'], as_index=False).sum().loc[:, ['order_purchase_year', 'payment_type', 'payment_value']]\ndf_dpt = df.groupby(['order_purchase_year', 'payment_type'], as_index=False).mean().loc[:, ['order_purchase_year', 'payment_type', 'payment_value']]\n\n#displaying total orders in years, comparitive year on month, and month on days of the week\nfig, axs = plt.subplots(1, 3, figsize=(22, 5))\ncount_plot(feature='payment_type', df=df, ax=axs[0], title='Total Order Purchase by Year')\nbar_plot(x='order_purchase_year', y='payment_value', ax=axs[1], hue='payment_type', df=df_ypt.sort_values(by='payment_value', ascending=False), value=True)\nbar_plot(x='payment_type', y='payment_value', ax=axs[2], hue='order_purchase_year', df=df_dpt.sort_values(by='payment_value', ascending=False), value=True)\n\nformat_spines(ax, right_border=False)\nplt.suptitle('Score Counting Through the Years', y=1.1)\nplt.show()","0f9cdb85":"df_ypt","c623f556":"df_dpt","cbcf31bc":"# Grouping by customer state\ndf_cus_st = df.groupby(['customer_state'], as_index=False).sum().loc[:, ['customer_state', 'payment_value']].sort_values(by='payment_value', ascending=False)\ndf_cus_ct = df.groupby(['customer_city'], as_index=False).sum().loc[:, ['customer_city', 'payment_value']].sort_values(by='payment_value', ascending=False).head(20)\n\nfig, axs = plt.subplots(1, 2, figsize=(22, 7))\nbar_plot(x='payment_value', y='customer_state', df=df_cus_st, ax=axs[0], value=False)\nbar_plot(x='payment_value', y='customer_city', df=df_cus_ct, ax=axs[1], value=False)\nformat_spines(ax, right_border=False)\naxs[0].set_title('Monthly Sales in 2016')\naxs[1].set_title('Monthly Sales in 2017')\n\nplt.show()","10a22b8f":"df_cus_ct.sort_values(by='payment_value', ascending=False)","2f812a21":"df_cus_st.head(20).sort_values(by='payment_value', ascending=False)","1184d606":"customer_value_sum = (df.groupby(['customer_unique_id'])[['payment_value', 'payment_installments','review_score']]\n.agg({'payment_value':['count', 'mean', 'sum'], 'payment_installments': ['mean'], 'review_score': ['mean']})\n                ).sort_values(by=('payment_value','sum'), ascending=False)\n\ncustomer_value_sum.head(20)","67acd31f":"From","9ce24c03":"From","b9e35314":"From","2c8212d7":"# Logistics and Customer Rating Analysis","9e56dd76":"From","b9526a93":"From","91588563":"From the Dataset provided, Majority of the orders captured were from 2018, followed by 2017 and the least orders came in 2016 ","0967312c":"# Time Series Analysis","d9501b79":"From","b59e5b7d":"# Payment Analysis","68fe87e8":"The above master dataframe constitutes of the various independent dataset provided joined together via unique keys. Date columns have also been converted to datetime and new essential columns engineered for analysis purpose. ","d670aafa":"# Customer analysis"}}