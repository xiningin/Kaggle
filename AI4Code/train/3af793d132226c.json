{"cell_type":{"af9c03e2":"code","3c6e66e0":"code","35e67ec0":"code","72c96122":"code","aa065b1f":"code","89d00490":"code","44cf1b26":"code","3c1da01e":"code","34d73edd":"code","ec1a0235":"code","d87014e5":"code","21e48620":"code","fafec856":"code","78b5142f":"code","adee46ec":"code","efb4ed8c":"code","bd714421":"code","8f76cb62":"markdown","94b14f62":"markdown","5fc1f593":"markdown","1b626f3c":"markdown","6908072e":"markdown","987fd6ff":"markdown","e437c1d9":"markdown","412d0502":"markdown","e744a387":"markdown","443840d9":"markdown","cd82b005":"markdown","06b5122c":"markdown","1edc6631":"markdown","b1014d22":"markdown","e35398b7":"markdown","67a14946":"markdown"},"source":{"af9c03e2":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport math\nimport io\nimport os\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\nfrom torchvision import transforms, datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport cv2\nimport glob","3c6e66e0":"seed = 3\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False","35e67ec0":"import zipfile\n\n#unzip BDRW_train_1.zip\nz = zipfile.ZipFile('..\/input\/bdrw\/BDRW_train\/BDRW_train_1.zip', \"r\")\nfor name in z.namelist():\n    z.extract(name)\n    \n#unzip BDRW_train_2.zip    \nz = zipfile.ZipFile('..\/input\/bdrw\/BDRW_train\/BDRW_train_2.zip', \"r\")\nfor name in z.namelist():\n    z.extract(name)","72c96122":"#read the excel file-labels.xls containing the image labels\nlabels = pd.read_excel('BDRW_train_2\/labels.xls')\nlabels.columns = ['digit', 'label']","aa065b1f":"#view the labels dataframe\nlabels.head()","89d00490":"#Plot a histogram with x-axis : class label, y-axis : percentage of data in that class\nlabels['label'].hist(density = True)","44cf1b26":"bdrw_train_1 = [f[13:-4] for f in glob.glob(\"BDRW_train_1\/*\")] #list of image names in BDRW_train_1 folder\nbdrw_train_2 = [f[13:-4] for f in glob.glob(\"BDRW_train_2\/*\")] #list of image names in BDRW_train_2 folder\n\nprint('Number of images in BDRW_train_1: ', len(bdrw_train_1))\nprint('Number of images in BDRW_train_2: ', len(bdrw_train_2))\n\nprint('First 5 images in BDRW_train_1:', bdrw_train_1[:5])\nprint('First 5 images in BDRW_train_2:', bdrw_train_2[:5])","3c1da01e":"size = 32 #size of the resized image\nX = []\n\nfor i,row in labels.iterrows(): #loop across the rows of the 'labels' dataframe\n    \n    #read the image in the 'digit' column of 'labels' dataframe\n    if(row['digit'] in bdrw_train_1): #if the image is in BDRW_train_1 folder\n        image = cv2.imread('BDRW_train_1\/' + row['digit'] + \".jpg\", 0)  \n    else:  #if the image is in BDRW_train_2 folder\n        image = cv2.imread('BDRW_train_2\/' + row['digit'] + \".jpg\", 0)\n        \n    image = cv2.resize(image, dsize = (size,size)) #resize the image\n    X.append(image) #append the image to the list\n\nX = np.array(X) #convert the image into numpy array\nX = X\/float(255.0) #normalize the values\ny = labels['label'].values #get the labels\n\nprint(\"Shape of X: \", X.shape, \"\\t Shape of y: \", y.shape)","34d73edd":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.70, random_state = 25, stratify = y) #put 70% data in train\n\nX_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.50, random_state = 25, stratify = y_test) #put 15% data in test and validation each\n\nprint(\"Shape of train data: \\t\\t\", (X_train.shape, y_train.shape))\nprint(\"Shape of validation data: \\t\", (X_val.shape, y_val.shape))\nprint(\"Shape of test data: \\t\\t\", (X_test.shape, y_test.shape))","ec1a0235":"# converting training images into torch format\nX_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2])\nX_train  = torch.from_numpy(X_train)\n\n# converting the training labels into torch format\ny_train = y_train.astype(int);\ny_train = torch.from_numpy(y_train)\ny_train = y_train.squeeze()\n\n# shape of training data\nprint(\"Shape of train data, \\t X : \", X_train.shape,\"\\t and y: \", y_train.shape)\n\n# converting validation images into torch format\nX_val = X_val.reshape(X_val.shape[0], 1, X_val.shape[1], X_val.shape[2])\nX_val  = torch.from_numpy(X_val)\n\n# converting the validation labels into torch format\ny_val = y_val.astype(int);\ny_val = torch.from_numpy(y_val)\ny_val = y_val.squeeze()\n\n# shape of validation data\nprint(\"Shape of val. data, \\t X : \", X_val.shape,\"\\t and y: \", y_val.shape) \n\n# converting test images into torch format\nX_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1], X_test.shape[2])\nX_test  = torch.from_numpy(X_test)\n\n# converting the test labels into torch format\ny_test = y_test.astype(int);\ny_test = torch.from_numpy(y_test)\ny_test = y_test.squeeze()\n\n# shape of test data\nprint(\"Shape of test data, \\t X : \", X_test.shape,\"\\t and y: \", y_test.shape) ","d87014e5":"def random_mini_batches(X, Y, mini_batch_size = 32, seed = 3):\n    \n    np.random.seed(seed)            \n    m = X.shape[0]                  # number of training examples\n    mini_batches = []\n        \n    # Step 1: Shuffle (X, Y)\n    permutation = list(np.random.permutation(m))\n    shuffled_X = X[permutation,:,:,:]\n    shuffled_Y = Y[permutation].reshape((m,1))\n\n    # Step 2: Partition (shuffled_X, shuffled_Y). Excluding the end case.\n    num_complete_minibatches = math.floor(m\/mini_batch_size) # number of complete mini batches of size mini_batch_size\n    for k in range(0, num_complete_minibatches):\n        mini_batch_X = shuffled_X[mini_batch_size*k : mini_batch_size*(k+1), :, :, :]\n        mini_batch_Y = shuffled_Y[mini_batch_size*k : mini_batch_size*(k+1), :]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    # Handling the end case (last mini-batch < mini_batch_size)\n    if m % mini_batch_size != 0:\n        mini_batch_X = shuffled_X[mini_batch_size*num_complete_minibatches : , :, :, :]\n        mini_batch_Y = shuffled_Y[mini_batch_size*num_complete_minibatches : , :]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    return mini_batches","21e48620":"#An architechture inspired from the famous LeNet5 architechture\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        self.conv1 = nn.Conv2d(1, 6, kernel_size = 5, stride = 1, padding = 0) #input size:1*32*32 , output size: 6*28*28 \n        self.max_pool_1 = nn.MaxPool2d(kernel_size=2) #input size:6*28*28 , output size: 6*14*14 \n        self.batch_norm_1 = nn.BatchNorm2d(6) #normalizes the input to the next conv2d layer\n        self.conv2 = nn.Conv2d(6, 16, kernel_size = 5, stride = 1, padding = 0) #input size:6*14*14 , output size: 16*10*10 \n        self.max_pool_2 = nn.MaxPool2d(kernel_size=2) #input size:16*10*10 , output size:16*5*5 \n        self.batch_norm_2 = nn.BatchNorm2d(16) #normalizes the input to the next fully connected layer\n        self.fc1 = nn.Linear(16*5*5, 120) #input size:16*5*5 , output size: 120\n        self.dropout_1 = nn.Dropout(p = 0.5) #dropout for regularization (to prevent overfitting on the train set)\n        self.fc2 = nn.Linear(120, 84) #input size:120 , output size: 84\n        self.dropout_2 = nn.Dropout(p = 0.5) #dropout for regularization (to prevent overfitting on the train set)\n        self.fc3 = nn.Linear(84, 10) #input size:84 , output size: 10 (no. of classes for our problem)\n\n#define the data flow\n    def forward(self, x):\n        \n        x = F.relu(self.conv1(x))\n        x = self.max_pool_1(x)\n        x = self.batch_norm_1(x)\n        x = x = F.relu(self.conv2(x))\n        x = self.max_pool_2(x)\n        x = self.batch_norm_2(x)\n        x = x.view(-1, 16*5*5) #reshape for input to the fully connected layer 1 (fc1)\n        x = F.relu(self.fc1(x))\n        x = self.dropout_1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout_2(x)\n        x = self.fc3(x)\n        return F.log_softmax(x, dim = 1)","fafec856":"# defining the model\nmodel = Net()\nmodel = model.float()\n\n# defining the optimizer\nlearning_rate = 0.0004\noptimizer = optim.Adam(model.parameters(), lr = learning_rate) #Adam optimizer\n\n# defining the loss function\nvalues, counts = np.unique(y_train.float(), return_counts = True)\nweights = sum(counts)\/counts\nweights = torch.tensor(weights, dtype = torch.float)\ncriterion = nn.CrossEntropyLoss(weight = weights) #weights used to deal with the Class Imbalance problem\n\n# checking if GPU is available\nif torch.cuda.is_available():\n    model = model.cuda()\n    criterion = criterion.cuda()\n    \nprint(model) ","78b5142f":"def train(epoch, X_train, y_train, X_val, y_val):\n    \n    model.train()\n\n    # converting the data into GPU format\n    if torch.cuda.is_available():\n        X_train = X_train.cuda()\n        y_train = y_train.cuda()\n        X_val = X_val.cuda()\n        y_val = y_val.cuda()\n\n    # clearing the Gradients of the model parameters\n    optimizer.zero_grad()\n    \n    # prediction for training and validation set\n    output_train = model(X_train.float())\n    output_val = model(X_val.float())\n    \n    # computing the training and validation loss\n    loss_train = criterion(output_train, y_train.long())\n    loss_val = criterion(output_val, y_val.long())\n        \n    # computing the predictions for training and validation set\n    preds_train = torch.argmax(output_train,dim=1)\n    preds_val = torch.argmax(output_val,dim=1)\n\n    # computing the updated weights of all the model parameters\n    loss_train.backward()\n    optimizer.step()\n\n    return((loss_val, preds_val), (loss_train, preds_train))","adee46ec":"seed = 3 #random seed\nn_epochs = 50 #number of epochs\nmini_batch_size = 16 #size of the mini batch\nm = X_train.shape[0] #no of training examples\nn_batches = np.ceil(y_train.shape[0]\/mini_batch_size) #no of batches\n\n# empty lists to store training losses, accuracy\ntrain_losses = []\ntrain_accuracy = []\n\n# empty lists to store validation losses, accuracy\nval_losses = []\nval_accuracy = []\n\n# training the model\nfor epoch in range(n_epochs):\n    \n    val_running_loss = 0\n    val_running_corr = 0\n    train_running_loss = 0\n    train_running_corr = 0\n    seed += 1 #change the seed to reshuffle the dataset differently after each epoch \n    minibatches = random_mini_batches(X_train, y_train, mini_batch_size, seed) #get the minibacthes\n    i = 0\n    \n    for minibatch in minibatches:\n        \n        (minibatch_X, minibatch_Y) = minibatch\n        size = minibatch_Y.shape[0] #get the size of minibatch_Y\n        minibatch_Y = torch.reshape(minibatch_Y, (size,)) #reshape appropriately \n        (loss_val, preds_val), (loss_train, preds_train) = train(epoch, minibatch_X, minibatch_Y, X_val, y_val) #get the losses and predictions after training\n        \n        val_running_loss += loss_val \n        val_running_corr += torch.sum(preds_val == y_val.long())\n        train_running_loss += loss_train \n        train_running_corr += torch.sum(preds_train == minibatch_Y.long())\n        i = i+1\n        \n    val_epoch_loss = val_running_loss.item()\/i\n    val_epoch_acc = val_running_corr.item()\/(X_val.shape[0] * i)\n    if((epoch+1)%2 == 0):\n        print('Epoch {:.0f}\/{:.0f} : Validation loss: {:.4f} | Validation Accuracy: {:.4f}'.format(epoch+1,n_epochs,val_epoch_loss,val_epoch_acc*100))\n    \n    train_epoch_loss = train_running_loss.item()\/i\n    train_epoch_acc = train_running_corr.item()\/X_train.shape[0]\n    \n    #append the losses and accuracies to the lists\n    train_losses.append(train_epoch_loss)\n    val_losses.append(val_epoch_loss)\n    train_accuracy.append(train_epoch_acc)\n    val_accuracy.append(val_epoch_acc)","efb4ed8c":"plt.plot(train_losses, label='Training loss')\nplt.plot(val_losses, label='Validation loss')\nplt.legend()\nplt.show()","bd714421":"if torch.cuda.is_available():\n    X_test = X_test.cuda()\n    y_test = y_test.cuda()\noutput_test = model(X_test.float())\npreds_test =  torch.argmax(output_test,dim=1)\ntest_acc = 100*torch.sum(preds_test == y_test.long()).item()\/len(y_test)\nprint('Testing accuracy is: %0.4f'%test_acc)","8f76cb62":"### **Train-Test-Validation Split**","94b14f62":"### **Define model, optimizer, loss function**","5fc1f593":"### **Training the dataset**","1b626f3c":"### **Read the images**","6908072e":"### **Training function**","987fd6ff":"### **Load and preprocess data**","e437c1d9":"### **Define the Network Architechture**","412d0502":"1. **Conv2d layer 1:** #input size: 1x32x32 , output size: 6x28x28 <br>\nParams = (cwh + 1)k = ((1 * 5 * 5) + 1) * 6 = 156 <br>\nFlops = (cwh + 1)k * Ow * Oh = ((1 * 5 * 5) + 1) * 6 * 28 * 28 = 122304 <br>\n\n2. **ReLU:** #input size: 6x28x28  , output size: 6x28x28 <br>\nParams = 0 <br>\nFlops = 2cMN = 2 * 6 * 28 * 28 = 9408 <br>\n\n3. **Max pool layer 1:** #input size: 6x28x28  , output size: 6x14x14 <br>\nParams = 0 <br>\nFlops = c*(wh - 1) * Ow * Oh = 6 * ((2 * 2) - 1) * 14 * 14 = 3528 <br>\n\n4. **Conv2d layer 2:** #input size: 6x14x14  , output size: 16x10x10  <br>\nParams = (cwh + 1)k = ((6 * 5 * 5) + 1) * 16 = 2416 <br>\nFlops = (cwh + 1)k * Ow * Oh = ((6 * 5 * 5) + 1) * 16 * 10 * 10 = 241600 <br>\n\n5. **ReLU:** #input size:  16x10x10   , output size:  16x10x10   <br>\nParams = 0 <br>\nFlops = 2cMN = 2 * 16 * 10 * 10 = 3200 <br>\n\n6. **Max pool layer 2:** #input size: 16x10x10  , output size: 16x5x5  <br>\nParams = 0 <br>\nFlops = c*(wh - 1) * Ow * Oh = 16*((2 * 2) - 1) * 5 * 5 = 1200 <br>\n\n7. **Fully connected layer 1:** #input size: 16x5x5, output size: 120 <br>\nParams = (n + 1)k = (16 * 5 * 5 + 1) * 120 = 48120 <br>\nFlops = (n + 1)k = (16 * 5 * 5 + 1) * 120 = 48120 <br>\n\n8. **ReLU:** #input size: 120, output size: 120 <br>\nParams = 0 <br>\nFlops = 2n = 2 * 120 = 240 <br>\n\n9. **Fully connected layer 2:** #input size: 120, output size: 84 <br>\nParams = (n + 1)k = (120 + 1) * 84 = 10164 <br>\nFlops = (n + 1)k = (120 + 1) * 84 = 10164 <br>\n\n10. **ReLU:** #input size: 84, output size: 84 <br>\nParams = 0 <br>\nFlops = 2n = 2 * 84 = 168 <br>\n\n11. **Fully connected layer 3:** #input size: 84, output size: 10 <br>\nParams = (n + 1)k = (84 + 1) * 10 = 850 <br>\nFlops = (n + 1)k = (84 + 1) * 10 = 850 <br>\n\n**Total Params = 61,706 <br>\nTotal FLOPS = 440,782 <br>**\n\nNote: Assuming that #params and #flops for dropout and batch normalization layers ~ 0","e744a387":"### **Convert the data into usable torch format**","443840d9":"### **Function to create minibatches**","cd82b005":"### **Import libraries**","06b5122c":"### **Check the model accuracy on the unseen test set**","1edc6631":"### **Check the class distribution**","b1014d22":"### **Model complexity calculations**","e35398b7":"### **Plot the training and validation loss curves**","67a14946":"### **Set the random seed**"}}