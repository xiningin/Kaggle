{"cell_type":{"7eb28387":"code","f19ef739":"code","aaf16eb3":"code","9086b620":"code","a2afeb47":"code","c583b21c":"code","32f3a62e":"code","c96bc167":"code","30705d3e":"code","dd11d49f":"code","5e3a8bf6":"code","4306ae28":"code","84921802":"code","d26951a9":"code","da59e437":"code","a01eb9d1":"markdown","93c3b628":"markdown","bfe0a5cf":"markdown","aebce5a8":"markdown","f45be87f":"markdown","396b0000":"markdown","038f27d6":"markdown","c66d9675":"markdown"},"source":{"7eb28387":"import pandas as pd","f19ef739":"train = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_inicial_train\/ib_base_inicial_train.csv\")\nX_test = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_inicial_test\/ib_base_inicial_test.csv\")\n\nsunat = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_sunat\/ib_base_sunat.csv\")\nreniec = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_reniec\/ib_base_reniec.csv\")\nvehicular = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_vehicular\/ib_base_vehicular.csv\")\ncampanias = pd.read_csv(\"\/kaggle\/input\/interbank-internacional-2019\/ib_base_campanias\/ib_base_campanias.csv\")","aaf16eb3":"y_train = train[['codmes', 'id_persona', 'margen']].copy()\ny_train[\"prediction_id\"] = y_train[\"id_persona\"].astype(str) + \"_\" + y_train[\"codmes\"].astype(str)\ny_train[\"target\"] = (y_train[\"margen\"] > 0).astype(int)\ny_train = y_train.set_index(\"prediction_id\")\nX_train = train.drop([\"codtarget\", \"margen\"], axis=1)\nX_train[\"prediction_id\"] = X_train[\"id_persona\"].astype(str) + \"_\" + X_train[\"codmes\"].astype(str)\ndel train","9086b620":"sunat = sunat.groupby([\"id_persona\", \"activ_econo\"]).meses_alta.sum().unstack(level=1, fill_value=0).astype(\"int32\")\nvehicular1 = vehicular.groupby([\"id_persona\", \"marca\"]).veh_var1.sum().unstack(level=1, fill_value=0).astype(\"float32\")\nvehicular2 = vehicular.groupby([\"id_persona\", \"marca\"]).veh_var2.sum().unstack(level=1, fill_value=0).astype(\"float32\")\nreniec = reniec.set_index(\"id_persona\").astype(\"float32\")\ndel vehicular","a2afeb47":"vehicular1.columns = [c + \"_v1\" for c in vehicular1.columns]\nvehicular2.columns = [c + \"_v2\" for c in vehicular2.columns]","c583b21c":"X_train = X_train.set_index(\"prediction_id\").astype(\"int32\").reset_index().set_index(\"id_persona\").join(vehicular1).join(vehicular2).join(reniec).join(sunat)\nX_test = X_test.set_index(\"prediction_id\").astype(\"int32\").reset_index().set_index(\"id_persona\").join(vehicular1).join(vehicular2).join(reniec).join(sunat)\ndel vehicular1, vehicular2, reniec, sunat","32f3a62e":"camp_canal = campanias.groupby([\"codmes\", \"id_persona\", \"canal_asignado\"]).size().unstack(level=2, fill_value=0).reset_index().set_index(\"codmes\").sort_index().astype(\"int32\")\ncamp_prod = campanias.groupby([\"codmes\", \"id_persona\", \"producto\"]).size().unstack(level=2, fill_value=0).reset_index().set_index(\"codmes\").sort_index().astype(\"int32\")\ndel campanias","c96bc167":"import gc\ngc.collect()","30705d3e":"meses = {\n    201901: slice(201808, 201810),\n    201902: slice(201809, 201811),\n    201903: slice(201810, 201812),\n    201904: slice(201811, 201901),\n    201905: slice(201812, 201902),\n    201906: slice(201901, 201903),\n    201907: slice(201902, 201904)\n}\n\ncomplementos = []\nfor mes in meses.keys():\n    print(\"*\"*10, mes, \"*\"*10)\n    res = pd.concat([\n        camp_canal.loc[meses[mes]].groupby(\"id_persona\").sum(),\n        camp_prod.loc[meses[mes]].groupby(\"id_persona\").sum()\n        \n    ], axis=1)\n    res[\"codmes\"] = mes\n    res = res.reset_index().set_index([\"id_persona\", \"codmes\"]).astype(\"float32\")\n    complementos.append(res)\n\ngc.collect()\nprint(\"contatenando complementos\")\ncomplementos = pd.concat(complementos)\ngc.collect()\nprint(\"X_train join\")\nX_train = X_train.reset_index().join(complementos, on=[\"id_persona\", \"codmes\"]).set_index(\"prediction_id\")\ngc.collect()\nprint(\"X_test join\")\nX_test = X_test.reset_index().join(complementos, on=[\"id_persona\", \"codmes\"]).set_index(\"prediction_id\")\ngc.collect()\n\ndel camp_canal, camp_prod, complementos,res\ngc.collect()","dd11d49f":"non_ascii = X_train.columns[[not all(ord(c) < 128 for c in s) for s in X_train.columns]].tolist()\nnon_ascii","5e3a8bf6":"for i, c in enumerate(non_ascii):\n    X_train[\"non_ascii_\" + str(i)] = X_train[c]\n    X_train = X_train.drop(c, axis= 1)\n    X_test[\"non_ascii_\" + str(i)] = X_test[c]\n    X_test = X_test.drop(c, axis= 1)","4306ae28":"from lightgbm import LGBMClassifier\ndrop_cols = [\"codmes\"]\nfi = []\ntest_probs = []\ntrain_probs = []\nfor mes in X_train.codmes.unique():\n    print(\"*\"*10, mes, \"*\"*10)\n    Xt = X_train[X_train.codmes != mes]\n    yt = y_train.loc[Xt.index, \"target\"]\n    Xt = Xt.drop(drop_cols, axis=1)\n\n    Xv = X_train[X_train.codmes == mes]\n    yv = y_train.loc[Xv.index, \"target\"]\n    \n    learner = LGBMClassifier(n_estimators=10000)\n    learner.fit(Xt, yt,  early_stopping_rounds=10, eval_metric=\"auc\",\n                eval_set=[(Xt, yt), (Xv.drop(drop_cols, axis=1), yv)], verbose=50)\n    \n    test_probs.append(pd.Series(learner.predict_proba(X_test.drop(drop_cols, axis=1))[:, -1],\n                                index=X_test.index, name=\"fold_\" + str(mes)))\n    train_probs.append(pd.Series(learner.predict_proba(Xv.drop(drop_cols, axis=1))[:, -1],\n                                index=Xv.index, name=\"probs\"))\n    fi.append(pd.Series(learner.feature_importances_ \/ learner.feature_importances_.sum(), index=Xt.columns))\n\ntest_probs = pd.concat(test_probs, axis=1).mean(axis=1)\ntrain_probs = pd.concat(train_probs)\nfi = pd.concat(fi, axis=1).mean(axis=1)","84921802":"fi.sort_values().tail(50).to_frame()","d26951a9":"from scipy.optimize import differential_evolution\n\nres = y_train.join(train_probs.rename(\"probs\"))\noptimization = differential_evolution(lambda c: -((res.probs > c[0]) * res.margen \/ res.margen.sum()).sum(), [(0, 1)])\noptimization","da59e437":"test_preds = (test_probs > optimization[\"x\"][0]).astype(int)\ntest_preds.index.name=\"prediction_id\"\ntest_preds.name=\"class\"\ntest_preds.to_csv(\"benchmark1.csv\", header=True)","a01eb9d1":"## Importancia de Variables\n\nObservamos la importancia media que le dieron los modelos a cada variables","93c3b628":"## Consolidaci\u00f3n de Bases\n\nSe unene todas las bases por id_persona","bfe0a5cf":"## Lectura de Datos\n\nSe leer\u00e1n las bases b\u00e1sicas, que solo tienen registros a nivel de usuario. S\u00f3lo se leer\u00e1 la informaci\u00f3n de campa\u00f1a que dependa del tiempo. Queda para mejorar, la incorporacion de m\u00e1s informaici\u00f3n temporal. ","aebce5a8":"## Guardado del modelo para hacer la presentaci\u00f3n","f45be87f":"## Renombrado de Variables con nombre no ascii\n\nEl algoritmo que usamos no se lleva bien con cadenas de texto con caracteres especiales, las renombramos.","396b0000":"## Creaci\u00f3n del Target de predicci\u00f3n\n\nSe opta por construir un target binario, para establecer quienes son clientes rentables y, por tanto, es conveniente hacerles campa\u00f1a para atraerlos. ","038f27d6":"## Optimizaci\u00f3n de punto de corte\n\nCon las probabilidades calculadas en validaci\u00f3n, calcularmos el punto de corte optimo para maximizar la ecuaci\u00f3n econ\u00f3mica de la empresa","c66d9675":"## Entrenamiento del Modelo\n\nSe entrena un modelo con valores en default, pero optimizando en nro de estimadores inferiores, con validaci\u00f3n basada en meses."}}