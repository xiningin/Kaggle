{"cell_type":{"1e0b311f":"code","e5a87ba3":"code","4c77a28a":"code","28246208":"code","82505e05":"code","2731e0cb":"code","5f144d33":"code","88f84f86":"code","80d28760":"code","78b43d82":"code","abe0c902":"code","6a1203e6":"code","5c3056cf":"code","1a344316":"code","b23c7e2b":"code","4856aa4f":"code","d479824a":"code","463d2dac":"code","2cf73e36":"code","cb643130":"code","e65dd44d":"code","7f7339a5":"code","338a4303":"code","96db3675":"code","6bdef9f5":"code","8afc23c2":"code","9005ac21":"code","af46d1d0":"code","f6cf229a":"code","be12a215":"code","a44cd04c":"code","cf968d84":"code","1d614cf2":"code","650b6a0a":"code","0b734250":"code","ee82f130":"code","0c13c321":"code","b9271861":"markdown","4e8e9385":"markdown","636cdc4b":"markdown","5961f920":"markdown"},"source":{"1e0b311f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport numpy as np\n%matplotlib inline\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e5a87ba3":"df = pd.read_csv(\"..\/input\/bank-customer-churn-modeling\/Churn_Modelling.csv\")\ndf.sample(5)","4c77a28a":"df.columns","28246208":"df.drop(['RowNumber', 'CustomerId', 'Surname'],axis=1,inplace=True)","82505e05":"df.sample(5)","2731e0cb":"df['Geography'].nunique()","5f144d33":"df['Gender'].replace({'Female':1,'Male':0},inplace=True)","88f84f86":"df.sample(10)","80d28760":"df[df.Exited==1]","78b43d82":"df1 = pd.get_dummies(data=df, columns=['Geography'])","abe0c902":"df1.sample(10)","6a1203e6":"df1.dtypes","5c3056cf":"exited_no = df1[df1.Exited==0].Tenure\nexited_yes = df1[df1.Exited==1].Tenure\n\nplt.xlabel(\"tenure\")\nplt.ylabel(\"Number Of Customers\")\nplt.title(\"Customer Exited Prediction Visualiztion\")\n\nplt.hist([exited_yes,exited_no], rwidth=0.95, color=['green','red'],label=['Exited=Yes','Exited=No'])\nplt.legend()","1a344316":"exited_no = df1[df1.Exited==0].Age\nexited_yes = df1[df1.Exited==1].Age\n\nplt.xlabel(\"Age\")\nplt.ylabel(\"Number Of Customers\")\nplt.title(\"Customer Exited Prediction Visualiztion based on Age \")\n\nplt.hist([exited_yes,exited_no], rwidth=0.95, color=['green','red'],label=['Exited=Yes','Exited=No'])\nplt.legend()","b23c7e2b":"exited_no = df1[df1.Exited==0].NumOfProducts\nexited_yes = df1[df1.Exited==1].NumOfProducts\n\nplt.xlabel(\"NumOfProducts\")\nplt.ylabel(\"Number Of Customers\")\nplt.title(\"Customer Exited Prediction Visualiztion based on Age \")\n\nplt.hist([exited_yes,exited_no], rwidth=0.95, color=['green','red'],label=['Exited=Yes','Exited=No'])\nplt.legend()","4856aa4f":"cols_to_scale = ['CreditScore','Age','Tenure','Balance','EstimatedSalary','NumOfProducts']\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndf1[cols_to_scale] = scaler.fit_transform(df1[cols_to_scale])","d479824a":"df1.sample(10)","463d2dac":"df1.shape","2cf73e36":"X = df1.drop('Exited',axis='columns')\ny = df1['Exited']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)","cb643130":"X_train.shape","e65dd44d":"X_test.shape","7f7339a5":"len(X_train.columns)","338a4303":"import tensorflow as tf\nfrom tensorflow_addons import losses\nfrom tensorflow import keras\nfrom sklearn.metrics import confusion_matrix , classification_report\nfrom sklearn.metrics import confusion_matrix ,  classification_report","96db3675":"def ann(X_train, y_train, X_test, y_test, loss, weights):\n    model = keras.Sequential([\n        keras.layers.Dense(12, input_dim=12, activation='relu'),\n        keras.layers.Dense(6, activation='relu'),\n        keras.layers.Dense(1, activation='sigmoid')\n    ])\n\n    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n    \n    if weights == -1:\n        model.fit(X_train, y_train, epochs=100)\n    else:\n        model.fit(X_train, y_train, epochs=100, class_weight = weights)\n    \n    print(model.evaluate(X_test, y_test))\n    \n    y_preds = model.predict(X_test)\n    y_preds = np.round(y_preds)\n    \n    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n    \n    return y_preds","6bdef9f5":"count_class_0, count_class_1 = df1.Exited.value_counts()\n\ndf_class_0 = df1[df1['Exited'] == 0]\ndf_class_1 = df1[df1['Exited'] == 1]","8afc23c2":"df_class_0_under = df_class_0.sample(count_class_1)\ndf_test_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n\nprint('Under-sampling:')\nprint(df_test_under.Exited.value_counts())","9005ac21":"X = df_test_under.drop('Exited',axis='columns')\ny = df_test_under['Exited']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)","af46d1d0":"y_preds = ann(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)","f6cf229a":"df_class_1_over = df_class_1.sample(count_class_0, replace=True)\ndf_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n\nprint('over-sampling:')\nprint(df_test_over.Exited.value_counts())","be12a215":"X = df_test_over.drop('Exited',axis='columns')\ny = df_test_over['Exited']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)","a44cd04c":"loss = keras.losses.BinaryCrossentropy()\nweights = 1\ny_preds = ann(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)","cf968d84":"import seaborn as sn\ncm = tf.math.confusion_matrix(labels=y_test,predictions=y_preds)\n\nplt.figure(figsize = (10,7))\nsn.heatmap(cm, annot=True, fmt='d')\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","1d614cf2":"from imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(sampling_strategy='minority')\nX_sm, y_sm = smote.fit_resample(X, y)\n\ny_sm.value_counts()","650b6a0a":"X = df1.drop('Exited',axis='columns')\ny = df1['Exited']","0b734250":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size = 0.2, random_state = 15 , stratify = y_sm)","ee82f130":"y_preds =ann(X_train, y_train, X_test, y_test, 'binary_crossentropy', -1)","0c13c321":"import seaborn as sn\ncm = tf.math.confusion_matrix(labels=y_test,predictions=y_preds)\n\nplt.figure(figsize = (10,7))\nsn.heatmap(cm, annot=True, fmt='d')\nplt.xlabel('Predicted')\nplt.ylabel('Truth')","b9271861":"1. using undersampling","4e8e9385":"2.  Oversampling","636cdc4b":"# Hanndling  imbalanced data","5961f920":"3. SMOTE"}}