{"cell_type":{"ab71d7a6":"code","132f941b":"code","3bcc40de":"code","65be520d":"code","8a2ec8c5":"code","16b96a07":"code","ed3b6cad":"code","90779d8b":"code","b155dc7e":"code","42dfe99a":"code","0d2368cd":"markdown","233292ac":"markdown","504b95a6":"markdown","62ca5037":"markdown","c523daf0":"markdown","e9c50131":"markdown","20780023":"markdown","a6ce3323":"markdown","86ea7032":"markdown"},"source":{"ab71d7a6":"# importing basic libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns # for visualization\n# reading data\nraw_data = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\nprint(\"First 5 rows of dataset: \")\nraw_data.head(5)","132f941b":"raw_data.isna().sum().any()","3bcc40de":"raw_data.Class.value_counts()","65be520d":"from sklearn.utils import resample,shuffle\ndf_majority = raw_data[raw_data['Class']==0]\ndf_minority = raw_data[raw_data['Class']==1]\ndf_majority_downsampled = resample(df_majority,replace=False,n_samples=492,random_state = 123)\nbalanced_df = pd.concat([df_minority,df_majority_downsampled])\nbalanced_df = shuffle(balanced_df)\nbalanced_df.Class.value_counts()","8a2ec8c5":"sns.distplot(balanced_df.Amount,color='green');","16b96a07":"sns.boxenplot(balanced_df.Time,palette='Set1');","ed3b6cad":"balanced_df.describe()","90779d8b":"from sklearn.preprocessing import StandardScaler\n\nX = balanced_df.drop('Class',axis=1)\ny = balanced_df.Class\nscaled_X = pd.DataFrame(StandardScaler().fit_transform(X),columns=X.columns)","b155dc7e":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(scaled_X,y,test_size=0.3,shuffle=True,random_state=42)\nx_train.shape,x_test.shape","42dfe99a":"# importing classifiers\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import f1_score,accuracy_score\n\nclassifiers = {\n    'Logistic Regression' : LogisticRegression(),\n    'Decision Tree' : DecisionTreeClassifier(),\n    'Random Forest' : RandomForestClassifier(),\n    'Support Vector Machines' : SVC(),\n    'K-nearest Neighbors' : KNeighborsClassifier(),\n    'XGBoost' : XGBClassifier()\n}\nresults=pd.DataFrame(columns=['Accuracy in %','F1-score'])\nfor method,func in classifiers.items():\n    func.fit(x_train,y_train)\n    pred = func.predict(x_test)\n    results.loc[method]= [100*np.round(accuracy_score(y_test,pred),decimals=4),\n                         round(f1_score(y_test,pred),2)]\nresults","0d2368cd":"Now,we split our data into training and test set. We do this to get accuracy score on unseen data so that we are sure our model has not overfitted training set.","233292ac":"Now we apply various machine learning algorithms to separate fraud and non-fraudalent cases and compare them with help of following two measures:\n* Accuracy score is the number of correct predictions made divided by the total number of predictions made.\n* The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. The relative contribution of precision and recall to the F1 score are equal.","504b95a6":"> *Please **upvote** if you found this notebook useful!*\n\n# CREDIT CARD FRAUD DETECTION","62ca5037":"We have 492 frauds out of 284,807 transactions. Thus, the dataset is highly **unbalanced**, the positive class (frauds) account for 0.172% of all transactions.\nTo deal with unbalanced dataset, we can upsample minority class or downsample majority class. I choose to downsample majority class as upsampling will create duplicate or fake observations which can divert my model.\nDown sampling the majority class involves randomly removing observations from the majority class to prevent its signal from dominating the learning algorithm. We do it by using resample module from sklearn.","c523daf0":"**About the dataset:**\nIt is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase. The dataset contains transactions made by credit cards in September 2013 by European cardholders. This dataset presents transactions that occurred in two days. It contains only numerical input variables which are the result of a PCA transformation. The only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset.\nFeature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.","e9c50131":"All our models have accuracy above 90 and f1-score pretty close to 1.\nFor more robust models we need to have a large number of observations.","20780023":"Luckily, there are no missing values.","a6ce3323":"There is a huge difference between mean values of all the features so it would be better to standardize these.\nStandard scaler transform all the features to the same scale and center them using Gaussian distribution. This is important in k-nearest neighbor and distance based omparisons as it puts all features on the same scale before modelling.","86ea7032":"***hey hey wait.... you forgot to upvote...;)***"}}