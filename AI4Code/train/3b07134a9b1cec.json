{"cell_type":{"aea679c1":"code","1afcca56":"code","c92f839f":"code","477b2629":"code","527c4b32":"code","ae47c2bb":"code","49db76e3":"code","0861d95c":"code","3008b2f9":"code","457ee2a5":"code","d08d27bc":"code","4493143b":"code","57d79dc8":"code","99f11681":"code","cf1c49b1":"code","2cfa5c5d":"code","b0e1c566":"code","c85a5fab":"code","039751bb":"code","540acb5b":"code","534e72a4":"code","2c69d1d9":"code","33795c05":"code","59be255e":"code","a530a329":"code","b6c076c1":"code","0d2f55f1":"code","930ff1f1":"code","8bab78a6":"code","c75918fd":"code","0858dff6":"code","aa12d56e":"code","f6080a1a":"code","f86d9380":"code","e6eb9d7b":"code","11414703":"code","3c65902d":"code","60d5f604":"markdown","3d66c9cd":"markdown","97c7da09":"markdown","e5d045a3":"markdown","30c7a944":"markdown","310aedb6":"markdown"},"source":{"aea679c1":"#import dependences\nimport torch\n\nimport numpy as np \nimport pandas as pd\nimport torch.nn as nn\nimport seaborn as sns\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\n\nfrom pathlib import Path\nfrom warnings import simplefilter\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess","1afcca56":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"","c92f839f":"# plot utilities\ndef plot_predictions(y_true, y_pred, message):\n    y_train = pd.Series(y_true)\n    y_pred = pd.Series(y_pred)\n    plt.figure(figsize = (12, 7))\n    ax = y_train.plot(**plot_params, label='Real', alpha=0.5, title='Air Quality', ylabel='pm2p5')\n    ax = y_pred.plot(ax=ax, label='Predicted')\n    ax.legend()\n    plt.show()\n    print('MSE' + message + f'{mean_squared_error(y_train, y_pred)}')\n    \n    \nplot_params = dict(\n    color=\"0.75\",\n    style=\".-\",\n    markeredgecolor=\"0.25\",\n    markerfacecolor=\"0.25\",\n    legend=False,\n)","477b2629":"# read data and store it in dataframe\ndf = pd.read_csv('..\/input\/air-quality-in-milan-summer-2020\/aq_milan_summer_2020.csv')\ndf['local_datetime'] = pd.to_datetime(df['local_datetime'], format='%Y-%m-%d %H:%M:%S')\ndf['time'] = np.arange(len(df.index))\ndf.set_index('local_datetime', inplace=True)\ndf.head()\n","527c4b32":"# read extra data\ndef get_extra_features(path, old_label, new_label):\n    _df = pd.read_csv(path)\n    _df = _df.drop(columns=['Id Sensore'])\n    _df['Data-Ora'] = pd.to_datetime(_df['Data-Ora'], format='%Y-%m-%d %H:%M:%S')\n    _df.rename(columns={old_label:new_label}, inplace=True)\n    _df.set_index('Data-Ora', inplace=True)\n    return(_df)\n    \ntemperature = get_extra_features('..\/input\/meteorological-data-milan\/RW_20211201165306_465190_5920_1.csv', ' Medio', 'temperature')\nhumidity = get_extra_features('..\/input\/meteorological-data-milan\/RW_20211201165306_465190_6185_1.csv', ' Medio', 'humidity')\nrain = get_extra_features('..\/input\/meteorological-data-milan\/RW_20211201165306_465190_9341_4.csv', 'Valore Cumulato', 'rain')\nwind = get_extra_features('..\/input\/meteorological-data-milan\/RW_20211201165307_465190_19005_1.csv', ' Medio', 'wind')","ae47c2bb":"# fixing outliers from the features\ntemperature[temperature['temperature']<14.5] = 26\nhumidity[humidity['humidity']<28.9] = 64\nrain[rain['rain']<-100] = 0\nwind[wind['wind']<-100] = 1.02","49db76e3":"# merging extra features to the dataframe\ndf = df.merge(temperature, left_index=True, right_index=True)\ndf = df.merge(humidity, left_index=True, right_index=True)\ndf = df.merge(rain, left_index=True, right_index=True)\ndf = df.merge(wind, left_index=True, right_index=True)\n\ndf.head()","0861d95c":"# check if there are any null values\nprint(df.isnull().values.any())","3008b2f9":"# plot pm2p5 vs time\nplt.figure(figsize = (12, 7))\nplt.xlabel('time')\nplt.ylabel('pm2p5')\nplt.plot(df.index, df['pm2p5'])","457ee2a5":"# add lag features\ndf['lag_pm2p5'] = df['pm2p5'].shift(1)\ndf['lag_temperature'] = df['temperature'].shift(1)\ndf['lag_rain'] = df['rain'].shift(1)\ndf['lag_humidity'] = df['humidity'].shift(1)\ndf['lag_wind'] = df['wind'].shift(1)\n\n# set nan values to the average value of their columns\ndf['lag_pm2p5'].fillna(df['pm2p5'].mean(), inplace=True)\ndf['lag_temperature'].fillna(df['temperature'].mean(), inplace=True)\ndf['lag_rain'].fillna(df['rain'].mean(), inplace=True)\ndf['lag_humidity'].fillna(df['humidity'].mean(), inplace=True)\ndf['lag_wind'].fillna(df['wind'].mean(), inplace=True)\n\ndf.head()","d08d27bc":"# create time dummy \ndp = DeterministicProcess(\n    index=df.index,\n    constant=False,               # dummy feature for bias (y-intercept)\n    order=1,                     # trend (order 1 means linear)\n    seasonal=True,\n    period = 7,                  # weeklyseasonality (indicators)\n    drop=True,                   # drop terms to avoid collinearity\n)\n\n# create features for dates\nX = dp.in_sample()  \nX = X.fillna(0.0)\nX.head()","4493143b":"# merge all features in entire dataframe except non-lagged features\nX = X.merge(df.drop(columns=['pm2p5','time','temperature','humidity','rain','wind']), left_index=True, right_index=True)\nX.head()","57d79dc8":"# train and test split\nTEST_SIZE = 420\n\nX_train = X.iloc[:-TEST_SIZE].copy()\nX_test = X.iloc[-TEST_SIZE:].copy()\n\ny = df[['pm2p5']]\ny_train = y.iloc[:-TEST_SIZE]\ny_test = y.iloc[-TEST_SIZE:]","99f11681":"# normalize data\nscaler = MinMaxScaler()\n\nX_train[['lag_pm2p5', 'lag_temperature', 'lag_rain', 'lag_wind', 'lag_humidity']] = scaler.fit_transform(X_train[['lag_pm2p5', 'lag_temperature', 'lag_rain', 'lag_wind', 'lag_humidity']])\nX_test[['lag_pm2p5', 'lag_temperature', 'lag_rain', 'lag_wind', 'lag_humidity']] = scaler.transform(X_test[['lag_pm2p5', 'lag_temperature', 'lag_rain', 'lag_wind', 'lag_humidity']])\n\ny_train = scaler.fit_transform(y_train)\ny_test = scaler.transform(y_test)","cf1c49b1":"# train model\nmodel = LinearRegression().fit(X_train, y_train)","2cfa5c5d":"# forecast on train set\ny_pred = model.predict(X_train).squeeze(1)\nplot_predictions(y_train.squeeze(1), y_pred, ' Linear Regression on Train Set: ')","b0e1c566":"# forecast on test set\ny_pred = model.predict(X_test).squeeze(1)\nplot_predictions(y_test.squeeze(1), y_pred, ' Linear Regression on Test Set: ')","c85a5fab":"# train model\nmodel = GradientBoostingRegressor().fit(X_train, y_train.squeeze(1))","039751bb":"# forecast on test set\ny_pred = model.predict(X_train)\nplot_predictions(y_train.squeeze(1), y_pred, ' XGBoost on Train Set: ')","540acb5b":"# forecast on test set\ny_pred = model.predict(X_test)\nplot_predictions(y_test.squeeze(1), y_pred, ' XGBoost on Test Set: ')","534e72a4":"# define new dataframe without lag features  \ndata = df.drop(columns = ['time', 'lag_temperature', 'lag_humidity', 'lag_rain', 'lag_wind', 'lag_pm2p5'])\n# train test split\nTEST_SIZE = 420  # hours in the test set\ntrain_data = data.iloc[:-TEST_SIZE]\ntest_data = data.iloc[-TEST_SIZE:]\n# normalization\nscaler  = MinMaxScaler()\ntrain_data = scaler.fit_transform(train_data)\ntest_data = scaler.transform(test_data)","2c69d1d9":"# model class\nclass LSTMModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n        super(LSTMModel, self).__init__()\n\n        # Defining the number of layers and the nodes in each layer\n        self.hidden_dim = hidden_dim\n        self.layer_dim = layer_dim\n\n        # LSTM layers\n        self.lstm = nn.LSTM(\n            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n        )\n\n        # Fully connected layer\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        # Initializing hidden state for first input with zeros\n        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n\n        # Initializing cell state for first input with zeros\n        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_().to(device)\n\n        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n        # If we don't, we'll backprop all the way to the start even after going through another batch\n        # Forward propagation by passing in the input, hidden state, and cell state into the model\n        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n\n        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n        # so that it can fit into the fully connected layer\n        out = out[:, -1, :]\n\n        # Convert the final state to our desired output shape (batch_size, output_dim)\n        out = self.fc(out)\n\n        return out\n    \n# model optimization class\nclass Optimization:\n    def __init__(self, model, loss_fn, optimizer):\n        self.model = model\n        self.loss_fn = loss_fn\n        self.optimizer = optimizer\n        self.train_losses = []\n    \n    def train_step(self, x, y):\n        # Sets model to train mode\n        self.model.train()\n\n        # Makes predictions\n        yhat = self.model(x)\n\n        # Computes loss\n        loss = self.loss_fn(y, yhat)\n\n        # Computes gradients\n        loss.backward()\n\n        # Updates parameters and zeroes gradients\n        self.optimizer.step()\n        self.optimizer.zero_grad()\n\n        # Returns the loss\n        return loss.item()\n    \n    def train(self, train_loader, batch_size=64, n_epochs=50, n_features=1):\n\n        for epoch in range(1, n_epochs + 1):\n            batch_losses = []\n            for x_batch, y_batch in train_loader:\n                x_batch = x_batch.view([batch_size, -1, n_features]).to(device)\n                y_batch = y_batch.to(device)\n                loss = self.train_step(x_batch, y_batch)\n                batch_losses.append(loss)\n            training_loss = np.mean(batch_losses)\n            self.train_losses.append(training_loss)\n\n\n            if (epoch <= 10) | (epoch % 50 == 0):\n                print(\n                    f\"[{epoch}\/{n_epochs}] Training loss: {training_loss:.4f}\"\n                )\n\n    \n    def evaluate(self, test_loader, batch_size=1, n_features=1):\n        with torch.no_grad():\n            predictions = []\n            values = []\n            for x_test, y_test in test_loader:\n                #print(x_test)\n                x_test = x_test.view([batch_size, -1, n_features]).to(device)\n                y_test = y_test.to(device)\n                self.model.eval()\n                yhat = self.model(x_test)\n                predictions.append(yhat.detach().cpu().numpy())\n                values.append(y_test.detach().cpu().numpy())\n\n        return predictions, values","33795c05":"# constants\nHIDDEN_DIM = 50\nLAYER_DIM = 2\nBATCH_SIZE = 64\nDROPOUT = 0.2\nN_EPOCHS = 50\nLEARNING_RATE = 1e-2\nWEIGHT_DECAY = 1e-6","59be255e":"# create sequences of length n_steps\ndef sampling(sequence, n_steps):\n    X, Y = list(), list()\n    for i in range(len(sequence)):\n        sam = i + n_steps\n        if sam > len(sequence)-1:\n            break\n        x, y = sequence[i:sam], sequence[sam, 0]\n        X.append(x)\n        Y.append(y)\n    return np.array(X), np.array(Y)\n\nN_STEPS = 7  # number of hours used to make a single hour prediction\nX_train, y_train = sampling(train_data, N_STEPS)\nX_test, y_test = sampling(test_data, N_STEPS)","a530a329":"# constants\nINPUT_DIM = 5\nOUTPUT_DIM = 1","b6c076c1":"# create dataset and dataloader for train and test sets\ntrain_features = torch.Tensor(np.array(X_train))\ntrain_targets = torch.Tensor(np.array(y_train)).unsqueeze(1)\n\ntest_features = torch.Tensor(np.array(X_test))\ntest_targets = torch.Tensor(np.array(y_test)).unsqueeze(1)\n\ntrain = TensorDataset(train_features, train_targets)\ntest = TensorDataset(test_features, test_targets)\n\ntrain_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\ntest_loader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n\ntrain_loader_one = DataLoader(train, batch_size=1, shuffle=False, drop_last=True)\ntest_loader_one = DataLoader(test, batch_size=1, shuffle=False, drop_last=True)","0d2f55f1":"# initialize model\nmodel_params = {'input_dim': INPUT_DIM,\n                'hidden_dim' : HIDDEN_DIM,\n                'layer_dim' : LAYER_DIM,\n                'output_dim' : OUTPUT_DIM,\n                'dropout_prob' : DROPOUT}\nmodel = LSTMModel(**model_params)\nmodel.to(device)\n\n# define loss and optimizer\nloss_fn = nn.MSELoss(reduction=\"mean\")\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n\n#train model\nopt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\nopt.train(train_loader, batch_size=BATCH_SIZE, n_epochs=N_EPOCHS, n_features=INPUT_DIM)","930ff1f1":"# forecast on train set\npredictions, values = opt.evaluate(train_loader_one, batch_size=1, n_features=INPUT_DIM)\ny_pred = pd.Series(np.concatenate(predictions).ravel().tolist())\ny_train = pd.Series(np.concatenate(values).ravel().tolist())\nplot_predictions(y_train, y_pred, ' LSTM Single Hour on Train Set: ')","8bab78a6":"# forecast on test set\npredictions, values = opt.evaluate(test_loader_one, batch_size=1, n_features=INPUT_DIM)\ny_pred = pd.Series(np.concatenate(predictions).ravel().tolist())\ny_test = pd.Series(y_test)\nplot_predictions(y_test, y_pred, ' LSTM Single Hour on Test Set: ')","c75918fd":"def sampling_multi(sequence, n_steps, m_steps):\n    X, Y = list(), list()\n    for i in range(len(sequence)):\n        sam = i + n_steps\n        t_sam = sam + m_steps # target sampling\n        if sam > len(sequence)-1 or t_sam > len(sequence)-1:\n            break\n        x, y = sequence[i:sam], sequence[sam:t_sam, 0]\n        X.append(x)\n        Y.append(y)\n    return np.array(X), np.array(Y)\n\nM_STEPS = 12  # number of sequence will be predicted\nN_STEPS = 24  # number of hours used to make a single hour prediction\nX_train, y_train = sampling_multi(train_data, N_STEPS, M_STEPS)\nX_test, y_test = sampling_multi(test_data, N_STEPS, M_STEPS)","0858dff6":"# constants\nINPUT_DIM = 5\nOUTPUT_DIM = M_STEPS","aa12d56e":"# create dataset and dataloader for train and test sets\ntrain_features = torch.Tensor(np.array(X_train))\ntrain_targets = torch.Tensor(np.array(y_train))\n\ntest_features = torch.Tensor(np.array(X_test))\ntest_targets = torch.Tensor(np.array(y_test))\n\ntrain = TensorDataset(train_features, train_targets)\ntest = TensorDataset(test_features, test_targets)\n\ntrain_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\ntest_loader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n\ntrain_loader_one = DataLoader(train, batch_size=1, shuffle=False, drop_last=True)\ntest_loader_one = DataLoader(test, batch_size=1, shuffle=False, drop_last=True)","f6080a1a":"# initialize model\nmodel_params = {'input_dim': INPUT_DIM,\n                'hidden_dim' : HIDDEN_DIM,\n                'layer_dim' : LAYER_DIM,\n                'output_dim' : OUTPUT_DIM,\n                'dropout_prob' : DROPOUT}\nmodel = LSTMModel(**model_params)\nmodel.to(device)\n\n# define loss and optimizer\nloss_fn = nn.MSELoss(reduction=\"mean\")\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n\n#train model\nopt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\nopt.train(train_loader, batch_size=BATCH_SIZE, n_epochs=N_EPOCHS, n_features=INPUT_DIM)","f86d9380":"# forecast on sequences of train set\npredictions, values = opt.evaluate(train_loader_one, batch_size=1, n_features=INPUT_DIM)\ny_pred = np.array(predictions).squeeze(1)\ny_train = np.array(values).squeeze(1)\nfig, axs = plt.subplots(nrows=3, ncols=2, figsize=(12,8), sharex=True)\nplt.setp(axs, ylim=(0., 1.))\nfor n, ax in enumerate(axs.flatten()):\n    ax.plot(range(len(y_pred[n * 10])), y_pred[n * 10], label = 'Predicted')\n    ax.plot(range(len(y_train[n * 10])), y_train[n * 10], label = 'Real')\n    ticks = [n % 4 == 0, n > 12]\n    ax.tick_params(left=ticks[0], bottom=ticks[1])\nax.legend()\nplt.suptitle('Air Quality LSTM Multi-Hour on Train', y = 0.95)\nplt.subplots_adjust(wspace=0.2)\nplt.show()","e6eb9d7b":"#forecast on entire train set\ny_pred = np.array([predictions[i*M_STEPS] for i in range(int(len(predictions)\/M_STEPS))]).flatten()\ny_train = np.array([values[i*M_STEPS] for i in range(int(len(values)\/M_STEPS))]).flatten()\nplot_predictions(y_train, y_pred, ' LSTM Multi-Hour on Train: ')","11414703":"# forecast on sequences of test set\npredictions, values = opt.evaluate(test_loader_one, batch_size=1, n_features=INPUT_DIM)\ny_pred = np.array(predictions).squeeze(1)\ny_test = np.array(values).squeeze(1)\nfig, axs = plt.subplots(nrows=3, ncols=2, figsize=(12,8), sharex=True)\nplt.setp(axs, ylim=(0., 1.))\nfor n, ax in enumerate(axs.flatten()):\n    ax.plot(range(len(y_pred[n * 10])), y_pred[n * 10], label = 'Predicted')\n    ax.plot(range(len(y_test[n * 10])), y_test[n * 10], label = 'Real')\n    ticks = [n % 4 == 0, n > 12]\n    ax.tick_params(left=ticks[0], bottom=ticks[1])\nax.legend()\nplt.suptitle('Air Quality LSTM Multi-Hour on Test', y = 0.95)\nplt.subplots_adjust(wspace=0.2)\nplt.show()","3c65902d":"#forecast on entire test set\ny_pred = np.array([predictions[i*M_STEPS] for i in range(int(len(predictions)\/M_STEPS))]).flatten()\ny_test = np.array([values[i*M_STEPS] for i in range(int(len(values)\/M_STEPS))]).flatten()\nplot_predictions(y_test, y_pred, ' LSTM Multi-Hour on Test: ')","60d5f604":"* **Multi-hour predictions**","3d66c9cd":"**Linear regression**","97c7da09":"* **Single hour prediction**","e5d045a3":"**XGBoost**","30c7a944":"**LSTM**","310aedb6":"**Data visualization**"}}