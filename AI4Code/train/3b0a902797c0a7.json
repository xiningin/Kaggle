{"cell_type":{"6c5c247a":"code","239f4ec7":"code","931027ca":"code","586ebc5b":"code","c3ed5284":"code","770f5e6e":"code","1d0cdea7":"code","3b69761e":"code","bcf7effb":"code","ed0cf017":"code","81a44c0d":"code","3850278f":"code","c5344946":"code","e852243b":"code","17e3fb9b":"code","c1a153d3":"code","0516abaa":"code","df627860":"code","b9d1e47c":"code","94acc667":"code","194039a3":"code","86a07710":"code","42899828":"code","c7c29558":"code","e73a6b20":"code","67a332f4":"code","ab380ea7":"code","2af56fdc":"code","fab4c273":"code","16a10892":"code","ab8e11c3":"code","b216cc21":"code","42ad0aec":"code","8e8d2b13":"code","185be2fa":"code","bc989f9d":"code","b664c06e":"code","dc45b825":"code","55f6b11e":"code","a56526a3":"code","fbdb9735":"markdown","64c56811":"markdown","28c7322e":"markdown","a906d93e":"markdown","5b9dabd4":"markdown","2930beee":"markdown","6326a67d":"markdown","ad48d027":"markdown","d306393d":"markdown","5a54134e":"markdown","6e4b9ac3":"markdown","438067e6":"markdown","447c40ef":"markdown","0e7374af":"markdown","14d6e3a8":"markdown","0d8cb0c4":"markdown","d6d4ce0f":"markdown","d4b27c9c":"markdown"},"source":{"6c5c247a":"import pandas as pd","239f4ec7":"df = pd.read_csv('..\/input\/vehicle-images-dataset\/vehcle_img_data.csv', low_memory=False)\ndf.shape","931027ca":"df.isna().sum()","586ebc5b":"df = df[~df.Image_Path.isnull()]","c3ed5284":"import matplotlib.pyplot as plt","770f5e6e":"df.Brand.value_counts().plot(kind='bar', figsize=(23, 3))\n# commenting the plot \nplt.title(\"Cars brend\")\nplt.xlabel(\"Brend name\")\nplt.ylabel(\"Count\"); ","1d0cdea7":"N = 4\ntop_NBrands = df.Brand.value_counts()[:N].index\ntop_NBrands","3b69761e":"df_NB = df[df.Brand.isin(top_NBrands)] ","bcf7effb":"df_NB.Image_Path = '..\/input\/vehicle-images-dataset\/vehicle_images\/' + df_NB.Image_Path.str.replace('.\/','', regex=False)\ndf_NB.Image_Path","ed0cf017":"import os\nx = os.listdir('..\/input\/vehicle-images-dataset\/vehicle_images\/vehicle_images\/')\nlen(x)","81a44c0d":"x[0]","3850278f":"t = list(df_NB.Image_Path.str.replace('..\/input\/vehicle-images-dataset\/vehicle_images\/vehicle_images\/','', regex=False))\n","c5344946":"no_image = []\nfor index, image in enumerate(t):\n    if image not in x:\n        no_image.append(index)","e852243b":"no_image","17e3fb9b":"df_NB.drop(df_NB.iloc[no_image, :].index, axis=0, inplace=True);","c1a153d3":"df_NB.shape","0516abaa":"X = df_NB.Image_Path\ny = df_NB.Brand","df627860":"X.shape, y.shape","b9d1e47c":"from IPython.display import display, Image","94acc667":"print(y[4])\nImage(X[4]) ","194039a3":"def simple_transformer(column):\n    \"\"\"\n    this transformer will convert any giving categoricol column to numerical.\n    \"\"\"\n    # all unique values for column \n    names = column.value_counts().index\n    # how size of them\n    size = len(names)\n    # create dict value:name \/ ex: {1:'category 1'}... \n    replacement = dict(zip(names, range(size)))\n    # aplly the changes\n    column.replace(replacement, inplace=True)\n    return replacement","86a07710":"simple_transformer(y)","42899828":"y.head()","c7c29558":"from sklearn.model_selection import train_test_split\n\n# creating test and train data\nX_train, X_test, y_train, y_test = train_test_split(X,\n                                                  y, \n                                                  test_size=0.2,\n                                                  random_state=42, shuffle=True, stratify=y)","e73a6b20":"# create validation data from train\nX_train, X_val, y_train, y_val = train_test_split(X_train,\n                                                  y_train, \n                                                  test_size=0.2,\n                                                  random_state=42, shuffle=True, stratify=y_train)","67a332f4":"import tensorflow as tf","ab380ea7":"# Check GPU \nprint(\"GPU available\" if tf.config.list_physical_devices(\"GPU\") else \"not available\");","2af56fdc":"# image size\nIMG_SIZE = 220\n\ndef process_image(image_path):\n    \"\"\"\n    Convert an image file path and turns it into a Tensor.\n    \"\"\"\n    # Read an image from path\n    image = tf.io.read_file(image_path)\n    # Decode the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n    image = tf.image.decode_jpeg(image, channels=3)\n    # Convert the colour channel values from 0-225 to 0-1 values\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    # Resize the image to our desired size IMG_SIZE\n    image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n    return image","fab4c273":"# function to return a tuple (image, label)\ndef get_image_label(image_path, label):\n    \"\"\"\n    Takes an image file path name and the associated label,\n    processes the image and returns a tuple of (image, label).\n    \"\"\"\n    image = process_image(image_path)\n    return image, label","16a10892":"import numpy as np","ab8e11c3":"# batch size of 32 is a good default\nBATCH_SIZE = 256\n\n# function to turn data into batches\ndef create_data_batches(x, y, batch_size=BATCH_SIZE):\n    \"\"\"\n    Creates batches of data out of image (x) and label (y) pairs.\n    \"\"\"\n    print(\"Creating data batches...\")\n    # Turn filepaths and labels into Tensors\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n                                               tf.constant(y))) # labels  \n    # Create (image, label) tuples (this also turns the image path into a preprocessed image)\n    data = data.map(get_image_label)\n    # Turn the data into batches\n    \n    data_batch = data.batch(BATCH_SIZE)\n    return data_batch","b216cc21":"# Create training and validation data batches\ntrain_data = create_data_batches(X_train, y_train)\nval_data = create_data_batches(X_val, y_val)\n# train_ds = train_ds.prefetch(buffer_size=32)\n# val_ds = val_ds.prefetch(buffer_size=32)","42ad0aec":"from tensorflow.keras import layers, models","8e8d2b13":"def create_model():\n    \"\"\"\n    Function to build the model.    \n    \"\"\"\n    # building the model\n    data_augmentation = tf.keras.models.Sequential([\n        layers.RandomFlip(\"horizontal\", input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n        layers.RandomRotation(0.1),\n        layers.RandomZoom(0.1)])\n    \n    model = models.Sequential([\n                data_augmentation,\n        \n                layers.Conv2D(32, 5, padding='same', activation='relu'),\n                layers.MaxPooling2D(),\n        \n                layers.Conv2D(32, 5, padding='same', activation='relu'),\n                layers.MaxPooling2D(),\n        \n                layers.Conv2D(64, 3, padding='same', activation='relu'),\n                layers.MaxPooling2D(),\n\n                layers.Conv2D(64, 3, padding='same', activation='relu'),\n                layers.MaxPooling2D(),\n        \n                layers.Conv2D(64, 3, padding='same', activation='relu'),\n                layers.MaxPooling2D(),\n                 \n                layers.Flatten(),\n                layers.Dense(512, activation='relu'),\n                        \n                layers.Dense(N, activation='softmax')])\n    \n    model.compile(optimizer= tf.keras.optimizers.Adam(),\n                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                  metrics=['accuracy'])\n\n    return model\n\n# Creating our model \nmodel = create_model()\nmodel.summary()","185be2fa":"from tensorflow import keras","bc989f9d":"# Create early stopping (callback function) (once our model stops improving, stop training)\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n                                                  patience=10) # stops after 3 rounds of no improvements\n# number of epochs\nNUM_EPOCHS = 100\n\n# function to train and return a trained model\ndef train_model():\n    \"\"\"\n    Trains a given model and returns the trained version.\n    \"\"\"\n    # Create a model\n    model = create_model()\n\n    history = model.fit(\n        train_data,\n        epochs=NUM_EPOCHS,\n        validation_data=val_data,\n        callbacks= [early_stopping])\n  \n    return model, history\n\n# Fit the model to the data\nmodel, history = train_model()","b664c06e":"import matplotlib.pyplot as plt","dc45b825":"plt.plot(history.history['accuracy'], label='Train Acc')\nplt.plot(history.history['val_accuracy'], label='Val Acc')\nplt.xlabel('Number Of Epochs')\nplt.ylabel('Accuracy %')\nplt.title('Accuracy Evaluation')\nplt.legend()\nplt.show()","55f6b11e":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Loss Evaluation')\nplt.ylabel('Loss %')\nplt.xlabel('Number Of Epochs')\nplt.legend(['Train Loss', 'Val Loss'], loc='lower left')\nplt.show()","a56526a3":"# model accuracy on test data\ntest_data = create_data_batches(X_test, y_test)\nmodel.evaluate(test_data)","fbdb9735":"## Cheking na values","64c56811":"## Data Engineering","28c7322e":"### Cheking for non existing paths","a906d93e":"## Summarize history for loss\n","5b9dabd4":"## Accuracy Evaluation\n","2930beee":"## Features \/ Target","6326a67d":"#### ","ad48d027":"## Loading Data","d306393d":"## Visualisation","5a54134e":"### Fixing paths","6e4b9ac3":"## Modeling","438067e6":"### Consediring only top N brends","447c40ef":"## Imports","0e7374af":"### Deleting the non existing images","14d6e3a8":"#### we have two null paths","0d8cb0c4":"### showing an image simple\n ","d6d4ce0f":"#### indexs of paths ","d4b27c9c":"## Evaluating on test data"}}