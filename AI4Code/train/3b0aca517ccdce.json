{"cell_type":{"21d16421":"code","ade1295d":"code","c5f0b216":"code","4ba14dfc":"code","a53c2691":"code","0b02a919":"code","13d32a8c":"code","b71232bf":"code","b29a0772":"code","eac7ff5e":"code","9ba71b83":"code","789aa972":"code","37a3be85":"code","f403f0e1":"code","71ba6ae8":"code","b92b9c9d":"code","69a3ac04":"code","fd86548f":"code","ca949c0a":"code","88e3cba5":"code","7d872884":"code","65554490":"code","13d411e8":"code","9a5c2e35":"code","0c15f7f7":"code","e6cecca4":"code","9d8189da":"code","fe9e6eb6":"code","1d9ab1c7":"markdown"},"source":{"21d16421":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ade1295d":"from keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Dropout, Flatten\nfrom keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.preprocessing import image\nfrom keras.callbacks import ModelCheckpoint\nimport os\nimport numpy as np\nimport numpy as np\nfrom PIL import Image\nfrom math import floor\nimport numpy as np\nimport time\nfrom functools import partial\nfrom random import random\nfrom pandas import Series, DataFrame\nimport pandas as pd\nimport seaborn as sns\nimport pickle\nfrom keras.optimizers import SGD\nimport cv2\nimport os\nimport keras\nfrom keras import layers\nfrom sklearn.preprocessing import LabelBinarizer\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation, Flatten, Dropout, Dense\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.densenet import DenseNet201\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.vgg19 import VGG19, preprocess_input\nfrom keras.applications import InceptionResNetV2\nfrom keras.applications.densenet import DenseNet201\nfrom keras.applications import MobileNetV2\nfrom keras.models import Model\nfrom keras.layers import Dropout\nfrom keras.models import Model,Sequential\nfrom keras.layers import Input,MaxPooling2D,concatenate,Dense,Flatten\nfrom keras.layers.core import Activation, Reshape\nfrom keras.layers.convolutional import Convolution2D\nfrom keras.layers.normalization import BatchNormalization\n#from tensorflow.python.keras.layers import Dense\n#from random_eraser import get_random_eraser\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.layers import Activation,Conv2D,Flatten,SeparableConv2D,Dense,Input,Dropout,BatchNormalization,GlobalMaxPooling2D,GlobalAveragePooling2D,MaxPooling2D,AveragePooling2D","c5f0b216":"os.listdir('..\/input\/')\ndirectory_root = '..\/input\/'\ntest_dir='..\/input\/testdata\/'\nbatch_size=32\ntrain_data_dir='..\/input\/dancedata\/Train Images\/'\n#train_data_dir='..\/input\/newdata\/stage 02\/'\nnum_classes=2","4ba14dfc":"train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,validation_split=0.2)\n\n#test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)","a53c2691":"train_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    batch_size=batch_size,\n    target_size=(224,224),\n    class_mode='categorical',\n    subset='training') # set as training data\ntrain_generator.class_indices","0b02a919":"validation_generator = train_datagen.flow_from_directory(\n    train_data_dir, # same directory as training data\n    batch_size=batch_size,\n    target_size=(224,224),\n    class_mode='categorical',\n    subset='validation')","13d32a8c":"test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\ntest_generator = test_datagen.flow_from_directory(\n    test_dir, # same directory as training data\n    batch_size=batch_size,\n    target_size=(224,224),\n    class_mode='categorical')","b71232bf":"#mobilenetsv2\nbase_model=MobileNetV2(weights='imagenet',include_top=False)\nx=base_model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\nx=Dropout(0.1)(x)\nx=Dense(1024,activation='relu')(x) #dense layer 2\nx=Dropout(0.1)(x)\nx=Dense(512,activation='relu')(x) #dense layer 3\n#preds=Dense(2,activation='sigmoid')(x) #final layer with softmax activation\npreds=Dense(8,activation='softmax')(x)\nmodel=Model(inputs=base_model.input,outputs=preds)\n\nfor layer in model.layers:\n    layer.trainable=False\n# or if we want to set the first 20 layers of the network to be non-trainable\nfor layer in model.layers[:20]:\n    layer.trainable=False\nfor layer in model.layers[20:]:\n    layer.trainable=True","b29a0772":"#mobilenetsv2\nbase_model=MobileNetV2(weights='imagenet',include_top=False,input_shape=(224,224,3))\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2, activation='sigmoid'))\nbase_model.trainable=False","eac7ff5e":"#VGG16\nmodel = Sequential()\nbase_model=VGG16(include_top=False,weights='imagenet',input_shape=(224,224,3))\n\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(8, activation='softmax'))\nbase_model.trainable=False\n#model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n","9ba71b83":"#inceptionv3\nnclass=8\nimport os\nfrom keras import layers\nfrom keras import Model\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.optimizers import RMSprop\n\n# local_weights_file = '\/kaggle\/input\/inceptionv3\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\npre_trained_model = InceptionV3(input_shape = (224,224, 3), \n                                include_top = False, \n                                weights = \"imagenet\")\n\n# pre_trained_model.load_weights(local_weights_file)\n\nfor layer in pre_trained_model.layers:\n     layer.trainable = False\n        \n# pre_trained_model.summary()\nlast_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n\nx = layers.Flatten()(last_output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense(8, activation='softmax')(x)           \n\nmodel = Model(pre_trained_model.input, x) \nmodel.summary()\n#model.compile(optimizer = RMSprop(lr=0.0001),loss = 'sparse_categorical_crossentropy',metrics = ['acc'])\n#model.summary()\n#history=model.fit(x_train,y_train,epochs=1,validation_data=(x_test,y_test))\n\n\n#base_model = InceptionV3(weights='imagenet', include_top=False)\n#base_model.trainable = False\n#model = Sequential()\n#model.add(base_model)\n#model.add(GlobalAveragePooling2D())\n#model.add(Dropout(0.5))\n#model.add(Dense(nclass, activation='softmax'))\n\n#model.compile(loss='categorical_crossentropy',optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),metrics=['accuracy'])","789aa972":"base_model = InceptionV3(weights='imagenet', include_top=False, input_shape = (224,224, 3))\nbase_model.trainable = False\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(layers.Dense(8, activation='softmax'))\n\n# we chose to train the top 2 inception blocks, i.e. we will freeze\n# the first 249 layers and unfreeze the rest:\n\n#model.compile(loss='categorical_crossentropy',optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),metrics=['accuracy'])","37a3be85":"#resnet50\nnum_classes=8\nbase_model = Sequential()\nbase_model.add(ResNet50(include_top=False, pooling='avg', weights='imagenet')) \t# entire resnet model is the first layer!\nbase_model.add(Dense(num_classes, activation='softmax'))\nbase_model.layers[0].trainable = False\n#base_model.summary()\n#base_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n#achieved acc of- ","f403f0e1":"#resnet50\nmodel = ResNet50(weights='imagenet',include_top=False)\nmodel.summary()\nlast_layer = model.output\n# add a global spatial average pooling layer\nx = GlobalAveragePooling2D()(last_layer)\n# add fully-connected & dropout layers\nx = Dense(512, activation='relu',name='fc-1')(x)\nx = Dropout(0.5)(x)\nx = Dense(256, activation='relu',name='fc-2')(x)\nx = Dropout(0.5)(x)\n# a softmax layer for 4 classes\nout = Dense(num_classes, activation='softmax',name='output_layer')(x)\n\n# this is the model we will train\ncustom_resnet_model2 = Model(inputs=model.input, outputs=out)\n\ncustom_resnet_model2.summary()\n\nfor layer in custom_resnet_model2.layers[:-6]:\n\tlayer.trainable = False\n\ncustom_resnet_model2.layers[-1].trainable\n\ncustom_resnet_model2.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","71ba6ae8":"from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\nreduce_learning_rate = ReduceLROnPlateau(monitor='loss',\n                                         factor=0.1,\n                                         patience=2,\n                                         cooldown=2,\n                                         min_lr=0.00001,\n                                         verbose=1)\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)\nes1 = EarlyStopping(monitor='accuracy', mode='max', verbose=1,patience=15)\ncallbacks_list = [es,reduce_learning_rate,es1]","b92b9c9d":"model=base_model\nINIT_LR = 1e-3\n#opt = Adam(lr=INIT_LR, decay=INIT_LR \/ 50)\n#opt='rmsprop'\n#opt='adam'\n#opt=SGD(lr=1e-4, momentum=0.9)\n#opt = SGD(lr=0.001, momentum=0.9)\nopt = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n#opt=Adam()\n# distribution\nmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n#model.compile(optimizer=opt, loss='binary_crossentropy',  metrics=['accuracy'])\n# train the network\n\nprint(\"[INFO] training network...\")","69a3ac04":"model=base_model\nhistory=model.fit_generator(\n    train_generator,\n    steps_per_epoch = train_generator.samples \/\/ batch_size,\n    validation_data = validation_generator, \n    validation_steps = validation_generator.samples \/\/ batch_size,\n    epochs = 30,shuffle=True,\n    #callbacks=callbacks_list\n    )","fd86548f":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","ca949c0a":"from keras.models import model_from_json\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")    ","88e3cba5":"from IPython.display import FileLink\nFileLink(r'model.h5')","7d872884":"#evaluate_model\n#STEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID=validation_generator.n\/\/validation_generator.batch_size\n#STEP_SIZE_TEST=test_generator.n\/\/test_generator.batch_size\nmodel.evaluate_generator(generator=validation_generator,\nsteps=STEP_SIZE_VALID)","65554490":"#STEP_SIZE_TEST=test_generator.n\/\/test_generator.batch_size +1\nSTEP_SIZE_VALID=validation_generator.n\/\/validation_generator.batch_size +1\n#test_generator.reset()\ny_pred = model.predict_generator(validation_generator, steps=STEP_SIZE_VALID,\nverbose=1)\ny_true=validation_generator.classes\n#print(len(y_true))\n#print(y_true)","13d411e8":"#train_data_prediction\nSTEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size +1\n#test_generator.reset()\ny_pred = model.predict_generator(train_generator, steps=STEP_SIZE_TRAIN,\nverbose=1)\ny_true=train_generator.classes\n#print(len(y_true))\n#print(y_true)\npredicted_class_indices=np.argmax(y_pred,axis=1)\nprint(predicted_class_indices)\nprint(len(predicted_class_indices))\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]","9a5c2e35":"#validation_data_prediction\nSTEP_SIZE_VALID=validation_generator.n\/\/validation_generator.batch_size +1\n#test_generator.reset()\ny_pred = model.predict_generator(validation_generator, steps=STEP_SIZE_VALID,\nverbose=1)\ny_true=validation_generator.classes\n#print(len(y_true))\n#print(y_true)\npredicted_class_indices=np.argmax(y_pred,axis=1)\nprint(predicted_class_indices)\nprint(len(predicted_class_indices))\nlabels = (validation_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]","0c15f7f7":"#test_data_prediction\nSTEP_SIZE_TEST=test_generator.n\/\/test_generator.batch_size +1\n#test_generator.reset()\ny_pred = model.predict_generator(test_generator, steps=STEP_SIZE_TEST,verbose=1)\n#y_true=test_generator.classes\n#print(len(y_true))\n#print(y_true)\npredicted_class_indices=np.argmax(y_pred,axis=1)\nprint(predicted_class_indices)\nprint(len(predicted_class_indices))\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]","e6cecca4":"from sklearn.metrics import confusion_matrix \nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report \ntn, fp, fn, tp=confusion_matrix(y_true, predicted_class_indices).ravel()\nprint(confusion_matrix(y_true, predicted_class_indices))\nprint((tp+tn)\/(tp+tn+fp+fn))\nprint('tn, fp, fn, tp')\nprint((tn, fp, fn, tp))","9d8189da":"import pandas as pd\nfilenames=test_generator.filenames\ny=[]\n#print(len(filenames))\nfor i in range(len(filenames)):\n    a,b=filenames[i].split('\/')\n    y.append(b)\n#print(y)\nresults=pd.DataFrame({\"Image\":y,\n                      \"target\":predictions})\nresults.to_csv(\"results.csv\",index=False)","fe9e6eb6":"from IPython.display import FileLink\nFileLink(r'results.csv')","1d9ab1c7":"Evaluating model"}}