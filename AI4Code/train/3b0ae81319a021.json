{"cell_type":{"8ab8ab83":"code","cb82f1bf":"code","bfe5e2c6":"code","8b72d030":"code","f7478cc9":"code","0462a9c0":"code","8707f51b":"code","69c28b05":"code","a6899eb8":"code","16ddf97d":"code","cb83101c":"code","d140131f":"code","0e111a9c":"code","0ba514bc":"code","889c683d":"code","f6f7233c":"code","043f8695":"code","f71a2e14":"code","2969159a":"code","34e7c2d7":"code","565226dc":"code","4d4e5097":"code","d473da84":"code","b4c17fd3":"code","77962ae0":"code","3b603aff":"code","1b4a3850":"code","4098ee02":"code","73787c9b":"code","88d9d085":"code","3bcf8555":"code","981a6f9e":"code","24ebf728":"code","b90dba57":"code","7f3c73a3":"code","e5026bd0":"code","bbe03c94":"code","8db0a6cb":"code","b8fd72b8":"code","f70fb014":"code","66357871":"code","602f3752":"code","88b9533e":"code","7926c53e":"code","6e880926":"code","410913a9":"code","f9d5626f":"code","fc8721fa":"code","cd0c1d31":"code","bf2450bc":"code","5c58c459":"code","7f7ce019":"code","836d34d1":"code","2a7bb602":"code","ce61ff70":"code","1464bf77":"code","a9d0943e":"code","2cbae281":"code","99ba51e8":"code","7c804bc1":"code","92cbd848":"code","e9f2659f":"code","34c82860":"markdown","62b35816":"markdown","25b35308":"markdown","98d4d263":"markdown","e129e27e":"markdown","979cb865":"markdown","09886e6f":"markdown","b328fb41":"markdown","e0084cdd":"markdown","f2524a07":"markdown","d425bc17":"markdown","beca6de3":"markdown","c7bc629c":"markdown","fed398b4":"markdown","025ff42b":"markdown","3362b074":"markdown","33bbd40c":"markdown","000897ea":"markdown","9ad96386":"markdown","e9d27117":"markdown","55ac6337":"markdown","8f5f920b":"markdown","b9f2fba9":"markdown","23559054":"markdown","b03ad323":"markdown","a4afeeca":"markdown","737db41c":"markdown"},"source":{"8ab8ab83":"%matplotlib inline\nimport pandas as pd\nimport dask.dataframe as dd\nfrom dask_ml.preprocessing import DummyEncoder\nimport numpy as np\nimport altair as alt\nimport seaborn as sns\nimport math\n\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\nfrom sklearn import metrics\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.cluster import KMeans\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import svm\n\n\nplt.style.use('ggplot')","cb82f1bf":"# 878049 rows x 9 columns\ndata = pd.read_csv('..\/input\/crimetrain\/crimetrain.csv', parse_dates=[\"Dates\"])\n# train = pd.read_csv('crimetrain.csv')\ndata.head()","bfe5e2c6":"data.info()","8b72d030":"print(\"Num of Categories: \", data['Category'].nunique())\nprint(\"Num of Descripts: \", data['Descript'].nunique())","f7478cc9":"data.Resolution.unique()","0462a9c0":"encodeddata = pd.read_csv('..\/input\/crimetrain\/crimetrain.csv')\nlabelencoder = LabelEncoder()\nfor col in encodeddata.columns:\n    encodeddata[col] = labelencoder.fit_transform(encodeddata[col])","8707f51b":"plt.figure(figsize = (16,5))\nax = sns.heatmap(encodeddata.corr(), annot=True)","69c28b05":"data = pd.read_csv('..\/input\/crimetrain\/crimetrain.csv', parse_dates=['Dates'])","a6899eb8":"popcrime = data.groupby('Category').count().reset_index()\npopcrime = popcrime.drop(['Dates', 'Descript', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X'], axis=1)\npopcrime = popcrime.rename(columns={'Y':'count'}).sort_values(by='count', ascending=False)\npopcrime.plot.bar(x='Category', y='count', figsize=(15, 8))\nplt.ylabel(\"count\")","16ddf97d":"dangerous = data.groupby('PdDistrict').count().reset_index()\ndangerous = dangerous.drop(['Dates', 'Category', 'Descript', 'DayOfWeek', 'Resolution', 'Address', 'X'], axis=1)\ndangerous = dangerous.rename(columns={'Y':'num_of_crimes'}).sort_values(by='num_of_crimes', ascending=False)\ndangerous.plot.bar(x='PdDistrict', y='num_of_crimes', figsize=(10, 5))\nplt.ylabel('Number of Crimes')","cb83101c":"# cpddist = data.groupby(['Category', 'PdDistrict']).count().reset_index()\n# for category in cpddist['Category'].unique():\n#     ddata = cpddist[cpddist['Category'] == category]\n#     ddata.plot.bar(x='PdDistrict', y='Dates') # doesn't matter which, just looking at count\n#     plt.xlabel(category)\n#     plt.ylabel('Count')","d140131f":"data.head()","0e111a9c":"# adding a total column\nperct = pd.crosstab([data.Category], data.PdDistrict).reset_index()\nperct['total'] = perct.sum(axis=1)\n\n# calculating percent for each row        \nfor district in data.PdDistrict.unique():\n    perct[district+'%'] = perct.apply(lambda perct: perct[district]\/perct.total*100, axis=1)\n\n# dropping unncessary columns\nperct = perct.drop(['BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN', 'total'], axis=1)\nperct.head()","0ba514bc":"perct.plot.bar(x='Category', y=['NORTHERN%', 'PARK%', 'INGLESIDE%', 'BAYVIEW%', 'RICHMOND%', 'CENTRAL%', 'TARAVAL%', 'TENDERLOIN%', 'MISSION%', 'SOUTHERN%'], stacked=True, figsize=(21,10))\nplt.ylabel('% of PdDistrict')","889c683d":"perct.plot.bar(x='Category', y=['NORTHERN%', 'PARK%', 'INGLESIDE%', 'BAYVIEW%', 'RICHMOND%', 'CENTRAL%', 'TARAVAL%', 'TENDERLOIN%', 'MISSION%', 'SOUTHERN%'], figsize=(21,10))\nplt.ylabel('% of PdDistrict')","f6f7233c":"# what district is the hightest for prostitution? --it's hard to tell looking at the graph so let's pull up the table\np = data[data['Category'] == 'PROSTITUTION'].groupby(['Category', 'PdDistrict']).count().reset_index().sort_values(by='Dates', ascending=False)\np = p.drop(['Dates', 'Descript', 'DayOfWeek', 'Resolution', 'Address', 'X'], axis=1)\np = p.rename(columns={'Y':'count'}).sort_values(by='count', ascending=False)\np","043f8695":"descript = data.groupby(['Category', 'Descript']).count().reset_index()\ndescript = descript.drop(['Dates', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X'], axis=1)\ndescript = descript.rename(columns={'Y':'count'}).sort_values(by='count', ascending=False)\ndescript.head(n=10)","f71a2e14":"timedata = pd.read_csv('..\/input\/crimetrain\/crimetrain.csv', parse_dates=['Dates'])","2969159a":"timedata['Dates_year'] = timedata['Dates'].dt.year\ntimedata['Dates_month'] = timedata['Dates'].dt.month\ntimedata['Dates_day'] = timedata['Dates'].dt.day\ntimedata['Dates_hour'] = timedata['Dates'].dt.hour\n\nfig, ((axis1,axis2),(axis3,axis4)) = plt.subplots(nrows=2, ncols=2)\nfig.set_size_inches(18,6)\n\nsns.countplot(data=timedata, x='Dates_year', ax=axis1)\nsns.countplot(data=timedata, x='Dates_month', ax=axis2)\nsns.countplot(data=timedata, x='Dates_day', ax=axis3)\nsns.countplot(data=timedata, x='Dates_hour', ax=axis4)","34e7c2d7":"# cpddist = data.groupby(['Category', 'DayOfWeek']).count().reset_index()\n# for category in cpddist['Category'].unique():\n#     ddata = cpddist[cpddist['Category'] == category]\n#     ddata.plot.bar(x='DayOfWeek', y='Dates')\n#     plt.xlabel(category)\n#     plt.ylabel('Count')","565226dc":"timedata['Dates_week'] = timedata['Dates'].dt.week\nweekly = timedata[['Dates_week', 'Dates_year']]\nweekly = pd.crosstab([weekly.Dates_week], weekly.Dates_year).reset_index()\ngrab_dates = weekly.iloc[:, 1:]\nweekly.plot(x='Dates_week', y=grab_dates.columns, figsize=(20, 8))","4d4e5097":"hourly = timedata[['Dates_hour', 'PdDistrict']]\nhourly = pd.crosstab([hourly.Dates_hour], hourly.PdDistrict).reset_index()\ngrab_dists = hourly.iloc[:, 1:]\nhourly.plot(x='Dates_hour', y=grab_dists.columns, figsize=(20, 8))\n# plt.xticks(np.arange(min(x), max(x)+1, 1.0))","d473da84":"hourly = timedata[['Dates_hour', 'PdDistrict']]\npd.crosstab([hourly.Dates_hour], hourly.PdDistrict).reset_index().sort_values(by='SOUTHERN', ascending=False).head()","b4c17fd3":"addryear = timedata[(timedata.Address == '800 Block of BRYANT ST') | (timedata.Address == '800 Block of MARKET ST') | \n             (timedata.Address == '2000 Block of MISSION ST') | (timedata.Address == '1000 Block of POTRERO AV') | \n             (timedata.Address == '900 Block of MARKET ST') | (timedata.Address == '0 Block of TURK ST') |\n             (timedata.Address == '0 Block of 6TH ST') | (timedata.Address == '300 Block of ELLIS ST') |\n             (timedata.Address == '400 Block of ELLIS ST') | (timedata.Address == '16TH ST \/ MISSION ST')]\naddressyear = addryear[['Dates_year', 'Address']]\naddressyear = pd.crosstab([addryear.Dates_year], addryear.Address).reset_index()\ngrab_addresses = addressyear.iloc[:, 1:]\naddressyear.plot(x='Dates_year', y=grab_addresses.columns, figsize=(20, 9))\nplt.ylabel('Number of Crimes')","77962ae0":"timedata.groupby(['Category', 'PdDistrict', 'Address']).count().reset_index().sort_values(by='Dates', ascending=False)","3b603aff":"datareorder = data[['Category', 'Descript', 'Dates', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y']]\ndatareorder.head(n=1)","1b4a3850":"labelencoder = LabelEncoder()\nfor col in datareorder.columns:\n    datareorder[col] = labelencoder.fit_transform(datareorder[col])\ndatareorder.head()","4098ee02":"from sklearn.naive_bayes import GaussianNB\nmodel_naive = GaussianNB()","73787c9b":"X = datareorder.iloc[:, 1:] \ny = datareorder.iloc[:, 0]","88d9d085":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","3bcf8555":"X_train","981a6f9e":"model_naive.fit(X_train, y_train)\nnb_pred = model_naive.predict(X_test)","24ebf728":"accuracy_score(y_test, nb_pred)","b90dba57":"confusion_matrix(y_test, nb_pred)\n# true positive, false negative\n# false positive, true negative","7f3c73a3":"print(classification_report(y_test, nb_pred, target_names = data['Category'].unique()))","e5026bd0":"from sklearn.tree import DecisionTreeClassifier\nmodel_tree = DecisionTreeClassifier(max_features=\"auto\")","bbe03c94":"model_tree.fit(X_train, y_train)\ntree_pred = model_tree.predict(X_test)","8db0a6cb":"accuracy_score(y_test, tree_pred)","b8fd72b8":"confusion_matrix(y_test, tree_pred)","f70fb014":"print(classification_report(y_test, tree_pred, target_names=data['Category'].unique()))","66357871":"from sklearn.ensemble import RandomForestClassifier\nmodel_forest = RandomForestClassifier(max_features=\"auto\") # max_features=20","602f3752":"model_forest.fit(X_train, y_train)\nforest_pred = model_forest.predict(X_test)","88b9533e":"accuracy_score(y_test, forest_pred)","7926c53e":"x = confusion_matrix(y_test, forest_pred)\nfor item in x:\n    print(x)","6e880926":"print(classification_report(y_test, forest_pred, target_names=data['Category'].unique()))","410913a9":"data.head()","f9d5626f":"dask = dd.read_csv(\"..\/input\/crimetrain\/crimetrain.csv\", parse_dates=['Dates'])\n# dropping some columns because memory errors are still occuring. Dropping Descript because keeping it \n# feels like cheating anyway, as well as DayOfWeek, X, and Y. Dropping Category so dask doesn't one hot encode it\ndask = dask.drop(['Category', 'Descript', 'DayOfWeek', 'X', 'Y'], axis=1)\n# telling dask what columns are categorical for one hot\ndask = dask.categorize(columns=['PdDistrict', 'Resolution', 'Address'])\n# moving columns around\ndask = dask[['Dates', 'PdDistrict', 'Resolution', 'Address']]","fc8721fa":"dask.columns","cd0c1d31":"# one hot encoding categorical data\nenc = DummyEncoder([\"PdDistrict\", \"Resolution\", \"Address\"])","bf2450bc":"enc","5c58c459":"dask = enc.fit_transform(dask)","7f7ce019":"dask.columns","836d34d1":"# prints every column in dask\n# cols = list(dask.columns[0:])\n# cols\n# dask[cols].compute()","2a7bb602":"# the kernel keeps dying here\n# Xoh = dask \n# yoh = datareorder.iloc[:, 0]\n# Xoh_train, Xoh_test, yoh_train, yoh_test = train_test_split(Xoh, yoh, test_size=0.2)","ce61ff70":"# model_forest.fit(X_train, y_train)\n# forest_pred = model_forest.predict(X_test)","1464bf77":"dropDes = datareorder.drop([\"Descript\"], axis=1)\ndropDes.head()","a9d0943e":"XdropDes = dropDes.iloc[:, 1:] \nydropDes = dropDes.iloc[:, 0]","2cbae281":"XdropDes_train, XdropDes_test, ydropRes_train, ydropDes_test = train_test_split(XdropDes, ydropDes, test_size=0.2)","99ba51e8":"model_forestDropDes = RandomForestClassifier(max_features=\"auto\") # max_features=20\nmodel_forestDropDes.fit(XdropDes, ydropDes)\nforest_predDropDes = model_forestDropDes.predict(XdropDes_test)","7c804bc1":"accuracy_score(ydropDes_test, forest_predDropDes)","92cbd848":"confusion_matrix(ydropDes_test, forest_predDropDes)","e9f2659f":"# print(classification_report(ydropDes_test, forest_predDropDes, target_names=data['Category'].unique()))","34c82860":"## What district is the most dangerous?","62b35816":"### Takeaways\n- Why are the number of crimes for 2015 so low?\n- Number of crimes relatively the same from day to day except for the first of the month and the 31 (because not all months have 31 days)\n- Crimes by hour pretty interesting. Descreases from midnight to 5:00am and steadily increases from 8:00am to 6:00pm with a spike at noon","25b35308":"# Testing","98d4d263":"## PdDistrict and Category","e129e27e":"### Takeaways\n- The number of crimes by address stays relatively the same (at least for the top 10 most crime ridden areas) over the years except for 800 Block of BRYANT ST and 800 Block of MARKET ST whicy appear to have a lot of peeks and valleys. This may have to do with the fact that both of these addresses are part of the Southern district--the distict known for having the most criminal actitivity.","979cb865":"Out of the GaussianNB, Decision Tree, and Random Forest classifiers, the Random Forest Classifier performed the best concerning accuracy with a score of .92 (remarkably better than the Gaussian's and Decision Tree's .44 and .77 respectively), and most likely the confusion matrix as well, though it is difficult to be certain as the confusion matrix is so big that it is hard to print out in a readable format. Additionally, after removing the Descript column, the Random Forest classifier did noteably worse (accuracy score of .84) as expected given that Descript had the highest correlation with the Category variable that we were trying to predict. One hot encoding everything still needs to be desired as well as attempting to classify the data using SVM and Logistic Regression.","09886e6f":"# Crime Classification in San Francisco\n## Multi-class classification\nhttps:\/\/www.kaggle.com\/c\/sf-crime\n\n\"From 1934 to 1963, San Francisco was infamous for housing some of the world's most notorious criminals on the inescapable island of Alcatraz.\n\nToday, the city is known more for its tech scene than its criminal past. But, with rising wealth inequality, housing shortages, and a proliferation of expensive digital toys riding BART to work, there is no scarcity of crime in the city by the bay.\n\nFrom Sunset to SOMA, and Marina to Excelsior, this competition's dataset provides nearly 12 years of crime reports from across all of San Francisco's neighborhoods. Given time and location, you must predict the category of crime that occurred.\"\n\n\n![image.png](attachment:image.png)","b328fb41":"## What is the most popular crime?","e0084cdd":"#### Must use dask because of memory error that occurs with pandas","f2524a07":"## Number of cases hourly by PdDistrict","d425bc17":"### Takeaways\n- The dataset does not contain data past June 2015\n- Crime seems to decrease just a bit in the beginning of summer","beca6de3":"# Exploratory Data Analysis","c7bc629c":"## Summary","fed398b4":"## Category and Descript","025ff42b":"The kernel keeps dying everytime I try to split the data into a train and test set. Seeing if labeling encoding the data improves results will have to wait until another time.","3362b074":"## Random Forest","33bbd40c":"## Decision Trees","000897ea":"## Number of cases bi-weekly","9ad96386":"## Time Series  ","e9d27117":"### Takeaways\n- The number of crimes fall between midnight and 5:00am for each district\n- Number of crimes increases from 5:00am to 8:00am, level off for a little bit until noon\n- The number of crimes jumps up around noon\n- The greatest number of crimes occur around 6:00pm\n- Ingleside seems to be the only (sort of) anomaly ","55ac6337":"## Does one-hot encoding improve results?","8f5f920b":"## Top 10 address with the most crimes across the years","b9f2fba9":"## Percentage of crime by PdDistrict","23559054":"### Takeaways\n- PdDistrict may not be the best indicator of Category, but there are definitely some PdDistricts where certain crimes occur more so than others","b03ad323":"- TREA = Trespassing or loitering near posted industrial property","a4afeeca":"## GaussianNB","737db41c":"## How does dropping the Descript column (the column having the highest correlation with Category) compare to the previous Random Forest model?"}}