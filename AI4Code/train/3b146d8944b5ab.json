{"cell_type":{"b7990c62":"code","386aed81":"code","c202bae1":"code","787c258f":"code","ca846027":"code","221e29f8":"code","3ad54964":"code","2e4bc2ca":"code","ffe6144b":"code","38898f2b":"code","79651c1e":"code","ebdabf42":"code","6a800d8d":"code","975cd3cd":"code","8e01b610":"code","f0c86a0a":"code","77a40d29":"code","79a1f54d":"code","4c3ac0ac":"code","2bfeaf82":"code","9e24d69d":"code","c81f1a70":"code","24a74b70":"code","a33d9d39":"code","7f830b2c":"code","99c14d76":"code","a177d18e":"code","4e189485":"code","ba0bd2cc":"code","5c7294dd":"code","7fbb20a3":"code","3dbb8cb9":"code","709ebb5a":"code","cc870181":"code","1da5273a":"code","4857ddf4":"code","3457b73c":"code","5f382db1":"markdown","b8f6a8de":"markdown","9e666206":"markdown","d89fe4b9":"markdown","f04fe3c6":"markdown","5c7d11c5":"markdown","c49ddac0":"markdown","4d439ac4":"markdown","ad2f0f29":"markdown","f51e6112":"markdown","1ae555fa":"markdown"},"source":{"b7990c62":"import pandas as pd","386aed81":"npr = pd.read_csv('..\/input\/npr-data\/npr.csv')","c202bae1":"npr.head()","787c258f":"from sklearn.feature_extraction.text import TfidfVectorizer","ca846027":"tfidf = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')","221e29f8":"dtm = tfidf.fit_transform(npr['Article'])","3ad54964":"dtm","2e4bc2ca":"from sklearn.decomposition import NMF","ffe6144b":"nmf_model = NMF(n_components=7,random_state=42)","38898f2b":"# This can take awhile, we're dealing with a large amount of documents!\nnmf_model.fit(dtm)","79651c1e":"len(tfidf.get_feature_names())","ebdabf42":"import random","6a800d8d":"for i in range(10):\n    random_word_id = random.randint(0,54776)\n    print(tfidf.get_feature_names()[random_word_id])","975cd3cd":"for i in range(10):\n    random_word_id = random.randint(0,54776)\n    print(tfidf.get_feature_names()[random_word_id])","8e01b610":"len(nmf_model.components_)","f0c86a0a":"nmf_model.components_","77a40d29":"len(nmf_model.components_[0])","79a1f54d":"single_topic = nmf_model.components_[0]","4c3ac0ac":"# Returns the indices that would sort this array.\nsingle_topic.argsort()","2bfeaf82":"# Word least representative of this topic\nsingle_topic[18302]","9e24d69d":"# Word most representative of this topic\nsingle_topic[42993]","c81f1a70":"# Top 10 words for this topic:\nsingle_topic.argsort()[-10:]","24a74b70":"top_word_indices = single_topic.argsort()[-10:]","a33d9d39":"for index in top_word_indices:\n    print(tfidf.get_feature_names()[index])","7f830b2c":"for index,topic in enumerate(nmf_model.components_):\n    print(f'THE TOP 15 WORDS FOR TOPIC #{index}')\n    print([tfidf.get_feature_names()[i] for i in topic.argsort()[-15:]])\n    print('\\n')","99c14d76":"dtm","a177d18e":"dtm.shape","4e189485":"len(npr)","ba0bd2cc":"topic_results = nmf_model.transform(dtm)","5c7294dd":"topic_results.shape","7fbb20a3":"topic_results[0]","3dbb8cb9":"topic_results[0].round(2)","709ebb5a":"topic_results[0].argmax()","cc870181":"npr.head()","1da5273a":"topic_results.argmax(axis=1)","4857ddf4":"npr['Topic'] = topic_results.argmax(axis=1)","3457b73c":"npr.head(10)","5f382db1":"### Attaching Discovered Topic Labels to Original Articles","b8f6a8de":"## NMF","9e666206":"This means that our model thinks that the first article belongs to topic #1.","d89fe4b9":"These look like business articles perhaps... Let's confirm by using .transform() on our vectorized articles to attach a label number. But first, let's view all the 10 topics found.","f04fe3c6":"### Combining with Original Data","5c7d11c5":"**`max_df`**` : float in range [0.0, 1.0] or int, default=1.0`<br>\nWhen building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.\n\n**`min_df`**` : float in range [0.0, 1.0] or int, default=1`<br>\nWhen building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.","c49ddac0":"# Non-Negative Matric Factorization\n\nLet's repeat thet opic modeling task from the previous lecture, but this time, we will use NMF instead of LDA.","4d439ac4":"Notice how we don't have the topic of the articles! Let's use LDA to attempt to figure out clusters of the articles.","ad2f0f29":"## Displaying Topics","f51e6112":"## Preprocessing","1ae555fa":"## Data\n\nWe will be using articles scraped from NPR (National Public Radio), obtained from their website [www.npr.org](http:\/\/www.npr.org)"}}