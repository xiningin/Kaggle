{"cell_type":{"62b6ee75":"code","6bd7a181":"code","eab2d8dd":"code","9cc7d303":"code","2d366860":"code","29795520":"code","bd472f26":"code","a1c93b5a":"code","ea567380":"code","6522c510":"code","dab2cc0e":"code","9231e02b":"code","a310eae9":"code","78135f12":"code","0b75fcb3":"code","0e00794a":"code","1b7a4681":"code","1bbc536d":"code","10f00712":"code","f567c183":"code","3bbd8d42":"code","c0d665b5":"code","2de57827":"markdown","6b75052e":"markdown","73a08960":"markdown","709ae0a1":"markdown","e9fabc04":"markdown","ee98b533":"markdown","625c5b8a":"markdown","8b012f16":"markdown","c415e69f":"markdown","371cfffb":"markdown","a89659a7":"markdown"},"source":{"62b6ee75":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6bd7a181":"import shap\nimport numpy as np\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","eab2d8dd":"!cp \/kaggle\/input\/imageslogisticregression\/Images\/* .\n!ls","9cc7d303":"data = load_iris()\nX = data.data\n# Y_labels = [data.target_names[v] for v in data.target]\nY_labels = data.target\ndf = pd.DataFrame(np.column_stack((X,Y_labels)),columns= (data.feature_names + ['Class']))\ndf['Class'] = pd.to_numeric(df['Class'],downcast='integer')\ndf.head()","2d366860":"X.shape","29795520":"len(Y_labels)","bd472f26":"df.isnull().sum()","a1c93b5a":"print(data.target_names)\nsns.pairplot(df,hue = 'Class')","ea567380":"sns.heatmap(df.loc[:, df.columns != 'Class'].corr(),\n            annot=True,\n            cmap='Blues',\n           )","6522c510":"X_train, X_test, y_train, y_test = train_test_split(X, Y_labels, test_size=0.25, random_state=0)","dab2cc0e":"print(round(X_train.shape[0]\/X.shape[0],2))\nprint(round(X_test.shape[0]\/X.shape[0],2))","9231e02b":"model = LogisticRegression(max_iter=200)\nmodel.fit(X_train, y_train)","a310eae9":"model.coef_,model.intercept_","78135f12":"predicted = model.predict(X_train)\nprint(\"Accuracy for Train-set \",round(accuracy_score(y_train,predicted),3))","0b75fcb3":"predicted = model.predict(X_test) \nprint(\"Accuracy for Test-set \",round(accuracy_score(y_test,predicted),3))","0e00794a":"cm = confusion_matrix(y_test,predicted)\nsns.heatmap(cm,\n            cmap='Blues',\n            annot=True,\n            xticklabels=data.target_names,\n            yticklabels=data.target_names,\n            linecolor=\"Darkblue\",\n            linewidths=0.1\n           )","1b7a4681":"# explain all the predictions in the test set\nexplainer = shap.KernelExplainer(model.predict_proba, X_train, feature_names=data.feature_names)\nshap_values = explainer.shap_values(X_test)\n","1bbc536d":"explainer.expected_value","10f00712":"shap.summary_plot(shap_values,X_test,feature_names=data.feature_names)","f567c183":"shap.initjs()\nfor ind in range(3):\n    print('Class - ',data.target_names[ind])\n    display(shap.force_plot(explainer.expected_value[ind], shap_values[ind], X_test,feature_names=data.feature_names))","3bbd8d42":"for ind in range(3):\n    print('Class - ',data.target_names[ind])\n    display(shap.summary_plot(shap_values[ind],X_test,feature_names=data.feature_names,class_names=data.target_names))","c0d665b5":"for i in range(10):\n    ind = i\n    print(X_test[ind],data.target_names[y_test[ind]],data.target_names[predicted[ind]])\n    shap_display = shap.force_plot(explainer.expected_value[0],shap_values[0][ind,:],X_test[ind],feature_names=data.feature_names)\n    display(shap_display)","2de57827":"# Local interpretability","6b75052e":"<h2> Summary<\/h2>\n<font color='Blue'><i><br>\n1. We learnt model fitting for Multi-Class Classification problem utilising Logistic regression.<br>\n2. The model was able to lean the patterns in data and Explainable AI confirms that. ","73a08960":"<h2> References<\/h2>\n<font color='Blue'><i><br>\n1. <a href='https:\/\/towardsdatascience.com\/explain-any-models-with-the-shap-values-use-the-kernelexplainer-79de9464897a'>https:\/\/towardsdatascience.com\/explain-any-models-with-the-shap-values-use-the-kernelexplainer-79de9464897a<\/a><br>\n2. <a href='https:\/\/towardsdatascience.com\/linear-regression-and-its-assumptions-ef6e8db4904d'>https:\/\/towardsdatascience.com\/linear-regression-and-its-assumptions-ef6e8db4904d<\/a><br>\n3. <a href='https:\/\/shap.readthedocs.io\/en\/latest\/'>https:\/\/shap.readthedocs.io\/en\/latest\/<\/a><br>\n4. <a href='https:\/\/shap.readthedocs.io\/en\/latest\/example_notebooks\/tabular_examples\/model_agnostic\/Iris%20classification%20with%20scikit-learn.html#Logistic-regression'>https:\/\/shap.readthedocs.io\/en\/latest\/example_notebooks\/tabular_examples\/model_agnostic\/Iris%20classification%20with%20scikit-learn.html#Logistic-regression<\/a><br>\n  ","709ae0a1":"# Key notes from last lecture(in practice)\n<font color='red'><i>\n* In multi-class Classification, Softmax activation function is used .\n* One beta is learnt per feature\/per class.\n* Every class has its own hyperplane.\n    <\/i><\/font>\n<figure>\n  <img src=\"LogisticRegression.png\" style=\"width:100%\">\n    <center><figcaption><b>Image Source:<\/b> <a href='https:\/\/www.kdnuggets.com\/2016\/07\/softmax-regression-related-logistic-regression.html'>https:\/\/www.kdnuggets.com\/2016\/07\/softmax-regression-related-logistic-regression.html<\/a><\/figcaption><\/center>\n<\/figure>","e9fabc04":"\n<h3>EDA: Next we will do Exploratory Data Analysis (EDA) to understand our dataset better.<\/h3>\n\n<figure>\n  <img src=\"eda.jpg\" style=\"width:75%\">\n    <center><figcaption><b>Image Source:<\/b> <a href='https:\/\/www.freepik.com\/free-vector\/data-inform-illustration-concept_6195525.htm'>https:\/\/www.freepik.com\/free-vector\/data-inform-illustration-concept_6195525.htm<\/a><\/figcaption><\/center>\n<\/figure>\n","ee98b533":"# Explainable AI\/ML\n<font color='red'><i>\nExplainable AI is a set of tools and frameworks to understand and interpret predictions made by machine learning models. <br>\nWith it, we can debug and improve model performance, and help us and others understand our model's behavior.\n    <\/i><\/font>\n","625c5b8a":"<font color='red'><i>\nThe above plot indicates that petal length (cm) had the greatest influence on the predictions for all 3 classes followed by petal width (cm).<\/i><\/font>","8b012f16":"<h3><b>Features explanation:<\/b><\/h3>\n\n<figure>\n  <img src=\"feature_clarification.png\" style=\"width:30%\">\n    <center><figcaption><b>Image Source:<\/b> <a href='https:\/\/mammothmemory.net\/biology\/plants\/sexual-reproduction-in-plants\/sepal.html'>https:\/\/mammothmemory.net\/biology\/plants\/sexual-reproduction-in-plants\/sepal.html<\/a><\/figcaption><\/center>\n<\/figure>","c415e69f":"<font color='red'><i>\n* Sepal Length, petal length and petal width smaller for Setosa, followed by Versicolor and Virginica. <br>\n* Sepalwidth doesnt show much deviation  but follows a different pattern. Smaller for Vericolor and Virginica but relatively larger for Setosa.<br><\/i><\/font>","371cfffb":"<font color='blue'><i><b>\nLundberg et al. in their brilliant paper \u201cA unified approach to interpreting model predictions\u201d proposed the SHAP (SHapley Additive exPlanations) values which offer a high level of interpretability for a model. The SHAP values provide two great advantages:\n    <\/b>\n<ol>\n<li>Global interpretability \u2014 the SHAP values can show how much each predictor contributes, either positively or negatively, to the target variable.\n<li>Local interpretability \u2014 each observation gets its own set of SHAP values (see the individual force plots below). This greatly increases its transparency. We can explain why a case receives its prediction and the contributions of the predictors. \n    <\/ol><\/i><\/font>","a89659a7":"<h1>Practical Example running Logistic Regression using Python including EDA + Explainable AI<\/h1>\n\n<figure>\n          <img src= \"species.png\" style=\"width:75%\">\n    <center><\/center>\n<\/figure>"}}