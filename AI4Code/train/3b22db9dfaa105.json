{"cell_type":{"db046eda":"code","d5c2f2ae":"code","aaaec559":"code","5ad0a0d5":"code","99f04733":"code","a25607b1":"code","4d0d411e":"code","1edff1b1":"code","922884be":"code","6ca37ac6":"code","43a58327":"markdown","1ad81274":"markdown","eab48b2e":"markdown","5035eba8":"markdown","92f77d0f":"markdown","2c65dae1":"markdown"},"source":{"db046eda":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom imblearn.over_sampling import RandomOverSampler\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.metrics import accuracy_score, f1_score","d5c2f2ae":"data = pd.read_csv('..\/input\/sales-analysis\/SalesKaggle3.csv')","aaaec559":"data","5ad0a0d5":"data.info()","99f04733":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Only use historical data\n    df = df.query(\"File_Type == 'Historical'\")\n    \n    # Drop unused columns\n    df = df.drop(['Order', 'File_Type', 'SKU_number', 'SoldCount'], axis=1)\n    \n    # Shuffle data\n    df = df.sample(frac=1.0, random_state=1)\n    \n    # Split df into X and y\n    y = df['SoldFlag']\n    X = df.drop('SoldFlag', axis=1)\n    \n    return X, y","a25607b1":"X, y = preprocess_inputs(data)","4d0d411e":"X","1edff1b1":"y.value_counts()","922884be":"def build_pipeline():\n    binary_transformer = Pipeline(steps=[\n        ('onehot', OneHotEncoder(sparse=False, drop='if_binary'))\n    ])\n    \n    nominal_transformer = Pipeline(steps=[\n        ('onehot', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n    ])\n    \n    preprocessor = ColumnTransformer(transformers=[\n        ('binary', binary_transformer, ['MarketingType']),\n        ('nominal', nominal_transformer, ['ReleaseNumber'])\n    ], remainder='passthrough')\n    \n    model = Pipeline(steps=[\n        ('preprocessor', preprocessor),\n        ('regressor', RandomForestClassifier(random_state=1))\n    ])\n    \n    return model","6ca37ac6":"accs = []\nf1s = []\n\nkf = KFold(n_splits=5)\n\nfor train_idx, test_idx in kf.split(X):\n    X_train = X.iloc[train_idx, :]\n    X_test = X.iloc[test_idx, :]\n    y_train = y.iloc[train_idx]\n    y_test = y.iloc[test_idx]\n    \n    # Address class imbalance\n    num_samples = int(y_train.value_counts().mean())\n    majority_indices = y_train[y_train == 0.0].index\n    samples_to_drop = y_train[majority_indices].sample(len(y_train) - num_samples, random_state=1).index\n    X_train = X_train.drop(samples_to_drop, axis=0)\n    y_train = y_train.drop(samples_to_drop, axis=0)\n    oversampler = RandomOverSampler(random_state=1)\n    X_train, y_train = oversampler.fit_resample(X_train, y_train)\n    \n    model = build_pipeline()\n    model.fit(X_train, y_train)\n    \n    y_pred = model.predict(X_test)\n    \n    accs.append(accuracy_score(y_test, y_pred))\n    f1s.append(f1_score(y_test, y_pred, pos_label=1.0))\n\nacc = np.mean(accs)\nf1 = np.mean(f1s)\n\nprint(\"Accuracy: {:.2f}%\".format(acc * 100))\nprint(\"F1-Score: {:.5f}\".format(f1))","43a58327":"# Training\/Validation","1ad81274":"# Preprocessing","eab48b2e":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/0N__PFjOqno","5035eba8":"# Task for Today  \n\n***\n\n## Product Sales Prediction  \n  \nGiven *data about products being sold*, let's try to predict if a given product will have been **sold in the last six months**.  \n  \nWe will use a random forest classification model to make our predictions.","92f77d0f":"# Building Pipeline","2c65dae1":"# Getting Started"}}