{"cell_type":{"109e9cf7":"code","2a4e7687":"code","f3223dec":"code","0aa2b301":"code","d46de44a":"code","08eb6827":"code","2b927ef7":"code","1a487352":"code","fd986df6":"code","0603dfea":"code","27c04c16":"code","26d13152":"code","20936d98":"code","8ce71969":"code","15ce1ba8":"code","78fe3286":"code","cd7738bd":"code","865a851c":"code","25e3dbe2":"code","6c4ec58f":"code","fd5d9f0f":"code","6aadbfa9":"code","bdabc625":"code","3dd89875":"code","14d0564d":"code","906f2539":"code","78da9c6b":"code","e3d93ed2":"code","8d378214":"code","c9e42dfd":"code","055f6719":"code","bd1d19f2":"code","cc66b99d":"code","eb018bd7":"code","bd2ec11f":"code","4e53f648":"code","214607de":"code","a1d320a2":"code","6a547fe5":"code","cb941792":"code","16c455c6":"code","0a7a82af":"code","9b77a7b8":"code","5cab06c2":"code","31509ab8":"code","bd0e10b6":"code","cfbed4a6":"code","5a1b4b1c":"code","f66577e8":"code","635c21f8":"code","7ea53b16":"code","d2fbb042":"code","abd8aaec":"code","fb4038b5":"code","2908c98c":"code","e6a280d3":"code","f51c6830":"markdown","e2facbe0":"markdown","e1de53dd":"markdown","e749babd":"markdown","3c32badb":"markdown","7a867fc3":"markdown","54c1d06f":"markdown","c066144c":"markdown","9f2657f9":"markdown","4c0f150f":"markdown","140210d1":"markdown","87639bf7":"markdown","f8575576":"markdown","dd871b52":"markdown","e11f825f":"markdown","5ba3fe7e":"markdown","533b09b6":"markdown","767a7e97":"markdown","bb01dcbe":"markdown","d5ccbbe7":"markdown","ab72570e":"markdown","468e5ae1":"markdown","5e856696":"markdown","4f1cdac9":"markdown","7ac99156":"markdown","b658d311":"markdown","f1610358":"markdown","c3a4c5f7":"markdown","62aa582c":"markdown","21b2a7e4":"markdown","d714801e":"markdown"},"source":{"109e9cf7":"import numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport seaborn as sns\nfrom nltk.corpus import stopwords\n\nfrom nltk.util import ngrams\nfrom wordcloud import WordCloud\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom collections import defaultdict\nfrom collections import  Counter\nplt.style.use('ggplot')\nstop=set(stopwords.words('english'))\n\nimport re\nfrom nltk.tokenize import word_tokenize\nimport gensim\nimport string\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom tqdm import tqdm\nfrom keras.models import Sequential\nfrom keras.layers import Embedding,LSTM,Dense,SpatialDropout1D\nfrom keras.initializers import Constant\nfrom sklearn.model_selection import train_test_split\nfrom keras.optimizers import Adam\n\nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.metrics import classification_report,confusion_matrix\n\nimport torch\n\nimport warnings\nwarnings.simplefilter('ignore')","2a4e7687":"import os\n#os.listdir('..\/input\/glove-global-vectors-for-word-representations\/glove.6B.100d.txt')","f3223dec":"tweet= pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ntest=pd.read_csv('..\/input\/nlp-getting-started\/test.csv')\ntweet.head(3)","0aa2b301":"print('There are {} rows and {} columns in train'.format(tweet.shape[0],tweet.shape[1]))\nprint('There are {} rows and {} columns in train'.format(test.shape[0],test.shape[1]))","d46de44a":"x=tweet.target.value_counts()\nsns.barplot(x.index,x)\nplt.gca().set_ylabel('samples')","08eb6827":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_len=tweet[tweet['target']==1]['text'].str.len()\nax1.hist(tweet_len,color='red')\nax1.set_title('disaster')\ntweet_len=tweet[tweet['target']==0]['text'].str.len()\nax2.hist(tweet_len,color='blue')\nax2.set_title('Not disaster')\nfig.suptitle('Characters in tweets')\nplt.show()","2b927ef7":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\ntweet_len=tweet[tweet['target']==1]['text'].str.split().map(lambda x: len(x))\nax1.hist(tweet_len,color='red')\nax1.set_title('disaster')\ntweet_len=tweet[tweet['target']==0]['text'].str.split().map(lambda x: len(x))\nax2.hist(tweet_len,color='blue')\nax2.set_title('Not disaster')\nfig.suptitle('Words in tweets')\nplt.show()","1a487352":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\nword=tweet[tweet['target']==1]['text'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax1,color='red')\nax1.set_title('disaster')\nword=tweet[tweet['target']==0]['text'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax2,color='blue')\nax2.set_title('Not disaster')\nfig.suptitle('Average word length in each tweet')","fd986df6":"def create_corpus(target):\n    corpus=[]\n    \n    for x in tweet[tweet['target']==target]['text'].str.split():\n        for i in x:\n            corpus.append(i)\n    return corpus","0603dfea":"corpus=create_corpus(0)\n\ndic=defaultdict(int)\nfor word in corpus:\n    if word in stop:\n        dic[word]+=1\n        \ntop=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] ","27c04c16":"x,y=zip(*top)\nplt.bar(x,y,color='red')","26d13152":"corpus=create_corpus(1)\n\ndic=defaultdict(int)\nfor word in corpus:\n    if word in stop:\n        dic[word]+=1\n\ntop=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n\nx,y=zip(*top)\nplt.bar(x,y,color='red')","20936d98":"plt.figure(figsize=(10,5))\ncorpus=create_corpus(1)\n\ndic=defaultdict(int)\nimport string\nspecial = string.punctuation\nfor i in (corpus):\n    if i in special:\n        dic[i]+=1\n        \nx,y=zip(*dic.items())\nplt.bar(x,y,color='blue')","8ce71969":"counter=Counter(corpus)\nmost=counter.most_common()\nx=[]\ny=[]\nfor word,count in most[:40]:\n    if (word not in stop) :\n        x.append(word)\n        y.append(count)","15ce1ba8":"sns.barplot(x=y,y=x)","78fe3286":"def get_top_tweet_bigrams(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","cd7738bd":"plt.figure(figsize=(10,5))\ntop_tweet_bigrams=get_top_tweet_bigrams(tweet['text'])[:10]\nx,y=map(list,zip(*top_tweet_bigrams))\nsns.barplot(x=y,y=x)","865a851c":"df=pd.concat([tweet,test])\ndf.shape","25e3dbe2":"example=\"New competition launched :https:\/\/www.kaggle.com\/c\/nlp-getting-started\"","6c4ec58f":"def remove_URL(text):\n    url = re.compile(r'https?:\/\/\\S+|www\\.\\S+')\n    return url.sub(r'',text)\n\nremove_URL(example)","fd5d9f0f":"df['text']=df['text'].apply(lambda x : remove_URL(x))","6aadbfa9":"example = \"\"\"<div>\n<h1>Real or Fake<\/h1>\n<p>Kaggle <\/p>\n<a href=\"https:\/\/www.kaggle.com\/c\/nlp-getting-started\">getting started<\/a>\n<\/div>\"\"\"","bdabc625":"def remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\nprint(remove_html(example))","3dd89875":"df['text']=df['text'].apply(lambda x : remove_html(x))","14d0564d":"# Reference : https:\/\/gist.github.com\/slowkow\/7a7f61f495e3dbb7e3d767f97bd7304b\ndef remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\nremove_emoji(\"Omg another Earthquake \ud83d\ude14\ud83d\ude14\")","906f2539":"df['text']=df['text'].apply(lambda x: remove_emoji(x))","78da9c6b":"def remove_punct(text):\n    table=str.maketrans('','',string.punctuation)\n    return text.translate(table)\n\nexample=\"I am a #king\"\nprint(remove_punct(example))","e3d93ed2":"df['text']=df['text'].apply(lambda x : remove_punct(x))","8d378214":"corpus_new1=create_corpus(1)\nlen(corpus_new1)","c9e42dfd":"corpus_new1[:10]","055f6719":"# Generating the wordcloud with the values under the category dataframe\nplt.figure(figsize=(12,8))\nword_cloud = WordCloud(background_color='grey',max_font_size = 80).generate(\" \".join(corpus_new1[:50]))\nplt.imshow(word_cloud)\nplt.axis('off')\nplt.show()","bd1d19f2":"corpus_new0=create_corpus(0)\nlen(corpus_new0)","cc66b99d":"corpus_new0[:10]","eb018bd7":"# Generating the wordcloud with the values under the category dataframe\nplt.figure(figsize=(12,8))\nword_cloud = WordCloud(background_color='grey',max_font_size = 80).generate(\" \".join(corpus_new0[:50]))\nplt.imshow(word_cloud)\nplt.axis('off')\nplt.show()","bd2ec11f":"df.head(10)","4e53f648":"def cv(data):\n    count_vectorizer = CountVectorizer()\n\n    emb = count_vectorizer.fit_transform(data)\n\n    return emb, count_vectorizer\n\nlist_corpus = df[\"text\"].tolist()\nlist_labels = df[\"target\"].tolist()\n\nX_train, X_test, y_train, y_test = train_test_split(list_corpus, list_labels, test_size=0.2, random_state=42)\n\nX_train_counts, count_vectorizer = cv(X_train)\nX_test_counts = count_vectorizer.transform(X_test)","214607de":"def plot_LSA(test_data, test_labels, savepath=\"PCA_demo.csv\", plot=True):\n        lsa = TruncatedSVD(n_components=2)\n        lsa.fit(test_data)\n        lsa_scores = lsa.transform(test_data)\n        color_mapper = {label:idx for idx,label in enumerate(set(test_labels))}\n        color_column = [color_mapper[label] for label in test_labels]\n        colors = ['blue','red']\n        if plot:\n            plt.scatter(lsa_scores[:,0], lsa_scores[:,1], s=8, alpha=.8, c=test_labels, cmap=matplotlib.colors.ListedColormap(colors))\n            blue_patch = mpatches.Patch(color='blue', label='Not')\n            red_patch = mpatches.Patch(color='red', label='Real')\n            plt.legend(handles=[blue_patch, red_patch], prop={'size': 30})\n\nfig = plt.figure(figsize=(16, 16))          \nplot_LSA(X_train_counts, y_train)\nplt.show()","a1d320a2":"def tfidf(data):\n    tfidf_vectorizer = TfidfVectorizer()\n\n    train = tfidf_vectorizer.fit_transform(data)\n\n    return train, tfidf_vectorizer\n\nX_train_tfidf, tfidf_vectorizer = tfidf(X_train)\nX_test_tfidf = tfidf_vectorizer.transform(X_test)","6a547fe5":"fig = plt.figure(figsize=(16, 16))          \nplot_LSA(X_train_tfidf, y_train)\nplt.show()","cb941792":"def create_corpus(df):\n    corpus=[]\n    for tweet in tqdm(df['text']):\n        words=[word.lower() for word in word_tokenize(tweet) if((word.isalpha()==1) & (word not in stop))]\n        corpus.append(words)\n    return corpus","16c455c6":"corpus=create_corpus(df)","0a7a82af":"embedding_dict={}\nwith open('..\/input\/glove-global-vectors-for-word-representations\/glove.6B.100d.txt','r') as f:\n    for line in f:\n        values=line.split()\n        word=values[0]\n        vectors=np.asarray(values[1:],'float32')\n        embedding_dict[word]=vectors\nf.close()","9b77a7b8":"MAX_LEN=50\ntokenizer_obj=Tokenizer()\ntokenizer_obj.fit_on_texts(corpus)\nsequences=tokenizer_obj.texts_to_sequences(corpus)\n\ntweet_pad=pad_sequences(sequences,maxlen=MAX_LEN,truncating='post',padding='post')","5cab06c2":"word_index=tokenizer_obj.word_index\nprint('Number of unique words:',len(word_index))","31509ab8":"num_words=len(word_index)+1\nembedding_matrix=np.zeros((num_words,100))\n\nfor word,i in tqdm(word_index.items()):\n    if i > num_words:\n        continue\n    \n    emb_vec=embedding_dict.get(word)\n    if emb_vec is not None:\n        embedding_matrix[i]=emb_vec","bd0e10b6":"tweet_pad[0][0:]","cfbed4a6":"model=Sequential()\n\nembedding=Embedding(num_words,100,embeddings_initializer=Constant(embedding_matrix),\n                   input_length=MAX_LEN,trainable=False)\n\nmodel.add(embedding)\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(1, activation='sigmoid'))\n\noptimzer=Adam(learning_rate=1e-5)\n\nmodel.compile(loss='binary_crossentropy',optimizer=optimzer,metrics=['accuracy'])","5a1b4b1c":"model.summary()","f66577e8":"train=tweet_pad[:tweet.shape[0]]\ntest=tweet_pad[tweet.shape[0]:]","635c21f8":"X_train,X_test,y_train,y_test=train_test_split(train,tweet['target'].values,test_size=0.15)\nprint('Shape of train',X_train.shape)\nprint(\"Shape of Validation \",X_test.shape)","7ea53b16":"fig = plt.figure(figsize=(16, 16))          \nplot_LSA(train,tweet['target'])\nplt.show()","d2fbb042":"history=model.fit(X_train,y_train,batch_size=4,epochs=15,validation_data=(X_test,y_test),verbose=2)","abd8aaec":"train_pred_GloVe = model.predict(train)\ntrain_pred_GloVe_int = train_pred_GloVe.round().astype('int')","fb4038b5":"sample_sub=pd.read_csv('..\/input\/nlp-getting-started\/sample_submission.csv')","2908c98c":"y_pre=model.predict(test)\ny_pre=np.round(y_pre).astype(int).reshape(3263)\nsub=pd.DataFrame({'id':sample_sub['id'].values.tolist(),'target':y_pre})\nsub.to_csv('submission.csv',index=False)","e6a280d3":"sub.head()","f51c6830":"## \u0e02\u0e31\u0e49\u0e19\u0e15\u0e2d\u0e19\u0e17\u0e35\u0e48 8: TF-IDF","e2facbe0":"## \u0e02\u0e31\u0e49\u0e19\u0e15\u0e2d\u0e19\u0e17\u0e35\u0e48 5: Data Cleaning\n\u0e2d\u0e22\u0e48\u0e32\u0e07\u0e17\u0e35\u0e48\u0e40\u0e23\u0e32\u0e17\u0e23\u0e32\u0e1a\u0e01\u0e31\u0e19\u0e14\u0e35\u0e27\u0e48\u0e32 \u0e17\u0e27\u0e34\u0e15\u0e40\u0e15\u0e2d\u0e23\u0e4c\u0e15\u0e49\u0e2d\u0e07\u0e44\u0e14\u0e49\u0e23\u0e31\u0e1a\u0e01\u0e32\u0e23 cleaning \u0e40\u0e2a\u0e21\u0e2d \u0e01\u0e48\u0e2d\u0e19\u0e17\u0e35\u0e48\u0e40\u0e23\u0e32\u0e08\u0e30\u0e40\u0e02\u0e49\u0e32\u0e2a\u0e39\u0e48 modelling \u0e14\u0e31\u0e07\u0e19\u0e31\u0e49\u0e19\u0e40\u0e23\u0e32\u0e08\u0e30 cleaning \u0e1e\u0e37\u0e49\u0e19\u0e10\u0e32\u0e19\u0e1a\u0e32\u0e07\u0e2d\u0e22\u0e48\u0e32\u0e07 \u0e40\u0e0a\u0e48\u0e19 \u0e01\u0e32\u0e23\u0e41\u0e01\u0e49\u0e44\u0e02\u0e01\u0e32\u0e23\u0e2a\u0e30\u0e01\u0e14 (punctuations) \u0e01\u0e32\u0e23\u0e25\u0e1a\u0e40\u0e04\u0e23\u0e37\u0e48\u0e2d\u0e07\u0e2b\u0e21\u0e32\u0e22\u0e27\u0e23\u0e23\u0e04\u0e15\u0e2d\u0e19 \u0e01\u0e32\u0e23\u0e25\u0e1a\u0e41\u0e17\u0e47\u0e01 html \u0e41\u0e25\u0e30\u0e2d\u0e34\u0e42\u0e21\u0e08\u0e34 \u0e40\u0e1b\u0e47\u0e19\u0e15\u0e49\u0e19","e1de53dd":"## \u0e02\u0e31\u0e49\u0e19\u0e15\u0e2d\u0e19\u0e17\u0e35\u0e48 4: Exploratory Data Analysis of tweets\n\u0e02\u0e31\u0e49\u0e19\u0e41\u0e23\u0e01 \u0e40\u0e23\u0e32\u0e08\u0e30\u0e17\u0e33\u0e01\u0e32\u0e23\u0e27\u0e34\u0e40\u0e04\u0e23\u0e32\u0e30\u0e2b\u0e4c\u0e02\u0e31\u0e49\u0e19\u0e1e\u0e37\u0e49\u0e19\u0e10\u0e32\u0e19 \u0e19\u0e31\u0e48\u0e19\u0e04\u0e37\u0e2d\u0e23\u0e30\u0e14\u0e31\u0e1a\u0e15\u0e31\u0e27\u0e2d\u0e31\u0e01\u0e29\u0e23 \u0e23\u0e30\u0e14\u0e31\u0e1a\u0e04\u0e33 \u0e41\u0e25\u0e30\u0e01\u0e32\u0e23\u0e27\u0e34\u0e40\u0e04\u0e23\u0e32\u0e30\u0e2b\u0e4c\u0e23\u0e30\u0e14\u0e31\u0e1a\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e04","e749babd":"## Real or Not: NLP with Disaster tweets\n### DSI206 Multimedia Representation Management\n\n\u0e43\u0e19\u0e1b\u0e31\u0e08\u0e08\u0e38\u0e1a\u0e31\u0e19 \u0e41\u0e2d\u0e1b\u0e1e\u0e25\u0e34\u0e40\u0e04\u0e0a\u0e31\u0e48\u0e19\u0e15\u0e48\u0e32\u0e07\u0e46\u0e21\u0e35\u0e1a\u0e17\u0e1a\u0e32\u0e17\u0e43\u0e19\u0e01\u0e32\u0e23\u0e2a\u0e37\u0e48\u0e2d\u0e2a\u0e32\u0e23\u0e02\u0e2d\u0e07\u0e21\u0e19\u0e38\u0e29\u0e22\u0e4c\u0e21\u0e32\u0e01\u0e02\u0e36\u0e49\u0e19 \u0e0b\u0e36\u0e48\u0e07 Twitter \u0e40\u0e1b\u0e47\u0e19\u0e2b\u0e19\u0e36\u0e48\u0e07\u0e43\u0e19\u0e19\u0e31\u0e49\u0e19\u0e41\u0e25\u0e30\u0e40\u0e1b\u0e47\u0e19\u0e41\u0e2d\u0e1e\u0e1e\u0e25\u0e34\u0e40\u0e04\u0e0a\u0e31\u0e48\u0e19\u0e22\u0e2d\u0e14\u0e19\u0e34\u0e22\u0e21\u0e17\u0e35\u0e48\u0e2a\u0e32\u0e21\u0e32\u0e23\u0e16\u0e40\u0e02\u0e49\u0e32\u0e16\u0e36\u0e07\u0e40\u0e19\u0e37\u0e49\u0e2d\u0e2b\u0e32\u0e02\u0e2d\u0e07\u0e02\u0e48\u0e32\u0e27\u0e2a\u0e32\u0e23\u0e15\u0e48\u0e32\u0e07\u0e46\u0e08\u0e32\u0e01\u0e40\u0e17\u0e23\u0e19\u0e14\u0e4c\u0e17\u0e35\u0e48\u0e02\u0e36\u0e49\u0e19\u0e2d\u0e31\u0e19\u0e14\u0e31\u0e1a 1 \u0e43\u0e19\u0e17\u0e27\u0e34\u0e15\u0e40\u0e15\u0e2d\u0e23\u0e4c \u0e23\u0e27\u0e21\u0e16\u0e36\u0e07\u0e02\u0e48\u0e32\u0e27\u0e2a\u0e32\u0e23\u0e17\u0e35\u0e48\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e01\u0e31\u0e1a\u0e1b\u0e31\u0e0d\u0e2b\u0e32\u0e14\u0e49\u0e32\u0e19\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34\u0e17\u0e32\u0e07\u0e18\u0e23\u0e23\u0e21\u0e0a\u0e32\u0e15\u0e34\u0e14\u0e49\u0e27\u0e22\u0e40\u0e0a\u0e48\u0e19\u0e01\u0e31\u0e19 \u0e41\u0e15\u0e48\u0e40\u0e19\u0e37\u0e48\u0e2d\u0e07\u0e14\u0e49\u0e27\u0e22\u0e43\u0e19\u0e42\u0e25\u0e01\u0e42\u0e0b\u0e40\u0e0a\u0e35\u0e22\u0e25\u0e19\u0e31\u0e49\u0e19 \u0e04\u0e33\u0e43\u0e19\u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21\u0e1a\u0e32\u0e07\u0e2d\u0e22\u0e48\u0e32\u0e07\u0e2d\u0e32\u0e08\u0e08\u0e30\u0e44\u0e21\u0e48\u0e44\u0e14\u0e49\u0e2a\u0e37\u0e48\u0e2d\u0e16\u0e36\u0e07\u0e43\u0e19\u0e40\u0e23\u0e37\u0e48\u0e2d\u0e07\u0e46\u0e19\u0e31\u0e49\u0e19\u0e41\u0e15\u0e48\u0e2d\u0e32\u0e08\u0e19\u0e33\u0e21\u0e32\u0e43\u0e0a\u0e49\u0e43\u0e19\u0e1a\u0e23\u0e34\u0e1a\u0e17\u0e2d\u0e37\u0e48\u0e19 \u0e0b\u0e36\u0e48\u0e07\u0e17\u0e33\u0e43\u0e2b\u0e49\u0e40\u0e01\u0e34\u0e14\u0e04\u0e27\u0e32\u0e21\u0e40\u0e02\u0e49\u0e32\u0e43\u0e08\u0e1c\u0e34\u0e14\u0e04\u0e34\u0e14\u0e27\u0e48\u0e32\u0e2a\u0e34\u0e48\u0e07\u0e17\u0e35\u0e48\u0e2a\u0e37\u0e48\u0e2d\u0e16\u0e36\u0e07\u0e40\u0e1b\u0e47\u0e19\u0e40\u0e23\u0e37\u0e48\u0e2d\u0e07\u0e14\u0e31\u0e07\u0e01\u0e25\u0e48\u0e32\u0e27 \u0e14\u0e49\u0e27\u0e22\u0e40\u0e2b\u0e15\u0e38\u0e19\u0e35\u0e49 \u0e1b\u0e31\u0e0d\u0e2b\u0e32\u0e17\u0e35\u0e48\u0e40\u0e01\u0e34\u0e14\u0e02\u0e36\u0e49\u0e19\u0e14\u0e31\u0e07\u0e01\u0e25\u0e48\u0e32\u0e27\u0e08\u0e36\u0e07\u0e40\u0e1b\u0e47\u0e19\u0e41\u0e23\u0e07\u0e08\u0e39\u0e07\u0e43\u0e08\u0e2b\u0e25\u0e31\u0e01\u0e43\u0e19\u0e01\u0e32\u0e23\u0e40\u0e02\u0e49\u0e32\u0e01\u0e32\u0e23\u0e41\u0e02\u0e48\u0e07\u0e02\u0e31\u0e19\u0e04\u0e23\u0e31\u0e49\u0e07\u0e19\u0e35\u0e49 \u0e42\u0e14\u0e22\u0e01\u0e32\u0e23\u0e17\u0e33\u0e19\u0e32\u0e22\u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21\u0e08\u0e32\u0e01 twitter \u0e27\u0e48\u0e32\u0e40\u0e1b\u0e47\u0e19\u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e01\u0e31\u0e1a\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34\u0e2b\u0e23\u0e37\u0e2d\u0e44\u0e21\u0e48","3c32badb":"\n\u0e01\u0e32\u0e23\u0e01\u0e23\u0e30\u0e08\u0e32\u0e22\u0e02\u0e2d\u0e07\u0e17\u0e31\u0e49\u0e07\u0e2a\u0e2d\u0e07\u0e01\u0e23\u0e32\u0e1f\u0e14\u0e39\u0e40\u0e2b\u0e21\u0e37\u0e2d\u0e19\u0e08\u0e30\u0e40\u0e01\u0e37\u0e2d\u0e1a\u0e40\u0e17\u0e48\u0e32\u0e01\u0e31\u0e19 120 \u0e16\u0e36\u0e07 140 \u0e15\u0e31\u0e27\u0e2d\u0e31\u0e01\u0e29\u0e23\u0e43\u0e19\u0e17\u0e27\u0e35\u0e15\u0e19\u0e31\u0e49\u0e19\u0e1e\u0e1a\u0e21\u0e32\u0e01\u0e17\u0e35\u0e48\u0e2a\u0e38\u0e14\u0e43\u0e19\u0e17\u0e31\u0e49\u0e07\u0e2a\u0e2d\u0e07","7a867fc3":"### Common stopwords in tweets\n\u0e01\u0e48\u0e2d\u0e19\u0e2d\u0e37\u0e48\u0e19 \u0e40\u0e23\u0e32\u0e08\u0e30\u0e27\u0e34\u0e40\u0e04\u0e23\u0e32\u0e30\u0e2b\u0e4c\u0e17\u0e27\u0e35\u0e15\u0e14\u0e49\u0e27\u0e22\u0e04\u0e25\u0e32\u0e2a 0","54c1d06f":"## \u0e02\u0e31\u0e49\u0e19\u0e15\u0e2d\u0e19\u0e17\u0e35\u0e48 1: Importing required Libraries.\n\u0e17\u0e33\u0e01\u0e32\u0e23 import module \u0e15\u0e48\u0e32\u0e07\u0e17\u0e35\u0e48\u0e08\u0e33\u0e40\u0e1b\u0e47\u0e19\u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e43\u0e19\u0e21\u0e32\u0e43\u0e0a\u0e49\u0e43\u0e19\u0e08\u0e31\u0e14\u0e01\u0e32\u0e23\u0e01\u0e31\u0e1a\u0e04\u0e48\u0e32\u0e15\u0e48\u0e32\u0e07\u0e46 \u0e23\u0e27\u0e21\u0e16\u0e36\u0e07\u0e1f\u0e31\u0e07\u0e01\u0e4c\u0e0a\u0e31\u0e48\u0e19\u0e17\u0e35\u0e48\u0e16\u0e39\u0e01\u0e19\u0e33\u0e21\u0e32\u0e43\u0e0a\u0e49\u0e04\u0e33\u0e19\u0e27\u0e13\u0e01\u0e31\u0e1a Dataset","c066144c":"## \u0e02\u0e31\u0e49\u0e19\u0e15\u0e2d\u0e19\u0e17\u0e35\u0e48 6: WordCloud\nThanks to https:\/\/www.kaggle.com\/arthurtok\/spooky-nlp-and-topic-modelling-tutorial","9f2657f9":"## \u0e02\u0e31\u0e49\u0e19\u0e15\u0e2d\u0e19\u0e17\u0e35\u0e48 7: Bag of Words","4c0f150f":"### Removing punctuations","140210d1":"### Removing HTML tags","87639bf7":"### Analyzing punctuations\n\u0e01\u0e48\u0e2d\u0e19\u0e2d\u0e37\u0e48\u0e19\u0e21\u0e32\u0e15\u0e23\u0e27\u0e08\u0e2a\u0e2d\u0e1a\u0e17\u0e27\u0e35\u0e15\u0e17\u0e35\u0e48\u0e23\u0e30\u0e1a\u0e38\u0e16\u0e36\u0e07\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34\u0e08\u0e23\u0e34\u0e07","f8575576":"## \u0e02\u0e31\u0e49\u0e19\u0e15\u0e2d\u0e19\u0e17\u0e35\u0e48 10: Baseline Model","dd871b52":"### Number of characters in tweets","e11f825f":"\u0e2d\u0e22\u0e48\u0e32\u0e07\u0e17\u0e35\u0e48\u0e40\u0e2b\u0e47\u0e19\u0e43\u0e19\u0e01\u0e23\u0e32\u0e1f \u0e21\u0e35\u0e01\u0e32\u0e23\u0e41\u0e08\u0e01\u0e41\u0e08\u0e07\u0e04\u0e25\u0e32\u0e2a \u0e21\u0e35\u0e17\u0e27\u0e35\u0e15\u0e17\u0e35\u0e48\u0e21\u0e35\u0e04\u0e25\u0e32\u0e2a 0 (\u0e44\u0e21\u0e48\u0e21\u0e35\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34) \u0e21\u0e32\u0e01\u0e01\u0e27\u0e48\u0e32\u0e04\u0e25\u0e32\u0e2a 1 (\u0e17\u0e27\u0e35\u0e15\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34)","5ba3fe7e":"### Removing urls","533b09b6":"## \u0e02\u0e31\u0e49\u0e19\u0e15\u0e2d\u0e19\u0e17\u0e35\u0e48 3: Class distribution\n\u0e01\u0e48\u0e2d\u0e19\u0e17\u0e35\u0e48\u0e40\u0e23\u0e32\u0e08\u0e30\u0e40\u0e23\u0e34\u0e48\u0e21\u0e15\u0e49\u0e19\u0e01\u0e31\u0e19 \u0e43\u0e2b\u0e49\u0e15\u0e23\u0e27\u0e08\u0e2a\u0e2d\u0e1a\u0e01\u0e32\u0e23\u0e01\u0e23\u0e30\u0e08\u0e32\u0e22\u0e04\u0e25\u0e32\u0e2a \u0e21\u0e35\u0e40\u0e1e\u0e35\u0e22\u0e07\u0e2a\u0e2d\u0e07\u0e04\u0e25\u0e32\u0e2a\u0e04\u0e37\u0e2d 0 \u0e41\u0e25\u0e30 1","767a7e97":"## Dataset \u0e17\u0e35\u0e48\u0e16\u0e39\u0e01\u0e19\u0e33\u0e43\u0e0a\u0e49\n\u0e1b\u0e23\u0e30\u0e01\u0e2d\u0e1a\u0e44\u0e1b\u0e14\u0e49\u0e27\u0e22 3 Dataset \u0e04\u0e37\u0e2d\n\n1) train.csv : \u0e21\u0e35\u0e08\u0e33\u0e19\u0e27\u0e19\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e21\u0e14 7,613 \u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25 \u0e41\u0e25\u0e30\u0e21\u0e35 Attribute \u0e08\u0e33\u0e19\u0e27\u0e19 5 Attribute \u0e44\u0e14\u0e49\u0e41\u0e01\u0e48\n* ID : \u0e25\u0e33\u0e14\u0e31\u0e1a\u0e40\u0e25\u0e02\u0e1b\u0e23\u0e30\u0e08\u0e33\u0e15\u0e31\u0e27\n* Keyword : \u0e04\u0e33\u0e43\u0e0a\u0e49\u0e43\u0e19\u0e01\u0e32\u0e23\u0e17\u0e33\u0e19\u0e32\u0e22\n* Location : \u0e1e\u0e34\u0e01\u0e31\u0e14\u0e02\u0e2d\u0e07\u0e1c\u0e39\u0e49\u0e43\u0e0a\u0e49\u0e07\u0e32\u0e19\n* Text : \u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21\u0e17\u0e35\u0e48\u0e42\u0e1e\u0e2a\u0e15\u0e4c\n* Target : \u0e1c\u0e25\u0e01\u0e32\u0e23\u0e17\u0e33\u0e19\u0e32\u0e22\u0e27\u0e48\u0e32\u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21\u0e17\u0e35\u0e48\u0e40\u0e08\u0e2d\u0e19\u0e31\u0e49\u0e19\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e02\u0e49\u0e2d\u0e07\u0e01\u0e31\u0e1a\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34\u0e2b\u0e23\u0e37\u0e2d\u0e44\u0e21\u0e48 \u0e42\u0e14\u0e22\u0e16\u0e49\u0e32\u0e43\u0e0a\u0e48\u0e08\u0e30\u0e40\u0e1b\u0e47\u0e19 1 \u0e44\u0e21\u0e48\u0e43\u0e0a\u0e48\u0e08\u0e30\u0e40\u0e1b\u0e47\u0e19 0\n\n2) test.csv : \u0e21\u0e35\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e21\u0e14\u0e08\u0e33\u0e19\u0e27\u0e19 3,263 \u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25 \u0e41\u0e25\u0e30\u0e21\u0e35 Attribute \u0e08\u0e33\u0e19\u0e27\u0e19 4 Attribute \u0e44\u0e14\u0e49\u0e41\u0e01\u0e48\n* ID : \u0e25\u0e33\u0e14\u0e31\u0e1a\u0e40\u0e25\u0e02\u0e1b\u0e23\u0e30\u0e08\u0e33\u0e15\u0e31\u0e27\n* Keyword : \u0e04\u0e33\u0e43\u0e0a\u0e49\u0e43\u0e19\u0e01\u0e32\u0e23\u0e17\u0e33\u0e19\u0e32\u0e22\n* Location : \u0e1e\u0e34\u0e01\u0e31\u0e14\u0e02\u0e2d\u0e07\u0e1c\u0e39\u0e49\u0e43\u0e0a\u0e49\u0e07\u0e32\u0e19\n* Text : \u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21\u0e17\u0e35\u0e48\u0e42\u0e1e\u0e2a\u0e15\u0e4c\n\n3) sample_submission.csv : \u0e1c\u0e25\u0e25\u0e31\u0e1e\u0e18\u0e4c\u0e17\u0e35\u0e48\u0e44\u0e14\u0e49\u0e08\u0e32\u0e01\u0e01\u0e32\u0e23\u0e23\u0e27\u0e1a\u0e23\u0e27\u0e21\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e08\u0e32\u0e01 ID \u0e41\u0e25\u0e30 Target \u0e27\u0e48\u0e32\u0e02\u0e49\u0e2d\u0e04\u0e27\u0e32\u0e21\u0e17\u0e35\u0e48\u0e1c\u0e39\u0e49\u0e43\u0e0a\u0e49\u0e44\u0e14\u0e49\u0e42\u0e1e\u0e2a\u0e15\u0e4c\u0e25\u0e07\u0e43\u0e19\u0e41\u0e2d\u0e1e\u0e1e\u0e25\u0e34\u0e40\u0e04\u0e0a\u0e31\u0e48\u0e19 Twitter \u0e19\u0e31\u0e49\u0e19\u0e21\u0e35\u0e04\u0e27\u0e32\u0e21\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e01\u0e31\u0e1a\u0e20\u0e31\u0e22\u0e1e\u0e34\u0e1a\u0e31\u0e15\u0e34\u0e2b\u0e23\u0e37\u0e2d\u0e44\u0e21\u0e48","bb01dcbe":"\u0e15\u0e2d\u0e19\u0e19\u0e35\u0e49\u0e40\u0e23\u0e32\u0e08\u0e30\u0e27\u0e34\u0e40\u0e04\u0e23\u0e32\u0e30\u0e2b\u0e4c\u0e17\u0e27\u0e35\u0e15\u0e14\u0e49\u0e27\u0e22\u0e04\u0e25\u0e32\u0e2a 1","d5ccbbe7":"\u0e43\u0e19\u0e17\u0e31\u0e49\u0e07\u0e04\u0e39\u0e48 \"the\" \u0e08\u0e30\u0e04\u0e23\u0e2d\u0e1a\u0e07\u0e33\u0e0b\u0e36\u0e48\u0e07\u0e15\u0e32\u0e21\u0e14\u0e49\u0e27\u0e22 \"a\" \u0e43\u0e19\u0e04\u0e25\u0e32\u0e2a 0 \u0e41\u0e25\u0e30 \"in\" \u0e43\u0e19\u0e04\u0e25\u0e32\u0e2a 1","ab72570e":"## \u0e02\u0e31\u0e49\u0e19\u0e15\u0e2d\u0e19\u0e17\u0e35\u0e48 11: Making our submission","468e5ae1":"### Real Disaster","5e856696":"## \u0e02\u0e31\u0e49\u0e19\u0e15\u0e2d\u0e19\u0e17\u0e35\u0e48 9: GloVe for Vectorization\n\u0e43\u0e19\u0e17\u0e35\u0e48\u0e19\u0e35\u0e49\u0e40\u0e23\u0e32\u0e08\u0e30\u0e43\u0e0a\u0e49 GloVe pretrained corpus model \u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e41\u0e2a\u0e14\u0e07\u0e16\u0e36\u0e07\u0e04\u0e33\u0e1e\u0e39\u0e14\u0e02\u0e2d\u0e07\u0e40\u0e23\u0e32 \u0e21\u0e35\u0e43\u0e2b\u0e49\u0e40\u0e25\u0e37\u0e2d\u0e01 3 \u0e41\u0e1a\u0e1a: 50D, 100D \u0e41\u0e25\u0e30 200 Dimentional \u0e0b\u0e36\u0e48\u0e07\u0e40\u0e23\u0e32\u0e08\u0e30\u0e25\u0e2d\u0e07 100 D \u0e17\u0e35\u0e48\u0e19\u0e35\u0e48","4f1cdac9":"### Non Disaster","7ac99156":"### Common words ?","b658d311":"## \u0e02\u0e31\u0e49\u0e19\u0e15\u0e2d\u0e19\u0e17\u0e35\u0e48 2: Loading the data and getting basic idea","f1610358":"### Average word length in a tweet","c3a4c5f7":"### Number of words in a tweet","62aa582c":"### Removing Emojis","21b2a7e4":"### Visualizing the embeddings","d714801e":"### Ngram analysis\n\u0e40\u0e23\u0e32\u0e08\u0e30\u0e17\u0e33\u0e01\u0e32\u0e23\u0e27\u0e34\u0e40\u0e04\u0e23\u0e32\u0e30\u0e2b\u0e4c bigram (n = 2) \u0e43\u0e19\u0e17\u0e27\u0e35\u0e15 \u0e14\u0e49\u0e27\u0e22\u0e01\u0e32\u0e23\u0e15\u0e23\u0e27\u0e08\u0e2a\u0e2d\u0e1a bigrams \u0e17\u0e35\u0e48\u0e1e\u0e1a\u0e1a\u0e48\u0e2d\u0e22\u0e17\u0e35\u0e48\u0e2a\u0e38\u0e14\u0e43\u0e19\u0e17\u0e27\u0e35\u0e15"}}