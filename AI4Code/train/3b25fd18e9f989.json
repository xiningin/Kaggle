{"cell_type":{"5b61774d":"code","3009a0db":"code","548e2c4a":"code","299beebb":"code","9bec5bb9":"code","d6b8ec93":"code","f41a3179":"code","7e599e39":"code","465af5ef":"code","6ed2ee5e":"code","673a2d5a":"code","80da8b55":"code","37df27c1":"code","fc137a38":"code","af8dcbd8":"code","8a9de267":"code","75e267ff":"code","856927ce":"code","efccd80d":"code","5427055f":"code","0dc287f5":"code","19b223bd":"code","0a8cc6c9":"code","571333d3":"markdown","5e2578cc":"markdown","7547d33c":"markdown","ced0db59":"markdown","f89377ba":"markdown","22a1c1f1":"markdown","5af16024":"markdown","504ab0f4":"markdown"},"source":{"5b61774d":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport os\nimport matplotlib.pyplot as plt\nfrom subprocess import check_output\nprint(os.listdir(\"..\/input\"))\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n","3009a0db":"iris = pd.read_csv(\"..\/input\/Iris.csv\") #load the dataset\niris.head(5)","548e2c4a":"iris.info()","299beebb":"iris.drop('Id',axis=1,inplace =True) #drop Id from column which also reflects in data frame","9bec5bb9":"fig =iris[iris.Species=='Iris-setosa'].plot(kind ='scatter',x='SepalLengthCm',y ='SepalWidthCm',color ='orange', \n                                           label ='Setosa')\niris[iris.Species=='Iris-versicolor'].plot(kind ='scatter',x='SepalLengthCm',y ='SepalWidthCm',color ='blue', \n                                           label ='Versicolor',ax= fig)\niris[iris.Species=='Iris-virginica'].plot(kind='scatter',x='SepalLengthCm',y='SepalWidthCm',color='green', \n                                          label='Virginica', ax=fig)\nfig.set_title(\"Sepal Length VS Width\")\nfig.set_xlabel('Sepal Length')\nfig.set_ylabel('Sepal Width')\nfig=plt.gcf() #get current figure\nfig.set_size_inches(10,6) #enlarges the graph\nplt.show()","d6b8ec93":"fig =iris[iris.Species=='Iris-setosa'].plot(kind ='scatter',x='PetalLengthCm',y ='PetalWidthCm',color ='orange', \n                                           label ='Setosa')\niris[iris.Species=='Iris-versicolor'].plot(kind ='scatter',x='PetalLengthCm',y ='PetalWidthCm',color ='blue', \n                                           label ='Versicolor',ax= fig)\niris[iris.Species=='Iris-virginica'].plot(kind='scatter',x='PetalLengthCm',y='PetalWidthCm',color='green', \n                                          label='Virginica', ax=fig)\nfig.set_title(\"Petal Length VS Width\")\nfig.set_xlabel('Petal Length')\nfig.set_ylabel('Petal Width')\nfig=plt.gcf() #get current figure\nfig.set_size_inches(10,6) #enlarges the graph\nplt.show()","f41a3179":"iris.hist(edgeColor='black',linewidth=1.2)\nfig=plt.gcf()\nfig.set_size_inches(12,6)\nplt.show()","7e599e39":"plt.figure(figsize=(15,10))\nplt.subplot(2,2,1)\nsns.violinplot(x='Species',y='SepalLengthCm',data=iris)\nplt.subplot(2,2,2)\nsns.violinplot(x='Species',y='SepalWidthCm',data=iris)\nplt.subplot(2,2,3)\nsns.violinplot(x='Species',y='PetalLengthCm',data=iris)\nplt.subplot(2,2,4)\nsns.violinplot(x='Species',y='PetalWidthCm',data =iris)","465af5ef":"from sklearn.linear_model import LogisticRegression\n#from sklearn.cross_validation import train_test_split ---- this is depreciated\nfrom sklearn.model_selection import train_test_split #to split the dataset for training and testing\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import svm\nfrom sklearn import metrics #for checking model accuracy\nfrom sklearn.tree import DecisionTreeClassifier","6ed2ee5e":"iris.shape","673a2d5a":"plt.figure(figsize=(7,5))\nsns.heatmap(data =iris.corr(),annot=True,cmap='cubehelix_r')","80da8b55":"train, test =train_test_split(iris, test_size =0.3)\nprint(train.shape)\nprint(test.shape)","37df27c1":"train_x =train[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]\ntrain_y =train[['Species']]\ntest_x =test[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]\ntest_y =test[['Species']]","fc137a38":"model =svm.SVC()\nmodel.fit(train_x,train_y)\nprediction =model.predict(test_x)\nprint(\"The accuracy of the SVM model is\",metrics.accuracy_score(prediction,test_y))","af8dcbd8":"model =LogisticRegression()\nmodel.fit(train_x,train_y)\npredictions =model.predict(test_x)\nprint(\"The accuracy with Logistic Regression is \",metrics.accuracy_score(predictions,test_y))","8a9de267":"model=KNeighborsClassifier(n_neighbors=3) #this examines 3 neighbours for putting the new data into a class\nmodel.fit(train_x,train_y)\nprediction=model.predict(test_x)\nprint('The accuracy of the KNN is',metrics.accuracy_score(prediction,test_y))","75e267ff":"a_index=list(range(1,11))\na=pd.Series()\nx=[1,2,3,4,5,6,7,8,9,10]\nfor i in list(range(1,11)):    \n    model=KNeighborsClassifier(n_neighbors=i) \n    model.fit(train_x,train_y)\n    prediction=model.predict(test_x)\n    a=a.append(pd.Series(metrics.accuracy_score(prediction,test_y)))\nplt.plot(a_index, a)\nplt.xticks(x) #marks x-axis ","856927ce":"petal=iris[['PetalLengthCm','PetalWidthCm','Species']]\nsepal=iris[['SepalLengthCm','SepalWidthCm','Species']]","efccd80d":"train_p,test_p=train_test_split(petal,test_size=0.3,random_state=0)  #petals\ntrain_x_p=train_p[['PetalWidthCm','PetalLengthCm']]\ntrain_y_p=train_p[['Species']]\ntest_x_p=test_p[['PetalWidthCm','PetalLengthCm']]\ntest_y_p=test_p[['Species']]\n\n\ntrain_s,test_s=train_test_split(sepal,test_size=0.3,random_state=0)  #Sepal\ntrain_x_s=train_s[['SepalWidthCm','SepalLengthCm']]\ntrain_y_s=train_s.Species\ntest_x_s=test_s[['SepalWidthCm','SepalLengthCm']]\ntest_y_s=test_s.Species","5427055f":"model =svm.SVC()\nmodel.fit(train_x_p,train_y_p)\nprediction =model.predict(test_x_p)\nprint(\"The accuracy of SVM model with petals as features are\",metrics.accuracy_score(prediction,test_y_p))\n\nmodel =svm.SVC()\nmodel.fit(train_x_s,train_y_s)\nprediction =model.predict(test_x_s)\nprint(\"The accuracy of SVM model with sepals as features are\",metrics.accuracy_score(prediction,test_y_p))","0dc287f5":"model = LogisticRegression()\nmodel.fit(train_x_p,train_y_p) \nprediction=model.predict(test_x_p) \nprint('The accuracy of the Logistic Regression using Petals is:',metrics.accuracy_score(prediction,test_y_p))\n\nmodel.fit(train_x_s,train_y_s) \nprediction=model.predict(test_x_s) \nprint('The accuracy of the Logistic Regression using Sepals is:',metrics.accuracy_score(prediction,test_y_s))","19b223bd":"model=DecisionTreeClassifier()\nmodel.fit(train_x_p,train_y_p) \nprediction=model.predict(test_x_p) \nprint('The accuracy of the Decision Tree using Petals is:',metrics.accuracy_score(prediction,test_y_p))\n\nmodel.fit(train_x_s,train_y_s) \nprediction=model.predict(test_x_s) \nprint('The accuracy of the Decision Tree using Sepals is:',metrics.accuracy_score(prediction,test_y_s))","0a8cc6c9":"model=KNeighborsClassifier(n_neighbors=3) \nmodel.fit(train_x_p,train_y_p) \nprediction=model.predict(test_x_p) \nprint('The accuracy of the KNN using Petals is:',metrics.accuracy_score(prediction,test_y_p))\n\nmodel.fit(train_x_s,train_y_s) \nprediction=model.predict(test_x_s) \nprint('The accuracy of the KNN using Sepals is:',metrics.accuracy_score(prediction,test_y_s))","571333d3":"## Observation\n##### Petal Length and Petal Width are highly correlated. Sepal Length and Sepal Width are barely correlated\n##### Now, I split the dataset in train and test data in 7:3 ratio","5e2578cc":"### SVM on Petals as features","7547d33c":"## Support Vector Machine algorithm\n##### we use .fit() for training and .predict(testXLabels) for prediction","ced0db59":"### Histogram is plotted here to note the frequency of distribution","f89377ba":"##### As you can see SVM gives very good accuracy. Lets check with other algorithms too","22a1c1f1":"### Since this is a classification problem, I am trying here various classification algorithms","5af16024":"# Extrapolatory Data Analysis","504ab0f4":"##### It is important to check the correlation between features because if many features are correlated, then training algorithm with all those features will reduce the accuracy of model. If your dataset has perfectly positive or negative attributes then there is a high chance that the performance of the model will be impacted by a problem called\u200a\u2014\u200a\u201cMulticollinearity\u201d, to know more about it [see here](https:\/\/towardsdatascience.com\/why-feature-correlation-matters-a-lot-847e8ba439c4). Even though this dataset has less features, we will see correlation"}}