{"cell_type":{"41d47bc4":"code","f527eafd":"code","e025d80d":"code","de3fd4fd":"code","630233ba":"code","cdad89f0":"code","f4492560":"code","fd947d02":"code","43e3046b":"code","0d8c530c":"code","637eeba2":"code","ee0b3c16":"code","da9e016b":"code","673ee56e":"code","6a0f08b6":"code","52adf67e":"code","57bb7ff0":"code","5aaeea0c":"code","a68a3a74":"code","3b4b29d6":"code","45a1e330":"code","cbe3c5f1":"code","dfdbd49c":"code","f90917be":"code","c03bb863":"code","a2ecdd24":"code","37f203f1":"code","1cba83c5":"code","f7502cf7":"code","133ea622":"code","eeeedcc0":"code","090a5ecb":"code","f1599427":"code","57c9f0c6":"code","e0d62097":"code","51030a47":"code","07285544":"code","0400ca3c":"code","997a33e5":"code","a3dda7e2":"code","c9259cb1":"code","caa8c48c":"markdown","6085c389":"markdown","097acfed":"markdown","f308009f":"markdown"},"source":{"41d47bc4":"#!nvidia-smi","f527eafd":"!git clone https:\/\/github.com\/fizyr\/keras-retinanet.git","e025d80d":"!pip install --upgrade keras","de3fd4fd":"%cd keras-retinanet\/\n\n!pip install .","630233ba":"!python setup.py build_ext --inplace","cdad89f0":"!pip install gdown\n!pip install tensorflow-gpu","f4492560":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport pandas as pd\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom pandas.plotting import register_matplotlib_converters\nfrom sklearn.model_selection import train_test_split\nimport urllib\nimport os\nimport csv\nimport cv2\nimport time\nfrom PIL import Image\n\nfrom keras_retinanet import models\nfrom keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\nfrom keras_retinanet.utils.visualization import draw_box, draw_caption\nfrom keras_retinanet.utils.colors import label_color\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nregister_matplotlib_converters()\nsns.set(style='whitegrid', palette='muted', font_scale=1.5)\n\nrcParams['figure.figsize'] = 22, 10\n\nRANDOM_SEED = 42\n\nnp.random.seed(RANDOM_SEED)\ntf.random.set_seed(RANDOM_SEED)","fd947d02":"!gdown --id 1mTtB8GTWs74Yeqm0KMExGJZh1eDbzUlT --output indian_number_plates.json","43e3046b":"os.makedirs(\"snapshots\", exist_ok=True)","0d8c530c":"!gdown --id 1wPgOBoSks6bTIs9RzNvZf6HWROkciS8R --output snapshots\/resnet50_csv_10.h5","637eeba2":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ee0b3c16":"! ls \/kaggle\/input","da9e016b":"\nplates_df = pd.read_csv('\/kaggle\/input\/vottexp\/vott-csv-export\/ANPR-export.csv')","673ee56e":"os.makedirs(\"vott-csv-export\", exist_ok=True)","6a0f08b6":"plates_df","52adf67e":"plates_df['newImage'] = 'vott-csv-export\/'+plates_df.image\nplates_df['xmin']=plates_df['xmin'].apply(round)\nplates_df['ymin']=plates_df['ymin'].apply(round)\nplates_df['xmax']=plates_df['xmax'].apply(round)\nplates_df['ymax']=plates_df['ymax'].apply(round)\nplates_df.head()","57bb7ff0":"'''\ndataset = dict()\ndataset[\"image_name\"] = list()\ndataset[\"x_min\"] = list()\ndataset[\"y_min\"] = list()\ndataset[\"x_max\"] = list()\ndataset[\"y_max\"] = list()\ndataset[\"class_name\"] = list()\n\ncounter = 0\nfor index, row in plates_df.iterrows():\n    img = urllib.request.urlopen(row[\"content\"])\n    img = Image.open(img)\n    img = img.convert('RGB')\n    img.save(f'number_plates\/licensed_car_{counter}.jpeg', \"JPEG\")\n    \n    dataset[\"image_name\"].append(f'number_plates\/licensed_car_{counter}.jpeg')\n    \n    data = row[\"annotation\"]\n  \n    width = data[0][\"imageWidth\"]\n    height = data[0][\"imageHeight\"]\n\n    dataset[\"x_min\"].append(int(round(data[0][\"points\"][0][\"x\"] * width)))\n    dataset[\"y_min\"].append(int(round(data[0][\"points\"][0][\"y\"] * height)))\n    dataset[\"x_max\"].append(int(round(data[0][\"points\"][1][\"x\"] * width)))\n    dataset[\"y_max\"].append(int(round(data[0][\"points\"][1][\"y\"] * height)))\n    dataset[\"class_name\"].append(\"license_plate\")\n    \n    counter += 1\nprint(\"Downloaded {} car images.\".format(counter))\n'''","5aaeea0c":"df = plates_df.drop('image',axis=1)\ndf = df.iloc[:,[5,0,1,2,3,4]]\ndf.head()","a68a3a74":"def show_image_objects(image_row):\n\n  img_path = image_row.newImage\n  box = [\n    image_row.xmin, image_row.ymin, image_row.xmax, image_row.ymax\n  ]\n\n  image = read_image_bgr(img_path)\n\n  draw = image.copy()\n  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n\n  draw_box(draw, box, color=(255, 255, 0))\n\n  plt.axis('off')\n  plt.imshow(draw)\n  plt.show()","3b4b29d6":"! pwd","45a1e330":"show_image_objects(df.iloc[0])","cbe3c5f1":"show_image_objects(df.iloc[5])","dfdbd49c":"df","f90917be":"train_df, test_df = train_test_split(\n  df, \n  test_size=0.2, \n  random_state=RANDOM_SEED\n)","c03bb863":"ANNOTATIONS_FILE = 'annotations.csv'\nCLASSES_FILE = 'classes.csv'","a2ecdd24":"train_df.to_csv(ANNOTATIONS_FILE, index=False, header=None)","37f203f1":"classes = set(['license_plate'])\n\nwith open(CLASSES_FILE, 'w') as f:\n  for i, line in enumerate(sorted(classes)):\n    f.write('{},{}\\n'.format(line,i))","1cba83c5":"!head classes.csv","f7502cf7":"!head annotations.csv","133ea622":"PRETRAINED_MODEL = '.\/snapshots\/_pretrained_model.h5'\n\nURL_MODEL = 'https:\/\/github.com\/fizyr\/keras-retinanet\/releases\/download\/0.5.1\/resnet50_coco_best_v2.1.0.h5'\nurllib.request.urlretrieve(URL_MODEL, PRETRAINED_MODEL)\n\nprint('Downloaded pretrained model to ' + PRETRAINED_MODEL)","eeeedcc0":"!keras_retinanet\/bin\/train.py --freeze-backbone --random-transform --weights {PRETRAINED_MODEL} --batch-size 8 --steps 500 --epochs 10 csv annotations.csv classes.csv","090a5ecb":"!ls snapshots","f1599427":"model_path = os.path.join('snapshots', sorted(os.listdir('snapshots'), reverse=True)[0])\nprint(model_path)\n\nmodel = models.load_model(model_path, backbone_name='resnet50')\nmodel = models.convert_model(model)\n\nlabels_to_names = pd.read_csv(CLASSES_FILE, header=None).T.loc[0].to_dict()","57c9f0c6":"def predict(image):\n  image = preprocess_image(image.copy())\n  image, scale = resize_image(image)\n\n  boxes, scores, labels = model.predict_on_batch(\n    np.expand_dims(image, axis=0)\n  )\n\n  boxes \/= scale\n\n  return boxes, scores, labels","e0d62097":"THRES_SCORE = 0.1\n\ndef draw_detections(image, boxes, scores, labels):\n  for box, score, label in zip(boxes[0], scores[0], labels[0]):\n    if score < THRES_SCORE:\n        break\n\n    color = label_color(label)\n\n    b = box.astype(int)\n    draw_box(image, b, color=color)\n\n    caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n    draw_caption(image, b, caption)\n","51030a47":"def show_detected_objects(image_row):\n  img_path = image_row.newImage\n  \n  image = read_image_bgr(img_path)\n\n  boxes, scores, labels = predict(image)\n\n  draw = image.copy()\n  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n\n  true_box = [\n    image_row.xmin, image_row.ymin, image_row.xmax, image_row.ymax\n  ]\n  draw_box(draw, true_box, color=(255, 255, 0))\n\n  draw_detections(draw, boxes, scores, labels)\n\n  plt.axis('off')\n  plt.imshow(draw)\n  plt.show()","07285544":"test_df.head(n=10)","0400ca3c":"show_detected_objects(test_df.iloc[0])","997a33e5":"show_detected_objects(test_df.iloc[1])","a3dda7e2":"show_detected_objects(test_df.iloc[2])","c9259cb1":"test_df","caa8c48c":"# Preprocessing","6085c389":"# Training","097acfed":"# Loading the trained model","f308009f":"# Predictions"}}