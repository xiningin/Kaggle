{"cell_type":{"ddd5f0b6":"code","b2bd3758":"code","77671097":"code","6a5c7867":"code","144af8dc":"code","25f8a21a":"code","a04f35c4":"code","5941c1fb":"code","6ba25e80":"code","2ad99ce7":"code","335e6196":"code","ff0ade0d":"code","7558e02b":"code","a9cd8c47":"markdown","8d04dd9c":"markdown","ad5852ad":"markdown","06ac5daf":"markdown","6e678d2c":"markdown","e861710c":"markdown"},"source":{"ddd5f0b6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b2bd3758":"from tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os, cv2 \nfrom multiprocessing import Pool\nimport threading","77671097":"! mkdir -p \/root\/.kaggle\/\n! cp ..\/input\/api-token\/kaggle.json \/root\/.kaggle\/kaggle.json\n! mkdir -p \/kaggle\/tmp\/hpa_512x512_dataset\n! kaggle datasets init -p \/kaggle\/tmp\/hpa_512x512_dataset","6a5c7867":"%%bash\necho \"{\n  \\\"title\\\": \\\"HPA: 512x512 dataset\\\",\n  \\\"id\\\": \\\"tchaye59\/HPA512x512DATASET\\\",\n  \\\"licenses\\\": [\n    {\n      \\\"name\\\": \\\"CC0-1.0\\\"\n    }\n  ]\n}\" > \/kaggle\/tmp\/hpa_512x512_dataset\/dataset-metadata.json","144af8dc":"DATA_DIR = \"..\/input\/hpa-single-cell-image-classification\/\"\nTRAIN_DIR = os.path.join(DATA_DIR,\"train\/\")\nTEST_DIR = os.path.join(DATA_DIR,\"test\/\")\n\nDS_DIR = '\/kaggle\/tmp\/hpa_512x512_dataset\/'\ntrain_df = pd.read_csv('..\/input\/hpa-single-cell-image-classification\/train.csv')\ntest_df = pd.read_csv('..\/input\/hpa-single-cell-image-classification\/sample_submission.csv')","25f8a21a":"# Runs a process in a thread\nclass Worker(threading.Thread):\n    \n    def __init__(self, process,args,pbar=None):\n        super().__init__()\n        self.pbar = pbar\n        self.process = process\n        self.args = args\n\n    def run(self):\n        res = self.process(self.args)\n        if self.pbar:\n            self.pbar.update(1)","a04f35c4":"def rgb_worker_fn(args):\n    id_,src_path,dest_path,rgb_dest_dir = args\n    dim = (512, 512)\n    \n    red_image = cv2.imread(src_path+id_+\"_red.png\", cv2.IMREAD_UNCHANGED)\n    red_image = cv2.resize(red_image, dim, interpolation = cv2.INTER_AREA)\n    cv2.imwrite(dest_path+id_+\"_red.png\" , red_image)\n    \n    green_image = cv2.imread(src_path+id_+\"_green.png\", cv2.IMREAD_UNCHANGED)\n    green_image = cv2.resize(green_image, dim, interpolation = cv2.INTER_AREA)\n    cv2.imwrite(dest_path+id_+\"_green.png\" , green_image)\n    \n    blue_image = cv2.imread(src_path+id_+\"_blue.png\", cv2.IMREAD_UNCHANGED)\n    blue_image = cv2.resize(blue_image, dim, interpolation = cv2.INTER_AREA)\n    cv2.imwrite(dest_path+id_+\"_blue.png\" , blue_image)\n    \n    yellow_image = cv2.imread(src_path+id_+\"_yellow.png\", cv2.IMREAD_UNCHANGED)\n    yellow_image = cv2.resize(yellow_image, dim, interpolation = cv2.INTER_AREA)\n    cv2.imwrite(dest_path+id_+\"_yellow.png\" , yellow_image)\n        \n    image = np.array([red_image, green_image, blue_image,])\n    image = np.transpose(image, (1,2,0))\n    #image=image.astype(np.uint8) \n    cv2.imwrite(rgb_dest_dir+id_+\".png\" , image)","5941c1fb":"ids = train_df.ID.values\nsrc_dir  =  TRAIN_DIR\ndest_dir = DS_DIR+'train\/'\nrgb_dest_dir =  DS_DIR+'rgb_train\/'\nos.makedirs(dest_dir,exist_ok=True)\nos.makedirs(rgb_dest_dir,exist_ok=True)","6ba25e80":"size = len(ids)\npbar = tqdm(total=size)\nn = 1000\nfor i in range(0,size,n):\n    workers = []\n    for id_ in ids[i:min(size,i+n)]:\n        worker =  Worker(rgb_worker_fn,(id_,src_dir,dest_dir,rgb_dest_dir),pbar=pbar)\n        worker.start()\n        workers.append(worker)\n    for worker in workers:\n        worker.join()","2ad99ce7":"ids = test_df.ID.values\nsrc_dir  =  TEST_DIR\ndest_dir = DS_DIR+'test\/'\nrgb_dest_dir =  DS_DIR+'rgb_test\/'\nos.makedirs(dest_dir,exist_ok=True)\nos.makedirs(rgb_dest_dir,exist_ok=True)","335e6196":"size = len(ids)\npbar = tqdm(total=size)\nn = 1000\nfor i in range(0,size,n):\n    workers = []\n    for id_ in ids[i:min(size,i+n)]:\n        worker =  Worker(rgb_worker_fn,(id_,src_dir,dest_dir,rgb_dest_dir),pbar=pbar)\n        worker.start()\n        workers.append(worker)\n    for worker in workers:\n        worker.join()","ff0ade0d":"! kaggle datasets version -p \/kaggle\/tmp\/hpa_512x512_dataset -m \"add rgb images\"  --dir-mode tar\n#! kaggle datasets create -p \/kaggle\/tmp\/hpa_512x512_dataset\/ -u --dir-mode tar","7558e02b":"! rm -rf \/root\/.kaggle\/kaggle.json","a9cd8c47":"# Testing images","8d04dd9c":"# Training images","ad5852ad":"Initialize the Kaggle API with my Auth token and the dataset metadata","06ac5daf":"# This notebook creates a new dataset by resizing each single image","6e678d2c":"# Build dataset","e861710c":"Dataset link : https:\/\/www.kaggle.com\/tchaye59\/hpa512x512dataset"}}