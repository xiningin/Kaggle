{"cell_type":{"d008711e":"code","35f16f03":"code","14edf638":"code","a07766c2":"code","d430ef76":"code","c32e4b6c":"code","3c19a851":"code","5d08b03e":"code","3f1f4458":"code","d3e692dc":"code","dbf3d25b":"code","d3370049":"code","c808fc11":"code","6851b7d6":"code","e4600a77":"code","9024abdf":"code","a3de311f":"code","62c4ee75":"code","0b9382f2":"code","ec4ab606":"code","fc8b13de":"code","d77339ea":"code","12325db2":"code","fe634e00":"code","ce237755":"code","18d6b05d":"code","5eb27b19":"code","1b8c71cb":"code","ab99147c":"code","c764204a":"code","52b1aed5":"code","ceb7201d":"code","6fe2809e":"markdown","70f0323a":"markdown","06a676cc":"markdown","23725d53":"markdown","8a28fb07":"markdown","03a01533":"markdown","86c4eb28":"markdown","5230fcc5":"markdown","1b3f875f":"markdown","540ca665":"markdown","ec1a4101":"markdown","0c305359":"markdown","247f89a5":"markdown","25f029b7":"markdown"},"source":{"d008711e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport torch\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport torch.nn.functional as F\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","35f16f03":"def show_image(image,label,get_denormalize=True):\n    image=image.permute(1,2,0)\n    # PyTorch modules dealing with image data require tensors to be laid out as (C \u00d7 H \u00d7 W) : channels, height, and width, respectively.\n    # Note how we have to use permute to change the order of the axes from (C \u00d7 H \u00d7 W) to (H \u00d7 W \u00d7 C) to match what Matplotlib expects.\n    mean=torch.FloatTensor([0.485,0.456,0.406])\n    std=torch.FloatTensor([0.229,0.224,0.225]) \n    # for normalizing the data\n    \n    \n    if get_denormalize==True:\n        image=image*std+mean # normalizing\n        image=np.clip(image,0,1) \n        # Given an interval, values outside the interval are clipped to the interval edges.\n        # For example, if an interval of [0, 1] is specified, values smaller than 0 become 0, and values larger than 1 become 1.\n        plt.imshow(image)\n        plt.title(label)\n        \n    else:\n        plt.imshow(image)\n        plt.title(label)","14edf638":"def show_grid(image,title=None):\n    image=image.permute(1,2,0)\n    mean=torch.FloatTensor([0.485,0.456,0.406])\n    std=torch.FloatTensor([0.229,0.224,0.225])\n\n    image=image*std+mean\n    image=np.clip(image,0,1)\n    \n    plt.figure(figsize=(15,15))\n    plt.imshow(image)\n    \n    if title!=None:\n        plt.title(title)","a07766c2":"def accuracy(y_pred,y_true):\n    y_pred=F.softmax(y_pred,dim=1) #applying softmax\n    top_p,top_class=y_pred.topk(1,dim=1) \n    # topk Returns the k largest elements (here k=1) of the given input tensor along a given dimension.\n    # If dim is not given, the last dimension of the input is chosen.\n    \n    equals=top_class==y_true.view(*top_class.shape) \n    # View function returns a new tensor with the same data as the self tensor but of a different shape.\n    # comparing the topmost class with the true value from y_true\n    \n    return torch.mean(equals.type(torch.FloatTensor))","d430ef76":"def view_classify(image,ps,label):\n    class_name=['NORMAL','PNEUMONIA']\n    classes=np.array(class_name)\n    \n    ps=ps.cpu().data.numpy().squeeze()\n    # numpy.squeeze() function is used when we want to remove single-dimensional entries from the shape of an array.\n    \n    image = image.permute(1,2,0)\n    mean = torch.FloatTensor([0.485, 0.456, 0.406])\n    std = torch.FloatTensor([0.229, 0.224, 0.225])\n    \n    image = image*std + mean\n    img = np.clip(image,0,1)\n    \n    fig,(ax1,ax2)=plt.subplots(figsize=(8,12),ncols=2)\n    \n    ax1.imshow(img)\n    ax1.set_title('Ground Truth : {}'.format(class_name[label]))\n    ax1.axis('off') # turns the axis off\n    \n    \n    ax2.barh(classes,ps) \n    # Make a horizontal bar plot.\n    ax2.set_aspect(0.1)\n    ax2.set_yticks(classes) # yticks is the data range on the y axis\n    ax2.set_yticklabels(classes)\n    ax2.set_title('Predicted Class-')\n    ax2.set_xlim(0,1.1) # sets the x axis limits\n    \n    plt.tight_layout()\n    \n    return None","c32e4b6c":"class CFG:\n    epochs=20            # No. of epochs for training the model\n    lr = 0.001           # Learning rate\n    batch_size = 16      # Batch Size for Dataset\n    \n    \n    model_name = 'tf_efficientnet_b4_ns'# Model name to import from timm\n    img_size=224 # resize all images to 224*224\n    \n    train_path='..\/input\/chest-xray-pneumonia\/chest_xray\/train'\n    test_path='..\/input\/chest-xray-pneumonia\/chest_xray\/test'\n    validate_path='..\/input\/chest-xray-pneumonia\/chest_xray\/val'\n    \n    \ndevice=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device we are on:{}\".format(device))\n    ","3c19a851":"from torchvision import transforms as T,datasets","5d08b03e":"train_transform=T.Compose([\n                            T.Resize(size=(CFG.img_size,CFG.img_size)),# Resizing the image to be 224 by 224\n    \n                            T.RandomRotation(degrees=(-20,+20)),#Randomly Rotate Images by +\/- 20 degrees \n                            # Image argumentation for each epoch\n    \n                            T.ToTensor(), # converting the dimension from (height,weight,channel) to (channel,height,weight) \n                            # convention of PyTorch\n    \n                            T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) # Normalize by 3 means 3 StD's of the image net, 3 channels\n    \n                            ]) # Composes several transforms together. \n\n\nvalidate_transform=T.Compose([\n                            T.Resize(size=(CFG.img_size,CFG.img_size)),# Resizing the image to be 224 by 224\n    \n                            #T.RandomRotation(degrees=(-20,+20)) # no need in validation\n    \n                            T.ToTensor(), # converting the dimension from (height,weight,channel) to (channel,height,weight) \n                            # convention of PyTorch\n    \n                            T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) # Normalize by 3 means 3 StD's of the image net, 3 channels\n    \n                            ]) # Composes several transforms together. \n\n\ntest_transform=T.Compose([\n                            T.Resize(size=(CFG.img_size,CFG.img_size)),# Resizing the image to be 224 by 224\n    \n                            # T.RandomRotation(degrees=(-20,+20)) # no need in test\n    \n                            T.ToTensor(), # converting the dimension from (height,weight,channel) to (channel,height,weight) \n                            # convention of PyTorch\n    \n                            T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]) # Normalize by 3 means 3 StD's of the image net, 3 channels\n    \n                            ]) # Composes several transforms together. \n","3f1f4458":"trainset=datasets.ImageFolder(CFG.train_path,transform=train_transform) # loading the training set with transformation\nprint(\"Trainset Size: {}\".format(len(trainset)))","d3e692dc":"validateset=datasets.ImageFolder(CFG.validate_path,transform=validate_transform) # loading the validation set with transformation\nprint(\"Validateset Size: {}\".format(len(validateset)))","dbf3d25b":"testset=datasets.ImageFolder(CFG.test_path,transform=test_transform) # loading the test set with transformation\nprint(\"Testset Size: {}\".format(len(testset)))","d3370049":"img,label=trainset[1]\nclass_name=['NORMAL','PNEUMONIA']\nshow_image(img,class_name[label])","c808fc11":"img,label=trainset[20]\nclass_name=['NORMAL','PNEUMONIA']\nshow_image(img,class_name[label])\n# print(label)\n# print(class_name[label])\n# print(img)","6851b7d6":"from torch.utils.data import DataLoader\nfrom torchvision.utils import make_grid","e4600a77":"trainloader=DataLoader(trainset,batch_size=CFG.batch_size,shuffle=True)\nprint(\"No. of batches in trainloader:{}\".format(len(trainloader))) # Trainset Size: 5216 \/ batch_size: 16 = 326(No. of batches in trainloader) \nprint(\"No. of Total examples:{}\".format(len(trainloader.dataset)))","9024abdf":"validationloader=DataLoader(validateset,batch_size=CFG.batch_size,shuffle=True)\nprint(\"No. of batches in trainloader:{}\".format(len(validationloader))) # Validationset Size: 16 \/ batch_size: 16 = 1(No. of batches in validationl)\nprint(\"No. of Total examples:{}\".format(len(validationloader.dataset)))","a3de311f":"testloader = DataLoader(testset,batch_size=CFG.batch_size,shuffle=True)\nprint(\"No. of batches in testloader:{}\".format(len(testloader))) # Testset Size:  624 \/ batch_size: 16 = 39(No. of batches in testloader) \nprint(\"No. of Total examples:{}\".format(len(testloader.dataset)))","62c4ee75":"# Basically iter() calls the __iter__() method on the data_loader which returns an iterator\n#. next() then calls the __next__() method on that iterator to get the first iteration. \n# Running next() again will get the second item of the iterator, etc.\ndataiter=iter(trainloader)\nimages,labels=dataiter.next()\n\nout=make_grid(images,nrow=4) # Make a grid of images. nrow is the number of rows of images\nshow_grid(out,title=[class_name[x] for x in labels])","0b9382f2":"!pip install timm # install pytorch image models","ec4ab606":"from torch import nn\nimport torch.nn.functional as F\nimport timm # pytorch image models\n\nmodel=timm.create_model(CFG.model_name,pretrained=True) # Load Pretrained model","fc8b13de":"model","d77339ea":"for param in model.parameters():\n    param.requires_grad=False\n    \n# If you want to freeze part of your model and train the rest, you can set requires_grad of the parameters you want to freeze to False.\n# By switching the requires_grad flags to False, no intermediate buffers will be saved,\n# until the computation gets to some point where one of the inputs of the operation requires the gradient.\n\n#orginally, it was:\n#(classifier): Linear(in_features=1792, out_features=1000, bias=True)\n\n#we are updating it as a 2-class classifier:\nmodel.classifier=nn.Sequential(\n    nn.Linear(in_features=1792,out_features=625),# 1792 is the input features originally given\n    nn.ReLU(), # RELU to be the activation function\n    nn.Dropout(p=0.3),\n    # During training, randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution.\n    # Each channel will be zeroed out independently on every forward call.\n    nn.Linear(in_features=625,out_features=256),\n    nn.ReLU(),\n    nn.Linear(in_features=256,out_features=2),\n)\n# By the above block of codes, we replace the linear classifier with a sequence of 3 layers of neurons\n# plus their ReLU activation layers and a dropout layer in the middle.","12325db2":"model\n\n\n# after updatingnow it becomes:\n#(classifier): Sequential(\n#    (0): Linear(in_features=1792, out_features=625, bias=True)\n#    (1): ReLU()\n#    (2): Dropout(p=0.3, inplace=False)\n#    (3): Linear(in_features=625, out_features=256, bias=True)\n#    (4): ReLU()\n#    (5): Linear(in_features=256, out_features=2, bias=True)\n#  )","fe634e00":"!pip install torchsummary","ce237755":"from torchsummary import  summary\nmodel.to(device) # move the model to GPU\nsummary(model,input_size=(3,224,224))","18d6b05d":"class PneumoniaTrainer():\n    \n    def __init__(self,criterion=None,optimizer=None,schedular=None):\n        self.criterion=criterion\n        self.optimizer=optimizer\n        self.schedular=schedular\n        # initialization\n        \n    def train_batch_loop(self,model,trainloader):\n        # training the model in batches\n        train_acc=0\n        train_loss=0\n        # initially both are zero \n        \n        \n        for images,labels in tqdm(trainloader):# for the progress bar and get the data from the trainloader\n            # move data to GPU\n            images=images.to(device)\n            labels=labels.to(device)\n            \n            logits=model(images)\n            loss=self.criterion(logits,labels) # calculating loss\n            \n            \n            # updating the gradient\n            self.optimizer.zero_grad() # gradients to zero\n            # n PyTorch, for every mini-batch during the training phase, we typically want to explicitly set the gradients\n            # to zero before starting to do backpropragation\n            # (i.e., updating the Weights and biases) because PyTorch accumulates the gradients on subsequent backward passes.\n            \n            loss.backward() # update loss\n            #  The gradients are \"stored\" by the tensors themselves (they have a grad and a requires_grad attributes)\n            # once you call backward() on the loss.\n             # So, the default action has been set to accumulate (i.e. sum) the gradients on every loss.backward() call.\n            # Because of this, when you start your training loop, ideally you should zero out the gradients so that you \n            # do the parameter update correctly. Otherwise, the gradient would be a combination of the old gradient, \n            # which you have already used to update your model parameters, and the newly-computed gradient. \n            \n            self.optimizer.step()\n            # After computing the gradients for all tensors in the model, calling optimizer.step() makes the optimizer\n            # iterate over all parameters (tensors) it is supposed to update and \n            # use their internally stored grad to update their values.\n            \n            \n            train_loss+=loss.item()\n            train_acc+=accuracy(logits,labels)\n        \n        \n        return train_loss\/len(trainloader), train_acc\/len(trainloader) # calculating the average\n             \n                \n    # Train classifying layers in batches, this function loads the images and labels from the data loader.\n    # It then delivers the data to the model for training.\n    # After it finds the gradients.\n    # Lastly, it returns the average training loss and average training accuracy.\n    \n    def valid_batch_loop(self,model,validloader):\n        valid_loss=0.0\n        valid_acc=0.0\n        \n        for images,labels in tqdm(validloader):\n            \n            # move the data to GPU\n            images=images.to(device) \n            labels=labels.to(device)\n            \n            logits=model(images)\n            loss=self.criterion(logits,labels)\n            \n            valid_loss+=loss.item()\n            valid_acc+=accuracy(logits,labels)\n            \n        return valid_loss\/len(validloader),valid_acc\/len(validloader)\n    \n    # Very similar idea to the validation data. But we don\u2019t need to update the gradients.\n    \n    def fit(self,model,trainloader,validloader,epochs):\n        \n        valid_min_loss=np.Inf # initial loss is infinity \n        \n        for i in range(epochs):\n            model.train() # train in epochs turn on dropout\n            avg_train_loss,avg_train_acc=self.train_batch_loop(model,trainloader)\n            \n            model.eval() # turns off the dropout and batch norm\n            avg_valid_loss,avg_valid_acc=self.valid_batch_loop(model,validloader)\n            \n            \n            if avg_valid_loss<=valid_min_loss:\n                print(\"Valid_loss decreased {} --> {}\".format(valid_min_loss,avg_valid_loss))\n                torch.save(model.state_dict(),'EffNetPneumoniaModel.pt')\n                valid_min_loss = avg_valid_loss\n                # whenever the validation loss is smaller than what it was before it gets saved\n                \n                \n            print(\"Epoch : {} Train Loss : {:.6f} Train Acc : {:.6f}\".format(i+1, avg_train_loss, avg_train_acc))\n            print(\"Epoch : {} Valid Loss : {:.6f} Valid Acc : {:.6f}\".format(i+1, avg_valid_loss, avg_valid_acc))\n\n            \n        # validation loss goes down, the trained model gets saved by this function.\n","5eb27b19":"criterion=nn.CrossEntropyLoss()\n# This criterion computes the cross entropy loss between input and target.\n# Cross-entropy loss refers to the contrast between two random variables;\n# it measures them in order to extract the difference in the information they contain, \n# showcasing the results. We use this type of loss function to calculate how accurate \n# our machine learning or deep learning model is by defining the difference between the estimated probability\n# with our desired outcome.\n\noptimizer=torch.optim.Adam(model.parameters(),lr=CFG.lr)\n# Implements Adam algorithm\n# Adam is an optimization algorithm that can be used instead of the classical stochastic gradient descent\n# procedure to update network weights iterative based in training data.\n\n\n'''\nStochastic gradient descent maintains a single learning rate (termed alpha) for all weight updates and the learning\nrate does not change during training.\nA learning rate is maintained for each network weight (parameter) \n'''\n\ntrainer=PneumoniaTrainer(criterion,optimizer)\ntrainer.fit(model,trainloader,validationloader,epochs=CFG.epochs)","1b8c71cb":"model.load_state_dict(torch.load('.\/EffNetPneumoniaModel.pt')) \n# Load the model data we saved\nmodel.eval()\n# model.eval() is a kind of switch for some specific layers\/parts of the model that behave differently during training\n# and inference (evaluating) time. For example, Dropouts Layers, BatchNorm Layers etc.\n# You need to turn off them during model evaluation, and .eval() will do it for you. In addition,\n# the common practice for evaluating\/validation is using torch.no_grad() in pair with model.eval()\n# to turn off gradients computation:\n\navg_test_loss,avg_test_acc=trainer.valid_batch_loop(model,testloader) \n# run it through the testing images\n\nprint(\"Test Loss: {}\".format(avg_test_loss))\nprint(\"Test Acc : {}\".format(avg_test_acc))","ab99147c":"import torch.nn.functional as F\n\nimage,label=testset[13]\nprint(label)\n\nps=model(image.to(device).unsqueeze(0)) \n# unsqueeze- Returns a new tensor with a dimension of size one inserted at the specified position.\n\nps=F.softmax(ps,dim=1)\n# Applies the Softmax function to an n-dimensional input Tensor rescaling them so that \n# the elements of the n-dimensional output Tensor lie in the range [0,1] and sum to 1.\n\nview_classify(image,ps,label)","c764204a":"image,label=testset[5]\n\nps=model(image.to(device).unsqueeze(0))\nps=F.softmax(ps,dim=1)\n\nview_classify(image,ps,label)\n","52b1aed5":"image,label=testset[300]\n\nps=model(image.to(device).unsqueeze(0))\nps=F.softmax(ps,dim=1)\n\nview_classify(image,ps,label)\n","ceb7201d":"image,label=testset[115]\n\nps=model(image.to(device).unsqueeze(0))\nps=F.softmax(ps,dim=1)\n\nview_classify(image,ps,label)\n","6fe2809e":"# Summary of the model","70f0323a":"## Trying prediction tests","06a676cc":"## Helper function to display a grid of images","23725d53":"## Function to display the Classification","8a28fb07":"## Helper Function to display an image","03a01533":"## Displaying grid ","86c4eb28":"## Training","5230fcc5":"## Updating the pretrained model","1b3f875f":"## Image Augmentation","540ca665":"## Displaying Random images from the dataset","ec1a4101":"## Model","0c305359":"## Configurations","247f89a5":"## Accuracy Function","25f029b7":"## Load training data into batches"}}