{"cell_type":{"cd6ea88d":"code","db0ec4f8":"code","408dacc6":"code","6619ce7c":"code","d2bb10c9":"code","0c4aa6c5":"code","21daf0f5":"code","0d95a3e0":"code","53d84f88":"code","e4cc3779":"markdown","9d0d613f":"markdown"},"source":{"cd6ea88d":"\"\"\" To estimate execution time of the Kernel \"\"\"\nimport time\nstart = time.time()","db0ec4f8":"\"\"\" Include packages \"\"\"\nimport pandas as pd\nimport glob\nimport os\nimport subprocess as sp\nimport tqdm.notebook as tqdm\nfrom tqdm import tqdm\nfrom collections import defaultdict\nimport numpy as np\nimport json\n\n!pip install \/kaggle\/input\/mtcnn-package\/mtcnn-0.1.0-py3-none-any.whl  \nimport cv2\nfrom mtcnn import MTCNN","408dacc6":"\"\"\" Read files from test folder \"\"\"\ntest_dir = '\/kaggle\/input\/deepfake-detection-challenge\/test_videos\/'\nfilenames=os.listdir(test_dir)\nfilenames.sort()\ntest_video_files = [test_dir + x for x in filenames]","6619ce7c":"\"\"\" Utility functions \"\"\"\ndetector = MTCNN()\n\nimport pickle\nwith open('\/kaggle\/input\/db0001\/model_0001.pkl', 'rb') as f:\n    model = pickle.load(f)\n    \n# Parameters for contrast enhancement\nlookUpTable = np.empty((1,256), np.uint8)\ngamma = 0.5\nfor i in range(256):\n    lookUpTable[0,i] = np.clip(pow(i \/ 255.0, gamma) * 255.0, 0, 255)    \n\ndef detect_face(img):\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    final = []\n    detected_faces_raw = detector.detect_faces(img)\n    if detected_faces_raw == []:\n        print('no faces found, skip to next frame', end='\\r')\n        return []\n    for x in detected_faces_raw:\n        x, y, w, h = x['box']\n        final.append([x, y, w, h])\n    return final\n\ndef crop(img, x, y, w, h):\n    x -= 40\n    y -= 40\n    w += 80\n    h += 80\n    if x < 0:\n        x = 0\n    if y <= 0:\n        y = 0\n    \n    frame = cv2.resize(img[y: y + h, x: x + w],(256,256),interpolation = cv2.INTER_AREA)\n    return (255*(frame\/frame.max())).astype('uint8')\n\ndef detect_video(video):\n    cap = cv2.VideoCapture(video)\n    max_skip = 0\n    while True:\n        ret = cap.grab()\n        ret, frame = cap.retrieve()\n        \n        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        \n        #cv2.normalize(frame,  frame, 0, 255, cv2.NORM_MINMAX)\n        #frame = cv2.LUT(frame, lookUpTable)\n            \n        bounding_box = detect_face(frame)\n        if bounding_box == []:\n            if(max_skip==10):\n                return []\n            max_skip += 1\n            continue\n        x, y, w, h = bounding_box[0]\n        return crop(frame, x, y, w, h) \n    \ndef predict(frame, model):\n    if frame == []:\n        return []\n    else:\n        frame = np.expand_dims(frame, axis = 0)\n        return np.around(model.predict(frame).clip(0.15,0.85).astype('float64'), decimals=2)","d2bb10c9":"\"\"\" Read sample submission \"\"\"\nsub = pd.read_csv('\/kaggle\/input\/deepfake-detection-challenge\/sample_submission.csv')\nsub.label = 0.5\nsub = sub.set_index('filename',drop=False)","0c4aa6c5":"\"\"\" Update submission file with predcition from Keras model \"\"\"\ncount = 0\nfor filename in test_video_files:\n    print(count, end='\\r')\n    count += 1\n    fn = filename.split('\/')[-1]\n    if detect_video(filename)==[]:\n        sub.loc[fn, 'label'] = 0.5 \n    else:\n        pred = predict(detect_video(filename), model)\n        sub.loc[fn, 'label'] = pred[0][1]  ","21daf0f5":"sub.head()","0d95a3e0":"\"\"\" Write submission csv \"\"\"\nsub.to_csv('submission.csv', index=False)","53d84f88":"\"\"\" How long it took? \"\"\"\nend = time.time()  \nprint('Time: ', end-start)","e4cc3779":"# A simple kernel that uses a Keras model trained in my local system.\n**(c) 2019, Debanga Raj Neog**","9d0d613f":"# Submission Test"}}