{"cell_type":{"e5cfdd1e":"code","49d1662e":"code","d168ed00":"code","e740e73d":"code","47afe7b6":"code","308e60d1":"code","0c8e0468":"code","12374129":"code","180fb4c7":"code","e929a378":"code","61b757cb":"code","ec124316":"code","c95552b2":"code","a63db8c4":"code","f18206a0":"code","6573a25b":"code","eac809eb":"code","86fdc2e8":"code","0a705259":"markdown","d77b2999":"markdown","ab04b04b":"markdown","c4e29a35":"markdown","fe9c76b8":"markdown","7bf6d701":"markdown","3ef328ab":"markdown","31803916":"markdown","8e118233":"markdown","13b80ddb":"markdown","c8ace11b":"markdown"},"source":{"e5cfdd1e":"# Importing libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import confusion_matrix\n\nimport seaborn as sn\n\nimport tensorflow as tf\nfrom tensorflow import keras","49d1662e":"train_set = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\")\ntesting_set = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_test.csv\")","d168ed00":"train_set.head()","e740e73d":"testing_set.head()","47afe7b6":"train_set = np.array(train_set, dtype=\"float32\")\ntesting_set = np.array(testing_set, dtype=\"float32\")","308e60d1":"# For data\nX = (train_set[:, 1:])\/255.0\ny = train_set[:, 0]\n\n# For labels\nX_test = (testing_set[:, 1:])\/255.0\ny_test = testing_set[:, 0]","0c8e0468":"input_size = (28, 28)\ninput_shape = (28, 28, 1)","12374129":"plt.figure(figsize=(12, 9))\nfor i in range(15):\n    plt.subplot(3, 5, i + 1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X[i].reshape(input_size))\n    plt.title(y[i])\nplt.show()","180fb4c7":"print(X.shape)\nprint(X_test.shape)","e929a378":"X = X.reshape(X.shape[0], *input_shape)\nX_test = X_test.reshape(X_test.shape[0], *input_shape)\n\n# Transform labels to categorical\ny = keras.utils.to_categorical(y)\ny_test = keras.utils.to_categorical(y_test)","61b757cb":"print(X.shape)\nprint(X_test.shape)","ec124316":"def sequential_model(input_shape):\n    model = keras.Sequential([\n        keras.layers.Conv2D(32, (3, 3), activation=\"relu\",\n                           input_shape=input_shape),\n        keras.layers.MaxPooling2D(2, 2),\n        keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n        keras.layers.MaxPooling2D(2, 2),\n        keras.layers.Flatten(),\n        keras.layers.Dense(128, activation=\"relu\"),\n        keras.layers.Dense(10, activation=\"softmax\"),\n    ])\n    \n    model.compile(optimizer=\"adam\",\n                  loss=\"categorical_crossentropy\",\n                  metrics=[\"accuracy\"])\n    \n    return model","c95552b2":"k = 6\ncross_val = KFold(k, shuffle=True, random_state=1)\nfold_count = 1\n\n# For training epochs\nepochs = 32\n\n# For loss & acc plotting\nhistories = []\n\n# For testing\/evaluation acc scores\neval_scores = []\n\n# For callbacks\nes_callbacks = keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n                                          mode=\"min\",\n                                          verbose=1,\n                                          patience=4)","a63db8c4":"for train, validation in cross_val.split(X):\n    print(\"=\"*80)\n    print(\"Fold-{}\".format(fold_count))\n    print(\"-\"*80)\n    print(\"Training & Validation\")\n    fold_count = fold_count + 1\n    \n    model = sequential_model(input_shape)\n    \n    X_train, y_train = X[train], y[train]\n    X_val, y_val = X[validation], y[validation]\n    \n    history = model.fit(X_train, y_train,\n                        epochs=epochs,\n                        validation_data=(X_val, y_val),\n                        callbacks=[es_callbacks])\n    \n    print(\"-\"*80)\n    print(\"Testing\/evaluation\")\n    eval_loss, eval_accuracy = model.evaluate(X_test, y_test)\n    \n    histories.append(history)\n    eval_scores.append(eval_accuracy)\n    print(\"_\"*80)","f18206a0":"def display_kfold_result(history, k=1):\n    # Train & Val Loss\n    loss = history.history[\"loss\"]\n    val_loss = history.history[\"val_loss\"]\n    \n    # Train & Val Accuracy\n    accuracy = history.history[\"accuracy\"]\n    val_accuracy = history.history[\"val_accuracy\"]\n    \n    plt.figure(figsize=(15, 5))\n    \n    plt.subplot(1, 2, 1)\n    plt.title(\"Loss\")\n    plt.plot(loss, label=\"Training\")\n    plt.plot(val_loss, label=\"Validation\")\n    plt.legend(loc=\"upper right\")\n    \n    plt.subplot(1, 2, 2)\n    plt.title(\"Accuracy\")\n    plt.plot(accuracy, label=\"Training\")\n    plt.plot(val_accuracy, label=\"Validation\")\n    plt.legend(loc=\"lower right\")\n    \n    plt.suptitle(\"Fold-{}\".format(k))\n    plt.show()","6573a25b":"# Displaying the graph results\n\nfor history in histories:\n    display_kfold_result(history, (histories.index(history)+1))","eac809eb":"i = 0\nfloat2 = \"{0:.2f}\"\nfor score in eval_scores:\n    percent = score * 100\n    print(\"Fold-{}: {}%\".format(i+1, float2.format(percent)))\n    i = i + 1","86fdc2e8":"# The best model instance was from fold-2","0a705259":"### Data Reshape","d77b2999":"### Start Training and Validation","ab04b04b":"### Define the CNN Model","c4e29a35":"### Data Normalization","fe9c76b8":"### Display some data","7bf6d701":"### Result Visualization\nVisualizing loss and accuracy graphs from every fold","3ef328ab":"## Fashion MNIST with K-Fold Cross-Validation","31803916":"Fashion MNIST Image Classification using Keras CNN and K-Fold Cross Validation\n\nIn this notebook:\n- Load\/Prepare Dataset\n- Define CNN model\n- Train-Val Configuration\n- Training & validation\n- Testing\/evaluation","8e118233":"### Load Dataset","13b80ddb":"### Configure Training & Validation (K-Fold) Properties","c8ace11b":"### Display Testing\/Evaluation Accuracies"}}