{"cell_type":{"d9a33c39":"code","2faea0c1":"code","941d2e07":"code","d4499f70":"code","c164b2b7":"code","eea47dc0":"code","6ded2ff1":"code","307da8d4":"code","59d2efff":"code","2bbf8a93":"code","65af6176":"code","ea5ae637":"code","8054ad76":"code","acbffcf4":"code","76230198":"code","d74ba070":"code","78dacdbc":"code","8c2de10e":"code","390cfd2a":"code","c830a8dd":"code","4bd171b6":"code","50e9c5e0":"code","9438b5c4":"code","41a97e4d":"markdown","1ae7b517":"markdown","be9a4aa9":"markdown","e5246dd0":"markdown","fab45bdf":"markdown","96a00248":"markdown","32fb7c58":"markdown","4b582a6f":"markdown","fc863fe4":"markdown","c32ad956":"markdown","52ee6320":"markdown","5e00039a":"markdown","ab4ab168":"markdown","8169f1b4":"markdown","dc0aa144":"markdown","078f5f48":"markdown","d785c7c1":"markdown","e7d56fa2":"markdown","1fa9e56c":"markdown","89515f71":"markdown","2e312c9b":"markdown","c97a0ce1":"markdown","2450eb17":"markdown","79f11add":"markdown","37625396":"markdown","a5bf691a":"markdown","5bbf0c0c":"markdown","192edffa":"markdown","a4e1adb8":"markdown","2c38cb69":"markdown","019282ab":"markdown","5ae4642f":"markdown"},"source":{"d9a33c39":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score, KFold\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","2faea0c1":"cols = ['symboling', 'normalized-losses', 'make', 'fuel-type', 'aspiration', 'num-of-doors', 'body-style', 'drive-wheels', 'engine-location', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-type', 'num-of-cylinders', 'engine-size', 'fuel-system', 'bore', 'stroke', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']\ncars = pd.read_csv('..\/input\/imports-85.data.txt', names=cols)\nprint(cars.shape)\ncars.head()","941d2e07":"cars.describe()","d4499f70":"continuous_numeric = ['normalized-losses', 'wheel-base', 'length', 'width', \n                      'height', 'curb-weight', 'bore', 'stroke', 'compression-ratio', \n                      'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']\n\nnumeric_cars = cars[continuous_numeric].copy()\nnumeric_cars.head()","c164b2b7":"numeric_cars.isnull().sum()","eea47dc0":"numeric_cars['normalized-losses'].value_counts()","6ded2ff1":"numeric_cars.replace('?', np.nan, inplace=True)\nprint(\"\\nMissing values before: \\n\\n\", numeric_cars.isnull().sum(), \"\\n\\n\")","307da8d4":"numeric_cars.dtypes","59d2efff":"to_numeric_cols = ['normalized-losses', 'bore', 'stroke', 'horsepower', 'peak-rpm', 'price']\nnumeric_cars[to_numeric_cols] = numeric_cars[to_numeric_cols].astype(float)\nnumeric_cars.dtypes","2bbf8a93":"numeric_cars.dropna(axis=0, thresh=2, inplace=True)\nnumeric_cars = numeric_cars.fillna(numeric_cars.mean())\nprint(\"\\nMissing values after: \\n\\n\", numeric_cars.isnull().sum(), \"\\n\")","65af6176":"normalized_cars = (numeric_cars - numeric_cars.min())\/(numeric_cars.max() - numeric_cars.min())\n#normalized_cars = np.abs((numeric_cars - numeric_cars.mean())\/numeric_cars.std())\nnormalized_cars['price'] = numeric_cars['price']\nprint(normalized_cars.shape)\nnormalized_cars.head()","ea5ae637":"# Univariate model\ndef knn_train_test_uni(feature, target_column, df, k):\n    \n    # Randomize order of rows in data frame.\n    np.random.seed(1)\n    shuffled_index = np.random.permutation(df.index)\n    rand_df = df.reindex(shuffled_index)\n\n    # Split the dataset\n    train_set = rand_df.iloc[0:int(len(rand_df)\/2)]\n    test_set = rand_df.iloc[int(len(rand_df)\/2):]\n    \n    # Train\n    knn = KNeighborsRegressor(n_neighbors=k)\n    knn.fit(train_set[[feature]], train_set[target_column])\n    \n    # Predict\n    predictions = knn.predict(test_set[[feature]])\n    \n    # Calculate RMSE\n    rmse = np.sqrt(mean_squared_error(test_set[target_column], predictions))\n    \n    return rmse\n","8054ad76":"k_values = [1, 3, 5, 7, 9]\nrmse_uni = {}\ncurrent_rmse = []\ntarget_column = 'price'\n\nfor feature in continuous_numeric[0:-1]:\n    for k in k_values:\n        current_rmse.append(knn_train_test_uni(feature, target_column, normalized_cars, k))\n        \n    rmse_uni[feature] = current_rmse\n    current_rmse = []\n\nrmse_uni","acbffcf4":"fig, ax = plt.subplots(1)\n\nfor key, values in rmse_uni.items():\n    ax.plot(k_values, values, label=key)\n    ax.set_xlabel('k value')\n    ax.set_ylabel('RMSE')\n    ax.set_title('RMSE for Each Training Column\\nvs. k value')\n    ax.tick_params(top=\"off\", left=\"off\", right=\"off\", bottom='off')\n    ax.legend(bbox_to_anchor=(1.5, 1), prop={'size': 11})\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)","76230198":"# Multivariate model\ndef knn_train_test(features, target_column, df, k):\n    \n    # Randomize order of rows in data frame.\n    np.random.seed(1)\n    shuffled_index = np.random.permutation(df.index)\n    rand_df = df.reindex(shuffled_index)\n\n    # Split the dataset\n    train_set = rand_df.iloc[0:int(len(rand_df)\/2)]\n    test_set = rand_df.iloc[int(len(rand_df)\/2):]\n    \n    # Train\n    knn = KNeighborsRegressor(n_neighbors=k)\n    knn.fit(train_set[features], train_set[target_column])\n    \n    # Predict\n    predictions = knn.predict(test_set[features])\n    \n    # Calculate RMSE\n    rmse = np.sqrt(mean_squared_error(test_set[target_column], predictions))\n    \n    return rmse\n","d74ba070":"avg_rmse = {}\n\nfor key, values in rmse_uni.items():\n    avg_rmse[key] = np.mean(values)\n\navg_rmse = pd.Series(avg_rmse)\navg_rmse.sort_values()","78dacdbc":"features = {\n        'best_2': ['highway-mpg', 'curb-weight'],\n        'best_3': ['highway-mpg', 'curb-weight', 'horsepower'],\n        'best_4': ['highway-mpg', 'curb-weight', 'horsepower', 'width'],\n        'best_5': ['highway-mpg', 'curb-weight', 'horsepower', 'width', 'city-mpg'],\n        'best_6': ['highway-mpg', 'curb-weight', 'horsepower', 'width', 'city-mpg', 'length']\n    } \n\nrmse_multi = {}\ntarget_column = 'price'\nk = 5\n\nfor key, value in features.items():\n    rmse_multi[key] = knn_train_test(value, target_column, normalized_cars, k)\n    \npd.Series(rmse_multi).sort_values()","8c2de10e":"top_models = {\n        'best_2': ['highway-mpg', 'curb-weight'],\n        'best_3': ['highway-mpg', 'curb-weight', 'horsepower'],\n        'best_6': ['highway-mpg', 'curb-weight', 'horsepower', 'width', 'city-mpg', 'length']\n    } \n\nk_values = list(range(1, 26))\nrmse_multi_k = {}\nrmse_current = []\n\nfor key, value in top_models.items():\n    for k in k_values:\n        rmse_current.append(knn_train_test(value, target_column, normalized_cars, k))\n        \n    rmse_multi_k[key] = rmse_current\n    rmse_current = []\n    \nprint(rmse_multi_k)","390cfd2a":"# Returns a dict with the min value of every key's list and its index the list\ndef min_key_value(dictionary):\n    min_values = {}\n    for k, v in dictionary.items():\n        min_values[k] = [min(v), v.index(min(v))]\n        \n    return min_values\n        \nbest_k = min_key_value(rmse_multi_k)\nprint(best_k)\n\n# Plot results\nfig, ax = plt.subplots(1)\n\nfor key, values in rmse_multi_k.items():\n    ax.plot(k_values, values, label=key)\n    ax.set_xlabel('k value')\n    ax.set_ylabel('RMSE')\n    ax.set_title('RMSE for Top 3 Models vs. k value\\n Test\/Train Validation')\n    ax.tick_params(top=\"off\", left=\"off\", right=\"off\", bottom='off')\n    ax.legend(bbox_to_anchor=(1.5, 1), prop={'size': 11})\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)","c830a8dd":"def knn_cross_validation(features, target_column, df, k): \n    knn = KNeighborsRegressor(n_neighbors=k)\n    kf = KFold(n_splits=10, shuffle=True, random_state=1)\n    mses = cross_val_score(knn, df[features], df[target_column], scoring='neg_mean_squared_error', cv=kf)\n    avg_rmse = np.mean(np.sqrt(np.absolute(mses)))\n    \n    return avg_rmse\n","4bd171b6":"features = {\n        'best_2': ['highway-mpg', 'curb-weight'],\n        'best_3': ['highway-mpg', 'curb-weight', 'horsepower'],\n        'best_4': ['highway-mpg', 'curb-weight', 'horsepower', 'width'],\n        'best_5': ['highway-mpg', 'curb-weight', 'horsepower', 'width', 'city-mpg'],\n        'best_6': ['highway-mpg', 'curb-weight', 'horsepower', 'width', 'city-mpg', 'length']\n    } \n\nrmse_multi = {}\ntarget_column = 'price'\nk = 5\n\nfor key, value in features.items():\n    rmse_multi[key] = knn_cross_validation(value, target_column, normalized_cars, k)\n    \npd.Series(rmse_multi).sort_values()\n\n","50e9c5e0":"top_models = {\n        'best_3': ['highway-mpg', 'curb-weight', 'horsepower'],\n        'best_4': ['highway-mpg', 'curb-weight', 'horsepower', 'width'],\n        'best_5': ['highway-mpg', 'curb-weight', 'horsepower', 'width', 'city-mpg']\n    } \n\nk_values = list(range(1, 26))\nrmse_multi_k = {}\nrmse_current = []\n\nfor key, value in top_models.items():\n    for k in k_values:\n        rmse_current.append(knn_cross_validation(value, target_column, normalized_cars, k))\n        \n    rmse_multi_k[key] = rmse_current\n    rmse_current = []\n    \nprint(rmse_multi_k)","9438b5c4":"best_k = min_key_value(rmse_multi_k)\nprint(best_k)\n\n# Plot results\nfig, ax = plt.subplots(1)\n\nfor key, values in rmse_multi_k.items():\n    ax.plot(k_values, values, label=key)\n    ax.set_xlabel('k value')\n    ax.set_ylabel('RMSE')\n    ax.set_title('RMSE for Top 3 Models vs. k value\\n 10-Fold Cross Validation')\n    ax.tick_params(top=\"off\", left=\"off\", right=\"off\", bottom='off')\n    ax.legend(bbox_to_anchor=(1.5, 1), prop={'size': 11})\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)","41a97e4d":"<a id='section5'><\/a>\n## Missing values","1ae7b517":"<a id='section14'><\/a>\n## Testing\n<a id='section15'><\/a>\n### Feature selection\nTo test different multivariate models, I will select the best 2, 3, 4, 5 and lastly 6 best features of the previous univariate 'RMSE ranking', and see which set of features performs best for the default _k_ value.","be9a4aa9":"<a id='section16'><\/a>\n### Hyperparameter tuning\nFrom the top 3 models in the last section (those using 'best_6', 'best_2', and 'best_3' as features), let's see how they perform when tuning the _k_ value from 1 to 25.","e5246dd0":"The dataset has 205 rows, and we've seen how there're up to 41 NaN values. This means handling those by removing any row where there's a NaN value would result in losing close to 25% of the data, which is not a good solution.\n\nLet's only apply that to any row that has more than one missing value, and handle the rest by replacing any NaN value with the average of that column.","fab45bdf":"Using k-fold cross validation, the trend is similar to what we got before using test\/train validation. However, this time we got better results:\n\n- 'best_3': RMSE of **2824.09** dollars, for **k=2**\n- 'best_4': RMSE of **3035.18** dollars, for **k=3**\n- 'best_5': RMSE of **3159.23** dollars, for **k=3**","96a00248":"<a id='section3'><\/a>\n# Cleaning","32fb7c58":"<a id='section6'><\/a>\n## Normalization\nNormalizing the numeric values using min-max normalization will make all values range from 0 to 1. This will prevent outliers when measuring squared erros.\n\nLet's apply that to all columns except for the target column, 'price'.","4b582a6f":"<a id='section21'><\/a>\n## Results","fc863fe4":"----\n <a id='section4'><\/a>\n## Numeric vs. non-numeric columns\nBefore selecting the features to use for the model, let's see which ones are numeric. \n\nIn this case, referring to the Attribute Information of the dataset, found at https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/autos\/imports-85.names, and only selecting numeric columns with continuous values results in the most effective way to achieve this.","c32ad956":"The univariate model will use test\/train validation, taking a single column as the selected feature, split the dataset into a training and test set, train and make predictions, returning the RMSE for the model.\n\nIt takes the training column name, target column name, the dataframe object, and a parameter for the _k_ value.\n\nIn this case, we'll consider splitting the dataset so that 50% of the rows represent the training set and the remaining 50% represent the test set.\n\nSince we want to predict car prices, we will use the 'price' column as the target column for the model.","52ee6320":"<a id='section13'><\/a>\n## Top 5 features\nIn order to effectively test different set of features for the multivariate model, using sets of the top 5 from the univariate model could be a good approach.\n\nWe can achieve this by computing the average of all RMSE values got for each _k_ value, and assign that to every column that's been used.","5e00039a":"<a id='section12'><\/a>\n## Definition","ab4ab168":"---\n<a id='section1'><\/a>\n# Introduction\nThis project aims to predict car prices using different K-Nearest Neighbors models. The data is sourced from https:\/\/archive.ics.uci.edu\/ml\/datasets\/automobile.","8169f1b4":"The top 5 features using this method are 'highway-mpg', 'curb-weight', 'horsepower', 'width' and 'city-mpg'.","dc0aa144":"Let's replace any question mark in the data with the numpy.nan missing value.","078f5f48":"The best results for each model are:\n\n- 'best_6': RMSE of **3303.16** dollars, for **k=1**\n- 'best_3': RMSE of **3382.88** dollars, for **k=2**\n- 'best_2': RMSE of **3802.87** dollars, for **k=6**\n\nAll of them tend to perform worse as k increases from a certain point (between k=5 and k=10 approximately). \n\nIt also seems like the more features, the lower _k_ value that performs best. This may be because more features make entries (cars in this case) more unique, which means if a new car has a lot of attributes or features that make it distinct, it will be harder for it to be similar to a big number of cars in our training set (i.e. selecting a big _k_ when using many features may result in worse predictions).\n\nAs an example, that may be why the case of _k=1_ for the 'best_6' model (6 attributes\/features) performs best, since even though every new car only chooses one similar\/close in distance car (neighbor) from the training set, that one car is the most similar cosindering a big number of attributes, which results in a a good prediction.","d785c7c1":"This time, the 3 best models in terms of RMSE were 'best_4', 'best_3', and 'best_5'. \n\nPerforming hyperparameter tuning will tell us what the optimal _k_ value is for each of them, just as we did before.","e7d56fa2":"<a id='section10'><\/a>\n## Results","1fa9e56c":"<a id='section19'><\/a>\n## Feature selection\nProceeding the exact same way as before, using the same selected features, the RMSE values returned are:","89515f71":"<a id='section20'><\/a>\n## Hyperparameter tuning","2e312c9b":"Any column that now has NaN values on it, before containg question marks, which made pandas cast it to the object data types, as seen below.","c97a0ce1":"<a id='section17'><\/a>\n## Results","2450eb17":"<a id='section9'><\/a>\n## Testing\nLet's test different models by changing:\n\n- The column used as feature: every numeric column (as previously stored in 'continuous_numeric').\n- The _k_ value: 1, 3, 5, 7 and 9.\n\nFor every numeric column, we'll try all k values, store and plot the RMSE results.","79f11add":"<a id='section8'><\/a>\n## Definition","37625396":"<a id='section2'><\/a>\n# Read in the data","a5bf691a":"# Table of contents\n*  [Introduction](#section1) \n*  [Read in the data](#section2)\n*  [Cleaning](#section3)\n    - [Numeric vs. non-numeric columns](#section4)\n    - [Missing values](#section5)\n    - [Normalization](#section6)\n*  [Univariate model](#section7)\n    - [Definition](#section8)\n    - [Testing](#section9)\n    - [Results](#section10)\n*  [Multivariate model](#section11)\n    - [Definition](#section12)\n    - [Top 5 features](#section13)\n    - [Testing](#section14)\n        - [Feature selection](#section15)\n        - [Hyperparameter tuning](#section16)\n    - [Results](#section17)\n*  [Cross validation](#section18) \n    - [Feature selection](#section19)\n    - [Hyperparameter tuning](#section20)\n    - [Results](#section21)\n    \n    by @samaxtech","5bbf0c0c":"<a id='section11'><\/a>\n# Multivariate model\nThe multivariate model will perform the exact same way as the univariate, but will take a list of column names to be used as features.","192edffa":"<a id='section18'><\/a>\n# Cross validation\nLastly, for the multivariate model let's modify the knn_train_test() function to use k-fold cross validation instead of test\/train validation and see how it performs for 10 folds.","a4e1adb8":"While there's not any NULL values in the cars dataframe, the 'normalized-losses' column contains 41 missing values, symbolized by a question mark '?', as seen below.","2c38cb69":"We can see how the RMSE values range from 4,000 up to 11,000 dollars. \n\nLater on in this project, I will select the top 5 features based on the average of all RMSE values for each _k_ value, to be used to test different multivariate models, defined in the next section.","019282ab":"Let's convert those to numeric types, since they all contain numeric data values.","5ae4642f":"<a id='section7'><\/a>\n# Univariate model"}}