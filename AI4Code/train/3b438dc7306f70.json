{"cell_type":{"7f235409":"code","e90be1d1":"code","a7789bc0":"code","004903d0":"code","d42d7100":"code","9e8f8ae3":"code","80df3f76":"code","f4c946cb":"code","c80ec7f8":"code","2af97826":"code","d1b4e7c7":"code","53c03941":"code","c6302735":"code","d5d84920":"code","69cffb8d":"code","b6719c48":"code","b6e79ce3":"code","6c815144":"code","746a10d0":"code","186a2ac8":"code","fda8ed3b":"code","466fb97c":"code","bb02dcf4":"code","40b327c9":"code","01780685":"code","49116a38":"code","4831f225":"code","1b38eac6":"code","7b800b94":"code","208c4baa":"code","c0adde97":"code","81111163":"code","531f7644":"code","fd04fd27":"code","d8120b1a":"code","aa4f88c7":"markdown","0b7dd3ea":"markdown","191d5c22":"markdown","997e8bb3":"markdown","f1bde3e6":"markdown","f3289ac0":"markdown","04de37f0":"markdown","5fea84fc":"markdown"},"source":{"7f235409":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e90be1d1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom pandas import plotting\n\n#plotly \nimport plotly.offline as py\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import tools\ninit_notebook_mode(connected=True)\nimport plotly.figure_factory as ff\nimport plotly.express as px\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import preprocessing\nfrom sklearn import neighbors\nfrom sklearn.metrics import confusion_matrix,classification_report,precision_score, plot_roc_curve, plot_precision_recall_curve, balanced_accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nsns.set(style=\"whitegrid\")\n\nplt.style.use('fivethirtyeight')\n\nimport warnings\n\ndef fxn():\n    warnings.warn(\"deprecated\", DeprecationWarning)\n\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    fxn()","a7789bc0":"df=pd.read_csv('..\/input\/gender-classification\/Transformed Data Set - Sheet1.csv')","004903d0":"df.head()","d42d7100":"df.isnull().sum()","9e8f8ae3":"df.info()","80df3f76":"#Fetch features of type Object\nobjFeatures = df.select_dtypes(include=\"object\").columns\nobjFeatures","f4c946cb":"col = \"Gender\"\ngrouped = df[col].value_counts().sort_values(ascending=False).head(10).reset_index()\ngrouped = grouped.rename(columns = {col : \"count\", \"index\" : col})\n\n## plot\ntrace = go.Pie(labels=grouped[col], values=grouped['count'], pull=[0.05, 0], marker=dict(colors=[\"#6ad49b\", \"#a678de\"]))\nlayout = go.Layout(title=\"Gender\", height=600, legend=dict(x=0.1, y=1.1))\nfig = go.Figure(data = [trace], layout = layout)\niplot(fig)","c80ec7f8":"col = \"Favorite Color\"\ngrouped = df[col].value_counts().sort_values(ascending=False).head(10).reset_index()\ngrouped = grouped.rename(columns = {col : \"count\", \"index\" : col})\n\n## plot\ntrace = go.Pie(labels=grouped[col], values=grouped['count'], pull=[0.05, 0], marker=dict(colors=[\"blues\", \"#a678de\"]))\nlayout = go.Layout(title=\"Colors\", height=600, legend=dict(x=0.1, y=1.1))\nfig = go.Figure(data = [trace], layout = layout)\niplot(fig)","2af97826":"fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(10,18))\nfor i in range(len(df.columns)):\n    sns.countplot(data=df, x=df.iloc[:,i],ax=axes[i])","d1b4e7c7":"#Iterate a loop for features of type object\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\nfor feat in objFeatures:\n    df[feat] = le.fit_transform(df[feat].astype(str))\n    \ndf.info()","53c03941":"X = df.drop(['Gender'], axis = 1)\ny = df.Gender","c6302735":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","d5d84920":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\n\ndef clf_scores(clf, y_predicted):\n    # Accuracy\n    acc_train = clf.score(X_train, y_train)*100\n    acc_test = clf.score(X_test, y_test)*100\n    \n    roc = roc_auc_score(y_test, y_predicted)*100 \n    tn, fp, fn, tp = confusion_matrix(y_test, y_predicted).ravel()\n    cm = confusion_matrix(y_test, y_predicted)\n    correct = tp + tn\n    incorrect = fp + fn\n    d=[acc_train, acc_test,  roc, correct, incorrect,  cm]\n    index=[\"acc_train\",'Test Accuracy',\"Roc Score\",\"COrrect\",\"Incorrect\",\"Confusion\"  ]\n    output=pd.DataFrame(data=d, index=index)\n    \n    d=sns.heatmap(cm, annot=True)\n    dd=plot_roc_curve(clf, X_train, y_train)\n    ddd=plot_precision_recall_curve(clf, X_train, y_train)\n\n    return output,d, dd, ddd\n    \n    #return acc_train, acc_test, roc, correct, incorrect, cm, d","69cffb8d":"#1. Logistic regression\n\nfrom sklearn.linear_model import LogisticRegression\nclf_lr = LogisticRegression()\nclf_lr.fit(X_train, y_train)\n\nY_pred_lr = clf_lr.predict(X_test)\nprint(clf_scores(clf_lr, Y_pred_lr))","b6719c48":"#6. Radom forest classifier\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nclf_rfc = RandomForestClassifier(max_depth=10, random_state=42)\nclf_rfc.fit(X_train, y_train)\n\nY_pred_rfc = clf_rfc.predict(X_test)\nprint(clf_scores(clf_rfc, Y_pred_rfc))","b6e79ce3":"#7. Gradient boosting classifier\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nclf_gbc = GradientBoostingClassifier(random_state=42)\nclf_gbc.fit(X_train, y_train)\n\nY_pred_gbc = clf_gbc.predict(X_test)\nprint(clf_scores(clf_gbc, Y_pred_gbc))","6c815144":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)","746a10d0":"from sklearn.linear_model import LogisticRegression\nmodel= LogisticRegression()\nmodel.fit(X_train, y_train)","186a2ac8":"threshold = []\naccuracy = []\n\nfor p in np.unique(model.predict_proba(X_train)[:,1]):\n  threshold.append(p)\n  y_pred = (model.predict_proba(X_train)[:,1] >= p).astype(int)\n  accuracy.append(balanced_accuracy_score(y_train,y_pred))","fda8ed3b":"plt.figure(figsize=(10,6))\nplt.scatter(threshold,accuracy)\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"Balanced accuracy\")\nplt.show()","466fb97c":"lr = LogisticRegression()","bb02dcf4":"param_grid = [    \n    {'penalty' : ['l1', 'l2', 'elasticnet'],\n    'C' : np.logspace(-4, 4, 20),\n    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n    'max_iter' : [100, 1000,2500, 5000]\n    }\n]","40b327c9":"from sklearn.model_selection import GridSearchCV","01780685":"clf = GridSearchCV(lr, param_grid = param_grid, cv = 3, verbose=True, n_jobs=-1)","49116a38":"best_clf = clf.fit(X_train,y_train)","4831f225":"best_clf.best_estimator_","1b38eac6":"from sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix,ConfusionMatrixDisplay","7b800b94":"model=LogisticRegression(C=1.623776739188721)","208c4baa":"model.fit(X_train, y_train)","c0adde97":"y_pred =model.predict_proba(X_train)[:,1] >= 0.38","81111163":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","531f7644":"y_test_pred=model.predict(X_test)>= 0.38","fd04fd27":"lr_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",lr_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","d8120b1a":"acc_train = model.score(X_train, y_train)*100\nacc_test = model.score(X_test, y_test)*100\n    \nroc = roc_auc_score(y_test, y_test_pred)*100 \ntn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\ncm = confusion_matrix(y_test, y_test_pred)\ncorrect = tp + tn\nincorrect = fp + fn\nd=[acc_train, acc_test,  roc, correct, incorrect,  cm]\nindex=[\"acc_train\",'Test Accuracy',\"Roc Score\",\"COrrect\",\"Incorrect\",\"Confusion\"  ]\noutput=pd.DataFrame(data=d, index=index)\n    \nsns.heatmap(cm, annot=True)\nplot_roc_curve(clf, X_train, y_train)\nplot_precision_recall_curve(clf, X_train, y_train)","aa4f88c7":"# Separating Categorical features","0b7dd3ea":"# Build Logistic Regression with Hyperparameter","191d5c22":"* All the the categorical variables","997e8bb3":"* THe balanced dataset\n* NO need to perform the smpling ","f1bde3e6":"# Threshhold Probability","f3289ac0":"# Obs\n* The threshold probability should be 0.38 or 0.56.\n* C=1.623776739188721","04de37f0":"# Label Encoding ","5fea84fc":"* 0.38 and 0.55 are the correct values where se accuracy is high"}}