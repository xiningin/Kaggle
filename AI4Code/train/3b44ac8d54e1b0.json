{"cell_type":{"927ab34b":"code","fb997769":"code","cd5b8df2":"code","c9c3c6b8":"code","4dcedb40":"code","16fa2ebf":"code","bc6aec64":"code","efdd9e99":"code","30293fd6":"code","296ddf47":"code","30878062":"code","e798f1a5":"code","7ddf5e84":"code","f6ccab2b":"code","5bd818b7":"code","d3d51e95":"code","54e907f3":"code","cd1d384d":"code","0c7592b9":"code","18d5c218":"code","1334777d":"code","7e76e2f9":"code","d3385e4d":"code","9f6a9b20":"code","af2b7a3d":"code","59ac1926":"code","f2f95bf4":"code","ca869269":"code","a5235b54":"code","b53c0756":"code","ff95ce22":"code","f0b3a645":"code","71c26aee":"code","df2a568a":"code","4239351a":"code","efb275f6":"code","551a9843":"code","ad53be0c":"code","dbda04a3":"code","0337a55a":"markdown","22b86461":"markdown","cff50bc7":"markdown","d0d45088":"markdown","8dfe4e72":"markdown","f45faeba":"markdown","c0d1695e":"markdown","db911b67":"markdown","c9af51bc":"markdown","d5c9f1c7":"markdown","31c276c0":"markdown"},"source":{"927ab34b":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nfrom sklearn.preprocessing import normalize\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree   import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\n\n\n\nfrom sklearn.svm import SVC\n\nfrom prettytable import PrettyTable","fb997769":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\neval_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\n\neval_data_raw = eval_data\ntrain_data_raw = train_data\n\ntrain_len = len(train_data)\njoin_data = train_data.append(eval_data,ignore_index = True)\n","cd5b8df2":"#------------------------------------------------------------------------------------------\n# train_data\n#------------------------------------------------------------------------------------------\njoin_data = join_data[['PassengerId','Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked','Survived']]\njoin_data.head()","c9c3c6b8":"join_data.describe()","4dcedb40":"#------------------------------------------------------------------------------------------\n# NaN Count\n#------------------------------------------------------------------------------------------\ndf = pd.DataFrame(join_data.isnull().sum(),columns=[\"Train NaN\"])\ndf","16fa2ebf":"#------------------------------------------------------------------------------------------\n# Visualize the data\n#------------------------------------------------------------------------------------------\nfig,axx= plt.subplots(1, 3, figsize=(20,5))\naxx[0].set_title('Ticket Class Train')\nsns.countplot(x='Pclass', data=join_data, ax=axx[0])\naxx[1].set_title('Sex Train')\nsns.countplot(x='Sex', data=join_data, ax=axx[1])\naxx[2].set_title('Embarked(C - Cherbourg, Q - Queenstown, S - Southampton) Train')\nsns.countplot(x='Embarked', data=join_data, ax=axx[2])\nplt.tight_layout()","bc6aec64":"ages_hist = np.histogram(join_data[\"Age\"], bins=[0,10,20,30,40,50,60,70,80,90])\n\nages_hist_labels = [\"0\u201310\", \"11\u201320\", \"21\u201330\", \"31\u201340\", \"41\u201350\", \"51\u201360\", \"61\u201370\", \"71\u201380\", \"81\u201390\"]\n\nplt.figure(figsize=(7,7))\nplt.title('Age Distribution of Passenger')\nplt.bar(ages_hist_labels, ages_hist[0])\nfor i, bin in zip(ages_hist[0], range(9)):\n    plt.text(bin, i+3, str(int(i)), fontsize=12,\n             horizontalalignment='center', verticalalignment='center')\nplt.show()","efdd9e99":"#------------------------------------------------------------------------------------------\n# Embarked and Fare(1 in eval) NaN\n#------------------------------------------------------------------------------------------\njoin_data['Embarked'].fillna(value='S', inplace=True) #most common\njoin_data['Fare'].fillna(value=join_data.Fare.mean(), inplace=True)","30293fd6":"#------------------------------------------------------------------------------------------\n# New Feature AgeGroup \n#------------------------------------------------------------------------------------------\n\n#from Titanic encyclopedia(https:\/\/www.encyclopedia-titanica.org\/children-on-titanic\/) children where consider between 0 - 14 years\n\njoin_data['AgeGroup'] = 'adult'\njoin_data.loc[join_data['Name'].str.contains('Master'),'AgeGroup'] = \"child\"\njoin_data.loc[join_data['Age'] <= 14.0,'AgeGroup'] = \"child\"\njoin_data.loc[(join_data['Age'].isnull()) & (join_data['Name'].str.contains('Miss')) & (join_data['Parch'] != 0) ,'AgeGroup'] = \"child\"\npd.DataFrame(join_data[join_data['Age'].notnull()].groupby(['Pclass','Sex','AgeGroup'])['Age'].mean())","296ddf47":"#------------------------------------------------------------------------------------------\n# Age\n#------------------------------------------------------------------------------------------\ndef Age(cols):\n    Age=cols[0]\n    Pclass=cols[1]\n    Sex=cols[2]\n    AgeGroup=cols[3]\n    if pd.isnull(Age):\n        if Pclass==1:\n            if Sex==\"male\":\n                if AgeGroup=='adult':\n                    return 40\n                else:\n                    return 7\n            elif Sex==\"female\":\n                if AgeGroup=='adult':\n                    return 37\n                else:\n                    return 8\n        elif Pclass==2:\n            if Sex==\"male\":\n                if AgeGroup=='adult':\n                    return 33\n                else:\n                    return 4\n            elif Sex==\"female\":\n                if AgeGroup=='adult':\n                    return 31\n                else:\n                    return 7\n        elif Pclass==3:\n            if Sex==\"male\":\n                if AgeGroup=='adult':\n                    return 30\n                else:\n                    return 7\n            elif Sex==\"female\":\n                if AgeGroup=='adult':\n                    return 26\n                else:\n                    return 5\n    else:\n        return Age\n    \njoin_data[\"Age\"]=join_data[[\"Age\",\"Pclass\",\"Sex\",\"AgeGroup\"]].apply(Age,axis=1)","30878062":"#------------------------------------------------------------------------------------------\n# New feature AgeRange\n#------------------------------------------------------------------------------------------\nbins = [0, 7, 14, 21, 28, 35, 42, 49, 56, np.inf]\nnames = ['<=7', '8-14', '15-21','22-28','29-35','35-42','43-49','50-56','>57']\njoin_data['AgeRange'] = pd.cut(join_data['Age'], bins, labels=names)","e798f1a5":"#------------------------------------------------------------------------------------------\n# New feature Deck and Room\n#------------------------------------------------------------------------------------------\njoin_data[\"Deck\"] = join_data[\"Cabin\"].str.slice(0,1)\njoin_data[\"Room\"] = join_data[\"Cabin\"].str.slice(1,5).str.extract(\"([0-9]+)\", expand=False).astype(\"float\")\n\njoin_data[\"Deck\"] = join_data[\"Deck\"].fillna(\"N\")\njoin_data[\"Room\"] = join_data[\"Room\"].fillna(0)","7ddf5e84":"#------------------------------------------------------------------------------------------\n# New feature Family_size\n#------------------------------------------------------------------------------------------\njoin_data['Family_size'] = join_data['SibSp'] + join_data['Parch'] + 1","f6ccab2b":"#------------------------------------------------------------------------------------------\n# New feature Alone\n#------------------------------------------------------------------------------------------\ndef create_alone_feature(SibSp_Parch):\n    if (SibSp_Parch[0]+SibSp_Parch[1])==0:\n        return 1\n    else:\n        return 0\njoin_data['Alone'] = join_data[['SibSp','Parch']].apply(create_alone_feature, axis=1)","5bd818b7":"#------------------------------------------------------------------------------------------\n# Correlation map\n#------------------------------------------------------------------------------------------\ncorr_matrix = join_data.corr()\ncmap = sns.diverging_palette(230, 20, as_cmap=True) \nsns.heatmap(corr_matrix, annot=None ,cmap=cmap)","d3d51e95":"#------------------------------------------------------------------------------------------\n# Pclass vs Fare\n#------------------------------------------------------------------------------------------\nfig,axx= plt.subplots(1, 2, figsize=(20,5))\naxx[0].set_title('Pclass vs Fare Train')\nsns.boxplot(x='Pclass',y='Fare',data=join_data, palette='Set2', ax = axx[0])\naxx[1].set_title('Pclass vs Fare Eval')\nsns.boxplot(x='Pclass',y='Fare',data=join_data, palette='Set2',ax = axx[1])\nplt.tight_layout()","54e907f3":"#------------------------------------------------------------------------------------------\n# Survive by Sex\n#------------------------------------------------------------------------------------------\nsns.set_style('whitegrid')\nsns.countplot(x=join_data['Sex'],hue=join_data['Survived'],data=join_data)","cd1d384d":"#------------------------------------------------------------------------------------------\n# Survive by AgeRange\n#------------------------------------------------------------------------------------------\nsns.set_style('whitegrid')\nsns.countplot(x=join_data['AgeRange'],hue=join_data['Survived'],data=join_data)","0c7592b9":"#------------------------------------------------------------------------------------------\n# Survive by AgeRange\/PClass\n#------------------------------------------------------------------------------------------\ng = sns.FacetGrid(join_data[join_data['Survived'].notnull()], col='Pclass')\ng = g.map(sns.barplot,\"AgeRange\",\"Survived\", order=['<=7', '8-14', '15-21','22-28','29-35','35-42','43-49','50-56','>57'])\nfor axes in g.axes.flat:\n    _ = axes.set_xticklabels(axes.get_xticklabels(), rotation=70)\nplt.tight_layout()","18d5c218":"#------------------------------------------------------------------------------------------\n# Survive by Alone\n#------------------------------------------------------------------------------------------\nsns.set_style('whitegrid')\nsns.countplot(x=join_data['Alone'],hue=join_data['Survived'],data=join_data)\n","1334777d":"#------------------------------------------------------------------------------------------\n# Survive by Family Size\n#------------------------------------------------------------------------------------------\nsns.set_style('whitegrid')\nsns.countplot(x=join_data['Family_size'],hue=join_data['Survived'],data=join_data)","7e76e2f9":"#------------------------------------------------------------------------------------------\n# Survive by Pclass\n#------------------------------------------------------------------------------------------\nsns.set_style('whitegrid')\nsns.countplot(x=join_data['Pclass'],hue=join_data['Survived'],data=join_data)","d3385e4d":"#------------------------------------------------------------------------------------------\n# Survive by Embarked\n#------------------------------------------------------------------------------------------\nsns.set_style('whitegrid')\nsns.countplot(x=join_data['Embarked'],hue=join_data['Survived'],data=join_data)","9f6a9b20":"#------------------------------------------------------------------------------------------\n# Embarked by PClass\n#------------------------------------------------------------------------------------------\ndf=join_data\nfig,axx= plt.subplots(1, 3, figsize=(20,5))\naxx[0].set_title('Embarked in Southampton by Class')\nsns.countplot(x=df[df[\"Embarked\"] == \"S\"][\"Pclass\"],hue=df[df[\"Embarked\"] == \"S\"]['Survived'],data=df[df[\"Embarked\"] == \"S\"], ax=axx[0])\naxx[1].set_title('Embarked in Cherbourg by Class')\nsns.countplot(x=df[df[\"Embarked\"] == \"C\"][\"Pclass\"],hue=df[df[\"Embarked\"] == \"C\"]['Survived'],data=df[df[\"Embarked\"] == \"C\"], ax=axx[1])\naxx[2].set_title('Embarked in Queenstown by Class')\nsns.countplot(x=df[df[\"Embarked\"] == \"Q\"][\"Pclass\"],hue=df[df[\"Embarked\"] == \"Q\"]['Survived'],data=df[df[\"Embarked\"] == \"Q\"], ax=axx[2])\nplt.tight_layout()","af2b7a3d":"#------------------------------------------------------------------------------------------\n# Survive by Deck\n#------------------------------------------------------------------------------------------\nsns.set_style('whitegrid')\nsns.countplot(x=join_data['Deck'],hue=join_data['Survived'],data=join_data)","59ac1926":"#------------------------------------------------------------------------------------------\n# Sex categories\n#------------------------------------------------------------------------------------------\ncategories = {\"female\": 1, \"male\": 2}\njoin_data['Sex'] = join_data['Sex'].map(categories)\n\n#------------------------------------------------------------------------------------------\n# Embarked Categorize\n#------------------------------------------------------------------------------------------\ncategories = {\"S\": 1, \"C\": 2, \"Q\": 3}\njoin_data['Embarked'] = join_data['Embarked'].map(categories)\n\n#------------------------------------------------------------------------------------------\n# Deck Category\n#------------------------------------------------------------------------------------------\ncategories = {'C': 1, 'B': 2, 'D':3, 'E': 4, 'A': 5,'N': 6,'G': 7, 'F':8,'T':9}\njoin_data['Deck'] = join_data[\"Deck\"].map(categories)\n\n#------------------------------------------------------------------------------------------\n# AgeRange Categories\n#------------------------------------------------------------------------------------------\ncategories = {'<=7':0, '8-14':1, '15-21':2,'22-28':3,'29-35':4,'35-42':5,'43-49':6,'50-56':7,'>57':8}\njoin_data['AgeRange'] = join_data[\"AgeRange\"].map(categories)\n\n#------------------------------------------------------------------------------------------\n# AgeGroup Categories\n#------------------------------------------------------------------------------------------\ncategories = {'child':0, 'adult':1}\njoin_data['AgeGroup'] = join_data[\"AgeGroup\"].map(categories)","f2f95bf4":"#------------------------------------------------------------------------------------------\n# Separate Again to train and eval\n#------------------------------------------------------------------------------------------\ntrain_data = join_data[:train_len]\neval_data = join_data[train_len:]\n\neval_data = eval_data.drop(columns=[\"Survived\"])","ca869269":"#------------------------------------------------------------------------------------------\n# Features and Label\n#------------------------------------------------------------------------------------------\nfeatures = [\"Pclass\", \"Sex\", \"Family_size\", \"Embarked\", \"Fare\", \"Age\", \"Alone\", \"AgeGroup\", \"AgeRange\"]\nlabel = \"Survived\"\n\ntrain_data= train_data[features]\neval_data = eval_data[features]","a5235b54":"train_data","b53c0756":"eval_data","ff95ce22":"#------------------------------------------------------------------------------------------\n# Normalization\n#------------------------------------------------------------------------------------------\n#https:\/\/www.geeksforgeeks.org\/python-how-and-where-to-apply-feature-scaling\/\n#td = normalize(train_data)\n#train_data = pd.DataFrame(td, columns=features)\n#ev = normalize(eval_data)\n#eval_data = pd.DataFrame(ev, columns=features)   ","f0b3a645":"#------------------------------------------------------------------------------------------\n# Split\n#------------------------------------------------------------------------------------------\nX, y = train_data, train_data_raw[label].values\n\n# Split data 70%-30% into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 0) \n\nX_eval = eval_data","71c26aee":"#------------------------------------------------------------------------------------------\n# Cross Validation Models \n#------------------------------------------------------------------------------------------\nrandom_state = 0\nkfold = StratifiedKFold(n_splits=10)\n\nestimators = []\nestimators.append(DecisionTreeClassifier(random_state=random_state))\nestimators.append(RandomForestClassifier(random_state=random_state))\nestimators.append(GradientBoostingClassifier(random_state=random_state))\nestimators.append(AdaBoostClassifier(random_state=random_state))\nestimators.append(SVC(random_state=random_state))\n\ncv_results = []\nfor estimator in estimators :\n    cv_results.append(cross_val_score(estimator, X_train, y = y_train, scoring = \"accuracy\", cv = kfold))\n\ncv_means = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n\ncv_res = pd.DataFrame({\"Algorithm\":[\n    \"Decision Tree\",\n    \"Random Forest\",\n    \"Gradient Boosting\",\n    \"Ada Boost\",\n    \"SVC\"],\"Score\":cv_means,\"Std Desv\": cv_std})\n\ncv_res\n\n#   Algorithm           Score       Std Desv\n#0  Decision Tree       0.765489    0.055503\n#1  Random Forest       0.784997    0.045718\n#2  Gradient Boosting   0.831336    0.035730\n#3  Ada Boost           0.791270    0.042242\n#4  SVC                 0.653379    0.039603","df2a568a":"#------------------------------------------------------------------------------------------\n# Hyper parameters Random Forest\n#------------------------------------------------------------------------------------------\nrf = RandomForestClassifier(random_state=random_state)\nclf = GridSearchCV(estimator=rf, param_grid={'max_depth':[4, 5, 6], \n                                          'criterion':['gini','entropy'],\n                                          'min_samples_split':[2, 3, 10], \n                                          'min_samples_leaf':[1, 2, 3, 10], \n                                          'n_estimators':[100, 200]}\n                                          ,cv = kfold \n                                          )\n\nclf.fit(X_train, y_train)\nclf.score(X_test, y_test)\nRandomFlorest_best = clf.best_estimator_\n\nprint(clf.best_params_)\nprint(clf.best_score_)\ndf = pd.DataFrame(clf.cv_results_)\nsorted_df = df.sort_values(by = \"rank_test_score\",ascending = True).head(10)\nsorted_df[[\n    'param_criterion', \n    'param_max_depth', \n    'param_min_samples_split', \n    'param_min_samples_leaf', \n    'param_n_estimators', \n    'mean_test_score',\n    'rank_test_score']]\n\n#{'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n#0.8363031233998977","4239351a":"#------------------------------------------------------------------------------------------\n# Hyper parameters Gradient Boster\n#------------------------------------------------------------------------------------------\nrf = GradientBoostingClassifier()\nclf = GridSearchCV(estimator=rf, param_grid={\n                                          'n_estimators':[100, 200, 300], \n                                          'learning_rate': [0.1, 0.05, 0.01],\n                                          'max_depth': [4, 8], \n                                          'min_samples_leaf': [100,150], \n                                          'max_features': [0.3, 0.1] }\n                                          ,cv=kfold \n                                          )\n\nclf.fit(X_train, y_train)\nclf.score(X_test, y_test)\nGradientBoster_best = clf.best_estimator_\n\nprint(clf.best_params_)\nprint(clf.best_score_)\ndf = pd.DataFrame(clf.cv_results_)\nsorted_df = df.sort_values(by = \"rank_test_score\",ascending = True).head(10)\nsorted_df[[\n    'param_n_estimators',\n    'param_learning_rate',\n    'param_max_depth',\n    'param_min_samples_leaf',\n    'param_max_features',\n    'mean_test_score',\n    'rank_test_score']]\n\n#{'learning_rate': 0.1, 'max_depth': 4, 'max_features': 0.3, 'min_samples_leaf': 100, 'n_estimators': 300}\n#0.8121863799283154","efb275f6":"#------------------------------------------------------------------------------------------\n# Hyper parameters SVC\n#------------------------------------------------------------------------------------------\nrf = SVC(random_state=random_state, probability = True)\nclf = GridSearchCV(estimator=rf, param_grid={\n                                            'kernel': ['rbf'],\n                                            'gamma': [ 0.001, 0.01, 0.1, 1],\n                                            'C': [1, 10, 50, 100,200,300, 1000]\n                                            })\n\nclf.fit(X_train, y_train)\nclf.score(X_test, y_test)\nSVC_best = clf.best_estimator_\n\nprint(clf.best_params_)\nprint(clf.best_score_)\ndf = pd.DataFrame(clf.cv_results_)\nsorted_df = df.sort_values(by = \"rank_test_score\",ascending = True).head(10)\nsorted_df[[\n    'param_kernel',\n    'param_gamma',\n    'param_C',\n    'mean_test_score','rank_test_score']]\n\n#{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n#0.7834193548387097","551a9843":"#------------------------------------------------------------------------------------------\n# Hyper parameters Ada Booster\n#------------------------------------------------------------------------------------------\ndtc = DecisionTreeClassifier()\nrf = AdaBoostClassifier(dtc,random_state=random_state)\nclf = GridSearchCV(estimator=rf, param_grid={\n                                            'base_estimator__criterion': [\"gini\", \"entropy\"],\n                                            'base_estimator__splitter': [\"best\", \"random\"],\n                                            'algorithm': [\"SAMME\",\"SAMME.R\"],\n                                            \"n_estimators\" :[1,2],\n                                            \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]\n                                            })\n\nclf.fit(X_train, y_train)\nclf.score(X_test, y_test)\nAdaBooste_best = clf.best_estimator_\n\nprint(clf.best_params_)\nprint(clf.best_score_)\ndf = pd.DataFrame(clf.cv_results_)\nsorted_df = df.sort_values(by = \"rank_test_score\",ascending = True).head(10)\nsorted_df[[\n    'param_base_estimator__criterion',\n    'param_base_estimator__splitter',\n    'param_algorithm',\n    'param_n_estimators',\n    'param_n_estimators',\n    'mean_test_score','rank_test_score']]\n\n#{'algorithm': 'SAMME.R', 'base_estimator__criterion': 'entropy', 'base_estimator__splitter': 'best', 'learning_rate': 0.1, 'n_estimators': 2}\n#0.7913290322580646","ad53be0c":"#------------------------------------------------------------------------------------------\n# VotingClassifier\n#------------------------------------------------------------------------------------------\nv1 = RandomFlorest_best\nv2 = GradientBoster_best\nv3 = SVC_best\n\n#ensemble model\nemodel = VotingClassifier(estimators=[('rf', v1), ('gb', v2),('svc', v3)],voting='hard')\n\nfor clf, label in zip([v1, v2, v3, emodel], [ 'Random Forest','Gradient Boster', 'SVC', 'Ensemble']): \n    scores = cross_val_score(clf, X, y, cv=kfold, scoring='accuracy')\n    print(\"Accuracy: %0.2f [%s]\" % (scores.mean(), label))\n    \nfmodel = emodel \n\n# Best combination\n#Accuracy: 0.83 [Random Forest]\n#Accuracy: 0.82 [Gradient Boster]\n#Accuracy: 0.82 [SVC]\n#Accuracy: 0.84 [Ensemble]\n\n#Accuracy: 0.83 [Random Forest]\n#Accuracy: 0.81 [Gradient Boster]\n#Accuracy: 0.79 [Ada Booster]\n#Accuracy: 0.83 [Ensemble]","dbda04a3":"#final model fit\nfmodel.fit(X_train, y_train)\n\n#Score\npredictions_train = fmodel.predict(X_train)\npredictions_test = fmodel.predict(X_test)\nprint('train score :',accuracy_score(y_train ,predictions_train))\nprint('test score :',accuracy_score(y_test , predictions_test))\nprint(classification_report(y_test, predictions_test ))\n\n#------------------------------------------------------------------------------------------\n# Submit\n#------------------------------------------------------------------------------------------\n\npredictions = fmodel.predict(X_eval)\n\noutput = pd.DataFrame({'PassengerId': eval_data_raw.PassengerId, 'Survived': predictions})\noutput.to_csv(\"submission.csv\", index=False)\nprint(datetime.datetime.now() , \"Your submissions was successfully saved!\")\n\noutput.head()","0337a55a":"# 5. Feature Correlation","22b86461":"# 1.Imports","cff50bc7":"# 7. X and y Split","d0d45088":"# 3. Data analysis","8dfe4e72":"# 10. Analyse the results and submit","f45faeba":"# 9. Hyperparameters","c0d1695e":"# 8. Cross Validation Models","db911b67":"# 2.Datasets","c9af51bc":"# 6. Final Preparation of Data","d5c9f1c7":"# Titanic Survival Model\n![Titanic](https:\/\/imgc.allpostersimages.com\/img\/print\/u-g-PGF0TC0.jpg?w=200&h=300)\n","31c276c0":"# 4. Feature Engineering"}}