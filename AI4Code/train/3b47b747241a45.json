{"cell_type":{"00aba148":"code","bdb1c055":"code","6be4405f":"code","996832d3":"code","09781a86":"code","49a42a14":"code","77a51595":"code","de75f88a":"code","6ba0e810":"code","9bfa153b":"code","8bb39a59":"code","d9f657c7":"code","afd66cc0":"code","795cc5c5":"code","58b28d8a":"code","b287484e":"code","341a8ae2":"code","555c1dd6":"code","95a2fc33":"code","1f92f335":"code","5ad04004":"code","bc933cdb":"code","64fdcfae":"code","10dc15ff":"code","53ffd04b":"code","510cd372":"code","ef5b7859":"code","da717985":"code","f6ddedcc":"code","5ff2f404":"code","8f63fe97":"code","9f28e4a7":"code","01cad917":"code","50ce24a6":"code","3d986734":"code","99685d09":"code","0143336b":"code","45822d12":"code","041b0b04":"code","6cf36e58":"markdown","d07c510f":"markdown","8a789a1f":"markdown","3f42968e":"markdown","69b759ea":"markdown","2e4c3050":"markdown","18649078":"markdown","a67dd99a":"markdown","45a804a6":"markdown","839d1268":"markdown","e045564d":"markdown","dc9ee947":"markdown","06774360":"markdown","fa6bc507":"markdown","acd51445":"markdown","183773e9":"markdown","a6eebeb9":"markdown","8bccac75":"markdown","51acea03":"markdown","3b0e7d26":"markdown","6960edad":"markdown","4bbbbf9a":"markdown"},"source":{"00aba148":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bdb1c055":"data1 = pd.read_excel('..\/input\/lemon-trade\/lemon.xlsx')","6be4405f":"data1.info()","996832d3":"data1.head()","09781a86":"data1.describe()","49a42a14":"data1.columns","77a51595":"data1_countries = pd.DataFrame(data1.iloc[:,0])\ndata1_features = data1.iloc[:,1:]","de75f88a":"from sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\nimputer.fit(data1_features)\ndata1_features_imputed = imputer.transform(data1_features)","6ba0e810":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\ndata1_features_scaled = sc.fit_transform(data1_features_imputed)\ndata1_df = pd.DataFrame(data1_features_scaled, columns = [\"Import value ($)\", \"Annual increase rate in import (%)\",\"Quarterly increase rate in import (%)\", \"Import unit value (USD\/ton)\",\n\"Turkey's export value ($)\", \"Annual increase rate in Turkey's export (%)\",\"Quarterly increase rate in Turkish export (%)\",\"Turkey's export unit value (USD\/ton)\"])","9bfa153b":"data1_df.head()","8bb39a59":"#In this round we will use import values of countries and Turkey's export value for first clustering\nx1 = data1_df.loc[:,[\"Import value ($)\",\"Turkey's export value ($)\"]].values","d9f657c7":"print((x1))","afd66cc0":"from sklearn.cluster import KMeans\nwcss = []\nfor i in range(1,11):\n  kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 0)  # init = 'k-means++' is used to avoid random initilization trap\n  kmeans.fit(x1)\n  wcss.append(kmeans.inertia_)\nplt.plot(range(1,11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","795cc5c5":"kmeans = KMeans(n_clusters = 5, init = 'k-means++', random_state = 0)  # init = 'k-means++' is used to avoid random initilization trap\ny1 = kmeans.fit_predict(x1)","58b28d8a":"print(y1)","b287484e":"plt.scatter(x1[y1 == 0, 0], x1[y1 == 0, 1], s = 100, c = 'blue', label = 'Cluster 1' )\nplt.scatter(x1[y1 == 1, 0], x1[y1 == 1, 1], s = 100, c = 'red', label = 'Cluster 2' )\nplt.scatter(x1[y1 == 2, 0], x1[y1 == 2, 1], s = 100, c = 'green', label = 'Cluster 3' )\nplt.scatter(x1[y1 == 3, 0], x1[y1 == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4' )\nplt.scatter(x1[y1 == 4, 0], x1[y1 == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5' )\nplt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s = 10, c = 'orange', label = 'Centroids')\nplt.title('Clusters_1')\nplt.xlabel('Import Value($)')\nplt.ylabel(\"Turkey's Export Value\")\nplt.legend()\nplt.show()","341a8ae2":"data1_df[\"Clusters_1\"] = y1\ndata1_final = pd.concat([data1_countries, data1_df], sort=False, axis=1)\nprint(\"Clusters According to Import and TR Export Values\")\ndata1_final.head()","555c1dd6":"# In this round we will further subgroup clusters 2,3 and 5 of the first round\nclusters_1 = [1,2,4]  # clusters 2,3,5\ndata2 = data1_final[data1_final.Clusters_1.isin(clusters_1)]    # filtering","95a2fc33":"data2.info()","1f92f335":"data2_countries = pd.DataFrame(data2.iloc[:,0])\ndata2_df = data2.iloc[:,1:]","5ad04004":"#In this round we will use annual increase rate in import values of countries and Turkey's export value for second clustering\nx2 = data2_df.loc[:,[\"Annual increase rate in import (%)\",\"Annual increase rate in Turkey's export (%)\"]].values","bc933cdb":"print(x2)","64fdcfae":"from sklearn.cluster import KMeans\nwcss = []\nfor i in range(1,11):\n  kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 0)  # init = 'k-means++' is used to avoid random initilization trap\n  kmeans.fit(x2)\n  wcss.append(kmeans.inertia_)\nplt.plot(range(1,11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","10dc15ff":"kmeans = KMeans(n_clusters = 3, init = 'k-means++', random_state = 0)  # init = 'k-means++' is used to avoid random initilization trap\ny2 = kmeans.fit_predict(x2)","53ffd04b":"print(y2)","510cd372":"plt.scatter(x2[y2 == 0, 0], x2[y2 == 0, 1], s = 100, c = 'blue', label = 'Cluster 1' )\nplt.scatter(x2[y2 == 1, 0], x2[y2 == 1, 1], s = 100, c = 'red', label = 'Cluster 2' )\nplt.scatter(x2[y2 == 2, 0], x2[y2 == 2, 1], s = 100, c = 'green', label = 'Cluster 3' )\nplt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s = 10, c = 'orange', label = 'Centroids')\nplt.title('Clusters_2')\nplt.xlabel('Annual increase rate in import(%)')\nplt.ylabel(\"Annual increase rate in Turkey's export (%)\")\nplt.legend()\nplt.show()","ef5b7859":"data2_df[\"Clusters_2\"] = y2\ndata2_final = pd.concat([data2_countries, data2_df], sort=False, axis=1)\nprint(\"Clusters According to Annual Increase Rates\")\ndata2_final.head()","da717985":"# In this round we will further subgroup clusters 2 and 3 of the second round\nclusters_2 = [1,2]  # clusters 2,3\ndata3 = data2_final[data2_final.Clusters_2.isin(clusters_2)]    # filtering","f6ddedcc":"data3.info()","5ff2f404":"data3_countries = pd.DataFrame(data3.iloc[:,0])\ndata3_df = data3.iloc[:,1:]","8f63fe97":"#In this round we will use import unit value of countries and export unit value for Turkey for third clustering\nx3 = data3_df.loc[:,[\"Import unit value (USD\/ton)\",\"Turkey's export unit value (USD\/ton)\"]].values","9f28e4a7":"print(x3)","01cad917":"from sklearn.cluster import KMeans\nwcss = []\nfor i in range(1,6):\n  kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 0)  # init = 'k-means++' is used to avoid random initilization trap\n  kmeans.fit(x3)\n  wcss.append(kmeans.inertia_)\nplt.plot(range(1,6), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","50ce24a6":"kmeans = KMeans(n_clusters = 3, init = 'k-means++', random_state = 0)  # init = 'k-means++' is used to avoid random initilization trap\ny3 = kmeans.fit_predict(x3)","3d986734":"print(y3)","99685d09":"plt.scatter(x3[y3 == 0, 0], x3[y3 == 0, 1], s = 100, c = 'blue', label = 'Cluster 1' )\nplt.scatter(x3[y3 == 1, 0], x3[y3 == 1, 1], s = 100, c = 'red', label = 'Cluster 2' )\nplt.scatter(x3[y3 == 2, 0], x3[y3 == 2, 1], s = 100, c = 'green', label = 'Cluster 3' )\nplt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s = 10, c = 'orange', label = 'Centroids')\nplt.title('Clusters_3')\nplt.xlabel('Import unit value (USD\/ton)')\nplt.ylabel(\"Turkey's export unit value (USD\/ton)\")\nplt.legend()\nplt.show()","0143336b":"data3_df[\"Clusters_3\"] = y3\ndata3_final = pd.concat([data3_countries, data3_df], sort=False, axis=1)\nprint(\"Clusters According to Unit Values\")\ndata3_final.head()","45822d12":"# Clusters with respectively higher unit values for Turkish Export are chosen as the target markets\nclusters_3 = [0,2]  # clusters 1,3\ndata_final = data3_final[data3_final.Clusters_3.isin(clusters_3)]    # filtering\ndata_final.head()","041b0b04":"plt.scatter(x3[y3 == 0, 0], x3[y3 == 0, 1], s = 100, c = 'blue', label = 'Cluster 1' )\nplt.scatter(x3[y3 == 2, 0], x3[y3 == 2, 1], s = 100, c = 'green', label = 'Cluster 3' )\nplt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s = 10, c = 'orange', label = 'Centroids')\nplt.title('Clusters_3')\nplt.xlabel('Import unit value (USD\/ton)')\nplt.ylabel(\"Turkey's export unit value (USD\/ton)\")\nplt.legend()\nplt.show()","6cf36e58":"**Using the elbow method to find the optimal number of clusters**","d07c510f":"**Visualising the clusters**","8a789a1f":"**Using the elbow method to find the optimal number of clusters**","3f42968e":"**Training the K-Means model on the dataset**","69b759ea":"**Final Results**","2e4c3050":"**First Round of Clustering**","18649078":"**Visualising the clusters**","a67dd99a":"**Conclusion**\n\nIn this kernel, I used K-Means Clustering to select target markets for lemon exporting Turkish firms. After a 3 step clustering Canada, Poland, Russia and USA seems to be best markets to find potential customers.","45a804a6":"**Taking care of missing data**","839d1268":"**Preprocessing the data**","e045564d":"**Preprocessing the data**","dc9ee947":"**Data with clusters**","06774360":"In this kernel K-Means clustering is used to select target markets for lemon export by Turkish firms. To do this we will use 6 features of world lemon trade in 2016. For visualization purposes, clustering will be made in three rounds with two features each time. This data has been acquired from www.trademap.org","fa6bc507":"**Data with clusters**","acd51445":"**Visualising the clusters**","183773e9":"**Training the K-Means model on the dataset**","a6eebeb9":"**Feature Scaling**","8bccac75":"**Importing and preprocessing the data**","51acea03":"**Data with clusters**","3b0e7d26":"**Training the K-Means model on the dataset**","6960edad":"**Using the elbow method to find the optimal number of clusters**","4bbbbf9a":"**Second Round of Clustering**"}}