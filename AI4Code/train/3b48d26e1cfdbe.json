{"cell_type":{"7522dc87":"code","bee89a14":"code","384633aa":"code","bf01715d":"code","7f6805a1":"code","94e7c52b":"code","2880b0c3":"code","4b72d8fe":"code","4fe1a597":"code","363acf83":"code","1223ac20":"code","d7cd6aa8":"code","4fecb250":"code","9bacadc8":"code","6160c567":"code","aadb45e9":"code","8d625e33":"code","fef7e5d9":"code","9986e305":"code","64ccb78e":"code","eeb436fb":"code","74fe4d69":"code","dcfed0c5":"code","f7d583aa":"code","9987c233":"code","5d87c7b4":"code","5c3f8466":"markdown","91c661af":"markdown","d1c0fb41":"markdown","ba02bac2":"markdown","88e16319":"markdown","c6a23c4f":"markdown","29136fbc":"markdown","ce79687e":"markdown"},"source":{"7522dc87":"#importing liberaries \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nimport os\nimport glob as gb\nimport cv2\nimport tensorflow as tf\nimport keras","bee89a14":"#data path\ntrainpath = '..\/input\/intel-image-classification\/seg_train\/'\ntestpath = '..\/input\/intel-image-classification\/seg_test\/'\npredpath = '..\/input\/intel-image-classification\/seg_pred\/'","384633aa":"#training data informations \nFolder_name=[]\nfolder_item_numbers = []\nfor folder in  os.listdir(trainpath + 'seg_train') : \n    files = gb.glob(pathname= str( trainpath +'seg_train\/\/' + folder + '\/*.jpg'))\n    Folder_name.append(folder)\n    folder_item_numbers.append(len(files))\nfoldernames=pd.DataFrame({'Folder_name':Folder_name})\nitemnumbers=pd.DataFrame({'Traning Image Numbers':folder_item_numbers})\ninformations=pd.concat([foldernames,itemnumbers],axis=1)\nprint(informations)\n","bf01715d":"#test data informations \nFolder_name=[]\nfolder_item_numbers = []\nfor folder in  os.listdir(testpath + 'seg_test') : \n    files = gb.glob(pathname= str( testpath +'seg_test\/\/' + folder + '\/*.jpg'))\n    Folder_name.append(folder)\n    folder_item_numbers.append(len(files))\nfoldernames=pd.DataFrame({'Folder_name':Folder_name})\nitemnumbers=pd.DataFrame({' Test Image Numbers':folder_item_numbers})\ninformations=pd.concat([foldernames,itemnumbers],axis=1)\nprint(informations)","7f6805a1":"#prediction data informations \nFolder_name=[]\nfolder_item_numbers = []\nfor folder in  os.listdir(predpath) : \n    files = gb.glob(pathname= str( predpath + folder + '\/*.jpg'))\n    Folder_name.append(folder)\n    folder_item_numbers.append(len(files))\nfoldernames=pd.DataFrame({'Folder_name':Folder_name})\nitemnumbers=pd.DataFrame({' pred Image Numbers':folder_item_numbers})\ninformations=pd.concat([foldernames,itemnumbers],axis=1)\nprint(informations)","94e7c52b":"#checking image size for traning data\nImage_size = []\nfor folder in  os.listdir(trainpath +'seg_train') : \n    files = gb.glob(pathname= str( trainpath +'seg_train\/\/' + folder + '\/*.jpg'))\n    for image in files: \n        read_image = plt.imread(image)\n        Image_size.append(read_image.shape)\npd.Series(Image_size).value_counts()","2880b0c3":"#checking image size for test data\nImage_size = []\nfor folder in  os.listdir(testpath +'seg_test') : \n    files = gb.glob(pathname= str( testpath +'seg_test\/\/' + folder + '\/*.jpg'))\n    for image in files: \n        read_image = plt.imread(image)\n        Image_size.append(read_image.shape)\npd.Series(Image_size).value_counts()","4b72d8fe":"#checking image size for pred data\nImage_size = []\nfor folder in  os.listdir(predpath) : \n    files = gb.glob(pathname= str( predpath + folder + '\/*.jpg'))\n    for image in files: \n        read_image = plt.imread(image)\n        Image_size.append(read_image.shape)\npd.Series(Image_size).value_counts()","4fe1a597":"#resize each image in all folders\n#identifing new size as 100 \n#converting images to an array as X_train and and making a labeling array for it as y_train\nnew_size=100    \nX_train = []\ny_train = []\nfor folder in  os.listdir(trainpath +'seg_train') : \n    files = gb.glob(pathname= str( trainpath +'seg_train\/\/' + folder + '\/*.jpg'))\n    for file in files: \n        image_class = {'buildings':0 ,'forest':1,'glacier':2,'mountain':3,'sea':4,'street':5}\n        orignal_image = cv2.imread(file)\n        resized_image = cv2.resize(orignal_image , (new_size,new_size))\n        X_train.append(list(resized_image))\n        y_train.append(image_class[folder])\n","363acf83":"#check items in X_train\nprint(\"items in X_train is:       \",len(X_train) , \" items\")","1223ac20":"#showing training images with labels\nplt.figure(figsize=(20,20))\nfor n , i in enumerate(list(np.random.randint(0,len(X_train),36))) : \n    plt.subplot(6,6,n+1)\n    plt.imshow(X_train[i])   \n    plt.axis('off')\n    classes = {'buildings':0 ,'forest':1,'glacier':2,'mountain':3,'sea':4,'street':5}\n    def get_img_class(n):\n        for x , y in classes.items():\n            if n == y :\n                return x\n    plt.title(get_img_class(y_train[i]))","d7cd6aa8":"#resize each image in all folders for Test Data\n#identifing new size as 100 \n#converting images to an array as X_test and and making a labeling array for it as y_test\nnew_size=100    \nX_test = []\ny_test = []\nfor folder in  os.listdir(testpath +'seg_test') : \n    files = gb.glob(pathname= str( testpath +'seg_test\/\/' + folder + '\/*.jpg'))\n    for file in files: \n        image_class = {'buildings':0 ,'forest':1,'glacier':2,'mountain':3,'sea':4,'street':5}\n        orignal_image = cv2.imread(file)\n        resized_image = cv2.resize(orignal_image , (new_size,new_size))\n        X_test.append(list(resized_image))\n        y_test.append(image_class[folder])","4fecb250":"#check items in X_test\nprint(\"items in X_test is:       \",len(X_test) , \" items\")","9bacadc8":"#showing test images with labels\nplt.figure(figsize=(20,20))\nfor n , i in enumerate(list(np.random.randint(0,len(X_test),36))) : \n    plt.subplot(6,6,n+1)\n    plt.imshow(X_test[i])   \n    plt.axis('off')\n    classes = {'buildings':0 ,'forest':1,'glacier':2,'mountain':3,'sea':4,'street':5}\n    def get_img_class(n):\n        for x , y in classes.items():\n            if n == y :\n                return x\n    plt.title(get_img_class(y_test[i]))","6160c567":"#resize each image in all folders for prediction Data\n#identifing new size as 100 \n#converting images to an array as X_pred\nnew_size=100    \nX_pred = []\nfor folder in  os.listdir(predpath) : \n    files = gb.glob(pathname= str( predpath + folder + '\/*.jpg'))\n    for file in files: \n        image_class = {'buildings':0 ,'forest':1,'glacier':2,'mountain':3,'sea':4,'street':5}\n        orignal_image = cv2.imread(file)\n        resized_image = cv2.resize(orignal_image , (new_size,new_size))\n        X_pred.append(list(resized_image))","aadb45e9":"#check items in X_pred\nprint(\"items in X_pred is:       \",len(X_pred) , \" items\")","8d625e33":"#showing some prediction images\nplt.figure(figsize=(20,20))\nfor n , i in enumerate(list(np.random.randint(0,len(X_pred),36))) : \n    plt.subplot(6,6,n+1)\n    plt.imshow(X_pred[i])   \n    plt.axis('off')","fef7e5d9":"#converting all data to array\nX_train = np.array(X_train)\nX_test = np.array(X_test)\nX_Pred = np.array(X_pred)\ny_train = np.array(y_train)\ny_test = np.array(y_test)\nprint(\"X_train shape  : \",X_train.shape)\nprint(\"X_test shape  :\" ,X_test.shape)\nprint(\"X_Pred shape :\" , X_Pred.shape)\nprint(\"y_train shape :\" ,y_train.shape)\nprint(\"y_test shape :\", y_test.shape)","9986e305":"\nClassification_Model_Keras = keras.models.Sequential([\n        keras.layers.Conv2D(256,kernel_size=(3,3),activation='relu',input_shape=(new_size,new_size,3)),\n        keras.layers.Conv2D(128,kernel_size=(3,3),activation='relu'),\n        keras.layers.Conv2D(64,kernel_size=(3,3),activation='relu'),\n        keras.layers.MaxPool2D(4,4),\n        keras.layers.Conv2D(128,kernel_size=(3,3),activation='relu'),    \n        keras.layers.Conv2D(64,kernel_size=(3,3),activation='relu'),    \n        keras.layers.Conv2D(32,kernel_size=(3,3),activation='relu'),\n        keras.layers.MaxPool2D(4,4),\n        keras.layers.Flatten() ,    \n        keras.layers.Dense(128,activation='relu') ,    \n        keras.layers.Dense(64,activation='relu') ,    \n        keras.layers.Dense(32,activation='relu') ,        \n        keras.layers.Dropout(rate=0.5) ,            \n        keras.layers.Dense(6,activation='softmax') ,    \n        ])","64ccb78e":"Classification_Model_Keras.compile(optimizer ='adam',\n                                   loss='sparse_categorical_crossentropy',\n                                   metrics=['accuracy'])","eeb436fb":"print('Model Summary: ')\nprint(Classification_Model_Keras.summary())","74fe4d69":"epochs = 40\nKerasModel = Classification_Model_Keras.fit(X_train, y_train, epochs=epochs,batch_size=64,verbose=1)\n","dcfed0c5":"val_Loss, val_Acc = Classification_Model_Keras.evaluate(X_test, y_test)\n\nprint('Test Loss:', val_Loss)\nprint('Test Accuracy :', val_Acc)","f7d583aa":"y_test_pred = Classification_Model_Keras.predict(X_test)\n\nprint('y_test_pred Shape :',y_test_pred.shape)","9987c233":"y_pred = Classification_Model_Keras.predict(X_Pred)\n\nprint('Prediction Shape for y_result : ',y_pred.shape)","5d87c7b4":"plt.figure(figsize=(20,20))\nfor n , i in enumerate(list(np.random.randint(0,len(X_pred),36))) : \n    plt.subplot(6,6,n+1)\n    plt.imshow(X_pred[i])    \n    plt.axis('off')\n    classes = {'buildings':0 ,'forest':1,'glacier':2,'mountain':3,'sea':4,'street':5}\n    def get_img_class(n):\n        for x , y in classes.items():\n            if n == y :\n                return x\n    plt.title(get_img_class(np.argmax(y_pred[i])))","5c3f8466":"for compling Model:\nwe will use adam optimizer\nsparse categorical crossentropy loss as we have 6 output\n\n","91c661af":"train the model \nwe will  use 40 epochs","d1c0fb41":"final loss & accuracy","ba02bac2":"Model summary ","88e16319":"Categories Prediction (y_pred) of X_Pred","c6a23c4f":" showing some random images from the predicted images and its predicting category","29136fbc":"predicting Categories of X_test","ce79687e":"building the CNN model using Keras \nwe will make Conv2D layers , MaxPooling & Denses"}}