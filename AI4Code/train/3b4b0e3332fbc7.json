{"cell_type":{"6251b6e8":"code","359f27ad":"code","7ad5f763":"code","019c169d":"code","1f52039b":"code","535faba2":"code","f589e01b":"code","b5915350":"code","8f7a5a86":"code","28b72b61":"code","3db9e8eb":"code","8df792b9":"code","3c7b70ba":"code","174d7c81":"code","a61fc66d":"code","493380e2":"code","85a7579f":"code","400ea8cb":"code","66f92325":"code","4a084e8d":"code","691af4ee":"code","6d95dc97":"code","c5a5c071":"code","1dc449a5":"code","0271ad09":"code","48e4e63c":"code","70344fce":"markdown"},"source":{"6251b6e8":"from fastai import *\nfrom fastai.text import * \n\ndef random_seed(seed_value, use_cuda):\n    np.random.seed(seed_value) # cpu vars\n    torch.manual_seed(seed_value) # cpu  vars\n    random.seed(seed_value) # Python\n    if use_cuda: \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value) # gpu vars\n        torch.backends.cudnn.deterministic = True  #needed\n        torch.backends.cudnn.benchmark = False\n        \nrandom_seed(42, True)","359f27ad":"Path('data\/hard\/').mkdir(parents=True, exist_ok=True)\n!cp '..\/input\/balanced-reviews\/balanced-reviews-utf8.tsv' data\/hard\/balanced-reviews.tsv","7ad5f763":"path=Path('data\/hard\/')\ndf_ar = pd.read_csv(path\/'balanced-reviews.tsv', delimiter='\\t')\ndf_ar.head() # the first review sounds positive but rating is 2 (-ve). Reviewer's choice!","019c169d":"df_ar = df_ar[['rating', 'review']] # we are interested in rating and review only\n# code rating as +ve if > 3, -ve if less, no 3s in dataset \ndf_ar['rating'] = df_ar['rating'].apply(lambda x: -1 if x < 3 else 1)\n# rename columns to fit default constructor in fastai\ndf_ar.columns = ['label', 'text']\ndf_ar.head()","1f52039b":"df_valid = df_ar.sample(21140, replace = False) # 20% for validation\ndf_valid['is_valid'] = True\ndf_train = df_ar.drop(df_valid.index)\ndf_train['is_valid'] = False\n\ndf_all = pd.concat([df_train, df_valid])\ndf_all.head()","535faba2":"# write to csv (overwrites by default)\ndf_all.to_csv(path\/'hard_text.csv', index=False)","f589e01b":"df = pd.read_csv(path\/'hard_text.csv')\ndf.head()","b5915350":"Path('models\/').mkdir(parents=True, exist_ok=True)\n!cp -a '..\/input\/model45_30_4\/lm_best.pth' models\/\n!cp '..\/input\/model45_30_4\/itos.pkl' models\/","8f7a5a86":"Path('models\/').absolute() # get absolute path od model files","28b72b61":"pretrained_fnames=['\/kaggle\/working\/models\/lm_best','\/kaggle\/working\/models\/itos']","3db9e8eb":"# Language model data\ndata_lm = TextLMDataBunch.from_csv(path, 'hard_text.csv')\n# Classifier model data\ndata_clas = TextClasDataBunch.from_csv(path, 'hard_text.csv', vocab=data_lm.train_ds.vocab, bs=64, num_workers=0)","8df792b9":"data_lm.save()\ndata_clas.save()\ndata_lm = TextLMDataBunch.load(path)\ndata_clas = TextClasDataBunch.load(path, bs=64)","3c7b70ba":"learn = language_model_learner(data_lm, pretrained_fnames=pretrained_fnames, drop_mult=0.1) # was .5\nlearn.lr_find(start_lr = slice(10e-7,10e-5),end_lr=slice(0.1,10))#start_lr = slice(10e-7,10e-5),end_lr=slice(0.1,10))\nlearn.recorder.plot(skip_end=10)","174d7c81":"learn.fit_one_cycle(1, 2e-2)","a61fc66d":"learn.unfreeze()\nlearn.fit_one_cycle(3, 2e-2)","493380e2":"learn.predict(\"\u0643\u0627\u0646 \u0627\u0644\u0627\u0633\u062a\u0642\u0628\u0627\u0644 \u0641\u064a \u0627\u0644\u0641\u0646\u062f\u0642\", n_words=10)\n# first amount of words (here 10), the next 10 target words (actual) and the ones predicted.\n#learn.show_results(max_len = 10)","85a7579f":"learn.save_encoder('ft_enc')\nlearn.recorder.plot_losses()","400ea8cb":"#classifier\nlearn_clas = text_classifier_learner(data_clas, drop_mult=0.5)\nlearn_clas.load_encoder('ft_enc')","66f92325":"data_clas.show_batch(2)","4a084e8d":"learn_clas.lr_find(start_lr = slice(10e-7,10e-5),end_lr=slice(0.1,10))\nlearn_clas.recorder.plot(skip_end=10)","691af4ee":"learn_clas.fit_one_cycle(1, 2e-3)","6d95dc97":"learn_clas.freeze_to(-2)\nlearn_clas.fit_one_cycle(1, slice(1e-4, 1e-2))","c5a5c071":"learn_clas.unfreeze()\nlearn_clas.fit_one_cycle(3, slice(1e-4, 1e-2))","1dc449a5":"print(learn_clas.validate())","0271ad09":"learn_clas.recorder.plot_losses()","48e4e63c":"learn_clas.show_results(rows=20)","70344fce":"**Arabic ULMFiT Language Model Example**   \nThe dataset used for classification in this example is from the source cited below. It is being hosted here for easy access from Kaggle kernels (obtained from https:\/\/github.com\/elnagara\/HARD-Arabic-Dataset with one modification to text encoding: encoded as utf-8).  See the readme file from the authors for more details.   \nThe classification accuracy using this model is a little better than the one reported in the paper.  \n**Citation:**  \nElnagar A., Khalifa Y.S., Einea A. (2018) Hotel Arabic-Reviews Dataset Construction for Sentiment Analysis Applications. \n    In: Shaalan K., Hassanien A., Tolba F. (eds) Intelligent Natural Language Processing: Trends and Applications. \n    Studies in Computational Intelligence, vol 740, pp: 35-52. Springer International Publishing. \n    doi=\"10.1007\/978-3-319-67056-0_3. url=\"https:\/\/doi.org\/10.1007\/978-3-319-67056-0_3\" \n    ![Table 5: Results from citation](https:\/\/raw.githubusercontent.com\/abedkhooli\/ds2\/master\/ulmfit2\/models\/arabic-nlp-hard-ashraf-elnagar.PNG) "}}