{"cell_type":{"5c7a0dc3":"code","07328ee6":"code","1157b46f":"code","fc62eea9":"code","a7f94976":"code","fe69176e":"code","059993c9":"code","98f0162e":"code","4a235e40":"code","cf894198":"code","cdd788f9":"code","bbc15d24":"code","260db1da":"code","ca5208ba":"code","10c902cc":"code","1131c8e9":"code","cce7beea":"code","cf37937c":"code","8aba85e0":"code","c3c5d0dc":"code","8df9a291":"code","955e6c72":"code","0516aa52":"code","986cd4d5":"code","3e6edc14":"code","f9d2afd7":"code","2528d8d3":"code","dca42a3f":"code","fd6c8018":"code","48f72429":"code","55a3c2b5":"code","66696659":"code","950de365":"code","c51da5dd":"code","d29c9470":"code","347a8401":"code","fba8f843":"code","ee865b5f":"code","29db8846":"code","e0024d26":"code","dea6bc4f":"code","664526f9":"code","b961d9f7":"code","1accd995":"code","1a306a95":"code","6687c3ab":"code","7e202d5d":"code","4f9d22fe":"code","889b1eed":"code","09f1fd07":"code","4ca889d9":"code","1789b151":"code","3300d1d5":"code","53a9307a":"code","d0a71407":"code","65654879":"code","86ef7d8b":"code","b137c14f":"code","67cb9698":"code","2ccaf063":"code","3624580f":"code","a4ed49c5":"code","f0a6a236":"code","4ed4e3ec":"markdown","69bf3f7a":"markdown","92e9af85":"markdown","82cad36d":"markdown","75cc52d5":"markdown","9c3db852":"markdown","32284a24":"markdown","3bd7d35a":"markdown","0bb8b6f8":"markdown","ef38f44d":"markdown","27712e2b":"markdown","004e03cb":"markdown","821cde8a":"markdown","3e4b8d7d":"markdown","084524a3":"markdown","0fc19894":"markdown","65c02658":"markdown","921bf11b":"markdown","7baac811":"markdown","1562f4bd":"markdown"},"source":{"5c7a0dc3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","07328ee6":"# This post is just a practice for myself \n# I referred Udemy Jose Portilla's course 'Python for Data Science and Machine Learning Bootcamp'\n# I also have my own codes in as well\n# I have no clue how well this model will predict \n","1157b46f":"original_train = pd.read_csv('\/kaggle\/input\/train.csv')\noriginal_test = pd.read_csv('\/kaggle\/input\/test.csv')\noriginal_test.shape","fc62eea9":"original_train.head()","a7f94976":"import seaborn as sns","fe69176e":"sns.heatmap(original_train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","059993c9":"original_train['Embarked'].value_counts()","98f0162e":"# 'Embarked' visiulization\n\nsns.set_style('whitegrid')\nsns.countplot(x='Embarked',data=original_train,palette='RdBu_r')\n","4a235e40":"sns.countplot(x='Pclass',data=original_train,palette='RdBu_r')","cf894198":"sns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='Pclass',data=original_train,palette='rainbow')","cdd788f9":"original_train['Fare'].hist(color='green',bins=40,figsize=(8,4))","bbc15d24":"# get dummies for 'Sex' and 'Embarked'\nsex = pd.get_dummies(original_train['Sex'],drop_first=True)\nembark = pd.get_dummies(original_train['Embarked'],drop_first=True)","260db1da":"original_train.drop(['PassengerId','Sex','Embarked','Name','Ticket','Cabin'],axis=1,inplace=True)","ca5208ba":"original_train.head()","10c902cc":"train = pd.concat([original_train,sex,embark],axis=1)","1131c8e9":"train.head()","cce7beea":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","cf37937c":"nn = train.groupby('Pclass')","8aba85e0":"nn.mean()","c3c5d0dc":"def impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        \n        if Pclass == 1:\n            return 38.23\n        elif Pclass == 2:\n            return 29.87\n        else:\n            return 25.14\n        \n    else:\n        return Age","8df9a291":"train['Age'] = train[['Age','Pclass']].apply(impute_age,axis=1)","955e6c72":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","0516aa52":"import random\ndef my_split(percentage,new_df,y):\n    '''\n    this is for train test split function practice\n    '''\n    \n    lst = list(range(0,len(new_df)))\n    random.seed('5')\n    num_train = random.sample(lst,len(new_df))[:int((1-percentage)*len(new_df))]\n    \n    # this is for the remaining of the lst\n    num_test = []\n    for i in lst:\n        if i not in num_train:\n            num_test.append(i) \n\n    X_train = new_df.iloc[num_train,:]\n    X_test = new_df.iloc[num_test,:]\n    \n    y_train = y.iloc[num_train]\n    y_test = y.iloc[num_test]\n    \n    return X_train, X_test, y_train, y_test","986cd4d5":"#X_train, X_test, y_train, y_test = my_split(0.3,train.drop('Survived',axis = 1), y= train['Survived'])","3e6edc14":"#X_train.info()","f9d2afd7":"from sklearn.model_selection import train_test_split","2528d8d3":"X_train, X_test, y_train, y_test = train_test_split(train.drop('Survived',axis=1),\n                                                    train['Survived'], test_size=0.30, \n                                                    random_state=101)","dca42a3f":"from sklearn.linear_model import LogisticRegression","fd6c8018":"logmodel = LogisticRegression()\nlogmodel.fit(X_train,y_train)","48f72429":"preditions = logmodel.predict(X_test)","55a3c2b5":"from sklearn.metrics import classification_report","66696659":"print(classification_report(y_test,preditions))","950de365":"preditions","c51da5dd":"kaggle_test = pd.read_csv('\/kaggle\/input\/test.csv')\n#final_predic = logmodel.predict('\/kaggle\/input\/test.csv')\nkaggle_test['Age'] = kaggle_test[['Age','Pclass']].apply(impute_age,axis=1)\n","d29c9470":"sns.heatmap(kaggle_test.isnull(),yticklabels=False,cbar=False,cmap='viridis')","347a8401":"X_test.head()","fba8f843":"# get dummies for 'Sex' and 'Embarked'\ntest_sex = pd.get_dummies(kaggle_test['Sex'],drop_first=True)\ntest_embark = pd.get_dummies(kaggle_test['Embarked'],drop_first=True)\nkaggle_test.drop(['PassengerId','Sex','Embarked','Name','Ticket','Cabin'],axis=1,inplace=True)\nkaggle_test = pd.concat([kaggle_test,test_sex,test_embark],axis=1)","ee865b5f":"sns.heatmap(kaggle_test.isnull(),yticklabels=False,cbar=False,cmap='viridis')\n","29db8846":"X_test.head()","e0024d26":"kaggle_test.head()\n\nnew_kaggle = kaggle_test.fillna(value=kaggle_test['Fare'].mean())\n\nnew_kaggle[new_kaggle['Fare'].isnull()==True]","dea6bc4f":"sns.heatmap(kaggle_test.isnull(),yticklabels=False,cbar=False,cmap='viridis')","664526f9":"\n#preditions = logmodel.predict(X_test)\nkaggle_prediction = logmodel.predict(new_kaggle)","b961d9f7":"kaggle_prediction","1accd995":"submission = pd.DataFrame({'PassengerId':original_test['PassengerId'],'Survived':kaggle_prediction})\n\n#Visualize the first 5 rows\nsubmission.head()","1a306a95":" filename = 'Titanic Predictions 2.csv'\n\nsubmission.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)","6687c3ab":"from sklearn.tree import DecisionTreeClassifier","7e202d5d":"dtree = DecisionTreeClassifier()","4f9d22fe":"dtree.fit(X_train,y_train)","889b1eed":"prediction_tree = dtree.predict(X_test)","09f1fd07":"from sklearn.metrics import classification_report,confusion_matrix","4ca889d9":"print(classification_report(y_test,prediction_tree))","1789b151":"kaggle_prediction_tree = dtree.predict(new_kaggle)","3300d1d5":"kaggle_prediction_tree","53a9307a":" filename = 'Titanic Predictions 1_tree.csv'\n\nsubmission.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)","d0a71407":"from sklearn.ensemble import RandomForestClassifier","65654879":"ranforest = RandomForestClassifier()","86ef7d8b":"clf = ranforest.fit(X_train,y_train)","b137c14f":"ranforest_predict = ranforest.predict(X_test)","67cb9698":"ranforest_predict","2ccaf063":"print(classification_report(y_test,ranforest_predict))","3624580f":"kaggle_prediction_forest = ranforest.predict(new_kaggle)","a4ed49c5":"kaggle_prediction_forest","f0a6a236":"filename = 'Titanic Predictions froest.csv'\n\nsubmission.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)","4ed4e3ec":"**Now we can easily see that for different Pclass, its corresponding average age varies.**\n**\nSo we got to impute the missing data with the average for each pclass**","69bf3f7a":"**Second, SKlearn**","92e9af85":"**1\uff0c Import data from Kaggle**","82cad36d":"**We kick off with exploratory on the original data**\n\n****Let's look at the head of the dataset****","75cc52d5":"**2\uff0c Data Cleaning**\n\n**After we explore the original data, we left below items which we need to clean**\n\n**1, variable 'Name','Ticket' are on our drop menu**\n\n**2, so I would put 'Cabin' on drop menu as well.**\n\n**3,  but for 'Age', the proportion of missing ages are small enough for resonable replacements with some form of imputation. I would fill the missing parts with some values (we will get to this later)**\n\n**4, convert 'Embarked' by using creating dummies **\n","9c3db852":"**now let's try random forest method**","32284a24":"**first we train test split the data, here we can use sklearn model to import a train test split function\nbut I have completed my own function called my_split which is doing the exact the same thing as sklearn train test split, and this is just for my own practice only**\n\n**Here I am using two ways to split the data, first use my own function, second will be sklearn import**","3bd7d35a":"**Obviously we will need drop some variables that has no contribution to the pridiction **\n\n**1, I would say the variable 'Name','Ticket' are on our drop menu**\n\n**Next let's check the missing data**","0bb8b6f8":"**now we evaluate the prediction**","ef38f44d":"**then we will concatenate dummies and original data together**","27712e2b":"**the accurancy is 83%**","004e03cb":"**now let's check the head**","821cde8a":"**OK, next we train and build the model**","3e4b8d7d":"**it looks like 'Age' has some missings and 'Cabin' pretty much has no value to us since it has too much missing values\uff0c **\n\n**2, so I would put 'Cabin' on drop menu as well.**\n\n**3,  but for 'Age', the proportion of missing ages are small enough for resonable replacements with some form of imputation. I would fill the missing parts with some values (we will get to this later)**","084524a3":"**We notice that the variable 'Embarked' looks a little tricky, let's play around it to get more visibility.**","0fc19894":"**As we can see now, data is ready to go**","65c02658":"filename = 'Titanic Predictions 1_forest.csv'\n\nsubmission.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)","921bf11b":"**now our data is cleaned and one more step just need to impute the missing data**","7baac811":"## filename = 'Titanic Predictions 2.csv'\n\nsubmission.to_csv(filename,index=False)\n\nprint('Saved file: ' + filename)","1562f4bd":"**it seems'Embarked' has 3 types so we need to convert this string to numerical data so our model can read it**\n\n**4, convert 'Embarked' by using creating dummies **\n\n**let's continue by visualizing more of the data**\n\n\n\n\n"}}