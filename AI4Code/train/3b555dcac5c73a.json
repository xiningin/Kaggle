{"cell_type":{"e512e495":"code","c910b896":"code","2c4dec95":"code","fb4fe148":"code","f59356d3":"code","be67eaba":"code","9ecd9130":"code","07a96e22":"markdown","331808bc":"markdown","ae3db845":"markdown","5c47d362":"markdown","9f9b447c":"markdown"},"source":{"e512e495":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c910b896":"\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Construct a reference to the \"sdoh_hrsa_shortage_areas\" dataset\n# remember to look into \"view dataset\" in the links above to get the 1st reference.\ndataset_ref = client.dataset(\"sdoh_hrsa_shortage_areas\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)","2c4dec95":"dataset_ref","fb4fe148":"type(dataset_ref)","f59356d3":"# Construct a reference to the \"hpsa_primary_care\" table\ntable_ref = dataset_ref.table(\"hpsa_primary_care\")\n\n# List all the tables in the \"Health Professional Shortage\" dataset\ntables = list(client.list_tables(dataset))\n\n# Print names of all tables in the dataset (there are four!)\nfor table in tables:  \n    print(table.table_id)","be67eaba":"# Preview the first five lines of the \"Health Professional Shortage\" table\nclient.list_rows(table, max_results=5).to_dataframe()","9ecd9130":"cities =         \"\"\"\n                          SELECT City\n                          FROM `bigquery-public-data.sdoh_hrsa_shortage_areas.hpsa_primary_care`\n                       \"\"\"\n\n# Set up the query (cancel the query if it would use too much of your quota)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\ncities_query_job = client.query(cities, job_config=safe_config) \n\n# API request - run the query, and return a pandas DataFrame\ncities_result = cities_query_job.to_dataframe() # Your code goes here\n\n# View results\nprint(cities_result)","07a96e22":"This actually gives us a dataset reference.","331808bc":"# REMEMBER TO CHOOSE ONE of the names of the tables to be used as a table reference.\n This will be important to allow querying in bigQuery.","ae3db845":"it works!","5c47d362":"https:\/\/console.cloud.google.com\/marketplace\/product\/hhs\/health-professional-shortage-areas?project=hiiiiii-245402&folder=&organizationId=\n\n#NOTE: https:\/\/console.cloud.google.com\/marketplace\/browse?q=&filter=solution-type:dataset\n\n# Is the marketplace to find datasets.","9f9b447c":"We now have acquired the reference from the public site."}}