{"cell_type":{"fd1c417d":"code","258ed514":"code","a212c479":"code","4ccb143f":"code","2331b998":"code","13777e7f":"code","649f6937":"code","8bd4114f":"code","298f806b":"code","aabbaa5e":"code","9cfb123c":"code","07540e76":"code","7d9ca997":"code","929d957d":"code","6dd43c2c":"code","a902e166":"code","416427a7":"code","6b15802a":"code","d0a9cb10":"code","e6534b30":"code","69d8012a":"code","3fc34779":"markdown","e777ca42":"markdown","34fa7314":"markdown","8faf08cb":"markdown","84a9129d":"markdown","836397db":"markdown","4d424c38":"markdown","e3cacf63":"markdown","a9fe9654":"markdown","cc60d634":"markdown","3662fd9e":"markdown","4e126a64":"markdown","c38b61a1":"markdown","4196cc19":"markdown","0954b3c8":"markdown","cc758db4":"markdown","b31c5d1b":"markdown"},"source":{"fd1c417d":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","258ed514":"from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split, cross_validate\nfrom sklearn.metrics import plot_confusion_matrix, accuracy_score\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier","a212c479":"PATH = \"..\/input\/\"","4ccb143f":"data = pd.read_csv(os.path.join(PATH, 'titanic', 'train.csv')).set_index('PassengerId')","2331b998":"data.head()","13777e7f":"# Helper function\ndef plot_barchart(index, datas, labels, title, ylabel):\n    p1 = plt.bar(index, datas[0], 0.35)\n    p2 = plt.bar(index, datas[1], 0.35,\n                 bottom=datas[0])\n\n    plt.ylabel(ylabel)\n    plt.title(title)\n    plt.ylim(0, 1.1)\n    if labels:\n        plt.legend((p1[0], p2[0]), labels)\n\n    plt.show()    ","649f6937":"# Genders\ngenders = data.groupby(['Sex'])['Sex'].count()\n\nplt.bar(genders.index, genders)\nplt.title('Gender distribution')\nplt.show()","8bd4114f":"# Genders\nsurvival = data.groupby(['Survived'])['Survived'].count()\n\nplt.bar(['Dead', 'Alive'], survival)\nplt.title('Survival distribution')\nplt.show()","298f806b":"aliveMeans = data[data['Survived'] == 1].groupby(['Sex'])['Sex'].count() \/ data.groupby(['Sex'])['Survived'].count()\ndeadMeans = data[data['Survived'] == 0].groupby(['Sex'])['Sex'].count() \/ data.groupby(['Sex'])['Survived'].count()\n\nplot_barchart(aliveMeans.index, [aliveMeans, deadMeans],('Alive', 'Dead'), 'Survived percentage by gender', '% Survived' )","aabbaa5e":"plt.hist(data['Age'].dropna(), bins=50, label='Overall', color='#0000ff' )\nplt.hist(data[data['Survived'] ==0]['Age'].dropna(), bins=50, label='Deceased', color='#ff000055' )\nplt.hist(data[data['Survived'] ==1]['Age'].dropna(), bins=50, label='Survived', color='#00ff0055')\nplt.title('Age distribution')\nplt.ylabel('Number of passengers')\nplt.xlabel('Age')\nplt.legend()\nplt.show()","9cfb123c":"# Average age\ndata[['Age', 'Survived']].dropna().groupby(['Survived']).mean()","07540e76":"# Median age\ndata[['Age', 'Survived']].dropna().groupby(['Survived']).median()","7d9ca997":"# Age distibution for dead\/alive\nage_survival = data[['Age', 'Survived']].dropna()\n\nplt.boxplot([age_survival[(age_survival['Survived'] == 0)]['Age'], \n             age_survival[(age_survival['Survived'] == 1)]['Age']], labels=['Dead', 'Alive'], vert=False)\n\nplt.title('Age distribution for dead and alive')\nplt.ylabel('Age')\nplt.show()","929d957d":"# Passenger class\npclass_enum = sorted([f'{x} class' for x in data['Pclass'].dropna().unique()])\n\nplot_barchart(pclass_enum, [data[data['Survived'] == 1].groupby(['Pclass'])['Pclass'].count() \/ data.groupby(['Pclass'])['Survived'].count(),\n                                                   data[data['Survived'] == 0].groupby(['Pclass'])['Pclass'].count() \/ data.groupby(['Pclass'])['Survived'].count()],\n                                        ('Alive', 'Dead'), \n                                      'Survived percentage by passenger class', '% Survived' )","6dd43c2c":"# Embarked\nembarked_enum = {'C': 'Cherbourg', 'Q': 'Queenstown', 'S':'Southampton'}\nembarked_enum = sorted([embarked_enum[x] for x in data['Embarked'].dropna().unique()])\n\nplot_barchart(embarked_enum, [data[data['Survived'] == 1].groupby(['Embarked'])['Embarked'].count() \/ data.groupby(['Embarked'])['Survived'].count(),\n                                                   data[data['Survived'] == 0].groupby(['Embarked'])['Embarked'].count() \/ data.groupby(['Embarked'])['Survived'].count()],\n                      ('Alive', 'Dead'),\n                      'Survived percentage by Port of Embarkation', \n                      '% Survived' )\n","a902e166":"data.isnull().mean() * 100","416427a7":"y = data['Survived']","6b15802a":"# Suggest Age, Fare, Pclass and Sex are meaningful for survival\n# Fill missing Age values with median\n# Of course, standartization id our friend\ndata['Age'] = data['Age'].fillna(data['Age'].median())\nX_train = StandardScaler().fit_transform(pd.get_dummies(data[['Age', 'Sex', 'Fare', 'Pclass']]))\n\nlog_model = LogisticRegression(solver='liblinear', penalty='l1')\nknn_model = KNeighborsClassifier()\n\nlog_model.fit(X=X_train, y=y)\nknn_model.fit(X=X_train, y=y)\n\nprint( f'LogisticRegression model accuracy: {accuracy_score(y, log_model.predict(X_train))}')\nprint( f'KNeighborsClassifier model accuracy: {accuracy_score(y, knn_model.predict(X_train))}')\n\nprint( f'LogisticRegression model cross validate score (mean): {cross_validate(log_model, X_train, y, cv=5)[\"test_score\"].mean()}')\nprint( f'KNeighborsClassifier model cross validate score (mean): {cross_validate(knn_model, X_train, y, cv=5)[\"test_score\"].mean()}')\n","d0a9cb10":"# Data preparation (this is the end of VERY LONG way)\n# - Divide dataset in 3 parts for children, adult and aged people\n# - Use different models for these parts\n# - `Age` and `Fare` are meaningful only for adults\n# - `Family` is useful for all ages\n# - `Ticket` might identify people traveling together\n\nnp.random.seed(52)\n\n# Read all available data\ndata = pd.read_csv(os.path.join(PATH, 'titanic', 'train.csv')).set_index('PassengerId')\ntest_data_preprocess = pd.read_csv(os.path.join(PATH, 'titanic', 'test.csv')).set_index('PassengerId')\n# Combine datasets to create correct ranges for Age and Fare\nwhole_data = data.append(test_data_preprocess)\n\n# Number of persons in family: parents + siblilngs\nwhole_data['Family'] = whole_data['Parch'] + whole_data['SibSp']\n\n# Extract family name for every person\nwhole_data['FamilyName'] = whole_data['Name'].str.split(',', expand=True)[0]\n\n# Detect real 'families': several persons with the same surname\nfamilies = whole_data[(whole_data['Parch'] + whole_data['SibSp'] > 0)]['FamilyName'].unique()\n\n# Do the same for train dataset\ndata['FamilyName'] = data['Name'].str.split(',', expand=True)[0]\n\n# Detect families who most likely survived or not. \n# Assumption: people in the same family have similar chances to survive, especially children\nsurvived_families = data[(data['FamilyName'].isin(families)) & (data['Survived'] == 1)]['FamilyName'].unique()\ndeceased_families = data[(data['FamilyName'].isin(families)) & (data['Survived'] == 0)]['FamilyName'].unique()\n\n# Detect missing ages base on person title\ntitle_remap = {' Mr': 'Mr', ' Mrs': 'Mrs', ' Miss': 'Miss', ' Master': 'Master', ' Don': 'Mr', ' Rev': 'Rev', ' Dr': 'Mr', ' Mme': 'Mrs',\n   ' Ms': 'Miss', ' Major': 'Mr', ' Lady': 'Mrs', ' Sir': 'Mr', ' Mlle': 'Miss', ' Col': 'Mr', ' Capt': 'Mr',\n   ' the Countess': 'Mrs', ' Jonkheer': 'Mr', ' Dona': 'Mrs'}\n\n# Extract title and remap\nwhole_data['Title'] = whole_data['Name'].str.split('[,.]', expand=True)[1].replace(title_remap)\n# Fill missing ages with median in the same title\nwhole_data['PreparedAge'] = whole_data['Age'].fillna(whole_data.groupby(['Title'])['Age'].transform('median'))\n\n# Ages breakpoints.\n# Assumption: children, adults and aged people should have different models for prediction\nchild_age = 17\naged_age = 65\n\n# Fill AgeRange only for adults. Age is suggested non-meaningful for children and aged people\nwhole_data.loc[(whole_data['PreparedAge'] >= child_age) \n               | (whole_data['PreparedAge'] < aged_age), 'AgeRange'] = pd.qcut(\n            whole_data[(whole_data['PreparedAge'] >= child_age) \n                       | (whole_data['PreparedAge'] < aged_age)]['PreparedAge'], 4)\n\n# Fill missing fare based on median of the same person class\nwhole_data['PreparedFare'] = whole_data['Fare'].fillna(whole_data.groupby(['Pclass'])['Fare'].transform('mean'))\n\n# Fill FareRange only for adults. Fare is suggested non-meaningful for children and aged people\nwhole_data.loc[(whole_data['PreparedAge'] >= child_age) \n               | (whole_data['PreparedAge'] < aged_age), 'FareRange'] = pd.qcut(\n            whole_data[(whole_data['PreparedAge'] >= child_age) \n                       | (whole_data['PreparedAge'] < aged_age)]['PreparedFare'], 5)\n\n# Assumption: people having the same ticket are travelling together (family-like). Count person-per-ticket feature\nwhole_data['TicketCount'] = whole_data.groupby('Ticket')['Ticket'].transform('count')\n\n# Calculate probabily to survive based on size of group with one ticket. Looks correlated with survival\nwhole_data['SurvivalPerTicketCount'] = whole_data.groupby('TicketCount')['Survived'].transform('mean')\n\n# Extract train dataset from whole_data and split it for child, adult and aged\ny = whole_data[:891]\ny_child = y[y['PreparedAge'] < child_age]['Survived']\ny_adult = y[(y['PreparedAge'] >= child_age) & (y['PreparedAge'] < aged_age)]['Survived']\ny_aged = y[y['PreparedAge'] >= aged_age]['Survived']\n\n# Function to transform train and test data\ndef transform_data(df, ageRange='adult'):\n    # Add pre-calculated columns from whole_data\n    df = df.join(whole_data[['FareRange', 'AgeRange', 'Family', 'SurvivalPerTicketCount', 'PreparedAge']])\n\n    # Extract family name. Again.\n    df['FamilyName'] = df['Name'].str.split(',', expand=True)[0]\n    \n    # Define \"family survival\": feature shows is anybody from family survived or everybody deceased\n    # Useful for child and aged people\n    df['FamilySurvival'] = 0.5\n    df.loc[df['FamilyName'].isin(survived_families) & (df['FamilySurvival'] == 0.5), 'FamilySurvival'] = 1\n    df.loc[df['FamilyName'].isin(deceased_families) & (df['FamilySurvival'] == 0.5), 'FamilySurvival'] = 0\n\n    # Some features encoding\n    df['SexCode'] = LabelEncoder().fit_transform(df['Sex'])\n    df['FareRangeCode'] = LabelEncoder().fit_transform(df['FareRange'])\n    df['AgeRangeCode'] = LabelEncoder().fit_transform(df['AgeRange'])\n\n    # Looks useful fo children\n    df['EmbarkedCode'] = LabelEncoder().fit_transform(df['Embarked'])\n    \n    # Special feature to identify alone children\n    df['AloneCode'] = LabelEncoder().fit_transform(df['Family'] == 0)\n\n    # Return child, adult or aged based on funcition parameters\n    if ageRange == 'children':\n        df = df[df['PreparedAge'] < child_age][[\n        'Pclass', 'FamilySurvival', 'Family', 'EmbarkedCode', 'AloneCode']]\n    elif ageRange == 'aged':\n        df = df[df['PreparedAge'] >= aged_age][[\n        'Pclass', 'FamilySurvival', 'Family']]\n    else:\n        df = df[(df['PreparedAge'] >= child_age) & (df['PreparedAge'] < aged_age)][['Family',\n        'AgeRangeCode', 'SexCode', 'Pclass', 'FareRangeCode', 'SurvivalPerTicketCount']]\n\n    std_scaler = StandardScaler()\n    # Do final standartization and return scaled data and result dataframe for testing purposes\n    return std_scaler.fit_transform(df), df","e6534b30":"# Code to brute-force model hyper-params. Results are just a suggestion..\n# Major outcome from all experiments: best values are around weights='uniform', algorithm='auto', k=[20;28]\nX_train, _ = transform_data(data.copy(), 'children')\nres_max = 0\nfor neighb in np.arange(2, 36):\n    for algo in['auto', 'ball_tree', 'kd_tree', 'brute']:\n        for w in ['uniform', 'distance']:\n            for leaf in np.arange(20, 40):\n                knn_model_upgrade = KNeighborsClassifier(n_neighbors=neighb, weights=w, algorithm=algo, leaf_size=leaf)\n                res = cross_validate(knn_model_upgrade, X_train, y_child, cv=5)[\"test_score\"].mean()\n                if res_max < res:\n                    res_max = res\n                    params = (neighb, algo, w, leaf)\n\nprint(f'{params}: {res_max}')","69d8012a":"# Final prediction: do almost the same for children, adult and aged people. Models parameters slightly differs\nmodels = {\n    'children': {\n        'model': KNeighborsClassifier(n_neighbors=26, weights='uniform', algorithm='auto',leaf_size=20),\n        'y': y_child},\n    'adult': {\n        'model': KNeighborsClassifier(n_neighbors=24, weights='uniform', algorithm='auto',leaf_size=20),\n        'y': y_adult},\n    'aged': {\n        'model': KNeighborsClassifier(n_neighbors=6, weights='uniform', algorithm='auto',leaf_size=20),\n        'y': y_aged},\n} \n\nanswer = pd.DataFrame({'PassengerId': [], 'Survived': []})\n\nfor ageRange, model_data in models.items():\n    # Fit\n    X_train, _ = transform_data(data.copy(), ageRange)\n    model_data['model'].fit(X_train, model_data['y'])\n    \n    # Predict\n    test_data = pd.read_csv(os.path.join(PATH, 'titanic', 'test.csv'))\n    X_test, tmp_df = transform_data(test_data.copy().set_index('PassengerId'), ageRange)\n    y_pred = model_data['model'].predict(X_test)\n\n    # Add results to target dataframe\n    answer = answer.append(pd.DataFrame({'PassengerId': tmp_df.index, 'Survived': y_pred}))\n\n# Do some transformation to prepare output\nanswer['PassengerId'] = answer['PassengerId'].astype(int)\nanswer['Survived'] = answer['Survived'].astype(int)\nanswer = answer.set_index('PassengerId').sort_index()\n\n# Save file\nanswer.to_csv('titanic_age_split.csv')","3fc34779":"**(0.5 points)** How many females and males are there in the dataset? What about the survived passengers? Is there any relationship between the gender and the survival?","e777ca42":"**(0.5 points)** Plot age distribution of the passengers. What is the average and the median age of survived and deceased passengers? Do age distributions differ for survived and deceased passengers? Why?","34fa7314":"Load the test set and make the predictions. Submit them to kaggle and see the results :)\nSelect the best model, load the test set and make the predictions. Submit them to kaggle.\n\n**Note**. X points will depend on your kaggle leaderboard score.\n$$ f(score) = 0.5, \\ \\ 0.76 \\leq score < 0.78,$$\n$$ f(score) = 1.0, \\ \\ 0.78 \\leq score < 0.81,$$ \n$$ f(score) = 2.5, \\ \\ 0.81 \\leq score $$ \nYour code should generate the output submitted to kaggle. Fix random seeds to make the results reproducible.","8faf08cb":"**(1.5 points)** Prepare the features and train two models (KNN and Logistic Regression) to predict the survival. Compare the results. Use accuracy as a metric. Don't forget about cross-validation!","84a9129d":"**Thoughts:** First-class passengers are more likely to survive. Port of embarkation has light influence on survival probability. Cherbourg is a France town, so survival might be related to nationality.","836397db":"**(0.5 + X points)** Try more feature engineering and hyperparameter tuning to improve the results. You may use either KNN or Logistic Regression (or both).","4d424c38":"### Dataset\n\nRead the description here: https:\/\/www.kaggle.com\/c\/titanic\/data. Download the dataset and place it in the *data\/titanic\/* folder in your working directory.\nYou will use train.csv for model training and validation. The test set is used for model testing: once the model is trained, you can predict whether a passenger survived or not for each passenger in the test set, and submit the predictions: https:\/\/www.kaggle.com\/c\/titanic\/overview\/evaluation.  \n","e3cacf63":"**(1 point)** Explore \"passenger class\" and \"embarked\" features. What class was \"the safest\"? Is there any relationship between the embarkation port and the survival? Provide the corresponding visualizations.","a9fe9654":"**Thoughts:** Age distibution for dead and alive a little bit different: very old people is likely to decease. Average and median ages are almost the same.\nObservation can be easily explained: youngers are faster and theirs health is stronger.","cc60d634":"### EDA","3662fd9e":"# Classification. Linear models and KNN","4e126a64":"Think about the ways to handle these missing values for modelling and write your answer below. Which methods would you suggest? What are their advantages and disadvantages?","c38b61a1":"**Thoughts:** \n- For `Embarked` add new value 'NA'\n    (`+` - separate calculations for 'unknown' port, `-` - survival probability for real ports might be incorrect)\n- For `Cabin` drop feature, because too many missing values \n    (`+` - lower noise in model, `-` - probable missing influence of passenger location)\n- For `Age` suggest mean value.\n    (`+` - age is taken into account, `-` - probable incorrect age for passenges)","4196cc19":"### Modelling","0954b3c8":"**Conclusion:** You'd better to be a female to survive on Titanic, probability to stay alive almost 3 time higher than for male.","cc758db4":"## Part 1: Titanic survival prediction","b31c5d1b":"**(0.5 points)** Find the percentage of missing values for each feature. "}}