{"cell_type":{"50c5e0e3":"code","9fdb4080":"code","e9491e5e":"code","e2ee89af":"code","47bad116":"code","e6b52a11":"code","89ceac74":"code","94c8194b":"code","cecf3d93":"code","21eab319":"code","9b477551":"code","671daa7f":"code","50454344":"code","805d766e":"code","a526ff47":"code","f9d0ecba":"code","a3e92da6":"code","8ed70f79":"code","325a3efc":"code","bdcc68f7":"code","75df591b":"code","2e18f66d":"code","9fd6af13":"code","e26ac96a":"code","7508af48":"code","f609ea8f":"code","a1468259":"markdown","c5aabeaf":"markdown","40de9aaf":"markdown","df989f17":"markdown","af46f9ee":"markdown","4a1983cf":"markdown"},"source":{"50c5e0e3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9fdb4080":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","e9491e5e":"train_data = pd.read_csv('..\/input\/digit-recognizer\/train.csv')","e2ee89af":"test_data = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","47bad116":"train_data","e6b52a11":"X_train = train_data.iloc[:,1:]\ny_train = train_data.iloc[:,0]","89ceac74":"X_train","94c8194b":"y_train","cecf3d93":"X_train","21eab319":"X_train = X_train.to_numpy().reshape(-1,28,28)","9b477551":"X_train.shape","671daa7f":"y_train.shape","50454344":"from tensorflow import keras","805d766e":"class ResidualUnit(keras.layers.Layer):\n    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n        super().__init__(**kwargs)\n        self.activation = keras.activations.get(activation)\n        self.main_layers = [\n            keras.layers.Conv2D(filters, 3, strides=strides,\n            padding=\"same\", use_bias=False),\n            keras.layers.BatchNormalization(),\n            self.activation,\n            keras.layers.Conv2D(filters, 3, strides=1,\n            padding=\"same\", use_bias=False),\n            keras.layers.BatchNormalization()]\n        self.skip_layers = []\n        if strides > 1:\n            self.skip_layers = [\n            keras.layers.Conv2D(filters, 1, strides=strides,\n            padding=\"same\", use_bias=False),\n            keras.layers.BatchNormalization()]\n    def call(self, inputs):\n        Z = inputs\n        for layer in self.main_layers:\n            Z = layer(Z)\n        skip_Z = inputs\n        for layer in self.skip_layers:\n            skip_Z = layer(skip_Z)\n        return self.activation(Z + skip_Z)","a526ff47":"model = keras.models.Sequential()\nmodel.add(keras.layers.Conv2D(64, 7, strides=2, input_shape=[28, 28, 1],\npadding=\"same\", use_bias=False))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Activation(\"relu\"))\nmodel.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\"))\nprev_filters = 64\nfor filters in [64] * 6 + [128] * 8 + [256] * 12 + [512] * 6:\n    strides = 1 if filters == prev_filters else 2\n    model.add(ResidualUnit(filters, strides=strides))\n    prev_filters = filters\nmodel.add(keras.layers.GlobalAvgPool2D())\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(10, activation=\"softmax\"))","f9d0ecba":"y_train = y_train.to_numpy().reshape(-1,1)","a3e92da6":"X_train = X_train \/ 255","8ed70f79":"model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])","325a3efc":"X_train = X_train.reshape(-1,28,28,1)","bdcc68f7":"model.fit(X_train,y_train,epochs=100,batch_size=32)","75df591b":"test_data = test_data \/ 255","2e18f66d":"test_data = test_data.to_numpy().reshape(-1,28,28,1)","9fd6af13":"y_pred = model.predict(test_data)","e26ac96a":"y_pred.shape","7508af48":"final_ans = []\nfor i in range(y_pred.shape[0]):\n    final_ans.append(np.argmax(y_pred[i]))","f609ea8f":"pd.DataFrame({'ImageId':range(1,28001),'Label':final_ans}).to_csv('submission.csv',index=False)","a1468259":"## preprocessing and reshaping data","c5aabeaf":"## import data","40de9aaf":"## import labraries","df989f17":"## creating model","af46f9ee":"## fitting model","4a1983cf":"## making submission"}}