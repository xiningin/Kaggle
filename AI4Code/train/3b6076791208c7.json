{"cell_type":{"f1bd7b50":"code","38fe5460":"code","edf8fc87":"code","757bfaa2":"code","7656de1c":"code","a4014fd7":"code","73f47f92":"code","da278105":"code","e48a5185":"code","204fcf66":"code","c65c46dc":"code","29d10678":"code","505e8ebd":"code","5337f211":"code","a8eb3272":"code","41ebe4dd":"code","a75f6660":"markdown","6a2f8254":"markdown","77e918f5":"markdown","d0a8592f":"markdown","982c2ac9":"markdown","c3d4544f":"markdown","8ec274e2":"markdown","baf00afa":"markdown","3fbff59c":"markdown","1e60bfcb":"markdown","4e5fb3c8":"markdown","161aa193":"markdown","6a7534c6":"markdown"},"source":{"f1bd7b50":"# Referred from Research Paper Controlling perceptual factors in neural style transfer - Gatys et al\n# Andrew Ng's neural style transfer\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import VGG16\n","38fe5460":"\"\"\"\n# Google-colab\nfrom kaggle import files\ncontent=files.upload()\nfor c in content.keys():\n  # Upload Content image\n  content_image_path='\/content\/' + c\"\"\"\n  ","edf8fc87":"content_image_path=\"..\/input\/taj-pic\/Taj Mahal.jpeg\"","757bfaa2":"\"\"\"\n# Google Colab\nfrom google.colab import files\nstyle=files.upload()\nfor s in style.keys():\n  # Upload Style image\n  style_art_image_path='\/content\/' + s\"\"\"\n  ","7656de1c":"style_art_image_path=\"..\/input\/oil-painting\/oil_painting.jpg\"","a4014fd7":"# Combined image dimension\n# Size of content image is taken into account for columns\nw, h = keras.preprocessing.image.load_img(content_image_path).size\nrows = 600\ncols = int(w * rows \/ h)\n","73f47f92":"from tensorflow.keras.applications import vgg16\ndef preprocess_image(image_path):\n    # Util function to open, resize and format pictures into appropriate tensors\n    img = keras.preprocessing.image.load_img(\n        image_path, target_size=(rows, cols)\n    )\n    img = keras.preprocessing.image.img_to_array(img)\n    # Expanding dimension to add 1 to dimension to match the dimensions\n    img = np.expand_dims(img, axis=0)\n    img = vgg16.preprocess_input(img)\n    return tf.convert_to_tensor(img)","da278105":"# Source of three type of image\ncontent_image = preprocess_image(content_image_path)\nstyle_art_image = preprocess_image(style_art_image_path)\n# Intializing tf.Variable constructor with random tensor, properties of tensor from content image\ngenerated_combined_image = tf.Variable(preprocess_image(content_image_path))\n#######","e48a5185":"# VGG16 model loaded \n# weights=\"imagenet\" loads pre-trained ImageNet weights\n# include_top=False to not include the 3 fully-connected layers at the top of the network\nmodel = VGG16(weights=\"imagenet\", include_top=False)\n#use model.summary() to check the layers in vgg16\n#It would helpful to extract desired activation layer\n\n#layer_name_output_dict contains key value pair of key being layer_name and its output\nlayer_name_output_dict = dict([(layer.name, layer.output) for layer in model.layers])\n\n# Set up a model that returns the activation values for every layer in VGG16 (as a dict).\n#This vgg16_features_engine will take a input tensor and outputs \nvgg16_features_engine = keras.Model(inputs=model.inputs, outputs=layer_name_output_dict)","204fcf66":"model.summary()","c65c46dc":"#vgg16_features_engine.save('\/tmp\/mvgg16.h5')","29d10678":"#from tensorflow.keras.models import load_model\n#xvgg16=load_model('\/tmp\/mvgg16.h5')","505e8ebd":"# CALCULATE TOTAL LOSS= alpha x CONTENT_COST_FUNCTION + beta x STYLE_COST_FUNCTION\n# Layer for the content loss\n# Content_loss_layer is chosen from higher layer to get the context of image\ncontent_layer_name = \"block5_conv3\"\n\n# Layers for the style loss.\n# Style_loss_layer is chosen from every layer get the texture of the style image\nstyle_layer_names = [\n    \"block1_conv1\",\n    \"block2_conv1\",\n    \"block3_conv2\",\n    \"block4_conv2\",\n    \"block5_conv1\",\n]\n\n# Weights of the different loss components\ntotal_loss_coeff = 1.05e-6\nbeta = 1.1e-6\nalpha = 2.3e-7\n\ndef total_loss(generated_combined_image, content_image, style_art_image):\n    #we take tensors\n    extracted_tensors = tf.concat([content_image, style_art_image, generated_combined_image], axis=0)\n    \n    features = vgg16_features_engine(extracted_tensors)\n    \n    # Loss initialized with zeros\n    loss = tf.zeros(shape=())\n    # As in extracted_tensors 0=content_image;1=style_art_image;2=generated_combined_image\n    # Add content loss\n    layer_features = features[content_layer_name]\n    # activation of layer \"block5_conv3\" of content_image \n    content_image_features = layer_features[0, :, :, :]\n    combination_features = layer_features[2, :, :, :]\n    # Calculate element-wise sum of squared difference multiplied with alpha and added to loss\n    loss = loss + alpha * tf.reduce_sum(tf.square(combination_features - content_image_features))\n    \n    \n    def style_matrix(feature_matrix_X):\n    # style is defined as correlation between activation across different channel\n    # style_matrix is 2D whereas the image is 3D. \n    # The first line permute transpose to bring channel dimension in row dimension ==> (2,0,1)\n    # Flattened it along spatial dimension i.e we multiply its height and width together that reshape does\n    # style_matrix is also called gram-matrix, it is a autocorrelation i.e X.X'(transpose)\/N\n    # Finally it takes X(c,hw)==> X(c,c)\n      feature_matrix_X = tf.transpose(feature_matrix_X, (2, 0, 1))\n      features = tf.reshape(feature_matrix_X, (tf.shape(feature_matrix_X)[0], -1))\n      return tf.matmul(features, tf.transpose(features))\n       \n\n    # Add style loss\n    for layer_name in style_layer_names:\n        layer_features = features[layer_name]\n        #activation of layer from block_1 to block_5 of style image\n        style_art_features = layer_features[1, :, :, :]\n        # activation of layer of generated_combined_image\n        combination_features = layer_features[2, :, :, :]\n        # To get correlation between channels of style image and combination image\n        S = style_matrix(style_art_features)\n        G = style_matrix(combination_features)\n        channels = 3\n        size = rows * cols\n        # Calculate element-wise sum of squared difference multiplied with beta and added to loss\n        # And dividing by a constant\n        style_loss = tf.reduce_sum(tf.square(S - G)) \/ (4.0 * (channels ** 2) * (size ** 2))\n        \n        loss =loss+ (beta \/ len(style_layer_names)) * style_loss\n\n    \n    a = tf.square(generated_combined_image[:, : rows - 1, : cols - 1, :] - generated_combined_image[:, 1:, : cols - 1, :])\n    b = tf.square(generated_combined_image[:, : rows - 1, : cols - 1, :] - generated_combined_image[:, : rows - 1, 1:, :])  \n    \n    # Adding total loss\n    loss =loss+ total_loss_coeff * tf.reduce_sum(tf.pow(a + b, 1.25))\n    return loss\n\n","5337f211":"# Custom loss function with custom differentiation in tensorflow to get gradient \ndef total_loss_and_gradient(generated_combined_image, content_image, style_art_image):\n  # Gradient Tape performs differentiation \n    with tf.GradientTape() as t:\n        loss = total_loss(generated_combined_image, content_image, style_art_image)\n    # To simply put does gradient descent on loss function\n    grads = t.gradient(loss, generated_combined_image)\n    return loss, grads\n","a8eb3272":"import datetime\n# Inherits from  LearningRateSchedule\n# A useful method for hyper-paramter optimisation to determine learning Rate Combined with callbacks\n# SGD= Stochastic gradient descent\nlearning_rate_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=80.0,\n    decay_steps=100,\n    decay_rate=0.9)\n# initial_learning_rate * decay_rate ^ (step \/ decay_steps)\n# Tried with different optimizers like Adam,RMSprop, l-bfgs but it worked best\noptimizer = keras.optimizers.SGD(learning_rate=learning_rate_scheduler,momentum=0.9)\n# Backtrace from here\n# Iterating and reducing the loss\n#more iteration the better but 3000-4000 is optimal\nt0=datetime.datetime.now()\niterations = 3000\nfor i in range(1, iterations + 1):\n    loss, gradient = total_loss_and_gradient(generated_combined_image, content_image, style_art_image)\n    optimizer.apply_gradients([(gradient, generated_combined_image)])\n    if i%50==0:\n      print(\"*\"*25,\"PAINTING\",\"*\"*25)\n      print(\"time elapsed\",datetime.datetime.now()-t0)\n      print(\"loss=%.1f\" %(loss))\n\n#deprocess image\nnumpy_img_matrix=generated_combined_image.numpy()\nnumpy_img_matrix = numpy_img_matrix.reshape((rows, cols, 3))\n# Remove zero-center by mean pixel\n# Reversing effect of Keras pre-processing\n# Just a boiler-plate(dont worry about the number)\nnumpy_img_matrix[:, :, 0] += 103.939\nnumpy_img_matrix[:, :, 1] += 116.779\nnumpy_img_matrix[:, :, 2] += 123.68\nnumpy_img_matrix = numpy_img_matrix[:, :, ::-1]\nimg = np.clip(numpy_img_matrix, 0, 255).astype(\"uint8\")\nprint(\"Final--> loss=%.1f\" %(loss))\nprint(\"Completed in-->\",datetime.datetime.now()-t0)\nkeras.preprocessing.image.save_img(\"Combined_Image.jpg\", img)\n","41ebe4dd":"\"\"\"\n# Download Final image\nfrom google.colab import files\nfiles.download(\"\/content\/\"+\"Combined_Image.jpg\")\"\"\"","a75f6660":"## **Training loop & De-process Image**","6a2f8254":"## Future Prospects and Work\n### 1. Ways to make training process Faster\n### 2. Thinking of combining GAN with Neural Style Transfer\n### 3. Implementing NST with Inception\n## Any suggestion on above Ideas is very much appreciated","77e918f5":"<img src=\".\/Combined_Image.jpg\" width=\"500px\">\n\n","d0a8592f":"# ***Artistic Moods***\n## \"Get drawn by **Picasso, Dali, Van Gogh, Da Vinci ,Monet ,Pollock ,Kahlo**\"\n","982c2ac9":"### The network has 41 layers. There are 16 layers with learnable weights: 13 convolutional layers, and 3 fully connected layers used in ImageNet, based on VGG by Simonyan and Zisserman\n\n\n\n\n### Drawback is very slow to train\n### Here I used trained model with pre-defined weights.","c3d4544f":"### Result after 3000 iterations","8ec274e2":"### **2. Using VGG16 to get the activation of hidden layer**","baf00afa":"## **MUST USE RULE**\n### ALWAYS USE **shift+Tab** IF YOU DONT GET WHAT FUNCTION IS DOING. IT POPS UP DOCUMENTATION","3fbff59c":"## **Model**","1e60bfcb":"### **Completed a project on concepts including**\n### 1. Transfer Learning\n### 2. CNN\n### 3. Advanced CNN with auto-correlation between channels in gram matrix \n## **I have developed this project in Flask as a webapp but due to my low computation power. I implemented it again in Google-colab. It is recommended to do so.** ","4e5fb3c8":"##**Cost_Function**\n#### Total cost function = alpha x content_cost_function + beta x style_cost_function\n\nContent Cost Function:\n","161aa193":"### Types of Arts\n#### 1. Realism - An Art Style to bring about the true society. A revolution against the classist society of kings and nobels -Whitsler\n#### 2. Cubism - An Art style to bring about every side of object in 2D plane. Mainly drawn with a cubic style -Picaso\n#### 3. Surrealism- An art style for free forming imagination - Dali","6a7534c6":"# Implemented by **Ankan Sharma**"}}