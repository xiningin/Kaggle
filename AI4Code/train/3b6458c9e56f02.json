{"cell_type":{"c5dac5fa":"code","3ce74b81":"code","7369ab81":"code","613938c3":"code","db00d41d":"code","d8137f2e":"code","01abf3f7":"code","b2421dec":"code","c4fb263a":"code","540a74e4":"code","3dfc1100":"code","f41ad38e":"code","2b96f9c2":"code","c37e6af1":"code","e8a75ddc":"code","b6f3fa95":"code","2cd0eb6c":"code","6b9324fc":"code","8cf9821b":"code","c15ab6b0":"code","c594384d":"code","d200cab9":"code","3fdac2eb":"code","dba7d554":"code","423202dc":"code","28aaa66c":"code","5b612d53":"code","3c55266c":"markdown","48fdfddc":"markdown","077235d5":"markdown","edd698c8":"markdown","6c0e2b0b":"markdown","6a39a6f5":"markdown","e78249d4":"markdown","77fe9cd4":"markdown"},"source":{"c5dac5fa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3ce74b81":"from sklearn.model_selection import train_test_split\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","7369ab81":"def female (row):\n    if row['Sex'] == 'male':\n        a1 = -1\n    else:\n        a1 = 1        \n    return a1","613938c3":"def C (row):\n    if row['Embarked'] == 'C':\n        a1 = 1\n    else:\n        a1 = 0        \n    return a1\ndef Q (row):\n    if row['Embarked'] == 'Q':\n        a1 = 1\n    else:\n        a1 = 0        \n    return a1\n\ndef S (row):\n    if row['Embarked'] == 'S':\n        a1 = 1\n    else:\n        a1 = 0        \n    return a1","db00d41d":"def Cab (row):\n    if row['Cabin'] == 0:\n        a = -1\n    else:\n        if row['female'] == 1:\n            a = 1\n        else:\n            a = -1\n    return a","d8137f2e":"from sklearn.utils import shuffle\ncol = ['Survived','Pclass','Sex', 'Age', 'SibSp', 'Parch','Ticket', 'Fare', 'Cabin', 'Embarked']\nout = ['Pclass', 'Age', 'Parch', 'Fare', 'female','C','S','Q','Cab']\ntrain['female'] = train.apply (lambda row: female (row),axis=1)\ntrain['C'] = train.apply (lambda row: C (row),axis=1)\ntrain['S'] = train.apply (lambda row: S (row),axis=1)\ntrain['Q'] = train.apply (lambda row: Q (row),axis=1)\nmean_age = train['Age'].median()\nmean_Fare = train['Fare'].median()\ntrain['Age'] = train['Age'].fillna(mean_age)\ntrain['Fare'] = train['Fare'].fillna(mean_Fare)\ntrain['Cabin'] = train['Cabin'].fillna(0)\ntrain['Cab'] = train.apply (lambda row: Cab (row),axis=1)\ntrain = train[train['Age'] != mean_age] \ntrain = train[train['Fare'] != mean_Fare] \n\ntest['female'] = test.apply (lambda row: female (row),axis=1)\ntest['C'] = test.apply (lambda row: C (row),axis=1)\ntest['S'] = test.apply (lambda row: S (row),axis=1)\ntest['Q'] = test.apply (lambda row: Q (row),axis=1)\ntest['Cab'] = test.apply (lambda row: Cab (row),axis=1)\ntest['Age'] = test['Age'].fillna(mean_age)\ntest['Fare'] = test['Fare'].fillna(mean_Fare)\ntest['Cabin'] = test['Cabin'].fillna(0)\n\ntest['Q'] = test.apply (lambda row: Q (row),axis=1)\ndf_train , df_val= train_test_split(train, test_size=0.2, random_state=111)\n\ny_train_final = shuffle(train)\ny_train_final_o = y_train_final['Survived']\nX_train_final_i = y_train_final[out]\n\ny_train = df_train['Survived']\ny_val = df_val['Survived']\nX_train = df_train[out]\nX_val = df_val[out]\nX_test = test[out]\n\nprint(X_train_final_i.shape,y_train_final_o.shape, y_train.shape)\n\n","01abf3f7":"from sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn import svm\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LogisticRegression","b2421dec":"X_train= X_train.reset_index(drop=True)\nX_val= X_val.reset_index(drop=True)\nX_train.head()","c4fb263a":"from sklearn.preprocessing import LabelBinarizer\n\njobs_encoder = LabelBinarizer()\njobs_encoder.fit(X_train['Pclass'])\ntransformed_train = jobs_encoder.transform(X_train['Pclass'])\nohe_train = pd.DataFrame(transformed_train, columns=['a', 'b', 'c'])\nX_train = pd.concat([X_train, ohe_train], axis=1).drop(['Pclass'], axis=1)\n\ntransformed_val = jobs_encoder.transform(X_val['Pclass'])\nohe_val = pd.DataFrame(transformed_val, columns=['a', 'b', 'c'])\nX_val = pd.concat([X_val, ohe_val], axis=1).drop(['Pclass'], axis=1)\n\ntransformed_test = jobs_encoder.transform(X_test['Pclass'])\nohe_test = pd.DataFrame(transformed_test, columns=['a', 'b', 'c'])\nX_test = pd.concat([X_test, ohe_test], axis=1).drop(['Pclass'], axis=1)","540a74e4":"X_train.head()","3dfc1100":"clf_L = LogisticRegression(random_state=0).fit(X_train, y_train)\nclf_preL = clf_L.predict(X_val)\n\n\n\nprint('Logistic regression')\nprint('Accuracy score:', accuracy_score(clf_preL, y_val))\nprint(classification_report(clf_preL, y_val))\nprint(confusion_matrix(clf_preL, y_val))\n","f41ad38e":"X_train.head()","2b96f9c2":"\n\n#random foreset \nclf = RandomForestClassifier(n_estimators=50)\n    \nclf.fit(X_train, y_train)\nclf_prediction = clf.predict(X_val)\n\n\n\nprint('Random Forest Classifier details')\nprint('Accuracy score:', accuracy_score(clf_prediction, y_val))\nprint(classification_report(clf_prediction, y_val))\nprint(confusion_matrix(clf_prediction, y_val))\n\n\n#final ","c37e6af1":"#SVC \n\nSVC_model_f = svm.SVC(kernel = 'poly')\nStd = StandardScaler()\nstd_fit = Std.fit(X_train)\nX_train_f = Std.transform(X_train)\nSVC_model_f.fit(X_train_f, y_train)\nSVC_prediction = SVC_model_f.predict(X_val)\nprint('SVC details')\nprint('Accuracy score:', accuracy_score(SVC_prediction, y_val))\nprint(classification_report(SVC_prediction, y_val))\nprint(confusion_matrix(SVC_prediction, y_val))","e8a75ddc":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\n\n\nX_train_d = sc.fit_transform(X_train) # you are finding the MEan and STD{with the fit()\n#                                    }on training data and aslo transforming that\n\nX_test_d = sc.transform(X_test) ","b6f3fa95":"from sklearn.tree import DecisionTreeClassifier\n\n#DecisionTreeClassifier?","2cd0eb6c":"from sklearn.tree import DecisionTreeClassifier\n\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0,max_depth=10)\n\nclassifier.fit(X_train_d, y_train)\ny_val_DT = classifier.predict(X_val)\n","6b9324fc":"print('Decision Tree')\nprint('Accuracy score:', accuracy_score(y_val_DT, y_val))\nprint(classification_report(y_val_DT, y_val))\nprint(confusion_matrix(y_val_DT, y_val))","8cf9821b":"from sklearn.model_selection import GridSearchCV","c15ab6b0":"pGrid = {'max_depth': range(1, 10), # 8\n        'min_samples_leaf': range(5, 51, 10),  # 5\n        'min_samples_split': range(5, 81, 20)}   # 4\n\ngscv_dt = GridSearchCV(estimator = DecisionTreeClassifier(), param_grid = pGrid, cv = 5,\n                       scoring = 'recall', n_jobs = -1, verbose = True)","c594384d":"gscv_dt.fit(X_train, y_train)","d200cab9":"gscv_dt.best_params_","3fdac2eb":"GS_prediction = gscv_dt.predict(X_val)\nprint('GS details')\nprint('Accuracy score:', accuracy_score(GS_prediction, y_val))\nprint(classification_report(GS_prediction, y_val))\nprint(confusion_matrix(GS_prediction, y_val))","dba7d554":"output = gscv_dt.predict(X_test)","423202dc":"print(output.shape , X_test.shape)\nprint(output)","28aaa66c":"# Create the pandas DataFrame \ndf_final = pd.DataFrame(columns = ['PassengerId', 'Survived']) \ndf_final['PassengerId'] = test['PassengerId']\ndf_final['Survived'] = output","5b612d53":"df_final.to_csv('final_05.csv',index =False)","3c55266c":"poly = PolynomialFeatures(interaction_only=True)\nX_train = pd.DataFrame(poly.fit_transform(X_train))\nX_val = pd.DataFrame(poly.fit_transform(X_val))\nX_test = pd.DataFrame(poly.fit_transform(X_test))","48fdfddc":"# SVC model\n- val accurancy 73 ","077235d5":"# Random Forest\n- Val accuracy 80 %","edd698c8":"# Decision trees\n- Val with normal entropy 46\n- val with ","6c0e2b0b":"# Grid SearchCV\n- 78 percent accuracy ","6a39a6f5":"Training data","e78249d4":"# Python code\n- Logistic Regression\n- Random Forest\n- SVC Model\n","77fe9cd4":"# Logistic Regression\n- 82 % valution accuracy "}}