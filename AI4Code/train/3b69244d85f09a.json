{"cell_type":{"0262aeb1":"code","95e95951":"code","e15d6d13":"code","37e1174a":"code","f55b019c":"code","dcd1bf5e":"code","116163a7":"markdown","2d632e64":"markdown","7e6cab13":"markdown","05a331f0":"markdown","03794011":"markdown"},"source":{"0262aeb1":"import sys\nsys.path.append('..\/input\/utils-shopee')\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')","95e95951":"import math\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\n\nimport timm\nimport torch\nfrom torch import nn \nimport torch.nn.functional as F \n\nimport engine\nfrom dataset import ShopeeDataset\nfrom custom_scheduler import ShopeeScheduler\nfrom augmentations import get_train_transforms\nfrom math import sqrt","e15d6d13":"DATA_DIR = '..\/input\/shopee-product-matching\/train_images'\nTRAIN_CSV = '..\/input\/utils-shopee\/folds.csv'\nMODEL_PATH = '.\/'\n\n\nclass CFG:\n    seed = 54\n    img_size = 512\n    classes = 11014\n    scale = 30\n    margin = 0.5\n    fc_dim = 512\n    epochs = 18\n    batch_size = 16\n    num_workers = 8\n    model_name = 'tf_efficientnet_b3'\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    scheduler_params = {\n        \"lr_start\": 1e-5 * sqrt(2),\n        \"lr_max\": 1e-5 * batch_size * sqrt(2),     # 1e-5 * 32 (if batch_size(=32) is different then)\n        \"lr_min\": 1e-6 * sqrt(2),\n        \"lr_ramp_ep\": 5,\n        \"lr_sus_ep\": 0,\n        \"lr_decay\": 0.8,\n    }","37e1174a":"class ArcMarginProduct(nn.Module):\n    def __init__(self, in_features, out_features, scale=30.0, margin=0.50, easy_margin=False, ls_eps=0.0):\n        super(ArcMarginProduct, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.scale = scale\n        self.margin = margin\n        self.ls_eps = ls_eps  # label smoothing\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n        self.easy_margin = easy_margin\n        self.cos_m = math.cos(margin)\n        self.sin_m = math.sin(margin)\n        self.th = math.cos(math.pi - margin)\n        self.mm = math.sin(math.pi - margin) * margin\n\n    def forward(self, input, label):\n        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n    \n        one_hot = torch.zeros(cosine.size(), device='cuda')\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps \/ self.out_features\n\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.scale\n        return output, nn.CrossEntropyLoss()(output,label)\n\n\nclass ShopeeModel(nn.Module):\n\n    def __init__(\n        self,\n        n_classes = CFG.classes,\n        model_name = CFG.model_name,\n        fc_dim = CFG.fc_dim,\n        margin = CFG.margin,\n        scale = CFG.scale,\n        use_fc = True,\n        pretrained = True):\n\n        super(ShopeeModel,self).__init__()\n        print('Building Model Backbone for {} model'.format(model_name))\n\n        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n        in_features = self.backbone.classifier.in_features\n        self.backbone.classifier = nn.Identity()\n        self.backbone.global_pool = nn.Identity()\n        self.pooling =  nn.AdaptiveAvgPool2d(1)\n        self.use_fc = use_fc\n\n        if use_fc:\n            self.dropout = nn.Dropout(p=0.1)\n            self.classifier = nn.Linear(in_features, fc_dim)\n            self.bn = nn.BatchNorm1d(fc_dim)\n            self._init_params()\n            in_features = fc_dim\n\n        self.final = ArcMarginProduct(\n            in_features,\n            n_classes,\n            scale = scale,\n            margin = margin,\n            easy_margin = False,\n            ls_eps = 0.0\n        )\n\n    def _init_params(self):\n        nn.init.xavier_normal_(self.classifier.weight)\n        nn.init.constant_(self.classifier.bias, 0)\n        nn.init.constant_(self.bn.weight, 1)\n        nn.init.constant_(self.bn.bias, 0)\n\n    def forward(self, image, label):\n        features = self.extract_features(image)\n        if self.training:\n            logits = self.final(features, label)\n            return logits\n        else:\n            return features\n\n    def extract_features(self, x):\n        batch_size = x.shape[0]\n        x = self.backbone(x)\n        x = self.pooling(x).view(batch_size, -1)\n\n        if self.use_fc and self.training:\n            x = self.dropout(x)\n            x = self.classifier(x)\n            x = self.bn(x)\n        return x\n","f55b019c":"def run_training():\n    \n    df = pd.read_csv(TRAIN_CSV)\n\n    labelencoder= LabelEncoder()\n    df['label_group'] = labelencoder.fit_transform(df['label_group'])\n\n    trainset = ShopeeDataset(df,\n                             DATA_DIR,\n                             transform = get_train_transforms(img_size = CFG.img_size))\n\n    trainloader = torch.utils.data.DataLoader(\n        trainset,\n        batch_size = CFG.batch_size,\n        num_workers = CFG.num_workers,\n        pin_memory = True,\n        shuffle = True,\n        drop_last = True\n    )\n\n    model = ShopeeModel()\n    model.to(CFG.device)\n\n    optimizer = torch.optim.Adam(model.parameters(),\n                                 lr = CFG.scheduler_params['lr_start'])\n    scheduler = ShopeeScheduler(optimizer, **CFG.scheduler_params)\n\n    for epoch in range(CFG.epochs):\n        avg_loss_train = engine.train_fn(model, trainloader, optimizer, scheduler, epoch, CFG.device)\n        torch.save(model.state_dict(), MODEL_PATH + f'arcface_512x512_b3_lrsq2_{epoch}.pt'.format(CFG.model_name))\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer': optimizer.state_dict(),\n            'scheduler': scheduler.state_dict()\n            },\n            MODEL_PATH + f'arcface_512x512_b3_lrsq2_{epoch}_checkpoints.pt'.format(CFG.model_name)\n        )","dcd1bf5e":"run_training()","116163a7":"# About Notebook\n\n* Thanks to PyTorch Arcface Implementation by @tanulsingh077 from [here](https:\/\/www.kaggle.com\/tanulsingh077\/pytorch-metric-learning-pipeline-only-images)\n\n* One can train any EfficientNet(b0-b7) model by changing `model_name` in **CFG**.\n\n* Inference Notebook for the same can be found [here](https:\/\/www.kaggle.com\/vatsalmavani\/eff-b4-tfidf-0-727)\n\n#### **NOTE:** \n*     If you are using kaggle GPU, you must have to change `batch_size`. In addition, you also have to change `CFG.lr_max = 1e-5 * 32`","2d632e64":"# Import Packages","7e6cab13":"# Training","05a331f0":"# Config and Directories","03794011":"# Create Model"}}