{"cell_type":{"b35f2a11":"code","d9f79efe":"code","c14c4149":"code","6f57dd74":"code","fc18443e":"code","836ddd32":"code","d2a3b416":"code","667d7e48":"code","19904310":"markdown","0f4afc1b":"markdown","6d627e54":"markdown"},"source":{"b35f2a11":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d9f79efe":"df = pd.read_csv('\/kaggle\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')\ndf.head()","c14c4149":"df.isnull().sum()","6f57dd74":"X = df.iloc[:,[3,4]].values\nX","fc18443e":"from sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nwcss = []\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters=i, init ='k-means++',random_state=42)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1,11),wcss)\nplt.title('Elbow method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show();","836ddd32":"kmeans = KMeans(n_clusters = 5, init ='k-means++', random_state=42)\ny_means = kmeans.fit_predict(X)\nlabels = kmeans.labels_\nprint(labels)","d2a3b416":"# adding one more column label to the dataframe\ndf['cluster'] = labels\ndf.head()","667d7e48":"plt.scatter(X[y_means == 0,0],X[y_means ==0,1],c='r',s=100,label='cluster1')\nplt.scatter(X[y_means == 1,0],X[y_means ==1,1],c='blue',s=100,label='cluster2')\nplt.scatter(X[y_means == 2,0],X[y_means ==2,1],c='green',s=100,label='cluster3')\nplt.scatter(X[y_means == 3,0],X[y_means ==3,1],c='cyan',s=100,label='cluster4')\nplt.scatter(X[y_means == 4,0],X[y_means ==4,1],c='magenta',s=100,label='cluster5')\nplt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],s=100,c='yellow',label='centroid')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","19904310":"**Visualizing the clusters**","0f4afc1b":"**Using the elbow method to find the optimal number of clusters**","6d627e54":"**Training the K-Means model on the dataset\u00b6**"}}