{"cell_type":{"64beca07":"code","5e5fd725":"code","ef7d2e52":"code","68bc4cf1":"code","11c88a16":"code","d56faae8":"code","9e8614a5":"code","769eb80b":"code","04bc0081":"code","0e290580":"code","427790f5":"code","e9601255":"code","469a2ea0":"code","46fe1c93":"markdown","ae700285":"markdown","1ed6ee87":"markdown","d699b4cc":"markdown","bf707f8d":"markdown","6b29fb18":"markdown","d4c97987":"markdown","9370d1d7":"markdown","ba729798":"markdown","ccf28eb2":"markdown","eb73aa0b":"markdown","83356a04":"markdown","53229033":"markdown","1586c6a6":"markdown"},"source":{"64beca07":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5e5fd725":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","ef7d2e52":"print(train.head())","68bc4cf1":"type(train)","11c88a16":"train_x = train.drop([\"label\"], axis = 1)\ntrain_y = train[\"label\"]\n\ntrain_x1 = np.array(train_x).reshape(-1,28,28)# in case your wondering, -1 here refers to the last row\n\n#We will normalize the data, as it will give poor accuracy if we don't \n#The accuracy I was getting before normalizing was approx 0.2 but after normalization, it increased to 0.8\n#I know...It's awesome how small steps like these affect accuracy!\ntrain_x1 = train_x1\/255\n\n#we also perform the same operations on the test set\ntest = np.array(test).reshape(-1,28,28)\ntest = test\/255\n\n#here's how to plot a single image through indexing\nimport matplotlib.pyplot as plt\nplt.imshow(train_x1[0], cmap = plt.cm.binary)\n\n#you can also loop any number of images that you'd like to display using a for loop.\nplt.figure()\nfor i in range(16):\n    plt.subplot(4,4,i+1)\n    plt.imshow(train_x1[i], cmap = plt.cm.binary)\nplt.show()","d56faae8":"print(np.shape(train))\nprint(np.shape(train_y))\nprint(np.shape(train_x))\nprint(np.shape(train_x1))","9e8614a5":"train_y.head()","769eb80b":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nmodel = keras.Sequential([\n    layers.Flatten(input_shape = (28,28)),\n    layers.Dense(88, activation = \"gelu\"),\n    layers.Dense(10, activation = \"softmax\")\n])","04bc0081":"model.compile(optimizer = \"sgd\",\n             loss = \"sparse_categorical_crossentropy\",\n             metrics = [\"accuracy\"])","0e290580":"#fitted_model = \nmodel.fit(train_x1, train_y, batch_size = 10, epochs = 20)","427790f5":"np.shape(test)","e9601255":"#We split the training set provided into a validation set as well to determine overfitting or underfitting to evaluate the model\n#I have not done the evaluation step here, we'll just move on to prediction\npredicted_value = model.predict_classes(test)\n\n#our test set has 28000 rows, but does not include an ID column, so we will define it\nimageid = list(range(1,28001))\nsubmission = pd.DataFrame({\"ImageId\": imageid, \"Label\": predicted_value})\nsubmission.to_csv(\"submission.csv\", index = False)","469a2ea0":"s = pd.read_csv(\"submission.csv\")\ns.head()","46fe1c93":"**Step 1 - Defining Our Network**","ae700285":"# **Reading the data**","1ed6ee87":"Okay, so here's the thing, the standard activation functions that we use in the output layer for different kinds of machine learning problems are - \n\n* for **multiclass classification** problems we use **softmax function** at the ouput layer\n* for **binary classification** we use **sigmoid function**\n* for **regression problems** we use **linear activation function**\n\nIf you want to use some other activation functions and optimizers below are quick reference links to Tensorflow documentation : \n* [Activation Functions](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/activations)\n* [Optimizers](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/optimizers)\n\nAlso if you are a bit confused as to when to use which optimizer, [here](https:\/\/towardsdatascience.com\/7-tips-to-choose-the-best-optimizer-47bb9c1219e) is a link to an article you can refer to help you a little.","d699b4cc":"So as a beginner I was a bit confused how to plot the image if pixel values are given. So, here's the solution that I came across after doing a bit of research and thought it would be helpful to write kind of a walkthrough for people who might be facing the same problem-\n\nWe use the imshow() method from matplotlib. Okay so we are given the values of a pixel in rows so 1 row corresponds to 1 image. So, we iterate on as many rows as we want images to be printed. As parameters we pass the data with the row indexed and the other parameter is cmap = plt.cm.binary. Here,\n* cmap - stands for colormap\n* cm - the builtin colormaps in matplotlib are accessible via matplotlib.cm module\n* binary - binary is one of the colormaps\n\nIf you want to see other colormaps you can refer matpotlib documentation\nHere's a comparison chart taken from matplotlib documentation for a quick reference -\n\n![Colormap difference](https:\/\/matplotlib.org\/3.1.0\/_images\/sphx_glr_colormaps_003.png)\n\nBut what happens when you run this simply is that you run into an error which tells you that the shape is invalid. Hence we reshape our train_x data. And since we cannot apply reshape() function on a dataframe, we first convert it to an array.","bf707f8d":"Thus there are 784 pixels. Thus the dimension of the images is 28x28. Let's view a sample image.","6b29fb18":"A bit about **epochs** and **batch_size**, \n* We train our network for a specific number of epochs. This is the number of times our Neural Network accesses the data.\n* Now, epochs can be divided as per you preference into batch_size. Batch_size is the number of samples that are processed by the network before it updates it's weights.","d4c97987":"Here are the shapes after the various stages of manipulation that we did on our train_x for reference","9370d1d7":"# **Viewing an Image**","ba729798":"For multiclass classification, \n* we usually use **sparse_categorical_crossentropy** as a loss function\n(I tried to use categorical_crossentropy first, but that was resulting in value error)\n* for optimizer I have used **Stochastic Gradient Descent (sgd)**\n* for the evaluation metrics I have used **accuracy**","ccf28eb2":"**Step 3 - Fitting our network**","eb73aa0b":"Now we come to the fun part. For making a neural network model, there is a simple workflow that we usually follow,\n\n1. Define the network\n2. Compile the network\n3. Fit the network\n4. Evaluate the network\n5. Make Predictions\n\nReference taken from \"*Generative Adversarial Networks with Python*\" by Jason Brownlee.\n\nHere's the link if you want to read more [\"*Generative Adversarial Networks with Python*\" by Jason Brownlee](https:\/\/machinelearningmastery.com\/generative_adversarial_networks\/)","83356a04":"# **Making a Neural Network Model for Digit Recognition**","53229033":"**Step 2 - Compiling our network**","1586c6a6":"**Step 4 & 5 - Evaluate model and Make Predictions**"}}