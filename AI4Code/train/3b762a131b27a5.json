{"cell_type":{"8096b70d":"code","f80b0aac":"code","cea3a2fb":"code","6288753d":"code","d0f76108":"markdown"},"source":{"8096b70d":"# import libs\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nimport gc\nimport glob\nimport pickle","f80b0aac":"##### config #####\n# select inference only or not, debug or not\ninfer_only = False\ndebug = False\n\n# cols\nbasic_cols = ['row_id', 'time_id', 'investment_id', 'target']\nnum_feat = 300\nfeatures = [f'f_{i}' for i in range(num_feat)]\nfeatures.append('investment_id')\n\n# params for lgbm\nparams = {\n        'random_state':2022, \n        'verbosity': -1,\n        'metrics': 'rmse',\n    }\nnum_round = 500\n\n# fold\nnum_folds = 5\nfolds = [0] #[0,1,2,3,4]\n\n# debug\nif debug:\n    num_round = 1","cea3a2fb":"models = []\n\n# if train and infer\nif not infer_only:\n    oof = np.zeros((3141410))\n    for fold in folds:\n        print('='*40)\n        print(f'fold{fold}')\n        # to avoid memory error, load df and delete repeatedly \n        train_df = pd.read_parquet(f'..\/input\/different-splits-for-the-competition-parquets\/df_gs_{num_folds}folds.parquet')\n        tr_y = train_df[train_df['fold']!=fold]['target'].values\n        tr_x = train_df[train_df['fold']!=fold][features].values\n        val_idx = np.array(train_df['fold']==fold).tolist()\n        val_y = train_df.iloc[val_idx]['target'].values\n        val_x = train_df.iloc[val_idx][features].values\n        \n        del train_df\n        gc.collect()      \n\n        lgb_train = lgb.Dataset(tr_x, tr_y, categorical_feature=[300],)\n        lgb_eval = lgb.Dataset(val_x, val_y, categorical_feature=[300],)\n        model = lgb.train(params, lgb_train, valid_sets=lgb_eval,\n                          verbose_eval=50,\n                          num_boost_round = num_round,\n                          early_stopping_rounds=100)\n        oof_preds = model.predict(val_x)\n        oof[val_idx] = oof_preds\n        models.append(model)\n        pickle.dump(model, open(f'lgb_fold{fold}.pkl', 'wb'))\n        \n        del lgb_train, lgb_eval, tr_x, tr_y, val_x, val_y, model, val_idx\n        gc.collect()\n    #targets = pd.read_csv('..\/input\/ubiquant-market-prediction\/train.csv', usecols=['target'])\n    np.save('oof', oof)\n# if just infer\nelse:\n    model_paths = glob.glob(f'..\/input\/ubiquant-lgb-models-1901\/lgb_fold*.pkl')\n    for model_path in model_paths:\n        models.append(pickle.load(open(model_path, 'rb')))\n        print(f'loaded {model_path}')","6288753d":"# inference\nimport ubiquant\nenv = ubiquant.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\nfor (test_df, sample_prediction_df) in iter_test:\n    preds = []\n    for model in models:\n        preds.append(model.predict(test_df[features].values))\n    sample_prediction_df['target'] = np.median(preds, axis=0)  # make your predictions here\n    env.predict(sample_prediction_df)   # register your predictions","d0f76108":"- version\n\nver 1: singlefold, train using only 30 features >>> lb 0.103\n\nver 5: 5 GroupKFolds (actually train just one fold), make oof, train using all features\n\nver 6: just infer with ver5 model >>>  lb0.132\n\nver 7: wanna solve memory error... >>> failed\n\nver 8-11: train fold1-4\n\nver 12: infer with 5 models from ver5, 8-11 >>> made mistake, infer by just one model\n\nver 14: infer with 5 models from ver5, 8-11 >>> lb0.136\n\nver 16: median ensemble of ver 14 >>> lb0.135\n\nver 17: train with categorical feature 'investment_id'\n\n- reference\n\nhttps:\/\/www.kaggle.com\/nischaydnk\/different-splits-for-the-competition-parquets\n\nhttps:\/\/www.kaggle.com\/columbia2131\/speed-up-reading-csv-to-pickle\n\nhttps:\/\/www.kaggle.com\/currypurin\/ubiquant-simple-lgbm-custom-metric"}}