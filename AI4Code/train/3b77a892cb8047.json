{"cell_type":{"c3c01aac":"code","aedb3a67":"code","ad14a1ae":"code","3650f1d4":"code","37b28f30":"code","80e7fe46":"code","ea898366":"code","af254af1":"code","44a0b7e9":"code","491c8d6f":"code","369c1e75":"code","f91bab65":"code","d805f5f8":"code","c6b7a59d":"code","e7fc41bd":"code","3a604e9e":"code","4975a935":"code","c8e79396":"code","61de6544":"code","45d8055e":"code","5eef8a33":"code","9ea9104c":"code","c6be7b94":"code","66e5672a":"code","c4ac77bc":"code","9c076d4b":"code","5c437ed4":"code","d996b8c5":"code","0f69bca2":"code","a925266f":"markdown","6ee32154":"markdown","be396692":"markdown","434daaed":"markdown","a91aaa62":"markdown","f2059e31":"markdown","959e1cc0":"markdown","31243303":"markdown","13d4e97d":"markdown","816f4014":"markdown","0300a50b":"markdown","9f3b6685":"markdown","2b80dcd1":"markdown","97ad8bdb":"markdown","e375a0df":"markdown"},"source":{"c3c01aac":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport warnings\nwarnings.filterwarnings('ignore')","aedb3a67":"# Data Loading\ndf = pd.read_csv('..\/input\/ibm-hr-analytics-attrition-dataset\/WA_Fn-UseC_-HR-Employee-Attrition.csv')\ndf.head()","ad14a1ae":"df.shape","3650f1d4":"df.describe()","37b28f30":"df.nunique().sort_values(ascending=True)","80e7fe46":"# We have 3 features which have unique values, we can delete them as they don't bring any significance for model \n# We have one feature which has unique values for each record, We can delete this one also, It is kind of unique key\ndf.drop(['Over18','StandardHours','EmployeeCount','EmployeeNumber'],axis=1,inplace=True)","ea898366":"plt.figure(figsize=(20,10))\nsns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='viridis')\nplt.show()","af254af1":"df.Attrition.replace(['Yes','No'],[1,0],inplace=True)\ndf.Gender.replace(['Male','Female'],[1,0],inplace=True)\ndf.OverTime.replace(['Yes','No'],[1,0],inplace=True)\n#df.head()","44a0b7e9":"# Object datatypes\nobj_fea = df.select_dtypes(include=['object'])\n# Numerical datatypes\nnum_fea = df.select_dtypes(exclude=['object'])\nobj_fea","491c8d6f":"# Relation of target variable with Categorical features\nplt.figure(figsize=(20,20))\nfor i,feat in enumerate(obj_fea.columns):\n    plt.subplot(3,2,i+1)\n    sns.barplot(x=df[feat],y=df['Attrition'])\n    plt.xticks(rotation=45)\nplt.show()","369c1e75":"num_fea.head()","f91bab65":"# Visualizing Numeric features \n\n# Age\nplt.figure(figsize=(10,8))\nsns.barplot(x=df['Age'],y=df['Attrition'])\nplt.xticks(rotation=45)\nplt.show()","d805f5f8":"# DistanceFromHome\nplt.figure(figsize=(10,8))\nsns.barplot(x=df['DistanceFromHome'],y=df['Attrition'])\nplt.xticks(rotation=45)\nplt.show()","c6b7a59d":"# Education\nplt.figure(figsize=(10,8))\nsns.barplot(x=df['Education'],y=df['Attrition'])\nplt.xticks(rotation=45)\nplt.show()","e7fc41bd":"# EnvironmentSatisfaction\nplt.figure(figsize=(10,8))\nsns.barplot(x=df['EnvironmentSatisfaction'],y=df['Attrition'])\nplt.xticks(rotation=45)\nplt.show()","3a604e9e":"# JobInvolvement\nplt.figure(figsize=(10,8))\nsns.barplot(x=df['JobInvolvement'],y=df['Attrition'])\nplt.xticks(rotation=45)\nplt.show()","4975a935":"# Gender\nplt.figure(figsize=(10,8))\nsns.barplot(x=df['Gender'],y=df['Attrition'])\nplt.xticks(rotation=45)\nplt.show()","c8e79396":"other_fea = ['NumCompaniesWorked','OverTime','PercentSalaryHike','PerformanceRating','RelationshipSatisfaction','StockOptionLevel']\nplt.figure(figsize=(20,20))\nfor i,feat in enumerate(other_fea):\n    plt.subplot(3,2,i+1)\n    sns.barplot(x=df[feat],y=df['Attrition'])\n    plt.xticks(rotation=45)\nplt.show()","61de6544":"num_fea.columns","45d8055e":"other_fea = ['TotalWorkingYears','WorkLifeBalance','YearsAtCompany','YearsInCurrentRole','YearsSinceLastPromotion','YearsWithCurrManager']\nplt.figure(figsize=(20,20))\nfor i,feat in enumerate(other_fea):\n    plt.subplot(3,2,i+1)\n    sns.barplot(x=df[feat],y=df['Attrition'])\n    plt.xticks(rotation=45)\nplt.show()","5eef8a33":"plt.figure(figsize=(20,20))\nsns.heatmap(df.corr(),annot=True,cmap='RdYlGn')\nplt.show()","9ea9104c":"df.head()","c6be7b94":"#Categorical Variable conversion\ndf = pd.get_dummies(df,drop_first=True)\ndf.head()","66e5672a":"df.info()","c4ac77bc":"# Unique Value Features\nuni_val_feat = [feat for feat in df.columns if df[feat].std() == 0]\nprint(uni_val_feat)\n\n# Quasi Constants\nfrom sklearn.feature_selection import VarianceThreshold\nsel = VarianceThreshold(threshold=0.01)\nsel.fit(df)\n\nquasi_const_feat = df.columns.difference(df.columns[sel.get_support()])\nprint(quasi_const_feat)","9c076d4b":"X = df.drop(['Attrition'],axis=1)\ny = df.Attrition\n\nfrom sklearn.model_selection import train_test_split\nXtrain,Xtest,ytrain,ytest = train_test_split(X,y,test_size=1\/3,random_state=1)","5c437ed4":"# LogisticRegression\nfrom sklearn.linear_model import LogisticRegression\nlo = LogisticRegression(solver='liblinear')\nlo_model = lo.fit(Xtrain,ytrain)\nlo_predict = lo_model.predict(Xtest)\n\nfrom sklearn.metrics import accuracy_score\nprint('Accuracy with LogisticRegression : ' + str(round(accuracy_score(ytest,lo_predict),2)*100))","d996b8c5":"# DecisionTreeClassifier\n\nfrom sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt_model = dt.fit(Xtrain,ytrain)\ndt_predict = dt_model.predict(Xtest)\n\nprint('Accuracy with DecisionTreeClassifier : ' + str(round(accuracy_score(ytest,lo_predict),2)*100))","0f69bca2":"# Ensemble Techniques\n\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom xgboost import XGBClassifier\n\n# RandomForestClassifier\nrf = RandomForestClassifier()\nrf_model = rf.fit(Xtrain,ytrain)\n# predicting values for test data\nrf_ypredict = rf_model.predict(Xtest)\nprint('Accuracy Score with RandomForestClassifier : ' + str(round(accuracy_score(ytest,rf_ypredict),2)*100))\nprint('#####################################################')\n\n# AdaBoostClassifier\nada = AdaBoostClassifier()\nada_model = ada.fit(Xtrain,ytrain)\n# predicting values for test data\nada_ypredict = ada_model.predict(Xtest)\nprint('Accuracy Score with AdaBoostClassifier : ' + str(round(accuracy_score(ytest,ada_ypredict),2)*100))\nprint('#####################################################')\n\n# GradientBoostingClassifier\ngb = GradientBoostingClassifier()\ngb_model = gb.fit(Xtrain,ytrain)\n# predicting values for test data\ngb_ypredict = gb_model.predict(Xtest)\nprint('Accuracy Score with GradientBoostingClassifier : ' + str(round(accuracy_score(ytest,gb_ypredict),2)*100))\nprint('#####################################################')\n\n# XGBClassifier\nxgb = XGBClassifier()\nxgb_model = xgb.fit(Xtrain,ytrain)\n# predicting values for test data\nxgb_ypredict = xgb_model.predict(Xtest)\nprint('Accuracy Score with XGBClassifier : ' + str(round(accuracy_score(ytest,xgb_ypredict),2)*100))\nprint('#####################################################')","a925266f":"Here we need to find whether Attrition happens or not based on given features, So we have to build **Classification Model** ","6ee32154":"Observation:-\n\n1. Who travels from long distance to workplace tends leave company than others","be396692":"Observations : - \n\n1. Who travel frequently for business purpose tends to leave company early than who travel rarely and Who don't need to travel will stay in company than others \n\n2. Reasearch and Development team employees will stay longer in company than other departments\n\n3. Whose education background is from Human resources,Techical degrees, Marketing tends to leave company than other ones from other Educational background\n\n4. Sales representatives will leave company much earlier than others, Research Directors rarely leaves the company\n\n5. Singles tends to leave company than Married ones and divorced\n","434daaed":"Observations:-\n\n1. Men tends to leave company sooner than women","a91aaa62":"There are no null information in dataset","f2059e31":"Observations:-\n\n1. Who leastly involves in Job in company tends to leave company sooner than others","959e1cc0":"**AdaBoostClassifier** performed well on this problem","31243303":"Observations:-\n\n1. Who worked for more number of compannies tends to switch again!\n\n2. Who works overtime tends to leave early\n\n3. Surprisingly Who got more percentage of hike tending to leave company!\n\n4. Performance Rating 3 & 4 Almost equal probability to leave or stay in company (We might need to remove this feature, because it doesn't have much say in Modeling\n\n5. Who have less Relationship Satisfaction tends to leave earlier than other\n\n6. Who have no company stocks tends to leave than who have more options, Who have more stock options tends to leave than who have comparitively less options.\n","13d4e97d":"Observations:-\n\n1. Who leastly likes the environment in company tends to leave company sooner than others","816f4014":"Observations:-\n\n1. Joblevel is highly corelated with MonthlyIncome (95%)\n\n2. JobLevel is correlated with TotalExperience (78%)\n\n3. Percentage of SalaryHike is related to PerformanceRating (77%)\n\n4. MonthlyIncome is correlated with TotalExperience (77%)\n\n5. YearsAtCompany is correlated with YearswithCurrentManager (77%)\n\n6. YearsAtCompany is correlated with YearCurrentRole (76%)\n\n7. Attrition rate is comparatevely highly correlated with OverTime (25%)","0300a50b":"# Reading Data","9f3b6685":"Observations:- \n\n1. Teenagers highly tends to leave company than Mid aged\n\n2. Persons whose age more than 55 tends to leave company than Mid aged ","2b80dcd1":"Observations:-\n\n1. Whose is less educated tends to leave company sooner than others","97ad8bdb":"Observations:-\n\n1. Employees who have 40 years experience will tend to leave company, Later who joined recently (whose experience is below 2) tends to leave \n\n2. Who have least worklife balance tends to resign faster than other\n\n3. Seniors in company tends to leave sooner than others\n\n4. Who stays in current role for longer time and who just got new role tends to leave company sooner than others\n\n5. Who don't get promotion for long time tends to leave comapany\n\n6. Who stays with Manager for longer time and shorter time tends to leave company than others","e375a0df":"# Exploratory Data Analasis"}}