{"cell_type":{"c738629e":"code","b8babe3c":"code","08dd1b6c":"code","a985d24e":"code","7810d3a8":"code","559b5b83":"code","70dd5c50":"code","ab7ecc51":"code","d0e1486d":"code","3c45e643":"markdown","7c596988":"markdown","76124e46":"markdown","906625b5":"markdown","ca93a423":"markdown","ee6a4ded":"markdown"},"source":{"c738629e":"!pip install pygam","b8babe3c":"import os\nimport gc\nimport time\nimport math\nimport random\nimport numpy as np\nimport pandas as pd\n\nimport scipy.stats as sc\nfrom scipy.stats import skew\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n\nfrom pygam import LogisticGAM, s, f","08dd1b6c":"def get_stats_per_row(data):\n    data['mv_row'] = data.isna().sum(axis=1)\n    data['min_row'] = data.min(axis=1)\n    data['std_row'] = data.std(axis=1)\n\n    return data\n\ndef impute_skewed_features(data):\n    skewed_feat = data.skew()\n    skewed_feat = [*skewed_feat[abs(skewed_feat.values) > 1].index]\n\n    for feat in skewed_feat:\n        median = data[feat].median()\n        data[feat] = data[feat].fillna(median)\n        \n    return data\n\ndef reduce_memory_usage(df, verbose=True):\n    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n    start_mem = df.memory_usage().sum() \/ 1024 ** 2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (\n                    c_min > np.finfo(np.float16).min\n                    and c_max < np.finfo(np.float16).max\n                ):\n                    df[col] = df[col].astype(np.float16)\n                elif (\n                    c_min > np.finfo(np.float32).min\n                    and c_max < np.finfo(np.float32).max\n                ):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() \/ 1024 ** 2\n    if verbose:\n        print(\n            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n                end_mem, 100 * (start_mem - end_mem) \/ start_mem\n            )\n        )\n    return df","a985d24e":"train_data = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv', index_col=0)\ntest_data = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv', index_col=0)\n\n# prepare dataframe for modeling\nX = train_data.drop(columns=['claim']).copy()\ntarget = train_data['claim'].copy()\n\n# feature-engineering\nX = get_stats_per_row(X)\ntest_data = get_stats_per_row(test_data)\n\n# get skewed features to impute median instead of mean\nX = impute_skewed_features(X)\ntest_data = impute_skewed_features(test_data)\n\npipeline = Pipeline([\n    ('impute', SimpleImputer(strategy='mean')),\n    ('scale', StandardScaler())\n])\n\nX = pd.DataFrame(columns=X.columns, data=pipeline.fit_transform(X))\ntest = pd.DataFrame(columns=test_data.columns, data=pipeline.transform(test_data))\n\nfeatures = [x for x in X.columns.values if x[0]==\"f\"]\n\nX['multiply'] = X[features].prod(axis=1)\ntest['multiply'] = test[features].prod(axis=1)","7810d3a8":"train = pd.concat([X, target], axis=1)\n\ntrain = reduce_memory_usage(train)\n\ntest = reduce_memory_usage(test)","559b5b83":"del train_data\n\ndel test_data\n\ndel X\n\ngc.collect()","70dd5c50":"n_folds = 5\nrandom_state = 42\n\nfeat_imp = [\"f40\", \"f1\", \"f42\", \"f47\", \"f13\", \"f70\", \"f65\", \"f106\", \"f75\", \"f7\",\n            \"f35\", \"f5\", \"f34\", \"f107\", \"f77\", \"f28\", \"f81\", \"f61\", \"f31\", \"f24\",\n            \"f30\", \"f29\", \"f50\", \"f12\", \"f103\", \"f6\", \"f45\", \"f86\", \"f99\", \"f21\",\n            \"mv_row\", \"min_row\", \"std_row\",\t\"multiply\"]\n\nfeat_imp2 = [\"f40\", \"f1\", \"f42\", \"f47\", \"f13\", \"f70\", \"f65\", \"f106\", \"f75\", \"f7\",\n            \"f35\", \"f5\", \"f34\", \"f107\", \"f77\", \"f28\", \"f81\", \"f61\", \"f31\", \"f24\",\n             \"mv_row\", \"min_row\", \"std_row\", \"multiply\"]\n\nfeat_imp3 = [\"f40\", \"f1\", \"f42\", \"f47\", \"f13\", \"f70\", \"f65\", \"f106\", \"f75\", \"f7\",\n             \"mv_row\", \"min_row\", \"std_row\", \"multiply\"]\n\n\nk_fold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n\ntrain_preds = np.zeros(len(train.index))\ntest_preds = np.zeros(len(test.index))\n\ntrain_preds2 = np.zeros(len(train.index))\ntest_preds2 = np.zeros(len(test.index))\n\ntrain_preds3 = np.zeros(len(train.index))\ntest_preds3 = np.zeros(len(test.index))\n\ntrain_preds4 = np.zeros(len(train.index))\ntest_preds4 = np.zeros(len(test.index))\n\ntrain_preds5 = np.zeros(len(train.index))\ntest_preds5 = np.zeros(len(test.index))\n\nfor fold, (train_index, test_index) in enumerate(k_fold.split(train, target)):\n    print(\"--> Fold {}\".format(fold + 1))\n    y_train = target.iloc[train_index]\n    y_valid = target.iloc[test_index]\n\n    x_train = pd.DataFrame(train[feat_imp].iloc[train_index])\n    x_valid = pd.DataFrame(train[feat_imp].iloc[test_index])\n\n    x_train2 = pd.DataFrame(train[feat_imp].iloc[train_index])\n    x_valid2 = pd.DataFrame(train[feat_imp].iloc[test_index])\n\n    x_train3 = pd.DataFrame(train[feat_imp].iloc[train_index])\n    x_valid3 = pd.DataFrame(train[feat_imp].iloc[test_index])\n\n    x_train4 = pd.DataFrame(train[feat_imp2].iloc[train_index])\n    x_valid4 = pd.DataFrame(train[feat_imp2].iloc[test_index])\n\n    x_train5 = pd.DataFrame(train[feat_imp3].iloc[train_index])\n    x_valid5 = pd.DataFrame(train[feat_imp3].iloc[test_index])\n\n    model = LogisticGAM(max_iter=100, n_splines=12)\n\n    model.fit(\n        x_train, \n        y_train)\n\n    train_oof_preds = model.predict_proba(x_valid)\n    test_oof_preds = model.predict_proba(test[feat_imp])\n    train_preds[test_index] = train_oof_preds\n    test_preds += test_oof_preds \/ n_folds\n\n    print(\": GAM - AUC = {}\".format(roc_auc_score(y_valid, train_oof_preds)))\n\n    model2 = LogisticGAM(max_iter=100, n_splines=14)\n\n    model2.fit(\n        x_train2, \n        y_train\n    )\n\n    train_oof_preds = model2.predict_proba(x_valid2)\n    test_oof_preds = model2.predict_proba(test[feat_imp])\n    train_preds2[test_index] = train_oof_preds\n    test_preds2 += test_oof_preds \/ n_folds\n\n    print(\": GAM2 - AUC = {}\".format(roc_auc_score(y_valid, train_oof_preds)))\n\n    model3 = LogisticGAM(max_iter=100, n_splines=16)\n\n    model3.fit(\n        x_train3, \n        y_train\n    )\n\n    train_oof_preds = model3.predict_proba(x_valid3)\n    test_oof_preds = model3.predict_proba(test[feat_imp])\n    train_preds3[test_index] = train_oof_preds\n    test_preds3 += test_oof_preds \/ n_folds\n\n    print(\": GAM3 - AUC = {}\".format(roc_auc_score(y_valid, train_oof_preds)))\n\n    model4 = LogisticGAM(max_iter=100, n_splines=25)\n\n    model4.fit(\n        x_train4,\n        y_train\n    )\n\n    train_oof_preds = model4.predict_proba(x_valid4)\n    test_oof_preds = model4.predict_proba(test[feat_imp2])\n    train_preds4[test_index] = train_oof_preds\n    test_preds4 += test_oof_preds \/ n_folds\n\n    print(\": GAM4 - AUC = {}\".format(roc_auc_score(y_valid, train_oof_preds)))\n\n\n    model5 = LogisticGAM(max_iter=100, n_splines=14)\n\n    model5.fit(\n        x_train5,\n        y_train\n    )\n\n    train_oof_preds = model5.predict_proba(x_valid5)\n    test_oof_preds = model5.predict_proba(test[feat_imp3])\n    train_preds5[test_index] = train_oof_preds\n    test_preds5 += test_oof_preds \/ n_folds\n\n    print(\": GAM5 - AUC = {}\".format(roc_auc_score(y_valid, train_oof_preds)))\n\n    print(\"\")\n\nprint(\"--> Overall metrics\")\nprint(\": GAM - AUC = {}\".format(roc_auc_score(target, train_preds)))\nprint(\": GAM2 - AUC = {}\".format(roc_auc_score(target, train_preds2)))\nprint(\": GAM3 - AUC = {}\".format(roc_auc_score(target, train_preds3)))\nprint(\": GAM4 - AUC = {}\".format(roc_auc_score(target, train_preds4)))\nprint(\": GAM5 - AUC = {}\".format(roc_auc_score(target, train_preds5)))","ab7ecc51":"n_folds = 10\nrandom_state = 42\nk_fold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n\nl1_train = pd.DataFrame(data={\n    \"gam\": train_preds.tolist(),\n    \"gam2\": train_preds2.tolist(),\n    \"gam3\": train_preds3.tolist(),\n    \"gam4\": train_preds4.tolist(),\n    \"gam5\": train_preds5.tolist(),\n    \"target\": target.tolist()\n})\n\nl1_test = pd.DataFrame(data={\n    \"gam\": test_preds.tolist(),\n    \"gam2\": test_preds2.tolist(),\n    \"gam3\": test_preds3.tolist(),\n    \"gam4\": test_preds4.tolist(),\n    \"gam5\": test_preds5.tolist(),\n})\n\ntrain_preds_final = np.zeros(len(l1_train.index))\ntest_preds_final = np.zeros(len(l1_test.index))\nfeatures = [\"gam\", \"gam2\", \"gam3\", \"gam4\", \"gam5\"]\n\nfor fold, (train_index, test_index) in enumerate(k_fold.split(l1_train, target)):\n    print(\"--> Fold {}\".format(fold + 1))\n    y_train = target.iloc[train_index]\n    y_valid = target.iloc[test_index]\n\n    x_train = pd.DataFrame(l1_train[features].iloc[train_index])\n    x_valid = pd.DataFrame(l1_train[features].iloc[test_index])\n\n    model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, random_state=random_state, max_iter=1000, n_jobs=4)\n    model.fit(\n        x_train,\n        y_train,\n    )\n\n    train_oof_preds = model.predict_proba(x_valid)[:, -1]\n    test_oof_preds = model.predict_proba(l1_test[features])[:, -1]\n    train_preds_final[test_index] = train_oof_preds\n    test_preds_final += test_oof_preds \/ n_folds\n    print(\": AUC = {}\".format(roc_auc_score(y_valid, train_oof_preds)))\n    print(\"\")\n    \nprint(\"--> Overall metrics\")\nprint(\": AUC = {}\".format(roc_auc_score(target, train_preds_final)))","d0e1486d":"submission = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv\")\nsubmission[\"claim\"] = test_preds_final.tolist()\nsubmission.to_csv(\"submission.csv\", index=False)\n\nsubmission.head()","3c45e643":"## Collect oof predictions and define meta-model","7c596988":"## Load and process data","76124e46":"## Define functions","906625b5":"## Create final submission","ca93a423":"## Import libraries","ee6a4ded":"## Get out of fold (oof) predictions"}}