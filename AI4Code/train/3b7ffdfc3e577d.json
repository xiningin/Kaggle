{"cell_type":{"d076c906":"code","11f5673f":"code","262ca4e7":"code","13413722":"code","68cb87cb":"code","9fb158eb":"code","e4bd3cb9":"code","bba44c48":"code","bdd2873a":"code","295f00d3":"code","c9dd8b95":"code","17362484":"code","013199c6":"code","d8533190":"code","85136c07":"code","fbd53acf":"code","adcded5d":"code","d8d8e75b":"code","eb9341d4":"code","6e5d2e0b":"code","8bd02617":"code","a5956bfb":"code","8bd82f38":"code","fe012c74":"markdown","399e2897":"markdown","6bc6932f":"markdown","b662072b":"markdown","92f997fa":"markdown","6769b161":"markdown","1bb39d65":"markdown","99988e7a":"markdown"},"source":{"d076c906":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","11f5673f":"import matplotlib.pyplot as plt\nimport tensorflow as tf\nimport unidecode\nimport nltk\n\nfrom tensorflow import keras\nfrom keras.preprocessing.text import text_to_word_sequence\nfrom gensim.parsing.preprocessing import remove_stopwords\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn import svm\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n","262ca4e7":"path = '..\/input\/nlp-getting-started\/'\n\n#Data files\ntrain_data_file = path + 'train.csv'\ntest_data_file = path + 'test.csv'\n\n\ndataset = pd.read_csv(train_data_file)\ndataset.head()\n\ntest_set = pd.read_csv(test_data_file)\n","13413722":"target_category = dataset[\"target\"].unique()\ntarget_category=list(map(str,target_category))\nprint(target_category)\n\n","68cb87cb":"print(len(dataset))\nprint(len(test_set))","9fb158eb":"dataset = dataset[['text','target']]\ndataset.head()","e4bd3cb9":"dataset.groupby(\"target\").target.count().plot.bar(ylim=0)","bba44c48":"text = dataset[\"text\"]\ntext.head()","bdd2873a":"print(text.iloc[31])","295f00d3":"def processing(text): \n    \n    #for row in text:\n    \n#tokenization using keras text to word sequence tokenizer\n    tokenized_text = text_to_word_sequence(text)\n    #print(tokenized_text)\n        \n#stop word removal using remove_stopwords from gensim\n    text = ' '.join(tokenized_text)\n    text = text.replace(\"'\", \"\")\n    stop_word_removed_text = remove_stopwords(text)\n    #print(stop_word_removed_text)\n        \n#remove numbers\n    number_removed_text = new_string = ''.join(filter(lambda x: not x.isdigit(), stop_word_removed_text))\n    #print(number_removed_text)\n        \n#remove extra white spaces\n    extra_whitespace_removed = word_tokenize(number_removed_text)\n    extra_whitespace_removed = number_removed_text.split()\n    #print(extra_whitespace_removed)\n        \n    extra_whitespace_removed = ' '.join(extra_whitespace_removed)\n    #print(extra_whitespace_removed)\n        \n#Convert Accented Characters(\u00fb -> u)\n    accented_removed_text = unidecode.unidecode(extra_whitespace_removed)\n    #print(accented_removed_text)\n        \n#lemmatization\n    lemmatizer = WordNetLemmatizer()\n\n    def get_wordnet_pos(word):\n        \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n        tag = nltk.pos_tag([word])[0][1][0].upper()\n        tag_dict = {\"J\": wordnet.ADJ,\n                    \"N\": wordnet.NOUN,\n                    \"V\": wordnet.VERB,\n                    \"R\": wordnet.ADV}\n\n        return tag_dict.get(tag, wordnet.NOUN)\n\n    lem_input = nltk.word_tokenize(accented_removed_text)\n    lem_text= ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in lem_input])\n    #print(lem_text)\n       \n#stemming \n    stemmer= PorterStemmer()\n\n    stem_input= nltk.word_tokenize(lem_text)\n    stem_text=' '.join([stemmer.stem(word) for word in stem_input])\n    #print(stem_text) \n        \n#remove single letters\n    preprocessed_text = ' '.join( [w for w in stem_text.split() if len(w)>1] )\n    #print(preprocessed_text)\n        \n    return preprocessed_text\n        \ndataset['text']=dataset['text'].apply(processing)  \n","c9dd8b95":"text = dataset['text']\ntext.head(10)","17362484":"target = dataset[\"target\"]\ntarget.head()","013199c6":"X_train, X_test, Y_train, Y_test = train_test_split(text,target, test_size = 0.3, random_state = 60,shuffle=True)\n\nprint(len(X_train))\nprint(len(X_test))","d8533190":"nb = Pipeline([('tfidf', TfidfVectorizer()),\n               ('clf', MultinomialNB()),\n              ])\nnb.fit(X_train,Y_train)\n\ntest_predict = nb.predict(X_test)\n\ntrain_accuracy = round(nb.score(X_train,Y_train)*100)\ntest_accuracy =round(accuracy_score(test_predict, Y_test)*100)\n\n\nprint(\"Naive Bayes Train Accuracy Score : {}% \".format(train_accuracy ))\nprint(\"Naive Bayes Test Accuracy Score  : {}% \".format(test_accuracy ))\nprint()\nprint(classification_report(test_predict, Y_test, target_names=target_category))\n\n","85136c07":"sgd = Pipeline([('tfidf', TfidfVectorizer()),\n                ('clf', SGDClassifier()),\n               ])\n\nsgd.fit(X_train, Y_train)\n\ntest_predict = sgd.predict(X_test)\n\ntrain_accuracy = round(sgd.score(X_train,Y_train)*100)\ntest_accuracy =round(accuracy_score(test_predict, Y_test)*100)\n\nprint(\"SVM Train Accuracy Score : {}% \".format(train_accuracy ))\nprint(\"SVM Test Accuracy Score  : {}% \".format(test_accuracy ))\nprint()\nprint(classification_report(test_predict, Y_test, target_names=target_category))\n\n\n","fbd53acf":"dt = Pipeline([('tfidf', TfidfVectorizer()),\n                ('dt', DecisionTreeClassifier()),\n               ])\n\ndt.fit(X_train, Y_train)\n\ntest_predict = dt.predict(X_test)\n\ntrain_accuracy = round(dt.score(X_train,Y_train)*100)\ntest_accuracy =round(accuracy_score(test_predict, Y_test)*100)\n\nprint(\"Decision Tree Train Accuracy Score : {}% \".format(train_accuracy ))\nprint(\"Decision Tree Test Accuracy Score  : {}% \".format(test_accuracy ))\nprint()\nprint(classification_report(test_predict, Y_test, target_names=target_category))\n","adcded5d":"knn = Pipeline([('tfidf', TfidfVectorizer()),\n                ('knn', KNeighborsClassifier(n_neighbors=5, metric='euclidean')),\n               ])\n\nknn.fit(X_train, Y_train)\n\ntest_predict = knn.predict(X_test)\n\ntrain_accuracy = round(knn.score(X_train,Y_train)*100)\ntest_accuracy =round(accuracy_score(test_predict, Y_test)*100)\n\nprint(\"K-Nearest Neighbour Train Accuracy Score : {}% \".format(train_accuracy ))\nprint(\"K-Nearest Neighbour Test Accuracy Score  : {}% \".format(test_accuracy ))\nprint()\nprint(classification_report(test_predict, Y_test, target_names=target_category))\n","d8d8e75b":"\nlr = Pipeline([('tfidf', TfidfVectorizer()),\n                ('lr', LogisticRegression()),\n               ])\n\nlr.fit(X_train, Y_train)\n\ntest_predict = lr.predict(X_test)\n\ntrain_accuracy = round(lr.score(X_train,Y_train)*100)\ntest_accuracy =round(accuracy_score(test_predict, Y_test)*100)\n\nprint(\"Logistic regression Train Accuracy Score : {}% \".format(train_accuracy ))\nprint(\"Logistic regression  Test Accuracy Score  : {}% \".format(test_accuracy ))\nprint()\nprint(classification_report(test_predict, Y_test, target_names=target_category))\n","eb9341d4":"rfc = Pipeline([('tfidf', TfidfVectorizer()),\n                ('rfc', RandomForestClassifier(n_estimators=100)),\n               ])\n\nrfc.fit(X_train, Y_train)\n\ntest_predict = rfc.predict(X_test)\n\ntrain_accuracy = round(rfc.score(X_train,Y_train)*100)\ntest_accuracy =round(accuracy_score(test_predict, Y_test)*100)\n\nprint(\"Random Forest Classifier Train Accuracy Score : {}% \".format(train_accuracy ))\nprint(\"Random Forest Classifier Test Accuracy Score  : {}% \".format(test_accuracy ))\nprint()\nprint(classification_report(test_predict, Y_test, target_names=target_category))\n\n\n\n","6e5d2e0b":"test_set.head()","8bd02617":"test_set['text'] = test_set['text'].apply(processing)\n\ntest_id = test_set['id']\ntest_text = test_set['text']\ny_prdict = nb.predict(test_text)\n\n","a5956bfb":"#submission = pd.DataFrame(test_id)\nsubmission = pd.DataFrame(list(zip(test_id, y_prdict)),\n               columns =['id', 'target'])\nsubmission.head(20)","8bd82f38":"submission.to_csv('submission.csv', index=False)","fe012c74":"**K-Nearest Neighbour**","399e2897":"**Text Preprocessing**","6bc6932f":"**Naive Bayes as the finel model**","b662072b":"**Naive Bayes Classifier**","92f997fa":"**Logistic Regression**","6769b161":"**Decision Tree Classifier**","1bb39d65":"**Support Vector Machine Classifier**","99988e7a":"**Random Forest Classifier**"}}