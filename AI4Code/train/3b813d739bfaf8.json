{"cell_type":{"eaf1ae7d":"code","93f46cb1":"code","136dea36":"code","6c98e846":"code","b4b4681b":"code","088a9a70":"code","b5871364":"code","abbc866e":"code","df7e8221":"code","40c880b6":"code","0a6cbed0":"code","a2a2e3ef":"code","cc2956bd":"code","bde74e72":"code","914aad00":"code","90128415":"code","a9828ca9":"code","bce80628":"code","dda1270a":"code","b0217bf0":"code","b4d41e01":"code","f71e66c4":"code","44eccdc4":"code","f00ed1a4":"code","391b3c1b":"code","c8f48df5":"code","093fe6ba":"code","e3b717c8":"code","e047f834":"code","3e0ca8d7":"code","0f046171":"code","23081d64":"code","5ea54069":"code","c2ccbba0":"markdown","7b785bf2":"markdown","07a7587b":"markdown","96401b90":"markdown","7ce6b594":"markdown","cf2d137c":"markdown","91c2e165":"markdown","7c71d840":"markdown","32869e8e":"markdown","c6ea1458":"markdown","8c4b1874":"markdown"},"source":{"eaf1ae7d":"import pandas as pd\nimport numpy as np","93f46cb1":"df = pd.read_csv('..\/input\/melbourne-dataset\/Melbourne_Dataset.csv')","136dea36":"df.head()","6c98e846":"df.describe().transpose()","b4b4681b":"df.info()","088a9a70":"## columns with missing values\nmissing_values_cols = [col for col in df.columns\n                      if df[col].isnull().any()]\nmissing_values_cols\ndf_for_model = df.drop(missing_values_cols,axis=1)","b5871364":"## Categorize columns in Numerical and Categorical\nnumerical_cols = (df_for_model.dtypes != 'object')\nnumerical_cols = list(numerical_cols[numerical_cols].index)\ncategorical_cols = (df_for_model.dtypes == 'object')\ncategorical_cols = list(categorical_cols[categorical_cols].index)\nnumerical_cols , categorical_cols","abbc866e":"df[numerical_cols].shape , df[categorical_cols].shape","df7e8221":"numerical_cols.remove('Price')","40c880b6":"numerical_cols","0a6cbed0":"X = df_for_model[numerical_cols]\ny = df_for_model['Price']","a2a2e3ef":"from sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error as MAE","cc2956bd":"train_X,val_X,train_y,val_y = train_test_split(X,y,random_state=42)","bde74e72":"## function to return model\ndef return_model(train_X,val_X,train_y,val_y):\n    model = RandomForestRegressor(n_estimators=100, random_state=1)\n    model.fit(train_X,train_y)\n    return model","914aad00":"## score_model\ndef score_model(val_X):\n    predictions = model.predict(val_X)\n    error = MAE(val_y,predictions)\n    return 'Mean Absolute Error is :' + str(error)","90128415":"model = return_model(train_X,val_X,train_y,val_y)\nerror = score_model(val_X)\nerror","a9828ca9":"df_test = pd.read_csv('..\/input\/melbourne-datasettest\/Melbourne_Dataset-Test.csv')\nX_test = df_test[numerical_cols]","bce80628":"predictions = model.predict(X_test)\ndf_final = pd.DataFrame({'X:':df_test.Price,\n                         'y:':predictions})\ndf_final","dda1270a":"from sklearn.impute import SimpleImputer\n#     - If \"mean\", then replace missing values using the mean along\n#       each column. Can only be used with numeric data.\n#     - If \"median\", then replace missing values using the median along\n#       each column. Can only be used with numeric data.\n#     - If \"most_frequent\", then replace missing using the most frequent\n#       value along each column. Can be used with strings or numeric data.\n#     - If \"constant\", then replace missing values with fill_value. Can be\n#       used with strings or numeric data.","b0217bf0":"imputer_mean = SimpleImputer()","b4d41e01":"## Categorize columns in Numerical and Categorical\nnumerical_cols = (df.dtypes != 'object')\nnumerical_cols = list(numerical_cols[numerical_cols].index)","f71e66c4":"numerical_cols.remove('Price')","44eccdc4":"categorical_cols = (df.dtypes == 'object')\ncategorical_cols = list(categorical_cols[categorical_cols].index)","f00ed1a4":"X = df[numerical_cols]\ny = df['Price']","391b3c1b":"train_X,val_X,train_y,val_y = train_test_split(X,y,random_state=42)","c8f48df5":"df_iputed_cols_train = pd.DataFrame(imputer_mean.fit_transform(train_X)) ","093fe6ba":"df_iputed_cols_val = pd.DataFrame(imputer_mean.transform(val_X)) ","e3b717c8":"df_iputed_cols_train.columns = train_X.columns\ndf_iputed_cols_val.columns = val_X.columns","e047f834":"df_iputed_cols_train.shape","3e0ca8d7":"df_iputed_cols_val.shape","0f046171":"model = return_model(df_iputed_cols_train,df_iputed_cols_val,train_y,val_y)\nerror = score_model(df_iputed_cols_val)\nerror","23081d64":"X_test = df_test[numerical_cols]\ndf_iputed_cols_test = pd.DataFrame(imputer_mean.transform(X_test)) \npredictions = model.predict(df_iputed_cols_test)","5ea54069":"df_final = pd.DataFrame({'X:':df_test.Price,\n                         'y:':predictions})\ndf_final","c2ccbba0":"## Testing data set with 2nd method : SimpleImputer","7b785bf2":"<h3>5. Numerical cols columns in dataset<\/h3>\n<h3>6. Categorical columns in dataset<\/h3>","07a7587b":"## Imputation method Simple Imputer (default mean value replacement)","96401b90":"<h3>9. Split into training and validation sets<\/h3>\n<h3>10. Train the model and record the Mean Absolute Error of models<\/h3>","7ce6b594":"<h3>8. X,y features creation<\/h3>","cf2d137c":"<h3>3. Find the missing col names<\/h3>\n<h3>4. Drop them from dataset<\/h3>","91c2e165":"## Missing-Values-Methods\n### First notebook sharing on Kaggle :)\n* Drop Column\n* Imputation\n\n* I have created this notebook to practice my hands on skills for missing value issue in Machine learning.\n* This is not an full flexed model design ,goal is to handle missing data using 2 techniques\n* I will improve the model performance by practice :)\n* Any suggestions which can help to make my work better will be great \n* Keep learning\n* Melbourne dataset used","7c71d840":"## Test data set","32869e8e":"<h3>1.  Read dataset<\/h3>\n<h3>2. Check dataset stats<\/h3>","c6ea1458":"<h3>7. List of X features<\/h3>","8c4b1874":"## Testing data set with 1st method : column removal"}}