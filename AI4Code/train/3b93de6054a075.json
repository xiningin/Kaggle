{"cell_type":{"94a54baa":"code","af7fbcb3":"code","bf281bd5":"code","df7ee070":"code","2869f5ee":"code","f71fe2f4":"code","e44789e4":"code","f0ce8511":"code","4e353b0b":"code","2c4b9985":"code","f2abad1c":"code","5f3e2b2f":"code","1498a6ed":"code","f8220600":"code","ff5053f6":"code","e53ef63c":"markdown","a557c628":"markdown","bc622887":"markdown","893c580b":"markdown","cd02a859":"markdown","58544d83":"markdown","551fd360":"markdown","d59cbb4b":"markdown","a4baf572":"markdown"},"source":{"94a54baa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfrom glob import glob\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","af7fbcb3":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\n%matplotlib inline\nfrom IPython.display import Audio, display, HTML\nimport itertools\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport umap.umap_ as umap\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\nfrom librosa import load\n\ndef standardize(f):\n    return StandardScaler( # z = (x - mean) \/ stddev\n        #with_std=False, #z = (x - mean) if False\n        #with_mean=False,#z = x\/stddev if False\n    ).fit_transform(f)\n\ndef get_pca(features, n_components=2):\n    pca = PCA(n_components=n_components)\n    comp = pca.fit(features).transform(standardize(features))\n    return MinMaxScaler().fit_transform(comp)\n\n\n\ndef get_tsne_embeddings(features, n_components=2, perplexity=15, iteration=20000):\n    tsne_embedding = TSNE(n_components=n_components,\n                     perplexity=perplexity,\n                     verbose=0,\n                     n_iter=iteration).fit_transform(standardize(features))\n    return MinMaxScaler().fit_transform(tsne_embedding)\n\n\ndef get_umap_embeddings(features, n_components=2, neighbor=15, distance=0.1):\n    umap_embedding = umap.UMAP(n_neighbors=neighbor,\n                               min_dist=distance,\n                               n_epochs=5000,\n                               metric='correlation', \n                               n_components=n_components, \n                               verbose=False).fit_transform(standardize(features))\n    return MinMaxScaler().fit_transform(umap_embedding)","bf281bd5":"df = pd.read_csv(\"..\/input\/gtzan-dataset-music-genre-classification\/Data\/features_3_sec.csv\")\ndf = df[df.filename.apply(lambda x: x.split(\".\")[-2]=='0')].copy().reset_index(drop=True)\nfeatures = df.iloc[:,2:-1]\nle = LabelEncoder()\ntarget = le.fit_transform(df.iloc[:,-1])\ndf.sample(5)","df7ee070":"tsne_embeddings = dict()\nperplexities = [10,15,20,25,30]\niterations = [5000,10000,15000,20000,25000]\nfor perplexity, iteration in tqdm(list(itertools.product(perplexities,iterations))): #for a prettier progress bar\n    tsne_embedding = get_tsne_embeddings(features,\n                                         perplexity=perplexity,\n                                         iteration=iteration)\n    tsne_embeddings[f\"{perplexity}_{iteration}\"]= tsne_embedding","2869f5ee":"color_scheme = {\n 'classical': '#FE88FC',\n 'jazz': '#F246FE',\n 'blues': '#BF1CFD', \n 'metal': '#6ECE58',\n 'rock': '#35B779',\n 'disco': '#1F9E89',\n 'pop': '#Fb9B06',\n 'reggae': '#ED6925',\n 'hiphop': '#CF4446',   \n 'country': '#000004',   \n }\n\ndef plot_components(embeddings, n_rows, n_cols, title, suptitle):\n    \"\"\"helper function to plot embeddings\"\"\"\n    fig, ax = plt.subplots(n_rows, n_cols, sharex=True, sharey=True, figsize=(20,20))\n    r=0\n    c=0\n    for i in embeddings:\n        df_ = pd.DataFrame(embeddings[i])\n        df_.columns = [f'pc{i}' for i in range(1, len(df_.columns)+1)]\n        df_['genre'] = df.iloc[:,-1]\n        genres = df_.genre.unique()\n        if c>n_cols-1: c=0; r+=1\n        if r> n_rows-1: break\n        for genre in genres:\n            ax[r,c].scatter(df_[df_.genre==genre]['pc1'],\n                            df_[df_.genre==genre]['pc2'], \n                            color=color_scheme[genre],\n                            s=1\n                           )\n        ax[r,c].set_title(title.format(i.split('_')[0],i.split('_')[1]))\n        ax[r,c].axis('off')\n        c+=1\n\n    plt.figlegend(df_.genre.unique(), loc='center right', prop={'size': 18}, markerscale=10);\n    plt.suptitle(suptitle,fontsize=24);","f71fe2f4":"plot_components(tsne_embeddings, len(perplexities), len(iterations), \"perplexity={}\\nepochs={}\",\"t-SNE\")","e44789e4":"umap_embeddings = dict()\nneighbors = list(range(10,31,5))\ndistances = [0.01, 0.02, 0.03, 0.04, 0.05]\nfor neighbor, distance in tqdm(list(itertools.product(neighbors,distances))):#for a prettier progress bar\n    umap_embedding = get_umap_embeddings(features,\n                                         neighbor=neighbor,\n                                         distance=distance)\n    umap_embeddings[f\"{neighbor}_{distance}\"]= umap_embedding","f0ce8511":"plot_components(umap_embeddings, len(neighbors), len(distances), \"neighbors={}\\nmin distance={}\",\"UMAP\")","4e353b0b":"tsne_embedding = get_tsne_embeddings(features,\n                                     n_components=3,\n                                     perplexity=30,\n                                     iteration=20000)\ndf_tsne = pd.DataFrame(tsne_embedding)\ndf_tsne.columns = ['pc1','pc2','pc3']\ndf_tsne['genre'] = df.iloc[:,-1]\ndf_tsne['text'] = df[['filename','label']].apply(lambda x: f'{x[0]}<br>{x[1]}', axis=1)","2c4b9985":"import plotly.graph_objects as go\n\ndata = []\nfor g in df_tsne.genre.unique():\n    trace = go.Scatter3d(\n    x=df_tsne[df_tsne.genre==g].pc1.values,\n    y=df_tsne[df_tsne.genre==g].pc2.values,\n    z=df_tsne[df_tsne.genre==g].pc3.values,\n    mode='markers',\n    text=df_tsne[df_tsne.genre==g].text.values,\n    hoverinfo = 'text',\n    name=g,\n    marker=dict(\n            size=3,\n            color=color_scheme[g],                \n            opacity=0.9,\n        )\n    )\n    data.append(trace)\nfig = go.Figure(data=data)\n\nfig.update_layout(title=f'TSNE', autosize=False,\n                      width=600, height=600,\n                      margin=dict(l=50, r=50, b=50, t=50),\n                      scene=dict(xaxis=dict(title='pc1'), yaxis=dict(title='pc2'), zaxis=dict(title='pc3'))\n                     )\nfig.show()","f2abad1c":"umap_embedding = get_umap_embeddings(features,\n                                     n_components=3,\n                                     neighbor=20,\n                                     distance=0.05)\ndf_umap = pd.DataFrame(umap_embedding)\ndf_umap.columns = ['pc1','pc2','pc3']\ndf_umap['genre'] = df.iloc[:,-1]\ndf_umap['text'] = df[['filename','label']].apply(lambda x: f'{x[0]}<br>{x[1]}', axis=1)\ndf_umap['color'] = df_umap.genre.apply(lambda x: color_scheme[x])","5f3e2b2f":"data = []\nfor g in df_umap.genre.unique():\n    trace = go.Scatter3d(\n    x=df_umap[df_umap.genre==g].pc1.values,\n    y=df_umap[df_umap.genre==g].pc2.values,\n    z=df_umap[df_umap.genre==g].pc3.values,\n    mode='markers',\n    text=df_umap[df_umap.genre==g].text.values,\n    hoverinfo = 'text',\n    name=g,\n    marker=dict(\n            size=3,\n            color=color_scheme[g],                \n            opacity=0.9,\n        )\n    )\n    data.append(trace)\nfig = go.Figure(data=data)\n\n# tight layout\nfig.update_layout(title=f'UMAP (Unsupervised)', autosize=False,\n                      width=600, height=600,\n                      margin=dict(l=50, r=50, b=50, t=50),\n                      scene=dict(xaxis=dict(title='pc1'), yaxis=dict(title='pc2'), zaxis=dict(title='pc3'))\n                     )\nfig.show()","1498a6ed":"# pick a random point\na_pt = umap_embedding[np.random.randint(0,len(umap_embedding))]\n# compute euclidean distances from all points to this point. Get sorted indices of top 6. The first one being the original point.\nidx = np.argsort(np.linalg.norm(umap_embedding-a_pt, axis=1))[:6]\n\n# display and play\npath = \"..\/input\/gtzan-dataset-music-genre-classification\/Data\/genres_original\/{}\/{}.wav\"\nfor i, k in enumerate(idx):\n    # \"filename\" in the dataset is not a real file. Following lines involve some skulduggery to get correct audio segment from file. \n    fname = path.format(df.iloc[k,:]['label'],\".\".join(df.iloc[k,:]['filename'].split(\".\")[:-2]))\n    segment_index = int(df.iloc[k,:]['filename'].split(\".\")[-2])\n    y, sr = load(fname, mono=True)\n    start = segment_index*sr\n    end = start+(sr*3)\n    y = y[start:end]\n    \n    if i==0: display(HTML(f\"<p>Original:{df.iloc[k,:]['label']}<\/p><p>{fname}<\/p>\"), Audio(y, rate=sr))\n    else: display(HTML(f\"<p>Neighbor {i}:{df.iloc[k,:]['label']}<\/p><p>{fname}<\/p>\"), Audio(y, rate=sr))","f8220600":"umap_embedding = umap.UMAP(n_neighbors=30,\n                               min_dist=0.4,\n                               metric='correlation', \n                               n_components=3,\n                               set_op_mix_ratio=0.25,\n                               verbose=False).fit_transform(standardize(features), y=target)\numap_embedding = MinMaxScaler().fit_transform(umap_embedding)\ndf_umap = pd.DataFrame(umap_embedding)\ndf_umap.columns = ['pc1','pc2','pc3']\ndf_umap['genre'] = df.iloc[:,-1]\ndf_umap['text'] = df[['filename','label']].apply(lambda x: f'{x[0]}<br>{x[1]}', axis=1)","ff5053f6":"data = []\nfor g in df_umap.genre.unique():\n    trace = go.Scatter3d(\n    x=df_umap[df_umap.genre==g].pc1.values,\n    y=df_umap[df_umap.genre==g].pc2.values,\n    z=df_umap[df_umap.genre==g].pc3.values,\n    mode='markers',\n    text=df_umap[df_umap.genre==g].text.values,\n    hoverinfo = 'text',\n    name=g,\n    marker=dict(\n            size=3,\n            color=color_scheme[g],                \n            opacity=0.9,\n        )\n    )\n    data.append(trace)\nfig = go.Figure(data=data)\n\n# tight layout\nfig.update_layout(title=f'UMAP (Supervised)', autosize=False,\n                      width=600, height=600,\n                      margin=dict(l=50, r=50, b=50, t=50),\n                      scene=dict(xaxis=dict(title='pc1'), yaxis=dict(title='pc2'), zaxis=dict(title='pc3'))\n                     )\nfig.show()","e53ef63c":"### t-SNE with 3 components","a557c628":"### Supervised UMAP","bc622887":"### Plot UMAP results","893c580b":"### Get t-SNE embeddings for selected clips\nExtract t-SNE embeddings for two components over multiple perplexity settings and epochs.","cd02a859":"## Dimensionality reduction using t-SNE and UMAP\n\n### Load features \n\nLoad data from ````features_3_sec.csv````. Keep only features associated with first 3sec (0th segment). Discard features from other clips from the same song.","58544d83":"### Plot t-SNE results\n","551fd360":"### UMAP with 3 components","d59cbb4b":"### What do songs in a cluster sound like?\n\n* Pick a random point from UMAP embeddings.\n* Find 5 nearest neighbors (by Euclidean distance) of that point.\n* Listen to corresponding audio files.","a4baf572":"### Get UMAP embeddings\nExtract UMAP embeddings for 2 components over multiple neighbor and min distance settings"}}