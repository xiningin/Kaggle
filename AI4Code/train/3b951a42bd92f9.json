{"cell_type":{"544499ad":"code","990e6d2e":"code","06f5d3da":"code","da6b5f12":"code","6d18c238":"code","806fe8b1":"code","e13fa96c":"code","ebf6f8b0":"code","7d24a4e1":"code","22bd558c":"code","9c29f574":"code","1eb9fc74":"code","de33557e":"code","41191436":"code","890693da":"code","8e74b35f":"code","92f2ddb3":"code","00dfa612":"code","69e4917f":"code","115f6dea":"code","ab500e2b":"code","38d9ba8c":"code","27aab9d1":"code","f55353f2":"code","0cbad287":"code","a15debbe":"code","0f8b3e1d":"code","f5a2f02d":"code","1fe95d66":"code","53c3321b":"code","c9be8bf9":"code","4fc7506d":"markdown","64d00acd":"markdown","ebfedfb3":"markdown","31e90287":"markdown","395f4bcf":"markdown","9b1f3c92":"markdown","dab5219e":"markdown","1f9fc55d":"markdown","6d16a9a6":"markdown","dd8704fe":"markdown","48d114ae":"markdown","d5623b2e":"markdown","1aad9be2":"markdown","7935edc7":"markdown","cbc2001a":"markdown","53eb9b6a":"markdown","540cd4b0":"markdown"},"source":{"544499ad":"!pip install python-dotenv\n!pip install slack_sdk","990e6d2e":"from pathlib import Path\nimport os\nfrom dotenv import load_dotenv\nfrom slack_sdk import WebClient\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom skimage import io\nfrom timeit import default_timer as time\nfrom torch import optim\nfrom torch.utils.data import Dataset, DataLoader, Sampler\nfrom sklearn.model_selection import train_test_split\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch import nn\nfrom sklearn.metrics import classification_report, precision_recall_fscore_support\nimport copy","06f5d3da":"env_path = Path('..\/input\/slack-env\/.env')\nannotations_path = Path('..\/input\/spacenet-7-change-detection-chips-and-masks\/annotations.csv')\nroot_dir = Path('..\/input\/spacenet-7-change-detection-chips-and-masks\/chip_dataset\/chip_dataset\/change_detection')\nmodel_path = Path('..\/input\/training-evaluation-of-spacenet-7-change-detection\/resnet50.pt')","da6b5f12":"load_dotenv(dotenv_path=env_path)\nclient = WebClient(token=os.environ['TOKEN'])","6d18c238":"def log_bot(msg,client=client,notify=False):\n    try:\n        channel = os.environ['CHANNEL']\n        if notify:\n            client.chat_postMessage(channel=channel,text='<@U019HM89QAY>')\n        client.chat_postMessage(channel=channel,text=msg)\n    except: \n        pass","806fe8b1":"df = pd.read_csv(annotations_path)","e13fa96c":"df.head()","ebf6f8b0":"len(df['im_name'].unique())","7d24a4e1":"train_im_names = df['im_name'].value_counts()[:40].index\ndev_im_names = df['im_name'].value_counts()[-20:-10].index\nvalid_im_names = df['im_name'].value_counts()[-10:].index","22bd558c":"def filter_by_im_name(df,im_names):\n    mask = df['im_name'].map(lambda x: x in im_names)\n    return df[mask].reset_index(drop=True)","9c29f574":"df_dict = {'train':filter_by_im_name(df,train_im_names),\n           'dev':filter_by_im_name(df,dev_im_names),\n           'valid':filter_by_im_name(df,valid_im_names)\n          }","1eb9fc74":"# Data augmentation and normalization for training\n# Just normalization for validation\nchip_dimension = 64\ndata_transforms = {\n    'train': A.Compose([\n        A.PadIfNeeded(min_height=chip_dimension,min_width=chip_dimension,value=0,p=1),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        ToTensorV2()\n        # A.Normalize([],[])\n    ]),\n    'dev': A.Compose([\n        A.PadIfNeeded(min_height=chip_dimension,min_width=chip_dimension,value=0,p=1),\n        ToTensorV2()\n        # A.Normalize([], [])\n    ]), \n    'valid': A.Compose([\n        A.PadIfNeeded(min_height=chip_dimension,min_width=chip_dimension,value=0,p=1),\n        ToTensorV2()\n        # A.Normalize([], [])\n    ]),\n}","de33557e":"class ChangeDetectionChipDataset(Dataset):\n    '''SpaceNet 7 Chip Change Detection Dataset'''\n    def __init__(self,df, root_dir, aug=None):\n        \"\"\"\n        Args:\n            df (pandas.core.frame.DataFrame): DataFrame containing file annotations\n            root_dir (Path): Parent directory containing all other directories.\n            aug (callable, optional): Optional augmentations to be applied on a sample.\n             \n        \"\"\"\n        \n        self.annotations = df\n        self.root_dir = root_dir\n        self.aug = aug\n                \n    def __len__(self):\n        return len(self.annotations)\n\n    def __getitem__(self,idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        # get chip path for corresponding index\n        chip_path = Path(self.root_dir\/self.annotations.loc[idx,'chip_path'])\n        # read chip into numpy array\n        chip = io.imread(chip_path)\n        # get target for corresponding chip\n        target = self.annotations.loc[idx,'target']\n\n        sample = {'image':chip,'category_id':target}\n\n        # apply transforms to sample\n        if self.aug is not None:\n            sample = self.aug(image=chip, category_id=target)\n        \n        sample['image'] = sample['image'].float()\n\n        return sample","41191436":"df.target.mean()","890693da":"class BalancingSampler(Sampler):\n    def __init__(self,dataset,change_pct=0.5):\n        \"\"\"\n        Args:\n            dataset (PyTorch Dataset): Instance of PyTorch Dataset Class\n            change_pct (float): Percentage of the batch containing chips with change in them; Val between 0 and 1\n        \"\"\"\n        \n        assert 0 <= change_pct <= 1,'change_pct must be a value between 0 and 1'\n        \n        self.dataset = dataset\n        self.change_pct = change_pct\n        self.len_ = len(dataset)\n        \n    def __len__(self):\n        return self.len_\n    \n    def __iter__(self):\n        # get indices for blank chips and change chips\n        change_chip_idxs = np.where(self.dataset.annotations['target'] == 1)[0]\n        blank_chip_idxs = np.where(self.dataset.annotations['target'] == 0)[0]\n        # randomly sample from the incides of each class\n        change_chip_idxs = np.random.choice(change_chip_idxs,int(self.len_ * self.change_pct), replace=True)\n        blank_chip_idxs = np.random.choice(blank_chip_idxs,int(self.len_ * (1 - self.change_pct))+1, replace=False)\n        # stack the sampled class indices and shuffle\n        all_idxs = np.hstack([change_chip_idxs,blank_chip_idxs])\n        np.random.shuffle(all_idxs)\n        all_idxs[:]\n        \n        return iter(all_idxs)","8e74b35f":"# setting device on GPU if available, else CPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\nprint()","92f2ddb3":"params = {\n    'batch_size': 512,\n    'learning_rate': 0.0003,\n}","00dfa612":"datasets = {x:ChangeDetectionChipDataset(df_dict[x],root_dir,aug = data_transforms[x]) for x in ['train','dev','valid']}","69e4917f":"sampler = BalancingSampler(datasets['train'],change_pct=0.5)","115f6dea":"samplers = {'train':sampler,'dev':None,'valid':None}","ab500e2b":"dataloaders = {x: DataLoader(dataset=datasets[x],batch_size=params['batch_size'],sampler=samplers[x],num_workers=4,pin_memory=True) for x in ['train','dev','valid']}","38d9ba8c":"dataset_sizes = {x: len(datasets[x]) for x in ['train', 'dev', 'valid']}","27aab9d1":"# setting device on GPU if available, else CPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\nprint()","f55353f2":"model_pretrained = torch.load(model_path, map_location=device)","0cbad287":"criterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer = optim.Adam(model_pretrained.parameters(), lr=params['learning_rate'])\n\n# Decay LR if the loss did not improve after 3 epochs\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, patience=1, verbose=True)","a15debbe":"def log_precision_recall_f1_score(epoch,epoch_loss,epoch_acc,running_preds,running_labels,phase,num_epochs):\n    precision,recall,f1_score,_ = precision_recall_fscore_support(running_labels,running_preds,average='binary')\n    report = classification_report(running_labels,running_preds,target_names=['no change','change'])\n    \n    if phase == 'train':\n        log_bot('TRAINING EPOCH SUMMARY',notify=True)\n    else:\n        log_bot('VALIDATION EPOCH SUMMARY',notify=True)\n        \n    log_bot('-'*100)\n    log_bot(f'\\nEPOCH {epoch}\/{num_epochs-1}\\n')\n    log_bot(f'Loss: {epoch_loss:.4f}\\nAccuracy: {epoch_acc:.4f}\\nF1-Score:{f1_score:.4f}\\nPrecision: {precision:.4f}\\nRecall: {recall:.4f}')\n    log_bot(f\"```{report}```\")\n    log_bot('-'*100)","0f8b3e1d":"def log_batch_statistics(batch_number,batch_labels,batch_preds,phase,loss,since,num_batches,period=500):\n    if batch_number % period == 0:\n        report = classification_report(batch_labels.data.to('cpu'),batch_preds.to('cpu'),target_names=['no change','change'])\n        time_elapsed = time() - since\n        \n        if phase == 'train':\n            log_bot('TRAINING BATCH')\n        else:\n            log_bot('VALIDATION BATCH')\n            \n        log_bot('-'*50)\n        log_bot(f'\\n{batch_number}\/{num_batches-1}:')\n        log_bot(f'Total Time Elapsed: {time_elapsed\/60:.2f} mins')\n        log_bot(f'Batch Loss: {loss.item():.4f}\\n')\n        log_bot(f\"```{report}```\")\n        log_bot('-'*50)","f5a2f02d":"def break_time_limit(start_time,time_limit=28080):\n    time_elapsed = time()-start_time\n    if time_elapsed > time_limit:\n        sys.exit()","1fe95d66":"def train_model(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes=dataset_sizes,num_epochs=25):\n    start_time = time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    best_f1_score = 0.0\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}\/{num_epochs-1}')\n        print('-' * 10)\n        log_bot(f'\\nEPOCH {epoch}\/{num_epochs-1}',notify=True)\n        log_bot('-' * 100)\n        \n        # Each epoch has a training and validation phase\n        for phase in ['dev', 'train']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n            running_preds = []\n            running_labels = []\n\n            # Iterate over data.\n            num_batches = len(dataloaders[phase])\n            try:\n                for i,batch in enumerate(dataloaders[phase]):\n                    # get the input and target values from dictionary\n                    inputs, labels = batch.values()\n                    # set the device\n                    inputs = inputs.to(device)\n                    labels = labels.to(device)\n                    # get the batch_size\n                    batch_size = len(labels)\n\n                    # zero the parameter gradients\n                    optimizer.zero_grad()\n\n                    # forward\n                    # track history if only in train\n                    with torch.set_grad_enabled(phase == 'train'):\n                        outputs = model(inputs)\n                        _, preds = torch.max(outputs, 1)\n                        loss = criterion(outputs, labels)\n\n                        # backward + optimize only if in training phase\n                        if phase == 'train':\n                            loss.backward()\n                            optimizer.step()       \n                    # statistics\n                    running_loss += loss.item() * inputs.size(0)\n                    running_corrects += torch.sum(preds == labels.data)\n\n                    running_preds.extend(preds)\n                    running_labels.extend(labels.data)\n\n                    # print internal epoch statistics every n number of  iterations\n                    log_batch_statistics(i,labels,preds,phase,loss=loss,num_batches=num_batches,since=start_time)\n\n                if phase == 'train':\n                    scheduler.step(running_loss)\n\n                epoch_loss = running_loss \/ dataset_sizes[phase]\n                epoch_acc = running_corrects \/ dataset_sizes[phase]\n\n                running_labels = torch.stack(running_labels).squeeze().to('cpu')\n                running_preds = torch.stack(running_preds).squeeze().to('cpu')\n\n                precision,recall,f1_score,_ = precision_recall_fscore_support(running_labels,running_preds,average='binary')\n                report = classification_report(running_labels,running_preds,target_names=['no change','change'])\n\n                # log statistics to slack bot\n                log_precision_recall_f1_score(epoch,epoch_loss,epoch_acc,running_preds,running_labels,phase,num_epochs)\n\n                # deep copy the model\n                if phase == 'dev' and f1_score > best_f1_score:\n                    best_f1_score = f1_score\n                    best_model_wts = copy.deepcopy(model.state_dict())\n            except:\n                log_bot(f'failed at batch {i}',notify=True)\n                pass\n            \n    time_elapsed = time() - start_time\n    print()\n    print(f'Training complete in {time_elapsed \/\/ 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best val Acc: {best_acc:4f}')\n    print(f'Best val F1-Score: {best_f1_score:4f}')\n\n    log_bot(f'Training complete in {time_elapsed \/\/ 60:.0f}m {time_elapsed % 60:.0f}s')\n    log_bot(f'Best val F1-Score: {best_f1_score:4f}')\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","53c3321b":"model_pretrained = train_model(model_pretrained,criterion,optimizer,scheduler, dataloaders, num_epochs = 3)","c9be8bf9":"torch.save(model_pretrained, 'resnet50.pt')\nlog_bot('Model Saved', notify=True)","4fc7506d":"## Training Loop","64d00acd":"## Evaluation Metrics","ebfedfb3":"## Creating PyTorch Dataset\nBelow we create a simple pytorch dataset class that allows us to access our data more easily.","31e90287":"## Define Paths","395f4bcf":"We will store our dataframes in a dictionary.","9b1f3c92":"# Training and Evaluation of PyTorch Change Detection Network\nIn the [previous notebook](https:\/\/www.kaggle.com\/amerii\/spacenet-7-change-detection-pytorch-starter) we went over creating and training a neural network on the stacked images of our chips dataset. The model is fed 2 satellite images taken in the same location but during different times.\nThe input shape into our neural network are stacked chips giving us an input dimension of 6x64x64. \n\nThe objective of the model is to determine whether a change has occured or not. Our dataset, contains labeled masks as well as a target column that indicates whether a change has occured between the 2 images.\n\nIn this notebook, we will be focusing on training our model for a longer period of time while still retaining the ability to monitor the progress of the model. We will achieve this by using slack's api, to send messages onto a custom channel.\n\nWe will send evaluation metrics, such as precision, recall, f1 score to the slack channel. This will also help us to make sure that our model is running correctly, so that we don't waste our gpu hours. For more details on how to create a very simple slack bot, check out the following [notebook](https:\/\/www.kaggle.com\/amerii\/simple-slack-bot-for-monitoring-model-metrics).","dab5219e":"In order to remedy this problem we will create a custom PyTorch Sampler that will allow us to sample the chips that have change in them more than once. We can also specify the percentage of change chips that we want relative to the blank chips. The defualt is 0.5.","1f9fc55d":"## Reading Annotations CSV File","6d16a9a6":"## Saving Model","dd8704fe":"## Creating Custom Sampler for DataLoader\nThe dataset for our satellite images is highly imbalanced. If we take a look below at the ratio of our target column we will find that most of our targets actually have no change in them.","48d114ae":"## Import Dependencies","d5623b2e":"## Setting up Slack Metric Monitoring Bot\nBelow we set up the bot that we will be using for sending updates to slack while our model is training. For more info on how to set this up, check out the following [notebook](https:\/\/www.kaggle.com\/amerii\/simple-slack-bot-for-monitoring-model-metrics).","1aad9be2":"## Install Required Libraries","7935edc7":"Below is a short helper function to filter the datasets by the desired indices.","cbc2001a":"## Transformations and Augmentations\n\nIn order to enhance our dataset we will be using the albumentations library to augment our datasets. \n\nThe PadIfNeeded function allows us to add padding to any chips that are not of the desired size. In our case, our dataset should consist of 64x64 chips, so our input dimension for the padding will be 64.\n\nWe also add a random horizantal and vertical flip as well with 50% percent chance of occuring. \n\nFinally we use the ToTensorV2 function to convert our arrays to torch.Tensor and divide by 255 if image or mask are uint8 type. ","53eb9b6a":"## Splitting our Dataset \nBelow we will split our datasets to training, development and validation sets.\n\nFirst we obtain the indices which we want to use to split our data by.\n\nThe reason for splitting our data this way, is because each of our image folder stands for a location in which the satellite image was captured. By having the same location in the same set, we ensure that we are avoiding data leakage.","540cd4b0":"## Model Settings"}}