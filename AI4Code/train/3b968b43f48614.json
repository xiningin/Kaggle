{"cell_type":{"28c0407f":"code","27c9bf68":"code","7ee84868":"code","c74c8481":"code","69348acb":"code","0729ea59":"code","747f846c":"code","f5fda2fa":"code","694987ee":"code","f8d859e8":"code","aac9eead":"code","db7f2e9c":"code","d9029a25":"code","e1be043a":"code","3f08fb70":"code","8b9a4bc9":"code","14432c40":"code","82e7347b":"code","00827f03":"code","cdcc75b4":"code","130aca78":"code","9f7dd5ad":"code","c3000085":"markdown","ea3d08bd":"markdown","48632268":"markdown","569117b6":"markdown","72df0a73":"markdown","ad66168b":"markdown","75b99c05":"markdown","4c10dc1e":"markdown","e98d0b8c":"markdown","307a4939":"markdown","76755156":"markdown","b72901da":"markdown"},"source":{"28c0407f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","27c9bf68":"Dataset = pd.read_csv(\"\/kaggle\/input\/scene-classification\/train-scene classification\/train.csv\")    # Dataframe","7ee84868":"# Converting Class number to strings\nDataset[\"label\"] = Dataset[\"label\"].astype(str)","c74c8481":"Dataset.head()","69348acb":"import matplotlib.pyplot as plt\nimport seaborn as sns","0729ea59":"# Displaying number of samples for each Disease\nfig, ax = plt.subplots(figsize = (10, 4))                                # Setting Figure Size\nsns.countplot(x ='label', data=Dataset)                                  # Creating Seaborn Count Plot\nplt.xlabel(\"Class Label\")                                                # X-Label of the plot\nplt.ylabel(\"Number of Samples\")                                          # Y-Label of the plot\nplt.show() ","747f846c":"from sklearn.model_selection import train_test_split","f5fda2fa":"Data_train, Data_test = train_test_split(Dataset, test_size=0.2)                   # Splitting in 80:20","694987ee":"from keras.preprocessing.image import ImageDataGenerator","f8d859e8":"datagen = ImageDataGenerator(rescale=1.\/255)                            # Normalizing pixels of images","aac9eead":"# Training Set Directory\ndir1='\/kaggle\/input\/scene-classification\/train-scene classification\/train\/'","db7f2e9c":"train_gen=datagen.flow_from_dataframe(dataframe = Data_train,           # Training Dataframe\n                                      directory=dir1,                   # Training set Directory\n                                      batch_size=20,                    # Size of Batch\n                                      class_mode=\"categorical\",         # Type of Labels\n                                      x_col=\"image_name\",               # Input Column\n                                      color_mode=\"rgb\",                 # Image Format\n                                      y_col=\"label\",                    # Target Column\n                                      target_size=(224,224))            # Image Size","d9029a25":"valid_gen=datagen.flow_from_dataframe(dataframe = Data_test,            # Training Dataframe\n                                      directory=dir1,                   # Training set Directory\n                                      batch_size=20,                    # Size of Batch\n                                      class_mode=\"categorical\",         # Type of Labels\n                                      x_col=\"image_name\",               # Input Column\n                                      color_mode=\"rgb\",                 # Image Format\n                                      y_col=\"label\",                    # Target Column\n                                      target_size=(224,224))            # Image Size","e1be043a":"import keras","3f08fb70":"ResNet_model = keras.applications.ResNet152V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))","8b9a4bc9":"from keras import Model \nfrom keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten,GlobalAveragePooling2D\nfrom keras.models import Sequential","14432c40":"for layer in ResNet_model.layers[:-15]:       # Freezing all layers other than last 15 Layers\n    layer.trainable = False\n\nx = ResNet_model.output\nx = GlobalAveragePooling2D()(x)\nx = Flatten()(x)\nx = Dense(units=512, activation='relu')(x)\nx = Dropout(0.3)(x)\nx = Dense(units=512, activation='relu')(x)\nx = Dropout(0.3)(x)\noutput  = Dense(units=6, activation='softmax')(x)\nmodel = Model(ResNet_model.input, output)","82e7347b":"# model Summary\nprint(model.summary())","00827f03":"loss = keras.losses.CategoricalCrossentropy()\noptimizer = keras.optimizers.Adam(learning_rate=0.001)\nmodel.compile(optimizer=optimizer, loss=loss, metrics= ['accuracy'])","cdcc75b4":"STEP_SIZE_TRAIN=train_gen.n\/\/train_gen.batch_size\nSTEP_SIZE_VALID=valid_gen.n\/\/valid_gen.batch_size\n\nprint(STEP_SIZE_TRAIN)\nprint(STEP_SIZE_VALID)","130aca78":"transfer_learning_history = model.fit_generator(generator=train_gen,\n                            steps_per_epoch=STEP_SIZE_TRAIN,\n                            validation_data=valid_gen,\n                            validation_steps=STEP_SIZE_VALID,\n                            epochs=3)","9f7dd5ad":"import matplotlib.pyplot as plt\n\nacc = transfer_learning_history.history['accuracy']\nval_acc = transfer_learning_history.history['val_accuracy']\n\nloss = transfer_learning_history.history['loss']\nval_loss = transfer_learning_history.history['val_loss']\n\nepochs_range = range(3)\n\nplt.figure(figsize=(20, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","c3000085":"Firstly, we will load the Dataset which have Image name and corresponding Labels","ea3d08bd":"## Splitting Data into Train\/Test","48632268":"## Creating Keras Image Data Flow","569117b6":"## Creating Training Data","72df0a73":"## Visualizing accuracy and loss","ad66168b":"### Compiling the Model","75b99c05":"# Since, we are using Pre-trained Moedl. The Model Convergers very fast.\n# This is the reason we are getting best results in only 2 epochs","4c10dc1e":"## Creating Validation Data","e98d0b8c":"The Data is almost balanced.","307a4939":"### Setting Loss function, Optimizer and Compling the model","76755156":"## Building Model","b72901da":"## Importing Resnet Model to apply Transfer Learning"}}