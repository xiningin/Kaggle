{"cell_type":{"dde073d3":"code","66b7d97a":"code","1bc129df":"code","33f04696":"code","9b497e39":"code","5fab410f":"code","fe5d5cf7":"code","37e262ca":"code","6f7becd2":"code","322cf8f9":"code","f25a6146":"code","f336375e":"code","bd96a995":"code","aa32f5cf":"code","ddaa2c65":"code","0fb15a25":"code","5afcb291":"code","507bd313":"code","975f3140":"code","d6e14123":"code","0f8ffd52":"code","b9159347":"code","89e258d7":"code","18d1fded":"code","9d07706d":"code","64c2e4d7":"code","ea84ace1":"code","7a6032f8":"code","d1b82d6d":"code","7253967e":"code","b95977ab":"code","00160085":"code","30aa4626":"code","866a926c":"code","132b3261":"code","ef5e140e":"code","61b7458f":"code","c7dc5aff":"code","18e4c7da":"code","8d68944f":"code","5a3a170c":"code","fbac1086":"code","48015c69":"code","35956e68":"code","6826ebc9":"code","338165ca":"code","3be791f0":"code","12244b66":"code","40b2f00e":"code","00143148":"code","2771367f":"code","86497b1a":"code","10fd245f":"code","2879d55a":"code","98c1267e":"code","c8a8be3d":"code","adbf4442":"code","5afbe67b":"code","2a9e05b3":"code","bd361819":"code","efba1341":"code","d2136af9":"code","0d1f947a":"code","fcd93a4d":"code","7a9a64a4":"code","8d17fabf":"code","3ed7ef5c":"code","6bb7d6cb":"code","8bca6aa0":"code","90fb160d":"code","dad58732":"code","e7f59f6e":"code","0bf688d9":"code","18cf33f0":"code","81ca59d8":"code","26c9c346":"code","e88be52c":"code","d2ab1d3c":"code","3ca7cbf1":"code","96651f50":"code","41b6d6c4":"code","dbe0a855":"code","5ddd38a9":"code","cc5f95f4":"code","b4a5245e":"code","7ba39fbc":"code","d677fc20":"code","d3afe8e5":"code","c3372cc4":"code","1e60a3d4":"code","113d608a":"code","48510b00":"code","dd024c6b":"code","e9111317":"markdown"},"source":{"dde073d3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","66b7d97a":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('ggplot')\n%matplotlib inline","1bc129df":"# \u6a5f\u68b0\u5b66\u7fd2\u95a2\u9023\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u7fa4\n\nfrom sklearn.model_selection import train_test_split # \u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5206\u5272\n# from sklearn.cross_validation import train_test_split # \u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5206\u5272\nfrom sklearn.metrics import confusion_matrix # \u6df7\u5408\u884c\u5217\n\nfrom sklearn.decomposition import PCA #\u4e3b\u6210\u5206\u5206\u6790\nfrom sklearn.linear_model import LogisticRegression # \u30ed\u30b8\u30b9\u30c6\u30a3\u30c3\u30af\u56de\u5e30\nfrom sklearn.neighbors import KNeighborsClassifier # K\u8fd1\u508d\u6cd5\nfrom sklearn.svm import SVC # \u30b5\u30dd\u30fc\u30c8\u30d9\u30af\u30bf\u30fc\u30de\u30b7\u30f3\nfrom sklearn.tree import DecisionTreeClassifier # \u6c7a\u5b9a\u6728\nfrom sklearn.ensemble import RandomForestClassifier # \u30e9\u30f3\u30c0\u30e0\u30d5\u30a9\u30ec\u30b9\u30c8\nfrom sklearn.ensemble import AdaBoostClassifier # AdaBoost\nfrom sklearn.naive_bayes import GaussianNB # \u30ca\u30a4\u30fc\u30d6\u30fb\u30d9\u30a4\u30ba\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA # \u7dda\u5f62\u5224\u5225\u5206\u6790\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA # \u4e8c\u6b21\u5224\u5225\u5206\u6790\nfrom lightgbm import LGBMClassifier # LightGBM","33f04696":"# train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv', index_col=0)\n# test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv', index_col=0)\n\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","9b497e39":"train.head()","5fab410f":"test.head()","fe5d5cf7":"# \u5f62\u72b6\u628a\u63e1\nprint(\"train_data_shape\",train.shape)\nprint(\"test_data_shape\",test.shape)","37e262ca":"test_PassengerId = test.PassengerId","6f7becd2":"test_PassengerId.shape","322cf8f9":"test_PassengerId.head(10)","f25a6146":"train.info()","f336375e":"test.info()","bd96a995":"train.describe().T","aa32f5cf":"test.describe().T","ddaa2c65":"# train data\n# df_train['Survived']=df_train['Survived'].astype('object')\ntrain['Pclass']=train['Pclass'].astype('object')\ntrain['SibSp']=train['SibSp'].astype('object')\ntrain['Parch']=train['Parch'].astype('object')\n# test data\ntest['Pclass']=test['Pclass'].astype('object')\ntest['SibSp']=test['SibSp'].astype('object')\ntest['Parch']=test['Parch'].astype('object')","0fb15a25":"train.info()","5afcb291":"test.info()","507bd313":"# \u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\nplt.figure(figsize=[7,7])\nplt.hist(train.Pclass, bins=3, color='r', label='train', alpha=0.5, density=True)\nplt.hist(test.Pclass, bins=3, color='b', label='test', alpha=0.5, density=True)\nplt.legend()\nplt.show()","975f3140":"sns.countplot(x='Survived',hue='Pclass',data=train)","d6e14123":"# Name\n# \u30ab\u30a6\u30f3\u30c8 \/ \u30e6\u30cb\u30fc\u30af\u6570\u78ba\u8a8d\ntrain.Name.value_counts(sort=False)","0f8ffd52":"# \u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\nplt.figure(figsize=[7,7])\nplt.hist(train.Sex, bins=3, color='r', label='train', alpha=0.5, density=True)\nplt.hist(test.Sex, bins=3, color='b', label='test', alpha=0.5, density=True)\nplt.legend()\nplt.show()","b9159347":"sns.countplot(x='Survived',hue='Sex',data=train)","89e258d7":"sns.distplot(train['Age'])","18d1fded":"# \u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\nplt.figure(figsize=[7,7])\nplt.hist(train.SibSp, bins=9, color='r', label='train', alpha=0.5, density=True)\nplt.hist(test.SibSp, bins=9, color='b', label='test', alpha=0.5, density=True)\nplt.legend()\nplt.show()","9d07706d":"sns.countplot(x='Survived',hue='SibSp',data=train)","64c2e4d7":"# \u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\nplt.figure(figsize=[7,7])\nplt.hist(train.Parch, bins=10, color='r', label='train', alpha=0.5, density=True)\nplt.hist(test.Parch, bins=10, color='b', label='test', alpha=0.5, density=True)\nplt.legend()\nplt.show()","ea84ace1":"sns.countplot(x='Survived',hue='Parch',data=train)","7a6032f8":"# \u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\n# Ticket\n# \u30ab\u30a6\u30f3\u30c8\ntrain.Ticket.value_counts(sort=False)","d1b82d6d":"# \u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\nplt.figure(figsize=[21,7])\nplt.hist(train.Fare, bins=30, color='r', label='train', alpha=0.5, density=True)\nplt.hist(test.Fare, bins=30, color='b', label='test', alpha=0.5, density=True)\nplt.legend()\nplt.show()","7253967e":"sns.distplot(train['Fare'])","b95977ab":"# \u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\n# Cabin\n# \u30ab\u30a6\u30f3\u30c8\ntrain.Cabin.value_counts(sort=True)","00160085":"# Embarked\n# \u30d2\u30b9\u30c8\u30b0\u30e9\u30e0\n# Embarked\n# \u30ab\u30a6\u30f3\u30c8\ntrain.Embarked.value_counts(sort=True)","30aa4626":"print(train.query('Embarked == \"S\"'))\nprint(train.query('Embarked == \"C\"'))\nprint(train.query('Embarked == \"Q\"'))","866a926c":"print(train.query('Embarked != \"S\" and Embarked != \"C\" and Embarked != \"Q\"'))","132b3261":"print(train.query('Fare >= 75.0 and Fare <= 85.0'))","ef5e140e":"print(train.query('Cabin == \"B28\"'))","61b7458f":"print(train.query('Ticket == \"113572\"'))","c7dc5aff":"# Embarked == \"NaN\" => Set \"S\" to Embarked\ntrain.at[62, 'Embarked'] = 'S'\ntrain.at[830, 'Embarked'] = 'S'","18e4c7da":"print(train.query('Ticket == \"113572\"'))","8d68944f":"train.info()","5a3a170c":"train = train.drop('PassengerId', axis=1)\ntrain = train.drop('Cabin', axis=1)","fbac1086":"train.info()","48015c69":"test = test.drop('PassengerId', axis=1)\ntest = test.drop('Cabin', axis=1)","35956e68":"test.info()","6826ebc9":"train = train.fillna({'Age': train.Age.mean(), 'Fare': train.Fare.mean()})\ntest = test.fillna({'Age': test.Age.mean(), 'Fare': test.Fare.mean()})","338165ca":"print(train.info())\nprint(test.info())","3be791f0":"train.head(50)","12244b66":"test.head(50)","40b2f00e":"train = train.drop('Name', axis=1)\ntrain = train.drop('Ticket', axis=1)\ntest = test.drop('Name', axis=1)\ntest = test.drop('Ticket', axis=1)","00143148":"train = pd.get_dummies(train)","2771367f":"test = pd.get_dummies(test)","86497b1a":"print(train.info())\nprint(test.info())","10fd245f":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler() \nscaled_values = scaler.fit_transform(train) \ntrain.loc[:,:] = scaled_values","2879d55a":"train.head(100)","98c1267e":"train.corr()","c8a8be3d":"color = sns.color_palette()","adbf4442":"plt.figure(figsize=(30,24))\nsns.heatmap(train.corr(),linecolor='white',linewidths=2,cmap='magma',square=True,annot=True)","5afbe67b":"train = train.drop('Sex_male', axis=1)\ntest = test.drop('Sex_male', axis=1)","2a9e05b3":"train = train.drop('SibSp_0', axis=1)\ntest = test.drop('SibSp_0', axis=1)\n\ntrain = train.drop('Parch_0', axis=1)\ntest = test.drop('Parch_0', axis=1)\n\ntrain = train.drop('Embarked_S', axis=1)\ntest = test.drop('Embarked_S', axis=1)","bd361819":"train = train.drop('Pclass_3', axis=1)\ntest = test.drop('Pclass_3', axis=1)","efba1341":"plt.figure(figsize=(30,24))\nsns.heatmap(train.corr(),linecolor='white',linewidths=2,cmap='magma',square=True,annot=True)","d2136af9":"print(train.head(1))\nprint(train.shape)","0d1f947a":"print(test.head(1))\nprint(test.shape)","fcd93a4d":"train['Parch_9'] = 0","7a9a64a4":"print(train.head(1))\nprint(train.shape)","8d17fabf":"# from sklearn.model_selection import train_test_split","3ed7ef5c":"X_train, X_test, y_train, y_test = train_test_split(train.drop('Survived',axis=1), \n                                                    train['Survived'], test_size=0.20, \n                                                    random_state=42)","6bb7d6cb":"X_train.shape","8bca6aa0":"y_train.shape","90fb160d":"X_test.shape","dad58732":"from sklearn.linear_model import LogisticRegression\nLR = LogisticRegression()","e7f59f6e":"# Fitting the model on our trained dataset.\nLR.fit(X_train,y_train)","0bf688d9":"print(\"Accuracy:\",round(LR.score(X_train, y_train)*100,2))","18cf33f0":"LR.coef_","81ca59d8":"pred = LR.predict(test)","26c9c346":"names = [\"Logistic Regression\", \"Nearest Neighbors\", \n         \"Linear SVM\", \"Polynomial SVM\", \"RBF SVM\", \"Sigmoid SVM\", \n         \"Decision Tree\",\"Random Forest\", \"AdaBoost\", \"Naive Bayes\", \n         \"Linear Discriminant Analysis\",\"Quadratic Discriminant Analysis\"]\n\nclassifiers = [\n    LogisticRegression(),\n    KNeighborsClassifier(),\n    SVC(kernel=\"linear\"),\n    SVC(kernel=\"poly\"),\n    SVC(kernel=\"rbf\"),\n    SVC(kernel=\"sigmoid\"),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GaussianNB(),\n    LDA(),\n    QDA()]","e88be52c":"result = []\nfor name, clf in zip(names, classifiers): # \u6307\u5b9a\u3057\u305f\u8907\u6570\u306e\u5206\u985e\u6a5f\u3092\u9806\u756a\u306b\u547c\u3073\u51fa\u3059\n    clf.fit(X_train, y_train) # \u5b66\u7fd2\n    score1 = clf.score(X_train, y_train) # \u6b63\u89e3\u7387\uff08train\uff09\u306e\u7b97\u51fa\n    score2 = clf.score(X_test, y_test) # \u6b63\u89e3\u7387\uff08test\uff09\u306e\u7b97\u51fa\n    result.append([score1, score2]) # \u7d50\u679c\u306e\u683c\u7d0d\n\n# test \u306e\u6b63\u89e3\u7387\u306e\u5927\u304d\u3044\u9806\u306b\u4e26\u3079\u308b\n# df_result = pd.DataFrame(result, columns=['train', 'test'], index=names).sort('test', ascending=False)\n# \u3082\u3057\u4e0a\u306e\u30b3\u30fc\u30c9\u304c\u52d5\u304b\u306a\u3044\u5834\u5408\u3001\u4ee5\u4e0b\u306e\u30b3\u30fc\u3092\u8a66\u3057\u3066\u307f\u3066\u304f\u3060\u3055\u3044\u3002\ndf_result = pd.DataFrame(result, columns=['train', 'test'], index=names).sort_values('test', ascending=False)","d2ab1d3c":"df_result # \u7d50\u679c\u306e\u78ba\u8a8d","3ca7cbf1":"# \u68d2\u30b0\u30e9\u30d5\u306e\u63cf\u753b\ndf_result.plot(kind='bar', alpha=0.5, grid=True)","96651f50":"KNC = KNeighborsClassifier()","41b6d6c4":"KNC.fit(X_train,y_train)","dbe0a855":"print(\"Accuracy:\",round(KNC.score(X_train, y_train)*100,2))","5ddd38a9":"pred = KNC.predict(test)","cc5f95f4":"LGBM = LGBMClassifier()","b4a5245e":"LGBM.fit(X_train,y_train)","7ba39fbc":"print(\"Accuracy:\",round(LGBM.score(X_train, y_train)*100,2))","d677fc20":"pred = LGBM.predict(test)","d3afe8e5":"print(pred)","c3372cc4":"columns = ['Survived']\noutput = pd.DataFrame(pred, columns=columns, dtype='int64')","1e60a3d4":"output","113d608a":"output = pd.concat([test_PassengerId, output], axis=1)","48510b00":"output","dd024c6b":"output.to_csv('submission_03.csv',index=False)","e9111317":"1st \u30e2\u30c7\u30eb LogisticRegression"}}