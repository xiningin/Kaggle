{"cell_type":{"074b8bdd":"code","58a23a47":"code","0be118a5":"code","928c5344":"code","af11f0ec":"code","35b4da00":"code","c9c7f24e":"code","61e62da1":"code","7ebe1f96":"code","64f75f27":"code","976e177f":"code","f3c6611b":"code","f400f001":"code","ededcda3":"code","f4536c42":"code","1ca70302":"code","4d1686d2":"code","33d489e5":"code","5b013da1":"code","b12455a7":"code","2710e42b":"code","36c61c0c":"code","39c9198b":"markdown","7ec05b58":"markdown","d3c5eb73":"markdown","a9f237b8":"markdown","c5049d9c":"markdown","e9c6fd8a":"markdown","2c59fc7a":"markdown","f45a65fc":"markdown","d97f1977":"markdown","7017897b":"markdown","cd053965":"markdown","d678e4cc":"markdown"},"source":{"074b8bdd":"!wget https:\/\/github.com\/PacktPublishing\/Machine-Learning-for-Cybersecurity-Cookbook\/raw\/master\/PE%20Samples%20Dataset\/Benign%20PE%20Samples%201.7z\n!wget https:\/\/github.com\/PacktPublishing\/Machine-Learning-for-Cybersecurity-Cookbook\/raw\/master\/PE%20Samples%20Dataset\/Benign%20PE%20Samples%202.7z\n!wget https:\/\/github.com\/PacktPublishing\/Machine-Learning-for-Cybersecurity-Cookbook\/raw\/master\/PE%20Samples%20Dataset\/Benign%20PE%20Samples%203.7z\n!wget https:\/\/github.com\/PacktPublishing\/Machine-Learning-for-Cybersecurity-Cookbook\/raw\/master\/PE%20Samples%20Dataset\/Benign%20PE%20Samples%204.7z\n!wget https:\/\/github.com\/PacktPublishing\/Machine-Learning-for-Cybersecurity-Cookbook\/raw\/master\/PE%20Samples%20Dataset\/Benign%20PE%20Samples%205.7z\n!wget https:\/\/github.com\/PacktPublishing\/Machine-Learning-for-Cybersecurity-Cookbook\/raw\/master\/PE%20Samples%20Dataset\/Benign%20PE%20Samples%206.7z\n!wget https:\/\/github.com\/PacktPublishing\/Machine-Learning-for-Cybersecurity-Cookbook\/raw\/master\/PE%20Samples%20Dataset\/Malicious%20PE%20Samples%201.7z\n!wget https:\/\/github.com\/PacktPublishing\/Machine-Learning-for-Cybersecurity-Cookbook\/raw\/master\/PE%20Samples%20Dataset\/Malicious%20PE%20Samples%202.7z","58a23a47":"!dir","0be118a5":"!apt install p7zip-full p7zip-rar -y ","928c5344":"!mkdir Benign_PE_samples\n!mkdir Malicious_PE_samples","af11f0ec":"%cd Benign_PE_samples\/","35b4da00":"for i in range(1,7):\n  !7z e -y ..\/Benign\\ PE\\ Samples\\ {i}.7z ","c9c7f24e":"%cd ..\/Malicious_PE_samples\/","61e62da1":"for i in range(1,3):\n  !7z e -y ..\/Malicious\\ PE\\ Samples\\ {i}.7z -pinfected","7ebe1f96":"%cd ..","64f75f27":"for i in range(1,3):\n    !rm -rf \"\/content\/Malicious_PE_samples\/Malicious PE Samples {i}\"\n\nfor i in range(1,7):\n     !rm -rf \"\/content\/Benign_PE_samples\/Benign PE Samples {i}\"","976e177f":"!dir","f3c6611b":"from os import listdir\nfrom nltk import ngrams\nimport hashlib\n\ndirectories = [\"Benign_PE_samples\", \"Malicious_PE_samples\"]\nN = 2","f400f001":"def read_file(file_path):\n    binary_file = open(file_path, \"rb\")\n    data = binary_file.read()\n    return data\n\ndef byte_sequence_to_Ngrams(byte_sequence, N):\n    return ngrams(byte_sequence, N)","ededcda3":"def hash_input(inp):\n    return int(hashlib.md5(inp).hexdigest(), 16)","f4536c42":"def make_ngram_hashable(Ngram):\n    return bytes(Ngram)","1ca70302":"def hash_file_Ngrams_into_dictionary(file_Ngrams,T):\n    for Ngram in file_Ngrams:\n        hashable_Ngram = make_ngram_hashable(Ngram)\n        hashed_and_reduced = hash_input(hashable_Ngram) % B\n        T[hashed_and_reduced] = T.get(hashed_and_reduced, 0) + 1","4d1686d2":"B = 65521\nT = {}","33d489e5":"for dataset_path in directories:\n    samples = [ f for f in listdir(dataset_path)]\n    for file in samples:\n        try:\n            file_path = dataset_path + \"\/\" + file\n            file_byte_sequence = read_file(file_path)\n            file_Ngrams = byte_sequence_to_Ngrams(file_byte_sequence,N)\n            hash_file_Ngrams_into_dictionary(file_Ngrams,T)\n        except Exception as e:\n            print(e)","5b013da1":"K1 = 1000\nimport heapq\n\nK1_most_common_Ngrams_Using_Hash_Grams = heapq.nlargest(K1, T)","b12455a7":"def featurize_sample(file,K1_most_common_Ngrams_Using_Hash_Grams):\n    K1 = len(K1_most_common_Ngrams_Using_Hash_Grams)\n    fv = K1 * [0]\n    file_byte_sequence = read_file(file_path)\n    file_Ngrams = byte_sequence_to_Ngrams(file_byte_sequence,N)\n    for Ngram in file_Ngrams:\n        hashable_Ngram = make_ngram_hashable(Ngram)\n        hashed_and_reduced = hash_input(hashable_Ngram) % B\n        if hashed_and_reduced in K1_most_common_Ngrams_Using_Hash_Grams:\n            index = K1_most_common_Ngrams_Using_Hash_Grams.index(hashed_and_reduced)\n            fv[index] += 1\n    return fv","2710e42b":"X = []\nfor dataset_path in directories:\n    try:\n        samples = [f for f in listdir(dataset_path)]\n        for file in samples:\n            file_path = dataset_path + \"\/\" + file\n            X.append(featurize_sample(file_path, K1_most_common_Ngrams_Using_Hash_Grams))\n    except Exception as e:\n        print(e)","36c61c0c":"X","39c9198b":"We iterate over our files and count theur hashed Ngrams","7ec05b58":"We specify the value for B the largest prime number smaller than 2^16 and create an empty dictionary","d3c5eb73":"Once the top hashed N grams have been selected these make up the feature set. In order to featurize the sample one iterates over its Ngrams , hashes adn","a9f237b8":"# PART 1 getting the data","c5049d9c":"# Part 2 working with Hash grams","e9c6fd8a":"We select the most frequent K1=100 using heapq","2c59fc7a":"finally we featurize the data set\n","f45a65fc":"The has_file_Ngrams_into_dictionary function takes an Ngram, hashes it and then increments the count in the dictionary of the hash. The reduction module B ensures that there can be no more than B keys in the dictionary","d97f1977":"We create a function to read in the bytes of a file and turn these into N-grams","7017897b":"lets begin by specifying the folders containing our samples, the parameter N and importing a library for hashing and a library to extract N-grams from a string","cd053965":"Now we want to hash the Ngrams","d678e4cc":"This notebook is adapted from chapter 3 of `https:\/\/github.com\/PacktPublishing\/Machine-Learning-for-Cybersecurity-Cookbook`"}}