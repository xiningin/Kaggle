{"cell_type":{"3629340b":"code","319fe7ef":"code","6120ba6e":"code","2a9371c6":"code","b815cc70":"code","a8feae41":"code","8954c190":"code","6db88b8f":"code","219b737a":"code","1c6d123b":"code","6b7ea394":"code","dc53f509":"code","415aabc8":"code","2934b2e7":"code","4239902c":"code","4b3930c3":"code","ecc1e497":"code","5ca4a89e":"markdown","b4f53934":"markdown","73dc21b3":"markdown","c3c237c8":"markdown","b53d0bd9":"markdown","4ae71c9a":"markdown","f6bdd964":"markdown","988bc2e1":"markdown","c41b5ffb":"markdown","43cd8ab5":"markdown","3a414b31":"markdown","4a7760e1":"markdown","bcb6b83a":"markdown","423a4977":"markdown","8a6de808":"markdown","3ae1fa20":"markdown","528dde18":"markdown","d75da133":"markdown","bbce9b2e":"markdown","3c584fbe":"markdown","aa600ef6":"markdown"},"source":{"3629340b":"# Importing necessary libraries \nimport os\nimport cv2\nfrom PIL import Image\nimport numpy as np \nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom collections import Counter\nfrom sklearn.metrics import confusion_matrix\n\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\n","319fe7ef":"# path of image folder\npath  = '\/kaggle\/input\/pollen-grain-image-classification\/'\n\nnames = [name.replace(' ', '_').split('_')[0] for name in os.listdir(path)]\nclasses = Counter(names)  #returns dictionary\n\nprint(\"Total number of images is {}\".format(len(names)))\n","6120ba6e":"plt.figure(figsize = (12,8))\nplt.title('Class Counts in Dataset')\nplt.bar(*zip(*classes.items()))\nplt.xticks(rotation='vertical')\nplt.show()","2a9371c6":"path_class  = {key:[] for key in classes.keys()}\n\nfor name in os.listdir(path):\n    key = name.replace(' ', '_').split('_')[0]\n    path_class[key].append(path + name)","b815cc70":"fig = plt.figure(figsize=(15, 15))\nfor i, key in enumerate(path_class.keys()):\n    img1 = Image.open(path_class[key][0]) \n    img2 = Image.open(path_class[key][1]) \n    img3 = Image.open(path_class[key][2]) \n\n    ax = fig.add_subplot(8, 9,  3*i + 1, xticks=[], yticks=[])\n    ax.imshow(img1)\n    ax.set_title(key)\n    \n    ax = fig.add_subplot(8, 9,  3*i + 2, xticks=[], yticks=[])\n    ax.imshow(img2)\n    ax.set_title(key)\n\n    ax = fig.add_subplot(8, 9,  3*i + 3, xticks=[], yticks=[])\n    ax.imshow(img3)\n    ax.set_title(key)\n    \n","a8feae41":"size = [cv2.imread(path + name).shape for name in os.listdir(path)]\nx, y, _ = zip(*size)\n\nfig = plt.figure(figsize=(12, 10))\n# scatter plot\nplt.scatter(x,y)\nplt.title(\"Image size scatterplot\")\n\n# add diagonal red line \nplt.plot([0,800],[0,800], 'r')","8954c190":"def process_img(img, size = (128,128)):\n    img = cv2.resize(img, size)  # resize image\n    img = img\/255                   # devide values to 255\n    return img   ","6db88b8f":"# Read all images and put in X variable, Y variable is class names\nX, Y = [], []\nfor name  in os.listdir(path):\n    img = cv2.imread(path + name)\n    X.append(process_img(img))\n    Y.append(name.replace(' ', '_').split('_')[0])\n\nX = np.array(X)","219b737a":"from sklearn.preprocessing import LabelEncoder\nfrom keras.utils import np_utils\n\nle = LabelEncoder()\nY_le = le.fit_transform(Y)\nY_cat = np_utils.to_categorical(Y_le, 23)","1c6d123b":"from sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y_cat, test_size=0.285, stratify=Y_le)\nprint(\"Images in each class in Test set: {}\".format(np.sum(Y_test, axis =0)))","6b7ea394":"input_shape =  X_train[0].shape\noutput_shape = 23\n\nmodel = Sequential()\nmodel.add(Conv2D(filters = 16, kernel_size = 3, input_shape = input_shape, activation= 'relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(filters = 32, kernel_size = 2, activation= 'relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(filters = 64, kernel_size = 2, activation= 'relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Conv2D(filters = 128, kernel_size = 2, activation= 'relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(500, activation = 'relu'))\n# model.add(Dropout(0.2))\nmodel.add(Dense(150, activation = 'relu'))\n# model.add(Dropout(0.2))\nmodel.add(Dense(output_shape, activation = 'softmax'))\nmodel.summary()","dc53f509":"model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\nprint('Model is Compiled!')","415aabc8":"datagener = ImageDataGenerator(\n                rotation_range= 20,\n                width_shift_range = 0.2,\n                height_shift_range = 0.2,\n                horizontal_flip = True,\n                vertical_flip = True,)\n# fit data generator\ndatagener.fit(X_train)","2934b2e7":"batch_size = 4\nepochs = 500\n\nmodel_path = 'cnn.hdf5'\ncallbecks = [EarlyStopping(monitor ='val_loss', patience = 20), \n             ModelCheckpoint(filepath = model_path, save_best_only = True)]\n\n\nhistory = model.fit(\n        datagener.flow(X_train, Y_train, batch_size=batch_size), \n        batch_size = batch_size, \n        steps_per_epoch = len(X_train) \/\/ batch_size,\n        epochs = epochs,\n        validation_data = (X_train, Y_train),\n        callbacks = callbecks,\n        verbose = 1)\n\n\n","4239902c":"model.load_weights(model_path)\nscore = model.evaluate(X_test, Y_test, verbose=0)\nprint('Test set accuracy: {}'.format(score[1]))","4b3930c3":"def plot_confusion_matrix(model, x, y, plot_title = ''):\n    y_pred = model.predict(x)                            # get predictions on x using model\n    predicted_categories = tf.argmax(y_pred, axis=1)     # get index of predicted category\n    true_categories = tf.argmax(y, axis=1)               # get index of true category\n    # create confusion matrix using sklearn\n    cm = confusion_matrix(true_categories, predicted_categories)\n    # create DataFrame from the confusion matrix. We retrieve labels from LabelEncoder.\n    df_cm = pd.DataFrame(cm, index = le.classes_ ,  columns = le.classes_)\n    # divide each row to its sum in the DataFrame to get normalized output\n    df_cm = df_cm.div(df_cm.sum(axis=1), axis=0)\n    \n    plt.figure(figsize = (15,12))\n    plt.title(plot_title)\n    sns.heatmap(df_cm, annot=True)\n    \nplot_confusion_matrix(model, X_train, Y_train, \"Train set\")\nplot_confusion_matrix(model, X_test,  Y_test,  \"Test set\")","ecc1e497":"plt.figure(figsize = (15,12))     \n   \nplt.subplot(211)  \nplt.title('Model Accuracy')  \nplt.plot(history.history['accuracy'])  \nplt.plot(history.history['val_accuracy'])  \nplt.ylabel('Accuracy')  \nplt.xlabel('Epoch')  \nplt.legend(['Generated Data', 'Original Train Data'], loc='best')  \n      \nplt.subplot(212)  \nplt.plot(history.history['loss'])  \nplt.plot(history.history['val_loss'])  \nplt.title('Model Loss')  \nplt.ylabel('Categorical Crossentropy')  \nplt.xlabel('Epoch')  \nplt.legend(['Generated Data', 'Original Train Data'], loc='best')  \nplt.show()","5ca4a89e":"For the training step using `EarlyStopping` makes sure the model will stop training when results are not improving. `ModelCheckpoint` helps to save the best model. I feed DataGenerator to the model, On the one hand, it augments our dataset and also it helps avoid overfitting. For Early stopping, I used the original training set. Model accuracy on train and validation sets are not the same as model train accuracy is calculated on the augmented Training set (by `ImageDataGenerator`) and accuracy on the validation set is calculated on the unchanged train set. Because of it, we can use Train set as a criterion for early stoppings.","b4f53934":"Lastly, I've plotted model accuracy and Categorical Crossentropy loss for each epoch. As it turns out, `ImageDataGenerator` prevents the model from overfitting. It is visible that the model has better accuracy and less loss on Original Train Data than on Generated Data.","73dc21b3":"Some image names use underscore after class names and some use whitespace. To get all class names and their counts, lets make a list of class names from all images, later counted unique values in the list. ","c3c237c8":"For the preprocessing step it is necessary to resize and rescale images. For this task, I resize images to 128x128 pixels, as most of the images are almost square-shaped.","b53d0bd9":"Plot confusion matrix for training and test set. We see that almost all classes are learned correctly.","4ae71c9a":"Plotting three image from each class helps understand how does pollen images differ from each other. As expected, there are different shapes, consistence, and color. The deep learning models should be able to achieve high accuracy. ","f6bdd964":"The target variable is categorical and we need to make one hot encoding to be able to feed Keras model. The `LabelEncoder` changes categorical values to numerical and `to_categorical` create 23 columns and write 1 in the corresponding class, 0-s in the others.  ","988bc2e1":"To save training time turn on GPU before running the notebook!","c41b5ffb":"Create a dictionary, where keys are class names and values are full path to the images corresponding to each class.","43cd8ab5":"Load weights of best model and calculate accuracy on the test set","3a414b31":"For the data exploration part, I will describe the parameters of the dataset. Such are class names, image counts for each class, shape of the images. Also, visualize several example from each class. ","4a7760e1":"## Preprocessing","bcb6b83a":"Split data to train and test. Test set contains exactly 10 images for all classes except Anadenanthera (6 images) ","423a4977":"# Training and Visualisation","8a6de808":"Create a Data generator where specifying rotation range, width and height shift range, and set flipping to True.","3ae1fa20":"All images have different shapes. Image length can vary from 80 pixels to 800 pixels. A scatterplot of image shapes shows that most images are almost square. Redline is a diagonal line and represents where square images will be on the plot. ","528dde18":"\n# Data Exploration","d75da133":"For the training part we construct model from scratch using keras. I will use data augmentation because the train data does not have lot of images. Using `ImageDataGenerator` from `keras.preprocessing.image` also helps avoid overfeeting on the training set.","bbce9b2e":"Plot class counts using barplot. Every class has 35 images except *Anadenanthera*, which has only 20 images.","3c584fbe":"At first, we need to count the number of Pollen Grain classes. I use `Counter` from the `collections` library.  \nImages are placed in one folder and names determine the class of the image. For example, the image `\"anadenanthera_16.jpg\"` is pollen from Anadenanthera. ","aa600ef6":"Thank you for Reading my notebook! \nIf you liked it, please upvote. "}}