{"cell_type":{"71bca90f":"code","162b805c":"code","5ced6a8c":"code","7289d8a7":"code","13e81fbc":"code","dad80963":"code","eff646c1":"code","06ce4afc":"code","6d9a3244":"code","57f839fd":"code","a9a1a334":"code","8ee9ffad":"code","eac7bcef":"code","f7bb5fec":"markdown","8fd94c4d":"markdown","4090675a":"markdown","bbb6bfb2":"markdown","7abaea7a":"markdown","2969497f":"markdown","cb21a84d":"markdown","4d8b089d":"markdown","1ea12b53":"markdown","591e4d3f":"markdown","7644fab4":"markdown","f2ee4cd3":"markdown","603ff805":"markdown","d45e7941":"markdown","f6765353":"markdown","c401fd24":"markdown","cd81c1f2":"markdown","67f0860d":"markdown","8b07db81":"markdown","a4651753":"markdown"},"source":{"71bca90f":"# Programming\nimport pandas as pd\nimport numpy as np\nimport warnings\nwarnings.simplefilter('ignore')\n\n# Modelling\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\n# Visualizations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(rc={'figure.figsize': (20, 5)})","162b805c":"train = pd.read_csv('..\/input\/walmart-sales-prediction\/train.csv', parse_dates=['Date'])","5ced6a8c":"# Converting Date from first day of week to Year-Week format\ntrain['Date'] =  train.Date.dt.strftime('%Y-%U')\ntrain = train.set_index(['Date'])[['Weekly_Sales']]\nprint('\\n TRAIN')\nprint(train.shape)\nprint(train.head())\n\n# Aggregating at Walmart level\nprint('\\n TRAIN GROUPED')\nwalmart_weekly_sales = train.groupby(by=train.index).sum()\nprint(walmart_weekly_sales.shape)\nprint(walmart_weekly_sales.head())","7289d8a7":"sns.lineplot(x=walmart_weekly_sales.index, y=walmart_weekly_sales.Weekly_Sales.fillna(np.inf), color='dodgerblue')\nplt.xticks(rotation=90)\nplt.ticklabel_format(style='plain', axis='y')\nplt.show()\nplt.close()","13e81fbc":"# Opening an empty DF\ntrend_seasonality = walmart_weekly_sales.copy()\n\n# Decomposing the series into Trend and Seasonality\nseas_decomp = seasonal_decompose(walmart_weekly_sales.Weekly_Sales, period=52, model='additive', extrapolate_trend='freq')\ntrend_seasonality['Weekly_Sales_Trend'] = seas_decomp.trend\ntrend_seasonality['Weekly_Sales_Seasonal'] = seas_decomp.seasonal\n\n# Plot\n    # Trend\nsns.lineplot(x=trend_seasonality.index, y=trend_seasonality.Weekly_Sales_Trend, color='dodgerblue', label='TREND')\n    # Seasonality\nsns.lineplot(x=trend_seasonality.index, y=trend_seasonality.Weekly_Sales_Seasonal, color='darkorange', label='SEASONALITY')  \n    # Plot formatting\nplt.xticks(rotation=90)\nplt.ticklabel_format(style='plain', axis='y')\nplt.show()\nplt.close()","dad80963":"# Split percentage and data point\nsplit_percentage = 0.75\nsplit = int(len(walmart_weekly_sales)*split_percentage)\n\n# DF split\nwalmart_train = walmart_weekly_sales[:split]\nwalmart_test = walmart_weekly_sales[split:]\n\n# Series Split\ntrain_data = walmart_train.Weekly_Sales.values\ntest_data = walmart_test.Weekly_Sales.values","eff646c1":"# Opening hyperparamter recording list\norder_aic_bic = []\nmodel_number = 1\n\n# Executing exhaustive search\nfor p in range(10):\n    for d in range(1):\n        for q in range(10):\n            for P in range(10):\n                for D in range(1):\n                    for Q in range(10):\n                        total_models = 10*1*10*10*1*10\n                        try:\n                            model = SARIMAX(train_data, order=(p,d,q), seasonal_order=(P,D,Q,52))\n                            results = model.fit(disp=False)\n                            order_aic_bic.append((p, d, q, P, D, Q, 52, results.aic, results.bic))\n                            print(f'{model_number} \/ {total_models}')\n                            model_number = model_number + 1\n                        except:\n                            print(f'{model_number} \/ {total_models}')\n                            model_number = model_number + 1\n                            continue\n\n# Creating a DF with the results\norder_df = pd.DataFrame(order_aic_bic, columns=['AR(p)', 'Diff(d)', 'MA(q)', 'SAR(P)', 'SDiff(D)', 'SMA(Q)', 'Seas(S)', 'AIC', 'BIC'])\nsorted_order_df = order_df.sort_values('AIC')\nprint(sorted_order_df.head())","06ce4afc":"# Creating the model\nsarima = SARIMAX(train_data, order=(0,1,1), seasonal_order=(1,1,0,52))\n\n# Fitting th model\nsarima_fit = sarima.fit()\n\n# Summary Statistics of the model\nsarima_summary = sarima_fit.summary()\nprint(sarima_summary)","6d9a3244":"# Model predictions on test set\n    # Prediction\npredictions = sarima_fit.get_forecast(len(test_data))\n    # Mean and prediction interval data\npred_values = predictions.predicted_mean\npred_intervals = predictions.conf_int(alpha=0.05) # 95% Confidence\npred_int_low = pd.Series(pred_intervals[:,0], index=walmart_test.index)\npred_int_high = pd.Series(pred_intervals[:,1], index=walmart_test.index)\n\n# Plot 1: Full data\n    # Training data\nsns.lineplot(x=walmart_train.index, y=train_data, color='grey', label='TRAINING')\n    # Actuals data\nsns.lineplot(x=walmart_test.index, y=test_data, color='dodgerblue', label='ACTUALS')\n    # Prediction data\nsns.lineplot(x=walmart_test.index, y=pred_values, color='darkorange', label='PREDICTION')\nplt.fill_between(pred_int_low.index, pred_int_low, pred_int_high, color='darkgrey', alpha=0.25)\n    # Plot formatting\nplt.title('TRAINING + TEST DATA\\nPrediction Confidence Interval = 95%')\nplt.xticks(rotation=90)\nplt.ticklabel_format(style='plain', axis='y')\nplt.show()\nplt.close()\n\n# Plot 2: Prediction Zoom-In\n    # Actuals data\nsns.lineplot(x=walmart_test.index, y=test_data, color='dodgerblue', label='ACTUALS')\n    # Prediction Data\nsns.lineplot(x=walmart_test.index, y=pred_values, color='darkorange', label='PREDICTION')\nplt.fill_between(pred_int_low.index, pred_int_low, pred_int_high, color='darkgrey', alpha=0.25)\n    # Plot formatting\nplt.title('TEST DATA ZOOM-IN\\nPrediction Confidence Interval = 95%')\nplt.xticks(rotation=90)\nplt.ticklabel_format(style='plain', axis='y')\nplt.show()\nplt.close()","57f839fd":"# Model performance analysis\n    # Error values\nerror = pred_values - test_data\nerror_perc = (pred_values- test_data) \/ test_data\n    # Performance metrics\nmae = mean_absolute_error(test_data, pred_values)\nmse = mean_squared_error(test_data, pred_values)\nrmse = np.sqrt(mse)\nmpe = np.mean(error_perc) * 100\nmape = (np.mean(abs(error_perc))*100)\nprint('SUMMARY STATISTICS')\nprint('Percentage Metrics')\nprint(f'MAPE: {mape.round(2)}%')\nprint(f'MPE: {mpe.round(2)}%\\n')\nprint('Sales Metrics')\nprint(f'MAE: {int(mae)}')\nprint(f'MSE: {int(mse)}')\nprint(f'RMSE: {int(rmse)}\\n')\n\n# Plot 1: Error Values\nsns.barplot(x=walmart_test.index, y=error, color='dodgerblue')\nplt.xticks(rotation=90)\nplt.ticklabel_format(style='plain', axis='y')\nplt.title('PREDICTION ERRORS')\nplt.show()\nplt.close()\n\n# Plot 2: Error Distribution\n\nsns.kdeplot(x=error, color='dodgerblue', fill=True)\nplt.title('ERROR DISTRIBUTION')\nplt.show()\nplt.close()\n\n# Plot 3: Error Correlogram","a9a1a334":"forecast = pd.read_csv('..\/input\/walmart-sales-prediction\/test.csv', parse_dates=['Date'])\nforecast['Date'] =  forecast.Date.dt.strftime('%Y-%U')\nforecast = forecast.set_index(['Date'])[['Store']]\nforecast = forecast.groupby(by=forecast.index).sum()\nprint(forecast.shape)\nprint(forecast.head())","8ee9ffad":"# Model predictions on forecast set\n    # Forecast\nw39_forecast = sarima_fit.get_forecast(len(test_data)+len(forecast))\n    # Mean and prediction interval data\nw39_fore_values = w39_forecast.predicted_mean[len(test_data):]\nw39_fore_intervals = w39_forecast.conf_int(alpha=0.05)[len(test_data):] # 95% Confidence\nfore_int_low = pd.Series(w39_fore_intervals[:,0], index=forecast.index)\nfore_int_high = pd.Series(w39_fore_intervals[:,1], index=forecast.index)","eac7bcef":"# Plot 1: Full data\n    # Training data\nsns.lineplot(x=walmart_train.index, y=train_data, color='grey', label='TRAINING')\n    # Actuals data\nsns.lineplot(x=walmart_test.index, y=test_data, color='dodgerblue', label='ACTUALS')\n    # Prediction data\nsns.lineplot(x=walmart_test.index, y=pred_values, color='darkorange', label='PREDICTION')\nplt.fill_between(pred_int_low.index, pred_int_low, pred_int_high, color='darkgrey', alpha=0.25)\n    # Forecast data\nsns.lineplot(x=forecast.index, y=w39_fore_values, color='darkorange', linestyle='--', label='FORECAST')\nplt.fill_between(fore_int_low.index, fore_int_low, fore_int_high, color='darkgrey', alpha=0.25)\n    # Plot formatting\nplt.xticks(rotation=90)\nplt.ticklabel_format(style='plain', axis='y')\nplt.show()\nplt.close()\n\n# Plot 2: Forecast Zoom-In\n    # Forecast data    \nsns.lineplot(x=forecast.index, y=w39_fore_values, color='darkorange', linestyle='--', label='FORECAST')\nplt.fill_between(fore_int_low.index, fore_int_low, fore_int_high, color='darkgrey', alpha=0.25)\n    # Plot formatting\nplt.xticks(rotation=90)\nplt.ticklabel_format(style='plain', axis='y')\nplt.show()\nplt.close()","f7bb5fec":"From the intial look into the raw data and the trend+seasonality decomposition we gather that Walmart sales present a **slight upwards trend** with a **strong yearly seasonal cycle** that presents two major peaks (weeks 46-47 and weeks 51-52) and a pit on weeks 04-05.","8fd94c4d":"<a id='4.2'><\/a>\n#### *Hyperparameter Tuning*","4090675a":"<a id='5'><\/a>\n## Conclusions","bbb6bfb2":"<a id='1'><\/a>\n## Introduction","7abaea7a":"<a id='4'><\/a>\n## Model Implementation","2969497f":"After splitting the data into test-train sets to be able to validate the model and executing a search for the optimal model hyperparamters we:\n1. Found that **both models (trend and seasonal) are non-stationary** (d and D orders =! 0). This non-stationary its what causes the prediction confidence interval to grow over time, as the model is forced to make predictions over predicted values instead of actuals.\n2. Obtained a model that predicts values with a **mean absolute percentage error (MAPE) of 2.5%** and **effectively reproduces the expected effect of the seasonal periods**.\n3. Model error values and error distribution suggests that **the model tends to overestimate (predictions > actuals)**. ","cb21a84d":"<a id='3'><\/a>\n## Feature Engineering","4d8b089d":"<a id='2.1'><\/a>\n#### *Full Data*","1ea12b53":"## Table of Contents\n* [Introduction](#1)\n    - [Data Sources | Task Definition | Planned Approach](#1.1)\n    - [Library Imports](#1.2)\n    - [Data Imports](#1.3)\n* [Exploratory Data Analysis](#2)\n    - [Full Data](#2.1)\n    - [Trend and Seasonality](#2.2)\n* [Pre-Processing | Feature Engineering](#3)\n    - [Aggregating at Walmart level](#3.1)\n    - [Handling Missing Values](#3.2)\n* [Model Implementation](#4)\n    - [Test-Train Split](#4.1)\n    - [Hyperparmater Tuning](#4.2)\n    - [Optimal Model](#4.3)\n    - [Summary Statistics](#4.4)\n    - [Forecasting](#4.5)\n* [Conclusions](#5)","591e4d3f":"<a id='4.3'><\/a>\n#### *Optimal Model*","7644fab4":"<a id='1.2'><\/a>\n#### *Library Imports*","f2ee4cd3":"<a id='1.3'><\/a>\n#### *Data Imports*","603ff805":"<a id='1.1'><\/a>\n#### *Data Source & Contents*\nThis datasets contain data about the historical weekly sales of Walmart stores\n\n#### *Tasks*\n1. Aggregate the data into an overall Walmart dataset\n2. **Create a model based on historical sales* and provide a forecast for the requested dates (next 39 weeks)\n\n#### *Approach*\n1. Fill any missing gaps on the source data\n2. Feature Engineering: Aggregate the store and department data into an overall Walmart data\n3. Hyperparameter tuning through a grid search\n4. Validate results and forecast the following 39 week period","d45e7941":"<a id='4.5'><\/a>\n#### *Forecasting*","f6765353":"<a id='4.4'><\/a>\n#### *Summary Statistics*","c401fd24":"<a id='2'><\/a>\n## Exploratory Data Analysis","cd81c1f2":"After exploring the data and creating a seasonal model to predict the requeted following 39 weeks we produced:\n1. A model that effectively reproduces the expected behaviour based on the provided historical data (seasonal peaks on weeks 46-47 and 51-52 with a pit on weeks 04-05)\n2. A model that predicts values within a +-2.5% percent of the real historical values (with higher chance of overestimating than underestimating)","67f0860d":"<a id='4.1'><\/a>\n#### *Test-Train Split*","8b07db81":"<a id='2.2'><\/a>\n#### *Trend and Seasonality*","a4651753":"<a id='2.3'><\/a>\n#### *Aggregating at Walmart level*"}}