{"cell_type":{"447c4b98":"code","3588d0f5":"code","aa69cca2":"code","f1672ea9":"code","e53ef5d6":"code","fb03a53e":"code","8d3935dc":"code","9702cb72":"code","492e14ce":"code","205b8e00":"code","b8941d7c":"code","d3fa27ea":"code","b975795e":"code","69bf6507":"code","a157ab5b":"code","798197d9":"code","f9c43461":"code","44dcb46f":"code","7e7fb5e3":"code","e6794edd":"code","eb881c08":"code","8d9e3fed":"code","77651d7d":"code","2fee83f1":"code","7a5090bd":"code","7628371a":"code","bf6476a2":"code","375acbf7":"code","0377d28f":"code","7a83b15b":"code","aad65111":"code","16569a14":"code","d5786a68":"code","9880282f":"code","8eb23dcb":"code","605baa7b":"code","65e3154c":"code","a82e1768":"code","f41ed68e":"code","a8ebaaf0":"code","aa7ffe00":"code","74f11a54":"code","9ecf7017":"code","6d88522d":"code","3637bfd0":"code","51c10500":"code","9675aee5":"code","84170786":"code","b24d8e8c":"code","37ea438a":"code","8765060e":"code","1dc5b9c5":"code","adbb8908":"code","a45ca61c":"code","16536bcb":"code","c830fe8f":"code","6203fb5a":"markdown","e51f677d":"markdown","338106fb":"markdown","ff257d1a":"markdown","5fc23eb2":"markdown","58bf5326":"markdown","5ecccce6":"markdown","92db4590":"markdown","534e238a":"markdown","ab1758b0":"markdown","2c85a75b":"markdown","53e2663d":"markdown","b1afd5a9":"markdown","3a1e6216":"markdown","38b964f0":"markdown","dff6fc8f":"markdown","9cd85421":"markdown","81cab799":"markdown","4ce3f568":"markdown","2a3aac8e":"markdown","4b89bfe4":"markdown"},"source":{"447c4b98":"import numpy as np\nimport pandas as pd \nimport seaborn as sns \nimport matplotlib.pyplot as plt\nimport missingno as msno\nimport gc\nfrom sklearn.model_selection import cross_val_score,GridSearchCV,train_test_split\nfrom sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier\nfrom sklearn.metrics import roc_curve,roc_auc_score,classification_report,mean_squared_error,accuracy_score\nfrom sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier,BaggingClassifier,VotingClassifier,AdaBoostClassifier\nimport lightgbm as lgb\nfrom sklearn.metrics import precision_recall_curve,roc_auc_score,classification_report,roc_curve\nfrom tqdm import tqdm","3588d0f5":"from subprocess import check_output\n\ntrain = pd.read_csv('..\/input\/wsdm-kkbox\/train.csv')\ntest = pd.read_csv('..\/input\/wsdm-kkbox\/test.csv')\nsongs = pd.read_csv('..\/input\/wsdm-kkbox\/songs.csv')\nmembers = pd.read_csv('..\/input\/wsdm-kkbox\/members.csv')\n#sample = pd.read_csv('..\/input\/wsdm-kkbox\/sample_submission.csv')","aa69cca2":"train.head()","f1672ea9":"test.head()","e53ef5d6":"songs.head()","fb03a53e":"members.head()","8d3935dc":"members.shape\ntrain.info()\nprint(\"\\n\")\nsongs.info()\nprint(\"\\n\")\nmembers.info()","9702cb72":"plt.figure(figsize=(20,15))\nsns.set(font_scale=2)\nsns.countplot(x='source_type',hue='source_type',data=train)\nsns.set(style=\"darkgrid\")\nplt.xlabel('source types',fontsize=30)\nplt.ylabel('count',fontsize=30)\nplt.xticks(rotation='45')\nplt.title('Count plot source types for listening music',fontsize=30)\nplt.tight_layout()","492e14ce":"plt.figure(figsize=(20,15))\nsns.set(font_scale=2)\nsns.countplot(y='source_screen_name',data=train,facecolor=(0,0,0,0),linewidth=5,edgecolor=sns.color_palette('dark',3))\nsns.set(style=\"darkgrid\")\nplt.xlabel('source types',fontsize=30)\nplt.ylabel('count',fontsize=30)\nplt.xticks(rotation='45')\nplt.title('Count plot for which  screen using ',fontsize=30)\nplt.tight_layout()","205b8e00":"plt.figure(figsize=(20,15))\nsns.set(font_scale=2)\nsns.countplot(x='source_system_tab',hue='source_system_tab',data=train)\nsns.set(style=\"darkgrid\")\nplt.xlabel('source types',fontsize=30)\nplt.ylabel('count',fontsize=30)\nplt.xticks(rotation='45')\nplt.title('Count plot for system tab there are using',fontsize=30)\nplt.tight_layout()","b8941d7c":"import matplotlib as mpl\n\nmpl.rcParams['font.size']=40.0\nlabels=['Male','Female']\nplt.figure(figsize = (10,10))\nsizes = pd.value_counts(members.gender)\n\npatches, texts, autotexts = plt.pie(sizes, labels=labels, autopct='%.0f%%',shadow=True, radius=0.6, startangle=90)\n\nfor t in texts:\n    t.set_size('smaller')\nplt.legend()\nplt.show()","d3fa27ea":"import matplotlib.pyplot as plt\nmpl.rcParams['font.size'] = 40.0\nplt.figure(figsize = (20, 20)) \n\ngroup_names=['explore','my library','search','discover','radio','listen with','notification','settings']\ngroup_size=pd.value_counts(train.source_system_tab)\nprint(group_size)\nsubgroup_names=['Male','Female']\nsubgroup_size=pd.value_counts(members.gender)\n\n# Create colors\na, b, c,d,e,f,g,h=[plt.cm.autumn, plt.cm.GnBu, plt.cm.YlGn,plt.cm.Purples,plt.cm.cool,plt.cm.RdPu,plt.cm.BuPu,plt.cm.bone]\n\nfig, ax = plt.subplots()\nax.axis('equal')\nmypie, texts = ax.pie(group_size,radius=2, labels= group_names,colors = [a(0.6), b(0.6), c(0.6),d(0.6), e(0.6), f(0.6),g(0.6)])\nplt.setp(mypie, width=0.3, edgecolor='white')\n\nplt.legend() \n# show it\nplt.show()","b975795e":"mpl.rcParams['font.size'] = 40.0\nplt.figure(figsize = (20, 20)) \nsns.distplot(members.registration_init_time)\nsns.set(font_scale=2)\nplt.ylabel('estimated-pdf',fontsize=40)\nplt.xlabel('registration time ' ,fontsize=40)","69bf6507":"members.describe()","a157ab5b":"songs.describe()","798197d9":"train.describe()","f9c43461":"train_members = pd.merge(train, members, on='msno', how='inner')\ntrain_merged = pd.merge(train_members, songs, on='song_id', how='outer')\ntrain_merged.head()","44dcb46f":"test_members = pd.merge(test, members, on='msno', how='inner')\ntest_merged = pd.merge(test_members, songs, on='song_id', how='outer')\ntest_merged.head()\n","7e7fb5e3":"print(len(test_merged.columns))","e6794edd":"train_merged.columns.to_series().groupby(train_merged.dtypes).groups","eb881c08":"test_merged.columns.to_series().groupby(test_merged.dtypes).groups","8d9e3fed":"msno.heatmap(train_merged)","77651d7d":"def check_missing_values(df):\n    print(df.isnull().values.any())\n    if(df.isnull().values.any() == True):\n        columns_with_nan = df.columns[df.isnull().any()].tolist()\n    print(columns_with_nan)\n    \n    for col in columns_with_nan:\n        print(\"%s : %d \"%(col,df[col].isnull().sum()))\n\ncheck_missing_values(train_merged)\ncheck_missing_values(test_merged)\n    ","2fee83f1":"def replace_nan_non_object(df):\n    object_cols = list(df.select_dtypes(include=['float']).columns)\n    for col in object_cols:\n        df[col] = df[col].fillna(np.int(-5))\n\nreplace_nan_non_object(train_merged)\nreplace_nan_non_object(test_merged)","7a5090bd":"#--- memory consumed by train dataframe ---\nmem = train_merged.memory_usage(index=True).sum()\nprint(\"Memory consumed by training set  :   {} MB\" .format(mem\/ 1024**2))\n \n#--- memory consumed by test dataframe ---\nmem = test_merged.memory_usage(index=True).sum()\nprint(\"Memory consumed by test set      :   {} MB\" .format(mem\/ 1024**2))\n","7628371a":"def change_datatype(df):\n    float_cols = list(df.select_dtypes(include=['float']).columns)\n    for col in float_cols:\n        if((np.max(df[col]) <= 127) and (np.min(df[col] >= -128))):\n            df[col] = df[col].astype(np.int8)\n        elif((np.max(df[col])<=32767) and (np.min(df[col] >= -32768))):\n            df[col] = df[col].astype(np.int16)\n        elif((np.max(df[col]) <= 2147483647) and (np.min(df[col] >= -2147483648))):\n            df[col] = df[col].astype(np.int32)\n        else:\n            df[col]= df[col].astype(np.int64)\n\nchange_datatype(train_merged)\nchange_datatype(test_merged)","bf6476a2":"train_merged.info()","375acbf7":"data = train_merged.groupby('target').aggregate({'msno':'count'}).reset_index()\na4_dims =(15,8)\nfig, ax = plt.subplots(figsize = a4_dims)\nax = sns.barplot(x='target', y ='msno', data=data)","0377d28f":"mpl.rcParams['font.size']= 40.0\nplt.figure(figsize=(15,15))\ndata = train_merged.groupby('source_system_tab').aggregate({'msno': 'count'}).reset_index()\nsns.barplot(x ='source_system_tab', y ='msno', data = data)\nplt.xticks(rotation='90')","7a83b15b":"data = train_merged.groupby('source_screen_name').aggregate({'msno':'count'}).reset_index()\na4_dims = (15, 7)\nfig, ax = plt.subplots(figsize=a4_dims)\nax = sns.barplot(x='source_screen_name', y='msno', data=data)\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)","aad65111":"data = train_merged.groupby('source_type').aggregate({'msno':'count'}).reset_index()\na4_dims = (15, 7)\nfig, ax = plt.subplots(figsize=a4_dims)\nax = sns.barplot(x='source_type', y='msno', data=data)\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)","16569a14":"data = train_merged.groupby('language').aggregate({'msno':'count'}).reset_index()\na4_dims = (15, 7)\nfig, ax = plt.subplots(figsize=a4_dims)\nax = sns.barplot(x='language', y='msno', data=data)\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)","d5786a68":"data = train_merged.groupby('registered_via').aggregate({'msno':'count'}).reset_index()\na4_dims = (15, 7)\nfig, ax = plt.subplots(figsize=a4_dims)\nax = sns.barplot(x='registered_via', y='msno', data=data)\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)","9880282f":"print(train_merged.columns)\ndata = train_merged.groupby('city').aggregate({'msno':'count'}).reset_index()\na4_dims = (15, 7)\nfig, ax = plt.subplots(figsize=a4_dims)\nax = sns.barplot(x='city', y='msno', data=data)\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)","8eb23dcb":"a4_dims = (15, 7)\nfig, ax = plt.subplots(figsize=a4_dims)\nax=sns.countplot(x=\"source_system_tab\",data=train_merged,palette=['lightblue','orange','green'],hue=\"target\")\nplt.xlabel(\"source_screen_tab\")\nplt.ylabel(\"count\")\nplt.title(\"source_system_tab vs target \")\nplt.show()","605baa7b":"a4_dims = (15, 7)\nfig, ax = plt.subplots(figsize=a4_dims)\nax=sns.countplot(x=\"source_screen_name\",data=train_merged,palette=['#A8B820','yellow','#98D8D8'],hue=\"target\")\nplt.xlabel(\"source_screen_name\")\nplt.ylabel(\"count\")\nplt.title(\"source_screen_name vs target \")\nplt.xticks(rotation='90')\nplt.show()","65e3154c":"a4_dims = (15, 7)\nfig, ax = plt.subplots(figsize=a4_dims)\nax=sns.countplot(x=\"gender\",data=train_merged,palette=['#705898','#7038F8','yellow'],hue=\"target\")\nplt.xlabel(\"male female participation\")\nplt.ylabel(\"count\")\nplt.title(\"male female participation vs target \")\nplt.xticks(rotation='90')\nplt.legend(loc='upper left')\nplt.show()","a82e1768":"a4_dims = (15, 7)\nfig, ax = plt.subplots(figsize=a4_dims)\nax=sns.heatmap(data=train_merged.corr(),annot=True,fmt=\".2f\")","f41ed68e":"a4_dims = (15, 7)\nfig, ax = plt.subplots(figsize=a4_dims)\nax=sns.boxplot(x=\"gender\",y=\"city\",data=train_merged,palette=['blue','orange','green'],hue=\"target\")\nplt.xlabel(\"gender\")\nplt.ylabel(\"city\")\nplt.title(\"city vs registered_via  \")\nplt.show()","a8ebaaf0":"ax=sns.lmplot(x=\"bd\",y=\"registered_via\",data=train_merged,palette=['blue','orange','green'],hue=\"target\",fit_reg=False)\nplt.xlabel(\"bd age group\")\nplt.ylabel(\"registred_via\")\nplt.title(\" bd age group vs registration_via \")\nplt.show()","aa7ffe00":"ax=sns.lmplot(x=\"bd\",y=\"city\",data=train_merged,palette=['blue','orange','green'],hue=\"target\",fit_reg=False)\nplt.xlabel(\"bd age group\")\nplt.ylabel(\"city\")\nplt.title(\"bd (age group) vs city \")\nplt.show()","74f11a54":"a4_dims = (15, 7)\nfig, ax = plt.subplots(figsize=a4_dims)\nax=sns.boxplot(x=\"bd\",y=\"gender\",data=train_merged,palette=['blue','orange','green'])\nplt.xlabel(\"bd age group\")\nplt.ylabel(\"gender\")\nplt.title(\"bd age group vs gender \")\nplt.show()","9ecf7017":"train_merged.describe()\ndef remove_outlier(df_in, col_name):\n\n    #q1 = df_in[col_name].quantile(0.25)\n    #q3 = df_in[col_name].quantile(0.75)\n    #iqr = q3-q1 #Interquartile range\n    fence_low  = 12\n    fence_high = 45\n    df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n    return df_out\ndf_final_train=remove_outlier(train_merged,'bd')","6d88522d":"data_path = '..\/input\/wsdm-kkbox\/'\ntrain = pd.read_csv(data_path + 'train.csv', dtype={'msno' : 'category',\n                                                'source_system_tab' : 'category',\n                                                  'source_screen_name' : 'category',\n                                                  'source_type' : 'category',\n                                                  'target' : np.uint8,\n                                                  'song_id' : 'category'})\ntest = pd.read_csv(data_path + 'test.csv', dtype={'msno' : 'category',\n                                                'source_system_tab' : 'category',\n                                                'source_screen_name' : 'category',\n                                                'source_type' : 'category',\n                                                'song_id' : 'category'})\nsongs = pd.read_csv(data_path + 'songs.csv',dtype={'genre_ids': 'category',\n                                                  'language' : 'category',\n                                                  'artist_name' : 'category',\n                                                  'composer' : 'category',\n                                                  'lyricist' : 'category',\n                                                  'song_id' : 'category'})\nmembers = pd.read_csv(data_path + 'members.csv',dtype={'city' : 'category',\n                                                      'bd' : np.uint8,\n                                                      'gender' : 'category',\n                                                      'registered_via' : 'category'},\n                     parse_dates=['registration_init_time','expiration_date'])\nsongs_extra = pd.read_csv(data_path + 'song_extra_info.csv')\nprint('Done loading...')","3637bfd0":"song_cols = ['song_id', 'artist_name', 'genre_ids', 'song_length', 'language']\ntrain = train.merge(songs[song_cols], on='song_id', how='left')\ntest = test.merge(songs[song_cols], on='song_id', how='left')\n\nmembers['registration_year'] = members['registration_init_time'].apply(lambda x: int(str(x)[0:4]))\n\nmembers['expiration_year'] = members['expiration_date'].apply(lambda x: int(str(x)[0:4]))\nmembers['expiration_month'] = members['expiration_date'].apply(lambda x: int(str(x)[4:6]))\n\n# Convert date to number of days\nmembers['membership_days'] = (members['expiration_date'] - members['registration_init_time']).dt.days.astype(int)","51c10500":"# categorize membership_days \nmembers['membership_days'] = members['membership_days']\/\/200\nmembers['membership_days'] = members['membership_days'].astype('category')","9675aee5":"member_cols = ['msno','city','registered_via', 'registration_year', 'expiration_year', 'membership_days']\n\ntrain = train.merge(members[member_cols], on='msno', how='left')\ntest = test.merge(members[member_cols], on='msno', how='left')","84170786":"train.info()","b24d8e8c":"def isrc_to_year(isrc):\n    if type(isrc) == str:\n        if int(isrc[5:7]) > 17:\n            return int(isrc[5:7])\/\/5\n        else:\n            return int(isrc[5:7])\/\/5\n    else:\n        return np.nan\n#categorize song_year per 5years\n\nsongs_extra['song_year'] = songs_extra['isrc'].apply(isrc_to_year)\nsongs_extra.drop(['isrc', 'name'], axis = 1, inplace = True)","37ea438a":"train = train.merge(songs_extra, on = 'song_id', how = 'left')\ntest = test.merge(songs_extra, on = 'song_id', how = 'left')","8765060e":"train['genre_ids'] = train['genre_ids'].str.split('|').str[0]\ntemp_song_length = train['song_length']\ntrain.drop('song_length', axis = 1, inplace = True)\ntest.drop('song_length',axis = 1 , inplace =True)","1dc5b9c5":"train.head()","adbb8908":"song_count = train.loc[:,[\"song_id\",\"target\"]]\n\n# measure repeat count by played songs\nsong_count1 = song_count.groupby([\"song_id\"],as_index=False).sum().rename(columns={\"target\":\"repeat_count\"})\n\n# count play count by songs\nsong_count2 = song_count.groupby([\"song_id\"],as_index=False).count().rename(columns = {\"target\":\"play_count\"})","a45ca61c":"song_repeat = song_count1.merge(song_count2,how=\"inner\",on=\"song_id\")\nsong_repeat[\"repeat_percentage\"] = round((song_repeat['repeat_count']*100) \/ song_repeat['play_count'],1)\nsong_repeat['repeat_count'] = song_repeat['repeat_count'].astype('int')\nsong_repeat['repeat_percentage'] = song_repeat['repeat_percentage'].replace(100.0,np.nan)\n#cuz most of 100.0 are played=1 repeated=1 values. I think it is not fair compare with other played a lot songs","16536bcb":"train = train.merge(song_repeat,on=\"song_id\",how=\"left\")\ntest = test.merge(song_repeat,on=\"song_id\",how=\"left\")","c830fe8f":"# type cast\ntest['song_id'] = test['song_id'].astype('category')\ntest['repeat_count'] = test['repeat_count'].fillna(0)\ntest['repeat_count'] = test['repeat_count'].astype('int')\ntest['play_count'] = test['play_count'].fillna(0)\ntest['play_count'] = test['play_count'].astype('int')","6203fb5a":"## KKbox Music Recommender Preprocessing and EDA  ","e51f677d":"it is visible that in members and songs csv files,there is a large differences between min and max values which can be give us an inference that there are outliers in the csv files. these has to be removed before proceeding further","338106fb":"new female users are more than male users about 500 to 600","ff257d1a":"from the above distribution it can be infered that teh max people registered during an interval of 2015 to 2018 with most of them registering in the year 2016","5fc23eb2":"from the above plot we can see that most of the people who had installed kkbox app for music basically go back to their old songs rather than exploring to new songs.  from that we can assume that most of them are using it only as a player rather than music library. ","58bf5326":"from the above pie chart we can infer that most of the people are using explore feature in it and mylibrary the next ","5ecccce6":"From the above plot we can higlight that most of the listeners listen to local playlist","92db4590":"here we can see that most of our user are between 5 to 14 no of cities might be female ratio is same","534e238a":"Preprocessing\n","ab1758b0":"**Analysing the Missing Values**","2c85a75b":"new user are coming form discover and my library and old ones are from my library","53e2663d":"Now checking missing values and replacing them with some unique values","b1afd5a9":"with outlier as we can we didn't remove till now we will remove bd outliers at final stages before applying Ml but that last results insights are telling we have age group 20 to 30+ ages and city index we most 5 to 14","3a1e6216":"Memory Consumption","38b964f0":"we can see that mean age group we have 24 to 27 with max is 50 in female case and in male case 48 about age group is max and min in female it is about 16 and in male case 18\n\none more observation we can see that female outlier are more there reason behind this logic females always tend fill up the things in hurry way because in male we can't see male with 100 , as if this bit funny logic , apart from this it all due unclean data that's it which we have to remove outliers","dff6fc8f":"now we can see that music users vary in age form 0 to 100. we can see here are outliers to in bd but interesting information is that most users age group of younsters and 30+ age group form 5 to 10 registered_via index","9cd85421":"In the above visualization we can see that the local library is more preferred than most of other source types and online playlist occupies the second position","81cab799":"Data conversion of int , float and categorical has to be done to reduce the data size for computation as well as storage","4ce3f568":"we can observe that lot of missing values are coming up but we notice that most of the missing values are arrived from members and songs\n\nmissing values from the heatmap also shows information about which are missing and has positive correlation. gender with 4 variables of train.csv and rest of varibales with members.csv","2a3aac8e":"from the plot we can see that the male and female ratio of the users using the app is almost the same. which can help us deduce that it maintains gender neutrality","4b89bfe4":"local playlist among new user and old one more most common way to get back their songs"}}