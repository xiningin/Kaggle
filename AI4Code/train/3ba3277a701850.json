{"cell_type":{"03f2cdb7":"code","cfb4873a":"code","8152c961":"code","abdf08c2":"code","24206525":"code","6c0daa15":"code","65f0a694":"code","da6d86f1":"code","36fac6ac":"code","8c357816":"code","187bc364":"code","b03564d8":"code","50816f6b":"code","6e7c6609":"code","436d3b8f":"code","265b7aee":"code","413df0ba":"code","7e8510a1":"code","e3b52929":"markdown"},"source":{"03f2cdb7":"\nfrom google.colab import drive\ndrive.mount('\/content\/gdrive')\n\nPATH_OF_DATA= '\/content\/gdrive\/\"My Drive\"\/data_global'\n!ls {PATH_OF_DATA}","cfb4873a":"\n\n\nfrom __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\n\nplt.ion()   # interactive mode\nimport torch\nimport os \nimport torchvision\nimport numpy as np\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms","8152c961":"# Comment 0: define transformation that you wish to apply on image\n# Data augmentation and normalization for training\n# Just normalization for validation\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","abdf08c2":"data_dir = '\/content\/gdrive\/My Drive\/data_global'\nimage_datasets = {x: torchvision.datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=4)\n              for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n","24206525":"def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])","6c0daa15":"def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","65f0a694":"def visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images\/\/2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)","da6d86f1":"model_ft = models.resnet18(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\n# Here the size of each output sample is set to 2.\n# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\nmodel_ft.fc = nn.Linear(num_ftrs, 2)\n\nmodel_ft = model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)","36fac6ac":"model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n                       num_epochs=25)","8c357816":"visualize_model(model_ft)","187bc364":"model_conv = torchvision.models.resnet18(pretrained=True)\nfor param in model_conv.parameters():\n    param.requires_grad = False\n\n# Parameters of newly constructed modules have requires_grad=True by default\nnum_ftrs = model_conv.fc.in_features\nmodel_conv.fc = nn.Linear(num_ftrs, 2)\n\nmodel_conv = model_conv.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that only parameters of final layer are being optimized as\n# opposed to before.\noptimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)","b03564d8":"model_conv = train_model(model_conv, criterion, optimizer_conv,\n                         exp_lr_scheduler, num_epochs=25)","50816f6b":"visualize_model(model_conv)\n\nplt.ioff()\nplt.show()","6e7c6609":"from PIL import Image\nimport time\nfrom torch.autograd import Variable\nimport json\nimport copy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport PIL\nfrom PIL import Image\nfrom collections import OrderedDict\nimport torch\nfrom torch import nn, optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torch.nn as nn\nimport torch.nn.functional as F\nimage_path = '\/content\/gdrive\/My Drive\/data_global\/val\/benign\/888.jpg'\nimg = Image.open(image_path)","436d3b8f":"def process_image(image):\n    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n        returns an Numpy array\n    '''\n    # TODO: Process a PIL image for use in a PyTorch model\n    # tensor.numpy().transpose(1, 2, 0)\n    preprocess = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                             std=[0.229, 0.224, 0.225])\n    ])\n    image = preprocess(image)\n    return image\ndef imshow(image, ax=None, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    if ax is None:\n        fig, ax = plt.subplots()\n    \n    # PyTorch tensors assume the color channel is the first dimension\n    # but matplotlib assumes is the third dimension\n    image = image.numpy().transpose((1, 2, 0))\n    \n    # Undo preprocessing\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    image = std * image + mean\n    \n    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n    image = np.clip(image, 0, 1)\n    \n    ax.imshow(image)\n    \n    return ax\nwith Image.open(image_path) as image:\n    plt.imshow(image)\nmodel_ft.class_to_idx = image_datasets['train'].class_to_idx","265b7aee":"def predict2(image_path, model, topk=2):\n    ''' Predict the class (or classes) of an image using a trained deep learning model.\n    '''\n    \n    # TODO: Implement the code to predict the class from an image file\n    img = Image.open(image_path)\n    img = process_image(img)\n    \n    # Convert 2D image to 1D vector\n    img = np.expand_dims(img, 0)\n    \n    \n    img = torch.from_numpy(img)\n    \n    model.eval()\n    inputs = Variable(img).to(device)\n    logits = model.forward(inputs)\n    \n    ps = F.softmax(logits,dim=1)\n    topk = ps.cpu().topk(topk)\n    \n    return (e.data.numpy().squeeze().tolist() for e in topk)","413df0ba":"img_path = '\/content\/gdrive\/My Drive\/data_global\/val\/benign\/888.jpg'\nprobs, classes = predict2(img_path, model_ft.to(device))\nprint(probs)\nprint(classes)\n","7e8510a1":"def view_classify(img_path, prob, classes):\n    ''' Function for viewing an image and it's predicted classes.\n    '''\n    image = Image.open(img_path)\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,10), ncols=1, nrows=2)\n    \n    \n    ax1.imshow(image)\n    ax1.axis('off')\n    \n    y_pos = np.arange(len(prob))\n    ax2.barh(y_pos, prob, align='center')\n    ax2.set_yticks(y_pos)\n    \n    ax2.invert_yaxis()  # labels read top-to-bottom\n    ax2.set_title('Class Probability')\nview_classify(img_path, probs, classes)","e3b52929":"# RUN the code in GOOGLE COLAB"}}