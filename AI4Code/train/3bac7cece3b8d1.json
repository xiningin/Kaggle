{"cell_type":{"6e3ba120":"code","fc5286e6":"code","7f29c9c8":"code","14c84f21":"code","35a28dc2":"code","308aa5a5":"code","b2cf2c87":"code","c27d3a76":"code","ad709d78":"code","af4763ee":"code","6437bb66":"code","7c9e09c5":"code","252c6bc9":"code","3f791afa":"code","eed66b1d":"code","f873be5e":"code","bd2e265d":"code","fb236b80":"code","51d31633":"code","5b153f33":"code","4953fb88":"code","8406a1d8":"code","52f61ce8":"code","cbe5ae56":"code","2ece1f59":"code","7f04da26":"markdown","73b22f7f":"markdown","3897cffb":"markdown","c26f8881":"markdown","bd6b9604":"markdown"},"source":{"6e3ba120":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fc5286e6":"# Importando a base\ndf_cardio = pd.read_csv('\/kaggle\/input\/cardiovascular-disease-dataset\/cardio_train.csv', sep=';')\n\ndf_cardio.shape","7f29c9c8":"# Visualizando os dados\ndf_cardio.head()","14c84f21":"# Altura minima\ndf_cardio['height'].min()","35a28dc2":"# Altura maxima\ndf_cardio['height'].max()","308aa5a5":"# Tipos e tamanhos\ndf_cardio.info()","b2cf2c87":"# Selecionando as colunas para treinamento\nfeats = [c for c in df_cardio.columns if c not in ['id', 'cardio']]","c27d3a76":"# Separando o dataframe\nfrom sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(df_cardio, random_state = 42, test_size=0.1)\n\ntrain, valid = train_test_split(train, random_state = 42, test_size=0.1)\n\ntrain.shape, valid.shape, test.shape","ad709d78":"# Treinando um modelo de RF Classifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42)\n\nrf.fit(train[feats], train['cardio'])","af4763ee":"# Fazendo previs\u00f5es com o modelo treinado na base de valida\u00e7\u00e3o\npreds_val = rf.predict(valid[feats])\n\npreds_val","6437bb66":"# Visualizando os 3 primeiros registros da base de valida\u00e7\u00e3o\nvalid.head(3)","7c9e09c5":"# Visualizando os 3 \u00faltimos registros da base de valida\u00e7\u00e3o\nvalid.tail(3)","252c6bc9":"# Verificando o desempenho de acordo com a m\u00e9trica - base de valida\u00e7\u00e3o\nfrom sklearn.metrics import accuracy_score\n\naccuracy_score(valid['cardio'], preds_val)","3f791afa":"# Vamos verificar qual o valor de base para a coluna target da base de valida\u00e7\u00e3o\nvalid['cardio'].value_counts(normalize=True)","eed66b1d":"# Fazendo previs\u00f5es com o modelo treinado na base de teste\npreds_test = rf.predict(test[feats])\n\npreds_test","f873be5e":"# Verificando o desempenho de acordo com a m\u00e9trica - base de teste\naccuracy_score(test['cardio'], preds_test)","bd2e265d":"# Dividindo novamente os dados apenas em treino e teste\ntrain, test = train_test_split(df_cardio, random_state = 42, test_size=0.1)\n\ntrain.shape, test.shape","fb236b80":"# Criando um modelo de RF Classifier e usando o Cross Validation\nrf = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42)\n\nfrom sklearn.model_selection import cross_val_score\n\nscores = cross_val_score(rf, train[feats], train['cardio'], cv=5, n_jobs=-1)\n\nscores","51d31633":"# M\u00e9dias dos scores de valida\u00e7\u00e3o\nscores.mean()","5b153f33":"# Treinamento e fazendo previs\u00f5es\nrf.fit(train[feats], train['cardio'])\n\npreds_test = rf.predict(test[feats])\n\naccuracy_score(test['cardio'], preds_test)","4953fb88":"# Dividindo novamente os dados apenas em treino e teste\ntrain, test = train_test_split(df_cardio, random_state = 42, test_size=0.1)\n\ntrain.shape, test.shape","8406a1d8":"# Treinando um modelo de RF Classifier usando oob_score\nrf = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42, oob_score=True)\n\nrf.fit(train[feats], train['cardio'])","52f61ce8":"# Fazendo previs\u00f5es com o modelo treinado na base de teste\npreds_test = rf.predict(test[feats])\n\naccuracy_score(test['cardio'], preds_test)","cbe5ae56":"# Treinando um modelo de RF Classifier\nrf = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42, oob_score=True,\n                           min_samples_leaf=5, min_samples_split=20, max_depth=10)\n\nrf.fit(train[feats], train['cardio'])","2ece1f59":"# Fazendo previs\u00f5es com o modelo treinado na base de teste\npreds_test = rf.predict(test[feats])\n\naccuracy_score(test['cardio'], preds_test)","7f04da26":"## Cross Validation\nConjunto de t\u00e9cnicas que usam os pr\u00f3prios dados de treinamento para realizar a valida\u00e7\u00e3o do modelo.\n\nComo o modelo deve ser validado com dados que n\u00e3o foram usados ainda, s\u00e3o aplicadas t\u00e9cnicas espec\u00edficas para separar alguns dados de treino e assim realizar a valida\u00e7\u00e3o.\n\nA vantagem \u00e9 n\u00e3o precisar dividir nossos dados de treino em conjuntos de treino e valida\u00e7\u00e3o, j\u00e1 que a valida\u00e7\u00e3o vai ser feita pelo Cross Validation. Isso \u00e9 extremamente \u00fatil principalmente em conjunto de dados pequenos, onde a separa\u00e7\u00e3o em treino e valida\u00e7\u00e3o pode reduzir muito o conjunto de dados de treinamento e com isso comprometer o desempenho do modelo.\n\nUm exemplo de t\u00e9cnica \u00e9 o KFold, que divide os dados de treino em k itera\u00e7\u00f5es e para cada itera\u00e7\u00e3o uma amostra dos dados de treino \u00e9 separada para fazer valida\u00e7\u00e3o.\n\n\n![Cross](https:\/\/scikit-learn.org\/stable\/_images\/grid_search_cross_validation.png)\n","73b22f7f":"## OOB - Out Of Bag\nInicialmente precisamos lembrar como funciona o modelo de random forest: s\u00e3o criadas diversas \u00e1rvores de decis\u00e3o que recebem amostras dos dados originais. Essas amostras s\u00e3o criadas de forma aleat\u00f3ria, com repeti\u00e7\u00e3o.\n\n![random](https:\/\/miro.medium.com\/max\/1050\/1*ixvrbH45K8CcNZaj98JGuA.png)\n\n\u00c9 f\u00e1cil notar que, em cada \u00e1rvore criada, alguns dados foram usados e outros n\u00e3o. Ou seja, para cada \u00e1rvore, alguns dados entraram na cesta de dados de treinamento, enquanto outros ficaram fora da cesta de treinamento (out of bag).\n\n![oob](https:\/\/miro.medium.com\/max\/1043\/1*_J-O7FJ99a3Zehb3eUlqcg.png)\n\nPara cada \u00e1rvore existe um conjunto de dados que o modelo nunca viu, aqueles que ficaram fora da cesta de treinamento. Ent\u00e3o, podemos usar esses dados nunca vistos pela \u00e1rvore para fazer a valida\u00e7\u00e3o da pr\u00f3pria \u00e1rvore, uma vez que precisamos de dados n\u00e3o usados no treinamento para realizarmos a valida\u00e7\u00e3o.\n\nPara usar o conceito de OOB e determinar que o modelo deve ser validado com o dados que ele mesmo deixou de fora do treinamento, basta usar o par\u00e2metro **oob_score = True** no momento de instanciar o modelo de Randon Forest.\n\nMais uma vez, esse artif\u00edcio \u00e9 de grande valia para bases pequenas, pois n\u00e3o precisamos criar uma base de dados de valida\u00e7\u00e3o, mas apenas usar para valida\u00e7\u00e3o os dados que o pr\u00f3prio modelo descartou.\n","3897cffb":"# IESB - Miner II - Aula 07 - Cross Validation e OOB","c26f8881":"## Doen\u00e7as cardiovasculares - Modelo de classifica\u00e7\u00e3o bin\u00e1ria","bd6b9604":"## Melhorando os par\u00e2metros do modelo Random Forest"}}