{"cell_type":{"87e0a053":"code","4f098d46":"code","ba8d5f45":"code","7cf1a330":"code","91bda871":"markdown","bc2cf114":"markdown"},"source":{"87e0a053":"# Load the data\nimport pandas as pd\n!wget https:\/\/raw.githubusercontent.com\/MicrosoftDocs\/mslearn-introduction-to-machine-learning\/main\/Data\/ml-basics\/seeds.csv\ndata = pd.read_csv('seeds.csv')\nfeatures = data[data.columns[0:6]]\nfeatures.sample(10)","4f098d46":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA\n\n# Normalize the numeric features\nscaled_features =  MinMaxScaler().fit_transform(features)\n\n# Get principal components\n\npca = PCA(n_components = 2).fit(scaled_features)\nfeatures_2d = pca.transform(scaled_features)\nfeatures_2d[0:10]","ba8d5f45":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.scatter(features_2d[:,0], features_2d[:,1])\nplt.xlabel(\"Dimension 1\")\nplt.ylabel(\"Dimension 2\")\nplt.title(\"Data\")\nplt.show()","7cf1a330":"# Train and evalate a clustetring Model\n#Importing libraries\nimport numpy as np\nfrom sklearn.cluster import KMeans\n\n# create 10 models with 1 to 10 clusters\nwcss = []\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters = i)\n    kmeans.fit(features.values)\n    # Get the WCSS (inertia) value\n    wcss.append(kmeans.inertia_)\n    \n# Plot the WCSS values onto a line graph\nplt.plot(range(1,11), wcss)\nplt.xlabel(\"WCSS by Clusters\")\nplt.ylabel(\"Number of clusters\")\nplt.title(\"WCSS\")\nplt.show()\n    \n","91bda871":"# Clustering","bc2cf114":"The plot shows a large reduction in WCSS (so greater tightness) as the number of clusters increases from one to two, and a further noticable reduction from two to three clusters. After that, the reduction is less pronounced, resulting in an \"elbow\" in the chart at around three clusters. This is a good indication that there are two to three reasonably well separated clusters of data points"}}