{"cell_type":{"fae6deb8":"code","12cb0217":"code","b89f8df4":"code","59a121e7":"code","23a465c8":"code","fd23fe61":"code","9ab57a28":"code","54ec975b":"code","4130cb31":"code","e3a061b1":"code","6f4aab54":"code","bd36978f":"code","5e152012":"code","4d27a6fb":"code","76d016fa":"code","58bad488":"code","b919696a":"code","05d06118":"code","3fa14ea5":"code","6095b461":"code","ed12db61":"code","56da4f19":"code","fcb39272":"code","0524810b":"code","c3f1adfc":"code","e30905b4":"code","52d8f642":"code","b4b6ba53":"code","2b863dac":"code","815aaed3":"code","9de7a314":"code","5d844610":"code","09cced96":"code","4984ad94":"code","fd93361c":"code","962ea4e7":"code","ebd7b930":"code","35ad70f0":"code","18358918":"code","aeb74c8c":"code","12d92e75":"code","4bcb4a18":"code","c872568f":"code","5fd25423":"code","3da19d4e":"code","7b756ca8":"code","c9814a9e":"markdown","e458d3e5":"markdown","8506374c":"markdown","6b6e93a9":"markdown","b8dde530":"markdown"},"source":{"fae6deb8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","12cb0217":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline","b89f8df4":"df = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf","59a121e7":"df.info()","23a465c8":"# df.count() does not include NULL values, dropping column where value in column missing % is at most 30%\ndf2 = df[[column for column in df if df[column].count() \/ len(df) >= 0.3]]\ndel df2['Id']\nprint(\"List of dropped columns:\", end=\" \")\nfor c in df.columns:\n    if c not in df2.columns:\n        print(c, end=\", \")\nprint('\\n')\ndf = df2","fd23fe61":"print(df['SalePrice'].describe())\nplt.figure(figsize=(9, 8))\nsns.distplot(df['SalePrice'], color='g', bins=100, hist_kws={'alpha': 0.4});","9ab57a28":"print(np.log(df['SalePrice']).describe())\nplt.figure(figsize=(9, 8))\nsns.distplot(np.log(df['SalePrice']), color='g', bins=100, hist_kws={'alpha': 0.4});","54ec975b":"#Right skewed price with outlier ~500000\nlist(set(df.dtypes.tolist()))","4130cb31":"df_num = df.select_dtypes(include = ['float64', 'int64'])\ndf_num.head()","e3a061b1":"df_num.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8); ","6f4aab54":"df_num_corr = df_num.corr()['SalePrice'][:-1] # -1 because the latest row is SalePrice\ncorr_feature = df_num_corr[abs(df_num_corr) > 0.5].sort_values(ascending=False)\nprint(\"There is {} strongly correlated values with SalePrice:\\n{}\".format(len(corr_feature), corr_feature))","bd36978f":"for i in range(0, len(df_num.columns), 5):\n    sns.pairplot(data=df_num,\n                x_vars=df_num.columns[i:i+5],\n                y_vars=['SalePrice'])","5e152012":"import operator\n\nindividual_features_df = []\nfor i in range(0, len(df_num.columns) - 1): # -1 because the last column is SalePrice\n    tmpDf = df_num[[df_num.columns[i], 'SalePrice']]\n    tmpDf = tmpDf[tmpDf[df_num.columns[i]] != 0]\n    individual_features_df.append(tmpDf)\n\nall_correlations = {feature.columns[0]: feature.corr()['SalePrice'][0] for feature in individual_features_df}\nall_correlations = sorted(all_correlations.items(), key=operator.itemgetter(1))\nfor (key, value) in all_correlations:\n    print(\"{:>15}: {:>15}\".format(key, value))","4d27a6fb":"corr_feature = [key for key, value in all_correlations if abs(value) >= 0.5]\nprint(\"There is {} strongly correlated values with SalePrice:\\n{}\".format(len(corr_feature), corr_feature))","76d016fa":"corr = df_num.drop('SalePrice', axis=1).corr() # We already examined SalePrice correlations\nplt.figure(figsize=(12, 10))\n\nsns.heatmap(corr[(corr >= 0.5) | (corr <= -0.4)], \n            cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n            annot=True, annot_kws={\"size\": 8}, square=True);\n","58bad488":"object_columns_df = df.select_dtypes(include=['object'])","b919696a":"#Number of null values in each feature\nnull_counts = object_columns_df.isnull().sum()","05d06118":"columns_None = ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','GarageType','GarageFinish','GarageQual','FireplaceQu','GarageCond']\nobject_columns_df[columns_None]= object_columns_df[columns_None].fillna('None')","3fa14ea5":"columns_with_lowNA = ['MSZoning','Utilities','Exterior1st','Exterior2nd','MasVnrType','Electrical','KitchenQual','Functional','SaleType']\n#fill missing values for each column (using its own most frequent value)\nobject_columns_df[columns_with_lowNA] = object_columns_df[columns_with_lowNA].fillna(object_columns_df.mode().iloc[0])","6095b461":"numerical_columns_df =df.select_dtypes(exclude=['object'])\n#Number of null values in each feature\nnull_counts = numerical_columns_df.isnull().sum()\nprint(\"Number of null values in each column:\\n{}\".format(null_counts))","ed12db61":"print((numerical_columns_df['YrSold']-numerical_columns_df['YearBuilt']).median())\nprint(numerical_columns_df[\"LotFrontage\"].median())","56da4f19":"numerical_columns_df['GarageYrBlt'] = numerical_columns_df['GarageYrBlt'].fillna(numerical_columns_df['YrSold']-35)\nnumerical_columns_df['LotFrontage'] = numerical_columns_df['LotFrontage'].fillna(68)\nnumerical_columns_df= numerical_columns_df.fillna(0)","fcb39272":"object_columns_df = object_columns_df.drop(['Heating','RoofMatl','Condition2','Street','Utilities'],axis=1)","0524810b":"numerical_columns_df['Age_House']= (numerical_columns_df['YrSold']-numerical_columns_df['YearBuilt'])\nnumerical_columns_df['Age_House'].describe()","c3f1adfc":"numerical_columns_df['TotalBsmtBath'] = numerical_columns_df['BsmtFullBath'] + numerical_columns_df['BsmtFullBath']*0.5\nnumerical_columns_df['TotalBath'] = numerical_columns_df['FullBath'] + numerical_columns_df['HalfBath']*0.5 \nnumerical_columns_df['TotalSA']=numerical_columns_df['TotalBsmtSF'] + numerical_columns_df['1stFlrSF'] + numerical_columns_df['2ndFlrSF']","e30905b4":"numerical_columns_df.head()","52d8f642":"bin_map  = {'TA':2,'Gd':3, 'Fa':1,'Ex':4,'Po':1,'None':0,'Y':1,'N':0,'Reg':3,'IR1':2,'IR2':1,'IR3':0,\"None\" : 0,\n            \"No\" : 2, \"Mn\" : 2, \"Av\": 3,\"Gd\" : 4,\"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3,\"BLQ\" : 4, \"ALQ\" : 5, \"GLQ\" : 6\n            }\nobject_columns_df['ExterQual'] = object_columns_df['ExterQual'].map(bin_map)\nobject_columns_df['ExterCond'] = object_columns_df['ExterCond'].map(bin_map)\nobject_columns_df['BsmtCond'] = object_columns_df['BsmtCond'].map(bin_map)\nobject_columns_df['BsmtQual'] = object_columns_df['BsmtQual'].map(bin_map)\nobject_columns_df['HeatingQC'] = object_columns_df['HeatingQC'].map(bin_map)\nobject_columns_df['KitchenQual'] = object_columns_df['KitchenQual'].map(bin_map)\nobject_columns_df['FireplaceQu'] = object_columns_df['FireplaceQu'].map(bin_map)\nobject_columns_df['GarageQual'] = object_columns_df['GarageQual'].map(bin_map)\nobject_columns_df['GarageCond'] = object_columns_df['GarageCond'].map(bin_map)\nobject_columns_df['CentralAir'] = object_columns_df['CentralAir'].map(bin_map)\nobject_columns_df['LotShape'] = object_columns_df['LotShape'].map(bin_map)\nobject_columns_df['BsmtExposure'] = object_columns_df['BsmtExposure'].map(bin_map)\nobject_columns_df['BsmtFinType1'] = object_columns_df['BsmtFinType1'].map(bin_map)\nobject_columns_df['BsmtFinType2'] = object_columns_df['BsmtFinType2'].map(bin_map)\n\nPavedDrive =   {\"N\" : 0, \"P\" : 1, \"Y\" : 2}\nobject_columns_df['PavedDrive'] = object_columns_df['PavedDrive'].map(PavedDrive)","b4b6ba53":"#Select categorical features\nrest_object_columns = object_columns_df.select_dtypes(include=['object'])\n#Using One hot encoder\nobject_columns_df = pd.get_dummies(object_columns_df, columns=rest_object_columns.columns) ","2b863dac":"object_columns_df.head()","815aaed3":"df_final = pd.concat([object_columns_df, numerical_columns_df], axis=1,sort=False)\ndf_final.head()","9de7a314":"target= np.log(df_final['SalePrice'])","5d844610":"from sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nimport sklearn.metrics as metrics\nimport math","09cced96":"x_train,x_test,y_train,y_test = train_test_split(df_final,target,test_size=0.33,random_state=0)","4984ad94":"sns.distplot(y_test, color='g', bins=100, hist_kws={'alpha': 0.4});","fd93361c":"\n\nxgb =XGBRegressor( booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.6, gamma=0,\n             importance_type='gain', learning_rate=0.01, max_delta_step=0,\n             max_depth=4, min_child_weight=1.5, n_estimators=2400,\n             n_jobs=1, nthread=None, objective='reg:linear',\n             reg_alpha=0.6, reg_lambda=0.6, scale_pos_weight=1, \n             silent=None, subsample=0.8, verbosity=1)","962ea4e7":"xgb.fit(x_train, y_train)","ebd7b930":"lgbm = LGBMRegressor(objective='regression', \n                                       num_leaves=4,\n                                       learning_rate=0.01, \n                                       n_estimators=12000, \n                                       max_bin=200, \n                                       bagging_fraction=0.75,\n                                       bagging_freq=5, \n                                       bagging_seed=7,\n                                       feature_fraction=0.4, \n                                       )","35ad70f0":"lgbm.fit(x_train, y_train,eval_metric='rmse')","18358918":"predict1 = xgb.predict(x_test)\npredict = lgbm.predict(x_test)","aeb74c8c":"predict2 = xgb.predict(x_train)\npredict3 = lgbm.predict(x_train)","12d92e75":"print('Root Mean Square Error test = ' + str(math.sqrt(metrics.mean_squared_error(y_test, predict1))))\nprint('Root Mean Square Error test = ' + str(math.sqrt(metrics.mean_squared_error(y_test, predict))))","4bcb4a18":"plt.figure(figsize=(9, 8))\nsns.distplot(predict1, color='g', bins=100, hist_kws={'alpha': 0.4});","c872568f":"sum(y_test)-sum(predict1)","5fd25423":"#score(predict1,x_test,y_test)\ntype(y_test.values)","3da19d4e":"type(predictions)","7b756ca8":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import r2_score\n#predictions = [round(value) for value in predict1]\nr2_score = r2_score((y_test), predict1)\nprint(\"Accuracy: %.2f%%\" % (r2_score * 100.0))","c9814a9e":"Deeling with categorical feature ","e458d3e5":"Remove 0 values and repeat the process of finding correlated values:","8506374c":"    encode categorical features\n\n    Ordinal categories features - Mapping from 0 to N ","6b6e93a9":"Try to find co-relation between sales-price and these feature and store them in corr_feature.","b8dde530":"Plot the numerical features and see which ones have very few or explainable outliers\nRemove the outliers from these features and see which one can have a good correlation without their outliers\n"}}