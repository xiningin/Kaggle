{"cell_type":{"54e1c7d9":"code","3e8349ec":"code","ab38419a":"code","aa5ba8d3":"code","06e002eb":"code","c3e58689":"code","9377d89a":"code","bc88a889":"code","21a19906":"code","97ca7c03":"code","d8ab4993":"code","b5a30e6c":"code","3078a965":"code","dc7afa31":"code","468e32c0":"code","c74dd926":"code","d6f18512":"code","51b342d2":"code","5a09b512":"code","398b59cc":"code","0db2af90":"code","7a443ad0":"code","332e96f4":"code","6a11f6f3":"code","4a8d3349":"code","3c7635c8":"code","142c4cfb":"code","6c304dc3":"code","eed8d567":"code","f5019b9d":"code","a4410a0b":"code","8a7e2c15":"code","cb983602":"code","2d6ddbe1":"code","1cb97a8f":"code","449e4de4":"code","c503a71e":"code","47870173":"code","0f85cd96":"code","c70563c6":"code","b819643c":"code","90389682":"code","da4f1c07":"code","336efb62":"code","fad69d01":"code","705c823f":"code","b45c664f":"code","2aef43dd":"code","0d90be28":"code","62eb6c50":"code","6875e097":"code","56eb1618":"code","d8d15ed5":"code","e470cd1c":"code","ee1333b4":"code","723a6092":"code","7b975aa3":"code","bbe8d73e":"code","77bb8505":"code","40b2e385":"code","176007ed":"code","e1609a34":"code","05989453":"code","c9e57d59":"code","56b487a4":"code","04ef2da2":"code","63644446":"code","98865aa0":"markdown","ac96f1cc":"markdown","c824da11":"markdown","cc3c4e66":"markdown","711dd916":"markdown","ac5de15b":"markdown","6a57f407":"markdown","57c757e0":"markdown","60fb9984":"markdown","539dfe21":"markdown","b8aa8c0e":"markdown","467fe406":"markdown","9e9c2559":"markdown","b3583fba":"markdown","8f2365cc":"markdown","7c520b1f":"markdown","19785035":"markdown","41aa7470":"markdown","ae6ee0ba":"markdown","5aec96b9":"markdown","ead1f1c9":"markdown","ade04a2f":"markdown","15a4bb7a":"markdown","aa47526e":"markdown","87e8d8b5":"markdown","b983a091":"markdown","e3593e59":"markdown","26c8f33e":"markdown","09ee9d84":"markdown","9effd2bb":"markdown","66e7a69c":"markdown","66db7a96":"markdown","5b0b4a5f":"markdown","5e26aba6":"markdown","b39506b1":"markdown","ea4193e5":"markdown","b6362473":"markdown","4490612d":"markdown","95dd1739":"markdown"},"source":{"54e1c7d9":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom scipy import stats\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3e8349ec":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntrain[\"type\"] = 0\ntest[\"type\"] = 1\ndf = pd.concat([train,test],axis=0)\ndf","ab38419a":"df.describe()","aa5ba8d3":"fig,ax = plt.subplots(1,3,figsize=(21,6))\nsns.histplot(df[\"SalePrice\"],kde=True,ax=ax[0])\nresult = stats.probplot(df[\"SalePrice\"],dist=stats.norm,plot=ax[1])\nsns.boxplot(df[\"SalePrice\"])\nplt.show()\nprint('-'*25)\nprint(\"salePrice skew:{}.\".format(df[\"SalePrice\"].skew()))","06e002eb":"sale_500000 = df[df[\"SalePrice\"] > 500000][\"Id\"]\nsale_500000","c3e58689":"df[\"SalePrice\"] = stats.boxcox(df[\"SalePrice\"].values,0.35)\nprint(\"-\"*30)\nprint(\"SalePrice after_skew:{}\".format(df[\"SalePrice\"].skew()))\ndf","9377d89a":"fig,ax = plt.subplots(1,3,figsize=(21,6))\nsns.histplot(df[\"SalePrice\"],kde=True,ax=ax[0])\nresult = stats.probplot(df[\"SalePrice\"],dist=stats.norm,plot=ax[1])\nsns.boxplot(df[\"SalePrice\"])\nplt.show()","bc88a889":"isnull = df[df[\"type\"] == 0].isnull().sum()\/df[df[\"type\"] == 0].shape[0]\nisnull[isnull>0].sort_values(ascending=False)","21a19906":"def null_plot(df,feature,target):\n    fig,ax = plt.subplots(1,2,figsize=(10,8))\n    sca = sns.scatterplot(data=df,x=feature,y=target,ax=ax[0])\n    count = sns.countplot(data=df,y=feature,ax=ax[1])\n    return sca,count","97ca7c03":"null_plot(df,\"PoolQC\",\"SalePrice\")","d8ab4993":"null_plot(df,\"MiscFeature\",\"SalePrice\")","b5a30e6c":"null_plot(df,\"Alley\",\"SalePrice\")","3078a965":"null_plot(df,\"Fence\",\"SalePrice\")","dc7afa31":"null_plot(df,\"FireplaceQu\",\"SalePrice\")","468e32c0":"list_col = [\"PoolQC\",\"MiscFeature\",\"Alley\",\"Fence\",\"FireplaceQu\"]\nfor col in list_col:\n    if col == \"MiscFeature\":\n        df = df.drop(columns=[col])\n    else:\n        df[col] = df[col].fillna(\"Missing\")","c74dd926":"other_lis = [\"LotFrontage\",\"GarageType\",\"GarageYrBlt\",\"GarageFinish\",\"GarageQual\",\"GarageCond\",\"BsmtExposure\"\n             ,\"BsmtFinType2\",\"BsmtFinType1\",\"BsmtCond\",\"BsmtQual\",\"MasVnrArea\",\"MasVnrType\",\"Electrical\"]\nfig,axes = plt.subplots(7,2,figsize=(16,25))\ni = 0\nfor col,ax in zip(other_lis,axes.flat):\n    sns.scatterplot(data=df,x=col,y=\"SalePrice\",ax=ax)\n    ax.set_xlabel(col)\n","d6f18512":"# Use training set data to fill in missing values\nfor i in other_lis:\n    df[i] = df[i].fillna(df[df[\"type\"] == 0][i].mode()[0])","51b342d2":"a= df.isnull().sum()\na_null_other = a[a>0][:-1]\nfor col in a_null_other.index:\n    df[col] = df[col].fillna(df[df[\"type\"] == 0][col].mode()[0])\n","5a09b512":"def outlier(df,feature,target):\n    a = df[feature]\n    dataset = df.copy()\n    cet_25 = a.quantile(0.25)\n    cet_50 = a.quantile(0.50)\n    cet_75 = a.quantile(0.75)\n    q = cet_75 - cet_25\n    out_min = cet_25-3*q\n    out_max = cet_75+3*q\n    print(\"{} out_max_values:{}\".format(feature,str(out_max)))\n    fig,ax = plt.subplots(1,1,figsize=(10,6))\n    sns.regplot(data=dataset,x=feature,y=target)\n#     ax.axvline(out_min,0,1,color=\"b\")\n    ax.axvline(out_max,0,1,color=\"r\")\n    ax.set_title(feature+\"-Outliers\")","398b59cc":"num = []\ncat = []\nfor i in df.drop(columns=[\"Id\",\"type\"]).columns.tolist():\n    if (df[i].nunique()) < 10 or df[i].dtypes == \"object\":\n        cat.append(i)\n    else:\n        num.append(i)","0db2af90":"for col in num:\n    outlier(df[df[\"type\"] == 0],col,\"SalePrice\")","7a443ad0":"# new_cat_col = \n# new_num_col\nfind_col_cat = [\"MSSubClass\",\"OverallQual\",\"YearBuilt\",\"YearRemodAdd\",\"TotRmsAbvGrd\",\"MoSold\"]\nnew_cat_col = cat + find_col_cat\nfor i in find_col_cat:\n    num.remove(i)","332e96f4":"from sklearn.ensemble import IsolationForest\n\nlotf_out = df[df[\"type\"] == 0][\"LotFrontage\"]\nlotf_out = lotf_out[lotf_out>136]\n\nlotarea_out = df[df[\"type\"] == 0][\"LotArea\"]\nlotarea_out = lotarea_out[lotarea_out>23746]\n\nmaxvnr_out = df[df[\"type\"] == 0][\"MasVnrArea\"]\nmaxvnr_out = maxvnr_out[maxvnr_out>657]\n\nBsmtFin_out = df[df[\"type\"] == 0][\"BsmtFinSF1\"]\nBsmtFin_out = BsmtFin_out[BsmtFin_out>2849]\n\nTotalBsm_out = df[df[\"type\"] == 0][\"TotalBsmtSF\"]\nTotalBsm_out = TotalBsm_out[TotalBsm_out>2806]\n\nstFl_out = df[df[\"type\"] == 0][\"1stFlrSF\"]\nstFl_out = stFl_out[stFl_out>2919]\n\nGrLiv_out = df[df[\"type\"] == 0][\"GrLivArea\"]\nGrLiv_out = GrLiv_out[GrLiv_out>3719]\n\nGarag_out = df[df[\"type\"] == 0][\"GarageArea\"]\nGarag_out = Garag_out[Garag_out>1300]\n\nWoodDeck_out = df[df[\"type\"] == 0][\"WoodDeckSF\"]\nWoodDeck_out = WoodDeck_out[WoodDeck_out>672]\n\nopenporch_out = df[df[\"type\"] == 0][\"OpenPorchSF\"]\nopenporch_out = openporch_out[openporch_out>272]","6a11f6f3":"Isaof = IsolationForest()\nIsaof.fit(np.array(df[df[\"type\"] == 0][\"LotFrontage\"]).reshape(-1,1))\nIsaof.predict(np.array(lotf_out).reshape(-1,1))","4a8d3349":"Isaof.fit(np.array(df[df[\"type\"] == 0][\"LotArea\"]).reshape(-1,1))\nIsaof.predict(np.array(lotarea_out).reshape(-1,1))","3c7635c8":"Isaof.fit(np.array(df[df[\"type\"] == 0][\"MasVnrArea\"]).reshape(-1,1))\nIsaof.predict(np.array(maxvnr_out).reshape(-1,1))","142c4cfb":"Isaof.fit(np.array(df[df[\"type\"] == 0][\"BsmtFinSF1\"]).reshape(-1,1))\nIsaof.predict(np.array(BsmtFin_out).reshape(-1,1))","6c304dc3":"Isaof.fit(np.array(df[df[\"type\"] == 0][\"TotalBsmtSF\"]).reshape(-1,1))\nIsaof.predict(np.array(TotalBsm_out).reshape(-1,1))","eed8d567":"Isaof.fit(np.array(df[df[\"type\"] == 0][\"1stFlrSF\"]).reshape(-1,1))\nIsaof.predict(np.array(stFl_out).reshape(-1,1))","f5019b9d":"Isaof.fit(np.array(df[df[\"type\"] == 0][\"GrLivArea\"]).reshape(-1,1))\nIsaof.predict(np.array(GrLiv_out).reshape(-1,1))","a4410a0b":"Isaof.fit(np.array(df[df[\"type\"] == 0][\"GarageArea\"]).reshape(-1,1))\nIsaof.predict(np.array(Garag_out).reshape(-1,1))","8a7e2c15":"Isaof.fit(np.array(df[df[\"type\"] == 0][\"WoodDeckSF\"]).reshape(-1,1))\nIsaof.predict(np.array(WoodDeck_out).reshape(-1,1))","cb983602":"Isaof.fit(np.array(df[df[\"type\"] == 0][\"OpenPorchSF\"]).reshape(-1,1))\nIsaof.predict(np.array(openporch_out).reshape(-1,1))","2d6ddbe1":"len(df[df[\"type\"] == 1])","1cb97a8f":"df_test = df[df[\"type\"] ==1]\ndf_train = df[df[\"type\"] == 0]\n\ndf_train = df_train.drop(df_train[df_train[\"LotFrontage\"] > 136].index,axis=0)\ndf_train = df_train.drop(df_train[df_train[\"LotArea\"] > 23746].index,axis=0)\ndf_train = df_train.drop(df_train[(df_train[\"MasVnrArea\"] > 657)].index,axis=0)\ndf_train = df_train.drop(df_train[df_train[\"BsmtFinSF1\"] > 2849].index,axis=0)\ndf_train = df_train.drop(df_train[df_train[\"TotalBsmtSF\"] > 2806].index,axis=0)\ndf_train = df_train.drop(df_train[df_train[\"1stFlrSF\"] > 2919].index,axis=0)\ndf_train = df_train.drop(df_train[df_train[\"GrLivArea\"] > 3719].index,axis=0)\ndf_train = df_train.drop(df_train[df_train[\"GarageArea\"] > 1300].index,axis=0)\ndf_train = df_train.drop(df_train[df_train[\"WoodDeckSF\"] > 672].index,axis=0)\ndf_train = df_train.drop(df_train[df_train[\"OpenPorchSF\"] > 272].index,axis=0)\n\ndf = pd.concat([df_train,df_test],axis=0)","449e4de4":"df[\"YearLength_of_stay\"] = df[\"YrSold\"] - df[\"YearBuilt\"]\ndf[\"house_layers\"] = df[\"2ndFlrSF\"].apply(lambda x:1 if x>0 else 2)\ndf[\"total_areas\"] = df[\"TotalBsmtSF\"] + df[\"GrLivArea\"]","c503a71e":"fig,ax = plt.subplots(1,3,figsize=(15,6))\nlis = [\"YearLength_of_stay\",\"house_layers\",\"total_areas\"]\nfor col,ax in zip(lis,ax.flat):\n    sns.regplot(data=df,x=col,y=\"SalePrice\",ax=ax)\n    ax.set_title(\"{} and SalePrice regplot.\".format(col))","47870173":"new_cat_col = new_cat_col + [\"house_layers\"]\nnum = num + [\"YearLength_of_stay\",\"total_areas\"]","0f85cd96":"cat_corr = abs(df[df[\"type\"] == 0][new_cat_col+[\"SalePrice\"]].corr(method=\"kendall\")[\"SalePrice\"])\ncat_corr = cat_corr[cat_corr>0.1]\ncat_corr","c70563c6":"num_corr = abs(df[df[\"type\"] == 0][num].corr(method=\"spearman\")[\"SalePrice\"])\nnum_corr = num_corr[num_corr>0.1]\nnum_corr","b819643c":"cat_col = list(cat_corr.index)\nnum_col = list(num_corr.index)\ncol = list(set(cat_col+num_col+[\"Id\",\"type\"]))\ndf = df[col]\nnum_df = df[num_col+[\"type\"]]\nnum_df","90389682":"fig,ax = plt.subplots(4,4,figsize=(20,20))\ncols = num_df.drop(columns=[\"SalePrice\",\"type\"]).columns.tolist()\ndata = num_df[num_df[\"type\"] == 0]\nfor col,ax in zip(cols,ax.flat):\n    sns.scatterplot(data=data,x=col,y=\"SalePrice\",ax=ax)\n    ax.set_title(f\"{col} and SalePrice -- regplot\")","da4f1c07":"from sklearn.preprocessing import StandardScaler\nscala_col = num_df.drop(columns=[\"type\",\"SalePrice\"]).columns.tolist()\nfor col in scala_col:\n    rs = StandardScaler()\n    rs.fit(df[df[\"type\"] == 0][col].values.reshape(-1,1))\n    df[col] = rs.transform(df[col].values.reshape(-1,1))","336efb62":"cat_col_ = []\nfor i in cat_col:\n    if i == \"SalePrice\":\n        pass\n    else:\n        cat_col_.append(i)","fad69d01":"for col in cat_col_:\n    df = pd.get_dummies(df,columns=[col],drop_first=True)","705c823f":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score,KFold,learning_curve\ntest = df[df[\"type\"] == 1]   #test data\ntrain = df[df['type'] == 0]  #train data\nids = test[[\"Id\"]]\ntest_submission = test.drop(columns=[\"Id\",\"type\",\"SalePrice\"])","b45c664f":"def learn_curve(model,trainx,trainy,k):\n    \"\"\"\n    :model    Regression model\n    \uff1ax and y     Characteristic data and target data   \n    \uff1ak    Represents cross-validation, and the default is 5 times.\n    \"\"\"\n    trainsize,train_score,test_score = learning_curve(estimator=model,X=trainx,y=trainy,cv=k,scoring=\"neg_mean_squared_error\")\n    train_mean = np.mean(train_score,axis=1)\n    test_mean = np.mean(test_score,axis=1)\n    fig,ax = plt.subplots(1,1,figsize=(6,6))\n    plt.plot(trainsize,-train_mean,color='r',linestyle=\"--\",label=\"train_score\")\n    plt.plot(trainsize,-test_mean,linestyle=\":\",label=\"test_score_men\")\n    plt.title(\"learning curve--Observe the degree of fit\")\n    plt.legend()\n    plt.show()    ","2aef43dd":"train_x = train.drop(columns=[\"type\",\"Id\",\"SalePrice\"])\ntrain_y = train[[\"SalePrice\"]]\nline = LinearRegression()\nlearn_curve(model=line,trainx=train_x.values,trainy=train_y.values,k=5)","0d90be28":"xtrain,xtest,ytrain,ytest = train_test_split(train_x,train_y,test_size=0.25,random_state=123)\nline.fit(xtrain,ytrain)\nline_pred = line.predict(xtest)\nline_error = mean_squared_error(ytest,line_pred)\nline_test_pre = line.predict(test_submission)\nprint(\"LinearRegression mean_squared_error:{}.\".format(line_error))","62eb6c50":"from sklearn.linear_model import Ridge\nrd = Ridge()\nlearn_curve(model=rd,trainx=train_x.values,trainy=train_y.values,k=5)","6875e097":"rd.fit(xtrain,ytrain)\nrd_pred = rd.predict(xtest)\nrd_error = mean_squared_error(ytest,rd_pred)\nrd_test_pre = line.predict(test_submission)\nprint(\"rd mean_squared_error:{}.\".format(rd_error))","56eb1618":"from sklearn.ensemble import GradientBoostingRegressor\ngbdt = GradientBoostingRegressor()\nlearn_curve(model=gbdt,trainx=train_x.values,trainy=train_y.values.ravel(),k=5)","d8d15ed5":"gbdt.fit(xtrain,ytrain)\ngbdt_pred = gbdt.predict(xtest)\ngbdt_error = mean_squared_error(ytest,gbdt_pred)\ngbdt_test_pre = gbdt.predict(test_submission)\nprint(\"gbdt mean_squared_error:{}.\".format(gbdt_error))","e470cd1c":"from sklearn.model_selection import RandomizedSearchCV\nparmas={\n    \"learning_rate\":(0.1,0.5),\n    \"n_estimators\":(100,400),\n}\nrandomcv = RandomizedSearchCV(gbdt,param_distributions=parmas,random_state=123)\nrandomcv.fit(xtrain,ytrain.values.ravel())\nrandomcv.best_params_","ee1333b4":"randomcv_pred = randomcv.predict(xtest)\nrandomcv_error = mean_squared_error(ytest,randomcv_pred)\nrandomcv_test_pre = randomcv.predict(test_submission)\nprint(\"randomcv(GBDT) mean_squared_error:{}.\".format(randomcv_error))","723a6092":"from xgboost import XGBRegressor\nxgbr = XGBRegressor(seed=123)\nlearn_curve(model=xgbr,trainx=train_x.values,trainy=train_y.values.ravel(),k=5)","7b975aa3":"params = {\n    \n    \"gamma\":(0.1,0.3),\n    \"max_depth\":(6,20),\n    \"lambda\":(2,9),\n    \"subsample\":(0.5,0.8),\n    \"colsample_bytree\":(0.5,0.8)\n}\nrandomxgb = RandomizedSearchCV(xgbr,param_distributions=params,random_state=123)\nrandomxgb.fit(xtrain,ytrain)\nrandomxgb_pred = randomxgb.predict(xtest)\nrandomxgb_error = mean_squared_error(ytest,randomxgb_pred)\nrandomxgb_test_pre = randomxgb.predict(test_submission)\nprint(\"xgb best params:\",randomxgb.best_params_)\nprint(\"randomcv(xgb) mean_squared_error:{}.\".format(randomxgb_error))","bbe8d73e":"from sklearn.linear_model import SGDRegressor\nsgd = SGDRegressor()\nlearn_curve(model=sgd,trainx=train_x.values,trainy=train_y.values.ravel(),k=5)","77bb8505":"sgd.fit(xtrain,ytrain)\nsgd_pred = rd.predict(xtest)\nsgd_error = mean_squared_error(ytest,sgd_pred)\nsgd_test_pre = sgd.predict(test_submission)\nprint(\"sgd mean_squared_error:{}.\".format(sgd_error))","40b2e385":"from sklearn.linear_model import ElasticNet\nelast = ElasticNet()\nlearn_curve(model=elast,trainx=train_x.values,trainy=train_y.values.ravel(),k=5)","176007ed":"elast.fit(xtrain,ytrain)\nelast_pred = elast.predict(xtest)\nelast_error = mean_squared_error(ytest,elast_pred)\nelast_test_pre = elast.predict(test_submission)\nprint(\"elast mean_squared_error:{}.\".format(elast_error))","e1609a34":"paras = {\n    \"alpha\":(1,3),\n    \"l1_ratio\":(0.5,0.8)\n}\nrandomclast = RandomizedSearchCV(elast,param_distributions=paras,random_state=123)\n\nrandomclast.fit(xtrain,ytrain)\nrandomclast_pred = randomclast.predict(xtest)\nrandomclast_error = mean_squared_error(ytest,randomclast_pred)\nrandomclast_test_pre = randomclast.predict(test_submission)\nprint(\"randomclast best params:\",randomclast.best_params_)\nprint(\"randomclast(elast) mean_squared_error:{}.\".format(randomclast_error))","05989453":"from sklearn.svm import SVR\nsvr = SVR()\nlearn_curve(model=svr,trainx=train_x.values,trainy=train_y.values.ravel(),k=5)","c9e57d59":"paras = {\n    \"degree\":(3,7),\n    \"C\":(0.5,1)\n}\nrandomsvr = RandomizedSearchCV(svr,param_distributions=paras,random_state=123)\n\nrandomsvr.fit(xtrain,ytrain.values.ravel())\nrandomsvr_pred = randomsvr.predict(xtest)\nrandomsvr_error = mean_squared_error(ytest,randomsvr_pred)\nrandomsvr_test_pre = randomsvr.predict(test_submission)\nprint(\"randomsvr best params:\",randomsvr.best_params_)\nprint(\"randomsvr(svr) mean_squared_error:{}.\".format(randomsvr_error))","56b487a4":"total_pre = 0.2*line_test_pre + 0.3*rd_test_pre +0.1*randomcv_test_pre + 0.3*sgd_test_pre + 0.1*randomxgb_test_pre\ntotal_pre = np.mean(total_pre,axis=1)","04ef2da2":"submission =pd.DataFrame()\nsubmission[\"Id\"] = ids\nsubmission[\"SalePrice\"] = total_pre\nsubmission","63644446":"submission.to_csv('submission.csv',index=None)","98865aa0":"<div style=\"color: #fff7f7;\n           display:fill;\n           border-radius:10px;\n           border-style: solid;\n           border-color:#424949;\n           text-align:center;\n           background-color:#8ac6d1 ;\n           font-size:20px;\n           letter-spacing:0.5px;\n           padding: 0.7em;\n           text-align:left\">  \n<center> Quartile and isolated forest outlier detection results  <\/center> \n <hr>\n <ul>\n <p>\n It is perfect. We can see that the outliers detected by the quartile are also detected by the isolation forest algorithm.<br>\n This means that we can use four-digit scores to detect outliers in the future, as well as isolated forests. Now let's delete these outliers.\n     <\/p>\n <\/ul>\n <hr>\n<\/div>","ac96f1cc":"- Let's first look at the relationship between the other missing value columns and the target value column.","c824da11":"- **Use the isolated forest algorithm to detect outliers.**\n- Isolated forest is an unsupervised anomaly detection method suitable for continuous numerical data, that is, no labeled samples are needed for training, but the features need to be continuous. For how to find which points are easily isolated (isolated), iForest uses a very efficient strategy. In isolated forests, the data set is randomly divided recursively until all sample points are isolated. Under this random segmentation strategy, abnormal points usually have shorter paths.","cc3c4e66":"# View numerical outliers","711dd916":"# Modeling","ac5de15b":"- After adjusting the parameters, it was reduced by 3 points.","6a57f407":"# View missing values","57c757e0":"- **LinearRegression**","60fb9984":"- Numerical variables","539dfe21":"# Feature structure  and Encoding classification features","b8aa8c0e":"- LotFrontage\/GarageYrBlt\/MasVnrArea.These three columns are numeric, and the remaining columns are categorical.\n- For categorical data, we use the mode to fill. Note that LotFrontage has outliers, we can consider using median filling to improve its robustness.","467fe406":"- Observation results\uff1a\n1. As can be seen from the first picture, the earlier the house is built, the lower the house sale price, which is in line with our common sense of life.\n2. The price of a one-story house seems to be slightly higher than the price of a two-story house.\n3.  The larger the area, the higher the house price. This is in line with our common sense of life.","9e9c2559":"- Fence: Fence quality\n- A missing value means no fence. Obviously, there is a clear difference between an unfenced house price and a fenced house price. For the convenience of the period, we will replace the missing value with an identifier.","b3583fba":"- Analyze our target value","8f2365cc":"- Categorical variables","7c520b1f":"- **ElasticNet**","19785035":"- View outliers according to quartiles. The columns with outliers are as follows: LotFrontage\/LotArea\/MasVnrArea\/BsmtFinSF1\/BsmtFinSF2\/TotalBsmtSF\/1stFlrSF\/LowQualFinSF\/GrLivArea\/GarageArea\/WoodDeckSF\/OpenPorchSF\/EnclosedPorch\/3SsnPorch\/ScreenPorch\/PoolArea\/MoSold\n- It looks like a numeric variable, but it is actually a column of categorical variables: \n  MSSubClass\/OverallQual\/YearBuilt\/YearRemodAdd\/TotRmsAbvGrd\/MoSold","41aa7470":"<div style=\"color: #fff7f7;\n           display:fill;\n           border-radius:10px;\n           border-style: solid;\n           border-color:#424949;\n           text-align:center;\n           background-color:#8ac6d1 ;\n           font-size:20px;\n           letter-spacing:0.5px;\n           padding: 0.7em;\n           text-align:left\">  \n<center> Comparative ----Rough result  <\/center> \n <hr>\n <ul>\n <p>\n-  LinearRegression mean_squared_error:69.5265612708615.<br>\n- Ridge mean_squared_error:67.00316415552072.<br>\n- gbdt mean_squared_error:86.64929158092997.<br>\n- sgd mean_squared_error:67.00316415552074.<br>\n- xgboost mean_squared_error:88.46882213309675.<br>\n- ElasticNet mean_squared_error:127.19010126944309.<br>\n- svr mean_squared_error:180.30945633092242.\n     <\/p>\n <\/ul>\n <hr>\n <p>\n  <h>my choice:<br><\/h>\n--------You can consider using linear regression\/ridge regression\/GBDT\/SGD for model fusion, and perform a linear combination according to the respective output results as the final result.\n  <\/p>\n <hr>\n<\/div>","ae6ee0ba":"- FireplaceQu: Fireplace quality\n- The missing value is 40 percent, which means there is no fireplace. Having a fireplace will increase the structure of the house, so intuitively, the price will be higher than that without a fireplace. We use Missing to indicate no fireplace.","5aec96b9":"<div style=\"color: #fff7f7;\n           display:fill;\n           border-radius:10px;\n           border-style: solid;\n           border-color:#424949;\n           text-align:center;\n           background-color:#8ac6d1 ;\n           font-size:20px;\n           letter-spacing:0.5px;\n           padding: 0.7em;\n           text-align:left\">  \n<center> Observe the image above  <\/center> \n <hr>\n <ul>\n <p>\n- Some data has a long tail. Although this part of the data is not much, it may interfere with the model. You can decide whether to delete these long tail data according to the sample size.<br>\n- Because the amount of data is relatively small, we temporarily ignore these seemingly abnormal data, while scaling these data.\n     <\/p>\n <\/ul>\n <hr>\n<\/div>","ead1f1c9":"- The sales price is not normally distributed, so we should convert it first.","ade04a2f":"<div style=\"color: #fff7f7;\n           display:fill;\n           border-radius:10px;\n           border-style: solid;\n           border-color:#424949;\n           text-align:center;\n           background-color:#8ac6d1 ;\n           font-size:20px;\n           letter-spacing:0.5px;\n           padding: 0.7em;\n           text-align:left\">  \n<center> Comparative observation  <\/center> \n <hr>\n <ul>\n <p>\n- We can see that when using xgb with default parameters, the model is overfitting. At the same time, we can also see that the linear regression and ridge regression algorithms are not as effective as the tree model.<br>\n- Possible reason: We use one-hot encoding for data features. A large number of data features have only a small amount of data in a certain column, which affects the splitting of the tree and ultimately leads to inferior results as ordinary linear regression. <br>  \n- Considering the above results, when the model is fused, only the results of the linear model are used, and the results of the xgboost-model are not considered.\n     <\/p>\n <\/ul>\n <hr>\n<\/div>","15a4bb7a":"- PoolQC \n- Missing values in this column account for 99. The meaning of missing values is no swimming pool. We can use the identifier -Missing to fill in.","aa47526e":"- **Ridge regression**","87e8d8b5":"- **SGD**","b983a091":"<div style=\"color: #fff7f7;\n           display:fill;\n           border-radius:10px;\n           border-style: solid;\n           border-color:#424949; \n           text-align:center;\n           background-color:#8ac6d1 ;\n           font-size:20px;\n           letter-spacing:0.5px;\n           padding: 0.7em;\n           text-align:left\">  \n<center> My observation \u2705 <\/center> \n <hr>\n <ul>\n\n <li> 1stFlrSF + 2ndFlrSF = GrLivArea.\n <li>If the area of the second floor is greater than 0, it means the room has two floors, otherwise there is only one floor.\n <li>TotalBsmtSF = BsmtFinSF1+BsmtFinSF2+BsmtUnfSF\n <li>The area on the ground and the area of the underground garage can be the total area of the house\n <\/ul>\n <hr>\n<\/div>","e3593e59":"- **GBDT**","26c8f33e":"- xgboost","09ee9d84":"- As the sample size increases, the training score increases, but the test set score decreases.","9effd2bb":"- **LotArea\u2014\u2014Observation results\uff1a**\n The identification value of the isolated forest prediction is -1, which indicates that the data is an outlier, which is the same as our quartile detection result.","66e7a69c":"- Alley: Type of alley access to property\n- The missing value indicates that the hutong is not accessible, accounting for more than 90%, which means that most of the houses have not changed types, and only a few exist.","66db7a96":"# Feature selection ","5b0b4a5f":"- The model seems to be OK?","5e26aba6":"- **LotFrontage\u2014\u2014Observation results\uff1a**\n The identification value of the isolated forest prediction is -1, which indicates that the data is an outlier, which is the same as our quartile detection result.","b39506b1":"- MiscFeature: Miscellaneous feature not covered in other categories\n- This column is similar to mud. Everything that is not included in the other columns is placed in this column. From the figure, it has no substantive meaning and the meaning is not clear. For convenience, this column is deleted.","ea4193e5":"- **MasVnrArea\u2014\u2014Observation results\uff1a**\n The identification value of the isolated forest prediction is -1, which indicates that the data is an outlier, which is the same as our quartile detection result.","b6362473":"- SVR","4490612d":"- What are the characteristics of a house with a target value of more than 500,000?\n- Temporarily save the house price Id of more than 500,000.","95dd1739":"- Extract data from different columns and detect outliers through quartiles.\n- Through observation, we temporarily ignore the feature that the critical point of outliers is 0."}}