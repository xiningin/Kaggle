{"cell_type":{"485578d6":"code","610c6111":"code","0c3d0e67":"code","2b341005":"code","7914ace0":"code","be373670":"code","ac0f3e76":"code","32e2a7f8":"code","17ad5c33":"code","6f3bda19":"code","8e30759c":"code","5534264f":"code","11f4235e":"code","7e7ec082":"code","05843283":"code","2b2a1a3d":"code","80d90f97":"markdown","360a26b1":"markdown","4c51b170":"markdown","ac248e7f":"markdown","4786e92e":"markdown","6729cb65":"markdown","08ce7625":"markdown","31e8b4a3":"markdown","c2159039":"markdown","14d9916b":"markdown","677fa44c":"markdown"},"source":{"485578d6":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler","610c6111":"data=pd.read_csv('..\/data\/raw\/train.csv')\ndata_predict=pd.read_csv('..\/data\/raw\/test.csv')\n#data.columns = data.columns.str.replace(' ', '')\nX=data.drop([\"SalePrice\"],1)\ny=data.SalePrice.values\n#Dropping the 5 lines with NaNs before appending our test set\nX=X.dropna(subset=[\"MSZoning\", \"SaleType\"],axis=0)\nsep=len(X) #this should give us our separator\nX=X.append(data_predict)\nX","0c3d0e67":"#Here we might take drop NaN columns to see if it improves\nX=X.drop(columns=[\"Alley\",\"PoolQC\",\"Fence\",\"MiscFeature\"])","2b341005":"#Initial number of NaNs\ncolumns=list(X.columns) #All column names\nobjects=X.select_dtypes(include='object').columns\nnumbers=X.select_dtypes(exclude='object').columns#All the object columns needed to be encoded\nfor i in objects:\n    dummy=pd.get_dummies(X[i])\n    X=pd.concat([X,dummy],axis=1)\nX=X.drop(columns=objects,axis=1)\n","7914ace0":"#Now we take care of our numerical varaibles by using imputescaler\nfor i in numbers[1:]:\n    sc=SimpleImputer(missing_values=np.nan, strategy='mean')\n    X[i]=sc.fit_transform(X[i].values.reshape(-1,1))\nsum(X.isnull().sum()) #Now we have no missing values","be373670":"#We drop de Id class\nX=X.drop(columns=\"Id\")","ac0f3e76":"for i in numbers[1:]:\n    sc=StandardScaler()\n    X[i]=sc.fit_transform(X[i].values.reshape(-1,1))\nX","32e2a7f8":"#Feature scaling our y variable\nsc_y=StandardScaler()\ny=sc_y.fit_transform(y.reshape(-1,1))\ny","17ad5c33":"data_train=X.iloc[:1460,:]\ndata_test=X.iloc[1460:,:]","6f3bda19":"X_train,X_test,y_train,y_test=train_test_split(data_train, y, test_size = 0.2, random_state = 0)","8e30759c":"from sklearn.svm import SVR\nregressor = SVR(kernel = 'rbf')\nregressor.fit(X_train, y_train)","5534264f":"y_pred=sc_y.inverse_transform(regressor.predict(X_test))","11f4235e":"regressor.score(X_test,y_test)","7e7ec082":"y_pred=sc_y.inverse_transform(regressor.predict(data_test)) #Predictions created","05843283":"results=pd.DataFrame({\"Id\":data_predict.Id.values,\"SalePrice\":y_pred}) #Format for csv","2b2a1a3d":"results.to_csv('..\/predictions\/house_pricing.csv') #CSV export","80d90f97":"# Creating our SVM Regressor model","360a26b1":"# Data Preprocessing and Feature Scaling","4c51b170":"### Feature Scaling","ac248e7f":"## Importing our datasets and splitting X and Y","4786e92e":"# Here we create our predictions for submitting to kaggle","6729cb65":"#### We got 82% Accuracy... Not bad","08ce7625":"### Dummies for categorical","31e8b4a3":"## Importing our libraries","c2159039":"### Now we split again our data test and separate our train data","14d9916b":"### Dealing with numeric variables","677fa44c":"# House pricing-Kaggle \n## by: Guillermo Campollo\n### 5\/16\/2020"}}