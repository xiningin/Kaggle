{"cell_type":{"169f15fc":"code","46a6d3f8":"code","69a80ce2":"code","da89d208":"code","5aa63777":"code","8dee8ad0":"code","484d8548":"code","6c1d64bc":"code","4cf12b57":"code","86c830d3":"markdown","78d3e658":"markdown","07d97855":"markdown"},"source":{"169f15fc":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import f1_score\nfrom sklearn.svm import SVC\nimport seaborn as sns\nimport matplotlib.animation as animation\nfrom sklearn.metrics import plot_confusion_matrix","46a6d3f8":"data = pd.read_csv(r\"..\/input\/iris-dataset\/iris_.csv\")\ndata = data.drop(['Unnamed: 0'], axis=1)\ndata.head()","69a80ce2":"#Vizualising correlation between data\nplt.figure(figsize=(10,8), dpi= 80)\nsns.pairplot(data, hue=\"Species\")\nplt.show()","da89d208":"#preprocessing of data\nX = data[[\"Sepal.Length\",\"Sepal.Width\",\"Petal.Length\",\"Petal.Width\"]].values\ny = data[\"Species\"].values\nX = StandardScaler().fit(X).transform(X.astype(float))","5aa63777":"#confusion Matrix \ndef conf_matrix(classifier_):\n  class_names = ['setosa','versicolor','virginia']\n\n  np.set_printoptions(precision=2)\n\n  # Plot non-normalized confusion matrix\n  disp = plot_confusion_matrix(classifier_, X_test, y_test,\n                                display_labels=class_names,\n                                cmap=plt.cm.Blues,\n                                normalize='true')\n  disp.ax_.set_title(\"Normalized confusion matrix\")\n  plt.show()","8dee8ad0":"#calculating best test_size\nk=[i\/10 for i in range(1,10)]\naccu = []\nfor i in range(1,10):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=k[i-1], random_state = 42)\n    LR = LogisticRegression().fit(X_train,y_train)\n    result = f1_score(y_test, LR.predict(X_test), average='weighted')\n    accu.append(result)\n\n#using best test size obtained from above\nk.reverse()\naccu.reverse()\nts = (10-(accu.index(max(accu))+1))\/10\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ts, random_state = 42)\n\nplt.plot(k,accu, color=\"red\")\nplt.title('Test_size VS Accuracy')\nplt.xlabel('Test_size')\nplt.ylabel('F1_score -(accuracy)')\narrowprops=dict(color='blue', linewidth=1, mutation_scale=150)\nxy=(ts, max(accu))\nplt.annotate('(%s, %s)' % xy, xy=xy)\nplt.annotate('Maximum', xy=xy, xytext=(ts-0.13, max(accu)-0.04), xycoords='data', textcoords='data', arrowprops=arrowprops)\nprint(\"We have taken test size which has maximum accuracy with least train size\")\nplt.show()","484d8548":"#Using Logisitic Regression \nLR = LogisticRegression().fit(X_train,y_train)\nresult = f1_score(y_test, LR.predict(X_test), average='micro')","6c1d64bc":"conf_matrix(LR)\nprint(\"Model Score = \",result)","4cf12b57":"svm_ = SVC(gamma='auto').fit(X_train,y_train)\nconf_matrix(svm_)\n#test_size = 0.3\nprint(\"Model score = \",f1_score(y_test, svm_.predict(X_test), average='micro'))","86c830d3":"# Logistic Regression","78d3e658":"### From above we have concluded that for *test_size = 0.3*, and Using `LogisticRegression` having **average Parameter as micro** gives us **Model score** of **1**.  \n### We also checked accuracy for `svm.SVC` which also result in **Model score** of **1** with *test_size = 0.3*.","07d97855":"# Support Vector Machine (SVM)"}}