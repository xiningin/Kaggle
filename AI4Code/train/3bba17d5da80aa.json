{"cell_type":{"833ea156":"code","df1a77ff":"code","fe303ca8":"code","96b23823":"code","35a66c73":"code","c7e6c619":"code","58ff8671":"code","f7d6ab93":"code","e27ffebf":"code","3988327f":"code","fb2a2800":"code","d316896a":"code","5f31393a":"code","b6d175b1":"code","69f80e62":"code","f3c36384":"code","818d9ef0":"code","6a45f120":"code","84f36b1b":"code","f0599b81":"code","1bff0827":"code","6bf5c694":"code","85298cf6":"code","4f77a789":"code","4c232496":"code","3b6fb952":"markdown","7e5a231d":"markdown","8e4239c8":"markdown","f8710d79":"markdown","73667569":"markdown","5d8611f3":"markdown","e13b93eb":"markdown","3de4d754":"markdown","8d246acc":"markdown","fada8546":"markdown","68f5e378":"markdown","20ce6d3c":"markdown","d33a013f":"markdown","a1051c2c":"markdown","5005ea7a":"markdown","6393ba0d":"markdown","b057d9b5":"markdown","a62cc818":"markdown"},"source":{"833ea156":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt","df1a77ff":"data = pd.read_csv('\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv')","fe303ca8":"data.head()","96b23823":"data.columns","35a66c73":"data.shape","c7e6c619":"data.describe().T","58ff8671":"data.info()","f7d6ab93":"diabetes_data_copy = data.copy(deep = True)\ndiabetes_data_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = diabetes_data_copy[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\n\n## showing the count of Nans\nprint(diabetes_data_copy.isnull().sum())","e27ffebf":"p= data.hist(figsize=(20,20))","3988327f":"sns.pairplot(data,hue= 'Outcome')","fb2a2800":"corr = data.corr()\ncorr.style.background_gradient()","d316896a":"p = sns.heatmap(corr, annot = True)","5f31393a":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nscaled_data_X =  pd.DataFrame(sc_X.fit_transform(data.drop([\"Outcome\"],axis = 1),),\n        columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n       'BMI', 'DiabetesPedigreeFunction', 'Age'])\nscaled_data_Y = data.Outcome\nscaled_data_X.head()","b6d175b1":"scaled_data_X.hist(figsize=(20,10))","69f80e62":"from sklearn.metrics import accuracy_score, precision_score","f3c36384":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(scaled_data_X,scaled_data_Y,train_size = 0.8 ,random_state=42)","818d9ef0":"from sklearn.neighbors import KNeighborsClassifier\nfor i in range(1,15):\n  knn = KNeighborsClassifier(n_neighbors=i)\n  knn = knn.fit(X_train, y_train)\n  print(i, knn.score(X_test,y_test))","6a45f120":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt = dt.fit(X_train,y_train)\nprint(dt.score(X_test,y_test))","84f36b1b":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier(n_estimators= 275, min_samples_leaf= 0.12 ,random_state= 2)\nrfc = rfc.fit(X_train,y_train)\ny_pred = rfc.predict(X_test)\nprint(accuracy_score(y_pred,y_test))","f0599b81":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nbagging = BaggingClassifier(KNeighborsClassifier(),n_estimators=200,random_state= 42222)\nbagging = bagging.fit(X_train, y_train)\nprint(bagging.score(X_test,y_test))","1bff0827":"from sklearn.ensemble import AdaBoostClassifier\nada = AdaBoostClassifier(n_estimators = 200, learning_rate= 1, random_state= 2)\nada = ada.fit(X_train, y_train)\nprint(ada.score(X_test,y_test))","6bf5c694":"from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier(n_estimators = 300, learning_rate= 1, random_state= 2)\ngb = gb.fit(X_train, y_train)\nprint(gb.score(X_test,y_test))","85298cf6":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import accuracy_score\n\ndt = DecisionTreeClassifier(max_depth=2,random_state=1)\nlr = LogisticRegression(random_state=1)\nknn = KNeighborsClassifier()\nClassifiers = {'LogisticRegression':lr,'KNearestNeighbors':knn,'DecisionTreeClassifier':dt}\nfor clf_name,clf in Classifiers.items():\n  clf.fit(X_train,y_train)\n  y_pred = clf.predict(X_test)\n  print('{:s}:{:.3f}'.format(clf_name,100*accuracy_score(y_test,y_pred)))","4f77a789":"vc = VotingClassifier(estimators = Classifiers.items())\nvc.fit(X_train,y_train)\ny_pred = vc.predict(X_test)\nprint('Voting Classifier:{:.3f}'.format(100*accuracy_score(y_test,y_pred)))","4c232496":"vc_ans = vc.predict(X_test)\nanswer = pd.DataFrame({\"Voting Classifier\": vc_ans})\nanswer.sample(15)","3b6fb952":"##**Bagging Classifier**","7e5a231d":"\n### histogram","8e4239c8":"# Modelling","f8710d79":"###**Splitting into train and test data**","73667569":"##**Random Forest**","5d8611f3":"# **Pima Indians Diabetes**\n## Predict the onset of diabetes based on diagnostic measures","e13b93eb":"## Pair plot for data","3de4d754":"##**Importing libraries and dataset**","8d246acc":"## Intial Data Exploration","fada8546":"## Scaling data","68f5e378":"##**Voting Classifier**","20ce6d3c":"## **AdaBoost**","d33a013f":"##**KNN**","a1051c2c":"##**Gradient Boosting**","5005ea7a":"##**Exploratory Data Analysis**","6393ba0d":"Every column is positively correlated with the outcome and the glucose has the most impact","b057d9b5":"###**Voting Classifier has most accuracy 76.6**","a62cc818":"##**Decision Tree**"}}