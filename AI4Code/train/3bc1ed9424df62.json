{"cell_type":{"de940d9f":"code","3036a91e":"code","94a55a29":"code","83cba2dc":"code","f503c888":"code","0d3ae6b8":"code","1b03fa2c":"code","dfb1c6ce":"code","4196b0cb":"code","b8c088bd":"code","d127970c":"code","2ac88d1a":"code","1bd9c528":"code","a5596db7":"code","49330fb4":"code","4359b149":"code","e74a4170":"code","7b7d679b":"code","7445a419":"code","9a66a84e":"markdown","8ef8d9a7":"markdown","8f840e83":"markdown","46340214":"markdown"},"source":{"de940d9f":"# Install Pycocotools\n!pip install 'git+https:\/\/github.com\/cocodataset\/cocoapi.git#subdirectory=PythonAPI'\n# Install detectron 2\n!python -m pip install detectron2 -f https:\/\/dl.fbaipublicfiles.com\/detectron2\/wheels\/cu102\/torch1.7\/index.html","3036a91e":"%matplotlib inline\nfrom pycocotools.coco import COCO\nimport numpy as np\nimport skimage.io as io\nimport matplotlib.pyplot as plt\nimport pylab\nimport random\npylab.rcParams['figure.figsize'] = (8.0, 10.0)# Import Libraries\n\n# For visualization\nimport os\nimport seaborn as sns\nfrom matplotlib import colors\nfrom tensorboard.backend.event_processing import event_accumulator as ea\nfrom PIL import Image\n\n# Scipy for calculating distance\nfrom scipy.spatial import distance","94a55a29":"# I am visualizing some images in the 'val\/' directory\n\ndataDir='..\/input\/coco-car-damage-detection-dataset\/val'\ndataType='COCO_val_annos'\nmul_dataType='COCO_mul_val_annos'\nannFile='{}\/{}.json'.format(dataDir,dataType)\nmul_annFile='{}\/{}.json'.format(dataDir,mul_dataType)\nimg_dir = \"..\/input\/coco-car-damage-detection-dataset\/img\"","83cba2dc":"# initialize coco api for instance annotations\ncoco=COCO(annFile)\nmul_coco=COCO(mul_annFile)","f503c888":"import torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())","0d3ae6b8":"assert torch.__version__.startswith(\"1.7\")","1b03fa2c":"import detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# import some common libraries\nimport numpy as np\nimport os, json, cv2, random\nimport matplotlib.pyplot as plt\nimport skimage.io as io\n\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\nfrom detectron2.engine import DefaultTrainer\nfrom detectron2.utils.visualizer import ColorMode\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.data import build_detection_test_loader\n\n# Set base params\nplt.rcParams[\"figure.figsize\"] = [16,9]","dfb1c6ce":"# To find out inconsistent CUDA versions, if there is no \"failed\" word in this output then things are fine.\n!python -m detectron2.utils.collect_env","4196b0cb":"dataset_dir = \"..\/input\/coco-car-damage-detection-dataset\"\nimg_dir = \"img\/\"\ntrain_dir = \"train\/\"\nval_dir = \"val\/\"","b8c088bd":"from detectron2.data.datasets import register_coco_instances\nregister_coco_instances(\"car_dataset_val\", {}, os.path.join(dataset_dir,val_dir,\"COCO_val_annos.json\"), os.path.join(dataset_dir,img_dir))\nregister_coco_instances(\"car_mul_dataset_val\", {}, os.path.join(dataset_dir,val_dir,\"COCO_mul_val_annos.json\"), os.path.join(dataset_dir,img_dir))","d127970c":"#get configuration\ncfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml\"))\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # only has one class (damage) + 1\ncfg.MODEL.RETINANET.NUM_CLASSES = 2 # only has one class (damage) + 1\ncfg.MODEL.WEIGHTS = os.path.join(\"..\/input\/coco-damage-detection-trained-models\/damage_segmentation_model.pth\")\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 \ncfg['MODEL']['DEVICE']='cuda'#or cpu\ndamage_predictor = DefaultPredictor(cfg)","2ac88d1a":"cfg_mul = get_cfg()\ncfg_mul.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation\/mask_rcnn_R_50_FPN_3x.yaml\"))\ncfg_mul.MODEL.ROI_HEADS.NUM_CLASSES = 6  # only has five classes (headlamp,hood,rear_bumper,front_bumper_door) + 1\ncfg_mul.MODEL.RETINANET.NUM_CLASSES = 6 # only has five classes (headlamp,hood,rear_bumper,front_bumper_door) + 1\ncfg_mul.MODEL.WEIGHTS = os.path.join(\"..\/input\/coco-damage-detection-trained-models\/part_segmentation_model.pth\")\ncfg_mul.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7 \ncfg_mul['MODEL']['DEVICE']='cuda' #or cpu\npart_predictor = DefaultPredictor(cfg_mul)","1bd9c528":"def detect_damage_part(damage_dict, parts_dict):\n  \"\"\"\n  Returns the most plausible damaged part for the list of damages by checking the distance \n  between centers centers of damage_polygons and parts_polygons\n\n  Parameters\n  -------------\n   damage_dict: dict\n                Dictionary that maps damages to damage polygon centers.\n   parts_dict: dict\n                Dictionary that maps part labels to parts polygon centers.\n  Return\n  ----------\n  part_name: str\n            The most plausible damaged part name.\n  \"\"\"\n  try:\n    max_distance = 10e9\n    assert len(damage_dict)>0, \"AssertError: damage_dict should have atleast one damage\"\n    assert len(parts_dict)>0, \"AssertError: parts_dict should have atleast one part\"\n    max_distance_dict = dict(zip(damage_dict.keys(),[max_distance]*len(damage_dict)))\n    part_name = dict(zip(damage_dict.keys(),['']*len(damage_dict)))\n\n    for y in parts_dict.keys():\n        for x in damage_dict.keys():\n          dis = distance.euclidean(damage_dict[x], parts_dict[y])\n          if dis < max_distance_dict[x]:\n            part_name[x] = y.rsplit('_',1)[0]\n\n    return list(set(part_name.values()))\n  except Exception as e:\n    print(e)","a5596db7":"damage_class_map= {0:'damage'}\nparts_class_map={0:'headlamp',1:'rear_bumper', 2:'door', 3:'hood', 4: 'front_bumper'}","49330fb4":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize =(16,12))\nim = io.imread(\"https:\/\/di-uploads-pod6.dealerinspire.com\/carhopredesign\/uploads\/2018\/05\/Car-scratches-silver-bumper_45002223.jpg\")\n\n#damage inference\ndamage_outputs = damage_predictor(im)\ndamage_v = Visualizer(im[:, :, ::-1],\n                   metadata=MetadataCatalog.get(\"car_dataset_val\"), \n                   scale=0.5, \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n)\ndamage_out = damage_v.draw_instance_predictions(damage_outputs[\"instances\"].to(\"cpu\"))\n\n#part inference\nparts_outputs = part_predictor(im)\nparts_v = Visualizer(im[:, :, ::-1],\n                   metadata=MetadataCatalog.get(\"car_mul_dataset_val\"), \n                   scale=0.5, \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n)\nparts_out = parts_v.draw_instance_predictions(parts_outputs[\"instances\"].to(\"cpu\"))\n\n#plot\nax1.imshow(damage_out.get_image()[:, :, ::-1],)\nax2.imshow(parts_out.get_image()[:, :, ::-1])","4359b149":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize =(16,12))\nim = io.imread(\"https:\/\/www.thesupercarblog.com\/wp-content\/uploads\/2019\/02\/Dent-removal.jpg\")\n\n#damage inference\ndamage_outputs = damage_predictor(im)\ndamage_v = Visualizer(im[:, :, ::-1],\n                   metadata=MetadataCatalog.get(\"car_dataset_val\"), \n                   scale=0.5, \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n)\ndamage_out = damage_v.draw_instance_predictions(damage_outputs[\"instances\"].to(\"cpu\"))\n\n#part inference\nparts_outputs = part_predictor(im)\nparts_v = Visualizer(im[:, :, ::-1],\n                   metadata=MetadataCatalog.get(\"car_mul_dataset_val\"), \n                   scale=0.5, \n                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n)\nparts_out = parts_v.draw_instance_predictions(parts_outputs[\"instances\"].to(\"cpu\"))\n\n#plot\nax1.imshow(damage_out.get_image()[:, :, ::-1],)\nax2.imshow(parts_out.get_image()[:, :, ::-1])","e74a4170":"damage_prediction_classes = [ damage_class_map[el] + \"_\" + str(indx) for indx,el in enumerate(damage_outputs[\"instances\"].pred_classes.tolist())]\ndamage_polygon_centers = damage_outputs[\"instances\"].pred_boxes.get_centers().tolist()\ndamage_dict = dict(zip(damage_prediction_classes,damage_polygon_centers))","7b7d679b":"\nparts_prediction_classes = [ parts_class_map[el] + \"_\" + str(indx) for indx,el in enumerate(parts_outputs[\"instances\"].pred_classes.tolist())]\nparts_polygon_centers =  parts_outputs[\"instances\"].pred_boxes.get_centers().tolist()\n\n\n\n#Remove centers which lie in beyond 800 units\nparts_polygon_centers_filtered = list(filter(lambda x: x[0] < 800 and x[1] < 800, parts_polygon_centers))\nparts_dict = dict(zip(parts_prediction_classes,parts_polygon_centers_filtered))","7445a419":"print(\"Damaged Parts: \",detect_damage_part(damage_dict,parts_dict))","9a66a84e":"For now allowing multiple polygons of same class label","8ef8d9a7":"For now allowing multiple polygons of same class label","8f840e83":"# <center><img src=\"https:\/\/raw.githubusercontent.com\/facebookresearch\/detectron2\/master\/.github\/Detectron2-Logo-Horz.svg\"><center\/>","46340214":"#### Register Train Dataset, so that we can use its Metadata"}}