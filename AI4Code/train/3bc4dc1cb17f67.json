{"cell_type":{"cce1bbe5":"code","18b56187":"code","8690be43":"code","4960380f":"code","695ab3cd":"code","a0a40be0":"code","9ce35042":"code","4d5dc4ac":"code","2c4a35b5":"code","1a01d995":"code","c03326a4":"markdown"},"source":{"cce1bbe5":"train_folder = '\/kaggle\/input\/smiledetection\/datasets\/train_folder\/'\ntest_folder = '\/kaggle\/input\/smiledetection\/datasets\/test_folder\/'","18b56187":"!pip install imutils","8690be43":"import numpy as np\nimport os\nimport argparse\nimport cv2\nfrom imutils import paths\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Layer,Conv2D,Activation,MaxPool2D,Dense,Flatten,Dropout\nfrom tensorflow.keras.optimizers import SGD\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n\n\n\ndef dataextractor(path,height=32,width=32):\n    data=[]\n    labels = []\n    imagepaths = list(paths.list_images(path))\n    for imagepath in imagepaths:\n        image = cv2.imread(imagepath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        image = cv2.resize(image,(height,width),interpolation=cv2.INTER_AREA)\n        image = img_to_array(image)\n        label = imagepath.split(os.sep)[-2]\n        label = int(label)\n        labels.append(label)\n        data.append(image)\n    return np.array(data,dtype='float')\/255.0,np.array(labels)\n    # splitting the data into train and test\n\ntrain_X,train_y =dataextractor(train_folder)\ntest_X,test_y = dataextractor(test_folder)\n\n# (train_X,test_X,train_y,test_y) = train_test_split(data,labels,test_size=0.2,random_state=123)\n\nheight = 32\nwidth = 32\ndepth =1\nclasses=2\n\ninput_shape = (width,height,depth)\n\n\n\n\n\n\n\n\n\n\n","4960380f":"train_y = train_y.reshape((-1,1))\ntest_y = test_y.reshape((-1,1))","695ab3cd":"print(train_X.shape)\nprint(train_y.shape)\nprint(test_X.shape)\nprint(test_y.shape)","a0a40be0":"sgd = SGD(lr=0.01)\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), input_shape=input_shape))\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nmodel.summary()","9ce35042":"H = model.fit(train_X,train_y,validation_data=(test_X,test_y),epochs=15,batch_size=32)\n\n\n","4d5dc4ac":"from sklearn.metrics import classification_report\nprint(\"[INFO] evaluating network...\")\npredictions = model.predict(test_X, batch_size=64)\npredicted_val = [int(round(p[0])) for p in predictions]\nprint(\"classification report \",classification_report(test_y,predicted_val,target_names=['smiling','not_smiling']))","2c4a35b5":"\n## ploting the training plot and the validation plot\n\nplt.figure(figsize=(10,8))\nplt.plot(np.arange(0,15),H.history['loss'],label='loss')\nplt.plot(np.arange(0,15),H.history['val_loss'],label='val_loss')\nplt.plot(np.arange(0,15),H.history['accuracy'],label='accuracy')\nplt.plot(np.arange(0,15),H.history['val_accuracy'],label='val_accuracy')\nplt.xlabel('Epchos')\nplt.ylabel('Percentage')\nplt.title('Training &validation Loss and accuracy Plot')\nplt.legend()\nplt.show()\n","1a01d995":"print(\"[INFO] serializing network...\")\nmodel.save('smile.hdf5')","c03326a4":"## Please Do Upvote "}}