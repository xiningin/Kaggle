{"cell_type":{"4f6b7d53":"code","8e60b580":"code","fa082697":"code","ff4f9c4d":"code","ce145825":"code","dd4bd686":"code","ad38dd52":"code","e60f4467":"code","4b577f38":"code","edec8432":"code","70625eb3":"code","179dd544":"code","df38fd8f":"code","796c0318":"code","5a91754a":"code","663a036c":"code","0f4f2929":"markdown","3281c9e2":"markdown","25bbd086":"markdown","30a6e7e5":"markdown","6479789f":"markdown","71c4f93b":"markdown","2cdf502b":"markdown","e7fb5595":"markdown"},"source":{"4f6b7d53":"#Importing helpful libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns\nfrom PIL import Image\nimport os\nprint(os.listdir(\"..\/input\"))","8e60b580":"#Train and Test folder directory\nos.listdir(\"..\/input\/car_data\/car_data\")","fa082697":"#Making seperate variables for train and test directories\ntrain_dir = \"..\/input\/car_data\/car_data\/train\"\ntest_dir = \"..\/input\/car_data\/car_data\/test\"","ff4f9c4d":"#Dictionary that has name of car class as key and image name as its values\ncar_names_train = {}\n\nfor i in os.listdir(train_dir):\n    car_names_train[i] = os.listdir(train_dir + '\/' + i)","ce145825":"#Code to create two lists for class name and image directories corresponding to it\ncar_images_ls = []\ncar_names_ls = []\ncar_classes = []\ncar_directories = []\n\nfor i in car_names_train:\n    car_classes.append(i)\n\nfor i,j in enumerate(car_names_train.values()):\n    for img in j:\n        car_images_ls.append(img)\n        car_names_ls.append(car_classes[i])\n        \nfor i in range(len(car_names_ls)):\n    car_directories.append(train_dir + '\/' + car_names_ls[i] + '\/' + car_images_ls[i])","dd4bd686":"#Sample image to check the consistency of the two lists\nplt.imshow(Image.open(car_directories[1000]))\nplt.title(car_names_ls[1000])","ad38dd52":"#Creating a data frame from the above two lists\ndf = pd.DataFrame(data = [car_directories, car_names_ls], index = [\"Directories\", \"Car Class\"]).T\ndf.head()\ndf.to_csv('car_names_directories.csv', index = False)","e60f4467":"#Importing various modules from the Keras Library that are used in Deep Learning\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import densenet\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\nfrom keras import regularizers","4b577f38":"#Pre-Defining some hyper-parameters\nimg_width, img_height = 256, 256\nnb_train_samples = 8144\nnb_validation_samples = 8041\nepochs = 10\nsteps_per_epoch = 256\nbatch_size = 64\nn_classes = 196\n","edec8432":"#Data Augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/ 255,\n    zoom_range=0.2,\n    rotation_range = 8,\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='categorical')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='categorical')","70625eb3":"#Creating the Convolution Neural Network\ncnn = Sequential()\ncnn.add(Conv2D(filters = 16, kernel_size = (5,5), padding = 'same', activation = 'relu', input_shape = (256,256,3)))\ncnn.add(MaxPooling2D(pool_size = (2,2)))\ncnn.add(BatchNormalization(axis = 1))\ncnn.add(Dropout(0.22))\ncnn.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'same', activation = 'relu', input_shape = (256,256,3)))\ncnn.add(MaxPooling2D(pool_size = (2,2)))\ncnn.add(BatchNormalization(axis = 1))\ncnn.add(Dropout(0.22))\ncnn.add(Conv2D(filters = 64, kernel_size = (4,4), padding = 'same', activation = 'relu', input_shape = (256,256,3)))\ncnn.add(MaxPooling2D(pool_size = (2,2)))\ncnn.add(BatchNormalization(axis = 1))\ncnn.add(Dropout(0.2))\ncnn.add(Conv2D(filters = 96, kernel_size = (3,3), padding = 'same', activation = 'relu', input_shape = (256,256,3)))\ncnn.add(MaxPooling2D(pool_size = (2,2)))\ncnn.add(BatchNormalization(axis = 1))\ncnn.add(Flatten())\ncnn.add(Dropout(0.18))\ncnn.add(Dense(512, activation = 'relu'))\ncnn.add(BatchNormalization())\ncnn.add(Dense(512, activation = 'relu'))\ncnn.add(BatchNormalization())\ncnn.add(Dense(196, activation = 'sigmoid'))\ncnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","179dd544":"#Let's take a look at the CNN we created\ncnn.summary()","df38fd8f":"#Training begins here\nmodel_history = cnn.fit_generator(\n    train_generator,\n    epochs=epochs,\n    validation_data=validation_generator,\n    steps_per_epoch = steps_per_epoch,\n    validation_steps = nb_validation_samples \/\/ batch_size)\n\ncnn.save_weights('stanford_cars_folder_cnn_weights.h5')","796c0318":"#Visualization of how validation and training set performs per epoch\nplt.figure(0, figsize = (5,5))\nplt.plot(model_history.history['acc'],'orange')\nplt.plot(model_history.history['val_acc'],'blue')\nplt.legend(['Train-Accuracy','Val-Accuracy'])\n_ = plt.title('Train vs Val Accuracy')\n_ = plt.xlabel('Epochs')\n_ = plt.ylabel('Accuracy')\n\nplt.figure(1, figsize = (5,5))\nplt.plot(model_history.history['loss'],'orange')\nplt.plot(model_history.history['val_loss'],'blue')\nplt.legend(['train','validation'])\n_ = plt.xlabel(\"Num of Epochs\")\n_ = plt.ylabel(\"Loss\")\n_ = plt.title(\"Training Loss vs Validation Loss\")","5a91754a":"\"\"\"TO OVERFIT THE MODEL\"\"\"\n#As there is insufficient images per class (40-45 images per set for 196 classes) to get satisfactory\n#results, I overfitted the model to perform best on the training set\nmodel_history = cnn.fit_generator(\n    train_generator,\n    epochs=epochs + 20,\n    validation_data=validation_generator,\n    steps_per_epoch = steps_per_epoch,\n    validation_steps = nb_validation_samples \/\/ batch_size)\n\ncnn.save_weights('stanford_cars_folder_cnn_weights_OVERFITTED.h5')","663a036c":"#Visualization of Validation and training set performance after overfitting\nplt.figure(0, figsize = (5,5))\nplt.plot(model_history.history['acc'],'orange')\nplt.plot(model_history.history['val_acc'],'blue')\nplt.legend(['Train-Accuracy','Val-Accuracy'])\n_ = plt.title('Train vs Val Accuracy (OVERFITTED)')\n_ = plt.xlabel('Epochs')\n_ = plt.ylabel('Accuracy')\n\nplt.figure(1, figsize = (5,5))\nplt.plot(model_history.history['loss'],'orange')\nplt.plot(model_history.history['val_loss'],'blue')\nplt.legend(['train','validation'])\n_ = plt.xlabel(\"Num of Epochs\")\n_ = plt.ylabel(\"Loss\")\n_ = plt.title(\"Training Loss vs Validation Loss (OVERFITTED)\")","0f4f2929":"**Creating a Dense Convolution NN**\n\n4 Convolution layers are used to have a high variance. We can use a less dense model too as there are few images per class, but when overfitting is in mind we should make a denser model","3281c9e2":"Creating a dataframe containing all the image directories and the car class corresponding to it","25bbd086":"**Model Performance Visualization**\n\nThis model performance visualization is just before the model starts to overfit. It can be seen that on both the Training set and Test\/Validation set, loss and accuracy is poor and the reason for that is:\n* Too many classes\n* Very less images per class\n* Model was not trained enough (If we trained the model for more epochs, we will overfit the training set)","30a6e7e5":"**OVERFITTING Alert**\n\nJust for the sake of results on train set, overfitting is done. The model is now trained for 30 more epochs and accuracy achieved on training set is over 92%.","6479789f":"**OVERFITTED Model Performance Visualization**\n\nThis model performance is when overfitting starts. After training on 30 more epochs, the model just learns how to classify only on the training set. The loss function on test set keeps on increasing as expected because of overfitting, although there is a very little accuracy improvement on the test set but it is still useless. \nThe reason of poor performance on the test set is:\n* Even after Data Augmentation, we have a very little image set per class. The golden rule for Image classification is atleast 1000 images should be used per class to get good results.\n* After overfitting the training set, the model learns by heart on how to classify the images only on the training set. It is just like you are learning the answers to some questions again and again and you perform good on those questions and getting 92\/100, but when new questions come you cannot even get 6\/100. If you were a student, you will look to learn from more questions other than those in which you are getting 92\/100 to get better marks on test.\n* By overfitting, we get a high variance and that is the reason for very high loss.","71c4f93b":"**Hyper-Parameters**\n\nImage size is set to be  256*256 pixels and epochs are set equal to 10 because after that, we are just overfitting the CNN.","2cdf502b":"**Before and After Overfitting Comparision on Stanford Cars Dataset**\n\nThis kernel will analyze how a Deep CNN will perform on a dataset that has 196 classes and around 40-45 images per class. In the first training session, only 10 epochs were used and then metrics like loss and accuracy of both test set and training set were compared. As we have very less images per class, it is not worthy to even give 10% accuracy on test set so, overfitting was done so that atleast we can get good results on training set. After overfitting, it can be seen that Loss on test set increases significantly as expected and there is very less improvement on accuracy on test set.","e7fb5595":"References:\nhttps:\/\/www.kaggle.com\/jutrera\/training-a-densenet-for-the-stanford-car-dataset"}}