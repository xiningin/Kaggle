{"cell_type":{"ab8cf7f3":"code","ecae38d1":"code","68ddfec4":"code","6d56e928":"code","47741673":"code","1e7a9e6e":"code","30e54833":"code","3e00ef8d":"code","11616ac1":"code","c251c109":"markdown"},"source":{"ab8cf7f3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ecae38d1":"import pandas as pd\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport matplotlib.pyplot as plt\nimport nltk\nfrom nltk.corpus import stopwords","68ddfec4":"df=pd.read_csv('..\/input\/twittersentimentbycountry\/TwitterSentimentByCountry.csv')","6d56e928":"def word_freq_generator(dfWordCloud):\n    ##Count frequencies of words\n    ##Removes the stop words and characters\n    stop_words = set(stopwords.words('english'))\n    stop_char=['#','@','&']\n    stop_words.update([\"rt\",\"https\",\"https.\",\"-\",'.',':'])\n    dfWordCloud\n    text = \" \".join(tweet.lower() for tweet in dfWordCloud.text)\n    all_freq={}\n    for word in text.split():\n        res = [char for char in stop_char if(char in word)]\n        if len(res)==0:\n            if word not in stop_words:\n                if word in all_freq: \n                    all_freq[word] += 1\n                else: \n                    all_freq[word] = 1  \n    return all_freq","47741673":"## Change this for a different country\ndfCountry=df[df['file_name']=='HongKong']\n# dfCountry=df[df['file_name']=='Australia']","1e7a9e6e":"all_freq=word_freq_generator(dfCountry)\ns = pd.Series(all_freq, name='count')\ns.index.name = 'word'\nsdf=s.reset_index()\nsdf=sdf.sort_values('count',ascending=False)","30e54833":"fig, ax = plt.subplots(figsize=(8, 8))\n\n# Plot horizontal bar graph\nsdf[0:20].sort_values(by='count').plot.barh(x='word',\n                      y='count',\n                      ax=ax,\n                      color=\"purple\")\n\nax.set_title(\"Common Words Found in Tweets (Without Stop Words)\")\n\nplt.show()","3e00ef8d":"##Generate wordcloud from frequencies\nwordcloud = WordCloud(stopwords=stopwords,background_color=\"white\").generate_from_frequencies(all_freq)\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","11616ac1":"dfWordCloud['polarity'].mean()","c251c109":"## How to generate Wordclouds with this dataset:\nIt's quite simple actually (I will add more documentation when I feel like it lol)"}}