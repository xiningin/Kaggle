{"cell_type":{"cd36c185":"code","81b2ce7c":"code","7b09613b":"code","0522fed7":"code","93921a38":"code","2a33e610":"code","1de01949":"code","4b8af429":"code","39e50e2b":"code","7643b2ed":"code","b968fc85":"code","370db5c9":"code","4ff4dfab":"code","3a548c75":"code","141050de":"code","d15d118b":"code","98150334":"code","9ad1c9da":"code","784eb7de":"code","c2846cf4":"code","c9d4439d":"code","3f3a6f79":"markdown","d1135371":"markdown","241f1d3a":"markdown","f52deefb":"markdown","473e9f1c":"markdown","3a735393":"markdown","7c374b3b":"markdown","56d6a86c":"markdown","ce4026c4":"markdown","8051b0a1":"markdown","42eb8040":"markdown"},"source":{"cd36c185":"#import libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set (color_codes=True)\n\n","81b2ce7c":"#import file\n\ndataset = pd.read_csv('\/kaggle\/input\/company-bankruptcy-prediction\/data.csv')\ncol = dataset.columns.values","7b09613b":"dataset.head(5)","0522fed7":"dataset.dtypes","93921a38":"dataset.shape\n","2a33e610":"duplicate_rows_dataset = dataset[dataset.duplicated()]\nprint(\"number of duplicate rows: \", duplicate_rows_dataset.shape)","1de01949":"#Finding the missing data\n\nprint(dataset.isnull().sum())\n","4b8af429":"from sklearn.preprocessing import MinMaxScaler\n\nMMS = MinMaxScaler()\n\ndata= MMS.fit_transform(dataset.values)\ndata= pd.DataFrame(data, columns=col)\n\ndata_mean = data.loc[dataset[\"Bankrupt?\"]].mean()\ndata_std = data.loc[dataset[\"Bankrupt?\"]].std()\n","39e50e2b":"visual = sns.catplot(x=np.arange(len(col)) , y = data_mean[:], kind = \"bar\", data=data)\nsns.despine()\nplt.title(\"Data Standardization_Mean\")\nvisual.fig.set_size_inches(30,10)\n\n\n\nvisual = sns.catplot(x=np.arange(len(col)) , y = data_std[:], kind = \"bar\",color = \"black\", data=data)\nsns.despine()\nplt.title(\"Data Standardization_Standard Deviation\")\nvisual.fig.set_size_inches(30,10)\n\n","7643b2ed":"X = data.iloc[:, 1:96].values              \ny = data.iloc[:, 0].values               \n\nprint(X)\n","b968fc85":"data.head(5)","370db5c9":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)","4ff4dfab":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","3a548c75":"X_train","141050de":"from sklearn.decomposition import PCA\npca = PCA(n_components = 2)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)","d15d118b":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'rbf', random_state = 0, gamma = 0.1)\nclassifier.fit(X_train, y_train)","98150334":"from sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))","9ad1c9da":"from sklearn.model_selection import GridSearchCV\nparameters = [{'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear']},\n              {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\ngrid_search = GridSearchCV(estimator = classifier,\n                           param_grid = parameters,\n                           scoring = 'accuracy',\n                           cv = 10,\n                           n_jobs = -1)\ngrid_search.fit(X_train, y_train)\nbest_accuracy = grid_search.best_score_\nbest_parameters = grid_search.best_params_\nprint(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\nprint(\"Best Parameters:\", best_parameters)","784eb7de":"from sklearn.metrics import confusion_matrix, accuracy_score\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","c2846cf4":"from sklearn.metrics import precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score\n\n\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy : %f' % accuracy)\n\nprecision = precision_score(y_test, y_pred)\nprint('Precision : %f' % precision)\n\nrecall = recall_score(y_test, y_pred)\nprint('Recall : %f' % recall)\n\nf1 = f1_score(y_test, y_pred)\nprint('F1 : %f' % f1)\n\nkappa = cohen_kappa_score(y_test, y_pred)\nprint('Cohens kappa : %f' % kappa)\n\nauc = roc_auc_score(y_test, y_pred)\nprint('ROC AUC : %f' % auc)\n\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","c9d4439d":"from sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(classifier, X_test, y_test)","3f3a6f79":"> accuracy has been imported to PCA analysis","d1135371":"> no duplicate rows","241f1d3a":"# Feature Scaling (Standardization)","f52deefb":"# Checking Data Condition","473e9f1c":"# Finding The Missing Data","3a735393":"# Data Separation","7c374b3b":"# Data Analysis","56d6a86c":"> no missing data","ce4026c4":"# Preparation","8051b0a1":"# Exploratory Data Analysis","42eb8040":"# Data Splitting"}}