{"cell_type":{"b42aca21":"code","c1346957":"code","1e2756c5":"code","f3bd3062":"code","a61b54a3":"code","908b414e":"code","420fb2ff":"code","b3e32af2":"code","1b67f991":"code","4761a004":"code","0a6ca518":"code","0fa7a96a":"code","ecb17e70":"code","ad85e3ff":"code","f460985e":"code","f2eb52b5":"code","19f7a10d":"code","2ea89714":"code","7be25bf8":"code","bf92fd9f":"markdown","e206d1c8":"markdown","1576c7c7":"markdown","536a4d6b":"markdown"},"source":{"b42aca21":"#import python packages\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\nimport os\nnp.random.seed(0)","c1346957":"# import sklearn packages\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools","1e2756c5":"# import keras packages\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau","f3bd3062":"train_data = pd.read_csv('..\/input\/train.csv')\ntest_data = pd.read_csv('..\/input\/test.csv')\n\nX = train_data.drop(labels = ['label'], axis= 1)\ny = train_data['label']\n\n# free space\ndel train_data\n\n# count digits\nsns.countplot(y)","a61b54a3":"# check missing values\nX.isnull().any().describe()","908b414e":"# normalize the data\nX = X\/255.0\ntest_data = test_data\/255.0","420fb2ff":"# Reshape the data as Keras work with numpy not with dataframes\nX = X.values.reshape(-1,28,28,1)\ntest_data = test_data.values.reshape(-1,28,28,1)","b3e32af2":"# Encode the digits using One hot encoding method\ny = to_categorical(y, num_classes=10)","1b67f991":"# Split the train and val data\nrandom_seed =5\nX_train,X_val,y_train, y_val =train_test_split(X,y,random_state=random_seed, test_size=0.08)","4761a004":"# View digit\nplt.imshow(X_train[4][:,:,0])","0a6ca518":"model = Sequential()\n\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.3))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.3))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","0fa7a96a":"# Define the optimizer\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","ecb17e70":"# Compile the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","ad85e3ff":"# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","f460985e":"epochs = 35\nbatch_size = 64","f2eb52b5":"# Data Augmentation(creating extra training data to avoid overfitting)\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        )  \ndatagen.fit(X_train)","19f7a10d":"# Fit the model\nhistory = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] \/\/ batch_size\n                              , callbacks=[learning_rate_reduction])","2ea89714":"# predict results\nresults = model.predict(test_data)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","7be25bf8":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"digit_cnn_keras.csv\",index=False)","bf92fd9f":"## Importing packages","e206d1c8":"## Keras CNN implementation:","1576c7c7":"## Preprocessing Data:","536a4d6b":"## Load and View Data:"}}