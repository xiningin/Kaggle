{"cell_type":{"19a24f78":"code","2ec1a68d":"code","c1d8d359":"code","eacfc757":"code","ea2928bf":"code","e360e653":"code","80d430e5":"code","698dfda1":"code","4daf57a3":"code","c48d0128":"code","9c170b24":"code","204a1a2c":"code","e25047c2":"code","3aeca30f":"code","0f3625b9":"code","1f220b37":"code","6d7d0704":"code","6c003990":"code","28c575a4":"code","c49adcad":"code","21ec4146":"code","cc54b70c":"code","5a3b1985":"code","f37fb836":"code","8d660861":"code","0ba33fde":"code","c6daeca5":"code","4c1fa062":"code","fe6d990b":"code","05d0a0ee":"code","a4bc949a":"code","877c9762":"code","de409b85":"code","53cfecc4":"code","79fab51f":"code","75f5866f":"code","fc6932ab":"code","1854fb52":"code","63fd18db":"code","34af4ad9":"code","4f3264a2":"code","e4a4f04a":"code","8d65163f":"code","85fde4f3":"code","e11eae43":"code","2a88ca09":"code","8ec697d4":"code","ba0f88c6":"code","b85300e6":"code","b9b36350":"code","353a5757":"code","1f57a264":"code","448eaec5":"code","d60f9fac":"code","d303816a":"code","b75bf2f1":"code","04c0e33b":"code","8f9b8d46":"code","eb0d66da":"code","46883e42":"code","c2dff478":"code","5d1bfe9f":"code","06e47d46":"code","fdbc0c12":"code","cd1bbf31":"code","fa176f70":"code","3f2acd42":"code","1634de11":"code","49ff0e69":"code","a3002fba":"code","f0d60d70":"code","13666cac":"code","0585c796":"code","680a20b5":"markdown","8a54f21c":"markdown","b735b46c":"markdown","2c52dac2":"markdown","a75ad4ec":"markdown","3bbb7ddd":"markdown","00970cff":"markdown","fd72606f":"markdown","2c81a7c8":"markdown","87050e21":"markdown","4fced45c":"markdown","b2ecbaa3":"markdown"},"source":{"19a24f78":"# read csv files\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","2ec1a68d":"df = pd.read_csv('..\/input\/train.csv')\n\ndf.head()","c1d8d359":"test_df = pd.read_csv('..\/input\/test.csv')\ntest_df.head()","eacfc757":"surv_col = df.iloc[:,1]\nsurv_col.head()","ea2928bf":"train_df = df.iloc[:,2:]\ntrain_df.head()","e360e653":"pessengerId = test_df.iloc[:,0]\npessengerId.head()","80d430e5":"test_df.drop(['PassengerId'],axis=1,inplace=True)\n\ntest_df.head()","698dfda1":"train_df.head()","4daf57a3":"concated_df = pd.concat([train_df,test_df])\n\nconcated_df.head()","c48d0128":"concated_df.info()","9c170b24":"from sklearn import preprocessing as prep","204a1a2c":"le = prep.LabelEncoder()\n\nconcated_df.Sex =le.fit_transform(concated_df.Sex)\n\ndf.Sex[0:10]","e25047c2":"concated_df.head()","3aeca30f":"concated_df.info()","0f3625b9":"embarked = concated_df['Embarked'].fillna('0')\n\nembarked.unique()","1f220b37":"concated_df.Embarked = le.fit_transform(embarked)\n\nconcated_df.Embarked.unique()","6d7d0704":"concated_df.head()","6c003990":"concated_df.tail()","28c575a4":"concated_df.dtypes","c49adcad":"print( 'Pclass:' ,concated_df.Pclass.unique())\nprint( 'Sex:' ,concated_df.Sex.unique())\nprint( 'SibSp:' ,concated_df.SibSp.unique())\nprint( 'Parch:' ,concated_df.Parch.unique())\nprint( 'Embarked:' ,concated_df.Embarked.unique())","21ec4146":"concated_df.drop(['Cabin'],axis=1,inplace=True)\n\nconcated_df.head()","cc54b70c":"NameSplit = concated_df.Name.str.split('[,.]')\n\nNameSplit.head()","5a3b1985":"titles = [str.strip(name[1]) for name in NameSplit.values]\ntitles[:10]","f37fb836":"# new feature\n\nconcated_df['Title'] = titles\n\nconcated_df.head()","8d660861":"concated_df.Title.unique()","0ba33fde":"# useless words: I will combine Mademoiselle and Madame into a single type\n\nconcated_df.Title.values[concated_df.Title.isin(['Mme', 'Mmle'])] = 'Mmle'","c6daeca5":"# keep reducing\n\nconcated_df.Title.values[concated_df.Title.isin(['Capt', 'Don', 'Major', 'Sir'])] = 'Sir'\nconcated_df.Title.values[concated_df.Title.isin(['Dona', 'Lady', 'the Countess', 'Jonkheer'])] = 'Lady'","4c1fa062":"concated_df.Title.unique()","fe6d990b":"# label encode new feature too\n\nconcated_df.Title = le.fit_transform(concated_df.Title)\nconcated_df.head()","05d0a0ee":"# new feature is family size\n# number of spouses and siblings and oneself is family size\n\nconcated_df['FamilySize'] = concated_df.SibSp.values + concated_df.Parch.values + 1","a4bc949a":"concated_df.head()","877c9762":"surnames = [str.strip(name[0]) for name in NameSplit]\nsurnames[:10]","de409b85":"concated_df['Surname'] = surnames\nconcated_df['FamilyID'] = concated_df.Surname.str.cat(concated_df.FamilySize.astype(str),sep='')\nconcated_df.head()","53cfecc4":"# I will mark if any family id as small if family size is less than or equal to 2\n\nconcated_df.FamilyID.values[concated_df.FamilySize.values <= 2] = 'Small'\n\nconcated_df.head()","79fab51f":"# check up the frequency of family ids\nconcated_df.FamilyID.value_counts()","75f5866f":"freq = list(dict(zip(concated_df.FamilyID.value_counts().index.tolist(), concated_df.FamilyID.value_counts().values)).items())\n\ntype(freq)","fc6932ab":"freq = np.array(freq)\n\nfreq[:10]","1854fb52":"freq.shape","63fd18db":"# select the family ids with frequency of 2 or less\nfreq[freq[:,1].astype(int) <= 2].shape","34af4ad9":"freq = freq[freq[:,1].astype(int) <= 2]","4f3264a2":"# I'll assign 'Small' for those\nconcated_df.FamilyID.values[concated_df.FamilyID.isin(freq[:,0])] = 'Small'\nconcated_df.FamilyID.value_counts()","e4a4f04a":"# label encoding for family id\n\nconcated_df.FamilyID = le.fit_transform(concated_df.FamilyID)\nconcated_df.FamilyID.unique()","8d65163f":"# I will choose usefull features\nconcated_reduce = concated_df[[\n    'Pclass', 'Sex', 'Age', 'SibSp',\n    'Parch', 'Fare', 'Title', 'Embarked', 'FamilySize',\n    'FamilyID']]\n\nconcated_reduce.head()","85fde4f3":"concated_reduce.Age.unique()","e11eae43":"concated_reduce.info()","2a88ca09":"concated_reduce['Age'].fillna(concated_reduce['Age'].median(), inplace=True)\nconcated_reduce['Fare'].fillna(concated_reduce['Fare'].median(), inplace=True)","8ec697d4":"concated_reduce.info()","ba0f88c6":"train_final = concated_reduce.iloc[:891].copy()\ntest_final = concated_reduce.iloc[891:].copy()","b85300e6":"train_final.head()","b9b36350":"test_final.head()","353a5757":"X = train_final.values\n\nX","1f57a264":"y = surv_col.values\n\ny","448eaec5":"X.shape","d60f9fac":"y.shape","d303816a":"test_data = test_final.values\n\ntest_data","b75bf2f1":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout","04c0e33b":"model = Sequential()\n\nmodel.add(Dense(32, init = 'uniform', activation='relu', input_dim = 10))\nmodel.add(Dense(64, init = 'uniform', activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(64, init = 'uniform', activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(12, init = 'uniform', activation='relu'))\nmodel.add(Dense(1, init = 'uniform', activation='sigmoid'))\n\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","8f9b8d46":"model.fit(X,y, epochs=500, batch_size = 64, verbose = 1)","eb0d66da":"pred = model.predict(test_data)","46883e42":"pred","c2dff478":"# convert to integer\noutputBin = np.zeros(0)\nfor i in pred:\n    \n    if i <= .5:\n        \n        outputBin = np.append(outputBin, 0)\n    else:\n        \n        outputBin = np.append(outputBin, 1)\noutput = np.array(outputBin).astype(int)","5d1bfe9f":"output","06e47d46":"d = {'PassengerId':pessengerId, 'Survived':output}","fdbc0c12":"final_df = pd.DataFrame(data=d)","cd1bbf31":"final_df.head()","fa176f70":"final = final_df.to_csv('new_result.csv',index=False) #convert to csv file\n\nfinal","3f2acd42":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=350, max_depth=15, random_state=42)\n\nprint(\"train accuracy: {} \".format(rf.fit(X, y).score(X, y)))\n","1634de11":"rf_pred = rf.predict(test_data)","49ff0e69":"rf_pred","a3002fba":"r = {'PassengerId':pessengerId, 'Survived':rf_pred}","f0d60d70":"final_rf = pd.DataFrame(data=r)","13666cac":"final_rf.head(13)","0585c796":"final_rf = final_df.to_csv('random_forest_result.csv',index=False) #convert to csv file\n\nfinal_rf","680a20b5":"### On the some columns, there are some missing values. Firstly I need to fill that columns","8a54f21c":"### I will remove Cabin columns","b735b46c":"# Label Encoding for Sex Column","2c52dac2":"## There are too many family ids with few family members. maybe some families had different last names. I'll clean this.","a75ad4ec":"# -- Feature Engineering --","3bbb7ddd":"## There are missing values on Age Column. Therefore I will fill taking Median","00970cff":"# Random Forest Classifier","fd72606f":"# So, That Dataset (concated_reduce) is ready for spliting as Train and Test values.","2c81a7c8":"#### Data Dictionary\n\n* Survival\t0 = No, 1 = Yes\n* pclass =>\tTicket class (1 = 1st, 2 = 2nd, 3 = 3rd)\n* sex = Sex\n* Age => Age in years\n* sibsp => # of siblings \/ spouses aboard the Titanic\n* parch => # of parents \/ children aboard the Titanic\n* ticket => Ticket number\t\n* fare => Passenger fare\t\n* cabin => Cabin number\n* embarked => Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n\n\n\n#### Variable Notes\n#### pclass: A proxy for socio-economic status (SES)\n* 1st = Upper\n* 2nd = Middle\n* 3rd = Lower\n\n\n\n#### age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\n\n\n#### sibsp: The dataset defines family relations in this way...\n* Sibling = brother, sister, stepbrother, stepsister\n* Spouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\n\n\n#### parch: The dataset defines family relations in this way...\n* Parent = mother, father\n* Child = daughter, son, stepdaughter, stepson\n* Some children travelled only with a nanny, therefore parch=0 for them.\n\n\n","87050e21":"# Creating Neural Network with Keras","4fced45c":"# Label Encoding for Embarked Column","b2ecbaa3":"## At the outset, I splited some columns on the dataset. Now I will use that columns for creating Train dataset"}}