{"cell_type":{"276bde7b":"code","a7a592e1":"code","16e0aaca":"code","445248fc":"code","79e28e04":"code","ef0bbab5":"code","4b6e8af9":"code","eb502413":"markdown","a7c23bd2":"markdown","ea4a05d1":"markdown"},"source":{"276bde7b":"from dataclasses import fields\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras\nimport keras.models as km\nfrom keras.layers import Dense, BatchNormalization, Flatten, Conv2D, MaxPooling2D, Dropout\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array\nfrom keras.callbacks import ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential","a7a592e1":"def print_summary(file,model):\n    with open(file,'w') as f : model.summary(print_fn= lambda x:f.write(x+'\\n'))\ndef write_file(file,s):\n    with open (file,'w') as f : f.write(s);\ndef write_np(file,np):\n    file = open(file, \"w+\")\n    content = str(np)\n    file.write(content)\n    file.close()\n    ","16e0aaca":"\ndef process(dataset):\n    with open(dataset) as f:\n        file = f.readlines()\n    lines = np.array(file)\n    y = []\n    x = []\n    X_train=[]\n    X_test=[]\n    Y_train=[]\n    Y_test=[]\n    \n    X_public=[]\n    Y_public=[]\n    dict = {\n        '0':np.array([1., 0., 0., 0., 0., 0., 0.]),        \n        '1':np.array([0., 1., 0., 0., 0., 0., 0.]),\n        '2':np.array([0., 0., 1., 0., 0., 0., 0.]),\n        '3':np.array([0., 0., 0., 1., 0., 0., 0.]),\n        '4':np.array([0., 0., 0., 0., 1., 0., 0.]),\n        '5':np.array([0., 0., 0., 0., 0., 1., 0.]),\n        '6':np.array([0., 0., 0., 0., 0., 0., 1.])\n    }\n    for i in range(1, lines.size):\n        ident, pixels, cat = lines[i].split(\",\")\n        pixels = pixels.split()\n        pixels = np.array(pixels, 'float32')\n        ident = dict[ident]\n        if('Training' in cat) :\n            X_train.append(pixels)\n            Y_train.append(ident)\n        elif('PrivateTest' in cat):\n            X_test.append(pixels)\n            Y_test.append(ident)\n        else :\n            X_public.append(pixels)\n            Y_public.append(ident)\n#         y.append(ident)\n#         x.append(pixels)\n\n#     X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2, random_state=100)\n\n    #changing type\n    X_train = np.array(X_train,'float32')\n    Y_train = np.array(Y_train,'float32')\n    X_test = np.array(X_test,'float32')\n    Y_test = np.array(Y_test,'float32')    \n    X_public = np.array(X_public,'float32')\n    Y_public = np.array(Y_public,'float32')\n\n    \n    #normalizing\n    X_train = X_train\/255.\n    X_test = X_test\/255.\n    X_public = X_public\/255.\n    #reshaping\n    X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n    X_train = X_train.astype('float32')\n    X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n    X_test = X_test.astype('float32')\n    X_public = X_public.reshape(X_public.shape[0], 48, 48, 1)\n    X_public = X_public.astype('float32')\n    \n    return X_train, X_test, Y_train, Y_test, X_public, Y_public\n\nX_train, X_test, Y_train, Y_test, X_public, Y_public=process('..\/input\/fer2013\/fer2013.csv')\n# print(\"\\ny\",Y_train.max())\nwrite_np('x_test.txt',X_test)\nwrite_np('y_test.txt',Y_test)\nwrite_np('x_train.txt',X_train)\nwrite_np('y_train.txt',Y_train)\n","445248fc":"#model\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3), padding='same',\n          activation='relu', input_shape=(48, 48, 1)))\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n#2\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n#3\nmodel.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n#4\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.15))\nmodel.add(Dense(7, activation='softmax'))\n\nprint_summary('model_summary.txt', model)\nmodel.summary()\n\n\n","79e28e04":"model.compile(loss='categorical_crossentropy',\n              optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n\ntrain = model.fit(x=X_train, y=Y_train, batch_size=32, epochs=40, validation_data=(X_test, Y_test),\n                  callbacks=[ModelCheckpoint(filepath='model8.h5'), ])","ef0bbab5":"# img = image.load_img('input.jpg')\ns='..\/input\/happyf\/sadkid.jpg'\noriginal=image.load_img(s)\nimg = image.load_img(s, color_mode='grayscale', target_size=(48, 48))\nx = img_to_array(img)\nx = np.expand_dims(x, axis = 0)\n#normalize\nx = x\/255.\nmodel = keras.models.load_model('model8.h5')\nresult = model.predict(x)\n\ntick_label = ['angry', 'disgust', 'fear', 'happy',\n              'sad', 'surprise', 'neutral']\nleft = [0, 1, 2, 3, 4, 5, 6]\nplt.figure(figsize=(10,5))\nplt.subplot(1,2,1)\nplt.bar(left,result[0],tick_label=tick_label)\nplt.xlabel('emotions')\nplt.ylabel('predictions')\nplt.ylim(top=1)\nplt.subplot(1,2,2)\nplt.imshow(original)\n\n\nplt.show()","4b6e8af9":"#Evaluation\ntrain_score = model.evaluate(X_train, Y_train, verbose=0)\nprint('Training accuracy:', train_score[1])\n \ntest_score = model.evaluate(X_test, Y_test, verbose=0)\nprint('Test accuracy:', test_score[1])\n\nvalidation_score = model.evaluate(X_public, Y_public, verbose=0)\nprint('validation accuracy:', validation_score[1])\n\nplt.bar(['train','test','valid'],[train_score[1], test_score[1], validation_score[1]])\nplt.ylim(top=1)\nplt.show()","eb502413":"# **Requied funcions for writing files**\n","a7c23bd2":"# **libraries**","ea4a05d1":"# Preprocessing input file"}}