{"cell_type":{"5f527a67":"code","a3b47bed":"code","2ddcdd4c":"code","82285534":"code","2c9eaec3":"code","49a2313f":"code","7b5b0934":"code","e4b7905c":"code","1eff63bf":"code","c9c70542":"code","280af1d5":"code","939ff485":"code","e2d2793c":"code","d912e12a":"code","d1e22b99":"code","03d55e3e":"code","4fa323da":"code","cb8bb81c":"code","d843c0cd":"code","814e02a0":"code","7c42fc85":"code","89c6d8b4":"code","6405727f":"code","7959cfa9":"markdown","94666af4":"markdown","b6fca3a4":"markdown","a4a927fc":"markdown","81ca9982":"markdown","6fc06e81":"markdown","c8b4311e":"markdown","14bd1f65":"markdown","af718adc":"markdown","648f42fa":"markdown","e2609003":"markdown","25e95c56":"markdown","06ff3a47":"markdown","454fba1f":"markdown","9715545c":"markdown","0c20eed3":"markdown","006e714f":"markdown","2d687ad5":"markdown","87f1f375":"markdown"},"source":{"5f527a67":"import pandas as pd\nimport numpy as np\n\nimport squarify\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('ggplot')\n\nimport warnings\nwarnings.filterwarnings('ignore')","a3b47bed":"orders = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_orders_dataset.csv')\npayments = pd.read_csv('..\/input\/brazilian-ecommerce\/olist_order_payments_dataset.csv')","2ddcdd4c":"orders['order_delivered_carrier_date'] = pd.to_datetime(orders['order_delivered_carrier_date']) # datetime conversion\npayments = payments.set_index('order_id') # preparation before the join\norders = orders.set_index('order_id') # preparation before the join\n\njoined = orders.join(payments) # join on order_id","82285534":"joined.isna()\\\n      .sum()\\\n      .sort_values(ascending=False)","2c9eaec3":"joined.nunique()\\\n      .sort_values(ascending=False)","49a2313f":"last_date = joined['order_delivered_carrier_date'].max() + pd.to_timedelta(1, 'D')\n\nRFM = joined.dropna(subset=['order_delivered_carrier_date'])\\\n            .reset_index()\\\n            .groupby('customer_id')\\\n            .agg(Recency = ('order_delivered_carrier_date', lambda x: (last_date - x.max()).days ),\n                 Frequency = ('order_id', 'size'),\n                 Monetary = ('payment_value', 'sum'))","7b5b0934":"RFM.isna().sum()","e4b7905c":"RFM.describe([0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99]).T","1eff63bf":"plt.figure(figsize=(12, 6))\nsns.boxplot(x='Recency', data=RFM)\nplt.title('Boxplot of Recency');","c9c70542":"RFM['Frequency'].value_counts(normalize=True)*100","280af1d5":"RFM['Frequency'].apply(lambda x: 'less or equal to 5' if x<=5 else 'greater than 5')\\\n                .value_counts(normalize=True) * 100","939ff485":"RFM = RFM[RFM['Frequency'] <= 5]","e2d2793c":"RFM['Monetary'].describe([0.25, 0.5, 0.75, 0.9, 0.95, 0.99])","d912e12a":"plt.figure(figsize=(12, 6))\nplt.title('Distribution of Monetary < 95%')\nsns.distplot(RFM[RFM['Monetary']<447].Monetary);","d1e22b99":"RFM = RFM[RFM['Monetary'] < 447]","03d55e3e":"RFM['R_score'] = pd.qcut(RFM['Recency'], 3, labels=[1, 2, 3]).astype(str)\nRFM['M_score'] = pd.qcut(RFM['Monetary'], 3, labels=[1, 2, 3]).astype(str)\nRFM['F_score'] = RFM['Frequency'].apply(lambda x: '1' if x==1 else '2')\n\nRFM['RFM_score'] = RFM['R_score'] + RFM['F_score'] + RFM['M_score']","4fa323da":"def segment(x):\n    if x == '123':\n        return 'Core'\n    elif x in ['311', '312', '313']:\n        return 'Gone'\n    elif x in ['111', '112', '113']:\n        return 'Rookies'\n    elif x in ['323', '213', '223']:\n        return 'Whales'\n    elif x in ['221', '222', '321', '322']:\n        return 'Loyal'\n    else:\n        return 'Regular'","cb8bb81c":"RFM['segments'] = RFM['RFM_score'].apply(segment)\nRFM['segments'].value_counts(normalize=True)*100","d843c0cd":"segmentwise = RFM.groupby('segments').agg(RecencyMean = ('Recency', 'mean'),\n                                          FrequencyMean = ('Frequency', 'mean'),\n                                          MonetaryMean = ('Monetary', 'mean'),\n                                          GroupSize = ('Recency', 'size'))\nsegmentwise","814e02a0":"font = {'family' : 'normal',\n        'weight' : 'normal',\n        'size'   : 18}\n\nplt.rc('font', **font)\n\n\nfig = plt.gcf()\nax = fig.add_subplot()\nfig.set_size_inches(16, 16)\nsquarify.plot(sizes = segmentwise['GroupSize'], \n              label = segmentwise.index,\n              color = ['gold', 'teal', 'steelblue', 'limegreen', 'darkorange', 'coral'],\n              alpha = 0.8)\nplt.title(\"RFM Segments\",fontsize=18,fontweight=\"bold\")\nplt.axis('off')\nplt.show()","7c42fc85":"from operator import attrgetter\n\njoined['order_purchase_timestamp'] = pd.to_datetime(joined['order_purchase_timestamp'])\n\njoined['order_months'] = joined['order_purchase_timestamp'].dt.to_period('M')\njoined['cohorts'] = joined.groupby('customer_id')['order_months'].transform('min')\n\ncohorts_data = joined.reset_index()\\\n                     .groupby(['cohorts', 'order_months'])\\\n                     .agg(ClientsCount = ('customer_id', 'nunique'),\n                          Revenue = ('payment_value', 'sum'),\n                          Orders = ('order_id', 'count'))\\\n                     .reset_index()\n\ncohorts_data['periods'] = (cohorts_data.order_months - cohorts_data.cohorts).apply(attrgetter('n')) # periods for which the client have stayed\n\ncohorts_data.head()","89c6d8b4":"font = {'family' : 'normal',\n        'weight' : 'normal',\n        'size'   : 12}\n\nplt.rc('font', **font)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24,6)) # for 2 parrallel plots\n\ncohorts_data.set_index('cohorts').Revenue.plot(ax=ax1)\nax1.set_title('Cohort-wise revenue')\n\ncohorts_data.set_index('cohorts').ClientsCount.plot(ax=ax2, c='b')\nax2.set_title('Cohort-wise clients counts');","6405727f":"ig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24,6))\n\n(cohorts_data['Revenue']\/cohorts_data['Orders']).plot(ax=ax1)\nax1.set_title('Average Order Amount per cohort')\n\nsns.boxplot((cohorts_data['Revenue']\/cohorts_data['Orders']), ax=ax2)\nax2.set_title('Boxplot of the Average Order Amount');","7959cfa9":"It seems like we have missing values. And unfortunately order_delivered_carrier_date also has missing values. Thus, they should be dropped","94666af4":"# Recency","b6fca3a4":"Here, it seems like 95% percentile should be used to drop the outliers","a4a927fc":"As it was pointed out above, the average order is the same for almost all the cohors. But we have some outliers that are located at the start and end of the left graph. Those outliers probably should be ignored and we can assume that Average Order Amount is the same for each cohort. Thus, it may imply that the company should work on increasing the number of clients","81ca9982":"I have used quantiles for assigning scores for Recency and Monetary. \n* groups are 0-33, 33-66, 66-100 quantiles\n\nFor Frequency I have decided to group them by hand\n* score=1 if the frequency value is 1\n* otherwise, the score will be 2","6fc06e81":"# Importing the modules","c8b4311e":"# Dataframes join","14bd1f65":"# Cohort Analysis\n","af718adc":"# Loading the data","648f42fa":"The figure above reveals the dynamics of Revenue and Number of Clients per cohort.\n\nOn the left side we can see Revenue plot and on the right side can see ClientsCount plot.\n\nOverall, we can come to the next conclusions:\n* dynamics of two graphs are almost identical. Thus, it seems like the Average Order Amount was the same almost for each cohort. It could mean that the only way to get more revenue is to get more clients. Also, we know that we have 97% of non-recurring clients, thus maybe resolving this issue and stimulating customers to comeback would also result in revenue increase\n\n* I suspect that we don't have the full data for the last several months, because we can see abnormal drop. Thus, these last months shouldn't be taken into considerations\n\n* Cohort of November-2017 looks like out of trend, since this cohort showed outstanding results. It can be due to Black Friday sales that often happen at Novembers, or maybe during the November of 2017 some experimental marketing campaigns were performed that lead to good results. Thus, this cohort should be investigated by the company in order to identify the reason behind such an outstanding result, and take it into account","e2609003":"1. CORE - '123' - most recent, frequent, revenue generating - core customers that should be considered as most valuable clients\n2. GONE - '311', '312', '313' - gone, one-timers - those clients are probably gone;\n3. ROOKIE - '111', '112', '113' - just have joined - new clients that have joined recently\n4. WHALES - '323', '213', '223 - most revenue generating - whales that generate revenue\n5. LOYAL - '221', '222', '321', '322' - loyal users\n6. REGULAR - '121', '122', '211', '212', - average users - just regular customers that don't stand out\n\n","25e95c56":"Sanity check - do we have NaN values or not?","06ff3a47":"# Frequency","454fba1f":"I guess here we should select only frequency values that are greater than 5, because by doing this we only drop 0.11% of records","9715545c":"This notebook reveals my solution for __RFM Analysis Task__ offered by Renat Alimbekov. \n\nThis task is part of the __Task Series__ for Data Analysts\/Scientists\n__Task Series__ - is a rubric where Alimbekov challenges his followers to solve tasks and share their solutions.\nSo here I am :)\n\nOriginal solution can be found at - https:\/\/alimbekov.com\/rfm-python\/\n\nThe task is to perform RFM Analysis. \n* __olist_orders_dataset.csv__ and __olist_order_payments_dataset.csv__ should be used\n* order_delivered_carrier_date - should be used in this task\n* Since the dataset is not actual by 2021, thus we should assume that we were asked to perform RFM analysis the day after the last record\n","0c20eed3":"# Monetary","006e714f":"So, here we can see that we have some outliers in Freqency and Monetary groups. Thus, they should be dropped and be analyzed separately","2d687ad5":"Since, majority of our clients are not recurring ones, we can't perform proper cohort analysis on retention and other possible metrics.\n\nFortunately, we can analyze dynamics of the bussiness and maybe will be even able to identify some relatively good cohorts that might be used as a prototype (e.g. by marketers).","87f1f375":"# RFM groups"}}