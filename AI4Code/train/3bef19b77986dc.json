{"cell_type":{"967ad211":"code","9e4b9ce6":"code","dee21927":"code","1b267cf9":"code","c6b30490":"code","f0df200a":"code","389c1df3":"code","91141f0d":"code","c5ec3c56":"code","3db51b64":"code","63ce5c1e":"markdown"},"source":{"967ad211":"import os\nimport sys\nsys.path.append('..\/input\/pytorch-images-seresnet')\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nfrom matplotlib import pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nimport albumentations\nfrom albumentations import *\nfrom albumentations.pytorch import ToTensorV2\n\n\nimport timm\n\nfrom torch.cuda.amp import autocast, GradScaler\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","9e4b9ce6":"BATCH_SIZE = 128\nTEST_PATH = '..\/input\/ranzcr-clip-catheter-line-classification\/test'","dee21927":"test = pd.read_csv('..\/input\/ranzcr-clip-catheter-line-classification\/sample_submission.csv')","1b267cf9":"class TestDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['StudyInstanceUID'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names[idx]\n        file_path = f'{TEST_PATH}\/{file_name}.jpg'\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        return image","c6b30490":"def get_transforms(image_size=640):\n        return Compose([\n            Resize(image_size, image_size),\n            Normalize(),\n            ToTensorV2(),\n        ])","f0df200a":"class ResNet200D(nn.Module):\n    def __init__(self, model_name='resnet200d_320'):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False)\n        n_features = self.model.fc.in_features\n        self.model.global_pool = nn.Identity()\n        self.model.fc = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(n_features, 11)\n\n    def forward(self, x):\n        bs = x.size(0)\n        features = self.model(x)\n        pooled_features = self.pooling(features).view(bs, -1)\n        output = self.fc(pooled_features)\n        return output\n\nclass SeResNet152D(nn.Module):\n    def __init__(self, model_name='seresnet152d_320'):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False)\n        n_features = self.model.fc.in_features\n        self.model.global_pool = nn.Identity()\n        self.model.fc = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(n_features, 11)\n\n    def forward(self, x):\n        bs = x.size(0)\n        features = self.model(x)\n        pooled_features = self.pooling(features).view(bs, -1)\n        output = self.fc(pooled_features)\n        return output\n    \nclass RANZCRResNet200D(nn.Module):\n    def __init__(self, model_name='resnet200d', out_dim=11, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False)\n        n_features = self.model.fc.in_features\n        self.model.global_pool = nn.Identity()\n        self.model.fc = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(n_features, out_dim)\n\n    def forward(self, x):\n        bs = x.size(0)\n        features = self.model(x)\n        pooled_features = self.pooling(features).view(bs, -1)\n        output = self.fc(pooled_features)\n        return output","389c1df3":"def inference(models, test_loader, device):\n    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n    probs = []\n    for i, (images) in tk0:\n        images = images.to(device)\n        avg_preds = []\n        for model in models:\n            with torch.no_grad():\n                y_preds1 = model(images)\n                y_preds2 = model(images.flip(-1))\n            y_preds = (y_preds1.sigmoid().to('cpu').numpy() + y_preds2.sigmoid().to('cpu').numpy()) \/ 2\n            avg_preds.append(y_preds)\n        avg_preds = np.mean(avg_preds, axis=0)\n        probs.append(avg_preds)\n    probs = np.concatenate(probs)\n    return probs","91141f0d":"models200D = []\nmodel = ResNet200D()\nmodel.load_state_dict(torch.load(\"..\/input\/resnet200d-public\/resnet200d_320_CV9632.pth\")['model'])\nmodel.eval()\nmodel.to(device)\nmodels200D.append(model)\n\nmodels200D_2 = []\nmodel = RANZCRResNet200D()\nmodel.load_state_dict(torch.load(\"..\/input\/resnet200d-baseline-benchmark-public\/resnet200d_fold0_cv953.pth\", map_location='cuda:0'))\nmodel.eval()\nmodel.to(device)\nmodels200D_2.append(model)\n\nmodel = RANZCRResNet200D()\nmodel.load_state_dict(torch.load(\"..\/input\/resnet200d-baseline-benchmark-public\/resnet200d_fold1_cv955.pth\", map_location='cuda:0'))\nmodel.eval()\nmodel.to(device)\nmodels200D_2.append(model)\n\nmodel = RANZCRResNet200D()\nmodel.load_state_dict(torch.load(\"..\/input\/resnet200d-baseline-benchmark-public\/resnet200d_fold2_cv955.pth\", map_location='cuda:0'))\nmodel.eval()\nmodel.to(device)\nmodels200D_2.append(model)\n\nmodel = RANZCRResNet200D()\nmodel.load_state_dict(torch.load(\"..\/input\/resnet200d-baseline-benchmark-public\/resnet200d_fold3_cv957.pth\", map_location='cuda:0'))\nmodel.eval()\nmodel.to(device)\nmodels200D_2.append(model)\n\nmodel = RANZCRResNet200D()\nmodel.load_state_dict(torch.load(\"..\/input\/resnet200d-baseline-benchmark-public\/resnet200d_fold4_cv954.pth\", map_location='cuda:0'))\nmodel.eval()\nmodel.to(device)\nmodels200D_2.append(model)\n\nmodels152D = []\nmodel = SeResNet152D()\nmodel.load_state_dict(torch.load('..\/input\/seresnet152d-cv9615\/seresnet152d_320_CV96.15.pth')['model'])\nmodel.eval()\nmodel.to(device)\nmodels152D.append(model)","c5ec3c56":"test_dataset_512 = TestDataset(test, transform=get_transforms(image_size=512))\ntest_loader_512 = DataLoader(test_dataset_512, batch_size=BATCH_SIZE, shuffle=False, num_workers=4 , pin_memory=True)\n\ntest_dataset_640 = TestDataset(test, transform=get_transforms(image_size=640))\ntest_loader_640 = DataLoader(test_dataset_640, batch_size=BATCH_SIZE, shuffle=False, num_workers=4 , pin_memory=True)\n\npredictions200d = inference(models200D, test_loader_640, device)\npredictions200d_2 = inference(models200D_2, test_loader_512, device)\npredictions152d = inference(models152D, test_loader_640, device)\npredictions = (predictions200d + predictions200d_2 + 0.50 * predictions152d) \/ 2.5","3db51b64":"target_cols = test.iloc[:, 1:12].columns.tolist()\ntest[target_cols] = predictions\ntest[['StudyInstanceUID'] + target_cols].to_csv('submission.csv', index=False)\ntest.head()","63ce5c1e":"Credits\n\nhttps:\/\/www.kaggle.com\/ammarali32\/resnet200d-inference-single-model-lb-96-5\n\nhttps:\/\/www.kaggle.com\/ammarali32\/seresnet152d-inference-single-model-lb-96-2\n\nhttps:\/\/www.kaggle.com\/underwearfitting\/resnet200d-public-benchmark-2xtta-lb0-965\n"}}