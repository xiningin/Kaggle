{"cell_type":{"e432b8cb":"code","134aa9d4":"code","09d8ea12":"code","70c38621":"code","b22c2147":"code","f200eef1":"code","94372265":"code","c1d209f8":"code","f136d542":"code","8795094e":"code","e9632b69":"code","bb565ce6":"code","ebd77178":"code","6ccd7485":"code","ed3a9c1e":"code","bed9f687":"code","e44bb296":"code","13592360":"code","57137bf8":"code","39b8d45f":"code","ea8bd891":"code","2f684e69":"code","7f53a178":"code","a59fa07c":"code","c34038c3":"code","dff25785":"code","d7dd0f3b":"code","cb04cbcd":"code","23309350":"code","24dbf829":"code","9ee335b8":"code","2eea39a5":"code","53b6956d":"code","d4dace58":"code","33890185":"code","af1ea69a":"code","bbea0404":"code","795c0cff":"code","e42ebac6":"code","07ae06dd":"code","4cbf048a":"code","c98dca0c":"code","25a6e0b8":"code","d54c940e":"code","29f39667":"code","ecab97d2":"code","c6b4f7d6":"code","dfc405b0":"code","7b5477d8":"code","9e45ffdc":"code","d8b7fae1":"code","3f89f8a8":"code","3e9e2094":"code","a1478e93":"code","3f902b39":"code","9c3590c4":"code","60131f92":"code","679892e8":"code","97a19b3b":"markdown","2ef875ef":"markdown","beaf3bb2":"markdown","fe6e6345":"markdown","98771b60":"markdown","79aa6886":"markdown","addf8105":"markdown","ca4ec9d6":"markdown","f14ff2e4":"markdown","486cd69a":"markdown","abb15426":"markdown","adfeaa25":"markdown","0fe7df4a":"markdown","5e3b3a3b":"markdown","0477780b":"markdown","a1d1a595":"markdown","a8a6edc0":"markdown","9ac106aa":"markdown"},"source":{"e432b8cb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","134aa9d4":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nplt.style.use('ggplot')","09d8ea12":"from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import RobustScaler, StandardScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom scipy.stats import skew\nfrom sklearn.decomposition import PCA, KernelPCA\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, KFold\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\nfrom sklearn.svm import SVR, LinearSVR\nfrom sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge\nfrom sklearn.kernel_ridge import KernelRidge\nfrom xgboost import XGBRegressor","70c38621":"import pandas as pd\nsample_submission = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","b22c2147":"plt.figure(figsize=(15,8))\nsns.boxplot(train.YearBuilt, train.SalePrice)","f200eef1":"#deleting outliers for GrLivArea with 800000 or more\nplt.figure(figsize=(12,6))\nplt.scatter(x=train.GrLivArea, y=train.SalePrice)\nplt.xlabel(\"GrLivArea\", fontsize=13)\nplt.ylabel(\"SalePrice\", fontsize=13)\nplt.ylim(0,800000)","94372265":"train.drop(train[(train[\"GrLivArea\"]>4000)&(train[\"SalePrice\"]<300000)].index,inplace=True)","c1d209f8":"full=pd.concat([train,test], ignore_index=True)\nfull.drop(['Id'],axis=1, inplace=True)\nfull.shape","f136d542":"aa = full.isnull().sum()\naa[aa>0].sort_values(ascending=False)","8795094e":"#Seeing the mean median and count of LotFrontage \nfull.groupby(['Neighborhood'])[['LotFrontage']].agg(['mean','median','count'])","e9632b69":"#Since LotArea is a continuous feature, We use qcut to divide it into 10 parts.\nfull[\"LotAreaCut\"] = pd.qcut(full.LotArea,10)\nfull.groupby(['LotAreaCut'])[['LotFrontage']].agg(['mean','median','count'])","bb565ce6":"#filling the LotFrontage with its median\nfull['LotFrontage']=full.groupby(['LotAreaCut','Neighborhood'])['LotFrontage'].transform(lambda x: x.fillna(x.median()))\nfull['LotFrontage']=full.groupby(['LotAreaCut'])['LotFrontage'].transform(lambda x: x.fillna(x.median()))","ebd77178":"#filling other missing values\ncols=[\"MasVnrArea\", \"BsmtUnfSF\", \"TotalBsmtSF\", \"GarageCars\", \"BsmtFinSF2\", \"BsmtFinSF1\", \"GarageArea\"]\nfor col in cols:\n    full[col].fillna(0, inplace=True)","6ccd7485":"cols1 = [\"PoolQC\" , \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\", \"GarageQual\", \"GarageCond\", \"GarageFinish\", \"GarageYrBlt\", \"GarageType\", \"BsmtExposure\", \"BsmtCond\", \"BsmtQual\", \"BsmtFinType2\", \"BsmtFinType1\", \"MasVnrType\"]\nfor col in cols1:\n    full[col].fillna(\"None\", inplace=True)","ed3a9c1e":"# fill in with mode\ncols2 = [\"MSZoning\", \"BsmtFullBath\", \"BsmtHalfBath\", \"Utilities\", \"Functional\", \"Electrical\", \"KitchenQual\", \"SaleType\",\"Exterior1st\", \"Exterior2nd\"]\nfor col in cols2:\n    full[col].fillna(full[col].mode()[0], inplace=True)","bed9f687":"full.isnull().sum()[full.isnull().sum()>0]","e44bb296":"#Converting some categorical values into numerical values\nNumStr = [\"MSSubClass\",\"BsmtFullBath\",\"BsmtHalfBath\",\"HalfBath\",\"BedroomAbvGr\",\"KitchenAbvGr\",\"MoSold\",\"YrSold\",\"YearBuilt\",\"YearRemodAdd\",\"LowQualFinSF\",\"GarageYrBlt\"]\nfor col in NumStr:\n    full[col]=full[col].astype(str)","13592360":"full.groupby(['MSSubClass'])[['SalePrice']].agg(['mean','median','count'])","57137bf8":"#mapping as many values to let the classifier choose \ndef map_values():\n    full[\"oMSSubClass\"] = full.MSSubClass.map({'180':1, \n                                        '30':2, '45':2, \n                                        '190':3, '50':3, '90':3, \n                                        '85':4, '40':4, '160':4, \n                                        '70':5, '20':5, '75':5, '80':5, '150':5,\n                                        '120': 6, '60':6})\n    \n    full[\"oMSZoning\"] = full.MSZoning.map({'C (all)':1, 'RH':2, 'RM':2, 'RL':3, 'FV':4})\n    \n    full[\"oNeighborhood\"] = full.Neighborhood.map({'MeadowV':1,\n                                               'IDOTRR':2, 'BrDale':2,\n                                               'OldTown':3, 'Edwards':3, 'BrkSide':3,\n                                               'Sawyer':4, 'Blueste':4, 'SWISU':4, 'NAmes':4,\n                                               'NPkVill':5, 'Mitchel':5,\n                                               'SawyerW':6, 'Gilbert':6, 'NWAmes':6,\n                                               'Blmngtn':7, 'CollgCr':7, 'ClearCr':7, 'Crawfor':7,\n                                               'Veenker':8, 'Somerst':8, 'Timber':8,\n                                               'StoneBr':9,\n                                               'NoRidge':10, 'NridgHt':10})\n    \n    full[\"oCondition1\"] = full.Condition1.map({'Artery':1,\n                                           'Feedr':2, 'RRAe':2,\n                                           'Norm':3, 'RRAn':3,\n                                           'PosN':4, 'RRNe':4,\n                                           'PosA':5 ,'RRNn':5})\n    \n    full[\"oBldgType\"] = full.BldgType.map({'2fmCon':1, 'Duplex':1, 'Twnhs':1, '1Fam':2, 'TwnhsE':2})\n    \n    full[\"oHouseStyle\"] = full.HouseStyle.map({'1.5Unf':1, \n                                           '1.5Fin':2, '2.5Unf':2, 'SFoyer':2, \n                                           '1Story':3, 'SLvl':3,\n                                           '2Story':4, '2.5Fin':4})\n    \n    full[\"oExterior1st\"] = full.Exterior1st.map({'BrkComm':1,\n                                             'AsphShn':2, 'CBlock':2, 'AsbShng':2,\n                                             'WdShing':3, 'Wd Sdng':3, 'MetalSd':3, 'Stucco':3, 'HdBoard':3,\n                                             'BrkFace':4, 'Plywood':4,\n                                             'VinylSd':5,\n                                             'CemntBd':6,\n                                             'Stone':7, 'ImStucc':7})\n    \n    full[\"oMasVnrType\"] = full.MasVnrType.map({'BrkCmn':1, 'None':1, 'BrkFace':2, 'Stone':3})\n    \n    full[\"oExterQual\"] = full.ExterQual.map({'Fa':1, 'TA':2, 'Gd':3, 'Ex':4})\n    \n    full[\"oFoundation\"] = full.Foundation.map({'Slab':1, \n                                           'BrkTil':2, 'CBlock':2, 'Stone':2,\n                                           'Wood':3, 'PConc':4})\n    \n    full[\"oBsmtQual\"] = full.BsmtQual.map({'Fa':2, 'None':1, 'TA':3, 'Gd':4, 'Ex':5})\n    \n    full[\"oBsmtExposure\"] = full.BsmtExposure.map({'None':1, 'No':2, 'Av':3, 'Mn':3, 'Gd':4})\n    \n    full[\"oHeating\"] = full.Heating.map({'Floor':1, 'Grav':1, 'Wall':2, 'OthW':3, 'GasW':4, 'GasA':5})\n    \n    full[\"oHeatingQC\"] = full.HeatingQC.map({'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n    \n    full[\"oKitchenQual\"] = full.KitchenQual.map({'Fa':1, 'TA':2, 'Gd':3, 'Ex':4})\n    \n    full[\"oFunctional\"] = full.Functional.map({'Maj2':1, 'Maj1':2, 'Min1':2, 'Min2':2, 'Mod':2, 'Sev':2, 'Typ':3})\n    \n    full[\"oFireplaceQu\"] = full.FireplaceQu.map({'None':1, 'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5})\n    \n    full[\"oGarageType\"] = full.GarageType.map({'CarPort':1, 'None':1,\n                                           'Detchd':2,\n                                           '2Types':3, 'Basment':3,\n                                           'Attchd':4, 'BuiltIn':5})\n    \n    full[\"oGarageFinish\"] = full.GarageFinish.map({'None':1, 'Unf':2, 'RFn':3, 'Fin':4})\n    \n    full[\"oPavedDrive\"] = full.PavedDrive.map({'N':1, 'P':2, 'Y':3})\n    \n    full[\"oSaleType\"] = full.SaleType.map({'COD':1, 'ConLD':1, 'ConLI':1, 'ConLw':1, 'Oth':1, 'WD':1,\n                                       'CWD':2, 'Con':3, 'New':3})\n    \n    full[\"oSaleCondition\"] = full.SaleCondition.map({'AdjLand':1, 'Abnorml':2, 'Alloca':2, 'Family':2, 'Normal':3, 'Partial':4})            \n                \n                        \n                        \n    \n    return \"Complete!\"","39b8d45f":"#calling the function to map the different values\nmap_values()","ea8bd891":"# drop 2 unwanted columns LotAreaCut & SalePrice(Target value)\nfull.drop(\"LotAreaCut\",axis=1,inplace=True)\nfull.drop(['SalePrice'],axis=1,inplace=True)","2f684e69":"#Label Encoding three \"Year\" features.\nclass labelenc(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    \n    def fit(self,X,y=None):\n        return self\n    \n    def transform(self,X):\n        lab=LabelEncoder()\n        X[\"YearBuilt\"] = lab.fit_transform(X[\"YearBuilt\"])\n        X[\"YearRemodAdd\"] = lab.fit_transform(X[\"YearRemodAdd\"])\n        X[\"GarageYrBlt\"] = lab.fit_transform(X[\"GarageYrBlt\"])\n        return X","7f53a178":"#Applying log1p {log(1 + x)} to the skewed features, then get_dummies.\nclass skew_dummies(BaseEstimator, TransformerMixin):\n    def __init__(self,skew=0.5):\n        self.skew = skew\n    \n    def fit(self,X,y=None):\n        return self\n    \n    def transform(self,X):\n        X_numeric=X.select_dtypes(exclude=[\"object\"])\n        skewness = X_numeric.apply(lambda x: skew(x))\n        skewness_features = skewness[abs(skewness) >= self.skew].index\n        X[skewness_features] = np.log1p(X[skewness_features])\n        X = pd.get_dummies(X)\n        return X","a59fa07c":"# building pipeline\npipe = Pipeline([('labenc', labelenc()),('skew_dummies', skew_dummies(skew=1)),])","c34038c3":"# saving the original data for later use\nfull2 = full.copy()","dff25785":"data_pipe = pipe.fit_transform(full2)\ndata_pipe.shape","d7dd0f3b":"data_pipe.head()","cb04cbcd":"#Scaling the data for other outliers\nscaler = RobustScaler()\n\nn_train=train.shape[0]\n\nX = data_pipe[:n_train]\ntest_X = data_pipe[n_train:]\ny= train.SalePrice\n\nX_scaled = scaler.fit(X).transform(X)\ny_log = np.log(train.SalePrice)\ntest_X_scaled = scaler.transform(test_X)","23309350":"lasso=Lasso(alpha=0.001)\nlasso.fit(X_scaled,y_log)","24dbf829":"FI_lasso = pd.DataFrame({\"Feature Importance\":lasso.coef_}, index=data_pipe.columns)\nFI_lasso.sort_values(\"Feature Importance\",ascending=False)","9ee335b8":"#plotting the above table\nFI_lasso[FI_lasso[\"Feature Importance\"]!=0].sort_values(\"Feature Importance\").plot(kind=\"barh\",figsize=(15,25))\nplt.xticks(rotation=90)\nplt.show()","2eea39a5":"#adding new features based on the Feature Importance plot\nclass add_feature(BaseEstimator, TransformerMixin):\n    def __init__(self,additional=1):\n        self.additional = additional\n    \n    def fit(self,X,y=None):\n        return self\n    \n    def transform(self,X):\n        if self.additional==1:\n            X[\"TotalHouse\"] = X[\"TotalBsmtSF\"] + X[\"1stFlrSF\"] + X[\"2ndFlrSF\"]   \n            X[\"TotalArea\"] = X[\"TotalBsmtSF\"] + X[\"1stFlrSF\"] + X[\"2ndFlrSF\"] + X[\"GarageArea\"]\n            \n        else:\n            X[\"TotalHouse\"] = X[\"TotalBsmtSF\"] + X[\"1stFlrSF\"] + X[\"2ndFlrSF\"]   \n            X[\"TotalArea\"] = X[\"TotalBsmtSF\"] + X[\"1stFlrSF\"] + X[\"2ndFlrSF\"] + X[\"GarageArea\"]\n            \n            X[\"+_TotalHouse_OverallQual\"] = X[\"TotalHouse\"] * X[\"OverallQual\"]\n            X[\"+_GrLivArea_OverallQual\"] = X[\"GrLivArea\"] * X[\"OverallQual\"]\n            X[\"+_oMSZoning_TotalHouse\"] = X[\"oMSZoning\"] * X[\"TotalHouse\"]\n            X[\"+_oMSZoning_OverallQual\"] = X[\"oMSZoning\"] + X[\"OverallQual\"]\n            X[\"+_oMSZoning_YearBuilt\"] = X[\"oMSZoning\"] + X[\"YearBuilt\"]\n            X[\"+_oNeighborhood_TotalHouse\"] = X[\"oNeighborhood\"] * X[\"TotalHouse\"]\n            X[\"+_oNeighborhood_OverallQual\"] = X[\"oNeighborhood\"] + X[\"OverallQual\"]\n            X[\"+_oNeighborhood_YearBuilt\"] = X[\"oNeighborhood\"] + X[\"YearBuilt\"]\n            X[\"+_BsmtFinSF1_OverallQual\"] = X[\"BsmtFinSF1\"] * X[\"OverallQual\"]\n            \n            X[\"-_oFunctional_TotalHouse\"] = X[\"oFunctional\"] * X[\"TotalHouse\"]\n            X[\"-_oFunctional_OverallQual\"] = X[\"oFunctional\"] + X[\"OverallQual\"]\n            X[\"-_LotArea_OverallQual\"] = X[\"LotArea\"] * X[\"OverallQual\"]\n            X[\"-_TotalHouse_LotArea\"] = X[\"TotalHouse\"] + X[\"LotArea\"]\n            X[\"-_oCondition1_TotalHouse\"] = X[\"oCondition1\"] * X[\"TotalHouse\"]\n            X[\"-_oCondition1_OverallQual\"] = X[\"oCondition1\"] + X[\"OverallQual\"]\n            \n           \n            X[\"Bsmt\"] = X[\"BsmtFinSF1\"] + X[\"BsmtFinSF2\"] + X[\"BsmtUnfSF\"]\n            X[\"Rooms\"] = X[\"FullBath\"]+X[\"TotRmsAbvGrd\"]\n            X[\"PorchArea\"] = X[\"OpenPorchSF\"]+X[\"EnclosedPorch\"]+X[\"3SsnPorch\"]+X[\"ScreenPorch\"]\n            X[\"TotalPlace\"] = X[\"TotalBsmtSF\"] + X[\"1stFlrSF\"] + X[\"2ndFlrSF\"] + X[\"GarageArea\"] + X[\"OpenPorchSF\"]+X[\"EnclosedPorch\"]+X[\"3SsnPorch\"]+X[\"ScreenPorch\"]\n\n    \n            return X","53b6956d":"#adding the feature in the pipeline\npipe = Pipeline([\n    ('labenc', labelenc()),\n    ('add_feature', add_feature(additional=2)),\n    ('skew_dummies', skew_dummies(skew=1)),\n    ])","d4dace58":"full_pipe = pipe.fit_transform(full)\nfull_pipe.shape","33890185":"n_train=train.shape[0]\nX = full_pipe[:n_train]\ntest_X = full_pipe[n_train:]\ny= train.SalePrice\n\nX_scaled = scaler.fit(X).transform(X)\ny_log = np.log(train.SalePrice)\ntest_X_scaled = scaler.transform(test_X)","af1ea69a":"pca = PCA(n_components=410)\n\nX_scaled=pca.fit_transform(X_scaled)\ntest_X_scaled = pca.transform(test_X_scaled)\n\nX_scaled.shape, test_X_scaled.shape","bbea0404":"# defining cross validation strategy i.e RMSE\ndef rmse_cv(model,X,y):\n    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=5))\n    return rmse","795c0cff":"models = [LinearRegression(),Ridge(),Lasso(alpha=0.01,max_iter=10000),RandomForestRegressor(),GradientBoostingRegressor(),SVR(),LinearSVR(),\n          ElasticNet(alpha=0.001,max_iter=10000),SGDRegressor(max_iter=1000,tol=1e-3),BayesianRidge(),KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5),\n          ExtraTreesRegressor(),XGBRegressor()]\n\nnames = [\"LR\", \"Ridge\", \"Lasso\", \"RF\", \"GBR\", \"SVR\", \"LinSVR\", \"Ela\",\"SGD\",\"Bay\",\"Ker\",\"Extra\",\"Xgb\"]\nfor name, model in zip(names, models):\n    score = rmse_cv(model, X_scaled, y_log)\n    print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std()))","e42ebac6":"#defining a gridsearch method\nclass grid():\n    def __init__(self,model):\n        self.model = model\n    \n    def grid_get(self,X,y,param_grid):\n        grid_search = GridSearchCV(self.model,param_grid,cv=5, scoring=\"neg_mean_squared_error\")\n        grid_search.fit(X,y)\n        print(grid_search.best_params_, np.sqrt(-grid_search.best_score_))\n        grid_search.cv_results_['mean_test_score'] = np.sqrt(-grid_search.cv_results_['mean_test_score'])\n        print(pd.DataFrame(grid_search.cv_results_)[['params','mean_test_score','std_test_score']])","07ae06dd":"grid(Lasso()).grid_get(X_scaled,y_log,{'alpha': [0.0004,0.0005,0.0007,0.0009],'max_iter':[10000]})","4cbf048a":"grid(Ridge()).grid_get(X_scaled,y_log,{'alpha':[35,40,45,50,55,60,65,70,80,90]})","c98dca0c":"grid(SVR()).grid_get(X_scaled,y_log,{'C':[11,13,15],'kernel':[\"rbf\"],\"gamma\":[0.0003,0.0004],\"epsilon\":[0.008,0.009]})","25a6e0b8":"param_grid={'alpha':[0.2,0.3,0.4], 'kernel':[\"polynomial\"], 'degree':[3],'coef0':[0.8,1]}\ngrid(KernelRidge()).grid_get(X_scaled,y_log,param_grid)","d54c940e":"grid(ElasticNet()).grid_get(X_scaled,y_log,{'alpha':[0.0008,0.004,0.005],'l1_ratio':[0.08,0.1,0.3],'max_iter':[10000]})","29f39667":"class AverageWeight(BaseEstimator, RegressorMixin):\n    def __init__(self,mod,weight):\n        self.mod = mod\n        self.weight = weight\n        \n    def fit(self,X,y):\n        self.models_ = [clone(x) for x in self.mod]\n        for model in self.models_:\n            model.fit(X,y)\n        return self\n    \n    def predict(self,X):\n        w = list()\n        pred = np.array([model.predict(X) for model in self.models_])\n        # for every data point, single model prediction times weight, then add them together\n        for data in range(pred.shape[1]):\n            single = [pred[model,data]*weight for model,weight in zip(range(pred.shape[0]),self.weight)]\n            w.append(np.sum(single))\n        return w","ecab97d2":"lasso = Lasso(alpha=0.0005,max_iter=10000)\nridge = Ridge(alpha=60)\nsvr = SVR(gamma= 0.0004,kernel='rbf',C=13,epsilon=0.009)\nker = KernelRidge(alpha=0.2 ,kernel='polynomial',degree=3 , coef0=0.8)\nela = ElasticNet(alpha=0.005,l1_ratio=0.08,max_iter=10000)\nbay = BayesianRidge()","c6b4f7d6":"# assign weights based on their gridsearch score\nw1 = 0.02\nw2 = 0.2\nw3 = 0.25\nw4 = 0.3\nw5 = 0.03\nw6 = 0.2","dfc405b0":"#averaging the weight\nweight_avg = AverageWeight(mod = [lasso,ridge,svr,ker,ela,bay],weight=[w1,w2,w3,w4,w5,w6])\n\nscore = rmse_cv(weight_avg,X_scaled,y_log)\nprint(score.mean())","7b5477d8":"#Averaging the best 2 models i.e. SVR and KernelRidge\nweight_avg = AverageWeight(mod = [svr,ker],weight=[0.5,0.5])\n\nscore = rmse_cv(weight_avg,X_scaled,y_log)\nprint(score.mean())","9e45ffdc":"class stacking(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self,mod,meta_model):\n        self.mod = mod\n        self.meta_model = meta_model\n        self.kf = KFold(n_splits=5, random_state=42, shuffle=True)\n        \n    def fit(self,X,y):\n        self.saved_model = [list() for i in self.mod]\n        oof_train = np.zeros((X.shape[0], len(self.mod)))\n        \n        for i,model in enumerate(self.mod):\n            for train_index, val_index in self.kf.split(X,y):\n                renew_model = clone(model)\n                renew_model.fit(X[train_index], y[train_index])\n                self.saved_model[i].append(renew_model)\n                oof_train[val_index,i] = renew_model.predict(X[val_index])\n        \n        self.meta_model.fit(oof_train,y)\n        return self\n    \n    def predict(self,X):\n        whole_test = np.column_stack([np.column_stack(model.predict(X) for model in single_model).mean(axis=1) \n                                      for single_model in self.saved_model]) \n        return self.meta_model.predict(whole_test)\n    \n    def get_oof(self,X,y,test_X):\n        oof = np.zeros((X.shape[0],len(self.mod)))\n        test_single = np.zeros((test_X.shape[0],5))\n        test_mean = np.zeros((test_X.shape[0],len(self.mod)))\n        for i,model in enumerate(self.mod):\n            for j, (train_index,val_index) in enumerate(self.kf.split(X,y)):\n                clone_model = clone(model)\n                clone_model.fit(X[train_index],y[train_index])\n                oof[val_index,i] = clone_model.predict(X[val_index])\n                test_single[:,j] = clone_model.predict(test_X)\n            test_mean[:,i] = test_single.mean(axis=1)\n        return oof, test_mean","d8b7fae1":"a = Imputer().fit_transform(X_scaled)\nb = Imputer().fit_transform(y_log.values.reshape(-1,1)).ravel()","3f89f8a8":"stack_model = stacking(mod=[lasso,ridge,svr,ker,ela,bay],meta_model=ker)","3e9e2094":"score = rmse_cv(stack_model,a,b)\nprint(score.mean())","a1478e93":"X_train_stack, X_test_stack = stack_model.get_oof(a,b,test_X_scaled)\n\nX_train_stack.shape, a.shape","3f902b39":"X_train_add = np.hstack((a,X_train_stack))\n\nX_test_add = np.hstack((test_X_scaled,X_test_stack))\n\nX_train_add.shape, X_test_add.shape","9c3590c4":"score = rmse_cv(stack_model,X_train_add,b)\nprint(score.mean())","60131f92":"stack_model = stacking(mod=[lasso,ridge,svr,ker,ela,bay],meta_model=ker)\nstack_model.fit(a,b)","679892e8":"pred = np.exp(stack_model.predict(test_X_scaled))\nresult=pd.DataFrame({'Id':test.Id, 'SalePrice':pred})\nresult.to_csv(\"submission.csv\",index=False)","97a19b3b":"### ElasticNet","2ef875ef":"### extracting the features generated from stacking, then combine them with original features.","beaf3bb2":"**Finding the null values**","fe6e6345":"## Modelling","98771b60":"## Stacking the models\n### also combining the stacking and original features","79aa6886":"### KernelRidge","addf8105":"it gives a better result","ca4ec9d6":"## **using Lasso**","f14ff2e4":"# More Feature Engineering","486cd69a":"### Ridge","abb15426":"### SVR","adfeaa25":"### doing Principal Component Analysis (PCA) to examine the interrelation among a set of variables ","0fe7df4a":"Hence there is no missing values except the target value","5e3b3a3b":"prices of recent built houses are higher","0477780b":"### hyperparameters tuning","a1d1a595":"## Average base models according to their weights.","a8a6edc0":"### Lasso","9ac106aa":"# Building a Pipeline"}}