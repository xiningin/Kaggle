{"cell_type":{"c583d085":"code","674681e0":"code","89e26db7":"code","b1c86af5":"code","9eb8a02a":"code","75c78746":"code","db04b320":"code","ff9cdc11":"code","b49febd9":"code","4801606b":"code","cbdbf81c":"code","8e80d881":"code","2ddf8fca":"code","86f2affe":"code","48c8c6f9":"markdown","82a81db0":"markdown","7e92f2f6":"markdown","a00c3845":"markdown","9f38cdcf":"markdown","be6bbc4e":"markdown"},"source":{"c583d085":"from pandas import read_csv, DataFrame, to_datetime\nfrom numpy import radians, sin, cos, arcsin, sqrt, mean\nfrom sklearn import ensemble\nimport time\nfrom datetime import datetime\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\n\n","674681e0":"train = read_csv(\"..\/input\/train.csv\")\ntest = read_csv(\"..\/input\/test.csv\")\n","89e26db7":"# Since the training file is very large, I only use the first 1 million records\ntrain = train[:5000000]","b1c86af5":"#Identify null values\n\nprint(train.isnull().sum())","9eb8a02a":"#Drop rows with null values\ntrain = train.dropna(how = 'any', axis = 'rows')","75c78746":"# Then we take all the values between the minimum and the maximum for each column\n\npickup_longitude_min = test.pickup_longitude.min()\npickup_longitude_max = test.pickup_latitude.max()\npickup_latitude_min = test.pickup_latitude.min()\npickup_latitude_max = test.pickup_latitude.max()\ndropoff_longitude_min = test.dropoff_longitude.min()\ndropoff_longitude_max = test.dropoff_longitude.max()\ndropoff_latitude_min = test.dropoff_latitude.min()\ndropoff_latitude_max = test.dropoff_latitude.max()\n\ntrain = train.loc[(train['fare_amount'] > 0) & (train['fare_amount'] < 300)]\ntrain = train.loc[(train['pickup_longitude'] > pickup_longitude_min) & (train['pickup_longitude'] < pickup_longitude_max)]\ntrain = train.loc[(train['pickup_latitude'] > pickup_latitude_min) & (train['pickup_latitude'] < pickup_latitude_max)]\ntrain = train.loc[(train['dropoff_longitude'] > dropoff_longitude_min) & (train['dropoff_longitude'] < dropoff_longitude_max)]\ntrain = train.loc[(train['dropoff_latitude'] > dropoff_latitude_min) & (train['dropoff_latitude'] < dropoff_latitude_max)]","db04b320":"# Using the formulas of spherical trigonometry, we find the distance between points\n\ndef rasst(value1, value2, value3, value4):\n\n    longitude_1, latitude_1, longitude_2, latitude_2 = value1, value2, value3, value4\n    longitude_1, latitude_1, longitude_2, latitude_2 = map(radians, [longitude_1, latitude_1, longitude_2, latitude_2])\n\n    dlongitude = longitude_2 - longitude_1\n    dlatitude = latitude_2 - latitude_1\n\n    value = sin(dlatitude\/2.0)**2 + cos(latitude_1) * cos(latitude_2) * sin(dlongitude\/2.0)**2\n\n    c = 2 * arcsin(sqrt(value))\n    km = c * 6367\n    return km","ff9cdc11":"# Sort the date by individual columns\n\ntrain['pickup_datetime'] = to_datetime(train['pickup_datetime'])\ntrain['hour_of_day'] = train.pickup_datetime.dt.hour.astype(float)\ntrain['day'] = train.pickup_datetime.dt.day.astype(float)\ntrain['week'] = train.pickup_datetime.dt.week.astype(float)\ntrain['month'] = train.pickup_datetime.dt.month.astype(float)\ntrain['day_of_year'] = train.pickup_datetime.dt.dayofyear.astype(float)\ntrain['week_of_year'] = train.pickup_datetime.dt.weekofyear.astype(float)\ntrain['passenger_count'] = train['passenger_count'].astype(float)\ntrain['rasst'] = rasst(train['pickup_longitude'], train['pickup_latitude'], train['dropoff_longitude'], train['dropoff_latitude'])\n\ntest['pickup_datetime'] = to_datetime(test['pickup_datetime'])\ntest['hour_of_day'] = test.pickup_datetime.dt.hour.astype(float)\ntest['day'] = test.pickup_datetime.dt.day.astype(float)\ntest['week'] = test.pickup_datetime.dt.week.astype(float)\ntest['month'] = test.pickup_datetime.dt.month.astype(float)\ntest['day_of_year'] = test.pickup_datetime.dt.dayofyear.astype(float)\ntest['week_of_year'] = test.pickup_datetime.dt.weekofyear.astype(float)\ntest['passenger_count'] = test['passenger_count'].astype(float)\ntest['rasst'] = rasst(test['pickup_longitude'], test['pickup_latitude'], test['dropoff_longitude'], test['dropoff_latitude'])","b49febd9":"test.head()","4801606b":"train.head()\n","cbdbf81c":"train_y = train[\"fare_amount\"]\ntest_key = test['key']\ntrain_x = train.drop([\"fare_amount\", \"key\"], axis = 1)\ntrain_x = train_x.drop(['pickup_datetime'], axis = 1)\ntest = test.drop(['pickup_datetime', 'key'], axis = 1)\n","8e80d881":"\n\ntrain_xgb = xgb.DMatrix(train_x, train_y)\ntest_xgb = xgb.DMatrix(test)\n\n","2ddf8fca":"# Since there is a lot of data, we use the approximation in three-methods\n\nnum_round = 10\nparam = {'max_depth':20, 'eta':0.5,'min_child-weight':2, 'gamma':2, 'booster':'dart', 'three-method':'approx', 'normalize_type':'forest', 'rate_drop':0.5, 'eval_metric':'rmse'}\ntrain = xgb.train(param, train_xgb, num_round)\npredict = train.predict(test_xgb, ntree_limit = num_round)","86f2affe":"#Create submission file\nsubmission = DataFrame({\n        \"key\": test_key,\n        \"fare_amount\": predict.round(2)\n})\n\nsubmission.to_csv('taxi_fare_submission.csv',index=False)\nsubmission.head()","48c8c6f9":"Since there is a lot of data, we use the approximation","82a81db0":"Using the formulas of spherical trigonometry, we find the distance between points","7e92f2f6":"We have a few rows with null values so it is safe to remove them.","a00c3845":"Then we take all the values between the minimum and the maximum for each column","9f38cdcf":"Since the training file is very large, I only use the first 5 million records","be6bbc4e":"\nSort the date by individual columns"}}