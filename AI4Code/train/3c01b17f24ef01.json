{"cell_type":{"745f656a":"code","5d8ed6f0":"code","e4e8053e":"code","44feeb8a":"code","c16c930f":"code","4fdc7b22":"code","ec8032bc":"code","56f80206":"code","df894188":"code","1d8bd4a9":"code","93e1ac8f":"code","3cd049ff":"code","1a9fdcd0":"code","813d6883":"code","b8fa7179":"code","2d641139":"code","6e3c0aa3":"code","dec99939":"code","ffac5044":"code","9119e2f6":"code","5096caea":"code","731d8b11":"code","319b14ef":"code","11c73814":"code","22f02d9d":"code","68250c67":"code","68f489a4":"code","f28e7f37":"code","6a137cc5":"code","1aac56cd":"code","6f03ab2e":"code","d53648b5":"code","3dbd76c3":"code","7441d2db":"code","42cd5cf3":"markdown","12087e5b":"markdown","b0a2e8bc":"markdown","e5e5d631":"markdown","3c7f863c":"markdown","8ff15438":"markdown","e1c26a7b":"markdown","4cdb0533":"markdown","34210268":"markdown","2b7ae29c":"markdown","46cea83a":"markdown","512ddb8c":"markdown","e9a8d693":"markdown"},"source":{"745f656a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5d8ed6f0":"train_df  = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\nprint (\"*\"*10, \"Dataset information\", \"*\"*10)\nprint (train_df.info())","e4e8053e":"print (\"*\"*10, \"First 5 Train File Rows\", \"*\"*10)\ntrain_df.head(5)","44feeb8a":"test_df = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nprint(test_df.info())","c16c930f":"train_df.drop(['Name', 'Ticket','Cabin'], inplace= True, axis = 1)\ntest_df.drop(['Name', 'Ticket', 'Cabin'], inplace= True, axis = 1)","4fdc7b22":"print(train_df.info(), test_df.info())","ec8032bc":"train_df.isnull().sum()","56f80206":"test_df.isnull().sum()","df894188":"train_df.Embarked.value_counts()","1d8bd4a9":"#Embarked null fix\ndata = [train_df, test_df]\n\nfor dataset in data:\n    dataset.Embarked = dataset.Embarked.fillna('S')","93e1ac8f":"train_df.Fare.value_counts()","3cd049ff":"train_df.Age.value_counts()","1a9fdcd0":"#Age, Fare null fix\ndata = [train_df, test_df]\n\nfor dataset in data:\n    dataset.Fare = dataset.Fare.fillna(dataset.Fare.mean())\n    dataset.Age = dataset.Age.fillna(dataset.Age.mean())","813d6883":"train_df.isnull().sum()","b8fa7179":"print(train_df.info(), test_df.info())","2d641139":"train_df.Age.value_counts()","6e3c0aa3":"train_df[['Age', 'Survived']].groupby(['Age'], as_index = False).mean().sort_values(by = \"Survived\", ascending = False)","dec99939":"tempFare = train_df.Fare\ntempFare = pd.qcut(tempFare, 5)\ntempFare.value_counts()","ffac5044":"data = [train_df, test_df]\n\nfor dataset in data:\n    dataset.loc[(dataset['Fare'] <= 7.854), 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] >= 7.854) & (dataset['Fare'] <= 10.5), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] >= 10.5) & (dataset['Fare'] <= 21.679), 'Fare'] = 2\n    dataset.loc[(dataset['Fare'] >= 21.679) & (dataset['Fare'] <= 39.688), 'Fare'] = 3\n    dataset.loc[(dataset['Fare'] >= 39.688), 'Fare'] = 4\n    dataset.Fare = dataset['Fare'].astype(int)\n    \ntrain_df.Fare.value_counts()","9119e2f6":"tempAge = train_df.Age\ntempAge = pd.qcut(tempAge, 5)\ntempAge.value_counts()","5096caea":"data = [train_df, test_df]\n\nfor dataset in data:\n    dataset.loc[(dataset['Age'] <= 20.0), 'Age'] = 0\n    dataset.loc[(dataset['Age'] >=20.0) & (dataset['Age'] <= 28.0), 'Age'] = 1\n    dataset.loc[(dataset['Age'] >= 28.0) & (dataset['Age'] <= 29.699), 'Age'] = 2\n    dataset.loc[(dataset['Age'] >= 29.699) & (dataset['Age'] <= 38.0 ), 'Age'] = 3\n    dataset.loc[(dataset['Age'] >= 38.0), 'Age'] = 4\n    dataset.Fare = dataset['Age'].astype(int)\n    \ntrain_df.Age.value_counts()","731d8b11":"print(train_df.info(), test_df.info())","319b14ef":"print(train_df['Sex'].value_counts())\nprint(train_df['Embarked'].value_counts())","11c73814":"genderMap = {\"male\": 0, \"female\": 1}\nembarkedMap = {\"S\": 0, \"C\": 1, \"Q\":2}\n\ndata = [train_df, test_df] \n\nfor dataset in data:\n    dataset['Sex'] = dataset['Sex'].map(genderMap)\n    dataset['Embarked'] = dataset['Embarked'].map(embarkedMap)","22f02d9d":"print(train_df.info(), test_df.info())","68250c67":"X_train = train_df.drop(['Survived', 'PassengerId'], axis=1)\nY_train = train_df['Survived']\n\nX_test = test_df.drop(\"PassengerId\", axis=1)","68f489a4":"#1. Logistic Regression\n\nfrom sklearn.linear_model import LogisticRegression\n\nclf_lr = LogisticRegression(random_state = 0) \nclf_lr.fit(X_train, Y_train) \n\nacc_logistic = round(clf_lr.score(X_train, Y_train)*100, 2)\n\nprint (acc_logistic)","f28e7f37":"#2. SVM\nfrom sklearn.svm import SVC\n\nclf_svm = SVC() \nclf_svm.fit(X_train, Y_train) \n\nacc_svm = round(clf_svm.score(X_train, Y_train)*100, 2)\n\nprint (acc_svm)","6a137cc5":"#3. Gaussian Naive Bayes\nfrom sklearn.naive_bayes import GaussianNB\n\nclf_gnb = GaussianNB()\nclf_gnb.fit(X_train, Y_train) \n\nacc_gnb = round(clf_gnb.score(X_train, Y_train)*100, 2)\n\nprint (acc_gnb)","1aac56cd":"#4. Ridge Classifier\nfrom sklearn.linear_model import RidgeClassifier\n\nclf_rc = RidgeClassifier()\nclf_rc.fit(X_train, Y_train) \n\nacc_rc = round(clf_rc.score(X_train, Y_train)*100, 2)\n\nprint (acc_rc)","6f03ab2e":"#5. K Nearest Neighbours Classifier (KNN)\nfrom sklearn.neighbors import KNeighborsClassifier\n\nclf_knn = KNeighborsClassifier(n_neighbors=3)\nclf_knn.fit(X_train, Y_train)\n\nacc_knn = round(clf_knn.score(X_train, Y_train)*100, 2)\n\nprint (acc_knn)","d53648b5":"### Best score submission to the leaderboard","3dbd76c3":"Y_pred  = clf_knn.predict(X_test)","7441d2db":"output = pd.DataFrame({'PassengerId': test_df.PassengerId, 'Survived': Y_pred})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","42cd5cf3":"### Intermediate Level 2.0 - The Titanic Dataset\u00b6\n","12087e5b":"### Fixed NULL values for Fare and Age features by Mean value","b0a2e8bc":"### Deleting features that we are not using for the INTERMEDIATE Solution","e5e5d631":"### Data PreProcessing on 2 features - Age and Fare","3c7f863c":"### Model Training","8ff15438":"This notebook is created in for the Youtube Channel Video.\n\nChannel Link:https:\/\/www.youtube.com\/c\/TheIndianDeveloper\n\nVideo Link:https:\/\/youtu.be\/uE6u0jxsRis\n\n![2.0%20banner%20less%20than%201.png](attachment:2.0%20banner%20less%20than%201.png)","e1c26a7b":"If you have reached till here, share your experience in the comments section. \n\nNext, I will be creating an Advanced version of this where we will add all the remaining features, create 1-2 new features, do some data cleaning and feature engineering. Also, I will show how to use few other models and see compare the scores. \n\n## If you like the notebook please upvote for it!\n\nPlease share your reviews on my video: \n## Video Link:https:\/\/youtu.be\/uE6u0jxsRis\n\nStay tuned!","4cdb0533":"### Identify Features with NULL values, Fix the NULL values","34210268":"### Identify columns with datatype other than int or float","2b7ae29c":"### Final check on the Data.","46cea83a":"### Fix Null Values of Embarked Features","512ddb8c":"### Separating X's and Y's i.e. features and labels","e9a8d693":"### Read the Data, describe rows and columns"}}