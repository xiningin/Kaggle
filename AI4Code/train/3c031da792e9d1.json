{"cell_type":{"7a9c5110":"code","66402ee2":"code","c61794f7":"code","e844b094":"code","69a3fda5":"code","5b92f776":"code","c8ccd707":"code","daa67b0a":"code","17118c59":"code","e1de52d2":"code","e687ea1c":"markdown"},"source":{"7a9c5110":"import numpy as np\n\nfrom keras.datasets import cifar10\nfrom keras.utils.np_utils import to_categorical ","66402ee2":"(X_train, y_train), (X_test, y_test) = cifar10.load_data()","c61794f7":"print(\"Shape of training data:\")\nprint(X_train.shape)\nprint(y_train.shape)\nprint(\"Shape of test data:\")\nprint(X_test.shape)\nprint(y_test.shape)","e844b094":"import matplotlib.pyplot as plt\n\ncifar_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\nprint('Example training images and their labels: ' + str([x[0] for x in y_train[0:5]])) \nprint('Corresponding classes for the labels: ' + str([cifar_classes[x[0]] for x in y_train[0:5]]))\n\nf, axarr = plt.subplots(1, 5)\nf.set_size_inches(16, 6)\n\nfor i in range(5):\n    img = X_train[i]\n    axarr[i].imshow(img)\nplt.show()","69a3fda5":"# Transform label indices to one-hot encoded vectors\n\ny_train = to_categorical(y_train, num_classes=10)\ny_test = to_categorical(y_test, num_classes=10)\n\n# Transform images from (32,32,3) to 3072-dimensional vectors (32*32*3)\n\nX_train = np.reshape(X_train,(50000,3072))\nX_test = np.reshape(X_test,(10000,3072))\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\n# Normalization of pixel values (to [0-1] range)\n\nX_train \/= 255\nX_test \/= 255","5b92f776":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom tensorflow.keras.optimizers import SGD\n\nmodel = Sequential()\nmodel.add(Dense(256, activation='relu', input_dim=3072))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n\nmodel.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])","c8ccd707":"# Training the MLP\n\nhistory = model.fit(X_train,y_train, epochs=10, batch_size=32, verbose=1, validation_split=0.2)","daa67b0a":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show()","17118c59":"# Evaluating the MLP\nscore = model.evaluate(X_test, y_test, batch_size=128, verbose=0)","e1de52d2":"print(model.metrics_names)\nprint(score)","e687ea1c":"2. Classify CIFAR-10 data set using MLP classifier. Perform the following"}}