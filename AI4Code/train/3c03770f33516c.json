{"cell_type":{"435f070b":"code","dca7067d":"code","615140ff":"code","3f4ab0e8":"code","6bf8cdb5":"code","d3461f58":"code","318de882":"code","6e943b36":"code","c5b3c6cd":"code","399b9cd3":"code","b37e16be":"code","68803596":"code","de20e2f7":"code","b1baf85e":"code","01a6a90b":"code","976dd4f7":"code","74826943":"code","933fe7b3":"code","a606c650":"code","460d59c8":"code","a6320fc6":"code","6c363d3e":"code","3ee3663a":"code","f8789ac1":"code","46d50567":"code","9670ff4d":"code","ec576281":"code","c5ee17bc":"code","9cec71bd":"code","f370871d":"code","25c17167":"code","a6cc8aa6":"code","4a441556":"code","e6823829":"code","58df077c":"code","170db555":"code","ba89a4f1":"code","60e51fc4":"code","9a505e54":"code","0248e450":"code","ea0c3ace":"code","a4b1d60b":"code","4f8040d9":"code","eff5c943":"code","09e29cbb":"code","683dc0a8":"code","428f5ab4":"code","651e97a8":"code","b0c7aeff":"code","d86edc9a":"code","10801443":"code","c8169caf":"code","e1c68d73":"code","50be4081":"code","d284e118":"code","8f19c13b":"markdown","c9535f16":"markdown","12d177a1":"markdown","139766f5":"markdown","59bf9cd0":"markdown","1d43a264":"markdown","468c70ed":"markdown","3ea1de56":"markdown","e456f082":"markdown","81b31a70":"markdown","d5c6c375":"markdown","3329728c":"markdown","37215aa7":"markdown","fd60defe":"markdown"},"source":{"435f070b":"import nltk\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use(style='ggplot')\nplt.rcParams['figure.figsize'] = (10,8)\nimport seaborn as sns\n%matplotlib inline\nimport re\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\nimport pandas_profiling","dca7067d":"#Load data as Pandas Dataframe\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","615140ff":"def columns(num_str, letter_equal_to_one, name_of_column):\n    list1 = []\n    for word in train['type'].str[num_str]:\n        if word == letter_equal_to_one:\n            list1.append(1)\n        else:\n            list1.append(0)\n    train[name_of_column] = list1","3f4ab0e8":"columns(0, 'E', 'Mind')\ncolumns(1, 'N', 'Energy')\ncolumns(2, 'T', 'Nature')\ncolumns(3, 'J', 'Tactics')","6bf8cdb5":"#plugging the data into the library for EDA\npandas_profiling.ProfileReport(train.drop('posts', axis=1))","d3461f58":"#remove urls\npattern_url = r'http[s]?:\/\/(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\nsubs_url = r'url-web'\ntrain['posts'] = train['posts'].replace(to_replace = pattern_url, value = subs_url, regex = True)\ntest['posts'] = test['posts'].replace(to_replace = pattern_url, value = subs_url, regex = True)","318de882":"#turn to lowercase\ntrain['posts'] = train['posts'].str.lower()","6e943b36":"test['posts'] = test['posts'].str.lower()","c5b3c6cd":"import string\nprint(string.punctuation)\ndef remove_punctuation(post):\n    return ''.join([l for l in post if l not in string.punctuation])","399b9cd3":"train['posts'] = train['posts'].apply(remove_punctuation)","b37e16be":"test['posts'] = test['posts'].apply(remove_punctuation)","68803596":"from nltk.tokenize import word_tokenize, TreebankWordTokenizer\ntokeniser = TreebankWordTokenizer()\ntrain['posts'] = train['posts'].apply(tokeniser.tokenize)\ntest['posts'] = test['posts'].apply(tokeniser.tokenize)","de20e2f7":"def post_stemmer(words, stemmer):\n    return [stemmer.stem(word) for word in words]","b1baf85e":"from nltk import SnowballStemmer, PorterStemmer, LancasterStemmer\nstemmer = SnowballStemmer('english')\ntrain['posts'] = train['posts'].apply(post_stemmer, args=(stemmer, ))\ntest['posts'] = test['posts'].apply(post_stemmer, args=(stemmer, ))","01a6a90b":"from nltk.stem import WordNetLemmatizer\nnltk.download('wordnet')\n\nlemmatizer = WordNetLemmatizer()","976dd4f7":"def mbti_lemma(words, lemmatizer):\n    return [lemmatizer.lemmatize(word) for word in words]","74826943":"train['posts'] = train['posts'].apply(mbti_lemma, args=(lemmatizer, ))\ntest['posts'] = test['posts'].apply(mbti_lemma, args=(lemmatizer, ))","933fe7b3":"from nltk.corpus import stopwords\ndef remove_stop_words(tokens):\n    return [t for t in tokens if t not in stopwords.words('english')]","a606c650":"from nltk.corpus import stopwords\ntrain['posts'] = train['posts']\nstop = stopwords.words('english')\ntrain['posts'] = train['posts'].apply(lambda x: [item for item in x if item not in stop])","460d59c8":"test['posts'] = test['posts']\nstop = stopwords.words('english')\ntest['posts'] = test['posts'].apply(lambda x: [item for item in x if item not in stop])","a6320fc6":"# Machine Learning.\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import CountVectorizer","6c363d3e":"from sklearn.pipeline import Pipeline","3ee3663a":"model1=Pipeline([('Vectorizer', CountVectorizer(min_df=2, ngram_range=(1, 2),tokenizer= list, preprocessor= list)), ('model', LogisticRegression(penalty='l2', \n                           C=0.005, fit_intercept=True))])","f8789ac1":"dfLogReg1 = test[['id']]","46d50567":"X = train['posts']\ny = train['Mind']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)\nmodel1.fit(X_train, y_train)\npred_mind = model1.predict(X_test)","9670ff4d":"X = train['posts']\ny = train['Energy']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)\nmodel1.fit(X_train, y_train)\npred_energy = model1.predict(X_test)","ec576281":"X = train['posts']\ny = train['Nature']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)\nmodel1.fit(X_train, y_train)\npred_nature = model1.predict(X_test)","c5ee17bc":"X = train['posts']\ny = train['Tactics']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)\nmodel1.fit(X_train, y_train)\npred_tactics = model1.predict(X_test)","9cec71bd":"print(\"The accuracy score of the model Logistic Regession Mind is:\", accuracy_score(y_test_Mind, pred_mind))\nprint(\"The accuracy score of the model Logistic Regession Energy is:\", accuracy_score(y_test_Energy, pred_energy))\nprint(\"The accuracy score of the model Logistic Regession Nature is:\", accuracy_score(y_test_Nature, pred_nature))\nprint(\"The accuracy score of the model Logistic Regession Tactics is:\", accuracy_score(y_test_Tactics, pred_tactics))","f370871d":"X = train['posts']\ny = train['Mind']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)\nmodel1.fit(X_train, y_train)\npred_mind = model1.predict(test['posts'])\ndfLogReg1['mind'] = pred_mind\n\nX = train['posts']\ny = train['Energy']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)\nmodel1.fit(X_train, y_train)\npred_energy = model1.predict(test['posts'])\ndfLogReg1['energy'] = pred_energy\n\nX = train['posts']\ny = train['Nature']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)\nmodel1.fit(X_train, y_train)\npred_nature = model1.predict(test['posts'])\ndfLogReg1['nature'] = pred_nature\n\nX = train['posts']\ny = train['Tactics']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)\nmodel1.fit(X_train, y_train)\npred_tactics = model1.predict(test['posts'])\ndfLogReg1['tactics'] = pred_tactics","25c17167":"dfLogReg1.to_csv('BestSubLogRegV1.csv', index=False)","a6cc8aa6":"#trying out random forest classifier","4a441556":"from sklearn.ensemble import RandomForestClassifier\nmodelRF1=Pipeline([('Vectorizer', CountVectorizer(tokenizer= list, preprocessor= list)), ('model', RandomForestClassifier(bootstrap=True, max_depth=70, max_features='auto', min_samples_leaf=4, min_samples_split=10, n_estimators=400))])","e6823829":"dfRFC1 = test[['id']]","58df077c":"X = train['posts']\ny = train['Mind']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=11)\nmodelRF1.fit(X_train, y_train)\npred_mind = modelRF1.predict(X_test)","170db555":"X = train['posts']\ny = train['Energy']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=11)\nmodelRF1.fit(X_train, y_train)\npred_energy = modelRF1.predict(X_test)","ba89a4f1":"X = train['posts']\ny = train['Nature']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)\nmodelRF1.fit(X_train, y_train)\npred_nature = modelRF1.predict(X_test)","60e51fc4":"X = train['posts']\ny = train['Tactics']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)\nmodelRF1.fit(X_train, y_train)\npred_tactics = modelRF1.predict(X_test)","9a505e54":"print(\"The accuracy score of the model Random Forest Mind is:\", accuracy_score(y_test_Mind, RFpred_mind))\nprint(\"The accuracy score of the model Random Forest Energy is:\", accuracy_score(y_test_Energy, RFpred_energy))\nprint(\"The accuracy score of the model Random Forest Nature is:\", accuracy_score(y_test_Nature, RFpred_nature))\nprint(\"The accuracy score of the model Random Forest Tactics is:\", accuracy_score(y_test_Tactics, RFpred_tactics))","0248e450":"#gave a worse score than logistic regression","ea0c3ace":"#using random search for best parameters","a4b1d60b":"#from scipy.stats import uniform\n#from sklearn.model_selection import RandomizedSearchCV","4f8040d9":"#lr=LogisticRegression()","eff5c943":"#train['posts']=[\" \".join(post) for post in train['posts']]","09e29cbb":"#train['posts'].head()","683dc0a8":"#count_vectorizer = CountVectorizer(min_df=2, ngram_range=(1,2))\n#x_cv = count_vectorizer.fit_transform(train['posts'])","428f5ab4":"#X = x_cv\n\n#y = train['Mind']\n#penalty = ['l1', 'l2']\n#C = uniform(0.0001,30)\n#hyperparameters = dict(C=C, penalty=penalty)\n#clf = RandomizedSearchCV(lr, hyperparameters, random_state=1, n_iter=50, cv=5, verbose=0, n_jobs=-1)\n#best_model = clf.fit(X, y)","651e97a8":"#print(\"Tuned Logistic Parameters: {}\".format(best_model.best_params_))","b0c7aeff":"model4=Pipeline([('Vectorizer', CountVectorizer(min_df=2, ngram_range=(1, 2),tokenizer= list, preprocessor= list)), ('model', LogisticRegression(penalty='l1', \n                           C=0.06416732983821728))])","d86edc9a":"dfLogReg4 = test[['id']]","10801443":"X = train['posts']\ny = train['Mind']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)\nmodel4.fit(X_train, y_train)\npred_mind = model4.predict(test['posts'])\ndfLogReg4['mind'] = pred_mind","c8169caf":"X = train['posts']\ny = train['Energy']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)\nmodel4.fit(X_train, y_train)\npred_energy = model4.predict(test['posts'])\ndfLogReg4['energy'] = pred_energy","e1c68d73":"X = train['posts']\ny = train['Nature']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)\nmodel4.fit(X_train, y_train)\npred_nature = model4.predict(test['posts'])\ndfLogReg4['nature'] = pred_nature","50be4081":"X = train['posts']\ny = train['Tactics']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)\nmodel4.fit(X_train, y_train)\npred_tactics = model4.predict(test['posts'])\ndfLogReg4['tactics'] = pred_tactics","d284e118":"dfLogReg4.to_csv('FinalSubLogRegV7.csv', index=False)","8f19c13b":"##### Stop Words\nuseless words","c9535f16":"We create a function to encode MBTI types into four categories.","12d177a1":"We create a function to remove punctuation","139766f5":"##### Lemmatization\nMorphological analysis of the word","59bf9cd0":"## Implementing results from random search function","1d43a264":"##### Tokenizing \nsplitting into words","468c70ed":"## EDA\nusing pandas profiling","3ea1de56":"##### Stemming \nNormalize words into its base form or root form","e456f082":"## Parameter Tuning Model","81b31a70":"## Load packages and data","d5c6c375":"# Personality Profile Prediction\n\nIn this notebook, we will be covering steps required to train a model capable of predicting a person's Myers-Briggs Type Indicator (MBTI) personality type, using only what they post online.\n\nFour dimensions of the MBTI:\n* **Mind** - **I**ntroversion vs **E**xtroversion\n* **Energy** - i**N**tuition vs **S**ensing\n* **Nature** - **T**hinking vs **F**eeling\n* **Tacticts** - **J**udging vs **P**ercieving\n\nWe will be using NLP techniques to process these 'post' features to predict the 'type' labels.","3329728c":"### Pre - Processing\n* Splitting the data into feature and labels\n* Splitting the data into training and testing data","37215aa7":"## Model Creation","fd60defe":"## NPL techniques \ntransforming unstructured data into structured data"}}