{"cell_type":{"f8afe77f":"code","3006582e":"code","e600cb84":"code","385bb1ff":"code","fa21d6bc":"code","fd6095a1":"code","83a1136d":"markdown","54231f7a":"markdown","5888850d":"markdown","26edd598":"markdown","8a24b171":"markdown","ca19eb08":"markdown","66c3dbf8":"markdown","04d80f7b":"markdown","bb3faf5a":"markdown","37487c54":"markdown"},"source":{"f8afe77f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3006582e":"%matplotlib notebook\nimport pandas as pd\nimport seaborn as sn\nimport numpy as np\nfrom sklearn.neural_network import MLPClassifier   #Multi-Layer Perceptron Classifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nimport matplotlib.pyplot as plt     \nfrom prettytable import from_csv    #To draw tables\n\ndataset=pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')\n\n#dataset.describe()\n\nprint(\"The dataset shape is : \",dataset.shape)     #prints shape of dataset\n\n    \ndataset.head()","e600cb84":"data=dataset.drop(['trestbps','fbs','exang','oldpeak','slope','ca','thal','target'],axis=1)\nlabels=dataset[['target']]\nprint(data.head(5))     #prints the first 5 values\nlabels=np.asarray(labels)\nlabels=labels.ravel()\n#print(labels)","385bb1ff":"x_train,x_test,y_train,y_test=train_test_split(data,labels,test_size=0.2,random_state=4)\nmodel1=MLPClassifier(activation='relu',solver='lbfgs',alpha=1e-5,random_state=1,)   #\nmodel1.fit(x_train,y_train)\nk1=model1.predict(x_test)\nprint(\"Accuracy of the MLP Classifier model on unseen data is \"+str(accuracy_score(k1,y_test)*100)+\" %\")\nmodel2=SVC(kernel='linear')\nmodel2.fit(x_train,y_train)\nk2=model2.predict(x_test)\nprint(\"Accuracy of the SVC model on unseen data is \"+str(accuracy_score(k2,y_test)*100)+\" %\")\nmodel3=LogisticRegression()\nmodel3.fit(x_train,y_train)\nk3=model3.predict(x_test)\nprint(\"Accuracy of the Logistic regression model on unseen data is \"+str(accuracy_score(k3,y_test)*100)+\" %\")","fa21d6bc":"def index2word(p):\n    if(p[0]==1):\n        return \"Patient has heart disease\"\n    else:\n        return \"Patient does not have heart disease\"   \n# p1=model1.predict([[50,1,2,239,0,183]])\n# print(index2word(p1))\n# p2=model2.predict([[50,1,2,239,0,183]])\n# print(index2word(p2))\np3=model3.predict([[40,1,0,240,0,160]])\nprint(index2word(p3))","fd6095a1":"cm1=confusion_matrix(y_test,k1)\ncm2=confusion_matrix(y_test,k2)\ncm3=confusion_matrix(y_test,k3)\n\nplt.figure()\nplt.title(\"Confusion Matrix for Neural network model\")\ndf_cm = pd.DataFrame(cm1, range(2),range(2))\nsn.set(font_scale=1.4)     #for label size\nsn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}) # font size\n\n\nplt.figure()\nplt.title(\"Confusion Matrix for SVC model\")\ndf_cm = pd.DataFrame(cm2, range(2),range(2))\nsn.set(font_scale=1.4)     #for label size\nsn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}) # font size\n\n\nplt.figure()\nplt.title(\"Confusion Matrix for Logistic regression model\")\ndf_cm = pd.DataFrame(cm3, range(2),range(2))\nsn.set(font_scale=1.4)     #for label size\nsn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16}) # font size","83a1136d":"## Data and Lables","54231f7a":"Here we feed the model the data it has never seen anywhere neither in the training set not the testing set.\n\nThe index2word function is used to convert the label values which are in binary(0 or 1) to natural language words ,i.e; 1 corresponds to \"Patient has heart disease\" and 0 corresponds to \"Patient doesnot have heart disease\".","5888850d":"## Dependencies and Data","26edd598":"## Splitting the dataset and training the model","8a24b171":"## Create Confusion Matix","ca19eb08":"Here we create a confusion matrix for the obtained models.\n\nConfusion matrices give the values for \"True Positives\",\"True Negatives\",\"False Positives\",\"False Negatives\".\n\nConfusion matrices give a better understanding about the model performance.","66c3dbf8":"Here we split the whole dataset into training and testing data.\n\nThe training data will be subjected to training where the model ca see both the data and the labels corresponding to the data and train on it.\n\nThe testing data is used for validation purpose and during the testing proces, the model can only see the data and it has to predict the labels, as we want it to run .","04d80f7b":"Here before moving into the coding part as always we need to import all the dependencies.\n\nOnce that is done, we move on to expressing our dataset.\n\nThe dataset has 303 rows and 14 columns.","bb3faf5a":"## Testing the model on user data","37487c54":"We need to convert the dataset in such a way that the labels are seperated from the dataset.\n\nUsing redundant features will decrease the accuracy of the model for predicting the test labels because of overfitting etc.\n\nSo, we choose to drop certain columns manually from the original dataset and keep only the data columns manually selected to be imoortant.\n\nThis method is not at all efficient when it comes to larger dataset and more redundant columns in  the dataset. \n\nThere are feature elimination algorithms which will be discussed in the 'heart-disease-RFE-code' code."}}