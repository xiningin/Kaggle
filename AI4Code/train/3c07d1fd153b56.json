{"cell_type":{"aa5ef2a1":"code","45ce3f45":"code","e105c197":"code","c5f6b36b":"code","846dde37":"code","3021fa0d":"code","6f08952d":"code","4407ebc0":"code","2d442353":"code","ad231bdd":"code","ef950856":"code","f76a83ec":"code","1e4bc417":"code","504fb6bc":"code","fc540275":"code","40bea049":"code","6e633fc0":"code","9979453c":"code","c87f4079":"code","3eb55f23":"code","0aeb051b":"code","c207d901":"code","bbe65b20":"code","ce9d6424":"code","04c96e21":"code","62ff5e67":"code","7c458920":"code","f3514e5e":"code","472f4941":"code","0b3a0aa0":"code","abe23cdb":"code","02560616":"code","465e04c9":"code","e9acf0bb":"code","177693bc":"code","ab5a40f1":"code","8eab4bb7":"code","5929d5a7":"code","b4f48861":"code","bd2b6669":"code","f6ba8545":"code","6a4e2508":"code","92dd8309":"code","15f2e294":"code","60a4b8c4":"code","3c874ab5":"code","6118e015":"code","7acd8021":"markdown","e019bda5":"markdown","cd8e9b5c":"markdown","e4593779":"markdown","7f3c88f2":"markdown","c059ae29":"markdown","8cf7764f":"markdown","e67f4270":"markdown","ae202c0f":"markdown","d1265461":"markdown","709c235e":"markdown","f626c980":"markdown","98889149":"markdown","247aaa7c":"markdown","7c8dc60d":"markdown","e5aabaca":"markdown","671f8245":"markdown","0b32aef1":"markdown","b8ef05e8":"markdown","20a7352e":"markdown","2275eaaf":"markdown","00c437b8":"markdown","4af2c3db":"markdown","376d048f":"markdown","684f4dfd":"markdown","839e7d6f":"markdown","eb25134a":"markdown","baf66004":"markdown","55a2b5c9":"markdown","e6ad9f8a":"markdown","ad2c60ab":"markdown","c7d5c270":"markdown","6156fd4b":"markdown","e91a8b56":"markdown","318b8430":"markdown","ea89fa00":"markdown","2e324c75":"markdown","cbd4b97f":"markdown","eec8eeb4":"markdown","cdd66ac3":"markdown","0c356160":"markdown","9b5a1b92":"markdown","8d09ca64":"markdown","32d4d41a":"markdown","fd73f227":"markdown","d60ce912":"markdown","c1f85353":"markdown","5eb5578f":"markdown","ce0d0f70":"markdown","17920a59":"markdown","19f40318":"markdown","10f031bd":"markdown","175a3453":"markdown","487257fa":"markdown"},"source":{"aa5ef2a1":"# Import the main libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n%matplotlib inline","45ce3f45":"# Import the dataset and print the first 5 rows\npath = '..\/input\/fish-market\/Fish.csv'\ndf = pd.read_csv(path)\ndf.head()","e105c197":"# Let's count the null values in the dataset\ndf_null = df.isnull()\ndf_null.head()","c5f6b36b":"# Let's print the missing values for each column name\nfor column in df_null.columns.to_list():\n  print(column)\n  print(df_null[column].value_counts())\n  print('')","846dde37":"df.shape","3021fa0d":"df.dtypes","6f08952d":"df.describe()","4407ebc0":"# Identify the rows where the Weight is missing\ndf.loc[df['Weight']==0]","2d442353":"# Drop the row where weight=0\ndf = df[df['Weight'] != 0]\nprint(df.shape)\ndf.head()","ad231bdd":"df.describe(include='object')","ef950856":"df['Species'].value_counts()","f76a83ec":"# Define the x_labels\nspecies = df['Species'].unique()\n\n# Define the bar chart\nplt.figure(figsize=(8,6))\nplt.bar(species, df['Species'].value_counts(), color='G')\n\n# Graphics\nplt.xlabel('Species', fontsize=12, color='W')\nplt.ylabel('Number of records', fontsize=12, color ='W')\nplt.title('Barplot of number of species in the dataset', fontsize=16, color ='W')","1e4bc417":"# I want to identify the average weight, length1, length2, lenght3, height and width grouped by species\ndf_s_group = df.groupby('Species').mean()\ndf_s_group","504fb6bc":"sp_list = df['Species'].unique()\nfor sp in sp_list:\n  print(sp)\n  print(df[df['Species'] == sp].describe())\n  print('')","fc540275":"sns.pairplot(df, kind='scatter', hue='Species')","40bea049":"sp_list = df['Species'].unique()\nfor sp in sp_list:\n  print(sp)\n  print(df[df['Species'] == sp].corr())\n  print('')","6e633fc0":"df.corr()","9979453c":"df_Perch = df[df['Species'] == 'Perch']\nsns.pairplot(df_Perch, kind='scatter')","c87f4079":"# Import from scipy library the stats module\nfrom scipy import stats","3eb55f23":"col_list = df.columns.to_list()[2:]\nY = df['Weight']\nfor x_pearson in col_list:\n  pearson_coef, p_value = stats.pearsonr(df[x_pearson], Y)\n  print(x_pearson)\n  print('The Pearson Correlation Coefficient is ', pearson_coef, ' and the P-value is ', p_value)\n  print('')","0aeb051b":"# Import LinearRegression from sklearn\nfrom sklearn.linear_model import LinearRegression","c207d901":"# Let's define a new LinearRegression model\nlm = LinearRegression()\nlm","bbe65b20":"# Let's identify the X variable and the Y variable. Considering the Pearson test, the best variable to use to  develop a Simple Linear Regression is 'Length3'\nX = df[['Length3']]\nY = df[['Weight']]\n\nlm.fit(X,Y)","ce9d6424":"# I want to print the intercept and the coefficient of the Linear Regression\nprint('The coefficient is: ', lm.coef_)\nprint('The intercept is: ', lm.intercept_)","04c96e21":"# Use seaborn to plot the Linear Regression model\nsns.regplot(X,Y)","62ff5e67":"# Import the metrics I need\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score","7c458920":"# Let's plot the residual\nsns.residplot(X,Y)","f3514e5e":"Yhat_lm = lm.predict(X)\nYhat_lm[0:4]","472f4941":"mse_lm = mean_squared_error(Y,Yhat_lm)\nr_score_lm = r2_score(Y, Yhat_lm)\nprint('The Mean Squared Error is ', mse_lm, ' and the R^2 score is ', r_score_lm)","0b3a0aa0":"# Use the col_list to define the independent variable.\n\nfor x in col_list:\n  print(x)\n  loop_lm = LinearRegression().fit(df[[x]], Y)\n  print('The intercept is ', loop_lm.intercept_, ' and the coefficient is ', loop_lm.coef_)\n  Yhat_loop_lm = loop_lm.predict(df[[x]])\n  print('The Mean Squared Error is ', mean_squared_error(Y, Yhat_loop_lm), ' and the R^2 score is ', r2_score(Y,Yhat_loop_lm))\n  print('')\n","abe23cdb":"# Define the Multiple Linear Regression Model and the independent variables. Train it on dependent and independent variables.\nX = df[col_list]\nmlrm = LinearRegression().fit(X,Y)\nmlrm","02560616":"print('The intercept is ', mlrm.intercept_, ' and the coefficients are ', mlrm.coef_)","465e04c9":"# Let's plot the distribution of the Y and the predicted Y\nYhat_mlrm = mlrm.predict(X)\n\nplt.figure(figsize=(8,6))\n\nax1 =  sns.distplot(Y, hist=False, color='R', label='Actual weight')\nsns.distplot(Yhat_mlrm, hist=False, color='B', ax=ax1, label='Predicted weight')","e9acf0bb":"# Calculate the Mean Squared Error and the R^2 score value\nprint('The Mean Squared Error is ', mean_squared_error(Y, Yhat_mlrm), ' and the R^2 Score is ', r2_score(Y, Yhat_mlrm))","177693bc":"def PlotPolly(model, independent_variable, dependent_variable, Name):\n    x_new = np.linspace(min(independent_variable)*0.98, max(independent_variable)*1.01, 100)\n    y_new = model(x_new)\n\n    plt.plot(independent_variable, dependent_variable, '.', x_new, y_new, '-')\n    plt.title('Polynomial Fit with Matplotlib for Weight')\n    ax = plt.gca()\n    ax.set_facecolor((0.898, 0.898, 0.898))\n    fig = plt.gcf()\n    plt.xlabel(Name)\n    plt.ylabel('Weight of fish')\n\n    plt.show()\n    #plt.close()","ab5a40f1":"# Train a 5 degrees polynome\npol = np.polyfit(df['Width'], df['Weight'], 5)\nfunc = np.poly1d(pol)\nprint(func)","8eab4bb7":"# Plot the function\nPlotPolly(func, df['Width'], df['Weight'], 'Width')","5929d5a7":"for x in col_list:\n  pol_loop = np.polyfit(df[x], df['Weight'], 5)\n  func_loop = np.poly1d(pol_loop)\n  print(func_loop)\n  plt.figure()\n  PlotPolly(func_loop, df[x], Y, Name=x)\n  plt.show()","b4f48861":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler","bd2b6669":"# Define the features we need to take in consideration for this model\nX_polF = df[col_list]","f6ba8545":"# Define the Input for the pipeline\nInput = [('standardscaler', StandardScaler()), ('polynomial', PolynomialFeatures(degree=2, include_bias=False)), ('model', LinearRegression()) ]","6a4e2508":"pipe = Pipeline(Input)\npipe","92dd8309":"pipe.fit(X_polF, Y)","15f2e294":"Yhat_pipe = pipe.predict(X_polF)\nYhat_pipe[0:4]","60a4b8c4":"# We can visualise the distribution of Yhat_pipe and the actual Y values in order to understand if the Polynomial Feature Regression model is a better model.\nplt.figure(figsize=(12,10))\nax2 = sns.distplot(Y, hist=False, color='R', label='Actual values')\nsns.distplot(Yhat_pipe, hist=False, color='G', label='Predicted values')\nplt.show()","3c874ab5":"print(\"The Mean Squared Error of the Polynomial Multiple Linear Regression is \",  mean_squared_error(Y, Yhat_pipe), ' and the R^2 score is ', r2_score(Y, Yhat_pipe))","6118e015":"Y_pred = pd.DataFrame(data=Yhat_pipe, columns=['Estimate Weight'])\nprediction_df = pd.concat([Y_pred, Y], axis=1)\nprediction_df","7acd8021":"<p>The analytical expression for Multivariate Polynomial function gets complicated. For example, the expression for a second-order (degree=2)polynomial with two variables is given by:<\/p>","e019bda5":"$$\na: intercept\\\\\nb_1 :coefficients \\ of\\ Variable \\ 1\\\\\nb_2: coefficients \\ of\\ Variable \\ 2\\\\\nb_3: coefficients \\ of\\ Variable \\ 3\\\\\nb_4: coefficients \\ of\\ Variable \\ 4\\\\\n$$","cd8e9b5c":"As we can see the distribution of the predicted values is close to the distribution of the actual values but there are rooms for improvement.","e4593779":"As we can see from the distribution, the Polynomial Features Regression Model rappresent the data in a better way. Now we need to do some evaluation of the model. <\/br>\n<\/br>\nThe previous best model was the following Simple Linear Regression: <\/br>\n<br>\n_Length3 The Mean Squared Error is 18804.23911410419 and the R^2 score is 0.852095743638909_<\/br>\n<\/br>\nLet's calculate the Mean Squared Error and the R^2 score of the new model.","7f3c88f2":"$$\n Y: Response \\ Variable\\\\\n X: Predictor \\ Variables\n$$\n","c059ae29":" <b>Linear function:<\/b>\n$$\nYhat = a + b  X\n$$","8cf7764f":"<p>A Model will help us understand the exact relationship between different variables and how these variables are used to predict the result.<\/p>","e67f4270":"<b>P-value<\/b>: \n<p>What is this P-value? The P-value is the probability value that the correlation between these two variables is statistically significant. Normally, we choose a significance level of 0.05, which means that we are 95% confident that the correlation between the variables is significant.<\/p>\n\nBy convention, when the\n<ul>\n    <li>p-value is $<$ 0.001: we say there is strong evidence that the correlation is significant.<\/li>\n    <li>the p-value is $<$ 0.05: there is moderate evidence that the correlation is significant.<\/li>\n    <li>the p-value is $<$ 0.1: there is weak evidence that the correlation is significant.<\/li>\n    <li>the p-value is $>$ 0.1: there is no evidence that the correlation is significant.<\/li>\n<\/ul>","ae202c0f":"<h2 id=\"slr\">Linear Regression and Multiple Linear Regression<\/h2>","d1265461":"As we can see, the minimum value of the column weight is equal to 0. This means we have missing values into the dependent variable. Let's print how many rows have the weight equal to 0.","709c235e":"<center><b>Quadratic - 2nd order<\/b><\/center>\n$$\nYhat = a + b_1 X^2 +b_2 X^2 \n$$\n\n\n<center><b>Cubic - 3rd order<\/b><\/center>\n$$\nYhat = a + b_1 X^2 +b_2 X^2 +b_3 X^3\\\\\n$$\n\n\n<center><b>Higher order<\/b>:<\/center>\n$$\nY = a + b_1 X^2 +b_2 X^2 +b_3 X^3 ....\\\\\n$$","f626c980":"<h2 id=\"data_wrangling\"> Data Wrangling <\/h2>","98889149":"<h3> Automate the process for all the columns <\/h3>","247aaa7c":"<p><b>Correlation<\/b>: a measure of the extent of interdependence between variables.<\/p>\n\n<p><b>Causation<\/b>: the relationship between cause and effect between two variables.<\/p>\n\n<p>It is important to know the difference between these two and that correlation does not imply causation. Determining correlation is much simpler  the determining causation as causation may require independent experimentation.<\/p>","7c8dc60d":"Let's see how many different species we have in the dataset.","e5aabaca":"<h1><center> Fish Weight Prediction <\/center><\/h1>","671f8245":"<p>What if we want to predict fish weigth using more than one variable?<\/p>\n\n<p>If we want to use more variables in our model to predict fish weight, we can use <b>Multiple Linear Regression<\/b>.\nMultiple Linear Regression is very similar to Simple Linear Regression, but this method is used to explain the relationship between one continuous response (dependent) variable and <b>two or more<\/b> predictor (independent) variables.\nMost of the real-world regression models involve multiple predictors. We will illustrate the structure by using four predictor variables, but these results can generalize to any integer:<\/p>","0b32aef1":"From the previous anasysis we highlighted that all the dependent variables we have are good to predict the fish weight. We are going to use all of them to train a model.","b8ef05e8":"<h1 id=\"model_development\">Model Development<\/h1>","20a7352e":"<h2 id=\"poly\"> Pipelines and Polynomial Regressions <\/h2>","2275eaaf":"If we have to use a Simple Linear Regression as model, the best rappresentation of the data and the clostest prediction would be achieved by using the 'Length3' column.","00c437b8":"<h2 id=\"conclusions\">Conclusions <\/h2>\n<\/br>\nAs we can see, the Mean Squared Error of the new model is ways better than the privious models and the R^2 score is very high. This means that the model is able to predict almost perfectly the weight of the fish based on his dimensions.","4af2c3db":"As we can see, is better to differentiate the model based on the \"Species\" in order to maximize the correlation between the independent variables and the dependent variable. It's important to notice that the relationship between the independent variable Height and the dependent variable Weight are highly correlated if you consider the species once per time. This doesn't happend when we consider the entire dataset.","376d048f":"<h2 id=\"correlation_causation\">Correlation and Causation - Pearson and Pvalue<\/h2>","684f4dfd":"As we can see there are 7 different species of fish in the dataset and the most frequent is the 'Perch'. <\/br>\nI want to count how many records I have for each species.","839e7d6f":"<h2> Table of contents <\/h2>\nFist of all we need to understand the dataset a bit. <\/br>\n<\/br>\n\n*   Species: species name of fish\n*   Weight: weight of fish in Gram g\n*   Length1: vertical length in cm\n*   Length2: diagonal length in cm\n*   Length3: cross length in cm\n*   Height: height in cm\n*   Width: diagonal width in cm\n\n<\/br>\n\nWe will use the following plan to make sure the data are ready to be used for a machine learning implementation:\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n<ul>\n    <li><a href=\"#data_wrangling\">Data Wrangling<\/a><\/li>\n    <li><a href=\"#identify_handle_missing_values\">Identify and handle missing values<\/a>\n        <ul>\n            <li><a href=\"#missing_values\">Identify missing values<\/a><\/li>\n        <\/ul>\n    <\/li>\n    <li><a href=\"#group_pivot\">Grouping and Pivoting<\/a><\/li>\n    <li><a href=\"#correlation_causation\">Correlation and Causation - Pearson and Pvalue<\/a><\/li>\n    <li><a href=\"#summary\">Summary of the Data Exploration<\/a><\/li>\n    <li><a href=\"#model_development\">Model development<\/a>\n        <ul>\n            <li><a href=\"#slr\">Linear Regression and Multiple Linear Regression<\/a><\/li>\n            <li><a href=\"#poly\">Pipeline and Polynomial Regression<\/a><\/li>\n        <\/ul>\n    <\/li>\n    <li><a href=\"#conclusions\">Conclusions<\/a><\/li><\/ul>\n<\/br>\n<hr>","eb25134a":"<h2 id=\"group_pivot\"> Grouping and Pivoting <\/h2>","baf66004":"<ul>\n    <li>a refers to the <b>intercept<\/b> of the regression line0, in other words: the value of Y when X is 0<\/li>\n    <li>b refers to the <b>slope<\/b> of the regression line, in other words: the value with which Y changes when X increases by 1 unit<\/li>\n<\/ul>","55a2b5c9":"<h2 id=\"summary\"> Summary of the data exploration<\/h2>\nAll the columns are well related with the dependent variable. We can use all of them or perform a PCA to reduce the number of independent variables.\n","e6ad9f8a":"$$\nYhat = a + b_1 X_1 + b_2 X_2 + b_3 X_3 + b_4 X_4\n$$","ad2c60ab":"<p>In this section, we will develop several models that will predict the weight of the fish using the variables or features. This is just an estimate but should give us an objective idea of how much the fish should weight.<\/p>","c7d5c270":"<hr>\n<h3 id=\"missing_values\"> Identify Missing Values <\/h3>","6156fd4b":"\n<p>One example of a Data  Model that we will be using is<\/p>\n<b>Simple Linear Regression<\/b>.\n\n<br>\n<p>Simple Linear Regression is a method to help us understand the relationship between two variables:<\/p>\n<ul>\n    <li>The predictor\/independent variable (X)<\/li>\n    <li>The response\/dependent variable (that we want to predict)(Y)<\/li>\n<\/ul>\n\n<p>The result of Linear Regression is a <b>linear function<\/b> that predicts the response (dependent) variable as a function of the predictor (independent) variable.<\/p>\n\n","e91a8b56":"We can notice that the residual are not randomply distributed around the mean. This means that even if a Simple Linear Regression is a good approssimation of the distribution, there are other models that better rappresent the data.","318b8430":"The model seams to better rappresent the distribution.","ea89fa00":"<h2 id=\"mlr\"> Multiple Linear Regression <\/h2>\n","2e324c75":"As highlighted in the tables above, each species is very different from another.","cbd4b97f":"We want to identify when the correlation between the dependent variable \"Weight\" and the indipendent variables is statistically significant.\nWe can do it using a loop.","eec8eeb4":"The equation is given by","cdd66ac3":"<h3> Note: <\/h3>\nIt is probabily a good idea to build 2 different models. The first one using all the features we have, the second one performing a dimensionality reduction using the principal component analysis and saving probably just one of the column of 'Length1', 'Length2' and 'Length3'.\n\n\n---\n\nFor semplicity, in this case we will fit models taking in consideration the entire dataset as generalization.","0c356160":"$$\nY: Response \\ Variable\\\\\nX_1 :Predictor\\ Variable \\ 1\\\\\nX_2: Predictor\\ Variable \\ 2\\\\\nX_3: Predictor\\ Variable \\ 3\\\\\nX_4: Predictor\\ Variable \\ 4\\\\\n$$","9b5a1b92":"<p><b>Polynomial regression<\/b> is a particular case of the general linear regression model or multiple linear regression models.<\/p> \n<p>We get non-linear relationships by squaring or setting higher-order terms of the predictor variables.<\/p>\n\n<p>There are different orders of polynomial regression:<\/p>","8d09ca64":"The higher the R^2 score and the lower the Mean Squared Error, the better.","32d4d41a":"I want to plot a bar chart to graphically show it.","fd73f227":"<h3> Is this a good approssimation? Is this a good model? <\/h3>\nIn order to evaluate the model and to compare it with others, is important to have some metrics that summarize it.\nThese metrics can be the R^2 and the Mean Squared Error.\n<\/br>\nThe R^2 tell us how well the liner regression approssimate the data","d60ce912":"<h3>Linear Regression<\/h3>","c1f85353":"<p>We saw earlier that a linear model did not provide the best fit while using highway-mpg as the predictor variable. Let's see if we can try fitting a polynomial model to the data instead.<\/p>","5eb5578f":"The best Simple Linear Regression model we have trained so far hat the following results:\n\nLength3\nThe Mean Squared Error is  18804.23911410419  and the R^2 score is  0.852095743638909\n<\/br>\nConsidering that the Mean Squared Error of the Multiple Linear Regression is lower than the Mean Squared Error from the Simple Linear Regrassion model trained on the 'Length3' column, the MLR predict the fish weigth better than the SLR.<\/br>\nWhat about the R^2 score? <\/br>\nThe R^2 score of the Multiple Linear Regression model is higher then the SLR model. This means that in general the MLRM better rappresent the dataset.","ce0d0f70":"<p3>Pearson Correlation<\/p>\n<p>The Pearson Correlation measures the linear dependence between two variables X and Y.<\/p>\n<p>The resulting coefficient is a value between -1 and 1 inclusive, where:<\/p>\n<ul>\n    <li><b>1<\/b>: Total positive linear correlation.<\/li>\n    <li><b>0<\/b>: No linear correlation, the two variables most likely do not affect each other.<\/li>\n    <li><b>-1<\/b>: Total negative linear correlation.<\/li>\n<\/ul>","17920a59":"As we can see all the columns are correctly formatted. Let's print some statistics about the dataset.","19f40318":"Apparently we do not have Null values in the dataframe but some of the missing value could have a different character such as a question mark. Let's print the data types of each column.","10f031bd":"<p>We will use the following function to plot the data:<\/p>","175a3453":"$$\nYhat = a + b_1 X_1 +b_2 X_2 +b_3 X_1 X_2+b_4 X_1^2+b_5 X_2^2\n$$","487257fa":"We can perform a polynomial transform on multiple features. First, we import the module:"}}