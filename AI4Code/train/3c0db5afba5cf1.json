{"cell_type":{"af6ef2ba":"code","c2424675":"code","2ad0e156":"code","9f12d8bf":"code","81443032":"code","d9dc025a":"code","7a0a8b14":"code","f01c3126":"code","2d784726":"code","7a402495":"code","fc47bdd9":"code","58f9756a":"code","de1e91f2":"code","6539318f":"code","30259346":"code","7abe0591":"code","898d4cb4":"code","96a3ff33":"code","b3bbadd8":"code","93eeb9a5":"code","22a3921e":"code","c9027ed6":"code","538f570f":"code","a111c4af":"code","de71523e":"code","04c90424":"code","5976822f":"code","794f2b00":"code","819f1361":"code","1c4c2ea9":"code","bd7e3894":"code","5b626861":"code","ed6fbc27":"code","bb5be49b":"code","34c52626":"code","72e7d816":"code","d908d3da":"code","b53597e9":"code","04844d27":"code","0d770cae":"code","da288475":"code","2e1eb149":"code","0e8d490a":"code","736debe5":"code","c9c1419c":"code","c0698b20":"code","e54d2c30":"code","ad78bbe3":"code","481bc797":"code","c2234d58":"code","8f6293ef":"code","5f84c63e":"code","670660cb":"code","1984aeee":"code","d326a7e6":"code","8490c0e0":"markdown","d2a4e06f":"markdown","1fbe465d":"markdown","aa25bcba":"markdown","12414c9b":"markdown"},"source":{"af6ef2ba":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os","c2424675":"#import libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom math import sqrt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, classification_report\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","2ad0e156":"# Import data. Read files\ntrain_data = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_data = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntrain_data.shape","9f12d8bf":"# Drop Id from train data\ntrain_data.drop(\"Id\", axis = 1, inplace = True)","81443032":"#delete excess null values\ndef delete_null (df, p100):\n    percent = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False)\n    list_null = percent[percent > p100].index\n    df.drop(list_null, axis=1, inplace=True)\n    return df","d9dc025a":"#handle null values\ndef handle_null(df, func):\n    na_cols=df.columns[df.isna().sum()>0]\n    for col in na_cols:\n        if func=='mean':\n            df[col]=df[col].fillna(df[col].mean())\n        if func=='mode':\n            df[col]=df[col].fillna(df[col].mode()[0])\n    return df","7a0a8b14":"#check null values\ntotal = train_data.isnull().sum().sort_values(ascending=False)\npercent = (train_data.isnull().sum()\/train_data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data = missing_data.loc[missing_data.Percent>0]\nmissing_data","f01c3126":"#delete variable with more than 17% of null values\ntrain_data = delete_null(train_data, 0.17)\ntrain_data.shape","2d784726":"test_data = delete_null(test_data, 0.17)\ntest_data.shape","7a402495":"train_data.describe()","fc47bdd9":"# check correlation between independent variables\ncorrmat = train_data.corr()\nc1= corrmat.abs().unstack()\nc1[c1==1] = 0\nc2= c1.sort_values(ascending = False)\nc2= c2[c2 > 0.70]\nc2","58f9756a":"# delete correlational variables with less impact on SalePrice\ntrain_data = train_data.drop(['TotRmsAbvGrd','GarageArea','1stFlrSF','GarageYrBlt'], axis=1)","de1e91f2":"#same for test data\ntest_data = test_data.drop(['TotRmsAbvGrd','GarageArea','1stFlrSF','GarageYrBlt'], axis=1)","6539318f":"# Move target variable SalePrice to another data frame\nY_data = train_data.SalePrice\ntrain_data.drop(['SalePrice'], axis=1, inplace=True)","30259346":"# Split in numeric and categorical data\n#Get numerical data\nnum_data = train_data.select_dtypes(include=np.number)\nnum_test = test_data.select_dtypes(include=np.number)\nnum_data","7abe0591":"#Get categorical data\ncat_data = train_data.select_dtypes(include=np.object)\ncat_test = test_data.select_dtypes(include=np.object)\ncat_data","898d4cb4":"num_data.describe()","96a3ff33":"#Numeric variables with null values\nnull_data = num_data.isnull().sum().sort_values(ascending=False)\nnull_data = null_data[null_data > 0]\nnull_data","b3bbadd8":"#Replace null values with mean\nnum_data=handle_null(num_data, 'mean')\nnum_test=handle_null(num_test, 'mean')","93eeb9a5":"#Describe categorical variables\ncat_data.describe()","22a3921e":"#List values in categorical variables\nfor variable in cat_data.columns:\n    print(\n        f\"{variable} :{len(cat_data[variable].unique())}: {cat_data[variable].unique()}\"\n    )","c9027ed6":"#Replace null values with mean\ncat_data=handle_null(cat_data, 'mode')\ncat_test=handle_null(cat_test, 'mode')","538f570f":"# Encoding of categorical variables\nlabel_encoder = LabelEncoder()\nfor col in cat_data.columns:\n    cat_data[col] = label_encoder.fit_transform(cat_data[col])","a111c4af":"label_encoder = LabelEncoder()\nfor col in cat_test.columns:\n    cat_test[col] = label_encoder.fit_transform(cat_test[col])","de71523e":"cat_data.head()","04c90424":"#concat numerical and categorical variable\ndata_final = pd.concat([num_data,cat_data], axis=1)\ndata_final_test = pd.concat([num_test,cat_test], axis=1)","5976822f":"data_final.shape","794f2b00":"Y_data.shape","819f1361":"#split in train and test data\nX_train, X_test, Y_train, Y_test = train_test_split(data_final, Y_data, train_size=0.75, random_state=23)\nprint('X_train :'+str(X_train.shape))\nprint('Y_train :'+str(Y_train.shape))\nprint('---')\nprint('Y_test :'+str(Y_test.shape))\nprint('X_test :'+str(X_test.shape))","1c4c2ea9":"from sklearn.feature_selection import SelectKBest, f_classif\nselector = SelectKBest(f_classif, k=30)\nX_new = selector.fit_transform(X_train, Y_train)","bd7e3894":"# Get back the kept features as a DataFrame with dropped columns as all 0s\nselected_features = pd.DataFrame(selector.inverse_transform(X_new), index=X_train.index, columns=X_train.columns)","5b626861":"# Find the columns that were dropped\ndropped_columns = selected_features.columns[selected_features.var() == 0]\ndropped_columns","ed6fbc27":"X_features = selected_features.columns[selected_features.var() != 0]\nX_features","bb5be49b":"X_train[X_features].shape","34c52626":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train[X_features],Y_train)","72e7d816":"#Model accuracy\nprint('Precisi\u00f3n del entrenamiento: '+str(lr.score(X_train[X_features], Y_train)))\nprint('Precisi\u00f3n en la validaci\u00f3n: '+str(lr.score(X_test[X_features], Y_test)))","d908d3da":"#Cross-validation 7 folds\nlr_cross = cross_val_score(lr, data_final[X_features], Y_data, cv=7)\nprint(lr_cross)\nprint('Mean Absolute Error %2f' %(lr_cross.mean()))","b53597e9":"#model prediction\nlr_pred= lr.predict(X_test[X_features])","04844d27":"lr_mse = mean_squared_error(Y_test, lr_pred)\nlr_rmse = sqrt(lr_mse)\nlr_mae = mean_absolute_error(Y_test, lr_pred)\nprint(\"Error Cuadratico Medio (MSE) en la prediccion: {:.4f}\".format(lr_mse))\nprint(\"Ra\u00edz Cuadrada del Error Cuadratico Medio (RMSE) en la prediccion: {:.4f}\".format(lr_rmse))\nprint(\"Error Absoluto Medio (MAE): {:.4f}\".format(lr_mae))","0d770cae":"from sklearn.tree import DecisionTreeRegressor\n# with pruning = 8\ntree_model = DecisionTreeRegressor(max_depth=8)\ntree_model.fit(X_train[X_features], Y_train)","da288475":"#Model accuracy\nprint('Precisi\u00f3n del entrenamiento: '+str(tree_model.score(X_train[X_features], Y_train)))\nprint('Precisi\u00f3n en la validaci\u00f3n: '+str(tree_model.score(X_test[X_features], Y_test)))","2e1eb149":"#Cross-validation 7 folds\ntree_cross = cross_val_score(tree_model, data_final[X_features], Y_data, cv=7)\nprint(tree_cross)\nprint('Mean Absolute Error %2f' %(tree_cross.mean()))","0e8d490a":"#model prediction\ntree_pred= tree_model.predict(X_test[X_features])","736debe5":"tree_mse = mean_squared_error(Y_test, tree_pred)\ntree_rmse = sqrt(tree_mse)\ntree_mae = mean_absolute_error(Y_test, tree_pred)\nprint(\"Error Cuadratico Medio (MSE) en la prediccion: {:.4f}\".format(tree_mse))\nprint(\"Ra\u00edz Cuadrada del Error Cuadratico Medio (RMSE) en la prediccion: {:.4f}\".format(tree_rmse))\nprint(\"Error Absoluto Medio (MAE): {:.4f}\".format(tree_mae))","c9c1419c":"forest_model=RandomForestRegressor(n_estimators=300, n_jobs=None, max_features='auto', oob_score=True)\nforest_model.fit(X_train[X_features], Y_train)","c0698b20":"#Model accuracy\nprint('Precisi\u00f3n del entrenamiento: '+str(forest_model.score(X_train[X_features], Y_train)))\nprint('Precisi\u00f3n en la validaci\u00f3n: '+str(forest_model.score(X_test[X_features], Y_test)))\nprint('Error oob: '+str(forest_model.oob_score_))","e54d2c30":"#Cross-validation 7 folds\nforest_cross = cross_val_score(forest_model, data_final[X_features], Y_data, cv=7)\nprint(forest_cross)\nprint('Mean Absolute Error %2f' %(forest_cross.mean()))","ad78bbe3":"#model prediction\nforest_pred= forest_model.predict(X_test[X_features])","481bc797":"forest_mse = mean_squared_error(Y_test, forest_pred)\nforest_rmse = sqrt(forest_mse)\nforest_mae = mean_absolute_error(Y_test, forest_pred)\nprint(\"Error Cuadratico Medio (MSE) en la prediccion: {:.4f}\".format(forest_mse))\nprint(\"Ra\u00edz Cuadrada del Error Cuadratico Medio (RMSE) en la prediccion: {:.4f}\".format(forest_rmse))\nprint(\"Error Absoluto Medio (MAE): {:.4f}\".format(forest_mae))","c2234d58":"plt.figure(figsize=(15,12))\n\nplt.subplot(221)\n# Mostramos en una gr\u00e1fica para Arboles de Decisi\u00f3n\nplt.scatter(tree_pred, Y_test)\nplt.ylabel('Real price')\nplt.xlabel('Predicted price')\nplt.title(r'Decision Tree')\n# A\u00f1adir la linea ideal de predicci\u00f3n\ndiagonal = np.linspace(0, np.max(tree_pred), 100)\nplt.plot(diagonal, diagonal, '-r')\n\nplt.subplot(222)\n# Mostramos en una gr\u00e1fica precisi\u00f3n de Random Forest\nplt.scatter(forest_pred, Y_test)\nplt.ylabel('Real price')\nplt.xlabel('Predicted price')\nplt.title(r'Random Forest')\n# A\u00f1adir la linea ideal de predicci\u00f3n\ndiagonal = np.linspace(0, np.max(forest_pred), 100)\nplt.plot(diagonal, diagonal, '-r')\n\nplt.subplot(223)\n# Mostramos en una gr\u00e1fica para Arboles de Decisi\u00f3n\nplt.scatter(lr_pred, Y_test)\nplt.ylabel('Real price')\nplt.xlabel('Predicted price')\nplt.title(r'Linear Regression')\n# A\u00f1adir la linea ideal de predicci\u00f3n\ndiagonal = np.linspace(0, np.max(lr_pred), 100)\nplt.plot(diagonal, diagonal, '-r')\n\nplt.show()","8f6293ef":"test_pred= forest_model.predict(data_final_test[X_features])","5f84c63e":"data_final_test['SalePrice']=test_pred","670660cb":"df_solution = data_final_test[['Id','SalePrice']]","1984aeee":"df_solution.head(10)","d326a7e6":"df_solution.to_csv ('sample_submission.csv', index = False, header=True)","8490c0e0":"## Submission Test Data","d2a4e06f":"## Random Forest","1fbe465d":"## Linear Regression","aa25bcba":"## Decision Tree","12414c9b":"## Feature Selection"}}