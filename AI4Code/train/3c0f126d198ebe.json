{"cell_type":{"994570be":"code","08a208a8":"code","277bd300":"code","c90d2889":"code","496064c4":"code","935b26fe":"code","d306e774":"code","8bc26fe6":"code","65fac30c":"code","ec71f175":"code","34bdf70b":"code","e4810356":"markdown","e97e1949":"markdown","9e65f655":"markdown","476b1483":"markdown","60e840c4":"markdown"},"source":{"994570be":"import numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Activation, Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization","08a208a8":"train_dir= '..\/input\/emotion-detection-fer\/train'\nvalidation_dir= '..\/input\/emotion-detection-fer\/test'","277bd300":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n                    rescale=1.\/255,\n\t\t\t\t\trotation_range=30,\n\t\t\t\t\tshear_range=0.3,\n\t\t\t\t\tzoom_range=0.3,\n\t\t\t\t\twidth_shift_range=0.4,\n\t\t\t\t\theight_shift_range=0.4,\n\t\t\t\t\thorizontal_flip=True,\n\t\t\t\t\tfill_mode='nearest')\nvalidation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255)\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(48,48),\n        batch_size=64,\n        color_mode = \"grayscale\",\n        shuffle=True,\n        class_mode='categorical')\nvalidation_generator = validation_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(48, 48),\n        batch_size=64,\n        color_mode = \"grayscale\",\n        shuffle=True,\n        class_mode='categorical')","c90d2889":"\nmodel = tf.keras.Sequential()\n\nmodel.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(48,48,1)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32,(3,3),padding='same',kernel_initializer='he_normal',input_shape=(48,48,1)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n# Block-2 \n\nmodel.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n# Block-3\n\nmodel.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n# Block-4 \n\nmodel.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\n# Block-5\n\nmodel.add(Flatten())\nmodel.add(Dense(64,kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# Block-6\n\nmodel.add(Dense(64,kernel_initializer='he_normal'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# Block-7\n\nmodel.add(Dense(7,kernel_initializer='he_normal'))\nmodel.add(Activation('softmax'))\n\nmodel.summary()","496064c4":"\n\n\ncheckpoint = tf.keras.callbacks.ModelCheckpoint('.\/Emotion_recog.h5',\n                             monitor='val_loss',\n                             mode='min',\n                             save_best_only=True,\n                             verbose=1)\n\nearlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=3,\n                          verbose=1,\n                          restore_best_weights=True\n                          )\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=3,\n                              verbose=1,\n                              min_delta=0.0001)\n\ncallbacks = [earlystop,checkpoint,reduce_lr]\n\nopt = tf.keras.optimizers.Adam(lr=0.0005,decay=1e-6)\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer = opt,\n              metrics=['accuracy'])\n","935b26fe":"history = model.fit_generator(train_generator, epochs=50, validation_data=validation_generator,callbacks=callbacks)","d306e774":"fig , ax = plt.subplots(1,2)\ntrain_accuracy = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(10,5)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epochs')\nax[0].legend(['Train', 'Validation'], loc='best')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epochs')\nax[1].legend(['Train', 'Validation'], loc='best')\n\nplt.show()","8bc26fe6":"model.save('emotion_detection.h5')\nmodel.save_weights('model_weight.h5')\nnp.save(\"history\", history.history)\n","65fac30c":"train_loss, train_accu = model.evaluate(train_generator)\nval_loss, val_accu = model.evaluate_generator(validation_generator)\n\nprint(\"Train Accuracy = {:.2f} \\n  Validation Accuracy = {:.2f}\".format(train_accu*100, val_accu*100))","ec71f175":"\nimg=cv2.imread('..\/input\/emotion-detection-fer\/train\/angry\/im1009.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nimg=cv2.resize(img,(48,48))\nprint(img.shape)\nplt.imshow(img)\nplt.show()","34bdf70b":"img = np.expand_dims(img,axis = 0) #makes image shape (1,48,48)\nimg = img.reshape(1,48,48,1)\nresult = model.predict(img)\nresult = list(result[0])\nprint(result)\nlabels={0:'Angry',1:'Disgust',2:'Fear',3:'Happy',4:'Neutral',5:'Sad',6:'Surprise'}\nlabel=np.argmax(result)\nprint(labels[label])","e4810356":"Accuracy on validation set is stuck at 66% also no overfitting can se seen in the dataset hence is can be concluded that the inefficiency may be due to the unbalanced dataset","e97e1949":"## Compile Model and callbacks","9e65f655":"## Creating Model","476b1483":"## load data ","60e840c4":"### Import Libraries"}}