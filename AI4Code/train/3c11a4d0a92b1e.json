{"cell_type":{"b0a7a520":"code","64eb8176":"code","271d12c2":"code","ec6d0d77":"code","b123e17c":"code","71c3a6da":"code","d619ca32":"markdown","65a93f64":"markdown","4da25ccd":"markdown","99029964":"markdown"},"source":{"b0a7a520":"# Start by importing the bq_helper module and calling on the specific active_project and dataset_name for the BigQuery dataset.\nimport bq_helper\nfrom bq_helper import BigQueryHelper\n# https:\/\/www.kaggle.com\/sohier\/introduction-to-the-bq-helper-package\n\ninvestigations = bq_helper.BigQueryHelper(active_project=\"patents-public-data\",\n                                   dataset_name=\"usitc_investigations\")","64eb8176":"# View table names under the usitc_investigations\nbq_assistant = BigQueryHelper(\"patents-public-data\", \"usitc_investigations\")\nbq_assistant.list_tables()","271d12c2":"# View the first three rows of the investigations data table\nbq_assistant.head(\"investigations\", num_rows=3)","ec6d0d77":"# View information on all columns in the investigations data table\nbq_assistant.table_schema(\"investigations\")","b123e17c":"query1 = \"\"\"\nSELECT DISTINCT\n  currentStatus\nFROM\n  `patents-public-data.usitc_investigations.investigations`\nLIMIT\n  20;\n        \"\"\"\nresponse1 = investigations.query_to_pandas_safe(query1)\nresponse1.head(20)","71c3a6da":"bq_assistant.estimate_query_size(query1)","d619ca32":"## Example SQL Query\nWhat are the possible current statuses of all the investigations?","65a93f64":"Interpretting this number, this means my query scanned almost 0GB of data in order to return a table of unique current statuses from the dataset.","4da25ccd":"## Importance of Knowing Your Query Sizes\n\nIt is important to understand how much data is being scanned in each query due to the free 5TB per month quota. For example, if a query is formed that scans all of the data in a particular column, given how large BigQuery datasets are it wouldn't be too surprising if it burns through a large chunk of that monthly quota!\n\nFortunately, the bq_helper module gives us tools to very easily estimate the size of our queries before running a query. Start by drafting up a query using BigQuery's Standard SQL syntax. Next, call the estimate_query_size function which will return the size of the query in GB. That way you can get a sense of how much data is being scanned before actually running your query.","99029964":"# How to Query Intellectual Property Investigations by the USITC (BigQuery)\n[Click here](https:\/\/www.kaggle.com\/mrisdal\/safely-analyzing-github-projects-popular-licenses) for a detailed notebook demonstrating how to use the bq_helper module and best practises for interacting with BigQuery datasets."}}