{"cell_type":{"f31ce823":"code","cbd1e0ae":"code","a638b763":"code","5e73af94":"code","41527882":"code","d2a042e3":"code","4d9f8c4e":"code","f8ecdcae":"code","3837dc3d":"code","0aa01ba3":"code","c7ace72c":"code","f865e86f":"code","7807c120":"code","9d5359bc":"code","7a05cb30":"code","53e31dd0":"code","ac4ff941":"code","7bfb60ec":"code","e54c1060":"code","58d76b69":"code","6827a304":"code","e5aa881b":"code","adcd0580":"code","a6100b05":"code","c5b86a4f":"code","c2c27844":"code","f4bb2bd4":"code","210bac66":"code","45306e3e":"code","523e6e30":"code","3f52b510":"code","5f1cd71e":"code","132a4315":"code","e31c3100":"code","e5897a08":"code","df70cfb2":"code","084a3408":"markdown","c3cf752b":"markdown","1eada21a":"markdown","cb4f9ed3":"markdown","2670cb79":"markdown","9cb6ca98":"markdown","fef07b6d":"markdown","7e51c25d":"markdown","f153e5e5":"markdown","569606e8":"markdown","2efbf9b7":"markdown","af8dd567":"markdown","49a37c01":"markdown","f073b5a7":"markdown","40864b3e":"markdown"},"source":{"f31ce823":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nimport glob\nimport os","cbd1e0ae":"image_paths = glob.glob('..\/input\/anime-faces\/data\/*.png')","a638b763":"len(image_paths)","5e73af94":"def load_preprosess_image(image_path):\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_png(img,channels=3)\n    img = tf.cast(img, tf.float32)\n    img = img \/ 255\n    img = img * 2 - 1\n    img = img.numpy()\n    \n    return img","41527882":"plt.imshow((load_preprosess_image(image_paths[0])+1)\/2)","d2a042e3":"images = [load_preprosess_image(path) for path in image_paths]","4d9f8c4e":"images = np.array(images).astype(np.float32)","f8ecdcae":"images.shape","3837dc3d":"images.dtype","0aa01ba3":"image_ds = tf.data.Dataset.from_tensor_slices(images)","c7ace72c":"image_ds","f865e86f":"image_ds.__len__()","7807c120":"BATCH_SIZE = 64\nShuffle_parameter = len(image_paths) \/\/ 2","9d5359bc":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nimage_ds = image_ds.shuffle(Shuffle_parameter).batch(BATCH_SIZE,drop_remainder=True).prefetch(AUTOTUNE)","7a05cb30":"image_ds","53e31dd0":"image_ds.__len__()","ac4ff941":"def make_generator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Dense(8*8*256, use_bias=False, input_shape=(100,)))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Reshape((8, 8, 256)))\n    assert model.output_shape == (None, 8, 8, 256) # \u6ce8\u610f\uff1abatch size \u6ca1\u6709\u9650\u5236\n\n    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n    assert model.output_shape == (None, 8, 8, 128)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    assert model.output_shape == (None, 16, 16, 64)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    \n    model.add(layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n    assert model.output_shape == (None, 32, 32, 32)\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n\n    model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n    assert model.output_shape == (None, 64, 64, 3)\n\n    return model","7bfb60ec":"generator = make_generator_model()\n\nnoise = tf.random.normal([1, 100])\ngenerated_image = generator(noise, training=False)\n\nplt.imshow(((generated_image[0, :, :, :])+1)\/2)","e54c1060":"generator.summary()","58d76b69":"def make_discriminator_model():\n    model = tf.keras.Sequential()\n    model.add(layers.Conv2D(32, (5, 5), strides=(2, 2), padding='same',\n                                     input_shape=[64, 64, 3]))\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n    \n    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n    \n    model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU())\n    model.add(layers.Dropout(0.3))\n\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1,activation='sigmoid'))\n\n    return model","6827a304":"discriminator = make_discriminator_model()\ndecision = discriminator(generated_image)\nprint (decision)","e5aa881b":"discriminator.summary()","adcd0580":"cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)","a6100b05":"def discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss","c5b86a4f":"def generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)","c2c27844":"generator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5,beta_1=0.5, beta_2=0.999)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5,beta_1=0.5, beta_2=0.999)","f4bb2bd4":"EPOCHS = 100\nnoise_dim = 100\nnum_examples_to_generate = 4\n\n\n# \u6211\u4eec\u5c06\u91cd\u590d\u4f7f\u7528\u8be5\u79cd\u5b50\uff08\u56e0\u6b64\u5728\u52a8\u753b GIF \u4e2d\u66f4\u5bb9\u6613\u53ef\u89c6\u5316\u8fdb\u5ea6\uff09\nseed = tf.random.normal([num_examples_to_generate, noise_dim])","210bac66":"def image_show():\n    \n    predictions = generator(seed, training=False)\n    \n    fig = plt.figure(figsize=(4, 4))\n    \n    for i in range(predictions.shape[0]):\n        plt.subplot(2, 2, i+1)\n        plt.imshow((predictions[i, :, :, :3] + 1)\/2)\n        plt.axis('off')\n    plt.show()\n    \n    return predictions","45306e3e":"pred = image_show()","523e6e30":"@tf.function\ndef train_discriminator(batch_imgs):\n    # \u8bad\u7ec3discriminator\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n    with tf.GradientTape() as discriminator_tape:\n\n        real_output = discriminator(batch_imgs,training=True)\n        generated_images = generator(noise,training=True)\n        fake_output = discriminator(generated_images,training=True)\n\n        disc_loss = discriminator_loss(real_output,fake_output)\n\n    discriminator_grads = discriminator_tape.gradient(disc_loss, discriminator.trainable_variables)\n    discriminator_optimizer.apply_gradients(zip(discriminator_grads, discriminator.trainable_variables))\n    \n    return disc_loss","3f52b510":"@tf.function\ndef train_generator():\n    noise = tf.random.normal([BATCH_SIZE, noise_dim])        \n    with tf.GradientTape() as generator_tape:\n        generated_images = generator(noise,training=True)\n        fake_output = discriminator(generated_images,training=True)\n\n        gen_loss = generator_loss(fake_output)\n\n    generator_grads = generator_tape.gradient(gen_loss, generator.trainable_variables)\n    generator_optimizer.apply_gradients(zip(generator_grads, generator.trainable_variables))\n    \n    return gen_loss","5f1cd71e":"Evolutionary_history = []","132a4315":"from tqdm import tqdm\nimport time","e31c3100":"pbr = tqdm(range(EPOCHS))\nfor epoch in pbr:\n    \n    START = time.time()\n\n    for batch_imgs in image_ds:\n        \n        # \u8bad\u7ec3discriminator\n        disc_loss = train_discriminator(batch_imgs)\n\n        # \u8bad\u7ec3generator\n        gen_loss = train_generator()\n        \n    if (epoch+1)%10 == 0:\n        cache = generator(seed, training=False)\n        Evolutionary_history.append(cache)\n        \n    END = time.time()\n    Run_time = END - START\n        \n    pbr.set_description('Epoch:%d,Run_time = %.4fs,disc_loss = %.2f,gen_loss = %.4f' % (epoch+1,Run_time,disc_loss,gen_loss))","e5897a08":"len(Evolutionary_history)","df70cfb2":"for predictions in Evolutionary_history:\n    fig = plt.figure(figsize=(4, 4))\n    \n    for i in range(predictions.shape[0]):\n        plt.subplot(2, 2, i+1)\n        plt.imshow((predictions[i, :, :, :3] + 1)\/2)\n        plt.axis('off')\n    plt.show()","084a3408":"# **\u8bad\u7ec3**","c3cf752b":"# **\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668**","1eada21a":"# **\u8bfb\u53d6\u56fe\u7247\u8def\u5f84**","cb4f9ed3":"**\u8bb0\u5f55\u8bad\u7ec3\u8fc7\u7a0b**","2670cb79":"# **\u5c06\u6240\u6709\u56fe\u7247\u8bfb\u5165\u5185\u5b58**","9cb6ca98":"# **\u8fdb\u5316\u53f2**","fef07b6d":"# **\u5b9a\u4e49Discriminator**","7e51c25d":"# **\u5c55\u793a\u4e00\u5f20\u56fe\u7247**","f153e5e5":"**\u4f7f\u7528\uff08\u5c1a\u672a\u8bad\u7ec3\u7684\uff09\u751f\u6210\u5668\u521b\u5efa\u4e00\u5f20\u56fe\u7247**","569606e8":"**\u5171\u8bad\u7ec310\u6b21\uff0c\u603b\u8ba11000\u4ee3**","2efbf9b7":"# **\u5b9a\u4e49Generator**","af8dd567":"**\u4f7f\u7528@tf.function\u52a0\u5feb\u8bad\u7ec3**","49a37c01":"# **\u521b\u5efaDataset\u6570\u636e\u7ba1\u9053**","f073b5a7":"# **\u8bad\u7ec3\u8d85\u53c2**","40864b3e":"**\u4f7f\u7528discriminator\u9884\u6d4b\u521a\u521a\u751f\u6210\u7684\u56fe\u7247**"}}