{"cell_type":{"d746a9ff":"code","be6c6af0":"code","ba772438":"code","117df215":"code","fdc2db91":"code","2ccab336":"code","df8d7027":"code","cd8b1e38":"code","9ed31bba":"code","68803a0f":"markdown","9089c9ab":"markdown","8862f4a7":"markdown"},"source":{"d746a9ff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","be6c6af0":"df = pd.read_json('\/kaggle\/input\/scl-2021-da\/contacts.json')\nnpdata = df.values\ndf.head()","ba772438":"memory = {}\nconnections = {}","117df215":"def add_to_memory(user_id, value):\n    if value != \"\":\n        if value in memory:\n            memory[value].add(user_id)\n            return\n        memory[value] = {user_id}","fdc2db91":"for row in tqdm(npdata):\n    user_id = row[0]\n    add_to_memory(user_id, row[4])\n    add_to_memory(user_id, row[1])\n    add_to_memory(user_id, row[2])","2ccab336":"for ids in tqdm(memory.values(), total=len(memory.values())):\n    current_connection = set(ids)\n    \n    for uid in ids:\n        if uid in connections:\n            current_connection.update(connections[uid])\n    \n    for uid in current_connection:\n        connections[uid] = current_connection","df8d7027":"output = []\nfor user_id, trace in tqdm(sorted(connections.items())):\n    contacts = np.sum(npdata[list(trace), 3])\n    trace = \"-\".join([str(_id) for _id in sorted(trace)])\n    answer = \"{}, {}\".format(trace, contacts)\n    output.append({\"ticket_id\": user_id,  \"ticket_trace\/contact\": answer})","cd8b1e38":"output_df = pd.DataFrame(output)\noutput_df.head(20)","9ed31bba":"filename = \"output.csv\"\noutput_df.to_csv(filename, index=False)","68803a0f":"## Sum contacts and build output format","9089c9ab":"Our memory will look like this.\n```json\n{\n  \"randomemail\\@gg.com\": {id1, id2, id3},\n  \"randomorderid987227\": {id4, id5, id6, id7, id8},\n  ...\n}\n```","8862f4a7":"## Trace\n\ndefine memory (dictionary) with value: set of ids, and email\/phone\/order_id as key."}}