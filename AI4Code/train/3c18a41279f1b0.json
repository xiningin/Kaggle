{"cell_type":{"d2dd22b0":"code","1fc85993":"code","bb669643":"code","8333ee2d":"code","332386dc":"code","7e774ff0":"code","f036c82f":"code","30de038c":"code","a7221ff0":"code","ab3721bc":"code","5815878c":"code","cb76c572":"code","599a6c61":"code","acbe25ee":"code","26297ccc":"code","32dc37ad":"code","6ca465fb":"markdown","4b4b0070":"markdown","4bf5093f":"markdown","1c6ff405":"markdown","36a372a2":"markdown"},"source":{"d2dd22b0":"import numpy as np\nimport matplotlib.pyplot as plt","1fc85993":"X = 2 * np.random.rand(100,1)\ny = 4 + 3 * X + np.random.rand(100,1)","bb669643":"plt.plot(X,y,\"b.\")\nplt.axis([0,2,0,15])\nplt.show()","8333ee2d":"X_b = np.c_[np.ones((100,1)),X]\ntheta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)","332386dc":"theta","7e774ff0":"X_new = np.array([[0],[2]])\nX_new_b = np.c_[np.ones((2,1)),X_new]\ny_prdct = X_new_b.dot(theta)\ny_prdct","f036c82f":"plt.plot(X_new,y_prdct,\"r-\")\nplt.plot(X,y,\"b.\")\nplt.axis([0,2,0,15])\nplt.show()","30de038c":"from sklearn.linear_model import LinearRegression","a7221ff0":"lin_reg = LinearRegression()\nlin_reg.fit(X,y)\nlin_reg.intercept_, lin_reg.coef_","ab3721bc":"eta = 0.1        #learnng rate\nn_iterations = 1000\nm = 100\n\ntheta1 = np.random.randn(2,1)\n\nfor iteration in range(n_iterations):\n    gradients = 2\/m * X_b.T.dot(X_b.dot(theta1)- y)\n    theta1 = theta1 - eta * gradients\n    \n    X_new = np.array([[0],[2]])\n    X_new_b = np.c_[np.ones((2,1)),X_new]\n    y_prdct1 = X_new_b.dot(theta1)\n    plt.plot(X_new,y_prdct1,\"r-\")\n    plt.plot(X,y,\"b.\")\n    plt.axis([0,2,0,15])\n    \n","5815878c":"theta","cb76c572":"n_epochs = 10\nt0, t1 = 5, 50 #Learning schedule Hyperparameters\n\ndef learning_schedule(t):\n    return t0 \/ (t + t1)\n\ntheta2 = np.random.randn(2,1) # random initialization\nfor epoch in range(n_epochs):\n    for i in range(m):\n        random_index = np.random.randint(m)\n        xi = X_b[random_index:random_index+1]\n        yi = y[random_index:random_index+1]\n        gradients = 2 * xi.T.dot(xi.dot(theta2) - yi)\n        eta = learning_schedule(epoch * m + i)\n        theta2 = theta2 - eta * gradients\n        \n        X_SD = np.array([[0],[2]])\n        X_new_SD = np.c_[np.ones((2,1)),X_SD]\n        y_SD = X_new_SD.dot(theta2)\n        plt.plot(X_SD,y_SD,\"r-\")\n        plt.plot(X,y,\"b.\")\n        plt.axis([0,2,0,15])\n        ","599a6c61":"theta2","acbe25ee":"eta","26297ccc":"from sklearn.linear_model import SGDRegressor\nsgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.1)\nsgd_reg.fit(X, y.ravel())","32dc37ad":"sgd_reg.intercept_, sgd_reg.coef_","6ca465fb":"## Batch Gradient Descent","4b4b0070":"## Normal Equation","4bf5093f":"## Stochastic Gradient Descend","1c6ff405":"## sklearn Linear Model","36a372a2":"## Linear Regression"}}