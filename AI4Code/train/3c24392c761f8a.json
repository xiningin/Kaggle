{"cell_type":{"ee34db9e":"code","1e816d45":"code","38823e3d":"code","0be06dca":"code","4b873c8c":"code","e1f61bef":"code","05deccf4":"code","a26b98c9":"code","47b073a1":"code","4d4d1fb6":"code","a24c2fdb":"code","1e562fb9":"code","56997404":"code","93c8c4b2":"code","81ecfeed":"code","494bf757":"code","b2176252":"code","936e755f":"code","2124cf50":"code","91a3efa4":"code","647883ca":"code","c77fd0c1":"markdown"},"source":{"ee34db9e":"# Import, configuration cell\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # simple matplotlib interface for data visualization\n\nimport os # to work with directories\nimport zipfile # to extract images from input .zip file\nimport shutil  # to copy data between folders\n\nfrom tqdm import tqdm # loops progress bar \n\nimport torch # main machine learning framework\nimport imgaug.augmenters as iaa # image augmentation library\nimport torchvision # image loader, augmentation, neural networks architectures\nfrom torchvision import transforms, models\n\n\n# Configuration for the kernel\nconfig = {\n    \"n_train_epoch\": 65,\n    \"batch_size\": 8,\n    \"scheduler_use\": False,\n    \"n_augmentation_repeat\": 8,\n    \"show_train_progress\": True,\n    \"show_augmented_images\": True\n}","1e816d45":"# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n# Any results you write to the current directory are saved as output.\n\nprint('Contents of the input folder: \\n', \n      os.listdir(\"..\/input\/\"))\n\n# Extract all the contents of zip file in current directory\nwith zipfile.ZipFile('..\/input\/plates.zip', 'r') as zip_obj:\n    zip_obj.extractall('\/kaggle\/working\/')\n    \nprint('After zip extraction: \\n', \n      os.listdir(\"\/kaggle\/working\/\"))","38823e3d":"data_root = '\/kaggle\/working\/plates\/'\ntrain_dir = 'train'\nval_dir = 'val'\n\nclass_names = ['cleaned', 'dirty']\n\n# Creating 'cleaned' and 'dirty' folders inside the 'train' and 'val' directories\nfor dir_name in [train_dir, val_dir]:\n    for class_name in class_names:\n        os.makedirs(os.path.join(dir_name, class_name), exist_ok=True)\n\n# Copy images from the 'train' folder to the new 'train' folder considering the labels\n# Each sixth image goes to validation data\nfor class_name in class_names:\n    source_dir = os.path.join(data_root, 'train', class_name)\n    for i, file_name in enumerate(tqdm(sorted(os.listdir(source_dir)))):\n        dest_dir = os.path.join(train_dir if i%5!=0 else val_dir, class_name)\n        shutil.copy(os.path.join(source_dir, file_name), \n                        os.path.join(dest_dir, file_name))","0be06dca":"!ls train\/cleaned","4b873c8c":"# Train augmentation cell with imgaug library.\n# Unfortunaly, this library doesn't updated on kaggle, so i couldn't use a lot of important functions.\n# This cell isn't used, but just i just left it here.\n\n# random_using(0.45, ...) applies the given augmenter in 45% of all cases.\nrandom_using = lambda aug: iaa.Sometimes(0.45, aug)\n\nclass ImgAugTransform:\n    def __init__(self):\n        self.aug = iaa.Sequential(\n            [\n                # Apply the following augmenters to most images\n                random_using(iaa.CropAndPad(percent=(-0.1, 0.3))),\n                iaa.Fliplr(0.5), # horizontally flip 50% of all images\n                iaa.Flipud(0.2),  # vertically flip 20% of all images\n                random_aug_use(iaa.Affine(\n                    rotate=(-90, 90), # rotate by -90 to +45 degrees\n                )),\n                iaa.Add((30, 30)), # change brightness of images (by -30 to 30 of original value) \n                iaa.AddToHueAndSaturation((-15, 15))               \n            ], random_order=True)\n    \n    def __call__(self, img):\n        img = np.array(img)\n        return np.ascontiguousarray(self.aug.augment_image(img))","e1f61bef":"train_transforms = transforms.Compose([\n    #ImgAugTransform(),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.35),\n    transforms.RandomAffine(degrees=(-60, 60)),\n    transforms.ColorJitter(brightness=(0.7, 1.35), \n                           contrast=(0.8, 1.4), \n                           saturation=(0.8, 1.2), \n                           hue=(-0.1, 0.1)),\n    transforms.CenterCrop((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\nval_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.RandomHorizontalFlip(p=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntrain_dataset = torch.utils.data.ConcatDataset([\n     torchvision.datasets.ImageFolder(train_dir, train_transforms)\n    for _ in range(config['n_augmentation_repeat'])\n])\nval_dataset = torchvision.datasets.ImageFolder(val_dir, val_transforms)\n\n\nbatch_size = config['batch_size']\ntrain_dataloader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True, num_workers=batch_size)\nval_dataloader = torch.utils.data.DataLoader(\n    val_dataset, batch_size=batch_size, shuffle=False, num_workers=batch_size)","05deccf4":"def show_input(input_tensor, title=''):\n    \"\"\"\n    Function for showing images. \n        \n    Keyword arguments:\n        input_rensor -- one torch.Tensor object\n        title -- plate type (cleaned or dirty) (default '')\n    \"\"\"\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    image = input_tensor.permute(1, 2, 0).numpy()\n    image = std * image + mean\n    plt.imshow(image.clip(0, 1))\n    plt.title(title)\n    plt.show()\n    plt.pause(0.001)","a26b98c9":"for X_batch, y_batch in tqdm(train_dataloader): \n    for x_item, y_item in zip(X_batch, y_batch):\n        show_input(x_item, title=class_names[y_item])\n    break","47b073a1":"def train_model(model, loss, optimizer, scheduler, num_epochs):\n    \"\"\"\n    Model training function. In range of epochs number it passes 2 phases: training and validation.\n    If the validation phase, we don't allow the network to change.\n    \n    Keyword arguments:\n    \"\"\"\n    \n    global config\n    statistics = {\n        'val_loss': [],\n        'train_loss': [],\n        'val_acc': [],\n        'train_acc': []\n    }\n    \n    for epoch in range(num_epochs):\n        if config['show_train_progress']:\n            print('Epoch {}\/{}:'.format(epoch, num_epochs - 1), flush=True)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                dataloader = train_dataloader\n                if config['scheduler_use']:\n                    scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                dataloader = val_dataloader\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.\n            running_acc = 0.\n\n            # Iterate over data.\n            for inputs, labels in tqdm(dataloader):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                # forward and backward\n                with torch.set_grad_enabled(phase == 'train'):\n                    preds = model(inputs)\n                    loss_value = loss(preds, labels)\n                    preds_class = preds.argmax(dim=1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss_value.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss_value.item()\n                running_acc += (preds_class == labels.data).float().mean()\n\n            epoch_loss = running_loss \/ len(dataloader)\n            epoch_acc = running_acc \/ len(dataloader)\n\n            if phase == 'train':\n                statistics['train_loss'].append(epoch_loss)\n                statistics['train_acc'].append(epoch_acc.item())\n            else:\n                statistics['val_loss'].append(epoch_loss)\n                statistics['val_acc'].append(epoch_acc.item())\n    \n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)\n\n    return (model, statistics)","4d4d1fb6":"model = models.mobilenet_v2(pretrained = True)\n\n# Disable grad for all conv layers\n#for param in model.parameters():\n    #param.requires_grad = False\n\nmodel.classifier[1] = torch.nn.Sequential(\n    torch.nn.Linear(model.classifier[1].in_features, model.classifier[1].in_features),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(p=0.5),\n\n    torch.nn.Linear(model.classifier[1].in_features, 2)\n)\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\nloss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1.0e-3)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)","a24c2fdb":"model, stats = train_model(model, \n                           loss, \n                           optimizer, \n                           scheduler, \n                           num_epochs=config['n_train_epoch'])","1e562fb9":"# Saving the model\nmodel_filename = 'model_state_dict.pt'\ntorch.save(model.state_dict(), model_filename)","56997404":"plt.figure(figsize=(24, 9))\nfunction_names = ['Loss', 'Accuracy']\nstats_names = iter(list(stats.keys()))\n  \nfor i in range(2):\n    ax = plt.subplot(1, 2, i+1)\n    ax.plot(range(config['n_train_epoch']),\n            stats[next(stats_names)], \n            label='Validation', \n            color='darkorchid', \n            lw=2.5)\n    ax.plot(range(config['n_train_epoch']), \n            stats[next(stats_names)], \n            label='Training', \n            color='mediumspringgreen', \n            lw=2.5)\n    ax.set_xlabel('Number of training epochs')\n    ax.set_ylabel(function_names[i] + ' value')\n    ax.set_title(function_names[i] + ' Functions', fontsize=20)\n    ax.legend(fontsize=14)","93c8c4b2":"test_dir = 'test'\nshutil.copytree(os.path.join(data_root, 'test'), \n                os.path.join(test_dir, 'unknown'))","81ecfeed":"class ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n    def __getitem__(self, index):\n        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n        path = self.imgs[index][0]\n        tuple_with_path = (original_tuple + (path,))\n        return tuple_with_path\n    \ntest_dataset = ImageFolderWithPaths('\/kaggle\/working\/test', val_transforms)\n\ntest_dataloader = torch.utils.data.DataLoader(\n    test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)","494bf757":"test_dataset","b2176252":"model.eval()\n\ntest_predictions = []\n\ntest_img_paths = []\nfor inputs, labels, paths in tqdm(test_dataloader):\n    inputs = inputs.to(device)\n    labels = labels.to(device)\n    with torch.set_grad_enabled(False):\n        preds = model(inputs)\n    test_predictions.append(\n        torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy())\n    test_img_paths.extend(paths)\n    \ntest_predictions = np.concatenate(test_predictions)","936e755f":"for i, (inputs, labels, paths) in enumerate(test_dataloader):\n    for img, pred in zip(inputs, test_predictions):\n        show_input(img, title=pred)\n    if i == 1:\n        break","2124cf50":"# Creating and postprocessing data to csv file.\nsubmission_df = pd.DataFrame.from_dict({'id': test_img_paths, 'label': test_predictions})\n\nsubmission_df['label'] = submission_df['label'].map(lambda pred: 'dirty' if pred > 0.5 else 'cleaned')\nsubmission_df['id'] = submission_df['id'].str.replace('\/kaggle\/working\/test\/unknown\/', '')\nsubmission_df['id'] = submission_df['id'].str.replace('.jpg', '')\nsubmission_df.set_index('id', inplace=True)\nsubmission_df.head(n=20)","91a3efa4":"submission_df.to_csv(\"submission.csv\")","647883ca":"!rm -rf plates train val test","c77fd0c1":"##  Little comment\n\nBeginning with 35 epoch we can see some overfitting traces. But as practice shows, by reducing the number of epochs to 20-35, we do not achieve an improvement in the model with a 100 percent probability. The model is learning unstable, and I got my best score at 65 epochs, when traces of overfitting appear in the interval of epochs from 18 to 25. But I am sure that by going through the options for training parameters, it would be possible to increase the score even more."}}