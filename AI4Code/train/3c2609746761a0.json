{"cell_type":{"687b7922":"code","692cee01":"code","a34a26d6":"code","7a6c113a":"code","f51e2258":"code","c5ec74b6":"code","56b1c946":"code","d5a0dd35":"code","86e9f8e7":"code","1dbc677c":"code","601851e7":"code","b2cb547e":"code","5e742001":"code","8ed256c4":"code","7529ec62":"code","a3dddc9e":"code","c86944bb":"code","884e28e3":"code","df14de04":"code","5c5359e5":"code","8427f744":"code","2282e829":"code","dff4ef6c":"code","1873a321":"code","24d47885":"code","b2d5dd6f":"code","3ef50fca":"code","470fc571":"code","866e3bd0":"code","fcf74b18":"code","e2542eb9":"code","592a88f9":"code","7b8a9fdf":"code","31d51645":"code","01c3b78e":"code","c0ca144f":"code","90788d67":"code","eb430188":"code","8974058b":"code","b56ec078":"code","5483d4f6":"code","1e7108af":"code","3de1a0dc":"code","a8c0b75a":"code","ff816d95":"code","a7326221":"code","eb6addb0":"code","a72f81d1":"code","0a8a07ac":"code","b556d701":"code","f3b9ac30":"code","8e91b4d6":"code","a5ad31b8":"code","b8278a9e":"code","ed84a4b7":"code","d247eb4b":"code","a6a77466":"code","568c747f":"code","bf12cc93":"code","272f80d6":"code","5ad03dce":"code","09c89541":"code","e336352f":"code","11a7f32e":"code","4afb9431":"code","fad2e73a":"code","cf7152b5":"code","257e7946":"code","91d7e5ba":"code","b52aaaba":"code","ba29b890":"code","cee471d9":"code","8e2a6a86":"code","44017ff8":"code","08a48f59":"code","891808c6":"markdown","8b85fe8f":"markdown","2820bb48":"markdown","e1b0f763":"markdown","5f0c54cf":"markdown","d8b863f5":"markdown","da80ba94":"markdown","9913449f":"markdown","65df8483":"markdown","c37733d0":"markdown","083f19cc":"markdown","0a704638":"markdown","81d999fb":"markdown","d00c589a":"markdown","aacada45":"markdown","fb0f7d2d":"markdown","8cc48330":"markdown","5919fd30":"markdown","6b40c1ce":"markdown","fea37fdd":"markdown","3deaad98":"markdown","0f9fe9cc":"markdown","5521a288":"markdown","aa4a7ef6":"markdown","42f67dd7":"markdown","1e6de4da":"markdown","cbd9437d":"markdown","45076197":"markdown","d808c6ce":"markdown","6632e451":"markdown","4fdbdb8a":"markdown","a7cd8b71":"markdown","da829cc8":"markdown","b414a685":"markdown","5bce2a13":"markdown","295bd542":"markdown","634b1124":"markdown","702e097d":"markdown","a817edac":"markdown","a22b5c2e":"markdown","94b87a1d":"markdown","e5b7240a":"markdown","13cf1b49":"markdown","a3289662":"markdown","eb1e9240":"markdown","7d6e7514":"markdown"},"source":{"687b7922":"from numpy.random import seed\nseed(101)\n\nimport pandas as pd\nimport numpy as np\n\n\nimport os\nimport cv2\n\nimport imageio\nimport skimage\nimport skimage.io\nimport skimage.transform\n\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\n\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport itertools\nimport shutil\nimport matplotlib.pyplot as plt\n%matplotlib inline","692cee01":"base_path = '..\/input\/computed-tomography-ct-images\/computed-tomography-images-for-intracranial-hemorrhage-detection-and-segmentation-1.0.0\/'\nos.listdir(base_path)","a34a26d6":"\nIMAGE_HEIGHT_ORIG = 650\nIMAGE_WIDTH_ORIG = 650\n\nNUM_TEST_IMAGES = 10 # 10 with intracranial hem + 10 without intracranial hem\n\nIMAGE_HEIGHT = 256\nIMAGE_WIDTH = 256\nIMAGE_CHANNELS = 3\n\nBATCH_SIZE = 10\n","7a6c113a":"# Function to perform the augmentations\n\ndef augment_image_and_mask(augmentation, image, mask):\n    \n    \"\"\"\n    Uses the Albumentations library.\n    \n    Inputs: \n    1. augmentation - this is the instance of type of augmentation to do \n    e.g. aug_type = HorizontalFlip(p=1) \n    # p=1 is the probability of the transform being executed.\n    \n    2. image - image with shape (h,w)\n    3. mask - mask with shape (h,w)\n    \n    Output:\n    Augmented image as a numpy array.\n    Augmented mask as a numpy array.\n    \n    \"\"\"\n    # get the transform as a dict\n    aug_image_dict =  augmentation(image=image, mask=mask)\n    # retrieve the augmented matrix of the image\n    image_matrix = aug_image_dict['image']\n    \n    mask_matrix = aug_image_dict['mask']\n    \n    return image_matrix, mask_matrix\n","f51e2258":"! pip install segmentation-models","c5ec74b6":"path = base_path + 'hemorrhage_diagnosis.csv'\ndf_diag = pd.read_csv(path)\n\n# The existing No_Hemorrhage target column is not intuitive. \n# Create a new target column to make the binary targets easier to understand.\n\ndef swap_target(x):\n    if x == 0:\n        return 1\n    else:\n        return 0\n\n# create a new target column\ndf_diag['Has_Hemorrhage'] = df_diag['No_Hemorrhage'].apply(swap_target)\n\n# drop the old target column\ndf_diag = df_diag.drop('No_Hemorrhage', axis=1)\n\nprint(df_diag.shape)\n\ndf_diag.head()","56b1c946":"# Patient 84\n# Brain image 36.jpg exists but bone image 36.jpg is missing.\n\n# Therefore, we will drop this row from the dataframe.\n\nindex_to_drop = df_diag[(df_diag['PatientNumber'] == 84) & (df_diag['SliceNumber'] == 36)].index\n\nindex_to_drop = index_to_drop[0]\n\ndf_diag = df_diag.drop(index_to_drop, axis=0)\n\n\n# Check that the row that we dropped has been removed\ndf_diag[df_diag.index == index_to_drop]","d5a0dd35":"# Create new columns\n\n\ndef get_mask_fname(row):\n        \n    mask_id = str(row['SliceNumber']) + '_HGE_Seg.jpg'\n    return mask_id\n    \n\n# create a new column with mask file names\ndf_diag['mask_fname'] = df_diag.apply(get_mask_fname, axis=1)\n\n\n\n\ndef new_mask_fname(row):\n        \n    mask_id = str(row['PatientNumber']) + '_' + str(row['SliceNumber']) + '_HGE_Seg.jpg'\n    return mask_id\n\n\n# create a new column with a new mask file names\ndf_diag['new_mask_fname'] = df_diag.apply(new_mask_fname, axis=1)\n\n\n\n\ndef assign_image_fname(row):\n    \n    image_fname = str(row['SliceNumber']) + '.jpg'\n    \n    return image_fname\n\n\n# create a new column with image file names\ndf_diag['image_fname'] = df_diag.apply(assign_image_fname, axis=1)\n\n\n\ndef assign_new_fname(row):\n         \n    mask_id = str(row['PatientNumber']) + '_' + str(row['SliceNumber']) + '.jpg'\n    \n    return mask_id\n    \n# create a new column with new image file names\ndf_diag['new_image_fname'] = df_diag.apply(assign_new_fname, axis=1)\n\n\n\ndf_diag.head()","86e9f8e7":"# This is the binary target distribution.\n# You will note that it is unbalanced - most images have no signs of hemorrhage.\n\ndf_diag['Has_Hemorrhage'].value_counts()","1dbc677c":"# This is the total number of patients\n\ndf_diag['PatientNumber'].nunique()","601851e7":"path = base_path + 'Patients_CT'\n\nfolder_list = os.listdir(path)\n\nlen(folder_list)","b2cb547e":"# create a new mask dir\nmask_dir = 'mask_dir'\nos.mkdir(mask_dir)","5e742001":"# For non blank masks i.e. masks showing intracranial hemorrhage\n\nfor folder_name in folder_list:\n    \n    # convert the folder name to integer\n    patient_num = int(folder_name)\n    \n    # filter by patient number\n    df = df_diag[df_diag['PatientNumber'] == patient_num]\n    \n    # filter by Has_Hemorrhage\n    df = df[df['Has_Hemorrhage'] == 1]\n    \n    # get the list of mask file names\n    mask_list = list(df['mask_fname'])\n    \n    for fname in mask_list:\n        \n        # add the patient number to the file name\n        new_fname = str(patient_num) + '_' + fname\n        \n        # Source path to mask.\n        # All masks are in the brain folder.\n        path = base_path + 'Patients_CT\/' + folder_name + '\/brain'\n        src = os.path.join(path, fname)\n        # destination path to mask\n        dst = os.path.join(mask_dir, new_fname)\n        # copy the mask from the source to the destination\n        shutil.copyfile(src, dst)\n        \n# Check how many masks are in the new folder. (Should be 318)\nlen(os.listdir('mask_dir'))","8ed256c4":"# For blank masks i.e. masks without intracranial hemorrhage\n\nblank_mask = np.zeros((IMAGE_HEIGHT_ORIG, IMAGE_WIDTH_ORIG))\n\n\nfor folder_name in folder_list:\n    \n    # convert the folder name to integer\n    patient_num = int(folder_name)\n    \n    # filter by patient number\n    df = df_diag[df_diag['PatientNumber'] == patient_num]\n    \n    # filter by Has_Hemorrhage\n    df = df[df['Has_Hemorrhage'] == 0]  # <-- for empty masks change filter here\n    \n    # get the list of mask file names\n    mask_list = list(df['mask_fname'])\n    \n    for fname in mask_list:\n        \n        # add the patient number to the file name\n        new_fname = str(patient_num) + '_' + fname\n        \n        # set the destination where the file will be saved\n        dst = os.path.join(mask_dir, new_fname)\n      \n        # save the image\n        cv2.imwrite(dst, blank_mask)\n        \n# Check how many masks are in the new folder. (Should be 2500)\nlen(os.listdir('mask_dir'))\n\n","7529ec62":"# create a new mask dir\nbrain_image_dir = 'brain_image_dir'\nos.mkdir(brain_image_dir)","a3dddc9e":"for folder_name in folder_list:\n    \n    # convert the folder name to integer\n    patient_num = int(folder_name)\n    \n    # filter by patient number\n    df = df_diag[df_diag['PatientNumber'] == patient_num]\n    \n    \n    # get the list of image file names\n    image_list = list(df['image_fname'])\n    \n    for fname in image_list:\n        \n        # add the patient number to the file name\n        new_fname = str(patient_num) + '_' + fname\n        \n        # source path to image\n        path = base_path + 'Patients_CT\/' + folder_name + '\/brain'\n        src = os.path.join(path, fname)\n        # destination path to mask\n        dst = os.path.join(brain_image_dir, new_fname)\n        # copy the mask from the source to the destination\n        shutil.copyfile(src, dst)\n        \n        \n\n# Check how many images are in the new folder (Should be 2500)\nlen(os.listdir('brain_image_dir'))","c86944bb":"# create a new mask dir\nbone_image_dir = 'bone_image_dir'\nos.mkdir(bone_image_dir)","884e28e3":"for folder_name in folder_list:\n    \n    # convert the folder name to integer\n    patient_num = int(folder_name)\n    \n    # filter by patient number\n    df = df_diag[df_diag['PatientNumber'] == patient_num]\n    \n    \n    # get the list of image file names\n    image_list = list(df['image_fname'])\n    \n    for fname in image_list:\n        \n        # add the patient number to the file name\n        new_fname = str(patient_num) + '_' + fname\n        \n        # source path to image\n        path = base_path + 'Patients_CT\/' + folder_name + '\/bone'\n        src = os.path.join(path, fname)\n        # destination path to mask\n        dst = os.path.join(bone_image_dir, new_fname)\n        # copy the mask from the source to the destination\n        shutil.copyfile(src, dst)\n        \n        \n# Check how many images are in the new folder (Should be 2500)\nlen(os.listdir('bone_image_dir'))","df14de04":"# brain image\n\nindex = 14\nfname = df_diag.loc[index, 'new_image_fname']\npath = 'brain_image_dir\/' + fname\n# read the image as a matrix\nbrain_image = plt.imread(path)\n\nprint(brain_image.shape)\n\nplt.imshow(brain_image, cmap='gray')","5c5359e5":"# bone image\n\nfname = df_diag.loc[index, 'new_image_fname']\npath = 'bone_image_dir\/' + fname\n# read the image as a matrix\nbone_image = plt.imread(path)\n\nprint(bone_image.shape)\n\nplt.imshow(bone_image, cmap='gray')","8427f744":"# mask\n\nfname = df_diag.loc[index, 'new_mask_fname']\npath = 'mask_dir\/' + fname\n# read the image as a matrix\nmask = plt.imread(path)\n\nprint(mask.shape)\n\nplt.imshow(mask, cmap='Blues', alpha=0.7)","2282e829":"plt.imshow(brain_image, cmap='gray')\nplt.imshow(mask, cmap='Blues', alpha=0.7)","dff4ef6c":"# HOW TO DO MULTIPLE AUGMENTATIONS\n\nimport albumentations as albu\n\n# Define the augmentations\n\naug_types = albu.Compose([\n    albu.HorizontalFlip(p=0.5),\n    albu.OneOf([\n        albu.RandomContrast(),\n        albu.RandomGamma(),\n        albu.RandomBrightness(),\n        ], p=0.3),\n    albu.OneOf([\n        albu.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n        albu.GridDistortion(),\n        albu.OpticalDistortion(distort_limit=2, shift_limit=0.5),\n        ], p=0.3),\n    albu.ShiftScaleRotate(scale_limit=0.1, rotate_limit=10, shift_limit=0.1, p=0.5, border_mode=0),\n])\n\n\n# This how to call the function\n# aug_image, aug_mask = augment_image_and_mask(aug_types, image, mask)","1873a321":"# brain image\n\nindex = 14\nfname = df_diag.loc[index, 'new_image_fname']\npath = 'brain_image_dir\/' + fname\n# read the image as a matrix\nbrain_image = cv2.imread(path)\n\nprint(brain_image.shape)\n\nplt.imshow(brain_image, cmap='gray')","24d47885":"# mask\n\nfname = df_diag.loc[index, 'new_mask_fname']\npath = 'mask_dir\/' + fname\n# read the image as a matrix\nmask = plt.imread(path)\n\nprint(mask.shape)\n\nplt.imshow(mask, cmap='Blues', alpha=0.7)","b2d5dd6f":"plt.imshow(brain_image, cmap='gray')\nplt.imshow(mask, cmap='Blues', alpha=0.7)","3ef50fca":"# Example augmentation - image and mask\n\n# augment the image and mask\naug_image, aug_mask = augment_image_and_mask(aug_types, brain_image, mask)\n\n\n\nplt.imshow(aug_image, cmap='gray')\nplt.imshow(aug_mask, cmap='Blues', alpha=0.7)","470fc571":"# source: https:\/\/www.kaggle.com\/gpreda\/honey-bee-subspecies-classification\n\ndef draw_category_images(col_name,figure_cols, df, IMAGE_PATH):\n    \n    \"\"\"\n    Give a column in a dataframe,\n    this function takes a sample of each class and displays that\n    sample on one row. The sample size is the same as figure_cols which\n    is the number of columns in the figure.\n    Because this function takes a random sample, each time the function is run it\n    displays different images.\n    \"\"\"\n    \n\n    categories = (df.groupby([col_name])[col_name].nunique()).index\n    f, ax = plt.subplots(nrows=len(categories),ncols=figure_cols, \n                         figsize=(4*figure_cols,4*len(categories))) # adjust size here\n    \n    # draw a number of images for each location\n    for i, cat in enumerate(categories):\n        sample = df[df[col_name]==cat].sample(figure_cols) # figure_cols is also the sample size\n        for j in range(0,figure_cols):\n            file=IMAGE_PATH + sample.iloc[j]['new_image_fname']\n            im=imageio.imread(file)\n            ax[i, j].imshow(im, resample=True, cmap='gray')\n            ax[i, j].set_title(cat, fontsize=14)\n               \n    plt.tight_layout()\n    plt.show()\n    \n   \n  \n  \ndef draw_category_masks(col_name,figure_cols, df, IMAGE_PATH):\n    \n    \"\"\"\n    Give a column in a dataframe,\n    this function takes a sample of each class and displays that\n    sample on one row. The sample size is the same as figure_cols which\n    is the number of columns in the figure.\n    Because this function takes a random sample, each time the function is run it\n    displays different images.\n    \"\"\"\n    \n\n    categories = (df.groupby([col_name])[col_name].nunique()).index\n    f, ax = plt.subplots(nrows=len(categories),ncols=figure_cols, \n                         figsize=(4*figure_cols,4*len(categories))) # adjust size here\n    # draw a number of images for each location\n    for i, cat in enumerate(categories):\n        sample = df[df[col_name]==cat].sample(figure_cols) # figure_cols is also the sample size\n        for j in range(0,figure_cols):\n            file=IMAGE_PATH + sample.iloc[j]['new_mask_fname']\n            im=imageio.imread(file)\n            ax[i, j].imshow(im, resample=True, cmap='gray')\n            ax[i, j].set_title(cat, fontsize=14)  \n    plt.tight_layout()\n    plt.show()\n    ","866e3bd0":"# Brain images\n\nIMAGE_PATH = 'brain_image_dir\/'\ndraw_category_images('Has_Hemorrhage',4, df_diag, IMAGE_PATH)","fcf74b18":"# Bone images\n\nIMAGE_PATH = 'bone_image_dir\/'\n\ndraw_category_images('Has_Hemorrhage',4, df_diag, IMAGE_PATH)","e2542eb9":"# Masks\n\nIMAGE_PATH = 'mask_dir\/'\n\ndraw_category_masks('Has_Hemorrhage',4, df_diag, IMAGE_PATH)","592a88f9":"NUM_TEST_IMAGES = 10\n\n\n# get 10 images without hemorrhages\n\ndf = df_diag[df_diag['Has_Hemorrhage'] == 0]\n\ndf_no_hem = df.sample(NUM_TEST_IMAGES, random_state=101)\n\n# Reset the index.\ndf_no_hem = df_no_hem.reset_index(drop=True)\n\n# create a list of images\ntest_images_list = list(df_no_hem['new_mask_fname'])\n\n\n# Select only rows that are not part of the test set.\n# Note the use of ~ to execute 'not in'.\ndf_diag = df_diag[~df_diag['new_mask_fname'].isin(test_images_list)]\n\n\n# get 10 images with hemorrhages\n\ndf = df_diag[df_diag['Has_Hemorrhage'] == 1]\n\ndf_with_hem = df.sample(NUM_TEST_IMAGES, random_state=102)\n\n# Reset the index.\ndf_with_hem = df_with_hem.reset_index(drop=True)\n\n# create a list of images\ntest_images_list = list(df_with_hem['new_mask_fname'])\n\n\n# Select only rows that are not part of the test set.\n# Note the use of ~ to execute 'not in'.\ndf_diag = df_diag[~df_diag['new_mask_fname'].isin(test_images_list)]\n\n\n# create the test set\ndf_test = pd.concat([df_with_hem, df_no_hem], axis=0).reset_index(drop=True)\n\n\n\nprint(df_diag.shape)\nprint(df_test.shape)","7b8a9fdf":"df_test.head()","31d51645":"# train_test_split\n\n\n# shuffle\ndf_diag = shuffle(df_diag)\n\n# reset the index\ndf_diag = df_diag.reset_index(drop=True)\n\n# We will stratify by target\ny = df_diag['Has_Hemorrhage']\n\ndf_train, df_val = train_test_split(df_diag, test_size=0.15, random_state=107, stratify=y)\n\nprint(df_train.shape)\nprint(df_val.shape)","01c3b78e":"# Check the target distribution in the train set\n\ndf_train['Has_Hemorrhage'].value_counts()","c0ca144f":"# Check the target distribution in the val set\n\ndf_val['Has_Hemorrhage'].value_counts()","90788d67":"df_diag.to_csv('df_data.csv.gz', compression='gzip', index=False)\n\ndf_train.to_csv('df_train.csv.gz', compression='gzip', index=False)\ndf_val.to_csv('df_val.csv.gz', compression='gzip', index=False)\n\ndf_test.to_csv('df_test.csv.gz', compression='gzip', index=False)\n","eb430188":"# check if the files were saved\n!ls","8974058b":"# Note:\n# We won't be using densenet101 pre-processing however,\n# this code would need to be run if we were going to use it in the generators.\n\nfrom segmentation_models import  get_preprocessing # this line has an error in the docs\n\nBACKBONE = 'densenet121'\npreprocess_input = get_preprocessing(BACKBONE)","b56ec078":"# We are only using brain images for training.\n# These are originally single channel images but cv2 will read them with 3 channels.\n\ndef train_generator(batch_size=10):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_train.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['new_image_fname'])\n            mask_id_list = list(df['new_mask_fname'])\n            \n            # Create empty X matrix - 3 channels\n            X_train = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n            # create empty Y matrix - 1 channel\n            Y_train = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, 1), dtype=np.bool)\n\n        \n            \n            # Create X_train\n            #================\n            \n            for i in range(0, len(image_id_list)):\n              \n              \n                # get the image and mask\n                image_id = image_id_list[i]\n                mask_id = mask_id_list[i]\n              \n                \n\n                # set the path to the image\n                path = 'brain_image_dir\/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n                \n                \n            \n            \n            # Create Y_train\n            # ===============\n                \n \n\n                # set the path to the mask\n                path = 'mask_dir\/' + mask_id\n\n                # read the mask\n                mask = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n                \n                # resize the mask\n                mask = cv2.resize(mask, (IMAGE_HEIGHT, IMAGE_WIDTH))\n                \n                # expand dims from (800,600) to (800,600,1)\n                mask = np.expand_dims(mask, axis=-1)\n         \n                \n                \n              \n              \n              \n            # Augment the image and mask\n            # ===========================\n            \n                aug_image, aug_mask = augment_image_and_mask(aug_types, image, mask)\n              \n                # insert the image into X_train\n                X_train[i] = aug_image\n                \n                # insert the image into Y_train\n                Y_train[i] = aug_mask\n                \n                              \n                \n            # Normalize the images\n            X_train = X_train\/255\n\n            yield X_train, Y_train","5483d4f6":"# Test the generator\n\n# initialize\ntrain_gen = train_generator(batch_size=10)\n\n# run the generator\nX_train, Y_train = next(train_gen)\n\nprint(X_train.shape)\nprint(Y_train.shape)","1e7108af":"# print the first image in X_train\n\nimg = X_train[7,:,:,:]\nplt.imshow(img)","3de1a0dc":"# print the mask in Y_train\n\nmsk = Y_train[7,:,:,0]\nplt.imshow(msk)","a8c0b75a":"plt.imshow(img, cmap='gray')\nplt.imshow(msk, cmap='Blues', alpha=0.7)","ff816d95":"def val_generator(batch_size=10):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_val.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['new_image_fname'])\n            mask_id_list = list(df['new_mask_fname'])\n            \n            # Create empty X matrix - 3 channels\n            X_val = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n            # create empty Y matrix - 1 channel\n            Y_val = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, 1), dtype=np.bool)\n\n        \n            \n            # Create X_val\n            #================\n            \n            for i, image_id in enumerate(image_id_list):\n                \n\n                # set the path to the image\n                path = 'brain_image_dir\/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n                \n                # insert the image into X_train\n                X_val[i] = image\n            \n            \n            # Create Y_val\n            # ===============\n                \n            for j, mask_id in enumerate(mask_id_list):\n\n                # set the path to the mask\n                path = 'mask_dir\/' + mask_id\n\n                # read the mask\n                mask = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n                \n                # resize the mask\n                mask = cv2.resize(mask, (IMAGE_HEIGHT, IMAGE_WIDTH))\n                \n                # expand dims from (800,600) to (800,600,1)\n                mask = np.expand_dims(mask, axis=-1)\n                \n                \n                \n                \n                # insert the image into Y_train\n                Y_val[j] = mask\n                \n            \n            # Normalize the images\n            X_val = X_val\/255\n            \n            yield X_val, Y_val","a7326221":"# Test the generator\n\n# initialize\nval_gen = val_generator(batch_size=10)\n\n# run the generator\nX_val, Y_val = next(val_gen)\n\nprint(X_val.shape)\nprint(Y_val.shape)","eb6addb0":"# print the image from X_val\n\nimg = X_val[7,:,:,:]\nplt.imshow(img)","a72f81d1":"# print the mask from Y_val\n\nmsk = Y_val[7,:,:,0]\nplt.imshow(msk)","0a8a07ac":"# Combine the mask and the image\n\nplt.imshow(img, cmap='gray')\nplt.imshow(msk, cmap='Blues', alpha=0.7)","b556d701":"def test_generator(batch_size=1):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_test.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['new_image_fname'])\n            mask_id_list = list(df['new_mask_fname'])\n            \n            # Create empty X matrix - 3 channels\n            X_test = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n            # create empty Y matrix - 1 channel\n            Y_test = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, 1), dtype=np.bool)\n            \n\n\n            \n            # Create X_test\n            #================\n            \n            for i, image_id in enumerate(image_id_list):\n                \n\n                # set the path to the image\n                path = 'brain_image_dir\/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n           \n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n                \n                # insert the image into X_train\n                X_test[i] = image\n                \n             \n            # Create Y_test\n            # ===============\n                \n            for j, mask_id in enumerate(mask_id_list):\n\n                # set the path to the mask\n                path = 'mask_dir\/' + mask_id\n\n                # read the mask\n                mask = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n                \n                # resize the mask\n                mask = cv2.resize(mask, (IMAGE_HEIGHT, IMAGE_WIDTH))\n                \n                # expand dims from (800,600) to (800,600,1)\n                mask = np.expand_dims(mask, axis=-1)\n                \n                \n                \n                \n                # insert the image into Y_train\n                Y_test[j] = mask\n            \n            \n            # Normalize the images\n            X_test = X_test\/255\n            \n            yield X_test, Y_test\n","f3b9ac30":"# Test the generator\n\n# initialize\ntest_gen = test_generator(batch_size=15)\n\n# run the generator\nX_test, Y_test = next(test_gen)\n\nprint(X_test.shape)\nprint(Y_test.shape)","8e91b4d6":"# print the image from X_test\n\nimg = X_test[14,:,:,:]\nplt.imshow(img)","a5ad31b8":"# print the mask from Y_test\n\nmsk = Y_test[14,:,:,0]\nplt.imshow(msk)","b8278a9e":"# Combine the mask and the image\n\nplt.imshow(img, cmap='gray')\nplt.imshow(msk, cmap='Blues', alpha=0.7)","ed84a4b7":"from keras.models import Model, load_model\nfrom keras.layers import Input, UpSampling2D\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K\n\nfrom keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n                                        ModelCheckpoint, CSVLogger, LearningRateScheduler)\n\n\nfrom keras.optimizers import Adam\nfrom keras.losses import binary_crossentropy\n\nfrom keras.initializers import he_normal \n\nimport tensorflow as tf","d247eb4b":"\n\nfrom segmentation_models import Unet, FPN\nfrom segmentation_models import  get_preprocessing # this line has an error in the docs\n\nfrom segmentation_models.losses import bce_jaccard_loss\nfrom segmentation_models.metrics import iou_score\n\nfrom segmentation_models.losses import dice_loss\n#from segmentation_models.metrics import dice_score\n\nfrom segmentation_models.utils import set_trainable","a6a77466":"#preprocess = get_preprocessing('resnet101') # for resnet, img = (img-110.0)\/1.0\n\nBACKBONE = 'densenet121'\npreprocess_input = get_preprocessing(BACKBONE)\n\n# Note that the model takes 3-channel images as input\nmodel = Unet(BACKBONE, input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), \n             #freeze_encoder=False,\n             classes=1, \n             encoder_weights='imagenet',\n             activation='sigmoid')\n\n#model.summary()","568c747f":"# initialize\ntest_gen = test_generator(batch_size=len(df_test))\n\n# run the generator\nX_test, Y_test = next(test_gen)\n\nprint(X_test.shape)\nprint(Y_test.shape)","bf12cc93":"num_train_samples = len(df_train)\nnum_val_samples = len(df_val)\ntrain_batch_size = BATCH_SIZE\nval_batch_size = BATCH_SIZE\n\n# determine numtrain steps\ntrain_steps = np.ceil(num_train_samples \/ train_batch_size)\n# determine num val steps\nval_steps = np.ceil(num_val_samples \/ val_batch_size)","272f80d6":"# Initialize the generators\ntrain_gen = train_generator(batch_size=BATCH_SIZE)\nval_gen = val_generator(batch_size=BATCH_SIZE)\n\nmodel.compile(\n    Adam(lr=0.0001),\n    loss=dice_loss,\n    metrics=[iou_score],\n)\n\n\n\nfilepath = \"model.h5\"\n\nearlystopper = EarlyStopping(patience=5, verbose=1)\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, \n                                   verbose=1, mode='min')\n\n\n\nlog_fname = 'training_log.csv'\ncsv_logger = CSVLogger(filename=log_fname,\n                       separator=',',\n                       append=False)\n\ncallbacks_list = [checkpoint, earlystopper, csv_logger, reduce_lr]\n\nhistory = model.fit_generator(train_gen, steps_per_epoch=train_steps, epochs=40, \n                              validation_data=val_gen, validation_steps=val_steps,\n                             verbose=1,\n                             callbacks=callbacks_list)","5ad03dce":"# Make a prediction\n\n# initialize the test generator\ntest_gen = test_generator(batch_size=1)\n\nmodel.load_weights('model.h5')\npredictions = model.predict_generator(test_gen, \n                                      steps=len(df_test),  \n                                      verbose=1)","09c89541":"!ls","e336352f":"preds_test_thresh = (predictions >= 0.7).astype(np.uint8)\n\npreds_test_thresh.shape\n\nprint(preds_test_thresh.min())\nprint(preds_test_thresh.max())","11a7f32e":"# This is a predicted mask\n\nmask = preds_test_thresh[3,:,:,0]\nplt.imshow(mask, cmap='Reds', alpha=0.3)","4afb9431":"# This is a true mask\n\ntrue_mask = Y_test[3,:,:,0]\nplt.imshow(true_mask, cmap='Blues', alpha=0.3)","fad2e73a":"# This is the x-ray image\n\nimage = X_test[3,:,:,:]\n\nplt.imshow(image)","cf7152b5":"# This is an overlay of the pred mask, true mask and \n# the x-ray image.\n\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)","257e7946":"# set up the canvas for the subplots\nplt.figure(figsize=(20,20))\nplt.tight_layout()\nplt.axis('Off')\n\npredicted_masks = preds_test_thresh\n\n\n\n    \n# image\nplt.subplot(1,4,1)\nimage = X_test[1,:,:,:] \nmask = predicted_masks[1, :, :, 0]\ntrue_mask = Y_test[1, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,4,2)\nimage = X_test[2,:,:,:] \nmask = predicted_masks[2, :, :, 0]\ntrue_mask = Y_test[2, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,4,3)\nimage = X_test[3,:,:,:]\nmask = predicted_masks[3, :, :, 0]\ntrue_mask = Y_test[3, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,4,4)\nimage = X_test[4,:,:,:] \nmask = predicted_masks[4, :, :, 0]\ntrue_mask = Y_test[4, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n\n# ============ #\n\n\n# set up the canvas for the subplots\nplt.figure(figsize=(20,20))\nplt.tight_layout()\nplt.axis('Off')\n\n\n# image\nplt.subplot(1,4,1)\nimage = X_test[5,:,:,:] \nmask = predicted_masks[5, :, :, 0]\ntrue_mask = Y_test[5, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,4,2)\nimage = X_test[6,:,:,:] \nmask = predicted_masks[6, :, :, 0]\ntrue_mask = Y_test[6, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,4,3)\nimage = X_test[7,:,:,:] \nmask = predicted_masks[7, :, :, 0]\ntrue_mask = Y_test[7, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,4,4)\nimage = X_test[8,:,:,:] \nmask = predicted_masks[8, :, :, 0]\ntrue_mask = Y_test[8, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# ============ #\n\n\n# set up the canvas for the subplots\nplt.figure(figsize=(20,20))\nplt.tight_layout()\nplt.axis('Off')\n\n\n# image\nplt.subplot(1,4,1)\nimage = X_test[9,:,:,:] \nmask = predicted_masks[9, :, :, 0]\ntrue_mask = Y_test[9, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,4,2)\nimage = X_test[10,:,:,:] \nmask = predicted_masks[10, :, :, 0]\ntrue_mask = Y_test[10, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,4,3)\nimage = X_test[11,:,:,:] \nmask = predicted_masks[11, :, :, 0]\ntrue_mask = Y_test[11, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,4,4)\nimage = X_test[12,:,:,:] \nmask = predicted_masks[12, :, :, 0]\ntrue_mask = Y_test[12, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\nplt.show()","91d7e5ba":"# --ignore-installed is added to fix an error.\n\n# https:\/\/stackoverflow.com\/questions\/49932759\/pip-10-and-apt-how-to-avoid-cannot-uninstall\n# -x-errors-for-distutils-packages\n\n!pip install tensorflowjs --ignore-installed","b52aaaba":"# Use the command line conversion tool to convert the model\n\n!tensorflowjs_converter --input_format keras model.h5 tfjs\/model","ba29b890":"# check that the folder containing the tfjs model files has been created\n!ls","cee471d9":"# Delete the image data directorys we created to prevent a Kaggle error.\n# Kaggle allows a max of 500 files to be saved.\n\nif os.path.isdir('brain_image_dir') == True: # return true if the directory exists\n    \n    shutil.rmtree('brain_image_dir')\n    \n\nif os.path.isdir('bone_image_dir') == True: # return true if the directory exists\n    \n    shutil.rmtree('bone_image_dir')\n    \n\nif os.path.isdir('mask_dir') == True: # return true if the directory exists\n    \n    shutil.rmtree('mask_dir')","8e2a6a86":"# Segmentation only\n# Encoder: efficientnetb0 \n# Decoder: Unet\n\n\nBACKBONE = 'efficientnetb0'\npreprocess_input = get_preprocessing(BACKBONE)\n\n# Note that the model takes 3-channel images as input\nmodel = Unet(BACKBONE, input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), \n             #freeze_encoder=False,\n             classes=1, \n             encoder_weights='imagenet',\n             activation='sigmoid')\n\n#model.summary()","44017ff8":"# Segmentation and Binary Classification\n# Encoder: efficientnetb0 \n# Decoder: Unet\n\n\nfrom keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D)\n\n\nBACKBONE = 'efficientnetb0'\npreprocess_input = get_preprocessing(BACKBONE)\n\n# Note that the model takes 3-channel images as input\nmodel = Unet(BACKBONE, input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), \n             #freeze_encoder=False,\n             classes=1, \n             encoder_weights='imagenet',\n             activation='sigmoid')\n\n\n# classif path\nx = GlobalAveragePooling2D()(model.layers[266].output)\nx = Dropout(0.5)(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\nclassif_output = Dense(1, activation='sigmoid', name='classif_output')(x)\n\n\nmy_model = Model(inputs=[model.input], outputs=[model.output, classif_output])\n\n\n\n#my_model.summary()","08a48f59":"# Segmentation and Binary Classification\n# Encoder: densenet121 \n# Decoder: Unet\n\nfrom keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D)\n\nBACKBONE = 'densenet121'\npreprocess_input = get_preprocessing(BACKBONE)\n\n# Note that the model takes 3-channel images as input\nmodel = Unet(BACKBONE, input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), \n             #freeze_encoder=False,\n             classes=1, \n             encoder_weights='imagenet',\n             activation='sigmoid')\n\n\n# classif path\nx = GlobalAveragePooling2D()(model.layers[266].output) #layer 197 Resnet34, 266 for efficientnetb0\nx = Dropout(0.5)(x)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\nclassif_output = Dense(1, activation='sigmoid', name='classif_output')(x)\n\n\nmy_model = Model(inputs=[model.input], outputs=[model.output, classif_output])\n\n#my_model.summary()","891808c6":"## Set up data augmentation","8b85fe8f":"## Make a test set prediction","2820bb48":"## Please note...\n\nThe training results in this kernel are quite poor. Please use this notebook only as a guide that demonstrates the overall workflow. Strangely, I got much better results when I trained this model in Google Colab. The Colab model is the one that's used in the web app. The colab notebook can be found here:<br>\nhttps:\/\/github.com\/vbookshelf\/Intracranial-Hemorrhage-Analyzer\/blob\/master\/Colab_Notebook_Intracranial_Hemorrhage_Analyzer.ipynb\n","e1b0f763":"This is the link to the live app. The html, css, and javascript code is available on Github. I recommend using the latest version of the Chrome browser. To see the app in action simply submit a brain window CT image.\n\n> Web App<br>\n> http:\/\/brain.test.woza.work\/<br>\n> \n> Github<br>\n> https:\/\/github.com\/vbookshelf\/Intracranial-Hemorrhage-Analyzer\n","5f0c54cf":"## Create X_test\nHere we will use the test generator with a batch size of len(df_test) to create X_test and Y_test. Because the batch size is equal to the number of rows in df_test, the generator will ouput the entire\ntest set (100 rows) as a matrix.","d8b863f5":"## More Architectures to try...\n\nThese are three other architectures that I experimented with. They also produced good results in google colab. ","da80ba94":"## Convert the Model to Tensorflow.js","9913449f":"## Display Images and Masks","65df8483":"## Prepare the data","c37733d0":"### [ 1 ] Train Generator","083f19cc":"## Helpful Resources\n\n- CT Scan Basics<br>\nhttps:\/\/www.kaggle.com\/c\/rsna-intracranial-hemorrhage-detection\/discussion\/109335\n\n- Kaggle RSNA Intracranial Hemorrhage Detection Competition<br>\nhttps:\/\/www.kaggle.com\/c\/rsna-intracranial-hemorrhage-detection\/overview\n\n\n- segmentation_models package by Pavel Yakubovskiy <br>\nhttps:\/\/github.com\/qubvel\/segmentation_models\n\n- Write up on segmentation models package by Chris Deotte<br>\nhttps:\/\/www.kaggle.com\/c\/severstal-steel-defect-detection\/discussion\/103367\n\n\n- Albumentations paper:<br>\nAlbumentations: fast and flexible image augmentations<br>\nhttps:\/\/arxiv.org\/abs\/1809.06839\n\n- If you would like to learn how to build apps like this I recommend this video tutorial:<br>\nhttps:\/\/www.youtube.com\/watch?v=HEQDRWMK6yY\n\n\n- I've also included a few practical tips on the readme page in this repo:<br>\nhttps:\/\/github.com\/vbookshelf\/Skin-Lesion-Analyzer\n\n","0a704638":"<img src=\"http:\/\/brain.test.woza.work\/assets\/ichwebpage.png\" width=\"600\"><\/img>\n\n<h5 align=\"center\">Sample output from the web app<\/h5>","81d999fb":"## Train the Model","d00c589a":"### Display a ramdom sample of images from each dataset by target","aacada45":"## Overlay pred masks, true masks and the x-ray image\n\nRed - True Mask<br>\nBlue - Pred Mask","fb0f7d2d":"### Move all brain window images into the same folder","8cc48330":"The ouput from a generator does not accumulate in memory. Each output batch overwrites the last one. This means that we can feed large amounts of data into a model without running out of RAM and crashing the kernel. There's a 13GB RAM limit when using a GPU.\n\nWe will use Pandas chunking and the compressed csv files to feed data into the generators. Using chunking simplifies the code. For example, the last batch that is fed into a generator will be smaller than the others. Pandas chunking will handle this change in batch size automatically which means that we won't need to write code to handle this condition.\n\nChunking is very useful when the csv file data is too large to be loaded into memory i.e. into a single Pandas dataframe.\n\nIf you would like to understand how generators work please refer to this notebook:<br>\nhttps:\/\/www.kaggle.com\/vbookshelf\/python-generators-to-reduce-ram-usage-part-2\n","5919fd30":"### [ 3 ] Test Generator","6b40c1ce":"## Download Packages","fea37fdd":"## Data Summary\n\n- 82 patients in total\n- 36 patients with intracranial hemorrhage\n- 46 normal patients\n- Approx. 30 CT slices for each patient (e.g. 34 for patient 58)\n- 46 males\n- 36 females\n\n- 318 of 2500 images have masks that show intracranial hemorrhage\n\n- Images: 650x650x1\n- Masks: 650x650x1\n\n- Two kinds of windowed images are available - brain window and bone window\n\nIf you would like to know what windowing is, please refer to this link:<br>\nhttps:\/\/www.youtube.com\/watch?v=KZld-5W99cI","3deaad98":"## Create a holdout test set\n\nThis will be set aside and won't be used during training and validation. We will use it later to check how the trained model performs on unseen data.","0f9fe9cc":"These csv files will allow us to use Pandas chunking to feed images into the generators.","5521a288":"> ### Intracranial Hemorrhage Analyzer\nby Marsh [ @vbookshelf ]<br>\n28 December 2019","aa4a7ef6":"We will use the excellent segmentation_models package by Pavel Yakubovskiy <br>\nhttps:\/\/github.com\/qubvel\/segmentation_models\n\nMore info can be found here:<br>\nhttps:\/\/www.kaggle.com\/c\/severstal-steel-defect-detection\/discussion\/103367","42f67dd7":"In this test generator we will output both the test images (X_test) and the test masks (Y_test). ","1e6de4da":"## What is an intracranial hemorrhage?","cbd9437d":"Here we will be creating new image and mask file names to make the data easier to handle later. These new names will be added as new columns in df_diag.","45076197":"<iframe width=\"560\" height=\"315\" src=\"https:\/\/www.youtube.com\/embed\/05lgdEDpS5E?rel=0\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen><\/iframe>","d808c6ce":"### Threshold the predictions","6632e451":"The predictions are actually probabilities that a pixel is either part of a lung or part of the background. Here we threshold the predictions to convert all values to either 0 or 1.\n\nWe will use a threshold of 0.7. I got this number by trial and error - try a threshold value and look at the quality of the test set segmentations. ","4fdbdb8a":"## Build the Data Generators","a7cd8b71":"## Helper Functions","da829cc8":"## Citations\n\nHssayeni, M. (2019). Computed Tomography Images for Intracranial Hemorrhage Detection and Segmentation. PhysioNet. doi:10.13026\/w8q8-ky94\n\nGoldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh, Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals (2003). Circulation. 101(23):e215-e220.","b414a685":"## Introduction","5bce2a13":"> ### - Segmentation using efficientnet","295bd542":"## Model Architecture","634b1124":"My goal for this project was to build a prototype tensorflow.js web app and deploy it online. The app automatically detects and segments intracranial hemorrhages in brain CT scans. It takes as input a single jpg or png image (brain window) and outputs a segmentation showing the area where bleeding has been detected.","702e097d":"### [ 2 ] Val Generator","a817edac":"### Move all bone window images into the same folder","a22b5c2e":"## Train Test Split","94b87a1d":"### Move all masks into the same folder","e5b7240a":"## Save the dataframes as compressed csv files","13cf1b49":"### Creat new columns","a3289662":"> ### - Segmentation and Classification combined\n\nThese models output both an image segmentation and an image binary classification (classifies whether intracranial hemorrhage is present or not).","eb1e9240":"## Approach\n\n- We will only use the brain window images. We will convert these to 3 channel images to suit the model.\n- Resize images and masks to 256x256\n- Set aside 20 images as a holdout test set.\n- Split the remainder of the data into 85% train and 15% validation.\n- Use a Keras Densenet121 encoder with a Unet decoder - Adam optimizer and dice loss.\n- We won't use Densenet pre-procesing. Instead we will simply normalize the images by dividing by 255.\n- The dataset is quite small therefore, we will use data augmentation to reduce overfitting and to help the model generalize better.","7d6e7514":"## Conclusion\n\nIt would be interesting to know how well the app performs in the real world. If you are able to test it please share your experience in the comment section.\n\nThank you for reading."}}