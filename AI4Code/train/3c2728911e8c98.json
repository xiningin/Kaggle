{"cell_type":{"3fb1880d":"code","34614aed":"code","893cb4d1":"code","8f9f50ef":"code","0b454bea":"code","32384ef5":"code","81124171":"code","4df81c4a":"code","69b2838e":"code","fc8bb998":"code","b981a1d5":"code","c3c56e82":"code","7eb70b40":"code","16516a64":"code","be141196":"code","61c6683c":"code","9cf1b96b":"code","32301dff":"code","b6eae3b1":"code","8982f11a":"code","c1669bc6":"code","a6ec7a8f":"code","f5ec554c":"code","bddb6ac0":"code","131dbfcb":"code","4742eebd":"code","6518a266":"code","270c0bae":"code","0dc97fd2":"code","e3ebdb42":"code","21d8e90c":"code","fe902579":"code","8f257216":"code","ac45424d":"code","1a1bc005":"code","2ead13e0":"code","cc70da8f":"code","677b0adf":"code","b08a4628":"code","22d0ee84":"markdown","e6404d7e":"markdown","fc9d16f8":"markdown"},"source":{"3fb1880d":"from google.colab import drive\ndrive.mount(\"\/content\/drive\")","34614aed":"import numpy as np\nimport pandas as pd \nimport keras \n\nfrom keras.models import Sequential\n\nfrom keras.optimizers import RMSprop\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.layers import Dense, Activation, Dropout, Flatten\n\nfrom keras.preprocessing import image\n\nimport keras.optimizers\n\nfrom tensorflow.python.keras.optimizer_v2.adam import Adam\n\nimport os\nimport glob\n\nfrom skimage.io import imshow, imread, imsave\n\nfrom keras.preprocessing.image import ImageDataGenerator,array_to_img, img_to_array, load_img \n\nimport matplotlib.pyplot as plt\n\nimport cv2","893cb4d1":"p_train=pd.read_csv('\/content\/drive\/MyDrive\/Plant_Pathology_2020\/train.csv')\np_test=pd.read_csv('\/content\/drive\/MyDrive\/Plant_Pathology_2020\/test.csv')\n\ntarget = p_train[['healthy', 'multiple_diseases', 'rust', 'scab']]\ntest_ids = p_test['image_id']\n\nimg_size=224","8f9f50ef":"# Direkt g\u00f6r\u00fcnt\u00fcleri listeye aktarm\u0131\u015f oluyoruz\n\ntrain_image=[]\nfor name in p_train['image_id']:\n    path='\/content\/drive\/MyDrive\/Plant_Pathology_2020\/images\/'+name+'.jpg'\n    img=cv2.imread(path)\n    image=cv2.resize(img,(img_size,img_size),interpolation=cv2.INTER_AREA)\n    train_image.append(image)\n\nfig, ax = plt.subplots(1, 4, figsize=(15, 15))\nfor i in range(4):\n    ax[i].set_axis_off()\n    ax[i].imshow(train_image[i])\n    \n    \ntest_image=[]\nfor name in p_test['image_id']:\n    path='\/content\/drive\/MyDrive\/Plant_Pathology_2020\/test_images\/'+name+'.jpg'\n    img=cv2.imread(path)\n    image=cv2.resize(img,(img_size,img_size),interpolation=cv2.INTER_AREA)\n    test_image.append(image)\n\nfig, ax = plt.subplots(1, 4, figsize=(15, 15))\nfor i in range(4):\n    ax[i].set_axis_off()\n    ax[i].imshow(test_image[i])    \n\n","0b454bea":"print(train_image[0].shape)\nprint(type(train_image[0]))\n\na = np.array(train_image)\nprint(a.shape)","32384ef5":"#listeden arraye d\u00f6n\u00fc\u015ft\u00fcr\u00fcyoruz\n\n#x_train = np.ndarray(train_image) # bu \u015fekilde olmuyor\n#x_test = np.ndarray(test_image)\nx_train = np.ndarray(shape=(len(train_image), img_size, img_size, 3),dtype = np.float32)\ni=0\nfor image in train_image:\n    x_train[i]=img_to_array(image)\n    x_train[i]=train_image[i]\n    i=i+1\nx_train=x_train\/255 # scale\nprint('Train Shape: {}'.format(x_train.shape))","81124171":"x_train[0]","4df81c4a":"x_test = np.ndarray(shape=(len(test_image), img_size, img_size, 3),dtype = np.float32)\ni=0\nfor image in test_image:\n    x_test[i]=img_to_array(image)\n    x_test[i]=test_image[i]\n    i=i+1\n    \nx_test=x_test\/255 # scale\nprint('Test Shape: {}'.format(x_test.shape))","69b2838e":"x_test[0]","fc8bb998":"y = p_train.copy()\ndel y['image_id'] # image_id kolonunu sildik\ny.head()","b981a1d5":"y_train = np.array(y.values)\nprint(y_train.shape,y_train[0])\n","c3c56e82":"from sklearn.model_selection import train_test_split\n\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n\nx_train.shape, x_val.shape, y_train.shape, y_val.shape","7eb70b40":"from keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import EarlyStopping\n\nLR_reduce=ReduceLROnPlateau(monitor='val_accuracy',\n                            factor=.5,\n                            patience=10,\n                            min_lr=.000001,\n                            verbose=1)\n\nES_monitor=EarlyStopping(monitor='val_loss',\n                          patience=20)\n\n","16516a64":"\n#Evri\u015fimli Sinir A\u011f\u0131 Mimarisini Olu\u015fturma\nmodel2 = Sequential()\n\n#1. evri\u015fim katman\u0131\nmodel2.add(Conv2D(128, (5, 5), activation='LeakyReLU', input_shape=(224,224,3))) \nmodel2.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n\n\n#2. Evri\u015fim katman\u0131\nmodel2.add(Conv2D(256, (3, 3), activation='LeakyReLU')) \nmodel2.add(Conv2D(256, (3, 3), activation='LeakyReLU'))\n#model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\nmodel2.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n\n\n\n#3. Evri\u015fim katman\u0131\nmodel2.add(Conv2D(512, (3, 3), activation='LeakyReLU')) \nmodel2.add(Conv2D(512, (3, 3), activation='LeakyReLU'))\n#model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\nmodel2.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n\n\nmodel2.add(Flatten())\n\n# Tam ba\u011flant\u0131 katman\u0131\nmodel2.add(Dense(1024, activation='LeakyReLU'))\n#model2.add(Dropout(0.1))\nmodel2.add(Dense(1024, activation='LeakyReLU'))\n#model2.add(Dropout(0.1))\n\nmodel2.add(Dense(1, activation='softmax')) \n#------------------------------\nmodel2.summary()\n\n#------------------------------\nopt = keras.optimizers.Adam(learning_rate=0.3)\n\nmodel2.compile(optimizer='rmsprop', \n              loss='categorical_crossentropy',\n              metrics=['accuracy']\n)\n\n\n\n\n\n","be141196":"\"\"\"ImageDataGenerator, Keras'\u0131n derin \u00f6\u011frenme i\u00e7in g\u00f6r\u00fcnt\u00fc verilerinin ard\u0131\u015f\u0131k d\u00fczenlenmesi i\u00e7in ba\u015fvurdu\u011fu s\u0131n\u0131ft\u0131r. \nYerel dosya sisteminize kolay eri\u015fim ve farkl\u0131 yap\u0131lardan veri y\u00fcklemek i\u00e7in birden fazla farkl\u0131 y\u00f6ntem sa\u011flar. \nAyr\u0131ca olduk\u00e7a g\u00fc\u00e7l\u00fc veri \u00f6n i\u015fleme ve art\u0131rma yeteneklerine sahiptir\"\"\"\n\ndatagen = ImageDataGenerator(rotation_range=45,\n                             shear_range=0.25,\n                              zoom_range=0.25,\n                              width_shift_range=0.25,\n                              height_shift_range=0.25,\n                              rescale=1\/255,\n                              brightness_range=[0.5,1.5],\n                              horizontal_flip=True,\n                              vertical_flip=True,\n                              fill_mode='nearest'\n#                              featurewise_center=True,\n#                              samplewise_center=True,\n#                              featurewise_std_normalization=True,\n#                              samplewise_std_normalization=True,\n#                              zca_whitening=True\n                              )\n","61c6683c":"from keras.callbacks import ModelCheckpoint\n\nroot = '\/content\/drive\/MyDrive\/Plant_Pathology_2020\/'\n# en ba\u015far\u0131l\u0131 a\u011f\u0131rl\u0131klar\u0131 kaydet\ncheckpointer = ModelCheckpoint(filepath=root + 'data\/face_model.h5', verbose=1, save_best_only=True)\n","9cf1b96b":"\nhistory = model2.fit_generator(datagen.flow(x_train, y_train, batch_size=24), # train verileri i\u00e7in veri art\u0131rma\n                              epochs=300,\n                              steps_per_epoch=x_train.shape[0] \/\/ 24,\n                              verbose=1,\n                              callbacks=[ES_monitor,LR_reduce],\n                              validation_data=datagen.flow(x_val, y_val,batch_size=24), # validation verileri i\u00e7in veri art\u0131rma\n                              validation_steps=x_val.shape[0]\/\/24\n                              )\n\n","32301dff":"x_train[0]","b6eae3b1":"x_test[0]","8982f11a":"# save model to json\nmodel_json = model2.to_json()\nwith open(root + \"data\/face_model.json\", \"w\") as json_file:\n    json_file.write(model_json)","c1669bc6":"from matplotlib import pyplot as plt\n\nh = history.history\n\noffset = 5\nepochs = range(offset, len(h['loss']))\n\nplt.figure(1, figsize=(20, 6))\n\nplt.subplot(121)\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.plot(epochs, h['loss'][offset:], label='train')\nplt.plot(epochs, h['val_loss'][offset:], label='val')\nplt.legend()\n\nplt.subplot(122)\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.plot(h[f'accuracy'], label='train')\nplt.plot(h[f'val_accuracy'], label='val')\nplt.legend()\n\nplt.show()\n\nfrom sklearn.metrics import roc_auc_score\n\npred_test = model2.predict(x_val)\nroc_sum = 0\nfor i in range(4):\n    score = roc_auc_score(y_val[:, i], pred_test[:, i])\n    roc_sum += score\n    print(f'{score:.3f}')\n\nroc_sum \/= 4\nprint(f'totally:{roc_sum:.3f}')","a6ec7a8f":"pred = model2.predict(x_test)\n\nres = pd.DataFrame()\nres['image_id'] = test_ids\nres['healthy'] = pred[:, 0]\nres['multiple_diseases'] = pred[:, 1]\nres['rust'] = pred[:, 2]\nres['scab'] = pred[:, 3]\nres.to_csv('Mysubmission.csv', index=False)\nres.head(10)","f5ec554c":"# en iyi a\u011f\u0131rl\u0131klar\u0131 y\u00fckle\nmodel2.load_weights(root + 'data\/face_model.h5')","bddb6ac0":"from keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import EarlyStopping\n\nLR_reduce=ReduceLROnPlateau(monitor='val_accuracy',\n                            factor=.5,\n                            patience=10,\n                            min_lr=.000001,\n                            verbose=1)\n\nES_monitor=EarlyStopping(monitor='val_loss',\n                          patience=20)\n","131dbfcb":"\n#------------------------------\n#Evri\u015fimli Sinir A\u011f\u0131 Mimarisini Olu\u015fturma\nmodel3 = Sequential()\n\n#1. evri\u015fim katman\u0131\nmodel3.add(Conv2D(128, (5, 5), activation='ReLU', input_shape=(224,224,3))) \nmodel3.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n#64den 128 \n\n#2. Evri\u015fim katman\u0131\nmodel3.add(Conv2D(256, (3, 3), activation='ReLU')) #128 den 256\nmodel3.add(Conv2D(256, (3, 3), activation='ReLU'))\n#model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\nmodel3.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n\n\n\n#3. Evri\u015fim katman\u0131\nmodel3.add(Conv2D(512, (3, 3), activation='ReLU')) #256 dan 512\nmodel3.add(Conv2D(512, (3, 3), activation='ReLU'))\n#model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\nmodel3.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n\n\nmodel3.add(Flatten())\n\n# Tam ba\u011flant\u0131 katman\u0131\nmodel3.add(Dense(1024, activation='ReLU'))\nmodel3.add(Dropout(0.25))\nmodel3.add(Dense(1024, activation='ReLU'))\nmodel3.add(Dropout(0.25))\n\nmodel3.add(Dense(1, activation='softmax')) #model.add(Dense(num_classes, activation='softmax'))\n#------------------------------\nmodel3.summary()\n\n#------------------------------\n#opt = keras.optimizers.Adam(learning_rate=0.3)\n#adam = Adam() #tf.keras.optimizers.Adam(learning_rate=0.1)\nmodel3.compile(optimizer='rmsprop', \n              loss='categorical_crossentropy',\n              metrics=['accuracy']\n)\n\n#------------------------------\n\n\n\n","4742eebd":"\"\"\"ImageDataGenerator, Keras'\u0131n derin \u00f6\u011frenme i\u00e7in g\u00f6r\u00fcnt\u00fc verilerinin ard\u0131\u015f\u0131k d\u00fczenlenmesi i\u00e7in ba\u015fvurdu\u011fu s\u0131n\u0131ft\u0131r. \nYerel dosya sisteminize kolay eri\u015fim ve farkl\u0131 yap\u0131lardan veri y\u00fcklemek i\u00e7in birden fazla farkl\u0131 y\u00f6ntem sa\u011flar. \nAyr\u0131ca olduk\u00e7a g\u00fc\u00e7l\u00fc veri \u00f6n i\u015fleme ve art\u0131rma yeteneklerine sahiptir\"\"\"\n\ndatagen = ImageDataGenerator(rotation_range=45,\n                             shear_range=0.25,\n                              zoom_range=0.25,\n                              width_shift_range=0.25,\n                              height_shift_range=0.25,\n                              rescale=1\/255,\n                              brightness_range=[0.5,1.5],\n                              horizontal_flip=True,\n                              vertical_flip=True,\n                              fill_mode='nearest'\n#                              featurewise_center=True,\n#                              samplewise_center=True,\n#                              featurewise_std_normalization=True,\n#                              samplewise_std_normalization=True,\n#                              zca_whitening=True\n                              )\n","6518a266":"from keras.callbacks import ModelCheckpoint\n\nroot = '\/content\/drive\/MyDrive\/Plant_Pathology_2020\/'\n# en ba\u015far\u0131l\u0131 a\u011f\u0131rl\u0131klar\u0131 kaydet\ncheckpointer = ModelCheckpoint(filepath=root + 'plant_model.h5', verbose=1, save_best_only=True)\n\n\n\nhistory = model3.fit_generator(datagen.flow(x_train, y_train, batch_size=24), # train verileri i\u00e7in veri art\u0131rma\n                              epochs=300,\n                              steps_per_epoch=x_train.shape[0] \/\/ 24,\n                              verbose=1,\n                              callbacks=[ES_monitor,LR_reduce],\n                              validation_data=datagen.flow(x_val, y_val,batch_size=24), # validation verileri i\u00e7in veri art\u0131rma\n                              validation_steps=x_val.shape[0]\/\/24\n                              )\n\n# save model to json\nmodel_json = model3.to_json()\nwith open(root + \"plant_model.json\", \"w\") as json_file:\n    json_file.write(model_json)","270c0bae":"x_train[0]","0dc97fd2":"x_test[0]","e3ebdb42":"from matplotlib import pyplot as plt\n\nh = history.history\n\noffset = 5\nepochs = range(offset, len(h['loss']))\n\nplt.figure(1, figsize=(20, 6))\n\nplt.subplot(121)\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.plot(epochs, h['loss'][offset:], label='train')\nplt.plot(epochs, h['val_loss'][offset:], label='val')\nplt.legend()\n\nplt.subplot(122)\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.plot(h[f'accuracy'], label='train')\nplt.plot(h[f'val_accuracy'], label='val')\nplt.legend()\n\nplt.show()\n\nfrom sklearn.metrics import roc_auc_score\n\nprint(\"ROC-AUC SCORE\")\npred_test = model3.predict(x_val)\nroc_sum = 0\nfor i in range(4):\n    score = roc_auc_score(y_val[:, i], pred_test[:, i])\n    roc_sum += score\n    print(f'{score:.3f}')\n\nroc_sum \/= 4\nprint(f'totally:{roc_sum:.3f}')","21d8e90c":"pred = model3.predict(x_test)\n\nres = pd.DataFrame()\nres['image_id'] = test_ids\nres['healthy'] = pred[:, 0]\nres['multiple_diseases'] = pred[:, 1]\nres['rust'] = pred[:, 2]\nres['scab'] = pred[:, 3]\nres.to_csv('Mysubmission2.csv', index=False)\nres.head(10)","fe902579":"from keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import EarlyStopping\n\nLR_reduce=ReduceLROnPlateau(monitor='val_accuracy',\n                            factor=.5,\n                            patience=10,\n                            min_lr=.000001,\n                            verbose=1)\n\nES_monitor=EarlyStopping(monitor='val_loss',\n                          patience=20)\n\n#reg = .0005","8f257216":"\n#------------------------------\n#Evri\u015fimli Sinir A\u011f\u0131 Mimarisini Olu\u015fturma\nmodel2_2 = Sequential()\n\n#1. evri\u015fim katman\u0131\nmodel2_2.add(Conv2D(128, (5, 5), activation='LeakyReLU', input_shape=(224,224,3))) \nmodel2_2.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n#64den 128 \n\n#2. Evri\u015fim katman\u0131\nmodel2_2.add(Conv2D(256, (3, 3), activation='LeakyReLU')) #128 den 256\nmodel2_2.add(Conv2D(256, (3, 3), activation='LeakyReLU'))\n#model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\nmodel2_2.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n\n\n\n#3. Evri\u015fim katman\u0131\nmodel2_2.add(Conv2D(512, (3, 3), activation='LeakyReLU')) #256 dan 512\nmodel2_2.add(Conv2D(512, (3, 3), activation='LeakyReLU'))\n#model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\nmodel2_2.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))\n\n\nmodel2_2.add(Flatten())\n\n# Tam ba\u011flant\u0131 katman\u0131\nmodel2_2.add(Dense(1024, activation='LeakyReLU'))\n#model2.add(Dropout(0.1))\nmodel2_2.add(Dense(1024, activation='LeakyReLU'))\n#model2.add(Dropout(0.1))\n\nmodel2_2.add(Dense(1, activation='softmax'))\n#------------------------------\nmodel2_2.summary()\n\n#------------------------------\n\nmodel2_2.compile(optimizer='rmsprop', \n              loss='categorical_crossentropy',\n              metrics=['accuracy']\n)\n\n#------------------------------\n\n\n\n","ac45424d":"\"\"\"ImageDataGenerator, Keras'\u0131n derin \u00f6\u011frenme i\u00e7in g\u00f6r\u00fcnt\u00fc verilerinin ard\u0131\u015f\u0131k d\u00fczenlenmesi i\u00e7in ba\u015fvurdu\u011fu s\u0131n\u0131ft\u0131r. \nYerel dosya sisteminize kolay eri\u015fim ve farkl\u0131 yap\u0131lardan veri y\u00fcklemek i\u00e7in birden fazla farkl\u0131 y\u00f6ntem sa\u011flar. \nAyr\u0131ca olduk\u00e7a g\u00fc\u00e7l\u00fc veri \u00f6n i\u015fleme ve art\u0131rma yeteneklerine sahiptir\"\"\"\n\ndatagen = ImageDataGenerator(rotation_range=45,\n                             shear_range=0.25,\n                              zoom_range=0.25,\n                              width_shift_range=0.25,\n                              height_shift_range=0.25,\n                              rescale=1\/255,\n                              brightness_range=[0.5,1.5],\n                              horizontal_flip=True,\n                              vertical_flip=True,\n                              fill_mode='nearest'\n#                              featurewise_center=True,\n#                              samplewise_center=True,\n#                              featurewise_std_normalization=True,\n#                              samplewise_std_normalization=True,\n#                              zca_whitening=True\n                              )\n","1a1bc005":"from keras.callbacks import ModelCheckpoint\n\nroot = '\/content\/drive\/MyDrive\/Plant_Pathology_2020\/'\n# en ba\u015far\u0131l\u0131 a\u011f\u0131rl\u0131klar\u0131 kaydet\ncheckpointer = ModelCheckpoint(filepath=root + 'data\/plant_model2.h5', verbose=1, save_best_only=True)\n\n\n\nhistory = model2_2.fit_generator(datagen.flow(x_train, y_train, batch_size=24), # train verileri i\u00e7in veri art\u0131rma\n                              epochs=300,\n                              steps_per_epoch=x_train.shape[0] \/\/ 24,\n                              verbose=1,\n                              callbacks=[ES_monitor,LR_reduce],\n                              validation_data=datagen.flow(x_val, y_val,batch_size=24), # validation verileri i\u00e7in veri art\u0131rma\n                              validation_steps=x_val.shape[0]\/\/24\n                              )\n\n# save model to json\nmodel_json = model2_2.to_json()\nwith open(root + \"data\/plant_model2.json\", \"w\") as json_file:\n    json_file.write(model_json)","2ead13e0":"x_train[0]","cc70da8f":"x_test[0]","677b0adf":"from matplotlib import pyplot as plt\n\nh = history.history\n\noffset = 5\nepochs = range(offset, len(h['loss']))\n\nplt.figure(1, figsize=(20, 6))\n\nplt.subplot(121)\nplt.xlabel('epochs')\nplt.ylabel('loss')\nplt.plot(epochs, h['loss'][offset:], label='train')\nplt.plot(epochs, h['val_loss'][offset:], label='val')\nplt.legend()\n\nplt.subplot(122)\nplt.xlabel('epochs')\nplt.ylabel('accuracy')\nplt.plot(h[f'accuracy'], label='train')\nplt.plot(h[f'val_accuracy'], label='val')\nplt.legend()\n\nplt.show()\n\nfrom sklearn.metrics import roc_auc_score\n\npred_test = model2_2.predict(x_val)\nroc_sum = 0\nfor i in range(4):\n    score = roc_auc_score(y_val[:, i], pred_test[:, i])\n    roc_sum += score\n    print(f'{score:.3f}')\n\nroc_sum \/= 4\nprint(f'totally:{roc_sum:.3f}')","b08a4628":"pred = model2_2.predict(x_test)\n\nres = pd.DataFrame()\nres['image_id'] = test_ids\nres['healthy'] = pred[:, 0]\nres['multiple_diseases'] = pred[:, 1]\nres['rust'] = pred[:, 2]\nres['scab'] = pred[:, 3]\nres.to_csv('Mysubmission3.csv', index=False)\nres.head(10)","22d0ee84":"# Model 1","e6404d7e":"# MODEL 2","fc9d16f8":"# MODEL 1 TEKRAR"}}