{"cell_type":{"743fe6d4":"code","2d8af1bd":"code","e5ef3b7f":"code","ea722097":"code","135e4fc2":"code","1487b393":"code","5eecbecd":"code","501f048d":"code","807c326e":"code","2ac9ce58":"code","e6df2400":"code","8314bfc0":"code","a7fe5078":"code","326e9c28":"code","2441e995":"code","7972f4f2":"code","67fd7a66":"code","14ac70f7":"code","ebdb1032":"code","6007cfd0":"code","60e36316":"code","2c992edb":"code","5d24550f":"code","a117388a":"markdown","662e27ea":"markdown","8d7229b0":"markdown","20cf0e91":"markdown","67655fd1":"markdown","a73eb360":"markdown","b5ba44fb":"markdown","ea5e2a85":"markdown","8c5da3a5":"markdown","c1b72c27":"markdown","d3cc1e53":"markdown","0d144e16":"markdown","66fc888e":"markdown","1d591fc9":"markdown","b1ac4e1b":"markdown","d67850cc":"markdown"},"source":{"743fe6d4":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","2d8af1bd":"!pip install pandas_flavor","e5ef3b7f":"from pandas_flavor import register_dataframe_method,register_series_method\nfrom IPython.core.display import display, HTML\n\n@register_dataframe_method\ndef get_missing(df):        \n    tmp =  sorted(\n                [(col , str(df[col].dtypes) ,df[col].isna().sum(), np.round( df[col].isna().sum() \/ len(df) * 100,2) ) for col in df.columns if df[col].isna().sum() !=0 ],\n                key = lambda x: x[2], reverse=True)\n    \n    return pd.DataFrame(tmp).rename({0:\"Feature\", 1:\"dtype\", 2:\"count\", 3:\"percent\"},axis=1)  \n\n@register_dataframe_method\ndef get_numeric_df(df):\n    return df.select_dtypes(np.number)\n\n@register_dataframe_method\ndef get_numeric_cols(df):\n    return list(df.select_dtypes(np.number).columns)\n\n@register_dataframe_method\ndef get_object_cols(df):\n    return list(df.select_dtypes(exclude = np.number).columns)\n\n@register_dataframe_method\ndef get_object_df(df):\n    return df.select_dtypes(exclude = np.number)\n\n@register_dataframe_method\ndef get_discrete_cols(df,thresold):\n#     thresold in number of unique values\n    return [feature for feature in df.columns if len(df[feature].unique()) < thresold]\n\n@register_dataframe_method\ndef get_discrete_df(df,thresold):\n#     thresold in number of unique values\n    return df[ get_discrete_cols(df=df,thresold=thresold) ]\n\n@register_dataframe_method\ndef describe_discrete_cols(df,thresold, ascending=True):\n    \n    values = pd.DataFrame()\n    \n    for col in df.get_discrete_cols(thresold=thresold):\n        values[col] = [df[col].unique(), df[col].nunique()]\n        \n    return values.transpose().sort_values(by = 1,ascending=ascending).rename({0:\"Values\",1:\"cardinality\"},axis=1)\n\n@register_dataframe_method\ndef get_continuous_cols(df,thresold):\n    #     thresold in number of unique values\n    return [feature for feature in df.columns if len(df[feature].unique()) >= thresold]\n\n@register_dataframe_method\ndef get_continuous_df(df,thresold):\n    #     thresold in number of unique values\n    return df[ get_continuous_cols(df=df,thresold=thresold) ]\n\n\n@register_dataframe_method\ndef describe_continuous_cols(df,thresold, ascending=True):\n    return df[df.get_continuous_cols(thresold=thresold)].describe().T\n\n@register_dataframe_method\ndef dtypes_of_cols(df):\n    return pd.DataFrame(df.dtypes).reset_index().rename(columns={'index':\"Columns\",0: \"dtype\"})\n\n\n@register_series_method\ndef IQR_range(df):\n    if isinstance(df, pd.Series):\n        Q3 = np.quantile(df, 0.75)\n        Q1 = np.quantile(df, 0.25)\n        IQR = Q3 - Q1\n\n        lower_range = Q1 - 1.5 * IQR\n        upper_range = Q3 + 1.5 * IQR\n\n        return (lower_range,upper_range)\n    else:\n        assert False, \"df must be of type pandas.Series\"\n        \n@register_dataframe_method\ndef IQR_range(df):\n    if isinstance(df, pd.DataFrame):\n        cols = df.get_numeric_cols()\n        features = {}\n        for i in cols:\n            Q3 = np.quantile(df[i], 0.75)\n            Q1 = np.quantile(df[i], 0.25)\n            IQR = Q3 - Q1\n\n            lower_range = Q1 - 1.5 * IQR\n            upper_range = Q3 + 1.5 * IQR\n\n\n            features[i] = (lower_range,upper_range)\n            \n        return pd.DataFrame.from_dict(features,orient='index').rename({0: 'IQR_Low',1: 'IQR_High'}, axis=1)\n    else:\n        assert False, \"df must be of type pandas.DataFrame\"\n        \n@register_series_method\ndef IQR_percent(df):\n    if isinstance(df, pd.Series):\n        \n        lower_range, upper_range = df.IQR_range()\n\n        length = len(df)\n        return np.round((length - df.between(lower_range,upper_range).sum())\/length * 100, 2)\n    else:\n        assert False, \"df must be of type pandas.Series\"\n\n@register_dataframe_method\ndef IQR_percent(df):\n    if isinstance(df, pd.DataFrame):\n        cols = df.get_numeric_cols()\n        features = {}\n        for i in cols:\n            lower_range, upper_range = df[i].IQR_range()\n#             length - Number of NON outliers\n            length = len(df[i])\n            outlier_count = length - df[i].between(lower_range,upper_range).sum()\n            \n            percent = np.round( outlier_count \/length * 100, 2)\n            if outlier_count != 0:\n                features[i] = [percent, outlier_count]\n#             features[i] = IQR_percent(df[i])\n            \n        return pd.DataFrame.from_dict(features,orient='index').rename({0: 'Outlier percent', 1:\"Count\"}, axis=1)\n    else:\n        assert False, \"df must be of type pandas.DataFrame\"\n\n@register_dataframe_method\ndef get_outlier_cols(df):\n    return df.IQR_percent().reset_index()[\"index\"].to_list()\n        \n@register_dataframe_method\ndef drop_row_outlier(df, cols, inplace=False):\n#     init empty index\n    indices = pd.Series(np.zeros(len(df), dtype=bool), index=df.index)\n\n    for col in cols:\n        low, top = df[col].IQR_range()\n        indices |= (df[col] > top) | (df[col] < low)\n        \n    \n    return df.drop(df[ indices ].index, inplace=inplace)\n\n@register_series_method\ndef drop_row_outlier(df, inplace=False):\n#     init empty index\n\n    low, top = df.IQR_range()\n    indices = (df > top) | (df < low)\n        \n    \n    return df.drop(df[ indices ].index, inplace=inplace)\n        \n@register_dataframe_method\ndef compare_cols(df,l_feat,r_feat, percent=False, percent_of_total=False):\n    \n#     [L_feat] {R_feat1: agg1, R_feat2: agg2}\n\n    \n    if percent or percent_of_total:\n        \n        comp = []\n        for key, val in zip(r_feat,r_feat.values()):\n            tmp = pd.DataFrame()\n            tmp[key + \" \" + val] =  df.groupby(l_feat,sort=True).agg({key: val})\n            \n            if percent: tmp[key +\" %\"] = tmp.groupby(level=0).apply(lambda x: np.round(100 * x \/ float(x.sum()),2))\n\n            if percent_of_total: tmp[key+\" % of total\"] = np.round(tmp[key + \" \" + val] \/ tmp[key + \" \" + val].sum() * 100 , 2)\n            \n            comp.append(tmp)\n            \n        return comp\n    \n    else:\n        comp = []\n        for key, val in zip(r_feat,r_feat.values()):\n            tmp = pd.DataFrame()\n            tmp[key + \" \" + val] =  df.groupby(l_feat,sort=True).agg({key: val})           \n            comp.append(tmp)\n            \n        return comp  \n    \n    \n\n@register_dataframe_method\ndef count_dtypes(df, ascending=False):\n    return pd.DataFrame(df.dtypes.value_counts(ascending=ascending)).rename({0:\"Count\"},axis=1)\n\n@register_dataframe_method\ndef about(df):\n\n    display(HTML('<h1 style=\"color:green\"> <b> Shape of data <\/b> <\/h1>'))\n    print(df.shape)    \n\n    display(HTML('<h1 style=\"color:green\"> <b> Datatypes in data <\/b> <\/h1> '))\n    display(pd.DataFrame(df.dtypes.value_counts(ascending=False) ).rename({0:\"count\"},axis=1))\n\n    display(HTML('<h1 style=\"color:green\"> <b> dtypes of columns <\/b> <\/h1> '))\n    display(df.dtypes_of_cols())\n\n    display(HTML('<h1 style=\"color:green\"> <b> Percentage of missing values <\/b> <\/h1> '))\n    tmp = get_missing(df)\n    display(tmp) if len(tmp) != 0 else display(HTML(\"<h2> <b> None <b> <\/h2>\"))\n\n    display(HTML('<h1 style=\"color:green\"> <b> Data description <\/b> <\/h1> '))\n    display(df.describe().T)\n    \n    display(HTML('<h1 style=\"color:green\"> <b> Outlier Percentage(IQR) <\/b> <\/h1> '))\n    tmp = df.IQR_percent()\n    display(tmp) if len(tmp) != 0 else display(HTML(\"<h2> <b> None <b> <\/h2>\"))\n\n    display(HTML('<h1 style=\"color:green\"> <b> Example of data <\/b> <\/h1> '))\n    display(df.head())\n    \n    \nimport itertools\ndef display_multiple_tables(table_list):\n    table_list = list(itertools.chain(*table_list) )\n    return HTML(\n        '<table><tr style=\"background-color:white;\">' + \n        ''.join(['<td>' + table._repr_html_() + '<\/td>' for table in table_list]) +\n        '<\/tr><\/table>')","ea722097":"import matplotlib as mpl\n\nsns.set(style=\"darkgrid\",font_scale=1.1)\n# plt.rcParams['figure.dpi']=200\n\nmpl.rcParams['figure.dpi'] = 200\nmpl.rcParams['axes.spines.top'] = False\nmpl.rcParams['axes.spines.right'] = False\nmpl.rcParams['font.family'] = 'sans-serif'\nmpl.rcParams['font.sans-serif'] = [\"SF UI Display\",\"Inter\", \"Helvetica\"]\nmpl.rcParams['font.weight'] = 500\nmpl.rcParams['axes.titleweight'] = 800\nmpl.rcParams['axes.labelsize'] = \"large\"\nmpl.rcParams['axes.titlesize'] = \"x-large\"\nmpl.rcParams['xtick.labelsize'] = \"medium\"\nmpl.rcParams['ytick.labelsize'] = \"medium\"\n\n# mpl.rcParams['patch.antialiased'] = True \n# mpl.rcParams['patch.linewidth'] = 1.5\n# sns.set_context(rc = {'patch.linewidth': 5.0})\n\n# \u2018xx-small\u2019, \u2018x-small\u2019, \u2018small\u2019, \u2018medium\u2019, \u2018large\u2019, \u2018x-large\u2019, \u2018xx-large\u2019.\n\n\n\nfrom matplotlib.ticker import MaxNLocator\n\ndef srt_reg(y, df,x_size=20,y_size=20,*args,**kwargs):\n    \n    ncols = 3\n    nrows = int(np.ceil(df.shape[1]\/ncols))\n    \n    fig, axes = plt.subplots(nrows, ncols, figsize=(x_size,y_size))\n    axes = axes.flatten()\n\n    for i, j in zip(df.columns, axes):\n\n        sns.regplot(x=i,\n                    y=y,\n                    data=df,\n                    ax=j,\n                    order=3,\n                    ci=None,\n                    color='#e74c3c',\n                    line_kws={'color': 'black'},\n                    scatter_kws={'alpha':0.4},\n                   *args,**kwargs)\n        j.tick_params(labelrotation=45)\n        j.yaxis.set_major_locator(MaxNLocator(nbins=10))\n\n        plt.tight_layout()\n\ndef srt_box(y, df,*args,**kwargs):\n    fig, axes = plt.subplots(19, 3, figsize=(30,30))\n    axes = axes.flatten()\n\n    for i, j in zip(df.columns, axes):\n\n        sortd = df.groupby([i])[y].median().sort_values(ascending=False)\n        sns.boxplot(x=i,\n                    y=y,\n                    data=df,\n                    palette='plasma',\n                    order=sortd.index,\n                    ax=j,\n                    *args,**kwargs)\n        j.tick_params(labelrotation=45)\n        j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n        plt.tight_layout()\n\n\n        \ndef histplt(df,ncols = 3, x_size=30,y_size=30,*args,**kwargs):\n    \n    if len(df.shape) == 1:\n        fig, ax = plt.subplots(figsize=(x_size,y_size))\n        sns.histplot(x=df,ax=ax,*args,**kwargs)\n#         [ ax.bar_label(tmp) for tmp in ax.containers]\n        \n        ax.tick_params(labelrotation=45)\n#         plt.tight_layout()\n        \n    else:\n    \n#         ncols = 3\n        nrows = int(np.ceil(df.shape[1]\/ncols))\n\n        fig, axes = plt.subplots(nrows, ncols, \n                                 figsize=(x_size,y_size)\n                                )\n        axes = axes.flatten()\n\n        for i, j in zip(df.columns, axes):\n\n            sns.histplot(data=df, x=i,ax=j,*args,**kwargs)\n            j.tick_params(labelrotation=45)\n#             [ j.bar_label(tmp) for tmp in j.containers]\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n        \n\ndef countplt(df,ncols = 3, x_size=30,y_size=30,*args,**kwargs):\n    \n    if len(df.shape) == 1:\n        fig, ax = plt.subplots(figsize=(x_size,y_size))\n        sns.countplot(x=df,ax=ax,*args,**kwargs)\n        [ ax.bar_label(tmp) for tmp in ax.containers]\n        \n        ax.tick_params(labelrotation=45)\n#         plt.tight_layout()\n        \n    else:\n    \n#         ncols = 3\n        nrows = int(np.ceil(df.shape[1]\/ncols))\n\n        fig, axes = plt.subplots(nrows, ncols, \n                                 figsize=(x_size,y_size)\n                                )\n        axes = axes.flatten()\n\n        for i, j in zip(df.columns, axes):\n\n            sns.countplot(data=df, x=i,ax=j,*args,**kwargs)\n            j.tick_params(labelrotation=45)\n            [ j.bar_label(tmp) for tmp in j.containers]\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n\n\n    \n    \ndef barplt(df,y,x_size=30,y_size=30,*args,**kwargs):\n    ncols = 3\n    nrows = int(np.ceil(df.shape[1]\/ncols))\n    \n    fig, axes = plt.subplots(nrows, ncols, \n                             figsize=(x_size,y_size)\n                            )\n    axes = axes.flatten()\n\n    for i, j in zip(df.columns, axes):\n        \n        if i == y:\n            continue\n\n        sns.barplot(data=df,\n                    x=i,\n                    y=y,\n                    ax=j,*args,**kwargs)\n\n        j.tick_params(labelrotation=45)\n        [ j.bar_label(tmp) for tmp in j.containers]\n#         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n        plt.tight_layout()\n    \n    \ndef violinplt(df,y,ncols=3,x_size=30,y_size=30,x_scale = \"linear\", y_scale = \"linear\", *args,**kwargs):\n    \n    \n    nrows = int(np.ceil(df.shape[1]\/ncols))\n    \n    fig, axes = plt.subplots(nrows, ncols, \n                             figsize=(x_size,y_size)\n                            )\n    axes = axes.flatten()\n    \n    if df[y].dtype == 'O':\n\n        for i, j in zip(df.columns, axes):\n\n            if i == y:\n                continue\n\n            sns.violinplot(data=df,\n                        x=y,\n                        y=i,\n                        ax=j,*args,**kwargs)\n            \n            lower_range, upper_range = df[i].IQR_range()\n            outliers = df[(df[i] > upper_range) | (df[i] < lower_range)][i]\n            sns.scatterplot(y=outliers, x=0, marker='D', color='crimson', ax=j)\n            j.tick_params(labelrotation=45)\n\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n        \n        \n    else:\n\n        for i, j in zip(df.columns, axes):\n\n            if i == y:\n                continue\n\n            g = sns.violinplot(data=df,\n                        x=i,\n                        y=y,\n                        ax=j,*args,**kwargs)\n            g.set_xscale(x_scale)\n            g.set_yscale(y_scale)\n            j.tick_params(labelrotation=45)\n\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n        \ndef boxplt(df,y,x_size=30,y_size=30,*args,**kwargs):\n\n    ncols = 3\n    nrows = int(np.ceil(df.shape[1]\/ncols))\n    \n    fig, axes = plt.subplots(nrows, ncols, \n                             figsize=(x_size,y_size)\n                            )\n    axes = axes.flatten()\n    \n    if df[y].dtype == 'O':\n\n        for i, j in zip(df.columns, axes):\n\n            if i == y:\n                continue\n\n            sns.boxplot(data=df,\n                        x=y,\n                        y=i,\n                        ax=j,*args,**kwargs)\n\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n        \n        \n    else:\n\n        for i, j in zip(df.columns, axes):\n\n            if i == y:\n                continue\n\n            sns.boxplot(data=df,\n                        x=i,\n                        y=y,\n                        ax=j,*args,**kwargs)\n\n    #         j.yaxis.set_major_locator(MaxNLocator(nbins=18))\n\n            plt.tight_layout()\n\n\nimport scipy.stats as stats\n\ndef qqplt(df,x_size=30,y_size=30,*args,**kwargs):\n    \n    if len(df.shape) == 1:\n        fig, ax = plt.subplots(figsize=(x_size,y_size))\n        stats.probplot(df,plot=ax, *args,**kwargs)\n        \n#         ax.set_title(label=df.columns)\n        ax.tick_params(labelrotation=45)\n        ax.yaxis.set_major_locator(MaxNLocator(nbins=10))\n\n#         plt.tight_layout()\n        \n    \n    else:\n        ncols = 3\n        nrows = int(np.ceil(df.shape[1]\/ncols))\n\n        fig, axes = plt.subplots(nrows, ncols, figsize=(x_size,y_size))\n        axes = axes.flatten()\n\n        for i, j in zip(df.columns, axes):\n\n            stats.probplot(df[i],plot=j, *args,**kwargs)\n            j.set_title(label=i)\n            j.tick_params(labelrotation=45)\n            j.yaxis.set_major_locator(MaxNLocator(nbins=10))\n\n            plt.tight_layout()","135e4fc2":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndf = pd.read_csv(\"..\/input\/song-popularity-prediction\/train.csv\")\ndf.drop(\"id\", axis=1, inplace=True)\ntarget = \"song_popularity\"\ndf.about()","1487b393":"thresold = 20_000","5eecbecd":"df.describe_discrete_cols(thresold)","501f048d":"discrete = df.get_discrete_cols(thresold)\ndiscrete","807c326e":"continuous = df.get_continuous_cols(thresold)\ncontinuous","2ac9ce58":"display(HTML('<h1 style=\"color:green\"> <b> Distribution <\/b> <\/h1>'))\ncountplt(df[discrete], ncols=2, y_size=15)","e6df2400":"display(HTML('<h1 style=\"color:green\"> <b> vs song_popularity <\/b> <\/h1>'))\ndisplay(\ndisplay_multiple_tables([\n    compare_cols(df, l_feat=[i,target], r_feat={target:\"count\"}, percent_of_total=True) for i in discrete]))\n\ncountplt(df[discrete], ncols=2, y_size=15, hue=target, )\n","8314bfc0":"display(HTML('<h1 style=\"color:green\"> <b> vs audio_mode <\/b> <\/h1>'))\ndisplay(\ndisplay_multiple_tables([\n    compare_cols(df, l_feat=[i,\"audio_mode\"], r_feat={target:\"count\"}, percent_of_total=True) for i in discrete]))\n\ncountplt(df[discrete], ncols=2, y_size=15, hue=\"audio_mode\", )","a7fe5078":"histplt(df[continuous], ncols=2, y_size=30, kde=True )","326e9c28":"histplt(df[continuous], ncols=2, y_size=30, kde=True, hue=df[target] )","2441e995":"def normalize(a):\n    return pd.Series((a - a.min() ) \/ (a.max() - a.min()) )","7972f4f2":"tmp = df[continuous + [target]]\n\ntmp.loc[:, 'song_duration_ms'] = np.log(tmp['song_duration_ms'])\n\ntmp.loc[:,'loudness'] = tmp['loudness'] - tmp['loudness'].min()\n\ntmp.loc[:,'tempo'] = np.log(tmp['tempo'])","67fd7a66":"song_duration = normalize(tmp['song_duration_ms'].dropna())\nloudness = normalize(tmp['loudness'].dropna())\ntempo = normalize(tmp['tempo'].dropna())\n\nacousticness = tmp['acousticness'].dropna()\ndanceability = tmp['danceability'].dropna()\nenergy = tmp['energy'].dropna()\ninstrumentalness= tmp['instrumentalness'].dropna()\nliveness = tmp['liveness'].dropna()\nspeechiness = tmp['speechiness'].dropna()\naudio_valence = tmp['audio_valence'].dropna()","14ac70f7":"display(\nsong_duration.describe(),\nloudness.describe(),\ntempo.describe()\n       )","ebdb1032":"names = [\n    *continuous, continuous[0]\n]\n\nvar = [\n    song_duration,\n    acousticness,\n    danceability,\n    energy,\n    instrumentalness,\n    liveness,\n    loudness,\n    speechiness,\n    tempo,\n    audio_valence,\n    song_duration,\n    ]","6007cfd0":"label_loc = np.linspace(start=0, stop=2 * np.pi, num=len(var))\n\nplt.figure(figsize=(15,15))\nplt.subplot(polar=True)\n\nlow = []\nhigh = []\nmean = []\nfor i in var:\n    low.append(i.IQR_range()[0])\n    high.append(i.IQR_range()[1])\n    mean.append(i.mean())\n    \nplt.plot(label_loc, low, label='low')\nplt.plot(label_loc, high, label='high')\nplt.plot(label_loc, mean, label='mean')\nplt.title('Radar Plot of IQR range')\nplt.thetagrids(np.degrees(label_loc), labels=names)\nplt.tight_layout()\nplt.legend()\nplt.show()","60e36316":"song_duration = normalize(tmp['song_duration_ms'].loc[tmp[target] == 0].dropna())\nloudness = normalize(tmp['loudness'].loc[tmp[target] == 0].dropna())\ntempo = normalize(tmp['tempo'].loc[tmp[target] == 0].dropna())\n\nacousticness = tmp['acousticness'].loc[tmp[target] == 0].dropna()\ndanceability = tmp['danceability'].loc[tmp[target] == 0].dropna()\nenergy = tmp['energy'].loc[tmp[target] == 0].dropna()\ninstrumentalness= tmp['instrumentalness'].loc[tmp[target] == 0].dropna()\nliveness = tmp['liveness'].loc[tmp[target] == 0].dropna()\nspeechiness = tmp['speechiness'].loc[tmp[target] == 0].dropna()\naudio_valence = tmp['audio_valence'].loc[tmp[target] == 0].dropna()\n\n\nlabel_loc = np.linspace(start=0, stop=2 * np.pi, num=len(var))\n\nplt.figure(figsize=(15,15))\nplt.subplot(polar=True)\n\nlow = []\nhigh = []\nmean = []\nfor i in var:\n    low.append(i.IQR_range()[0])\n    high.append(i.IQR_range()[1])\n    mean.append(i.mean())\n    \nplt.plot(label_loc, low, label='low')\nplt.plot(label_loc, high, label='high')\nplt.plot(label_loc, mean, label='mean')\nplt.title(f'Radar Plot of IQR range, {target} = 0 ')\nplt.thetagrids(np.degrees(label_loc), labels=names)\nplt.legend()\nplt.show()","2c992edb":"song_duration = normalize(tmp['song_duration_ms'].loc[tmp[target] == 1].dropna())\nloudness = normalize(tmp['loudness'].loc[tmp[target] == 1].dropna())\ntempo = normalize(tmp['tempo'].loc[tmp[target] == 1].dropna())\n\nacousticness = tmp['acousticness'].loc[tmp[target] == 1].dropna()\ndanceability = tmp['danceability'].loc[tmp[target] == 1].dropna()\nenergy = tmp['energy'].loc[tmp[target] == 1].dropna()\ninstrumentalness= tmp['instrumentalness'].loc[tmp[target] == 1].dropna()\nliveness = tmp['liveness'].loc[tmp[target] == 1].dropna()\nspeechiness = tmp['speechiness'].loc[tmp[target] == 1].dropna()\naudio_valence = tmp['audio_valence'].loc[tmp[target] == 1].dropna()\n\n\nlabel_loc = np.linspace(start=0, stop=2 * np.pi, num=len(var))\n\nplt.figure(figsize=(15,15))\nplt.subplot(polar=True)\n\nlow = []\nhigh = []\nmean = []\nfor i in var:\n    low.append(i.IQR_range()[0])\n    high.append(i.IQR_range()[1])\n    mean.append(i.mean())\n    \nplt.plot(label_loc, low, label='low')\nplt.plot(label_loc, high, label='high')\nplt.plot(label_loc, mean, label='mean')\nplt.title(f'Radar Plot of IQR range, {target} = 1 ')\nplt.thetagrids(np.degrees(label_loc), labels=names)\nplt.legend()\nplt.show()","5d24550f":"display(HTML('<h1 style=\"color:green\"> <b> The distribution for both is the same, hence no difference in Radar Plot <\/b> <\/h1>'))","a117388a":"**IF unique values of columns is more than `thresold` it is Continuous ELSE Categorical**","662e27ea":"<h1 id =\"Exploring Continuous Data\" style=\"color:#E36149;\">Exploring Continuous Data<\/h1>","8d7229b0":"### Thanks to Remek for the discussion!\n<h1 id =\"Thanks to Remek for the discussion\" style=\"color:#E36149;\">Thanks to Remek for the discussion<\/h1>\nhttps:\/\/www.kaggle.com\/c\/song-popularity-prediction\/discussion\/301616\n\nSource - Spotify: \"In Spotify's API is something called Valence, that describes the musical positiveness conveyed by a track. Tracks with high valence sound more positive (happy, cheerful, euphoric), while tracks with low valence sound more negative (sad, depressed, angry).\"\n\n\nFrom very good article explaining Spotify API **What Makes a Song Likeable?**- https:\/\/towardsdatascience.com\/what-makes-a-song-likeable-dbfdb7abe404 we can read that:\n\n\n**Spotify Audio Features**\nFor every track on their platform, Spotify provides data for thirteen Audio Features.The Spotify Web API developer guide defines them as follows:\n\n\n- **Danceability**: Describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity.\n\n\n- **Valence**: Describes the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n\n\n- **Energy**: Represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale.\n\n\n- **Tempo**: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece, and derives directly from the average beat duration.\n\n\n- **Loudness**: The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks.\n\n\n- **Speechiness**: This detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value.\nInstrumentalness: Predicts whether a track contains no vocals. \u201cOoh\u201d and \u201caah\u201d sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \u201cvocal\u201d.\n\n\n- **Liveness**: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live.\n\n\n- **Acousticness**: A confidence measure from 0.0 to 1.0 of whether the track is acoustic.\n\n\n- **Key**: The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C\u266f\/D\u266d, 2 = D, and so on.\n\n\n- **Mode**: Indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n\n\n- **Duration**: The duration of the track in milliseconds.\n\n\n- **Time Signature**: An estimated overall time signature of a track. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure).\n\n","20cf0e91":"<h1 id =\"Imports\" style=\"color:#E36149;\">Imports<\/h1>","67655fd1":"<h1 id =\"Exploring Discrete Data\" style=\"color:#E36149;\">Exploring Discrete Data<\/h1>","a73eb360":"## Observations","b5ba44fb":"- Lots of missing values.\n- IQR suggests 100% outlier for multiple columns, most likely its a categorical variable","ea5e2a85":"<h1 id =\"Introduction\" style=\"color:#E36149;\">Introduction<\/h1>","8c5da3a5":"<h1 id =\"Initial Impressions\" style=\"color:#E36149;\">Initial Impressions<\/h1>","c1b72c27":"**Its quite interesting to observe the above dist, its probably synthetic data**","d3cc1e53":"<h1 id =\"Figuring out which are Categorical and Continuous\" style=\"color:#E36149;\">Figuring out which are Categorical and Continuous<\/h1>","0d144e16":"- `instrumentalness` is highly skewed\n- It would probably be a good idea to convert `tempo` to Discrete variable by binning it","66fc888e":"<h1 id =\"Start\" style=\"color:#E36149;\">Start<\/h1>","1d591fc9":"<h1 id =\"Pandas Helper methods\" style=\"color:#E36149;\">Pandas Helper methods<\/h1>","b1ac4e1b":"<h1 id =\"Plots Helper Functions\" style=\"color:#E36149;\">Plots Helper Functions<\/h1>","d67850cc":"**It is most likely that the data is generated, since we have have observed really unrealistic distribution, especially in   the Radar Plot and Histogram for Continuous variables.**"}}