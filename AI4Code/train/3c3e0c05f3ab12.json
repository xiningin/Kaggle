{"cell_type":{"00dfcf32":"code","4a3d9747":"code","9e8ffd90":"code","3073ddbc":"code","6aad61a5":"code","afe47b1f":"code","cfdc534d":"code","8682ca8b":"code","e042b159":"code","76dde15a":"code","b80ac939":"code","e49604dc":"code","bbf19836":"code","314671d0":"markdown","851c3f2b":"markdown","63cabdfc":"markdown","adc79f2d":"markdown","eaf6a1df":"markdown","fcebb0f7":"markdown","3e7a9a69":"markdown","5ba444c2":"markdown","82141a4f":"markdown","b02f232c":"markdown","0d55ad0d":"markdown"},"source":{"00dfcf32":"! pip install astroNN\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom tensorflow import keras\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, AveragePooling2D, Flatten, Dense, Dropout\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.optimizers import Adam\n\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom tensorflow.keras import utils\n\nfrom astroNN.datasets import galaxy10\nfrom astroNN.datasets.galaxy10 import galaxy10cls_lookup","4a3d9747":"images, labels = galaxy10.load_data()\n\nx_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)\n\nfeatures = ['Disk, Face-on, No Spiral', 'Smooth, Completely round', 'Smooth, in-between round', 'Smooth, Cigar shaped', 'Disk, Edge-on, Rounded Bulge', 'Disk, Edge-on, Boxy Bulge', \n            'Disk, Edge-on, No Bulge','Disk, Face-on, Tight Spiral', 'Disk, Face-on, Medium Spiral', 'Disk, Face-on, Loose Spiral']\n\nx_train = x_train \/ 255.0\nx_test = x_test \/ 255.0","9e8ffd90":"x_train.shape, x_test.shape","3073ddbc":"fig = plt.figure(figsize=(20,20)) \n\nfor i in range(25):\n    plt.subplot(5,5,i+1)    \n    plt.imshow(x_train[i])\n    plt.title(features[y_train[i]])\n    fig.tight_layout(pad=3.0)\n    \nplt.show()","6aad61a5":"# Check class distribution\n\ndf = pd.DataFrame(data=labels)\n\ncounts = df.value_counts().sort_index()\nprint(counts)","afe47b1f":"def class_distribution(x, y, labels):\n    fig, ax = plt.subplots()\n    ax.bar(x, y)\n    ax.set_xticklabels(labels, rotation=90)\n    plt.show()\n    \nclass_distribution(features, counts, features)","cfdc534d":"model = Sequential()\n\n# Baseline model to compare to LeNet-5\nmodel.add(Flatten(input_shape=(69, 69, 3)))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel_optimizer = Adam(lr=0.001)\n\nmodel.compile(optimizer=model_optimizer, loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\nreduceLR = ReduceLROnPlateau(monitor='accuracy', factor=.001, patience=1, min_delta=0.01, mode=\"auto\")\nlol = model.fit(x_train, y_train, epochs=10, callbacks=[reduceLR])","8682ca8b":"# Predictions on baseline model \n\npredictions = model.predict(x_test)\n\nfor i in range(10):\n    print(\"Actual:\", features[y_test[i]])\n    print(\"Prediction:\", features[np.argmax(predictions[i])])\n    print (\"______\")\n    print()\n        ","e042b159":"model2 = Sequential()\n\n# LeNet-5 conv-net architecture\nmodel2.add(Conv2D(filters=6, kernel_size=(5,5), strides=(1,1), activation='tanh', input_shape=(69,69,3)))\nmodel2.add(AveragePooling2D(pool_size=(2,2), strides=(2,2)))\nmodel2.add(Conv2D(filters=16, kernel_size=(5,5), strides=(1,1), activation='tanh'))\nmodel2.add(AveragePooling2D(pool_size=(2,2), strides=(2,2)))\n\nmodel2.add(Flatten())\nmodel2.add(Dense(units=120, activation='tanh'))\nmodel2.add(Dense(units=84, activation='tanh'))\nmodel2.add(Dense(units=10, activation='softmax'))\n\nmodel_optimizer = Adam(lr=0.001)\n\nreduceLR = ReduceLROnPlateau(monitor='accuracy', factor=.001, patience=1, min_delta=0.01, mode=\"auto\")\n\nmodel2.compile(optimizer=model_optimizer, loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\nmodel2.fit(x_train, y_train, epochs=10, callbacks=[reduceLR])","76dde15a":"predict = model2.predict(x_test).argmax(axis=1)\n\nfor i in range(10):\n    print(\"Actual:\", features[y_test[i]])\n    print(\"Prediction:\", features[np.argmax(predict[i])])\n    print(\"-----\")\n    print()","b80ac939":"classification_report(y_test, predict)","e49604dc":"print('                  precision  recall  f1-score   support\\n\\n           '\n'0       0.54      0.50      0.52       728\\n           '\n'1       0.86      0.91      0.89      1375\\n           '\n'2       0.80      0.87      0.83      1243\\n           '\n'3       0.47      0.41      0.44        61\\n           '\n'4       0.73      0.81      0.77       296\\n           '\n'5       0.00      0.00      0.00         6\\n           '\n'6       0.74      0.73      0.73       132\\n           '\n'7       0.46      0.34      0.39       211\\n           '\n'8       0.40      0.27      0.32       187\\n           '\n'9       0.53      0.36      0.43       118\\n    '\n' macro avg     0.55      0.52      0.53      4357\\n' \n'  weighted avg     0.72      0.74      0.73      4357\\n'\n'  accuracy: 0.74      4357\\n')","bbf19836":"matrix = confusion_matrix(y_test, predict)\nsns.heatmap(matrix, annot=True)\nplt.title('Galaxy Confusion Matrix')\nplt.xlabel('Predicted class')\nplt.ylabel('True class')","314671d0":"# LeNet-5 Architecture\n\nAn old but classic convolutional neural network architecture developed in 1998 by Yann Andre LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. When first developed, it was designed for the handwritten MNIST digits recognition and became the foundation for future architectures like AlexNet and VGG.\n\nThe first convolution block consists of two convolutional and average pooling layers which is succeeded by a flatten layer and then followed by 3 dense layers. \n\n![image.png](attachment:image.png)","851c3f2b":"For improved legibility: I refactored the classification report.","63cabdfc":"It looks like some of the galaxy classes are being confused for others. It's difficult for even humans to correctly classify each of the image classes. To gain a better understanding of the mistakes made, using confusion matrixes are helpful. We'll also be taking a look at the classification report here.","adc79f2d":"#  Imbalanced Data; The Accuracy Paradox\n\nHere, we have quite an unbalanced dataset. The number of images in each class range from 17 (min) in class 5 and 6997 (max) in class 1. The issue with data that has skewed class distributions is that accuracy is no longer an evaluation metric that correctly reflects the machine learning model's ability to classify the images. This is also known as the **accuracy paradox** which states that a model with a higher accuracy might have less predictive power than a model with a lower accuracy. \n\nTo sum it up: accuracy may not always be the best metric to evaluate your model. As a result, it would be a more fair analysis if we used other evaluation metrics like precision or recall. \n\n**Precision**:  Precision = True Positive (TP) \/ True Positive (TP) + False Positive (FP)\n\n**Recall**:  Recall = True Positive (TP) \/ True Positive (TP) + False Negative (FN)\n\n**Side note:** Precision and recall metrics have been removed so we'll train the conv nets w\/ accuracy as the metric but use Scikit Learn's classification report later on to gain a better understanding of our model's precision, recall, and f1 score.","eaf6a1df":"From this report, we can tell that our model has a high precision and recall for classifying classes 0, 1, 2, 4 (specifically 1 and 2). Notice how classes 1 and 2 also had the most training and testing samples too. On the other end of the spectrum, the model has a very low precision and recall (0) for class 5 where there were only 6 testing samples. Plotting a confusion matrix will provide further transparency on what those 6 testing samples were predicted as.","fcebb0f7":"# Galaxy Multi-Image Classification with LeNet-5 \n\nSummary of contents:\n\n* **Importing Dependencies**\n* **About the Dataset (Galaxy 10)**\n* **Data Exploration**\n    1. Data Dimensions\n    2. Data Visualization\n    3. Class Distribution\n* **Accuracy Paradox**\n* **Baseline model**\n* **About LeNet-5 architecture**\n* **Implementation of LeNet-5 model**\n* **Predictions, classification report, and confusion matrix**\n","3e7a9a69":"# Galaxy10 Dataset\n\nThe galaxy10 dataset is a dataset that contains 21785 69x69 pixels colored galaxy images with 10 different classes. The images from this dataset come from Sloan Digital Sky Survey and the labels come from Galaxy Zoo.\n\nEach of the images within the dataset are classified under one of the 10 classes, however, there were discrepancies in the classes assigned to certain images from the human volunteers who were tasked with labelling the images which serves as empirical evidence that there is a high level of similarity in the images between the classes. To mitigate this issue, the Galaxy10 dataset does not include images where there was no definitive decision. (55% of votes casted by human volunteers towards one class)","5ba444c2":"# Conclusion\n\nThis was an interesting dataset to toy around with! When I'd found it and examined the images, it'd been difficult for me as a human to discern between the differences of the different galaxy classes as they shared highly similar characteristics, so I was intrigued to see how a machine learning model would perform in comparison to a human. Some of the initial assumptions I'd made were right: I'd believed that the model would have most difficulty with the spirals, others were a little off. I had thought that the model would confuse classes 1 and 2 (Smooth, Completely round and Smooth, in-between round) more often as those classes also looked very similar in some images. After training, I would attribute the model's ability to discern between the two classes so well due to the fact that it had a good amount of images for each class to train on.\n\nOther things to note: accuracy isn't always the best metric to evaluate your model and also a side note for LeNet-5; LeNet-5 while it may be relatively old of an architecture, it didn't perform too poorly on this dataset. ","82141a4f":"Now, we know a bit more about our dataset. Here, we have a dataset of 17248 colored training images w\/ dimensions of 69 by 69 and 4357 colored testing images w\/ dimensions of 69 by 69. Let's take a look at a random selection of images within our dataset.","b02f232c":"Let's take a look at the dataset dimensions.","0d55ad0d":"The model did well with predicting class 1 and 2 images! No surprising since they're the classes with the most samples. 0 and 4 didn't do too bad either. Our model consistently confused class 0 for class 7 (76 samples), class 1 and 2 were also frequently predcited for class 0. Also, the model had issues with classifying class 8, often mistaking it with class 0 and 7. Let's look into that. Class 8 is the Disk, Face-on, Medium Spiral, class 0 is Disk, Face-on, No Spiral, and class 7 is Disk, Face-on, Tight Spiral. Taking a look at the images visualized above, it's quite easy to discern why, these images look quite similar."}}