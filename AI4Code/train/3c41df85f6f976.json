{"cell_type":{"3185abe3":"code","092b8d94":"code","cedfbaa4":"code","c65f520c":"code","dd63db87":"code","ab30b952":"code","c81e5c63":"code","6c924cd7":"code","139a0757":"code","c5bc7e1f":"code","a1217e91":"code","d847a408":"code","8a7f2b36":"code","90b5c109":"code","c996e98b":"code","2a83393e":"code","ba59fc52":"code","71a8b3c0":"code","fc358597":"code","d993cfc3":"code","cec3609a":"code","3f94d389":"code","8b0c0f84":"code","b04f9fdb":"code","1a530592":"code","26996e58":"code","e6d409df":"code","f4158095":"code","2b2785cf":"code","868a63a2":"code","2a8250fe":"code","d42a343f":"code","d72f6b9a":"code","0175a355":"code","9a166068":"code","1466928c":"code","53088625":"code","8b73573e":"code","e51abef2":"code","baf7fbb2":"code","4326ed55":"code","2c27f659":"code","59717bd2":"code","2ab5dcfd":"code","f43d0c83":"code","f9f66c16":"code","4f652159":"code","036cd827":"code","a50d6d7b":"code","2b08962c":"code","fd70642a":"code","fe6a527d":"code","467a7589":"code","d6aa2dc0":"code","4c63b36b":"code","085bdf4e":"code","12d515f0":"code","350931a9":"code","c738c8ec":"code","5a5f2ab6":"code","aedc9829":"code","17aec4f2":"code","a31195c7":"code","602c32a3":"code","ad925047":"code","04444f5a":"code","9f62f05f":"code","432dd5c7":"code","04912896":"code","7c5d58ed":"code","b597e06a":"code","09aec3d9":"code","a0c39dc6":"code","ca185e40":"code","ca3ec34b":"code","1d4ac708":"code","b7a222c3":"code","bc5f6288":"code","f40a872d":"code","ad26546d":"code","29b3fd9b":"code","39063a31":"code","6ba45b13":"code","1940ab56":"code","2667ec92":"code","aabc750e":"code","22f237b6":"code","9cf60fad":"code","127e36df":"markdown","136ccf77":"markdown","7da945d5":"markdown","7cfaea5b":"markdown","45ea1953":"markdown","618f1c21":"markdown","b82f0c0d":"markdown","d4215877":"markdown","6d50e1fe":"markdown","a63996d6":"markdown","7a7f1717":"markdown","dde50465":"markdown","7ee3dcbd":"markdown","ff2cdf7b":"markdown","8e2043dd":"markdown","9e77d893":"markdown","1eedbc78":"markdown","cabc18cf":"markdown","a4a56616":"markdown"},"source":{"3185abe3":"#importing required packages\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly.graph_objs import *\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport string\nimport os","092b8d94":"#reading data\nF1=pd.read_csv(\"..\/input\/chefmozaccepts.csv\")\nF2=pd.read_csv(\"..\/input\/chefmozcuisine.csv\")\nF3=pd.read_csv(\"..\/input\/chefmozhours4.csv\")\nF4=pd.read_csv(\"..\/input\/chefmozparking.csv\")\nF5=pd.read_csv(\"..\/input\/usercuisine.csv\")\nF6=pd.read_csv(\"..\/input\/userpayment.csv\")\nF7=pd.read_csv(\"..\/input\/userprofile.csv\")\nF8=pd.read_csv(\"..\/input\/geoplaces2.csv\")\n\nT=pd.read_csv(\"..\/input\/rating_final.csv\")","cedfbaa4":"F1.head()","c65f520c":"F1.info()","dd63db87":"# plot to visualise most accepted payments by Restaurants\nF1plt=F1.Rpayment.value_counts().plot.bar(title=\"Payments Accepted\")\nF1plt.set_xlabel('payments mode',size=15)\nF1plt.set_ylabel('count',size=15)","ab30b952":"#creating dummy variables for differen payments.\nF1dum = pd.get_dummies(F1,columns=['Rpayment'])\nF1dum1 = F1dum.groupby('placeID',as_index=False).sum()\nlen(F1dum1)","c81e5c63":"F1dum1.head()","6c924cd7":"F2.head()","139a0757":"F2.info()","c5bc7e1f":"#plot to visualize top cuisines offered by the restaurants\nF2plt=F2.Rcuisine.value_counts()[:10].plot.bar(title=\"Top 10 cuisine\")\nF2plt.set_xlabel('cuisine',size=15)\nF2plt.set_ylabel('count',size=15)","a1217e91":"#creating dummy variables for different cuisines.\nF2dum = pd.get_dummies(F2,columns=['Rcuisine'])\nF2dum1 = F2dum.groupby('placeID',as_index=False).sum()\nlen(F2dum1)","d847a408":"F2dum1.head()","8a7f2b36":"F3.head()","90b5c109":"F3.info()","c996e98b":"F4.head()","2a83393e":"F4.info()","ba59fc52":"#plot to visualize available parking place at the Restaurants\nF4plt=F4.parking_lot.value_counts().plot.bar(title=\"parking place\")\nF4plt.set_xlabel('Available parking',size=15)\nF4plt.set_ylabel('count',size=15)","71a8b3c0":"#creating dummy variables for different parking lots.\nF4dum = pd.get_dummies(F4,columns=['parking_lot'])\nF4dum1 = F4dum.groupby('placeID',as_index=False).sum()\nlen(F4dum1)","fc358597":"F4dum1.head()","d993cfc3":"F5.head()","cec3609a":"F5.info()","3f94d389":"#Top 10 favorite cuisines for the customers\nF5plt=F5.Rcuisine.value_counts()[:10].plot.bar(title=\"Top 10 user cuisine\")\nF5plt.set_xlabel('user cuisine',size=15)\nF5plt.set_ylabel('count',size=15)","8b0c0f84":"#creating dummy variables for differen usercuisines.\nF5dum = pd.get_dummies(F5,columns=['Rcuisine'])\nF5dum1 = F5dum.groupby('userID',as_index=False).sum()\nlen(F5dum1)","b04f9fdb":"F5dum1.head()","1a530592":"F6.head()","26996e58":"F6.info()","e6d409df":"#top type of payments done by the users\nF6plt=F6.Upayment.value_counts().plot.bar(title=\"User payments\")\nF6plt.set_xlabel('User payments',size=15)\nF6plt.set_ylabel('count',size=15)","f4158095":"#creating dummy variables for different userpayments.\nF6dum = pd.get_dummies(F6,columns=['Upayment'])\nF6dum1 =F6dum.groupby('userID',as_index=False).sum()\nlen(F6dum1)","2b2785cf":"F6dum1.head()","868a63a2":"F7.head()","2a8250fe":"F7.info()","d42a343f":"# as data contains unknown value, we are replacinf with Nan.\nF7rep=F7.replace('?', np.nan)","d72f6b9a":"#now we are finding missing value cnt n perct for all variables.\nmss=F7rep.isnull().sum()\ncolumns = F7rep.columns\npercent_missing = F7rep.isnull().sum() * 100 \/ len(F7rep)\nmissing_value_F7rep = pd.DataFrame({'missing_cnt':mss,'percent_missing': percent_missing})\nmissing_value_F7rep","0175a355":"#since the missing value pernt is very low in each variables, we are replacing with mode of that individual column.\nfor column in F7rep.columns:\n    F7rep[column].fillna(F7rep[column].mode()[0], inplace=True)","9a166068":"#plotting for marital status vs smoker n drinklevel.\nF7rep.groupby('marital_status')['smoker','drink_level'].nunique().plot.bar(rot=0)","1466928c":"#plot to visualize user's personal info based on birthyear.\nF7repplt=F7rep.groupby('birth_year')['interest','personality','religion','activity'].nunique().plot.bar(figsize=(15, 5))","53088625":"#now performing label encoding to convert char to factors.\nF7char=F7rep.select_dtypes(include=['object'])\n\nencoder = LabelEncoder()\nF7charLE = F7char.apply(encoder.fit_transform, axis=0)\nF7charLE=F7charLE.drop(['userID'],axis=1)\nF7charLE[['userID','latitude','longitude','birth_year','weight','height']]=F7rep[['userID','latitude','longitude','birth_year','weight','height']]\nF7charLE.head()\n\n","8b73573e":"F8.head()","e51abef2":"F8.info()","baf7fbb2":"#replacing unknown value with Nan.\nF8rep=F8.replace('?', np.nan)","4326ed55":"#now we are finding missing value cnt n perct for all variables.\nmss=F8rep.isnull().sum()\ncolumns = F8rep.columns\npercent_missing = F8rep.isnull().sum() * 100 \/ len(F8rep)\nmissing_value_F8rep = pd.DataFrame({'missing_cnt':mss,\n                                 'percent_missing': percent_missing})\nmissing_value_F8rep","2c27f659":"#dropping columns with more than 50% missing values\nF8new=F8rep.drop(['fax','zip','url'],axis=1)\n#and replacing remaining colvalues with mode\nfor column in F8new.columns:\n    F8new[column].fillna(F8new[column].mode()[0], inplace=True)","59717bd2":"#clean n cnt of city\nF8new.city=F8new.city.apply(lambda x: x.lower())\nF8new.city=F8new.city.apply(lambda x:''.join([i for i in x \n                            if i not in string.punctuation]))\n\nF8new.city.value_counts()","2ab5dcfd":"#replacing city with unique. \nF8new['city']=F8new['city'].replace(['san luis potos','san luis potosi','slp','san luis potosi '],'san luis potosi' )\nF8new['city']=F8new['city'].replace(['victoria','cd victoria','victoria '],'ciudad victoria' )\nF8new.city.value_counts()","f43d0c83":"#clean n cnt of state\nF8new.state=F8new.state.apply(lambda x: x.lower())\nF8new.state=F8new.state.apply(lambda x:''.join([i for i in x \n                            if i not in string.punctuation]))\n\nF8new.state.value_counts()","f9f66c16":"#replacing state with unique.\nF8new['state']=F8new['state'].replace(['san luis potos','san luis potosi','slp'],'san luis potosi' )\nF8new.state.value_counts()","4f652159":"#clean n cnt of country\nF8new.country=F8new.country.apply(lambda x: x.lower())\nF8new.country=F8new.country.apply(lambda x:''.join([i for i in x \n                            if i not in string.punctuation]))\n\nF8new.country.value_counts()","036cd827":"#label encoding\nF8char=F8new.select_dtypes(include=['object'])\nF8charLE = F8char.apply(encoder.fit_transform, axis=0)\nF8charLE[['placeID','latitude','longitude']]=F8new[['placeID','latitude','longitude']]\nF8charLE.head()","a50d6d7b":"#plot for facilities provided by Restaurants based on city.\nF8newplt=F8new.groupby('city')['alcohol','smoking_area','accessibility','price','Rambience','other_services'].nunique().plot.bar(figsize=(15,5))","2b08962c":"mapbox_access_token='pk.eyJ1IjoibmF2ZWVuOTIiLCJhIjoiY2pqbWlybTc2MTlmdjNwcGJ2NGt1dDFoOSJ9.z5Jt4XxKvu5voCJZBAenjQ'","fd70642a":"mcd=F8rep[F8rep.country =='Mexico']\nmcd_lat = mcd.latitude\nmcd_lon = mcd.longitude\n\ndata = [\n    go.Scattermapbox(\n        lat=mcd_lat,\n        lon=mcd_lon,\n        mode='markers',\n        marker=dict(\n            size=6,\n            color='rgb(255, 0, 0)',\n            opacity=0.4\n        ))]\nlayout = go.Layout(\n    title='Restaurants Locations',\n    autosize=True,\n    hovermode='closest',\n    showlegend=False,\n    mapbox=dict(\n        accesstoken=mapbox_access_token,\n        bearing=0,\n        center=dict(\n            lat=23,\n            lon=-102\n        ),\n        pitch=2,\n        zoom=4.5,\n        style='dark'\n    ),\n)\n\nfig = dict(data=data, layout=layout)\niplot(fig, filename='restaurants')","fe6a527d":"#merging ratingfile(T) with userprofile(F7)\nA=pd.merge(T,F7charLE)","467a7589":"#merging A with userpayments(F6) \nB=pd.merge(A,F6dum1,how='left',on=['userID'])","d6aa2dc0":"#merging B with usercuisine(F5)\nC=pd.merge(B,F5dum1,how='left',on=['userID'])","4c63b36b":"#merging C with geoplaces2(F8)\nD=pd.merge(C,F8charLE,how='left',on=['placeID'])","085bdf4e":"#merging D with chefmozparking(F4)\nE=pd.merge(D,F4dum1,how='left',on=['placeID'])","12d515f0":"#merging E with chefmozcuisine(F2)\nF=pd.merge(E,F2dum1,how='left',on=['placeID'])","350931a9":"#merging F with chefmozaccepts(F1)\nG=pd.merge(F,F1dum1,how='left',on=['placeID'])","c738c8ec":"len(G)","5a5f2ab6":"G.head()","aedc9829":"G.info()","17aec4f2":"print('No of columns',G.shape[1])\nprint('No of rows',G.shape[0])","a31195c7":"#check for Null values\nG.isnull().values.any()","602c32a3":"#finding percentage of null values across columns\ncolumns = G.columns\npercent_missing = G.isnull().sum() * 100 \/ len(G)\nmissing_value_G = pd.DataFrame({'percent_missing': percent_missing})\nmissing_value_G","ad925047":"#replacing missing values with zero and check.\nG=G.fillna(0)\nG.isnull().values.any()","04444f5a":"#for modelling purpose we are label encoding userID.\nG['userID']=encoder.fit_transform(G['userID'])","9f62f05f":"#packages for modelling\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import confusion_matrix,classification_report\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_curve,auc\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import cohen_kappa_score","432dd5c7":"# splitting train and test data as 75\/25.\nX=G.drop(['placeID','rating','food_rating','service_rating'],axis=1)\ny=G['rating']\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)","04912896":"#model building.\nlogmodel = LogisticRegression()\nlogmodel.fit(X_train,y_train)","7c5d58ed":"#predicting on test data.\npredictions1 =  logmodel.predict(X_test)","b597e06a":"print(\"confusion matrix\")\nprint(confusion_matrix(y_test,predictions1))\nprint(\"Accuracy_score\")\nprint(accuracy_score(y_test, predictions1))","09aec3d9":"print(\"classification_report\")\nprint(classification_report(y_test,predictions1))","a0c39dc6":"#kappa score.\ncohen_kappa_score(y_test, predictions1)","ca185e40":"#model building.\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X_train,y_train)","ca3ec34b":"#predicting on test data.\npredictions2 =  clf.predict(X_test)","1d4ac708":"print(\"confusion matrix\")\nprint(confusion_matrix(y_test,predictions2))\nprint(\"Accuracy_score\")\nprint(accuracy_score(y_test, predictions2))","b7a222c3":"print(\"classification_report\")\nprint(classification_report(y_test,predictions2))","bc5f6288":"#kappa score.\ncohen_kappa_score(y_test, predictions2)","f40a872d":"#model building.\nRndclf = RandomForestClassifier(max_depth=2, random_state=0) \nRndclf.fit(X_train,y_train)","ad26546d":"#predicting on test data.\npredictions3 = Rndclf.predict(X_test)","29b3fd9b":"print(\"confusion matrix\")\nprint(confusion_matrix(y_test,predictions3))\nprint(\"Accuracy_score\")\nprint(accuracy_score(y_test, predictions3))","39063a31":"print(\"classification_report\")\nprint(classification_report(y_test,predictions3))","6ba45b13":"#kappa score.\ncohen_kappa_score(y_test, predictions3)","1940ab56":"#model building.\nxgb = XGBClassifier()\nxgb.fit(X_train, y_train)","2667ec92":"#predicting on test data.\npredictions4 = xgb.predict(X_test)","aabc750e":"print(\"confusion matrix\")\nprint(confusion_matrix(y_test,predictions4))\nprint(\"Accuracy_score\")\nprint(accuracy_score(y_test, predictions4))","22f237b6":"print(\"classification_report\")\nprint(classification_report(y_test,predictions4))","9cf60fad":"#kappa score.\ncohen_kappa_score(y_test, predictions4)","127e36df":"# F7 - userprofile.csv","136ccf77":"# F3 - chefmozhours4.csv","7da945d5":"# F6 - userpayment.csv","7cfaea5b":"Producing Map location for the Restaurants","45ea1953":"# F1-chefmozaccepts.csv","618f1c21":"# By Comparing the above built models, we find that XGboost is giving better predictions based on Accuracy,F1-score and kappa score.\n","b82f0c0d":"# F4 - chefmozparking.csv","d4215877":"# F2 - chefmozcuisine.csv","6d50e1fe":"since some variables contains dirty values, we are going to perform data cleaning on those variables.","a63996d6":"##Random Forest","7a7f1717":"# Merging multiple files into one","dde50465":"# F5 - usercuisine.csv","7ee3dcbd":"Now we are going to explore and preprocess each csv files individualy","ff2cdf7b":"# Model Building","8e2043dd":"# Final Data","9e77d893":"##XGboost model","1eedbc78":"##Decision Tree","cabc18cf":"##Logistic Regression","a4a56616":"# F8 - geoplaces2.csv"}}