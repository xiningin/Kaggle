{"cell_type":{"eeb0ae5f":"code","509ac00a":"code","aad42394":"code","819a83d4":"code","23acaa07":"code","fcf8772e":"code","7ad8f9d5":"code","d423a09d":"code","9ef4879d":"code","0bc9e9a1":"code","96220c78":"code","1817187a":"code","e5362fa0":"code","c10d84e5":"code","1618062a":"code","c557e4c4":"code","737e3ad5":"code","2e1717c3":"code","a49117fd":"code","2f9d3caf":"code","9aaa8c9b":"code","64224004":"code","7e2eb89f":"code","3e40a333":"code","b15fe0a2":"code","da3708ff":"code","022c611f":"markdown","ef1c17fc":"markdown","895abf82":"markdown","c2d28be9":"markdown","f47b07d1":"markdown","5cc805e5":"markdown","a7e0915f":"markdown","10fc78ec":"markdown","b220bacc":"markdown","8634d58d":"markdown","b2ad4737":"markdown","5af21841":"markdown","20024f03":"markdown"},"source":{"eeb0ae5f":"!ls -lh ..\/input\/data-science-bowl-2019\/","509ac00a":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm_notebook\n\nimport altair as alt\nfrom altair.vega import v5\nfrom IPython.display import HTML\n\n%matplotlib inline\nplt.rc('figure', figsize=(15.0, 8.0))","aad42394":"root = '..\/input\/data-science-bowl-2019\/'\ntrain = pd.read_csv(root + 'train.csv')\ntrain_labels = pd.read_csv(root + 'train_labels.csv')\nspecs = pd.read_csv(root + 'specs.csv')\ntest = pd.read_csv(root + 'test.csv')\nsample_submission = pd.read_csv(root + 'sample_submission.csv')","819a83d4":"train.head()","23acaa07":"train.info()","fcf8772e":"train['installation_id'].unique().shape # total 17000 installations in train data","7ad8f9d5":"specs.head()","d423a09d":"specs.info()","9ef4879d":"train_labels.head()","0bc9e9a1":"train_labels.info()","96220c78":"test.head()","1817187a":"test['installation_id'].unique().shape # total 1000 installations for which we have to predict","e5362fa0":"sample_submission.head()","c10d84e5":"sample_submission.shape # to predict for 1000 installations","1618062a":"train = train.merge(specs, on='event_id')\ntrain_labels = train.merge(train_labels, on=['game_session', 'installation_id']) # returns only type == Assessments","c557e4c4":"train.shape, train_labels.shape","737e3ad5":"train.head()","2e1717c3":"train_labels.head()","a49117fd":"fig, ax = plt.subplots(figsize=(10, 10))\nplot = sns.countplot(y=\"type\", data=train, palette=['navy', 'darkblue', 'blue', 'dodgerblue']).set_title('train type count', fontsize=16)\nplt.yticks(fontsize=14)\nplt.xlabel(\"Count\", fontsize=15)\nplt.ylabel(\"type\", fontsize=15)\nplt.show(plot)","2f9d3caf":"fig, ax = plt.subplots(figsize=(10, 10))\nplot = sns.countplot(y=\"type\", data=test, palette=['navy', 'darkblue', 'blue', 'dodgerblue']).set_title('test type count', fontsize=16)\nplt.yticks(fontsize=14)\nplt.xlabel(\"Count\", fontsize=15)\nplt.ylabel(\"type\", fontsize=15)\nplt.show(plot)","9aaa8c9b":"train_by_type = train.groupby('type')\ntrain_clip = train_by_type.get_group('Clip')\ntrain_game = train_by_type.get_group('Game')\ntrain_activity = train_by_type.get_group('Activity')\ntrain_assessment = train_by_type.get_group('Assessment')","64224004":"train_clip.head()","7e2eb89f":"train_game.head()","3e40a333":"train_activity.head()","b15fe0a2":"train_assessment.head()","da3708ff":"sample_submission.to_csv('submission.csv', index=False)","022c611f":"# 2019 Data Science Bowl","ef1c17fc":"`type`: Media type of the game or video, let's see `type`'s distribution in train\/test set","895abf82":"For each `installation_id` in test.csv we have to predict the accuracy group (based on the outcome of the assessment event)","c2d28be9":"Now:\n* `train` contains train + specs data for all event types.\n* `train_labels` contains train + specs + labels for all assessments","f47b07d1":"According to data page of the competition:\n\n>Each application install is represented by an `installation_id`. This will typically correspond to one child, but you should expect noise from issues such as shared devices. In the training set, you are provided the full history of gameplay data. In the test set, we have truncated the history after the start event of a single assessment, chosen randomly, for which you must predict the number of attempts. Note that the training set contains many `installation_id`s which never took assessments, whereas every `installation_id` in the test set made an attempt on at least one assessment.","5cc805e5":"One of the most awaited competitions is here!, let's do a quick EDA","a7e0915f":"### train.csv & test.csv\n\nThese are the main data files which contain the gameplay events.\n\n* `event_id` - Randomly generated unique identifier for the event type. Maps to event_id column in specs table.\n* `game_session` - Randomly generated unique identifier grouping events within a single game or video play session.\n* `timestamp` - Client-generated datetime\n* `event_data` - Semi-structured JSON formatted string containing the events parameters. Default fields are: event_count, event_code, and game_time; otherwise fields are determined by the event type.\n* `installation_id` - Randomly generated unique identifier grouping game sessions within a single installed application instance.\n* `event_count` - Incremental counter of events within a game session (offset at 1). Extracted from event_data.\n* `event_code` - Identifier of the event 'class'. Unique per game, but may be duplicated across games. E.g. event code '2000' always identifies the 'Start Game' event for all games. Extracted from event_data.\n* `game_time` - Time in milliseconds since the start of the game session. Extracted from event_data.\n* `title` - Title of the game or video.\n* `type` - Media type of the game or video. Possible values are: 'Game', 'Assessment', 'Activity', 'Clip'.\n* `world` - The section of the application the game or video belongs to. Helpful to identify the educational curriculum goals of the media. Possible values are: 'NONE' (at the app's start screen), TREETOPCITY' (Length\/Height), 'MAGMAPEAK' (Capacity\/Displacement), 'CRYSTALCAVES' (Weight).\n","10fc78ec":"### train_labels.csv\nThis file demonstrates how to compute the ground truth for the assessments (`train.type == \"Assessments\"`) in the training set.\n\nThe outcomes in this competition are grouped into 4 groups (labeled `accuracy_group` in the data):\n\n   * 3: the assessment was solved on the first attempt\n   * 2: the assessment was solved on the second attempt\n   * 1: the assessment was solved after 3 or more attempts\n   * 0: the assessment was never solved\n\n\nThe file train_labels.csv has been provided to show how these groups would be computed on the assessments in the training set. Assessment attempts are captured in `event_code`, 4100 for all assessments except for Bird Measurer, which uses event_code 4110. If the attempt was correct, it contains `\"correct\":true`.","b220bacc":"## Let's do in-depth analysis","8634d58d":"The dataset for this competitions comes from [PBS KIDS Measure Up! app](https:\/\/pbskids.org\/apps\/pbs-kids-measure-up.html), in this app children of ages 3 to 5 learn early math concepts focused on length, width, capacity, and weight. They have to navitage though maps and complete various levels, which may be activities, video clips, games, or **assessments**. Each **assessment** is designed to test a child's comprehension of a certain set of measurement-related skills. There are five assessments: Bird Measurer, Cart Balancer, Cauldron Filler, Chest Sorter, and Mushroom Sorter.\nThe intent of the competition is to use the gameplay data to forecast how many attempts a child will take to pass a given **assessment**.","b2ad4737":"### specs.csv\n\nThis file gives the specification of the various event types.\n\n* `event_id` - Global unique identifier for the event type. Joins to `event_id` column in events table.\n* `info` - Description of the event.\n* `args` - JSON formatted string of event arguments. Each argument contains:\n     - name - Argument name.\n     - type - Type of the argument (string, int, number, object, array).\n     - info - Description of the argument.\n","5af21841":"To be updated!","20024f03":"Let's merge train, specs and train_labels dataframe"}}