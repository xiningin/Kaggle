{"cell_type":{"abe8c28a":"code","640ddbfd":"code","1e7b5fa5":"code","96b00ab6":"code","acdfc492":"code","f2e32f32":"code","30feba8e":"code","f8f517a0":"code","72157832":"code","27e33437":"code","4a72e8b9":"code","4fc0fd3e":"code","e6865535":"code","3186c24a":"code","668372f8":"code","90b74bab":"code","0677043e":"code","9e682e0b":"code","abbc761f":"code","247a80e9":"code","1a181ff2":"code","f9aa921a":"code","78d343d4":"code","1d542409":"code","b0ad4de0":"code","2c3409e6":"code","af4449f6":"markdown","443ecb41":"markdown","8735536f":"markdown","706b148c":"markdown","267c843b":"markdown","be878270":"markdown","edf811f3":"markdown","1059d5c5":"markdown"},"source":{"abe8c28a":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\n\nfrom sklearn.metrics import confusion_matrix, classification_report","640ddbfd":"data = pd.read_csv('..\/input\/twitter-user-gender-classification\/gender-classifier-DFE-791531.csv', encoding='latin-1')","1e7b5fa5":"data","96b00ab6":"data.info()","acdfc492":"data.isna().mean()","f2e32f32":"def get_sequences(texts, vocab_length):\n    tokenizer = Tokenizer(num_words=vocab_length)\n    tokenizer.fit_on_texts(texts)\n    \n    sequences = tokenizer.texts_to_sequences(texts)\n    \n    max_seq_length = np.max([len(sequence) for sequence in sequences])\n    \n    sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n    \n    return sequences","30feba8e":"np.int('ED', 16)","f8f517a0":"def hex_to_decimal(x):\n    try:\n        return np.int(x, 16)\n    except:\n        return 0\n\ndef get_rgb(colors):\n    r = colors.apply(lambda x: hex_to_decimal(x[0:2]))\n    g = colors.apply(lambda x: hex_to_decimal(x[2:4]))\n    b = colors.apply(lambda x: hex_to_decimal(x[4:6]))\n    return r, g, b","72157832":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop unnecessary columns\n    df = df.drop(['_unit_id', 'name', 'profileimage', 'tweet_id'], axis=1)\n    \n    # Encode unknown values in the target column as np.NaN\n    df['gender'] = df['gender'].replace('unknown', np.NaN)\n    \n    # Drop rows with missing target values\n    gender_nas = df[df['gender'].isna()].index\n    df = df.drop(gender_nas, axis=0).reset_index(drop=True)\n    \n    # Drop columns with over 30% missing values\n    missing_cols = df.columns[df.isna().mean() > 0.3]\n    df = df.drop(missing_cols, axis=1)\n    \n    # There are only 50 remaining missing values in the _last_judgment_at columns, so let's drop those rows\n    judgment_nas = df[df['_last_judgment_at'].isna()].index\n    df = df.drop(judgment_nas, axis=0).reset_index(drop=True)\n    \n    # Let's encode the missing values in the description column as empty strings\n    df['description'] = df['description'].fillna('')\n    \n    # Create date\/time columns\n    for column in ['_last_judgment_at', 'created', 'tweet_created']:\n        df[column] = pd.to_datetime(df[column])\n    \n    df['judgment_day'] = df['_last_judgment_at'].apply(lambda x: x.day)\n    df['judgment_hour'] = df['_last_judgment_at'].apply(lambda x: x.hour)\n    \n    df['created_year'] = df['created'].apply(lambda x: x.year)\n    df['created_month'] = df['created'].apply(lambda x: x.month)\n    df['created_day'] = df['created'].apply(lambda x: x.day)\n    df['created_hour'] = df['created'].apply(lambda x: x.hour)\n    \n    df['tweet_hour'] = df['tweet_created'].apply(lambda x: x.hour)\n    \n    df = df.drop(['_last_judgment_at', 'created', 'tweet_created'], axis=1)\n    \n    # Get sequence data for description and text columns\n    desc = get_sequences(df['description'], vocab_length=20000)\n    tweets = get_sequences(df['text'], vocab_length=20000)\n    \n    df = df.drop(['description', 'text'], axis=1)\n    \n    # Drop columns with only one value\n    df = df.drop(['_golden', '_unit_state', '_trusted_judgments', 'profile_yn'], axis=1)\n    \n    # Encode color columns as RGB values\n    df['link_red'], df['link_green'], df['link_blue'] = get_rgb(df['link_color'])\n    df['side_red'], df['side_green'], df['side_blue'] = get_rgb(df['sidebar_color'])\n    \n    df = df.drop(['link_color', 'sidebar_color'], axis=1)\n    \n    # Encode label column\n    label_mapping = {'female': 0, 'male': 1, 'brand': 2}\n    df['gender'] = df['gender'].replace(label_mapping)\n    \n    # Split df into X and y\n    y = df['gender'].copy()\n    X = df.drop('gender', axis=1).copy()\n    \n    # Scale X with a standard scaler\n    scaler = StandardScaler()\n    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n    \n    return X, desc, tweets, y","27e33437":"X, desc, tweets, y = preprocess_inputs(data)","4a72e8b9":"X","4fc0fd3e":"{column: len(X[column].unique()) for column in X.columns}","e6865535":"desc.shape","3186c24a":"tweets.shape","668372f8":"y.value_counts()","90b74bab":"X_train, X_test, desc_train, desc_test, tweets_train, tweets_test, y_train, y_test = \\\n    train_test_split(X, desc, tweets, y, train_size=0.7, random_state=1)","0677043e":"desc.shape","9e682e0b":"def build_model():\n\n    X_inputs = tf.keras.Input(shape=(X.shape[1],))\n    desc_inputs = tf.keras.Input(shape=(desc.shape[1],))\n    tweet_inputs = tf.keras.Input(shape=(tweets.shape[1],))\n\n    # X\n    X_dense1 = tf.keras.layers.Dense(256, activation='relu')(X_inputs)\n    X_dense2 = tf.keras.layers.Dense(256, activation='relu')(X_dense1)\n\n    # desc\n    desc_embedding = tf.keras.layers.Embedding(\n        input_dim=20000,\n        output_dim=256,\n        input_length=desc.shape[1]\n    )(desc_inputs)\n    desc_gru = tf.keras.layers.GRU(256, return_sequences=False)(desc_embedding)\n    desc_flatten = tf.keras.layers.Flatten()(desc_embedding)\n    desc_concat = tf.keras.layers.concatenate([desc_gru, desc_flatten])\n\n    # tweets\n    tweet_embedding = tf.keras.layers.Embedding(\n        input_dim=20000,\n        output_dim=256,\n        input_length=tweets.shape[1]\n    )(tweet_inputs)\n    tweet_gru = tf.keras.layers.GRU(256, return_sequences=False)(tweet_embedding)\n    tweet_flatten = tf.keras.layers.Flatten()(tweet_embedding)\n    tweet_concat = tf.keras.layers.concatenate([tweet_gru, tweet_flatten])\n\n    concat = tf.keras.layers.concatenate([X_dense2, desc_concat, tweet_concat])\n\n    outputs = tf.keras.layers.Dense(3, activation='softmax')(concat)\n\n\n    model = tf.keras.Model(inputs=[X_inputs, desc_inputs, tweet_inputs], outputs=outputs)\n\n    return model","abbc761f":"model = build_model()\n\nprint(model.summary())\ntf.keras.utils.plot_model(model)","247a80e9":"model.compile(\n    optimizer='adam',\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nbatch_size = 32\nepochs = 3\n\nhistory = model.fit(\n    [X_train, desc_train, tweets_train],\n    y_train,\n    validation_split=0.2,\n    batch_size=batch_size,\n    epochs=epochs,\n    callbacks=[\n        tf.keras.callbacks.ModelCheckpoint('.\/model.h5', save_best_only=True, save_weights_only=True),\n        tf.keras.callbacks.ReduceLROnPlateau()\n    ]\n)","1a181ff2":"model.load_weights('.\/model.h5')","f9aa921a":"results = model.evaluate([X_test, desc_test, tweets_test], y_test, verbose=0)\nprint(\"Model Accuracy: {:.2f}%\".format(results[1] * 100))","78d343d4":"y_true = np.array(y_test)\n\ny_pred = model.predict([X_test, desc_test, tweets_test])\ny_pred = map(lambda x: np.argmax(x), y_pred)\ny_pred = np.array(list(y_pred))","1d542409":"cm = confusion_matrix(y_true, y_pred)\nclr = classification_report(y_true, y_pred, target_names=['Female', 'Male', 'Brand'])","b0ad4de0":"plt.figure(figsize=(6, 6))\nsns.heatmap(cm, annot=True, fmt='g', cbar=False, cmap='Blues')\nplt.xticks(np.arange(3) + 0.5, ['Female', 'Male', 'Brand'])\nplt.yticks(np.arange(3) + 0.5, ['Female', 'Male', 'Brand'])\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix\")\nplt.show()","2c3409e6":"print(\"Classification Report:\\n\\n\", clr)","af4449f6":"# Modeling","443ecb41":"# Train-Test Split","8735536f":"# Training","706b148c":"# Preprocessing","267c843b":"# Results","be878270":"# Task for Today  \n\n***\n\n## Twitter User Gender Prediction  \n\nGiven *data about users on Twitter*, let's try to predict the **gender** of a given user.  \n  \nWe will use a deep recurrent neural network with multiple inputs to make our predictions.","edf811f3":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/0Jb0ywwLQgI","1059d5c5":"# Getting Started"}}