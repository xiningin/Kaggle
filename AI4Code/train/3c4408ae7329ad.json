{"cell_type":{"0578aa0f":"code","c438adb6":"code","2f3093f9":"code","630d652b":"code","90ebea9c":"code","0cdeba04":"code","b2ad2421":"code","983264f4":"markdown","9dbf008d":"markdown","a0e65ad0":"markdown","73346ff3":"markdown","38919ee2":"markdown","91402f1d":"markdown"},"source":{"0578aa0f":"!pip install pycocotools>=2.0.2 > \/dev\/null\n!pip install timm>=0.3.2 > \/dev\/null\n!pip install omegaconf>=2.0 > \/dev\/null\n!pip install ensemble-boxes > \/dev\/null\n!pip install effdet > \/dev\/null","c438adb6":"import sys\nimport torch\nimport os\nimport warnings\nimport time\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport gc\nfrom tqdm.auto import tqdm\nfrom datetime import datetime\nfrom collections import Counter\nfrom glob import glob\n\nfrom ensemble_boxes import weighted_boxes_fusion\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GroupKFold, train_test_split\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom torch.utils.data.dataloader import default_collate\n\nfrom effdet import get_efficientdet_config, EfficientDet, DetBenchTrain, DetBenchPredict\nfrom effdet.efficientdet import HeadNet\nfrom effdet import create_model, unwrap_bench, create_loader, create_dataset, create_evaluator, create_model_from_config\nfrom effdet.data import resolve_input_config, SkipSubset\nfrom effdet.anchors import Anchors, AnchorLabeler\nfrom timm.models import resume_checkpoint, load_checkpoint\nfrom timm.optim import create_optimizer\nfrom timm.scheduler import create_scheduler\n\nimport geopandas\nfrom shapely.geometry import Point, mapping\nfrom fiona import collection\n\nimport random\nimport gdal\n\n# Global variables\nTEST_ROOT_PATH = '..\/input\/splitimages\/split_test_folder\/'\n\nTEST_IMAGE = '..\/input\/swimming-pool-512x512\/TEST_SET_ALPES_MARITIMES.3.png'\nTEST_IMAGE_TIF = '..\/input\/swimming-pool-512x512\/TEST_SET_ALPES_MARITIMES.3.tif'\n\nMODEL_PATH = '..\/input\/efficientdet-swimming-pool-detection-custom\/training_job\/fold-1-best-checkpoint-033epoch.bin'\n\nIMG_SIZE = 512\nCONF_TH = 0.3\n\n# Load full size image\nfull_size_img = cv2.imread(TEST_IMAGE)\nfull_size_img = cv2.cvtColor(full_size_img, cv2.COLOR_BGR2RGB)\nfull_size_img.shape","2f3093f9":"def collate_fn(batch):\n    batch = list(filter(lambda x: x is not None, batch))\n    \n    return tuple(zip(*batch))\n\ndef get_test_transforms():\n    return A.Compose(\n        [\n            ToTensorV2(p=1.0),\n        ], \n        p=1.0, \n    )\n\nclass DatasetRetriever(Dataset):\n\n    def __init__(self, image_ids, transforms=None):\n        super().__init__()\n        self.image_ids = image_ids\n        self.transforms = transforms\n\n    def __getitem__(self, index: int):\n        image_id = self.image_ids[index]\n        image = cv2.imread(f'{TEST_ROOT_PATH}\/{image_id}', cv2.IMREAD_COLOR).copy()\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image \/= 255.0\n        if self.transforms:\n            sample = {'image': image}\n            sample = self.transforms(**sample)\n            image = sample['image']\n        return image, image_id\n\n    def __len__(self) -> int:\n        return self.image_ids.shape[0]","630d652b":"# Creation validation dataset\ntest_dataset = DatasetRetriever(\n                        image_ids=np.array([path.split('\/')[-1] for path in glob(f'{TEST_ROOT_PATH}\/*.png')]),\n                        transforms=get_test_transforms(),\n                        )\n\n# Create test loader\ntest_loader = torch.utils.data.DataLoader(\n    test_dataset, \n    batch_size=1,\n    num_workers=1,\n    shuffle=False,\n    sampler=SequentialSampler(test_dataset),\n    pin_memory=False,\n    collate_fn=collate_fn,\n)\n\nbase_config = get_efficientdet_config('tf_efficientdet_d1')\nbase_config.image_size = (IMG_SIZE, IMG_SIZE)\nbase_config.num_classes = 1\n\nmodel = EfficientDet(base_config, pretrained_backbone=False)\n\ncheckpoint = torch.load(MODEL_PATH)\nmodel.load_state_dict(checkpoint['model_state_dict'])\nmodel = DetBenchPredict(model)\n\ndel checkpoint\ngc.collect()\nmodel.eval()\nmodel.cuda()\n\nimg = test_dataset[0][0]\n\nboxes = model(img.unsqueeze(0).cuda().float())\nprint(boxes.shape)\nnp_img = img.permute(1,2,0).cpu().numpy().copy()\n\nfor box in boxes[0]:\n    if box[4] > 0.25:\n        cv2.rectangle(np_img, (box[0], box[1]), (box[2],  box[3]), (0, 1, 0), 2)\nplt.imshow(np_img)","90ebea9c":"CONF_TH = 0.3\n\ntemp_boxes = []\ntemp_scores = []\nfor images, image_ids in tqdm(test_loader, total=len(test_loader)):\n    with torch.no_grad():\n        images = torch.stack(images)\n        images = images.cuda().float()\n        \n        det = model(images)\n\n        for i in range(images.shape[0]):\n            boxes = det[i].detach().cpu().numpy()[:,:4]    \n            scores = det[i].detach().cpu().numpy()[:,4]\n            \n            xmin_patch = image_ids[i].split('_')[3]\n            ymin_patch = image_ids[i].split('_')[4]\n            xmax_patch = image_ids[i].split('_')[5]\n            ymax_patch = image_ids[i].split('_')[6].split('.')[0]\n            \n            # Keep only boxes for scores > CONF_TH\n            k_ids = np.where(scores > CONF_TH)[0]\n            boxes = boxes[k_ids]\n            scores = scores[k_ids]\n            \n            boxes_full_size_img = boxes.copy()\n            boxes_full_size_img[:, 0] += float(xmin_patch)\n            boxes_full_size_img[:, 1] += float(ymin_patch)\n            boxes_full_size_img[:, 2] += float(xmin_patch)\n            boxes_full_size_img[:, 3] += float(ymin_patch)\n        \n            temp_boxes.append(boxes_full_size_img)\n            temp_scores.append(scores)\n            \n# Apply WBF\nfinal_boxes = []\nfor x in temp_boxes:\n    for y in x:\n        final_boxes.append(y)\n        \nfinal_scores = []\nfor x in temp_scores:\n    for y in x:\n        final_scores.append(y)\n        \nfinal_labels = [1] * len(final_scores)\n\nfinal_boxes = [b \/ (full_size_img.shape[0] - 1) for b in final_boxes]\nfinal_boxes, final_scores, final_labels = weighted_boxes_fusion([final_boxes], [final_scores], [final_labels], weights=None, iou_thr=0.1, skip_box_thr=0) # small iou threshold since overlapping between boxes is rare\nfinal_boxes = (final_boxes * (full_size_img.shape[0] - 1)).astype(int) # de normalize","0cdeba04":"# Define shp file to write to\nshpOut = 'poly.shp'\n\n# Define shp file schema\nschema = { 'geometry': 'Polygon', 'properties': { 'Name': 'str' } }\n\n# Create array for storing vertices\npolyPoints = []\n\n# Convert to geographic coordinates\nds = gdal.Open(TEST_IMAGE_TIF) \ngeotransform = ds.GetGeoTransform()\n\noriginX = geotransform[0]\noriginY = geotransform[3]\npixelWidth = geotransform[1]\npixelHeight = geotransform[5]\n\nfinal_boxes_x = []\nfinal_boxes_y = []\n\nfor b in final_boxes:\n    #for b in img:\n    # Convert bbox to points\n    xc = (b[0] + b[2]) \/\/ 2\n    yc = (b[1] + b[3]) \/\/ 2\n\n    # Transform to coordinates in space\n    posX = originX + pixelWidth * xc\n    posY = originY + pixelHeight * yc\n\n    final_boxes_x.append(posX)\n    final_boxes_y.append(posY)\n        \n\ndf = {'x': final_boxes_x, 'y': final_boxes_y}\ndf = pd.DataFrame(df)\n\ngdf = geopandas.GeoDataFrame(\n    df, geometry=geopandas.points_from_xy(df.x, df.y))\n\ngdf['geometry'].plot()\ngdf.to_file('test.shp')","b2ad2421":"print('Number of pools', len(gdf))","983264f4":" <span style=\"color: #000508; font-family: Segoe UI; font-size: 2.0em; font-weight: 300;\">Online installations<\/span>","9dbf008d":"<span style=\"color: #000508; font-family: Segoe UI; font-size: 2.0em; font-weight: 300;\">Import Packages<\/span>","a0e65ad0":"# Inference","73346ff3":"# Define functions","38919ee2":"# Create shapefile","91402f1d":"# Load the model"}}