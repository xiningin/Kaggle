{"cell_type":{"f10deb0c":"code","4c6cce29":"code","2d1461ce":"code","cd1625e6":"code","a979deda":"code","1ae5f066":"code","368c7271":"code","a7870266":"code","27ea700d":"code","dfb27509":"code","7a355878":"code","d45007b3":"code","3dfc5815":"code","c6db42a7":"code","5eaadb3a":"code","e75291f3":"code","6441bdfe":"code","23ba7fce":"code","d6d8db31":"code","4872cbe1":"code","ea937374":"code","4fb9f22c":"code","0ccaf8aa":"code","8d59a6fb":"code","b8bdbdd5":"code","20d3c3eb":"code","16a991fd":"code","e1508392":"code","8114adbe":"code","fddb0d34":"code","b14313a7":"code","8b84ed5f":"code","1e63fd42":"code","bd5bfd1f":"markdown","906cf5f8":"markdown","d9d6d3ab":"markdown","71c7d1fa":"markdown","6d24bfec":"markdown","c8f9bae8":"markdown","81ada0dd":"markdown","d2415fc5":"markdown","4f6f5775":"markdown","a700a29b":"markdown","b0dc6e72":"markdown","bb6e93b1":"markdown","50135611":"markdown","0ff68b50":"markdown","e0934614":"markdown","cea6dbdb":"markdown","fcc81269":"markdown","ce0fa346":"markdown","0e6cad03":"markdown","3f42dd7b":"markdown","f1099d34":"markdown","134f58a4":"markdown","e4a74914":"markdown","7db12b36":"markdown","3fe3ba04":"markdown","840f8377":"markdown","ad1296e8":"markdown","f781e8eb":"markdown","d2cb833b":"markdown","f620c3f8":"markdown","0159bfd9":"markdown","90a40c7c":"markdown","00018d3e":"markdown","a5ef271a":"markdown","9dc7f9c9":"markdown","fa3bb0a1":"markdown","6ce8d257":"markdown","1c2edd36":"markdown","f7d6811e":"markdown","107ce159":"markdown","91a53efc":"markdown","ef06da8d":"markdown"},"source":{"f10deb0c":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4c6cce29":"train = pd.read_csv(\"..\/input\/health-insurance-cross-sell-prediction\/train.csv\")\ntest = pd.read_csv(\"..\/input\/health-insurance-cross-sell-prediction\/test.csv\")\n\nprint(\"Shape of train dataset \",train.shape )\nprint(\"Shape of test dataset \",test.shape )\n","2d1461ce":"train.head(3).append(train.tail(3))","cd1625e6":"train.info()","a979deda":"col = train.columns.tolist()\ncol.remove('id')\ntrain[col].describe(percentiles = [.25,.50,.75,.95,.99])","1ae5f066":"\nplt.subplot(1, 2, 1)\nsns.countplot(train['Response'], palette=\"cool\")\nplt.title(\"Count of response (target variable)\")\n\nplt.subplot(1,2,2)\ncount = train['Response'].value_counts()\ncount.plot.pie(autopct = '%1.1f%%',colors=['green','orange'], figsize = (10,7),explode = [0,0.1],title = \"pie chart of Percentage of target class\")\n\nprint( \"Percentage of target class\\n\")\nprint(train['Response'].value_counts()\/len(train)*100)\n\n","368c7271":"\nplt.figure(figsize = (13,5))\nplt.subplot(1,2,1)\nsns.countplot(train['Gender'])\nplt.title(\"count of male and female\")\nplt.subplot(1,2,2)\nsns.countplot(train['Gender'], hue = train['Response'],palette=\"rocket_r\")\nplt.title(\"Response in Male and female category\")\nplt.show()\n","a7870266":"plt.figure(figsize = (15,3))\nsns.countplot(train['Age'], palette = 'hsv')\nplt.title('Count of Age')\nplt.show()","27ea700d":"\nf,ax = plt.subplots(nrows=1,ncols=2,figsize=(20,5))\naxx = ax.flatten()\nsns.distplot(train['Age'] ,ax = axx[0],color='Blue')\nsns.boxplot(train['Age'],ax = axx[1],color='Orange')","dfb27509":"print(\"Percentage of  Driving_License feature\\n \")\nprint(train['Driving_License'].value_counts()\/len(train)*100)\nf,ax = plt.subplots(nrows=1,ncols=2,figsize=(12,6))\naxx = ax.flatten()\nplt.title(\"Count plot of Driving_License vs Response\")\nsns.countplot(train['Driving_License'],ax = axx[0],palette = 'rocket')\nsns.countplot('Driving_License', hue = 'Response',ax =axx[1],data = train,palette=\"rocket_r\")\n","7a355878":"\nplt.figure(figsize = (30,10))\nplt.subplot(3,1,1)\nsns.countplot(train['Region_Code'], palette = 'hsv')\nplt.title('Count of Region code')\nplt.figure(figsize = (10,7))\nplt.subplot(3,1,2)\nsns.distplot(train['Region_Code'])\nplt.title('Distribution of Region code')\nplt.figure(figsize = (10,7))\nplt.subplot(3,1,3)\nsns.boxplot(train['Region_Code'])\nplt.title('Boxplot of Region code')\nplt.show()\n","d45007b3":"print(\"Percentage ofPreviously_Insured feature\\n \")\nprint(train['Previously_Insured'].value_counts()\/len(train)*100)\nf,ax = plt.subplots(nrows=1,ncols=2,figsize=(12,5))\naxx = ax.flatten()\nsns.countplot(train['Previously_Insured'],ax = axx[0])\nsns.countplot('Previously_Insured', hue = 'Response',ax =axx[1],data = train,palette=\"cool_r\")\n","3dfc5815":"print(\"Percentage of vechicle age feature\\n \")\nprint(train['Vehicle_Age'].value_counts()\/len(train)*100)\nplt.figure(figsize = (13,5))\nplt.subplot(1,2,1)\nsns.countplot(train['Vehicle_Age'])\nplt.title(\"Count plot of vechicle age\")\nplt.subplot(1,2,2)\nplt.title(\"Plot of vechicle age vs response\")\nsns.countplot('Vehicle_Age', hue = 'Response',data = train,palette=\"cool\")\n","c6db42a7":"print(\"Percentage of vechicle damage feature\\n \")\nprint(train['Vehicle_Damage'].value_counts()\/len(train)*100)\nplt.figure(figsize = (13,5))\nplt.subplot(1,2,1)\nsns.countplot(train['Vehicle_Damage'],palette=\"rocket_r\")\nplt.title(\"Count plot of Vehicle_Damage\")\nplt.subplot(1,2,2)\nplt.title(\"Plot of vechicle damage vs response\")\nsns.countplot('Vehicle_Damage', hue = 'Response',data = train,palette=\"cool\")","5eaadb3a":"plt.figure(figsize=(13,7))\nplt.subplot(2,1,1)\nsns.distplot(train['Annual_Premium'], color='green')\nplt.title(\"Distribution of Annual premium\")\nplt.show()\n#print(\"-------------------------------------\")\nplt.figure(figsize=(13,7))\nplt.subplot(2,1,2)\nsns.boxplot(train['Annual_Premium'],color='green')\nplt.title(\"boxplot of Annual premium\")\nplt.show()","e75291f3":"plt.figure(figsize = (20,3))\n\nplt.subplot(1,3,1)\nplt.title(\"Distribution of Policy_Sales_Channel\")\nsns.distplot(train['Policy_Sales_Channel'])\n\nplt.subplot(1,3,2)\nplt.title(\"Boxplot of Policy_Sales_Channel\")\nsns.boxplot(train['Policy_Sales_Channel'],color='Orange')\n","6441bdfe":"\nf,ax = plt.subplots(nrows=2,ncols=1,figsize=(10,5))\naxx = ax.flatten()\nsns.distplot(train['Vintage'],ax=axx[0], color='Blue')\nsns.boxplot(train['Vintage'],ax=axx[1],color='green')\n","23ba7fce":"plt.figure(figsize=(10,10))\nplt.title(\"Correlation plot\")\nsns.heatmap(train[col].corr(),linewidths=5, annot=True, square=True,annot_kws={'size': 10},cmap='YlGnBu')","d6d8db31":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\ntrain['is_train'] = 1               \ntest['is_train'] = 0\ntest['Response'] = None\ndf = pd.concat((train,test))       # Combining train and test together for preprocessing \ndf.tail(2)","4872cbe1":"df['Vehicle_Age'] = le.fit_transform(df['Vehicle_Age'])\ndf['Gender'] = le.fit_transform(df['Gender'])\ndf['Vehicle_Damage'] = le.fit_transform(df['Vehicle_Damage'])\ndf['Vehicle_Age'] = le.fit_transform(df['Vehicle_Age'])\ndf['Gender'] = le.fit_transform(df['Gender'])\ndf.head()","ea937374":"df['Region_Code']=df['Region_Code'].astype(int)              # converting the float variables to int because cat boost dosen't take float for categorical variables \ndf['Policy_Sales_Channel']=df['Policy_Sales_Channel'].astype(int)","4fb9f22c":"train = df[df['is_train']==1]                             \ntest = df[df['is_train']==0]\ntrain = train.drop(['is_train'],axis=1)              \ntest = test.drop(['is_train','Response'] ,axis=1)\n\ntrain['Response'] = train['Response'].astype(int)  # Converting object to int\ntrain.shape , test.shape","0ccaf8aa":"col_1 = train.columns.tolist()\ncol_1.remove('id')\ncol_1.remove('Response')\ncat_col=['Gender','Driving_License', 'Region_Code', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage','Policy_Sales_Channel']","8d59a6fb":"from sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split \n\nX=train[col_1]\ny=train['Response']\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.25, random_state=42,stratify=y,shuffle=True)","b8bdbdd5":"from catboost import CatBoostClassifier\n\ncat = CatBoostClassifier(learning_rate=0.03, l2_leaf_reg=1, iterations= 500, depth= 9, border_count= 20,eval_metric = 'AUC')\n\ncat= cat.fit(X_train, y_train,cat_features=cat_col,eval_set=(X_test, y_test),early_stopping_rounds=70,verbose=50)\n\npred_proba = cat.predict_proba(X_test)[:, 1]\nprint('CatBoost ROC AUC SCORE: {}'.format(roc_auc_score(y_test,pred_proba)))","20d3c3eb":"from lightgbm import LGBMClassifier\n\nlgb = LGBMClassifier(boosting_type='gbdt',n_estimators=500,depth=10,learning_rate=0.04,objective='binary',metric='auc',is_unbalance=True,\n                 colsample_bytree=0.5,reg_lambda=2,reg_alpha=2,random_state=42,n_jobs=-1)\n\nlgb= lgb.fit(X_train, y_train,eval_metric='auc',eval_set=(X_test , y_test),verbose=50,categorical_feature=cat_col,early_stopping_rounds= 50)\n\n\npred_proba = lgb.predict_proba(X_test)[:, 1]\nprint('Lightgbm ROC AUC SCORE: {}'.format(roc_auc_score(y_test, pred_proba)))\n","16a991fd":"from sklearn.model_selection import StratifiedKFold\n\n\n\nlgb = LGBMClassifier(n_estimators=500,depth=5,learning_rate=0.04,objective='binary',metric='auc',is_unbalance=True,\n                 colsample_bytree=0.5,reg_lambda=2,reg_alpha=2,random_state=42,n_jobs=-1)              # The parameter here are selected by manual tuning \n \n\nfold = StratifiedKFold(n_splits = 5, shuffle =True)\npred = []\nscore =[]\nfor train_index , test_index in fold.split(X,y):\n    X_train,X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train,y_test = y.iloc[train_index], y.iloc[test_index]\n   \n    lgb= lgb.fit(X_train, y_train,eval_metric='auc',eval_set=(X_test , y_test),verbose=100,categorical_feature=cat_col,early_stopping_rounds= 50)\n    pred_proba = lgb.predict_proba(X_test)[:, 1]\n    score.append(roc_auc_score(y_test, pred_proba))","e1508392":"print(\"Mean AUC \",np.array(score).mean())\nprint(\"Max AUC \", np.array(score).max())\n","8114adbe":"lgb= lgb.fit(X, y,eval_metric='auc',verbose=2,categorical_feature=cat_col)","fddb0d34":"\n\nparam = { 'depth':[3,1,2,6,4,8,9,10,20,30,50],\n         'iterations':[250,100,500,1000],\n         'learning_rate':[0.03,0.001,0.01,0.1,0.13,0.2,0.3],\n         'l2_leaf_reg':[3,1,5,10,100],\n         'border_count':[32,5,10,20,100,200]\n        }\n","b14313a7":"\"\"\"\nfrom sklearn.model_selection import RandomizedSearchCV\n\nrandm = RandomizedSearchCV(cat, param_distributions = param, cv=5,refit = True,n_iter = 10, n_jobs=-1)\nrandm.fit(X_train, y_train)\nprint(\"\\n The best parameters across ALL searched params:\\n\",\n          randm.best_params_)\n \"\"\"\nprint(\"The best parameters across ALL searched params:{'learning_rate': 0.03, 'l2_leaf_reg': 1, 'iterations': 500, 'depth': 9, 'border_count': 20}\")","8b84ed5f":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(lgb, random_state=1).fit(X_train, y_train)\neli5.show_weights(perm, feature_names = X_train.columns.tolist())","1e63fd42":"pred_cat = cat.predict_proba(test[col_1])[:,1]\npred_lgb = lgb.predict_proba(test[col_1])[:,1]     #extract only the probabilities of response = 1\n\nw1 = 0.8                    # higher weights for the catboost because from different submission catboost gave better score than lgbm\nw2 = 0.2                    # Tried with different weights for lgbm and catboost and found this pair of optimal values \n\nfinal = (1\/2)*((w1*pred_cat) + (w2*pred_lgb))        # Blending using average performed good for my model\nsubmit = pd.DataFrame({'id': test.id, 'Response': final})\nsubmit.to_csv('Blend_cat_lgb3.csv', index=False)\n","bd5bfd1f":"1. The gender variable in the dataset is almost equally distributed\n2. Male category is slightly greater than that of female and chances of buying the insurance is also little high. ","906cf5f8":"##  <span style = \"color:blue\">Cat Boost Model<\/span>","d9d6d3ab":"# <span style = \"color:blue\">Data set<\/span>","71c7d1fa":"## <span style = \"color:blue\"> Driving License  <\/span> ","6d24bfec":"##  <span style = \"color:blue\">Splitting data for training and validation<\/span> ","c8f9bae8":"* Customers with vechicle damage(Yes and NO) are equally distributed with (50.48 % , 49.51 %) \n* Customers with vechicle damage are more interested in Vehicle Insurance","81ada0dd":"### <span style = \"color:red\">If you find this notebook helpful then please provide your appreciation <\/span> ","d2415fc5":"* The indivisuals with region code 28 the highest as compared to the other ones\n* From the box plot it looks like there is no outliers in the data \n- Further  we can analyze which region has highest intrested customers ","4f6f5775":"##  <span style = \"color:blue\">Policy_Sales_Channel<\/span> ","a700a29b":"1. By the plot we can say that this is the problem of imbalance binary classification problem\n2. The indivisuals interested is 87 % as compared to the othe one.","b0dc6e72":"* From the correlation plot we observe that policy sales channel has slightly greater correlation with Age variable, this may be the   indication of multicollinearity. We can futher use VIF to check this","bb6e93b1":"*  **Public LB rank__  : 38**\n*  **Private LB rank_ : 10**\n* Link to Leaderboard : \nhttps:\/\/datahack.analyticsvidhya.com\/contest\/janatahack-cross-sell-prediction\/#LeaderBoard","50135611":"* From the distribution plot we can infer that the annual premimum variable is right skewed\n* From the boxplot we can observe lot of outliers in the variable ","0ff68b50":"##  <span style = \"color:blue\"> Region Code  <\/span> ","e0934614":" ## <span style = \"color:blue\">Label Encoding <\/span> ","cea6dbdb":"##  <span style = \"color:blue\">Vehicle Age  <\/span> ","fcc81269":"##  <span style = \"color:blue\">Annual_Premium<\/span> ","ce0fa346":"#  Tuning","0e6cad03":"## <span style = \"color:blue\"> Age variable <\/span>","3f42dd7b":"* There is very less number of customers with vechicle age less than 2 years\n* Customers with vechicle age 1-2 years are more likely to interested as compared to the other two","f1099d34":"# <span style = \"color:blue\">Basic EDA<\/span>","134f58a4":"* By looking at the summary of the data we can infer the mean,standard deviation, min and max of the \n* We will be able to get a idea on the outliers here by the percentiles ( In the Annual_Premium the 99th percentile is 72963 and the \n  max is 540165 this represents the outliers in this column)","e4a74914":"*  There is no missing value in the data\n*  By looking at the info of the dataset we can get a rough idea on the numeric and the string columns","7db12b36":"* The evaluation metric specified for this hackathon is AUC ROC \n* It is expected to submit the probabilities of the interested customers(Response - 1)","3fe3ba04":"1. Count of the indivisuals with age 24 are greater in the dataset\n2. Variable Age looks like right skewed\n3. From the boxplot we observe that here is not serious outliers in the data ","840f8377":"* Test size here was randomly selected  by trail and error method \n* Since this is the case of imbalance problem we need to set stratify for the target variable this divides the data into different     stratum and then the shuffle variable randomly shuffles the data \n","ad1296e8":"1. Customers who have the DL are 99% \n2. Customers who are interested in Vehicle Insurance almost all have driving license","f781e8eb":"## <span style = \"color:blue\">Gender variable<\/span>","d2cb833b":"## <span style = \"color:blue\">Blending<\/span>","f620c3f8":"# <span style = \"color:blue\">Problem statement <\/span>","0159bfd9":"##  <span style = \"color:blue\">Cross validation using StratifiedKFold<\/span>","90a40c7c":"1. The variable perviosly insured almost has equal count \n2. Customer who are not perviosly insured are likely to be inetrested\n","00018d3e":"By using the permutation importance we can get an idea of the important features (features at the top)\n* Permutation importance differ from model to model \n* Trained the model by removing the least importance features, scaling the variables,treating the outliers but model performance did not increase ","a5ef271a":"## <span style = \"color:blue\">Vechicle damage   <\/span> \n","9dc7f9c9":"##  <span style = \"color:blue\">Previously Insured   <\/span> ","fa3bb0a1":"![image.png](attachment:image.png)","6ce8d257":"##  <span style = \"color:blue\">Vintage<\/span> ","1c2edd36":"Your client is an Insurance company that has provided Health Insurance to its customers now they need your help in building a model to predict whether the policyholders (customers) from past year will also be interested in Vehicle Insurance provided by the company.\n\nAn insurance policy is an arrangement by which a company undertakes to provide a guarantee of compensation for specified loss, damage, illness, or death in return for the payment of a specified premium. A premium is a sum of money that the customer needs to pay regularly to an insurance company for this guarantee.\n\nFor example, you may pay a premium of Rs. 5000 each year for a health insurance cover of Rs. 200,000\/- so that if, God forbid, you fall ill and need to be hospitalised in that year, the insurance provider company will bear the cost of hospitalisation etc. for upto Rs. 200,000. Now if you are wondering how can company bear such high hospitalisation cost when it charges a premium of only Rs. 5000\/-, that is where the concept of probabilities comes in picture. For example, like you, there may be 100 customers who would be paying a premium of Rs. 5000 every year, but only a few of them (say 2-3) would get hospitalised that year and not everyone. This way everyone shares the risk of everyone else.\n\nJust like medical insurance, there is vehicle insurance where every year customer needs to pay a premium of certain amount to insurance provider company so that in case of unfortunate accident by the vehicle, the insurance provider company will provide a compensation (called \u2018sum assured\u2019) to the customer.\n\nBuilding a model to predict whether a customer would be interested in Vehicle Insurance is extremely helpful for the company because it can then accordingly plan its communication strategy to reach out to those customers and optimise its business model and revenue. \nNow, in order to predict, whether the customer would be interested in Vehicle insurance, you have information about demographics (gender, age, region code type), Vehicles (Vehicle Age, Damage), Policy (Premium, sourcing channel) etc.","f7d6811e":"Training the model on whole data ","107ce159":"![IMG_20200921_132236.jpg](attachment:IMG_20200921_132236.jpg)","91a53efc":"##  <span style = \"color:blue\">Light GBM model<\/span>","ef06da8d":"## <span style = \"color:blue\">Response (Target variable)<\/span>"}}