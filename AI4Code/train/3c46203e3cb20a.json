{"cell_type":{"79baeca2":"code","ff632b28":"code","ee0662ca":"code","b3d91574":"code","3984796a":"code","b3a4f507":"code","16be849c":"code","c53f9740":"code","4091ebfe":"code","a8ab0bcd":"code","8852db07":"code","5ac170c3":"code","363aed1a":"code","c4583751":"code","8ab65694":"code","5cd7adb8":"code","a13dfa30":"code","dc8ddf4d":"code","83c07d51":"code","4d0085e0":"code","fcaa05e3":"code","a1a0bd75":"code","c186539c":"code","c354e525":"code","600124ef":"code","9811707d":"code","84182f08":"code","298c9cf3":"code","735d8ff1":"code","47a9bfe4":"markdown","3d9bdbcd":"markdown","58eae434":"markdown","7cd9da35":"markdown","0ae8af88":"markdown","370f3448":"markdown","1fbc552b":"markdown","133dea4b":"markdown","68e3e1be":"markdown","036005f8":"markdown","aa31b246":"markdown","2dabd6a3":"markdown","a6ccb6b2":"markdown","862cdd89":"markdown","4c5f47ef":"markdown","31a442c5":"markdown","d9a255e6":"markdown","fc891bfd":"markdown","fcf7e94c":"markdown","63d84ef0":"markdown","07003274":"markdown","e22bdee3":"markdown","f735639d":"markdown","fb5d0f38":"markdown","6cbe49d2":"markdown"},"source":{"79baeca2":"#This notebook is to assess and compare existing methods for receipt OCR to construct a new process better suited to my specific problem. \n#It may use existing datasets and techniqus for comparison","ff632b28":"#Imports\nimport re\nimport cv2\nimport pytesseract\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom skimage.filters import threshold_local\nfrom PIL import Image\nfrom pytesseract import Output\nfrom prettytable import PrettyTable","ee0662ca":"#Initialise Methods\n\n#Resize image\ndef opencv_resize(image, ratio):\n    width = int(image.shape[1] * ratio)\n    height = int(image.shape[0] * ratio)\n    dim = (width, height)\n    return cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n\n#Display grey scale image\ndef plot_gray(image):\n    plt.figure(figsize=(16,10))\n    return plt.imshow(image, cmap='Greys_r')\n\n#Display RGB colour image\ndef plot_rgb(image):\n    plt.figure(figsize=(16,10))\n    return plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n\n#We will use approxPolyDP for approximating more primitive contour shape consisting of as few points as possible\n#Approximate the contour by a more primitive polygon shape\ndef approximate_contour(contour):\n    peri = cv2.arcLength(contour, True)\n    return cv2.approxPolyDP(contour, 0.032 * peri, True)\n\n#Find 4 points of receipt\ndef get_receipt_contour(contours):    \n    # loop over the contours\n    for c in contours:\n        approx = approximate_contour(c)\n        # if our approximated contour has four points, we can assume it is receipt's rectangle\n        if len(approx) == 4:\n            return approx\n        \n#Convert 4 points into lines \/ rect      \ndef contour_to_rect(contour):\n    pts = contour.reshape(4, 2)\n    rect = np.zeros((4, 2), dtype = \"float32\")\n    # top-left point has the smallest sum\n    # bottom-right has the largest sum\n    s = pts.sum(axis = 1)\n    rect[0] = pts[np.argmin(s)]\n    rect[2] = pts[np.argmax(s)]\n    # compute the difference between the points:\n    # the top-right will have the minumum difference \n    # the bottom-left will have the maximum difference\n    diff = np.diff(pts, axis = 1)\n    rect[1] = pts[np.argmin(diff)]\n    rect[3] = pts[np.argmax(diff)]\n    return rect \/ resize_ratio\n\n#Original receipt with wrapped perspective\ndef wrap_perspective(img, rect):\n    # unpack rectangle points: top left, top right, bottom right, bottom left\n    (tl, tr, br, bl) = rect\n    # compute the width of the new image\n    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n    # compute the height of the new image\n    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n    # take the maximum of the width and height values to reach\n    # our final dimensions\n    maxWidth = max(int(widthA), int(widthB))\n    maxHeight = max(int(heightA), int(heightB))\n    # destination points which will be used to map the screen to a \"scanned\" view\n    dst = np.array([\n        [0, 0],\n        [maxWidth - 1, 0],\n        [maxWidth - 1, maxHeight - 1],\n        [0, maxHeight - 1]], dtype = \"float32\")\n    # calculate the perspective transform matrix\n    M = cv2.getPerspectiveTransform(rect, dst)\n    # warp the perspective to grab the screen\n    return cv2.warpPerspective(img, M, (maxWidth, maxHeight))\n\n#Threshold image\ndef bw_scanner(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    T = threshold_local(gray, 21, offset = 5, method = \"gaussian\")\n    return (gray > T).astype(\"uint8\") * 255\n\ndef plot_gray(image):\n    plt.figure(figsize=(16,10))\n    return plt.imshow(image, cmap='Greys_r')\n\ndef plot_rgb(image):\n    plt.figure(figsize=(16,10))\n    return plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n\ndef find_amounts(text):\n    amounts = re.findall(r'\\d+\\.\\d{2}\\b', text)\n    floats = [float(amount) for amount in amounts]\n    unique = list(dict.fromkeys(floats))\n    return unique","b3d91574":"# Sample file out of the dataset\n#dummy 01 : image on white background\n#dummy 02 : image on gradient backgound\n#dummy 03 : random reciept\n#dummy 04 : random reciept\n#Hits 02 and 09\nfile_name = '\/kaggle\/input\/diveroreceiptdataset\/dummy02.jpg'\n\nimg = Image.open(file_name)\nimg.thumbnail((800,800), Image.ANTIALIAS)\nimg","3984796a":"image = cv2.imread(file_name)\n\n#Downscale image.\n#Finding receipt contour is more efficient on a small image\nresize_ratio = 500 \/ image.shape[0]\noriginal = image.copy()\nimage = opencv_resize(image, resize_ratio)","b3a4f507":"# Convert to grayscale for further processing\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nplot_gray(gray)","16be849c":"blurred = cv2.GaussianBlur(gray, (5, 5), 0)\nplot_gray(blurred)","c53f9740":"# Detect white regions\nrectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))\ndilated = cv2.dilate(blurred, rectKernel)\nplot_gray(dilated)","4091ebfe":"edged = cv2.Canny(dilated, 50, 125, apertureSize=3)\nplot_gray(edged)","a8ab0bcd":"contours, hierarchy = cv2.findContours(edged, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\nimage_with_contours = cv2.drawContours(image.copy(), contours, -1, (0,255,0), 3)\nplot_rgb(image_with_contours)","8852db07":"# Get 10 largest contours\nlargest_contours = sorted(contours, key = cv2.contourArea, reverse = True)[:1]\nimage_with_largest_contours = cv2.drawContours(image.copy(), largest_contours, -1, (0,255,0), 3)\nplot_rgb(image_with_largest_contours)","5ac170c3":"get_receipt_contour(largest_contours)","363aed1a":"receipt_contour = get_receipt_contour(largest_contours)","c4583751":"image_with_receipt_contour = cv2.drawContours(image.copy(), [receipt_contour], -1, (0, 255, 0), 2)\nplot_rgb(image_with_receipt_contour)","8ab65694":"scanned = wrap_perspective(original.copy(), contour_to_rect(receipt_contour))\nplt.figure(figsize=(16,10))\nplt.imshow(scanned)","5cd7adb8":"result = bw_scanner(scanned)\nplot_gray(result)","a13dfa30":"file_name = '\/kaggle\/input\/diveroreceiptdataset\/dummy02.jpg'\n\nimg = Image.open(file_name)\nimg.thumbnail((800,800), Image.ANTIALIAS)\nimg\n","dc8ddf4d":"#Save image locally\noutput = Image.fromarray(result)\noutput.save('result.png')","83c07d51":"img\nfile_name = \"result.png\"\nimage = cv2.imread(file_name, cv2.IMREAD_GRAYSCALE) \nplot_gray(image)","4d0085e0":"d = pytesseract.image_to_data(image, output_type=Output.DICT)\n\nn_boxes = len(d['level'])\nboxes = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2RGB)\nfor i in range(n_boxes):\n    (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])    \n    boxes = cv2.rectangle(boxes, (x, y), (x + w, y + h), (0, 255, 0), 2)\n    \nplot_rgb(boxes)","fcaa05e3":"custom_config = r'--oem 3 --psm 6'\nextracted_text = pytesseract.image_to_string(image, config=custom_config)\nprint(extracted_text)","a1a0bd75":"#Lines to excluse on the receipt\nexclusion_list = [\"bank\", \"total\", \"promo\", \"vat\", \"change\", \"recyclable\"]\n\n#Words to ommit\nremove_list = [\"vit\", \"etc\"]","c186539c":"#Extract letters and numbers regex\nregex_line = []\nfor line in extracted_text.splitlines():\n    if re.search(r\"[0-9]*\\.[0-9]|[0-9]*\\,[0-9]\", line):\n        regex_line.append(line)\nprint(regex_line)","c354e525":"#Apply exclusion list\nfood_item = []\nfor eachLine in regex_line:\n    found = False\n    for exclude in exclusion_list:\n        if exclude in eachLine.lower():\n            found = True\n        \n    if found == False:\n        food_item.append(eachLine)\nprint(food_item)","600124ef":"#Word ommit\nnew_food_item_list = []\nfor item in food_item:\n    for subToRemove in remove_list:\n        item = item.replace(subToRemove, \"\")\n        item = item.replace(subToRemove.upper(), \"\")\n    new_food_item_list.append(item)\nprint(new_food_item_list)","9811707d":"#Food item cost regex\nfood_item_cost = []\nfor line in new_food_item_list:\n    line = line.replace(\",\", \".\")\n    cost = re.findall('\\d*\\.?\\d+|\\d*\\,?\\d+|',line)\n    \n    for possibleCost in cost:\n        if \".\" in possibleCost:\n            food_item_cost.append(possibleCost)\nprint(new_food_item_list)\n","84182f08":"#Remove cost price from food item\ncount = 0;\nonly_food_items = []\nfor item in new_food_item_list:\n    only_alpha = \"\"\n    for char in item:\n        if char.isalpha() or char.isspace():\n            only_alpha += char\n            \n    only_alpha = re.sub(r'(?:^| )\\w(?:$| )', ' ', only_alpha).strip()\n    only_food_items.append(only_alpha)\nprint(only_food_items)","298c9cf3":"#Removes 2 letter words from food item\n#No core food item has two letters (Most cases)\nfood = []\nfor item in only_food_items:\n    # getting splits\n    temp = item.split()\n\n    # omitting K lengths\n    res = [ele for ele in temp if len(ele) != 2]\n\n    # joining result\n    res = ' '.join(res)\n    \n    food.append(res)\nprint(food)","735d8ff1":"#Taulate Food Item and Cost\nt = PrettyTable(['Food Item', 'Cost'])\nfor counter in range (0,len(food)):\n    t.add_row([food[counter], food_item_cost[counter]])\nprint(t)","47a9bfe4":"# Text box detection","3d9bdbcd":"# 1.2. Get rid of noise with Gaussian Blur filter","58eae434":"# 1.1. Convert image to grayscale","7cd9da35":"# Apply Dilation to Detect Regions","0ae8af88":"To find the contour of receipt we use of two heuristics \/ conditions:\n\n    receipt is the largest contour whithin image\n    receipt is expected to be of a rectangular shape\n\nWe will start with the first heuristic by getting TOP 1 largest contours.\n","370f3448":"# Threshold prepare image for OCR","1fbc552b":"# Text recognition","133dea4b":"# Computer Vision: Image Pre-Processing Model Output","68e3e1be":"# Apply Canny Edge Detection","036005f8":"# Display wrapped perspecive of receipt","aa31b246":"## OCR MODEL","2dabd6a3":"Vertices have been detected at a pixel level","a6ccb6b2":"This images still has a lot of light and shading which could affect the OCR model","862cdd89":"Notes\n\nUsually pytesseract is effective only for high resolution images. \nCertain morphological operations such as dilation, erosion, OTSU binarization can help increase in pytesseract performance.","4c5f47ef":"Bounding box looks for dictionaty words","31a442c5":"# Optical Character Recognition Model Output","d9a255e6":"# Display the Image with Overlayed Contour","fc891bfd":"> It is also important to get down to just four contour points, as we will need them for perspective restoration","fcf7e94c":"# Original Input Receipt","63d84ef0":"# Step 1: Receipt Contour Detection\nIn order to find receipt contour, standart edge detection preprocessing is applied:\n\n    1.1. Convert image to grayscale\n    1.2. Apply Gaussian filter 5x5 to get rid of noise\n    1.3. Run Canny edge detector\n","07003274":"# Applying Regular Expressions and String handling to clean up raw data ","e22bdee3":"# Cropping and perspective restoration\n\nWe will make use of cv2.warpPerspective to restore perspective of the receipt.\n\n    convert contour into a rectangle-like coordinate array consisting of clockwise ordered points: top-left, top-right, bottom-right, bottom-left\n    use rectangle points to calculate destination points of the \"scanned\" view\n    feed destination points into cv2.getPerspectiveTransform to calculate transformation matrix\n    and finally use cv2.warpPerspective to restore the perspective!\n\n","f735639d":"# Detect all contours in Canny-edged image\n","fb5d0f38":"> If on a white backgroud then contours cannot be detected correctly","6cbe49d2":"This mimics a scanned image. Attempts to increase OCR detection"}}