{"cell_type":{"0fc3dbc7":"code","7813646a":"code","61a0166d":"code","974f53f1":"code","bd3da4d7":"code","7bf9d150":"code","4ba98cb3":"code","943340df":"code","6cbad706":"code","bf2c560b":"code","9c6f3f46":"code","31c2f2a9":"code","9e4283a3":"code","cb900e84":"code","24162d72":"code","949bc3df":"code","c3994307":"code","b729ade7":"code","81edd968":"code","3ce7a8f5":"code","5e46b61f":"code","64c1820f":"code","01867f7b":"code","8e4da356":"code","f75143db":"code","ca09654d":"code","8b39f783":"code","8ca76675":"markdown","f62a5246":"markdown","86bd5551":"markdown","60ce6fc4":"markdown","842cdac1":"markdown","ca3adfb0":"markdown","fd812265":"markdown","248b3ea1":"markdown","186609f7":"markdown","d7ef847a":"markdown","d1e718db":"markdown","c704b747":"markdown","f2e56140":"markdown","b6290fec":"markdown","db3b92e5":"markdown","dbd4bd61":"markdown","3f2605b8":"markdown","d90742f1":"markdown","4eb2577b":"markdown","98a9ff12":"markdown","f9a9bd5a":"markdown","51087a57":"markdown","6d1b44d3":"markdown","936547a1":"markdown","944d40f9":"markdown","5cbb0e3b":"markdown","d644efbe":"markdown","16007697":"markdown","9341f608":"markdown","c9504d5c":"markdown","be1af449":"markdown","5f979968":"markdown","71dce1d8":"markdown","54bf0cc0":"markdown","501dbd18":"markdown","01da2b5a":"markdown","a9ccca9d":"markdown","8c879fab":"markdown","272af667":"markdown","1ae7ded3":"markdown","d38ef35e":"markdown","3db827db":"markdown","c214e887":"markdown","d177b591":"markdown","82fa34a4":"markdown","0d5b5690":"markdown"},"source":{"0fc3dbc7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7813646a":"calendar = pd.read_csv(\"\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv\")","61a0166d":"calendar.head()","974f53f1":"calendar.isnull().sum()","bd3da4d7":"calendar.describe()","7bf9d150":"calendar[\"event_name_1\"].unique()","4ba98cb3":"len(calendar[\"event_name_1\"].unique())","943340df":"calendar[\"event_type_1\"].unique()","6cbad706":"calendar[\"event_name_2\"].unique()","bf2c560b":"calendar[\"event_type_2\"].unique()","9c6f3f46":"event_name = set(calendar[\"event_name_1\"].unique()) & set(calendar[\"event_name_2\"].unique())\nprint(event_name)","31c2f2a9":"event_type = set(calendar[\"event_type_1\"].unique()) & set(calendar[\"event_type_2\"].unique())\nprint(event_type)","9e4283a3":"event_name_one = calendar[\"event_name_1\"]\nevent_name_one = pd.get_dummies(event_name_one)\nevent_name_one.head()","cb900e84":"event_name_two = calendar[\"event_name_2\"]\nevent_name_two = pd.get_dummies(event_name_two)\nevent_name_two.head()","24162d72":"event_names = pd.merge(event_name_one, event_name_two, right_index=True, left_index=True)\nevent_names.head()","949bc3df":"event_names.columns","c3994307":"event_names['Easter'] = 0\nevent_names['Cinco De Mayo'] = 0\nevent_names['OrthodoxEaster'] = 0\nevent_names[\"Father's day\"] = 0","b729ade7":"for index in event_names.index:\n    if event_names.loc[index,\"Cinco De Mayo_x\"] == 1 or event_names.loc[index,\"Cinco De Mayo_y\"] == 1:\n        event_names.loc[index,\"Cinco De Mayo\"] = 1        \n    if event_names.loc[index,\"Easter_x\"] == 1 or event_names.loc[index,\"Easter_y\"] == 1:\n        event_names.loc[index,\"Easter\"] = 1    \n    if event_names.loc[index,\"Father's day_x\"] == 1 or event_names.loc[index,\"Father's day_y\"] == 1:\n        event_names.loc[index,\"Father's day\"] = 1    \n    if event_names.loc[index,\"OrthodoxEaster_x\"] == 1 or event_names.loc[index,\"OrthodoxEaster_y\"] == 1:\n        event_names.loc[index,\"OrthodoxEaster\"] = 1    \n        \nevent_names.drop('Cinco De Mayo_x', axis=1, inplace=True)\nevent_names.drop('Cinco De Mayo_y', axis=1, inplace=True)\nevent_names.drop('Easter_x', axis=1, inplace=True)\nevent_names.drop('Easter_y', axis=1, inplace=True)\nevent_names.drop(\"Father's day_x\", axis=1, inplace=True)\nevent_names.drop(\"Father's day_y\", axis=1, inplace=True)\nevent_names.drop('OrthodoxEaster_x', axis=1, inplace=True)\nevent_names.drop('OrthodoxEaster_y', axis=1, inplace=True)","81edd968":"event_names.columns","3ce7a8f5":"event_type_one = calendar[\"event_type_1\"]\nevent_type_one = pd.get_dummies(event_type_one)\nevent_type_one.head()","5e46b61f":"event_type_two = calendar[\"event_type_2\"]\nevent_type_two = pd.get_dummies(event_type_two)\nevent_type_two.head()","64c1820f":"event_types = pd.merge(event_type_one, event_type_two, right_index=True, left_index=True)\nevent_types['Cultural'] = 0\nevent_types['Religious'] = 0\nevent_types.head()","01867f7b":"for index in event_types.index:\n    if event_types.loc[index,\"Cultural_x\"] == 1 or event_types.loc[index,\"Cultural_y\"] == 1:\n        event_types.loc[index,\"Cultural\"] = 1        \n    if event_types.loc[index,\"Religious_x\"] == 1 or event_types.loc[index,\"Religious_y\"] == 1:\n        event_types.loc[index,\"Religious\"] = 1    \n        \n        \nevent_types.drop('Cultural_x', axis=1, inplace=True)\nevent_types.drop('Cultural_y', axis=1, inplace=True)\nevent_types.drop('Religious_x', axis=1, inplace=True)\nevent_types.drop('Religious_y', axis=1, inplace=True)\n\nevent_types.head()","8e4da356":"calendar = pd.concat([calendar, event_names, event_types], axis=1)\ncalendar.drop('event_name_1', axis=1, inplace=True)\ncalendar.drop('event_type_1', axis=1, inplace=True)\ncalendar.drop('event_name_2', axis=1, inplace=True)\ncalendar.drop('event_type_2', axis=1, inplace=True)","f75143db":"calendar.head()","ca09654d":"calendar.isnull().sum()","8b39f783":"calendar.to_csv('calendar_dummied.csv', index=False)","8ca76675":"Then, let's see the contents of each data.","f62a5246":"## event_name_1","86bd5551":"Thank you for reading to the last.","60ce6fc4":"If we watched carefully, we can realize that there are same contents in both name ans event.","842cdac1":"Next, let's check \"event_type_1\".","ca3adfb0":"In this notebook, I'd like to talk about one of the ways to deal with \"calendar.csv\".","fd812265":"I use \"set\" to check the duplication.","248b3ea1":"Thank you for opening this notebook!","186609f7":"# Finalize calendar","d7ef847a":"I used \"merge\". Duplicated data like Cinco De Mayo has \"_x\" or \"_y\".","d1e718db":"2 We make new feature values by using them.","c704b747":"By the way there is a question that why \"calendar.csv\" has \"event_name_2\" and \"event_type_2\".","f2e56140":"# See the contents of each data.","b6290fec":"# Loading data and check missing values","db3b92e5":"# Dummying special days and kinds.","dbd4bd61":"If one day did not adapt to any special days, its all columns are 0.","3f2605b8":"Here, I made calendar's \"event_name_1\" dummy variable. I do same thing to \"event_name_2\".","d90742f1":"1 We eliminate four columns.","4eb2577b":"I eliminated duplicated data. There is not any more \"nan\".","98a9ff12":"We can see missing values in event_name_1, event_type_1, event_name_2 and event_type_2.","f9a9bd5a":"Next, I make Cinco De Mayo, OrthodoxEaster, Easter and Father's day again.","51087a57":"If something_x or something_y had 1, something's value make 1. ","6d1b44d3":"We can see that the rate of missing value is high.","936547a1":"Below code is last action.","944d40f9":"I deal with event_type by using same way of thinking.","5cbb0e3b":"This might lead to trouble of machine learning.","d644efbe":"We can say that some day corresponds to TWO SPECIAL DAYS.","16007697":"## event_type_1","9341f608":"Let's check.","c9504d5c":"## event_name_2, event_type_2","be1af449":"Here, we choose second option.","5f979968":"There are lots of 'NaN'. Let's check the num of missing values. Here, I use \"isnull().sum()\".","71dce1d8":"To avoid the situation, we can select two actions.","54bf0cc0":"I finished loading. Then, let's check the begining of the data. Here, I use 'head()'.","501dbd18":"There is no more missing values.","01da2b5a":"# What to do in this article?\n## I preprocess \"calendar.csv\" so that we can use to Machine Learning\n# What not to do in this article?\n## I don't make a prediction using other files.","a9ccca9d":"Finally, I coalesce original data, event_name and event_types.","8c879fab":"It seems that these datas mention the kinds of special days.","272af667":"I completed making dummy variable. Next, I coalesce two data.","1ae7ded3":"There are 31 kinds of data in \"event_name_1\". It seems that they are names of special days such as 'SuperBowl' and 'ValentinesDay'.","d38ef35e":"To make special days feature values, we need to deal with \"nan\".","3db827db":"We can say that there are duplicates in event_name and event_type.","c214e887":"Then, I express if each days adapts to each special days by using 0 and 1.","d177b591":"At first, I load calendar.csv on this notebook.","82fa34a4":"In this notebook, I preprocessed calendar.csv to make special days dummy values and eliminate missing values.","0d5b5690":"It seems that the number is not few. Let's check the outline by using \"describe()\"."}}