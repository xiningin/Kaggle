{"cell_type":{"2f79bbf4":"code","c0ed678c":"code","ff0f5b0b":"code","64ccdb2d":"code","aab0ad90":"code","97711ee5":"code","3821b997":"code","620be338":"code","5de5615e":"code","57b1ff36":"code","ae049d6e":"code","c898d355":"code","22217cf2":"code","63638c3f":"markdown","61362a83":"markdown","1987cf81":"markdown","b6abe943":"markdown","b2824535":"markdown","55613d4d":"markdown","d54ad805":"markdown","a86001ef":"markdown","b95a70e7":"markdown","24643d87":"markdown","7cbeab39":"markdown","8b4a0af7":"markdown","9fd3fb59":"markdown","4aaede35":"markdown","52c18170":"markdown","3aea95b9":"markdown","e04a8c65":"markdown","8950c868":"markdown","2a92a7a4":"markdown","5f0c5e6d":"markdown"},"source":{"2f79bbf4":"!pip install tensorflow==2.0.0","c0ed678c":"import tensorflow as tf\nprint(tf.__version__)","ff0f5b0b":"#load the Mnist data\nmnist = tf.keras.datasets.mnist\n\n#Split into training and testing\n(x_train,y_train) , (x_test,y_test) = mnist.load_data()\n#Normalizing\nx_train,x_test = x_train\/255.0 , x_test\/255.0","64ccdb2d":"x_test.shape","aab0ad90":"#Build the model\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Flatten(input_shape=(28, 28))) #Shapeof our data\nmodel.add(tf.keras.layers.Dense(130,activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.2))\n#we are using softmax layer because we have to do multiclass classification\nmodel.add(tf.keras.layers.Dense(10,activation='softmax')) ","97711ee5":"#Compile the model\nmodel.compile(optimizer = 'adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])","3821b997":"r = model.fit(x_train,y_train,validation_data=(x_test, y_test), epochs=10)","620be338":"import matplotlib.pyplot as plt\n#To adjust size of Figure\nplt.rcParams['figure.figsize'] = [10,5]\n\nplt.plot(r.history['loss'],label='loss')\nplt.plot(r.history['val_loss'],label='val_loss')\nplt.legend()","5de5615e":"\nplt.plot(r.history['accuracy'],label='accuracy')\nplt.plot(r.history['val_accuracy'],label='val_accuracy')\nplt.legend()","57b1ff36":"# Evaluate the model\nprint(model.evaluate(x_test, y_test))","ae049d6e":"#Plot confusion matrix\n# Plot confusion matrix\nfrom sklearn.metrics import confusion_matrix\nimport numpy as np\nimport itertools\nplt.rcParams['figure.figsize'] = [10,7]\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n  \"\"\"\n  This function prints and plots the confusion matrix.\n  Normalization can be applied by setting `normalize=True`.\n  \"\"\"\n  if normalize:\n      cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n      print(\"Normalized confusion matrix\")\n  else:\n      print('Confusion matrix, without normalization')\n\n  print(cm)\n\n  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n  plt.title(title)\n  plt.colorbar()\n  tick_marks = np.arange(len(classes))\n  plt.xticks(tick_marks, classes, rotation=45)\n  plt.yticks(tick_marks, classes)\n\n  fmt = '.2f' if normalize else 'd'\n  thresh = cm.max() \/ 2.\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n      plt.text(j, i, format(cm[i, j], fmt),\n               horizontalalignment=\"center\",\n               color=\"white\" if cm[i, j] > thresh else \"black\")\n\n  plt.tight_layout()\n  plt.ylabel('True label')\n  plt.xlabel('Predicted label')\n  plt.show()\n\n\np_test = model.predict(x_test).argmax(axis=1)\ncm = confusion_matrix(y_test, p_test)\nplot_confusion_matrix(cm, list(range(10)))\n\n# Do these results make sense?\n# It's easy to confuse 9 <--> 4, 9 <--> 7, 2 <--> 7, etc. ","c898d355":"#Find some accurate prediction\nmp = np.where(p_test==y_test)[0]\ni = np.random.choice(mp)\nplt.imshow(x_test[i],cmap='gray')\nplt.title(\"True label: %s Predicted: %s\" % (y_test[i], p_test[i]));","22217cf2":"#Find some misclassified prediction\nmp = np.where(p_test!=y_test)[0]\ni = np.random.choice(mp)\nplt.imshow(x_test[i],cmap='gray')\nplt.title(\"True label: %s Predicted: %s\" % (y_test[i], p_test[i]));","63638c3f":"![](https:\/\/cdn-images-1.medium.com\/max\/1000\/1*2HET8vYbgkgDsAkqs1C0jQ.png)","61362a83":"# Let's evaluate the model perfomance","1987cf81":"**-> If you are newbie in Deep learning than you have to start with this basic and clean mnist dataset, here you can understand convept of neural network easily**","b6abe943":"# Building the our Neural network","b2824535":"## Mnist Data","55613d4d":"## You can change the parameters according to yours","d54ad805":"**-> Now it is inbuilt in keras, just you have to use it**","a86001ef":"#  Install tensorflow 2.0.0(Stable version)","b95a70e7":"## Lol:):) My neural network is also misclassifying the result ","24643d87":"## Lol:)) that's the reality \ud83d\ude02","7cbeab39":"# Mnist Dataset prediction using ANN(Beginner code)","8b4a0af7":"## Check the TF version","9fd3fb59":"# Check the Loss & accuracy(Plotting with Matplotlib)","4aaede35":"# Load the Mnist dataset","52c18170":"# I am putting memes because of you can learn with laughing:), upvote my kernel if you like.","3aea95b9":"**The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. **","e04a8c65":"![](https:\/\/corochann.com\/wp-content\/uploads\/2017\/02\/mnist_plot-800x600.png)","8950c868":"## Compile the Neural network","2a92a7a4":"![](https:\/\/pics.me.me\/thumb_corporate-needs-you-to-find-the-differences-between-this-picture-56774219.png)","5f0c5e6d":"## Let's fit our data into Neural network"}}