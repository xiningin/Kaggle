{"cell_type":{"978ba7d3":"code","889b97d1":"code","96b7c67e":"code","cf436b6b":"code","0ea7eeb0":"code","23778260":"code","3ed420f9":"code","b8a220e3":"code","05db2b84":"code","7cf1ef9d":"markdown","c86ef954":"markdown"},"source":{"978ba7d3":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\n\ndef weights_init(m):\n    if type(m) == nn.Linear:\n        m.weight.data.normal_(0.0, 1e-3)\n        m.bias.data.fill_(0.)\n\ndef update_lr(optimizer, lr):\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n        \n\n\n\n\n#--------------------------------\n# Device configuration\n#--------------------------------\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device: %s'%device)\n\n#--------------------------------\n# Hyper-parameters\n#--------------------------------\ninput_size = 3\nnum_classes = 10\nhidden_size = [128, 512, 512, 512, 512]\nnum_epochs = 20\nbatch_size = 200\nlearning_rate = 2e-3\nlearning_rate_decay = 0.95\nreg=0.001\nnum_training= 49000\nnum_validation =1000\nnorm_layer = None #norm_layer = 'BN'\nprint(hidden_size)","889b97d1":"#-------------------------------------------------\n# Load the CIFAR-10 dataset\n#-------------------------------------------------\n#################################################################################\n# TODO: Q3.a Choose the right data augmentation transforms with the right       #\n# hyper-parameters and put them in the data_aug_transforms variable             #\n#################################################################################\ndata_aug_transforms = []\n# *****START OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\n\n\n\n# *****END OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\nnorm_transform = transforms.Compose(data_aug_transforms+[transforms.ToTensor(),\n                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n                                     ])\ntest_transform = transforms.Compose([transforms.ToTensor(),\n                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n                                     ])\ncifar_dataset = torchvision.datasets.CIFAR10(root='datasets\/',\n                                           train=True,\n                                           transform=norm_transform,\n                                           download=True)\n\ntest_dataset = torchvision.datasets.CIFAR10(root='datasets\/',\n                                          train=False,\n                                          transform=test_transform\n                                          )\n\n#-------------------------------------------------\n# Prepare the training and validation splits\n#-------------------------------------------------\nmask = list(range(num_training))\ntrain_dataset = torch.utils.data.Subset(cifar_dataset, mask)\nmask = list(range(num_training, num_training + num_validation))\nval_dataset = torch.utils.data.Subset(cifar_dataset, mask)\n\n#-------------------------------------------------\n# Data loader\n#-------------------------------------------------\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                           batch_size=batch_size,\n                                           shuffle=True)\n\nval_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n                                           batch_size=batch_size,\n                                           shuffle=False)\n\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                          batch_size=batch_size,\n                                          shuffle=False)","96b7c67e":"def make_layers(layers, hidden_layers, batch_norm=False):\n    in_channels = 3\n    for v in hidden_layers:\n        conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n        if batch_norm:\n            layers += [conv2d, nn.BatchNorm2d(v), nn.MaxPool2d(kernel_size=2, stride=2), nn.ReLU(inplace=True)]\n        else:\n            layers += [conv2d, nn.MaxPool2d(kernel_size=2, stride=2), nn.ReLU(inplace=True)]\n        in_channels = v\n    layers += [nn.Linear(512,10)]\n    return nn.Sequential(*layers)\n\n#-------------------------------------------------\n# Convolutional neural network (Q1.a and Q2.a)\n# Set norm_layer for different networks whether using batch normalization\n#-------------------------------------------------\nclass ConvNet(nn.Module):\n    def __init__(self, input_size, hidden_layers, num_classes, norm_layer=None):\n        super(ConvNet, self).__init__()\n        #################################################################################\n        # TODO: Initialize the modules required to implement the convolutional layer    #\n        # described in the exercise.                                                    #\n        # For Q1.a make use of conv2d and relu layers from the torch.nn module.         #\n        # For Q2.a make use of BatchNorm2d layer from the torch.nn module.              #\n        # For Q3.b Use Dropout layer from the torch.nn module.                          #\n        #################################################################################\n        layers = []\n        self.layers = make_layers(layers, hidden_layers, batch_norm=False)\n        # *****END OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\n\n    def forward(self, x):\n        #################################################################################\n        # TODO: Implement the forward pass computations                                 #\n        #################################################################################\n        # *****START OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\n        out = self.layers[:-1](x)\n        out = torch.flatten(out, 1)\n        out = self.layers[-1](out)\n\n        # *****END OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\n        return out","cf436b6b":"class EarlyStopping:\n    def __init__(self, patience=7, mode=\"max\", delta=0.0001):\n        self.patience = patience\n        self.counter = 0\n        self.mode = mode\n        self.best_score = None\n        self.early_stop = False\n        self.delta = delta\n        if self.mode == \"min\":\n            self.val_score = np.Inf\n        else:\n            self.val_score = -np.Inf\n\n    def __call__(self, epoch_score, model, model_path):\n\n        if self.mode == \"min\":\n            score = -1.0 * epoch_score\n        else:\n            score = np.copy(epoch_score)\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(epoch_score, model, model_path)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(epoch_score, model, model_path)\n            self.counter = 0\n\n    def save_checkpoint(self, epoch_score, model, model_path):\n        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n            print('Validation score improved ({} --> {}). Saving model!'.format(self.val_score, epoch_score))\n            torch.save(model.state_dict(), model_path)\n        self.val_score = epoch_score","0ea7eeb0":"#-------------------------------------------------\n# Calculate the model size (Q1.b)\n# if disp is true, print the model parameters, otherwise, only return the number of parameters.\n#-------------------------------------------------\ndef PrintModelSize(model, disp=True):\n    #################################################################################\n    # TODO: Implement the function to count the number of trainable parameters in   #\n    # the input model. This useful to track the capacity of the model you are       #\n    # training                                                                      #\n    #################################################################################\n    # *****START OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\n    model_sz = sum(p.numel() for p in model.parameters())\n    if disp:\n        print(f'Number of Parameters: {model_sz}')\n    # *****END OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\n    return model_sz\n\n\n\n\n#-------------------------------------------------\n# Calculate the model size (Q1.c)\n# visualize the convolution filters of the first convolution layer of the input model\n#-------------------------------------------------\ndef VisualizeFilter(model):\n    #################################################################################\n    # TODO: Implement the functiont to visualize the weights in the first conv layer#\n    # in the model. Visualize them as a single image of stacked filters.            #\n    # You can use matlplotlib.imshow to visualize an image in python                #\n    #################################################################################\n    # *****START OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\n    conv1 = model.layers[0].weight.data.cpu().numpy() \n    for i in range(6):\n        plt.figure(figsize = (8,0.5))\n        for j in range(16):         \n            plt.subplot(i+1,16,j+1); plt.imshow(conv1[i*6+j, ...], vmin=0, vmax=255)\n            plt.axis('off')\n            plt.axis(\"tight\")\n        plt.show()  \n\n    # *****END OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****","23778260":"#======================================================================================\n# Q1.a: Implementing convolutional neural net in PyTorch\n#======================================================================================\n# In this question we will implement a convolutional neural networks using the PyTorch\n# library.  Please complete the code for the ConvNet class evaluating the model\n#--------------------------------------------------------------------------------------\nmodel = ConvNet(input_size, hidden_size, num_classes, norm_layer=norm_layer).to(device)\n# Q2.a - Initialize the model with correct batch norm layer\n\nmodel.apply(weights_init)\n# Print the model\nprint(model)\n# Print model size\n#======================================================================================\n# Q1.b: Implementing the function to count the number of trainable parameters in the model\n#======================================================================================\nPrintModelSize(model)\n#======================================================================================\n# Q1.a: Implementing the function to visualize the filters in the first conv layers.\n# Visualize the filters before training\n#======================================================================================\nVisualizeFilter(model)\n\n\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=reg)\n\n# Train the model\nlr = learning_rate\ntotal_step = len(train_loader)\nloss_train = []\nloss_val = []\nbest_accuracy = None\naccuracy_val = []\nbest_model = type(model)(input_size, hidden_size, num_classes, norm_layer=norm_layer) # get a new instance\n#best_model = ConvNet(input_size, hidden_size, num_classes, norm_layer=norm_layer)\nes = EarlyStopping(patience=2, mode=\"max\")\n\nfor epoch in range(num_epochs):\n\n    model.train()\n\n    loss_iter = 0\n    for i, (images, labels) in enumerate(train_loader):\n        # Move tensors to the configured device\n        images = images.to(device)\n        labels = labels.to(device)\n\n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        loss_iter += loss.item()\n        \n        if (i+1) % 100 == 0:\n            print ('Epoch [{}\/{}], Step [{}\/{}], Loss: {:.4f}'\n                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n            \n    loss_train.append(loss_iter\/(len(train_loader)*batch_size))\n\n    \n    # Code to update the lr\n    lr *= learning_rate_decay\n    update_lr(optimizer, lr)\n    \n        \n    model.eval()\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        loss_iter = 0\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            loss = criterion(outputs, labels)\n            loss_iter += loss.item()\n        \n        loss_val.append(loss_iter\/(len(val_loader)*batch_size))\n\n        accuracy = 100 * correct \/ total\n        accuracy_val.append(accuracy)\n        print('Validation accuracy is: {} %'.format(accuracy))\n        #################################################################################\n        # TODO: Q2.b Implement the early stopping mechanism to save the model which has #\n        # the model with the best validation accuracy so-far (use best_model).          #\n        #################################################################################\n\n        # *****START OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\n\n        es(accuracy, model, 'pytorch_model.bin')   \n        if es.early_stop:\n            print(\"Early stopping\")             \n            break\n\n        # *****END OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\n\n    \n\n# Test the model\n# In test phase, we don't need to compute gradients (for memory efficiency)\nmodel.eval()\n\n\n\nplt.figure(2)\nplt.plot(loss_train, 'r', label='Train loss')\nplt.plot(loss_val, 'g', label='Val loss')\nplt.legend()\nplt.show()\n\nplt.figure(3)\nplt.plot(accuracy_val, 'r', label='Val accuracy')\nplt.legend()\nplt.show()\n\n\n\n#################################################################################\n# TODO: Q2.b Implement the early stopping mechanism to load the weights from the#\n# best model so far and perform testing with this model.                        #\n#################################################################################\n# *****START OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\nmodel = ConvNet(input_size, hidden_size, num_classes, norm_layer=norm_layer).to(device)\nmodel.load_state_dict(torch.load(f\"pytorch_model.bin\"))\nmodel.eval()\n# *****END OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\n\n#Compute accuracy on the test set\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        if total == 1000:\n            break\n\n    print('Accuracy of the network on the {} test images: {} %'.format(total, 100 * correct \/ total))\n\n\n\n# Q1.c: Implementing the function to visualize the filters in the first conv layers.\n# Visualize the filters before training\nVisualizeFilter(model)\n\n\n\n# Save the model checkpoint\n#torch.save(model.state_dict(), 'model.ckpt')","3ed420f9":"import torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import models\nimport torchvision.transforms as transforms\n\nimport matplotlib.pyplot as plt\n\ndef weights_init(m):\n    if type(m) == nn.Linear:\n        m.weight.data.normal_(0.0, 1e-3)\n        m.bias.data.fill_(0.)\n\ndef update_lr(optimizer, lr):\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n\n#--------------------------------\n# Device configuration\n#--------------------------------\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device: %s'%device)\n\n#--------------------------------\n# Hyper-parameters\n#--------------------------------\ninput_size = 32 * 32 * 3\nlayer_config= [512, 256]\nnum_classes = 10\nnum_epochs = 30\nbatch_size = 200\nlearning_rate = 1e-3\nlearning_rate_decay = 0.99\nreg=0#0.001\nnum_training= 49000\nnum_validation =1000\nfine_tune = False\npretrained=False","b8a220e3":"#-------------------------------------------------\n# Load the CIFAR-10 dataset\n#-------------------------------------------------\ndata_aug_transforms = [transforms.RandomHorizontalFlip(p=0.5)]#, transforms.RandomGrayscale(p=0.05)]\n###############################################################################\n# TODO: Add to data_aug_transforms the best performing data augmentation      #\n# strategy and hyper-parameters as found out in Q3.a                          #\n###############################################################################\n\nnorm_transform = transforms.Compose(data_aug_transforms+[transforms.ToTensor(),\n                                     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n                                     ]) #Need to preserve the normalization values of the pre-trained model\ncifar_dataset = torchvision.datasets.CIFAR10(root='datasets\/',\n                                           train=True,\n                                           transform=norm_transform,\n                                           download=True)\n\ntest_dataset = torchvision.datasets.CIFAR10(root='datasets\/',\n                                          train=False,\n                                          transform=norm_transform\n                                          )\n#-------------------------------------------------\n# Prepare the training and validation splits\n#-------------------------------------------------\nmask = list(range(num_training))\ntrain_dataset = torch.utils.data.Subset(cifar_dataset, mask)\nmask = list(range(num_training, num_training + num_validation))\nval_dataset = torch.utils.data.Subset(cifar_dataset, mask)\n\n#-------------------------------------------------\n# Data loader\n#-------------------------------------------------\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                           batch_size=batch_size,\n                                           shuffle=True)\n\nval_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n                                           batch_size=batch_size,\n                                           shuffle=False)\n\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                          batch_size=batch_size,\n                                          shuffle=False)","05db2b84":"def set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False\n            \n\nclass VggModel(nn.Module):\n    def __init__(self, n_class, fine_tune, pretrained=True):\n        super(VggModel, self).__init__()\n        #################################################################################\n        # TODO: Build the classification network described in Q4 using the              #\n        # models.vgg11_bn network from torchvision model zoo as the feature extraction  #\n        # layers and two linear layers on top for classification. You can load the      #\n        # pretrained ImageNet weights based on the pretrained flag. You can enable and  #\n        # disable training the feature extraction layers based on the fine_tune flag.   #\n        #################################################################################\n        # *****START OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\n        \n        backbone = torchvision.models.vgg11_bn(pretrained)       \n        self.backbone = backbone.features\n        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096, bias=True),\n            nn.BatchNorm1d(4096),\n            nn.ReLU(),\n            nn.Linear(4096, n_class, bias=True)\n        )        \n\n        # *****END OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\n\n    def forward(self, x):\n        #################################################################################\n        # TODO: Implement the forward pass computations                                 #\n        #################################################################################\n        # *****START OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\n\n        x = self.backbone(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        out = self.classifier(x)\n\n        # *****END OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\n        return out\n\n# Initialize the model for this run\nmodel = VggModel(num_classes, fine_tune, pretrained)\n\nif (pretrained==False):\n    model.apply(weights_init)\n\n# Print the model we just instantiated\nprint(model)\n\n#################################################################################\n# TODO: Only select the required parameters to pass to the optimizer. No need to#\n# update parameters which should be held fixed (conv layers).                   #\n#################################################################################\nprint(\"Params to learn:\")\nif fine_tune:\n    params_to_update = []\n    # *****START OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\n    params_to_update=model.classifier.parameters()\n    for name, param in model.classifier.named_parameters():\n        print('\\t', name)\n    \n    \n    # *****END OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\nelse:\n    params_to_update = model.parameters()\n    for name,param in model.named_parameters():\n        if param.requires_grad == True:\n            print(\"\\t\",name)\n\n\nmodel.to(device)\n\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params_to_update, lr=learning_rate, weight_decay=reg)\n\n# Train the model\nlr = learning_rate\ntotal_step = len(train_loader)\nloss_train = []\nloss_val = []\nbest_accuracy = None\naccuracy_val = []\nbest_model = type(model)(num_classes, fine_tune, pretrained) # get a new instance\n\nes = EarlyStopping(patience=2, mode=\"max\")\nfor epoch in range(num_epochs):\n\n    model.train()\n\n    loss_iter = 0\n    for i, (images, labels) in enumerate(train_loader):\n        # Move tensors to the configured device\n        images = images.to(device)\n        labels = labels.to(device)\n\n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        loss_iter += loss.item()\n\n        if (i+1) % 100 == 0:\n            print ('Epoch [{}\/{}], Step [{}\/{}], Loss: {:.4f}'\n                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n\n    loss_train.append(loss_iter\/(len(train_loader)*batch_size))\n\n\n    # Code to update the lr\n    lr *= learning_rate_decay\n    update_lr(optimizer, lr)\n    \n    \n    model.eval()\n    with torch.no_grad():\n        correct = 0\n        total = 0\n        loss_iter = 0\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            loss = criterion(outputs, labels)\n            loss_iter += loss.item()\n            \n        loss_val.append(loss_iter\/(len(val_loader)*batch_size))\n\n        accuracy = 100 * correct \/ total\n        accuracy_val.append(accuracy)\n        \n        print('Validataion accuracy is: {} %'.format(accuracy))\n        #################################################################################\n        # TODO: Q2.b Use the early stopping mechanism from previous questions to save   #\n        # the model with the best validation accuracy so-far (use best_model).          #\n        #################################################################################\n\n        # *****START OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\n        es(accuracy, model, 'pytorch_model.bin')   \n        if es.early_stop:\n            print(\"Early stopping\")             \n            break\n\n        # *****END OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\n\n    \n\n# Test the model\n# In test phase, we don't need to compute gradients (for memory efficiency)\nmodel.eval()\n\n\nplt.figure(2)\nplt.plot(loss_train, 'r', label='Train loss')\nplt.plot(loss_val, 'g', label='Val loss')\nplt.legend()\nplt.show()\n\nplt.figure(3)\nplt.plot(accuracy_val, 'r', label='Val accuracy')\nplt.legend()\nplt.show()\n\n\n\n#################################################################################\n# TODO: Use the early stopping mechanism from previous question to load the     #\n# weights from the best model so far and perform testing with this model.       #\n#################################################################################\n# *****START OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\nmodel = VggModel(num_classes, fine_tune, pretrained).to(device)\nmodel.load_state_dict(torch.load(f\"pytorch_model.bin\"))\nmodel.eval()\n\n# *****END OF YOUR CODE (DO NOT DELETE\/MODIFY THIS LINE)*****\n\n# Test the model\n# In test phase, we don't need to compute gradients (for memory efficiency)\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        if total == 1000:\n            break\n\n    print('Accuracy of the network on the {} test images: {} %'.format(total, 100 * correct \/ total))\n\n\n\n# Save the model checkpoint\n#torch.save(model.state_dict(), 'model.ckpt')","7cf1ef9d":"# Part 1","c86ef954":"# PART 4"}}