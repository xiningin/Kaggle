{"cell_type":{"959173b0":"code","7c29a224":"code","bcbc7a64":"code","2fdf8ce8":"code","e97f258e":"code","5afc95a5":"code","289d3d2c":"code","d9056c00":"code","5604850a":"code","5466d20b":"code","136d1eec":"code","8515915e":"code","32d951d3":"code","06a32e61":"code","30282ba7":"code","2133561f":"code","8d1ec664":"code","cfcf1f99":"code","3194e405":"code","e0a182d3":"code","d28758b9":"code","d7e993b7":"code","3da0500d":"code","f3155842":"code","ffe955f2":"code","745f2ca9":"code","ec8c02c9":"code","63cced8c":"code","431c80af":"code","bc5e5b86":"code","21598cb5":"code","8a1428bb":"code","07ded9fd":"code","a3d5f814":"code","bb4e208f":"code","01dd26d1":"code","5f880e4e":"code","8c612949":"code","7945eafc":"code","500ae788":"code","19c8bf1e":"code","63567c80":"code","73e43363":"code","6687ace2":"code","af921727":"code","3ca1a61a":"code","6aa2c9e3":"code","cd143182":"markdown","cedda7b1":"markdown","c361c926":"markdown","435f67fb":"markdown","7961f111":"markdown","a2656390":"markdown","2c26d1bd":"markdown","f23bc42d":"markdown","297a8d17":"markdown","e7fbc48d":"markdown","696ec572":"markdown","2b7b6a2f":"markdown","02e3fbb5":"markdown","95a14603":"markdown","e44e52da":"markdown","332994d1":"markdown","d134ab52":"markdown","ce92f55b":"markdown","82f61110":"markdown","4e64290a":"markdown","e170ad46":"markdown","cee4a965":"markdown","7750a30e":"markdown","9c260b9f":"markdown","c3b67c85":"markdown","5e57ab7c":"markdown","d6f68b28":"markdown","4ff97497":"markdown","3d96039a":"markdown","29a30ca7":"markdown","dd135ffc":"markdown","f3d87144":"markdown","9640f376":"markdown","e49012fa":"markdown","7c1a9167":"markdown","e1dd7973":"markdown","23f909dd":"markdown","218a9c9e":"markdown","9169edc1":"markdown","66b4a880":"markdown","1ecb05a4":"markdown","d1c634ff":"markdown","d4d400d5":"markdown"},"source":{"959173b0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport csv\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom scipy import stats\nfrom sklearn.model_selection import GridSearchCV\nimport statistics\nfrom xgboost import XGBClassifier","7c29a224":"# defining directory paths\ntrain_dir = \"..\/input\/train.csv\"\ntest_dir = \"..\/input\/test.csv\"","bcbc7a64":"df = pd.read_csv(train_dir)\ntest_df = pd.read_csv(test_dir)","2fdf8ce8":"df.drop([\"Ticket\"], axis = 1, inplace = True)\ntest_df.drop([\"Ticket\"], axis = 1, inplace = True)\ndf.info()\ndf.head()","e97f258e":"# checking class distribution\nprint(df[\"Survived\"].value_counts())\ndf[\"Survived\"].value_counts().plot(kind = \"pie\")","5afc95a5":"df.drop(\"PassengerId\", axis = 1, inplace = True)\ntest_df.drop(\"PassengerId\", axis = 1, inplace = True)","289d3d2c":"f,ax = plt.subplots(figsize=(15, 13))\nsns.heatmap(df.corr(), annot=True, cmap = \"Blues\", linewidths=.5, fmt= '.2f',ax = ax)\nplt.show()","d9056c00":"df_survived = df[df[\"Survived\"]==1]\ndf_notsurvived = df[df[\"Survived\"]==0]\ngb_pclass_surv = df_survived.groupby(\"Pclass\")[\"Survived\"].sum()\n#a = gb_pclass_surv.plot(kind= \"bar\")\ngb_pclass_notsurv = df_notsurvived.groupby(\"Pclass\")[\"Survived\"].count()\n#b = gb_pclass_notsurv.plot(kind= \"bar\")\n\nfig = plt.figure(figsize = (10,4))\nf1 = fig.add_subplot(1, 2, 1)\nf1.set_ylim([0,400])\nf2 = fig.add_subplot(1,2,2)\nf2.set_ylim([0,400])\ngb_pclass_surv.plot(kind= \"bar\", title = \"Survived\", ax = f1)\ngb_pclass_notsurv.plot(kind= \"bar\", title = \"Not Survived\", ax = f2);","5604850a":"sns.catplot(x = 'Pclass', y = \"Survived\", data = df, kind = \"bar\");","5466d20b":"pclass_dum = pd.get_dummies(df[\"Pclass\"])\ntest_pclass_dum = pd.get_dummies(test_df[\"Pclass\"])\n\ndf = pd.concat([df, pclass_dum], axis = 1)\ntest_df = pd.concat([test_df, test_pclass_dum], axis = 1)\n\ndf.rename({1:\"pclass1\", 2:\"pclass2\", 3:\"pclass3\"}, axis = 1, inplace = True)\ntest_df.rename({1:\"pclass1\", 2:\"pclass2\", 3:\"pclass3\"}, axis = 1, inplace = True)\n\ndf.drop([\"Pclass\"], axis = 1, inplace = True)\ntest_df.drop([\"Pclass\"], axis = 1, inplace = True)","136d1eec":"print(\"SibSp unqiue value counts :\\n\" + str(df[\"SibSp\"].value_counts()))\n\nfig = plt.figure(figsize = (15,5))\nf1 = fig.add_subplot(1, 3, 1)\nf1.set_ylim([0,700])\nf2 = fig.add_subplot(1,3,2)\nf2.set_ylim([0,700])\nf3 = fig.add_subplot(1,3, 3)\nf3.set_ylim([0,700])\ndf[\"SibSp\"].value_counts().plot(kind= \"bar\", title = \"(SibSp) Total\", ax = f1)\ndf_survived[\"SibSp\"].value_counts().plot(kind= \"bar\", title = \"(SibSp) Survived\", ax = f2)\ndf_notsurvived[\"SibSp\"].value_counts().plot(kind= \"bar\", title =  \"(SibSp) Not Survived\", ax = f3)\nplt.show()","8515915e":"print(\"Parch unique value counts : \\n\" + str(df[\"Parch\"].value_counts()))\n\nfig = plt.figure(figsize = (15,5))\nf1 = fig.add_subplot(1, 3, 1)\nf1.set_ylim([0,700])\nf2 = fig.add_subplot(1,3,2)\nf2.set_ylim([0,700])\nf3 = fig.add_subplot(1,3, 3)\nf3.set_ylim([0,700])\ndf[\"Parch\"].value_counts().plot(kind= \"bar\", title = \"(Parch) Total\", ax = f1)\ndf_survived[\"Parch\"].value_counts().plot(kind= \"bar\", title = \"(Parch) Survived\", ax = f2)\ndf_notsurvived[\"Parch\"].value_counts().plot(kind= \"bar\", title =  \"(Parch) Not Survived\", ax = f3)\nplt.show()","32d951d3":"df[\"Sex\"].replace(\"male\", 0, inplace = True)\ntest_df[\"Sex\"].replace(\"male\", 0, inplace = True)\ndf[\"Sex\"].replace(\"female\", 1, inplace = True)\ntest_df[\"Sex\"].replace(\"female\", 1, inplace = True)\n\ndf[\"Embarked\"].fillna(\"S\", inplace = True)\ntest_df[\"Embarked\"].fillna(\"S\", inplace = True)\n\npclass_dum = pd.get_dummies(df[\"Embarked\"])\ntest_pclass_dum = pd.get_dummies(test_df[\"Embarked\"])\n\ndf = pd.concat([df, pclass_dum], axis = 1)\ntest_df = pd.concat([test_df, test_pclass_dum], axis = 1)\n\ndf.rename({\"S\":\"embarked_s\", \"C\":\"embarked_c\", \"Q\":\"embarked_q\"}, axis = 1, inplace = True)\ntest_df.rename({\"S\":\"embarked_s\", \"C\":\"embarked_c\", \"Q\":\"embarked_q\"}, axis = 1, inplace = True)\n\ndf.drop([\"Embarked\"], axis = 1, inplace = True)\ntest_df.drop([\"Embarked\"], axis = 1, inplace = True)","06a32e61":"df[\"n_fam_mem\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\ntest_df[\"n_fam_mem\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\ndf_survived[\"n_fam_mem\"] = df_survived[\"SibSp\"] + df_survived[\"Parch\"]\ndf_notsurvived[\"n_fam_mem\"] = df_notsurvived[\"SibSp\"] + df_notsurvived[\"Parch\"]\n\nfig = plt.figure(figsize = (15,5))\nf1 = fig.add_subplot(1, 3, 1)\nf1.set_ylim([0,600])\nf2 = fig.add_subplot(1,3,2)\nf2.set_ylim([0,600])\nf3 = fig.add_subplot(1,3, 3)\nf3.set_ylim([0,600])\n\ndf[\"n_fam_mem\"].value_counts().plot(kind = \"bar\", title = \"all\", ax = f1)\ndf_survived[\"n_fam_mem\"].value_counts().plot(kind = \"bar\", title = \"Survived\", ax = f2)\ndf_notsurvived[\"n_fam_mem\"].value_counts().plot(kind = \"bar\", title = \"Not Survived\", ax = f3);","30282ba7":"def create_family_ranges(df):\n    familysize = []\n    for members in df[\"n_fam_mem\"]:\n        if members == 1:\n            familysize.append(1)\n        elif members == 2:\n            familysize.append(2)\n        elif members>2 and members<=4:\n            familysize.append(3)\n        elif members > 4:\n            familysize.append(4)\n    return familysize\n\nfamsize = create_family_ranges(df)\ndf[\"familysize\"] = famsize\n\ntest_famsize = create_family_ranges(test_df)\ntest_df[\"familysize\"] = test_famsize","2133561f":"fsizedummies = pd.get_dummies(df[\"familysize\"])\ntest_fsizedummies = pd.get_dummies(test_df[\"familysize\"])\n\ndf = pd.concat([df, fsizedummies], axis = 1)\ntest_df = pd.concat([test_df, test_fsizedummies], axis = 1)\n\ndf.rename({1:\"fam_single\",2:\"fam_small\",3:\"fam_medium\", 4:\"fam_big\"}, axis = 1, inplace = True)\ntest_df.rename({1:\"fam_single\",2:\"fam_small\",3:\"fam_medium\", 4:\"fam_big\"}, axis = 1, inplace = True)","8d1ec664":"df.head()","cfcf1f99":"reg_df = df.drop([\"Survived\", \"Name\", \"Cabin\"], axis = 1)\nreg_df_test = test_df.drop([\"Name\", \"Cabin\"], axis = 1)\n    \nage_reg_df = reg_df[reg_df[\"Age\"].isna() == False]\nage_reg_df_test = reg_df_test[reg_df_test[\"Age\"].isna() == False]\n\nnew_age_df = age_reg_df.append(age_reg_df_test)\n    \nnew_age_X = new_age_df.drop([\"Age\"], axis = 1)\nnew_age_y = new_age_df[\"Age\"]\n\nnew_age_X[\"Fare\"].fillna(df[\"Fare\"].median(), inplace = True)\n\nlinear_reg_model = LinearRegression().fit(new_age_X, new_age_y)","3194e405":"# get indexes of rows that have NaN value\ndef get_age_indexes_to_replace(df):\n    age_temp_list = df[\"Age\"].values.tolist()\n    indexes_age_replace = []\n    age_temp_list = [str(x) for x in age_temp_list]\n    for i, item in enumerate(age_temp_list):\n        if item == \"nan\":\n            indexes_age_replace.append(i)\n    return indexes_age_replace\n\nindexes_to_replace_main = get_age_indexes_to_replace(df)\nindexes_to_replace_test = get_age_indexes_to_replace(test_df)\n\n# make predictions on the missing values\ndef linear_age_predictions(reg_df, indexes_age_replace):\n    reg_df_temp = reg_df.drop([\"Age\"], axis = 1)\n    age_predictions = []\n    for i in indexes_age_replace:\n        x = reg_df_temp.iloc[i]\n        x = np.array(x).reshape(1,-1)\n        pred = linear_reg_model.predict(x)\n        age_predictions.append(pred)\n    return age_predictions\n\nage_predictions_main = linear_age_predictions(reg_df, indexes_to_replace_main)\nage_predictions_test = linear_age_predictions(reg_df_test, indexes_to_replace_test)\n\n# fill the missing values with predictions\ndef fill_age_nan(df, indexes_age_replace, age_predictions):\n    for i, item in enumerate(indexes_age_replace):\n        df[\"Age\"][item] =  age_predictions[i]\n    return df\n\ndf = fill_age_nan(df, indexes_to_replace_main, age_predictions_main)\ndf_test = fill_age_nan(test_df, indexes_to_replace_test, age_predictions_test)","e0a182d3":"def age_to_int(df):\n    agelist = df[\"Age\"].values.tolist()\n    for i in range(len(agelist)):\n        if agelist[i] < 14: #children\n            agelist[i] = 0\n        elif agelist[i] >= 14 and agelist[i] < 25: #youth\n            agelist[i] = 1\n        elif agelist[i]>=25 and agelist[i]<60:# adult\n            agelist[i] = 2\n        elif agelist[i]>=60:# senior\n            agelist[i] = 3\n    ageint = pd.DataFrame(agelist)\n    return ageint","d28758b9":"ageint = age_to_int(df)\ndf[\"Ageint\"] = ageint\ndf.drop(\"Age\", axis = 1, inplace = True)\n\ntest_ageint = age_to_int(test_df)\ntest_df[\"Ageint\"] = test_ageint\ntest_df.drop(\"Age\", axis = 1, inplace = True)","d7e993b7":"fig = plt.figure(figsize = (15,5))\nf1 = fig.add_subplot(1, 3, 1)\nf1.set_ylim([0,400])\nf2 = fig.add_subplot(1,3,2)\nf2.set_ylim([0,400])\ndf[\"Ageint\"][df[\"Survived\"] == 1].value_counts().plot(kind = \"pie\", title = \"Survived\", ax = f1)\ndf[\"Ageint\"][df[\"Survived\"] == 0].value_counts().plot(kind = \"pie\", title = \"Not Survived\", ax = f2);","3da0500d":"test_df[\"Fare\"].fillna(test_df[\"Fare\"].median(), inplace = True)\n\ndf[\"actual_fare\"] = df[\"Fare\"]\/df[\"n_fam_mem\"]\n\ntest_df[\"actual_fare\"] = test_df[\"Fare\"]\/test_df[\"n_fam_mem\"]\n\ndf[\"actual_fare\"].plot()\ndf[\"actual_fare\"].describe()","f3155842":"def conv_fare_ranges(df): \n    fare_ranges = []\n    for fare in df[\"actual_fare\"]:\n        if fare < 7:\n            fare_ranges.append(0)\n        elif fare >=7 and fare < 14:\n            fare_ranges.append(1)\n        elif fare >=14 and fare < 30:\n            fare_ranges.append(2)\n        elif fare >=30 and fare < 50:\n            fare_ranges.append(3)\n        elif fare >=50:\n            fare_ranges.append(4)\n    return fare_ranges\n        \nfare_ranges = conv_fare_ranges(df)\ndf[\"fare_ranges\"] = fare_ranges\n\ntest_fare_ranges = conv_fare_ranges(test_df)\ntest_df[\"fare_ranges\"] = test_fare_ranges","ffe955f2":"df_nonsurv_fare = df[df[\"Survived\"]==0]\ndf_surv_fare = df[df[\"Survived\"]==1]\n\nfig = plt.figure(figsize = (15,5))\nf1 = fig.add_subplot(1, 3, 1)\nf1.set_ylim([0,500])\nf2 = fig.add_subplot(1,3,2)\nf2.set_ylim([0,500])\nf3 = fig.add_subplot(1,3, 3)\nf3.set_ylim([0,500])\n\ndf[\"fare_ranges\"].value_counts().plot(kind=\"bar\", title = \"Fare Ranges all\", ax = f1)\ndf_surv_fare[\"fare_ranges\"].value_counts().plot(kind=\"bar\", title =  \"Survived\", ax = f2)\ndf_nonsurv_fare[\"fare_ranges\"].value_counts().plot(kind=\"bar\", title = \"Not Survived\", ax = f3);","745f2ca9":"df[\"Cabin\"].fillna(\"unknown\", inplace = True)\ntest_df[\"Cabin\"].fillna(\"unknown\", inplace = True)","ec8c02c9":"cabins = [i[0]  if i!= 'unknown' else 'unknown' for i in df['Cabin']]\ntest_cabins = [i[0]  if i!= 'unknown' else 'unknown' for i in test_df['Cabin']]\n\ndf.drop([\"Cabin\"], axis = 1, inplace = True)\ntest_df.drop([\"Cabin\"], axis = 1, inplace = True)\n\ndf[\"cabintype\"] = cabins\ntest_df[\"cabintype\"] = test_cabins","63cced8c":"fig = plt.figure(figsize = (15,5))\nf1 = fig.add_subplot(1, 3, 1)\nf1.title.set_text('Upper class')\nf2 = fig.add_subplot(1,3,2)\nf2.title.set_text('Middle class')\nf3 = fig.add_subplot(1,3, 3)\nf3.title.set_text('Lower class')\nsns.catplot(y=\"pclass1\",x=\"cabintype\",data = df, kind = \"bar\",order = ['A','B','C','D','E','F','G','unknown'], ax = f1)\nsns.catplot(y=\"pclass2\",x=\"cabintype\",data = df, kind = \"bar\",order = ['A','B','C','D','E','F','G','unknown'], ax = f2)\nsns.catplot(y=\"pclass3\",x=\"cabintype\",data = df, kind = \"bar\",order = ['A','B','C','D','E','F','G','unknown'], ax = f3)\nplt.close(2)\nplt.close(3)\nplt.close(4)","431c80af":"sns.catplot(y=\"Survived\",x=\"cabintype\",data = df, kind = \"bar\",order = ['A','B','C','D','E','F','G','unknown']);","bc5e5b86":"df.drop([\"cabintype\"], axis = 1, inplace = True)\ntest_df.drop([\"cabintype\"], axis = 1, inplace = True)","21598cb5":"def name_to_int(df):\n    name = df[\"Name\"].values.tolist()\n    namelist = []\n    for i in name:\n        index = 1\n        inew = i.split()\n        if inew[0].endswith(\",\"):\n            index = 1\n        elif inew[1].endswith(\",\"):\n            index = 2\n        elif inew[2].endswith(\",\"):\n            index = 3\n        namelist.append(inew[index])\n        \n    titlelist = []\n    \n    for i in range(len(namelist)): \n        titlelist.append(namelist[i])\n    return titlelist","8a1428bb":"titlelist = name_to_int(df)\ndf[\"titles\"] = titlelist\ndf[\"titles\"].value_counts()\ntesttitlelist = name_to_int(test_df)\ntest_df[\"titles\"] = testtitlelist\ndf[\"titles\"].value_counts()","07ded9fd":"df[\"titles\"].replace([\"Jonkheer.\",\"the\",\"Don.\",\"Capt.\",\"Sir.\",\"Col.\",\"Major.\",\"Dr.\",\"Rev.\"], \"sometitle\", inplace = True)\ntest_df[\"titles\"].replace([\"Jonkheer.\",\"the\",\"Don.\",\"Capt.\",\"Sir.\",\"Col.\",\"Major.\",\"Dr.\",\"Rev.\",\"Dona.\"],\"sometitle\", inplace = True)\n\ndf[\"titles\"].replace([\"Mlle.\",\"Lady.\",\"Mme.\",\"Ms.\"],\"Miss.\", inplace = True)\ntest_df[\"titles\"].replace([\"Mlle.\",\"Lady.\",\"Mme.\",\"Ms.\"],\"Miss.\", inplace = True)\n\nplot = sns.catplot(y=\"Survived\",x=\"titles\",data = df, kind = \"bar\",order = [\"Mr.\",\"Miss.\",\"Mrs.\",\"Master.\",\"sometitle\"])\nplot.set_ylabels(\"Survival Probability\")","a3d5f814":"df[\"titles\"].replace([\"Mr.\", \"Miss.\", \"Mrs.\", \"Master.\",\"sometitle\"],[0,1,2,3,4], inplace = True)\ndf[\"titles\"].astype(\"int64\")\n\ntest_df[\"titles\"].replace([\"Mr.\", \"Miss.\", \"Mrs.\", \"Master.\", \"sometitle\"],[0,1,2,3,4], inplace = True)\ntest_df[\"titles\"].astype(\"int64\")\n\ndf.drop([\"Name\"], axis = 1, inplace = True)\ntest_df.drop([\"Name\"], axis = 1, inplace = True)","bb4e208f":"df.drop([\"Fare\",\"n_fam_mem\",\"actual_fare\"], axis = 1, inplace = True)\ntest_df.drop([\"Fare\",\"n_fam_mem\",\"actual_fare\"], axis = 1, inplace = True)","01dd26d1":"df.info()","5f880e4e":"labels = df[\"Survived\"]\ndata = df.drop(\"Survived\", axis = 1)","8c612949":"final_clf = None\nclf_names = [\"Logistic Regression\", \"KNN(3)\", \"XGBoost Classifier\", \"Random forest classifier\", \"Decision Tree Classifier\",\n            \"Gradient Boosting Classifier\", \"Support Vector Machine\"]","7945eafc":"classifiers = []\nscores = []\nfor i in range(10):\n    \n    X_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size = 0.1)\n    tempscores = []\n    \n    # logistic Regression\n    lr_clf = LogisticRegression()\n    lr_clf.fit(X_train, Y_train)\n    tempscores.append((lr_clf.score(X_test, Y_test))*100)\n    \n    # KNN n_neighbors = 3\n    knn3_clf = KNeighborsClassifier(n_neighbors = 3)\n    knn3_clf.fit(X_train, Y_train)\n    tempscores.append((knn3_clf.score(X_test, Y_test))*100)\n\n    # XGBoost\n    xgbc = XGBClassifier(n_estimators=15, seed=41)\n    xgbc.fit(X_train, Y_train)\n    tempscores.append((xgbc.score(X_test, Y_test))*100)\n\n    # Random Forest\n    rf_clf = RandomForestClassifier(n_estimators = 100)\n    rf_clf.fit(X_train, Y_train)\n    tempscores.append((rf_clf.score(X_test, Y_test))*100)\n\n    # Decision Tree\n    dt_clf = DecisionTreeClassifier()\n    dt_clf.fit(X_train, Y_train)\n    tempscores.append((dt_clf.score(X_test, Y_test))*100)\n\n    # Gradient Boosting \n    gb_clf = GradientBoostingClassifier()\n    gb_clf.fit(X_train, Y_train)\n    tempscores.append((gb_clf.score(X_test, Y_test))*100)\n\n    #SVM\n    svm_clf = SVC(gamma = \"scale\")\n    svm_clf.fit(X_train, Y_train)\n    tempscores.append((svm_clf.score(X_test, Y_test))*100)\n    \n    scores.append(tempscores)","500ae788":"scores = np.array(scores)\nclfs = pd.DataFrame({\"Classifier\":clf_names})\nfor i in range(len(scores)):\n    clfs['iteration' + str(i)] = scores[i].T\n\nmeans = clfs.mean(axis = 1)\nmeans = means.values.tolist()\n\nclfs[\"Average\"] = means","19c8bf1e":"clfs.set_index(\"Classifier\", inplace = True)\nprint(\"Accuracies : \")\nclfs[\"Average\"].head(10)","63567c80":"# defining multiple SVM classifiers.\ndef create_multiple():    \n    ensembles = []\n    ensemble_scores = []\n    for i in range(5):\n        X_train, X_test, Y_train, Y_test = train_test_split(data, labels, test_size = 0.07)\n        svm_clf = SVC(gamma = \"scale\")\n        svm_clf = svm_clf.fit(X_train, Y_train)\n        ensemble_scores.append((svm_clf.score(X_test, Y_test))*100)\n        ensembles.append(svm_clf)\n    return ensembles, ensemble_scores\nSVM_ensembles, SVM_ensemble_scores = create_multiple()","73e43363":"def print_ensemble_score(ensemble_scores, model_name):    \n    e_score = 0\n    for i in range(len(ensemble_scores)):\n        e_score = e_score + ensemble_scores[i]\n    print(\"SCORE (ENSEMBLE MODELS) \" +str(model_name)+ \" : \" + str(e_score\/len(ensemble_scores)))\n    return\n\nprint_ensemble_score(SVM_ensemble_scores, \"SVM\")","6687ace2":"def per_model_prediction(ensembles):    \n    test_data = test_df\n    predictions_ensembles = []\n    for clf in ensembles:\n        temppredictions = clf.predict(test_data)\n        predictions_ensembles.append(temppredictions)\n    return predictions_ensembles","af921727":"def get_predictions_modes(predictions_ensembles):    \n    final_predictions_list = []\n    for i in range(len(predictions_ensembles[0])):\n        temp = [predictions_ensembles[0][i], predictions_ensembles[1][i], predictions_ensembles[2][i], predictions_ensembles[3][i], predictions_ensembles[4][i]]\n        final_predictions_list.append(temp)\n\n    final_predictions_list = np.array(final_predictions_list)\n    pred_modes = stats.mode(final_predictions_list, axis = 1)\n\n    final_predictions = []\n    for i in pred_modes[0]:\n        final_predictions.append(i[0])\n    \n    return final_predictions","3ca1a61a":"SVM_predictions_ensembles = per_model_prediction(SVM_ensembles)\nSVM_final_predictions = get_predictions_modes(SVM_predictions_ensembles)","6aa2c9e3":"passengerid = [892 + i for i in range(len(SVM_final_predictions))]\nsub = pd.DataFrame({'PassengerId': passengerid, 'Survived':SVM_final_predictions})\nsub.to_csv('submission.csv', index = False)","cd143182":"Now we will divide the n_fam_mem into specific ranges or type, say single person (1), small family (2), medium family(2-4) or big family(>4), ","cedda7b1":"The above figure shows that most of the people from class 3 did'nt survive while nearly equal no. of people from the 2nd class did and did not survive, while more people of the 1st class survived as compared to non survival rate, thus pclass is an important data for training the classifier.","c361c926":"Now lets check the distribution of **cabins** according to the **class**.","435f67fb":"Fare Ranges and Survival plot :","7961f111":"**Fare Ranges = less than 7 , 7-14 , 14-30 , 30-50 , more than 50 **","a2656390":"Now looking at the **Cabin** feature, it consists of a lot of missing values and values with cabin no. and type.","2c26d1bd":"Dividing the actual fare into 5 different ranges.","f23bc42d":"Converting Age to Categorical:","297a8d17":"**Now lets check the class distribution.**","e7fbc48d":"As we can see from the figure survival rate of children was more than any other age group, while the survival rate of adults and seniors was very low.","696ec572":"**ENSEMBLING MODELS**","2b7b6a2f":"Now, the columns **Sex** and **Embarked** are object type columns, thus we need to change them to numeric type.","02e3fbb5":"Plotting the survival probability will clear it.","95a14603":"**Defining and choosing the best from one of the classifiers given below : **\n1. Logistic Regression\n2. K-nearest Neighbors with n_neighbors = 3\n3. XGBoost\n4. Random Forest Classifier\n5. Decision Tree Classifier\n6. Gradient Boosting Classifier\n7. Support Vector Machine","e44e52da":"Now the data in **Fare** seems like it is the total of what the passenger paid including the fare of the other family members, so we create a new column named actual_fare i.e., the fare divided by n_fam_mem.","332994d1":"We have cleaned and processed the data, we only need to get rid of a few original columns which we used to derive new columns. we need to drop :\n(Fare, n_fam_mem, actual_fare)","d134ab52":"Next step is to define multiple classifiers and check which one works the best.","ce92f55b":"We will use the above 5 classifiers to make predictions on our test data.","82f61110":"## Performance of Different Classifiers","4e64290a":"Now checking class distribution of **pclass**, i.e., how many people from each class survived.","e170ad46":"Here we will use ensemble learning to get better results : we will train the SVM classifier for a total of 5 times on different splits of data and then use them all to find the mode of the predictions and then use that mode.","cee4a965":"Now lets check the probability of survival in accordance with the cabins.","7750a30e":"Then we will find the probability of survival by each title.","9c260b9f":"## Using Regression to predict missing Age values\nThe Age column contains a lot of missing values in both the training and the testing dataset we will deal with the missing values in the following way : \n1. Fitting a linear model on the known values of Age from both the dataframes (training and testing)\n2. Using the above model to predict the unknown values of Age on both the dataframes.","c3b67c85":"Using the **parch** and **sibsp** column we can make a new column named no. of family members onboard **(n_fam_mem)**. \nAnd visualizing results.","5e57ab7c":"NOTE - V26 : Handling missing values in AGE column using Linear Regression. ","d6f68b28":"There is no object type data left. You can check this by df.info()","4ff97497":"Now lets check the survival rate of age groups.","3d96039a":"Converting family size into dummies.","29a30ca7":"**Correlation map :**","dd135ffc":"Saving final resutls into the csv file for submission.","f3d87144":"Checking data in sibsp (sibling\/spouse) and parch(parent\/children), basically these columns gives information about how many family members the person is travelling with.","9640f376":"As we can see a lot of titles occur only one thus we will replace this by \"sometitle\"","e49012fa":"the dataset contains a lot of missing values in age and cabin columns, we will be taking care of those values later.","7c1a9167":"This clearly shows that people who have higher socioeconomic status have higher chances to survive and people with lower status have a lower chance of survival (survival rate nearly equal to 25%)","e1dd7973":"This shows that **women(Miss., Mrs)** and the **children(Master.)** have the most survival probability.","23f909dd":"But the data contains most of the values for unknown cabins thus it would be better to drop these data columns.","218a9c9e":"Here we can see that most of the upper class people got known cabins(A-E), middle class got a lot of known cabins and  very few unknown cabins while the lower class got the most unknown cabins, thus cabins directly relate to the socioeconomic status of the person.","9169edc1":"As we can see the survival probability of people with unknown cabins are much less than people with known cabins.","66b4a880":"Next, the **name** column has unique data item in every row, but each name has a title with it. We can use the title and check if it relates to something.","1ecb05a4":"Now Choosing the classifier accordingly, After training and assessing multiple times it turns out that SVM is best classifier and provides best results. We do get better results while training with the Xgboost clf but while submission SVM performs much better.","d1c634ff":"The PassengerId column only tells about the id of the passenger travelling on the ship thus it is useless for training purpose thus dropping PassengerId. ","d4d400d5":"This pclass1 is really important feature thus we will convert the Pclass column to dummy columns pclass1, pclass2, pclass3."}}