{"cell_type":{"19644e45":"code","4c087156":"code","2a28e3fd":"code","77e009c1":"markdown","fa756118":"markdown","edb4eec6":"markdown"},"source":{"19644e45":"# just following official install instruction.\n# https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/docs\/get_started.md\n!pip install openmim\n!mim install mmdet\n!git clone https:\/\/github.com\/open-mmlab\/mmdetection.git\n%cd mmdetection\n!pip install -q -e .","4c087156":"%%writefile configs\/faster_rcnn\/custom_faster_rcnn_r50_fpn.py\n\n# dataset settings\ndataset_type = 'CocoDataset'\nclasses = ('Helmet',) # Added\ndata_root = '\/kaggle\/input\/' # Modified\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True),\n    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n    dict(type='RandomFlip', flip_ratio=0.5),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(1333, 800),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(type='Normalize', **img_norm_cfg),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img']),\n        ])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=2,\n    train=dict(\n        type=dataset_type,\n        ann_file=data_root + 'nfl2021-coco-train-val-annotations\/train.json', # Modified\n        img_prefix=data_root + 'nfl2021-train-images\/train_images\/', # Modified\n        classes=classes, # Added\n        pipeline=train_pipeline),\n    val=dict(\n        type=dataset_type,\n        ann_file=data_root + 'nfl2021-coco-train-val-annotations\/valid.json', # Modified\n        img_prefix=data_root + 'nfl2021-train-images\/train_images\/', # Modified\n        classes=classes, # Added\n        pipeline=test_pipeline),\n    test=dict(\n        type=dataset_type,\n        ann_file=data_root + 'nfl2021-coco-train-val-annotations\/valid.json', # Modified\n        img_prefix=data_root + 'nfl2021-train-images\/train_images\/', # Modified\n        classes=classes, # Added\n        pipeline=test_pipeline))\nevaluation = dict(interval=1, metric='bbox')\n\n# model settings\nmodel = dict(\n    type='FasterRCNN',\n    backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch',\n        init_cfg=dict(type='Pretrained', checkpoint='torchvision:\/\/resnet50')),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        num_outs=5),\n    rpn_head=dict(\n        type='RPNHead',\n        in_channels=256,\n        feat_channels=256,\n        anchor_generator=dict(\n            type='AnchorGenerator',\n            scales=[8],\n            ratios=[0.5, 1.0, 2.0],\n            strides=[4, 8, 16, 32, 64]),\n        bbox_coder=dict(\n            type='DeltaXYWHBBoxCoder',\n            target_means=[.0, .0, .0, .0],\n            target_stds=[1.0, 1.0, 1.0, 1.0]),\n        loss_cls=dict(\n            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n    roi_head=dict(\n        type='StandardRoIHead',\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        bbox_head=dict(\n            type='Shared2FCBBoxHead',\n            in_channels=256,\n            fc_out_channels=1024,\n            roi_feat_size=7,\n            num_classes=1, # Modified\n            bbox_coder=dict(\n                type='DeltaXYWHBBoxCoder',\n                target_means=[0., 0., 0., 0.],\n                target_stds=[0.1, 0.1, 0.2, 0.2]),\n            reg_class_agnostic=False,\n            loss_cls=dict(\n                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),\n    # model training and testing settings\n    train_cfg=dict(\n        rpn=dict(\n            assigner=dict(\n                type='MaxIoUAssigner',\n                pos_iou_thr=0.7,\n                neg_iou_thr=0.3,\n                min_pos_iou=0.3,\n                match_low_quality=True,\n                ignore_iof_thr=-1),\n            sampler=dict(\n                type='RandomSampler',\n                num=256,\n                pos_fraction=0.5,\n                neg_pos_ub=-1,\n                add_gt_as_proposals=False),\n            allowed_border=-1,\n            pos_weight=-1,\n            debug=False),\n        rpn_proposal=dict(\n            nms_pre=2000,\n            max_per_img=1000,\n            nms=dict(type='nms', iou_threshold=0.7),\n            min_bbox_size=0),\n        rcnn=dict(\n            assigner=dict(\n                type='MaxIoUAssigner',\n                pos_iou_thr=0.5,\n                neg_iou_thr=0.5,\n                min_pos_iou=0.5,\n                match_low_quality=False,\n                ignore_iof_thr=-1),\n            sampler=dict(\n                type='RandomSampler',\n                num=512,\n                pos_fraction=0.25,\n                neg_pos_ub=-1,\n                add_gt_as_proposals=True),\n            pos_weight=-1,\n            debug=False)),\n    test_cfg=dict(\n        rpn=dict(\n            nms_pre=1000,\n            max_per_img=1000,\n            nms=dict(type='nms', iou_threshold=0.7),\n            min_bbox_size=0),\n        rcnn=dict(\n            score_thr=0.05,\n            nms=dict(type='nms', iou_threshold=0.5),\n            max_per_img=100)\n        # soft-nms is also supported for rcnn testing\n        # e.g., nms=dict(type='soft_nms', iou_threshold=0.5, min_score=0.05)\n    ))\n\n# optimizer\noptimizer = dict(type='SGD', lr=0.002, momentum=0.9, weight_decay=0.0001) # Modified\noptimizer_config = dict(grad_clip=None)\n# learning policy\nlr_config = dict(\n    policy='step',\n    warmup='linear',\n    warmup_iters=500,\n    warmup_ratio=0.001,\n    step=[8,]) # If you changed max_epochs, it's better to change when you decrease LR too here.\nrunner = dict(type='EpochBasedRunner', max_epochs=10) # You can set max_epochs as you want.\n\ncheckpoint_config = dict(interval=1)\n# yapf:disable\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='TextLoggerHook'),\n        # dict(type='TensorboardLoggerHook')\n    ])\n# yapf:enable\ncustom_hooks = [dict(type='NumClassCheckHook')]\n\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = 'https:\/\/download.openmmlab.com\/mmdetection\/v2.0\/faster_rcnn\/faster_rcnn_r50_fpn_mstrain_3x_coco\/faster_rcnn_r50_fpn_mstrain_3x_coco_20210524_110822-e10bd31c.pth'  # Modified\nresume_from = None\nworkflow = [('train', 1)]\n","2a28e3fd":"# training is just one line. \n# !python tools\/train.py configs\/faster_rcnn\/custom_faster_rcnn_r50_fpn.py\n\n# You can also test the model like this.\n# !python tools\/test.py configs\/faster_rcnn\/custom_faster_rcnn_r50_fpn.py YOUR_MODEL_PATH --eval bbox","77e009c1":"## Installation","fa756118":"## Setting config\n\nWhat you need to train detector is just to modify config!\n\nIn below example I use FasterRCNN as baseline, but you can use any of configs in mmdetection repository.  \nmodel zoo: https:\/\/github.com\/open-mmlab\/mmdetection\/blob\/master\/docs\/model_zoo.md  \nconfigs: https:\/\/github.com\/open-mmlab\/mmdetection\/tree\/master\/configs\n\nBut there are so many parameters and it's not easy to fing what you need to change for beginners.  \nI've annotated where I modified or added in below example, but I'll summarize what you need to do minimally.\n\n### Dataset\n1. You need to change num classes to 1.(We only need to detect only Helmet class.)\n2. You need to specify image dir and annotation path for train\/valid\/test set.\n\n### Model\n1. You need to change num classes to 1.(We only need to detect only Helmet class.)\n\n### Others\n1. You need to set pretrained model path in `load_from` because what we want to do here is finetune, not training from scratch.\n2. Also it's better to decrease LR for finetuning.\n3. You can also change `max_epochs` as you want, here I set to 1 for just demonstration.\n\nNote that original config files use inheritation system, but here I included full config in a single file.  \n(In my opinion it's easier to understand diff, but may not for others.)","edb4eec6":"## How to use mmdetection\nI've already created train images and also coco annotations.\n\n- Create image dataset  \nnotebook: https:\/\/www.kaggle.com\/bamps53\/create-image-dataset  \ndataset: https:\/\/www.kaggle.com\/bamps53\/nfl2021-train-images  \n\n- Convert ground truth to coco format(with train\/val split)  \nnotebook: https:\/\/www.kaggle.com\/bamps53\/create-coco-format-annotations-train-val  \ndataset: https:\/\/www.kaggle.com\/bamps53\/nfl2021-coco-train-val-annotations  \n\nNow it's way easy to train your own detector.  \nIn this notebook I'll introduce one of the most famous object detection library, mmdetection."}}