{"cell_type":{"db19daf0":"code","1f161a50":"code","76faeef9":"code","08a8a4ca":"code","2bf5e1a9":"code","2bdb994b":"code","1b4ed826":"code","49e1e0be":"code","e3ab1b36":"code","28ac760c":"code","274dba85":"code","7c4f945d":"code","7e623b45":"code","3cbd2ae4":"code","03923d27":"code","3912754b":"code","5984a3f9":"code","5d9ad4e9":"code","2272591b":"code","210e0a3d":"code","d7bdd4ad":"code","4bc72eda":"code","09c8d3a8":"code","385255a2":"code","5b59ac2b":"code","18e81670":"code","78bd137c":"code","e91f4a41":"code","9c21ad4d":"code","d3cb8669":"code","6aafee94":"code","5dc4d42f":"code","2a327e7f":"code","230010bc":"code","210edc5d":"markdown","02371d54":"markdown","4049bcc8":"markdown","023a63b3":"markdown","bcbe9681":"markdown","db354c37":"markdown"},"source":{"db19daf0":"# Import libraries\n","1f161a50":"from platform import python_version","76faeef9":"\nprint(python_version())","08a8a4ca":"pip install -U numpy","2bf5e1a9":"pip install opencv-python --upgrade","2bdb994b":"import os, glob, cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport torchvision\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import confusion_matrix, recall_score, f1_score,precision_score, accuracy_score\nfrom tqdm import tqdm\n \n#for reading and displaying images\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n \n%matplotlib inline\n \n# for evaluating the model\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\n \n# PyTorch libraries and modules\nimport torch\nfrom torch.autograd import Variable\nfrom torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\nfrom torch.optim import Adam, SGD\nimport os\n ","1b4ed826":"#EPOCHS = 100\nBATCH_SIZE = 8\nIMG_HEIGHT = 150\nIMG_WIDTH  = 150\n\n# cataract dataset\n\n#IMG_ROOT = '..\/input\/dataset\/dataset\/'\n#..\/input\/odir-preprocessing-augmentation\/ODIR-IMAGE\/\n#..\/input\/datacataract\/Dataset1\nIMG_ROOT = '..\/input\/datacataract2\/Dataset1\/'\nIMG_DIR = [IMG_ROOT+'Normal', IMG_ROOT+'Cataract']","49e1e0be":"cat_df = pd.DataFrame(0, \n                  columns=['paths', \n                           'cataract'],\n                  index=range(1000))\n\nfilepaths = glob.glob(IMG_ROOT + '*\/*')\n\nfor i, filepath in enumerate(filepaths):\n    filepath = os.path.split(filepath)\n    cat_df.iloc[i, 0] = filepath[0] + '\/' + filepath[1]\n    if filepath[0] == IMG_DIR[0]:    # normal\n        cat_df.iloc[i, 1] = 0\n    elif filepath[0] == IMG_DIR[1]:  # cataract\n        cat_df.iloc[i, 1] = 1","e3ab1b36":"cat_df","28ac760c":"def clahe_rgb(path, cliplimit, tilesize):\n    \n    \"\"\" \n    For RGB images, the image is first converted to the LAB format, \n    and then CLAHE is applied to the isolated L channel.\n    Input:\n      img_path: path to the image file\n      cliplimit: the high contrast limit applied to CLAHE processing; this value is often 2, 3 or 4.\n      tilesize: defines the local neighborhood for histogram equalization\n    Returns:\n      bgr: image after CLAHE processing\n    \"\"\"\n  \n    bgr = cv2.imread(path)\n    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n    lab_planes = cv2.split(lab)\n    clahe = cv2.createCLAHE(clipLimit=cliplimit,tileGridSize=(tilesize, tilesize))\n    lab_planes[0] = clahe.apply(lab_planes[0])\n    lab = cv2.merge(lab_planes)\n    bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n    return bgr","274dba85":"def equalize_clahe_color(img):\n    \"\"\"Equalize the image splitting the image applying CLAHE to each channel\n    and merging the results\n    \"\"\"\n\n    cla = cv2.createCLAHE(clipLimit=150.0)\n    channels = cv2.split(img)\n    eq_channels = []\n    for ch in channels:\n        eq_channels.append(cla.apply(ch))\n\n    eq_image = cv2.merge(eq_channels)\n    return eq_image\n","7c4f945d":"def histogram_equalization(img):\n\n    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n\n    # -----Splitting the LAB image to different channels-------------------------\n    l, a, b = cv2.split(lab)\n\n    # -----Applying CLAHE to L-channel-------------------------------------------\n    clahe = cv2.createCLAHE(clipLimit=120.0, tileGridSize=(16, 16))\n    cl = clahe.apply(l)\n\n    # -----Merge the CLAHE enhanced L-channel with the a and b channel-----------\n    limg = cv2.merge((cl, a, b))\n\n    # -----Converting image from LAB Color model to RGB model--------------------\n    final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n\n    return final ","7e623b45":"def create_datasets(cat_df, img_width, img_height):\n    \n \n    \n    \"\"\"Creating the cataract dataset from the file paths in the dataframe cat_df.\n    inputs: - cat_df _pandas dataframe_: two-column dataframe that contains the \n          path and the corresponding label for each image \n            - img_width _int_: the width of the image.\n            - img_height _int_: the height of the image.\n    outputs: - imgs _numpy array_: an array that contains all images.\n             - labels _ numpy array_ : an array that contains all labels.\n    \"\"\"\n    imgs = []\n    \n    for path in tqdm(cat_df['paths']):\n        # reading the image\n        \n        img = cv2.imread(path)\n        img = histogram_equalization(img)\n        #img  = clahe_rgb(path, cliplimit=120, tilesize=8) \n        #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n        # resizing the image\n        #img = cv2.resize(img, (img_width, img_height))\n        img = cv2.resize(img, (img_width, img_height))\n        imgs.append(img)\n        \n    imgs = np.array(imgs, dtype='float32')\n    labels = np.array(list(cat_df['cataract']), dtype='int32')\n    return imgs, labels\n\nimgs, labels = create_datasets(cat_df, IMG_WIDTH, IMG_HEIGHT)\n\n# rescaling the image\nimgs = imgs \/ 255.0","3cbd2ae4":"print(imgs[1].size)","03923d27":"# imgs[0]\nplt.imshow(imgs[0])\n","3912754b":"X = imgs\ny = labels\nkf = KFold(n_splits=5, random_state=7, shuffle=True)\nfolds = []","5984a3f9":"\nfor train_index, test_index in kf.split(X):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    folds.append({'train': (X_train, y_train), 'test': (X_test, y_test)})\n    \ndef get_dataset_from_ith_iteration(i):\n    \"\"\"\n        Parameters:\n        \n            i : represent the ith interation of K Fold, \n                i is in the range [1, 2, 3, 4, 5] \n        \n        Return:\n        \n            Return a dictionary of datasets from the ith iteration of K Fold \n            the returned dictionary have the following structure \n            {\n                'train': (X_train, y_train), \n                'test': (X_test, y_test)\n            }\n            \n        Usage:\n            \n            the following example show how to get data for train and test \n            from the 1  iteration of K Fold\n            \n            i = 1\n            data = get_data_from_ith_iteration(i)\n            X_train, y_train = data['train']\n            X_test, y_test = data['test']\n    \"\"\"\n    dataset = folds[i]\n    dataset[\"train\"] = sklearn.utils.shuffle(dataset[\"train\"][0],dataset[\"train\"][1], random_state=0)\n    dataset[\"test\"] = sklearn.utils.shuffle(dataset[\"test\"][0],dataset[\"test\"][1], random_state=1)\n\n    return dataset","5d9ad4e9":"import sklearn\ndataset = get_dataset_from_ith_iteration(1)\nimgs = dataset['train'][0]\nlabels = dataset['train'][1]       \n# plot the first 25 sheets of image data for training\nf, ax = plt.subplots(5, 5, figsize=(15,15))\nnorm_list = labels[:25]\nfor i, img in enumerate(imgs[:25]):\n    ax[i\/\/5, i%5].imshow(img)\n    ax[i\/\/5, i%5].axis('off')\n    if norm_list[i] == 0:\n        ax[i\/\/5, i%5].set_title('TrainData: Normal')\n    else:\n        ax[i\/\/5, i%5].set_title('TrainData: Cataract')\nplt.show()","2272591b":"for train_index, test_index in kf.split(X):\n    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\ni =0\nfor  train_index, test_index in kf.split(X):\n    print(\"interation\", i)\n    print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    i+= 1\n    #folds.append({'train': (X_train, y_train), 'test': (X_test, y_test)})","210e0a3d":"import torch\nimport torch.nn as nn\n\n\nclass Block(nn.Module):\n    def __init__(self, num_layers, in_channels, out_channels, identity_downsample=None, stride=1):\n        assert num_layers in [18, 34, 50, 101, 152], \"should be a a valid architecture\"\n        super(Block, self).__init__()\n        self.num_layers = num_layers\n        if self.num_layers > 34:\n            self.expansion = 4\n        else:\n            self.expansion = 1\n        # ResNet50, 101, and 152 include additional layer of 1x1 kernels\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        if self.num_layers > 34:\n            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n        else:\n            # for ResNet18 and 34, connect input directly to (3x3) kernel (skip first (1x1))\n            self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0)\n        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n        self.relu = nn.ReLU()\n        self.identity_downsample = identity_downsample\n\n    def forward(self, x):\n        identity = x\n        if self.num_layers > 34:\n            x = self.conv1(x)\n            x = self.bn1(x)\n            x = self.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        x = self.conv3(x)\n        x = self.bn3(x)\n\n        if self.identity_downsample is not None:\n            identity = self.identity_downsample(identity)\n\n        x += identity\n        x = self.relu(x)\n        return x\n\n\nclass ResNet(nn.Module):\n    def __init__(self, num_layers, block, image_channels, num_classes):\n        assert num_layers in [18, 34, 50, 101, 152], f'ResNet{num_layers}: Unknown architecture! Number of layers has ' \\\n                                                     f'to be 18, 34, 50, 101, or 152 '\n        super(ResNet, self).__init__()\n        if num_layers < 50:\n            self.expansion = 1\n        else:\n            self.expansion = 4\n        if num_layers == 18:\n            layers = [2, 2, 2, 2]\n        elif num_layers == 34 or num_layers == 50:\n            layers = [3, 4, 6, 3]\n        elif num_layers == 101:\n            layers = [3, 4, 23, 3]\n        else:\n            layers = [3, 8, 36, 3]\n        self.in_channels = 64\n        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        # ResNetLayers\n        self.layer1 = self.make_layers(num_layers, block, layers[0], intermediate_channels=64, stride=1)\n        self.layer2 = self.make_layers(num_layers, block, layers[1], intermediate_channels=128, stride=2)\n        self.layer3 = self.make_layers(num_layers, block, layers[2], intermediate_channels=256, stride=2)\n        self.layer4 = self.make_layers(num_layers, block, layers[3], intermediate_channels=512, stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * self.expansion, num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.reshape(x.shape[0], -1)\n        x = self.fc(x)\n        return x\n\n    def make_layers(self, num_layers, block, num_residual_blocks, intermediate_channels, stride):\n        layers = []\n\n        identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, intermediate_channels*self.expansion, kernel_size=1, stride=stride),\n                                            nn.BatchNorm2d(intermediate_channels*self.expansion))\n        layers.append(block(num_layers, self.in_channels, intermediate_channels, identity_downsample, stride))\n        self.in_channels = intermediate_channels * self.expansion # 256\n        for i in range(num_residual_blocks - 1):\n            layers.append(block(num_layers, self.in_channels, intermediate_channels)) # 256 -> 64, 64*4 (256) again\n        return nn.Sequential(*layers)\n\n\ndef ResNet18(img_channels=3, num_classes=1000):\n    return ResNet(18, Block, img_channels, num_classes)\n\n\ndef ResNet34(img_channels=3, num_classes=1000):\n    return ResNet(34, Block, img_channels, num_classes)\n\n#def ResNet50(img_channels=3, num_classes=1000):\n   #return ResNet(50, Block, img_channels, num_classes)\n\n\n#def ResNet101(img_channels=3, num_classes=1000):\n    #return ResNet(101, Block, img_channels, num_classes)\n","d7bdd4ad":"import torch\nimport torch.nn as nn\n\n\nclass Block(nn.Module):\n    def __init__(self, num_layers, in_channels, out_channels, identity_downsample=None, stride=1):\n        assert num_layers in [18, 34, 50, 101, 152], \"should be a a valid architecture\"\n        super(Block, self).__init__()\n        self.num_layers = num_layers\n        if self.num_layers > 34:\n            self.expansion = 4\n        else:\n            self.expansion = 1\n        # ResNet50, 101, and 152 include additional layer of 1x1 kernels\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        if self.num_layers > 34:\n            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n        else:\n            # for ResNet18 and 34, connect input directly to (3x3) kernel (skip first (1x1))\n            self.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0)\n        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n        self.relu = nn.ReLU()\n        self.identity_downsample = identity_downsample\n\n    def forward(self, x):\n        identity = x\n        if self.num_layers > 34:\n            x = self.conv1(x)\n            x = self.bn1(x)\n            x = self.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        x = self.conv3(x)\n        x = self.bn3(x)\n\n        if self.identity_downsample is not None:\n            identity = self.identity_downsample(identity)\n\n        x += identity\n        x = self.relu(x)\n        return x\n\n\nclass ResNet(nn.Module):\n    def __init__(self, num_layers, block, image_channels, num_classes):\n        assert num_layers in [18, 34, 50, 101, 152], f'ResNet{num_layers}: Unknown architecture! Number of layers has ' \\\n                                                     f'to be 18, 34, 50, 101, or 152 '\n        super(ResNet, self).__init__()\n        if num_layers < 50:\n            self.expansion = 1\n        else:\n            self.expansion = 4\n        if num_layers == 18:\n            layers = [2, 2, 2, 2]\n        elif num_layers == 34 or num_layers == 50:\n            layers = [3, 4, 6, 3]\n        elif num_layers == 101:\n            layers = [3, 4, 23, 3]\n        else:\n            layers = [3, 8, 36, 3]\n        self.in_channels = 64\n        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        # ResNetLayers\n        self.layer1 = self.make_layers(num_layers, block, layers[0], intermediate_channels=64, stride=1)\n        self.layer2 = self.make_layers(num_layers, block, layers[1], intermediate_channels=128, stride=2)\n        self.layer3 = self.make_layers(num_layers, block, layers[2], intermediate_channels=256, stride=2)\n        self.layer4 = self.make_layers(num_layers, block, layers[3], intermediate_channels=512, stride=2)\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * self.expansion, num_classes)\n        self.softmax = nn.Softmax(dim=1)\n        # Define sigmoid activation and softmax output \n        #self.sigmoid = nn.Sigmoid()\n      \n        #x = torch.nn.functional.softmax(x)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.reshape(x.shape[0], -1)\n        x = self.fc(x)\n        x = self.softmax(x)\n        #x = torch.nn.functional.softmax(x)\n        return x\n\n    def make_layers(self, num_layers, block, num_residual_blocks, intermediate_channels, stride):\n        layers = []\n\n        identity_downsample = nn.Sequential(nn.Conv2d(self.in_channels, intermediate_channels*self.expansion, kernel_size=1, stride=stride),\n                                            nn.BatchNorm2d(intermediate_channels*self.expansion))\n        layers.append(block(num_layers, self.in_channels, intermediate_channels, identity_downsample, stride))\n        self.in_channels = intermediate_channels * self.expansion # 256\n        for i in range(num_residual_blocks - 1):\n            layers.append(block(num_layers, self.in_channels, intermediate_channels)) # 256 -> 64, 64*4 (256) again\n        return nn.Sequential(*layers)\n\n\ndef ResNet18(img_channels=3, num_classes=2):\n    return ResNet(18, Block, img_channels, num_classes)\n\n\ndef ResNet34(img_channels=3, num_classes=1000):\n    return ResNet(34, Block, img_channels, num_classes)\n\ndef ResNet50(img_channels=3, num_classes=1000):\n    return ResNet(50, Block, img_channels, num_classes)\n","4bc72eda":"import torch\nimport torch.nn as nn\n\n\nclass Conv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, padding, stride=1, bias=True):\n        super(Conv2d, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1)\n        self.relu = nn.ReLU(inplace=True)\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\n\nclass Reduction_A(nn.Module):\n    # 35 -> 17\n    def __init__(self, in_channels, k, l, m, n):\n        super(Reduction_A, self).__init__()\n        self.branch_0 = Conv2d(in_channels, n, 3, stride=2, padding=0, bias=False)\n        self.branch_1 = nn.Sequential(\n            Conv2d(in_channels, k, 1, stride=1, padding=0, bias=False),\n            Conv2d(k, l, 3, stride=1, padding=1, bias=False),\n            Conv2d(l, m, 3, stride=2, padding=0, bias=False),\n        )\n        self.branch_2 = nn.MaxPool2d(3, stride=2, padding=0)\n\n    def forward(self, x):\n        x0 = self.branch_0(x)\n        x1 = self.branch_1(x)\n        x2 = self.branch_2(x)\n        return torch.cat((x0, x1, x2), dim=1) # 17 x 17 x 1024\n\n\nclass Stem(nn.Module):\n    def __init__(self, in_channels):\n        super(Stem, self).__init__()\n        self.features = nn.Sequential(\n            Conv2d(in_channels, 32, 3, stride=2, padding=0, bias=False), # 149 x 149 x 32\n            Conv2d(32, 32, 3, stride=1, padding=0, bias=False), # 147 x 147 x 32\n            Conv2d(32, 64, 3, stride=1, padding=1, bias=False), # 147 x 147 x 64\n            nn.MaxPool2d(3, stride=2, padding=0), # 73 x 73 x 64\n            Conv2d(64, 80, 1, stride=1, padding=0, bias=False), # 73 x 73 x 80\n            Conv2d(80, 192, 3, stride=1, padding=0, bias=False), # 71 x 71 x 192\n            nn.MaxPool2d(3, stride=2, padding=0), # 35 x 35 x 192\n        )\n        self.branch_0 = Conv2d(192, 96, 1, stride=1, padding=0, bias=False)\n        self.branch_1 = nn.Sequential(\n            Conv2d(192, 48, 1, stride=1, padding=0, bias=False),\n            Conv2d(48, 64, 5, stride=1, padding=2, bias=False),\n        )\n        self.branch_2 = nn.Sequential(\n            Conv2d(192, 64, 1, stride=1, padding=0, bias=False),\n            Conv2d(64, 96, 3, stride=1, padding=1, bias=False),\n            Conv2d(96, 96, 3, stride=1, padding=1, bias=False),\n        )\n        self.branch_3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            Conv2d(192, 64, 1, stride=1, padding=0, bias=False)\n        )\n    def forward(self, x):\n        x = self.features(x)\n        x0 = self.branch_0(x)\n        x1 = self.branch_1(x)\n        x2 = self.branch_2(x)\n        x3 = self.branch_3(x)\n        return torch.cat((x0, x1, x2, x3), dim=1)\n\n\nclass Inception_ResNet_A(nn.Module):\n    def __init__(self, in_channels, scale=1.0):\n        super(Inception_ResNet_A, self).__init__()\n        self.scale = scale\n        self.branch_0 = Conv2d(in_channels, 32, 1, stride=1, padding=0, bias=False)\n        self.branch_1 = nn.Sequential(\n            Conv2d(in_channels, 32, 1, stride=1, padding=0, bias=False),\n            Conv2d(32, 32, 3, stride=1, padding=1, bias=False)\n        )\n        self.branch_2 = nn.Sequential(\n            Conv2d(in_channels, 32, 1, stride=1, padding=0, bias=False),\n            Conv2d(32, 48, 3, stride=1, padding=1, bias=False),\n            Conv2d(48, 64, 3, stride=1, padding=1, bias=False)\n        )\n        self.conv = nn.Conv2d(128, 320, 1, stride=1, padding=0, bias=True)\n        self.relu = nn.ReLU(inplace=True)\n    def forward(self, x):\n        x0 = self.branch_0(x)\n        x1 = self.branch_1(x)\n        x2 = self.branch_2(x)\n        x_res = torch.cat((x0, x1, x2), dim=1)\n        x_res = self.conv(x_res)\n        return self.relu(x + self.scale * x_res)\n\n\nclass Inception_ResNet_B(nn.Module):\n    def __init__(self, in_channels, scale=1.0):\n        super(Inception_ResNet_B, self).__init__()\n        self.scale = scale\n        self.branch_0 = Conv2d(in_channels, 192, 1, stride=1, padding=0, bias=False)\n        self.branch_1 = nn.Sequential(\n            Conv2d(in_channels, 128, 1, stride=1, padding=0, bias=False),\n            Conv2d(128, 160, (1, 7), stride=1, padding=(0, 3), bias=False),\n            Conv2d(160, 192, (7, 1), stride=1, padding=(3, 0), bias=False)\n        )\n        self.conv = nn.Conv2d(384, 1088, 1, stride=1, padding=0, bias=True)\n        self.relu = nn.ReLU(inplace=True)\n    def forward(self, x):\n        x0 = self.branch_0(x)\n        x1 = self.branch_1(x)\n        x_res = torch.cat((x0, x1), dim=1)\n        x_res = self.conv(x_res)\n        return self.relu(x + self.scale * x_res)\n\n\nclass Reduciton_B(nn.Module):\n    def __init__(self, in_channels):\n        super(Reduciton_B, self).__init__()\n        self.branch_0 = nn.Sequential(\n            Conv2d(in_channels, 256, 1, stride=1, padding=0, bias=False),\n            Conv2d(256, 384, 3, stride=2, padding=0, bias=False)\n        )\n        self.branch_1 = nn.Sequential(\n            Conv2d(in_channels, 256, 1, stride=1, padding=0, bias=False),\n            Conv2d(256, 288, 3, stride=2, padding=0, bias=False),\n        )\n        self.branch_2 = nn.Sequential(\n            Conv2d(in_channels, 256, 1, stride=1, padding=0, bias=False),\n            Conv2d(256, 288, 3, stride=1, padding=1, bias=False),\n            Conv2d(288, 320, 3, stride=2, padding=0, bias=False)\n        )\n        self.branch_3 = nn.MaxPool2d(3, stride=2, padding=0)\n\n    def forward(self, x):\n        x0 = self.branch_0(x)\n        x1 = self.branch_1(x)\n        x2 = self.branch_2(x)\n        x3 = self.branch_3(x)\n        return torch.cat((x0, x1, x2, x3), dim=1)\n\n\nclass Inception_ResNet_C(nn.Module):\n    def __init__(self, in_channels, scale=1.0, activation=True):\n        super(Inception_ResNet_C, self).__init__()\n        self.scale = scale\n        self.activation = activation\n        self.branch_0 = Conv2d(in_channels, 192, 1, stride=1, padding=0, bias=False)\n        self.branch_1 = nn.Sequential(\n            Conv2d(in_channels, 192, 1, stride=1, padding=0, bias=False),\n            Conv2d(192, 224, (1, 3), stride=1, padding=(0, 1), bias=False),\n            Conv2d(224, 256, (3, 1), stride=1, padding=(1, 0), bias=False)\n        )\n        self.conv = nn.Conv2d(448, 2080, 1, stride=1, padding=0, bias=True)\n        self.relu = nn.ReLU(inplace=True)\n    def forward(self, x):\n        x0 = self.branch_0(x)\n        x1 = self.branch_1(x)\n        x_res = torch.cat((x0, x1), dim=1)\n        x_res = self.conv(x_res)\n        if self.activation:\n            return self.relu(x + self.scale * x_res)\n        return x + self.scale * x_res\n\n\nclass Inception_ResNetv2(nn.Module):\n    def __init__(self, in_channels=3, classes=2, k=256, l=256, m=384, n=384):\n        super(Inception_ResNetv2, self).__init__()\n        blocks = []\n        blocks.append(Stem(in_channels))\n        for i in range(10):\n            blocks.append(Inception_ResNet_A(320, 0.17))\n        blocks.append(Reduction_A(320, k, l, m, n))\n        for i in range(20):\n            blocks.append(Inception_ResNet_B(1088, 0.10))\n        blocks.append(Reduciton_B(1088))\n        for i in range(9):\n            blocks.append(Inception_ResNet_C(2080, 0.20))\n        blocks.append(Inception_ResNet_C(2080, activation=False))\n        self.features = nn.Sequential(*blocks)\n        self.conv = Conv2d(2080, 1536, 1, stride=1, padding=0, bias=False)\n        self.global_average_pooling = nn.AdaptiveAvgPool2d((1, 1))\n        self.linear = nn.Linear(1536, classes)\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.conv(x)\n        x = self.global_average_pooling(x)\n        x = x.view(x.size(0), -1)\n        x = self.linear(x)\n        x = self.softmax(x)\n        return x\n","09c8d3a8":"import torch\nimport torch.nn as nn\n\nclass Conv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, padding, stride=1, bias=True):\n        super(Conv2d, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, bias=bias)\n        self.bn = nn.BatchNorm2d(out_channels, eps=0.001, momentum=0.1)\n        self.relu = nn.ReLU(inplace=True)\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\n\nclass Reduction_A(nn.Module):\n    # 35 -> 17\n    def __init__(self, in_channels, k, l, m, n):\n        super(Reduction_A, self).__init__()\n        self.branch_0 = Conv2d(in_channels, n, 3, stride=2, padding=0, bias=False)\n        self.branch_1 = nn.Sequential(\n            Conv2d(in_channels, k, 1, stride=1, padding=0, bias=False),\n            Conv2d(k, l, 3, stride=1, padding=1, bias=False),\n            Conv2d(l, m, 3, stride=2, padding=0, bias=False),\n        )\n        self.branch_2 = nn.MaxPool2d(3, stride=2, padding=0)\n\n    def forward(self, x):\n        x0 = self.branch_0(x)\n        x1 = self.branch_1(x)\n        x2 = self.branch_2(x)\n        return torch.cat((x0, x1, x2), dim=1) # 17 x 17 x 1024\n    \nclass Stem(nn.Module):\n    def __init__(self, in_channels):\n        super(Stem, self).__init__()\n        self.conv2d_1a_3x3 = Conv2d(in_channels, 32, 3, stride=2, padding=0, bias=False)\n\n        self.conv2d_2a_3x3 = Conv2d(32, 32, 3, stride=1, padding=0, bias=False)\n        self.conv2d_2b_3x3 = Conv2d(32, 64, 3, stride=1, padding=1, bias=False)\n\n        self.mixed_3a_branch_0 = nn.MaxPool2d(3, stride=2, padding=0)\n        self.mixed_3a_branch_1 = Conv2d(64, 96, 3, stride=2, padding=0, bias=False)\n\n        self.mixed_4a_branch_0 = nn.Sequential(\n            Conv2d(160, 64, 1, stride=1, padding=0, bias=False),\n            Conv2d(64, 96, 3, stride=1, padding=0, bias=False),\n        )\n        self.mixed_4a_branch_1 = nn.Sequential(\n            Conv2d(160, 64, 1, stride=1, padding=0, bias=False),\n            Conv2d(64, 64, (1, 7), stride=1, padding=(0, 3), bias=False),\n            Conv2d(64, 64, (7, 1), stride=1, padding=(3, 0), bias=False),\n            Conv2d(64, 96, 3, stride=1, padding=0, bias=False)\n        )\n\n        self.mixed_5a_branch_0 = Conv2d(192, 192, 3, stride=2, padding=0, bias=False)\n        self.mixed_5a_branch_1 = nn.MaxPool2d(3, stride=2, padding=0)\n\n    def forward(self, x):\n        x = self.conv2d_1a_3x3(x) # 149 x 149 x 32\n        x = self.conv2d_2a_3x3(x) # 147 x 147 x 32\n        x = self.conv2d_2b_3x3(x) # 147 x 147 x 64\n        x0 = self.mixed_3a_branch_0(x)\n        x1 = self.mixed_3a_branch_1(x)\n        x = torch.cat((x0, x1), dim=1) # 73 x 73 x 160\n        x0 = self.mixed_4a_branch_0(x)\n        x1 = self.mixed_4a_branch_1(x)\n        x = torch.cat((x0, x1), dim=1) # 71 x 71 x 192\n        x0 = self.mixed_5a_branch_0(x)\n        x1 = self.mixed_5a_branch_1(x)\n        x = torch.cat((x0, x1), dim=1) # 35 x 35 x 384\n        return x\n\n\nclass Inception_A(nn.Module):\n    def __init__(self, in_channels):\n        super(Inception_A, self).__init__()\n        self.branch_0 = Conv2d(in_channels, 96, 1, stride=1, padding=0, bias=False)\n        self.branch_1 = nn.Sequential(\n            Conv2d(in_channels, 64, 1, stride=1, padding=0, bias=False),\n            Conv2d(64, 96, 3, stride=1, padding=1, bias=False),\n        )\n        self.branch_2 = nn.Sequential(\n            Conv2d(in_channels, 64, 1, stride=1, padding=0, bias=False),\n            Conv2d(64, 96, 3, stride=1, padding=1, bias=False),\n            Conv2d(96, 96, 3, stride=1, padding=1, bias=False),\n        )\n        self.brance_3 = nn.Sequential(\n            nn.AvgPool2d(3, 1, padding=1, count_include_pad=False),\n            Conv2d(384, 96, 1, stride=1, padding=0, bias=False)\n        )\n\n    def forward(self, x):\n        x0 = self.branch_0(x)\n        x1 = self.branch_1(x)\n        x2 = self.branch_2(x)\n        x3 = self.brance_3(x)\n        return torch.cat((x0, x1, x2, x3), dim=1)\n\n\nclass Inception_B(nn.Module):\n    def __init__(self, in_channels):\n        super(Inception_B, self).__init__()\n        self.branch_0 = Conv2d(in_channels, 384, 1, stride=1, padding=0, bias=False)\n        self.branch_1 = nn.Sequential(\n            Conv2d(in_channels, 192, 1, stride=1, padding=0, bias=False),\n            Conv2d(192, 224, (1, 7), stride=1, padding=(0, 3), bias=False),\n            Conv2d(224, 256, (7, 1), stride=1, padding=(3, 0), bias=False),\n        )\n        self.branch_2 = nn.Sequential(\n            Conv2d(in_channels, 192, 1, stride=1, padding=0, bias=False),\n            Conv2d(192, 192, (7, 1), stride=1, padding=(3, 0), bias=False),\n            Conv2d(192, 224, (1, 7), stride=1, padding=(0, 3), bias=False),\n            Conv2d(224, 224, (7, 1), stride=1, padding=(3, 0), bias=False),\n            Conv2d(224, 256, (1, 7), stride=1, padding=(0, 3), bias=False)\n        )\n        self.branch_3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            Conv2d(in_channels, 128, 1, stride=1, padding=0, bias=False)\n        )\n    def forward(self, x):\n        x0 = self.branch_0(x)\n        x1 = self.branch_1(x)\n        x2 = self.branch_2(x)\n        x3 = self.branch_3(x)\n        return torch.cat((x0, x1, x2, x3), dim=1)\n\n\nclass Reduction_B(nn.Module):\n    # 17 -> 8\n    def __init__(self, in_channels):\n        super(Reduction_B, self).__init__()\n        self.branch_0 = nn.Sequential(\n            Conv2d(in_channels, 192, 1, stride=1, padding=0, bias=False),\n            Conv2d(192, 192, 3, stride=2, padding=0, bias=False),\n        )\n        self.branch_1 = nn.Sequential(\n            Conv2d(in_channels, 256, 1, stride=1, padding=0, bias=False),\n            Conv2d(256, 256, (1, 7), stride=1, padding=(0, 3), bias=False),\n            Conv2d(256, 320, (7, 1), stride=1, padding=(3, 0), bias=False),\n            Conv2d(320, 320, 3, stride=2, padding=0, bias=False)\n        )\n        self.branch_2 = nn.MaxPool2d(3, stride=2, padding=0)\n\n    def forward(self, x):\n        x0 = self.branch_0(x)\n        x1 = self.branch_1(x)\n        x2 = self.branch_2(x)\n        return torch.cat((x0, x1, x2), dim=1)  # 8 x 8 x 1536\n\n\nclass Inception_C(nn.Module):\n    def __init__(self, in_channels):\n        super(Inception_C, self).__init__()\n        self.branch_0 = Conv2d(in_channels, 256, 1, stride=1, padding=0, bias=False)\n\n        self.branch_1 = Conv2d(in_channels, 384, 1, stride=1, padding=0, bias=False)\n        self.branch_1_1 = Conv2d(384, 256, (1, 3), stride=1, padding=(0, 1), bias=False)\n        self.branch_1_2 = Conv2d(384, 256, (3, 1), stride=1, padding=(1, 0), bias=False)\n\n        self.branch_2 = nn.Sequential(\n            Conv2d(in_channels, 384, 1, stride=1, padding=0, bias=False),\n            Conv2d(384, 448, (3, 1), stride=1, padding=(1, 0), bias=False),\n            Conv2d(448, 512, (1, 3), stride=1, padding=(0, 1), bias=False),\n        )\n        self.branch_2_1 = Conv2d(512, 256, (1, 3), stride=1, padding=(0, 1), bias=False)\n        self.branch_2_2 = Conv2d(512, 256, (3, 1), stride=1, padding=(1, 0), bias=False)\n\n        self.branch_3 = nn.Sequential(\n            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n            Conv2d(in_channels, 256, 1, stride=1, padding=0, bias=False)\n        )\n\n    def forward(self, x):\n        x0 = self.branch_0(x)\n        x1 = self.branch_1(x)\n        x1_1 = self.branch_1_1(x1)\n        x1_2 = self.branch_1_2(x1)\n        x1 = torch.cat((x1_1, x1_2), 1)\n        x2 = self.branch_2(x)\n        x2_1 = self.branch_2_1(x2)\n        x2_2 = self.branch_2_2(x2)\n        x2 = torch.cat((x2_1, x2_2), dim=1)\n        x3 = self.branch_3(x)\n        return torch.cat((x0, x1, x2, x3), dim=1) # 8 x 8 x 1536\n\n\nclass Inceptionv4(nn.Module):\n    def __init__(self, in_channels=3, classes=2, k=192, l=224, m=256, n=384):\n        super(Inceptionv4, self).__init__()\n        blocks = []\n        blocks.append(Stem(in_channels))\n        for i in range(4):\n            blocks.append(Inception_A(384))\n        blocks.append(Reduction_A(384, k, l, m, n))\n        for i in range(7):\n            blocks.append(Inception_B(1024))\n        blocks.append(Reduction_B(1024))\n        for i in range(3):\n            blocks.append(Inception_C(1536))\n        self.features = nn.Sequential(*blocks)\n        self.global_average_pooling = nn.AdaptiveAvgPool2d((1, 1))\n        self.linear = nn.Linear(1536, classes)\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.global_average_pooling(x)\n        x = x.view(x.size(0), -1)\n        x = self.linear(x)\n        x = self.softmax(x)\n        return x","385255a2":"def test():\n    net = ResNet50(img_channels=3, num_classes=2)\n    y = net(torch.randn(4, 3, 224, 224)).to(\"cuda\")\n    print(y.size())\n\ntest()","5b59ac2b":"def binary_acc(y_pred, y_test):\n\n    acc = (y_pred.argmax(dim=1) == y_test).to(dtype=torch.float).mean()\n    acc = torch.round(acc * 100)\n    \n    return acc.item()","18e81670":"def haspred (output_train):\n\n    y_hat = []\n\n    for p in output_train:\n        if (p[0]>0.5):\n            y_hat.append(0) \n      \n        if (p[1]>0.5):\n            y_hat.append(1)\n         \n    return y_hat\n","78bd137c":"\ndef train(model, epochs, fold_number, LEARNING_RATE):\n\n    #_________ defining the model and the optmizer ________________\n    if torch.cuda.is_available():\n      model = model.cuda()\n\n    # defining the loss\n    criterion = nn.CrossEntropyLoss()\n    # defining the optimizer \n    #optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9, weight_decay=1e-2)\n    #optimizer = optim.Adagrad(model.parameters(), lr=LEARNING_RATE,weight_decay=1e-3)\n    #optimizer = optim.Adadelta(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-3)    \n    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n    #optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01,amsgrad=False)\n    #optimizer= optim.SparseAdam(model.parameters(), lr=LEARNING_RATE)\n    #optimizer = optim.Adamax(model.parameters(), lr=LEARNING_RATE,weight_decay=0)\n    #optimizer = optim.ASGD(model.parameters(), lr=LEARNING_RATE, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)\n    #optimizer = optim.Rprop(model.parameters(), lr=LEARNING_RATE, etas=(0.5, 1.2), step_sizes=(1e-06, 50))   \n    #___________ define some variables _____________\n    tr_loss = 0\n    train_losses = []\n    test_losses = []\n    train_accuracies = []\n    test_accuracies = []\n    classes = []\n    Kfold_score = []\n \n        #____________ preparing data ________________ \n    # getting the training set\n    ds = get_dataset_from_ith_iteration(fold_number)\n    \n    train_x, train_y = ds['train']\n    # x_train, y_train = to_tensor(train_x, train_y)\n    x_train, y_train = Variable(torch.from_numpy(train_x)), Variable(torch.from_numpy(train_y))\n    \n    # print(x_train.shape)\n    # getting the test set\n    \n    x_test, y_test = ds['test']\n    x_test, y_test = torch.from_numpy(x_test), torch.from_numpy(y_test)\n    #print (len(x_train))\n    print(x_train.shape)\n    print(y_train.shape)\n    \n    #reshaping input   \n    x_train = torch.reshape(x_train, (800,3,IMG_HEIGHT,IMG_WIDTH))\n    x_test = torch.reshape(x_test, (200,3,IMG_HEIGHT,IMG_WIDTH))\n    y_train = y_train.to(dtype=torch.long)\n    y_test = y_test.to(dtype=torch.long)\n\n    # converting the data into GPU format\n    if torch.cuda.is_available():\n        x_train = x_train.cuda()\n        y_train = y_train.cuda()\n        x_test = x_test.cuda()\n        y_test = y_test.cuda()\n\n    #_______ training the network _____________________\n\n    for epoch in range(epochs):\n    # clearing the Gradients of the model parameters\n        model.train()\n        optimizer.zero_grad()\n\n        # prediction for training and test set\n        #print(x_train.shape)\n        output_train = model(x_train).squeeze()\n      \n        # computing the training\n        # print(output_train)\n        loss_train = criterion(output_train,y_train)\n    \n      \n       \n        # return output_train, y_train\n        train_accuracy = binary_acc(output_train, y_train) \n        train_losses.append(loss_train.item())\n        train_accuracies.append(train_accuracy)\n\n        # computing the updated weights of all the model parameters\n        loss_train.backward()\n        optimizer.step()\n        tr_loss = loss_train.item()\n\n        # computing the test loss\n        model.eval()\n        output_test = model(x_test).squeeze()\n        test_accuracy = binary_acc(output_test, y_test)\n        \n        loss_test = criterion(output_test, y_test)\n        test_losses.append(loss_test.item())\n        test_accuracies.append(test_accuracy)\n            \n                \n        if epoch%1 == 0:\n        # printing the train loss\n            print('Epoch : ',epoch+1, '\\t', 'train loss :', loss_train.item(), \n                  'train accuracy :', train_accuracy, 'test loss :', loss_test.item(), \n                  'test accuracy :', test_accuracy)\n         \n      \n    #Kfold_score.append(test_accuracy)\n                 \n    trained_model = model\n    predicted_y = model(x_test).squeeze()\n    predict_y = haspred(predicted_y)\n    y_test = y_test.cpu().numpy()\n        \n       \n    # Print Metrics\n    print (\"==============Metrics===============================\\n\")\n    print (\"Confusion matrix: \")\n    print (confusion_matrix(y_test, predict_y))\n    print (\"Recall_score:\",recall_score(y_test, predict_y))\n    print (\"Precision_score:\",precision_score(y_test, predict_y))\n    print (\"Accuracy_score:\",accuracy_score(y_test, predict_y),'\\n')\n        \n         \n    plt.figure(figsize=(10,5))\n    plt.title(\"Training and Testing\")\n    plt.plot(train_accuracies,label=\"Train\")\n    plt.plot(test_accuracies,label=\"Test\")\n    plt.xlabel(\"epoch\")\n    plt.ylabel(\"accuracy\")\n    plt.legend()\n    plt.show()\n    \n    print (Kfold_score)\n    return model, train_accuracy, test_accuracy","e91f4a41":"\n\n#trained_model, train_accuracies, test_accuracies= train(model=model, epochs=50,fold_number, LEARNING_RATE=0.0001)","9c21ad4d":"import torch.nn as nn\nimport torch.optim as optim\n\ni = 0\nfor i in range (5):\n    print(\"Interacion\", i)\n    model = ResNet18(img_channels=3, num_classes=2)\n    #model = Xception(pretrained=False,**kwargs)\n    #model = Inception_ResNetv2()\n    #model=segnet()\n    #model = Inceptionv4()\n    trained_model, train_accuracies, test_accuracies= train(model=model, epochs=100,fold_number = i, LEARNING_RATE= 0.001)    \n ","d3cb8669":"for param in model.parameters()\n    print (param)","6aafee94":"weight_decay=1e-5","5dc4d42f":"\nlen(output_train)","2a327e7f":"hashp = haspred (output_train)","230010bc":"len(hashp)","210edc5d":"# Process Cataract dataset","02371d54":" # Inception_ResNet","4049bcc8":"# Create datasets","023a63b3":"# Set configurations and read metadata","bcbe9681":"# InceptionV4","db354c37":"#  Defining Resnet"}}