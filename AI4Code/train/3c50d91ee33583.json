{"cell_type":{"484e887f":"code","4876fef5":"code","9f56e875":"code","ae50ce9b":"code","1f3eeb8c":"code","e1981fa0":"code","903bb2f3":"code","6c7715fe":"code","cf4f65d5":"code","b4263671":"code","43761243":"code","7acf195e":"code","0e878148":"code","8bef54ec":"code","6109dce2":"code","e42213a1":"code","ca1aa8b5":"code","dc0b45ff":"code","495337f6":"code","a814b715":"code","5a6917b3":"code","29f2c203":"code","7110d2b4":"code","09dbb391":"code","22713ca3":"code","4a91b26e":"code","c0c3893e":"code","2f88aa47":"code","21b77e14":"code","0c15c763":"code","367f8cf2":"code","bf5087be":"code","e404a8e0":"code","7e2ac124":"code","18eb01e4":"code","9fba902a":"code","e92b3f5e":"code","aa52a5cc":"code","cd81ae8f":"code","7fddb072":"code","a86298a0":"code","473a8459":"code","7d60d3d9":"code","d50cb6d3":"code","8ec9ff3a":"code","768c88db":"code","062c5802":"code","11991ea1":"code","740be0ba":"code","22834045":"code","4aafac70":"code","a2aa9f87":"code","b388d4df":"code","094be787":"code","dabc5422":"code","86e7523f":"code","482e0603":"code","119bbfb1":"code","56f42299":"code","2ef0e608":"markdown","0bba574b":"markdown","87041c4d":"markdown","2b601a54":"markdown","fabe459a":"markdown","f162d71f":"markdown","1a77302b":"markdown","392a0b75":"markdown","4f3e98e6":"markdown","253807e2":"markdown","e61993c8":"markdown"},"source":{"484e887f":"from IPython.display import clear_output\n!pip install imutils","4876fef5":"import numpy as np\nimport pandas as pd\nimport cv2\nfrom PIL import Image\nimport scipy\nimport  os\nimport tensorflow as tf\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras.optimizers import *\nfrom tensorflow.keras.losses import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras.preprocessing.image import *\nfrom tensorflow.keras.utils import *\nimport shutil\nimport itertools\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelBinarizer\n# import pydot\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import *\nimport tensorflow.keras.backend as K\n\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import tools\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom tqdm import tqdm, tqdm_notebook\nfrom colorama import Fore\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom glob import glob\nfrom skimage.io import *\n%config Completer.use_jedi = False\nimport time\nfrom sklearn.decomposition import PCA\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nimport lightgbm as lgb\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n\nprint(\"All modules have been imported\")","9f56e875":"!apt-get install tree\nclear_output()\n# create new folders\n!mkdir TRAIN TEST VAL TRAIN\/YES TRAIN\/NO TEST\/YES TEST\/NO VAL\/YES VAL\/NO\n!tree -d","ae50ce9b":"IMG_PATH = \"..\/input\/brain-tumor-detection-mri\/Brain_Tumor_Detection\"\n\n# split the data by train\/val\/test\nignored = {\"pred\"}\n# split the data by train\/val\/test\nfor CLASS in os.listdir(IMG_PATH):\n    if CLASS not in ignored:\n        if not CLASS.startswith('.'):\n            IMG_NUM = len(os.listdir(IMG_PATH +\"\/\"+ CLASS))\n            for (n, FILE_NAME) in enumerate(os.listdir(IMG_PATH +\"\/\"+ CLASS)):\n                img = IMG_PATH+ '\/' +  CLASS + '\/' + FILE_NAME\n                if n < 300:\n                    shutil.copy(img, 'TEST\/' + CLASS.upper() + '\/' + FILE_NAME)\n                elif n < 0.8*IMG_NUM:\n                    shutil.copy(img, 'TRAIN\/'+ CLASS.upper() + '\/' + FILE_NAME)\n                else:\n                    shutil.copy(img, 'VAL\/'+ CLASS.upper() + '\/' + FILE_NAME)","1f3eeb8c":"def load_data(dir_path, img_size=(100,100)):\n    \"\"\"\n    Load resized images as np.arrays to workspace\n    \"\"\"\n    X = []\n    y = []\n    i = 0\n    labels = dict()\n    for path in tqdm(sorted(os.listdir(dir_path))):\n        if not path.startswith('.'):\n            labels[i] = path\n            for file in os.listdir(dir_path + path):\n                if not file.startswith('.'):\n                    img = cv2.imread(dir_path + path + '\/' + file)\n                    X.append(img)\n                    y.append(i)\n            i += 1\n    X = np.array(X)\n    y = np.array(y)\n    print(f'{len(X)} images loaded from {dir_path} directory.')\n    return X, y, labels\n\n\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (6,6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    cm = np.round(cm,2)\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","e1981fa0":"TRAIN_DIR = 'TRAIN\/'\nTEST_DIR = 'TEST\/'\nVAL_DIR = 'VAL\/'\nIMG_SIZE = (224,224)\n\n# use predefined function to load the image data into workspace\nX_train, y_train, labels = load_data(TRAIN_DIR, IMG_SIZE)\nX_test, y_test, _ = load_data(TEST_DIR, IMG_SIZE)\nX_val, y_val, _ = load_data(VAL_DIR, IMG_SIZE)","903bb2f3":"y = dict()\ny[0] = []\ny[1] = []\nfor set_name in (y_train, y_val, y_test):\n    y[0].append(np.sum(set_name == 0))\n    y[1].append(np.sum(set_name == 1))\n\ntrace0 = go.Bar(\n    x=['Train Set', 'Validation Set', 'Test Set'],\n    y=y[0],\n    name='No',\n    marker=dict(color='#33cc33'),\n    opacity=0.7\n)\ntrace1 = go.Bar(\n    x=['Train Set', 'Validation Set', 'Test Set'],\n    y=y[1],\n    name='Yes',\n    marker=dict(color='#ff3300'),\n    opacity=0.7\n)\ndata = [trace0, trace1]\nlayout = go.Layout(\n    title='Count of classes in each set',\n    xaxis={'title': 'Set'},\n    yaxis={'title': 'Count'}\n)\nfig = go.Figure(data, layout)\niplot(fig)","6c7715fe":"def plot_samples(X, y, labels_dict, n=50):\n    \"\"\"\n    Creates a gridplot for desired number of images (n) from the specified set\n    \"\"\"\n    for index in range(len(labels_dict)):\n        imgs = X[np.argwhere(y == index)][:n]\n        j = 10\n        i = int(n\/j)\n\n        plt.figure(figsize=(15,6))\n        c = 1\n        for img in imgs:\n            plt.subplot(i,j,c)\n            plt.imshow(img[0])\n\n            plt.xticks([])\n            plt.yticks([])\n            c += 1\n        plt.suptitle('Tumor: {}'.format(labels_dict[index]))\n        plt.show()","cf4f65d5":"plot_samples(X_train, y_train, labels, 30)","b4263671":"RATIO_LIST = []\nfor set in (X_train, X_test, X_val):\n    for img in set:\n        RATIO_LIST.append(img.shape[1]\/img.shape[0])\n        \nplt.hist(RATIO_LIST)\nplt.title('Distribution of Image Ratios')\nplt.xlabel('Ratio Value')\nplt.ylabel('Count')\nplt.show()","43761243":"def crop_imgs(set_name, add_pixels_value=0):\n    \"\"\"\n    Finds the extreme points on the image and crops the rectangular out of them\n    \"\"\"\n    set_new = []\n    for img in set_name:\n        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        gray = cv2.GaussianBlur(gray, (5, 5), 0)\n\n        # threshold the image, then perform a series of erosions +\n        # dilations to remove any small regions of noise\n        thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n        thresh = cv2.erode(thresh, None, iterations=2)\n        thresh = cv2.dilate(thresh, None, iterations=2)\n\n        # find contours in thresholded image, then grab the largest one\n        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        cnts = imutils.grab_contours(cnts)\n        c = max(cnts, key=cv2.contourArea)\n\n        # find the extreme points\n        extLeft = tuple(c[c[:, :, 0].argmin()][0])\n        extRight = tuple(c[c[:, :, 0].argmax()][0])\n        extTop = tuple(c[c[:, :, 1].argmin()][0])\n        extBot = tuple(c[c[:, :, 1].argmax()][0])\n\n        ADD_PIXELS = add_pixels_value\n        new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n        set_new.append(new_img)\n\n    return np.array(set_new)","7acf195e":"import imutils\nimg = cv2.imread('.\/VAL\/NO\/no852.jpg')\nimg = cv2.resize(\n            img,\n            dsize=IMG_SIZE,\n            interpolation=cv2.INTER_CUBIC\n        )\ngray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\ngray = cv2.GaussianBlur(gray, (5, 5), 0)\n\n# threshold the image, then perform a series of erosions +\n# dilations to remove any small regions of noise\nthresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\nthresh = cv2.erode(thresh, None, iterations=2)\nthresh = cv2.dilate(thresh, None, iterations=2)\n\n# find contours in thresholded image, then grab the largest one\ncnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\ncnts = imutils.grab_contours(cnts)\nc = max(cnts, key=cv2.contourArea)\n\n# find the extreme points\nextLeft = tuple(c[c[:, :, 0].argmin()][0])\nextRight = tuple(c[c[:, :, 0].argmax()][0])\nextTop = tuple(c[c[:, :, 1].argmin()][0])\nextBot = tuple(c[c[:, :, 1].argmax()][0])\n\n# add contour on the image\nimg_cnt = cv2.drawContours(img.copy(), [c], -1, (0, 255, 255), 4)\n\n# add extreme points\nimg_pnt = cv2.circle(img_cnt.copy(), extLeft, 8, (0, 0, 255), -1)\nimg_pnt = cv2.circle(img_pnt, extRight, 8, (0, 255, 0), -1)\nimg_pnt = cv2.circle(img_pnt, extTop, 8, (255, 0, 0), -1)\nimg_pnt = cv2.circle(img_pnt, extBot, 8, (255, 255, 0), -1)\n\n# crop\nADD_PIXELS = 0\nnew_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()","0e878148":"plt.figure(figsize=(15,6))\nplt.subplot(141)\nplt.imshow(img)\nplt.xticks([])\nplt.yticks([])\nplt.title('Step 1. Get the original image')\nplt.subplot(142)\nplt.imshow(img_cnt)\nplt.xticks([])\nplt.yticks([])\nplt.title('Step 2. Find the biggest contour')\nplt.subplot(143)\nplt.imshow(img_pnt)\nplt.xticks([])\nplt.yticks([])\nplt.title('Step 3. Find the extreme points')\nplt.subplot(144)\nplt.imshow(new_img)\nplt.xticks([])\nplt.yticks([])\nplt.title('Step 4. Crop the image')\nplt.show()","8bef54ec":"# apply this for each set\nX_train_crop = crop_imgs(set_name=X_train)\nX_val_crop = crop_imgs(set_name=X_val)\nX_test_crop = crop_imgs(set_name=X_test)","6109dce2":"plot_samples(X_train_crop, y_train, labels, 30)","e42213a1":"RATIO_LIST = []\nfor set in (X_train_crop, X_test_crop, X_val_crop):\n    for img in set:\n        RATIO_LIST.append(img.shape[1]\/img.shape[0])\n        \nplt.hist(RATIO_LIST)\nplt.title('Distribution of Image Ratios')\nplt.xlabel('Ratio Value')\nplt.ylabel('Count')\nplt.show()","ca1aa8b5":"def save_new_images(x_set, y_set, folder_name):\n    i = 0\n    for (img, imclass) in zip(x_set, y_set):\n        if imclass == 0:\n            cv2.imwrite(folder_name+'NO\/'+str(i)+'.jpg', img)\n        else:\n            cv2.imwrite(folder_name+'YES\/'+str(i)+'.jpg', img)\n        i += 1","dc0b45ff":"# saving new images to the folder\n!mkdir TRAIN_CROP TEST_CROP VAL_CROP TRAIN_CROP\/YES TRAIN_CROP\/NO TEST_CROP\/YES TEST_CROP\/NO VAL_CROP\/YES VAL_CROP\/NO\n\nsave_new_images(X_train_crop, y_train, folder_name='TRAIN_CROP\/')\nsave_new_images(X_val_crop, y_val, folder_name='VAL_CROP\/')\nsave_new_images(X_test_crop, y_test, folder_name='TEST_CROP\/')","495337f6":"def preprocess_imgs(set_name, img_size):\n    set_new = []\n    for img in set_name:\n        img = cv2.resize(\n            img,\n            dsize=img_size,\n            interpolation=cv2.INTER_CUBIC\n        )\n        set_new.append(preprocess_input(img))\n    return np.array(set_new)","a814b715":"X_train_prep = preprocess_imgs(set_name=X_train_crop, img_size=IMG_SIZE)\nX_test_prep = preprocess_imgs(set_name=X_test_crop, img_size=IMG_SIZE)\nX_val_prep = preprocess_imgs(set_name=X_val_crop, img_size=IMG_SIZE)","5a6917b3":"plot_samples(X_train_prep, y_train, labels, 30)","29f2c203":"RATIO_LIST = []\nfor set in (X_train_prep, X_test_prep, X_val_prep):\n    for img in set:\n        RATIO_LIST.append(img.shape[1]\/img.shape[0])\n        \nplt.hist(RATIO_LIST)\nplt.title('Distribution of Image Ratios')\nplt.xlabel('Ratio Value')\nplt.ylabel('Count')\nplt.show()","7110d2b4":"TRAIN_DIR = 'TRAIN_CROP\/'\nVAL_DIR = 'VAL_CROP\/'\nRANDOM_SEED = 42\ntrain_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input\n)\n\n\ntest_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input\n)\n\n\ntrain_generator = train_datagen.flow_from_directory(\n    TRAIN_DIR,\n    color_mode='rgb',\n    target_size=IMG_SIZE,\n    batch_size=32,\n    class_mode='binary',\n    seed=RANDOM_SEED\n)\n\nvalidation_generator = test_datagen.flow_from_directory(\n    VAL_DIR,\n    color_mode='rgb',\n    target_size=IMG_SIZE,\n    batch_size=16,\n    class_mode='binary',\n    seed=RANDOM_SEED\n)","09dbb391":"from sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn import metrics\nnames = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n        \"ANN Classifier\"\n         ]\nclassifiers = [\n    KNeighborsClassifier(),\n    SVC(probability = True),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n    MLPClassifier()\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    y_pred_train = [1 if x>0.5 else 0 for x in y_pred_train]\n    y_pred_val = [1 if x>0.5 else 0 for x in y_pred_val]\n    y_pred_test = [1 if x>0.5 else 0 for x in y_pred_test]\n\n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2)\n    test_roc_auc = metrics.roc_auc_score(y_test, y_pred_test ,multi_class='ovo', average='weighted')\n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    confusion_mtx = confusion_matrix(y_train, y_pred_train) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    confusion_mtx = confusion_matrix(y_val, y_pred_val) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    print(\"ROC AUC score : {}\".format(test_roc_auc))\n    confusion_mtx = confusion_matrix(y_test, y_pred_test) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('\\t\\tClassification Report:\\n', metrics.classification_report(y_test, y_pred_test))\n    \n    print(\"-\"*80)\n    print()","22713ca3":"def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","4a91b26e":"base_model= ResNet50(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Dropout(0.5)(x)\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(64,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\npredictions = Activation('relu')(x)\n#x = Dropout(0.5)(x)\n\n#predictions = Dense(1, activation='sigmoid')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(X_train_prep)\nval_features=model_feat.predict(X_val_prep)\ntest_features=model_feat.predict(X_test_prep)","c0c3893e":"names = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n        \"ANN Classifier\"\n         ]\nclassifiers = [\n    KNeighborsClassifier(),\n    SVC(probability = True),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n    MLPClassifier()\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    y_pred_train = [1 if x>0.5 else 0 for x in y_pred_train]\n    y_pred_val = [1 if x>0.5 else 0 for x in y_pred_val]\n    y_pred_test = [1 if x>0.5 else 0 for x in y_pred_test]\n\n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2)\n    test_roc_auc = metrics.roc_auc_score(y_test, y_pred_test ,multi_class='ovo', average='weighted')\n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    confusion_mtx = confusion_matrix(y_train, y_pred_train) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    confusion_mtx = confusion_matrix(y_val, y_pred_val) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    print(\"ROC AUC score : {}\".format(test_roc_auc))\n    confusion_mtx = confusion_matrix(y_test, y_pred_test) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('\\t\\tClassification Report:\\n', metrics.classification_report(y_test, y_pred_test))\n    \n    print(\"-\"*80)\n    print()\n    \n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","2f88aa47":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","21b77e14":"base_model= VGG16(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Dropout(0.5)(x)\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(64,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\npredictions = Activation('relu')(x)\n#x = Dropout(0.5)(x)\n#predictions = Dense(1 , activation='sigmoid')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(X_train_prep)\nval_features=model_feat.predict(X_val_prep)\ntest_features=model_feat.predict(X_test_prep)","0c15c763":"names = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n        \"ANN Classifier\"\n         ]\nclassifiers = [\n    KNeighborsClassifier(),\n    SVC(probability = True),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n    MLPClassifier()\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    y_pred_train = [1 if x>0.5 else 0 for x in y_pred_train]\n    y_pred_val = [1 if x>0.5 else 0 for x in y_pred_val]\n    y_pred_test = [1 if x>0.5 else 0 for x in y_pred_test]\n\n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2)\n    test_roc_auc = metrics.roc_auc_score(y_test, y_pred_test ,multi_class='ovo', average='weighted')\n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    confusion_mtx = confusion_matrix(y_train, y_pred_train) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    confusion_mtx = confusion_matrix(y_val, y_pred_val) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    print(\"ROC AUC score : {}\".format(test_roc_auc))\n    confusion_mtx = confusion_matrix(y_test, y_pred_test) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('\\t\\tClassification Report:\\n', metrics.classification_report(y_test, y_pred_test))\n    \n    print(\"-\"*80)\n    print()\n    \n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","367f8cf2":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","bf5087be":"base_model= VGG19(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Dropout(0.5)(x)\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(64,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\npredictions = Activation('relu')(x)\n#x = Dropout(0.5)(x)\n#predictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(X_train_prep)\nval_features=model_feat.predict(X_val_prep)\ntest_features=model_feat.predict(X_test_prep)","e404a8e0":"names = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n        \"ANN Classifier\"\n         ]\nclassifiers = [\n    KNeighborsClassifier(),\n    SVC(probability = True),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n    MLPClassifier()\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    y_pred_train = [1 if x>0.5 else 0 for x in y_pred_train]\n    y_pred_val = [1 if x>0.5 else 0 for x in y_pred_val]\n    y_pred_test = [1 if x>0.5 else 0 for x in y_pred_test]\n\n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2)\n    test_roc_auc = metrics.roc_auc_score(y_test, y_pred_test ,multi_class='ovo', average='weighted')\n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    confusion_mtx = confusion_matrix(y_train, y_pred_train) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    confusion_mtx = confusion_matrix(y_val, y_pred_val) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    print(\"ROC AUC score : {}\".format(test_roc_auc))\n    confusion_mtx = confusion_matrix(y_test, y_pred_test) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('\\t\\tClassification Report:\\n', metrics.classification_report(y_test, y_pred_test))\n    \n    print(\"-\"*80)\n    print()\n    \n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","7e2ac124":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","18eb01e4":"base_model= ResNet101(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(64,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\npredictions = Activation('relu')(x)\n#x = Dropout(0.5)(x)\n#predictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(X_train_prep)\nval_features=model_feat.predict(X_val_prep)\ntest_features=model_feat.predict(X_test_prep)","9fba902a":"names = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n        \"ANN Classifier\"\n         ]\nclassifiers = [\n    KNeighborsClassifier(),\n    SVC(probability = True),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n    MLPClassifier()\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    y_pred_train = [1 if x>0.5 else 0 for x in y_pred_train]\n    y_pred_val = [1 if x>0.5 else 0 for x in y_pred_val]\n    y_pred_test = [1 if x>0.5 else 0 for x in y_pred_test]\n\n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2)\n    test_roc_auc = metrics.roc_auc_score(y_test, y_pred_test ,multi_class='ovo', average='weighted')\n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    confusion_mtx = confusion_matrix(y_train, y_pred_train) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    confusion_mtx = confusion_matrix(y_val, y_pred_val) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    print(\"ROC AUC score : {}\".format(test_roc_auc))\n    confusion_mtx = confusion_matrix(y_test, y_pred_test) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('\\t\\tClassification Report:\\n', metrics.classification_report(y_test, y_pred_test))\n    \n    print(\"-\"*80)\n    print()\n    \n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","e92b3f5e":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","aa52a5cc":"base_model= MobileNetV2(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(64,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\npredictions = Activation('relu')(x)\n#x = Dropout(0.5)(x)\n#predictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(X_train_prep)\nval_features=model_feat.predict(X_val_prep)\ntest_features=model_feat.predict(X_test_prep)","cd81ae8f":"names = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n        \"ANN Classifier\"\n         ]\nclassifiers = [\n    KNeighborsClassifier(),\n    SVC(probability = True),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n    MLPClassifier()\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    y_pred_train = [1 if x>0.5 else 0 for x in y_pred_train]\n    y_pred_val = [1 if x>0.5 else 0 for x in y_pred_val]\n    y_pred_test = [1 if x>0.5 else 0 for x in y_pred_test]\n\n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2)\n    test_roc_auc = metrics.roc_auc_score(y_test, y_pred_test ,multi_class='ovo', average='weighted')\n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    confusion_mtx = confusion_matrix(y_train, y_pred_train) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    confusion_mtx = confusion_matrix(y_val, y_pred_val) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    print(\"ROC AUC score : {}\".format(test_roc_auc))\n    confusion_mtx = confusion_matrix(y_test, y_pred_test) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('\\t\\tClassification Report:\\n', metrics.classification_report(y_test, y_pred_test))\n    \n    print(\"-\"*80)\n    print()\n    \n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","7fddb072":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","a86298a0":"base_model= MobileNet(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(64,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\npredictions = Activation('relu')(x)\n#x = Dropout(0.5)(x)\n#predictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(X_train_prep)\nval_features=model_feat.predict(X_val_prep)\ntest_features=model_feat.predict(X_test_prep)","473a8459":"names = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n        \"ANN Classifier\"\n         ]\nclassifiers = [\n    KNeighborsClassifier(),\n    SVC(probability = True),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n    MLPClassifier()\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    y_pred_train = [1 if x>0.5 else 0 for x in y_pred_train]\n    y_pred_val = [1 if x>0.5 else 0 for x in y_pred_val]\n    y_pred_test = [1 if x>0.5 else 0 for x in y_pred_test]\n\n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2)\n    test_roc_auc = metrics.roc_auc_score(y_test, y_pred_test ,multi_class='ovo', average='weighted')\n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    confusion_mtx = confusion_matrix(y_train, y_pred_train) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    confusion_mtx = confusion_matrix(y_val, y_pred_val) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    print(\"ROC AUC score : {}\".format(test_roc_auc))\n    confusion_mtx = confusion_matrix(y_test, y_pred_test) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('\\t\\tClassification Report:\\n', metrics.classification_report(y_test, y_pred_test))\n    \n    print(\"-\"*80)\n    print()\n    \n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","7d60d3d9":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","d50cb6d3":"base_model= InceptionV3(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(64,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\npredictions = Activation('relu')(x)\n#x = Dropout(0.5)(x)\n#predictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(X_train_prep)\nval_features=model_feat.predict(X_val_prep)\ntest_features=model_feat.predict(X_test_prep)","8ec9ff3a":"names = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n        \"ANN Classifier\"\n         ]\nclassifiers = [\n    KNeighborsClassifier(),\n    SVC(probability = True),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n    MLPClassifier()\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    y_pred_train = [1 if x>0.5 else 0 for x in y_pred_train]\n    y_pred_val = [1 if x>0.5 else 0 for x in y_pred_val]\n    y_pred_test = [1 if x>0.5 else 0 for x in y_pred_test]\n\n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2)\n    test_roc_auc = metrics.roc_auc_score(y_test, y_pred_test ,multi_class='ovo', average='weighted')\n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    confusion_mtx = confusion_matrix(y_train, y_pred_train) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    confusion_mtx = confusion_matrix(y_val, y_pred_val) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    print(\"ROC AUC score : {}\".format(test_roc_auc))\n    confusion_mtx = confusion_matrix(y_test, y_pred_test) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('\\t\\tClassification Report:\\n', metrics.classification_report(y_test, y_pred_test))\n    \n    print(\"-\"*80)\n    print()\n    \n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","768c88db":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","062c5802":"base_model= InceptionResNetV2(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(64,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\npredictions = Activation('relu')(x)\n#x = Dropout(0.5)(x)\n#predictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(X_train_prep)\nval_features=model_feat.predict(X_val_prep)\ntest_features=model_feat.predict(X_test_prep)","11991ea1":"names = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n        \"ANN Classifier\"\n         ]\nclassifiers = [\n    KNeighborsClassifier(),\n    SVC(probability = True),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n    MLPClassifier()\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    y_pred_train = [1 if x>0.5 else 0 for x in y_pred_train]\n    y_pred_val = [1 if x>0.5 else 0 for x in y_pred_val]\n    y_pred_test = [1 if x>0.5 else 0 for x in y_pred_test]\n\n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2)\n    test_roc_auc = metrics.roc_auc_score(y_test, y_pred_test ,multi_class='ovo', average='weighted')\n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    confusion_mtx = confusion_matrix(y_train, y_pred_train) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    confusion_mtx = confusion_matrix(y_val, y_pred_val) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    print(\"ROC AUC score : {}\".format(test_roc_auc))\n    confusion_mtx = confusion_matrix(y_test, y_pred_test) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('\\t\\tClassification Report:\\n', metrics.classification_report(y_test, y_pred_test))\n    \n    print(\"-\"*80)\n    print()\n    \n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","740be0ba":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","22834045":"base_model= DenseNet169(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(64,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\npredictions = Activation('relu')(x)\n#x = Dropout(0.5)(x)\n#predictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(X_train_prep)\nval_features=model_feat.predict(X_val_prep)\ntest_features=model_feat.predict(X_test_prep)","4aafac70":"names = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n        \"ANN Classifier\"\n         ]\nclassifiers = [\n    KNeighborsClassifier(),\n    SVC(probability = True),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n    MLPClassifier()\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    y_pred_train = [1 if x>0.5 else 0 for x in y_pred_train]\n    y_pred_val = [1 if x>0.5 else 0 for x in y_pred_val]\n    y_pred_test = [1 if x>0.5 else 0 for x in y_pred_test]\n\n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2)\n    test_roc_auc = metrics.roc_auc_score(y_test, y_pred_test ,multi_class='ovo', average='weighted')\n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    confusion_mtx = confusion_matrix(y_train, y_pred_train) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    confusion_mtx = confusion_matrix(y_val, y_pred_val) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    print(\"ROC AUC score : {}\".format(test_roc_auc))\n    confusion_mtx = confusion_matrix(y_test, y_pred_test) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('\\t\\tClassification Report:\\n', metrics.classification_report(y_test, y_pred_test))\n    \n    print(\"-\"*80)\n    print()\n    \n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","a2aa9f87":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","b388d4df":"base_model= DenseNet121(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(64,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\npredictions = Activation('relu')(x)\n#x = Dropout(0.5)(x)\n#predictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(X_train_prep)\nval_features=model_feat.predict(X_val_prep)\ntest_features=model_feat.predict(X_test_prep)","094be787":"names = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n        \"ANN Classifier\"\n         ]\nclassifiers = [\n    KNeighborsClassifier(),\n    SVC(probability = True),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n    MLPClassifier()\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    y_pred_train = [1 if x>0.5 else 0 for x in y_pred_train]\n    y_pred_val = [1 if x>0.5 else 0 for x in y_pred_val]\n    y_pred_test = [1 if x>0.5 else 0 for x in y_pred_test]\n\n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2)\n    test_roc_auc = metrics.roc_auc_score(y_test, y_pred_test ,multi_class='ovo', average='weighted')\n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    confusion_mtx = confusion_matrix(y_train, y_pred_train) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    confusion_mtx = confusion_matrix(y_val, y_pred_val) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    print(\"ROC AUC score : {}\".format(test_roc_auc))\n    confusion_mtx = confusion_matrix(y_test, y_pred_test) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('\\t\\tClassification Report:\\n', metrics.classification_report(y_test, y_pred_test))\n    \n    print(\"-\"*80)\n    print()\n    \n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","dabc5422":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","86e7523f":"base_model= Xception(input_shape=(224,224,3), weights='imagenet', include_top=False)\nx = base_model.output\nx = Flatten()(x)\nx = BatchNormalization()(x)\nx = Dense(64,kernel_initializer='he_uniform')(x)\nx = BatchNormalization()(x)\npredictions = Activation('relu')(x)\n#x = Dropout(0.5)(x)\n#predictions = Dense(3, activation='softmax')(x)\n\nmodel_feat = Model(inputs=base_model.input,outputs=predictions)\n\ntrain_features = model_feat.predict(X_train_prep)\nval_features=model_feat.predict(X_val_prep)\ntest_features=model_feat.predict(X_test_prep)","482e0603":"names = [\n        \"K Nearest Neighbour Classifier\",\n        'SVM',\n        \"Random Forest Classifier\",\n        \"AdaBoost Classifier\", \n        \"XGB Classifier\",\n        \"ANN Classifier\"\n         ]\nclassifiers = [\n    KNeighborsClassifier(),\n    SVC(probability = True),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    XGBClassifier(),\n    MLPClassifier()\n        ]\nzipped_clf = zip(names,classifiers)\ndef classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    \n    y_pred_train= sentiment_fit.predict(X_train)\n    y_pred_val = sentiment_fit.predict(X_val)\n    y_pred_test = sentiment_fit.predict(X_test)\n    y_pred_train = [1 if x>0.5 else 0 for x in y_pred_train]\n    y_pred_val = [1 if x>0.5 else 0 for x in y_pred_val]\n    y_pred_test = [1 if x>0.5 else 0 for x in y_pred_test]\n\n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n    \n    \n    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n   \n    \n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),2)\n    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),2)\n    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),2)\n    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),2)\n    test_roc_auc = metrics.roc_auc_score(y_test, y_pred_test ,multi_class='ovo', average='weighted')\n    \n    print()\n    print('------------------------ Train Set Metrics------------------------')\n    print()\n    print(\"Accuracy core : {}%\".format(train_accuracy))\n    confusion_mtx = confusion_matrix(y_train, y_pred_train) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Validation Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(val_accuracy))\n    confusion_mtx = confusion_matrix(y_val, y_pred_val) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('------------------------ Test Set Metrics------------------------')\n    print()\n    print(\"Accuracy score : {}%\".format(test_accuracy))\n    print(\"F1_score : {}\".format(test_F1))\n    print(\"Kappa Score : {} \".format(test_kappa))\n    print(\"Recall score: {}\".format(test_recall))\n    print(\"Precision score : {}\".format(test_precision))\n    print(\"ROC AUC score : {}\".format(test_roc_auc))\n    confusion_mtx = confusion_matrix(y_test, y_pred_test) \n    cm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)\n    \n    print('\\t\\tClassification Report:\\n', metrics.classification_report(y_test, y_pred_test))\n    \n    print(\"-\"*80)\n    print()\n    \n    \ndef classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([('Classifier', c)])\n        print(\"------------------------------Fitting {} on input_data-------------------------------- \".format(n))\n        #print(c)\n        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)","119bbfb1":"classifier_comparator(train_features,y_train,val_features,y_val,test_features,y_test,classifier=zipped_clf)","56f42299":"# clean up the space\n!rm -rf TRAIN TEST VAL TRAIN_CROP TEST_CROP VAL_CROP","2ef0e608":"# Inception-V3","0bba574b":"# ResNet101","87041c4d":"# ResNet-50","2b601a54":"# VGG-16","fabe459a":"# XceptionNet","f162d71f":"# DenseNet-169","1a77302b":"# InceptionResNet-V2","392a0b75":"# MobileNet-V2","4f3e98e6":"# MobileNet","253807e2":"# VGG-19","e61993c8":"# DenseNet-121"}}