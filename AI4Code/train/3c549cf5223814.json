{"cell_type":{"0251a5c6":"code","4f624063":"code","19b7f948":"code","6bf91518":"code","74c98a49":"code","c1d66e03":"code","92dd93e0":"code","e89adc65":"code","8f63768f":"code","9a33c0ff":"code","33624c12":"code","5b505160":"code","7ce7b017":"code","76c604dd":"code","9b296ed9":"markdown","bf9fd4c2":"markdown","2c96d178":"markdown","66c975c9":"markdown","bcc0666e":"markdown","09d19d94":"markdown"},"source":{"0251a5c6":"import keras\nfrom keras import regularizers, optimizers\nfrom keras import losses\nfrom keras.models import Sequential, Model, load_model\nfrom keras.layers import Dense, Input, Dropout, Embedding, LSTM\nfrom keras.optimizers import RMSprop, Adam, Nadam\nfrom keras.preprocessing import sequence\n\nfrom keras.layers import Input, Conv1D, Dense, Flatten, Activation, UpSampling1D, MaxPooling1D, ZeroPadding1D\nfrom keras.callbacks import ModelCheckpoint, TensorBoard\nfrom keras.utils import to_categorical\n\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, roc_auc_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import roc_auc_score\n\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib\n\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n%matplotlib inline\n\nimport tensorflow \nimport sys","4f624063":"path = '..\/input\/creditcardfraud\/creditcard.csv'\ndf = pd.read_csv(path, sep=\",\", index_col=None)\ndf.head()","19b7f948":"# Standardize\ndf['Amount'] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1, 1))\ndf['Time'] = StandardScaler().fit_transform(df['Time'].values.reshape(-1, 1))","6bf91518":"anomalies = df[df[\"Class\"] == 1]\nnormal = df[df[\"Class\"] == 0]\n\nanomalies.shape, normal.shape","74c98a49":"for f in range(0, 20):\n    normal = normal.iloc[np.random.permutation(len(normal))]\n    \n\ndata_set = pd.concat([normal[:2000], anomalies])\n\nx_train, x_test = train_test_split(data_set, test_size = 0.4, random_state = 42)\n\nx_train = x_train.sort_values(by=['Time'])\nx_test = x_test.sort_values(by=['Time'])\n\ny_train = x_train[\"Class\"]\ny_test = x_test[\"Class\"]\n\nx_train.head(10)","c1d66e03":"x_train = np.array(x_train).reshape(x_train.shape[0], x_train.shape[1], 1)\nx_test = np.array(x_test).reshape(x_test.shape[0], x_test.shape[1], 1)\ninput_shape = (x_train.shape[1], 1)\n\ny_train = keras.utils.to_categorical(y_train, 2)\ny_test = keras.utils.to_categorical(y_test, 2)\n\nprint(\"Shapes:\\nx_train:%s\\ny_train:%s\\n\" % (x_train.shape, y_train.shape))\nprint(\"x_test:%s\\ny_test:%s\\n\" % (x_test.shape, y_test.shape))\nprint(\"input_shape:{}\\n\".format(input_shape))","92dd93e0":"input_layer = Input(shape=(input_shape ))\n\n### ENCODING STAGE\n# Pairs of causal 1D convolutional layers and pooling layers comprising the encoding stage\nconv_1 = Conv1D(filters=int(input_shape[0]), kernel_size=2, dilation_rate=1,\n                padding='causal', strides=1,input_shape=input_shape,\n                kernel_regularizer=regularizers.l2(0.01),\n                activation='relu')(input_layer)\n\npool_1 = MaxPooling1D(pool_size=2, strides=2)(conv_1)\n\nconv_2 = Conv1D(filters=int(input_shape[0] \/ 2), kernel_size=2, dilation_rate=1,\n                padding='causal',strides=1, kernel_regularizer=regularizers.l2(0.01),\n                activation='relu')(pool_1)\n\npool_2 = MaxPooling1D(pool_size=2, strides=3)(conv_2)\n\nconv_3 = Conv1D(filters=int(input_shape[0] \/ 3), kernel_size=2, dilation_rate=1,\n                padding='causal', strides=1,kernel_regularizer=regularizers.l2(0.01),\n                activation='relu')(pool_2)\n\n\n### OUTPUT OF ENCODING STAGE\nencoder = Dense(int(input_shape[0] \/ 6), activation='relu')(conv_3)\n\n### DECODING STAGE\n# Pairs of upsampling and causal 1D convolutional layers comprising the decoding stage\nupsample_1 = UpSampling1D(size=3)(encoder)\n\nconv_4 = Conv1D(filters=int(input_shape[0]\/3), kernel_size=2, dilation_rate=1,\n                padding='causal',strides=1, kernel_regularizer=regularizers.l2(0.01),\n                activation='relu')(upsample_1)\n\nupsample_2 = UpSampling1D(size=2)(conv_4)\n\nconv_5 = Conv1D(filters=int(input_shape[0]\/2), kernel_size=2, dilation_rate=1,\n                padding='causal', strides=1,kernel_regularizer=regularizers.l2(0.05),\n                activation='relu')(upsample_2)\n\nzero_pad_1 = ZeroPadding1D(padding=(0,1))(conv_5)\n\nconv_6 = Conv1D(filters=int(input_shape[0]), kernel_size=2, dilation_rate=1,\n                padding='causal', strides=1,kernel_regularizer=regularizers.l2(0.05),\n                activation='relu')(zero_pad_1)\n\n\n### Output of decoding stage flattened and passed through softmax to make predictions\nflat = Flatten()(conv_6)\n\noutput_layer = Dense(2, activation='softmax')(flat)\n\nTCN = Model(inputs=input_layer, outputs=output_layer)","e89adc65":"TCN.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=optimizers.Adam(lr=0.002),\n           metrics=[\"accuracy\"])\n\nTCN.summary()","8f63768f":"TCN.fit(x_train, y_train,\n          batch_size=128,\n          epochs=25,\n          verbose=1,\n          validation_data=(x_test, y_test))","9a33c0ff":"score = TCN.evaluate(x_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","33624c12":"preds = TCN.predict(x_test)\ny_pred = np.round(preds)\nprint(y_pred)\nauc = roc_auc_score( y_pred, y_test)\nprint(\"AUC: {:.2%}\".format (auc))","5b505160":"print(classification_report(y_test, y_pred))","7ce7b017":"class Visualization:\n    labels = [\"Normal\", \"Anomaly\"]\n\n    def draw_confusion_matrix(self, y, ypred):\n        matrix = confusion_matrix(y, ypred)\n\n        plt.figure(figsize=(10, 8))\n        colors=[ \"orange\",\"green\"]\n        sns.heatmap(matrix, xticklabels=self.labels, yticklabels=self.labels, cmap=colors, annot=True, fmt=\"d\")\n        plt.title(\"Confusion Matrix\")\n        plt.ylabel('Actual')\n        plt.xlabel('Predicted')\n        plt.show()\n\n\n    def draw_anomaly(self, y, error, threshold):\n        groupsDF = pd.DataFrame({'error': error,\n                                 'true': y}).groupby('true')\n\n        figure, axes = plt.subplots(figsize=(12, 8))\n\n        for name, group in groupsDF:\n            axes.plot(group.index, group.error, marker='x' if name == 1 else 'o', linestyle='',\n                    color='r' if name == 1 else 'g', label=\"Anomaly\" if name == 1 else \"Normal\")\n\n        axes.hlines(threshold, axes.get_xlim()[0], axes.get_xlim()[1], colors=\"b\", zorder=100, label='Threshold')\n        axes.legend()\n        \n        plt.title(\"Anomalies\")\n        plt.ylabel(\"Error\")\n        plt.xlabel(\"Data\")\n        plt.show()\n\n    def draw_error(self, error, threshold):\n            plt.plot(error, marker='o', ms=3.5, linestyle='',\n                     label='Point')\n\n            plt.hlines(threshold, xmin=0, xmax=len(error)-1, colors=\"b\", zorder=100, label='Threshold')\n            plt.legend()\n            plt.title(\"Reconstruction error\")\n            plt.ylabel(\"Error\")\n            plt.xlabel(\"Data\")\n            plt.show()","76c604dd":"visualize = Visualization()\ny_pred2 = np.argmax(y_pred, axis=1)\ny_test2 = np.argmax(y_test, axis=1)\nvisualize.draw_confusion_matrix(y_test2, y_pred2)","9b296ed9":"<h1 id=\"training\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Training\n        <a class=\"anchor-link\" href=\"#training\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","bf9fd4c2":"<h1 id=\"dataset\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Dataset\n        <a class=\"anchor-link\" href=\"#dataset\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","2c96d178":"<h1 id=\"tcn\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Encoder-Decoder TCN\n        <a class=\"anchor-link\" href=\"#tcn\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","66c975c9":"<h1 id=\"analyze\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Analyze\n        <a class=\"anchor-link\" href=\"#analyze\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>","bcc0666e":"<div>\n    <img src=\"https:\/\/storage.googleapis.com\/kaggle-datasets-images\/312305\/633246\/752964d08f6001573444649668b0b011\/dataset-cover.jpg?t=2019-08-22-03-58-44\" class=\"Header_CoverImg-sc-1431b7d ibFJYv\">\n<\/div>","09d19d94":"<h1 id=\"visualization\" style=\"color:#a97828; background:#4dc5ea;\"> \n    <center>Visaulization\n        <a class=\"anchor-link\" href=\"#visualization\" target=\"_self\">\u00b6<\/a>\n    <\/center>\n<\/h1>"}}