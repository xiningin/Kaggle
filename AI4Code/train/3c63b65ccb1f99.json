{"cell_type":{"85702390":"code","8648ec28":"code","9400553b":"code","38d22c42":"code","ad7a3c21":"code","c0617775":"code","80520752":"code","33a0db2f":"code","dee909ff":"code","c357e9a6":"code","d01f40f5":"code","db04805a":"code","58024ff2":"code","e2ab46fe":"code","8e4894cd":"code","79cdb98b":"code","0f4c7b34":"code","920718a7":"code","849d8f9a":"code","ca2059bc":"code","30ba9bf9":"code","3a7ac81a":"code","82be4be9":"code","1e148cfd":"code","a359a397":"code","6c642c38":"code","e8e32c4d":"code","d2bb3d6a":"code","ad7bff35":"code","723ce4a1":"code","331e6c49":"code","09cacb0d":"code","3c6a489b":"code","2e0f3abc":"code","eff241ce":"code","0a90fcdb":"code","ac1f3d17":"code","a5360278":"code","e99cc1b7":"code","1915ae25":"code","09b7e778":"markdown","de2a451f":"markdown","a53ed9ec":"markdown","83a2cc35":"markdown","1c9d58df":"markdown","747ff797":"markdown","a2577e14":"markdown","d97c896d":"markdown","d1bc72e4":"markdown","6d864e42":"markdown","cf52a5b2":"markdown","b4e07bcf":"markdown","3fc3ef7b":"markdown","995c0c16":"markdown","2cd3078e":"markdown","51169b43":"markdown","cdddafde":"markdown","5b89b683":"markdown","62063747":"markdown","e8a69b95":"markdown","a4bb082f":"markdown","e9393ff0":"markdown","58d0eb28":"markdown","5a415a64":"markdown","afad2ec0":"markdown","7c179e05":"markdown"},"source":{"85702390":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8648ec28":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport seaborn as sns","9400553b":"data = pd.read_csv(\"..\/input\/big-mart-sales\/Test-Set.csv\") #Read the data","38d22c42":"data.head(10) #print the top-10 rows","ad7a3c21":"data.info #For known the information of dataset","c0617775":"data.columns #Display the all columns of dataset","80520752":"data.dtypes #For known each columns has which datatype","33a0db2f":"data.isnull() #for chech null value","dee909ff":"data.isnull().sum() #sum of null vlaues","c357e9a6":"data.corr() #correlation between numerical value","d01f40f5":"sns.heatmap(data.isnull(),yticklabels=False,cbar = False,cmap = 'viridis')","db04805a":"data.isnull().mean() #find the mean of null values columns","58024ff2":"data['OutletSize']","e2ab46fe":"mean_value=data['Weight'].mean()\ndata['Weight'].fillna(value=mean_value, inplace=True) #Replace all null value with mean value of Weight coulmn","8e4894cd":"data.isnull().sum()","79cdb98b":"data['ProductID'].unique() #unique value","0f4c7b34":"data['ProductID'].value_counts() #count the vlaues","920718a7":"data['ProductID'].value_counts().sum()","849d8f9a":"plt.figure(figsize=(24,6))\nsns.set_theme()\nbar = sns.barplot(x=data['ProductType'],y=data['Weight'])\nbar.set_title(\"Weight of products\",fontsize=30,weight = 'bold')\nbar.set_xlabel('ProductType',fontsize = 30,weight = 'bold' )\nbar.set_ylabel('Weight',fontsize = 30,weight = 'bold')\n\nbar.set_xticklabels(bar.get_xticklabels(),rotation = 20, size = 10)","ca2059bc":"data['FatContent'].value_counts()","30ba9bf9":"plt.figure(figsize=(16,6))\nsns.set_theme()\ncount_plot = sns.countplot(x=data['FatContent'])\ncount_plot.set_title(\"product is low on fat or not\",fontsize=25,weight = 'bold')\ncount_plot.set_xlabel('FatContent',fontsize = 22,weight = 'bold' )\ncount_plot.set_ylabel('Count',fontsize = 22,weight = 'bold')","3a7ac81a":"data['FatContent'].value_counts().plot(kind='pie')","82be4be9":"fatContent_dummies = pd.get_dummies(data['FatContent']) #Creating dummy column of fatcontent \nfatContent_dummies","1e148cfd":"data = pd.concat([data,fatContent_dummies],axis=1) #join with the original data\ndata.head(8)","a359a397":"plt.figure(figsize=(30,6))\nbar = sns.barplot(x=data['ProductType'] , y = data['ProductVisibility'])\nbar.set_xlabel('ProductType',fontsize = 22,weight = 'bold' )\nbar.set_ylabel('ProductVisibility',fontsize = 22,weight = 'bold')","6c642c38":"plt.figure(figsize=(30,6))\nsns.barplot(x=data['MRP'],y=data['ProductType'])","e8e32c4d":"data['OutletID'].unique()","d2bb3d6a":"data['OutletID'].value_counts()","ad7bff35":"data['EstablishmentYear'].head(8)","723ce4a1":"print(\"Year of Establishment of the outlets: \",data['EstablishmentYear'].min())","331e6c49":"data['OutletSize']","09cacb0d":"data['OutletSize'].value_counts()","3c6a489b":"# filling with most common class\ndf_clean = data.apply(lambda x: x.fillna(x.value_counts().index[0]))\ndf_clean","2e0f3abc":"sns.countplot(x=data['OutletSize'])","eff241ce":"data['LocationType'].value_counts()","0a90fcdb":"sns.countplot(x=data['LocationType'])","ac1f3d17":"locationType = pd.get_dummies(data['LocationType'])\nlocationType","a5360278":"data = pd.concat([data,locationType],axis=1)\ndata","e99cc1b7":"data['OutletType']","1915ae25":"plt.figure(figsize=(16,6))\nsns.countplot(x=data['OutletType'])","09b7e778":"## ALL BASICS PERFORMAENCE OF DATASET","de2a451f":"## OutletID : unique store ID","a53ed9ec":" # So \"Others\" products has maximum Weight","83a2cc35":"##  OutletType : specifies whether the outlet is just a grocery store or some sort of supermarket","1c9d58df":"### So here we can see maximum \"OutletSize\" covered as Medium size","747ff797":"# ProductID : unique product ID","a2577e14":"## MRP : Maximum Retail Price (listed price) of the products","d97c896d":"# OutletType according to loacationType","d1bc72e4":"## IMPORT ALL REQUIRED LIBRARY FOR DATA VISUALIZATION","6d864e42":"# By using countplot","cf52a5b2":"### \"Supermarket Type1\" has 36% - 37%.\n### \"Grocery Store \"    has 7%-8%.\n### \"Supermaket Type3\"  has 6% -7%.\n### \"Supermarket Type2\" has 6% - 7%.","b4e07bcf":"## READ THE DATASET BY HELP OF PANDA LIBARARY","3fc3ef7b":"## By heatmap we can see \"Weight\" an \"OutletSize\" has the null value.","995c0c16":"## OutletSize : the size of the store in terms of ground area covered","2cd3078e":"## EstablishmentYear : year of establishment of the outlets","51169b43":"## Visibility : percentage of total display area of all products in a store allocated to the particular product","cdddafde":"## FatContent : specifies whether the product is low on fat or not","5b89b683":"# Which Product has highest Low Fat","62063747":"# Weight : weight of products","e8a69b95":"# CONTENT\n\n**The dataset provides the product details and the outlet information of the products purchased with their sales value**","a4bb082f":"## DATASET --> Big Mart Sales (EDA) (Test-Set.csv)\n## CONTEXT\n**The data scientists at Big Mart have collected 2013 sales data for 1559 products across 10 stores in different cities. Also, certain attributes of each product and store have been defined. The aim is to build a predictive model and predict the sales of each product at a particular outlet.**\n\n**Using this model, Big Mart will try to understand the properties of products and outlets which play a key role in increasing sales.**\n","e9393ff0":"# By using piechart","58d0eb28":"### unique product id is 1543","5a415a64":" # \" Starchy Foods \" has the maximum Retail Price (MRP-RS.153)","afad2ec0":"## \"Breakfast\" ProductType has the maximum visibility -> 7%","7c179e05":"## LocationType : the type of city in which the store is located"}}