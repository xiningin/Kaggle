{"cell_type":{"0377e5c5":"code","d6153311":"code","e011ce9e":"code","4f0cbff6":"code","8da2d3d0":"code","37fae7c1":"code","a83b1b3c":"code","fd501422":"code","eedf8a56":"markdown","0a05d4e2":"markdown","55f3eca8":"markdown","1c196af1":"markdown","5b117403":"markdown","dba2cb64":"markdown"},"source":{"0377e5c5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport matplotlib.pyplot as plt\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\n\nfrom time import time\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16\n\nfrom keras.callbacks import TensorBoard\n\n# import the necessary packages\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Dense\nfrom keras import backend as K","d6153311":"df = pd.read_csv('..\/input\/train_labels.csv')\nprint(df.head())","e011ce9e":"print('Number of image : ', len(df))\nprint('Ratio labels : ', sum(df['label'].values)\/len(df))\nimg = plt.imread(\"..\/input\/train\/\"+df.iloc[0]['id']+'.tif')\nprint('Images shape', img.shape)","4f0cbff6":"for i in range(5):\n    img = plt.imread(\"..\/input\/train\/\"+df.iloc[i]['id']+'.tif')\n    print(df.iloc[i]['label'])\n    plt.imshow(img)\n    plt.show()","8da2d3d0":"df = pd.read_csv('..\/input\/train_labels.csv')\n\ntrain_datagen = ImageDataGenerator(\n       # horizontal_flip=True,\n       #vertical_flip=True,\n       #brightness_range=[0.5, 1.5],\n       #fill_mode='reflect',                               \n        #rotation_range=15,\n        rescale=1.\/255,\n        #shear_range=0.2,\n        #zoom_range=0.2\n        validation_split=0.15\n    \n)\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_path = '..\/input\/train'\nvalid_path = '..\/input\/train'\n\ntrain_generator = train_datagen.flow_from_dataframe(\n                dataframe=df,\n                directory=train_path,\n                x_col = 'id',\n                y_col = 'label',\n                has_ext=False,\n                subset='training',\n                target_size=(96, 96),\n                batch_size=64,\n                class_mode='binary'\n                )\n\nvalidation_generator = train_datagen.flow_from_dataframe(\n                dataframe=df,\n                directory=valid_path,\n                x_col = 'id',\n                y_col = 'label',\n                has_ext=False,\n                subset='validation', # This is the trick to properly separate train and validation dataset\n                target_size=(96, 96),\n                batch_size=64,\n                shuffle=False,\n                class_mode='binary'\n                )","37fae7c1":"model = Sequential()\nmodel.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = (96, 96, 3)))\nmodel.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(MaxPooling2D(pool_size = 3))\n\nmodel.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(MaxPooling2D(pool_size = 3))\n\nmodel.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(MaxPooling2D(pool_size = 3))\n\nmodel.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'elu'))\nmodel.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'elu'))\nmodel.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'elu'))\nmodel.add(Dropout(0.3))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.summary()\n","a83b1b3c":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nSTEP_SIZE_TRAIN=train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID=validation_generator.n\/\/validation_generator.batch_size\n\nmodel.fit_generator(\n                train_generator,\n                steps_per_epoch=STEP_SIZE_TRAIN,\n                epochs=15,\n                validation_data=validation_generator,\n                validation_steps=STEP_SIZE_VALID)\n","fd501422":"test_df = pd.read_csv('..\/input\/sample_submission.csv')\n\nfrom matplotlib.pyplot import imread\n# Kaggle testing\nfrom glob import glob\nTESTING_BATCH_SIZE = 64\ntesting_files = glob(os.path.join('..\/input\/test\/','*.tif'))\nsubmission = pd.DataFrame()\nprint(len(testing_files))\nfor index in range(0, len(testing_files), TESTING_BATCH_SIZE):\n    data_frame = pd.DataFrame({'path': testing_files[index:index+TESTING_BATCH_SIZE]})\n    data_frame['id'] = data_frame.path.map(lambda x: x.split('\/')[3].split(\".\")[0])\n    data_frame['image'] = data_frame['path'].map(imread)\n    images = np.stack(data_frame.image, axis=0)\n    predicted_labels = [model.predict(np.expand_dims(image\/255.0, axis=0))[0][0] for image in images]\n    predictions = np.array(predicted_labels)\n    data_frame['label'] = predictions\n    submission = pd.concat([submission, data_frame[[\"id\", \"label\"]]])\n    if index % 1000 == 0 :\n        print(index\/len(testing_files) * 100)\nsubmission.to_csv('submission_new_model.csv', index=False, header=True)\nprint(submission.head())","eedf8a56":"<h1><center> CNN with Keras <\/center><h1>","0a05d4e2":"## Some Exploratory Data Analysis (EDA)","55f3eca8":"## Submission","1c196af1":"## Dataset Generators","5b117403":"## Training routine ","dba2cb64":"## Model definition "}}