{"cell_type":{"19dc5a04":"code","553206c5":"code","43713e45":"code","d868a128":"code","7c66fa3c":"code","342fdac4":"code","f46fdd49":"code","cb6f57bb":"code","f6500652":"code","b3d6da61":"code","7285cfbf":"code","5a49d6d9":"code","05ec447c":"code","64cfbd82":"code","c5e7dc19":"code","fd6dc907":"code","323fae3a":"code","c523a15b":"code","9080b3c4":"code","2038d0d5":"code","ae9b410b":"code","375b4ccf":"code","7364ba25":"code","a90cc7f1":"code","6b59b7e8":"code","30390024":"code","51c96af3":"code","e6eceb3b":"code","3fbcce31":"code","1087398c":"code","231f26bc":"code","9c133246":"code","ad3d2031":"code","a37a668f":"code","610a0c0b":"code","e6d893ba":"code","fefeeb2d":"code","2785678a":"code","da164fac":"code","a17fb9c6":"code","e956b46c":"code","e1aa450d":"code","6100b798":"code","fecec1f8":"code","1b85db0c":"code","14c8d9de":"code","0b6e19bb":"code","153e8f75":"code","279828cf":"code","24efea9d":"code","3ccd8dc7":"code","c7c1cefb":"code","7feb0d02":"code","9f418086":"code","0da1816f":"code","ef4ab1a8":"code","e72e7963":"code","e304783a":"code","17bf1786":"code","2f90cf17":"code","5ddea40d":"code","39392de6":"code","6f8ec2b2":"code","59a4eee3":"code","2155ff32":"code","ce10eb91":"code","f6119219":"code","d062095d":"code","b4ee076d":"code","69c2e3f1":"code","a0b58a5b":"code","77de9c33":"code","815195b5":"code","7f696df6":"code","46ce8dea":"code","de0ce253":"code","438d9f29":"code","ad438fd4":"code","a250368b":"code","c3a51051":"code","00d68904":"code","16581939":"code","614ff0b1":"code","ed83d59e":"code","0b01ecf6":"code","97bff1ab":"code","b755f95e":"code","9f3dd1cb":"code","808b5260":"code","17cea113":"code","cea869ff":"code","31e30136":"code","588673c6":"code","c90fcc3a":"code","909cf615":"code","a563ee94":"code","62d85875":"code","2b5aa3c5":"code","f0029d3d":"code","a8d8a086":"code","05247713":"code","6bad2d51":"code","bdd54805":"code","cc7528cb":"code","26aa112f":"code","376f04e6":"code","1022c509":"code","65d5bad7":"code","31e93c3e":"code","61274542":"markdown","232c7782":"markdown","4288f0c9":"markdown","f89e4993":"markdown","e606a04f":"markdown","ec1bc800":"markdown","f84575ea":"markdown","65718855":"markdown","f1975b4b":"markdown","4e145636":"markdown","713f1feb":"markdown","44b05f9b":"markdown","644ded84":"markdown","b16d2433":"markdown","f26813ab":"markdown","c1e73798":"markdown","a28e6723":"markdown","1771b26b":"markdown","99bbf153":"markdown","48d99568":"markdown","30f20e23":"markdown","d47c43dc":"markdown","64de37cd":"markdown","db9b0123":"markdown","c7a8206b":"markdown","9565cefb":"markdown","10b7c8e0":"markdown","d41f243e":"markdown","49949dbc":"markdown","721c471b":"markdown","68f2cf41":"markdown","3b306341":"markdown","5b1a00ab":"markdown","d2a6c653":"markdown","56630b45":"markdown","9ac3bd23":"markdown"},"source":{"19dc5a04":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","553206c5":"from yellowbrick.classifier import ROCAUC\nfrom yellowbrick.classifier import PrecisionRecallCurve\nfrom yellowbrick.classifier import ClassificationReport\nfrom yellowbrick.classifier import ClassPredictionError\nfrom yellowbrick.classifier import DiscriminationThreshold\nfrom yellowbrick.classifier import ConfusionMatrix\nfrom yellowbrick.classifier.threshold import discrimination_threshold\n#!pip install pycomp\n#!pip install pywaffle","43713e45":"import warnings\nwarnings.filterwarnings('ignore')\nimport os\nfrom pandas import DataFrame\nimport pylab as pl\nimport seaborn as sns\nfrom scipy import stats\n#from pywaffle import Waffle\nimport plotly.offline as py\n#from pycomp.viz.insights import *\nfrom collections import Counter\nimport plotly.express as px\n\n#from pywaffle import Waffle\nfrom yellowbrick.classifier import classification_report\nfrom plotly.subplots import make_subplots\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","d868a128":"custom_colors = [\"#c8e7ff\",\"#deaaff\", \"#f72585\",\"#d100d1\",\"#4f000b\",\"#720026\",\"#ce4257\",\n                 \"#ff7f51\",\"#ff9b54\",\"#6930c3\",\"#5e60ce\",\"#0096c7\",\"#48cae4\",\"#ade8f4\",\"#ff7f51\",\n                 \"#ff9b54\",\"#ffbf69\",\"#aa4465\",\"#dd2d4a\",\"#f26a8d\",\"#f49cbb\",\"#ffcbf2\",\"#e2afff\",\n                 \"#ff86c8\",\"#ffa3a5\",\"#ffbf81\",\"#e9b827\",\"#f9e576\"]\ncustomPalette = sns.set_palette(sns.color_palette(custom_colors))\nsns.palplot(sns.color_palette(custom_colors),size=1)\nplt.tick_params(axis='both', labelsize=0, length = 0)\nsns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})","7c66fa3c":"kaggle_train=pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\nkaggle_test=pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nsubmission=pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")","342fdac4":"kaggle_train.head()","f46fdd49":"print(kaggle_train.shape)\nprint(kaggle_train.info())","cb6f57bb":"display(kaggle_train.describe())","f6500652":"from IPython.core.display import HTML\nHTML(\"\"\"\n<style>\n.output_png {\n    display: table-cell;\n    text-align: center;\n    vertical-align: middle;\n}\n<\/style>\n\"\"\")","b3d6da61":"import missingno as msno\nmsno.matrix(kaggle_train)\ntotal = kaggle_train.isnull().sum().sort_values(ascending=False)\npercent_1 = kaggle_train.isnull().sum()\/kaggle_train.isnull().count()*100\npercent_2 = (round(percent_1, 1)).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent_2], axis=1, keys=['Total','%'])\nprint(missing_data.head(5))","7285cfbf":"c = pd.crosstab(kaggle_train.Pclass, kaggle_train.Survived).apply(lambda x: x\/x.sum(), axis=1)\nc[\"odds\"] = c.loc[:, 1] \/ c.loc[:, 0]\ndisplay(c)\n# So the odds of Survival of Pclass1\/ Pclass 3 can be given as\nClass1=1.7000\nClass2=0.3199\nOdds_Ratio=Class1\/Class2\ndisplay(Odds_Ratio)","5a49d6d9":"sns.catplot(\"Survived\", col=\"Embarked\", col_wrap=4,data=kaggle_train,kind=\"count\", height=4,aspect=.6)\nplt.show()","05ec447c":"d = pd.crosstab(kaggle_train.Embarked, kaggle_train.Survived).apply(lambda x: x\/x.sum(), axis=1)\nd[\"odds\"] = d.loc[:, 1] \/ d.loc[:, 0]\ndisplay(d)","64cfbd82":"sns.countplot(kaggle_train['Embarked'], hue=kaggle_train['Sex'])","c5e7dc19":"plt.figure(figsize = (15,7))\nsns.kdeplot(kaggle_train['Fare'][kaggle_train.Survived == 1], color=custom_colors[10], shade=True)\nsns.kdeplot(kaggle_train['Fare'][kaggle_train.Survived == 0], color=custom_colors[12], shade=True)\nplt.legend(['Survived', 'Not Survived'])\nplt.show()","fd6dc907":"mask = np.triu(np.ones_like(kaggle_train.corr(), dtype=bool))\nfig, ax = plt.subplots(figsize=(16,10),dpi=80, facecolor='w', edgecolor='k')\nsns.heatmap(kaggle_train.corr(), mask=mask,linewidth=0.5, cmap=\"YlGnBu\", vmax=.3, center=0,annot = True,\n            square=True)\nplt.show()","323fae3a":"f, ax = plt.subplots(1,2,figsize=(15,8))\nsns.violinplot(\"Pclass\", \"Age\", hue=\"Survived\", data=kaggle_train, split=True, ax=ax[0])\nax[0].set_title('Pclass and Age vs Survived')\nax[0].set_yticks(range(0, 110, 10))\nsns.violinplot(\"Sex\",\"Age\", hue=\"Survived\", data=kaggle_train, split=True, ax=ax[1])\nax[1].set_title('Sex and Age vs Survived')\nax[1].set_yticks(range(0, 110, 10))\nplt.show()","c523a15b":"#https:\/\/www.kaggle.com\/shubhamksingh\/create-beautiful-notebooks-formatting-tutorial","9080b3c4":"def triple_plot(x, title,c):\n    fig, ax = plt.subplots(3,1,figsize=(15,8),sharex=True)\n    sns.distplot(x, ax=ax[0],color=c)\n    ax[0].set(xlabel=None)\n    ax[0].set_title('Histogram + KDE')\n    sns.boxplot(x, ax=ax[1],color=c)\n    ax[1].set(xlabel=None)\n    ax[1].set_title('Boxplot')\n    sns.violinplot(x, ax=ax[2],color=c)\n    ax[2].set(xlabel=None)\n    ax[2].set_title('Violin plot')\n    fig.suptitle(title, fontsize=16)\n    plt.tight_layout(pad=3.0)\n    plt.show()\ntriple_plot(kaggle_train['Age'],'Distribution of Age',custom_colors[12])","2038d0d5":"triple_plot(kaggle_train['Fare'],'Distribution of Fare',custom_colors[10])","ae9b410b":"x1=pd.DataFrame(kaggle_test.isna().sum(),index=kaggle_test.columns)\nx2=pd.DataFrame(kaggle_train.isna().sum(),index=kaggle_train.columns)\nresult = pd.concat([x1, x2], axis=1)\nresult.columns = ['Test_NA', 'Train_NA']\nresult","375b4ccf":"### Dropping Cabin Column\nkaggle_train=kaggle_train.drop([\"Cabin\"],axis=1,inplace=False)\nkaggle_test=kaggle_test.drop([\"Cabin\"],axis=1,inplace=False)","7364ba25":"### Imputing Misisng Value in Embarked Column with Most Frequent(Mode)\nprint(kaggle_train.groupby('Embarked').size())\ndef embarked_impute(kaggle_train, kaggle_test):\n    for i in [kaggle_train, kaggle_test]:\n        i['Embarked'] = i['Embarked'].fillna('S')\n    return kaggle_train, kaggle_test\nkaggle_train, kaggle_test = embarked_impute(kaggle_train, kaggle_test)","a90cc7f1":"kaggle_test['Embarked'] = kaggle_test['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\nkaggle_train['Embarked']=kaggle_train['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)","6b59b7e8":"kaggle_test['Sex'] = kaggle_test['Sex'].map({'female': 0, 'male': 1}).astype(int)\nkaggle_train['Sex']=kaggle_train['Sex'].map({'female': 0, 'male': 1}).astype(int)","30390024":"kaggle_train[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False).T","51c96af3":"kaggle_test['Total_Member']=(kaggle_test['Parch']+kaggle_test['SibSp']+1)\nkaggle_train['Total_Member']=(kaggle_train['Parch']+kaggle_train['SibSp']+1)","e6eceb3b":"kaggle_train['Title'] = kaggle_train['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\nkaggle_test['Title'] = kaggle_test['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\n#kaggle_train['Title'].value_counts()","3fbcce31":"fig = px.box(kaggle_train, y=\"Age\",points=\"all\")\nfig.show()","1087398c":"def age_impute(kaggle_train, kaggle_test):\n    for i in [kaggle_train, kaggle_test]:\n        i['Age'] = i['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n        data = kaggle_train.groupby(['Title','Pclass'])['Age']\n        #i['Age'] = data.transform(lambda x: x.fillna(x.median()))\n        i['Age'] = data.transform(lambda x: x.fillna(x.mode()))\n\n    return train, test\nkaggle_train, kaggle_test = embarked_impute(kaggle_train, kaggle_test)","231f26bc":"kaggle_train['Age']=kaggle_train['Age'].fillna(kaggle_train.groupby([\"Title\",\"Sex\",\"Pclass\"])['Age'].transform('median'),inplace=False)\nkaggle_test['Age']=kaggle_test['Age'].fillna(kaggle_test.groupby([\"Title\",\"Sex\",\"Pclass\"])['Age'].transform('median'),inplace=False)\nkaggle_test['Age']=kaggle_test['Age'].ffill()","9c133246":"kaggle_test.info()","ad3d2031":"# fig = px.box(kaggle_train, y=\"Fare\",points=\"all\")\n# fig.show()\nplt.figure(figsize = (8,4))\nsns.boxplot(data = kaggle_train.Fare,orient=\"h\")","a37a668f":"# Q1 = kaggle_train['Fare'].quantile(0.25)\n# Q3 = kaggle_train['Fare'].quantile(0.75)\n# IQR = Q3 - Q1\n# print(IQR)\n# print(kaggle_train['Fare'] < (Q1 - 1.5 * IQR))|(kaggle_train['Fare'] > (Q3 + 1.5 * IQR))","610a0c0b":"plt.figure(figsize = (15,7))\nfrom yellowbrick.regressor import CooksDistance\n# Load the regression dataset\nX = kaggle_train[\"Age\"].values.reshape(-1,1)\nY = kaggle_train[\"Fare\"]\n# Instantiate and fit the visualizer\nvisualizer = CooksDistance()\nvisualizer.fit(X, Y)\nvisualizer.show()","e6d893ba":"q = kaggle_train['Fare'].quantile(0.99)\ndisplay(q)\nkaggle_train[kaggle_train.Fare > q]","fefeeb2d":"avg =kaggle_train['Fare'].mean()\nr=kaggle_train.loc[(kaggle_train[\"Fare\"]>q), 'Fare'] = avg # Replacing the Row with Base Price less than q with Average Price\nr","2785678a":"kaggle_train=kaggle_train.drop([\"PassengerId\",\"Name\",\"SibSp\",\"Parch\",\"Ticket\",\"Title\"],axis=1,inplace=False)\nkaggle_test=kaggle_test.drop([\"PassengerId\",\"Name\",\"SibSp\",\"Parch\",\"Ticket\",\"Title\"],axis=1,inplace=False)","da164fac":"kaggle_test['Fare']=kaggle_test['Fare'].fillna(kaggle_test.groupby([\"Sex\",\"Pclass\"])['Fare'].transform('median'),inplace=False)","a17fb9c6":"pd.get_dummies(kaggle_train['Embarked'], prefix='Emb_')\nkaggle_train = pd.concat([kaggle_train, pd.get_dummies(kaggle_train['Embarked'], prefix='Emb_')], axis=1)\npd.get_dummies(kaggle_test['Embarked'], prefix='Emb_')\nkaggle_test = pd.concat([kaggle_test, pd.get_dummies(kaggle_test['Embarked'], prefix='Emb_')], axis=1)","e956b46c":"pd.get_dummies(kaggle_train['Pclass'], prefix='Pc_')\nkaggle_train = pd.concat([kaggle_train, pd.get_dummies(kaggle_train['Pclass'], prefix='Pc_')], axis=1)\npd.get_dummies(kaggle_test['Pclass'], prefix='Pc_')\nkaggle_test = pd.concat([kaggle_test, pd.get_dummies(kaggle_test['Pclass'], prefix='Pc_')], axis=1)","e1aa450d":"pd.get_dummies(kaggle_train['Sex'], prefix='Sx_')\nkaggle_train = pd.concat([kaggle_train, pd.get_dummies(kaggle_train['Sex'], prefix='Sx_')], axis=1)\npd.get_dummies(kaggle_test['Sex'], prefix='Sx_')\nkaggle_test = pd.concat([kaggle_test, pd.get_dummies(kaggle_test['Sex'], prefix='Sx_')], axis=1)","6100b798":"kaggle_train=kaggle_train.drop([\"Embarked\",\"Pclass\",\"Sex\",\"Emb__1\",\"Pc__1\",\"Sx__0\"],axis=1,inplace=False)\nkaggle_test=kaggle_test.drop([\"Embarked\",\"Pclass\",\"Sex\",\"Emb__1\",\"Pc__1\",\"Sx__0\"],axis=1,inplace=False)","fecec1f8":"#correlation heatmap of dataset\ndef correlation_heatmap(kaggle_train):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        kaggle_train.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\ncorrelation_heatmap(kaggle_train)","1b85db0c":"X=kaggle_train.drop(['Survived'],axis=1)\nY=kaggle_train.Survived\nfrom statsmodels.tools.tools import add_constant\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nX_vif = add_constant(X)\nvif = pd.Series([variance_inflation_factor(X_vif.values, i) \n               for i in range(X_vif.shape[1])], \n              index=X_vif.columns)","14c8d9de":"print(vif.sort_values(ascending = False).head(10))","0b6e19bb":"df=kaggle_train[[\"Emb__0\",\"Emb__2\",\"Pc__2\",\"Pc__3\",\"Sx__1\",\"Survived\"]]\ndf.head()","153e8f75":"X=df.drop(['Survived'],axis=1)\nY=df.Survived\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=123)","279828cf":"from sklearn.feature_selection import chi2\nF_P_Values=chi2(X_train,y_train)\np_values=pd.DataFrame(F_P_Values[1])\np_values.index=X_train.columns\np_values.sort_values(by=[0],ascending=True)","24efea9d":"from sklearn.feature_selection import mutual_info_classif\nmutual_info=mutual_info_classif(X_train,y_train)\nmutual_info=pd.DataFrame(mutual_info)\nmutual_info.index=X_train.columns\nmutual_info.sort_values(by=[0],ascending=False)","3ccd8dc7":"kaggle_train=kaggle_train.drop(['Emb__0','Pc__2'],axis=1,inplace=False)\nkaggle_test=kaggle_test.drop(['Emb__0','Pc__2'],axis=1,inplace=False)","c7c1cefb":"# Scaling train Data\nx=kaggle_train[['Fare','Age','Total_Member']]\nfrom sklearn.preprocessing import MinMaxScaler\nscaled_features = MinMaxScaler().fit_transform(x.values)\nscaled_features_df = pd.DataFrame(scaled_features,index=x.index, columns=x.columns)","7feb0d02":"kaggle_train=kaggle_train.drop(['Fare','Age','Total_Member'],axis=1,inplace=False)\nkaggle_train=pd.concat([scaled_features_df,kaggle_train], axis=1).reindex(kaggle_train.index)\nkaggle_train.head()","9f418086":"# Scaling Test data\nx=kaggle_test[['Fare','Age','Total_Member']]\nfrom sklearn.preprocessing import MinMaxScaler\nscaled_features = MinMaxScaler().fit_transform(x.values)\nscaled_features_df = pd.DataFrame(scaled_features,index=x.index, columns=x.columns)","0da1816f":"kaggle_test=kaggle_test.drop(['Fare','Age','Total_Member'],axis=1,inplace=False)\nkaggle_test=pd.concat([scaled_features_df,kaggle_test], axis=1).reindex(kaggle_test.index)\nkaggle_test.head()","ef4ab1a8":"kaggle_train.head()","e72e7963":"X=kaggle_train.drop([\"Survived\"],axis=1)\nY=kaggle_train.Survived","e304783a":"from sklearn.model_selection import train_test_split\nX_train,X_Val,Y_train,Y_Val=train_test_split(X,Y, test_size = 0.30,random_state=120)","17bf1786":"Y_train.value_counts()","2f90cf17":"from sklearn.linear_model import LogisticRegression\nclf = LogisticRegression()\nclf.fit(X_train,Y_train)\ny_pred = clf.predict(X_Val)\nacc_log_clf=clf.score(X_train,Y_train)\nacc_log_clf","5ddea40d":"print(\"Test Accuracy:\",clf.score(X_Val, Y_Val))","39392de6":"#Confusion Matrix\nplt.figsize=(10, 8)\ncm = ConfusionMatrix(clf, classes=[0,1],size=(520,520))\ncm.fit(X_train,Y_train)\ncm.score(X_Val,Y_Val)\ncm.show()","6f8ec2b2":"#Classification Report\nclasses=['0','1']\nvisualizer = ClassificationReport(clf, classes=classes, support=True,size=(720,360))\nvisualizer.fit(X_train, Y_train)        # Fit the visualizer and the model\nvisualizer.score(X_Val, Y_Val)        # Evaluate the model on the test data\nvisualizer.show() ","59a4eee3":"#ROC Curve\nvisualizer = ROCAUC(clf, classes=['0','1'],size=(720,720))\nvisualizer.fit(X_train, Y_train)        # Fit the training data to the visualizer\nvisualizer.score(X_Val, Y_Val)        # Evaluate the model on the test data\nvisualizer.show()       ","2155ff32":"#Precission Recall Curve\nviz = PrecisionRecallCurve(clf,size=(720,720),colormap=\"YlOrRd\")\nviz.fit(X_train, Y_train)\nviz.score(X_Val, Y_Val)\nviz.show()","ce10eb91":"# Class Prediction Error\nvisualizer = ClassPredictionError(clf,classes=classes,size=(540,360))\n# Fit the training data to the visualizer\nvisualizer.fit(X_train, Y_train)\n# Evaluate the model on the test data\nvisualizer.score(X_Val, Y_Val)\n# Draw visualization\nvisualizer.show()","f6119219":"# Descriminant Threshold \ndiscrimination_threshold(clf, X_train, Y_train,size=(720,720))","d062095d":"from sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.metrics import confusion_matrix\n\nprobs = clf.predict_proba(X_Val)[::,1] #Let's take probablities from our classifier, instead of classes.\nauc = roc_auc_score(Y_Val, probs)\nprint(auc)\nfpr, tpr, threshold = roc_curve(Y_Val, probs)\n","b4ee076d":"optimal_idx = np.argmax(tpr - fpr)\noptimal_threshold = threshold[optimal_idx]\noptimal_threshold","69c2e3f1":"new_predictions = np.where(probs>optimal_threshold, 1, 0)\nfrom mlxtend.plotting import plot_confusion_matrix\nconf_mat=confusion_matrix(Y_Val, new_predictions)\nfig, ax = plot_confusion_matrix(conf_mat=conf_mat,figsize=(8, 8),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.show()","a0b58a5b":"from sklearn.metrics import classification_report\nprint(classification_report(Y_Val, new_predictions))","77de9c33":"import xgboost as xgb\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\nfrom sklearn.model_selection import cross_val_score\n\nparameters = {'n_estimators': [50],\n        'max_depth': range(1, 11),\n        'learning_rate': [1e-3, 1e-2, 1e-1, 0.5, 1.],\n        'subsample': np.arange(0.05, 1.01, 0.05),\n        'min_child_weight': range(1, 10),\n        'objective': ['reg:squarederror'],\n        'n_jobs': [-1], # replace \"nthread\"\n        'verbosity': [0]} # add this line to slient warning message\n\nxgb_clf = xgb.XGBClassifier()\nxgb_clf = GridSearchCV(xgb_clf,parameters,cv=10,scoring='accuracy',)\nxgb_clf.fit(X_train, Y_train)\nprint(f'Best parameters {xgb_clf.best_params_}')\nprint('-----')\nprint(f'Mean cross-validated accuracy score of the best_estimator: ' + f'{xgb_clf.best_score_:.3f}')","815195b5":"print(\"Test Accuracy:\",xgb_clf.score(X_Val, Y_Val))","7f696df6":"Y_Pred=xgb_clf.predict(X_Val)\ncnf_mat=confusion_matrix(Y_Val, Y_Pred)\nfig, ax = plot_confusion_matrix(conf_mat=cnf_mat,figsize=(8, 8),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.show()","46ce8dea":"print(classification_report(Y_Val,Y_Pred))","de0ce253":"from sklearn.ensemble import RandomForestClassifier\nparameters={'bootstrap': [True],\n    'max_depth': [10,20,30,40,50],\n    'max_features': [2, 3],\n    'min_samples_leaf': [3, 4, 5],\n    'min_samples_split': [8, 10, 12],\n    'n_estimators': [100, 200, 300]}\nrf_clf=RandomForestClassifier()\nrf_clf = GridSearchCV(rf_clf,parameters,cv=5,n_jobs=-1)\nrf_clf.fit(X_train,Y_train)\nprint(f'Best parameters {rf_clf.best_params_}')\nprint('-----')\nprint(f'Mean cross-validated accuracy score of the best_estimator: ' + f'{rf_clf.best_score_:.3f}')\n","438d9f29":"print(\"Test Accuracy:\",rf_clf.score(X_Val, Y_Val))","ad438fd4":"Y_Pred=rf_clf.predict(X_Val)\ncnf_mat=confusion_matrix(Y_Val, Y_Pred)\nfig, ax = plot_confusion_matrix(conf_mat=cnf_mat,figsize=(8, 8),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.show()","a250368b":"print(classification_report(Y_Val,Y_Pred))","c3a51051":"import lightgbm as lgbm\nparameters = {'n_estimators': [5, 10, 15, 20, 25, 50],\n              'learning_rate': [0.01, 0.05, 0.1],\n              'num_leaves': [7, 15, 31]}\nlgbm_clf = lgbm.LGBMClassifier()\nlgbm_clf = GridSearchCV(lgbm_clf,parameters,cv=5,scoring='accuracy',)\nlgbm_clf.fit(X_train,Y_train)\nprint(f'Best parameters {lgbm_clf.best_params_}')\nprint('-----')\nprint(f'Mean cross-validated accuracy score of the best_estimator: '+f'{lgbm_clf.best_score_:.3f}')","00d68904":"print(\"Test Accuracy:\",lgbm_clf.score(X_Val, Y_Val))","16581939":"Y_Pred=lgbm_clf.predict(X_Val)\ncnf_mat=confusion_matrix(Y_Val, Y_Pred)\nfig, ax = plot_confusion_matrix(conf_mat=cnf_mat,figsize=(8, 8),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.show()","614ff0b1":"print(classification_report(Y_Val,Y_Pred))","ed83d59e":"from sklearn.tree import DecisionTreeClassifier\nparameters = {\"criterion\":[\"gini\",\"entropy\"],\n              \"max_depth\":range(1,10),\n              \"min_samples_split\":range(1,20,1),\n              \"min_samples_leaf\":range(1,6)}\n\ndf_clf=DecisionTreeClassifier()\ndf_clf = GridSearchCV(df_clf,parameters,cv=5,scoring='accuracy',)\ndf_clf.fit(X_train,Y_train)\nprint(f'Best parameters {df_clf.best_params_}')\nprint('-----')\nprint(f'Mean cross-validated accuracy score of the best_estimator: '+f'{df_clf.best_score_:.3f}')","0b01ecf6":"print(\"Test Accuracy:\",df_clf.score(X_Val, Y_Val))","97bff1ab":"Y_Pred=df_clf.predict(X_Val)\ncnf_mat=confusion_matrix(Y_Val, Y_Pred)\nfig, ax = plot_confusion_matrix(conf_mat=cnf_mat,figsize=(8, 8),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.show()","b755f95e":"print(classification_report(Y_Val,Y_Pred))","9f3dd1cb":"import catboost as cb\nfrom catboost import CatBoostClassifier\n\nparameters = {'depth': [4, 7, 10],\n              'learning_rate' : [0.03, 0.1, 0.15],\n              'l2_leaf_reg': [1,4,9],\n              'iterations': [300]}\ncb_clf = cb.CatBoostClassifier()\ncb_clf = GridSearchCV(cb_clf, parameters, scoring=\"roc_auc\", cv = 5)\ncb_clf.fit(X_train,Y_train)\nprint(f'Best parameters {cb_clf.best_params_}')\nprint('-----')\nprint(f'Mean cross-validated accuracy score of the best_estimator: '+f'{cb_clf.best_score_:.3f}')","808b5260":"print(\"Test Accuracy:\",cb_clf.score(X_Val, Y_Val))","17cea113":"Y_Pred=cb_clf.predict(X_Val)\ncnf_mat=confusion_matrix(Y_Val, Y_Pred)\nfig, ax = plot_confusion_matrix(conf_mat=cnf_mat,figsize=(8, 8),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.show()","cea869ff":"print(classification_report(Y_Val,Y_Pred))","31e30136":"from sklearn.ensemble import  AdaBoostClassifier\nada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),random_state = 42)\nparameters = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n              \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n              \"n_estimators\" :[10, 100, 200, 250],\n              \"learning_rate\":  [0.05, 0.5, 1.5, 2.5]}\nada_clf = GridSearchCV(ada_clf, parameters, cv=5, scoring=\"accuracy\", n_jobs= -1)\nada_clf.fit(X_train, Y_train)\nprint(f'Best parameters {ada_clf.best_params_}')\nprint('-----')\nprint(f'Mean cross-validated accuracy score of the best_estimator: '+f'{ada_clf.best_score_:.3f}')","588673c6":"print(\"Test Accuracy:\",ada_clf.score(X_Val, Y_Val))","c90fcc3a":"Y_Pred=ada_clf.predict(X_Val)\ncnf_mat=confusion_matrix(Y_Val, Y_Pred)\nfig, ax = plot_confusion_matrix(conf_mat=cnf_mat,figsize=(8, 8),\n                                show_absolute=True,\n                                show_normed=True,\n                                colorbar=True)\nplt.show()","909cf615":"print(classification_report(Y_Val,Y_Pred))","a563ee94":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense","62d85875":"num_classes = X_train.shape\nnum_classes","2b5aa3c5":"# define classification model\ndef classification_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(100, activation='relu', input_shape=(6,)))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dense(16, activation='relu'))\n    model.add(Dense(4, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    \n    # compile model\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    return model","f0029d3d":"# build the model\nmodel = classification_model()\n# fit the model\nHistory=model.fit(X_train, Y_train, validation_data=(X_Val, Y_Val), epochs=100, verbose=2)\n# evaluate the model\nscores = model.evaluate(X_Val, Y_Val, verbose=0)","a8d8a086":"import matplotlib.style as style\nplt.figure(figsize=(15,8))\nstyle.use('fivethirtyeight')\nplt.plot(History.history['loss'],label='train')\nplt.xlabel('epochs')\nplt.plot(History.history['val_loss'],label='test')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","05247713":"plt.figure(figsize=(15,8))\nplt.plot(History.history['accuracy'],label='train')\nplt.xlabel('epochs')\nplt.plot(History.history['val_accuracy'],label='test')\nplt.ylabel('accuracy')\nplt.legend()\nplt.show()","6bad2d51":"models = pd.DataFrame({'Model': ['Logistic Regression', 'XG Boost', 'Random Forest ','LightGBM', \n                                 'Decision Tree','Cat Boost', 'AdaBoost'],\n                       'Train_Score': [clf.score(X_train,Y_train),xgb_clf.score(X_train,Y_train),\n                                       rf_clf.score(X_train,Y_train),lgbm_clf.score(X_train,Y_train),\n                                       df_clf.score(X_train,Y_train),cb_clf.score(X_train,Y_train),\n                                       ada_clf.score(X_train,Y_train)],\n                       'Validation_Score': [clf.score(X_Val,Y_Val),xgb_clf.score(X_Val,Y_Val),\n                                       rf_clf.score(X_Val,Y_Val),lgbm_clf.score(X_Val,Y_Val),\n                                       df_clf.score(X_Val,Y_Val),cb_clf.score(X_Val,Y_Val),\n                                       ada_clf.score(X_Val,Y_Val)]})\nmodels.sort_values(by='Train_Score', ascending=False)","bdd54805":"#Model Selection\nmodels['Difference']=models['Train_Score']-models['Validation_Score']","cc7528cb":"models.sort_values(by='Difference', ascending=True)","26aa112f":"kaggle_test.head()","376f04e6":"submission\npreds = lgbm_clf.predict(kaggle_test.values)","1022c509":"submission.head()","65d5bad7":"\nsubmission_df = pd.DataFrame(columns=['PassengerId', 'Survived'])\nsubmission_df['PassengerId'] = submission['PassengerId']\nsubmission_df['Survived'] = preds\nsubmission_df.to_csv('submissions.csv', header=True, index=True)\nsubmission_df.head(10)","31e93c3e":"submission.head()","61274542":"<div style=\"color:white;\n           display:fill;\n           border-radius:1px;\n           background-color:#aa4465;\n           font-size:155%;\n           font-family:Times New Roman;\n           letter-spacing:0.8px\">\n\n<p style=\"text-align:center;color:white;\">Decision Tree-GridSearchCV\n    <\/h1>\n    <\/p>\n<\/div>","232c7782":"<span style=\"color:red\">Receiver Operating Characteristic (ROC) curves are a measure of a classifier\u2019s predictive quality that compares and visualizes the tradeoff between the models\u2019 sensitivity and specificity. The ROC curve displays the true positive rate on the Y axis and the false positive rate on the X axis on both a global average and per-class basis. The ideal point is therefore the top-left corner of the plot: false positives are zero and true positives are one.<span>\n\n<span style=\"color:green\">This leads to another metric, area under the curve (AUC), a computation of the relationship between false positives and true positives. The higher the AUC, the better the model generally is. However, it is also important to inspect the \u201csteepness\u201d of the curve, as this describes the maximization of the true positive rate while minimizing the false positive rate. Generalizing \u201csteepness\u201d usually leads to discussions about convexity, which we do not get into here.<span>","4288f0c9":"<div style=\"color:white;\n           display:fill;\n           border-radius:1px;\n           background-color:#aa4465;\n           font-size:155%;\n           font-family:Times New Roman;\n           letter-spacing:0.8px\">\n\n<p style=\"text-align:center;color:white;\">CatBoost-GridSearchCV\n    <\/h1>\n    <\/p>\n<\/div>","f89e4993":"<div style=\"color:white;\n           display:fill;\n           border-radius:1px;\n           background-color:#aa4465;\n           font-size:155%;\n           font-family:Times New Roman;\n           letter-spacing:0.8px\">\n\n<p style=\"text-align:center;color:white;\">Logistic Regression\n    <\/h1>\n    <\/p>\n<\/div>","e606a04f":"##### Outlier Detection Using Boz Plot, IQR & Cooks Distance","ec1bc800":"#### Dropping Columns in Order to Avoid Dummy Variable trap","f84575ea":"<div style=\"color:white;\n           display:fill;\n           border-radius:1px;\n           background-color:#aa4465;\n           font-size:150%;\n           font-family:Verdana;\n           letter-spacing:0.6px\">\n\n<p style=\"padding: 15px;\n              color:white;\">\n    Feature Engineering\n    <\/p>\n<\/div>\n","65718855":"### Model Building","f1975b4b":"<div style=\"color:white;\n           display:fill;\n           border-radius:1px;\n           background-color:#aa4465;\n           font-size:155%;\n           font-family:Times New Roman;\n           letter-spacing:0.8px\">\n<p style=\"text-align:center;color:white;\">XGBoost-GridSearchCV\n    <\/h1>\n    <\/p>\n<\/div>","4e145636":"#### Chi-Squared Test","713f1feb":"### Updating model based on optimal probability threshold","44b05f9b":"#### Getting Dummies(One Hot Encoding)","644ded84":"<span style=\"color:green\">Precision:<span>\n<span style=\"color:red\">Precision can be seen as a measure of a classifier\u2019s exactness. For each class, it is defined as the ratio of true positives to the sum of true and false positives. Said another way, \u201cfor all instances classified positive, what percent was correct?\u201d<span>\n\n<span style=\"color:green\">Recall:<span>\n<span style=\"color:red\">Recall is a measure of the classifier\u2019s completeness; the ability of a classifier to correctly find all positive instances. For each class, it is defined as the ratio of true positives to the sum of true positives and false negatives. Said another way, \u201cfor all instances that were actually positive, what percent was classified correctly?\u201d<span>\n\n<span style=\"color:green\">f1 score:<span>\n<span style=\"color:red\">The F1 score is a weighted harmonic mean of precision and recall such that the best score is 1.0 and the worst is 0.0. Generally speaking, F1 scores are lower than accuracy measures as they embed precision and recall into their computation. As a rule of thumb, the weighted average of F1 should be used to compare classifier models, not global accuracy.<span>\n\n<span style=\"color:green\">support:<span>\n<span style=\"color:red\">Support is the number of actual occurrences of the class in the specified dataset. Imbalanced support in the training data may indicate structural weaknesses in the reported scores of the classifier and could indicate the need for stratified sampling or rebalancing. Support doesn\u2019t change between models but instead diagnoses the evaluation process.<span>","b16d2433":"#### Correlation Among Features","f26813ab":"#### NAME TITLE------ AGE VALUE IMPUTATION","c1e73798":"By Information Gain we can see Emb__0 column can be dropped as with the help of chi2-test and, Mutual Info Gain maid clear that it doesnot add any value to our analysis","a28e6723":"<div style=\"color:white;\n           display:fill;\n           border-radius:1px;\n           background-color:#aa4465;\n           font-size:155%;\n           font-family:Times New Roman;\n           letter-spacing:0.8px\">\n\n<p style=\"text-align:center;color:white;\">Neural Net\n    <\/h1>\n    <\/p>\n<\/div>","1771b26b":"#### NAME TITLE","99bbf153":"#### PARCH & SIBSP","48d99568":"<p style=\"background-color:lightblue;\">\n<span style=\"color:red\">DiscriminationThreshold Visualizes how precision, recall, f1 score, and queue rate change as the discrimination threshold increases. For probabilistic, binary classifiers, the discrimination threshold is the probability at which you choose the positive class over the negative. Generally this is set to 50%, but adjusting the discrimination threshold will adjust sensitivity to false positives which is described by the inverse relationship of precision and recall with respect to the threshold.<span><p>\n<p style=\"background-color:lightblue;\">\n<span style=\"color:red\">The visualizer also accounts for variability in the model by running multiple trials with different train and test splits of the data. The variability is visualized using a band such that the curve is drawn as the median score of each trial and the band is from the 10th to 90th percentile.<span><p>\n<p style=\"background-color:lightblue;\">\n<span style=\"color:red\">The visualizer is intended to help us to determine an appropriate threshold for decision making (e.g. at what threshold do we have a human review the data), given a tolerance for precision and recall or limiting the number of records to check (the queue rate).<span><p>\n\n<p style=\"background-color:lightblue;\">\n<span style=\"color:k\">Queue Rate: The \u201cqueue\u201d is the spam folder or the inbox of the fraud investigation desk. This metric describes the percentage of instances that must be reviewed. If review has a high cost (e.g. fraud prevention) then this must be minimized with respect to business requirements; if it doesn\u2019t (e.g. spam filter), this could be optimized to ensure the inbox stays clean.<spam><p>\n    \n<p style=\"background-color:cornsilk;\">\nOne common use of binary classification algorithms is to use the score or probability they produce to determine cases that require special treatment. For example, a fraud prevention application might use a classification algorithm to determine if a transaction is likely fraudulent and needs to be investigated in detail. In the figure above, we present an example where a binary classifier determines if an email is \u201cspam\u201d (the positive case) or \u201cnot spam\u201d (the negative case). Emails that are detected as spam are moved to a hidden folder and eventually deleted.<p>\n\n<p style=\"background-color:cornsilk;\">\nMany classifiers use either a decision_function to score the positive class or a predict_proba function to compute the probability of the positive class. If the score or probability is greater than some discrimination threshold then the positive class is selected, otherwise, the negative class is.<p>\n\n<p style=\"background-color:cornsilk;\">\nGenerally speaking, the threshold is balanced between cases and set to 0.5 or 50% probability. However, this threshold may not be the optimal threshold: often there is an inverse relationship between precision and recall with respect to a discrimination threshold. By adjusting the threshold of the classifier, it is possible to tune the F1 score (the harmonic mean of precision and recall) to the best possible fit or to adjust the classifier to behave optimally for the specific application.<p>","30f20e23":"<span style=\"color:red\">Precision-Recall curves are a metric used to evaluate a classifier\u2019s quality, particularly when classes are very imbalanced. The precision-recall curve shows the tradeoff between precision, a measure of result relevancy, and recall, a measure of completeness. For each class, precision is defined as the ratio of true positives to the sum of true and false positives, and recall is the ratio of true positives to the sum of true positives and false negatives.<span>\n\n<span style=\"color:red\">A large area under the curve represents both high recall and precision, the best case scenario for a classifier, showing a model that returns accurate results for the majority of classes it selects.<span>","d47c43dc":"#### CABIN","64de37cd":"#### EMBARKED","db9b0123":"#### VIF","c7a8206b":"<span style=\"color:blue\">\nWe see that the probability that a Passengers of Class 3 has lower probability of Survival substantially lower than the Class 2 and Class 1 Passengers (47.28% and 62.96%). In the odds for a Passengers of Class 3 survival being much less than 1 (around 0.31), while the odds for class 1 is around 1.7 which is pretty much high.<\/span><br>\n<span style=\"color:red\">\nThe odds ratio of Survival, comparing Class1 to Class2, is around 5.314. In other words, Class 1 Passengers has around 5.314 times greater odds of survival than Class2 (in the population represented by these data).<\/span>","9565cefb":"#### FARE","10b7c8e0":"<div style=\"color:white;\n           display:fill;\n           border-radius:1px;\n           background-color:#aa4465;\n           font-size:155%;\n           font-family:Times New Roman;\n           letter-spacing:0.8px\">\n\n<p style=\"text-align:center;color:white;\">LightGBM-GridSearchCV\n    <\/h1>\n    <\/p>\n<\/div>","d41f243e":"#### Min-Max Scaling ","49949dbc":"<span style=\"color:red\">A confusion matrix shows each combination of the true and predicted classes for a test data set.<span>","721c471b":"> Seems we can drop emb__2 & Pc__2 as their P-Value is Gr.than 5%. But let first check it by one more method which is Information Gain.","68f2cf41":"<div style=\"color:white;\n           display:fill;\n           border-radius:1px;\n           background-color:#aa4465;\n           font-size:155%;\n           font-family:Times New Roman;\n           letter-spacing:0.8px\">\n\n<p style=\"text-align:center;color:white;\">Random Forest-GridSearchCV\n    <\/h1>\n    <\/p>\n<\/div>","3b306341":"**<span style=\"color:green\">If we drop above shown outliers then we might be loosing datas as we can see in index number 258 & 738. These are passsengers travelling alone and the cost of Fare is High. So, we must look at Fare per Person in order to detect necessary outliers.<span>","5b1a00ab":"<div style=\"color:white;\n           display:fill;\n           border-radius:1px;\n           background-color:#aa4465;\n           font-size:155%;\n           font-family:Times New Roman;\n           letter-spacing:0.8px\">\n\n<p style=\"text-align:center;color:white;\">AdaBoost-GridSearchCV\n    <\/h1>\n    <\/p>\n<\/div>","d2a6c653":"#### SEX","56630b45":"<span style=\"color:red\">Class Prediction Error chart that shows the support for each class in the fitted classification model displayed as a stacked bar. Each bar is segmented to show the distribution of predicted classes for each class. It is initialized with a fitted model and generates a class prediction error chart on draw.<span>","9ac3bd23":"**Log Odds**"}}