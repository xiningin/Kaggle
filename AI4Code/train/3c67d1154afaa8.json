{"cell_type":{"06c2225e":"code","d9d24ef5":"code","c3a2823a":"code","edda52b8":"code","3290592d":"code","3c025cd4":"code","d652c445":"code","6a6f8900":"code","0f2fbcaa":"code","97482183":"code","17ca395e":"code","234cf19f":"code","d7bf66be":"code","4e790b40":"code","4ce1cd45":"code","86c693b0":"code","47a7091e":"code","7ef7afce":"code","3030396e":"code","f5fa20c7":"code","ffe53ca5":"code","d22b1676":"code","dd207fe8":"code","1014f9ba":"code","d80cfb60":"code","b880cb07":"code","25a54413":"code","bfa0579b":"code","26118762":"code","7f3411d6":"code","5095bd3c":"code","50b62925":"code","8f3f94c3":"code","af16212f":"code","f630dda9":"code","28e869d8":"code","dd43d108":"code","43f7f68a":"code","ce5126fe":"code","34191878":"code","200aed08":"code","544b6842":"code","3a4ba7ec":"code","d3042e8c":"code","af48d095":"code","bde0375a":"code","0561f48b":"markdown","c9ceebdd":"markdown","7a4815f6":"markdown","fdcd1ac1":"markdown","9e9ec88d":"markdown","a878bc9a":"markdown"},"source":{"06c2225e":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","d9d24ef5":"dataset = pd.read_csv('..\/input\/telecom-users-dataset\/telecom_users.csv')#import dataset\ndataset.head()","c3a2823a":"dataset.drop('Unnamed: 0',axis=1,inplace=True)#Dropping unnecesarry features\ndataset.drop(\"customerID\",axis=1,inplace = True)","edda52b8":"dataset.head()","3290592d":"dataset.describe()","3c025cd4":"dataset.info()","d652c445":"dataset.isnull().sum()#checking Null values in Dataset","6a6f8900":"dataset['TotalCharges'] = pd.to_numeric(dataset['TotalCharges'],errors = 'coerce')#Converting Total charges to numerical","0f2fbcaa":"dataset['TotalCharges'].isnull().sum()#checking null values","97482183":"dataset[\"TotalCharges\"]=dataset[\"TotalCharges\"].fillna(dataset[\"TotalCharges\"].mean())#replacing null values with mean value","17ca395e":"dataset.describe()","234cf19f":"numerical_feature = [feature for feature in dataset.columns if dataset[feature].dtype != 'O']#extracting numerical features from data\nnumerical_feature","d7bf66be":"categorical_feature = [feature for feature in dataset.columns if dataset[feature].dtype == \"O\"]#extracting categorical features from data\ncategorical_feature","4e790b40":"for feature in categorical_feature: #calculating no of categories in features\n    print(\"{} has {} features\".format(feature,len(dataset[feature].unique())))","4ce1cd45":"for feature in numerical_feature: #distribution of numerical values\n    dataset[feature].hist(bins=25)\n    plt.xlabel(feature)\n    plt.ylabel(\"count\")\n    plt.title(feature)\n    plt.show()","86c693b0":"for feature in categorical_feature: #evaluating the impact of categorical features on churn\n    sns.countplot(data=dataset,x=feature,hue = 'Churn')\n    plt.show()","47a7091e":"dataset = pd.get_dummies(data=dataset, columns= categorical_feature,drop_first=True)#one hot encoding","7ef7afce":"dataset.head()","3030396e":"import matplotlib.pyplot as plt #evaluating correlation\nplt.rcParams[\"figure.figsize\"] = (20,30)\nsns.heatmap(dataset.corr(),annot=True)","f5fa20c7":"def corr(dataset,threshold): #this function will select features with high correlation \n    corr_matrix = dataset.corr()\n    col_corr = set()\n    for i in range(len(corr_matrix)):\n        for j in range(i):\n            if corr_matrix.iloc[i,j]> threshold:\n                col_name = corr_matrix.columns[i]\n                col_corr.add(col_name)\n    return col_corr\n                ","ffe53ca5":"corr_features = corr(dataset,0.85)\nlen(corr_features)","d22b1676":"corr_features #highly correlated features","dd207fe8":"drop_features = ['DeviceProtection_No internet service',\n 'OnlineBackup_No internet service',\n 'OnlineSecurity_No internet service',\n 'StreamingMovies_No internet service',\n 'StreamingTV_No internet service',\n 'TechSupport_No internet service']","1014f9ba":"dataset.drop(drop_features,axis=1,inplace=True)#dropping highly correlated features","d80cfb60":"dataset.head()","b880cb07":"dataset['Churn_Yes'].value_counts()#checking for imbalances in target variable","25a54413":"dataset.describe()","bfa0579b":"from sklearn.preprocessing import StandardScaler#perfoming pre-processing by applying Standard scaler\nscaler = StandardScaler()\nnumerical_feature.remove('SeniorCitizen')\ndata = dataset.copy()\nfeatures = data[numerical_feature]\nfeatures = data = scaler.fit_transform(features.values)","26118762":"scaled_features = pd.DataFrame(features, columns = ['TotalCharges_new','MonthlyCharges_new','tenure_new'])\nscaled_features.reset_index(inplace=True)\ndataset.reset_index(inplace=True)","7f3411d6":"dataset = pd.concat([dataset,scaled_features],axis=1)","5095bd3c":"dataset.head()","50b62925":"dataset.drop(['TotalCharges','MonthlyCharges','tenure','index'],axis=1,inplace=True)#dropping duplicate columns","8f3f94c3":"dataset.head()","af16212f":"X = dataset.drop('Churn_Yes',axis=1) \nY = dataset['Churn_Yes']","f630dda9":"from sklearn.model_selection import train_test_split #train test split\nx_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=40)","28e869d8":"from sklearn.linear_model import LogisticRegression #importing models and metrics\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn import svm\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score,classification_report,accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier","dd43d108":"model_classify = [LogisticRegression(),DecisionTreeClassifier(),RandomForestClassifier(),GradientBoostingClassifier(),KNeighborsClassifier(n_neighbors=12)]","43f7f68a":"for model in model_classify: #using loop to evaluate data using different models\n    model.fit(x_train,y_train)\n    model.score(x_train,y_train)\n    y_pred = model.predict(x_test)\n    print(\"F1 score of {} is {}\".format(model,f1_score(y_test,y_pred)))\n    print(\"Accuracy score of {} is {:.2f}%\\n\".format(model, accuracy_score(y_test, y_pred)*100))","ce5126fe":"for model in model_classify: #checking ROC score for train and test data\n    model.fit(x_train,y_train)\n    ytrain_pred = model.predict_proba(x_train)\n    ytest_pred = model.predict_proba(x_test)\n    print(\"ROC train Score {} is {}\".format(model,roc_auc_score(y_train,ytrain_pred[:,1])))\n    print(\"ROC test Score {} is {}\".format(model,roc_auc_score(y_test,ytest_pred[:,1])))\n    print(\"***************************************************************************************\")","34191878":"pred = [] #extracting mean ROC score\nfor model in model_classify:\n    pred.append(pd.Series(model.predict_proba(x_test)[:,1]))\nfinal_prediction = pd.concat(pred,axis=1).mean(axis=1)\nprint(\"test ROC-AUC\",roc_auc_score(y_test,final_prediction))","200aed08":"from sklearn.metrics import roc_curve, auc #finding threshold,fpr,tpr\nfpr,tpr,threshold = roc_curve(y_test,final_prediction)\nthreshold","544b6842":"from sklearn.metrics import accuracy_score #finding accuracy with different thresholds\naccuracy_ls = []\nfor thres in threshold:\n    y_pred = np.where(final_prediction>thres,1,0)\n    accuracy_ls.append(accuracy_score(y_test,y_pred,normalize=True))\n    \naccuracy_ls = pd.concat([pd.Series(threshold),pd.Series(accuracy_ls)],axis=1)\naccuracy_ls.columns = ['threshold','accuracy']\naccuracy_ls.sort_values(by='accuracy',ascending=False,inplace =True)\naccuracy_ls.head()","3a4ba7ec":"from sklearn.ensemble import GradientBoostingClassifier #choosing Gradient Boosting as a final model\ngradient_model = GradientBoostingClassifier(learning_rate=0.1,n_estimators=100)\ngradient_model.fit(x_train,y_train)\ny_pred = gradient_model.predict(x_test)\nprint(\"roc test score :\",roc_auc_score(y_test,y_pred))","d3042e8c":"threshold = 0.525896 #selecting the best threshold and evaluating the model on its basis\npredicted_proba = gradient_model.predict_proba(x_test)\npredicted = (predicted_proba [:,1] >= threshold).astype('int')\naccuracy = accuracy_score(y_test, predicted)*100\nprint(accuracy)\n","af48d095":"from sklearn.metrics import precision_score, recall_score, f1_score #measuring perfomance of model\np_score = precision_score(y_test, y_pred)\nprint('p_score',p_score)\nr_score = recall_score(y_test, y_pred)\nprint('r_score',r_score)\nf1 = f1_score(y_test, y_pred)\nprint('f1 score',f1)","bde0375a":"from sklearn.metrics import confusion_matrix # confusion matrix\nconfusion_matrix(y_test,y_pred)","0561f48b":"## Data Cleaning","c9ceebdd":"## Exploratory Data analysis","7a4815f6":"## Data Preprocessing","fdcd1ac1":"## Selecting The Best Model","9e9ec88d":"## Results","a878bc9a":"## Evaluating the best model"}}