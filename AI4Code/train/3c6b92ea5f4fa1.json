{"cell_type":{"2d500e44":"code","b767dbf9":"code","47e821c3":"code","a794b615":"code","ba24f587":"code","8d94076d":"code","899d4121":"code","3502db9b":"code","67510b98":"code","9505fca3":"code","a976ff77":"code","b0d3f33e":"code","5bbef70c":"code","74a48b29":"code","44a37572":"code","eba03daa":"code","b9f2cc76":"code","c30d3139":"code","9aec8985":"code","b55df66b":"code","dd44d79c":"code","e39c07e2":"code","d7aae293":"code","9bb6fe9e":"code","4ab034e8":"code","8051ac80":"code","73c4913d":"code","7447f88c":"code","f928b37d":"code","be65a1db":"code","c9883ab8":"code","7abf1a92":"code","5924a6dd":"code","4e0071a6":"code","ad2fef1e":"code","605b32ed":"markdown","4ef0eafa":"markdown","f8253a47":"markdown","363458a6":"markdown","7979d2bb":"markdown","886a3986":"markdown","3e00116b":"markdown","85151361":"markdown","a3bdee51":"markdown","0c442ace":"markdown","a4be6532":"markdown","bc93f646":"markdown","0e9363f0":"markdown","164aebc9":"markdown"},"source":{"2d500e44":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams","b767dbf9":"import os\nprint(os.listdir(\"..\/input\"))","47e821c3":"dataset = [line.rstrip() for line in open('..\/input\/amazon-alexa-reviews\/amazon_alexa.tsv')]","a794b615":"import pandas as pd\ndataset = pd.read_csv('..\/input\/amazon-alexa-reviews\/amazon_alexa.tsv', sep='\\t')","ba24f587":"dataset.head()","8d94076d":"dataset.describe()","899d4121":"dataset.groupby('rating').count()","3502db9b":"dataset.groupby('feedback').count()","67510b98":"dataset.query('feedback==\"0\" & rating>2')","9505fca3":"dataset[dataset['feedback'] == 0]['verified_reviews'].iloc[2]","a976ff77":"#to calculate how long the reviews are:\n\ndataset['length'] = dataset['verified_reviews'].apply(len)\ndataset.head()","b0d3f33e":"dataset.length.max()","5bbef70c":"dataset.query('length==\"2851\"')","74a48b29":"dataset[dataset['length'] == 2851]['verified_reviews'].iloc[0]","44a37572":"dataset.length.min()","eba03daa":"dataset.query('length==\"2\"')","b9f2cc76":"dataset.query('length==\"1\"')","c30d3139":"dataset.query('length==\"3\"')","9aec8985":"%matplotlib inline","b55df66b":"dataset['length'].plot(bins=50, kind='hist')","dd44d79c":"# Cleaning the texts\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer \nfrom nltk.tokenize import word_tokenize\ncorpus=[]\nfor i in range(0,3150):\n    \n    #replace non-letter with space\n    review = re.sub('[^a-zA-Z]', ' ', dataset['verified_reviews'][i] )\n    \n    #convert all to lower case\n    review=review.lower()\n    \n    #split\n    review=review.split()\n    \n    #stemming and Lemmanization\n    ps=PorterStemmer()\n    lm = WordNetLemmatizer()\n    \n    #review=[ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n    review = [lm.lemmatize(word) for word in review if word not in set(stopwords.words('english'))] \n    review=' '.join(review)\n    corpus.append(review)","e39c07e2":"corpus","d7aae293":"#creating Bag of Words\nfrom sklearn.feature_extraction.text import CountVectorizer\ncv=CountVectorizer(max_features=1500)\nX=cv.fit_transform(corpus).toarray()\ny=dataset.iloc[:,4].values","9bb6fe9e":"print(cv.get_feature_names())","4ab034e8":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)","8051ac80":"X_train","73c4913d":"# Fitting Random Forest classifier with 100 trees to the Training set\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)","7447f88c":"# Predicting the Test set results\ny_pred = classifier.predict(X_test)","f928b37d":"y_pred","be65a1db":"# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)","c9883ab8":"cm","7abf1a92":"from sklearn.metrics import precision_score\n# calculate prediction\nprecision = precision_score(y_test, y_pred, average='binary')","5924a6dd":"precision","4e0071a6":"from sklearn.metrics import f1_score\nscore = f1_score(y_test, y_pred, average='binary')","ad2fef1e":"score","605b32ed":"An example of a review having negative feedback.","4ef0eafa":"if a review has a rating of 3 or more than 3, it is given a feedback of 1, else 0","f8253a47":"Wow, that's a pretty long review!","363458a6":"Majority of the reviews are reviews ranging between 0 and ~200 characters","7979d2bb":"Let's start with cleaning the texts and data preparation","886a3986":"Longest review is of 2851 characters. Let us see which one it is.","3e00116b":"You can use this data to analyze Amazon\u2019s Alexa products, discover insights into consumer reviews and train machine learning models for sentiment analysis and analyze customer reviews.","85151361":"The least ratings are rating 2 having only 96 entries and rating 5 is the one having the highest entries","a3bdee51":"Let's perform a small EDA on the dataset","0c442ace":"We will be using the data to perform Sentiment Analysis on the dataset.","a4be6532":"About the Data\n\nThis dataset consists of a nearly 3000 Amazon customer reviews (input text), star ratings, date of review, variant and feedback of various amazon Alexa products like Alexa Echo, Echo dots, Alexa Firesticks etc.","bc93f646":"Let us now calculate Precision and F1 Score to determine the correctness of the model.","0e9363f0":"As we can see, the dataset has almost 10 times positive reviews compared to negative reviews.","164aebc9":"Now let us check some of the minimum character reviews."}}