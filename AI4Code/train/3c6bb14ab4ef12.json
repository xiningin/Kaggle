{"cell_type":{"95b27ade":"code","f09b49ea":"code","10c6f0a2":"code","4b80f161":"code","e42a2ac2":"code","2ec5b59f":"code","0401a681":"code","f5d4219d":"code","8170cf3a":"code","68bcdddb":"code","f03fa572":"code","831698a9":"code","a2684df0":"code","cbe0c632":"code","e4a45812":"code","3994707d":"code","9dc8a361":"code","5a313f6c":"code","fd643760":"code","ddcaec18":"code","2f820d84":"code","bf10c609":"code","d3d24fd2":"code","b88d9b8d":"code","a239bb53":"code","307d1db6":"code","0e5c739e":"code","72428a19":"code","90734dc5":"code","60ae0e74":"code","deaa66fd":"code","8a86ce7f":"code","42c1b438":"code","c37ac6e5":"code","6b3d379c":"code","f6fe57d5":"code","c807892b":"code","a04fdf52":"code","e5d2dd1b":"code","b62172e2":"code","733d65a9":"code","a414fdf2":"code","96231e78":"code","72108982":"code","296e846e":"code","64810d02":"code","a3e252be":"code","a8ea7718":"code","79c11918":"code","3de85d8b":"code","83f4b1e7":"code","70bb5020":"code","dfad0064":"code","863f8e17":"code","de20265e":"code","ed0dd6d1":"code","0c168a60":"code","eef3198e":"code","0fcc7235":"code","a33d16ce":"code","d7a1034f":"code","3970efa8":"code","9ebfa017":"code","ed6bcc3c":"code","4dae94d4":"code","a8e8ae06":"code","059c5452":"code","23a66a57":"code","193ccf3a":"code","f48b59c1":"code","299304d0":"code","58323d8c":"code","db12d997":"code","406c6aff":"code","92f18095":"code","3e5276af":"code","b7a4ff64":"code","fdd9122d":"code","a11ae805":"code","508f5ebe":"code","3600e085":"code","155bd708":"code","76bc5651":"code","d040ee33":"code","d3b3e3d6":"code","7bb98caa":"code","6bca5a8e":"code","4a9b8ad4":"code","8bd89d57":"code","76ec7ee8":"code","3dafd8fa":"code","077972c8":"code","b73c3a3e":"code","b6c2e744":"code","c1fe5357":"code","9461c95e":"code","d2f694f5":"code","06e311ad":"code","a4d64c63":"code","dcd1ce88":"code","1ccb53ca":"code","95259d13":"code","88533b38":"code","dcade233":"code","dd0cafdd":"code","520a0c94":"code","9e6de37a":"code","1d5d0427":"code","14eda1c3":"code","243d76c9":"code","186c0069":"code","b94f443b":"code","879160cd":"code","bd067d2b":"code","e5f9580c":"code","bd06a400":"code","0206648c":"code","35127a95":"code","3e15a365":"code","8c538c98":"code","bb6cac91":"code","5393b47e":"code","7a212baa":"code","009e33c5":"code","4ae63da4":"code","405f6639":"code","53aa67cc":"code","d5e92dff":"code","095eaeb9":"code","76885e14":"code","e97a4e7a":"code","dde37256":"code","abcde1b5":"code","6542c7bc":"code","a7f8b5d3":"code","a3021beb":"code","2b881453":"code","6c82abce":"code","6357a926":"code","9716d9e1":"code","debf76df":"code","1ff055e7":"code","49fa98a3":"code","25a308be":"code","d02d1ef4":"code","2c1e47ed":"code","24388a88":"code","e010a800":"code","b81e0893":"code","a29e1bb8":"code","2a3236e9":"code","440d57c7":"code","5051f609":"code","8ea069cf":"code","420ad7cb":"markdown","c0ccf998":"markdown","b18a982e":"markdown","db4042cf":"markdown","7cbf12c8":"markdown","c49afd3a":"markdown","33c9caa6":"markdown","731e0d46":"markdown","e28c1ff1":"markdown","23505112":"markdown","15b4bb3a":"markdown","5fcdf717":"markdown","9d6c4286":"markdown","73413c7f":"markdown","ba3fd838":"markdown","4a4b3bc9":"markdown","5dbb7c1a":"markdown","8f43455a":"markdown","ce528d5e":"markdown","04f05641":"markdown","f64a5471":"markdown","70a891ca":"markdown","a9de45bd":"markdown","1b2fff33":"markdown","808073ad":"markdown","ad127111":"markdown","a7bb7700":"markdown","54cc487f":"markdown","20d6dd12":"markdown","9d8aa116":"markdown","58e9a83a":"markdown","ba5a99c2":"markdown","51dcab14":"markdown","8315ca3a":"markdown","dff30c86":"markdown","0c492fda":"markdown","5c97881b":"markdown","898d34dc":"markdown","483181e0":"markdown","510a04ba":"markdown","76562fc1":"markdown","5c9296df":"markdown","87c2b97a":"markdown","2c600b64":"markdown","e1ab5897":"markdown","70aec8ec":"markdown","c0f4aa01":"markdown","862a6d08":"markdown"},"source":{"95b27ade":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f09b49ea":"# B\u00fct\u00fcn k\u00fct\u00fcphaneler\nimport numpy as np\nimport pandas as pd \nfrom sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score, accuracy_score\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import scale \nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn import model_selection\nfrom sklearn.linear_model import LinearRegression \nfrom sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn import neighbors\nfrom sklearn.svm import SVR\n\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\n\n\n#uyar\u0131 mesaj\u0131nn\u0131 gelmesini istemiyorsan, yaz\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","10c6f0a2":"hit = pd.read_csv(\"\/kaggle\/input\/hitters-baseball-data\/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna() #eksik g\u00f6zlemleri u\u00e7ur\ndms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\ny = df[\"Salary\"]\nX_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25, \n                                                    random_state=42)","4b80f161":"# train seti, ba\u011f\u0131ms\u0131z de\u011fi\u015fkenlerle\nX_train.head()","e42a2ac2":"X_test.head()","2ec5b59f":"knn_model = KNeighborsRegressor().fit(X_train, y_train)\nknn_model.get_params()","0401a681":"#kom\u015fu say\u0131s\u0131\nknn_model.n_neighbors","f5d4219d":"#kom\u015fu say\u0131s\u0131: Ne t\u00fcr metri\u011fi var\nknn_model.metric","8170cf3a":"#kullan\u0131lm\u0131\u015f \nknn_model.effective_metric_","68bcdddb":"# model nesnesi i\u00e7inden al\u0131nabilecekleri g\u00f6rmek\ndir(knn_model)","f03fa572":"# tahmin edilen model\nknn_model.predict(X_test)[0:5]","831698a9":"# tahmini Y de\u011ferleri, yani maa\u015f\ny_pred = knn_model.predict(X_test)","a2684df0":"#hata kareler ortalmas\u0131n\u0131n kare k\u00f6k\u00fc\n#RMSE\nnp.sqrt(mean_squared_error(y_test, y_pred))","cbe0c632":"# k= kom\u015fu say\u0131\u015f\u0131\n# n_neigbors=5 \u00f6n tan\u0131ml\u0131 de\u011feri 5\nknn_model.get_params()","e4a45812":"range(10)","3994707d":"for k in range(10):\n    print(k)","9dc8a361":"# hata keler ortalamas\u0131nn karek\u00f6k\u00fc\n# el il k say\u0131s\u0131n\u0131 bulma\nRMSE = [] \n\nfor k in range(20): \n    k = k+1\n    knn_model = KNeighborsRegressor(n_neighbors = k).fit(X_train, y_train)\n    # train i\u00e7in \n    y_pred = knn_model.predict(X_train) \n    \n    rmse = np.sqrt(mean_squared_error(y_train,y_pred)) \n    RMSE.append(rmse) \n    print(\"k =\" , k , \"i\u00e7in RMSE de\u011feri: \", rmse)","5a313f6c":"from sklearn.model_selection import GridSearchCV\nknn_params = {'n_neighbors': np.arange(1,30,1)}","fd643760":"#knn model nesnesi\nknn = KNeighborsRegressor()","ddcaec18":"#en iyi kom\u015fu say\u0131s\u0131n\u0131 bulma\nknn_cv_model = GridSearchCV(knn, knn_params, cv = 10)","2f820d84":"#modeli \u00e7al\u0131\u015ft\u0131rma, fit edilme\nknn_cv_model.fit(X_train, y_train)","bf10c609":"# best params\n# k en iyi ka\u00e7t\u0131r? komu\u015fu say\u0131s\u0131 \nknn_cv_model.best_params_[\"n_neighbors\"]","d3d24fd2":"RMSE = [] \nRMSE_CV = []\nfor k in range(10):\n    k = k+1\n    knn_model = KNeighborsRegressor(n_neighbors = k).fit(X_train, y_train)\n    y_pred = knn_model.predict(X_train) \n    rmse = np.sqrt(mean_squared_error(y_train,y_pred)) \n    rmse_cv = np.sqrt(-1*cross_val_score(knn_model, X_train, y_train, cv=10, \n                                         scoring = \"neg_mean_squared_error\").mean())\n    RMSE.append(rmse) \n    RMSE_CV.append(rmse_cv)\n    print(\"k =\" , k , \"i\u00e7in RMSE de\u011feri: \", rmse, \"RMSE_CV de\u011feri: \", rmse_cv )","b88d9b8d":"# final model \nknn_tuned = KNeighborsRegressor(\n    n_neighbors = knn_cv_model.best_params_[\"n_neighbors\"])","a239bb53":"knn_tuned.fit(X_train, y_train)","307d1db6":"#final modelin test hatas\u0131\n# ilkel test hatas\u0131na g\u00f6re daha da d\u00fc\u015fm\u00fc\u015f\n\nnp.sqrt(mean_squared_error(y_test, knn_tuned.predict(X_test)))","0e5c739e":"#de\u011fi\u015fkenlerin \u00f6nem d\u00fczeylerinin hesaplanm\u0131\u015f \u015fekli.\nImportance = pd.DataFrame({\"Importance\": knn_tuned.feature_importances_*100},\n                         index = X_train.columns)\n\nImportance.sort_values(by = \"Importance\", \n                       axis = 0, \n                       ascending = True).plot(kind =\"barh\", color = \"r\")\n\nplt.xlabel(\"De\u011fi\u015fken \u00d6nem D\u00fczeyleri\")\nplt.gca.legend_ = None","72428a19":"hit = pd.read_csv(\"\/kaggle\/input\/hitters-baseball-data\/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna()\ndms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\ny = df[\"Salary\"]\nX_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25, \n                                                    random_state=42)","90734dc5":"from sklearn.svm import SVR","60ae0e74":"# karnenl linear se\u00e7tik, do\u011frusal olmayanlarda kernel de\u011fi\u015ftirilir.\nsvr_model = SVR(\"linear\").fit(X_train, y_train)","deaa66fd":"svr_model.get_params()","8a86ce7f":"#model tahmin\nsvr_model.predict(X_train)[0:5]","42c1b438":"#model tahmin\nsvr_model.predict(X_test)[0:5]","c37ac6e5":"# sabit katsay\u0131lar,\nsvr_model.intercept_","6b3d379c":"#veri setindeki katsay\u0131lar\u0131\nsvr_model.coef_\n\n# model denklemi nas\u0131l yaz\u0131labilir?","f6fe57d5":"#ilkel test hatas\u0131: SVR valide edilmeden,optimun ceza parametresi de\u011feri bulunmadan, bulu\u015fmu\u015f olan hatas\u0131\n\ny_pred = svr_model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","c807892b":"# radial basis function kernel\n# do\u011frusal olmayan kernel\nsvr_model = SVR(\"rbf\").fit(X_train, y_train)","a04fdf52":"#ilkel test hatas\u0131\ny_pred = svr_model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","e5d2dd1b":"svr_model.get_params()","b62172e2":"svr_model = SVR(\"linear\")","733d65a9":"svr_model.get_params()","a414fdf2":"#parametre say\u0131s\u0131 art\u0131k\u00e7a, i\u015flem uzacakt\u0131r.\n# 10 c paremetresi yazd\u0131k\u00e7a, \n# C ceza katsay\u0131s\u0131\nsvr_params = {\"C\":  [0.1,0.5,1,3]}\nsvr_cv_model = GridSearchCV(svr_model, \n                            svr_params, cv = 5).fit(X_train,y_train)","96231e78":"# hangi parametre daha iyi ?\nsvr_cv_model.best_params_","72108982":"# verbose = 2 yaz\u0131nca durumu raporlar.\n#GridSearchCV fonksiyonunun n_jobs arg\u00fcman\u0131 \"-1\"e e\u015fitlendi\u011finde fonksiyon nas\u0131l davran\u0131r? \n## \u0130\u015flemcileri maksimum performansla kullan\u0131r \nsvr_cv_model = GridSearchCV(svr_model, svr_params, cv = 5, \n                            verbose = 2, #\u00e7al\u0131\u015fma raporunu da yan\u0131nlar\n                            n_jobs= -1 # maksimun i\u015flemci g\u00fcc\u00fc kullanma\n                           ).fit(X_train,y_train)","296e846e":"# hangi parametre daha iyi ?\nsvr_cv_model.best_params_","64810d02":"svr_tuned =(SVR(\"linear\", \n                C =0.5).\n            fit(X_train, y_train))","a3e252be":"# testleri tahmin etmeni istiyorum.\n# opitmun edilmi\u015f modeli kullanmak\ny_pred = svr_tuned.predict(X_test)","a8ea7718":"# hata kareler de\u011ferini bulmak\nnp.sqrt(mean_squared_error(y_test, y_pred))","79c11918":"#de\u011fi\u015fkenlerin \u00f6nem d\u00fczeylerinin hesaplanm\u0131\u015f \u015fekli.\nImportance = pd.DataFrame({\"Importance\": svr_tuned.feature_importances_*100},\n                         index = X_train.columns)\n\nImportance.sort_values(by = \"Importance\", \n                       axis = 0, \n                       ascending = True).plot(kind =\"barh\", color = \"r\")\n\nplt.xlabel(\"De\u011fi\u015fken \u00d6nem D\u00fczeyleri\")\nplt.gca.legend_ = None","3de85d8b":"import pandas as pd\nhit = pd.read_csv(\"\/kaggle\/input\/hitters-baseball-data\/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna()\ndms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\ny = df[\"Salary\"]\nX_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25, \n                                                    random_state=42)","83f4b1e7":"# nesne : d\u00f6n\u00fc\u015ft\u00fcrme\n# standartla\u015ft\u0131rma\nscaler = StandardScaler()","70bb5020":"# train seti standart hale geldi\nscaler.fit(X_train)\n# X train \u00f6l\u00e7eklendirilmi\u015ftir\nX_train_scaled = scaler.transform(X_train)\n\n# test  seti standart hale geldi\nscaler.fit(X_test)\n# X test \u00f6l\u00e7eklendirilmi\u015ftir\nX_test_scaled = scaler.transform(X_test)","dfad0064":"# multilayer perceptron: \u00e7ok katmanl\u0131 alg\u0131lama\n# Multilayer Perceptron (MLP)\n\nmlp_model =MLPRegressor().fit(X_train_scaled, y_train)\nmlp_model.get_params()","863f8e17":"#  tahmin ettt\u011fimz de\u011ferler\nmlp_model.predict(X_test_scaled)[0:5]","de20265e":"# ilkel parametre\n#ilkel test hatas\u0131\ny_pred =mlp_model.predict(X_test_scaled)\nnp.sqrt(mean_squared_error(y_test,y_pred))","ed0dd6d1":"# alpha: ceza katsay\u0131lar\n# toplojik ifade etme, girdi\u011fimiz de\u011fer kadar katman\n# hidden layers= gizli katman\n#(10,2) iki katmanl\u0131 10 ve 2 n\u00f6ronlu\n#\nmlp_params = {\"alpha\": [0.1, 0.01, 0.02, 0.001, 0.0001],\n              \"hidden_layer_sizes\": [(10,20), (5,5), (100,100)], # gizli katman say\u0131s\u0131\n             }\nmlp_params","0c168a60":"# mlp_model nesnesi parametrelerleoynanmam\u0131\u015f hali idi.\n\nmlp_cv_model=GridSearchCV(mlp_model, mlp_params, \n                          cv =10, verbose =2, \n                          n_jobs=-1).fit(X_train_scaled,y_train)","eef3198e":"# en iyi parametre de\u011ferleri nelerdir?\nmlp_cv_model.best_params_","0fcc7235":"#final\nmlp_tuned =MLPRegressor(alpha =0.1, \n                        hidden_layer_sizes = (100, 100) ).fit(X_train_scaled, y_train)","a33d16ce":"#ilkel test hatas\u0131, tune edilmemi\u015f 659 idi\ny_pred = mlp_tuned.predict(X_test_scaled)\nnp.sqrt(mean_squared_error(y_test, y_pred))","d7a1034f":"#de\u011fi\u015fkenlerin \u00f6nem d\u00fczeylerinin hesaplanm\u0131\u015f \u015fekli.\nImportance = pd.DataFrame({\"Importance\": mlp_tuned.feature_importances_*100},\n                         index = X_train.columns)\n\nImportance.sort_values(by = \"Importance\", \n                       axis = 0, \n                       ascending = True).plot(kind =\"barh\", color = \"r\")\n\nplt.xlabel(\"De\u011fi\u015fken \u00d6nem D\u00fczeyleri\")\nplt.gca.legend_ = None","3970efa8":"hit = pd.read_csv(\"\/kaggle\/input\/hitters-baseball-data\/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna()\ndms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\ny = df[\"Salary\"]\nX_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.30, \n                                                    random_state=42)","9ebfa017":"X_train = pd.DataFrame(X_train[\"Hits\"])\nX_test = pd.DataFrame(X_test[\"Hits\"])\n\n# regreson kurup model arg\u00fcm olu\u015fturmakt\ncart_model = DecisionTreeRegressor().fit(X_train, y_train)","ed6bcc3c":"cart_model.get_params()","4dae94d4":"import matplotlib.pyplot as plt\n\nX_grid = np.arange(min(np.array(X_train)), max(np.array(X_train)), 0.01)\nX_grid = X_grid.reshape((len(X_grid), 1))\n\nplt.scatter(X_train, y_train, color = 'red') \nplt.plot(X_grid, cart_model.predict(X_grid), color = \"blue\")\n\nplt.title(\"CART REGRESSION TREE\")\nplt.xlabel(\"At\u0131\u015f Say\u0131s\u0131(Hits)\")\nplt.ylabel(\"Maa\u015f (Salary)\");","a8e8ae06":"# regreson kurup model arg\u00fcm olu\u015fturmakt\ncart_model = DecisionTreeRegressor(max_leaf_nodes = 3).fit(X_train, y_train)\nimport matplotlib.pyplot as plt\n\nX_grid = np.arange(min(np.array(X_train)), max(np.array(X_train)), 0.01)\nX_grid = X_grid.reshape((len(X_grid), 1))\n\nplt.scatter(X_train, y_train, color = 'red') \nplt.plot(X_grid, cart_model.predict(X_grid), color = \"blue\")\n\nplt.title(\"CART REGRESSION TREE\")\nplt.xlabel(\"At\u0131\u015f Say\u0131s\u0131(Hits)\")\nplt.ylabel(\"Maa\u015f (Salary)\");","059c5452":"# regreson kurup model arg\u00fcm olu\u015fturmakt\ncart_model = DecisionTreeRegressor(max_leaf_nodes = 10).fit(X_train, y_train)\nimport matplotlib.pyplot as plt\n\nX_grid = np.arange(min(np.array(X_train)), max(np.array(X_train)), 0.01)\nX_grid = X_grid.reshape((len(X_grid), 1))\n\nplt.scatter(X_train, y_train, color = 'red') \nplt.plot(X_grid, cart_model.predict(X_grid), color = \"blue\")\n\nplt.title(\"CART REGRESSION TREE\")\nplt.xlabel(\"At\u0131\u015f Say\u0131s\u0131(Hits)\")\nplt.ylabel(\"Maa\u015f (Salary)\");","23a66a57":"# tahmin\n# regreson kurup model arg\u00fcm olu\u015fturmakt\n# tek de\u011fi\u015fkenli model olu\u015fturma\ncart_model = DecisionTreeRegressor(max_leaf_nodes = 10).fit(X_train, y_train)\n\ncart_model.predict(X_test)[0:5]","193ccf3a":"# tune edilmemi\u015f, ilkel test hatas\u0131\ny_pred = cart_model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test,y_pred))","f48b59c1":"# CART: E\u011fer genellebilir kayg\u0131n\u0131z yoksa, mevcut durumu ifade etmek i\u00e7in CART en ba\u015far\u0131 algoritmalardan biridir. Olaylar\u0131 iyi tasvir eder. Hedef De\u011fi\u015fkene, ba\u011f\u0131ms\u0131z de\u011fi\u015fkenlerin nas\u0131l homojenle\u015fmesi gerekti\u011fini en iyi \u015fekilde anlat\u0131r.\n\ncart_model.get_params()","299304d0":"cart_model = DecisionTreeRegressor( ).fit(X_train, y_train)\n\n# tune edilmi\u015f\ny_pred = cart_model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test,y_pred))","58323d8c":"cart_model = DecisionTreeRegressor( max_depth = 10).fit(X_train, y_train)\n\n# tune edilmi\u015f\ny_pred = cart_model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test,y_pred))","db12d997":"cart_model = DecisionTreeRegressor( max_depth = 5).fit(X_train, y_train)\n\n# tune edilmi\u015f\ny_pred = cart_model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test,y_pred))","406c6aff":"#max_leaf_nodes,\n# max_depth= maksimun derinlik, a\u011fa\u00e7 ne kadar derinle\u015ftisn.\n# min_samples_split\n#min_samples_split : son yapra\u011f\u0131n yaprak olmas\u0131 i\u00e7in gereken \u00f6rnek say\u0131s\u0131.\ncart_model = DecisionTreeRegressor( max_depth = 3).fit(X_train, y_train)\n\n# tune edilmi\u015f\ny_pred = cart_model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test,y_pred))","92f18095":"cart_model = DecisionTreeRegressor( max_depth = 1).fit(X_train, y_train)\n\n# tune edilmi\u015f\ny_pred = cart_model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test,y_pred))","3e5276af":"#hiperparemetreler hakk\u0131nda bilgi almak i\u00e7in\n#splitter \n# min_samples_leaf = nereye kadar dallanma yap\u0131lacak. \u00f6rne 3 denirse, 3 daldan az olursa duru. daha fazla dallanma olmaz\n\n# a\u011f\u0131c\u0131n gene\n?cart_model","b7a4ff64":"cart_model.get_params().keys()","fdd9122d":"#paremetreleri girelim.\ncart_params= { \"max_depth\": [2,3,4,5,10,20], # maksimun derinlik\n           \"min_samples_split\": [2,10,5,30,50,100,300,500]}","a11ae805":"# \ncart_model = DecisionTreeRegressor( )","508f5ebe":"# cross validation 10\n\ncart_cv_model = GridSearchCV(cart_model,\n                             cart_params,\n                            cv =10).fit(X_train,  y_train)","3600e085":"cart_cv_model.best_params_","155bd708":"# tune edilmi\u015f CART modeli\ncart_tuned = DecisionTreeRegressor( max_depth=4, \n                                   min_samples_split=50).fit(X_train, y_train)","76bc5651":"y_pred = cart_tuned.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))\n\n# hiperparemetrelerin de\u011ferlerinig g\u00f6rme","d040ee33":"#de\u011fi\u015fkenlerin \u00f6nem d\u00fczeylerinin hesaplanm\u0131\u015f \u015fekli.\nImportance = pd.DataFrame({\"Importance\": cart_tuned.feature_importances_*100},\n                         index = X_train.columns)\n\nImportance.sort_values(by = \"Importance\", \n                       axis = 0, \n                       ascending = True).plot(kind =\"barh\", color = \"r\")\n\nplt.xlabel(\"De\u011fi\u015fken \u00d6nem D\u00fczeyleri\")\nplt.gca.legend_ = None","d3b3e3d6":"hit = pd.read_csv(\"\/kaggle\/input\/hitters-baseball-data\/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna()\ndms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\ny = df[\"Salary\"]\nX_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25, \n                                                    random_state=42)","7bb98caa":"from sklearn.ensemble import RandomForestRegressor","6bca5a8e":"# random state ayarlamas\u0131 yapmak i\u00e7im.\n# rfmodel: model nesnesi\nrf_model = RandomForestRegressor(random_state = 42)","4a9b8ad4":"rf_model.fit(X_train, y_train)","8bd89d57":"rf_model.get_params()\n# max leaf: maks yaprak node\n# max_depth\n# max_features: b\u00f6l\u00fcnmelerde g\u00f6z \u00f6n\u00fcnde bulundurulacak de\u011fi\u015fken say\u0131s\u0131\n# max_leaf_nodes maks yaprak nodelar\u0131\n# min_samples_leaf: bir node b\u00f6l\u00fcmden \u00f6nce, ancak bu kadar node varsa b\u00f6l\u00fcn\n# n_estimators kullan\u0131l\u0131acak a\u011fa\u00e7 say\u0131s\u0131","76ec7ee8":"rf_model.predict(X_test)[0:5]","3dafd8fa":"y_pred = rf_model.predict(X_test)","077972c8":"# ilkel hatam\u0131z\nnp.sqrt(mean_squared_error(y_test, y_pred))","b73c3a3e":"rf_params = {'max_depth':[5,8,10],\n            'max_features': [2,5,10],#b\u00f6l\u00fcnmelerde g\u00f6z \u00f6n\u00fcnde bulunacak de\u011fi\u015fken say\u0131s\u0131\n            'n_estimators' : [ 200, 500, 1000, 2000],\n            \"min_samples_split\": [2,10,80,100]}","b6c2e744":"# model nesnesi\nrf_model = RandomForestRegressor(random_state = 42)","c1fe5357":"\nrf_cv_model = GridSearchCV(rf_model, \n                           rf_params, \n                           cv = 10, \n                            n_jobs = -1,#i\u015flemcileri h\u0131zland\u0131rma\n                          verbose =2) #var olan i\u015flemleri g\u00f6zlemlemk istiyorum","9461c95e":"##1440  fit etme i\u015flemi\nrf_cv_model.fit(X_train, y_train)","d2f694f5":"# en iyi parametreler neler\nrf_cv_model.best_params_","06e311ad":"#final modeli\n# max_depth\/max_features param ile oynanmayabilir ama kurcalayabilirsinisiniz\nrf_tuned = RandomForestRegressor(max_depth  = 8, \n                                 max_features = 2, \n                                 n_estimators =200,\n                                 min_samples_split =2 )","a4d64c63":"rf_tuned.fit(X_train, y_train)","dcd1ce88":"y_pred = rf_tuned.predict(X_test)","1ccb53ca":"# tune edilmi\u015f test hatas\u0131\n# ilkel hatam 345 idi\n\nnp.sqrt(mean_squared_error(y_test, y_pred))","95259d13":"rf_tuned.feature_importances_*100","88533b38":"#de\u011fi\u015fkenlerin \u00f6nem d\u00fczeylerinin hesaplanm\u0131\u015f \u015fekli.\nImportance = pd.DataFrame({\"Importance\": rf_tuned.feature_importances_*100},\n                         index = X_train.columns)\n\nImportance.sort_values(by = \"Importance\", \n                       axis = 0, \n                       ascending = True).plot(kind =\"barh\", color = \"r\")\n\nplt.xlabel(\"De\u011fi\u015fken \u00d6nem D\u00fczeyleri\")\nplt.gca.legend_ = None","dcade233":"from sklearn.ensemble import GradientBoostingRegressor","dd0cafdd":"hit = pd.read_csv(\"\/kaggle\/input\/hitters-baseball-data\/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna()\ndms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\ny = df[\"Salary\"]\nX_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25, \n                                                    random_state=42)","520a0c94":"#fonksiyonu kullanmak\n# model kurmak,\ngbm_model = GradientBoostingRegressor()\n#fit etme i\u015flemi\ngbm_model.fit(X_train, y_train)","9e6de37a":"gbm_model.get_params()","1d5d0427":"#ilkel test hatas\u0131\n# ilkel hatas\u0131 bile \n# algoritmalar ilerledik\u00e7e, \ny_pred = gbm_model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","14eda1c3":"gbm_params = {\n    'learning_rate': [0.001, 0.01, 0.1],# a\u011fa\u00e7lar\u0131n kat\u0131k\u0131s\u0131\n    'max_depth': [3, 5, 8], #a\u011fac\u0131n derinli\u011fi\n    'n_estimators': [100,200,500],# kullan\u0131lacak a\u011fa\u00e7 say\u0131s\u0131\n    'subsample': [1,0.5,0.8],# olu\u015fturulacak a\u011fa\u00e7lar\u0131n g\u00f6z \u00f6n\u00fcnde bulundurularacak oran\n    \"loss\": [\"ls\", \"lad\", \"quantile\"]# cost,lost, kay\u0131p, \n}","243d76c9":"#GBM referans modeli\n# 2430 fit i\u015flemi\ngbm_model = GradientBoostingRegressor()\ngbm_model.get_params()","186c0069":"gbm_cv_model = GridSearchCV(gbm_model, \n                            gbm_params, \n                            cv = 10, \n                            n_jobs = -1, \n                            verbose = 2)\ngbm_cv_model.fit(X_train, y_train)","b94f443b":"gbm_cv_model.get_params()","879160cd":"gbm_cv_model.best_params_","bd067d2b":"# tune edilmi\u015f model\ngbm_tuned = GradientBoostingRegressor(learning_rate = 0.01,\n                                      loss= 'lad',\n                                      max_depth = 3, \n                                      n_estimators = 500, \n                                      subsample = 0.5)\n\ngbm_tuned = gbm_tuned.fit(X_train,y_train)","e5f9580c":"#tahmin\ny_pred = gbm_tuned.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","bd06a400":"## De\u011fi\u015fken \u00f6nem d\u00fczeyi\nImportance = pd.DataFrame({\"Importance\": gbm_tuned.feature_importances_*100},\n                         index = X_train.columns)\nImportance.sort_values(by = \"Importance\", \n                       axis = 0, \n                       ascending = True).plot(kind =\"barh\", color = \"r\")\n\nplt.xlabel(\"De\u011fi\u015fken \u00d6nem D\u00fczeyleri\")","0206648c":"hit = pd.read_csv(\"\/kaggle\/input\/hitters-baseball-data\/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna()\ndms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\ny = df[\"Salary\"]\nX_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25, \n                                                    random_state=42)","35127a95":"#!pip install xgboost\nimport xgboost from xgboost import XGBRegressor","3e15a365":"xgb_model = XGBRegressor().fit(X_train, y_train)\nxgb_model.get_params()","8c538c98":"# ilkel test hatas\u0131\ny_pred = xgb_model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","bb6cac91":"# temel model\nxgb = XGBRegressor()\nxgb.get_params()","5393b47e":"xgb_params = { \n     'learning_rate': [0.1, 0.01], # overvfiting engellemek i\u00e7in.\n     'max_depth': [2,3,4,5,8], # \n    'n_estimators':[100, 200], #a\u011fa\u00e7 say\u0131s\u0131, tahminci say\u0131s\u0131\n    'colsample_bytree': [0.4, 0.7,1] #a\u011falarda olu\u015facak de\u011fi\u015fken alt k\u00fcmeleri\n}","7a212baa":"xgb_cv_model = GridSearchCV(xgb, \n                            xgb_params,\n                            cv = 5,\n                            n_jobs= -1,\n                            verbose = 2).fit(X_train,y_train)","009e33c5":"# en iyi hiperparemetre de\u011feri\nxgb_cv_model.best_params_","4ae63da4":"# tune edilmi\u015f model\nxgb_tuned = XGBRegressor(colsample_bytree = 0.59, \n                         learning_rate = 0.1, \n                         max_depth = 2, \n                         n_estimators = 500) \n\nxgb_tuned = xgb_tuned.fit(X_train,y_train)","405f6639":"# tune edilmi\u015f test hatas\u0131\ny_pred = xgb_tuned.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","53aa67cc":"## De\u011fi\u015fken \u00f6nem d\u00fczeyi\nImportance = pd.DataFrame({\"Importance\": xgb_tuned.feature_importances_*100},\n                         index = X_train.columns)\nImportance.sort_values(by = \"Importance\", \n                       axis = 0, \n                       ascending = True).plot(kind =\"barh\", color = \"r\")\n\nplt.xlabel(\"De\u011fi\u015fken \u00d6nem D\u00fczeyleri\")","d5e92dff":"hit = pd.read_csv(\"\/kaggle\/input\/hitters-baseball-data\/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna()\ndms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\ny = df[\"Salary\"]\nX_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, \n                                                    y, \n                                                    test_size=0.25, \n                                                    random_state=42)","095eaeb9":"#!pip install lightgbm\nfrom lightgbm import LGBMRegressor\n#conda install -c conda-forge lightgbm","76885e14":"lgbm = LGBMRegressor()\nlgbm_model = lgbm.fit(X_train, y_train)\nlgbm_model.get_params()","e97a4e7a":"y_pred = lgbm_model.predict(X_test)\n#ilkel test hatas\u0131\nnp.sqrt(mean_squared_error(y_test, y_pred))","dde37256":"lgbm_model = LGBMRegressor()\nlgbm_model.get_params()","abcde1b5":"# en ilkel yol, \u00f6n tan\u0131ml\u0131 de\u011ferlerine bakmak ve ilkel parametre \u00e7evresi\nlgbm_params = {\n        'learning_rate': [0.01, 0.1, 0.5, 1],\n        'n_estimators': [20, 40, 100, 200, 500,1000],\n        'max_depth': [1,2,3,4,5,6,7,8]\n}","6542c7bc":" # gridSearchCv, ile farkl\u0131 CV y\u00f6ntemleri de var.\n# light gbm daha fazla model bar\u0131nd\u0131r\u0131yor.\nlgbm_cv_model = GridSearchCV(lgbm_model, \n                             lgbm_params, \n                             cv=10, \n                             n_jobs = -1, \n                             verbose = 2)\n#modeli e\u011fitmek\nlgbm_cv_model.fit(X_train, y_train)","a7f8b5d3":"lgbm_cv_model.best_params_","a3021beb":"# final modeli\nlgbm_tuned = LGBMRegressor(learning_rate = 0.1, \n                           max_depth = 6, \n                           n_estimators = 20)\n\nlgbm_tuned = lgbm_tuned.fit(X_train,y_train)","2b881453":"# tune edilmi\u015f final modeli\ny_pred = lgbm_tuned.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","6c82abce":"## De\u011fi\u015fken \u00f6nem d\u00fczeyi\nImportance = pd.DataFrame({\"Importance\": lgbm_tuned.feature_importances_*100},\n                         index = X_train.columns)\nImportance.sort_values(by = \"Importance\", \n                       axis = 0, \n                       ascending = True).plot(kind =\"barh\", color = \"r\")\n\nplt.xlabel(\"De\u011fi\u015fken \u00d6nem D\u00fczeyleri\")","6357a926":"hit = pd.read_csv(\"\/kaggle\/input\/hitters-baseball-data\/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna()\ndms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\ny = df[\"Salary\"]\nX_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25, \n                                                    random_state=42)","9716d9e1":"# !pip install catboost\nfrom catboost import CatBoostRegressor","debf76df":"catb = CatBoostRegressor()\n#temel modeli kurmak\ncatb_model = catb.fit(X_train, y_train)","1ff055e7":"#ilkel test hatas\u0131\ny_pred = catb_model.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","49fa98a3":"catb_params = {\n    'iterations': [200,500,100], # a\u011fa\u00e7 say\u0131s\u0131\n    'learning_rate': [0.01, 0.1],# \n    'depth': [3,6,8] } # derinlik","25a308be":"catb = CatBoostRegressor()\ncatb_cv_model = GridSearchCV(catb, \n                             catb_params,\n                             cv=5, \n                             n_jobs = -1,\n                             verbose = 2)","d02d1ef4":"catb_cv_model.fit(X_train, y_train)","2c1e47ed":"catb_cv_model.best_params_","24388a88":"catb_tuned = CatBoostRegressor(depth = 3,\n                               iterations = 200, \n                               learning_rate = 0.1 \n                               )\n\ncatb_tuned = catb_tuned.fit(X_train,y_train)","e010a800":"# tune edilmi\u015f test hatas\u0131\ny_pred = catb_tuned.predict(X_test)\nnp.sqrt(mean_squared_error(y_test, y_pred))","b81e0893":"## De\u011fi\u015fken \u00f6nem d\u00fczeyi\nImportance = pd.DataFrame({\"Importance\": catb_tuned.feature_importances_*100},\n                         index = X_train.columns)\nImportance.sort_values(by = \"Importance\", \n                       axis = 0, \n                       ascending = True).plot(kind =\"barh\", color = \"r\")\n\nplt.xlabel(\"De\u011fi\u015fken \u00d6nem D\u00fczeyleri\")","a29e1bb8":"hit = pd.read_csv(\"\/kaggle\/input\/hitters-baseball-data\/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna()\ndms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])","2a3236e9":"def compML(df, y, alg):\n    \n    #train-test ayrimi\n    y = df[y] # bagimli degiskeni gelecek\n    X_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\n    X = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25, \n                                                    random_state=42)\n    #modelleme\n    model = alg().fit(X_train,y_train)\n    y_pred = model.predict(X_test)\n    RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n    # modelin ismi alacak\n    model_ismi = alg.__name__\n    print(model_ismi, \"Modeli test hatasi:\", RMSE)","440d57c7":"compML(df, \"Salary\", SVR)","5051f609":"models = [LGBMRegressor, \n         XGBRegressor,\n         GradientBoostingRegressor,\n         RandomForestRegressor,\n         DecisionTreeRegressor,\n         MLPRegressor,\n         KNeighborsRegressor,\n         SVR]\nmodels","8ea069cf":"models = [LGBMRegressor, \n         XGBRegressor,\n         GradientBoostingRegressor,\n         RandomForestRegressor,\n         DecisionTreeRegressor,\n         MLPRegressor,\n         KNeighborsRegressor,\n         SVR]\nfor i in models:\n    (i, \"Algrtm Test Hatas\u0131:\", compML(df, \"Salary\", i))","420ad7cb":"# 37.3. XGBoost Model Tuning","c0ccf998":"## De\u011fi\u015fken \u00f6nem d\u00fczeyi","b18a982e":"# 36.3. Gradient Boosting Machines Model Tuning","db4042cf":"# 34.1. CART  Classification and Regression Tree (CART)\n\n        Classification and Regression Tree (CART)\n        S\u0131n\u0131fland\u0131rma ve Regresyon A\u011fac\u0131\n        \n        CART: E\u011fer genellebilir kayg\u0131n\u0131z yoksa, mevcut durumu ifade etmek i\u00e7in CART en ba\u015far\u0131 algoritmalardan biridir. Olaylar\u0131 iyi tasvir eder. Hedef De\u011fi\u015fkene, ba\u011f\u0131ms\u0131z de\u011fi\u015fkenlerin nas\u0131l homojenle\u015fmesi gerekti\u011fini en iyi \u015fekilde anlat\u0131r.\n* Ama\u00e7: Veri setindeki karma\u015f\u0131k yap\u0131lar\u0131 basit karar yap\u0131lar\u0131na d\u00f6n\u00fc\u015ft\u00fcrmektir.\n   * Heterojen veri setleri berlenmi\u015f bir hedef de\u011fi\u015fkenine g\u00f6re homojen alt gruplara ayr\u0131l\u0131r. Breiman 1984\n            Nas\u0131l yap\u0131yor bunu? Hedef de\u011fi\u015fkene g\u00f6re homojen alt\u0131 gruba ay\u0131rmaya \u00e7al\u0131\u015f\u0131yor. \n            Tahmin yak\u0131nl\u0131  di\u011fer a\u011fa\u00e7 yap\u0131lar\u0131na g\u00f6re\n            \n![image.png](attachment:40f242c6-e129-4188-a55b-1de30109665a.png)\n- karar a\u011fa\u00e7lar, g\u00f6zetimli y\u00f6ntemler\n- **`FAKAT`**: 'a\u015f\u0131r\u0131 \u00f6\u011frenmeye meyilidir.'\n- B\u00fcy\u00fck veri setlerinde, tahmin ba\u015far\u0131s\u0131 d\u00fc\u015f\u00fck olabilir di\u011fer algoritmalara nazaran.\n\nKafadaki sorular\n* Deneyim y\u0131l\u0131 ve at\u0131\u015f say\u0131s\u0131na bakarak almas\u0131 gereken maa\u015f ne olmal\u0131?\n    - d\u00fc\u011f\u00fcm 1. deneyim y\u0131l\u0131 2. at\u0131\u015f say\u0131s\u0131: iki b\u00fcy\u00fck dala ay\u0131rm\u0131\u015ft\u0131r.\n    - \u00dc\u00e7 son d\u00fc\u011f\u00fcm: yaprak vard\u0131r.\n    \n![image.png](attachment:c8eff4a6-9c64-459f-b8b0-b0c6c1b2da1a.png)\n* Year: maa\u015flara etki eden en \u00f6nemli fakt\u00f6rd\u00fcr.\n    \n![image.png](attachment:62437f6e-2dff-427c-96dd-cf9fdf3319fd.png)\n * \u00d6nemli NOT!: yapraklarda bulunan her bir say\u0131, yapra\u011f\u0131n bulundu\u011fu b\u00f6lgeye kar\u015f\u0131l\u0131k gelen yan\u0131t de\u011fi\u015fkeninin ortalamas\u0131d\u0131r.\n    * ki-kare & gini gibi alt gruplara b\u00f6lme i\u015flemi yap\u0131l\u0131r.\n\n![image.png](attachment:ce3a63c7-d43a-4bd3-aecd-bb5a96306af4.png)\n\n![CART](https:\/\/www.statology.org\/wp-content\/uploads\/2020\/11\/tree3-768x588.png)","7cbf12c8":"##   KNN i\u00e7in GridSearchCV\n#### Hiperparemetre de\u011ferlerini bulmak i\u00e7in bir fonksiyon\n#### farkl\u0131 ve \u0131zgara mant\u0131\u011f\u0131 ile de\u011ferlnedimr","c49afd3a":"# 34.3. CART Model Tuning","33c9caa6":"![model kernel](https:\/\/scikit-learn.org\/stable\/_images\/sphx_glr_plot_iris_svc_0011.png)","731e0d46":"# 36.1. Gradient Boosting Machines GBM\n![image.png](attachment:f8402ff1-d80f-4418-9fee-57b933a8cfee.png)","e28c1ff1":"# 31.2. K En Yak\u0131n Kom\u015fu Model ve Tahmini\n\n[Videolar\u0131 indirme linki](https:\/\/drive.google.com\/file\/d\/1V1iWuBaWsK9ztEPndPwP5xTCDAmz5Hmc\/view?usp=sharing)","23505112":"# 39.4 Makine \u00d6\u011frenmesi G\u00f6revlerinin Otomatikle\u015ftirilmesi","15b4bb3a":"# 38.1. Light GBM\n\nLight GBM, XGBoost'un e\u011fetim s\u00fcresi performas\u0131n\u0131 art\u0131rmaya y\u00f6nelik geli\u015ftirilen bir di\u011fer GBM t\u00fcr\u00fcd\u00fcr. Microsoft 2017\n\n![image.png](attachment:2918c43c-6f0e-41f4-aab7-5edfdf2bbbb4.png)\n\nNeden Daha Performansl\u0131\n1. Daha Performansl\u0131\n1. XGBoost = Level-wise B\u00fcy\u00fcme stratejisini kulln\u0131yor. de\u011fi\u015fkenleri ay\u0131rmak i\u00e7in karar a\u011fa\u00e7lar\u0131n\u0131 kulln\u0131yor. Geni\u015f kapsaml\u0131 arama yapar. Breadth-fisrt Serch(BFS)\n    1. Light GBM= leaf-wise b\u00fcy\u00fcme strajesini kulln\u0131yor. ilk kapsaml\u0131 aramas\u0131n\u0131 derinlemesine yapar. Depth-first search (DFS)\n    \n    \n![image.png](attachment:9b348d13-1657-4461-8300-c0779babcdc0.png)","5fcdf717":" # 36.2. Gradient Boosting Machines Model ve Tahmin","9d6c4286":"## Random Forests: Tahmin","73413c7f":"# 35.1. Random Forests\nTopluluk \u00f6\u011frenme y\u00f6ntemenleri: Birden fazla algoritman\u0131n ya da birden fazla a\u011fac\u0131n bir araya gelerek toplu bir \u015fekilde \u00f6\u011frenmesi ve tahmin etmeye \u00e7al\u0131\u015fmas\u0131d\u0131r.\n![image.png](attachment:43a86184-8de6-4c20-9ff7-37484cfdbb88.png)\n\n**bagging: boostrap aggration: Temeli boostrap y\u00f6ntemi ile olu\u015fturulan birden fazla karar a\u011fac\u0131n\u0131n \u00fcretti\u011fi tahminlerin bir araya getirelerel de\u011ferlendirilmesine dayan\u0131r. Breiman 1996**\n\nBudama Y\u00f6ntemi: a\u015f\u0131r \u00f6\u011frenmeye kar\u015f\u0131,A\u011fac\u0131n ilgili k\u0131sm\u0131n\u0131 kesersin ki daha iyi b\u00fcy\u00fcs\u00fcn.\n\nboostrap: yerine koymal\u0131 se\u00e7meli. \u00d6ncekiden bir a\u011fa\u00e7 var iken \u015fimdi 10 farkl\u0131 veri, 10 farkl\u0131 a\u011fa\u00e7. Bunlardan fikir soruyor.\n\n- \u00c7al\u0131\u015fma prensibinin kilit noktas\u0131: Boostrap rastgele \u00f6rnekeleme y\u00f6ntemidir.\n- Boostrap rastegele \u00f6rnekleme y\u00f6ntemi, g\u00f6zlem birimlerinin i\u00e7inden yerine koymal\u0131 bir \u015fekilde tekrar tekrar \u00f6rnek \u00e7ekmek demektir.\n- rassal\u0131\u011f\u0131 \u00e7ok iyi sa\u011flam\u0131\u015f.\n- Bagging y\u00f6ntemi: Hatta kareler ortalamas\u0131n\u0131n karek\u00f6k\u00fc de\u011ferini d\u00fc\u015f\u00fcr\u00fcr.\n![image.png](attachment:c2641699-9380-4a03-9d1b-52925ee971cd.png)\n\nBAgging ile\n- Do\u011fru s\u0131n\u0131fland\u0131rma oran\u0131n\u0131 art\u0131r\u0131r. \n\n- Varyans\u0131 d\u00fc\u015f\u00fcr\u00fcr ve ezberlemeye kar\u015f\u0131 dayan\u0131kl\u0131d\u0131r.\n\n- g\u00f6zlerimleri rassal\u0131\u011f\u0131 art\u0131rm\u0131\u015f\n- Random forests ile g\u00f6zlem se\u00e7me i\u015flemine de rassal\u0131\u011f\u0131 belirlemi\u015ftir.\n![image.png](attachment:a11baf83-8085-493c-aac1-b8284c221ef2.png)\n\n- \u00c7al\u0131\u015fma prensibinin kilit noktas\u0131: Boostrap rastgele \u00f6rnekeleme y\u00f6ntemidir.\n- Boostrap rastegele \u00f6rnekleme y\u00f6ntemi, g\u00f6zlem birimlerinin i\u00e7inden yerine koymal\u0131 bir \u015fekilde tekrar tekrar \u00f6rnek \u00e7ekmek demektir.\n- rassal\u0131\u011f\u0131 \u00e7ok iyi sa\u011flam\u0131\u015f.\n\nRandom Forest: Temei birden \u00e7ok karar a\u011fac\u0131n \u00fcretti\u011fi tahminlerin \n**bagging: boostrap aggration:**\n\n![image.png](attachment:7d163198-17dc-4f29-be64-73b08da1e3fb.png)\n\n![image.png](attachment:bc4541d0-a594-45e0-aa39-9de41a23ac5d.png) \n\n- **`De\u011fi\u015fken se\u00e7imi:`** faydal\u0131 konu\u015fanlara daha \u00e7ok konu\u015fma hakk\u0131 oluyor.\n- p = de\u011fi\u015fen say\u0131s\u0131 p>k rastgele k de\u011ferleri\n\n![Random](https:\/\/miro.medium.com\/max\/1280\/1*9kACduxnce_JdTrftM_bsA.gif)\n\n\n![image.png](attachment:f99e20cf-d2ce-40ac-91f5-75fe8a2a8328.png)\n\nRandom Forests\n\nA\u011fa\u00e7lar i\u00e7in g\u00f6zlemler boostrap rasgele \u00f6rnek se\u00e7im y\u00f6ntemi ile de\u011fi\u015fkenler random subspace y\u00f6netmi ile se\u00e7ilir.\n\nKarar a\u011fac\u0131n\u0131n her bir d\u00fc\u011f\u00fcm\u00fcnde en iyi dallara ay\u0131r\u0131(bilgi kazanc\u0131) de\u011fi\u015fken t\u00fcm de\u011fi\u015fkenler aras\u0131ndan rastgele se\u00e7ilen daha az say\u0131daki de\u011fi\u015fken aras\u0131ndan se\u00e7ilir.","ba3fd838":"Baz\u0131 algoritmalar baz\u0131 problemlerde iyi \u00e7al\u0131\u015fabilirken, baz\u0131lar\u0131nda iyi \u00e7al\u0131\u015fmayabilir.","4a4b3bc9":" # 33.2. Yapay Sinir A\u011flar\u0131 Model ve Tahmin","5dbb7c1a":"# 35.2. Random Forests Model ve Tahmin\nTopluluk \u00f6\u011frenme y\u00f6ntemenleri:\n\n\n![](https:\/\/i1.wp.com\/sefiks.com\/wp-content\/uploads\/2017\/11\/random-forest.png?resize=602%2C344&ssl=1)","8f43455a":"## Birka\u00e7 Soru\n\n    I.   S\u00fcrekli de\u011fi\u015fken tahmin i\u00e7in kullan\u0131l\u0131r\n    II.  G\u00fc\u00e7l\u00fc ve esnek bir modelleme tekni\u011fidir\n    III. K\u0131salt\u0131lm\u0131\u015f\u0131 SVR\u2019d\u0131r\n    IV. S\u0131n\u0131fland\u0131rma problemleri i\u00e7in de kullan\u0131labilir\n    V.  Ayk\u0131r\u0131 g\u00f6zlemlere kar\u015f\u0131 diren\u00e7lidir\n\n1. Destek Vekt\u00f6r Regresyonu ile ilgili verilen bilgilerden hangileri do\u011frudur?\n\n2. Bootstrap tekni\u011finin tan\u0131m\u0131 hangisidir? \n    1. Rastgeleli\u011fe dayal\u0131 s\u0131ralama i\u015flemi \n    2. Rastgeleli\u011fe dayal\u0131 se\u00e7me i\u015flemi \n    3. Yerine koymal\u0131 s\u0131ralama i\u015flemi \n    4. Yerine koymal\u0131 se\u00e7me i\u015flemi \n    5. Se\u00e7me ve s\u0131ralama i\u015flemi\n\n\n3. GridSearchCV fonksiyonunu kullama amac\u0131m\u0131z nedir?\n    1. H\u0131zl\u0131 olmas\u0131\n    2. Parametre se\u00e7me i\u015flemindeki ba\u015far\u0131s\u0131\n    3. Farkl\u0131 donan\u0131msal teknoloji kullanmas\u0131\n    4. Bir\u00e7ok hiper parametre kombinasyonunu kolayca deneme imkan\u0131 vermesi\n    5. Kat say\u0131s\u0131n\u0131 kullan\u0131c\u0131n\u0131n belirleyebilmesi\n\n\n4. **XGBoost model k\u00fct\u00fcphanesini \u00e7a\u011f\u0131rmadan \u00f6nce notebook arac\u0131l\u0131\u011f\u0131 ile ilgili paketi kurmam\u0131z\u0131 sa\u011flayan kod nedir?**\n\n    * I.   S\u0131n\u0131fland\u0131rma ve regresyon i\u00e7in kullan\u0131labilir\n    * II.  Kuvvetli bir makine \u00f6\u011frenmesi algoritmas\u0131d\u0131r\n    * III. \u0130nsan beyninin bilgi i\u015fleme \u015feklini referans alm\u0131\u015ft\u0131r\n    * IV. Hatay\u0131 minimize eden a\u011f\u0131rl\u0131klar\u0131 bulmay\u0131 ama\u00e7lar\n\n5. Yukar\u0131da verilen bilgilerden hangileri Yapay sinir a\u011flar\u0131 modellemesinin \u00f6zelliklerindendir?\n\n    * model = KNeighborsRegressor() \n    * model.fit(X, y) \n6. Yukar\u0131da verilen kod ile e\u015fde\u011fer olan kod a\u015fa\u011f\u0131dakilerden hangisidir?\n    * model = KNeighborsRegressor(fit(X, y))\n    * model = KNeighborsRegressor().apply(fit(X, y))\n    * model = KNeighborsRegressor().transform(fit(X, y))\n    * model = KNeighborsRegressor().fit(X, y)\n    * KNeighborsRegressor() = model.fit(X, y)\n\n\n7. **Makine \u00f6\u011frenmesi modellerinden hangisi Yandex taraf\u0131ndan geli\u015ftirilmi\u015ftir?**\n\n\n    * I. from sklearn.neighbors import KNeighborsRegressor \n    * II. knn_model = KNeighborsRegressor() \n    * III. knn_model.fit(X_train, y_train) \n    * IV. knn_model.n_neighbors \n    * V. knn_model.predict(X_test) \n8. **Yukar\u0131daki numaraland\u0131r\u0131lm\u0131\u015f kodlar\u0131n her biri Jupiter Notebook \u00fczerinde ayr\u0131 h\u00fccrelerde \u00e7al\u0131\u015ft\u0131rm\u0131\u015ft\u0131r. H\u00fccre \u00e7\u0131kt\u0131lar\u0131 ile ilgili se\u00e7eneklerden hangisi yanl\u0131\u015ft\u0131r?** \n    1. I. ad\u0131mda K-En Yak\u0131n Kom\u015fu Regresyon fonksiyonu \u00e7al\u0131\u015fmaya dahil edilmi\u015ftir \n    2. II. ad\u0131mda K-En Yak\u0131n Kom\u015fu model nesnesi olu\u015fturulmu\u015ftur \n    3. III. ad\u0131mda model e\u011fitme i\u015flemi yap\u0131lm\u0131\u015ft\u0131r \n    4. IV. ad\u0131mda kom\u015fuluk say\u0131s\u0131 belirlenmi\u015ftir\n    5. V. ad\u0131mda bir model kullan\u0131larak tahmin i\u015flemi yap\u0131lm\u0131\u015ft\u0131r\n    \n9. `A\u015fa\u011f\u0131dakilerden hangisi do\u011frusal olmayan regresyon modellerinden birisi de\u011fildir?` \n    1. Random Forests \n    2. Gradient Boosting Machines\n    3. XGBoost \n    4. ElasticNet Regresyon \n    5. LightGBM \n    \n10. **K-En Yak\u0131n Kom\u015fu y\u00f6ntemindeki ''K'' neyi ifade eder?** \n\n    1. Cross-Validation i\u015fleminde veri setinin ka\u00e7 par\u00e7aya ayr\u0131laca\u011f\u0131n\u0131 belirtir \n    2. Cross-Validation i\u015fleminin ka\u00e7 katl\u0131 olaca\u011f\u0131n\u0131 belirtir \n    3. Tahmin edilecek de\u011ferin belirli bir mesafe civar\u0131nda bulunan g\u00f6zlem say\u0131s\u0131n\u0131 ifade eder \n    4. Tahmin etme i\u015flemi i\u00e7in g\u00f6z \u00f6n\u00fcnde bulundurulacak kom\u015fu say\u0131s\u0131n\u0131 ifade eder \n    5. Tahmin edilecek de\u011ferin ona en yak\u0131n k. (k\u2019n\u0131nc\u0131) g\u00f6zlemin se\u00e7ilece\u011fini ifade eder\n\n\n11. **A\u015fa\u011f\u0131da \u00f6zellikleri verilen model hangisidir?** \n    * I. R, Python, Hadoop ve Scala ile kullan\u0131labilir \n    * II. H\u0131zl\u0131d\u0131r, a\u011faca dayal\u0131 bir modeldir \n    * III. Tahmin ba\u015far\u0131s\u0131 y\u00fcksektir\n    * IV. Bir \u00e7ok uluslararas\u0131 yar\u0131\u015fmada kendini kan\u0131tlam\u0131\u015ft\u0131r\n    * V. \u00d6l\u00e7eklenebilirdir \n\n \n\n\n12. **GridSearchCV fonksiyonunun \"verbose\" arg\u00fcman\u0131 2\u2019ye e\u015fitlendi\u011finde fonksiyon nas\u0131l davran\u0131r?** \n        1. \u0130\u015flemciyi daha az kullan\u0131r \n        2. Kulland\u0131\u011f\u0131 ram miktar\u0131n\u0131 minimum tutar\n        3. Yap\u0131lan i\u015flemlerle ilgili bilgi verir\n        4. Daha h\u0131zl\u0131 \u00e7al\u0131\u015f\u0131r\n        5. \u0130\u015flemciyi maksimum performansla kullan\u0131r\n\n\n13. **XGBoost modelinde fit edilecek a\u011fa\u00e7 say\u0131s\u0131n\u0131 ifade eden hiper parametre a\u015fa\u011f\u0131dakilerden hangisidir?**\n\n    1. learning_rate \n    2. n_estimators \n    3. colsample_bytree \n    4. booster \n    5. colsample_bylevel\n    \n    \n        \n14. **mean_squared_error(A, B)** Yukar\u0131da verilen fonksiyonun yapt\u0131\u011f\u0131 i\u015flem hangisidir? \n    1. A ve B veri setleri aras\u0131ndaki farkl\u0131 g\u00f6zlem say\u0131s\u0131n\u0131 verir\n    2. A ve B veri setleri aras\u0131nda kar\u015f\u0131l\u0131kl\u0131 her g\u00f6zlemin farkl\u0131n\u0131 hesaplar\n    3. A ve B veri setleri aras\u0131nda kar\u015f\u0131l\u0131kl\u0131 her g\u00f6zlemin farkl\u0131n\u0131 hesaplay\u0131p bu say\u0131lar\u0131n karelerini al\u0131r\n    4. A ve B veri setleri aras\u0131nda kar\u015f\u0131l\u0131kl\u0131 her g\u00f6zlemin farkl\u0131n\u0131 hesaplay\u0131p, bu say\u0131lar\u0131n karelerini al\u0131p, toplar\n    5. A ve B veri setleri aras\u0131nda kar\u015f\u0131l\u0131kl\u0131 her g\u00f6zlemin farkl\u0131n\u0131 hesaplay\u0131p, bu say\u0131lar\u0131n karelerini al\u0131p, toplar ve sonucun karek\u00f6k\u00fcn\u00fc hesaplar\n    \n\n       \nKod: svr_model\n      \n```python\n  SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n      gamma='auto_deprecated', kernel='linear', max_iter=-1,\n      shrinking=True,\n      tol=0.001, verbose=False)\n```\n15. Yukar\u0131da bir modelin parametre bilgileri verilmi\u015ftir. Buna g\u00f6re bu modeli do\u011frusal olmayacak \u015fekilde kurmak i\u00e7in hangi arg\u00fcman\u0131 de\u011fi\u015ftirmemiz gerekir? \n\n    1. gamma\n    2. kernel\n    3. max_iter\n    4. shrinking\n    5. verbose\n\n\n     ```python\nmlp_params = {\"alpha\": [0.1, 0.01, 0.02, 0.001, 0.0001], \"hidden_layer_sizes\": [(10,12), (5,5,10), (25,30,40)]} \n        ```\n\n16. Yukar\u0131da Yapay Sinir A\u011f\u0131 modellemesi i\u00e7in GridSearchCV fonksiyonu ile kullan\u0131lmak \u00fczere bir hiper parametre seti olu\u015fturulmu\u015ftur. \n    * Bu bilgiye g\u00f6re algoritma \u00fczerinde denenecek olan gizli katman say\u0131lar\u0131 s\u0131ras\u0131yla nedir?\n\n    \n    \n 17.  model.best_params_\n    * Yukar\u0131da verilen kod par\u00e7ac\u0131\u011f\u0131nda yer alan \"best_params_\" ifadesi hangi bilgiyi ta\u015f\u0131r?\n\n18. **A\u015fa\u011f\u0131dakilerden hangisi CART modelinin hiper parametrelerinden biri de\u011fildir?** \n    1. max_depth \n    2. min_samples_leaf \n    3. min_samples_split \n    4. alpha \n    5.min_impurity_decrease\n\n19. Python sklearn k\u00fct\u00fcphanesini kullanarak Yapay Sinir A\u011flar\u0131n\u0131 kullan\u0131rken genelde veri setine standardizasyon uygulan\u0131r, bunun sebebi nedir?\n\n\n    1. \u0130lgili algoritma homojen veri seti \u00fczerinde daha iyi sonu\u00e7 verdi\u011fi i\u00e7in\n    2. \u0130lgili algoritma standartla\u015ft\u0131r\u0131lmam\u0131\u015f bir veriyi i\u015fleyemedi\u011fi i\u00e7in\n    3. \u0130\u015flemi daha h\u0131zl\u0131 yapabilmek i\u00e7in\n    4. \u0130\u015flemci kullan\u0131m\u0131ndan tasarruf edilmesi i\u00e7in\n    5. T\u00fcm algoritmalar i\u00e7in standartla\u015ft\u0131rma uygulan\u0131r\n    \n    \n20. Modelleme a\u015famalar\u0131nda ilkel test hatas\u0131 diye isimlendirilen \u015fey nedir?\n    1. Tune edilmemi\u015f modelin test veri setine ait tahmin hatas\u0131\n    2. Veriyi ay\u0131rmadan kurulan modelin tahmin hatas\u0131 \n    3. Parametrelerin bir k\u0131sm\u0131 optimize edilen modelin tahmin hatas\u0131 \n    5. Model nesnesini ayr\u0131ca isimlendirilme yap\u0131lmadan \u00f6nceki tahmin hatas\u0131 \n    5. Veri setinin train b\u00f6l\u00fcm\u00fcne ait tahmin hatas\u0131\n\n    \n    \n21. **A\u015fa\u011f\u0131dakilerden hangisi do\u011frusal olmayan regresyon modellerinden birisi de\u011fildir?** \n    1. K-En Yak\u0131n Kom\u015fu \n    2. Do\u011frusal Olmayan Destek Vekt\u00f6r Regresyonu \n    3. Yapay Sinir A\u011flar\u0131 \n    4. CART\n \n22. **\u2026 : AdaBoost\u2019un s\u0131n\u0131fland\u0131rma ve regresyon problemlerine kolayca uyarlanabilen genelle\u015ftirilmi\u015f versiyonudur. Yukar\u0131da bo\u015f b\u0131rak\u0131lan yere hangisi gelmelidir?** \n        1. CART \n        2. Random Forest\n        3. Gradient Boosting Machines\n        4. Yapay Sinir A\u011flar\u0131 \n        5. Destek Vektor Regresyonu\n\n   \n23. **Verilen modellerin hangisi ya da hangileri a\u011faca dayal\u0131 y\u00f6ntemlerdir?\n    1. I. LightGBM\n    1. II. Gradient Boosting Machines\n    1. III. XGBoost \n\n24. **GridSearchCV fonksiyonunun n_jobs arg\u00fcman\u0131 \"-1\"e e\u015fitlendi\u011finde fonksiyon nas\u0131l davran\u0131r? \n\n\n    ```python\n    SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n    gamma='auto_deprecated', kernel='linear', max_iter=-1, shrinking=True,\n    tol=0.001, verbose=False)\n    ```\n\n25. Yukar\u0131da bir SVR model nesnesi \u00e7\u0131kt\u0131s\u0131 verilmi\u015ftir. Bu modelleme i\u00e7in **ceza parametresi** a\u015fa\u011f\u0131dakilerden hangisidir? C cache_size coef0 gamma verbose\n    \n\n26. **Python sklearn k\u00fct\u00fcphanesini kullanarak Yapay Sinir A\u011flar\u0131n\u0131 kullan\u0131rken genelde veri setine standardizasyon uygulan\u0131r, bunun sebebi nedir?**\n  \n\n\n\n27. **A\u015f\u0131\u011f\u0131da verilen bilgilerden hangileri Yapay sinir a\u011flar\u0131 modellemesinin \u00f6zelliklerindendir?**\n\n    1. I. S\u0131n\u0131fland\u0131rma ve regresyon i\u00e7in kullan\u0131labilir \n    1. II. Kuvvetli bir makine \u00f6\u011frenmesi algoritmas\u0131d\u0131r \n    1. III. \u0130nsan beyninin bilgi i\u015fleme \u015feklini referans alm\u0131\u015ft\u0131r \n    1. IV. Hatay\u0131 minimize eden a\u011f\u0131rl\u0131klar\u0131 bulmay\u0131 ama\u00e7lar","ce528d5e":"# 33.1. Yapay Sinir A\u011flar\u0131\n        Ama\u00e7: en k\u00fc\u00e7\u00fck hata ile tahmin yapabilecek katsay\u0131lara eri\u015fmektir.\n        \n![image.png](attachment:81c0ea98-3bf2-40bf-9955-0dae90af8691.png)\n\n![image.png](attachment:d430c742-c54e-4de5-b869-9d5e2bdb434f.png)\n1. Yapay sinir a\u011flar\u0131nda fonksiyonel bir yap\u0131 oldu\u011fundan \u00f6t\u00fcr\u00fc katsay\u0131lar\u0131 eri\u015fiyor. Ama a\u011faca dayal\u0131 bir y\u00f6ntem kullansayd\u0131k, oradaki kural setlerine eri\u015fmeye \u00e7al\u0131\u015f\u0131yoruz.\n\n2. Dentritten gelen bilgileri a\u011f\u0131rl\u0131klar\u0131 de\u011fi\u015ftirebiliyor. \n\n3. Girdiler= Ba\u011f\u0131ms\u0131z de\u011ferler\n        * A\u011f\u0131rl\u0131klar= katsay\u0131lar\n        * \n1. Her a\u011f\u0131rl\u0131k, di\u011fer katmanlarla ili\u015fkilidir.\n\n![image.png](attachment:60a260b5-2188-4ab0-98d1-aa95ad881145.png)\n\n4. \n    - input\n    - hidden\n    - output\n- `Delta \u00f6\u011frenme kural\u0131:` kabul edilebilir bir hata gelene kadar,  a\u011f \u00e7\u0131kt\u0131s\u0131 ile ger\u00e7ek \u00e7\u0131kt\u0131lar aras\u0131ndaki farklar azalt\u0131lmaya \u00e7al\u0131\u015f\u0131l\u0131r. Bunu da girdilerin a\u011f\u0131rl\u0131klar\u0131 de\u011fi\u015ftirilerek yap\u0131lmaya \u00e7al\u0131\u015f\u0131yor. Kat say\u0131lar de\u011fi\u015ftik\u00e7e a\u011f \u00f6\u011freniyor.\n- kimya, ila\u00e7 yaparken farkl\u0131 \u00f6l\u00e7ekte kullanmaya \u00e7al\u0131\u015fmak: a\u011f \u00f6\u011freniyor.\n\n![image.png](attachment:2ae72184-7c11-49e4-b8a2-092e169f6490.png)\n\n1. Nas\u0131l ger\u00e7ekle\u015fiyor?\n    1. \u00d6rnek veri seti toplan\u0131r\n    1. A\u011f\u0131n topolojik yap\u0131s\u0131na kara verilir.\n    1. A\u011fdabulunan a\u011f\u0131rl\u0131klara ba\u015flang\u0131\u00e7 de\u011ferleri atan\u0131r.\n    1. \u00d6rnek veri seti a\u011fa sunulur.\n    1. \u0130leri hesaplama i\u015flemleri yap\u0131l\u0131r.\n    1. Ger\u00e7ek \u00e7\u0131kt\u0131lar ile tahmin \u00e7\u0131kt\u0131lar\u0131 kar\u015f\u0131la\u015ft\u0131r\u0131l\u0131r. \u00d6\u011frenmenin tamamlanmas\u0131 basamaklar\u0131 ger\u00e7ekle\u015fir. \n        * Sonu\u00e7: Ger\u00e7ek de\u011fer ile tahmin de\u011fer aras\u0131ndaki farklar\u0131na bak\u0131l\u0131r.\n        \n![image.png](attachment:b11c9646-1adc-41a1-a225-e4723f29c6e6.png)\n\n* back propation:  denklemin \u00e7\u00f6z\u00fcm\u00fc global bir \u00e7\u00f6z\u00fcm de\u011fildir. Her parametre de\u011fi\u015fkenlik g\u00f6sterebilir, veriye g\u00f6re.\n\n- Geriye yay\u0131l\u0131m kural\u0131:\n\n![image.png](attachment:5f8d20ed-3fee-42d7-a1c0-d2fabac5d5e9.png)\n\n! Baz\u0131 algoritmalar heterojen veri setlerinde iyi \u00e7al\u0131\u015f\u0131rken baz\u0131lar\u0131 homojeni sever. **Yapay da homojeni sever**. \u00c7\u00fcnk\u00fc hatalar\u0131n optimuzsayonu a\u015famas\u0131nda ortaya \u00e7\u0131kan ayk\u0131l\u0131klar\u0131n\u0131 t\u00fcrevleme i\u015flemi s\u0131ras\u0131nda, yani ger\u00e7ek de\u011fer ile tahmin de\u011fer aras\u0131nda ciddi fark olu\u015fturan de\u011ferleri. Standartla\u015fma i\u015flemi sonras\u0131nda kullanmak sa\u011fl\u0131kl\u0131 olur\n\n![Yapay sinir A\u011flar\u0131](https:\/\/miro.medium.com\/max\/1400\/1*BIpRgx5FsEMhr1k2EqBKFg.gif)","04f05641":"# 34.2. CART Model ve Tahmin (Classification and Regression Tree)","f64a5471":"# 32.1. SVR Destek Vekt\u00f6r Regresyonu\n### support Vector Regresion\n0. Nedir?: G\u00fc\u00e7l\u00fc ve esnek modelleme tekniklerinden birisidir.\n1. S\u0131n\u0131fland\u0131rma ve regresyon i\u00e7in kullanabilir.\n1. Robost:Dayan\u0131kl\u0131 bir regresyon modelleme tekni\u011fidir. Ayk\u0131r\u0131 g\u00f6zlemlere kar\u015f\u0131 dayan\u0131kl\u0131\n1. Ama\u00e7: Bir marjin ara\u011f\u0131na mksimum noktas\u0131 en k\u00fc\u00e7\u00fck hata ile alabilecek bir do\u011fru ya da e\u011fri belirlemektedir. (Smola 1996 ve Drucker 1997)\n 1. art\u0131klari ayk\u0131r\u0131 de\u011ferler do\u011frununu e\u011fimini belirliyor. C, ceza ya da kontrol parametresi il\n \n![image.png](attachment:b55d9d46-21a0-430f-b135-51cdd4d47710.png)\n\n![image.png](attachment:1cd867eb-a678-4ea2-8cf9-e6194959d5b0.png)\n\n\n![image.png](attachment:8dc40d96-e61e-4f2a-b43d-1fd44385e3de.png)\n\n Art\u0131lar\u0131:\n1. Net bir ay\u0131rma marj\u0131yla ger\u00e7ekten iyi \u00e7al\u0131\u015f\u0131yor\n1. Y\u00fcksek boyutlu bo\u015fluklarda etkilidir.\n1. Boyut say\u0131s\u0131n\u0131n numune say\u0131s\u0131ndan fazla oldu\u011fu durumlarda etkilidir.\n1. Karar i\u015flevinde (destek vekt\u00f6rleri olarak adland\u0131r\u0131l\u0131r) e\u011fitim noktalar\u0131n\u0131n bir alt k\u00fcmesini kullan\u0131r, bu nedenle bellek a\u00e7\u0131s\u0131ndan da etkilidir.\n\nEksileri:\n1. Gerekli e\u011fitim s\u00fcresi daha y\u00fcksek oldu\u011fu i\u00e7in b\u00fcy\u00fck veri k\u00fcmesine sahip oldu\u011fumuzda iyi performans g\u00f6stermez\n2. Ayr\u0131ca, veri k\u00fcmesinde daha fazla g\u00fcr\u00fclt\u00fc oldu\u011funda, yani hedef s\u0131n\u0131flar \u00f6rt\u00fc\u015ft\u00fc\u011f\u00fcnde \u00e7ok iyi performans g\u00f6stermez.\n3. SVM, do\u011frudan olas\u0131l\u0131k tahminleri sa\u011flamaz, bunlar pahal\u0131 bir be\u015f kat \u00e7apraz do\u011frulama kullan\u0131larak hesaplan\u0131r. Python scikit-learn k\u00fct\u00fcphanesinin ilgili SVC y\u00f6ntemine dahil edilmi\u015ftir.","70a891ca":"# 30.1 Giri\u015f\n![image.png](attachment:7e333c74-1fe4-4eaa-9f15-ddb8ea968306.png)\n## Do\u011frusal Olmayan Regresyon Modelleri\n    1. K-En Yak\u0131n Kom\u015fu\n    2. Destek Vekt\u00f6r Regresyonu\n    3. Yapay Sinir A\u011flar\u0131\n    4. CART\n    5. Random Forests\n    6. Gradinet Boosting Machines\n    7. XGBoost\n    8. LightBGM\n    9. CatBoost","a9de45bd":"## T\u00fcm De\u011fi\u015fkenlerle Tune Etme\n\n- **Nas\u0131l homojenle\u015fti\u011fi gerekti\u011fini \u00e7ok iyi anlat\u0131yor.**\n- **Genelleme kayg\u0131s\u0131 varsa a\u015f\u0131r\u0131 \u00f6\u011frenme ortaya \u00e7\u0131kabilir**","1b2fff33":"## XGBoost: Tahmin","808073ad":"## GBM: Tahmin","ad127111":"\n* XGBoost, GBM'in H\u0131z ve tahmin performans\u0131n\u0131 artt\u0131rmak \u00fczere optimize edilmi\u015f; \u00f6l\u00e7eklenebilir ve farkl\u0131 platformlara entegre edilebilir halidir. (Tianqi Chen 2014)\n    * GBM'in \u00fczerine kurulmu\u015f.\n    \n![image.png](attachment:62fd4326-dc88-4298-a85f-a2a7ca6db59a.png)\n\n1. I. R, Python, Hadoop ve Scala ile kullan\u0131labilir \n1. II. H\u0131zl\u0131d\u0131r, a\u011faca dayal\u0131 bir modeldir \n1. III. Tahmin ba\u015far\u0131s\u0131 y\u00fcksektir\n1. IV. Bir \u00e7ok uluslararas\u0131 yar\u0131\u015fmada kendini kan\u0131tlam\u0131\u015ft\u0131r, [kaggle.com](http:\/\/kaggle.com)\n1. V. \u00d6l\u00e7eklenebilirdir\n\n![image.png](attachment:2b0c3a82-a262-4ac4-84a3-ace4c94ba51d.png)","a7bb7700":"# 38.2. Light GBM Model ve Tahmin","54cc487f":"## standartla\u015ft\u0131rma","20d6dd12":"## LigthGBM: Tahmin","9d8aa116":"![Sertifika 301](https:\/\/gelecegiyazanlar.turkcell.com.tr\/kisi\/belge\/ildesse3\/Makine%20%C3%96%C4%9Frenmesi\/301)","58e9a83a":"## 1.2 KNN Tahmin","ba5a99c2":"1. Kategorik de\u011fi\u015fkenler ile otomatik olarak m\u00fccadele edebilen, h\u0131zl\u0131, ba\u015far\u0131l\u0131 bir di\u011fer GBM t\u00fcrevi.\n\n![image.png](attachment:c1bda5bb-9ab6-4908-a02b-ecd835033c6b.png)\n\n1. Kategorik de\u011fi\u015fken deste\u011fi\n2. H\u0131zl\u0131 ve \u00f6l\u00e7eklenebilir GPU deste\u011fi\n3. Daha Ba\u015far\u0131l\u0131 tahminler\n4. H\u0131zl\u0131 train ve h\u0131zl\u0131 tahmin\n5. Rusyan\u0131n ilk a\u00e7\u0131k kaynak kodlu, ba\u015farl\u0131 ML \u00e7al\u0131\u015fmas\u0131\ni\u015flemleri uzun s\u00fcrebiliyor, dikkat\n\n![image.png](attachment:295af9e9-032b-4033-ab30-a41c9790f47d.png)\n\n\n# 39.2. CatBoost Model ve Tahmin","51dcab14":"## CatBoost: Tahmin","8315ca3a":"# 39.1. CatBoost: Category Boosting","dff30c86":" \nAma\u00e7: \n\n\nGBM: AdaBoost'un s\u0131n\u0131fland\u0131rma ve regresyon problemlerine kolayca uyarlanabilen genelle\u015ftirilmi\u015f versiyonudur. \n* Art\u0131k \u00fczerine tek bir tahminsel model formunda olan modeller serisi kurulur. (2001 Freidman)\n    * Art\u0131k: ger\u00e7ek de\u011fer ile tahmini de\u011fer aras\u0131ndaki farklar.\n- adaptive boosting adaboost\n- temel odak:s\u0131n\u0131fland\u0131rma problemidir.\n\n![image.png](attachment:27ba8bf9-280d-4dce-9c2b-fa9a8f3987d6.png)\n----------------------------------------\n1. Zay\u0131f \u00f6\u011flerincilerin bir araya getirip g\u00fc\u00e7l\u00fc bir \u00f6\u011frenci ortaya \u00e7\u0131karmak fikrine dayan\u0131r. (Keams ve Valiant 1990)\n    * k\u00f6t\u00fc tahmin, ger\u00e7ekleri ile tahmin de\u011ferlerin fark\u0131n\u0131n al\u0131nmas\u0131 sonucunda ortaya \u00e7\u0131kan b\u00fcy\u00fck de\u011ferlerdir K\u00f6t\u00fc tahminde bulunan a\u011fa\u00e7lar da zay\u0131f tahmincilerdir.\n![image.png](attachment:18df95cb-aee2-4764-883a-76de5cf7c1b5.png)\n\n2. Adaptive Boosting(AdaBoost): Zay\u0131f s\u0131n\u0131flad\u0131r\u0131clar\u0131n bir araya gelerek g\u00fc\u00e7l\u00fc bir s\u0131n\u0131fland\u0131r\u0131c\u0131 olu\u015f\u015fturmas\u0131 fikrini hayata ge\u00e7iren algoritmad\u0131r. (Schapires ve Freund 1996-1999)\n--------\n- `zay\u0131f \u00f6\u011frenciler`: k\u00f6t\u00fc tahminde bulanan a\u011fa\u00e7lar\n* adaboost: ilk \u00e7\u0131kt\u0131\u011f\u0131nda s\u0131n\u0131fland\u0131rma i\u00e7in problemleri \u00e7\u00f6zmek i\u00e7in yapmaya \u00e7al\u0131\u015ft\u0131.\n- **`fakat`**: tek bir cost fonksiyon sahip. Farkl\u0131 link fonksiyonlar\u0131 adapte etmekte zorlan\u0131yor.\n- adaptive: yani sona eklenmeli.\n\n![image.png](attachment:05204716-66df-4a05-a459-03f2f2a83e70.png)\n\n![adaboost](https:\/\/vitalflux.com\/wp-content\/uploads\/2020\/09\/Screenshot-2020-09-09-at-8.17.33-AM.png)\n\n![adaptive](https:\/\/miro.medium.com\/max\/850\/0*KYszvMnr3nCtjaGy.png)\n\n-----\n1. Gradient boosting tek bir tahminsel model formunda olan modeller serisi olu\u015fturur.\n1. Seri i\u00e7erisindeki bir model serideki bir \u00f6nceeki modelin tahmin art\u0131klar\u0131n\u0131n \/ hatalar\u0131n\u0131n(residuals) \u00fczerine kurularak fit olu\u015fturulur.\n1. GM diferansiyellenebilen herhangi bir kay\u0131p fonksiyonunu opitimize edebilen Gradient descent algoritmas\u0131n\u0131 kullanmakta\n1. GB bir\u00e7ok temel \u00f6\u011fretici tipi(base learner type) kullabilir. (Trees, leaner terms, splines...)\n1. Cost Fonskiyonlar\u0131 ve link fonksiyonlar\u0131 modifiye edebilirler.\n1. Boosting + Gradient Descent\n\n![image.png](attachment:83598d0b-ba02-4b57-bc96-410940a1f6d3.png)","0c492fda":"# 301-1. K-En Yak\u0131n Kom\u015fu\n![image.png](attachment:237dadff-94d5-438e-90d7-84abbc98ab11.png)\n![image.png](attachment:aa16dd2b-d34c-43a2-a812-d5afa94589ac.png)\n- Performans\u0131 iyi olmayabilir\n- Ama basit bir uygulan\u0131\u015f\u0131 var.\n\nNas\u0131l \u00e7al\u0131\u015f\u0131r?: G\u00f6zlemlerin birbirine olan benzerlikleri \u00fczerinden tahmin yap\u0131l\u0131r.\n\n1. S\u0131n\u0131fland\u0131rma ya da regresyon problemlerind kullan\u0131l\u0131r.\n2. Parametrik olmayan bir \u00f6\u011frenme t\u00fcr\u00fcd\u00fcr.\n3. G\u00f6zlemlerin birbirine olan benzerlikleri \u00fczerinden tahmin yap\u0131l\u0131r.\n\n![image.png](attachment:e4e44b79-7d95-4e93-9721-7e49937836d7.png)\n\n* KNN Basamaklar\u0131\n        1. Kom\u015fu say\u0131s\u0131n\u0131 belirle(K)\n        2. Bilinmeyen nokta ile di\u011fer t\u00fcm noktalar ile aras\u0131ndaki uzakl\u0131\u011f\u0131 hesapla\n        3. Uzakl\u0131klar\u0131 s\u0131rala ve belirlenen k say\u0131s\u0131na g\u00f6re en yak\u0131n olan k adet g\u00f6zlemi se\u00e7\n        4. S\u0131n\u0131flad\u0131rma ise en s\u0131k s\u0131n\u0131f, regresyon ise ortalama de\u011feri tahmin de\u011feri olarak ver. \n        \n![image.png](attachment:96b538a3-8455-434d-8f74-e012c6ade8e3.png)\n\n\n![KNN](https:\/\/res.cloudinary.com\/dyd911kmh\/image\/upload\/f_auto,q_auto:best\/v1531424125\/KNN_final_a1mrv9.png)  \n\n![pic](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcT0UXM7e2txxheGL0B3BUREJIp6HKK77KjSnQ&usqp=CAU)","5c97881b":"# 31.3. K En Yak\u0131n Kom\u015fu Model Tuning","898d34dc":"# 37.2. XGBoost Model ve Tahmin","483181e0":"# 32.3. Destek Vekt\u00f6r Regresyonu Model Tuning","510a04ba":"# 301 Makine \u00d6\u011frenmesi  \n* Do\u011frusal Olmayan Regreson Modelleri","76562fc1":"### 1.1. KNN Model","5c9296df":"# 32.2. Destek Vekt\u00f6r Regresyonu Model ve Tahmin","87c2b97a":"# 39.3. CatBoost: Model Tuning","2c600b64":"# 38.3. Light GBM: Model Tuning","e1ab5897":" #  35.3. Random Forests Model Tuning\n\n* Optimize edilecek \u20acn \u00f6nemli \u00fc\u00e7 parametre: \n    1. n_estimators=fit edilecek a\u011fa\u00e7 say\u0131s\u0131 b\u00f6l\u00fcn\u00fccek a\u011fa\u00e7 say\u0131s\u0131\n    2. B\u00f6l\u00fcm i\u015flemlerinde g\u00f6z \u00f6n\u00fcnde bulundurulacak de\u011fi\u015fken say\u0131s\u0131\n    3. min_samples_split\/ max_depth parametreleri\n    \n    \n* CART de ise en \u00f6nemli parametreler\n    1. min_samplet_split\n    2. max_depth","70aec8ec":"## de\u011fi\u015fken \u00f6nem d\u00fczeyi\nmodelleme s\u0131ras\u0131nda g\u00f6z \u00f6n\u00fcnde bulundururken neye dikkat etmem gerekiyor.","c0f4aa01":"# 37.1. XGBoost","862a6d08":"# 33.3. Yapay Sinir A\u011flar\u0131 Model Tuning"}}