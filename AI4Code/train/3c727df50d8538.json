{"cell_type":{"5fbeb26b":"code","eef294f3":"code","498c7850":"code","6813fb6d":"code","2831ca50":"code","d52d8f8f":"code","903e77d4":"code","cec31a27":"code","9be9c1c8":"code","1c4f893b":"code","8926d53a":"code","ad901d3a":"code","25b431e1":"code","05a27cd7":"code","c7e818f6":"code","b1257e19":"code","5c3793bc":"code","2c331e60":"code","731569d2":"code","fac1ada1":"markdown","042864cf":"markdown","250ed64e":"markdown","00005421":"markdown","d76bb875":"markdown","22e85dd0":"markdown","64edf5ff":"markdown","1c94ecda":"markdown","4e505e3f":"markdown","bb7fa227":"markdown","450e4ed8":"markdown"},"source":{"5fbeb26b":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom skimage.util import montage\nfrom IPython.display import Image, display, SVG, clear_output, HTML\nplt.rcParams[\"figure.figsize\"] = (6, 6)\nplt.rcParams[\"figure.dpi\"] = 125\nplt.rcParams[\"font.size\"] = 14\nplt.rcParams['font.family'] = ['sans-serif']\nplt.rcParams['font.sans-serif'] = ['DejaVu Sans']\nplt.style.use('ggplot')\nsns.set_style(\"whitegrid\", {'axes.grid': False})\nplt.rcParams['image.cmap'] = 'gray' # grayscale looks better\nimport networkx as nx\ndef draw_graph_mpl(g, pos=None, ax=None, layout_func=nx.drawing.layout.kamada_kawai_layout, draw_labels=True):\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n    else:\n        fig = None\n    if pos is None:\n        pos = layout_func(g)\n    node_color = []\n    node_labels = {}\n    shift_pos = {}\n    for k in g:\n        node_color.append(g.nodes[k].get('color', 'green'))\n        node_labels[k] = g.nodes[k].get('label', k)\n        shift_pos[k] = [pos[k][0], pos[k][1]]\n    \n    edge_color = []\n    edge_width = []\n    for e in g.edges():\n        edge_color.append(g.edges[e].get('color', 'black'))\n        edge_width.append(g.edges[e].get('width', 0.5))\n    nx.draw_networkx_edges(g, pos, font_weight='bold', edge_color=edge_color, width=edge_width, alpha=0.5, ax=ax)\n    nx.draw_networkx_nodes(g, pos, node_color=node_color, node_shape='p', node_size=300, alpha=0.75, ax=ax)\n    if draw_labels:\n        nx.draw_networkx_labels(g, shift_pos, labels=node_labels, arrows=True, ax=ax)\n    ax.autoscale()\n    return fig, ax, pos","eef294f3":"from keras import Input, Model\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Dense, Flatten, Lambda, Dropout, concatenate, Conv1D, GlobalAvgPool1D, GlobalMaxPool1D, Reshape\nfrom keras.metrics import sparse_top_k_categorical_accuracy\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2","498c7850":"# Parameters\nl2_reg = 5e-4         # Regularization rate for l2\nlearning_rate = 1e-3  # Learning rate for SGD\nbatch_size = 16       # Batch size\nepochs = 20        # Number of training epochs\nes_patience = 10     # Patience fot early stopping","6813fb6d":"import h5py\nfrom keras.utils.io_utils import HDF5Matrix\n_h5_path = '..\/input\/mnist-based-graphs\/disjoint_mnist.h5'\nraw_h5 = False\nstrip_xy = True\nif raw_h5:\n    _bare_h5 = h5py.File(_h5_path, 'r')\n    def load_xya(in_id):\n        in_group = _bare_h5[in_id]\n        feat = in_group['feature']\n        labels = in_group['label']\n        adj = in_group['adjacency_distance']\n        return feat, labels, adj\nelse:\n    def load_xya(in_id, normalize=False):\n        # use the hdf5matrix wrapper\n        feat = HDF5Matrix(_h5_path, f\"{in_id}\/feature\")\n        labels = HDF5Matrix(_h5_path, f\"{in_id}\/label\")\n        adj = HDF5Matrix(_h5_path, f\"{in_id}\/adjacency_distance\", normalizer=normalized_laplacian if normalize else None)\n        return feat, labels, adj\n\nx_train, y_train, adj_train = load_xya('train')\nx_valid, y_valid, adj_valid = load_xya('val')\nx_test, y_test, adj_test = load_xya('test')","2831ca50":"print(adj_train[0].shape, 'adjacency matrix')\nplt.matshow(adj_train[0])","d52d8f8f":"G = nx.from_numpy_array(adj_train[0])","903e77d4":"draw_graph_mpl(G);","cec31a27":"c_pos = x_train[0][:, :2]\nc_pos[c_pos==0] = np.NAN\ndraw_graph_mpl(G, pos=c_pos);","9be9c1c8":"N = x_train.shape[1]\nF = x_train.shape[2]\nn_out = np.max(y_train)+1","1c4f893b":"# Model definition\nX_in = Input(shape=(N, F), name='Features')\nA_in = Input(shape=(N, N), name='Topology')\n\nif strip_xy:\n    x = Lambda(lambda x: x[:, :, 2:], name='StripXY')(X_in)\nelse:\n    x = X_in\n\n\nconv_layers = []\nattn_layers = []\nfor i in range(6):\n    x = Conv1D(8*2**i,\n               kernel_size=(1,),\n               activation='elu',\n               kernel_regularizer=l2(l2_reg),\n              name='C1D_{}'.format(i),\n               use_bias=True)(x)\n    x_flat = Conv1D(1,\n               kernel_size=(1,),\n               activation='elu',\n               kernel_regularizer=l2(l2_reg),\n              name='C1D_Bottleneck_{}'.format(i),\n               use_bias=True)(x)\n    x_flat = Flatten()(x_flat)\n    x_flat = Dense(2, activation='elu', kernel_regularizer=l2(l2_reg))(x_flat)\n    x_flat = Dense(N, activation='elu', kernel_regularizer=l2(l2_reg))(x_flat)\n    x = concatenate([x, Reshape((N, 1))(x_flat)])\n    conv_layers.append(x)\n    c_attn = GlobalMaxPool1D(name='GMP_{}'.format(i))(x)\n    c_attn = Dense(32, activation='elu', kernel_regularizer=l2(l2_reg))(c_attn)\n    attn_layers.append(c_attn)\n\ngap_1 = concatenate(attn_layers)\ngap_dr = Dropout(0.5)(gap_1)\n\nfc = Dense(32, activation='relu')(gap_dr)\noutput = Dense(n_out, activation='softmax')(fc)\n\n# Build model\nmodel = Model(inputs=[X_in, A_in], outputs=output, name='DeeperGraph')\noptimizer = Adam(lr=learning_rate)\n\ndef top_3_acc(y_true, y_pred):\n    return sparse_top_k_categorical_accuracy(y_true, y_pred, k=3)\n\nmodel.compile(optimizer=optimizer,\n              loss='sparse_categorical_crossentropy',\n              metrics=['acc', top_3_acc])\nmodel.summary()","8926d53a":"from keras.utils.vis_utils import model_to_dot\nImage(model_to_dot(model, show_shapes=True).create_png())","ad901d3a":"# Train model\nvalidation_data = ({'Features': x_valid, 'Topology': adj_valid}, y_valid)\nmodel.fit({'Features': x_train, 'Topology': adj_train},\n          y_train,\n          batch_size=batch_size,\n          validation_data=validation_data,\n          epochs=epochs,\n          shuffle=\"batch\",\n          callbacks=[\n              EarlyStopping(patience=es_patience, restore_best_weights=True)\n          ])","25b431e1":"# Evaluate model\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nprint('Evaluating model.')\neval_pred = model.predict({'Features': x_test, 'Topology': adj_test},\n                              batch_size=batch_size,\n                         verbose=True)\neval_cat = np.argmax(eval_pred, -1)","05a27cd7":"print('Test acc: {:2.1%}'.format(accuracy_score(y_true=y_test[:], y_pred=eval_cat)))\nfig, ax1 = plt.subplots(1, 1, figsize=(15, 15))\nsns.heatmap(confusion_matrix(y_true=y_test[:], y_pred=eval_cat), annot=True, fmt='d', ax=ax1)","c7e818f6":"i_model = Model(inputs=[X_in, A_in], outputs=conv_layers+[gap_1, fc])","b1257e19":"*conv_outputs, gap_out, fc_out = i_model.predict({'Features': x_test[:256], 'Topology': adj_test[:256]})","5c3793bc":"fig, m_axs = plt.subplots(5, 1+len(conv_outputs), figsize=(20, 5*(1+len(conv_outputs))))\nfor c_ax in m_axs.flatten():\n    c_ax.set_xlim(0, 1)\n    c_ax.set_ylim(0, 1)\n    c_ax.axis('off')\ndef show_wrapped(in_ax, in_pos, in_vec):\n    row_count = np.sqrt(in_vec.shape[1]).astype(int)\n    max_x, max_y = 0, 0\n    for i in range(in_vec.shape[1]):\n        x_offset = i % row_count\n        max_x = max(x_offset, max_x)\n        y_offset = i \/\/ row_count\n        max_y = max(y_offset, max_y)\n        nmax_val = np.percentile(np.abs(in_vec[:, i]), 99)\n        in_ax.scatter(in_pos[:, 0]+x_offset, \n                      in_pos[:, 1]+y_offset, \n                      c=in_vec[:, i], \n                      s=5\/row_count, \n                      cmap='RdBu', \n                      vmin=-nmax_val, \n                      vmax=nmax_val)\n    in_ax.set_xlim(0, row_count+1)\n    in_ax.set_ylim(0, max_y+1)\n\nfor i, n_axs in enumerate(m_axs):\n    ax1, *r_axs = n_axs\n    x_vec = x_test[i]\n    pos_vec = x_vec[:, :2].copy()\n    pos_vec[pos_vec==0] = np.NAN\n    x_topo = adj_test[i]\n    G = nx.from_numpy_array(x_topo)\n    draw_graph_mpl(G, pos=pos_vec, ax=ax1, draw_labels=False);\n    ax1.scatter(pos_vec[:, 0], pos_vec[:, 1], c=x_vec[:, 2])\n    ax1.set_title(y_test[i])\n    ax1.set_xlim(0, 1)\n    ax1.set_ylim(0, 1)\n    \n    for j, (c_ax, conv_out) in enumerate(zip(r_axs, conv_outputs)):\n        show_wrapped(c_ax, in_pos=pos_vec, in_vec=conv_out[i])\n        c_ax.set_title('{}\\n{}'.format(i_model.output_names[j], conv_out[i].shape))","2c331e60":"n_keys = y_test[:gap_out.shape[0]]\nfig, m_axs = plt.subplots(4, 3, figsize=(12, 14))\nm_val = np.percentile(np.abs(gap_out.ravel()), 95)\nout_img_list = []\nfor i, c_ax in enumerate(m_axs.flatten()):\n    c_img = gap_out[n_keys==i, :]\n    if c_img.shape[0]>0:\n        out_img_list.append(c_img)\n        c_ax.imshow(c_img.T, vmin=-m_val, vmax=m_val, cmap='RdBu')\n        c_ax.set_title(i)\n    c_ax.axis('off')\nm_axs.ravel()[-1].imshow(np.concatenate(out_img_list, 0).T, vmin=-m_val, vmax=m_val, cmap='RdBu')\nm_axs.ravel()[-1].set_title('Combined')","731569d2":"fig, m_axs = plt.subplots(4, 3, figsize=(12, 14))\nm_val = np.percentile(np.abs(fc_out.ravel()), 99.5)\nout_img_list = []\nfor i, c_ax in enumerate(m_axs.flatten()):\n    c_img = fc_out[n_keys==i, :]\n    if c_img.shape[0]>0:\n        out_img_list.append(c_img)\n        c_ax.imshow(c_img.T, vmin=-m_val, vmax=m_val, cmap='RdBu')\n        c_ax.set_title(i)\n    c_ax.axis('off')\nm_axs.ravel()[-1].imshow(np.concatenate(out_img_list, 0).T, vmin=-m_val, vmax=m_val, cmap='RdBu')\nm_axs.ravel()[-1].set_title('Combined')","fac1ada1":"## Goal\nThe goal of the problem is to correctly classify the digits using the intensity values as the nodes and the neighborhood relationships as the edges. When we visualize the adjacency matrix we can see the effect of a simply unraveled 2D array","042864cf":"## Libraries\nHere are the libraries and imports to make the model","250ed64e":"- Use positions","00005421":"# Model Building\nNow we can build the model which uses the graph topology shown above as the basis. We feed the topology in as a constant tensor ($A_{in}$) and the convolutions occur across this topology. ","d76bb875":"## Install Dependencies","22e85dd0":"## Global Attention Features\n- What sort of features do we have after the attention layer\n- Are there easily distinguishable between digits?","64edf5ff":"# Overview\nHere is the baseline of how well a model can classify without any topology information on the graph. We try using just 1D convolutions and then a model with a fully connected layer. ","1c94ecda":"# What did the model actually learn?\nWe can now try and reassemble what the model actually learnt by exporting the intermediate layers","4e505e3f":"### Label Nodes and Show Connections\nHere we can visualize the topology a bit better and see what the graph actually looks like.","bb7fa227":"## Show intermediate output values\nHere we can rearrange the output of the graph convolutions to see if the model is learning similar sorts of features to the standard convolutional neural networks","450e4ed8":"## Fully Connected Features"}}