{"cell_type":{"fcaaaaf3":"code","054597d6":"code","05b16977":"code","5de45d91":"code","24064e9a":"code","fafc7e3b":"code","73c43397":"code","c51c7d6a":"code","d46c2a9c":"code","6273227a":"code","b620aae3":"code","49308d9c":"code","16f1a8be":"code","1a88b550":"code","dd04107f":"code","cbe0cbfb":"code","7b901dc6":"code","c1cdf3b1":"code","bf9e2eb7":"code","99f7a6a3":"code","b6c6fb23":"code","236b2a2d":"code","7dc843cf":"code","c5683e09":"code","a8764ab4":"code","260df8e6":"markdown"},"source":{"fcaaaaf3":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","054597d6":"train_data=pd.read_csv(\"..\/input\/train.csv\")\ntest_data=pd.read_csv(\"..\/input\/test.csv\")","05b16977":"train_data.info()","5de45d91":"test_data.info()","24064e9a":"train_data.describe()","fafc7e3b":"train_data.Cover_Type.value_counts()","73c43397":"train_data['HF1'] = train_data['Horizontal_Distance_To_Hydrology']+train_data['Horizontal_Distance_To_Fire_Points']\ntrain_data['HF2'] = abs(train_data['Horizontal_Distance_To_Hydrology']-train_data['Horizontal_Distance_To_Fire_Points'])\ntrain_data['HR1'] = abs(train_data['Horizontal_Distance_To_Hydrology']+train_data['Horizontal_Distance_To_Roadways'])\ntrain_data['HR2'] = abs(train_data['Horizontal_Distance_To_Hydrology']-train_data['Horizontal_Distance_To_Roadways'])\ntrain_data['FR1'] = abs(train_data['Horizontal_Distance_To_Fire_Points']+train_data['Horizontal_Distance_To_Roadways'])\ntrain_data['FR2'] = abs(train_data['Horizontal_Distance_To_Fire_Points']-train_data['Horizontal_Distance_To_Roadways'])\ntrain_data['ele_vert'] = train_data.Elevation-train_data.Vertical_Distance_To_Hydrology\n\ntrain_data['slope_hyd'] = (train_data['Horizontal_Distance_To_Hydrology']**2+train_data['Vertical_Distance_To_Hydrology']**2)**0.5\ntrain_data.slope_hyd=train_data.slope_hyd.map(lambda x: 0 if np.isinf(x) else x)\ntrain_data['Mean_Amenities']=(train_data.Horizontal_Distance_To_Fire_Points + train_data.Horizontal_Distance_To_Hydrology + train_data.Horizontal_Distance_To_Roadways) \/ 3 \ntrain_data['Mean_Fire_Hyd']=(train_data.Horizontal_Distance_To_Fire_Points + train_data.Horizontal_Distance_To_Hydrology) \/ 2 \ntest_data['HF1'] = test_data['Horizontal_Distance_To_Hydrology']+test_data['Horizontal_Distance_To_Fire_Points']\ntest_data['HF2'] = abs(test_data['Horizontal_Distance_To_Hydrology']-test_data['Horizontal_Distance_To_Fire_Points'])\ntest_data['HR1'] = abs(test_data['Horizontal_Distance_To_Hydrology']+test_data['Horizontal_Distance_To_Roadways'])\ntest_data['HR2'] = abs(test_data['Horizontal_Distance_To_Hydrology']-test_data['Horizontal_Distance_To_Roadways'])\ntest_data['FR1'] = abs(test_data['Horizontal_Distance_To_Fire_Points']+test_data['Horizontal_Distance_To_Roadways'])\ntest_data['FR2'] = abs(test_data['Horizontal_Distance_To_Fire_Points']-test_data['Horizontal_Distance_To_Roadways'])\ntest_data['ele_vert'] = test_data.Elevation-test_data.Vertical_Distance_To_Hydrology\n\ntest_data['slope_hyd'] = (test_data['Horizontal_Distance_To_Hydrology']**2+test_data['Vertical_Distance_To_Hydrology']**2)**0.5\ntest_data.slope_hyd=test_data.slope_hyd.map(lambda x: 0 if np.isinf(x) else x)\ntest_data['Mean_Amenities']=(test_data.Horizontal_Distance_To_Fire_Points + test_data.Horizontal_Distance_To_Hydrology + test_data.Horizontal_Distance_To_Roadways) \/ 3 \ntest_data['Mean_Fire_Hyd']=(test_data.Horizontal_Distance_To_Fire_Points + test_data.Horizontal_Distance_To_Hydrology) \/ 2","c51c7d6a":"real_data_columns=[\"Elevation\",\"Aspect\",\"Slope\",\"Horizontal_Distance_To_Hydrology\",\"Vertical_Distance_To_Hydrology\",\n          \"Hillshade_9am\",\"Hillshade_Noon\",\"Hillshade_3pm\",\"Horizontal_Distance_To_Fire_Points\",\"Horizontal_Distance_To_Roadways\",\n                  \"HF1\",\"HF2\",\"HR1\",\"HR2\",\"FR1\",\"FR2\",\"ele_vert\",\"slope_hyd\",\"Mean_Amenities\",\"Mean_Fire_Hyd\"]","d46c2a9c":"train_data.Soil_Type40.value_counts()","6273227a":"train_data=train_data.drop(['Soil_Type25'],axis=1)\ntest_data=test_data.drop(['Soil_Type25'],axis=1)","b620aae3":"train_data=train_data.drop(['Soil_Type7'],axis=1)\ntest_data=test_data.drop(['Soil_Type7'],axis=1)","49308d9c":"print(train_data.shape)\nprint(test_data.shape)","16f1a8be":"test_id=test_data[\"Id\"].values\ntest_data=test_data.drop([\"Id\"],axis=1)\ntrain_target=train_data[\"Cover_Type\"].values\ntrain_data=train_data.drop([\"Id\",\"Cover_Type\"],axis=1)","1a88b550":"train_data.head()","dd04107f":"test_data.head()","cbe0cbfb":"train_data_real=train_data[real_data_columns]\ntest_data_real=test_data[real_data_columns]\ntrain_data_bynary=train_data.drop(real_data_columns,axis=1)\ntest_data_bynary=test_data.drop(real_data_columns,axis=1)\nmean=train_data_real.mean(axis=0)\nstd=train_data_real.std(axis=0)\ntrain_data_real-=mean\ntrain_data_real\/=std\ntest_data_real-=mean\ntest_data_real\/=std\nX_train=np.hstack((train_data_real,train_data_bynary))\nX_test=np.hstack((test_data_real,test_data_bynary))\nmapping={1:0,2:1,3:2,4:3,5:4,6:5,7:6}\nY_train=[mapping[y] for y in train_target]","7b901dc6":"from sklearn.model_selection import train_test_split","c1cdf3b1":"training_data,val_data,training_target,val_target=train_test_split(X_train,\n                                                                   Y_train,test_size=0.3)","bf9e2eb7":"from keras import models\nfrom keras.models import load_model\nfrom keras import layers\nfrom keras import regularizers\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping\nfrom sklearn.metrics import accuracy_score","99f7a6a3":"model=models.Sequential()\nmodel.add(layers.Dense(64,activation=\"relu\",\n                       input_shape=(X_train.shape[1],)))\nmodel.add(layers.Dense(64,activation=\"relu\"))\nmodel.add(layers.Dense(64,activation=\"relu\"))\nmodel.add(layers.Dense(7,activation='softmax'))\nmodel.compile(optimizer='rmsprop',loss='sparse_categorical_crossentropy',metrics=['accuracy']) ","b6c6fb23":"from sklearn.model_selection import ShuffleSplit","236b2a2d":"earlystopper = EarlyStopping(patience=5, verbose=1)\ncheckpointer = ModelCheckpoint('model-tgs-salt-1.h5', verbose=1, save_best_only=True)\nhistory=model.fit(X_train,Y_train,epochs=40,batch_size=128,validation_split=0.1,verbose=1,callbacks=[earlystopper,checkpointer])\nval_loss,val_acc=model.evaluate(v_data,v_target,verbose=0)\nscores.append(val_acc)\nvalid_loss=(history.history[\"val_loss\"])\nloss=(history.history[\"loss\"])\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, valid_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","7dc843cf":"print(np.mean(scores))","c5683e09":"model=load_model(\"model-tgs-salt-1.h5\")\npred=model.predict(X_train)\npred=np.argmax(pred,axis=1)\nmapping={0:1,1:2,2:3,3:4,4:5,5:6,6:7}\npred=[mapping[y] for y in pred]\nprint(accuracy_score(Y_train,pred))","a8764ab4":"predictions=model.predict(X_test)\npredictions=np.argmax(predictions,axis=1)\nmapping={0:1,1:2,2:3,3:4,4:5,5:6,6:7}\npredictions=[mapping[y] for y in predictions]\ndata_submission=pd.DataFrame()\ndata_submission['Id']=test_id\ndata_submission[\"Cover_Type\"]=predictions\ndata_submission.to_csv(\"my_submission.csv\",index=False)","260df8e6":"This feature engeneering is taken from the following source:https:\/\/www.kaggle.com\/codename007\/forest-cover-type-eda-baseline-model?scriptVersionId=4280427"}}