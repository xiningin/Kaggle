{"cell_type":{"36bbfd4f":"code","863b1377":"code","2d9e01f3":"code","d3b00af0":"code","b18791a2":"code","b515d802":"code","5d08dc45":"code","361b306c":"code","cc43e015":"code","d0564462":"code","415ff549":"code","229d7f3b":"code","0b6aa5bf":"code","fb1d0ba4":"code","f8c49256":"code","cc5560c1":"code","f9ab836e":"code","70955b0c":"code","db56f05a":"code","fbb7c8e4":"markdown","3f8bacb0":"markdown","371e6eef":"markdown","887ee24d":"markdown","a85b72ff":"markdown","661c0b81":"markdown"},"source":{"36bbfd4f":"from math import sqrt\nimport pandas as pd \nimport numpy as np\nimport seaborn as sns\nimport random\nimport sys\nimport math, copy\nimport csv\nimport matplotlib.pyplot as plt\nimport surprise\nimport os\nimport io\nfrom collections import defaultdict\nfrom numpy import inf\nfrom itertools import groupby\nfrom surprise import SVD\nfrom surprise import accuracy\nfrom surprise.model_selection import train_test_split\nfrom surprise import Reader, Dataset\nfrom surprise import KNNBasic\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics.pairwise import linear_kernel\nfrom sklearn.metrics.pairwise import pairwise_distances\nfrom surprise.model_selection import cross_validate","863b1377":"df_ratings = pd.read_csv(\"..\/input\/movielens-20m-dataset\/rating.csv\")\n\ndf_movies = pd.read_csv(\"..\/input\/movielens-20m-dataset\/movie.csv\")\n\ndf_movies_ratings=pd.concat([df_movies, df_ratings], axis='columns')\ndf_movies_ratings = df_movies_ratings[['movieId','title','userId','rating']]\ndf_movies_ratings.head()","2d9e01f3":"df_movies_ratings.keys()","d3b00af0":"df_movies_ratings.columns = ['movie', 'movieId', 'title','userId', 'rating']\ndf_movies_ratings.drop(['movie'], inplace=True, axis=1)","b18791a2":"# Utility Matrix\ndf = df_movies_ratings.head(1000000)\nratings_matrix_items = df.pivot_table(index=['userId'],\n                       columns=['movieId'],values='rating').reset_index(drop=True)\n\nratings_matrix_items.fillna(0, inplace = True)","b515d802":"# Generate similarity pairwise matrix with pearson correlation\n\nmov_sim = np.corrcoef(ratings_matrix_items)\nmatrix_item= pd.DataFrame(mov_sim)\nmovie_similarity = 1-matrix_item\nmatrix_item= pd.DataFrame(movie_similarity)\nmatrix_item.shape","5d08dc45":"def CalculateTime(jarak, kecepatan):\n    return 0 if kecepatan == 0 else jarak\/kecepatan\n\ndef GetDistance(data, row, col):\n    row -=1\n    col -=1\n#     print(row, col)\n    return data.iloc[row][col]\n\ndef CalculateDistance(data, rute):\n    totalDistance = 0\n    for i in range(len(rute)-1):\n        distance = GetDistance(data, rute[i], rute[i+1])\n        if (distance == 0):\n            return inf #No edge found\n        totalDistance += distance\n        if (rute[i+1] == a):\n            return totalDistance #End Route\n    return totalDistance\n\ndef PrintStatus(statusRoute, rute, time):\n    print(statusRoute, rute, '\\nTime: ', time, '\\n\\n')\n\ndef Init():\n    #data = pd.read_csv(\"mov_rating.csv\")\n    data = matrix_item\n    rute_utama =[]\n    rute_utama.extend(range(0,a))\n    jarak_rute_utama = CalculateDistance(data, rute_utama)\n    kecepatan_rute_utama = 1 # jeda antar userId\n    #PrintStatus('Main Route: ', rute_utama, CalculateTime(jarak_rute_utama, kecepatan_rute_utama))\n    return data\n\ndef CalculateLightIntensity(data, kecepatan, rute):\n    jarak = CalculateDistance(data, rute)\n    if (jarak == inf):\n        return 0\n    time = CalculateTime(jarak, kecepatan)\n    return 0 if time == 0 else 1\/time\n\ndef GetLightIntensityFromAllFireflies(populasi, data, kecepatan):\n    lights = []\n    for rute in populasi:\n        lights.append(CalculateLightIntensity(data, kecepatan, rute))\n    return lights\n\ndef InitialPopulation(nPopulasi, nGen):\n    populasi = []\n    \n    for i in range(nPopulasi):\n        firefly=[]\n        firefly.extend(np.random.choice(range(2,nGen+1), nGen-1, replace=False)) #Random permutasi, without replacement\n        populasi.append(firefly)\n    return populasi\n\ndef OrderPopulation(light, populasi):\n    indeks = np.argsort(light, axis=0) #sorting ascending\n    light_ = [light[idx] for idx in indeks]\n    populasi_ = [populasi[idx] for idx in indeks]\n    return light_, populasi_\n\ndef EvaluatePopulasi(populasi):\n    return [k for k,v in groupby(sorted(populasi))]","361b306c":"### Main Program\na = 943\nnp.seterr(divide='ignore', invalid='ignore')\ndata = Init()\nkecepatan_rute_alt = 1 # m\/menit = 20km\/jam\ngamma = 0.01; # Absorption coefficient\nbeta0 = 1 # Attractiveness constant\nalpha=1.0 # Randomness strength 0--1 (highly random)\ntheta=0.97 # Randomness reduction factor theta=10^(-5\/tMax)\nnPopulasi = 943\nnGen = 943 # Dimension\n\nlb=0\nub=943\nscale = ub - lb\n\nbestFirefly = []\nsolutionFound = False\npopulasi = InitialPopulation(nPopulasi, nGen)\ntempPopulasi = []\n\nlight = GetLightIntensityFromAllFireflies(populasi, data, kecepatan_rute_alt)\n\nlight_, populasi_ = OrderPopulation(light, populasi)\n\n# best firefly check\nif (light_[len(light_)-1] > 0):\n    solutionFound = True\n    bestFirefly = populasi_[len(populasi_)-1]\n    \nwhile (solutionFound == False):\n    alpha *= theta\n    populasi.extend(tempPopulasi)\n    populasi = EvaluatePopulasi(populasi) # Remove duplicate populasi\n    light = GetLightIntensityFromAllFireflies(populasi, data, kecepatan_rute_alt)\n    light_, populasi_ = OrderPopulation(light, populasi)\n    \n    # best firefly check\n    if (light_[len(light_)-1] > 0):\n        solutionFound = True\n        bestFirefly = populasi_[len(populasi_)-1]\n        break\n    \n    tempPopulasi = []\n    \n    # Movement populasi firefly\n    for i in range(len(populasi_)):\n        for j in range(i):\n            if light_[j] >= light_[i]:\n                selectedFirefly = populasi_[i]\n                r=np.sqrt(np.sum([k**2 for k in ([a-b for a,b in zip(populasi_[i], populasi_[j])])])) #Euclidean distance\n                beta = beta0*math.exp(-gamma*(r**2))\n                indexForSwap = int(scale * np.random.uniform(0,1,1) + lb)\n                if alpha*np.random.uniform(0,1,1) > 0.5:\n                    index2ForSwap = indexForSwap + int(beta) + lb\n                else:\n                    index2ForSwap = indexForSwap - int(beta) - lb\n                if (index2ForSwap > ub):\n                    selectedFirefly[indexForSwap-1], selectedFirefly[ub-1] =  selectedFirefly[ub-1], selectedFirefly[indexForSwap-1]\n                elif (index2ForSwap < lb):\n                    selectedFirefly[indexForSwap-1], selectedFirefly[lb-1] =  selectedFirefly[lb-1], selectedFirefly[indexForSwap-1]\n                else:\n                    selectedFirefly[indexForSwap-1], selectedFirefly[index2ForSwap-1] =  selectedFirefly[index2ForSwap-1], selectedFirefly[indexForSwap-1]\n                tempPopulasi.append(selectedFirefly)\n                \nprint('Best Firefly: ', bestFirefly)","cc43e015":"bf = pd.DataFrame(bestFirefly)\nbf.rename(columns={0:'user_id'}, inplace=True)\nlg = pd.DataFrame(sorted(light_, reverse=True))\nlg.rename(columns={0:'weight'}, inplace=True)\nresult = pd.concat([bf, lg], axis =1)\nresult","d0564462":"result = result.dropna()\nresult","415ff549":"result.describe()","229d7f3b":"# Merge Rating and weight\n\ndf_weight = df.merge(result, left_on='userId', right_on='user_id')\ndf_weight.head()","0b6aa5bf":"def experiment(k,weight,test_size):\n    reader = Reader()\n    data = Dataset.load_from_df(df_weight[[str(weight),'user_id','rating']], reader)\n    trainset, testset = train_test_split(data, test_size=test_size, random_state=50)\n\n    sim_options = {'name': 'pearson_baseline','shrinkage': 0}\n    algo = KNNBasic(sim_options=sim_options)\n    algo_knn = KNNBasic(k=k, sim_options=sim_options, user_based=True)\n    prediction_knn = algo_knn.fit(trainset).test(testset)\n    cv = cross_validate(algo_knn, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)","fb1d0ba4":"experiment(10,'weight',0.2)","f8c49256":"k, weight, test_size = 10, 'weight', 0.2\nreader = Reader()\ndata = Dataset.load_from_df(df_weight[[str(weight),'user_id','rating']], reader)\ntrainset, testset = train_test_split(data, test_size=test_size, random_state=50)\n\nsim_options = {'name': 'pearson_baseline','shrinkage': 0}\nalgo = KNNBasic(sim_options=sim_options)\nalgo_knn = KNNBasic(k=k, sim_options=sim_options, user_based=True)\nprediction_knn = algo_knn.fit(trainset).test(testset)\ncv = cross_validate(algo_knn, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)","cc5560c1":"algo.fit(trainset)\npredictions = algo.test(testset)","f9ab836e":"def precision_recall_at_k(predictions, k=10, threshold=3.5):\n    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n\n    # First map the predictions to each user.\n    user_est_true = defaultdict(list)\n    for uid, _, true_r, est, _ in predictions:\n        user_est_true[uid].append((est, true_r))\n\n    precisions = dict()\n    recalls = dict()\n    accuracy = {}\n    for uid, user_ratings in user_est_true.items():\n\n        # Sort user ratings by estimated value\n        user_ratings.sort(key=lambda x: x[0], reverse=True)\n\n        # Number of relevant items\n        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n\n        # Number of recommended items in top k\n        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n\n        # Number of relevant and recommended items in top k\n        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n                              for (est, true_r) in user_ratings[:k])\n\n        # Precision@K: Proportion of recommended items that are relevant\n        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n\n        precisions[uid] = n_rel_and_rec_k \/ n_rec_k if n_rec_k != 0 else 0\n\n        # Recall@K: Proportion of relevant items that are recommended\n        # When n_rel is 0, Recall is undefined. We here set it to 0.\n\n        recalls[uid] = n_rel_and_rec_k \/ n_rel if n_rel != 0 else 0\n        accuracy[uid] = (n_rel + n_rec_k) \/ (n_rel_and_rec_k + n_rel + n_rec_k) if n_rel!=0 else 0\n\n    return precisions, recalls, accuracy","70955b0c":"precisions, recalls, acc = precision_recall_at_k(predictions)\nprint(sum(prec for prec in precisions.values()) \/ len(precisions))\nprint(sum(rec for rec in recalls.values()) \/ len(recalls))\nprint(sum(ac for ac in acc.values()) \/ len(acc))","db56f05a":"def get_top_n(predictions, n=10):\n    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n\n    Args:\n        predictions(list of Prediction objects): The list of predictions, as\n            returned by the test method of an algorithm.\n        n(int): The number of recommendation to output for each user. Default\n            is 10.\n\n    Returns:\n    A dict where keys are user (raw) ids and values are lists of tuples:\n        [(raw item id, rating estimation), ...] of size n.\n    \"\"\"\n\n    # First map the predictions to each user.\n    top_n = defaultdict(list)\n    for uid, iid, true_r, est, _ in predictions:\n        top_n[uid].append((iid, est))\n\n    # Then sort the predictions for each user and retrieve the k highest ones.\n    for uid, user_ratings in top_n.items():\n        user_ratings.sort(key=lambda x: x[1], reverse=True)\n        top_n[uid] = user_ratings[:n]\n\n    return top_n\n\n\ntop_n = get_top_n(predictions, n=10)\n\n# Print the recommended items for each user\nuser = 25\n\nfor uid, user_ratings in top_n.items():\n    if uid == user:\n        for (iid, rating) in user_ratings:\n            movie = iid\n            print('Movie:', iid, '-', movie, ', rating:', str(rating))\n        #print(uid, [iid for (iid, _) in user_ratings])","fbb7c8e4":"## Firefly Process","3f8bacb0":"## Define the libraries ","371e6eef":"## Define the datasets","887ee24d":"# Recommender System \n\n- SI : Firefly Algorithm\n- DATASET : MovieLens\n- Similarity : Pearson Correlation Coefficient\n- Rating Prediction : KNN Basic","a85b72ff":"### EX001\n\n- K = 10\n- Train = 80%\n- User Based = True\n- Sim = Pearson\n- CV = 5\n- Weight = YES","661c0b81":"## FA Weighting Result\n\nBased on result FA produce \n1. The most weighted user_id : 810\n2. Mean of Weight : 0.006614\n3. Std of weight : 0.017754\n4. Max of weight : 0.257814\n5. Min of weight : 0.001194"}}