{"cell_type":{"6da774ad":"code","99f44899":"code","3da464a6":"code","b57ff608":"code","da04ae88":"code","ad23521f":"code","f851b340":"code","aaf9620b":"code","5031c15f":"code","12e32acd":"code","5c1a0084":"code","42a2cac3":"code","369e93a5":"code","f2c7aded":"code","57a44201":"code","18d434e5":"code","41eac097":"code","6991842b":"code","6a286994":"code","62716e6e":"code","bce608f2":"code","ed6da677":"code","657bc1b6":"code","8f176719":"code","2adf24da":"code","696c01c1":"code","f87599ed":"code","2ebbe926":"code","8fa3d317":"code","f62e3ff8":"markdown","2ade5ac3":"markdown","4a62db8d":"markdown"},"source":{"6da774ad":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","99f44899":"# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u307f\u307e\u3059\u3002\ndf_train = pd.read_csv('\/kaggle\/input\/ml-study-meetup-osaka\/OsakaWinter_train.csv', index_col=0)\ndf_test = pd.read_csv('\/kaggle\/input\/ml-study-meetup-osaka\/OsakaWinter_test.csv', index_col=0)","3da464a6":"# \u5b66\u7fd2\u30c7\u30fc\u30bf\u3068\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u5148\u982d5\u884c\u3092\u305d\u308c\u305e\u308c\u898b\u3066\u307f\u307e\u3057\u3087\u3046\ndf_train.head()","b57ff608":"df_test.head()","da04ae88":"# \u5e9c\u770c\u306e\u5185\u8a33\u3092\u78ba\u8a8d\u3057\u3066\u307f\u307e\u3057\u3087\u3046\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u5185\u3067\u306f\u5175\u5eab\u306b\u7269\u4ef6\u304c\u591a\u304f\u3001\u6b21\u3044\u3067\u4eac\u90fd\u306b\u591a\u3044\u3088\u3046\u3067\u3059\u3002\ndf_train.Prefecture.value_counts()","ad23521f":"df_test.Prefecture.value_counts()","f851b340":"# \u5b66\u7fd2\u30c7\u30fc\u30bf\u5185\u306e\u5404\u5e9c\u770c\u306e\u5e73\u5747TradePrice\u306e\u30e9\u30f3\u30ad\u30f3\u30b0\u3002\u5b66\u7fd2\u30c7\u30fc\u30bf\u5185\u3067\u306f\u4eac\u90fd\u3001\u3064\u3044\u3067\u5175\u5eab\u306e\u7269\u4ef6\u304c\u5e73\u5747\u7684\u306b\u306f\u9ad8\u3044\u3088\u3046\u3067\u3059\u3002\n# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306e\u5206\u306f\uff08\u305d\u308c\u304c\u4e88\u6e2c\u30bf\u30fc\u30b2\u30c3\u30c8\u306a\u306e\u3067\uff09\u3042\u308a\u307e\u305b\u3093\u304c\u3001\u304a\u305d\u3089\u304f\u306f\u4eac\u90fd\u3088\u308a\u3055\u3089\u306b\u4e0a\u304b\u3082\u3057\u308c\u307e\u305b\u3093\u306d\u3002\u809d\u5fc3\u306e\u5927\u962a\u304c\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3068\u3044\u3046\u306e\u306f\u5b9f\u306b\u5384\u4ecb\u3067\u3059\u306d\uff01\ndf_train.groupby(['Prefecture']).TradePrice.mean().sort_values(ascending=False)","aaf9620b":"# \u30b5\u30d6\u306e\u5e02\u753a\u6751\u30c7\u30fc\u30bf\u3068\u9244\u9053\u99c5\u30c7\u30fc\u30bf\u3082\u3056\u3063\u3068\u773a\u3081\u3066\u307f\u307e\u3057\u3087\u3046\ndf_city = pd.read_csv('\/kaggle\/input\/ml-study-meetup-osaka\/OsakaWinter_city.csv')\ndf_station = pd.read_csv('\/kaggle\/input\/ml-study-meetup-osaka\/OsakaWinter_station.csv')","5031c15f":"df_city.head()","12e32acd":"df_station.head()","5c1a0084":"# wiki_desctiption\u306e\u4e2d\u3082\u898b\u3066\u307f\u307e\u3057\u3087\u3046\u3002\u307e\u305a\u306f\u5e02\u753a\u6751\u30c7\u30fc\u30bf\ndf_city.wiki_description[0]","42a2cac3":"# \u3064\u3044\u3067\u9244\u9053\u99c5\u30c7\u30fc\u30bf\u3002\u3069\u3046\u3067\u3057\u3087\u3046\uff1f\u6709\u7528\u305d\u3046\u306a\u60c5\u5831\u306f\u3042\u308a\u305d\u3046\u3067\u3057\u3087\u3046\u304b\uff1f\ndf_station.wiki_description[0]","369e93a5":"# \u3055\u3066\u3001\u307e\u305a\u306f\u30b7\u30f3\u30d7\u30eb\u306a\u30d9\u30fc\u30b9\u30e9\u30a4\u30f3\u30e2\u30c7\u30eb\u3092\u4f5c\u3063\u3066\u3044\u304d\u307e\u3057\u3087\u3046\n# \u307e\u305a\u306f\u30bf\u30fc\u30b2\u30c3\u30c8\u5909\u6570\u3068\u7279\u5fb4\u91cf\u306b\u5206\u5272\u3057\u307e\u3059\ny_train = df_train.TradePrice\nX_train = df_train.drop(['TradePrice'], axis=1)\nX_test = df_test.copy()\ngroups = df_train.Prefecture","f2c7aded":"# \u5b66\u7fd2\u3068\u30c6\u30b9\u30c8\u306f\u5730\u7406\u3067\u533a\u5207\u3089\u308c\u3066\u3044\u308b\u305f\u3081\u3001\u3053\u308c\u3089\u306e\u5730\u540d\u306f\u76f4\u63a5\u306f\u7528\u3044\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u305b\u3093\u3002\ncol_geo = ['Prefecture', 'Municipality', 'DistrictName', 'NearestStation']","57a44201":"# \u5730\u540d\u305d\u306e\u307e\u307e\u306f\u4f7f\u3048\u306a\u3044\u306e\u3067\u3001\u3088\u308a\u4e00\u822c\u5316\u3057\u305f\u8868\u73fe\u3068\u3057\u3066\u3053\u3053\u3067\u306fCount Encoding(\u51fa\u73fe\u56de\u6570\u306b\u7f6e\u63db\u3059\u308b)\u3092\u884c\u306a\u3063\u3066\u307f\u307e\u3059\u3002\n# \u5148\u307b\u3069\u306e\u770c\u540d\u3067value_counts\u3057\u305f\u969b\u306b\u307b\u307c\u4eba\u53e3\u6bd4\u306b\u306a\u3063\u3066\u3044\u305f\u3088\u3046\u306b\u898b\u3048\u305f\u306e\u3067\u3001\u3053\u308c\u3067\u5404\u5730\u57df\u306e\u4eba\u53e3\u6bd4\u306e\u8fd1\u4f3c\u5024\u306e\u3088\u3046\u306a\u7279\u5fb4\u91cf\u306b\u306a\u308b\u3053\u3068\u3092\u671f\u5f85\u3057\u3066\u3044\u307e\u3059\u3002\nfor col in col_geo:\n    summary_train = X_train[col].value_counts()\n    summary_test = X_test[col].value_counts()\n    \n    X_train[col] = X_train[col].map(summary_train)\n    X_test[col] = X_test[col].map(summary_test)","18d434e5":"# \u3053\u306e\u3088\u3046\u306b\u30a8\u30f3\u30b3\u30fc\u30c9\u3055\u308c\u307e\u3057\u305f\nX_train[col_geo]","41eac097":"X_test[col_geo]","6991842b":"# \u5148\u307b\u3069head\u3092\u307f\u305f\u3068\u304d\u306b\u6700\u5bc4\u308a\u99c5\u307e\u3067\u306e\u6240\u8981\u6642\u9593\u306b\u6587\u5b57\u5217\u304c\u542b\u307e\u308c\u3066\u3044\u305f\u306e\u304c\u6c17\u306b\u306a\u308a\u307e\u3057\u305f\u3088\u306d\u3002\nX_train.TimeToNearestStation.value_counts()","6a286994":"# \u6570\u5024\u3067\u7d71\u4e00\u3067\u304d\u308b\u3088\u3046\u306b\u7f6e\u63db\u3057\u3066\u304a\u304d\u307e\u3057\u3087\u3046\nreplace_dict = {'30-60minutes':30, '1H-1H30':60, '1H30-2H':90, '2H-':120}\nX_train['TimeToNearestStation'].replace(replace_dict, inplace=True)\nX_test['TimeToNearestStation'].replace(replace_dict, inplace=True)\n\nX_train['TimeToNearestStation'] = X_train['TimeToNearestStation'].astype(float)\nX_test['TimeToNearestStation'] = X_test['TimeToNearestStation'].astype(float)","62716e6e":"from category_encoders import OrdinalEncoder\n\ncol_cat = []\nfor col in X_train.columns:\n    if X_train[col].dtype=='object':\n        col_cat.append(col)\n        \nencoder = OrdinalEncoder()\nencoder.fit(X_train[col_cat])\nX_train[col_cat] = encoder.transform(X_train[col_cat])\nX_test[col_cat] = encoder.transform(X_test[col_cat])","bce608f2":"# \u307e\u305a\u306f\u6700\u4f4e\u9650\u306e\u524d\u51e6\u7406\u304c\u3067\u304d\u305f\u306e\u3067\u3001\u30e2\u30c7\u30eb\u306e\u5b66\u7fd2\u3092\u3057\u3066\u307f\u307e\u3057\u3087\u3046\nX_train.head()","ed6da677":"X_test.head()","657bc1b6":"from pandas import DataFrame\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import mean_squared_error\nfrom lightgbm import LGBMRegressor","8f176719":"seed = 71\nlgb_params = {\n                    'boosting_type': 'gbdt',\n                    'objective': 'rmse',\n                    'metric': 'rmse',\n                    'subsample': 0.71,\n                    'subsample_freq': 1,\n                    'learning_rate': 0.05,\n                    'n_estimators':9999,\n                    'num_leaves': 7,\n                    'min_data_in_leaf': 10,\n                    'feature_fraction': 0.71,\n                    'importance_type':'gain',\n                    'verbose': -1,\n                    'seed':seed,\n                    'device': 'gpu',# \u4eca\u56de\u306fGPU\u3092\u7528\u3044\u3066\u307f\u307e\u3057\u3087\u3046\n                    'gpu_use_dp': False\n                } ","2adf24da":"# \u90fd\u9053\u5e9c\u770c\u3067\u533a\u5207\u3063\u3066\u4ea4\u5dee\u691c\u5b9a\u3092\u884c\u3044\u3001\u4e88\u6e2c\u7cbe\u5ea6\u3092\u898b\u7a4d\u3082\u308b\u3002\n# \u540c\u6642\u306b\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u306b\u5bfe\u3057\u3066cv averaging\u3092\u884c\u3044\u3001\u4e88\u6e2c\u5024\u3092\u5f97\u308b\u3002\nn_fold = 3\ncv = GroupKFold(n_splits=n_fold) # \u5b66\u7fd2\u3068\u30c6\u30b9\u30c8\u304c\u5e9c\u770c\u3067\u533a\u5207\u3089\u308c\u3066\u3044\u308b\u306e\u3067\u3001\u8a55\u4fa1\u3082\u540c\u69d8\u306b\u5e9c\u770c\u3067\u533a\u5207\u308a\u307e\u3059\u3002\n\ny_pred_train = np.zeros(len(X_train))\ny_pred_test = np.zeros(len(X_test))\nimportances = DataFrame(np.zeros(len(X_train.columns)), index=X_train.columns, columns=['importance'])\nscores = []\n\nfor i, (train_index, val_index) in enumerate(cv.split(X_train, y_train, groups)):\n    X_train_, y_train_ = X_train.iloc[train_index], y_train.iloc[train_index]\n    X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n    \n    model = LGBMRegressor(**lgb_params)\n    model.fit(X_train_, np.log1p(y_train_), eval_set=[(X_val, np.log1p(y_val))], early_stopping_rounds=50, eval_metric='rmse')# Evaluation\u306e\u30da\u30fc\u30b8\u306e\u8a55\u4fa1\u5f0f\u3092\u898b\u308b\u3068\u308f\u304b\u308a\u307e\u3059\u304c\u3001\u5bfe\u6570\u5909\u63db\u3057\u3066RMSE\u3092\u7528\u3044\u308b\u3068RMSLE\u3068\u7b49\u4fa1\u306b\u306a\u308a\u307e\u3059\u3002\n    y_pred_val = np.expm1(model.predict(X_val))\n    y_pred_test += np.expm1(model.predict(X_test))\/n_fold\n    importances['importance'] += model.feature_importances_\/n_fold\n    \n    y_pred_train[val_index] = y_pred_val\n    score = mean_squared_error(np.log1p(y_val), np.log1p(y_pred_val))**0.5\n    scores.append(score)\n    \n    print(\"Fold%d RMSLE: %f\"%(i, score))\n    \nprint(\"Overall RMSLE: %f\u00b1%f\"%(np.mean(scores), np.std(scores)))","696c01c1":"import matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline","f87599ed":"# \u5909\u6570\u91cd\u8981\u5ea6\u3082\u78ba\u8a8d\u3057\u3066\u304a\u304d\u307e\u3057\u3087\u3046\nimportances.sort_values(['importance'], ascending=False, inplace=True)\n\nplt.figure(figsize=[6,10])\nplt.title('Feature Importance')\nplt.barh(importances.index[::-1], importances.importance[::-1])\nplt.xlabel('importance')\nplt.show()","2ebbe926":"# \u4e88\u6e2c\u5024\u3092\u6240\u5b9a\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306b\u4ee3\u5165\u3057\u3066\u63d0\u51fa\u7528\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3057\u307e\u3059\nsubmission = pd.read_csv('\/kaggle\/input\/ml-study-meetup-osaka\/OsakaWinter_sample_submission.csv')\nsubmission['TradePrice'] = y_pred_test\nsubmission","8fa3d317":"# \u4fdd\u5b58\u3057\u307e\u3059\nsubmission.to_csv('submission.csv', index=False)","f62e3ff8":"## \u30c7\u30fc\u30bf\u306e\u6e96\u5099\u3092\u3057\u307e\u3057\u3087\u3046","2ade5ac3":"## \u30d9\u30fc\u30b9\u30e9\u30a4\u30f3\u30e2\u30c7\u30eb\u3092\u69cb\u7bc9\u3057\u3066\u307f\u3088\u3046","4a62db8d":"## \u307e\u305a\u306f\u3088\u304f\u30c7\u30fc\u30bf\u3092\u898b\u3066\u307f\u307e\u3057\u3087\u3046"}}