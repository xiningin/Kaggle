{"cell_type":{"81df0ca9":"code","fa0098ab":"code","7d56b81a":"code","6679be31":"code","7cd92ec8":"code","d70d700a":"code","ba7806ec":"code","a434df0a":"code","e3e69c67":"code","4ade14ce":"code","24ad60c6":"code","ad1ddf5d":"code","1f4f92a8":"code","56b7038a":"markdown","43ef46bc":"markdown","ce5511ef":"markdown","63e11469":"markdown","14bd783b":"markdown","7e28e27b":"markdown","1c2dab0d":"markdown","358d3a49":"markdown","343f8248":"markdown"},"source":{"81df0ca9":"import numpy as np\nimport scipy.stats\nimport pandas as pd\npd.set_option('max_columns', None)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression","fa0098ab":"data = pd.read_csv('..\/input\/airlines-customer-satisfaction\/Invistico_Airline.csv')","7d56b81a":"data","6679be31":"data.info()","7cd92ec8":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Fill missing arrival delay values with column mean\n    df['Arrival Delay in Minutes'] = df['Arrival Delay in Minutes'].fillna(df['Arrival Delay in Minutes'].mean())\n    \n    # Binary encoding\n    df['Gender'] = df['Gender'].replace({\n        'Female': 0,\n        'Male': 1\n    })\n    df['Customer Type'] = df['Customer Type'].replace({\n        'disloyal Customer': 0,\n        'Loyal Customer': 1\n    })\n    df['Type of Travel'] = df['Type of Travel'].replace({\n        'Personal Travel': 0,\n        'Business travel': 1\n    })\n    \n    # One-hot encoding\n    flight_class_dummies = pd.get_dummies(df['Class'], prefix='Flight_class')\n    df = pd.concat([df, flight_class_dummies], axis=1)\n    df = df.drop('Class', axis=1)\n    \n    return df","d70d700a":"X = preprocess_inputs(data)","ba7806ec":"X","a434df0a":"eda_df = X.drop('satisfaction', axis=1).copy()\nnonbinary_columns = [column for column in eda_df.columns if len(eda_df[column].unique()) > 2]\n\nplt.figure(figsize=(20, 20))\n\nfor i, column in enumerate(nonbinary_columns):\n    plt.subplot(3, 6, i + 1)\n    sns.boxplot(data=eda_df[column], color='darkviolet')\n    plt.title(column)\n\nplt.suptitle(\"Boxplots With Outliers\", size=30)\nplt.show()","e3e69c67":"def remove_outliers(df, columns, threshold):\n    df = df.copy()\n    \n    # Calculate the lower and upper bounds on the Z distribution given a threshold value\n    lower_bound = scipy.stats.norm.ppf(q=(threshold \/ 2), loc=0, scale=1)\n    upper_bound = scipy.stats.norm.ppf(q=1 - (threshold \/ 2), loc=0, scale=1)\n    \n    # Calculate z-scores of every example in the columns specified\n    outlier_df = df.loc[:, columns].copy()\n    zscores = pd.DataFrame(scipy.stats.zscore(outlier_df, axis=0), index=outlier_df.index, columns=outlier_df.columns)\n    \n    # Get boolean arrays denoting the outlier examples\n    lower_outliers = (zscores < lower_bound).any(axis=1)\n    upper_outliers = (zscores >= upper_bound).any(axis=1)\n    \n    # Get indicies of all outlier examples\n    outliers = df[pd.concat([lower_outliers, upper_outliers], axis=1).any(axis=1)].index\n    \n    # Drop the outliers\n    df = df.drop(outliers, axis=0).reset_index(drop=True)\n    print(len(outliers), \"examples dropped.\")\n    \n    return df","4ade14ce":"outliers_df = remove_outliers(\n    df=X,\n    columns=[\n        'On-board service',\n        'Checkin service',\n        'Departure Delay in Minutes',\n        'Arrival Delay in Minutes',\n        'Online boarding'\n    ],\n    threshold=0.08\n)\n\nplt.figure(figsize=(20, 20))\n\nfor i, column in enumerate(nonbinary_columns):\n    plt.subplot(3, 6, i + 1)\n    sns.boxplot(data=outliers_df[column], color='cornflowerblue')\n    plt.title(column)\n\nplt.suptitle(\"Boxplots Without Outliers\", size=30)\nplt.show()","24ad60c6":"def finalize_inputs(df, keep_outliers=True, outlier_threshold=0.05):\n    df = df.copy()\n    \n    \n    \n    # Train-test Split\n    train_df, test_df = train_test_split(df, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Remove outliers\n    if keep_outliers == False:\n        train_df = remove_outliers(\n            train_df,\n            columns=[\n                'On-board service',\n                'Checkin service',\n                'Departure Delay in Minutes',\n                'Arrival Delay in Minutes'\n            ],\n            threshold=outlier_threshold\n        )\n    \n    # Split df into X and y\n    y_train = train_df['satisfaction']\n    y_test = test_df['satisfaction']\n    X_train = train_df.drop('satisfaction', axis=1)\n    X_test = test_df.drop('satisfaction', axis=1)\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    X_train = pd.DataFrame(scaler.transform(X_train), index=X_train.index, columns=X_train.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), index=X_test.index, columns=X_test.columns)\n    \n    return X_train, X_test, y_train, y_test","ad1ddf5d":"X_train1, X_test1, y_train1, y_test1 = finalize_inputs(X, keep_outliers=True)\n\nmodel1 = LogisticRegression()\nmodel1.fit(X_train1, y_train1)\n\nprint(\"Test Accuracy: {:.3f}%\".format(model1.score(X_test1, y_test1) * 100))","1f4f92a8":"X_train2, X_test2, y_train2, y_test2 = finalize_inputs(X, keep_outliers=False, outlier_threshold=0.0000001)\n\nmodel2 = LogisticRegression()\nmodel2.fit(X_train2, y_train2)\n\nprint(\"Test Accuracy: {:.3f}%\".format(model2.score(X_test2, y_test2) * 100))","56b7038a":"# Outlier Detection","43ef46bc":"# Training With Outlier Removal","ce5511ef":"# Finalizing Model Inputs","63e11469":"# Task for Today  \n\n***\n\n## Airline Customer Satisfaction Prediction  \n\nGiven *data about airline customers*, let's try to predict if a given customer will be **satisfied with the airline**.\n\nWe will use a logistic regression model to make our predictions, but first we will detect and remove outliers using z-scores.","14bd783b":"# Getting Started","7e28e27b":"# Outlier Removal","1c2dab0d":"# Training Without Outlier Removal","358d3a49":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/drTBYwjFjn4","343f8248":"# Preprocessing"}}