{"cell_type":{"943e5f3e":"code","876b027e":"code","3bcff0a8":"code","efa1fdc7":"code","6657b661":"code","9bfa6aca":"code","c0a31796":"code","8091a9c4":"code","aa149c83":"code","c3eb689c":"code","d33e7eff":"code","1cb82741":"code","62552a1d":"code","5415ee60":"code","8d20d749":"code","f93e6306":"code","57a38170":"code","c4b31697":"code","503a655c":"code","4b840892":"code","54948f0c":"code","604a4d72":"code","b983f1f9":"code","3c27ae40":"code","0743d1a9":"code","6a9e3280":"code","7c895a98":"code","9d5bbb89":"code","1585df0d":"code","b2340e1a":"code","9466f5d8":"code","ffdf8e0d":"code","27581ee5":"code","d2e4b810":"code","827ad5de":"code","615abce8":"code","e70be54d":"code","51df10ea":"markdown","85c70f66":"markdown","e63d1ba5":"markdown","c1b8d0c9":"markdown","c493baf2":"markdown","f24a4f2c":"markdown","ae1223bc":"markdown","4aa9931b":"markdown","0366ab0c":"markdown","5f1efac5":"markdown","f0f93c6c":"markdown","fab7b946":"markdown","575f6c89":"markdown","014953e3":"markdown","1a6203a0":"markdown","fde797bd":"markdown","7ad21dc8":"markdown","1d0f3569":"markdown","60e1e9aa":"markdown","debca0d5":"markdown"},"source":{"943e5f3e":"import numpy as np\nimport pandas as pd\n\n#visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom os.path import join, isfile\nfrom os import path, scandir, listdir\n\nimport gc","876b027e":"def list_all_files(location='kaggle\/input\/', pattern=None, recursive=True):\n    \"\"\"\n    This function returns a list of files at a given location (including subfolders)\n    \n    - location: path to the directory to be searched\n    - pattern: part of the file name to be searched (ex. pattern='.csv' would return all the csv files)\n    - recursive: boolean, if True the function calls itself for every subdirectory it finds\n    \"\"\"\n    subdirectories= [f.path for f in scandir(location) if f.is_dir()]\n    files = [join(location, f) for f in listdir(location) if isfile(join(location, f))]\n    if recursive:\n        for directory in subdirectories:\n            files.extend(list_all_files(directory))\n    if pattern:\n        files = [f for f in files if pattern in f]\n    return files","3bcff0a8":"list_all_files('\/kaggle\/input\/Electricity\/', pattern='stedin')","efa1fdc7":"def importer(file_list):\n    imported = {}\n    for file in file_list:\n        yr = file.split('_')[-1].split('.')[0]\n        if '0101' in yr:\n            yr = yr.replace('0101', '')\n        name = file.split('\/')[-1].split('_')[0]\n        # print(name, yr)\n        df = pd.read_csv(file)\n        # print(df.shape)\n        imported[name + '_' + yr] = df\n        del df\n    return imported","6657b661":"elec_list = list_all_files('\/kaggle\/input\/Electricity\/')\ngas_list = list_all_files('\/kaggle\/input\/Gas\/')\nimp_elec = importer(elec_list)\nimp_gas = importer(gas_list)\nprint('Done!')","9bfa6aca":"def merge_manager(data_dict):\n    all_man = pd.DataFrame()\n    n_rows = 0\n    for key in data_dict.keys():\n        df = data_dict[key].copy()\n        yr = key.split('_')[1]\n        yr = str(int(yr) - 1) # account for the \"delayed data issue\"\n        df = df.rename(columns={'annual_consume' : 'annual_consume_' + yr,\n                               'delivery_perc': 'delivery_perc_' + yr,\n                               'num_connections': 'num_connections_' + yr,\n                               'perc_of_active_connections': 'perc_of_active_connections_' + yr,\n                               'annual_consume_lowtarif_perc': 'annual_consume_lowtarif_perc_' + yr,\n                               'smartmeter_perc': 'smartmeter_perc_' + yr})\n        del df['type_conn_perc']\n        del df['type_of_connection']\n        del df['net_manager']\n        del df['purchase_area']\n        n_rows += df.shape[0]\n        if len(all_man) == 0:\n            all_man = df.copy()\n        else:\n            del df['street']\n            del df['city']\n            all_man = pd.merge(all_man, df, on=['zipcode_from', 'zipcode_to'], how='inner') # 'city', 'street',  \n        del df\n        gc.collect()\n    print(f\"Total rows before merge: {n_rows}\")\n    print(f\"Total rows after merge: {all_man.shape[0]}\")\n    return all_man\n\n\ndef merge_yr(data_dict):\n    all_yr = pd.DataFrame()\n    for manager in ['enexis', 'liander', 'stedin']:\n        print(manager)\n        tmp = { key: data_dict[key] for key in data_dict.keys() if manager in key}\n        all_man = merge_manager(tmp)\n        if len(all_yr) == 0:\n            all_yr = all_man.copy()\n        else:\n            all_yr = pd.concat([all_yr, all_man], ignore_index=True, join='inner')\n        del all_man\n        gc.collect()\n        print(\"_\"*40)\n    print(f\"Final shape: {all_yr.shape}\")\n    return all_yr","c0a31796":"print(\"Electricity merging...\")\nelec_full = merge_yr(imp_elec)\nprint('_'*40)\nprint('_'*40)\nprint(\"Gas merging...\")\ngas_full = merge_yr(imp_gas)","8091a9c4":"elec_full.head()","aa149c83":"def consume_per_connection(data, consume_list):\n    for col in consume_list:\n        yr = col.split('_')[-1]\n        data['consume_per_conn_'+yr] = data[col] \/ (data['num_connections_' + yr] * \n                                                   data['perc_of_active_connections_' + yr] \/ 100)\n        data.loc[data['consume_per_conn_' + yr] == np.inf, 'consume_per_conn_' + yr] = 0\n    return data","c3eb689c":"consume = [col for col in elec_full.columns if 'annual_consume_2' in col]\nconsume.sort()","d33e7eff":"elec_full = consume_per_connection(elec_full, consume)\nelec_full[consume + [col for col in elec_full.columns if 'consume_per_conn_' in col]].describe()","1cb82741":"gas_full = consume_per_connection(gas_full, consume)\ngas_full[consume + [col for col in gas_full.columns if 'consume_per_conn_' in col]].describe()","62552a1d":"fig, ax = plt.subplots(1,2, figsize=(17,8))\n\nfor col in consume:\n    sns.distplot(elec_full.loc[elec_full[col] < 20000, col], \n                 hist=False, label=col.split('_')[-1], ax=ax[0], axlabel='Annual Consumption')\n    sns.distplot(gas_full.loc[gas_full[col] < 6000, col], \n                 hist=False, label=col.split('_')[-1], ax=ax[1], axlabel='Annual Consumption') \n\nax[0].set_title('Electricity', fontsize=15)\nax[1].set_title('Gas', fontsize=15)\nfig.suptitle('Annual consumption', fontsize=22)\nplt.show()","5415ee60":"cons_per_conn = [col for col in gas_full.columns if 'consume_per_conn_' in col]\ncons_per_conn.sort()","8d20d749":"fig, ax = plt.subplots(1,2, figsize=(17,8))\n\nfor col in cons_per_conn:\n    sns.distplot(elec_full.loc[elec_full[col] < 1000, col], \n                 hist=False, label=col.split('_')[-1], ax=ax[0], axlabel='Annual Consumption')\n    sns.distplot(gas_full.loc[gas_full[col] < 400, col], \n                 hist=False, label=col.split('_')[-1], ax=ax[1],  axlabel='Annual Consumption')\n\nax[0].set_title('Electricity', fontsize=15)\nax[1].set_title('Gas', fontsize=15)\nfig.suptitle('Annual consume per connection', fontsize=22)\nplt.show()","f93e6306":"plt.figure(figsize=(10,10))\nsns.pairplot(elec_full[consume].sample(10000), kind=\"reg\")\n\nplt.suptitle('Correlations between electricity consumptions at different years', fontsize=22, y=1.01)\nplt.show()","57a38170":"elec_city = elec_full[['city', 'annual_consume_2009']].groupby('city', as_index=False).sum()\n\nfor col in consume:\n    if col == 'annual_consume_2009':\n        continue\n    tmp = elec_full[['city', col]].groupby('city', as_index=False).sum()\n    elec_city = pd.merge(elec_city, tmp, on='city')\n\nelec_city = elec_city.set_index('city')\nelec_city['mean_consume'] = elec_city.mean(axis=1)\nelec_city.sample(5)","c4b31697":"tmp = elec_city.nlargest(10, 'mean_consume')\ndel tmp['mean_consume'] # so it doesn't show up in the plot\ntmp.columns = tmp.columns.str.replace('annual_consume_', '')\nax = tmp.T.plot(figsize=(10,8))\nax.set_xticklabels(['','2009', '2011','2013','2015', '2017'])\nax.set_ylabel(\"kWh\")\nax.set_xlabel(\"Year\")\nax.set_title(\"Electricity consumption by year (top 10 cities)\", fontsize=18)\ndel tmp","503a655c":"elec_city = elec_full[['city', 'annual_consume_2009', 'num_connections_2009']].groupby('city', as_index=False).sum()\nelec_city['cons_per_con_2009'] = elec_city['annual_consume_2009'] \/ elec_city['num_connections_2009']\ndel elec_city['num_connections_2009']\ndel elec_city['annual_consume_2009']\n\nfor col in consume:\n    if col == 'annual_consume_2009':\n        continue\n    yr = col.split('_')[-1]\n    tmp = elec_full[['city', col, 'num_connections_'+yr]].groupby('city', as_index=False).sum()\n    tmp['cons_per_con_'+yr] = tmp[col] \/ tmp['num_connections_'+yr]\n    del tmp[col]\n    del tmp['num_connections_'+yr]\n    elec_city = pd.merge(elec_city, tmp, on='city')\n\nelec_city = elec_city.set_index('city')\nelec_city['mean_consume'] = elec_city.mean(axis=1)\ntmp = elec_city.nlargest(10, 'mean_consume')\ndel tmp['mean_consume']\ntmp.columns = tmp.columns.str.replace('cons_per_con_', '')\nax = tmp.T.plot(figsize=(10,8), title='Electricity consumption per connection by year')\nax.set_xticklabels(['','2009', '2011', '2013','2015','2017', '2019'])\nax.set_ylabel(\"kWh\")\nax.set_xlabel(\"Year\")\nax.set_title(\"Electricity consumption per connection by year (top 10 cities)\", fontsize=18)\ndel tmp\nplt.show()","4b840892":"gas_city = gas_full[['city', 'annual_consume_2009', 'num_connections_2009']].groupby('city', as_index=False).sum()\ngas_city['cons_per_con_2009'] = gas_city['annual_consume_2009'] \/ gas_city['num_connections_2009']\ndel gas_city['num_connections_2009']\ndel gas_city['annual_consume_2009']\n\nfor col in consume:\n    if col == 'annual_consume_2009':\n        continue\n    yr = col.split('_')[-1]\n    tmp = gas_full[['city', col, 'num_connections_'+yr]].groupby('city', as_index=False).sum()\n    tmp['cons_per_con_'+yr] = tmp[col] \/ tmp['num_connections_'+yr]\n    del tmp[col]\n    del tmp['num_connections_'+yr]\n    gas_city = pd.merge(gas_city, tmp, on='city')\n\ngas_city = gas_city.set_index('city')\ngas_city['mean_consume'] = gas_city.mean(axis=1)\ntmp = gas_city.nlargest(10, 'mean_consume')\ndel tmp['mean_consume']\ntmp.columns = tmp.columns.str.replace('cons_per_con_', '')\nax = tmp.T.plot(figsize=(10,8), title='Gas consumption per connection by year')\nax.set_xticklabels(['','2009', '2011', '2013','2015','2017', '2019'])\nax.set_ylabel(\"m3\")\nax.set_xlabel(\"Year\")\nax.set_title(\"Gas consumption per connection by year (top 10 cities)\", fontsize=18)\ndel tmp","54948f0c":"print(elec_city.nlargest(10, 'mean_consume')['mean_consume'])\nprint('_'*40)\nprint(gas_city.nlargest(10, 'mean_consume')['mean_consume'])","604a4d72":"del elec_full\ndel gas_full\ndel elec_city\ndel gas_city\n\ngc.collect()","b983f1f9":"def aggr_yr(data, yr):\n    # useful features\n    data['net_annual_cons_'+yr] = data['annual_consume'] * data['delivery_perc'] \/ 100\n    data['self_production_'+yr] = data['annual_consume'] - data['net_annual_cons_'+yr]\n    data['low_tarif_cons_'+yr] = data['annual_consume'] * data['annual_consume_lowtarif_perc'] \/ 100\n    data['active_conn_'+yr] = data['num_connections'] * data['perc_of_active_connections'] \/ 100\n    data['num_smartmeters_'+yr] = data['num_connections'] * data['smartmeter_perc'] \/ 100\n    data = data.rename(columns={'annual_consume': 'annual_consume_'+yr})\n    # aggregations\n    aggregation = data[['city', 'annual_consume_'+yr, 'net_annual_cons_'+yr,\n                        'self_production_'+yr, 'low_tarif_cons_'+yr,\n                        'active_conn_'+yr, 'num_smartmeters_'+yr]].groupby('city', as_index=False).sum()\n    return aggregation\n\ndef aggr_mng(data_dict):\n    all_man = pd.DataFrame()\n    for key in data_dict.keys():\n        df = data_dict[key].copy()\n        yr = key.split('_')[-1]\n        yr = str(int(yr) - 1) # account for the \"delayed data issue\"\n        if len(all_man) == 0:\n            all_man = aggr_yr(df, yr)\n        else:\n            df = aggr_yr(df,yr)\n            all_man = pd.merge(all_man, df, on='city')\n        del df\n        gc.collect()\n    all_man = all_man.set_index('city')\n    return all_man\n\ndef aggregations(data_dict):\n    result = pd.DataFrame()\n    for manager in ['enexis', 'liander', 'stedin']:\n        print(manager)\n        tmp = { key: data_dict[key] for key in data_dict.keys() if manager in key}\n        all_man = aggr_mng(tmp)\n        if len(result) == 0:\n            result = all_man.copy()\n        else:\n            result = pd.concat([result, all_man], join='inner')\n        del all_man\n        gc.collect()\n        print(\"_\"*40)\n    print(f\"Final shape: {result.shape}\")\n    return result","3c27ae40":"cities_el = aggregations(imp_elec)\ncities_el.sample(10)","0743d1a9":"cities_el.describe()","6a9e3280":"cities_gas = aggregations(imp_gas)\ncities_gas.sample(10)","7c895a98":"cities_gas.describe()","9d5bbb89":"consume = [col for col in cities_el.columns if 'annual_consume_' in col]\nconsume.sort()","1585df0d":"fig, ax = plt.subplots(1,2, figsize=(20, 8))\n\ncities_el[consume].sum().plot(title='Total Electricity consumption per year', ax=ax[0])\nax[0].set_xticklabels(['','2009', '2011', '2013','2015','2017', '2019'])\nax[0].set_ylabel(\"kWh\")\nax[0].set_xlabel(\"Year\")\ncities_gas[consume].sum().plot(title='Total Gas consumption per year', ax=ax[1])\nax[1].set_xticklabels(['','2009', '2011', '2013','2015','2017', '2019'])\nax[1].set_ylabel(\"m3\")\nax[1].set_xlabel(\"Year\")\nplt.show()","b2340e1a":"tmp = cities_el[consume].copy()\ntmp['mean_consume'] = tmp.mean(axis=1)\ntmp = tmp.nlargest(10, 'mean_consume')\ndel tmp['mean_consume']\ntmp.columns = tmp.columns.str.replace('annual_consume_', '')\n\nfig, ax = plt.subplots(1,2, figsize=(20, 8))\ntmp.T.sum().plot(kind='bar', title='Total Electricity top 10 cities', ax=ax[0])\ntmp.T.plot(title='Electricity consumption per year top 10 cities',ax=ax[1])\nax[0].set_ylabel(\"kWh\")\nax[1].set_xticklabels(['','2009', '2011', '2013','2015','2017', '2019'])\nax[1].set_xlabel(\"Year\")\nplt.show()","9466f5d8":"tmp = cities_gas[consume].copy()\ntmp['mean_consume'] = tmp.mean(axis=1)\ntmp = tmp.nlargest(10, 'mean_consume')\ndel tmp['mean_consume']\ntmp.columns = tmp.columns.str.replace('annual_consume_', '')\n\nfig, ax = plt.subplots(1,2, figsize=(20, 8))\ntmp.T.sum().plot(kind='bar', title='Total Gas top10 cities', ax=ax[0])\ntmp.T.plot(title='Gas consumption per year top10 cities',ax=ax[1])\nax[0].set_ylabel(\"m3\")\nax[1].set_xticklabels(['','2009', '2011', '2013','2015','2017', '2019'])\nax[1].set_xlabel(\"year\")\nplt.show()","ffdf8e0d":"self_prod = [col for col in cities_el.columns if 'self_production_' in col]\nself_prod.sort()","27581ee5":"ax = cities_el[self_prod].sum().plot(figsize=(12, 8), fontsize=12)\nax.set_xticklabels(['','2009', '2011', '2013','2015','2017', '2019'])\nax.set_title('Total Electricity self-produced per year', fontsize=22)\nax.set_ylabel(\"kWh\", fontsize=12)\nax.set_xlabel(\"year\", fontsize=12)\nplt.show()","d2e4b810":"tmp = cities_el[self_prod].copy()\ntmp['max_prod'] = tmp.max(axis=1)\ntmp = tmp.nlargest(10, 'max_prod')\ndel tmp['max_prod']\ntmp.columns = tmp.columns.str.replace('self_production_', '')\n\nfig, ax = plt.subplots(1,2, figsize=(20, 8))\ntmp['2018'].T.plot(kind='bar', title='Electricity self-produced in 2018, top10 cities', ax=ax[0])\ntmp.T.plot(title='Electricity self-produced per year top10 cities',ax=ax[1])\nax[0].set_ylabel(\"kWh\")\nax[1].set_xticklabels(['','2009', '2011', '2013','2015','2017', '2019'])\nax[1].set_xlabel(\"Year\")\nplt.show()","827ad5de":"smrt = [col for col in cities_el.columns if 'num_smartmeters_' in col]\nsmrt.sort()","615abce8":"ax = cities_el[smrt].sum().plot(figsize=(12, 8),fontsize=12)\nax.set_xticklabels(['','2009', '2011', '2013','2015','2017', '2019'])\nax.set_ylabel(\"Number of smart meters\", fontsize=12)\nax.set_xlabel(\"year\", fontsize=12)\nax.set_title('Total smart meters per year', fontsize=22)\nplt.show()","e70be54d":"tmp = cities_el[smrt].copy()\ntmp['max_num'] = tmp.max(axis=1)\ntmp = tmp.nlargest(10, 'max_num')\ndel tmp['max_num']\ntmp.columns = tmp.columns.str.replace('num_smartmeters_', '')\n\nfig, ax = plt.subplots(1,2, figsize=(20, 8))\ntmp['2018'].T.plot(kind='bar', title='Total number of smart meters in 2018, top10 cities', ax=ax[0])\ntmp.T.plot(title='Total number of smart meters per year top10 cities',ax=ax[1])\nax[0].set_ylabel(\"Number of smart meters\")\nax[1].set_xticklabels(['','2009', '2011', '2013','2015','2017', '2019'])\nax[1].set_xlabel(\"Year\")\nplt.show()","51df10ea":"Not only this plot is very bad looking, but also somewhat misleading since we are aggregating by city a dataset that does not have all the data of every city (due to the merge). Let's free up some memory and do it in a better way and see if we still get what it appears to be a slightly negative trend.\n\n# Aggregating data by city, the better way","85c70f66":"And the same can be done for the consumption per connection we created above","e63d1ba5":"One thing we can do is to calculate the consumption per connection. Thus we divide the annual consumption by the number of active connections.","c1b8d0c9":"## Self-production\n\nLet's see if we can identify some trend in the energy produced by the population (most likely solar panels, for which there have been some incentives given by the government)","c493baf2":"The data are structured as follows","f24a4f2c":"It appears to be very consistent every year, I wonder if we can observe that better (yes, it is pairplot time)","ae1223bc":"## Smart meters","4aa9931b":"This time, we aggregate the data *before* the merge.","0366ab0c":"*Note*: Every file actually refers to the energy consumption of the year before. Thus `stedin_electricity_2011.csv` contains the data about 2010, for Stedin administrated connections.\n\nLet's proceed in importing everything in a convenient structure.","5f1efac5":"We indeed observe a descending trend, with something odd happening in 2017. **This can very well be a mistake during the data cleaning or data preparation.**\n\nAgain, focusing on cities with high consumption will just lead to the most populated cities.","f0f93c6c":"Let's see the top 10 cities by electricity consumption","fab7b946":"While it was predictable to find Amsterdam and Rotterdam leading this chart (being the biggest cities), it is interesting to notice that they grew similarly even though their networks are managed by different companies (Liander and Stedin, respectively)\n\n# Conclusions\n\nI hope this kernel gave you some inspiration on how to use this dataset, please share your thoughts about it, use it, make something beautiful, find problems in the data and help me fix them :)\n\nOn a more personal note, I am not used (as you see) to making visualizations so every feedback will be very much appreciated.\n\nCheers.","575f6c89":"If we define the top cities as the one that had the maximum production at some point in the period under analysis, we get some **Almere pride** in the air","014953e3":"# A first look at the data\n\nIn this section, we will try to merge all these files together so that we can have an overview of the energy consumption at a given zip code (or group of zip codes) every year. We will first merge by company and then concatenate the results\n\nThere are a few obstacles:\n* the zip codes can be grouped differently every year\n* the zip codes can change from year to year (some of them got redefined during this period)\n* not only the annual consumption changes but also the number of connections and other indicators change every year, we have to account for that.\n\nAs we will see, this approach is useful to keep track of what happens to a specific group of zip codes year by year, but it is not very good if we try some kind of aggregation.","1a6203a0":"Enexis, Liander, and Stedin are the three major network administrators of the Netherlands and, together, they provide energy to nearly the entire country. Every year, they release on their websites a table with the energy consumption of the areas under their administration.\n\nThe data are anonymized by aggregating the Zipcodes so that every entry describes at least 10 connections.\n\nThis market is not competitive, meaning that the zones are assigned. This means that every year they roughly provide energy to the same zipcodes. Small changes can happen from year to year either for a change of management or for a different aggregation of zipcodes.\n\nThis kernel aims to explore and spark some ideas on how to use this new dataset. \n\nIn drafting it, I was able to spot a few issues in the dataset and correct them. However, the data are coming from different companies and cover several years: assume that there will be inconsistencies for a while.\n\n***v14 notes***: this is a run to test that the new version of the dataset is healthy. The 2018 data are added for 2 companies out of 3, they will not be displayed by the current analysis. As soon as Stedin put their data out, a new version will be released\n\n***v16 notes***: This run includes the data for Stedin in 2018 as well, the purpose is again to test that the dataset preparation went reasonably well\n\n***v17 notes***: A run to test 2019 data.","fde797bd":"Which is nice but it is just confirming that some cities are more populated than others. Let's do it again with consumption per connection.","7ad21dc8":"As we see, we lose a considerable amount of entries due to the merge, we will think about a solution for this later and move on for now.\n\nMoreover, one company does not have a `2009` table and I am silently dropping the other `2009` tables. \n\nDuring the merge, I have also corrected for the year ambiguity. Thus now, for example, `num_connections_2014` really refers to the value of 2014.","1d0f3569":"Nothin looks particulary weird but it was at this point that I have noticed a problem with a few files that were using the `.` for the thousands in a non obvious way. The solution proposed is temporary but keep that in mind.\n\nWe can make some  plots with the distribution of the consumption of electricity and gas every year. (We exclude the ectremely large values)\n\n(The warning happens only on the kaggle kernel, probably due to a different scipy\/seaborn version)","60e1e9aa":"## Energy consumption\n\nLet's have a look at the total energy consumption of the country.","debca0d5":"Yep, it is pretty consistent.\n\nNext, we could focus on aggregating by city"}}