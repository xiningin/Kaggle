{"cell_type":{"87258938":"code","2bd8c667":"code","c2c787e7":"code","c3f428ba":"code","5bb2876f":"code","0da5fa8c":"code","849f3fea":"code","20ebdd26":"code","c8fa651e":"code","8da1872c":"code","2e04586b":"code","7f1a1033":"code","42e98623":"code","4624aaaf":"code","450738d8":"code","6971f276":"code","47ac7f07":"code","2ec70d9b":"markdown","ba51b7c0":"markdown","e2a6a519":"markdown","71870d22":"markdown","995738f5":"markdown","44d05268":"markdown","44698058":"markdown","8c3e6db2":"markdown"},"source":{"87258938":"import os\nimport pandas as pd\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('seaborn-bright')\n\nnp.random.seed(0)\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport tensorflow as tf\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","2bd8c667":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","c2c787e7":"print('Train Data Shape: {}'.format(train.shape))\nprint('Test Data Shape: {}'.format(test.shape))","c3f428ba":"train.head()","5bb2876f":"plt.figure(figsize=(6, 4))\nsns.countplot(train['label'])\nplt.xlabel('Label')\nplt.ylabel('Count')","0da5fa8c":"y_train = train.label.astype('float32')\nX_train = train.drop('label', axis=1).astype('float32')\nX_test = test.astype('float32')\n\nprint(X_train.shape, y_train.shape, X_test.shape)","849f3fea":"X_train = X_train.values.reshape(-1, 28, 28, 1)\nX_train = X_train \/ 255.0\n\nX_test = X_test.values.reshape(-1, 28, 28, 1)\nX_test = X_test \/ 255.0\n\nprint(X_train.shape, X_test.shape)","20ebdd26":"plt.figure(figsize=(12, 12))\nfor i in range(1, 6):\n    plt.subplot(5, 5, i)\n    plt.imshow(X_train[random.randint(0, len(X_train))])","c8fa651e":"plt.figure(figsize=(12, 12))\nfor i in range(1, 6):\n    plt.subplot(5, 5, i)\n    plt.imshow(X_test[random.randint(0, len(X_test))])","8da1872c":"y_train = tf.keras.utils.to_categorical(y_train, 10)\ny_train.shape","2e04586b":"train['label'].head()","7f1a1033":"y_train[0:5, :]","42e98623":"model = tf.keras.models.Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)), \n    Conv2D(32, (3, 3), activation='relu'),\n    MaxPooling2D(2, 2), \n    Conv2D(64, (3, 3), activation='relu', padding='Same'), \n    Conv2D(64, (3, 3), activation='relu', padding='Same'), \n    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)), \n    Dropout(0.25), \n    Conv2D(64, (3, 3), activation='relu', padding='Same'), \n    Conv2D(64, (3, 3), activation='relu', padding='Same'), \n    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n    Dropout(0.25), \n    Flatten(), \n    Dense(256, activation='relu'), \n    Dense(256, activation='relu'), \n    Dropout(0.50), \n    Dense(10, activation='softmax')\n])\nmodel.summary()","4624aaaf":"class Callback(tf.keras.callbacks.Callback):\n    def end_if(self, epoch, logs={}):\n        if (logs.get('accuracy') > 0.999):\n            print('Reached 0.99 accuracy')\n            self.model.stop_training = True\n            \ncallbacks = Callback()","450738d8":"optimizer = tf.keras.optimizers.Adam(\n                    learning_rate=0.0005, \n                    beta_1=0.9, \n                    beta_2=0.999, \n                    epsilon=1e-07, \n                    name='Adam')\n\nmodel.compile(optimizer=optimizer,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(X_train, y_train, batch_size=50, epochs=20, callbacks=[callbacks])","6971f276":"pred = model.predict(X_test)\n\npred = np.argmax(pred, axis=1)\n\npred = pd.Series(pred, name='Label')","47ac7f07":"submission = pd.concat([pd.Series(range(1, 28001), name='ImageID'), pred], axis=1)\nsubmission.to_csv('submission.csv', index=False)\n\nsubmission.head(10)","2ec70d9b":"##### Class to stop fitting when it needs","ba51b7c0":"#### Reshaping Data","e2a6a519":"##### Lets Take a Look at Some Samples from both Datasets","71870d22":"#### Fitting the model","995738f5":"#### One Hot Encoding Target Values","44d05268":"##### Here is the comparison between standart and encoded values","44698058":"#### Label Samples Distribution","8c3e6db2":"### Modeling"}}