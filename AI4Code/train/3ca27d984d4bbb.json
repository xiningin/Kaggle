{"cell_type":{"dda0f398":"code","eaf45302":"code","178fcd2a":"code","cfd1f4ea":"code","59eeb561":"code","088695b6":"code","105bbf81":"code","4bb3186e":"code","63356c88":"code","08f82fd3":"code","03873ac7":"code","97fc2d2a":"code","327b786a":"code","62b2e4e8":"code","513f5c62":"code","5f8bdec2":"code","bbea64d5":"code","6afbc943":"code","f315b6c7":"code","9459824b":"code","a6a6fb1a":"code","c1b6684b":"code","837c92b6":"code","deb4ccd5":"code","c6aada66":"code","2759211e":"code","236f8d77":"code","e231ab9e":"code","d26a2fc8":"code","7b4afedf":"markdown","3438de1d":"markdown","3665ac70":"markdown","92178da5":"markdown","37772b94":"markdown","5f87d6a8":"markdown","3a4f8ce8":"markdown","5744c138":"markdown","bb922b22":"markdown"},"source":{"dda0f398":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport gc\n#pd.options.display.max_colwidth=100\npd.set_option('display.max_colwidth',100)\n# Any results you write to the current directory are saved as output.","eaf45302":"gc.collect()","178fcd2a":"train=pd.read_csv('..\/input\/train.tsv',sep='\\t')\nprint(train.shape)\ntrain.head()","cfd1f4ea":"test=pd.read_csv('..\/input\/test.tsv',sep='\\t')\nprint(test.shape)\ntest.head()","59eeb561":"sub=pd.read_csv('..\/input\/sampleSubmission.csv')\nsub.head()","088695b6":"test['Sentiment']=-999\ntest.head()","105bbf81":"df=pd.concat([train,test],ignore_index=True)\nprint(df.shape)\ndf.tail()","4bb3186e":"del train,test\ngc.collect()","63356c88":"from nltk.tokenize import word_tokenize\nfrom nltk.stem import SnowballStemmer,WordNetLemmatizer\nstemmer=SnowballStemmer('english')\nlemma=WordNetLemmatizer()\nfrom string import punctuation\nimport re\nfrom bs4 import BeautifulSoup","08f82fd3":"def clean_review(review_col):\n    review_corpus=[]\n    for i in range(0,len(review_col)):\n        review=str(review_col[i])\n        review=re.sub('[^a-zA-Z]',' ',review)\n        #review=[stemmer.stem(w) for w in word_tokenize(str(review).lower())]\n        review=[lemma.lemmatize(w) for w in word_tokenize(str(review).lower())]\n        review=' '.join(review)\n        review_corpus.append(review)\n    return review_corpus","03873ac7":"df['clean_review']=clean_review(df.Phrase.values)\ndf.head()\n","97fc2d2a":"df_train=df[df.Sentiment!=-999]\ndf_train.shape","327b786a":"df_test=df[df.Sentiment==-999]\ndf_test.drop('Sentiment',axis=1,inplace=True)\nprint(df_test.shape)\ndf_test.head()","62b2e4e8":"del df\ngc.collect()","513f5c62":"# from sklearn.feature_extraction.text import CountVectorizer\n# cv=CountVectorizer()","5f8bdec2":"# c_train=cv.fit_transform(df_train.clean_review).toarray()\n# print(c_train.shape)\n# c_test=cv.transform(df_test.clean_review).toarray()\n# print(c_test.shape)","bbea64d5":"# bow_df=pd.DataFrame(data=c_train,columns=cv.get_feature_names())\n# bow_df.head()","6afbc943":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf=TfidfVectorizer(ngram_range=(1,2),max_df=0.95,min_df=10,sublinear_tf=True)","f315b6c7":"c2_train=tfidf.fit_transform(df_train.clean_review).toarray()\nprint(c2_train.shape)\nc2_test=tfidf.transform(df_test.clean_review).toarray()\nprint(c2_test.shape)","9459824b":"from sklearn.preprocessing import LabelEncoder,OneHotEncoder","a6a6fb1a":"le=LabelEncoder()\ny=le.fit_transform(df_train.Sentiment.values)\n#y=pd.get_dummies(y).values\ny.shape","c1b6684b":"del df_train,df_test\ngc.collect()","837c92b6":"# from sklearn.model_selection import train_test_split","deb4ccd5":"# X_train,X_val,y_train,y_val=train_test_split(c2_train,y,test_size=0.2)\n# print(X_train.shape,y_train.shape)\n# print(X_val.shape,y_val.shape)","c6aada66":"from sklearn.linear_model import LogisticRegression\nlr=LogisticRegression()","2759211e":"lr.fit(c2_train,y)","236f8d77":"y_pred=lr.predict(c2_test)","e231ab9e":"sub.Sentiment=y_pred\nsub.head()","d26a2fc8":"sub.to_csv('submission.csv',index=False)","7b4afedf":"### Loading dataset and basic visualization","3438de1d":"### Bag of Words model","3665ac70":"**Adding Sentiment column to test datset and joing train and test for preprocessing**","92178da5":"** cleaning review**","37772b94":"### Tfidf","5f87d6a8":"### One hot encoding of target variable","3a4f8ce8":"### splitting data into train and validation set","5744c138":"## 1. Logistic regression","bb922b22":"** seperating train and test dataset**"}}