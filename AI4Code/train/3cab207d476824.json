{"cell_type":{"ccc8b4ad":"code","53d78baa":"code","adce07cb":"code","0a9d61c8":"code","d52176c1":"code","0a01063f":"code","b0e39fa1":"code","389ef5cf":"code","ef8b1a6c":"code","0199de14":"code","d6a11ed2":"code","64dc0d8d":"code","21a83eba":"code","edda21ba":"code","ee784c9b":"code","ae860d38":"code","61ca5eb2":"code","1a3c7b18":"code","90a84ac0":"code","5736428d":"code","4871e4aa":"code","62a37bf4":"code","7e883be6":"code","520a7d55":"code","c12b215b":"markdown","d431f230":"markdown","9c88da8b":"markdown","f9dfabda":"markdown","e95f93c5":"markdown"},"source":{"ccc8b4ad":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","53d78baa":"train_data = pd.read_csv('\/kaggle\/input\/ml2020spring-hw1\/train.csv', encoding='big5')\ntrain_data.info()","adce07cb":"train_data.head(20)","0a9d61c8":"train_data.describe()","d52176c1":"train_data = train_data.drop(['\u6e2c\u7ad9'], axis=1).copy()\ntrain_data.head(20)","0a01063f":"test_data = pd.read_csv('\/kaggle\/input\/ml2020spring-hw1\/test.csv', \n                        encoding='big5', names = ['id', '\u6e2c\u9805', '0', '1', '2', '3', '4', '5', '6', '7', '8'])\ntest_data.info()","b0e39fa1":"test_data.head(20)","389ef5cf":"train_s = train_data[['\u65e5\u671f', '\u6e2c\u9805', '8']].copy()\ntrain_s['\u65e5\u671f'] = pd.to_datetime(train_s['\u65e5\u671f'] + ' ' + '8' +':00:00')\ntrain_s = train_s.pivot(index='\u65e5\u671f', columns='\u6e2c\u9805', values='8')\ntrain_s","ef8b1a6c":"train_data_fixed = pd.DataFrame()\nfor i in range(24):\n    train_data_slice = train_data[['\u65e5\u671f', '\u6e2c\u9805', str(i)]].copy()\n    train_data_slice['\u65e5\u671f'] = pd.to_datetime(train_data_slice['\u65e5\u671f'] + ' ' + str(i) +':00:00')\n    train_data_slice = train_data_slice.pivot(index='\u65e5\u671f', columns='\u6e2c\u9805', values=str(i))\n    train_data_fixed = pd.concat([train_data_fixed, train_data_slice])\n\ntrain_data_fixed","0199de14":"train_data_fixed = train_data_fixed.replace('NR', '0').astype('float64').sort_index().reset_index().drop(['\u65e5\u671f'], axis=1)","d6a11ed2":"data_mean = train_data_fixed.mean().copy()\ndata_std = train_data_fixed.std().copy()\nfor i in range(18):\n    train_data_fixed.iloc[:,[i]] = (train_data_fixed.iloc[:,[i]] - data_mean[i]) \/ data_std[i]\ntrain_data_fixed.describe()","64dc0d8d":"txx = train_data_fixed\n","21a83eba":"tx = train_data_fixed.copy()\ntx.columns = tx.columns + '_0'\nfor i in range(1,10):\n    ty = train_data_fixed.copy()\n    if i == 9:\n        ty = ty[['PM2.5']]\n        # \u7ed3\u679c\u5217\u4e0d\u9700\u8981\u6807\u51c6\u5316\uff0c\u9700\u8981\u653e\u5927\u56de\u53bb\n        ty = ty * data_std['PM2.5'] + data_mean['PM2.5']\n    ty.columns = ty.columns + '_' + str(i)\n    for j in range(i):\n        ty = ty.drop([j])\n    tx = pd.concat([tx, ty.reset_index().drop(['index'], axis=1)], axis=1)\n\nfor i in range(12):\n    for j in range(9):\n        tx = tx.drop([480*(i+1)-9+j])\ntrain_data = tx\ntrain_data","edda21ba":"train_data.describe()","ee784c9b":"train_data_name = train_data.columns.copy()\nfor i in train_data_name:\n    if i == 'PM2.5_9':\n        continue\n    train_data[i + '_*2'] = (train_data[i] ** 2)\n    train_data[i + '_*3'] = (train_data[i] ** 3) \/ 10\ntrain_data","ae860d38":"train_x = train_data.drop(['PM2.5_9'], axis=1)\ntrain_y = train_data[['PM2.5_9']]\nx = np.hstack((train_x.values, np.ones((np.size(train_x.values,0), 1), 'double')))\ny = train_y.values\nprint(np.size(x,0), np.size(x,1))\nprint(np.size(y,0), np.size(y,1))","61ca5eb2":"def get_loss(_x, _y, _theta):\n    return np.sum((_y-_x.dot(_theta))**2)\n\ntheta = np.random.random((np.size(x,1), 1))\nlearning_rate = 41e-9\nregular_param = 1\n\ntrain_X = x[:4239]\ntrain_Y = y[:4239]\nvari_X = x[4239:]\nvari_Y = y[4239:]\n\nx_mix = train_X.T.dot(train_X)\nx_sub = train_X.T.dot(train_Y)\n\ndef get_gradient(_x, _y, _theta):\n    return x_mix.dot(_theta)-x_sub + (regular_param * _theta)\n\nfor i in range(1000001):\n    theta = theta - learning_rate*get_gradient(train_X, train_Y, theta)\n    if i % 20000 == 0:\n        print(i, get_loss(train_X, train_Y, theta) \/ np.size(train_Y,0), get_loss(vari_X, vari_Y, theta) \/ np.size(vari_Y,0))","1a3c7b18":"test_data_id = test_data['id']\ntest_data['id'] = test_data['id'].str.split('_', expand = True)[1].astype('int')","90a84ac0":"test_data_fixed = pd.DataFrame()\nfor i in range(9):\n    test_data_slice = test_data[['id', '\u6e2c\u9805', str(i)]].copy()\n    test_data_slice = test_data_slice.pivot(index='id', columns='\u6e2c\u9805', values=str(i))\n    test_data_slice.columns = test_data_slice.columns + '_' + str(i)\n    for j in range(18):\n        test_data_slice.iloc[:,[j]] = (test_data_slice.iloc[:,[j]].replace('NR', '0').astype('float64') - data_mean[j]) \/ data_std[j]\n    test_data_fixed = pd.concat([test_data_fixed, test_data_slice], axis=1)\n\ntest_data_fixed = test_data_fixed.replace('NR', '0').astype('float64').reset_index().drop(['id'], axis=1)\ntest_data_fixed","5736428d":"test_data_name = test_data_fixed.columns.copy()\nfor i in test_data_name:\n    if i == 'PM2.5_9':\n        continue\n    test_data_fixed[i + '_*2'] = test_data_fixed[i] ** 2\n    test_data_fixed[i + '_*3'] = (test_data_fixed[i] ** 3) \/ 10\ntest_data_fixed","4871e4aa":"test_x = np.hstack((test_data_fixed.values, np.ones((np.size(test_data_fixed.values,0), 1), 'double')))\nprint(np.size(test_x,0), np.size(test_x,1))","62a37bf4":"test_y = test_x.dot(theta)\ntest_y","7e883be6":"submission = pd.DataFrame({\n        \"id\": test_data_id.unique(),\n        \"value\": test_y.T[0]\n    })\nsubmission.to_csv('\/kaggle\/working\/submission.csv', index=False)","520a7d55":"theta","c12b215b":"\u518d\u770b\u4e00\u4e0btest\u6570\u636e","d431f230":"\u9898\u76ee\u8981\u6c42\u4f7f\u7528\u7ebf\u6027\u56de\u5f52\u5e76\u4e14\u7528\u68af\u5ea6\u4e0b\u964d\u903c\u8fd1\uff0c\u6240\u4ee5\u95ee\u9898\u70b9\u96c6\u4e2d\u5728\u6570\u636e\u5904\u7406\u548c\u6a21\u578b\u8c03\u4f18\u4e0a\u3002\n\n\u5148\u770b\u8bad\u7ec3\u6570\u636e\uff1a","9c88da8b":"\u6211\u4eec\u7684\u76ee\u6807\u662f\uff0c\u6839\u636e\u524d9\u5c0f\u65f6\u7684\u6240\u6709\u6570\u636e\uff0c\u9884\u6d4b\u7b2c10\u5c0f\u65f6\u7684PM2.5\u3002\u4e8e\u662f\u9996\u5148\u662f\u5148\u8981\u5904\u7406\u6570\u636e\u683c\u5f0f\u6210\u4e3a\u6bcf\u5c0f\u65f6\u7684\u6570\u636e","f9dfabda":"\u53c2\u8003\u5e73\u5747\u6570\u4e00\u9879\uff0c\u4e4b\u540e\u4e3a\u4e86\u7ebf\u6027\u56de\u5f52\u80fd\u987a\u5229\u8fdb\u884c\uff0c\u9700\u8981\u8fdb\u884c\u6807\u51c6\u5316","e95f93c5":"\u53ef\u4ee5\u770b\u5230\u6d4b\u7ad9\u53ea\u6709\u4e00\u4e2a\uff0c\u53ef\u4ee5\u5c06\u8fd9\u884c\u780d\u6389"}}