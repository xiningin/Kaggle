{"cell_type":{"9f05b473":"code","3fb02265":"code","96fae671":"code","4e8092e3":"code","e86ea278":"code","55c9db60":"code","d89a055a":"code","0cce9683":"code","9a33215f":"code","378c0546":"code","49d0cd57":"code","53af458b":"code","edb4ef65":"code","c5f98b54":"code","70dbb217":"code","7fcf7171":"code","995beda4":"code","13f9e4b0":"code","785701f8":"code","cbf7eee5":"code","01c7ae0b":"code","7914264d":"code","2aa47676":"code","218ee8aa":"code","a8cb1bb5":"code","5e327ba8":"code","da2ff838":"code","353abcb2":"code","b6f5b52b":"code","be034bb9":"code","a48a2d2f":"code","71733101":"markdown","ec2529a7":"markdown","d7443950":"markdown","ecbf708d":"markdown","2a9c4852":"markdown","06a56ccc":"markdown","1c36637f":"markdown","e983d723":"markdown","e5888803":"markdown","4e5ef777":"markdown","a05c4017":"markdown"},"source":{"9f05b473":"!pip install tensorflow==2.3.0 -q","3fb02265":"\nimport os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt\nimport PIL\n","96fae671":"\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:',tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_systems(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\nprint(tf.__version__)","4e8092e3":"#!\/usr\/bin\/python\n\nimport os, sys\n\n# Create new Train and val folders\n\nbase_dir = 'kaggle\/input\/RiceLeafs'\ntrain_path = '\/kaggle\/input\/RiceLeafs\/train'\nval_path = 'kaggle\/input\/RiceLeafs\/validation\/'\n\ncolumn_names = os.listdir(train_path)\nfor i in column_names:\n    os.makedirs(f'..\/kaggle\/output\/train\/{i}')\n    os.makedirs(f'..\/kaggle\/output\/validation\/{i}')\n\nout_path = '..\/kaggle\/output\/train\/'\n\n\n","e86ea278":"from PIL import Image\ndef resize(input_path,folder,column_name):\n    dirs = os.listdir(input_path)\n    for item in dirs:\n        item_path = input_path +'\/' +item\n        if os.path.isfile(item_path):\n            #print('CHECK')\n            im = Image.open(item_path)\n\n            # Check whether the specified \n            # path exists or not \n            outpath = f'\/kaggle\/kaggle\/output\/{folder}\/{column_name}'\n            temp_out_path = outpath+'\/'+item\n            f, e = os.path.splitext(temp_out_path)\n\n            imResize = im.resize((150,150), Image.ANTIALIAS)\n            #print('CHECK 3')\n            imResize.save(f + '.jpg', 'JPEG', quality=90)\n\n\n\n","55c9db60":"input_path = '..\/input\/RiceLeafs\/train\/Healthy'\nfolder = 'train'\ncolumn_name = 'Healthy'\nresize(input_path,folder,column_name)\n\ninput_path = '..\/input\/RiceLeafs\/train\/BrownSpot'\nfolder = 'train'\ncolumn_name = 'BrownSpot'\nresize(input_path,folder,column_name)\n\ninput_path = '..\/input\/RiceLeafs\/train\/Hispa'\nfolder = 'train'\ncolumn_name = 'Hispa'\nresize(input_path,folder,column_name)\n\ninput_path = '..\/input\/RiceLeafs\/train\/LeafBlast'\nfolder = 'train'\ncolumn_name = 'LeafBlast'\nresize(input_path,folder,column_name)\n\nprint('Done with train resizing')","d89a055a":"## VALIDATION\ninput_path = '..\/input\/RiceLeafs\/validation\/Healthy'\nfolder = 'validation'\ncolumn_name = 'Healthy'\nresize(input_path,folder,column_name)\n\ninput_path = '..\/input\/RiceLeafs\/validation\/BrownSpot'\nfolder = 'validation'\ncolumn_name = 'BrownSpot'\nresize(input_path,folder,column_name)\n\ninput_path = '..\/input\/RiceLeafs\/validation\/Hispa'\nfolder = 'validation'\ncolumn_name = 'Hispa'\nresize(input_path,folder,column_name)\n\ninput_path = '..\/input\/RiceLeafs\/validation\/LeafBlast'\nfolder = 'validation'\ncolumn_name = 'LeafBlast'\nresize(input_path,folder,column_name)\n\nprint('Done with Validation resizing')","0cce9683":"os.path.exists('\/kaggle\/kaggle\/output\/validation\/Healthy\/')","9a33215f":"os.path.exists('\/kaggle\/kaggle\/output\/train\/')\nos.path.exists('\/kaggle\/kaggle\/output\/validation\/')\n","378c0546":"os.listdir('\/kaggle\/kaggle\/output\/train\/BrownSpot\/')","49d0cd57":"data_dir = os.path.join(os.path.dirname('\/kaggle\/kaggle\/'), 'output')","53af458b":"# Use this if you avoided the resizing\n#data_dir = os.path.join(os.path.dirname('..\/input\/'), 'riceleafs\/RiceLeafs')","edb4ef65":"train_dir = os.path.join(data_dir, 'train')\ntrain_BrownSpot_dir = os.path.join(train_dir, 'BrownSpot')\ntrain_Healthy_dir = os.path.join(train_dir, 'Healthy')\ntrain_Hispa_dir = os.path.join(train_dir, 'Hispa')\ntrain_LeafBlast_dir = os.path.join(train_dir, 'LeafBlast')\n\n\nvalidation_dir = os.path.join(data_dir, 'validation')\nvalidation_BrownSpot_dir = os.path.join(validation_dir, 'BrownSpot')\nvalidation_Healthy_dir = os.path.join(validation_dir, 'Healthy')\nvalidation_Hispa_dir = os.path.join(validation_dir, 'Hispa')\nvalidation_LeafBlast_dir = os.path.join(validation_dir, 'LeafBlast')","c5f98b54":"train_BrownSpot_names = os.listdir(train_BrownSpot_dir)\nprint(train_BrownSpot_names[:10])\n\ntrain_Healthy_names =  os.listdir(train_Healthy_dir)\nprint(train_Healthy_names[:10])\n\ntrain_Hispa_names = os.listdir(train_Hispa_dir)\nprint(train_Hispa_names[:10])\n\ntrain_LeafBlast_names =  os.listdir(train_LeafBlast_dir)\nprint(train_LeafBlast_names[:10])","70dbb217":"\nimport time\nimport os\nfrom os.path import exists\n\ndef count(dir, counter=0):\n    \"returns number of files in dir and subdirs\"\n    for pack in os.walk(dir):\n        for f in pack[2]:\n            counter += 1\n    return dir + \" : \" + str(counter) + \" files\"\n\nprint('total images for training :', count(train_dir))\nprint('total images for validation :', count(validation_dir))","7fcf7171":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n\n# Parameters for our graph; we'll outpu images in a 4x4 configuration\nnrows = 4\nncols = 4\n\n# for iternating over images\npic_index = 0","995beda4":"# Set up matplotlib fig, and size it to fit 4x4 pics\n\nfig = plt.gcf()\nfig.set_size_inches(ncols *4, nrows*4)\n\npic_index += 4\nnext_BrownSpot_pix = [os.path.join(train_BrownSpot_dir, fname)\n                for fname in train_BrownSpot_names[pic_index-4:pic_index]]\n\nnext_Healthy_pix = [os.path.join(train_Healthy_dir, fname)\n                for fname in train_Healthy_names[pic_index-4:pic_index]]\n\nnext_Hispa_pix = [os.path.join(train_Hispa_dir, fname)\n                for fname in train_Hispa_names[pic_index-4:pic_index]]\n\nnext_LeafBlast_pix = [os.path.join(train_LeafBlast_dir, fname)\n                for fname in train_LeafBlast_names[pic_index-4:pic_index]]\n\nfor i, img_path in enumerate(next_BrownSpot_pix + next_Healthy_pix + next_Hispa_pix + next_LeafBlast_pix):\n  # Set up subplot; subplot indices start at 1\n  sp = plt.subplot(nrows,ncols,i +1)\n  #sp.axis('Off') # Don't show axes (or gridlines)\n\n  img = mpimg.imread(img_path)\n  plt.imshow(img)\n\nplt.show()","13f9e4b0":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nEPOCHS = 100\nIMAGE_SIZE = (150, 150)\nBATCH_SIZE = 32 * strategy.num_replicas_in_sync","785701f8":"print(strategy.num_replicas_in_sync)","cbf7eee5":"from tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# train_ds = ImageDataGenerator(\n# rescale = 1.\/255,\n# width_shift_range= 0.2,\n# height_shift_range = 0.2,\n# shear_range = 0.4,\n# rotation_range = 40,\n# horizontal_flip = True,\n# fill_mode = 'nearest')\n\ntraining_generator = image_dataset_from_directory(\n    train_dir,\n    validation_split = 0.2,\n    subset = 'training',\n    seed = 220,\n    image_size = IMAGE_SIZE,\n    batch_size = BATCH_SIZE,\n    #class_mode = 'categorical'\n)\n\n# validation_ds = ImageDataGenerator(\n#             rescale = 1.\/255)\n\nvalidation_generator = image_dataset_from_directory(\n        validation_dir,\n        validation_split = 0.2,\n        subset = 'validation',\n        seed = 220,\n        batch_size = BATCH_SIZE,\n        image_size = IMAGE_SIZE,\n        )","01c7ae0b":"plt.figure(figsize=(10, 10))\nfor images, labels in training_generator.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(training_generator.class_names[labels[i]])\n    plt.axis(\"off\")","7914264d":"class_names = os.listdir(train_dir)\n\nprint(class_names)\n\ntraining_generator.class_names = class_names\nvalidation_generator.class_names = class_names\n\nNUM_CLASSES = len(class_names)","2aa47676":"def one_hot_label(image, label):\n    label = tf.one_hot(label, NUM_CLASSES)\n    return image, label\n\ntrain_ds = training_generator.map(one_hot_label, num_parallel_calls=AUTOTUNE)\nval_ds = validation_generator.map(one_hot_label, num_parallel_calls=AUTOTUNE)","218ee8aa":"train_ds = train_ds.cache().prefetch(buffer_size = AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size = AUTOTUNE)","a8cb1bb5":"def conv_block(filters):\n    block = tf.keras.Sequential([\n        tf.keras.layers.SeparableConv2D(filters,3,activation = 'relu',padding = 'same'),\n        tf.keras.layers.SeparableConv2D(filters,3,activation = 'relu',padding = 'same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPool2D()\n    ])\n    return block","5e327ba8":"def dense_block(units,dropout_rate):\n    block = tf.keras.Sequential([\n        tf.keras.layers.Dense(units,activation = 'relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(dropout_rate)\n    ])\n    return block","da2ff838":"def build_model():\n    model = tf.keras.Sequential([\n        tf.keras.Input(shape=(*IMAGE_SIZE,3)),\n        tf.keras.layers.Conv2D(16,3,activation = 'relu', padding = 'same'),\n        tf.keras.layers.MaxPool2D(),\n        \n        conv_block(32),\n        conv_block(64),\n        \n        #conv_block(128),\n        tf.keras.layers.Dropout(0.2),\n        \n        conv_block(256),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Flatten(),\n        \n        #dense_block(512,0.7),\n        dense_block(128,0.5),\n        dense_block(64,0.3),\n        \n        tf.keras.layers.Dense(NUM_CLASSES,activation = 'softmax')\n            ])\n    return model\n","353abcb2":"with strategy.scope():\n    model = build_model()\n    \n    METRICS = [tf.keras.metrics.AUC(name='auc')]\n    \n    model.compile(\n    optimizer = 'adam',\n    loss = tf.losses.CategoricalCrossentropy(),\n    metrics = METRICS\n    )","b6f5b52b":"def exponential_decay(lr0,s):\n    def exponential_decay_fn(epoch):\n        return lr0 * 0.1 **(epoch\/s) \n    return exponential_decay_fn\n\n\nexponential_decay_fn = exponential_decay(0.001,20)\n\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n\ncheckpoint_cb = tf.keras.callbacks.ModelCheckpoint('Alzheimer_model.h5',\n                                                  save_best_only = True)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience = 10,\n                                                    restore_best_weights = True)","be034bb9":"history = model.fit(\n    train_ds,\n    validation_data=val_ds,\n    callbacks=[checkpoint_cb, early_stopping_cb, lr_scheduler],\n    epochs=EPOCHS\n)","a48a2d2f":"fig, ax = plt.subplots(1, 2, figsize=(20, 3))\nax = ax.ravel()\n\nfor i, met in enumerate(['auc', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])","71733101":"# Training the Model","ec2529a7":"# Feature Engineering","d7443950":"# Loading Dataset <a name=\"LoadingDataset\"><\/a>","ecbf708d":"#### TensorFlow Hub Dataset\n- [EfficientNet B7](https:\/\/tfhub.dev\/tensorflow\/efficientnet\/b7\/feature-vector\/1)","2a9c4852":"## Viewing Images  <a name=\"ViewingImages\"><\/a>","06a56ccc":"## Image Count <a name=\"ImageCount\"><\/a>","1c36637f":"# Resizing Image  <a name=\"Resize\"><\/a>","e983d723":"# Build the Model","e5888803":"# Data Generators <a name=\"DataAugAndGen\"><\/a>","4e5ef777":"# Training and Validation Split  <a name=\"Split\"><\/a>","a05c4017":"# Importing Libraries <a name=\"ImportingLibraries\"><\/a>"}}