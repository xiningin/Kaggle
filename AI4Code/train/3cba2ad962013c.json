{"cell_type":{"278c9297":"code","ae6ac927":"code","992ec000":"code","77b4b8bb":"code","44cb1692":"code","4bc0da50":"code","2ff210a0":"code","1f4283f0":"code","86b6982d":"code","3f85e308":"code","329885f5":"code","0b1d6945":"code","b4925a38":"code","90e98755":"code","4d29846e":"code","c8f0495d":"code","627490a8":"code","5bc27fab":"code","8df5889d":"code","e35da738":"code","7953f809":"code","351ef2c3":"code","ff288a5a":"code","f724591f":"code","844cb872":"code","58c553ad":"code","0ca47bd9":"markdown","35c694d0":"markdown","1159082d":"markdown","0de6266d":"markdown"},"source":{"278c9297":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))","ae6ac927":"import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport seaborn as sns\n\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image","992ec000":"df = pd.read_csv('..\/input\/bolsonaro_tweets.csv')","77b4b8bb":"df.shape","44cb1692":"df.head()","4bc0da50":"# We will use data only after the day Bolsonaro was elected as the President of Brazil\ndf = df[df['date'] >= '2018-10-28'].copy()","2ff210a0":"df.shape","1f4283f0":"df.head()","86b6982d":"def clean_df(df_clean):\n    remove_names = False # if True, assumes you have a nomes.txt file with common brazilian names in your current dir\n    remove_usernames = False\n    \n    # Copy the original text for later metadata\n    df_clean['original_text'] = df_clean['text']\n\n    # Lower case\n    df_clean['text'] = df_clean['text'].apply(\n        lambda x: \" \".join(x.lower() for x in x.split()))\n\n    # Remove usernames\n    if remove_usernames:\n        df_clean['text'] = df_clean['text'].str.replace(\n            '@[^\\s]+', \"\")\n\n    # Remove links\n    df_clean['text'] = df_clean['text'].str.replace(\n        'https?:\\\/\\\/.*[\\r\\n]*', '')\n\n    # Remove punctuation\n    df_clean['text'] = df_clean['text'].str.replace(\n        '[^\\w\\s]', '')\n\n    # Remove stopwords\n    from nltk.corpus import stopwords\n    stop = stopwords.words('portuguese')\n    df_clean['text'] = df_clean['text'].apply(\n        lambda x: \" \".join(x for x in x.split() if x not in stop))\n\n    # Remove common brazilian names\n    if remove_names:\n        nomes = pd.read_csv('nomes.txt', encoding='latin', header=None)\n        lista_nomes = (nomes[0].str.lower()).tolist()\n        df_clean['text'] = df_clean['text'].apply(lambda x: \" \".join(\n            x for x in x.split() if x not in lista_nomes))\n\n    # Remove numbers\n    df_clean['text'] = df_clean['text'].str.replace(\n        '\\d+', '')\n\n    # Remove words with 1-3 chars\n    df_clean['text'] = df_clean['text'].str.replace(\n        r'\\b(\\w{1,3})\\b', '')\n\n    # Replace accents and \u00e7\n    df_clean.text = df_clean.text.str.normalize('NFKD')\\\n        .str.encode('ascii', errors='ignore')\\\n        .str.decode('utf-8')\n    \n    return df_clean","3f85e308":"df = clean_df(df)\ndf.head()","329885f5":"text = \" \".join(review for review in df.text)\nwordcloud = WordCloud(\n    width=3000,\n    height=2000,\n    background_color='white').generate(text)\nfig = plt.figure(\n    figsize=(40, 30))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","0b1d6945":"cv = CountVectorizer()\ncount_matrix = cv.fit_transform(df['text'])","b4925a38":"word_count = pd.DataFrame(cv.get_feature_names(), columns=[\"word\"])\nword_count[\"count\"] = count_matrix.sum(axis=0).tolist()[0]\nword_count = word_count.sort_values(\"count\", ascending=False).reset_index(drop=True)","90e98755":"freq_series = pd.Series.from_array(word_count['count'][:10])\n\nx_labels = word_count['word'][:10]\n\nplt.figure(figsize=(12, 8))\nax = freq_series.plot(kind='bar')\nax.set_xticklabels(x_labels)\n\nrects = ax.patches\nlabels = word_count['count'][:10]\n\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width() \/ 2, height + 5, label,\n            ha='center', va='bottom')","4d29846e":"df.head()","c8f0495d":"tfidf_vectorizer = TfidfVectorizer()","627490a8":"X = tfidf_vectorizer.fit_transform(df['text'])","5bc27fab":"print(tfidf_vectorizer.get_feature_names()[0:10])","8df5889d":"print(X.shape)","e35da738":"cosine_similarity(X[0:1], X).shape","7953f809":"#fig, ax = plt.subplots(figsize=(20, 20))\n# Drop self-correlations\n#dropSelf = np.zeros_like(cos_sim)\n#dropSelf[np.triu_indices_from(dropSelf)] = True\n# Generate Color Map\n#colormap = sns.diverging_palette(220, 10, as_cmap=True)\n#sns.heatmap(cos_sim,mask=dropSelf,cmap=colormap)","351ef2c3":"def find_similar(tfidf_matrix, index, top_n = 5):\n    cosine_similarities = cosine_similarity(tfidf_matrix[index:index+1], tfidf_matrix).flatten()\n    related_docs_indices = [i for i in cosine_similarities.argsort()[::-1] if i != index]\n    return [(index, cosine_similarities[index]) for index in related_docs_indices][0:top_n]","ff288a5a":"df['text'][100]","f724591f":"for index, score in find_similar(X, 100):\n       print(\"{} - {}\".format(score, df['text'][index]))","844cb872":"df['text'][25]","58c553ad":"for index, score in find_similar(X, 25):\n       print(\"{} - {}\".format(score, df['text'][index]))","0ca47bd9":"# Cleaning the text\n\nLet's do some cleaning on the text before doing word clouds and using the scatter text library for visualization","35c694d0":"## Most common words","1159082d":"We see that some tweets disappeared as they were just emoji. We won't bother cleaning these rows as our libraries won't take them in consideration anyways. A future idea that we could implement is to substitute each emoji by a word that describes it.\n\n# Word clouds\n\nWe're going to use [this](https:\/\/github.com\/amueller\/word_cloud) word cloud library to provide a beautiful visualization. I will keep the background _white_ in the _before_ dataframe and **dark** in the **after** dataframe just to help us visualize.","0de6266d":"# Simple Cosine Similarity Analysis on Jair Bolsonaro tweets"}}