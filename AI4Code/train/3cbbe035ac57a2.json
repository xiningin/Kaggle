{"cell_type":{"ca1ee432":"code","30b5e1f9":"code","93505c3d":"code","1a8660a5":"code","6211fca1":"code","f93fb1ec":"code","aac49685":"code","6e6ea39d":"code","1bad5d54":"code","f8a5a33f":"code","3ac78dd0":"code","ea19de88":"code","a0ca40c0":"code","3a7352d7":"code","bfc5acbe":"code","66c61c04":"code","9e30f881":"code","80f07085":"code","81eceab4":"code","fada692e":"code","6a83f857":"code","b627918c":"code","6ff05d08":"code","ad525147":"code","8e4f794d":"code","f8d75e61":"code","b6080dd8":"code","9cc65f08":"code","43170ac7":"code","e199b702":"code","7624ea27":"code","bed603bc":"code","b3f7e57a":"code","7cac2beb":"code","9c80bdca":"code","fdc362b7":"code","56ef8536":"code","ecaadde6":"code","0f320793":"code","11f89683":"code","cc8bfae5":"code","bdba6c93":"code","7557721a":"code","ba4c5e76":"code","e4f4dffd":"code","e1f58833":"code","e3867631":"code","3cc91c2f":"code","23bae800":"code","7b33e4a5":"code","58af847a":"markdown","5699bfd8":"markdown","61513a28":"markdown","5b6a7369":"markdown","c0ce6beb":"markdown","25b9d48f":"markdown","e9bf558d":"markdown","086a2304":"markdown","bd57aa3b":"markdown","7b4bac55":"markdown","dc5ef466":"markdown","878ecf4c":"markdown","2219bf77":"markdown","08d34029":"markdown","5ba6cd37":"markdown","25398ff7":"markdown","3996a286":"markdown","8d6a6469":"markdown","d39cfcf2":"markdown","9df21d23":"markdown","002d275f":"markdown","f1396611":"markdown","6ba121ec":"markdown","d1e5f282":"markdown","e60da017":"markdown","50858d7a":"markdown","f015c850":"markdown","03aa70a9":"markdown","1d3b3d16":"markdown","8e5f811d":"markdown","d34fff4a":"markdown","12bb9726":"markdown","cb2cea2e":"markdown","47b1c149":"markdown","61ec6331":"markdown","e684d7da":"markdown","484d2cf9":"markdown","e2fd6a2e":"markdown","8a5a12f7":"markdown","65b12c0e":"markdown","bd6af3d9":"markdown","af6b4bce":"markdown","156d5a60":"markdown","4ca77d3a":"markdown","b5b34e9a":"markdown","84fb92a3":"markdown","642e70aa":"markdown","58b20df9":"markdown","44615955":"markdown"},"source":{"ca1ee432":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n        \n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","30b5e1f9":"data = pd.read_csv('\/kaggle\/input\/indian-food-101\/indian_food.csv')","93505c3d":"data.head()","1a8660a5":"data.head()","6211fca1":"data.info()","f93fb1ec":"data.isnull().sum()","aac49685":"data.ingredients[0]","6e6ea39d":"data.ingredients[1]","1bad5d54":"data.ingredients[2]","f8a5a33f":"material_list = []\nfor material_string in data.ingredients:\n    \n    material_string = material_string.lower()\n    materials = material_string.split(\",\")\n    materials = [material.strip() for material in materials]\n    for material in materials:\n        \n        if material not in material_list:\n            material_list.append(material)\n            \n\nprint(\"There are {} unique materials in the dataset\".format(len(material_list)))\n","3ac78dd0":"print(material_list[:20])","ea19de88":"matrix_list = []\n\nfor material in material_list:\n    column = []\n    for ingredient in data.ingredients:\n        \n        ingredient = ingredient.lower().replace(\",\",\" \")\n        \n        \n        if material in ingredient:\n            column.append(1)\n        else:\n            column.append(0)\n            \n    matrix_list.append(column)","a0ca40c0":"material_matrix = np.array(matrix_list)\nprint(\"Shape of material_matrix is {}\".format(material_matrix.shape))","3a7352d7":"print(material_matrix[0])","bfc5acbe":"material_df = pd.DataFrame(material_matrix.T)\nmaterial_df.columns = material_list\nmaterial_df.head()","66c61c04":"data.head()","9e30f881":"import random\ndef random_color(number):\n    color_li = []\n    for i in range(number):\n        R = str(random.randint(0,255))\n        G = str(random.randint(0,255))\n        B = str(random.randint(0,255))\n        A = \"0.7\"\n        STRING = \"rgba({},{},{},{})\".format(R,G,B,A)\n        color_li.append(STRING)\n    return color_li\n    ","80f07085":"random_color(1)","81eceab4":"trace1 = go.Bar(x=data.diet.value_counts().index\n          ,y=data.diet.value_counts().values\n          ,marker=dict(color=random_color(len(data.diet.value_counts())))\n          )\n\nlayout = go.Layout(title=\"Distribution - Diet\",\n                   xaxis=dict(title=\"Diet Type\")\n                  ,yaxis=dict(title=\"Count\"))\n\n\nfigure = go.Figure(data=trace1,layout=layout)\niplot(figure)","fada692e":"trace1 = go.Histogram(x=data.prep_time,\n                      marker=dict(color=\"blue\"),\n                     )\n\nlayout = go.Layout(title=\"Histogram Of Preparation Time\",\n                   xaxis=dict(title=\"Preparation Time\"),\n                   yaxis=dict(title=\"Count\")\n                  )\n\nfigure = go.Figure(data=trace1,layout=layout)\niplot(figure)","6a83f857":"trace1 = go.Histogram(x=data.cook_time,\n                      marker=dict(color=\"green\"),\n                     )\n\nlayout = go.Layout(title=\"Histogram Of Cook Time\",\n                   xaxis=dict(title=\"Cook Time\"),\n                   yaxis=dict(title=\"Count\")\n                  )\n\nfigure = go.Figure(data=trace1,layout=layout)\niplot(figure)","b627918c":"trace1 = go.Bar(x=data.flavor_profile.value_counts().index\n          ,y=data.flavor_profile.value_counts().values\n          ,marker=dict(color=random_color(len(data.flavor_profile.value_counts())))\n          )\n\nlayout = go.Layout(title=\"Distribution - Flavor Profile\",\n                   xaxis=dict(title=\"Flavor Profile\")\n                  ,yaxis=dict(title=\"Count\"))\n\n\nfigure = go.Figure(data=trace1,layout=layout)\niplot(figure)","6ff05d08":"trace1 = go.Bar(x=data.course.value_counts().index\n          ,y=data.course.value_counts().values\n          ,marker=dict(color=random_color(len(data.course.value_counts())))\n          )\n\nlayout = go.Layout(title=\"Distribution - Course\",\n                   xaxis=dict(title=\"Course Type\")\n                  ,yaxis=dict(title=\"Count\"))\n\n\nfigure = go.Figure(data=trace1,layout=layout)\niplot(figure)","ad525147":"trace1 = go.Bar(x=data.state.value_counts().index\n          ,y=data.state.value_counts().values\n          ,marker=dict(color=random_color(len(data.state.value_counts())))\n          )\n\nlayout = go.Layout(title=\"Distribution - State\",\n                   xaxis=dict(title=\"State Name\")\n                  ,yaxis=dict(title=\"Number Of Foods\"))\n\n\nfigure = go.Figure(data=trace1,layout=layout)\niplot(figure)","8e4f794d":"trace1 = go.Bar(x=data.region.value_counts().index\n          ,y=data.region.value_counts().values\n          ,marker=dict(color=random_color(len(data.region.value_counts())))\n          )\n\nlayout = go.Layout(title=\"Distribution - Region\",\n                   xaxis=dict(title=\"Region Name\")\n                  ,yaxis=dict(title=\"Number Of Foods\"))\n\n\nfigure = go.Figure(data=trace1,layout=layout)\niplot(figure)","f8d75e61":"data.corr()","b6080dd8":"data.groupby(\"diet\").mean()","9cc65f08":"veg_foods = data[data.diet==\"vegetarian\"]\nnon_veg_foods = data[data.diet==\"non vegetarian\"]\n\n","43170ac7":"veg_foods.flavor_profile.value_counts()","e199b702":"non_veg_foods.flavor_profile.value_counts()","7624ea27":"veg_foods.course.value_counts()","bed603bc":"non_veg_foods.course.value_counts()","b3f7e57a":"veg_foods.state.value_counts()","7cac2beb":"non_veg_foods.state.value_counts()","9c80bdca":"veg_foods.region.value_counts()","fdc362b7":"non_veg_foods.region.value_counts()","56ef8536":"data.head()","ecaadde6":"data.drop(\"ingredients\",axis=1,inplace=True)\ndata.head()","0f320793":"data.drop(\"name\",axis=1,inplace=True)\ndata.head()","11f89683":"diet_li = []\n\nfor diet in data.diet:\n    \n    if diet == \"vegetarian\":\n        diet_li.append(1)\n    else:\n        diet_li.append(0)\n        \n        \ndata.diet = diet_li","cc8bfae5":"data.head()","bdba6c93":"data = pd.get_dummies(data=data,columns=[\"flavor_profile\",\"course\",\"state\",\"region\"])\ndata.head()","7557721a":"data = pd.concat([data,material_df],axis=1)\ndata.info()","ba4c5e76":"from sklearn.model_selection import train_test_split\nx = data.drop(\"diet\",axis=1)\ny = data.diet\n\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=1)\n\n","e4f4dffd":"print(\"x_train's shape is\",x_train.shape)\nprint(\"x_test's shape is\",x_test.shape)\nprint(\"y_train's shape is\",y_train.shape)\nprint(\"y_test's. shape is \",y_test.shape)","e1f58833":"x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.1,random_state=1)","e3867631":"import warnings as wrn\nfrom sklearn.linear_model import LogisticRegression\n\nwrn.filterwarnings('ignore')\nLR = LogisticRegression()\nLR.fit(x_train,y_train)\nprint(\"Validation score is\",LR.score(x_val,y_val))\n","3cc91c2f":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\ny_pred = LR.predict(x_test)\n\nprint(\"Accuracy score of test: {}\".format(accuracy_score(y_pred,y_test)))","23bae800":"conf_matrix = confusion_matrix(y_pred=y_pred,y_true=y_test)\nsns.heatmap(conf_matrix,annot=True,linewidths=1.5,cmap=\"CMRmap_r\")","7b33e4a5":"conf_matrix","58af847a":"* Now I am going to convert diet feature to 0 and 1. If the food is vegetarian, its diet will be 0 else it will be 1.","5699bfd8":"* 417. Such a number!\n* Let's take a look at the materials","61513a28":"* Most of the foods are main course.\n* Starters are really rare.\n","5b6a7369":"# Distrubution Of Preparation Time\n","c0ce6beb":"* Let's encode flavor_profile,course,state and region.","25b9d48f":"# Detailed Data Analyses\n\n## Correlation Between Preparation Time and Cook Time","e9bf558d":"* There is only one missing value in the dataset. We can fill it easily.","086a2304":"# Data Preprocessing\n\nIn this section I am going to process the dataset. Let's start.","bd57aa3b":"* Vegetarian foods' preparation and cook time is shorter than non vegetarian foods. \n* So we can use this features in machine learning.","7b4bac55":"* First, I will drop the ingredients feature because I will add the ingredients sparse matrix.","dc5ef466":"# Machine Learning\n\nIn this section I am going to classify foods by their diet type. As machine learning model, I will use Logistic Regression.","878ecf4c":"# Importing All The Things\n\nIn this section I am gonna import all the things that I will use in the EDA.","2219bf77":"# Distribution Of State\n","08d34029":"# Data Overview\n\nIn this section I am going to take a look at the data.","5ba6cd37":"* What? There is a flavor profile named -1.\n* Most of the dataset is spicy and sweet.\n* Everyone knows that. In India, people like spicy tastes\n","25398ff7":"* There are 255 foods in this dataset.","3996a286":"2. Now I am going to convert each ingredients string to sparse matrix. ","8d6a6469":"* Validation score is %90. Now let's predict x_test.","d39cfcf2":"* Now I am going to add add our ingredients sparce matrix.","9df21d23":"# Random Color Function\n\nIn this section I am going to define a function that creates random colors. I will use this function when I start the data analyses.","002d275f":"# Simple Data Analyses\n\nIn this section, I am going to examine the distribution of all the features. Let's start with diet.","f1396611":"* Now I am going to convert this matrix to pandas dataframe.","6ba121ec":"# Distribution Of Flavor Profile","d1e5f282":"# Conclusion\n\nThanks for your attention. If you have any question in your mind, please ask me. I will definetely return to you.\n\nHave a good day!","e60da017":"# Distribution of Course","50858d7a":"* Now I am going to split train set to train and validation.","f015c850":"* Our score looks great. Let's take a look at the confusion matrix.","03aa70a9":"## Distribution Of Diet","1d3b3d16":"* Most of the foods' cook time is less than 100\n* There is an interesting food that have cook time 700 minutes. It equals 11.5 hours.","8e5f811d":"# Distribution Of Cook Time\n","d34fff4a":"* We can say that if a food is not vegetarian, its flavor profile must be spicy.\n* But in vegetarian foods, we can't say anything.","12bb9726":"# Introduction\n\nHello people, welcome to this kernel. In this kernel I am going to examine the indian food 101 dataset, I will do some EDA and machine learning. Before starting, let's take a look at the content\n\n# Content\n1. Importing All The Things\n1. Data Overview\n1. Feature Engineering \/ Ingredients\n1. Random Color Function\n1. Simple Data Analyses\n    * Distribution Of Diet\n    * Distribution Of Preparation Time\n    * Distribution Of Cook Time\n    * Distribution Of Flavor Profile\n    * Distribution of Course\n    * Distribution Of State\n    * Distribution Of Region\n1. Detailed Data Analyses\n    * Correlation Between Preparation Time and Cook Time\n    * Detailed Analyses: Diet\n1. Data Preprocessing\n1. Machine Learning\n1. Conclusion","cb2cea2e":"* Most of the indian cousine came from West and South.","47b1c149":"* let's take a look at the matrix","61ec6331":"* Most of the foods are vegetarian.","e684d7da":"# Feature Engineering \/ Ingredients\n\nIn this section I am going to handle the ingredients feature, before starting let's take a look at that.","484d2cf9":"* For this moment, I am not going to add this dataset, into our dataset. But we will use this.","e2fd6a2e":"* Most of the non vegetarian foods are main course.\n* There is no non vegetarian dessert or snack, all of them are vegetarian.\n* There is no vegetarian starter.\n* We can use this feature in machine learning.\n","8a5a12f7":"* We can say that, correlation between preparation time and cook time is not high enough to be significant.","65b12c0e":"1. First, I will determine all unique materials.","bd6af3d9":"* There are 9 features in the dataset. \n* 7 of them are object and 2 of them are numerical\n","af6b4bce":"* Again -1. I guess data collector named missing values as -1.\n* Gujarat,Punjab,Maharashtra are good places to try something new.","156d5a60":"* Just as we expected, model predicted vegetarian foods great, but when the food was non vegetarian, model was confused. \n* It happened because of unbalanced data. If we have more non-vegetarian food, our model would have predicted better.","4ca77d3a":"# Distribution Of Region","b5b34e9a":"* As we can see, materials seperated with seperator. So we can easily split them.","84fb92a3":"* Now I am going to split the data to train and test.","642e70aa":"* Although most of the foods' preparation time is less than 100 minutes, there are the foods that have preparation time higher than 200.","58b20df9":"* Name is unrelevant. We can drop it.","44615955":"# Detailed Analyses: Diet"}}