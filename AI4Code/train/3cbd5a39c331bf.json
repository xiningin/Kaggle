{"cell_type":{"461a9590":"code","e2d0ddb6":"code","8ed86483":"code","63b54733":"code","28781ab2":"code","7237284b":"code","fb2d804e":"code","b9289bc7":"code","4d3b34b4":"code","3531e274":"code","aab45da2":"code","7fe64f70":"code","fa6683ba":"code","a250b2ca":"code","51646b24":"code","63f805a4":"code","52a4f9d4":"code","47daec4b":"code","9e04f995":"code","738a3dce":"code","8f524e90":"code","8058933a":"code","8ec38340":"code","6aec4bd7":"code","f3a08884":"code","6e5428fe":"code","9a767061":"code","89ff7fac":"code","8efac234":"code","c8061e5d":"code","2bec3bd7":"code","17c626aa":"code","728bd66d":"code","6bb77d83":"code","5d8fe743":"code","1ec05be2":"markdown","6aa79272":"markdown","26953593":"markdown","ac9f8fd0":"markdown","25c96695":"markdown","fcd293fe":"markdown","7ca8b83a":"markdown","ef88f776":"markdown","a2d1b283":"markdown","daa10724":"markdown","d942106a":"markdown","2aca7ca7":"markdown"},"source":{"461a9590":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e2d0ddb6":"#import data\n# a mock sample submission file in the correct format\nexample_sample_submission = pd.read_csv('\/kaggle\/input\/jane-street-market-prediction\/example_sample_submission.csv')\n#metadata pertaining to the anonymized features\nfeatures= pd.read_csv('\/kaggle\/input\/jane-street-market-prediction\/features.csv')\n# a mock test set which represents the structure of the unseen test set. You will not be directly using the test set or sample submission in this competition, as the time-series API will get\/set the test set and predictions.\nexample_test= pd.read_csv('\/kaggle\/input\/jane-street-market-prediction\/example_test.csv')\n# the training set, contains historical data and returns\ntrain= pd.read_csv('\/kaggle\/input\/jane-street-market-prediction\/train.csv')\n","8ed86483":"train.info()","63b54733":"#resp_{1,2,3,4} values that represent returns over different time horizons\n#Trades with weight = 0 were intentionally included in the dataset for completeness, although such trades will not contribute towards the scoring evaluation.\ntrain.head()","28781ab2":"def histo(col):\n    title1 = np.round(train[col].mean(),2)\n    title2 = np.round(train[col].skew(),2)\n    title3 = np.round(train[col].kurtosis(),2)\n    plt.style.use('ggplot')\n    plt.hist(train[col], bins = 100)\n    plt.title(col + ' Avg ' + np.str(title1) + ' Skew ' + np.str(title2) + ' Kurt ' + np.str(title3))\n    plt.show()","7237284b":"histo('resp')","fb2d804e":"histo('resp_1')","b9289bc7":"histo('resp_2')","4d3b34b4":"histo('resp_3')","3531e274":"histo('resp_4')","aab45da2":"histo('weight')","7fe64f70":"train['weight_resp'] = train['weight'] * train['resp'] ","fa6683ba":"histo('weight_resp')","a250b2ca":"sns.jointplot(x=\"weight\", y=\"resp\", data=train, height=10, ratio=3, color=\"r\")\nplt.show()","51646b24":"sns.jointplot(x=\"weight\", y=\"resp_1\", data=train, height=10, ratio=3, color=\"r\")\nplt.show()","63f805a4":"sns.jointplot(x=\"weight\", y=\"resp_2\", data=train, height=10, ratio=3, color=\"r\")\nplt.show()","52a4f9d4":"sns.jointplot(x=\"weight\", y=\"resp_3\", data=train, height=10, ratio=3, color=\"r\")\nplt.show()","47daec4b":"sns.jointplot(x=\"weight\", y=\"resp_4\", data=train, height=10, ratio=3, color=\"r\")\nplt.show()","9e04f995":"\n\nfig, ax = plt.subplots(figsize=(15, 5))\nv1= pd.Series(train['weight_resp']).cumsum()\nv2= pd.Series(train['resp']).cumsum()\n# v3= pd.Series(train['weight'])\nax.set_xlabel (\"Trade\", fontsize=18)\nax.set_ylabel (\"Cumulative\", fontsize=18)\nv1.plot(lw=3)\nv2.plot(lw=3)\n# v3.plot(lw=3)\nax.legend(('weight_resp','resp','weight'))\n\n\n","738a3dce":"fig, ax = plt.subplots(figsize=(15, 5))\nbalance= pd.Series(train['resp']).cumsum()\nresp_1= pd.Series(train['resp_1']).cumsum()\nresp_2= pd.Series(train['resp_2']).cumsum()\nresp_3= pd.Series(train['resp_3']).cumsum()\nresp_4= pd.Series(train['resp_4']).cumsum()\nax.set_xlabel (\"Trade\", fontsize=18)\nax.set_title (\"Cumulative resp and time horizons 1, 2, 3, and 4 (500 days)\", fontsize=18)\nbalance.plot(lw=3)\nresp_1.plot(lw=3)\nresp_2.plot(lw=3)\nresp_3.plot(lw=3)\nresp_4.plot(lw=3)\nplt.legend(loc=\"upper left\");\ndel resp_1\ndel resp_2\ndel resp_3\ndel resp_4\n","8f524e90":"#Correlation between responses\nf,ax = plt.subplots(figsize=(15, 15))\nsns.heatmap(train[['resp_1','resp_2','resp_3','resp_4']].corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.show()","8058933a":"sns.jointplot(x=\"resp_1\", y=\"resp_4\", data=train, height=10, ratio=3, color=\"r\")\nplt.show()","8ec38340":"train_features = ([col for col in train.columns if 'feature' in col])\ntrain_response = ([col for col in train.columns if 'resp' in col])\ntrain_heatmap = train_response + train_features","6aec4bd7":"train_heatmap","f3a08884":"#Correlation between features and weight_resp\nfig, ax = plt.subplots(figsize=(12,12))\nsns.heatmap(train[train_heatmap].corr()[['weight_resp']].sort_values('weight_resp').tail(20),\n vmax=1, vmin=-1, cmap='YlGnBu', annot=True, ax=ax);\nax.invert_yaxis()","6e5428fe":"# fig, ax = plt.subplots(figsize=(12,12))\n# sns.heatmap(train[train_heatmap].corr()[['weight']].sort_values('weight').tail(20),\n#  vmax=1, vmin=-1, cmap='YlGnBu', annot=True, ax=ax);\n# ax.invert_yaxis()","9a767061":"fig, ax = plt.subplots(figsize=(12,12))\nsns.heatmap(train[train_heatmap].corr()[['resp']].sort_values('resp').tail(20),\n vmax=1, vmin=-1, cmap='YlGnBu', annot=True, ax=ax);\nax.invert_yaxis()","89ff7fac":"# fig, ax = plt.subplots(figsize=(12,12))\n# sns.heatmap(train[train_heatmap].corr()[['resp_1']].sort_values('resp_1').tail(20),\n#  vmax=1, vmin=-1, cmap='YlGnBu', annot=True, ax=ax);\n# ax.invert_yaxis()","8efac234":"# fig, ax = plt.subplots(figsize=(12,12))\n# sns.heatmap(train[train_heatmap].corr()[['resp_2']].sort_values('resp_2').tail(20),\n#  vmax=1, vmin=-1, cmap='YlGnBu', annot=True, ax=ax);\n# ax.invert_yaxis()","c8061e5d":"# fig, ax = plt.subplots(figsize=(12,12))\n# sns.heatmap(train[train_heatmap].corr()[['resp_3']].sort_values('resp_3').tail(20),\n#  vmax=1, vmin=-1, cmap='YlGnBu', annot=True, ax=ax);\n# ax.invert_yaxis()","2bec3bd7":"# fig, ax = plt.subplots(figsize=(12,12))\n# sns.heatmap(train[train_heatmap].corr()[['resp_4']].sort_values('resp_4').tail(20),\n#  vmax=1, vmin=-1, cmap='YlGnBu', annot=True, ax=ax);\n# ax.invert_yaxis()","17c626aa":"data = train.copy()\ndata = data[data['resp_1'] < data['resp_1'].quantile(0.99)]\ndata = data[data['resp_1'] < data['resp_1'].quantile(0.99)]\n\nf,ax1 = plt.subplots(figsize =(20,10))\nsns.pointplot(x='heals',y='winPlacePerc',data=data,color='lime',alpha=0.8)\nsns.pointplot(x='boosts',y='winPlacePerc',data=data,color='blue',alpha=0.8)\nplt.text(4,0.6,'Heals',color='lime',fontsize = 17,style = 'italic')\nplt.text(4,0.55,'Boosts',color='blue',fontsize = 17,style = 'italic')\nplt.xlabel('Number of heal\/boost items',fontsize = 15,color='blue')\nplt.ylabel('Win Percentage',fontsize = 15,color='blue')\nplt.title('Heals vs Boosts',fontsize = 20,color='blue')\nplt.grid()\nplt.show()","728bd66d":"example_sample_submission.head()","6bb77d83":"features.head()","5d8fe743":"example_test.head()","1ec05be2":"Each trade has an associated weight and resp, which together represents a return on the trade. Trades with weight = 0 were intentionally included in the dataset for completeness, although such trades will not contribute towards the scoring evaluation.","6aa79272":"What is weight? We know that weight * resp gives us the return. How weight is actually derived is not disclosed but perhaps I will think of it as an existing model or algorithm, and this task is to optimise decisions using this information. I base this on the below charts, the weight is high when the variance of resp is low, i.e. could it be when the model has more confidence in taking a small but more certain gain, it will assign a higher weight and vice versa.","26953593":"### Understanding Resp\n","ac9f8fd0":"...developing good models will be challenging for many reasons, including a very low signal-to-noise ratio, potential redundancy, strong feature correlation...","25c96695":"### Understanding features","fcd293fe":"This competition is evaluated on a utility score. Each row in the test set represents a trading opportunity for which you will be predicting an action value, 1 to make the trade and 0 to pass on it. Each trade j has an associated weight and resp, which represents a return.\n\nFor each date i, we define:\n\n<math xmlns=\"http:\/\/www.w3.org\/1998\/Math\/MathML\" display=\"block\">\n  <msub>\n    <mi>p<\/mi>\n    <mi>i<\/mi>\n  <\/msub>\n  <mo>=<\/mo>\n  <munder>\n    <mo>&#x2211;<!-- \u2211 --><\/mo>\n    <mi>j<\/mi>\n  <\/munder>\n  <mo stretchy=\"false\">(<\/mo>\n  <mi>w<\/mi>\n  <mi>e<\/mi>\n  <mi>i<\/mi>\n  <mi>g<\/mi>\n  <mi>h<\/mi>\n  <msub>\n    <mi>t<\/mi>\n    <mrow class=\"MJX-TeXAtom-ORD\">\n      <mi>i<\/mi>\n      <mi>j<\/mi>\n    <\/mrow>\n  <\/msub>\n  <mo>&#x2217;<!-- \u2217 --><\/mo>\n  <mi>r<\/mi>\n  <mi>e<\/mi>\n  <mi>s<\/mi>\n  <msub>\n    <mi>p<\/mi>\n    <mrow class=\"MJX-TeXAtom-ORD\">\n      <mi>i<\/mi>\n      <mi>j<\/mi>\n    <\/mrow>\n  <\/msub>\n  <mo>&#x2217;<!-- \u2217 --><\/mo>\n  <mi>a<\/mi>\n  <mi>c<\/mi>\n  <mi>t<\/mi>\n  <mi>i<\/mi>\n  <mi>o<\/mi>\n  <msub>\n    <mi>n<\/mi>\n    <mrow class=\"MJX-TeXAtom-ORD\">\n      <mi>i<\/mi>\n      <mi>j<\/mi>\n    <\/mrow>\n  <\/msub>\n  <mo stretchy=\"false\">)<\/mo>\n  <mo>,<\/mo>\n<\/math>\n<br>\n<math xmlns=\"http:\/\/www.w3.org\/1998\/Math\/MathML\" display=\"block\">\n  <mi>t<\/mi>\n  <mo>=<\/mo>\n  <mfrac>\n    <mrow>\n      <mo>&#x2211;<!-- \u2211 --><\/mo>\n      <msub>\n        <mi>p<\/mi>\n        <mi>i<\/mi>\n      <\/msub>\n    <\/mrow>\n    <msqrt>\n      <mo>&#x2211;<!-- \u2211 --><\/mo>\n      <msubsup>\n        <mi>p<\/mi>\n        <mi>i<\/mi>\n        <mn>2<\/mn>\n      <\/msubsup>\n    <\/msqrt>\n  <\/mfrac>\n  <mo>&#x2217;<!-- \u2217 --><\/mo>\n  <msqrt>\n    <mfrac>\n      <mn>250<\/mn>\n      <mrow>\n        <mrow class=\"MJX-TeXAtom-ORD\">\n          <mo stretchy=\"false\">|<\/mo>\n        <\/mrow>\n        <mi>i<\/mi>\n        <mrow class=\"MJX-TeXAtom-ORD\">\n          <mo stretchy=\"false\">|<\/mo>\n        <\/mrow>\n      <\/mrow>\n    <\/mfrac>\n  <\/msqrt>\n  <mo>,<\/mo>\n<\/math>\n\nwhere |i| is the number of unique dates in the test set. The utility is then defined as:\n<br>\n<math xmlns=\"http:\/\/www.w3.org\/1998\/Math\/MathML\" display=\"block\">\n  <mi>u<\/mi>\n  <mo>=<\/mo>\n  <mi>m<\/mi>\n  <mi>i<\/mi>\n  <mi>n<\/mi>\n  <mo stretchy=\"false\">(<\/mo>\n  <mi>m<\/mi>\n  <mi>a<\/mi>\n  <mi>x<\/mi>\n  <mo stretchy=\"false\">(<\/mo>\n  <mi>t<\/mi>\n  <mo>,<\/mo>\n  <mn>0<\/mn>\n  <mo stretchy=\"false\">)<\/mo>\n  <mo>,<\/mo>\n  <mn>6<\/mn>\n  <mo stretchy=\"false\">)<\/mo>\n  <mo>&#x2211;<!-- \u2211 --><\/mo>\n  <msub>\n    <mi>p<\/mi>\n    <mi>i<\/mi>\n  <\/msub>\n  <mo>.<\/mo>\n<\/math>","7ca8b83a":"Any small sudden movements in resp appear to be magnified by the weight as seen in the weight_resp.","ef88f776":"... you are provided a resp value, as well as several other resp_{1,2,3,4} values that represent returns over different time horizons. <i><b>These variables are not included in the test set.<\/i><\/b> Trades with weight = 0 were intentionally included in the dataset for completeness, although such trades will not contribute towards the scoring evaluation.","a2d1b283":"### Jane Street Market Prediction | EDA","daa10724":"When the weight is high the variance of resp is low, more confident in taking small gains at risk of making small losses.","d942106a":"### Understanding Weight vs Resp","2aca7ca7":"Jane Street Market Prediction <br>\nTest your model against future real market data"}}