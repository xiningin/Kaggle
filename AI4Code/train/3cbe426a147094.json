{"cell_type":{"4d6f3207":"code","dce8c059":"code","fd7dbd35":"code","9e083650":"code","d8b47e94":"code","f9b5d925":"code","2589159a":"code","d64c8f95":"code","d64c27d6":"code","bc6e19ab":"code","3b2bceff":"code","d89a49ba":"code","305f283f":"code","5d47be54":"code","2906da71":"code","d0be95e4":"code","6ccab672":"code","0a69066b":"code","0fa54b63":"code","abef2ff6":"code","5bd39d24":"code","4733d6e5":"code","884d00a7":"code","2445773f":"code","d4b3a122":"code","e2cc73a9":"code","bcd4e323":"code","e6b8a6af":"code","942fd51f":"code","68a54e0e":"code","c1c14a7b":"code","2e495b59":"code","9c09fbf6":"code","92e51f9a":"code","54282a08":"code","30c32d4c":"code","c030ee68":"code","286c2ffb":"code","047f96e4":"markdown","ae7c456a":"markdown","d73e2e2a":"markdown","65b1de16":"markdown","e48b6c63":"markdown","0bc43087":"markdown","e8cdd3e2":"markdown","8dd463c3":"markdown","d1aa961c":"markdown","9336f86e":"markdown"},"source":{"4d6f3207":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom random import sample \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dce8c059":"metadata = pd.read_csv(\"\/kaggle\/input\/the-movies-dataset\/movies_metadata.csv\", low_memory = False, nrows = 25000)\nmetadata = metadata.drop([19730]) # Remove rows with bad ID\nmetadata.sample(3)","fd7dbd35":"metadata.shape","9e083650":"# Calculate mean of vote average column\nC = metadata['vote_average'].mean()\nprint(C)","d8b47e94":"# Calculate the minimum number of votes required to be in the chart, m\nm = metadata['vote_count'].quantile(0.90)\nprint(m)","f9b5d925":"q_movies = metadata.copy().loc[metadata['vote_count'] >= m]\nq_movies.shape","2589159a":"# Function that computes the weighted rating of each movie\ndef weighted_rating(x, m = m, C = C):\n    v = x['vote_count']\n    R = x['vote_average']\n    \n    # Calculation based on the IMDB formula\n    return (v\/(v+m) * R) + (m\/(m+v) * C)","d64c8f95":"# Define a new feature 'score' and calculate its value with `weighted_rating()`\nq_movies['score'] = q_movies.apply(weighted_rating, axis = 1)","d64c27d6":"#Sort movies based on score calculated above\nq_movies = q_movies.sort_values('score', ascending = False)\n\n#Print the top 15 movies\nq_movies[['title', 'vote_count', 'vote_average', 'score']].head(20)","bc6e19ab":"import plotly.express as px\ndata = q_movies[['title', 'vote_count', 'vote_average', 'score']].head(10)\n\nfig = px.bar(data, x = 'title', y = 'score',\n             hover_data = ['vote_count', 'vote_average'], color='score',\n             labels = {'score':'IMDB Score', 'title': 'Movie Name'}, height = 400,\n             title = 'Movie rating disturbition')\nfig.show()","3b2bceff":"#Print plot overviews of the first 5 movies.\nmetadata['overview'].head()","d89a49ba":"#Import TfIdfVectorizer from scikit-learn\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\ntfidf = TfidfVectorizer(stop_words = 'english')\n\n#Replace NaN with an empty string\nmetadata['overview'] = metadata['overview'].fillna('')\n\n#Construct the required TF-IDF matrix by fitting and transforming the data\ntfidf_matrix = tfidf.fit_transform(metadata['overview'])\n\n#Output the shape of tfidf_matrix\ntfidf_matrix.shape","305f283f":"sample(tfidf.get_feature_names(), 10)","5d47be54":"# Import linear_kernel\nfrom sklearn.metrics.pairwise import linear_kernel\n\n# Compute the cosine similarity matrix\ncosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\ncosine_sim.shape","2906da71":"cosine_sim[1]","d0be95e4":"#Construct a reverse map of indices and movie titles\nindices = pd.Series(metadata.index, index = metadata['title']).drop_duplicates()\nindices[:10]","6ccab672":"# Function that takes in movie title as input and outputs most similar movies\ndef get_recommendations(title, cosine_sim = cosine_sim):\n    # Get the index of the movie that matches the title\n    idx = indices[title]\n\n    # Get the pairwsie similarity scores of all movies with that movie\n    sim_scores = list(enumerate(cosine_sim[idx]))\n\n    # Sort the movies based on the similarity scores\n    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse=True)\n\n    # Get the scores of the 10 most similar movies\n    sim_scores = sim_scores[1:11]\n\n    # Get the movie indices\n    movie_indices = [i[0] for i in sim_scores]\n\n    # Return the top 10 most similar movies\n    return metadata['title'].iloc[movie_indices]","0a69066b":"metadata['title'][:5]","0fa54b63":"get_recommendations('Batman Forever')","abef2ff6":"get_recommendations('Toy Story')","5bd39d24":"# Load keywords and credits\ncredits = pd.read_csv('\/kaggle\/input\/the-movies-dataset\/credits.csv', nrows = 25000)\nkeywords = pd.read_csv('\/kaggle\/input\/the-movies-dataset\/keywords.csv', nrows = 25000)","4733d6e5":"# Convert IDs to int. Required for merging\nkeywords['id'] = keywords['id'].astype('int')\ncredits['id'] = credits['id'].astype('int')\nmetadata['id'] = metadata['id'].astype('int')\n\n# Merge keywords and credits into your main metadata dataframe\nmetadata = metadata.merge(credits, on = 'id')\nmetadata = metadata.merge(keywords, on = 'id')","884d00a7":"# Print the first two movies of your newly merged metadata\nmetadata.head(2)","2445773f":"metadata.shape","d4b3a122":"# Parse the stringified features into their corresponding python objects\nfrom ast import literal_eval\n\nfeatures = ['cast', 'crew', 'keywords', 'genres']\nfor feature in features:\n    metadata[feature] = metadata[feature].apply(literal_eval)","e2cc73a9":"def get_director(x):\n    for i in x:\n        if i['job'] == 'Director':\n            return i['name']\n    return np.nan","bcd4e323":"def get_list(x):\n    if isinstance(x, list):\n        names = [i['name'] for i in x]\n        #Check if more than 3 elements exist. If yes, return only first three. If no, return entire list.\n        if len(names) > 3:\n            names = names[:3]\n        return names\n\n    #Return empty list in case of missing\/malformed data\n    return []","e6b8a6af":"# Define new director, cast, genres and keywords features that are in a suitable form.\nmetadata['director'] = metadata['crew'].apply(get_director)\n\nfeatures = ['cast', 'keywords', 'genres']\nfor feature in features:\n    metadata[feature] = metadata[feature].apply(get_list)","942fd51f":"# Print the new features of the first 3 films\nmetadata[['title', 'cast', 'director', 'keywords', 'genres']].head(3)","68a54e0e":"# Function to convert all strings to lower case and strip names of spaces\ndef clean_data(x):\n    if isinstance(x, list):\n        return [str.lower(i.replace(\" \", \"\")) for i in x]\n    else:\n        #Check if director exists. If not, return empty string\n        if isinstance(x, str):\n            return str.lower(x.replace(\" \", \"\"))\n        else:\n            return ''","c1c14a7b":"# Apply clean_data function to your features.\nfeatures = ['cast', 'keywords', 'director', 'genres']\n\nfor feature in features:\n    metadata[feature] = metadata[feature].apply(clean_data)","2e495b59":"def create_soup(x):\n    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])","9c09fbf6":"# Create a new soup feature\nmetadata['soup'] = metadata.apply(create_soup, axis=1)\nmetadata[['soup']].head(5)","92e51f9a":"# Import CountVectorizer and create the count matrix\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ncount = CountVectorizer(stop_words='english')\ncount_matrix = count.fit_transform(metadata['soup'])\ncount_matrix.shape","54282a08":"# Compute the Cosine Similarity matrix based on the count_matrix\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ncosine_sim2 = cosine_similarity(count_matrix, count_matrix)","30c32d4c":"# Reset index of your main DataFrame and construct reverse mapping as before\nmetadata = metadata.reset_index()\nindices = pd.Series(metadata.index, index=metadata['title'])","c030ee68":"get_recommendations('The Dark Knight Rises', cosine_sim2)","286c2ffb":"get_recommendations('Toy Story', cosine_sim2)","047f96e4":"## Content-Based Recommender","ae7c456a":"### Since we are trying to build a clone of IMDB's Top 250, let's use its weighted rating formula as a metric\/score. Mathematically, it is represented as follows:\n\n### WeightedRating(WR) = (v\/(v+m) * R) + (m\/(m+v) * C)\n\nIn the above equation,\n\n* v is the number of votes for the movie\n\n* m is the minimum votes required to be listed in the chart\n\n* R is the average rating of the movie\n\n* C is the mean vote across the whole report\n\n#### Let's define a new feature score, of which you'll calculate the value by applying this function to your DataFrame of qualified movies:","d73e2e2a":"#### These are some of the similar movies recommended by the engine","65b1de16":"### Now, let's use the cosine_similarity to measure the distance between the embeddings","e48b6c63":"### Next, let's calculate the number of votes, m, received by a movie in the 90th percentile. The pandas library makes this task extremely trivial using the .quantile() method of pandas:","0bc43087":"## Credits, Genres, and Keywords Based Recommender","e8cdd3e2":"### You can now reuse your get_recommendations() function by passing in the new cosine_sim2 matrix as your second argument.","8dd463c3":"### Fortunately, scikit-learn gives you a built-in TfIdfVectorizer class that produces the TF-IDF matrix in a couple of lines.\n\n* Import the Tfidf module using scikit-learn\n* Remove stop words like 'the', 'an', etc. since they do not give any useful information about the topic\n* Replace not-a-number values with a blank string\n* Finally, construct the TF-IDF matrix on the data","d1aa961c":"### As a first step, let's calculate the value of C, the mean rating across all movies using the pandas .mean() function:","9336f86e":"### Finally, let's sort the DataFrame in descending order based on the score feature column and output the title, vote count, vote average, and weighted rating (score) of the top 20 movies."}}