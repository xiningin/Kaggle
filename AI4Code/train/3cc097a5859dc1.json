{"cell_type":{"c3f78584":"code","bff0c26f":"code","aea43ef2":"code","b1d9050b":"code","c8b46344":"code","e90c7d29":"code","26628da9":"code","3f146111":"code","f1d53640":"code","dd4d3126":"code","054371c7":"code","0eb7d909":"code","83f6c9ff":"code","23fc0307":"code","f4ccfe99":"code","1fbb7919":"code","b71f7771":"code","ed603ded":"code","9995e668":"code","03cc60b5":"code","4a6468c3":"code","16de42df":"code","bc2086a2":"code","19ae022d":"code","6e2b19cd":"code","b2708ebd":"code","ad152266":"code","3e56eeb2":"code","96bccd09":"code","84f3de8a":"code","a8585ce9":"code","325c1dc6":"code","d2e6e11a":"code","c48956a1":"code","57101ba6":"code","8f36d338":"code","32125379":"code","1614994b":"code","84835b40":"code","16f037b5":"code","8d51d7e7":"code","c74efeed":"code","30384c4a":"code","8a0c8f21":"code","8ab2fe82":"markdown","742b28f1":"markdown","95e6bdb2":"markdown","96c68891":"markdown","538b215e":"markdown","a89fad4e":"markdown","5f847f79":"markdown","5f60ad66":"markdown","f3e17ffa":"markdown","34bf5231":"markdown","40ebf935":"markdown","378c5f84":"markdown","d6b8026d":"markdown","b5e117c6":"markdown","da0f43fd":"markdown","84271c47":"markdown","e7e21f8d":"markdown","5aa4f607":"markdown","dd5cfc93":"markdown","9a184d77":"markdown"},"source":{"c3f78584":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import SelectPercentile\nfrom sklearn.feature_selection import chi2 , f_classif \nfrom sklearn.model_selection import train_test_split\n","bff0c26f":"df = pd.read_csv('..\/input\/weather-dataset-rattle-package\/weatherAUS.csv')","aea43ef2":"df.columns.values","b1d9050b":"df.head()","c8b46344":"df.describe()","e90c7d29":"df.info()","26628da9":"df[\"RainTomorrow\"].isnull().sum()","3f146111":"df[\"RainTomorrow\"].value_counts()","f1d53640":"df.dropna(subset=['RainTomorrow'], inplace=True)","dd4d3126":"df[\"RainTomorrow\"].isnull().sum()","054371c7":"df['Date']=pd.to_datetime(df['Date'],format='%Y-%m-%d')\n","0eb7d909":"df['Year']=df['Date'].dt.year\ndf['Month']=df['Date'].dt.month\ndf['day']=df['Date'].dt.day\n","83f6c9ff":"df.drop('Date', axis = 1, inplace = True)\n","23fc0307":"df.head()","f4ccfe99":"msno.bar(df)","1fbb7919":"total = df.isnull().sum().sort_values(ascending=False)\npercent = (df.isnull().sum() \/ df.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n","b71f7771":"\nList = list(missing_data[missing_data['Percent'] > 0.10].index)\ndf.drop(List, axis=1, inplace=True)","ed603ded":"df.shape","9995e668":"\ndf.head(5)","03cc60b5":"df_object = df.select_dtypes(include=\"O\")\ndf_number = df.select_dtypes(exclude=\"O\")\n","4a6468c3":"df_object.isnull().sum().sort_values(ascending=False)","16de42df":"for col in df_object.columns:\n    mode = df_object[col].mode()[0]\n    df_object[col].fillna(mode, inplace = True)","bc2086a2":"df_object.isnull().sum().sort_values(ascending=False)","19ae022d":"df_number.isnull().sum().sort_values(ascending=False)","6e2b19cd":"for col in df_number.columns:\n    mean = df_number[col].mean()\n    df_number[col].fillna(mean, inplace = True)","b2708ebd":"df_number.isnull().sum().sort_values(ascending=False)","ad152266":"df.head(5)","3e56eeb2":"df_object","96bccd09":"from sklearn.preprocessing import LabelEncoder\nlabel = LabelEncoder()\ndf_object = df_object.astype(str).apply(label.fit_transform)\ndf_object","84f3de8a":"data = pd.concat([df_object, df_number], axis = 1)\n","a8585ce9":"data.head(5)","325c1dc6":"df.columns","d2e6e11a":"\ncols = ['MinTemp', 'MaxTemp', 'Temp9am', 'Temp3pm', 'WindGustSpeed', 'WindSpeed3pm', 'Pressure9am', 'Pressure3pm']\nsns.pairplot(df[cols], diag_kind='hist', kind='scatter')","c48956a1":"X = data.drop(['RainTomorrow'], axis=1)\ny = data.RainTomorrow\n","57101ba6":"plt.figure(figsize=(15,10))\nsns.heatmap(X.corr(), linecolor='black', linewidth=1, annot=True)","8f36d338":"print('Original X Shape is ' , X.shape)\nFeatureSelection = SelectPercentile(score_func = f_classif, percentile=50) # score_func can = f_classif\nX = FeatureSelection.fit_transform(X, y)\n\n#showing X Dimension \nprint('X Shape is ' , X.shape)\nprint('Selected Features are : ' , FeatureSelection.get_support())\n","32125379":"scaler = MinMaxScaler(copy=True, feature_range=(0, 1))\nX = scaler.fit_transform(X)\n\n#showing data\nprint('X \\n' , X[:3])","1614994b":"X_train, X_test, y_train, y_test = train_test_split(X, y,\n                                   test_size=0.33, random_state=44, shuffle =True)\n","84835b40":"\nfrom sklearn.linear_model import LogisticRegression\n\nLogisticRegressionModel = LogisticRegression(penalty='l2',solver='sag',C=1.0,random_state=33)\nLogisticRegressionModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('LogisticRegressionModel Train Score is : ' , LogisticRegressionModel.score(X_train, y_train))\nprint('LogisticRegressionModel Test Score is : ' , LogisticRegressionModel.score(X_test, y_test))\n\n#print('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = LogisticRegressionModel.predict(X_test)\ny_pred_prob = LogisticRegressionModel.predict_proba(X_test)\nprint('Predicted Value for LogisticRegressionModel is : ' , y_pred[:10])\nprint('Prediction Probabilities Value for LogisticRegressionModel is : ' , y_pred_prob[:10])\n","16f037b5":"from sklearn.linear_model import SGDClassifier\n\nSGDClassifierModel = SGDClassifier(penalty='l2',loss='squared_loss',learning_rate='optimal',random_state=33)\nSGDClassifierModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('SGDClassifierModel Train Score is : ' , SGDClassifierModel.score(X_train, y_train))\nprint('SGDClassifierModel Test Score is : ' , SGDClassifierModel.score(X_test, y_test))\n\n#Calculating Prediction\ny_pred = SGDClassifierModel.predict(X_test)\nprint('Predicted Value for SGDClassifierModel is : ' , y_pred[:10])\nprint('Predicted Value for SGDClassifierModel is : ' , y_pred_prob[:10])","8d51d7e7":"from sklearn.svm import SVC\n\nSVCModel = SVC(kernel= 'sigmoid',# it can be also linear,poly,sigmoid,precomputed\n               max_iter=10000,C=100,gamma='auto')\nSVCModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('SVCModel Train Score is : ' , SVCModel.score(X_train, y_train))\nprint('SVCModel Test Score is : ' , SVCModel.score(X_test, y_test))\n#print('----------------------------------------------------')\n\n#Calculating Prediction\ny_pred = SVCModel.predict(X_test)\nprint('Predicted Value for SVCModel is : ' , y_pred[:10])\nprint('Prediction Probabilities Value for LogisticRegressionModel is : ' , y_pred_prob[:10])\n","c74efeed":"from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\n\nQDAModel = QuadraticDiscriminantAnalysis(tol=0.0001)\nQDAModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('QDAModel Train Score is : ' , QDAModel.score(X_train, y_train))\nprint('QDAModel Test Score is : ' , QDAModel.score(X_test, y_test))\nprint('QDAModel means are : ' , QDAModel.means_)\n\n#Calculating Prediction\ny_pred = QDAModel.predict(X_test)\ny_pred_prob = QDAModel.predict_proba(X_test)\nprint('Predicted Value for QDAModel is : ' , y_pred[:10])\nprint('Prediction Probabilities Value for QDAModel is : ' , y_pred_prob[:10])","30384c4a":"from sklearn.naive_bayes import MultinomialNB\n\n\nMultinomialNBModel = MultinomialNB(alpha=1.0)\nMultinomialNBModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('MultinomialNBModel Train Score is : ' , MultinomialNBModel.score(X_train, y_train))\nprint('MultinomialNBModel Test Score is : ' , MultinomialNBModel.score(X_test, y_test))\n\n#Calculating Prediction\ny_pred = MultinomialNBModel.predict(X_test)\ny_pred_prob = MultinomialNBModel.predict_proba(X_test)\nprint('Predicted Value for MultinomialNBModel is : ' , y_pred[:10])\nprint('Prediction Probabilities Value for MultinomialNBModel is : ' , y_pred_prob[:10])","8a0c8f21":"#Import Libraries\nfrom sklearn.tree import DecisionTreeClassifier\n\n\nDecisionTreeClassifierModel = DecisionTreeClassifier(criterion='gini',max_depth=3,random_state=33) #criterion can be entropy\nDecisionTreeClassifierModel.fit(X_train, y_train)\n\n#Calculating Details\nprint('DecisionTreeClassifierModel Train Score is : ' , DecisionTreeClassifierModel.score(X_train, y_train))\nprint('DecisionTreeClassifierModel Test Score is : ' , DecisionTreeClassifierModel.score(X_test, y_test))\n\n#Calculating Prediction\ny_pred = DecisionTreeClassifierModel.predict(X_test)\ny_pred_prob = DecisionTreeClassifierModel.predict_proba(X_test)\nprint('Predicted Value for DecisionTreeClassifierModel is : ' , y_pred[:10])\nprint('Prediction Probabilities Value for DecisionTreeClassifierModel is : ' , y_pred_prob[:10])","8ab2fe82":"# **Applying SVC Model**","742b28f1":"# **Importing Libraries and Data**","95e6bdb2":"# **Dropping rows with any empty cell in RainTomorrow**","96c68891":"# **Applying SGDClassifier Model**","538b215e":"# **Applying LogisticRegression Model**","a89fad4e":"# **Applying MultinomialNB Model**","5f847f79":"# **Feature Selection**","5f60ad66":"# **Applying QDA Model** ","f3e17ffa":"# **Feature Engineering of Date variable.**","34bf5231":"# **Data Transformations**","40ebf935":"# **Cleaning Data**","378c5f84":"# **Getting rid of the columns with nulls more than 10% which will not be used in our model**\n","d6b8026d":"# **Splitting Data to X,y**","b5e117c6":"# **Data Exploration**","da0f43fd":"# **Splitting data**","84271c47":"# **Correlation Heatmap**\n","e7e21f8d":"# **Applying DecisionTreeClassifier Model**","5aa4f607":"# **View our target variable RainTomorrow**","dd5cfc93":"# **MinMaxScaler for Data**","9a184d77":"# **Number of Nan values in each column**"}}