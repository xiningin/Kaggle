{"cell_type":{"a124f4b7":"code","3df856c8":"code","5375452e":"code","7d29eb68":"code","25e63d02":"code","dcc615bb":"code","3308c161":"code","20096dfe":"code","161c7f27":"code","c92fc6cf":"code","c7b7e274":"code","b74fac55":"code","52c6749d":"code","668d1ee3":"code","8612b2c8":"code","bf3109b9":"code","e07845a7":"code","1c3b2203":"code","44070356":"code","3aafcb0a":"code","d6c2816a":"code","d816c823":"code","27f81d33":"code","ec101efc":"code","0dd3c08a":"code","42b2ae99":"code","0630b6f8":"code","5ae37c44":"code","49786205":"code","6efd5b09":"code","1f733641":"code","eec784a5":"code","0b24e2d1":"markdown","1c79d9f4":"markdown","b81aa9e8":"markdown","4e8114ef":"markdown","e2e1d300":"markdown","f01d3e8e":"markdown"},"source":{"a124f4b7":"import pandas as pd\ndf = pd.read_csv(\"\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")\ndf.columns = [col.lower() for col in df.columns]","3df856c8":"df[((df[\"age\"] < 18) & \n    (df[\"work_type\"] != \"children\"))].head(10)","5375452e":"df = df[((df[\"age\"] >= 18) |\n         (df[\"work_type\"] == \"children\"))]","7d29eb68":"categorical_columns = [\"gender\",\n                       \"hypertension\",\n                       \"heart_disease\",\n                       \"ever_married\",\n                       \"work_type\",\n                       \"residence_type\",\n                       \"smoking_status\"]\n\nnumerical_columns = [\"age\",\n                     \"avg_glucose_level\",\n                     \"bmi\"]\n\ntarget = \"stroke\"","25e63d02":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style = \"whitegrid\")\n\ndef plot_cnt_prc(feature, target, data, axes):\n    sns.barplot(x = feature, y = \"id\",\n                data = data.groupby([feature, target]).count().reset_index(),\n                color = \"#d6d6f5\", hue = target, ax = axes[0])\n    \n    axes[0].set_xlabel(axes[0].get_xlabel(), size = 16)\n    axes[0].set_ylabel(\"Quantity\", size = 16)\n    \n    sns.barplot(x = feature, y = target,\n                data = (data.groupby(feature).mean() * 100).reset_index(),\n                color = \"#d6d6f5\", ax = axes[1])\n    \n    axes[1].set_xlabel(axes[1].get_xlabel(), size = 16)\n    axes[1].set_ylabel(\"Percentage\", size = 16)\n\n    \ncolumns = [\"gender\",\n           \"age\",\n           \"hypertension\",\n           \"heart_disease\",\n           \"ever_married\",\n           \"work_type\",\n           \"residence_type\",\n           \"avg_glucose_level\",\n           \"bmi\",\n           \"smoking_status\"]\n    \n\nfig, axes = plt.subplots(10, 2, figsize = (20, 70))\ndata = df.copy()\nfor ax, col in zip(axes, columns):\n    if col in numerical_columns:\n        data[col] = pd.qcut(data[col], q = 5,\n                            duplicates = \"drop\")\n    plot_cnt_prc(col, target, data, ax)\n\nplt.show()","dcc615bb":"counts = df[target].value_counts()\nplt.figure(figsize = (12, 6))\n\nplt.pie(x = counts,\n        labels = counts.keys(),\n        autopct = \"%.1f%%\",\n        explode = (0, 0.1),\n        colors = [\"#99b3ff\", \"#4d79ff\"])\nplt.show()","3308c161":"import scipy.stats as stats\nimport numpy as np\nfrom sklearn.preprocessing import OrdinalEncoder\n\ndef correlation_plot(df, columns, \n                     method = \"pearson\", \n                     figsize = (12, 6)):\n    corr = df.loc[:, columns].corr(method = method)\n    mask = np.triu(np.ones_like(corr, dtype = np.bool))\n    \n    plt.figure(figsize = figsize)\n    heatmap = sns.heatmap(data = corr, mask = mask,\n                          vmin = -1, vmax = 1,\n                          annot = True, cmap = \"coolwarm\")\n    \n    heatmap.set_title(\"Correlation Heatmap\", fontdict = {\"fontsize\": 15})\n    plt.show()\n\ndef cramers_v(x, y):\n    confusion_matrix = pd.crosstab(x,y)\n    chi2 = stats.chi2_contingency(confusion_matrix)[0]\n    n = confusion_matrix.sum().sum()\n    phi2 = chi2\/n\n    r,k = confusion_matrix.shape\n    phi2corr = max(0, phi2-((k-1)*(r-1))\/(n-1))\n    rcorr = r-((r-1)**2)\/(n-1)\n    kcorr = k-((k-1)**2)\/(n-1)\n    return np.sqrt(phi2corr\/min((kcorr-1),(rcorr-1)))","20096dfe":"data = df.copy()\nencoder = OrdinalEncoder()\ncolumns = categorical_columns + [target]\n\ndata = pd.DataFrame(encoder.fit_transform(data[columns]), \n                    columns = columns)\n\ncorrelation_plot(df = data,\n                 columns = columns,\n                 method = cramers_v)\ndel data","161c7f27":"columns = numerical_columns + [target]\ncorrelation_plot(df = df,\n                 columns = columns)","c92fc6cf":"pd.DataFrame(df.isna().sum(), \n             columns = [\"na_quantity\"])","c7b7e274":"def glucose_level(glucose):\n    if glucose <= 70:\n        return \"TOO_LOW_GLUCOSE_LEVEL\"\n    elif glucose <= 99:\n        return \"NORMAL_BLOOD_GLUCOSE_LEVEL\"\n    elif glucose <= 125:\n        return \"PRE_DIABETES\"\n    else:\n        return \"DIABETES\"\n\ndef bmi(bmi_level):\n    if str(bmi_level) == \"nan\":\n        return \"NAN\"\n    elif bmi_level < 16:\n        return \"SEVERELY_UNDERWEIGHT\"\n    elif bmi_level < 16.99:\n        return \"EMACIATION\"\n    elif bmi_level < 18.49:\n        return \"UNDERWEIGHT\"\n    elif bmi_level < 24.99:\n        return \"NORMAL_WEIGHT\"\n    elif bmi_level < 29.99:\n        return \"OVERWEIGHT\"\n    elif bmi_level < 34.99:\n        return \"OBESITY_CLASS_I\"\n    elif bmi_level < 39.99:\n        return \"OBESITY_CLASS_II\"\n    else:\n        return \"OBESITY_CLASS_III\"\n\ndata = df.copy()\ndata[\"avg_glucose_level\"] = data[\"avg_glucose_level\"].apply(glucose_level)\ndata[\"bmi\"] = data[\"bmi\"].apply(bmi)","b74fac55":"categorical_columns = [\"gender\",\n                       \"hypertension\",\n                       \"heart_disease\",\n                       \"ever_married\",\n                       \"work_type\",\n                       \"residence_type\",\n                       \"smoking_status\",\n                       \"avg_glucose_level\",\n                       \"bmi\"]\n\nnumerical_columns = [\"age\"]","52c6749d":"encoder = OrdinalEncoder()\ncolumns = categorical_columns + [target]\n\ndata = pd.DataFrame(encoder.fit_transform(data[columns]), \n                    columns = columns)\n\ncorrelation_plot(df = data,\n                 columns = columns,\n                 method = cramers_v)\ndel data","668d1ee3":"from sklearn.base import BaseEstimator\nfrom sklearn.base import TransformerMixin\n\nclass Transformer(BaseEstimator, TransformerMixin):\n    def __bmi(self, value):\n        if str(value) == \"nan\":\n            return \"NAN\"\n        elif value < 16:\n            return \"SEVERELY_UNDERWEIGHT\"\n        elif value < 16.99:\n            return \"EMACIATION\"\n        elif value < 18.49:\n            return \"UNDERWEIGHT\"\n        elif value < 24.99:\n            return \"NORMAL_WEIGHT\"\n        elif value < 29.99:\n            return \"OVERWEIGHT\"\n        elif value < 34.99:\n            return \"OBESITY_CLASS_I\"\n        elif value < 39.99:\n            return \"OBESITY_CLASS_II\"\n        else:\n            return \"OBESITY_CLASS_III\"\n  \n    def __glucose(self, value):\n        if value <= 70:\n            return \"TOO_LOW_GLUCOSE_LEVEL\"\n        elif value <= 99:\n            return \"NORMAL_BLOOD_GLUCOSE_LEVEL\"\n        elif value <= 125:\n            return \"PRE_DIABETES\"\n        else:\n            return \"DIABETES\"\n\n    def transform(self, X, y = None):\n        X = X.copy()\n        X[\"bmi\"] = X[\"bmi\"].apply(self.__bmi)\n        X[\"avg_glucose_level\"] = X[\"avg_glucose_level\"].apply(self.__glucose)\n        return X\n\n    def fit(self, X, y = None):\n        return self","8612b2c8":"from sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom category_encoders import WOEEncoder\nfrom sklearn.compose import ColumnTransformer\n\nX = df[categorical_columns + numerical_columns]\nY = df[target]\n\nX_train, X_test, Y_train, Y_test =\\\n  train_test_split(X, Y, test_size = 0.2, stratify = Y, random_state = 1)","bf3109b9":"pipeline = Pipeline([(\"bmi_glucose\", Transformer()),\n                     (\"woe\", WOEEncoder(cols = categorical_columns))])\n\ntransformer = ColumnTransformer([(\"pipeline\",\n                                  pipeline,\n                                  categorical_columns),\n                                 (\"scale\",\n                                  StandardScaler(),\n                                  numerical_columns)])\n\nX_train = pd.DataFrame(transformer.fit_transform(X_train, Y_train),\n                       columns = X_train.columns,\n                       index = X_train.index)\nX_test = pd.DataFrame(transformer.transform(X_test),\n                      columns = X_test.columns,\n                      index = X_test.index)","e07845a7":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\n\nlr = LogisticRegression(class_weight = \"balanced\")\nlr.fit(X_train, Y_train)\n\nprint(classification_report(Y_test, lr.predict(X_test)))","1c3b2203":"import optuna \nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\n\nX_train_skf = X_train.values\nY_train_skf = Y_train.values\n\ndef objective(trial):\n    param_grid = {\n          \"class_weight\": \"balanced\",\n          \"random_state\": 1,\n          \"solver\": \"liblinear\",\n          \"C\": trial.suggest_float(\"C\", 0.01, 1),\n          \"penalty\": trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"])\n      }\n  \n    skf = StratifiedKFold(n_splits = 3)\n    test_scores = []\n\n    for train_index, test_index in skf.split(X_train_skf, Y_train_skf):\n        X_train_fold, X_test_fold = X_train_skf[train_index], X_train_skf[test_index]\n        Y_train_fold, Y_test_fold = Y_train_skf[train_index], Y_train_skf[test_index]\n  \n    classifier = LogisticRegression(**param_grid)\n    classifier.fit(X_train_fold, Y_train_fold)\n    test_scores.append(roc_auc_score(Y_test_fold, classifier.predict_proba(X_test_fold)[:, 1]))\n\n    return np.asarray(test_scores).mean()\n\noptuna.logging.disable_default_handler()\nstudy = optuna.create_study(direction = \"maximize\")\nstudy.optimize(objective, n_trials = 300)","44070356":"from optuna.visualization import plot_parallel_coordinate\nplot_parallel_coordinate(study)","3aafcb0a":"from sklearn.model_selection import GridSearchCV, StratifiedKFold\nfrom sklearn.metrics import make_scorer\n\nparam_grid = {\n      \"class_weight\": [\"balanced\"],\n      \"random_state\": [1],\n      \"solver\": [\"liblinear\"],\n      \"C\": [0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2],\n      \"penalty\": [\"l1\", \"l2\"]\n}\n\ngrid = GridSearchCV(estimator = LogisticRegression(),\n                    param_grid = param_grid,\n                    cv = StratifiedKFold(n_splits = 3), \n                    n_jobs = -1,\n                    verbose = 10,\n                    scoring = make_scorer(roc_auc_score, needs_proba = True))\n\ngrid.fit(X_train, Y_train)","d6c2816a":"lr = LogisticRegression(**grid.best_params_)\nlr.fit(X_train, Y_train)\n\nprint(classification_report(Y_test, lr.predict(X_test)))","d816c823":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import plot_confusion_matrix\n\nfig, ax = plt.subplots(figsize = (10, 6))\nplot_confusion_matrix(lr, \n                      X_test, \n                      Y_test, \n                      ax = ax, \n                      values_format = '.0f')\nplt.grid(False)\nplt.show()","27f81d33":"from sklearn.metrics import roc_curve\n\nfpr, tpr, threshold = roc_curve(Y_test, lr.predict_proba(X_test)[:, 1])\ndata = list(zip(threshold, tpr, fpr))\ntrh = pd.DataFrame(data, \n                   columns = [\"threshold\", \n                              \"true_positive_rate\", \n                              \"false_positive_rate\"])\ntrh[\"tpr-fpr\"] = trh[\"true_positive_rate\"] - trh[\"false_positive_rate\"]","ec101efc":"trh.sort_values(by = \"tpr-fpr\", ascending = False).head(3)","0dd3c08a":"data = X_test.copy()\ncolumns = data.columns\ndata[\"label\"] = Y_test\ndata[\"pred_proba\"] = lr.predict_proba(data[columns])[:, 1]\n\ndata = data.reset_index()","42b2ae99":"import shap\n\nexplainer = shap.Explainer(lr.predict_proba, data.loc[:, columns])\nexplainer_output = explainer(data.loc[:, columns])\n\nexpected_values = explainer_output.base_values[:1, :].reshape(-1)\nshap_values = explainer_output.values","0630b6f8":"shap.summary_plot(shap_values[:, :, 1], data.loc[:, columns])","5ae37c44":"data.sort_values(by = \"pred_proba\").head(3)","49786205":"shap.initjs()\nshap.force_plot(expected_values[1], shap_values[508].T[1], df.loc[4581, columns])","6efd5b09":"data.sort_values(by = \"pred_proba\", ascending=False).head(5)","1f733641":"shap.initjs()\nshap.force_plot(expected_values[1], shap_values[65].T[1], df.loc[218, columns])","eec784a5":"shap.initjs()\nshap.force_plot(expected_values[1], shap_values[313].T[1], df.loc[4164, columns])","0b24e2d1":"Dataset does not include highly correlated categorical features","1c79d9f4":"Dataset does not include highly correlated numerical features.","b81aa9e8":"Stroke is third most common cause of death and main cause of disability or complete dependance on performing activities of daily living within adults. There are two main varieties:\n* Hemorrhagic stroke (sudden bleeding may occur due to a ruptured brain aneurysm, which damages brain structure)\n* Ischemic (usuallt caused by blockage of a blood vessel) \n\nWe can highlight several factors of a stroke:\n* Age\n* Family history of stroke\n* Hypertension\n* Heart diseases\n* Diabetes\n* Smoking status\n* Alcohol abuse\n* Amphetamine, cocaine abuse\n* Obesity\n","4e8114ef":"Dataset includes part of observations, where the target variable is classified as 0, and simultaneously they are very similar to obesrvations reffered to as \u201esuccess\u201d. Age turned out to be the most relevant attribute out of the accessible set. Perhaps inserting additional features to the set would improvement of the results.","e2e1d300":"Observations, that include a 7 or 8 yeard old running a business (or other unusuall) would require consulting with a specialist. Propable errors in collecting data.","f01d3e8e":"Assuming, that glucose measurment\n* Was performed on empty stomach\n* Is given with set of units mg\/dL\n\nWe can highlight (surely this would require consulting a specialist) four categories:\n* avg_glucose_level < 70 \u2013\u00a0too low glucose level\n* 70 < avg_glucose_level < 88 \u2013\u00a0normal blood glucose level\n* 100 < avg_glucose_level < 125 \u2013 pre-diabetes\n* 126 < avg_glucose_level \u2013\u00a0diabetes\n\nWe can assign BMI values to 8 categories (this would also require consulting a specialist):\n* BMI < 16 \u2013\u00a0severely underweight\n* 16 < BMI < 16.99 -\u00a0emaciation\n* 17 < BMI < 18.49 -\u00a0underweight\n* 18.5 < BMI < 24.99 \u2013\u00a0normal weight\n* 25 < BMI < 29.99 -\u00a0overweight\n* 30 < BMI < 34.99 \u2013\u00a0obesity class I \n* 35 < BMI < 39.99 -\u00a0obesity class II\n* 40 < BMI -\u00a0obesity class III\n"}}