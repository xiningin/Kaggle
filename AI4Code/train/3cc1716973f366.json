{"cell_type":{"0a0e7a06":"code","19727a91":"code","00096426":"code","6cb0e454":"code","e585b2a6":"code","e863a225":"code","4891a93e":"code","37336f5a":"code","e8aaa925":"code","f9f72928":"code","606dc3ce":"code","f9ab7413":"code","dbdbafc3":"code","56001353":"code","f3166b9e":"code","f3a03806":"code","47d7619f":"code","b632de4f":"code","cbce8ad4":"code","76a0c6a1":"code","9eaf66b0":"code","7d78df9f":"markdown","575f66cd":"markdown","a994bb6d":"markdown","2e75412b":"markdown","4e72d702":"markdown","cefeb528":"markdown","db6806b0":"markdown","deb758c3":"markdown","046dc92d":"markdown","4b6b2e66":"markdown","f32493fc":"markdown"},"source":{"0a0e7a06":"pip install opencv-python opencv-contrib-python\n","19727a91":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","00096426":"# Import Dependencies\n%matplotlib inline\n\n# Start Python Imports\nimport math, time, random, datetime\n\n# Data Manipulation\nimport numpy as np\nimport pandas as pd\n\n# Visualization \nimport matplotlib.pyplot as plt\nimport missingno\nimport seaborn as sns\nplt.style.use('seaborn-whitegrid')\n\n# Preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize\n# Machine learning\nimport catboost\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, tree, preprocessing, metrics, linear_model\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom catboost import CatBoostClassifier, Pool, cv\nfrom sklearn.preprocessing import StandardScaler\nfrom keras.layers.advanced_activations import ReLU\nfrom keras.models import Sequential, Model\nfrom keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten,Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D\nimport keras\nimport cv2\nimport tensorflow\nfrom keras.utils import np_utils\nfrom keras.callbacks import ModelCheckpoint\n\n\n\n# Let's be rebels and ignore warnings for now\nimport warnings\nwarnings.filterwarnings('ignore')\n","6cb0e454":"TRAIN_PATH  = '..\/input\/covid-face-mask-detection-dataset\/New Masks Dataset\/Train'\nTEST_PATH  = '..\/input\/covid-face-mask-detection-dataset\/New Masks Dataset\/Test'\nIMG_SIZE = 100","e585b2a6":"categories=os.listdir(TRAIN_PATH)\nprint('Categories Name :' ,categories)\nlabels=[i for i in range(len(categories))]\nprint('After convert it to 0,1 :',labels)","e863a225":"label_dict=dict(zip(categories,labels))\nprint(label_dict)\nprint('len of Labels dictionary : ' , len(label_dict))","4891a93e":"\n\nImges_Data_Train=[]\ntarget_Train=[]\n\n\nfor  i in categories :\n    path_Cat=os.path.join(TRAIN_PATH,i)\n    print('Path Now is :', path_Cat)\n    Img_Names=os.listdir(path_Cat)\n    print(Img_Names[0:10])\n    \n    for img in Img_Names :\n        img_path=os.path.join(path_Cat,img)\n        imge=cv2.imread(img_path)\n        #print(imge)\n        gray_img=cv2.cvtColor(imge,cv2.COLOR_BGR2GRAY)           \n        #print(gray_img)\n        dim=(IMG_SIZE,IMG_SIZE)\n        resized_img = cv2.resize(gray_img, dim)\n        Imges_Data_Train.append(resized_img)\n        #print(Imges_Data_Train)\n        target_Train.append(label_dict[i])\n        #print(target)\n","37336f5a":"# Make Normalization for data\nImges_Data_Train=np.array(Imges_Data_Train)\/255.0\n# Reshape Data\nImges_Data_Train=np.reshape(Imges_Data_Train,(Imges_Data_Train.shape[0],IMG_SIZE,IMG_SIZE,1))\n\n#print(Imges_Data)","e8aaa925":"target_Train=np.array(target_Train)\n","f9f72928":"Target_Train=np_utils.to_categorical(target_Train)\nprint(Target_Train)","606dc3ce":"categories=os.listdir(TEST_PATH)\nprint('Categories Name :' ,categories)\nlabels=[i for i in range(len(categories))]\nprint('After convert it to 0,1 :',labels)","f9ab7413":"label_dict=dict(zip(categories,labels))\nprint(label_dict)\nprint('len of Labels dictionary : ' , len(label_dict))","dbdbafc3":"\n\nImges_Data_Test=[]\ntarget_Test=[]\n\n\nfor  i in categories :\n    path_Cat=os.path.join(TEST_PATH,i)\n    print('Path Now is :', path_Cat)\n    Img_Names=os.listdir(path_Cat)\n    print(Img_Names[0:10])\n    \n    for img in Img_Names :\n        img_path=os.path.join(path_Cat,img)\n        imge=cv2.imread(img_path)\n        #print(imge)\n        gray_img=cv2.cvtColor(imge,cv2.COLOR_BGR2GRAY)           \n        #print(gray_img)\n        dim=(IMG_SIZE,IMG_SIZE)\n        resized_img = cv2.resize(gray_img, dim)\n        Imges_Data_Test.append(resized_img)\n        #print(Imges_Data_Test)\n        target_Test.append(label_dict[i])\n        #print(target)\n","56001353":"# Make Normalization for data\nImges_Data_Test=np.array(Imges_Data_Test)\/255.0\n# Reshape Data\nImges_Data_Test=np.reshape(Imges_Data_Test,(Imges_Data_Test.shape[0],IMG_SIZE,IMG_SIZE,1))\n\n#print(Imges_Data_Test)","f3166b9e":"target_Test=np.array(target_Test)\n","f3a03806":"Target_Test=np_utils.to_categorical(target_Test)\nprint(Target_Test)","47d7619f":"\nmodel=Sequential()\n\nmodel.add(Conv2D(100,(3,3),input_shape=Imges_Data_Train.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n#The first CNN layer followed by Relu and MaxPooling layers\n\nmodel.add(Conv2D(100,(3,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n#The second convolution layer followed by Relu and MaxPooling layers\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\n#Flatten layer to stack the output convolutions from second convolution layer\nmodel.add(Dense(50,activation='relu'))\n#Dense layer of 64 neurons\nmodel.add(Dense(2,activation='softmax'))\n#The Final layer with two outputs for two categories\n\n","b632de4f":"model.summary()","cbce8ad4":"model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","76a0c6a1":"results=model.fit(Imges_Data_Train,Target_Train,epochs=5,validation_split=0.2)\n","9eaf66b0":"print(model.evaluate(Imges_Data_Test,Target_Test))\n","7d78df9f":"# ![image.png](attachment:image.png)\n","575f66cd":"# Constants ","a994bb6d":"# live Detection","2e75412b":"# prepare Train Data","4e72d702":"make a target binary values 0,1","cefeb528":"Also make a target values in array to can use in CNN model","db6806b0":"# Fit Model","deb758c3":"![](http:\/\/)![](http:\/\/)![](http:\/\/)OK, now we have a Data imges (Feature for each image) and Target of them.\nnow we need to resize data to ","046dc92d":"# Prepare Test Data","4b6b2e66":"# Imports","f32493fc":"# Build Cnn Model"}}