{"cell_type":{"773cb6b4":"code","dba482ec":"code","28c2368c":"code","95dfa43f":"code","147c33c6":"code","f2b3fb09":"code","2f3fade0":"code","6452cef3":"code","fcbed70b":"code","dda815f3":"code","b4f83bef":"code","640c5702":"code","07a1b947":"code","6d261425":"code","5a80c02b":"code","b43efaa0":"code","1da618de":"code","4b349642":"code","63468413":"code","f0d7ef3b":"code","a36d803d":"code","84825dbc":"code","a2a2c229":"code","a7e93671":"code","acb64738":"code","3fdfe2b0":"code","2fbeea2a":"code","aa33ffbe":"code","26661e2e":"code","a8604f3f":"code","975e12f5":"code","e01fedf6":"code","38484d91":"code","33608d7a":"code","6ca11bb6":"code","0f0fd7d3":"code","599bb001":"code","6b8fe2c3":"code","6b74ee52":"code","5f52bbd4":"code","0ed38025":"code","6f38519b":"code","0d7e4d2e":"code","033774a0":"code","e925ed21":"code","b8d352ef":"code","155792f4":"code","9ccf5d27":"code","f36000c7":"code","f678044f":"code","d2cdf05d":"code","7ff5feeb":"code","fbd0fe72":"code","e845bfd4":"code","1df1b98d":"code","620e495f":"code","d8862419":"code","ef7d19a9":"code","e91ce671":"code","7481c427":"code","35ba895d":"code","c5d7a9db":"code","d77ad59a":"code","d5b59a85":"code","869c8e8a":"code","36d778c7":"code","4c3cd4a1":"code","b7d610c4":"code","c6044420":"code","78e5ead9":"code","5e68a127":"code","088f1923":"code","daffd283":"code","cadd70dd":"code","72644222":"code","a264a499":"code","a4999005":"code","f5011649":"code","2827e3e3":"code","49a33203":"code","db73191b":"code","6ebab351":"code","ab229657":"code","f1cc6a09":"code","03ba3d0f":"code","7c2a4921":"code","2e90b40c":"code","3f5cfaee":"code","58fec11a":"code","963731b3":"code","35a783e2":"code","51a05203":"code","b0a170e4":"code","d98bbaed":"code","198d9249":"code","e4a471f2":"code","0fc6594b":"code","3f4a81fd":"code","1f7aa016":"code","2f7d185e":"code","a76b1ecc":"code","3e43415a":"code","eb806d8f":"markdown","3a6a5944":"markdown","47a5937a":"markdown","7d1cc8e4":"markdown","7384f0fb":"markdown","f3c0415d":"markdown","eb0ba433":"markdown","636c85b0":"markdown","54a66195":"markdown","9b73a6a1":"markdown","58a4d918":"markdown","6d587347":"markdown","a18083e0":"markdown","d390f6f0":"markdown","28e6a57f":"markdown","a81fa1c2":"markdown","c6891273":"markdown","1e9991e5":"markdown","6a846de3":"markdown","be962f09":"markdown","46e43c82":"markdown","569f33cf":"markdown","f1bde9cb":"markdown","9c5d45c5":"markdown","0486f60e":"markdown","5a49b613":"markdown","2f8fe8ea":"markdown","6e3ae33b":"markdown","b90d198a":"markdown","eb257e82":"markdown","746a1583":"markdown","6ba60325":"markdown","d6b0c9f1":"markdown","38c6fa95":"markdown","3543dbad":"markdown","99c7d233":"markdown","a23d69ed":"markdown","d7c9d12d":"markdown","1fc7ce91":"markdown","4f9e6206":"markdown","e932a417":"markdown","4382c971":"markdown","d6a5e32b":"markdown","1b0c1a76":"markdown","0758ba1b":"markdown","36128a04":"markdown","3d9d7b0e":"markdown","92645c36":"markdown","5a033966":"markdown","e9873519":"markdown","3a0a2011":"markdown","58e4f29d":"markdown","d5232204":"markdown","6ab6157b":"markdown","4838acaa":"markdown","94029743":"markdown","ea00dc63":"markdown","84adef54":"markdown","eb1c2feb":"markdown","c7540b28":"markdown","535b510f":"markdown","cdc86018":"markdown","15efa20b":"markdown","8c716b5e":"markdown","33160d6c":"markdown","6a201fe8":"markdown","b9f68500":"markdown","c4ff6a82":"markdown","1bf5192a":"markdown","0a30717e":"markdown","c396230f":"markdown","a282de34":"markdown","39de47ae":"markdown","3c2fbd57":"markdown","d7754c24":"markdown","bdd28af8":"markdown","a4b4bd28":"markdown","59311a45":"markdown","e7b44514":"markdown","321fe55e":"markdown","93a8b247":"markdown","d55bed6c":"markdown","bad9bba6":"markdown","7e70e8f9":"markdown","ed915a72":"markdown","4a90f8f5":"markdown","ce9ec8dc":"markdown","feb230b7":"markdown","2e453f39":"markdown","ab133149":"markdown","6bf62699":"markdown","8c49ec2f":"markdown","240d10c5":"markdown","30753a16":"markdown"},"source":{"773cb6b4":"import pandas as pd\ndata=pd.read_csv('..\/input\/covid19-tracking-germany\/covid_de.csv')\ndf = pd.DataFrame(data)\ndf['date']=pd.to_datetime(df['date'].astype(str), format='%Y-%m-%d') \nsorted_df = df.sort_values(by=[\"date\"], ascending=True)","dba482ec":"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport scipy\nimport string\nimport math\nimport seaborn as sns\nfrom scipy.stats import norm\nfrom statsmodels.stats.diagnostic import lilliefors\nfrom statsmodels.graphics.gofplots import qqplot\nfrom scipy.stats import norm, kurtosis, kurtosistest, pearsonr, skew, normaltest, chisquare, chi2_contingency, chi2\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nimport datetime as dt #Not used!\n\nfrom matplotlib import pyplot\n#import cupy as cp #Not available \n\n#Get DOF with least RMSE\n## Kudos to jonnybazookatone: https:\/\/stackoverflow.com\/questions\/47442102\/how-to-find-the-best-degree-of-polynomials\n\ndef get_degree (a,b):\n    X = a\n    y = b\n\n    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n\n    rmses = []\n    degrees = np.arange(1, 100)\n    min_rmse, min_deg = 1e10, 0\n\n    for deg in degrees:\n\n    # Train features\n        poly_features = PolynomialFeatures(degree=deg, include_bias=False)\n        x_poly_train = poly_features.fit_transform(x_train)\n\n    # Fit data\n        poly_reg = LinearRegression()\n        poly_reg.fit(x_poly_train, y_train)\n\n    # Get RMSE of test data\n        x_poly_test = poly_features.fit_transform(x_test)\n        poly_predict = poly_reg.predict(x_poly_test)\n        poly_mse = mean_squared_error(y_test, poly_predict)\n        poly_rmse = np.sqrt(poly_mse)\n        rmses.append(poly_rmse)\n    \n    # CV\n        if min_rmse > poly_rmse:\n            min_rmse = poly_rmse\n            min_deg = deg\n\n# Print calculated DOF\n    print('Best DOF {} with RMSE {}'.format(min_deg, min_rmse))\n        \n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.plot(degrees, rmses)\n    ax.set_yscale('log')\n    ax.set_xlabel('Degree')\n    ax.set_ylabel('RMSE')\n    return min_deg","28c2368c":"df['date']=pd.to_datetime(df['date'].astype(str), format='%Y-%m-%d') \nsorted_df = df.sort_values(by=[\"date\"], ascending=True)\nsorted_df = sorted_df.dropna()\nsorted_df = sorted_df.reset_index(drop=True)\n\nprint('Entities pre cleanup %d'%df.shape[0])\nprint('Entities post cleanup %d'%sorted_df.shape[0])\nprint('Removed entities %d'%(df.shape[0]-sorted_df.shape[0]))\nprint('Percentage removed %f'%((100\/df.shape[0])*(df.shape[0]-sorted_df.shape[0])))","95dfa43f":"sorted_df.head(5)","147c33c6":"sorted_df.describe(include = [np.number])","f2b3fb09":"sorted_df.describe(include=['object'])","2f3fade0":"print('Cases total: {} '.format(sorted_df['cases'].sum())) #Summe\nprint('Deaths total: {} '.format(sorted_df['deaths'].sum())) #Summe\nprint('Recoveries total: {} '.format(sorted_df['recovered'].sum())) #Summe","6452cef3":"cinf=sorted_df['deaths'].sum()+sorted_df['recovered'].sum()\naktiv=(sorted_df['cases'].sum()-cinf)\nprint('Currently infected: {}'.format(aktiv))","fcbed70b":"df_male = sorted_df['gender'] == \"M\"\ndf_female = sorted_df['gender'] == \"F\"\ndf_male = sorted_df[df_male]\ndf_female = sorted_df[df_female]\ndf_male=df_male.reset_index(drop=True)\ndf_female=df_female.reset_index(drop=True)\n","dda815f3":"unique_f = df_female['date'].unique() \nunique = sorted_df['date'].unique()\nunique_m = df_male['date'].unique()\n\n# Female Dataset\ndates_cases_f = []\nfor x in unique_f:\n    filter = np.where(df_female['date']==x)[0]\n    \n    dates_cases_f.append((np.sum(df_female['cases'][filter]))) \n\ndates_deaths_f = []\nfor x in unique_f:\n    filter = np.where(df_female['date']==x)[0]\n    \n    dates_deaths_f.append((np.sum(df_female['deaths'][filter]))) \n\ndates_recovered_f = []\nfor x in unique_f:\n    filter = np.where(df_female['date']==x)[0]\n    \n    dates_recovered_f.append((np.sum(df_female['recovered'][filter]))) \n\n# Male dataset\ndates_cases_m = []\nfor x in unique_m:\n    filter = np.where(df_male['date']==x)[0]\n    \n    dates_cases_m.append((np.sum(df_male['cases'][filter]))) \n\n\ndates_deaths_m = []\nfor x in unique_m:\n    filter = np.where(df_male['date']==x)[0]\n    \n    dates_deaths_m.append((np.sum(df_male['deaths'][filter]))) \n\n\ndates_recovered_m = []\n\nfor x in unique_m: \n    filter = np.where(df_male['date']==x)[0]\n    \n    dates_recovered_m.append((np.sum(df_male['recovered'][filter]))) \n\n# Main dataset\ndates_cases = []\n\nfor x in unique:\n    filter = np.where(sorted_df['date']==x)[0]\n    \n    dates_cases.append((np.sum(sorted_df['cases'][filter]))) \n\ndates_death = []\nfor x in unique: \n    filter = np.where(sorted_df['date']==x)[0] \n\n    dates_death.append((np.sum(sorted_df['deaths'][filter]))) \n\ndates_recovered = []\n\nfor x in unique: #\n    filter = np.where(sorted_df['date']==x)[0]\n    \n    dates_recovered.append((np.sum(sorted_df['recovered'][filter]))) \n","b4f83bef":"print('Analytics involving {} days'.format(np.array(dates_cases).size))\nprint('First day (Y-D-M): {}'.format(unique[0]))\nprint('Last day (Y-D-M): {}'.format(unique[unique.size-1]))\nprint('')\nprint('On average {} cases per day in Germany'.format(np.mean(dates_cases)))\nprint('On average {} deaths per day in Germany'.format(np.mean(dates_death)))\nprint('On average {} recoveries per day in Germany'.format(np.mean(dates_recovered)))","640c5702":"print('Mortality overall: %f'%((100\/sorted_df['cases'].sum())*sorted_df['deaths'].sum()))\nprint('Mortality females: %f'%((100\/df_female['cases'].sum())*df_female['deaths'].sum()))\nprint('Mortality males: %f'%((100\/df_male['cases'].sum())*df_male['deaths'].sum()))","07a1b947":"%matplotlib inline\nplt.figure(figsize=(20,20))\nsns.distplot(sorted_df['cases'], kde=False)","6d261425":"%matplotlib inline\nplt.figure(figsize=(20,20))\nsns.distplot(sorted_df['deaths'], kde=False)","5a80c02b":"%matplotlib inline\nplt.figure(figsize=(20,20))\nsns.distplot(sorted_df['recovered'], kde=False)","b43efaa0":"unique = sorted_df['state'].unique()\nclasses_mean = []\nclasses = []\nfor states in unique: \n    filter = np.where(sorted_df['state']==states)[0]\n    print (states)\n    classes_mean.append(np.average((sorted_df['cases'][filter]))) \nclasses_mean=np.array(classes_mean)\nclasses=np.array(classes)","1da618de":"plt.figure(figsize = (20,20))\nheight = np.sort(classes_mean)\nbars = unique[np.argsort(classes_mean)]\ny_pos = np.arange(len(bars))\navg = np.mean(classes_mean)\nplt.axhline(avg, color='k', linestyle='dashed', linewidth=1)\nplt.text(10, avg, avg, fontsize=20, va='center', ha='center', backgroundcolor='w')\n\nplt.bar(y_pos, height)\n \n\nplt.title('Mean of daily reported cases per state')\nplt.xlabel('State')\nplt.ylabel('Mean of cases per day')\n \nplt.ylim(0,20)\n \nplt.xticks(y_pos, bars, rotation=90)\n\nplt.show()","4b349642":"sum_female=sum(np.array(df_female['cases']))\nsum_male=sum(np.array(df_male['cases']))\n\n#Array bauen\ngender_counts = sorted_df['gender'].value_counts()\ngender_counts[0]=sum_female\ngender_counts[1] = sum_male\ndf2 = pd.DataFrame({'Cases ratio': gender_counts}, \n                     index = ['M', 'F']\n                   )\ndf2.plot.pie(y='Cases ratio', figsize=(10,10), autopct='%1.1f%%')","63468413":"sum_female_death=sum(np.array(df_female['deaths']))\nsum_male_death=sum(np.array(df_male['deaths']))\n\ngender_counts = sorted_df['gender'].value_counts()\ngender_counts[0]=sum_female_death\ngender_counts[1] = sum_male_death\ndf2 = pd.DataFrame({'Deaths ratio': gender_counts}, \n                     index = ['M', 'F']\n                   )\ndf2.plot.pie(y='Deaths ratio', figsize=(10,10), autopct='%1.1f%%')","f0d7ef3b":"sum_female_rec=sum(np.array(df_female['recovered']))\nsum_male_rec=sum(np.array(df_male['recovered']))\n\ngender_counts = sorted_df['gender'].value_counts()\ngender_counts[0]=sum_female_rec\ngender_counts[1] = sum_male_rec\ndf2 = pd.DataFrame({'Recovery ratio': gender_counts}, \n                     index = ['M', 'F']\n                   )\ndf2.plot.pie(y='Recovery ratio', figsize=(10,10), autopct='%1.1f%%')","a36d803d":"fig, ax = plt.subplots(figsize = (20, 15))\nsns.set_style(\"darkgrid\")\nsns.lineplot(ax=ax,data=sorted_df, x=\"date\", y=\"cases\", hue=\"age_group\", ci='sd', hue_order=['80-99','60-79','35-59','15-34','05-14','00-04'])","84825dbc":"fig, ax = plt.subplots(figsize = (20, 15))\nsns.set_style(\"darkgrid\")\nsns.lineplot(ax=ax,data=sorted_df, x=\"date\", y=\"cases\", hue=\"age_group\", ci=95, hue_order=['80-99','60-79','35-59','15-34','05-14','00-04'])","a2a2c229":"fig, ax = plt.subplots(figsize = (20, 15))\nsns.set_style(\"darkgrid\")\nsns.lineplot(ax=ax,data=sorted_df, x=\"date\", y=\"cases\", hue=\"gender\", ci='sd')","a7e93671":"fig, ax = plt.subplots(figsize = (20, 15))\nsns.set_style(\"darkgrid\")\nsns.lineplot(ax=ax,data=sorted_df, x=\"date\", y=\"cases\", hue=\"gender\", ci=95)\n","acb64738":"fig, ax = plt.subplots(figsize = (20, 15))\nsns.set_style(\"darkgrid\")\nsns.lineplot(ax=ax,data=sorted_df, x=\"date\", y=\"deaths\", hue=\"age_group\", ci='sd', hue_order=['80-99','60-79','35-59','15-34','05-14','00-04'])","3fdfe2b0":"fig, ax = plt.subplots(figsize = (20, 15))\nsns.set_style(\"darkgrid\")\nsns.lineplot(ax=ax,data=sorted_df, x=\"date\", y=\"deaths\", hue=\"age_group\", ci=95, hue_order=['80-99','60-79','35-59','15-34','05-14','00-04'])","2fbeea2a":"fig, ax = plt.subplots(figsize = (20, 15))\nsns.set_style(\"darkgrid\")\nsns.lineplot(ax=ax,data=sorted_df, x=\"date\", y=\"deaths\", hue=\"gender\", ci='sd')","aa33ffbe":"fig, ax = plt.subplots(figsize = (20, 15))\nsns.set_style(\"darkgrid\")\nsns.lineplot(ax=ax,data=sorted_df, x=\"date\", y=\"deaths\", hue=\"gender\", ci=95)","26661e2e":"fig, ax = plt.subplots(figsize = (20, 15))\nsns.set_style(\"darkgrid\")\nsns.lineplot(ax=ax,data=sorted_df, x=\"date\", y=\"recovered\", hue=\"age_group\", ci='sd', hue_order=['80-99','60-79','35-59','15-34','05-14','00-04'])","a8604f3f":"fig, ax = plt.subplots(figsize = (20, 15))\nsns.set_style(\"darkgrid\")\nsns.lineplot(ax=ax,data=sorted_df, x=\"date\", y=\"recovered\", hue=\"age_group\", ci=95, hue_order=['80-99','60-79','35-59','15-34','05-14','00-04'])","975e12f5":"fig, ax = plt.subplots(figsize = (20, 15))\nsns.set_style(\"darkgrid\")\nsns.lineplot(ax=ax,data=sorted_df, x=\"date\", y=\"recovered\", hue=\"gender\", ci='sd')","e01fedf6":"fig, ax = plt.subplots(figsize = (20, 15))\nsns.set_style(\"darkgrid\")\nsns.lineplot(ax=ax,data=sorted_df, x=\"date\", y=\"recovered\", hue=\"gender\", ci=95)","38484d91":"qqplot(sorted_df['cases'], line='s') \npyplot.show()","33608d7a":"qqplot(sorted_df['deaths'], line='s') \npyplot.show()","6ca11bb6":"qqplot(sorted_df['recovered'], line='s') \npyplot.show()","0f0fd7d3":"qqplot(np.array(dates_cases), line='s') \npyplot.show()","599bb001":"qqplot(np.array(dates_death), line='s') \npyplot.show()","6b8fe2c3":"qqplot(np.array(dates_recovered), line='s') \npyplot.show()","6b74ee52":"%matplotlib inline\nplt.figure(figsize=(20,20))\nsns.distplot(dates_cases, kde=False)","5f52bbd4":"%matplotlib inline\nplt.figure(figsize=(20,20))\nsns.distplot(dates_death, kde=False)","0ed38025":"%matplotlib inline\nplt.figure(figsize=(20,20))\nsns.distplot(dates_recovered, kde=False)","6f38519b":"unique = sorted_df['date'].unique() #unique value was gone?\npoly_x = unique.reshape(-1,1) #poly_x is used later\nday_index = np.arange(0,poly_x.size,1)\nday_index = day_index.reshape(-1,1)\nday_index.shape\n\ndays_f = unique_f.reshape(-1,1)\nday_index_f = np.arange(0,days_f.size,1)\nday_index_f = day_index_f.reshape(-1,1)\nday_index_f.shape\n\ndays_m = unique_m.reshape(-1,1)\nday_index_m = np.arange(0,days_m.size,1)\nday_index_m = day_index_m.reshape(-1,1)\nday_index_m.shape","0d7e4d2e":"%matplotlib inline\nplt.rcParams.update(plt.rcParamsDefault)\nplt.clf()\nfig, ax = plt.subplots(figsize = (30, 15))\nsns.lineplot(ax=ax, x=np.arange(0,day_index.size,1), y=dates_cases)\n\nplt.vlines(x=30, ymin=dates_cases[30], ymax=40000, label=\"Prob. wave 1\",color='k', linestyle='dashed', linewidth=2)\nplt.text(10, 40000, 'Prob. wave 1', fontsize=20, va='center', ha='center', backgroundcolor='w')\n\n\nplt.vlines(x=230, ymin=dates_cases[230], ymax=40000, label=\"Prob. wave 2\",color='k', linestyle='dashed', linewidth=2)\nplt.text(210, 40000, 'Prob. wave 2', fontsize=20, va='center', ha='center', backgroundcolor='w')\n\nplt.vlines(x=380, ymin=dates_cases[380], ymax=40000, label=\"Prob. wave 3\",color='k', linestyle='dashed', linewidth=2)\nplt.text(360, 40000, 'Prob. wave 3', fontsize=20, va='center', ha='center', backgroundcolor='w')\n","033774a0":"print('Start wave 1 ca. {}'.format(unique[30]))\nprint('Start wave 2 ca. {}'.format(unique[230]))\nprint('Start wave 3 ca. {}'.format(unique[380]))","e925ed21":"poly_reg = PolynomialFeatures(degree=get_degree(day_index,dates_cases))\nX_poly = poly_reg.fit_transform(day_index)\npol_reg = LinearRegression()\npol_reg.fit(X_poly, dates_cases)\n\nfig, ax = plt.subplots(figsize = (20, 15))\n\ndef viz_polymonial():\n    plt.scatter(day_index, dates_cases, color='red')\n    plt.plot(day_index, pol_reg.predict(poly_reg.fit_transform(day_index)), color='blue')\n    plt.title('Polynomial Reg')\n    plt.xlabel('Time index')\n    plt.ylabel('Reported cases')\n    plt.show()\n    return\nviz_polymonial()","b8d352ef":"poly_reg = PolynomialFeatures(degree=get_degree(day_index,dates_death))\nX_poly = poly_reg.fit_transform(day_index)\npol_reg = LinearRegression()\npol_reg.fit(X_poly, dates_death)\n\nfig, ax = plt.subplots(figsize = (20, 15))\n\ndef viz_polymonial():\n    plt.scatter(day_index, dates_death, color='red')\n    plt.plot(day_index, pol_reg.predict(poly_reg.fit_transform(day_index)), color='blue')\n    plt.title('Polynomial Reg')\n    plt.xlabel('Time index')\n    plt.ylabel('Reported deaths')\n    plt.show()\n    return\nviz_polymonial()","155792f4":"poly_reg = PolynomialFeatures(degree=get_degree(day_index,dates_recovered))\nX_poly = poly_reg.fit_transform(day_index)\npol_reg = LinearRegression()\npol_reg.fit(X_poly, dates_recovered)\n\nfig, ax = plt.subplots(figsize = (20, 15))\n\ndef viz_polymonial():\n    plt.scatter(day_index, dates_recovered, color='red')\n    plt.plot(day_index, pol_reg.predict(poly_reg.fit_transform(day_index)), color='blue')\n    plt.title('Polynomial Reg')\n    plt.xlabel('Time index')\n    plt.ylabel('Reported recoveries')\n    plt.show()\n    return\nviz_polymonial()","9ccf5d27":"print('Start wave 3 {}'.format(unique[np.where(pol_reg.predict(poly_reg.fit_transform(day_index)) == np.min(pol_reg.predict(poly_reg.fit_transform(day_index))[350:400]))][0]))","f36000c7":"print('Start wave 4 {}'.format(unique[np.where(pol_reg.predict(poly_reg.fit_transform(day_index)) == np.min(pol_reg.predict(poly_reg.fit_transform(day_index))[450:481]))][0]))","f678044f":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\npoly_reg = PolynomialFeatures(degree=get_degree(day_index[:150],dates_recovered[:150]))\nX_poly = poly_reg.fit_transform(day_index[:150])\npol_reg = LinearRegression()\npol_reg.fit(X_poly, dates_cases[:150])\n\nfig, ax = plt.subplots(figsize = (20, 15))\n\n# Visualizing the Polymonial Regression results\ndef viz_polymonial():\n    plt.scatter(day_index[:150], dates_cases[:150], color='red')\n    plt.plot(day_index[:150], pol_reg.predict(poly_reg.fit_transform(day_index[:150])), color='blue')\n    plt.axhline(np.mean(np.array(dates_cases[:150])), color='k', linestyle='dashed', linewidth=1) #Integration des horizontalen Mittelwertes\n    plt.text(110, np.mean(np.array(dates_cases[:150])), np.mean(np.array(dates_cases[:150])), fontsize=20, va='center', ha='center', backgroundcolor='w') #Textdefinition Mittelwert\n    plt.title('Polynomial regression cases 1st wave')\n    plt.xlabel('Time index')\n    plt.ylabel('Reported cases')\n    plt.show()\n    return\nviz_polymonial()","d2cdf05d":"get_degree(day_index_m,dates_cases_m) #Sub-Dataset male","7ff5feeb":"get_degree(day_index_f,dates_cases_f) #Sub-Dataset female","fbd0fe72":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\npoly_reg = PolynomialFeatures(degree=14) #Use same DOF cause optimal DOF is identical\n\nX_poly_f = poly_reg.fit_transform(day_index_f)\npol_reg_f = LinearRegression()\npol_reg_f.fit(X_poly_f, dates_cases_f)\n\nX_poly_m = poly_reg.fit_transform(day_index_m)\npol_reg_m = LinearRegression()\npol_reg_m.fit(X_poly_m, dates_cases_m)\n\nfig, ax = plt.subplots(figsize = (20, 15))\n\ndef viz_polymonial():\n    plt.scatter(day_index_f, dates_cases_f, color='red')\n    plt.plot(day_index_f, pol_reg_f.predict(poly_reg.fit_transform(day_index_f)), color='red')\n    plt.scatter(day_index_m, dates_cases_m, color='blue')\n    plt.plot(day_index_m, pol_reg_m.predict(poly_reg.fit_transform(day_index_m)), color='blue')\n    plt.title('Polynomial regression cases M\/F')\n    plt.xlabel('Time Index')\n    plt.ylabel('Reported Cases')\n    plt.show()\n    return\nviz_polymonial()","e845bfd4":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\npoly_reg_m = PolynomialFeatures(degree=get_degree(day_index_m,dates_deaths_m))\npoly_reg_f = PolynomialFeatures(degree=get_degree(day_index_f,dates_deaths_f))\n\nX_poly_f = poly_reg_f.fit_transform(day_index_f)\npol_reg_f = LinearRegression()\npol_reg_f.fit(X_poly_f, dates_deaths_f)\n\nX_poly_m = poly_reg_m.fit_transform(day_index_m)\npol_reg_m = LinearRegression()\npol_reg_m.fit(X_poly_m, dates_deaths_m)\n\nfig, ax = plt.subplots(figsize = (20, 15))\n\n# Visualizing the Polymonial Regression results\ndef viz_polymonial():\n    plt.scatter(day_index_f, dates_deaths_f, color='red')\n    plt.plot(day_index_f, pol_reg_f.predict(poly_reg_f.fit_transform(day_index_f)), color='red')\n    plt.scatter(day_index_m, dates_deaths_m, color='blue')\n    plt.plot(day_index_m, pol_reg_m.predict(poly_reg_m.fit_transform(day_index_m)), color='blue')\n    plt.title('Polynomial Reg')\n    plt.xlabel('Zeitindex in Tagen')\n    plt.ylabel('Gemeldete Tode')\n    plt.show()\n    return\nviz_polymonial()","1df1b98d":"get_degree(day_index_m,dates_recovered_m) #All Data","620e495f":"get_degree(day_index_f,dates_recovered_f) #All Data","d8862419":"plt.rcParams.update(plt.rcParamsDefault)\nplt.clf()\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.linear_model import LinearRegression\npoly_reg = PolynomialFeatures(degree=14) #Same\n\nX_poly_f = poly_reg.fit_transform(day_index_f)\npol_reg_f = LinearRegression()\npol_reg_f.fit(X_poly_f, dates_recovered_f)\n\nX_poly_m = poly_reg.fit_transform(day_index_m)\npol_reg_m = LinearRegression()\npol_reg_m.fit(X_poly_m, dates_recovered_m)\n\nfig, ax = plt.subplots(figsize = (20, 15))\n\ndef viz_polymonial():\n    plt.scatter(day_index_f, dates_recovered_f, color='red')\n    plt.plot(day_index_f, pol_reg_f.predict(poly_reg.fit_transform(day_index_f)), color='red')\n    plt.scatter(day_index_m, dates_recovered_m, color='blue')\n    plt.plot(day_index_m, pol_reg_m.predict(poly_reg.fit_transform(day_index_m)), color='blue')\n    plt.title('Polynomial Reg')\n    plt.xlabel('Zeitindex in Tagen')\n    plt.ylabel('Gemeldete Genesungen')\n    plt.show()\n    return\nviz_polymonial()","ef7d19a9":"print('Kurtosis cases: {}'.format(kurtosis(sorted_df['cases'], fisher=True)))\nprint('Kurtosis deaths: {}'.format(kurtosis(sorted_df['deaths'], fisher=True)))\nprint('Kurtosis recoveries: {}'.format(kurtosis(sorted_df['recovered'], fisher=True)))","e91ce671":"print('Kurtosis cases: {}'.format(kurtosis(sorted_df['cases'], fisher=False)))\nprint('Kurtosis deaths: {}'.format(kurtosis(sorted_df['deaths'], fisher=False)))\nprint('Kurtosis recoveries: {}'.format(kurtosis(sorted_df['recovered'], fisher=False)))","7481c427":"print('Skew Cases: %.3f'%skew(sorted_df['cases']))\nprint('Skew Recovered: %.3f'%skew(sorted_df['recovered']))\nprint('Skew Deaths: %.3f'%skew(sorted_df['deaths']))","35ba895d":"print('Test whether cases data is normal disrtibuted: {}'.format(scipy.stats.anderson(sorted_df['cases'], dist='norm')))\nprint('Test whether cases data is gumbal distributed: {}'.format(scipy.stats.anderson(sorted_df['cases'], dist='gumbel')))\nprint('Test whether cases data is exponential distributed: {}'.format(scipy.stats.anderson(sorted_df['cases'], dist='expon')))\nprint('Test whether cases data is logisic distributed: {}'.format(scipy.stats.anderson(sorted_df['cases'], dist='logistic')))\nprint('##########################################################################')\nprint('Test whether deaths data is normal disrtibuted: {}'.format(scipy.stats.anderson(sorted_df['deaths'], dist='norm')))\nprint('Test whether deaths data is gumbal distributed: {}'.format(scipy.stats.anderson(sorted_df['deaths'], dist='gumbel')))\nprint('Test whether deaths data is exponential distributed: {}'.format(scipy.stats.anderson(sorted_df['deaths'], dist='expon')))\nprint('Test whether deaths data is logisic distributed: {}'.format(scipy.stats.anderson(sorted_df['deaths'], dist='logistic')))\nprint('##########################################################################')\nprint('Test whether revoered data is normal disrtibuted: {}'.format(scipy.stats.anderson(sorted_df['recovered'], dist='norm')))\nprint('Test whether recovered data is gumbal distributed: {}'.format(scipy.stats.anderson(sorted_df['recovered'], dist='gumbel')))\nprint('Test whether recovered data is exponential distributed: {}'.format(scipy.stats.anderson(sorted_df['recovered'], dist='expon')))\nprint('Test whether recovered data is logisic distributed: {}'.format(scipy.stats.anderson(sorted_df['recovered'], dist='logistic')))","c5d7a9db":"Mean = np.mean(sorted_df['cases'])\nSTD = np.std(sorted_df['cases'])\nk_cases = scipy.stats.kstest(sorted_df['cases'], 'norm', args=(Mean, STD))\n\nMean = np.mean(sorted_df['deaths'])\nSTD = np.std(sorted_df['deaths'])\nk_deaths = scipy.stats.kstest(sorted_df['deaths'], 'norm', args=(Mean, STD))\n\nMean = np.mean(sorted_df['recovered'])\nSTD = np.std(sorted_df['recovered'])\nk_rec = scipy.stats.kstest(sorted_df['recovered'], 'norm', args=(Mean, STD))\n\nprint('K-Test cases: {}'.format(k_cases))\nprint('K-Test deaths: {}'.format(k_deaths))\nprint('K-Test recoveries: {}'.format(k_rec))","d77ad59a":"stat, p = normaltest(sorted_df['cases'])\nprint('Statistics=%.3f, p=%.3f' % (stat, p)) \n\nalpha = 0.05\nif p > alpha:\n\tprint('Cases data is normal distributed (Can not reject H0)') \nelse:\n\tprint('Cases data is not normal distributed (Reject H0)') \nprint('##########################################################################')\nstat, p = normaltest(sorted_df['deaths']) \nprint('Statistics=%.3f, p=%.3f' % (stat, p)) \n\nalpha = 0.05 \nif p > alpha:\n\tprint('Deaths data is normal distributed (Can not reject H0)')\nelse:\n\tprint('Deaths data is not normal distributed (Reject H0)')\nprint('##########################################################################')\nstat, p = normaltest(sorted_df['recovered'])\nprint('Statistics=%.3f, p=%.3f' % (stat, p)) \n\nalpha = 0.05\nif p > alpha:\n\tprint('Recoveries data is normal distributed (Can not reject H0)')\nelse:\n\tprint('Recoveries data is not normal distributed (Reject H0)')","d5b59a85":"print('Cases: {}'.format(lilliefors(sorted_df['cases'], pvalmethod='table')))\nprint('Deaths: {}'.format(lilliefors(sorted_df['deaths'], pvalmethod='table')))\nprint('Recoveries: {}'.format(lilliefors(sorted_df['recovered'], pvalmethod='table')))","869c8e8a":"print('Pearson correlation cases\/recoveries: {}'.format(pearsonr(sorted_df['cases'],sorted_df['recovered'])[0]))\nprint('Pearson correlation cases\/deaths: {}'.format(pearsonr(sorted_df['cases'],sorted_df['deaths'])[0]))\nprint('Pearson correlation deaths\/recoveries: {}'.format(pearsonr(sorted_df['deaths'],sorted_df['recovered'])[0]))","36d778c7":"sorted_df.corr()","4c3cd4a1":"print('Kurtosis cases aggreg. data: {}'.format(kurtosis(dates_cases, fisher=True)))\nprint('Kurtosis deaths aggreg. data: {}'.format(kurtosis(dates_death, fisher=True)))\nprint('Kurtosis recoveries aggreg. data: {}'.format(kurtosis(dates_recovered, fisher=True)))","b7d610c4":"print('Kurtosis cases aggreg. data: {}'.format(kurtosis(dates_cases, fisher=False)))\nprint('Kurtosis deaths aggreg. data: {}'.format(kurtosis(dates_death, fisher=False)))\nprint('Kurtosis recoveries aggreg. data: {}'.format(kurtosis(dates_recovered, fisher=False)))","c6044420":"print('Skew Cases: %.3f'%skew(dates_cases))\nprint('Skew Recovered: %.3f'%skew(dates_death))\nprint('Skew Deaths: %.3f'%skew(dates_recovered))","78e5ead9":"print('Pearson correlation cases\/recoveries: {}'.format(pearsonr(dates_cases,dates_recovered)[0]))\nprint('Pearson correlation cases\/deaths: {}'.format(pearsonr(dates_cases,dates_death)[0]))\nprint('Pearson correlation deaths\/recoveries: {}'.format(pearsonr(dates_death,dates_recovered)[0]))","5e68a127":"df_male.describe(include = [np.number])","088f1923":"df_male.describe(include=['object'])","daffd283":"df_female.describe(include = [np.number])","cadd70dd":"df_female.describe(include=['object'])","72644222":"print('Difference variances cases: {}'.format(math.sqrt(math.pow(np.var(df_male['cases'])-np.var(df_female['cases']),2))))\nprint('Difference variances deaths: {}'.format(math.sqrt(math.pow(np.var(df_male['deaths'])-np.var(df_female['deaths']),2))))\nprint('Difference variances recoveries: {}'.format(math.sqrt(math.pow(np.var(df_male['recovered'])-np.var(df_female['recovered']),2))))","a264a499":"print('T-Statistic cases M\/F: {}'.format(stats.ttest_ind(df_male['cases'], df_female['cases'], equal_var=False))) #Welch-Test\nprint('T-Statistic deaths M\/F: {}'.format(stats.ttest_ind(df_male['deaths'], df_female['deaths'], equal_var=True)))\nprint('T-Statistic recoveries M\/F: {}'.format(stats.ttest_ind(df_male['recovered'], df_female['recovered'], equal_var=False))) #Welch-Test","a4999005":"print('Difference variances cases: {}'.format(math.sqrt(math.pow(np.var(np.array(dates_cases_m))-np.var(np.array(dates_cases_f)),2))))\nprint('Difference variances deaths: {}'.format(math.sqrt(math.pow(np.var(np.array(dates_deaths_m))-np.var(np.array(dates_deaths_f)),2))))\nprint('Difference variances recoveries: {}'.format(math.sqrt(math.pow(np.var(np.array(dates_recovered_m))-np.var(np.array(dates_recovered_f)),2))))\n\n","f5011649":"print('T-Statistic cases M\/F: {}'.format(stats.ttest_ind(np.array(dates_cases_m), np.array(dates_cases_f), equal_var=False))) #Welch-Test\nprint('T-Statistic deaths M\/F: {}'.format(stats.ttest_ind(np.array(dates_deaths_m), np.array(dates_deaths_f), equal_var=True))) #Welch-Test\nprint('T-Statistic recoveries M\/F: {}'.format(stats.ttest_ind(np.array(dates_recovered_m), np.array(dates_recovered_f), equal_var=False))) #Welch-Test","2827e3e3":"print(np.array(dates_cases_m).shape)\nprint(np.array(dates_cases_f).shape)","49a33203":"print(np.array(dates_deaths_m).shape)\nprint(np.array(dates_deaths_f).shape)","db73191b":"print(np.array(dates_recovered_m).shape)\nprint(np.array(dates_recovered_f).shape)","6ebab351":"dates_cases_m = dates_cases_m[:np.array(dates_recovered_f).shape[0]]\ndates_deaths_m = dates_deaths_m[:np.array(dates_deaths_f).shape[0]]\ndates_recovered_m = dates_recovered_m[:np.array(dates_recovered_f).shape[0]]","ab229657":"print('Korrelation nach Pearson zwischen Neuinfektionen M\/W: {}'.format(pearsonr(dates_cases_m,dates_cases_f)[0]))\nprint('Korrelation nach Pearson zwischen Tode M\/W: {}'.format(pearsonr(dates_deaths_m,dates_deaths_f)[0]))\nprint('Korrelation nach Pearson zwischen Genesungen M\/W: {}'.format(pearsonr(dates_recovered_m,dates_recovered_f)[0]))\n","f1cc6a09":"arr_m = [np.array(dates_cases_m), np.array(dates_deaths_m), np.array(dates_recovered_m)]\narr_f = [np.array(dates_cases_f), np.array(dates_deaths_f), np.array(dates_recovered_f)]","03ba3d0f":"print('Order x,y = Cases, Deaths, Recovered')\nnp.corrcoef(arr_m) # Male","7c2a4921":"print('Reihenfolge x,y = Cases, Deaths, Recovered')\nnp.corrcoef(arr_f) # Female","2e90b40c":"prob = 0.95\ncontigency= pd.crosstab(np.array(dates_cases_m), np.array(dates_cases_f))\ncontigency","3f5cfaee":"stat, p, dof, expected = chi2_contingency(contigency) \nchi2_contingency(contigency) \n\n\ncritical = chi2.ppf(prob, dof)\nprint('probability=%.3f, critical=%.3f, stat=%.3f' % (prob, critical, stat))\nif abs(stat) >= critical:\n\tprint('Dependent (Reject H0)')\nelse:\n\tprint('Independent (Can not reject H0)')\n# Interpretiere Hypothese anhand des p-Wertes\nalpha = 1.0 - prob\nprint('significance=%.3f, p=%.3f' % (alpha, p))\nif p <= alpha:\n\tprint('Dependent (Reject H0)')\nelse:\n\tprint('Independent (Can not reject H0)')","58fec11a":"X2 = stat\ndata = [np.array(dates_cases_m),np.array(dates_cases_f)]\nn = np.sum(data)\n#Choose smaller dimension: x or y => x\nminDim = 452-1\n\n#Berechne Cramer's V\nV = np.sqrt((X2\/n) \/ minDim)\n\nprint('Cramers V: {}'.format(V))","963731b3":"prob = 0.95\ncontigency= pd.crosstab(np.array(dates_deaths_m), np.array(dates_deaths_f))\ncontigency","35a783e2":"stat, p, dof, expected = chi2_contingency(contigency) \nchi2_contingency(contigency) \n\n\ncritical = chi2.ppf(prob, dof)\nprint('probability=%.3f, critical=%.3f, stat=%.3f' % (prob, critical, stat))\nif abs(stat) >= critical:\n\tprint('Dependent (Reject H0)')\nelse:\n\tprint('Independent (Can not reject H0)')\n# Interpretiere Hypothese anhand des p-Wertes\nalpha = 1.0 - prob\nprint('significance=%.3f, p=%.3f' % (alpha, p))\nif p <= alpha:\n\tprint('Dependent (Reject H0)')\nelse:\n\tprint('Independent (Can not reject H0)')","51a05203":"X2 = stat\ndata = [np.array(dates_deaths_m),np.array(dates_deaths_f)]\nn = np.sum(data)\n#Choose smaller dimension: x or y => x\nminDim = 452-1\n\n#Berechne Cramer's V\nV = np.sqrt((X2\/n) \/ minDim)\n\nprint('Cramers V: {}'.format(V))","b0a170e4":"prob = 0.95\ncontigency= pd.crosstab(np.array(dates_recovered_m), np.array(dates_recovered_f))\ncontigency","d98bbaed":"stat, p, dof, expected = chi2_contingency(contigency) \nchi2_contingency(contigency) \n\n\ncritical = chi2.ppf(prob, dof)\nprint('probability=%.3f, critical=%.3f, stat=%.3f' % (prob, critical, stat))\nif abs(stat) >= critical:\n\tprint('Dependent (Reject H0)')\nelse:\n\tprint('Independent (Can not reject H0)')\n\nalpha = 1.0 - prob\nprint('significance=%.3f, p=%.3f' % (alpha, p))\nif p <= alpha:\n\tprint('Dependent (Reject H0)')\nelse:\n\tprint('Independent (Can not reject H0)')","198d9249":"X2 = stat\ndata = [np.array(dates_recovered_m),np.array(dates_recovered_f)]\nn = np.sum(data)\n#Choose smaller dimension: x or y => x\nminDim = 452-1\n\nV = np.sqrt((X2\/n) \/ minDim)\n\nprint('Cramers V: {}'.format(V))","e4a471f2":"from scipy.stats import ranksums, wilcoxon\nranksums(np.array(dates_cases_m), np.array(dates_cases_f))","0fc6594b":"ranksums(np.array(dates_deaths_m), np.array(dates_deaths_f))","3f4a81fd":"ranksums(np.array(dates_recovered_m), np.array(dates_recovered_f))","1f7aa016":"wilcoxon(np.array(dates_deaths_m), np.array(dates_deaths_f),alternative=\"greater\")","2f7d185e":"wilcoxon(np.array(dates_deaths_m), np.array(dates_deaths_f))","a76b1ecc":"wilcoxon(np.array(dates_deaths_f), np.array(dates_deaths_m),alternative=\"greater\")","3e43415a":"wilcoxon(np.array(dates_recovered_m), np.array(dates_recovered_f))","eb806d8f":"# ***Analysis of Germany COVID-19 pandemic***\n## My hands on try for using python for data analytics and visualizations. Mostly compare the data in relation to the gender, but although other analytics where made.\n## Titles could be formatted in a more uniform way...it come's to my to-do list for the next analysis...I promise! ;) ","3a6a5944":"# **Advanced analysis of gender specific wave distributions by using polynomial regression**","47a5937a":"## Recoveries in relation to age group (CI = 0.95)","7d1cc8e4":"# **Use regression with tight time domain index from day 0 to day 150 for more precise analytic of 1st wave**","7384f0fb":"## Pearson...see section 2.","f3c0415d":"## Cases in relation to age group (CI = 0.95)","eb0ba433":"# Check normal distribution using D'Agostino Omnibus Test (H0\/H1 stays same)","636c85b0":"# Trim larger dataset to match length of smaller dataset\n## Yet just implemented case: dataset male > dataset female!","54a66195":"# Analyze correlation\n### Positive correlations imply that as x increases, so does y. Negative correlations imply that as x increases, y decreases.","9b73a6a1":"# Plot distribution of reported deaths for main dataset","58a4d918":"## => Right Skewed data","6d587347":"## High variance of datapoints after 2nd wave results in skip of 1st wave\n## Regression imply that 2nd wave started way before day 230","a18083e0":"## Deaths","d390f6f0":"# Time domain analysis with different hues\n## Cases in relation to age group (CI = STD)","28e6a57f":"# !!!Start of waves based on own interpretations! More precise identification at a later time!!!","a81fa1c2":"# Use T-Test for check Hypothesis H0 that both sub-datasets share same average of data (\u03bcX=\u03bcY). NON AGGREGATED DATA!\n## Measure variance for check whether using Welch-Test or not (use Welch-Test when sub-datasets variances differ)","c6891273":"## Deaths in relation to gender (CI = 0.95)","1e9991e5":"# Plot distribution of reported cases for main dataset","6a846de3":"# Plot distribution of aggregated reported cases for main dataset\n## Cases","be962f09":"# Kolmogorov-Smirnov test with hypothesis H0: Data come from normal distributed population","46e43c82":"## Compare regression cases M\/F","569f33cf":"## Regression Recoveries","f1bde9cb":"### Using Pearson: Norm => 3.0","9c5d45c5":"## => P-Value abote alpha=0.05 => Failed to reject H0. Gender specific sub-datasets share same averages WHEN AGGREGATED!","0486f60e":"# **1. Graphical analysis of data distributions**","5a49b613":"# **Check data distributions of aggregated main dataset**\n## Cases","2f8fe8ea":"# **2.2 Use aggregated sub-datasets M\/F**\n# Quick representation of sub-datasets","6e3ae33b":"## Compare regression recoveries M\/F","b90d198a":"# Wilcoxon-Test (alpha = 0.05)","eb257e82":"## => Stronger correlation of aggregated data towards non aggregated data","746a1583":"## => Extremely Leptokurtic ","6ba60325":"## Calculate Cramers V Deaths","d6b0c9f1":"# Use T-Test for check Hypothesis H0 that both sub-datasets share same average of data (\u03bcX=\u03bcY). AGGREGATED DATA!\n## Measure variance for check whether using Welch-Test or not (use Welch-Test when sub-datasets variances differ)","38c6fa95":"### => Males are dying sligthly more ","3543dbad":"## Recoveries","99c7d233":"## => There is a measureable correlation between the gender specific sub-datasets","a23d69ed":"# Skew","d7c9d12d":"## Deaths in relation to age group (CI = STD)","1fc7ce91":"## => P-Value way too low, reject H0 => \u03bcX\u2260\u03bcY","4f9e6206":"## Deaths in relation to age group (CI = 0.95)","e932a417":"# Aggregate daily reports for unique day indexes for main dataset and sub datasets","4382c971":"## Gender ratio of reported deaths","d6a5e32b":"## => Behaviour of regression curves between cases and recoveries between M\/F mostly identical. Differences can be visually identiefied between the deaths.","1b0c1a76":"# Quick representation of dataset","0758ba1b":"# Analyze correlation aggregated data\n### Positive correlations imply that as x increases, so does y. Negative correlations imply that as x increases, y decreases.","36128a04":"# Pearsons Chi Square to check independency of data\n## Cases","3d9d7b0e":"## Calculate Cramers V Recoveries","92645c36":"## Gender ratio of reported recoveries","5a033966":"# Split dataset for gender specific sub-datasets","e9873519":"## Cases in relation to gender (CI = STD)","3a0a2011":"## Deaths","58e4f29d":"# Kurtosis\n### Using Fisher: Norm => 0.0","d5232204":"# **Check data distributions of non aggregated main dataset**\n## Plot QQ-Plot","6ab6157b":"# **Advanced analysis of wave distribution by using polynomial regression**\n## Get best degree of freedom by simulating differend DOF-values mentioned at the beginning","4838acaa":"## Cases","94029743":"## Recoveries","ea00dc63":"## Gender ratio of reported cases ","84adef54":"## => Non aggregated data shows mostly no correlation except cases\/recovered","eb1c2feb":"## Compare regression deaths M\/F\n### Different DOF's indicated in earlier calculations","c7540b28":"## P-Value always < alpha=0.05. Reject H0","535b510f":"## Cases in relation to gender (CI = 0.95)","cdc86018":"## Calculate local minima between 2nd and 3rd wave to predict start of 3th wave more precisely","15efa20b":"## => Continuous reject H0 and choosing alternative hypothesis H1 that data does not come from normal distributed population","8c716b5e":"# Import packages and functions","33160d6c":"## Deaths","6a201fe8":"## Deaths in relation to gender (CI = STD)\n","b9f68500":"## Recoveries","c4ff6a82":"## There is a noticeable exceed of the mean from between day 20-30 until day 80. Probably our first wave.","1bf5192a":"## Calculate local minima between 3rd and 4th wave to predict \"start\" of 4th wave more precisely","0a30717e":"## Calculate Camers V Cases","c396230f":"## Recoveries in relation to age group (CI = 0.95)","a282de34":"## => Continuous reject H0 and choosing alternative hypothesis H1 that data does not follow given distributions","39de47ae":"# Kurtosis\n## Fisher...see section 2. ","3c2fbd57":"## Recoveries","d7754c24":"## Regression cases","bdd28af8":"# Check for type of destribution. Specify H0 hypothesis as: Data come from [insert type of distribution here] distribution","a4b4bd28":"# Normalize and clean dataset","59311a45":"# !!!Predicted fourth wave mainly due to high DOF! More data will show...!!!","e7b44514":"# **2.1 Use aggregated dataset**\n## => Aggregate cases\/deaths\/recoveries from all Germany for each unique day.\n## => Hypothesis tests share same results. So doesn't wrote them down.","321fe55e":"# Finally use lilliefors test for verify that H0 is not suitable","93a8b247":"## Regression Deaths","d55bed6c":"## Deaths","bad9bba6":"# Plot distribution of reported recoveries for main dataset","7e70e8f9":"## Recoveries in relation to gender (CI = STD)","ed915a72":"## Plot mean of reported cases for each state. Compare against grand-mean","4a90f8f5":"# Analyze correlation aggregated gender data\n### Positive correlations imply that as x increases, so does y. Negative correlations imply that as x increases, y decreases.","ce9ec8dc":"# **Plot infection waves from aggregated reported cases data**\n## Format dates to index","feb230b7":"# Import Dataset from Kaggle\n### Kudos to headsortails!!","2e453f39":"## Recoveries in relation to age group (CI = STD)","ab133149":"## => Right Skewed data","6bf62699":"# **2. Non-Graphical analytics of the dataset(s)**\n## Non aggregated data","8c49ec2f":"## => Cases\/Recoveries mostly STD, Platykurtic \n## => Deaths seems like hyperbolic or laplace, Leptokurtic\n","240d10c5":"# Skew","30753a16":"### => Data distirbutions are bimodal distributed"}}