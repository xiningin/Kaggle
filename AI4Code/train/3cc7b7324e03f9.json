{"cell_type":{"be16db8b":"code","a92cfcd4":"code","dc8e72a5":"code","9255b730":"code","74dd668a":"code","b0df2403":"code","a8376897":"code","95b1e6d9":"code","0cad347a":"code","3a6fec58":"code","54a7751b":"code","c2d3717e":"code","ceff49ee":"code","5c17a66f":"code","9e487688":"code","a80ec18c":"code","e20a759b":"code","378b7a8b":"code","3426bf06":"code","c082a8d4":"code","7224f617":"code","3da60c01":"code","3d16d3d4":"code","37fab94a":"code","b0f74478":"code","d8244ccb":"code","84b6e390":"code","50021d6d":"code","e7980cf4":"code","f4eace26":"code","eba72525":"code","260ba55e":"code","2c6c6b20":"code","c756ef9c":"code","b45498a1":"code","94de3d86":"code","1ece7d4d":"code","bf58c7c9":"code","e44c439b":"code","51ce969a":"code","306b23c5":"code","7e527baa":"code","26851dfd":"code","8095075a":"code","c2b28e56":"code","07dd58b2":"code","31ac59e7":"code","248e441a":"code","24e6a7db":"code","3fd378c1":"markdown"},"source":{"be16db8b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","a92cfcd4":"train_raw = pd.read_csv('..\/input\/commonlitreadabilityprize\/train.csv')\ntest_raw = pd.read_csv('..\/input\/commonlitreadabilityprize\/test.csv')\ntrain_raw.head()","dc8e72a5":"# split the excerpt to sentenses\nimport re\nalphabets= \"([A-Za-z])\"\nprefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\nsuffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\nstarters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\nacronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\nwebsites = \"[.](com|net|org|io|gov)\"\n\ndef split_into_sentences(text):\n    text = \" \" + text + \"  \"\n    text = text.replace(\"\\n\",\" \")\n    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n    text = re.sub(websites,\"<prd>\\\\1\",text)\n    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n    if \"\u201d\" in text: text = text.replace(\".\u201d\",\"\u201d.\")\n    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n    text = text.replace(\".\",\".<stop>\")\n    text = text.replace(\"?\",\"?<stop>\")\n    text = text.replace(\"!\",\"!<stop>\")\n    text = text.replace(\"<prd>\",\".\")\n    sentences = text.split(\"<stop>\")\n    sentences = sentences[:-1]\n    sentences = [s.strip() for s in sentences]\n    return sentences","9255b730":"# syllables in a word\ndef syllables_count(word):\n    #referred from stackoverflow.com\/questions\/14541303\/count-the-number-of-syllables-in-a-word\n    count = 0\n    vowels = 'aeiouy'\n    word = word.lower()\n    if word[0] in vowels:\n        count +=1\n    for index in range(1,len(word)):\n        if word[index] in vowels and word[index-1] not in vowels:\n            count +=1\n    if word.endswith('e'):\n        count -= 1\n    if word.endswith('le'):\n        count += 1\n    if count == 0:\n        count += 1\n    return count","74dd668a":"# no. of sentences in an excerpt\ndef noOfSentences(text):\n    return len(split_into_sentences(text))","b0df2403":"# no. of words in an excerpt\ndef noOfWords(text):\n    count = len(re.findall(\"[a-zA-Z_]+\", text))\n    return count","a8376897":"test_raw['target'] = ''","95b1e6d9":"test_raw[['id','excerpt','target']]","0cad347a":"train_raw[['id','excerpt','target']]","3a6fec58":"# union test and train data for later data transformation\ntrain_raw = pd.concat([test_raw[['id','excerpt','target']], train_raw[['id','excerpt','target']]])","54a7751b":"train_raw['No_Of_Words'] = train_raw.excerpt.apply(lambda x: noOfWords(x))","c2d3717e":"train_raw['No_Of_Sentences'] = train_raw.excerpt.apply(lambda x: noOfSentences(x))","ceff49ee":"train_raw['No_Of_Syllables'] = train_raw.excerpt.apply(lambda x: syllables_count(x))","5c17a66f":"# calculate the syllables difficulty\nsyllables_morethan_2 = [[syllables_count(x)>2 for x in excerpt.split()] for excerpt in train_raw.excerpt]\ntrain_raw['syllables_difficulty'] = [sum(x)\/len(x) for x in syllables_morethan_2]","9e487688":"train_raw.head(10)","a80ec18c":"# transform each word to a number according to Tokenizer\nfrom keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer(num_words=50000)\ntokenizer.fit_on_texts(train_raw.excerpt)\n\nexcept_tokenized = tokenizer.texts_to_sequences(train_raw.excerpt)","e20a759b":"# calculate the word difficulty according the index of word while tokenization\ntrain_raw['word_difficulty'] = [sum(x)\/len(x) for x in except_tokenized]","378b7a8b":"train_raw.tail()","3426bf06":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer()\ntfidf_vec = tfidf.fit_transform(train_raw.excerpt)\n# train_raw[tfidf.get_feature_names()] = tfidf_vec.toarray()","c082a8d4":"# # rename target to target in order to avoid conflicting with target word in excerpt\n# train_raw.rename(columns={'target':'target'}, inplace=True)\n# train_raw.head()","7224f617":"# np.shape(tfidf_vec.toarray())","3da60c01":"\n# len(tfidf.get_feature_names())","3d16d3d4":"train_raw = train_raw.reset_index(drop=True)","37fab94a":"word_vec = pd.DataFrame(tfidf_vec.toarray(), columns=tfidf.get_feature_names())\nword_vec.rename(columns={'id':'id_word','target':'target_word'}, inplace=True)\ntrain_raw = pd.concat([train_raw, word_vec], axis=1)","b0f74478":"train = train_raw.drop('excerpt',axis=1)","d8244ccb":"# calculate Average Words per Sentence (AWS)\ntrain['AWS'] = train.No_Of_Words\/train.No_Of_Sentences","84b6e390":"# calculate Average Syllables per Word (ASW)\ntrain['ASW'] = train.No_Of_Syllables\/train.No_Of_Words","50021d6d":"train.tail()","e7980cf4":"# drop unnecessary columns\ntrain = train.drop(['No_Of_Words','No_Of_Syllables','No_Of_Sentences'],axis=1)","f4eace26":"train.head(10)","eba72525":"# apply standard scaler to make all the features to a number btw -1 and 1\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ntrain[['AWS','ASW','word_difficulty','syllables_difficulty']] = scaler.fit_transform(train[['AWS','ASW','word_difficulty','syllables_difficulty']])","260ba55e":"train.head(10)","2c6c6b20":"# test = train.iloc[0:7, :]\n# train_model = train.iloc[8:, :]\n","c756ef9c":"test = train[train.target == '']\ntrain_model = train[train.target != '']","b45498a1":"# split train data to train and validation data for the sake of cross validation\nfrom sklearn.model_selection import train_test_split\n\nXtrain, Xtest, ytrain, ytest = train_test_split(train_model.drop(['id','target'],axis=1), \n                                                train_model.target, test_size=0.2, random_state=0)\n","94de3d86":"ytrain.head()","1ece7d4d":"# select model and train the model\n\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\n\ngb_model = GradientBoostingRegressor(n_estimators=133,  min_samples_leaf=15,subsample=0.83,\n                          max_depth=4,learning_rate=0.299,max_features='sqrt', \n                          min_samples_split=160,random_state=0)\ngb_model.fit(Xtrain, ytrain)\ny_pred1 = gb_model.predict(Xtest)\nmean_squared_error(y_pred1, ytest)","bf58c7c9":"from sklearn.svm import LinearSVR\nmodel_svr = LinearSVR()\nmodel_svr.fit(Xtrain, ytrain)\ny_pred1 = model_svr.predict(Xtest)\nmean_squared_error(y_pred1, ytest)","e44c439b":"from sklearn.linear_model import ElasticNet, LinearRegression, Ridge, Lasso, RidgeCV\nfrom sklearn.svm import LinearSVR, SVR\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import r2_score\n\n\nmodels = {'Elastic Net': ElasticNet(),\n          'Lasso': Lasso(),\n          'LinearRegression': LinearRegression(),\n          'MLPRegressor': MLPRegressor(),\n          'Ridge': Ridge(),\n          'LinearSVR': LinearSVR(),\n          'RandomForest': RandomForestRegressor(),\n#           'XGBoost': XGBRegressor(n_estimators=10,eta=0.1, tree_method='hist'), \n          'SVR': SVR(kernel = 'rbf')}","51ce969a":"mean_squared_errors = []\nr2_scores = []\nfor m in models.values():\n    print(m)\n    m.fit(Xtrain,ytrain)\n    preds = m.predict(Xtest)\n    mean_squared_errors.append(mean_squared_error(ytest,preds))\n    r2_scores.append(r2_score(ytest,preds))","306b23c5":"plt.style.use('ggplot')\nplt.figure(figsize=(12,5))\nplt.plot(models.keys(),mean_squared_errors,color='r',marker='o')\nplt.ylabel('Mean Squared Error')\nplt.title('Mean Squared Error by Model')\nplt.show()\nprint(mean_squared_errors)","7e527baa":"plt.figure(figsize=(12,5))\nplt.plot(models.keys(), r2_scores, color='b', marker='*')\nplt.ylabel('Coeff. of determination (R2 Score)')\nplt.title('R2 score by Model')\nplt.show()\n\nprint(r2_scores)","26851dfd":"# Best model\n\nmodel = Ridge(alpha=0.6)\nmodel.fit(Xtrain, ytrain)\n# print(model.alpha_)\ny_pred1 = model.predict(Xtest)\nmean_squared_error(y_pred1, ytest)","8095075a":"# predict test data using gb_model\ntest_pred = model.predict(test.drop(['id','target'],axis=1))\ntest_pred","c2b28e56":"submission = test","07dd58b2":"submission['target'] = np.round(test_pred,6)","31ac59e7":"submission = submission[['id','target']]","248e441a":"submission","24e6a7db":"# save to submission.csv file\nsubmission.to_csv('submission.csv', index=False)","3fd378c1":"The reading ease may be related to below few factors:\n* Average Words per Sentence (AWS): the no. of words are devided by the no. of sentences in an excerpt\n* Average Syllables per Word (ASW): the no. of syllables are devided by the no. of words in an excerpt\n* Word difficulty: the less frequent used words are easier\n* Syllable difficulty: no. of syllables in a word greater than 2 is regarded as a difficult word\n"}}