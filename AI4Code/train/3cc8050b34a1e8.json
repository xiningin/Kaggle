{"cell_type":{"e7030031":"code","51ccc5da":"code","44bdf797":"code","a7acc358":"code","aff92825":"code","d0ac2778":"code","65ca1946":"code","97b0f4c2":"code","8c911b92":"code","bcdf310a":"code","25b99aef":"code","8adb1a88":"code","6349e18f":"code","85eb0c3e":"code","8623a0c7":"code","99029273":"code","359d471b":"code","6b7a5492":"code","9be543bc":"markdown","9914fb90":"markdown","c1a03f65":"markdown","86474a71":"markdown","582aad8f":"markdown","eca929b9":"markdown","e7298133":"markdown","e9a08949":"markdown","f3c87ce8":"markdown","cb5233cf":"markdown"},"source":{"e7030031":"import pandas as pd\nimport numpy as np","51ccc5da":"test = pd.read_csv('..\/input\/test.csv.gz', index_col=False)\nsample_submission = pd.read_csv('..\/input\/sample_submission.csv.gz', index_col='ID')\ntransactions = pd.read_csv('..\/input\/sales_train.csv.gz', index_col=False)","44bdf797":"all_ones_submission = sample_submission.copy()\nall_ones_submission.item_cnt_month = 1\nall_ones_submission.head()","a7acc358":"all_ones_submission.to_csv('..\/allOnes.csv')","aff92825":"all_zeros_submission = sample_submission.copy()\nall_zeros_submission.item_cnt_month = 0\nall_zeros_submission.head()","d0ac2778":"all_zeros_submission.to_csv('..\/allZeros.csv')","65ca1946":"# I won't post the results of my submissions as that might constitute unfair \n# teaming but you can duplicate my work.\n# It's just as easy to calculate the variance of the test labels, I'll leave\n# that to the reader. ","97b0f4c2":"# First of all, we can only probe things that are in the test set\n\ntest_shops = test.shop_id.unique()\ntest_items = test.item_id.unique()\n\ntest_transactions = transactions[transactions.item_id.isin(test_items) & transactions.shop_id.isin(test_shops)]","8c911b92":"items_by_month = test_transactions.groupby(['date_block_num', 'item_id']).sum()\nitems_by_month = items_by_month.unstack('date_block_num')[['item_cnt_day']]\nitems_by_month.rename(columns={'item_cnt_day':'total_item_cnt'}, inplace=True)\nitems_by_month.fillna(0, inplace=True)\nitems_by_month.head()","bcdf310a":"# Let's find some items that didn't sell at all in the last two years of the train\n# data. We'll assume they didn't sell at all during the test period as well. \nlast_26_months = items_by_month[items_by_month.columns[7:]]\nitems_by_month[last_26_months.sum(axis=1)==0]","25b99aef":"# Didn't sell a single one since month 1. This is almost certainly going to be \n# 0 in the test sets. \nprobe_item = 13536","8adb1a88":"# We're just sort of hoping that this will be in the public test set and not the \n# private one. Run it a few times until the error we get is larger than $e_0$. \nshop_num = np.random.choice(test_shops)\nshop_num","6349e18f":"# We'll fill in a single row with this value\n# We want it big for numerical reasons. \nM = 500","85eb0c3e":"probe_submission = all_zeros_submission.copy()\nprobe_submission[(test.item_id==probe_item) & (test.shop_id==shop_num)] = M\n\nprobe_submission.to_csv('..\/testSizeProbe.csv')","8623a0c7":"# Again, not posting my results...have fun!","99029273":"# Note that this is just a random shop here - if you know one that's definitely \n# in the private test set you'll want to use that one instead. \nshop_num","359d471b":"probe_submission_2 = all_zeros_submission.copy()\nprobe_submission_2[test.shop_id==shop_num] = 20\n\nprobe_submission_2.to_csv('publicPrivateSplitProbe.csv')","6b7a5492":"# That's it! Just check and see if the error here is any different from $e_0$. ","9be543bc":"# Probe for the Mean and Variance\n\nWith the rmse from two constant submissions we can infer the mean and variance of the test data. ","9914fb90":"# Imports and Load Data","c1a03f65":"### Calculate Public Test Set Size\n\nLet $e_{size}$ be the rmse from our size probe, and let $e_0$, $n$, and $M$ be as above. Then because we have assumed that the true label for our probe item is 0 we know that\n$$e_{size}{}^2 = \\frac{1}{n}\\left(\\left(\\sum y_i{}^2\\right) + M^2\\right)$$\n$$e_{size}{}^2 - e_0{}^2 = \\frac{1}{n}M^2$$\n$$n = \\frac{M^2}{e_{size}{}^2 - e_0{}^2}$$\n\n#### Numerical Issues\nNote that we only get 5 decimal digits of precision for $e_0$ and $e_{size}$ so it's bad if they're too close together. For example if $e_0{}^2=1.11111...$ and $e_{size}{}^2 = 1.11113...$ then our best guess is $e_0{}^2 - e_{size}{}^2 = 0.00002...$ and this has only 1 digit of precision! (Python will output more digits, but they're not reliable.) That's not enough to calculate $n$. So we made $M$ larger to make $e_{size}$ more different from $e_0$. ","86474a71":"# Conclusion\nLeaderboard probing isn't real data science, it's a way to game the competition. But we get to do some fun math and if we want to win competitions then we probably need to do it. There's more leaderboard probing that we can do than I put in this notebook, I'm not giving away all my tricks just yet!","582aad8f":"## Find an item that probably didn't sell\nIf we know that the true label is 0 then we will know how much we've changed the error when we change our prediction for this item. ","eca929b9":"## Submit the Probe","e7298133":"# Leaderboard Probing\nThey mentioned in the coarse that it is possible to probe the leaderboard for some information about the public test set. In this competetion we get to probe both the public and private test sets, but you get a lot more submissions for the public leaderboard. In this notebook we'll take a look at a few basic leaderboard probes for the \"Final Project: Predict Future Sales\" competetion. ","e9a08949":"# Probe the Public\/Private Test Set Split\n\nDid the organizers split the test set by shop id, item id, randomly, or something else? Here we'll test whether or not they split by shop id. \n\nAssuming we got unlucky at least once above we've discovered a shop\/item pair that isn't in the public test set. We'll change the predictions from 0 to 20 for every item in that shop and see if the error changes at all. ","f3c87ce8":"## Calculating the mean\n\nLet $e_0$ be the rmse from our all zeros probe, $e_1$, be the rmse from our all ones probe, $n$ be the size of the public test set, and let $\\mu = \\frac{1}{n}\\sum{y_i}$ be the mean of the test labels. Then \n$$e_0{}^2 = \\frac{1}{n}\\sum{y_i{}^2}$$ and\n\n$$\\begin{eqnarray}\n e_1{}^2 &=& \\frac{1}{n}\\sum{(y_i{} - 1)^2} \\\\\n  &=& \\left(\\frac{1}{n}\\sum{y_i{}^2}\\right) - 2\\left(\\frac{1}{n}\\sum{y_i}\\right)  + \\frac{1}{n}\\sum{1} \\\\\n  &=& \\left(\\frac{1}{n}\\sum{y_i{}^2}\\right) - 2\\mu  + 1\n \\end{eqnarray}$$\n \n Thus\n \n$$\\begin{eqnarray}\ne_1{}^2 - e_0^2 &=& -2\\mu + 1 \\\\\n\\frac{e_1{}^2 - e_0^2 - 1}{-2} &=& \\mu\n\\end{eqnarray} $$","cb5233cf":"# Probe for the Public Test Set Size\n\nSeems like something we might like to know."}}