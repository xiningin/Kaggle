{"cell_type":{"30a33fe4":"code","8b6eb17c":"code","903ec061":"code","b9c14ebd":"code","7f91584b":"code","e3fef517":"code","04d8b83c":"code","06b87dab":"code","131885ff":"code","8db43bf6":"code","68aa0d63":"code","65cb1796":"code","a7eec38a":"code","25d29708":"code","cfaf6ddd":"code","03a59bb7":"code","c5bbfbf1":"code","0831e05e":"code","d276136d":"code","aaed01da":"code","d7c7fcf2":"code","6e54d2ba":"code","30dfb189":"code","d9b3aad7":"code","d801d090":"code","dfb17b74":"code","5b4ed9ea":"code","1f3ba6e9":"code","82736644":"code","c11f4648":"markdown","3887a47c":"markdown","581bb6f4":"markdown","6fc45f44":"markdown","1aec274c":"markdown","780a01e4":"markdown","75776b65":"markdown","4ae35215":"markdown","515ad370":"markdown"},"source":{"30a33fe4":"import torch\nprint(torch.__version__)\nprint(torch.version.cuda)","8b6eb17c":"!pip install torch-scatter -f https:\/\/pytorch-geometric.com\/whl\/torch-1.7.0+cu102.html\n!pip install torch-sparse -f https:\/\/pytorch-geometric.com\/whl\/torch-1.7.0+cu102.html\n!pip install torch-cluster -f https:\/\/pytorch-geometric.com\/whl\/torch-1.7.0+cu102.html\n!pip install torch-spline-conv -f https:\/\/pytorch-geometric.com\/whl\/torch-1.7.0+cu102.html\n!pip install torch-geometric\n!pip install captum","903ec061":"from torch_geometric.datasets.amazon import Amazon\nreview_type = \"computers\"\ndataset = Amazon(\"root\", review_type)\nprint(\"Selected reviews for \" + review_type)","b9c14ebd":"print(\"Number of graphs: %i\" % (len(dataset)))\n\ngraph = dataset[0]\nprint(\"Number of nodes: %i\" % (graph.num_nodes))\nprint(\"Number of features in node: %i\" % (graph.num_node_features))\n\nprint(\"Graph is homogenous, each node has features represented as bag of words vectors.\")\nprint()\n\nprint(\"Number of edge feature: %i\" %(graph.num_edge_features))\nprint(\"Edges number of edges: %i\" %(graph.edge_index.size()[1]))\n\nprint(\"Edges have no additional weights, connected edge means that items are frequently bought together.\")\nprint()\n\n\nprint(\"Example y classes: \" + str(graph.y[0:10].numpy()))\nprint(\"Minimal class index: \" + str(torch.min(graph.y).item()))\nprint(\"Maximal class index: \" + str(torch.max(graph.y).item()))\noutput_classes = (torch.max(graph.y)-torch.min(graph.y)+1).item()\nprint(\"Number of output classes: \" + str(output_classes))\nprint(\"Output variable represents 10 distinct product categories.\")","7f91584b":"#Splitting dataset\ntrain_percentage = 0.7\n\ndef assign_train_and_test_mask_property(data,train_percentage):\n    split_point = int(data.x.size()[0]*train_percentage)\n    data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n    data.train_mask[:split_point] = 1\n    data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n    data.test_mask[split_point:] = 1\n    \nassign_train_and_test_mask_property(graph,train_percentage)\nprint(\"Splitted tests by adding train_mask and test_mask with training set of size %i%%\" % (train_percentage*100))","e3fef517":"#Class distributions\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ntrain_class_counts = np.zeros(output_classes)\ntest_class_counts = np.zeros(output_classes)\n\nlabels = [\"C\" + str(i) for i in range(output_classes)]\n\nfor i in range(graph.num_nodes):\n    if graph.train_mask[i] == 1:\n        train_class_counts[graph.y[i]]+=1\n    else:\n        test_class_counts[graph.y[i]]+=1\n\n        \nprint(train_class_counts)\nprint(test_class_counts)\n","04d8b83c":"#Model\nfrom torch_geometric.nn.conv.gcn_conv import GCNConv\nimport torch.nn.functional as F \n\nclass GCNNetwork(torch.nn.Module):\n\n    def __init__(self, in_features, out_classes):\n        super(GCNNetwork, self).__init__()\n        self.gcn_conv1 = GCNConv(in_channels=in_features, out_channels=100)\n        self.gcn_conv2 = GCNConv(in_channels=100, out_channels=out_classes)\n        self.relu = torch.nn.ReLU()\n\n    def forward_data(self, data):\n        x = self.gcn_conv1(data.x, data.edge_index) \n        x = self.relu(x)\n        x = self.gcn_conv2(x, data.edge_index)\n        return x\n    \n    def forward(self, x, edge_index):\n        return self.forward_data(torch_geometric.data.Data(x=x,edge_index=edge_index))\n        ","06b87dab":"#Training configuration\n\nmodel = GCNNetwork(graph.num_node_features, output_classes)\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=0.001)\nnum_epochs = 200\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\ngraph = graph.to(device)","131885ff":"#Training loop\nimport time\n\ndef test(model, data):\n    model.eval()\n    log_probs, accs = model.forward_data(data), []\n    for _, mask in data('train_mask', 'test_mask'):\n        pred = log_probs[mask].max(1)[1]\n        acc = pred.eq(data.y[mask]).sum().item() \/ mask.sum().item()\n        accs.append(acc)\n    return accs\n\nfor epoch in range(num_epochs):\n    start_time = time.time()\n    #Train\n    model.train()\n    optimizer.zero_grad()\n\n    y_pred = model.forward_data(graph)[graph.train_mask]\n    y_target = graph.y[graph.train_mask]\n\n    loss = criterion(y_pred, y_target)\n\n    print (\"Loss: \" + str(loss))\n    loss.backward()\n    optimizer.step()\n\n    #Evaluate\n    if (epoch+1) % 5 == 0:\n        model.eval()\n        log = 'Epoch: {:03d}, Train: {:.4f}, Test: {:.4f}, Time in seconds: {:.4f}'\n        print(log.format(epoch+1, *test(model, graph), time.time()-start_time))\n\n    \nlog = 'Last Epoch: {:03d}, Train: {:.4f}, Test: {:.4f}, Time in seconds: {:.4f}'\nprint(log.format(epoch+1, *test(model, graph), time.time()-start_time))\n  ","8db43bf6":"#Saliency\nimport torch_geometric\nfrom captum.attr import Saliency\n\ndef custom_forward(x, edge_index):\n    return model(x.squeeze(), edge_index[0])\n\nig = Saliency(custom_forward)\nattr = ig.attribute(graph.x, additional_forward_args=((graph.edge_index.unsqueeze(0))), target=graph.y)\n\nprint(\"Node features size: \" + str(list(graph.x.size())))\nprint(\"Saliency attributes size: \" + str(list(attr.size())))\nprint()\nprint(\"Minimal saliency value: \" + str(torch.min(attr).item()))\nprint(\"Maximal saliency value: \" + str(torch.max(attr).item()))\nprint()\nprint(\"Top 5 saliency feature index: \" + str(torch.topk(torch.mean(attr,axis=0),5)))\nprint()\nprint(\"Top 5 saliency node index: \" + str(torch.topk(torch.mean(attr,axis=1),5)))\nprint()\n","68aa0d63":"class MaskedMatrix():\n    def __init__(self, matrix):\n        self.matrix= matrix\n        self.mask = np.ones_like(matrix)\n        \n    \n    def mask_rows(self,row_indexes):\n        for index in row_indexes:\n            self.mask_row(index)\n    \n    def mask_rows_except_for(self, row_indexes_to_leave):\n        all_rows_indexes = [i for i in range(self.matrix.shape[0])]\n        rows_to_mask = list(filter(lambda a: a not in row_indexes_to_leave, all_rows_indexes))\n        self.mask_rows(rows_to_mask)\n    \n    def mask_row(self,row_index):\n        self.mask[row_index,:] = np.zeros((1,self.mask.shape[1]))\n        \n    def mask_columns(self,column_indexes):\n        for index in column_indexes:\n            self.mask_column(index)\n    \n    def mask_columns_except_for(self, column_indexes_to_leave):\n        all_column_indexes = [i for i in range(self.matrix.shape[1])]\n        columns_to_mask = list(filter(lambda a: a not in column_indexes_to_leave, all_column_indexes))\n        self.mask_columns(columns_to_mask)\n    \n    \n    def mask_column(self,column_index):\n        self.mask[:,column_index] = np.zeros((self.mask.shape[0]))\n    \n    def masked_features(self):\n        return self.matrix * self.mask\n    \n    def get_mask():\n        return self.mask\n        \ntest_array =np.array([[1,2,3,4],\n                      [5,6,7,8],\n                      [9,10,11,12],\n                      [13,14,15,16]])\n\nmasked_matrix = MaskedMatrix(test_array)\nmasked_matrix.mask_row(0)\n\nprint(masked_matrix.mask)\n\nmasked_matrix.mask_column(1)\nprint(masked_matrix.mask)\n\nprint(masked_matrix.masked_features())\n\nprint(\"------------\")\n\n\nmasked_matrix2 = MaskedMatrix(test_array)\nmasked_matrix2.mask_columns_except_for([0,2])\nprint(masked_matrix2.masked_features())\n","65cb1796":"import copy \nfrom scipy.spatial import distance\nimport torch\n\ndef create_masked_graph_with_percentage_of_top_features(graph,x_attribution,percentage=0.1, is_reverse=False):\n    \"\"\"\n    Calculates masked graph\n    \n    is_reverse - when set to true mask will remove top percentage instead of leave\n    \"\"\"\n    \n    graph_cpy = copy.copy(graph)\n    \n    top_percentage_count = int(graph.x.size()[1] * percentage)\n    top_features = list(torch.topk(torch.mean(torch.abs(x_attribution),axis=0),top_percentage_count)[1])\n    \n    #TODO -> detach()?\n    masked_x = MaskedMatrix(graph_cpy.x.detach())\n    \n    if is_reverse:\n        masked_x.mask_columns_except_for(top_features)\n    else:\n        masked_x.mask_columns(top_features)\n    \n    graph_cpy.x = masked_x.masked_features()\n    return graph_cpy\n\ndef fidelity(y_true, y_pred_unmasked, y_pred_masked):\n    \"\"\"\n    y_true, y_pred_unmasked, y_pred_masked - tensor of predicted classes\n\n    Fidelity describes loss of accuracy under removal of least important features\n    \n    Positive value means that prediction without mask was better than the one with mask\n    By intuition removing less important features should provide little to no loss in accuracy (Smaller value better)\n    \n    \"\"\"\n    N = y_true.size()[0]\n    masked = torch.eq(y_true,y_pred_masked).int().sum()\n    unmasked = torch.eq(y_true,y_pred_unmasked).int().sum()\n    return ((unmasked - masked)\/N).item()\n\ndef infidelity(y_true, y_pred_unmasked, y_pred_masked_rev):\n    \"\"\"\n    Infideility describes loss of accuracy when major features are removed\n    \n    By intuition the greater value the better removed features described explaination (Greater value better)     \n    \"\"\"\n    \n    return fidelity(y_true, y_pred_unmasked, y_pred_masked_rev)\n\ndef node_reduction(masked_graph):\n    \"\"\"\n    This is the sparcity in respect to nodes\n    \n    https:\/\/arxiv.org\/pdf\/2012.15445.pdf\n    \"\"\"\n    \n    nodes = np.where(np.all(np.isclose(masked_graph.x.numpy(), 0), axis=1))[0]\n    zero_nodes_count = nodes.shape[0] \n    return zero_nodes_count\/masked_graph.x.size(0)\n\ndef feature_reduction(masked_graph):\n    x = masked_graph.x.numpy()\n    return np.nonzero(x)[0].shape[0] \/masked_graph.num_nodes \/masked_graph.num_node_features\n\n\ndef attribution_to_binary_heatmap_by_top_percentage(attribution, percentile=80 ):\n    percentile_value = np.percentile(attribution.flatten(), percentile)\n    return np.array( attribution > percentile_value ,dtype=np.int)\n\ndef node_positive_and_negative_heatmaps(node_idx, graph, attribution_method, attribution_call, output_classes, percentile=90):\n    correct_class = graph.y[node_idx]\n    incorrect_classes = [i for i in range(output_classes) if i != correct_class]\n    \n    correct_heatmap = attribution_to_binary_heatmap_by_top_percentage(attribution_call(attribution_method,graph), percentile)\n    \n    incorrect_heatmaps = []\n    for incorrect_class in incorrect_classes:\n        graph_cpy = copy.copy(graph)\n        graph_cpy.y[node_idx] = incorrect_class\n        incorrect_heatmaps.append(attribution_to_binary_heatmap_by_top_percentage(attribution_call(attribution_method,graph_cpy),percentile))\n    \n    negative_heatmap = np.array(incorrect_heatmaps[0],dtype=np.bool)\n    for i in range(1,len(incorrect_heatmaps)):\n        #TODO -> or or and?????\n        negative_heatmap = np.bitwise_and(negative_heatmap,np.array(incorrect_heatmaps[i],dtype=np.bool))\n        \n    \n    return correct_heatmap, np.array(negative_heatmap, dtype=np.int)\n\ndef concrascity(positive_heatmap, negative_heamap):\n    hamming_distance = distance.hamming(positive_heatmap.flatten(),negative_heamap.flatten())\n    common_part = np.sum(np.array(np.bitwise_or(np.array(positive_heatmap,dtype=np.bool),np.array(negative_heatmap,dtype=np.bool)),dtype=np.int))\n    return hamming_distance \/ common_part\n  \ndef sparsity(positive_heatmap, negative_heamap):\n    num_node_features = positive_heatmap.shape[0]*positive_heatmap.shape[1]\n    common_part = np.sum(np.array(np.bitwise_or(np.array(positive_heatmap,dtype=np.bool),np.array(negative_heatmap,dtype=np.bool)),dtype=np.int))\n    return 1- (common_part\/num_node_features)\n\n\ndef total_concrascity_and_sparcity(graph, attribution_method, attribution_call, output_classes, num_nodes=100, percentile=90):\n    assert num_nodes <= graph.num_nodes\n    \n    concrascities = []\n    sparcities = []\n    for i in range(num_nodes):\n        print(\"Processing (\" + str(i+1) + \"\/\" + str(num_nodes) + \")\")\n        positive_heatmap,negative_heatmap = node_positive_and_negative_heatmaps(0,graph, ig, attribution_call, output_classes)\n        concrascities.append(concrascity(positive_heatmap, negative_heatmap))\n        sparcities.append(sparsity(positive_heatmap, negative_heatmap))\n        \n        \n    return sum(concrascities)\/len(concrascities), sum(sparcities)\/len(sparcities)\n    \n\ny_pred_unmasked = torch.argmax(model.forward_data(graph),1)\nmasked_graph1 = create_masked_graph_with_percentage_of_top_features(graph,attr,is_reverse=False)\ny_pred_masked = torch.argmax(model.forward_data(masked_graph1) ,1)\ny_true = graph.y\n    \n\nmasked_graph2 = create_masked_graph_with_percentage_of_top_features(graph,attr,is_reverse=True)    \ny_pred_masked_rev = torch.argmax(model.forward_data(masked_graph2) ,1)\n\n\n# print(y[0])\nprint(y_pred.size())\nprint(y_true.size())\n\nprint(\"Fidelity: \" + str(fidelity(y_true, y_pred_unmasked, y_pred_masked)))\nprint(\"Infidelity: \" + str(infidelity(y_true, y_pred_unmasked, y_pred_masked_rev)))\nprint(\"Feature reduction (fidelity): \" + str(feature_reduction(masked_graph1)))\nprint(\"Feature reduction (infidelity): \" + str(feature_reduction(masked_graph2)))\n\nprint(\"Node reduction (fidelity): \" + str(node_reduction(masked_graph1)))\nprint(\"Node reduction (infidelity): \" + str(node_reduction(masked_graph2)))\n\n# attribution_call = lambda method,graph: method.attribute(graph.x, additional_forward_args=((graph.edge_index)), target=graph.y)\n# positive_heatmap,negative_heatmap = node_positive_and_negative_heatmaps(0,graph, ig, attribution_call, output_classes)\n# print(\"Node contrasctiy: \" + str(concrascity(positive_heatmap, negative_heatmap)))\n# print(\"Node sparsity: \" + str(sparsity(positive_heatmap, negative_heatmap)))\n\n# total_concrascity, total_sparsity = total_concrascity_and_sparcity(graph, ig, attribution_call, output_classes, num_nodes=20)\n# print(\"Total contrasctiy: \" + str(total_concrascity))\n# print(\"Total sparsity: \" + str(total_sparsity))\n","a7eec38a":"import matplotlib.pyplot as plt\n\ndef plot_importances(importances_list, title=''):\n    plt.title(title)\n    \n    xs = np.arange(len(importances_list))\n    ys = np.array(importances_list)\n    ys.sort()\n    ys = ys[::-1]\n    print(xs.shape)\n    print(ys[:20])\n    plt.bar(xs ,ys)\n    plt.show()\n\nnode_importances = torch.mean(attr,axis=1).tolist()\nplot_importances(node_importances,\"Node importances\")\n","25d29708":"feature_importances = torch.mean(attr,axis=0).tolist()\nplot_importances(feature_importances, \"Feature importances\")","cfaf6ddd":"#GradientShap\n\nfrom captum.attr import GradientShap\n\ndef custom_forward(x, edge_index):\n    return model(x.squeeze(), edge_index[0])\n\nig = GradientShap(custom_forward)\nattr = ig.attribute(graph.x, additional_forward_args=((graph.edge_index.unsqueeze(0))), target=graph.y, baselines=torch.zeros_like(graph.x))\n\nprint(\"Node features size: \" + str(list(graph.x.size())))\nprint(\"Attributes size: \" + str(list(attr.size())))\nprint()\nprint(\"Minimal GradientShap value: \" + str(torch.min(attr).item()))\nprint(\"Maximal GradientShap value: \" + str(torch.max(attr).item()))\nprint()\nprint(\"Top 5 GradientShap feature index: \" + str(torch.topk(torch.mean(torch.abs(attr),axis=0),5)))\nprint()\nprint(\"Top 5 GradientShap node index: \" + str(torch.topk(torch.mean(torch.abs(attr),axis=1),5)))\nprint()\n","03a59bb7":"node_importances = torch.mean(torch.abs(attr),axis=1).tolist()\nplot_importances(node_importances,\"Node importances [sorted]\")","c5bbfbf1":"feature_importances = torch.mean(torch.abs(attr),axis=0).tolist()\nplot_importances(feature_importances, \"Feature importances\")","0831e05e":"y_pred_unmasked = torch.argmax(model.forward_data(graph),1)\nmasked_graph1 = create_masked_graph_with_percentage_of_top_features(graph,attr,is_reverse=False)\ny_pred_masked = torch.argmax(model.forward_data(masked_graph1) ,1)\ny_true = graph.y\n    \n\nmasked_graph2 = create_masked_graph_with_percentage_of_top_features(graph,attr,is_reverse=True)    \ny_pred_masked_rev = torch.argmax(model.forward_data(masked_graph2) ,1)\n\n\nprint(\"Fidelity: \" + str(fidelity(y_true, y_pred_unmasked, y_pred_masked)))\nprint(\"Infidelity: \" + str(infidelity(y_true, y_pred_unmasked, y_pred_masked_rev)))\nprint(\"Feature reduction (fidelity): \" + str(feature_reduction(masked_graph1)))\nprint(\"Feature reduction (infidelity): \" + str(feature_reduction(masked_graph2)))\n\nprint(\"Node reduction (fidelity): \" + str(node_reduction(masked_graph1)))\nprint(\"Node reduction (infidelity): \" + str(node_reduction(masked_graph2)))\n\n# attribution_call = lambda method,graph: method.attribute(graph.x, additional_forward_args=((graph.edge_index.unsqueeze(0))), target=graph.y, baselines=torch.zeros_like(graph.x))\n# positive_heatmap,negative_heatmap = node_positive_and_negative_heatmaps(0,graph, ig, attribution_call, output_classes)\n# print(\"Node contrasctiy: \" + str(concrascity(positive_heatmap, negative_heatmap)))\n# print(\"Node sparsity: \" + str(sparsity(positive_heatmap, negative_heatmap)))\n\n# total_concrascity, total_sparsity = total_concrascity_and_sparcity(graph, ig, attribution_call, output_classes, num_nodes=20)\n# print(\"Total contrasctiy: \" + str(total_concrascity))\n# print(\"Total sparsity: \" + str(total_sparsity))\n","d276136d":"#DeepLift\n\n# from captum.attr import DeepLift\n\n# def custom_forward(x, edge_index):\n#     return model(x.squeeze(), edge_index[0])\n\n# ig = DeepLift(model)\n# attr = ig.attribute(graph.x, additional_forward_args=((graph.edge_index.unsqueeze(0))), target=graph.y, baselines=torch.zeros_like(graph.x))\n\n# print(\"Node features size: \" + str(list(graph.x.size())))\n# print(\"Attributes size: \" + str(list(attr.size())))\n# print()\n# print(\"Minimal DeepLift value: \" + str(torch.min(attr).item()))\n# print(\"Maximal DeepLift value: \" + str(torch.max(attr).item()))\n# print()\n# print(\"Top 5 DeepLift feature index: \" + str(torch.topk(torch.mean(torch.abs(attr),axis=0),5)))\n# print()\n# print(\"Top 5 DeepLift node index: \" + str(torch.topk(torch.mean(torch.abs(attr),axis=1),5)))\n# print()\nprint(\"Looks like DeepLift requires weights to be set\")","aaed01da":"#FeatureAblation\n\nfrom captum.attr import FeatureAblation\n\ndef custom_forward(x, edge_index):\n    return model(x.squeeze(), edge_index[0])\n\nig = FeatureAblation(custom_forward)\nattr = ig.attribute(graph.x, additional_forward_args=((graph.edge_index.unsqueeze(0))), target=graph.y, baselines=torch.zeros_like(graph.x))\n\nprint(\"Node features size: \" + str(list(graph.x.size())))\nprint(\"Attributes size: \" + str(list(attr.size())))\nprint()\nprint(\"Minimal FeatureAblation value: \" + str(torch.min(attr).item()))\nprint(\"Maximal FeatureAblation value: \" + str(torch.max(attr).item()))\nprint()\nprint(\"Top 5 FeatureAblation feature index: \" + str(torch.topk(torch.mean(torch.abs(attr),axis=0),5)))\nprint()\nprint(\"Top 5 FeatureAblation node index: \" + str(torch.topk(torch.mean(torch.abs(attr),axis=1),5)))\nprint()\n","d7c7fcf2":"node_importances = torch.mean(torch.abs(attr),axis=1).tolist()\nplot_importances(node_importances,\"Node importances [sorted]\")","6e54d2ba":"feature_importances = torch.mean(torch.abs(attr),axis=0).tolist()\nplot_importances(feature_importances, \"Feature importances\")","30dfb189":"y_pred_unmasked = torch.argmax(model.forward_data(graph),1)\nmasked_graph1 = create_masked_graph_with_percentage_of_top_features(graph,attr,is_reverse=False)\ny_pred_masked = torch.argmax(model.forward_data(masked_graph1) ,1)\ny_true = graph.y\n    \n\nmasked_graph2 = create_masked_graph_with_percentage_of_top_features(graph,attr,is_reverse=True)    \ny_pred_masked_rev = torch.argmax(model.forward_data(masked_graph2) ,1)\n\n\nprint(\"Fidelity: \" + str(fidelity(y_true, y_pred_unmasked, y_pred_masked)))\nprint(\"Infidelity: \" + str(infidelity(y_true, y_pred_unmasked, y_pred_masked_rev)))\nprint(\"Feature reduction (fidelity): \" + str(feature_reduction(masked_graph1)))\nprint(\"Feature reduction (infidelity): \" + str(feature_reduction(masked_graph2)))\n\nprint(\"Node reduction (fidelity): \" + str(node_reduction(masked_graph1)))\nprint(\"Node reduction (infidelity): \" + str(node_reduction(masked_graph2)))\n\n# attribution_call = lambda method,graph: method.attribute(graph.x, additional_forward_args=((graph.edge_index.unsqueeze(0))), target=graph.y, baselines=torch.zeros_like(graph.x))\n# positive_heatmap,negative_heatmap = node_positive_and_negative_heatmaps(0,graph, ig, attribution_call, output_classes)\n# print(\"Node contrasctiy: \" + str(concrascity(positive_heatmap, negative_heatmap)))\n# print(\"Node sparsity: \" + str(sparsity(positive_heatmap, negative_heatmap)))\n\n# total_concrascity, total_sparsity = total_concrascity_and_sparcity(graph, ig, attribution_call, output_classes, num_nodes=20)\n# print(\"Total contrasctiy: \" + str(total_concrascity))\n# print(\"Total sparsity: \" + str(total_sparsity))\n","d9b3aad7":"#IntegratedGradients\n\nfrom captum.attr import IntegratedGradients\n\ndef custom_forward(x, edge_index):\n    return model(x.squeeze(), edge_index[0])\n\nig = IntegratedGradients(custom_forward)\nattr = ig.attribute(graph.x, additional_forward_args=((graph.edge_index.unsqueeze(0))), target=graph.y, baselines=torch.zeros_like(graph.x))\n\nprint(\"Node features size: \" + str(list(graph.x.size())))\nprint(\"Attributes size: \" + str(list(attr.size())))\nprint()\nprint(\"Minimal IntegratedGradients value: \" + str(torch.min(attr).item()))\nprint(\"Maximal IntegratedGradients value: \" + str(torch.max(attr).item()))\nprint()\nprint(\"Top 5 IntegratedGradients feature index: \" + str(torch.topk(torch.mean(torch.abs(attr),axis=0),5)))\nprint()\nprint(\"Top 5 IntegratedGradients node index: \" + str(torch.topk(torch.mean(torch.abs(attr),axis=1),5)))\nprint()\n","d801d090":"node_importances = torch.mean(torch.abs(attr),axis=1).tolist()\nplot_importances(node_importances, \"Node importances\")","dfb17b74":"feature_importances = torch.mean(torch.abs(attr),axis=0).tolist()\nplot_importances(feature_importances, \"Feature importances\")","5b4ed9ea":"y_pred_unmasked = torch.argmax(model.forward_data(graph),1)\nmasked_graph1 = create_masked_graph_with_percentage_of_top_features(graph,attr,is_reverse=False)\ny_pred_masked = torch.argmax(model.forward_data(masked_graph1) ,1)\ny_true = graph.y\n    \n\nmasked_graph2 = create_masked_graph_with_percentage_of_top_features(graph,attr,is_reverse=True)    \ny_pred_masked_rev = torch.argmax(model.forward_data(masked_graph2) ,1)\n\n\nprint(\"Fidelity: \" + str(fidelity(y_true, y_pred_unmasked, y_pred_masked)))\nprint(\"Infidelity: \" + str(infidelity(y_true, y_pred_unmasked, y_pred_masked_rev)))\nprint(\"Feature reduction (fidelity): \" + str(feature_reduction(masked_graph1)))\nprint(\"Feature reduction (infidelity): \" + str(feature_reduction(masked_graph2)))\n\nprint(\"Node reduction (fidelity): \" + str(node_reduction(masked_graph1)))\nprint(\"Node reduction (infidelity): \" + str(node_reduction(masked_graph2)))\n\n# attribution_call = lambda method,graph: method.attribute(graph.x, additional_forward_args=((graph.edge_index.unsqueeze(0))), target=graph.y, baselines=torch.zeros_like(graph.x))\n# positive_heatmap,negative_heatmap = node_positive_and_negative_heatmaps(0,graph, ig, attribution_call, output_classes)\n# print(\"Node contrasctiy: \" + str(concrascity(positive_heatmap, negative_heatmap)))\n# print(\"Node sparsity: \" + str(sparsity(positive_heatmap, negative_heatmap)))\n\n# total_concrascity, total_sparsity = total_concrascity_and_sparcity(graph, ig, attribution_call, output_classes, num_nodes=20)\n# print(\"Total contrasctiy: \" + str(total_concrascity))\n# print(\"Total sparsity: \" + str(total_sparsity))","1f3ba6e9":"#GNNExplainer\n\nimport torch_geometric\n\nexplainer = torch_geometric.nn.GNNExplainer(model)\n\nnode_idx = 1\nnode_feat_mask, edge_mask = explainer.explain_node(node_idx,graph.x, graph.edge_index)\n\nmaximal_feature_importance = torch.max(node_feat_mask).item()\nmaximal_edge_importance = torch.max(edge_mask).item()\n\nprint(\"Maximal feature importance: %d \" % (maximal_feature_importance))\nprint(\"Maximal edge importance: %d \" % (maximal_edge_importance,))\nprint()\n\n# if maximal_feature_importance > 1e-8: \n#     print(\"Top 5 GNNExplainer feature indexes for node: \" + str(torch.topk(torch.mean(torch.abs(node_feat_mask),axis=0),5)))\n#     print()\n# else:\n#     print(\"GNN no feature importances assigned!!!\")\n#     print()\n\n    \n# if maximal_edge_importance >1e-8:\n#     explainer.visualize_subgraph(node_idx, graph.edge_index, edge_mask)\n# else:\n#     print(\"GNNExplainer edge visualization has proven to be unsuccessful when edges have no weights (importances = 0)\")","82736644":"explainer.visualize_subgraph(node_idx, graph.edge_index, edge_mask)\nplt.show()","c11f4648":"<h2> Integrated Gradients <\/h2>\n\n<img src=\"https:\/\/discuss.pytorch.org\/uploads\/default\/original\/3X\/c\/7\/c7e577fb1b096f649c0e338faeb15546caacf4f2.png\"><\/img>\n\n<img src=\"https:\/\/miro.medium.com\/max\/1250\/1*FM1npGt_RLRLSpWlJoF3sQ.png\"><\/img>\n\n<img src=\"https:\/\/miro.medium.com\/max\/1250\/1*pkYrYSBkfVksd19VjI4FtQ.png\"><\/img>\n\n<img src=\"https:\/\/miro.medium.com\/max\/1250\/1*429m9da6zUdf1M6GjUGDRA.png\"><\/img>","3887a47c":"<h2>GNNExplainer<\/h2>\n\n<img src=\"https:\/\/europepmc.org\/articles\/PMC7138248\/bin\/nihms-1062398-f0002.jpg\"\/>\n","581bb6f4":"<h2>Saliency <\/h2>\n<img src=\"https:\/\/www.guru99.com\/images\/1\/030819_0937_BackPropaga1.png\" width=\"600\" style=\"float:left\"><\/img>","6fc45f44":"<h1>Interpretation<\/h1>","1aec274c":"<img src=\"http:\/\/tkipf.github.io\/graph-convolutional-networks\/images\/gcn_web.png\" width=\"500\"><\/img>\n\nForward progagation\n\n<img src=\"https:\/\/miro.medium.com\/max\/480\/1*2cT063K_PIvJVRqFn8c5gg.png\"><\/img>\n\nNormalization (renormalization trick)\n\n<img src=\"https:\/\/miro.medium.com\/max\/424\/1*yd8uL8Ewj_C4ES5faZVUxg.png\"><\/img>\n\n\nSelf loops - we want to take information from node as well\n\n<img src=\"https:\/\/i.stack.imgur.com\/RTTKo.jpg\"><\/img>","780a01e4":"<h2> Gradient Shap <\/h2>\n\n${\\displaystyle \\phi _{i}(v)=\\sum _{S\\subseteq N\\setminus \\{i\\}}{\\frac {|S|!\\;(n-|S|-1)!}{n!}}(v(S\\cup \\{i\\})-v(S)).}$\n\n<img src=\"data:image\/png;base64,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\"><\/img>","75776b65":"<h1>Explaining Graph Neural Network Predictions with PyTorch Geometric and Captum<\/h1>\n\n<img src=\"https:\/\/miro.medium.com\/max\/1116\/1*AMTs2MPLKCwOZy4WaKbYTw.png\" width=\"500\"><\/img>\n\n<img src=\"https:\/\/captum.ai\/img\/captum_logo.svg\"  width=\"500\"><\/img>","4ae35215":"<h1>Model training<\/h1>","515ad370":"<h1> EDA <\/h1>\n\n<img src=\"https:\/\/assets.entrepreneur.com\/content\/3x2\/2000\/20190102185524-GettyImages-1053681812-crop.jpeg\" width=\"500\"><\/img>"}}