{"cell_type":{"71d5e3e7":"code","1a4f6f3e":"code","e394cffa":"code","c7fbf8f3":"code","aedcb06b":"code","ac90be82":"code","f1417bc1":"code","b1b3850f":"code","7721de6d":"code","b9c83419":"code","65f0bacc":"code","3e3fb9fb":"code","32a767c1":"code","ecce58d2":"code","27cb6cd7":"code","67fa315a":"code","1c15f8c8":"code","e8f28e8e":"code","74d1e5e8":"code","10cedcca":"code","84ec2f00":"code","92a96057":"code","1c057aa4":"code","206898ff":"code","f50919b6":"code","0a0e06dd":"code","66bd6407":"code","1bb1fc14":"code","fed360cd":"code","8b6b3a8c":"code","feb3797c":"code","1a0d3b8c":"code","8408c0b9":"code","f8a9b8fc":"code","b2aa9853":"code","3a52e3da":"code","26da24ad":"code","b082ab14":"code","690b3eb7":"code","5261712a":"code","7f51c8ff":"code","45751a34":"code","0b2b4432":"code","7446ad68":"code","5a9971ce":"code","75fdcb4b":"code","4904b96b":"code","a491e60a":"code","7f7cb43e":"code","2a3f85be":"code","bc16a857":"code","fd66a552":"code","a983b6be":"code","be837b38":"code","bb7e51e7":"code","7bfbac38":"code","cd30a2b1":"code","45e99d55":"code","f82413c1":"code","75739daf":"code","a93a195c":"code","9573f347":"code","70532944":"code","1e839722":"code","62a2d468":"code","bdb21f62":"code","ab06fcd5":"code","d6bafe4d":"code","c6ebeab0":"code","cbdacfc7":"code","d6fada9d":"code","b519e760":"code","8ff4267c":"code","08ea1425":"code","9e52879e":"code","338a1657":"code","a8064ea5":"code","115550f4":"code","f0a52681":"code","c45f2dd2":"code","454f4f57":"code","f71a4315":"code","f31f9333":"code","69812c46":"code","bc174162":"code","8d04a6cf":"markdown","487a04ae":"markdown","b56d607c":"markdown","735a5821":"markdown","069ffb56":"markdown","543df5b9":"markdown","29e89307":"markdown","d1cc1494":"markdown","dba75c54":"markdown","8788738f":"markdown","733bbb1c":"markdown","24d3982f":"markdown","3dc0e55d":"markdown","1b155826":"markdown","0426dc9d":"markdown","f21c927b":"markdown","90259d4e":"markdown","a95e5201":"markdown","338990b9":"markdown","5a5dd32b":"markdown","26b9d80b":"markdown","6fd6cc1f":"markdown","b7d7fa5c":"markdown"},"source":{"71d5e3e7":"#Let's import the necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport io\nimport os\nimport sys\nimport time\nimport json\nimport re\nfrom IPython.display import display\nfrom time import strftime, gmtime\n\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, KBinsDiscretizer, LabelEncoder\n# Column Transformer\nfrom sklearn.compose import ColumnTransformer","1a4f6f3e":"# Output columns\ncolumns = [\"Churn?\", \"State\", \"Account Length\", \"Area Code\", \"Int'l Plan\",\n           \"VMail Plan\", \"VMail Message\", \"Day Mins\", \"Day Calls\", \n           \"Eve Mins\", \"Eve Calls\", \n           \"Night Mins\", \"Night Calls\",\n           \"Intl Mins\", \"Intl Calls\",\n           \"CustServ Calls\"]","e394cffa":"#Let's import the dataset\ndf = pd.read_csv('..\/input\/customer-churn\/churn.csv')\npd.set_option('display.max_columns', 30)","c7fbf8f3":"df.head()","aedcb06b":"#let's check the datatypes of each feature\ndf.dtypes","ac90be82":"#Let's find out some infomration about the datasets\ndf.describe()","f1417bc1":"# Frequency tables for each categorical feature\nfor column in df.select_dtypes(include=['object']).columns:\n    display(pd.crosstab(index=df[column], columns='% observations', normalize='columns'))","b1b3850f":"# Histograms for each numeric features\nhist = df.hist(bins=30, sharey=True, figsize=(10, 10))","7721de6d":"df.drop(columns=['Phone'], inplace=True)\ndf['Area Code'] = df['Area Code'].astype(object)","b9c83419":"for column in df.select_dtypes(include=['object']).columns:\n    if column != 'Churn?':\n        display(pd.crosstab(index=df[column], columns=df['Churn?'], normalize='columns'))","65f0bacc":"for column in df.select_dtypes(exclude=['object']).columns:\n    print(column)\n    hist = df[[column, 'Churn?']].hist(by='Churn?', bins=30)\n    plt.show()","3e3fb9fb":"display(df.corr())","32a767c1":"# https:\/\/stackoverflow.com\/questions\/43217174\/how-can-the-sizes-and-rotations-of-text-of-a-pandas-scatter-matrix-be-set\nscatter_matrix = pd.plotting.scatter_matrix(df, figsize=(12, 12))\n\nfor ax in scatter_matrix.ravel():\n    ax.set_xlabel(ax.get_xlabel(), fontsize = 10, rotation = 45)\n    ax.set_ylabel(ax.get_ylabel(), fontsize = 10, rotation = 45)        \n    \nplt.show()    ","ecce58d2":"pd.plotting.scatter_matrix(df[['Day Charge','Day Mins','Day Calls']], figsize=(12, 12))\nplt.show()","27cb6cd7":"# Drop columns that are highly correlated with other columns\ndf.drop(columns=['Day Charge', 'Eve Charge', 'Night Charge', 'Intl Charge'], inplace=True)","67fa315a":"#missing data\ntotal = df.isnull().sum().sort_values(ascending=False)\npercent = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(25)","1c15f8c8":"#encode_features =  [\"Churn?\", \"State\", \"Int'l Plan\", \"VMail Plan\"]\n# df['Churn?'].unique()\n\nstate_list = ['AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA',\n       'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME',\n       'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM',\n       'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX',\n       'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY']\nchurn_list = ['False.', 'True.']\nplans = ['no', 'yes']\n\n# Encode Class Labels to integers\nstate_le = LabelEncoder()\nstate_le.fit(state_list)\n\nchurn_le = LabelEncoder()\nchurn_le.fit(churn_list)\n\nplans_le = LabelEncoder()\nplans_le.fit(plans)","e8f28e8e":"df.head()","74d1e5e8":"# Encode specific columns\ndf['State'] = state_le.transform(df['State'])\ndf['Churn?'] = churn_le.transform(df['Churn?'])\ndf[\"Int'l Plan\"] = plans_le.transform(df[\"Int'l Plan\"])\ndf[\"VMail Plan\"] = plans_le.transform(df[\"VMail Plan\"])","10cedcca":"df.head()","84ec2f00":"df.tail()","92a96057":"df.shape","1c057aa4":"# Customer churn is a binary label - no need to one hot encode\n# However, for multi-class classification, label needs to be one hot encoded for neural network training.\n\n# All other categorical features need to be \ncategorical_features =['State',\"Int'l Plan\",\"VMail Plan\",'Area Code']\n\nnumeric_features = ['Account Length','VMail Message',\n                    'Day Mins','Day Calls','Eve Mins','Eve Calls','Night Mins','Night Calls',\n                   'Intl Mins','Intl Calls','CustServ Calls']","206898ff":"categorical_features + numeric_features","f50919b6":"colTransformer = ColumnTransformer([('onehot',\n                                     OneHotEncoder(categories='auto',sparse=False),\n                                     categorical_features),\n                                    ('standardize',\n                                    StandardScaler(),numeric_features)\n                                   ],\n                                   remainder=\"passthrough\")","0a0e06dd":"colTransformer.fit(df[categorical_features + numeric_features])","66bd6407":"train_data, validation_data, test_data = np.split(df.sample(frac=1, random_state=1729), \n                                                  [int(0.7 * len(df)), int(0.9 * len(df))])","1bb1fc14":"print(train_data.shape,validation_data.shape,test_data.shape)","fed360cd":"train_data[columns].head()","8b6b3a8c":"train_data_transformed = colTransformer.transform (train_data[categorical_features + numeric_features])\n\nvalidation_data_transformed = colTransformer.transform (validation_data[categorical_features + numeric_features])\n\ntest_data_transformed = colTransformer.transform (test_data[categorical_features + numeric_features])","feb3797c":"print(train_data_transformed.shape, validation_data_transformed.shape, test_data_transformed.shape)","1a0d3b8c":"train_data['Churn?'].values","8408c0b9":"train_data_transformed = np.concatenate((np.array([train_data['Churn?']]).T, train_data_transformed),axis=1)\nvalidation_data_transformed = np.concatenate((np.array([validation_data['Churn?']]).T, validation_data_transformed),axis=1)\ntest_data_transformed = np.concatenate((np.array([test_data['Churn?']]).T, test_data_transformed),axis=1)","f8a9b8fc":"print(train_data_transformed.shape, validation_data_transformed.shape, test_data_transformed.shape)","b2aa9853":"train_data_transformed[:1]","3a52e3da":"# https:\/\/stackoverflow.com\/questions\/6081008\/dump-a-numpy-array-into-a-csv-file\n# Write Training Set\nnp.savetxt('train_onehot.csv',train_data_transformed,delimiter=\",\",fmt='%.5e')","26da24ad":"# Write Validation Set\nnp.savetxt('validation_onehot.csv',validation_data_transformed,delimiter=\",\",fmt='%.5e')","b082ab14":"# Write Test Set\nnp.savetxt('test_onehot.csv',test_data_transformed,delimiter=\",\",fmt='%.5e')","690b3eb7":"# Write Training Set\ntrain_data.to_csv('train.csv'\n                          ,index=False,header=False\n                          ,columns=columns)","5261712a":"# Write Validation Set\nvalidation_data.to_csv('validation.csv'\n                          ,index=False,header=False\n                          ,columns=columns)","7f51c8ff":"# Write Test Set\ntest_data.to_csv('test.csv'\n                          ,index=False,header=False\n                          ,columns=columns)","45751a34":"# Write Column List\nwith open('column_list.txt','w') as f:\n    f.write(','.join(columns))","0b2b4432":"# https:\/\/keras.io\/\n# https:\/\/github.com\/keras-team\/keras\/issues\/2743\n# Change Kernel to use Tensor Flow. For example: conda_tensorflow_p36\nimport sys\nimport numpy as np\n# Set random seed\nnp.random.seed(0)\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport itertools\n\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Column Transformer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, KBinsDiscretizer\n\n# Keras Library\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation","7446ad68":"ls","5a9971ce":"train_file = 'train_onehot.csv'\nvalidation_file = 'validation_onehot.csv'\ntest_file = 'test_onehot.csv'","75fdcb4b":"# Specify the column names as the file does not have column header\ndf_train = pd.read_csv(train_file, header=None)\ndf_validation = pd.read_csv(validation_file, header=None)\ndf_test = pd.read_csv(test_file, header=None)","4904b96b":"df_train.shape","a491e60a":"df_train.head()","7f7cb43e":"df_validation.head()","2a3f85be":"df_test.head()","bc16a857":"X_train = df_train.iloc[:,1:] # Features: 1st column onwards \ny_train = df_train.iloc[:,0].ravel() # Target: 0th column\n\nX_validation = df_validation.iloc[:,1:] # Features: 1st column onwards \ny_validation = df_validation.iloc[:,0].ravel() # Target: 0th column\n\nX_test = df_test.iloc[:,1:] # Features: 1st column onwards \ny_test = df_test.iloc[:,0].ravel() # Target: 0th column","fd66a552":"# https:\/\/keras.io\/getting-started\/sequential-model-guide\/\nmodel = Sequential()\n# 1 hidden layer with 30 neurons with relu activation\n# output layer - binaryclassification, so use sigmoid activation\n# optimizer - use adam or rmsprop\n# loss function - logistic loss function - called as binary cross entropy in keras\n# metrics - additional metrics to report\nmodel.add(Dense(30, activation='relu', input_dim=X_train.shape[1]))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","a983b6be":"from keras.callbacks import EarlyStopping","be837b38":"early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)","bb7e51e7":"# Train the model, iterating on the data in batches of 32 samples\nhistory = model.fit(X_train, y_train, epochs=20, batch_size=32,\n         validation_data=(X_validation,y_validation),callbacks=[early_stopping])","7bfbac38":"plt.scatter(x=history.epoch,y=history.history['loss'],label='Training Error')\nplt.scatter(x=history.epoch,y=history.history['val_loss'],label='Validation Error')\nplt.grid(True)\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Training Vs Validation Error')\nplt.legend()\nplt.show()","cd30a2b1":"# Predicts a binary outcome for each observation\nresult = model.predict(X_test)","45e99d55":"result[:10]","f82413c1":"column_list_file = 'column_list.txt'\ntest_file = 'test.csv'","75739daf":"columns = ''\nwith open(column_list_file,'r') as f:\n    columns = f.read().split(',')","a93a195c":"df_test = pd.read_csv(test_file,names=columns)","9573f347":"df_test['predicted_prob'] = result","70532944":"df_test['predicted_class'] = np.where(result > 0.5,1,0)","1e839722":"df_test[['Churn?','predicted_class', 'predicted_prob']].head(10)","62a2d468":"# Reference: https:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html\n# Explicitly stating labels. Pass=1, Fail=0\ndef true_positive(y_true, y_pred): \n    return confusion_matrix(y_true, y_pred,labels=[1,0])[0, 0]\n\ndef true_negative(y_true, y_pred): \n    return confusion_matrix(y_true,y_pred,labels=[1,0])[1, 1]\n\ndef false_positive(y_true, y_pred): \n    return confusion_matrix(y_true, y_pred,labels=[1,0])[1, 0]\n\ndef false_negative(y_true, y_pred): \n    return confusion_matrix(y_true, y_pred,labels=[1,0])[0, 1]","bdb21f62":"# Compute Binary Classifier Metrics\n# Returns a dictionary {\"MetricName\":Value,...}\n\ndef binary_classifier_metrics(y_true, y_pred):\n    metrics = {}\n\n    # References: \n    #  https:\/\/docs.aws.amazon.com\/machine-learning\/latest\/dg\/binary-classification.html\n    #  https:\/\/en.wikipedia.org\/wiki\/Confusion_matrix\n    \n    # Definition:\n    # true positive = tp = how many samples were correctly classified as positive (count)\n    # true negative = tn = how many samples were correctly classified as negative (count)\n    # false positive = fp = how many negative samples were mis-classified as positive (count)\n    # false_negative = fn = how many positive samples were mis-classified as negative (count)\n    \n    # positive = number of positive samples (count)\n    #          = true positive + false negative\n    # negative = number of negative samples (count)\n    #          = true negative + false positive\n    \n    tp = true_positive(y_true, y_pred)\n    tn = true_negative(y_true, y_pred)\n    fp = false_positive(y_true, y_pred)\n    fn = false_negative(y_true, y_pred)\n    \n    positive = tp + fn\n    negative = tn + fp\n    \n    metrics['TruePositive'] = tp\n    metrics['TrueNegative'] = tn\n    metrics['FalsePositive'] = fp\n    metrics['FalseNegative'] = fn\n    \n    metrics['Positive'] = positive\n    metrics['Negative'] = negative\n    \n    # True Positive Rate (TPR, Recall) = true positive\/positive\n    # How many positives were correctly classified? (fraction)\n    # Recall value closer to 1 is better. closer to 0 is worse\n    if tp == 0:\n        recall = 0\n    else:\n        recall = tp\/positive\n        \n    metrics['Recall'] = recall\n    \n    # True Negative Rate = True Negative\/negative\n    # How many negatives were correctly classified? (fraction)\n    # True Negative Rate value closer to 1 is better. closer to 0 is worse\n    if tn == 0:\n        tnr = 0\n    else:\n        tnr = tn\/(negative)\n    metrics['TrueNegativeRate'] = tnr\n    \n    # Precision = True Positive\/(True Positive + False Positive)\n    # How many positives classified by the algorithm are really positives? (fraction)\n    # Precision value closer to 1 is better. closer to 0 is worse\n    if tp == 0:\n        precision = 0\n    else:\n        precision = tp\/(tp + fp)\n    metrics['Precision'] = precision\n    \n    # Accuracy = (True Positive + True Negative)\/(total positive + total negative)\n    # How many positives and negatives were correctly classified? (fraction)\n    # Accuracy value closer to 1 is better. closer to 0 is worse\n    accuracy = (tp + tn)\/(positive + negative)\n    metrics['Accuracy'] = accuracy\n    \n    # False Positive Rate (FPR, False Alarm) = False Positive\/(total negative)\n    # How many negatives were mis-classified as positives (fraction)\n    # False Positive Rate value closer to 0 is better. closer to 1 is worse\n    if fp == 0:\n        fpr = 0\n    else:\n        fpr = fp\/(negative)\n    metrics['FalsePositiveRate'] = fpr\n    \n    # False Negative Rate (FNR, Misses) = False Negative\/(total Positive)\n    # How many positives were mis-classified as negative (fraction)\n    # False Negative Rate value closer to 0 is better. closer to 1 is worse\n    fnr = fn\/(positive)\n    metrics['FalseNegativeRate'] = fnr\n    \n    # F1 Score = harmonic mean of Precision and Recall\n    # F1 Score closer to 1 is better. Closer to 0 is worse.\n    if precision == 0 or recall == 0:\n        f1 = 0\n    else:        \n        f1 = 2*precision*recall\/(precision+recall)\n\n    metrics['F1'] = f1\n    \n    return metrics","ab06fcd5":"# Reference: \n# https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        #print(\"Normalized confusion matrix\")\n    #else:\n    #    print('Confusion matrix, without normalization')\n\n    #print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","d6bafe4d":"# Compute confusion matrix\n# 1 = customer left\/churn, 0 = stayed\ncnf_matrix = confusion_matrix(df_test['Churn?'], df_test['predicted_class'],labels=[1,0])","c6ebeab0":"# Plot confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix,classes=['Churn','Stay'],\n                      title='Customer Churn')","cbdacfc7":"# Plot confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['Churn','Stay'],\n                      title='Customer Churn - Fraction', normalize=True)","d6fada9d":"metrics = [binary_classifier_metrics(df_test['Churn?'], df_test['predicted_class'])]\ndf_metrics=pd.DataFrame.from_dict(metrics)\ndf_metrics.index = ['Model']","b519e760":"df_metrics","8ff4267c":"print('Counts')\nprint(df_metrics[['TruePositive',\n                  'FalseNegative',\n                  'FalsePositive',\n                  'TrueNegative',]].round(2))\nprint()\nprint('Fractions')\nprint(df_metrics[['Recall',\n                  'FalseNegativeRate',\n                  'FalsePositiveRate',\n                  'TrueNegativeRate',]].round(2))\nprint()\n\nprint(df_metrics[['Precision',\n                  'Accuracy',\n                  'F1']].round(2))","08ea1425":"print(classification_report(df_test['Churn?'], df_test['predicted_class'],\n                            labels=[1,0],\n                            target_names=['Churn','Stay']))","9e52879e":"df = df_test.sort_values('Churn?')\ndf = df.reset_index(drop=True)","338a1657":"stay = df[df['Churn?']==0]\nchurn = df[df['Churn?']==1]\n\nplt.figure()\nplt.scatter(df.index,df['Churn?'],label='Actual')\nplt.scatter(stay.index,stay['predicted_prob'],label='stay')\nplt.scatter(churn.index,churn['predicted_prob'],label='churn')\nplt.plot([df_test.index.min(),df_test.index.max()],[0.5,0.5],color='r')\nplt.xlim(left=0)\nplt.xlabel('Sample')\nplt.ylabel('Churn \/ Stay')\nplt.legend(loc=2)\nplt.show()","a8064ea5":"# ROC AUC Score - Measure of how Recall and False Alarm change at different cutoff thresholds\nfrom sklearn.metrics import roc_auc_score\nroc_score = roc_auc_score(df_test['Churn?'], df_test['predicted_prob'])\nprint('ROC AUC Score: {0:.3f}'.format(roc_score))","115550f4":"pd.crosstab(index=df_test['Churn?'], columns=np.where(df_test['predicted_prob'] > 0.5, 1, 0))","f0a52681":"cutoffs = np.arange(0.1, .9, 0.01)\ncosts = []\nfor c in cutoffs:\n    costs.append(np.sum(np.sum(np.array([[0, 100], [500, 100]]) * \n                               pd.crosstab(index=df_test['Churn?'],columns=np.where(df_test['predicted_prob'] > c, 1, 0)))))","c45f2dd2":"costs = np.array(costs)\nplt.plot(cutoffs, costs)\nplt.ylabel('Cost')\nplt.xlabel('Cutoff')\nplt.show()\n\nprint('Cost is minimized near a cutoff of:', cutoffs[np.argmin(costs)], 'for a cost of:', np.min(costs))","454f4f57":"stay = df[df['Churn?']==0]\nchurn = df[df['Churn?']==1]\n\nplt.figure()\nplt.scatter(df.index,df['Churn?'],label='Actual')\nplt.scatter(stay.index,stay['predicted_prob'],label='stay')\nplt.scatter(churn.index,churn['predicted_prob'],label='churn')\nplt.plot([df_test.index.min(),df_test.index.max()],[cutoffs[np.argmin(costs)],cutoffs[np.argmin(costs)]],color='r')\nplt.xlim(left=0)\nplt.xlabel('Sample')\nplt.ylabel('Churn \/ Stay')\nplt.legend(loc=2)\nplt.show()","f71a4315":"# Compute confusion matrix\ncnf_matrix = confusion_matrix(df['Churn?'], np.where(df['predicted_prob'] > cutoffs[np.argmin(costs)], 1, 0),labels=[1,0])\n\n# Plot confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['Churn','Stay'],\n                      title='Confusion Matrix at {0:0.2f}'.format(cutoffs[np.argmin(costs)]), normalize=True)\n","f31f9333":"# Compute confusion matrix\ncnf_matrix = confusion_matrix(df['Churn?'], np.where(df['predicted_prob'] > .5, 1, 0),labels=[1,0])\n\n# Plot confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['Churn','Stay'],\n                      title='Confusion Matrix at 0.5', normalize=True)","69812c46":"# Improved recall and f1-score with lower cutoff\n# However, precision has gone down\n# So, cutoff threshold is a tradeoff based on problem at hand\nprint(classification_report(df['Churn?'], np.where(df['predicted_prob'] > cutoffs[np.argmin(costs)], 1, 0),\n                            labels=[1,0],\n                            target_names=['Churn','Stay']))","bc174162":"print(classification_report(df['Churn?'], np.where(df['predicted_prob'] > 0.5, 1, 0),\n                            labels=[1,0],\n                            target_names=['Churn','Stay']))","8d04a6cf":"The continuous valued predictions coming from our model tend to skew toward 0 or 1, but there is sufficient mass between 0.1 and 0.9 that adjusting the cutoff should indeed shift a number of customers' predictions. For example...","487a04ae":"Next let's look at the relationship between each of the features and our target variable.","b56d607c":"# Need to concatenate Label to the data\nhttps:\/\/docs.scipy.org\/doc\/numpy\/reference\/generated\/numpy.concatenate.html\n* a = np.array([[1, 2], [3, 4]])\n* b = np.array([[5, 6]])\n* np.concatenate((b.T,a), axis=1)","735a5821":"We can see that changing the cutoff from 0.5 to 0.3 results in 1 more true positives, 3 more false positives, and 1 fewer false negatives. The numbers are small overall here, but that's 6-10% of customers overall that are shifting because of a change to the cutoff. Was this the right decision? We may end up retaining 3 extra customers, but we also unnecessarily incentivized 5 more customers who would have stayed. Determining optimal cutoffs is a key step in properly applying machine learning in a real-world setting. Let's discuss this more broadly and then apply a specific, hypothetical solution for our current problem.\n\nRelative cost of errors\nAny practical binary classification problem is likely to produce a similarly sensitive cutoff. That by itself isn\u2019t a problem. After all, if the scores for two classes are really easy to separate, the problem probably isn\u2019t very hard to begin with and might even be solvable with simple rules instead of ML.\n\nMore important, if I put an ML model into production, there are costs associated with the model erroneously assigning false positives and false negatives. I also need to look at similar costs associated with correct predictions of true positives and true negatives. Because the choice of the cutoff affects all four of these statistics, I need to consider the relative costs to the business for each of these four outcomes for each prediction.\n\nAssigning costs\nWhat are the costs for our problem of mobile operator churn? The costs, of course, depend on the specific actions that the business takes. Let's make some assumptions here.\n\nFirst, assign the true negatives the cost of $0. Our model essentially correctly identified a happy customer in this case, and we don\u2019t need to do anything.\n\nFalse negatives are the most problematic, because they incorrectly predict that a churning customer will stay. We lose the customer and will have to pay all the costs of acquiring a replacement customer, including foregone revenue, advertising costs, administrative costs, point of sale costs, and likely a phone hardware subsidy. A quick search on the Internet reveals that such costs typically run in the hundreds of dollars so, for the purposes of this example, let's assume $500. This is the cost of false negatives.\n\nFinally, for customers that our model identifies as churning, let's assume a retention incentive in the amount of $100.\n\nIf my provider offered me such a concession, I\u2019d certainly think twice before leaving. This is the cost of both true positive and false positive outcomes.\n\nIn the case of false positives (the customer is happy, but the model mistakenly predicted churn), we will waste the $100 concession. We probably could have spent that $100 more effectively, but it's possible we increased the loyalty of an already loyal customer, so that\u2019s not so bad.\n\n* Finding the optimal cutoff\n\nIt\u2019s clear that false negatives are substantially more costly than false positives. Instead of optimizing for error based on the number of customers, we should be minimizing a cost function that looks like this:\n\n$500 * FN(C) + $0 * TN(C) + $100 * FP(C) + $100 * TP(C)\n\nFN(C) means that the false negative percentage is a function of the cutoff, C, and similar for TN, FP, and TP. We need to find the cutoff, C, where the result of the expression is smallest.\n\nA straightforward way to do this, is to simply run a simulation over a large number of possible cutoffs. We test 100 possible values in the for loop below.","069ffb56":"* let's convert our categorical features into numeric features.","543df5b9":"# Binary Classifier Metrics","29e89307":"# Binary Classification using TensorFlow \nBuild the Neural Network using Keras - Easy and Portable across different implementations\nhttps:\/\/keras.io\/\n","d1cc1494":"# Data Visualization","dba75c54":"* Left side of plot has all \"stay\" samples - Majority of the samples are clustered near 0 (good) and only few are misclassified (above 0.5 threshold)\n* Right side of plot has all \"churn\" samples - Majority of the samples are above cutoff (good); however, few are misclassified (below 0.5 threshold)","8788738f":"# We can see immediately that:\n\n* State appears to be quite evenly distributed\n* Phone takes on too many unique values to be of any practical use. It's possible parsing out the prefix could have some value, but without more context on how these are allocated, we should avoid using it.\n* Only 14% of customers churned, so there is some class imabalance, but nothing extreme.\n* Most of the numeric features are surprisingly nicely distributed, with many showing bell-like gaussianity. VMail Message being a notable exception (and Area Code showing up as a feature we should convert to non-numeric).","733bbb1c":"* Great!, We do not have missing values","24d3982f":"# Missing Values","3dc0e55d":"# Welcome to my Tutorial Notebook\n# This notebook covers:\n* data preparation for training on neural networks\n* One hot encode all categorical features and Standardize numeric features\n* Customer Churn Prediction\n\nLosing customers is costly for any business. Identifying unhappy customers early on gives you a chance to offer them incentives to stay. This notebook describes using machine learning (ML) for the automated identification of unhappy customers, also known as customer churn prediction. ML models rarely give perfect predictions though, so this notebook is also about how to incorporate the relative costs of prediction mistakes when determining the financial outcome of using ML.","1b155826":"# Additional Data Transformation\n* One Hot Encoding of categorical features and Standardization of numeric features\n* Both these transformation are required for training on linear models and on neural network","0426dc9d":"* Let's get some inution about the correlation of each fatures","f21c927b":"# Build Model using Keras\nReference: https:\/\/keras.io\/getting-started\/sequential-model-guide\/","90259d4e":"# Store Original Format\n# Easy to assess performance","a95e5201":"# Data\nMobile operators have historical records on which customers ultimately ended up churning and which continued using the service. We can use this historical information to construct an ML model of one mobile operator\u2019s churn using a process called training. After training the model, we can pass the profile information of an arbitrary customer (the same profile information that we used to train the model) to the model, and have the model predict whether this customer is going to churn. Of course, we expect the model to make mistakes\u2013after all, predicting the future is tricky business! But I\u2019ll also show how to deal with prediction errors.\n\n# US mobile operator. The attributes are:\n\n* State: the US state in which the customer resides, indicated by a two-letter abbreviation; for example, OH or NJ\n* Account Length: the number of days that this account has been active\n* Area Code: the three-digit area code of the corresponding customer\u2019s phone number\n* Phone: the remaining seven-digit phone number\n* Int\u2019l Plan: whether the customer has an international calling plan: yes\/no\n* VMail Plan: whether the customer has a voice mail feature: yes\/no\n* VMail Message: presumably the average number of voice mail messages per month\n* Day Mins: the total number of calling minutes used during the day\n* Day Calls: the total number of calls placed during the day\n* Day Charge: the billed cost of daytime calls\n* Eve Mins, Eve Calls, Eve Charge: the billed cost for calls placed during the evening\n* Night Mins, Night Calls, Night Charge: the billed cost for calls placed during nighttime\n* Intl Mins, Intl Calls, Intl Charge: the billed cost for international calls\n* CustServ Calls: the number of calls placed to Customer Service\n* Churn?: whether the customer left the service: true\/false\n* The last attribute, Churn?, is known as the target attribute\u2013the attribute that we want the ML model to predict. Because the target attribute is binary, our model will be performing binary prediction, also known as binary classification.\n\nLet's begin exploring the data:","338990b9":"* We could use the Early Stopping Techniques to avoid from overfitting","5a5dd32b":"# Notice\nWe see several features that essentially have 100% correlation with one another. Including these feature pairs in some machine learning algorithms can create catastrophic problems, while in others it will only introduce minor redundancy and bias. Let's remove one feature from each of the highly correlated pairs: Day Charge from the pair with Day Mins, Night Charge from the pair with Night Mins, Intl Charge from the pair with Intl Mins:","26b9d80b":"The above chart shows how picking a threshold too low results in costs skyrocketing as all customers are given a retention incentive. Meanwhile, setting the threshold too high results in too many lost customers, which ultimately grows to be nearly as costly. The overall cost can be minimized at $8400 by setting the cutoff to 0.46, which is substantially better than the $20k+ I would expect to lose by not taking any action.","6fd6cc1f":"* Let's Visualize the relationship of each feature with the two types (False, True) of the Target","b7d7fa5c":"# Data Underestanding"}}