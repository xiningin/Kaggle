{"cell_type":{"9f70ad97":"code","d503e3a2":"code","27263ba0":"code","3d00fa3e":"code","7e97dbc3":"code","03116474":"code","66c4e27b":"code","89f0331c":"code","5b603965":"code","ba2a6f60":"code","39da23d7":"code","ad58ad24":"code","a54021d9":"code","b6e4c40c":"code","28315827":"code","2443ebde":"code","cfbaf392":"markdown","e1b4c5cb":"markdown","ed58df62":"markdown","e72d83c7":"markdown","c24f5d4a":"markdown","9d66b2c2":"markdown","a8914cae":"markdown","edae41cf":"markdown","a69c7617":"markdown"},"source":{"9f70ad97":"import xarray as xr\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport glob\nimport numpy as np\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt","d503e3a2":"all_data = []\nfor i, path in enumerate(sorted(glob.glob('\/kaggle\/input\/*.nc'))):\n    print('Reading', i, path)\n    ds  = xr.open_dataset(path)\n    data = torch.stack([torch.tensor(ds['tcc'].values), torch.tensor(ds['msl'].values)], dim=1)\n    resized = F.interpolate(data, size=(32, 64), mode='bilinear')\n    all_data.append(resized)\n    \nall_data = torch.cat(all_data, dim=0)","27263ba0":"all_data.size() # Shape of this is (num_observations, num_channels, height, width). The channels are tcc an msl.","3d00fa3e":"# Normalize the data to 0..1\nm = all_data.min(dim=0, keepdim=True)[0].min(dim=-1, keepdim=True)[0].min(dim=-2, keepdim=True)[0]\nM = all_data.max(dim=0, keepdim=True)[0].max(dim=-1, keepdim=True)[0].max(dim=-2, keepdim=True)[0]\nall_data = (all_data - m)\/(M - m)","7e97dbc3":"# A function to plot a TSNE with colors representing the seasons\ndef show_tsne(x, num_years=None):\n    x_embedded = TSNE(n_components=2, perplexity=30).fit_transform(x)\n    if num_years is None:\n        colors = plt.cm.jet(np.linspace(0,1,x.shape[0]))\n    else:\n        colors = plt.cm.cool(np.linspace(0,1,365))\n        colors = np.concatenate([colors,  colors[::-1]])\n        colors = np.concatenate([colors for _ in range(num_years)])\n    plt.scatter(x_embedded[:, 0], x_embedded[:, 1], s=5, c=colors)\n    plt.show()","03116474":"class Model(nn.Module):\n    def __init__(self, **kwargs):\n        super(Model, self).__init__(**kwargs)\n\n        self.conv_1 = nn.Conv2d(in_channels=2, out_channels=8, kernel_size=3, stride=2, padding=0)\n#         self.conv_1_2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n        self.conv_2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=2, padding=0)\n        self.conv_3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=0)\n        self.conv_4 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=0)\n#         self.linear = nn.Linear(in_features=192, out_features=8)\n\n    def forward(self, x):\n\n        x = self.conv_1(x).relu()\n        x = self.conv_2(x).relu()\n        x = self.conv_3(x).relu()\n        x = self.conv_4(x).relu()\n        x = x.flatten(start_dim=1)\n#         x = self.linear(x)\n\n        return x\n\nmodel = Model()","66c4e27b":"def get_triplet(batch_size=32, max_interval=10, device='cpu'):\n\n    i_ref = torch.randint(low=max_interval, high=all_data.size(0)-max_interval, size=(batch_size,), device=device)\n    i_neg = torch.randint(low=0, high=all_data.size(0), size=(batch_size,), device=device)\n\n    intervals = torch.randint(low=1, high=max_interval+1, size=(batch_size,), device=device)\n    signs = torch.rand(size=(batch_size,), device=device)\n    signs[signs>0.5] = 1\n    signs[signs<=0.5] = -1\n    i_pos = i_ref + signs.type(torch.int32)*intervals\n    \n    x_ref = all_data[i_ref]\n    x_pos = all_data[i_pos]\n    x_neg = all_data[i_neg]\n\n    return x_ref, x_pos, x_neg","89f0331c":"device = 'cuda'\nmodel = model.to(device)","5b603965":"all_data = all_data.to(device)","ba2a6f60":"optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\nrunning_loss_alpha = 0.99\nrunning_loss = 0","39da23d7":"for i in range(200000):\n\n    optimizer.zero_grad()\n    x_ref, x_pos, x_neg = get_triplet(device=device)\n\n    emb_ref = model(x_ref) # shape (batch_size, 192)\n    emb_pos = model(x_pos) # shape (batch_size, 192)\n    emb_neg = model(x_neg) # shape (batch_size, 192)\n\n    s_pos = torch.sum(emb_ref * emb_pos, dim=-1) # shape (batch_size,)\n    s_neg = torch.sum(emb_ref * emb_neg, dim=-1) # shape (batch_size,)\n\n    loss = -s_pos + torch.log(s_pos.exp() + s_neg.exp())\n    loss = loss.sum()\n\n    loss.backward()\n    optimizer.step()\n\n    running_loss = running_loss * running_loss_alpha + (1-running_loss_alpha) * loss.item()\n    \n    if (i+1) % 500 == 0:\n        print('step {0} - running loss {1}'.format(i + 1, running_loss))","ad58ad24":"torch.save(model.state_dict(), 'model.pth')","a54021d9":"show_tsne(all_data[:2*365*4].reshape(2*365*4, -1).cpu(), num_years=4)","b6e4c40c":"with torch.no_grad():\n    show_tsne(model(all_data[:2*365*8]).cpu(), num_years=8)","28315827":"# take = torch.rand(size=(all_data.size(0),)) < 0.1\nwith torch.no_grad():\n    predictions = all_data.flatten(start_dim=1)[take].cpu().numpy()\n\ncolors = plt.cm.cool(np.linspace(0,1,365))\ncolors = np.concatenate([colors,  colors[::-1]])\ncolors = np.concatenate([colors for _ in range(41)])\ncolors = np.concatenate([colors, colors[:20]])\ncolors = colors[take]\nx_embedded = TSNE(n_components=2, perplexity=30).fit_transform(predictions)\nplt.scatter(x_embedded[:, 0], x_embedded[:, 1], s=5, c=colors)\nplt.show()","2443ebde":"# take = torch.rand(size=(all_data.size(0),)) < 0.1\nwith torch.no_grad():\n    predictions = model(all_data[take]).cpu().numpy()\n\ncolors = plt.cm.cool(np.linspace(0,1,365))\ncolors = np.concatenate([colors,  colors[::-1]])\ncolors = np.concatenate([colors for _ in range(41)])\ncolors = np.concatenate([colors, colors[:20]])\ncolors = colors[take]\nx_embedded = TSNE(n_components=2, perplexity=30).fit_transform(predictions)\nplt.scatter(x_embedded[:, 0], x_embedded[:, 1], s=5, c=colors)\nplt.show()","cfbaf392":"## TSNE of the same observations in the embedding space","e1b4c5cb":"## Triplet generation\nWe define this function that will return batches of triplets for training.","ed58df62":"## Model\nWe define a simple convolutional feature extractor.","e72d83c7":"## Introduction\nWe map the raw msl and tcc data (input space) to an embedding space of low dimension with a CNN. We do that because we hope that analysing the data in this new space will be more fruitful than in the raw input space.\n\nThe input space has dimension 2\\*101\\*201 = 40602.\n\nThe CNN outputs an embedding of dimension 192.\n\nTo train the CNN, we use unsupervised contrastive learning. The objective that we optimize is defined on page 1 of http:\/\/proceedings.mlr.press\/v97\/saunshi19a\/saunshi19a.pdf. It means that we want similar samples to be close in the embedding space, whereas disimilar samples should be far away.\n\nHere, we take advantage of the temporal continuity of the data. Samples that are observed a few days apart will be similar whereas samples that are observed a long time apart are assumed to be disimilar with high probability.","c24f5d4a":"## TSNE of about 3000 observations sampled randomly from the 41 years in the raw data space","9d66b2c2":"We read the files and put the data in tensors","a8914cae":"## Training","edae41cf":"## TSNE of the 8 first years in the embedding space","a69c7617":"## TSNE of the raw data (4 first years)"}}