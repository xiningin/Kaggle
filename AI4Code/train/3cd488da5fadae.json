{"cell_type":{"6e263de0":"code","ec0ca9e4":"code","9d4308b0":"code","4b664277":"code","5aa79cf1":"code","4da11e1f":"code","73118f22":"code","240b079f":"code","88c9d90a":"code","eab560db":"code","43b33142":"code","e1679f06":"code","0d5140bc":"code","a5336e40":"code","66b0f063":"code","31ac7028":"code","23d83be6":"code","632db57b":"code","5cbaf0bf":"code","2c998e8e":"code","837ad600":"code","33490190":"code","1a796ac9":"code","2404c0f7":"code","775253c8":"code","4d70f087":"code","992a6956":"code","93a72a83":"code","f537259e":"code","72e3fd1a":"code","1a43622b":"code","99f12c04":"code","d5a00d5f":"markdown","507b48a1":"markdown","ea4e24f4":"markdown","719314c6":"markdown","38dd61fa":"markdown","ba259e6e":"markdown","ecee0343":"markdown","df78cc5c":"markdown"},"source":{"6e263de0":"!pip3 install https:\/\/github.com\/OlafenwaMoses\/ImageAI\/releases\/download\/2.0.2\/imageai-2.0.2-py3-none-any.whl","ec0ca9e4":"import pandas as pd\nimport numpy as np\nfrom bq_helper import BigQueryHelper\nfrom matplotlib import pyplot as plt\nimport skimage\nimport skimage.util\nimport cv2\nfrom urllib.request import urlretrieve\nfrom imageai.Prediction import ImagePrediction\nfrom tqdm import tqdm_notebook\n\n%matplotlib inline","9d4308b0":"open_images = BigQueryHelper(active_project=\"bigquery-public-data\", dataset_name=\"open_images\")\nopen_images.list_tables()","4b664277":"query = \"\"\"\n            SELECT *\n            FROM `bigquery-public-data.open_images.images` \n            WHERE image_id IN \n            (SELECT image_id\n            FROM `bigquery-public-data.open_images.labels`\n            WHERE label_name = '\/m\/01g317' and confidence > 0.8\n            LIMIT 10000\n            )\n            LIMIT 100\n            \n        \"\"\"\nurls = open_images.query_to_pandas_safe(query, max_gb_scanned=10)\nurls","5aa79cf1":"!mkdir images","4da11e1f":"# get only 300k quality images\nsamples = range(10)\nimage_url_samples_with_person = urls[\"thumbnail_300k_url\"].iloc[samples].tolist()\n\n# download images and load it in\nlist_images_samples = []\nfor img_file in image_url_samples_with_person:\n    img_data = skimage.io.imread(img_file)\n    np_img = np.array(img_data)\n    np_img = skimage.transform.resize(np_img, (256, 256))\n    \n    # convert grayscale images to rgb by just tinting the three dimensions\n    if len(np_img.shape) == 2:\n        np_img = skimage.color.gray2rgb(np_img)\n    \n    list_images_samples.append(np_img)","73118f22":"plt.figure(figsize=(20,20))\nplt.imshow(skimage.util.montage(np.array(list_images_samples[:9]), multichannel=True), cmap='gray')\nplt.title(\"Sample images\")\nplt.show()","240b079f":"!wget https:\/\/github.com\/OlafenwaMoses\/ImageAI\/releases\/download\/1.0\/yolo.h5","88c9d90a":"from imageai.Detection import ObjectDetection\n\ndetector = ObjectDetection()\ndetector.setModelTypeAsYOLOv3()\ndetector.setModelPath(\"yolo.h5\")\ndetector.loadModel()","eab560db":"plt.imshow((list_images_samples[0] * 255).astype(np.int32))","43b33142":"input_img = (list_images_samples[0] * 255).astype(np.int32)\ndetections = detector.detectObjectsFromImage(input_img, input_type='array', \n                                             minimum_percentage_probability=50, output_type='array')","e1679f06":"plt.imshow(detections[0])","0d5140bc":"list_image_detections = []\nlist_dict_results = []\n\nfor np_img in tqdm_notebook(list_images_samples):\n    input_img = (np_img * 255).astype(np.int32)\n    detections = detector.detectObjectsFromImage(input_img, input_type='array', \n                                                 minimum_percentage_probability=50, output_type='array')\n    \n    list_image_detections.append(detections[0])\n    list_dict_results.append(detections[1])","a5336e40":"plt.figure(figsize=(20,20))\nplt.imshow(skimage.util.montage(np.array(list_image_detections[:9]), multichannel=True), cmap='gray')\nplt.title(\"Objects detected in images using YOLO\")\nplt.show()","66b0f063":"list_dict_results[0]","31ac7028":"np_img_montage = skimage.util.montage(np.array(list_images_samples[:9]), multichannel=True)","23d83be6":"input_img = (np_img_montage * 255).astype(np.int32)\ndetections = detector.detectObjectsFromImage(input_img, input_type='array', \n                                             minimum_percentage_probability=50, output_type='array')","632db57b":"plt.figure(figsize=(20, 20))\nplt.imshow(detections[0])\nplt.title(\"Objects detected if all images are stitched and processed in one go\")","5cbaf0bf":"!wget https:\/\/github.com\/OlafenwaMoses\/ImageAI\/releases\/download\/1.0\/yolo-tiny.h5","2c998e8e":"from imageai.Detection import ObjectDetection\n\ndetector = ObjectDetection()\ndetector.setModelTypeAsTinyYOLOv3()\ndetector.setModelPath(\"yolo-tiny.h5\")\ndetector.loadModel()","837ad600":"list_image_detections = []\nlist_dict_results = []\n\nfor np_img in tqdm_notebook(list_images_samples):\n    input_img = (np_img * 255).astype(np.int32)\n    detections = detector.detectObjectsFromImage(input_img, input_type='array', \n                                                 minimum_percentage_probability=50, output_type='array')\n    \n    list_image_detections.append(detections[0])\n    list_dict_results.append(detections[1])","33490190":"plt.figure(figsize=(20,20))\nplt.imshow(skimage.util.montage(np.array(list_image_detections[:9]), multichannel=True), cmap='gray')\nplt.title(\"Detected objects using Tiny YOLO\")\nplt.show()","1a796ac9":"# get only 300k quality images\nsamples = range(10, 20)\nimage_url_samples_with_person = urls[\"thumbnail_300k_url\"].iloc[samples].tolist()\n\n# download images and load it in\nlist_images_samples = []\nfor img_file in image_url_samples_with_person:\n    img_data = skimage.io.imread(img_file)\n    np_img = np.array(img_data)\n    np_img = skimage.transform.resize(np_img, (256, 256))\n    \n    # convert grayscale images to rgb by just tinting the three dimensions\n    if len(np_img.shape) == 2:\n        np_img = skimage.color.gray2rgb(np_img)\n    \n    list_images_samples.append(np_img)","2404c0f7":"plt.figure(figsize=(20,20))\nplt.imshow(skimage.util.montage(np.array(list_images_samples[:9]), multichannel=True), cmap='gray')\nplt.title(\"Sample Images\")\nplt.show()","775253c8":"from imageai.Detection import ObjectDetection\n\ndetector = ObjectDetection()\ndetector.setModelTypeAsYOLOv3()\ndetector.setModelPath(\"yolo.h5\")\ndetector.loadModel()","4d70f087":"list_image_detections = []\nlist_dict_results = []\n\nfor np_img in tqdm_notebook(list_images_samples):\n    input_img = (np_img * 255).astype(np.int32)\n    detections = detector.detectObjectsFromImage(input_img, input_type='array', \n                                                 minimum_percentage_probability=50, output_type='array')\n    \n    list_image_detections.append(detections[0])\n    list_dict_results.append(detections[1])","992a6956":"plt.figure(figsize=(20,20))\nplt.imshow(skimage.util.montage(np.array(list_image_detections[:9]), multichannel=True), cmap='gray')\nplt.title(\"Objects detected in images using YOLO\")\nplt.show()","93a72a83":"list_dict_results[5]","f537259e":"# get only 300k quality images\nsamples = range(30, 40)\nimage_url_samples_with_person = urls[\"thumbnail_300k_url\"].iloc[samples].tolist()\n\n# download images and load it in\nlist_images_samples = []\nfor img_file in image_url_samples_with_person:\n    img_data = skimage.io.imread(img_file)\n    np_img = np.array(img_data)\n    np_img = skimage.transform.resize(np_img, (256, 256))\n    \n    # convert grayscale images to rgb by just tinting the three dimensions\n    if len(np_img.shape) == 2:\n        np_img = skimage.color.gray2rgb(np_img)\n    \n    list_images_samples.append(np_img)","72e3fd1a":"plt.figure(figsize=(20,20))\nplt.imshow(skimage.util.montage(np.array(list_images_samples[:9]), multichannel=True), cmap='gray')\nplt.title(\"Sample Images\")\nplt.show()","1a43622b":"list_image_detections = []\nlist_dict_results = []\n\nfor np_img in tqdm_notebook(list_images_samples):\n    input_img = (np_img * 255).astype(np.int32)\n    detections = detector.detectObjectsFromImage(input_img, input_type='array', \n                                                 minimum_percentage_probability=50, output_type='array')\n    \n    list_image_detections.append(detections[0])\n    list_dict_results.append(detections[1])","99f12c04":"plt.figure(figsize=(20,20))\nplt.imshow(skimage.util.montage(np.array(list_image_detections[:9]), multichannel=True), cmap='gray')\nplt.title(\"Objects detected in images using YOLO\")\nplt.show()","d5a00d5f":"Looks like it found nothing. Tiny YOLO is created for speed and fast detection jobs.","507b48a1":"# Object Detection Tasks","ea4e24f4":"# Stitch all the images together and run!","719314c6":"# Another sample","38dd61fa":"# Sample 3","ba259e6e":"# Let's try out tiny yolo v3","ecee0343":"## Perform everything in a loop","df78cc5c":"# Download a sampling of images"}}