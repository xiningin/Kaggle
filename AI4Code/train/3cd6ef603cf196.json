{"cell_type":{"9fda3e84":"code","36e6ecc1":"code","2b1e75de":"code","944dc567":"code","daa1c3f8":"code","df547bd8":"code","4b3ff885":"code","38b03134":"code","1ca79558":"code","33f2891c":"code","707f174c":"code","165bc372":"code","9dbcf282":"code","0dcfbdfa":"code","8ae83dc1":"code","78470918":"code","a3f30d35":"code","272128d2":"code","a9ec72a7":"code","5d089121":"code","66269cbf":"code","8481d171":"code","8a6041a1":"code","2df5a3b7":"code","518fdd53":"code","76229d9f":"code","e7263860":"code","dd2a7dc7":"code","b23773e9":"code","20d6bd32":"code","a2aa1af7":"code","82870c3c":"code","94eb1852":"code","6a863044":"code","8af398ee":"code","875ac5c7":"markdown","e93cdcf8":"markdown","d8bf2b33":"markdown","90b1b010":"markdown","8728a79b":"markdown","1f86bcb9":"markdown","813830fe":"markdown","a703925c":"markdown","7986c1de":"markdown"},"source":{"9fda3e84":"!pip install langdetect","36e6ecc1":"import numpy as np\nimport pandas as pd \nimport umap\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom langdetect import detect\nfrom tqdm import tqdm\n\ndef detect_lang(text):\n    try:\n        return detect(text)\n    except:\n        return \"unk\"","2b1e75de":"estate = pd.read_csv(\"..\/input\/kyiv-real-estate\/class_flat.csv\")\nestate.loc[estate['currency'] == 'UAH', 'price'] = estate.loc[estate['currency'] == 'UAH', 'price'] \/ 28\nestate.loc[estate['currency'] == 'UAH', 'price_sm'] = estate.loc[estate['currency'] == 'UAH', 'price_sm'] \/ 28\nestate['currency'] = (estate['currency'] == \"USD\").astype('int')\nestate.loc[estate['description'].isna(), 'description'] = \"\"\ntfidf_vectorizer = TfidfVectorizer(max_df=0.4, min_df=2,max_features=1000)\nX = tfidf_vectorizer.fit_transform(estate['description'])\nembedding = umap.UMAP(n_components=2, metric='hellinger').fit_transform(X)\nestate['description_1'] = embedding[:, 0]\nestate['description_2'] = embedding[:, 1]\nestate['description_lang'] = [1 if detect_lang(i) == 'uk' else 0 for i in tqdm(estate['description'])]\nestate = estate.drop(columns=['id', 'description', 'city', 'address', 'price'])\nestate = pd.get_dummies(estate)\nestate","944dc567":"estate = estate.loc[:, estate.sum() > 50]\nestate","daa1c3f8":"estate.info()","df547bd8":"from sklearn.impute import KNNImputer\n\nimputer = KNNImputer(n_neighbors=20)\n\ny_reg = estate['price_sm'].values\nx_reg = imputer.fit_transform(estate.drop(columns=['price_sm']).values)\nx_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(x_reg, y_reg, test_size=0.2, random_state=42)\n\ny_class = estate['bad_proposal'].values\nx_class = imputer.fit_transform(estate.drop(columns=['bad_proposal']).values)\nx_train_class, x_test_class, y_train_class, y_test_class = train_test_split(x_class, y_class, test_size=0.2, random_state=42)","4b3ff885":"y_test_reg.shape","38b03134":"from sklearn.ensemble import VotingClassifier\n\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\n#clf = QuadraticDiscriminantAnalysis(reg_param=0.05)\n\nlog_clf = LogisticRegression(random_state=1)  #QuadraticDiscriminantAnalysis(reg_param=0.05)#\nsvm_clf = SVC(C=10, gamma=0.001, random_state=1) #QuadraticDiscriminantAnalysis(reg_param=0.05)#\nknn_clf = KNeighborsClassifier(20, n_jobs=-1)\n\nvoting_clf = VotingClassifier(\n    #weights= [0.2, 0.7, 0.2],\n    estimators=[('logistic_regression', log_clf), ('knn', knn_clf), ('svc', svm_clf)], \n    voting='hard'\n) \n\nvot_model = voting_clf.fit(x_train_class, y_train_class) ","1ca79558":"from sklearn.metrics import accuracy_score\n\nfor clf in (log_clf, knn_clf, svm_clf, voting_clf):\n    clf.fit(x_train_class, y_train_class)\n    y_pred = clf.predict(x_test_class)\n    print(clf.__class__.__name__, accuracy_score(y_test_class, y_pred))","33f2891c":"qda_clf = QuadraticDiscriminantAnalysis(reg_param=0.05)\n\nlog_clf = LogisticRegression(random_state=1) \n\nfrom sklearn.tree import DecisionTreeClassifier\n\ntree_clf = DecisionTreeClassifier(\n    max_depth=5, \n    min_samples_leaf=21, \n    max_features=0.9, \n    criterion=\"gini\",                                    \n    random_state=1)\n\nvoting_clf = VotingClassifier( \n    weights = [0.3, 0.05, 0.3, 0.4],\n    estimators=[('lr', log_clf), ('knn', knn_clf), ('qda', qda_clf), ('tree', tree_clf)], voting='soft'\n    ) ","707f174c":"from sklearn.metrics import roc_auc_score\n\nfor clf in (log_clf, knn_clf, qda_clf, tree_clf, voting_clf):\n    clf.fit(x_train_class, y_train_class)\n    y_pred = clf.predict_proba(x_test_class)\n    print(clf.__class__.__name__, roc_auc_score(y_test_class, y_pred[:,1]))","165bc372":"from sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import VotingRegressor\n\nlin_reg = LinearRegression() \ndt_reg = DecisionTreeRegressor(\n    max_depth=5, \n    min_samples_leaf=10, \n    max_features=0.9, \n    criterion=\"mae\",                                    \n    random_state=1)\n\nknn_reg = KNeighborsRegressor(50, n_jobs=-1)\n\nvot_reg = VotingRegressor(estimators=[('lin', lin_reg), ('dt', dt_reg), ('knn', knn_reg)], weights=[0.39, 0.6, 0.01])","9dbcf282":"from sklearn.metrics import mean_squared_error, mean_absolute_error\nprint(\"model\\t\\t\\t RMSE\\t\\t\\t MAE\")\nfor reg in (lin_reg, knn_reg, dt_reg, vot_reg):\n    reg.fit(x_train_reg, y_train_reg)\n    y_pred = reg.predict(x_test_reg)\n    print(reg.__class__.__name__, \"\\t\", mean_squared_error(y_test_reg, y_pred)**0.5, \"\\t\", mean_absolute_error(y_test_reg, y_pred))","0dcfbdfa":"from sklearn.ensemble import BaggingClassifier \n\nbagging = BaggingClassifier(tree_clf, max_samples=0.85, max_features=0.85, random_state=1)\n\nbag_fit = bagging.fit(x_train_class, y_train_class)\n\nk = tree_clf.fit(x_train_class, y_train_class)\n\nroc_auc_score(y_test_class, k.predict_proba(x_test_class)[:,1]), roc_auc_score(y_test_class, bagging.predict_proba(x_test_class)[:,1])","8ae83dc1":"voting_clf = VotingClassifier( \n    weights = [0.15, 0.01, 0.15, 0.69],\n    estimators=[('lr', BaggingClassifier(log_clf, max_samples=0.85, max_features=0.85, random_state=1)), \n                ('knn', BaggingClassifier(knn_clf, max_samples=0.85, max_features=0.85, random_state=1)), \n                ('qda', BaggingClassifier(qda_clf, max_samples=0.85, max_features=0.85, random_state=1)), \n                ('tree', BaggingClassifier(tree_clf, max_samples=0.85, max_features=0.85, random_state=1))], voting='soft'\n    ) ","78470918":"from sklearn.metrics import roc_auc_score\n\nfor clf in (log_clf, knn_clf, qda_clf, tree_clf, voting_clf):\n    #clf = BaggingClassifier(clf, max_samples=0.85, max_features=0.85, random_state=1)\n    clf.fit(x_train_class, y_train_class)\n    y_pred = clf.predict_proba(x_test_class)\n    print(clf.__class__.__name__, roc_auc_score(y_test_class, y_pred[:,1]))","a3f30d35":"from sklearn.ensemble import RandomForestClassifier\n\nrnd_clf = RandomForestClassifier(max_depth=5,\n                                 n_estimators=1000, \n                                 max_features = 0.4,\n                                 max_samples = 0.4,\n                                 max_leaf_nodes=50, \n                                 min_samples_leaf = 20,  \n                                 n_jobs=-1, \n                                 verbose=1, \n                                 random_state=1)\n\nrnd_clf.fit(x_train_class, y_train_class)\n\ny_pred_rf = rnd_clf.predict_proba(x_test_class)\n\nroc_auc_score(y_test_class, y_pred_rf[:,1]), roc_auc_score(y_train_class, rnd_clf.predict_proba(x_train_class)[:,1])","272128d2":"pd.DataFrame({\n    'feature': estate.drop(columns=['bad_proposal']).columns,\n    'importance': rnd_clf.feature_importances_\n}).sort_values('importance', ascending=False).head(30)","a9ec72a7":"from sklearn.ensemble import RandomForestRegressor\n\nrnd_reg = RandomForestRegressor(max_depth=7,\n                                 n_estimators=100, \n                                 max_features = 0.6,\n                                 max_samples = 0.6,\n                                 max_leaf_nodes=400, \n                                 min_samples_leaf=10, \n                                criterion=\"mae\",\n                                 n_jobs=-1, \n                                 verbose=1, \n                                 random_state=1)\n\nrnd_reg.fit(x_train_reg, y_train_reg)\n\ny_pred_rf = rnd_reg.predict(x_test_reg)\n\nmean_absolute_error(y_test_reg, y_pred_rf), mean_absolute_error(y_train_reg, rnd_reg.predict(x_train_reg))","5d089121":"pd.DataFrame({\n    'feature': estate.drop(columns=['price_sm']).columns,\n    'importance': rnd_reg.feature_importances_\n}).sort_values('importance', ascending=False).head(30)","66269cbf":"from sklearn.ensemble import AdaBoostClassifier\n\nada_clf = AdaBoostClassifier(n_estimators=100, learning_rate=0.01)\n\nada_clf.fit(x_train_class, y_train_class)\n\ny_pred_rf = ada_clf.predict_proba(x_test_class)\n\nroc_auc_score(y_test_class, y_pred_rf[:,1]), roc_auc_score(y_train_class, ada_clf.predict_proba(x_train_class)[:,1])","8481d171":"pd.DataFrame({\n    'feature': estate.drop(columns=['bad_proposal']).columns,\n    'importance': ada_clf.feature_importances_\n}).sort_values('importance', ascending=False).head(30)","8a6041a1":"from sklearn.ensemble import GradientBoostingRegressor\n\nada_reg = GradientBoostingRegressor(n_estimators=200)\n\nada_reg.fit(x_train_reg, y_train_reg)\n\ny_pred = ada_reg.predict(x_test_reg)\n\nmean_absolute_error(y_test_reg, y_pred), mean_absolute_error(y_train_reg, ada_reg.predict(x_train_reg))","2df5a3b7":"pd.DataFrame({\n    'feature': estate.drop(columns=['price_sm']).columns,\n    'importance': ada_reg.feature_importances_\n}).sort_values('importance', ascending=False).head(30)","518fdd53":"import lightgbm\nfrom lightgbm import LGBMClassifier\n\ntrain_data = lightgbm.Dataset(x_train_class, label=y_train_class)\ntest_data = lightgbm.Dataset(x_test_class, label=y_test_class)\n\nparameters = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'is_unbalance': 'true',\n    'boosting': 'gbdt',\n    'num_leaves': 30,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.9,\n    'bagging_freq': 5,\n    'learning_rate': 0.05,\n    'verbose': 0\n}\n\nlgb_model = lightgbm.train(parameters,\n                       train_data,\n                       valid_sets=test_data,\n                       num_boost_round=5000,\n                       early_stopping_rounds=400)","76229d9f":"pd.DataFrame({\n    'variable': estate.drop(columns=['bad_proposal']).columns,\n    'importance': lgb_model.feature_importance(importance_type=\"gain\")\n}).sort_values('importance', ascending=False)","e7263860":"train_data = lightgbm.Dataset(x_train_reg, label=y_train_reg)\ntest_data = lightgbm.Dataset(x_test_reg, label=y_test_reg)\n\nparameters = {\n    'objective': 'regression',\n    'metric': 'l1',\n    'is_unbalance': 'true',\n    'boosting': 'gbdt',\n    'num_leaves': 100,\n    'feature_fraction': 0.9,\n    'bagging_fraction': 0.9,\n    'bagging_freq': 5,\n    'learning_rate': 0.01,\n    'verbose': 1\n}\n\nlgb_model = lightgbm.train(parameters,\n                       train_data,\n                       valid_sets=test_data,\n                       num_boost_round=5000,\n                       early_stopping_rounds=200)","dd2a7dc7":"pd.DataFrame({\n    'feature': estate.drop(columns=['price_sm']).columns,\n    'importance': lgb_model.feature_importance(importance_type=\"gain\")\n}).sort_values('importance', ascending=False).head(30)","b23773e9":"?xgb.XGBClassifier","20d6bd32":"import xgboost as xgb\n\nxg_class = xgb.XGBClassifier(\n    learning_rate=0.02, \n    max_delta_step=0, \n    max_depth=10,\n    min_child_weight=0.1, \n    missing=None, \n    n_estimators=500, \n    nthread=4,\n    importance_type=\"cover\",\n    objective='binary:logistic', \n    reg_alpha=0.01, \n    reg_lambda = 0.01,\n    scale_pos_weight=1, \n    seed=0, \n    silent=False, \n    subsample=0.9)\n\nxg_fit=xg_class.fit(x_train_class, y_train_class)\n\nroc_auc_score(y_test_class, xg_class.predict_proba(x_test_class)[:,1])","a2aa1af7":"pd.DataFrame({\n    'variable': estate.drop(columns=['bad_proposal']).columns,\n    'importance': xg_fit.feature_importances_\n}).sort_values('importance', ascending=False)","82870c3c":"print(\"\ud83d\ude00\")","94eb1852":"from catboost import CatBoostClassifier\n\ncat_model = CatBoostClassifier(\n    eval_metric='AUC', \n    use_best_model=True,\n    random_seed=42, iterations=20000)\n\ncat_model.fit(x_train_class, y_train_class, eval_set = (x_test_class, y_test_class))","6a863044":"pd.DataFrame({\n    'variable': estate.drop(columns=['bad_proposal']).columns,\n    'importance': cat_model.feature_importances_\n}).sort_values('importance', ascending=False)","8af398ee":"roc_auc_score(y_test_class, (xg_class.predict_proba(x_test_class)[:,1]*0.2+cat_model.predict_proba(x_test_class)[:,1]*0.3+lgb_model.predict(x_test_class)*0.3))","875ac5c7":"## \u041f\u0440\u0430\u043a\u0442\u0438\u0447\u043d\u0435 \u0437\u0430\u0432\u0434\u0430\u043d\u043d\u044f \u21162: Soft voting classifier","e93cdcf8":"## \u041f\u0440\u0430\u043a\u0442\u0438\u0447\u043d\u0435 \u0437\u0430\u0432\u0434\u0430\u043d\u043d\u044f \u21164: Random forest","d8bf2b33":"## \u041f\u0440\u0430\u043a\u0442\u0438\u0447\u043d\u0435 \u0437\u0430\u0432\u0434\u0430\u043d\u043d\u044f \u21161: Hard voting classifier","90b1b010":"# \u041f\u0440\u0430\u043a\u0442\u0438\u0447\u043d\u0430 \u0440\u043e\u0431\u043e\u0442\u0430 \u0437 \u0442\u0435\u043c\u0438 \"\u0410\u043d\u0441\u0430\u043c\u0431\u043b\u0456\"\n\n## \u041f\u0456\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0434\u043e \u043f\u0440\u0430\u043a\u0442\u0438\u0447\u043d\u043e\u0457 \u0440\u043e\u0431\u043e\u0442\u0438\n\n1. \u0417\u0430\u0432\u0430\u043d\u0442\u0430\u0436\u0435\u043d\u043d\u044f \u043e\u0441\u043d\u043e\u0432\u043d\u0438\u0445 \u0431\u0456\u0431\u043b\u0456\u043e\u0442\u0435\u043a \u0442\u0430 \u0444\u0443\u043d\u043a\u0446\u0456\u0439\n2. \u0417\u0430\u0432\u0430\u043d\u0442\u0430\u0436\u0435\u043d\u043d\u044f \u0434\u0430\u043d\u0438\u0445","8728a79b":"## \u041f\u0440\u0430\u043a\u0442\u0438\u0447\u043d\u0435 \u0437\u0430\u0432\u0434\u0430\u043d\u043d\u044f \u21168: Catboost","1f86bcb9":"## \u041f\u0440\u0430\u043a\u0442\u0438\u0447\u043d\u0435 \u0437\u0430\u0432\u0434\u0430\u043d\u043d\u044f \u21166: Lightgbm","813830fe":"## \u041f\u0440\u0430\u043a\u0442\u0438\u0447\u043d\u0435 \u0437\u0430\u0432\u0434\u0430\u043d\u043d\u044f \u21163: Bagging","a703925c":"## \u041f\u0440\u0430\u043a\u0442\u0438\u0447\u043d\u0435 \u0437\u0430\u0432\u0434\u0430\u043d\u043d\u044f \u21165: ADAboost & GBM","7986c1de":"## \u041f\u0440\u0430\u043a\u0442\u0438\u0447\u043d\u0435 \u0437\u0430\u0432\u0434\u0430\u043d\u043d\u044f \u21167: XGBoost"}}