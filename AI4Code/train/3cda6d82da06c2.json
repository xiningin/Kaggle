{"cell_type":{"1c2820df":"code","2c303acd":"code","da235861":"code","2d2862a4":"code","41097b94":"code","af7f507a":"code","2a49e9d1":"code","10430405":"code","2e9f68a0":"code","5b9327bd":"code","f2647887":"code","3929ea15":"code","7084056a":"code","5b70a467":"code","e9128d88":"code","85987691":"code","4941bfe7":"code","b76c7b8d":"code","649a1747":"code","5ee0991f":"code","02379950":"code","0916054f":"code","8e515d9e":"code","98340753":"code","baf29e78":"code","5d1b575b":"code","ecb91348":"code","ca5ba387":"code","99756df8":"code","816fceb1":"code","595ad4ed":"code","070cd99b":"code","884bb0a5":"code","f403bee1":"code","848a4629":"code","5c2b134d":"code","dc566be3":"code","208b0137":"code","2e2bad9f":"code","36bc326a":"code","d54867e8":"code","46df21de":"code","3ba1eb15":"code","0d2022c9":"code","84a34e19":"code","c9f5838c":"code","52146635":"code","f6122dae":"code","9bb2f9a9":"code","7a9886c1":"code","fa9c4269":"code","b891448c":"code","fa3d4e02":"code","4ba3b226":"code","4aa38514":"code","4dd1fbf6":"code","ef91b5b1":"code","00fc24d8":"code","fdd58dea":"code","983a5580":"code","a4a2807e":"code","165c6b52":"code","df828ae3":"markdown","70c0d17f":"markdown","45f761c7":"markdown","62866783":"markdown","ab936966":"markdown","d3d4058e":"markdown","3eb9998e":"markdown","810e34df":"markdown","3fd1bafa":"markdown","54762d7f":"markdown","5075f1e6":"markdown","f8a8c80f":"markdown","52279c49":"markdown"},"source":{"1c2820df":"# Clear Ipython memory\n%reset -f\n\n# 1.1 Data manipulation and plotting modules\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# 1.2 Data pre-processing\n#     z = (x-mean)\/stdev\nfrom sklearn.preprocessing import StandardScaler as ss\n\n# 1.3 Dimensionality reduction\nfrom sklearn.decomposition import PCA\n\n# 1.4 Data splitting and model parameter search\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# 1.5 Modeling modules\nfrom sklearn.preprocessing import StandardScaler\nfrom xgboost.sklearn import XGBClassifier\n\n# 1.6 Model pipelining\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import make_pipeline\n\n# 1.7 Model evaluation metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import auc, roc_curve\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_recall_fscore_support\n\n# 1.8\nimport matplotlib.pyplot as plt\nfrom xgboost import plot_importance\n\n# 1.9 Needed for Bayes optimization\nfrom sklearn.model_selection import cross_val_score\n\n# 1.10 Install as: pip install bayesian-optimization\nfrom bayes_opt import BayesianOptimization\n\n# 1.11 Find feature importance of ANY BLACK BOX estimator\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\n# 1.12 Misc\nimport time\nimport os\nimport gc\nimport random\nfrom scipy.stats import uniform","2c303acd":"# 1.13 Set option to dislay many rows\npd.set_option('display.max_columns', 100)","da235861":"# 2.1 Set working directory\n\n#os.chdir(\"F:\\\\Practice\\\\Machine Learning and Deep Learning\\\\Classes\\\\Assignment\\\\Kaggle\\\\3rd\")\nos.chdir(\"..\/input\") \nos.listdir()","2d2862a4":"#Data\ntr_f = \"winequalityN.csv\"\n\ndata = pd.read_csv(\n         tr_f,\n         header=0)\n","41097b94":"data.isnull().sum()","af7f507a":"data = data.dropna(axis=0)","2a49e9d1":"data.head()","10430405":"data.shape","2e9f68a0":"data.describe()","5b9327bd":"data.corr()","f2647887":"sns.countplot(x = data.quality, data=data, hue='type')","3929ea15":"plt.figure(figsize=(14,14))\nsns.heatmap(data.iloc[:,0:13].corr(), cbar = True,  square = True, annot=True, cmap= 'BuGn_r')","7084056a":"fig = plt.figure(figsize=(12,12))\nax1 = fig.add_subplot(1,4,1)\nax1.set_xticklabels(labels = 'Type', rotation=90)\n\nsns.boxenplot(x='type',y='quality',data=data)\nax1 = fig.add_subplot(1,4,2)\nsns.boxenplot(x='type',y='fixed acidity',data=data)\nax1 = fig.add_subplot(1,4,3)\nsns.boxenplot(x='type',y='volatile acidity',data=data)\nax1 = fig.add_subplot(1,4,4)\nsns.boxenplot(x='type',y='citric acid',data=data)\n\nfig2 = plt.figure(figsize=(12,12))\nax2 = fig2.add_subplot(1,4,1)\nsns.boxenplot(x='type',y='residual sugar',data=data)\nax2 = fig2.add_subplot(1,4,2)\nsns.boxenplot(x='type',y='chlorides',data=data)\nax2 = fig2.add_subplot(1,4,3)\nsns.boxenplot(x='type',y='free sulfur dioxide',data=data)\nax2 = fig2.add_subplot(1,4,4)\nsns.boxenplot(x='type',y='total sulfur dioxide',data=data)\n\nfig3 = plt.figure(figsize=(12,12))\nax3 = fig3.add_subplot(1,4,1)\nsns.boxenplot(x='type',y='density',data=data)\nax3 = fig3.add_subplot(1,4,2)\nsns.boxenplot(x='type',y='pH',data=data)\nax3 = fig3.add_subplot(1,4,3)\nsns.boxenplot(x='type',y='sulphates',data=data)\nax3 = fig3.add_subplot(1,4,4)\nsns.boxenplot(x='type',y='alcohol',data=data)","5b70a467":"fig = plt.figure(figsize=(24,10))\nfeatures = [\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\",\"quality\"]\n\nfor i in range(12):\n    ax1 = fig.add_subplot(3,4,i+1)\n    sns.barplot(x='quality', y=features[i],data=data, hue='type')","e9128d88":"X = data.iloc[ :, 1:13]\nX.head(3)","85987691":"y = data.iloc[ : , 0]\ny.head()","4941bfe7":"data.type.unique()","b76c7b8d":"y = y.map({'white':1, 'red' : 0})\ny.dtype","649a1747":"colnames = X.columns.tolist()\ncolnames","5ee0991f":"X_train, X_test, y_train, y_test = train_test_split(X,\n                                                    y,\n                                                    test_size=0.35,\n                                                    shuffle = True\n                                                    )","02379950":"X_train.shape","0916054f":"X_test.shape","8e515d9e":"y_train.shape","98340753":"y_test.shape","baf29e78":"steps_xg = [('sts', ss() ),\n            ('pca', PCA()),\n            ('xg',  XGBClassifier(silent = False,\n                                  n_jobs=2))]","5d1b575b":"pipe_xg = Pipeline(steps_xg)","ecb91348":"parameters = {'xg__learning_rate':  [0, 1],\n              'xg__n_estimators':   [50,  100],  \n              'xg__max_depth':      [3,5],\n              'pca__n_components' : [5,7]}","ca5ba387":"#Grid Search\nclf = GridSearchCV(pipe_xg,\n                   parameters,\n                   n_jobs = 2,\n                   cv =5 ,\n                   verbose =2,\n                   scoring = ['accuracy', 'roc_auc'], \n                   refit = 'roc_auc')","99756df8":"# Start fitting data to pipeline\nstart = time.time()\nclf.fit(X_train, y_train)\nend = time.time()\n(end - start)\/60","816fceb1":"f\"Best score: {clf.best_score_} \"","595ad4ed":"f\"Best parameter set {clf.best_params_}\"","070cd99b":"y_pred_gs = clf.predict(X_test)","884bb0a5":"# Accuracy\naccuracy_gs = accuracy_score(y_test, y_pred_gs)\nf\"Accuracy: {accuracy_gs * 100.0}\"","f403bee1":"plt.bar(clf.best_params_.keys(), clf.best_params_.values())\nplt.xticks(rotation=10)","848a4629":"parameters = {'xg__learning_rate':  uniform(0, 1),\n              'xg__n_estimators':   range(50,100),\n              'xg__max_depth':      range(3,5),\n              'pca__n_components' : range(5,7)}","5c2b134d":"rs = RandomizedSearchCV(pipe_xg,\n                        param_distributions=parameters,\n                        scoring= ['roc_auc', 'accuracy'],\n                        n_iter=20, \n                        verbose = 3,\n                        refit = 'roc_auc',n_jobs = 2,\n                        cv = 5)","dc566be3":"start = time.time()\nrs.fit(X_train, y_train)\nend = time.time()\n(end - start)\/60","208b0137":"f\"Best score: {rs.best_score_} \"","2e2bad9f":"f\"Best parameter set: {rs.best_params_} \"","36bc326a":"plt.bar(rs.best_params_.keys(), rs.best_params_.values())\nplt.xticks(rotation=10)","d54867e8":"y_pred_rs = rs.predict(X_test)","46df21de":"accuracy_rs = accuracy_score(y_test, y_pred_rs)\nf\"Accuracy: {accuracy_rs * 100.0}\"","3ba1eb15":"para_set = {\n           'learning_rate':  (0, 1),                 \n           'n_estimators':   (50,100),               \n           'max_depth':      (3,5),                 \n           'n_components' :  (5,7)          \n            }","0d2022c9":"def xg_eval(learning_rate,n_estimators, max_depth,n_components):\n    #  Make pipeline. Pass parameters directly here\n    pipe_xg1 = make_pipeline (ss(),                    \n                              PCA(n_components=int(round(n_components))),\n                              XGBClassifier(\n                                           silent = False,\n                                           n_jobs=2,\n                                           learning_rate=learning_rate,\n                                           max_depth=int(round(max_depth)),\n                                           n_estimators=int(round(n_estimators))\n                                           )\n                             )\n\n    # Now fit the pipeline and evaluate\n    cv_result = cross_val_score(estimator = pipe_xg1,\n                                X= X_train,\n                                y = y_train,\n                                cv = 2,\n                                n_jobs = 2,\n                                scoring = 'f1'\n                                ).mean()            \n\n\n    #  Finally return maximum\/average value of result\n    return cv_result","84a34e19":"xgBO = BayesianOptimization(\n                             xg_eval, \n                             para_set \n                             )","c9f5838c":"start = time.time()\nxgBO.maximize(init_points=5,    \n               n_iter=25,        \n               )\nend = time.time()\n(end-start)\/60","52146635":"f\"Best parameter set: {xgBO.max} \"","f6122dae":"xgBO.max.values()","9bb2f9a9":"for features in xgBO.max.values():\n        print(features)","7a9886c1":"features","fa9c4269":"plt.bar(features.keys(), features.values())\nplt.xticks(rotation=10)","b891448c":"# Grid Search\nxg_gs = XGBClassifier(learning_rate = clf.best_params_['xg__learning_rate'],\n                    max_depth = clf.best_params_['xg__max_depth'],\n                    n_estimators=clf.best_params_['xg__n_estimators'])\n#Randomized search\nxg_rs = XGBClassifier(learning_rate = rs.best_params_['xg__learning_rate'],\n                    max_depth = rs.best_params_['xg__max_depth'],\n                    n_estimators=rs.best_params_['xg__n_estimators'])\n#Bayes Optimization\nxg_bo = XGBClassifier(learning_rate = xgBO.max['params']['learning_rate'],\n                    max_depth = int(xgBO.max['params']['max_depth']),\n                    n_estimators= int(xgBO.max['params']['n_estimators']))","fa3d4e02":"start = time.time()\nxg_gs.fit(X_train, y_train)\nxg_rs.fit(X_train, y_train)\nxg_bo.fit(X_train, y_train)","4ba3b226":"#Fit the data using X_Train and y_train\nxg_gs1 = xg_gs.fit(X_train,y_train)\nxg_rs1 = xg_rs.fit(X_train,y_train)\nxg_bo1 = xg_bo.fit(X_train,y_train)","4aa38514":"y_pred_xg_gs = xg_gs1.predict(X_test)\ny_pred_xg_rs = xg_rs1.predict(X_test)\ny_pred_xg_bo = xg_bo1.predict(X_test)\n","4dd1fbf6":"y_pred_xg_gs_prob = xg_gs1.predict_proba(X_test)\ny_pred_xg_rs_prob = xg_rs1.predict_proba(X_test)\ny_pred_xg_bo_prob = xg_bo1.predict_proba(X_test)","ef91b5b1":"print (accuracy_score(y_test,y_pred_xg_gs))\nprint (accuracy_score(y_test,y_pred_xg_rs))\nprint (accuracy_score(y_test,y_pred_xg_bo))","00fc24d8":"confusion_matrix(y_test,y_pred_xg_gs)\nconfusion_matrix(y_test,y_pred_xg_rs)\nconfusion_matrix(y_test,y_pred_xg_bo)","fdd58dea":"fpr_xg_gs, tpr_xg_gs, thresholds = roc_curve(y_test,\n                                 y_pred_xg_gs_prob[: , 1],\n                                 pos_label= 1\n                                 )\nfpr_xg_rs, tpr_xg_rs, thresholds = roc_curve(y_test,\n                                 y_pred_xg_rs_prob[: , 1],\n                                 pos_label= 1\n                                 )\nfpr_xg_bo, tpr_xg_bo, thresholds = roc_curve(y_test,\n                                 y_pred_xg_bo_prob[: , 1],\n                                 pos_label= 1\n                                 )","983a5580":"p_xg_gs,r_xg_gs,f_xg_gs,_ = precision_recall_fscore_support(y_test,y_pred_xg_gs)\np_xg_rs,r_xg_rs,f_xg_rs,_ = precision_recall_fscore_support(y_test,y_pred_xg_rs)\np_xg_bo,r_xg_bo,f_xg_bo,_ = precision_recall_fscore_support(y_test,y_pred_xg_bo)","a4a2807e":"print (auc(fpr_xg_gs,tpr_xg_gs))\nprint (auc(fpr_xg_rs,tpr_xg_rs))\nprint (auc(fpr_xg_bo,tpr_xg_bo))","165c6b52":"fig = plt.figure(figsize=(12,10))\nax = fig.add_subplot(111)\nax.plot([0, 1], [0, 1], ls=\"--\")\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nax.set_title('ROC curve for multiple tuning methods')\nax.set_xlim([0.0, 1.0])\nax.set_ylim([0.0, 1.0])\n\n\nax.plot(fpr_xg_gs, tpr_xg_gs, label = \"xg_gs\")\nax.plot(fpr_xg_rs, tpr_xg_rs, label = \"xg_rs\")\nax.plot(fpr_xg_bo, tpr_xg_bo, label = \"xg_bo\")\n\nax.legend(loc=\"lower right\")\nplt.show()","df828ae3":"ROC curve","70c0d17f":"Calculate the AUC","45f761c7":"Bayesian Optimization","62866783":"Completed","ab936966":"DATA EXPLORATION","d3d4058e":"Split dataset into train and validation parts","3eb9998e":"Parameter tuning using Grid Search, Random Search and Bayesian Optimization","810e34df":"ROC GRAPH","3fd1bafa":"Random Search","54762d7f":"Model fitting using best parameters from above tuning techniques.","5075f1e6":"Creating Pipeline","f8a8c80f":"Calculate the Precision, Recall and F1 Score","52279c49":"predictors and target"}}