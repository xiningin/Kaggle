{"cell_type":{"4c4e49b9":"code","8bca9df5":"code","f84c79ab":"code","c71c4490":"code","3240b694":"code","15601720":"markdown","f54d1659":"markdown","88e57912":"markdown","c226e616":"markdown"},"source":{"4c4e49b9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8bca9df5":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tensorflow import keras\nfrom tqdm import tqdm_notebook, tnrange\nfrom glob import glob\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model, load_model, save_model\nimport tensorflow as tf\nfrom skimage.color import rgb2gray\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","f84c79ab":"DataPath = \"\/kaggle\/input\/lgg-mri-segmentation\/kaggle_3m\/\"  # Path to the data\nEPOCHS = 25\nBATCH_SIZE = 16\nImgHieght = 256\nImgWidth = 256\nChannels = 3\nMODEL_SAVE_PATH = \"model_unet_3m.h5\"  # directory to save the  best model\nAugmentation = True  # True or False defines whether to use data augmentation or not\nBachNopm_Dropout = True #  it is better if we have batch normalization, we dont use dropout, and vise versa.\n####\n\n\nclass Data_PreProcessing():\n    def __init__(self):\n        self.DataPath = DataPath\n\n    def prepare_data(self):\n        dirs = []\n        images = []\n        masks = []\n        for dir, subdirs, files in os.walk(self.DataPath):\n            for file in files:\n                if 'mask' in file:\n                    dirs.append(dir.replace(self.DataPath, ''))\n                    masks.append(file)\n                    images.append(file.replace('_mask', ''))\n        # print size of three lists to check if they are equal\n        print('Number of directories:', len(dirs), len(images), len(masks))\n        # now create a dataframe with the three lists\n        image_df = pd.DataFrame({'dir': dirs, 'image': images, 'mask': masks})\n        # configuring the dataframe with the whole path to the images and masks\n        image_df['image_path'] = self.DataPath + image_df['dir'] + '\/' + image_df['image']\n        image_df['mask_path'] = self.DataPath + image_df['dir'] + '\/' + image_df['mask']\n        return image_df\n\n    def training_validation_configuration(self):\n        data = self.prepare_data()\n        # split the data into training and validation sets\n        train_df, val_df = train_test_split(data, test_size=0.2, random_state=42)\n        ### TRAINING SET ###\n        # define the augmentation configuration\n        data_augmenation = dict(rotation_range=0.2, zoom_range=0.1, horizontal_flip=True,\n                                width_shift_range=0.05,\n                                height_shift_range=0.05,\n                                shear_range=0.05, fill_mode='nearest')\n        # define the data generators:\n        if Augmentation:\n            imagedatagen = ImageDataGenerator(rescale=1 \/ 255., **data_augmenation)\n            maskdatagen = ImageDataGenerator(rescale=1 \/ 255., **data_augmenation)\n        else:\n            imagedatagen = ImageDataGenerator(rescale=1 \/ 255.)\n            maskdatagen = ImageDataGenerator(rescale=1 \/ 255.)\n        # create the training image generator\n        self.train_image_generator = imagedatagen.flow_from_dataframe(dataframe=train_df,\n                                                                      x_col='image_path',\n                                                                      batch_size=BATCH_SIZE,\n                                                                      class_mode=None,\n                                                                      target_size=(ImgHieght, ImgWidth),\n                                                                      seed=42,\n                                                                      color_mode='rgb',\n                                                                      shuffle=True)\n        # create the training mask generator\n        self.train_mask_generator = maskdatagen.flow_from_dataframe(dataframe=train_df,\n                                                                    x_col='mask_path',\n                                                                    batch_size=BATCH_SIZE,\n                                                                    class_mode=None,\n                                                                    target_size=(ImgHieght, ImgWidth),\n                                                                    seed=42,\n                                                                    color_mode='grayscale')\n        #### VALIDATION SET ###\n        # define the data generators:\n        val_imagedatagen = ImageDataGenerator(rescale=1 \/ 255.)\n        val_maskdatagen = ImageDataGenerator(rescale=1 \/ 255.)\n        # create the validation image generator\n        self.val_image_generator = val_imagedatagen.flow_from_dataframe(dataframe=val_df,\n                                                                        x_col='image_path',\n                                                                        batch_size=BATCH_SIZE,\n                                                                        class_mode=None,\n                                                                        target_size=(ImgHieght, ImgWidth),\n                                                                        seed=42,\n                                                                        color_mode='rgb')\n        # create the validation mask generator\n        self.val_mask_generator = val_maskdatagen.flow_from_dataframe(dataframe=val_df,\n                                                                      x_col='mask_path',\n                                                                      batch_size=BATCH_SIZE,\n                                                                      class_mode=None,\n                                                                      target_size=(ImgHieght, ImgWidth),\n                                                                      seed=42,\n                                                                      color_mode='grayscale')\n        return self.train_image_generator.n, self.val_image_generator.n\n    #\n\n    def data_iterator(self, image_generator, mask_generator):\n        while True:\n            X, Y = next(image_generator), next(mask_generator)\n            yield X, Y\n\n    def data_generator(self):\n        return self.data_iterator(self.train_image_generator, self.train_mask_generator), self.data_iterator(self.val_image_generator, self.val_mask_generator)\n","c71c4490":"# Define UNET model in Keras in order to train it\n# we define it in class type in order to use it in the training function\n\n\nclass UNET():\n    def __init__(self, dropout_rate=0.1, batch_norm=True):\n        self.ImgHieght = ImgHieght\n        self.ImgWidth = ImgWidth\n        self.Channels = Channels\n        self.dropout_rate = dropout_rate\n        self.batch_norm = batch_norm\n        self.model = self.build_UNET()\n        self.model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n        self.model.summary()\n        self.model_save_path = MODEL_SAVE_PATH\n\n    def conv2d_block(self, inputs, filters, kernel_size, batchnorm=False):\n        \"\"\"\n        This function creates a convolutional block consisting of two convolutional layers\n        and an optional batch normalization layer.\n        \"\"\"\n        # first layer\n        x = Conv2D(filters, kernel_size=(kernel_size, kernel_size), kernel_initializer='he_normal', padding='same')(inputs)\n        x = Activation('relu')(x)\n        if BachNopm_Dropout:\n            x = BatchNormalization()(x)\n        # second layer\n        x = Conv2D(filters, kernel_size=(kernel_size, kernel_size), kernel_initializer='he_normal', padding='same')(x)\n        x = Activation('relu')(x)\n        if BachNopm_Dropout:\n            x = BatchNormalization()(x)\n        return x\n\n    def build_UNET(self):\n        inputs = Input((self.ImgHieght, self.ImgWidth, self.Channels))\n        # first layer\n        x = self.conv2d_block(inputs, 64, 3, batchnorm=self.batch_norm)\n        # encoder side of the UNET\n        enc1 = self.conv2d_block(x, 64, 3, batchnorm=self.batch_norm)\n        pol1 = MaxPooling2D((2, 2))(enc1)\n        drp1 = Dropout(self.dropout_rate)(pol1)\n        # second layer\n        enc2 = self.conv2d_block(drp1, 128, 3, batchnorm=self.batch_norm)\n        pol2 = MaxPooling2D((2, 2))(enc2)\n        drp2 = Dropout(self.dropout_rate)(pol2)\n        # third layer\n        enc3 = self.conv2d_block(drp2, 256, 3, batchnorm=self.batch_norm)\n        pol3 = MaxPooling2D((2, 2))(enc3)\n        drp3 = Dropout(self.dropout_rate)(pol3)\n        # fourth layer\n        enc4 = self.conv2d_block(drp3, 512, 3, batchnorm=self.batch_norm)\n        pol4 = MaxPooling2D((2, 2))(enc4)\n        drp4 = Dropout(self.dropout_rate)(pol4)\n        # fifth layer or the bottleneck\n        enc5 = self.conv2d_block(drp4, 1024, 3, batchnorm=self.batch_norm)\n        # decoder side of the UNET\n        # 1\n        dec1 = Conv2DTranspose(512, 3, strides=2, padding='same')(enc5)\n        dec2 = self.conv2d_block(concatenate([dec1, enc4]), 512, 3, batchnorm=self.batch_norm)\n        dec2 = Dropout(self.dropout_rate)(dec2)\n        # 2\n        dec2 = Conv2DTranspose(256, 3, strides=2, padding='same')(dec2)\n        dec3 = self.conv2d_block(concatenate([dec2, enc3]), 256, 3, batchnorm=self.batch_norm)\n        dec3 = Dropout(self.dropout_rate)(dec3)\n        # 3\n        dec3 = Conv2DTranspose(128, 3, strides=2, padding='same')(dec3)\n        dec4 = self.conv2d_block(concatenate([dec3, enc2]), 128, 3, batchnorm=self.batch_norm)\n        dec4 = Dropout(self.dropout_rate)(dec4)\n        # 4\n        dec4 = Conv2DTranspose(64, 3, strides=2, padding='same')(dec4)\n        dec5 = self.conv2d_block(concatenate([dec4, enc1]), 32, 3, batchnorm=self.batch_norm)\n        dec5 = Dropout(self.dropout_rate)(dec5)\n        # final layer\n        outputs = Conv2D(1, (1, 1), activation='sigmoid')(dec5)\n        model = Model(inputs=[inputs], outputs=[outputs])\n        return model\n\n    def train(self):\n        data_train = Data_PreProcessing()\n        num_train, num_valid = data_train.training_validation_configuration()\n        STEP_SIZE_TRAIN = num_train \/ BATCH_SIZE\n        STEP_SIZE_VALID = num_valid \/ BATCH_SIZE\n        train_gen, val_gen = data_train.data_generator()\n        Callbacks = [ModelCheckpoint(self.model_save_path, monitor='val_loss', save_best_only=True, save_weights_only=True),\n                     EarlyStopping(monitor='val_loss', patience=15, verbose=1),\n                     ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)]\n        self.history = self.model.fit_generator(train_gen,\n                                                steps_per_epoch=STEP_SIZE_TRAIN,\n                                                epochs=EPOCHS,\n                                                validation_data=val_gen,\n                                                validation_steps=STEP_SIZE_VALID,\n                                                callbacks=Callbacks)\n\n    def plot_history(self):\n        plt.plot(self.history.history['loss'])\n        plt.plot(self.history.history['val_loss'])\n        plt.title('model loss')\n        plt.ylabel('loss')\n        plt.xlabel('epoch')\n        plt.legend(['train', 'val'], loc='upper left')\n        plt.show()\n\n    def validation(self):\n        data_validation = Data_PreProcessing()\n        num_train, num_valid = data_validation.training_validation_configuration()\n        STEP_SIZE_TRAIN = num_train \/ BATCH_SIZE\n        STEP_SIZE_VALID = num_valid \/ BATCH_SIZE\n        train_gen, val_gen = data_validation.data_generator()\n        self.model.load_weights(self.model_save_path)\n        self.evaluated_results = self.model.evaluate_generator(val_gen, steps=STEP_SIZE_VALID)\n        print('Loss: ', self.evaluated_results[0])\n        print('Accuracy: ', self.evaluated_results[1])\n\n    def plot_image_results(self, num_images=8):\n        # show performance of the model on some of the images in the dataset\n        data_load = Data_PreProcessing()\n        imagepath_df = data_load.prepare_data()\n        for i in range(0, num_images):\n            idx = np.random.randint(0, len(imagepath_df))\n            image_path = os.path.join(DataPath, imagepath_df['dir'].iloc[idx], imagepath_df['image'].iloc[idx])\n            mask_path = os.path.join(DataPath, imagepath_df['dir'].iloc[idx], imagepath_df['mask'].iloc[idx])\n            image = cv2.imread(image_path)\n            mask = cv2.imread(mask_path)\n            img = cv2.resize(image, (self.ImgWidth, self.ImgHieght))\n            msk = cv2.resize(mask, (self.ImgWidth, self.ImgHieght))\n\n            img = img.astype(np.float32)\n            img = img \/ 255.0\n            img = np.expand_dims(img, axis=0)\n            #\n            self.model.load_weights(self.model_save_path)\n            predict = self.model.predict(img)\n            # plot the original input image the original mask and the output image, and the binary prediction\n            fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n            ax[0].imshow(image)\n            ax[0].set_title('Original image')\n            ax[1].imshow(mask)\n            ax[1].set_title('Original mask')\n            ax[2].imshow(predict[0, :, :, 0])\n            ax[2].set_title('Predicted mask')\n            ax[3].imshow(predict[0, :, :, 0] > 0.5)\n            ax[3].set_title('Predicted mask binary')\n            plt.show()","3240b694":"def main():\n    unet = UNET()\n    unet.train()\n    unet.plot_history()\n    unet.validation()\n    unet.plot_image_results()\n\n\nif __name__ == '__main__':\n    main()","15601720":"## Define UNET","f54d1659":"## Import useful libraries to this Segmentation task","88e57912":"## Main Function to do TRAINING, VALIDATION and SHOWING the results:","c226e616":"## Preparing the input data to read into the deep learning algorithem:"}}