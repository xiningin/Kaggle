{"cell_type":{"164b2da5":"code","b68acb4a":"code","6c48a325":"code","bbcbf2d6":"code","70e4fcd4":"code","ca07f01d":"code","ffd2e364":"code","c67e5017":"code","3a59fb95":"code","2ee001f2":"code","bd14e898":"code","74b3c27a":"markdown","7e678105":"markdown","69ebc716":"markdown","19b44f10":"markdown","b3aa532c":"markdown","0df7373e":"markdown","b116ff7a":"markdown","9f58fc0b":"markdown"},"source":{"164b2da5":"import numpy as np","b68acb4a":"def sigmoid(x):\n    return 1 \/ (1 + np.exp(-x))","6c48a325":"def sigmoid_derivative(x):\n    return x * (1 - x)","bbcbf2d6":"training_inputs = np.array([\n                               [0,0,1],\n                               [1,1,1],\n                               [1,0,1],\n                               [0,1,1]\n                           ]\n                          )\ntraining_outputs = np.array([[0,1,1,0]]).T","70e4fcd4":"np.random.seed(1)\nsynaptic_weights = 2 * np.random.random((3,1)) - 1\n\nprint(\"Random Starting Synaptic Weights : \")\nprint(synaptic_weights)","ca07f01d":"for iteration in range(1):\n    input_layer = training_inputs\n    \n    outputs = sigmoid(np.dot(input_layer, synaptic_weights))\n    \nprint(\"Outputs after Training : \")\nprint(outputs)","ffd2e364":"# Lets modify the same function to calculate the errors and adjust the weights.\nfor iteration in range(20000): # Play around the iteration to get accurate outputs. Start with 1;5;10;100;1000;10000; 20000\n    input_layer = training_inputs\n    \n    outputs = sigmoid(np.dot(input_layer, synaptic_weights))\n    \n    error = training_outputs - outputs\n    \n    adjustments = error * sigmoid_derivative(outputs)\n    \n    synaptic_weights += np.dot(input_layer.T, adjustments)\n    \nprint('Synaptic Weights after Training : ')\nprint(synaptic_weights)\nprint('-'*20)\nprint(\"Outputs after Training : \")\nprint(outputs)","c67e5017":"# import numpy as np","3a59fb95":"class NeuralNetwork():\n    \n    def __init__(self):\n        np.random.seed(1)\n        \n        self.synaptic_weights = 2 * np.random.random((3,1)) - 1\n        \n    def sigmoid(self, x):\n        return 1 \/ (1+np.exp(-x))\n    \n    def sigmoid_derivative(self, x):\n        return x * (1-x)\n    \n    def train(self, training_inputs, training_outputs, training_iterations):\n        for  iteration in range(training_iterations):\n            output = self.think(training_inputs)\n            error = training_outputs - output\n            adjustments = np.dot(training_inputs.T, error * self.sigmoid_derivative(output))\n            self.synaptic_weights += adjustments\n            \n    def think(self, inputs):\n        inputs = inputs.astype(float)\n        output = self.sigmoid(np.dot(inputs, self.synaptic_weights))\n        return output\n    ","2ee001f2":"# if __name__ = \"__main__\":\nneural_network = NeuralNetwork()\n\nprint(\"Random Synaptic Weights\")\nprint(neural_network.synaptic_weights)\n\nneural_network.train(training_inputs, training_outputs, 10000)\n\nprint(\"Random Synaptic Weights After Training\")\nprint(neural_network.synaptic_weights)\n","bd14e898":"# Test this.\ntest_input = np.array([1,1,1])\n\nprint(\"Output Data for {}: \".format(test_input))\nprint(neural_network.think(test_input))\n\nprint('-*'*20)\n\ntest_input = np.array([1,0,0])\n\nprint(\"Output Data for {}: \".format(test_input))\nprint(neural_network.think(test_input))\n\nprint('-*'*20)\n\ntest_input = np.array([0,0,1])\n\nprint(\"Output Data for {}: \".format(test_input))\nprint(neural_network.think(test_input))","74b3c27a":"Below is the code snippet with Tensorflow using Keras.\n![image.png](attachment:image.png)","7e678105":"![image.png](attachment:image.png)","69ebc716":"# Pytorch Vs Keras Vs Tensorflow\nPytorch and Tensorflow are two most popular Deep Learning (DL) frameworks.\nThere is one more framework for DL which is CNTK, but not famous as other two.\nPytorch is by Facebook and Tensorflow is by Google. CNTK is by Microsoft.\nKeras is not a full-fledge DL framework, it is just a nice wrapper around Tensorflow, CNTK and Theano. To provide a convinence to use the said frameworks.\n\nWith Tensorflow 2.0, Keras is a part of Tensorflow itself. So there is no need to install Keras seperately, insted can use Keras from Tensorflow.","19b44f10":"This is how Neural Network learns.\nNext will see how can we implement this into actual NN.","b3aa532c":"## Just to have a hands-on, without actually using any specific library.","0df7373e":"Below is the Code snippet with Keras.\n![image.png](attachment:image.png)","b116ff7a":"To start with Neural Net, will use `Class`.","9f58fc0b":"# Deep Learning Tutorial - Basic\nHere we are goign to use Tensorflow to train our model.\n\n## Deep Learning \nDeep Learning is a form of Machine Learning that uses a model of computing that's very much inspired by the structure of the human brain.\n\nBefore that lets understand what is TensorFlow?\n1. Tensors are the standard way of representing data in Deep Learning.\n2. Tensors are just multi-dimensional arrays, an extension of 2-D table \/ matrices to data with higher dimension.\n3. In Tensorflow, computation is approached as a dataflow graph.\n4. TensorFlow Core programs consists of two discrete sections such as \n    * Building a computational graph\n    * Running a computational graph\n5. A computational graph is a series of TensorFlow operations arranged into a graph of nodes.\n\nBefore we actually start with the MNIST Dataset, lets build a simple computational graph.\n\n![image.png](attachment:image.png)\n"}}