{"cell_type":{"417cfc98":"code","0a07ac72":"code","a5859c1b":"code","3e8d7256":"code","a1e962eb":"code","a21c1640":"code","c98cb08b":"code","ab8a7e13":"code","d426ab0f":"code","09a72a53":"code","9f6f0362":"code","b871a080":"code","9288b97f":"code","b54e1561":"code","f84f7dcc":"code","c46347b7":"code","490fc21a":"code","665ccd36":"code","9f3e10c4":"code","9990319a":"code","7c35ea23":"code","57df20c7":"code","e9b7e491":"code","32f9b5cf":"code","36ed8653":"code","33180876":"code","2684168b":"markdown","593dd224":"markdown","6dd77948":"markdown","cdea5c13":"markdown","4d75c9e0":"markdown","b4ba692b":"markdown","54be5a0d":"markdown","02cf540a":"markdown"},"source":{"417cfc98":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0a07ac72":"from sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns","a5859c1b":"train = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/test.csv')","3e8d7256":"x_data = train.drop(['id', 'target'], axis=1)\ny_data = train.target \nx_test = test.drop('id', axis=1)","a1e962eb":"null_count = pd.isnull(x_data).sum().sum()\nprint(f'null data, {null_count}')","a21c1640":"x_data.describe()","c98cb08b":"x_data.info()","ab8a7e13":"x_data.head()","d426ab0f":"\nplt.hist(x_data.std())","09a72a53":"x_test.shape","9f6f0362":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler.fit(x_data)\nx_data = scaler.transform(x_data)\nx_test = scaler.transform(x_test)","b871a080":"from sklearn.metrics import roc_auc_score","9288b97f":"x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.5)","b54e1561":"from sklearn.linear_model import LogisticRegression\n\nlogis_model = LogisticRegression()\nlogis_model.fit(x_train, y_train)\n\nlogis_train_pred = logis_model.predict_proba(x_train)[:, 1]\nscore = roc_auc_score(y_train, logis_train_pred)\nprint(f'train score {score}')\n\nlogis_val_pred = logis_model.predict_proba(x_val)[:, 1]\nscore = roc_auc_score(y_val, logis_val_pred)\nprint(f'val score {score}')\n\n# logis_pred = logis_model.predict_proba(x_data)[:, 1]\n# print(f'logis pred {logis_pred.shape}')","f84f7dcc":"from sklearn.svm import LinearSVC\n\n# x_train, x_val, y_train, y_val = train_test_split(x_data, y_data)\nsvc_model = LinearSVC()\nsvc_model.fit(x_train, y_train)\n\nsvc_train_pred = svc_model.decision_function(x_train)\nscore = roc_auc_score(y_train, svc_train_pred)\nprint(f'train score {score}')\n\nsvc_val_pred = svc_model.decision_function(x_val)\nscore = roc_auc_score(y_val, svc_val_pred)\nprint(f'val score {score}')\n\n# svc_pred = svc_model.decision_function(x_data)\n# print(f'logis pred {svc_pred.shape}')","c46347b7":"from xgboost import XGBClassifier","490fc21a":"xgb_params = {\n                'n_estimators': 4492,\n                'learning_rate': 0.01,\n                'subsample': 1.0,\n                'colsample_bytree': 0.2,\n                'max_depth': 15,\n                'gamma': 1.0328829988080024,\n                'reg_alpha': 100,\n                'reg_lambda': 93 }\n\nxgb_params['tree_method'] = 'gpu_hist'\nxgb_params['predictor'] = 'gpu_predictor'\nxgb_params['use_label_encoder'] = False","665ccd36":"# x_train, x_val, y_train, y_val = train_test_split(x_data, y_data)\nxgb_model = XGBClassifier(**xgb_params)\nxgb_model.fit(x_train, y_train)\n\nxgb_train_pred = xgb_model.predict_proba(x_train)[:, 1]\nscore = roc_auc_score(y_train, xgb_train_pred)\nprint(f'train score {score}')\n\nxgb_val_pred = xgb_model.predict_proba(x_val)[:, 1]\nscore = roc_auc_score(y_val, xgb_val_pred)\nprint(f'val score {score}')\n\n# xgb_pred = xgb_model.predict_proba(x_data)[:, 1]\n# print(f'logis pred {svc_pred.shape}')","9f3e10c4":"new_x_train_data = np.hstack([logis_train_pred[:, np.newaxis], svc_train_pred[:, np.newaxis], xgb_train_pred[:, np.newaxis]])\nprint(f'new_x_data shape {new_x_train_data.shape}')\n\nnew_x_train_data = np.hstack([x_train, new_x_train_data])\n\nnew_x_val_data = np.hstack([logis_val_pred[:, np.newaxis], svc_val_pred[:, np.newaxis], xgb_val_pred[:, np.newaxis]])\nprint(f'new_x_data shape {new_x_val_data.shape}')\n\nnew_x_val_data = np.hstack([x_val, new_x_val_data])","9990319a":"# x_train, x_val, y_train, y_val = train_test_split(new_x_data, y_data)\nmodel = XGBClassifier(**xgb_params)\nmodel.fit(new_x_val_data, y_val)\n\ntrain_pred = model.predict_proba(new_x_train_data)[:, 1]\nscore = roc_auc_score(y_train, train_pred)\nprint(f'train score {score}')\n\nval_pred = model.predict_proba(new_x_val_data)[:, 1]\nscore = roc_auc_score(y_val, val_pred)\nprint(f'val score {score}')","7c35ea23":"new_x_data = np.vstack([new_x_train_data, new_x_val_data])\nprint(new_x_data.shape)\n\nnew_y_data = np.concatenate([y_train, y_val])\nprint(new_y_data.shape)","57df20c7":"# from sklearn.linear_model import Ridge","e9b7e491":"# x_train, x_val, y_train, y_val = train_test_split(new_x_data, y_data)\n# model = LogisticRegression()\n# model.fit(x_train, y_train)\n\n# train_pred = model.predict(x_train)\n# score = roc_auc_score(y_train, train_pred)\n# print(f'train score {score}')\n\n# val_pred = model.predict(x_val)\n# score = roc_auc_score(y_val, val_pred)\n# print(f'val score {score}')","32f9b5cf":"logis_test_pred = logis_model.predict_proba(x_test)[:, 1]\nsvc_test_pred = svc_model.decision_function(x_test)\nxgb_test_pred = xgb_model.predict_proba(x_test)[:, 1]\n\nnew_x_test = np.hstack([logis_test_pred[:, np.newaxis], svc_test_pred[:, np.newaxis], xgb_test_pred[:, np.newaxis]])\nnew_x_test = np.hstack([x_test, new_x_test])\n\ny_test = model.predict_proba(new_x_test)[:, 1]","36ed8653":"# from sklearn.model_selection import KFold\n# n_split = 10\n# kfold = KFold(n_split)\n# y_test = np.zeros(shape=(new_x_test.shape[0],))\n# for i, (train_index, val_index) in enumerate(kfold.split(new_x_train_data)):\n#     print(f'fold {i}')\n    \n#     x_train = new_x_data[train_index]\n#     y_train = new_y_data[train_index]\n    \n#     x_val = new_x_data[val_index]\n#     y_val = new_y_data[val_index]\n    \n#     model = XGBClassifier(**xgb_params)\n#     model.fit(x_train, y_train)\n    \n#     train_pred = model.predict_proba(x_train)[:, 1]\n#     score = roc_auc_score(y_train, train_pred)\n#     print(f'train score {score}')\n\n#     val_pred = model.predict_proba(x_val)[:, 1]\n#     score = roc_auc_score(y_val, val_pred)\n#     print(f'val score {score}')\n    \n#     y_test += model.predict_proba(new_x_test)[:, 1] \/ n_split","33180876":"sub_mission = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')\nsub_mission.target = y_test\nsub_mission.to_csv('submission.csv', index=False)\n\nplt.figure()\nsns.kdeplot(y_test)","2684168b":"### train xgboost","593dd224":"### logis_pred svc_pred xgb_pred as a new feature","6dd77948":"### LogisticRegression","cdea5c13":"I use three models\uff1a\n==\nLogisticRegression\n\nLinearSVC\n\nXGBClassifier\n\nUse their predictions as a new feature:(logis_pred\uff0c svc_pred\uff0c xgb_pred\uff09\nThen tarin a XGBClassifier\n\nThe validation score \ntrain score 0.8503685147840804\nval score 0.8254763097498596\n\nBut the effect is very poor on the test set\n\nCan someone tell me why\uff1f","4d75c9e0":"### LinearSVC","b4ba692b":"## model trainning","54be5a0d":"### XGBClassifier","02cf540a":"### predict"}}