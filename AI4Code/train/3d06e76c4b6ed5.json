{"cell_type":{"66f72fc9":"code","5e8b66be":"code","e110233b":"code","64550859":"code","e64592bb":"code","79ec8d91":"code","d1467caa":"code","27f90592":"code","5a66c21e":"code","59a1feb0":"code","d83ad968":"code","1555327b":"code","dcf3b609":"code","303a0c3d":"markdown","d21942ae":"markdown","f2f92328":"markdown","f8a7312e":"markdown","013f788d":"markdown","3d48c4c8":"markdown"},"source":{"66f72fc9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport warnings\nwarnings.filterwarnings('ignore')\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n        print(dirname)\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5e8b66be":"import tensorflow\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","e110233b":"data = ImageDataGenerator(rescale=1.0\/255.0,validation_split=.3)\ntrain = data.flow_from_directory('\/kaggle\/input\/womens-faces-when-dressed-and-undressed\/ti\/',subset='training',target_size=(100, 100),class_mode='binary',color_mode='grayscale')\nval = data.flow_from_directory('\/kaggle\/input\/womens-faces-when-dressed-and-undressed\/ti\/',subset='validation',target_size=(100, 100),class_mode='binary',color_mode='grayscale')\n","64550859":"\"\"\"import os\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nimg_lbl=[]\nundress = os.listdir('\/kaggle\/input\/womens-faces-when-dressed-and-undressed\/ti\/undressed')\nfor i in undress:\n    path = os.path.join('\/kaggle\/input\/womens-faces-when-dressed-and-undressed\/ti\/undressed',i)\n    image = cv.imread(path,cv.IMREAD_GRAYSCALE)  \n\n    image = cv.resize(image,(50,50))\n    image = image\/255.0\n    img_lbl.append([image,1])\nlen(img_lbl)\ndress = os.listdir('\/kaggle\/input\/womens-faces-when-dressed-and-undressed\/ti\/dressed')\nfor i in dress:\n    path = os.path.join('\/kaggle\/input\/womens-faces-when-dressed-and-undressed\/ti\/dressed',i)\n    image = cv.imread(path,cv.IMREAD_GRAYSCALE)  \n    image = cv.resize(image,(50,50))\n    image = image\/255.0\n    img_lbl.append([image,0])\n\nlen(img_lbl)\"\"\"","e64592bb":"\"\"\"#split\ndef preprocess2(data):\n    train=[]\n    lbl=[]\n    for xx,yy in data:\n        train.append(xx)\n        lbl.append(yy)\n    \n    img = np.array(train).reshape(-1,50,50,1)\n    img = img\/255.0\n    lbl = np.array(lbl).reshape(-1,1)\n    return img,lbl\n\nimage,label = preprocess2(img_lbl)\"\"\"","79ec8d91":"\"\"\"len(image),len(label)\"\"\"","d1467caa":"\"\"\"from sklearn.model_selection import train_test_split\ntrainimg,testimg,trainlbl,testlbl = train_test_split(image,label,test_size=.2)\"\"\"","27f90592":"import tensorflow\nfrom tensorflow import keras\nfrom keras.layers import Conv2D,Dense,Flatten,LeakyReLU,MaxPooling2D,Dropout,BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential","5a66c21e":"model =Sequential()\nmodel.add(Conv2D(32,kernel_size = (3,3),input_shape=(100,100,1),activation = 'LeakyReLU',padding ='same'))\nmodel.add(MaxPooling2D(strides=2))\n\nmodel.add(Conv2D(64,kernel_size=(3,3),activation = 'LeakyReLU',padding = 'same'))\nmodel.add(MaxPooling2D(strides=2))\n\nmodel.add(Flatten())\nmodel.add(Dense(4096))\nmodel.add(Dense(1,activation='sigmoid'))\n#model.add(BatchNormalization())","59a1feb0":"model.compile(Adam(.001),loss='binary_crossentropy',metrics=['accuracy'])","d83ad968":"from tensorflow.keras.callbacks import EarlyStopping\ner = EarlyStopping(monitor='accuracy',patience=2,baseline=1,verbose=1)","1555327b":"model.fit(train,validation_data=val,epochs=40)","dcf3b609":"val = model.evaluate(train,steps=200)","303a0c3d":"# Spliting train and test data","d21942ae":"## Handling files and preprocess images","f2f92328":"# trainning model","f8a7312e":"# evaluate\n","013f788d":"# VGG16 model with Batchnormalization layer","3d48c4c8":"# Compile\n"}}