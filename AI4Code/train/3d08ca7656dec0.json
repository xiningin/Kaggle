{"cell_type":{"fb9ac586":"code","d38af844":"code","97e33c1a":"code","781c0f93":"code","60eafeb4":"code","79e83a65":"code","52eae1a6":"code","ee760a28":"code","eef1de1f":"code","8bc33ebd":"code","970ae320":"code","ff2044d2":"code","00481298":"code","1c564d42":"code","da3d82c3":"code","0ec22fcd":"code","45964000":"code","5a5eee1e":"code","b3598ad5":"code","1ac2aa9f":"code","1eda6427":"code","3614a3cc":"code","c6c90716":"code","6633d75b":"code","42753257":"code","6eb67a97":"code","5ad14a78":"code","2ce19a29":"code","d5dca3d9":"code","1442be18":"code","9fd7bef8":"code","cd0098c7":"code","02fcb8ec":"code","53a5fb04":"code","93abb01f":"code","5a6fecf7":"code","7ecbb242":"code","0967bae2":"code","f0bfe818":"code","d5d692ea":"code","e91c7567":"code","251ddb21":"code","cb2edb0a":"code","c22df384":"code","46e55fe3":"code","1cb90908":"code","3fc46cb0":"code","821f2028":"code","c6732104":"code","af594cbf":"code","fa7b1463":"code","da9beefc":"code","b5f2994f":"markdown","2c983d5f":"markdown","0b168a73":"markdown","8ca482df":"markdown","3d376e99":"markdown","d946a46a":"markdown","14fd162f":"markdown","c8a1b4ad":"markdown","6bd33c0a":"markdown","9f4874da":"markdown","8da3819e":"markdown","0ce81447":"markdown","96b71732":"markdown","761dbc23":"markdown","95f2ccb5":"markdown","8cd70d1f":"markdown","5dd4808b":"markdown","cb6c97fa":"markdown","6d986b88":"markdown","397d7d95":"markdown","905f4449":"markdown"},"source":{"fb9ac586":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom scipy import stats\nimport warnings\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier,plot_tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nfrom sklearn.naive_bayes import GaussianNB\nwarnings.filterwarnings('ignore')\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d38af844":"df = pd.read_csv('..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')","97e33c1a":"df.head()","781c0f93":"df.info()","60eafeb4":"cat_col = [i for i in df.columns if df[i].nunique()<10]\nprint('Categorical features of dataset:',cat_col)\nprint('\\n')\n\nnum_col = [i for i in df.columns if df[i].nunique()>10]\nprint('Numerical features of dataset:',num_col)","79e83a65":"print('Sahpe of dataset:',df.shape)","52eae1a6":"print('Null values in dataset:',df.isna().sum().sum())","ee760a28":"val = df['output'].value_counts()\nval","eef1de1f":"plt.pie(val,\n        autopct='%1.2f%%',\n        labels=['0(Low risk)','1(High risk)'],\n        colors=['g','r'])\n \nplt.legend()\nplt.show()","8bc33ebd":"df.sex.value_counts()","970ae320":"print(df[['cp','output']].groupby(['cp'],as_index = False).mean())","ff2044d2":"print(df[['fbs','output']].groupby(['fbs'],as_index=False).mean())","00481298":"print(df[['exng','output']].groupby(['exng'],as_index=False).mean())","1c564d42":"print(df[['slp','output']].groupby(['slp'],as_index=False).mean())","da3d82c3":"print(df[['caa','output']].groupby(['caa'],as_index=False).mean())","0ec22fcd":"print(df[['thall','output']].groupby(['thall'],as_index=False).mean())","45964000":"df['_trtbps_']=pd.cut(df['trtbps'],5)\nprint(df[['_trtbps_','output']].groupby(['_trtbps_'],as_index=False).mean())","5a5eee1e":"df['_age_']=pd.cut(df['age'],5)","b3598ad5":"print(df[['_age_','output']].groupby(['_age_'],as_index=True).mean())","1ac2aa9f":"print(df[['exng','output']].groupby(['exng'],as_index=True).mean())","1eda6427":"df.columns","3614a3cc":"sns.swarmplot(x='caa',y='thalachh',data=df,hue='output')\nplt.show()","c6c90716":"sns.swarmplot(x='fbs',y='thalachh',data=df,hue='output')\nplt.show()","6633d75b":"sns.swarmplot(x='fbs',y='oldpeak',data=df,hue='output')\nplt.show()","42753257":"sns.boxplot(y=df.trtbps)","6eb67a97":"sns.boxplot(y=df.chol)","5ad14a78":"sns.boxplot(y=df.thalachh)","2ce19a29":"sns.boxplot(y=df.oldpeak)","d5dca3d9":"out = np.abs(stats.zscore(df[num_col]))\nthreshold=3\nprint(np.where(out>=threshold))\nprint(('value of z[28][2]='),(out[28][2]))","1442be18":"fig,(a1,a2,a3)=plt.subplots(1,3,figsize=(10,5))\nsns.boxplot(y=df['age'],ax=a1)\nsns.boxplot(y=df['trtbps'],ax=a2)\nsns.boxplot(y=df['chol'],ax=a3)\nfig, (a1,a2) = plt.subplots(1,2,figsize=(15,5))\nsns.boxplot(y=df['thalachh'],ax=a1)\nsns.boxplot(y=df['oldpeak'],ax=a2)","9fd7bef8":"df.columns","cd0098c7":"X = df.iloc[:,:-3]\ny= df['output']","02fcb8ec":"X_train,X_test,y_train,y_test = train_test_split(X,y,\n                                                test_size=0.25,\n                                                random_state=25,)","53a5fb04":"cret = {'gini':[],'entropy':[]}\nfor i in cret.keys():\n    for j in range(1,20):\n        dec = DecisionTreeClassifier(criterion=i,max_depth=j)\n        dec.fit(X_train,y_train)\n        y_pred = dec.predict(X_test)\n        cret[i].append(accuracy_score(y_test,y_pred))","93abb01f":"plt.plot(cret['gini'],c='r',marker='o',label='gini')\nplt.plot(cret['entropy'],c='g',marker='+',label='entropy')\nplt.legend()\nplt.show()","5a6fecf7":"dec = DecisionTreeClassifier(criterion='entropy',max_depth=5)\ndec.fit(X_train,y_train)\ny_pred = dec.predict(X_test)","7ecbb242":"plt.figure(figsize=[10,5])\n\n_ = plot_tree(dec,filled=True,feature_names=X.columns,node_ids=True)","0967bae2":"print('Test accuracy:',dec.score(X_test,y_test))\nprint('Train accuracy:',dec.score(X_train,y_train))\ndecission=round(dec.score(X_test,y_test)*100,2)\ndecission","f0bfe818":"rnd = RandomForestClassifier(n_estimators=100,max_depth=3,random_state=2)\nrnd.fit(X_train,y_train)\npredict= rnd.predict(X_test)","d5d692ea":"print('Test accuracy:',rnd.score(X_test,y_test))\nprint('Train accuracy:',rnd.score(X_train,y_train))\nrand = round(rnd.score(X_train,y_train)*100,2)\nrand","e91c7567":"wt={'uniform':[],'distance':[]}\nfor i in wt.keys():\n    for j in range(1,21,2):\n        neig=KNeighborsClassifier(n_neighbors=j,\n                                 weights=i)\n        neig.fit(X_train,y_train)\n        y_pred=neig.predict(X_test)\n        wt[i].append(accuracy_score(y_test,y_pred))","251ddb21":"plt.plot(wt['uniform'],marker='o',c='r',label='uniform')\nplt.plot(wt['distance'],marker='o',c='g',label='distance')\nplt.legend()\nplt.show()","cb2edb0a":"wt={'1':[],'2':[]}\nfor i in wt.keys():\n    for j in range(1,21,2):\n        neig=KNeighborsClassifier(n_neighbors=j,\n                                 weights='distance',\n                                 p=int(i))\n        neig.fit(X_train,y_train)\n        y_pred=neig.predict(X_test)\n        wt[i].append(accuracy_score(y_test,y_pred))","c22df384":"plt.plot(wt['1'],marker='o',c='r',label='1')\nplt.plot(wt['2'],marker='o',c='g',label='2')\nplt.legend()\nplt.show()","46e55fe3":"neig=KNeighborsClassifier(n_neighbors=16,\n                                 weights='distance',\n                                 p=1)\nneig.fit(X_train,y_train)\ny_pred=neig.predict(X_test)","1cb90908":"print('Test accuracy:',neig.score(X_test,y_test))\nknn=round(neig.score(X_test,y_test)*100,2)\nknn","3fc46cb0":"confusion_matrix(y_test,y_pred)","821f2028":"guss=GaussianNB()\nguss.fit(X_train,y_train)\npredict = guss.predict(X_test)","c6732104":"print('Test accuracy:',guss.score(X_test,y_test))\ngussian = round(guss.score(X_test,y_test)*100,2)\ngussian","af594cbf":"model = pd.DataFrame({\n    'model':['knn','decission tree','random forest','navi bayes'],\n    'score':[knn,decission,rand,gussian]\n})","fa7b1463":"sns.barplot(y='model',x='score',data=model)","da9beefc":"model.sort_values(by='score',ascending=True, ignore_index=True)","b5f2994f":"1. Split data for training and testing","2c983d5f":"# conslusion of analysis:\n* those heve less oldpeak they have high chance of heart-attack\n* those have high thalachh they have more chance of hert-attack","0b168a73":"# caa","8ca482df":"**Analysis**","3d376e99":"## exng","d946a46a":"# age","14fd162f":"# slp","c8a1b4ad":"# KNN","6bd33c0a":"# Preprocessing data for ML","9f4874da":"# Compare model score","8da3819e":"**Import necessary tools**\n* pandas\n* numpy\n* matplotlib\n* seaborn\n* sklearn\n* scipy","0ce81447":"***From numerical data he identify that is outliers is there,removing of outliers is best for ML model accuracy***","96b71732":"#       Heart attack analysis and prediction","761dbc23":"# Random Forest","95f2ccb5":"## fbs ","8cd70d1f":"# Load dataset","5dd4808b":"# thall","cb6c97fa":"# trtbps","6d986b88":"## **CP**","397d7d95":"# Decission Tree","905f4449":"# Naive Bayes"}}