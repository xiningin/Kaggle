{"cell_type":{"9beb8897":"code","a35715f7":"code","e842cd73":"code","716ba5ad":"code","a374cc16":"code","5062313c":"code","ee67ef84":"code","c6d5b019":"code","6739a7e9":"code","562be160":"code","6ce85f1e":"code","982d05f4":"code","bd780831":"code","f23678d3":"code","61e5bacb":"code","e7ed32af":"code","0d44e157":"markdown","966bd477":"markdown","bdc48331":"markdown","0f9ededa":"markdown","51d553ec":"markdown","00fb675c":"markdown","f5141d99":"markdown","d34ebd3a":"markdown"},"source":{"9beb8897":"%%capture\nimport sys\n!cp ..\/input\/rapids\/rapids.0.15.0 \/opt\/conda\/envs\/rapids.tar.gz\n!cd \/opt\/conda\/envs\/ && tar -xzvf rapids.tar.gz > \/dev\/null\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\/site-packages\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\/python3.7\"] + sys.path\nsys.path = [\"\/opt\/conda\/envs\/rapids\/lib\"] + sys.path \n!cp \/opt\/conda\/envs\/rapids\/lib\/libxgboost.so \/opt\/conda\/lib\/","a35715f7":"import cudf, cuml\nimport pandas as pd\nimport numpy as np\nfrom cuml.manifold import TSNE\n# from sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nfrom itertools import combinations_with_replacement\nfrom matplotlib.colors import ListedColormap\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","e842cd73":"data_dir = '\/kaggle\/input\/stanford-covid-vaccine\/'\ntrain = pd.read_json(data_dir + 'train.json', lines=True)\ntest = pd.read_json(data_dir + 'test.json', lines=True)\nsample_df = pd.read_csv(data_dir + 'sample_submission.csv')\n\npublic_df = test.query(\"seq_length == 107\")\nprivate_df = test.query(\"seq_length == 130\")\n\npred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']","716ba5ad":"# Train\ntrain_dict = {}\nfor col in ['sequence','structure','predicted_loop_type']:\n        for sentence in train[col].iteritems():\n            char_list = list(sentence[1])\n            for i,c in enumerate(char_list):\n                if f\"{col}_{str(i)}\" in train_dict:\n                    train_dict[f\"{col}_{str(i)}\"].append(c)\n                else:\n                    train_dict[f\"{col}_{str(i)}\"] = [c]\n                    \n# public_df   \npublic_dict = {}\nfor col in ['sequence','structure','predicted_loop_type']:\n        for sentence in public_df[col].iteritems():\n            char_list = list(sentence[1])\n            for i,c in enumerate(char_list):\n                if f\"{col}_{str(i)}\" in public_dict:\n                    public_dict[f\"{col}_{str(i)}\"].append(c)\n                else:\n                    public_dict[f\"{col}_{str(i)}\"] = [c]\n                    \n# private_df  \nprivate_dict = {}\nfor col in ['sequence','structure','predicted_loop_type']:\n        for sentence in private_df[col].iteritems():\n            char_list = list(sentence[1])\n            for i,c in enumerate(char_list):\n                if f\"{col}_{str(i)}\" in private_dict:\n                    private_dict[f\"{col}_{str(i)}\"].append(c)\n                else:\n                    private_dict[f\"{col}_{str(i)}\"] = [c]","a374cc16":"train_df = pd.DataFrame(train_dict)\ntrain_df.head()","5062313c":"train_df_one_hot = pd.get_dummies(train_df)\nfor col,chars in zip(['sequence','structure','predicted_loop_type'],[['G','A', 'C', 'U'],['.', '(', ')'],['E', 'S', 'H', 'B', 'X','I','M']]):\n    print(col,chars)\n    for i in range(107):\n        for char in chars:\n            if f\"{col}_{i}_{char}\" not in train_df_one_hot.columns:\n                train_df_one_hot[f\"{col}_{i}_{char}\"] = 0\n#                 print(\"Column\",f\"{col}_{i}_{char}\", \"Added\")\ntrain_df_one_hot.head()","ee67ef84":"select_features = []\npublic_df = pd.DataFrame(public_dict)\npublic_df_one_hot = pd.get_dummies(public_df)\nfor col,chars in zip(['sequence','structure','predicted_loop_type'],[['G','A', 'C', 'U'],['.', '(', ')'],['E', 'S', 'H', 'B', 'X','I','M']]):\n    for i in range(107):\n        for char in chars:\n            select_features.append(f\"{col}_{i}_{char}\")\n            if f\"{col}_{i}_{char}\" not in public_df_one_hot.columns:\n                public_df_one_hot[f\"{col}_{i}_{char}\"] = 0\n#                 print(\"Column\",f\"{col}_{i}_{char}\", \"Added\")\npublic_df_one_hot.head()","c6d5b019":"private_df = pd.DataFrame(private_dict)\nprivate_df_one_hot = pd.get_dummies(private_df)\nfor col,chars in zip(['sequence','structure','predicted_loop_type'],[['G','A', 'C', 'U'],['.', '(', ')'],['E', 'S', 'H', 'B', 'X','I','M']]):\n    for i in range(130):\n        for char in chars:\n            if f\"{col}_{i}_{char}\" not in private_df_one_hot.columns:\n                private_df_one_hot[f\"{col}_{i}_{char}\"] = 0\n#                 print(\"Column\",f\"{col}_{i}_{char}\", \"Added\")\nprivate_df_one_hot.head()","6739a7e9":"print(\"Train Features Shape : \",train_df_one_hot.shape)\nprint(\"Public Features Shape : \",public_df_one_hot.shape)\nprint(\"private Features Shape : \",private_df_one_hot.shape)","562be160":"def get_tsne(X):\n    X_reshape = X.reshape(len(X),-1)\n    tsne = TSNE(n_components=2 ,init='pca', n_iter=2500, random_state=23)\n    X_reshape_2D = tsne.fit_transform(X_reshape)\n    return X_reshape_2D","6ce85f1e":"fig, (ax1,ax2,ax3) = plt.subplots(nrows=1,ncols=3,figsize=(21,7))\nfig.suptitle(\"Apply TSNE on Individual data (Original Features Only) : ['sequence','structure','predicted_loop_type']\", fontsize=18)\n\ntrain_2D = get_tsne(train_df_one_hot[select_features].values)\ntrain_SN_filter = train_SN_filter = train['SN_filter'].values\nclasses = ['SN_filter == 0', 'SN_filter == 1']\ncolours = ListedColormap(['r','b'])\nax1.set(title=\"Train Inputs\")\nscatter = ax1.scatter(train_2D[:,0], train_2D[:,1],c=train_SN_filter,cmap=colours,s = 0.7)\nax1.legend(handles=scatter.legend_elements()[0], labels=classes)\n\npublic_2D = get_tsne(public_df_one_hot[select_features].values)\nscatter = ax2.scatter(public_2D[:,0], public_2D[:,1],s = 0.7)\nax2.set(title=\"Public Inputs\")\n\nprivate_2D = get_tsne(private_df_one_hot.values)\nscatter = ax3.scatter(private_2D[:,0], private_2D[:,1],s = 0.7)\nax3.set(title=\"Private Inputs\")\n\nplt.savefig('0.png')\nplt.show()","982d05f4":"test_public = np.vstack([train_df_one_hot[select_features].values, public_df_one_hot[select_features].values])\nprint(\"Train Features Shape : \",train_df_one_hot.shape)\nprint(\"Public Features Shape : \",public_df_one_hot.shape)\nprint(\"test_public Shape: \",test_public.shape)\n\ntest_public_2D = get_tsne(test_public)\ntest_public_y = [0]*len(train_df_one_hot) + [1]*len(public_df_one_hot) \nfig, ax1 = plt.subplots(nrows=1,ncols=1,figsize=(12,12))\nfig.suptitle(\"Apply TSNE Public+Train data\", fontsize=18)\nclasses = ['T rain', 'Public']\ncolours = ListedColormap(['r','b'])\nax1.set(title=\"Used One Hot-Encoded Features\")\nscatter = ax1.scatter(test_public_2D[:,0], test_public_2D[:,1],c=test_public_y,cmap=colours,s = 0.7)\nax1.legend(handles=scatter.legend_elements()[0], labels=classes)\n\nplt.savefig('1.png')\nplt.show()","bd780831":"X_all = np.vstack([train_df_one_hot[select_features].values, public_df_one_hot[select_features].values,private_df_one_hot[select_features].values])\nprint(\"Train Features Shape : \",train_df_one_hot.shape)\nprint(\"Public Features Shape : \",public_df_one_hot.shape)\nprint(\"private Features Shape : \",private_df_one_hot.shape)\nprint(\"X_all Shape: \",X_all.shape)\n\nX_all_2D = get_tsne(X_all)\nX_all_y = [0]*len(train_df_one_hot) + [1]*len(public_df_one_hot) + [2]*len(private_df_one_hot)\nfig, ax1 = plt.subplots(nrows=1,ncols=1,figsize=(12,12))\nfig.suptitle(\"Apply TSNE all data\", fontsize=18)\nclasses = ['T rain', 'Public', 'Private']\ncolours = ListedColormap(['r','b','g'])\nax1.set(title=\"Used 107 Length on Private data\")\nscatter = ax1.scatter(X_all_2D[:,0], X_all_2D[:,1],c=X_all_y,cmap=colours,s = 0.7)\nax1.legend(handles=scatter.legend_elements()[0], labels=classes)\n\nplt.savefig('2.png')\nplt.show()","f23678d3":"## https:\/\/www.kaggle.com\/its7171\/dangerous-features\npublic_df = test.query(\"seq_length == 107\")\nprivate_df = test.query(\"seq_length == 130\")\n\ndef read_bpps_max(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps_arr.append(np.load(f\"..\/input\/stanford-covid-vaccine\/bpps\/{mol_id}.npy\").max(axis=1))\n    return bpps_arr\n\ndef read_bpps_sum(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps_arr.append(np.load(f\"..\/input\/stanford-covid-vaccine\/bpps\/{mol_id}.npy\").sum(axis=1))\n    return bpps_arr\n\ndef read_bpps_nb(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps = np.load(f\"..\/input\/stanford-covid-vaccine\/bpps\/{mol_id}.npy\")\n        bpps_nb = (bpps > 0).sum(axis=0) \/ bpps.shape[0]\n        bpps_arr.append(bpps_nb)\n    return bpps_arr \n\ntrain['bpps_max'] = read_bpps_max(train)\npublic_df['bpps_max'] = read_bpps_max(public_df)\nprivate_df['bpps_max'] = read_bpps_max(private_df)\n\ntrain['bpps_sum'] = read_bpps_sum(train)\npublic_df['bpps_sum'] = read_bpps_sum(public_df)\nprivate_df['bpps_sum'] = read_bpps_sum(private_df)\n\ntrain['bpps_nb'] = read_bpps_nb(train)\npublic_df['bpps_nb'] = read_bpps_nb(public_df)\nprivate_df['bpps_nb'] = read_bpps_nb(private_df)\n\ntrain_bpps = np.transpose( np.array(train[['bpps_max','bpps_sum','bpps_nb']].values.tolist()),(0, 2, 1))\npublic_bpps = np.transpose( np.array(public_df[['bpps_max','bpps_sum','bpps_nb']].values.tolist()),(0, 2, 1))\nprivate_bpps = np.transpose( np.array(private_df[['bpps_max','bpps_sum','bpps_nb']].values.tolist()),(0, 2, 1))\n\nprint(\"train_bpps Shape : \",train_bpps.shape)\nprint(\"public_bpps Shape : \",public_bpps.shape)\nprint(\"private_bpps Shape : \",private_bpps.shape)","61e5bacb":"### BPPS Feaures TSNE on individual columns\n\ntrain_public_private_bpps_max = np.vstack([train_bpps[:,:,0], public_bpps[:,:,0],private_bpps[:,:107,0]])\ntrain_public_private_bpps_sum = np.vstack([train_bpps[:,:,1], public_bpps[:,:,1],private_bpps[:,:107,1]])\ntrain_public_private_bpps_nb = np.vstack([train_bpps[:,:,2], public_bpps[:,:,2],private_bpps[:,:107,2]])\n\nprint(\"train_public_private_bpps_max Shape : \",train_public_private_bpps_max.shape)\nprint(\"train_public_private_bpps_sum Shape : \",train_public_private_bpps_sum.shape)\nprint(\"train_public_private_bpps_nb Shape : \",train_public_private_bpps_nb.shape)\n\nyy = [0]*len(train_bpps) + [1]*len(public_bpps) + [2]*len(private_bpps)\n\nfig, (ax1,ax2,ax3) = plt.subplots(nrows=1,ncols=3,figsize=(21,7))\nfig.suptitle(\"Apply TSNE on Individual BPPS data : ['MAX','SUM','nb']\", fontsize=18)\n\ntrain_public_private_bpps_max_2D = get_tsne(train_public_private_bpps_max)\nclasses = ['train_bpps','public_bpps','private_bpps']\ncolours = ListedColormap(['r','b','g'])\nax1.set(title=\"MAX\")\nscatter = ax1.scatter(train_public_private_bpps_max_2D[:,0], train_public_private_bpps_max_2D[:,1],c=yy,cmap=colours,s = 0.7)\nax1.legend(handles=scatter.legend_elements()[0], labels=classes)\n\ntrain_public_private_bpps_sum_2D = get_tsne(train_public_private_bpps_sum)\nclasses = ['train_bpps','public_bpps','private_bpps']\ncolours = ListedColormap(['r','b','g'])\nax2.set(title=\"MAX\")\nscatter = ax2.scatter(train_public_private_bpps_sum_2D[:,0], train_public_private_bpps_sum_2D[:,1],c=yy,cmap=colours,s = 0.7)\nax2.legend(handles=scatter.legend_elements()[0], labels=classes)\n\ntrain_public_private_bpps_nb_2D = get_tsne(train_public_private_bpps_nb)\nclasses = ['train_bpps','public_bpps','private_bpps']\ncolours = ListedColormap(['r','b','g'])\nax3.set(title=\"NB\")\nscatter = ax3.scatter(train_public_private_bpps_nb_2D[:,0], train_public_private_bpps_nb_2D[:,1],c=yy,cmap=colours,s = 0.7)\nax3.legend(handles=scatter.legend_elements()[0], labels=classes)\n\nplt.savefig('3.png')\nplt.show()","e7ed32af":"### BPPS Feaures TSNE\n\ntrain_public_private_bpps = np.vstack([train_bpps, public_bpps,private_bpps[:,:107,:]])\ntrain_public_private_bpps_2D = get_tsne(train_public_private_bpps)\ntrain_public_private_bpps_y = [0]*len(train_bpps)+[1]*len(public_bpps)+[2]*len(private_bpps)\n\nprint(\"train_public_private_input shape : \",train_public_private_bpps.shape)\n\nfig, ax1 = plt.subplots(nrows=1,ncols=1,figsize=(12,12))\nfig.suptitle(\"Apply TSNE on BPPS Feaures ['bpps_max','bpps_sum','bpps_nb']\", fontsize=18)\nclasses = ['Train', 'Public', 'Private']\ncolours = ListedColormap(['r','b','g'])\nax1.set(title=\"Used 107 Length on Private data\")\nscatter = ax1.scatter(train_public_private_bpps_2D[:,0], train_public_private_bpps_2D[:,1],c=train_public_private_bpps_y,cmap=colours,s = 0.7)\nax1.legend(handles=scatter.legend_elements()[0], labels=classes)\n\nplt.savefig('4.png')\nplt.show()","0d44e157":"## All data","966bd477":"###  Individual data","bdc48331":"## Train + Public","0f9ededa":"## Plot TSNE","51d553ec":"#### NVIDIA created [RAPIDS](https:\/\/rapids.ai\/) \u2013 an open-source data analytics and machine learning acceleration platform that leverages GPUs to accelerate computations. RAPIDS is based on Python, has Pandas-like and Scikit-Learn-like interfaces, is built on Apache Arrow in-memory data format, and can scale from 1 to multi-GPU to multi-nodes. RAPIDS integrates easily into the world\u2019s most popular data science Python-based workflows. RAPIDS accelerates data science end-to-end \u2013 from data prep, to machine learning, to deep learning","00fb675c":"# BPPS Data","f5141d99":"## Method for get TSNE 2D axis","d34ebd3a":"## Load data"}}