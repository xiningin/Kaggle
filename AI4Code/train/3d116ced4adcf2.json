{"cell_type":{"d1a53122":"code","df56180b":"code","539cf1c7":"code","f06488d1":"code","4647423b":"code","b2df0df0":"code","e8867e60":"code","9641c05d":"code","943101e6":"code","a20955eb":"code","e34c892c":"code","dd8f954e":"code","951b82fd":"code","072cbd3c":"code","7c128760":"code","57c11675":"code","0783aefa":"code","3c6f837b":"code","43135ef5":"code","17eaed3d":"code","3b8f264b":"code","3d00f043":"code","23d8ad15":"code","b655bd5b":"code","a7e538c6":"code","0a44462d":"code","bebc6f9b":"code","b2c5004a":"code","1fb0cbaa":"code","94540977":"code","6bb5a76a":"code","550f35c0":"code","f73e87db":"code","fc09a8db":"code","eb2e1088":"code","60aae978":"code","01de1515":"code","f8fccc70":"code","2730e6b3":"code","32ecf911":"code","4a973f2c":"code","512b85f6":"code","7f4a5248":"code","dc741fd8":"code","7306b5ea":"code","992e3b49":"code","82b2cdf2":"markdown","710aa93c":"markdown","867bef81":"markdown","c01e658b":"markdown","4df96f63":"markdown","aab6979d":"markdown","b8f587af":"markdown","a7cecd38":"markdown","75997bc0":"markdown","18f957ef":"markdown","21d83fcc":"markdown","c7e4bc33":"markdown","fbae821d":"markdown","607a3b40":"markdown","7a37d6cd":"markdown","d2d5d83c":"markdown","b06826e7":"markdown","4aee7294":"markdown","a10d887e":"markdown","bf8b5909":"markdown","3479444a":"markdown","59c9b1f1":"markdown","6125c4d8":"markdown","0e6ebdba":"markdown","203d2512":"markdown"},"source":{"d1a53122":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","df56180b":"train_data = pd.read_csv('\/kaggle\/input\/customer-segmentation\/Train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/customer-segmentation\/Test.csv')\ndata = pd.concat([train_data,test_data])\ndata.head()","539cf1c7":"data.info()","f06488d1":"data.isnull().sum()","4647423b":"data.duplicated().sum()","b2df0df0":"data.describe()","e8867e60":"data.describe(include='object')","9641c05d":"categorical_col = data.select_dtypes('object')\n\nfor i in categorical_col:\n    print(data[i].value_counts(), end=\"\\n\\n\")","943101e6":"data.drop_duplicates(inplace=True)","a20955eb":"sns.histplot(data['Work_Experience'],kde=True)\nprint(\"Median value of Work experience feature is:\",data['Work_Experience'].median())","e34c892c":"sns.histplot(data['Family_Size'],kde=True)\nprint(\"Median value of Family size feature is:\",data['Family_Size'].median())","dd8f954e":"data['Work_Experience'] = data['Work_Experience'].fillna(data['Work_Experience'].median())\ndata['Family_Size'] = data['Family_Size'].fillna(data['Family_Size'].median())","951b82fd":"data['Ever_Married'].fillna('No',inplace=True)\ndata['Graduated'].fillna('No',inplace=True)\ndata.dropna(subset=['Profession'],inplace=True)\ndata.dropna(subset=['Var_1'],inplace=True)\ndata.info()","072cbd3c":"data = data.drop('ID',axis=1)","7c128760":"plt.figure(figsize=(10,6))\nplt.title('Segmentation Count')\nsns.countplot(x=data.Segmentation)","57c11675":"plt.figure(figsize=(10,6))\nplt.title('Gender Count color by segmentation')\nsns.countplot(data=data,x='Gender',hue='Segmentation')","0783aefa":"plt.figure(figsize=(10,6))\nplt.title('Married Count color by segmentation')\nsns.countplot(data=data,x='Ever_Married',hue='Segmentation')","3c6f837b":"plt.figure(figsize=(10,6))\nplt.title('Graduated Count color by segmentation')\nsns.countplot(data=data,x='Graduated',hue='Segmentation')","43135ef5":"plt.figure(figsize=(10,6))\nplt.title('Profession Count color by segmentation')\nsns.countplot(data=data,x='Profession',hue='Segmentation')","17eaed3d":"plt.figure(figsize=(10,6))\nplt.title('Spending Score Count color by segmentation')\nsns.countplot(data=data,x='Spending_Score',hue='Segmentation')","3b8f264b":"plt.figure(figsize=(10,6))\nplt.title('Anonymised Category Count color by segmentation')\nsns.countplot(data=data,x='Var_1',hue='Segmentation')","3d00f043":"plt.figure(figsize=(10,6))\nplt.title('Age histogram')\nsns.histplot(data=data,x='Age',kde=True)","23d8ad15":"plt.figure(figsize=(10,6))\nsns.pairplot(data,hue='Segmentation')","b655bd5b":"genders = {'Male':0,'Female':1}\ndata['Gender'] = data['Gender'].map(genders)\n\nmarried = {'No':0,'Yes':1}\ndata['Ever_Married'] = data['Ever_Married'].map(married)\n\ngraduate = {'No':0,'Yes':1}\ndata['Graduated'] = data['Graduated'].map(graduate)\n\nspending_score = {'Low':0,'Average':1,'High':2}\ndata['Spending_Score'] = data['Spending_Score'].map(spending_score)\n\nvar_score = {'Cat_1':1,'Cat_2':2,'Cat_3':3,'Cat_4':4,'Cat_5':5,'Cat_6':6,'Cat_7':7}\ndata['Var_1'] = data['Var_1'].map(var_score)\n\nrank = {'A':0,'B':1,'C':2,'D':3}\ndata['Segmentation'] = data['Segmentation'].map(rank)\n\ndata.head()","a7e538c6":"print(data['Profession'].value_counts())","0a44462d":"data = pd.get_dummies(data)\ndata.head()","bebc6f9b":"from sklearn.model_selection import train_test_split\n\nfeatures = data.drop(columns=['Segmentation'],axis=1)\ntarget = data['Segmentation']\nX_train,X_test,y_train,y_test = train_test_split(features,target,test_size=0.2,random_state=0)","b2c5004a":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report","1fb0cbaa":"models = {'LogisticRegression': LogisticRegression(max_iter=10000),\n          'KNeighborsClassifier': KNeighborsClassifier(),\n          'SVC': SVC(),\n          'DecisionTreeClassifier': DecisionTreeClassifier(),\n          'RandomForestClassifier': RandomForestClassifier(),\n          'GradientBoostingClassifier': GradientBoostingClassifier(),\n          'AdaBoostClassifier': AdaBoostClassifier(),\n          'XGBClassifier': XGBClassifier()}","94540977":"def fit_and_score(models, X_train, X_test, y_train, y_test):\n    np.random.seed(0)\n    \n    model_scores = {}\n    \n    for name, model in models.items():\n        model.fit(X_train,y_train)\n        model_scores[name] = model.score(X_test,y_test)\n\n    model_scores = pd.DataFrame(model_scores,index=['Score']).transpose()\n    model_scores = model_scores.sort_values('Score')\n    \n    \n    return model_scores","6bb5a76a":"model_scores = fit_and_score(models,X_train,X_test,y_train,y_test)","550f35c0":"cm = sns.color_palette('PuBuGn',as_cmap=True)\nscore = model_scores.style.background_gradient(cmap=cm)\nscore","f73e87db":"from sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import f1_score\n\ndef randomsearch_cv_scores(models, params, X_train, X_test, y_train, y_test):\n    np.random.seed(0)\n    \n    model_rs_scores = {}\n    model_rs_best_param = {}\n    \n    for name, model in models.items():\n        rs_model = RandomizedSearchCV(model,\n                                      param_distributions=params[name],\n                                      cv=5,\n                                      n_iter=20,n_jobs=-1,\n                                      verbose=2)        \n        rs_model.fit(X_train,y_train)\n        model_rs_scores[name] = rs_model.score(X_test,y_test)\n        model_rs_best_param[name] = rs_model.best_params_\n        \n    return model_rs_scores, model_rs_best_param","fc09a8db":"models = {'AdaBoostClassifier': AdaBoostClassifier(),\n          'GradientBoostingClassifier': GradientBoostingClassifier()\n         }\n\nparams = {'AdaBoostClassifier': {'n_estimators': [20,50,100,200,400],\n                                'learning_rate': [0.001,0.01,0.1,1.0],\n                                'algorithm': ['SAMME','SAMME.R']},\n          'GradientBoostingClassifier' : {'loss': ['deviance', 'exponential'],\n                                          'learning_rate': [0.001,0.01,0.1,1.0],\n                                          'n_estimators': [20,50,100,200,400],\n                                          'criterion': ['friedman_mse', 'mse'],\n                                          'max_depth' : [2,3,6,10,20],\n                                          'ccp_alpha' : [0.0,0.001,0.01,0.1,1]\n                                          }\n         }","eb2e1088":"model_rs_scores,model_rs_best_param = randomsearch_cv_scores(models,params,X_train,X_test,y_train,y_test)","60aae978":"model_rs_scores = pd.DataFrame(model_rs_scores,index=['Score']).transpose()\nmodel_rs_scores.sort_values('Score')","01de1515":"model_rs_best_param","f8fccc70":"from sklearn.metrics import classification_report,plot_confusion_matrix \nfrom sklearn.model_selection import cross_val_score","2730e6b3":"ada = AdaBoostClassifier(n_estimators=400,learning_rate=0.1,algorithm='SAMME.R')\nada.fit(X_train,y_train)\ny_pred = ada.predict(X_test)","32ecf911":"print(classification_report(y_test,y_pred))","4a973f2c":"plot_confusion_matrix(ada,X_test,y_test,cmap='BuPu')","512b85f6":"cv_accuracy = cross_val_score(ada,X_train,y_train,cv=5,scoring='accuracy')","7f4a5248":"print(f'Cross Validaion accuracy Scores: {cv_accuracy}')\nprint(f'Cross Validation accuracy Mean Score: {cv_accuracy.mean()}')","dc741fd8":"feat_importance = ada.feature_importances_\nfeat_importance = pd.DataFrame(feat_importance,\n                               columns=['Score'],\n                               index=features.columns)","7306b5ea":"feat_importance.sort_values(by='Score',ascending=False).style.background_gradient(cmap=cm)","992e3b49":"plt.figure(figsize=(20,10))\nplt.title('Feature Importances')\nsns.barplot(x=feat_importance.Score,y=feat_importance.index)","82b2cdf2":"### AdaBoostClassifier","710aa93c":"### (B)Dummy Variable Encoding","867bef81":"## 5. Building Model","c01e658b":"**Observations:**\n* Having missing values\n* Having duplicated values\n* Columns with numerical values are of object type","4df96f63":"### Split train test data","aab6979d":"## 1. Reading Dataset","b8f587af":"### (B)Handling Missing Values","a7cecd38":"## Introduction: Business Goal & Problem Definition\n\nThe goal of this project is to study and predict the right group of new customers for an automotive company, so the company can adopt the specific proven marketing strategy to each of them and be more succesful in the business.\n\n![image.jpeg](attachment:5c9902f5-ba50-42f3-a708-4fc9b1112e82.jpeg)","75997bc0":"### (C)Drop Unnecessary column","18f957ef":"## 2. Data Cleaning","21d83fcc":"## 3. Exploratory Data Analysis","c7e4bc33":"**Numerical features**\n* Family_Size: median\n* Work_Experience: median\n\n**Category features**\n* Ever_Married: consider missing values as No\n* Graduated: consider missing values as No\n* Profession: delete\n* Var_1: delete","fbae821d":"### HyperTuning by Random search CV","607a3b40":"### (A)Converting Categorical Variables to Numeric","7a37d6cd":"### (A)Visualization for Categorical Variables","d2d5d83c":"## 6. Model Evalution","b06826e7":"### (B)Visualization for Numerical Variables","4aee7294":"**Conclusion:**\n\nThe chosen model was AdaBoost since it\u00b4s the most accurate, although it has limitations and doesn\u2019t present a high accuracy.Through the analysis of feature importance, we can assume that Age is the tje most important features of classification.","a10d887e":"### Baseline Model Training","bf8b5909":"### (A)Remove duplicated rows","3479444a":"For that we use the Customer Segmentation Classification Dataset available in Kaggle, here is the columns in our data:\n* **ID**-Unique ID\n\n* **Gender**-Gender of the customer\n\n* **Ever_Married**-Marital status of the customer\n\n* **Age**-Age of the customer\n\n* **Graduated**-Is the customer a graduate?\n\n* **Profession**-Profession of the customer\n\n* **Work_Experience**-Work Experience in years\n\n* **Spending_Score**-Spending score of the customer\n\n* **Family_Size**-Number of family members for the customer (including the customer)\n\n* **Var_1**-Anonymised Category for the customer\n\n* **Segmentation**-(target) Customer Segment of the customer","59c9b1f1":"When the distribution is skewed, using **median values** to replace the missing values","6125c4d8":"### Feature Importance","0e6ebdba":"## 4. Feature Engineering","203d2512":"We will now based **AdaBoostClassifier** and **GradientBoostingClassifier** on the CV on the f1 scores"}}