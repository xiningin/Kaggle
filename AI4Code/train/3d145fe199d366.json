{"cell_type":{"86e9a25d":"code","67abd054":"code","59bfc044":"code","8810a0ab":"code","ca388f84":"code","27e26fbd":"code","0baba859":"code","d2c36f86":"code","e2c62cd7":"code","ff5fd085":"code","2777ac72":"code","764aa4e5":"code","55ad5f21":"markdown","84af51f4":"markdown"},"source":{"86e9a25d":"import argparse\nimport os\nimport numpy as np\nimport math\n\nimport torchvision.transforms as transforms\nfrom torchvision.utils import save_image\n\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt \n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch\nimport torchvision\nimport torchvision.transforms.functional as tf\nimport PIL","67abd054":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n\ndef get_dataloader(trainset, size):\n    new_trainset = torch.from_numpy(trainset.astype(np.float32)).view(-1, 1, 28, 28)\n    new_trainset = tf.resize(new_trainset, size, interpolation=PIL.Image.NEAREST)\n    batch_size = 64\n    return DataLoader(new_trainset, batch_size = batch_size, num_workers = 1, shuffle=True)\n\ndef get_latent_noise(batch_size, dim):\n    z = torch.empty(batch_size, dim)\n    nn.init.normal_(z, 0, 1.)\n    z = z.to(device)\n    return z\n\ndef calc_gradient_penalty(netD, real, fake):\n    alpha = torch.rand(real.shape[0], 1, 1, 1).to(device)\n    interpolation = alpha * real + (1-alpha) * fake\n    interpolation = interpolation.to(device).requires_grad_(True)\n    \n    LAMBDA = 10\n    disc = netD(interpolation)\n    grad_out = torch.ones(disc.shape).to(device)\n    \n    gradients = torch.autograd.grad(outputs=disc, inputs=interpolation, \n                                   grad_outputs=grad_out, \n                                   create_graph=True, retain_graph=True, only_inputs=True)[0]\n    penalty = ((gradients.view(real.shape[0], -1).norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n    \n    return penalty","59bfc044":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\ntrainset = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        if 'png' in filename:\n            pathfile = os.path.join(dirname, filename)\n            img = cv2.imread(pathfile)\n            trainset.append(img)\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\ntrainset = np.array(trainset)\n\nmean_imgs = np.mean(trainset)\nstd_imgs = np.std(trainset)*1.2\ndef normalize(trainset):\n    mean, std = mean_imgs, std_imgs\n    trainset = (trainset-mean)\/std\n    print(np.max(trainset), np.min(trainset))\n    return trainset\n\ntrainset = normalize(trainset)\n\ntrainset = torch.from_numpy(trainset.transpose((0, 3, 1, 2)).astype(np.float32))\nprint(trainset.shape)\ndataloader = DataLoader(trainset, batch_size = 64, shuffle = True, num_workers = 2)","8810a0ab":"class MinibatchDiscrimination(nn.Module):\n    def __init__(self, in_features, out_features, kernel_dims, mean=False):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.kernel_dims = kernel_dims\n        self.mean = mean\n        self.T = nn.Parameter(torch.Tensor(in_features, out_features, kernel_dims))\n        torch.nn.init.normal(self.T, 0, 1)\n\n    def forward(self, x):\n        # x is NxA\n        # T is AxBxC\n        matrices = x.mm(self.T.view(self.in_features, -1))\n        matrices = matrices.view(-1, self.out_features, self.kernel_dims)\n\n        M = matrices.unsqueeze(0)  # 1xNxBxC\n        M_T = M.permute(1, 0, 2, 3)  # Nx1xBxC\n        norm = torch.abs(M - M_T).sum(3)  # NxNxB\n        expnorm = torch.exp(-norm)\n        o_b = (expnorm.sum(0) - 1)   # NxB, subtract self distance\n        if self.mean:\n            o_b \/= x.size(0) - 1\n\n        x = torch.cat([x, o_b], 1)\n        return x","ca388f84":"\n\nos.makedirs(\"images\", exist_ok=True)\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--n_epochs\", type=int, default=50000, help=\"number of epochs of training\")\nparser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\nparser.add_argument(\"--lr\", type=float, default=0.0005, help=\"adam: learning rate\")\nparser.add_argument(\"--b1\", type=float, default=0.3, help=\"adam: decay of first order momentum of gradient\")\nparser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\nparser.add_argument(\"--n_cpu\", type=int, default=2, help=\"number of cpu threads to use during batch generation\")\nparser.add_argument(\"--latent_dim\", type=int, default=128, help=\"dimensionality of the latent space\")\nparser.add_argument(\"--img_size\", type=int, default=32, help=\"size of each image dimension\")\nparser.add_argument(\"--channels\", type=int, default=3, help=\"number of image channels\")\nparser.add_argument(\"--sample_interval\", type=int, default=400, help=\"interval between image sampling\")\nparser.add_argument('--n_critic', type=int, default=2, help='number of critics updates per generator update')\nopt, unknown = parser.parse_known_args()\n\nprint(opt)\n\n\ncuda = True if torch.cuda.is_available() else False\n\ng_his, fake_his, real_his = [], [], []\nd_his = []\n\ndef weights_init_normal(m):\n    classname = m.__class__.__name__\n    if classname.find(\"Conv\") != -1:\n        torch.nn.init.normal_(m.weight.data, 0.0, 0.05)\n    elif classname.find(\"BatchNorm2d\") != -1:\n        torch.nn.init.normal_(m.weight.data, 0.0, 0.05)\n        torch.nn.init.constant_(m.bias.data, 0.0)\n\n\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n\n        self.init_size = opt.img_size \/\/ 4\n        self.hidden_channel = 128\n        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, self.hidden_channel * self.init_size ** 2))\n        \n        self.conv_blocks = nn.Sequential(\n            nn.BatchNorm2d(self.hidden_channel),\n            nn.Upsample(scale_factor=2, mode='nearest'),\n            nn.Conv2d(self.hidden_channel, self.hidden_channel, 3, stride=1, padding=1, padding_mode='reflect'),\n            nn.BatchNorm2d(self.hidden_channel, 0.8),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Upsample(scale_factor=2, mode='nearest'),\n            nn.Conv2d(self.hidden_channel, self.hidden_channel\/\/2, 3, stride=1, padding=1, padding_mode='reflect'),\n            nn.BatchNorm2d(self.hidden_channel\/\/2, 0.8),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(self.hidden_channel\/\/2, opt.channels, 3, stride=1, padding=1, padding_mode='reflect'),\n#             nn.Tanh(),\n        )\n\n    def forward(self, z):\n        out = self.l1(z)\n        out = out.view(out.shape[0], self.hidden_channel, self.init_size, self.init_size)\n        img = self.conv_blocks(out)\n        return img\n\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        def discriminator_block(in_filters, out_filters, bn=True):\n            block = [nn.Conv2d(in_filters, out_filters, 3, 1, 1, padding_mode='reflect'), \n                     nn.LeakyReLU(0.2, inplace=True),\n                     nn.AvgPool2d(2, stride=2),\n                     nn.Dropout2d(0.2)]\n            if bn:\n                block.append(nn.BatchNorm2d(out_filters, 0.8))\n            return block\n        self.hidden_channel = 16\n        self.model = nn.Sequential(\n            *discriminator_block(opt.channels, self.hidden_channel, bn=False),\n            *discriminator_block(self.hidden_channel, self.hidden_channel*2),\n            *discriminator_block(self.hidden_channel*2, self.hidden_channel*4),\n            *discriminator_block(self.hidden_channel*4, self.hidden_channel*8),\n        )\n\n        # The height and width of downsampled image\n        ds_size = opt.img_size \/\/ 2 ** 4\n        self.adv_layer = nn.Sequential(MinibatchDiscrimination(self.hidden_channel*8 * ds_size ** 2, 32, 32),\n                            nn.Linear(32 + self.hidden_channel*8 * ds_size ** 2, 1))\n\n    def forward(self, img):\n#         print(img.shape)\n        out = self.model(img)\n#         print(out.shape)\n        out = out.view(out.shape[0], -1)\n        validity = self.adv_layer(out)\n\n        return validity\n\n\n# Loss function\nadversarial_loss = torch.nn.BCELoss()\n\n# Initialize generator and discriminator\ngenerator = Generator()\ndiscriminator = Discriminator()\n\nif cuda:\n    generator.cuda()\n    discriminator.cuda()\n    adversarial_loss.cuda()\n\n# Initialize weights\ngenerator.apply(weights_init_normal)\ndiscriminator.apply(weights_init_normal)\n\n# Configure data loader\n\n\n# Optimizers\noptimizer_G = torch.optim.RMSprop(generator.parameters(), lr=opt.lr)\noptimizer_D = torch.optim.RMSprop(discriminator.parameters(), lr=opt.lr)\n\nTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n\n# ----------\n#  Training\n# ----------\n\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nfor epoch in range(opt.n_epochs):\n    for i, (imgs) in enumerate(dataloader):\n        # Configure input\n        real_imgs = Variable(imgs.type(Tensor))\n#         real_label = torch.ones(real_imgs.shape[0], 1).to(device)\n#         fake_label = torch.zeros(real_imgs.shape[0], 1).to(device)\n       \n        # ---------------------\n        #  Train Discriminator\n        # ---------------------\n\n        optimizer_D.zero_grad()\n        \n        # Sample noise as generator input\n        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n\n        # Generate a batch of images\n        fake_imgs = generator(z).detach()\n        # Adversarial loss\n        loss_D = -torch.mean(discriminator(real_imgs)) + torch.mean(discriminator(fake_imgs))\n#         loss_D = adversarial_loss(discriminator(fake_imgs), fake_label) + adversarial_loss(discriminator(real_imgs), real_label)\n\n        loss_D.backward()\n\n        grad_loss = calc_gradient_penalty(discriminator, real_imgs.detach(), fake_imgs.detach())\n        grad_loss.backward()\n\n        \n        optimizer_D.step()\n         \n        d_his.append(-loss_D.item())\n        if i % opt.n_critic != 0:\n            continue\n            \n        # -----------------\n        #  Train Generator\n        # -----------------\n\n        optimizer_G.zero_grad()\n\n        # Sample noise as generator input\n        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n\n        # Generate a batch of images\n        gen_imgs = generator(z)\n        # Adversarial loss\n        loss_G = -torch.mean(discriminator(gen_imgs))\n#         loss_G = adversarial_loss(discriminator(gen_imgs), real_label)\n\n        loss_G.backward()\n        optimizer_G.step()\n\n        # -----------------\n        #  Update history\n        # -----------------\n\n        g_his.append(-loss_G.item())\n\n        batches_done = epoch * len(dataloader) + i\n        if batches_done % opt.sample_interval == 0:\n            save_image(gen_imgs.data[:25]*std_imgs + mean_imgs, \"images\/%d.png\" % batches_done, nrow=5, normalize=True,range=(0, 255))\n            print(\n                \"[Epoch %d\/%d] [Batch %d] [D loss: %f] [G loss: %f]\"\n                % (epoch, opt.n_epochs, batches_done, d_his[-1], -loss_G.item())\n            )","27e26fbd":"\n# z = Variable(Tensor(np.random.normal(0, 1, (3, opt.latent_dim))))\n# print(z.shape)\n# gen_imgs = generator(z)\n# print(gen_imgs.shape)","0baba859":"# G, D = generator, discriminator\n# x = torch.rand(12, opt.latent_dim)\n# print(x.shape)\n# # # G._grow_net()\n# # # D._grow_net()\n# x_ = G(x)\n# print(x_.shape)\n\n# y = D(x_)\n# print(y.shape)","d2c36f86":"with torch.no_grad():\n    generator.eval()\n    z = get_latent_noise(100, dim = opt.latent_dim)\n    gen_imgs = generator(z)\n    save_image(gen_imgs*std_imgs+mean_imgs, 'result.png',\n                            nrow=10, normalize=True, range=(0, 255))","e2c62cd7":"plt.figure(figsize=(10, 10))\nx = range(len(d_his))\nplt.plot(x, d_his, label='wasserstein estimate')\nplt.legend()\nplt.show()","ff5fd085":"plt.figure(figsize=(10, 10))\nx = range(len(g_his))\nplt.plot(x, g_his, label='generator realness')\nplt.legend()\nplt.show()","2777ac72":"torch.save(generator.state_dict(), 'model.pt')","764aa4e5":"print(generator)\nprint(discriminator)","55ad5f21":"# Result","84af51f4":"# What is new\n* use minibatch discriminator\n* use wasserstein gradient penalty"}}