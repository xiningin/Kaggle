{"cell_type":{"486395ec":"code","8bc0ed4c":"code","c38f6326":"code","d9ae5461":"code","e1345bc6":"code","525183b0":"code","f10986c9":"code","fa761388":"code","949825dc":"code","68496777":"code","7a0f290f":"code","57f8dd78":"code","2d41f8bd":"code","bae86708":"code","f4e7e0b8":"code","31901ae8":"code","b46d80ce":"code","8143e34c":"code","a957419e":"markdown"},"source":{"486395ec":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","8bc0ed4c":"#https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df\n\n\ndef import_data(file):\n    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n    df = reduce_mem_usage(df)\n    return df\n\nimport matplotlib.pyplot as plt\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=True,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()\n    \n\ntrain = import_data(\"..\/input\/train.csv\")\ntest = import_data(\"..\/input\/test.csv\")\n#train.head()","c38f6326":"test_id = test['id']\ntest.drop(['id'], axis=1, inplace=True)\n\nimport lightgbm as lgb\ndic = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\ndic1 = {'CA':0,'DA':1,'SS':3,'LOFT':4}\ntrain[\"event\"] = train[\"event\"].apply(lambda x: dic[x])\ntrain[\"event\"] = train[\"event\"].astype('int8')\ntrain['experiment'] = train['experiment'].apply(lambda x: dic1[x])\ntest['experiment'] = test['experiment'].apply(lambda x: dic1[x])\n\ntrain['experiment'] = train['experiment'].astype('int8')\ntest['experiment'] = test['experiment'].astype('int8')\n\n#train.info()\ny = train['event']\ntrain.drop(['event'], axis=1, inplace=True)","d9ae5461":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n         train, y, test_size=0.4, random_state=42)","e1345bc6":"from imblearn.over_sampling import SMOTE\nX_train, y_train = SMOTE().fit_resample(X_train, y_train.ravel())","525183b0":"from sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.ensemble import VotingClassifier\nimport lightgbm as lgb\n\n\nclf1 = lgb.LGBMClassifier(\n        n_estimators=100,\n        learning_rate=0.05)\nclf2 = lgb.LGBMClassifier(\n        n_estimators=300,\n        learning_rate=0.1)\nclf3 = lgb.LGBMClassifier(\n        n_estimators=500,\n        learning_rate=0.2)","f10986c9":"clf1.fit(X_train, y_train)\npred1 = clf1.predict(X_test)\nprint(\"lgbm1: \", accuracy_score(pred1, y_test))\n\npred = clf1.predict_proba(test)\nsub = pd.DataFrame(pred,columns=['A', 'B', 'C', 'D'])\nsub['id'] = test_id\ncols = sub.columns.tolist()\ncols = cols[-1:] + cols[:-1]\nsub = sub[cols]\nsub.to_csv(\"sub_lgb1.csv\", index=False)","fa761388":"cnf_matrix = confusion_matrix(y_test, pred1)\nplot_confusion_matrix(cnf_matrix, classes=[\"A\", \"B\", \"C\", \"D\"],\n                      title='Confusion matrix, lgbm1')","949825dc":"clf2.fit(X_train, y_train)\npred2 = clf2.predict(X_test)\nprint(\"lgbm2: \", accuracy_score(pred2, y_test))","68496777":"cnf_matrix = confusion_matrix(y_test, pred2)\nplot_confusion_matrix(cnf_matrix, classes=[\"A\", \"B\", \"C\", \"D\"],\n                      title='Confusion matrix, lgbm2')","7a0f290f":"clf3.fit(X_train, y_train)\npred3 = clf3.predict(X_test)\nprint(\"lgbm3: \", accuracy_score(pred3, y_test))","57f8dd78":"cnf_matrix = confusion_matrix(y_test, pred3)\nplot_confusion_matrix(cnf_matrix, classes=[\"A\", \"B\", \"C\", \"D\"],\n                      title='Confusion matrix, lgbm3')","2d41f8bd":"eclf1 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\neclf1 = eclf1.fit(X_train, y_train)\npred_v1 = eclf1.predict(X_test)\nprint(\"VotingClassifier 1: \", accuracy_score(pred_v1, y_test))","bae86708":"cnf_matrix = confusion_matrix(y_test, pred_v1)\nplot_confusion_matrix(cnf_matrix, classes=[\"A\", \"B\", \"C\", \"D\"],\n                      title='Confusion matrix, VotingClassifier 1')","f4e7e0b8":"eclf2 = VotingClassifier(estimators=[\n        ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n        voting='soft')\neclf2 = eclf2.fit(X_train, y_train)\npred_v2 = eclf2.predict(X_test)\nprint(\"VotingClassifier 2: \", accuracy_score(pred_v2, y_test))\n\npred = eclf2.predict_proba(test)\nsub = pd.DataFrame(pred,columns=['A', 'B', 'C', 'D'])\nsub['id'] = test_id\ncols = sub.columns.tolist()\ncols = cols[-1:] + cols[:-1]\nsub = sub[cols]\nsub.to_csv(\"sub_vt2.csv\", index=False)","31901ae8":"cnf_matrix = confusion_matrix(y_test, pred_v2)\nplot_confusion_matrix(cnf_matrix, classes=[\"A\", \"B\", \"C\", \"D\"],\n                      title='Confusion matrix, VotingClassifier 2')","b46d80ce":"eclf3 = VotingClassifier(estimators=[\n       ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n       voting='soft', weights=[2,1,1],\n       flatten_transform=True)\neclf3 = eclf3.fit(X_train, y_train)\npred_v3 = eclf3.predict(X_test)\nprint(\"VotingClassifier 3: \", accuracy_score(pred_v3, y_test))","8143e34c":"cnf_matrix = confusion_matrix(y_test, pred_v3)\nplot_confusion_matrix(cnf_matrix, classes=[\"A\", \"B\", \"C\", \"D\"],\n                      title='Confusion matrix, VotingClassifier 3:')","a957419e":"***Imbalance learning***"}}