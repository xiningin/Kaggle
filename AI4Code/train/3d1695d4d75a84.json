{"cell_type":{"04e43268":"code","eae565ca":"code","74a21679":"code","bbaf1265":"code","9440b864":"code","f663574a":"code","941d3081":"code","0246b2c9":"code","c607f484":"code","f1a09615":"code","17764031":"code","37795cb5":"code","691fdb62":"code","780a28e8":"code","0cb35638":"code","a5bb073d":"code","5b61e44c":"code","289f2caf":"code","977f85b9":"code","a47e0330":"code","a77c4c89":"code","15ed56c7":"code","db69a40e":"code","335b94f2":"code","28990ae9":"code","b9d24889":"code","3bac1d15":"markdown","374bd286":"markdown","cad6ba22":"markdown","1db762f0":"markdown","28e877f4":"markdown","fa4b7424":"markdown","06184583":"markdown","5c18a35c":"markdown","98cfa8ba":"markdown","a1a66adb":"markdown","00103c80":"markdown","f3c56444":"markdown","27638fb0":"markdown","dfd66fe5":"markdown","ee08a7e4":"markdown","6181dec3":"markdown","ed040208":"markdown","098f821c":"markdown","f58d2e1f":"markdown","05956c8e":"markdown","88c4d16d":"markdown","42f96b4e":"markdown","805ec7d9":"markdown","a4978d09":"markdown"},"source":{"04e43268":"import pandas as pd\nimport numpy as np\n\ntrain_df = pd.read_csv('..\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('..\/input\/titanic\/test.csv')\nsubmission_df = pd.read_csv('..\/input\/titanic\/gender_submission.csv')","eae565ca":"train_df = train_df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])\ntest_df = test_df.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'])","74a21679":"age_mean = train_df['Age'].mean()\nfare_mean = train_df['Fare'].mean()\n\ntrain_df['Age'] = train_df['Age'].fillna(age_mean)\ntest_df['Age'] = test_df['Age'].fillna(age_mean)\ntrain_df['Fare'] = train_df['Fare'].fillna(fare_mean)\ntest_df['Fare'] = test_df['Fare'].fillna(fare_mean)\ntrain_df['Embarked'] = train_df['Embarked'].fillna('S')\ntest_df['Embarked'] = test_df['Embarked'].fillna('S')\ntrain_df.loc[train_df['Sex']=='male', 'Sex'] = 0\ntrain_df.loc[train_df['Sex']=='female', 'Sex'] = 1\ntest_df.loc[test_df['Sex']=='male', 'Sex'] = 0\ntest_df.loc[test_df['Sex']=='female', 'Sex'] = 1\ntrain_df.loc[train_df['Embarked']=='S', 'Embarked'] = 0\ntrain_df.loc[train_df['Embarked']=='C', 'Embarked'] = 1\ntrain_df.loc[train_df['Embarked']=='Q', 'Embarked'] = 2\ntest_df.loc[test_df['Embarked']=='S', 'Embarked'] = 0\ntest_df.loc[test_df['Embarked']=='C', 'Embarked'] = 1\ntest_df.loc[test_df['Embarked']=='Q', 'Embarked'] = 2\n\ntrain_df['Sex'] = train_df['Sex'].astype(int)\ntest_df['Sex'] = test_df['Sex'].astype(int)\ntrain_df['Embarked'] = train_df['Embarked'].astype(int)\ntest_df['Embarked'] = test_df['Embarked'].astype(int)","bbaf1265":"X_train = train_df.iloc[:, 1:]\ny_train = train_df.iloc[:, 0]\nX_test = test_df","9440b864":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\n\nss = StandardScaler()\nmms = MinMaxScaler()\n\nss.fit(X_train)\nX_train_ss = ss.transform(X_train)\nX_test_ss = ss.transform(X_test)\n\nmms.fit(X_train)\nX_train_mms = mms.transform(X_train)\nX_test_mms = mms.transform(X_test)","f663574a":"from sklearn.svm import SVC\n\nsvc = SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n   max_iter=-1, probability=False, random_state=3, shrinking=True,\n   tol=0.001, verbose=False)\nsvc.fit(X_train, y_train)\n\nsubmission_df['Survived'] = svc.predict(X_test)\nsubmission_df.to_csv('submission_SVC_rbf_NonScaling.csv', index=False)","941d3081":"svc = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n   max_iter=-1, probability=False, random_state=3, shrinking=True,\n   tol=0.001, verbose=False)\nsvc.fit(X_train_ss, y_train)\n\nsubmission_df['Survived'] = svc.predict(X_test_ss)\nsubmission_df.to_csv('submission_SVC_rbf_StandardScaler.csv', index=False)","0246b2c9":"svc = SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n   decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n   max_iter=-1, probability=False, random_state=3, shrinking=True,\n   tol=0.001, verbose=False)\nsvc.fit(X_train_mms, y_train)\n\nsubmission_df['Survived'] = svc.predict(X_test_mms)\nsubmission_df.to_csv('submission_SVC_rbf_MinMaxScaler.csv', index=False)","c607f484":"svc = SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n   max_iter=-1, probability=False, random_state=None, shrinking=True,\n   tol=0.001, verbose=False)\nsvc.fit(X_train, y_train)\n\nsubmission_df['Survived'] = svc.predict(X_test)\nsubmission_df.to_csv('submission_SVC_linear_NonScaling.csv', index=False)","f1a09615":"svc = SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n   max_iter=-1, probability=False, random_state=None, shrinking=True,\n   tol=0.001, verbose=False)\nsvc.fit(X_train_ss, y_train)\n\nsubmission_df['Survived'] = svc.predict(X_test_ss)\nsubmission_df.to_csv('submission_SVC_linear_StandardScaler.csv', index=False)","17764031":"svc = SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n   decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n   max_iter=-1, probability=False, random_state=None, shrinking=True,\n   tol=0.001, verbose=False)\nsvc.fit(X_train_mms, y_train)\n\nsubmission_df['Survived'] = svc.predict(X_test_mms)\nsubmission_df.to_csv('submission_SVC_linear_MinMaxScaler.csv', index=False)","37795cb5":"from sklearn.neighbors import KNeighborsClassifier\n\nknc = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n            metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n            weights='uniform')\nknc.fit(X_train, y_train)\n\nsubmission_df['Survived'] = knc.predict(X_test)\nsubmission_df.to_csv('submission_KNeighborsClassifier_NonScaling.csv', index=False)","691fdb62":"knc = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n            metric_params=None, n_jobs=1, n_neighbors=12, p=2,\n            weights='uniform')\nknc.fit(X_train_ss, y_train)\n\nsubmission_df['Survived'] = knc.predict(X_test_ss)\nsubmission_df.to_csv('submission_KNeighborsClassifier_StandardScaler.csv', index=False)","780a28e8":"knc = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n            metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n            weights='uniform')\nknc.fit(X_train_mms, y_train)\n\nsubmission_df['Survived'] = knc.predict(X_test_mms)\nsubmission_df.to_csv('submission_KNeighborsClassifier_MinMaxScaler.csv', index=False)","0cb35638":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n           penalty='l2', random_state=3, solver='liblinear', tol=0.0001,\n           verbose=0, warm_start=False)\nlr.fit(X_train, y_train)\n\nsubmission_df['Survived'] = lr.predict(X_test)\nsubmission_df.to_csv('submission_LogisticRegression_NonScaling.csv', index=False)","a5bb073d":"lr = LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n           penalty='l2', random_state=3, solver='liblinear', tol=0.0001,\n           verbose=0, warm_start=False)\nlr.fit(X_train_ss, y_train)\n\nsubmission_df['Survived'] = lr.predict(X_test_ss)\nsubmission_df.to_csv('submission_LogisticRegression_StandardScaler.csv', index=False)","5b61e44c":"lr = LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n           penalty='l2', random_state=3, solver='liblinear', tol=0.0001,\n           verbose=0, warm_start=False)\nlr.fit(X_train_mms, y_train)\n\nsubmission_df['Survived'] = lr.predict(X_test_mms)\nsubmission_df.to_csv('submission_LogisticRegression_MinMaxScaler.csv', index=False)","289f2caf":"from sklearn.linear_model import Perceptron\n\nppn = Perceptron(alpha=1e-10, class_weight=None, eta0=1.0, fit_intercept=True,\n       max_iter=10000, n_jobs=1, penalty=None, random_state=3,\n       shuffle=True, tol=None, verbose=0, warm_start=False)\nppn.fit(X_train, y_train)\n\nsubmission_df['Survived'] = ppn.predict(X_test)\nsubmission_df.to_csv('submission_Perceptron_NonScaling.csv', index=False)","977f85b9":"ppn = Perceptron(alpha=1e-10, class_weight=None, eta0=1.0, fit_intercept=True,\n       max_iter=10000, n_jobs=1, penalty=None, random_state=3,\n       shuffle=True, tol=None, verbose=0, warm_start=False)\nppn.fit(X_train_ss, y_train)\n\nsubmission_df['Survived'] = ppn.predict(X_test_ss)\nsubmission_df.to_csv('submission_Perceptron_StandardScaler.csv', index=False)","a47e0330":"ppn = Perceptron(alpha=1e-10, class_weight=None, eta0=1.0, fit_intercept=True,\n       max_iter=10000, n_jobs=1, penalty=None, random_state=3,\n       shuffle=True, tol=None, verbose=0, warm_start=False)\nppn.fit(X_train_mms, y_train)\n\nsubmission_df['Survived'] = ppn.predict(X_test_mms)\nsubmission_df.to_csv('submission_Perceptron_MinMaxScaler.csv', index=False)","a77c4c89":"from sklearn.neural_network import MLPClassifier\n\nmlpc = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n        hidden_layer_sizes=(30, 20, 10), learning_rate='constant',\n        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n        nesterovs_momentum=True, power_t=0.5, random_state=3, shuffle=True,\n        solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n        warm_start=False)\nmlpc.fit(X_train, y_train)\n\nsubmission_df['Survived'] = mlpc.predict(X_test)\nsubmission_df.to_csv('submission_MLPClassifier_NonScaling.csv', index=False)","15ed56c7":"mlpc = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n        hidden_layer_sizes=(100,), learning_rate='constant',\n        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n        nesterovs_momentum=True, power_t=0.5, random_state=3, shuffle=True,\n        solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n        warm_start=False)\nmlpc.fit(X_train_ss, y_train)\n\nsubmission_df['Survived'] = mlpc.predict(X_test_ss)\nsubmission_df.to_csv('submission_MLPClassifier_StandardScaler.csv', index=False)","db69a40e":"mlpc = MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n        beta_2=0.999, early_stopping=False, epsilon=1e-08,\n        hidden_layer_sizes=(50, 50), learning_rate='constant',\n        learning_rate_init=0.001, max_iter=200, momentum=0.9,\n        nesterovs_momentum=True, power_t=0.5, random_state=3, shuffle=True,\n        solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n        warm_start=False)\nmlpc.fit(X_train_mms, y_train)\n\nsubmission_df['Survived'] = mlpc.predict(X_test_mms)\nsubmission_df.to_csv('submission_MLPClassifier_MinMaxScaler.csv', index=False)","335b94f2":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n             max_depth=7, max_features='auto', max_leaf_nodes=None,\n             min_impurity_decrease=0.0, min_impurity_split=None,\n             min_samples_leaf=1, min_samples_split=2,\n             min_weight_fraction_leaf=0.0, n_estimators=14, n_jobs=1,\n             oob_score=False, random_state=3, verbose=0, warm_start=False)\nrfc.fit(X_train, y_train)\n\nsubmission_df['Survived'] = rfc.predict(X_test)\nsubmission_df.to_csv('submission_RandomForestClassifier_NonScaling.csv', index=False)","28990ae9":"rfc = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n             max_depth=7, max_features='auto', max_leaf_nodes=None,\n             min_impurity_decrease=0.0, min_impurity_split=None,\n             min_samples_leaf=1, min_samples_split=2,\n             min_weight_fraction_leaf=0.0, n_estimators=14, n_jobs=1,\n             oob_score=False, random_state=3, verbose=0, warm_start=False)\nrfc.fit(X_train_ss, y_train)\n\nsubmission_df['Survived'] = rfc.predict(X_test_ss)\nsubmission_df.to_csv('submission_RandomForestClassifier_StandardScaler.csv', index=False)","b9d24889":"rfc = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n             max_depth=7, max_features='auto', max_leaf_nodes=None,\n             min_impurity_decrease=0.0, min_impurity_split=None,\n             min_samples_leaf=1, min_samples_split=2,\n             min_weight_fraction_leaf=0.0, n_estimators=14, n_jobs=1,\n             oob_score=False, random_state=3, verbose=0, warm_start=False)\nrfc.fit(X_train_mms, y_train)\n\nsubmission_df['Survived'] = rfc.predict(X_test_mms)\nsubmission_df.to_csv('submission_RandomForestClassifier_MinMaxScaler.csv', index=False)","3bac1d15":"## 2-2. SVC Linear - StandardScaler","374bd286":"## 3-3. KNeighborsClassifier - MinMaxScaler","cad6ba22":"## 7-1. RandomForestClassifier - NonScaling","1db762f0":"## 2-3. SVC Linear - MinMaxScaler","28e877f4":"* Thanks for https:\/\/newtechnologylifestyle.net\/kaggle_titanic\/","fa4b7424":"## 6-1. MLPClassifier - NonScaling","06184583":"## 1-1. SVC RBF - NonScaling","5c18a35c":"## 5-1. Perceptron - NonScaling","98cfa8ba":"## 1-3. SVC RBF - MinMaxScaler","a1a66adb":"## 3-2. KNeighborsClassifier - StandardScaler","00103c80":"## 4-3. LogisticRegression - MinMaxScaler","f3c56444":"## 5-3. Perceptron - MinMaxScaler","27638fb0":"## 4-1. LogisticRegression - NonScaling","dfd66fe5":"## 6-2. MLPClassifier - StandardScaler","ee08a7e4":"## 1-2. SVC RBF - StandardScaler","6181dec3":"# Modeling, Submission","ed040208":"## 3-1. KNeighborsClassifier - NonScaling","098f821c":"## 7-2. RandomForestClassifier - StandardScaler","f58d2e1f":"## 7-3. RandomForestClassifier - MinMaxScaler","05956c8e":"## 6-3. MLPClassifier - MinMaxScaler","88c4d16d":"## 5-2. Perceptron - StandardScaler","42f96b4e":"# Import, Read CSV, Preprocessing","805ec7d9":"## 2-1. SVC Linear - NonScaling","a4978d09":"## 4-2. LogisticRegression - StandardScaler"}}