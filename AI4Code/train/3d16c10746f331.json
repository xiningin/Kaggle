{"cell_type":{"3a6f0024":"code","5e9ef28c":"code","59aef7c9":"code","67a8214d":"code","b76c1643":"code","172d1f15":"code","368e7192":"code","59ea7886":"code","5939980a":"code","e38d3650":"code","e27b04ff":"code","4376d944":"code","1b5678ec":"code","eee7262e":"code","297fd954":"code","0dc45e17":"code","9471a6c2":"code","ec80c268":"code","083146db":"code","de46bf9a":"code","5d4fd7cb":"code","65508434":"code","5a840e89":"code","16cce7a8":"code","8517dc70":"code","fc27331c":"markdown","fdc65f32":"markdown","058948e6":"markdown","1d9f3494":"markdown","d49e8905":"markdown","79c728ea":"markdown","1a8ebade":"markdown","4dd650c4":"markdown","f625f0df":"markdown","f9828c7b":"markdown","320845c5":"markdown","a5b47d0c":"markdown","4d4c3c94":"markdown","514e9bb6":"markdown","56cc9eb5":"markdown","0655dd2e":"markdown","2e927a9d":"markdown","68e3b6e2":"markdown","cf928d9b":"markdown","cd0baeaf":"markdown"},"source":{"3a6f0024":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport itertools\nimport gc","5e9ef28c":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df\n\n\ndef rmse(predictions, targets):\n    return np.sqrt(((predictions - targets) ** 2).mean())\n\n#from https:\/\/www.kaggle.com\/marlesson\/simple-pytorch-model don't know if is right\nweigths = [1]*16 + [0.75]*16 + [0.6]*16 + [0.5]*16 + [0.43]*16 + [0.38]*16 + [0.33]*16\ndef wrmse(predictions, targets, weigths):\n    return np.sqrt((((predictions - targets) ** 2)*weigths).mean())\n","59aef7c9":"columns_size = None\nrows_size = 1000","67a8214d":"path='\/kaggle\/input\/kddbr-2020\/'\n\ndef get_files(years=[],months=12,pre=''):\n    files = []\n    \n    for year in years:\n        for month in range(1,months + 1):\n            file = F'0{month}' if month < 10 else str(month)\n            files.append( F'{path}\/{pre}{year}{file}.csv' )\n    return files\n\nbase = [pd.read_csv(file,parse_dates=['date']) for file in get_files( ['2018'], 12) ]\nbase = pd.concat(base, ignore_index=True)","b76c1643":"if (columns_size != None or rows_size != None):\n    inputs = list( base.columns[ base.columns.str.contains('input')][:columns_size])\n    inputs.sort()\n    output = list(base.columns[ base.columns.str.contains('output')] )\n    cols = list( base[ inputs + output  ].columns )\n    cols.append('id')\n    cols.append('date')\n    base = base[cols].copy()[:rows_size]\n\nbase.head()","172d1f15":"print(base.shape)\nbase.head()","368e7192":"base = reduce_mem_usage(base)\n#test = reduce_mem_usage(test)","59ea7886":"#Check if date was parsed\nbase[['date']].info()","5939980a":"#check first 4 feature\nfor i in range(4):\n    col = 'input_'+str(i)\n    print(col,' : ', base[col].shape[0], base[col].nunique() )\n","e38d3650":"input_columns = base.columns[base.columns.str.contains('input') ]\noutput_columns = base.columns[base.columns.str.contains('output') ]\n\nprint(F'Inputs: {input_columns.shape} Outputs: {output_columns.shape}')\ninput_columns, output_columns","e27b04ff":"len(base.columns[ base.columns.str.contains('input_4_') ])\nfor i in range(2000):\n    \n    if F'input_4_{i}' in input_columns:\n        print(F'input_1_{i}')","4376d944":"plt.figure(figsize=(36, 22))\nplt.subplots_adjust(top=1.2, hspace = 0.8)\nsns.set_palette(\"husl\")\npalette = itertools.cycle(sns.color_palette())\nfor i in range(1,15):\n    plt.subplot( 5, 3 ,i)\n    col = F'input_4_{i}'\n    plot = base.groupby( base['date'].dt.date )[col].mean().reset_index()\n    sns.lineplot( plot.date, plot[col] , color=next(palette))\n    plt.xticks(rotation=45,ha='right')\n    plt.title(F\" Mean of {col} distributed per month \")\n\nplt.show()","1b5678ec":"plt.figure(figsize=(36, 22))\nplt.subplots_adjust(top=1.2, hspace = 0.8)\nsns.set_palette(\"husl\")\npalette = itertools.cycle(sns.color_palette())\nfor i in range(4,20):\n    plt.subplot( 5, 4 ,i - 3)\n    col = F'input_{i}_1'\n    plot = base.groupby( base['date'].dt.date )[col].mean().reset_index()\n    sns.lineplot( plot.date, plot[col] , color=next(palette))\n    plt.xticks(rotation=45,ha='right')\n    plt.title(F\" Mean of {col} distributed per month \")\n\nplt.show()","eee7262e":"def create_features(df):\n    df['input_month'] = df.date.dt.month\n    df['input_year'] = df.date.dt.year\n    df['input_day'] = df.date.dt.day\n    df['input_dt_sin_quarter']     = np.sin(2*np.pi*df.date.dt.quarter\/4)\n    df['input_dt_sin_day_of_week'] = np.sin(2*np.pi*df.date.dt.dayofweek\/6)\n    df['input_dt_sin_day_of_year'] = np.sin(2*np.pi*df.date.dt.dayofyear\/365)\n    df['input_dt_sin_day']         = np.sin(2*np.pi*df.date.dt.day\/30)\n    df['input_dt_sin_month']       = np.sin(2*np.pi*df.date.dt.month\/12)\n    \n    return df\n\n\ncreate_features(base)\n\ninput_columns = base.columns[base.columns.str.contains('input') ]\noutput_columns = base.columns[base.columns.str.contains('output') ]\n","297fd954":"X = base[input_columns[:columns_size] ].fillna(0).values\nY = base[output_columns].fillna(0).values\n\ndel base\ngc.collect()","0dc45e17":"from sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.20, random_state=42)\nx_train.shape, y_train.shape","9471a6c2":"%%time\nfrom sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(n_estimators = 1000, max_depth=10, random_state=0)\n\n# fit model\nmodel.fit(x_train,y_train)\n#LB = 0.79503","ec80c268":"y_pred = model.predict(x_val)","083146db":"print( rmse(y_pred, y_val) )\nprint( wrmse(y_pred, y_val, weigths) )","de46bf9a":"input_columns[:-1]","5d4fd7cb":"#Loading test file\ntest = [pd.read_csv(file,parse_dates=['date']) for file in get_files(['2019'], 12,'public' )]\ntest = pd.concat(test, ignore_index=True).fillna(0)\ntest.head()","65508434":"test = create_features(test)\ninput_columns = test.columns[test.columns.str.contains('input') ]","5a840e89":"pred = model.predict(test[input_columns].values)\npred_sub = pd.DataFrame(pred)\npred_sub.columns = output_columns\npred_sub['id']   = test['id']\npred_sub.head()","16cce7a8":"submission = []\nfor i, row in pred_sub.iterrows():\n    for column, value in zip(output_columns, row.values):\n        id = \"{}_{}\".format(int(row.id), column)\n        submission.append([id, value])\n\nsubmission = pd.DataFrame(submission)\nsubmission.columns = ['id', 'value']\nsubmission","8517dc70":"submission.to_csv('submission.csv', index=False)","fc27331c":"### Check Categorical Variables\n\nDescription: The input variables are 557 features<br>\nThey are labeled from 0 up to 556, with the first four being categorical variables, and the rest being numerical.<br>\nChecking Categorical Variables","fdc65f32":"### Different Features\n\nNow let's check for different features (input_4_1 to input_20_1).","058948e6":"<a id=\"id5\"><\/a> <br> \n# **5. Model** ","1d9f3494":"# Let's dive into the date\n\n### First, let's check if input is correlated with month. ","d49e8905":"<img src=\"https:\/\/wordpress-network.prod.aws.skyscnr.com\/wp-content\/uploads\/2019\/02\/RentalCarLG.jpg?w=1000&h=312&crop=1\" width=1900px height=300px \/>","79c728ea":"<a id=\"id3\"><\/a> <br> \n# **3. Load the Dataset** \n\n\n","1a8ebade":"### All Functions Used in this Kernel","4dd650c4":"<a id=\"id1\"><\/a> <br> \n# **1. Problem Definition:** \n\nThe objective of this competition is to predict the unavailability of cars in a car rental agency. <br>\nWhen a car is unavailable, its status can be either \u201cin maintenance\u201d or \u201cbeing washed\u201d. The goal is to predict the number of cars entering and leaving each of the two status, for each of the four shifts in a day","f625f0df":"### Session Parameters\n\nThis parameters controls the size of train\/test. Only for test speed up\n* `columns_size`: number or None(use all columns)\n* `rows_size` : numer or None(user all rows)","f9828c7b":"For the numerical variables, all the previous fourteen (14) values are provided (one for each day in two weeks before the tuple date). The input column names follow the syntax below:\n\n","320845c5":"<a id=\"id7\"><\/a> <br> \n# **7. Submittion** ","a5b47d0c":"## Random Forest","4d4c3c94":"As you can see, next to vacation months (January, June, July, August, December), features like `input_4` raises. <br>\n\nMaybe later we can take an advantage of this information. ","514e9bb6":"# KDD First EDA\n\n<h3> Kernel description: <\/h3>\nThis my first try\n","56cc9eb5":"<a id=\"id6\"><\/a> <br> \n# **6. Visualization and Analysis of Results** \n\n","0655dd2e":"<a id=\"id4\"><\/a> <br> \n# **4. Data Pre-processing** ","2e927a9d":"# Table of Contents:\n\n**1. [Problem Definition](#id1)** <br>\n**2. [Get the Data (Collect \/ Obtain)](#id2)** <br>\n**3. [Load the Dataset](#id3)** <br>\n**4. [Data Pre-processing](#id4)** <br>\n**5. [Model](#id5)** <br>\n**6. [Visualization and Analysis of Results](#id6)** <br>\n**7. [Submittion](#id7)** <br>\n**8. [References](#ref)** <br>","68e3b6e2":"<a id=\"ref\"><\/a> <br> \n# **8. References** \n\n","cf928d9b":"> **Nota**: This Kernel is used as a WorkFlow template. <br>\nMade by[@AdrianoAvelar](https:\/\/www.kaggle.com\/adrianoavelar) <br>\nFork and Code.","cd0baeaf":"<a id=\"id2\"><\/a> <br> \n# **2. About the Data (Collect \/ Obtain):** \n\n The training set, built using real data from 2017 and 2018, contains both input and output columns.<br>\n In the test set, containing data from 2019, only the input columns are provided."}}