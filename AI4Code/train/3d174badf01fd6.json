{"cell_type":{"755ec36d":"code","fee29938":"code","0a7694d9":"code","c1ae042b":"code","72a0b4f1":"code","3be3796f":"code","f84489c8":"code","7e1c1c22":"code","a4aaa84f":"code","ae3e4b92":"code","cd209480":"code","2d86d455":"code","8800dddd":"code","6b106165":"code","377678da":"code","df2e68a7":"code","7fdfa331":"code","bd62de26":"code","4d440578":"code","1cf9c1ca":"code","758d574c":"code","620de3e6":"code","3071d63d":"code","9c436177":"code","78ec9094":"code","cd206775":"code","fc1b852e":"code","4a8999d8":"code","3bb7162e":"code","478a347b":"code","67ee8699":"code","353c10a3":"code","89695cc0":"code","a4271aee":"code","d08bfbb5":"code","da2fe664":"code","c5820ee7":"code","5e65be7a":"code","b221923d":"code","9c0ece79":"code","cf74d153":"markdown","7f6c3dc9":"markdown","94ed26eb":"markdown","599eeee5":"markdown","0c9c6c47":"markdown","87257311":"markdown","26ccc8e9":"markdown","c2be815d":"markdown","3483dbb4":"markdown","aa965fc8":"markdown","e916da63":"markdown","1ae0056e":"markdown","02f1c949":"markdown","35d8db1f":"markdown","3c538b21":"markdown","32f8f6d4":"markdown","22798636":"markdown","08e446a8":"markdown","ff9c9961":"markdown","8cdf92c9":"markdown","8f3e2b2a":"markdown","07576812":"markdown","96a56ea1":"markdown","8f55bf41":"markdown","83f4c1bd":"markdown"},"source":{"755ec36d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom scipy import stats\nimport statsmodels.api as sm\n\nimport matplotlib.pyplot as plt # plotting\n%matplotlib inline\nimport seaborn as sns # plotting\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","fee29938":"base_url = '\/kaggle\/input\/web-traffic-time-series-forecasting\/'\n\ntrain_1 = pd.read_csv(base_url+'train_1.csv')\ntrain_2 = pd.read_csv(base_url+'train_2.csv')","0a7694d9":"train_1.shape","c1ae042b":"train_1.head()","72a0b4f1":"trainT = train_1.drop('Page', axis=1).T\ntrainT.columns = train_1.Page.values\ntrainT.head()","3be3796f":"metallica = pd.DataFrame(trainT['Metallica_es.wikipedia.org_all-access_all-agents'])\nmetallica.head()","f84489c8":"print (metallica.shape)","7e1c1c22":"print (metallica.isnull().sum())","a4aaa84f":"plt.figure(figsize=(24, 12))\nmetallica.plot();","ae3e4b92":"def plotMovingAverage(series, window, plot_intervals=False, scale=1.96, plot_anomalies=False):\n\n    \"\"\"\n        series - dataframe with timeseries\n        window - rolling window size \n        plot_intervals - show confidence intervals\n        plot_anomalies - show anomalies \n\n    \"\"\"\n    # Calculate and plot rolling mean\n    rolling_mean = series.rolling(window=window).mean()\n    \n    plt.figure(figsize=(15,5))\n    plt.title(\"Moving average\\n window size = {}\".format(window))\n    plt.plot(rolling_mean, \"g\", label=\"Rolling mean trend\")\n\n    # Plot confidence intervals for smoothed values\n    if plot_intervals:\n        mae = mean_absolute_error(series[window:], rolling_mean[window:])\n        deviation = np.std(series[window:] - rolling_mean[window:])\n        lower_bond = rolling_mean - (mae + scale * deviation)\n        upper_bond = rolling_mean + (mae + scale * deviation)\n        plt.plot(upper_bond, \"r--\", label=\"Upper Bond \/ Lower Bond\")\n        plt.plot(lower_bond, \"r--\")\n        \n        # Having the intervals, find abnormal values\n        if plot_anomalies:\n            anomalies = pd.DataFrame(index=series.index, columns=series.columns)\n            anomalies[series<lower_bond] = series[series<lower_bond]\n            anomalies[series>upper_bond] = series[series>upper_bond]\n            plt.plot(anomalies, \"ro\", markersize=10)\n    \n    # Plot original series values\n    plt.plot(series[window:], label=\"Actual values\")\n    plt.legend(loc=\"upper left\")\n    plt.grid(True)","cd209480":"plotMovingAverage(metallica, 14)","2d86d455":"from fbprophet import Prophet","8800dddd":"metallica.columns","6b106165":"metallica.rename(columns={'Metallica_es.wikipedia.org_all-access_all-agents': 'y'}, inplace=True)\nmetallica.head()","377678da":"ds = pd.Series(metallica.index)\ny = pd.Series(metallica.iloc[:,0].values)\nframe = { 'ds': ds, 'y': y }\ndf = pd.DataFrame(frame)\ndf.head()","df2e68a7":"df.plot();","7fdfa331":"# Instantiate and fit the Prophet model\nm = Prophet()\nm.fit(df);","bd62de26":"# Make future predictions to the next 60 days\nforecast = m.make_future_dataframe(periods=60)","4d440578":"forecast.shape","1cf9c1ca":"forecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(3)","758d574c":"forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head(3)","620de3e6":"fig1 = m.plot(forecast)","3071d63d":"fig2 = m.plot_components(forecast)","9c436177":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(15, 7))\nplt.plot(df.y)\nplt.plot(forecast.yhat, \"g\");","78ec9094":"df['cap'] = 500\ndf['floor'] = 0.0\nfuture['cap'] = 500\nfuture['floor'] = 0.0\nm = Prophet(growth='logistic')\nforecast = m.fit(df).predict(future)\nfig1 = m.plot(forecast)\nfig2 = m.plot_components(forecast)","cd206775":"m = Prophet(daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=True)\nforecast = m.fit(df).predict(future)\nfig1 = m.plot(forecast)\nfig2 = m.plot_components(forecast)","fc1b852e":"from fbprophet.plot import add_changepoints_to_plot\nfig = m.plot(forecast)\na = add_changepoints_to_plot(fig.gca(), m, forecast)","4a8999d8":"m = Prophet(changepoint_prior_scale=0.9)\nforecast = m.fit(df).predict(future)\nfig = m.plot(forecast)","3bb7162e":"from datetime import date\nimport holidays\n\n# Select country\nes_holidays = holidays.Spain(years = [2015,2016,2017])\nes_holidays = pd.DataFrame.from_dict(es_holidays, orient='index')\nes_holidays = pd.DataFrame({'holiday': 'Spain', 'ds': es_holidays.index})","478a347b":"m = Prophet(holidays=es_holidays)\nm.add_country_holidays(country_name='ES')\nforecast = m.fit(df).predict(future)\nfig1 = m.plot(forecast)\nfig2 = m.plot_components(forecast)","67ee8699":"m = Prophet(interval_width=0.95)\nforecast = m.fit(df).predict(future)\nfig1 = m.plot(forecast)\nfig2 = m.plot_components(forecast)","353c10a3":"# m = Prophet(mcmc_samples=0)\nm = Prophet(mcmc_samples=300)\nforecast = m.fit(df).predict(future)\nfig1 = m.plot(forecast)\nfig2 = m.plot_components(forecast)","89695cc0":"m = Prophet(growth='linear',\n            daily_seasonality=True, weekly_seasonality=True, yearly_seasonality=True,\n            seasonality_mode='multiplicative',\n            seasonality_prior_scale=25,\n            changepoint_prior_scale=0.05,\n            holidays=es_holidays,\n            holidays_prior_scale=20,\n            interval_width=0.95,\n            mcmc_samples=0)\n\nm.add_country_holidays(country_name='ES')\n\nforecast = m.fit(df).predict(future)\n\nfig1 = m.plot(forecast)\na = add_changepoints_to_plot(fig1.gca(), m, forecast)\n\nfig2 = m.plot_components(forecast)","a4271aee":"from fbprophet.plot import plot_plotly\nimport plotly.offline as py\npy.init_notebook_mode()\n\nfig = plot_plotly(m, forecast)  # This returns a plotly Figure\npy.iplot(fig)","d08bfbb5":"plt.figure(figsize=(15, 7))\nplt.plot(df.y)\nplt.plot(forecast.yhat, \"g\");","da2fe664":"def smape(y_true, y_pred):\n    denominator = (np.abs(y_true) + np.abs(y_pred))\n    diff = np.abs(y_true - y_pred) \/ denominator\n    diff[denominator == 0] = 0.0\n    return 200 * np.mean(diff)\n\n# Source: http:\/\/shortnotes.herokuapp.com\/how-to-implement-smape-function-in-python-149","c5820ee7":"smape_metallica = smape(df.y, forecast.yhat)\nsmape_metallica","5e65be7a":"from fbprophet.diagnostics import cross_validation","b221923d":"cv_results = cross_validation(m, initial='360 days', period='30 days', horizon='60 days')","9c0ece79":"smape_cv = smape(cv_results.y, cv_results.yhat)\nsmape_cv","cf74d153":"### Cross Validation","7f6c3dc9":"### Symmetric Mean Absolute Percentage Error\n$$ SMAPE = \\frac{100\\%}{n} \\sum_{t=1}^{n} \\frac{\\left|F_t - A_t\\right|}{(\\left|A_t\\right|+\\left|F_t\\right|)\/2} $$","94ed26eb":"#### This parameter determines if the model uses Maximum a posteriori (MAP) estimation or a full \n##### Bayesian inference with the specified number of Markov Chain Monte Carlo (MCMC) samples to train and predict.\n##### So if you make MCMC zero then it will do MAP estimation, otherwise you need to specify the number of samples to use with MCMC.\n##### Source: https:\/\/towardsdatascience.com\/implementing-facebook-prophet-efficiently-c241305405a3","599eeee5":"## Conclusions","0c9c6c47":"### Changepoints","87257311":"> ## Modeling and forecast","26ccc8e9":"### page visit are clearly on the rise around November\n### the popular weekdays are Tueday and Friday\n### there is a clear growing trend, that should continue according to the forecast\n### the forecast error is 12%\n","c2be815d":"## Prediction","3483dbb4":"### Holidays","aa965fc8":"## Data description","e916da63":"### Basic plotting","1ae0056e":"##### horizon: forecast horizon\n##### initial: size of the initial training period\n##### period: spacing between cutoff dates\n\n##### Here we do cross-validation to assess prediction performance on a horizon of 60 days, \n##### starting with 130 days of training data in the first cutoff and then making predictions every 60 days\n##### On this 610 days time series, this corresponds to 8 total forecasts","02f1c949":"**Seasonality & Holiday Parameters**\n\nParameter and Description\n\n- yearly_seasonality -> Fit yearly seasonality\n- weekly_seasonality -> Fit weekly seasonality\n- daily_seasonality -> Fit daily seasonality\n- holidays -> Feed dataframe containing holiday name and date\n- seasonality_prior_scale -> Parameter for changing strength of seasonality model\n- holidays_prior_scale -> Parameter for changing strength of holiday model\n\nSource: https:\/\/www.analyticsvidhya.com\/blog\/2018\/05\/generate-accurate-forecasts-facebook-prophet-python-r\/","35d8db1f":"### Seasonality","3c538b21":"### Dynamic Plotting","32f8f6d4":"## Creating Matallica ES and basic plots","22798636":"## Evaluating the Model","08e446a8":"### Saturating forecasts","ff9c9961":"### Uncertainty in seasonality","8cdf92c9":"#### Uncertainty in the trend","8f3e2b2a":"## Prediction with parametrization","07576812":"## Data","96a56ea1":"# Metallica Spain Tour [Prophet]\n### Based on Wikipedia Web Page Traffic","8f55bf41":"### Uncertainty interval","83f4c1bd":"#### Train Data Content - 145.063 rows representing different Wikipedia URL pages, 551 columns\n#### first column is the URL page and then each column represents a value of the number of visits to the page in that day\n#### dates from 2015-07-01 to 2016-12-31 (1.5 year, total of 550 days)"}}