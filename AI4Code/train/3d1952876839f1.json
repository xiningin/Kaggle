{"cell_type":{"68312f83":"code","ddac6eb2":"code","a44d130d":"code","f1622fe4":"code","76c9bc1e":"code","a5b4577f":"code","d5453451":"code","c8e818f1":"code","112937a0":"code","4acbc8d0":"code","2e759f73":"code","9983fab4":"code","635a6535":"code","bc775553":"code","accf9cc0":"code","e984020a":"code","ec8f3b8d":"code","d6b47f15":"code","da52f11f":"markdown"},"source":{"68312f83":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ddac6eb2":"!ls","a44d130d":"import sklearn.datasets\nimport sklearn.model_selection\nimport keras.preprocessing.image\nimport keras.utils\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom skimage import color\nfrom sklearn.metrics import accuracy_score\nimport keras.callbacks\nimport os\nimport numpy as np\nimport cv2\n\n#def load_data(infDir):\n#    infData=sklearn.datasets.load_files(infDir,load_content=False)\n#    y_inf = np.array(infData['target'])\n#    y_inf_names = np.array(infData['target_names'])\n#    nclasses = len(np.unique(y_inf))\n#    target_size=50\n#    x_inf=[]\n#    for filename in infData['filenames']:\n#        x_inf.append(\n#                keras.preprocessing.image.img_to_array(\n#                        keras.preprocessing.image.load_img(filename,target_size=(target_size, target_size))\n#                )\n#        )\n#    return([x_inf,y_inf])\n    \n    \n\ntrain_dir = '..\/input\/fruits-360_dataset\/fruits-360\/Training'\ntrainData=sklearn.datasets.load_files(train_dir,load_content=False)\n\ntest_dir = '..\/input\/fruits-360_dataset\/fruits-360\/Test'\ntestData=sklearn.datasets.load_files(test_dir,load_content=False)\n\n\ny_train = np.array(trainData['target'])\ny_train_names = np.array(trainData['target_names'])\n\ny_test = np.array(testData['target'])\ny_test_names = np.array(testData['target_names'])\n\nnclasses = len(np.unique(y_train))\ntarget_size=50\n\nx_train=[]\nfor filename in trainData['filenames']:\n    x_train.append(\n            keras.preprocessing.image.img_to_array(\n                    keras.preprocessing.image.load_img(filename,target_size=(target_size, target_size))\n                    )\n            )\n    \n    \nx_test=[]\nfor filename in testData['filenames']:\n    x_test.append(\n            keras.preprocessing.image.img_to_array(\n                    keras.preprocessing.image.load_img(filename,target_size=(target_size, target_size))\n                    )\n            )","f1622fe4":"x_train=np.array(x_train)\nx_train=x_train\/255\ny_train=keras.utils.np_utils.to_categorical(y_train,nclasses)\n\n\nx_test=np.array(x_test)\nx_test=x_test\/255\ny_test=keras.utils.np_utils.to_categorical(y_test,nclasses)","76c9bc1e":"x_train, x_val, y_train, y_val = sklearn.model_selection.train_test_split(\n        x_train, y_train, test_size=0.2\n)\nprint(y_train.shape)\nprint(y_val.shape)","a5b4577f":"N_SAMPLES = 5\n\nimages = keras.layers.Input(x_train.shape[1:])\n\n#inizio blocco 1\nx = keras.layers.Conv2D(filters=16, kernel_size=[1, 1], padding='same')(images)\nblock = keras.layers.Conv2D(filters=16, kernel_size=[3, 3], padding=\"same\")(x)\nblock = keras.layers.BatchNormalization()(block)\nblock = keras.layers.Activation(\"relu\")(block)\nblock = keras.layers.Conv2D(filters=16, kernel_size=[3, 3], padding=\"same\")(block)\n\n# #inio Squeeze and Excitation 1\n# sq = keras.layers.GlobalAveragePooling2D()(block)\n# sq = keras.layers.Reshape((1,1,16))(sq)\n# sq = keras.layers.Dense(units=16,activation=\"sigmoid\")(sq)\n# block = keras.layers.multiply([block,sq])\n# #fine Squeeze and Excitation 1\n\nnet = keras.layers.add([x,block])\nnet = keras.layers.BatchNormalization()(net)\nnet = keras.layers.Activation(\"relu\")(net)\nnet = keras.layers.MaxPooling2D(pool_size=(2, 2),name=\"block_1\")(net)\n\n\n\n#fine blocco 1\n#inizio blocco 2\nx = keras.layers.Conv2D(filters=32, kernel_size=[1, 1], padding='same')(net)\nblock = keras.layers.Conv2D(filters=32, kernel_size=[3, 3], padding=\"same\")(x)\nblock = keras.layers.BatchNormalization()(block)\nblock = keras.layers.Activation(\"relu\")(block)\nblock = keras.layers.Conv2D(filters=32, kernel_size=[3, 3], padding=\"same\")(block)\n\n# #inio Squeeze and Excitation 2\n# sq = keras.layers.GlobalAveragePooling2D()(block)\n# sq = keras.layers.Reshape((1,1,32))(sq)\n# sq = keras.layers.Dense(units=32,activation=\"sigmoid\")(sq)\n# block = keras.layers.multiply([block,sq])\n# #fine Squeeze and Excitation 2\n\n\nnet = keras.layers.add([x,block])\nnet = keras.layers.BatchNormalization()(net)\nnet = keras.layers.Activation(\"relu\")(net)\nnet = keras.layers.MaxPooling2D(pool_size=(2, 2),name=\"block_2\")(net)\n#fine blocco 2\n#inizio blocco 3\nx = keras.layers.Conv2D(filters=64, kernel_size=[1, 1], padding='same')(net)\nblock = keras.layers.Conv2D(filters=64, kernel_size=[3, 3], padding=\"same\")(x)\nblock = keras.layers.BatchNormalization()(block)\nblock = keras.layers.Activation(\"relu\")(block)\nblock = keras.layers.Conv2D(filters=64, kernel_size=[3, 3], padding=\"same\")(block)\n\n# #inio Squeeze and Excitation 3\n# sq = keras.layers.GlobalAveragePooling2D()(block)\n# sq = keras.layers.Reshape((1,1,64))(sq)\n# sq = keras.layers.Dense(units=64,activation=\"sigmoid\")(sq)\n# block = keras.layers.multiply([block,sq])\n# #fine Squeeze and Excitation 3\n\nnet = keras.layers.add([x,block])\nnet = keras.layers.BatchNormalization()(net)\nnet = keras.layers.Activation(\"relu\")(net)\nnet = keras.layers.MaxPooling2D(pool_size=(2, 2),name=\"block_3\")(net)\n\n#net = keras.layers.GlobalAveragePooling2D()(net)\n\n\nnet = keras.layers.Flatten()(net)\n\nshared1 = keras.layers.Dense(units=10)\nshared2 = keras.layers.Dense(units=nclasses,activation=\"softmax\")\n\n\nd_net = []\nfor _ in range(N_SAMPLES):\n    n = keras.layers.Dropout(0.5)(net)\n    n = shared1(n)\n    n = shared2(n)\n    d_net.append(n)\nnet = keras.layers.Average()(d_net)\n\n\nmodel = keras.models.Model(inputs=images,outputs=net)\n\n\n\ndef custom_loss_funct(y_true, y_pred):\n    loss = keras.losses.categorical_crossentropy(y_true, d_net[0])\n    for i in range(1,len(d_net)):\n        loss += keras.losses.categorical_crossentropy(y_true, d_net[i])\n    loss = loss\/len(d_net)\n    return(loss)\n\n\nmodel.summary()","d5453451":"from IPython.display import SVG\nimport IPython\nfrom keras.utils import model_to_dot\n\nprint(model.summary())\n\nkeras.utils.plot_model(model, to_file='test_keras_plot_model.png', show_shapes=True)\nIPython.display.Image('test_keras_plot_model.png')\n","c8e818f1":"model.compile(loss=custom_loss_funct,\n              optimizer='adadelta',\n              metrics=['accuracy'])\ncheckpointer = keras.callbacks.ModelCheckpoint(filepath = 'cnn_from_scratch_fruits.hdf5', verbose = 1, save_best_only = True)\nearlystopper = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto', baseline=None, restore_best_weights=False)","112937a0":"history=model.fit(x_train, y_train, batch_size=64, epochs=15,validation_data=(x_val, y_val), callbacks = [checkpointer,earlystopper], shuffle=True)","4acbc8d0":"model.load_weights('cnn_from_scratch_fruits.hdf5')","2e759f73":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","9983fab4":"# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\nplt.show()","635a6535":"test_image = keras.preprocessing.image.img_to_array(keras.preprocessing.image.load_img(train_dir+\"\/Apple Braeburn\/0_100.jpg\",target_size=(target_size, target_size)))\ntest_image = test_image\/255\n\nplt.imshow(test_image)","bc775553":"fig = plt.figure(figsize=(8, 8))\nfor img in range(3):\n    ax = fig.add_subplot(1, 3, img+1)\n    ax = plt.imshow(test_image[:, :, img],cmap='gray')\n    plt.xticks([])\n    plt.yticks([])\n    fig.subplots_adjust(wspace=0.05, hspace=0.05)\n\n\ntest_image = np.expand_dims(test_image, axis=0)","accf9cc0":"hidden_rappresenter = keras.models.Model(inputs=model.input, outputs=model.get_layer('block_1').output)\nresult=hidden_rappresenter.predict(test_image)\nresult.shape\n\nfig = plt.figure(figsize=(16, 16))\nfor img in range(16):\n    ax = fig.add_subplot(4, 4, img+1)\n    ax = plt.imshow(result[0, :, :, img], cmap='gray')\n    plt.xticks([])\n    plt.yticks([])\n    fig.subplots_adjust(wspace=0.05, hspace=0.05)","e984020a":"hidden_rappresenter = keras.models.Model(inputs=model.input, outputs=model.get_layer('block_2').output)\nresult=hidden_rappresenter.predict(test_image)\nresult.shape\n\nfig = plt.figure(figsize=(16, 16))\nfor img in range(32):\n    ax = fig.add_subplot(6, 6, img+1)\n    ax = plt.imshow(result[0, :, :, img], cmap='gray')\n    plt.xticks([])\n    plt.yticks([])\n    fig.subplots_adjust(wspace=0.05, hspace=0.05)","ec8f3b8d":"hidden_rappresenter = keras.models.Model(inputs=model.input, outputs=model.get_layer('block_3').output)\nresult=hidden_rappresenter.predict(test_image)\nresult.shape\n\nfig = plt.figure(figsize=(16, 16))\nfor img in range(64):\n    ax = fig.add_subplot(8, 8, img+1)\n    ax = plt.imshow(result[0, :, :, img], cmap='gray')\n    plt.xticks([])\n    plt.yticks([])\n    fig.subplots_adjust(wspace=0.05, hspace=0.05)","d6b47f15":"y_test_pred = model.predict(x_test)\naccuracy_score(np.argmax(y_test_pred,axis=1), np.argmax(y_test,axis=1))","da52f11f":"**Visualization** Internal rappresentation"}}