{"cell_type":{"5315fcd3":"code","0ddc7baa":"code","fcff1133":"code","d3f9d582":"code","14b046f2":"code","56bb8abd":"code","2256644c":"code","e1f37127":"code","10bca372":"code","46314236":"code","9287845a":"code","1dd444ae":"code","3aeb027e":"code","94e3a5a1":"code","b14086c8":"code","8274d68f":"code","91ccbd62":"code","0c67d9ce":"code","bd03c7e3":"code","29d51496":"code","f1a2fbb8":"code","efcfac80":"code","b2eabb64":"code","c2b9896d":"code","da51abf4":"markdown","a92af203":"markdown","771ab13a":"markdown","ccf17703":"markdown","c7c000e8":"markdown","60e2ec98":"markdown","aa8bbd7a":"markdown","71b1daad":"markdown"},"source":{"5315fcd3":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport datetime as dt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport tensorflow as tf\nfrom sklearn import metrics","0ddc7baa":"os.chdir('\/kaggle\/input\/wallmart-sales\/')\ntotal_value = pd.read_csv('total_value.csv')\ntotal_value.head()","fcff1133":"os.chdir('\/kaggle\/input\/wallmart\/')\ncal = pd.read_csv('calendar.csv')","d3f9d582":"cal","14b046f2":"# One-hot encoding months\nmonth = pd.get_dummies(cal['month'],prefix='month',drop_first=True)\n\n# Dropping unecessary cols\ncal.drop(['wm_yr_wk', 'weekday','d', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_TX', 'snap_WI'],1,inplace=True)\n\n# Handling events\ncal['event_name_1'] = cal['event_name_1'].fillna(0)\ncal['event_name_1'] = np.where(cal['event_name_1'] != 0,1,0)\n\n# One-hot encoding day of months\ncal['date'] = pd.to_datetime(cal['date'])\ncal['dayofmonth'] = cal['date'].dt.day     \ndom = pd.DataFrame(np.where(cal['dayofmonth']>=15,1,0),columns=['day_ge_15'])\n\n# One-hot encoding years\nyear = pd.get_dummies(cal['year'],prefix='year_',drop_first=True)\n\n# One-hot encoding weekdays\nwday = pd.get_dummies(cal['wday'],prefix='wday_',drop_first=True)\n\n# Combing and removing features\ncal.drop(['month','year','dayofmonth','wday'],1,inplace=True)\ncal = pd.concat([cal,month,year,dom,wday],axis=1)","56bb8abd":"# Function for filtering california store 3 items\ndef california_store_3(item):\n    state = item.split('_')[3] \n    store_no = int(item.split('_')[4])\n    if (state == 'CA' and store_no == 3): \n        return True\n    else: \n        return False","2256644c":"item_list = list(total_value.columns[:-1])\ncalifornia_store_3_item = filter(california_store_3, item_list)\ncalifornia_store_3_item_list = [i for i in california_store_3_item]","e1f37127":"california_store_3_df = total_value.loc[:,california_store_3_item_list]\ncalifornia_store_3_df","10bca372":"# Concatinating categorical variables\ncalifornia_store_3_df = pd.concat([cal.iloc[:1941,:],california_store_3_df],1)\ncalifornia_store_3_df.head()","46314236":"california_store_3_df['date'] = pd.to_datetime(california_store_3_df['date'])","9287845a":"# 3049 items\ncalifornia_store_3_last_1_year_df = california_store_3_df[california_store_3_df['date'] >='2015-02-22']\ncalifornia_store_3_last_1_year_df.head()","1dd444ae":"# 3021 items\ncalifornia_store_3_last_1_year_df_without_Nas = california_store_3_last_1_year_df.dropna(axis=1)\ncalifornia_store_3_last_1_year_df_without_Nas.head()","3aeb027e":"# Fuction for filtering household\ndef california_store_3_household(item):\n    category = item.split('_')[0]\n    if (category == 'HOUSEHOLD'): \n        return True\n    else: \n        return False","94e3a5a1":"categorical_variables = list(california_store_3_last_1_year_df_without_Nas.columns[:26])\ncalifornia_store_3_last_1_year_without_Nas_item_list = list(california_store_3_last_1_year_df_without_Nas.columns[26:])\ncalifornia_store_3_last_1_year_without_Nas_item_household = filter(california_store_3_household, california_store_3_last_1_year_without_Nas_item_list)\ncalifornia_store_3_last_1_year_without_Nas_item_household_list = categorical_variables + [i for i in california_store_3_last_1_year_without_Nas_item_household]","b14086c8":"california_store_3_last_1_year_without_Nas_item_household_df = california_store_3_last_1_year_df_without_Nas.loc[:,california_store_3_last_1_year_without_Nas_item_household_list]\ncalifornia_store_3_last_1_year_without_Nas_item_household_df","8274d68f":"master_df = california_store_3_last_1_year_without_Nas_item_household_df.copy()","91ccbd62":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=master_df.date, \n                         y=master_df.iloc[26:].sum(axis=1),\n                         mode='lines',\n                         name='pred'))\n   \nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=700,\n    margin=dict(\n        l=50,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    ),\n    paper_bgcolor=\"LightSteelBlue\",\n    title=\"Walmart California store 3 food sales\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"Sales\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#042a30\"\n    )\n)\n\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","0c67d9ce":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=master_df.date, \n                         y=master_df.iloc[:,26:26+15].sum(axis=1),\n                         mode='lines',\n                         name='pred'))\n   \nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=700,\n    margin=dict(\n        l=50,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    ),\n    paper_bgcolor=\"LightSteelBlue\",\n    title=\"Walmart California store 3 household sales for 15 items\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"Sales\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#042a30\"\n    )\n)\n\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","bd03c7e3":"master_df_15_items = master_df.iloc[:,:26+15]","29d51496":"# loop for lstm\n\ncategorical_varibales = master_df_15_items.iloc[:,:26] \ntarget_variables = master_df_15_items.iloc[:,26:].columns\n\npredictions = pd.DataFrame(np.arange(1,29),columns=['index'])\nactual = pd.DataFrame(np.arange(1,29),columns=['index'])\n\nfor target_variable in target_variables:\n    \n    # Making dataset\n    dataset = pd.concat([categorical_varibales,master_df[target_variable]],1)\n\n    # Splitting train and test data\n    split_date = '2016-04-24'\n    Train = dataset.loc[dataset['date'] <= split_date].copy()\n    Test = dataset.loc[dataset['date'] > split_date].copy()\n    \n    # Dropping date\n    Train.drop(['date'],axis=1,inplace=True)\n    Test.drop(['date'],axis=1,inplace=True)\n    \n    x_train = Train.drop([target_variable],1)\n    y_train = Train[target_variable]\n    x_test = Test.drop([target_variable],1)\n    y_test = Test[target_variable]\n\n    #Create model layers\n    model = tf.keras.Sequential([\n        tf.keras.layers.LSTM(64,input_shape=(len(x_test.keys()),1)),\n        tf.keras.layers.Dense(1)\n    ])\n\n    #Choose optimizer\n    optimizer = tf.keras.optimizers.Adam()\n\n    #Compile model with mean squared error as loss function\n    model.compile(loss='mse',\n                  optimizer=optimizer,\n                  metrics=['mae', 'mse'])\n\n    # Number of epochs\n    EPOCHS = 10\n    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n    history=model.fit(np.reshape(x_train.values, (x_train.shape[0], x_train.shape[1], 1))\n    , y_train,epochs=EPOCHS, validation_split = 0.2,callbacks=[early_stop], verbose=1)\n    \n    # Predictions\n    test_predictions = model.predict(np.reshape(x_test.values, (x_test.shape[0], x_test.shape[1], 1))).flatten()\n    print(f'{target_variable}:{metrics.mean_squared_error(test_predictions,y_test)}')\n\n    test_predictions = pd.DataFrame(test_predictions, columns=[target_variable])\n    predictions = pd.concat([predictions, test_predictions], 1)\n\n    y_test = pd.DataFrame(y_test.values, columns=[target_variable])\n    actual = pd.concat([actual, y_test], 1, ignore_index = True)","f1a2fbb8":"fig = go.Figure()\n\n\nfig.add_trace(go.Scatter(x=predictions.index, y=predictions.sum(axis=1),mode='lines',name='pred'))\n\nfig.add_trace(go.Scatter(x=predictions.index, y=actual.sum(axis=1),mode='lines',name='actual'))\n    \n    \nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=700,\n    margin=dict(\n        l=50,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    ),\n    paper_bgcolor=\"LightSteelBlue\",\n    title=\"Walmart California store 3 household sales for 15 items\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"Sales\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#042a30\"\n    )\n)\n\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","efcfac80":"# Packages for arima\n!python3.7 -m pip install --upgrade pip\n!pip install pmdarima\nfrom pmdarima.arima import auto_arima","b2eabb64":"# loop for arima\n\ntarget_variables = master_df_15_items.iloc[:,26:].columns\n\npredictions_ar = pd.DataFrame(np.arange(1,29),columns=['index'])\nactual_ar = pd.DataFrame(np.arange(1,29),columns=['index'])\n\nfor target_variable in target_variables:\n     \n    # Making dataset\n    dataset = master_df[target_variable]\n\n    # Splitting train and test data\n    df_arima_train = dataset[:-28]\n    y_test = dataset[-28:]    \n    \n    # Defining model\n    stepwise_model = auto_arima(df_arima_train,start_p=1,start_q=1,max_p=3,max_q=3,m=7,start_P=0,seasonal=True,d=1,D=1,trace=True,error_action='ignore',suppress_warnings=True,stepwise=True)\n\n    # Predictions\n    test_predictions = stepwise_model.predict(n_periods=28)\n    ar_day_rmse = np.sqrt(metrics.mean_squared_error(test_predictions, y_test))\n    print(f'{target_variable}th rmse:{ar_day_rmse}')\n\n    test_predictions = pd.DataFrame(test_predictions, columns=[target_variable])\n    predictions_ar = pd.concat([predictions_ar, test_predictions], 1)\n\n    y_test = pd.DataFrame(y_test.values, columns=[target_variable])\n    actual_ar = pd.concat([actual_ar, y_test], 1, ignore_index = True)","c2b9896d":"fig = go.Figure()\n\n\nfig.add_trace(go.Scatter(x=predictions.index, y=predictions_ar.sum(axis=1),mode='lines',name='pred_ar'))\n\nfig.add_trace(go.Scatter(x=predictions.index, y=actual_ar.sum(axis=1),mode='lines',name='actual'))\n    \n    \nfig.update_layout(\n    autosize=False,\n    width=1000,\n    height=700,\n    margin=dict(\n        l=50,\n        r=50,\n        b=100,\n        t=100,\n        pad=4\n    ),\n    paper_bgcolor=\"LightSteelBlue\",\n    title=\"Walmart California store 3 household sales for 15 items\",\n    xaxis_title=\"Date\",\n    yaxis_title=\"Sales\",\n    font=dict(\n        family=\"Courier New, monospace\",\n        size=18,\n        color=\"#042a30\"\n    )\n)\n\n\nfig.update_xaxes(rangeslider_visible=True)\nfig.show()","da51abf4":"## Reading data","a92af203":"## LSTM","771ab13a":"## Pre-processing total_value dataset","ccf17703":"### Seperating HOUSEHOLD items","c7c000e8":"## Arima","60e2ec98":"## Importing libraries","aa8bbd7a":"# Model building and preprocessing","71b1daad":"## Pre-processing cal dataset"}}