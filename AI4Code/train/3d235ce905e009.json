{"cell_type":{"978548d3":"code","8d611f93":"code","6760d4fa":"code","cf18fa59":"code","ba5ea74e":"code","3275ff3d":"code","fa61e0dc":"code","aec400f2":"markdown","fac22291":"markdown","0deeeb75":"markdown","9bc42893":"markdown","8fcb58fd":"markdown","95dae62f":"markdown","1682a844":"markdown","1e025c23":"markdown"},"source":{"978548d3":"import os\nimport ast\nfrom typing import Tuple\n\nfrom IPython.display import display\nfrom PIL import Image\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","8d611f93":"DIRECTORY_PATH = '..\/input\/petfinder-pawpularity-score'\nTRAIN_FOLDER_PATH = os.path.join(DIRECTORY_PATH, 'train')\nTRAIN_CSV_PATH = os.path.join(DIRECTORY_PATH, 'train.csv')\nTEST_FOLDER_PATH = os.path.join(DIRECTORY_PATH, 'test')\nTEST_CSV_PATH = os.path.join(DIRECTORY_PATH, 'test.csv')","6760d4fa":"def image_from_id(imgid: str, is_test: bool = False) -> np.ndarray:\n    if is_test:\n        img_path = os.path.join(TEST_FOLDER_PATH, f'{imgid}.jpg')\n    else:\n        img_path = os.path.join(TRAIN_FOLDER_PATH, f'{imgid}.jpg')\n    img = cv2.imread(img_path)\n    return img\n\ndef shape_from_id(imgid: str, is_test: bool = False) -> Tuple[int, int]:\n    img = image_from_id(imgid, is_test=is_test)\n    return img.shape[0], img.shape[1]\n\ndef aspect_from_id(imgid: str, is_test: bool = False) -> Tuple[int, int]:\n    shape = shape_from_id(imgid, is_test=is_test)\n    gcd = np.gcd(shape[0], shape[1])\n    return shape[0] \/\/ gcd, shape[1] \/\/ gcd\n\ndef convert_ndarray_to_PIL(img: np.ndarray) -> Image.Image:\n    return Image.fromarray(np.uint8(img)).convert('RGB')\n\ndef square_image_zfill(img: np.ndarray, img_size: int) -> np.ndarray:\n    # [height, width, 3]\n    if img.shape[0] < img.shape[1]:\n        diff = img.shape[1] - img.shape[0]\n        zarr1 = np.zeros((diff\/\/2, img.shape[1], 3), dtype=np.uint8)\n        zarr2 = np.zeros((diff\/\/2 + diff%2, img.shape[1], 3), dtype=np.uint8)\n        img_square = np.concatenate([zarr1, img, zarr2], axis=0)\n    elif img.shape[0] > img.shape[1]:\n        diff = img.shape[0] - img.shape[1]\n        zarr1 = np.zeros((img.shape[0], diff\/\/2, 3), dtype=np.uint8)\n        zarr2 = np.zeros((img.shape[0], diff\/\/2 + diff%2, 3), dtype=np.uint8)\n        img_square = np.concatenate([zarr1, img, zarr2], axis=1)\n    else:\n        img_square = img\n    return cv2.resize(img_square, (img_size, img_size))","cf18fa59":"df_train = pd.read_csv(TRAIN_CSV_PATH, dtype=str)\ndf_test = pd.read_csv(TEST_CSV_PATH, dtype=str)\n\npd.set_option('display.max_columns', None)\n\ndisplay('train.csv')\ndisplay(df_train.head(5))\ndisplay('test.csv')\ndisplay(df_test.head(5))\n\ntrain_display_id = df_train[\"Id\"][0]\ndisplay(f'train image - Id: {train_display_id}')\ndisplay(convert_ndarray_to_PIL(image_from_id(train_display_id)))\ntest_display_id = df_test[\"Id\"][0]\ndisplay(f'test image - Id: {test_display_id}')\ndisplay(convert_ndarray_to_PIL(image_from_id(test_display_id, is_test=True)))","ba5ea74e":"if os.path.exists('..\/input\/petfinder-image-shape\/train_img_shape.csv'):\n    df_train_img_shape = pd.read_csv('..\/input\/petfinder-image-shape\/train_img_shape.csv', dtype=str)\nelse:\n    df_train_img_shape = df_train.loc[:, ['Id']]\n    df_train_img_shape.loc[:, 'img_shape'] = df_train_img_shape.loc[:, 'Id'].apply(shape_from_id).values\n    df_train_img_shape.loc[:, 'aspect_ratio'] = df_train_img_shape.loc[:, 'Id'].apply(aspect_from_id).values\n    df_train_img_shape.to_csv('train_img_shape.csv', index=False)\n\ndisplay(df_train_img_shape.head(5))\npd.set_option('display.max_rows', None)\n\ndisplay('aspect ratio')\ndf_value_counts = df_train_img_shape['aspect_ratio'].value_counts()\ndisplay(df_value_counts[df_value_counts >= 5])\npd.set_option('display.max_rows', 60)","3275ff3d":"df_train_img_shape.loc[:, 'img_shape'] = df_train_img_shape.loc[:, 'img_shape'].apply(ast.literal_eval).values\ndf_train_img_shape.loc[:, 'num_pixels'] = df_train_img_shape.loc[:, 'img_shape'].apply(lambda x: x[0]*x[1]).values\n\npd.set_option('display.float_format', '{:.0f}'.format)\ndisplay(df_train_img_shape['num_pixels'].describe())\ndisplay(df_train_img_shape[df_train_img_shape['num_pixels'] == 10800])\ndisplay(df_train_img_shape[df_train_img_shape['num_pixels'] == 1638400])","fa61e0dc":"IMG_SIZE = 224\nplt.figure()\nfor i in range(12):\n    fig = plt.subplot(3, 4, i+1)\n    train_display_id = df_train[\"Id\"][i]\n    img = square_image_zfill(image_from_id(train_display_id), IMG_SIZE)\n    fig.imshow(img)\nplt.show()","aec400f2":"## Load data","fac22291":"## Get shape of train image","0deeeb75":"## Function declaration","9bc42893":"# PetFinder.my: Train image shape information\n\nBefore running machine learning, you need to know some information about the images you are going to use.\n\nexample:\n- RGB or glay scale ?\n- How many pixels? 1280 x 960 ?\n- How much is the aspect ratio? 4:3 ?\n\netc.\n\nThis notebook (and output csv file \/ dataset) shows you the size and aspect ratio of train image.\n\nBased on this result, I believe that image pre-processing, such as extracting only the area around the pet, or resizing the image so as not to change its aspect ratio, will be necessary for this competition.\n\nI hope this notebook will be of some help to you :)\n\n\n# Index\n1. [Import libraries](#Import-libraries)\n2. [Constant declaration](#Constant-declaration)\n3. [Function declaration](#Function-declaration)\n4. [Load data](#Load-data)\n5. [Get shape of train image](#Get-shape-of-train-image)\n6. [Number of pixels](#Number-of-pixels)\n7. [Preprocess example](#Preprocess-example)","8fcb58fd":"## Preprocess example","95dae62f":"## Constant declaration","1682a844":"## Number of pixels","1e025c23":"## Import libraries"}}