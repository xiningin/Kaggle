{"cell_type":{"b7a3c5e2":"code","68b74b5d":"code","24638d2a":"code","e1f39d12":"code","6fc01cdc":"code","d1375c26":"code","a3e14a46":"code","095d004b":"code","2c54b96b":"code","45caeb41":"code","f7edfbf2":"code","7aadb190":"code","10cfa032":"code","897d6db8":"code","ac442445":"code","18230680":"code","48720c70":"code","e3f8f97b":"code","b44697ed":"code","e422b0f7":"code","abedb153":"code","356afdd5":"code","326a9c6b":"code","3f6ea820":"code","23f072f2":"code","02111078":"code","9345e219":"code","4e3b1bd5":"code","9c20eee3":"code","0a9f6811":"code","ce27372c":"code","d8454e07":"code","bfeaa211":"code","42cece65":"code","160be0a8":"code","aa8e92d2":"code","d9c679f0":"code","e5c4c337":"code","48d36d4b":"code","e7cb8092":"code","fbf3e5cc":"code","abca2403":"code","9419c5cb":"code","ba564866":"code","f8a31a42":"code","650f1a40":"code","9da57df2":"code","04a04a7a":"code","8912ef56":"code","cb665c7f":"code","0ba5feab":"code","4baa7926":"code","f07898f6":"code","10d00fcf":"code","9149f73f":"code","9e1c4ae7":"code","4ef34a46":"code","26033d41":"code","070bd294":"code","d3da08d6":"code","e976e9dd":"code","5cd862ba":"code","5b89abf0":"code","db7613ad":"code","def3c11f":"code","5cd6501d":"code","2979f9a3":"code","9c612965":"code","91096ae3":"code","7ece6e49":"code","ff8ffa4b":"code","298c044e":"code","48542bab":"code","99738011":"code","f6a48d87":"markdown","beb3563e":"markdown","9586ceca":"markdown","abdabf51":"markdown","e69c075d":"markdown","33029adc":"markdown","cec94eb4":"markdown","4b262413":"markdown","0201db7b":"markdown","dcc40d25":"markdown","617211a2":"markdown","8cbf5046":"markdown","26498683":"markdown","c736c575":"markdown","e70526e4":"markdown","05ca5c29":"markdown","5a194331":"markdown","06a97a06":"markdown","e764b397":"markdown","dcf2e639":"markdown","c298ce42":"markdown","67798369":"markdown","679441ac":"markdown","f3434b66":"markdown","203216c8":"markdown","8912a178":"markdown","07d3860e":"markdown","5a42cc15":"markdown","d606eaf2":"markdown","43c4e739":"markdown","209e5258":"markdown","be7e28ad":"markdown","4a4aab3d":"markdown","0efbbf3c":"markdown","ed56da88":"markdown","8b40bc35":"markdown","d2da409a":"markdown","ce7a30ba":"markdown","79d6d7db":"markdown","8b425f30":"markdown","9b4e5045":"markdown"},"source":{"b7a3c5e2":"\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nfrom fastai.learner import *\nfrom fastai.column_data import *\nfrom sklearn.decomposition import PCA\nfrom plotnine import *\nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n","68b74b5d":"path='..\/input\/'\ntmp_path='\/kaggle\/working\/tmp\/'\nmodels_path='\/kaggle\/working\/models\/'","24638d2a":"ratings = pd.read_csv(path+'rating_final.csv')\nratings","e1f39d12":"ratings.info()","6fc01cdc":"places = pd.read_csv(path+'geoplaces2.csv')\nplaces","d1375c26":"len(ratings['rating'].isnull())","a3e14a46":"df = ratings['rating']\nsns.countplot(df)\nplt.title('Count of ratings given')","095d004b":"import plotly.graph_objs as go\ndf = places['country'].value_counts()\n\niplot([go.Choropleth(\nlocationmode='country names',\nlocations=df.index.values,\ntext=df.index,\nz=df.values\n)])","2c54b96b":"sns.countplot(places['country'])\nplt.title('Count of countries')","45caeb41":"sns.set()\ncolumns = ['rating', 'food_rating','service_rating']\nsns.pairplot(ratings[columns],height=5,kind='scatter')\nplt.show()","f7edfbf2":"fig = (\n   ratings.loc[:,['rating', 'food_rating','service_rating']]\n).corr()\n\nsns.heatmap(fig, annot=True)","7aadb190":"len(ratings['placeID'].unique())","10cfa032":"len(ratings['userID'].unique())","897d6db8":"\n\nratings['userID'].value_counts().head(10).plot.bar( title='Users with the most reviews ')\n","ac442445":"ratings['placeID'].value_counts().head(10).plot.bar(title='Places with most reviews')\n","18230680":"mean = ratings['placeID'].value_counts().mean()\nmean","48720c70":"\nsns.boxplot(\n   x='placeID',\n    y='rating',\n    data=ratings.head(5)\n    \n    \n )","e3f8f97b":"ratings.isnull().any()","b44697ed":"places.isnull().any()","e422b0f7":"places['country'] = places.country.apply(lambda x: x.replace('?','Mexico'))","abedb153":"places['country'] = places.country.apply(lambda x: x.replace('mexico country','Mexico'))","356afdd5":"places['country'] = places.country.apply(lambda x: x.replace('mexico','Mexico'))","326a9c6b":"val_idxs = get_cv_idxs(len(ratings))\nwd=2e-4\nn_factors=50","3f6ea820":"cf = CollabFilterDataset.from_csv(path, 'rating_final.csv','userID','placeID','rating')\nlearn = cf.get_learner(n_factors, val_idxs, 64, opt_fn=optim.Adam,\n                       tmp_name=tmp_path,models_name=models_path)\n","23f072f2":"learn.fit(1e-2,2,wds=wd, cycle_len=1,cycle_mult=2)","02111078":"math.sqrt(0.536)","9345e219":"learn.fit(1e-2,5,wds=wd, cycle_len=1,cycle_mult=2)","4e3b1bd5":"math.sqrt(0.516)","9c20eee3":"restaurant_names = places.set_index('placeID')['name'].to_dict()\ng=ratings.groupby('placeID')['rating'].count()\ntopRestaurants = g.sort_values(ascending=False).index.values[:3000]\ntopRestIdx = np.array([cf.item2idx[o] for o in topRestaurants])","0a9f6811":"m=learn.model; m.cuda()","ce27372c":"restaurant_bias = to_np(m.ib(V(topRestIdx)))","d8454e07":"restaurant_bias","bfeaa211":"restaurant_ratings = [(b[0], restaurant_names[i] ) for i,b in zip(topRestaurants,restaurant_bias)]","42cece65":"sorted(restaurant_ratings, key=lambda o: o[0])[:15]","160be0a8":"sorted(restaurant_ratings, key=lambda o: o[0], reverse=True)[:15]","aa8e92d2":"rest_emb = to_np(m.i(V(topRestIdx)))\nrest_emb.shape","d9c679f0":"pca = PCA(n_components=3)\nrest_pca = pca.fit(rest_emb.T).components_","e5c4c337":"rest_pca.shape","48d36d4b":"fac0 = rest_pca[0]\nrest_comp = [(f,restaurant_names[i]) for f,i in zip(fac0, topRestaurants)]","e7cb8092":"sorted(rest_comp, key=itemgetter(0), reverse=True)[:10]","fbf3e5cc":"sorted(rest_comp, key=itemgetter(0))[:10]","abca2403":"fac1 = rest_pca[1]\nrest_comp= [(f,restaurant_names[i]) for f,i in zip(fac1, topRestaurants)]","9419c5cb":"sorted(rest_comp, key=itemgetter(0), reverse=True)[:10]","ba564866":"sorted(rest_comp, key=itemgetter(0))[:10]","f8a31a42":"idxs = np.random.choice(len(topRestaurants), 50, replace=False)\nX = fac0[idxs]\nY = fac1[idxs]\nplt.figure(figsize=(15,15))\nplt.scatter(X,Y)\nfor i, x, y in zip(topRestaurants[idxs], X, Y):\n    plt.text(x,y,restaurant_names[i],color=np.random.rand(3)*0.7, fontsize=11)\nplt.show()","650f1a40":"#Declear ttwo tensors\na = T([[1.,2],\n      [3,4]])\nb = T([[2.,2],\n      [10,10]])","9da57df2":"a,b","04a04a7a":"a*b","8912ef56":"#this will allow it to run on the GPU\na*b.cuda()","cb665c7f":"(a*b).sum(1)","0ba5feab":"class DotProduct(nn.Module):\n    def forward(self, u, m): return (u*m).sum(1)","4baa7926":"model=DotProduct()","f07898f6":"model(a,b)","10d00fcf":"unique_users = ratings.userID.unique()\nuser_to_idx = {o:i for i,o in enumerate(unique_users)}\nratings.userID = ratings.userID.apply(lambda x:user_to_idx[x])","9149f73f":"unique_places = ratings.placeID.unique()\nplace_to_idx = {o:i for i,o in enumerate(unique_places)}\nratings.placeID = ratings.placeID.apply(lambda x:place_to_idx[x])","9e1c4ae7":"n_users=int(ratings.userID.nunique())\nn_places=int(ratings.placeID.nunique())","4ef34a46":"class EmbeddingDot(nn.Module):\n    def __init__(self, n_users, n_places):\n        super().__init__()\n        self.u = nn.Embedding(n_users, n_factors)\n        self.m = nn.Embedding(n_places, n_factors)\n        self.u.weight.data.uniform_(0,0.05)\n        self.m.weight.data.uniform_(0,0.05)\n        \n    def forward(self, cats, const):\n        users,places = cats[:,0],cats[:,1]\n        u,m = self.u(users),self.m(places)\n        return (u*m).sum(1).view(-1,1)","26033d41":"x = ratings.drop(['rating'],axis=1)\ny = ratings['rating'].astype(np.float32)","070bd294":"ratings['rating'] = ratings['rating'].astype(float)\n","d3da08d6":"ratings['userID'] = ratings.userID.apply(lambda x: x.replace('U',''))","e976e9dd":"data = ColumnarModelData.from_data_frame(path,val_idxs, x, y, ['userID','placeID'], 64)","5cd862ba":"#initialize optimization function\nwd=1e-5\nmodel = EmbeddingDot(n_users, n_places).cuda()\nopt = optim.SGD(model.parameters(), 1e-1,weight_decay=wd,momentum=0.9)","5b89abf0":"fit(model, data, 3, opt, F.mse_loss)","db7613ad":"set_lrs(opt, 0.01)","def3c11f":"fit(model, data, 3, opt, F.mse_loss)","5cd6501d":"set_lrs(opt, 0.0001)","2979f9a3":"fit(model, data, 5, opt, F.mse_loss)","9c612965":"min_rating, max_rating =ratings.rating.min(), ratings.rating.max()\nmin_rating, max_rating","91096ae3":"#1\ndef get_emb(ni,nf):\n    e = nn.Embedding(ni,nf)\n    e.weight.data.uniform_(-0.01,0.01)\n    return e\n\nclass EmbeddingDotBias(nn.Module):\n    def __init__(self,n_users, n_places):\n        super().__init__()\n        #2\n        (self.u, self.m, self.ub, self.mb) = [get_emb(*o) for o in [\n            (n_users, n_factors),(n_places, n_factors), (n_users,1),(n_places,1)\n        ]]\n        \n    #3\n    def forward(self, cats, conts):\n        users,places = cats[:,0],cats[:,1]\n        um = (self.u(users)*self.m(places)).sum(1)\n        res = um + self.ub(users).squeeze() + self.mb(places).squeeze()\n        res= torch.sigmoid(res) * (max_rating-min_rating) + min_rating\n        return res.view(-1,1)","7ece6e49":"wd=2e-4\nmodel = EmbeddingDotBias(cf.n_users, cf.n_items).cuda()\nopt = optim.SGD(model.parameters(), 1e-1,weight_decay=wd,momentum=0.9)\n","ff8ffa4b":"fit(model, data, 3, opt, F.mse_loss)\n","298c044e":"class EmbeddingNet(nn.Module):\n    def __init__(self, n_users, n_places, nh=10, p1=0.05,p2=0.5):\n        super().__init__()\n        (self.u, self.m) = [get_emb(*o) for o in [\n            (n_users,n_factors), (n_places,n_factors)\n        ]]\n        self.lin1 = nn.Linear(n_factors*2, nh)\n        self.lin2 = nn.Linear(nh,1)\n        self.drop1 = nn.Dropout(p1)\n        self.drop2 = nn.Dropout(p2)\n        \n    def forward(self, cats, conts):\n        users,places = cats[:,0],cats[:,1]\n        x = self.drop1(torch.cat([self.u(users), self.m(places)],dim=1))\n        x = self.drop2(F.relu(self.lin1(x)))\n        return F.sigmoid(self.lin2(x)) * (max_rating-min_rating+1) + min_rating-0.5\n    ","48542bab":"wd=1e-5\nmodel=EmbeddingNet(n_users,n_places).cuda()\nopt=optim.Adam(model.parameters(), 1e-3,weight_decay=wd)","99738011":"fit(model, data,3, opt, F.mse_loss)","f6a48d87":"# Table of Contents\n\n* Import dependancies and datasets\n* EDA \n* Cleaning\n* Create Model\n* Analysis of results\n* Create a filtering module from scratch","beb3563e":"We need to fix some of the data to make it sequential and contiguous IDs. ","9586ceca":"## Import dependancies and datasets","abdabf51":"Lets map out our components:","e69c075d":"Each restaurant has an average of about 8 ratings.","33029adc":"## Create Model","cec94eb4":"Top rated resturants","4b262413":"We set up our crosstab where x is everything besides the rating , while y is the rating.\n\n","0201db7b":"first component:","dcc40d25":"## Cleaning\n","617211a2":"## Analysis of results","8cbf5046":"The Top Restaurant has about 35 reviews","26498683":"Lets take a look at the bias for the restaurants:","c736c575":"**Dot product example**","e70526e4":"# Welcome! Lets build a recommendation system together [WIP]\ud83d\udc69\u200d\ud83c\udf73\n\n![Food](https:\/\/images.unsplash.com\/photo-1505714197102-6ae95091ed70?ixlib=rb-0.3.5&ixid=eyJhcHBfaWQiOjEyMDd9&s=e60943a98136dce6e62c7256bfeca5f8&auto=format&fit=crop&w=1350&q=80)\n\nThe goal of this notebook is to apply collaborative filtering on a [restaurant dataset](https:\/\/www.kaggle.com\/uciml\/restaurant-data-with-consumer-ratings) with customer ratings. Collaborative filtering allows us to create recommendation systems based on what activity a user has taken. Recommendation systems are around us on our faviourite services, like Netfix, Amazon, etc. \n\nIn this case we will be using the Fast.ai library which will implement probalisitic matrix factorization. We will just use two factorized matrices as embedding matrices that can be modeled by addding an embedding layer in the neural net. \n\n*[This is still a work in progress]*\n\n\n","05ca5c29":"## Bias\nWe need bias for cases where a user gives low scores to restaurants. We will need to create a new model that takes the bias into account, however, it will differ in that that it uses a convience method to make embeddings and normalizes scores returns from the forward pass.","5a194331":"Second component:","06a97a06":"Ratings seem to go as high as 2, which seems odd.","e764b397":"## EDA \n","dcf2e639":"Lets load our datasets:","c298ce42":"In an attempt to improve the model by training it more, I lead it to overfit. ","67798369":"#### Moving forward\n\n* How do I serve such a model for inference? \n","679441ac":"We can start settung up our model:","f3434b66":"What is going on here?\n\n1. We are getting the number of rows and factors from the rows and columns in the embedding matrix\n2. The embedding matrices and bias vectors are initialized.\n3. We apply a dot product, add our bias vectors and normilize the results","203216c8":"While there appears to 138 different users who gave reviews","8912a178":"From this plot it seems 100% of the resturants in the dataset come from Mexico.","07d3860e":"Lets perform element-wise multiplication:","5a42cc15":"### Mini Neural Net\nWe are going to feed the embedding values into a linear layer.","d606eaf2":"Here we are going to build our own NN to process inputs and compute activations. The PyTorch module is derived from nn.Module which will contain a function called forward to compute the forward pass.","43c4e739":"In the `places` dataframe we will need to do some cleaning, as there is \"mexico country\" and \"?\", listed as countries.","209e5258":"We have about 130 different restaurants in the dataset.","be7e28ad":"### Principla Component Analysis & Embeddings ","4a4aab3d":"From my observations the three variables `rating`, `food_rating` and `service_rating` have a relationship that is weird. If the value of `rating` is 0 the user gave  `service_rating` that was 0 too. the relationship is the same with all the other variables too.","0efbbf3c":"Lets make our paths:","ed56da88":"Worst rated restaurants:","8b40bc35":"However it appears that all the variables in the `ratings` dataframe have a strong positive relantionship with each other.","d2da409a":"Our validation loss is dramatically better!","ce7a30ba":"We will do learning rate annealing to try and reduce the loss.","79d6d7db":"We need the tensor dot product, which is achived by elementwise multiplication and summed across the columns.\n","8b425f30":"# Creating the module\n\nWe will create a module that looks up the factors for the users and places from the embedding matrix and then take the dot product.\n\nin EmbeddingDot we create embedding matrices for users and restuarants, then they are initialized. With the forward pass we take categorical and contiuous variables.","9b4e5045":"# Create a filtering module from scratch"}}