{"cell_type":{"7aa430b3":"code","57e888bc":"code","18aa0725":"code","e6ab8654":"code","1d997a15":"code","a20511e2":"code","f8981c04":"code","636d9983":"code","8286a8f8":"code","5b06ebe0":"code","1354b0ad":"code","a88c9c0a":"code","5a4c79cc":"markdown","067a6c4d":"markdown","8286f753":"markdown","d91c43ed":"markdown","b44f62b9":"markdown","97641969":"markdown","8e5bd890":"markdown","bd1b41b4":"markdown","a0e87f81":"markdown","f07eec7a":"markdown"},"source":{"7aa430b3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","57e888bc":"df=pd.read_csv('..\/input\/FuelConsumption.csv')\ndf.head()","18aa0725":"# summarize the data\ndf.describe()","e6ab8654":"cdf = df[['ENGINESIZE','CYLINDERS','FUELCONSUMPTION_COMB','CO2EMISSIONS']]\ncdf.head(9)","1d997a15":"cdf.hist()","a20511e2":"plt.scatter(cdf.ENGINESIZE, cdf.CO2EMISSIONS)\nplt.xlabel('Engine Size')\nplt.ylabel('Co2 Emissions')","f8981c04":"plt.scatter(cdf.CYLINDERS, cdf.CO2EMISSIONS)\nplt.xlabel('Cylinders')\nplt.ylabel('Co2 Emissions')","636d9983":"plt.scatter(cdf.FUELCONSUMPTION_COMB, cdf.CO2EMISSIONS)\nplt.xlabel('Fuel Consumption')\nplt.ylabel('Co2 Emissions')","8286a8f8":"dataset=np.random.rand (len(df))<0.8\ntrain=cdf[dataset]\ntest=cdf[~dataset]","5b06ebe0":"plt.scatter(train.ENGINESIZE, train.CO2EMISSIONS)\nplt.xlabel('Engine Size')\nplt.ylabel('CO2 Emissions')","1354b0ad":"from sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression\n\nreg = LinearRegression()\ntrain_x = np.asanyarray(train[['ENGINESIZE']])\ntrain_y = np.asanyarray(train[['CO2EMISSIONS']])\nregr.fit(train_x,train_y)\nprint ('Coefficients: ', regr.coef_)\nprint ('Intercept: ',regr.intercept_)","a88c9c0a":"plt.scatter(train.ENGINESIZE, train.CO2EMISSIONS,  color='blue')\nplt.plot(train_x, regr.coef_[0][0]*train_x + regr.intercept_[0], '-r')\nplt.xlabel(\"Engine size\")\nplt.ylabel(\"Emission\")","5a4c79cc":"Using sklearn package to model data.","067a6c4d":"Now, lets plot each of these features vs the Emission, to see how linear is their relation:","8286f753":"## Creating train and test dataset\nTrain\/Test Split involves splitting the dataset into training and testing sets respectively, which are mutually exclusive. After which, you train with the training set and test with the testing set. This will provide a more accurate evaluation on out-of-sample accuracy because the testing dataset is not part of the dataset that have been used to train the data. It is more realistic for real world problems.\n\nThis means that we know the outcome of each data point in this dataset, making it great to test with! And since this data has not been used to train the model, the model has no knowledge of the outcome of these data points. So, in essence, it is truly an out-of-sample testing.\n\nLets split our dataset into train and test sets, 80% of the entire data for training, and the 20% for testing. We create a mask to select random rows using np.random.rand() function:","d91c43ed":"## Plot Outputs","b44f62b9":"## Reading the data in","97641969":"### Train data distribution","8e5bd890":"## Modeling","bd1b41b4":"### Simple Regression Model","a0e87f81":"Lets select some features to explore more.","f07eec7a":"<h2 id=\"data_exploration\">Data Exploration<\/h2>\nLets first have a descriptive exploration on our data."}}