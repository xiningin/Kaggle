{"cell_type":{"4718e50b":"code","a5436830":"code","e65bd437":"code","728e5a58":"code","28b06d68":"code","ac769d48":"code","4873b97c":"code","c50829e8":"code","03ce7fb5":"code","8163903b":"code","84025fbe":"code","7c64e3f5":"code","5aef5f40":"code","0ed1c25e":"code","0fc23710":"code","b73ac6c0":"code","a0496a16":"code","dd0e814c":"code","8d8f2152":"code","a0cfeea2":"code","281288c7":"code","bb9a91c3":"code","ea11725f":"code","8bdcdf50":"code","527eb512":"markdown","8abc8946":"markdown","c2f948bd":"markdown","2566a8b0":"markdown","7187f383":"markdown","956c5ed3":"markdown","fa703d99":"markdown","765804f4":"markdown","0043a88e":"markdown","c7e89cea":"markdown","35642d3b":"markdown","c0232172":"markdown","0a5bf13e":"markdown","ba9a8c1e":"markdown","a8abf87f":"markdown","5dc963a9":"markdown","53d2d287":"markdown","fb90e829":"markdown","a856f3f1":"markdown"},"source":{"4718e50b":"import os\nimport sys\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport cv2\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import ToTensor\n\nfrom sklearn.model_selection import train_test_split\n\nsys.path.append(\"..\/input\/timm-pytorch-image-models\")\nimport timm","a5436830":"df_train = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\ndf_train['Img_path'] = df_train['Id'].apply(lambda i: '..\/input\/petfinder-pawpularity-score\/train\/' + i + \".jpg\")\ndf_test = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\ndf_test['Pawpularity'] = 0\ndf_test['Img_path'] = df_test['Id'].apply(lambda j: '..\/input\/petfinder-pawpularity-score\/test\/' + j + \".jpg\")","e65bd437":"df_test.head()","728e5a58":"df_train.head(10)","28b06d68":"df_train.info()","ac769d48":"plt.figure(figsize=(15,6))\nplt.hist(df_train['Pawpularity'], \n         bins=50,\n         color='lightsteelblue',\n         edgecolor='black')\nplt.ylabel('Count')\nplt.xlabel('Pawpularity')\nplt.title('Pawpularity distribution')","4873b97c":"image_size = 224\nbatch_size = 64\nnum_epochs = 10\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device)","c50829e8":"image_transforms = {'train_transform': A.Compose([A.Resize(image_size, image_size), \n                                                  A.HorizontalFlip(p=0.5), \n                                                  A.VerticalFlip(p=0.5), \n                                                  A.ToSepia(p=0.1), \n                                                  A.Normalize(mean=(0.485, 0.456, 0.406), \n                                                              std=(0.229, 0.224, 0.225), \n                                                              max_pixel_value=255.0, \n                                                              p=1.0), \n                                                  ToTensorV2()]),\n                    \n                   'validation_transform': A.Compose([A.Resize(image_size, image_size), \n                                                      A.Normalize(mean=(0.485, 0.456, 0.406), \n                                                                  std=(0.229, 0.224, 0.225), \n                                                                  max_pixel_value=255.0, \n                                                                  p=1.0), \n                                                      ToTensorV2()]),\n                   'visualization_transform': A.Compose([A.Resize(image_size, image_size), \n                                                         A.HorizontalFlip(p=0.5), \n                                                         A.VerticalFlip(p=0.5),\n                                                         A.ToSepia(p=0.1)])}","03ce7fb5":"class ImageDataset(Dataset):\n    def __init__(self, image_labels, image_dir, transform=None, target_transform=None):\n        self.image_labels = image_labels\n        self.image_dir = image_dir\n        self.transform = transform\n        self.target_transform = target_transform\n        \n        \n    def __len__(self):\n        return len(self.image_labels)\n    \n    \n    def __getitem__(self, index):\n        image_path = self.image_dir.iloc[index]\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        label = self.image_labels.iloc[index]\n        if self.transform:\n            image = self.transform(image=image)['image']\n        if self.target_transform:\n            label = self.target_transform(label=label)\n        return image, label","8163903b":"train_target = df_train['Pawpularity']\ntrain_features = df_train.drop(['Pawpularity'], axis=1)\n\ntest_target = df_test['Pawpularity']\ntest_features = df_test.drop(['Pawpularity'], axis=1)\n\nX_train, X_val, y_train, y_val = train_test_split(train_features, train_target, test_size=0.2)","84025fbe":"train_dataset = ImageDataset(y_train, X_train['Img_path'], transform=image_transforms['train_transform'])\nval_dataset = ImageDataset(y_val, X_val['Img_path'], transform=image_transforms['validation_transform'])\ntest_dataset = ImageDataset(test_target, test_features['Img_path'], transform=image_transforms['validation_transform'])\nvisual_train_dataset =  ImageDataset(y_train, X_train['Img_path'], transform=image_transforms['visualization_transform'])","7c64e3f5":"test_batch_size = len(test_dataset)","5aef5f40":"train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\nvisual_loader = DataLoader(visual_train_dataset, batch_size=batch_size, shuffle=True)","0ed1c25e":"visual_loader","0fc23710":"visual_train_f, visual_train_t = next(iter(visual_loader))\nprint(f'Feature batch shape: {visual_train_f.size()}')\nprint(f'Target batch shape: {visual_train_t.size()}')","b73ac6c0":"def plot_batch(features, target, batch_size=batch_size):\n    '''Shows one batch of augmented images'''\n    plt.figure(figsize=(20, 60))\n    for i in range(batch_size):\n        img = features[i]\n        label = target[i]\n        \n        plt.subplot(16, 4, i+1)\n        plt.title(f'Pawpularity: {label}')\n        plt.imshow(img)\n    plt.show()","a0496a16":"plot_batch(visual_train_f, visual_train_t)","dd0e814c":"pretrained_path = '..\/input\/timmefficientnet\/tf_efficientnet_b0_ns-c0e6a31c.pth'\n\nmodel = timm.create_model('tf_efficientnet_b0_ns', pretrained=False, in_chans=3)\nmodel.load_state_dict(torch.load(pretrained_path))\n\nfor param in model.parameters():\n    param.requires_grad = False\n\nprint(model)","8d8f2152":"model.classifier = nn.Sequential(nn.Linear(1280, 1000, bias=True), \n                                 nn.SiLU(inplace=True),\n                                 nn.Linear(1000, 1, bias=True))\n\nprint(model)","a0cfeea2":"model.to(device)\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","281288c7":"def training_loop(model, training_loader, validation_loader, criterion, optimizer, epochs=num_epochs):\n    '''Training loop for train and eval modes'''\n    for epoch in range(1, epochs+1):\n        train_loss = 0\n        for image, target in training_loader:\n            image = image.to(device)\n            target = target.to(device)\n            target = target.unsqueeze(1)\n            optimizer.zero_grad()\n            outputs = model(image)\n            loss = torch.sqrt(criterion(outputs.float(), target.float()))\n            \n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            \n        with torch.no_grad():\n            model.eval()\n            valid_loss = 0\n            for val_image, val_target in validation_loader:\n                val_image = val_image.to(device)\n                val_target = val_target.to(device)\n                val_target = val_target.unsqueeze(1)\n                val_outputs = model(val_image)\n                val_loss = torch.sqrt(criterion(val_outputs.float(), val_target.float()))\n                \n                valid_loss += val_loss.item()\n                \n        print(f'Epoch: {epoch} Training loss: {train_loss\/len(training_loader)}  Val loss: {valid_loss\/len(validation_loader)}')","bb9a91c3":"training_loop(model, train_loader, val_loader, criterion, optimizer, epochs=num_epochs)","ea11725f":"model.eval()\npreds = []\nfor image, target in test_loader:\n    image = image.to(device)\n    target = target.to(device)\n    test_pred = model(image)\n    preds.extend(list(test_pred.cpu().detach().numpy().reshape(len(test_pred))))\n    \nimgs = list(df_test.iloc[:, 0].values)\npreds = [round(x, 2) for x in preds]\n\npred_df = pd.DataFrame({'Id': imgs, 'Pawpularity': preds})\npred_df.head(10)","8bdcdf50":"# pred_df.to_csv('submission.csv', index=False)","527eb512":"Defining optimizer and loss function:","8abc8946":"Thank You for watching!","c2f948bd":"Changing the last Classifier layer for regression task:","2566a8b0":"Downloading train and test meta DataFrames and appending path for each image:","7187f383":"Creating instances of DataLoader class for all of the datasets:","956c5ed3":"Defining three groups of transformations.\nFor validation, only Resize, Normalization and ToTensor are applied, and for visualization of a batch of images, on the contrary, Normalization and ToTensor are not applied.\nThe mean, std and max_pixel_value are taken from the imagenet dataset.","fa703d99":"Yes, it's ok there.","765804f4":"Estimation of the Pawpularity value distribution:","0043a88e":"Downloading the model EfficientNet_b0 and pretrained state:","c7e89cea":"Checking that the size of the data in the batch matches the requirements of the neural network:","35642d3b":"Defining some configuration variables:","c0232172":"Hi to everyone who decides to read this! \n\nThis is my first experience in computer vision and fine tuning pre-trained models, I couldn't get past such a nice dataset with cute animals :)\n\nThere will be no cross-validation, and I don't know how to use meta-information here either, so this is a very simple beginner's notebook, and I'm very glad that it works","0a5bf13e":"Importing the necessary libraries and ensuring that timm works without an internet connection:","ba9a8c1e":"The distribution looks like a normal one. Values of Pawpularity=100 in this case will not be considered outliers due to the specifics of the data.","a8abf87f":"Now just look at these augmented cuties that are in the same batch, I would take them all home if I could :)","5dc963a9":"Splitting the data and creating train, val, test and visual instances of dataset class:","53d2d287":"Training the model with training loop:","fb90e829":"And finally, predictions:","a856f3f1":"Creating custom dataset class:"}}