{"cell_type":{"fa8060b7":"code","a06801da":"code","c74c14c1":"code","2f22b041":"code","915db7c8":"code","e9a1291c":"code","82a10474":"code","b1a4fae9":"code","94ed399e":"code","41a2def0":"code","074a2749":"code","d82a6344":"code","8850de8d":"code","68e09420":"code","d0a50b64":"code","422dc12d":"code","67dc860d":"code","02103135":"code","d2c12a1e":"code","20e2c211":"markdown","822b18ca":"markdown","ff245cf8":"markdown","f89bb60d":"markdown","4e50cab1":"markdown","ea0ced6a":"markdown","4f6400f7":"markdown"},"source":{"fa8060b7":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LinearRegression,Lasso,Ridge\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import GridSearchCV\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","a06801da":"df = pd.read_csv('..\/input\/delhi-house-price-prediction\/MagicBricks.csv')","c74c14c1":"# Lets check first five rows of the data\ndf.head()","2f22b041":"# Data Shape\ndf.shape","915db7c8":"# lets check the missing values in dataframe\ndf.isnull().sum()","e9a1291c":"df.info()","82a10474":"def get_uniques(df, columns):\n    return {column: list(df[column].unique()) for column in columns if not column == 'Locality'}","b1a4fae9":"def get_categorical_columns(df):\n    return [column for column in df.columns if df.dtypes[column] == 'object']","94ed399e":"get_uniques(df, get_categorical_columns(df))","41a2def0":"def onehot_encoder(df, column, rename=False):\n    df = df.copy()\n    if rename == True:\n        df[column] = df[column].replace({x: i for i, x in enumerate(df[column].unique())})\n    dummies_df = pd.get_dummies(df[column], prefix=column,drop_first=True)\n    df = pd.concat([df, dummies_df], axis=1)\n    df.drop(column, axis=1,inplace=True)\n    return df","074a2749":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop Per_Sqft column\n    df.drop('Per_Sqft', axis=1,inplace=True)\n    \n    # Fill missing values by mode because they are categorical columns\n    missing_values_col = ['Bathroom', 'Parking', 'Type']\n    for col in missing_values_col:\n        df[col] = df[col].fillna(df[col].mode()[0])\n    \n    # One-hot encoding\n    df = onehot_encoder(df, column='Furnishing', rename=False)\n    df = onehot_encoder(df, column='Locality', rename=True)\n    \n    # Binary encoding\n    df['Status'] = df['Status'].replace({\n        'Almost_ready': 0,\n        'Ready_to_move': 1\n    })\n    df['Transaction'] = df['Transaction'].replace({\n        'New_Property': 0,\n        'Resale': 1\n    })\n    df['Type'] = df['Type'].replace({\n        'Builder_Floor': 0,\n        'Apartment': 1\n    })\n    \n    # Split data into X and y\n    y = df['Price']\n    X = df.drop('Price', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=50)\n    \n    # Scale X\n    sc = StandardScaler()\n    X_train = pd.DataFrame(sc.fit_transform(X_train), index=X_train.index, columns=X_train.columns)\n    X_test = pd.DataFrame(sc.transform(X_test), index=X_test.index, columns=X_test.columns)\n    \n    return X_train, X_test, y_train, y_test","d82a6344":"X_train, X_test, y_train, y_test = preprocess_inputs(df)","8850de8d":"# Models\nmodels = [\n    LinearRegression(),\n    Lasso(),\n    Ridge(),\n    KNeighborsRegressor(),\n    DecisionTreeRegressor(),\n    RandomForestRegressor(),\n    XGBRegressor()\n]\nmodel_names = [\n    'LinearRegression',\n    'Lasso',\n    'Ridge',\n    'KNeighborsRegressor',\n    'DecisionTreeRegressor',\n    'RandomForestRegressor',\n    'XGBRegressor']\n\nscore = []\ndictionary = {}\nfor model in range(len(models)):\n    reg = models[model]\n    reg.fit(X_train,y_train)\n    y_pred = reg.predict(X_test)\n    score.append(r2_score(y_test,y_pred))\n     \ndictionary = {'Model Names':model_names,'R2 Score': score}\n# Put the accuracies in a data frame.\nscore_df = pd.DataFrame(dictionary)\nscore_df.style.set_precision(5)","68e09420":"model_params = {\n    'XGBRegressor':{\n        'model':XGBRegressor(),\n        'params':{\n            'learning_rate': [0.01, 0.1],\n            'max_depth': [3, 5, 7, 10],\n            'min_child_weight': [1, 3, 5],\n            'subsample': [0.5, 0.7],\n            'colsample_bytree': [0.5, 0.7],\n            'n_estimators' : [100, 200, 500],\n            'objective': ['reg:squarederror']\n        }\n    },\n\n    'RandomForestRegressor':{\n        'model':RandomForestRegressor(),\n        'params':{\n            'n_estimators':range(100,300,50),\n            'criterion':['mse','mae'],\n            'max_features':['auto', 'sqrt', 'log2']\n        }\n    }\n}","d0a50b64":"scores = []\nfor model_name,model in model_params.items():\n    grid = GridSearchCV(model['model'],model['params'],cv=5,return_train_score=False,scoring='r2')\n    grid.fit(X_train,y_train)\n    scores.append({\n      'model':model_name,\n      'best_score':grid.best_score_,\n      'best_params':grid.best_params_\n  })","422dc12d":"df_scores = pd.DataFrame(scores,columns=['model','best_score','best_params'])\ndf_scores","67dc860d":"## XGBoost\nxgb = XGBRegressor(\n    colsample_bytree= 0.7,\n    learning_rate= 0.01,\n    max_depth= 7,\n    min_child_weight = 1,\n    n_estimators=500,\n    objective = 'reg:squarederror',\n    subsample= 0.7\n)\n\nxgb.fit(X_train,y_train)\nxgb_pred = xgb.predict(X_test)\n\nprint(\" R^2 Score: {:.5f}\".format(r2_score(y_test,xgb_pred)))","02103135":"## Random Forest\nrf = RandomForestRegressor(\n    criterion= 'mae',\n    max_features = 'auto',\n    n_estimators= 250\n)\n\nrf.fit(X_train,y_train)\nrf_pred = rf.predict(X_test)\n\nprint(\" R^2 Score: {:.5f}\".format(r2_score(y_test,rf_pred)))","d2c12a1e":"# Save the tuned Model to file in the current working directory\nimport pickle\n\nPkl_Filename = \"XGB.pkl\"  \n\nwith open(Pkl_Filename, 'wb') as file:  \n    pickle.dump(xgb, file)","20e2c211":"<p>As we can see that there are missing values present in our dataset which we need to handle.<\/p>","822b18ca":"### Data Preprocessing","ff245cf8":"### Hyperparamter Tuning","f89bb60d":"### Importing Required Libraries","4e50cab1":"# **Delhi House Price Prediction**","ea0ced6a":"### Best Fit","4f6400f7":"### Load Data"}}