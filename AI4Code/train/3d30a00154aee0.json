{"cell_type":{"5e0ab956":"code","c2f1bdb8":"code","3c9b5f9b":"code","9517ee2a":"code","0008f550":"code","00f80b2c":"code","c6dd5d84":"code","d6a31247":"code","5c2f3f86":"code","16108eb5":"code","0c162247":"code","ffb2e572":"code","b095c08c":"code","cddd3a77":"code","2cdff5ff":"code","7b251824":"code","eea19ac1":"code","f9cca48e":"code","1158d669":"code","2c53075c":"code","5fb437b5":"code","404c17b4":"code","26d5ce2e":"code","f2a24a69":"code","4316e15a":"code","381aad5b":"code","ee7cba00":"code","89fb07df":"code","4d9af5f2":"code","ee3827c2":"code","de7b7aa6":"code","b34f2235":"code","78649f05":"code","0f999fd9":"code","12fe57be":"code","e25bb687":"code","88ae1b62":"code","e094399b":"code","af7ecbbc":"code","cc76e899":"code","4cb106c2":"code","2f28eac8":"code","75030f3f":"code","65596573":"code","8a6a2756":"code","96acc67a":"code","21fa8a84":"code","49b8e01f":"code","70205358":"code","a87da82d":"code","352d2daa":"code","9c833619":"markdown","dad00997":"markdown","c1ff07c5":"markdown","bbdd0d4a":"markdown","11940390":"markdown","7680d1ca":"markdown","b2424033":"markdown","39355539":"markdown","cb7231a1":"markdown","187e7cbf":"markdown","9a9a6272":"markdown","5d15b7dc":"markdown","6680202e":"markdown","ff88a664":"markdown","3411f205":"markdown","7c425057":"markdown","15911993":"markdown","d4ef3d80":"markdown","d2ae82bf":"markdown","699975fe":"markdown","47caf39d":"markdown"},"source":{"5e0ab956":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c2f1bdb8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","3c9b5f9b":"train = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")","9517ee2a":"submission_look = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\nsubmission_look.head()","0008f550":"print(\"\\n TRAIN FILE \\n\")\ndisplay(train.head())\nprint(\"\\n TEST FILE \\n\")\ndisplay(test.head())","00f80b2c":"print(\"\\n TRAIN FILE \\n\")\ndisplay(train.shape)\nprint(\"\\n TEST FILE \\n\")\ndisplay(test.shape)","c6dd5d84":"print(\"\\n TRAIN FILE \\n\")\ndisplay(train.describe())\nprint(\"\\n TEST FILE \\n\")\ndisplay(test.describe())","d6a31247":"print(\"\\n TRAIN FILE \\n\")\ndisplay(train.columns)\nprint(\"\\n TEST FILE \\n\")\ndisplay(test.columns)","5c2f3f86":"print(\"\\n TRAIN FILE \\n\")\ndisplay(train.isnull().sum())\nprint(\"\\n TEST FILE \\n\")\ndisplay(test.isnull().sum())","16108eb5":"def missing_data_percentage(a):\n    total = a.isnull().sum().sort_values(ascending=False)\n    percent = (a.isnull().sum()\/a.isnull().count()).sort_values(ascending=False)\n    b = pd.concat([total, percent], axis=1, keys=['Total NULL values', 'Percentage'])\n    return b\n\nprint(\"\\n TRAIN FILE \\n\")\ndisplay(missing_data_percentage(train))\nprint(\"\\n TEST FILE \\n\")\ndisplay(missing_data_percentage(test))","0c162247":"a = missing_data_percentage(train)","ffb2e572":"f, ax = plt.subplots(figsize=(10, 8))\nplt.xticks(rotation='90')\nsns.barplot(x=a.index, y=a['Percentage']*100)\nplt.xlabel('Features', fontsize=1)\nplt.ylabel('Percent of missing values', fontsize=15)\nplt.title('Percent missing data by feature', fontsize=15)","b095c08c":"print(\"\\n TRAIN FILE \\n\")\ndisplay(train.dtypes)\nprint(\"\\n TEST FILE \\n\")\ndisplay(test.dtypes)","cddd3a77":"print(\"\\n Description \\n\")\ndisplay(train['SalePrice'].describe())","2cdff5ff":"sns.distplot(train['SalePrice'])","7b251824":"print(\"Skewness Value:\",train['SalePrice'].skew())\nprint(\"Kurtosis value:\", train['SalePrice'].kurt())","eea19ac1":"corrmat = train.corr()\nk = 10\ncols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\ncm = np.corrcoef(train[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","f9cca48e":"cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\nsns.pairplot(train[cols])","1158d669":"sns.distplot(np.log(train['SalePrice']), fit=norm);\nfig = plt.figure()\nres = stats.probplot(np.log(train['SalePrice']), plot=plt)","2c53075c":"#train['SalePrice'] = np.log(train['SalePrice'])\n#train['GrLivArea'] = np.log(train['GrLivArea'])\n#train['TotalBsmtSF'] = np.log(train['TotalBsmtSF'])","5fb437b5":"def preprocess(df):\n    df.dropna(inplace=True, axis=1)\n    df.reset_index(inplace=True,drop=True) \n    object_type_columns = df.select_dtypes(include=['object']).columns\n    print(\"Object_Type_Columns:\\n\",object_type_columns)\n    display(\"Top 10 most affecting factors\")\n    corrmat = train.corr()\n    k = 10\n    cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n    cm = np.corrcoef(train[cols].values.T)\n    sns.set(font_scale=1.25)\n    hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n    plt.show()\n    display('Before Label Encoding Dataframe')\n    display(df)\n    from sklearn import preprocessing\n    le = preprocessing.LabelEncoder()\n    for i in object_type_columns:\n        df[i] = le.fit_transform(df[i])\n    display('Making Data ready for Fitting in Model')\n    return df","404c17b4":"preprocess(train)","26d5ce2e":"train_cols = train.columns","f2a24a69":"test1 = train.drop(['SalePrice'],axis=1)\ntest_new = test[test1.columns]\ndisplay(test_new.columns)\ndisplay(test_new.dtypes)","4316e15a":"#test_new[['MSZoning']].idxmax()","381aad5b":"def preprocess_test(df):\n    #df = df.replace({np.nan:'-'})\n    object_type_columns = df.select_dtypes(include=['object']).columns\n    float_type_columns = df.select_dtypes(include=['float']).columns\n    print(\"Object_Type_Columns:\\n\",object_type_columns)\n    print(\"\\nFloat_Type_Columns:\\n\",float_type_columns)\n    display('Before Label Encoding Dataframe')\n    display(df)\n    \n    for o in object_type_columns:\n        values = df[o].value_counts().idxmax()\n        df[o] = df[o].fillna(value=values)\n    \n    for f in float_type_columns:\n        values = df[f].mean()\n        df[f] = df[f].fillna(value=values)\n        \n    from sklearn import preprocessing\n    #from sklearn.preprocessing import OneHotEncoder\n    le = preprocessing.LabelEncoder()\n    #ohe = OneHotEncoder(handle_unknown='ignore')\n    for i in object_type_columns:\n        df[i] = le.fit_transform(df[i])\n    display('Making Data ready for Fitting in Model')\n    return df","ee7cba00":"preprocess_test(test_new)","89fb07df":"X = train.drop(['SalePrice'],axis=1)\n#test1 = test[X.columns]\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)\ny = np.array(train['SalePrice']).reshape(-1,1)\ny = sc.fit_transform(y)","4d9af5f2":"from sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1\/3, random_state=0)","ee3827c2":"from sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)","de7b7aa6":"'''viz_train = plt\nviz_train.scatter(X_train, y_train, color='red')\nviz_train.plot(X_train, regressor.predict(X_train), color='blue')\nviz_train.show()\n\n# Visualizing the Test set results\nviz_test = plt\nviz_test.scatter(X_test, y_test, color='red')\nviz_test.plot(X_train, regressor.predict(X_train), color='blue')\nviz_test.show()'''","b34f2235":"regressor.score(X_train, y_train)","78649f05":"y_pred = regressor.predict(X_test)","0f999fd9":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error","12fe57be":"a = mean_squared_error(y_test, y_pred)","e25bb687":"rmse = a**0.5\nrmse","88ae1b62":"from sklearn.tree import DecisionTreeRegressor  \n  \n# create a regressor object \nregressorTree = DecisionTreeRegressor(random_state = 0)  \n  \n# fit the regressor with X and Y data \nregressorTree.fit(X_train, y_train) ","e094399b":"regressorTree.score(X_train, y_train)","af7ecbbc":"y_pred_tree = regressor.predict(X_test)","cc76e899":"DTRrmse = (mean_squared_error(y_test, y_pred_tree))**0.5\nDTRrmse","4cb106c2":"from sklearn.ensemble import GradientBoostingRegressor\n\nregressorGB = GradientBoostingRegressor(\n    max_depth=5,\n    n_estimators=10,\n    learning_rate=0.8\n)\nregressorGB.fit(X_train, y_train)","2f28eac8":"errors = [mean_squared_error(y_test, y_pred) for y_pred in regressorGB.staged_predict(X_test)]\nbest_n_estimators = np.argmin(errors)","75030f3f":"regressorGB.score(X_train, y_train)","65596573":"y_predGB = regressorGB.predict(X_test)","8a6a2756":"GBrmse = (mean_squared_error(y_test, y_predGB))**0.5\n\nGBrmse","96acc67a":"predictions = regressorGB.predict(test_new)","21fa8a84":"predictions_transform = sc.inverse_transform(predictions)","49b8e01f":"predictions_transform","70205358":"submission = pd.DataFrame(data = { 'Id' : test_new['Id'], 'SalePrice' : predictions_transform})","a87da82d":"submission","352d2daa":"submission.to_csv('Submission.csv', index=False)","9c833619":"### Statistical Description","dad00997":"> We need to now apply transformations to our data, remove columns ","c1ff07c5":"# Regression Model ","bbdd0d4a":"# **Getting Data**","11940390":"#### Distribution Curve","7680d1ca":"### Data Type of columns","b2424033":"### Looking into Data","39355539":"### NULL VALUES","cb7231a1":"#### HeatMap\n    To get important features","187e7cbf":"## Preprocessing Test File","9a9a6272":"## Preprocessing Train File","5d15b7dc":"# **EDA**","6680202e":"# Data Preprocessing","ff88a664":"### Sales Price Analysis","3411f205":"#### Data is skewed and dense at bottom, So checking for skewness and kurtosis","7c425057":"### Shape of Data","15911993":"### Getting View of Submission file","d4ef3d80":"#### Pairplot","d2ae82bf":"### Columns","699975fe":"### Missing Data(in percentage)","47caf39d":"## Linear Regression"}}