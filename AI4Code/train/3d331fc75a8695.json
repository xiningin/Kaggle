{"cell_type":{"c7daa11a":"code","a9f92271":"code","a010cfe2":"code","6d1f8d75":"code","6b53ef51":"code","e2dd1bf7":"code","d8f7091f":"code","07c0520f":"code","4e7bc27d":"code","9b40bff5":"code","0f85a84a":"code","201bd61c":"markdown","14f60c53":"markdown","f9b34129":"markdown"},"source":{"c7daa11a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a9f92271":"import matplotlib.pyplot as plt","a010cfe2":"train= pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv',index_col=0)\nprint(train.describe())\nprint(train.dtypes)\nprint(train.shape)","6d1f8d75":"X=train.drop(['Class'],axis=1)\ny=train[['Class']]","6b53ef51":"#Check for missing values\nprint(X.isnull().sum())","e2dd1bf7":"import seaborn as sns\n#Define few functions for data visualization\n \ndef countplot(df):\n    plt.figure(figsize=(10,6))\n    sns.countplot(df,palette='spring')\n    plt.title('Countplot')\n    plt.show()\n\ncountplot(y['Class'])\nprint(y.value_counts())      \n","d8f7091f":"from sklearn.preprocessing import StandardScaler\nstd=StandardScaler()\nX['Amount']=std.fit_transform(X[['Amount']])\nprint(X.head(n=6))","07c0520f":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.25,random_state=99)","4e7bc27d":"from catboost import CatBoostClassifier,Pool\n\ncat_col=X_train.select_dtypes(exclude=[np.number]).columns\ncat_cols=[c for c in cat_col]\n\ncat_features = [X_all.columns.get_loc(col) for col in cat_cols]\nprint(cat_features)\n\ntrain_x=Pool(data=X_train,label=y_train,cat_features=cat_features)\ntest_x=Pool(data=X_test,label=y_test,cat_features=cat_features)\n\nparams = {'loss_function':'Logloss',\n          'learning_rate':0.03,\n          'depth':7,\n          'n_estimators':10000,\n          'eval_metric':'AUC',\n          'od_type': 'Iter',\n          'od_wait':1000,\n          'verbose':200,\n          'one_hot_max_size':0,\n          'class_weights':(577,1),\n          'random_state':99\n         }\ncat=CatBoostClassifier(**params)\ncat.fit(train_x,eval_set=test_x,use_best_model=True,plot=True)","9b40bff5":"\npredict=cat.predict(test_x)\npred_prob=cat.predict_proba(test_x)[:,1]\nprint(pred.shape)\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, predict))","0f85a84a":"my_submission=pd.DataFrame({'Prediction':pred_prob })\nmy_submission.to_csv('\/kaggle\/working\/submission.csv', index=False)","201bd61c":"**CatBoost performs very good on the validation set**","14f60c53":"No missing values\n","f9b34129":"The dataset is highly imblanced. We cannot build a good model out of this dataset. Lets still try it using CatBoostClassifier"}}