{"cell_type":{"85a43b0e":"code","c29f7365":"code","b85d01cf":"code","c5e2c3fc":"code","1d138ef6":"code","ab1fd6da":"code","8e426f34":"code","84eb3f1e":"code","b580e56e":"code","a5c2f25a":"code","526472d6":"code","4245c826":"code","fd787145":"code","d435332b":"code","b4523425":"code","a71ed555":"code","4b5be6c6":"code","3387b617":"code","566a1feb":"code","6927af69":"code","5e275727":"code","a5f801ec":"markdown","269e1f0e":"markdown","5e0b5f31":"markdown","b9a0d1ca":"markdown","4189cfe4":"markdown","dc48c5bf":"markdown","1f5eaca5":"markdown","5bcc0f50":"markdown","8e9f11f6":"markdown","1ee72d8d":"markdown","7b207c96":"markdown","95b2e507":"markdown","91fb68f2":"markdown","fbd53940":"markdown","30f85a32":"markdown","60ccac0e":"markdown","41402f7d":"markdown","53badec2":"markdown"},"source":{"85a43b0e":"import sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nsys.path.append('..\/input\/earlystoppingpytorch\/early-stopping-pytorch')","c29f7365":"# Import libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport path\nimport random\nimport cv2\nimport timm\nimport gc\nimport albumentations\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Import PyTorch Libraries\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nfrom pytorchtools import EarlyStopping\nfrom torch.utils.data import DataLoader\n\n\n# Import SKlearn Libraries\nfrom sklearn import datasets\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import mean_squared_error\n\n# Deciding the device used for calculation. CUDA = GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","b85d01cf":"data_df = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/test.csv\")","c5e2c3fc":"target = ['Pawpularity']\nnot_features = ['Id', 'kfold', 'image_path', 'Pawpularity']\ncols = list(data_df.columns)\nfeatures = [feat for feat in cols if feat not in not_features]\nprint(features)","1d138ef6":"params = {\n    'folder_dir': '..\/input\/petfinder-pawpularity-score\/',\n    'model':'swin_large_patch4_window12_384',\n    'image_dir': '..\/input\/petfinder2-cropped-dataset\/crop\/',\n    'test_img_dir': '..\/input\/petfinder-pawpularity-score\/test\/',\n    'features': features,\n    'img_size' : 384,\n    'dropout':0.4,\n    'num_workers':2,\n    'fold' : 10,\n    'batch_size' : 8,\n    'lr' : 1e-5,\n    'scheduler_name': 'CosineAnnealingWarmRestarts',\n    'T_0':10,\n    'min_lr':1e-7,\n    'pretrained':True,\n    'weight_decay':1e-6\n}\n\n# Setting manual seed to everything.\n# So that we will get the same results everything we run the notebook.\nSEED = 42\n\ndef seed_everything(seed=SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything()","ab1fd6da":"class PawDataSet():\n    def __init__(self,dataset, params, features, transform = None,):\n        self.dataset = dataset\n        self.image_path = dataset['Id'].apply(lambda x: os.path.join(params['image_dir'],f'{x}.jpg'))\n        self.target_label = dataset['Pawpularity']\n        self.features = dataset[features].values\n        self.class_label = self.target_label\/100\n        self.transform = transform\n        self.params = params\n    \n    # Returen the len of data.\n    def __len__(self):\n        return len(self.image_path)\n    \n    # Load images and target score according to index number (idx)\n    def __getitem__(self, idx):\n        image_filepath = self.image_path[idx]\n        image = cv2.imread(image_filepath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        \n        image = np.transpose(image,(2, 0, 1)).astype(np.float32)\n        image = torch.tensor(image)\n        features = self.features[idx, :]\n        targets = torch.tensor(self.class_label[idx]).float()\n        \n        return image, features, targets","8e426f34":"# Augmentation function for the training data.\ndef Transform_train(DIM = params['img_size']):\n    return albumentations.Compose(\n        [\n            albumentations.Resize(DIM,DIM),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n            albumentations.HorizontalFlip(p=0.5),\n            albumentations.VerticalFlip(p=0.5),\n            albumentations.Rotate(limit=45, p=0.4),\n            albumentations.ShiftScaleRotate(\n                shift_limit = 0.1, scale_limit=0.1, rotate_limit=45, p=0.5\n            ),\n            albumentations.HueSaturationValue(\n                hue_shift_limit=0.2, sat_shift_limit=0.2,\n                val_shift_limit=0.2, p=0.5\n            ),\n            albumentations.RandomBrightnessContrast(\n                brightness_limit=(-0.1, 0.1),\n                contrast_limit=(-0.1, 0.1), p=0.5\n            )\n        ],\n        p=1.0\n    )","84eb3f1e":"# Augmentation function for the validation data.\ndef Transform_val(DIM = params['img_size']):\n    return albumentations.Compose(\n        [\n            albumentations.Resize(DIM, DIM),\n            albumentations.Normalize(\n                mean = [0.485, 0.456, 0.406],\n                std = [0.229, 0.224, 0.225],\n                max_pixel_value=255.0,\n                p = 1.0\n            ),\n        ],\n        p=1.0\n    )","b580e56e":"# Using Sturges' rule to determine the best number of bins for our data.\nnum_bins = int(np.floor(1+np.log2(len(data_df))))","a5c2f25a":"data_df['bins'] = pd.cut(data_df['Pawpularity'], bins=num_bins, labels=False)\ndata_df['fold'] = -1\n\n# Function to create Folds.\ndef create_folds(data, num_splits):\n    strat_kfold = StratifiedKFold(n_splits=num_splits, random_state=SEED, shuffle=True)\n    for i, (_, idx) in enumerate(strat_kfold.split(data_df.index, data_df['bins'])):\n        data_df.iloc[idx, -1] = i\n    \n    data_df['fold'] = data_df['fold'].astype('int')\n    data_df.fold.value_counts().plot.bar(xlabel=\"Fold\", ylabel=\"Number of data\")\n    ","526472d6":"# 5 Folds\ndf_5 = create_folds(data_df, num_splits=5)","4245c826":"# 10 Folds\ndf_10 = create_folds(data_df, num_splits=10)","fd787145":"def usr_rmse_score(output, target):\n    y_pred = torch.sigmoid(output).cpu()\n    y_pred = y_pred.detach().numpy()*100\n    target = target.cpu()*100\n    \n    return mean_squared_error(target, y_pred, squared=False)","d435332b":"class MetricMonitor:\n    def __init__(self, float_precision=3):\n        self.float_precision = float_precision\n        self.reset()\n        \n    def reset(self):\n        self.metrics = defaultdict(lambda: {'val':0, 'count':0, 'avg':0})\n    \n    def update(self, metric_name, val):\n        metric = self.metrics[metric_name]\n        \n        metric['val'] += val\n        metric['count'] += 1\n        metric['avg'] = metric['val'] \/ metric['count']\n        \n    def __str__(self):\n        return \"|\".join(\n            [\n                \"{metric_name}: {avg:.{float_precision}f}\".format(\n                    metric_name=metric_name, avg=metric['avg'],\n                    float_precision=self.float_precision\n                )\n                for (metric_name, metric) in self.metrics.items()\n            ]\n        )\n    ","b4523425":"def get_scheduler(optimizer, scheduler_params=params):\n    if scheduler_params['scheduler_name'] == 'CosineAnnealingWarmRestarts':\n        scheduler = CosineAnnealingWarmRestarts(\n            optimizer,\n            T_0 = scheduler_params['T_0'],\n            eta_min = scheduler_params['min_lr'],\n            last_epoch = -1\n        )\n    return scheduler","a71ed555":"# Load and print out the architecture of the pretrained model.\n# We will change only the last layer of the model(head) in the next column.\nSWIN_model = timm.create_model(model_name = params['model'])\nprint(SWIN_model)","4b5be6c6":"class PetNet(nn.Module):\n    def __init__(self, model_name=params['model'], pretrained=params['pretrained'], features=len(params['features']) ):\n        super().__init__()\n        self.model = timm.create_model(model_name=model_name, pretrained=pretrained, in_chans=3)\n        # Replace the final head layers in model with our own Linear layer\n        num_features = self.model.head.in_features\n        self.model.head = nn.Linear(num_features, 128)\n        self.fully_connect = nn.Sequential(nn.Linear(128 + features, 64),\n                                           nn.ReLU(),\n                                           nn.Linear(64, 1)\n                                          )\n        self.dropout = nn.Dropout(p=0.5)\n    \n    def forward(self, image, features):\n        x = self.model(image)\n        # Using dropout functions to randomly shutdown some of the nodes in hidden layers to prevent overfitting.\n        x = self.dropout(x)\n        # Concatenate the metadata into the results.\n        x = torch.cat([x, features], dim=1)\n        output = self.fully_connect(x)\n        return output","3387b617":"def train_fn(train_loader, model, criterion, optimizer ,epoch, params, scheduler=None):\n    metric_monitor = MetricMonitor()\n    # Set the model into train model. There are train mode and eval mode.\n    model.train()\n    \n    # Load the data using tqdm to visualize the training process.\n    stream = tqdm(train_loader)\n    \n    for i, (images,features, target) in enumerate(stream):\n        images = images.to(device)\n        target = target.to(device).view(-1, 1)\n        features = features.to(device)\n        \n        # Generate predictions by passing images through the model.\n        preds = model(images, features)\n        \n        # Calculate the difference between prediction value and target value ('Pawpularity' label). \n        loss = criterion(preds, target)\n        \n        # Generate Root Mean Square Error score\n        rmse_score = usr_rmse_score(preds, target)\n        metric_monitor.update('Loss', loss.item())\n        metric_monitor.update('RMSE', rmse_score)\n        \n        # Generate loss gradient and optimize the weight of model using optimizer.\n        loss.backward()\n        if (i+1)%4==0:\n            optimizer.step()\n        \n        # Use scheduler to change the learning rate.\n            scheduler.step()\n            \n        # Reset the gradient after each loop. To avoid it from adding up.\n        optimizer.zero_grad()\n        \n        # Set description to the progress bar when we run this training function\n        stream.set_description(f\"Epoch: {epoch:02}. Train. {metric_monitor}\")","566a1feb":"def validate_fn(val_loader, model, criterion, epoch, params):\n    metric_monitor = MetricMonitor()\n    \n    # Set the model into evaluation mode. This will turn off the Dropout layers or BatchNorm layers in the model.\n    model.eval()\n    stream = tqdm(val_loader)\n    valid_targets = []\n    predictions = []\n    \n    # Turn off the gradient tracking for faster processing.\n    with torch.no_grad():\n        for i, (images,features, target) in enumerate(stream, start=1):\n            images = images.to(device)\n            target = target.float().view(-1, 1)\n            target = target.to(device)\n            features = features.to(device)\n           \n            preds = model(images, features)\n            loss = criterion(preds, target)\n           \n            rmse_score = usr_rmse_score(preds, target)\n            metric_monitor.update('Loss', loss.item())\n            metric_monitor.update('RMSE', rmse_score)\n            stream.set_description(f'Epoch: {epoch:02}. Valid. {metric_monitor}')\n            \n            targets = (target.detach().cpu().numpy()*100).tolist()\n            outputs = (torch.sigmoid(preds).detach().cpu().numpy()*100).tolist()\n            \n            valid_targets.extend(targets)\n            predictions.extend(outputs)\n            \n    return valid_targets, predictions","6927af69":"best_models_of_each_fold = []\nrmse_tracker = []","5e275727":"# Set the range from 0 to 10 to run the whole Folds.\nfor fold in range(2):\n    # Split the data into training data and validation data for cross validation\n    # The data that have same label as the fold will be used as Validation data, the rest as Training data.\n    train = data_df[data_df['fold']!=fold].reset_index(drop=True)\n    val = data_df[data_df['fold']==fold].reset_index(drop=True)\n    \n    # Making training and validating dataset.\n    train_dataset = PawDataSet(\n        dataset = train,\n        params = params,\n        features = params['features'],\n        transform = Transform_train()\n    )\n    val_dataset = PawDataSet(\n        dataset = val,\n        params = params,\n        features = params['features'],\n        transform = Transform_val()\n    )\n    \n    # Making data loader using PyTorch DataLoader function. This allow us to separate data into small batches to train the model.\n    train_loader  = DataLoader(\n        train_dataset, batch_size=params['batch_size'], shuffle=True, \n        num_workers=params['num_workers']\n    )\n    \n    val_loader = DataLoader(\n        val_dataset, batch_size=params['batch_size'], shuffle=False,\n        num_workers=params['num_workers']\n    )\n    \n    # Loading model into GPU.\n    model = PetNet()\n    model = model.to(device)\n    \n    # Setting criterion to calculate loss, optimizer and scheduler.\n    criterion = nn.BCEWithLogitsLoss()\n    optimizer = torch.optim.AdamW(model.parameters(),\n                                 lr=params['lr'],\n                                 weight_decay=params['weight_decay'],\n                                 amsgrad=False)\n    \n    # Use the scheduler functions that we defined at section 5.2 to update the learning rate in optimizer.\n    scheduler = get_scheduler(optimizer)\n    \n    # Early stopping functions to stop the training process if the model is not improving after each epoch.\n    early_stopping = EarlyStopping(patience=2, verbose=True)\n    \n    # Training and validation loop\n    best_rmse = np.inf\n    best_epoch = np.inf\n    best_model_name = None\n    \n    # Epoch = how many times to repeat the training loop.\n    for epoch in range(40):\n        train_fn(train_loader, model, criterion, optimizer, epoch, params, scheduler)\n        predictions, valid_targets = validate_fn(val_loader, model, criterion, epoch, params)\n        rmse = round(mean_squared_error(valid_targets, predictions, squared=False), 3)\n        \n        # Condition loop to save the model with best score.\n        if rmse < best_rmse:\n            best_rmse = rmse\n            best_epoch = epoch\n            if best_model_name is not None:\n                os.remove(best_model_name)\n                \n            # Saving state_dict of the best model to rerun it later for inference.\n            torch.save(model.state_dict(),\n                       f\"{params['model']}_epoch_f{fold}.pth\")\n            best_model_name = f\"{params['model']}_epoch_f{fold}.pth\"\n        \n        # Evaluate the output rmse of the model to decide whether to stop the loop or not.\n        early_stopping(rmse, model)\n        \n        # Stop the training loop if the score doesn't improve after each epoch.\n        if early_stopping.early_stop:\n            print(\"Early stopping\")\n            break\n            \n    # Print summary\n    print('')\n    print(f'The best RMSE: {best_rmse} for fold {fold+1} was achieved on epoch: {best_epoch}')\n    print(f'The best saved model is: {best_model_name}')\n    best_models_of_each_fold.append(best_model_name)\n    rmse_tracker.append(best_rmse)\n    print(''.join(['#']*50))\n    del model\n    gc.collect()\n    torch.cuda.empty_cache()\n    \nprint('')\nprint(f'Average RMSE of all folds: {round(np.mean(rmse_tracker), 4)}')\n    \n    ","a5f801ec":"# 4. Spliting the data into K Fold\n\nAt this section, I will split the data into different Folds(batches) to perform cross validation. By splitting the data into K folds, I can leave out one fold of the data as validation data and use K-1 folds to train the model. By doing this, I can prevent the model from overfitting and be able to predict general data more accurately.\n\nMore about cross validation here : https:\/\/machinelearningmastery.com\/repeated-k-fold-cross-validation-with-python\/","269e1f0e":"# 7. Conclusion\n\nBy using pretrained models, I was able to improve my competition score from 21.15 to the scores listed below.\n\n1. EfficientNet pretrained model: 18.51\n2. SWIN Transform pretrained model: 18.15\n\nThrough this notebook I have learned that instead of spending hours to build my own model, using publicly available pretrained model is the way to go in CNN. Because each of the pretrained model come with very complicated state-of-art architecture of neural network and pretrained weights built inside them. \n\nThe trained model will be run with test result in this inference version : https:\/\/www.kaggle.com\/gohweizheng\/swin-transformer-inference?scriptVersionId=84293799","5e0b5f31":"**2.2 Parameters setting**\n\nBundling all the parameters that will be used in this notebook here for easy editing.","b9a0d1ca":"**5.4 Training function**\n\nThis function is used to input images into the model and generate prediction. Then, the difference between generated prediction values and target values will be calculated using loss function. Lastly, the gradient of the loss will be calculated and be used to optimize the parameters of the weights.\n","4189cfe4":"# 3. Image augmentation\n\nAugmentation is used to transform image data into the desired type or shape, normalize it and turn it into a tensor form. At the same time, augmentation can also be used to create multiple images out of the single image input by flipping, rotating or mixing up a few different images. Images will be transformed bit by bit using this function when they are iterated at the cross validation process. \n","dc48c5bf":"**4.1 K fold function**","1f5eaca5":"# 2. Data Loading\n\n**2.1 Data loading from CSV file**\n","5bcc0f50":"**5.5 Validation Function**\n\nThis function will be used to validate the trained model by using the unseen validation data set. The result will be used to determine whether the model is improving or not. \n\nValidation function is very important in the process of training a model because model tends to overfit by memorizing all the training data at the training phase. Overfitting will make the model seems to be able to generate very accurate result, but often failed to reproduce similar result when it's used on unseen data. Thus, it's very important to reserve part of the data and have a separate function to validate the model with unseen data in order to have a accurate evaluation of the model.","8e9f11f6":"# 1. Introduction\n\nIn my previous attempt, I have constructed a CNN model myself ([Link](https:\/\/www.kaggle.com\/gohweizheng\/petfinder-wz-first-cnn)) to solve this problem. But the result wasn't great. So, in this notebook I will try to get better result by using different pretrained models available on the internet.\n\nTested pretrained models: tf_efficientnet_b0_ns, swin_large_patch4_window12_384\n\nModel structure was refered from this tutorial: https:\/\/albumentations.ai\/docs\/examples\/pytorch_classification\/\nAnd this notebook : https:\/\/www.kaggle.com\/manabendrarout\/transformers-classifier-method-starter-train\n\nPlease give an upvote to this notebook.\n","1ee72d8d":"# Pretrained SWIN Transformer\n\n**Description:** Millions of stray animal suffer on the streets or euthanized in shelters every day around the world. A good picture of homeless animal might increase their chance of getting adopted. But what makes a good picture? Our mission is to build an ML model which is able to accurately determine a pet photo's appeal and even suggest improvements to give these rescue animals a higher chance of loving homes.\n\nThis competition is organized by PetFinder.my. They are Malaysia's leading animal welfare platform, featuring 180,000 animals with 54,000 happily adopted. Good and accurate model might have a change to be adapted into AI tools that will guide shelters and rescuers around the world to improve the photo quality of their sheltered pet. \n\n**Data:** 9912 images of pet animals labeled with \"Pawpularity\" score from 1 to 100. Photo Metadata = (Focus, Eyes, Face, Near, Action, Accessory, Group, Collage, Human, Occlusion, Info, Blur)\n\n![](https:\/\/pbs.twimg.com\/media\/CvhLlXxXgAA5TDJ.jpg)\n","7b207c96":"**5.3 Pretrained Model**\n\nIn this section, model class will be built by downloading pretrained model from the internet. This technique is known as Transfer Learning.\n\nBy using pretrained model, the state-of-art architecture of convolutional neural network that was built by world top data scientist can be utilized in this ML solution. For example ResNet, VGG 16, EfficientNet and etc. At the same time, pretrained weights of each layers that were trained by the developer can also be imported by setting the pretrained = True. \n\nIn this notebook, SWIN Transform was chosen as the pretrained model. Only the final fully-connected layer will be edited to return one output which is the Pawpularity score of each animal image. The CNN architecture of the model will be printed out in the next column.","95b2e507":"**End notes**\n\nBoth EfficientNet and SWIN Transform model took very long time to train them. EfficientNet took me 10 GPU hours and SWIN transform model took me 20 GPU hours to finish training all the Folds. EfficientNet was quick to train but require many epoches to reach the global optimum, thus Early Stopping function was necessary to get best model. On other hand, SWIN Transform took very long time to train as the architecture of the model is very complicated compared to EfficientNet, but it was able to reach global optimum much quicker compared to EfficientNet. It may be faster to train by using 4 epoches to train instead of using Early Stopping.","91fb68f2":"**5.1 Metrics function**\n\nMetrics function is used to monitor the performance of the model so that the model's performance can be visualized after each epoch. Metrics function is different from loss function where metrics function will not be used in model training process.  ","fbd53940":"**2.2 Data Processing**\n\nIn this section, I will build a pipeline to process data by bundling all the functions and data processing code in a class using object oriented programming(OOP). Class is like a container where we can store all the data and functions that we need inside it to make our code tidier. Moreover, it has a very convenient function that allows inheritance of all the functions and data inside it at other further processes. ","30f85a32":"**5.2 Scheduler function**\n\nScheduler function is used to change the learning rate of optimizer automatically after each epoch. So that there are more flexibility when learning rate of optimizer are setted up initially. \n\nSetting a learning rate that is too small will take forever for the model to train while setting a learning rate that is too big might prevent the model to ever reach the minimal optimum point. Thus having a scheduler function allows me to set bigger learning rate at early stage and automatically lower the learning rate as the model training is iterated.\n\nIn this notebook I used CosineAnnealingWarmRestarts for my scheduler function. But there are many other kind of scheduler functions that can be used, you can find them in this website: https:\/\/pytorch.org\/docs\/stable\/optim.html.","60ccac0e":"# 5. Model Building\n\nMany different fuctions that are needed to train the model will be written in this session.","41402f7d":"**4.2 Splitting the data into K fold**\n\nUsing the K fold functions above, data are splited into 5 and 10 folds. I will only use the 10 folds data in the further process.\n","53badec2":"# 6. Run function\n"}}