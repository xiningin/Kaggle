{"cell_type":{"edb7367d":"code","dddd6933":"code","fc0a22e8":"code","a4085ef4":"code","3612656a":"code","e55f8213":"code","e3ef55bb":"code","ea825606":"code","abc01254":"code","0bdcebc2":"code","3cb13705":"code","103cecc9":"code","e4e23934":"code","e83a2c88":"code","c38f584f":"code","4627f915":"code","97e3e8dd":"code","d19c6a11":"code","c051e34f":"code","b3e98797":"code","ddcbf5bc":"code","77ae9443":"code","1d4051a8":"code","e848697a":"code","b4e03f46":"code","f32cfb21":"code","70e8ac5f":"code","98c6c670":"code","404e4602":"code","66b1f473":"code","bd6d85e4":"code","47cb32eb":"code","9cb7bcf6":"code","c216641a":"code","de3d3b0c":"code","e8522507":"code","6bb2f1fd":"code","729bbbde":"code","3c79dfc0":"code","5ff0194a":"code","d931e9f8":"code","dd3c89bd":"code","18a557b3":"code","5db12bcf":"markdown","a0e1739c":"markdown","45583040":"markdown","a644be9b":"markdown","d635ea81":"markdown","9a3cbf50":"markdown","0722b36f":"markdown","1c16fb0d":"markdown","da0d7b02":"markdown","2dc5812c":"markdown","e942388e":"markdown","06a95bc2":"markdown","214c740d":"markdown","b4a10cfd":"markdown","5dc2fc9e":"markdown","28afdb44":"markdown","d7ad3ba9":"markdown","01774759":"markdown","089dfd0c":"markdown"},"source":{"edb7367d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dddd6933":"# importing required librery\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\npd.pandas.set_option('display.max_columns',None)","fc0a22e8":"data = pd.read_csv(\"\/kaggle\/input\/summeranalytics2020\/train.csv\")\ndata2 = pd.read_csv(\"\/kaggle\/input\/summeranalytics2020\/test.csv\")\ndata_y = data.Attrition\ndata.head()","a4085ef4":"data.shape","3612656a":"data2.shape","e55f8213":"data.info()","e3ef55bb":"data2.info()","ea825606":"data.describe()","abc01254":"import pandas_profiling\ndata.profile_report()","0bdcebc2":"data = data.drop(['Id','Attrition','EmployeeNumber','Behaviour'],axis=1)\ndata2 = data2.drop(['Id','EmployeeNumber','Behaviour'],axis=1)","3cb13705":"catagory_col = [col for col in data.columns if data[col].dtype=='object']\ncatagory_col","103cecc9":"for column in data[catagory_col]:\n    print(str(column) + str(' : ') + str(data[column].unique()))\n    print(data[column].value_counts())\n    print('____________________________________________________')\n    print('')","e4e23934":"# import librery for lable encoding\n\nfrom sklearn.preprocessing import LabelEncoder\n\nl_encoder = LabelEncoder()\n\nfor column in catagory_col:\n    data[column+'_n'] = l_encoder.fit_transform(data[column])\n    data2[column+'_n'] = l_encoder.fit_transform(data2[column])\n    data = data.drop([column],axis=1)\n    data2 = data2.drop([column],axis=1)","e83a2c88":"\"\"\"\n\ntemp = pd.get_dummies(data[catagory_col])\ndata = pd.concat([data,temp],axis=1)\ndata = data.drop(catagory_col,axis=1)\n\ntemp2 = pd.get_dummies(data2[catagory_col])\ndata2 = pd.concat([data2,temp2],axis=1)\ndata2 = data2.drop(catagory_col,axis=1)","c38f584f":"data.head()","4627f915":"data.shape","97e3e8dd":"# make set ofcolumn required standerdizing\n\n","d19c6a11":"# runonly if we want to modeling on nontree based model\n\n\"\"\" \n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\ndata_arr = scaler.fit_transform(data)\ndata2_arr = scaler.fit_transform(data2)\n\ndata = pd.DataFrame(data_arr,columns = data.columns)\ndata2 = pd.DataFrame(data2_arr,columns = data2.columns)","c051e34f":"data.head()","b3e98797":"data.shape","ddcbf5bc":"plt.subplots(figsize=(10,4))\nsns.boxplot(x=data.MonthlyIncome)\nplt.figure()\nplt.subplots(figsize=(10,4))\nsns.boxplot(x=data2.MonthlyIncome)","77ae9443":"sns.distplot(data.Age,bins=100)\nsns.distplot(data2.Age,bins=100)","1d4051a8":"sns.distplot(data.MonthlyIncome,bins=100)\nsns.distplot(data2.MonthlyIncome,bins=100)","e848697a":"sns.distplot(data.NumCompaniesWorked,bins=50)\nsns.distplot(data2.NumCompaniesWorked,bins=50)","b4e03f46":"from sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\nfeature = ExtraTreesClassifier()\nfeature.fit(data,data_y)\n\nscore = feature.feature_importances_\nscore","f32cfb21":"feat_score = pd.Series(score, index=data.columns).sort_values(ascending = False)\n\nplt.figure(figsize=(10,20))\nfeat_score.plot(kind='barh')\nplt.show()","70e8ac5f":"top_feature = list(feat_score.index[0:29])\ntop_feature","98c6c670":"feat_score","404e4602":"data_imp = data[top_feature]\ndata2_imp = data2[top_feature]\n\nprint(data_imp.shape)\nprint(data2_imp.shape)","66b1f473":"top_corr_feat = []\nfor i in data.columns:\n    if(abs(data_y.corr(data[i]))>=0.01):\n        top_corr_feat.append(i)\n        \nprint(top_corr_feat)","bd6d85e4":"data_imp = data[top_corr_feat]\ndata2_imp = data2[top_corr_feat]\n\nprint(data_imp.shape)\nprint(data2_imp.shape)","47cb32eb":"# train test split\n\nfrom sklearn.model_selection import train_test_split as tts\n\nx_train,x_test,y_train,y_test = tts(data_imp,data_y,test_size=0.3,random_state=4)","9cb7bcf6":"x_train.shape","c216641a":"x_test.shape","de3d3b0c":"from sklearn.ensemble import RandomForestClassifier as RFS","e8522507":"model = RFS(random_state=24,n_estimators=250,max_depth=20)\n\n#model.fit(x_train,y_train)\n\nmodel.fit(data_imp,data_y)","6bb2f1fd":"y_predict_1 = model.predict(x_test)\ny_predict_2 = model.predict(data_imp)","729bbbde":"from sklearn.metrics import roc_auc_score\n\nroc_auc_score(y_test,y_predict_1)","3c79dfc0":"roc_auc_score(data_y,y_predict_2)","5ff0194a":"y_prob = model.predict_proba(data2_imp)\ny_prob = list(y_prob[:,1])\ndata2_predict = model.predict(data2_imp)\ndata2_predict","d931e9f8":"Id = np.arange(1,len(y_prob)+1)\n\nId = list(Id)","dd3c89bd":"ans = pd.DataFrame(list(zip(Id,y_prob)),columns=['Id','Attrition'])\nans","18a557b3":"ans.to_csv('answer4.csv',index=False)","5db12bcf":"#    \n\n\n\n\n\n## test-train split","a0e1739c":"#   \n\n\n\n\n\n## outlier detection","45583040":"#   \n\n\n\n\n\n## Data Preprocessing\n\n","a644be9b":"#   \n\n\n\n\n\n## Encoding of Column with Objective Datatype","d635ea81":"### now we drop column which is not important","9a3cbf50":"#  \n\n\n\n\n\n## standerdizing data","0722b36f":"both train and test shows same distribution","1c16fb0d":"#   \n\n\n\n\n\n\n## Select Important Features","da0d7b02":"### importing data","2dc5812c":"#   \n\n\n\n\n\n## One-hot Encoding","e942388e":"we find corelation tequnique are more accurate","06a95bc2":"# ---------------------------------------------------","214c740d":"### 2) using correlation between feature","b4a10cfd":"# Summer Analytics 2020 Capstone Project\n## Predicting Employee Attrition in the Dawn of Recession\n\n        \n       As the COVID-19 keeps unleashing its havoc, the world continues to get pushed into the crisis of the great economic recession, more and more companies start to cut down their underperforming employees. Companies firing hundreds and thousands of Employees is a typical headline today. Cutting down employees or reducing an employee salary is a tough decision to take. It needs to be taken with utmost care as imprecision in the identification of employees whose performance is attriting may lead to sabotaging of both employees' career and the company's reputation in the market.\n\n### Aim of The Competition\n    To predict Employee Attrition by the given data about his\/her past history.","5dc2fc9e":"### Created By :- Faldu jay\n#### Email :- jay.faldu928@gmail.com","28afdb44":"#  \n\n\n\n\n\n## Random Forest Classification","d7ad3ba9":"### we perform feature selection by two method\n#### 1) using extraa tree classifier\n#### 2) by observing coreelation between features","01774759":"### 1) using extra tree classifier","089dfd0c":"# pandas profilling"}}