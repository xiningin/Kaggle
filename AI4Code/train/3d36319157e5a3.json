{"cell_type":{"6bb27ae8":"code","44dbe6fb":"code","578e0b5f":"code","ec531d9a":"code","ed23e7ae":"code","1cb9b877":"code","93c1f1bb":"code","907fd6d4":"code","b52e4ec6":"code","7c0f4174":"code","d7c38fd7":"code","6da9f342":"code","e09fa476":"code","9d030942":"code","5ae1f580":"code","a26321a2":"code","c95ff357":"code","dafa54f8":"code","f82a3726":"code","e675dc8e":"code","0dced156":"code","e57d86ce":"code","98846bc1":"code","ebe448ec":"markdown","bd237716":"markdown","7fef7f2a":"markdown","39bb36ab":"markdown","dd8d6ad1":"markdown","fd46c3ef":"markdown","bb127a59":"markdown","e0203be9":"markdown","8352dff9":"markdown","d31d54a3":"markdown","d0beac79":"markdown","bfee9646":"markdown","b3601fc7":"markdown","a7152e0d":"markdown","bf139921":"markdown","c8e1e3bc":"markdown","5ae8fc4d":"markdown"},"source":{"6bb27ae8":"import os\nimport sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nfrom glob import glob\n\nimport pickle\nimport functools\nimport itertools\nimport random\n\nimport json\nimport numpy as np\nimport pandas as pd\nimport random\nimport math\n\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold\nfrom skimage.draw import line_aa\nfrom tqdm import tqdm\n\nimport timm\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms","44dbe6fb":"train_df = pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')\ntrain_df['filepath'] = train_df.id.apply(lambda x: f'..\/input\/seti-breakthrough-listen\/train\/{x[0]}\/{x}.npy')\ntrain_df_0 = train_df[train_df.target==0].copy().reset_index(drop=True)\ntrain_df_1 = train_df[train_df.target==1].copy().reset_index(drop=True)","578e0b5f":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device('cpu')\n    print(\"GPU not available, CPU used\")","ec531d9a":"class setiDataset(Dataset):\n    def __init__(self, df_0, df_1, transform = None): \n        self.df_0 = df_0\n        self.df_1 = df_1\n        self.transform = transform\n    \n    def fileinfo(self, idx):\n        return self.df_0.filepath.iloc[idx], self.df_1.filepath.iloc[idx]\n    \n    def loadfile(self, filepath):\n        image = np.load(filepath)\n        image = np.vstack([image[0],image[2],image[4]]).astype('float32')\n        image = cv2.resize(image, dsize=(260, 320), interpolation=cv2.INTER_AREA).transpose(1,0)\n        image = np.stack([image,image,image])\n        return image\n    \n    \n    def __getitem__(self, idx):\n        filepath_0, filepath_1 = self.fileinfo(idx)\n        image_0 = self.loadfile(filepath_0)\n        image_1 = self.loadfile(filepath_1)\n        \n        if self.transform:\n            image_0 = image_0.transpose(1,2,0)\n            augmented = self.transform(image=image_0)\n            image_0 = augmented['image']\n            \n            image_1 = image_1.transpose(1,2,0)\n            augmented = self.transform(image=image_1)\n            image_1 = augmented['image']\n            return image_0, image_1, torch.tensor(0, dtype=torch.long), torch.tensor(1, dtype=torch.long)\n\n        return  torch.tensor(image_0, dtype=torch.float), torch.tensor(image_1, dtype=torch.float), torch.tensor(0, dtype=torch.long), torch.tensor(1, dtype=torch.long)\n    \n    def __len__(self):\n        return len(self.df_1)","ed23e7ae":"train_transform = A.Compose([\n    A.GridDistortion(p=0.75),\n    A.OneOf([\n        A.VerticalFlip(p=1),\n        A.HorizontalFlip(p=1)\n    ], p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.15, scale_limit=0.05, rotate_limit=0, p=0.75),\n    A.pytorch.ToTensor()\n])","1cb9b877":"# for visualization, not training.\nSD = setiDataset(train_df_0, train_df_1)\nSD_aug = setiDataset(train_df_0, train_df_1, transform = train_transform)","93c1f1bb":"for i in range(2):\n    a = np.random.randint(low=0, high= len(SD))\n    b = np.random.randint(low=0, high= len(SD))\n    image1, _, _, _ = SD[a]\n    image2, _, _, _ = SD_aug[a]\n    plt.figure(figsize=(20,10))\n    plt.subplot(2,2,1)\n    plt.title('Target 0 Image, Original', fontsize=12)\n    plt.imshow(image1[0],aspect='auto')\n    plt.subplot(2,2,2)\n    plt.title('Target 0 Image, Augmented', fontsize=12)\n    plt.imshow(image2[0],aspect='auto')\n    plt.show()\nprint(f'target0. {image1.shape}')\n\nfor i in range(2):\n    a = np.random.randint(low=0, high= len(SD))\n    b = np.random.randint(low=0, high= len(SD))\n    _, image1, _, _ = SD[a]\n    _, image2, _, _ = SD_aug[a]\n    _, image3, _, _ = SD_aug[b]\n    plt.figure(figsize=(20,10))\n    plt.subplot(2,2,1)\n    plt.title('Target 1 Image, Original', fontsize=12)\n    plt.imshow(image1[0],aspect='auto')\n    plt.subplot(2,2,2)\n    plt.title('Target 1 Image, Augmented', fontsize=12)\n    plt.imshow(image2[0],aspect='auto')\n    plt.show()\nprint(f'targe01. {image1.shape}')","907fd6d4":"class cspdarknet_baseline(nn.Module):\n    def __init__(self,model_name = 'cspdarknet53', pretrained = False):\n        super(cspdarknet_baseline,self).__init__()\n        print(f'Model: {model_name}')\n        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n        self.myfc_1 = nn.Linear(1000,1)\n\n    def forward(self, x):\n        x = self.backbone(x)\n        x = self.myfc_1(x)\n        return x","b52e4ec6":"model = cspdarknet_baseline()\nmodel.load_state_dict(torch.load('..\/input\/epoch5\/epoch5.pt'))","7c0f4174":"def sigmoid(x):\n    return 1\/(1+np.exp(-x))","d7c38fd7":"image_0, image_1, target0, target1 = SD[1]\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,1)\nplt.imshow(image_0[0], aspect='auto')\nimage_0 = torch.unsqueeze(image_0, dim=0)\ntarget0 = int(target0.item())\noutput = model(image_0).item()\noutput = sigmoid(output)\nplt.title(f'Target {target0}, Model value: {round(output,4)}', fontsize=12)\n\nplt.subplot(2,2,2)\nplt.imshow(image_1[0], aspect='auto')\nimage_1 = torch.unsqueeze(image_1, dim=0)\ntarget1 = int(target1.item())\noutput = model(image_1).item()\noutput = sigmoid(output)\nplt.title(f'Target {target1}, Model value: {round(output,4)}', fontsize=12)\nplt.show()\nprint(image_1.shape)","6da9f342":"class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.main = nn.Sequential(\n            # Initial convolution block\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(3, 64, 7),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(inplace=True),\n\n            # Downsampling\n            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n            nn.InstanceNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n            nn.InstanceNorm2d(256),\n            nn.ReLU(inplace=True),\n\n            # Residual blocks\n            ResidualBlock(256),\n            ResidualBlock(256),\n            ResidualBlock(256),\n            ResidualBlock(256),\n            ResidualBlock(256),\n            ResidualBlock(256),\n\n            # Upsampling\n            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n            nn.InstanceNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(inplace=True),\n\n            # Output layer\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(64, 3, 7),\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        return self.main(x)\n\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels):\n        super(ResidualBlock, self).__init__()\n\n        self.res = nn.Sequential(nn.ReflectionPad2d(1),\n                                 nn.Conv2d(in_channels, in_channels, 3),\n                                 nn.InstanceNorm2d(in_channels),\n                                 nn.ReLU(inplace=True),\n                                 nn.ReflectionPad2d(1),\n                                 nn.Conv2d(in_channels, in_channels, 3),\n                                 nn.InstanceNorm2d(in_channels))\n\n    def forward(self, x):\n        return x + self.res(x)","e09fa476":"def weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find(\"Conv\") != -1:\n        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n    elif classname.find(\"BatchNorm\") != -1:\n        torch.nn.init.normal_(m.weight, 1.0, 0.02)\n        torch.nn.init.zeros_(m.bias)","9d030942":"Gen_0_t1 = Generator()\nGen_1_t0 = Generator()\nGen_0_t1.apply(weights_init)\nGen_1_t0.apply(weights_init)\nprint('Generator model is created')","5ae1f580":"fake_image_1 = Gen_0_t1(image_1)\nfake_image_1 = fake_image_1.detach().numpy().reshape(3,260,320)\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,1)\nplt.imshow(image_1.reshape(3,260,320)[0], aspect='auto')\nplt.subplot(2,2,2)\nplt.imshow(fake_image_1[0], aspect='auto')\nplt.show()","a26321a2":"def trainGenerator(data_loader, model, Gen_0_t1, Gen_1_t0, optimizer_G, device):\n    model.eval()\n    Gen_0_t1.train()\n    Gen_1_t0.train()\n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        image_0, image_1, target_0, target_1 = data\n        \n        image_0 = image_0.to(device, dtype=torch.float)\n        target_0 = target_0.to(device, dtype=torch.float)\n        image_1 = image_1.to(device, dtype=torch.float)\n        target_1 = target_1.to(device, dtype=torch.float)\n        \n        \n        optimizer_G.zero_grad()\n        \n        # Automorphism (Identity) loss\n        auto_image_1 = Gen_0_t1(image_1)\n        loss_identity_1 = nn.L1Loss()(auto_image_1, image_1) * 5.0\n        \n        \n        auto_image_0 = Gen_1_t0(image_0)\n        loss_identity_0 = nn.L1Loss()(auto_image_0, image_0) * 5.0\n        \n\n        # Generating loss\n        fake_image_1 = Gen_0_t1(image_0)\n        model_expect_fake_1 = model(fake_image_1)\n        model_expect_fake_1 = nn.Sigmoid()(model_expect_fake_1)\n        loss_GAN_0_t1 = nn.MSELoss()(model_expect_fake_1, target_1.view(-1,1))\n        \n        \n        fake_image_0 = Gen_1_t0(image_1)\n        model_expect_fake_0 = model(fake_image_0)\n        model_expect_fake_0 = nn.Sigmoid()(model_expect_fake_0)\n        loss_GAN_1_t0 = nn.MSELoss()(model_expect_fake_0, target_0.view(-1,1))\n        \n        \n        \n        # Cycle loss\n        recovered_image_0 = Gen_1_t0(fake_image_1)\n        loss_cycle_010 = nn.L1Loss()(recovered_image_0, image_0) * 10.0\n        \n\n        recovered_image_1 = Gen_1_t0(fake_image_0)\n        loss_cycle_101 = nn.L1Loss()(recovered_image_1, image_1) * 10.0\n\n\n        total_errG = loss_identity_1 + loss_identity_0 + loss_GAN_0_t1 + loss_GAN_1_t0 + loss_cycle_010 + loss_cycle_101\n        total_errG.backward()\n        \n        optimizer_G.step()","c95ff357":"def trainModel(data_loader, model, optimizer, device):\n    model.train()\n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        image_0, image_1, target_0, target_1 = data\n        \n        images = torch.cat([image_0, image_1], dim = 0)\n        targets = torch.cat([target_0, target_1])\n        images = images.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n    \n        # normal loss\n        output = model(images)\n        loss = nn.BCEWithLogitsLoss()(output, targets.view(-1,1))\n        \n        loss.backward()\n        optimizer.step()\n        \ndef trainModel2(data_loader, model, Gen_0_t1, Gen_1_t0, optimizer, device):\n    Gen_0_t1.eval()\n    Gen_1_t0.eval()\n    model.train()\n    \n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        image_0, image_1, target_0, target_1 = data\n        \n        image_1 = image_1.to(device, dtype=torch.float)\n        target_1 = target_1.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n    \n        # Generating loss\n        fake_image_0 = Gen_1_t0(image_1)\n        model_expect_fake_0 = model(fake_image_0)\n        model_expect_fake_0 = nn.Sigmoid()(model_expect_fake_0)\n        loss_model_0 = nn.MSELoss()(model_expect_fake_0,  target_1.view(-1,1)) * 0.5\n        \n        image_0 = image_0.to(device, dtype=torch.float)\n        target_0 = target_0.to(device, dtype=torch.float)\n        fake_image_1 = Gen_0_t1(image_0)\n        model_expect_fake_1 = model(fake_image_1)\n        model_expect_fake_1 = nn.Sigmoid()(model_expect_fake_1)\n        loss_model_1 = nn.MSELoss()(model_expect_fake_1,  target_0.view(-1,1)) * 0.5\n        \n        loss = loss_model_0 + loss_model_1\n        loss.backward()\n        optimizer.step()       ","dafa54f8":"def evaluate(data_loader, model, device):\n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    validate_losses = 0\n    cnt = 0\n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            cnt += 1\n            image_0, image_1, target_0, target_1 = data\n\n            images = torch.cat([image_0, image_1], dim = 0)\n            targets = torch.cat([target_0, target_1])\n            \n            images = images.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            \n            output = model(images)\n            loss = nn.BCEWithLogitsLoss()(output, targets.view(-1, 1))\n            validate_losses += loss.item()\n\n\n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n    return final_outputs, final_targets, validate_losses\/cnt","f82a3726":"import gc\ntry:\n    obj = None\n    gc.collect()\n    torch.cuda.empty_cache()\n    del model\n    del SD_aug\n    del SD\n    del Gen_0_t1\n    del Gen_1_t0\nexcept:\n    pass","e675dc8e":"Batch_Size = 4\n\n#cspdarknet53\nmodel = cspdarknet_baseline(pretrained=True)\nmodel.to(device)\noptimizer1 = torch.optim.Adam(model.parameters(), lr=3e-4, eps=1e-5)\noptimizer2 = torch.optim.RMSprop(model.parameters(), lr=5e-6, eps=1e-5)\n\n#Image generator 0 to 1 and 1 to 0.\nGen_0_t1 = Generator()\nGen_1_t0 = Generator()\nGen_0_t1.apply(weights_init)\nGen_1_t0.apply(weights_init)\n\nGen_0_t1.to(device)\nGen_1_t0.to(device)\noptimizer_G = torch.optim.Adam(itertools.chain(Gen_0_t1.parameters(), Gen_1_t0.parameters()),\n                               lr=2e-4, betas=(0.5, 0.999))\n\n\ntrain_df_1 = train_df[train_df.target==1].reset_index(drop=True)\ntrain_df_0 = train_df[train_df.target==0].sample(len(train_df_1)).reset_index(drop=True)\n\n\nskf = StratifiedKFold(n_splits=5)\nX = train_df_1.filepath.values\nY = train_df_0.target.values\n\nfor train_index, test_index in skf.split(X, Y):\n    \n    tra1_df = train_df_1.loc[train_index]\n    tra0_df = train_df_0.loc[train_index]\n    val1_df = train_df_1.loc[test_index]\n    val0_df = train_df_0.loc[test_index]\n    \n    train_dataset = setiDataset(tra0_df, tra1_df, transform = train_transform)\n    train_loader= torch.utils.data.DataLoader(train_dataset, batch_size=Batch_Size, shuffle=False)\n    valid_dataset = setiDataset(val0_df, val1_df)\n    valid_loader= torch.utils.data.DataLoader(valid_dataset, batch_size=Batch_Size, shuffle=False)\n    \n    trainModel(train_loader, model, optimizer1, device)\n    predictions, valid_targets, valid_loss = evaluate(valid_loader, model, device=device)\n    roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n    print(f\"Part1: Valid Loss={valid_loss}, Valid ROC AUC={roc_auc}\")\n    \n    trainGenerator(train_loader,model, Gen_0_t1, Gen_1_t0, optimizer_G, device)\n    trainModel2(train_loader, model, Gen_0_t1, Gen_1_t0, optimizer2, device)\n\n    predictions, valid_targets, valid_loss = evaluate(valid_loader, model, device=device)\n    roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n    print(f\"Part2: Valid Loss={valid_loss}, Valid ROC AUC={roc_auc}\")","0dced156":"torch.save(model.state_dict(),'model.pt')\ntorch.save(Gen_0_t1.state_dict(),'Gen_0_t1.pt')\ntorch.save(Gen_1_t0.state_dict(),'Gen_1_t0.pt')  ","e57d86ce":"SD = setiDataset(train_df_0, train_df_1)\nimage0, image1, t0, t1 = SD[1]\n\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,1)\nplt.imshow(image0[0], aspect='auto')\nimage0 = torch.unsqueeze(image0, dim=0)\nimage0 = image0.to('cuda')\noutput = model(image0).item()\noutput = sigmoid(output)\nplt.title(f'Target {0}, Model value: {round(output,4)}', fontsize=12)\n\nplt.subplot(2,2,2)\nGen_0_t1.eval()\nfake_image_1 = Gen_0_t1(image0)\noutput2 = model(fake_image_1).item()\noutput2 = sigmoid(output2)\nfake_image_1 = fake_image_1.detach().cpu().numpy()\nfake_image_1 = fake_image_1.reshape(3,260,320)\nplt.imshow(fake_image_1[0], aspect='auto')\nplt.title(f'Target {0} to Fake 1, Model value: {round(output2,4)}', fontsize=12)\nplt.show()","98846bc1":"SD = setiDataset(train_df_0, train_df_1)\nimage0, image1, t0, t1 = SD[2]\n\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,1)\nplt.imshow(image0[0], aspect='auto')\nimage0 = torch.unsqueeze(image0, dim=0)\nimage0 = image0.to('cuda')\noutput = model(image0).item()\noutput = sigmoid(output)\nplt.title(f'Target {0}, Model value: {round(output,4)}', fontsize=12)\n\nplt.subplot(2,2,2)\nGen_0_t1.eval()\nfake_image_1 = Gen_0_t1(image0)\noutput2 = model(fake_image_1).item()\noutput2 = sigmoid(output2)\nfake_image_1 = fake_image_1.detach().cpu().numpy()\nfake_image_1 = fake_image_1.reshape(3,260,320)\nplt.imshow(fake_image_1[0], aspect='auto')\nplt.title(f'Target {0} to Fake 1, Model value: {round(output2,4)}', fontsize=12)\nplt.show()","ebe448ec":"Finally, I visualization training results for one data.","bd237716":"The generator has multiple residual block and convolution kernel.","7fef7f2a":"The following two training codes for the generator and the model, respectively.","39bb36ab":"The blow fake image generator model is from\n\nhttps:\/\/github.com\/Lornatang\/CycleGAN-PyTorch\n> @inproceedings{CycleGAN2017,\n>   title={Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networkss},\n>   author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},\n>   booktitle={Computer Vision (ICCV), 2017 IEEE International Conference on},\n>   year={2017}\n> }","dd8d6ad1":"I use validation set dependently with a traning set.<br>\nSo the performance has a strict upper bound of the score after 2 epoch.\n\nI will fix this problem in near future.","fd46c3ef":"It is not working well now. AUC value oscilate in low value and not converge.\n\nBut it is a prototype. My aim in this project is to update this code.","bb127a59":"# I propose a baseline of \n# CycleGAN + cspdarknet53 for image classification.\n\n\nI use following materials.\n* Cyclegan's code: https:\/\/github.com\/Lornatang\/CycleGAN-PyTorch (unofficial code) and\n> @inproceedings{CycleGAN2017,\n>   title={Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networkss},\n>   author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},\n>   booktitle={Computer Vision (ICCV), 2017 IEEE International Conference on},\n>   year={2017}\n> }\n* Tensorflow tutorial: https:\/\/www.tensorflow.org\/tutorials\/generative\/cyclegan?hl=ko.\n\n* timm pytorch image model with several kaggle notebook.","e0203be9":"![img](https:\/\/www.tensorflow.org\/tutorials\/generative\/images\/horse2zebra_1.png\/)","8352dff9":"The shape of the input and output is the same. <br>\nSomething is destroyed now but the generator may trained during trainig step.","d31d54a3":"At first time, I hope CycleGan do something like this.","d0beac79":"The above code is for augmentation image.<br>\nI apply agumentation on image using albumentations libarary.","bfee9646":"The above value in pictures are the prediction of baseline model. <br>\nThe baseline model initially does not work well predict.","b3601fc7":"Images for training change slightly by using augmentation.\n\nAs a baseline, I use a cspdarknet53. <br>\nThe baseline model will check if the image is a needle or not.","a7152e0d":"The below is an image converted using a initial generator.","bf139921":"???????","c8e1e3bc":"I believe the loss from cyclegan act as a Regulrization of base model's decision boundary.\n\n\nSince the code is not optimized, so the memory keeps fulled.\n\nI use batch size 4...","5ae8fc4d":"Something... hmm"}}