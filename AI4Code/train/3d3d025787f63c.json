{"cell_type":{"0af7cebb":"code","d9e1132a":"code","dfef54d8":"code","d991ff09":"code","eaca7cd5":"code","7531c65d":"code","4abbeba2":"code","2c19794e":"code","df605240":"code","700559ed":"code","24c63c64":"code","7094c751":"code","2ccf65bb":"code","4f32d15e":"code","676c8277":"code","6764c7c6":"code","b0a3ca1f":"code","5049c4f2":"code","6de86413":"code","6cad4aa8":"code","4dbef06c":"code","9d2c1c39":"code","9bd853f5":"code","2d0399bf":"code","d9679398":"code","b79de27d":"code","e84bfd42":"code","2abdb3db":"code","f9038335":"code","46ec738c":"code","6a9c83a5":"code","c43e0c2f":"code","45438a2a":"markdown","442a8063":"markdown"},"source":{"0af7cebb":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nsns.set(style='white', palette='deep')\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\ndef autolabel_without_pct(rects,ax): #autolabel\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy = (rect.get_x() + rect.get_width()\/2, height),\n                    xytext= (0,3),\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom', fontsize=10)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d9e1132a":"#Importing dataset\ndf = pd.read_csv('\/kaggle\/input\/beer-consumption-sao-paulo\/Consumo_cerveja.csv')\ndf.head()","dfef54d8":"#Analysing dataset with tradicinal way\n#Statistical\nstatistical = df.describe()\nstatistical","d991ff09":"#Using info\ndf.info()","eaca7cd5":"#Looking for null values\nnull_values = (df.isnull().sum()\/len(df))*100\nnull_values = pd.DataFrame(null_values,columns=['% of Null Values'])\nnull_values","7531c65d":"df_feature = df.copy()\ndf_feature = df_feature.dropna()","4abbeba2":"df_feature.columns","2c19794e":"#Tranforming string in float columns\ndf_feature.columns\nfor i in df_feature[['Temperatura Media (C)', 'Temperatura Minima (C)',\n       'Temperatura Maxima (C)', 'Precipitacao (mm)']]:\n    df_feature[i] = df_feature[i].str.replace(',','.')\n\nfor i in df_feature[['Temperatura Media (C)', 'Temperatura Minima (C)',\n       'Temperatura Maxima (C)', 'Precipitacao (mm)']]:\n    df_feature[i] = df_feature[i].astype(np.float64)","df605240":"#Creating 'Dia da Semana' column\nimport calendar\n\ndf_feature['Data'] = df_feature['Data'].apply(pd.to_datetime)\ndf_feature['Dia da Semana'] = df_feature['Data'].apply(lambda x: x.weekday())\n\ndias = {}\nfor i,v in enumerate(list(calendar.day_name)):\n    dias[i]=v\n    \ndias_nomes = np.array([])\nfor i in df_feature['Dia da Semana']:\n    for j in range(0,len(dias)):\n        if i == list(dias.keys())[j]:\n            dias_nomes = np.append(dias_nomes,dias[j])\n\ndf_feature['Dia da Semana'] = dias_nomes \n","700559ed":"df.columns","24c63c64":"#Which day of the week is consumed more alcohol?\npivot_table_day = df_feature.pivot_table('Consumo de cerveja (litros)','Dia da Semana').sort_values(by='Consumo de cerveja (litros)',\n                                          ascending=False)\n\npivot_table_day.index[0]\npivot_table_day.values[1][0]\nind = np.arange(len(pivot_table_day.index))\nfig = plt.figure(figsize=(10,10))\nax = fig.add_subplot(1,1,1)\nfor i in np.arange(len(ind)):\n    rects = ax.bar(pivot_table_day.index[i],np.around(pivot_table_day.values[i][0],2), edgecolor='b')\n    autolabel_without_pct(rects,ax)\nax.set_title('Consumption per day of week')\nax.set_xlabel('Day of week')\nax.set_xticks(ind)\nax.set_ylabel('Consumption')\nax.grid(b=True, which='major', linestyle='--')\nplt.tight_layout()","7094c751":"df.columns","2ccf65bb":"#Which range of temperature is consumed more alcohol?\ndf_feature.columns\nbins = np.arange(12,35,5)\nbins_temp = bins.astype(str)\nlabels = []\ncount1=0\ncount2=1\nwhile count2 != len(bins_temp):\n    labels.append('['+bins_temp[count1]+' - '+bins_temp[count2]+']')\n    count1+=1\n    count2+=1\n\nind = np.arange(len(labels))\n\ntemp = pd.cut(df_feature['Temperatura Media (C)'], bins)\n\npivot_table_temp = df_feature.pivot_table('Consumo de cerveja (litros)',temp)\n\nfig = plt.figure(figsize=(10,10))\nax = fig.add_subplot(1,1,1)\npivot_table_temp.plot(ax=ax, marker='o', markeredgecolor='b')\nax.set_xticks(ind)\nax.set_xticklabels(labels)\nax.set_ylabel('Consumption')\nax.set_title('Consumption per range of temperature')\nax.grid(b=True, which='major', linestyle='-')\nplt.tight_layout()","4f32d15e":"#Define X and y\ndf_feature.columns\nX = df_feature.drop(['Consumo de cerveja (litros)', 'Data'], axis=1)\ny = df_feature['Consumo de cerveja (litros)']","676c8277":"#Get Dummies\nX = pd.get_dummies(X)","6764c7c6":"#Avoiding Dummies Trap\nX.columns\nX = X.drop(['Dia da Semana_Monday'], axis= 1)","b0a3ca1f":"#Splitting the Dataset into the training set and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nX_train.shape,X_test.shape,y_train.shape,y_test.shape","5049c4f2":"#Feature scaling\nfrom sklearn.preprocessing import StandardScaler\nsc_x = StandardScaler()\nX_train = pd.DataFrame(sc_x.fit_transform(X_train), columns=X.columns.values)\nX_test = pd.DataFrame(sc_x.transform(X_test), columns=X.columns.values)","6de86413":"## Multiple Linear Regression Regression\nfrom sklearn.linear_model import LinearRegression\nlr_regressor = LinearRegression()\nlr_regressor.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = lr_regressor.predict(X_test)\nfrom sklearn import metrics\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nresults = pd.DataFrame([['Multiple Linear Regression', mae, mse, rmse, r2]],\n               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])","6cad4aa8":"## Polynomial Regressor\nfrom sklearn.preprocessing import PolynomialFeatures\npoly_reg = PolynomialFeatures(degree = 2)\nX_poly = poly_reg.fit_transform(X_train)\nlr_poly_regressor = LinearRegression()\nlr_poly_regressor.fit(X_poly, y_train)\n\n# Predicting Test Set\ny_pred = lr_poly_regressor.predict(poly_reg.fit_transform(X_test))\nfrom sklearn import metrics\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Polynomial Regression', mae, mse, rmse, r2]],\n               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n\nresults = results.append(model_results, ignore_index = True)","4dbef06c":"## Suport Vector Regression \n'Necessary Standard Scaler '\nfrom sklearn.svm import SVR\nsvr_regressor = SVR(kernel = 'rbf')\nsvr_regressor.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = svr_regressor.predict(X_test)\nfrom sklearn import metrics\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Support Vector RBF', mae, mse, rmse, r2]],\n               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n\nresults = results.append(model_results, ignore_index = True)","9d2c1c39":"## Decision Tree Regression\nfrom sklearn.tree import DecisionTreeRegressor\ndt_regressor = DecisionTreeRegressor(random_state=0)\ndt_regressor.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = dt_regressor.predict(X_test)\nfrom sklearn import metrics\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Decision Tree Regression', mae, mse, rmse, r2]],\n               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n\nresults = results.append(model_results, ignore_index = True)","9bd853f5":"## Random Forest Regression\nfrom sklearn.ensemble import RandomForestRegressor\nrf_regressor = RandomForestRegressor(n_estimators=300, random_state=0)\nrf_regressor.fit(X_train,y_train)\n\n# Predicting Test Set\ny_pred = rf_regressor.predict(X_test)\nfrom sklearn import metrics\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Random Forest Regression', mae, mse, rmse, r2]],\n               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n\nresults = results.append(model_results, ignore_index = True)","2d0399bf":"## Ada Boosting\nfrom sklearn.ensemble import AdaBoostRegressor\nad_regressor = AdaBoostRegressor()\nad_regressor.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = ad_regressor.predict(X_test)\nfrom sklearn import metrics\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['AdaBoost Regressor', mae, mse, rmse, r2]],\n               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n\nresults = results.append(model_results, ignore_index = True)","d9679398":"##Gradient Boosting\nfrom sklearn.ensemble import GradientBoostingRegressor\ngb_regressor = GradientBoostingRegressor()\ngb_regressor.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = gb_regressor.predict(X_test)\nfrom sklearn import metrics\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['GradientBoosting Regressor', mae, mse, rmse, r2]],\n               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n\nresults = results.append(model_results, ignore_index = True)","b79de27d":"##Xg Boosting\nfrom xgboost import XGBRegressor\nxgb_regressor = XGBRegressor()\nxgb_regressor.fit(X_train, y_train)\n\n# Predicting Test Set\ny_pred = xgb_regressor.predict(X_test)\nfrom sklearn import metrics\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['XGB Regressor', mae, mse, rmse, r2]],\n               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n\nresults = results.append(model_results, ignore_index = True)","e84bfd42":"##Ensemble Voting regressor\nfrom sklearn.ensemble import VotingRegressor\nvoting_regressor = VotingRegressor(estimators= [('lr', lr_regressor),\n                                                  ('lr_poly', lr_poly_regressor),\n                                                  ('svr', svr_regressor),\n                                                  ('dt', dt_regressor),\n                                                  ('rf', rf_regressor),\n                                                  ('ad', ad_regressor),\n                                                  ('gr', gb_regressor),\n                                                  ('xg', xgb_regressor)])\n\nfor clf in (lr_regressor,lr_poly_regressor,svr_regressor,dt_regressor,\n            rf_regressor, ad_regressor,gb_regressor, xgb_regressor, voting_regressor):\n    clf.fit(X_train,y_train)\n    y_pred = clf.predict(X_test)\n    print(clf.__class__.__name__, metrics.r2_score(y_test, y_pred))\n\n# Predicting Test Set\ny_pred = voting_regressor.predict(X_test)\nfrom sklearn import metrics\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Ensemble Voting', mae, mse, rmse, r2]],\n               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n\nresults = results.append(model_results, ignore_index = True)  ","2abdb3db":"#The Best Classifier\nprint('The best regressor is:')\nprint('{}'.format(results.sort_values(by='R2 Score',ascending=False).head(5)))","f9038335":"#Applying K-fold validation\nfrom sklearn.model_selection import cross_val_score\ndef display_scores (scores):\n    print('Scores:', scores)\n    print('Mean:', scores.mean())\n    print('Standard:', scores.std())\n\nlin_scores = cross_val_score(estimator=lr_regressor, X=X_train, y=y_train, \n                             scoring= 'neg_mean_squared_error',cv=10)\nlin_rmse_scores = np.sqrt(-lin_scores)\ndisplay_scores(lin_rmse_scores)","46ec738c":"#Applying PCA (If Necessary)\nfrom sklearn.decomposition import PCA\npca = PCA(n_components = 2)\nX_train_pca = pca.fit_transform(X_train)\nX_test_pca = pca.transform(X_test)\nexplained_variance = pca.explained_variance_ratio_ ","6a9c83a5":"## Multiple Linear Regression Regression (PCA)\nfrom sklearn.linear_model import LinearRegression\nlr_regressor_pca = LinearRegression()\nlr_regressor_pca.fit(X_train_pca, y_train)\n\n# Predicting Test Set\ny_pred = lr_regressor_pca.predict(X_test_pca)\nfrom sklearn import metrics\nmae = metrics.mean_absolute_error(y_test, y_pred)\nmse = metrics.mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\nr2 = metrics.r2_score(y_test, y_pred)\n\nmodel_results = pd.DataFrame([['Multiple Linear Regression (PCA)', mae, mse, rmse, r2]],\n               columns = ['Model', 'MAE', 'MSE', 'RMSE', 'R2 Score'])\n\nresults = results.append(model_results, ignore_index = True)","c43e0c2f":"results.sort_values(by='R2 Score', ascending=False)","45438a2a":"# Feature engineering","442a8063":"# Model Building \n### Comparing Models"}}