{"cell_type":{"f3ce54bd":"code","9a8220fe":"code","3b9ef47d":"code","c1251dfc":"code","6f96c282":"code","ce544a29":"code","8c325144":"code","35a6e1ee":"code","efc47b16":"code","3dcbe3c1":"code","09006fb9":"code","a2fce011":"code","1f85b251":"code","454bf5bf":"code","f3c2252a":"code","8a937d67":"code","f65353f4":"code","c71a86cb":"code","279c65e4":"code","3ed827d7":"code","22c311c4":"code","429454f0":"code","f466f927":"code","28d19f74":"code","68b08fd7":"code","92584fa4":"markdown","1d2672cc":"markdown","b61de91b":"markdown","87de7325":"markdown","1e9d851d":"markdown","f15bf0fc":"markdown","da5fc8be":"markdown","e1674dac":"markdown","4774e16e":"markdown","185fdcca":"markdown","ebf5828a":"markdown","4cb7b232":"markdown","d7477ccb":"markdown"},"source":{"f3ce54bd":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score, accuracy_score, confusion_matrix,roc_auc_score\nfrom sklearn.utils import resample\nfrom sklearn.ensemble import RandomForestClassifier\n## to ignore waarning\nimport warnings\nwarnings.filterwarnings(\"ignore\")#, category=DeprecationWarning)","9a8220fe":"data = pd.read_csv(\"\/kaggle\/input\/paysim1\/PS_20174392719_1491204439457_log.csv\")\ndata.head()","3b9ef47d":"print(\"Number of records:\\t\\t\",data.shape[0])\nprint(\"Number of features per record:\\t\",data.shape[1])","c1251dfc":"print(\"Any missing data?\",data.isnull().sum().any())","6f96c282":"#print(\"% of Valid transactions:\",round(data.isFraud.value_counts()[0]\/data.shape[0] * 100,2))\n#print(\"% of Fraud transactions:\",round(data.isFraud.value_counts()[1]\/data.shape[0] * 100,2))\n\nprint(\"No of Valid transactions:\",data.isFraud.value_counts()[0],'which is ',round(data.isFraud.value_counts()[0]\/data.shape[0] * 100,2),'%')\nprint(\"No of Fraud transactions:\",data.isFraud.value_counts()[1],'which is ',round(data.isFraud.value_counts()[1]\/data.shape[0] * 100,2),'%')\n\ndata.isFraud.value_counts()","ce544a29":"print(\"No of transactions Flagged as Valid:\",data.isFlaggedFraud.value_counts()[0])\nprint(\"No of transactions Flagged as Fraud:\",data.isFlaggedFraud.value_counts()[1])","8c325144":"print(\"Are there any mismatch in the balance at origin and destination after transaction?\")\ndata['error_orig'] = (data[\"oldbalanceOrg\"] - data[\"amount\"] != data[\"newbalanceOrig\"]).astype(int)\ndata['error_dest'] = (data[\"oldbalanceDest\"] + data[\"amount\"] != data[\"newbalanceDest\"]).astype(int)\n\nprint(\"Balance Error(%) at the origin:\",round(data['error_orig'].value_counts()[1]\/data.shape[0] * 100,2))\nprint(\"Balance Error(%) at the destination:\",round(data['error_dest'].value_counts()[1]\/data.shape[0] * 100,2))\n\n#print(\"Valid Balance(%) at the origin:\",round(data['error_orig'].value_counts()[0]\/data.shape[0] * 100,2))\n#print(\"Valid Balance(%) at the dest:\",round(data['error_dest'].value_counts()[0]\/data.shape[0] * 100,2))","35a6e1ee":"print(\"Any transaction with amount less than or equal to 0?\")\nprint(len(data[data.amount<=0]))\nprint(\"What type of transactions are they?\")\nprint(data[data.amount<=0]['type'].value_counts().index[0])\nprint(\"Are all these marked as Fraud Transactions?\")\ndata[data.amount<=0]['isFraud'].value_counts()[1] == len(data[data.amount<=0])","efc47b16":"data_temp = data[data.isFlaggedFraud==1]\nprint(\"How many frauds transactions are Flagged?:\")\nprint(\"\\t\",len(data_temp))\n\nprint(\"What type of transactions are they?\")\nprint(\"\\t\",data_temp['type'].value_counts().index[0])\n\nprint(\"Are all these flagged also marked as Fraud Transactions?\")\nprint(\"\\t\",data_temp['isFraud'].value_counts()[1] == len(data_temp))\n\nprint(\"Minumum amount transfered in these transactions\")\nprint(\"\\t\",data_temp.amount.min())\n\nprint(\"Maximum amount transfered in these transactions\")\nprint(\"\\t\",data_temp.amount.max())","3dcbe3c1":"data = data.loc[(data['type'].isin(['TRANSFER', 'CASH_OUT']))]\ndata.head()","09006fb9":"#create pie chart\nplt.figure(figsize=(10,8))\nplt.pie(data.type.value_counts().values,labels=data.type.value_counts().index,  autopct='%.0f%%')\nplt.title(\"Transaction Type\")\nplt.show()","a2fce011":"d = data.groupby('type')['amount'].sum()\nplt.figure(figsize=(10,8))\nax = sns.barplot(x=d.index,y=d.values)\nfor p in ax.patches:\n    ax.annotate(str(format(int(p.get_height()), ',d')), (p.get_x()+0.24, p.get_height()*1.01))\n    \nplt.title(\"Total amount in each transaction type\")\nplt.yticks([])\nplt.xlabel(\"Transaction Type\")\nplt.show()","1f85b251":"plt.figure(figsize=(10,8))\nax = data.groupby(['type','isFraud']).size().plot(kind='bar')\n\nfor p in ax.patches:\n    ax.annotate(str(format(int(p.get_height()), ',d')), (p.get_x(), p.get_height()*1.01))\nplt.title(\"Fradulent Transactions\")\nplt.xlabel(\"Transaction Type\")\nplt.yticks([])\n#plt.xticks([' Valid CashOut','Fraud CashOut','Valid Transfer','Fraud Transfer'])\nplt.xticks(rotation=45)\nplt.show()","454bf5bf":"data.drop(['step','type','nameOrig','nameDest','error_orig','error_dest','isFlaggedFraud'],axis=1,inplace=True)\ndata.head()","f3c2252a":"ss = StandardScaler()\n\ndata.amount         = ss.fit_transform(data[['amount']])\ndata.oldbalanceOrg  = ss.fit_transform(data[['oldbalanceOrg']])\ndata.oldbalanceDest = ss.fit_transform(data[['oldbalanceDest']])\ndata.newbalanceOrig = ss.fit_transform(data[['newbalanceOrig']])\ndata.newbalanceDest = ss.fit_transform(data[['newbalanceDest']])","8a937d67":"X = data.drop([\"isFraud\"],axis=1)\ny = data.isFraud\nX_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","f65353f4":"# Function to create a confusion matrix \ndef conf_matrix(y_test, pred_test):    \n    \n    # Creating a confusion matrix\n    con_mat = confusion_matrix(y_test, pred_test)\n    con_mat = pd.DataFrame(con_mat, range(2), range(2))\n   \n    #Ploting the confusion matrix\n    \n    plt.figure(figsize=(6,6))\n    plt.title(\"Confusion Matrix\")\n    sns.set(font_scale=1.5) \n    sns.heatmap(con_mat, annot=True, annot_kws={\"size\": 16}, fmt='g', cmap='Blues', cbar=False)\n    ","c71a86cb":"lr = LogisticRegression(solver='newton-cg')\nlr.fit(X_train, y_train)\n\nlr_pred = lr.predict(X_test)\n\nprint(\"How many class does the model predict?\",np.unique( lr_pred ))\nprint(\"Numbers in each class:\\t\\t\",\"0 :\",len(lr_pred[lr_pred==0]))\nprint(\"\\t\\t 1 :\",len(lr_pred[lr_pred==1]))\n\nf1score = f1_score(y_test, lr_pred)\nprint('f1 score:', f1score)\n\nconf_matrix(y_test, lr_pred)\n \nacc_lr= accuracy_score(y_test, lr_pred)\nprint(\"Accuracy of this model:\", acc_lr)","279c65e4":"n = data.isFraud.value_counts()[0]\n\n# Separate majority and minority classes\ndf_majority = data[data.isFraud==0]\ndf_minority = data[data.isFraud==1]\n\n# Upsample minority class\ndf_minority_upsampled = resample(df_minority, \n                                 replace=True,     # sample with replacement\n                                 n_samples=n,    # to match majority class\n                                 random_state=123) # reproducible results\n \n# Combine majority class with upsampled minority class\ndf_upsampled = pd.concat([df_majority, df_minority_upsampled])\n \nprint(\"The new class count are :\")\ndf_upsampled.isFraud.value_counts()","3ed827d7":"X = df_upsampled.drop([\"isFraud\"],axis = 1)\ny = df_upsampled.isFraud\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\nlr = LogisticRegression(solver='newton-cg')\nlr.fit(X_train, y_train)\n\n# Predicting on the test data\nup_scale_pred = lr.predict(X_test)\n\n#Calculating and printing the f1 score \nf1up_scale_pred = f1_score(y_test, up_scale_pred)\nprint('f1 score for the testing data:\\t', f1up_scale_pred)\n\n#Calling function \nconf_matrix(y_test,up_scale_pred)\n\nacc_up_scale=accuracy_score(y_test, up_scale_pred)\nprint(\"Accuracy of thie model:\\t\\t\",acc_up_scale)\n","22c311c4":"n = data.isFraud.value_counts()[1]\n\n# Separate majority and minority classes\n\ndf_majority = data[data.isFraud==0]\ndf_minority = data[data.isFraud==1]\n\n \n# Downsample majority class\ndf_majority_downsampled = resample(df_majority, \n                                 replace=False,    # sample without replacement\n                                 n_samples=n,     # to match minority class\n                                 random_state=123) # reproducible results\n \n# Combine minority class with downsampled majority class\ndf_downsampled = pd.concat([df_majority_downsampled, df_minority])\n \nprint(\"The new class count are:\")\nprint(df_downsampled.isFraud.value_counts())","429454f0":"# Separate input features (X) and target variable (y)\ny = df_downsampled.isFraud\nX = df_downsampled.drop(['isFraud'], axis=1)\n \n# Train model\nlr = LogisticRegression().fit(X, y)\n \n# Predict on training set\ndown_scale_pred = lr.predict(X)\n \nprint(\"How many class does the model predict?\",np.unique( down_scale_pred ))\nprint(\"Count in each class:\\t\\t\\t\",\"0 :\",len(down_scale_pred[down_scale_pred==0]))\nprint(\"\\t\\t\\t\\t\\t 1 :\",len(down_scale_pred[down_scale_pred==1]))\n\n#Calculating and printing the f1 score \nf1down_scale_pred = f1_score(y, down_scale_pred)\nprint('f1 score for the testing data:\\t\\t', f1down_scale_pred)\n\nconf_matrix(y, down_scale_pred)\n      \nacc_down_scale=accuracy_score(y, down_scale_pred) \nprint(\"Accuracy of the model:\\t\\t\\t\", acc_down_scale)\n","f466f927":"# Separate input features (X) and target variable (y)\ny = data.isFraud\nX = data.drop(['isFraud'], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\n# Train model\nrfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)\n# Predict on training set\nrfc_pred = rfc.predict(X_test)","28d19f74":"\nprob_y = rfc.predict_proba(X_test)\nprob_y = [p[1] for p in prob_y]\n\nprint(\"AUROC:\\t\\t\\t\",roc_auc_score(y_test, prob_y))\n\nf1_rfc = f1_score(y_test, rfc_pred)\nprint('f1 score:\\t\\t', f1_rfc)\n\nconf_matrix(y_test, rfc_pred)\n\nacc_rfc=accuracy_score(y_test, rfc_pred) \nprint(\"Accuracy of the model:\\t\", acc_rfc)\n","68b08fd7":"data = {'Model':['Logistic Regression','UpScale Logistic Regression','DownScale Logistic Regression','RandomForest'],\n        'f1 score':[f1score,f1up_scale_pred,f1down_scale_pred,f1_rfc],\n        'Accuracy Score':[acc_lr,acc_up_scale,acc_down_scale,acc_rfc]}\n\ncomparision_table=pd.DataFrame(data)                               \nprint(comparision_table)","92584fa4":"#### Exploratory Data Analysis","1d2672cc":"## Data Visualization","b61de91b":"#### Delete unwanted features (Remove isFlaggedFraud and keep isFraud as target feature)","87de7325":"# 2. Down-sample Majority Class\n     Randomly remove data from the majority class","1e9d851d":"### All the fraud trnasactions belong to Transfer or Cash-out type, so discard data corresponding to other types","f15bf0fc":"##### Load the dataset","da5fc8be":"##### Import neccessary libraries","e1674dac":"## Since the dataset extremely imbalanced, some workaround can be done to overcome this. Below are all the methods listed","4774e16e":"# Objective\n* The objective of this exercise is to identify a fraudlent transaction as accurately as possible.\n* Compare different models based on their performance","185fdcca":"##### Appears the Fraud occurs both at sending and receiving ends","ebf5828a":"# 3. Tree-Based Algorithms","4cb7b232":"#### Standardizing all the continuous values to be between 0 and 1","d7477ccb":"# 1. Up-sample Minority Class\n    Randomly duplicate the data from the minority class."}}