{"cell_type":{"9a56e3c8":"code","d1883cb7":"code","c36cb6a4":"code","95b17db6":"code","809a2c9d":"code","7a58291b":"code","6360fefc":"code","e77e78b1":"code","abb5a62d":"code","ddabdefb":"code","db64776a":"code","aab7569b":"code","a7378ff0":"code","a1e40256":"code","2ce52837":"code","ff8d813d":"code","9679c467":"code","69ba8e14":"code","eb060668":"code","16058bad":"code","02ebdbb0":"code","5d5ce742":"code","a3309fa5":"code","a890c0f0":"code","2e9ce0cb":"code","e0ed94dd":"code","6473b007":"code","99d8eaa7":"markdown","5d22adef":"markdown","c2e44230":"markdown","304f9cfe":"markdown","0140578d":"markdown","752f0ec9":"markdown","5cb0ea9a":"markdown","acaf3b91":"markdown","83c9b831":"markdown"},"source":{"9a56e3c8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport random\nimport cv2\nimport tqdm as tqdm\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d1883cb7":"root_dir = \"\/kaggle\/input\/multiclass-weather-dataset\/dataset\/\"\nos.listdir(root_dir)","c36cb6a4":"foggy = \"\/kaggle\/input\/multiclass-weather-dataset\/dataset\/foggy\"\nsunrise = \"\/kaggle\/input\/multiclass-weather-dataset\/dataset\/sunrise\"\nshine = \"\/kaggle\/input\/multiclass-weather-dataset\/dataset\/shine\"\nrainy = \"\/kaggle\/input\/multiclass-weather-dataset\/dataset\/rainy\"\ncloudy = \"\/kaggle\/input\/multiclass-weather-dataset\/dataset\/cloudy\"\ntest = \"\/kaggle\/input\/multiclass-weather-dataset\/dataset\/alien_test\"","95b17db6":"print(\"Number of Images in Each Directory:\")\nprint(f\"Foggy: {len(os.listdir(foggy))}\")\nprint(f\"Sunrise: {len(os.listdir(sunrise))}\")\nprint(f\"Shine: {len(os.listdir(shine))}\")\nprint(f\"Rainy: {len(os.listdir(rainy))}\")\nprint(f\"Cloudy: {len(os.listdir(cloudy))}\")","809a2c9d":"x = []\ny = [] \ndataset =[]\ndef create_dataset(directory,dir_name):\n    for i in tqdm.tqdm(os.listdir(directory)):\n        full_path = os.path.join(directory,i)\n        try:\n            img = cv2.imread(full_path)\n            img = cv2.resize(img,(150,150))\n        except:\n            continue\n        x.append(img)\n        y.append(dir_name)\n    return x,y","7a58291b":"x,y= create_dataset(foggy,\"foggy\")\nx,y= create_dataset(sunrise,\"sunrise\")\nx,y= create_dataset(shine,\"shine\")\nx,y= create_dataset(rainy,\"rainy\")\nx,y= create_dataset(cloudy,\"cloudy\")","6360fefc":"x =  np.array(x)\ny = np.array(y)\nx.shape,y.shape","e77e78b1":"import seaborn as sns\nplt.figure(figsize=(9,7))\nplt.style.use(\"fivethirtyeight\")\nsns.countplot(y)\nplt.show()","abb5a62d":"fig = plt.figure(figsize=(12,7))\nfor i in range(15):\n    sample =  random.choice(range(len(x)))\n    image = x[sample]\n    category = y[sample]\n    plt.subplot(3,5,i+1)\n    plt.subplots_adjust(hspace=0.3)\n    plt.imshow(image)\n    plt.xlabel(category)\n    \nplt.tight_layout()\nplt.show()","ddabdefb":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)","db64776a":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)","aab7569b":"img_size =150\n\nx_train = np.array(x_train)\/255.0\nx_test = np.array(x_test)\/255.0\n\n\nx_train = x_train.reshape(-1,img_size,img_size,3)\ny_train = np.array(y_train)\n\nx_test = x_test.reshape(-1,img_size,img_size,3)\ny_test = np.array(y_test)","a7378ff0":"from sklearn.preprocessing import LabelBinarizer\nlb = LabelBinarizer()\ny_train_lb = lb.fit_transform(y_train)\ny_test_lb = lb.fit_transform(y_test)","a1e40256":"y_train_lb.shape,y_test_lb.shape","2ce52837":"from tensorflow.keras.applications.vgg19 import VGG19\nvgg = VGG19(weights = \"imagenet\",include_top=False,input_shape=(img_size,img_size,3))","ff8d813d":"for layer in vgg.layers:\n    layer.trainable = False","9679c467":"from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Flatten,Dense\nmodel =Sequential()\nmodel.add(vgg)\nmodel.add(Flatten())\nmodel.add(Dense(5,activation=\"softmax\"))","69ba8e14":"model.summary()","eb060668":"model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=\"accuracy\")\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\ncheckpoint = ModelCheckpoint(\"vgg19.h5\",monitor=\"val_accuracy\",verbose=1,save_best_only=True,\n                             save_weights_only=False)\nearlystop = EarlyStopping(monitor=\"val_accuracy\",patience=5,verbose=1)","16058bad":"unique,counts = np.unique(y_train_lb,return_counts=True)\nprint(unique,counts)","02ebdbb0":"batch_size=32\nhistory =  model.fit(x_train,y_train_lb,epochs=15,validation_data=(x_test,y_test_lb),\n                     batch_size=32 ,verbose=1,callbacks=[checkpoint,earlystop])","5d5ce742":"loss,accuracy = model.evaluate(x_test,y_test_lb)\nprint(f\"Loss: {loss}\")\nprint(f\"Accuracy: {accuracy}\")     ","a3309fa5":"y_pred = model.predict_classes(x_test)\ny_pred[:15]","a890c0f0":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))","2e9ce0cb":"from sklearn.metrics import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\ncm = confusion_matrix(y_test,y_pred)\nplot_confusion_matrix(conf_mat = cm,figsize=(8,7),class_names = [\"cloudy\",\"foggy\",\"rainy\",\"shine\",\"sunrise\"],\n                      show_normed = True);","e0ed94dd":"plt.style.use(\"ggplot\")\nfig = plt.figure(figsize=(12,6))\nepochs = range(1,16)\nplt.subplot(1,2,1)\nplt.plot(epochs,history.history[\"accuracy\"],\"go-\")\nplt.plot(epochs,history.history[\"val_accuracy\"],\"ro-\")\nplt.title(\"Model Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend([\"Train\",\"val\"],loc = \"upper left\")\n\nplt.subplot(1,2,2)\nplt.plot(epochs,history.history[\"loss\"],\"go-\")\nplt.plot(epochs,history.history[\"val_loss\"],\"ro-\")\nplt.title(\"Model Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend([\"Train\",\"val\"],loc = \"upper left\")\nplt.show()","6473b007":"plt.figure(figsize=(12,9))\nplt.style.use(\"ggplot\")\nfor i in range(10):\n    sample = random.choice(range(len(x_test)))\n    plt.subplot(2,5,i+1)\n    plt.subplots_adjust(hspace=0.3)\n    plt.imshow(x_test[sample])\n    plt.xlabel(f\"Actual: {y_test[sample]}\\n Predicted: {y_pred[sample]}\")\n    \nplt.tight_layout()    \nplt.show()                       ","99d8eaa7":"---\n\n<h1 style=\"text-align: center;font-size: 40px;\">Weather Type Prediction<\/h1>\n\n---\n","5d22adef":"><h3>Classification Report<\/h3>","c2e44230":"><h3>Let's see some of the Images<\/h3>","304f9cfe":"<h3>Data preprocessing for our Model<\/h3>","0140578d":"><h3>Model Performance:<\/h3>","752f0ec9":"><h3>Learning Curve:<\/h3>","5cb0ea9a":"><h3>Confusion Matrix<\/h3>","acaf3b91":"><h3>Model building<\/h3>","83c9b831":"---\n\n<h1 style=\"text-align: center;font-size: 20px;\">Thanks for Reading!!<\/h1>\n\n---\n"}}