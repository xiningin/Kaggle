{"cell_type":{"a6647c62":"code","9c857697":"code","bb35a188":"code","f5ba507f":"code","7a1e3bc9":"code","19498f64":"code","0c0ce632":"code","80c45316":"code","0b50b829":"code","4055e794":"code","a319e264":"code","d2548921":"code","e99545c6":"code","28e73ad4":"code","4771bf69":"code","df4020d1":"code","62804b3a":"code","a93d73b4":"code","f87b5ed5":"code","2d50702f":"code","4a60fb1e":"code","013e7036":"code","02178c75":"code","c7be0e29":"code","d3e1f1eb":"code","102a9960":"code","cacd2c3b":"code","66c4ce8f":"code","5fa5260d":"code","b86d8f31":"code","2ba2ed68":"code","172e42ba":"code","2b9d2ffb":"code","514b2471":"code","5bf81868":"code","2c29fda6":"code","f7bcc9be":"code","c6515de2":"code","e32e3b93":"code","7ddf361e":"markdown","701d2d95":"markdown","56aeca99":"markdown","f8350e6d":"markdown","27ace3f9":"markdown","d4ce294b":"markdown","35b8230b":"markdown","36966a30":"markdown","0425ac6e":"markdown","ae5f571a":"markdown","aff93d43":"markdown","406e1d1a":"markdown","1a8e3c88":"markdown","6685e296":"markdown","8add044f":"markdown","96ce4d7f":"markdown","49818bcb":"markdown","621f9a59":"markdown","4e294bd1":"markdown","50ee2c4a":"markdown","23c92a55":"markdown","08809c40":"markdown","914b48f2":"markdown","4d76002b":"markdown","038bb27a":"markdown","2d784807":"markdown","fe71a4f0":"markdown","a3d6be65":"markdown","7d2c2fe6":"markdown","7c93585e":"markdown","5190c951":"markdown","701da926":"markdown","0807adfc":"markdown","4ed98d29":"markdown","1b9fe6d0":"markdown","f8ee8731":"markdown"},"source":{"a6647c62":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom matplotlib import cm\nimport matplotlib.pyplot as plt\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split , GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report , recall_score ,  precision_score\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import classification_report\nimport seaborn as sns","9c857697":"# Read data\n\nflight_details_janury_2019 = pd.read_csv('\/kaggle\/input\/flight-delay-prediction\/Jan_2019_ontime.csv')\n\nflight_details_janury_2019.head()","bb35a188":"# check the columns:\nflight_details_janury_2019.columns","f5ba507f":"# check type of columns:\nflight_details_janury_2019.info()","7a1e3bc9":"flight_details_janury_2019['DELAYED'] = (flight_details_janury_2019['ARR_DEL15'].astype(bool) | flight_details_janury_2019['DEP_DEL15'].astype(bool)).astype(int)\n","19498f64":"print(\"The number of rows before deleted 'Cancelled' column and `DIVERTED` is \" + str(flight_details_janury_2019.shape[0]) )\n\nflight_details_janury_2019.drop(flight_details_janury_2019[flight_details_janury_2019.CANCELLED == 1].index, inplace=True)\n\nflight_details_janury_2019.drop(flight_details_janury_2019[flight_details_janury_2019.DIVERTED == 1].index, inplace=True)\n\nprint(\"The number of rows after deleted 'Cancelled' column and `DIVERTED` is \" + str(flight_details_janury_2019.shape[0]) )\n","0c0ce632":"flight_details_janury_2019.drop(['OP_CARRIER_AIRLINE_ID','TAIL_NUM','OP_CARRIER_FL_NUM','ORIGIN_AIRPORT_ID','ORIGIN_AIRPORT_SEQ_ID','DEST_AIRPORT_ID','DEST_AIRPORT_SEQ_ID','Unnamed: 21','OP_CARRIER','ARR_DEL15','DEP_DEL15','CANCELLED', 'DIVERTED'], axis='columns', inplace=True)\n","80c45316":"flight_details_janury_2019['DELAYED'].value_counts()","0b50b829":"# Split the data into positive and negative\npos = flight_details_janury_2019.loc[flight_details_janury_2019.DELAYED == 1]\nneg = flight_details_janury_2019.loc[flight_details_janury_2019.DELAYED == 0]\n\n# Merge the balanced data\ndata = pd.concat([pos, neg.sample(n = len(pos))], axis = 0)\n\n# Shuffle the order of data\nflight_details_janury_2019 = data.sample(n = len(data)).reset_index(drop = True)","4055e794":"flight_details_janury_2019['DELAYED'].value_counts()","a319e264":"flight_details_janury_2019 = flight_details_janury_2019.rename(columns={\"OP_UNIQUE_CARRIER\": \"AIRLINE_CODE\"})","d2548921":"flight_details_janury_2019.isna().sum()","e99545c6":"print(\"The Data types is:\")\nflight_details_janury_2019.info()","28e73ad4":"print(\"Our final data include: \" + str(flight_details_janury_2019.shape[0]) + \" Rows and \" + str(flight_details_janury_2019.shape[1]) + \" Columns\" )","4771bf69":" flight_details_janury_2019.head()","df4020d1":"\nflight_details_janury_2019.hist(figsize= (15, 14))","62804b3a":" flight_details_janury_2019.describe()","a93d73b4":"# Count delayes by company\ncount_delayed=flight_details_janury_2019.groupby('AIRLINE_CODE')['DELAYED'].apply(lambda x: (x==1).sum()).reset_index(name='Number Delayed')\n\ncolor = cm.inferno_r(np.linspace(.4, .8, 30))\n\ncount_delayed= count_delayed.sort_values(\"Number Delayed\" , ascending=[False])\ncount_delayed.plot.bar(x='AIRLINE_CODE', y='Number Delayed', color=color , figsize=(12,7))\n","f87b5ed5":"monthly_days_delayed=flight_details_janury_2019.groupby('DAY_OF_MONTH')['DELAYED'].apply(lambda x: (x==1).sum()).reset_index(name='Number Delayed')\nplt.figure(figsize=(10, 6))\nplt.xticks(monthly_days_delayed['DAY_OF_MONTH'])\nplt.plot(monthly_days_delayed['DAY_OF_MONTH'],monthly_days_delayed['Number Delayed'])\nplt.ylabel('Delayed')\nplt.xlabel('Day in month')\nplt.show()","2d50702f":"#Calculate the precent of delays with average distance:\navg_distance_delay = flight_details_janury_2019[flight_details_janury_2019['DELAYED'] == 1]['DISTANCE'].values.mean()\n#Calculate the precent of delays without average distance:\navg_distance_without_delay = flight_details_janury_2019[flight_details_janury_2019['DELAYED'] == 0]['DISTANCE'].values.mean()\n\nprint(\"Avergae Distance with delay: \" + str(avg_distance_delay) + \" mile\")\nprint(\"Avergae Distance without delay: \"+ str(avg_distance_without_delay) +\" mile\")\n\nlabels = ['Distance With Delay', 'Distance Without Delay']\nsizes = [avg_distance_delay,avg_distance_without_delay]\ncolors = ['yellowgreen', 'gold']\ntexts = plt.pie(sizes, colors=colors, shadow=True, startangle=90, autopct='%1.1f%%')\nplt.legend(labels, loc=\"best\")\nplt.axis('equal')\nplt.tight_layout()\nplt.show()","4a60fb1e":"# Create the data for the days adays_values\ndays_values = flight_details_janury_2019.groupby('DAY_OF_WEEK')['DELAYED'].apply(lambda x: (x==1).sum()).reset_index(name='Number Delayed')\ndays_values.sort_values(\"DAY_OF_WEEK\" )\n\ndays_values['DAY_OF_WEEK'] = days_values['DAY_OF_WEEK'].map({1: 'Sun', 2: 'Mon', 3:'Thu',4:'Wed',5:'Thr',6:'Fri',7:'Sat'})\n\ndf = pd.DataFrame({'Days':days_values['DAY_OF_WEEK'],'Delayed':days_values['Number Delayed']})\nax = df.plot.barh(x='Days',y='Delayed',figsize=(12,7))","013e7036":"def encode_categories(features):\n    lb_make = LabelEncoder()\n    for i in range(len(features)):\n        flight_details_janury_2019[features[i]] = lb_make.fit_transform(flight_details_janury_2019[features[i]])\n","02178c75":"encode_categories(['AIRLINE_CODE','ORIGIN','DEST','DEP_TIME_BLK',])\nflight_details_janury_2019.info()","c7be0e29":"plt.figure(figsize = (12, 10))\nsns.heatmap(flight_details_janury_2019.corr(), annot = True, cmap = 'coolwarm')\nplt.show()","d3e1f1eb":"# Create test and train:\nfeature_names = ['DAY_OF_MONTH','DAY_OF_WEEK','AIRLINE_CODE','ORIGIN','DEST','DEP_TIME','DEP_TIME_BLK','ARR_TIME','DISTANCE']\nX =  flight_details_janury_2019[feature_names].values\ny =  flight_details_janury_2019['DELAYED'].values","102a9960":"# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n","cacd2c3b":"rf = RandomForestClassifier(n_estimators = 350,max_depth=14,min_samples_leaf=15,min_samples_split=5, n_jobs=-1)\nrf.fit(X_train,y_train)","66c4ce8f":"gb = GradientBoostingClassifier()\ngb.fit(X_train,y_train)","5fa5260d":"dt = DecisionTreeClassifier(max_depth=15)\ndt.fit(X_train,y_train)","b86d8f31":"ab = AdaBoostClassifier()\nab.fit(X_train, y_train)","2ba2ed68":"# Acurracy of each model\ndef get_accuracy(model):\n        pred = model[0].predict(X_test)\n        check_overfitting(model)\n        return accuracy_score(y_test, pred)","172e42ba":"def check_overfitting(model):\n        pred = model[0].predict(X_test)\n        over_fit_check_pred = model[0].predict(X_train)\n        print('Checking '+ model[1] + ' Overffiting:')\n        print('Train Accuracy ' + str(accuracy_score(y_train, over_fit_check_pred)))\n        print('Test Accuracy ' + str(accuracy_score(y_test, pred)))\n        print('--------------------------')","2b9d2ffb":"# Plot the confusion matrix for each model:\ndef get_confusion_matrix(model):\n    from sklearn.metrics import plot_confusion_matrix\n    class_names=['Delay-False','Delay-true']\n    disp = plot_confusion_matrix(model[0], X_test, y_test,\n                                     display_labels=class_names, values_format='d',\n                                     cmap=model[2])\n    precision = precision_score(y_test, model[0].predict(X_test), average='binary')\n    recall = recall_score(y_test, model[0].predict(X_test), average='binary')\n    print('Avg Precision:' +  str(precision))\n    print('Avg Recall:' + str(recall))\n    \n    disp.ax_.set_title(model[1])\n    plt.show()","514b2471":"### Save the accuracy\nmodels = [[rf,'Random Forest',plt.cm.Blues],[gb,'Gradient Boosting',plt.cm.Greens],[dt,'Decision Tree',plt.cm.Reds],[ab,'AdaBoost',plt.cm.Oranges]]\naccuracy = []\nfor model in models:\n    accuracy.append(get_accuracy(model))","5bf81868":"for model in models:\n    get_confusion_matrix(model)","2c29fda6":"plt.figure(figsize=(15,5))\nmodel_names = ['Random Forest','Gradient Boosting','Decision Tree','AdaBoost']\nax = sns.barplot(x = model_names, y =accuracy)\n\naccuracy_dic = dict(zip(model_names, accuracy))\n\nfor p, value in zip(ax.patches, list(accuracy_dic.values())):\n    _x = p.get_x() + p.get_width() \/ 2\n    _y = p.get_y() + p.get_height() + 0.008\n    ax.text(_x, _y, round(value, 3), ha=\"center\") \n\nplt.xlabel(\"Models\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Model vs. Accuracy\")\nplt.show()","f7bcc9be":"print(classification_report(y_test, rf.predict(X_test), target_names=['Delayed','Not Delayed']))","c6515de2":"importances = rf.feature_importances_\nfeatures = list(flight_details_janury_2019.columns)\nindices = np.argsort(importances)[::-1]\n\nnames = [features[i] for i in indices]\n\nplt.figure(figsize=(15,5))\nplt.bar(range(X_train.shape[1]), importances[indices])\nplt.xticks(range(X_train.shape[1]), names, rotation=30, fontsize = 10)\nplt.title(\"Feature Importance\")\nplt.show()","e32e3b93":"# Save the older accur:\nrf_old_accur = accuracy[0]\n\nrf = RandomForestClassifier(n_estimators=200, min_samples_split=5, max_features='sqrt', max_depth=45)\nrf.fit(X_train,y_train)\n\npred = rf.predict(X_test)\nrf_new_accur = accuracy_score(y_test, pred)\n\nprint(\"The Accuracy of RandomForest Model before tuning: \" + str(rf_old_accur))\nprint(\"The Accuracy of RandomForest Model after tuning: \" + str(rf_new_accur))\n\nprint(\"Increase of : \" + str(100-((rf_old_accur * 100 ) \/ rf_new_accur ))+' %')","7ddf361e":"**GradientBoosting**","701d2d95":"Plot accurcay of each model","56aeca99":"Show the confusion matrix for each model with Recall and Precision","f8350e6d":"**AdaBoostClassifier**","27ace3f9":"Lets understand what we are looking to predict:\n* We have dataset of flights from januray 2019 and we want to predict if some flight will delayed or not. \n* In our dataset, we have 2 columns of delay: 1 column for departure delay [DEP_DEL15], and 1 column for arrivel delay [ARR_DEL15] \n* We want to predict if someflight will delayed in any time - arrival or departure. So lets create new classifier, named under \"delayed\" with 2 result:\n\n1.  Delayed - 1 the flight will delay\n2.  Delayed - 0 the flight will not delay","d4ce294b":"First Lets see if there some dfference between airline companies delay, due to result we can understand if there problem with spesific company.","35b8230b":"**Random Forest**","36966a30":"Correlation between the day of the month to number of delays:","0425ac6e":"We can see that there are very highly difference between the rows with value 1 and 0 , so we should decrease our rows with value 0.","ae5f571a":"**Collerations between our features:**","aff93d43":"Check for some Null\/Na values:","406e1d1a":"Lets prepare our data for modeling","1a8e3c88":"# **Exploratory Data Analysis**\n","6685e296":"We have to encode our categorial Variabels before we move to modeling:\n* OP_UNIQUE_CARRIER\n* ORIGIN\n* DEST\n* DEST_TIME_BLK","8add044f":"**Lets look for some corelations between the features and our classifier for better understanding,\nand learn a more about our features.** \n\n","96ce4d7f":"We see that Random Forest give us the best accuracy. Lets try to change our params for Random forset, and maybe we will get better result.","49818bcb":"the data is clean , we dont have any null values.","621f9a59":"Lets get rid of unuseful columns, that not impact on our results:\n* **OP_CARRIER_AIRLINE_ID** - The id of the airline , because we will use the name of airline , for correltions and plots , more clearly to understand ariline name code than the airline id , and after that we will convert the name to numeric value\n* **TAIL_NUM** - dosnt give us any information\n* **OP_CARRIER_FL_NUM** - dosnt give us any information\n* **ORIGIN_AIRPORT_ID** , **'ORIGIN_AIRPORT_ID'** ,**ORIGIN_AIRPORT_SEQ_ID','DEST_AIRPORT_ID','DEST_AIRPORT_SEQ_ID'** - we have instead the origin and destination airport ATA code , more clearly for understading in plots.\n* **Unnamed: 21** - Unrelevant column\n* **OP_CARRIER** - same as OP_UNIQUE_CARRIER\n* **DEP_DEL15** - We convert the DEP and ARR to DELAYED Column\n* **ARR_DEL15** - We convert the DEP and ARR to DELAYED Column\n* **CANCELED**  - We check only for delayed flight , so Canceled flight are dont relevant\n* **DIVERTED**  - We check only for delayed flight , so Canceled flight are dont relevant","4e294bd1":"Evaluating of accuarcy of our models","50ee2c4a":"Now lets see if there any corellation between the distance and delays:","23c92a55":"**Hyperparameter tuning for RandomForest**","08809c40":"**Decision Tree**","914b48f2":"**Summerize**:","4d76002b":"Test again the model after we did some optimization and find good parameters:","038bb27a":" the optimization takes 20 minutes. for avoid long run time ,you can see the code and the  result in report\n\n","2d784807":"# **Data Preparation:**","fe71a4f0":"Let's see in wich day are the higher number of delays:","a3d6be65":"Feature Importance:****","7d2c2fe6":"# Modeling","7c93585e":"# Evaluate","5190c951":"**Final Data Format:**\n\nAfter we carefully analyzing each data points, This is the final data:\n\n* DAY_OF_MONTH - Day of Month\n* DAY_OF_WEEK - Day of Week\n* AIRLINE_CODE - Airline Carrier Code\n* ORIGIN - Origin airport location\n* DEST - Destination airport location\n* DEP_TIME - Actual Departure Time (local time: hhmm)\n* DEP_TIME_BLK - Time Block Departure (hhmm-hhmm)\n* ARR_TIME - Actual Arrivel Time (local time: hhmm)\n* DISTANCE - Distance between airports (miles)\n* DELAYED - Classifier - 1 If flight delayed, else - 0","701da926":"We want to remove the canceled and diverted flights, because we are looking for flights that succesfuly departed","0807adfc":"**Lets check distribution of our target variable:**\n","4ed98d29":"Histograms:","1b9fe6d0":"Lets rename names if needed for more readble:","f8ee8731":"Lets first create Test set and Train set:"}}