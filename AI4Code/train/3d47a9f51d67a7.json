{"cell_type":{"043d676b":"code","58daf5f2":"code","103a2ebc":"code","23bb2806":"code","896fb1e7":"code","82be556e":"code","bb1856fd":"code","2fb57733":"code","e1516a1c":"code","aa472203":"code","0ef0be26":"code","a6350f97":"code","ad2594d6":"code","71d4c1d1":"code","d8e18332":"code","90b20d77":"code","7d3342f1":"code","5e89916d":"code","c98f6ecc":"code","012ae73d":"code","29aa884f":"code","377060a3":"code","44a669c4":"code","f1f08b30":"code","06384515":"code","edff0662":"code","a415d610":"code","7f123212":"code","9a7317c9":"code","c6b23164":"code","1c6061da":"code","1575dd68":"code","1d35ee94":"code","e17964cc":"code","1ab8a521":"code","de9f5a21":"code","98034638":"code","f9d2c686":"code","73bc1336":"code","f7508b6c":"code","89246016":"code","eb4f84f9":"code","56f8a0d2":"code","0d883aac":"code","cab564ec":"code","650a34b1":"markdown","f5b9293b":"markdown","c909481e":"markdown","e2343aa0":"markdown","808d530d":"markdown","5a89918d":"markdown","01844a9f":"markdown","cd9127b8":"markdown","4931cee1":"markdown","67a329dd":"markdown","26ae7eac":"markdown","767893f9":"markdown","2ce7c46b":"markdown","583a26e6":"markdown"},"source":{"043d676b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","58daf5f2":"# read the data to pandas dataframe\n\nretail = pd.read_csv('..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv', sep=\",\", encoding=\"ISO-8859-1\", header=0)\nretail.head()","103a2ebc":"# shape of df\n\nretail.shape","23bb2806":"# df info\n\nretail.info()","896fb1e7":"type_counts = retail['Country'].value_counts()\nCountry=pd.DataFrame(type_counts)\nCountry.head()","82be556e":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(20,10))\nCountry=Country.head()\nax = sns.barplot(y='Country',x=Country.index, data=Country.head())\nplt.xticks(rotation=45)","bb1856fd":"retail=retail[retail['Country']=='Germany']\nretail.shape","2fb57733":"# Calculating the Missing Values % contribution in DF\n\ndf_null = round(100*(retail.isnull().sum())\/len(retail), 2)\ndf_null","e1516a1c":"# Droping rows having missing values\n\nretail = retail.dropna()\nretail.shape","aa472203":"# Changing the datatype of Customer Id as per Business understanding\n\nretail['CustomerID'] = retail['CustomerID'].astype(str)","0ef0be26":"# New Attribute : Recency\n\n# Convert to datetime to proper datatype\n\nretail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'],format='%d-%m-%Y %H:%M')","a6350f97":"# Compute the maximum date to know the last transaction date\n\nmax_date = max(retail['InvoiceDate'])\nmax_date","ad2594d6":"# Compute the difference between max date and transaction date\n\nretail['Diff'] = max_date - retail['InvoiceDate']\nretail.head()","71d4c1d1":"# Compute last transaction date to get the recency of customers\n\nrfm_r = retail.groupby('CustomerID')['Diff'].min().reset_index()\nrfm_r.head()","d8e18332":"# Extract number of days only\n\nrfm_r['Diff'] = rfm_r['Diff'].dt.days\nrfm_r.columns = ['CustomerID','Recency']\nrfm_r.head()","90b20d77":"### New Attribute : Frequency\n\nrfm_f = retail.groupby('CustomerID')['InvoiceNo'].count().reset_index()\nrfm_f.columns = ['CustomerID', 'Frequency']\nrfm_f.head()","7d3342f1":"# New Attribute : Monetary\n\nretail['Amount'] = retail['Quantity']*retail['UnitPrice']\nrfm_m = retail.groupby('CustomerID')['Amount'].sum().reset_index()\nrfm_m.head()","5e89916d":"rfm = rfm_r.merge(rfm_f,how='inner',on=['CustomerID'])\nrfm =rfm.merge(rfm_m,how='inner',on=['CustomerID'])\nrfm.head()","c98f6ecc":"# Outlier Analysis of Amount Frequency and Recency\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nattributes = ['Recency','Frequency','Amount',]\nplt.rcParams['figure.figsize'] = [10,8]\nsns.boxplot(data = rfm[attributes], orient=\"v\", palette=\"Set2\" ,whis=1.5,saturation=1, width=0.7)\nplt.title(\"Outliers Variable Distribution\", fontsize = 14, fontweight = 'bold')\nplt.ylabel(\"Range\", fontweight = 'bold')\nplt.xlabel(\"Attributes\", fontweight = 'bold')","012ae73d":"# Removing (statistical) outliers for Amount\nQ1 = rfm.Amount.quantile(0.05)\nQ3 = rfm.Amount.quantile(0.95)\nIQR = Q3 - Q1\nrfm = rfm[(rfm.Amount >= Q1 - 1.5*IQR) & (rfm.Amount <= Q3 + 1.5*IQR)]\n\n# Removing (statistical) outliers for Recency\nQ1 = rfm.Recency.quantile(0.05)\nQ3 = rfm.Recency.quantile(0.95)\nIQR = Q3 - Q1\nrfm = rfm[(rfm.Recency >= Q1 - 1.5*IQR) & (rfm.Recency <= Q3 + 1.5*IQR)]\n\n# Removing (statistical) outliers for Frequency\nQ1 = rfm.Frequency.quantile(0.05)\nQ3 = rfm.Frequency.quantile(0.95)\nIQR = Q3 - Q1\nrfm = rfm[(rfm.Frequency >= Q1 - 1.5*IQR) & (rfm.Frequency <= Q3 + 1.5*IQR)]","29aa884f":"# Rescaling the attributes\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\n\nrfm_df = rfm[['Recency','Frequency', 'Amount']]\n\n# Instantiate\nscaler = StandardScaler()\n\n# fit_transform\nrfm_df_scaled = scaler.fit_transform(rfm_df)\nrfm_df_scaled.shape","377060a3":"rfm_df_scaled = pd.DataFrame(rfm_df_scaled)\nrfm_df_scaled.columns = ['Amount', 'Frequency', 'Recency']\nrfm_df_scaled.head()","44a669c4":"# k-means with some arbitrary k\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=4, max_iter=50)\nkmeans.fit(rfm_df_scaled)\n# assign the label\nrfm['Cluster_Id'] = kmeans.labels_\nrfm.head()","f1f08b30":"### visualize the result\nimport plotly.express as px\nrfm[\"Cluster_Id\"] = rfm[\"Cluster_Id\"].astype(str) #convert to string\nfig = px.scatter_3d(rfm, x='Recency', y='Frequency', z='Amount',\n              color='Cluster_Id')\nfig.show()","06384515":"from yellowbrick.cluster import KElbowVisualizer\nmodel = KMeans()\nvisualizer = KElbowVisualizer(\n    model, k=(2,9), metric='distortion')\n\nvisualizer.fit(rfm_df_scaled)        # Fit the data to the visualizer\nvisualizer.show() ","edff0662":"from yellowbrick.cluster import KElbowVisualizer\nmodel = KMeans()\nvisualizer = KElbowVisualizer(\n    model, k=(2,9), metric='silhouette')\n\nvisualizer.fit(rfm_df_scaled)        # Fit the data to the visualizer\nvisualizer.show()        # Finalize and render the figure","a415d610":"from yellowbrick.cluster import KElbowVisualizer\nmodel = KMeans()\nvisualizer = KElbowVisualizer(\n    model, k=(2,9), metric='calinski_harabasz')\n\nvisualizer.fit(rfm_df_scaled)        # Fit the data to the visualizer\nvisualizer.show()        # Finalize and render the figure","7f123212":"# k-means with some arbitrary k\nk=4\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=k, max_iter=50)\nkmeans.fit(rfm_df_scaled)\n# assign the label\nrfm['Cluster_Id'] = kmeans.labels_\nrfm.head()","9a7317c9":"### visualize the result\nimport plotly.express as px\nrfm[\"Cluster_Id\"] = rfm[\"Cluster_Id\"].astype(str) #convert to string\nfig = px.scatter_3d(rfm, x='Recency', y='Frequency', z='Amount',\n              color='Cluster_Id')\nfig.show()","c6b23164":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Id', y='Recency', data=rfm)","1c6061da":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Id', y='Frequency', data=rfm)","1575dd68":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Id', y='Amount', data=rfm)","1d35ee94":"Target_Customer = rfm[rfm['Cluster_Id']=='3']\nTarget_Customer.head()","e17964cc":"Target_Customer.count()","1ab8a521":"from scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree","de9f5a21":"# Single linkage: \n\nmergings = linkage(rfm_df_scaled, method=\"single\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","98034638":"# Complete linkage\n\nmergings = linkage(rfm_df_scaled, method=\"complete\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","f9d2c686":"# Average linkage\n\nmergings = linkage(rfm_df_scaled, method=\"average\", metric='euclidean')\ndendrogram(mergings)\nplt.show()","73bc1336":"# 3 clusters\nk=4\ncluster_labels = cut_tree(mergings, n_clusters=k).reshape(-1, )\nrfm['Cluster_Labels'] = cluster_labels\nrfm.head()","f7508b6c":"### visualize the result\nimport plotly.express as px\nrfm[\"Cluster_Labels\"] = rfm[\"Cluster_Labels\"].astype(str) #convert to string\nfig = px.scatter_3d(rfm, x='Recency', y='Frequency', z='Amount',\n              color='Cluster_Labels')\nfig.show()","89246016":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Labels', y='Recency', data=rfm)","eb4f84f9":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Labels', y='Frequency', data=rfm)","56f8a0d2":"# Box plot to visualize Cluster Id vs Frequency\nimport seaborn as sns\n\nsns.boxplot(x='Cluster_Labels', y='Amount', data=rfm)","0d883aac":"Target_Customer2 = rfm[rfm['Cluster_Labels']=='2']\nTarget_Customer2.head()","cab564ec":"Target_Customer2.count()","650a34b1":"3. Calculating Monetary","f5b9293b":"# **Step 3: K-Means Clustering**","c909481e":"4. Remove Outliers","e2343aa0":"**2. Finding the best K: A fundamental step for any unsupervised algorithm is to determine the optimal number of clusters into which the data may be clustered. **","808d530d":"1. Initial Cluster Given K","5a89918d":"2. Calculating Frequency","01844a9f":"# **Step 1: Import and Examine the data**","cd9127b8":"5. Rescaling the Attributes by Standardisation (mean-0, sigma-1)","4931cee1":"1. Calculating Recency","67a329dd":"Method 1: Finding the elbow point for (inertia_) \"Sum of squared distances of samples to their closest cluster center\".","26ae7eac":"# **Step 3: Data Preparation for RFM Factors**","767893f9":"# **Step 4: Hierarchical Clustering**","2ce7c46b":"# **Step 2: Data Cleaning**","583a26e6":"1. Visualize Tree by Linkage Methods"}}