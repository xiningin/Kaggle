{"cell_type":{"22e6f1fa":"code","7faefac0":"code","499d66c4":"code","17f419ee":"code","9b59d962":"code","f656a1ab":"code","0c3a59a1":"code","9abbfc46":"code","8d42b812":"code","e038dfcb":"code","03328483":"code","c4dfb3b5":"code","6c8bd735":"code","cfb2fca7":"code","d6167bb3":"code","d9f98a0f":"code","b2d4a9d2":"code","1ce3b15a":"code","57f9106b":"code","a84c1cb4":"code","cde52e42":"code","f9869416":"code","4da81352":"code","54f7b174":"code","221e7fee":"code","3f24111c":"code","ca8ab05a":"markdown","4318716d":"markdown","1a43764a":"markdown","61ff0f00":"markdown","0fed5dc8":"markdown","78c0c5a9":"markdown","86479c25":"markdown","8e2accf3":"markdown"},"source":{"22e6f1fa":"# !pip3 install graphviz\n# !pip3 install ann_visualizer","7faefac0":"import numpy as np\nimport pandas as pd\nimport os\nfrom glob import glob\nimport itertools\nimport fnmatch\nimport random\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport cv2\nfrom PIL import Image\n# from ann_visualizer.visualize import ann_viz;\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nimport tensorflow as tf\nimport keras\nfrom keras import backend as K\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n%matplotlib inline","499d66c4":"# Adding path of all the images together \nimagePatches = glob('\/kaggle\/input\/breast-histopathology-images\/**\/*.png', recursive=True)\nfor filename in imagePatches[0:10]:\n    print(filename)","17f419ee":"image_sample = \"\/kaggle\/input\/breast-histopathology-images\/12933\/1\/12933_idx5_x1001_y801_class1.png\"\ndsize=(50,50)\n\nimage = cv2.imread(image_sample)\nimage = cv2.resize(image, dsize)\nplt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)); plt.axis('off')\n","9b59d962":"resized_images,labels_arr = [],[]\ndsize=(50,50)\n    \nfor img in imagePatches[0:20000]:\n    full_size_image = cv2.imread(img)\n    resized_images.append(cv2.resize(full_size_image, dsize, interpolation=cv2.INTER_CUBIC))\n    labels_arr.append(int(img[-5]))","f656a1ab":"def describeData(a,b):\n    print('Total number of images: {}'.format(len(a)))\n    print('Number of IDC(-) Images: {}'.format(len(a)-np.sum(b)))\n    print('Number of IDC(+) Images: {}'.format(np.sum(b)))\n    print('Image shape (Width, Height, Channels): {}'.format(a[0].shape))\ndescribeData(resized_images,labels_arr)","0c3a59a1":"X=np.array(resized_images)\nY=pd.Series(labels_arr) \nX=X\/255.0\n \nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0, stratify=Y)\n\nprint(\"Training Data Shape:\", X_train.shape)\nprint(\"Testing Data Shape:\", X_test.shape)","9abbfc46":"plt.title(\"Distribution of target classes\")\nsns.countplot(Y) ","8d42b812":"# Make Data 1D for compatability upsampling methods\nimage_shape = 50*50*3\n\nX_train = X_train.reshape(X_train.shape[0], image_shape)\nX_test = X_test.reshape(X_test.shape[0], image_shape)\n","e038dfcb":"print(\"Shape of flattened training data:\",X_train.shape,\"\\nShape of flatened testing data: \",X_test.shape)","03328483":"# Deal with imbalanced class sizes below\n\n# from imblearn.over_sampling import RandomOverSampler \nfrom imblearn.under_sampling import RandomUnderSampler\n\n# Ros = RandomOverSampler(sampling_strategy='auto') \nRus = RandomUnderSampler(sampling_strategy='auto')\n\nX_trainRusFlat, Y_trainRus = Rus.fit_sample(X_train, Y_train)\nX_testRusFlat, Y_testRus = Rus.fit_sample(X_test, Y_test)\n\n#Reshape the images\nX_trainRus = X_trainRusFlat.reshape(len(X_trainRusFlat),50,50,3)\nX_testRus = X_testRusFlat.reshape(len(X_testRusFlat),50,50,3)\n\n# Encode labels\nY_trainRus = to_categorical(Y_trainRus, num_classes = 2)\nY_testRus = to_categorical(Y_testRus, num_classes = 2)\n","c4dfb3b5":"print(\"New shape of Train data =\",X_trainRus.shape)\nprint(\"New shape of Test data =\",X_testRus.shape)","6c8bd735":"# Helper Functions  Learning Curves and Confusion Matrix \n\nclass MetricsCheckpoint(Callback):\n    \"\"\"Callback that saves metrics after each epoch\"\"\"\n    def __init__(self, savepath):\n        super(MetricsCheckpoint, self).__init__()\n        self.savepath = savepath\n        self.history = {}\n    def on_epoch_end(self, epoch, logs=None):\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n        np.save(self.savepath, self.history)\n\ndef plotLearningCurve():\n    \n    plt.figure(figsize=(10,6))\n    metrics = np.load('logs.npy', allow_pickle=True)[()]\n    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n    \n    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n        l = np.array(metrics[k])\n        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n        y = l[x]\n        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')\n    \n    plt.legend(loc=4)\n    plt.axis([0, None, None, None]);\n    plt.grid()\n    plt.xlabel('Number of epochs')\n\ndef plot_learning_curve(history):\n    \n    plt.figure(figsize=(10,6))\n    \n    #model accuracy\n    plt.subplot(1,2,1)\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    \n    # model loss\n    plt.subplot(1,2,2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    \ndef plot_confusion_matrix(cm, normalize=False, cmap=plt.cm.Blues):\n    title='Confusion matrix'\n    classes = {0: 'IDC(-)', 1: 'IDC(+)'}\n    plt.figure(figsize = (6,6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","cfb2fca7":"def build_ANN(num_classes=2,input_shape = (50,50, 3)):\n#     input_shape=(7500,)\n    model=Sequential()\n    model.add(Flatten(input_shape=input_shape))\n    \n    #first layer with 500 neurons and relu activation function \n    model.add(Dense(100, activation=\"relu\"))\n    \n    #second layer with 500 neurons and relu activation function \n    model.add(Dense(100, activation=\"relu\"))\n    \n    #third layer with 500 neurons and relu activation function \n    model.add(Dense(100, activation=\"relu\"))\n    \n    #fourth layer with 500 neurons and relu activation function \n    model.add(Dense(100, activation=\"relu\"))\n    \n    #fifth layer with 500 neurons and relu activation function \n    model.add(Dense(100, activation=\"relu\"))\n    \n    #output sigmoid layer \n    model.add(Dense(num_classes, activation=\"sigmoid\"))\n        \n    return model","d6167bb3":"def build_base_CNN(num_classes=2, input_shape = (50,50, 3)):\n        \n    model = Sequential()\n    model.add(Conv2D(32, (5, 5), activation='relu', input_shape=input_shape))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n    \n    model.add(Conv2D(32, (5, 5), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n    \n    model.add(Flatten())\n    model.add(Dense(64, activation='relu'))\n    \n    model.add(Dropout(0.4))\n    model.add(Dense(num_classes, activation='sigmoid'))\n    \n    return model","d9f98a0f":"def build_final_CNN(num_classes=2, input_shape = (50,50, 3)):\n    \n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n    model.add(MaxPooling2D(pool_size=(3, 3))) \n    model.add(Dropout(0.2))\n    \n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(3, 3)))\n    model.add(Dropout(0.3))\n    \n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    \n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes, activation='sigmoid')) # output 1 value between 0 and 1 : probability to have cancer\n      \n    return model","b2d4a9d2":"def eval_model(model, a, b, c, d, model_name=None, Visualize=False):\n    \n    batch_size = 32\n    epochs = 25\n    \n    model.compile(loss=\"binary_crossentropy\", # Use binary crossentropy as a loss function  \n                  optimizer=\"adam\",\n                  metrics=['accuracy'])\n    \n    model.summary()\n    if Visualize:\n        print(\"Visualizing your neural network.\")\n       # ann_viz(model, title=model_name, filename=model_name)\n    \n    history = model.fit(a,b,\n              batch_size=batch_size,\n              epochs=epochs,\n              verbose=1,\n              validation_data = (c,d),\n            callbacks = [MetricsCheckpoint('logs')])\n    \n    if model_name:\n        model.save(model_name+\".h5\")\n    \n    score = model.evaluate(c,d, verbose=0)\n    print('\\n accuracy:', score[1],'\\n')\n    \n    y_pred = model.predict(c)\n    map_characters = {0: 'IDC(-)', 1: 'IDC(+)'}\n    \n    print('\\n', classification_report(np.where(d > 0)[1], np.argmax(y_pred, axis=1), target_names=list(map_characters.values())), sep='')    \n    Y_pred_classes = np.argmax(y_pred,axis=1) \n    \n    Y_true = np.argmax(d,axis=1) \n    \n    plotLearningCurve()\n    plt.show()  \n    plot_learning_curve(history)\n    plt.show()\n    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n    plot_confusion_matrix(confusion_mtx) \n    plt.show()","1ce3b15a":"eval_model(build_ANN(), X_trainRusFlat, Y_trainRus, X_testRusFlat, Y_testRus, 'ANN')","57f9106b":"eval_model(build_base_CNN(), X_trainRus, Y_trainRus, X_testRus, Y_testRus, 'base_CNN', True)","a84c1cb4":"eval_model(build_final_CNN(), X_trainRus, Y_trainRus, X_testRus, Y_testRus, 'final_CNN', True)","cde52e42":"annmodel = load_model('..\/input\/breast-cancer-detection-using-deep-learning\/ANN.h5')\nbase_cnnmodel = load_model('..\/input\/breast-cancer-detection-using-deep-learning\/base_CNN.h5')\nfinal_cnnmodel = load_model('..\/input\/breast-cancer-detection-using-deep-learning\/final_CNN.h5')","f9869416":"#function to plot image\ndef img_plot(arr,index=0):\n    plt.title('Test Image')\n    plt.imshow(arr[index])\n    ","4da81352":"index1 = 222\nimg_plot(X_testRus, index1)","54f7b174":"label1 = Y_testRus[index1].argmax()\ninput1 = X_testRus[index1:index1+1]\nannpred1 = annmodel.predict(input1)[0].argmax()\nbase_cnnpred1 = base_cnnmodel.predict(input1)[0].argmax()\nfinal_cnnpred1 = final_cnnmodel.predict(input1)[0].argmax()\n\nprint('Predicted Value using ann model',annpred1)\nprint('Predicted Value using base cnn model',base_cnnpred1)\nprint('Predicted Value using final cnn model',final_cnnpred1)\n\nprint(\"\\nTrue Value\",label1,\"\\n\")\n\nprint(\"0 means the sample tested is benign\")","221e7fee":"index2 = 1222\nimg_plot(X_testRus, index2)","3f24111c":"label2 = Y_testRus[index2].argmax()\ninput2 = X_testRus[index2:index2+1]\nannpred2 = annmodel.predict(input2)[0].argmax()\nbase_cnnpred2 = base_cnnmodel.predict(input2)[0].argmax()\nfinal_cnnpred2 = final_cnnmodel.predict(input2)[0].argmax()\n\nprint('Predicted Value using ann model',annpred2)\nprint('Predicted Value using base cnn model',base_cnnpred2)\nprint('Predicted Value using final cnn model',final_cnnpred2)\n\nprint(\"\\nTrue Value\",label2,\"\\n\")\n\nprint(\"1 means the sample tested is malignant\")","ca8ab05a":"- The data is scaled from 0 to 256 but we want it to be scaled from 0 to 1.\n- We also want to set aside 20% of the data for testing.\n- And finally, we will use an undersampling strategy to deal with the imbalanced class sizes.","4318716d":"## *Step 2: Explore Data*","1a43764a":"## *Step 1: Import Modules*","61ff0f00":"## *Step 5: Evaluate Classification Models*","0fed5dc8":"## *Step 4: Define Helper Functions for the Classification Task*","78c0c5a9":"## *Step 3: Preprocess Data*","86479c25":"## Test Case 1","8e2accf3":"## Test Case 2"}}