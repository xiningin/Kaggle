{"cell_type":{"d6815e09":"code","850aa4d5":"code","ffe869c7":"code","a7ef218f":"code","31048f53":"code","40f17724":"code","125f9197":"code","5ebbafba":"code","237d1e32":"code","fe89e575":"code","9e963265":"code","88c77925":"code","e6b8b5a8":"code","42c39e07":"code","7f4da6f7":"code","8e180465":"code","4add5dd3":"code","60cec7d8":"code","ecb8200c":"code","4e81f8b0":"markdown","26ac757c":"markdown","a5328bce":"markdown","1982ceed":"markdown"},"source":{"d6815e09":"import pandas as pd       \nimport matplotlib as mat\nimport matplotlib.pyplot as plt    \nimport numpy as np\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n#from lightgbm import LGBMClassifier\nfrom sklearn.linear_model import LogisticRegression","850aa4d5":"df_train = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/train.csv', index_col = 'id')\nY_train = df_train['target'].copy()\nX_train = df_train.copy().drop('target', axis = 1)\n\nX_test = pd.read_csv('..\/input\/tabular-playground-series-may-2021\/test.csv', index_col = 'id')","ffe869c7":"oof_lgb = pd.read_csv(\"..\/input\/tps05-21-lgbm-tuned-w-hyperopt\/lgbm_train_oof.csv\")\ntest_lgb = pd.read_csv(\"..\/input\/tps05-21-lgbm-tuned-w-hyperopt\/submission.csv\", index_col = 'id')\n\noof_knn = pd.read_csv(\"..\/input\/tps05-21-knn\/knn_train_oof.csv\")\ntest_knn = pd.read_csv(\"..\/input\/tps05-21-knn\/submission.csv\", index_col = 'id')\n\noof_nn = pd.read_csv(\"..\/input\/tps05-21-nn-with-keras-first-nn\/nn_train_oof.csv\")\ntest_nn = pd.read_csv(\"..\/input\/tps05-21-nn-with-keras-first-nn\/submission.csv\", index_col = 'id')\n\noof_lr = pd.read_csv(\"..\/input\/tps05-21-logistic-regression\/lr_train_oof.csv\")\ntest_lr = pd.read_csv(\"..\/input\/tps05-21-logistic-regression\/submission.csv\", index_col = 'id')\n\noof_nb = pd.read_csv(\"..\/input\/tps05-21-multinomialnb\/nb_train_oof.csv\")\ntest_nb = pd.read_csv(\"..\/input\/tps05-21-multinomialnb\/submission.csv\", index_col = 'id')","a7ef218f":"oof_lgb.columns = [('lgb_{0:d}').format(i) for i in range(1,5)]\ntest_lgb.columns = [('lgb_{0:d}').format(i) for i in range(1,5)]\n\noof_knn.columns = [('knn_{0:d}').format(i) for i in range(1,5)]\ntest_knn.columns = [('knn_{0:d}').format(i) for i in range(1,5)]\n\noof_nn.columns = [('nn_{0:d}').format(i) for i in range(1,5)]\ntest_nn.columns = [('nn_{0:d}').format(i) for i in range(1,5)]\n\noof_lr.columns = [('lr_{0:d}').format(i) for i in range(1,5)]\ntest_lr.columns = [('lr_{0:d}').format(i) for i in range(1,5)]\n\noof_nb.columns = [('nb_{0:d}').format(i) for i in range(1,5)]\ntest_nb.columns = [('nb_{0:d}').format(i) for i in range(1,5)]","31048f53":"allpredictions_train = pd.concat([oof_lgb, oof_knn, oof_nn, oof_lr, oof_nb], axis=1)\nallpredictions_test = pd.concat([test_lgb, test_knn, test_nn, test_lr, test_nb], axis=1)","40f17724":"allpredictions_train","125f9197":"allpredictions_test","5ebbafba":"plt.figure(figsize=(16,10))\n\nsns.heatmap(allpredictions_train.corr(), annot = True, fmt=\".2f\", vmin=-1, vmax=1, center= 0, cmap = 'rocket')\nplt.show()","237d1e32":"plt.figure(figsize=(16,10))\n\nsns.heatmap(allpredictions_test.corr(), annot = True, fmt=\".2f\", vmin=-1, vmax=1, center= 0, cmap = 'rocket')\nplt.show()","fe89e575":"n4predictions_train = pd.concat([oof_lgb, oof_knn, oof_nn, oof_lr], axis=1)\nn4predictions_test = pd.concat([test_lgb, test_knn, test_nn, test_lr], axis=1)\n\nn3predictions_train = pd.concat([oof_lgb, oof_knn, oof_nn], axis=1)\nn3predictions_test = pd.concat([test_lgb, test_knn, test_nn], axis=1)","9e963265":"def cv_function (X_train, Y_train, model):\n    \n    kfold = StratifiedKFold(n_splits = 10)\n    logloss = []\n   \n    cv_pred = np.zeros((100000,4))\n    \n    for idx in kfold.split(X=X_train, y=Y_train):\n        train_idx, test_idx = idx[0], idx[1]\n        xtrain = X_train.iloc[train_idx]\n        ytrain = Y_train.iloc[train_idx]\n        xtest = X_train.iloc[test_idx]\n        ytest = Y_train.iloc[test_idx]\n        \n        # fit model for current fold        \n        model.fit(xtrain, ytrain)\n        \n        #create predictions\n        preds = model.predict_proba(xtest)\n        cv_pred[test_idx] = preds\n                              \n        # calculate and append accuracy\n        fold_logloss = metrics.log_loss(ytest,preds)\n        print(\"LogLoss: {0:0.4f}\". format(fold_logloss))\n        logloss.append(fold_logloss)\n        \n    print (np.mean(logloss))\n    #return np.mean(accuracies)\n    return cv_pred","88c77925":"lr_model = LogisticRegression(C = 3.0, random_state = 42, n_jobs = -1)","e6b8b5a8":"#stacking_5_cvpred = cv_function(allpredictions_train, Y_train, lr_model) #1.090460058588747\n#stacking_4_cvpred = cv_function(n4predictions_train, Y_train, lr_model) #1.0903964690708698\n#stacking_3_cvpred = cv_function(n3predictions_train, Y_train, lr_model) #1.0904649018880122\n#1.0904597097069197 after update","42c39e07":"def prediction (X_train, Y_train, model, X_test):\n    \n    kfold = StratifiedKFold(n_splits = 20)\n\n    y_pred = np.zeros((50000,4))\n    train_oof = np.zeros((100000,4))\n    \n    for idx in kfold.split(X=X_train, y=Y_train):\n        train_idx, val_idx = idx[0], idx[1]\n        xtrain = X_train.iloc[train_idx]\n        ytrain = Y_train.iloc[train_idx]\n        xval = X_train.iloc[val_idx]\n        yval = Y_train.iloc[val_idx]\n        \n        # fit model for current fold\n        model.fit(xtrain, ytrain)\n        \n        #create predictions    \n        y_pred += model.predict_proba(X_test)\/kfold.n_splits\n        print(y_pred)\n               \n        val_pred = model.predict_proba(xval)\n        # getting out-of-fold predictions on training set\n        train_oof[val_idx] = val_pred\n        \n        # calculate and append logloss\n        fold_logloss = metrics.log_loss(yval,val_pred)\n        print(\"Logloss: {0:0.5f}\". format(fold_logloss))\n  \n    return y_pred, train_oof","7f4da6f7":"#stack_pred, train_oof = prediction (allpredictions_train, Y_train, lr_model, allpredictions_test)\n#stack_pred, train_oof = prediction (n4predictions_train, Y_train, lr_model, n4predictions_test)\nstack_pred, train_oof = prediction (n3predictions_train, Y_train, lr_model, n3predictions_test)","8e180465":"train_oof = pd.DataFrame(train_oof, columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4'])\ntrain_oof","4add5dd3":"pred_test = pd.DataFrame(stack_pred, columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4'])\npred_test","60cec7d8":"train_oof.to_csv('stack_train_oof.csv', index=False)\ntrain_oof","ecb8200c":"output = pred_test\noutput['id'] = X_test.index\noutput.to_csv('submission.csv', index=False)\n\noutput","4e81f8b0":"## Testing Combinations","26ac757c":"## Making Predictions","a5328bce":"# <center>Tabular Playground Series - May\/2021<center>\n## <center>Model Stacking using Logistic Regression as Meta-Learner<center>\n---\n\nModels used for stacking:\n- [LightGBM](https:\/\/www.kaggle.com\/jonaspalucibarbosa\/tps05-21-lgbm-tuned-w-hyperopt)\n- [Neural Network](https:\/\/www.kaggle.com\/jonaspalucibarbosa\/tps05-21-nn-with-keras-first-nn)\n- KNN (w\/Log Transformation and Standard Scaler applied to features)\n- Logistic Regression (w\/Log Transformation applied to features)\n- Multinomial Naive Bayers (w\/Log Transformation applied to features)\n    \n\nMy other notebooks in this competition:\n- [Tabular Playground Series - May\/2021: LightGBM Tuned with Hyperopt](https:\/\/www.kaggle.com\/jonaspalucibarbosa\/tps05-21-lgbm-tuned-w-hyperopt)\n- [Tabular Playground Series - May\/2021: Neural Network with Keras](https:\/\/www.kaggle.com\/jonaspalucibarbosa\/tps05-21-nn-with-keras-first-nn)    ","1982ceed":"## Importing Libraries and Datasets"}}