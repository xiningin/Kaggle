{"cell_type":{"56924eba":"code","1acf7c14":"code","d09e6dbb":"code","3ee84d42":"code","580f1092":"code","efee47ac":"code","197bbe49":"code","f7f5e6ba":"code","96a7e70b":"code","e5bb2967":"code","2395353d":"code","6b58532c":"code","9112f03a":"code","4d63b959":"code","0cd677ab":"code","0fc74321":"code","1bef06fc":"code","22abbba0":"code","42de3f15":"code","994e462b":"code","7d9d5737":"code","a9772c27":"code","5783825d":"code","ae483e56":"code","0d077018":"code","907cad29":"code","37e94cd0":"code","f50653a3":"code","05b4c3a8":"code","47dbf518":"code","390bc328":"code","fbe37296":"code","463268f7":"code","c09b471d":"code","1dce3ca6":"code","ba9a3e3f":"code","b3f529bd":"code","57e4d8d0":"code","f2c7e84e":"code","bc3596e8":"code","9fc8480e":"code","d57ce258":"code","1dcaf062":"code","1cd5b930":"markdown","350d6577":"markdown","62451bf1":"markdown","05ce2c7d":"markdown","835923fe":"markdown","e295ea8e":"markdown","8a2cbbc0":"markdown","4b4314e8":"markdown","9efd636c":"markdown","d4d085a2":"markdown","0ce58a92":"markdown","dfbc091a":"markdown"},"source":{"56924eba":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport cv2\nimport random\nfrom random import randint\nimport time\n\n\nimport torch\nfrom torch.utils.data import Dataset, random_split, DataLoader\nimport torch.nn.functional as F\nimport torch.nn as nn\n\nfrom PIL import Image\nfrom scipy import ndimage\n\nimport torchvision\nimport torchvision.models as models\nimport torchvision.transforms as T\nfrom torchvision.utils import make_grid\nfrom torchvision.datasets.utils import download_url\nfrom torchvision.datasets import ImageFolder\n\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.utils import shuffle","1acf7c14":"DATA_DIR = '..\/input\/10-monkey-species'\n\nTRAIN_DIR = DATA_DIR + '\/training\/training\/'                           \nVAL_DIR = DATA_DIR + '\/validation\/validation\/'                             \nLABEL_FIL=DATA_DIR +\"\/monkey_labels.txt\"","d09e6dbb":"labels ={   0 : 'mantled_howler',\n            1 : 'patas_monkey',\n            2 : 'bald_uakari',\n            3 : 'japanese_macaque',\n            4 : 'pygmy_marmoset',\n            5 : 'white_headed_capuchin',\n            6 : 'silvery_marmoset',\n            7 : 'common_squirrel_monkey',\n            8 : 'black_headed_night_monkey',\n            9 : 'nilgiri_langur' }\n","3ee84d42":"# Load the paths to the images in a directory\n\ndef load_images_from_folder(folder,only_path = False, label = \"\"):\n    if only_path == False:\n        images = []\n        file_name=[]\n        for filename in os.listdir(folder):\n            img = plt.imread(os.path.join(folder,filename))\n            \n            if img is not None:\n                end=filename.find(\".\")\n                file_name.append(file[0:end])\n                images.append(img)\n                \n        return images, file_name\n    else:\n        path = []\n        for filename in os.listdir(folder):\n            img_path = os.path.join(folder,filename)\n            if img_path is not None:\n                path.append([label,img_path])\n        return path","580f1092":"# Load the paths on the images\nimages = []\npath = TRAIN_DIR\nfor f in os.listdir(path):\n    if \"jpg\" in os.listdir(path+f)[0]:\n        images += load_images_from_folder(path+f,True,label = f)\n      \n    else: \n        for d in os.listdir(path+f):\n            images += load_images_from_folder(path+f+\"\/\"+d,True,label = f)\n            \n                        \n# Create a dataframe with the paths and the label for each monkey species\ntrain_df = pd.DataFrame(images, columns = [\"monkey_id\", \"path_img\"])\ntrain_len=len(train_df[\"path_img\"])\n\n\nmonkey_label=[]\nmonkey_name=[]\nfor i in range(train_len):\n    temp=train_df.monkey_id[i][1]\n    temp=int(temp)\n    \n    monkey_label.append(temp)\n    monkey_name.append(labels[temp])\n\n\ntrain_df['monkey_label'] = monkey_label\ntrain_df['monkey_name'] =monkey_name\n\n\ntrain_df.head()\n\n\n\n","efee47ac":"# Load the paths on the images\nimages = []\npath = VAL_DIR\nfor f in os.listdir(path):\n    if \"jpg\" in os.listdir(path+f)[0]:\n        images += load_images_from_folder(path+f,True,label = f)\n      \n    else: \n        for d in os.listdir(path+f):\n            images += load_images_from_folder(path+f+\"\/\"+d,True,label = f)\n            \n                        \n# Create a dataframe with the paths and the label for each monkey species\nval_df = pd.DataFrame(images, columns = [\"monkey_id\", \"path_img\"])\nval_len=len(val_df[\"path_img\"])\n\n\nmonkey_label=[]\nmonkey_name=[]\nfor i in range(val_len):\n    temp=val_df.monkey_id[i][1]\n    temp=int(temp)\n    \n    monkey_label.append(temp)\n    monkey_name.append(labels[temp])\n\n\nval_df['monkey_label'] = monkey_label\nval_df['monkey_name'] =monkey_name\n\n\nval_df.head()\n\n","197bbe49":"train_len\nprint('Number of images in Training file:', train_len)\nval_len\nprint('Number of images in Validation file:', val_len)\n\n\nno_labels=len(train_df[\"monkey_id\"].unique())\nprint('Number of Monkey species:', no_labels)\n","f7f5e6ba":"bar = train_df[\"monkey_name\"].value_counts(ascending=True).plot.bar(figsize = (30,5))\nplt.title(\"Distribution of the Monkeys\", fontsize = 20)\nbar.tick_params(labelsize=16)\nplt.show()","96a7e70b":"train_df[\"monkey_name\"].value_counts(ascending=False)","e5bb2967":"# Shuffle the dataset\n\ntrain_df = shuffle(train_df, random_state = 0)\ntrain_df = train_df.reset_index(drop=True)\n\n\nfig, axes = plt.subplots(nrows=4, ncols=5, figsize=(15, 15),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n   # j=randint(50*(i),50*(i+1))\n    j=i\n    ax.imshow(plt.imread(train_df.path_img[j]))\n    ax.set_title(train_df.monkey_name[j])\nplt.tight_layout()\nplt.show()","2395353d":"imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n\ntrain_tfms = T.Compose([\n    T.Resize((512,512)),\n#    T.CenterCrop(256),\n#    T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n#    T.RandomCrop(32, padding=4, padding_mode='reflect'),\n    T.RandomHorizontalFlip(), \n    T.RandomRotation(10),\n    T.ToTensor(),\n#    T.Normalize(*imagenet_stats,inplace=True), \n#    T.RandomErasing(inplace=True)\n])\n\nvalid_tfms = T.Compose([\n    T.Resize((512,512)),\n#    T.CenterCrop(256),\n    T.ToTensor(),\n#    T.Normalize(*imagenet_stats)\n])\n","6b58532c":"train_ds = ImageFolder ( TRAIN_DIR , transform=train_tfms )\nval_ds = ImageFolder ( VAL_DIR , transform=valid_tfms ) \nlen(train_ds), len(val_ds)","9112f03a":"def show_sample(img, target, invert=True):\n    if invert:\n        plt.imshow(1 - img.permute((1, 2, 0)))\n    else:\n        plt.imshow(img.permute(1, 2, 0))\n    print('Labels:', target)","4d63b959":"show_sample(*train_ds[83])","0cd677ab":"show_sample(*train_ds[228])","0fc74321":"np.random.seed(42)\n\n","1bef06fc":"batch_size = 16","22abbba0":"train_dl = DataLoader(train_ds, batch_size, shuffle=True, \n                          num_workers=4, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size, \n                        num_workers=4, pin_memory=True)","42de3f15":"def show_batch(dl, invert=True):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(32, 16))\n        ax.set_xticks([]); ax.set_yticks([])\n        data = 1-images if invert else images\n        ax.imshow(make_grid(data, nrow=8).permute(1, 2, 0))\n        break","994e462b":"show_batch(train_dl, invert=True)","7d9d5737":"show_batch(train_dl, invert=False)","a9772c27":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass MonkeyClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","5783825d":"class MonkeyCnnModel(MonkeyClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n             nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),  # output: 32 x 128 x 128\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n             nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 64 x 64 x 64\n\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n             nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),  # output: 64 x 32 x 32\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),   # output: 128 x 16 x 16\n\n            nn.Flatten(), \n            nn.Linear(128*16*16, 2048),\n            nn.ReLU(),\n            nn.Linear(2048, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 10))\n        \n    def forward(self, xb):\n        return self.network(xb)","ae483e56":"class MonkeyResnet34(MonkeyCnnModel):\n    def __init__(self):\n        super().__init__()\n        # Use a pretrained model\n        self.network = models.resnet34(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Linear(num_ftrs, 10)\n    \n    def forward(self, xb):\n        return torch.sigmoid(self.network(xb))","0d077018":"model = MonkeyResnet34()\nmodel","907cad29":"for images, labels in train_dl:\n    print('images.shape:', images.shape)\n    out = model(images)\n    print('out.shape:', out.shape)\n    print('out[0]:', out[0])\n    break","37e94cd0":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","f50653a3":"device = get_default_device()\ndevice","05b4c3a8":"train_loader = DeviceDataLoader(train_dl, device)\nval_loader = DeviceDataLoader(val_dl, device)\nto_device(model, device);","47dbf518":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","390bc328":"model = to_device(MonkeyResnet34(), device)","fbe37296":"evaluate(model, val_loader)","463268f7":"num_epochs = 2\nlr = 0.0001\nopt_func = torch.optim.Adam","c09b471d":"%%time\nstarttime= time.time()\nhistory = fit(num_epochs, lr, model, train_loader, val_loader, opt_func)","1dce3ca6":"lr=lr\/10\nhistory += fit(num_epochs, lr, model, train_loader, val_loader, opt_func)","ba9a3e3f":"#lr=lr\/10\n#history += fit(num_epochs, lr, model, train_loader, val_loader, opt_func)","b3f529bd":"endtime=time.time()\n\nduration=endtime-starttime\ntrain_time=time.strftime('%M:%S', time.gmtime(duration))\n","57e4d8d0":"train_time","f2c7e84e":"def plot_scores(history):\n    scores = [x['val_acc'] for x in history]\n    plt.plot(scores, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('accuracy vs. No. of epochs');","bc3596e8":"plot_scores(history)","9fc8480e":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","d57ce258":"plot_losses(history)","1dcaf062":"weights_fname = 'Monkey-resnet.pth'\ntorch.save(model.state_dict(), weights_fname)","1cd5b930":"# Model - Transfer Learning","350d6577":"As there are 10 monkey species, a default accuracy of around 10% is expected \nThe evaluate model also shaows an intial \"val_acc\" of 10% or 0.1","62451bf1":"# Training","05ce2c7d":"## Preparing the Data","835923fe":"# Monkey Species Classification Using CNN & Resnet34","e295ea8e":"# Save and Commit","8a2cbbc0":"# Data holders","4b4314e8":"# Define classes and functions","9efd636c":"In this project, I am to build a model that can classify monkeys into the 10 different species.\n\n            0 : 'mantled_howler',\n            1 : 'patas_monkey',\n            2 : 'bald_uakari',\n            3 : 'japanese_macaque',\n            4 : 'pygmy_marmoset',\n            5 : 'white_headed_capuchin',\n            6 : 'silvery_marmoset',\n            7 : 'common_squirrel_monkey',\n            8 : 'black_headed_night_monkey',\n            9 : 'nilgiri_langur'\n            \n I used PyTorch, CNN and Resnet34 pretrained model for the classification\n \n I obtain over 99% accuracy in around 5 minutes of training! ","d4d085a2":"# Import libraries","0ce58a92":"Let us load the required directories and files","dfbc091a":"In the start always import the libraries that you feel you may use or need. Over time, build a list of libraries that you use and use it in all the notebooks you are working. You will naturally strat using some of the libraries that you are comfortable with and this will help."}}