{"cell_type":{"74eae6b8":"code","011119a8":"code","e38b0ed2":"code","c10126f8":"code","5fafc5eb":"code","1628eb77":"code","697eb0e5":"code","6d2aec1f":"code","7fc19a75":"code","db4c241b":"code","0983879d":"code","a7bd709e":"code","bafcb7c3":"code","964f7964":"code","b2e2b216":"code","25a091c9":"code","b8e59d87":"code","1c241cce":"code","00379ec8":"code","5aba03df":"code","452052c4":"code","99b34e5e":"code","0f7cfb6a":"code","ea901425":"code","a04a956a":"code","da757b4e":"code","cedf0ca5":"code","a2954daa":"code","75a6cedf":"code","c3d32e8e":"code","3c398377":"code","5100eb84":"code","f1e5104e":"code","aff70d0f":"code","bb1bd2d7":"markdown","ef18e1e1":"markdown","fc1334a1":"markdown","2fb6be27":"markdown","da5dd5e4":"markdown","3437cdb5":"markdown","24751543":"markdown","f65fa962":"markdown","86b33c9f":"markdown"},"source":{"74eae6b8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport copy\nimport sys\nfrom PIL import Image\nimport time \nfrom tqdm.autonotebook import tqdm\nimport random\nimport gc\nimport cv2\nimport scipy\nimport math\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom sklearn.metrics import fbeta_score\n\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader,Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.optim.optimizer import Optimizer\nimport torch.backends.cudnn as cudnn\nfrom torch.autograd import Variable\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR, _LRScheduler\n\n# Any results you write to the current directory are saved as output.","011119a8":"import scipy.special\n\nSEED = 42\nbase_dir = '..\/input\/'\ndef seed_everything(seed=SEED):\n    random.seed(seed)\n    os.environ['PYHTONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nseed_everything(SEED)","e38b0ed2":"train_df = pd.read_csv('..\/input\/train.csv')\nlabels_df = pd.read_csv('..\/input\/labels.csv')\ntest_df = pd.read_csv('..\/input\/sample_submission.csv')\n\ntr, val = train_test_split(train_df['id'], test_size=0.15, random_state=SEED)\n\nimg_class_dict = {k:v for k, v in zip(train_df.id, train_df.attribute_ids)}\n\ndef get_label(attribute_ids):\n    attribute_ids = attribute_ids.split()\n    one_hot = np.zeros(1103, dtype=np.int)\n    for _,ids in enumerate(attribute_ids):\n        one_hot[int(ids)] = 1\n    return one_hot","c10126f8":"print(train_df.columns)\nprint(labels_df.columns)","5fafc5eb":"classes =train_df['attribute_ids'].value_counts().to_frame().reset_index()\nclasses.rename(columns={'index': 'classes', 'attribute_ids':'counts'}, inplace=True)","1628eb77":"print(classes)","697eb0e5":"#classes['classes'] = classes['classes'].apply(get_label)","6d2aec1f":"classes['ratio'] = classes['counts']\/train_df.shape[0]","7fc19a75":"classes.head(10)","db4c241b":"def get_label_name(attribute_ids):\n    attribute_ids = attribute_ids.split()\n    attribute_name = []\n    for _,ids in enumerate(attribute_ids):\n        attribute_name.append(labels_df.loc[labels_df['attribute_id']==int(ids)])\n    return attribute_name","0983879d":"#train_df['attribute_name'] = train_df['attribute_ids'].apply(get_label_name)\n#too slow","a7bd709e":"train_df['count'] = train_df.groupby(['attribute_ids'])['id'].transform('count')","bafcb7c3":"train_df = train_df.sort_values(by='attribute_ids')","964f7964":"#train_df['attribute_ids'] = train_df['attribute_ids'].apply(get_label)","b2e2b216":"train_df.head(30)","25a091c9":"grouped_id = train_df.groupby('attribute_ids')['id']","b8e59d87":"collect_image_names = {}\n\nfor key in classes['classes']:\n    name = grouped_id.get_group(key).values[0]\n    count = grouped_id.get_group(key).values.shape[0]\n    collect_image_names[name] = count","1c241cce":"import operator\nsorted_collect_image_names = sorted(collect_image_names.items(), key=operator.itemgetter(1))\nsorted_collect_image_names.reverse()\nprint(len(sorted_collect_image_names))","00379ec8":"print(sorted_collect_image_names[:10])","5aba03df":"image_name = sorted_collect_image_names[0][0]\nattribute_ids = train_df.loc[train_df['id']==image_name]['attribute_ids'].values[0]\nprint(attribute_ids.split())","452052c4":"c = 1\nplt.figure(figsize=[20, 20])\nfor idx in range(10):\n    image_name = sorted_collect_image_names[idx][0]\n    img = cv2.imread(\"..\/input\/train\/{}.png\".format(image_name))[...,[2,1,0]]\n    plt.subplot(5,2,c)\n    plt.imshow(img)\n    \n    attribute_ids = train_df.loc[train_df['id']==image_name]['attribute_ids'].values[0].split()\n    attribute_name = []\n    for _,ids in enumerate(attribute_ids):\n        attribute_name.append(labels_df.loc[labels_df['attribute_id']==int(ids)]['attribute_name'].values[0])\n    plt.title(\"train image {} count {}\".format(attribute_name, sorted_collect_image_names[idx][1]))\n    c += 1\nplt.show()","99b34e5e":"c = 1\nplt.figure(figsize=[20,20])\n\nsize = len(sorted_collect_image_names)\n\nfor idx in range(size-10, size):\n    image_name = sorted_collect_image_names[idx][0]\n    img = cv2.imread(\"..\/input\/train\/{}.png\".format(image_name))[...,[2,1,0]]\n    plt.subplot(5,2,c)\n    plt.imshow(img)\n    \n    attribute_ids = train_df.loc[train_df['id']==image_name]['attribute_ids'].values[0].split()\n    attribute_name = []\n    for _,ids in enumerate(attribute_ids):\n        attribute_name.append(labels_df.loc[labels_df['attribute_id']==int(ids)]['attribute_name'].values[0])\n    plt.title(\"train image {} count {}\".format(attribute_name, sorted_collect_image_names[idx][1]))\n    c += 1\nplt.show()","0f7cfb6a":"name = grouped_id.get_group(classes['classes'][0]).values[0]\ncount = grouped_id.get_group(classes['classes'][0]).values.shape[0]","ea901425":"c = 1\nplt.figure(figsize=[20,20])\n\nmost_frequent_class_top_10 = {}\n\nfor i in range(10):\n    name = grouped_id.get_group(classes['classes'][0]).values[i]\n    count = grouped_id.get_group(classes['classes'][0]).values.shape[0]\n    most_frequent_class_top_10[name] = count\n\nsize = len(most_frequent_class_top_10)\n\nfor element in most_frequent_class_top_10:\n    image_name = element\n    img = cv2.imread(\"..\/input\/train\/{}.png\".format(image_name))[...,[2,1,0]]\n    plt.subplot(5,2,c)\n    plt.imshow(img)\n    \n    attribute_ids = train_df.loc[train_df['id']==image_name]['attribute_ids'].values[0].split()\n    attribute_name = []\n    for _,ids in enumerate(attribute_ids):\n        attribute_name.append(labels_df.loc[labels_df['attribute_id']==int(ids)]['attribute_name'].values[0])\n    plt.title(\"train image {} count {}\".format(attribute_name, most_frequent_class_top_10[element]))\n    c += 1\nplt.show()","a04a956a":"category_count = {}\n\nfor i in range(1103):\n    category_count[i] = 0","da757b4e":"for key in classes['classes']:\n    category_name = key.split()\n    count = grouped_id.get_group(key).values.shape[0]\n    for element in category_name:\n        category_count[int(element)] += count","cedf0ca5":"sorted_category_count = sorted(category_count.items(), key=operator.itemgetter(1))\nsorted_category_count.reverse()","a2954daa":"sorted_category_count_frame = pd.DataFrame.from_dict(sorted_category_count)\nsorted_category_count_frame.columns=['attribute_id', 'count']\nsorted_category_count_frame['ratio'] = sorted_category_count_frame['count']\/train_df.shape[0]","75a6cedf":"sorted_category_count_frame.head(30)","c3d32e8e":"category_name_count = {}\n\nfor element in sorted_category_count:\n    key = element[0]\n    name = labels_df[labels_df['attribute_id']==key]['attribute_name'].values[0]\n    category_name_count[name] = element[1]","3c398377":"sorted_category_name_count = sorted(category_name_count.items(), key=operator.itemgetter(1))\nsorted_category_name_count.reverse()","5100eb84":"sorted_sorted_category_name_count_frame = pd.DataFrame.from_dict(sorted_category_name_count)\nsorted_sorted_category_name_count_frame.columns=['attribute_name', 'count']\nsorted_sorted_category_name_count_frame['ratio'] = sorted_sorted_category_name_count_frame['count']\/train_df.shape[0]","f1e5104e":"sorted_sorted_category_name_count_frame.head(30)","aff70d0f":"sorted_category_count_frame.to_csv('sorted_category_count_frame.csv', index=False)","bb1bd2d7":"**We can see that the most frequent categories are 'tag::men'(ratio 0.18), 'tag::women'(ratio 0.13), 'tag::flowers'(ratio 0.07), 'culture::...'(...)**","ef18e1e1":"# Let's see the samples","fc1334a1":"# **Let's see 10 images from the most frequent class (one class)**<br\/>\n**the most frequent class is 'culture::american'+'tag::actresses'+'tag::portaits'+'tag::women'**","2fb6be27":"# We get all classes of labels ","da5dd5e4":"# **Let's see the top 10 most frequent classes (one image per class)**","3437cdb5":"# **We collect one image from one class**","24751543":"# **Let's see the top 10 least frequent classes (one image per class)**","f65fa962":"**WE have 50238 classes(too many) which means the samples in one class are few comparing to the whole dataset.**<br\/>\n**If we use triplet-loss an anchor may hardly find a positive sample in a batch.**","86b33c9f":"# Let's get sorted categories count"}}