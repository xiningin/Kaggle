{"cell_type":{"d54ad162":"code","48cc74d0":"code","a09e508b":"code","187d6775":"code","d15ea248":"code","e0c5704b":"code","923e77c0":"code","23edd33b":"code","a98a96d9":"code","7081c4e8":"code","5d739841":"code","a21cb940":"code","6a4022ea":"code","8e69381f":"code","73968902":"code","fb245d45":"code","9785f423":"code","2eeaffca":"code","bf00e0a1":"code","ad263c08":"code","c5e43d9a":"code","ef2e7f12":"code","b4a1ddbf":"code","fc8199db":"code","bcc8348b":"code","8e169c47":"markdown","ee6f0439":"markdown","ff9bef76":"markdown","d20374d1":"markdown","00e5a2b5":"markdown","537df68a":"markdown","23c5ab0d":"markdown","e104822e":"markdown","048a9eb4":"markdown","60ec7c3f":"markdown","31b90183":"markdown","2858a8c4":"markdown","423cfa65":"markdown","008e6ad5":"markdown","b07ebed9":"markdown","0b1a5b1c":"markdown","eb966884":"markdown","de24f9ac":"markdown","5357855a":"markdown","16d2e7b7":"markdown","b7fe2fd1":"markdown","a1e32027":"markdown","bbff7838":"markdown","c1cb1ed3":"markdown","773fa21c":"markdown"},"source":{"d54ad162":"!conda install gdcm -c conda-forge -y","48cc74d0":"import cv2\nimport datetime\nimport gc\nimport glob\nimport imagehash\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport PIL\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport sys\nimport tqdm","a09e508b":"base_path = '..\/input\/siim-covid19-detection'","187d6775":"def read_dicom_image(image_file, voi_lut=True, fix_monochrome=True):\n    \"\"\"\n    Reads a dicom image from a file an returns a numpy array.\n    References: https:\/\/www.kaggle.com\/trungthanhnguyen0502\/eda-vinbigdata-chest-x-ray-abnormalities\n    Args:\n        image_file:\n        voi_lut:\n        fix_monochrome:\n\n    Returns:\n\n    \"\"\"\n    dicom = pydicom.read_file(image_file)\n    # VOI LUT (if available by DICOM device) is used to\n    # transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data\n\n\ndef string2boxes(string):\n    strings = string.split()\n    if strings[0].lower() == 'none':\n        return []\n    else:\n        return [{'class': strings[idx],\n                 'conf': float(strings[idx+1]),\n                 'x1': float(strings[idx+2]),\n                 'y1': float(strings[idx+3]),\n                 'x2': float(strings[idx+4]),\n                 'y2': float(strings[idx+5]),\n                 } for idx in range(0, len(strings), 6)]\n\n    \ndef plot_image(image, boxes=None, size=(5,5), title=None, columns=4):\n    def plot_img(image, boxes=None, title=None):\n        if isinstance(image, str):\n            image_id = os.path.splitext(os.path.split(image)[1])[0]\n            df = df_image.loc[df_image['id'] == image_id + '_image']\n            boxes = string2boxes(df['label'].iloc[0]) if len(df) > 0 else None\n            image = read_dicom_image(image)\n        image = np.stack([image] * 3, axis=-1)\n        if boxes is not None:\n            for box in boxes:\n                image = cv2.rectangle(image, (int(box['x1']), int(box['y1'])), (int(box['x2']), int(box['y2'])), [0, 255, 0], 10)\n        plt.axis('on')\n        plt.imshow(image, cmap='gray')\n        if title is not None:\n            plt.title(title)\n\n    plt.figure(figsize=size)\n    if isinstance(image, list):\n        num = len(image)\n        columns = min(columns, num)\n        rows = math.ceil(num \/ columns)\n\n        for index, single_image in enumerate(image):\n            plt.subplot(rows, columns, index + 1)\n            plot_img(single_image, boxes=boxes, title=None if title is None else title[index])\n    else:\n        plot_img(image, boxes=boxes, title=title)\n    plt.show()\n\n\ndef images_find_duplicates(image_files, threshold=0.9):\n    \"\"\"\n    Function to find duplicates in images.\n    References: https:\/\/www.kaggle.com\/appian\/let-s-find-out-duplicate-images-with-imagehash\n    Args:\n        image_files:\n        threshold:\n\n    Returns:\n\n    \"\"\"\n    funcs = [imagehash.average_hash, imagehash.phash, imagehash.dhash, imagehash.whash]\n    image_ids = image_files\n    hashes = []\n    for file in tqdm.tqdm(image_files):\n        image = PIL.Image.fromarray(read_dicom_image(file))\n        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))\n    hashes_all = np.array(hashes)\n\n    # Comparisons without Pytorch\n    sim_list = []\n    for i in tqdm.tqdm(range(hashes_all.shape[0])):\n        sim_list.append(np.sum(hashes_all[i] == hashes_all, axis=1)\/256)\n\n    # nxn-matrix of similarities (n = # of images), upper triangular matrix\n    similarities = np.triu(np.array(sim_list), 1)\n\n    idx_pair = np.where(similarities > threshold)\n    df_pairs = pd.DataFrame({'image1': [image_ids[i] for i in list(idx_pair[0])],\n                             'image2': [image_ids[i] for i in list(idx_pair[1])],\n                             'similarity': [similarities[i1, i2] for i1, i2 in zip(idx_pair[0], idx_pair[1])]})\n\n    idx_group = np.zeros(len(image_files))\n    group_id = 1\n    for i1, i2 in zip(idx_pair[0], idx_pair[1]):\n        if idx_group[i1] == 0 and idx_group[i2] == 0:\n            idx_group[i1] = group_id\n            idx_group[i2] = group_id\n            group_id += 1\n        elif idx_group[i1] != 0 and idx_group[i2] == 0:\n            idx_group[i2] = idx_group[i1]\n        elif idx_group[i1] == 0 and idx_group[i2] != 0:\n            idx_group[i1] = idx_group[i2]\n        elif idx_group[i1] != 0 and idx_group[i2] != 0 and idx_group[i1] != idx_group[i2]:\n            common_id = min(idx_group[i1], idx_group[i2])\n            idx_group[idx_group == idx_group[i1]] = common_id\n            idx_group[idx_group == idx_group[i2]] = common_id\n\n    group_list = []\n    for i in range(1, group_id + 1):\n        group_ids = list(np.where(idx_group == i)[0])\n        if len(group_ids) > 0:\n            group_list.append([image_ids[j] for j in group_ids])\n\n    return df_pairs, group_list","d15ea248":"print('Directories:')\nprint('\\n'.join([dir for dir in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, dir))]))\nprint('\\nFiles:')\nprint('\\n'.join([dir for dir in os.listdir(base_path) if not os.path.isdir(os.path.join(base_path, dir))]))","e0c5704b":"df_study = pd.read_csv(os.path.join(base_path, 'train_study_level.csv'))\nprint(f'Number of rows: {len(df_study)}')\ndisplay(df_study)","923e77c0":"df_study['Num Labels'] = df_study.iloc[:,1:].sum(axis=1)\nprint(f'Minimum number of labels per row: {min(df_study[\"Num Labels\"])}')\nprint(f'Maximum number of labels per row: {max(df_study[\"Num Labels\"])}')\nprint(f'Number of unique ids: {len(df_study[\"id\"].unique())}')","23edd33b":"plt.figure(figsize=(10,5))\nplt.bar([1,2,3,4], df_study.iloc[:,1:5].sum(axis=0), tick_label=df_study.columns[1:5])\nplt.xlabel('Class')\nplt.ylabel('Frequency')\nplt.grid()","a98a96d9":"df_image = pd.read_csv(os.path.join(base_path, 'train_image_level.csv'))\nprint(f'Number of rows: {len(df_image)}')\ndisplay(df_image)","7081c4e8":"dir_studies = glob.glob(os.path.join(base_path, 'train\/*'))\nprint(f'Number of studies: {len(dir_studies)}')\ndir_series = [glob.glob(dir_study + '\/*') for dir_study in dir_studies]\ncount_series = pd.Series([len(dir_ser) for dir_ser in dir_series])\n_ = plt.hist(count_series)\nplt.title('Number of series per study')\nplt.xlabel('Number of series per study')\nplt.ylabel('Frequency')\nplt.grid()\nplt.show()\nprint(count_series.value_counts().sort_index().to_string())","5d739841":"dir_images = [glob.glob(dir_study + '\/*\/*.dcm') for dir_study in dir_studies]\ndf_study_train = pd.DataFrame({'study_id': [s.split('\/')[-1] for s in dir_studies]})\ndf_study_train['num_images'] = [len(dir_img) for dir_img in dir_images]\n_ = plt.hist(df_study_train['num_images'])\nplt.title('Number of images per study')\nplt.xlabel('Number of images per study')\nplt.ylabel('Frequency')\nplt.grid()\nplt.show()\nprint(df_study_train['num_images'].value_counts().sort_index().to_string() + '\\n')\nprint('Studies with the most images')\ndisplay(df_study_train.sort_values('num_images', ascending=False)[0:10])\ndf_study_train.to_csv('study_train.csv', index=False)","a21cb940":"train_files = sorted(glob.glob(os.path.join(base_path, 'train\/*\/*\/*.dcm')))\nprint(f'Number of training files: {len(train_files)}')","6a4022ea":"plot_image(train_files[7], size=(20,20))\nplot_image(train_files[0:16], size=(20,20))","8e69381f":"df_image['box_dict'] = df_image['label'].apply(lambda x: string2boxes(x))\ndf_image['num_boxes'] = df_image['box_dict'].apply(lambda x: len(x))\noutput = plt.hist(df_image['num_boxes'])\nplt.xlabel('Number of bounding boxes')\nplt.ylabel('Frequency')\nplt.grid()\nplt.show()\nprint(df_image['num_boxes'].value_counts().sort_index().to_string())","73968902":"img_list = []\nfor file in tqdm.tqdm(train_files):\n    img = read_dicom_image(file)\n    img_list.append({'file': file, 'width': img.shape[1], 'height': img.shape[0]})\ndf_images = pd.DataFrame(img_list)\ndf_images['ratio'] = df_images['width'] \/ df_images['height']\nplt.figure(figsize=(18,5))\nplt.subplot(1,2,1)\nplt.hist(df_images['width'])\nplt.title('Width Distribution of the Images')\nplt.xlabel('Width')\nplt.ylabel('Frequency')\nplt.grid()\nplt.subplot(1,2,2)\nplt.hist(df_images['height'])\nplt.title('Height Distribution of the Images')\nplt.xlabel('Height')\nplt.ylabel('Frequency')\nplt.grid()\nplt.show()\nplt.figure(figsize=(18,5))\nplt.subplot(1,2,1)\nplt.scatter(df_images['width'], df_images['height'])\nplt.title('Width and Height Distribution of the Images')\nplt.xlabel('Width')\nplt.ylabel('Height')\nplt.grid()\nplt.subplot(1,2,2)\nplt.hist(df_images['ratio'], bins = 20)\nplt.title('Width to Height Ratio of the Images')\nplt.xlabel('Width to Height Ratio')\nplt.ylabel('Frequency')\nplt.grid()","fb245d45":"df_pairs, group_list = images_find_duplicates(train_files[0:200], threshold=0.95)\nprint(f'\\nNumber of duplicate pairs: {len(df_pairs)}')\nprint(f'Number of duplicate groups: {len(group_list)}')","9785f423":"for i, group in enumerate(group_list):\n    group_ids = [os.path.basename(file) for file in group]\n    print(f'\\nGroup {i+1}')\n    plot_image(group, size=(20, 10), title=group_ids, columns=8)","2eeaffca":"dir_studies = glob.glob(os.path.join(base_path, 'test\/*'))\nprint(f'Number of studies: {len(dir_studies)}')\ndir_series = [glob.glob(dir_study + '\/*') for dir_study in dir_studies]\ncount_series = pd.Series([len(dir_ser) for dir_ser in dir_series])\n_ = plt.hist(count_series)\nplt.title('Number of series per study')\nplt.xlabel('Number of series per study')\nplt.ylabel('Frequency')\nplt.grid()\nplt.show()\nprint(count_series.value_counts().sort_index().to_string())","bf00e0a1":"dir_images = [glob.glob(dir_study + '\/*\/*.dcm') for dir_study in dir_studies]\ndf_study_test = pd.DataFrame({'study_id': [s.split('\/')[-1] for s in dir_studies]})\ndf_study_test['num_images'] = [len(dir_img) for dir_img in dir_images]\n_ = plt.hist(df_study_test['num_images'])\nplt.title('Number of images per study')\nplt.xlabel('Number of images per study')\nplt.ylabel('Frequency')\nplt.grid()\nplt.show()\nprint(df_study_test['num_images'].value_counts().sort_index().to_string() + '\\n')\nprint('Studies with the most images')\ndisplay(df_study_test.sort_values('num_images', ascending=False)[0:10])\ndf_study_test.to_csv('study_test.csv', index=False)","ad263c08":"test_files = sorted(glob.glob(os.path.join(base_path, 'test\/*\/*\/*.dcm')))\nprint(f'Number of test files: {len(test_files)}')","c5e43d9a":"plot_image(test_files[7], size=(20,20))\nplot_image(test_files[0:16], size=(20,20))","ef2e7f12":"img_list = []\nfor file in tqdm.tqdm(test_files):\n    img = read_dicom_image(file)\n    img_list.append({'file': file, 'width': img.shape[1], 'height': img.shape[0]})\ndf_images = pd.DataFrame(img_list)\ndf_images['ratio'] = df_images['width'] \/ df_images['height']\nplt.figure(figsize=(18,5))\nplt.subplot(1,2,1)\nplt.hist(df_images['width'])\nplt.title('Width Distribution of the Images')\nplt.xlabel('Width')\nplt.ylabel('Frequency')\nplt.grid()\nplt.subplot(1,2,2)\nplt.hist(df_images['height'])\nplt.title('Height Distribution of the Images')\nplt.xlabel('Height')\nplt.ylabel('Frequency')\nplt.grid()\nplt.show()\nplt.figure(figsize=(18,5))\nplt.subplot(1,2,1)\nplt.scatter(df_images['width'], df_images['height'])\nplt.title('Width and Height Distribution of the Images')\nplt.xlabel('Width')\nplt.ylabel('Height')\nplt.grid()\nplt.subplot(1,2,2)\nplt.hist(df_images['ratio'], bins = 20)\nplt.title('Width to Height Ratio of the Images')\nplt.xlabel('Width to Height Ratio')\nplt.ylabel('Frequency')\nplt.grid()\nplt.show()","b4a1ddbf":"df_pairs, group_list = images_find_duplicates(test_files[0:200], threshold=0.95)\nprint(f'\\nNumber of duplicate pairs: {len(df_pairs)}')\nprint(f'Number of duplicate groups: {len(group_list)}')","fc8199db":"for i, group in enumerate(group_list):\n    group_ids = [os.path.basename(file) for file in group]\n    print(f'\\nGroup {i+1}')\n    plot_image(group, size=(20, 10), title=group_ids, columns=8)","bcc8348b":"df_submission = pd.read_csv(os.path.join(base_path,'sample_submission.csv'))\ndisplay(df_submission)","8e169c47":"## Number of Images\nSimilarly, each study contains between 1 and 7 images with most studies consisting of 1 image.","ee6f0439":"## Image Display\nThe next step is to load the list of test files.","ff9bef76":"# SIIM Covid-19 Detection Basic Exploratory Data Analysis (EDA)\nThis notebook provides a basic exploratory data analysis of the SIIM Covid-19 Detection data set. \n\n# Summary of Findings\n## Training Set\n- The dataset contains 6054 annotated training studies.\n- Each study has one of 4 labels.\n- Three labels indicates Covid-19 positive, 1 label Covid-10 negative.\n- Study labels are not balanced.\n- Each study contains between 1 and 9 training images with most studies constisting of 1 or 2 training images.\n- The dataset contains 6334 annotated training images.\n- Each training images has between 0 and 8 bounding boxes with most images having 0 to 2 bounding boxes.\n- **The dataset contains several duplicate images with different boudning boxes marked.**\n- The image height and width varies roughly between 1500 and 4000 pixels.\n- The width to height ratio of the images is approximately 1.2\n\n## Test Set\n- The dataset contains 1214 training studies.\n- Each study contains between 1 and 7 images with most studies containing 1 or 2 images.\n- The dataset contains 1263 images.\n- **The dataset contains several duplicate images.**\n- The image height and width varies roughly between 1500 and 4000 pixels.\n- The width to height ratio of the images is approximately 1.2\n\n# References\nThe following references were used in this notebook.\n- Notebook with all duplicate images: https:\/\/www.kaggle.com\/kwk100\/siim-covid-19-duplicate-training-images\n- Reading dicom images: https:\/\/www.kaggle.com\/trungthanhnguyen0502\/eda-vinbigdata-chest-x-ray-abnormalities\n ","d20374d1":"## Number of Images\nSimilarly, each study contains between 1 and 9 images with most studies consisting of 1 image.","00e5a2b5":"## Duplicate Images\nIt is worthwile to check the dataset for duplicate images. For speed reasons, we are only checking the first 200 files for duplicates.","537df68a":"# Imports","23c5ab0d":"In each row, exactly one of the 4 class is associated with the study id.\n\nSince the number of unique studies is the same as the number of rows, so each study occurs only once in the table and each study is associated with only 1 class.\n\nThe frequency of the 4 classes in the training set is shown below.","e104822e":"# Parameters","048a9eb4":"# Training Images\nThe train images are arranged in directories and sub-directories with the structure `study`\/`series`\/`image`.\n\n## Number of Studies\n\nEach study contains between 1 and 9 series, with most studies containing 1 series.","60ec7c3f":"# CSV Files\n# Train_Study_Level.csv\nLets take a look at the contents of the study training file.","31b90183":"# Test Images\nThe test images are arranged in directories and sub-directories with the structure `study`\/`series`\/`image`.\n\n## Number of Studies\n\nEach study contains between 1 and 4 series, with most studies containing 1 series.","2858a8c4":"## Image Size","423cfa65":"## Image Display\nThe next step is to load the list of training files.","008e6ad5":"## Image Size","b07ebed9":"## Bounding Boxes\nThe number of bounding boxes in an image varies. From the data below, we can see that each image can contain between 0 and 8 bounding with most of the images having between 0 and 2 boxes.","0b1a5b1c":"# Sample_Submission.csv\nThe `sample_submission.csv` file shows the format of the submissions file. consisting of the test image id and an rle encoded masks. The submission file contains both the study predictions and the image predictions using a common format with two columns.\n- `id`: Id of the study\/image followed by '_study' or '_image'\n- `PredictionString`: A single string for the prediction for the study\/image.\n  - for studies: This is the predicted class followed by a confidence score and a one-pixel bounding box '0 0 1 1'\n  - for images: class ID ('opacity'\/'none'), confidence score, bounding box for each detected object.","eb966884":"Since several duplicate images were found in the dataset, we plot some of them. It turns out that in the duplicate images, the bounding boxes are different!","de24f9ac":"Now that the list is loaded, lets take a look at one image full-size and several scaled down images with their bounding boxes.","5357855a":"## Duplicate Images\nWe also check the test images for duplicates. For speed reasons, we are only checking the first 200 files for duplicates.","16d2e7b7":"- The `label` column contains the bounding boxes for the image `bounding box 1`, `bounding box 2`, ...\n  - Each bounding box is given in the format `class` `confidence score` `x1` `y1` `x2` `y2`\n- The `boxes` column contains the x, y, width, and height information only in dictionary format.","b7fe2fd1":"Since several duplicate images were found in the dataset, we plot some of them.","a1e32027":"# Train_Image_Level.csv\nLets take a look at the contents of the image training file.","bbff7838":"# Utility Functions","c1cb1ed3":"Now that the list is loaded, lets take a look at one image full-size and several scaled down images.","773fa21c":"# File Structure\nThe files in the root of the dataset are shown below.\nThe dataset consists of 2 directories that contain training and test images and 3 csv-files with additional information about the images and the competition.\n## Directory Contents"}}