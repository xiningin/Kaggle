{"cell_type":{"b70c38b5":"code","19aa863e":"code","84e22aa5":"code","197c18ff":"code","bb69c8f2":"code","fcc9207d":"code","064c0da7":"code","7c03f289":"code","78b050c5":"code","f7d905fc":"code","c3c3e4b4":"code","8897f885":"code","6690ab07":"code","be139c28":"code","828bd6ed":"code","4e86ec52":"code","28d3178a":"code","aa42fc03":"code","fe6a6568":"code","87939246":"code","a5a57f31":"code","3727ae54":"code","a6cda006":"markdown","23c38331":"markdown","aa99684e":"markdown","20c49a69":"markdown","0386201f":"markdown","b4fafd06":"markdown","f5434efe":"markdown","e3ab0713":"markdown","437bac9f":"markdown","577618b6":"markdown","4c67706d":"markdown","a8738c11":"markdown","76be4931":"markdown","0b14529e":"markdown"},"source":{"b70c38b5":"!pip install --upgrade fastai","19aa863e":"!pip install timm","84e22aa5":"import cv2\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom fastai.vision.all import *","197c18ff":"set_seed(999,reproducible=True)","bb69c8f2":"dataset_path = Path('..\/input\/seti-breakthrough-listen')\ndf = pd.read_csv(dataset_path\/'train_labels.csv')","fcc9207d":"df['path'] = df['id'].apply(lambda x: str(dataset_path\/'train'\/x[0]\/x)+'.npy') #adding the path for each id for easier processing","064c0da7":"df.head()","7c03f289":"class SETIDataset:\n    def __init__(self, df, spatial=True, sixchan=True):\n        self.df = df\n        self.spatial = spatial\n        self.sixchan = sixchan\n        \n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        label = self.df.iloc[index].target\n        filename = self.df.iloc[index].path\n        data = np.load(filename).astype(np.float32)\n        if not self.sixchan: data = data[::2].astype(np.float32)\n        if self.spatial:\n            data = np.vstack(data).transpose((1, 0))\n            data = cv2.resize(data, dsize=(256,256))     \n            data_tensor = torch.tensor(data).float().unsqueeze(0)\n        else:\n            data = np.transpose(data, (1,2,0))\n            data = cv2.resize(data, dsize=(256,256))     \n            data = np.transpose(data, (2, 0, 1)).astype(np.float32)\n            data_tensor = torch.tensor(data).float()\n            \n        \n\n        return (data_tensor, torch.tensor(label))","78b050c5":"train_df, valid_df = train_test_split(df, test_size=0.2, random_state=999)","f7d905fc":"train_ds = SETIDataset(train_df)\nvalid_ds = SETIDataset(valid_df)\n\nbs = 128\ntrain_dl = torch.utils.data.DataLoader(train_ds, batch_size=bs, num_workers=8)\nvalid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=bs, num_workers=8)","c3c3e4b4":"dls = DataLoaders(train_dl, valid_dl)","8897f885":"from timm import create_model\nfrom fastai.vision.learner import _update_first_layer\n\ndef create_timm_body(arch:str, pretrained=True, cut=None, n_in=3):\n    \"Creates a body from any model in the `timm` library.\"\n    model = create_model(arch, pretrained=pretrained, num_classes=0, global_pool='')\n    _update_first_layer(model, n_in, pretrained)\n    if cut is None:\n        ll = list(enumerate(model.children()))\n        cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n    if isinstance(cut, int): return nn.Sequential(*list(model.children())[:cut])\n    elif callable(cut): return cut(model)\n    else: raise NamedError(\"cut must be either integer or function\")\n        \ndef create_timm_model(arch:str, n_out, cut=None, pretrained=True, n_in=3, init=nn.init.kaiming_normal_, custom_head=None,\n                     concat_pool=True, **kwargs):\n    \"Create custom architecture using `arch`, `n_in` and `n_out` from the `timm` library\"\n    body = create_timm_body(arch, pretrained, None, n_in)\n    if custom_head is None:\n        nf = num_features_model(nn.Sequential(*body.children()))\n        head = create_head(nf, n_out, concat_pool=concat_pool, **kwargs)\n    else: head = custom_head\n    model = nn.Sequential(body, head)\n    if init is not None: apply_init(model[1], init)\n    return model\n\ndef timm_learner(dls, arch:str, loss_func=None, pretrained=True, cut=None, splitter=None,\n                y_range=None, config=None, n_in=3, n_out=None, normalize=True, **kwargs):\n    \"Build a convnet style learner from `dls` and `arch` using the `timm` library\"\n    if config is None: config = {}\n    if n_out is None: n_out = get_c(dls)\n    assert n_out, \"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\n    if y_range is None and 'y_range' in config: y_range = config.pop('y_range')\n    model = create_timm_model(arch, n_out, default_split, pretrained, n_in=n_in, y_range=y_range, **config)\n    learn = Learner(dls, model, loss_func=loss_func, splitter=default_split, **kwargs)\n    if pretrained: learn.freeze()\n    return learn","6690ab07":"def roc_auc(preds,targ):\n    try: return roc_auc_score(targ.cpu(),preds.squeeze().cpu())\n    except: return 0.5","be139c28":"learn = timm_learner(dls,'resnext50_32x4d',pretrained=True,n_in=1,n_out=1,metrics=[roc_auc], opt_func=ranger, loss_func=BCEWithLogitsLossFlat()).to_fp16()","828bd6ed":"learn.lr_find()","4e86ec52":"learn.fit_one_cycle(3, 0.1, cbs=[ReduceLROnPlateau()])","28d3178a":"learn.recorder.plot_loss()","aa42fc03":"learn = learn.to_fp32()","fe6a6568":"learn.save('resnext50_32x4d-3epochs')\nlearn = learn.load('resnext50_32x4d-3epochs')","87939246":"test_df = pd.read_csv(dataset_path\/'sample_submission.csv')\ntest_df['path'] = test_df['id'].apply(lambda x: str(dataset_path\/'test'\/x[0]\/x)+'.npy')\ntest_ds = SETIDataset(test_df)\n\nbs = 128\ntest_dl = torch.utils.data.DataLoader(test_ds, batch_size=bs, num_workers=8, shuffle=False)","a5a57f31":"preds = []\nfor xb, _ in tqdm(test_dl):\n    with torch.no_grad(): output = learn.model(xb.cuda())\n    preds.append(torch.sigmoid(output.float()).squeeze().cpu())\npreds = torch.cat(preds)    ","3727ae54":"sample_df = pd.read_csv(dataset_path\/'sample_submission.csv')\nsample_df['target'] = preds\nsample_df.to_csv('submission.csv', index=False)","a6cda006":"Now we will use fastai functionality to wrap the dataloaders into the `DataLoaders` class, which gathers all the dataloaders into a single object which can be passed into fastai's `Learner`. You can see how flexible fastai really is: you can use any custom PyTorch DataLoader!","23c38331":"Now, **WE ARE DONE!**\n\nIf you enjoyed this notebook, please give it an upvote. If you have any questions or suggestions, please leave a comment!","aa99684e":"## PyTorch Dataset\n\nWe can make a simple dataset class as shown below. Here, I have written a class that allows you to use channel vs. spatial approaches, and 3- vs. 6-channel apporaches, which were the main approaches discussed on the forums. For this notebook, we will train with the spatial approach as mentioned [here](https:\/\/www.kaggle.com\/c\/seti-breakthrough-listen\/discussion\/238611). ","20c49a69":"## Inference\n\nInference is also quite trivial. Let's load our CSV file and create our dataloader.","0386201f":"Let's save our model if needed for later:","b4fafd06":"# Training\n\nWe will use Zachary Mueller's `timm_learner` function to create an already-instantiated `Learner` object with the `DataLoaders` and an appropriately defined CNN model taken from Ross Wightman's amazing `timm` package. The code for `timm_learner` (see the hidden cell below) is based on fastai's `cnn_learner` function. We can tell`timm_learner` what CNN backbone we want to use, as well as the number of input and output channels, and fastai automatically defines the appropriate model. We also pass in the metrics and the loss function. Fastai's default optimizer is AdamW. Finally, we can also use mixed precision training easily.\n\nWe'll use a simple ImageNet-pretrained ResNext50_32x4d model.","f5434efe":"The idea is that the learning rate where the loss decreases the most is likely the best learning rate. In this case, this is around ~3e-2.\n\nLet's fine-tune the pretrained model using fastai's fit_one_cycle function to train the frozen pretrained model with a one-cycle learning rate schedule. I use high weight decay regularization to prevent overfitting.","e3ab0713":"fastai provides a useful function to help determine the most optimal learning rate:","437bac9f":"Create the submission file and save:","577618b6":"While fastai provides inference functions if we use their specific data API, in this case we used plain PyTorch dataloaders. So we'll just have to iterate over the dataloader and apply the model:","4c67706d":"## Setup\nHere, let's import the required modules and set a random seed for reproducibility.","a8738c11":"# CNNs for SETI ET signal detection! (using fastai and PyTorch)\n\n**BEFORE YOU COPY AND EDIT NOTEBOOK, PLEASE SUPPORT AND UPVOTE**\n\nSpectrograms can also be represented as images which can be passed into CNNs, so here we will try training a CNN from scratch with PyTorch and fastai. I will walk you through all of the code, so you can use these notebook as a jumping point for your own experiments! \ud83d\ude42\n\nIf you want to learn more about this competition, please check out my EDA over [here](https:\/\/www.kaggle.com\/tanlikesmath\/seti-simple-eda-to-help-you-get-started)!","76be4931":"Now let's load our CSV file and process them.","0b14529e":"Split the `DataFrame` into `train_df` and `valid_df` in a reproducible manner."}}