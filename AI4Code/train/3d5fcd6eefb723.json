{"cell_type":{"71458bf9":"code","12770e98":"code","fe0dacf5":"code","2c4ae2d4":"code","4a9f48bc":"code","30a907ee":"code","2321b0a3":"code","003ba563":"code","0b89035b":"code","661e64b8":"code","03de6f7c":"code","d949d451":"code","32e41b6e":"code","121e8a59":"code","d3be90e0":"code","e7822e10":"code","3a3955d6":"code","f7c96e89":"code","51863276":"code","22631b4d":"code","1fd95eab":"code","a79f1292":"code","07916417":"markdown","c7efcf7d":"markdown","e765cc6a":"markdown","a94f208b":"markdown","cf782a60":"markdown","61d6abd6":"markdown","8be798ff":"markdown","e77274b5":"markdown","cee8c441":"markdown","3e5faf25":"markdown","873a5e4b":"markdown","fcb91ef6":"markdown","bb0b57b8":"markdown","434cea07":"markdown","9b50713b":"markdown"},"source":{"71458bf9":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\nfrom sklearn.model_selection import train_test_split\nimport time\n\n#import tensorflow.keras as keras\n#from keras import backend as K\nfrom sklearn.preprocessing import OneHotEncoder\n\n#import tensorflow as tf\nimport random\n\nimport torch\nfrom torch import nn, optim\n#from torchsummary import summary\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, sampler, random_split, Dataset\nimport math\nfrom IPython.display import display\n","12770e98":"#totalDir=0\n#totalFiles=0\n#for base, dirs, files in os.walk('..\/input\/g2net-gravitational-wave-detection\/train'):\n    #print('Searching in : ',base)\n    #for directories in dirs:\n        #totalDir += 1\n    #for Files in files:\n        #totalFiles += 1\n        \n#print('Total number of files',totalFiles,'\\n\\n')\n\n\nlabels = pd.read_csv('..\/input\/g2net-gravitational-wave-detection\/training_labels.csv')\nlabels.info()\n\n","fe0dacf5":"def get_complete_path(basedir, file_id): \n    #return os.path.join(basedir, file_id[0], file_id[1], file_id[2], file_id+ '.npy' )\n    return os.path.join(basedir,file_id[0], file_id[1], file_id[2], file_id+ '.npy' )\ndef get_part_path(basedir, file_id): \n    #return os.path.join(basedir, file_id[0], file_id[1], file_id[2], file_id+ '.npy' )\n    return os.path.join(basedir, file_id[1], file_id[2], file_id+ '.npy' )","2c4ae2d4":"# Revisamos si est\u00e1n balanceadas las clases\nprint(len(labels))#total de observaciones\nlabels.target.sum()# total de clase 1","4a9f48bc":"#leer N ejemplos aleatorios\nN=4\n\noptions = random.sample(range(0, 150), N)\n\n\neventos = [labels['id'].iloc[i] for i in options]\ncategorias = [labels['target'].iloc[i]for i in options]\n\nprint(eventos)","30a907ee":"data_array_list=[]\nfor evento in eventos:\n    path=get_complete_path('..\/input\/g2net-gravitational-wave-detection\/train\/',evento)\n    data_array = np.load(path)\n    data_array_list.append(data_array)\n    \n'''print(\"\\nData summary:\\n\", data_array)\nprint(\"\\nData shape:\\n\", data_array.shape)\n'''\ndf = pd.DataFrame(data_array).T\n\nfig, axs =f, axs = plt.subplots(N,figsize=(15,5*N)) \nfor i in range(N):\n    for j in range(3):\n        \n        axs[i].plot(data_array_list[i][j])\n        \n\n#df.plot( figsize=(15,4))\n\nprint(\"\\n\\n\\n--------------------------------Las categor\u00eda son:\",categorias,'---------------------------\\n\\n')","2321b0a3":"\n\nclass Dataset(torch.utils.data.Dataset):\n    'Characterizes a dataset for PyTorch'\n    def __init__(self, list_IDs, labels):\n        'Initialization'\n        self.labels = labels\n        #print(self.labels)\n        self.list_IDs = list_IDs\n        #print(self.list_IDs)\n    def __len__(self):\n        'Denotes the total number of samples'\n        return len(self.list_IDs)\n\n    def __getitem__(self, index):\n        'Generates one sample of data'\n        # Select sample\n        #print(index)\n        ID = self.list_IDs[index]\n        #print('ID',ID)    \n        # Load data and get label\n        path = get_complete_path('..\/input\/g2net-gravitational-wave-detection\/train', ID)\n        #print(path)\n        X = torch.from_numpy(np.load(path))\n        #X=X[:][0]\n        #print(X)\n        y = self.labels[index]\n        #print(y)\n\n        return X, y","003ba563":"def make_trainDL(labels):\n    trainingDS = Dataset(labels['id'], labels['target'])\n    training_generator = DataLoader(trainingDS,batch_size=16, shuffle=True)\n    return trainingDS , training_generator \n    ","0b89035b":"%%time\n\nmsk = np.random.rand(len(labels)) < 0.98\ntrain_data=labels[msk].reset_index()\nval_data=labels[~msk].reset_index()\n\n\n\nprint(train_data.iloc[:32])\ntrain, train_dl = make_trainDL(train_data.iloc[:32])\nval, val_dl = make_trainDL(train_data.iloc[:32])\n","661e64b8":"# Display text and label.\nprint(len(train),len(val))\nprint('\\nFirst iteration of data set: ', next(iter(train_dl)), '\\n')# Print how many items are in the data set\n","03de6f7c":"#print(train.shape,y_labels.shape)\n\ntrainiter = iter(train_dl)\nfeatures, labels = next(trainiter)\nprint(features.shape, labels)\nfeatures, labels = next(trainiter)\nprint(features.shape, labels)","d949d451":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","32e41b6e":"#onehot_encoder = OneHotEncoder(sparse=False)\n#integer_encoded = y_labels.reshape(len(y_labels), 1)\n#y_labels = onehot_encoder.fit_transform(integer_encoded)\n#print(y_labels)","121e8a59":"class funcionesBase(nn.Module):\n    \n\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n        \n    def validation_step(self, batch, loss_):\n        graf, labels = batch \n        out = self(graf.double().to(device))  \n        #print(labels)\n        loss = loss_(out.to(device), labels.to(device)) \n        acc = accuracy(out.to(device), labels.to(device))           \n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   \n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      \n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n\ndef accuracy(outputs, labels):\n    #print(outputs)\n    _, preds = torch.max(outputs, dim=1)\n    #print('PRED:',preds,'LABELS:',labels)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))","d3be90e0":"class clasificadorOndasGrav(funcionesBase):\n    \n    def __init__(self):\n        \n            super().__init__()   \n            self.c1=nn.Conv1d(in_channels=3, out_channels=16, kernel_size=3, stride=3).double()\n            self.m1=nn.MaxPool1d(4).double()\n            self.c2=nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, stride=3).double()\n            self.m2=nn.MaxPool1d(4).double()\n            self.c3=nn.Conv1d(in_channels=16, out_channels=8, kernel_size=3, stride=1).double()\n            self.m3=nn.MaxPool1d(2).double()\n            #self.c4=nn.Conv1d(in_channels=8, out_channels=8, kernel_size=3, stride=1).double()\n            #self.m4=nn.MaxPool1d(2).double()\n            self.f=nn.Flatten().double()\n            #self.l1=nn.Linear(21824,10912).double()\n            #self.r1=nn.ReLU().double()\n            self.l2=nn.Linear(104,36).double()\n            self.r2=nn.ReLU().double()\n            self.l3=nn.Linear(36,2).double()\n            self.s=nn.Sigmoid().double()\n            \n            \n    \n    def forward(self, xb):\n        #self.network = self.network.double()\n        #print('xb',xb.shape)\n        out=self.c1(xb.double())\n        out=self.m1(out)\n        out=self.c2(out)\n        out=self.m2(out)\n        out=self.c3(out)\n        out=self.m3(out)\n        #out=self.c4(out)\n        #out=self.m4(out)\n        #print(out.shape)\n        out=self.f(out)\n        #print(out.shape)\n        #out=self.l1(out)\n        #print(out.shape)\n        #out=self.r1(out)\n        out=self.l2(out)\n        out=self.r2(out)\n        out=self.l3(out)\n        out=self.s(out)\n        return out\n\n    ","e7822e10":"model=clasificadorOndasGrav()\n#model.to(device)\nmodel","3a3955d6":"#@torch.no_grad()\ndef evaluate(model, loss_, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch, loss_) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, loss_, train_loader,val_loader, opt_func = torch.optim.SGD):\n    \n    history = []\n    optimizer = opt_func(model.parameters(),lr)\n    for epoch in range(epochs):\n        \n        #model.train()\n        train_losses = []\n        for i,batch in enumerate(train_loader):\n        \n            graf, labels = batch\n            #print(graf.shape)\n            graf = graf*1e20\n            #print(graf)\n            optimizer.zero_grad()\n            \n            \n            out = model(graf.to(device))\n            #print(out.shape,labels.shape)\n            print('out',out,'labels',labels,'\\n')\n            loss = loss_(out.to(device), labels.to(device)) \n            print(loss)\n            \n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            \n            '''if i%10==0:\n                print(\".\",end=\"\")\n            #if i%100==0:\n            print(\".\",end=\"\")\n        result = evaluate(model,loss_, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n        #model.train()\n    \n    return history'''","f7c96e89":"num_epochs = 300\nopt_func = torch.optim.Adam\nlr = 0.001\n\nloss=nn.CrossEntropyLoss() \n\nfit(num_epochs, lr, model, loss, train_dl, val_dl, opt_func)","51863276":"def hacer_predic (model,graf):\n    with torch.no_grad():\n        y_pred = model(graf)\n    return y_pred","22631b4d":"submission = pd.read_csv(\"..\/input\/g2net-gravitational-wave-detection\/sample_submission.csv\")\npred_list=[]\nfor i in range(1):\n    evento_a_pred = submission['id'].iloc[i]\n    path_pred = get_complete_path('..\/input\/g2net-gravitational-wave-detection\/test', evento_a_pred)\n    array = np.load(path_pred)\n    pred_list.append(array)\n    \ndata = torch.from_numpy(np.stack(pred_list, axis=0))\npred = hacer_predic(model,data)\npred.shape\n","1fd95eab":"submission = pd.read_csv(\"..\/input\/g2net-gravitational-wave-detection\/sample_submission.csv\")\n\n\nsubmission.to_csv('submission.csv',index=False)","a79f1292":"display(submission)","07916417":"# dividir en train\/validation\n\n\nX_train, X_val, y_train, y_val = \\\n    train_test_split(train, y_labels, test_size=0.3, random_state=42)\n\nprint('X_train',X_train.shape,'y_train', y_train.shape,'\\nX_val',X_val.shape,'y_val',y_val.shape)\nver=X_train[0].shape\nprint(ver)","c7efcf7d":"print('train tiene forma: ',train.shape)\n#train=np.transpose(train, (0,2,1))\ntrain.shape","e765cc6a":"from scipy.fft import fft, ifft,fftfreq,rfft,rfftfreq\n\nyf=[]\nyf.append(rfft(train[1][0]))\n#yf.append(rfft(train[1][1]))\n#yf.append(rfft(train[1][2]))\n\n# Number of sample points\nprint(np.abs(yf[0]),'\\n',len(yf[0]))\nN = len(train[1][0])\nT = 1.0\/N\n\nxf = rfftfreq(N, T)\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(20,10))\nplt.plot(xf[:100],np.abs(yf[0][:100]))\n\nplt.grid()\n\nplt.show()","a94f208b":"def make_train_data(path,labels):\n    data_list=[]\n    target_list=[]\n    n=1\n    for base, dirs, files in os.walk(path):\n        for file in files:\n            indir=base[:-5]\n            n+=1\n            file_path = get_complete_path(indir,file)[:-4]\n            array = np.load(file_path)\n            #array = array.transpose()\n            data_list.append(array)\n            a=labels.loc[labels['id'] == file[:-4], 'target'].iloc[0]\n            target_list.append(a)\n    data = np.stack(data_list, axis=0)\n    data_l = np.array(target_list)\n    data_l = data_l.reshape(data_l.shape[0],-1)\n    return data,data_l\n            \n    ","cf782a60":"criterion = nn.BCELoss() \noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","61d6abd6":"# Analisis de frecuencias","8be798ff":"# Analisis","e77274b5":"# Para probar el DataLoader","cee8c441":"# Definimos un Modelo","3e5faf25":"# Hacer predicci\u00f3n ","873a5e4b":"# Para entrenar","fcb91ef6":"for epoch in range(22):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(train_dl, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = model(inputs)\n        loss = criterion(outputs.double(), labels.double())\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 2 == 0:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss \/ 2))\n            running_loss = 0.0\n\nprint('Finished Training')","bb0b57b8":"# Preparaci\u00f3n ","434cea07":"\nX_trainT=torch.from_numpy(X_train)\ny_trainT=torch.from_numpy(y_train)\nX_valT=torch.from_numpy(X_val)\ny_valT=torch.from_numpy(y_val)\n\ntrain_dl = [[X_trainT,y_trainT]]\nval_dl = [[X_valT,y_valT]]\n\n","9b50713b":"y_trainT.type()\nX_trainT.type()"}}