{"cell_type":{"a7d0b97c":"code","d1b4dfbe":"code","a59b850f":"code","ea470212":"code","cd258cf1":"code","f3a276d6":"code","86d49aca":"code","77eb7650":"code","507d853d":"code","150b1473":"code","87de063f":"code","caf8f306":"code","2b3c6fed":"code","f01c1233":"code","03e303e0":"code","b4489212":"code","e3a10534":"code","e6526562":"code","9b411aed":"code","5e303d77":"code","5c711657":"code","381d7cf1":"code","b5cec71e":"code","0af54c8e":"code","e27a4dcc":"code","ffcf5253":"code","747dfad9":"markdown","9abfe33c":"markdown","a1ab3bdb":"markdown","9cb522f4":"markdown","1fb498ce":"markdown","f9b2adc5":"markdown","fb7b2391":"markdown","c8f73d05":"markdown","771461a2":"markdown","31b71ccd":"markdown","e9ac0e75":"markdown","febde854":"markdown","1d7088d8":"markdown","bf955bf1":"markdown","e1727284":"markdown","2830dc3e":"markdown","6a25fa92":"markdown","33cdd091":"markdown","fd891da5":"markdown","eeb4f581":"markdown","adc5de55":"markdown","8581bc54":"markdown","a87366f0":"markdown","c310fbb5":"markdown","cdb2683b":"markdown","a7e3fb5b":"markdown","ff92ec5d":"markdown","cfa4680d":"markdown","112b7ca7":"markdown"},"source":{"a7d0b97c":"import os\nimport numpy as np\nimport pandas as pd \n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\nfrom tensorflow.keras.utils import to_categorical\n\nimport matplotlib.pyplot as plt\nimport random\n\nprint(os.listdir(\"..\/input\"))","d1b4dfbe":"# True if you want to quick test you model (training for 3 epochs). False to have a full train (50 epochs).\nFAST_RUN = False \nepochs = 3 if FAST_RUN else 50\n# Enter the width and height of images.\nIMAGE_WIDTH=256\nIMAGE_HEIGHT=192\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n# 3 if RGB. 1 if Grayscale.\nIMAGE_CHANNELS=3\nbatch_size = 32\n# Dropout rate\nd = 0.3\n\n# Use when training on pre-trained weights\nSTART_EPOCH = 0 # if fresh train, enter 0\nTransfer = False\nPretrained_Link = \"..\/input\/pretrained-model\/model.h5\"","a59b850f":"# Create a blank dataframe with two columns: image file name and the waste category\ndf = pd.DataFrame({\n    'filename': [],\n    'category': []\n})\n\ndirectory = \"..\/input\/unsortedwaste\/UnSortedWaste\/\"\n# directory of images\nfilenames = os.listdir(directory)\n\n# append filename and category of all images into the dataframe, one by one.\nfor filename in filenames:\n        # use the first three letters of image file name to identify category.\n        category = filename[0:3]\n        if category == 'car':\n            categories='cardboard'\n        elif category == 'gla':\n            categories='glass'\n        elif category == 'met':\n            categories='metal'\n        elif category == 'pap':\n            categories='paper'\n        elif category == 'pla':\n            categories='plastic'\n        else:\n            categories='trash'\n        df=df.append({'filename':directory + filename, 'category': categories},ignore_index=True)\n\n# load from another dataset ---------------------------------------------------------------------\ndirectory = \"..\/input\/waste-images-2\/solid_waste\/\"\n# directory of images\nfilenames = os.listdir(directory)\n\n# append filename and category of all images into the dataframe, one by one.\nfor filename in filenames:\n        # use the first three letters of image file name to identify category.\n        category = filename[0:3]\n        if category == 'car':\n            categories='cardboard'\n        elif category == 'gla':\n            categories='glass'\n        elif category == 'met':\n            categories='metal'\n        elif category == 'pap':\n            categories='paper'\n        elif category == 'pla':\n            categories='plastic'\n        else:\n            categories='trash'\n        df=df.append({'filename':directory + filename, 'category': categories},ignore_index=True)\n","ea470212":"df = df.dropna()\nprint(\"Number of images = {}\".format(df.size))\n# Quick look of the dataframe\ndf.head()","cd258cf1":"df['category'].value_counts().plot.bar()\nprint (df['category'].value_counts())","f3a276d6":"# Randomly sample 80% of data from dataframe for training. Replace = False to prevent repeat sampling.\ndf_train=df.sample(frac=0.8,replace=False)\n# The rest 20% is the validation images.\ndf_valid=df.drop(df_train.index.values)","86d49aca":"df_train['category'].value_counts().plot.bar()\nprint (df_train['category'].value_counts())","77eb7650":"df_valid['category'].value_counts().plot.bar()\nprint(df_valid['category'].value_counts())","507d853d":"sample = random.choice(df_train['filename'])\nimage = load_img(sample)\nplt.imshow(image)\nprint(sample)","150b1473":"# Importing models from Keras\nfrom tensorflow.keras.models import Sequential\n# Import from \"tensorflow.keras.layers\" instead of \"tensorflow.keras\" \n# so that we don't need to write \"layers.\" in every line\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n# Create Keras Sequential Model\nmodel = Sequential([\n        # Convolution 2D layer (filters, strides, activation function, padding) \n        Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)),\n        # Normalize to inprove accuracy\n        BatchNormalization(),\n        # Extract features, reduce image size\n        MaxPooling2D(pool_size=(2, 2)),\n        # Dropout to prevent overfitting\n        Dropout(d),\n\n        Conv2D(64, (3, 3), activation='relu',padding='same'),\n        BatchNormalization(),\n        MaxPooling2D(pool_size=(2, 2)),\n        Dropout(d),\n\n        Conv2D(128, (3, 3), activation='relu',padding='same'),\n        BatchNormalization(),\n        MaxPooling2D(pool_size=(2, 2)),\n        Dropout(d),\n    \n        Conv2D(256, (3, 3), activation='relu',padding='same'),\n        BatchNormalization(),\n        MaxPooling2D(pool_size=(2, 2)),\n        Dropout(d),\n\n        # Flatten 3D tensor (2D visual + 1D channel) into 1D array to pass through Dense layer\n        Flatten(),\n        Dense(1024, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.5),\n        Dense(512, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.5),\n        Dense(128, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.5),\n        Dense(6, activation='softmax')# 6 because we have 6 classes\n])\n\nif Transfer:\n    model.load_weights(Pretrained_Link)\n\nmodel.compile(\n    # use categorical\n    loss='categorical_crossentropy', \n    optimizer='adam', \n    metrics=['categorical_accuracy'],\n)\n\nmodel.summary()","87de063f":"# import needed libraries\nfrom tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler","caf8f306":"earlystop = EarlyStopping(patience=10,restore_best_weights=True)","2b3c6fed":"# Learning rate (LR) schedule for TPU, GPU and CPU.\n\nLR_START = 5e-4\nLR_MIN = 1e-6\nLR_EXP_DECAY = .94\n\n# Define a Learning Rate function on epoch that will decrease exponentially.\ndef lrfn(epoch):\n    lr = (LR_START - LR_MIN) * LR_EXP_DECAY**(epoch+START_EPOCH) + LR_MIN\n    return lr\n    \nlr_callback = LearningRateScheduler(lrfn, verbose=True)\n\n# Visualize the change in learning rate\nrng = [i for i in range(START_EPOCH,epochs+START_EPOCH)]\ny = [lrfn(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g}\".format(y[0], y[-1]))","f01c1233":"# Total number of images for training\ntotal_train = df_train.shape[0]\n# Total number of images for validation\ntotal_validate = df_valid.shape[0]\n\nprint(\"Training: {}, Validation: {}\".format(total_train,total_validate))","03e303e0":"# Use tensorflow.keras.preprocessing.image.ImageDataGenerator for data Augmentation\n# Stretch, rotate, rescale, flip, etc. the training waste images to better train the model\ntrain_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1.\/255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\n# According to the dataframe, pull images one by one from image directory\ntrain_generator = train_datagen.flow_from_dataframe(\n    df_train, \n    \"\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size,\n)","b4489212":"# Validation doesn't need much data Augmentation\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# According to the dataframe, pull images one by one from image directory\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    df_valid, \n    \"\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=batch_size\n)","e3a10534":"# Get one sample image name from train dataframe\nexample_df = df_train.sample(n=1).reset_index(drop=True)\n# Pull the image from directory\nexample_generator = train_datagen.flow_from_dataframe(\n    example_df, \n    \"\", \n    x_col='filename',\n    y_col='category',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical'\n)\n\n# Plot the effect of the data augmentation\nplt.figure(figsize=(12, 12))\nfor i in range(0, 15):\n    plt.subplot(5, 3, i+1)\n    for X_batch, Y_batch in example_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()\n\nexample_df","e6526562":"history = model.fit(\n    # The train generator just tested, can pull training images out from directory.\n    train_generator, \n    # Batch size and epochs already set at beginning.\n    batch_size=batch_size,\n    epochs=epochs,\n    # The validation generator, can pull validation images out from directory.\n    validation_data=validation_generator,\n\n    validation_steps=total_validate\/\/batch_size,\n    steps_per_epoch=total_train\/\/batch_size,\n    # Two callback methods: early stopping and learning rate scheduling\n    callbacks=[earlystop, lr_callback]\n)\n\n# Save Model\nmodel.save_weights(\"model.h5\")","9b411aed":"import matplotlib.pyplot as plt \nimport matplotlib\n# Visualize the training process by graphing the loss curves and accuracy curves\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n\nax1.plot(history.history['loss'],c=\"b\",label=\"Training loss\")\nax1.plot(history.history['val_loss'], c='r', label=\"validation loss\")\nax1.legend()\nax1.grid()\nax1.set_xticks(np.arange(1, len(history.history[\"loss\"]), 5))\nax1.set_yticks(np.arange(0, max(history.history['val_loss']), round(max(history.history['val_loss'])\/10, 1)))\n\nax2.plot(history.history['categorical_accuracy'], color='b', label=\"Training accuracy\")\nax2.plot(history.history['val_categorical_accuracy'], color='r',label=\"Validation accuracy\")\nax2.legend()\nax2.grid()\nax2.set_xticks(np.arange(1, len(history.history[\"loss\"]), 5))\nax2.set_yticks(np.arange(0, 1, 0.05))\nplt.tight_layout()\nplt.show()","5e303d77":"# Since this notebook is not in a competition, \n# we will just randomly select samples from the dataset for testing.\n# Randomly select 30% of data\ntest_df = df.sample(frac = 0.3)\n# Number of testing samples\nnb_samples = test_df.shape[0]","5c711657":"# Test generator in the same fashion of the train\/validation generators\ntest_gen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    \"\", \n    x_col='filename',\n    y_col=None,\n    class_mode=None,\n    target_size=IMAGE_SIZE,\n    batch_size=batch_size,\n    shuffle=False\n)","381d7cf1":"predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples\/batch_size))","b5cec71e":"# For categoral classication the prediction will come with probability of each category. \n# So we will pick the category that have the highest probability with numpy average max\n# We store the predicted results besides the true labels in a dataframe.\ntest_df['pred_category'] = np.argmax(predict, axis=-1)\n\nlabel_map = dict((v,k) for k,v in train_generator.class_indices.items())\ntest_df['pred_category'] = test_df['pred_category'].replace(label_map)","0af54c8e":"test_df['pred_category'].value_counts().plot.bar()","e27a4dcc":"import matplotlib.pyplot as plt \nimport matplotlib\n\nsample_test = test_df.sample(n=18)\nplt.figure(figsize=(12, 24))\n\ni=1\nfor index, row in sample_test.iterrows():\n    if i <= 18:\n        filename = row['filename']\n        category = row['pred_category']\n        img = load_img(filename, target_size=IMAGE_SIZE)\n        plt.subplot(6, 3, i)\n        plt.imshow(img)\n        plt.title('(predicted=' + \"{}\".format(category) + ')')\n        i+=1\nplt.tight_layout()\n\nplt.show()","ffcf5253":"submission_df = test_df.copy()\nsubmission_df.to_csv('.\/submission.csv', index=False)\ntest_df.head(30)","747dfad9":"# Visualize Training","9abfe33c":"# Build Model","a1ab3bdb":"### See sample image","9cb522f4":"### Training Image Generator for model fitting","1fb498ce":"# Define Constants","f9b2adc5":"# Prepare data","fb7b2391":"# Fit Model","c8f73d05":"### Overview of training dataset","771461a2":"### Early Stop\n\nTo prevent overfitting, we will stop training if the validation dataset accuracy doesn't increase for 10 consecutive epochs. Then we will restore the best weights throughout the training.","31b71ccd":"### Test functionality of generators","e9ac0e75":"Use Keras Sequential to build model to extract 2D visual values.","febde854":"# Predict","1d7088d8":"This Kernel for someone want to deep dive into image classification. I use CNN for classification model. If you found this Kernel helpful please up vote it. If you have some feedback and question don't forget to comment below. ","bf955bf1":"### Overview of data","e1727284":"# Training Preparation: Loading Images and Labels","2830dc3e":"### Visualize Result","6a25fa92":"### Overview of all data","33cdd091":"# Import Libraries","fd891da5":"# Callbacks","eeb4f581":"# Create Testing Generator","adc5de55":"### Learning Rate Scheduler\n\nReduce the Learning Rate over time to increase training accuracy over time.\n\nThis is like switching from the rough calibration on a microscope to the fine calibration","8581bc54":"### Validation Generator","a87366f0":"#### Seems nice!","c310fbb5":"# Training Preparation: Splitting Training and Testing","cdb2683b":"Looking good! Now we can start building our model.","a7e3fb5b":"### See predicted result with images","ff92ec5d":"# Prepare Testing Data","cfa4680d":"### Overview of testing dataset","112b7ca7":"From our data we have 2167 glass, 2123 plastic, 2085 metal, 594 paper, 403 cardboards, and 137 trash."}}