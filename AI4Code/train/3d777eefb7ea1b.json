{"cell_type":{"da719433":"code","6aa701f9":"code","895eff94":"code","e8ccb9c7":"code","dee1531c":"code","bb26462b":"code","c9d5180b":"code","d5120b54":"code","8468f64d":"code","1f83ea4e":"code","7f1cb091":"code","7d34dff6":"code","e67bbaae":"code","0b7db1b4":"code","f3b3fadd":"code","f949046d":"code","d1db14b4":"code","aa27c6c5":"code","e0127712":"code","32e2fee4":"code","570fc0ba":"code","081742fe":"code","70df4c24":"code","309fc959":"code","afce30ce":"code","cbf83819":"markdown","489912d5":"markdown","22cb5a5d":"markdown","dbc7ed81":"markdown","d007019d":"markdown","e8c1ff61":"markdown","c10022f3":"markdown","89abe9d3":"markdown","3cba9ade":"markdown","d72555d7":"markdown","8b14401e":"markdown","ec2c8d0f":"markdown","0f399d9f":"markdown","a0033cfd":"markdown","d39bac72":"markdown","c0fbc701":"markdown","6a4bfaca":"markdown","7d7ee54a":"markdown","dcea83a7":"markdown","68a14a7e":"markdown","e1e261ca":"markdown","272abf37":"markdown","0a1fb517":"markdown","e0156b68":"markdown","dbaa90e5":"markdown","c6cf059d":"markdown","dad7beff":"markdown"},"source":{"da719433":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\nimport glob\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom scipy.stats import reciprocal\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom tensorflow import keras","6aa701f9":"csvfiles = []\nfor file in glob.glob(\"..\/input\/used-car-dataset-ford-and-mercedes\/*.csv\"):\n    csvfiles.append(file)","895eff94":"csvfiles","e8ccb9c7":"csvfiles.remove(\"..\/input\/used-car-dataset-ford-and-mercedes\/unclean focus.csv\")\ncsvfiles.remove(\"..\/input\/used-car-dataset-ford-and-mercedes\/unclean cclass.csv\")","dee1531c":"pds = []\nfor i, file in enumerate(csvfiles):\n    pds.append(pd.read_csv(file))\n    name = file[44:-4]\n    pds[i][\"type\"] = name\n    print(i, \": \", len(pds[i].columns))","bb26462b":"pds = [x for x in pds if not len(x.columns) != 10]","c9d5180b":"for element in pds:\n    print(len(element.columns))","d5120b54":"for element in pds:\n    print(element.columns)","8468f64d":"names = pds[0].columns.tolist()","1f83ea4e":"for element in pds:\n    element.columns = names","7f1cb091":"the_data = pd.DataFrame()\nfor element in pds:\n    the_data = the_data.append(element, ignore_index=True)","7d34dff6":"the_data.isnull().sum()","e67bbaae":"the_data.describe()","0b7db1b4":"the_data[the_data[\"year\"] > 2020]","f3b3fadd":"the_data = the_data[the_data[\"year\"] < 2020]","f949046d":"the_data.info()","d1db14b4":"num_vars = [\"year\", \"mileage\", \"tax\", \"mpg\", \"engineSize\"]\ncat_vars = [\"type\", \"fuelType\", \"transmission\", \"model\"]\n\nfull_pipeline = ColumnTransformer([\n    (\"num\", StandardScaler(), num_vars),\n    (\"cat\", OneHotEncoder(), cat_vars)\n])\n\nthe_data_transformed = full_pipeline.fit_transform(the_data)\n# convert to dense matrix\nthe_data_transformed = the_data_transformed.toarray()","aa27c6c5":"X_train_full, X_test, y_train_full, y_test = train_test_split(the_data_transformed, the_data[\"price\"])","e0127712":"X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)","32e2fee4":"def build_neural(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[217]):\n    model = keras.models.Sequential()\n    model.add(keras.layers.InputLayer(input_shape=input_shape))\n    for layer in range(n_hidden):\n        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n    model.add(keras.layers.Dense(1))\n    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n    model.compile(loss=\"mse\", optimizer=opt)\n    return model","570fc0ba":"keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_neural)","081742fe":"parameters = {\n    \"n_hidden\": range(5),\n    \"n_neurons\": range(100),\n    \"learning_rate\": reciprocal(3e-4, 3e-2)\n}\n\nrandom_search = RandomizedSearchCV(keras_reg, parameters, n_iter=10, cv=3)","70df4c24":"random_search.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid),\n                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])","309fc959":"random_search.best_params_","afce30ce":"model_best = random_search.best_estimator_.model\ny_hat = model_best.predict(X_test)\nplt.scatter(y_test, y_hat, alpha=0.2)\nax = plt.gca()\nax.axline([0, 0], [1, 1], color=\"black\")","cbf83819":"Some files have 8 columns while most have 10. Remove the ones that dont have 10 columns:","489912d5":"Now that we have the function, we can use it in a wrapper that will allow us to treat it as a regular Scikit-Learn regressor:","22cb5a5d":"We now split the data into train and test sets:","dbc7ed81":"We now read the data files","d007019d":"Everything looks fine.","e8c1ff61":"We should remove this record:","c10022f3":"Check the number of columns in each panda","89abe9d3":"We are now ready to fit the model:","3cba9ade":"We also split the full train sets into a train and validate set in order to use when fitting our neural network:","d72555d7":"Summarise the data:","8b14401e":"Some files have the word \"unclean\" in the title. Let us remove these files:","ec2c8d0f":"We have numerical variables ad categorical variables. We need to scale the numerical variables and encode the categorical variables:","0f399d9f":"First we import the necessary libraries","a0033cfd":"Now read  into a pandas array the files into pandas and print number of columns from each file also, create a new column with the name of the car:","d39bac72":"We see that the model performs quite well.","c0fbc701":"We are now ready to fit a neural network to the data. We will fit a squential network. However, we need to find the optimal number of layers and the optimal number of neurons in each layer. To find the optimal values of the parameters, we will use a randomized search. In order to do this, we first need to write a function that builds the network for us using supplied values of the number of layers, number of neurons, and the learning rate:","6a4bfaca":"## Transform the data","7d7ee54a":"Now append the data frames into a single data frame:","dcea83a7":"Let us now look at the names of the columns:","68a14a7e":"Check for missing values:","e1e261ca":"Get the best model and use it to predict the prices in the test set. Plot th epredicted values against the actual values while drawing the x = y line in order to visualise how well the model does:","272abf37":"We note that in one case the tax column is labelled differently. We need the same labels. Get the column names from first data frame:","0a1fb517":"Get the optimal values of the parameters:","e0156b68":"We now set the parameters that we will use in the Randmized search:","dbaa90e5":"It seems that the maximum year is 2060. This doesnt make sense.","c6cf059d":"Now loop thrpugh the data frames setting the names to this variable:","dad7beff":"Let us look at the names of the files"}}