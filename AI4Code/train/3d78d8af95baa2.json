{"cell_type":{"2ddf6b30":"code","dfcb41ab":"code","2e24ef1f":"code","63785698":"code","349006ee":"code","185bc0fd":"code","abdffc43":"code","f5193e16":"code","d0a8da9e":"code","4e5284d0":"code","4f349bbe":"code","3ba36ec2":"code","ad35e554":"code","afc5ce51":"code","cda54be7":"code","0590a049":"code","e18652e4":"code","f52e8a0f":"code","24046a44":"code","3025fdc7":"code","b9fd9d63":"code","c3bf5870":"code","a2813096":"code","f5a5c9d3":"code","f110d7ec":"code","43a035e6":"code","35b35104":"code","3f0477dd":"code","2b7a2ab0":"code","768507e9":"code","6094ef7a":"code","9446bc1b":"code","494c89ae":"code","82abd680":"code","2aa5596e":"code","0757b602":"code","07a39b88":"markdown","02c32e4c":"markdown","6a39ddf8":"markdown","7a09304f":"markdown","d995d04b":"markdown","0c9defb2":"markdown","78ce9c69":"markdown","9690adee":"markdown","27f0e798":"markdown","71060fa3":"markdown","09eaa1ba":"markdown","df39effc":"markdown","d859f79e":"markdown","ac5c398c":"markdown","55176582":"markdown","25b9c816":"markdown"},"source":{"2ddf6b30":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import OneHotEncoder\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dfcb41ab":"df = pd.read_csv(\"\/kaggle\/input\/heart-failure-prediction\/heart.csv\")","2e24ef1f":"df.head()","63785698":"df.info()\n","349006ee":"def bar_plot(variable):\n    #get variable\n    var = df[variable]\n    #count number of categorical variable(value\/sample)\n    varValue = var.value_counts()\n    \n    #visualize\n    plt.figure(figsize=(9,3))\n    plt.bar(varValue.index, varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}\".format(variable,varValue))","185bc0fd":"category1 = [\"ChestPainType\",\"FastingBS\",\"Sex\",\"RestingECG\",\"ExerciseAngina\",\"ST_Slope\"]\nfor c in category1:\n    bar_plot(c)","abdffc43":"def plot_hist(variable):\n    plt.figure(figsize=(9,3))\n    plt.hist(df[variable], bins=50)\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(f\" {variable} distribution with hist\")\n    plt.show()","f5193e16":"numeric_var = [\"Age\",\"RestingBP\",\"Cholesterol\",\"MaxHR\",\"Oldpeak\"]\nfor i in numeric_var:\n    plot_hist(i)","d0a8da9e":"#\"ChestPainType\",\"Sex\",\"RestingECG\",\"ExerciseAngina\",\"ST_Slope\"\ndf[[\"ChestPainType\",\"HeartDisease\"]].groupby([\"ChestPainType\"],as_index= False).mean().sort_values(by=\"HeartDisease\",ascending=False)","4e5284d0":"df[[\"Sex\",\"HeartDisease\"]].groupby([\"Sex\"],as_index= False).mean().sort_values(by=\"HeartDisease\",ascending=False)","4f349bbe":"df[[\"RestingECG\",\"HeartDisease\"]].groupby([\"RestingECG\"],as_index= False).mean().sort_values(by=\"HeartDisease\",ascending=False)","3ba36ec2":"df[[\"ExerciseAngina\",\"HeartDisease\"]].groupby([\"ExerciseAngina\"],as_index= False).mean().sort_values(by=\"HeartDisease\",ascending=False)","ad35e554":"df[[\"ST_Slope\",\"HeartDisease\"]].groupby([\"ST_Slope\"],as_index= False).mean().sort_values(by=\"HeartDisease\",ascending=False)","afc5ce51":"def detect_outliers(df,features):\n    outlier_indices=[]\n    \n    for i in features:\n        # 1st quartile\n        Q1 = np.percentile(df[i],25)\n        # 3rd quartile\n        Q3 = np.percentile(df[i],75)\n        # IQR\n        IQR = Q3 - Q1\n        # Outlier step\n        outlier_step = IQR * 1.5\n        # Detect outliers and their indices\n        outlier_list_col = df[(df[i] < Q1 - outlier_step) | (df[i] > Q3 + outlier_step)].index\n        # Store indices\n        outlier_indices.extend(outlier_list_col)\n        \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i , v in outlier_indices.items() if v>2)\n    \n    return multiple_outliers","cda54be7":"df.iloc[detect_outliers(df, [\"Age\", \"MaxHR\",\"RestingBP\",\"Cholesterol\"])]","0590a049":"df.columns[df.isnull().any()]","e18652e4":"df.isnull().sum()","f52e8a0f":"df[\"Sex\"] = [1 if i == \"M\" else 0 for i in df[\"Sex\"]]","24046a44":"df[\"ExerciseAngina\"] = [1 if i == \"Y\" else 0 for i in df[\"ExerciseAngina\"]]","3025fdc7":"df[\"RestingECG\"] = [1 if i == \"Normal\" else 0 for i in df[\"RestingECG\"]]","b9fd9d63":"df[\"ST_Slope\"] = [1 if i == \"Up\" else 0 for i in df[\"ST_Slope\"]]","c3bf5870":"df[\"Oldpeak\"] =  df[\"Oldpeak\"].astype(int)","a2813096":"for i in range(len(df[\"ChestPainType\"])):\n    if df[\"ChestPainType\"][i] == \"ATA\":\n        df[\"ChestPainType\"][i] = 0\n    elif df[\"ChestPainType\"][i] == \"NAP\":\n        df[\"ChestPainType\"][i] = 1\n    elif df[\"ChestPainType\"][i] == \"ASY\":\n        df[\"ChestPainType\"][i] = 2\n    elif df[\"ChestPainType\"][i] == \"TA\":\n        df[\"ChestPainType\"][i] = 3\n    ","f5a5c9d3":"df[\"ChestPainType\"].astype(int)\n","f110d7ec":"df.head()","43a035e6":"df.info()","35b35104":"list1=[\"Age\", \"Sex\", \"RestingBP\",\"Cholesterol\", \"MaxHR\", \"Oldpeak\",\"HeartDisease\"]\nf, ax=plt.subplots(figsize=(11,9))\nsns.heatmap(df[list1].corr(), annot=True, fmt=\" .2f\", ax=ax)\nplt.show()","3f0477dd":"x_train = df.drop(labels = [\"HeartDisease\"], axis = 1)\ny_train = df[\"HeartDisease\"]\nx_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.33, random_state = 42)\nprint(\"X_train\",len(x_train))\nprint(\"X_test\",len(x_test))\nprint(\"y_train\",len(y_train))\nprint(\"y_test\",len(y_test))","2b7a2ab0":"x_train","768507e9":"y_train","6094ef7a":"logreg = LogisticRegression(solver='liblinear')\nlogreg.fit(x_train, y_train)\nacc_log_train = round(logreg.score(x_train, y_train)*100,2) \nacc_log_test = round(logreg.score(x_test,y_test)*100,2)\nprint(\"Training Accuracy: % {}\".format(acc_log_train))\nprint(\"Testing Accuracy: % {}\".format(acc_log_test))","9446bc1b":"random_state = 17\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000],\n                  \"probability\":[False]}\n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"],\n                     \"solver\" : [\"liblinear\"]\n                    }\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]","494c89ae":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(x_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","82abd680":"cv_result=[100*each for each in cv_result]","2aa5596e":"results=pd.DataFrame({\"Cross Validation Best Scores\": cv_result, \"ML Models\": [\"DecisionTreeClassifier\", \"SVM\", \"RandomForestClassifier\", \"KNeighborsClassifier\", \"LogisticRegression\"]})\nf,ax=plt.subplots(figsize=(12,7))\ng = sns.barplot(data=results, y=\"ML Models\", x=\"Cross Validation Best Scores\")\ng.set_ylabel(\"\")\ng.set_xlabel(\"Accuracy %\")\nplt.show()\nfor i in range(len(results)):\n    print(results[\"ML Models\"][i], \"Accuracy:\", results[\"Cross Validation Best Scores\"][i], \"%\")","0757b602":"votingC = VotingClassifier(estimators = [(\"dt\",best_estimators[0]),\n                                        (\"rfc\",best_estimators[2]),\n                                        (\"knn\",best_estimators[3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(x_train, y_train)\nprint(accuracy_score(votingC.predict(x_test),y_test))","07a39b88":"<a id='2'><\/a><br>\n# Variable Description\n\n    1.Age: age of the patient [years]\n    2.Sex: sex of the patient [M: Male, F: Female]\n    3.ChestPainType: chest pain type [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic]\n    4.RestingBP: resting blood pressure [mm Hg]\n    5.Cholesterol: serum cholesterol [mm\/dl]\n    6.FastingBS: fasting blood sugar [1: if FastingBS > 120 mg\/dl, 0: otherwise]\n    7.RestingECG: resting electrocardiogram results [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV), LVH: showing probable or definite     left ventricular hypertrophy by Estes' criteria]\n    8.MaxHR: maximum heart rate achieved [Numeric value between 60 and 202]\n    9.ExerciseAngina: exercise-induced angina [Y: Yes, N: No]\n    10.Oldpeak: oldpeak = ST [Numeric value measured in depression]\n    11.ST_Slope: the slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]\n    12.HeartDisease: output class [1: heart disease, 0: Normal]","02c32e4c":"<a id='16'><\/a><br>\n\n## Ensemble Modeling","6a39ddf8":"<a id='12'><\/a><br>\n\n# Modeling","7a09304f":"<a id='11'><\/a><br>\n# Correlation Between Age -- Sex -- RestingBP -- Cholesterol -- MaxHR -- Oldpeak -- HeartDisease","d995d04b":"<a id='5'><\/a><br>\n## Numerical Variable :","0c9defb2":"<a id='12'><\/a><br>\n# Feature Engineering","78ce9c69":"<a id='4'><\/a><br>\n## Categorical Variable :","9690adee":"<a id='15'><\/a><br>\n## Hyperparameter Tuning -- Grid Search -- Cross Validation","27f0e798":"<a id='8'><\/a><br>\n# Missing Value Detection","71060fa3":"<a id='13'><\/a><br>\n\n## Train - Test Split","09eaa1ba":"<a id='1'><\/a><br>\n\n# Load and Check Data","df39effc":"<a id='14'><\/a><br>\n## Simple Logistic Regression","d859f79e":"\n# **Introduction**\n<img src= \"https:\/\/images.medicinenet.com\/images\/article\/main_image\/what-causes-chf.jpg\">\n\nCardiovascular diseases (CVDs) are the number 1 cause of death globally, taking an estimated 17.9 million lives each year, which accounts for 31% of all deaths worldwide. Four out of 5CVD deaths are due to heart attacks and strokes, and one-third of these deaths occur prematurely in people under 70 years of age. Heart failure is a common event caused by CVDs and this dataset contains 11 features that can be used to predict a possible heart disease.\n\n<font color = 'blue'>\n\n\n\nContent:\n    \n1. [Load and Check Data](#1)\n2. [Variable Description](#2)\n    * [Univarite Variable Analysis](#3)\n        * [Categorical Variable](#4)\n        * [Numerical Variable](#5)\n3. [Basic Data Analysis](#6)   \n4. [Outlier Detection](#7) \n5. [Missing Value Detection](#8)    \n6. [Correlation Between Age -- Sex -- RestingBP -- Cholesterol -- MaxHR -- Oldpeak -- HeartDisease](#11)    \n7. [Feature Engineering](#12)  \n8. [Modeling](#13) \n    * [Train - Test Split](#14)\n    * [Hyperparameter Tuning -- Grid Search -- Cross Validation](#15)\n    * [Ensemble Modeling](#16)\n    ","ac5c398c":"<a id='3'><\/a><br>\n# Univarite Variable Analysis\n* Categorical Variable : ChestPainType, Sex, ST_Slope, ExerciseAngina, RestingECG\n* Numerical Variable : Age, RestingBP, Cholesterol, FastingBS, MaxHR, Oldpeak, HeartDisease","55176582":"<a id='6'><\/a><br>\n\n# Basic Data Analysis\n* ChestPainType - HeartDisease\n* Sex - HeartDisease\n* RestinECG - HeartDisease\n* ExerciseAngina - HeartDisease\n* ST_Slope - HeartDisease","25b9c816":"<a id='7'><\/a><br>\n# Outlier Detection"}}