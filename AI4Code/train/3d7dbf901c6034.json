{"cell_type":{"7fac98e5":"code","0762fd3d":"code","bc8494dd":"code","2be8575f":"code","7e560208":"code","0f47dbc6":"code","dd1d60e4":"code","f716eca0":"code","c75c7f98":"code","db6d3f4f":"code","15706866":"code","a125e71f":"code","3904ab2f":"code","326e81b9":"code","355a4a42":"code","d426c473":"code","5d4c11e0":"code","e1160095":"code","8b5724b3":"code","f5686356":"code","4e8ba3d5":"code","c0185309":"code","23f24bf0":"code","dddf49b6":"code","4c8aad78":"code","610e828b":"markdown","491247df":"markdown","e7e22cc6":"markdown","c04ae6ef":"markdown","f351e512":"markdown","f3fc5478":"markdown","c6b92c05":"markdown","2789d822":"markdown","caccd19e":"markdown"},"source":{"7fac98e5":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LinearRegression","0762fd3d":"rides_df = pd.read_csv('..\/input\/uber-lyft-cab-prices\/cab_rides.csv')\nweather_df = pd.read_csv('..\/input\/uber-lyft-cab-prices\/weather.csv')","bc8494dd":"rides_df","2be8575f":"rides_df.info()","7e560208":"weather_df","0f47dbc6":"weather_df.info()","dd1d60e4":"rides_df","f716eca0":"rides_df.isna().sum()","c75c7f98":"rides_df = rides_df.dropna(axis=0).reset_index(drop=True)","db6d3f4f":"weather_df","15706866":"weather_df.isna().sum()","a125e71f":"weather_df = weather_df.fillna(0)","3904ab2f":"weather_df","326e81b9":"weather_df.groupby('location').mean()","355a4a42":"avg_weather_df = weather_df.groupby('location').mean().reset_index(drop=False)\navg_weather_df = avg_weather_df.drop('time_stamp', axis=1)\navg_weather_df","d426c473":"rides_df","5d4c11e0":"source_weather_df = avg_weather_df.rename(\n    columns={\n        'location': 'source',\n        'temp': 'source_temp',\n        'clouds': 'source_clouds',\n        'pressure': 'source_pressure',\n        'rain': 'source_rain',\n        'humidity': 'source_humidity',\n        'wind': 'source_wind'\n    }\n)\n\nsource_weather_df","e1160095":"destination_weather_df = avg_weather_df.rename(\n    columns={\n        'location': 'destination',\n        'temp': 'destination_temp',\n        'clouds': 'destination_clouds',\n        'pressure': 'destination_pressure',\n        'rain': 'destination_rain',\n        'humidity': 'destination_humidity',\n        'wind': 'destination_wind'\n    }\n)\n\ndestination_weather_df","8b5724b3":"data = rides_df\\\n    .merge(source_weather_df, on='source')\\\n    .merge(destination_weather_df, on='destination')\n\ndata","f5686356":"def onehot_encode(df, column, prefix):\n    df = df.copy()\n    dummies = pd.get_dummies(df[column], prefix=prefix)\n    df = pd.concat([df, dummies], axis=1)\n    df = df.drop(column, axis=1)\n    return df","4e8ba3d5":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Drop id column\n    df = df.drop('id', axis=1)\n    \n    # Binary encode cab_type column\n    df['cab_type'] = df['cab_type'].replace({'Lyft': 0, 'Uber': 1})\n    \n    # One-hot encode remaining categorical columns\n    for column, prefix in [('destination', \"dest\"), ('source', \"src\"), ('product_id', \"pid\"), ('name', \"nm\")]:\n        df = onehot_encode(df, column=column, prefix=prefix)\n    \n    # Split df into X and y\n    y = df['price']\n    X = df.drop('price', axis=1)\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True, random_state=1)\n    \n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    \n    X_train = pd.DataFrame(scaler.transform(X_train), columns=X.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n    \n    return X_train, X_test, y_train, y_test","c0185309":"X_train, X_test, y_train, y_test = preprocess_inputs(data)","23f24bf0":"X_train","dddf49b6":"y_train","4c8aad78":"model = LinearRegression()\nmodel.fit(X_train, y_train)\n\nprint(\"Test R^2 Score: {:.5f}\".format(model.score(X_test, y_test)))","610e828b":"# Training","491247df":"# Cleaning Ride Data","e7e22cc6":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/0qSPtCw0InE","c04ae6ef":"# Creating Average Weather DataFrame","f351e512":"# Merging DataFrames","f3fc5478":"# Preprocessing","c6b92c05":"# Task for Today  \n\n***\n\n## Lyft\/Uber Price Prediction  \n\nGiven *data about Lyft and Uber rides*, let's try to predict the **price** of a given ride.  \n  \nWe will use a linear regression model to make our predictions.","2789d822":"# Getting Started","caccd19e":"# Cleaning Weather Data"}}