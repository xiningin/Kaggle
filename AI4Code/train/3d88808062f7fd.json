{"cell_type":{"3fdcf8e9":"code","11b96110":"code","c2af3f70":"code","10038393":"code","9e144e7d":"code","25e6c195":"code","6debb8ec":"code","a0e20235":"code","6537db17":"code","d5aff97c":"code","7dced104":"code","1c7b866e":"code","4ac1e7e2":"code","64eee22c":"code","d03d954e":"code","ef8ac43f":"code","7f8b2042":"code","8978da2d":"code","3e708b1e":"code","b240c1e8":"code","3b36cc27":"code","008b06d0":"code","e09bf445":"code","8dc56317":"code","3e7d7497":"markdown","b0873631":"markdown","6d6a1176":"markdown","388722b2":"markdown"},"source":{"3fdcf8e9":"import pandas as pd       \nimport matplotlib as mat\nimport matplotlib.pyplot as plt    \nimport numpy as np\nimport seaborn as sns\n%matplotlib inline\n\nimport random\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\n\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import callbacks","11b96110":"#Trying to get reproducible results\nfrom numpy.random import seed\nseed(42)\nfrom tensorflow.random import set_seed\nset_seed(42)\n\nrandom.seed(42)\nos.environ['PYTHONHASHSEED'] = str(42)","c2af3f70":"df_train = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv', index_col = 'id')\nY_train = df_train['target'].copy()\nX_train = df_train.copy().drop('target', axis = 1)\n\nX_test = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv', index_col = 'id')","10038393":"scaler = StandardScaler()\n\nX_concat = pd.concat([X_train, X_test]).reset_index(drop=True)\nfor col in X_train.columns:\n    #X_concat[col] = np.log(X_concat[col]-(min(X_concat[col]-1)))\n    X_concat[col] = np.log1p(X_concat[col])\nX_concat = pd.DataFrame(scaler.fit_transform(X_concat), columns = X_train.columns)\nX_concat","9e144e7d":"X_concat.info()","25e6c195":"X_train_logscaled = X_concat[:X_train.shape[0]][X_train.columns]\nX_test_logscaled = X_concat[X_train.shape[0]:][X_train.columns].reset_index(drop=True)\n\nX_train_logscaled","6debb8ec":"X_test_logscaled","a0e20235":"class_map = {'Class_1': 0,\n            'Class_2': 1,\n            'Class_3': 2,\n            'Class_4': 3,\n            'Class_5': 4,\n            'Class_6': 5,\n            'Class_7': 6,\n            'Class_8': 7,\n            'Class_9': 8}\nY_train = Y_train.map(class_map).astype('int')\nY_train","6537db17":"#Converting target series to matrix for multiclass classification on Keras\n\nY_train = to_categorical(Y_train)\nY_train","d5aff97c":"def get_model():\n    model = keras.Sequential([\n        layers.BatchNormalization(input_shape = [75]),\n        layers.Dense(units = 128, activation = 'relu'),\n        layers.BatchNormalization(),\n        layers.Dropout(0.3),\n        layers.Dense(units = 64, activation = 'relu'),\n        layers.BatchNormalization(),\n        layers.Dropout(0.3),\n        layers.Dense(units = 32, activation = 'relu'),\n        layers.BatchNormalization(),\n        layers.Dropout(0.3),    \n        layers.Dense(9, activation = 'softmax'),\n    ])\n    \n    return model","7dced104":"keras.backend.clear_session()\n\nmodel = get_model()\nmodel.compile(loss='categorical_crossentropy', optimizer = keras.optimizers.Adam(learning_rate=0.002), metrics='accuracy')\n\nmodel.summary()","1c7b866e":"X_train_split, X_val_split, Y_train_split, Y_val_split = train_test_split(X_train_logscaled, Y_train, test_size = 0.2, random_state = 42\n                                                    , stratify = Y_train)","4ac1e7e2":"early_stopping = callbacks.EarlyStopping(\n    patience=20,\n    min_delta=0.0000001,\n    restore_best_weights=True,\n)\n\n#New callback\nplateau = callbacks.ReduceLROnPlateau(\n    factor = 0.5,                                     \n    patience = 2,                                   \n    min_delt = 0.0000001,                                \n    cooldown = 0,                               \n    verbose = 1\n) ","64eee22c":"history = model.fit(X_train_split, Y_train_split,\n          batch_size = 128, epochs = 100,\n          validation_data=(X_val_split, Y_val_split),\n          callbacks=[early_stopping, plateau]);","d03d954e":"score = model.evaluate(X_val_split, Y_val_split, verbose = 0)\nprint('Test loss: {}'.format(score[0]))\nprint('Test accuracy: {}%'.format(score[1] * 100))","ef8ac43f":"fig, ax = plt.subplots(figsize=(20,8))\nsns.lineplot(x = history.epoch, y = history.history['loss'])\nsns.lineplot(x = history.epoch, y = history.history['val_loss'])\nax.set_title('Learning Curve (Loss)')\nax.set_ylabel('Loss')\nax.set_xlabel('Epoch')\nax.legend(['train', 'test'], loc='best')\nplt.show()","7f8b2042":"Y_train = df_train['target'].copy()\nY_train = Y_train.map(class_map).astype('int')\nY_train","8978da2d":"def prediction (X_train, Y_train, X_test):\n    \n    keras.backend.clear_session()\n\n    kfold = StratifiedKFold(n_splits = 10)\n\n    y_pred = np.zeros((100000,9))\n    train_oof = np.zeros((200000,9))\n    \n    for idx in kfold.split(X=X_train, y=Y_train):\n        train_idx, val_idx = idx[0], idx[1]\n        xtrain = X_train.iloc[train_idx]\n        ytrain = Y_train.iloc[train_idx]\n        xval = X_train.iloc[val_idx]\n        yval = Y_train.iloc[val_idx]\n        \n        ytrain = to_categorical(ytrain)\n        yval = to_categorical(yval)\n        \n        # fit model for current fold\n        model = get_model()\n        model.compile(loss='categorical_crossentropy', optimizer = keras.optimizers.Adam(learning_rate=0.002), metrics='accuracy')\n        \n        model.fit(xtrain, ytrain,\n        batch_size = 128, epochs = 100,\n        validation_data=(xval, yval),\n        callbacks=[early_stopping, plateau]);\n\n        #create predictions\n        y_pred += model.predict(X_test)\/kfold.n_splits\n        print(y_pred)\n               \n        val_pred = model.predict(xval)\n        # getting out-of-fold predictions on training set\n        train_oof[val_idx] = val_pred\n        \n        # calculate and append logloss\n        fold_logloss = metrics.log_loss(yval,val_pred)\n        print(\"Logloss: {0:0.5f}\". format(fold_logloss))\n  \n    return y_pred, train_oof","3e708b1e":"nn_pred, train_oof = prediction (X_train_logscaled, Y_train, X_test_logscaled)","b240c1e8":"print(\"Logloss: {0:0.6f}\".format(metrics.log_loss(Y_train,train_oof)))","3b36cc27":"train_oof = pd.DataFrame(train_oof, columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9'])\ntrain_oof","008b06d0":"pred_test = pd.DataFrame(nn_pred, columns = ['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9'])\npred_test","e09bf445":"train_oof.to_csv('nn_train_oof.csv', index=False)\ntrain_oof","8dc56317":"output = pred_test\noutput['id'] = X_test.index\noutput.to_csv('submission.csv', index=False)\n\noutput","3e7d7497":"## Making Predictions","b0873631":"## Importing Libraries and Datasets","6d6a1176":"# <center>Tabular Playground Series - June\/2021<center>\n## <center>Simple Neural Network with Keras<center>\n---\n\nNeural Network with a similar approach from my [NN notebook in TPS-May Competition](https:\/\/www.kaggle.com\/jonaspalucibarbosa\/tps05-21-nn-with-keras-first-nn). Inspired by [@subinium's](https:\/\/www.kaggle.com\/subinium) notebook [Deeplearning Pipeline for Beginner](https:\/\/www.kaggle.com\/subinium\/tps-may-deeplearning-pipeline-for-beginner) and by some tips that [@pourchot](https:\/\/www.kaggle.com\/pourchot) gave me. This notebook provides a baseline score for NN\u2019s.\n    \nMy other notebooks in this competition:\n- [Tabular Playground Series - June\/2021: Starter - EDA + Base LightGBM](https:\/\/www.kaggle.com\/jonaspalucibarbosa\/tps06-21-starter-eda-base-lgbm)\n- [Tabular Playground Series - June\/2021: Keras Neural Network with Embedding Layer](https:\/\/www.kaggle.com\/jonaspalucibarbosa\/tps06-21-keras-nn-with-embedding)\n- [Tabular Playground Series - June\/2021: Wide and Deep Neural Network with Keras](https:\/\/www.kaggle.com\/jonaspalucibarbosa\/tps06-21-wide-and-deep-nn-w-keras)\n- [Tabular Playground Series - June\/2021: LightAutoML with KNN Features](https:\/\/www.kaggle.com\/jonaspalucibarbosa\/tps06-21-lightautoml-w-knn-feats)\n- [Tabular Playground Series - June\/2021: Keras Neural Network with Skip Connections](https:\/\/www.kaggle.com\/jonaspalucibarbosa\/tps06-21-keras-nn-with-skip-connections)\n","388722b2":"## Creating and Evaluating the NN"}}