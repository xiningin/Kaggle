{"cell_type":{"99b9da27":"code","d2740371":"code","c3f0d78f":"code","36d8d2a7":"code","0cdc9290":"code","8ff6b742":"code","d8048734":"code","70545729":"code","8042a25b":"markdown","b2f699a4":"markdown","9421ba85":"markdown","d05a6286":"markdown","8ff3b185":"markdown","28a74309":"markdown","97b9d8b4":"markdown","f5515e3f":"markdown","9b0316fd":"markdown","4f2c2261":"markdown"},"source":{"99b9da27":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom itertools import combinations\nfrom collections import Counter\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d2740371":"# Create a list of data files from data dir.also import os\ndata_files_list = [file for file in os.listdir('..\/input\/sales-data-for-eda\/Sales_Data\/')]\n\n# Create an empty DF\ncombined_data = pd.DataFrame()\n\n# read each file in df and then concatenate with empty DF\n\nfor file in data_files_list:\n    temp_df = pd.read_csv('..\/input\/sales-data-for-eda\/Sales_Data\/'+file)\n    combined_data = pd.concat([combined_data, temp_df])\n\ncombined_data.to_csv('all_data_combined.csv', index=False)\n\n#data combined. Now read the combined file directly and use for analysis\nall_data = pd.read_csv('all_data_combined.csv')\n","c3f0d78f":"# find rows with NaN across df\n# nan_df = all_data[all_data.isna().any(axis=1)]\n# print(nan_df.head())\n# Drop nan from nan_df\nall_data = all_data.dropna(how='all')\n\n# #Check for error with unexpected field name starting 'Or'\nall_data = all_data[all_data['Order Date'].str[0:2] != 'Or']\n# print(temp_df.to_string())\n\n# Create a new column called Month, extract month number from Order Data and convert Month to int.\nall_data['Month'] = all_data['Order Date'].str[0:2]\nall_data['Month'] = all_data['Month'].astype('int')\n\n# Change column type of price and quantity to integer and float respectively\nall_data['Quantity Ordered'] = pd.to_numeric(all_data['Quantity Ordered']) #To int\nall_data['Price Each'] = pd.to_numeric(all_data['Price Each']) #To float\n# print(all_data.head().to_string())\n","36d8d2a7":"#Create column to calculate sales - quantity * price\nall_data['Sales'] = all_data['Quantity Ordered'] * all_data['Price Each']\n# print(all_data.head().to_string())\n\nsales_sum = all_data.groupby('Month').sum()\nprint(sales_sum)\n\n# Create bar chart using matplotlib and format\nimport matplotlib.pyplot as plt\nmonths = range(1,13)\nplt.bar(months, sales_sum['Sales'])\nplt.title('Monthly Sales comparision chart.')\nplt.xticks(months)\nplt.xlabel('Month number')\nplt.ylabel('Sales in USD ($)')\nplt.show()\nprint('A: December is the best month for sales, followed by October. The reason could be festive sales where the ecommerce industry witnesses a major sales boost.')","0cdc9290":"# create a city column by extracting city name off the address\n\n# City Splitter func definition\ndef get_city(address):\n    return address.split(',')[1]\n\n# State Splitter to avoid issues with multiple cities with same names\ndef get_state(address):\n    return address.split(',')[2].split(' ')[1]\n\n# Two option to split. Lambda function or lambda function call\nall_data['City'] = all_data['Purchase Address'].apply(lambda x: x.split(',')[1])\nall_data['City'] = all_data['Purchase Address'].apply(lambda x: get_city(x) + ' (' + get_state(x) + ')')\nall_data['City'] = all_data['Purchase Address'].apply(lambda x: f\"{get_city(x)} ({get_state(x)}) \")  #F string variation\n\n#City sales group by\ncitywise_sales = all_data.groupby('City').sum()\nprint(citywise_sales.to_string())\n\n# Create City wise sales bar chart\nimport matplotlib.pyplot as plt\ncities = [city for city, df in all_data.groupby('City')]  #List comprehension to match order of data\nplt.bar(cities, citywise_sales['Sales'])\nplt.xticks(cities, rotation='vertical', size=8)\nplt.xlabel('City Name (State)')\nplt.ylabel('Sales in USD ($)')\nplt.title('City-wise Sales in USA')\nplt.show()\n\nprint('A: San Francisco has the highest sales in US, followed by Los Angeles.')","8ff6b742":"#Covert data to date\/time object using data-time functions by making hour and minute columns\nall_data['Order Date'] = pd.to_datetime(all_data['Order Date']) #Create date\/time object\nall_data['Hour'] = all_data['Order Date'].dt.hour\nall_data['Minute'] = all_data['Order Date'].dt.minute\n\nhours = [hour for hour, df in all_data.groupby('Hour')]  #List comprehension to match order of data #Create list of 24 hours for analysis\nplt.plot(hours, all_data.groupby(['Hour']).count()) #count the orders each hours of the day\nplt.xticks(hours)\nplt.xlabel('Hour of the day')\nplt.ylabel('Number of orders')\nplt.grid()\nplt.title('Hour wise order analysis')\nplt.show()\n\nprint('A: 12pm and 7pm is probably the best time to advertise to maximise product purchase.')\n# print(all_data.head().to_string())\n","d8048734":"#Create a new df with duplicated order. Duplicated order indicates order with two or more products. keep=False to use all occurances\ncombo_df = all_data[all_data['Order Date'].duplicated(keep=False)]\n#Create a new column, group by orderid and combine products in a single cell comma separated\ncombo_df['Best Combo'] = combo_df.groupby('Order ID')['Product'].transform(lambda x: ','.join(x))\n#Remove duplicated entry and show only orderid and combo column results\ncombo_df = combo_df[['Order ID', 'Best Combo']].drop_duplicates()\n# print(combo_df.head())\n\n#Count the occurances\nfrom itertools import combinations\nfrom collections import Counter\n\n#count the combination of 2 products using the above mentioned libs.\ncount = Counter()\n#iterate through each cell, split products in a list and count\nfor row in combo_df['Best Combo']:\n    row_list = row.split(',')\n    count.update(Counter(combinations(row_list, 2))) #group of 2. Change to 3 for group of 3s\n\n#Most common occurance\nfor key, value in count.most_common(10):\n    print(key, value)\n    \nprint('\\n\\nA: iPhone along with Lightning Charging Cable is best selling product combination.')\n","70545729":"product_group = all_data.groupby('Product')\nquantity_ordered = product_group.sum()['Quantity Ordered']\n\nproducts = [product for product, df in product_group]\nplt.bar(products, quantity_ordered)\nplt.xticks(products, rotation='vertical', size=8)\nplt.xlabel('Product name')\nplt.ylabel('Quantity ordered')\nplt.title('Top selling products')\nplt.show()\n\n#Find price of the best selling products\nprices = all_data.groupby('Product').mean()['Price Each']\n\n#Find corelation between best products and their price\n#Add the second axis at y for price comparision in the same graph\nfig, ax1 = plt.subplots()\nax2 = ax1.twinx()\nax1.bar(products, quantity_ordered, color='g')\nax2.plot(products, prices, 'b-') #Second axis on y\n\nax1.set_xlabel('Product Name')\nax1.set_ylabel('Quantity Ordered', color='g')\nax1.title.set_text('Correlation betwen top selling products and its price')\nax2.set_ylabel('Price', color='b')\nax1.set_xticklabels(products, rotation='vertical', size=8)\nplt.show()\nprint(\"A: The top selling product is 'AAA Batteries'. The top selling products seem to have a correlation with the price of the product. The cheaper the product higher the quantity ordered and vice versa.\")","8042a25b":"# Q. What product sold the most? Why?","b2f699a4":"*Credit to Keith Galli for sharing such a cool project tutorial!*","9421ba85":"# An analysis of the sales data of electronic products in USA.","d05a6286":"# Merge 12 months of sales data into a single csv file**","8ff3b185":"# Q. Which city has the highest sales?","28a74309":"# Q. What time should we display advertisements to maximise for product purchase?","97b9d8b4":"# Q. What is the best month for sale? How much was earned?","f5515e3f":"# Q. What products are most often sold together?","9b0316fd":"# Data cleaning and formatting","4f2c2261":"Importing the required libraries and the database for our analysis."}}