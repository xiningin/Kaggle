{"cell_type":{"5e955695":"code","b9742ef9":"code","86280bb8":"code","5aef4fda":"code","c1f5fc68":"code","28dde445":"code","246fe25d":"code","5fd47cb2":"code","e0b25e27":"code","13a766ec":"code","7fe05e63":"code","13f8baa8":"code","edfed9d6":"code","d8e5e658":"code","cda62dc4":"code","a0ad20dd":"code","8243ed6e":"code","d5aa20ea":"code","fb78a510":"code","3299b4a9":"code","0a40ac6f":"code","e6e18171":"code","2a37adff":"markdown","8ad51c2d":"markdown","738a162a":"markdown","88798fb4":"markdown","86a463a7":"markdown","40a19d5e":"markdown"},"source":{"5e955695":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b9742ef9":"# imports\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import signal\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, f1_score, plot_confusion_matrix\nfrom keras.models import Model\nimport keras.layers as L\nimport lightgbm as lgb\n\n!pip install uc==2.2.0","86280bb8":"# read data\ndata = pd.read_csv('..\/input\/data-without-drift\/train_clean.csv')\ndata.head()","5aef4fda":"def calc_gradients(s, n_grads=4):\n    '''\n    Calculate gradients for a pandas series. Returns the same number of samples\n    '''\n    grads = pd.DataFrame()\n    \n    g = s.values\n    for i in range(n_grads):\n        g = np.gradient(g)\n        grads['grad_' + str(i+1)] = g\n        \n    return grads","c1f5fc68":"def calc_low_pass(s, n_filts=10):\n    '''\n    Applies low pass filters to the signal. Left delayed and no delayed\n    '''\n    wns = np.logspace(-2, -0.3, n_filts)\n    \n    low_pass = pd.DataFrame()\n    x = s.values\n    for wn in wns:\n        b, a = signal.butter(1, Wn=wn, btype='low')\n        zi = signal.lfilter_zi(b, a)\n        low_pass['lowpass_lf_' + str('%.4f' %wn)] = signal.lfilter(b, a, x, zi=zi*x[0])[0]\n        low_pass['lowpass_ff_' + str('%.4f' %wn)] = signal.filtfilt(b, a, x)\n        \n    return low_pass","28dde445":"def calc_high_pass(s, n_filts=10):\n    '''\n    Applies high pass filters to the signal. Left delayed and no delayed\n    '''\n    wns = np.logspace(-2, -0.1, n_filts)\n    \n    high_pass = pd.DataFrame()\n    x = s.values\n    for wn in wns:\n        b, a = signal.butter(1, Wn=wn, btype='high')\n        zi = signal.lfilter_zi(b, a)\n        high_pass['highpass_lf_' + str('%.4f' %wn)] = signal.lfilter(b, a, x, zi=zi*x[0])[0]\n        high_pass['highpass_ff_' + str('%.4f' %wn)] = signal.filtfilt(b, a, x)\n        \n    return high_pass","246fe25d":"def calc_roll_stats(s, windows=[10, 50, 100, 500, 1000]):\n    '''\n    Calculates rolling stats like mean, std, min, max...\n    '''\n    roll_stats = pd.DataFrame()\n    for w in windows:\n        roll_stats['roll_mean_' + str(w)] = s.rolling(window=w, min_periods=1).mean()\n        roll_stats['roll_std_' + str(w)] = s.rolling(window=w, min_periods=1).std()\n        roll_stats['roll_min_' + str(w)] = s.rolling(window=w, min_periods=1).min()\n        roll_stats['roll_max_' + str(w)] = s.rolling(window=w, min_periods=1).max()\n        roll_stats['roll_range_' + str(w)] = roll_stats['roll_max_' + str(w)] - roll_stats['roll_min_' + str(w)]\n        roll_stats['roll_q10_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.10)\n        roll_stats['roll_q25_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.25)\n        roll_stats['roll_q50_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.50)\n        roll_stats['roll_q75_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.75)\n        roll_stats['roll_q90_' + str(w)] = s.rolling(window=w, min_periods=1).quantile(0.90)\n    \n    # add zeros when na values (std)\n    roll_stats = roll_stats.fillna(value=0)\n             \n    return roll_stats","5fd47cb2":"def calc_ewm(s, windows=[10, 50, 100, 500, 1000]):\n    '''\n    Calculates exponential weighted functions\n    '''\n    ewm = pd.DataFrame()\n    for w in windows:\n        ewm['ewm_mean_' + str(w)] = s.ewm(span=w, min_periods=1).mean()\n        ewm['ewm_std_' + str(w)] = s.ewm(span=w, min_periods=1).std()\n        \n    # add zeros when na values (std)\n    ewm = ewm.fillna(value=0)\n        \n    return ewm","e0b25e27":"def add_features(s):\n    '''\n    All calculations together\n    '''\n    \n    gradients = calc_gradients(s)\n    low_pass = calc_low_pass(s)\n    high_pass = calc_high_pass(s)\n    roll_stats = calc_roll_stats(s)\n    ewm = calc_ewm(s)\n    \n    return pd.concat([s, gradients, low_pass, high_pass, roll_stats, ewm], axis=1)\n\n\ndef divide_and_add_features(s, signal_size=500000):\n    '''\n    Divide the signal in bags of \"signal_size\".\n    Normalize the data dividing it by 15.0\n    '''\n    # normalize\n    s = s\/15.0\n    \n    ls = []\n    for i in tqdm(range(int(s.shape[0]\/signal_size))):\n        sig = s[i*signal_size:(i+1)*signal_size].copy().reset_index(drop=True)\n        sig_featured = add_features(sig)\n        ls.append(sig_featured)\n    \n    return pd.concat(ls, axis=0)","13a766ec":"# apply every feature to data\ndf = divide_and_add_features(data['signal'])\ndf.head()","7fe05e63":"# The low pass lfilter captures the trend of the signal for different cutoff frequencies\ndf[['signal',\n    'lowpass_lf_0.0100',\n    'lowpass_lf_0.0154',\n    'lowpass_lf_0.0239',\n    'lowpass_lf_0.0369',\n    'lowpass_lf_0.5012']].iloc[:200].plot()","13f8baa8":"# The low pass filtfilt captures the trend of the signal for different cutoff frequencies\n# but without delay\ndf[['signal',\n    'lowpass_ff_0.0100',\n    'lowpass_ff_0.0154',\n    'lowpass_ff_0.0239',\n    'lowpass_ff_0.0369',\n    'lowpass_ff_0.5012']].iloc[:200].plot()","edfed9d6":"# The high pass lfilter captures fast variation of the signal for different cutoff frequencies\ndf[['signal',\n    'highpass_lf_0.0100',\n    'highpass_lf_0.0163',\n    'highpass_lf_0.0264',\n    'highpass_lf_0.3005',\n    'highpass_lf_0.7943']].iloc[:100].plot()","d8e5e658":"# The high pass lfilter captures fast variation of the signal for different cutoff frequencies\n# but without delay\ndf[['signal',\n    'highpass_ff_0.0100',\n    'highpass_ff_0.0163',\n    'highpass_ff_0.0264',\n    'highpass_ff_0.3005',\n    'highpass_ff_0.7943']].iloc[:200].plot()","cda62dc4":"# rolling mean, quantiles and ewm also capture the trend\ndf[['signal',\n    'roll_mean_10',\n    'roll_mean_50',\n    'roll_mean_100',\n    'roll_q50_100',\n    'ewm_mean_10',\n    'ewm_mean_50',\n    'ewm_mean_100']].iloc[:100].plot()","a0ad20dd":"# quantiles, min, max\ndf[['signal',\n    'roll_min_100',\n    'roll_q10_100',\n    'roll_q25_100',\n    'roll_q50_100',\n    'roll_q75_100',\n    'roll_q90_100',\n    'roll_max_100']].iloc[:1000].plot()","8243ed6e":"# rolling std, and emw std\ndf[['signal',\n    'roll_std_10',\n    'roll_std_50',\n    'ewm_std_10',\n    'ewm_std_50']].iloc[:100].plot()","d5aa20ea":"# Get train and test data\nx_train, x_test, y_train, y_test = train_test_split(df.values, data['open_channels'].values, test_size=0.2)\n\ndel data, df\nprint('x_train.shape=', x_train.shape)\nprint('x_test.shape=', x_test.shape)\nprint('y_train.shape=', y_train.shape)\nprint('y_test.shape=', y_test.shape)","fb78a510":"def get_class_weight(classes, exp=1):\n    '''\n    Weight of the class is inversely proportional to the population of the class.\n    There is an exponent for adding more weight.\n    '''\n    hist, _ = np.histogram(classes, bins=np.arange(12)-0.5)\n    class_weight = hist.sum()\/np.power(hist, exp)\n    \n    return class_weight\n\nclass_weight = get_class_weight(y_train)\nprint('class_weight=', class_weight)\nplt.figure()\nplt.title('classes')\nplt.hist(y_train, bins=np.arange(12)-0.5)\nplt.figure()\nplt.title('class_weight')\nplt.bar(np.arange(11), class_weight)\nplt.title('class_weight')","3299b4a9":"from uc.mlp import MLP\n\nmlp = MLP(\n    layer_size = [x_train.shape[1], 100, 100, 100, 11],\n    activation = 'a2m2l',\n    op='fc',\n\n    # rate_init = 0.08, \n    leaky = -0.2,\n    rate_init = 0.04,   \n    bias_rate = [], \n    regularization = 1,\n    importance_mul = 0.0001, \n    output_shrink = 0.1, \n    output_range = None, \n    loss_type = \"softmax\",\n    verbose=1, \n    importance_out=False,\n    rate_decay = 0.9, \n    epoch_train = 30 \/ 10 \/ 3, \n    epoch_decay = 3 \/ 10 \/ 3,\n    epoch_log = 0.01,\n)\n\n\n","0a40ac6f":"# fit the model\nmlp.fit(x_train, y_train)","e6e18171":"print('Reading data...')\ndata = pd.read_csv('..\/input\/data-without-drift\/test_clean.csv')\n\nprint('Feature engineering...')\ndf = divide_and_add_features(data['signal'])\n\n\nmlp_pred = mlp.predict(df.values)\nmlp_pred = np.clip(mlp_pred, 0, 10)\nmlp_pred = np.int0(np.rint(mlp_pred))\n\nprint('Writing submission...')\nsubmission = pd.DataFrame()\nsubmission['time'] = data['time']\nsubmission['open_channels'] = mlp_pred\nsubmission.to_csv('submission.csv', index=False, float_format='%.4f')\n\nprint('Submission finished!')\n\nsubmit_result(mlp_pred)","2a37adff":"# Feature engineering\nAdd to signal several other signals: gradients, rolling mean, std, low\/high pass filters...\n\nFE is the same as this notebook https:\/\/www.kaggle.com\/martxelo\/fe-and-simple-mlp with corrections in filters.","8ad51c2d":"Let's plot the signals to see how they look like.","738a162a":"# Build a MLP model","88798fb4":"# Divide in train and test","86a463a7":"# Classes weights","40a19d5e":"# Load data\nThanks to https:\/\/www.kaggle.com\/cdeotte\/data-without-drift."}}