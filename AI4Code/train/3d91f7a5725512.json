{"cell_type":{"b308f04f":"code","ccd633be":"code","5e75de14":"code","279f06e8":"code","8c4522c7":"code","11849270":"code","d2e3abab":"code","14929c91":"code","787f0728":"code","8fb2b20d":"code","6297e162":"code","fa451790":"code","257fc439":"code","fa452e49":"code","6df898b1":"code","20ef6914":"code","89d80d36":"code","6d98ab15":"code","34603e01":"code","ed82033d":"code","972417cb":"code","b4fc0ae3":"code","cd092730":"code","d794e8bf":"markdown","f2bd6f42":"markdown","8846ecaa":"markdown","2e52e2e5":"markdown","129a4715":"markdown","60795a45":"markdown","8bfbf875":"markdown","9e1ff8fa":"markdown","597756cc":"markdown"},"source":{"b308f04f":"# Veamos la data que tenemos\n!ls ..\/input","ccd633be":"!ls -U ..\/input\/train\/ | tail -n 5","5e75de14":"!ls ..\/input\/test\/ | tail -n 5","279f06e8":"import math\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tqdm import tqdm_notebook\nfrom pathlib import Path\n%matplotlib inline","8c4522c7":"train_path = Path('..\/input\/train\/')\ncat_imgs, dog_imgs = [], []\nfor e in train_path.iterdir():\n    if 'cat' in e.name: cat_imgs.append(e)\n    else              : dog_imgs.append(e)\nlen(cat_imgs), len(dog_imgs)","11849270":"# Definimos una funcion para leer una imagen y hacer el preprocesamiento\nfrom keras.applications.resnet50 import preprocess_input\nimg_size = 224\n\ndef read_img(path):\n    x = Image.open(path)\n    x = x.resize((img_size, img_size))\n    x = np.asarray(x, np.float32)\n    return preprocess_input(x)","d2e3abab":"# Cargamos una muestra de imagenes para train y validation\n\n# Primero inicializamos los arrays que vamos a usar\nx_train = np.ndarray(shape=(2000, img_size, img_size, 3), dtype=np.float32)\ny_train = np.zeros(shape=(2000), dtype=np.int8)\nx_val = np.ndarray(shape=(200, img_size, img_size, 3), dtype=np.float32)\ny_val = np.zeros(shape=(200), dtype=np.int8)","14929c91":"# Cargamos el train set\nfor i,e in tqdm_notebook(enumerate(cat_imgs[:1000] + dog_imgs[:1000])):\n    x_train[i] = read_img(e)\n\ny_train[1000:] = 1 # cat -> 0 | dog -> 1","787f0728":"# Cargamos el validation set\nfor i,e in tqdm_notebook(enumerate(cat_imgs[1000:1100] + dog_imgs[1000:1100])):\n    x_val[i] = read_img(e)\n\ny_val[100:] = 1 # cat -> 0 | dog -> 1","8fb2b20d":"from keras.applications.resnet50 import ResNet50\nbase_model = ResNet50(include_top=False, input_shape=(img_size,img_size,3), pooling='avg')\nbase_model.summary()","6297e162":"base_model.input, base_model.output","fa451790":"# Dado que solo queremos entrenar las capas densas del modelo que agregaremos\n# en el siguiente paso, vamos a setear \"trainable = False\" para que los pesos\n# de la red entrenada no cambien.\nbase_model.trainable = False","257fc439":"from keras.models import Sequential\nfrom keras.layers import Dense, Flatten\nfrom keras.optimizers import Adam\n\ntop_model = Sequential([\n    Dense(128, activation='relu', input_shape=(2048,)),\n    Dense(1, activation='sigmoid')\n])\n\ntop_model.compile(loss='binary_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\ntop_model.summary()","fa452e49":"final_model = Sequential([base_model, top_model])\n\nfinal_model.compile(loss='binary_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\nfinal_model.summary()","6df898b1":"# log = final_model.fit(x_train, y_train, batch_size=64, validation_data=[x_val, y_val])","20ef6914":"precomputed_train = base_model.predict(x_train, batch_size=128, verbose=1)\nprecomputed_train.shape","89d80d36":"precomputed_val = base_model.predict(x_val, batch_size=128, verbose=1)\nprecomputed_val.shape","6d98ab15":"# Ahora podemos usar un batch_size mas grande, ya que los features son mas peque\u00f1os\n# que las imagenes.\nlog = top_model.fit(precomputed_train, y_train, epochs=5, batch_size=256, validation_data=[precomputed_val, y_val])","34603e01":"def show_results(log):\n    fig, axes = plt.subplots(1, 2, figsize=(14,4))\n    ax1, ax2 = axes\n    ax1.plot(log.history['loss'], label='train')\n    ax1.plot(log.history['val_loss'], label='validation')\n    ax1.set_xlabel('epoch'); ax1.set_ylabel('loss')\n    ax2.plot(log.history['acc'], label='train')\n    ax2.plot(log.history['val_acc'], label='validation')\n    ax2.set_xlabel('epoch'); ax2.set_ylabel('accuracy')\n    for ax in axes: ax.legend()","ed82033d":"show_results(log)","972417cb":"test_path = Path('..\/input\/test\/')\ntest_files = list(test_path.iterdir())","b4fc0ae3":"def get_class(path):\n    # Cargar la imagen del path\n    img = Image.open(path)\n    \n    # Cambiar el tama\u00f1o de la imagen\n    img_resized = img.resize((224, 224))\n    \n    # Cambiar a formato numpy y preprocesar\n    x = np.asarray(img_resized, np.float32)[None]\n    x = preprocess_input(x)\n    \n    # Obtener predicciones\n    y = final_model.predict(x)\n    \n    # Decodear predicciones\n    pred = 'cat' if y < 0.5 else 'dog'\n    \n    # Mostrar la imagen\n    plt.imshow(img)\n    plt.axis('off')\n    plt.title(pred, size=14)\n    \n    return","cd092730":"sample = np.random.choice(test_files)\nget_class(sample)","d794e8bf":"La red de base que estamos usando (ResNet50) tiene bastantes capas y hacer todas estas operaciones toma un tiempo considerable, en CPU hacer este entrenamiento puede resultar impractico.\n# Precompute\nSi tenemos en cuenta que vamos a entrenar nuestro dataset un cierto n\u00famero de \u00e9pocas, en cada \u00e9poca se van a repetir exactamente las mismas operaciones en la misma data. Para no redundar, es bastante \u00fatil hacer un precompute de la data:\n1. Pasar todas nuestras imagenes por la red base (ResNet50).\n2. Guardamos los features extraidos.\n3. Entrenamos las capas densas con los features extraidos.","f2bd6f42":"https:\/\/www.kaggle.com\/c\/dogs-vs-cats-redux-kernels-edition","8846ecaa":"# Ejercicio: usando el modelo completo en el test set","2e52e2e5":"# Cargando las imagenes","129a4715":"# Creamos el modelo clasificador","60795a45":"# Entrenando en nuestro dataset","8bfbf875":"# Entrenar a partir de los features extraidos","9e1ff8fa":"# Cargamos una red entrenada\nVamos a cargar la red **ResNet50** ya entrenada, pero sin incluir las capas densas, ya que vamos a adaptar la red a nuestro caso espec\u00edfico.","597756cc":"# Juntamos los 2 modelos"}}