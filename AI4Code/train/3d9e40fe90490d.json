{"cell_type":{"21d5d428":"code","d3154adc":"code","31ed8e07":"code","185e7799":"code","655ed108":"code","056a2175":"code","aff4a9a8":"code","1848dbed":"code","c0257b6a":"code","931fa511":"code","2e819b70":"code","bfa59533":"code","6b1ce20d":"code","83e2e9c3":"code","e653ef02":"code","c15147af":"code","9bc3b790":"code","b91a0c90":"code","d4e098b1":"code","eca3a386":"code","99fcd776":"code","4d49aad8":"code","15574e4f":"code","650a5271":"code","8b6bae26":"code","2e6cd4c9":"code","d1aabe5b":"code","6c605b74":"code","f0480c18":"code","4493b8fa":"code","624609e7":"code","ba1b9422":"code","f3f1e585":"code","d4e69902":"code","fd5475d2":"code","3e0a46ba":"code","87260ba8":"code","ccecce3a":"code","6b9a27f2":"code","cf957311":"code","741860a0":"code","13d58979":"code","e51070f2":"code","c2407f87":"code","d525a82e":"code","eff47809":"code","ac143337":"code","7931cbb2":"code","05d542d7":"code","14daa8ed":"markdown","0f172a72":"markdown","5d027b56":"markdown","dc251eca":"markdown","0c0afa9b":"markdown","2d7747af":"markdown","60f8331f":"markdown","db159aa6":"markdown","86eadfa5":"markdown","14a990d0":"markdown","91ae3676":"markdown","3a519cb4":"markdown","7616488c":"markdown","65bdcc50":"markdown","bd363c82":"markdown","48c8d427":"markdown","0990601b":"markdown","5b4f7f6a":"markdown","b5aa6d94":"markdown","08aa4a8c":"markdown","462702cb":"markdown","8824f8c3":"markdown"},"source":{"21d5d428":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport os\nfrom scipy import stats\n\nfrom tqdm import tqdm_notebook as tqdm\ntqdm().pandas()\n\n\nimport matplotlib.pylab as plt\nfrom matplotlib.patches import Circle, Rectangle, Arc\nimport seaborn as sns\n\nplt.style.use('seaborn-dark-palette')\nmypal = plt.rcParams['axes.prop_cycle'].by_key()['color'] # Grab the color pal\n\nimport gc\n\nimport eli5\n\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import GridSearchCV, KFold, train_test_split, cross_val_score, \\\n                                        RepeatedStratifiedKFold, StratifiedKFold\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.dummy import DummyClassifier\n\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.svm import SVC\n\nimport lightgbm as lgb\nimport xgboost as xgb","d3154adc":"PATH_MEN = '\/kaggle\/input\/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament\/'","31ed8e07":"MTeams = pd.read_csv(PATH_MEN + '\/MDataFiles_Stage1\/MTeams.csv')\nMTeams.sort_values(by='FirstD1Season', ascending=False).head(10)","185e7799":"MTeams.sort_values(by='FirstD1Season').head(10)","655ed108":"MSeasons = pd.read_csv(PATH_MEN + 'MDataFiles_Stage1\/MSeasons.csv')\n\nMSeasons.head()","056a2175":"MNCAATourneySeeds = pd.read_csv(PATH_MEN + 'MDataFiles_Stage1\/MNCAATourneySeeds.csv')\nMNCAATourneySeeds.head()","aff4a9a8":"MRegularSeasonCompactResults = pd.read_csv(PATH_MEN + 'MDataFiles_Stage1\/MRegularSeasonCompactResults.csv')\nMRegularSeasonCompactResults.head()","1848dbed":"# Lets Add the winning and losing team names to the results\nMRegularSeasonCompactResults = \\\n    MRegularSeasonCompactResults \\\n    .merge(MTeams[['TeamName', 'TeamID']],\n           left_on='WTeamID',\n           right_on='TeamID',\n           validate='many_to_one') \\\n    .drop('TeamID', axis=1) \\\n    .rename(columns={'TeamName': 'WTeamName'}) \\\n    .merge(MTeams[['TeamName', 'TeamID']],\n           left_on='LTeamID',\n           right_on='TeamID') \\\n    .drop('TeamID', axis=1) \\\n    .rename(columns={'TeamName': 'LTeamName'})\n\nMRegularSeasonCompactResults.head()","c0257b6a":"MRegularSeasonCompactResults['Score_Diff'] = MRegularSeasonCompactResults['WScore'] - MRegularSeasonCompactResults['LScore']\n\nplt.style.use('fivethirtyeight')\nMRegularSeasonCompactResults['Score_Diff'] \\\n    .plot(kind='hist',\n          bins=90,\n          figsize=(15, 5),\n          label='Mens',\n          alpha=0.5)\nplt.title('Score Differential')\nplt.xlim(0,60)\nplt.legend()\nplt.show()","931fa511":"MRegularSeasonCompactResults","2e819b70":"plt.style.use('fivethirtyeight')\nfig, axs = plt.subplots(1, 2, figsize=(15, 5))\nMRegularSeasonCompactResults['counter'] = 1\nMRegularSeasonCompactResults.groupby('WTeamName')['counter'] \\\n    .count() \\\n    .sort_values() \\\n    .tail(20) \\\n    .plot(kind='barh',\n          title='\u2b06\ufe0f Most Regular Season Wins (Mens)',\n          figsize=(15, 8),\n          xlim=(600, 920),\n          color=mypal[2],\n         ax=axs[0])\nMRegularSeasonCompactResults.groupby('WTeamName')['counter'] \\\n    .count() \\\n    .sort_values(ascending=False) \\\n    .tail(20) \\\n    .plot(kind='barh',\n          title='\u2b07\ufe0f Least Regular Season Wins (Mens)',\n          figsize=(15, 8),\n          xlim=(0, 150),\n          color=mypal[3],\n          ax=axs[1])\naxs[1].set_ylabel('')\nplt.tight_layout()\nplt.show()","bfa59533":"mens_events = []\nfor year in [2015, 2016, 2017, 2018, 2019]:\n    mens_events.append(pd.read_csv(f'{PATH_MEN}MEvents{year}.csv'))\nMEvents = pd.concat(mens_events)\nprint(MEvents.shape)\nMEvents.head()","6b1ce20d":"del mens_events\ngc.collect()","83e2e9c3":"plt.style.use('fivethirtyeight')\nMEvents['counter'] = 1\nMEvents.groupby('EventType')['counter'] \\\n    .sum() \\\n    .sort_values(ascending=False) \\\n    .plot(kind='bar',\n          figsize=(15, 5),\n         color=mypal[2],\n         title='Event Type Frequency (Mens)')\nplt.xticks(rotation=0)\nplt.show()","e653ef02":"area_mapping = {0: np.nan,\n                1: 'under basket',\n                2: 'in the paint',\n                3: 'inside right wing',\n                4: 'inside right',\n                5: 'inside center',\n                6: 'inside left',\n                7: 'inside left wing',\n                8: 'outside right wing',\n                9: 'outside right',\n                10: 'outside center',\n                11: 'outside left',\n                12: 'outside left wing',\n                13: 'backcourt'}\n\nMEvents['Area_Name'] = MEvents['Area'].map(area_mapping)","c15147af":"MEvents.groupby('Area_Name')['counter'].sum() \\\n    .sort_values() \\\n    .plot(kind='barh',\n          figsize=(15, 8),\n          title='Frequency of Event Area')\nplt.show()","9bc3b790":"fig, ax = plt.subplots(figsize=(15, 8))\nfor i, d in MEvents.loc[~MEvents['Area_Name'].isna()].groupby('Area_Name'):\n    d.plot(x='X', y='Y', style='.', label=i, ax=ax, title='Visualizing Event Areas')\n    ax.legend()\nplt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\nax.set_xticks([])\nax.set_yticks([])\nax.set_xlabel('')\nax.set_xlim(0, 100)\nax.set_ylim(0, 100)\nplt.show()","b91a0c90":"MPlayers = pd.read_csv(PATH_MEN + 'MPlayers.csv', error_bad_lines=False)\n\nMPlayers.head()","d4e098b1":"del MEvents\ndel MNCAATourneySeeds\ndel MPlayers\ndel MRegularSeasonCompactResults\ndel MSeasons\ndel MTeams\ngc.collect()","eca3a386":"tourney_result = pd.read_csv(PATH_MEN + 'MDataFiles_Stage1\/MNCAATourneyCompactResults.csv')\ntourney_result = tourney_result[tourney_result['Season'] < 2015]\n\ntourney_seed = pd.read_csv(PATH_MEN + 'MDataFiles_Stage1\/MNCAATourneySeeds.csv')\ntourney_seed = tourney_seed[tourney_seed['Season'] < 2015]\n\ntourney_result = tourney_result.drop(['DayNum', 'WScore', 'LScore', 'WLoc', 'NumOT'], axis=1)\ntourney_result = pd.merge(tourney_result, tourney_seed, left_on=['Season', 'WTeamID'], right_on=['Season', 'TeamID'], how='left')\ntourney_result.rename(columns={'Seed':'WSeed'}, inplace=True)\n\ntourney_result = tourney_result.drop('TeamID', axis=1)\ntourney_result = pd.merge(tourney_result, tourney_seed, left_on=['Season', 'LTeamID'], right_on=['Season', 'TeamID'], how='left')\ntourney_result.rename(columns={'Seed':'LSeed'}, inplace=True)\n\ntourney_result = tourney_result.drop('TeamID', axis=1)\n\n\ntourney_result['WSeed'] = tourney_result['WSeed'].apply(lambda x: int(x[1:3]))\ntourney_result['LSeed'] = tourney_result['LSeed'].apply(lambda x: int(x[1:3]))","99fcd776":"season_result = pd.read_csv(PATH_MEN + 'MDataFiles_Stage1\/MRegularSeasonCompactResults.csv')\nseason_result = season_result[season_result['Season'] < 2015]\n\nseason_win_result = season_result[['Season', 'WTeamID', 'WScore']]\nseason_lose_result = season_result[['Season', 'LTeamID', 'LScore']]\n\nseason_win_result.rename(columns={'WTeamID':'TeamID', 'WScore':'Score'}, inplace=True)\nseason_lose_result.rename(columns={'LTeamID':'TeamID', 'LScore':'Score'}, inplace=True)\n\nseason_result = pd.concat((season_win_result, season_lose_result)).reset_index(drop=True)\n\nseason_score = season_result.groupby(['Season', 'TeamID'])['Score'].sum().reset_index()\n\n\n\ntourney_result = pd.merge(tourney_result, season_score, left_on=['Season', 'WTeamID'], right_on=['Season', 'TeamID'], how='left')\ntourney_result.rename(columns={'Score':'WScoreT'}, inplace=True)\ntourney_result = tourney_result.drop('TeamID', axis=1)\n\ntourney_result = pd.merge(tourney_result, season_score, left_on=['Season', 'LTeamID'], right_on=['Season', 'TeamID'], how='left')\ntourney_result.rename(columns={'Score':'LScoreT'}, inplace=True)\ntourney_result = tourney_result.drop('TeamID', axis=1)\n\n\n\ntourney_win_result = tourney_result.drop(['Season', 'WTeamID', 'LTeamID'], axis=1)\ntourney_win_result.rename(columns={'WSeed':'Seed1', 'LSeed':'Seed2', 'WScoreT':'ScoreT1', 'LScoreT':'ScoreT2'}, inplace=True)\n\ntourney_lose_result = tourney_win_result.copy()\ntourney_lose_result['Seed1'] = tourney_win_result['Seed2']\ntourney_lose_result['Seed2'] = tourney_win_result['Seed1']\ntourney_lose_result['ScoreT1'] = tourney_win_result['ScoreT2']\ntourney_lose_result['ScoreT2'] = tourney_win_result['ScoreT1']","4d49aad8":"tourney_win_result['Seed_diff'] = tourney_win_result['Seed1'] - tourney_win_result['Seed2']\ntourney_win_result['ScoreT_diff'] = tourney_win_result['ScoreT1'] - tourney_win_result['ScoreT2']\ntourney_lose_result['Seed_diff'] = tourney_lose_result['Seed1'] - tourney_lose_result['Seed2']\ntourney_lose_result['ScoreT_diff'] = tourney_lose_result['ScoreT1'] - tourney_lose_result['ScoreT2']","15574e4f":"tourney_win_result['result'] = 1\ntourney_lose_result['result'] = 0\ntrain_df = pd.concat((tourney_win_result, tourney_lose_result)).reset_index(drop=True)\ntrain_df.head()","650a5271":"train_df['result'].value_counts()","8b6bae26":"season_result.head()","2e6cd4c9":"tourney_result.head()","d1aabe5b":"test_df = pd.read_csv(PATH_MEN+'MSampleSubmissionStage1_2020.csv')\nsub = test_df.copy()\n\ntest_df.head()","6c605b74":"test_df['Season'] = test_df['ID'].map(lambda x: int(x[:4]))\ntest_df['WTeamID'] = test_df['ID'].map(lambda x: int(x[5:9]))\ntest_df['LTeamID'] = test_df['ID'].map(lambda x: int(x[10:14]))","f0480c18":"tourney_seed = pd.read_csv(PATH_MEN + 'MDataFiles_Stage1\/MNCAATourneySeeds.csv')\ntourney_seed = tourney_seed[tourney_seed['Season'] > 2014]","4493b8fa":"season_result = pd.read_csv('..\/input\/google-cloud-ncaa-march-madness-2020-division-1-mens-tournament\/MDataFiles_Stage1\/MRegularSeasonCompactResults.csv')\nseason_result = season_result[season_result['Season'] > 2014]\nseason_win_result = season_result[['Season', 'WTeamID', 'WScore']]\nseason_lose_result = season_result[['Season', 'LTeamID', 'LScore']]\nseason_win_result.rename(columns={'WTeamID':'TeamID', 'WScore':'Score'}, inplace=True)\nseason_lose_result.rename(columns={'LTeamID':'TeamID', 'LScore':'Score'}, inplace=True)\nseason_result = pd.concat((season_win_result, season_lose_result)).reset_index(drop=True)\nseason_score = season_result.groupby(['Season', 'TeamID'])['Score'].sum().reset_index()","624609e7":"test_df = pd.merge(test_df, tourney_seed, left_on=['Season', 'WTeamID'], right_on=['Season', 'TeamID'], how='left')\ntest_df.rename(columns={'Seed':'Seed1'}, inplace=True)\ntest_df = test_df.drop('TeamID', axis=1)\ntest_df = pd.merge(test_df, tourney_seed, left_on=['Season', 'LTeamID'], right_on=['Season', 'TeamID'], how='left')\ntest_df.rename(columns={'Seed':'Seed2'}, inplace=True)\ntest_df = test_df.drop('TeamID', axis=1)\ntest_df = pd.merge(test_df, season_score, left_on=['Season', 'WTeamID'], right_on=['Season', 'TeamID'], how='left')\ntest_df.rename(columns={'Score':'ScoreT1'}, inplace=True)\ntest_df = test_df.drop('TeamID', axis=1)\ntest_df = pd.merge(test_df, season_score, left_on=['Season', 'LTeamID'], right_on=['Season', 'TeamID'], how='left')\ntest_df.rename(columns={'Score':'ScoreT2'}, inplace=True)\ntest_df = test_df.drop('TeamID', axis=1)","ba1b9422":"test_df['Seed1'] = test_df['Seed1'].map(lambda x: int(x[1:3]))\ntest_df['Seed2'] = test_df['Seed2'].map(lambda x: int(x[1:3]))\ntest_df['Seed_diff'] = test_df['Seed1'] - test_df['Seed2']\ntest_df['ScoreT_diff'] = test_df['ScoreT1'] - test_df['ScoreT2']\ntest_df = test_df.drop(['ID', 'Pred', 'Season', 'WTeamID', 'LTeamID'], axis=1)\ntest_df.head()","f3f1e585":"X = train_df.drop('result', axis=1)\ny = train_df.result","d4e69902":"def evaluate_model(X, y, model):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n    \n    scores = cross_val_score(model, X, y, scoring='f1', cv=cv, n_jobs=-1)\n    return scores","fd5475d2":"model = DummyClassifier(strategy='uniform')\n\nscores = evaluate_model(X, y, model)\n\nprint('Mean Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))","3e0a46ba":"def get_models():\n    models, names = list(), list()\n    # LR \n    models.append(LogisticRegression(solver='lbfgs')) \n    names.append('LR')\n    # LDA\n    models.append(LinearDiscriminantAnalysis()) \n    names.append('LDA')\n    # NB\n    models.append(GaussianNB())\n    names.append('NB')\n    # SVM\n    models.append(SVC(gamma='scale'))\n    names.append('SVM')\n    return models, names","87260ba8":"models, names = get_models()\n\nresults = list()\n\n\nfor i in range(len(models)):\n    \n    pipeline = Pipeline(steps=[('scale',MinMaxScaler()),('m',models[i])])\n    \n    scores = evaluate_model(X, y, pipeline)\n    \n    results.append(scores)\n\n    print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores))) ","ccecce3a":"plt.figure(figsize=(10,5))\n_ = plt.boxplot(results, labels=names, showmeans=True) \n_ = plt.show()","6b9a27f2":"# LGB\nlgb_num_leaves_max = 255\nlgb_in_leaf = 50\nlgb_lr = 0.0001\nlgb_bagging = 7\n\n# XGB\nxgb_max_depth = 20\nxgb_min_child_weight = 75\nxgb_lr = 0.0005\nxgb_num_boost_round_max = 4000\n# without early_stopping_rounds\n\n# Set weight of models\nw_lgb = 0.6\nw_xgb = 0.3\nw_logreg = 1 - w_lgb - w_xgb","cf957311":"params_lgb = {'num_leaves': lgb_num_leaves_max,\n              'min_data_in_leaf': lgb_in_leaf,\n              'objective': 'binary',\n              'max_depth': -1,\n              'learning_rate': lgb_lr,\n              \"boosting_type\": \"gbdt\",\n              \"bagging_seed\": lgb_bagging,\n              \"metric\": 'logloss',\n              \"verbosity\": -1,\n              'random_state': 42,\n             }","741860a0":"NFOLDS = 10\nfolds = KFold(n_splits=NFOLDS)\n#folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n\ncolumns = X.columns\nsplits = folds.split(X, y)\ny_preds_lgb = np.zeros(test_df.shape[0])\ny_train_lgb = np.zeros(X.shape[0])\ny_oof = np.zeros(X.shape[0])\n\nfeature_importances = pd.DataFrame()\nfeature_importances['feature'] = columns\n  \nfor fold_n, (train_index, valid_index) in enumerate(splits):\n    print('Fold:',fold_n+1)\n    X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    \n    dtrain = lgb.Dataset(X_train, label=y_train)\n    dvalid = lgb.Dataset(X_valid, label=y_valid)\n\n    clf = lgb.train(params_lgb, dtrain, 10000, valid_sets = [dtrain, dvalid], verbose_eval=200)\n    \n    feature_importances[f'fold_{fold_n + 1}'] = clf.feature_importance()\n    \n    y_pred_valid = clf.predict(X_valid)\n    y_oof[valid_index] = y_pred_valid\n    \n    y_train_lgb += clf.predict(X) \/ NFOLDS\n    y_preds_lgb += clf.predict(test_df) \/ NFOLDS\n    \n    del X_train, X_valid, y_train, y_valid\n    gc.collect()","13d58979":"def plot_cm(y_true, y_pred, title, figsize=(7,6)):\n    y_pred = y_pred.round().astype(int)\n    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n    cm_sum = np.sum(cm, axis=1, keepdims=True)\n    cm_perc = cm \/ cm_sum.astype(float) * 100\n    annot = np.empty_like(cm).astype(str)\n    nrows, ncols = cm.shape\n    for i in range(nrows):\n        for j in range(ncols):\n            c = cm[i, j]\n            p = cm_perc[i, j]\n            if i == j:\n                s = cm_sum[i]\n                annot[i, j] = '%.1f%%\\n%d\/%d' % (p, c, s)\n            elif c == 0:\n                annot[i, j] = ''\n            else:\n                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n    cm.index.name = 'Actual'\n    cm.columns.name = 'Predicted'\n    fig, ax = plt.subplots(figsize=figsize)\n    plt.title(title)\n    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax)","e51070f2":"plot_cm(y, y_train_lgb, 'Confusion matrix for LGB model')","c2407f87":"params_xgb = {'max_depth': xgb_max_depth,\n              'objective': 'binary:logistic',\n              'min_child_weight': xgb_min_child_weight,\n              'learning_rate': xgb_lr,\n              'eta'      : 0.3,\n              'subsample': 0.8,\n              'lambda '  : 4,\n              'eval_metric': 'logloss',\n              'colsample_bytree ': 0.9,\n              'colsample_bylevel': 1\n              }","d525a82e":"NFOLDS = 10\nfolds = KFold(n_splits=NFOLDS)\n\ncolumns = X.columns\nsplits = folds.split(X, y)\n\ny_preds_xgb = np.zeros(test_df.shape[0])\ny_train_xgb = np.zeros(X.shape[0])\ny_oof_xgb = np.zeros(X.shape[0])\n\ntrain_df_set = xgb.DMatrix(X)\ntest_set = xgb.DMatrix(test_df)\n  \nfor fold_n, (train_index, valid_index) in enumerate(splits):\n    print('Fold:',fold_n+1)\n    X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    \n    train_set = xgb.DMatrix(X_train, y_train)\n    val_set = xgb.DMatrix(X_valid, y_valid)\n    \n    clf = xgb.train(params_xgb, train_set, num_boost_round=xgb_num_boost_round_max, evals=[(train_set, 'train'), (val_set, 'val')], verbose_eval=100)\n    \n    y_train_xgb += clf.predict(train_df_set) \/ NFOLDS\n    y_preds_xgb += clf.predict(test_set) \/ NFOLDS\n    \n    del X_train, X_valid, y_train, y_valid\n    gc.collect()","eff47809":"plot_cm(y, y_train_xgb, 'Confusion matrix for XGB model')","ac143337":"scale = MinMaxScaler()\nX_scaled = scale.fit_transform(X)\nX_test_scaled = scale.transform(test_df)\n\nmodel = LogisticRegression(solver='liblinear')\n\nmodel.fit(X_scaled, y)\n\ny_logreg_train = model.predict(X_scaled)\ny_logreg_pred = model.predict(X_test_scaled)","7931cbb2":"plot_cm(y, y_logreg_train, 'Confusion matrix for LogReg model')","05d542d7":"y_train_preds = 0.8*y_train_lgb + 0.1*y_train_xgb + 0.1*y_logreg_train\n\nplot_cm(y, y_train_preds, 'Confusion matrix for Merging solution')\n","14daa8ed":"<h3><center>Introduction<\/center><\/h3>\n<div style=\"font-family:verdana; word-spacing:1.7px;\">\nIn this kernel we will be working with data from Google Cloud & NCAA\u00ae ML Competition 2019-Men's Challenge. We'll try to predict winners of NCAA based on previous tournaments! We have a lot of data, so let's start with EDA and then build a baseline model.\n\n<\/div>\n\n![image.png](attachment:image.png)","0f172a72":"<h3><center>4. Model Test & Baseline result<\/center><\/h3>","5d027b56":"<h3><center>9. Merging Solutions<\/center><\/h3>","dc251eca":"<h3>7. XGB<\/h3>","0c0afa9b":"<h3>Oldies<\/h3>","2d7747af":"<h3>6. LGB<\/h3>","60f8331f":"<h3>2.6. PlayerIDs<\/h3>","db159aa6":"<h3>2.3. Seed Data<\/h3>","86eadfa5":"<h3>2.1. Teams Data<\/h3>","14a990d0":"<h3>8. Log Reg <\/h3>","91ae3676":"<h3><center>5. Evaluate Machine Learning Algorithms<\/center><\/h3>","3a519cb4":"<h2><center>1. Importing Libraries<\/center><\/h2>","7616488c":"<h3><center>3. Preparing Training & Validation Data<\/center><\/h3>","65bdcc50":"<h3>2.4. Regular Season Results<\/h3>","bd363c82":"Testing Data","48c8d427":"Training Data","0990601b":"<h3>Winning & losing Teams<\/h3>","5b4f7f6a":"<h3>2.5. Event Data<\/h3>\n\nEach event is assigned to either a team or a single one of the team's players. Thus if a basket is made by one player and an assist is credited to a second player, that would show up as two separate records. The players are listed by PlayerID within the xPlayers.csv file.","b5aa6d94":"<h3>2.2. Seasons Data<\/h3>","08aa4a8c":"<h2><center>2. Exploring Data<\/center><\/h2>","462702cb":"<h3>Area Event<\/h3>\n\n<div style=\"font-family:verdana; word-spacing:1.7px;\">\nWe are told that the Area feature describes the 13 \"areas\" of the court, as follows: 1=under basket; 2=in the paint; 3=inside right wing; 4=inside right; 5=inside center; 6=inside left; 7=inside left wing; 8=outside right wing; 9=outside right; 10=outside center; 11=outside left; 12=outside left wing; 13=backcourt.\n    <\/div>","8824f8c3":"<h3>Newbies<\/h3>"}}