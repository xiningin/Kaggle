{"cell_type":{"9b836513":"code","ee3cb567":"code","041580f2":"code","f6a751a4":"code","89c0480a":"code","1e7c5643":"code","7c584feb":"code","7a61b73a":"code","2c3026da":"code","0e406c76":"code","2f2fbe6d":"code","9ce044eb":"code","8e274d0f":"code","47763a69":"code","46b77f6a":"code","18b027ec":"code","80fa9597":"code","fb779f6a":"code","c16c2657":"code","ac7fee9c":"code","8b16d001":"code","722453d1":"code","70152074":"code","277aaaa0":"code","8072f69e":"code","aac3fa6a":"code","9e1e8726":"code","571ea3a6":"code","01251e94":"code","11652a1d":"code","3a0a4d25":"code","4d9295cc":"code","9968ec23":"code","39997852":"code","2bbeee2c":"code","ae6836c1":"code","cacbbc62":"code","5a07ec28":"code","72c9a34a":"code","ee48e51a":"code","f2c7ae68":"code","146e31fb":"code","82985577":"code","e48ddf68":"code","c5b2956e":"code","a90a81c4":"code","1c35d8d0":"code","41e37e8d":"code","769227d8":"code","5f53a347":"code","35adfe9e":"code","a24840f4":"code","dc9be08a":"code","7f1546e3":"code","dc53ec32":"code","94cbab64":"code","56e24e4f":"code","e4f1a137":"markdown","e71724ff":"markdown","aa202f99":"markdown","b6d66a6a":"markdown","0c2c30ab":"markdown","c2dfd774":"markdown","0cd538a5":"markdown","f884b88e":"markdown","9d383af4":"markdown","5b1fc16c":"markdown","fe6d48fd":"markdown","1aaedba4":"markdown","482d9683":"markdown","a916b895":"markdown","caecbf53":"markdown","5b9c66ac":"markdown","13dc9f62":"markdown","59744f09":"markdown","ce736e2a":"markdown","276f6bee":"markdown","c1bdf5de":"markdown","9f69ce51":"markdown","e9bce617":"markdown","6cac4213":"markdown","bce4e610":"markdown","5a97654c":"markdown","387294bf":"markdown","f0c1e7b4":"markdown","8f8e6935":"markdown","39d45d94":"markdown","4549284a":"markdown","3b7fb701":"markdown","1a47d26a":"markdown","4f3ed0fe":"markdown"},"source":{"9b836513":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scipy\n\nfrom scipy import stats\nfrom scipy.stats import norm, skew, boxcox\nfrom collections import Counter\n\nfrom sklearn.preprocessing import RobustScaler, StandardScaler\nfrom sklearn.metrics import mean_squared_error, confusion_matrix, accuracy_score, plot_confusion_matrix, auc\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.feature_selection import RFE\nfrom imblearn.over_sampling import SMOTE\n\n#XGBOOST\nfrom xgboost import XGBClassifier\n\n#warning\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ee3cb567":"data = pd.read_csv(\"\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\")","041580f2":"#The Columns\nprint(\"Data Columns --> \",data.columns)","f6a751a4":"data.head()","89c0480a":"desc = data.describe()\ndesc","1e7c5643":"print(data.isna().sum())","7c584feb":"data.info()","7a61b73a":"def plot_hist(variable):\n    print(\"min {} : {} \".format(variable, min(data[variable])))\n    print(\"max {} : {}\".format(variable, max(data[variable])))\n    \n    plt.figure(figsize=(9,3))\n    plt.hist(data[variable], color=\"darkred\")\n    plt.xlabel(variable)\n    plt.ylabel(\"Frequency\")\n    plt.title(\"{} distribution with hist \".format(variable))\n    plt.show()","2c3026da":"numericVar = [\"age\",\"creatinine_phosphokinase\",\"ejection_fraction\",\"platelets\",\"serum_creatinine\",\"serum_sodium\",\"time\"]\nfor n in numericVar:\n    plot_hist(n)","0e406c76":"def bar_plot(variable):\n    \n    # get feature\n    var = data[variable]\n    #count number of categorical variable (value\/sample)\n    varValue = var.value_counts()\n\n    #visualize\n    plt.figure(figsize=(9,3))\n    plt.bar(varValue.index, varValue,color = \"lightgreen\", edgecolor = \"black\", linewidth = 2)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}: \\n {}\".format(variable,varValue))","2f2fbe6d":"category = [\"anaemia\",\"diabetes\",\"high_blood_pressure\",\"sex\",\"smoking\",\"DEATH_EVENT\"]\nfor c in category:\n    bar_plot(c)","9ce044eb":"corr_matrix = data.corr()\nsns.clustermap(corr_matrix, annot = True, fmt = \".2f\")\nplt.title(\"Correlaation btw features\")\nplt.show()","8e274d0f":"threshold = 0.2 \nfiltre = np.abs(corr_matrix[\"DEATH_EVENT\"]) > threshold\ncorr_features = corr_matrix.columns[filtre].tolist()\nsns.clustermap(data[corr_features].corr(), annot = True, fmt = \".2f\")\nplt.title(\"Correlation Between Features w Corr Theshold 0.75\")\nplt.show()","47763a69":"#pair plot\nsns.pairplot(data[corr_features], diag_kind = \"kde\", markers = \"+\", hue = \"DEATH_EVENT\")\nplt.show()","46b77f6a":"def detect_outliers(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(df[c],25)\n        # 3st quartile\n        Q3 = np.percentile(df[c],75)\n        # IQR\n        IQR = Q3 - Q1\n        # Outlier Step\n        outlier_step = IQR * 1.5\n        # detect outlier and their indeces\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        # store indeces \n        outlier_indices.extend(outlier_list_col)\n        \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 1) \n    \n    return multiple_outliers","18b027ec":"data.loc[detect_outliers(data,[\"age\",\"creatinine_phosphokinase\",\"ejection_fraction\",\"platelets\",\"serum_creatinine\",\"serum_sodium\",\"time\"])]","80fa9597":"data = data.drop(detect_outliers(data,[\"age\",\"creatinine_phosphokinase\",\"ejection_fraction\",\"platelets\",\"serum_creatinine\",\"serum_sodium\",\"time\"]),axis = 0).reset_index(drop=True)","fb779f6a":"skewed_feats = data.apply(lambda x: skew(x.dropna())).sort_values(ascending = False)\nskewness = pd.DataFrame(skewed_feats, columns = [\"skewed\"])\nskewness","c16c2657":"# creatinine_phosphokinase\nsns.distplot(data[\"creatinine_phosphokinase\"], fit = norm)\nplt.show()\n(mu, sigma) = norm.fit(data[\"creatinine_phosphokinase\"])\nprint(\"mu {} : {}, sigma {} : {}\".format(\"creatinine_phosphokinase\", mu, \"creatinine_phosphokinase\", sigma))\nprint()","ac7fee9c":"data[\"creatinine_phosphokinase\"], lam = boxcox(data[\"creatinine_phosphokinase\"])","8b16d001":"# creatinine_phosphokinase\nsns.distplot(data[\"creatinine_phosphokinase\"], fit = norm)\nplt.show()\n(mu, sigma) = norm.fit(data[\"creatinine_phosphokinase\"])\nprint(\"mu {} : {}, sigma {} : {}\".format(\"creatinine_phosphokinase\", mu, \"creatinine_phosphokinase\", sigma))\nprint()","722453d1":"# serum_creatinine\nsns.distplot(data[\"serum_creatinine\"], fit = norm)\nplt.show()\n(mu, sigma) = norm.fit(data[\"serum_creatinine\"])\nprint(\"mu {} : {}, sigma {} : {}\".format(\"serum_creatinine\", mu, \"serum_creatinine\", sigma))\nprint()","70152074":"data[\"serum_creatinine\"], lam_serum_creatine = boxcox(data[\"serum_creatinine\"])","277aaaa0":"# serum_creatinine\nsns.distplot(data[\"serum_creatinine\"], fit = norm)\nplt.show()\n(mu, sigma) = norm.fit(data[\"serum_creatinine\"])\nprint(\"mu {} : {}, sigma {} : {}\".format(\"serum_creatinine\", mu, \"serum_creatinine\", sigma))\nprint()","8072f69e":"# ejection_fraction\nsns.distplot(data[\"ejection_fraction\"], fit = norm)\nplt.show()\n(mu, sigma) = norm.fit(data[\"ejection_fraction\"])\nprint(\"mu {} : {}, sigma {} : {}\".format(\"ejection_fraction\", mu, \"smejection_fractionoking\", sigma))\nprint()","aac3fa6a":"data[\"ejection_fraction\"], lam_serum_creatine = boxcox(data[\"ejection_fraction\"])","9e1e8726":"# ejection_fraction\nsns.distplot(data[\"ejection_fraction\"], fit = norm)\nplt.show()\n(mu, sigma) = norm.fit(data[\"ejection_fraction\"])\nprint(\"mu {} : {}, sigma {} : {}\".format(\"ejection_fraction\", mu, \"smejection_fractionoking\", sigma))\nprint()","571ea3a6":"# platelets\nsns.distplot(data[\"platelets\"], fit = norm)\nplt.show()\n(mu, sigma) = norm.fit(data[\"platelets\"])\nprint(\"mu {} : {}, sigma {} : {}\".format(\"platelets\", mu, \"platelets\", sigma))\nprint()","01251e94":"data[\"platelets\"], lam_serum_creatine = boxcox(data[\"platelets\"])","11652a1d":"# platelets\nsns.distplot(data[\"platelets\"], fit = norm)\nplt.show()\n(mu, sigma) = norm.fit(data[\"platelets\"])\nprint(\"mu {} : {}, sigma {} : {}\".format(\"platelets\", mu, \"platelets\", sigma))\nprint()","3a0a4d25":"skewed_feats = data.apply(lambda x: skew(x.dropna())).sort_values(ascending = False)\nskewness_new = pd.DataFrame(skewed_feats, columns = [\"skewed\"])\nskewness_new","4d9295cc":"#AGE\ng = sns.FacetGrid(data, col = \"DEATH_EVENT\")\ng.map(sns.distplot, \"age\", bins = 25)\nplt.show()","9968ec23":"X = data.drop(\"DEATH_EVENT\", axis = 1)\ny = data.DEATH_EVENT","39997852":"X.head()","2bbeee2c":"print(\"Before Smote\")\ny.value_counts()","ae6836c1":"sm = SMOTE(random_state=42)\nX_sm, y_sm = sm.fit_resample(X, y)","cacbbc62":"print(\"After Smote\")\ny_sm.value_counts()","5a07ec28":"test_size = 0.2\nX_train, X_test, Y_train, Y_test = train_test_split(X_sm, y_sm, test_size = test_size, random_state = 42)","72c9a34a":"print(\"X_train shape {}, len {}.\".format(X_train.shape,len(X_train)))\nprint(\"X_test shape {}, len {}.\".format(X_test.shape,len(X_test)))\nprint(\"Y_train shape {}, len {}.\".format(Y_train.shape,len(Y_train)))\nprint(\"Y_test shape {}, len {}.\".format(Y_test.shape,len(Y_test)))","ee48e51a":"# list to keep our results\nresult_acc = []","f2c7ae68":"XGB = XGBClassifier(max_depth = 1)\nXGB.fit(X_train, Y_train)\ny_pred_xgb = XGB.predict(X_test)\ncm_xgb = confusion_matrix(y_pred_xgb, Y_test)\nacc_xgb = accuracy_score(Y_test, y_pred_xgb)\nresult_acc.append(acc_xgb)\nprint(\"RESULT\")\nprint(\"XGBoost Model Acc : \",acc_xgb)\nprint(\"XGBoost Model Cm : \",cm_xgb)","146e31fb":"model_rnd = RandomForestClassifier()\nmodel_rnd.fit(X_train, Y_train)\nimportance = model_rnd.feature_importances_\n\n# plot feature importance\nplt.bar([x for x in range(len(importance))], importance, color = \"red\")\nplt.show()","82985577":"x_train_random_forest = X_train[[\"age\",\"creatinine_phosphokinase\",\"ejection_fraction\",\"serum_creatinine\",\"time\"]]\nx_test_random_forest = X_test[[\"age\",\"creatinine_phosphokinase\",\"ejection_fraction\",\"serum_creatinine\",\"time\"]]","e48ddf68":"random_forest_model = RandomForestClassifier(max_depth=7, random_state=25)\nrandom_forest_model.fit(x_train_random_forest, Y_train)\ny_pred_random_forest = random_forest_model.predict(x_test_random_forest)\ncm_random_forest = confusion_matrix(y_pred_random_forest, Y_test)\nacc_random_forest = accuracy_score(Y_test, y_pred_random_forest)\nresult_acc.append(acc_random_forest)\nprint(\"RESULT\")\nprint(\"Random Forest Model Acc : \",acc_random_forest)\nprint(\"Random Forest Model Cm : \",cm_random_forest)","c5b2956e":"model_log_reg = LogisticRegression()\nmodel_log_reg.fit(X_train, Y_train)\nimportance = model_log_reg.coef_[0]\n\nplt.bar([x for x in range(len(importance))], importance, color = \"orange\")\nplt.show()","a90a81c4":"x_train_log_reg = X_train[[\"creatinine_phosphokinase\",\"ejection_fraction\",\"serum_creatinine\",\"sex\"]]\nx_test_log_reg = X_test[[\"creatinine_phosphokinase\",\"ejection_fraction\",\"serum_creatinine\",\"sex\"]]","1c35d8d0":"log_reg = LogisticRegression()\nlog_reg.fit(x_train_log_reg, Y_train)\ny_pred_log = log_reg.predict(x_test_log_reg)\ncm_log_reg = confusion_matrix(y_pred_log, Y_test)\nacc_log_reg = accuracy_score(Y_test, y_pred_log)\nresult_acc.append(acc_log_reg)\nprint(\"RESULT\")\nprint(\"Logistic Regression Model Acc : \",acc_log_reg)\nprint(\"Logistic Regression Model Cm : \",cm_log_reg)","41e37e8d":"model_decision_tree = DecisionTreeClassifier()\nmodel_decision_tree.fit(X_train, Y_train)\nimportance = model_decision_tree.feature_importances_\n\nplt.bar([x for x in range(len(importance))], importance, color = \"blue\")\nplt.show()","769227d8":"x_train_dec = X_train[[\"creatinine_phosphokinase\",\"ejection_fraction\",\"time\"]]\nx_test_dec = X_test[[\"creatinine_phosphokinase\",\"ejection_fraction\",\"time\"]]","5f53a347":"dt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20)}\n\ndecision_tree = DecisionTreeClassifier()\nclf = GridSearchCV(decision_tree, param_grid=dt_param_grid, cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\nclf.fit(x_train_dec,Y_train)\n\ny_pred_decision_tree = clf.predict(x_test_dec)\ncm_y_pred_decision_tree = confusion_matrix(y_pred_decision_tree, Y_test)\nacc_y_pred_decision_tree = accuracy_score(Y_test, y_pred_decision_tree)\nresult_acc.append(acc_y_pred_decision_tree)\nprint(\"RESULT\")\nprint(\"Decision Tree Model Acc : \",acc_y_pred_decision_tree)\nprint(\"Decision Tree Model Cm : \",cm_y_pred_decision_tree)","35adfe9e":"model_svm = SVC(kernel=\"linear\")\nmodel_svm.fit(X_train, Y_train)\nimportance = model_svm.coef_[0]\n\nplt.bar([x for x in range(len(importance))], importance, color = \"brown\")\nplt.show()","a24840f4":"x_train_svm = X_train[[\"creatinine_phosphokinase\",\"ejection_fraction\",\"serum_creatinine\",\"sex\"]]\nx_test_svm = X_test[[\"creatinine_phosphokinase\",\"ejection_fraction\",\"serum_creatinine\",\"sex\"]]","dc9be08a":"svm = SVC()\nsvm.fit(x_train_svm, Y_train)\ny_pred_svm = svm.predict(x_test_svm)\ncm_svm = confusion_matrix(y_pred_svm, Y_test)\nacc_svm = accuracy_score(Y_test, y_pred_svm)\nresult_acc.append(acc_svm)\nprint(\"RESULT\")\nprint(\"SVM Model Acc : \",acc_svm)\nprint(\"SVM Model Cm : \",cm_svm)","7f1546e3":"best_params = {'bagging_temperature': 0.8,\n               'depth': 5,\n               'iterations': 500,\n               'l2_leaf_reg': 30,\n               'learning_rate': 0.05,\n               'random_strength': 0.8}\n\nmodel_cat_boost = CatBoostClassifier(\n        **best_params,\n        loss_function='Logloss',\n        eval_metric='Accuracy',         \n        nan_mode='Min',\n        verbose=False\n    )\n\nmodel_cat_boost.fit(\n        X_train, Y_train,\n        verbose_eval=100, \n        early_stopping_rounds=50,\n        eval_set=(X_test, Y_test),\n        use_best_model=False,\n        plot=True\n)\n\ny_pred_cat_boost = model_cat_boost.predict(X_test)\n\ncm_cat_boost = confusion_matrix(y_pred_cat_boost, Y_test)\nacc_cat_boost = accuracy_score(Y_test, y_pred_cat_boost)\nresult_acc.append(acc_cat_boost)\nprint(\"RESULT\")\nprint(\"Cat Boost Model Acc : \",acc_cat_boost)\nprint(\"Cat Boost Model Cm : \",cm_cat_boost)","dc53ec32":"results = pd.DataFrame({\"Model Result\":result_acc, \n                        \"Models\":[\"XGBoost\",\n                                  \"RandomForest\",\n                                  \"LogisticRegression\",\n                                  \"DecisionTree\", \n                                  \"SVM\",\n                                  \"CatBoost\"]})","94cbab64":"results","56e24e4f":"g = sns.barplot(\"Model Result\", \"Models\", data = results)\ng.set_xlabel(\"Accuracy\")\ng.set_title(\"Models Result\", color = \"darkred\")\nplt.show()","e4f1a137":"<a id = \"12\"><\/a>\n<h3 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\"> 2\ufe0f\u20e3 Random Forest Model<\/h3>","e71724ff":"<a id = \"9\"><\/a>\n<h3 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\"> \u2753 What is skewness ? <\/h3>\n\n![skewed.PNG](attachment:3a7fcf6a-81cf-46a9-a6d7-de66c5089da9.PNG)\n\n<p style = \"color:black;font-weight:500\" > <strong> Skewness : <\/strong> Skewness refers to a distortion or asymmetry that deviates from the symmetrical bell curve, or normal distribution, in a set of data. In simple terms, it is how much a variable deviates from the normal distribution.  <\/p>\n\n<p style = \"color:black;font-weight:700\" >There are two types.<\/p>\n\n<ul> \n    <li style = \"color:darkred;font-weight:500\" >Right Skewed or Positive Skewed <\/li>\n    <li style = \"color:darkred;font-weight:500\" >Left Skewed or Negative Skewed<\/li>\n<\/ul>\n\n\n<p style = \"color:black;font-weight:500\" >Right Skewed or Positive Skewed --> The distribution has a rightward tail with respect to the normal distribution.<\/p>\n\n<p style = \"color:black;font-weight:500\" >Left Skewed or Negative Skewed --> The distribution has a tail to the left relative to the normal distribution.<\/p>\n\n<h3 style = \"color:gray\" >\nWhy is it important?<\/h3>\n<p style = \"color:black;font-weight:500\" >The model has difficulty in estimating the correct value at other points while focusing on the dense point while predicting on data that does not show a normal distribution.<\/p>\n\n<p style = \"color:black;font-weight:500\" >What do we do, we will look at our skewness values. If it is greater than 1, there is positive skewness, if it is less than -1, there is negative skewness.<\/p>\n\n<h5>Let's start.<\/h5>","aa202f99":"![Heart-Failure.jpg](attachment:ed3967f9-b648-4187-8d31-9bec5f2d4519.jpg)\n\n<center><h1 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\" >\ud83d\udcdc Introduction<\/h1><\/center>\n<p style = \"color:black;font-weight:500;text-indent:20px;font-size:16px\">Cardiovascular diseases (CVDs) are the number 1 cause of death globally, taking an estimated 17.9 million lives each year, which accounts for 31% of all deaths worlwide.\nHeart failure is a common event caused by CVDs and this dataset contains 12 features that can be used to predict mortality by heart failure.<\/p>\n\n<p style = \"color:black;font-weight:500;text-indent:20px;font-size:16px\">What we will do, we will examine these features well, and we will eliminate the situations that will adversely affect our model.Then, we will try to make predictions on the 6 models mentioned below and compare their results. <\/p>\n    \n\n<h2 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\">\ud83d\udccb Content :<\/h2>\n\n<ul>\n    <li style = \"color:darkgray;font-size:15px\"> <a href = \"#1\" style = \"color:black;font-weight:bold\"> Load and Check Data <\/a> <\/li>\n    <li style = \"color:darkgray;font-size:15px\"> <a href = \"#2\" style = \"color:black;font-weight:bold\"> Variable Description <\/a> <\/li>   \n    <li style = \"color:darkgray;font-size:15px\"> <a href = \"#3\" style = \"color:black;font-weight:bold\"> Univariate Variable Analysis <\/a> <ul> <li style = \"color:lightgray\"><a href = \"#4\" style = \"color:black;font-weight:500\"> Numerical Variable  <\/a><\/li> <li style = \"color:lightgray\"><a href = \"#5\" style = \"color:black;font-weight:500\"> Categorical Variable <\/a><\/li> <\/ul>            \n    <li style = \"color:darkgray;font-size:15px\"> <a href = \"#6\" style = \"color:black;font-weight:bold\">  Exploratory Data Analysis (EDA)  <\/a> <\/li>\n            <li style = \"color:darkgray;font-size:15px\"> <a href = \"#7\" style = \"color:black;font-weight:bold\"> Outlier Detection <\/a> <\/li>\n        <li style = \"color:darkgray;font-size:15px\"> <a href = \"#8\" style = \"color:black;font-weight:bold\"> Feature Engineering <\/a> <ul> <li style = \"color:lightgray\"><a href = \"#9\" style = \"color:black;font-weight:500\"> What is skewness ?  <\/a> <\/ul>\n            <li style = \"color:darkgray;font-size:15px\"> <a href = \"#10\" style = \"color:black;font-weight:bold\"> Modeling   <\/a> <ul> <li style = \"color:lightgray\"><a href = \"#11\" style = \"background:white;color:#8B0000;border:0;border-radius:3px;font-family:Impact;font-size:14px\">1\ufe0f\u20e3 XGBoost Model <\/a><\/li> <li style = \"color:lightgray\"><a href = \"#12\" style = \"background:white;color:#8B0000;border:0;border-radius:3px;font-family:Impact;font-size:14px\"> 2\ufe0f\u20e3 RandomForest Model <\/a><\/li> <li style = \"color:lightgray\"><a href = \"#13\" style = \"background:white;color:#8B0000;border:0;border-radius:3px;font-family:Impact;font-size:14px\">3\ufe0f\u20e3 Logistic Regression Model <\/a><\/li> <li style = \"color:lightgray\"><a href = \"#14\" style = \"background:white;color:#8B0000;border:0;border-radius:3px;font-family:Impact;font-size:14px\"> 4\ufe0f\u20e3 DecisionTree Model <\/a><\/li> <li style = \"color:lightgray\"><a href = \"#15\" style = \"background:white;color:#8B0000;border:0;border-radius:3px;font-family:Impact;font-size:14px\"> 5\ufe0f\u20e3 SVM Model <\/a><\/li> <li style = \"color:lightgray\"><a href = \"#16\" style = \"background:white;color:#8B0000;border:0;border-radius:3px;font-family:Impact;font-size:14px\">6\ufe0f\u20e3 CatBoost Model <\/a><\/li> <\/ul>\n    <li style = \"color:darkgray;font-size:15px\"> <a href = \"#17\" style = \"color:black;font-weight:bold\"> Model Result <\/a> <\/ul> \n\n","b6d66a6a":"<ul>\n    <li style = \"color:red\"> <p style = \"color:black;font-weight:bold\"> we checked the columns of the data. No null data. <\/p>  <\/li>\n<\/ul>","0c2c30ab":"<a id = \"16\"><\/a>\n<h3 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\"> 6\ufe0f\u20e3 CatBoost  Model<\/h3>","c2dfd774":"<ul>\n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> As we said in the definition above, we find our skewness values. <\/strong> <\/p> <\/li>\n<\/ul>","0cd538a5":"<a id = \"15\"><\/a>\n<h3 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\"> 5\ufe0f\u20e3 SVM Model<\/h3>","f884b88e":"<ol>    \n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> age : <\/strong> the age of the person with heart failure <\/p> <\/li>  \n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> anaemia : <\/strong> Decrease of red blood cells or hemoglobin (boolean) <\/p> <\/li>\n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> creatinine_phosphokinase : <\/strong> Level of the CPK enzyme in the blood (mcg\/L) <\/p> <\/li>  \n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> diabetes : <\/strong> If the patient has diabetes (boolean) <\/p> <\/li>\n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> ejection_fraction : <\/strong> Percentage of blood leaving the heart at each contraction (percentage) <\/p> <\/li>  \n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> high_blood_pressure  : <\/strong> If the patient has hypertension (boolean) <\/p> <\/li>\n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> platelets : <\/strong> Platelets in the blood (kiloplatelets\/mL) <\/p> <\/li>  \n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> serum_creatinine : <\/strong> Level of serum creatinine in the blood (mg\/dL) <\/p> <\/li>\n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> serum_sodium : <\/strong>Level of serum sodium in the blood (mEq\/L) <\/p> <\/li>\n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> sex : <\/strong> Woman or man (binary) <\/p> <\/li>\n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> smoking : <\/strong> If the patient smokes or not (boolean) <\/p> <\/li>\n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> time : <\/strong> Follow-up period (days) <\/p> <\/li>\n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> DEATH_EVENT : <\/strong> If the patient deceased during the follow-up period (boolean) <\/p> <\/li>\n<\/ol>","9d383af4":"<a id = \"6\"><\/a>\n<h2 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\"> \ud83d\udd0d Exploratory Data Analysis (EDA) <\/h2>","5b1fc16c":"<a id = \"5\"><\/a>\n<h3 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\"> \ud83d\udcb9 Categorical Variable <\/h3>","fe6d48fd":"<a id = \"7\"><\/a>\n<h2 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\"> \ud83d\udd75\ufe0f\u200d Outlier Detection <\/h2>","1aaedba4":"<ul>    \n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> float64 : <\/strong> age, platelets, serum_creatinine<\/p> <\/li> \n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> int64 : <\/strong> We see that all our remaining columns are int.<\/p> <\/li>\n<\/ul>","482d9683":"<a id = \"13\"><\/a>\n<h3 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\"> 3\ufe0f\u20e3 Logistic Regression Model<\/h3>","a916b895":"<a id = \"10\"><\/a>\n<h2 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\"> \ud83d\udcc1 Modeling <\/h2>","caecbf53":"<ul>    \n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> We draw the relationship matrix and examine the relationships between properties..  <\/strong>  <\/p> <\/li>\n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> If the relation between properties is 1 it means that it is true and -1 means it is inversely proportional.  <\/strong>  <\/p> <\/li> \n<\/ul>","5b9c66ac":"<a id = \"2\"><\/a>\n<h2 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\"> \ud83d\udcdd Variable Description <\/h2>","13dc9f62":"<ul>\n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> You can take a look at the change by comparing it with the skew chart above. <\/strong> <\/p> <\/li>\n<\/ul>","59744f09":"<a id = \"1\"><\/a>\n<h2 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\"> \u2714\ufe0f Load and Check Data <\/h2>","ce736e2a":"<ul>\n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> yes, we have come to the end. As you can see, our biggest success with random forest is 97.5 <\/strong> <\/p> <\/li>\n<\/ul>","276f6bee":"<a id = \"8\"><\/a>\n<h2 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\"> \ud83d\udcbb Feature Engineering <\/h2>","c1bdf5de":"<ul>\n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> We can't call our data too irregular, but we'd better get rid of this disorder anyway. <\/strong> <\/p> <\/li>\n<\/ul>","9f69ce51":"<ul>    \n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> We reduce our outliers from our data.  <\/strong>  <\/p> <\/li> \n<\/ul>","e9bce617":"<h3 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\"> \ud83d\udcca Train - Test Split <\/h3>","6cac4213":"<a id = \"11\"><\/a>\n<h3 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\"> 1\ufe0f\u20e3 XGBoost model <\/h3>","bce4e610":"<a id = \"17\"><\/a>\n<h2 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\"> \ud83d\udcc8 Model Result<\/h2>","5a97654c":"<ul>\n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> We also see the skewness of the value of creatine phosphokinase on the graph.<\/strong> <\/p> <\/li>\n        <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> We fix this disorder by using boxcox. <\/strong> <\/p> <\/li>\n<\/ul>","387294bf":"<a id = \"4\"><\/a>\n<h3 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\"> \ud83d\udd22 Numerical Variable <\/h3>","f0c1e7b4":"<h2 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\" > \ud83d\udcd6 Import Library <\/h2>","8f8e6935":"<ul>\n        <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> First of all, we will find our important features for that model and we will use them. <\/strong> <\/p> <\/li>\n            <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> we will do this for all other models too. <\/strong> <\/p> <\/li>\n<\/ul>","39d45d94":"<p  style = \"color:black;font-weight:500\" > We will carry out our trainings using the models you see below. Finally, we will compare their achievements. <\/p>\n<ul>\n    <li style = \"color:darkred;font-weight:bold\" > XGBoost Model<\/li>\n     <li style = \"color:darkred;font-weight:bold\" >RandomForest Model<\/li>\n     <li style = \"color:darkred;font-weight:bold\" >Logistic Regression Model<\/li>\n     <li style = \"color:darkred;font-weight:bold\" >DesisionTree Model<\/li>\n     <li style = \"color:darkred;font-weight:bold\" >SVM Model<\/li>\n     <li style = \"color:darkred;font-weight:bold\" >CatBoost Model<\/li>\n<\/ul>","4549284a":"<ul>\n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> We determine x and y. <\/strong> <\/p> <\/li>\n<\/ul>","3b7fb701":"<a id = \"14\"><\/a>\n<h3 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\"> 4\ufe0f\u20e3 DecisionTree Model<\/h3>","1a47d26a":"<a id = \"3\"><\/a>\n<h2 style = \"background:black;color:white;border:0;border-radius:3px;font-family:verdana\"> \u270d\ufe0f Univariate Variable Analysis <\/h2>\n\n<ul>    \n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> We see that our data consists of float and int columns. But there are some striking columns here. We see that these are categorical. Let's examine these columns.  <\/strong>  <\/p>\n        <ul>\n            <li style = \"color:gray\"> <p style = \"color:black\"> Numerical Variable <\/p> <\/li>\n            <li style = \"color:gray\"> <p style = \"color:black\"> Categorical Variable <\/p> <\/li>\n        <\/ul>\n    <\/li> \n<\/ul>","4f3ed0fe":"<ul>\n    <li style = \"color:darkred;font-weight:bold\" > <p style = \"color:black;font-weight:400\" > <strong> We can take a look at the improvement by examining the graph again. <\/strong> <\/p> <\/li>\n<\/ul>"}}