{"cell_type":{"f489b468":"code","27a8eab2":"code","248089d5":"code","5ad84e93":"code","12c46cca":"code","eb6220e9":"code","358121d0":"code","f901a49c":"code","f3a580c9":"code","f5fe9004":"code","08d9fb40":"code","6fed4bc7":"code","15ae791c":"code","2ead8328":"code","807a675d":"code","e294cd24":"code","67e623f8":"code","27335242":"code","292ab08a":"code","7803aafb":"code","3b09b6d0":"code","b8f453ca":"code","25438ff8":"code","1b6a47ce":"code","54d071e3":"code","b76f7a4b":"code","f9db9502":"code","18f53bc5":"code","bbf437bd":"code","3b82a1b3":"code","8e7890ab":"code","53ed9e86":"code","1cb1b44b":"code","ebe01f6c":"markdown","98b3cb3f":"markdown","3fd74be3":"markdown","c4d39707":"markdown","7f6d9443":"markdown","e1914726":"markdown","7ae548b1":"markdown","b74cd417":"markdown","8a7bf261":"markdown","bfccd0c4":"markdown","8769e6a5":"markdown"},"source":{"f489b468":"import pandas as pd \nimport os \nimport tensorflow as tf \nimport matplotlib.pyplot as plt \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","27a8eab2":"%config Completer.use_jedi = False","248089d5":"train_path = \"..\/input\/plant-seedlings-classification\/train\/\"\ntest_path = \"..\/input\/plant-seedlings-classification\"","5ad84e93":"for dirpath, dirnames, filenames in os.walk(\"..\/input\/plant-seedlings-classification\/\"): \n    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")","12c46cca":"train_data = tf.keras.preprocessing.image_dataset_from_directory(directory=train_path,\n                                                                 label_mode=\"categorical\", \n                                                                 shuffle=True,\n                                                                 image_size=(224,224),\n                                                                batch_size = 32,\n                                                                 seed=42,\n                                                                validation_split=0.2,\n                                                                   subset=\"training\")\n","eb6220e9":"valid_data = tf.keras.preprocessing.image_dataset_from_directory(directory=train_path,\n                                                                 label_mode=\"categorical\", \n                                                                 shuffle=False,\n                                                                 image_size=(224,224),\n                                                                batch_size = 32,\n                                                                 seed=42,\n                                                                validation_split=0.2,\n                                                                   subset=\"validation\")\n","358121d0":"class_names = train_data.class_names\nclass_names","f901a49c":"data = train_data.take(1)","f3a580c9":"for image, label in data: \n    plt.imshow(image[0]\/255.)\n    plt.title(f\"Target Class: {class_names[tf.argmax(label[0])]} \")\n","f5fe9004":"image[0], label[0]","08d9fb40":"plt.figure(figsize = (20,20)) \nimage, label = next(iter(train_data))\nfor i in range(0,25) : \n    \n    ax = plt.subplot(5,5,i+1) \n    plt.imshow(image[i]\/255.)\n    plt.title(f\"Target: {class_names[tf.argmax(label[i])]} \")\n    ax.axis(\"off\")","6fed4bc7":"base_model = tf.keras.applications.EfficientNetB0(include_top= False)\n\nbase_model.trainable = False \n\ninputs = tf.keras.layers.Input(shape=(224,224,3), name='Input_Layer') \n\nx = base_model(inputs) \n\nx = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n\noutputs = tf.keras.layers.Dense(len(class_names), activation='softmax', name='output_layer')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\nmodel.compile(loss='categorical_crossentropy',\n             optimizer = tf.keras.optimizers.Adam(), \n             metrics=['accuracy']) \n\nmodel_history = model.fit(train_data, \n                          steps_per_epoch=len(train_data),\n                          validation_data= valid_data,\n                        validation_steps= len(valid_data),\n                         epochs=5\n                         )","15ae791c":"#Evaluate on full data\nmodel.evaluate(valid_data)","2ead8328":"def plot_loss_curves(history):\n  \"\"\"\n  Returns separate loss curves for training and validation metrics.\n  Args:\n    history: TensorFlow model History object (see: https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/callbacks\/History)\n  \"\"\" \n  loss = history.history['loss']\n  val_loss = history.history['val_loss']\n\n  accuracy = history.history['accuracy']\n  val_accuracy = history.history['val_accuracy']\n\n  epochs = range(len(history.history['loss']))\n\n  # Plot loss\n  plt.plot(epochs, loss, label='training_loss')\n  plt.plot(epochs, val_loss, label='val_loss')\n  plt.title('Loss')\n  plt.xlabel('Epochs')\n  plt.legend()\n\n  # Plot accuracy\n  plt.figure()\n  plt.plot(epochs, accuracy, label='training_accuracy')\n  plt.plot(epochs, val_accuracy, label='val_accuracy')\n  plt.title('Accuracy')\n  plt.xlabel('Epochs')\n  plt.legend();","807a675d":"#Check our loss curves \nplot_loss_curves(model_history)","e294cd24":"prediction = model.predict(valid_data)","67e623f8":"# Turn prediction probabilities into their respective label (easier to understand)\ndef get_pred_label(prediction_probabilities):\n  \"\"\"\n  Turns an array of prediction probabilities into a label.\n  \"\"\"\n  return class_names[tf.argmax(prediction_probabilities)]\n\n# Get a predicted label based on an array of prediction probabilities\npred_label = get_pred_label(prediction[0])\npred_label","27335242":"# Create a function to unbatch a batched dataset\ndef unbatchify(data):\n  \"\"\"\n  Takes a batched dataset of (image, label) Tensors and returns separate arrays\n  of images and labels.\n  \"\"\"\n  images = []\n  labels = []\n  # Loop through unbatched data\n  for image, label in data.unbatch().as_numpy_iterator():\n    images.append(image\/255.)\n    labels.append(class_names[tf.argmax(label)])\n  return images, labels\n\n# Unbatchify the validation data\nval_images, val_labels = unbatchify(valid_data)\nval_images[0], val_labels[0]","292ab08a":"import numpy as np\ndef plot_pred(prediction_probabilities, labels, images, n=1):\n  \"\"\"\n  View the prediction, ground truth label and image for sample n.\n  \"\"\"\n  pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]\n  \n  # Get the pred label\n  pred_label = get_pred_label(pred_prob)\n  \n  # Plot image & remove ticks\n  plt.imshow(image)\n  plt.xticks([])\n  plt.yticks([])\n\n  # Change the color of the title depending on if the prediction is right or wrong\n  if pred_label == true_label:\n    color = \"green\"\n  else:\n    color = \"red\"\n\n  plt.title(\"{} {:2.0f}% ({})\".format(pred_label,\n                                      np.max(pred_prob)*100,\n                                      true_label),\n                                      color=color)","7803aafb":"# View an example prediction, original image and truth label\nplot_pred(prediction_probabilities=prediction,\n          labels=val_labels,\n          images=val_images,n=33)","3b09b6d0":"def plot_pred_conf(prediction_probabilities, labels, n=1):\n  \"\"\"\n  Plots the top 10 highest prediction confidences along with\n  the truth label for sample n.\n  \"\"\"\n  pred_prob, true_label = prediction_probabilities[n], labels[n]\n\n  # Get the predicted label\n  pred_label = get_pred_label(pred_prob)\n\n  # Find the top 10 prediction confidence indexes\n  top_10_pred_indexes = pred_prob.argsort()[-10:][::-1]\n  # Find the top 10 prediction confidence values\n  top_10_pred_values = pred_prob[top_10_pred_indexes]\n  # Find the top 10 prediction labels\n  top_10_pred_labels = np.array(class_names)[top_10_pred_indexes]\n\n  # Setup plot\n  top_plot = plt.bar(np.arange(len(top_10_pred_labels)), \n                     top_10_pred_values, \n                     color=\"grey\")\n  plt.xticks(np.arange(len(top_10_pred_labels)),\n             labels=top_10_pred_labels,\n             rotation=\"vertical\")\n\n  # Change color of true label\n  if np.isin(true_label, top_10_pred_labels):\n    top_plot[np.argmax(top_10_pred_labels == true_label)].set_color(\"green\")\n  else:\n    pass","b8f453ca":"plot_pred_conf(prediction_probabilities=prediction,\n               labels=val_labels,\n               n=1)","25438ff8":"# Let's check a few predictions and their different values\ni_multiplier = 0\nnum_rows = 3\nnum_cols = 2\nnum_images = num_rows*num_cols\nplt.figure(figsize=(5*2*num_cols, 5*num_rows))\nfor i in range(num_images):\n  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n  plot_pred(prediction_probabilities=prediction,\n            labels=val_labels,\n            images=val_images,\n            n=i+i_multiplier)\n  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  plot_pred_conf(prediction_probabilities=prediction,\n                labels=val_labels,\n                n=i+i_multiplier)\nplt.tight_layout(h_pad=1.0)\nplt.show()","1b6a47ce":"train_data = tf.keras.preprocessing.image_dataset_from_directory(directory=train_path,\n                                                                 label_mode=\"categorical\", \n                                                                 shuffle=True,\n                                                                 image_size=(224,224),\n                                                                batch_size = 32)","54d071e3":"base_model = tf.keras.applications.EfficientNetB0(include_top= False)\n\nbase_model.trainable = False \n\ninputs = tf.keras.layers.Input(shape=(224,224,3), name='Input_Layer') \n\nx = base_model(inputs) \n\nx = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n\noutputs = tf.keras.layers.Dense(len(class_names), activation='softmax', name='output_layer')(x)\n\nmodel = tf.keras.Model(inputs, outputs)\n\nmodel.compile(loss='categorical_crossentropy',\n             optimizer = tf.keras.optimizers.Adam(), \n             metrics=['accuracy']) \n\nmodel_history = model.fit(train_data, \n                          steps_per_epoch=len(train_data),\n                         epochs=10\n                         )","b76f7a4b":"#Prepare the Test data using Tensorflow Image Generator\n\ndatagen = ImageDataGenerator()\ngen = datagen.flow_from_directory(test_path ,shuffle =False,batch_size=100,\n                              target_size = (224,224),classes = ['test'])","f9db9502":"prediction = model.predict(gen)\nprediction.shape","18f53bc5":"class_names[tf.argmax(prediction[2])]","bbf437bd":"#Read sample submission file \nsample_submission = pd.read_csv('..\/input\/plant-seedlings-classification\/sample_submission.csv')\nsample_submission.head()","3b82a1b3":"len(sample_submission)","8e7890ab":"#Prepare prediction results\npredict_class = []\nfor pred in prediction: \n    predict_class.append(class_names[tf.argmax(pred)])\n\npredict_class[:10]","53ed9e86":"submission = pd.DataFrame({'file':sample_submission['file'],'species':predict_class})\nsubmission.head()","1cb1b44b":"submission.to_csv('submission.csv', index=False)","ebe01f6c":"Hmm, We learnt from here two things:\n\nThere are 794 images in test folder which will be used for testing.\n\nThere are images for each class in a directory structure for training. ","98b3cb3f":"# Using Tensorflow 2.x Transfer Learning to classify Plant seedlings \u2618\n\n### About the competition \nMany times it is very difficult to tell which plant it is from the seedlings. In this compition, we will make a ML model which can help to identify seedlings and tell which plant it is. \n\n### Kind of ML Problem\nThis kind of problem is called multi-class image classification. It's multi-class because we're trying to classify mutliple different plant seedlings. \n\n1. Getting data ready import dataset.\n2. Visualize the Dataset.\n3. Preprocess the Dataset for Tensorflow format.\n4. Prepare Tensorflow Tranfer learning Model.\n5. Train the model on small data.\n6. Visualize the model results.\n7. Train on complete data.\n8. Predict on test model.","3fd74be3":"## Train on full data","c4d39707":"Here, from the above plot we can see our model is generalizing really well on training and validation data. Great. \n\nLet's try to predict and check the predictions. ","7f6d9443":"## Visualizing the dataset","e1914726":"## Test data prediction","7ae548b1":"### View Images from training data set\n","b74cd417":"## Visualize Model results","8a7bf261":"## What's next? \n\nWoah! What an effort. If you've made it this far, you've just gone end-to-end on a multi-class image classification problem.\n\nYou can try using other approaches to improve your model.\n\n1. Data augmentation - Take the training images and manipulate (crop, resize) or distort them (flip, rotate) to create even more training data for the model to learn from. Check out the TensorFlow images documentation for a whole bunch of functions you can use on images. \n\n2. Fine-tuning - The model we used in this notebook was directly from TensorFlow Hub, we took what it had already learned from another dataset (ImageNet) and applied it to our own. Another option is to use what the model already knows and fine-tune this knowledge to our own dataset.\n\n\n#### Please Upvote if like you my work. If you have any queries please comment. \ud83d\ude0e","bfccd0c4":"## Building a tranfer learning model feature extraction using the keras functional API\n\nThe sequential API is straight forward, it runs our layers in sequential order.\n\nBut the functional API gives us more flexibility with our models","8769e6a5":"## Prepare the data for Training & Validation"}}