{"cell_type":{"28588572":"code","66862a46":"code","5536eff4":"code","0381c145":"code","28cf414f":"code","59b12609":"code","9820911f":"code","a6e4fc03":"code","91ff8d0b":"code","863a0576":"code","66066af8":"code","85cadf69":"code","0e96532b":"code","11aba19d":"code","e5e71353":"code","d5de0d13":"code","fdf20568":"code","12d9dd19":"code","4291e6f5":"code","4fb1dc94":"code","b6889b10":"code","e7265d1c":"code","bc32d090":"code","bf8f81eb":"code","839ea469":"code","deb5bf10":"code","8d3e3306":"code","256b5ec9":"code","487005d5":"code","c6fce4dc":"code","befb222a":"code","abf3a039":"code","3c4e57fa":"code","1c57bf3a":"code","31a346f7":"code","8b14a840":"code","161f17d6":"code","a669d222":"code","f2e07b11":"code","6f17fb10":"code","d0bad62d":"code","41d9bf6b":"code","d8ce6907":"code","d7444d87":"code","2ae4dc2b":"code","9cc4f9da":"code","80e1ef55":"code","b143b435":"code","4b1023c1":"code","38c4ae7e":"markdown","18127bd8":"markdown","43e921b1":"markdown","7e2a703d":"markdown","3fbb8226":"markdown","1abf00c1":"markdown","af4c1005":"markdown","8ba9b952":"markdown","c9128313":"markdown","9f3bf9f6":"markdown","f1364682":"markdown","b3de9404":"markdown","9e53f3ac":"markdown","f8b202ab":"markdown","58424b36":"markdown","0be8d400":"markdown","8027dc6f":"markdown"},"source":{"28588572":"%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os, random, math\nimport itertools\nfrom pathlib import Path\n\nfrom tqdm import tqdm\nimport gc\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\n\nfrom plotly.offline import iplot\n\nimport cufflinks as cf\ncf.go_offline()\ncf.set_config_file(offline = False, world_readable = True)\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GroupKFold, StratifiedKFold\nfrom sklearn.metrics import mean_squared_error\n\nplt.rcParams[\"figure.figsize\"] = (16, 10)\nplt.rcParams['axes.titlesize'] = 12\n\nprint(os.listdir('..\/input\/petfinder-pawpularity-score\/'))\n   \nfrom time import time, strftime, gmtime\n\nstart = time()\nprint(start)\n\nimport datetime\nprint(str(datetime.datetime.now()))\n\nimport warnings\nwarnings.simplefilter('ignore')","66862a46":"base_dir = '..\/input\/petfinder-pawpularity-score\/'","5536eff4":"train = pd.read_csv(base_dir + 'train.csv')\nprint(train.shape)\ntrain.head()","0381c145":"test = pd.read_csv(base_dir + 'test.csv')\nprint(test.shape)\ntest.head()","28cf414f":"sub = pd.read_csv(base_dir + 'sample_submission.csv')\nprint(sub.shape)\nsub.head()","59b12609":"train.info(), test.info()","9820911f":"train.describe().T","a6e4fc03":"plt.figure(figsize = (16, 8))\nsns.histplot(train['Pawpularity'], color = 'green', kde = True);","91ff8d0b":"fig, axes = plt.subplots(4, 3, figsize = (20, 16))\naxes = axes.ravel()\n\npalette = itertools.cycle(sns.color_palette())\n\nfor i, col in enumerate(train.columns[1:-2]):\n    c = next(palette)\n    ax = sns.countplot(data = train, x = col, ax = axes[i], color = c)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x() + p.get_width() \/ 2.0, height + 3,\n                f\"{round(100 * height \/ len(train[col]), 2)}%\",\n                ha = 'center')\nfig.tight_layout()","863a0576":"bins = [0, 25, 50, 75, 100]\ntrain['paw_binnned'] = pd.cut(train['Pawpularity'], bins = bins, labels = ['Not So Good', 'Average', 'Good', 'Great'])","66066af8":"ax = sns.countplot(train['paw_binnned'])\nax.set_title('Distribution of Pawpularity Score - Binned')\nfor p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x() + p.get_width() \/ 2.0, height + 3,\n                f\"{round(100 * height \/ len(train['paw_binnned']), 2)}%\",\n                ha = 'center')","85cadf69":"def pawlot_helper(nrows: int, ncols: int, category: str):\n    img_idx = np.random.choice(train[train['paw_binnned'] == category]['Id'], nrows * ncols)\n    fig, axes = plt.subplots(nrows, ncols, figsize = (16, 14))\n    axes = axes.ravel()\n    for i, idx in enumerate(img_idx):\n        img_path = f\"{base_dir}train\/{idx}.jpg\"\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        axes[i].imshow(img)\n        axes[i].set_title(f\"{category} - {train[train['Id'] == idx]['Pawpularity'].values[0]}\")\n        \n    plt.show()","0e96532b":"pawlot_helper(3, 3, 'Great')","11aba19d":"pawlot_helper(3, 3, 'Good')","e5e71353":"pawlot_helper(3, 3, 'Average')","d5de0d13":"pawlot_helper(3, 3, 'Not So Good')","fdf20568":"def category_plot_helper(df: pd.DataFrame, nrows: int, ncols: int, category: str):\n    img_idx = np.random.choice(df['Id'], nrows * ncols)\n    fig, axes = plt.subplots(nrows, ncols, figsize = (20, 10))\n    axes = axes.ravel()\n    for i, idx in enumerate(img_idx):\n        img_path = f\"{base_dir}train\/{idx}.jpg\"\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (224, 224))\n        axes[i].imshow(img)\n        axes[i].set_title(f\"{category} \\n {idx}\")\n        axes[i].axis('off')\n    fig.tight_layout()  \n    plt.show()","12d9dd19":"focus = train[train['Subject Focus'] == 1][['Id']].copy()\nno_focus = train[train['Subject Focus'] == 0][['Id']].copy()\ncategory_plot_helper(focus, 1, 6, 'Focus')\ncategory_plot_helper(no_focus, 1, 6, 'No Focus')\n\ndel focus, no_focus\n_ = gc.collect()","4291e6f5":"clear_eyes = train[train['Eyes'] == 1][['Id']].copy()\nno_clear_eyes = train[train['Eyes'] == 0][['Id']].copy()\ncategory_plot_helper(clear_eyes, 1, 6, 'Eyes')\ncategory_plot_helper(no_clear_eyes, 1, 6, 'No Clear Eyes')\n\ndel clear_eyes, no_clear_eyes\n_ = gc.collect()","4fb1dc94":"face = train[train['Face'] == 1][['Id']].copy()\nno_clear_face = train[train['Face'] == 0][['Id']].copy()\ncategory_plot_helper(face, 1, 6, 'Face')\ncategory_plot_helper(no_clear_face, 1, 6, 'No Clear Face')\n\ndel face, no_clear_face\n_ = gc.collect()","b6889b10":"near = train[train['Near'] == 1][['Id']].copy()\nno_near = train[train['Near'] == 0][['Id']].copy()\ncategory_plot_helper(near, 1, 6, 'Near')\ncategory_plot_helper(no_near, 1, 6, 'No Near')\n\ndel near, no_near\n_ = gc.collect()","e7265d1c":"group = train[train['Group'] == 1][['Id']].copy()\nno_group = train[train['Group'] == 0][['Id']].copy()\ncategory_plot_helper(group, 1, 6, 'Group')\ncategory_plot_helper(no_group, 1, 6, 'No Group')\n\ndel group, no_group\n_ = gc.collect()","bc32d090":"occlusion = train[train['Occlusion'] == 1][['Id']].copy()\nno_occlusion = train[train['Occlusion'] == 0][['Id']].copy()\ncategory_plot_helper(occlusion, 1, 6, 'Occlusion')\ncategory_plot_helper(no_occlusion, 1, 6, 'No Occlusion')\n\ndel occlusion, no_occlusion\n_ = gc.collect()","bf8f81eb":"temp = train[train.iloc[:, 1: -2].sum(axis = 1) == 0 ]\nprint(f\"Num of pets scoring 0 in all the categories: {len(temp)}\")\nfig, axes = plt.subplots(2, 4, figsize = (16, 8))\naxes = axes.ravel()\nfor i, idx in enumerate(np.random.choice(temp['Id'], 8)):\n    img_path = f\"{base_dir}train\/{idx}.jpg\"\n    img = cv2.imread(img_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (224, 224))\n    axes[i].imshow(img)\n    axes[i].set_title(f\"{idx}\")\n    axes[i].axis('off')\nfig.tight_layout()","839ea469":"!pip install -q efficientnet >> \/dev\/null","deb5bf10":"import tensorflow as tf\nimport tensorflow.keras.backend as K\n\nimport efficientnet.tfkeras as efn\n\nimport yaml\nfrom kaggle_datasets import KaggleDatasets","8d3e3306":"GCS_PATH  = KaggleDatasets().get_gcs_path('petfinder-pawpularity-score')\nGCS_PATH","256b5ec9":"train['img_path'] = GCS_PATH + '\/train\/' + train['Id'] + '.jpg'\ntest['img_path'] = GCS_PATH + '\/test\/' + test['Id'] + '.jpg'","487005d5":"config = {\n    'DEBUG': False,\n    'DIR': base_dir,\n    'DEVICE': 'TPU',\n    'EPOCHS': 15,\n    'MODEL': 'efn.EfficientNetB2',\n    'FOLDS': 5,\n    'SEED': 777,\n    'VERBOSE': 1,\n    'BATCH_SIZE': 16,\n    'IMG_SIZE': 512,\n    'LOSS': 'RMSE',\n    'OPT': 'Adam',\n    'SCHEDULER': 'exp', # Cosine - LR SCHEDULER\n    \n    #FLIP\n    'hflip': True, \n    'vflip': False,\n    \n    'clip': False,     #CLIP [0, 1]\n    \n    #Dropout\n    'drop_prob': 0.75,\n    'drop_cnt': 10,\n    'drop_size': 0.05,\n\n    #brightness, contrast\n    'sat': [0.7, 1.3],\n    'cont': [0.8, 1.2],\n    'bri': 0.15,\n    'hue': 0.05,\n    \n    'CAT_COLS': ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n                   'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'],\n    'TARGET_COL': ['Pawpularity']\n}\n\nwith open(r'config.yaml', 'w') as f:\n    yaml.dump(config, f)","c6fce4dc":"def seeding(SEED):\n    np.random.seed(SEED)\n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)\n    tf.random.set_seed(SEED)\n    print('seeding done!!!')\nseeding(config['SEED'])","befb222a":"if config['DEVICE'] == \"TPU\":\n    print(\"connecting to TPU...\")\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        print(\"Could not connect to TPU\")\n        tpu = None\n\n    if tpu:\n        try:\n            print(\"initializing  TPU ...\")\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"TPU initialized\")\n        except _:\n            print(\"failed to initialize TPU\")\n    else:\n        config['DEVICE'] = \"GPU\"\n\nif config['DEVICE'] != \"TPU\":\n    print(\"Using default strategy for CPU and single GPU\")\n    strategy = tf.distribute.get_strategy()\n\nif config['DEVICE'] == \"GPU\":\n    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n    \n\nAUTO     = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","abf3a039":"#Calculate bins for folds\nnum_bins = int(np.floor(1 + np.log2(len(train))))\nprint(num_bins)\ntrain['bins'] = pd.cut(train['Pawpularity'].values.reshape(-1), bins = num_bins, labels = False)\ntrain.head(2)","3c4e57fa":"skf = StratifiedKFold(n_splits = config['FOLDS'], shuffle = True, random_state = config['SEED'])\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(train, train['bins'])):\n    train.loc[val_idx, 'folds'] = fold\ntrain.groupby(['folds', 'bins']).size()","1c57bf3a":"#Thanks to @awsaf for his boilerplate data pipeline\n\ndef build_decoder(with_labels = True, target_size = config['IMG_SIZE'], ext = 'jpg'):\n    def decode(path):\n        file_bytes = tf.io.read_file(path)\n        if ext == 'png':\n            img = tf.image.decode_png(file_bytes, channels = 3)\n        elif ext in ['jpg', 'jpeg']:\n            img = tf.image.decode_jpeg(file_bytes, channels = 3)\n        else:\n            raise ValueError(\"Image extension not supported\")\n\n        img = tf.image.resize(img, (target_size, target_size))\n        img = tf.cast(img, tf.float32) \/ 255.0\n        img = tf.reshape(img, [target_size, target_size, 3])\n\n        return img\n    \n    def decode_with_labels(path, label):\n        return decode(path), tf.cast(label, tf.float32)\n    \n    return decode_with_labels if with_labels else decode\n\n\ndef build_augmenter(with_labels = True, dim = config['IMG_SIZE']):\n    def augment(img, dim = dim):\n        img = tf.image.random_flip_left_right(img) if config['hflip'] else img\n        img = tf.image.random_flip_up_down(img) if config['vflip'] else img\n        img = tf.image.random_hue(img, config['hue'])\n        img = tf.image.random_saturation(img, config['sat'][0], config['sat'][1])\n        img = tf.image.random_contrast(img, config['cont'][0], config['cont'][1])\n        img = tf.image.random_brightness(img, config['bri'])\n        #img = dropout(img, DIM = dim, PROBABILITY = config['drop_prob'], CT = config['drop_cnt'], SZ = config['drop_size'])\n        img = tf.clip_by_value(img, 0, 1)  if config['clip'] else img         \n        img = tf.reshape(img, [dim, dim, 3])\n        return img\n    \n    def augment_with_labels(img, label):    \n        return augment(img), label\n    \n    return augment_with_labels if with_labels else augment\n\n\ndef build_dataset(paths, labels = None, batch_size = 32, cache = True, decode_fn = None, augment_fn = None,\n                  augment = True, repeat = True, shuffle = 1024, cache_dir = \"\", drop_remainder = False):\n    \n    if cache_dir != \"\" and cache is True:\n        os.makedirs(cache_dir, exist_ok = True)\n    \n    if decode_fn is None:\n        decode_fn = build_decoder(labels is not None)\n    \n    if augment_fn is None:\n        augment_fn = build_augmenter(labels is not None)\n    \n    AUTO = tf.data.experimental.AUTOTUNE\n    slices = paths if labels is None else (paths, labels)\n    \n    ds = tf.data.Dataset.from_tensor_slices(slices)\n    ds = ds.map(decode_fn, num_parallel_calls = AUTO)\n    ds = ds.cache(cache_dir) if cache else ds\n    ds = ds.repeat() if repeat else ds\n    if shuffle: \n        ds = ds.shuffle(shuffle, seed = config['SEED'])\n        opt = tf.data.Options()\n        opt.experimental_deterministic = False\n        ds = ds.with_options(opt)\n    ds = ds.map(augment_fn, num_parallel_calls = AUTO) if augment else ds\n    ds = ds.batch(batch_size, drop_remainder = drop_remainder)\n    ds = ds.prefetch(AUTO)\n    return ds","31a346f7":"#Sanity check\ndef plot_dataset(dataset, row: int, col: int):\n    for (img, lbls) in dataset.take(1):\n        plt.figure(figsize = (16, 12))\n        for i in range(row * col):\n            ax = plt.subplot(row, col, i + 1)\n            plt.imshow(img[i].numpy())\n            plt.title(f\"Pawpularity: {lbls[i].numpy()}\", color = 'r')\n            plt.axis('off')\n            plt.grid(False)\n        plt.show()","8b14a840":"fold = 0\nfold_df = train.query('folds==@fold')[:2000]\npaths  = fold_df['img_path'].tolist()\nlabels = fold_df[config['TARGET_COL']].values\ndataset = build_dataset(paths, labels, cache = False, batch_size = config['BATCH_SIZE'] * REPLICAS,\n                   repeat = True, shuffle = True, augment = True)\nplot_dataset(dataset, 3, 3)","161f17d6":"fold = 0\nfold_df = train.query('folds!=@fold')[:2000]\npaths  = fold_df['img_path'].tolist()\nlabels = fold_df[config['TARGET_COL']].values\ndataset = build_dataset(paths, labels, cache = True, batch_size = config['BATCH_SIZE'] * REPLICAS,\n                   repeat = False, shuffle = False, augment = False)\nplot_dataset(dataset, 3, 3)\n\ndel dataset\n_ = gc.collect()","a669d222":"def get_lr_callback(batch_size = 8, plot = False):\n    lr_start   = 0.000005\n    lr_max     = 0.00000125 * REPLICAS * batch_size\n    lr_min     = 0.000001\n    lr_ramp_ep = 5\n    lr_sus_ep  = 0\n    lr_decay   = 0.8\n   \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) \/ lr_ramp_ep * epoch + lr_start\n            \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max\n            \n        elif config['SCHEDULER'] == 'exp':\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n            \n        elif config['SCHEDULER'] == 'cosine':\n            decay_total_epochs = config['EPOCHS'] - lr_ramp_ep - lr_sus_ep + 3\n            decay_epoch_index = epoch - lr_ramp_ep - lr_sus_ep\n            phase = math.pi * decay_epoch_index \/ decay_total_epochs\n            cosine_decay = 0.5 * (1 + math.cos(phase))\n            lr = (lr_max - lr_min) * cosine_decay + lr_min\n        return lr\n    if plot:\n        plt.figure(figsize = (10, 5))\n        plt.plot(np.arange(config['EPOCHS']), [lrfn(epoch) for epoch in np.arange(config['EPOCHS'])], marker = 'o')\n        plt.xlabel('epoch')\n        plt.ylabel('learnig rate')\n        plt.title('Learning Rate Scheduler')\n        plt.show()\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = False)\n    \n    return lr_callback\n\n_ = get_lr_callback(config['BATCH_SIZE'], plot = True )","f2e07b11":"#TF RMSE Loss\ndef RMSE(y_true, y_pred):\n    loss = tf.math.sqrt(tf.math.reduce_mean(tf.math.square(tf.subtract(y_true, y_pred))))\n    return loss","6f17fb10":"def create_model(dim = config['IMG_SIZE']): \n    \n    with strategy.scope():\n        pre_trained = efn.EfficientNetB2(input_shape = (dim, dim, 3),\n                            include_top = False,\n                            weights = 'imagenet')\n\n        x = tf.keras.layers.GlobalAveragePooling2D()(pre_trained.output)\n        x = tf.keras.layers.Dense(64, activation = 'selu')(x)\n        x = tf.keras.layers.Dense(1)(x)\n\n        model = tf.keras.Model(inputs = pre_trained.input, outputs = x)\n\n        opt = tf.keras.optimizers.Adam(learning_rate = 0.001)\n        loss = RMSE\n        metric = tf.keras.metrics.RootMeanSquaredError(name = 'rmse')\n        model.compile(optimizer = opt, loss = loss, metrics = metric)\n    \n    return model","d0bad62d":"model = create_model(dim = config['IMG_SIZE'])\nmodel.summary()\n\ndel model\n_ = gc.collect()","41d9bf6b":"if config['DEBUG']:\n    train = train.sample(frac = 0.2).reset_index(drop = True)\n    print(train.shape)","d8ce6907":"def plot_history(history):\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.legend(['loss', 'val_loss'])\n    plt.title(f'Loss: RMSE Loss')\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['rmse'])\n    plt.plot(history.history['val_rmse'])\n    plt.legend(['rmse', 'val_rmse'])\n    plt.title(f'Metric: RMSE')\n    plt.show()","d7444d87":"oof_preds = []\noof_scores = []\ntest_preds = []\nbatch_size = config['BATCH_SIZE'] * REPLICAS\n\nfor i, fold in enumerate(np.arange(config['FOLDS'])):\n    print('#############' * 10)\n    print(f\"Fold: {fold + 1}\")\n    train_df = train[train['folds'] != fold].copy()\n    valid_df = train[train['folds'] == fold].copy()\n    print(f\"Training with Model: {config['MODEL']}; Image Size: {config['IMG_SIZE']}; Batch Size: {batch_size}\")\n    print(f\"Num of Train Images: {len(train_df)}; Num of Valid Images: {len(valid_df)}\")\n    print()\n    train_paths = train_df['img_path'].values\n    train_labels = train_df['Pawpularity'].values\n    valid_paths = valid_df['img_path'].values\n    valid_labels = valid_df['Pawpularity'].values\n    #print(train_paths.shape, train_labels.shape, valid_paths.shape, valid_labels.shape)\n    \n    K.clear_session()\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(f\"paw_model_{fold}.h5\", monitor = 'val_rmse', verbose = 1, save_best_only = True,\n                                                    save_weights_only = False, mode = 'min', save_freq = 'epoch')\n    train_dataset = build_dataset(train_paths, train_labels, cache = False, batch_size = batch_size,\n                                   repeat = True, shuffle = True, augment = True)\n    valid_dataset = build_dataset(valid_paths, valid_labels, cache = True, batch_size = batch_size,\n                                   repeat = False, shuffle = False, augment = False)\n    \n    model = create_model(dim = config['IMG_SIZE'])\n    \n    print('Model Training...')\n    history = model.fit(\n                        train_dataset, \n                        epochs = config['EPOCHS'],\n                        callbacks = [checkpoint, get_lr_callback(batch_size)], \n                        steps_per_epoch = len(trn_idx) \/ batch_size \/\/ REPLICAS,\n                        validation_data = valid_dataset, \n                        verbose = 1\n                    )\n    print('Load best model for prediction...')\n    model.load_weights(f\"paw_model_{fold}.h5\")\n    print('Predict Valid - OOF...')\n    valid_preds = model.predict(valid_dataset, batch_size = batch_size, verbose = 1)\n    oof_preds.append(valid_preds)\n\n    print(f\"Fold RMSE: {RMSE(valid_labels.reshape(-1, 1).astype(np.float32), valid_preds):0.4f}\")\n    oof_scores.append(RMSE(valid_labels.reshape(-1, 1).astype(np.float32), valid_preds))\n    \n    #plot history\n    plot_history(history)\n    \n    print('Predict on Test dataset...')\n    test_paths = test['img_path'].values\n    test_dataset = build_dataset(test_paths, labels = None, cache = True, batch_size = batch_size,\n                               repeat = False, shuffle = False, augment = False)\n    \n    test_preds.append(model.predict(test_dataset, batch_size = batch_size, verbose = 1))\n    \n    del model, train_dataset, valid_dataset\n    _ = gc.collect()","2ae4dc2b":"#save parameters\nconfig['SCORES'] = oof_scores\nwith open(r'config.yaml', 'w') as f:\n    yaml.dump(config, f)","9cc4f9da":"oof_pred = np.concatenate(oof_preds).reshape(-1)","80e1ef55":"preds = np.mean(test_preds, axis = 0).reshape(-1)\nsub['Pawpularity'] = preds\nsub.to_csv('.\/submission.csv', index = False)","b143b435":"fig, ax = plt.subplots(1, 3, figsize = (16, 8))\nax = ax.ravel()\n\nax[0].set_title('Train Target Distribution')\nsns.kdeplot(train['Pawpularity'], shade = True, ax = ax[0], color = 'green')\nax[1].set_title('OOF Prediction Distribution')\nsns.kdeplot(oof_pred, shade = True, ax = ax[1], color = 'blue')\nax[2].set_title('Test Prediction Distribution')\nsns.kdeplot(sub['Pawpularity'], shade = True, ax = ax[2], color = 'red')","4b1023c1":"finish = time()\nprint(strftime(\"%H:%M:%S\", gmtime(finish - start)))","38c4ae7e":"### TPU Config","18127bd8":"# Competition Metric\nSubmissions are scored on the __Root Mean Squared Error__","43e921b1":"# Eyes \n- Both eyes are facing front or near-front, with at least 1 eye \/ pupil decently clear.","7e2a703d":"# Modeling and Prediction","3fbb8226":"# Data Pipeline","1abf00c1":"- #### Let's check the pets' pictures by category one by one:","af4c1005":"<font size = 4> Binning the pawpularity score into 4 categories<\/font>","8ba9b952":"# Face \n- Decently clear face, facing front or near-front.","c9128313":"# Occlusion \n- Specific undesirable objects blocking part of the pet (i.e. human, cage or fence). Note that not all blocking objects are considered occlusion.","9f3bf9f6":"# Group \n- More than 1 pet in the photo.","f1364682":"- There are pictures that could be in high score but given low scores - manual labeling error\n- Pictures are of different sizes - needs resizing before feeding into a NN","b3de9404":"# Competition Task\nThe objective of this competition is to find a populaity score for a pet given their picture and other meta-data. The metadata corresponds to the aesthetic features of the picture provided and it is hand labeled","9e53f3ac":"# Near \n- Single pet taking up significant portion of photo (roughly over 50% of photo width or height).","f8b202ab":"- We see that most of the score is between 25 to 50 range\n- The next highest cateogry is the between the range 0 to 25\n- We'll visualize few images from each of these categories to better understand the how they're scored","58424b36":"# Focus \n- Pet stands out against uncluttered background, not too close \/ far.","0be8d400":"# Code Requirements\n- CPU Notebook <= 9 hours run-time\n- GPU Notebook <= 9 hours run-time\n- Internet access disabled\n- Freely & publicly available external data is allowed, including pre-trained models\n- Submission file must be named submission.csv","8027dc6f":"# Model Training"}}