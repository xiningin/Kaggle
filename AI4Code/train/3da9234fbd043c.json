{"cell_type":{"12130299":"code","37e90657":"code","2402566a":"code","64d574ce":"code","e57f55aa":"code","e6f078f9":"code","0645fef4":"code","031de380":"code","b3abe93f":"code","a40aed55":"code","4e4feebe":"code","89de22df":"code","ece0190f":"code","635acabd":"code","5872a13c":"code","28be711d":"code","a614c62e":"code","e99673b2":"code","edf63d08":"code","5122f380":"code","c2b50228":"code","e2d25664":"code","d83275a0":"code","5f6be020":"code","317e9c7e":"code","242b0ca8":"code","9262708f":"markdown","ae261a62":"markdown","de95f7ca":"markdown","e63ac555":"markdown","805896fa":"markdown","09266526":"markdown","dcb4ccec":"markdown","6916aa93":"markdown","1b5cf323":"markdown","f7f3eb34":"markdown","daa27d3c":"markdown","80429509":"markdown","8328384f":"markdown","b892b961":"markdown","7c65ab38":"markdown","54828692":"markdown","f719ca4d":"markdown","d2b95a0b":"markdown","38f116e1":"markdown"},"source":{"12130299":"import numpy as np\nimport pickle\nimport cv2\nfrom os import listdir\nfrom sklearn.preprocessing import LabelBinarizer\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation, Flatten, Dropout, Dense\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint","37e90657":"EPOCHS = 5\nBS = 32\ndefault_image_size = tuple((128, 128))\nimage_size = 0\ndirectory_root = '..\/input\/ckplus-dataset\/ck\/CK+48'\nwidth=256\nheight=256\ndepth=3","2402566a":"def convert_image_to_array(image_dir):\n    try:\n        image = cv2.imread(image_dir)\n        if image is not None :\n            image = cv2.resize(image, default_image_size)   \n            return img_to_array(image)\n        else :\n            return np.array([])\n    except Exception as e:\n        print(f\"Error : {e}\")\n        return None","64d574ce":"image_list,label_list = [],[]\ntry:\n    print(\"loading images...\")\n    root_dir = listdir(directory_root)\n    for emotion_folder in root_dir:\n        print(f\"[INFO] Processing {emotion_folder}\")\n        images_list = listdir(f\"{directory_root}\/{emotion_folder}\")\n        \n        #for emotion_image in emotion_folder_list:\n        for images in images_list:\n            image = f\"{directory_root}\/{emotion_folder}\/{images}\"\n            image_list.append(convert_image_to_array(image))\n            label_list.append(emotion_folder)\nexcept Exception as e:\n    print(f\"Error : {e}\")","e57f55aa":"import pandas as pd\na = pd.DataFrame(label_list)\nidx = pd.Index(a)\ncount = idx.value_counts()\nprint(count)","e6f078f9":"image_size = len(image_list)\nprint(image_size)","0645fef4":"np_image_list = np.array(image_list,dtype=np.float32)\/255.0","031de380":"label_binarizer = LabelBinarizer()\nimage_labels = label_binarizer.fit_transform(label_list)\npickle.dump(label_binarizer,open('label_transform.pkl', 'wb'))\nn_classes = len(label_binarizer.classes_)\n","b3abe93f":"x_train,x_test,y_train,y_test = train_test_split(np_image_list,image_labels,test_size=0.01,random_state=42)","a40aed55":"x_train[0].shape","4e4feebe":"aug = ImageDataGenerator(\n    rotation_range=25, width_shift_range=0.1,\n    height_shift_range=0.1, shear_range=0.2, \n    zoom_range=0.2,horizontal_flip=True, \n    fill_mode=\"nearest\")","89de22df":"from keras.applications import VGG19\nfrom keras.optimizers import SGD,RMSprop,adam,Adadelta\n#Load the VGG model\nvgg_conv = VGG19(weights=None, include_top=False, input_shape=(128, 128,3))","ece0190f":"def vgg_custom():\n    model = Sequential()\n    #add vgg conv model\n    model.add(vgg_conv)\n    \n    #add new layers\n    model.add(Flatten())\n    model.add(Dense(7,  kernel_initializer='normal'))\n    model.compile(loss='mean_squared_error', optimizer=Adadelta())\n    \n    return model","635acabd":"model = vgg_custom()\nmodel.summary()","5872a13c":"from keras import callbacks\nfilename='model_train_new.csv'\nfilepath=\"Best-weights-my_model-{epoch:03d}-{loss:.4f}-{acc:.4f}.hdf5\"\n\ncsv_log=callbacks.CSVLogger(filename, separator=',', append=False)\ncheckpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [csv_log,checkpoint]\ncallbacks_list = [csv_log]","28be711d":"history = model.fit_generator(\n    aug.flow(x_train, y_train, batch_size=BS),\n    validation_data=(x_test, y_test),\n    steps_per_epoch=len(x_train) \/\/ BS,\n    epochs=EPOCHS, verbose=1,\n    callbacks = callbacks_list #early stopping\n    )","a614c62e":"no_images = 0\nno_sadness = 0\nno_anger = 0\nno_disgust = 0\nno_happy = 0\nno_fear = 0\nno_surprise = 0\nno_contempt = 0\nfor e in range(2):\n    print('Epoch', e)\n    batches = 0\n    for x_batch, y_batch in aug.flow(x_train, y_train, batch_size=32):\n        model.fit(x_batch, y_batch)\n        batches += 1\n        no_images +=len(x_batch)\n        y_batch_real = label_binarizer.inverse_transform(y_batch)\n        for label in y_batch_real:\n            if(label== 'sadness'):\n                no_sadness+=1\n            elif(label=='anger'):\n                no_anger+=1\n            elif(label=='disgust'):\n                no_disgust+=1\n            elif(label=='happy'):\n                no_happy+=1\n            elif(label=='fear'):\n                no_fear+=1\n            elif(label=='surprise'):\n                no_surprise+=1\n            elif(label=='contempt'):\n                no_contempt+=1\n        if batches >= len(x_train) \/ 32:\n            # we need to break the loop by hand because\n            # the generator loops indefinitely\n            break","e99673b2":"print(len(x_train))","edf63d08":"print(no_images)","5122f380":"print(no_anger)","c2b50228":"print(no_disgust)","e2d25664":"print(no_fear)","d83275a0":"print(no_happy)","5f6be020":"print(no_sadness)","317e9c7e":"print(no_surprise)","242b0ca8":"print(no_contempt)","9262708f":"Image shape","ae261a62":"Get Size of Processed Image","de95f7ca":"Happy augmented images","e63ac555":"No of images after augmentation","805896fa":"Function to convert images to array","09266526":"**Fetch images from directory\n**","dcb4ccec":"Disgust augmented images","6916aa93":"Fear augmented images","1b5cf323":"No of images per class before augmentation","f7f3eb34":"# Standard Model Load and Customization","daa27d3c":"Surprise augmented images","80429509":"Splitting data into train and test","8328384f":"# No of images after augmentation","b892b961":"Normalizing image dataset","7c65ab38":"# Data Fetching and Preprocessing","54828692":"# Training model","f719ca4d":"anger augmented images","d2b95a0b":"****Contempt augmented images","38f116e1":"Sad augmented images"}}