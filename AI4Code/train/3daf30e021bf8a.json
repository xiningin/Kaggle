{"cell_type":{"7a67116a":"code","2e451b18":"code","6a8846d2":"code","6a7c63e6":"code","26db8b92":"code","d7c746b7":"code","288e3af0":"code","a99883dc":"code","75bfa729":"code","07adfd82":"code","8457b1ab":"code","ee678cd7":"code","71552441":"code","c38ac965":"code","6ac8a65e":"code","4d214aac":"code","be045853":"code","01ef2408":"code","a33ae548":"code","3332c416":"code","da85ebfc":"code","5cac04d0":"code","c6d435d5":"code","b7ee47c9":"code","7a6fca3c":"code","4ed84285":"code","d473a33c":"code","2cd5721d":"code","9d2dbdf4":"code","81fcd1c0":"code","485baa7c":"code","6de810dc":"code","fd8d32f5":"code","05acb4cf":"code","7d29f6a2":"code","7246f6a0":"code","e24767f2":"code","2a3de0cb":"code","db172a8d":"code","64057602":"code","3cb51648":"code","bb59b778":"code","c538f960":"code","c765353b":"code","eee98cf5":"code","a865b5dc":"code","a27b3d46":"code","9b3ff299":"code","02cfdea0":"code","56fc6e35":"code","2844040f":"code","5bad578a":"code","46b20b65":"code","d392129f":"code","2f02c0cf":"code","94082e29":"code","d0c19cd0":"code","df85fb12":"code","c520ecfd":"code","fa44f181":"code","2a0e62b0":"code","d4da678a":"code","7c4df2c3":"code","0e3d8eb0":"code","2e620e24":"code","6b92e4fe":"code","2f98ccdb":"code","87d8d818":"code","19aacf6c":"code","61f6aa43":"code","e3c10f5c":"code","54fa19f7":"code","8c2047f5":"code","ebacee92":"code","5332ac06":"code","149f244f":"code","3b1cc5d0":"code","e2197b13":"code","30fd475b":"code","84de8390":"code","024e1be1":"code","c4b5f1c8":"code","cbaf19e2":"code","0a687863":"code","a787bf16":"code","66524898":"code","5f6762f4":"code","289a80ca":"code","d0161e1c":"code","151fbab3":"code","da41b8f1":"code","9fba39ab":"code","9a16779a":"code","501a29cb":"code","76c84b39":"markdown","4fdfcfa9":"markdown","7bb0085f":"markdown","577d5afc":"markdown","038754b8":"markdown","5fcca8d3":"markdown","30ba330d":"markdown","fabd6ce4":"markdown","fd7e0613":"markdown","c23b812a":"markdown","e8b779da":"markdown","b4e2fba7":"markdown","916634bf":"markdown","a733d06c":"markdown","546aa6a2":"markdown","5e758422":"markdown","c25ef967":"markdown","34d6e5b3":"markdown","9f1da9f0":"markdown","b54b7a54":"markdown","50164019":"markdown","79c6b710":"markdown","967af8ab":"markdown","11ffd158":"markdown","3d19e28d":"markdown","10ece279":"markdown","9afebe5b":"markdown","a0689450":"markdown","000fb7d5":"markdown","023363ea":"markdown","dbf26c00":"markdown","97a4a1cf":"markdown","2473c805":"markdown","c8426081":"markdown","896c53cf":"markdown"},"source":{"7a67116a":"#import the necessary python libraries\n\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats as st\nimport math\nimport datetime\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\nfrom IPython.display import display\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.ensemble import RandomForestRegressor \nfrom sklearn import metrics\nfrom sklearn.preprocessing import LabelEncoder\nfrom itertools import combinations\nfrom collections import Counter\nimport random\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures","2e451b18":"RANDOM_SEED = 42\n!pip freeze > requirements.txt\nCURRENT_DATE = pd.to_datetime('21\/09\/2020')","6a8846d2":"#charting function\n\ndef diagram_bar(data, column):\n    fig = plt.figure()\n    main_axes = fig.add_axes([0,0,1,1])\n    data[column].hist(bins = 20)\n    insert_axes = fig.add_axes([1.1,0,0.5,1])\n    data.boxplot(column = column)\n    ","6a7c63e6":"# function that determines the correctness of a hypothesis\n\ndef hypothyroidism(data, column, alpha):\n    \n    if (st.ttest_ind(df[(df['Sample'] == 1) & df[column] == 1].Rating, df[(df['Sample'] == 1) & df[column] == 0].Rating).pvalue < alpha):\n        print(\"\u041e\u0442\u0432\u0435\u0440\u0433\u0430\u0435\u043c \u043d\u0443\u043b\u0435\u0432\u0443\u044e \u0433\u0438\u043f\u043e\u0442\u0435\u0437\u0443\")\n        \n    else:\n        print(\"\u041d\u0435 \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u043e\u0441\u044c \u043e\u0442\u0432\u0435\u0440\u0433\u043d\u0443\u0442\u044c \u043d\u0443\u043b\u0435\u0432\u0443\u044e \u0433\u0438\u043f\u043e\u0442\u0435\u0437\u0443\")","26db8b92":"# function that determines the correctness of the hypothesis in the context of various combinations\n\ndef hypothyroidism_1(data, column, alpha):\n    \n    for row in combinations(data[column].unique(), 2):\n        print(row)\n        \n        if (st.ttest_ind(data[(data['Sample'] == 1) & data[column] == row[0]].Rating, data[(df['Sample'] == 1) & data[column] == row[1]].Rating).pvalue < alpha):\n            print(\"\u041e\u0442\u0432\u0435\u0440\u0433\u0430\u0435\u043c \u043d\u0443\u043b\u0435\u0432\u0443\u044e \u0433\u0438\u043f\u043e\u0442\u0435\u0437\u0443 \u0440\u0430\u0432\u0435\u043d\u0441\u0442\u0432\u0430 \u0440\u0435\u0439\u0442\u0438\u043d\u0433\u043e\u0432 \", row)\n            \n        else:\n            print(\"\u041d\u0435 \u043f\u043e\u043b\u0443\u0447\u0438\u043b\u043e\u0441\u044c \u043e\u0442\u0432\u0435\u0440\u0433\u043d\u0443\u0442\u044c \u043d\u0443\u043b\u0435\u0432\u0443\u044e \u0433\u0438\u043f\u043e\u0442\u0435\u0437\u0443 \u0440\u0430\u0432\u0435\u043d\u0441\u0442\u0432\u0430 \", row)\n    ","d7c746b7":"#function for predicting the objective function using the random forest method and calculating the MAE metric\n\n\ndef model_random_forest(X, y):\n    \n    RANDOM_SEED = 42\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n    model = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    \n    MAE = metrics.mean_absolute_error(y_test, y_pred)\n    print('MAE:', MAE)\n    \n    plt.rcParams['figure.figsize'] = (12,10)\n    feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n    feat_importances.nlargest(15).plot(kind='barh')","288e3af0":"# loading data\n\npath_to_file = '\/kaggle\/input\/sf-dst-restaurant-rating\/'\ndf_train = pd.read_csv(path_to_file+'main_task.csv')\ndf_test = pd.read_csv(path_to_file+'kaggle_task.csv')\nsample_submission = pd.read_csv(path_to_file+'\/sample_submission.csv')\n\n# view the data\n\npd.set_option('display.max_columns', 200)\ndisplay(df_train.head(2))\ndisplay(df_test.head(2))","a99883dc":"display(df_train.info())\ndisplay(df_test.info())","75bfa729":"# checking data for duplicates\n\ndf_train.drop('Reviews', axis = 1).duplicated().sum()","07adfd82":"df_test.drop('Reviews', axis = 1).duplicated().sum()","8457b1ab":"# build a diagram of the distribution of data in the Rating column\n\ndiagram_bar(df_train, 'Rating')","ee678cd7":"# connect two DFs for processing\n\ndf_train['Sample'] = 1 # \u043c\u0435\u0442\u043a\u0430 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 DF\ndf_test['Sample'] = 0 # \u043c\u0435\u0442\u043a\u0430 \u0434\u043b\u044f \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 DF\ndf_test['Rating'] = 0 # \u0442.\u043a. \u0432 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435 \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u0435\u0442 \u0441\u0442\u043e\u043b\u0431\u0435\u0446 Rating, \u0442\u043e \u0441\u043e\u0437\u0434\u0430\u0435\u043c \u0438 \u0437\u0430\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u0435\u0433\u043e \u0441\u0442\u043e\u043b\u0431\u0435\u0446 0\n\ndf = df_test.append(df_train, sort=False).reset_index(drop=True) ","71552441":"df.info()","c38ac965":"# determine the number of unique Restaurant_id\n\nlen(df.Restaurant_id.value_counts())","6ac8a65e":"# restaurants account for 13094 unique values.\n# Made decisions to just code them\n\nle = LabelEncoder()\nle.fit(df['Restaurant_id'])\ndf['Restaurant_id_code'] = le.transform(df['Restaurant_id'])","4d214aac":"restaurant = df.Restaurant_id.value_counts().reset_index()","be045853":"#we will introduce a new parameter chain or non-chain restaurant\n\nrestaurant = restaurant[restaurant.Restaurant_id > 1]\ndf['restaurant_chain'] = df['Restaurant_id'].where(df['Restaurant_id'].isin(restaurant['index']), 0)\ndf.loc[df.restaurant_chain != 0, 'restaurant_chain'] = 1","01ef2408":"# test the hypothesis about the equality of ratings of chain and chain restaurants\n\nhypothyroidism(df, 'restaurant_chain', 0.05)","a33ae548":"# define the unique meaning of cities\n\nlen(df['City'].value_counts())","3332c416":"# cities have 31 unique values. Previous analysis showed\n# that it makes no sense to reduce the number of cities.\n# So I decided to just encode them.\n\nle = LabelEncoder()\nle.fit(df['City'])\ndf['City_code'] = le.transform(df['City'])","da85ebfc":"#\u0441\u043e\u0437\u0434\u0430\u0434\u0438\u043c dummy-\u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435 \u0438\u0437 \u0441\u0442\u043e\u043b\u0431\u0446\u0430 City\n#\u043f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u043d\u0430 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 \u0432\u044b\u0434\u0435\u043b\u0438\u043c \u0433\u043e\u0440\u043e\u0434\u0430, \u0432\u043b\u0438\u044f\u044e\u0449\u0438\u0435 \u043d\u0430 \u0438\u0442\u043e\u0433\u043e\u0432\u0443\u044e \u043e\u0446\u0435\u043d\u043a\u0443\n\nCity = pd.get_dummies(df['City'])\nmodel_random_forest(City, df.Rating)","5cac04d0":"df = pd.concat([df, City['Rome']], axis = 1)","c6d435d5":"# highlight a new sign whether the city belongs to the capital or not\n\n\ndict_\u0421ity_capital = {'London' : 1, 'Paris' : 1, 'Madrid' : 1, 'Barcelona' : 0, \n                        'Berlin' : 1, 'Milan' : 0, 'Rome' : 1, 'Prague' : 1, \n                        'Lisbon' : 1, 'Vienna' : 1, 'Amsterdam' : 1, 'Brussels' : 1, \n                        'Hamburg' : 0, 'Munich' : 0, 'Lyon' : 0, 'Stockholm' : 0, \n                        'Budapest' : 1, 'Warsaw' : 1, 'Dublin' : 1, \n                        'Copenhagen' : 1, 'Athens' : 1, 'Edinburgh' : 1, \n                        'Zurich' : 1, 'Oporto' : 0, 'Geneva' : 0, 'Krakow' : 0, \n                        'Oslo' : 1, 'Helsinki' : 1, 'Bratislava' : 1, \n                        'Luxembourg' : 1, 'Ljubljana' : 1}\ndf['capital'] = df.apply(lambda row: dict_\u0421ity_capital[row['City']], axis = 1)\n\nhypothyroidism(df, 'capital', 0.05)","b7ee47c9":"# add a new feature - the population of cities\n\ndict_\u0421ity_population= {'London' : 8908, 'Paris' : 2206, 'Madrid' : 3223, 'Barcelona' : 1620, \n                        'Berlin' : 6010, 'Milan' : 1366, 'Rome' : 2872, 'Prague' : 1308, \n                        'Lisbon' : 506, 'Vienna' : 1888, 'Amsterdam' : 860, 'Brussels' : 179, \n                        'Hamburg' : 1841, 'Munich' : 1457, 'Lyon' : 506, 'Stockholm' : 961, \n                        'Budapest' : 1752, 'Warsaw' : 1764, 'Dublin' : 553, \n                        'Copenhagen' : 616, 'Athens' : 665, 'Edinburgh' : 513, \n                        'Zurich' : 415, 'Oporto' : 240, 'Geneva' : 201, 'Krakow' : 769, \n                        'Oslo' : 681, 'Helsinki' : 643, 'Bratislava' : 426, \n                        'Luxembourg' : 119, 'Ljubljana' : 284}\ndf['\u0421ity_population'] = df.apply(lambda row: dict_\u0421ity_population[row['City']], axis = 1)","7a6fca3c":"# add a new feature - average per capita income before taxes\n\ndict_\u0421ity_income = {'London' : 2511, 'Paris' : 3617, 'Madrid' : 2651, 'Barcelona' : 2663, \n                        'Berlin' : 4521, 'Milan' : 3183, 'Rome' : 2843, 'Prague' : 1400, \n                        'Lisbon' : 1526, 'Vienna' : 2646, 'Amsterdam' : 4612, 'Brussels' : 3401, \n                        'Hamburg' : 5604, 'Munich' : 5181, 'Lyon' : 2400, 'Stockholm' : 2391, \n                        'Budapest' : 670, 'Warsaw' : 1259, 'Dublin' : 3000, \n                        'Copenhagen' : 5000, 'Athens' : 1100, 'Edinburgh' : 2050, \n                        'Zurich' : 6758, 'Oporto' : 1288, 'Geneva' : 2100, 'Krakow' : 1027, \n                        'Oslo' : 4048, 'Helsinki' : 3691, 'Bratislava' : 1176, \n                        'Luxembourg' : 5000, 'Ljubljana' : 1807}\ndf['\u0421ity_income'] = df.apply(lambda row: dict_\u0421ity_income[row['City']], axis = 1)","4ed84285":"# select a new feature country of location\n\ndict_\u0421ountries = {'London' : 'England', 'Paris' : 'France', 'Madrid' : 'Spain', \n                  'Barcelona' : 'Spain', 'Berlin' : 'Germany', 'Milan' : 'Italy', \n                  'Rome' : 'Italy', 'Prague' : 'Czech_c', 'Lisbon' : 'Portugal', \n                  'Vienna' : 'Austria', 'Amsterdam' : 'Holland', \n                  'Brussels' : 'Belgium', 'Hamburg' : 'Germany', 'Munich' : 'Germany', \n                  'Lyon' : 'France', 'Stockholm' : 'Sweden', 'Budapest' : 'Romania', \n                  'Warsaw' : 'Poland', 'Dublin' : 'Ireland', 'Copenhagen' : 'Denmark', \n                  'Athens' : 'Greece', 'Edinburgh' : 'Scotland', 'Zurich' : 'Switzerland', \n                  'Oporto' : 'Portugal', 'Geneva' : 'Switzerland', 'Krakow' : 'Poland', \n                  'Oslo' : 'Norway', 'Helsinki' : 'Finland', 'Bratislava' : 'Slovakia', \n                  'Luxembourg' : 'Luxembourg_c', 'Ljubljana' : 'Slovenia'}\ndf['\u0421ountry'] = df.apply(lambda row: dict_\u0421ountries[row['City']], axis = 1)\n\n# encode data by country\n\nle = LabelEncoder()\nle.fit(df['\u0421ountry'])\ndf['code_\u0421ountry'] = le.transform(df['\u0421ountry'])","d473a33c":"# there are more than 22% missing values in the order column\n# this feature can be a good feature for the model\n\ndf['NAN_Cuisine'] = pd.isna(df['Cuisine Style']).astype('int')","2cd5721d":"hypothyroidism(df, 'NAN_Cuisine', 0.05)","9d2dbdf4":"# let's preprocess the values\n\ndf['Cuisine Style'] = df['Cuisine Style'].fillna(\"['Other']\")\ndf['Cuisine Style'] = df['Cuisine Style'].str.findall(r\"'(\\b.*?\\b)'\") \n\n# create a new feature number of cuisine styles\n\ndf['quantity_Cuisine_Style'] = df.apply(lambda row: len(row['Cuisine Style']), axis = 1)","81fcd1c0":"diagram_bar(df[df['NAN_Cuisine'] != 1], 'quantity_Cuisine_Style')","485baa7c":"df.loc[(df['NAN_Cuisine'] == 1), 'quantity_Cuisine_Style'] = df.loc[(df['NAN_Cuisine'] != 1), 'quantity_Cuisine_Style'].median()","6de810dc":"diagram_bar(df, 'quantity_Cuisine_Style')","fd8d32f5":"df.Ranking.describe()","05acb4cf":"diagram_bar(df, 'Ranking')","7d29f6a2":"# a large amount of emissions. Let's look at the distribution up to 11000 and more\nfig = plt.figure()\nmain_axes = fig.add_axes([0,0,1,1])\ndf[df['Ranking'] < 11000]['City'].value_counts(ascending=True).plot(kind='barh')\ninsert_axes = fig.add_axes([1.1,0,1,1])\ndf[df['Ranking'] >= 11000]['City'].value_counts(ascending=True).plot(kind='barh')","7246f6a0":"# emissions are found in 2 cities London and Paris. Emissions can be related to the number of establishments in cities\nfor x in (df_train['City'].value_counts())[0:10].index:\n    df_train['Ranking'][df_train['City'] == x].hist(bins=100)\nplt.show()","e24767f2":"# Normalizing the Ranking feature\n\nRanking_City_mean = df.groupby(['City'])['Ranking'].mean()\nRestorant_City_count = df['City'].value_counts(ascending=False)\ndf['Ranking_City_mean'] = df['City'].apply(lambda x: Ranking_City_mean[x])\ndf['Restorant_City_count'] = df['City'].apply(lambda x: Restorant_City_count[x])\ndf['Ranking_Rest_City_norm'] = (df['Ranking'] - df['Ranking_City_mean']) \/ df['Restorant_City_count']","2a3de0cb":"for x in (df['City'].value_counts())[0:10].index:\n    df['Ranking_Rest_City_norm'][df['City'] == x].hist(bins=100)\nplt.show()","db172a8d":"# encode data from the Price Range column\n\ndict_Price = {'$':1,'$$ - $$$':2,'$$$$':3}\ndf['Price Range']=df['Price Range'].map(lambda x: dict_Price.get(x,x))","64057602":"# for data gaps, I suggest filling in the gaps mod\n\ndf['Price Range'] = df['Price Range'].fillna(2)","3cb51648":"df['Number of Reviews'].describe()","bb59b778":"diagram_bar(df, 'Number of Reviews')","c538f960":"for element in [0,1]:\n    diagram_bar(df[df['Sample'] == element], 'Number of Reviews')\n    print(df[df['Sample'] == element]['Number of Reviews'].describe())","c765353b":"# re-rhyme the column and see how the data distribution changes\n\ndf['LOG_Number_Reviews'] = df['Number of Reviews'].apply(lambda x: math.log1p(x))\ndf['LOG_Number_Reviews'].hist(bins=50)","eee98cf5":"for x in df['City'].value_counts().index[0:10]:\n    df['Number of Reviews'][df['City'] == x].hist(bins=20)\nplt.show()","a865b5dc":"for x in df['City'].value_counts().index[0:10]:\n    df['LOG_Number_Reviews'][df['City'] == x].hist(bins=100)\nplt.show()","a27b3d46":"# \u0441\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u043d\u043e\u0432\u044b\u0439 \u043f\u0440\u0438\u0437\u043d\u0430\u043a \n\ndf['NAN_Number_Reviews'] = pd.isna(df['Number of Reviews']).astype('float64')","9b3ff299":"df['Number of Reviews'] = df['Number of Reviews'].fillna(df['Number of Reviews'].median())\n\ndf['LOG_Number_Reviews'] = df['LOG_Number_Reviews'].fillna(df['LOG_Number_Reviews'].median())","02cfdea0":"# there are no gaps in the review, but more than 6000 lines with the value [[], []]. In fact, these are empty lines, let's save them\ndf['Reviews'] = df['Reviews'].fillna('[[], []]')\n\n# analysis of the test base revealed two gaps, despite the fact that pandas.profiling did not reveal any gaps on the training base, fill them in '[[], []]' and drop them into empty_Reviewsdf['Reviews'] = df['Reviews'].fillna('[[], []]')\ndf['empty_Reviews'] = (df['Reviews']=='[[], []]').astype('float64')","56fc6e35":"# pull the date out of the review and create new criteria\n\ndf['date_of_Review'] = df['Reviews'].str.findall('\\d+\/\\d+\/\\d+')","2844040f":"df['len_date'] = df['date_of_Review'].apply(lambda x: len(x))\n","5bad578a":"df[df['len_date']>2]","46b20b65":"df.loc[df['len_date']>2]['Reviews']","d392129f":"# that people indicated dates in reviews and these dates were processed. throw data from DF\n\nfor row in df.loc[df['len_date']>2].index:\n    date_list = df.loc[row]['date_of_Review']\n    del date_list[0]\n    df.loc[row]['date_of_Review'] = date_list","2f02c0cf":"df.loc[df['len_date'] == 1]","94082e29":"# turned out to be reviews with one (1) review and a lot of them 5680\n# so I suggest working with one (first date)\n# I suggest using the month and day of the week of the most recent review as signs\n\ndf['week_day'] = df['date_of_Review'].apply(lambda x: pd.to_datetime(x).max().weekday())\ndf['month'] = df['date_of_Review'].apply(lambda x: pd.to_datetime(x).max().month)\n","d0c19cd0":"diagram_bar(df, 'week_day')","df85fb12":"df['week_day'] = df['week_day'].fillna(df['week_day'].value_counts().index[0])","c520ecfd":"diagram_bar(df, 'week_day')","fa44f181":"# create dummy variables\n\nday_week = pd.get_dummies(df['week_day'])\nday_week.columns = ['mo', 'Tu', 'We', 'Th', 'Fr', 'Sa', 'Su']\ndf = pd.concat([df,day_week], axis=1)","2a0e62b0":"for column in day_week.columns:\n    print(column)\n    hypothyroidism(df, column, 0.05)","d4da678a":"diagram_bar(df, 'month')","7c4df2c3":"df['month'] = df['month'].fillna(df['month'].value_counts().index[0])","0e3d8eb0":"diagram_bar(df, 'month')","2e620e24":"# create dummy variables\n\nmonth = pd.get_dummies(df['month'])\nmonth.columns = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'June', 'July', 'Aug', 'Sept', 'Oct', 'Nov', 'Dec']\ndf = pd.concat([df,month], axis=1)","6b92e4fe":"for column in month.columns:\n    print(column)\n    hypothyroidism(df, column, 0.05)","2f98ccdb":"# introduce new signs the difference between dates, and the statute of limitations\n\ndef delta_data(data):\n    if data['date_of_Review'] == []:\n        return None\n    return pd.to_datetime(data['date_of_Review']).max() - pd.to_datetime(data['date_of_Review']).min()\n\ndef delta_data_now(data):\n    if data['date_of_Review'] == []:\n        return None\n    return datetime.datetime.now() - pd.to_datetime(data['date_of_Review']).max()\n\ndef delta_data_start(data):\n    if data['date_of_Review'] == []:\n        return None\n    return abs(pd.to_datetime(data['date_of_Review']).min() - pd.to_datetime('01\/01\/2000'))","87d8d818":"df['delta_data'] = df.apply(delta_data, axis = 1).dt.days\ndf['delta_data_now'] = df.apply(delta_data_now, axis = 1).dt.days\ndf['delta_data_start'] = df.apply(delta_data_start, axis = 1).dt.days\n","19aacf6c":"df['delta_data_start'] = df['delta_data_start'].fillna(0)\ndf['delta_data_now'] = df['delta_data_now'].fillna(0)","61f6aa43":"# create polynomial features based on columns\n\npf = PolynomialFeatures(2)\ndelta_data = pf.fit_transform(df[['delta_data_now', 'delta_data_start']])","e3c10f5c":"# create a new feature, column length Reviews\n\ndf['LEN_Reviews'] = df['Reviews'].apply(lambda x: len(x))","54fa19f7":"diagram_bar(df, 'LEN_Reviews')","8c2047f5":"for x in df['Restaurant_id'].value_counts().index[0:10]:\n    df['LEN_Reviews'][df['Restaurant_id'] == x].hist(bins=100)\nplt.show()","ebacee92":"df.drop(['Rome', 'Greece', 'Restaurant_id', 'City', 'Cuisine Style', 'Price Range', 'Reviews', 'URL_TA', 'ID_TA', 'date_of_Review', '\u0421ountry', '\u0421ity_population', 'mean_Ranking_on_City', 'count_Restorant_in_City', 'max_Ranking_on_City'], axis=1, inplace=True, errors='ignore')\ndf_model = df","5332ac06":"display(df_model.describe())","149f244f":"#standardize two columns \n\ndef StandardScaler_column(d_col):\n    scaler = StandardScaler()\n    scaler.fit(df_model[[d_col]])\n    return scaler.transform(df_model[[d_col]])\n\nfor column in df_model.columns:\n    if column not in ['Rating','Sample']:\n        df_model[column] = StandardScaler_column(column)\n        if len(df_model[df_model[column].isna()]) < len(df_model):\n            df_model[column] = df_model[column].fillna(0)\n    \n","3b1cc5d0":"train_data = df_model.query('Sample == 1').drop(['Sample'], axis=1)\ntest_data = df_model.query('Sample == 0').drop(['Sample'], axis=1)","e2197b13":"# Checking the model on the training set\n\ny = train_data.Rating.values            \nX = train_data.drop(['Rating'], axis=1)\n\n# Let's use the special function train_test_split to split test data\n# allocate 20% of the data for validation (parameter test_size)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","30fd475b":"# check\n\ntest_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape","84de8390":"# building the model\n\nmodel = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)","024e1be1":"# Train the model on a test dataset\n\nmodel.fit(X_train, y_train)\n\n# We use a trained model to predict restaurant ratings in a test sample.\n# The predicted values are written to the y_pred variable\n\ny_pred = model.predict(X_test)","c4b5f1c8":"# standard mathematical rounding function\ndef classic_round(d_num):\n    return int(d_num + (0.5 if d_num > 0 else -0.5))\n\n# rounding function is a multiple of 0.5\ndef my_round(d_pred):\n    result = classic_round(d_pred*2)\/2\n    if result <=5:\n        return result\n    else:\n        return 5\n    \n# round off forecast values\nmy_vec_round = np.vectorize(my_round)","cbaf19e2":"y_pred = my_vec_round(y_pred)","0a687863":"# Compare the predicted values (y_pred) with the real ones (y_test), and see how much they differ on average\n# The metric is called the Mean Absolute Error (MAE) and shows the average deviation of the predicted values from the actual ones.\n\nMAE = metrics.mean_absolute_error(y_test, y_pred)\nprint('MAE:', MAE)","a787bf16":"# in RandomForestRegressor it is possible to display the most important features for the model\n\nplt.rcParams['figure.figsize'] = (12,10)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(15).plot(kind='barh')","66524898":"# Checking the correlation of important variables\n\ndf_temp = df_model.loc[df_model['Sample'] == 1, list(feat_importances.nlargest(15).index[0:15])]\nplt.rcParams['figure.figsize'] = (12,6)\nax = sns.heatmap(df_temp.corr(), annot=True, fmt='.2g')\ni, k = ax.get_ylim()\nax.set_ylim(i+0.5, k-0.5)","5f6762f4":"df_model.drop(['Ranking_City_mean'], axis=1, inplace=True, errors='ignore')","289a80ca":"train_data = df.query('Sample == 1').drop(['Sample'], axis=1)\ntest_data = df.query('Sample == 0').drop(['Sample','Rating'], axis=1)","d0161e1c":"y = train_data.Rating.values    \nX = train_data.drop(['Rating'], axis=1)","151fbab3":"model = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)","da41b8f1":"model.fit(X, y)","9fba39ab":"predict_submission = model.predict(test_data)","9a16779a":"predict_submission = my_vec_round(predict_submission)#","501a29cb":"sample_submission['Rating'] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","76c84b39":"**\u0428\u0430\u0433 5.** \u041e\u0442\u0431\u0435\u0440\u0435\u043c \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u044b\u0435 \u0444\u0430\u043a\u0442\u043e\u0440\u044b \u0432 \u043c\u043e\u0434\u0435\u043b\u044c.","4fdfcfa9":"**\u0412\u044b\u0432\u043e\u0434** \n\n\u0421\u0440\u0435\u0434\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u043e \u0440\u0435\u0439\u0442\u0438\u043d\u0433\u0435 \u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0443\u044e\u0442 \u0432\u044b\u0431\u0440\u043e\u0441\u044b \u043f\u043e \u043d\u0438\u0436\u043d\u0435\u0439 \u0433\u0440\u0430\u043d\u0438\u0446\u0435. \u0414\u0430\u043d\u043d\u044b\u0435 \u043e\u0442 \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432 \u043e\u0447\u0438\u0449\u0430\u0442\u044c \u043d\u0435 \u0431\u0443\u0434\u0435\u043c \u0442.\u043a. \u0442\u0435\u0440\u044f\u044e\u0442\u0441\u044f \u0443\u043d\u0438\u043a\u0430\u043b\u044c\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f.","7bb0085f":"Reviews","577d5afc":"**\u0412\u044b\u0432\u043e\u0434**\n\n\u041f\u043e\u0441\u043b\u0435 \u0430\u043d\u0430\u043b\u0438\u0437\u0430 \u0438 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d \u043d\u043e\u0432\u044b\u0439 \u043f\u0440\u0438\u0437\u043d\u0430\u043a: \u043e\u0442\u043d\u043e\u0441\u0438\u0442\u0441\u044f \u043b\u0438 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d \u043a \u0441\u0435\u0442\u0438 \u0438\u043b\u0438 \u043d\u0435\u0442. \u0412 \u043d\u043e\u0432\u043e\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0435 \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432 \u043d\u0435\u0442.","038754b8":"**\u0413\u0435\u043d\u0435\u0440\u0438\u0440\u0443\u0435\u043c \u043d\u043e\u0432\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438. **\n\n\u0421\u0442\u043e\u043b\u0438\u0446\u0430 \u0438\u043b\u0438 \u043d\u0435 \u0441\u0442\u043e\u043b\u0438\u0446\u0430","5fcca8d3":"**\u0412\u044b\u0432\u043e\u0434**\n\n \u0414\u043b\u044f \u0441\u043e\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u0438\u044f \u0431\u043e\u043b\u0435\u0435 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u0430, \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0435\u043c \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u0442\u044c \u0440\u0435\u0439\u0442\u0438\u043d\u0433 \u0438\u0441\u0445\u043e\u0434\u044f \u0438\u0437 \u0442\u0440\u0435\u0445 \u043d\u043e\u0432\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432: \n   1. \u0421\u0442\u043e\u043b\u0438\u0446\u0430 \/ \u043e\u0431\u044b\u0447\u043d\u044b\u0439 \u0433\u043e\u0440\u043e\u0434\n   2. \u0420\u0430\u0437\u043c\u0435\u0440 \u043d\u0430\u0441\u0435\u043b\u0435\u043d\u0438\u044f \u043d\u0430\u0441\u0435\u043b\u0435\u043d\u0438\u044f\n   3. \u0421\u0440\u0435\u0434\u043d\u0438\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0434\u043e\u0445\u043e\u0434\u0430 .\n   4. \u0421\u0442\u0440\u0430\u043d\u0430 \u043d\u0430\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u044f \u0433\u043e\u0440\u043e\u0434\u0430","30ba330d":"\u041e\u0441\u0443\u0449\u0435\u0441\u0442\u0432\u0438\u043c \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0443 \u0434\u0430\u043d\u043d\u044b\u0445\n------","fabd6ce4":"**\u0428\u0430\u0433 4.** \u0410\u043d\u0430\u043b\u0438\u0437 DF \u043f\u043e \u0441\u0442\u043e\u043b\u0431\u0446\u0430\u043c","fd7e0613":"Country","c23b812a":"\u041f\u0440\u0435\u0434\u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445\n------","e8b779da":"**\u0412\u044b\u0432\u043e\u0434**\n\n\u0421\u0442\u0440\u0430\u043d\u043d\u044b\u0439 \u0432\u0438\u0434 \u043f\u0440\u043e\u043b\u043e\u0433\u0430\u0440\u0438\u0444\u043c\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u043e\u0433\u043e \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f, \u043a\u0430\u043a \u0431\u0443\u0434\u0442\u043e \u0432 \u043d\u0435\u043c \u0434\u0432\u0430 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u043f\u0440\u0438\u0447\u0435\u043c \u043e\u0434\u043d\u043e \u043b\u043e\u0433\u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u043e\u0435, \u0430 \u0434\u0440\u0443\u0433\u043e\u0435 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0411\u0435\u0440\u043d\u0443\u043b\u0438","b4e2fba7":"**\u0412\u044b\u0432\u043e\u0434**\n\n\u0414\u0430\u043d\u043d\u044b\u0439 \u043f\u0440\u0438\u0437\u043d\u0430\u043a \u043c\u043e\u0436\u043d\u043e \u0432\u043a\u043b\u044e\u0447\u0438\u0442\u044c \u0432 \u043c\u043e\u0434\u0435\u043b\u044c","916634bf":"**\u0428\u0430\u0433 6.** \u0420\u0430\u0437\u0431\u0438\u0432\u0430\u0435\u043c df_model \u043d\u0430 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0439 \u0438 \u043f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u043c \u0442\u0440\u0435\u043d\u0438\u0440\u043e\u0432\u043e\u0447\u043d\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0443","a733d06c":"**City**\n\n\u041f\u0440\u043e\u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0441\u0442\u043e\u043b\u0431\u0446\u0430","546aa6a2":"Ranking","5e758422":"Number of Reviews ","c25ef967":"Price Range","34d6e5b3":"\u0412\u044b\u0432\u043e\u0434\n------\n\n   1. \u0421\u0442\u043e\u0438\u0442 \u043e\u0431\u0440\u0430\u0442\u0438\u0442\u044c \u043d\u0430 \u0431\u043e\u043b\u044c\u0448\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432 \u0432 \u0441\u0442\u043e\u043b\u0431\u0446\u0430\u0445 Cuisine Style, Price Range.\n   2. \u0421\u043b\u043e\u0436\u043d\u043e\u0435 \u0437\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 \u0441\u0442\u043e\u043b\u0431\u0446\u0435 Reviews \u0442\u0430\u043c \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0442\u0441\u044f \u0441\u0442\u0440\u043e\u043a\u043e\u0432\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u0438 \u0434\u0430\u0442\u044b.","9f1da9f0":"**\u0412\u044b\u0432\u043e\u0434**\n\n\u0411\u043e\u043b\u044c\u0448\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043f\u043e\u0434\u043f\u0430\u0434\u0430\u0435\u0442 \u043f\u043e\u0434 \u0432\u044b\u0431\u0440\u043e\u0441\u044b \u043f\u0440\u0435\u0434\u043b\u0430\u0433\u0430\u044e \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0434\u0435\u043b\u0430\u0442\u044c \u0441 \u0434\u0430\u043d\u043d\u044b\u043c\u0438","b54b7a54":"**\u0412\u044b\u0432\u043e\u0434**\n\n\u0414\u0443\u0431\u043b\u0438\u043a\u0430\u0442\u044b \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0442 \u043a\u0430\u043a \u0432 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0442\u0430\u043a \u0438 \u0432 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435","50164019":"**\u0418\u0442\u043e\u0433\u043e\u0432\u043e\u0435 \u0437\u0430\u0434\u0430\u043d\u0438\u0435** \n\n\u0428\u0438\u0448\u043b\u043e \u0421\u0435\u0440\u0433\u0435\u044f \u043f\u043e \u043f\u0440\u043e\u0435\u043a\u0442\u0443 3 \"\u041e \u0432\u043a\u0443\u0441\u043d\u043e\u0439 \u0438 \u0437\u0434\u043e\u0440\u043e\u0432\u043e\u0439 \u043f\u0438\u0449\u0435\" (DST-20).\n\n\u042e\u043d\u0438\u0442 3. \u0412\u0432\u0435\u0434\u0435\u043d\u0438\u0435 \u0432 \u043c\u0430\u0448\u0438\u043d\u043d\u043e\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 (\u043f\u043e\u0441\u043b\u0435\u0434\u043d\u044f\u044f \u0440\u0435\u0434\u0430\u043a\u0446\u0438\u044f 26.09.2020)","79c6b710":"**\u0412\u044b\u0432\u043e\u0434**\n\n\u041f\u0440\u043e\u0442\u0435\u0441\u0442\u0438\u0440\u0443\u0435\u043c \u0440\u0430\u0437\u043d\u044b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435 \u0432 \u043c\u043e\u0434\u0435\u043b\u0435 ","967af8ab":"**\u0412\u044b\u0432\u043e\u0434**\n\n\u0421\u0442\u043e\u0438\u0442 \u043e\u0431\u0440\u0430\u0442\u0438\u0442\u044c \u0432\u043d\u0438\u043c\u0430\u043d\u0438\u0435, \u0447\u0442\u043e \u0434\u0430\u043d\u043d\u044b\u0439 \u0441\u0442\u043e\u043b\u0431\u0438\u043a \u0445\u0430\u0440\u0430\u043a\u0442\u0435\u0440\u0435\u0437\u0443\u0435\u0442 \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0439 \u043d\u043e\u043c\u0435\u0440 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u0430 \/ \u0441\u0435\u0442\u0438 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u043e\u0432. \u0418\u0437 \u0434\u0430\u043d\u043d\u043e\u0433\u043e \u0441\u0442\u043e\u043b\u0431\u0446\u0430 \u0441\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u0443\u0435\u043c \u043d\u043e\u0432\u044b\u0439 \u043f\u0440\u0438\u0437\u043d\u0430\u043a \u0441\u0435\u0442\u044c \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u043e\u0431\u0449\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0433\u043e \u043f\u0438\u0442\u0430\u043d\u0438\u044f(1) \u0438\u043b\u0438 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u044b\u0439 \u0440\u0435\u0441\u0442\u0430\u0440\u0430\u043d(0). ","11ffd158":"**\u0412\u044b\u0432\u043e\u0434**\n\n\u041f\u0440\u043e\u0442\u0435\u0441\u0442\u0438\u0440\u0443\u0435\u043c \u0440\u0430\u0437\u043d\u044b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435 \u0432 \u043c\u043e\u0434\u0435\u043b\u0435 ","3d19e28d":"**\u0412\u044b\u0432\u043e\u0434**\n\n\u0424\u0430\u043a\u0442\u043e\u0440 \u0441\u0442\u043e\u043b\u0438\u0446\u0430\/\u043d\u0435 \u0441\u0442\u043e\u043b\u0438\u0446\u0430 \u043c\u044b \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0432 \u0431\u0443\u0434\u0443\u0449\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c","10ece279":"\u041f\u0440\u0438 \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0438 \u0441\u043e\u043e\u0442\u0432\u0435\u0441\u0442\u0432\u0438\u044f \u0441\u0440\u0435\u0434\u043d\u0435\u0433\u043e \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0440\u0435\u0439\u0442\u0438\u043d\u0433\u0430 \u0440\u0435\u0441\u0442\u043e\u0440\u0430\u043d\u0430\n   - H0 - \u0441\u0440\u0435\u0434\u043d\u0438\u0439 \u0440\u0435\u0439\u0442\u0438\u043d\u0433 \u0441\u0435\u0442\u0435\u0432\u044b\u0445 \u0438 \u043d\u0435\u0441\u0435\u0442\u0435\u0432\u044b\u0445 \u0437\u0430\u0432\u0435\u0434\u0435\u043d\u0438\u0439 \u043e\u0434\u0438\u043d\u0430\u043a\u043e\u0432\u044b\u0439\n   - \u041d1 - \u0441\u0440\u0435\u0434\u043d\u0438\u0439 \u0440\u0435\u0439\u0442\u0438\u043d\u0433 \u0441\u0435\u0442\u0435\u0432\u044b\u0445 \u0438 \u043d\u0435\u0441\u0435\u0442\u0435\u0432\u044b\u0445 \u0437\u0430\u0432\u0435\u0434\u0435\u043d\u0438\u0439 \u043d\u0435 \u0440\u0430\u0432\u0435\u043d\n   - \u041f\u043e\u0440\u043e\u0433\u043e\u0432\u043e\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 alpha 5%","9afebe5b":"**Restaurant_id**\n\n\u041f\u0440\u043e\u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u0441\u0442\u043e\u043b\u0431\u0446\u0430","a0689450":"**\u0412\u044b\u0432\u043e\u0434**\n\n\u0414\u043e\u0431\u043e\u0432\u043b\u044f\u0435\u043c \u043d\u043e\u0432\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u0432 \u0441\u0438\u0441\u0442\u0435\u043c\u0443","000fb7d5":"**\u0412\u044b\u0432\u043e\u0434**\n\n\u041f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0443\u044e quantity_Cuisine_Style \u0434\u043e\u0431\u043e\u0432\u043b\u044f\u0435\u043c \u0432 \u043c\u043e\u0434\u0435\u043b\u044c","023363ea":"**\u0428\u0430\u0433 1. \u041f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u043d\u0430 \u0434\u0443\u0431\u043b\u0438\u043a\u0430\u0442\u044b**\n\n\u0414\u043b\u044f \u0430\u043d\u0430\u043b\u0438\u0437\u0430 \u0431\u0443\u0434\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0434\u0430\u043d\u043d\u044b\u0435 \u0431\u0435\u0437 \u0443\u0447\u0435\u0442\u0430 \u043e\u0442\u0437\u044b\u0432\u043e\u0432","dbf26c00":"\u0421\u0440\u0435\u0434\u043d\u0438\u0439 \u0440\u0430\u0437\u043c\u0435\u0440 \u0434\u043e\u0445\u043e\u0434\u0430","97a4a1cf":"**\u0428\u0430\u0433 3.** \u0421\u043e\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u0435 \u0434\u0432\u0443\u0445 DF: \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0433\u043e \u0438 \u0442\u0440\u0435\u043d\u0435\u0440\u043e\u0432\u043e\u0447\u043d\u043e\u0433\u043e","2473c805":"**\u0428\u0430\u0433 2.** \u041f\u0440\u043e\u0430\u043d\u0430\u043b\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0446\u0435\u043b\u0435\u0432\u043e\u0439 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u043e\u0439 \u043d\u0430 \u0442\u0435\u0441\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435","c8426081":"\u041f\u0440\u043e\u0432\u0435\u0440\u0438\u043c \u043d\u0430 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0443\u044e \u0437\u043d\u0430\u0447\u0438\u043c\u043e\u0441\u0442\u044c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043d\u043e\u0432\u043e\u0433\u043e \u043a\u0440\u0438\u0442\u0435\u0440\u0438\u044f","896c53cf":"**Cuisine Style\t**"}}