{"cell_type":{"52a15e1b":"code","6e3cddbc":"code","528ff0fc":"code","a6678e3b":"code","6ba0540a":"code","734a7e68":"code","4cd17609":"code","efc27bec":"code","d5af8302":"code","87571438":"code","b257774c":"code","df820c85":"code","30b672d1":"code","3581d458":"code","6023168a":"code","42e8fa25":"code","621a13d1":"code","767e5d02":"code","0934ece8":"code","d4d93dd3":"code","c73e7696":"code","9ef406da":"code","c48e935b":"code","5440e4fc":"code","7588ee37":"code","688c2395":"code","92b681f0":"code","e4b85599":"code","133f0ffa":"code","2b0f6513":"code","d28145c3":"code","b6888832":"code","2ae4a1cf":"code","1318bc24":"code","7f32dd2a":"code","7620a226":"code","17b19e36":"code","c143f007":"code","ae1f8f67":"code","8f063273":"code","73343308":"code","691e5627":"code","03da55cd":"code","9e960099":"code","ce49e724":"code","acc16b94":"code","5f501ae2":"code","1803d00b":"code","627e7272":"code","1daf07a2":"code","d68f593d":"code","eee8d079":"code","94d60162":"code","0e124e23":"code","0bd6276f":"code","5601a37b":"code","8f22f5ef":"code","b1d4377f":"code","49b274f4":"code","e65eea3b":"code","10371ac5":"code","41dd1eb3":"code","41dfafb7":"code","2b85962c":"code","58975baf":"code","bc32e7a5":"code","59b0968b":"code","65c643a6":"code","045d9602":"code","6467aa44":"code","8a971fdd":"code","8921acc2":"code","7fcd4d78":"code","c78c7817":"code","e495dd3e":"code","e70f2ce7":"code","276d20b8":"markdown","b407acf6":"markdown","218ca297":"markdown","3619543a":"markdown","311d5fcd":"markdown","4487b6ad":"markdown","1a66c007":"markdown","5f54cbcc":"markdown","9b5d6946":"markdown","f9f85504":"markdown","50b494bf":"markdown","e33d50c4":"markdown","87018fc2":"markdown","24e77b86":"markdown","1f629b3f":"markdown","9c5ff1b1":"markdown","3834aa2d":"markdown","ebd8a113":"markdown","d8b80c25":"markdown","c94adcc1":"markdown","5ce93a2d":"markdown","ec754d40":"markdown"},"source":{"52a15e1b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6e3cddbc":"from sklearn import preprocessing\nimport matplotlib.pyplot as plt \nplt.rc(\"font\", size=14)\nimport seaborn as sns\nsns.set(style=\"white\") #white background style for seaborn plots\nsns.set(style=\"whitegrid\", color_codes=True)\n\nimport warnings\nwarnings.simplefilter(action='ignore')","528ff0fc":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntrain.head()","a6678e3b":"test = pd.read_csv('..\/input\/titanic\/test.csv')\ntest.head()","6ba0540a":"submission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission.head()","734a7e68":"print('The number of samples into the train data is {}.'.format(train.shape[0]))\nprint('The number of samples into the test data is {}.'.format(test.shape[0]))\n","4cd17609":"test.info()","efc27bec":"train.info()","d5af8302":"train.isnull().sum()","87571438":"train.dropna(subset = [\"Embarked\"], inplace =True)\ntrain=train.reset_index(drop=True)","b257774c":"type(train)","df820c85":"train.info()","30b672d1":"ax = train[\"Age\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\ntrain[\"Age\"].plot(kind='density', color='teal')\nax.set(xlabel='Age')\nplt.xlim(-10,85)\nplt.show()","3581d458":"train['Age'].unique()","6023168a":"train['is_Age_available'] = np.where(train['Age'].isnull(),'No','Yes')","42e8fa25":"train[train['is_Age_available']=='No']","621a13d1":"sns.countplot( x='Survived', hue='is_Age_available',data=train)","767e5d02":"sns.countplot( x='Pclass', hue='is_Age_available',data=train)","0934ece8":"sns.countplot( x='Sex', hue='is_Age_available',data=train)","d4d93dd3":"sns.countplot( x='SibSp', hue='is_Age_available',data=train)","c73e7696":"sns.countplot( x='Parch', hue='is_Age_available',data=train)","9ef406da":"sns.countplot( x='Embarked', hue='is_Age_available',data=train)","c48e935b":"# mean age\nprint('The mean of \"Age\" is %.2f' %(train[\"Age\"].mean(skipna=True)))\n# median age\nprint('The median of \"Age\" is %.2f' %(train[\"Age\"].median(skipna=True)))","5440e4fc":"train[\"Age\"].fillna(train[\"Age\"].median(skipna=True), inplace=True)\ntest[\"Age\"].fillna(train[\"Age\"].median(skipna=True), inplace=True) # simultaenously filling the data in test (validation) dataset as well\ntest[\"Fare\"].fillna(train[\"Fare\"].median(skipna=True), inplace=True) # test (validation dataset) has NULL values in Fare which is also replaced by Median (only one value)\n","7588ee37":"train.info()","688c2395":"train.Cabin.unique()","92b681f0":"train.drop('is_Age_available', axis=1, inplace=True)","e4b85599":"train['Cabin_class'] = np.where(train['Cabin'].isnull(),'Not Given',train['Cabin'].astype(str).str[0])","133f0ffa":"train['Cabin_class'].unique()","2b0f6513":"sns.countplot( x='Survived', hue='Cabin_class',data=train)","d28145c3":"sns.countplot( hue='Survived', x='Cabin_class',data=train)","b6888832":"sns.countplot( hue='Pclass', x='Cabin_class',data=train)","2ae4a1cf":"sns.countplot( hue='Sex', x='Cabin_class',data=train)","1318bc24":"sns.countplot( hue='SibSp', x='Cabin_class',data=train)","7f32dd2a":"sns.countplot( hue='Parch', x='Cabin_class',data=train)","7620a226":"sns.countplot( hue='Embarked', x='Cabin_class',data=train)","17b19e36":"train.drop(columns=['Cabin','Cabin_class'], axis=1, inplace=True)","c143f007":"train.head()","ae1f8f67":"train.drop(columns=['PassengerId','Name','Ticket'], axis=1, inplace=True)","8f063273":"train.head()","73343308":"sorted(train.Parch.unique())","691e5627":"sorted(train.SibSp.unique())","03da55cd":"## Create categorical variable for traveling alone\ntrain['TravelAlone']=np.where((train[\"SibSp\"]+train[\"Parch\"])>0, 0, 1)\ntrain.drop('SibSp', axis=1, inplace=True)\ntrain.drop('Parch', axis=1, inplace=True)","9e960099":"train.head()","ce49e724":"# Dummy variable\ncategorical_columns = ['Sex','Pclass','Embarked']\ntrain = pd.get_dummies(data = train,\n               columns = categorical_columns,\n                           drop_first = True\n               )\ntrain.info()","acc16b94":"train.head()","5f501ae2":"test.head()","1803d00b":"test.drop(columns=['PassengerId','Name','Ticket'], axis=1, inplace=True)\n\n## Create categorical variable for traveling alone\ntest['TravelAlone']=np.where((test[\"SibSp\"]+test[\"Parch\"])>0, 0, 1)\ntest.drop('SibSp', axis=1, inplace=True)\ntest.drop('Parch', axis=1, inplace=True)\n\n# Dummy variable\ncategorical_columns = ['Sex','Pclass','Embarked']\ntest = pd.get_dummies(data = test,\n               columns = categorical_columns,\n                           drop_first = True\n               )\ntest.head()","627e7272":"test.drop(columns=['Cabin'], axis=1, inplace=True)\ntest.head()","1daf07a2":"from sklearn import preprocessing\nscaler = preprocessing.MinMaxScaler()\nscaler.fit(train[['Age','Fare']])\ntrain[['Age','Fare']]=scaler.transform(train[['Age','Fare']])\ntest[['Age','Fare']]=scaler.transform(test[['Age','Fare']])","d68f593d":"train.head()","eee8d079":"test.head()","94d60162":"plt.figure(figsize=(15,8))\nax = sns.kdeplot(train[\"Age\"][train.Survived == 1], color=\"darkturquoise\", shade=True,cut=True)\nsns.kdeplot(train[\"Age\"][train.Survived == 0], color=\"lightcoral\", shade=True,cut=True)\nplt.legend(['Survived', 'Died'])\nplt.title('Density Plot of Age for Surviving Population and Deceased Population')\nax.set(xlabel='Age')\nplt.xlim(-0.5,1)\nplt.show()","0e124e23":"from matplotlib.ticker import FormatStrFormatter\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(20,8))\navg_survival_byage = train[[\"Age\", \"Survived\"]].groupby(['Age'], as_index=False).mean()\nax = sns.barplot(x='Age', y='Survived', data=avg_survival_byage, color=\"LightSeaGreen\")\n\n#ax.xaxis.set_major_formatter(FormatStrFormatter('%0.2f'))\n# ax.xaxis.set_ticks(np.arange(0, 1, 0.1))\n# ax.xaxis.set_major_locator(plt.MaxNLocator(11))\n\nplt.xticks(rotation=90)\nplt.show()\n","0bd6276f":"plt.figure(figsize=(15,8))\nax = sns.kdeplot(train[\"Fare\"][train.Survived == 1], color=\"darkturquoise\", shade=True, cut=True)\nsns.kdeplot(train[\"Fare\"][train.Survived == 0], color=\"lightcoral\", shade=True, cut=True)\nplt.legend(['Survived', 'Died'])\nplt.title('Density Plot of Fare for Surviving Population and Deceased Population')\nax.set(xlabel='Fare')\nplt.xlim(-0.25,1)\nplt.show()","5601a37b":"train['Is_Minor_or_Old']=np.where((train['Age']<=0.19) | (train['Age']>=0.78)  , 1, 0)\ntest['Is_Minor_or_Old']=np.where((test['Age']<=0.19) | (test['Age']>=0.78)  , 1, 0)","8f22f5ef":"X=train.drop('Survived', axis=1)\ny=train['Survived']","b1d4377f":"y.head()","49b274f4":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\nsize = np.arange(0.5,0.95,0.05)\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n","e65eea3b":"train_acc = []\ntest_acc = []\nfor i in size:\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = i, random_state = 42)\n    rfc = RandomForestClassifier(n_estimators=100, random_state=0)\n    rfc.fit(X_train, y_train)\n    y_pred_test = rfc.predict(X_test)\n    y_pred_train = rfc.predict(X_train)\n    train_acc.append(accuracy_score(y_train,y_pred_train))\n    test_acc.append(accuracy_score(y_test,y_pred_test))","10371ac5":"plt.plot(size,train_acc,label='Training Accuracy')\nplt.plot(size,test_acc,label='Testing Accuracy')\nplt.ylim([0.5,1.2])\nplt.xlabel('Train Size Ratio')\nplt.ylabel('Accuracy')\nplt.legend()\n","41dd1eb3":"randomnes = np.arange(1,101,1)\ntrain_acc = []\ntest_acc = []\nfor i in randomnes:\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, random_state = i)\n    rfc = RandomForestClassifier(n_estimators=100, random_state=i)\n    rfc.fit(X_train, y_train)\n    y_pred_test = rfc.predict(X_test)\n    y_pred_train = rfc.predict(X_train)\n    train_acc.append(accuracy_score(y_train,y_pred_train))\n    test_acc.append(accuracy_score(y_test,y_pred_test))","41dfafb7":"plt.plot(randomnes,train_acc,label='Training Accuracy')\nplt.plot(randomnes,test_acc,label='Testing Accuracy')\nplt.ylim([0.5,1.2])\nplt.xlabel('Randomness Seed')\nplt.ylabel('Accuracy')\nplt.legend()\n","2b85962c":"estimators = np.arange(5,101,5)\ntrain_acc = []\ntest_acc = []\nfor i in estimators:\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, random_state = 68)\n    rfc = RandomForestClassifier(n_estimators=i, random_state=68)\n    rfc.fit(X_train, y_train)\n    y_pred_test = rfc.predict(X_test)\n    y_pred_train = rfc.predict(X_train)\n    train_acc.append(accuracy_score(y_train,y_pred_train))\n    test_acc.append(accuracy_score(y_test,y_pred_test))","58975baf":"plt.plot(estimators,train_acc,label='Training Accuracy')\nplt.plot(estimators,test_acc,label='Testing Accuracy')\nplt.ylim([0.5,1.2])\nplt.xlabel('Estimators')\nplt.ylabel('Accuracy')\nplt.legend()\n","bc32e7a5":"depth = np.arange(3,11,1)\ntrain_acc = []\ntest_acc = []\nfor i in depth:\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, random_state = 68)\n    rfc = RandomForestClassifier(n_estimators=20, random_state=68, max_depth = i)\n    rfc.fit(X_train, y_train)\n    y_pred_test = rfc.predict(X_test)\n    y_pred_train = rfc.predict(X_train)\n    train_acc.append(accuracy_score(y_train,y_pred_train))\n    test_acc.append(accuracy_score(y_test,y_pred_test))","59b0968b":"plt.plot(depth,train_acc,label='Training Accuracy')\nplt.plot(depth,test_acc,label='Testing Accuracy')\nplt.ylim([0.5,1.2])\nplt.xlabel('Max Depth')\nplt.ylabel('Accuracy')\nplt.legend()\n","65c643a6":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.75, random_state = 68)\nrfc = RandomForestClassifier(n_estimators=100, random_state=68, max_depth = 3)\nrfc.fit(X_train, y_train)\ny_pred_test = rfc.predict(X_test)\ny_pred_train = rfc.predict(X_train)\nprint('The training accuracy of the model is {}'.format(accuracy_score(y_train,y_pred_train)))\nprint('The testing accuracy of the model is {}'.format(accuracy_score(y_test,y_pred_test)))","045d9602":"from sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, y_pred_test)\n\nprint(cm)\nplt.figure(figsize=(10,7))\ncategories = np.unique(y_pred_test)\ndf_cm = pd.DataFrame(cm, index = [i for i in categories], columns = [i for i in categories])\nsns.heatmap(df_cm,annot=True,cmap='Reds')\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()","6467aa44":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test, y_pred_test))","8a971fdd":"from sklearn.metrics import roc_curve\ny_true = y_test\ny_probas = y_pred_test\n\nfpr, tpr, threshold = roc_curve(y_true,y_probas)\n\nplt.plot(fpr,tpr,'r',label = 'RandomForest')\nplt.plot([0,1],[0,1],'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\nplt.show()\n\nauc = np.trapz(tpr,fpr)\n\nprint('The AUC: {:0.3f}% using Random Forest Classifier.'.format(auc*100))","8921acc2":"from sklearn.metrics import roc_auc_score\nr_a_score = roc_auc_score(y_true,y_probas)\nprint(\"ROC-AUC-Score:\", r_a_score)","7fcd4d78":"valid_set = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nvalid_set.head()","c78c7817":"\ny_pred_valid = rfc.predict(test)\n\n\n\nvalid_set_result = valid_set['Survived']\n\nprint('The accuracy of the model on validation set is {}'.format(accuracy_score(valid_set_result,y_pred_valid)))","e495dd3e":"new = pd.read_csv('..\/input\/titanic\/test.csv')\n","e70f2ce7":"submission = pd.DataFrame({\n        \"PassengerId\": new[\"PassengerId\"],\n        \"Survived\": y_pred_valid\n    })\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","276d20b8":"We have two categorical columns Sex and Embarked.  One Ordinal column Pclass. So we will replace this with One Hot Code Vector. We will drop one column to avoid the dummy trap. ","b407acf6":"From our analysis above, we found that most of the people were travelling alone rather than with sibling\/spouse\/parent\/child.\nSo we will replace these columns with 'Travel Alone' ","218ca297":"Now the data is in the required form for all the datasets i.e., train and test sets (with all the required transformations). As here test data is given without the \"Survived\" column. We need the test data set to validate our model so we classify our train set into two parts train and test for initial validataion and the real test set provided will be used only once the model with all the corrections and improvement is implemented. \n","3619543a":"Lets deep dive into other parameters such as max_depth and min_samples_split","311d5fcd":"Importing all the required libraries. ","4487b6ad":"Before we dig in further. We will drop PassengerId as it is not helpful to us as it is just used as identifier. Name and Ticket Column are also dropped.","1a66c007":"There seems to be NULL values in Age, Cabin and Embark Features. Let us look at the counts of NULL in each of these features.  ","5f54cbcc":"Rather looking at the data with each Cabin lets look at the Cabin class which is denoted by the letter prefixed to it.","9b5d6946":"Looking at all the relations with other categorical features where age is not available, We could not find the reason for missing data in Age. Looking from the distribution of Age and the data being positively skewed we fill the data with the Median Value rather than the Mean Value.","f9f85504":"Finally we move ahead with max_depth = 3 & n_estimators = 100 (max_depth implies the maximum level each tree can go and n_estimators implies number of decision trees in the Random forest. ","50b494bf":"More than 50% of the cabin values are NULL. Moreover, from our EDA we are not able to find any conclusions regarding the missing values.  For our analysis we will be dropping the cabin column.\n","e33d50c4":"Before we dig in further, let us remove the NULL records from Embarked feature by dropping the records.","87018fc2":"Now lets validate our model with the actual test set (which I used as validation set).","24e77b86":"We need to scale the values of Age and Fare between (0,1) to avoid delay in convergence.","1f629b3f":"As it is evident from the above scenario, in many of our earlier cases training accuracy was much higher than the test accuracy implying that the model is overfitting. But by using max_depth hyper parameter 7 & below we see one of the rare phenomenons where testing accuracy is higher than the training accuracy. So for our modeling we will keep our max depth = 3. We can repeat the above experiments with max_depth = 3 and refine the other parameters such as train_size or n_estimators. \n","9c5ff1b1":"Lets look at the test dataset it has same columns as the train dataset except the Survival (label) column. Remember this dataset will be used as part of the validation dataset at the end of the development of prediction model. For sake of testing our model during our experimentation we will split the train data into test and train dataset. ","3834aa2d":"lets fill the 'Age' NULL values with 28.00","ebd8a113":"We will drop the extra column that we created \"is_Age_available\"","d8b80c25":"Lets identify for whom the Age is not specified. Before we do that lets create one more column in train dataset which specifies whether Age is available or not. ","c94adcc1":"Lets check the distribution of Age data before we impute.","5ce93a2d":"We need to add one more feature \"Is_minor_or_old\" as it can be found that children & old people were saved in comparison to others.","ec754d40":"Lets read the train file and look at the structure of the data to get a basic idea of the dataset. "}}