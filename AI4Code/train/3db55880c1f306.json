{"cell_type":{"2dc7d0ee":"code","76e2b96b":"code","b73d20a8":"code","075cdfe1":"markdown","c10607c4":"markdown","c24220ba":"markdown"},"source":{"2dc7d0ee":"from keras.datasets import reuters\nimport numpy as np\n\n# use reuters news dataset from keras datasets\n(x_train, y_train), (x_test, y_test) = reuters.load_data()\n\nword_index = reuters.get_word_index(path=\"reuters_word_index.json\")\nreverse_word_index = {v:k for k,v in word_index.items()}\n\n# get train document vector\nfor i in range(x_train.__len__()):\n    for j in range(x_train[i].__len__()):\n        if(reverse_word_index.get(x_train[i][j])) == None:\n            continue\n        x_train[i][j] = reverse_word_index[x_train[i][j]]\n    x_train[i] = ' '.join(map(str, x_train[i]))\n\n# get test document vector\nfor i in range(x_test.__len__()):\n    for j in range(x_test[i].__len__()):\n        if(reverse_word_index.get(x_test[i][j])) == None:\n              continue\n        x_test[i][j] = reverse_word_index[x_test[i][j]]\n    x_test[i] = ' '.join(map(str, x_test[i]))\n\n# append test split into train split, I will use k fold    \nx_train = np.append(x_train, [x_test])\ny_train = np.append(y_train, [y_test])","76e2b96b":"import keras\nfrom keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(x_train)\n\n# create feature vectors of word counts\nencoded_docs = tokenizer.texts_to_matrix(x_train, mode='count')\nx_train = encoded_docs\n\n# make label vector of 46 categories\ny_train_cat = keras.utils.to_categorical(y_train, num_classes=46, dtype='float32')\n\nfeature_size = encoded_docs[0].__len__();","b73d20a8":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib\n\n# Instantiate the cross validator\nskf = StratifiedKFold(n_splits=5, shuffle=True)\n\ncsv_scores = []\ni = 1\nfor train, test in skf.split(x_train, y_train):\n    print(\"Train on %d. validation split\\n\" % i)\n    i += 1\n    \n    # Clear model, and create it\n    model = None\n    model = Sequential()\n    model.add(Dense(256, activation='relu', input_dim=feature_size))\n    model.add(Dense(46, activation='softmax'))\n    \n    # compile model\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy'])\n    \n    # train model\n    history = model.fit(x_train[train], y_train_cat[train], epochs=15, batch_size=4096, validation_data=(x_train[test], y_train_cat[test]))\n\n    loss_history = history.history['loss']\n    val_loss_history = history.history['val_loss']\n    \n    accuracy_history = history.history['acc']\n    val_accuracy_history = history.history['val_acc']\n    \n    csv_scores.append(val_accuracy_history[-1])\n\n    # plot losses\n    plt.plot(loss_history)\n    plt.plot(val_loss_history)\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    plt.show()\n    \n    # plot metrics\n    plt.plot(accuracy_history)\n    plt.plot(val_accuracy_history)\n    plt.title('Metrics')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    plt.show()\n    \n    \nprint(\"Average accuracy across kfold splits: %.4f%% (+\/- %.4f%%)\" % (100*np.mean(csv_scores), 100*np.std(csv_scores)))","075cdfe1":"**LOAD DATASET**","c10607c4":"**CREATE WORD COUNT VECTORS**","c24220ba":"**K-FOLD CROSS VALIDATION**"}}