{"cell_type":{"9883cb65":"code","0affd026":"code","53ea50c7":"code","78bbd274":"code","4b1bb34a":"code","8f71368b":"code","71c74b00":"code","8664822e":"code","01a24d8e":"code","596c7a23":"code","06324b2e":"code","f8d3b6f4":"code","33fa9a60":"code","97a17362":"code","1ca3a896":"code","8f75d939":"code","da0157c1":"code","e3400b79":"code","d4483518":"code","9603b3aa":"code","da7724ce":"code","0cb58e49":"code","032c65a9":"code","c895d717":"code","0204c127":"code","918db169":"code","782d97b2":"code","0ebb681c":"code","e3fade70":"code","054014b0":"code","798060f1":"code","79d308b8":"markdown","82b76cc7":"markdown","96cc2b77":"markdown","053c0b84":"markdown","df0b5a36":"markdown","9391fa9f":"markdown","c49d2041":"markdown","6a90004a":"markdown","ae279f76":"markdown","1bbaf155":"markdown","7423d200":"markdown","3dc5a691":"markdown","55625926":"markdown","b8750b0b":"markdown","548fc51e":"markdown","25fce699":"markdown","6b9ec86e":"markdown","a2bc14d3":"markdown","cecba144":"markdown","5d515928":"markdown","1e6a07c6":"markdown","165be90e":"markdown","66e91dd0":"markdown","23dba9d3":"markdown","1abd3871":"markdown"},"source":{"9883cb65":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport csv\nimport networkx as nx\nfrom subprocess import check_output\nfrom wordcloud import WordCloud, STOPWORDS\nimport tensorflow as tf\nfrom IPython.display import YouTubeVideo\nplt.style.use('ggplot')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Any results you write to the current directory are saved as output.","0affd026":"frame_lvl_record = \"..\/input\/frame-sample\/frame\/train00.tfrecord\"","53ea50c7":"print(os.listdir(\"..\/input\/frame-sample\/frame\"))\nprint(os.listdir(\"..\/input\/validate-sample\/validate\"))","78bbd274":"sub = pd.read_csv('..\/input\/sample_submission.csv')\nsub.head()\nprint (\"submission style ...\")","4b1bb34a":"vid_ids = []\nlabels = []\n\nfor example in tf.python_io.tf_record_iterator(frame_lvl_record):\n    tf_example = tf.train.Example.FromString(example)\n    vid_ids.append(tf_example.features.feature['id']\n                   .bytes_list.value[0].decode(encoding='UTF-8'))\n    labels.append(tf_example.features.feature['labels'].int64_list.value)","8f71368b":"print('Number of videos in this tfrecord: ',len(vid_ids))\nprint ('Number of labels in this tfrecord: ', len (labels))\nprint('Picking a youtube video id:',vid_ids[15])","71c74b00":"# With that video id, we can play the video\nYouTubeVideo('UzXQaOLQVCU')","8664822e":"# due to execution time, we're only going to read the first video\n\nfeat_rgb = []\nfeat_audio = []\n\nfor example in tf.python_io.tf_record_iterator(frame_lvl_record):  \n    tf_seq_example = tf.train.SequenceExample.FromString(example)\n    n_frames = len(tf_seq_example.feature_lists.feature_list['audio'].feature)\n    sess = tf.InteractiveSession()\n    rgb_frame = []\n    audio_frame = []\n    # iterate through frames\n    for i in range(n_frames):\n        rgb_frame.append(tf.cast(tf.decode_raw(\n                tf_seq_example.feature_lists.feature_list['rgb']\n                  .feature[i].bytes_list.value[0],tf.uint8)\n                       ,tf.float32).eval())\n        audio_frame.append(tf.cast(tf.decode_raw(\n                tf_seq_example.feature_lists.feature_list['audio']\n                  .feature[i].bytes_list.value[0],tf.uint8)\n                       ,tf.float32).eval())\n        \n        \n    sess.close()\n    \n    feat_audio.append(audio_frame)\n    feat_rgb.append(rgb_frame)\n    break","01a24d8e":"print('The first video has %d frames' %len(feat_rgb[0]))","596c7a23":"vocabulary = pd.read_csv('..\/input\/vocabulary.csv')\nvocabulary.head()","06324b2e":"vocabulary.info()","f8d3b6f4":"from collections import Counter\n\nlabel_mapping =  vocabulary[['Index', 'Name']].set_index('Index', drop=True).to_dict()['Name']\nprint(\"we have {} unique labels in the dataset\".format(len(vocabulary['Index'].unique())))","33fa9a60":"n = 30 # although, we'll only show those that appear in the 1,000 for this competition\ntop_n = Counter([item for sublist in labels for item in sublist]).most_common(n)\ntop_n_labels = [int(i[0]) for i in top_n]\ntop_n_label_names = [label_mapping[x] for x in top_n_labels if x in label_mapping] # filter out the labels that aren't in the 1,000 used for this competition\nprint(top_n_label_names)","97a17362":"labels_count_dict = dict(top_n)\nlabels_count_df = pd.DataFrame.from_dict(labels_count_dict, orient='index').reset_index()\nlabels_count_df.columns = ['label', 'count']\nlabels_count_df['label'] = labels_count_df['label'].map(label_mapping, na_action='ignore')\nTOP_labels = list(labels_count_df['label'])[:n]\nfig, ax = plt.subplots(figsize=(10,7))\nsns.barplot(y='label', x='count', data=labels_count_df)\nplt.title('Top {} labels with sample count'.format(n))","1ca3a896":"import networkx as nx\nfrom itertools import combinations\n\nG = nx.Graph()\n\nG.clear()\nfor list_of_nodes in labels:\n    filtered_nodes = set(list_of_nodes).intersection(set(top_n_labels) & \n                                                     set(vocabulary['Index'].unique()))  \n    for node1,node2 in list(combinations(filtered_nodes,2)): \n        node1_name = label_mapping[node1]\n        node2_name = label_mapping[node2]\n        G.add_node(node1_name)\n        G.add_node(node2_name)\n        G.add_edge(node1_name, node2_name)\n\nplt.figure(figsize=(9,9))\nnx.draw_networkx(G, font_size=\"12\")","8f75d939":"plt.figure(figsize = (10,8))\nvocabulary.groupby('Vertical1').TrainVideoCount.sum().plot(kind=\"bar\")\nplt.title(\"Average TrainVideoCount per vertical1\")\nplt.show()\n\nplt.figure(figsize = (10,8))\nvocabulary.groupby('Vertical1').Index.count().plot(kind=\"bar\")\nplt.title(\"Average number video per vertical1\")\nplt.show()","da0157c1":"plt.figure(figsize = (10,8))\nvocabulary.groupby('Vertical2').TrainVideoCount.sum().plot(kind=\"bar\")\nplt.title(\"Average TrainVideoCount per vertical2\")\nplt.show()\n\nplt.figure(figsize = (10,8))\nvocabulary.groupby('Vertical2').TrainVideoCount.count().plot(kind=\"bar\")\nplt.title(\"Average video number per vertical2\")\nplt.show()","e3400b79":"plt.figure(figsize = (10,8))\nvocabulary.groupby('Vertical3').TrainVideoCount.sum().plot(kind=\"bar\")\nplt.title(\"Average TrainVideoCount per vertical3\")\nplt.show()\n\nplt.figure(figsize = (10,8))\nvocabulary.groupby('Vertical3').TrainVideoCount.count().plot(kind=\"bar\")\nplt.title(\"Average video number per vertical3\")\nplt.show()","d4483518":"sns.lmplot(x='Index', y='TrainVideoCount', data=vocabulary , size=15)","9603b3aa":"vocabulary.groupby('Vertical1').corr()","da7724ce":"plt.figure(figsize = (15,15))\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n                          background_color='black',\n                          stopwords=stopwords,\n                          max_words=1000,\n                          max_font_size=120, \n                          random_state=42\n                         ).generate(str(vocabulary['WikiDescription']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.title(\"WORD CLOUD - description\")\nplt.axis('off')\nplt.show()","0cb58e49":"plt.figure(figsize = (15,15))\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n                          background_color='black',\n                          stopwords=stopwords,\n                          max_words=1000,\n                          max_font_size=120, \n                          random_state=42\n                         ).generate(str(vocabulary['Name']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.title(\"WORD CLOUD - Name\")\nplt.axis('off')\nplt.show()","032c65a9":"plt.figure(figsize = (15,15))\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n                          background_color='black',\n                          stopwords=stopwords,\n                          max_words=1000,\n                          max_font_size=120, \n                          random_state=42\n                         ).generate(str(vocabulary['Vertical1']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.title(\"WORD CLOUD - Vertical1\")\nplt.axis('off')\nplt.show()","c895d717":"plt.figure(figsize = (15,15))\n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n                          background_color='black',\n                          stopwords=stopwords,\n                          max_words=1000,\n                          max_font_size=120, \n                          random_state=42\n                         ).generate(str(vocabulary['Vertical2']))\n\nprint(wordcloud)\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.title(\"WORD CLOUD - Vertical2\")\nplt.axis('off')\nplt.show()","0204c127":"with open('..\/input\/vocabulary.csv', 'r') as f:\n  vocabularylist = list(csv.reader(f))\n\nT1=[]\n\nfor l in vocabularylist:\n    if l[5] != 'NaN' and l[6] !='NaN' and l[5] != '' and l[6] !='' and l[5] !=  l[6] :\n        c1 = l[5]\n        c2 = l[6]\n        tuple = (c1, c2)\n    if l[5] != 'NaN' and l[7] !='NaN' and l[5] != '' and l[7] !='' and l[5] !=  l[7] :\n        c1 = l[5]\n        c2 = l[7]\n        tuple = (c1, c2)\n    if l[6] != 'NaN' and l[7] !='NaN' and l[6] != '' and l[7] !='' and l[7] !=  l[6] :\n        c1 = l[6]\n        c2 = l[7]\n        tuple = (c1, c2)\n    T1.append(tuple)\n    \nedges = {k: T1.count(k) for k in set(T1)}\nprint (\"List = \",len(edges), \"elements\")\nedges","918db169":"B = nx.DiGraph()\nnodecolor=[]\nfor ed, weight in edges.items():\n    if ed[0]!='Vertical2' and ed[0]!='Vertical3' and  ed[1]!='Vertical2' and ed[1]!='Vertical3':\n        B.add_edge(ed[0], ed[1], weight=weight)\nfor k in B.nodes:\n    if (k == \"Beauty & Fitness\"):\n        nodecolor.append('blue')\n    elif (k == \"News\"):\n        nodecolor.append('Magenta')\n    elif (k == \"Food & Drink\"):\n        nodecolor.append('crimson')\n    elif (k == \"Health\"):\n        nodecolor.append('green')\n    elif (k == \"Science\"):\n        nodecolor.append('yellow')\n    elif (k == \"Business & Industrial\"):\n        nodecolor.append('cyan')\n    elif (k == \"Home & Garden\"):\n        nodecolor.append('darkorange')\n    elif (k == \"Travel\"):\n        nodecolor.append('slategrey')\n    elif (k == \"Arts & Entertainment\"):\n        nodecolor.append('red')\n    elif (k == \"Games\"):\n        nodecolor.append('grey')\n    elif (k == \"People & Society\"):\n        nodecolor.append('lightcoral')\n    elif (k == \"Shopping\"):\n        nodecolor.append('maroon')\n    elif (k ==\"Computers & Electronics\"):\n        nodecolor.append('orangered')\n    elif (k == \"Hobbies & Leisure\"):\n        nodecolor.append('saddlebrown')\n    elif (k == \"Sports\"):\n        nodecolor.append('lawngreen')\n    elif (k == \"Real Estate\"):\n        nodecolor.append('deeppink')\n    elif (k == \"Finance\"):\n        nodecolor.append('navy')\n    elif (k == \"Reference\"):\n        nodecolor.append('royalblue')\n    elif (k == \"Autos & Vehicles\"):\n        nodecolor.append('turquoise')\n    elif (k == \"Internet & Telecom\"):\n        nodecolor.append('lime')\n    elif (k == \"Law & Government\"):\n        nodecolor.append('palegreen')\n    elif (k == \"Jobs & Education\"):\n        nodecolor.append('springgreen')\n    elif (k == \"Pets & Animals\"):\n        nodecolor.append('lightpink')\n    elif (k == \"Books & Literature\"):\n        nodecolor.append('lightpink')","782d97b2":"plt.figure(figsize = (15,15))\nnx.draw(B, pos=nx.circular_layout(B), node_size=1500, with_labels=True, node_color=nodecolor)\nnx.draw_networkx_edge_labels(B, pos=nx.circular_layout(B), edge_labels=nx.get_edge_attributes(B, 'weight'))\nplt.title('Weighted graph representing the relationship between the categories', size=20)\nplt.show()","0ebb681c":"# analyse\nprint('Quick Review')\nprint (20*'...',\"\\n\")\nprint(\"number of node : %s\" % B.number_of_nodes())\nprint(\"number of arcs : %s\" % B.number_of_edges())\n\n# arc entrant\nindeg = 0\nfor n in B.in_degree():\n    indeg += n[1]\n\n# arc sortant\noutdeg = 0\nfor n in B.in_degree():\n    outdeg += n[1]\n\nprint('')\nprint(\"the number of edges pointing to the node : %s\" % indeg)\nprint(\"the number of edges pointing to the outside of the node : %s\" % outdeg)\n\n# passage en graphe non orient\u00e9\nG = B.to_undirected()\n\n# min et max de degree\nlistmindegre = (0, 10)\nlistmaxdegre = (0, 0)\nfor n in G.degree():\n    if (listmindegre[1] > n[1]):\n        listmindegre = n\n    if (listmaxdegre[1] < n[1]):\n        listmaxdegre = n\n\nprint('')\nprint(\"The node that has the minimal degree is : \", listmindegre)\nprint(\"The node that has the maximum degree is : \", listmaxdegre)\nedgdesmax=0\nfor ed,w in G.edges.items():\n    if(w['weight']>edgdesmax):\n        edgdesmax=w['weight']\n        edgdescat=ed\nedgdescat\nprint(\"both category \",edgdescat[0],\" and \",edgdescat[1],\" has the big relationship weight( w = \",edgdesmax,\")\")\n   \n# centrality\nlistmincentrality = (0, 10)\nlistmaxcentrality = (0, 0)\nfor n in (nx.betweenness_centrality(G)).items():\n    if (listmincentrality[1] > n[1]):\n        listmincentrality = n\n    elif (listmaxcentrality[1] < n[1]):\n        listmaxcentrality = n\n\nprint('')\nprint(\"The node that has minimal centrality is : \", listmincentrality)\nprint(\"The node that has the maximum centrality is : \", listmaxcentrality)\n\n# normalized\nlistminnormalized = (0, 10)\nlistmaxnormalized = (0, 0)\nfor n in (nx.degree_centrality(G)).items():\n    if (listminnormalized[1] > n[1]):\n        listminnormalized = n\n    elif (listmaxnormalized[1] < n[1]):\n        listmaxnormalized = n\n\nprint('')\nprint(\"The node that has the minimum (normalized) degree is : \", listminnormalized)\nprint(\"The node that has the maximal (normalized) degree is: \", listmaxnormalized)","e3fade70":"cl = list(nx.find_cliques(G))\nprint(\"estimate number of cliques %s\" % nx.graph_number_of_cliques(G))\nprint(\"click on who has maximum number %s\" % nx.graph_clique_number(G))\nprint('')\n\nprint(\">> possible cases of clique:\\n\")\nfor cl in nx.find_cliques(G):\n    if len(cl)==2 or len(cl)==3:\n        print(cl)","054014b0":"pathlengths = []\n\nfor v in G.nodes():\n    spl = nx.single_source_shortest_path_length(G, v)\n    for p in spl.values():\n        pathlengths.append(p)\nprint(\"average of the shortest paths %s\" % round((sum(pathlengths) \/ len(pathlengths)), 3))\n\nprint('')\n\nprint(\"density : %s\" % round(nx.density(G), 3))\nprint(\"diameter :\", nx.diameter(G.subgraph(max(nx.connected_components(G), key=len))))\n\n# eccentricity\nlistmineccentricity = (0, 10)\nlistmaxeccentricity = (0, 0)\nfor n in (nx.eccentricity(G.subgraph(max(nx.connected_components(G), key=len)))).items():\n    if (listmineccentricity[1] > n[1]):\n        listmineccentricity = n\n    elif (listmaxeccentricity[1] < n[1]):\n        listmaxeccentricity = n\n\nprint('')\nprint(\"The node that has the minimal eccentricity is : \", listmineccentricity)\nprint(\"The node that has the maximum eccentricity is : \", listmaxeccentricity)\nprint('')\n\nprint(\"center : %s\" % nx.center(G.subgraph(max(nx.connected_components(G), key=len))))\nprint(\"periphery : %s\" % nx.periphery(G.subgraph(max(nx.connected_components(G), key=len))))","798060f1":"plt.figure(figsize = (15,15))\nnx.draw_random(B,  node_size=1500, with_labels=True, node_color=nodecolor)\nnx.draw_networkx_edge_labels(B, pos=nx.circular_layout(B), edge_labels=nx.get_edge_attributes(B, 'weight'))\nplt.title('Weighted graph representing the relationship between the categories', size=20)\nplt.show()","79d308b8":"### Vertical 2","82b76cc7":"<br>\n### Vertical 1","96cc2b77":"### Vertical 2","053c0b84":"### Video-level information (extracted from the frame-level files)","df0b5a36":"### Name","9391fa9f":"### Plot data and regression model","c49d2041":"# GRAPHS","6a90004a":"### Vertical 3","ae279f76":"![](https:\/\/research.google.com\/youtube8m\/workshop2018\/logo.png)\n<br>\n![](https:\/\/storage.googleapis.com\/kaggle-media\/competitions\/youtube\/YT8M.png)\n\n\n<br>\n<br>\n\n# The 3rd YouTube-8M Video Understanding Challenge\n\nIn this competition, you will predict the ```Class``` labels of YouTube video segments. We provide you extracted frame-level features. The feature data and detailed feature information can be found on the [YouTube-8M](https:\/\/research.google.com\/youtube8m\/) dataset webpage. \n\nThe training dataset in this competition contains videos and labels that are publicly available on YouTube, while the test data is not publicly available. The test data also has anonymized video IDs to ensure the fairness of the competition.\n\n### File descriptions\n\n**frame-level data**\n\n- You may download to your local computer with instructions here\n- Total size of 1.53TB (Large file warning!)\n- Each video has\n\n    a. id: unique id for the video, in train set it is a YouTube video id, and in test\/validation they are anonymized.\n    \n    b. labels: list of labels of that video.\n    c. Each frame has rgb: float array of length 1024,\n    d. Each frame has audio: float array of length 128\n\n- A subset of the validation set videos are provided with segment-level labels. In addition to ```id```, ```labels``` and the frame level features described above, they come with\n\n    a. segment_start_times: list of segment start times.\n    b. segment_end_times: list of segment end times.\n    c. segment_labels: list of segment labels.\n    d. segment_scores: list of binary values indicating positive or negative corresponding to the segment labels.\n\n- Files are in [TFRecords](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/io#tfrecords_format_details) format, TensorFlow python readers are available in the [github repo](https:\/\/github.com\/google\/youtube-8m).\n\n**frame-sample.zip** - a sample of frame-level data including ```train00``` and ```train01```\n\n**validate-sample.zip** - a sample of validation set data including ```validate00``` and ```validate01```\n\n**vocabulary.csv** - the full data dictionary for label names and their descriptions \n\n**sample_submission.csv** - a sample submission file in the correct format\n\n- For each ```Class```, submit a space-delimited list of the segments your model predicts as having that class, ordered by confidence (highest first).\n\n- **IMPORTANT:** In order to minimize submission file sizes, for segment predictions, you should only include the video id and the segment start time, but not the segment end time. (These are not needed, since all segments are 5 seconds in duration.)","1bbaf155":"### Correlations","7423d200":"**Example: ** Read 1st video","3dc5a691":"### Labels","55625926":"### Cliques","b8750b0b":"### DiGraph - Directed graphs with self loops","548fc51e":"### Plot the relationships between each of these top labels...","25fce699":"# WordCloud","6b9ec86e":"# Vocabulary List","a2bc14d3":"<br>\n<br>\n**Load Required Packages**","cecba144":"### WikiDescription","5d515928":"<br>\n# Vocabulary","1e6a07c6":"<br>\n# Exploring Data (TFRecord format) using a subsample of the YouTube-8M video & frame-level data.\n\n### Check [Starter Kernel: YT8M 2019 Sample Data](https:\/\/www.kaggle.com\/inversion\/starter-kernel-yt8m-2019-sample-data)","165be90e":"**Plot Labels freq**","66e91dd0":"**Top n Labels**","23dba9d3":"### Shortest path","1abd3871":"### Vertical 1"}}