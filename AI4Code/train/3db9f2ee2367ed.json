{"cell_type":{"255a861e":"code","42a7a5dd":"code","c0c80c07":"code","3c8c9e9a":"code","85929d0f":"code","7b86fe30":"code","d8925494":"code","3a7f79ec":"code","34c19d00":"code","a00e5541":"code","e2d384f1":"code","567a7d63":"code","59a7724e":"code","005e5884":"code","12fcaf5d":"code","3004cb28":"code","3383f095":"code","2f1b296d":"code","070219c9":"code","73581a82":"code","1e056611":"code","71a8e9ae":"markdown","4dec6bea":"markdown","aedc011b":"markdown","418e354e":"markdown","25132291":"markdown","615a1053":"markdown","6e442813":"markdown","515c66e4":"markdown","4bccdaf9":"markdown","94fdebdb":"markdown","021a6b7f":"markdown","35e8d5fd":"markdown","7aee0297":"markdown","d4a639e4":"markdown","f6e2c576":"markdown","9e23e46e":"markdown","b6c12546":"markdown"},"source":{"255a861e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\n#Importing Preprocessing liberaries\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\nfrom sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler, Binarizer, OneHotEncoder\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV, RandomizedSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\n#Importing model liberaries \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n%matplotlib inline","42a7a5dd":"seed = 1\nscoring='accuracy'\nnum_folds = 10\ntest_size = 0.3\nkfold = KFold(n_splits=num_folds, random_state=seed)","c0c80c07":"filepath = '..\/input\/train.csv'\nlabeled_images = pd.read_csv(filepath)\nimages = labeled_images.iloc[:5000, 1:].values.astype('float32')\nlabels = labeled_images.iloc[:5000, :1].values.astype('int32')\n\ntrain_images,test_images, train_labels, test_labels = train_test_split(images, labels, test_size=test_size, random_state=seed)","3c8c9e9a":"sns.countplot(labeled_images['label'])\nprint(labeled_images.isnull().any().any())\nCounter(labeled_images['label'])","85929d0f":"train_images \/= 255.0\ntest_images \/= 255.0","7b86fe30":"plt.figure(figsize=(15,15))\nfor i in range(5):\n  plt.subplot(5, 5, i+1)\n  img = train_images[i].reshape(28,28)\n  plt.xticks([])\n  plt.yticks([])\n  plt.imshow(img, cmap='gray')\n  plt.colorbar()\n  plt.title(train_labels[i])","d8925494":"models = []\nmodels.append(('LR', LogisticRegression()))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('GB', GaussianNB()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('SVM', SVC()))\nmodels.append(('ExtraTrees', ExtraTreesClassifier()))\nmodels.append(('GradientBoosting', GradientBoostingClassifier()))\nmodels.append(('RandomForest', RandomForestClassifier()))\nresults = []\nnames = []","3a7f79ec":"# for name, model in models:\n#   cv_results = cross_val_score(model, train_images, train_labels.ravel(), cv=kfold)\n#   results.append(cv_results)\n#   names.append(name)\n#   print(name, cv_results.mean(), cv_results.std())","34c19d00":"# k_range = list(range(1,10))\n# weight_options = ['uniform', 'distance']\n# algorithm = ['auto', 'brute']\n# knn_params_grid = dict(n_neighbors=k_range, weights=weight_options)\n\n# def knn_param_selection(X, y, params_grid, num_folds):\n#     knn = KNeighborsClassifier()\n#     knnGrid = GridSearchCV(knn, params_grid, cv=num_folds, n_jobs=-1, scoring='accuracy')\n#     knnGrid.fit(train_images, train_labels.ravel())\n#     print(knnGrid.best_estimator_, knnGrid.best_score_, knnGrid.best_params_)\n    \n# knn_param_selection(train_images, train_labels, knn_params_grid, num_folds)","a00e5541":"#Fine Tuning KNN Hyperparameters\nmodel = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n           weights='distance')\nfinal_results = cross_val_score(model, train_images, train_labels, cv=kfold)\nprint(\"%s %f %f\" % ('KNN - FineTuned Grid', final_results.mean(), final_results.std()))","e2d384f1":"# kernels = ['rbf']\n# #first iteration params\n# #kernels = ['linear', 'rbf']\n# # Cs = [0.001, 0.01, 0.1, 1, 10]         \n# # gammas = [0.001, 0.01, 0.1, 1]\n# #Second iteration params\n# # Cs = [9, 10, 11, 12, 13, 14, 15]\n# # gammas = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07]\n# #third iteration params\n# Cs = [13, 14, 15, 16, 17]\n# gammas = [0.018, 0.019, 0.020, 0.021, 0.022 ]\n# svcParams_grid = dict(C=Cs, gamma=gammas, kernel=kernels)\n# def svc_param_selection(X, y, params_grid, num_folds):\n#     svc = SVC()\n#     svcRand = RandomizedSearchCV(svc, svcParams_grid, cv=num_folds, n_jobs=-1, scoring='accuracy')\n#     svcRand.fit(train_images, train_labels.ravel())\n#     print(svcRand.best_estimator_, svcRand.best_score_, svcRand.best_params_)\n\n# svc_param_selection(train_images, train_labels, svcParams_grid, num_folds)\n# #First iteration: {'kernel': 'rbf', 'gamma': 0.01, 'C': 10}  Score: 0.950857\n# #Second iteration: {'kernel': 'rbf', 'gamma': 0.02, 'C': 15}  Score: 0.9588571428571429\n# #Third iteration: {'kernel': 'rbf', 'gamma': 0.022, 'C': 17} Score: 0.9588571428571429 ","567a7d63":"#Fine Tuning SVM Hyperparameters\nsvc = SVC(C=15, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma=0.022, kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\nfinal_results = cross_val_score(svc, train_images, train_labels, cv=kfold)\nprint(\"%s %f %f\" % ('SVM - FineTuned Random', final_results.mean(), final_results.std()))","59a7724e":"#Predictions after tuning KNN Hyperparameter\nmodel = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n           weights='distance')\nmodel.fit(train_images, train_labels)\npredictions = model.predict(test_images)\nprint(\"%s %f\" % ('KNN - Fine Tuned', accuracy_score(test_labels, predictions)))","005e5884":"#Predictions after tuning SVM Hyperparameter\nsvc = SVC(C=15, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma=0.022, kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)\nsvc.fit(train_images, train_labels)\npredictions = svc.predict(test_images)\nprint(\"%s %f\" % ('SVM - Fine Tuned', accuracy_score(test_labels, predictions)))","12fcaf5d":"filepath = '..\/input\/test.csv'\ntest_data = pd.read_csv(filepath)\ntest_data_images = test_data.iloc[:, :].values.astype('float32')","3004cb28":"test_data_images \/= 255.0\ntest_data_images.shape","3383f095":"images = labeled_images.iloc[:, 1:].values.astype('float32')\nlabels = labeled_images.iloc[:, :1].values.astype('int32')\nimages \/= 255.0","2f1b296d":"# svc = SVC(C=15, cache_size=200, class_weight=None, coef0=0.0,\n#   decision_function_shape='ovr', degree=3, gamma=0.022, kernel='rbf',\n#   max_iter=-1, probability=False, random_state=None, shrinking=True,\n#   tol=0.001, verbose=False)\n# svc.fit(images, labels)\n# results = svc.predict(test_data_images)\n# df = pd.DataFrame(results)\n# df.index.name='ImageId'\n# df.index+=1\n# df.columns=['Label']\n# df.to_csv('results.csv', header=True)","070219c9":"#Trying to create an ensemble of few best performing \nfrom sklearn.ensemble import VotingClassifier\nlr_clf  = LogisticRegression()\nknn_clf = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n           weights='distance')\nsvm_clf = SVC(C=15, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape='ovr', degree=3, gamma=0.022, kernel='rbf',\n  max_iter=-1, random_state=None, shrinking=True,\n  tol=0.001, verbose=False, probability=True)\nextree_clf =  ExtraTreesClassifier()\n\n\nvoting_clf = VotingClassifier(\n              estimators= [('lr', lr_clf), ('knn', knn_clf), ('svm', svm_clf), ('extree', extree_clf)],\n              voting='soft')\nvoting_clf.fit(images, labels)\nresults = voting_clf.predict(test_data_images)\ndf = pd.DataFrame(results)\ndf.index.name='ImageId'\ndf.index+=1\ndf.columns=['Label']\ndf.to_csv('results.csv', header=True)","73581a82":"plt.figure(figsize=(15,15))\nfor i in range(25):\n  plt.subplot(5, 5, i+1)\n  img = test_data_images[i].reshape(28,28)\n  plt.xticks([])\n  plt.yticks([])\n  plt.imshow(img, cmap='gray')\n  plt.colorbar()\n  plt.title(results[i])","1e056611":"sns.countplot(df['Label'])\nCounter(df['Label'])","71a8e9ae":"****Submission result - Predictions on provided test data****","4dec6bea":"Plot few images from training data to do sanity check i.e. that labels are marked correctly in training data.","aedc011b":"Initialize all the models you want to check with their default hyperparameters.","418e354e":"As can be seen SVM accuracy is same for second and third iteration best hyperameters and hence choose best estimators discovered from second iteration only.","25132291":"Compare all the models in loop through cross validation:","615a1053":"Taking full training data for training for predictions instead of partial data taken eararlier:","6e442813":"**Make predictions and Test the predictions**","515c66e4":"Here I am choosing only a small amount of data 5000 records to compare the model as comparing with all the data \nwould involve so much time.","4bccdaf9":"Checking data for any NULL value and if it has normal distribution or any skewness.","94fdebdb":"Scale the data as we know that ML algorithms performs best when data range is small.","021a6b7f":"In this kernel I have tried to find the most suitable algorithms(leaving Deep learning) by comparing the performance across various and by further fine tuning algoritms.\n**Load all required preprocessing and model liberaries**","35e8d5fd":"**Declare global hyperparameters and load the input data**","7aee0297":"From the result it is clear that KNN, SVM and GradientBoosting models are the winners and are best choosen for further fine tuning the modes.\nHere I have done the fine tuning on KNN and SVM.(yet to do finish experiment on GradientBoosting).","d4a639e4":"**Fine tuning KNN Hyperparameters using GridSearchCV **","f6e2c576":"Fine tuning SVM Hyperparameters using RandomizedSearchCV. SVM takes much more time than KNN hence used RandomizedSearchCV for discovering hyperparameters. Used three iterations to zero in on final hyperparameters for SVM.","9e23e46e":"Checking distribution of predicitons:","b6c12546":"Doing a sanity check by plotting some 25 images and seeing that predicitions make sense."}}