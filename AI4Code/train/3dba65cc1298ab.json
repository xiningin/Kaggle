{"cell_type":{"127fe820":"code","d37a2711":"code","3ed26623":"code","94ae170f":"code","ff0b7c63":"code","76c36d0c":"code","39e63050":"code","3cf240e5":"code","a8e4c904":"code","6b3565ae":"code","55ca2220":"code","9b982387":"markdown","5b439684":"markdown","daaee92c":"markdown","212e580d":"markdown","5c5cbaa4":"markdown","f6bef406":"markdown","ef99900e":"markdown","d7d52603":"markdown","b31ada05":"markdown","fe946493":"markdown","84b7a437":"markdown","6221c9c1":"markdown"},"source":{"127fe820":"# install the uploaded version of healpy (1.14.0)\n!pip --disable-pip-version-check install \/kaggle\/input\/healpy-python-package-to-draw-sky-maps-1140\/healpy-1.14.0-cp37-cp37m-manylinux1_x86_64.whl | perl -pe 's\/\\n\/\\r\/g'\n# disable astropy internet download of leap-second file\nfrom astropy.utils import iers\niers.conf.auto_download = False # this prevents astropy from downloading the latest leap-second file,\n                                # something impossible in this kaggle version of the notebook without internet connection\n\n![ -d \/kaggle\/input\/release-2021-v1\/augeropendata ] && [ ! -d augeropendata ] && ln -s \/kaggle\/input\/release-2021-v1\/augeropendata augeropendata  # kaggle specific linking dataset to augeropendata directory","d37a2711":"%matplotlib inline\n\nfrom IPython.display import HTML, Latex, Math, display\n\n# Data analysis\nimport numpy as np\nimport pandas as pd\n\n# Create spherical-map\nimport healpy as hp\n\n# Manage & convert astro coordinates\nimport astropy.units as u\nimport astropy.coordinates as Coord\n\n# Tools for Rayleigh analysis\nfrom scipy.optimize import minimize, least_squares, curve_fit\nfrom scipy.stats import chi2\nfrom scipy.special import erfcinv\n\n# Plotting\nimport matplotlib\nfrom matplotlib import rcParams\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","3ed26623":"# Data loading, encapsulated to make it less installation and OS dependant\nimport os.path\nfrom zipfile import ZipFile\ndef AugerLoad(fdir,file):\n    \"\"\"\n    Loads a file from the auger open data release. Can be either in the local directory,\n    in the parent directory or in the augeropendata directory.\n    File is identified by it directory *fdir* and filename *file* and can be found in the directory\n    or in a zip file.\n    \"\"\"\n    for loc in [\".\",\"..\",\"augeropendata\"]:\n        fname=os.path.join(loc,fdir,file)\n        if os.path.isfile(fname):\n            return open(fname)\n        zname=os.path.join(loc,fdir+\".zip\")\n        if os.path.isfile(zname):\n            with ZipFile(zname) as myzip:\n                return myzip.open(os.path.join(fdir,file))\n","94ae170f":"# Load data\nraw_data = pd.read_csv(AugerLoad('summary','dataSummary.csv'))","ff0b7c63":"# Safeguard: select only events above Eth = 2.5 EeV, where full efficiency is reached for zenith angles < 60\u00b0\nEth = 2.5 # EeV\ne_cut = (raw_data.sd_energy>Eth)\ndata = raw_data[e_cut]\ntotalExposure = data.sd_exposure.iloc[-1]\n\n# Example: print the energy and the galactic coordinates of a randomly selected event\nevent = np.random.randint(0, data.shape[0])\nexample = data.iloc[event]\n\ndisplay(Latex(f'''Event #{event}:\n\\\\begin{{align}}\nE &= {example.sd_energy}\\\\,\\\\mathrm{{EeV}}\\\\\\\\\nl &= {example.sd_l} ^\\circ\\\\\\\\\nb &= {example.sd_b} ^\\circ\\\\\\\\\n\\\\end{{align}}\n'''))","76c36d0c":"def MapToHealpyCoord(galCoord, l, b):\n    \n    theta = np.pi\/2 - b\n    phi = l\n\n    if(not galCoord): # If equatorial coordinates\n        phi -= np.pi\n    return phi, theta\n\ndef HealpyCoordToMap(galCoord, phi, theta):\n    \n    b = np.pi\/2 - theta\n    l = phi\n    if(not galCoord): # If equatorial coordinates: l+\u03c0, projected to [0, 2*\u03c0]\n        l = np.where(l < np.pi, l + np.pi, l - np.pi) \n    return l, b\n\n\ndef LoadShapedData(galCoord = False, Emin = 8):\n    \n    # Coordinate conversion, returns (phi, theta)\n    coords = MapToHealpyCoord(galCoord,\n                              np.radians(data.sd_l if galCoord else data.sd_ra),\n                              np.radians(data.sd_b if galCoord else data.sd_dec))\n\n    # Event selection above Emin\n    unmasked = (data.sd_energy>Emin)\n    dataset = pd.DataFrame(dict(zip(['phi', 'theta'], coords)))[unmasked]\n    return dataset","39e63050":"def LoadCountMap(dataset, nside):\n    \n    # Pixel index for each events of coordinates (theta, phi)\n    index = hp.ang2pix(nside, np.array(dataset.theta), np.array(dataset.phi))\n\n    # Count map of parameter nside\n    npix = hp.nside2npix(nside)# npix corresponds to the number of pixel associated to a NSIDE healpy map\n    count_map = np.histogram(index, bins=np.arange(npix + 1))[0]\n    \n    return count_map\n\ndef PlotHPmap(HPmap, nside, galCoord, title, color_bar_title, projection=\"hammer\", cmap='afmhot', vmin=None, vmax=None, fig=None, ax=None):\n    \n    # Transform healpix map into matplotlib map (grid_map)\n    xsize = 2000 # grid size for matplotlib\n    ysize = int(xsize\/2.)\n    theta = np.linspace(np.pi, 0, ysize)\n    phi   = np.linspace(-np.pi, np.pi, xsize)\n    PHI, THETA = np.meshgrid(phi, theta)\n    grid_pix = hp.ang2pix(nside, THETA, PHI)\n    grid_map = HPmap[grid_pix]\n\n    # Define the figure\n    width = 15# width of the figure\n    if fig is None:\n        doubleFig = False\n        fig = plt.figure(figsize=(width,width\/1.5))\n        fig.suptitle(title, size=30)\n    else:\n        doubleFig = True\n    if ax is None:\n        ax = fig.add_subplot(111, projection=projection)\n    labelsize = 16\n    ax.tick_params(axis='x', labelsize=labelsize)\n    ax.tick_params(axis='y', labelsize=labelsize)\n            \n    # Set the size of the other fonts\n    fontsize = 22\n    font = {'size': fontsize}\n    matplotlib.rc('font', **font)\n    \n    # minimum and maximum values along the z-scale (colorbar)\n    if vmax is None:\n        vmax = np.max(HPmap)\n    if vmin is None:\n        vmin = np.min(HPmap)   \n    \n    # Plot the map, reverse the longitude axis \"[::-1]\" (astronomical convention)\n    longitude = np.radians(np.linspace(-180, 180, xsize))\n    latitude = np.radians(np.linspace(-90, 90, ysize))\n    image = ax.pcolormesh(longitude[::-1], latitude, grid_map, rasterized=True, \n                          cmap=plt.get_cmap(cmap), shading='auto', vmin=vmin, vmax=vmax)\n    if not doubleFig:\n        cb = fig.colorbar(image, orientation='horizontal', shrink=.6, pad=0.05)\n        cb.set_label(color_bar_title, size=fontsize)\n    \n    # Plot the labels considering if it is galactic or equatorial coordinates\n    if(galCoord):\n        ax.set_xticklabels([r\"150$\\degree$\", r\"120$\\degree$\", r\"90$\\degree$\", r\"60$\\degree$\", r\"30$\\degree$\", r\"GC\", r\"330$\\degree$\", r\"300$\\degree$\", r\"270$\\degree$\", r\"240$\\degree$\", r\"210$\\degree$\"])\n        ax.set_title(\"Galactic\")\n        ax.set_xlabel('l', size=labelsize)\n        ax.set_ylabel('b', size=labelsize)\n    else:\n        ax.set_xticklabels([r\"330$\\degree$\", r\"300$\\degree$\", r\"270$\\degree$\", r\"240$\\degree$\", r\"210$\\degree$\", r\"180$\\degree$\", r\"150$\\degree$\", r\"120$\\degree$\", r\"90$\\degree$\", r\"60$\\degree$\", r\"30$\\degree$\"])\n        ax.set_title(\"Equatorial\")\n        ax.set_xlabel('R.A.', size=labelsize)\n        ax.set_ylabel('Dec.', size=labelsize)\n        \n    ax.grid(True, alpha=0.25)\n\n    if doubleFig:\n        return image\n\n# Plot the count map\nEmin = 8 # EeV\ngalCoord = False\ndataset = LoadShapedData(galCoord, Emin) # data Emin\n\nnside = 64\ncount_map = LoadCountMap(dataset, nside)\n\ntitle=f\"Count Map, $E > {Emin}$ EeV\"\ncolor_bar_title = \"# events per pixel\"\nPlotHPmap(count_map, nside, galCoord, title, color_bar_title)","3cf240e5":"def exposure(dec):\n    \n    theta_max = np.radians(60) # Maximum zenith angle in the dataset\n    l = np.radians(-35.23) # Latitude of the center of the array (near Malarg\u00fce - Argentina)\n    \n    arg = (np.cos(theta_max) - np.sin(l)*np.sin(dec)) \/ (np.cos(l)*np.cos(dec))\n    hm = np.arccos(arg.clip(-1, 1))\n\n    return np.cos(l)*np.cos(dec)*np.sin(hm) + hm*np.sin(l)*np.sin(dec)\n\ndef Get_ra_dec(nside, galCoord):\n    \n     # Get the healpy coordinates of each pixel \n    npix = hp.nside2npix(nside)\n    phi, theta = hp.pix2ang(nside, np.arange(npix))\n\n    # Transform the (y,x) values into whether galactic coordinates or whether equatorial coordinates.\n    if(galCoord): #If galactic coordinates, get the declination value for a given (l,b)\n        l, b = HealpyCoordToMap(True, theta, phi)\n        c = Coord.SkyCoord(l=l*u.radian, b=b*u.radian, frame='galactic')\n        ra = c.icrs.ra.radian\n        dec = c.icrs.dec.radian\n    else:\n        ra, dec  = HealpyCoordToMap(False, theta, phi)\n        \n    return ra, dec\n\ndef LoadExposureMap(totalExposure, nside, galCoord):\n   \n    ra, dec = Get_ra_dec(nside, galCoord)\n    \n    # Compute the exposure_map for each pixel regarding its declination.\n    exposure_map = exposure(dec)*totalExposure\/np.sum(exposure(dec))\n    \n    return exposure_map\n\n\n# Compute the exposure in equatorial coordinates & save the figure in a file \"equatorial.jpg\"\nnside = 64\ntitle = \"Exposure Map\"\ncolor_bar_title = r\"Exposure [$\\rm km^{2} \\, sr \\, yr$ \/ pixel]\"\n\n\n# Plot the two exposure map\nrcParams['figure.figsize'] = 20, 14 #Size of figs\nfig, ax = plt.subplots(1, 2, subplot_kw={'projection': 'hammer'})\nfig.suptitle(title, fontsize=30)\n\nfor galCoord in [0, 1]:\n    exposure_map = LoadExposureMap(totalExposure, nside, galCoord)\n    image = PlotHPmap(exposure_map, nside, galCoord, title, color_bar_title, ax=ax[galCoord], fig=fig)\n\nfig.subplots_adjust(top=1.4)\ncbar_ax = fig.add_axes([0.25, 0.55, 0.5, 0.03])\ncb = fig.colorbar(image, orientation='horizontal', shrink=.6, pad=0.05, cax=cbar_ax)\ncb.set_label(color_bar_title, size=22)\n\n\nplt.show()","a8e4c904":"def top_hat_beam(radius, nside):\n    \n    b = np.linspace(0.0, np.pi, 10000)\n    bw = np.where(abs(b) <= radius, 1, 0)\n    return hp.sphtfunc.beam2bl(bw, b, lmax=nside*3) #beam in the spherical harmonics space\n\ndef LoadSmoothedMap(hp_map, radius_deg, nside):\n    \n    radius = np.radians(radius_deg)\n    solid_angle = 2.*np.pi*(1. - np.cos(radius))\n    return hp.smoothing(hp_map, beam_window=top_hat_beam(radius, nside), verbose=False) \/ solid_angle\n\n# Parameters of the maps\nEmin = 8 # EeV\nnside = 64\nradius_deg = 45 # top-hat radius in degrees\n\n\n# Define title and the color bar title of the smoothed exposure map\ntitle = f\"Smoothed Exposure Map, $R={radius_deg}\\\\degree$\"\ncolor_bar_title = r\"Exposure [$\\rm km^{2} \\, sr \\, yr$ \/ pixel]\"\n\n# Plot the two exposure map\nrcParams['figure.figsize'] = 20, 14 #Size of figs\nfig, ax = plt.subplots(1, 2, subplot_kw={'projection': 'hammer'})\nfig.suptitle(title, fontsize=30)\n\nfor galCoord in [0, 1]:\n    exposure_map = LoadExposureMap(totalExposure, nside, galCoord)\n    exposure_map_smoothed = LoadSmoothedMap(exposure_map, radius_deg, nside)\n    image = PlotHPmap(exposure_map_smoothed, nside, galCoord, title, color_bar_title, ax=ax[galCoord], fig=fig)\n\nfig.subplots_adjust(top=1.4)\ncbar_ax = fig.add_axes([0.25, 0.55, 0.5, 0.03])\ncb = fig.colorbar(image, orientation='horizontal', shrink=.6, pad=0.05, cax=cbar_ax)\ncb.set_label(color_bar_title, size=22)\n\n\n# Define title and the color bar title of the smoothed count map\ntitle = f\"Smoothed Count Map, $E >{Emin}$ EeV, $R = {radius_deg}\\\\degree$\"\ncolor_bar_title = r\"# events per pixel\"\n\n# Plot the two exposure map\nrcParams['figure.figsize'] = 20, 14 #Size of figs\nfig, ax = plt.subplots(1, 2, subplot_kw={'projection': 'hammer'})\nfig.suptitle(title, fontsize=30)\n\nfor galCoord in [0, 1]:\n    \n    dataset = LoadShapedData(galCoord, Emin)# data above 8 EeV\n    count_map = LoadCountMap(dataset, nside)\n    count_map_smoothed = LoadSmoothedMap(count_map, radius_deg, nside)\n    image = PlotHPmap(count_map_smoothed, nside, galCoord, title, color_bar_title, ax=ax[galCoord], fig=fig)\n\nfig.subplots_adjust(top=1.4)\ncbar_ax = fig.add_axes([0.25, 0.55, 0.5, 0.03])\ncb = fig.colorbar(image, orientation='horizontal', shrink=.6, pad=0.05, cax=cbar_ax)\ncb.set_label(color_bar_title, size=22)\n\nplt.show()\n","6b3565ae":"#LiMa significance map\ndef LiMaMap(nside, Non, Noff, alpha):\n    Non_log_term = (1. + alpha)*Non \/ (alpha*(Non + Noff))\n    Noff_log_term = (1. + alpha)*Noff \/ (Non + Noff)\n    \n    sig2_ov_2 = np.zeros_like(Non)\n    ind = np.where((Non > 0) & (alpha > 0))# ensures non negative log terms induced by smoothing\n    sig2_ov_2[ind] += Non[ind]*np.log(Non_log_term[ind])\n    ind = np.where(Noff > 0)# ensures non negative log terms induced by smoothing\n    sig2_ov_2[ind] += Noff[ind]*np.log(Noff_log_term[ind])\n\n    return np.sign(Non-alpha*Noff)*np.sqrt(np.abs(2*sig2_ov_2))\n\n# Parameters of the maps\nEmin = 8 # EeV\ngalCoord = True\nnside = 64\nradius_deg = 45 # top-hat radius in degrees\n\n# Exposure map\nexposure_map = LoadExposureMap(totalExposure, nside, galCoord)\nexposure_map_smoothed = LoadSmoothedMap(exposure_map, radius_deg, nside)\n\n# Count map\ndataset = LoadShapedData(galCoord, Emin) # data above 8 EeV\ncount_map = LoadCountMap(dataset, nside)\ncount_map_smoothed = LoadSmoothedMap(count_map, radius_deg, nside)\n\n# Flux-map\nflux_map = count_map_smoothed \/ exposure_map_smoothed \nra, dec = Get_ra_dec(nside, galCoord)\ndec_max = np.radians(24) # degrees corresponding to a 60\u00b0 maximum zenith angle\nflux_map[np.where(dec > dec_max)] = np.mean(flux_map[np.where(dec <= dec_max)]) #uniform above maximum dec\n\ntitle = f\"Smoothed Flux Map, $E > {Emin}$ EeV, $R = {radius_deg}\\\\degree$\"\ncolor_bar_title = r\"Flux [$\\rm km^{-2} \\, sr^{-1} \\, yr^{-1}$]\"\nPlotHPmap(flux_map, nside, galCoord, title, color_bar_title, cmap='twilight_shifted')\n\n# Normalize to the total number of events in the smoothing region\nsolid_angle_per_pix = 4.*np.pi \/ hp.nside2npix(nside)\nsolid_angle = 2.*np.pi * (1. - np.cos(np.radians(radius_deg)))\nnpix_per_region = solid_angle\/solid_angle_per_pix\n\n# alpha, Non, & Noff\nalpha = exposure_map_smoothed \/ (np.sum(exposure_map)\/npix_per_region - exposure_map_smoothed)\nNon = count_map_smoothed*npix_per_region\nNoff = np.sum(count_map) - Non\n\n# Significance map\nsig_map = LiMaMap(nside, Non, Noff, alpha) # Compute the significance map\nsig_map[np.where(dec > dec_max)] = 0 #uniform above maximum dec\nmax_map = np.max(np.abs(sig_map)) # Used to display a symmetric color scale\ntitle = f\"Significance Map, $E > {Emin}$ EeV, $R = {radius_deg}\\\\degree$\"\ncolor_bar_title = r\"Significance [$\\sigma$]\"\nPlotHPmap(sig_map, nside, galCoord, title, color_bar_title, cmap='twilight_shifted', vmin=-max_map, vmax=max_map)","55ca2220":"##### Data #############################################\ndef RA_Binning(ra, nbins, normalize=True):\n    \n    # Get the average flux, the error by binning in r.a. the flux_map\n    n_bin, bin_edges = np.histogram(ra, bins=nbins)\n    err_n_bin = np.sqrt(n_bin)\n    ra_bin = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n\n    # Normalize to average value\n    if(normalize):\n        weights = 1.\/(err_n_bin*err_n_bin)\n        average = np.sum(weights*n_bin)\/np.sum(weights)\n        n_bin = n_bin \/ average\n        err_n_bin = err_n_bin \/ average\n        \n    return ra_bin, n_bin, err_n_bin\n\n##### Fit ##############################################\ndef FuncConst(x, a):\n    return a*np.ones_like(x)\n\ndef FuncCos(x, a, b, c):\n    return (a + b*np.cos(np.radians(x)-c))\n\ndef Chi2_Const(par, args):\n    x, res, err = args[0], args[1], args[2]\n    return np.sum((res - FuncConst(x, par[0]))**2 \/ err**2)\n\ndef Chi2_Cos(par, args):\n    x, res, err = args[0], args[1], args[2]\n    return np.sum((res - FuncCos(x, par[0], par[1], par[2]))**2 \/ err**2)\n\ndef TwoSidedSignificance(prob):\n    return np.sqrt(2.)*erfcinv(prob)\n\ndef FitFirstHarmonics(ra_bin, n_bin, err_n_bin):\n\n    result_Sin, var_Sin = curve_fit(FuncCos, ra_bin, n_bin, sigma = err_n_bin, maxfev = 10000)\n    err_Sin = [np.sqrt(var_Sin[i][i]) for i in range(3)]\n\n    chi2_Sin = Chi2_Cos(result_Sin, [ra_bin,n_bin,err_n_bin])\n    \n    result_Const, var_Const = curve_fit(FuncConst, ra_bin, n_bin, sigma = err_n_bin, maxfev = 10000)\n    chi2_Const = Chi2_Const(result_Const, [ra_bin,n_bin,err_n_bin])\n    \n    prob = chi2.sf(chi2_Const - chi2_Sin, df=2)\n    sigma = TwoSidedSignificance(prob)\n    \n    display(Latex(f'''With $\\chi^2$ statistics, the first harmonic is preferred at {sigma:4.1f} sigma compared to isotropy, with parameters:\n    \\\\begin{{align}}\n    \\\\Phi_0 &= {result_Sin[0]:0.3f} \\pm {err_Sin[0]:0.3f}\\\\\\\\\n    r &=  {result_Sin[1]:0.3f} \\pm {err_Sin[1]:0.3f}\\\\\\\\\n    \\\\alpha_0 &= {np.degrees(result_Sin[2]):4.0f}^\\\\circ \\pm {np.degrees(err_Sin[2]):4.0f}^\\\\circ \\\\\\\\\n    \\\\end{{align}}\n    '''))\n    return result_Sin, result_Const\n\n##### Rayleigh analysis ################################\ndef Rayleigh(ra):\n    a = 2. * np.sum(np.cos(np.radians(ra))) \/ ra.size\n    b = 2. * np.sum(np.sin(np.radians(ra))) \/ ra.size\n    alpha0 = np.arctan2(b,a)\n    r = np.sqrt(a*a + b*b)\n    \n    p = np.exp(-ra.size*r*r\/4.)\n    sigma = TwoSidedSignificance(p)\n    \n    err_r = np.sqrt(2.\/ra.size)\n    err_alpha0 = np.sqrt(2.\/ra.size) \/ r\n    \n    display(Latex(f'''With Rayleigh statistics, the first harmonic is preferred at {sigma:2.1f} sigma compared to isotropy, with parameters:\n    \\\\begin{{align}}\n    r &= {r:5.2} \\\\pm {err_r:5.2}\\\\\\\\\n    \\\\alpha_0 &= {np.degrees(alpha0):4.0f}^\\\\circ \\pm {np.degrees(err_alpha0):4.0f}\\\\\\\\\n    \\\\end{{align}}\n    '''))\n    return r, alpha0\n\n##### Main #############################################\n# Load the dataset\nEmin = 8# EeV\nra_sel = data.sd_ra[data.sd_energy > Emin]\nra_sel[ra_sel < 0] += 360. # change [-180\u00b0 , 180\u00b0] to [0\u00b0 , 360\u00b0]\n\n# Rayleigh analysis\nr, alpha0 = Rayleigh(ra_sel)\n\n# Bin and fit the data\nnbins = 12 #Number of bin used\nra_bin, n_bin, err_n_bin = RA_Binning(ra_sel, nbins)\nresRayleigh, resConst = FitFirstHarmonics(ra_bin, n_bin, err_n_bin)\n\n# Create the figure\nwidth = 15# width of the figure\nfig = plt.figure(figsize=(width, width\/1.5))\nax = fig.add_subplot(111)\nax.set_xlabel(\"Right Ascension [deg]\")\nax.set_ylabel(\"Normalized rate\")\nplt.xticks(np.arange(0, 360 + 1, 60))\nax.invert_xaxis()\nplt.xlim(360, 0.)\n    \n# Plot the data\nxplot = np.linspace(0, 360, 100)\nax.plot(xplot, FuncConst(xplot, resConst), label=\"Constant fit (isotropy)\")\nax.plot(xplot, FuncCos(xplot, resRayleigh[0], resRayleigh[1], resRayleigh[2]), label=\"First harmonic fit\")\nax.plot(xplot, FuncCos(xplot, 1, r, alpha0), label=\"Rayleigh analysis\")\nax.errorbar(ra_bin, n_bin, yerr=err_n_bin, fmt='o', label=\"Data E > \"+str(Emin)+\" EeV\")\nplt.legend(loc=\"lower right\")\nplt.show()","9b982387":"## Rayleigh analysis in right ascension\n\nA Rayleigh analysis in right ascension can be performed to quantify any possible large-scale anisotropy of the flux, described as $\\Phi = \\Phi_0 \\times (1+r_\\alpha\\,\\cos(\\alpha-\\alpha_0))$. The robustness of such an analysis lies in the constancy of the exposure of the Observatory as a function of right ascension. The analysis presented here is simplified with respect to that performed in The Pierre Auger Collaboration (2017), Science 357, 6357, 1266, https:\/\/science.sciencemag.org\/content\/357\/6357\/1266, https:\/\/arxiv.org\/abs\/1709.07321: small non-uniformities in the exposure of the array as a function of right ascension and the tilt of the array towards the south-east are not accounted for.\n\nThe Rayleigh analysis in right ascension consists in determining the amplitude, $r_\\alpha$, and phase, $\\phi_\\alpha$, of the first-harmonic Fourier component as\n\n$r_\\alpha = \\sqrt{a_\\alpha^2 + b_\\alpha^2}$,\n\n$\\tan \\alpha_0 = b_\\alpha\/a_\\alpha$,\n\nwhere $a_\\alpha = \\frac{2}{N} \\sum_{i=1}^{N} \\cos \\alpha_i$ and $b_\\alpha = \\frac{2}{N} \\sum_{i=1}^{N} \\sin \\alpha_i$ and where $N$ is the number of events. The probability that an amplitude larger than $r_\\alpha$ arises from isotropy can be computed as $P(r_\\alpha) = \\exp(-Nr_\\alpha^2\/4)$. \n\nThe uncertainties of the Fourier parameters, $a_\\alpha$ and $b_\\alpha$, are analytical and such as $\\sigma_{a_{\\alpha}}=\\sigma_{b_{\\alpha}}=\\sqrt{\\frac{2}{N}}$. For the sake of simplicity, we adopt a simple propagation of the uncertainties, which yields $\\sigma_{r_{\\alpha}} = \\sqrt{\\frac{2}{N}}$ and $\\sigma_{\\alpha_0} = \\frac{1}{r_{\\alpha}}\\sqrt{\\frac{2}{N}}$. Note that this simple propagation of uncertainties fails for values of $a_\\alpha$ and $b_\\alpha$ that are compatible with zero. A full marginalization should be performed as in the above-mentioned publication to obtain refined uncertainties.\n\nWe compare below the Rayleigh approach to a $\\chi^2$ difference test, where both a cosine-modulated and a constant model are fitted to the data binned in right ascension. The uncertainties on the parameters are extracted from the diagonal terms of the covariance matrix.","5b439684":"The flux map appears to differ from the one published in The Pierre Auger Collaboration (2017), Science 357, 6357, 1266, https:\/\/science.sciencemag.org\/content\/357\/6357\/1266, https:\/\/arxiv.org\/abs\/1709.07321: with only 10% of the data, one mostly observes fluctuations due to the limited statistics.\n\nLarge-scale deviations from isotropy as function of right ascension can be further quantified, as shown in the following section.","daaee92c":"With only events up to zenith angles of 60\u00b0 and 10% of the full dataset, neither the Rayleigh analysis nor the $\\chi^2$ test yield any significant deviation from isotropy.","212e580d":"This is the kaggle version of a Pierre Auger Observatory Open Data notebook. You can run it by clicking on \"Copy and Edit\" in the top right corner.\n\nNote that in order to run, this notebook needs to install \"healpy\" which will take a few seconds at the beginning.","5c5cbaa4":"## Smoothed flux and significance maps\n\nThe flux map is obtained here as the ratio of the smoothed count and exposure maps, resulting in a flux estimate $\\Phi_{\\cal{R}} = \\sum_{{\\rm pix} \\in {\\cal{R}}} N_{\\rm pix} \/\\sum_{{\\rm pix} \\in {\\cal{R}}} \\omega_{\\rm pix}$, where $N_{\\rm pix}$ is the number of events in a given pixel and $\\omega_{\\rm pix}$ the associated exposure over a region $\\cal{R}$ defined as a disk of used-defined radius. It should be noted that an alternative convention could consist in estimating the flux as $\\sum_{{\\rm pix} \\in \\cal{R}} N_{\\rm pix} \/ \\omega_{\\rm pix}$. Both approaches result in consistent estimates away from the border of the field of view of the Observatory. We adopt the first convention for the sake of simplicity. \n\nThe validity of the smoothing is limited at large declinations ($\\delta > 24\u00b0$ for a maximum zenith angle of 60\u00b0), above which the exposure is close to zero. To avoid divisions by zero, pixels above the maximum declination are discarded when displaying the flux map. It should be noted that along this limit about half of the smoothing disk is filled with events or with a non-zero exposure. The aim being to highlight possible dipolar features in the flux map, the latter is displayed with a diverging color map, contrarily to exposure and count maps which are displayed with sequential colormaps.\n\nThe significance of an excess, or lack, of events in a given region with respect to the rest of the sky is estimated as in Biteau J. et al. (UHECR 2018), EPJ Web of Conferences 210, 01005, https:\/\/www.epj-conferences.org\/articles\/epjconf\/abs\/2019\/15\/epjconf_uhecr18_01005\/epjconf_uhecr18_01005.html, https:\/\/arxiv.org\/abs\/1905.04188. Local significances are determined with the LiMa method (Li & Ma, Astrophysical Journal, Vol. 272, www.doi.org\/10.1086\/161295, Eq. 17). Such local significances do not account for the scan of direction of the center of the test region.\n\nFor a single pixel, the significance is given by $\\small S= \\sqrt{2} \\times \\sqrt{N_{\\rm on} \\log \\left[ \\frac{1+\\alpha}{\\alpha} \\big( \\frac{N_{\\rm on}}{N_{\\rm on} + N_{\\rm off}}\\big) \\right] + N_{\\rm off} \\log \\left[ (1+\\alpha) \\big( \\frac{N_{\\rm off}}{N_{\\rm on} + N_{\\rm off}}\\big) \\right]} \\times {\\rm sign}({\\rm XS})$,\n\nwhere $N_{\\rm on}$ corresponds to the number of events counted in the region of interest (ON region), $N_{\\rm off}$ corresponds to the number of background events counted in the rest of the sky (OFF region), $\\alpha$ is the ratio of the exposures of the ON and OFF regions, and where ${\\rm XS} = N_{\\rm on} - \\alpha\\times N_{\\rm off}$ is the number of events in excess in the ON region with respect to the background.","f6bef406":"## Loading the dataset\n\nThe released data can be retrieved from the git directory: https:\/\/gitlab.com\/auger-observatory\/drt\/csvfiles. Ten percent of the data accumulated by the Pierre Auger Observatory are stored in the file \"dataSummary.csv\" which contains, among many pieces of information, the energy, the Galactic & equatorial coordinates of each event and the value of the exposure at the arrival time of the event. The released events have been selected below a zenith angle $60^\\circ$ and above an energy $E>2.5$ EeV, for which the full efficiency of the surface detector is reached.\nWe load below the dataset.","ef99900e":"## Healpy coordinates\n\nThe `healpy` package, which is based on the C++ library `HEALPix` (https:\/\/healpy.readthedocs.io\/), is used to bin the data on the celestial sphere.\n\n`HEALPix` uses classical spherical coordinates ($\\theta, \\phi$) that are directly linked to Galactic coordinates ($l = \\phi_{\\rm G}$, $b = 90^\\circ - \\theta_{\\rm G}$), where the Galactic Center ($l = 0^\\circ$, $b = 0^\\circ$) is at the origin, or to equatorial coordinates ($\\alpha = \\phi_{E} - 180^\\circ$, $\\delta = 90^\\circ - \\theta_{\\rm E}$), where ($\\alpha = 180^\\circ$, $\\delta = 0^\\circ$) is at the origin. We define in the raw code the function `HealpyCoordToMap`, which converts the spherical coordinates used by `HEALPix` ($\\phi$, $\\theta$) to Galactic coordinates (l,b) if `galCoord == True`, or to equatorial coordinates ($\\alpha$, $\\delta$) if `galCoord == False`. The inverse function `MapToHealpyCoord` is also defined. \n\nThe function `LoadShapedData` loads the arrival directions of events above an energy threshold, $E_{\\rm min}$, and returns a shaped dataset stored in a single Pandas DataFrame.","d7d52603":"We select the relevant columns for the anisotropy analysis and print out the characteristics of one random event in the dataset.","b31ada05":"## Count map\n\nA `HEALPix` map is defined by the size of its binning through the parameter `NSIDE` (generally a power of 2, see https:\/\/lambda.gsfc.nasa.gov\/toolbox\/tb_pixelcoords.cfm). The function `LoadCountMap` stores arrival directions of events with an energy above a user-defined threshold energy, $E_\\mathrm{min}$, into a `HEALPix` map (a 1D numpy array). The function `PlotHPmap` displays, using `matplotlib`, the map in the chosen coordinate system, as illustrated below.","fe946493":"## Smoothed count and exposure maps\n\nOne may wish to display smoothed maps to highlight features on a specific angular scale. A top-hat smoothing with a 45\u00b0 radius is used here, as in The Pierre Auger Collaboration, Science 357, 6357, 1266, https:\/\/science.sciencemag.org\/content\/357\/6357\/1266, https:\/\/arxiv.org\/abs\/1709.07321. Both the energy threshold and the smoothing radius can be changed by the user.","84b7a437":"## Exposure map\n\nThe exposure of the Pierre Auger Observatory surface detector is purely geometric (see Sommers P., Astroparticle Physics 2001, 271 - https:\/\/www.sciencedirect.com\/science\/article\/abs\/pii\/S0927650500001304?via%3Dihub, https:\/\/arxiv.org\/abs\/astro-ph\/0004016) and depends on declination in equatorial coordinates. $\\tt Astropy$ (https:\/\/www.astropy.org\/) is used here to switch from equatorial coordinates to Galactic coordinates when needed.","6221c9c1":"![PierreAugerObservatoryLogo.jpg](attachment:PierreAugerObservatoryLogo.jpg)\n# Large-scale anisotropy study of data from the Pierre Auger Observatory\n\n<i>Notebook released together with the Pierre Auger Observatory Open Data release 2021 (<a href=\"https:\/\/doi.org\/10.5281\/zenodo.4487613\">DOI 10.5281\/zenodo.4487613<\/a>). More information at the <a href=\"https:\/\/www.auger.org\/opendata\/\">Auger open data website<\/a>.<\/i>\n\nThis jupyter notebook loads the data released by the Pierre Auger Collaboration and displays on the sphere the arrival directions of events above a threshold energy ($E > E_{\\rm min}$). A Rayleigh analysis in right ascension is performed, whose results can be compared with those published in The Pierre Auger Collaboration (2017), Science 357, 6357, 1266, https:\/\/science.sciencemag.org\/content\/357\/6357\/1266, https:\/\/arxiv.org\/abs\/1709.07321. "}}