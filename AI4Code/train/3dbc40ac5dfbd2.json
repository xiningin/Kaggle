{"cell_type":{"e6fa4c16":"code","240d841c":"code","8a2d792e":"code","c2509b44":"code","04ed3fb6":"code","b9c433f4":"code","cbad9143":"code","2305f6ff":"code","e229d971":"code","e1c55ba0":"code","26bba452":"code","c9766a45":"code","ae7a45ed":"code","a7dfa544":"code","a2166295":"code","556acf68":"code","a23b4aaa":"code","08924b7a":"code","b9b4a52c":"code","f872c99a":"code","6fbf2656":"code","98990a97":"code","16b1a423":"code","dde02ffd":"code","6634b7e5":"code","cd9bb763":"markdown","09c88f33":"markdown","91359570":"markdown","df14697a":"markdown"},"source":{"e6fa4c16":"%cd \/opt","240d841c":"%%capture\n!tar xvf \/kaggle\/input\/extract-prebuilt-kaldi-from-docker\/kaldi.tar","8a2d792e":"%cd \/tmp","c2509b44":"!git clone https:\/\/github.com\/pytorch\/fairseq\/","04ed3fb6":"%%capture\n!pip install phonemizer","b9c433f4":"%%capture\n!pip install git+https:\/\/github.com\/pytorch\/fairseq\/","cbad9143":"%%capture\n!apt-get -y install espeak","2305f6ff":"!git clone https:\/\/github.com\/kpu\/kenlm","e229d971":"%%capture\n!apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev","e1c55ba0":"%%capture\n%cd kenlm\n!mkdir build\n%cd build\n!cmake ..\n!make -j 4\n%cd \/tmp","26bba452":"import os\nos.environ['PATH'] = f\"{os.environ['PATH']}:\/tmp\/kenlm\/build\/bin\/\"\nos.environ['FAIRSEQ_ROOT'] = '\/tmp\/fairseq'","c9766a45":"!cat \/kaggle\/input\/wav2vec-u-cv-swedish-audio\/*.wrd | grep -v '^$' | sort| uniq > \/kaggle\/working\/sentences.txt\n","ae7a45ed":"%cd fairseq\/examples\/wav2vec\/unsupervised","a7dfa544":"%%capture\n!apt-get -y install zsh","a2166295":"!mkdir \/kaggle\/working\/preppedtext","556acf68":"%cd scripts","a23b4aaa":"!wget https:\/\/dl.fbaipublicfiles.com\/fasttext\/supervised-models\/lid.176.bin","08924b7a":"!cat normalize_and_filter_text.py|sed -e 's\/187\/176\/' > tmp\n!mv tmp normalize_and_filter_text.py","b9b4a52c":"# Needed to see what's going wrong\nos.environ['HYDRA_FULL_ERROR'] = '1'","f872c99a":"import os\nos.environ['LD_LIBRARY_PATH'] = '\/opt\/conda\/lib:\/opt\/kaldi\/tools\/openfst-1.6.7\/lib:\/opt\/kaldi\/src\/lib'","6fbf2656":"!mkdir \/tmp\/fairseq\/examples\/speech_recognition\/kaldi\/config\/","98990a97":"%%writefile \/tmp\/fairseq\/examples\/speech_recognition\/kaldi\/config\/config.yaml\nkaldi_root: \"\/opt\/kaldi\"","16b1a423":"%%writefile prepare_text.sh\n#!\/usr\/bin\/env zsh\n# Copyright (c) Facebook, Inc. and its affiliates.\n#\n# This source code is licensed under the MIT license found in the\n# LICENSE file in the root directory of this source tree.\n\nlg=$1\ntext_path=$2\ntarget_dir=$3\n\n#ph_lg=${lg:l}\n#if test \"$lg\" = 'fr'; then\n#  ph_lg='fr-fr'\n#elif test \"$lg\" = 'en'; then\n#  ph_lg='en-us'\n#elif test \"$lg\" = 'pt'; then\n#  ph_lg='pt-br'\n#fi\nph_lg=\"sv\"\n\necho $lg\necho $ph_lg\necho $text_path\necho $target_dir\n\nmkdir -p $target_dir\n#python normalize_and_filter_text.py --lang $lg < $text_path | grep -v '\\-\\-\\-' >! $target_dir\/lm.upper.lid.txt\n#python $FAIRSEQ_ROOT\/fairseq_cli\/preprocess.py --dataset-impl mmap --trainpref $target_dir\/lm.upper.lid.txt --only-source --destdir $target_dir --thresholdsrc 2 --padding-factor 1 --dict-only\n#cut -f1 -d' ' $target_dir\/dict.txt | grep -v -x '[[:punct:]]*' | grep -Pv '\\d\\d\\d\\d\\d+' >! $target_dir\/words.txt\ncp \/kaggle\/input\/wav2vec-u-cv-swedish-audio\/train.wrd $target_dir\/lm.upper.lid.txt\ncut -f1 -d' ' \/kaggle\/input\/wav2vec-u-cv-swedish-audio\/dict.train >! $target_dir\/words.txt\n\n#one=$(echo \"1\" | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -p ' ' -w '' -l $ph_lg --language-switch remove-flags)\n#sed 's\/$\/ 1\/' $target_dir\/words.txt | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -o $target_dir\/phones.txt -p ' ' -w '' -l $ph_lg -j 70 --language-switch remove-flags\ncut -f2- -d' ' \/kaggle\/input\/wav2vec-u-cv-swedish-audio\/dict.train >! $target_dir\/phones.txt\n\n#echo \"one is ${one}\"\n\n#sed -i \"s\/${one}$\/\/\" $target_dir\/phones.txt\n#paste $target_dir\/words.txt $target_dir\/phones.txt >! $target_dir\/lexicon.lst\ncp \/kaggle\/input\/wav2vec-u-cv-swedish-audio\/dict.train $target_dir\/lexicon.lst\n\n#python $FAIRSEQ_ROOT\/fairseq_cli\/preprocess.py --dataset-impl mmap --trainpref $target_dir\/phones.txt --only-source --destdir $target_dir\/phones --thresholdsrc 1000 --padding-factor 1 --dict-only\npython $FAIRSEQ_ROOT\/fairseq_cli\/preprocess.py --dataset-impl mmap --trainpref $target_dir\/phones.txt --only-source --destdir $target_dir\/phones --thresholdsrc 2 --padding-factor 1 --dict-only\n\npython filter_lexicon.py -d $target_dir\/phones\/dict.txt < $target_dir\/lexicon.lst >! $target_dir\/lexicon_filtered.lst\npython phonemize_with_sil.py -s 0.25 --surround --lexicon $target_dir\/lexicon_filtered.lst < $target_dir\/lm.upper.lid.txt >! $target_dir\/phones\/lm.phones.filtered.txt\ncp $target_dir\/phones\/dict.txt $target_dir\/phones\/dict.phn.txt\necho \"<SIL> 0\" >> $target_dir\/phones\/dict.phn.txt\npython $FAIRSEQ_ROOT\/fairseq_cli\/preprocess.py --dataset-impl mmap --trainpref $target_dir\/phones\/lm.phones.filtered.txt --workers 70 --only-source --destdir $target_dir\/phones --srcdict $target_dir\/phones\/dict.phn.txt\n\nlmplz -o 4 < $target_dir\/lm.upper.lid.txt --discount_fallback --prune 0 0 0 3 >! $target_dir\/kenlm.wrd.o40003.arpa\nbuild_binary $target_dir\/kenlm.wrd.o40003.arpa $target_dir\/kenlm.wrd.o40003.bin\nlg=$lg python $FAIRSEQ_ROOT\/examples\/speech_recognition\/kaldi\/kaldi_initializer.py fst_dir=$target_dir\/fst\/phn_to_words_sil lm_arpa=$target_dir\/kenlm.wrd.o40003.arpa wav2letter_lexicon=$target_dir\/lexicon_filtered.lst data_dir=$target_dir\/phones \"blank_symbol='<SIL>'\" \"in_labels='phn'\" \"kaldi_root='\/opt\/kaldi'\"\nlg=$lg python $FAIRSEQ_ROOT\/examples\/speech_recognition\/kaldi\/kaldi_initializer.py fst_dir=$target_dir\/fst\/phn_to_words lm_arpa=$target_dir\/kenlm.wrd.o40003.arpa wav2letter_lexicon=$target_dir\/lexicon_filtered.lst data_dir=$target_dir\/phones  \"in_labels='phn'\" \"kaldi_root='\/opt\/kaldi'\"\n\nlmplz -o 4 < $target_dir\/phones\/lm.phones.filtered.txt --discount_fallback >! $target_dir\/phones\/lm.phones.filtered.04.arpa\nbuild_binary -s $target_dir\/phones\/lm.phones.filtered.04.arpa $target_dir\/phones\/lm.phones.filtered.04.bin\nlmplz -o 6 < $target_dir\/phones\/lm.phones.filtered.txt --discount_fallback >! $target_dir\/phones\/lm.phones.filtered.06.arpa\nbuild_binary -s $target_dir\/phones\/lm.phones.filtered.06.arpa $target_dir\/phones\/lm.phones.filtered.06.bin\n\nlg=$lg python $FAIRSEQ_ROOT\/examples\/speech_recognition\/kaldi\/kaldi_initializer.py fst_dir=$target_dir\/fst\/phn_to_phn_sil lm_arpa=$target_dir\/phones\/lm.phones.filtered.06.arpa data_dir=$target_dir\/phones \"blank_symbol='<SIL>'\" \"in_labels='phn'\" \"kaldi_root='\/opt\/kaldi'\"","dde02ffd":"%%writefile \/tmp\/fairseq\/examples\/speech_recognition\/kaldi\/add-self-loop-simple.cc\n\/*\n* Copyright (c) Facebook, Inc. and its affiliates.\n*\n* This source code is licensed under the MIT license found in the\n* LICENSE file in the root directory of this source tree.\n*\/\n\n#include <iostream>\n#include \"fstext\/fstext-lib.h\" \/\/ @manual\n#include \"util\/common-utils.h\" \/\/ @manual\n\n\/*\n * This program is to modify a FST without self-loop by:\n *   for each incoming arc with non-eps input symbol, add a self-loop arc\n *   with that non-eps symbol as input and eps as output.\n *\n * This is to make sure the resultant FST can do deduplication for repeated\n * symbols, which is very common in acoustic model\n *\n *\/\nnamespace {\nint32 AddSelfLoopsSimple(fst::StdVectorFst* fst) {\n  typedef fst::MutableArcIterator<fst::StdVectorFst> IterType;\n\n  int32 num_states_before = fst->NumStates();\n  fst::MakePrecedingInputSymbolsSame(false, fst);\n  int32 num_states_after = fst->NumStates();\n  KALDI_LOG << \"There are \" << num_states_before\n            << \" states in the original FST; \"\n            << \" after MakePrecedingInputSymbolsSame, there are \"\n            << num_states_after << \" states \";\n\n  auto weight_one = fst::StdArc::Weight::One();\n\n  int32 num_arc_added = 0;\n\n  fst::StdArc self_loop_arc;\n  self_loop_arc.weight = weight_one;\n\n  int32 num_states = fst->NumStates();\n  std::vector<std::set<int32>> incoming_non_eps_label_per_state(num_states);\n\n  for (int32 state = 0; state < num_states; state++) {\n    for (IterType aiter(fst, state); !aiter.Done(); aiter.Next()) {\n      fst::StdArc arc(aiter.Value());\n      if (arc.ilabel != 0) {\n        incoming_non_eps_label_per_state[arc.nextstate].insert(arc.ilabel);\n      }\n    }\n  }\n\n  for (int32 state = 0; state < num_states; state++) {\n    if (!incoming_non_eps_label_per_state[state].empty()) {\n      auto& ilabel_set = incoming_non_eps_label_per_state[state];\n      for (auto it = ilabel_set.begin(); it != ilabel_set.end(); it++) {\n        self_loop_arc.ilabel = *it;\n        self_loop_arc.olabel = 0;\n        self_loop_arc.nextstate = state;\n        fst->AddArc(state, self_loop_arc);\n        num_arc_added++;\n      }\n    }\n  }\n  return num_arc_added;\n}\n\nvoid print_usage() {\n  std::cout << \"add-self-loop-simple usage:\\n\"\n               \"\\tadd-self-loop-simple <in-fst> <out-fst> \\n\";\n}\n} \/\/ namespace\n\nint main(int argc, char** argv) {\n  if (argc != 3) {\n    print_usage();\n    exit(1);\n  }\n\n  auto input = argv[1];\n  auto output = argv[2];\n\n  auto fst = fst::ReadFstKaldi(input);\n  auto num_states = fst->NumStates();\n  KALDI_LOG << \"Loading FST from \" << input << \" with \" << num_states\n            << \" states.\";\n\n  int32 num_arc_added = AddSelfLoopsSimple(fst);\n  KALDI_LOG << \"Adding \" << num_arc_added << \" self-loop arcs \";\n\n  fst::WriteFstKaldi(*fst, std::string(output));\n  KALDI_LOG << \"Writing FST to \" << output;\n\n  delete fst;\n}","6634b7e5":"!zsh prepare_text.sh sv \/kaggle\/working\/sentences.txt \/kaggle\/working\/preppedtext","cd9bb763":"`add-self-loop-simple.cc` attempts to use `std::endl` with `KALDI_LOG`, which doesn't work, so rewrite that (I'm not sure if this actually prevents anything from working, but it is really distracting).","09c88f33":"Config options for `kaldi_initializer.py`\n\n- `in_labels`: a naming component, for the Kaldi lexicons\/fsts (required)\n- `wav2letter_lexicon`: path to wav2letter lexicon\n- `out_labels`: a naming component, for the Kaldi lexicons\/fsts: set to `in_label` if missing\n- `kaldi_root`: path to Kaldi: `\/opt\/kaldi` for my kaggle image\n- `fst_dir`: path where generated fsts will be saved\n- `data_dir`: path to phones data\n- `lm_arpa`: path to the lm in ARPA format\n- `blank_symbol`: CTC blank symbol (`<s>` here)\n- `silence_symbol`: Kaldi symbol for silence (`<SIL>` is set for two of the scripts)\n\nA config file needs to exist for this, even though the options set in it seem to be ignored.","91359570":"There are two lines with missing variables in `prepare_text.sh` - [pull request](https:\/\/github.com\/pytorch\/fairseq\/pull\/3569) - so replace the file.\n\nWhile I'm replacing the file: most of the first part of the script is unneeded, as I already have a phonetic dictionary, so I'm use that instead.\n\nWith the calls of the `preprocess.py` script, make sure to check the threshold: there's a divide by zero if the threshold is set too high.","df14697a":"The next part requires a FastText language id model; I don't know where the 187 language model comes from, but there is a model for 176 languages [here](https:\/\/fasttext.cc\/docs\/en\/language-identification.html#content)"}}