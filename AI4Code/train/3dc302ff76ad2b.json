{"cell_type":{"59177627":"code","2f6e965e":"code","df5f6f36":"code","2104f0dd":"code","5be5da20":"code","85f9f2d1":"code","ec3d507a":"code","74c8813e":"code","d2f38302":"code","8333635e":"code","05b6274c":"code","c6890cd3":"code","118723c8":"code","e21cffda":"code","de7741d4":"code","2746db03":"code","c8309314":"code","954d0984":"code","09192af8":"code","f6e9f5f8":"code","d310adf4":"code","62807871":"code","d09caa18":"code","16d183b4":"code","ca1febcb":"code","88f87609":"code","a9c0d061":"code","11cbcb44":"code","7710884f":"code","f865feaa":"code","80ada2b1":"code","d98ed398":"code","0b5de458":"code","7439290b":"code","63b4ff87":"code","4ce2d95d":"code","3f7e24c4":"code","5337a155":"code","fe305b33":"code","cab0aaf4":"code","154cbed9":"code","d2b4bd75":"code","1b81cde7":"code","2c29ff99":"markdown","f552b91a":"markdown","d8f58600":"markdown","a23bce75":"markdown","b94ce157":"markdown","940de402":"markdown","efb200c1":"markdown","79cc4b93":"markdown","86aa23cb":"markdown","990a58ed":"markdown","82c20a15":"markdown","b0b3ba7b":"markdown","701cfbaa":"markdown","afabd290":"markdown","94f8e357":"markdown","443b0fa8":"markdown","abce20a1":"markdown","466cf11b":"markdown","00676f28":"markdown","7c194813":"markdown","d3406734":"markdown"},"source":{"59177627":"import pandas as pd\npd.pandas.set_option('display.max_columns', 20)\n# Ensures that the output is on a single line.\npd.set_option('display.expand_frame_repr', False)","2f6e965e":"def create_user_movie_df():\n    import pandas as pd\n    movie = pd.read_csv('..\/input\/movielens-20m-dataset\/movie.csv')\n    rating = pd.read_csv('..\/input\/movielens-20m-dataset\/rating.csv')\n    df = movie.merge(rating, how=\"left\", on=\"movieId\")\n    comment_counts = pd.DataFrame(df[\"title\"].value_counts())\n    rare_movies = comment_counts[comment_counts[\"title\"] <= 1000].index\n    common_movies = df[~df[\"title\"].isin(rare_movies)]\n    user_movie_df = common_movies.pivot_table(index=[\"userId\"], columns=[\"title\"], values=\"rating\")\n    return user_movie_df\n# We can use this function directly in our operations.","df5f6f36":"user_movie_df = create_user_movie_df()\nuser_movie_df.iloc[0:5,0:5]","2104f0dd":"random_user = 108170\n#Let's reduce our data according to the user we have determined.\nrandom_user_df = user_movie_df[user_movie_df.index == random_user]\nrandom_user_df\n","5be5da20":"# We call random_user_df's columns without 'na' and assign it to a list.\nmovies_watched = random_user_df.columns[random_user_df.notna().any()].tolist()\nlen(movies_watched)","85f9f2d1":"movies_watched_df= user_movie_df[movies_watched]\n# Here, we assigned the reduced dataframe based on the movies watched \n# by the user we specified here, to our movies_wached_df variable.\nmovies_watched_df.head()","ec3d507a":"movies_watched_df.shape","74c8813e":"# We reduced user_movie_df according to the movies watched by random_user.\nuser_movie_count = movies_watched_df.T.notnull().sum() \nuser_movie_count.head()\n# The information came about how many movies they watched together with the random user.","d2f38302":"user_movie_count=user_movie_count.reset_index()\nuser_movie_count.head()","8333635e":"user_movie_count.columns=['userId','movie_count']\nuser_movie_count.head()\n# We have obtained the number of movies that these users watch together with the user.","05b6274c":"perc = len(movies_watched) * 60 \/ 100\nusers_same_movies = user_movie_count[user_movie_count[\"movie_count\"] > perc][\"userId\"]\nusers_same_movies\n# Now, we said that the number of movies watched jointly by the user and other users should be above 60%.","c6890cd3":"users_same_movies.count()","118723c8":"users_same_movies.head()\n","e21cffda":"final_df = movies_watched_df[movies_watched_df.index.isin(users_same_movies)]\nfinal_df.head()\n# We have brought the information of users watching 60% of the common movies.","de7741d4":"final_df.shape","2746db03":"#Now let's create our correlation matrix. User ids must be in columns. So we got the transpose.\nfinal_df.T.corr().head()","c8309314":"# If we apply unstack to this code to observe better, our matrix will be as follows.\nfinal_df.T.corr().unstack().head()","954d0984":"# Now, let's assign this correlation to the corr_df variable in order from largest to smallest.\ncorr_df=final_df.T.corr().unstack().sort_values()\ncorr_df.head()","09192af8":"type(corr_df)","f6e9f5f8":"# Let's convert the corr_df matrix to the pandas dataframe and assign the column name to corr.\ncorr_df = pd.DataFrame(corr_df,columns=['corr'])\ncorr_df.head()","d310adf4":"# We are changing the names of the user ids to make it easier to understand.\ncorr_df.index.names=['user_id_1','user_id_2']\ncorr_df.head()","62807871":"# Let's reset_index user_id1 and user_id2 to make columns.\ncorr_df=corr_df.reset_index()\ncorr_df.head()","d09caa18":"corr_df[(corr_df[\"user_id_1\"] == random_user)].sort_values('corr',ascending=False)","16d183b4":"top_users = corr_df[(corr_df[\"user_id_1\"] == random_user) & (corr_df[\"corr\"] >= 0.65)][\n                                                [\"user_id_2\", \"corr\"]].reset_index(drop=True)\ntop_users\n# Those with a correlation higher than 65% came in.","ca1febcb":"top_users = top_users.sort_values(by='corr', ascending=False)\n# Let's order from largest to smallest.\ntop_users\n#The first value is random_user itself. The others have the most similar features to random_user.","88f87609":"top_users.rename(columns={\"user_id_2\": \"userId\"}, inplace=True)\n# Let's rename user_id_2 using the rename method.\ntop_users","a9c0d061":"rating = pd.read_csv('..\/input\/movielens-20m-dataset\/rating.csv')\ntop_users_ratings = top_users.merge(rating[[\"userId\", \"movieId\", \"rating\"]], how='inner')\ntop_users_ratings.head(5)\n# Here we are reading the rating data again. \n# And we merge with top_users in order to reach the rating information of the users through the intersection.","11cbcb44":"# Let's remove random_user from top_users_ratings.\ntop_users_ratings = top_users_ratings[top_users_ratings[\"userId\"] != random_user]\ntop_users_ratings.head(5)","7710884f":"# So let's multiply the correlations and ratings and find the Weighted Average Score.\ntop_users_ratings['weighted_rating'] = top_users_ratings['corr'] * top_users_ratings['rating']\ntop_users_ratings.head()","f865feaa":"recommendation_df=top_users_ratings.groupby('movieId').agg({\"weighted_rating\": \"mean\"})\n# Let's get groupby by movieId to find movies to recommend. \nrecommendation_df","80ada2b1":"recommendation_df = recommendation_df.reset_index()\nrecommendation_df.head(5)","d98ed398":"recommendation_df.shape","0b5de458":"recommendation_df['weighted_rating'].max()","7439290b":"recommendation_df['weighted_rating'].min()","63b4ff87":"recommendation_df[recommendation_df[\"weighted_rating\"] > 3.5]\n# By looking at the maximum and minimum values of Weighted_rating, we can say that those above 3.5 should come. ","4ce2d95d":"movies_to_be_recommend = recommendation_df[recommendation_df[\"weighted_rating\"] > 3.5].sort_values(\"weighted_rating\", ascending=False)[0:5]\nmovies_to_be_recommend","3f7e24c4":"# Since the names are in the movie data, let's read the movie data again.\nmovie = pd.read_csv('..\/input\/movielens-20m-dataset\/movie.csv')\nmovie.head()","5337a155":"# Let's merge the movieId and title columns of the movie data with the recommended movieId.\nmovies_to_be_recommend.merge(movie[[\"movieId\", \"title\"]]).head()","fe305b33":"user = 108170\n\nmovie = pd.read_csv('..\/input\/movielens-20m-dataset\/movie.csv')\nrating = pd.read_csv('..\/input\/movielens-20m-dataset\/rating.csv')","cab0aaf4":"\nmovie_id = rating[(rating[\"userId\"] == user) & (rating[\"rating\"] == 5.0)]. \\\n               sort_values(by=\"timestamp\", ascending=False)[\"movieId\"][0:1].values[0]\nmovie_id","154cbed9":"# The name of the movie that random_user last watched and gave a rating of 5 points.\nmovie[movie['movieId']==movie_id]","d2b4bd75":"def item_based_recommender(movie_name, user_movie_df):\n    movie = user_movie_df[movie_name]\n    return user_movie_df.corrwith(movie).sort_values(ascending=False).head(10)","1b81cde7":"movies_from_item_based = item_based_recommender(movie[movie[\"movieId\"] == movie_id][\"title\"].values[0], user_movie_df)\n# 0. indeksteki filmin kendisi oldugu icin onu koymadik.\nmovies_from_item_based[1:6].index","2c29ff99":"*In the top output, all the movies that the user watched and did not watch came. but we only want to reach the information of the movies he watched.*","f552b91a":"*The correlation between the 1st users and the second users seems very comfortable at the moment.*","d8f58600":"***We found the user information with the highest correlation. But we still can't decide which movies to recommend.***","a23bce75":"* ***Now our aim is to reach the identity and information of the users who watch the same movies.***","b94ce157":"# **Hybrid Recommender System(User-Based and Item-Based Collaborative Filtering)**\n![image.png](https:\/\/miro.medium.com\/max\/1400\/1*QvhetbRjCr1vryTch_2HZQ.jpeg)","940de402":"*Now let's find the movies watched by the user to recommend.*","efb200c1":"# **ITEM BASED RECOMMEND**\n\nThe item-to-item filtering algorithm analyzes product similarities from user ratings. Click\/view rather than scoring can also be considered a variable. The purpose of this system is to ensure that the products purchased\/viewed by the user are recommended to other similar users by considering the similarity. In this method, product similarities are found using Pearson Correlation or cosine similarity methods, assuming the products are neighbors.","79cc4b93":"# Make 5 item-based suggestions based on the name of the highest rated movie the user has watched most recently.","86aa23cb":"* ***We brought those whose number of watching movies together with the given user is above 60%. but they may not have the same liking behavior. In this section, our aim is to bring the users with the most similar liking behaviors from these users.***","990a58ed":"# **DATA PRE-PROCESSING**","82c20a15":"# **USER BASED RECOMMENDER**\n\nUser-based filtering is a system that takes into account the similarity of user tastes. If two users have bought joint products, it is based on the probability that the other user will also receive a product purchased later. According to the scores of the users, the prediction is made as a result of Pearson Correlation or cosine similarity methods.","b0b3ba7b":"#  Calculating the Weighted Average Recommendation Score","701cfbaa":"***There are 5 movies that can be recommended with the user based method.***","afabd290":"# ***Business Problem***\nEstimate using the item-based and user-based recommender methods for the user : 108170 whose ID is given.","94f8e357":"#   **Find users who are most similar to the suggested user.**","443b0fa8":"# **Dataset Story**\nThe dataset was provided by MovieLens, a movie recommendation service. It contains the rating scores for these movies along with the movies.\nIt contains 2,000,0263 ratings across 27,278 movies.\nThis data was created by 138,493 users between 09 January 1995 and 31 March 2015. This data set was created on October 17, 2016.\nUsers are randomly selected. It is known that all selected users voted for at least 20 movies.","abce20a1":"***We found the correlation. Let's do one more filtering here. Let's say those with a correlation of more than 65% come. And since user_id1 is a random user, user_id2 and corr values will be enough for me. If we remove it from the index, we can observe much more easily.***","466cf11b":"# **VARIABLES**\n**Movie Dataset:**\n\nmovieId: Unique movie ID\n\ntitle: Movie Name\n\n**Rating Dataset:**\n\nuserId: Unique user ID\n\nmovieId: Unique movie ID\n\nrating: User ratings for movies\n\ntimestamp: Date for rating","00676f28":"***Now let's get to the names of these movieIds.***","7c194813":"***Now our goal is to find the correlation of the user with other users.***","d3406734":"![SON HYBRID.png](attachment:492a5ccb-c7c9-4b5c-92a2-3d746f72496b.png)"}}