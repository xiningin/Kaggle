{"cell_type":{"cefdf0ae":"code","8306a791":"code","beb3d090":"code","a99d102f":"code","66be898b":"code","50814432":"code","bb57e08f":"code","15975fba":"code","43ad8955":"code","7f04112c":"code","6a5026df":"code","8f2295d4":"code","4558ccdf":"code","7f4ee6d7":"code","7feb659e":"code","babf7b40":"code","944d4696":"code","00d4fe5e":"code","540f7678":"code","5d454012":"markdown","c5fbcf24":"markdown","d2a5dc22":"markdown","4366de11":"markdown"},"source":{"cefdf0ae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8306a791":"data=pd.read_csv(\"..\/input\/water-potability\/water_potability.csv\")","beb3d090":"data.head()","a99d102f":"data.isnull().sum()","66be898b":"data.shape","50814432":"data.drop(['ph','Sulfate','Trihalomethanes'],axis=1,inplace=True)","bb57e08f":"data","15975fba":"X = data.iloc[:,:6]\ny = data.iloc[:, -1]","43ad8955":"print(X)","7f04112c":"y","6a5026df":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","8f2295d4":"X_train","4558ccdf":"X_test","7f4ee6d7":"y_train","7feb659e":"y_test","babf7b40":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","944d4696":"ann = tf.keras.models.Sequential()\nann.add(tf.keras.layers.Dense(units=6, activation='relu'))\nann.add(tf.keras.layers.Dense(units=6, activation='relu'))\nann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))","00d4fe5e":"ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","540f7678":"ann.fit(X_train, y_train, batch_size = 32, epochs = 1000)","5d454012":"# Data Gathering","c5fbcf24":"# Standardization","d2a5dc22":"# Model building","4366de11":"# Train Test Split"}}