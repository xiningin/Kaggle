{"cell_type":{"2a3ee3f7":"code","08893cc8":"code","12afc165":"code","cbbe1c15":"code","70134f49":"code","febc15ac":"code","01e0eae1":"code","21d16ad6":"code","45e491b1":"code","ef32ff6c":"code","2ea96e70":"code","d7254bdf":"code","8701c879":"code","6e9403d6":"code","38f54c26":"code","c41d9607":"code","3ec26915":"code","4bcb4cef":"code","c42d4706":"code","2ceae958":"code","1e3c5774":"code","e93aa9dd":"code","f954a167":"code","48a27b73":"code","7a142185":"code","fdb840ff":"code","33bd4a59":"code","bdd3afe6":"code","4d9880c8":"code","efc338b3":"code","866e9939":"code","5efa464f":"code","cba54f91":"code","ac3905cf":"code","6afe99ee":"code","86693bb8":"code","c6e1cd2a":"code","c22c0f15":"code","bc804990":"code","b4b42260":"code","f9f7525b":"code","3f8e3479":"code","d2163376":"code","bfa98c81":"code","7d7c0877":"code","4aee1e6b":"code","64114a72":"code","12a2444b":"code","e9290b96":"code","abde08b5":"code","fd17c445":"code","b2d86678":"code","3f5235af":"code","d72da140":"code","e6a319bd":"code","bfe42ab8":"code","a55202fc":"code","f26ced01":"code","fc38f650":"code","053e9979":"code","a797541e":"code","779597c5":"code","e2fc7156":"code","ee41d14e":"code","6343639e":"code","8b43c679":"code","f22d1a88":"code","617b2d09":"code","db33b40e":"code","20582e78":"code","8dc555e6":"code","38710011":"code","ea90c5ae":"code","398661e6":"code","aee4e8de":"code","6b4ef1df":"code","34657fb2":"code","c9ca86ae":"code","e68bbe25":"code","735d545b":"code","92599655":"code","d33b2822":"code","9145ea05":"code","af38e6b6":"code","1916654a":"code","40d5356e":"code","1748761c":"code","8a456d2c":"code","fdcbd48e":"code","52161a97":"code","5d062ac9":"code","a57711e5":"code","5020a72d":"code","2ac2f38b":"code","9bbc030a":"code","3a905a91":"code","af215ad7":"code","7113318c":"code","68ce0360":"code","cadaad39":"code","7c61d2b3":"code","6b866c71":"code","3d31c571":"code","0f57f107":"code","15b7fa03":"code","50cbb213":"code","a459472f":"code","6881e427":"code","13634d12":"markdown","a1eabbdf":"markdown","a89d676c":"markdown","09ce1cb1":"markdown","9c6b3aee":"markdown","30c8891d":"markdown","89342fc5":"markdown","29148c06":"markdown","008700b6":"markdown","6927d7ad":"markdown","30b6cd9c":"markdown","84a07ebb":"markdown","c446720a":"markdown","0a49486f":"markdown","1099ada0":"markdown","d4f46611":"markdown","655bee68":"markdown","b234aa28":"markdown","24b2964a":"markdown","5a4b954f":"markdown","e204fc48":"markdown","0a6804b8":"markdown","104deb6b":"markdown","dda2b3d1":"markdown","db053f97":"markdown"},"source":{"2a3ee3f7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","08893cc8":"bitcoin_data =pd.read_csv(\"..\/input\/bitstampUSD_1-min_data_2012-01-01_to_2018-11-11.csv\")","12afc165":"bitcoin_data.info() #data information","cbbe1c15":"bitcoin_data.describe() #numeric value","70134f49":"bitcoin_data.columns","febc15ac":"bitcoin_data.head() #default first 5","01e0eae1":"bitcoin_data.tail()","21d16ad6":"bitcoin_data.corr()","45e491b1":"#correlation map \nf,ax = plt.subplots(figsize=(10,10))\nsns.heatmap(bitcoin_data.corr(),annot=True,linewidths=4,fmt=\".1f\",ax=ax)\nplt.show()","ef32ff6c":"bitcoin_data.isnull","2ea96e70":"#line plot\nbitcoin_data.Low.plot(kind=\"line\",color='r',label=\"low\",linewidth=1.5,alpha=0.5,grid=True,linestyle=\":\")\nbitcoin_data.High.plot(kind=\"line\",color=\"b\",label=\"high\",linewidth=1,alpha=0.5,grid=True,linestyle=\"-\")\nplt.legend(loc = \"upper right\")\nplt.xlabel(\"x axis\")\nplt.ylabel(\"y axis\")\nplt.title(\"line plot\")\nplt.show()","d7254bdf":"#scatter\n# x= low, y=high\nbitcoin_data.plot(kind=\"scatter\",x=\"Low\",y=\"High\",alpha=0.8,color=\"r\")\nplt.xlabel(\"low\")\nplt.ylabel(\"high\")\nplt.show()","8701c879":"# Histogram\n# bins = number of bar in figure\n#data.Speed.plot(kind = 'hist',bins = 50,figsize = (12,12))\nbitcoin_data.Close.plot(kind = \"hist\",bins = 10,orientation=\"horizontal\",figsize=(10,10)) #horizantal hist\nplt.show()\nbitcoin_data.Close.plot(kind=\"hist\",bins=16,figsize=(10,10))\nplt.show()\n\n","6e9403d6":"#clf clean plot \nbitcoin_data.High.plot(kind=\"hist\",bins = 40)\nplt.clf() \n#we cannot plot","38f54c26":"\nseries =bitcoin_data[\"High\"] #data[\"High\"] = series\nprint(type(series))\ndata_frame = bitcoin_data[[\"High\"]] #data[[\"High\"]] = data frame\nprint(type(data_frame))","c41d9607":"x =bitcoin_data[\"High\"]>300000\nprint(x)","3ec26915":"bitcoin_data[np.logical_and(bitcoin_data[\"Open\"]>290000 ,bitcoin_data[\"Close\"]<300000)]","4bcb4cef":"lis=[1,2,3,4,5]\nfor i in lis:\n     print('i is :',i)\n        \nprint('')   \n# Enumerate index and value of list\n# index : value = 0:1, 1:2, 2:3, 3:4, 4:5\nfor index,value in enumerate(lis):\n    print(index,\" :\",value)\nprint('') \n# We can use for loop to achive key and value of dictionary. We learnt key and value at dictionary part.\ndicto={'Turkey':'Ankara','spain':'madrid','canada':'toronto'}\nfor key,value in dicto.items():\n        print(key,\":\",value)\nprint(\"\")      \n# For pandas we can achieve index and value\nfor index,value in bitcoin_data[['High']][0:1].iterrows():  \n    print(key,\":\",value)\n    ","c42d4706":"#tuble: sequence of immutable python objects.\n#cant modify values\n#tuple uses paranthesis like tuple = (1,2,3)\n#unpack tuple into several variables like a,b,c = tuple\n\ndef tuple_x():\n    \"\"\" return defined t tuble\"\"\"\n    t =(1,2,3)\n    return t \na,b,c= tuple_x()\nprint(a,b,c)\n","2ceae958":"#Scope\n#What we need to know about scope:\n# global: defined main body in script\n# local: defined in a function\n#* built in scope: names in predefined built in scope module such as print, len\nx =2 \ndef f():\n    x =3\n    return x\nprint(x) #x is global\nprint(f()) #x is local","1e3c5774":"# What if there is no local scope\nx=4\ndef f ():\n    y=2*x  #x is not local spoce \n    return y \nprint(f())   # it uses global scope x\n# First local scopesearched, then global scope searched, if two of them cannot be found lastly built in scope searched.","e93aa9dd":"# How can we learn what is built in scope\nimport builtins\ndir(builtins)\n","f954a167":"#nested function: inside to funtion \ndef squared():\n    \"\"\"return square of value \"\"\"\n    def add():\n        \"\"\" return add to  2  local value\"\"\"\n        x=2\n        z=4\n        y=x+z\n        return y \n    return add()**2\nprint(squared())","48a27b73":"#default argment\ndef f(a,b=2,c=3):\n    y = a + b + c\n    return y \n\nprint(f(5))\n    # what if we want to change default arguments\nprint(f(5,4,6))","7a142185":"#flexible argument *args\ndef f(*args) :\n    for i in args :\n        print(i)\nf(1)\nprint(\"\")\nf(1,23,5)\n\n#flexible argument **kwargs\ndef f(**kwargs):\n    \"\"\"return key,value on dictionary\"\"\"\n    for index,value in kwargs.items():\n        print(index,\":\",value)\nf(country = \"spain\",capital =\"madrid\",population = 1478522)","fdb840ff":"#lambda funtion :faster function\nsquare = lambda x :x**2\nprint(square(5))\ntotal=lambda x,y,z : x+y+z\nprint(total(1,2,3))","33bd4a59":"# anonymous function : it like lambda but can be more then one argument\nnumber=[1,2,3,4]\ny =map(lambda x :x**3,number)\nprint(list(y))\n","bdd3afe6":"#iteration\nname=\"rihanna\"\nit =iter(name)\nprint(next(it)) #first \/next iteration\nprint(*it) #remaning iteration","4d9880c8":"#zip():zip list\nlist1=[1,2,3,4]\nlist2=[7,8,9,6]\nz=zip(list1,list2) \nprint(z)\nz_list=list(z) #convert z to list(z_list)\nprint(z_list)","efc338b3":"un_zip =zip(*z_list)\nulist1,ulist2=list(un_zip) #return to unzip yo tuble\nprint(ulist1)\nprint(ulist2)\nprint(type(ulist1))","866e9939":"#list comperhension:collapse for loops for building lists into a single line \n#ex: num1 = [1,2,3] and we want to make it num2 = [2,3,4]. This can be done with for loop. \n#However it is unnecessarily long. We can make it one line code that is list comprehension\nnum1=[1,2,3]\nnum2=[ i+1  for i in num1]\nprint(num2)\n\n#[i + 1 for i in num1 ]: list of comprehension\n#i +1: list comprehension syntax\n#for i in num1: for loop syntax\n#i: iterator\n#num1: iterable object\n","5efa464f":"# Conditionals on iterable\nnum1=[7,5,6]\nnum2 = [i**2 if i==5  else i-7 if i==7 else i+1 for i in num1]\nprint (num2)\nnu=[9,10,4]\nnu2 =[  i+5 if i<5 else i+1 if i<10  else i  for i in nu]\nprint(nu2)","cba54f91":"# lets classify bitcoin  whether they have high or low speed. Our threshold is average speed\nthreshold=sum(bitcoin_data.Open)\/len(bitcoin_data.Open)\nbitcoin_data[\"Open_Level\"] = [\" high\" if i >threshold else \"low\" for i in bitcoin_data.Open]\nbitcoin_data.loc[:10,[\"Open_Level\",\"Open\"]]  #we will learn loc more detailed later\n","ac3905cf":"data=pd.read_csv(\"..\/input\/bitstampUSD_1-min_data_2012-01-01_to_2018-11-11.csv\")","6afe99ee":"data.head() #first 5 rows","86693bb8":"data.tail() #last 5 rows","c6e1cd2a":"data.columns\n","c22c0f15":"data.shape #shape gives number of rows and columns in a tuple","bc804990":"data.info\n","b4b42260":"print(data.Open.value_counts(dropna=True))","f9f7525b":"data.describe()","3f8e3479":"data.boxplot(column=\"Open\",by=\"High\")","d2163376":"data_new =data.head()\ndata_new","bfa98c81":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted=pd.melt(frame=data_new,id_vars=\"Close\",value_vars=[\"High\",\"Low\"])\nmelted","7d7c0877":"# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index='Close',columns= 'variable',values= 'value')","4aee1e6b":"#firstl create 2 frame \ndata1=data.head()\ndata2=data.tail()\ncont_data_row=pd.concat([data1,data2],axis=0,ignore_index=True) #axis=0 add datadrame in  rows\ncont_data_row\n\n","64114a72":"data1=data[\"High\"].head()\ndata2=data[\"Low\"].head()\ncont_data_col=pd.concat([data1,data2],axis=1,ignore_index=True)\ncont_data_col","12a2444b":"data.dtypes","e9290b96":"# lets convert int to categorical and  float.\ndata['Timestamp']=data['Timestamp'].astype(\"category\")\ndata[\"Volume_(BTC)\"]=data[\"Volume_(BTC)\"].astype(\"int\")","abde08b5":"data.dtypes\n#as you can Timestamp convert int to categorry\n#Volume_BTc convert from float to int","fd17c445":"data.info()","b2d86678":"data[\"Timestamp\"].value_counts(dropna=False)","3f5235af":"data1=data\ndata1[\"Open\"].dropna(inplace=True) # inplace = True means we do not assign it to new variable. Changes automatically assigned to data","d72da140":"# Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true","e6a319bd":"# In order to run all code, we need to make this line comment\n#assert 1==2 # return error because it is false","bfe42ab8":"assert data['Open'].notnull().all() #returns nothingg becasue we drop non value","a55202fc":"data['Open'].fillna('empty',inplace=True)","f26ced01":"assert data['Open'].notnull().all() #returns nothing beacuse we do not not have nan values","fc38f650":"\n\n# # With assert statement we can check a lot of thing. For example\n# assert data.columns[1] == 'Open'\n# assert data.Open.dtypes == np.int\n\n","053e9979":"#data frame from dictionary\ncountry=[\"spain\",\"france\"]\npopulation=[\"12\",\"15\"]\nlist_label=[\"country\",\"population\"]\nlist_col=[country,population]\nzipped=list(zip(list_label,list_col))\ndata_dict=dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf\n","a797541e":"#add news columns\ndf[\"capital\"]=[\"madrid\",\"paris\"]\ndf","779597c5":"#broadcasting\ndf[\"incame\"]=0 #broadcast entire colunmn\ndf","e2fc7156":"#ploting all data\ndata1=data.loc[1:,[\"Open\",\"Low\",\"High\"]]\ndata1.plot()\n#it is confused","ee41d14e":"#subplot\ndata1.plot(subplots=True)\nplt.show()","6343639e":"#scater\ndata1.plot(kind=\"scatter\",x=\"Low\",y=\"High\")\nplt.show()","8b43c679":"#hist\ndata1.plot(kind=\"hist\",y=\"Low\",bins=60,range=(2500,3000000),normed= True)","f22d1a88":"# histogram subplot with non cumulative and cumulative\nfig,axes=plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\", y=\"Low\",bins=50 ,range=(25000,3000000),normed=True, ax=axes[0])\ndata1.plot(kind =\"hist\",y=\"Low\",bins=50, range=(25000,3000000),normed=True,ax=axes[0],cumulative=True)\nplt.savefig(\"graph.png\")\nplt.show()\n","617b2d09":"data.describe()","db33b40e":"time_list=[\"2018-02-10\",\"2018-03-04\"]\nprint(type(time_list)) #let see string\n# however we want it to be datetime object\ndatetime_object=pd.to_datetime(time_list)\nprint(type(datetime_object))","20582e78":"# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# In order to practice lets take head of bitcoin data and add it a time list\ndata2=data.head()\ndate_list =[\"2018-01-16\",\"2018-02-19\",\"2018-03-09\",\"2018-04-17\",\"2018-09-19\"]\ndatetime_object=pd.to_datetime(date_list)\ndata2[\"date\"]=datetime_object\n# lets make date as index\ndata2=data2.set_index(\"date\")\ndata2 \n\n","8dc555e6":"#now we can select according to our index\nprint(data2.loc[\"2018-02-19\"])\nprint(data2.loc[\"2018-01-01\":\"2018-06-01\"])","38710011":"data2.resample(\"A\").mean() #We will use data2 that we create at previous part","ea90c5ae":"# Lets resample with month\ndata2.resample(\"M\").mean() \n","398661e6":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")","aee4e8de":"# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","6b4ef1df":" #data =pd.read_csv(\"..\/input\/bitflyerJPY_1-min_data_2017-07-04_to_2018-06-27.csv\"\n#data=data.set_index(\"#\")\n#data.head()","34657fb2":"#indexing using square brackets\ndata[\"Open\"][1]","c9ca86ae":"# using column attribute and row label\ndata.Open[1]","e68bbe25":"# using loc accessor\ndata.loc[1,[\"Open\"]]","735d545b":"data[[\"Open\",\"Close\"]]\n","92599655":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"Open\"])) #series\nprint(type(data[[\"Open\"]])) #dataframes","d33b2822":"# Slicing and indexing series\ndata.loc[1:10,\"Open\":\"Close\"]  #10 and \"Close\" are inclusive\n","9145ea05":"# Reverse slicing \ndata.loc[10:1:-1,\"Open\":\"Close\"] #","af38e6b6":"# From something to end\ndata.loc[1:10,\"Low\":]","1916654a":"#creating booelan series\nboolen =data.Open >300000\ndata[boolen]","40d5356e":"#combining filters\nfirst_filter =data.Open<1500000\nseconde_filte=data.Close>300000\ndata[first_filter & seconde_filte]","1748761c":"# Filtering column based others\ndata.Open[data.Low<3000000]","8a456d2c":"#plain function\ndef div(n):\n    return n\/2\ndata.Timestamp.apply(div)","fdcbd48e":"# Or we can use lambda function\ndata.Timestamp.apply(lambda x : x\/2)","52161a97":"# Defining column using other columns\ndata[\"total_difference\"]= data.Close -data.Open\ndata.head()","5d062ac9":"# our index name is this:a\n#data.index.name=\"#\"\nprint(data.index.name)\n# lets change it\ndata.index.name = \"index_name\"\ndata\n","a57711e5":"# Overwrite index\n# if we want to modify index we need to change all of them.\ndata.head()\n# first copy of our data to data4 then change index \ndata4 = data.copy()\n# lets make index start from 100. It is not remarkable change but it is just example\n#data4.index = range(100,150,3)\ndata4.head()\n","5020a72d":"# We can make one of the column as index. I actually did it at the beginning of manipulating data \n# data= data.set_index(\"#\")\n# also you can use \n# data.index = data[\"#\"]","2ac2f38b":"#lets read dara frame one more time to start from beginning\ndata =pd.read_csv(\"..\/input\/bitstampUSD_1-min_data_2012-01-01_to_2018-11-11.csv\")\ndata.head()","9bbc030a":"# Setting index : type 1 is outer type 2 is inner index\ndata1=data.set_index([\"Open\",\"Close\"])\ndata1.head(100)\n#data1.loc[\"Low\",\"High\"] # howw to use indexes","3a905a91":"dic = {\"treament\":[\"A\",\"A\",\"B\",\"B\"],\"gender\":[\"F\",\"M\",\"F\",\"M\"],\"response\":[12,30,45,68],\"age\":[20,49,18,69]}\ndf = pd.DataFrame(dic)\ndf","af215ad7":"#pivoting\ndf.pivot(index=\"treament\",columns= \"gender\",values=\"age\"),\n","7113318c":"df1=df.set_index([\"treament\",\"gender\"])\ndf1","68ce0360":"# lets unstack it\n#level determines indexes\ndf1.unstack(level=0)\n","cadaad39":"df1.unstack(level=1)","7c61d2b3":"# change inner and outer level index position\ndf1.swaplevel(0,1)\ndf1","6b866c71":"df","3d31c571":"#df.pivot(index=\"treament\",columns=\"gender\",values=\"age\")\npd.melt(df,id_vars=\"treament\",value_vars=[\"age\",\"response\"])","0f57f107":"#we will use df\ndf","15b7fa03":"# according to treatment take means of other features\ndf.groupby(\"treament\").mean()   \n# there are other methods like sum, std,max or min","50cbb213":"# we can only choose one of the feature\ndf.groupby(\"treament\").age.max()","a459472f":"# Or we can choose multiple features\ndf.groupby(\"treament\")[[\"age\",\"response\"]].min()","6881e427":"df.info()\n# as you can see gender is object\n# However if we use groupby, we can convert it categorical data. \n# Because categorical data uses less memory, speed up operations like groupby\ndf[\"gender\"] = df[\"gender\"].astype(\"category\")\ndf[\"treament\"] = df[\"treament\"].astype(\"category\")\ndf[\"response\"]= df[\"response\"].astype(\"float\")\ndf.info()","13634d12":"<a id=\"17\"><\/a><br>\n### INDEXING PANDAS TIME SERIES\n*   datetime = object\n*    parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format\n","a1eabbdf":"<a id=\"19\"><\/a><br>\n### FILTERING DATA FRAMES\n* Creating boolean series Combining filters Filtering column based others","a89d676c":"<a id=\"19\"><\/a><br>\n### TIDY DATA\n* We tidy data with melt(). Describing melt is confusing. Therefore lets make example to understand it.\n","09ce1cb1":"<a id=\"19\"><\/a><br>\n### STATISTICAL EXPLORATORY DATA ANALYSIS\n<br>I already explained it at previous parts. However lets look at one more time.\n*  count: number of entries\n* mean: average of entries\n*  std: standart deviation\n*  min: minimum entry\n* 25%: first quantile\n*  50%: median or second quantile\n*  75%: third quantile\n*  max: maximum entry\n","9c6b3aee":"<a id=\"19\"><\/a><br>\n### DEFAULT and FLEXIBLE ARGUMENTS\n*  default argument def f(a,b=1) b=1 default argument\n* flexible argument def f(*args) \"\"\"  *args can be one or more \"\"\"\n* another flexible argument def f(**kwargs) \"\"\" **kwargs is dictionary\"\"\"\n\n\n    ","30c8891d":"<a id=\"20\"><\/a><br>\n### TRANSFORMING DATA\n*    Plain python functions\n*     Lambda function: to apply arbitrary python function to every element\n*     Defining column using other columns\n","89342fc5":"<a id=\"19\"><\/a><br>\n### SLICING DATA FRAME\n*    Difference between selecting columns\n*         Series and data frames\n*     Slicing and indexing series\n*     Reverse slicing\n*     From something to end\n\n","29148c06":"<a id=\"20\"><\/a><br>\n### MELTING DATA FRAMES\n*   Reverse of pivoting","008700b6":"<a id=\"42\"><\/a> <br>\n### CATEGORICALS AND GROUPBY","6927d7ad":"<a id=\"18\"><\/a>Cleaning Data  <br>\n<br>DIAGNOSE DATA for CLEANING\n<br>we need to diagnose and clean data before exploring\n<br>why need to  cleaning :missing data,diffrent  language,upper-lower case or space between word\n<br>We will use head, tail, columns, shape and info methods to diagnose data","30b6cd9c":"ITERATORS\n\n    iterable is an object that can return an iterator\n    iterable: an object with an associated iter() method\n    example: list, strings and dictionaries\n    iterator: produces next value with next() method\n","84a07ebb":"<a id=\"20\"><\/a><br>\n# PANDAS\n### REV\u0130EW of PANDAS\n<br>As you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\n*     single column = series\n*     NaN = not a number\n*     dataframe.values = numpy\n\n### BUILDING DATA FRAMES FROM SCRATCH\n*   We can build data frames from csv as we did earlier.\n*   Also we can build dataframe from dictionaries\n   *   zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n*    Adding new column\n*   Broadcasting: Create new column and assign a value to entire column\n\n","c446720a":"<a id =\"19\"><\/a><br>\n### INDEX OBJECTS AND LABELED DATA\n* index: sequence of label\n","0a49486f":"<a id=\"18\"><\/a> <br>\n### EXPLORATORY DATA ANALYSIS\nvalue_counts(): Frequency counts\n<br>outliers: the value that is considerably higher or lower from rest of the data\n* Lets say value at 75% is Q3 and value at 25% is Q1. \n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n<br>We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\n<br> What is quantile?\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The median is the number that is in **middle** of the sequence. In this case it would be 11.\n\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.","1099ada0":"<a id=\"19\"><\/a><br>\n### DATA TYPES\n<br>There are 5 basic data types: object(string),booleab, integer, float and categorical.\n<br>We can make conversion data types like from str to categorical or from int to float\n<br>Why is category important:\n*    make dataframe smaller in memory\n *   can be utilized for anlaysis especially for sklear(we will learn later)\n","d4f46611":"<a id=\"20\"><\/a><br>\n## PIVOTING DATA FRAMES\n*    pivoting: reshape tool\n","655bee68":"<a id=\"30\"><\/a><br>\n### STACKING and UNSTACKING DATAFRAME\n* deal with multi label indexes\n* level: position of unstacked index\n* swaplevel: change inner and outer level index position","b234aa28":"<a id=\"19\"><\/a><br>\n### CONCATENATING DATA\n* We can concatenate two dataframe","24b2964a":"<a id=\"19\"><\/a><br>\n### MISSING DATA and TESTING WITH ASSERT\n<br>If we encounter with missing data, what we can do:\n*     leave as is\n*     drop them with dropna()\n*     fill missing value with fillna()\n*     fill missing values with test statistics like mean\n*     Assert statement: check that you can turn on or turn off when you are done with your testing of the program\n","5a4b954f":"<a id=\"19\"><\/a><br>\n# MANIPULATING DATA FRAMES WITH PANDAS\n\n### INDEXING DATA FRAMES\n*    Indexing using square brackets\n*     Using column attribute and row label\n*     Using loc accessor\n*     Selecting only some columns\n","e204fc48":"<a id =\"19\"><\/a><br>\n### HIERARCHICAL INDEXING\n*    Setting indexing\n\n","0a6804b8":"<a id=\"19\"><\/a> <br>\n### VISUAL EXPLORATORY DATA ANALYSIS\n* Box plots: visualize basic statistics like outliers, min\/max or quantiles","104deb6b":"<a id=\"19\"><\/a><br>\n### PIVOTING DATA\n* Reverse of melting.\n","dda2b3d1":"<a id=\"19\"><\/a><br>\n### VISUAL EXPLORATORY DATA ANALYSIS\n*    Plot\n*     Subplot\n*     Histogram:\n*         bins: number of bins\n*         range(tuble): min and max values of bins\n*         normed(boolean): normalize or not\n*         cumulative(boolean): compute cumulative distribution","db053f97":"<a id=\"16\"><\/a><br>\n### RESAMPLING PANDAS TIME SERIES\n*    Resampling: statistical method over different time intervals\n*       Needs string to specify frequency like \"M\" = month or \"A\" = year\n*     Downsampling: reduce date time rows to slower frequency like from daily to weekly\n*     Upsampling: increase date time rows to faster frequency like from daily to hourly\n*     Interpolate: Interpolate values according to different methods like \u2018linear\u2019, \u2018time\u2019 or index\u2019\n*        https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.Series.interpolate.html\n"}}