{"cell_type":{"87c12dde":"code","09c5fef1":"code","74a998c9":"code","c0f5a577":"code","96a76a7a":"code","a87fca2d":"code","d79e37ad":"code","2a86a91d":"code","5e737592":"code","ca066a7b":"code","e3e19e65":"code","5f9648bc":"code","724ba2d5":"code","ef8e2583":"code","43cdaad2":"code","9a289860":"code","0f3ba421":"code","f223b9d5":"code","583c8096":"code","0f8e25be":"code","6c89316d":"markdown","e6d152a5":"markdown","0e43291e":"markdown"},"source":{"87c12dde":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tensorflow.keras.datasets import mnist\n\n#load data\n(X_train, Y_train), (X_test, Y_test) = mnist.load_data()","09c5fef1":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import accuracy_score\n\nfrom tensorflow.keras.layers import Dense,Dropout,LSTM\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.losses import sparse_categorical_crossentropy, categorical_crossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy\nfrom tensorflow.keras.backend import sign\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.utils import to_categorical","74a998c9":"print('MNIST Dataset Shape:')\nprint('X_train: ' + str(X_train.shape))\nprint('Y_train: ' + str(Y_train.shape))\nprint('X_test:  '  + str(X_test.shape))\nprint('Y_test:  '  + str(Y_test.shape))","c0f5a577":"X_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n# normalize the data\nX_train \/= 255.0\nX_test \/= 255.0","96a76a7a":"# change input dimensions to 3 for LSTM input\nX_train = np.reshape(X_train, (60000, 28, 28))\nX_test = np.reshape(X_test, (10000, 28, 28))","a87fca2d":"#convert y values to one hot encoding format\nY_train = to_categorical(Y_train)\nY_test = to_categorical(Y_test)","d79e37ad":"# LSTM model\nmodel = Sequential()\n\nmodel.add(LSTM(256, input_shape=(X_train.shape[1], 28)))\nmodel.add(Dropout(0.15))\nmodel.add(Dense(10, activation=\"sigmoid\"))\n\nmodel.summary()","2a86a91d":"adam_modified = optimizers.Adam(learning_rate=0.005, beta_1=0.7, beta_2=0.9, amsgrad=False)\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=adam_modified, metrics=[\"accuracy\"])\nhistory = model.fit(X_train, Y_train, epochs=5, validation_split=0.2)","5e737592":"predictions = model.predict_classes(X_test)\naccuracy_score(np.argmax(Y_test, axis=1), predictions)","ca066a7b":"#plot the loss and accuracy curves\ndef loss_curve(history):\n    \n    plt.figure(figsize=[8,6])\n    plt.plot(history.history['loss'],'r',linewidth=3.0)\n    plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n    plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n    plt.xlabel('Epochs ',fontsize=16)\n    plt.ylabel('Loss',fontsize=16)\n    plt.title('Loss Curves',fontsize=16)\n\ndef accuracy_curve(history):\n    \n    plt.figure(figsize=[8,6])\n    plt.plot(history.history['accuracy'],'r',linewidth=3.0)\n    plt.plot(history.history['val_accuracy'],'b',linewidth=3.0)\n    plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n    plt.xlabel('Epochs ',fontsize=16)\n    plt.ylabel('Accuracy',fontsize=16)\n    plt.title('Accuracy Curves',fontsize=16)\n    \naccuracy_curve(history)\nloss_curve(history)","e3e19e65":"#we should review \ndef plot_predictions(x_test, y_true, y_prediction):\n    #indice = rd.choice(np[0])   random 10 values\n    num_cols = 5\n    num_rows = 2\n    fig, axes = plt.subplots(num_rows, num_cols, figsize=(1.5*num_cols,2*num_rows))\n    for i in range(len(x_test)):\n        ax = axes[i\/\/num_cols, i%num_cols]\n        ax.imshow(x_test[i], cmap='gray_r')\n        ax.set_title('t: {} \\n p: {}'.format(np.argmax(y_true[i]), y_prediction[i]))\n    plt.tight_layout()\n    plt.show()\n    \nplot_predictions(X_test[:10], Y_test[0:10], predictions[0:10])","5f9648bc":"tf.version","724ba2d5":"def adversarial_pattern(image, label):\n    image = tf.cast(image, tf.float32)\n    \n    with tf.GradientTape() as tape:\n        tape.watch(image)\n        prediction = model(image)\n        \n        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)(label, prediction)\n    \n    gradient = tape.gradient(loss, image)\n    \n    signed_grad = tf.sign(gradient)\n    \n    return signed_grad\n\nsigned = adversarial_pattern(X_test, Y_test)","ef8e2583":"perturbed_data = X_test + 0.2 * signed #0.2\nX_perturbed = perturbed_data.numpy()","43cdaad2":"adversarial_predictions = model.predict_classes(X_perturbed)\naccuracy_score(Y_test, to_categorical(adversarial_predictions))","9a289860":"plot_predictions(X_test[:10], Y_test[0:10], adversarial_predictions[0:10])","0f3ba421":"plot_predictions(X_perturbed[:10], Y_test[0:10], adversarial_predictions[0:10])","f223b9d5":"def itrAdvAttacks(itr, epsilon, alfa, image, label):\n    adversarial = image\n    for i in range(itr):\n        n = alfa * adversarial_pattern(adversarial, label)\n        adversarial += n\n        maxValues = np.maximum((image-epsilon), np.array(adversarial)) \n        adversarial = np.minimum((image+epsilon), maxValues)\n        \n        itrPrediction = model.predict_classes(adversarial)\n        #print(i, np.array(itrPrediction).shape)\n        print(\"iteration \", (i+1) , accuracy_score(Y_test, to_categorical(itrPrediction)))\n    \n    return adversarial\n\niterativeAdv = itrAdvAttacks(5, 0.1, 0.05, X_test, Y_test)","583c8096":"itrPred = model.predict_classes(iterativeAdv)","0f8e25be":"plot_predictions(iterativeAdv[:10], Y_test[0:10], itrPred[0:10])","6c89316d":"Apply adversarial attack iteratively","e6d152a5":"# Train the LSTM model","0e43291e":"# Generating adversarial attack"}}