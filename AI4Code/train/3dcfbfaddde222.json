{"cell_type":{"f4e7c281":"code","04b76e13":"code","f7fe9865":"code","79a0428f":"code","9e0777c3":"code","f2577f45":"code","5c07d05b":"code","f6d0ef46":"code","b0330fb0":"code","ef2ad2b7":"code","5e995d91":"code","2233440b":"code","b5befdf5":"code","9f05a35f":"code","3f53971e":"code","e0e43b03":"code","e4c9f045":"code","6aba36b8":"code","0c71d471":"code","39768890":"code","15e38706":"code","2378a379":"code","b220d8ae":"code","9b91481a":"markdown","0101adeb":"markdown","4490cec7":"markdown","039a3831":"markdown","469e980a":"markdown","f8ac48c1":"markdown","837fccc9":"markdown","53bbc7e9":"markdown","b222b0ed":"markdown","8b0279d9":"markdown","fcd1c7f3":"markdown","435252b5":"markdown","8207344b":"markdown","dd4f1116":"markdown","7ac7092c":"markdown","f6325cce":"markdown","d76b5485":"markdown","285bf044":"markdown","e4280c16":"markdown","08b3aedf":"markdown","a4b466d8":"markdown","84f861c8":"markdown","eb77972d":"markdown","47f5d5fd":"markdown","0f4721ed":"markdown","4507c3d3":"markdown","599e2604":"markdown","0623dc54":"markdown","472bf500":"markdown"},"source":{"f4e7c281":"import time\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ntrain = pd.read_csv(\"..\/input\/nlp-getting-started\/train.csv\")\ndisplay(train)\n\ntest = pd.read_csv(\"..\/input\/nlp-getting-started\/test.csv\")\ndisplay(test)","04b76e13":"duplicates = pd.concat(x for _, x in train.groupby([\"text\"]) if len(x) > 1)\nwith pd.option_context(\"display.max_rows\", None, \"max_colwidth\", 240):\n    display(duplicates[[\"id\", \"target\", \"text\"]])","f7fe9865":"train.drop(\n    [\n        6449, 7034, 3589, 3591, 3597, 3600, 3603, \n        3604, 3610, 3613, 3614, 119, 106, 115,\n        2666, 2679, 1356, 7609, 3382, 1335, 2655, \n        2674, 1343, 4291, 4303, 1345, 48, 3374,\n        7600, 164, 5292, 2352, 4308, 4306, 4310, \n        1332, 1156, 7610, 2441, 2449, 2454, 2477,\n        2452, 2456, 3390, 7611, 6656, 1360, 5771, \n        4351, 5073, 4601, 5665, 7135, 5720, 5723,\n        5734, 1623, 7533, 7537, 7026, 4834, 4631, \n        3461, 6366, 6373, 6377, 6378, 6392, 2828,\n        2841, 1725, 3795, 1251, 7607\n    ], inplace=True\n)\nduplicates = pd.concat(x for _, x in train.groupby([\"text\"]) if len(x) > 1)\nwith pd.option_context(\"display.max_rows\", None, \"max_colwidth\", 240):\n    display(duplicates[[\"id\", \"target\", \"text\"]])","79a0428f":"train.drop(\n    [\n        4290, 4299, 4312, 4221, 4239, 4244, 2830, \n        2831, 2832, 2833, 4597, 4605, 4618, 4232, \n        4235, 3240, 3243, 3248, 3251, 3261, 3266, \n        4285, 4305, 4313, 1214, 1365, 6614, 6616, \n        1197, 1331, 4379, 4381, 4284, 4286, 4292, \n        4304, 4309, 4318, 610, 624, 630, 634, 3985,\n        4013, 4019, 1221, 1349, 6091, 6094, \n        6103, 6123, 5620, 5641\n    ], inplace=True\n)","9e0777c3":"from gensim.parsing.preprocessing import stem_text\n\ndef clean_location_keyword(df):\n    df[\"location\"] = df[\"location\"].astype(\"string\").str.lower()\n    df[\"location\"].fillna(\"<empty>\", inplace=True)\n    df[\"keyword\"] = df[\"keyword\"].astype(\"string\").str.lower()\n    df[\"keyword\"].replace(regex=r\"\\%20\", value=\" \", inplace=True)\n    df[\"keyword\"].fillna(\"<empty>\", inplace=True)\n    df[\"keyword\"] = df[\"keyword\"].apply(stem_text)\n\nclean_location_keyword(train)\nclean_location_keyword(test)","f2577f45":"counts = pd.DataFrame(train[\"target\"].value_counts())\ncounts.rename(columns={\"target\": \"Samples\"}, index={0: \"Not Real\", 1: \"Real\"}, inplace=True)\nax = sns.barplot(x=counts.index, y=counts.Samples)\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(\n        x=p.get_x()+(p.get_width()\/2),\n        y=height,\n        s=round(height),\n        ha=\"center\"\n    )","5c07d05b":"with pd.option_context(\"display.max_rows\", None):\n    display(train[\"keyword\"].unique())","f6d0ef46":"def collapse_keywords(x):\n    if x == \"arsonist\":\n        return \"arson\"\n    if x == \"blaze\":\n        return \"ablaz\"\n    if x == \"bloodi\":\n        return \"blood\"\n    if x == \"build burn\" or x == \"burn build\":\n        return \"build on fire\"\n    if x == \"blew up\":\n        return \"blown up\"\n    if x == \"colli\":\n        return \"collid\"\n    if x == \"explo\":\n        return \"explod\"\n    if x == \"hailstorm\":\n        return \"hail\"\n    if x == \"injuri\":\n        return \"injur\"\n    if x == \"panick\":\n        return \"panic\"\n    if x == \"suicid bomber\":\n        return \"suicid bomb\"\n    if x == \"wildfir\":\n        return \"wild fire\"\n    return x\n\ntrain[\"keyword\"] = train[\"keyword\"].apply(lambda x: collapse_keywords(x))\ntest[\"keyword\"] = test[\"keyword\"].apply(lambda x: collapse_keywords(x))\nwith pd.option_context(\"display.max_rows\", None):\n    display(train[\"keyword\"].unique())","b0330fb0":"with pd.option_context(\"display.max_rows\", None):\n    display(pd.DataFrame(data=train[[\"id\", \"keyword\", \"target\"]].groupby([\"keyword\", \"target\"]).count()).rename(columns={\"id\": \"count\"}).head(50))","ef2ad2b7":"print([location for location in train[\"location\"]][:500])","5e995d91":"import re\n\nfrom pycountry import subdivisions\n\ndef clean_state_country(df):\n    subs = [subdivision.name.lower() for subdivision in subdivisions]\n    countries = [subdivision.country_code for subdivision in subdivisions]\n    country = []\n    state = []\n    location_spam = []\n    for _, row in df.iterrows():\n        match_found = False\n        is_spam = 0\n        country_str = \"<none>\"\n        state_str = \"<none>\"\n        if row[\"location\"] != \"\":\n            for index, subdivision in enumerate(subs):\n                if subdivision in row[\"location\"]:\n                    country_str = countries[index]\n                    state_str = subdivision\n                    match_found = True\n                    break\n            if not match_found:\n                split_data = row[\"location\"].replace(\" \", \"\").split(\",\")\n                is_spam = 1\n                if len(split_data) == 2:\n                    if re.match(r\"[\\-]*[0-9]+\\.[0-9]+\", split_data[0]) and re.match(r\"[\\-]*[0-9]+\\.[0-9]+\", split_data[0]):\n                        is_spam = 0\n        location_spam.append(is_spam)\n        country.append(country_str)\n        state.append(state_str)\n    df[\"country\"] = country\n    df[\"state\"] = state\n    df[\"location_spam\"] = location_spam\n    \nclean_state_country(train)\nclean_state_country(test)","2233440b":"with pd.option_context(\"display.max_rows\", None):\n    display(pd.DataFrame(data=train[[\"id\", \"country\", \"target\"]].groupby([\"country\", \"target\"]).count()).rename(columns={\"id\": \"count\"}).head(50))","b5befdf5":"with pd.option_context(\"display.max_rows\", None):\n    display(pd.DataFrame(data=train[[\"id\", \"state\", \"target\"]].groupby([\"state\", \"target\"]).count()).rename(columns={\"id\": \"count\"}).head(50))","9f05a35f":"import re\nimport emoji\n\ndef engineer_features(df):\n    df[\"total_length\"] = df[\"text\"].apply(len)\n    df[\"avg_word_length\"] = df[\"text\"].apply(lambda x: round(sum(len(word) for word in x.split()) \/ len(x.split())))\n    df[\"num_ats\"] = df[\"text\"].apply(lambda x: x.count(\"@\"))\n    df[\"num_hashtags\"] = df[\"text\"].apply(lambda x: x.count(\"#\"))\n    df[\"num_numeric\"] = df[\"text\"].apply(lambda x: len(re.findall(r\"\\w[0-9,]+\\w\", x)))\n    df[\"num_urls\"] = df[\"text\"].apply(lambda x: x.count(\"http\"))\n    df[\"num_timestamps\"] = df[\"text\"].apply(lambda x: len(re.findall(r\"[0-9]+:[0-9]+\", x)))\n    df[\"hashtags\"] = df[\"text\"].apply(lambda x: \" \".join([z.lower() for z in re.findall(r'#(\\w+)', x)]) or \"<none>\")\n    df[\"mentions\"] = df[\"text\"].apply(lambda x: \" \".join([z.lower() for z in re.findall(r'@(\\w+)', x)]) or \"<none>\")\n    df[\"has_emojis\"] = df[\"text\"].apply(lambda x: 1 if bool(emoji.get_emoji_regexp().search(x)) else 0)\n    df[\"links\"] = df[\"text\"].apply(lambda x: \" \".join(re.findall(r'(https?:\/\/t.co\/\\S+)', x)).replace(\"http:\/\/t.co\/\", \"\"))\n\nengineer_features(train)\nengineer_features(test)\ntrain","3f53971e":"for _, row in train[\"text\"].head(50).iteritems():\n    print(row)","e0e43b03":"import re\n\nfrom gensim.parsing.preprocessing import remove_stopwords, strip_punctuation, strip_multiple_whitespaces, strip_numeric, stem_text\nfrom textblob import TextBlob\n\ndef fix_text_issues(x):\n    x = x.lower()\n    x = x.replace(\"&amp;\", \"and\")\n    x = x.replace(\"&lt;\", \"<\")\n    x = x.replace(\"&gt;\", \">\")\n    x = re.sub(\"(\\W|^)hwy\\.(\\W)\", \"\\\\1highway\\\\2\", x)\n    x = re.sub(\"(\\W|^)ave.(\\W)\", \"\\\\1avenue\\\\2\", x)\n    x = re.sub(\"(\\W|^)fyi(\\W)\", \"\\\\1for your information\\\\2\", x)\n    x = re.sub(\"(\\W|^)ain't(\\W)\", \"\\\\1am not\\\\2\", x)\n    x = re.sub(\"(\\W|^)can't(\\W)\", \"\\\\1cannot\\\\2\", x)\n    x = re.sub(\"(\\W|^)cant(\\W)\", \"\\\\1cannot\\\\2\", x)\n    x = re.sub(\"(\\W|^)rt(\\W)\", \"\\\\1retweet\\\\2\", x)\n    x = x.replace(\"g'day\", \"good day\")\n    x = x.replace(\"giv'n\", \"given\")\n    x = x.replace(\"let's\", \"let us\")\n    x = x.replace(\"ma'am\", \"madam\")\n    x = x.replace(\"ne'er\", \"never\")\n    x = x.replace(\"o'clock\", \"of the clock\")\n    x = x.replace(\"o'er\", \"over\")\n    x = x.replace(\"ol'\", \"old\")\n    x = x.replace(\"shan't\", \"shall not\")\n    x = x.replace(\"y'all\", \"you all\")\n    x = x.replace(\"'tis\", \"it is\")\n    x = x.replace(\"'hood\", \"neighborhood\")\n    x = x.replace(\"can\u0089 \u00aat\", \"cannot\")\n    x = x.replace(\"\u00e5\u00ca\", \" \")\n    x = x.replace(\"\u00db\u00cf\", \" \")\n    x = x.replace(\"?\u0089\u00db\", \" \")\n    x = x.replace(\"\u0089\u00db_\", \" \")\n    x = x.replace(\"\u00db\u00f7\", \" \")\n    x = x.replace(\"\u00fb\u00f2\", \" \")\n    x = x.replace(\"\u00fb\", \" \")\n    x = re.sub(\"\\W'twas\", \" it was\", x)\n    x = re.sub(\"\\W'cause\", \" because\", x)\n    x = re.sub(\"(\\w)'ve\", \"\\\\1 have\", x)\n    x = re.sub(\"(\\w)n't\", \"\\\\1 not\", x)\n    x = re.sub(\"(\\w)'s\", \"\\\\1 is\", x)\n    x = re.sub(\"(\\w)'d\", \"\\\\1 had\", x)\n    x = re.sub(\"(\\w)'ll\", \"\\\\1 will\", x)\n    x = re.sub(\"(\\w)'re\", \"\\\\1 are\", x)\n    x = re.sub(\"(\\w)'m\", \"\\\\1 am\", x)\n    x = re.sub(\"http[s]*:\/\/t.co\/\\S+\", \"\", x)\n    x = x.replace(\"...\", \" \")\n    x = strip_multiple_whitespaces(x)\n    return x.strip()\n\ndef get_sentiment(x):\n    tb = TextBlob(x)\n    return tb.sentiment.polarity\n\ndef get_subjectivity(x):\n    tb = TextBlob(x)\n    return tb.sentiment.subjectivity\n\ndef get_pos_tags(x):\n    tb = TextBlob(x)\n    return \" \".join([tag for _, tag in tb.tags])\n\ndef clean_text(df):\n    df[\"new_text1\"] = df[\"text\"].apply(fix_text_issues)\n    df[\"new_text\"] = df[\"new_text1\"].apply(strip_punctuation)\n    df[\"sentiment\"] = df[\"new_text1\"].apply(get_sentiment)\n    df[\"subjectivity\"] = df[\"new_text1\"].apply(get_subjectivity)\n    df[\"pos_tags\"] = df[\"new_text1\"].apply(get_pos_tags)\n\n    \nclean_text(train)\nclean_text(test)\ndisplay(train[[\"new_text\", \"sentiment\", \"subjectivity\", \"pos_tags\"]])","e4c9f045":"from collections import Counter\n\ndef extract_pos_features(df, existing_pos_tags=None):\n    if not existing_pos_tags:\n        pos_tags = []\n        for _, row in df[\"pos_tags\"].iteritems():\n            tags = row.split()\n            for tag in tags:\n                if tag not in pos_tags:\n                    pos_tags.append(tag)\n    else:\n        pos_tags = existing_pos_tags\n        \n    dataset_pos_counts = [[] for _ in pos_tags]\n    for _, row in df[\"pos_tags\"].iteritems():\n        tag_data = Counter(row.split())\n        for index, tag in enumerate(pos_tags):\n            dataset_pos_counts[index].append(tag_data[tag])\n        \n    for index, tag in enumerate(pos_tags):\n        pandas_col_name = \"pos_{}\".format(tag)\n        df[pandas_col_name] = dataset_pos_counts[index]\n        \n    return pos_tags, [\"pos_{}\".format(tag) for tag in pos_tags]\n\n(pos_tags, pos_feature_names) = extract_pos_features(train)\nextract_pos_features(test, existing_pos_tags=pos_tags)\ndisplay(train[pos_feature_names])","6aba36b8":"has_personal_pronouns = []\n\ndef scan_for_pronouns(x):\n    words = x.split(\" \")\n    if \"i\" in words or \"me\" in words or \"you\" in words or \"my\" in words:\n        return 1\n    return 0\n\ndef has_personal_pronouns(df):\n    df[\"has_personal_pronouns\"] = df[\"new_text\"].apply(scan_for_pronouns)\n\nhas_personal_pronouns(train)\nhas_personal_pronouns(test)\n\ndisplay(pd.DataFrame(data=train[[\"id\", \"has_personal_pronouns\", \"target\"]].groupby([\"has_personal_pronouns\", \"target\"]).count()).rename(columns={\"id\": \"count\"}).head(50))","0c71d471":"from gensim.parsing.preprocessing import remove_stopwords, strip_punctuation, strip_multiple_whitespaces, strip_numeric, stem_text\n\ndef normalize_text(df):\n    normalized_text = []\n\n    for _, row in df.iterrows():\n        new_text = row[\"new_text\"]\n        new_text = remove_stopwords(new_text)\n        new_text = re.sub(r\"t co [\\w]+\", \"\", new_text)\n        new_text = strip_numeric(new_text)\n        new_text = strip_multiple_whitespaces(new_text)\n        new_text = stem_text(new_text)\n        normalized_text.append(new_text.strip())\n\n    df[\"normalized_text\"] = normalized_text\n\nnormalize_text(train)\nnormalize_text(test)\ndisplay(train[[\"normalized_text\"]])","39768890":"import gc\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom catboost import CatBoostClassifier\n\nvectorizer = TfidfVectorizer()\nskf = StratifiedKFold(n_splits=5, random_state=2020, shuffle=True)\n\nfeatures = [\n    \"keyword\", \"state\", \"location_spam\", \"total_length\", \n    \"avg_word_length\", \"num_ats\", \"num_hashtags\", \"num_numeric\", \n    \"num_urls\", \"num_timestamps\", \"normalized_text\",\n    \"hashtags\", \"mentions\", \"has_emojis\", \"has_personal_pronouns\",\n    \"links\", \"sentiment\", \"subjectivity\"\n]\nfeatures.extend(pos_feature_names)\n\ncat_params = {\n    \"cat_features\": [\"location_spam\", \"has_emojis\", \"has_personal_pronouns\"],\n    \"text_features\": [\"keyword\", \"state\", \"normalized_text\", \"hashtags\", \"mentions\", \"links\"],\n    \"verbose\": 100,\n    \"learning_rate\": 0.05,\n    \"iterations\": 1200,\n    \"eval_metric\": \"F1\",\n    \"random_state\": 2020,\n    \"depth\": 9,\n    \"auto_class_weights\": \"Balanced\",\n    \"task_type\": \"GPU\",\n    \"devices\": \"0\",\n    \"early_stopping_rounds\": 100,\n}\n\nimportances = pd.DataFrame()\nbest_score = 0.0\nbest_model = None\n\nfor fold, (train_index, test_index) in enumerate(skf.split(train, train[\"target\"])):\n    print(\"-------> fold {} <--------\".format(fold + 1))\n    x_train, x_valid = pd.DataFrame(train.iloc[train_index]), pd.DataFrame(train.iloc[test_index])\n    y_train, y_valid = train[\"target\"].iloc[train_index], train[\"target\"].iloc[test_index]\n    \n    x_train_features = pd.DataFrame(x_train[features])\n    x_valid_features = pd.DataFrame(x_valid[features])\n\n    print(\": Build CatBoost model\")\n    model = CatBoostClassifier(\n        **cat_params\n    )\n    model.fit(\n        x_train_features, \n        y_train,\n        eval_set=[(x_valid_features, y_valid)],\n        verbose=100,\n    )\n\n    train_predictions = model.predict(x_valid_features)\n    \n    print(model.get_feature_importance(prettified=True))\n    importances_per_fold = pd.DataFrame(model.get_feature_importance(prettified=True))\n    importances = pd.concat([importances, importances_per_fold], axis=0, sort=False)\n    print(classification_report(y_valid, train_predictions, target_names=[\"Not Real\", \"Real\"]))\n    score = model.score(x_valid_features, y_valid)\n    if score > best_score:\n        print(\"--> This model is the best so far {:0.5}\".format(score))\n        best_model = model\n        best_score = score\n    del model\n    del x_train_features\n    del x_valid_features\n    gc.collect()","15e38706":"import warnings\nwarnings.simplefilter('ignore', FutureWarning)\n\nplt.figure(figsize=(14, 35))\n_ = sns.barplot(x=\"Importances\", y=\"Feature Id\", data=importances.sort_values('Importances', ascending=False))","2378a379":"train_features = pd.DataFrame(train[features])\n\nprint(\": Build CatBoost model\")\nmodel = CatBoostClassifier(\n    **cat_params\n)\nmodel.fit(\n    train_features, \n    train[\"target\"],\n)\n","b220d8ae":"test_features = pd.DataFrame(test[features])\npredictions = model.predict(test_features)\nsubmission = pd.DataFrame({\"id\": test[\"id\"], \"target\": predictions})\nsubmission.to_csv(\"submission.csv\", index=False)","9b91481a":"Now let's look at the keyword in relation to whether their target is real `1` or not real `0`. Let's just take a look at the first 50 rows or so.","0101adeb":"As predicted, we're missing the same amount of state information. Looking at the low counts for each state, we're probably not going to get very useful information from this field, but we'll keep it intact for now.","4490cec7":"There are a few things we can collapse. For example, `arson` and `arsonist` can be collapsed to `arson`. Let's go ahead and make a few of these changes.","039a3831":"Now that we have country and state information, we should be able to look at those fields the same way we examined keywords. Let's take a look what happens.","469e980a":"# 6.3 Personal Pronouns\n\nLet's take a look at personal pronouns for a moment. Our hypothesis is that disaster tweets are unlikely to contain personal pronouns such as `me` or `you` when talking about a disaster. Let's separate out those personal pronouns and see if they have any significance.","f8ac48c1":"Now we're facing a challenge. We could keep one duplicate with one target class, but we don't have access to the method by which the dataset creators used to mark up real versus not real disaster tweets. They may have had access to more information than us, so we have to be careful if we alter the dataset - we could introduce personal bias. While it may be tempting to try to keep some of the data (e.g. `that horrible sinking feeling when you've been at home on your phone for a while and you realise its been on 3G this whole time` seems like it should be marked as `not real`), the better approach is to simply delete the offending duplicates. While this cuts our training size down, we ensure we haven't inadventently introduced bias to the dataset.","837fccc9":"It looks like we have quite a few duplicates. In some instances, the duplicates resolve to the same target class, but in others such as duplicate indexes `5620` and `5641`, we have the same tweet belonging to two different classes. For those instances where the tweet belongs to the same class, we can simply delete the duplicates.","53bbc7e9":"# 6.1 Sentiment Analysis, Subjectivity, Contraction Removal\n\nWe are going to do some simple cleanup to help out with our word analysis. First, let's convert to lowercase, and fix contractions. While we're at it, let's extract the sentiment and subjectivity of each sentence as well. The idea is that disaster tweets should be closer to objective statements of facts, while other tweets may contain some degree of subjectivity. As well, the idea is that disaster tweets may contain a degree of sentiment different from other tweets. We'll see how useful this information is when we create a model. We'll also go ahead and extract the part-of-speech (POS) tags from each tweet. There may be signal in the POS frequencies that differs between disaster tweets and other tweets.","b222b0ed":"In some instances we have countries, others include states, and some include cities. Yet others include junk data such as `global` as well as `Twitter Lockout in progress`. We'll need a way to clean and normalize this data so that it's a little more useful to us. Normalizing this data may turn out to be beneficial, but based on how messy the field is, it may not be worthwhile to spend huge amounts of time trying to clean it. As it stands, let's see if we can use the Python package `pycountry` to help us sort out some of this data. What we'll do is try and sort out real locations from ones that are not real. We can compare what is in the `location` field to subdivision data from `pycountry`. If we get a match, we'll save the state and country to some new columns on the dataframe. If we don't get a match, we'll try and do a little more processing. If we have two floating point numbers, we probably have a set of geo coordinates, so we can mark that as not being location spam. Other than that, we can't do much with the data, so we'll flag it as probable spam.","8b0279d9":"# 6. Pre-processing Text\n\nFor our textual analysis to be useful, we'll have to perform some pre-processing on the text first to make it easier to work with. First, let's check out the text fields and see what we're dealing with in more detail.","fcd1c7f3":"# 7. Training and Validating the Classifier\n\nNow it's time to acutally build a classifier and see how well it does. To evaluate how well our features are working, we're going to split up our training data into a training set and a validation set. We'll do this 5 times for a 5-fold cross validation. Our difference between sets gives us an idea how robust our model actually is to variations in training data. To handle our textual data, we'll use CatBoost, as it can handle textual fields very nicely for us. It also allows us to conveniently handle categorical data as well, without having to resort to label encoding it ourselves. We'll set up CatBoost to automatically determine the best balance of each of the data fields for us, so we don't have to worry about a poorly performing field drowning out informative fields. We'll also set our evaluation metric for CatBoost to match the competition's output, so we can get a better idea of how well it's performing during our training phase.","435252b5":"There may be some separation here that can work to our favor. Specifically, we see that when the tweet contains personal pronouns, it has a higher probability of not being a real disaster.","8207344b":"We can see that there are certain keywords that are strongly tied to one class. For example, `airplane accident` is very strongly associated with the real disaster target - we see it appear 34 times, and 29 of those times it is a real disaster, while only 5 times it is not. This is good news, since it suggests there are likely keywords here that will provide separation between classes.","dd4f1116":"# 2. Looking at Class Imbalance\n\nIt looks like we have 7,613 training samples. Let's see how many tweets we have that are examples of disaster versus those that are not. What we're looking at is whether or not we have a balance between samples that are both real examples of disasters, and those that are not.","7ac7092c":"Here is the code to run the predictions on the test data, and build the submission file.","f6325cce":"# 9. Building and Submitting the Final Model\n\nLet's go ahead and build a model that uses all of the data, and takes all the features we've examined so far. Once the model is built, we can submit the result.","d76b5485":"# 1.2 Keyword and Location Normalization\n\nIt looks like we need to do a little cleanup here. Both `keyword` and `location` fields are meant to be interpreted as strings. While we're at it, we should probably convert them all to lowercase for ease of processing. We'll also fill all missing values (`<NA>` values) in `keyword` and `location` with the empty string. If we look at the `keyword` strings, we find that some entries have `%20` instead of a space. We should also stem the `keyword` field so we can collapse similar keywords into a single keyword (for example, `death` and `deaths` would become `death`). Let's go ahead and make those changes to the dataframe. ","285bf044":"# 5. Simple Feature Engineering\n\nBefore we look directly at the text as a feature, let's think about some of the other first-order information we can extract from it. Here are a few features that may be informative:\n\n* Total length of the text\n* Average word length\n* Number of `@` mentions\n* Number of hashtags\n* Number of numeric values in the text (excluding timestamps)\n* Number of URLs in the text\n* Number of timestamps in the text\n* Hashtags in the text\n* `@` mentions in the text\n* Emojis in the text\n\nLet's go ahead and extract these fields.","e4280c16":"# 1. Importing the Data\n\nThe first step in the process is to import our training data so we can see what kinds of information we have to work with. For this project, we'll start by importing the entire training dataset into a single Pandas dataframe.","08b3aedf":"There are quite a number of entries for which we have no country information. The first row shows us the number of rows without country information. The total is 5,353 entries, which is more than half of our available training data. For entries with countries, we're seeing somewhat equal splits between real and not real disasters. This is to be expected, as people geotag tweets from all countries whether or not they are actually disasters. It's unlikely that real disasters would exclusively be geotagged. This is probably the same for state information. Let's take a look.","a4b466d8":"# 8. Feature Performance\n\nWe can take a look and see how our various features are performing.","84f861c8":"# Introduction\n\nThe *Real or Not? NLP with Disaster Tweets* competitions offers a neat opportunity to see how different approaches to natural language processing work when compared to one another. In this notebook, we'll look at how to start examining NLP data and performing some rudimentary first and second-order feature engineering. Here's a breakdown of what this notebook covers:\n\n* Perform an initial exploration of some simple fields.\n* Clean and normalize the data set.\n* Extract first and second-order features and examine how useful they are.\n* Perform rudimentary natural language processing on the text field.\n* Evaluate our natural language model.\n* Use the model and make predictions that we can submit to the competition.","eb77972d":"# 3. Looking at Keywords\n\nLet's take a closer look at what kind of information we have in the `keyword` field, specifically what unique values we have.","47f5d5fd":"# 6.2 Part of Speech Analysis\n\nWe're going to take the part of speech field that we extracted last time and generate a set of new features. Each one will be associated with a POS tag, and will simply be a count of how many there are. We'll add these to the feature list for the classifier.","0f4721ed":"# 6.4 Normalization of Text for Bag-Of-Words Analysis\n\nFor the remaining part of the text, we're going to treat it as a bag-of-words. The idea is that occurrences of each word can appear independently of one another, and that certain words appear more often for real disaster tweets than other tweets. In order to perform this analysis, we need to do a little more data cleanup. Here's what we're going to do:\n\n* Remove words that don't have any value, such as `the`, `of`, `and` (stopword removal)\n* We're going to strip out any links since they are `tco` encoded for Twitter\n* We'll remove all punctuation\n* We'll remove the numerics\n* We'll remove multiple whitespaces\n* Stem the text","4507c3d3":"For this particular set of data, it looks like we have a slightly skewed distribution between the two classes. In this instance, we'll have to be careful with any machine learning algorithm we use, since we have more tweets that do not pertain to disasters than we do that contain real disasters. ","599e2604":"As we can see, the text of the tweet, plus the keywords fields are the major driving forces for correct categorization. ","0623dc54":"# 4. Looking at Location\n\nLet's take look at the first 500 entries in the location field and see what we're working with.","472bf500":"# 1.1 Eliminating Duplicates\n\nOne thing we should do is check to see if we have duplicated or conflicting data. Here's an easy way to check for textual duplicates against the `target` - which is the class we're trying to predict."}}