{"cell_type":{"40b7856e":"code","317c4be3":"code","53a9e7f1":"code","15e6f855":"code","8c2f1534":"code","e25e7288":"code","ca642e8e":"code","b795e633":"code","bbded5bd":"code","c1818d78":"code","a6c6348c":"code","d2194e62":"code","6694d585":"code","fe3c52a6":"code","81b6c9aa":"code","d8312544":"code","bef7e488":"code","f48009f3":"code","40c2f508":"code","23547e98":"code","2eba2e56":"code","b22741dc":"code","f01dc3bb":"code","07c6ebb5":"code","87b1cb05":"code","8a75f59c":"code","106d9707":"code","84325b77":"code","6d045c8b":"code","e84e369c":"code","96cf311b":"code","11e3377d":"code","6cba3903":"code","271b7946":"code","221a7616":"code","21ca606a":"code","22da2fe1":"code","780d9a2e":"markdown","64797e88":"markdown","0ed914a2":"markdown","77408132":"markdown","005c517c":"markdown","0630334f":"markdown","54d2c3f1":"markdown"},"source":{"40b7856e":"import sys\n!git clone --quiet https:\/\/github.com\/yabhi0807\/libml1.git \/kaggle\/tmp\/fastai # This is my repo with all the fastai(updated) libraries \nsys.path.append('\/kaggle\/tmp\/fastai')\n!mkdir \/kaggle\/tmp\/data\/\n!ln -s \/kaggle\/tmp\/* \/kaggle\/working\/","317c4be3":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","53a9e7f1":"from fastai.conv_learner import *","15e6f855":"PATH = '\/kaggle\/tmp\/data\/planet\/'","8c2f1534":"os.makedirs('\/kaggle\/tmp\/data\/planet\/models', exist_ok=True)\nos.makedirs('\/kaggle\/tmp\/cache\/planet\/tmp', exist_ok=True)","e25e7288":"!cp -r ..\/input\/planets-dataset\/planet\/planet\/train-jpg \/kaggle\/tmp\/data\/planet\/train-jpg\n!cp -r ..\/input\/planets-dataset\/planet\/planet\/test-jpg \/kaggle\/tmp\/data\/planet\/test-jpg\n!cp -r ..\/input\/planets-dataset\/planet\/planet\/train_classes.csv \/kaggle\/tmp\/data\/planet\/","ca642e8e":"ls {PATH}","b795e633":"from fastai.plots import *","bbded5bd":"list_paths = [f\"{PATH}train-jpg\/train_0.jpg\", f\"{PATH}train-jpg\/train_1.jpg\"]\ntitles=[\"haze primary\", \"agriculture clear primary water\"]\nplots_from_files(list_paths, titles=titles, maintitle=\"Multi-label classification\")","c1818d78":"from sklearn.metrics import fbeta_score\nimport warnings\n    \ndef f2(preds, targs, start=0.17, end=0.24, step=0.01):\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        return max([fbeta_score(targs.cpu(), (preds>th).cpu(), 2, average='samples')\n                    for th in np.arange(start,end,step)])","a6c6348c":"metrics=[f2]\nf_model = resnet34","d2194e62":"label_csv = f'{PATH}train_classes.csv'\nn = len(list(open(label_csv)))-1\nval_idxs = get_cv_idxs(n)","6694d585":"def get_data(sz):\n    tfms = tfms_from_model(f_model, sz, aug_tfms=transforms_top_down, max_zoom=1.05)\n    return ImageClassifierData.from_csv(PATH, 'train-jpg', label_csv, tfms=tfms,\n                    suffix='.jpg', val_idxs=val_idxs, test_name='test-jpg')","fe3c52a6":"data = get_data(256)","81b6c9aa":"x,y = next(iter(data.val_dl))","d8312544":"y","bef7e488":"list(zip(data.classes, y[0]))","f48009f3":"plt.imshow(data.val_ds.denorm(to_np(x))[0]*1.4); # multiplying by 1.4 to make it visible","40c2f508":"sz=64","23547e98":"data = get_data(sz)","2eba2e56":"data = data.resize(int(sz*1.3), 'tmp')","b22741dc":"learn = ConvLearner.pretrained(f_model, data, metrics=metrics)","f01dc3bb":"lrf=learn.lr_find()\nlearn.sched.plot()","07c6ebb5":"lr = 0.2","87b1cb05":"learn.fit(lr, 3, cycle_len=1, cycle_mult=2)","8a75f59c":"lrs = np.array([lr\/9,lr\/3,lr])","106d9707":"learn.unfreeze()\nlearn.fit(lrs, 3, cycle_len=1, cycle_mult=2)","84325b77":"learn.save(f'{sz}')","6d045c8b":"learn.sched.plot_loss()","e84e369c":"sz=128","96cf311b":"learn.set_data(get_data(sz))\nlearn.freeze()\nlearn.fit(lr, 3, cycle_len=1, cycle_mult=2)","11e3377d":"# learn.unfreeze()\n# learn.fit(lrs, 3, cycle_len=1, cycle_mult=2)\n# learn.save(f'{sz}')","6cba3903":"# Uncomment for better accuracy\n\n# sz=256\n\n# learn.set_data(get_data(sz))\n# learn.freeze()\n# learn.fit(lr, 3, cycle_len=1, cycle_mult=2)\n\n# learn.unfreeze()\n# learn.fit(lrs, 3, cycle_len=1, cycle_mult=2)\n# learn.save(f'{sz}')","271b7946":"multi_preds, y = learn.TTA()\npreds = np.mean(multi_preds, 0)","221a7616":"preds.shape, y.shape","21ca606a":"def f2_(preds, targs, start=0.17, end=0.24, step=0.01):\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        return max([fbeta_score(targs, (preds>th), 2, average='samples')\n                    for th in np.arange(start,end,step)])\nf2_(preds,y)","22da2fe1":"# learn.summary() # Uncomment for whole model summary","780d9a2e":"In single-label classification each sample belongs to one class. In the previous example, each image is either a *dog* or a *cat*.","64797e88":"## Multi-label versus single-label classification","0ed914a2":"We use a different set of data augmentations for this dataset - we also allow vertical flips, since we don't expect vertical orientation of satellite images to change our classifications.","77408132":"In multi-label classification each sample can belong to one or more classes. In the previous example, the first image belongs to two classes: *haze* and *primary*. The second image belongs to four classes: *agriculture*, *clear*, *primary* and  *water*.","005c517c":"## Model Summary","0630334f":"## Multi-label models for Planet dataset","54d2c3f1":"## Multi-label classification"}}