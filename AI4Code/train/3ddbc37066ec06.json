{"cell_type":{"fb801515":"code","f1b11bca":"code","3a043c9f":"code","c4752d90":"code","583307f1":"code","262f7b68":"code","c879016f":"code","4d1bc5f5":"code","d6e1d898":"code","7aeaa5b5":"code","d8196130":"code","05d16b8c":"code","a28d4f6c":"code","a9b8c9de":"code","feb9db85":"code","94780e4a":"code","a873c993":"code","4cd7621b":"code","5ce919e2":"code","1e5a210f":"code","ac99b003":"code","24d160fe":"code","c054e08b":"code","03f5902d":"code","5c8f864f":"code","da26e462":"code","5bb58af4":"code","e92c62f9":"code","a39174b0":"code","a2de8ef3":"code","3352b82e":"code","43a5c8ac":"code","ee73dea0":"code","aefce347":"code","ab8c5f0c":"code","739c861c":"code","831027de":"code","e9ec1863":"code","48fad1a1":"code","da38215d":"code","f6a66971":"code","5186a84f":"code","e2e0d733":"code","5f78cc3b":"code","bd5fa208":"code","60f1fe8d":"code","4fe22dfb":"code","3c45fff1":"code","8717defc":"code","99c47495":"code","ac20192f":"code","c6f433b7":"code","70f99a3e":"code","e52cf0b1":"code","edfaafaa":"code","6e1e6ea1":"code","5c9b9d95":"code","42922b87":"code","533543d9":"code","70dfd47b":"code","53d22373":"code","ec640896":"code","c327c78b":"code","dd44db22":"code","68d64cdc":"code","6f59d812":"code","04e873b6":"code","d9758b49":"code","98f18462":"code","bab609e0":"code","32c0bfe0":"code","e4d478cd":"markdown","b5b72c33":"markdown","7ec18272":"markdown","36860c0d":"markdown","5b4a88ce":"markdown","e75fea54":"markdown","f79d026c":"markdown","9ab5f353":"markdown","33ca0a6d":"markdown","5821e1c6":"markdown","c4c8b7a5":"markdown","dac35ff9":"markdown","2c039b20":"markdown","f8be2e95":"markdown","15734f6b":"markdown","fd13290c":"markdown"},"source":{"fb801515":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f1b11bca":"# import libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV","3a043c9f":"#load data\ndata=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndata.head(5)","c4752d90":"data.shape","583307f1":"data.describe()","262f7b68":"data.SalePrice.hist(bins=20)","c879016f":"data[\"SalePrice_log\"] = np.log1p(data.SalePrice)\ndata.drop(columns=\"SalePrice\", inplace=True)\ndata.SalePrice_log.hist(bins=20)","4d1bc5f5":"basement = ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1'\n            , 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF','BsmtFinType2'\n            , 'BsmtFinSF2', \"BsmtFullBath\", \"BsmtHalfBath\"]\nprint(*basement, sep=\", \")","d6e1d898":"def corr_heatmap(columns=None, saleprice=[\"SalePrice_log\"], df=data\n                 , figsize=(8,6), vmin=-1, vmax=1, showvalue=True):\n    columns = df.columns if columns == None else columns + saleprice\n    corr = df[columns].corr()\n    plt.figure(figsize=figsize)\n    return sns.heatmap(corr, vmin=vmin, vmax=vmax, annot=showvalue)\ncorr_heatmap(basement)","7aeaa5b5":"def pairplot(columns, include_sale=True, data=data, kwargs={}):\n    if include_sale & (\"SalePrice_log\" not in columns):\n        columns = columns + [\"SalePrice_log\"]\n    sns.pairplot(data=data[columns], **kwargs)\npairplot(basement, kwargs={\"markers\":\"+\", \"height\":1.25})","d8196130":"# to visulize null values in data\ndata.isnull().sum()","05d16b8c":"sns.heatmap(data.isnull(),yticklabels=False,cbar=False)","a28d4f6c":"#to display the column names\ndata.columns","a9b8c9de":"#dropping the columns\ndata.drop(['Alley'], axis=1, inplace=True)\ndata.drop(['FireplaceQu'], axis=1, inplace=True)\ndata.drop(['PoolQC'], axis=1, inplace=True)\ndata.drop(['Fence'], axis=1, inplace=True)\ndata.drop(['MiscFeature'], axis=1, inplace=True)\ndata.drop(['GarageYrBlt'], axis=1, inplace=True)","feb9db85":"#filling the missing data numerical\ndata['LotFrontage']=data['LotFrontage'].fillna(data['LotFrontage'].mean())\ndata['MasVnrArea']= data['MasVnrArea'].fillna(data['MasVnrArea'].mean())","94780e4a":"#filling the missing data discrete\ndata['MasVnrType']=data['MasVnrType'].fillna(data['MasVnrType'].mode()[0])\ndata['BsmtQual']=data['BsmtQual'].fillna(data['BsmtQual'].mode()[0])\ndata['BsmtCond']=data['BsmtCond'].fillna(data['BsmtCond'].mode()[0])\ndata['BsmtExposure']=data['BsmtExposure'].fillna(data['BsmtExposure'].mode()[0])\ndata['BsmtFinType1']=data['BsmtFinType1'].fillna(data['BsmtFinType1'].mode()[0])\ndata['BsmtFinType2']=data['BsmtFinType2'].fillna(data['BsmtFinType2'].mode()[0])\ndata['Electrical']=data['Electrical'].fillna(data['Electrical'].mode()[0])\ndata['GarageType']=data['GarageType'].fillna(data['GarageType'].mode()[0])\ndata['GarageFinish']=data['GarageFinish'].fillna(data['GarageFinish'].mode()[0])\ndata['GarageQual']=data['GarageQual'].fillna(data['GarageQual'].mode()[0])\ndata['GarageCond']=data['GarageCond'].fillna(data['GarageCond'].mode()[0])","a873c993":"#after Data Cleaning , Checking the data for missing values\ndata.isnull().sum()","4cd7621b":"sns.heatmap(data.isnull(),yticklabels=False,cbar=False)","5ce919e2":"#copy the train dataframe\ntrain_dataframe=data.copy()","1e5a210f":"train_dataframe.head()","ac99b003":"data=pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ndata.head(5)","24d160fe":"data.shape","c054e08b":"# to visulize null values in data\ndata.isnull().sum()","03f5902d":"#visualize with heatmap\nsns.heatmap(data.isnull(),yticklabels=False,cbar=False,cmap='viridis')","5c8f864f":"#to display the column names\ndata.columns","da26e462":"#dropping the columns with more than half of missing values\ndata.drop(['Alley','FireplaceQu','PoolQC','Fence','MiscFeature','GarageYrBlt'], axis=1, inplace=True)","5bb58af4":"#filling the missing data numerical\ndata['LotFrontage']=data['LotFrontage'].fillna(data['LotFrontage'].mean())\ndata['MasVnrArea']= data['MasVnrArea'].fillna(data['MasVnrArea'].mean())\ndata['BsmtFinSF1']= data['BsmtFinSF1'].fillna(data['BsmtFinSF1'].mean())\ndata['BsmtFinSF2']= data['BsmtFinSF2'].fillna(data['BsmtFinSF2'].mean())\ndata['BsmtUnfSF']= data['BsmtUnfSF'].fillna(data['BsmtUnfSF'].mean())\ndata['TotalBsmtSF']= data['TotalBsmtSF'].fillna(data['TotalBsmtSF'].mean())\ndata['GarageArea']= data['GarageArea'].fillna(data['GarageArea'].mean())","e92c62f9":"#filling the missing data discrete\ndata['MSZoning']=data['MSZoning'].fillna(data['MSZoning'].mode()[0])\ndata['Utilities']=data['Utilities'].fillna(data['Utilities'].mode()[0])\ndata['Exterior1st']=data['Exterior1st'].fillna(data['Exterior1st'].mode()[0])\ndata['Exterior2nd']=data['Exterior2nd'].fillna(data['Exterior2nd'].mode()[0])\ndata['MasVnrType']=data['MasVnrType'].fillna(data['MasVnrType'].mode()[0])\ndata['BsmtQual']=data['BsmtQual'].fillna(data['BsmtQual'].mode()[0])\ndata['BsmtCond']=data['BsmtCond'].fillna(data['BsmtCond'].mode()[0])\ndata['BsmtExposure']=data['BsmtExposure'].fillna(data['BsmtExposure'].mode()[0])\ndata['BsmtFinType1']=data['BsmtFinType1'].fillna(data['BsmtFinType1'].mode()[0])\ndata['BsmtFinType2']=data['BsmtFinType2'].fillna(data['BsmtFinType2'].mode()[0])\ndata['BsmtFullBath']=data['BsmtFullBath'].fillna(data['BsmtFullBath'].mode()[0])\ndata['BsmtHalfBath']=data['BsmtHalfBath'].fillna(data['BsmtHalfBath'].mode()[0])\ndata['KitchenQual']=data['KitchenQual'].fillna(data['KitchenQual'].mode()[0])\ndata['Functional']=data['Functional'].fillna(data['Functional'].mode()[0])\ndata['GarageType']=data['GarageType'].fillna(data['GarageType'].mode()[0])\ndata['GarageFinish']=data['GarageFinish'].fillna(data['GarageFinish'].mode()[0])\ndata['GarageCars']=data['GarageCars'].fillna(data['GarageCars'].mode()[0])\ndata['GarageQual']=data['GarageQual'].fillna(data['GarageQual'].mode()[0])\ndata['GarageCond']=data['GarageCond'].fillna(data['GarageCond'].mode()[0])\ndata['SaleType']=data['SaleType'].fillna(data['SaleType'].mode()[0])\ndata['SaleCondition']=data['SaleCondition'].fillna(data['SaleCondition'].mode()[0])","a39174b0":"#after Data Cleaning , Checking the data for missing values\ndata.isnull().sum()","a2de8ef3":"data.shape","3352b82e":"#visualize with heatmap\nsns.heatmap(data.isnull(),yticklabels=False,cbar=False,cmap='viridis')","43a5c8ac":"data.head(5)","ee73dea0":"#copy the twat dataframe\ntest_dataframe=data.copy()","aefce347":"#Concatinating train and test Dataset\ncombined_dataframe=pd.concat([train_dataframe,test_dataframe],axis=0,sort=True)","ab8c5f0c":"combined_dataframe.isnull().sum()","739c861c":"#visualize with heatmap\nsns.heatmap(combined_dataframe.isnull(),yticklabels=False,cbar=False,cmap='viridis')","831027de":"combined_dataframe.drop(['SaleCondition'], axis=1, inplace=True)","e9ec1863":"#visualize with heatmap\nsns.heatmap(combined_dataframe.isna(),yticklabels=False,cbar=False,cmap='viridis')","48fad1a1":"combined_dataframe['SalePrice'].isna().sum()\n\n","da38215d":"combined_dataframe['SalePrice']= combined_dataframe['SalePrice'].fillna(combined_dataframe['SalePrice'].mean())","f6a66971":"#visualize with heatmap\nsns.heatmap(combined_dataframe.isnull(),yticklabels=False,cbar=False,cmap='viridis')","5186a84f":"combined_dataframe.shape","e2e0d733":"#columns with categorical values\ncolumns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n        'ExterCond',\n         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n         'CentralAir',\n         'Electrical','KitchenQual','Functional',\n         'GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']","5f78cc3b":"#onehotcoding to convert categorical values to numerical\n\ndef category_onehot_multcols(multcolumns):\n    df_final=combined_dataframe\n    i=0\n    for fields in multcolumns:\n        \n        print(fields)\n        df1=pd.get_dummies(combined_dataframe[fields],drop_first=True)\n        \n        combined_dataframe.drop([fields],axis=1,inplace=True)\n        if i==0:\n            df_final=df1.copy()\n        else:\n            \n            df_final=pd.concat([df_final,df1],axis=1)\n        i=i+1\n        \n       \n    print(df_final)    \n    df_final=pd.concat([combined_dataframe,df_final],axis=1)\n        \n    return df_final","bd5fa208":"#calling the onehotcoding function\ncombined_dataframe = category_onehot_multcols(columns)","60f1fe8d":"#shape of dataframe after one hot encoding\ncombined_dataframe.shape","4fe22dfb":"# To remove duplicate column\ncombined_dataframe =combined_dataframe.loc[:,~combined_dataframe.columns.duplicated()]","3c45fff1":"combined_dataframe.shape","8717defc":"from sklearn.model_selection import train_test_split\nX=combined_dataframe.drop(['SalePrice'],axis=1)\ny=combined_dataframe['SalePrice']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","99c47495":"print(X_train.shape, y_train.shape)\nprint (X_test.shape, y_test.shape)","ac20192f":"scaler=MinMaxScaler()\nscaler.fit(X_train)\nscaled_X_train=scaler.transform(X_train)\nscaled_X_test=scaler.transform(X_test)","c6f433b7":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators =1000, random_state=42)\nrf.fit(scaled_X_train,y_train)","70f99a3e":"y_pred = rf.predict(scaled_X_test)","e52cf0b1":"print(\"The Train score of random forest: {:.3f}\".format(rf.score(scaled_X_train,y_train)))\nprint(\"The Test score of random forest: {:.3f}\".format(rf.score(scaled_X_test,y_test)))","edfaafaa":"#the result of predicted y value to  actual value of y\ndf= pd.DataFrame(data=[y_pred,y_test])\ndf","6e1e6ea1":"rss=((y_test-y_pred)**2).sum()\nmse=np.mean((y_test-y_pred)**2)\nprint(\"Final rmse value is =\",np.sqrt(np.mean((y_test-y_pred)**2)))","5c9b9d95":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\ncross_val_score(rf,scaled_X_train,y_train,cv=5).mean()\n\n\n\n\n","42922b87":"param_grid =  {'n_estimators' : np.arange(1000,4000,1000)}\ngrid = GridSearchCV(RandomForestRegressor(), param_grid=param_grid, cv=5, return_train_score=True)\ngrid.fit(scaled_X_train, y_train)\nprint(\"Best Parameter: {}\".format(grid.best_params_))\nprint(\"best_cv_score: {:.2f}\".format(grid.best_score_))\nprint(\"train_score: {:.3f}\".format(grid.score(scaled_X_train,y_train)))\nprint(\"test_score: {:.3f}\".format(grid.score(scaled_X_test,y_test)))\n\n\n","533543d9":"param_grid =  {'n_estimators' : np.arange(1000,4000,1000)}\ngrid = GridSearchCV(RandomForestRegressor(random_state=5,\n                                max_depth=9,min_samples_split=10,max_features='sqrt',\n                                min_samples_leaf=15), param_grid=param_grid, cv=5, )\ngrid.fit(scaled_X_train, y_train)\nprint(\"Best Parameter: {}\".format(grid.best_params_))\nprint(\"best_cv_score: {:.2f}\".format(grid.best_score_))\nprint(\"train_score: {:.3f}\".format(grid.score(scaled_X_train,y_train)))\nprint(\"test_score: {:.3f}\".format(grid.score(scaled_X_test,y_test)))","70dfd47b":"gridsearch_rfr=RandomForestRegressor(random_state=5,n_estimators=2000)\n\ngridsearch_rfr.fit(scaled_X_train, y_train)","53d22373":"y_pred = gridsearch_rfr.predict(scaled_X_test)","ec640896":"df= pd.DataFrame(data=[y_pred,y_test])\ndf","c327c78b":"rss=((y_test-y_pred)**2).sum()\nmse=np.mean((y_test-y_pred)**2)\nprint(\"Final rmse value is =\",np.sqrt(np.mean((y_test-y_pred)**2)))","dd44db22":"#grid search for Gradient Boosting\nfrom sklearn.ensemble import GradientBoostingRegressor \nmyparam_grid={'n_estimators' : range(1000,4000,1000)}\nmygrid = GridSearchCV(estimator = GradientBoostingRegressor(learning_rate=0.05, min_samples_split=10,min_samples_leaf=15,max_depth=4,max_features='sqrt',random_state=5), \n                      param_grid = myparam_grid,iid=False, cv=5)\n\nmygrid.fit(scaled_X_train,y_train)\nprint(\"The grid search GradientBoostingRegressor Train Dataset with score: {:.3f}\".format(mygrid.score(scaled_X_train,y_train)))\nprint(\"The grid search GradientBoostingRegressor Test Dataset with score: {:.3f}\".format(mygrid.score(scaled_X_test,y_test)))\nprint(\"Best Parameter: {}\".format(mygrid.best_params_))\nprint(\"best cv accuracy score:{:.2f}\".format(mygrid.best_score_))","68d64cdc":"gbm1 = GradientBoostingRegressor(random_state=5,n_estimators=3000,learning_rate=0.05,\n                                max_depth=9,min_samples_split=10,max_features='sqrt',\n                                min_samples_leaf=15,loss='huber')\ngbm1.fit(scaled_X_train, y_train)","6f59d812":"y_pred = gbm1.predict(scaled_X_test)","04e873b6":"print(\"The Train score of random forest: {:.3f}\".format(gbm1.score(scaled_X_train,y_train)))\nprint(\"The Train score of random forest: {:.3f}\".format(gbm1.score(scaled_X_test,y_test)))","d9758b49":"df= pd.DataFrame(data=[y_pred,y_test])\ndf","98f18462":"rss=((y_test-y_pred)**2).sum()\nmse=np.mean((y_test-y_pred)**2)\nprint(\"Final rmse value is =\",np.sqrt(np.mean((y_test-y_pred)**2)))","bab609e0":"sample=df_Test[['Id','SalePrice']]","32c0bfe0":"sample['SalePrice'] = y_pred\nsample.to_csv('final_submission.csv', index=False)","e4d478cd":"# Implementing Random Forest Regressor\n","b5b72c33":"### 1.1 Numerical features","7ec18272":"# Implementing Random Froest Regressor with cross validation","36860c0d":"1. # Data Loading and Exploration ","5b4a88ce":"# RMSE value for GridSearch Gradient Boosting Regressor","e75fea54":"# Implementing Gradient Boosting Regressor Technique with grid search","f79d026c":"# RMSE value for Random Forest Regressor","9ab5f353":"## Exploratory Data Analysis","33ca0a6d":"# Data loading and cleaning with test Dataset","5821e1c6":"### 1. Basement","c4c8b7a5":"\nThe overall-area variable TotalBsmtSF seems the most linearly predictive. If people are interested in area more than other characteristics of the basement (finished, unfinished, etc.), it may be worth removing the other three area variables BsmtFinSF1, BsmtFinSF2 and BsmtUnfSF to save running time and prevent overfitting. At the end, we will test whether dropping these variables is a good idea. In addition, as for BsmtFinSF1 and BsmtFinSF2, let's see if they are more predictive when combined with BsmtFinType.\n\nIt should also be noted that the majority of BsmtHalfBath is 0. Let's convert it to a dummy that evaluates to 0 if there is no basement halfbath and 1 otherwise.","dac35ff9":"# RMSE value for GridSearch Random Forest Regressor","2c039b20":"### Data cleaning of train Dataset","f8be2e95":"# Data preprocessing ","15734f6b":"# scaling the Dataset with MinMaxscaler","fd13290c":"# Merging Train and Test Data and cleaning the combined Dataset"}}