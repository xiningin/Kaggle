{"cell_type":{"c2108e94":"code","5108a041":"code","90498915":"code","0068cf2f":"code","0aa69bd4":"code","1acfe494":"code","0c750fb5":"code","98e59304":"code","630c56fe":"code","a8e72a3d":"code","febb6107":"code","ad2eb51c":"code","8260e385":"code","045ae322":"code","3b0728ea":"markdown","2075a95a":"markdown","55f3fa20":"markdown","6f9e3936":"markdown","3a646237":"markdown","13d78ee5":"markdown","cdb11dc0":"markdown","8493c8d3":"markdown","54f77754":"markdown","ba547bf6":"markdown","9bd63b50":"markdown","047de6cc":"markdown","3f22d406":"markdown","6f204065":"markdown","7b9644e6":"markdown","d5a9cc4f":"markdown","d11ea250":"markdown","21194efc":"markdown"},"source":{"c2108e94":"### Importing Required Packages\nimport pandas  as pd","5108a041":"## Setting up the files\nCANCERDATA = \"..\/input\/DS_WDBC_NOIDFIELD.data\"","90498915":"# Function to convert Categorical variables into numeric variables\ndef labelConvert(s):\n    s = s.strip().lower()\n    if s == \"m\":\n        return 0\n    if s == \"b\":\n        return 1\n    return -1\n\ndata = pd.read_csv(CANCERDATA, header = None, converters={30:labelConvert})\ndata[:10]","0068cf2f":"def split_Train_Test(data):\n    import random\n    TRAIN_TEST_RATIO = 0.8\n    train = []\n    test = []\n    for d in data:\n        if random.random() < TRAIN_TEST_RATIO:\n            train.append(d)\n        else:\n            test.append(d)\n    return train, test","0aa69bd4":"def predict(row, weights):\n    activation = weights[0]\n    for i in range(len(row)-1):\n        activation += weights[i + 1] * row[i]\n    return 1.0 if activation >= 0.0 else 0.0\n\n### We are using an algorithm called gradient descent.\n\ndef train_weights(train, l_rate, n_epoch):\n    weights = [0.0 for i in range(len(train[0]))]\n    for epoch in range(n_epoch):\n        sum_error = 0.0\n        for row in train:\n            prediction = predict(row, weights)\n            error = row[-1] - prediction\n            sum_error += error**2\n            weights[0] = weights[0] + l_rate * error\n            for i in range(len(row)-1):\n                weights[i + 1] = weights[i + 1] + l_rate * error * row[i]\n        if epoch % 100 == 0:\n            print('> epoch = %4d, lrate = %.4f, error =%6.1f' % (epoch, l_rate, sum_error))\n    return weights\n\n## Do not worry about the hyperparameters of this algorithm right now.\ntrain, test = split_Train_Test(data.values)\nprint(\"Training\", len(train))\nprint(\"Testing\", len(test))\nweights = train_weights(train, l_rate=0.001, n_epoch=2000)\nprint(weights)","1acfe494":"### You have preds and actuals now :)\n### Your Code Here\npred_list=[]\npass_cnt=0\nfor row in test:\n    pred = predict(row,weights)\n    pred_list.append(pred)\n    if(pred == row[-1]):\n        pass_cnt +=1\nprint(\"accuracy\", pass_cnt\/len(test))\n\nactual = [row[-1] for row in test]\n","0c750fb5":"def confusionmatrix(actuals, prediction):\n    TruePositive = sum([int(a == 1 and p == 1) for a, p in zip(actuals, prediction)])\n    TrueNegative = sum([int(a == 0 and p == 0) for a, p in zip(actuals, prediction)])\n    FalsePositive = sum([int(a == 0 and p == 1) for a, p in zip(actuals, prediction)])\n    FalseNegative = sum([int(a == 1 and p == 0) for a, p in zip(actuals, prediction)])\n    return TruePositive, TrueNegative, FalsePositive, FalseNegative\n#confusionmatrix(actual, pred)\nconfusionmatrix(actual, pred_list)","98e59304":"### Your Code Here\ntp,tn,fp,fn = confusionmatrix(actual, pred_list)\n\np = tp\/(tp+fp)\np","630c56fe":"### Your Code Here\nr = tp\/(tp+fn)\nr","a8e72a3d":"### Your Code Here\nm = 1-r\nm","febb6107":"### Your Code Here\na = (tp+tn)\/(tp+tn+fp+fn)\na","ad2eb51c":"F = 2 * ((p*r)\/p+r)\nF","8260e385":"TPR = tp\/tp+fn\n\nTPR","045ae322":"FPR = fp\/fp+tn\n\nFPR","3b0728ea":"A confusion matrix is a table that is often used to \ndescribe the performance of a classification model\non a set of test data for which the true values are known.\n\nThe entries in the confusion matrix have the following meaning in the context of our study:\n\n* a (True Positive) is the number of correct predictions that an instance is positive,\n* b (False Positive) is the number of incorrect predictions that an instance is positive,\n* c (False Negative) is the number of incorrect of predictions that an instance is negative, and\n* d (True Negative) is the number of correct predictions that an instance is negative.  \n\n\n![alt](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRozZ7IpyD6mTSUREZZ09SbaC-w8_Gae6syq2rKOBl8Az4gKzCU)","2075a95a":"Calculate miss rate\n\n$ m $ = $ 1 $ $ - $ $ r $","55f3fa20":"F1 score\n\n$ F $ = $ 2 $ *(($ precision $ * $ recall $)\/($ precision $ + $ recall $))","6f9e3936":"Here M is positive and B is negative; that is we are looking for cancerous cells. So M means it is cancerous that is positive.","3a646237":"The objective of this experiment is to learn Performance evaluation and metrics","13d78ee5":"Use the predict function and the weights that was learnt to calculate the accuracy on the test set.","cdb11dc0":"From above experiment we can say that an algorithm that has a high value for both is very good, an algorithm that is good at one or the other can be useful but it\u2019s important to understand when to use it.","8493c8d3":"Splitting dataset into train and test sets","54f77754":"** Precision ** -  ratio of correctly predicted positive observations to the total predicted positive observations. \n\n** Recall ** - ratio of correctly predicted positive observations to the all observations in actual class","ba547bf6":"### Summary","9bd63b50":"#### Assignment from my course (IIIT-H)","047de6cc":"Now let us calculate a different metric to analyze our results, called confusion matrix.","3f22d406":"In this experiment we will use Wisconsin Breast Cancer data set.The data has been modified as below\n\n* The id field has been removed\n* The diagnosis field has been moved to the end","6f204065":"#### Data Set Information\n\nNumber of instances: 569 \n\nNumber of attributes: 31 (diagnosis, 30 real-valued input features)\n\nTen real-valued features are computed for each cell nucleus:\n\n\ta) radius (mean of distances from center to points on the perimeter)\n\tb) texture (standard deviation of gray-scale values)\n\tc) perimeter\n\td) area\n\te) smoothness (local variation in radius lengths)\n\tf) compactness (perimeter^2 \/ area - 1.0)\n\tg) concavity (severity of concave portions of the contour)\n\th) concave points (number of concave portions of the contour)\n\ti) symmetry \n\tj) fractal dimension (\"coastline approximation\" - 1)\n\nThe mean, standard error, and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features.  For instance, field 1 is Mean Radius, field 11 is Radius SE, field 21 is Worst Radius. All feature values are recoded with four significant digits.\n\nThe last field is diagnosis: M for Malignant and B for Benign\n\nClass distribution: 357 benign, 212 malignant","7b9644e6":"Calculate accuracy and check with earlier accuracy that we computed.\n\n$ a $ = ($ tp $ + $ tn $) \/ ($ tp $ + $ tn $ + $ fp $ + $ fn $ )","d5a9cc4f":"Calculate precision\n\n$ p $ = $ tp $ $ \/ $ ($ tp $ + $ fp $)","d11ea250":"#### Data Source\n\nhttps:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/breast-cancer-wisconsin\/wdbc.data","21194efc":"Calculate recall \n\n$ r $ = $ tp $ $ \/$ ( $ tp $ + $fn $ ) "}}