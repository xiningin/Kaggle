{"cell_type":{"0e419503":"code","d3fc4089":"code","8c153ec7":"code","a0d9cede":"code","9285183d":"code","691e2eca":"code","64e4fd97":"code","69f89dc8":"code","56384905":"code","9eb02b94":"code","3c3e5957":"code","e8990f54":"code","12c04059":"markdown"},"source":{"0e419503":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","d3fc4089":"# Getting the Input names\nnames_list = pd.read_csv('..\/input\/NationalNames.csv')","8c153ec7":"name_gender = names_list[['Name','Gender']].drop_duplicates().copy()\n\nname_count = name_gender.groupby('Name',as_index=False).Gender.count().copy()\n\nname_count_1 = name_count[(name_count.Gender == 1)].copy()\n\nname_count_2 = name_count_1.drop('Gender',axis = 1).copy()\n\nname_gender_1 = name_gender[(name_gender.Name.isin(name_count_2.Name))].copy()\n\nname_gender_1.Name = name_gender_1.Name.str.lower()\n\nvowels = ('a','e','i','o','u')\n\n#Checking if name starts\/ends with vowels\/consonants\nname_gender_1.loc[:,'last_char_vow'] = np.where(name_gender_1.Name.str.endswith(vowels),1,0)\nname_gender_1.loc[:,'first_char_vow'] = np.where(name_gender_1.Name.str.startswith(vowels),1,0)\n\nname_gender_1.loc[:,'name_len'] = name_gender_1.Name.str.len()\n\nunq = []\n\nfor name in name_gender_1['Name']:\n    unq.append(len(list(set(name))))\n\nname_gender_1['unq_char'] = unq\n\nimport re\nrep_char = []\n\nfor name in name_gender_1['Name']:\n    rep_char.append(len(re.findall(r\"((.)\\2{1,})\",name)))\n\nname_gender_1['rep_char_count'] = rep_char\n\nname_gender_1.loc[:,'rep_char_pres'] = np.where(name_gender_1.rep_char_count > 0,1,0)\n\nrep_char_start = []\nrep_char_end = []\nfor name in name_gender_1['Name']:\n    l = list(name)\n    l_start = l[:2]\n    l_end = l[-2:]\n    if len(l_start) == len(set(l_start)):\n        rep_char_start.append(0)\n    else:\n        rep_char_start.append(1)\n    if len(l_end) == len(set(l_end)):\n        rep_char_end.append(0)\n    else:\n        rep_char_end.append(1)\n\nname_gender_1['rep_char_start_flg'] = rep_char_start \nname_gender_1['rep_char_end_flg'] = rep_char_end\n\n\nunq_name = []\nfor name in name_gender_1['Name']:\n    if len(list(name)) == len(list(set(name))):\n        unq_name.append(1)\n    else:\n        unq_name.append(0)\n\nname_gender_1['uniq_name'] = unq_name.copy() \n","a0d9cede":"all_names = name_gender_1.copy()","9285183d":"from sklearn.model_selection import train_test_split\n\nnum_test = 0.30\ntrain_data,validation_data = train_test_split(all_names, test_size=num_test, random_state=23)","691e2eca":"from sklearn import preprocessing\ndef encode_features(df_train, df_test):\n    features = ['Gender','last_char_vow','first_char_vow','rep_char_pres','rep_char_start_flg','rep_char_end_flg','uniq_name']\n    df_combined = pd.concat([df_train[features], df_test[features]])\n    \n    for feature in features:\n        le = preprocessing.LabelEncoder()\n        le = le.fit(df_combined[feature])\n        df_train[feature] = le.transform(df_train[feature])\n        df_test[feature] = le.transform(df_test[feature])\n    return df_train, df_test\n    \ndata_train, data_test = encode_features(train_data, validation_data)","64e4fd97":"from sklearn.preprocessing import OneHotEncoder\nenc=OneHotEncoder(sparse=False)\ndata_train_1=data_train\ndata_test_1=data_test\ncolumns=['last_char_vow','first_char_vow','rep_char_pres','rep_char_start_flg','rep_char_end_flg','uniq_name']\nfor col in columns:\n       # creating an exhaustive list of all possible categorical values\n        data=data_train[[col]].append(data_test[[col]])\n        enc.fit(data)\n       # Fitting One Hot Encoding on train data\n        temp = enc.transform(data_train[[col]])\n       # Changing the encoded features into a data frame with new column names\n        temp=pd.DataFrame(temp,columns=[(col+\"_\"+str(i)) for i in data[col]\n            .value_counts().index])\n       # In side by side concatenation index values should be same\n       # Setting the index values similar to the X_train data frame\n        temp=temp.set_index(data_train.index.values)\n       # adding the new One Hot Encoded varibales to the train data frame\n        data_train_1=pd.concat([data_train_1,temp],axis=1)\n       # fitting One Hot Encoding on test data\n        temp = enc.transform(data_test[[col]])\n       # changing it into data frame and adding column names\n        temp=pd.DataFrame(temp,columns=[(col+\"_\"+str(i)) for i in data[col]\n            .value_counts().index])\n       # Setting the index for proper concatenation\n        temp=temp.set_index(data_test.index.values)\n       # adding the new One Hot Encoded varibales to test data frame\n        data_test_1=pd.concat([data_test_1,temp],axis=1)","69f89dc8":"from sklearn.model_selection import train_test_split\n\nX_all = data_train_1\ny_all = data_train_1['Gender']\n\nnum_test = 0.20\nX_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, random_state=23)\n\nX_train_1 = X_train.drop(['Gender', 'Name','last_char_vow','first_char_vow',\n                          'rep_char_pres','rep_char_start_flg','rep_char_end_flg','uniq_name'], axis=1)\nX_test_1 = X_test.drop(['Gender', 'Name','last_char_vow','first_char_vow',\n                          'rep_char_pres','rep_char_start_flg','rep_char_end_flg','uniq_name'], axis=1)\n\ndata_test_1 = data_test_1.drop(['last_char_vow','first_char_vow',\n                          'rep_char_pres','rep_char_start_flg','rep_char_end_flg','uniq_name'], axis=1)","56384905":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.model_selection import GridSearchCV\n\n# Choose the type of classifier. \nclf = RandomForestClassifier()\n\n# Choose some parameter combinations to try\nparameters = {'n_estimators': [4, 6, 9], \n              'max_features': ['log2', 'sqrt','auto'], \n              'criterion': ['entropy', 'gini'],\n              'max_depth': [2, 3, 5, 10], \n              'min_samples_split': [2, 3, 5],\n              'min_samples_leaf': [1,5,8]\n             }\n\n# Type of scoring used to compare parameter combinations\nacc_scorer = make_scorer(accuracy_score)\n\n# Run the grid search\ngrid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer)\ngrid_obj = grid_obj.fit(X_train_1, y_train)\n\n# Set the clf to the best combination of parameters\nclf = grid_obj.best_estimator_\n\n# Fit the best algorithm to the data. \nclf.fit(X_train_1, y_train)\n\npredictions = clf.predict(X_test_1)\nprint(accuracy_score(y_test, predictions))","9eb02b94":"from sklearn.model_selection import KFold \nkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=None) \n\noutcomes = []\nfor train_index, test_index in kf.split(X_train_1):\n    print(\"Train:\", train_index, \"Validation:\",test_index)\n    X_train, X_test = X_train_1.values[train_index], X_train_1.values[test_index]\n    y_train, y_test = y_all.values[train_index], y_all.values[test_index]\n    clf.fit(X_train, y_train)\n    predictions = clf.predict(X_test)\n    accuracy = accuracy_score(y_test, predictions)\n    outcomes.append(accuracy)\n    print(\"Accuracy:\".format(accuracy))     \n    mean_outcome = np.mean(outcomes)\n    print(\"Mean Accuracy: {0}\".format(mean_outcome))","3c3e5957":"ids = data_test_1['Name']\n\npredictions = clf.predict(data_test_1.drop(['Name','Gender'], axis=1))\n\noutput = pd.DataFrame({ 'Name' : ids, 'Gender': predictions })\n# output.to_csv('titanic-predictions.csv', index = False)\n#output.head()","e8990f54":"merge = output.merge(data_test_1[['Name','Gender']],left_on='Name', right_on='Name', how='left')\n\nactuals = data_test_1.Gender\n\naccuracy = accuracy_score(actuals,output['Gender'])\nprint(accuracy)","12c04059":"# Creating features"}}