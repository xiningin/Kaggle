{"cell_type":{"126b4a46":"code","1a4d421d":"code","f7941bec":"code","b68c0de7":"code","5715ab74":"code","5e1d2de3":"code","f6b160dd":"code","3008c8f7":"code","dcad848c":"code","090f8650":"code","2ea1ddc4":"code","00af97bf":"code","51bc02da":"code","d7d8646f":"code","9bf9d3bb":"code","eabf2d27":"code","aceca137":"code","1efc0358":"code","55c12c49":"code","1ccda541":"code","f9299b25":"markdown","a4fb8aff":"markdown","a8ece653":"markdown","44dea1a5":"markdown","8c99eeb6":"markdown","e9583a4c":"markdown","9ed5972f":"markdown","a52d63c5":"markdown"},"source":{"126b4a46":"# Import de l'environnement classique en Data Science\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Import de la fonction permettant de s\u00e9parer notre jeu de donn\u00e9es en jeux d'entra\u00eenement et de test\nfrom sklearn.model_selection import train_test_split\n\n# Import de la fonction permettant d'impl\u00e9menter un mod\u00e8le xgboost\nimport xgboost as xgb\n\n# Import de la fonction permettant d'afficher plusieurs m\u00e9triques de performance li\u00e9es \u00e0 un mod\u00e8le de classification\nfrom sklearn.metrics import classification_report\n\n# Import de la fonction permettant d'afficher la courbe d'apprentissage d'un mod\u00e8le de Machine Learning\nfrom sklearn.model_selection import learning_curve\n\n# Commande permettant d'afficher des graphiques directement dans ce notebook\n%matplotlib inline","1a4d421d":"# Import du fichier CSV 'fashion-mnist-train' dans un DataFrame nomm\u00e9 df\ndf = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\n\n# Affichage des 10 premi\u00e8res lignes de df\ndf.head(10)","f7941bec":"# Comptage des modalit\u00e9s de notre variable 'cible'\ndf['label'].value_counts()","b68c0de7":"# Cr\u00e9ation d'une liste de labels selon la documentation du jeu de donn\u00e9es Fashion MNIST\nlabels = [\"T-shirt\/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n\n# Affichage des labels de la premi\u00e8re et derni\u00e8re image de notre jeu de donn\u00e9es d'entra\u00eenement\nprint(labels[df['label'].iloc[0]]) # Pullover\nprint(labels[df['label'].iloc[-1]]) # Sneaker","5715ab74":"# Assignation des labels \u00e0 notre jeu de donn\u00e9es en fonction du match entre les num\u00e9ros de classes et notre liste de labels\ndf['label'] = pd.Series([labels[df['label'].loc[i]] for i in range(df.shape[0])])\n\n# Affichage des nouvelles modalit\u00e9s de notre variable cible 'label'\ndf['label'].value_counts()","5e1d2de3":"# Stockage de la variable cible 'label' dans un vecteur y\ny = df['label']\n\n# Stockage des images dans un DataFrame X\nX = df.drop(['label'], axis = 1)\n\n# S\u00e9paration en un jeu d'apprentissage contenant 80% des donn\u00e9es et un jeu de test avec les donn\u00e9es restantes\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","f6b160dd":"# Transformation du DataFrame X en un tableau Numpy appel\u00e9 X_images\nX_images = np.array(X)\n\n# Affichage de la premi\u00e8re ligne de X_images\nprint(X_images[0])","3008c8f7":"# Application de la m\u00e9thode reshape pour convertir notre tableau a 784 colonnes en une matrice 28x28\nimage_1 = X_images[0].reshape(28, 28)\n\n# Affichage de la premi\u00e8re image de notre jeu de donn\u00e9es\nplt.imshow(image_1)\nplt.show()","dcad848c":"# Affichage de la premi\u00e8re image en niveaux de gris, sans graduation des axes et avec le label comme titre\nplt.imshow(image_1, cmap = \"gray_r\")\nplt.axis('off')\nplt.title(y[0])\nplt.show()","090f8650":"# Redimensionnement de toutes les lignes de notre jeu de donn\u00e9es en images 28x28\nn_samples = len(df.index)\nimages = X_images.reshape(n_samples, 28, 28)\n\n# Affichage des 50 premi\u00e8res images\nplt.figure(figsize = (20, 20))\nfor i in range(0, 50) :\n    plt.subplot(10, 5, i + 1)\n    plt.axis('off')\n    plt.imshow(images[i], cmap = \"gray_r\")\n    plt.title(y[i])","2ea1ddc4":"# Instanciation d'un classifieur xgboost nomm\u00e9 \"xgb_classifier\" \u00e0 l'aide de la classe XGBClassifier\nxgb_classifier = xgb.XGBClassifier(objective = 'binary:logistic', eval_metric = 'error', seed = 42,\n                                   tree_method = 'gpu_hist', gpu_id = 0)\n\n# Entra\u00eenement de notre mod\u00e8le xgb_classifier\nxgb_classifier.fit(X_train, y_train)\n\n# Stockage des pr\u00e9dictions effectu\u00e9es par notre mod\u00e8le xgb_baseline dans un vecteur y_xgb_baseline\ny_xgb = xgb_classifier.predict(X_test)\n\n# Calcul des m\u00e9triques de classification de notre mod\u00e8le xgb_baseline \u00e0 l'aide de la fonction classification_report\nclassification_report_xgb = classification_report(y_test, y_xgb)\nprint(classification_report_xgb)\n\n# Affichage d'une matrice de confusion entre y_test et y_xgb\nconf_matrix_xgb = pd.crosstab(y_test, y_xgb,\n                              rownames = ['Classe r\u00e9elle'],\n                              colnames = ['Classe pr\u00e9dite'])\nconf_matrix_xgb","00af97bf":"# Stockage des images de la classe 'Shirt' et de leurs indices dans les variables correspondantes\nindex_test_class_Shirt = y_test.reset_index(drop = True)[y_test.reset_index(drop = True) == 'Shirt'].index\nX_test_class_Shirt = X_test.reset_index(drop = True).loc[index_test_class_Shirt].reset_index(drop = True)\ny_test_class_Shirt = y_test.reset_index(drop = True)[y_test.reset_index(drop = True) == 'Shirt'].reset_index(drop = True)\ny_xgb_class_Shirt = pd.Series(y_xgb[index_test_class_Shirt])\n\n# Redimensionnement de toutes les lignes de notre jeu de donn\u00e9es X_test_class_Shirt en images 28x28\nn_test_class_Shirt = X_test_class_Shirt.shape[0]\nimages_class_Shirt = np.array(X_test_class_Shirt).reshape(n_test_class_Shirt, 28, 28)\n\n# Affichage de 50 images de la classe 6 mal pr\u00e9dites par notre mod\u00e8le\nplt.figure(figsize = (20, 20))\ni = 1\nfor j in range(n_test_class_Shirt) :\n    if (y_xgb_class_Shirt[j] != y_test_class_Shirt[j]) & (i <= 50):\n        plt.subplot(10, 5, i)\n        plt.axis('off')\n        plt.imshow(images_class_Shirt[j], cmap = \"gray_r\")\n        plt.title('pred: %s \/ true: %s' % (y_xgb_class_Shirt[j], y_test_class_Shirt[j]))\n        i += 1","51bc02da":"# Import de fonctions de la librairie Keras permettant d'impl\u00e9menter des r\u00e9seaux de neurones denses\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense","d7d8646f":"# Import du fichier CSV 'fashion-mnist-train' dans un DataFrame nomm\u00e9 df\ndf = pd.read_csv('..\/input\/fashionmnist\/fashion-mnist_train.csv')\n\n# Stockage de la variable cible 'label' dans un vecteur y\ny = df['label']\n\n# Stockage des images dans un DataFrame X\nX = df.drop(['label'], axis = 1)\n\n# Normalisation des valeurs de X entre 0 et 1\nX = X \/ 255\n\n# S\u00e9paration en un jeu d'apprentissage contenant 80% des donn\u00e9es et un jeu de test avec les donn\u00e9es restantes\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","9bf9d3bb":"# Stockage du nombre de classes dans une variable\nnum_classes = 10\n\n# Cr\u00e9ation d'un r\u00e9seau de neurones denses\nmodel = Sequential() # # mod\u00e8le de type s\u00e9quentiel\nmodel.add(Dense(200, activation = 'relu')) # couche cach\u00e9e de 200 neurones avec la fonction d'activation 'relu'\nmodel.add(Dense(60, activation = 'relu'))\nmodel.add(Dense(num_classes, activation = 'softmax')) # la derni\u00e8re couche (couche de sortie) contient 10 classes","eabf2d27":"model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","aceca137":"train = model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 100, verbose = 1)","1efc0358":"model.evaluate(X_test, y_test)","55c12c49":"def plot_scores(train):\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label = 'Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label = 'Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","1ccda541":"plot_scores(train)","f9299b25":"# Exercice Zalando Fashion MNIST","a4fb8aff":"D'apr\u00e8s le \"classification report\" et la matrice de confusion de notre mod\u00e8le xgb_classifier, nous pouvons en sortir plusieurs informations :\n- les performances pr\u00e9dictives du mod\u00e8le pour les classes **Ankle Boot**, **Bag**, **Sandal**, **Sneaker** et **Trouser** sont excellentes (precision allant de 96% \u00e0 99%)\n- les performances pour les classes **Coat**, **Dress**, **Pullover** et **T-shirt\/top** restent tr\u00e8s bonnes (precision allant de de 82% \u00e0 88%)\n- la performances pour la classe **Shirt** est moindre compar\u00e9\u00e9 aux autres nombres (precision de 74% et recall de 67% seulement)\n\nLes trois erreurs les plus courantes du mod\u00e8le par rapport \u00e0 cette classe **Shirt** est de pr\u00e9dire *T-shirt\/top*, *Pullover* et *Coat*, essayons alors d'afficher quelques images \u00e9tiquet\u00e9es **'Shirt'** mais qui ont \u00e9t\u00e9 pr\u00e9dites autrement :","a8ece653":"Maintenant que nous avons vu les performances pr\u00e9dictives d'un mod\u00e8le de Machine Learning tel que XGBoost, essayons de voir si nous pouvons am\u00e9liorer la pr\u00e9cision des pr\u00e9dictions \u00e0 l'aide d'un r\u00e9seau de neurones denses :","44dea1a5":"## Import des donn\u00e9es","8c99eeb6":"Nous pouvons ainsi voir que les **'Shirt'** (**chemise** en fran\u00e7ais) peuvent avoir des caract\u00e9ristiques diff\u00e9rentes telles que :\n- la pr\u00e9sence ou non de manches --> les chemises ont ainsi g\u00e9n\u00e9ralement \u00e9t\u00e9 pr\u00e9dites par erreur comme \u00e9tant des 'T-shirt\/top' ou des 'Dress'\n- la taille et la forme de l'habit --> La 19e image (4e ligne 4e colonne) repr\u00e9sente une chemise en crop-top mais a \u00e9t\u00e9 pr\u00e9dite comme \u00e9tant un sac","e9583a4c":"## Machine Learning","9ed5972f":"## Visualisation des images Fashion MNIST","a52d63c5":"## Deep Learning"}}