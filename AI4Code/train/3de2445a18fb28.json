{"cell_type":{"7093cdad":"code","3f72280c":"code","7aec2831":"code","8913c690":"code","568459fa":"code","0eb7868d":"code","a287a623":"code","1b5c3d88":"code","a2f2e2f8":"code","10e23e7a":"code","58c1b470":"code","6f5f88bd":"code","f4800592":"code","7b411e84":"code","97fa0cdc":"code","4468ce8e":"code","0141e051":"code","f0f6c65c":"code","594feb3a":"code","8379ecf3":"code","79862d0c":"code","b046cb5b":"code","27146125":"code","9c1de8f3":"code","90a4c655":"code","f65ff6ae":"code","3772962b":"code","6c75b105":"code","f835e511":"code","96136b7c":"markdown","70705679":"markdown","24bed453":"markdown","d2d4912a":"markdown","d7f3f110":"markdown","ae47aba4":"markdown","7ccf9191":"markdown","4f2b76f9":"markdown","b0ac54de":"markdown","d23acc4f":"markdown","b5e62001":"markdown","8a24e64a":"markdown","6acf6bd2":"markdown"},"source":{"7093cdad":"# Basics Imports for the kernel\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport gc\nfrom sklearn.model_selection import GroupShuffleSplit\nfrom sklearn.metrics import accuracy_score\nfrom scipy.stats import skew,kurtosis\nfrom sklearn.preprocessing import StandardScaler\nfrom numpy.fft import *\nimport keras\nimport math\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","3f72280c":"train_df = pd.read_csv('..\/input\/X_train.csv')\ntest_df = pd.read_csv('..\/input\/X_test.csv')","7aec2831":"train_df.head()","8913c690":"test_df.head()","568459fa":"# https:\/\/stackoverflow.com\/questions\/53033620\/how-to-convert-euler-angles-to-quaternions-and-get-the-same-euler-angles-back-fr?rq=1\ndef quaternion_to_euler(x, y, z, w):\n    t0 = +2.0 * (w * x + y * z)\n    t1 = +1.0 - 2.0 * (x * x + y * y)\n    X = math.atan2(t0, t1)\n\n    t2 = +2.0 * (w * y - z * x)\n    t2 = +1.0 if t2 > +1.0 else t2\n    t2 = -1.0 if t2 < -1.0 else t2\n    Y = math.asin(t2)\n\n    t3 = +2.0 * (w * z + x * y)\n    t4 = +1.0 - 2.0 * (y * y + z * z)\n    Z = math.atan2(t3, t4)\n\n    return X, Y, Z","0eb7868d":"def quaternions_conversion_1(actual):\n    \"\"\"Quaternions to Euler Angles\"\"\"\n    \n    x, y, z, w = actual['orientation_X'].tolist(), actual['orientation_Y'].tolist(), actual['orientation_Z'].tolist(), actual['orientation_W'].tolist()\n    nx, ny, nz = [], [], []\n    for i in range(len(x)):\n        xx, yy, zz = quaternion_to_euler(x[i], y[i], z[i], w[i])\n        nx.append(xx)\n        ny.append(yy)\n        nz.append(zz)\n    \n    actual['euler_x'] = nx\n    actual['euler_y'] = ny\n    actual['euler_z'] = nz\n    return actual","a287a623":"def quaternion_to_tait(q_val):\n    #We assume q_val is in this format: [qw, q1, q2, q3]\n    #And the quaternion is normalized\n    roll = np.arctan2(2*(q_val[0]*q_val[1] + q_val[2]*q_val[3]),1 - 2*(q_val[1]*q_val[1] + q_val[2]*q_val[2]))\n    pitch = np.arcsin(2*(q_val[0]*q_val[2] - q_val[3]*q_val[1]))\n    yaw = np.arctan2(2*(q_val[0]*q_val[3] + q_val[1]*q_val[2]),1 - 2*(q_val[2]*q_val[2] + q_val[3]*q_val[3]))\n    return roll, pitch, yaw","1b5c3d88":"def quaternions_conversion_2(actual):\n    \"\"\"Quaternions to Tait Angles\"\"\"\n    \n    x, y, z, w = actual['orientation_X'].tolist(), actual['orientation_Y'].tolist(), actual['orientation_Z'].tolist(), actual['orientation_W'].tolist()\n    nr, np, ny = [], [], []\n    for i in range(len(x)):\n        rr, pp, yy = quaternion_to_tait([w[i], x[i], y[i], z[i]])\n        nr.append(rr)\n        np.append(pp)\n        ny.append(yy)\n    \n    actual['roll'] = nr\n    actual['pitch'] = np\n    actual['yaw'] = ny\n    \n    return actual","a2f2e2f8":"# from @theoviel at https:\/\/www.kaggle.com\/theoviel\/fast-fourier-transform-denoising\ndef filter_signal(signal, threshold=1e3):\n    fourier = rfft(signal)\n    frequencies = rfftfreq(signal.size, d=20e-3\/signal.size)\n    fourier[frequencies > threshold] = 0\n    return irfft(fourier)","10e23e7a":"def calculate_diffs(data,feature_columns):\n        for ii,col in enumerate(feature_columns):\n            if col in ['orientation_X', 'orientation_Y', 'orientation_Z', 'orientation_W','euler_x', 'euler_y', 'euler_z','roll','pitch','yaw']:\n                np_arr = data[:,:,ii]\n                roll_arr = np.copy(np_arr)\n                roll_arr[:,1:] = roll_arr[:,:-1]\n                np_arr = np_arr - roll_arr\n                data[:,:,ii] = np_arr\n                print(f'Calculated Diffs  : {col}')\n            else:\n                pass\n                #print(f'Not changed : {col}')\n        return data","58c1b470":"def denoise(df,feature_columns):\n    for ii,col in enumerate(feature_columns):\n        if col in ['angular_velocity_X', 'angular_velocity_Y', 'angular_velocity_Z', 'linear_acceleration_X','linear_acceleration_Y', 'linear_acceleration_Z']:\n            denoised=df.groupby('series_id')[col].apply(lambda x:filter_signal(x))\n            list_denoised = []\n            for arr in denoised:\n                for val in arr:\n                    list_denoised.append(val)\n            df[col] = list_denoised\n            print(f'Denoised          : {col}')\n        else:\n            pass\n            #print(f'Not changed : {col}')\n    return df","6f5f88bd":"def process_data(train_df, Scalers=[]):\n    \n    feature_columns = train_df.columns[3:]\n    train_df = denoise(train_df,feature_columns)\n    train_df['totl_anglr_vel'] = np.power(np.power(train_df['angular_velocity_X'].values,2) + np.power(train_df['angular_velocity_Y'].values,2) \\\n                                      + np.power(train_df['angular_velocity_Z'].values,2),0.5)   \n\n    train_df['totl_linear_accel'] = np.power(np.power(train_df['linear_acceleration_X'].values,2) + np.power(train_df['linear_acceleration_Y'].values,2) \\\n                                          + np.power(train_df['linear_acceleration_Z'].values,2),0.5) \n        \n    train_df = quaternions_conversion_1(train_df)\n    train_df = quaternions_conversion_2(train_df)\n    \n    feature_columns = train_df.columns[7:]\n    features    = len(feature_columns)\n    data = train_df[feature_columns].values\n    data = data.reshape((data.shape[0]\/\/128,128,features))\n    \n    data = calculate_diffs(data,feature_columns)\n    \n    \n    meta_data = pd.DataFrame()\n    for ii,col in enumerate(feature_columns):\n        meta_data[col+'_mean'] = data[:,:,ii].mean(axis=1)\n        meta_data[col+'_std']  = data[:,:,ii].std(axis=1)\n        \n        meta_data[col+'_min']  = data[:,:,ii].min(axis=1)\n        meta_data[col+'_max']  = data[:,:,ii].max(axis=1)\n\n        meta_data[col+'_diff_mean']  = np.diff(data[:,:,ii],axis=1).mean(axis=1)\n        meta_data[col+'_diff_std']   = np.diff(data[:,:,ii],axis=1).std(axis=1)\n        \n        meta_data[col+'_skew']     = skew(data[:,:,ii],axis=1)\n        meta_data[col+'_kurtosis'] = kurtosis(data[:,:,ii],axis=1)\n        \n    data = data.reshape((data.shape[0]*128,features))\n    if Scalers==[]:\n        SS = StandardScaler()\n        SS.fit(data)\n        Scalers.append(SS)\n        SS_Meta = StandardScaler() \n        SS_Meta.fit(meta_data)\n        Scalers.append(SS_Meta)\n        \n    data      = Scalers[0].transform(data)\n    meta_data = Scalers[1].transform(meta_data)\n         \n    data = data.reshape((data.shape[0]\/\/128,128,features))\n    \n    return data,meta_data,Scalers","f4800592":"data_train,meta_data_train,Scalers=process_data(train_df)","7b411e84":"data_test,meta_data_test,_=process_data(test_df,Scalers)","97fa0cdc":"train_y = pd.read_csv('..\/input\/y_train.csv')","4468ce8e":"num_classes = len(train_y.surface.unique())\nsegments    = train_y.surface.size\nfeatures    = data_train.shape[2]","0141e051":"target = train_y.surface\n_=train_y.surface.value_counts().plot(kind='bar')","f0f6c65c":"_=train_y.groupby('surface').group_id.unique().map(lambda x:len(x)).sort_values().plot(kind='bar')","594feb3a":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntarget = le.fit_transform(train_y['surface'])\n\nGS = GroupShuffleSplit(n_splits=13,random_state=513131,test_size=0.1)\nfolds = [(t,v) for (t,v) in GS.split(np.zeros((segments,)),groups=train_y.group_id)]\n\ngroups_hard_tiles = train_y.group_id[train_y.surface=='hard_tiles'].index.tolist()\n\nfolds_set = []\nfor t,v in folds:\n    folds_set.append((np.array(list(set(t).union(groups_hard_tiles))),np.array(list(set(v).difference(groups_hard_tiles)))))\n    \nfor ii,(t,v) in enumerate(folds_set):\n    if 'hard_tiles' in train_y.surface.iloc[v].unique():\n        print(\"Hard_Tiles present in fold no: {ii+1}\")\nelse:\n    print('Hard_tiles group is excluded from the validation sets')","8379ecf3":"gc.collect()","79862d0c":"def first_inner_generator(out_units,l2,Spatial_dropout,dense_drop,noise):\n    \n    \n    input_main = keras.layers.Input(shape=(128,features))\n\n    cnn        = keras.layers.GaussianNoise(noise)(input_main)\n    \n    cnn        = keras.layers.Conv1D(out_units+(out_units\/\/4)*0,3,kernel_regularizer=keras.regularizers.l2(l2))(cnn)\n    cnn        = keras.layers.Activation('relu')(cnn)\n    cnn        = keras.layers.SpatialDropout1D(Spatial_dropout)(cnn)\n    cnn        = keras.layers.MaxPool1D()(cnn)\n    \n    cnn        = keras.layers.Conv1D(out_units+(out_units\/\/4)*1,3,kernel_regularizer=keras.regularizers.l2(l2))(cnn)\n    cnn        = keras.layers.Activation('relu')(cnn)\n    cnn        = keras.layers.SpatialDropout1D(Spatial_dropout)(cnn)\n    cnn        = keras.layers.MaxPool1D()(cnn)\n    \n    cnn        = keras.layers.Conv1D(out_units+(out_units\/\/4)*2,3,kernel_regularizer=keras.regularizers.l2(l2))(cnn)\n    cnn        = keras.layers.Activation('relu')(cnn)\n    cnn        = keras.layers.SpatialDropout1D(Spatial_dropout)(cnn)\n    \n    cnn        = keras.layers.Conv1D(out_units+(out_units\/\/4)*3,3,kernel_regularizer=keras.regularizers.l2(l2))(cnn)\n    cnn        = keras.layers.Activation('relu')(cnn)\n    cnn        = keras.layers.SpatialDropout1D(Spatial_dropout)(cnn)\n    \n    cnn        = keras.layers.Conv1D(out_units+(out_units\/\/4)*4,3,kernel_regularizer=keras.regularizers.l2(l2))(cnn)\n    cnn        = keras.layers.Activation('relu')(cnn)\n    cnn        = keras.layers.SpatialDropout1D(Spatial_dropout)(cnn)\n    \n    LSTM       = keras.layers.Bidirectional(keras.layers.CuDNNLSTM(out_units,return_sequences=True,kernel_regularizer=keras.regularizers.l2(l2)))(cnn)\n    \n    max_cnn    = keras.layers.GlobalMaxPool1D()(cnn)\n    avg_cnn    = keras.layers.GlobalAvgPool1D()(cnn)\n    \n    max_LSTM   = keras.layers.GlobalMaxPool1D()(LSTM)\n    avg_LSTM   = keras.layers.GlobalAvgPool1D()(LSTM)\n    \n    LSTM_last  = keras.layers.Lambda(lambda x:x[:,-1,:])(LSTM)\n    \n    dense     = keras.layers.Concatenate()([max_LSTM,avg_LSTM,max_cnn,avg_cnn,LSTM_last])\n    \n    dense      = keras.layers.Dense(out_units,activation=keras.activations.relu)(dense)\n    dense      = keras.layers.GaussianDropout(dense_drop)(dense) \n    \n    input_meta = keras.layers.Input(shape=(meta_data_train.shape[1],))\n    \n    meta      = keras.layers.GaussianNoise(noise*2)(input_meta)\n    dense     = keras.layers.Concatenate()([dense,meta])\n        \n    dense      = keras.layers.Dense(out_units,activation=keras.activations.relu,kernel_regularizer=keras.regularizers.l2(l2))(dense)\n    dense      = keras.layers.GaussianDropout(dense_drop)(dense)\n    \n    dense      = keras.layers.Dense(out_units,activation=keras.activations.relu,kernel_regularizer=keras.regularizers.l2(l2))(dense)\n    dense      = keras.layers.GaussianDropout(dense_drop)(dense)\n         \n\n    return keras.Model([input_main,input_meta],dense)","b046cb5b":"def second_inner_generator(in_units,l2,Spatial_dropout,dense_drop):\n    \n    input_main = keras.layers.Input(shape=(in_units,))\n\n    dense        = keras.layers.Dense(in_units,activation = keras.activations.relu,kernel_regularizer=keras.regularizers.l2(l2))(input_main)\n    dense        = keras.layers.GaussianDropout(dense_drop)(dense)\n  \n    out          = keras.layers.Dense(num_classes,kernel_regularizer=keras.regularizers.l2(l2),activation = keras.activations.softmax)(dense)\n    \n    return keras.Model(input_main,out)","27146125":"def model_generator(units,l2,Spatial_dropout,dense_drop,noise):\n    \n    model_inner   = first_inner_generator(units,l2,Spatial_dropout,dense_drop,noise)\n    model_outer   = second_inner_generator(units,l2,Spatial_dropout,dense_drop)\n    \n    \n    input_main_a = keras.layers.Input(shape=(128,features))\n    input_main_b = keras.layers.Input(shape=(128,features))\n    \n    input_meta_a = keras.layers.Input(shape=(meta_data_train.shape[1],))\n    input_meta_b = keras.layers.Input(shape=(meta_data_train.shape[1],))\n\n    model_inner_a  = model_inner([input_main_a,input_meta_a])\n    model_inner_b  = model_inner([input_main_b,input_meta_b])\n    \n    model_outer_a  = model_outer(model_inner_a)\n    model_outer_b  = model_outer(model_inner_b)\n    \n    dense_a       = keras.layers.Lambda(lambda x:x,name='a')(model_outer_a)\n    dense_b       = keras.layers.Lambda(lambda x:x,name='b')(model_outer_b)\n\n    pair_wise_out = keras.layers.Subtract()([model_inner_a,model_inner_b])\n    pair_wise_out = keras.layers.Lambda(lambda x:keras.backend.abs(x))(pair_wise_out)\n    \n    pair_wise_out_group = keras.layers.Dense(units,activation=keras.activations.relu,kernel_regularizer=keras.regularizers.l2(l2))(pair_wise_out)\n    pair_wise_out_group = keras.layers.GaussianDropout(dense_drop)(pair_wise_out_group)\n    \n    pair_wise_out_group = keras.layers.Dense(1,activation=keras.activations.sigmoid,kernel_regularizer=keras.regularizers.l2(l2),name='pair_wise_group')(pair_wise_out_group) \n    \n    pair_wise_out_surf = keras.layers.Dense(units,activation=keras.activations.relu,kernel_regularizer=keras.regularizers.l2(l2))(pair_wise_out)\n    pair_wise_out_surf = keras.layers.GaussianDropout(dense_drop)(pair_wise_out_surf)\n            \n    pair_wise_out_surf  = keras.layers.Dense(1,activation=keras.activations.sigmoid,kernel_regularizer=keras.regularizers.l2(l2),name='pair_wise_surf')(pair_wise_out_surf)\n    \n    model =  keras.Model([input_main_a,input_main_b,input_meta_a,input_meta_b],[dense_a,dense_b,pair_wise_out_group,pair_wise_out_surf]) \n\n    return model,model_inner,model_outer","9c1de8f3":"class generator(keras.utils.Sequence):\n    def __init__(self, data, meta, target, group, batch_size, slicing, mode='Training'):\n            if slicing is None:\n                self.data, self.meta, self.target, self.group, self.batch_size = data, meta, target, group, batch_size\n            else:\n                self.data, self.meta, self.target, self.group, self.batch_size = data[slicing], meta[slicing], target[slicing], group[slicing], batch_size\n            \n            self.num_samples = self.data.shape[0]\n                \n            self.epoch_a_data   = np.zeros(shape=(self.num_samples,self.data.shape[1],self.data.shape[2]))\n            self.epoch_b_data   = np.zeros(shape=(self.num_samples,self.data.shape[1],self.data.shape[2]))\n            \n            self.epoch_a_meta   = np.zeros(shape=(self.num_samples,self.meta.shape[1]))\n            self.epoch_b_meta   = np.zeros(shape=(self.num_samples,self.meta.shape[1]))\n            \n            self.epoch_a_target = np.zeros(shape=(self.num_samples,1))\n            self.epoch_b_target = np.zeros(shape=(self.num_samples,1))\n            \n            self.pair_wise_group   = np.zeros(shape=(self.num_samples,1))\n            self.pair_wise_surface = np.zeros(shape=(self.num_samples,1))\n            \n            self.counter = 0\n                        \n            print(f\"Processing {int(self.data.shape[0])} Samples for {mode}\")\n            \n            self.on_epoch_end()            \n            \n\n    def __len__(self):\n        self.steps = (self.num_samples\/\/self.batch_size) + 1\n        return self.steps\n\n    def __getitem__(self, idx):\n        if idx < self.steps-1:\n            batch_a_data       = self.epoch_a_data[idx * self.batch_size:(idx + 1) * self.batch_size]\n            batch_b_data       = self.epoch_b_data[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n            batch_a_meta       = self.epoch_a_meta[idx * self.batch_size:(idx + 1) * self.batch_size]\n            batch_b_meta       = self.epoch_b_meta[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n            batch_a_target     = self.epoch_a_target[idx * self.batch_size:(idx + 1) * self.batch_size]\n            batch_b_target     = self.epoch_b_target[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n            batch_pair_groups  = self.pair_wise_group[idx * self.batch_size:(idx + 1) * self.batch_size]\n            batch_pair_surface = self.pair_wise_surface[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n\n            return [batch_a_data,batch_b_data,batch_a_meta,batch_b_meta],[batch_a_target,batch_b_target,batch_pair_groups,batch_pair_surface]\n        else:\n            batch_a_data       = self.epoch_a_data[-self.batch_size:]\n            batch_b_data       = self.epoch_b_data[-self.batch_size:]\n\n            batch_a_meta       = self.epoch_a_meta[-self.batch_size:]\n            batch_b_meta       = self.epoch_b_meta[-self.batch_size:]\n\n            batch_a_target     = self.epoch_a_target[-self.batch_size:]\n            batch_b_target     = self.epoch_b_target[-self.batch_size:]\n\n            batch_pair_groups  = self.pair_wise_group[-self.batch_size:]\n            batch_pair_surface = self.pair_wise_surface[-self.batch_size:]\n\n\n            return [batch_a_data,batch_b_data,batch_a_meta,batch_b_meta],[batch_a_target,batch_b_target,batch_pair_groups,batch_pair_surface]\n\n    def on_epoch_end(self):\n        np.random.seed(513131 + self.counter)\n        self.pairs_a = np.random.choice(self.num_samples,size=(self.num_samples,),replace=False)\n        self.pairs_b = np.random.choice(self.num_samples,size=(self.num_samples,),replace=True)\n        self.counter+=1\n        for ii in range(self.num_samples):\n            self.epoch_a_data[ii]   = self.data[self.pairs_a[ii]]\n            self.epoch_b_data[ii]   = self.data[self.pairs_b[ii]]\n\n            self.epoch_a_meta[ii]   = self.meta[self.pairs_a[ii]]\n            self.epoch_b_meta[ii]   = self.meta[self.pairs_b[ii]]\n\n            self.epoch_a_target[ii] = self.target[self.pairs_a[ii]]\n            self.epoch_b_target[ii] = self.target[self.pairs_b[ii]]\n\n            self.pair_wise_group[ii]   = self.group[self.pairs_a[ii]]!=self.group[self.pairs_b[ii]]\n            self.pair_wise_surface[ii] = self.target[self.pairs_a[ii]]!=self.target[self.pairs_b[ii]]\n            ","90a4c655":"validation_scores= []\ntraining_scores = []\ntest_scores = np.zeros(shape=(data_test.shape[0],len(folds_set),num_classes))\n\nhistories = []\nfor ii,(t,v) in enumerate(folds_set):\n    keras.backend.clear_session()\n    model,model_inner,model_outer = model_generator(units=32,l2=0.002,Spatial_dropout=0.1,dense_drop=0.1,noise=0.1)\n    gc.collect()\n    if ii==0:\n        for m in [model_inner,model_outer,model,]:\n            m.summary()\n            \n    \n    print(f\"\\nModel {ii+1}\/{len(folds_set)}:\")\n    model.compile(optimizer=keras.optimizers.Adadelta(),loss={'a':keras.losses.sparse_categorical_crossentropy,'b':keras.losses.sparse_categorical_crossentropy,\n                                                         'pair_wise_group':keras.losses.binary_crossentropy,'pair_wise_surf':keras.losses.binary_crossentropy},\n              metrics={'a':keras.metrics.sparse_categorical_accuracy,'b':keras.metrics.sparse_categorical_accuracy,\n                      'pair_wise_group':keras.metrics.binary_accuracy,'pair_wise_surf':keras.metrics.binary_accuracy},\n             loss_weights=[1,1,2,2])\n    \n    counts = pd.Series(target[t]).value_counts()\n    weights = {ii:counts.max()\/val for ii,val in zip(counts.index,counts)}\n    weights = {ii:weights.get(ii,1) for ii in range(num_classes)}\n    \n    print('Class Weights : ',[(ii,np.round(weights[ii],decimals=2)) for ii in sorted(weights.keys())],'\\n\\n')\n    \n    hist = model.fit_generator(generator=generator(data=data_train,meta=meta_data_train,target=target,group=train_y.group_id.values,batch_size=32,slicing=t),\n                          validation_data=generator(data=data_train,meta=meta_data_train,target=target,group=train_y.group_id.values,batch_size=32,slicing=v,mode='Validation'),\n                          epochs=300,verbose=2,class_weight={'a':{ii:weights[ii] for ii in sorted(weights)},'b':{ii:weights[ii] for ii in sorted(weights)},\n                         'pair_wise_group':{1:1,0:train_y.group_id[t].unique().size},'pair_wise_surf':{1:1,0:train_y.surface[t].unique().size}})\n\n    histories.append(hist)\n    \n    preds_train    = model_inner.predict(x=[data_train[v],meta_data_train[v]])\n    preds_train    = model_outer.predict(x=preds_train)\n    validation_scores.append(accuracy_score(target[v],preds_train.argmax(axis=1)))\n    print('Validation Score :', np.round(validation_scores[-1],decimals=3))\n    \n    preds_train    = model_inner.predict(x=[data_train[t],meta_data_train[t]])\n    preds_train    = model_outer.predict(x=preds_train)\n    training_scores.append(accuracy_score(target[t],preds_train.argmax(axis=1)))\n    print('Training Score :', np.round(training_scores[-1],decimals=3))\n    \n    \n    preds_test           = model_inner.predict(x=[data_test,meta_data_test])\n    preds_test           = model_outer.predict(x=preds_test)\n    test_scores[:,ii,:]  = preds_test","f65ff6ae":"history_keys= ['loss', 'a_loss', 'pair_wise_group_loss', 'pair_wise_surf_loss', 'a_sparse_categorical_accuracy' \\\n               ,'pair_wise_group_binary_accuracy', 'pair_wise_surf_binary_accuracy']","3772962b":"fig,ax=plt.subplots(len(history_keys),1,figsize=(20,4*len(history_keys)))\nfor ii in range(len(history_keys)):\n    loss = np.zeros(shape=(hist.epoch[-1]+1))\n    val_loss = np.zeros(shape=(hist.epoch[-1]+1))\n    for hist in histories:\n        ax[ii].plot(hist.epoch,hist.history[history_keys[ii]],'#FFC300',alpha=0.6,linewidth=1)\n        ax[ii].plot(hist.epoch,hist.history[\"val_\"+history_keys[ii]],'#7882FF',alpha=0.6,linewidth=1)\n        loss += np.array(hist.history[history_keys[ii]])\/len(histories)\n        val_loss += np.array(hist.history[\"val_\"+history_keys[ii]])\/len(histories)\n    ax[ii].plot(hist.epoch,loss,'#FF5733',alpha=0.9,linewidth=3)\n    ax[ii].plot(hist.epoch,val_loss,'#3341FF',alpha=0.9,linewidth=3)\n    ax[ii].grid(b=True,which='both')\n    ax[ii].set_title(history_keys[ii])\n    \n\nplt.tight_layout()\nplt.show()\nplt.close()","6c75b105":"for ii,(val,train) in enumerate(zip(validation_scores,training_scores),start=1):\n    print(f'Model {ii} Validation : {np.round(val,decimals=3)}  Training : {np.round(train,decimals=3)}')\n    \nprint(f\"\\n\\nMean Validation Score : {np.round(np.mean(validation_scores),decimals=3)}\\nMean Training Score : {np.round(np.mean(training_scores),decimals=3)}\")","f835e511":"submission = pd.read_csv('..\/input\/sample_submission.csv')\nsubmission.surface = le.inverse_transform(np.array(test_scores.sum(axis=1).argmax(axis=1),dtype=np.int8))\nsubmission.to_csv('submission.csv',index=False)\nsubmission.surface.value_counts().plot(kind='bar')\npd.DataFrame(submission.surface.value_counts())","96136b7c":"Processing the surface labels to be understood by the model. \n\nThen creating training and validation sets using GroupShuffleSplit. Also ensuring that all training sets contain the hard-tiles group since there is only one group for this surface as shown from above histogram.","70705679":"# Using Group Id's the Right Way!\n\n\n**TL:DR** :: Creating a model that reduces the inter-group dependency and validation error by using pair-wise comparisons. \n\nHi All,\nAlthough a little late to the party; I wanted to try out the competition but wasn't able to accept the competition rules in time. I decided to give it a try anyway. Read the discussions and found out about the data linkage hack and decided to find a way to use Group Id's in a way that the final model would only depend on the 128 time series values from the given training data.\n\n### Model Layout:\n\nSo the basic idea for the project is to create a model that can reduces the modelling of group-specific patterns from the data and generalize well by focusing on surface-specific patternes in the data. The focus is on reducing inter-group validation error.\nTo do so, I have created a model that has the following structure:\n\n**Input**:\nTotal inputs = 4 (2 for each samples)\n*  Time series data for 2 samples, size = 128 (times steps) x 12 (features) each\n*  Meta data for 2 samples, size = 8 x 12 (features) each\n\n**Output**:\nTotal outputs = 4\n*  2 Surface prediction, one for each sample.\n*  Prediction wheter both samples have same Group Id.\n*  Prediction wheter samples are take from same surface.\n\n### Model Structure:\n**first_inner model**:\nThis consists of raw time series input being fed into multiple CNN layers followed by a Bi-LSTM. Then it takes the global avg\/max pooling for last CNN and Bi-LSTM and connects it to a FC layer.\nMeta_Data is then concatenated to this FC layer which is again followed by a FC layer.\n\n**second_inner model**:\nThis only consists of FC layers and the final output layer.\n\n**main_model**:\nThis consists of 2 pairs of first_inner and second_inner models, followed by a few lambda layers that basically compare the output of the both the first_inner models. And predicts if the both the samples are from same group and if both the samples are of the same surface.\n\n### Model for making predictions:\n**Predictions**:\nFor final predictions, I didn't feel the need to create a separate model so I just feedfoward the data through first_inner and second_inner model sequentially.\n\n\n## Feature Engineering:\nSince the main intent was to just reduce the inter_group dependencies, I only scratched the surface of the data during FE. Computed basic statistical values from features for the Meta_data. \nSince the orientation data didnt","24bed453":"Converting Quaternion to Euler and Tait Angles","d2d4912a":"Checking out what the data represents:","d7f3f110":"From the histogram we can see that the classes are not blanced, hence we need to incorporate this imbalance in out model.","ae47aba4":"# Wrap-up:\nSince I haven't accepted the rules, I can't do the submission to check against the test data. But I believe the results should be above 0.7.\n(Would be great if someone can check that up for me)\n\nFeel Free to subsitute your own high results model (up the 2nd last layer) in the first_inner_model generator and the last layer in second_inner_model. Let me know how much does the score improve by focusing on the reducing inter_group dependency.\n\n*Happy Kaggling,*\nAR","7ccf9191":"Main Model Generator Function:","4f2b76f9":"# Model Creation Starts Here","b0ac54de":"Reading the Data in:","d23acc4f":"Need to create a genarator for Main_model input, utilizing Keras Sequence Class for the purpose.\n\nEach Epoch contains the 2 x No. of samples in training data.","b5e62001":"Fucntion to de-noise the data using FFT","8a24e64a":"First_inner and second_inner model generator functions:","6acf6bd2":"Function to process the Training and Test data:"}}