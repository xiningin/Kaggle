{"cell_type":{"92e97950":"code","656b0911":"code","50401bd0":"code","3212c077":"code","438b9df2":"code","6e421cdb":"code","a1176498":"code","5688140e":"code","1c2b787e":"code","23a8f5a5":"code","a584ad64":"code","d4413e6a":"code","733f021d":"code","59f864b6":"code","3a1e81e4":"code","bde860e9":"code","bbb3a02d":"code","7875d705":"code","acf5c7aa":"code","40375bbe":"code","07c0a902":"code","2c3994d6":"markdown","919482ea":"markdown","37eabe1f":"markdown","6b513adc":"markdown","4c072241":"markdown","a3e27119":"markdown","aa6e852c":"markdown","d073c0cb":"markdown","05e1d69e":"markdown","5b0536b2":"markdown","a70bbd92":"markdown","7b0fe122":"markdown","a8038fa6":"markdown","eb24521f":"markdown","0aec4041":"markdown","2461f1ff":"markdown","0f0ac6b2":"markdown","7e40baab":"markdown","b4fcdce8":"markdown","1c4d6b88":"markdown","02ea7ea6":"markdown","0fa7bb65":"markdown","3fec7fbd":"markdown","f7652db5":"markdown"},"source":{"92e97950":"import os\nimport pickle\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.metrics import classification_report\nfrom collections import Counter\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nprint(tf.__version__)","656b0911":"def load_dataset():\n  df = pd.read_html(\"https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html\")\n  cifar10_classes = df[0][0].values.tolist()\n  num_classes = len(cifar10_classes)\n\n  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n\n  y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n  y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n\n  x_train = x_train.astype('float32')\n  x_test = x_test.astype('float32')\n  x_train = x_train \/ 255.0\n  x_test = x_test \/ 255.0\n\n  return x_train, y_train, x_test, y_test, np.array(cifar10_classes)","50401bd0":"def normalize_images(train, test):\n  mean = np.mean(train, axis=(0,1,2,3))\n  std = np.std(train, axis=(0,1,2,3))\n  train_norm = (train - mean)\/(std + 1e-7)\n  test_norm = (test - mean)\/(std + 1e-7)\n  \n  return train_norm, test_norm","3212c077":"def define_model():\n    weight_decay = 1e-4\n    L2 = tf.keras.regularizers.l2(weight_decay)\n\n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\", kernel_regularizer=L2, input_shape=x_train.shape[1:]),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\", kernel_regularizer=L2),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'), \n        tf.keras.layers.Dropout(0.2), \n\n        tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\", kernel_regularizer=L2),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\", kernel_regularizer=L2),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'),\n        tf.keras.layers.Dropout(0.3), \n\n        tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\", kernel_regularizer=L2),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\", kernel_regularizer=L2),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'),\n        tf.keras.layers.Dropout(0.4), \n\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(units=128, activation='relu'), \n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(units=128, activation='relu'), \n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(units=128, activation='relu'), \n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.4),\n        tf.keras.layers.Dense(units=128, activation='relu'), \n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(0.5),\n        tf.keras.layers.Dense(units=10, activation='softmax')\n    ])\n\n    opt = tf.keras.optimizers.RMSprop(lr=0.001, decay=1e-6)\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n\n    return model","438b9df2":"def summarize_diagnostics(history):\n    plt.subplot(211)\n    plt.title('Cross Entropy Loss')\n    plt.plot(history.history['loss'], color='blue', label='train')\n    plt.plot(history.history['val_loss'], color='orange', label='test')\n\n    plt.subplot(212)\n    plt.title('Classification Accuracy')\n    plt.plot(history.history['accuracy'], color='blue', label='train')\n    plt.plot(history.history['val_accuracy'], color='orange', label='test')","6e421cdb":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","a1176498":"x_train_df, y_train, x_test_df, y_test, classes_names = load_dataset()\nx_train_df.shape, y_train.shape, x_test_df.shape, y_test.shape","5688140e":"sample_training_images, _ = next(tf.keras.preprocessing.image.ImageDataGenerator().flow(x_train_df, y_train, batch_size=64))\nplotImages(sample_training_images[:5])","1c2b787e":"x_train, x_test = normalize_images(x_train_df, x_test_df)","23a8f5a5":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    rotation_range=15\n)\n\nbatch_size = 64\n\ntrain_generator = train_datagen.flow(x_train, y_train, batch_size=batch_size)","a584ad64":"reduce_learning_rate = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.5, patience=5, verbose=1, \n    mode='auto', min_delta=1e-10, cooldown=0, min_lr=0\n)\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', min_delta=0, patience=12, verbose=1, mode='auto',\n    baseline=None, restore_best_weights=False\n)","d4413e6a":"csv_logger = tf.keras.callbacks.CSVLogger(\n    'cifar10.epoch.results.csv', separator='|', append=False)\n\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    \"cifar10.partial.hdf5\", save_weights_only=True, mode='auto', \n    save_freq='epoch', verbose=0\n)","733f021d":"model = define_model()\nmodel.summary()","59f864b6":"epochs = 1000\n\nhistory = model.fit(\n    train_generator, \n    steps_per_epoch=x_train.shape[0]\/\/batch_size, \n    epochs=epochs,  \n    validation_data=(x_test, y_test), \n    callbacks=[csv_logger, reduce_learning_rate, early_stopping, model_checkpoint],\n    verbose=1\n)","3a1e81e4":"_, acc = model.evaluate(x_test, y_test, verbose=0)\nprint('> %.3f' % (acc * 100.0))","bde860e9":"model.save('cifar10.h5', overwrite=True, include_optimizer=True, save_format='h5')","bbb3a02d":"summarize_diagnostics(history)","7875d705":"res = pd.read_csv('cifar10.epoch.results.csv', sep='|')\nres.tail()","acf5c7aa":"model_load_tf = tf.keras.models.load_model('cifar10.h5')\nmodel_load_tf.summary()","40375bbe":"test_loss, test_acc = model_load_tf.evaluate(x_test, y_test)\nprint(f\"Accuracy: {test_acc} Loss: {test_loss}\")","07c0a902":"Y_test = np.argmax(y_test, axis=1)\ny_pred = model.predict_classes(x_test)\nprint(classification_report(Y_test, y_pred))","2c3994d6":"Time to define the model and print summary to check if everything is correctly set before training.","919482ea":"# Dataset layout\n\nThe archive contains the files data_batch_1, data_batch_2, ..., data_batch_5, as well as test_batch. Each of these files is a Python \"pickled\" object produced with [cPickle](http:\/\/www.python.org\/doc\/2.5\/lib\/module-cPickle.html).\n\nLoaded in this way, each of the batch files contains a dictionary with the following elements:\n* data -- a 10000x3072 [numpy](http:\/\/numpy.scipy.org\/) array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n* labels -- a list of 10000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data.\n\nThe dataset contains another file, called batches.meta. It too contains a Python dictionary object. It has the following entries:\n* label_names -- a 10-element list which gives meaningful names to the numeric labels in the labels array described above. For example, label_names[0] == \"airplane\", label_names[1] == \"automobile\", etc.\n","37eabe1f":"Since we're going to classify these images, some normalization is necessary to keep data within a range.","6b513adc":"Function to plot loss x val_loss and accuracy vs val_accuracy so we can see how the learning curve progressed.","4c072241":"I like to save the model just to keep track of changes.","a3e27119":"These callback functions are responsible for logging accuracy and loss results for each epoch and for checkpoint the model's weights, in case we have to stop and resume training later.","aa6e852c":"# Baseline results\n\nYou can find some baseline replicable results [on this dataset on the project page for cuda-convnet](http:\/\/code.google.com\/p\/cuda-convnet\/). These results were obtained with a convolutional neural network. Briefly, they are 18% test error without data augmentation and 11% with. Additionally, [Jasper Snoek](http:\/\/www.cs.toronto.edu\/~jasper\/) has a [paper](http:\/\/hips.seas.harvard.edu\/content\/practical-bayesian-optimization-machine-learning-algorithms) in which he used Bayesian hyperparameter optimization to find nice settings of the weight decay and other hyperparameters, which allowed him to obtain a test error rate of 15% (without data augmentation) using the architecture of the net that got 18%.\n\n[Rodrigo Benenson](http:\/\/rodrigob.github.com\/) has been kind enough to collect results on CIFAR-10\/100 and other datasets on his website; [click here](http:\/\/rodrigob.github.com\/are_we_there_yet\/build\/classification_datasets_results.html) to view.","d073c0cb":"I've instantiated a ImageDataGenerator to augment data. Nothing fancy, just a little bit of shift, flipping and rotation. We will train the model in batches of 64 samples.","05e1d69e":"Let's print the learning evolution.","5b0536b2":"The callback functions will take care that the model doesn't train for a long time, so we will pick a large number to use as total training epochs. If I'm not mistaken, this model will stop before reaching 90 epochs.","a70bbd92":"Now it is time to load the datasets from the disk.","7b0fe122":"We will load this dataset using Tensorflow. The classes will be loaded directly from [Alex Krizhevsky](https:\/\/www.cs.toronto.edu\/~kriz\/cifar.html) homepage. ","a8038fa6":"And check if the logging of accuracy and loss is okay.","eb24521f":"Let's evaluate the results.","0aec4041":"As you can see, with this simple model and little processing time we are not far from the best performers.","2461f1ff":"Data normalization will restrain data to a certain range.","0f0ac6b2":"This function is the exact same one found on tensorflow 2.1 website. It is used to plot some random images from the dataset so we can understand what we are dealing with.","7e40baab":"Let's check some images to verify if everything is okay so far.","b4fcdce8":"# The CIFAR-10 dataset\n\nThe CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n\nThe dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n\nThe classes in the dataset are **airplane, automobile, bird, cat, deer, dog, frog, horse, ship and truck**.\n\nThe classes are completely mutually exclusive. There is no overlap between automobiles and trucks. **Automobile** includes sedans, SUVs, things of that sort. **Truck** includes only big trucks. Neither includes pickup trucks.","1c4d6b88":"The model consists of 6 convolutional layers. I've noticed that this problem responds really well to convolutional filters. After each filter I'm applying a normalization to keep data within a range. I've tried different amount of dense layers, four responded well in an acceptible processing time.","02ea7ea6":"Doubts, suggestions, rants, please, comment down below. Best regards to all.","0fa7bb65":"Let's check if the saved model is okay.","3fec7fbd":"Let's check how the model learn about the classes.","f7652db5":"These callback functions are what let us achieve more than 90% of accuracy. The learning rate is reduced by a factor of 50% every 5 epochs if the model doesn't improve. If 12 epochs go by and no improvement is seen, the model stops. As such, we don't have to worry with the amount of epochs in total as we will see later."}}