{"cell_type":{"b5a7995c":"code","087c10cb":"code","2a5b8f73":"code","b269e4c7":"code","1eaa69d9":"code","1f380d95":"code","3d5cd51e":"code","fa1b6bd8":"code","88cec177":"code","6e59f5af":"code","713ab46e":"code","d5bb7343":"code","6ecdf174":"code","038bef17":"code","93157bc6":"code","9918a31c":"code","8f2f2670":"code","2c4cb57d":"code","bc607322":"code","316d9afc":"code","dcf57db5":"markdown","db95e9eb":"markdown","dd123c84":"markdown","48d286c5":"markdown","567194f8":"markdown","85909ae8":"markdown","35c0a5f2":"markdown"},"source":{"b5a7995c":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","087c10cb":"import numpy as np\nimport pandas as pd\nimport warnings\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import auc\nimport sklearn.metrics as metrics\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier as CB","2a5b8f73":"# importing datasets\ntrain = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-sep-2021\/test.csv') \nsub = pd.read_csv(\"..\/input\/tabular-playground-series-sep-2021\/sample_solution.csv\") ","b269e4c7":"train.head()","1eaa69d9":"test.head()","1f380d95":"print(train.isnull())\nprint(train.shape)","3d5cd51e":"seperator = train.shape[0]","fa1b6bd8":"train.drop(\"id\", axis=1, inplace=True)\ntest_id = test['id']\ntest.drop(\"id\", axis=1, inplace=True)","88cec177":"y = train['claim']\ntrain.drop(\"claim\", axis=1, inplace=True)","6e59f5af":"# Concatenating the datasets for pre-processing\ndf = pd.concat([train, test], axis=0)\nprint(train.shape, y.shape, seperator)","713ab46e":"median = SimpleImputer(missing_values=np.nan, strategy='median')\ndf = median.fit_transform(df)\ndf = pd.DataFrame(df) ","d5bb7343":"# Splitting the df back into train and test\ntrain = df.iloc[ :seperator, : ]\ntest = df.iloc[seperator: , : ]\nprint(train.shape, test.shape)","6ecdf174":"ss = StandardScaler()\ntrain = ss.fit_transform(train)\ntest = ss.transform(test)","038bef17":"X_train,X_test,y_train,y_test = train_test_split(train, y, test_size =0.3,random_state=11)","93157bc6":"X_train.shape","9918a31c":"# Logistic Regression\n# lr = LogisticRegression(C = 0.001)\n# lr.fit(X_train, y_train)\n# y_pred = lr.predict_proba(test)\n# new = y_pred[ : , 1]","8f2f2670":"# Gradient Boosting Classifier\n# rfc = RandomForestClassifier(n_estimators = 10, verbose = 1)\n# rfc.fit(X_train, y_train)\n# y_pred = rfc.predict_proba(test)\n# new = y_pred[ : , 1]","2c4cb57d":"cb_model = CB(learning_rate = 0.1, iterations=1000) \ncb_model.fit(X_train, y_train)","bc607322":"y_pred = cb_model.predict_proba(test)\nnew = y_pred[ : , 1] ","316d9afc":"output = pd.DataFrame({'id': test_id, 'claim': new}) \noutput.to_csv('submission_catboost.csv', index=False) ","dcf57db5":"# Data Preprocessing","db95e9eb":"# Tabluar Playground Series September'21","dd123c84":"# Training the Model","48d286c5":"# Importing the Dataset","567194f8":"# Submitting the predictions","85909ae8":"# Importing the Libraries","35c0a5f2":"* This is the notebook for the **Tablular Playground Series September'21**\n* In this notebook, I used the **StandardScaler** to standardize the dataset.\n* I also used **Median Imputation** for filling the NULL values.\n* I also used various models to train the data. The models are **Logistic Regression**, **Gradient Boosting Classifier** and **CatBoost Classifier**.\n* Among these models, **CatBoost Classifier** gave the best results.\n\nIf you like the notebook, please upvote  :)\n\nI am open to suggestions to improve the score."}}