{"cell_type":{"1da62ec8":"code","d172a137":"code","2475fd4e":"code","af46e128":"code","70498219":"code","1c2d5db0":"code","91312cef":"code","cb524fdd":"code","a6102f3c":"code","344bfbcd":"code","64d48621":"code","dba8cd2b":"code","fef8fa9d":"code","50654f5b":"code","eef16f79":"code","987807dd":"code","88febeb5":"code","116e2228":"code","dd8aa566":"markdown","70409502":"markdown","503e056d":"markdown"},"source":{"1da62ec8":"import sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nimport timm","d172a137":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torch.autograd import Variable\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torchvision\nfrom tqdm import tqdm\nimport cv2\nfrom skimage import io\nimport time\n\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n)\n\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nimport tqdm.notebook as tq\nfrom sklearn.model_selection import train_test_split\nfrom scipy.special import softmax","2475fd4e":"\nCFG = {\n    \n    'model_arch': 'tf_efficientnet_b3_ns',\n    'img_size': 512,\n    'valid_bs': 16,\n    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n}","af46e128":"df = pd.read_csv('\/kaggle\/input\/cassava-leaf-disease-classification\/sample_submission.csv')\ndf_torch = df.copy()\ndf_tf = df.copy()\n ","70498219":"PATH = '\/kaggle\/input\/cassava-leaf-disease-classification\/test_images\/'","1c2d5db0":"class CassavaImageClassifier(nn.Module):\n    def __init__ (self, model_arch, n_class, pretrained=False):\n        super().__init__ ()\n        self.model = timm.create_model(model_arch, pretrained=pretrained)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, n_class)\n\n    def forward (self, x):\n        x = self.model(x)\n        return x","91312cef":"class DiseaseDatasetInference(torch.utils.data.Dataset):\n\n    def __init__ (self, df, transform=None, opt_label=True):\n        self.df = df.reset_index(drop=True).copy()\n        self.transform = transform\n        self.opt_label = opt_label\n\n        if self.opt_label:\n            self.data = [(row['image_id'], row['label']) for _, row in self.df.iterrows()]\n\n        else:\n            self.data = [(row['image_id']) for _, row in self.df.iterrows()]\n\n        self.data = np.asarray(self.data)\n  \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__ (self, index):\n            # np.random.shuffle(self.data)\n        if self.opt_label:\n            image_path, label = self.data[index]    \n        else:\n            image_path = self.data[index]\n\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n\n        if self.opt_label == True:\n            return (image, int(label))\n\n        else:\n            return image","cb524fdd":"def get_inference_transforms():\n    return Compose([\n            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n            Resize(CFG['img_size'], CFG['img_size']),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.)","a6102f3c":"trained_model = torch.load('\/kaggle\/input\/cassava-effecientnet-b3\/model_6.pt', map_location=torch.device(CFG['device']))","344bfbcd":"test_csv = df.copy()\ntest_csv['image_id'] = PATH + test_csv['image_id']\n\ntest_ds = DiseaseDatasetInference(test_csv, transform=get_inference_transforms(), opt_label=False)\n\ntest_loader = torch.utils.data.DataLoader(test_ds, batch_size=CFG['valid_bs'], shuffle=False, pin_memory=False) ","64d48621":"trained_model.eval()\n\npreds_torch = []\nwith torch.no_grad():\n    test_tqdm = valid_bar = tq.tqdm(test_loader, total=len(test_loader), desc=\"Testing\", position=0, leave=True)\n    for images in test_tqdm:\n        images = images.to(CFG['device'])\n    \n        preds_torch.extend(trained_model(images).detach().cpu().numpy()) ","dba8cd2b":"torch_outcomes = pd.concat([df_torch['image_id'], pd.DataFrame(preds_torch)], axis=1).sort_values(['image_id'])","fef8fa9d":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport os\nfrom PIL import Image","50654f5b":"model = tf.keras.models.load_model('\/kaggle\/input\/plantdiseaseresnet50\/resnet50.h5')","eef16f79":"preds_tf = []\n\ntest_images = df_tf['image_id']\ntest_tqdm = valid_bar = tq.tqdm(test_images, total=len(test_images), desc=\"Testing\", position=0, leave=True)\nfor image_path in test_tqdm:\n    image = Image.open(PATH + image_path)\n    image = image.resize((CFG['img_size'], CFG['img_size']))\n    image = np.expand_dims(image, axis = 0)\n    preds_tf.append(model.predict(image)[0])","987807dd":"tf_outcomes = pd.concat([pd.DataFrame(test_images, columns=['image_id']), pd.DataFrame(preds_tf)], axis=1).sort_values(['image_id'])","88febeb5":"final_preds = (torch_outcomes.drop('image_id', axis=1)*0.7 + tf_outcomes.drop('image_id', axis=1)*0.3).to_numpy().argmax(1)","116e2228":"submit = pd.DataFrame({'image_id': torch_outcomes['image_id'].values, 'label': final_preds})\nsubmit.to_csv('submission.csv', index=False)","dd8aa566":"> # **EFNet(PyTorch)**","70409502":"# **TF2(TF)**","503e056d":"# **Combine**"}}