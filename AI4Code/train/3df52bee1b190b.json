{"cell_type":{"4a0a0231":"code","f8b0462f":"code","f2d3fa02":"code","8530a551":"code","848f3278":"code","d9eb465c":"code","1e545f0f":"code","2631879f":"code","fecd7249":"code","ad7c81a6":"code","9f351723":"code","af0d0b31":"code","61a575d5":"code","1758d46b":"code","2e6d702a":"code","1038d5b7":"code","a1bb8f74":"code","c25c2243":"code","6646e7d8":"code","7dbaca57":"code","32fb1006":"code","10725806":"code","078a863a":"code","1e05ddef":"code","8fa3893a":"code","b28a3d2b":"code","a84803e3":"code","57f6195a":"code","afae7827":"code","fc1990dd":"code","f54a9a36":"code","6e5720a1":"code","e3d99517":"code","50c75dfa":"code","e48e4533":"code","e81a08f8":"code","d35b7ff8":"code","a4113e09":"code","be9b0a0c":"code","c34af58c":"code","5901f6d7":"code","5befce13":"markdown","87ea36a2":"markdown","d3ee756a":"markdown","15b56c6e":"markdown","c4460b99":"markdown","3fbe57b2":"markdown"},"source":{"4a0a0231":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n\nimport tensorflow as tf\n\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f8b0462f":"df = pd.read_csv('\/kaggle\/input\/fake-news\/train.csv')","f2d3fa02":"test_df = pd.read_csv('\/kaggle\/input\/fake-news\/test.csv')","8530a551":"submission = pd.read_csv('\/kaggle\/input\/fake-news\/submit.csv')","848f3278":"\n\nmain_df = pd.concat([df.drop(['label'],axis=1),test_df],axis=0)","d9eb465c":"main_df.shape","1e545f0f":"main_df.title.head(5)","2631879f":"main_df.text.head(5)","fecd7249":"main_df.title=main_df.title.fillna(main_df['text'])","ad7c81a6":"\n\n\n\n\n\nmain_df.isnull().sum()","9f351723":"main_df.text=main_df.text.fillna(main_df.title)","af0d0b31":"main_df.isnull().sum()","61a575d5":"main_df[main_df.author.isnull()]","1758d46b":"main_df.author = main_df.author.fillna('unknown')","2e6d702a":"main_df.isnull().sum()","1038d5b7":"# We will be only using title and author name for prediction\n# Creating new coolumn total concatenating title and author\nmain_df['total'] = main_df['title']+' '+main_df['author']\n#test['total']=test['title']+' '+test['author']","a1bb8f74":"X= main_df\ny = df['label']","c25c2243":"from tensorflow.keras.layers import Embedding ,LSTM , Dense,Dropout\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.models import Sequential","6646e7d8":"voc_size= 5000\nmessages = X.copy()\nmessages.reset_index(inplace=True)","7dbaca57":"import nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\n","32fb1006":"nltk.download('stopwords')","10725806":"#Applying stemming and some preprocessing\nps = PorterStemmer()\ncorpus = []\nfor i in range(0,len(messages)):\n   \n    review = re.sub('[^a-zA-Z]',' ',messages['total'][i])\n    review =review.lower()\n    review = review.split()\n    review = [ps.stem(word)for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)","078a863a":"corpus[0]","1e05ddef":"one_represent = [one_hot(words,voc_size) for words in corpus]","8fa3893a":"one_represent[0]","b28a3d2b":"sent_length = 20\nembedded_docs = pad_sequences(one_represent,padding='pre',maxlen=sent_length)\nprint(embedded_docs[0])","a84803e3":"#We have used embedding layers with LSTM\nmodel = Sequential()\nmodel.add(Embedding(voc_size,40,input_length=25))\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(100))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint(model.summary())","57f6195a":"print(model.summary())","afae7827":"len(embedded_docs),y.shape\n","fc1990dd":"X_final=np.array(embedded_docs)\nX_train_final  = X_final[:20800]\n\nX_test_final   = X_final[20800:]\ny_final = np.array(y)\nX_test_final.shape","f54a9a36":"from sklearn.model_selection import train_test_split","6e5720a1":"X_train,X_test,y_train,y_test =train_test_split(X_train_final ,y_final ,test_size=0.33,random_state=42)\n","e3d99517":"model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=20,batch_size=64)","50c75dfa":"y_pred = model.predict_classes(X_test_final)\n","e48e4533":"\ny_pred.shape,test_df.id.shape","e81a08f8":"submission.head()","d35b7ff8":"y_pred=y_pred.reshape(5200)\ntype(y_pred)\n","a4113e09":"submission = pd.DataFrame({'id':test_df.id,'label':y_pred})","be9b0a0c":"submission.head()","c34af58c":"submission.shape","5901f6d7":"submission.to_csv('LSMT_model_work.csv',index=False)","5befce13":"## Missing Data","87ea36a2":"## predictions...","d3ee756a":"## Datasets Loading.....","15b56c6e":"embedding_vector_features = 40\nmodel = Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel.add(LSTM(100))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","c4460b99":"## Pre_processing...","3fbe57b2":"## Model creating..."}}