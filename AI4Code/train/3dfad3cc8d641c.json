{"cell_type":{"c207df74":"code","4d9131b0":"code","ea780b2d":"code","a5ccd40a":"code","3b549eae":"code","1caf6375":"code","6264ba17":"code","57a0b7bb":"code","7f61aead":"code","0537963d":"code","5dd4ee10":"code","eab71ac6":"code","aa9d833e":"code","a16334c9":"code","f8dc6e5d":"code","bc86e60f":"code","c36fd230":"code","6334aa31":"code","aade2e91":"code","874dd0c8":"code","0a1b5f27":"code","06aab674":"code","4c1e0a1c":"markdown","f3d842b1":"markdown","7a26b66e":"markdown","b78da551":"markdown","91d441c9":"markdown","59b00969":"markdown","f35522cf":"markdown","5dafe921":"markdown","b98f6971":"markdown","2103f476":"markdown","db25f0e1":"markdown","f3b391bd":"markdown"},"source":{"c207df74":"import numpy as np\nimport cv2\nimport os\nimport time\nfrom glob import glob\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.optimizers import Adam,RMSprop,SGD\nfrom keras.applications import VGG19\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense\nfrom keras.models import Sequential\n\nfrom sklearn.metrics import confusion_matrix\n","4d9131b0":"daisy_flower_paths = glob(\"..\/input\/flowers-recognition\/flowers\/daisy\"+\"\/*\")\ndandelion_flower_paths = glob(\"..\/input\/flowers-recognition\/flowers\/dandelion\"+\"\/*\")\nrose_flower_paths = glob(\"..\/input\/flowers-recognition\/flowers\/rose\"+\"\/*\")\nsunflower_flower_paths = glob(\"..\/input\/flowers-recognition\/flowers\/sunflower\"+\"\/*\")\ntulip_paths = glob(\"..\/input\/flowers-recognition\/flowers\/tulip\"+\"\/*\") \n","ea780b2d":"images = []\nlabels = []\n\nfor im_path in daisy_flower_paths:\n    try:\n        img = cv2.imread(im_path)\n        img = cv2.resize(img,(224,224)) # VGG19's default input shape is 224x224\n        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        images.append(img)\n        labels.append(0)\n    except:\n        print(im_path)\n\nfor im_path in dandelion_flower_paths:\n    try:\n        img = cv2.imread(im_path)\n        img = cv2.resize(img,(224,224)) # VGG19's default input shape is 224x224\n        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        images.append(img)\n        labels.append(1)\n    except:\n        print(im_path)\n    \nfor im_path in rose_flower_paths:\n    try:\n        img = cv2.imread(im_path)\n        img = cv2.resize(img,(224,224)) # VGG19's default input shape is 224x224\n        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        images.append(img)\n        labels.append(2)\n    except:\n        print(im_path)\n\nfor im_path in sunflower_flower_paths:\n    try:\n        img = cv2.imread(im_path)\n        img = cv2.resize(img,(224,224)) # VGG19's default input shape is 224x224\n        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        images.append(img)\n        labels.append(3)\n    except:\n        print(im_path)\n\nfor im_path in tulip_paths:\n    try:\n        img = cv2.imread(im_path)\n        img = cv2.resize(img,(224,224)) # VGG19's default input shape is 224x224\n        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        images.append(img)\n        labels.append(4)  \n    except:\n        print(im_path)\n    \n\ndata = np.array(images)\nlabels = np.array(labels)\nprint(data.shape)\nprint(labels.shape)","a5ccd40a":"# class distrubiton\nplt.subplots(figsize=(6,4))\nsns.countplot(labels)\nplt.title(\"Class Distribution\")\nplt.xlabel(\"Class Number\")\nplt.ylabel(\"Sample Count\")\nplt.show()","3b549eae":"# checking random samples\ndef check_sample(idx):\n    plt.imshow(data[idx])\n    plt.title(\"Label: {}\".format(labels[idx]))\n    plt.axis(\"off\")\n    plt.show()\n    \ncheck_sample(123)","1caf6375":"check_sample(678)","6264ba17":"check_sample(1233)","57a0b7bb":"# label encoding\nlabels = to_categorical(labels,num_classes=5)\nlabels.shape","7f61aead":"labels[0]","0537963d":"# train test splitting\nx_train,x_test,y_train,y_test = train_test_split(data,labels)\n\nprint(\"x_train shape \",x_train.shape)\nprint(\"x_test shape\" ,x_test.shape)\nprint(\"y_train shape \",y_train.shape)\nprint(\"y_test shape \",y_test.shape)","5dd4ee10":"VGG = VGG19(weights=\"imagenet\")\nVGG.summary()","eab71ac6":"# creating a blank model\nmodel = Sequential()\n\n# adding layers\nfor i in range(len(VGG.layers)-1):\n    model.add(VGG.layers[i])\n    ","aa9d833e":"# freezing layers\nfor layer in model.layers:\n    layer.trainable = False\n    ","a16334c9":"# adding prediction layer\nmodel.add(Dense(5,activation=\"softmax\"))","f8dc6e5d":"optim = Adam(lr=1e-4)\nmodel.compile(optimizer=optim,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","bc86e60f":"# Data Augmentation\ndatagen = ImageDataGenerator(horizontal_flip=True,\n                             vertical_flip=True\n                            )\n\ndatagen.fit(x_train)","c36fd230":"history = model.fit_generator(datagen.flow(x_train,y_train,batch_size=32),epochs=100)","6334aa31":"model.evaluate(x_test,y_test)","aade2e91":"# loss graph\nplt.subplots(figsize=(6,4))\nplt.plot(history.epoch,history.history[\"loss\"],color=\"green\",label=\"Train Loss\")\nplt.xlabel(\"Epoch Number\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","874dd0c8":"plt.subplots(figsize=(6,4))\nplt.plot(history.epoch,history.history[\"accuracy\"],color=\"green\",label=\"Train Accuracy\")\nplt.xlabel(\"Epoch Number\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.show()","0a1b5f27":"y_true = np.argmax(y_test, axis=1) # Decoding our one hot vectors\ny_pred = model.predict_classes(x_test)\n\n# Creating confusion matrix\nconf_matrix = confusion_matrix(y_true=y_true,y_pred=y_pred)\n","06aab674":"plt.subplots(figsize=(6,6))\nsns.heatmap(conf_matrix,annot=True,fmt=\".1f\",cmap=\"gist_stern_r\",linewidths=2.0)\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Class\")\nplt.ylabel(\"Actual Class\")\nplt.show()","4c1e0a1c":"* Let's check confusion matrix","f3d842b1":"# Introduction\nHello people, in this kernel I am going to classify images using VGG19 pre trained model. Before starting, let's take a look at the content of the kernel\n\n# Notebook Content\n1. Importing Necessary Libraires\n1. Loading Data\n1. Data Overview\n1. Data Preprocessing\n1. Preparing VGG19\n1. Training and Evaluating Results\n1. Conclusion","7a26b66e":"* Test accuracy is %84. Great!\n* Let's evaluate results.","b78da551":"# Data Preprocessing\nIn this section I am going to process the data in order to use in the model.","91d441c9":"# Importing Necessary Libraries","59b00969":"# Training and Evaluating Results\nIn this section I am going to train and evaluate the model.","f35522cf":"* Data is balanced.","5dafe921":"* Everything looks fine.","b98f6971":"# Loading Data\nIn this section I am going to load the data. ","2103f476":"# Conclusion\n\nThanks for your attention, if you have questions in your mind, please ask. I will definetely return to you. \n\nAnd if you liked this kernel, if you upvote I would be glad.","db25f0e1":"# Data Overview\nIn this section I am going to examine the data.","f3b391bd":"# Preparing VGG19 Model\nIn this section I am going to prepare VGG19 model."}}