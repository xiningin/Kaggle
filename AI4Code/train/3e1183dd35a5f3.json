{"cell_type":{"83195691":"code","1362a7e9":"code","2823975c":"code","3431d1e3":"code","1b57ea01":"code","b172472e":"code","f172200e":"code","a340544d":"code","806073d7":"code","6eabd2d1":"code","4902c887":"code","daba8c13":"code","8d7d5663":"code","41a7179d":"code","894c84e4":"code","21dc5176":"code","c0121c58":"code","8d38d435":"code","b7291157":"markdown","6c2ba038":"markdown","22d60475":"markdown","c14dbf09":"markdown","983d00ef":"markdown","2c151dc6":"markdown","5322b930":"markdown","ae85efc0":"markdown","e8150803":"markdown","6a8158c6":"markdown"},"source":{"83195691":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1362a7e9":"dating = pd.read_csv('..\/input\/speed-dating\/speeddating.csv')\ndating.head()","2823975c":"dating.isnull().sum()","3431d1e3":"list(dating.columns.values)","1b57ea01":"dating = dating.drop(columns=['has_null',\n                              'wave',\n                              'expected_happy_with_sd_people',\n                              'expected_num_interested_in_me',\n                              'expected_num_matches',\n                              'd_expected_happy_with_sd_people',\n                              'd_expected_num_interested_in_me',\n                              'd_expected_num_matches',\n                              'decision',\n                              'decision_o',\n                              'd_importance_same_race',\n                              'd_importance_same_religion',\n                              'd_pref_o_attractive',\n                              'd_pref_o_sincere',\n                              'd_pref_o_intelligence',\n                              'd_pref_o_funny',\n                              'd_pref_o_ambitious',\n                              'd_pref_o_shared_interests',\n                              'd_attractive_o',\n                              'd_sinsere_o',\n                              'd_intelligence_o',\n                              'd_funny_o',\n                              'd_ambitous_o',\n                              'd_shared_interests_o',\n                              'd_attractive_important',\n                              'd_sincere_important',\n                              'd_intellicence_important',\n                              'd_funny_important',\n                              'd_ambtition_important',\n                              'd_shared_interests_important',\n                              'd_attractive',\n                              'd_sincere',\n                              'd_intelligence',\n                              'd_funny',\n                              'd_ambition',\n                              'd_attractive_partner',\n                              'd_sincere_partner',\n                              'd_intelligence_partner',\n                              'd_funny_partner',\n                              'd_ambition_partner',\n                              'd_shared_interests_partner',\n                              'd_sports',\n                              'd_tvsports',\n                              'd_exercise',\n                              'd_dining',\n                              'd_museums',\n                              'd_art',\n                              'd_hiking',\n                              'd_gaming',\n                              'd_clubbing',\n                              'd_reading',\n                              'd_tv',\n                              'd_theater',\n                              'd_movies',\n                              'd_concerts',\n                              'd_music',\n                              'd_shopping',\n                              'd_yoga',\n                              'd_interests_correlate',\n                              'd_like',\n                              'd_guess_prob_liked'\n                             ], axis=1)\ndating.head()","b172472e":"list(dating.columns.values)","f172200e":"from sklearn.base import BaseEstimator, TransformerMixin, clone\nimport re\n\n\n# Use a custom transformer for data preprocessing\nclass DataCleaner(BaseEstimator, TransformerMixin):\n\n    def __init__(self, y_feature):\n        self.y_feature = y_feature\n        self.features_with_wrong_data_type = []\n        self.numerical_features = []\n        self.categorical_features = []\n        self.features_with_invalid_value = []\n        self.one_hot_features = []\n        self.invalid_values = set()\n\n    # Getter for numerical features\n    def getNumericalFeatures(self):\n        return self.numerical_features\n\n    # Getter for categorical features\n    def getCategoricalFeatures(self):\n        return self.categorical_features\n\n    # Getter for collected invalid values\n    def getInvalidValues(self):\n        return self.invalid_values\n\n    # Detect integer value in data using regex\/regular expression\n    def detect_int_value(self, data):\n        return np.any(data.astype(str).str.contains('^\\d+$', regex=True))\n\n    # Detect integer value in data using regex\/regular expression\n    def detect_float_value(self, data):\n        return np.any(data.astype(str).str.contains('^-?\\d+\\.\\d+$|^\\d+$', regex=True))\n\n    # Detect invalid integer value in data using regex\/regular expression\n    def get_invalid_int_value(self, data):\n        return ', '.join(data[~data.astype(str).str.contains('^\\d+$', regex=True)]\n                         .value_counts().index.to_list())\n\n    # Detect invalid float value in data using regex\/regular expression\n    def get_invalid_float_value(self, data):\n        return ', '.join(data[~data.astype(str).str.contains('^-?\\d+\\.\\d+$|^\\d+$', regex=True)]\n                         .value_counts().index.to_list())\n\n    def drop_rows_with_unknow_values(self, data, feature):\n        return data[~data[feature].isna()]\n\n    def find_invalid_values(self, data):\n        # Iterates all columns in the dating dataset and detect data types automatically\n        for feature in data.columns.values:\n\n            # Check if the features casted as object should be casted with float\n            if data[feature].dtype == 'object':\n                # If the features should be casted with float, flag the feature as 'features_with_wrong_data_type'\n                if self.detect_float_value(data[feature]):\n                    data[feature] = data[feature].astype(\n                        'float64', errors='ignore')\n                    invalid_value = self.get_invalid_float_value(data[feature])\n                    # If invalid values are found, flag the feature as 'features_with_invalid_value'\n                    if invalid_value != '':\n                        self.invalid_values.add(invalid_value)\n                        self.features_with_invalid_value.append(feature)\n                    self.features_with_wrong_data_type.append(feature)\n                # If the feature is actually categorical, flag the feature as 'categorical_features'\n                else:\n                    self.categorical_features.append(feature)\n\n            # Check for invalid integer value in numerical columns with 'int64' datatype\n            if data[feature].dtype == 'int64':\n                invalid_value = self.get_invalid_int_value(data[feature])\n                if invalid_value != '':\n                    self.invalid_values.add(invalid_value)\n                    self.features_with_invalid_value.append(feature)\n                data[feature] = data[feature].astype('float64', errors='raise')\n                self.numerical_features.append(feature)\n\n            # Check for invalid integer value in numerical columns with 'float64' datatype\n            elif data[feature].dtype == 'float64':\n                invalid_value = self.get_invalid_float_value(data[feature])\n                if invalid_value != '':\n                    self.invalid_values.add(invalid_value)\n                    self.features_with_invalid_value.append(feature)\n                self.numerical_features.append(feature)\n\n    def fit(self, data, y=None):\n\n        # Detect any numerical features casted with 'object' data type and with invalid values\n        self.find_invalid_values(data)\n\n        return self\n\n    def transform(self, data, y=None):\n\n        # Replace '?' value with NaN\n        data = data.replace('^\\?$', np.NaN, regex=True)\n\n        # Change numerical features with 'object' data type and change to 'float64'\n        for feature in self.features_with_invalid_value:\n            data[feature] = data[feature].astype('float64', errors='raise')\n\n        # Add the fixed features back to numerical features\n        self.numerical_features += self.features_with_invalid_value\n\n        # Remove unwanted quotes: change values like ''Example'' to 'Example'\n        for feature in self.categorical_features:\n            for value in data[feature].value_counts().index:\n                if re.search('^\\'.+\\'$', value.replace(' ', '')):\n                    index = data[data[feature] == value].index\n                    data.loc[index, feature] = value[1:-1]\n\n        return data","a340544d":"cleaner = DataCleaner('match')\ndating1 = cleaner.fit_transform(dating.copy())","806073d7":"print(f'Invalid values found: {cleaner.getInvalidValues()}')","6eabd2d1":"print('List of numerical features:')\nnum_attr = cleaner.getNumericalFeatures()\nnum_attr.remove('match')\nnum_attr","4902c887":"print('List of categorical features:')\ncat_attr = cleaner.getCategoricalFeatures()\ncat_attr","daba8c13":"dating1.head()","8d7d5663":"from sklearn.impute import SimpleImputer\nimp = SimpleImputer(strategy='most_frequent')\ndating2 = pd.DataFrame(imp.fit_transform(dating1))\ndating2.columns = dating1.columns.values\ndating2.head()","41a7179d":"X = dating2.drop(columns=['match'])\nX.head()","894c84e4":"y = dating2['match']\ny=y.astype('int')\ny.head()","21dc5176":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split (X, y, test_size=0.3, random_state=42, stratify=y)","c0121c58":"from imblearn.over_sampling import SMOTENC\nsmotenc = SMOTENC([0, 4, 5, 6, 10],random_state = 42)\nX_oversample, y_oversample = smotenc.fit_resample(X_train, y_train)","8d38d435":"from sklearn. import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nparam_grid = {'n_estimators':range(10,60,10)}\ngrid = GridSearchCV(RandomForestClassifier(), param_grid, cv=10)\ngrid.fit(X_oversample, y_oversample)\ngrid.best_params_\ngrid.best_score_","b7291157":"Import Data","6c2ba038":"SMOTENC\n0,4,5,6,10 --> locations of categorical data","22d60475":"Drop irrelevant columns","c14dbf09":"X and Y split","983d00ef":"Clean Data","2c151dc6":"Smote imbalance - SMOTE-NC and Train Test Split","5322b930":"Code from https:\/\/www.kaggle.com\/polarbearyap\/speeddating-part-ii","ae85efc0":"Attributes lists","e8150803":"Random Forest Classifier","6a8158c6":"Imputation of missing values with most frequent values"}}