{"cell_type":{"a3bfce57":"code","ad6e18c4":"code","1264094f":"code","49e2cd8e":"code","9821e80b":"code","3c0164cb":"code","5bd00bb6":"code","66992d2f":"code","b1b972c3":"code","224bdfb8":"code","8db92077":"code","d987d89d":"code","27077e90":"code","856ec0be":"code","667a7b99":"code","886e6a80":"code","9036c928":"code","b4e2983d":"code","2fe8a1e7":"code","eb1eaeeb":"code","9b3bf89c":"code","b10e4c98":"code","41544f44":"markdown","23c67859":"markdown","de8b53b8":"markdown","9aa8820e":"markdown","19adac84":"markdown","2ecdbb4e":"markdown","0014df5f":"markdown","ec30fc83":"markdown","8fb19915":"markdown","47aeef1a":"markdown","50c7bc2d":"markdown","e777a70c":"markdown","4a5adaac":"markdown","ccf19a3a":"markdown","695265c6":"markdown","99e3c687":"markdown","9189368a":"markdown","e7e97800":"markdown","6303b259":"markdown","3c88c8d9":"markdown","9aa7ee2d":"markdown","3efa51bf":"markdown"},"source":{"a3bfce57":"import pandas as pd\nimport numpy as np\npd.set_option(\"display.max_columns\", None)\n\nfrom datetime import datetime\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'font.size': 14})\n\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\n\nimport warnings # Supress warnings\nwarnings.filterwarnings(\"ignore\")\n\ndata_folder = \"..\/input\/g-research-crypto-forecasting\/\"\n\nasset_details = pd.read_csv(data_folder + 'asset_details.csv', low_memory=False)\ntrain = pd.read_csv(data_folder + 'train.csv', low_memory=False)\n#supplemental_train = pd.read_csv(data_folder + 'supplemental_train.csv', low_memory=False)\n#example_test = pd.read_csv(data_folder + 'example_test.csv', low_memory=False)\n#example_sample_submission = pd.read_csv(data_folder + 'example_sample_submission.csv', low_memory=False)\n\nrename_dict = {}\nfor a in asset_details['Asset_ID']:\n    rename_dict[a] = asset_details[asset_details.Asset_ID == a].Asset_Name.values[0]\n\n#display(asset_details)","ad6e18c4":"# Convert timestamp\ntrain['timestamp'] = train['timestamp'].astype('datetime64[s]')\n#supplemental_train['timestamp'] = supplemental_train['timestamp'].astype('datetime64[s]')\n#example_test['timestamp'] = example_test['timestamp'].astype('datetime64[s]')\n\n#train['date'] = pd.DatetimeIndex(train['timestamp']).date\n#supplemental_train['date'] = pd.DatetimeIndex(supplemental_train['timestamp']).date\n#example_test['date'] = pd.DatetimeIndex(example_test['timestamp']).date\n\n# Resample\ntrain_daily = pd.DataFrame()\n\nfor asset_id in asset_details.Asset_ID:\n    train_single = train[train.Asset_ID == asset_id].copy()\n\n    train_single_new = train_single[['timestamp','Count']].resample('D', on='timestamp').sum()\n    train_single_new['Open'] = train_single[['timestamp','Open']].resample('D', on='timestamp').first()['Open']\n    train_single_new['High'] = train_single[['timestamp','High']].resample('D', on='timestamp').max()['High']\n    train_single_new['Low'] = train_single[['timestamp','Low']].resample('D', on='timestamp').min()['Low']\n    train_single_new['Close'] = train_single[['timestamp','Close']].resample('D', on='timestamp').last()['Close']\n    train_single_new['Volume'] = train_single[['timestamp','Volume']].resample('D', on='timestamp').sum()['Volume']\n    # train_single_new['VWAP']\n    #train_single_new['Target'] = train_single[['timestamp','Target']].resample('D', on='timestamp').mean()['Target']\n    train_single_new['Asset_ID'] = asset_id\n\n    train_daily = train_daily.append(train_single_new.reset_index(drop=False))\ntrain_daily = train_daily.sort_values(by = ['timestamp', 'Asset_ID']).reset_index(drop=True)\n\ntrain_daily = train_daily.pivot(index='timestamp', columns='Asset_ID')[['Count', 'Open', 'High', 'Low', 'Close', 'Volume']]\ntrain_daily = train_daily.reset_index(drop=False)\n\ndisplay(train_daily.head(10))","1264094f":"# Visualize\nfig = make_subplots(\n    rows=len(asset_details.Asset_ID), cols=1,\n    subplot_titles=(asset_details.Asset_Name)\n)\n\nfor i, asset_id in enumerate(asset_details.Asset_ID):\n    fig.append_trace(go.Candlestick(x=train_daily.timestamp, \n                                         open=train_daily[('Open', asset_id)], \n                                         high=train_daily[('High', asset_id)], \n                                         low=train_daily[('Low', asset_id)], \n                                         close=train_daily[('Close', asset_id)]),\n                  row=i+1, col=1,\n                    )\n\n    fig.update_xaxes(range=[train_daily.timestamp.iloc[0], train_daily.timestamp.iloc[-1]], row=i+1, col=1)\n\n\nfig.update_layout(xaxis_rangeslider_visible = False, \n                  xaxis2_rangeslider_visible = False, \n                  xaxis3_rangeslider_visible = False,\n                  xaxis4_rangeslider_visible = False,\n                  xaxis5_rangeslider_visible = False,\n                  xaxis6_rangeslider_visible = False,\n                  xaxis7_rangeslider_visible = False,\n                  xaxis8_rangeslider_visible = False,\n                  xaxis9_rangeslider_visible = False,\n                  xaxis10_rangeslider_visible = False,\n                  xaxis11_rangeslider_visible = False,\n                  xaxis12_rangeslider_visible = False,\n                  xaxis13_rangeslider_visible = False,\n                  xaxis14_rangeslider_visible = False,\n                  height=3000, width=800, \n                  #title_text=\"Subplots with Annotations\"\n                      margin = dict(\n        l = 0,\n        r = 0,\n        b = 0,\n        t = 30,\n        pad = 0)\n                 )\n                 \nfig.show()","49e2cd8e":"train_daily['year'] = pd.DatetimeIndex(train_daily['timestamp']).year\ntrain_daily['quarter'] = pd.DatetimeIndex(train_daily['timestamp']).quarter\ntrain_daily['month'] = pd.DatetimeIndex(train_daily['timestamp']).month\ntrain_daily['weekofyear'] = pd.DatetimeIndex(train_daily['timestamp']).weekofyear\ntrain_daily['dayofyear'] = pd.DatetimeIndex(train_daily['timestamp']).dayofyear\ntrain_daily['weekday'] = pd.DatetimeIndex(train_daily['timestamp']).weekday","9821e80b":"# define function to compute log returns\ndef log_return(series, periods=1):\n    # Copied from https:\/\/www.kaggle.com\/cstein06\/tutorial-to-the-g-research-crypto-competition\n    return np.log(series).diff(periods=periods)\n\n\nfor i, asset_id in enumerate(asset_details.Asset_ID):\n    train_daily[('lret',  asset_id)] = log_return(train_daily[( 'Close',  asset_id)])","3c0164cb":"assets_mini = [1, 6]\n# Visualize\nf, ax = plt.subplots(nrows=len(assets_mini), ncols=1, figsize=(12, 6))\nfor i, asset_id in enumerate(assets_mini):\n\n    sns.lineplot(data=train_daily, x='timestamp', y = ( 'lret',  asset_id) , ax=ax[i]);\n    ax[i].set_title(asset_details[asset_details.Asset_ID == asset_id].Asset_Name.values[0])\n    ax[i].set_xlim([train_daily.timestamp.iloc[0], train_daily.timestamp.iloc[-1]])\n    ax[i].set_ylim([-0.6,0.6])\n    ax[i].set_ylabel('Log Return')\nplt.suptitle('Log Return\\n')\n\nplt.tight_layout()\nplt.show()","5bd00bb6":"f, ax = plt.subplots(nrows=2, ncols=1, figsize=(12, 8))\n\nsns.lineplot(data=train_daily, x='timestamp', y = ( 'Close',  1) , ax=ax[0]);\nsns.lineplot(data=train_daily, x='timestamp', y = ( 'lret',  1) , ax=ax[1]);\nax[0].set_xlim([pd.Timestamp('2019-09-01'), pd.Timestamp('2020-12-01')])\nax[0].set_ylim([0, 20000])\n\nax[1].set_xlim([pd.Timestamp('2019-09-01'), pd.Timestamp('2020-12-01')])\nax[1].annotate('COVID-19', xy=(pd.Timestamp('2020-03-15'), -0.5),  xycoords='data',\n            xytext=(0.6, 0.2), textcoords='axes fraction',\n            arrowprops=dict(facecolor='black', shrink=0.05, width=1),\n            #horizontalalignment='right', verticalalignment='top',\n            )\nplt.show()","66992d2f":"# Visualize\nfig = make_subplots(\n    rows=2, cols=1,\n    subplot_titles=(['Bitcoin', 'Ethereum'])\n)\n\nfor i, asset_id in enumerate([1, 6]):\n    fig.append_trace(go.Candlestick(x=train_daily.timestamp, \n                                         open=train_daily[('Open', asset_id)], \n                                         high=train_daily[('High', asset_id)], \n                                         low=train_daily[('Low', asset_id)], \n                                         close=train_daily[('Close', asset_id)]),\n                  row=i+1, col=1,\n                    )\n\n    fig.update_xaxes(range=[pd.Timestamp('2018-01-01'), pd.Timestamp('2018-03-01')], row=i+1, col=1)\n\nfig.update_yaxes(range=[0, 20000], row=1, col=1)\nfig.update_yaxes(range=[0, 2000], row=2, col=1)\n\nfig.update_layout(xaxis_rangeslider_visible = False, \n                  xaxis2_rangeslider_visible = False, \n                  #height=3000, \n                  width=800, \n                  #title_text=\"Subplots with Annotations\"\n                      margin = dict(\n        l = 0,\n        r = 0,\n        b = 0,\n        t = 30,\n        pad = 0)\n                 )\n                 \nfig.show()","b1b972c3":"f, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 8))\nsns.scatterplot(data=train_daily, x=('Close', 1), y=('Close', 6), hue='year', palette='Set1')\nax.set_xlabel('Bitcoin Close [$]')\nax.set_ylabel('Ethereum Close [$]')\nax.set_title('Relationship between Bitcoin and Ethereum')\nplt.show()","224bdfb8":"train_daily['ratio_btc_etc'] = train_daily[( 'Close',  6)] \/ train_daily[( 'Close',  1)]","8db92077":"f, ax = plt.subplots(nrows=1, ncols=1, figsize=(16, 4))\n\nsns.lineplot(data=train_daily, x='timestamp', y='ratio_btc_etc')\nax.axhline(y=0.03, color='k', linestyle='--')\nax.annotate('Death of ETH Party', xy=(pd.Timestamp('2021-03-01'), 0.03))\n\nax.axhline(y=0.07964, color='k', linestyle='--')\nax.annotate('Flippty Percent', xy=(pd.Timestamp('2021-03-01'), 0.07964))\n\nax.axhline(y=0.15929, color='k', linestyle='--')\nax.annotate('The Flippening', xy=(pd.Timestamp('2021-03-01'), 0.15929))\n\nax.set_ylim([0, 0.17])\nax.set_xlim([train_daily.timestamp.iloc[0], train_daily.timestamp.iloc[-1]])\nax.set_title('The RatioGang')\nplt.show()","d987d89d":"assets_mini = [1, 6]\n# Visualize\nf, ax = plt.subplots(nrows=len(assets_mini), ncols=2, figsize=(12, len(assets_mini)*3))\nfor i, asset_id in enumerate(assets_mini):\n    plot_acf(train_daily[('lret', i)].fillna(0), lags=16, ax=ax[i, 0], title=f\"ACF {asset_details[asset_details.Asset_ID == asset_id].Asset_Name.values[0]}\")\n    plot_pacf(train_daily[('lret', i)].fillna(0), lags=16, method='ols', ax=ax[i, 1], title=f\"PACF {asset_details[asset_details.Asset_ID == asset_id].Asset_Name.values[0]}\")\n    \nplt.tight_layout()\nplt.show()","27077e90":"for i, asset_id in enumerate(asset_details.Asset_ID):\n    train_daily[('lret -1',  asset_id)] = train_daily[('lret',  asset_id)].shift(1)","856ec0be":"from statsmodels.tsa.seasonal import seasonal_decompose\n\nperiods = [7, 28, 365]\n   \nasset_id = 1 # Bitcoin\n# Visualize\nf, ax = plt.subplots(nrows=len(periods), ncols=1, figsize=(12, 12))\nfor i, p in enumerate(periods):\n    decomp = seasonal_decompose(train_daily[('Close',  asset_id)].fillna(0), period=p, model='additive', extrapolate_trend='freq')\n    train_daily[(f'Trend_{p}',  asset_id)] = np.where(train_daily[('Close',  asset_id)].isna(), np.NaN, decomp.trend) #decomp.trend\n    \n    \n    sns.lineplot(data=train_daily, x='timestamp', y = ('Close',  asset_id) , ax=ax[i], color='lightgrey');\n    sns.lineplot(data=train_daily, x='timestamp', y = (f'Trend_{p}',  asset_id) , ax=ax[i], color='red');\n    ax[i].set_title(f\"{asset_details[asset_details.Asset_ID == asset_id].Asset_Name.values[0]} Trend with a Period of {p} Day\")\n    ax[i].set_xlim([train_daily.timestamp.iloc[0], train_daily.timestamp.iloc[-1]])\n    #ax[i].set_ylim([-0.6,0.6])\n    ax[i].set_ylabel('Close Price [$]')\n    \n#plt.suptitle(f'Underlying Trend with {PERIOD} day period\\n')\nplt.tight_layout()\nplt.show()","667a7b99":"trend = train_daily[('Close',  1)].rolling(\n    window=365,       # 365-day window\n    center=True,      # puts the average at the center of the window\n    min_periods=183,  # choose about half the window size\n).mean()   \n\nf, ax = plt.subplots(nrows=1, ncols=1, figsize=(12,5))\n\nsns.lineplot(data=train_daily, x='timestamp', y = ('Close',  1) , ax=ax, color='lightgrey');\nsns.lineplot(x=train_daily['timestamp'], y = trend, ax=ax, color='red');\n#ax[i].set_title(f\"{asset_details[asset_details.Asset_ID == asset_id].Asset_Name.values[0]} Trend with a Period of {p} Day\")\nax.set_xlim([train_daily.timestamp.iloc[0], train_daily.timestamp.iloc[-1]])\n#ax[i].set_ylabel('Close Price [$]')\n\n#plt.suptitle(f'Underlying Trend with {PERIOD} day period\\n')\nplt.show()","886e6a80":"# Visualize\nf, ax = plt.subplots(nrows=len(train_daily.year.unique()), ncols=1, figsize=(12, 12))\nfor i, year in enumerate(train_daily.year.unique()):\n\n    sns.lineplot(data=train_daily[train_daily.year == year], x='dayofyear', y = ('lret',  1), ax=ax[i])\n    sns.lineplot(data=train_daily[train_daily.year == year], x='dayofyear', y = 0 , ax=ax[i], color='black');\n\n    ax[i].set_title(year)\n    ax[i].set_xlim([0, 365])\n    ax[i].set_ylim([-.2, .2])\n\nplt.tight_layout()\nplt.show()","9036c928":"# https:\/\/www.kaggle.com\/ryanholbrook\/seasonality\n\n# annotations: https:\/\/stackoverflow.com\/a\/49238256\/5769929\ndef seasonal_plot(X, y, period, freq, ax=None):\n    if ax is None:\n        _, ax = plt.subplots()\n    palette = sns.color_palette(\"husl\", n_colors=X[period].nunique(),)\n    ax = sns.lineplot(\n        x=freq,\n        y=y,\n        hue=period,\n        data=X,\n        ci=False,\n        ax=ax,\n        palette=palette,\n        legend=False,\n    )\n    ax.set_title(f\"Seasonal Plot ({period}\/{freq})\")\n    for line, name in zip(ax.lines, X[period].unique()):\n        y_ = line.get_ydata()[-1]\n        ax.annotate(\n            name,\n            xy=(1, y_),\n            xytext=(6, 0),\n            color=line.get_color(),\n            xycoords=ax.get_yaxis_transform(),\n            textcoords=\"offset points\",\n            size=14,\n            va=\"center\",\n        )\n    return ax\n\n\ndef plot_periodogram(ts, detrend='linear', ax=None):\n    from scipy.signal import periodogram\n    fs = pd.Timedelta(\"1Y\") \/ pd.Timedelta(\"1D\")\n    freqencies, spectrum = periodogram(\n        ts,\n        fs=fs,\n        detrend=detrend,\n        window=\"boxcar\",\n        scaling='spectrum',\n    )\n    if ax is None:\n        _, ax = plt.subplots()\n    ax.step(freqencies, spectrum, color=\"purple\")\n    ax.set_xscale(\"log\")\n    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n    ax.set_xticklabels(\n        [\n            \"Annual (1)\",\n            \"Semiannual (2)\",\n            \"Quarterly (4)\",\n            \"Bimonthly (6)\",\n            \"Monthly (12)\",\n            \"Biweekly (26)\",\n            \"Weekly (52)\",\n            \"Semiweekly (104)\",\n        ],\n        rotation=30,\n    )\n    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n    ax.set_ylabel(\"Variance\")\n    ax.set_title(\"Periodogram\")\n    return ax\n","b4e2983d":"X = train_daily[[('Close', 1), ('dayofyear', ''), ('year', '')]]\nX.columns = X.columns.get_level_values(0)\n\nseasonal_plot(X, y='Close', period='year', freq='dayofyear');","2fe8a1e7":"X = train_daily[[('Close', 1), ('weekday', ''), ('weekofyear', '')]]\nX.columns = X.columns.get_level_values(0)\n\nseasonal_plot(X, y='Close', period='weekofyear', freq='weekday');","eb1eaeeb":"X = train_daily.set_index('timestamp')[('Close', 1)]\n\nplot_periodogram(X);","9b3bf89c":"# Upper Shadow and Lower Shadow as shown in the [Tutorial to the G-Research Crypto Competition](https:\/\/www.kaggle.com\/cstein06\/tutorial-to-the-g-research-crypto-competition)\n\nfor i, asset_id in enumerate(asset_details.Asset_ID):\n    train_daily[('upper_shadow',  asset_id)] = train_daily[('High',  asset_id)] - np.maximum(train_daily[('Close',  asset_id)], train_daily[('Open',  asset_id)])\n    train_daily[('lower_shadow',  asset_id)] = np.minimum(train_daily[('Close',  asset_id)], train_daily[('Open',  asset_id)]) - train_daily[('Low',  asset_id)]\n    \nasset_id = 1\n\ntemp = train_daily[[('Open',  asset_id), ('Low',  asset_id), ('High',  asset_id), ('Close',  asset_id), ('upper_shadow',  asset_id), ('lower_shadow',  asset_id)]]\nsns.heatmap(temp.corr(), vmin=0, vmax=1, cmap='Blues', annot=True)\nplt.show()\n\nasset_id = 6\n\ntemp = train_daily[[('Open',  asset_id), ('Low',  asset_id), ('High',  asset_id), ('Close',  asset_id), ('upper_shadow',  asset_id), ('lower_shadow',  asset_id)]]\nsns.heatmap(temp.corr(), vmin=0, vmax=1, cmap='Blues', annot=True)\nplt.show()","b10e4c98":"## Stationarity\n\n#The 'Close' prices seem to be mostly non-stationary. However, Bitcoin and Ethereum seem to be stationary.\n\nfrom statsmodels.tsa.stattools import adfuller\n\ndef check_stationarity(series, asset_id):\n    # Copied and edited from https:\/\/machinelearningmastery.com\/time-series-data-stationary-python\/\n\n    result = adfuller(series.values)\n    if (result[1] <= 0.05) & (result[4]['5%'] > result[0]):\n        print(f\"{asset_details[asset_details.Asset_ID == asset_id].Asset_Name.values[0]}: \\u001b[32mStationary\\u001b[0m\")\n    else:\n        print(f\"{asset_details[asset_details.Asset_ID == asset_id].Asset_Name.values[0]}: \\x1b[31mNon-stationary\\x1b[0m\")\n       \n    print('ADF Statistic: %f' % result[0])\n    print('p-value: %f' % result[1])\n    print('Critical Values:')\n    for key, value in result[4].items():\n        print('\\t%s: %.3f' % (key, value))\n    print('\\n')\n\nassets_mini = [1, 6, 9, 4]\nfor i, asset_id in enumerate(assets_mini):    \n    check_stationarity(train_daily[('Close', i)].fillna(0), asset_id)\n    \n    \n    \n# The log returns seem to be stationary.\nfor i, asset_id in enumerate(assets_mini):    \n    check_stationarity(train_daily[('lret', i)].fillna(0), asset_id)","41544f44":"## Feature Engineering: RatioGang\n[\ud83d\udcaa RatioGang \ud83d\udd25](https:\/\/ratiogang.com\/)","23c67859":"## Altcoin Season\n\n![5u7wzn.jpg](attachment:c94dc13e-fe1d-4fa1-9a3b-ca40cef2d235.jpg)\n\nThe term *altcoins* refers to all cryptocurrencies other than Bitcoin.\n\n> If 75% of the Top 50 coins performed better than Bitcoin over the last season (90 days) it is Altcoin Season. Excluded from the Top 50 are Stablecoins (Tether, DAI\u2026) and asset backed tokens (WBTC, stETH, cLINK,\u2026) - [Altcoin Season Index on blockchaincenter.net](https:\/\/www.blockchaincenter.net\/altcoin-season-index\/)","de8b53b8":"# Trend\nSince predicting random walks is quite challenging, let's see if we can at least decompose the time series and see if we can find an underlying trend.\n\nSo, **are we going to the moon or not**. That is the big question.\n\n![y6bmoq3ei1k61.jpg](attachment:62e2c74f-c69e-4d70-ae88-ceeec735fcce.jpg)\n\n<a href=\"https:\/\/www.reddit.com\/r\/CryptoCurrency\/comments\/ltqlz9\/what_happens_when_you_invest_in_crypto_you_go_to\/\">via reddit<\/a>\n\n","9aa8820e":"# Correlation\n\n> Among cryptocurrency assets with substantial valuations, **correlation is an on-and-off affair**. Bitcoin prices have set investor and price momentum in crypto markets for most of the last decade. Lately, however, as other cryptocurrencies have garnered popularity with developers and investors, that **correlation has proven difficult to maintain**. **For example, bitcoin prices fell even as prices for Ethereum\u2019s ether (ETH) rose to new heights in early 2018.** - [Correlations Within The Context of Cryptocurrencies](https:\/\/www.gemini.com\/cryptopedia\/asset-correlation-between-cryptocurrencies#section-establishing-correlations-between-cryptocurrencies)","19adac84":"# Introduction\n\nIn this notebook, we will try to find the underlying **relationships between the 14 coins** as suggested in the introductory notebook by the competition host. \n> We encourage participants to perform additional statistical analyses to have a stronger grasp on the dataset, including autocorrelation, time-series decomposition and stationarity tests. - [Tutorial to the G-Research Crypto Competition](https:\/\/www.kaggle.com\/cstein06\/tutorial-to-the-g-research-crypto-competition)\n\nAlong the way, we intend to interpret our findings in the hope of providing some **domain knowledge** about the crypto scene (which is also going to include a few memes).\n\n<img src=\"https:\/\/media.giphy.com\/media\/YkYt0FzMNPJkFnSQlf\/giphy.gif\" style=\"width: 800px;\">\n\n<a href=\"https:\/\/giphy.com\/gifs\/carlos-scam-bitconnect-YkYt0FzMNPJkFnSQlf\">via GIPHY<\/a>","2ecdbb4e":"# Autocorrelation and Partial Autocorrelation\n\nFor in depth explanation on Autocorrelation analysis see: [Time Series: Interpreting ACF and PACF](https:\/\/www.kaggle.com\/iamleonie\/time-series-interpreting-acf-and-pacf)\n\nFor the majority of the coins it looks like we have a slight negative correlation at a lag of 1. For the other lags, it looks like the autocorrelations are statistically insignificant. This could indicate, that we have some **Random-Walk behavior, which is going to make the prediction challenging**.","0014df5f":"## Feature Engineering: Log Return\n\nTo make a time series stationary, you can try differencing it. In this case, we will use the log return instead as shown below.","ec30fc83":"# Summary\n\n- Correlation between coins highly varies over time\n- Similarly to share prices, coin prices seem to follow a **random walk** pattern, which is difficult to predict\n- Feature Engineering:\n    - Time Features (e.g., `year`, `month`, `dayofweek`, etc.)\n    - Log Return\n    - Lag Features\n    - RatioGang: Ratio between BTC and ETH","8fb19915":"# Seasonality\n\nLet's see if we can see any similarity in volatility across several years. E.g. is the volatility always high at the end of the year?\n\nThe below plot does not necessarily seem to indicate any seasonal pattern like that on the first glance.","47aeef1a":"# Data Overview\n\nFurthermore, we have samples from 2018-01-01 to 2021-09-21 for the majority of coins. For TRON, Stellar, Cardano, IOTA, Maker, and Dogecoin we have fewer data starting from later in 2018 or even later in 2019 in Dogecoin's case.","50c7bc2d":"Utility functions from [Learn Tutorial: Time Series, Seasonality by Ryan Holbrook](https:\/\/www.kaggle.com\/ryanholbrook\/seasonality)","e777a70c":"The log return is also a good indicator of the volatility.","4a5adaac":"## Feature Engineering: Time Features\nLet's create some simple time features","ccf19a3a":"Furthermore, we can see that the relationship between the different coins can highly vary depending on the year, we are observing.","695265c6":"## COVID-19 Impact\n\nIn the below plots for the log return, we can see a negative peak around March 2020. If we have a closer look at the log return of e.g. Bitcoin, we can see that this was the impact of the COVID-19 pandemic.\n\n![st,small,507x507-pad,600x600,f8f8f8.jpg](attachment:3b28a366-cc09-41b5-9337-19430da55593.jpg)\n\n<a href=\"https:\/\/www.redbubble.com\/de\/i\/sticker\/Kaufte-mehr-Bitcoin-von-SecretPastures\/68916371.EJUG5\">via RedBubble<\/a>\n","99e3c687":"## Determining Trend with Time-Series Decomposition","9189368a":"Neither the seasonal plots nor the periodogram suggest any strong seasonality.","e7e97800":"# Preprocessing\n\nFor the following EDA, we will **resample the minute-wise crypto data to daily samples**. This reduces the amount of samples from 24,236,806 to 1,360. ","6303b259":"# Other Time Series Forecasting Notebooks\n\n- [Intro to Time Series Forecasting](https:\/\/www.kaggle.com\/iamleonie\/intro-to-time-series-forecasting)\n- [Time Series Forecasting: Building Intuition](https:\/\/www.kaggle.com\/iamleonie\/time-series-forecasting-building-intuition)\n- [Time Series: Interpreting ACF and PACF](https:\/\/www.kaggle.com\/iamleonie\/time-series-interpreting-acf-and-pacf)\n","3c88c8d9":"## Determining Trend with Moving Average Plot","9aa7ee2d":"So, it really depends on what period you look at:\nIf we look at the 365 day period trend, we are definitely going to the moon. ","3efa51bf":"## Feature Engineering 3: Lag Features\nHowever, we can still create a new feature for lag of 1 with the `.shift()` function."}}