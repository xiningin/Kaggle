{"cell_type":{"ada4c8bd":"code","a20f5ebb":"code","56b25c1b":"code","27acc8e1":"code","64bbf57c":"code","6f1dd65b":"code","189513e2":"code","3fcfa0ec":"code","c27cbc2b":"code","c662f21e":"code","8919625e":"code","06f8c72d":"code","d5b37bca":"code","72f0aa9c":"code","9b040953":"code","4e47e68f":"code","d41fbca6":"code","6671f9fd":"code","9a807dd0":"code","8fed2cbe":"code","196b5279":"markdown","6e59bcbd":"markdown","e7a93af3":"markdown","ba5bf2cd":"markdown","9a1b7d47":"markdown","3433ea2f":"markdown","5bff6bdf":"markdown","319575e6":"markdown","dfde0810":"markdown","15566903":"markdown","0c553586":"markdown","498a8eba":"markdown","d960b2cd":"markdown","0fd700fd":"markdown","9f3aa013":"markdown","2a806802":"markdown","0426e142":"markdown","bcdad5c9":"markdown"},"source":{"ada4c8bd":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nimport seaborn as sns\nimport scipy.stats\n\nimport missingno\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.feature_selection import f_classif\nfrom sklearn.feature_selection import SelectKBest, f_regression\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.ensemble import BaggingClassifier\nimport lightgbm as lgb\nfrom sklearn.utils import estimator_html_repr\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report,confusion_matrix\nfrom sklearn import svm\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nimport optuna\nimport os","a20f5ebb":"train = pd.read_csv('..\/input\/iba-ml2-mid-project\/train.csv')\ntest = pd.read_csv('..\/input\/iba-ml2-mid-project\/test.csv')","56b25c1b":"train[\"credit_line_utilization\"] = train[\"credit_line_utilization\"].replace(',','.', regex=True).astype(float)\ntest[\"credit_line_utilization\"] = test[\"credit_line_utilization\"].replace(',','.', regex=True).astype(float)","27acc8e1":"X = train.drop(['Id','defaulted_on_loan'], axis=1)\ny = train[['defaulted_on_loan']]","64bbf57c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle = True)\nprint(X_train.shape, y_test.shape)","6f1dd65b":"lr_pipeline=Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer(strategy='median')),\n    ('classifier', LogisticRegression())\n]) ","189513e2":"lr_pipeline.fit(X_train,y_train)\npred1 = lr_pipeline.predict_proba(X_test)\nprint(roc_auc_score(y_test, pred1[:,1]))","3fcfa0ec":"#model_pipeline2=Pipeline(steps=[\n#    ('scaler', StandardScaler()),\n#    ('impute', SimpleImputer()),\n#    ('classifier', PipelineHelper([\n#        \n#        \n#    \n#        ('lgb', lgb.LGBMClassifier())\n#    ])), \n# ])","c27cbc2b":"#params = {\n#    'classifier__selected_model': model_pipeline2.named_steps['classifier'].generate({\n#   'lgb__boosting_type' : ['gbdt','dart'],\n#   'lgb__num_leaves' : [2,3,4,5,6,7,8,9,10,15,20],\n#    'lgb__n_estimators' : [80,85,90,100,101]\n#        \n#    \n#        })\n#}\n\n#kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n# GridSearch is also doing cross-validation of data, but we can also add kfold\n#grid = GridSearchCV(model_pipeline2, params, cv=3, scoring='roc_auc')\n#result = grid.fit(X_train,y_train)\n#print('Best Score: ',  round((result.best_score_),4))\n#print('--------------------------------')\n#print(grid.best_params_)","c662f21e":"ctb_pipeline=Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer(strategy='median')),\n    ('classifier', CatBoostClassifier(silent=True,depth=9, iterations=1700, learning_rate=0.01, l2_leaf_reg=3,use_best_model=True))\n]) ","8919625e":"cate_features_index = np.where(X.dtypes != float)[0]\nctb_pipeline.fit(X_train, y_train,classifier__cat_features=cate_features_index, classifier__eval_set=(X_test,y_test))","06f8c72d":"pred3 = ctb_pipeline.predict_proba(X_test)\nprint(roc_auc_score(y_test, pred3[:,1]))","d5b37bca":"xgb_pipeline1 = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', XGBClassifier(max_depth = 7))  \n])","72f0aa9c":"xgb_pipeline1.fit(X_train, y_train)\npred4 = xgb_pipeline1.predict_proba(X_test)[:, 1]\n\n\nprint(roc_auc_score(y_test,pred4))","9b040953":"# %%time\n#def objective(trial):\n#    params = {\n#\n     \n\n#        'max_depth': trial.suggest_int('max_depth', 1, 10),\n#\n#        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n#\n#        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-8, 1.0),\n#        \n#       'reg_alpha':trial.suggest_uniform('reg_alpha',0,15),\n#       \n#       'reg_lambda':trial.suggest_uniform('reg_lambda',0,15),\n#        \n#         'gamma':trial.suggest_uniform('gamma', 0, 15),\n        \n#        'min_child_weight':trial.suggest_int('min_child_weight',0,15),    \n        \n#        'colsample_bytree':trial.suggest_uniform('colsample_bytree',0,1),\n#        'subsample':trial.suggest_uniform('subsample',0,1),\n        \n#        'scale_pos_weight':trial.suggest_int('scale_pos_weight',1,15), \n        \n        \n\n#    }\n    \n#    pl = Pipeline(steps=[\n#    ('scaler', StandardScaler()),\n#    ('impute', SimpleImputer()),\n#    ('classification', XGBClassifier(**params))  \n#])\n\n#    pl.fit(X_train, y_train)\n#    score = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n#\n#    return (score)   ","4e47e68f":"xgb_pipeline = Pipeline(steps=[\n    ('scaler', StandardScaler()),\n    ('impute', SimpleImputer()),\n    ('classification', XGBClassifier(max_depth = 8,  n_estimators = 380, learning_rate = 0.015, reg_alpha = 3.499, reg_lambda = 0.998,gamma = 1.65, min_child_weight = 1, colsample_bytree = 0.564, scale_pos_weight = 1))  \n])","d41fbca6":"xgb_pipeline.fit(X_train, y_train)\npred5 = xgb_pipeline.predict_proba(X_test)[:, 1]\n\n\nprint(roc_auc_score(y_test,pred5))","6671f9fd":"y_pred_final = ctb_pipeline.predict_proba(test.drop(['Id'],axis=1))\ny_pred_final2 = xgb_pipeline.predict_proba(test.drop(['Id'],axis=1))\n\n#Creating prediction column\nprediction = test[['Id']]\n\n#Adding average prediction values as new column\nprediction['Predicted'] = (y_pred_final[:,1]+y_pred_final2[:,1])\/2\n\n#checking the shape for consistency\nprediction.shape ","9a807dd0":"prediction.head(3)","8fed2cbe":"#prediction.to_csv(\"ML2submission16.csv\", index=False)\nprint(\"Submission was successfully saved!\")","196b5279":"### Starting with simplest","6e59bcbd":"### Prediction with optimized values:","e7a93af3":"### Loading necessary libraries:","ba5bf2cd":"#### Used Optuna for determining best hyperparameters, it tooks a bit long to compile, so I commented it out","9a1b7d47":"Oops, it seems this problem is 'too heavy' for LR, at least with imbalanced data and non-optimized hyperparameters.","3433ea2f":"<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https:\/\/miro.medium.com\/max\/1400\/1*QJZ6W-Pck_W7RlIDwUIN9Q.jpeg\" alt=\"Heat beating\" style=\"height:600px;margin-top:3rem;\"> <\/div>","5bff6bdf":"## Loading data","319575e6":"### Let's try LightGBM:","dfde0810":"### Simple XGBoost","15566903":"I used Voting Classifier initiallly but got better results in test dataset by simplying averaging the results of my 2 best predictors:","0c553586":"XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. Let's try it without any hyperparameter optimization.","498a8eba":"### Stacking Models`","d960b2cd":"### Without parameter optimization, XGBoost is giving good results and it is fast, let's find best parameters for it and give it a shot ","0fd700fd":"# <h1><center> *ML-2 Mid Project Model Interpretation\/Prediction Notebook* <\/center><\/h1>","9f3aa013":"I will start with simply LogisticRegression, whom is the king of classification for some banking problems!","2a806802":"## *Yandex's CatBoostClassifier:*","0426e142":"### Defining the predictors and target","bcdad5c9":"Nice score! I tried my submission and got score around 0.82. Let's improve our score."}}