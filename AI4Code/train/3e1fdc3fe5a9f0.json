{"cell_type":{"e4e02aa6":"code","296138fe":"code","1a4440d0":"code","cf30b6c5":"code","7f17f5a2":"code","d50c97e4":"code","cbe97fce":"code","25ab57ce":"code","7ae8add9":"code","72adb0df":"code","09ec9ba7":"code","44c79680":"code","9194ebe3":"code","2c31894a":"code","f2b0f567":"code","1c854689":"code","26afeba2":"code","168eaa0f":"code","922ad4e1":"markdown","c8478420":"markdown","b3feccab":"markdown"},"source":{"e4e02aa6":"import pandas as pd \nimport numpy as np\nimport cv2\nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","296138fe":"train_dir='..\/input\/real-life-industrial-dataset-of-casting-product\/casting_data\/casting_data\/train'\ntot_train=len(os.listdir(train_dir))\ntest_dir='..\/input\/real-life-industrial-dataset-of-casting-product\/casting_data\/casting_data\/test'\ntot_test=len(os.listdir(test_dir))\n\n","1a4440d0":"image=cv2.imread('..\/input\/real-life-industrial-dataset-of-casting-product\/casting_data\/casting_data\/train\/ok_front\/cast_ok_0_1092.jpeg')\nplt.title(\"OK IMAGE\")\ncv2.putText(image, \"OK_FRONT\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\nplt.imshow(image)","cf30b6c5":"image=cv2.imread(\"..\/input\/real-life-industrial-dataset-of-casting-product\/casting_data\/casting_data\/train\/def_front\/cast_def_0_1007.jpeg\")\nplt.title(\"DEFECT IMAGE\")\ncv2.putText(image, \"DEF_FRONT\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\nplt.imshow(image)\n\n","7f17f5a2":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndatagen=ImageDataGenerator(rescale=1.0\/255.0)","d50c97e4":"trainDatagen=datagen.flow_from_directory(train_dir,\n                                          target_size=(300,300),\n                                           batch_size=100,\n                                           class_mode='binary')\nvalDatagen=datagen.flow_from_directory(test_dir,\n                                              target_size=(300,300),\n                                           batch_size=70,\n                                           class_mode='binary')\n","cbe97fce":"model1=tf.keras.models.Sequential([tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(300,300,3)),\n                                 tf.keras.layers.MaxPooling2D(2,2),\n                                 tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n                                 tf.keras.layers.MaxPooling2D(2,2),\n                                 tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n                                 tf.keras.layers.MaxPooling2D(2,2),\n                                 tf.keras.layers.Dropout(0.3),\n                                   tf.keras.layers.Flatten(),\n                                 tf.keras.layers.Dense(512,activation='relu'),\n                                 tf.keras.layers.Dropout(0.4),\n                                 tf.keras.layers.Dense(1,activation='sigmoid')\n                                 ])\nmodel1.summary()","25ab57ce":"def create_model(input_shape):\n   \n    base_model = tf.keras.applications.Xception(input_shape = input_shape,\n                       include_top = False)\n                      \n\n    # we do not have to train all of the layers\n    for layer in base_model.layers:\n        layer.trainable = False\n        \n    x = tf.keras.layers.Flatten()(base_model.output)\n    #x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n    x = tf.keras.layers.Dense(256, activation = 'relu')(x)\n    x = tf.keras.layers.Dropout(0.5)(x)\n    x = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n    \n    return tf.keras.models.Model(base_model.input,x)\nmodel = create_model((300,300,3))\nmodel.summary()","7ae8add9":"model1.compile(loss='binary_crossentropy',\n             optimizer='adam',\n             metrics=['accuracy','AUC'])","72adb0df":"class mycallbacks(tf.keras.callbacks.Callback):\n    def on_epoch_end(self,epochs,logs={}):\n        if(logs.get('accuracy')>=1.0):\n            self.model.stop_training=True","09ec9ba7":"callbacks=mycallbacks()\nhistory=model1.fit_generator(trainDatagen,validation_data=valDatagen,epochs=20,verbose=1,callbacks=[callbacks])","44c79680":"model1.save('casting.h5')","9194ebe3":"acc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\nauc=history.history['auc']\nval_auc=history.history['val_auc']\nepochs=range(1,len(acc)+1)\n\nplt.plot(epochs,acc,'r',label='TRAINING ACCURACY')\nplt.plot(epochs,val_acc,'b',label='VALIDATION ACCURACY')\nplt.title('TRAINING vs VALIDATION ACCURACY')\nplt.legend()\nplt.figure()\nplt.show()\n\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Training vs validation loss')\nplt.legend()\n\nplt.show()\n\n\nplt.plot(epochs, auc, 'g', label='Training AUC') \nplt.plot(epochs, val_auc, 'r', label='Validation AUC')\nplt.title('Training vs validation AUC')\nplt.legend()\n\nplt.show()\n\n","2c31894a":"trainDatagen.class_indices","f2b0f567":"pred_probability = model1.predict_generator(valDatagen)\nvalDatagen.classes","1c854689":"from sklearn.metrics import classification_report\npredictions = pred_probability > 0.5\nprint(classification_report(valDatagen.classes,predictions))","26afeba2":"def prediction(image):\n    img=cv2.imread(image)\n    img=img\/255\n    pred = model1.predict(img.reshape(-1,300,300,3))\n    if (pred<0.5):\n        print(\"def_front\")\n        cv2.putText(img, \"def_front\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n    else:\n        print(\"ok_front\")\n        cv2.putText(img, \"ok_front\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n    \n    plt.imshow(img,cmap='gray')\n    plt.axis('off')\n    plt.show()","168eaa0f":"prediction('..\/input\/real-life-industrial-dataset-of-casting-product\/casting_data\/casting_data\/test\/def_front\/cast_def_0_1203.jpeg')","922ad4e1":"# > PREDICTION OF THE MODEL","c8478420":"# VISUALIZATION OF DEFECT AND CORRECT ONES","b3feccab":"# **IMPORTING LIBRARIES**"}}