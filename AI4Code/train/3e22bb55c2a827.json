{"cell_type":{"458aa380":"code","381cf827":"code","1ae762da":"code","b8f9faa0":"code","c5162f5e":"code","553309d9":"code","7e45d672":"code","a780019a":"code","703ed2d8":"code","f2d21054":"markdown"},"source":{"458aa380":"!mkdir outputs","381cf827":"%%writefile model.py\nimport torchvision.models as models\nimport torch.nn as nn\n\ndef build_model(pretrained=True, fine_tune=True):\n    if pretrained:\n        print('[INFO]: Loading pre-trained weights')\n    elif not pretrained:\n        print('[INFO]: Not loading pre-trained weights')\n    model = models.shufflenet_v2_x1_0(pretrained=pretrained)\n\n    if fine_tune:\n        print('[INFO]: Fine-tuning all layers...')\n        for params in model.parameters():\n            params.requires_grad = True\n    elif not fine_tune:\n        print('[INFO]: Freezing hidden layers...')\n        for params in model.parameters():\n            params.requires_grad = False\n            \n    # change the final classification head, it is trainable,\n    # there are 5 classes\n    model.fc = nn.Linear(1024, 5)\n    return model","1ae762da":"!python model.py","b8f9faa0":"%%writefile datasets.py\nimport torch\n\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\n# 20% of data for validation\nvalid_split = 0.2\nseed = 42\nbatch_size = 64\nroot_dir = '..\/input\/flowers-recognition\/flowers'\n\n# define the transforms...\n# resize, convert to tensors, ImageNet normalization\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n\n# the initial entire dataset\ndataset = datasets.ImageFolder(root_dir, transform=transform)\n\ndataset_size = len(dataset)\nprint(f\"Total number of images: {dataset_size}\")\n\nvalid_size = int(valid_split*dataset_size)\ntrain_size = len(dataset) - valid_size\n\n# training and validation sets\ntrain_data, valid_data = torch.utils.data.random_split(\n    dataset, [train_size, valid_size]\n)\n\nprint(f\"Total training images: {len(train_data)}\")\nprint(f\"Total valid_images: {len(valid_data)}\")\n\n# training and validation data loaders\ntrain_loader = DataLoader(\n    train_data, batch_size=batch_size, shuffle=True, num_workers=4\n)\nvalid_loader = DataLoader(\n    valid_data, batch_size=batch_size, shuffle=False, num_workers=4\n)","c5162f5e":"!python datasets.py","553309d9":"%%writefile utils.py\nimport torch\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nmatplotlib.style.use('ggplot')\n\n\ndef save_model(epochs, model, optimizer, criterion):\n    \"\"\"\n    Function to save the trained model to disk.\n    \"\"\"\n    torch.save({\n                'epoch': epochs,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'loss': criterion,\n                }, 'outputs\/model.pth')\n    \ndef save_plots(train_acc, valid_acc, train_loss, valid_loss):\n    \"\"\"\n    Function to save the loss and accuracy plots to disk.\n    \"\"\"\n    # accuracy plots\n    plt.figure(figsize=(10, 7))\n    plt.plot(\n        train_acc, color='green', linestyle='-', \n        label='train accuracy'\n    )\n    plt.plot(\n        valid_acc, color='blue', linestyle='-', \n        label='validataion accuracy'\n    )\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.savefig('outputs\/accuracy.png')\n    \n    # loss plots\n    plt.figure(figsize=(10, 7))\n    plt.plot(\n        train_loss, color='orange', linestyle='-', \n        label='train loss'\n    )\n    plt.plot(\n        valid_loss, color='red', linestyle='-', \n        label='validataion loss'\n    )\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.savefig('outputs\/loss.png')","7e45d672":"%%writefile train.py\nimport torch\nimport argparse\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom model import build_model\nfrom utils import save_model, save_plots\nfrom datasets import train_loader, valid_loader\nfrom tqdm.auto import tqdm\n\n# construct the argument parser\nparser = argparse.ArgumentParser()\nparser.add_argument('-e', '--epochs', type=int, default=20,\n    help='number of epochs to train our network for')\nargs = vars(parser.parse_args())\n\n# learning_parameters \nlr = 0.001\nepochs = args['epochs']\ndevice = ('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Computation device: {device}\\n\")\nmodel = build_model(pretrained=True, fine_tune=False).to(device)\n# total parameters and trainable parameters\ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f\"{total_params:,} total parameters.\")\ntotal_trainable_params = sum(\n    p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"{total_trainable_params:,} training parameters.\\n\")\n\n# optimizer\noptimizer = optim.Adam(model.parameters(), lr=lr)\n# loss function\ncriterion = nn.CrossEntropyLoss()\n\n# training\ndef train(model, trainloader, optimizer, criterion):\n    model.train()\n    print('Training')\n    train_running_loss = 0.0\n    train_running_correct = 0\n    counter = 0\n    for i, data in tqdm(enumerate(trainloader), total=len(trainloader)):\n        counter += 1\n        image, labels = data\n        image = image.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        # forward pass\n        outputs = model(image)\n        # calculate the loss\n        loss = criterion(outputs, labels)\n        train_running_loss += loss.item()\n        # calculate the accuracy\n        _, preds = torch.max(outputs.data, 1)\n        train_running_correct += (preds == labels).sum().item()\n        # backpropagation\n        loss.backward()\n        # update the optimizer parameters\n        optimizer.step()\n    \n    # loss and accuracy for the complete epoch\n    epoch_loss = train_running_loss \/ counter\n    epoch_acc = 100. * (train_running_correct \/ len(trainloader.dataset))\n    return epoch_loss, epoch_acc\n\n# validation\ndef validate(model, testloader, criterion):\n    model.eval()\n    print('Validation')\n    valid_running_loss = 0.0\n    valid_running_correct = 0\n    counter = 0\n    with torch.no_grad():\n        for i, data in tqdm(enumerate(testloader), total=len(testloader)):\n            counter += 1\n            \n            image, labels = data\n            image = image.to(device)\n            labels = labels.to(device)\n            # forward pass\n            outputs = model(image)\n            # calculate the loss\n            loss = criterion(outputs, labels)\n            valid_running_loss += loss.item()\n            # calculate the accuracy\n            _, preds = torch.max(outputs.data, 1)\n            valid_running_correct += (preds == labels).sum().item()\n        \n    # loss and accuracy for the complete epoch\n    epoch_loss = valid_running_loss \/ counter\n    epoch_acc = 100. * (valid_running_correct \/ len(testloader.dataset))\n    return epoch_loss, epoch_acc\n\n# lists to keep track of losses and accuracies\ntrain_loss, valid_loss = [], []\ntrain_acc, valid_acc = [], []\n# start the training\nfor epoch in range(epochs):\n    print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n    train_epoch_loss, train_epoch_acc = train(model, train_loader, \n                                              optimizer, criterion)\n    valid_epoch_loss, valid_epoch_acc = validate(model, valid_loader,  \n                                                 criterion)\n    train_loss.append(train_epoch_loss)\n    valid_loss.append(valid_epoch_loss)\n    train_acc.append(train_epoch_acc)\n    valid_acc.append(valid_epoch_acc)\n    print(f\"Training loss: {train_epoch_loss:.3f}, training acc: {train_epoch_acc:.3f}\")\n    print(f\"Validation loss: {valid_epoch_loss:.3f}, validation acc: {valid_epoch_acc:.3f}\")\n    print('-'*50)\n    \n# save the trained model weights\nsave_model(epochs, model, optimizer, criterion)\n# save the loss and accuracy plots\nsave_plots(train_acc, valid_acc, train_loss, valid_loss)\nprint('TRAINING COMPLETE')","a780019a":"!python train.py --epochs 95","703ed2d8":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 9))\nacc = plt.imread('outputs\/accuracy.png')\nplt.imshow(acc)\nplt.show()\nplt.figure(figsize=(12, 9))\nloss = plt.imread('outputs\/loss.png')\nplt.imshow(loss)\nplt.show()","f2d21054":"## Introduction\n* In this notebook, we use the PyTorch ShuffleNetV2 model for transfer learning on the [Flowers Recognition](https:\/\/www.kaggle.com\/alxmamaev\/flowers-recognition) dataset."}}