{"cell_type":{"e185b895":"code","71a4f418":"code","1ddcd71d":"code","7bd6cae2":"code","00944804":"code","0236e844":"code","823b2a20":"code","bf294a55":"code","304e5f0f":"code","ca6790b8":"code","3aec94bc":"code","0348b908":"code","343342e4":"code","d31caa7e":"code","b8f9a709":"code","d1634616":"code","af1b4ae2":"code","6d073586":"code","4d71c72a":"code","bd6c7847":"code","bbb7604a":"code","241cc1e7":"code","60321a65":"code","3b54c9f8":"code","c076c1a4":"code","80a5a5c1":"code","6fda78e4":"code","f7c91c74":"code","3f588f7d":"code","3a9ce727":"code","22a953be":"code","6fb34033":"code","26f4fb12":"code","816340f5":"code","67d16a90":"code","f63d9799":"code","ed54e6c9":"code","c3eb97f1":"code","a6b59748":"code","ace90910":"code","6aa4f018":"code","7b39a184":"code","5cd4225f":"code","b431c09a":"code","d2ed9ec3":"code","d9b824b8":"code","83c74bb3":"code","c04a017d":"code","cd9f215b":"code","15d2d8ab":"code","fe44f336":"code","2242853c":"code","94505d6b":"code","c887cc52":"code","3b662644":"code","273cda48":"code","58144f76":"code","de89d7d7":"code","2ad29b79":"code","d878bb2e":"code","510438b2":"code","9688b4bd":"code","e8e59e1d":"code","103fce7a":"code","3827c439":"code","d9ad9e70":"code","0222cbf1":"code","b1c2eadc":"code","eec94831":"code","5696d141":"code","cbfb939a":"code","704814b2":"code","383efa5e":"code","50f298fc":"code","315a3211":"code","3d9e4eeb":"code","bffb334a":"code","2259aae0":"code","42d381c2":"code","733b453e":"code","1c0c719b":"code","a8c6214d":"code","a542c2a7":"code","e3d9f063":"code","19bf3662":"code","bebe3df2":"code","032ffa63":"code","766e5ec2":"markdown","14be2897":"markdown","e52a81b9":"markdown","6b733551":"markdown","c468fd88":"markdown","42cefeda":"markdown","ee357261":"markdown","7f26cff6":"markdown"},"source":{"e185b895":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","71a4f418":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\n!pip install fastai==1.0.52\nimport fastai\n\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.tabular import *\n\n# from torchvision.models import *\n# import pretrainedmodels\n\nfrom utils import *\nimport sys\n\nfrom fastai.callbacks.hooks import *\n\nfrom fastai.callbacks.tracker import EarlyStoppingCallback\nfrom fastai.callbacks.tracker import SaveModelCallback","1ddcd71d":"from scipy.special import erfinv\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import *\nfrom torch.optim import *\nfrom fastai.tabular import *\nimport torch.utils.data as Data\nfrom fastai.basics import *\nfrom fastai.callbacks.hooks import *\nfrom tqdm import tqdm_notebook as tqdm","7bd6cae2":"def to_gauss(x): return np.sqrt(2)*erfinv(x)  #from scipy\n\ndef normalize(data, exclude=None):\n    # if not binary, normalize it\n    norm_cols = [n for n, c in data.drop(exclude, 1).items() if len(np.unique(c)) > 2]\n    n = data.shape[0]\n    for col in norm_cols:\n        sorted_idx = data[col].sort_values().index.tolist()# list of sorted index\n        uniform = np.linspace(start=-0.99, stop=0.99, num=n) # linsapce\n        normal = to_gauss(uniform) # apply gauss to linspace\n        normalized_col = pd.Series(index=sorted_idx, data=normal) # sorted idx and normalized space\n        data[col] = normalized_col # column receives its corresponding rank\n    return data","00944804":"df_train = pd.read_csv(\"..\/input\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/test.csv\")","0236e844":"df_train.head().T","823b2a20":"df_test.head().T","bf294a55":"df_train.info()","304e5f0f":"df_test.info()","ca6790b8":"add_datepart(df_train, \"datetime\", drop=False)\nadd_datepart(df_test, \"datetime\", drop=False)","3aec94bc":"df_train.head().T","0348b908":"df_train['season'] = df_train.season.map({1: 'spring', 2: 'summer', 3: 'fall', 4: 'winter'})\ndf_test['season'] = df_test.season.map({1: 'spring', 2: 'summer', 3: 'fall', 4: 'winter'})\n\ndf_train['holiday'] = df_train.holiday.map({0: 'non-holiday', 1: 'holiday'})\ndf_test['holiday'] = df_test.holiday.map({0: 'non-holiday', 1: 'holiday'})\n\ndf_train['workingday'] = df_train.workingday.map({0: 'holiday', 1: 'workingday'})\ndf_test['workingday'] = df_test.workingday.map({0: 'holiday', 1: 'workingday'})\n\ndf_train[\"weather\"] = df_train.weather.map({1: \" Clear + Few clouds + Partly cloudy + Partly cloudy\",\\\n                                        2 : \" Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \", \\\n                                        3 : \" Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\", \\\n                                        4 :\" Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \" })\n\ndf_test[\"weather\"] = df_test.weather.map({1: \" Clear + Few clouds + Partly cloudy + Partly cloudy\",\\\n                                        2 : \" Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \", \\\n                                        3 : \" Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\", \\\n                                        4 :\" Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \" })","343342e4":"df_train.head().T","d31caa7e":"df_train.info()","b8f9a709":"df_test.info()","d1634616":"procs=[FillMissing, Categorify]\n\ncat_vars = ['season', 'holiday', 'workingday', 'weather', 'datetimeYear', 'datetimeMonth',\n           'datetimeWeek', 'datetimeDay', 'datetimeDayofweek']\n\ncont_vars = ['temp', 'atemp', 'humidity', 'windspeed', 'casual', 'registered']\n\ndep_var = 'count'","af1b4ae2":"df_train.head().T","6d073586":"df_train = normalize(df_train, exclude=['season', 'holiday', 'workingday', 'weather', 'datetimeYear', 'datetimeMonth',\n           'datetimeWeek', 'datetimeDay', 'datetimeDayofweek', 'count', 'datetime'])","4d71c72a":"df_train.head().T","bd6c7847":"df = df_train[cat_vars + cont_vars + [dep_var,'datetime']].copy()\ndf.head().T","bbb7604a":"df_train['datetime'].min(), df_train['datetime'].max()","241cc1e7":"df_test['datetime'].min(), df_test['datetime'].max()","60321a65":"len(df_test), len(df_train)","3b54c9f8":"path = Path(\"..\/input\/\")","c076c1a4":"np.random.seed(42)\n\ndata = (TabularList.from_df(df, path=path, cat_names=cat_vars, cont_names=cont_vars, procs=procs)\n                .split_by_rand_pct(0.2, seed=42)\n                .label_from_df(cols=dep_var, label_cls=FloatList)\n                .databunch(bs=1024))","80a5a5c1":"data.show_batch()","6fda78e4":"learn = tabular_learner(data, layers=[1000,500], metrics=mean_squared_error, model_dir=\"..\/temp\/model\",\n                        ps=[0.1, 0.1], emb_drop=0.04)","f7c91c74":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","3f588f7d":"lr = 1e-1\nlearn.fit_one_cycle(5, max_lr=lr, wd=0.2, pct_start=0.3)","3a9ce727":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","22a953be":"lr = 1e-4\nlearn.fit_one_cycle(5, lr, wd=0.2, pct_start=0.3)","6fb34033":"learn.lr_find()\nlearn.recorder.plot(suggestion=True)","26f4fb12":"lr=5e-6\nlearn.fit_one_cycle(5, max_lr=lr, wd=0.2)","816340f5":"learn.save('1')\nlearn.recorder.plot_losses()","67d16a90":"class SaveFeatures():\n    features=None\n    def __init__(self, m): \n        self.hook = m.register_forward_hook(self.hook_fn)\n        self.features = None\n    def hook_fn(self, module, input, output): \n        out = output.detach().cpu().numpy()\n        if isinstance(self.features, type(None)):\n            self.features = out\n        else:\n            self.features = np.row_stack((self.features, out))\n    def remove(self): \n        self.hook.remove()","f63d9799":"learn.model","ed54e6c9":"sf = SaveFeatures(learn.model.layers[4])","c3eb97f1":"_= learn.get_preds(data.train_ds)","a6b59748":"label = [x for x in (list(data.train_ds.y.items))]","ace90910":"len(label)","6aa4f018":"df_new = pd.DataFrame({'label': label})","7b39a184":"df_new.head()","5cd4225f":"array = np.array(sf.features)","b431c09a":"x=array.tolist()","d2ed9ec3":"df_new['img_repr'] = x","d9b824b8":"df_new.head()","83c74bb3":"d2 = pd.DataFrame(df_new.img_repr.values.tolist(), index = df_new.index).rename(columns = lambda x: 'img_repr{}'.format(x+1))","c04a017d":"df_new_2 = df_new.join(d2)","cd9f215b":"df_new_2.head(10).T","15d2d8ab":"df_new_2.shape\n","fe44f336":"sf = SaveFeatures(learn.model.layers[4])","2242853c":"_=learn.get_preds(DatasetType.Valid)","94505d6b":"label = [x for x in (list(data.valid_ds.y.items))]","c887cc52":"df_new_valid = pd.DataFrame({'label': label})\n","3b662644":"array = np.array(sf.features)","273cda48":"x=array.tolist()\n","58144f76":"df_new_valid['img_repr'] = x\n","de89d7d7":"df_new_valid.head()","2ad29b79":"d2 = pd.DataFrame(df_new_valid.img_repr.values.tolist(), index = df_new_valid.index).rename(columns = lambda x: 'img_repr{}'.format(x+1))","d878bb2e":"df_new_valid_2 = df_new_valid.join(d2)\n","510438b2":"df_new_valid_2.head(10)","9688b4bd":"df_new_valid_2.shape","e8e59e1d":"df_new_valid_2.drop(['img_repr'], axis=1, inplace=True)","103fce7a":"df_new_valid_2.head()","3827c439":"df_new_2.drop(['img_repr'], axis=1, inplace=True)","d9ad9e70":"df_new_2.shape","0222cbf1":"df_new_2.describe()","b1c2eadc":"corr_matrix = df_new_2.corr()\n\ncorr_matrix[\"label\"].sort_values(ascending = False)","eec94831":"X = df_new_2\ny = df_new_2.label.copy()\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)","5696d141":"X_train.shape, y_train.shape, X_test.shape, y_test.shape","cbfb939a":"X_train = X_train.drop(\"label\", axis =1)\ny_train = y_train\n\nX_test = X_test.drop(\"label\", axis =1)\ny_test = y_test","704814b2":"X_train.shape, y_train.shape, X_test.shape, y_test.shape","383efa5e":"from sklearn.base import BaseEstimator, TransformerMixin\n\nclass DataFrameSelector(BaseEstimator, TransformerMixin):\n    \n    def __init__(self, attributes_names):\n        self.attributes_names = attributes_names\n        \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        return X[self.attributes_names].values","50f298fc":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n# numerical pipeline\n\nnum_pipeline = Pipeline([\n    \n    ('select_data', DataFrameSelector(X_train.columns)),\n    ('Std_Scaler', StandardScaler())\n])\n\nX_train_transformed = num_pipeline.fit_transform(X_train)\nX_test_transformed = num_pipeline.fit_transform(X_test)","315a3211":"X_train_transformed.shape, X_test_transformed.shape","3d9e4eeb":"from sklearn.ensemble import RandomForestRegressor\nimport time\n\nstart = time.time()\n\nrf_clf = RandomForestRegressor(bootstrap=True,\n            criterion='mse', max_depth=15, max_features=0.5,\n            max_leaf_nodes=None, min_impurity_decrease=0.0,\n            min_impurity_split=None, min_samples_leaf=3,\n            min_samples_split=8, min_weight_fraction_leaf=0.0,\n            n_estimators=185, n_jobs=1, oob_score=False, random_state=42,\n            verbose=0, warm_start=False)\n\nrf_clf.fit(X_train_transformed, y_train)\n\nend = time.time()\n\nprint(\"run_time:\", (end-start)\/(60*60))","bffb334a":"# import scipy.stats as st\n# from sklearn.model_selection import RandomizedSearchCV\n\n# one_to_left = st.beta(10, 1)  \n# from_zero_positive = st.expon(0, 50)\n\n# params = {  \n#     \"n_estimators\": st.randint(50, 300),\n#     \"max_depth\": st.randint(3, 40),\n#    \"min_samples_leaf\": st.randint(3, 40),\n#     \"min_samples_split\": st.randint(3, 20),\n#     \"max_features\": ['auto', 0.2, 0.3, 0.5]\n# }\n\n# gs = RandomizedSearchCV(rf_clf, params)","2259aae0":"# gs.fit(X_train_transformed, y_train)  ","42d381c2":"# gs.best_params_","733b453e":"from sklearn.model_selection import cross_val_predict, cross_val_score\n\nimport time\n\nstart = time.time()\n\nscore_rf = cross_val_score(rf_clf, X_train_transformed, y_train, cv=5, scoring='neg_mean_squared_error', verbose=0)\nprint(score_rf.mean())\n\nend = time.time()\n\nprint(\"run_time:\", (end-start)\/(60*60))","1c0c719b":"y_pred_test_rf = rf_clf.predict(X_test_transformed)","a8c6214d":"from sklearn.metrics import mean_squared_error\nmean_squared_error(y_test, y_pred_test_rf)","a542c2a7":"X = df_new_valid_2\ny = df_new_valid_2.label.copy()","e3d9f063":"X_val = X.drop(\"label\", axis =1)\ny_val = y","19bf3662":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\n# numerical pipeline\n\nnum_pipeline = Pipeline([\n    \n    ('select_data', DataFrameSelector(X_val.columns)),\n    ('Std_Scaler', StandardScaler())\n])\n\n\nX_val_transformed = num_pipeline.fit_transform(X_val)","bebe3df2":"y_pred_test_rf_val = rf_clf.predict(X_val_transformed)","032ffa63":"from sklearn.metrics import mean_squared_error\nmean_squared_error(y_val, y_pred_test_rf_val)","766e5ec2":"# Data Fields","14be2897":"# Prediction","e52a81b9":"# Fastai Hooks","6b733551":"# Data","c468fd88":"# Fastai - Tabular","42cefeda":"* datetime - hourly date + timestamp\n\n* season -  1 = spring, 2 = summer, 3 = fall, 4 = winter\n\n* holiday - whether the day is considered a holiday\n\n* workingday - whether the day is neither a weekend nor holiday\n\n* weather - \n* 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n\n* 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n\n* 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n\n* 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n\n* temp - temperature in Celsius\n\n* atemp - \"feels like\" temperature in Celsius\n\n* humidity - relative humidity\n\n* windspeed - wind speed\n\n* casual - number of non-registered user rentals initiated\n\n* registered - number of registered user rentals initiated\n\n* count - number of total rentals","ee357261":"# Embeddings for Valid Data","7f26cff6":"# Random Forest"}}