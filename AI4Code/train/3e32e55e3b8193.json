{"cell_type":{"dacef929":"code","cca7f564":"code","d639b8a9":"code","ccea05ea":"code","19315970":"code","85708502":"code","dba926d5":"code","ebeda972":"code","8ce67ef8":"code","3721576e":"code","4983d4fa":"code","17275c92":"code","0b66637b":"code","8a7d0280":"code","3a834c26":"code","004479dd":"code","a66d0518":"code","6f931e69":"code","bc013d19":"code","bc54839c":"code","ca6ca956":"code","8c895de2":"code","1ea1e815":"markdown","8756ae43":"markdown","35b22948":"markdown"},"source":{"dacef929":"# install pycaret\n!pip install pycaret","cca7f564":"# import libraries\nimport pandas as pd\nimport numpy as np","d639b8a9":"# read csv data\ndata = pd.read_csv('..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndata.head()","ccea05ea":"# check data types\ndata.dtypes","19315970":"# replace blanks with np.nan\ndata['TotalCharges'] = data['TotalCharges'].replace(' ', np.nan)\ndata.isnull().sum()","85708502":"# convert to float64\ndata['TotalCharges'] = data['TotalCharges'].astype('float64')\ndata.info()","dba926d5":"!pip install pandas-profiling","ebeda972":"from pandas_profiling import ProfileReport\nprofile = ProfileReport(data, title=\"EDA Report\")\nprofile","8ce67ef8":"# check missing values\ndata.isnull().sum()","3721576e":"round(data.Churn.value_counts()*100 \/ len(data),2)","4983d4fa":"categorical = []\nfor i in data.columns:\n    if (data[i].dtype=='object'):\n        categorical.append(i)\nprint(\"Categorical Attribute : {}\\n \".format(len(categorical)))\nfor x in range(len(categorical)): \n    print(categorical[x])","17275c92":"data[categorical].nunique()","0b66637b":"for i in categorical[1:]:\n    print(i)\n    print(data[i].unique())\n    print(\"\\n\")","8a7d0280":"# init setup\nfrom pycaret.classification import *\ntelecom = setup(data, target = 'Churn', ignore_features = ['customerID'],\n                ordinal_features = {'Contract' : ['Month-to-month' ,'One year', 'Two year']},\n                fix_imbalance = True,\n               transformation = True,#Transformation changes the shape of the distribution such that the transformed data can be represented by normal distribution\n                  normalize = True, #rescale the values of numeric columns\n                  handle_unknown_categorical = True, \n                  unknown_categorical_method = 'most_frequent',\n                  remove_multicollinearity = True, #rop one of the two features that are highly correlated with each other\n                  ignore_low_variance = True,#all categorical features with statistically insignificant variances are removed from the dataset.\n                  combine_rare_levels = True,# all levels in categorical features below the threshold defined in rare_level_threshold param are combined together as a single level\n                numeric_imputation='median',\n                categorical_imputation='mode',)","3a834c26":"# compare all models\nbest_model = compare_models()","004479dd":"ada= create_model('ada')","a66d0518":"print(ada)","6f931e69":"tuned_ada = tune_model(ada,optimize = 'AUC') #tuned on AUC","bc013d19":"evaluate_model(tuned_ada) #Graphical plot ","bc54839c":"predict_model(tuned_ada)# Test data evaluation ","ca6ca956":"final_ada = finalize_model(tuned_ada) # Final model \nfinal_ada","8c895de2":"predict_model(final_ada)#final test model evaluation ","1ea1e815":"# Exploratory Data Analysis","8756ae43":"# Data Preparation","35b22948":"# Missing Values"}}