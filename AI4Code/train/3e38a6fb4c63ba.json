{"cell_type":{"9f5fdff6":"code","8a2bbaff":"code","47c52469":"code","91af54d5":"code","dd2b61c7":"code","fc3800b0":"code","ba6f9427":"code","d33143c5":"code","0b15349d":"code","e06eed58":"code","0025abd9":"code","1336aaa4":"code","cfc7e078":"code","a39041f3":"code","77a10249":"code","03b2c82d":"code","7d6ed265":"code","4f0b1b60":"code","751f7ccc":"code","ebec433e":"code","f0934568":"code","8448f39c":"code","8dc99a67":"code","972abda8":"code","e9f5f073":"code","863abc58":"code","29e326a5":"code","d15822a3":"code","dfcaeb6d":"code","edf655e3":"code","29da60c4":"code","3a3287f2":"code","25c3206e":"code","be6d0374":"code","31cb8383":"code","a51c55a2":"code","014689f0":"code","06e406db":"code","4be829d4":"code","df8350ef":"code","9030a862":"code","241844f1":"code","0e306528":"code","29ff6d97":"code","20268f2a":"code","231656a8":"code","8d4822fa":"code","5b147ee6":"code","fd9507e9":"code","819c4b12":"code","f19f8796":"code","46c64324":"code","43e02307":"code","8fb40f9e":"code","7744288b":"code","857b5be2":"code","fa14741f":"code","bf967bad":"code","a883e7e1":"code","2663371e":"code","924f4299":"code","34e8426a":"code","3c84ff3e":"code","a2c7bae8":"code","7965147d":"code","3e68788a":"code","dbe92422":"code","ea658b0d":"code","5d80b94f":"code","ef37f976":"code","8926d700":"markdown","118f7aff":"markdown","cd571a0e":"markdown","80ead5da":"markdown","3a24d15b":"markdown","ae59d0e7":"markdown","064c1078":"markdown","bc16d3f3":"markdown","7a4024b2":"markdown","851babb9":"markdown","c1d17ed5":"markdown","004b99b8":"markdown","d0bbd9cf":"markdown","19989623":"markdown"},"source":{"9f5fdff6":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\nimport itertools\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\nfrom keras.preprocessing import image\nfrom skimage.feature import hessian_matrix, hessian_matrix_eigvals\nfrom scipy.ndimage.filters import convolve\nfrom skimage import data, io, filters\nimport skimage\nfrom skimage.morphology import convex_hull_image, erosion\nfrom skimage.morphology import square\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN, LSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.models import load_model\nimport keras\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","8a2bbaff":"Main_Non_DR = Path(\"..\/input\/diabetic-retinopathy-resized-arranged\/0\")","47c52469":"Non_DR_Path = list(Main_Non_DR.glob(r\"*.jpeg\"))","91af54d5":"DR_Path_Series = pd.Series(Non_DR_Path,name=\"JPEG\").astype(str)","dd2b61c7":"print(DR_Path_Series.head(-1))","fc3800b0":"Example_IMG = DR_Path_Series[23421]\nReading_IMG = cv2.imread(Example_IMG)\nReading_IMG = cv2.cvtColor(Reading_IMG,cv2.COLOR_BGR2RGB)\nplt.xlabel(Reading_IMG.shape)\nplt.ylabel(Reading_IMG.size)\nplt.imshow(Reading_IMG)","ba6f9427":"Example_IMG = DR_Path_Series[5]\nReading_IMG = cv2.imread(Example_IMG)\nReading_IMG = cv2.cvtColor(Reading_IMG,cv2.COLOR_BGR2RGB)\nplt.xlabel(Reading_IMG.shape)\nplt.ylabel(Reading_IMG.size)\nplt.imshow(Reading_IMG)","d33143c5":"Example_IMG = DR_Path_Series[1115]\nReading_IMG = cv2.imread(Example_IMG)\nReading_IMG = cv2.cvtColor(Reading_IMG,cv2.COLOR_BGR2RGB)\nplt.xlabel(Reading_IMG.shape)\nplt.ylabel(Reading_IMG.size)\nplt.imshow(Reading_IMG)","0b15349d":"figure,axis = plt.subplots(nrows=5,ncols=5,figsize=(12,12))\n\nfor i,ax in enumerate(axis.flat):\n    IMG_X = cv2.imread(DR_Path_Series[i])\n    IMG_X = cv2.cvtColor(IMG_X,cv2.COLOR_BGR2RGB)\n    ax.set_xlabel(IMG_X.shape)\n    ax.set_ylabel(IMG_X.size)\n    ax.imshow(IMG_X)\nplt.tight_layout()\nplt.show()","e06eed58":"figure,axis = plt.subplots(nrows=1,ncols=2,figsize=(12,12))\n\nExample_Image = cv2.imread(DR_Path_Series[4352])\nExample_Image = cv2.cvtColor(Example_Image,cv2.COLOR_BGR2RGB)\nCanny_Image = cv2.Canny(Example_Image,10,100)\n\naxis[0].imshow(Example_Image)\naxis[1].imshow(Canny_Image)","0025abd9":"figure,axis = plt.subplots(nrows=5,ncols=5,figsize=(12,12))\n\nfor i,ax in enumerate(axis.flat):\n    Example_Image = cv2.imread(DR_Path_Series[i])\n    Example_Image = cv2.cvtColor(Example_Image,cv2.COLOR_BGR2RGB)\n    Canny_Image = cv2.Canny(Example_Image,50,8)\n    ax.set_xlabel(Canny_Image.shape)\n    ax.set_ylabel(Canny_Image.size)\n    ax.imshow(Canny_Image)\nplt.tight_layout()\nplt.axis(\"off\")\nplt.show()","1336aaa4":"figure = plt.figure(figsize=(12,12))\nExample_Image = cv2.imread(DR_Path_Series[4578])\nExample_Image = cv2.cvtColor(Example_Image,cv2.COLOR_BGR2RGB)\nCanny_Image = cv2.Canny(Example_Image,50,8)\n\nplt.imshow(Canny_Image)","cfc7e078":"figure,axis = plt.subplots(nrows=1,ncols=2,figsize=(12,12))\n\nExample_Image = cv2.imread(DR_Path_Series[4578])\nExample_Image = cv2.cvtColor(Example_Image,cv2.COLOR_BGR2RGB)\n_,Threshold_Image = cv2.threshold(Example_Image,90,255,cv2.THRESH_BINARY_INV)\n\naxis[0].imshow(Example_Image)\naxis[1].imshow(Threshold_Image)","a39041f3":"figure,axis = plt.subplots(nrows=1,ncols=3,figsize=(12,12))\n\nExample_Image = cv2.imread(DR_Path_Series[4578])\nExample_Image = cv2.cvtColor(Example_Image,cv2.COLOR_BGR2RGB)\n_,Threshold_Image = cv2.threshold(Example_Image,90,255,cv2.THRESH_BINARY_INV)\nCanny_Image = cv2.Canny(Threshold_Image,10,8)\n\naxis[0].imshow(Example_Image)\naxis[1].imshow(Threshold_Image)\naxis[2].imshow(Canny_Image)","77a10249":"figure,axis = plt.subplots(nrows=1,ncols=2,figsize=(12,12))\n\nExample_Image = cv2.imread(DR_Path_Series[4578])\nExample_Image = cv2.cvtColor(Example_Image,cv2.COLOR_BGR2GRAY)\n\nHessian_Mat = hessian_matrix(Example_Image,sigma=0.15,order=\"rc\")\nmax_S,min_S = hessian_matrix_eigvals(Hessian_Mat)\n\naxis[0].imshow(min_S)\naxis[1].imshow(max_S)","03b2c82d":"figure,axis = plt.subplots(nrows=1,ncols=2,figsize=(12,12))\n\nExample_Image = cv2.imread(DR_Path_Series[48])\nExample_Image = cv2.cvtColor(Example_Image,cv2.COLOR_BGR2GRAY)\n\nHessian_Mat = hessian_matrix(Example_Image,sigma=4,order=\"rc\")\nmax_S,min_S = hessian_matrix_eigvals(Hessian_Mat)\n\naxis[0].imshow(min_S)\naxis[1].imshow(max_S)","7d6ed265":"figure,axis = plt.subplots(nrows=1,ncols=3,figsize=(12,12))\n\nExample_Image = cv2.imread(DR_Path_Series[4578])\nExample_Image = cv2.cvtColor(Example_Image,cv2.COLOR_BGR2GRAY)\n_,Threshold_Image = cv2.threshold(Example_Image,90,255,cv2.THRESH_BINARY_INV)\n\nArr_IMG = np.array(Example_Image > Threshold_Image).astype(int)\nSkeleton_IMG = skimage.morphology.skeletonize(Arr_IMG)\n\naxis[0].imshow(Example_Image)\naxis[1].imshow(Threshold_Image)\naxis[2].imshow(Skeleton_IMG)","4f0b1b60":"figure = plt.figure(figsize=(12,12))\nExample_Image = cv2.imread(DR_Path_Series[4578])\nExample_Image = cv2.cvtColor(Example_Image,cv2.COLOR_BGR2GRAY)\n_,Threshold_Image = cv2.threshold(Example_Image,90,255,cv2.THRESH_BINARY_INV)\n\nArr_IMG = np.array(Example_Image > Threshold_Image).astype(int)\nSkeleton_IMG = skimage.morphology.skeletonize(Arr_IMG)\n\nplt.imshow(Skeleton_IMG)","751f7ccc":"figure = plt.figure(figsize=(12,12))\nExample_Image = cv2.imread(DR_Path_Series[2201])\nExample_Image = cv2.cvtColor(Example_Image,cv2.COLOR_BGR2GRAY)\n_,Threshold_Image = cv2.threshold(Example_Image,90,255,cv2.THRESH_BINARY_INV)\n\nArr_IMG = np.array(Example_Image > Threshold_Image).astype(int)\nSkeleton_IMG = skimage.morphology.skeletonize_3d(Arr_IMG)\n\nplt.imshow(Skeleton_IMG)","ebec433e":"figure = plt.figure(figsize=(12,12))\nExample_Image = cv2.imread(DR_Path_Series[8])\nExample_Image = cv2.cvtColor(Example_Image,cv2.COLOR_BGR2GRAY)\n_,Threshold_Image = cv2.threshold(Example_Image,90,255,cv2.THRESH_BINARY_INV)\n\nArr_IMG = np.array(Example_Image > Threshold_Image).astype(int)\nSkeleton_IMG = skimage.morphology.skeletonize(Arr_IMG)\n\nplt.imshow(Skeleton_IMG)","f0934568":"figure,axis = plt.subplots(nrows=1,ncols=2,figsize=(12,12))\n\nExample_Image = cv2.imread(DR_Path_Series[48])\nExample_Image = cv2.cvtColor(Example_Image,cv2.COLOR_BGR2GRAY)\n\nHessian_Mat = hessian_matrix(Example_Image,sigma=4,order=\"rc\")\nmax_S,min_S = hessian_matrix_eigvals(Hessian_Mat)\n\nArr_IMG_Min = np.array(Example_Image > min_S).astype(int)\nSkeleton_IMG_Min = skimage.morphology.skeletonize(Arr_IMG_Min)\n\nArr_IMG_Max = np.array(Example_Image > max_S).astype(int)\nSkeleton_IMG_Max = skimage.morphology.skeletonize(Arr_IMG_Max)\n\naxis[0].imshow(Skeleton_IMG_Min)\naxis[1].imshow(Skeleton_IMG_Max)","8448f39c":"DR_Path_Series = DR_Path_Series[0:6000]","8dc99a67":"print(DR_Path_Series.head(-1))","972abda8":"Transformation_Data = []\n\nfor pick_IMG in DR_Path_Series:\n    IMG_Pick = cv2.imread(pick_IMG)\n    IMG_Pick = cv2.cvtColor(IMG_Pick,cv2.COLOR_BGR2RGB)\n    IMG_Pick = cv2.resize(IMG_Pick,(180,180))\n    IMG_Pick = IMG_Pick \/ 255.\n    Transformation_Data.append(IMG_Pick)","e9f5f073":"print(Transformation_Data[3].shape)","863abc58":"Training_Set = np.asarray(Transformation_Data)\nTraining_Set = Training_Set.reshape(-1,180,180,3)","29e326a5":"print(Training_Set.shape)","d15822a3":"Generator_Input = keras.Input(shape=(180,))\n\nx = layers.Dense(128*90*90)(Generator_Input)\nx = layers.LeakyReLU()(x)\nx = layers.Reshape((90,90,128))(x)\n\nx = layers.Conv2D(256,4,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2DTranspose(256,4,padding=\"same\",strides=2)(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(256,4,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(256,3,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(256,3,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(3,7,padding=\"same\",activation=\"tanh\")(x)","dfcaeb6d":"Generator = keras.models.Model(Generator_Input,x)","edf655e3":"print(Generator.summary())","29da60c4":"plot_model(Generator,show_dtype=True,show_layer_names=True)","3a3287f2":"Discriminator_Input = layers.Input(shape=(180,180,3))\n\nx = layers.Conv2D(128,3)(Discriminator_Input)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(128,4,strides=2)(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(128,4,strides=2)(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(128,4,strides=2)(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(128,3,strides=2)(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Flatten()(x)\nx = layers.Dense(1,activation=\"sigmoid\")(x)","25c3206e":"Discriminator = keras.models.Model(Discriminator_Input,x)","be6d0374":"print(Discriminator.summary())","31cb8383":"plot_model(Discriminator,show_dtype=True,show_layer_names=True)","a51c55a2":"Discriminator.compile(optimizer=RMSprop(lr=0.0004,clipvalue=1.0,decay=1e-8),loss=\"binary_crossentropy\")","014689f0":"Discriminator.trainable = False","06e406db":"GAN_Input = keras.Input(shape=(180,))\nGAN_Output = Discriminator(Generator(GAN_Input))","4be829d4":"GAN_Model = keras.models.Model(GAN_Input,GAN_Output)","df8350ef":"GAN_Model.compile(optimizer=RMSprop(lr=0.0004,clipvalue=1.0,decay=1e-8),loss=\"binary_crossentropy\")","9030a862":"print(GAN_Model.summary())","241844f1":"plot_model(GAN_Model,show_dtype=True,show_layer_names=True)","0e306528":"os.mkdir(\"NEW_IRIS_PIC\")","29ff6d97":"start_period = 0\nbatch_size = 32\ndim_size = 180\niterations = 3000","20268f2a":"for step in range(iterations):\n    random_noise_vector = np.random.normal(size=(batch_size,dim_size))\n    Generator_Iris = Generator.predict(random_noise_vector)\n    \n    stop = start_period + batch_size\n    \n    Real_Iris = Training_Set[start_period:stop]\n    \n    Combinated_Iris = np.concatenate([Generator_Iris,Real_Iris])\n    \n    labels = np.concatenate([np.ones((batch_size,1)),np.zeros((batch_size,1))])\n    labels = labels + 0.05 * np.random.random(labels.shape)\n    \n    Discriminator_Loss = Discriminator.train_on_batch(Combinated_Iris,labels)\n    \n    random_noise_vector = np.random.normal(size=(batch_size,dim_size))\n    \n    misleading_vector = np.zeros((batch_size,1))\n    \n    Adversarial_Loss = GAN_Model.train_on_batch(random_noise_vector,misleading_vector)\n    \n    start_period = start_period + batch_size\n    \n    if start_period > len(Training_Set) - batch_size:\n        start_period = 0\n    if step % 5 == 0:\n        GAN_Model.save_weights(\"DCGAN_M_Weights.h5\")\n        \n        print(\"DISCRIMINATOR LOSS: \", \"%.3f\" % Discriminator_Loss)\n        print(\"ADVERSARIAL LOSS: \", \"%.3f\" % Adversarial_Loss)\n        \n        Img_X_X = image.array_to_img(Generator_Iris[0] * 255., scale=False)\n        Img_X_X.save(os.path.join(\".\/NEW_IRIS_PIC\",\"FAKE\" + str(step)+\".png\"))\n        \n        Img_X_X = image.array_to_img(Real_Iris[0] * 255.,scale=False)\n        Img_X_X.save(os.path.join(\".\/NEW_IRIS_PIC\",\"REAL\"+str(step)+\".png\"))\n        \nGAN_Model.save(\"GAN_MAIN.h5\")\nprint(\"SUCCESS\")","231656a8":"Random_New_Noise = tf.random.normal(shape=[30,dim_size])","8d4822fa":"plt.imshow(Random_New_Noise)","5b147ee6":"Generator_Prediction_Iris = Generator(Random_New_Noise)","fd9507e9":"figure,axis = plt.subplots(nrows=5,ncols=5,figsize=(12,12))\n\nfor i,ax in enumerate(axis.flat):\n    IMG_Predict = Generator_Prediction_Iris[i]\n    ax.imshow(IMG_Predict)\n    ax.set_xlabel(IMG_Predict.shape)\nplt.tight_layout()\nplt.show()","819c4b12":"figure = plt.figure(figsize=(7,7))\nplt.axis(\"off\")\nplt.imshow(Generator_Prediction_Iris[7])\nplt.show()","f19f8796":"figure = plt.figure(figsize=(7,7))\nplt.axis(\"off\")\nplt.imshow(Generator_Prediction_Iris[5])\nplt.show()","46c64324":"figure = plt.figure(figsize=(7,7))\nplt.axis(\"off\")\nplt.imshow(Generator_Prediction_Iris[28])\nplt.show()","43e02307":"figure = plt.figure(figsize=(7,7))\nplt.axis(\"off\")\nplt.imshow(Generator_Prediction_Iris[1])\nplt.show()","8fb40f9e":"figure = plt.figure(figsize=(7,7))\nplt.axis(\"off\")\nplt.imshow(Generator_Prediction_Iris[18])\nplt.show()","7744288b":"Output_IMG = Path(\".\/NEW_IRIS_PIC\")\nList_Output_IMG = list(Output_IMG.glob(r\"*.png\"))\nList_Output_IMG_Series = pd.Series(List_Output_IMG,name=\"PNG\").astype(str)","857b5be2":"figure, axes = plt.subplots(nrows=7,ncols=7,figsize=(10,10))\n\nfor i,ax in enumerate(axes.flat):\n    List_Gen_Image = cv2.imread(List_Output_IMG_Series[i])\n    List_Gen_Image = cv2.cvtColor(List_Gen_Image,cv2.COLOR_BGR2RGB)\n    ax.imshow(List_Gen_Image,cmap=\"binary\")\n    ax.set_xlabel(List_Gen_Image.shape)\n    ax.set_ylabel(List_Gen_Image.size)\nplt.tight_layout()\nplt.show()","fa14741f":"def splitting_text(main_path,path_list,labels_list):\n    \n    for image in main_path:\n        ID_Path,document_type = os.path.splitext(image)\n        main_path,type_iris = ID_Path.split(\"\/\")\n        path_list.append(image)\n        labels_list.append(type_iris[0:4])","bf967bad":"Path_PNG_List = []\nLabels_PNG_List = []","a883e7e1":"splitting_text(List_Output_IMG,Path_PNG_List,Labels_PNG_List)","2663371e":"print(Path_PNG_List[0:3])","924f4299":"print(Labels_PNG_List[0:3])","34e8426a":"Path_PNG_Series = pd.Series(Path_PNG_List,name=\"PNG\").astype(str)\nLabels_PNG_Series = pd.Series(Labels_PNG_List,name=\"CATEGORY\")\nMain_Total_Data = pd.concat([Path_PNG_Series,Labels_PNG_Series],axis=1)","3c84ff3e":"print(Main_Total_Data.head(-1))","a2c7bae8":"Fake_Iris = Main_Total_Data[Main_Total_Data[\"CATEGORY\"] == \"FAKE\"]\nFake_Iris = Fake_Iris.reset_index()","7965147d":"figure, axes = plt.subplots(nrows=6,ncols=6,figsize=(10,10))\n\nfor i,ax in enumerate(axes.flat):\n    List_Gen_Image = cv2.imread(Fake_Iris[\"PNG\"][i])\n    List_Gen_Image = cv2.cvtColor(List_Gen_Image,cv2.COLOR_BGR2RGB)\n    ax.imshow(List_Gen_Image,cmap=\"binary\")\n    ax.set_xlabel(List_Gen_Image.shape)\n    ax.set_ylabel(List_Gen_Image.size)\nplt.tight_layout()\nplt.show()","3e68788a":"figure = plt.figure(figsize=(7,7))\nIMG_Fake = Fake_Iris[\"PNG\"][5]\nFake_Iris_Img = cv2.imread(IMG_Fake)\nFake_Iris_Img = cv2.cvtColor(Fake_Iris_Img,cv2.COLOR_BGR2RGB)\nplt.axis(\"off\")\nplt.imshow(Fake_Iris_Img)\nplt.show()","dbe92422":"figure = plt.figure(figsize=(7,7))\nIMG_Fake = Fake_Iris[\"PNG\"][8]\nFake_Iris_Img = cv2.imread(IMG_Fake)\nFake_Iris_Img = cv2.cvtColor(Fake_Iris_Img,cv2.COLOR_BGR2RGB)\nplt.axis(\"off\")\nplt.imshow(Fake_Iris_Img)\nplt.show()","ea658b0d":"figure = plt.figure(figsize=(7,7))\nIMG_Fake = Fake_Iris[\"PNG\"][10]\nFake_Iris_Img = cv2.imread(IMG_Fake)\nFake_Iris_Img = cv2.cvtColor(Fake_Iris_Img,cv2.COLOR_BGR2RGB)\nplt.axis(\"off\")\nplt.imshow(Fake_Iris_Img)\nplt.show()","5d80b94f":"figure = plt.figure(figsize=(7,7))\nIMG_Fake = Fake_Iris[\"PNG\"][23]\nFake_Iris_Img = cv2.imread(IMG_Fake)\nFake_Iris_Img = cv2.cvtColor(Fake_Iris_Img,cv2.COLOR_BGR2RGB)\nplt.axis(\"off\")\nplt.imshow(Fake_Iris_Img)\nplt.show()","ef37f976":"figure = plt.figure(figsize=(7,7))\nIMG_Fake = Fake_Iris[\"PNG\"][30]\nFake_Iris_Img = cv2.imread(IMG_Fake)\nFake_Iris_Img = cv2.cvtColor(Fake_Iris_Img,cv2.COLOR_BGR2RGB)\nplt.axis(\"off\")\nplt.imshow(Fake_Iris_Img)\nplt.show()","8926d700":"#### MAIN PATH","118f7aff":"#### NON DR PATH","cd571a0e":"# HISTORY","80ead5da":"# DATA PROCESS","3a24d15b":"#### INFORMATION\n\n* 0 - No DR\n* 1 - Mild\n* 2 - Moderate\n* 3 - Severe\n* 4 - Proliferative DR","ae59d0e7":"#### GENERATOR - DISCRIMINATOR STRUCTURE","064c1078":"# VISUALIZATION","bc16d3f3":"# PACKAGES AND LIBRARIES","7a4024b2":"#### TO SERIES","851babb9":"#### TRAINING","c1d17ed5":"# DC-GAN","004b99b8":"#### SAVING PATH","d0bbd9cf":"# PATH PROCESS","19989623":"#### PREDICTION"}}