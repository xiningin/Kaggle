{"cell_type":{"ff21082e":"code","db352eb2":"code","148b00a7":"code","34a7d1fb":"code","a1da712d":"code","a9c9e7bc":"code","2f4770f1":"code","e487fbb0":"code","1bfdde57":"code","a6c92885":"code","92eafcc5":"code","a4ed57eb":"code","2c3e2303":"code","81f7e925":"code","a9a721f5":"code","b4db254f":"code","07f7f228":"code","8c880e14":"code","bf5184d7":"code","f49b8a5d":"code","99f889fb":"code","a5d07d39":"code","2f953893":"code","1835f924":"code","50745bb1":"code","8a5a5250":"code","c3ca798f":"code","14111286":"code","dd50b6ec":"code","646d27b4":"code","14a8f2b3":"code","69829479":"code","8bd8d12a":"code","dd3b6769":"code","2cd0c0db":"code","ab3a74d0":"code","9db3dbec":"code","e27679c5":"code","60bc3226":"code","62a5fc1e":"code","6ec4cb2f":"code","fb169c05":"code","407fb6c5":"code","e31a2305":"code","f0ff47ab":"code","d742c8f2":"markdown","af6c731d":"markdown","b478ac83":"markdown","ff5ddc4e":"markdown","b06fc516":"markdown","9b4aaef7":"markdown","77ff48cc":"markdown","f064b553":"markdown","8e3c3fdf":"markdown","05f285db":"markdown","cf105ed5":"markdown","c23f7041":"markdown","9205e38a":"markdown","009cf8d3":"markdown","9130e26d":"markdown","a5bfb402":"markdown","56a2e864":"markdown","323ffb6d":"markdown","c241e07d":"markdown","435dae14":"markdown","03bf91ee":"markdown","b45c07ae":"markdown","c0852b86":"markdown","b56fa317":"markdown","9cbe5eaa":"markdown"},"source":{"ff21082e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","db352eb2":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb\n\n# to display all the columns in the dataset\npd.pandas.set_option('display.max_columns',None)","148b00a7":"train_df=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_df=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","34a7d1fb":"# Let's check the shape of the train data\ntrain_df.shape","a1da712d":"# Let's check the shape of the test data\ntest_df.shape","a9c9e7bc":"# Let's check the head of the train data\ntrain_df.head()","2f4770f1":"# Let's check the head of the test data\ntest_df.head()","e487fbb0":"train_ID=train_df['Id']\ntest_ID=test_df['Id']","1bfdde57":"# Histogram\nplt.figure(figsize=(8,6))\nsns.distplot(train_df['SalePrice']);","a6c92885":"plt.figure(figsize=(12,5))\ntrain_df.corr()['SalePrice'][:-1].sort_values().plot(kind='bar')\nplt.xlabel('Columns')\nplt.ylabel('Correlation')\nplt.show()","92eafcc5":"corrmat = train_df.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);","a4ed57eb":"plt.figure(figsize=(12,6))\nsns.boxplot(train_df['OverallQual'],train_df['SalePrice'])","2c3e2303":"plt.figure(figsize=(19,6))\nsns.boxplot(train_df['YearBuilt'],train_df['SalePrice'])\nplt.xticks(rotation=90);","81f7e925":"plt.scatter(x = train_df['TotalBsmtSF'], y = train_df['SalePrice'])","a9a721f5":"plt.scatter(x = train_df['GarageArea'], y = train_df['SalePrice'])","b4db254f":"plt.scatter(x = train_df['GarageCars'], y = train_df['SalePrice'])","07f7f228":"plt.scatter(x = train_df['GrLivArea'], y = train_df['SalePrice'])","8c880e14":"plt.scatter(x = train_df['OverallQual'], y = train_df['SalePrice'])","bf5184d7":"sns.distplot(train_df['SalePrice'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(train_df['SalePrice'], plot=plt)","f49b8a5d":"sns.distplot(train_df['GrLivArea'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(train_df['GrLivArea'], plot=plt)","99f889fb":"categorical_variables=[feature for feature in train_df.columns if train_df[feature].dtypes=='object']\nprint('Total number of numerial values: {}'.format(len(categorical_variables)))\n\ntrain_df[categorical_variables].head()","a5d07d39":"numerical_variables=[feature for feature in train_df.columns if train_df[feature].dtypes!='object']\n\nprint('Total number of numerial values: {}'.format(len(numerical_variables)))\n\n\ntrain_df[numerical_variables].head()","2f953893":"train=train_df.shape[0]\ntest=test_df.shape[0]\ny_train=train_df.SalePrice.values\ndf=pd.concat((train_df, test_df)).reset_index(drop=True)\ndf.drop(['SalePrice'], axis=1, inplace=True)","1835f924":"df.shape","50745bb1":"# Heatmap\nplt.figure(figsize=(10,6))\nsns.heatmap(df.isnull(),cbar=None,cmap='YlGnBu')","8a5a5250":"df=df.drop(['PoolQC','MiscFeature','Alley','Fence','FireplaceQu'],axis=1)","c3ca798f":"df_numerical_null=[feature for feature in df.columns if df[feature].isnull().sum() and df[feature].dtypes!='object']\n\nfor feature in df_numerical_null:\n    print(feature,round(df[feature].isnull().mean(),4))","14111286":"df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())\ndf['MasVnrArea']=df['MasVnrArea'].fillna(0)\ndf['BsmtFinSF1']=df['BsmtFinSF1'].fillna(0)\ndf['BsmtFinSF2']=df['BsmtFinSF2'].fillna(0)\ndf['BsmtUnfSF']=df['BsmtUnfSF'].fillna(0)\ndf['TotalBsmtSF']=df['TotalBsmtSF'].fillna(0)\ndf['BsmtFullBath']=df['BsmtFullBath'].fillna(0)\ndf['BsmtHalfBath']=df['BsmtHalfBath'].fillna(0)\ndf['GarageYrBlt']=df['GarageYrBlt'].fillna(0)\ndf['GarageCars']=df['GarageCars'].fillna(0)\ndf['GarageArea']=df['GarageArea'].fillna(0)","dd50b6ec":"df_categorical_null=[feature for feature in df.columns if df[feature].isnull().sum() and df[feature].dtypes=='object']\n\nfor feature in df_categorical_null:\n    print(feature,round(df[feature].isnull().mean(),4))","646d27b4":"df['MSZoning']=df['MSZoning'].fillna('RL')\ndf['Utilities']=df['Utilities'].fillna('None')\ndf['Exterior1st']=df['Exterior1st'].fillna(df['Exterior1st'].mode()[0])\ndf['Exterior2nd']=df['Exterior2nd'].fillna(df['Exterior2nd'].mode()[0])\ndf['MasVnrType']=df['MasVnrType'].fillna('None')\ndf['BsmtQual']=df['BsmtQual'].fillna('None')\ndf['BsmtCond']=df['BsmtCond'].fillna('None')\ndf['BsmtExposure']=df['BsmtExposure'].fillna('None')\ndf['BsmtFinType1']=df['BsmtFinType1'].fillna('None')\ndf['BsmtFinType2']=df['BsmtFinType2'].fillna('None')\ndf['Electrical']=df['Electrical'].fillna(df['Electrical'].mode()[0])\ndf['KitchenQual']=df['KitchenQual'].fillna('None')\ndf['Functional']=df['Functional'].fillna('Typ')\ndf['GarageType']=df['GarageType'].fillna('None')\ndf['GarageFinish']=df['GarageFinish'].fillna('None')\ndf['GarageQual']=df['GarageQual'].fillna('None')\ndf['GarageCond']=df['GarageCond'].fillna('None')\ndf['SaleType']=df['SaleType'].fillna(df['SaleType'].mode()[0])","14a8f2b3":"# Courtesy: https:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard\n\nnumeric_feats = df.dtypes[df.dtypes != \"object\"].index\n\n# Check the skew of all numerical features\nskewed_feats = df[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head(10)","69829479":"skewness = skewness[abs(skewness) > 0.75]\n\nfrom scipy.special import boxcox1p\nskewed_features = skewness.index\nlam = 0.15\nfor feat in skewed_features:\n    df[feat] += 1\n    df[feat] = boxcox1p(df[feat], lam)\n    \ndf[skewed_features] = np.log1p(df[skewed_features])","8bd8d12a":"# Getting rid of the Id column\ndf=df.drop('Id',axis=1)","dd3b6769":"df=pd.get_dummies(df)","2cd0c0db":"df.head()","ab3a74d0":"train=df[:train]\ntest=df[test:]","9db3dbec":"test=test.drop(test.index[0])","e27679c5":"#Validation function\nn_folds = 5\n\ndef rmsle_cv(model):\n    kf=KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n    rmse=np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)","60bc3226":"Ridge=KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\nscore=rmsle_cv(Ridge)\nprint(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","62a5fc1e":"Lasso=make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\nscore=rmsle_cv(Lasso)\nprint(\"Lasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","6ec4cb2f":"Elastic=make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\nscore=rmsle_cv(Elastic)\nprint(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","fb169c05":"GBoost=GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =5)\nscore = rmsle_cv(GBoost)\nprint(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))","407fb6c5":"model_lasso=Lasso.fit(train.values,y_train)\nElastic_model=Elastic.fit(train.values,y_train)\nRidge_model=Ridge.fit(train.values,y_train)\nGBoost_model=GBoost.fit(train.values,y_train)","e31a2305":"Model=(np.expm1(model_lasso.predict(test.values)) + np.expm1(Elastic_model.predict(test.values))\n           + np.expm1(Ridge_model.predict(test.values)) + np.expm1(GBoost_model.predict(test.values)))\/4\nModel","f0ff47ab":"submission = pd.DataFrame()\nsubmission['Id']=test_ID\nsubmission['SalePrice']=Model\nsubmission.to_csv('submission.csv',index=False)","d742c8f2":"## Exploring Relationship","af6c731d":"## Averaging Models","b478ac83":"### Train Test Split","ff5ddc4e":"# Advanced Regression Techniques\n\nIn this project we are going to predict the house prices based on a number of features \n\n\n### We will be performing:\n\n1.Data Analysis\n\n2.Feature Engineering\n\n3.Feature Selection\n\n4.Model Building\n\n5.Model Deployment","b06fc516":"## Getting dummies","9b4aaef7":"## Correlation matrix (heatmap)","77ff48cc":"## Lets start by importing libraries","f064b553":"### \"First things first\"\nAnalyzing the dependent feature (SalesPrice)","8e3c3fdf":"## Modelling ","05f285db":"## Finally we need to deal with skewed data","cf105ed5":"# Handling Missing Data\n\nIn statistics, missing data, or missing values, occur when no data value is stored for the variable in an observation. Missing data are a common occurrence and can have a significant effect on the conclusions that can be drawn from the data. Missing data can occur because of nonresponse: no information is provided for one or more items or for a whole unit.\n\nHow do you address that lost data?\n\n###### First, determine the pattern of your missing data. There are three types of missing data:\n\nMissing Completely at Random:  There is no pattern in the missing data on any variables. This is the best you can hope for.\n\nMissing at Random: There is a pattern in the missing data but not on your primary dependent variables such as likelihood to recommend or SUS Scores.\n\nMissing Not at Random: There is a pattern in the missing data that affect your primary dependent variables. For example, lower-income participants are less likely to respond and thus affect your conclusions about income and likelihood to recommend. Missing not at random is your worst-case scenario. Proceed with caution.\n\n###### What  is Imputation?\nImputation is replacing missing values with substitute values.","c23f7041":"#### Imputing missing values for numerical columns","9205e38a":"#### What Are Transformations?\n\nTransforming data means performing the same mathematical operation on each piece of original data. Some transformation examples from daily life are currency exchange rates (e.g., U.S. dollar into Euros) and converting degree Celsius into degree Fahrenheit.","009cf8d3":"### If you like my work, please do upvote and leave a comment if any suggestions to improve my model","9130e26d":"### Quest for nomalization\n\nApplying log transformation","a5bfb402":"## Some more EDA\n\n#### Let's have a look at the following\n\n1. Categorical variables\n2. Numerical variables\n","56a2e864":"# Exploratory data Analysis\n\nWe will be exploring to look for:\n\n1.Missing Values\n\n2.All The Numerical Variables\n\n3.Categorical Variables\n\n4.Outliers\n\n5.Relationship between independent and dependent feature(SalePrice)","323ffb6d":"### Quick Note:\n\nOutlier removal is not always safe as it hampers the accuracy. So, I won't be doing it\n\nFeel free to try it out if you wish to","c241e07d":"# Let's get down to some Feature Engineering\n\nLets concatenate the train and test data to save some time ","435dae14":"At the first glance we can observe that the feature is:\n\n1. Right\/Positive Skewed\n\n2. Deviated from the normal distribution","03bf91ee":"### Let's check the correation of the independent features w.r.t dependent feature","b45c07ae":"###### What is the Box-Cox Power Transformation?\n\nThe statisticians George Box and David Cox developed a procedure to identify an appropriate exponent (Lambda = l) to use to transform data into a \u201cnormal shape.\u201d The Lambda value indicates the power to which all data should be raised. In order to do this, the Box-Cox power transformation searches from Lambda = -5 to Lamba = +5 until the best value is found.","c0852b86":"# Hunting down the Outliers\n\nLet's plot the top 5 correlated feature to analze the outliers","b56fa317":"#### Imputing missing values for categorical columns","9cbe5eaa":"### Lets meet the data\n\nWe will be importing the dataset. I highly recommend to go through the \ndescription file for better understanding of the columns\n\n##### Here is a quick overview of each feature for people in a hurry\n\nSalePrice - This is the target variable\/dependent variable that you're trying to predict.\n\nMSSubClass: The building class\n\nMSZoning: The general zoning classification\n\nLotFrontage: Linear feet of street connected to property\n\nLotArea: Lot size in square feet\n\nStreet: Type of road access\n\nAlley: Type of alley access\n\nLotShape: General shape of property\n\nLandContour: Flatness of the property\n\nUtilities: Type of utilities available\n\nLotConfig: Lot configuration\n\nLandSlope: Slope of property\n\nNeighborhood: Physical locations within Ames city limits\n\nCondition1: Proximity to main road or railroad\n\nCondition2: Proximity to main road or railroad (if a second is present)\n\nBldgType: Type of dwelling\n\nHouseStyle: Style of dwelling\n\nOverallQual: Overall material and finish quality\n\nOverallCond: Overall condition rating\n\nYearBuilt: Original construction date\n\nYearRemodAdd: Remodel date\n\nRoofStyle: Type of roof\n\nRoofMatl: Roof material\n\nExterior1st: Exterior covering on house\n\nExterior2nd: Exterior covering on house (if more than one material)\n\nMasVnrType: Masonry veneer type\n\nMasVnrArea: Masonry veneer area in square feet\n\nExterQual: Exterior material quality\n\nExterCond: Present condition of the material on the exterior\n\nFoundation: Type of foundation\n\nBsmtQual: Height of the basement\n\nBsmtCond: General condition of the basement\n\nBsmtExposure: Walkout or garden level basement walls\n\nBsmtFinType1: Quality of basement finished area\n\nBsmtFinSF1: Type 1 finished square feet\n\nBsmtFinType2: Quality of second finished area (if present)\n\nBsmtFinSF2: Type 2 finished square feet\n\nBsmtUnfSF: Unfinished square feet of basement area\n\nTotalBsmtSF: Total square feet of basement area\n\nHeating: Type of heating\n\nHeatingQC: Heating quality and condition\n\nCentralAir: Central air conditioning\n\nElectrical: Electrical system\n\n1stFlrSF: First Floor square feet\n\n2ndFlrSF: Second floor square feet\n\nLowQualFinSF: Low quality finished square feet (all floors)\n\nGrLivArea: Above grade (ground) living area square feet\n\nBsmtFullBath: Basement full bathrooms\n\nBsmtHalfBath: Basement half bathrooms\n\nFullBath: Full bathrooms above grade\n\nHalfBath: Half baths above grade\n\nBedroom: Number of bedrooms above basement level\n\nKitchen: Number of kitchens\n\nKitchenQual: Kitchen quality\n\nTotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n\nFunctional: Home functionality rating Fireplaces: Number of fireplaces\n\nFireplaceQu: Fireplace quality\n\nGarageType: Garage location\n\nGarageYrBlt: Year garage was built\n\nGarageFinish: Interior finish of the garage\n\nGarageCars: Size of garage in car capacity\n\nGarageArea: Size of garage in square feet\n\nGarageQual: Garage quality\n\nGarageCond: Garage condition\n\nPavedDrive: Paved driveway\n\nWoodDeckSF: Wood deck area in square feet\n\nOpenPorchSF: Open porch area in square feet\n\nEnclosedPorch: Enclosed porch area in square feet\n\n3SsnPorch: Three season porch area in square feet\n\nScreenPorch: Screen porch area in square feet\n\nPoolArea: Pool area in square feet\n\nPoolQC: Pool quality\n\nFence: Fence quality\n\nMiscFeature: Miscellaneous feature not covered in other categories\n\nMiscVal: $Value of miscellaneous feature\n\nMoSold: Month Sold\n\nYrSold: Year Sold\n\nSaleType: Type of sale\n\nSaleCondition: Condition of sale"}}