{"cell_type":{"19d19902":"code","42e62d9b":"code","dfa32cde":"code","4192a6a2":"code","9cff8cc4":"code","7426541a":"code","35cfc2d3":"code","c055b6c0":"code","f4ff5bd1":"code","973a84f1":"code","793f7d8f":"code","c3ce6d70":"code","cc85f6e0":"code","26bf29a1":"code","cfc0b0f3":"code","a152b2a0":"code","78326ddb":"code","a5bf84c8":"code","3ba7530a":"code","dfb2e312":"code","7552936a":"code","bcf059fc":"code","6bc502d7":"code","635ccee2":"code","6ebcc5b1":"code","644f6549":"code","b9825457":"code","d76f0d83":"code","d385d18c":"code","499334bb":"code","b3e91c1b":"code","b09074a1":"code","ad2fb7fe":"code","a042aea5":"code","82cb8cff":"code","c188180e":"code","47761946":"code","b3e08375":"code","b1cc0abf":"code","e25a49b7":"code","a6e1f684":"code","bc9573c0":"code","3a8be61b":"code","2f782f45":"code","f640c23d":"markdown","82a90404":"markdown","42ffe97f":"markdown","d2cddd32":"markdown","29a12d3b":"markdown","5d1190fa":"markdown","7a110fbd":"markdown","f48b7f27":"markdown","0f966a3f":"markdown","8654107c":"markdown","49398782":"markdown","3dfc339a":"markdown","bb915f43":"markdown","a5f8b30d":"markdown","cca6d08c":"markdown","0b0cba44":"markdown","5b5f2e76":"markdown","a32e6a94":"markdown","0be314e5":"markdown","5cdd9d89":"markdown","b6c3fcad":"markdown","c3c5af07":"markdown","f1ce207c":"markdown","1704821a":"markdown"},"source":{"19d19902":"import warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as mpp \nimport seaborn as sb","42e62d9b":"# Read data from input\nsurvey = pd.read_csv('..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv')\n# Copy data without first column.\nsurvey = survey.iloc[1:, :]","dfa32cde":"# Show first five rows in dataframe.\nsurvey.head(2)","4192a6a2":"# Show data types in dataframe.\nsurvey.dtypes.value_counts()","9cff8cc4":"# Calculate the number of missing data in each column.\nnulls = survey.isnull().sum()\n# Calculate the percentage of missing data in each column.\npercentage = (nulls \/ survey.shape[0]) * 100\n# Show the missing data as DataFrame.\nnans_in_survey = pd.DataFrame({'NaN in Column':nulls, 'Percent Nan %':percentage}).astype('int64')\nnans_in_survey","7426541a":"# Show each column and its content.\nfor col in survey.iloc[:, 1:]:\n    print(f'{col} ---> {survey[col].unique()} \\n')","35cfc2d3":"# Create Serise that contents Age Column and number each category then sort it.\nage_data = survey['Q1'].value_counts().sort_index()","c055b6c0":"# Show the percentage for each category in Age column.\nage_data\/age_data.sum() * 100","f4ff5bd1":"# Show Categories of Age as bars char.\nfig, ax = mpp.subplots(1, 1, figsize=(16, 8))\nax.bar(age_data.index, age_data, width=0.6, edgecolor='#aaaaaa', color='#dddddd')\n# Set annotate on the bars.\nfor i in age_data.index:\n    ax.annotate(f'{age_data[i]}', xy=(i, age_data[i] + 100), va='center', ha='center', color='#222')\n# Remove the borders.\nfor b in ['top', 'left', 'right']:\n    ax.spines[b].set_visible(False)\n# Set lims and labels on axises.\nax.set_ylim(0, age_data.max()+(age_data.max()\/10))\nax.set_xticklabels(age_data.index)\nax.set_yticklabels(np.arange(0, age_data.max() + 499, 500))\n# Set text on figure.\nfig.text(0.1, 0.9, 'Q1 Age', fontsize=28, fontweight='bold', fontfamily='serif')\n# Display the grid as horizontal lines only.\nax.grid(axis='y', color='#a7a7a7', alpha=.36)\nmpp.show()","973a84f1":"# Set all values that other than Max and Women to Other.\nsurvey['Q2'][(survey['Q2'] != 'Man') & (survey['Q2'] != 'Woman')] = 'Other'","793f7d8f":"# Group Data by depending on Age and Gender then Show numbers of men,women and others for each age category.\n# T attr is transpose (index to columns and columns to index).\ngender_age = survey.groupby(['Q2'])['Q1'].value_counts().unstack().sort_index().T\ngender_age","c3ce6d70":"gender_age.sum() \/ survey.shape[0] * 100","cc85f6e0":"fig, ax = mpp.subplots(1, 1, figsize=(16, 8))\nax.bar(gender_age.index, gender_age['Man'], width=0.4, edgecolor='blue', color='blue')\nax.bar(gender_age.index, -gender_age['Woman'], width=0.4, edgecolor='red', color='red')\n# Set annotate to Man bars.\nfor i in gender_age.index:\n    ax.annotate(f\"{gender_age['Man'][i]}\", \n                   xy=(i, gender_age['Man'][i] + 100),\n                   va = 'center', ha='center',fontweight='light', fontfamily='serif',\n                   color='#333')\n# Set annotate to Women bars.\nfor i in gender_age['Woman'].index:\n    ax.annotate(f\"{gender_age['Woman'][i]}\", \n                   xy=(i, -gender_age['Woman'][i] - 100),\n                   va = 'center', ha='center',fontweight='light', fontfamily='serif',\n                   color='#333') \n# Remove the borders.\nfor b in ['top', 'left', 'bottom', 'right']:\n    ax.spines[b].set_visible(False)\n\nax.set_xticklabels(gender_age.index)\nax.set_yticks([])\n\nfig.text(0.1, 0.9, 'Age \/ Gender', fontsize=28, fontweight='bold', fontfamily='serif')\n\nax.grid(axis='y', color='#a7a7a7', alpha=.3)\n\nmpp.show()","26bf29a1":"gender_country = survey.groupby(['Q2', 'Q3'])['Q3'].count().unstack().T.fillna(0).astype('int64')","cfc0b0f3":"gender_country.head()","a152b2a0":"# Create function to splite dataframe to subdataframes\ndef split_dataframe(data, parts=None, chunks=None):\n    \"\"\"parts arg is the number of parts to be partitioned data into,\n       chunks is the size of each piece of data, that is, the number of lines in each segment\"\"\"\n    data_list = []\n    if parts == None:\n        if chunks == None:\n            raise('ValueError : \\'parts\\' and \\'chunks\\' are None')\n        else:\n            if type(chunks) != int:\n                raise('ValueError : type of \\'chunks\\' must be integer, but it \\'%s\\''%type(chunks))\n            else:\n                rows   = data.shape[0]\n                n_part = chunks\n                start  = 0\n                stop   = chunks\n                for i in range(0, parts):\n                    subdata = data.iloc[start:stop, :]\n                    data_list.append(subdata)\n                    start += n_part\n                    stop  += n_part\n                return data_list\n    else:\n        if type(parts) != int:\n            raise('ValueError : type of \\'parts\\' must be integer, but it \\'%s\\''%type(parts))\n        else:\n            rows   = data.shape[0]\n            n_part = int(np.ceil(rows\/parts))\n            start  = 0\n            stop   = n_part\n            for i in range(0, parts):\n                subdata = data.iloc[start:stop, :]\n                data_list.append(subdata)\n                start += n_part\n                stop  += n_part\n            return data_list","78326ddb":"gender_country = gender_country.sort_values('Man', ascending=False)\ndf_list        = split_dataframe(gender_country, parts=8)\nndx            = [x.index for x in df_list]","a5bf84c8":"fig, ax = mpp.subplots(8, 1, figsize=(10, 18), constrained_layout=True)\n# ax return array contents subplots try printing it.\nfor i in range(len(df_list)):\n    ax[i].bar(ndx[i], df_list[i]['Man'], color='blue', width=0.2, align='center')\n    ax[i].bar(ndx[i], df_list[i]['Woman'], color='red', width=0.2, align='center')\n    ax[i].bar(ndx[i], df_list[i]['Other'], color='yellow', width=0.2, align='center')\n\nmpp.show()","3ba7530a":"edu_data = survey['Q4'].value_counts()","dfb2e312":"bars_num = edu_data.shape[0]\ncolor_map = sb.color_palette('Greens_r', bars_num)\nfig, ax = mpp.subplots(1, 1, figsize=(16, 8))\nax.bar(edu_data.index, edu_data, color=color_map, width=0.45)\n\nfor i in edu_data.index:\n    ax.annotate(f'{edu_data[i]}', xy=(i, edu_data[i]+120), va='center', ha='center', color='#222')\n\nfor b in ['top', 'left', 'right']:\n    ax.spines[b].set_visible(False)\n\nax.set_xticklabels(edu_data.index, rotation=90)\nax.set_yticks([])\nfig.text(0.1, 0.9, 'Education', fontsize=28, fontweight='bold', fontfamily='serif')\nmpp.show()","7552936a":"cols  = survey.loc[:, 'Q7_Part_1':'Q9_OTHER'].columns\ntotal = survey.shape[0]\nNdx   = []\nCnt   = []\nPcn   = []\nfor col in cols:\n    s = survey[col].value_counts()\n    Ndx.append(s.index[0])\n    Cnt.append(s[0])\n    Pcn.append(round((s[0]\/total)*100, 2))\n    #print(f'{s.index[0]} \\n{s[0]} \\n{round((s[0]\/total)*100, 2)}% \\n')\nlang_stc = pd.DataFrame({'Counts':Cnt[:13], 'Percentage':Pcn[:13]}, index=Ndx[:13])\nlang_stc","bcf059fc":"fig, ax   = mpp.subplots(1, 1, figsize=(12, 8))\nbars_num  = lang_stc.shape[0]\ncolor_map = sb.color_palette('hls', bars_num)\nlang_stc  = lang_stc.drop('None', axis=0)\nax.bar(lang_stc.index, lang_stc['Counts'], color=color_map)\n\nfor i in lang_stc.index:\n    ax.annotate(f\"{lang_stc.at[i, 'Counts']}\", xy=(i, lang_stc.at[i, 'Counts']+200), va='center', ha='center', \n                color='#222')\n\nfor b in ['top', 'left', 'right']:\n    ax.spines[b].set_visible(False)\n\nax.set_yticks([])\nfig.text(0.1, 0.9, 'Languages Users', fontsize=28, fontweight='bold', fontfamily='serif')\nmpp.show()","6bc502d7":"ide_stc = pd.DataFrame({'Counts':Cnt[14:], 'Percentage':Pcn[14:]}, index=Ndx[14:])\nide_stc","635ccee2":"fig, ax   = mpp.subplots(1, 1, figsize=(12, 8))\nbars_num  = lang_stc.shape[0]\ncolor_map = sb.color_palette('tab10')\nide_stc   = ide_stc.drop('None', axis=0)\n\nax.bar(ide_stc.index, ide_stc['Counts'], color=color_map)\nax.set_yticks([])\nax.set_xticklabels(ide_stc.index, rotation=90)\n\nfor i in ide_stc.index:\n    ax.annotate(f\"{ide_stc.at[i, 'Counts']}\", xy=(i, ide_stc.at[i, 'Counts']+200), va='center', ha='center', color='#222')\n\nfor b in ['top', 'left', 'right']:\n    ax.spines[b].set_visible(False)\n\nfig.text(0.1, 0.9, 'IDEs Users', fontsize=28)\nmpp.show()","6ebcc5b1":"new_cols = list(lang_stc.index[:]) + list(ide_stc.index)\nnew_cols = [col.strip() for col in new_cols]\nnew_cols = list(filter(lambda x : x != 'None', new_cols))\nnew_cols[21] = 'MATLAB_IDE'\nnew_cols[11] = \"Other_Lng\"\nnew_cols[-1] = \"Other_IDE\"","644f6549":"new_survey = survey.loc[:, 'Q7_Part_1':'Q9_OTHER']\nnew_survey.drop(['Q7_Part_12', 'Q8', 'Q9_Part_11'], axis=1, inplace=True)","b9825457":"langs_ides = new_survey.set_axis(new_cols, axis=1)","d76f0d83":"langs_ides.fillna(0, inplace=True)","d385d18c":"def strip_value(value):\n    try:\n        return value.strip()\n    except:\n        return 0","499334bb":"langs_ides = langs_ides.applymap(strip_value)","b3e91c1b":"langs_ides['Other_Lng'][langs_ides['Other_Lng'] == 'Other']    = \"Other_Lng\"\nlangs_ides['MATLAB_IDE'][langs_ides['MATLAB_IDE'] == 'MATLAB'] = \"MATLAB_IDE\"\nlangs_ides['Other_IDE'][langs_ides['Other_IDE'] == 'Other']    = \"Other_IDE\"","b09074a1":"#Check\n#langs_ides.isna().sum()","ad2fb7fe":"for col in langs_ides.columns:\n    langs_ides[col] = langs_ides[col].map({col:1, 0:0})","a042aea5":"langs_ides.head()","82cb8cff":"langs_ides_corr = langs_ides.corr()","c188180e":"fig, ax = mpp.subplots(figsize=(16, 12))\n\nsb.heatmap(langs_ides_corr, cmap='rocket', annot=True, fmt='.2f', cbar=False)\n\nfig.text(0.1, 0.9, 'IDEs-Languages Correlation', fontsize=28, fontfamily='serif')\nmpp.show()","47761946":"platforms  = survey['Q11'].fillna('None')","b3e08375":"platforms_perc = round((platforms.value_counts() \/ len(platforms)) * 100, 2)\nplatforms_perc","b1cc0abf":"fig, ax = mpp.subplots(1, 1, figsize=(8, 8))\nlabels  = platforms_perc.index\nsizes   = platforms_perc.values\nexplode = [0]*len(labels)\n\nwedges, texts, autotexts = ax.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\nmpp.legend(wedges, labels, title=\"Platforms\", loc=[0.5, 0.0], bbox_to_anchor=(1, 0, 0.5, 1))\nfig.text(0.1, 0.9, 'Platforms', fontsize=28, fontfamily='serif')\nax.axis('equal')\nmpp.show()","e25a49b7":"experience          = survey[['Q6', 'Q15']].set_axis(['Code Experience', 'ML Experience'], axis=1)\nexperience['Count'] = 1\ncode_experience     = survey['Q6']\nml_experience       = survey['Q15']","a6e1f684":"code_experience_perc = round((code_experience.value_counts() \/ len(code_experience)) * 100, 2)\ncode_experience_perc","bc9573c0":"ml_experience_perc = round((ml_experience.value_counts() \/ len(ml_experience)) * 100, 2)\nml_experience_perc","3a8be61b":"pivot_experience = pd.pivot_table(experience, values='Count', columns=['ML Experience'], index=['Code Experience'], \n                                  aggfunc=np.sum)\npivot_experience = pivot_experience.fillna(0).astype('int64')","2f782f45":"fig, ax = mpp.subplots(1, 1, figsize=(16, 10))\n\nsb.heatmap(pivot_experience, cmap='icefire', annot=True, fmt='d', square=True, cbar=False, linewidths=1.4)\n\nax.spines['top'].set_visible(True)\nax.set_yticklabels(ax.get_yticklabels(), fontfamily='serif', rotation = 0, fontsize=11)\nax.set_xticklabels(ax.get_xticklabels(), fontfamily='serif', rotation=90, fontsize=11)\n\nfig.text(0.48, 1, 'ML EXperience & Code Experience', fontweight='bold', fontfamily='serif', fontsize=22)   \n\nmpp.tight_layout()\nmpp.show()","f640c23d":"<p style=\"font-size:42px;color:#fff;background-color:lime;height:60px;line-height:60px;text-align:center;padding 5px 0;\"> Q7-Languages \/ Q9-IDEs <\/p>","82a90404":"<p style=\"font-size:42px;color:#fff;background-color:lime;height:60px;line-height:60px;text-align:center;padding 5px 0;\"> Q1-Age \/ Q2-Gender <\/p>","42ffe97f":"<h2 style=\"color:#fff;background-color:blue;padding:5px;text-align;left;\">Total Experience<\/h2>","d2cddd32":"<div style=\"background-color:#9c9c9c;color:#fff;padding:6px;\">\n<p style=\"font-size:42px;color:#fff;background-color:red;height:60px;line-height:60px;text-align:center;padding 5px 0;\"> Kaggle Survey 2020 <\/p>\n<p style=\"border:1px solid #fff;\"><\/p>\n\n* Q1: What is your age (# years)?\n* Q2: What is your gender?\n* Q3: In which country do you currently reside?\n* Q4: What is the highest level of formal education that you have attained or plan to attain within the next 2 years?\n* Q5: Select the title most similar to your current role (or most recent title if retired)\n* Q6: For how many years have you been writing code and\/or programming?\n* Q7: What programming languages do you use on a regular basis?\n* Q8: What programming language would you recommend an aspiring data scientist to learn first?\n* Q9: Which of the following integrated development environments (IDE's) do you use on a regular basis?\n* Q10: Which of the following hosted notebook products do you use on a regular basis?\n* Q11: What type of computing platform do you use most often for your data science projects?\n* Q12: Which types of specialized hardware do you use on a regular basis?\n* Q13: Approximately how many times have you used a TPU (tensor processing unit)?\n* Q14: What data visualization libraries or tools do you use on a regular basis?\n* Q15: For how many years have you used machine learning methods?\n* Q16: Which of the following machine learning frameworks do you use on a regular basis?\n* Q17: Which of the following ML algorithms do you use on a regular basis?\n* Q18: Which categories of computer vision methods do you use on a regular basis?\n* Q19: Which of the following natural language processing (NLP) methods do you use on a regular basis?\n* Q20: What is the size of the company where you are employed?\n* Q21: Approximately how many individuals are responsible for data science workloads at your place of business?\n* Q22: Does your current employer incorporate machine learning methods into their business?\n* Q23: Select any activities that make up an important part of your role at work:\n* Q24: What is your current yearly compensation ( approximate USD)?\n* Q25: Approximately how much money have you (or your team) spent on machine learning and\/or cloud computing services at home (or at work) in the past 5 years ( approximate USD )?\n* Q26: Which of the following cloud computing platforms do you use on a regular basis?\n* Q27: Do you use any of the following cloud computing products on a regular basis?\n* Q28: Do you use any of the following machine learning products on a regular basis?\n* Q29: Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis?\n* Q30: Which of the following big data products (relational database, data warehouse, data lake, or similar) do you use most often?\n* Q31: Which of the following business intelligence tools do you use on a regular basis?\n* Q32: Which of the following business intelligence tools do you use most often?\n* Q33: Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis?\n* Q34: Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?\n* Q35: Do you use any tools to help manage machine learning experiments?\n* Q36: Where do you publicly share or deploy your data analysis or machine learning applications?\n* Q37: On which platforms have you begun or completed data science courses?\n* Q38: What is the primary tool that you use at work or school to analyze data?\n* Q39: Who\/what are your favorite media sources that report on data science topics?\n    <\/div>","29a12d3b":"<h3 style=\"color:red;border-bottom:1px solid red;margin-bottom:5px;\">Note<\/h3>\nAs you can see, the largest category is 25-29, also, people between 18-34 make up 70% of the participants. The surprise is that there are 76 people who are over the age of 70 ... I did not expect that, and I do not know the validity of this data.","5d1190fa":"<h2 style=\"color:#fff;background-color:blue;padding:5px;text-align;left;\">Languages Users<\/h2>","7a110fbd":"<h3 style=\"color:red\"> Colormaps, attr 'cmap' Click Here <\/h3>\n<!--\n'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'icefire', 'icefire_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'mako', 'mako_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'rocket', 'rocket_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'twilight', 'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', 'vlag', 'vlag_r', 'winter', 'winter_r'\n-->","f48b7f27":"<h2 style=\"color:#fff;background-color:blue;padding:5px;text-align;left;\">IDEs Users<\/h2>","0f966a3f":"<p style=\"font-size:42px;color:#fff;background-color:lime;height:60px;line-height:60px;text-align:center;padding 5px 0;\"> Read Data <\/p>","8654107c":"<p style=\"font-size:42px;color:#fff;background-color:lime;height:60px;line-height:60px;text-align:center;padding 5px 0;\"> Q11-Platforms<\/p>","49398782":"<h3 style=\"color:red;border-bottom:1px solid red;margin-bottom:5px;\">Note<\/h3>\nAs expected, the percentage of men is greater than the percentage of women, with men constituting approximately 79%, women 19% and 2% unspecified. I believe that the Kaggle team should attract more women.\nAlso, there is a clear difference in the distribution of ages according to both genders, the largest concentration of men is between 24-29, while the largest grouping of women is between 22-24.","3dfc339a":"<p style=\"font-size:42px;color:#fff;background-color:lime;height:60px;line-height:60px;text-align:center;padding 5px 0;\"> Data Labels <\/p>","bb915f43":"<p style=\"font-size:42px;color:#fff;background-color:lime;height:60px;line-height:60px;text-align:center;padding 5px 0;\"> Import Packages <\/p>","a5f8b30d":"<p style=\"font-size:42px;color:#fff;background-color:lime;height:60px;line-height:60px;text-align:center;padding 5px 0;\"> Q6-Code Experience \/ Q15-ML Experience<\/p>","cca6d08c":"<h2 style=\"color:#fff;background-color:blue;padding:5px;text-align;left;\">Code Experience<\/h2>","0b0cba44":"# @Tarek Ghajary\n\n[GitHub](https:\/\/www.github.com\/CHESyrian)\n[FaceBook](https:\/\/www.facebook.com\/T94GH09)\n[Twitter](https:\/\/www.twitter.com\/Tarekgh15)\n[Instagrame](https:\/\/www.instagram.com\/chesyrian)\n[CodePen](https:\/\/www.codepen.com\/tarekghajary)\n","5b5f2e76":"<p style=\"font-size:42px;color:#fff;background-color:lime;height:60px;line-height:60px;text-align:center;padding 5px 0;\"> Missisng Data <\/p>","a32e6a94":"<h2 style=\"color:#fff;background-color:blue;padding:5px;text-align;left;\">Languages & IDEs Users<\/h2>","0be314e5":"<h2 style=\"color:#fff;background-color:blue;padding:5px;text-align;left;\">ML Experience<\/h2>","5cdd9d89":"<h1 style=\"color:green;\">TO BE CONTINUED...<\/h1>","b6c3fcad":"<h3 style=\"color:red;border-bottom:1px solid red;margin-bottom:5px;\">Note<\/h3>\nFirst of all, I think Kaggle is giving gifts to my Indian friends or that they enjoy taking surveys. India topped the survey with 4,491 participants, far more than its closest competitor, USA. <br\/>\nSecond, 58% of the participants are concentrated in 6 countries (India, USA, Brazil, Japan, Russia, Nigeria). <br\/>\nThird, unfortunately, no country has more women than men participating. <br\/>\nFinally, I am worried that there are no Syrians among the participants. I am afraid that I will be the only one here. <br\/>\n((By the way, Kaggle is banned in Syria and we are using VPN to enter. Perhaps we are participating in sutvies under the name of India -_o.))","c3c5af07":"<p style=\"font-size:42px;color:#fff;background-color:lime;height:60px;line-height:60px;text-align:center;padding 5px 0;\"> Q2-Gender \/ Q3-Country <\/p>","f1ce207c":"<p style=\"font-size:42px;color:#fff;background-color:lime;height:60px;line-height:60px;text-align:center;padding 5px 0;\"> Q1-Age <\/p>","1704821a":"<p style=\"font-size:42px;color:#fff;background-color:lime;height:60px;line-height:60px;text-align:center;padding 5px 0;\"> Q4-Education <\/p>"}}