{"cell_type":{"c3b41697":"code","86ceb95d":"code","d838fd32":"code","5e366368":"code","1d1613ff":"code","e8f617b2":"code","02c2c43a":"code","ee9e6d6f":"code","75e9d6a2":"code","9203bcf6":"code","0fb9bdae":"code","4449b02b":"code","16ccd19a":"code","929fc8ef":"code","fb1c285a":"code","6f5aeb56":"code","4ae9c87e":"code","534aa565":"code","71bf363c":"code","821a5f16":"code","24070c01":"code","06c6c1d2":"code","dceb1e7d":"code","5ad1bf65":"code","b93c92b6":"code","27f1ea4d":"code","4d35037c":"code","9b18af9b":"code","41971d3f":"code","7c92fae5":"code","27494431":"code","eea1d56f":"code","0413f635":"code","38e8bd19":"code","d120a366":"code","15ca3e39":"code","70d7ccd8":"code","0ed869cc":"code","ce90528f":"code","8fb5bdf1":"code","14f08e05":"code","3e15f14d":"code","64ab084a":"code","431b5f73":"code","ad5ad29a":"code","b81368d6":"code","ce9cacf4":"code","b750f2cd":"code","2387c0ea":"code","3e79e8b0":"code","25d15cbe":"code","1802cf6a":"code","10367319":"code","197d8e7b":"code","4ff652ed":"code","f175bbb3":"code","3f0e6613":"code","c80b1656":"code","2bc71d34":"code","c4123ffb":"code","36506824":"code","279946d4":"code","d39fe7e5":"code","0787605d":"code","0e256126":"code","d2bd4603":"code","c59671b5":"code","3537be44":"code","0da1e80f":"code","260eb68a":"code","c189eaa2":"code","c5097123":"code","2afdbed3":"code","f219345c":"code","b90b5324":"code","292529a4":"code","6a28916c":"code","8dee592e":"code","14fdb42b":"code","d4f59ada":"code","3940a279":"code","44ebe3ab":"code","6cae4616":"code","e560afeb":"code","4f054806":"code","dab7d57c":"code","312b96be":"markdown","a0a113a1":"markdown","6f95bdcf":"markdown"},"source":{"c3b41697":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","86ceb95d":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","d838fd32":"!pip install xlrd","5e366368":"train_data=pd.read_excel('\/kaggle\/input\/flight-fare-prediction-mh\/Data_Train.xlsx')","1d1613ff":"!pip install openpyxl","e8f617b2":"train_data=pd.read_excel('\/kaggle\/input\/flight-fare-prediction-mh\/Data_Train.xlsx')","02c2c43a":"pd.set_option('display.max_columns',None)","ee9e6d6f":"train_data.head()","75e9d6a2":"train_data.info()","9203bcf6":"train_data.isnull().sum()","0fb9bdae":"train_data[\"Duration\"].value_counts()","4449b02b":"train_data[\"Duration\"].nunique()","16ccd19a":"train_data.dropna(inplace=True) #Route and total stops have null values which has been dropped","929fc8ef":"train_data.isnull().sum()","fb1c285a":"train_data.shape","6f5aeb56":"train_data[\"Journey_day\"]=pd.to_datetime(train_data.Date_of_Journey, format=\"%d\/%m\/%Y\").dt.day","4ae9c87e":"train_data[\"Journey_month\"]=pd.to_datetime(train_data.Date_of_Journey, format=\"%d\/%m\/%Y\").dt.month","534aa565":"train_data.head()","71bf363c":"train_data.drop([\"Date_of_Journey\"],axis=1,inplace=True)","821a5f16":"train_data[\"Dep_hour\"]=pd.to_datetime(train_data.Dep_Time).dt.hour\ntrain_data[\"Dep_min\"]=pd.to_datetime(train_data.Dep_Time).dt.minute\ntrain_data.drop([\"Dep_Time\"],axis=1,inplace=True)","24070c01":"train_data.head()","06c6c1d2":"train_data[\"Arrival_hour\"]=pd.to_datetime(train_data.Arrival_Time).dt.hour\ntrain_data[\"Arrival_min\"]=pd.to_datetime(train_data.Arrival_Time).dt.minute\ntrain_data.drop([\"Arrival_Time\"],axis=1,inplace=True)","dceb1e7d":"train_data.head()","5ad1bf65":"#Time taken by plane to reach destination is duration\n#It is the difference between Departure and Arrival time\n\n#Assigning and converting duration column into list\nduration=list(train_data[\"Duration\"])\n\nfor i in range(len(duration)):\n    if len(duration[i].split()) != 2:  #checks if duration contains only hours and minutes\n        if \"h\" in duration[i]:\n            duration[i]=duration[i].strip() + \" 0m\"  #Adds 0 minute\n        else:\n            duration[i]=\"0h \" + duration[i]          #Adds 0 hour\n\nduration_hours=[]\nduration_mins=[]\nfor i in range(len(duration)):\n    duration_hours.append(int(duration[i].split(sep=\"h\")[0]))            #Extract hours from duration\n    duration_mins.append(int(duration[i].split(sep=\"m\")[0].split()[-1])) #Extract min only fromduration","b93c92b6":"train_data[\"Duration_hours\"]=duration_hours\ntrain_data[\"Duration_mins\"]=duration_mins","27f1ea4d":"train_data.head()","4d35037c":"train_data.drop([\"Duration\"],axis=1,inplace=True)","9b18af9b":"train_data.head()","41971d3f":"train_data[\"Airline\"].value_counts()","7c92fae5":"#Airline Vs Price\nsns.catplot(y=\"Price\",x=\"Airline\", data=train_data.sort_values(\"Price\", ascending=False),kind=\"boxen\",height=6,aspect=3)\nplt.show()\n","27494431":"#As airline is nominal categorical data we will go for one hot encoding\nAirline= train_data[[\"Airline\"]]\nAirline=pd.get_dummies(Airline,drop_first=False)\nAirline.head()","eea1d56f":"Airline.shape","0413f635":"Airline= train_data[[\"Airline\"]]\nAirline=pd.get_dummies(Airline,drop_first=True) #drop_first=True makes us drop main column after getting \nAirline.head()                                  #dummies from that column","38e8bd19":"Airline.shape","d120a366":"train_data[\"Source\"].value_counts()","15ca3e39":"#Source Vs Price\nsns.catplot(y=\"Price\",x=\"Source\", data=train_data.sort_values(\"Price\", ascending=False),kind=\"boxen\",height=6,aspect=3)\nplt.show()","70d7ccd8":"#As Source is nominal categorical data we will go for one hot encoding\nSource= train_data[[\"Source\"]]\nSource=pd.get_dummies(Source,drop_first=True)\nSource.head()","0ed869cc":"train_data[\"Destination\"].value_counts()","ce90528f":"#As Destination is nominal categorical data we will go for one hot encoding\nDestination= train_data[[\"Destination\"]]\nDestination=pd.get_dummies(Destination,drop_first=True)\nDestination.head()","8fb5bdf1":"train_data[\"Route\"]","14f08e05":"#Additional_info has almost 80% no information\n#Route and total stops are related to each other\ntrain_data.drop([\"Route\",\"Additional_Info\"],axis=1, inplace=True)","3e15f14d":"train_data[\"Total_Stops\"].value_counts()","64ab084a":"#As this is ordinal category type we perform Label Encoder\n#Values are assigned with corresponding keys\ntrain_data.replace({\"non-stop\":0,\"1 stop\":1,\"2 stops\":2,\"3 stops\":3,\"4 stops\":4},inplace=True)","431b5f73":"train_data.head()","ad5ad29a":"#Concatenate dataframe--> train_data,Airline,Source,Destination\ndata_train=pd.concat([train_data,Airline,Source,Destination],axis=1)","b81368d6":"data_train.head()","ce9cacf4":"data_train.drop([\"Airline\",\"Source\",\"Destination\"],axis=1,inplace=True)","b750f2cd":"data_train.head()","2387c0ea":"data_train.shape","3e79e8b0":"test_data=pd.read_excel('\/kaggle\/input\/flight-fare-prediction-mh\/Test_set.xlsx')","25d15cbe":"test_data.head()","1802cf6a":"#Preprocessing\nprint(train_data.info())\nprint(train_data.isnull().sum())\n\ntest_data.dropna(inplace=True)\nprint(train_data.isnull().sum())\n\n#EDA\n\ntest_data[\"Journey_day\"]=pd.to_datetime(test_data.Date_of_Journey, format=\"%d\/%m\/%Y\").dt.day\ntest_data[\"Journey_month\"]=pd.to_datetime(test_data.Date_of_Journey, format=\"%d\/%m\/%Y\").dt.month\ntest_data.drop([\"Date_of_Journey\"],axis=1,inplace=True)\n\ntest_data[\"Dep_hour\"]=pd.to_datetime(test_data.Dep_Time).dt.hour\ntest_data[\"Dep_min\"]=pd.to_datetime(test_data.Dep_Time).dt.minute\ntest_data.drop([\"Dep_Time\"],axis=1,inplace=True)\n\ntest_data[\"Arrival_hour\"]=pd.to_datetime(test_data.Arrival_Time).dt.hour\ntest_data[\"Arrival_min\"]=pd.to_datetime(test_data.Arrival_Time).dt.minute\ntest_data.drop([\"Arrival_Time\"],axis=1,inplace=True)\n\n#Time taken by plane to reach destination is duration\n#It is the difference between Departure and Arrival time\n\n#Assigning and converting duration column into list\nduration=list(test_data[\"Duration\"])\n\nfor i in range(len(duration)):\n    if len(duration[i].split()) != 2:  #checks if duration contains only hours and minutes\n        if \"h\" in duration[i]:\n            duration[i]=duration[i].strip() + \" 0m\"  #Adds 0 minute\n        else:\n            duration[i]=\"0h \" + duration[i]          #Adds 0 hour\n\nduration_hours=[]\nduration_mins=[]\nfor i in range(len(duration)):\n    duration_hours.append(int(duration[i].split(sep=\"h\")[0]))            #Extract hours from duration\n    duration_mins.append(int(duration[i].split(sep=\"m\")[0].split()[-1])) #Extract min only fromduration\n    \ntest_data[\"Duration_hours\"]=duration_hours\ntest_data[\"Duration_mins\"]=duration_mins\n\ntest_data.drop([\"Duration\"],axis=1,inplace=True)\n\n#As airline is nominal categorical data we will go for one hot encoding\nAirline= test_data[[\"Airline\"]]\nAirline=pd.get_dummies(Airline,drop_first=True)\nAirline.head()\n\n#As Source is nominal categorical data we will go for one hot encoding\nSource= test_data[[\"Source\"]]\nSource=pd.get_dummies(Source,drop_first=True)\nSource.head()\n\n#As Destination is nominal categorical data we will go for one hot encoding\nDestination= test_data[[\"Destination\"]]\nDestination=pd.get_dummies(Destination,drop_first=True)\nDestination.head()\n\n#Additional_info has almost 80% no information\n#Route and total stops are related to each other\ntest_data.drop([\"Route\",\"Additional_Info\"],axis=1, inplace=True)\n\n#As this is ordinal category type we perform Label Encoder\n#Values are assigned with corresponding keys\ntest_data.replace({\"non-stop\":0,\"1 stop\":1,\"2 stops\":2,\"3 stops\":3,\"4 stops\":4},inplace=True)\n\n#Concatenate dataframe--> train_data,Airline,Source,Destination\ndata_test=pd.concat([test_data,Airline,Source,Destination],axis=1)\n\ndata_test.drop([\"Airline\",\"Source\",\"Destination\"],axis=1,inplace=True)","10367319":"data_test.head()","197d8e7b":"data_test.shape","4ff652ed":"Feature Selection\nBest features which will contribute and will have best relation with target variable\nFollowing are best feature selection methods:-\n    1)Heatmap\n    2)feature_importance_\n    3)SelectKBest","f175bbb3":"data_train.shape","3f0e6613":"X=data_train.loc[:, ['Total_Stops','Journey_day','Journey_month','Dep_hour','Dep_min','Arrival_hour','Arrival_min','Duration_hours','Duration_mins','Airline_Air India','Airline_GoAir','Airline_IndiGo','Airline_Jet Airways','Airline_Jet Airways Business','Airline_Multiple carriers','Airline_Multiple carriers Premium economy','Airline_SpiceJet','Airline_Trujet','Airline_Vistara','Airline_Vistara Premium economy','Source_Chennai','Source_Delhi','Source_Kolkata','Source_Mumbai','Destination_Cochin','Destination_Delhi','Destination_Hyderabad','Destination_Kolkata','Destination_New Delhi']]\nX.head()","c80b1656":"y=data_train.iloc[:,1]\ny.head()","2bc71d34":"#Finds correlation between dependent and independent variables\nplt.figure(figsize=(18,18))\nsns.heatmap(data_train.corr(),annot=True,cmap=\"RdYlGn\")\nplt.show()","c4123ffb":"#Extract important features using ExtraTreesRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nselection=ExtraTreesRegressor()\nselection.fit(X,y)","36506824":"print(selection.feature_importances_)","279946d4":"#plot features_importances for better visualization\nplt.figure(figsize=(12,8))\nfeat_importance=pd.Series(selection.feature_importances_,index=X.columns)\nfeat_importance.nlargest(20).plot(kind='barh')\nplt.show()","d39fe7e5":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=101)","0787605d":"from sklearn.ensemble import RandomForestRegressor\nreg_rf=RandomForestRegressor()\nreg_rf.fit(X_train,y_train)","0e256126":"y_pred=reg_rf.predict(X_test)","d2bd4603":"reg_rf.score(X_train,y_train)","c59671b5":"reg_rf.score(X_test,y_test)","3537be44":"sns.distplot(y_test-y_pred)\nplt.show()","0da1e80f":"plt.scatter(y_test,y_pred,alpha=0.5)\nplt.xlabel(\"y_test\")\nplt.ylabel(\"y_pred\")\nplt.show()\n","260eb68a":"from sklearn import metrics","c189eaa2":"print('MAE:',metrics.mean_absolute_error(y_test,y_pred))\nprint('MSE:',metrics.mean_squared_error(y_test,y_pred))\nprint('RMSE:',np.sqrt(metrics.mean_squared_error(y_test,y_pred)))","c5097123":"metrics.r2_score(y_test,y_pred)","2afdbed3":"from sklearn.model_selection import RandomizedSearchCV","f219345c":"#Randomized Search CV\n#Number of trees in random forest\nn_estimators=[int(x) for x in np.linspace(start=100,stop=1200,num=12)]\n#No.of features to consider at every split\nmax_features=['auto','sqrt']\n#Maximum no.of levels in tree\nmax_depth=[int(x) for x in np.linspace(5,30,num=6)]\n#Minimum no.of samples required to split a node\nmin_samples_split=[2,5,10,15,100]\n#Minimum no. of samples required at each leaf node\nmin_samples_leaf=[1,2,5,10]\n","b90b5324":"#Create the Random grid\nrandom_grid={'n_estimators':n_estimators,\n            'max_features':max_features,\n            'max_depth':max_depth,\n            'min_samples_split':min_samples_split,\n            'min_samples_leaf':min_samples_leaf\n            }","292529a4":"#Random search of parameters using 5 fold cross fold validation,search across 100 different combination\nrf_random=RandomizedSearchCV(estimator=reg_rf,param_distributions=random_grid,scoring='neg_mean_squared_error',n_iter=10,cv=5,verbose=2,random_state=42,n_jobs=1)","6a28916c":"rf_random.fit(X_train,y_train)","8dee592e":"rf_random.best_params_","14fdb42b":"prediction=rf_random.predict(X_test)","d4f59ada":"plt.figure(figsize=(8,8))\nsns.distplot(y_test-prediction)\nplt.show()","3940a279":"plt.figure(figsize=(8,8))\nplt.scatter(y_test,prediction,alpha=0.5)\nplt.xlabel(\"y_test\")\nplt.ylabel(\"prediction\")\nplt.show()","44ebe3ab":"print('MAE:',metrics.mean_absolute_error(y_test,prediction))\nprint('MSE:',metrics.mean_squared_error(y_test,prediction))\nprint('RMSE:',np.sqrt(metrics.mean_squared_error(y_test,prediction)))","6cae4616":"import pickle\n#open afile where you want to store the data\nfile=open('flight_rf.pkl','wb')\n\n#dump information to that file\npickle.dump(rf_random,file)","e560afeb":"model=open('flight_rf.pkl','rb')\nforest=pickle.load(model)","4f054806":"y_prediction=forest.predict(X_test)","dab7d57c":"metrics.r2_score(y_test,y_prediction)","312b96be":"Fitting model using Random Forest\n1)Split data set into train and test set in order to do prediction w.r.t. X_test\n2)If needed do scaling of data.Scaling not needed in Random Forest\n3)Import model\n4)Fit the data\n5)Predict w.r.t X_test\n6)In regression check RMSE score\n7)Plot graph\n","a0a113a1":"Hyper parameter Tuning\n-Choose following methods:\n    1)RandomizedSearchCV -->fast\n    2)GridSearchCV\n-Assign hyperparameters in form of dictionary\n-Fit the model\n-Check best parameters and best score","6f95bdcf":"Save the model to reuse it again"}}