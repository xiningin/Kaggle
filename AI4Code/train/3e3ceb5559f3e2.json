{"cell_type":{"b308a9b9":"code","8b9e409f":"code","1beaefc5":"code","2b08bfb7":"code","44f2d760":"code","04cfde0e":"code","6f79dc0a":"code","a8a2d03f":"code","4d256378":"code","683235dd":"code","c6347b99":"code","cfc70340":"code","336e6aea":"code","7da0b477":"code","c5c4ff33":"code","e777a0e5":"code","7d8977fd":"code","717bf3df":"code","ebd9f1d6":"code","cd4d02d3":"code","78fa9b5f":"code","4e12e91a":"code","57b04e65":"code","cfcf67f4":"code","3353beb0":"code","f42e3215":"code","42bc13a1":"code","7bda8296":"code","d4fe2234":"code","b7be6e10":"code","3befd3d7":"code","782a751a":"code","9bccebb6":"code","ce84cad8":"code","04893b43":"code","89e4deb0":"code","f60fbff0":"code","fc02225f":"code","8feaf3d9":"code","9562f043":"code","713b63fc":"code","e4602247":"code","9d028426":"code","20065692":"code","97047105":"code","54f5cd14":"code","7a4a8de5":"code","12407818":"code","b22e2e5c":"code","a72212da":"code","3fbd4cf9":"code","3f5c28ec":"code","fdecea6b":"markdown","21b89aa4":"markdown","03da767f":"markdown","f074a947":"markdown","29125ef5":"markdown","4564a23e":"markdown","e9f32cfd":"markdown","e2808d53":"markdown","586940e5":"markdown"},"source":{"b308a9b9":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom math import sqrt\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport plotly.express as px\nimport plotly.io as pio \npio.templates.default = \"plotly_white\"\n\n#\n\n\nfrom scipy import interp\nimport math\nfrom scipy.stats import norm\nfrom scipy import stats\n\n#\n\nimport warnings\nwarnings.filterwarnings('ignore')\npd.options.display.max_columns = 50\n\n#\n\nfrom sklearn.model_selection import StratifiedShuffleSplit, KFold, GridSearchCV, RandomizedSearchCV\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error,make_scorer,r2_score\nfrom sklearn.inspection import plot_partial_dependence\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.model_selection import train_test_split,cross_val_score\n\nfrom sklearn.linear_model import Lasso, Ridge, SGDRegressor,LinearRegression,RidgeCV\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler,MinMaxScaler\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import Pipeline\nfrom xgboost import XGBRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.tree import ExtraTreeRegressor,DecisionTreeRegressor\nfrom sklearn.neural_network import MLPRegressor\nimport xgboost as xgb\nimport lightgbm as lgb\n","8b9e409f":"data = pd.read_csv('\/kaggle\/input\/udemy-courses\/udemy_courses.csv',parse_dates=True)\ndata['published_timestamp']=pd.to_datetime(data['published_timestamp']).dt.date\ndata['year']=pd.to_datetime(data['published_timestamp']).dt.year\ndata['month']=pd.to_datetime(data['published_timestamp']).dt.day\ndata['day']=pd.to_datetime(data['published_timestamp']).dt.month\n","1beaefc5":"data.head()","2b08bfb7":"data.info()","44f2d760":"data.describe()","04cfde0e":"from pandas_profiling import ProfileReport \nreport = ProfileReport(data)\nreport","6f79dc0a":"def missing_percentage(df):\n    \"\"\"This function takes a DataFrame(df) as input and returns two columns, total missing values and total missing values percentage\"\"\"\n    total = df.isnull().sum().sort_values(ascending = False)\n    percent = round(df.isnull().sum().sort_values(ascending = False)\/len(df)*100,2)\n    return pd.concat([total, percent], axis=1, keys=['Total','Percent'])\n\n\nmissing_percentage(data)","a8a2d03f":"sns.pairplot(data, hue=\"is_paid\")","4d256378":"sns.set(style=\"darkgrid\")\nplt.subplots(figsize = (15,8))\nax = sns.barplot(x = \"subject\", \n                 y = \"price\", \n                 data=data, \n                linewidth=5\n                )\n\nplt.title(\"Price Distribution Across Courses offered\", fontsize = 25,loc = 'center', pad = 40)\nplt.ylabel(\"Price\", fontsize = 15, )\nplt.xlabel(\"subject\",fontsize = 15);","683235dd":"fig = plt.figure(figsize=(15,8),)\nax=sns.kdeplot(data.loc[(data['subject'] == 'Business Finance'),'price'] , color='gray',shade=True,label='Business Finance')\nax=sns.kdeplot(data.loc[(data['subject'] == 'Graphic Design'),'price'] , color='g',shade=True, label='Graphic Design')\nax=sns.kdeplot(data.loc[(data['subject'] == 'Musical Instruments'),'price'] , color='red',shade=True,label='Musical Instruments')\nax=sns.kdeplot(data.loc[(data['subject'] == 'Web Development'),'price'] , color='green',shade=True,label='Web Development')\nplt.title('Price Distribution', fontsize = 25, pad = 40)\nplt.ylabel(\"Frequency of Price\", fontsize = 15, labelpad = 20)\nplt.xlabel(\"Price\", fontsize = 15, labelpad = 20);","c6347b99":"plt.subplots(figsize = (22,10),)\nsns.distplot(data.price, bins = 100, kde = True, rug = False, norm_hist=False);","cfc70340":"data.head()","336e6aea":"g = sns.FacetGrid(data, size=5,hue=\"is_paid\", col =\"level\", margin_titles=True)\ng.map(plt.scatter, \"price\", \"num_subscribers\",edgecolor=\"w\").add_legend()\ng.fig.suptitle(\"Price by is_paid\", size = 25)\nplt.subplots_adjust(top=0.85)","7da0b477":"fig = px.bar(data, x=\"subject\", y=\"num_subscribers\", color=\"is_paid\",hover_name='subject')\nfig.show()","c5c4ff33":"df_sub = data.is_paid.value_counts().reset_index()\ndf_sub.columns = ['is_paid', 'Counts']\nfig = px.bar(df_sub, x=\"is_paid\", y=\"Counts\", color='is_paid', barmode='group',\n             height=400)\nfig.show()","e777a0e5":"df_sub = data.subject.value_counts().reset_index()\ndf_sub.columns = ['subject', 'Counts']\nfig = px.pie(df_sub, names='subject', values='Counts', width=500)\nfig.update_layout(title=\"Courses offered\")","7d8977fd":"gd = data.groupby([\"level\"])[[\"price\"]].mean().reset_index()\n\nfig = px.pie(gd,\n             values=\"price\",\n             names=\"level\",\n             template=\"seaborn\")\nfig.update_traces(rotation=90, pull=0.05, textinfo=\"percent+label\")\nfig.show()","717bf3df":"paid_df = data[data['is_paid'] == True]\ntop_rated_paid = paid_df.groupby('subject') \\\n.apply(lambda x: x.sort_values(['num_subscribers'], ascending=False)) \\\n.reset_index(drop=True) \\\n.groupby('subject') \\\n.head(1)\n\ntop_rated_paid = top_rated_paid[['course_title',\n                                 'content_duration',\n                                 'published_timestamp',\n                                 'num_subscribers',\n                                'subject']]\ntop_rated_paid\ntop_rated_paid.style.background_gradient(cmap='coolwarm').set_precision(2)\n","ebd9f1d6":"free_df = data[data['is_paid'] == False]\ntop_rated_free = free_df.groupby('subject') \\\n.apply(lambda x: x.sort_values(['num_subscribers'], ascending=False)) \\\n.reset_index(drop=True) \\\n.groupby('subject') \\\n.head(1)\n\ntop_rated_free = top_rated_free[['course_title',\n                                 'content_duration',\n                                 'published_timestamp',\n                                 'num_subscribers',\n                                'subject']]\ntop_rated_free\ntop_rated_free.style.background_gradient(cmap='coolwarm').set_precision(2)\n","cd4d02d3":"fig = px.scatter_matrix(top_rated_paid,dimensions=[\"content_duration\", \"num_subscribers\"], color=\"course_title\")\nfig.show()","78fa9b5f":"data.columns","4e12e91a":"fig = px.scatter(data, x=\"num_subscribers\", y=\"num_reviews\", color=\"num_reviews\", facet_col=\"is_paid\",\n           color_continuous_scale=px.colors.sequential.Viridis, render_mode=\"webgl\")\nfig.show()","57b04e65":"fig = px.scatter(data, x=\"num_subscribers\", y=\"num_lectures\", animation_frame=\"year\", animation_group=\"level\"\n        , color=\"level\", hover_name=\"level\", facet_col=\"level\",\n           log_x=True, size_max=45, range_x=[100,100000], range_y=[25,90])\nfig.show()","cfcf67f4":"p = data.sort_values(by=['year'])\np= p.head(200)\nfig=px.bar(p,x='course_title', y=\"price\", animation_frame=\"year\", \n           animation_group=\"course_title\", color=\"course_title\", hover_name=\"course_title\")\nfig.update_layout(title='Price vs Courses')","3353beb0":"fig = px.box(data, x=\"level\", y=\"price\", color=\"subject\", notched=True)\nfig.show()","f42e3215":"fig = px.box(data, x=\"subject\", y=\"price\", color=\"subject\", notched=True)\nfig.show()","42bc13a1":"plt.rcParams['figure.figsize'] = (20, 8)\nsns.countplot(data['price'], palette = 'rainbow')\nplt.title('Distribution of Courses Cost', fontsize = 20)\nplt.show()\nplt.rcParams['figure.figsize'] = (20, 8)\nsns.countplot(data['level'], palette = 'rainbow')\nplt.title('Distribution of levels', fontsize = 20)\nplt.show()\nplt.rcParams['figure.figsize'] = (20, 8)\nsns.countplot(data['is_paid'], palette = 'rainbow')\nplt.title('Distribution of Paid\/Free Courses', fontsize = 20)\nplt.show()","7bda8296":"plt.rcParams['figure.figsize'] = (30, 50)\nsns.catplot(x=\"level\", kind=\"count\",hue ='subject', data=data, col='is_paid');\nplt.show()","d4fe2234":"fig = px.scatter(data, x=\"num_lectures\", y=\"num_reviews\", color=\"is_paid\", marginal_y=\"violin\",\n           marginal_x=\"box\", trendline=\"ols\")\nfig.show()","b7be6e10":"fig = px.bar(data, x=\"price\", y=\"num_lectures\",color=\"is_paid\")\nfig.show()","3befd3d7":"fig = px.histogram(data, x=\"level\", y=\"num_subscribers\", color=\"subject\",\n                   marginal=\"violin\")\nfig.show()","782a751a":"fig = px.histogram(data, x=\"level\", y=\"num_subscribers\", color=\"is_paid\",\n                   marginal=\"box\")\nfig.show()","9bccebb6":"x = data['year']\ny = data['num_subscribers']\nplt.rcParams['figure.figsize'] = (20, 8)\nsns.lineplot(x, y, color = 'blue')\nplt.title('Year vs Number of Subscribers', fontsize = 10)\nplt.show()","ce84cad8":"grss = data.groupby([\"level\",\"subject\"])[[\"price\"]].mean().reset_index()\n\nfig = px.treemap(grss, path=[\"level\",\"subject\"], values='price',\n                  color='price', hover_data=['price'],\n                  color_continuous_scale='rainbow')\nfig.show()","04893b43":"ms = data.sort_values(by=['num_subscribers'],ascending=False)\nms = ms.head(10)\nfig = px.funnel(ms, x='price', y='course_title')\nfig.show()","89e4deb0":"from wordcloud import WordCloud, ImageColorGenerator\ntext = \" \".join(str(each) for each in data.course_title.unique())\nwordcloud = WordCloud(max_words=200,colormap='Set2', background_color=\"white\").generate(text)\nplt.figure(figsize=(15,10))\nplt.imshow(wordcloud, interpolation='Bilinear')\nplt.axis(\"off\")\nplt.figure(1,figsize=(12, 12))\nplt.show()\n","f60fbff0":"fig = px.parallel_categories(data, color=\"is_paid\", color_continuous_scale=px.colors.sequential.solar)\nfig.show()","fc02225f":"train_data =  data[data['is_paid'] == True]\ntrain_data = train_data.drop(['course_id','url','published_timestamp','course_title','is_paid'],axis=1)\nprint(\"train size is : {}\".format(train_data.shape))","8feaf3d9":"corrmat = train_data.corr()\nplt.subplots(figsize=(12,9))\nsns.heatmap(corrmat, vmax=0.9, square=True)","9562f043":"train_df = pd.get_dummies(train_data, columns=['level','subject'])","713b63fc":"# most correlated features\ncorrmat = train_df.corr()\ntop_corr_features = corrmat.index[abs(corrmat[\"num_reviews\"])>0.5]\nplt.figure(figsize=(10,10))\ng = sns.heatmap(train_df[top_corr_features].corr(),annot=True,cmap=\"winter\")","e4602247":"from scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\n\nsns.distplot(train_df['num_reviews'] , fit=norm);\n\n# Get the fitted parameters used by the function\n(mu, sigma) = norm.fit(train_df['num_reviews'])\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nplt.ylabel('Frequency')\nplt.title('Review distribution')\n\nfig = plt.figure()\nres = stats.probplot(train_df['num_reviews'], plot=plt)\nplt.show()","9d028426":"train_df.num_reviews = np.log1p(train_df.num_reviews )","20065692":"train_df.head()","97047105":"y = train_df.num_reviews\ntrain_df = train_df.drop(['num_reviews'],axis=1)\nX_train,X_test,y_train,y_test = train_test_split(train_df,y,test_size = 0.1,random_state= 0)","54f5cd14":"from sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\nfrom sklearn.metrics import mean_squared_error, make_scorer","7a4a8de5":"n_folds = 5\nfrom sklearn.metrics import make_scorer\nfrom sklearn.model_selection import KFold\nscorer = make_scorer(mean_squared_error,greater_is_better = False)\ndef rmse_CV_train(model):\n    kf = KFold(n_folds,shuffle=True,random_state=42).get_n_splits(X_train.values)\n    rmse = np.sqrt(-cross_val_score(model,X_train,y_train,scoring =\"neg_mean_squared_error\",cv=kf))\n    return (rmse)\ndef rmse_CV_test(model):\n    kf = KFold(n_folds,shuffle=True,random_state=42).get_n_splits(X_train.values)\n    rmse = np.sqrt(-cross_val_score(model,X_test,y_test,scoring =\"neg_mean_squared_error\",cv=kf))\n    return (rmse)","12407818":"lr = LinearRegression()\nlr.fit(X_train,y_train)\ntest_pre = lr.predict(X_test)\ntrain_pre = lr.predict(X_train)\nprint('rmse on train',rmse_CV_train(lr).mean())\nprint('rmse on train',rmse_CV_test(lr).mean())","b22e2e5c":"plt.scatter(train_pre, train_pre - y_train, c = \"blue\",  label = \"Training data\")\nplt.scatter(test_pre,test_pre - y_test, c = \"black\",  label = \"Validation data\")\nplt.title(\"Linear regression\")\nplt.xlabel(\"Predicted values\")\nplt.ylabel(\"Residuals\")\nplt.legend(loc = \"upper left\")\nplt.hlines(y = 0, xmin = 10.5, xmax = 13.5, color = \"red\")\nplt.show()","a72212da":"clfs = []\nseed = 3\n\nclfs.append((\"LinearRegression\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"LogReg\", LinearRegression())])))\n\nclfs.append((\"XGB\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"XGB\", XGBRegressor())]))) \nclfs.append((\"KNN\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"KNN\", KNeighborsRegressor())]))) \n\nclfs.append((\"DTR\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"DecisionTrees\", DecisionTreeRegressor())]))) \n\nclfs.append((\"RFRegressor\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RandomForest\", RandomForestRegressor())]))) \n\nclfs.append((\"GBRegressor\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"GradientBoosting\", GradientBoostingRegressor(max_features=15, \n                                                                       n_estimators=600))]))) \n\nclfs.append((\"MLP\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"MLP Regressor\", MLPRegressor())])))\n\n\nclfs.append((\"EXT Regressor\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"ExtraTrees\", ExtraTreeRegressor())])))\nclfs.append((\"SV Regressor\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"ExtraTrees\", SVR())])))\n\nscoring = 'r2'\nn_folds = 10\nmsgs = []\nresults, names  = [], [] \n\nfor name, model  in clfs:\n    kfold = KFold(n_splits=n_folds, random_state=seed)\n    cv_results = cross_val_score(model, X_train, y_train, \n                                 cv=kfold, scoring=scoring, n_jobs=-1)    \n    names.append(name)\n    results.append(cv_results)    \n    msg = \"%s: %f (+\/- %f)\" % (name, cv_results.mean(),  \n                               cv_results.std())\n    msgs.append(msg)\n    print(msg)","3fbd4cf9":"scaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","3f5c28ec":"forest = RandomForestRegressor(n_estimators = 100,\n                              criterion = 'mse',\n                              random_state = 1,\n                              n_jobs = -1)\nforest.fit(X_train,y_train)\nforest_train_pred = forest.predict(X_train)\nforest_test_pred = forest.predict(X_test)\n\nprint('MSE train data: %.3f, MSE test data: %.3f' % (\nmean_squared_error(y_train,forest_train_pred),\nmean_squared_error(y_test,forest_test_pred)))\nprint('R2 train data: %.3f, R2 test data: %.3f' % (\nr2_score(y_train,forest_train_pred),\nr2_score(y_test,forest_test_pred)))\nrms = sqrt(mean_squared_error(y_test, forest_test_pred))\nprint('Root mean Squared Error for Test Data {} '.format(rms))","fdecea6b":"<img src= \"https:\/\/www.freelancinggig.com\/blog\/wp-content\/uploads\/2018\/10\/Programming-Language-used-for-Udemy.jpg\">","21b89aa4":"## Phase I - EDA\n* Univariate Analysis\n* Bivariate Analysis","03da767f":"### Top Paid Courses","f074a947":"#### Skewness Test","29125ef5":"#### Baseline Model","4564a23e":"<b>Udemy, founded in May 2010, is an American online learning platform aimed at professional adults and students. As of Jan 2020, the platform has more than 50 million students and 57,000 instructors teaching courses in over 65 languages\nStudents take courses largely as a means of improving job-related skills. Some courses generate credit toward technical certification. Udemy has made a special effort to attract corporate trainers seeking to create coursework for employees of their company. As of 2020, there are more than 150,000 courses on the website.\n<\/b>\n\n<b> This dataset contains 3.682 records of courses from 4 subjects (Business Finance, Graphic Design, Musical Instruments and Web Design) taken from Udemy.\nUdemy is a massive online open course (MOOC) platform that offers both free and paid courses. Anybody can create a course, a business model by which allowed Udemy to have hundreds of thousands of courses.<\/b>","e9f32cfd":"### Top Free Courses","e2808d53":"### Please Show your Appreciation by Hitting Upvote \ud83e\udd17!!!!","586940e5":"## Phase II- Predictive Analysis\n### Predicting Number of Reviews for Paid Udemy Courses"}}