{"cell_type":{"4c594b9e":"code","2a7ab2d9":"code","65c747b9":"code","614a4d8b":"code","866b6a7e":"code","924417c5":"code","44c0c04b":"code","1d8322bc":"code","7a2bc59c":"code","a72cfcfc":"code","e63b7c24":"code","09c082ba":"code","064da5a1":"code","f2bb5786":"code","a4e41905":"code","5d40f02b":"code","8ea6d193":"code","b883fdba":"code","8109c6fd":"code","03a60f57":"code","b8e94eb3":"code","0edf982f":"code","015d8833":"code","26fc87b0":"code","1acee0ed":"code","fac84073":"code","775a859f":"code","b4d75130":"code","42a1ade9":"code","54221ac8":"code","0365faa5":"code","1d36c0b8":"code","87fe0305":"code","b16d8dd1":"code","0076bffc":"code","f79a28fd":"code","587cab2f":"code","f536c1d0":"code","c70407d8":"code","d953e74e":"code","8d347ce8":"code","9f895af8":"code","66c1ea9a":"code","942b22d7":"code","3ca06224":"code","a95e75ff":"code","847b4094":"code","ca1f4344":"code","5d79990b":"code","c954eac9":"code","06412ed5":"code","ee300573":"code","6a5bb04d":"code","bb348f35":"code","0f9bf973":"code","a5cbc8c8":"code","aabbb070":"code","76c21536":"code","f5aa669b":"code","59548820":"code","36a05582":"code","f341e475":"code","910bfb5a":"code","fb348697":"code","43ff2d92":"code","92423586":"code","51eb808c":"code","730a2739":"code","80571bc6":"code","b284d941":"code","b6e4ee8e":"code","2a53e8ba":"code","58acc2a2":"code","87f99658":"code","470bce87":"code","b676b043":"code","d513cf33":"code","53c3a818":"code","1cd0d025":"code","32f1f081":"code","a21cf469":"code","cd0828ea":"code","b830b4ba":"code","dfd12c3c":"code","c5856fe3":"code","48545e1f":"code","5c46172c":"code","2732cef4":"code","93e8a202":"code","c0a7cadc":"code","68ca41dd":"code","0010f324":"code","79c6b081":"code","c3ce96e6":"code","5a1742d3":"code","ebf6cf9b":"code","6d68ecd0":"code","40c651c8":"code","8f26e9a6":"code","9387eb0b":"code","ac95beb1":"code","41470551":"code","734ee5ba":"code","d5b497f2":"code","abc0483a":"markdown","388aa015":"markdown","b3f00535":"markdown","ebc4e200":"markdown","3c9dfe32":"markdown","9d0059eb":"markdown","c6099836":"markdown","838b6d73":"markdown","ec7f16a4":"markdown","8fbc621e":"markdown","fda57d7c":"markdown","f277ff00":"markdown","80a6aa0a":"markdown","4d4ba038":"markdown","5b578db4":"markdown","0bdd0b62":"markdown","ee7000e4":"markdown","e553decb":"markdown","6dc7443a":"markdown","6de17fe8":"markdown","88debfa9":"markdown","38d9e586":"markdown","faae86db":"markdown","9feed942":"markdown","82661a37":"markdown","2be3af1a":"markdown","a33010ab":"markdown","17c400ca":"markdown","e4049fe0":"markdown","ee611aa1":"markdown","0ffaccfd":"markdown","3530abae":"markdown","71c4411d":"markdown","7dbb0742":"markdown","7e1d66ef":"markdown","bdd2e568":"markdown","bbf5e9c7":"markdown","177922cf":"markdown","b94e5f3e":"markdown","167147a9":"markdown","7967390f":"markdown","b4b5bb20":"markdown","7846da5e":"markdown","11d22edd":"markdown","679010ce":"markdown","2f708328":"markdown","ab9c6edd":"markdown","bdbc7db8":"markdown","ee35bb98":"markdown","fa191860":"markdown","b322b8c0":"markdown","98caf6c5":"markdown","7deffaa2":"markdown","6099c6fe":"markdown","b2356927":"markdown","cf96ba66":"markdown","88db913c":"markdown","6049d2f6":"markdown","fdc4ff03":"markdown","510775dd":"markdown","3197dc98":"markdown","54d2c2ec":"markdown","e8416024":"markdown","e928c565":"markdown","3b4e5929":"markdown","96712b5d":"markdown","ea556fe8":"markdown","649a9d7a":"markdown","d3e7b7af":"markdown","125bbf6a":"markdown","6f5db686":"markdown","67209f39":"markdown","d6366cee":"markdown","da31f562":"markdown","4854a63c":"markdown","b9966f31":"markdown","52a63acf":"markdown","64cbcfae":"markdown"},"source":{"4c594b9e":"%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport sqlite3\nimport pandas as pd\nimport numpy as np\nimport nltk\nimport string\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_curve, auc\nfrom nltk.stem.porter import PorterStemmer\n\nimport re\n# Tutorial about Python regular expressions: https:\/\/pymotw.com\/2\/re\/\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nfrom gensim.models import Word2Vec\nfrom gensim.models import KeyedVectors\nimport pickle\n\nfrom tqdm import tqdm\nimport os\n\n# replaced -- from plotly import plotly with below line. as it was giving exception \n#reference from https:\/\/github.com\/plotly\/plotly.py\/issues\/1660\nfrom chart_studio.plotly import plot, iplot\nimport plotly.offline as offline\nimport plotly.graph_objs as go\noffline.init_notebook_mode()\nfrom collections import Counter","2a7ab2d9":"project_data = pd.read_csv('..\/input\/donors-chose\/train_data.csv')\nresource_data = pd.read_csv('..\/input\/donors-chose\/resources.csv')","65c747b9":"print(project_data.info())\nprint(resource_data.info())","614a4d8b":"print(\"Number of data points in train data\", project_data.shape)\nprint('-'*50)\nprint(\"The attributes of data :\", project_data.columns.values)","866b6a7e":"print(\"Number of data points in train data\", resource_data.shape)\nprint(resource_data.columns.values)\nresource_data.head(2)","924417c5":"# PROVIDE CITATIONS TO YOUR CODE IF YOU TAKE IT FROM ANOTHER WEBSITE.\n# https:\/\/matplotlib.org\/gallery\/pie_and_polar_charts\/pie_and_donut_labels.html#sphx-glr-gallery-pie-and-polar-charts-pie-and-donut-labels-py\n\n\ny_value_counts = project_data['project_is_approved'].value_counts()\nprint(\"Number of projects thar are approved for funding \", y_value_counts[1], \", (\", (y_value_counts[1]\/(y_value_counts[1]+y_value_counts[0]))*100,\"%)\")\nprint(\"Number of projects thar are not approved for funding \", y_value_counts[0], \", (\", (y_value_counts[0]\/(y_value_counts[1]+y_value_counts[0]))*100,\"%)\")\n\nfig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(aspect=\"equal\"))\nrecipe = [\"Accepted\", \"Not Accepted\"]\n\ndata = [y_value_counts[1], y_value_counts[0]]\n\nwedges, texts = ax.pie(data, wedgeprops=dict(width=0.5), startangle=-40)\n\nbbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\nkw = dict(xycoords='data', textcoords='data', arrowprops=dict(arrowstyle=\"-\"),\n          bbox=bbox_props, zorder=0, va=\"center\")\n\nfor i, p in enumerate(wedges):\n    ang = (p.theta2 - p.theta1)\/2. + p.theta1\n    y = np.sin(np.deg2rad(ang))\n    x = np.cos(np.deg2rad(ang))\n    horizontalalignment = {-1: \"right\", 1: \"left\"}[int(np.sign(x))]\n    connectionstyle = \"angle,angleA=0,angleB={}\".format(ang)\n    kw[\"arrowprops\"].update({\"connectionstyle\": connectionstyle})\n    ax.annotate(recipe[i], xy=(x, y), xytext=(1.35*np.sign(x), 1.4*y),\n                 horizontalalignment=horizontalalignment, **kw)\n\nax.set_title(\"Nmber of projects that are Accepted and not accepted\")\n\nplt.show()","44c0c04b":"# Pandas dataframe groupby count, mean: https:\/\/stackoverflow.com\/a\/19385591\/4084039\n\n#https:\/\/github.com\/plotly\/plotly.py\/issues\/1660\n\ntemp = pd.DataFrame(project_data.groupby(\"school_state\")[\"project_is_approved\"].apply(np.mean)).reset_index()\n# if you have data which contain only 0 and 1, then the mean = percentage (think about it)\ntemp.columns = ['state_code', 'num_proposals']\n\n# How to plot US state heatmap: https:\/\/datascience.stackexchange.com\/a\/9620\n\nscl = [[0.0, 'rgb(242,240,247)'],[0.2, 'rgb(218,218,235)'],[0.4, 'rgb(188,189,220)'],\\\n            [0.6, 'rgb(158,154,200)'],[0.8, 'rgb(117,107,177)'],[1.0, 'rgb(84,39,143)']]\n\ndata = [ dict(\n        type='choropleth',\n        colorscale = scl,\n        autocolorscale = False,\n        locations = temp['state_code'],\n        z = temp['num_proposals'].astype(float),\n        locationmode = 'USA-states',\n        text = temp['state_code'],\n        marker = dict(line = dict (color = 'rgb(255,255,255)',width = 2)),\n        colorbar = dict(title = \"% of pro\")\n    ) ]\n\nlayout = dict(\n        title = 'Project Proposals % of Acceptance Rate by US States',\n        geo = dict(\n            scope='usa',\n            projection=dict( type='albers usa' ),\n            showlakes = True,\n            lakecolor = 'rgb(255, 255, 255)',\n        ),\n    )\n\nfig = go.Figure(data=data, layout=layout)\noffline.iplot(fig, filename='us-map-heat-map')","1d8322bc":"temp.head(10)","7a2bc59c":"# https:\/\/www.csi.cuny.edu\/sites\/default\/files\/pdf\/administration\/ops\/2letterstabbrev.pdf\ntemp.sort_values(by=['num_proposals'], inplace=True)\nprint(\"States with lowest % approvals\")\nprint(temp.head(5))\nprint('='*50)\nprint(\"States with highest % approvals\")\nprint(temp.tail(5))","a72cfcfc":"#stacked bar plots matplotlib: https:\/\/matplotlib.org\/gallery\/lines_bars_and_markers\/bar_stacked.html\ndef stack_plot(data, xtick, col2='project_is_approved', col3='total'):\n    ind = np.arange(data.shape[0])\n    \n    plt.figure(figsize=(20,5))\n    p1 = plt.bar(ind, data[col3].values)\n    p2 = plt.bar(ind, data[col2].values)\n\n    plt.ylabel('Projects')\n    plt.title('Number of projects aproved vs rejected')\n    plt.xticks(ind, list(data[xtick].values))\n    plt.legend((p1[0], p2[0]), ('total', 'accepted'))\n    plt.show()","e63b7c24":"def univariate_barplots(data, col1, col2='project_is_approved', top=False):\n    # Count number of zeros in dataframe python: https:\/\/stackoverflow.com\/a\/51540521\/4084039\n    temp = pd.DataFrame(project_data.groupby(col1)[col2].agg(lambda x: x.eq(1).sum())).reset_index()\n\n    # Pandas dataframe grouby count: https:\/\/stackoverflow.com\/a\/19385591\/4084039\n    temp['total'] = pd.DataFrame(project_data.groupby(col1)[col2].agg({'total':'count'})).reset_index()['total']\n    temp['Avg'] = pd.DataFrame(project_data.groupby(col1)[col2].agg({'Avg':'mean'})).reset_index()['Avg']\n    \n    temp.sort_values(by=['total'],inplace=True, ascending=False)\n    #print(temp.head())\n    if top:\n        temp = temp[0:top]\n    \n    stack_plot(temp, xtick=col1, col2=col2, col3='total')\n    print(temp.head(5))\n    print(\"=\"*50)\n    print(temp.tail(5))","09c082ba":"univariate_barplots(project_data, 'school_state', 'project_is_approved', False)","064da5a1":"univariate_barplots(project_data, 'teacher_prefix', 'project_is_approved' , top=False)","f2bb5786":"univariate_barplots(project_data, 'project_grade_category', 'project_is_approved', top=False)","a4e41905":"catogories = list(project_data['project_subject_categories'].values)\n# remove special characters from list of strings python: https:\/\/stackoverflow.com\/a\/47301924\/4084039\n\n# https:\/\/www.geeksforgeeks.org\/removing-stop-words-nltk-python\/\n# https:\/\/stackoverflow.com\/questions\/23669024\/how-to-strip-a-specific-word-from-a-string\n# https:\/\/stackoverflow.com\/questions\/8270092\/remove-all-whitespace-in-a-string-in-python\ncat_list = []\nfor i in catogories:\n    temp = \"\"\n    temp_list=[]\n    temp_new=\"\"\n    # consider we have text like this \"Math & Science, Warmth, Care & Hunger\"\n    for j in i.split(','): # it will split it in three parts [\"Math & Science\", \"Warmth\", \"Care & Hunger\"]\n        if 'The' in j.split(): # this will split each of the catogory based on space \"Math & Science\"=> \"Math\",\"&\", \"Science\"\n            j=j.replace('The','') # if we have the words \"The\" we are going to replace it with ''(i.e removing 'The')\n        j = j.replace(' ','') # we are placeing all the ' '(space) with ''(empty) ex:\"Math & Science\"=>\"Math&Science\"\n        temp+=j.strip()+\" \" #\" abc \".strip() will return \"abc\", remove the trailing spaces\n        temp = temp.replace('&','_') # we are replacing the & value into \n        '''i have made a small change in the code while cleaning categories \n        for each project categories will now be listed in sorted order just to make sure we get unique combination for example\n        if a project had Math_science and arts_music and other has arts_music and Math_science both should be included in a unique\n        count i.e arts_music Math_science after sorting. this will give a unique result and will be good in analysis'''\n    temp_list=sorted(temp.split(' '))\n    for s in temp_list:\n        temp_new+=s+\" \"\n    cat_list.append(temp_new.strip())","5d40f02b":"project_data['clean_categories'] = cat_list\nproject_data.drop(['project_subject_categories'], axis=1, inplace=True)\nproject_data.head(2)","8ea6d193":"univariate_barplots(project_data, 'clean_categories', 'project_is_approved', top=20)","b883fdba":"print(len(project_data['clean_categories']))","8109c6fd":"# count of all the words in corpus python: https:\/\/stackoverflow.com\/a\/22898595\/4084039\nfrom collections import Counter\nmy_counter = Counter()\nfor word in project_data['clean_categories'].values:\n    my_counter.update(word.split())","03a60f57":"print(type(my_counter))\nprint(my_counter)","b8e94eb3":"# dict sort by value python: https:\/\/stackoverflow.com\/a\/613218\/4084039\ncat_dict = dict(my_counter)\nsorted_cat_dict = dict(sorted(cat_dict.items(), key=lambda kv: kv[1]))\n\nprint(\"categories counter\",cat_dict)\nprint(\"--\"*10)\nprint(\"Sorted Catregories counter\",sorted_cat_dict)\n\nind = np.arange(len(sorted_cat_dict))\nplt.figure(figsize=(20,5))\np1 = plt.bar(ind, list(sorted_cat_dict.values()))\n\nplt.ylabel('Projects')\nplt.title('% of projects aproved category wise')\nplt.xticks(ind, list(sorted_cat_dict.keys()))\nplt.show()","0edf982f":"for i, j in sorted_cat_dict.items():\n    print(\"{:20} :{:10}\".format(i,j))","015d8833":"sub_catogories = list(project_data['project_subject_subcategories'].values)\n# remove special characters from list of strings python: https:\/\/stackoverflow.com\/a\/47301924\/4084039\n\n# https:\/\/www.geeksforgeeks.org\/removing-stop-words-nltk-python\/\n# https:\/\/stackoverflow.com\/questions\/23669024\/how-to-strip-a-specific-word-from-a-string\n# https:\/\/stackoverflow.com\/questions\/8270092\/remove-all-whitespace-in-a-string-in-python\n\nsub_cat_list = []\nfor i in sub_catogories:\n    temp = \"\"\n    temp_list=[]\n    temp_new=\"\"\n    # consider we have text like this \"Math & Science, Warmth, Care & Hunger\"\n    for j in i.split(','): # it will split it in three parts [\"Math & Science\", \"Warmth\", \"Care & Hunger\"]\n        if 'The' in j.split(): # this will split each of the catogory based on space \"Math & Science\"=> \"Math\",\"&\", \"Science\"\n            j=j.replace('The','') # if we have the words \"The\" we are going to replace it with ''(i.e removing 'The')\n        j = j.replace(' ','') # we are placeing all the ' '(space) with ''(empty) ex:\"Math & Science\"=>\"Math&Science\"\n        temp +=j.strip()+\" \"#\" abc \".strip() will return \"abc\", remove the trailing spaces\n        temp = temp.replace('&','_')\n    temp_list=sorted(temp.split(' '))\n    for s in temp_list:\n        temp_new+=s+\" \"\n    \n    sub_cat_list.append(temp_new.strip())","26fc87b0":"project_data['clean_subcategories'] = sub_cat_list\nproject_data.drop(['project_subject_subcategories'], axis=1, inplace=True)\nproject_data.head(2)","1acee0ed":"univariate_barplots(project_data, 'clean_subcategories', 'project_is_approved', top=50)","fac84073":"# count of all the words in corpus python: https:\/\/stackoverflow.com\/a\/22898595\/4084039\nfrom collections import Counter\nmy_counter = Counter()\nfor word in project_data['clean_subcategories'].values:\n    my_counter.update(word.split())","775a859f":"# dict sort by value python: https:\/\/stackoverflow.com\/a\/613218\/4084039\nsub_cat_dict = dict(my_counter)\nsorted_sub_cat_dict = dict(sorted(sub_cat_dict.items(), key=lambda kv: kv[1]))\n\n\nind = np.arange(len(sorted_sub_cat_dict))\nplt.figure(figsize=(20,5))\np1 = plt.bar(ind, list(sorted_sub_cat_dict.values()))\n\nplt.ylabel('Projects')\nplt.title('% of projects aproved state wise')\nplt.xticks(ind, list(sorted_sub_cat_dict.keys()))\nplt.show()","b4d75130":"print(\"total Distinct Subcategories :\",len(sorted_sub_cat_dict))\n\n#print(sorted_sub_cat_dict.head())\n\nprint(\"*\"*20)\n\nfor i, j in sorted_sub_cat_dict.items():\n    print(\"{:20} :{:10}\".format(i,j),round(((j\/sum(sorted_sub_cat_dict.values()))*100),2))    ","42a1ade9":"#How to calculate number of words in a string in DataFrame: https:\/\/stackoverflow.com\/a\/37483537\/4084039\nword_count = project_data['project_title'].str.split().apply(len).value_counts()\nword_dict = dict(word_count)\n\nprint(word_dict)\n\nword_dict = dict(sorted(word_dict.items(), key=lambda kv: kv[1]))\n\n\nind = np.arange(len(word_dict))\nplt.figure(figsize=(20,5))\np1 = plt.bar(ind, list(word_dict.values()))\n\nplt.ylabel('Number of projects')\nplt.xlabel('Number words in project title')\nplt.title('Words for each title of the project')\nplt.xticks(ind, list(word_dict.keys()))\nplt.show()","54221ac8":"approved_title_word_count = project_data[project_data['project_is_approved']==1]['project_title'].str.split().apply(len)\napproved_title_word_count = approved_title_word_count.values\n\nrejected_title_word_count = project_data[project_data['project_is_approved']==0]['project_title'].str.split().apply(len)\nrejected_title_word_count = rejected_title_word_count.values","0365faa5":"# https:\/\/glowingpython.blogspot.com\/2012\/09\/boxplot-with-matplotlib.html\nplt.boxplot([approved_title_word_count, rejected_title_word_count])\nplt.xticks([1,2],('Approved Projects','Rejected Projects'))\nplt.ylabel('Words in project title')\nplt.grid()\nplt.show()","1d36c0b8":"plt.figure(figsize=(10,3))\nsns.kdeplot(approved_title_word_count,label=\"Approved Projects\", bw=0.6)\nsns.kdeplot(rejected_title_word_count,label=\"Not Approved Projects\", bw=0.6)\nplt.legend()\nplt.show()","87fe0305":"# merge two column text dataframe: \nproject_data[\"essay\"] = project_data[\"project_essay_1\"].map(str) +\\\n                        project_data[\"project_essay_2\"].map(str) + \\\n                        project_data[\"project_essay_3\"].map(str) + \\\n                        project_data[\"project_essay_4\"].map(str)","b16d8dd1":"approved_word_count = project_data[project_data['project_is_approved']==1]['essay'].str.split().apply(len)\napproved_word_count = approved_word_count.values\n\nrejected_word_count = project_data[project_data['project_is_approved']==0]['essay'].str.split().apply(len)\nrejected_word_count = rejected_word_count.values","0076bffc":"# https:\/\/glowingpython.blogspot.com\/2012\/09\/boxplot-with-matplotlib.html\nplt.boxplot([approved_word_count, rejected_word_count])\nplt.title('Words for each essay of the project')\nplt.xticks([1,2],('Approved Projects','Rejected Projects'))\nplt.ylabel('Words in project essays')\nplt.grid()\nplt.show()","f79a28fd":"plt.figure(figsize=(10,3))\nsns.distplot(approved_word_count, hist=False, label=\"Approved Projects\")\nsns.distplot(rejected_word_count, hist=False, label=\"Not Approved Projects\")\nplt.title('Words for each essay of the project')\nplt.xlabel('Number of words in each eassay')\nplt.legend()\nplt.show()","587cab2f":"# we get the cost of the project using resource.csv file\nresource_data.head(2)","f536c1d0":"# https:\/\/stackoverflow.com\/questions\/22407798\/how-to-reset-a-dataframes-indexes-for-all-groups-in-one-step\nprice_data = resource_data.groupby('id').agg({'price':'sum', 'quantity':'sum'}).reset_index()\nprice_data.head(2)","c70407d8":"# join two dataframes in python: \nproject_data = pd.merge(project_data, price_data, on='id', how='left')","d953e74e":"approved_price = project_data[project_data['project_is_approved']==1]['price'].values\n\nrejected_price = project_data[project_data['project_is_approved']==0]['price'].values","8d347ce8":"# https:\/\/glowingpython.blogspot.com\/2012\/09\/boxplot-with-matplotlib.html\nplt.boxplot([approved_price, rejected_price])\nplt.title('Box Plots of Cost per approved and not approved Projects')\nplt.xticks([1,2],('Approved Projects','Rejected Projects'))\nplt.ylabel('Price')\nplt.grid()\nplt.show()","9f895af8":"plt.figure(figsize=(10,3))\nsns.distplot(approved_price, hist=False, label=\"Approved Projects\")\nsns.distplot(rejected_price, hist=False, label=\"Not Approved Projects\")\nplt.title('Cost per approved and not approved Projects')\nplt.xlabel('Cost of a project')\nplt.legend()\nplt.show()","66c1ea9a":"# http:\/\/zetcode.com\/python\/prettytable\/\nfrom prettytable import PrettyTable\n\n#If you get a ModuleNotFoundError error , install prettytable using: pip3 install prettytable\n\nx = PrettyTable()\nx.field_names = [\"Percentile\", \"Approved Projects\", \"Not Approved Projects\",\"Price Difference\"]\n\nfor i in range(0,101,5):\n    x.add_row([i,np.round(np.percentile(approved_price,i), 3), np.round(np.percentile(rejected_price,i), 3),round((np.round(np.percentile(rejected_price,i), 3)-np.round(np.percentile(approved_price,i), 3)),3)])\nprint(x)","942b22d7":"univariate_barplots(project_data, 'teacher_number_of_previously_posted_projects', 'project_is_approved', top=25)","3ca06224":"approved_previouslyPostedProjectcount= project_data[project_data['project_is_approved']==1]['teacher_number_of_previously_posted_projects'].values\n\nrejected_previouslyPostedProjectcount = project_data[project_data['project_is_approved']==0]['teacher_number_of_previously_posted_projects'].values","a95e75ff":"plt.boxplot([approved_previouslyPostedProjectcount,rejected_previouslyPostedProjectcount])\nplt.title('Box Plots of projects count for number of previously Submitted Projects')\nplt.xticks([1,2],('Approved Projects','Rejected Projects'))\nplt.ylabel('teacher_number_of_prevnuiously_posted_projects')\nplt.grid()\nplt.show()","847b4094":"plt.figure(figsize=(10,3))\nsns.distplot(approved_previouslyPostedProjectcount, hist=False, label=\"Approved Projects\")\nsns.distplot(rejected_previouslyPostedProjectcount, hist=False, label=\"Not Approved Projects\")\nplt.title('PDF of teacher number of previously posted projects for Approved and Rejected Projects')\nplt.xlabel('teacher number of previously posted projects')\nplt.legend()\nplt.show()","ca1f4344":"project_data.head(5)","5d79990b":"#How to calculate number of words in a string in DataFrame: https:\/\/stackoverflow.com\/a\/37483537\/4084039\nword_count = project_data['project_resource_summary'].str.split().apply(len).value_counts()\nword_dict = dict(word_count)\n\nprint(word_dict)\n\nword_dict = dict(sorted(word_dict.items(), key=lambda kv: kv[1]))\n\n\nind = np.arange(len(word_dict))\nplt.figure(figsize=(20,5))\np1 = plt.bar(ind, list(word_dict.values()))\n\nplt.ylabel('Number of projects')\nplt.xlabel('Number words in project resource summary')\nplt.title('Words in each project resource summary')\nplt.xticks(ind, list(word_dict.keys()))\nplt.show()","c954eac9":"approved_projectresourcesummarycount = project_data[project_data['project_is_approved']==1]['project_resource_summary'].str.split().apply(len)\napproved_projectresourcesummarycount = approved_projectresourcesummarycount.values\n\nrejected_projectresourcesummarycount = project_data[project_data['project_is_approved']==0]['project_resource_summary'].str.split().apply(len)\nrejected_projectresourcesummarycount = rejected_projectresourcesummarycount.values","06412ed5":"x = PrettyTable()\nx.field_names = [\"Percentile\", \"Approved Projects\", \"Not Approved Projects\",\"word Difference\"]\n\nfor i in range(0,101,5):\n    x.add_row([i,np.round(np.percentile(approved_projectresourcesummarycount,i), 3), np.round(np.percentile(rejected_projectresourcesummarycount,i), 3),round((np.round(np.percentile(approved_projectresourcesummarycount,i), 3)-np.round(np.percentile(rejected_projectresourcesummarycount,i), 3)),3)])\nprint(x)","ee300573":"#resource https:\/\/stackoverflow.com\/questions\/19859282\/check-if-a-string-contains-a-number\n\ndef contains_Numbers(inputString):\n    x=0\n    if (any(char.isdigit() for char in inputString)):\n        x=1\n    else:\n        x=0\n    return x    ","6a5bb04d":"res_summary = list(project_data['project_resource_summary'].values)\nres_summary\nIsSummaryhasDigit_list = []\nfor i in res_summary:\n    IsSummaryhasDigit_list.append(contains_Numbers(i))","bb348f35":"project_data['numericdigit_summary_flag'] = IsSummaryhasDigit_list\nproject_data.head(5)","0f9bf973":"project_data['numericdigit_summary_flag'].value_counts(normalize=True)","a5cbc8c8":"univariate_barplots(project_data, 'numericdigit_summary_flag', 'project_is_approved')","aabbb070":"project_data.head(2)","76c21536":"# printing some random essays.\nprint(project_data['essay'].values[0])\nprint(\"=\"*50)\nprint(project_data['essay'].values[150])\nprint(\"=\"*50)\nprint(project_data['essay'].values[1000])\nprint(\"=\"*50)\nprint(project_data['essay'].values[20000])\nprint(\"=\"*50)\nprint(project_data['essay'].values[99999])\nprint(\"=\"*50)\n","f5aa669b":"# https:\/\/stackoverflow.com\/a\/47091490\/4084039\nimport re\n\ndef decontracted(phrase):\n    # specific\n    phrase = re.sub(r\"won't\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n\n    # general\n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n    return phrase","59548820":"sent = decontracted(project_data['essay'].values[20000])\nprint(sent)\nprint(\"=\"*50)","36a05582":"# \\r \\n \\t remove from string python: http:\/\/texthandler.com\/info\/remove-line-breaks-python\/\nsent = sent.replace('\\\\r', ' ')\nsent = sent.replace('\\\\\"', ' ')\nsent = sent.replace('\\\\n', ' ')\nprint(sent)","f341e475":"#remove spacial character: https:\/\/stackoverflow.com\/a\/5843547\/4084039\nsent = re.sub('[^A-Za-z0-9]+', ' ', sent)\nprint(sent)","910bfb5a":"# https:\/\/gist.github.com\/sebleier\/554280\n# we are removing the words from the stop words list: 'no', 'nor', 'not'\nstopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n            'won', \"won't\", 'wouldn', \"wouldn't\"]","fb348697":"# Combining all the above statemennts \nfrom tqdm import tqdm\npreprocessed_essays = []\n# tqdm is for printing the status bar\nfor sentance in tqdm(project_data['essay'].values):\n    sent = decontracted(sentance)\n    sent = sent.replace('\\\\r', ' ')\n    sent = sent.replace('\\\\\"', ' ')\n    sent = sent.replace('\\\\n', ' ')\n    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n    # https:\/\/gist.github.com\/sebleier\/554280\n    sent = ' '.join(e for e in sent.split() if e not in stopwords)\n    preprocessed_essays.append(sent.lower().strip())","43ff2d92":"# after preprocesing\npreprocessed_essays[20000]","92423586":"# similarly you can preprocess the titles also\n\n# Combining all the above statemennts \nfrom tqdm import tqdm\npreprocessed_projecttitle = []\n# tqdm is for printing the status bar\nfor sentance in tqdm(project_data['project_title'].values):\n    sent = decontracted(sentance)\n    sent = sent.replace('\\\\r', ' ')\n    sent = sent.replace('\\\\\"', ' ')\n    sent = sent.replace('\\\\n', ' ')\n    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n    # https:\/\/gist.github.com\/sebleier\/554280\n    sent = ' '.join(e for e in sent.split() if e not in stopwords)\n    preprocessed_projecttitle.append(sent.lower().strip())","51eb808c":"print(preprocessed_projecttitle[2000])\nprint(\"*\"*50)\nprint(preprocessed_projecttitle[3100])\n\nprint(preprocessed_projecttitle[20000])","730a2739":"project_data.columns","80571bc6":"list(sorted_cat_dict.keys())","b284d941":"# we use count vectorizer to convert the values into one hot encoded features\nfrom sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer(vocabulary=list(sorted_cat_dict.keys()), lowercase=False, binary=True)\nvectorizer.fit(project_data['clean_categories'].values)\nprint(vectorizer.get_feature_names())\n\n\ncategories_one_hot = vectorizer.transform(project_data['clean_categories'].values)\nprint(\"Shape of matrix after one hot encodig \",categories_one_hot.shape)","b6e4ee8e":"# we use count vectorizer to convert the values into one hot encoded features\nvectorizer = CountVectorizer(vocabulary=list(sorted_sub_cat_dict.keys()), lowercase=False, binary=True)\nvectorizer.fit(project_data['clean_subcategories'].values)\nprint(vectorizer.get_feature_names())\n\n\nsub_categories_one_hot = vectorizer.transform(project_data['clean_subcategories'].values)\nprint(\"Shape of matrix after one hot encodig \",sub_categories_one_hot.shape)","2a53e8ba":"my_counter_state = Counter()\nfor word in project_data['school_state'].values:\n    my_counter_state.update(word.split())","58acc2a2":"# dict sort by value python: https:\/\/stackoverflow.com\/a\/613218\/4084039\nstate_dict = dict(my_counter_state)\nsorted_state_dict = dict(sorted(my_counter_state.items(), key=lambda kv: kv[1]))","87f99658":"# we use count vectorizer to convert the values into one hot encoded features\nvectorizer = CountVectorizer(vocabulary=list(sorted_state_dict.keys()), lowercase=False, binary=True)\nvectorizer.fit(project_data['school_state'].values)\nprint(vectorizer.get_feature_names())\n\n\nstate_one_hot = vectorizer.transform(project_data['school_state'].values)\nprint(\"Shape of matrix after one hot encodig \",state_one_hot.shape)","470bce87":"my_counter_TeacherPrefix = Counter()\nfor word in project_data['teacher_prefix'].values:\n    word_str=str(word)\n    my_counter_TeacherPrefix.update(word_str.split())","b676b043":"# dict sort by value python: https:\/\/stackoverflow.com\/a\/613218\/4084039\nteacher_prefix_dict = dict(my_counter_TeacherPrefix)\nsorted_teacher_prefix_dict = dict(sorted(teacher_prefix_dict.items(), key=lambda kv: kv[1]))","d513cf33":"# we use count vectorizer to convert the values into one hot encoded features\nvectorizer = CountVectorizer(vocabulary=list(sorted_teacher_prefix_dict.keys()), lowercase=False, binary=True)\n#vectorizer.fit(project_data['teacher_prefix'].values)\n# the above line was showing error \"np.nan is an invalid document, expected byte or unicode string.\"\n#resource : https:\/\/stackoverflow.com\/questions\/39303912\/tfidfvectorizer-in-scikit-learn-valueerror-np-nan-is-an-invalid-document\n\nvectorizer.fit(project_data['teacher_prefix'].values.astype('U'))\n\nprint(vectorizer.get_feature_names())\n\nprint(\"*\"*50)\nteacher_prefix_one_hot = vectorizer.transform(project_data['teacher_prefix'].values.astype('U'))\nprint(\"Shape of matrix after one hot encodig \",teacher_prefix_one_hot.shape)","53c3a818":"my_counter_projgradcat = Counter()\nfor word in project_data['project_grade_category'].values:\n    my_counter_projgradcat.update(word.split())","1cd0d025":"# dict sort by value python: https:\/\/stackoverflow.com\/a\/613218\/4084039\nprojgrade_dict = dict(my_counter_projgradcat)\nsorted_projgrade_dict = dict(sorted(projgrade_dict.items(), key=lambda kv: kv[1]))\n\nsorted_projgrade_dict","32f1f081":"# we use count vectorizer to convert the values into one hot encoded features\nvectorizer = CountVectorizer(vocabulary=list(sorted_projgrade_dict.keys()), lowercase=False, binary=True)\nvectorizer.fit(project_data['project_grade_category'].values)\nprint(vectorizer.get_feature_names())\n\n\nproject_grade_category_one_hot = vectorizer.transform(project_data['project_grade_category'].values)\nprint(\"Shape of matrix after one hot encodig \",project_grade_category_one_hot.shape)","a21cf469":"# We are considering only the words which appeared in at least 10 documents(rows or projects).\nvectorizer = CountVectorizer(min_df=10)\ntext_bow = vectorizer.fit_transform(preprocessed_essays)\nprint(\"Shape of matrix after one hot encodig \",text_bow.shape)","cd0828ea":"# you can vectorize the title also \n# before you vectorize the title make sure you preprocess it\n# Similarly you can vectorize for title also\nvectorizer = CountVectorizer(min_df=10)\nprojtitle_bow = vectorizer.fit_transform(preprocessed_projecttitle)\nprint(\"Shape of matrix after one hot encodig \",projtitle_bow.shape)","b830b4ba":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(min_df=10)\ntext_tfidf = vectorizer.fit_transform(preprocessed_essays)\nprint(\"Shape of matrix after one hot encodig \",text_tfidf.shape)","dfd12c3c":"# Similarly you can vectorize for title also\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(min_df=10)\nprojecttitle_tfidf = vectorizer.fit_transform(preprocessed_projecttitle)\nprint(\"Shape of matrix after one hot encodig \",projecttitle_tfidf.shape)","c5856fe3":"'''\n# Reading glove vectors in python: https:\/\/stackoverflow.com\/a\/38230349\/4084039\ndef loadGloveModel(gloveFile):\n    print (\"Loading Glove Model\")\n    f = open(gloveFile,'r', encoding=\"utf8\")\n    model = {}\n    for line in tqdm(f):\n        splitLine = line.split()\n        word = splitLine[0]\n        embedding = np.array([float(val) for val in splitLine[1:]])\n        model[word] = embedding\n    print (\"Done.\",len(model),\" words loaded!\")\n    return model\nmodel = loadGloveModel(r'E:\\Applied-AI\\assignment-2-comp\\glove.42B.300d\\glove.42B.300d.txt')\n\n# ============================\n#Output:\n    \n#Loading Glove Model\n#1917495it [06:32, 4879.69it\/s]\n#Done. 1917495  words loaded!\n\n# ============================\n\nwords = []\nfor i in preprocessed_essays:\n    words.extend(i.split(' '))\n\nfor i in preprocessed_projecttitle:\n    words.extend(i.split(' '))\nprint(\"all the words in the coupus\", len(words))\nwords = set(words)\nprint(\"the unique words in the coupus\", len(words))\n\ninter_words = set(model.keys()).intersection(words)\nprint(\"The number of words that are present in both glove vectors and our coupus\", \\\n      len(inter_words),\"(\",np.round(len(inter_words)\/len(words)*100,3),\"%)\")\n\nwords_courpus = {}\nwords_glove = set(model.keys())\nfor i in words:\n    if i in words_glove:\n        words_courpus[i] = model[i]\nprint(\"word 2 vec length\", len(words_courpus))\n\n\n# stronging variables into pickle files python: http:\/\/www.jessicayung.com\/how-to-use-pickle-to-save-and-load-variables-in-python\/\n\nimport pickle\nwith open('glove_vectors', 'wb') as f:\n    pickle.dump(words_courpus, f)\n'''","48545e1f":"\n# stronging variables into pickle files python: http:\/\/www.jessicayung.com\/how-to-use-pickle-to-save-and-load-variables-in-python\/\n# make sure you have the glove_vectors file\nwith open('..\/input\/donors-chose\/glove_vectors', 'rb') as f:\n    model = pickle.load(f)\n    glove_words =  set(model.keys())    ","5c46172c":"# average Word2Vec\n# compute average word2vec for each review.\navg_w2v_vectors = []; # the avg-w2v for each sentence\/review is stored in this list\nfor sentence in tqdm(preprocessed_essays): # for each review\/sentence\n    vector = np.zeros(300) # as word vectors are of zero length\n    cnt_words =0; # num of words with a valid vector in the sentence\/review\n    for word in sentence.split(): # for each word in a review\/sentence\n        if word in glove_words:\n            vector += model[word]\n            cnt_words += 1\n    if cnt_words != 0:\n        vector \/= cnt_words\n    avg_w2v_vectors.append(vector)\n\nprint(len(avg_w2v_vectors))\nprint(len(avg_w2v_vectors[0]))","2732cef4":"# Similarly you can vectorize for title also\n# average Word2Vec\n# compute average word2vec for each review.\navg_w2v_vectors_projtitles = []; # the avg-w2v for each sentence\/review is stored in this list\nfor sentence in tqdm(preprocessed_projecttitle): # for each review\/sentence\n    vector = np.zeros(300) # as word vectors are of zero length\n    cnt_words =0; # num of words with a valid vector in the sentence\/review\n    for word in sentence.split(): # for each word in a review\/sentence\n        if word in glove_words:\n            vector += model[word]\n            cnt_words += 1\n    if cnt_words != 0:\n        vector \/= cnt_words\n    avg_w2v_vectors_projtitles.append(vector)\n\nprint(len(avg_w2v_vectors_projtitles))\nprint(len(avg_w2v_vectors_projtitles[0]))","93e8a202":"# S = [\"abc def pqr\", \"def def def abc\", \"pqr pqr def\"]\ntfidf_model = TfidfVectorizer()\ntfidf_model.fit(preprocessed_essays)\n# we are converting a dictionary with word as a key, and the idf as a value\ndictionary = dict(zip(tfidf_model.get_feature_names(), list(tfidf_model.idf_)))\ntfidf_words = set(tfidf_model.get_feature_names())","c0a7cadc":"# average Word2Vec\n# compute average word2vec for each review.\ntfidf_w2v_vectors = []; # the avg-w2v for each sentence\/review is stored in this list\nfor sentence in tqdm(preprocessed_essays): # for each review\/sentence\n    vector = np.zeros(300) # as word vectors are of zero length\n    tf_idf_weight =0; # num of words with a valid vector in the sentence\/review\n    for word in sentence.split(): # for each word in a review\/sentence\n        if (word in glove_words) and (word in tfidf_words):\n            vec = model[word] # getting the vector for each word\n            # here we are multiplying idf value(dictionary[word]) and the tf value((sentence.count(word)\/len(sentence.split())))\n            tf_idf = dictionary[word]*(sentence.count(word)\/len(sentence.split())) # getting the tfidf value for each word\n            vector += (vec * tf_idf) # calculating tfidf weighted w2v\n            tf_idf_weight += tf_idf\n    if tf_idf_weight != 0:\n        vector \/= tf_idf_weight\n    tfidf_w2v_vectors.append(vector)\n\nprint(len(tfidf_w2v_vectors))\nprint(len(tfidf_w2v_vectors[0]))","68ca41dd":"# Similarly you can vectorize for title also\n# S = [\"abc def pqr\", \"def def def abc\", \"pqr pqr def\"]\ntfidf_model = TfidfVectorizer()\ntfidf_model.fit(preprocessed_projecttitle)\n# we are converting a dictionary with word as a key, and the idf as a value\ndictionary = dict(zip(tfidf_model.get_feature_names(), list(tfidf_model.idf_)))\ntfidf_words_projtitle = set(tfidf_model.get_feature_names())","0010f324":"# average Word2Vec\n# compute average word2vec for each review.\ntfidf_w2v_vectors_projtitle = []; # the avg-w2v for each sentence\/review is stored in this list\nfor sentence in tqdm(preprocessed_projecttitle): # for each review\/sentence\n    vector = np.zeros(300) # as word vectors are of zero length\n    tf_idf_weight =0; # num of words with a valid vector in the sentence\/review\n    for word in sentence.split(): # for each word in a review\/sentence\n        if (word in glove_words) and (word in tfidf_words):\n            vec = model[word] # getting the vector for each word\n            # here we are multiplying idf value(dictionary[word]) and the tf value((sentence.count(word)\/len(sentence.split())))\n            tf_idf = dictionary[word]*(sentence.count(word)\/len(sentence.split())) # getting the tfidf value for each word\n            vector += (vec * tf_idf) # calculating tfidf weighted w2v\n            tf_idf_weight += tf_idf\n    if tf_idf_weight != 0:\n        vector \/= tf_idf_weight\n    tfidf_w2v_vectors_projtitle.append(vector)\n\nprint(len(tfidf_w2v_vectors_projtitle))\nprint(len(tfidf_w2v_vectors_projtitle[0]))","79c6b081":"# check this one: https:\/\/www.youtube.com\/watch?v=0HOqOcln3Z4&t=530s\n# standardization sklearn: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.StandardScaler.html\nfrom sklearn.preprocessing import StandardScaler\n\n# price_standardized = standardScalar.fit(project_data['price'].values)\n# this will rise the error\n# ValueError: Expected 2D array, got 1D array instead: array=[725.05 213.03 329.   ... 399.   287.73   5.5 ].\n# Reshape your data either using array.reshape(-1, 1)\n\nprice_scalar = StandardScaler()\nprice_scalar.fit(project_data['price'].values.reshape(-1,1)) # finding the mean and standard deviation of this data\nprint(f\"Mean : {price_scalar.mean_[0]}, Standard deviation : {np.sqrt(price_scalar.var_[0])}\")\n\n# Now standardize the data with above maen and variance.\nprice_standardized = price_scalar.transform(project_data['price'].values.reshape(-1, 1))","c3ce96e6":"price_standardized","5a1742d3":"PrevPostedPorjects_scalar = StandardScaler()\nPrevPostedPorjects_scalar.fit(project_data['teacher_number_of_previously_posted_projects'].values.reshape(-1,1)) # finding the mean and standard deviation of this data\nprint(f\"Mean : {PrevPostedPorjects_scalar.mean_[0]}, Standard deviation : {np.sqrt(PrevPostedPorjects_scalar.var_[0])}\")\n\n# Now standardize the data with above maen and variance.\nPrevPostedPorjects_standardized = PrevPostedPorjects_scalar.transform(project_data['teacher_number_of_previously_posted_projects'].values.reshape(-1, 1))","ebf6cf9b":"PrevPostedPorjects_standardized","6d68ecd0":"print(categories_one_hot.shape)\nprint(sub_categories_one_hot.shape)\nprint(state_one_hot.shape)\nprint(project_grade_category_one_hot.shape)\nprint(teacher_prefix_one_hot.shape)\nprint(projtitle_bow.shape)\nprint(projecttitle_tfidf.shape)\n#print(avg_w2v_vectors_projtitles.shape)\n#print(tfidf_w2v_vectors_projtitle.shape)\nprint(price_standardized.shape)\nprint(PrevPostedPorjects_standardized.shape)","40c651c8":"# merge two sparse matrices: https:\/\/stackoverflow.com\/a\/19710648\/4084039\nfrom scipy.sparse import hstack\n# with the same hstack function we are concatinating a sparse matrix and a dense matirx :)\nX = hstack((categories_one_hot, sub_categories_one_hot,state_one_hot,project_grade_category_one_hot,teacher_prefix_one_hot, projtitle_bow,projecttitle_tfidf,avg_w2v_vectors_projtitles,tfidf_w2v_vectors_projtitle, price_standardized,PrevPostedPorjects_standardized))\nX.shape","8f26e9a6":"# this is the example code for TSNE\nimport numpy as np\nfrom sklearn.manifold import TSNE\nfrom sklearn import datasets\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\niris = datasets.load_iris()\nx = iris['data']\ny = iris['target']\n\ntsne = TSNE(n_components=2, perplexity=30, learning_rate=200)\n\nX_embedding = tsne.fit_transform(x)\n# if x is a sparse matrix you need to pass it as X_embedding = tsne.fit_transform(x.toarray()) , .toarray() will convert the sparse matrix into dense matrix\n\nfor_tsne = np.hstack((X_embedding, y.reshape(-1,1)))\nfor_tsne_df = pd.DataFrame(data=for_tsne, columns=['Dimension_x','Dimension_y','Score'])\ncolors = {0:'red', 1:'blue', 2:'green'}\nplt.scatter(for_tsne_df['Dimension_x'], for_tsne_df['Dimension_y'], c=for_tsne_df['Score'].apply(lambda x: colors[x]))\nplt.show()","9387eb0b":"# please write all of the code with proper documentation and proper titles for each subsection\n# when you plot any graph make sure you use \n    # a. Title, that describes your plot, this will be very helpful to the reader\n    # b. Legends if needed\n    # c. X-axis label\n    # d. Y-axis label\n    \nfrom sklearn.manifold import TSNE\nfrom sklearn import datasets\n\n    \nx = hstack((categories_one_hot, sub_categories_one_hot,state_one_hot,project_grade_category_one_hot,teacher_prefix_one_hot, projtitle_bow, price_standardized,PrevPostedPorjects_standardized),format='csr').toarray()\nx = x[0:10000]\ny = project_data['project_is_approved']\ny = y[0:10000]\n\ntsne = TSNE(n_components=2, perplexity=100, random_state=0)\n\ntsne_data_bow = tsne.fit_transform(x)\ntsne_data_bow= np.vstack((tsne_data_bow.T, y)).T\ntsne_df_bow = pd.DataFrame(data=tsne_data_bow, columns=(\"Dimension_x\", \"Dimension_y\", \"Approved\"))\nsns.FacetGrid(tsne_df_bow, hue=\"Approved\", height=6).map(plt.scatter, 'Dimension_x', 'Dimension_y').add_legend()\nplt.title('TSNE with all Numerical, categorical feature and BOW encoding of PROJECT_TITLE feature')\nplt.show()    ","ac95beb1":"'''\n#please write all the code with proper documentation, and proper titles for each subsection\n# when you plot any graph make sure you use \n    # a. Title, that describes your plot, this will be very helpful to the reader\n    # b. Legends if needed\n    # c. X-axis label\n    # d. Y-axis label\n    \nx = hstack((categories_one_hot, sub_categories_one_hot,state_one_hot,project_grade_category_one_hot,teacher_prefix_one_hot,projecttitle_tfidf,price_standardized,PrevPostedPorjects_standardized),format='csr').toarray()\nx = x[0:6000]\ny = project_data['project_is_approved']\ny = y[0:6000]\n\ntsne = TSNE(n_components=2, perplexity=100, random_state=0)\n\ntsne_data_bow = tsne.fit_transform(x)\ntsne_data_bow= np.vstack((tsne_data_bow.T, y)).T\ntsne_df_bow = pd.DataFrame(data=tsne_data_bow, columns=(\"Dimension_x\", \"Dimension_y\", \"Approved\"))\nsns.FacetGrid(tsne_df_bow, hue=\"Approved\", height=6).map(plt.scatter, 'Dimension_x', 'Dimension_y').add_legend()\nplt.title('TSNE with all Numerical, categorical feature and TFIDF encoding of PROJECT_TITLE feature')\nplt.show()  \n'''","41470551":"'''\n# please write all the code with proper documentation, and proper titles for each subsection\n# when you plot any graph make sure you use \n    # a. Title, that describes your plot, this will be very helpful to the reader\n    # b. Legends if needed\n    # c. X-axis label\n    # d. Y-axis label\n#categories_one_hot, sub_categories_one_hot,state_one_hot,project_grade_category_one_hot,teacher_prefix_one_hot, projtitle_bow,projecttitle_tfidf,avg_w2v_vectors_projtitles,tfidf_w2v_vectors_projtitle, price_standardized,PrevPostedPorjects_standardized\n\nx = hstack((categories_one_hot, sub_categories_one_hot,state_one_hot,project_grade_category_one_hot,teacher_prefix_one_hot,avg_w2v_vectors_projtitles,price_standardized,PrevPostedPorjects_standardized),format='csr').toarray()\nx = x[0:15000]\ny = project_data['project_is_approved']\ny = y[0:15000]\n\ntsne = TSNE(n_components=2, perplexity=100, random_state=0)\n\ntsne_data_bow = tsne.fit_transform(x)\ntsne_data_bow= np.vstack((tsne_data_bow.T, y)).T\ntsne_df_bow = pd.DataFrame(data=tsne_data_bow, columns=(\"Dimension_x\", \"Dimension_y\", \"Approved\"))\nsns.FacetGrid(tsne_df_bow, hue=\"Approved\", height=6).map(plt.scatter, 'Dimension_x', 'Dimension_y').add_legend()\nplt.title('TSNE with all Numerical, categorical feature and AVG W2V encoding of PROJECT_TITLE feature')\nplt.show()   \n'''","734ee5ba":"'''\n# please write all the code with proper documentation, and proper titles for each subsection\n# when you plot any graph make sure you use \n    # a. Title, that describes your plot, this will be very helpful to the reader\n    # b. Legends if needed\n    # c. X-axis label\n    # d. Y-axis label\nx = hstack((categories_one_hot, sub_categories_one_hot,state_one_hot,project_grade_category_one_hot,teacher_prefix_one_hot, tfidf_w2v_vectors_projtitle, price_standardized,PrevPostedPorjects_standardized),format='csr').toarray()\nx = x[0:15000]\ny = project_data['project_is_approved']\ny = y[0:15000]\n\ntsne = TSNE(n_components=2, perplexity=100, random_state=0)\n\ntsne_data_bow = tsne.fit_transform(x)\ntsne_data_bow= np.vstack((tsne_data_bow.T, y)).T\ntsne_df_bow = pd.DataFrame(data=tsne_data_bow, columns=(\"Dimension_x\", \"Dimension_y\", \"Approved\"))\nsns.FacetGrid(tsne_df_bow, hue=\"Approved\", height=6).map(plt.scatter, 'Dimension_x', 'Dimension_y').add_legend()\nplt.title('TSNE with all Numerical, categorical feature and TFIDF Weighted W2V encoding of PROJECT_TITLE feature')\nplt.show()   \n'''  ","d5b497f2":"# please write all the code with proper documentation, and proper titles for each subsection\n# when you plot any graph make sure you use \n    # a. Title, that describes your plot, this will be very helpful to the reader\n    # b. Legends if needed\n    # c. X-axis label\n    # d. Y-axis label\nx = hstack((categories_one_hot, sub_categories_one_hot,state_one_hot,project_grade_category_one_hot,teacher_prefix_one_hot,projtitle_bow,projecttitle_tfidf,avg_w2v_vectors_projtitles,tfidf_w2v_vectors_projtitle,price_standardized,PrevPostedPorjects_standardized),format='csr').toarray()\nx = x[0:5000]\ny = project_data['project_is_approved']\ny = y[0:5000]\n\ntsne = TSNE(n_components=2, perplexity=100, random_state=0)\n\ntsne_data_bow = tsne.fit_transform(x)\ntsne_data_bow= np.vstack((tsne_data_bow.T, y)).T\ntsne_df_bow = pd.DataFrame(data=tsne_data_bow, columns=(\"Dimension_x\", \"Dimension_y\", \"Approved\"))\nsns.FacetGrid(tsne_df_bow, hue=\"Approved\", height=6).map(plt.scatter, 'Dimension_x', 'Dimension_y').add_legend()\nplt.title('TSNE with all Numerical, categorical feature and all verctors of PROJECT_TITLE feature')\nplt.show()  ","abc0483a":"### 3.4 one Hot Encoding of Teacher Prefix","388aa015":"Analysis --> 85% of projects does not have any numeric digit in the resource summary while the rest 85% have numneric digit","b3f00535":"<p>\nDonorsChoose.org receives hundreds of thousands of project proposals each year for classroom projects in need of funding. Right now, a large number of volunteers is needed to manually screen each submission before it's approved to be posted on the DonorsChoose.org website.\n<\/p>\n<p>\n    Next year, DonorsChoose.org expects to receive close to 500,000 project proposals. As a result, there are three main problems they need to solve:\n<ul>\n<li>\n    How to scale current manual processes and resources to screen 500,000 projects so that they can be posted as quickly and as efficiently as possible<\/li>\n    <li>How to increase the consistency of project vetting across different volunteers to improve the experience for teachers<\/li>\n    <li>How to focus volunteer time on the applications that need the most assistance<\/li>\n    <\/ul>\n<\/p>    \n<p>\nThe goal of the competition is to predict whether or not a DonorsChoose.org project proposal submitted by a teacher will be approved, using the text of project descriptions as well as additional metadata about the project, teacher, and school. DonorsChoose.org can then use this information to identify projects most likely to need further review before approval.\n<\/p>","ebc4e200":"### 1.3.1 Essay Text","3c9dfe32":"<h2> 2.3 TSNE with `AVG W2V` encoding of `project_title` feature (15k) records [commented] <\/h2>","9d0059eb":"**Analysis**\n\nif we look at the above Percentile table, we would come to know that for all the Percentils the Cost of rejected Projects is Higher than the Cost of Rejeced Projects which means project with large cost are tends to get rejected\n\nas will move from 0 Percentile to 95% the price difference is getting increased between Approved and Rejected Projects. \n\nif we look at the 95 percentild of Approved project, the value is \\\\$801.59 which says even if the highest cost can be \\\\$9999.00 but 95% of Approve projects only have cosrt less than \\\\$801.59 and only 5% of approve projecrts has cost between \\\\$802.00 to \\\\$9999.00\n","c6099836":"# 1.2 Data Analysis","838b6d73":"### 1.2.3 Univariate Analysis: project_grade_category","ec7f16a4":"- https:\/\/www.appliedaicourse.com\/course\/applied-ai-course-online\/lessons\/handling-categorical-and-numerical-features\/","8fbc621e":"**Analysis**\n\nsince the points overlapping both classes and class \"0\" is not visibile, we cannot analayse anything from the t-SNE plot\n\ntaking larger sets of data for the plot might work","fda57d7c":"<h1><font color='red'>Assignment 2: Apply TSNE<font><\/h1>","f277ff00":"### 1.2.2 Univariate Analysis: teacher_prefix","80a6aa0a":"**Analysis**\nproject which doesn't have numeric value in the resource field 84 % approval rate \n\nproject which has numeric value in the resource summry hase 89% approaval rate which is 5% higher than project without any numeric field in resource_summary column which somehow indicates that project with numeric value in resource_summary field has hgiher chances of approval","4d4ba038":"**Analysis**\n\n--> there are total 30 distinct subcategories in the entire data sets\n\n--> if we lokk at the list above, we find that there is too much variability in project submission and approval for distinct subcategories. \n\n--> the subcategory \"Economics\" has very less no of project as compared to \"Literacy\" Subcategory which has around 33700 Project which is around more than 100 times to that of \"econmics\"\n\n--> only 0.15% of project submitted have \"Economics\" as Subcategories\" while more than 19% of Project submitted has \"Literacy\" as Sub Category ","5b578db4":"### 1.2.5 Univariate Analysis: project_subject_subcategories","0bdd0b62":"# DonorsChoose","ee7000e4":"### 1.4.1 Vectorizing Categorical data","e553decb":"\n1) there are total of 109248 Data Points out of which 92706 i.e. nearly 85% of belongs to Positive class (Approved Project) and remaining 15% belongs to \"Rejected\" Projects\n\n2) state Vermont,District of Columbia, Texas , Monotana, Los Angles have minimal approval rate within 80-83 % approval rate. on the other side state New Hampshire, Ohio, Washington, North Dakota, Delaware are top 5 states where approval rates are high\n\n3). every state has more than 80% of Approval rate. \n\n4). highest nukber of Project has been submitted from California with project count of 15388 followed by Texas from where 7396 project has been submitted.\n\n5) state of Vermont lies at the bottom of the list both in the terms of number of Project and Approval rate. only 80 pojects has been submitted from the state and has approval rate of around 80%\n\n6) Teacher with Prefix \"Mrs\" has submitted heighest number of project i.e. 57269 with approval rating of 85.5% whereas Teacher with prefix Doctor \"Dr.\" has submitted just 13 projects with approval rate of 69% percent\n\n7).project approval rate among all the grade range of student is almost same i.e arround 83-86% percent. Student between grade 9 to 12 have submitted less projects as comared to Prek-2 and Grade 3-5 students\n\n8) there is lots of variability in number of project submmitted and approvd among different categories. the top three categories on which there is highest number of Project belongs to \"Lietacy and Literature\" , \"Math and Science\" or the combination og both categieries. while Health & sports with Literacy & language has very less number of submission\n\n9). category Literacy & Language has been used 52239 times or we can say in 52239 Project whereas category \"care & Hunger\" has been used only in 1388 Projects. this can be one of the important feature to predict whether a Project will be approved or not\n\n10).if you look at the top 5 subcategories which has highest submission and approval all are single or combination of \"Literacy\" , \"Mathematics\" and \"Literature\"\n\n11). there are total 30 distinct subcategories in the entire data sets\n\n12). the subcategory \"Economics\" has very less no of project as compared to \"Literacy\" Subcategory which has around 33700 Project which is around more than 100 times to that of \"econmics\". only 0.15% of project submitted have \"Economics\" as Subcategories\" while more than 19% of Project submitted has \"Literacy\" as Sub Category\n\n13).for all the Percentils the Cost of rejected Projects is Higher than the Cost of Rejeced Projects which means project with large cost are tends to get rejected also as will move from 0 Percentile to 95% the price difference is getting increased between Approved and Rejected Projects.\n\n14).most of the Project that has been Submitted is being submitted first time by any teacher.even though the number of projects submitted by teacher who has previously submitted project is very low , but if you look at the number it tells that teacher who has submitted more than 15 projects earlier. the acceptance rate is more than 86% and it increases as the number of fearture valriable increase. it says that this feature plays good role in deciding whether the project will be approved or not\n\n15)the minimum number of word that a project resource summary has is 4 while the maximum word in any summary is 137. more than 10000 projects has word count of 11. Majority of Project have word count between 11 to 31\n\n16). project which has numeric value in the resource summry hase 89% approaval rate which is 5% higher than project without any numeric field in resource_summary column which somehow indicates that project with numeric value in resource_summary field has hgiher chances of approval\n\n17). there are total 5 features which are categorical, 3 columns {price, teacher_number_of_previously_posted_projects} which are numerical and 2 text columns {essays,Project_title} which we have considered in tSNE Plot\n\n18) after convertinf all the features to numerical vector we have created tSNE plot using all the Categorical and Numerical feature along with differnet numerical vector {BOW, TFIDF, avg-W2v and TFIDF W2v} individually with all the numerical and Categorical feature we didn't find much sense from the tSNE plot. we have considered 15k Data Points for TSNE plot\n\n19). later we combined all the vector together and plotted tSNE, but still not find any plot that could help us in diffentiating between the class lables since the plots are overlapping","6dc7443a":"<h4><font color='red'> 1.4.2.2 Bag of Words on `project_title`<\/font><\/h4>","6de17fe8":"**Analysis from above bar plots**\n\n--> most of the Project that has been Submitted is being submitted first time by any teacher\n\n-->there are good chunks of number of Projects submitted lies between range 1 to 4. which says a good number of projects has been submitted by teacher who has submitted 1 to 4 projects in the past\n\n--> even though the number of projects submitted by teacher who has previously submitted project is very low , but if you look at the number it tells that teacher who has submitted more than 15 projects earlier. the acceptance rate is more than 86% and it increases as the number of fearture valriable increase. \nit says that this feature plays good role in deciding whether the project will be approved or not","88debfa9":"## 1. 4 Preparing data for models","38d9e586":"<h3><font color='red'>1.2.10 Univariate Analysis: project_resource_summary<\/font><\/h3>","faae86db":"if we look at the above summary we can colnclude two thing\n\n1). State Vermont has lowest Approval rate with 80% and Delaware has highest approval rate of around 90%\n\n2). even though our average approval rate is close to 85%, the variablity in approval rate lies between 80% to 90% which means \nthis feature plays a important role in deciding whether the project may or may not get approval","9feed942":"### 1.2.1 Univariate Analysis: School State","82661a37":"### 3.5 one Hot Encoding of project_grade_category","2be3af1a":"<h2> 2.2 TSNE with `TFIDF` encoding of `project_title` feature (6k) records [Commented] <\/h2>","a33010ab":"**Analysis**\n\nearlier we looked at projects with group of categories. but after calculating the word counter for each individual word\/categories we found that there is too much variablity in the project with different unique categories\n\ncategory Literacy & Language has been used 52239 times or we can say in 52239 Project whereas category \"care & Hunger\" has been used only in 1388 Projects\n\nthis can be one of the important feature to predict whether a Project will be approved or not","17c400ca":"## About the DonorsChoose Data Set\n\nThe `train.csv` data set provided by DonorsChoose contains the following features:\n\nFeature | Description \n----------|---------------\n**`project_id`** | A unique identifier for the proposed project. **Example:** `p036502`   \n**`project_title`**    | Title of the project. **Examples:**<br><ul><li><code>Art Will Make You Happy!<\/code><\/li><li><code>First Grade Fun<\/code><\/li><\/ul> \n**`project_grade_category`** | Grade level of students for which the project is targeted. One of the following enumerated values: <br\/><ul><li><code>Grades PreK-2<\/code><\/li><li><code>Grades 3-5<\/code><\/li><li><code>Grades 6-8<\/code><\/li><li><code>Grades 9-12<\/code><\/li><\/ul>  \n **`project_subject_categories`** | One or more (comma-separated) subject categories for the project from the following enumerated list of values:  <br\/><ul><li><code>Applied Learning<\/code><\/li><li><code>Care &amp; Hunger<\/code><\/li><li><code>Health &amp; Sports<\/code><\/li><li><code>History &amp; Civics<\/code><\/li><li><code>Literacy &amp; Language<\/code><\/li><li><code>Math &amp; Science<\/code><\/li><li><code>Music &amp; The Arts<\/code><\/li><li><code>Special Needs<\/code><\/li><li><code>Warmth<\/code><\/li><\/ul><br\/> **Examples:** <br\/><ul><li><code>Music &amp; The Arts<\/code><\/li><li><code>Literacy &amp; Language, Math &amp; Science<\/code><\/li>  \n  **`school_state`** | State where school is located ([Two-letter U.S. postal code](https:\/\/en.wikipedia.org\/wiki\/List_of_U.S._state_abbreviations#Postal_codes)). **Example:** `WY`\n**`project_subject_subcategories`** | One or more (comma-separated) subject subcategories for the project. **Examples:** <br\/><ul><li><code>Literacy<\/code><\/li><li><code>Literature &amp; Writing, Social Sciences<\/code><\/li><\/ul> \n**`project_resource_summary`** | An explanation of the resources needed for the project. **Example:** <br\/><ul><li><code>My students need hands on literacy materials to manage sensory needs!<\/code<\/li><\/ul> \n**`project_essay_1`**    | First application essay<sup>*<\/sup>  \n**`project_essay_2`**    | Second application essay<sup>*<\/sup> \n**`project_essay_3`**    | Third application essay<sup>*<\/sup> \n**`project_essay_4`**    | Fourth application essay<sup>*<\/sup> \n**`project_submitted_datetime`** | Datetime when project application was submitted. **Example:** `2016-04-28 12:43:56.245`   \n**`teacher_id`** | A unique identifier for the teacher of the proposed project. **Example:** `bdf8baa8fedef6bfeec7ae4ff1c15c56`  \n**`teacher_prefix`** | Teacher's title. One of the following enumerated values: <br\/><ul><li><code>nan<\/code><\/li><li><code>Dr.<\/code><\/li><li><code>Mr.<\/code><\/li><li><code>Mrs.<\/code><\/li><li><code>Ms.<\/code><\/li><li><code>Teacher.<\/code><\/li><\/ul>  \n**`teacher_number_of_previously_posted_projects`** | Number of project applications previously submitted by the same teacher. **Example:** `2` \n\n<sup>*<\/sup> See the section <b>Notes on the Essay Data<\/b> for more details about these features.\n\nAdditionally, the `resources.csv` data set provides more data about the resources required for each project. Each line in this file represents a resource required by a project:\n\nFeature | Description \n----------|---------------\n**`id`** | A `project_id` value from the `train.csv` file.  **Example:** `p036502`   \n**`description`** | Desciption of the resource. **Example:** `Tenor Saxophone Reeds, Box of 25`   \n**`quantity`** | Quantity of the resource required. **Example:** `3`   \n**`price`** | Price of the resource required. **Example:** `9.95`   \n\n**Note:** Many projects require multiple resources. The `id` value corresponds to a `project_id` in train.csv, so you use it as a key to retrieve all resources needed for a project:\n\nThe data set contains the following label (the value you will attempt to predict):\n\nLabel | Description\n----------|---------------\n`project_is_approved` | A binary flag indicating whether DonorsChoose approved the project. A value of `0` indicates the project was not approved, and a value of `1` indicates the project was approved.","e4049fe0":"<h4><font color='red'> 1.4.2.9 Using Pretrained Models: TFIDF weighted W2V on `project_title`<\/font><\/h4>","ee611aa1":"**Summary**\n\n--> grade level of students doesn't make much impact on Project approval rate. since all the grades has almost similar approval rate of around 83-85%\n\n--> but the project submitted by Grade Prek-2 students are slightly higher\n\n--> Student between grade 9 to 12 have submitted less projects as comared to Prek-2 and Grade 3-5 students","0ffaccfd":"<h2> 2.5 Summary <\/h2>","3530abae":"**Analysis**\n\nif we look at the box plot of project distributions for feature \"Word count in Title\", we find that median of both the Approved and Rejected Projects are almost same i.e. close to 5\n\nbut box plot of approved project is slightly high as Compared to Rejected Proeject class which indicates that number of words in Project title is slightly more than number of words in Project title for Rejected Projects","71c4411d":"### 1.2.6 Univariate Analysis: Text features (Title)","7dbb0742":"**Analysis --> from the above pie plot Number of Projects that are accepted are around 85% which much higher than number of projects which are rejected.**","7e1d66ef":"### 1.4.2 Vectorizing Text data","bdd2e568":"**Analysis**\n\nfrom the above percentile table we can see that all the percentiles has almost similar word counts in both approved and rejected categiories \n\nbut if we look at the 75% percentile, the 75% of approved projects have word count less than equal to 26","bbf5e9c7":"**Analysis*\n\njust like Box Plot, even the pdf plot don't tell anything much about the impace of cost on Project Approval or rejection since it override each other at post of the part of plot\n\n--> but if you look at the end part, tail of rejected project is slightly ahead of approved projects ,which says if the cst of project is high afyer certain price level, the rejections are more","177922cf":"**__SUMMARY**\n1) Every state has greater than 80% success rate in approval__\n\n2)highest number of Projects has been submitted from state  of California and lowest number of Projects has been Submitted from state of Vermont","b94e5f3e":"**Analysis**\n\neven after combing all the numberical and Categoriacal features with all diffferent vectors of Project_title we cann see much difference in the plot. only \"approved\" labels are visibile. \n\nalso since we have taken only 15k points for the plots and the truth that only 15% of our actual data sets are negative. \nthere are high chances that most of the records in our selected data are \"Approved\" class. hence the tSNE plot might not shows \"rejected\" labels that are way from \"Approved\" labels\"","167147a9":"**Analysis** \n\nMean Cost per Project is around \\\\$298.00 and Standered deviation is \\\\$367.5","7967390f":"**Analysis**\n\nsince the points overlapping both classes and class \"0\" is not visibile, we cannot analayse anything from the t-SNE plot\n\ntaking larger sets of data for the plot might work","b4b5bb20":"<h2> 2.4 TSNE with `TFIDF Weighted W2V` encoding of `project_title` feature (15k) records [commented] <\/h2>","7846da5e":"**Analysis**\n\nthe pdf for Approved projects move slightly ahead against rejected projects which says that teachers who have submiited the Projects earlier before current submission, the acceptance rate of such project is higher","11d22edd":"#### 1.4.2.7 Using Pretrained Models: TFIDF weighted W2V","679010ce":"## 1.1 Reading Data","2f708328":"### 1.4.3 Vectorizing Numerical features","ab9c6edd":"**Analysis**\n\nthe above plot shows almost similar analysis to that of Box plot\n\n--> the plot of Approved Projects is slightly ahead of Rejected Projects which says projects whose Word Count in the essay is higher has high chances of geeting approved","bdbc7db8":"**Analysis**\n\n=> the minimum number of word that a project resource summary has is 4 while the maximum word in any summary is 137\n\n=> even though the variance in the word count is from 4 to 137 but majority of project has word count between 11-15\n\n=> more than 10000 projects has word count of 11\n\n==> Majority of Project have word count between 11 to 31","ee35bb98":"**Analysis**\n\nfrom the above plot we can find that there is lot of variance in the total word count in Project title. project title with 1 word and more than 10 words are very very less or alomost negligible. wherease most of the project submission belongs to project which has project title between 3-7 words ","fa191860":"<h4><font color='red'> 1.4.2.6 Using Pretrained Models: AVG W2V on `project_title`<\/font><\/h4>","b322b8c0":" <font color=#F4274F>If you are using any code snippet from the internet, you have to provide the reference\/citations, as we did in the above cells. Otherwise, it will be treated as plagiarism without citations.<\/font>","98caf6c5":"### 3.1 one Hot Encoding of School State","7deffaa2":"### 1.2.4 Univariate Analysis: project_subject_categories","6099c6fe":"<h3><font color='red'>1.3.2 Project title Text<\/font><\/h3>","b2356927":"- we need to merge all the numerical vectors i.e catogorical, text, numerical vectors","cf96ba66":"**Analysis**\n\n--> boxplot don't depict much about the relation of Approvals and rejection of projects  with \"number of project submitted by teacher earlier\" because the number of projects which is submitted by teacher who has never submitted any projects before or have submitted only 1 or 2 projects before are much much higher","88db913c":"### checking the prsence of mumerical digit in Project Resource Summary","6049d2f6":"<h3><font color='red'>1.2.9 Univariate Analysis: teacher_number_of_previously_posted_projects<\/font><\/h3>","fdc4ff03":"### 1.2.7 Univariate Analysis: Text features (Project Essay's)","510775dd":"#### 1.4.2.3 TFIDF vectorizer","3197dc98":"### 1.4.4 Merging all the above features","54d2c2ec":"**Analysis**\n\nthe box plots for \"COst of Project\" is quite messy and gives no idea about the impace of cost of project on the whether the project was approved or not","e8416024":"<ol> \n    <li> In the above cells we have plotted and analyzed many features. Please observe the plots and write the observations in markdown cells below every plot.<\/li>\n    <li> EDA: Please complete the analysis of the feature: teacher_number_of_previously_posted_projects<\/li>\n    <li>\n        <ul>Build the data matrix using these features \n            <li>school_state : categorical data (one hot encoding)<\/li>\n            <li>clean_categories : categorical data (one hot encoding)<\/li>\n            <li>clean_subcategories : categorical data (one hot encoding)<\/li>\n            <li>teacher_prefix : categorical data (one hot encoding)<\/li>\n            <li>project_grade_category : categorical data (one hot encoding)<\/li>\n            <li>project_title : text data (BOW, TFIDF, AVG W2V, TFIDF W2V)<\/li>\n            <li>price : numerical<\/li>\n            <li>teacher_number_of_previously_posted_projects : numerical<\/li>\n         <\/ul>\n    <\/li>\n    <li> Now, plot FOUR t-SNE plots with each of these feature sets.\n        <ol>\n            <li>categorical, numerical features + project_title(BOW)<\/li>\n            <li>categorical, numerical features + project_title(TFIDF)<\/li>\n            <li>categorical, numerical features + project_title(AVG W2V)<\/li>\n            <li>categorical, numerical features + project_title(TFIDF W2V)<\/li>\n        <\/ol>\n    <\/li>\n    <li> Concatenate all the features and Apply TNSE on the final data matrix <\/li>\n    <li> <font color='blue'>Note 1: The TSNE accepts only dense matrices<\/font><\/li>\n    <li> <font color='blue'>Note 2: Consider only 5k to 6k data points to avoid memory issues. If you run into memory error issues, reduce the number of data points but clearly state the number of datat-poins you are using<\/font><\/li>\n<\/ol>","e928c565":"**Analysis**\n--> the PDF plot and Boxplot indticates almost similar thing i.e.\n\nsince the plot of Approved project is slightly ahead of Rejected Projectes, which means word count in Approved projects are slighlty higher than word count in rejected Proijects","3b4e5929":"**Analysis**\n\n--> even though the median of Rejected and Approved Projects are almost similar ,we can see that box of Approve Projects are\n\n--> 75% percents of approved projects have word count less or equal to 295 words while 75% of rejected projects have word count less than or equal to 275 words\n\n--> higher than that of rejeced Projects which says projects with higher number of word counnts have higher chances of getting approved","96712b5d":"### 1.2.8 Univariate Analysis: Cost per project","ea556fe8":"**Analysis**\n\n--> even in the subcategories there is lot og variablity in the data\n\n--> the Subcategory \"Literacy\" have highest number of submission and approval and even the approval rate is arounf 88% percent\n\n--> if you look at the top 5 subcategories which has highest submission and approval all are single or combination of \"Literacy\" , \"Mathematics\" and \"Literature\"\n\n--> while the subcategories that have least submission ranges from 330 t0 389 project whixh is very less as compared to the highest subcategories Project. so the variance in the Project submission is high\n","649a9d7a":"we are going to consider\n\n       - school_state : categorical data\n       - clean_categories : categorical data\n       - clean_subcategories : categorical data\n       - project_grade_category : categorical data\n       - teacher_prefix : categorical data\n       \n       - project_title : text data\n       - text : text data\n       - project_resource_summary: text data\n       \n       - quantity : numerical\n       - teacher_number_of_previously_posted_projects : numerical\n       - price : numerical","d3e7b7af":"<h2> 2.5 TSNE with all the Vectors `project_title` feature 15k records <\/h2>","125bbf6a":"#### 1.4.2.1 Bag of words","6f5db686":"**Analysis from Above plot**\n\n--> there is lots of variability in number of project submmitted and approvd among different categories\n\n--> the top three categories on which there is highest number of Project belongs to \"Lietacy and Literature\" , \"Math and Science\" or the combination og both categieries\n\n--> most of the projects that have highest number of submission and approval have atleast two categories\n\n--> even though there is less submission of project for \"warmth\" \"care & Hunger\" but the approval rate is around 93%\n\n--> Health & sports with Literacy & language has very less number of submission","67209f39":"**Analysis from above plot**\n--> number of Unique prefix's are 5\n\n--> teacher whose prefix are \"Mrs.\" have higher number of Project Submission and also Higher Submission rate of 85%\n\n--> Prefix \"Ms.\" and \"Mr.\" has alomost similar rate of Project approval but but slighlty low as compared to \"Mrs.\"\n\n--> Doctors have low approval rate of 69% as compared to \"Mrs\", \"Mr\" and \"Ms.\". but the project submitted by them is also very low. it just 14","d6366cee":"<h4><font color='red'> 1.4.2.4 TFIDF Vectorizer on `project_title`<\/font><\/h4>","da31f562":"## 1.3 Text preprocessing","4854a63c":"#### 1.4.2.5 Using Pretrained Models: Avg W2V","b9966f31":"<h2> 2.1 TSNE with `BOW` encoding of `project_title` feature (10k) recrods <\/h2>","52a63acf":"### Notes on the Essay Data\n\n<ul>\nPrior to May 17, 2016, the prompts for the essays were as follows:\n<li>__project_essay_1:__ \"Introduce us to your classroom\"<\/li>\n<li>__project_essay_2:__ \"Tell us more about your students\"<\/li>\n<li>__project_essay_3:__ \"Describe how your students will use the materials you're requesting\"<\/li>\n<li>__project_essay_4:__ \"Close by sharing why your project will make a difference\"<\/li>\n<\/ul>\n\n\n<ul>\nStarting on May 17, 2016, the number of essays was reduced from 4 to 2, and the prompts for the first 2 essays were changed to the following:<br>\n<li>__project_essay_1:__ \"Describe your students: What makes your students special? Specific details about their background, your neighborhood, and your school are all helpful.\"<\/li>\n<li>__project_essay_2:__ \"About your project: How will these materials make a difference in your students' learning and improve their school lives?\"<\/li>\n<br>For all projects with project_submitted_datetime of 2016-05-17 and later, the values of project_essay_3 and project_essay_4 will be NaN.\n<\/ul>\n","64cbcfae":"**Analysis**\n\nsince the points overlapping both classes and class \"0\" is not visibile, we cannot analayse anything from the t-SNE plot\n\ntaking larger sets of data for the plot might work"}}