{"cell_type":{"247e347c":"code","81bd4233":"code","b41c44d4":"code","c002562a":"code","c3af6525":"code","53f7b04d":"code","e3e8298c":"code","9ec1416d":"code","8ec830db":"code","aad97e75":"code","6a546f2f":"code","bc21770e":"code","fb2a5096":"code","ddb5cbc3":"code","33b10599":"code","a2c01262":"code","b683a01b":"code","1f661c29":"code","c2218478":"code","9a422f10":"code","f3ed200c":"code","892e01a7":"code","637688c3":"code","d384d51c":"code","06f6d9ae":"code","de3b5751":"code","053571b6":"code","88488970":"markdown","2e3587b3":"markdown","5e6f8cdb":"markdown","d23edd90":"markdown","0401fd9a":"markdown","aee6aafa":"markdown","cd6abad6":"markdown","b370ee3d":"markdown","1e7bb431":"markdown","3a2077df":"markdown","60b0555f":"markdown","4be7fd8a":"markdown","b61bf69c":"markdown","6c5c5847":"markdown","e64a1206":"markdown","3a607b21":"markdown","d2c7cfd0":"markdown","45d4e2e8":"markdown","f038bcae":"markdown"},"source":{"247e347c":"import os\nimport re\nimport html as ihtml\nimport warnings\nimport random\nwarnings.filterwarnings('ignore')\n\nos.environ[\"TFHUB_CACHE_DIR\"] = \"\/tmp\/\"\n\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport numpy as np\nimport scipy\nimport umap\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nimport plotly_express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\npd.set_option('display.max_colwidth', -1)\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_random_seed(SEED)\n\n%matplotlib inline","81bd4233":"umap.__version__","b41c44d4":"input_dir = '..\/input'\n\nquestions = pd.read_csv(os.path.join(input_dir, 'questions.csv'))\ntags = pd.read_csv(os.path.join(input_dir, 'tags.csv'))\ntag_questions = pd.read_csv(os.path.join(input_dir, 'tag_questions.csv'))","c002562a":"def clean_text(text, remove_hashtags=True):\n    text = BeautifulSoup(ihtml.unescape(text), \"lxml\").text\n    text = re.sub(r\"http[s]?:\/\/\\S+\", \"\", text)\n    if remove_hashtags:\n        text = re.sub(r\"#[a-zA-Z\\-]+\", \"\", text)\n    text = re.sub(r\"\\s+\", \" \", text)        \n    return text","c3af6525":"questions['questions_full_text'] = questions['questions_title'] + ' '+ questions['questions_body']","53f7b04d":"sample_text = questions[questions['questions_full_text'].str.contains(\"&a\")][\"questions_full_text\"].iloc[0]\nsample_text","e3e8298c":"sample_text = clean_text(sample_text)\nsample_text","9ec1416d":"%%time\nquestions['questions_full_text'] = questions['questions_full_text'].apply(clean_text)","8ec830db":"questions['questions_full_text'].sample(2)","aad97e75":"tag_questions.groupby(\n    \"tag_questions_tag_id\"\n).size().sort_values(ascending=False).to_frame(\"count\").merge(\n    tags, left_on=\"tag_questions_tag_id\", right_on=\"tags_tag_id\"\n).head(10)","6a546f2f":"questions_id_medicine = set(tag_questions[tag_questions.tag_questions_tag_id == 89].tag_questions_question_id)\nquestions_id_engineering = set(tag_questions[tag_questions.tag_questions_tag_id == 54].tag_questions_question_id)\nlen(questions_id_medicine), len(questions_id_engineering), len(questions_id_medicine.intersection(questions_id_engineering))","bc21770e":"embed = hub.Module(\"https:\/\/tfhub.dev\/google\/universal-sentence-encoder-large\/3\")","fb2a5096":"import logging\nfrom tqdm import tqdm_notebook\ntf.logging.set_verbosity(logging.WARNING)\nBATCH_SIZE = 128\n\nsentence_input = tf.placeholder(tf.string, shape=(None))\n# For evaluation we use exactly normalized rather than\n# approximately normalized.\nsentence_emb = tf.nn.l2_normalize(embed(sentence_input), axis=1)\n\nsentence_embeddings = []       \nwith tf.Session() as session:\n    session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n    for i in tqdm_notebook(range(0, len(questions), BATCH_SIZE)):\n        sentence_embeddings.append(\n            session.run(\n                sentence_emb, \n                feed_dict={\n                    sentence_input: questions[\"questions_full_text\"].iloc[i:(i+BATCH_SIZE)].values\n                }\n            )\n        )","ddb5cbc3":"sentence_embeddings = np.concatenate(sentence_embeddings, axis=0)\nsentence_embeddings.shape","33b10599":"%%time\nembedding = umap.UMAP(metric=\"cosine\", n_components=2, random_state=42).fit_transform(sentence_embeddings)","a2c01262":"df_se_emb = pd.DataFrame(embedding, columns=[\"x\", \"y\"])","b683a01b":"df_emb_sample = df_se_emb.sample(10000)\nfig, ax = plt.subplots(figsize=(12, 10))\nplt.scatter(\n    df_emb_sample[\"x\"].values, df_emb_sample[\"y\"].values, s=1\n)\nplt.setp(ax, xticks=[], yticks=[])\nplt.title(\"Sentence embeddings embedded into two dimensions by UMAP\", fontsize=18)\nplt.show()","1f661c29":"print(questions[df_se_emb.x > 10].shape[0])\nquestions[df_se_emb.x > 10].questions_full_text.sample(5)","c2218478":"print(questions[df_se_emb.y > 8].shape[0])\nquestions[df_se_emb.y > 8].questions_full_text.sample(5)","9a422f10":"questions_id_medicine = tag_questions[tag_questions.tag_questions_tag_id == 89].tag_questions_question_id\nquestions_id_engineering = tag_questions[tag_questions.tag_questions_tag_id == 54].tag_questions_question_id\ndf_se_emb[\"tag\"] = \"none\"\ndf_se_emb.loc[questions.questions_id.isin(questions_id_medicine), \"tag\"] = \"medicine\"\ndf_se_emb.loc[questions.questions_id.isin(questions_id_engineering), \"tag\"] = \"engineering\"\ndf_se_emb.loc[questions.questions_id.isin((set(questions_id_medicine).intersection(\n    set(questions_id_engineering)))), \"tag\"] = \"both\"","f3ed200c":"df_se_emb.tag.value_counts()","892e01a7":"px.colors.qualitative.D3","637688c3":"df_emb_sample = df_se_emb.loc[df_se_emb.tag != \"none\"].copy()\ndf_emb_sample[\"tag\"] = df_emb_sample.tag.astype(\"category\")\ndf_emb_sample[\"size\"] = 20\npx.scatter(\n    df_emb_sample, x=\"x\", y=\"y\", color=\"tag\", template=\"plotly_white\", size=\"size\",\n    range_x=((-7, 12)), range_y=((-9, 10)), opacity=0.3, size_max=5,\n    width=800, height=600, color_discrete_sequence=px.colors.qualitative.Vivid\n    \n)","d384d51c":"questions_id_medicine = tag_questions[tag_questions.tag_questions_tag_id == 89].tag_questions_question_id\nquestions_id_biz = tag_questions[tag_questions.tag_questions_tag_id == 27292].tag_questions_question_id\ndf_se_emb[\"tag\"] = \"none\"\ndf_se_emb.loc[questions.questions_id.isin(questions_id_medicine), \"tag\"] = \"medicine\"\ndf_se_emb.loc[questions.questions_id.isin(questions_id_biz), \"tag\"] = \"business\"\ndf_se_emb.loc[questions.questions_id.isin((set(questions_id_medicine).intersection(\n    set(questions_id_biz)))), \"tag\"] = \"both\"","06f6d9ae":"df_emb_sample = df_se_emb.loc[df_se_emb.tag != \"none\"].copy()\ndf_emb_sample[\"tag\"] = df_emb_sample.tag.astype(\"category\")\ndf_emb_sample = df_se_emb.loc[df_se_emb.tag != \"none\"].copy()\ndf_emb_sample[\"tag\"] = df_emb_sample.tag.astype(\"category\")\ndf_emb_sample[\"size\"] = 20\npx.scatter(\n    df_emb_sample, x=\"x\", y=\"y\", color=\"tag\", template=\"plotly_white\", size=\"size\",\n    range_x=((-7, 12)), range_y=((-9, 10)), opacity=0.3, size_max=5,\n    width=800, height=600, color_discrete_sequence=px.colors.qualitative.Vivid\n    \n)","de3b5751":"df_se_emb[\"tag\"] = \"none\"\ndf_se_emb.loc[questions.questions_id.isin(questions_id_engineering), \"tag\"] = \"engineering\"\ndf_se_emb.loc[questions.questions_id.isin(questions_id_biz), \"tag\"] = \"business\"\ndf_se_emb.loc[questions.questions_id.isin(questions_id_medicine), \"tag\"] = \"medicine\"\ndf_se_emb.loc[questions.questions_id.isin((set(questions_id_engineering).intersection(\n    set(questions_id_biz)))), \"tag\"] = \"none\"\ndf_se_emb.loc[questions.questions_id.isin((set(questions_id_medicine).intersection(\n    set(questions_id_biz)))), \"tag\"] = \"none\"\ndf_se_emb.loc[questions.questions_id.isin((set(questions_id_medicine).intersection(\n    set(questions_id_engineering)))), \"tag\"] = \"none\"","053571b6":"df_emb_sample = df_se_emb.loc[df_se_emb.tag != \"none\"].copy()\ndf_emb_sample[\"tag\"] = df_emb_sample.tag.astype(\"category\")\ndf_emb_sample = df_se_emb.loc[df_se_emb.tag != \"none\"].copy()\ndf_emb_sample[\"tag\"] = df_emb_sample.tag.astype(\"category\")\ndf_emb_sample[\"size\"] = 20\npx.scatter(\n    df_emb_sample, x=\"x\", y=\"y\", color=\"tag\", template=\"plotly_white\", size=\"size\",\n    range_x=((-7, 12)), range_y=((-9, 10)), opacity=0.3, size_max=5,\n    width=800, height=600, color_discrete_sequence=px.colors.qualitative.Vivid\n    \n)","88488970":"## Preprocessing","2e3587b3":"## Tag Visualization\n\nThe number of questions is relative small here so we could use the new [Plotly Express](https:\/\/medium.com\/@plotlygraphs\/introducing-plotly-express-808df010143d) library to provide interactive visualizations. The legends in the right side are clickable. Use them to help you better distinguish the questions from different tags.","5e6f8cdb":"## Sentence Embeddings\n\nThe model used is the universal sentence encoder (large\/transformer) version 3. The extracted sentence embeddings will have a dimension of 512. Here we also use cosine similarity.","d23edd90":"## Tags","0401fd9a":"### #engineering & #business & #medicine\n\nIn this plot we remove all the intersections to make the plot cleaner:","aee6aafa":"# Tag Visualization with Universal Sentence Encoder\n\nThis kernel is based on [An Attemplt to Visualize Topic Model (LDA)](https:\/\/www.kaggle.com\/ceshine\/an-attemplt-to-visualize-topic-model-lda). This kernel removes the topic model and instead focus on the sentence embeddings space from the universal sentence encoder model and the (hash)tags.\n\nAs with the previous kernel, hashtags are removed from the question texts. So the universal sentence encoder does **not** have any direct information whatsoever regarding to the questions associated hastags.\n\n> Hashtags are removed. I want to separate natural language understanding from (implicit) tag grouping in this task, that is, only focus on the questions, not tags.\n\nDimension reduction is done via [UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction](https:\/\/umap-learn.readthedocs.io\/en\/latest\/). And [Universal Sentence Encoder](https:\/\/tfhub.dev\/google\/universal-sentence-encoder-large\/3) comes from [TensorFlow Hub](https:\/\/www.tensorflow.org\/hub).","cd6abad6":"The far right cluster contains questions related to \"stream\". Many of them starts with \"In which stream\". Arguably this is not the best way to map these questions, as it's not useful in recommending questions to the professionals.","b370ee3d":"### The Real Deal","1e7bb431":"There are 24 questions tagged both #medicine and #engineering:","3a2077df":"Top tags:","60b0555f":"### Examine the outliers\n\n","4be7fd8a":"### #medicine & #engineering","b61bf69c":"## Imports","6c5c5847":"### Checking","e64a1206":"## Summary\n\nThe questions with #business, #engineering, and #medicine tags each formed one bigger cluster that are clearly separated from each other. Those questions are the \"easy\" ones. We can easily create a tag recommendation model for those questions. The others, however, can be a bit problematic. Many of them are still distinguishable, but might require higher degree of non-linearity to model them.\n\nThe results are better than I expected. At least we did not get something that are fully intertwined. The universal sentence encoder does show some potential for this problem.","3a607b21":"## Contents\n\n1. [Imports](#Imports)\n1. [Preprocessing](#Preprocessing)\n  * [Checking](#Checking)\n  * [The Real Deal](#The-Real-Deal)\n1. [Tags](#Tags)\n1. [Sentence Embeddings](#Sentence-Embeddings)\n1. [Visualization (Global)](#Global-Visualization)\n1. [Visualization (Tags)](#Tag-Visualization)\n  * [#medicine & #engineering](##medicine-&-#engineering)\n  * [#medicine & #business](##medicine-&-#business)\n  * [#engineering & #business & #medicine](##engineering-&-#business-&-#medicine)\n1. [Summary](#Summary)","d2c7cfd0":"## Global Visualization\n\nHere we plot 10,000 samples to give readers a sense of what does the embedding space looks like.","45d4e2e8":"The top cluster is related to textbooks. This one looks rather reasonable.","f038bcae":"### #medicine & #business"}}