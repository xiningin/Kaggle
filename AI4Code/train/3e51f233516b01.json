{"cell_type":{"5cc25db8":"code","55f091dc":"code","524e6375":"code","0eac9c5f":"code","af9c97eb":"code","0976d175":"code","cdf1a0e4":"code","84bb3ed2":"code","3ba0941d":"code","ed1e1dda":"code","2487ec5c":"code","df4e4839":"code","990a8c8a":"code","7c9405e2":"code","b75a4ea0":"code","38401582":"code","b9fc54cc":"code","5ed71da9":"code","e6d005ee":"code","0befedd2":"markdown","8ae76a4d":"markdown","ea48b316":"markdown","1185700f":"markdown","d6e313e9":"markdown","b5328f2e":"markdown","3231d8d2":"markdown","84ebac7e":"markdown","5e88339f":"markdown","2b9476ea":"markdown","9691b841":"markdown","ddf1e376":"markdown","25b41ff0":"markdown","a1caaa08":"markdown","9a444e10":"markdown","348d405a":"markdown","26b18835":"markdown","176d57f6":"markdown","0c4b3497":"markdown"},"source":{"5cc25db8":"import os\nimport glob\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping\nfrom sklearn.metrics import confusion_matrix, classification_report","55f091dc":"path = '..\/input\/eyes-rtte'\npath_img = list(glob.glob(path+'\/**\/*.jpg'))","524e6375":"labels = list(map(lambda x:os.path.split(os.path.split(x)[0])[1], path_img))\nfile_path = pd.Series(path_img, name='File_Path').astype(str)\nlabels = pd.Series(labels, name='Labels')\ndata = pd.concat([file_path, labels], axis=1)\ndata = data.sample(frac=1).reset_index(drop=True)\ndata.head()","0eac9c5f":"fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 8),\n                        subplot_kw={'xticks': [], 'yticks': []})\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(data.File_Path[i]))\n    ax.set_title(data.Labels[i])\nplt.tight_layout()\nplt.show()","af9c97eb":"counts = data.Labels.value_counts()\nsns.barplot(x=counts.index, y=counts)\nplt.xlabel('Labels')\nplt.ylabel('Count');","0976d175":"train_df, test_df = train_test_split(data, test_size=0.2, random_state=2)","cdf1a0e4":"def func(pre,name_model):\n    print('#####~Model => {} '.format(name_model))\n    train_datagen = ImageDataGenerator(preprocessing_function=pre, validation_split=0.2)\n    test_datagen = ImageDataGenerator(preprocessing_function=pre)\n    \n    train_gen = train_datagen.flow_from_dataframe(\n        dataframe=train_df,\n        x_col='File_Path',\n        y_col='Labels',\n        target_size=(100,100),\n        class_mode='categorical',\n        batch_size=32,\n        shuffle=True,\n        seed=0,\n        subset='training',\n        rotation_range=30,\n        zoom_range=0.15,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.15,\n        horizontal_flip=True,\n        fill_mode=\"nearest\")\n    valid_gen = train_datagen.flow_from_dataframe(\n        dataframe=train_df,\n        x_col='File_Path',\n        y_col='Labels',\n        target_size=(100,100),\n        class_mode='categorical',\n        batch_size=32,\n        shuffle=False,\n        seed=0,\n        subset='validation',\n        rotation_range=30,\n        zoom_range=0.15,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.15,\n        horizontal_flip=True,\n        fill_mode=\"nearest\")\n    test_gen = test_datagen.flow_from_dataframe(\n        dataframe=test_df,\n        x_col='File_Path',\n        y_col='Labels',\n        target_size=(100,100),\n        color_mode='rgb',\n        class_mode='categorical',\n        batch_size=32,\n        verbose=0,\n        shuffle=False)\n    \n    pre_model = name_model(input_shape=(100,100, 3),\n                   include_top=False,\n                   weights='imagenet',\n                   pooling='avg')\n    pre_model.trainable = False\n    inputs = pre_model.input\n    x = Dense(64, activation='relu')(pre_model.output)\n    x = Dense(64, activation='relu')(x)\n    outputs = Dense(2, activation='softmax')(x)\n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(loss = 'categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n    my_callbacks  = [EarlyStopping(monitor='val_loss',\n                              min_delta=0,\n                              patience=5,\n                              mode='auto')]\n    \n    history = model.fit(train_gen,validation_data=valid_gen,epochs=100,callbacks=my_callbacks,verbose=0);\n    print('\\033[01m              Plotting Accuracy, val_accuracy, loss, val_loss \\033[0m')\n    # Plotting Accuracy, val_accuracy, loss, val_loss\n    fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n    ax = ax.ravel()\n\n    for i, met in enumerate(['accuracy', 'loss']):\n        ax[i].plot(history.history[met])\n        ax[i].plot(history.history['val_' + met])\n        ax[i].set_title('Model {}'.format(met))\n        ax[i].set_xlabel('epochs')\n        ax[i].set_ylabel(met)\n        ax[i].legend(['Train', 'Validation'])\n    plt.show()\n    \n    # Predict Data Test\n    pred = model.predict(test_gen )\n    pred = np.argmax(pred,axis=1)\n    labels = (train_gen.class_indices)\n    labels = dict((v,k) for k,v in labels.items())\n    pred = [labels[k] for k in pred]\n    \n    print('\\033[01m              Classification_report \\033[0m')\n    # Classification report\n    cm=confusion_matrix(test_df.Labels,pred)\n    clr = classification_report(test_df.Labels, pred)\n    print(clr)\n    print('\\033[01m Display 6 pictures of the dataset with their labels \\033[0m')\n    # Display 6 pictures of the dataset with their labels\n    fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 8),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\n    for i, ax in enumerate(axes.flat):\n        ax.imshow(plt.imread(test_df.File_Path.iloc[i+1]))\n        ax.set_title(f\"True: {test_df.Labels.iloc[i+1]}\\nPredicted: {pred[i+1]}\")\n    plt.tight_layout()\n    plt.show()\n    \n    print('\\033[01m              Results \\033[0m')\n    # Results\n    results = model.evaluate(test_gen, verbose=0)\n    print(\"    Test Loss:\\033[31m \\033[01m {:.5f} \\033[30m \\033[0m\".format(results[0]))\n    print(\"Test Accuracy:\\033[32m \\033[01m {:.2f}% \\033[30m \\033[0m\".format(results[1] * 100))\n    \n    return results","84bb3ed2":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nresult_VGG16 = func(preprocess_input,VGG16)","3ba0941d":"from tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.applications.vgg19 import preprocess_input\nresult_VGG19 = func(preprocess_input,VGG19)","ed1e1dda":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nresult_ResNet50 = func(preprocess_input,ResNet50)","2487ec5c":"from tensorflow.keras.applications import ResNet101\nfrom tensorflow.keras.applications.resnet import preprocess_input\nresult_ResNet101 = func(preprocess_input,ResNet101)","df4e4839":"from tensorflow.keras.applications import MobileNet\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\nresult_MobileNet = func(preprocess_input,MobileNet)","990a8c8a":"from tensorflow.keras.applications import InceptionResNetV2\nfrom tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\nresult_InResNetV2 = func(preprocess_input,InceptionResNetV2)","7c9405e2":"from tensorflow.keras.applications import DenseNet201\nfrom tensorflow.keras.applications.densenet import preprocess_input\nresult_DenseNet201 = func(preprocess_input,DenseNet201)","b75a4ea0":"from tensorflow.keras.applications import Xception\nfrom tensorflow.keras.applications.xception import preprocess_input\nresult_Xception = func(preprocess_input,Xception)","38401582":"from tensorflow.keras.applications import EfficientNetB7\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nresult_Eff = func(preprocess_input,EfficientNetB7)","b9fc54cc":"output = pd.DataFrame({'Model':['VGG16','VGG19','ResNet50','ResNet101','MobileNet','InceptionResNetV2',\n                               'DenseNet201','Xception','EfficientNetB7'],\n                      'Accuracy':[result_VGG16[1], result_VGG19[1], result_ResNet50[1], result_ResNet101[1],\n                                  result_MobileNet[1],result_InResNetV2[1],result_DenseNet201[1],result_Xception[1],\n                                 result_Eff[1]]})","5ed71da9":"output","e6d005ee":"plt.figure(figsize=(12, 7))\nplots = sns.barplot(x='Model', y='Accuracy', data=output)\nfor bar in plots.patches:\n    plots.annotate(format(bar.get_height(), '.2f'),\n                   (bar.get_x() + bar.get_width() \/ 2,\n                    bar.get_height()), ha='center', va='center',\n                   size=15, xytext=(0, 8),\n                   textcoords='offset points')\n\nplt.xlabel(\"Models\")\nplt.ylabel(\"Accuracy\")\nplt.xticks(rotation=20);","0befedd2":"<h2>\u2714\ufe0f VGG19<\/h2>","8ae76a4d":"<h2>\u2714\ufe0f InceptionResNetV2<\/h2>","ea48b316":"<a id=\"3\"><\/a> <br>\n# \ud83d\udd25 EDA & Visualization","1185700f":"<h2>\u2714\ufe0f Xception<\/h2>","d6e313e9":"<a id=\"5\"><\/a> <br>\n# \ud83e\uddbe Function","b5328f2e":"<h2>\u2714\ufe0f ResNet101<\/h2>","3231d8d2":"<a id=\"2\"><\/a> <br> \n# \ud83d\uddc3\ufe0f Load Dataset","84ebac7e":"<h2>\u2714\ufe0f MobileNet<\/h2>","5e88339f":"<a id=\"61\"><\/a> <br>\n<h2>\u2714\ufe0f VGG16<\/h2>","2b9476ea":"<a id=\"7\"><\/a> <br>\n# \ud83d\udcca Final Report","9691b841":"<h2>\u2714\ufe0f ResNet50<\/h2>","ddf1e376":"<a id=\"1\"><\/a> <br>\n# \ud83d\udce5 Importing Libraries","25b41ff0":"<h2>\u2714\ufe0f EfficientNetB7<\/h2>","a1caaa08":"<h2 style=\"width: 100%;\n    margin: 0;\n    padding: 0;\n    text-align: center;\">---- Table of contents ----<\/h2>\n\n1. [Importing Libraries](#1)\n2. [Load Dataset](#2)\n3. [EDA & Visualization](#3)\n4. [Train & Test Split](#4)\n5. [Function](#5)\n6. [Training models](#6)\n  <ul>\n      <li>\u2714\ufe0f VGG16 <\/li>\n      <li>\u2714\ufe0f VGG19<\/li>\n      <li>\u2714\ufe0f ResNet50<\/li>\n      <li>\u2714\ufe0f ResNet101<\/li>\n      <li>\u2714\ufe0f MobileNet<\/li>\n      <li>\u2714\ufe0f InceptionResNetV2<\/li>\n      <li>\u2714\ufe0f DenseNet201<\/li>\n      <li>\u2714\ufe0f Xception<\/li>\n      <li>\u2714\ufe0f EfficientNetB7<\/li>\n  <\/ul>\n8. [Final Report](#7)","9a444e10":"<a id=\"4\"><\/a> <br>\n# \u2702\ufe0f Train & Test Split","348d405a":"<a id=\"6\"><\/a> <br>\n# \ud83d\udcda Training models","26b18835":"<h1 style=\"background-color:yellow;font-size:350%;text-align:center;border-radius: 50px 50px;padding: 15px\">Female And Male Eyes Classification<\/h1>","176d57f6":"<h2>\u2714\ufe0f DenseNet201<\/h2>","0c4b3497":"<img src=\"https:\/\/user-images.githubusercontent.com\/70811337\/151632920-0cc0d3b2-957f-41f3-9be5-cbda6138c910.png\" alt=\"Paris\" style=\"display: block;\n  margin-left: auto;\n  margin-right: auto;\">"}}