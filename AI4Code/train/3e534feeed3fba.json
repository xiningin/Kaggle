{"cell_type":{"f8a79577":"code","d2000359":"code","79217e20":"code","78d1b86b":"code","13ffcfee":"code","93906caa":"code","2df8b710":"code","3adf29be":"code","56a2352d":"code","71a6e1fc":"code","d3ca6168":"code","2f3b935f":"code","60d4dd56":"code","0d030012":"code","1271b6cd":"code","0f10138b":"code","787e14a2":"code","17a96d57":"code","9686dfd3":"code","c53f6580":"code","0c26f190":"code","af264129":"code","d0a5503d":"code","e010082d":"code","8b1b3151":"code","a38c701b":"markdown","daa8bc5c":"markdown","ced6d047":"markdown","2660ecfd":"markdown","8da2d428":"markdown","504ded3b":"markdown","c8e8ef23":"markdown","6ba8c9cb":"markdown","5d3f1c88":"markdown","35030be6":"markdown","6c65db55":"markdown","4cbdd8a2":"markdown","95224d54":"markdown","7b4d7a37":"markdown","6cb9cd23":"markdown","c53d8f95":"markdown","fa10c791":"markdown","733128ed":"markdown","5bc69319":"markdown","efc0910c":"markdown","1fde17c8":"markdown"},"source":{"f8a79577":"import numpy as np \nimport pandas as pd \nfrom tqdm import tqdm\nimport glob\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nimport pprint\nimport pydicom as dicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport albumentations as A\nimport cv2\nimport wandb\n\nfrom PIL import Image\nfrom colorama import Fore, Back, Style\n# colored output\ny_ = Fore.YELLOW\nr_ = Fore.RED\ng_ = Fore.GREEN\nb_ = Fore.BLUE\nm_ = Fore.MAGENTA\n\nsns.set(font=\"Serif\",style =\"white\")","d2000359":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\napi_key = user_secrets.get_secret(\"api_key\")\n\nos.environ[\"WANDB_SILENT\"] = \"true\"\n\nCONFIG = {'competition': 'siim-fisabio-rsna', '_wandb_kernel': 'ruch'}\n\n! wandb login $api_key","79217e20":"train_image_level = pd.read_csv(\"..\/input\/siim-covid19-detection\/train_image_level.csv\")\ntrain_study_level = pd.read_csv(\"..\/input\/siim-covid19-detection\/train_study_level.csv\")","78d1b86b":"train_image_level.head()","13ffcfee":"train_study_level.head()","93906caa":"train_directory = \"..\/input\/siim-covid19-detection\/train\/\"\ntest_directory = \"..\/input\/siim-covid19-detection\/test\/\"\n\ntrain_study_level['StudyInstanceUID'] = train_study_level['id'].apply(lambda x: x.replace('_study', ''))\ndel train_study_level['id']\ntrain_df = train_image_level.merge(train_study_level, on='StudyInstanceUID')","2df8b710":"train_df.head()","3adf29be":"training_paths = []\n\nfor sid in tqdm(train_df['StudyInstanceUID']):\n    training_paths.append(glob.glob(os.path.join(train_directory, sid +\"\/*\/*\"))[0])\n\ntrain_df['path'] = training_paths","56a2352d":"train_df.head()","71a6e1fc":"params = {'legend.fontsize': 'x-large',\n          'figure.figsize': (20, 32),\n         'axes.labelsize': 'x-large',\n         'axes.titlesize':'x-large',\n         'xtick.labelsize':'x-large',\n         'ytick.labelsize':'x-large'}\npylab.rcParams.update(params)\n\nfig, ax = plt.subplots(4,2)\nsns.kdeplot(train_df[\"Negative for Pneumonia\"], shade=True,ax=ax[0,0],color=\"#ffb4a2\")\nax[0,0].set_title(\"Negative for Pneumonia Distribution\",font=\"Serif\", fontsize=20,weight=\"bold\")\nsns.countplot(x = train_df[\"Negative for Pneumonia\"], ax=ax[0,1],color=\"#ffb4a2\")\nax[0,1].set_title(\"Negative for Pneumonia Distribution\",font=\"Serif\", fontsize=20,weight=\"bold\")\n\nsns.kdeplot(train_df[\"Typical Appearance\"], shade=True,ax=ax[1,0],color=\"#e5989b\")\nax[1,0].set_title(\"Typical Appearance Distribution\",font=\"Serif\", fontsize=20,weight=\"bold\")\nsns.countplot(x = train_df[\"Typical Appearance\"], ax=ax[1,1],color=\"#e5989b\")\nax[1,1].set_title(\"Typical Appearance Distribution\",font=\"Serif\", fontsize=20,weight=\"bold\")\n\nsns.kdeplot(train_df[\"Indeterminate Appearance\"], shade=True,ax=ax[2,0],color=\"#b5838d\")\nax[2,0].set_title(\"Indeterminate Appearance Distribution\",font=\"Serif\", fontsize=20,weight=\"bold\")\nsns.countplot(x = train_df[\"Indeterminate Appearance\"], ax=ax[2,1],color=\"#b5838d\")\nax[2,1].set_title(\"Indeterminate Appearance Distribution\",font=\"Serif\", fontsize=20,weight=\"bold\")\n\nsns.kdeplot(train_df[\"Atypical Appearance\"], shade=True,ax=ax[3,0],color=\"#6d6875\")\nax[3,0].set_title(\"Atypical Appearance Distribution\",font=\"Serif\", fontsize=20,weight=\"bold\")\nsns.countplot(x = train_df[\"Atypical Appearance\"], ax=ax[3,1],color=\"#6d6875\")\nax[3,1].set_title(\"Atypical Appearance Distribution\",font=\"Serif\", fontsize=20,weight=\"bold\")\n\nfig.subplots_adjust(wspace=0.2, hspace=0.4, top=0.93)\nplt.show()","d3ca6168":"#====== Function to plot WandB bar chart ======\ndef plot_wb_bar(df,col1,col2): \n    run = wandb.init(project='siim', job_type='image-visualization',name=col1,config = CONFIG)\n    \n    dt = [[label, val] for (label, val) in zip(df[col1], df[col2])]\n    table = wandb.Table(data=dt, columns = [col1,col2])\n    wandb.log({col1 : wandb.plot.bar(table, col1,col2,title=col1)})\n\n    run.finish()\n    \n#====== Function to create a dataframe of value counts ======\ndef count_values(df,col):\n    df = pd.DataFrame(df[col].value_counts().reset_index().values,columns=[col, \"counts\"])\n    return df\n\nplot_wb_bar(count_values(train_df,\"Negative for Pneumonia\"),\"Negative for Pneumonia\", 'counts')\nplot_wb_bar(count_values(train_df,\"Typical Appearance\"),\"Typical Appearance\", 'counts')\nplot_wb_bar(count_values(train_df,\"Indeterminate Appearance\"),\"Indeterminate Appearance\", 'counts')\nplot_wb_bar(count_values(train_df,\"Atypical Appearance\"),\"Atypical Appearance\", 'counts')","2f3b935f":"voi_lut=True\nfix_monochrome=True\n\ndef dicom_dataset_to_dict(filename,func):\n    \"\"\"Credit: https:\/\/github.com\/pydicom\/pydicom\/issues\/319\n               https:\/\/www.kaggle.com\/raddar\/convert-dicom-to-np-array-the-correct-way\n    \"\"\"\n    \n    dicom_header = dicom.dcmread(filename) \n    \n    #====== DICOM FILE DATA ======\n    dicom_dict = {}\n    repr(dicom_header)\n    for dicom_value in dicom_header.values():\n        if dicom_value.tag == (0x7fe0, 0x0010):\n            #discard pixel data\n            continue\n        if type(dicom_value.value) == dicom.dataset.Dataset:\n            dicom_dict[dicom_value.name] = dicom_dataset_to_dict(dicom_value.value)\n        else:\n            v = _convert_value(dicom_value.value)\n            dicom_dict[dicom_value.name] = v\n      \n    del dicom_dict['Pixel Representation']\n    \n    if func!='metadata_df':\n        #====== DICOM IMAGE DATA ======\n        # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n        if voi_lut:\n            data = apply_voi_lut(dicom_header.pixel_array, dicom_header)\n        else:\n            data = dicom_header.pixel_array\n        # depending on this value, X-ray may look inverted - fix that:\n        if fix_monochrome and dicom_header.PhotometricInterpretation == \"MONOCHROME1\":\n            data = np.amax(data) - data\n        data = data - np.min(data)\n        data = data \/ np.max(data)\n        modified_image_data = (data * 255).astype(np.uint8)\n    \n        return dicom_dict, modified_image_data\n    \n    else:\n        return dicom_dict\n\ndef _sanitise_unicode(s):\n    return s.replace(u\"\\u0000\", \"\").strip()\n\ndef _convert_value(v):\n    t = type(v)\n    if t in (list, int, float):\n        cv = v\n    elif t == str:\n        cv = _sanitise_unicode(v)\n    elif t == bytes:\n        s = v.decode('ascii', 'replace')\n        cv = _sanitise_unicode(s)\n    elif t == dicom.valuerep.DSfloat:\n        cv = float(v)\n    elif t == dicom.valuerep.IS:\n        cv = int(v)\n    else:\n        cv = repr(v)\n    return cv\n\nfor filename in train_df.path[0:5]:\n    df, img_array = dicom_dataset_to_dict(filename, 'fetch_both_values')\n    \n    fig, ax = plt.subplots(1, 2, figsize=[15, 8])\n    ax[0].imshow(img_array, cmap=plt.cm.gray)\n    ax[1].imshow(img_array, cmap=plt.cm.plasma)    \n    plt.show()\n    \n    pprint.pprint(df)","60d4dd56":"# dicom_data_list = []\n# for filename in train_df.path:\n#     try:\n#         data_di = dicom_dataset_to_dict(filename,'metadata_df')\n#         dicom_data_list.append(data_di)\n    \n#     except:\n#         continue\n\n# dicom_data_df = pd.DataFrame(dicom_data_list) \n# dicom_data_df\n\n# #====== Saving to csv files and creating artifacts ======\n# dicom_data_df.to_csv(\"dicom_metadata.csv\")\n\n# run = wandb.init(project='siim', name='dicom_metadata')\n\n# artifact = wandb.Artifact('dicom_metadata', type='dataset')\n\n# #====== Add a file to the artifact's contents ======\n# artifact.add_file(\"dicom_metadata.csv\")\n\n# #====== Save the artifact version to W&B and mark it as the output of this run ====== \n# run.log_artifact(artifact)\n\n# run.finish()","0d030012":"run = wandb.init(project='siim', config = CONFIG)\nartifact = run.use_artifact('ruchi798\/siim\/dicom_metadata:v1', type='dataset')\nartifact_dir = artifact.download()\nrun.finish()\n\npath = os.path.join(artifact_dir,\"dicom_metadata.csv\")\nmetadata = pd.read_csv(path)\nmetadata = metadata.drop(columns=[\"Unnamed: 0\"])\nmetadata.head()","1271b6cd":"def label_sizes(col):\n    labels = metadata[col].value_counts().index\n    sizes = metadata[col].value_counts()\n    uc = metadata[col].nunique()\n    return labels, sizes, uc\n\ndef plot_pie(col1,col2,c1,c2):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24,10))\n    axs = [ax1, ax2]\n    \n    labels, sizes, uc = label_sizes(col1)\n    explode = (0.05,)*uc\n    \n    if col1 == \"De-identification Method\":\n        labels = list(map(lambda b: b.replace(\"CTP Default:  based on DICOM PS3.15 AnnexE. Details in 0012,0064\",\"CTP Default:  based on DICOM PS3.15\"), labels))\n    \n    \n    ax1.pie(sizes, explode=explode, colors=c1, startangle=60, labels=labels,autopct='%1.0f%%', pctdistance=0.6)\n    ax1.add_artist(plt.Circle((0,0),0.4,fc='white'))\n    ax1.set_title(col1 + \" Distribution\",weight=\"bold\")\n\n    labels, sizes, uc = label_sizes(col2)\n    explode = (0.05,)*uc\n    ax2.pie(sizes, explode=explode, colors=c2, startangle=60, labels=labels,autopct='%1.0f%%', pctdistance=0.6)\n    ax2.add_artist(plt.Circle((0,0),0.4,fc='white'))\n    ax2.set_title(col2 + \" Distribution\",weight=\"bold\")\n    \n    plt.show()\n    \nplot_pie(\"Modality\",\"Photometric Interpretation\",['#5C8DFF','#abc4ff'],['#05979E','#87F5FB'])\n\nplt.figure(figsize=(16, 8))\nsns.countplot(y=\"Body Part Examined\",data=metadata,linewidth=3,palette=\"PRGn\")\nplt.title(\"Body Part Examined Distribution\",font=\"Serif\", size = 20,weight=\"bold\")\nplt.show()\n\nplt.figure(figsize=(16, 8))\nsns.countplot(y=\"Private Creator\",data=metadata,linewidth=3,palette=['#F9ADA0','#F9627D',\"#6DAEDB\"])\nplt.title(\"Private Creator Distribution\",font=\"Serif\", size = 20, weight=\"bold\")\nplt.show()\n\nplot_pie(\"De-identification Method\",\"Patient's Sex\",['#F3C98B',\"#fff3b0\",'#DE8E17'],['#E6C4E9','#C77ACD'])","0f10138b":"# WandB plots\n\nm = metadata.copy()\nm = m.rename(columns={\"Patient's Sex\": \"Patient Sex\"})\ncols_to_plot = [\"Modality\",\"Photometric Interpretation\",\"Body Part Examined\",\"Private Creator\",\"De-identification Method\",\"Patient Sex\"]\n\nfor col in cols_to_plot:\n    plot_wb_bar(count_values(m,col),col, 'counts')","787e14a2":"# initializing the run\nrun = wandb.init(project=\"siim\",\n                 job_type=\"upload\",\n                 config = CONFIG\n                 )\n\n# creating an artifact\nartifact = wandb.Artifact(name=\"dicom_metadata_image\", type=\"raw_data\")\n\n# setting up a WandB Table object to hold the dataset\ncolumns = ['image',\"Body Part Examined\",\"Image Type\",\"Modality\",\"Patient's Name\",\"Patient ID\",\"Patient's Sex\",\"Study Instance UID\"]\ntable = wandb.Table(\n    columns=columns\n)\n\nfor filename in train_df.path[0:5]:\n    data_di, img_array = dicom_dataset_to_dict(filename,'fetch_both_values')\n    \n    body_part_examined = data_di.get(\"Body Part Examined\")\n    img_type = data_di.get('Image Type')\n    modality = data_di.get(\"Modality\")\n    p_name = data_di.get(\"Patient's Name\")\n    p_id = data_di.get(\"Patient ID\")\n    p_gender = data_di.get(\"Patient's Sex\")\n    study_inst_uid = data_di.get(\"Study Instance UID\")\n    \n    img_object = Image.fromarray(img_array)\n    # raw image\n    raw_img = wandb.Image(img_object)\n\n    # adding a row to the table\n    row = [raw_img,body_part_examined,img_type,modality,p_name,p_id,p_gender,study_inst_uid]\n    table.add_data(*row)\n       \n# adding the table to the artifact\nartifact.add(table, \"dicom_examples\")\n   \n# logging the artifact\nrun.log_artifact(artifact)\n\nrun.finish()","17a96d57":"# initializing the run\nrun = wandb.init(project=\"siim\",\n                 job_type=\"upload\",\n                 config = CONFIG\n                 )\n\n# creating an artifact \nartifact = wandb.Artifact(name=\"dicom_images\", type=\"raw_data\")\n\n# setting up a WandB Table object to hold the dataset\ncolumns=[\"dicom image\", \"class\"]\n\ntable = wandb.Table(\n    columns=columns\n)\n\nclasses = ['Negative for Pneumonia','Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']\nfor siim_class in classes:\n    print(siim_class)\n    for _, row in train_df[train_df[siim_class]==1].iloc[:2].iterrows():\n        filename = row['path']\n        df, img_array = dicom_dataset_to_dict(filename,'fetch_both_values')\n        \n        fig, ax = plt.subplots(1, 2, figsize=[15, 8])\n        ax[0].imshow(img_array, cmap=plt.cm.gray)\n        ax[1].imshow(img_array, cmap=plt.cm.plasma)   \n        plt.show()\n        \n        img_object = Image.fromarray(img_array)\n        \n        # raw image\n        raw_img = wandb.Image(img_object)\n\n        # adding a row to the table\n        row = [raw_img,siim_class]\n        table.add_data(*row)\n        \n# adding the table to the artifact\nartifact.add(table, \"raw_examples\")\n    \n# logging the artifact\nrun.log_artifact(artifact)\n\nrun.finish()","9686dfd3":"train_jpg_directory = '..\/input\/siim-covid19-resized-to-256px-jpg\/train'\ntest_jpg_directory = '..\/input\/siim-covid19-resized-to-256px-jpg\/test'\n\ndef getImagePaths(path):\n    image_names = []\n    for dirname, _, filenames in os.walk(path):\n        for filename in filenames:\n            fullpath = os.path.join(dirname, filename)\n            image_names.append(fullpath)\n    return image_names\n\ntrain_images_path = getImagePaths(train_jpg_directory)\ntest_images_path = getImagePaths(test_jpg_directory)\n\nprint(f\"{y_}Number of train images: {g_} {len(train_images_path)}\\n\")\nprint(f\"{y_}Number of test images: {g_} {len(test_images_path)}\\n\")\n\ndef getShape(data, images_paths):\n    shape = cv2.imread(images_paths[0]).shape\n    for image_path in images_paths:\n        image_shape=cv2.imread(image_path).shape\n        if (image_shape!=shape):\n            return data +\" - Different image shape\"\n        else:\n            return data +\" - Same image shape \" + str(shape)","c53f6580":"run = wandb.init(project='siim', name='count',config = CONFIG)\n\nwandb.log({'Training samples': len(train_images_path) , \n           'Test samples': len(test_images_path) \n          })\n\nrun.finish()","0c26f190":"getShape('train',train_images_path)","af264129":"getShape('test',test_images_path)","d0a5503d":"def plot_augmentations(images, titles, sup_title):\n    fig, axes = plt.subplots(figsize=(20, 16), nrows=3, ncols=4, squeeze=False)\n    \n    for indx, (img, title) in enumerate(zip(images, titles)):\n        axes[indx \/\/ 4][indx % 4].imshow(img)\n        axes[indx \/\/ 4][indx % 4].set_title(title, fontsize=15)\n        \n    plt.tight_layout()\n    fig.suptitle(sup_title, fontsize = 20)\n    fig.subplots_adjust(wspace=0.2, hspace=0.2, top=0.93)\n    plt.show()\n    \ndef augment(paths, data):\n    \n    # list of albumentations\n    albumentations = [A.RandomSunFlare(p=1), A.RandomFog(p=1), A.RandomBrightness(p=1),\n                              A.RandomCrop(p=1,height = 128, width = 128), A.Rotate(p=1, limit=90),\n                              A.RGBShift(p=1), A.RandomSnow(p=1),\n                              A.HorizontalFlip(p=1), A.VerticalFlip(p=1), A.RandomContrast(limit = 0.5,p = 1),\n                              A.HueSaturationValue(p=1,hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=50)]\n    \n    # image titles\n    titles = [\"RandomSunFlare\",\"RandomFog\",\"RandomBrightness\",\n                       \"RandomCrop\",\"Rotate\", \"RGBShift\", \"RandomSnow\",\"HorizontalFlip\", \"VerticalFlip\", \"RandomContrast\",\"HSV\"]\n    \n    for i in paths:\n        image_path = i\n        \n        # getting image name from path\n        image_name = image_path.split(\"\/\")[4].split(\".\")[0]\n        \n        # reading image\n        image = cv2.imread(image_path)\n\n        # list of images\n        images = []\n        \n        # creating image augmentations\n        for augmentation_type in albumentations:\n            augmented_img = augmentation_type(image = image)['image']\n            images.append(augmented_img)\n\n        # original image\n        titles.insert(0, \"Original\")\n        images.insert(0,image)  \n        \n        sup_title = \"Image Augmentation for \" + data + \" - \" + image_name\n        plot_augmentations(images, titles, sup_title)\n        \n        titles.remove(\"Original\")","e010082d":"augment(train_images_path[0:2],'train')","8b1b3151":"augment(train_images_path[0:2],'test')","a38c701b":"| id                       | unique study identifier                                  |\n|--------------------------|----------------------------------------------------------|\n| Negative for Pneumonia   | 1 : if the study is negative for pneumonia, 0: otherwise |\n| Typical Appearance       | 1: if the study has this appearance, 0: otherwise        |\n| Indeterminate Appearance | 1: if the study has this appearance, 0: otherwise        |\n| Atypical Appearance      | 1: if the study has this appearance, 0: otherwise        |","daa8bc5c":"### Images and Classes","ced6d047":"<img src=\"https:\/\/camo.githubusercontent.com\/dd842f7b0be57140e68b2ab9cb007992acd131c48284eaf6b1aca758bfea358b\/68747470733a2f2f692e696d6775722e636f6d2f52557469567a482e706e67\">\n\nI will be integrating W&B for ```visualizations``` and ```logging artifacts```!\n\n[SIIM Project on W&B Dashboard](https:\/\/wandb.ai\/ruchi798\/siim?workspace=user-ruchi798)","2660ecfd":"| id    | unique study identifier                                      |\n|-------|--------------------------------------------------------------|\n| boxes | bounding boxes in easily-readable dictionary format          |\n| label | the correct prediction label for the provided bounding boxes |","8da2d428":"A snapshot of the newly created artifact:\n<img src=\"https:\/\/i.imgur.com\/QVHNpcB.png\">","504ded3b":"Visualizing the DICOM data in a W&B table: ","c8e8ef23":"# Data Augmentation","6ba8c9cb":"# DICOM data","5d3f1c88":"I've created a [dataset](https:\/\/www.kaggle.com\/ruchi798\/siimfisabiorsna-covid19-detection-augmented) of image augmentations for all the training and testing images as well \ud83e\udd73","35030be6":"Super thankful to @[xhlulu](https:\/\/www.kaggle.com\/xhlulu) for converting [dicom image data to jpg files](https:\/\/www.kaggle.com\/xhlulu\/siim-covid-19-convert-to-jpg-256px)! \u26a1","6c65db55":"We can interact with the W&B table by specifying filters on any column to **limit the visible rows down to only rows that match**!\n\nHere I've filtered the table to see only those images that have the class label as ```Atypical Appearance``` or ```Indeterminate Appearance```.","4cbdd8a2":"### Image and Metadata","95224d54":"### Checking if images in each directory have the same shape","7b4d7a37":"<img src = \"https:\/\/i.imgur.com\/Cbcn9nP.gif\">","6cb9cd23":"### Data Augmentation (train samples)","c53d8f95":"<img src = \"https:\/\/i.imgur.com\/LKLpFOv.png\">","fa10c791":"Work in Progress \u23f3","733128ed":"### Data Augmentation (test samples)","5bc69319":"This is what my [project](https:\/\/wandb.ai\/ruchi798\/siim?workspace=user-ruchi798) looks like on the W&B dashboard \u2b07\ufe0f\n<img src=\"https:\/\/i.imgur.com\/lFIrsJT.png\">","efc0910c":"<img src = \"https:\/\/i.imgur.com\/SeAidj8.gif\">","1fde17c8":"# Distribution of class labels"}}