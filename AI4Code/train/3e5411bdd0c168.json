{"cell_type":{"41504cbe":"code","52118a62":"code","a517357a":"code","b406a474":"code","482afa75":"code","d76ccdc1":"code","e2e84dcf":"code","711bbba5":"code","357cd91f":"code","dffd562b":"code","f39b92b1":"code","e295bebb":"code","b47196d2":"code","ee12853e":"code","ba1d8d16":"code","8de29586":"code","b8d60da1":"code","dc735418":"code","f82ba58b":"code","b75602c2":"code","3bb10418":"code","99999898":"code","b0a441be":"code","4543c258":"code","ba7e3e1a":"code","eb685160":"code","903753a5":"markdown","35c25ff0":"markdown","8ca2ecc8":"markdown","2e6bbc1d":"markdown","2d5ff9be":"markdown","561a825d":"markdown","0956d9a8":"markdown","8549a018":"markdown","1f0d2dd4":"markdown","c5533704":"markdown","c77645ef":"markdown","9699845e":"markdown","6d8ff4eb":"markdown","7191609e":"markdown","ad1e3644":"markdown","4ae5a061":"markdown","200cb191":"markdown","9637ae92":"markdown","438d862a":"markdown","16e8fc37":"markdown","b394b379":"markdown","3162332c":"markdown","9b49ae24":"markdown","2fc46b48":"markdown"},"source":{"41504cbe":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport random\nimport os\nimport cv2\nimport sys\nfrom pylab import rcParams\nfrom PIL import Image\nwarnings.filterwarnings('ignore')\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Input, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.applications import InceptionV3, Xception\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\nfrom sklearn.model_selection import StratifiedShuffleSplit","52118a62":"policy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_policy(policy) #shortens training time by 2x","a517357a":"df_train = pd.read_csv(\"..\/input\/cassava-leaf-disease-classification\/train.csv\")\ndf_train.head()","b406a474":"df_train[\"label\"] = df_train[\"label\"].astype(str) #convert to str as we want to use Categorical Cross Entropy (CCE) later on\ndf_train.info()","482afa75":"sns.set_style(\"whitegrid\")\nplt.figure(figsize=(10,8))\nsns.countplot(df_train[\"label\"], edgecolor=\"black\", palette=\"mako\")","d76ccdc1":"path = \"..\/input\/cassava-leaf-disease-classification\/train_images\/\"\ndf0 = df_train[df_train[\"label\"] == \"0\"]\nfiles = df0[\"image_id\"].sample(3).tolist()\n\nplt.figure(figsize=(15,5))\nindex = 0\nfor file in files:\n    image = Image.open(path + file)\n    plt.subplot(1, 3, index + 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    index += 1\n\nplt.show()","e2e84dcf":"df1 = df_train[df_train[\"label\"] == \"1\"]\nfiles = df1[\"image_id\"].sample(3).tolist()\n\nplt.figure(figsize=(15,5))\nindex = 0\nfor file in files:\n    image = Image.open(path + file)\n    plt.subplot(1, 3, index + 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    index += 1\n\nplt.show()","711bbba5":"df2 = df_train[df_train[\"label\"] == \"2\"]\nfiles = df2[\"image_id\"].sample(3).tolist()\n\nplt.figure(figsize=(15,5))\nindex = 0\nfor file in files:\n    image = Image.open(path + file)\n    plt.subplot(1, 3, index + 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    index += 1\n\nplt.show()","357cd91f":"df3 = df_train[df_train[\"label\"] == \"3\"]\nfiles = df3[\"image_id\"].sample(3).tolist()\n\nplt.figure(figsize=(15,5))\nindex = 0\nfor file in files:\n    image = Image.open(path + file)\n    plt.subplot(1, 3, index + 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    index += 1\n\nplt.show()","dffd562b":"df4 = df_train[df_train[\"label\"] == \"4\"]\nfiles = df4[\"image_id\"].sample(3).tolist()\n\nplt.figure(figsize=(15,5))\nindex = 0\nfor file in files:\n    image = Image.open(path + file)\n    plt.subplot(1, 3, index + 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n    index += 1\n\nplt.show()","f39b92b1":"batch_size=16\nimage_size=300\n\ninput_shape = (image_size, image_size, 3)\ntarget_size = (image_size, image_size)","e295bebb":"img_augmentation = tf.keras.Sequential(\n    [\n        tf.keras.layers.experimental.preprocessing.RandomCrop(image_size, image_size),\n        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n        tf.keras.layers.experimental.preprocessing.RandomRotation(0.25),\n        tf.keras.layers.experimental.preprocessing.RandomZoom((-0.25, 0.25), (-0.25, 0.25)),\n    ])","b47196d2":"path = \"..\/input\/cassava-leaf-disease-classification\/train_images\/\"\nfiles = df_train[\"image_id\"].tolist()\nfile = random.choice(files)\nimage = Image.open(path + file)\nplt.imshow(image)\nplt.axis(\"off\")\nplt.show()","ee12853e":"image = tf.expand_dims(np.array(image), 0)\n\nplt.figure(figsize=(14, 14))\nfor i in range(9):\n    augmented_image = img_augmentation(image)\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(augmented_image[0])\n    plt.axis(\"off\")","ba1d8d16":"!pip install git+https:\/\/github.com\/mjkvaak\/ImageDataAugmentor","8de29586":"from ImageDataAugmentor.image_data_augmentor import *\nimport albumentations as A\n\ntrain_augmentations = A.Compose([\n            A.RandomCrop(image_size, image_size, p=1),\n            A.CoarseDropout(p=0.5),\n            A.Cutout(p=0.5),\n            A.Flip(p=0.5),\n            A.ShiftScaleRotate(p=0.5),\n            A.HueSaturationValue(p=0.5, hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2),\n            A.RandomBrightnessContrast(p=0.5, brightness_limit=(-0.2,0.2), contrast_limit=(-0.2, 0.2)),\n            A.ToFloat()\n            ], p=1)\n\nval_augmentations = A.Compose([\n                A.CenterCrop(image_size, image_size, p=1),\n                A.ToFloat()\n                ], p=1)","b8d60da1":"def TFDataGenerator(train_set, val_set):\n    \n    train_generator = ImageDataAugmentor(augment=train_augmentations)\n    val_generator = ImageDataAugmentor(augment=val_augmentations)\n    \n    train_datagen = train_generator.flow_from_dataframe(\n                  dataframe = train_set,\n                  directory='..\/input\/cassava-leaf-disease-classification\/train_images',\n                  x_col='image_id',\n                  y_col='label',\n                  target_size=target_size,\n                  batch_size=batch_size,\n                  shuffle=True,\n                  class_mode='categorical',\n                  seed=2020)\n\n    val_datagen = val_generator.flow_from_dataframe(\n                dataframe = val_set,\n                directory='..\/input\/cassava-leaf-disease-classification\/train_images',\n                x_col='image_id',\n                y_col='label',\n                target_size=target_size,\n                batch_size=batch_size,\n                shuffle=False,\n                class_mode='categorical',\n                seed=2020)\n    \n    return train_datagen, val_datagen","dc735418":"train_set = df_train.iloc[:10]\nval_set = df_train.iloc[-10:]\n\ntrain_datagen, val_datagen = TFDataGenerator(train_set, val_set)","f82ba58b":"train_images, _ = next(train_datagen)\n\nplt.figure(figsize=(14, 14))\nfor i in range(9):\n    image = train_images[i]\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n\nplt.show()","b75602c2":"val_images, _ = next(val_datagen)\n\nplt.figure(figsize=(14, 14))\nfor i in range(9):\n    image = val_images[i]\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(image)\n    plt.axis(\"off\")\n\nplt.show()","3bb10418":"def create_Inception():\n    base_model = InceptionV3(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n\n    # Rebuild top\n    inputs = Input(shape=input_shape)\n\n    model = base_model(inputs)\n    pooling = GlobalAveragePooling2D()(model)\n    dropout = Dropout(0.2)(pooling)\n\n    outputs = Dense(5, activation=\"softmax\", name=\"dense\", dtype='float32')(dropout)\n\n    # Compile\n    inception = Model(inputs=inputs, outputs=outputs)\n    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2, from_logits=True)\n\n    inception.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n    return inception","99999898":"def create_Xception():\n    base_model = Xception(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n\n    # Rebuild top\n    inputs = Input(shape=input_shape)\n\n    model = base_model(inputs)\n    pooling = GlobalAveragePooling2D()(model)\n    dropout = Dropout(0.2)(pooling)\n\n    outputs = Dense(5, activation=\"softmax\", name=\"dense\", dtype='float32')(dropout)\n\n    # Compile\n    xception = Model(inputs=inputs, outputs=outputs)\n    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2, from_logits=True)\n\n    xception.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n    return xception","b0a441be":"fold_number = 0\nn_splits = 3\nepochs = 8\n\ntf.keras.backend.clear_session()\nsss = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.1, random_state=2020)\nfor train_index, val_index in sss.split(df_train[\"image_id\"], df_train[\"label\"]):\n    train_set = df_train.loc[train_index]\n    val_set = df_train.loc[val_index]\n    train_datagen, val_datagen = TFDataGenerator(train_set, val_set)\n    model = create_Inception()\n    print(\"Training fold no.: \" + str(fold_number+1))\n\n    model_name = \"inception \"\n    fold_name = \"fold.h5\"\n    filepath = model_name + str(fold_number+1) + fold_name\n    callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.2),\n                 EarlyStopping(monitor='val_loss', patience=3),\n                 ModelCheckpoint(filepath=filepath, monitor='val_loss', save_best_only=True)]\n\n    history = model.fit(train_datagen, epochs=epochs, validation_data=val_datagen, callbacks=callbacks)\n    fold_number += 1\n    if fold_number == n_splits:\n        print(\"Training finished!\")","4543c258":"fold_number = 0\nn_splits = 3\nepochs = 8\n\ntf.keras.backend.clear_session()\nsss = StratifiedShuffleSplit(n_splits=n_splits, test_size=0.1, random_state=2020)\nfor train_index, val_index in sss.split(df_train[\"image_id\"], df_train[\"label\"]):\n    train_set = df_train.loc[train_index]\n    val_set = df_train.loc[val_index]\n    train_datagen, val_datagen = TFDataGenerator(train_set, val_set)\n    model = create_Xception()\n    print(\"Training fold no.: \" + str(fold_number+1))\n\n    model_name = \"xception \"\n    fold_name = \"fold.h5\"\n    filepath = model_name + str(fold_number+1) + fold_name\n    callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.2),\n                 EarlyStopping(monitor='val_loss', patience=3),\n                 ModelCheckpoint(filepath=filepath, monitor='val_loss', save_best_only=True)]\n\n    history = model.fit(train_datagen, epochs=epochs, validation_data=val_datagen, callbacks=callbacks)\n    fold_number += 1\n    if fold_number == n_splits:\n        print(\"Training finished!\")","ba7e3e1a":"models = []\nfor i in range(n_splits):\n    inception = load_model(\".\/inception \" + str(i+1) + \"fold.h5\")\n    models.append(inception)\n    \nfor i in range(n_splits):\n    xception = load_model(\".\/xception \" + str(i+1) + \"fold.h5\")\n    models.append(xception)","eb685160":"ss = pd.read_csv(os.path.join('..\/input\/cassava-leaf-disease-classification', \"sample_submission.csv\"))\npreds = []\nresults = []\n\nfor image_id in ss.image_id:\n    image = Image.open(os.path.join('..\/input\/cassava-leaf-disease-classification', \"test_images\", image_id))\n    image = image.resize((image_size, image_size))\n    image = np.expand_dims(image, axis = 0)\n    for model in models:\n        preds.append(np.argmax(model.predict(image)))\n    res = max(set(preds), key = preds.count)\n    results.append(res)\n\nss['label'] = results\nss.to_csv('submission.csv', index = False)","903753a5":"In this tutorial, I will run you through an end-to-end solution for classifying 4 different types of diseases found in Cassava Plants through Tensorflow & Keras. \n\nThe following topics will be covered:\n1. Exploratory Data Analysis\n2. Image Augmentation\n3. Model Building and Selection\n4. Stratified K-Fold Cross Validation\n5. Model Ensembling and Inference","35c25ff0":"### Label 2: Cassava Green Mottle (CGM)","8ca2ecc8":"# Image Augmentation (Tensorflow)\nImage augmentation is important as, with all Machine Learning problems, we do not want the model to \"memorise\" the training set. In this case, we do not want our algorithm to memorise features specific to the training images such as the orientation, position or shade of the cassava plant. Therefore, we need to augment the images so that the model is able to generalise well and not overfit to the training set.\n\nOne of the ways we can perform image augmentation is through Tensorflow preprocessing layers. They provide basic augmentations such as cropping, flipping and rotating.","2e6bbc1d":"And now our validation set:","2d5ff9be":"### Label 0: Cassava Bacterial Blight (CBB)","561a825d":"We will be using two model architectures, InceptionV3 and Xception, for our model ensembling. I chose Stochastic Gradient Descent (SGD) with momentum as it generalizes better. Additionally, I enabled Nesterov momentum as it (theoretically) converges to a minimum more quickly. To understand the math behind the two implementations of SGD with momentum, refer to this: https:\/\/stats.stackexchange.com\/questions\/179915\/whats-the-difference-between-momentum-based-gradient-descent-and-nesterovs-acc\n\n![](https:\/\/i.stack.imgur.com\/YrpGA.png)","0956d9a8":"Now let's see how an image looks like pre-augmentation and post-augmentation.","8549a018":"### Label 4: Healthy","1f0d2dd4":"### Label 3: Cassava Mosiac Disease (CMD)","c5533704":"# Image Augmentation (Albumentations)\nI will now show you how to perform image augmentations through Albumentation (an external image augmentation library with much more functionality) through both ImageDataGenerator. We will use a tool called ImageDataAugmentor (big thanks to mjkvaak at github) that allows us to do this.","c77645ef":"### Label 1: Cassava Brown Streak Disease (CBSD)","9699845e":"And done! Please upvote this notebook if you liked it, it inspires me to make more quality notebooks. Thank you!","6d8ff4eb":"Now, we will take a look at the distribution of our data.","7191609e":"# Importing Libraries and Data","ad1e3644":"Now let's see how the generated images look like post-augmentation for our training set.","4ae5a061":"# Cassava Plant Disease Classification\n![](https:\/\/cff2.earth.com\/uploads\/2020\/11\/11065615\/shutterstock_12823926312-scaled.jpg)","200cb191":"# Training with Stratified K-Fold Cross Validation\nWe need to train our models with k-fold cross validation to ensure that our model isn't overfitting on the training data (or rather, specific aspects of the training data). Stratified k-fold cv ensures that we have the same class representation in every fold. Here's a brief intuition:\n\n![](https:\/\/scikit-learn.org\/stable\/_images\/sphx_glr_plot_cv_indices_0041.png)\n\nIn our case, we take 90% of the train images for training and 10% for testing. However, this split can be arbitary. Moreover, we saw earlier on that the data is imbalanced. Typically, the class with the most images will be the easiest to predict as the model is able to train much better with more data. Hence, splitting the dataset randomly can cause huge variance in the model's performance. For example, on some splits, the model might get a validation subset that is easy to predict.. On others, it might get a difficult subset to predict.\n\nBy using stratified cross validation, we ensure that a different subset of the data is split into training and test sets every time. Additionally, we ensure that class representation remains the same for all subsets, thereby allocating equal difficulty in all subsets.\n\nWe will only do a stratified 3-fold cv this time due to time constraints.","9637ae92":"First, let's take a look at our dataframe.","438d862a":"# Model Building and Selection\nEarlier on, I mentioned that to counter mislabelling, we would implement label smoothing on our loss metric (in this case, categorical cross-entropy). Here's how it works:\n\nWhen we apply the cross-entropy loss to a classification task, we\u2019re expecting true labels to be 1, while the others to be 0. In other words, we are sure that the labels are 100% correct. However, we already know that ***they are not!***\n\nOne way to circumvent this is to lower the confidence level of our labels. So instead of being 100% confident (or sure) that our labels are correct, we can be 90% or even 80% confident instead. This allows the model to \"learn\" that some the labels are not correct and make better predictions.\n\nOriginally, if an image is labelled \"0\" (Cassava Bacterial Blight Disease), the resulting one-hot label would be this: [1, 0, 0, 0, 0]. However, after applying label smoothing, then we get new one-hot labels according to this formula:\n\nnew_onehot_labels = onehot_labels * (1 - label_smoothing) + label_smoothing \/ num_classes\n\nIn our case, with a label smoothing value of 0.2, \n\nnew_onehot_labels \n\n= [1, 0, 0, 0, 0] * (1 - 0.2) + 0.2 \/ 5\n\n= [1, 0, 0, 0, 0] * 0.8 + 0.04\n\n= [0.84, 0.04, 0.04, 0.04, 0.04]\n                  \nThis means that we are ~84% confident in our labels!","16e8fc37":"From here, we can see that we have a highly unbalanced dataset. We have the largest number of samples for label 3, Cassava Mosiac Disease (CMD), and the fewest number of samples for label 0, Cassava Bacterial Blight (CBB). Let's visualize how some of these images look like next.","b394b379":"# Model Ensembling and Inference\nThis is the part where you should take the code below into a separate inference notebook with minor code changes to the filepaths. Reason being that we needed the internet enabled to install ImageDataAugmentor but internet access is not allowed in this competition. ","3162332c":"# Exploratory Data Analysis","9b49ae24":"Here are 9 possible outcomes after augmentation.","2fc46b48":"Note that the images in this training set are \"noisy\". This means that there are some images that are mislabelled and hence will affect predictive performance. One of the basic ways to mitigate this is to use label smoothing on our loss metric, as you will see later on."}}