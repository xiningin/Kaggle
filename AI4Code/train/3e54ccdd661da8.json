{"cell_type":{"975db2aa":"code","417c9b44":"code","abbd3a2f":"code","0fb1d31f":"code","99fea311":"code","cf70b3ff":"code","18aab2b3":"code","5ded1851":"code","f521dc55":"code","c6a20a47":"code","16e6f610":"code","0ab21f51":"code","559ba480":"code","2ab0da94":"code","a7fcbac3":"code","60dee083":"code","c17ddda4":"code","0ce0c91a":"code","8d53e860":"code","19e13515":"code","b4485f63":"code","c4542a90":"code","bb32dedd":"code","f78109ce":"code","ef5ef7a0":"code","968359c1":"code","390774a6":"markdown","c5f8d23b":"markdown","c377f087":"markdown"},"source":{"975db2aa":"import pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')","417c9b44":"df_train = pd.read_csv(\"..\/input\/train.csv\", index_col=\"Id\")\ndf_test = pd.read_csv(\"..\/input\/test.csv\", index_col=\"Id\")\nprint (df_train.shape)\nprint (df_test.shape)","abbd3a2f":"df_train.head()","0fb1d31f":"df_train.columns[df_train.isna().sum()>0]","99fea311":"missing = pd.DataFrame(df_train.isna().sum() \/ df_train.shape[0], columns = ['Percentage']).sort_values(by='Percentage', ascending=False)\nmissing[missing['Percentage']>0]","cf70b3ff":"columns_50less = missing[missing['Percentage']>=0.5].index\n\ndf_train.drop(columns_50less, axis = 1, inplace=True)\ndf_test.drop(columns_50less, axis = 1, inplace=True)","18aab2b3":"from sklearn.impute import SimpleImputer\n\nX = df_train.drop(['SalePrice'], axis =1)\ny = df_train.SalePrice","5ded1851":"numerical_cols = [nname for nname in X.columns\n                           if X[nname].dtype in ['int64','float64']]\n\ncategorical_cols = [cname for cname in X.columns\n                           if X[cname].dtype == 'object']\n\ncols = numerical_cols + categorical_cols\n\ndf_train = df_train[cols]\ndf_test = df_test[cols]","f521dc55":"numerical_imputer = SimpleImputer(strategy = 'median')\n\nimputed_train_num = pd.DataFrame(numerical_imputer.fit_transform(X[numerical_cols]))\nimputed_test_num = pd.DataFrame(numerical_imputer.transform(df_test[numerical_cols]))\n","c6a20a47":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nimputed_train_num=pd.DataFrame(scaler.fit_transform(imputed_train_num))\nimputed_test_num=pd.DataFrame(scaler.transform(imputed_test_num))\n\n\nimputed_train_num.columns = X[numerical_cols].columns\nimputed_test_num.columns = df_test[numerical_cols].columns","16e6f610":"categorical_imputer = SimpleImputer(strategy = 'most_frequent')\n\nimputed_train_cat = pd.DataFrame(categorical_imputer.fit_transform(X[categorical_cols]))\nimputed_test_cat = pd.DataFrame(categorical_imputer.transform(df_test[categorical_cols]))","0ab21f51":"imputed_train_num.head()","559ba480":"print (imputed_train_num.shape)\nprint (imputed_train_cat.shape)","2ab0da94":"imputed_train = pd.concat([imputed_train_num , imputed_train_cat], axis = 1)\nimputed_test = pd.concat([imputed_test_num , imputed_test_cat], axis = 1)","a7fcbac3":"imputed_train=pd.get_dummies(imputed_train)\nimputed_test=pd.get_dummies(imputed_test)","60dee083":"keep_train = [cname for cname in imputed_train.columns\n            if cname in imputed_test.columns]\n\nkeep_test = [cname for cname in imputed_test.columns\n            if cname in imputed_train.columns]","c17ddda4":"imputed_train_X = imputed_train[keep_train]\nimputed_test_X = imputed_test[keep_test]","0ce0c91a":"imputed_train_X.shape","8d53e860":"imputed_test_X.shape","19e13515":"from sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor","b4485f63":"params = {'alpha': [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]}\n\nparams_elastic ={'alpha': [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75],\n                'l1_ratio': [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]}","c4542a90":"ridge_cv = GridSearchCV(Ridge(), params, scoring = 'neg_mean_absolute_error')\n\nlasso_cv = GridSearchCV(Lasso(), params, scoring = 'neg_mean_absolute_error')","bb32dedd":"scores = -1 * cross_val_score(LinearRegression(),imputed_train_X,y,cv=5, \n                              scoring = \"neg_mean_absolute_error\")\n\nscores_ridge = -1 * cross_val_score(ridge_cv,imputed_train_X,y,cv=5, \n                              scoring = \"neg_mean_absolute_error\")\n\nscores_lasso = -1 * cross_val_score(lasso_cv,imputed_train_X,y,cv=5, \n                              scoring = \"neg_mean_absolute_error\")\n\nscores_rf = -1 * cross_val_score(RandomForestRegressor(),imputed_train_X,y,cv=5, \n                              scoring = \"neg_mean_absolute_error\")\n\nscores_xgb = -1 * cross_val_score(XGBRegressor(),imputed_train_X,y,cv=5, \n                              scoring = \"neg_mean_absolute_error\")","f78109ce":"imputed_train_X.head()","ef5ef7a0":"print (\"Linear Regression: %.3f\" %scores.mean())\nprint (\"Ridge Regression: %.3f\" %scores_ridge.mean())\nprint (\"Lasso Regression: %.3f\" %scores_lasso.mean())\nprint (\"RandomForest: %.3f\" %scores_rf.mean())\nprint (\"XGBoosting: %.3f\" %scores_xgb.mean())","968359c1":"output = pd.DataFrame({'Id':  df_test.index,\n                      'SalePrice': XGBRegressor().fit(imputed_train_X, y).predict(imputed_test_X)})\n\noutput.to_csv(\"submission.csv\", index=False)","390774a6":"# Final Prediction Output","c5f8d23b":"# Future Work\n\n1. Feature Selection\n2. Feature Extraction","c377f087":"# Missing Values\n\nThis dataset has 80 variables and some have many missing data. We need to deal with those missing data.\n\n**Approaches**:\n1. Drop columns that misses 50%+ of values\n2. Impute numerical values with their medians\n3. Impute categorical values with their most frequent values"}}