{"cell_type":{"a08aa9c9":"code","b4d7625c":"code","dbe4c639":"code","20ac366a":"code","20e028ff":"code","4a2d2339":"code","4c39e6a5":"code","d2fed564":"code","c9efb7fd":"code","038841bb":"code","8ff31890":"code","2dba6c88":"code","b9e3b395":"code","574bfdeb":"code","6f53629d":"code","0ffc3186":"code","812c14de":"code","6d705b4f":"code","57c25421":"code","172797bf":"code","a618f5af":"code","7a8f4df5":"code","0a6f57d0":"code","0367e652":"code","5d039ae7":"code","86b40730":"code","66941243":"code","6c020ebd":"code","2fe7d5f1":"code","857d5235":"code","0dae013f":"code","363bf1d5":"code","268f936d":"code","86c06c3a":"code","0ca7ce91":"code","d88c7690":"code","93770d36":"code","1f2f6638":"code","e15eb2b0":"code","18c9cf02":"code","48e55380":"code","f2f2176d":"code","4c92fbce":"code","08bd3fca":"code","f2c430f5":"code","ffa55c99":"code","732f0d18":"code","fae1da29":"markdown","106d39d5":"markdown","d8c1782d":"markdown","a931bf7f":"markdown","3b5201c7":"markdown","4e0d4fbd":"markdown","ba0220c7":"markdown","8a346f0d":"markdown","1a72d778":"markdown","8e67bc53":"markdown","d7f90939":"markdown","2aa29f0c":"markdown","f8ffcfd3":"markdown","4be62431":"markdown","9c588ae7":"markdown","b5f04636":"markdown","8ccfde85":"markdown","48abd785":"markdown","d25e8404":"markdown","ce22de0e":"markdown","523ba8e8":"markdown","7cd3b5e5":"markdown","ce84256d":"markdown","95e114c1":"markdown","340cf161":"markdown","72e52297":"markdown","d4591ef7":"markdown","72a14d8b":"markdown","f746cf61":"markdown","bf593fe2":"markdown","8579f832":"markdown","6c926a24":"markdown","8a7db2c9":"markdown","11ea9f1d":"markdown","8536f04f":"markdown","ae409172":"markdown","8e67903e":"markdown","e139f3dd":"markdown","764ec32c":"markdown","f261faad":"markdown","56e95d2e":"markdown","fd8aac1d":"markdown","0e1ef1e3":"markdown","b8d4bffb":"markdown","c9110655":"markdown","86572157":"markdown","1dfb6541":"markdown","94661baa":"markdown","f7440bca":"markdown","b3dd1567":"markdown","9af03f85":"markdown"},"source":{"a08aa9c9":"import numpy as np\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt","b4d7625c":"list_of_dicts = [ \n     {\"name\": \"Ginger\", \"breed\": \"Dachshund\", \"height_cm\": 22,\"weight_kg\": 10, \"date_of_birth\": \"2019-03-14\"},\n    {\"name\": \"Scout\", \"breed\": \"Dalmatian\", \"height_cm\": 59,\"weight_kg\": 25, \"date_of_birth\": \"2019-05-09\"}\n]\nnew_dogs = pd.DataFrame(list_of_dicts)\nnew_dogs","dbe4c639":"dict_of_lists = { \n     \"name\": [\"Ginger\", \"Scout\"], \n     \"breed\": [\"Dachshund\", \"Dalmatian\"], \n     \"height_cm\": [22, 59], \n     \"weight_kg\": [10, 25], \n     \"date_of_birth\": [\"2019-03-14\",\"2019-05-09\"]  } \nnew_dogs = pd.DataFrame(dict_of_lists) \nnew_dogs","20ac366a":"# read CSV from using pandas\navocado = pd.read_csv(\"..\/input\/avocado-prices\/avocado.csv\")\n# print the first few rows of the dataframe\navocado.head()","20e028ff":"# read CSV from using pandas and assigning Date as index of the dataframe\navocado = pd.read_csv(\"..\/input\/avocado-prices\/avocado.csv\",parse_dates=True, index_col='Date')\n# print the first few rows of the dataframe\navocado.head()","4a2d2339":"avocado = avocado.reset_index(drop=True)\navocado.head()","4c39e6a5":"avocado.to_csv(\"test_write.csv\")","d2fed564":"avocado = pd.read_csv(\"..\/input\/avocado-prices\/avocado.csv\")\navocado.head()","c9efb7fd":"avocado.tail(10)","038841bb":"avocado.info()","8ff31890":"print(avocado.shape)","2dba6c88":"avocado.describe()","b9e3b395":"avocado.values","574bfdeb":"print(avocado.columns)","6f53629d":"even = pd.Series([2,4,6,8,10])\nodd = pd.Series([1,3,5,7,9])\n\nres = even.append(odd)\nres","0ffc3186":"res.reset_index(drop=True)","812c14de":"# sort values based on \"AveragePrice\" (ascending) and \"year\" (descending)\navocado.sort_values([\"AveragePrice\", \"year\"], ascending=[True, False]) ","6d705b4f":"# Subsetting columns\navocado[\"AveragePrice\"]","57c25421":"# Subsetting multiple columns\navocado[[\"AveragePrice\",\"Date\"]]","172797bf":"# Subsetting rows\navocado[\"AveragePrice\"]<1","a618f5af":"# This will print only the rows with price < 1\navocado[avocado[\"AveragePrice\"]<1]","7a8f4df5":"# it will print all the rows with \"type\" = \"organic\"\navocado[avocado[\"type\"]==\"organic\"]","0a6f57d0":"# it will print all the rows with \"Date\" <= 2015-02-04\navocado[avocado[\"Date\"]<=\"2015-02-04\"]","0367e652":"# it will print all the rows with \"Date\" before 2015-02-04 and \"type\" == \"organic\"\navocado[(avocado[\"Date\"]<\"2015-02-04\") & (avocado[\"type\"]==\"organic\")]","5d039ae7":"# subset the avocado in the region Boston or SanDiego\nregionFilter = avocado[\"region\"].isin([\"Boston\", \"SanDiego\"])\navocado[regionFilter]","86b40730":"# subset the avocado in the region Boston or SanDiego in the year 2016 or 2017\nregionFilter = avocado[\"region\"].isin([\"Boston\", \"SanDiego\"])\nyearFilter = avocado[\"year\"].isin([\"2016\", \"2017\"])\navocado[regionFilter & yearFilter]","66941243":"avocado.isna()","6c020ebd":"avocado.isna().any()","2fe7d5f1":"avocado.isna().sum()","857d5235":"# Luckily we don't have any NaN but if we have we can use any of the two methods\n\navocado.dropna()\n\n# ****  OR  ****\n\nmeanVal = avocado[\"AveragePrice\"].mean()\navocado.fillna(meanVal)","0dae013f":"avocado[\"AveragePricePer100\"] = avocado[\"AveragePrice\"] * 100\navocado","363bf1d5":"avocado.drop([\"AveragePricePer100\"],axis = 1)","268f936d":"# mean of the AveragePrice of avocado\navocado[\"AveragePrice\"].mean()","86c06c3a":"avocado[\"Date\"].max()","0ca7ce91":"def pct30(column):     \n    #return the 0.3 quartile\n    return column.quantile(0.3)\ndef pct50(column):     \n    #return the 0.5 quartile\n    return column.quantile(0.5)\n\navocado[[\"AveragePrice\",\"Total Bags\"]].agg([pct30,pct50])","d88c7690":"temp = avocado.drop_duplicates(subset=[\"year\"])\ntemp","93770d36":"# count number of avocado in each year in descending order\navocado[\"year\"].value_counts(sort=True, ascending = False)","1f2f6638":"# group by multiple columns and perform multiple summary statistic operations\navocado.groupby([\"year\",\"type\"])[\"AveragePrice\"].agg([min,max,np.mean,np.median])","e15eb2b0":"# this is the same table we build in the previous cell but using pivot table\navocado.pivot_table(index=[\"year\",\"type\"], aggfunc=[min,max,np.mean,np.median], values=\"AveragePrice\")","18c9cf02":"regionIndex = avocado.set_index([\"region\"])\nregionIndex","48e55380":"# Insted of doing this\navocado[avocado[\"region\"].isin([\"Albany\", \"WestTexNewMexico\"])]","f2f2176d":"# we can simply do\nregionIndex.loc[[\"Albany\", \"WestTexNewMexico\"]]","4c92fbce":"avocado[\"AveragePrice\"].hist(bins=20)\nplt.show()","08bd3fca":"regionFilter = avocado.groupby(\"region\")[\"AveragePrice\"].mean().head(10)\nregionFilter","f2c430f5":"regionFilter.plot(kind = \"bar\",rot=45,title=\"Average price in 10 regions\")","ffa55c99":"avocado.plot(x=\"AveragePrice\", y=\"Total Volume\", kind=\"scatter\")","732f0d18":"# subtract AveragePrice with AveragePrice :P\n# Dah its 0\navocado[\"AveragePrice\"].sub(avocado[\"AveragePrice\"]) ","fae1da29":"### Subsetting multiple columns","106d39d5":"<a id=\"Explicit-indexes\"><\/a>\n# Explicit indexes\nIndexes make subsetting simpler using .loc and .iloc","d8c1782d":"## Join\n> DataFrame.merge(self, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None) \u2192 'DataFrame'[source]\u00b6\nMerge DataFrame or named Series objects with a database-style join.\n\nThe join is done on columns or indexes. If joining columns on columns, the DataFrame indexes will be ignored. Otherwise if joining indexes on indexes or indexes on a column or columns, the index will be passed on.\n\nParameters\nrightDataFrame or named Series\nObject to merge with.\n\nhow{\u2018left\u2019, \u2018right\u2019, \u2018outer\u2019, \u2018inner\u2019}, default \u2018inner\u2019\non: label or list\nColumn or index level names to join on. These must be found in both DataFrames. If on is None and not merging on indexes then this defaults to the intersection of the columns in both DataFrames.\n\nleft_on: label or list, or array-like\nColumn or index level names to join on in the left DataFrame. Can also be an array or list of arrays of the length of the left DataFrame. These arrays are treated as if they are columns.\n\nright_on: label or list, or array-like\nColumn or index level names to join on in the right DataFrame. Can also be an array or list of arrays of the length of the right DataFrame. These arrays are treated as if they are columns.\n\nleft_index: bool, default False\nUse the index from the left DataFrame as the join key(s). If it is a MultiIndex, the number of keys in the other DataFrame (either the index or a number of columns) must match the number of levels.\n\nright_index: bool, default False\nUse the index from the right DataFrame as the join key. Same caveats as left_index.\n\nsort: bool, default False\nSort the join keys lexicographically in the result DataFrame. If False, the order of the join keys depends on the join type (how keyword).\n\nsuffixes: tuple of (str, str), default (\u2018_x\u2019, \u2018_y\u2019)\nSuffix to apply to overlapping column names in the left and right side, respectively. To raise an exception on overlapping columns use (False, False).","a931bf7f":"### We can use .any() function to get a consise info","3b5201c7":"<a id=\"Counting-missing-values\"><\/a>\n# Counting missing values","4e0d4fbd":"### Read CSV and assign index\n<p>You can assign columns as index using \"index_col\" attribute.<\/p>\n<p>Since I want to index Date there is another helpful function called \"parse_date\" which will parse the date in the rows such that we can perform more complex subsetting(eg monthly, weekly etc).<\/p>","ba0220c7":"<a id=\"Arithmetic-with-Series-DataFrames\"><\/a>\n# Arithmetic with Series & DataFrames\n\nYou can use arithmetic operators directly on series but sometimes you need more control while performing these operations, here is where these explicit arithmetic functions come into the picture\n\nAdd\/Subtract function (just replece add with sub)\n```\nSyntax: Series.add(other, level=None, fill_value=None, axis=0)\n\nParameters:\nother: other series or list type to be added into caller series\nfill_value: Value to be replaced by NaN in series\/list before adding\nlevel: integer value of level in case of multi index\n\nReturn type: Caller series with added values\n```\n\nMultiplication function\n```\nSyntax: Series.mul(other, level=None, fill_value=None, axis=0)\n\nParameters:\nother: other series or list type to be added into caller series\nfill_value: Value to be replaced by NaN in series\/list before adding\nlevel: integer value of level in case of multi index\n\nReturn type: Caller series with added values\n```\n\nDivision function\n```\nSyntax: Series.div(other, level=None, fill_value=None, axis=0)\n\nParameters:\nother: other series or list type to be divided by the caller series\nfill_value: Value to be replaced by NaN in series\/list before division\nlevel: integer value of level in case of multi index\n\nReturn type: Caller series with divided values\n```","8a346f0d":"* **.info()** is used to get a concise summary of the DataFrame","1a72d778":"### Subsetting based on multiple conditions\nYou can use the logical operators to define a complex condition<br>\n* \"&\" and\n* \"|\" or\n* \"~\" not\n\n> ** SEPERATE EACH CONDITION WITH PARENTHESES TO AVOID ERRORS**","8e67bc53":"<a id=\"Creating-DataFrames\"><\/a>\n# Creating DataFrames\n* From a list of dictionaries (constructed row by row)","d7f90939":"### Summarizing dates\n\nTo find the min or max date in a dataframe","2aa29f0c":"### Multiple parameter Filtering\nUse logical operators to combine different filters","f8ffcfd3":"<a id=\"Subsetting-using\"><\/a>\n# Subsetting using .isin()\nisin() method helps in selecting rows with having a particular(or Multiple) value in a particular column\n\n> Syntax: DataFrame.isin(values)\n> \n> Parameters:\n> values: iterable, Series, List, Tuple, DataFrame or dictionary to check in the caller Series\/Data Frame.\n> \n> Return Type: DataFrame of Boolean of Dimension.\n> ","4be62431":"and then using it for subsetting the original dataframe","9c588ae7":"<a id=\"Visualizing-your-data\"><\/a>\n# Visualizing your data","b5f04636":"<a id=\"Removing-missing-values\"><\/a>\n# Removing missing values\n* Drop NaN ** .dropna() **\n* Fill NaN with value x ** .fillna(x) **","8ccfde85":"<a id=\"Merge-DataFrames\"><\/a>\n# Merge DataFrames\n\nSyntax:\n> DataFrame.merge(self, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None) \u2192 'DataFrame'[source]\u00b6\nMerge DataFrame or named Series objects with a database-style join.\n\nThe join is done on columns or indexes. If joining columns on columns, the DataFrame indexes will be ignored. Otherwise if joining indexes on indexes or indexes on a column or columns, the index will be passed on.\n\nParameters\nright: DataFrame or named Series\nObject to merge with.\n\nhow{\u2018left\u2019, \u2018right\u2019, \u2018outer\u2019, \u2018inner\u2019}, default \u2018inner\u2019\n\non: label or list\nColumn or index level names to join on. These must be found in both DataFrames. If on is None and not merging on indexes then this defaults to the intersection of the columns in both DataFrames.\n\nleft_on: label or list, or array-like\nColumn or index level names to join on in the left DataFrame. Can also be an array or list of arrays of the length of the left DataFrame. These arrays are treated as if they are columns.\n\nright_on: label or list, or array-like\nColumn or index level names to join on in the right DataFrame. Can also be an array or list of arrays of the length of the right DataFrame. These arrays are treated as if they are columns.\n\nleft_index: bool, default False\nUse the index from the left DataFrame as the join key(s). If it is a MultiIndex, the number of keys in the other DataFrame (either the index or a number of columns) must match the number of levels.\n\nright_index: bool, default False\nUse the index from the right DataFrame as the join key. Same caveats as left_index.\n\nsort: bool, default False\nSort the join keys lexicographically in the result DataFrame. If False, the order of the join keys depends on the join type (how keyword).\n\nsuffixes: tuple of (str, str), default (\u2018_x\u2019, \u2018_y\u2019)\nSuffix to apply to overlapping column names in the left and right side, respectively. To raise an exception on overlapping columns use (False, False).","48abd785":"* **.values** this attribute return a Numpy representation of the given DataFrame","d25e8404":"<a id=\"Pivot-table\"><\/a>\n# Pivot table\nA pivot table is a table of statistics that summarizes the data of a more extensive table.\n\nIMPORRANT parements to remember are<br>\n\"index\": it is the value that appeares on the left most side of the table (it can be a list)<br>\n\"columns\": these are the column you want to add to the pivot table<br>\n\"aggfunc\": it will call the function (it can be a list)<br>\n\"values\": it is the attribute which will be summarized in the table (values inside the table)<br>\n\n> Syntax<br>\n> pandas.pivot_table(data, values=None, index=None, columns=None, aggfunc=\u2019mean\u2019, fill_value=None, margins=False, dropna=True, margins_name=\u2019All\u2019)<br>\n> \n> Parameters:<br>\ndata : DataFrame<br>\nvalues : column to aggregate, optional<br>\nindex: column, Grouper, array, or list of the previousv\ncolumns: column, Grouper, array, or list of the previous<br>\n> \n> aggfunc: function, list of functions, dict, default numpy.mean<br>\n....If list of functions passed, the resulting pivot table will have hierarchical columns whose top level are the function names.<br>\n....If dict is passed, the key is column to aggregate and value is function or list of functions<br>\nfill_value[scalar, default None] : Value to replace missing values with<br>\nmargins[boolean, default False] : Add all row \/ columns (e.g. for subtotal \/ grand totals)<br>\ndropna[boolean, default True] : Do not include columns whose entries are all NaN<br>\nmargins_name[string, default \u2018All\u2019] : Name of the row \/ column that will contain the totals when margins is True.<br>\n> \n> Returns: DataFrame","ce22de0e":"### Remove index from dataframe .reset_index(drop)\n\nTo reset the index use this function","523ba8e8":"<a id=\"What-next\"><\/a>\n# What next?\n\nTry to use your skills on some other dataset<br>\n\nHave a look at my analysis of some other datasets :P\n* [Android App Market on Google Play](https:\/\/www.kaggle.com\/mohammedmurtuzalabib\/android-app-market-on-google-play-analysis)\n* [MNIST Ensemble of 5 CNNS to get 0.99742 score!!](https:\/\/www.kaggle.com\/mohammedmurtuzalabib\/mnist-ensemble-of-5-cnns-0-99742)\n* [Titanic Survival](https:\/\/www.kaggle.com\/mohammedmurtuzalabib\/titanic-survival-analysis)\n\nPlease upvote if you find it helpful :D","7cd3b5e5":"### Setting column as the index","ce84256d":"### Bar plots","95e114c1":"### Subsetting based on dates","340cf161":"### Subsetting based on text data","72e52297":"### Scatter plot","d4591ef7":"<a id=\".agg-method\"><\/a>\n# .agg() method\n\nPandas Series.agg() is used to pass a function or list of function to be applied on a series or even each element of series separately.\n\n> Syntax: Series.agg(func, axis=0)\n> \n> Parameters:\n> func: Function, list of function or string of function name to be called on Series.\n> axis:0 or \u2018index\u2019 for row wise operation and 1 or \u2018columns\u2019 for column wise operation.\n> \n> Return Type: The return type depends on return type of function passed as parameter.","72a14d8b":"# Some useful pandas function\n\n* **.head()** or **.head(x)** is used to get the first x rows of the DataFrame (x = 5 by default)","f746cf61":"* **.shape** is used to get the dimensions of the DataFrame","bf593fe2":"<a id=\"Detecting-missing-values\"><\/a>\n# Detecting missing values .isna()\n\n.isna() is a method used to find is there exist any NaN values in the DataFrame\n\nIt will give a True bool value if a cell has a NaN value","8579f832":"* **.tail()** or **.tail(x)** is used to get the last x rows of the DataFrame (x = 5 by default)","6c926a24":"# Pandas 101: One-stop Shop for Data Science\n\n### This notebook can be treated as pandas cheatsheet or a beginner-friendly guide to learn from basics.\n\nLast updated on 24-May-2020 (Appending & Concatenating Series)\n\n[1. Creating DataFrames](#Creating-DataFrames)<br>\n[2. Reading and writing CSVs](#Reading-and-writing-CSVs)<br>\n[3. Some useful pandas function](#Some-useful-pandas-function)<br>\n[4. Appending & Concatenating Series](#Appending-Concatenating-Series)<br>\n[5. Sorting](#Sorting)<br>\n[6. Subsetting](#Subsetting)<br>\n[7. Subsetting using .isin()](#Subsetting-using)<br>\n[8. Detecting missing values .isna()](#Detecting-missing-values)<br>\n[9. Counting missing values](#Counting-missing-values)<br>\n[10. Removing missing values](#Removing-missing-values)<br>\n[11. Adding a new column](#Adding-a-new-column)<br>\n[12. Deleting columns in DataFrame](#Deleting-columns-in-DataFrame)<br>\n[13. Summary statistics](#Summary-statistics)<br>\n[14. agg() method](#.agg-method)<br>\n[15. Dropping duplicate names](#Dropping-duplicate-names)<br>\n[16. Count categorical data](#Count-categorical-data)<br>\n[17. Grouped summaries](#Grouped-summaries)<br>\n[18. Pivot table](#Pivot-table)<br>\n[19. Explicit indexes](#Explicit-indexes)<br>\n[20. Visualizing your data](#Visualizing-your-data)<br>\n[21. Arithmetic with Series & DataFrames](#Arithmetic-with-Series-DataFrames)<br>\n[21. Merge DataFrames](#Merge-DataFrames)<br>\n[23. What next?](#What-next)<br>\n\n\"Avocado Prices\" dataset is used in this notebook :)","8a7db2c9":"<a id=\"Summary-statistics\"><\/a>\n# Summary statistics\nSome of the functions availabe in pandas are:\n\n> .median() .mode() .min() .max() .var() .std() .sum() .quantile()","11ea9f1d":"<a id=\"Grouped-summaries\"><\/a>\n# Grouped summaries .groupby(col)\nThis function will group similar categories into one and then we can perform some summary statistics\n\n> Syntax: DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, **kwargs)\n> \n> Parameters :\n> by : mapping, function, str, or iterable<br>\n> axis : int, default 0<br>\n> level : If the axis is a MultiIndex (hierarchical), group by a particular level or levels<br>\n> as_index : For aggregated output, return object with group labels as the index. Only relevant for DataFrame input. as_index=False is effectively \u201cSQL-style\u201d grouped output<br>\n> sort : Sort group keys. Get better performance by turning this off. Note this does not influence the order of observations within each group. groupby preserves the order of rows within each group.<br>\n> group_keys : When calling apply, add group keys to index to identify pieces<br>\n> squeeze : Reduce the dimensionality of the return type if possible, otherwise return a consistent type<br>\n> \n> Returns : GroupBy object","8536f04f":"To write a CSV file function dataframe.to_csv(FILE_NAME)","ae409172":"<a id=\"Sorting\"><\/a>\n# Sorting\nsyntax:<br>\n> DataFrame.sort_values(by, axis=0, ascending=True, inplace=False, kind=\u2019quicksort\u2019, na_position=\u2019last\u2019)\n\n* by: Single\/List of column names to sort Data Frame by.\n* axis: 0 or \u2018index\u2019 for rows and 1 or \u2018columns\u2019 for Column.\n* ascending: Boolean value which sorts Data frame in ascending order if True.\n* inplace: Boolean value. Makes the changes in passed data frame itself if True.\n* kind: String which can have three inputs(\u2018quicksort\u2019, \u2018mergesort\u2019 or \u2018heapsort\u2019) of algorithm used to sort data frame.\n* na_position: Takes two string input \u2018last\u2019 or \u2018first\u2019 to set position of Null values. Default is \u2018last\u2019.","8e67903e":"### Subsetting rows","e139f3dd":"More updates will come soon, please wait :)","764ec32c":"<a id=\"Appending-Concatenating-Series\"><\/a>\n# Appending & Concatenating Series\n\nappend(): Series & DataFrame method\n* Invocation:\n* s1.append(s2)\n* Stacks rows of s2 below s1 \n<br>\n<br>\n<br>\nconcat(): pandas module function<br>\n* Invocation:\n* pd.concat([s1, s2, s3])\n* Can stack row-wise or column-wise","f261faad":"<a id=\"Dropping-duplicate-names\"><\/a>\n# Dropping duplicate names .drop_duplicates(lst)\nDelete all the duplicate names from the dataframe\n\n","56e95d2e":"### Observe index got messed up\n\nYou can use .reset_index(drop=True) to fix it<br>\nNote: if drop = False then previous index will be added as a column","fd8aac1d":"### Sorting by index\n\nuse df.sort_index(ascending=True\/False)","0e1ef1e3":"* **.columns** this attribute return a Numpy representation of columns in the DataFrame","b8d4bffb":"### Histograms\nuse the function .hist()","c9110655":"* **.describe()** is used to view some basic statistical details like percentile, mean, std etc. of a DataFrame","86572157":"<a id=\"Deleting-columns-in-DataFrame\"><\/a>\n# Deleting columns in DataFrame .drop(lst,axis = 1)\n> dataFrame.drop(['COLUMN_NAME'], axis = 1)\n* the first parameter is a list of columns to be deleted\n* axis = 1 means delete column\n* axis = 0 means delete row","1dfb6541":"<a id=\"Count-categorical-data\"><\/a>\n# Count categorical data .value_counts()\n\nPandas Series.value_counts() function return a Series containing counts of unique values.\n\n> Syntax: Series.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True)\n> \n> Parameter :\nnormalize : If True then the object returned will contain the relative frequencies of the unique values.\nsort : Sort by values.\nascending : Sort in ascending order.\nbins : Rather than count values, group them into half-open bins, a convenience for pd.cut, only works with numeric data.\ndropna : Don\u2019t include counts of NaN.\n> \n> Returns : counts : Series","94661baa":"<a id=\"Reading-and-writing-CSVs\"><\/a>\n# Reading and writing CSVs\n* CSV = comma-separated values \n* Designed for DataFrame-like data \n* Most database and spreadsheet programs can use them or create them","f7440bca":"<a id=\"Subsetting\"><\/a>\n# Subsetting\n\nSubsetting is used to get a slice of the original dataframe","b3dd1567":"* From a dictionary of lists (constructed column by column)","9af03f85":"<a id=\"Adding-a-new-column\"><\/a>\n# Adding a new column\nIt can easily be done using the [ ] brackets\n\nLets add a new column to our dataframe called AveragePricePer100"}}