{"cell_type":{"8f6c18ef":"code","351fc447":"code","9a4a689e":"code","476057c2":"code","49a6966e":"code","088e171d":"code","2dbbd438":"code","c6f16bd7":"code","611909a9":"code","7a2e503c":"code","e24f027f":"code","e4f1d7e2":"code","a95d983a":"code","2ef29f75":"code","593aa96e":"code","787c8fc7":"code","6601201e":"code","fcb2d9ca":"markdown","5b7d5856":"markdown","4a278361":"markdown","4b2e0fa8":"markdown","2a3165b4":"markdown","e71e32b6":"markdown","bf017b2a":"markdown","5f006dab":"markdown","f542e80c":"markdown","6636af7d":"markdown","ce17e881":"markdown","2f7ab9de":"markdown","9f918cba":"markdown","0aee8ea9":"markdown","1c5bbfa1":"markdown"},"source":{"8f6c18ef":"import random\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n# from load_data import *\n# from utils import *\n# from stgcn import *","351fc447":"# load_data\n\nimport torch\nimport numpy as np\nimport pandas as pd\n\n\ndef load_matrix(file_path):\n    return pd.read_csv(file_path, header=None).values.astype(float)\n\n\ndef load_data(file_path, len_train, len_val):\n    df = pd.read_csv(file_path, header=0).drop(['time'], axis=1).values.astype(float)\n    train = df[: len_train]\n    val = df[len_train: len_train + len_val]\n    test = df[len_train + len_val:]\n    return train, val, test\n\n\ndef data_transform(data, n_his, n_pred, day_slot, device):\n    n_day = len(data) \/\/ day_slot\n    n_route = data.shape[1]\n    n_slot = day_slot - n_his - n_pred + 1\n    x = np.zeros([n_day * n_slot, 1, n_his, n_route])\n    y = np.zeros([n_day * n_slot, n_route])\n    for i in range(n_day):\n        for j in range(n_slot):\n            t = i * n_slot + j\n            s = i * day_slot + j\n            e = s + n_his\n            x[t, :, :, :] = data[s:e].reshape(1, n_his, n_route)\n            y[t] = data[e + n_pred - 1]\n    return torch.Tensor(x).to(device), torch.Tensor(y).to(device)\n\n\n# stgcn\n\nimport math\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.nn.functional as F\n\nclass align(nn.Module):\n    def __init__(self, c_in, c_out):\n        super(align, self).__init__()\n        self.c_in = c_in\n        self.c_out = c_out\n        if c_in > c_out:\n            self.conv1x1 = nn.Conv2d(c_in, c_out, 1)\n\n    def forward(self, x):\n        if self.c_in > self.c_out:\n            return self.conv1x1(x)\n        if self.c_in < self.c_out:\n            return F.pad(x, [0, 0, 0, 0, 0, self.c_out - self.c_in, 0, 0])\n        return x\n\nclass temporal_conv_layer(nn.Module):\n    def __init__(self, kt, c_in, c_out, act=\"relu\"):\n        super(temporal_conv_layer, self).__init__()\n        self.kt = kt\n        self.act = act\n        self.c_out = c_out\n        self.align = align(c_in, c_out)\n        if self.act == \"GLU\":\n            self.conv = nn.Conv2d(c_in, c_out * 2, (kt, 1), 1)\n        else:\n            self.conv = nn.Conv2d(c_in, c_out, (kt, 1), 1)\n\n    def forward(self, x):\n        x_in = self.align(x)[:, :, self.kt - 1:, :]\n        if self.act == \"GLU\":\n            x_conv = self.conv(x)\n            return (x_conv[:, :self.c_out, :, :] + x_in) * torch.sigmoid(x_conv[:, self.c_out:, :, :])\n        if self.act == \"sigmoid\":\n            return torch.sigmoid(self.conv(x) + x_in)\n        return torch.relu(self.conv(x) + x_in)\n\nclass spatio_conv_layer(nn.Module):\n    def __init__(self, ks, c, Lk):\n        super(spatio_conv_layer, self).__init__()\n        self.Lk = Lk\n        self.theta = nn.Parameter(torch.FloatTensor(c, c, ks))\n        self.b = nn.Parameter(torch.FloatTensor(1, c, 1, 1))\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        init.kaiming_uniform_(self.theta, a=math.sqrt(5))\n        fan_in, _ = init._calculate_fan_in_and_fan_out(self.theta)\n        bound = 1 \/ math.sqrt(fan_in)\n        init.uniform_(self.b, -bound, bound)\n\n    def forward(self, x):\n        x_c = torch.einsum(\"knm,bitm->bitkn\", self.Lk, x)\n        x_gc = torch.einsum(\"iok,bitkn->botn\", self.theta, x_c) + self.b\n        return torch.relu(x_gc + x)\n\nclass st_conv_block(nn.Module):\n    def __init__(self, ks, kt, n, c, p, Lk):\n        super(st_conv_block, self).__init__()\n        self.tconv1 = temporal_conv_layer(kt, c[0], c[1], \"GLU\")\n        self.sconv = spatio_conv_layer(ks, c[1], Lk)\n        self.tconv2 = temporal_conv_layer(kt, c[1], c[2])\n        self.ln = nn.LayerNorm([n, c[2]])\n        self.dropout = nn.Dropout(p)\n\n    def forward(self, x):\n        x_t1 = self.tconv1(x)\n        x_s = self.sconv(x_t1)\n        x_t2 = self.tconv2(x_s)\n        x_ln = self.ln(x_t2.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)        \n        return self.dropout(x_ln)\n\nclass fully_conv_layer(nn.Module):\n    def __init__(self, c):\n        super(fully_conv_layer, self).__init__()\n        self.conv = nn.Conv2d(c, 1, 1)\n\n    def forward(self, x):\n        return self.conv(x)\n\nclass output_layer(nn.Module):\n    def __init__(self, c, T, n):\n        super(output_layer, self).__init__()\n        self.tconv1 = temporal_conv_layer(T, c, c, \"GLU\")\n        self.ln = nn.LayerNorm([n, c])\n        self.tconv2 = temporal_conv_layer(1, c, c, \"sigmoid\")\n        self.fc = fully_conv_layer(c)\n\n    def forward(self, x):\n        x_t1 = self.tconv1(x)\n        x_ln = self.ln(x_t1.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n        x_t2 = self.tconv2(x_ln)\n        return self.fc(x_t2)\n\nclass STGCN(nn.Module):\n    def __init__(self, ks, kt, bs, T, n, Lk, p):\n        super(STGCN, self).__init__()\n        self.st_conv1 = st_conv_block(ks, kt, n, bs[0], p, Lk)\n        self.st_conv2 = st_conv_block(ks, kt, n, bs[1], p, Lk)\n        self.output = output_layer(bs[1][2], T - 4 * (kt - 1), n)\n\n    def forward(self, x):\n        x_st1 = self.st_conv1(x)\n        x_st2 = self.st_conv2(x_st1)\n        return self.output(x_st2)\n\n\n# utils\n\nimport torch\nimport numpy as np\n\n\ndef scaled_laplacian(A):\n    n = A.shape[0]\n    d = np.sum(A, axis=1)\n    L = np.diag(d) - A\n    for i in range(n):\n        for j in range(n):\n            if d[i] > 0 and d[j] > 0:\n                L[i, j] \/= np.sqrt(d[i] * d[j])\n    lam = np.linalg.eigvals(L).max().real\n    return 2 * L \/ lam - np.eye(n)\n\n\ndef cheb_poly(L, Ks):\n    n = L.shape[0]\n    LL = [np.eye(n), L[:]]\n    for i in range(2, Ks):\n        LL.append(np.matmul(2 * L, LL[-1]) - LL[-2])\n    return np.asarray(LL)\n\n\ndef evaluate_model(model, loss, data_iter):\n    model.eval()\n    l_sum, n = 0.0, 0\n    with torch.no_grad():\n        for x, y in data_iter:\n            y_pred = model(x).view(len(x), -1)\n            l = loss(y_pred, y)\n            l_sum += l.item() * y.shape[0]\n            n += y.shape[0]\n        return l_sum \/ n\n\n\ndef evaluate_metric(model, data_iter, scaler):\n    model.eval()\n    with torch.no_grad():\n        mae, mape, mse = [], [], []\n        for x, y in data_iter:\n            y = scaler.inverse_transform(y.cpu().numpy()).reshape(-1)\n            y_pred = scaler.inverse_transform(model(x).view(len(x), -1).cpu().numpy()).reshape(-1)\n            d = np.abs(y - y_pred)\n            mae += d.tolist()\n            mape += (d \/ y).tolist()\n            mse += (d ** 2).tolist()\n        MAE = np.array(mae).mean()\n        MAPE = np.array(mape).mean()\n        RMSE = np.sqrt(np.array(mse).mean())\n        return MAE, MAPE, RMSE\n","9a4a689e":"torch.manual_seed(2333)\ntorch.cuda.manual_seed(2333)\nnp.random.seed(2333)\nrandom.seed(2333)\ntorch.backends.cudnn.deterministic = True","476057c2":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")","49a6966e":"# matrix_path = \"..\/input\/stgcnpytorchmaster\/W_228.csv\"\n# data_path = \"..\/input\/stgcnpytorchmaster\/V_228.csv\"\n\nmatrix_path = \"..\/input\/stgcnsztti01010331\/W_SZRoads_12.csv\"\ndata_path = \"..\/input\/stgcnsztti01010331\/V_SZTTi_20190101-20190331.csv\"\n# data_path = \"..\/input\/stgcnsztti01010331\/V_SZSpeed_20190101-20190331.csv\"\n\nsave_path = \".model.pt\"","088e171d":"day_slot = 114\nn_train, n_val, n_test = 34, 5, 5","2dbbd438":"n_his = 12\nn_pred = 3\nn_route = 12\nKs, Kt = 3, 3\nblocks = [[1, 32, 64], [64, 32, 128]]\ndrop_prob = 0","c6f16bd7":"batch_size = 25\nepochs = 50\nlr = 1e-3","611909a9":"W = load_matrix(matrix_path)\nL = scaled_laplacian(W)\nLk = cheb_poly(L, Ks)\nLk = torch.Tensor(Lk.astype(np.float32)).to(device)","7a2e503c":"train, val, test = load_data(data_path, n_train * day_slot, n_val * day_slot)\nscaler = StandardScaler()\ntrain = scaler.fit_transform(train)\nval = scaler.transform(val)\ntest = scaler.transform(test)","e24f027f":"x_train, y_train = data_transform(train, n_his, n_pred, day_slot, device)\nx_val, y_val = data_transform(val, n_his, n_pred, day_slot, device)\nx_test, y_test = data_transform(test, n_his, n_pred, day_slot, device)","e4f1d7e2":"train_data = torch.utils.data.TensorDataset(x_train, y_train)\ntrain_iter = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True)\nval_data = torch.utils.data.TensorDataset(x_val, y_val)\nval_iter = torch.utils.data.DataLoader(val_data, batch_size)\ntest_data = torch.utils.data.TensorDataset(x_test, y_test)\ntest_iter = torch.utils.data.DataLoader(test_data, batch_size)","a95d983a":"loss = nn.MSELoss()\nmodel = STGCN(Ks, Kt, blocks, n_his, n_route, Lk, drop_prob).to(device)\noptimizer = torch.optim.RMSprop(model.parameters(), lr=lr)","2ef29f75":"scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.7)","593aa96e":"min_val_loss = np.inf\nfor epoch in range(1, epochs + 1):\n    l_sum, n = 0.0, 0\n    model.train()\n    for x, y in train_iter:\n        y_pred = model(x).view(len(x), -1)\n        l = loss(y_pred, y)\n        optimizer.zero_grad()\n        l.backward()\n        optimizer.step()\n        l_sum += l.item() * y.shape[0]\n        n += y.shape[0]\n    scheduler.step()\n    val_loss = evaluate_model(model, loss, val_iter)\n    if val_loss < min_val_loss:\n        min_val_loss = val_loss\n        torch.save(model.state_dict(), save_path)\n    print(\"epoch\", epoch, \", train loss:\", l_sum \/ n, \", validation loss:\", val_loss)","787c8fc7":"best_model = STGCN(Ks, Kt, blocks, n_his, n_route, Lk, drop_prob).to(device)\nbest_model.load_state_dict(torch.load(save_path))","6601201e":"l = evaluate_model(best_model, loss, test_iter)\nMAE, MAPE, RMSE = evaluate_metric(best_model, test_iter, scaler)\nprint(\"test loss:\", l, \"\\nMAE:\", MAE, \", MAPE:\", MAPE, \", RMSE:\", RMSE)","fcb2d9ca":"## File Path","5b7d5856":"## Packages","4a278361":"## Random Seed","4b2e0fa8":"## Loss & Model & Optimizer","2a3165b4":"## Standardization","e71e32b6":"## Graph","bf017b2a":"## Transform Data","5f006dab":"## Device","f542e80c":"## LR Scheduler","6636af7d":"## Load Best Model","ce17e881":"## Training & Save Model","2f7ab9de":"## Parameters","9f918cba":"## Evaluation","0aee8ea9":"# STGCN-PyTorch","1c5bbfa1":"## DataLoader"}}