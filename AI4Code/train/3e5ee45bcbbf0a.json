{"cell_type":{"dd7b153b":"code","c2eefa1d":"code","87492346":"code","8b02293f":"code","474632fc":"code","875b5ea9":"code","30096a7d":"code","c49047c6":"code","b82574b0":"code","6cd6bdaa":"code","056e9dfc":"code","0bef0a09":"code","4f782898":"code","116feaa2":"code","d6cf7805":"code","0c6cf918":"code","7c420466":"code","15c5a4d7":"code","f036e155":"code","0113196a":"code","20d77b59":"code","50ff9341":"code","12d600d2":"markdown","5b5ca983":"markdown","708b023e":"markdown","d4d10c96":"markdown","1072c1f1":"markdown","9273915f":"markdown","f5d47a57":"markdown","8243d138":"markdown","bf2982e7":"markdown","e256cf1a":"markdown","e9f11ef0":"markdown","83c223ff":"markdown","a0ad5e29":"markdown","46ce24e8":"markdown"},"source":{"dd7b153b":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c2eefa1d":"import pandas as pd\nimport numpy as np\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', 1000)\npd.set_option(\"display.colheader_justify\",\"left\")","87492346":"businesses = pd.read_csv(\"\/kaggle\/input\/yelp-dataset-csv-files\/restaurants.csv\", index_col=0)\nrestaurants = businesses[(businesses['categories'].str.contains('food',case=False)|\n                          businesses['categories'].str.contains('restaurant',case=False))\n                         &\n                         (businesses['categories'].str.contains('indian|thai|chinese|japanese|mex|french|italian|vegan|vietnamese|american',\n                                                                case=False))].copy()\n#only get relevant cuisine categories\n\nrestaurants.drop(['postal_code','attributes','hours','address'], axis=1, inplace=True) #non-relevant features\nrestaurants.head(5)","8b02293f":"# check for NA first:\nprint(\"is na:\")\nprint(restaurants.isna().sum())\n\nprint('\\n')\nprint(restaurants.describe())","474632fc":"import re \n\ncuisine_regex = '(chinese)|(thai)|(japanese)|(italian)|(french)|(american)|(vegan)|(indian)|(mex)|(vietnamese)'\nappended_cuisines = []\nfor i in restaurants['categories']:\n    temp = [\"\".join(x) for x in re.findall(cuisine_regex, i,flags=re.IGNORECASE)]\n    appended_cuisines.append(','.join(dict.fromkeys(temp)))  #get cuisine for each business, split them up with comma\nrestaurants['cuisine'] = appended_cuisines\nrestaurants.drop(restaurants[restaurants.cuisine.str.contains(',')].index, inplace=True) #drop any restaurants with a duplicate cuisine catgory\nrestaurants.cuisine.where(~(restaurants.cuisine=='Mex'), 'Mexican', inplace=True) #Fix Mexican Category (I consider tex-mex as mexican food)\n\n\nrestaurants = restaurants[restaurants.is_open==1] #filter for open restaurants, then drop open column\nrestaurants.drop(['categories', 'is_open'], axis=1,inplace=True)","875b5ea9":"restaurants.cuisine.value_counts()","30096a7d":"restaurants.state.value_counts()","c49047c6":"def review_text_processing(chunk):\n    chunk['dirty'] = chunk.text.str.contains('(dirty)|(un[- ]?clean)|(not[- ]?sanitary)|(not[- ]?clean)|(un[- ]?sanitary)|(filthy)',case=False)\n    chunk['clean'] = chunk.text.str.contains('(clean)|(sanitary)|(tidy)|(neat)|(spotless)|(pristine)',case=False)\n    chunk['loud'] = chunk.text.str.contains('(noisy)|(rowdy)|(loud)|(rambunctious)',case=False)\n    chunk['quiet'] = chunk.text.str.contains('(quiet)|(serene)|(peaceful)|(silent)',case=False)\n    chunk['expensive'] = chunk.text.str.contains('(pricey)|(expensive)|(overpriced)|(over-priced)|(exorbitant)',case=False)\n    chunk['cheap'] = chunk.text.str.contains('(cheap)|(affordable)|(inexpensive)|(economical)',case=False)\n    chunk.drop(['text'],axis=1,inplace=True)\n    return chunk\n","b82574b0":"chunksize = 100000\ndata_iterator = pd.read_csv('\/kaggle\/input\/yelp-dataset-csv-files\/restaurants_reviews.csv', usecols=['business_id', 'review_id','stars','text'],\n                            index_col='business_id', chunksize=chunksize)\n\nchunk_list = []  \n\n# Each chunk is in dataframe format\nfor data_chunk in data_iterator:  \n    filtered_chunk = review_text_processing(data_chunk)\n    chunk_list.append(filtered_chunk)\n    \nreviews_sample = pd.concat(chunk_list)\nreviews = reviews_sample[reviews_sample.index.isin(restaurants.index)].copy()\ndel reviews_sample\nreviews.head()","6cd6bdaa":"print(\"is na:\")\nprint(reviews.isna().sum())\n\nprint('\\n')\nprint(reviews.describe())","056e9dfc":"reviews.dropna(inplace=True)\nlen(reviews) ","0bef0a09":"data = restaurants.merge(reviews, left_index=True, right_index=True)\ndata.drop(['stars_x'], axis=1,inplace=True)\ndata.columns = ['name', 'city', 'state', 'latitude', 'longitude', 'review_count',\n       'cuisine', 'review_id', 'stars', 'dirty', 'clean', 'loud', 'quiet',\n       'expensive', 'cheap']","4f782898":"data[['dirty', 'clean', 'loud', 'quiet','expensive', 'cheap']] = data[['dirty', 'clean', 'loud', 'quiet','expensive', 'cheap']].astype('int32')","116feaa2":"review_data = data.copy()\n\nreview_data","d6cf7805":"descriptors = ['dirty', 'clean', 'loud', 'quiet','expensive', 'cheap']\ndata[descriptors] = data[descriptors].astype('int32')\nrestaurant_data = data[~data.index.duplicated(keep='first')].drop(['review_id','stars'],axis=1) \nrestaurant_data[['stars']+descriptors] = data.groupby(by=data.index).mean()[['stars']+descriptors]\nrestaurant_data = restaurant_data[['name', 'city', 'state', 'latitude', 'longitude', 'review_count','stars',\n       'cuisine', 'dirty', 'clean', 'loud', 'quiet', 'expensive', 'cheap']]\nrestaurant_data","0c6cf918":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\n\nnum_attributes = restaurant_data.select_dtypes(exclude='object').drop(['latitude','longitude'],axis=1).copy()\n\nfig = plt.figure(figsize=(15,24))\nfor i in range(len(num_attributes.columns)):\n    fig.add_subplot(9,4,i+1)\n    sns.distplot(num_attributes.iloc[:,i])\n    plt.xlabel(num_attributes.columns[i])\n\nplt.tight_layout()\nplt.show()","7c420466":"fig = plt.figure(figsize=(12,6))\nsns.distplot(restaurant_data.stars)\nplt.xlabel(restaurant_data.stars.name)\nplt.title('Rating distribution of Yelp Restaurants')\n\nplt.tight_layout()\nplt.show()\nprint(\"Mean = {}\".format(restaurant_data.stars.mean()))\nprint(\"Median = {}\".format(restaurant_data.stars.median()))\nprint(\"Std = {}\".format(restaurant_data.stars.std()))\nprint(\"Kurtosis = {}\".format(restaurant_data.stars.kurtosis()))\nprint(\"Skewness = {}\".format(restaurant_data.stars.skew()))","15c5a4d7":"rows_to_drop=restaurant_data[restaurant_data.review_count>restaurant_data.review_count.std()*3+restaurant_data.review_count.mean()].sort_values(by='review_count',ascending=False)\n\nprint('Rows to drop:')\nprint('')\n\nprint('Rows Dropped: {}'.format(len(rows_to_drop)))\n\n#drop outliers from both review_data and restaurant data and add minimum review count filter\nreview_data.drop(rows_to_drop.index,axis=0,inplace=True)\nrestaurant_data.drop(rows_to_drop.index,axis=0,inplace=True)\nreview_data = review_data[review_data.review_count>25]\nrestaurant_data = restaurant_data[restaurant_data.review_count>25]\n\nprint('New Max = {}, New Min = {}'.format(restaurant_data.review_count.max(),restaurant_data.review_count.min()))","f036e155":"fig = plt.figure(figsize=(12,6))\nsns.distplot(restaurant_data.review_count)\nplt.xlabel(restaurant_data.review_count.name)\nplt.title('Review Count distribution of Yelp Restaurants')\n\nplt.tight_layout()\nplt.show()\nprint(\"Mean = {}\".format(restaurant_data.review_count.mean()))\nprint(\"Median = {}\".format(restaurant_data.review_count.median()))\nprint(\"Std = {}\".format(restaurant_data.review_count.std()))\nprint(\"Kurtosis = {}\".format(restaurant_data.review_count.kurtosis()))\nprint(\"Skewness = {}\".format(restaurant_data.review_count.skew()))\n\n#filter out restaurants with less than 25 reviews","0113196a":"cuisine_correlation_array = []\nfor val in review_data.cuisine.unique():\n    temp = review_data[review_data.cuisine==val][['stars', 'dirty', 'clean', 'loud', 'quiet', 'expensive', 'cheap']].corr().stars.drop('stars')\n    temp_df=temp.to_frame().reset_index()\n    temp_df['cuisine'] = val\n    cuisine_correlation_array.append(temp_df)\n    \nstripplot_data_review = pd.concat(cuisine_correlation_array,axis=0)\n\ncuisine_correlation_array = []\nfor val in restaurant_data.cuisine.unique():\n    temp = restaurant_data[restaurant_data.cuisine==val][['stars', 'dirty', 'clean', 'loud', 'quiet', 'expensive', 'cheap']].corr().stars.drop('stars')\n    temp_df=temp.to_frame().reset_index()\n    temp_df['cuisine'] = val\n    cuisine_correlation_array.append(temp_df)\n    \nstripplot_data_rest = pd.concat(cuisine_correlation_array,axis=0)","20d77b59":"import plotly.express as px\nimport plotly.io as pio\n\nstripfig_rev = px.strip(data_frame = stripplot_data_review,\n        x = 'index',\n        y = 'stars',\n        hover_data=['cuisine'],\n        color = 'cuisine',\n        labels = {'index': 'review descriptor', 'stars':'R-value of correlation'},\n        title= 'Correlation between review descriptor and review rating',\n        stripmode = 'group',\n        height = 550,\n        width = 1000)\n\nstripfig_rev.update_traces(marker=dict(size=10))\nstripfig_rev.update_layout(title_x=0.47, title_y=.87)\n\npio.show(stripfig_rev)","50ff9341":"stripfig_rest = px.strip(data_frame = stripplot_data_rest,\n        x = 'index',\n        y = 'stars',\n        color = 'cuisine',\n        labels = {'index': 'review descriptor', 'stars':'R-value of correlation'},\n        title= 'Correlation between % of reviews matching descriptor and restaurant rating',\n        height = 550,\n        width = 1000,\n        stripmode = 'group')\n\nstripfig_rest.update_traces(marker=dict(size=10))\nstripfig_rest.update_layout(title_x=0.47, title_y=.87)\n\n\n\npio.show(stripfig_rest)","12d600d2":"I have started by converting the .JSON file to a csv. Also, because these files are so large, I needed my computer's RAM to load them all, as opposed to a Kaggle notebook","5b5ca983":"Once again, converted the reviews file from json to csv separately. Have also filtered for only restaurants. \n","708b023e":"### footnotes\n* I wanted the functionality of plotly over matplotlib but could not figure out how to reduce the jitter of the points in the stripplots. If anyone knows how, please let me know! \n* For the text matching for each descriptor, I used a few synonyms that I felt consumers would actually use. If anyone knows a better way to measure this category, I would appreciate the info.\n* NOTE: the review\/rest graphs do not have the same axes range. The reviews have much less significant correlations in comparison. \n* All feedback is appreciated, this is my first data project :) ","d4d10c96":"A quick overview of the restaurant data. Let's take a closer look at the review_count and stars fields","1072c1f1":"About 1\/3rd of all restaurants are closed, we will drop those. \n\nParse restaurant category for cuisine; drop any restaurants with duplicate cuisines (i.e. fusion restaurants):","9273915f":"## Correlation Analysis\n\nWant to analyze the relationship between each descriptor and the star rating of the rating\/restaurant. ","f5d47a57":"Not surprisingly, the majority of the restaurants are american. Another thing to consider is the majority of these restaurants are in a set of states throughout Canada and the US:","8243d138":"Will classify each review based on whether they match any of the descriptor categories","bf2982e7":"Let's remove outliers for review_count by removing values greater than three times the standard deviation. Then, add a minimum review filter (to reduce survival bias).","e256cf1a":"# Review processing:\n\nBecause the reviews file is so large (3.69 GB), we're going to extract only the substrings of each review characteristic we are interested in. As it relates to yelp reviews, I'm interested in seeing how reviews with the prescence of certain key words correlate to the rating of the review\/restaurant and breakdown that analysis by the cuisine category of the restaurant. \n\nThe descriptors I am interested in are:\n* Dirty\n* Clean\n* Loud \n* Quiet \n* Expensive\n* Cheap\n\nI want to then correlate the prescence of these descriptors to the rating of the restaurant and the rating of the reviews, separately, and compare the two. \n\nThis analysis will then tell us (for example):\n\n* What attributes of a restaurant are Yelpers more critical of depending on the cuisine? What attribute are they least critical of? For example, are reviewers more forgiving of American Restaurants that they perceive as dirty as opposed to Japanese restaurants they perceive as dirty? \n* What the main attribute to focus on for each cuisine is. For example, for a French restaurant, which characteristic has the most negative impact on the rating vs which characteristic has the most positive impact? \n* Compare each characteristic\/cuisine in the context of a restaurant vs a review. \n\nBelow function will process each review to check for substrings that relate to each descriptor. This method is not perfect but any inconsistencies should even out given how much data we have","e9f11ef0":"# Introduction \n\nI worked with the [Yelp Academic Data Set](https:\/\/www.yelp.com\/dataset) for a visualization project through coursera and had some unanswered questions. \n\n<ins>Curiosity Statement: <\/ins> How do Yelpers perceive certain characteristics across different cuisines? What are the most important characteristics for a restaurant with limited resources to focus on in the Yelp era of patronage?","83c223ff":"Want to group reviews by each unique restaurant and take average","a0ad5e29":"# Visualization\/Analysis","46ce24e8":"## General Conclusions\n\n* It is interesting to see the relationships for each descriptor: \n    * Hygiene - (Dirty\/Clean) is perceived as objectively good. The clean category has a much strong positive correlation than the dirty category.      \n    * Noise-level - (Loud\/Quiet) is not as disparate but consumers still appreciate a low noise-level. \n    * Price - (Expensive\/Cheap) has a very large spread among the cuisines but cheap food is generally favored.\n* Yelpers seem to be generally less critical of the pricing of mexican food--they have the highest correlation value in the cheap AND expensive categories. In contrast, they have one of the most negative correlation values in the dirty category, indicating that consumers could be very critical of the cleanliness of mexican restaurants. \n* Vegan restaurants exhibit nearly opposite behavior of that of mexican restaurants. Consumers seem to the be the least critical of dirty vegan restaurants and quite critical of both expensive and cheap vegan food.    \n* It is interesting to see that many cuisines exhibit similar behaviors for both their positive and negative categories (i.e. dirty\/clean). This could indicate the thought process of the consumer-base when they are leaving a review. For example, a consumer may leave a review where they were disappointed with the food at an american restaurant and also make a comment saying the bathrooms were unclean. Another consumer may have had a good experience at the same restaurant and say that the food was affordable. It is important to see the characeristics that consumers will applaud when satisfied with their experience and the characteristics they will criticize when disappointed."}}