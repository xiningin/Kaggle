{"cell_type":{"43cdaa9f":"code","a6ef053b":"code","6e4720ca":"code","911432aa":"code","719b6f9b":"code","61174ab4":"code","98ec9e2d":"code","1a04a430":"code","108c20b4":"code","97d59395":"code","8c511f33":"code","5a53d2bc":"code","9f07f1f6":"code","4e8eb2be":"code","e9cd1c38":"code","00c3b682":"code","d73a4db3":"code","552738f4":"code","a204432d":"code","940f3fa0":"code","ef772aeb":"code","585181b4":"code","fcb9f96f":"code","ed78394a":"markdown","7493d0fb":"markdown","9f450e9c":"markdown","66361c9c":"markdown","889705be":"markdown","83e0860d":"markdown","51c206f8":"markdown","16083b14":"markdown","f0a84a21":"markdown","981a6a17":"markdown","e45eb2ef":"markdown","9aacbed7":"markdown","28a701e0":"markdown","b91a1303":"markdown","cdd26071":"markdown","b1b5fce1":"markdown"},"source":{"43cdaa9f":"##Importing the packages\n#Data processing packages\nimport numpy as np \nimport pandas as pd \n\n#Visualization packages\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\n#Machine Learning packages\nfrom sklearn.svm import SVC,NuSVC\nfrom xgboost import XGBClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB,MultinomialNB\nfrom sklearn.linear_model import SGDClassifier, LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\t\nfrom sklearn.metrics import confusion_matrix\n\n#Suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')","a6ef053b":"#\"read_csv\" function from pandas is used to read the contents of csv file into dataframe (cc)\ndata = pd.read_csv('..\/input\/creditcard.csv')\ndata.head()","6e4720ca":"data.info()","911432aa":"#\"describe\" function displays common statistics like count, mean, max for each numeric fields\ndata.describe()","719b6f9b":"#Separating Feature and Target matrices\nX = data.drop(['Class'], axis=1)\ny=data['Class']","61174ab4":"#Feature scaling is a method used to standardize the range of independent variables or features of data.\n#Since the range of values of raw data varies widely, in some machine learning algorithms, objective functions will not work properly without normalization. \nfrom sklearn.preprocessing import StandardScaler\nscale = StandardScaler()\nX = scale.fit_transform(X)","98ec9e2d":"# Split the data into Training set and Testing set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size =0.2,random_state=42)","1a04a430":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=0, ratio = 1.0)\nX_train,y_train = sm.fit_sample(X_train,y_train)","108c20b4":"#Function to Train and Test Machine Learning Model\ndef train_test_ml_model(X_train,y_train,X_test,Model):\n    model.fit(X_train,y_train) #Train the Model\n    y_pred = model.predict(X_test) #Use the Model for prediction\n\n    # Test the Model\n    from sklearn.metrics import confusion_matrix\n    cm = confusion_matrix(y_test,y_pred)\n    accuracy = round(100*np.trace(cm)\/np.sum(cm),1)\n\n    #Plot\/Display the results\n    cm_plot(cm,Model)\n    print('Accuracy of the Model' ,Model, str(accuracy)+'%')","97d59395":"#Function to plot Confusion Matrix\ndef cm_plot(cm,Model):\n    plt.clf()\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n    classNames = ['Negative','Positive']\n    plt.title('Comparison of Prediction Result for '+ Model)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    tick_marks = np.arange(len(classNames))\n    plt.xticks(tick_marks, classNames, rotation=45)\n    plt.yticks(tick_marks, classNames)\n    s = [['TN','FP'], ['FN', 'TP']]\n    for i in range(2):\n        for j in range(2):\n            plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n    plt.show()\n    print(cm[1][0])","8c511f33":"from sklearn.svm import SVC,NuSVC  #Import packages related to Model\nModel = \"SVC\"\nmodel=SVC() #Create the Model\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","5a53d2bc":"#from sklearn.svm import SVC,NuSVC  #Import packages related to Model\n#Model = \"NuSVC\"\n#model=NuSVC()#Create the Model\n\n#train_test_ml_model(X_train,y_train,X_test,Model)","9f07f1f6":"from xgboost import XGBClassifier  #Import packages related to Model\nModel = \"XGBClassifier()\"\nmodel=XGBClassifier() #Create the Model\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","4e8eb2be":"from sklearn.naive_bayes import GaussianNB,MultinomialNB  #Import packages related to Model\nModel = \"GaussianNB\"\nmodel=GaussianNB()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","e9cd1c38":"from sklearn.linear_model import SGDClassifier, LogisticRegression #Import packages related to Model\nModel = \"SGDClassifier\"\nmodel=SGDClassifier()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","00c3b682":"from sklearn.linear_model import SGDClassifier, LogisticRegression #Import packages related to Model\nModel = \"LogisticRegression\"\nmodel=LogisticRegression()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","d73a4db3":"from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier #Import packages related to Model\nModel = \"DecisionTreeClassifier\"\nmodel=DecisionTreeClassifier()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","552738f4":"from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier #Import packages related to Model\nModel = \"ExtraTreeClassifier\"\nmodel=ExtraTreeClassifier()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","a204432d":"from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis #Import packages related to Model\nModel = \"QuadraticDiscriminantAnalysis\"\nmodel = QuadraticDiscriminantAnalysis()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","940f3fa0":"from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis #Import packages related to Model\nModel = \"LinearDiscriminantAnalysis\"\nmodel=LinearDiscriminantAnalysis()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","ef772aeb":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier #Import packages related to Model\nModel = \"RandomForestClassifier\"\nmodel=RandomForestClassifier()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","585181b4":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier #Import packages related to Model\nModel = \"AdaBoostClassifier\"\nmodel=AdaBoostClassifier()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","fcb9f96f":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier #Import packages related to Model\nModel = \"GradientBoostingClassifier\"\nmodel=GradientBoostingClassifier()\n\ntrain_test_ml_model(X_train,y_train,X_test,Model)","ed78394a":"### **Scaling the data values to standardize the range of independent variables**","7493d0fb":"**COMMENT:** Since all the fields have numerical datatype we don't need type conversion.","9f450e9c":"### **Import packages**","66361c9c":"### **Import data**","889705be":"**COMMENT:** Since all the fields have nuermical datatype we don't need to convert from categorical to numerical datatype.","83e0860d":"### **PERFORM PREDICTIONS USING MACHINE LEARNING ALGORITHMS**","51c206f8":"**COMMENT:** From the output of **describe** function it looks like all the fields have value, so we will not remove any field.","16083b14":"### **Check and remove if there are any fields which does not add value**","f0a84a21":"### **Perform datatype conversion or translation wherever required**","981a6a17":"### **Convert Categorical values to Numeric Values**","e45eb2ef":"**COMMENT:** Above output shows that there are No Null values.","9aacbed7":"### **Separating the Feature and Target Matrices**","28a701e0":"**Since the data is highly class imbalanced, we will have to oversample the data. Here SMOTE technique has been used to oversample the data as it proves to be the most effective one.**","b91a1303":"### **Check and remediate if there are any null values**","cdd26071":"### **Split the data into Training set and Testing set**","b1b5fce1":"### **Function definition**"}}