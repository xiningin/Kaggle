{"cell_type":{"a4bba59c":"code","219974b5":"code","c47a55c2":"code","5dbf2770":"code","bdb43131":"code","9c4126e6":"code","98179c88":"code","b59148ee":"code","f3893983":"code","3e6c804e":"code","6e5d56ed":"code","b3d0070f":"code","1b222f55":"code","d1580115":"code","12b67bb4":"code","c9a3b6e0":"code","4ec1cf54":"code","2e67dad0":"code","63621ed3":"code","20d5f988":"code","8f12b0f6":"code","f0f2314d":"code","a6937ecf":"code","cb3d14bd":"code","e0898233":"code","58b1e45e":"code","010bbcaf":"code","5db73949":"code","16e097b1":"code","745a77b7":"code","235df1e3":"markdown","2f1321fb":"markdown","0415cf74":"markdown","6127dea5":"markdown","6a8a6f78":"markdown","8e47b543":"markdown","535e1326":"markdown","fb1dafd4":"markdown","e1ceab18":"markdown","af5e3119":"markdown","53d0cc2f":"markdown","5f1a581e":"markdown"},"source":{"a4bba59c":"#%matplotlib notebook\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom collections import Counter\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\npd.set_option('precision', 3)\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\nimport xgboost as xgb\nfrom scipy.stats import skew\nfrom scipy.special import boxcox1p","219974b5":"houses_test = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\", header=0, delimiter=',')\nhouses_test.head()\nhouses_test.shape","c47a55c2":"houses_train = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\", header=0, delimiter=',')\nhouses_train.head()\nhouses_train.shape","5dbf2770":"houses_train.describe()","bdb43131":"null_columns = houses_train.columns[houses_train.isnull().any()]\nhouses_train[null_columns].isna().sum()","9c4126e6":"houses_train = houses_train.drop(columns = ['PoolQC', 'Fence', 'MiscFeature', 'Alley']) #We start deleting the features with more than half of null values\nhouses_test = houses_test.drop(columns = ['PoolQC', 'Fence', 'MiscFeature', 'Alley'])\nnull_columns.drop(['PoolQC', 'Fence', 'MiscFeature', 'Alley'])","98179c88":"# Collect the names of the Categorical and Numeric Variables seperately\nnum_columns = houses_train.select_dtypes(include=np.number).columns.tolist()\nnum_columns.remove(\"SalePrice\") # Capturing feature names exclusively\ncat_columns = houses_train.select_dtypes(exclude=np.number).columns.tolist()\n\n# Check if the number makes sense (+1 for the target variable that was dropped)\nlen(num_columns) + len(cat_columns) + 1 == len(houses_train.columns)","b59148ee":"for col in cat_columns:\n    print(col + \": \" + str(len(houses_train[col].unique()))) # we print categorical data columns and their distinct amount of categories","f3893983":"#We start visualizing a heat map for all numerical features\nplt.figure(figsize=(32,16))\nsn.heatmap(houses_train.corr(),cmap='magma_r',annot=True) #Big correlation between YearBuilt and GarageYrBuilt -> delete GarageYrBuilt (difficult to impute null values)\nhouses_test = houses_test.drop(columns = 'GarageYrBlt', axis = 1)\nhouses_train = houses_train.drop(columns = 'GarageYrBlt', axis = 1)\n","3e6c804e":"fig,ax = plt.subplots(3,1,figsize=(15,15))\nsn.lineplot(x=houses_train['OverallQual'],y=houses_train.SalePrice,ax=ax[0],color='r') #We visualize 3 features with different levels of correlation with SalePrice\nsn.lineplot(x=houses_train['YearBuilt'],y=houses_train.SalePrice,ax=ax[1],color='b')\nsn.lineplot(x=houses_train['MSSubClass'],y=houses_train.SalePrice,ax=ax[2],color='g')","6e5d56ed":"null_columns = houses_train.columns[houses_train.isnull().any()]\nnull_columns_2 = houses_test.columns[houses_test.isnull().any()]\nhouses_train[null_columns].isna().sum() #We still have null values in some numerical  and categorical features that we need to input\nhouses_test[null_columns_2].isna().sum()","b3d0070f":"def fill_nulls_None(houses_df):\n    houses_df.loc[houses_df.FireplaceQu.isna(),'FireplaceQu'] = 'None'\n    houses_df.loc[houses_df.GarageType.isna(),'GarageType'] = 'None' #No garage >>\n    houses_df.loc[houses_df.GarageFinish.isna(),'GarageFinish'] = 'None' #>>\n    houses_df.loc[houses_df.GarageQual.isna(),'GarageQual'] = 'None' #>>\n    houses_df.loc[houses_df.GarageCond.isna(),'GarageCond'] = 'None' #>>\n    houses_df.loc[houses_df.BsmtExposure.isna(),'BsmtExposure'] = 'None' #No basement >>\n    houses_df.loc[houses_df.BsmtFinType2.isna(),'BsmtFinType2'] = 'None' #>>\n    houses_df.loc[houses_df.BsmtCond.isna(),'BsmtCond'] = 'None' #>>\n    houses_df.loc[houses_df.BsmtFinType1.isna(),'BsmtFinType1'] = 'None' #>>\n    houses_df.loc[houses_df.BsmtQual.isna(),'BsmtQual'] = 'None' #>>\n    houses_df.loc[houses_df.MasVnrType.isna(),'MasVnrType'] = 'None' #No masonry >>\n    houses_df.loc[houses_df.MasVnrArea.isna(),'MasVnrArea'] = 0 #>>\n    houses_df = houses_df.loc[~houses_df.Electrical.isna()] #Dropping ONE row with Nan value in 'Electrical'\n    houses_df.loc[houses_df.MSZoning.isna(),'MSZoning'] = 'None'\n    houses_df.loc[houses_df.Utilities.isna(),'Utilities'] = 'None'\n    houses_df.loc[houses_df.Exterior1st.isna(),'Exterior1st'] = 'None'\n    houses_df.loc[houses_df.Exterior2nd.isna(),'Exterior2nd'] = 'None'\n    houses_df.loc[houses_df.BsmtFinSF1.isna(),'BsmtFinSF1'] = 0\n    houses_df.loc[houses_df.BsmtFinSF2.isna(),'BsmtFinSF2'] = 0\n    houses_df.loc[houses_df.BsmtUnfSF.isna(),'BsmtUnfSF'] = 0\n    houses_df.loc[houses_df.TotalBsmtSF.isna(),'TotalBsmtSF'] = 0\n    houses_df.loc[houses_df.BsmtFullBath.isna(),'BsmtFullBath'] = 0\n    houses_df.loc[houses_df.BsmtHalfBath.isna(),'BsmtHalfBath'] = 0\n    houses_df.loc[houses_df.KitchenQual.isna(),'KitchenQual'] = 'None'\n    houses_df.loc[houses_df.Functional.isna(),'Functional'] = 'None'\n    houses_df.loc[houses_df.GarageCars.isna(),'GarageCars'] = 0\n    houses_df.loc[houses_df.GarageArea.isna(),'GarageArea'] = 0\n    houses_df.loc[houses_df.SaleType.isna(),'SaleType'] = 'None'\n    return houses_df\n\nhouses_train = fill_nulls_None(houses_train)\nhouses_test = fill_nulls_None(houses_test)\nhouses_train['LotFrontage'].fillna(houses_train['LotFrontage'].mean(), inplace = True)\nhouses_test['LotFrontage'].fillna(houses_test['LotFrontage'].mean(), inplace = True)\n#We fill LotFrontage differently because it's the only numerical feature with a lot of missing values, so putting all 0s could cause trouble","1b222f55":"null_columns = houses_train.columns[houses_train.isnull().any()]\nhouses_train[null_columns].isna().sum() #No null values left","d1580115":"sn.distplot(houses_train[\"SalePrice\"] , color = \"r\", hist_kws={\"alpha\": 0.4}); #Not a normal distribution, skewed to the left of the figure","12b67bb4":"sn.distplot(np.log1p(houses_train[\"SalePrice\"]) , color = \"b\", hist_kws={\"alpha\": 0.4}); #Now it is a normal distribution","c9a3b6e0":"houses_train[\"SalePrice\"] = np.log1p(houses_train[\"SalePrice\"]) #We apply the log transformation seen above","4ec1cf54":"num_columns = houses_test.select_dtypes(include=np.number).columns.tolist() #We take the numerical columns from the test to avoid taking SalePrice\nnumvars_skewed = []\nfor i in num_columns:\n    if abs(houses_train[i].skew()) > 0.75:\n        numvars_skewed.append(i)\n        \nprint(numvars_skewed)\nhouses_train[numvars_skewed] = np.log1p(houses_train[numvars_skewed]) #We apply the log transformation to all the skewed features\nhouses_test[numvars_skewed] = np.log1p(houses_test[numvars_skewed])","2e67dad0":"houses_train['FireplaceQu'].value_counts() #There's a lot of categorical data with this punctuation method","63621ed3":"#We substitute all categorical that follow that common punctuation method with integers, because in this case, the categories do follow an order.\ndef new_punctuation(houses_df):\n    houses_df['ExterQual'] = houses_df['ExterQual'].map({'Ex':5,'Fa':2,'Gd':4,'TA':3,'Po':1,'None':0}).astype('int64')\n    houses_df['ExterCond'] = houses_df['ExterCond'].map({'Ex':5,'Fa':2,'Gd':4,'TA':3,'Po':1,'None':0}).astype('int64')\n    houses_df['BsmtQual'] = houses_df['BsmtQual'].map({'Ex':5,'Gd':4,'TA':3,'Fa':2,'Po':1,'None':0}).astype('int64')\n    houses_df['BsmtCond'] = houses_df['BsmtCond'].map({'Ex':5,'Fa':2,'Gd':4,'TA':3,'Po':1,'None':0}).astype('int64')\n    houses_df['BsmtExposure'] = houses_df['BsmtExposure'].map({'Av':3,'Gd':4,'Mn':2,'No':1,'None':0}).astype('int64')\n    houses_df['BsmtFinType1'] = houses_df['BsmtFinType1'].map({'ALQ':5, 'BLQ':4, 'GLQ':6, 'LwQ':2, 'None':0, 'Rec':3, 'Unf':1}).astype('int64')\n    houses_df['BsmtFinType2'] = houses_df['BsmtFinType2'].map({'ALQ':5, 'BLQ':4, 'GLQ':6, 'LwQ':2, 'None':0, 'Rec':3, 'Unf':1}).astype('int64')\n    houses_df['HeatingQC'] = houses_df['HeatingQC'].map({'Ex':5, 'Fa':2, 'Gd':4, 'Po':1, 'TA':3,'None':0}).astype('int64')\n    houses_df['KitchenQual'] = houses_df['KitchenQual'].map({'Ex':5,'Fa':2,'Gd':4,'TA':3,'Po':1,'None':0}).astype('int64')\n    houses_df['FireplaceQu'] = houses_df['FireplaceQu'].map({'Ex':5, 'Fa':2, 'Gd':4, 'None':0, 'Po':1, 'TA':3}).astype('int64')\n    houses_df['GarageCond'] = houses_df['GarageCond'].map({'Ex':5, 'Fa':2, 'Gd':4, 'None':0, 'Po':1, 'TA':3}).astype('int64')\n    houses_df['GarageQual'] = houses_df['GarageQual'].map({'Ex':5, 'Fa':2, 'Gd':4, 'None':0, 'Po':1, 'TA':3}).astype('int64')\n    return houses_df\n\nhouses_train = new_punctuation(houses_train)\nhouses_test = new_punctuation(houses_test)","20d5f988":"houses_train.dtypes #There are still a few categorical features that need to be turned into numerical before we start applying a model","8f12b0f6":"cat_columns = houses_train.select_dtypes(exclude=np.number).columns.tolist() \ncat_columns_2 = houses_test.select_dtypes(exclude=np.number).columns.tolist()\nprint(houses_train['SaleType'].value_counts())\nprint(cat_columns)\nprint(cat_columns == cat_columns_2) #Train and test dataframes have the same categorical columns","f0f2314d":"#We divide the categorical columns in terms of if they are elegible for OH enconding or not\ncat_cols_OH = ['Street', 'LotShape', 'LandContour', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'BldgType', 'RoofStyle', 'MasVnrType', 'Foundation', 'CentralAir', 'GarageType', 'GarageFinish', 'PavedDrive', 'SaleCondition']","a6937ecf":"# Get one hot encoding\nfor col in cat_cols_OH:\n    OHhtr = pd.get_dummies(houses_train[col], prefix = col + '_')\n    OHhte = pd.get_dummies(houses_test[col], prefix = col + '_')\n    houses_train = houses_train.drop(col, axis = 1)\n    houses_test = houses_test.drop(col, axis = 1)\n    houses_train = houses_train.join(OHhtr)\n    houses_test = houses_test.join(OHhte)","cb3d14bd":"#The rest are encoded using Ordinal Encoding\ncat_columns = houses_train.select_dtypes(exclude=np.number).columns.tolist() \nprint(cat_columns)\nenc = preprocessing.OrdinalEncoder(dtype = int)\nhouses_train[cat_columns] = enc.fit_transform(houses_train[cat_columns])\nhouses_test[cat_columns] = enc.fit_transform(houses_test[cat_columns])\n\nprint(houses_train.select_dtypes(exclude=np.number).columns.tolist())","e0898233":"def feature_eng(df):\n    df['Bathrooms'] = df['BsmtFullBath'] + df['BsmtHalfBath']*0.5 + df['FullBath'] + df['HalfBath']*0.5\n    df['Rooms'] = df['TotalBsmtSF'].apply(lambda x: 1 if x==0 else 0) + df['Bathrooms'] + df['TotRmsAbvGrd']\n    df['TotalUsedSF'] = df['MasVnrArea'] + df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF'] + df['GarageArea'] + df['EnclosedPorch'] + df['OpenPorchSF'] + df['WoodDeckSF'] + df['PoolArea'] + df['EnclosedPorch'] + df['3SsnPorch'] + df['ScreenPorch']\n    df['YearsSinceRemodeled'] = 2021 - df['YearRemodAdd']\n    return df\n\nhouses_train = feature_eng(houses_train)\nhouses_test = feature_eng(houses_test)","58b1e45e":"X = houses_train.drop(\"SalePrice\", axis=1)\nY = houses_train[\"SalePrice\"]\nx_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.2,random_state=0)","010bbcaf":"xgb_model = xgb.XGBRegressor(n_estimators = 500, random_state = 7, learning_rate = 0.05, max_depth = 6, min_child_weight = 1.5)\ncvxgb = cross_val_score(xgb_model, x_train, y_train, cv = 5)\nprint(cvxgb)\nprint(cvxgb.mean())","5db73949":"\"\"\"def rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n\nxgb_model = xgb.XGBRegressor(n_estimators = 5000, random_state = 2, learning_rate = 0.05, max_depth = 3, min_child_weight = 2)\nxgb_model.fit(x_train, y_train)\nxgb_train_pred = xgb_model.predict(x_train)\nxgb_pred = np.expm1(xgb_model.predict(x_test))\"\"\"","16e097b1":"#rf = RandomForestRegressor(n_estimators = 400, random_state = 4)\n#cvrf = cross_val_score(rf, x_train, y_train, cv = 5)\n#print(cvrf)\n#print(cvrf.mean())","745a77b7":"#submit\nX_fin = houses_train.drop(\"SalePrice\", axis=1)\nY_fin = houses_train[\"SalePrice\"]\nxgb_model.fit(X_fin, Y_fin)\nY_pred = np.expm1(xgb_model.predict(houses_test))\nsubmission = pd.DataFrame({\n        \"Id\": houses_test[\"Id\"],\n        \"SalePrice\": Y_pred\n    })\nsubmission.to_csv('submission.csv', index=False)","235df1e3":"**We have now succesfully gotten rid of all missing values**","2f1321fb":"**Lets start using Feature Engineering**","0415cf74":"We will procede to use Ordinal encoding for these remaining categorical features, it's important to note that we can't use OH encoding because the features in the test and train dataframes wouldn't be the same (OH would create different features for each).","6127dea5":"**Lets procede to input the null values**","6a8a6f78":"**We start examining our data to fill missing values**","8e47b543":"**Lets finish the feature engineering adding a few new variables**","535e1326":"**We start loading the dataset and giving it a first glimpse**","fb1dafd4":"**Lets now normalise our numerical features so that the model makes more accurate predictions**","e1ceab18":"We have succesfully applied Ordinal encoding so given that only numerical features remain we can apply our model","af5e3119":"**Now, for the rest of data, we will first do an exploration of the data to, among other things, decide which is the best way to imput the missing values**","53d0cc2f":"**We start applying our model**","5f1a581e":"**We submit the code to the competition**"}}