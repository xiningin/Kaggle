{"cell_type":{"3c3f3f16":"code","3e8ecb5f":"markdown"},"source":{"3c3f3f16":"import numpy as np\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n\ndef Create_Dataset():\n\n    X, y = datasets.make_classification(n_samples=10000, n_features=4, random_state=42)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n    return X_train, X_test, y_train, y_test\n\n\ndef Binary_Logistic_Regression(X_train, X_test, y_train, y_test):\n\n    class Logistic_Regression:\n\n        def __init__(self, learning_rate=0.001, n_iteration=10000):\n\n            self.learning_rate = learning_rate\n            self.n_iteration = n_iteration\n            self.weight = None\n            self.bias = None\n\n        def fit(self, X, y):\n\n            self.weight = np.zeros(X.shape[1])\n            self.bias = 0\n\n            for i in range(self.n_iteration):\n\n                linear_equation = np.dot(X, self.weight) + self.bias\n                hypothesis = self.sigmoid_function(linear_equation)\n\n                #cost_function = (-y * np.log(hypothesis) - (1 - y) * np.log(1 - hypothesis)).mean()\n\n                derivative_weight = np.mean(X.T * (hypothesis - y), axis=1)\n                derivative_bias = np.mean(hypothesis - y)\n\n                self.weight -= self.learning_rate * derivative_weight\n                self.bias -= self.learning_rate * derivative_bias\n\n        def predict(self, X):\n\n            linear_equation = np.dot(X, self.weight) + self.bias\n            hypothesis = self.sigmoid_function(linear_equation)\n            result = [1 if i >= 0.5 else 0 for i in hypothesis]\n            return result\n\n        def sigmoid_function(self, s):\n\n            return 1 \/ (1 + (np.exp(-s)))\n\n        def accuracy_score(self, y, y_prediction):\n\n            return np.sum(y == y_prediction) \/ len(y)\n\n\n    lr = Logistic_Regression(0.01, 15000)\n    lr.fit(X_train, y_train)\n    y_prediction = lr.predict(X_test)\n    print(\"\\nAccuracy score of Python Implementation: {}\".format(lr.accuracy_score(y_test, y_prediction)))\n\n\ndef Logistic_Regression_with_Sklearn(X_train, X_test, y_train, y_test):\n\n    lr = LogisticRegression()\n    lr.fit(X_train, y_train)\n    y_prediction = lr.predict(X_test)\n    print(\"Accuracy score of Sklearn: {}\".format(accuracy_score(y_test, y_prediction)))\n\n\nif __name__ == \"__main__\":\n\n    X_train, X_test, y_train, y_test = Create_Dataset()\n    Binary_Logistic_Regression(X_train, X_test, y_train, y_test)\n    Logistic_Regression_with_Sklearn(X_train, X_test, y_train, y_test)","3e8ecb5f":"**LOGISTIC REGRESSION**\n\nThis is the implementation of binary logistic regression. When implementing the algorithm, I have created a dataset of size 10.000 with four features and separated them as train and test data. The accuracy scores of Sklearn and the Python implementation are the same."}}