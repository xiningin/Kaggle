{"cell_type":{"c8ef69d3":"code","f348b951":"code","37ae0faa":"code","42f66db7":"code","ccba1bb3":"code","76565a64":"code","0e848e7e":"markdown","7c5fb1e1":"markdown"},"source":{"c8ef69d3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom sklearn import model_selection\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f348b951":"def padding_seq(data):\n    \"\"\"Pad sequences to sequence with length 10.\"\"\"\n    data = np.array(data)\n    to_pad = 10 - data.shape[0]\n    return np.pad(data, ((0, to_pad), (0, 0)), 'mean')\n\ndef create_x(dataframe):\n    X = dataframe['audio_embedding']\n    X = [padding_seq(data) for data in X]\n    return np.stack(X)\n\ndef create_y(dataframe):\n    return training_data['is_turkey'].values","37ae0faa":"training_data = pd.read_json(\"..\/input\/train.json\")\nX, y = create_x(training_data), create_y(training_data)\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y)","42f66db7":"class GruModel(tf.keras.Model):\n    def __init__(self, gru_units=128):\n        super(GruModel, self).__init__()\n        self.gru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=gru_units, dropout=0.2))\n        self.dense1 = tf.keras.layers.Dense(64, activation='tanh')\n        self.dense2 = tf.keras.layers.Dense(1, activation='sigmoid')\n    \n    def call(self, x):\n        result = self.gru(x)\n        return self.dense2(self.dense1(result))\n\nmodel = GruModel()\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X_train, y_train, epochs=100, batch_size=200, validation_data=(X_test, y_test))   ","ccba1bb3":"model = GruModel()\nX, y = create_x(training_data), create_y(training_data)\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X, y, epochs=200, batch_size=200)","76565a64":"test_data = pd.read_json('..\/input\/test.json')\nX = create_x(test_data)\npred = model.predict(X)\nsubmit = test_data[['vid_id']].copy()\nsubmit['is_turkey'] = np.squeeze(pred, axis=-1)\nsubmit.to_csv('result.csv', index=False)","0e848e7e":"Functions for reading data","7c5fb1e1":"Looks good! Let's retrain it on full training data and submit :)"}}