{"cell_type":{"115cb6a1":"code","5a5c7da1":"code","c8f40d5e":"code","460afc8b":"code","b6eefef6":"code","725aba7c":"code","0a254d00":"code","a514629b":"code","515096ea":"code","5e704fd1":"code","8584b197":"code","d093a913":"code","40c00a89":"code","db6d8d9e":"code","0a41a885":"code","e20f59de":"code","ca0d3f56":"code","516a6292":"code","2c91d953":"code","485f9f10":"code","5041bdb6":"code","2a76f5b8":"code","b13c91cc":"code","513bd0ef":"code","613575b0":"code","0544325a":"code","734dd8fe":"code","574acb90":"code","5a77bb47":"code","bf2ea3df":"code","b96009f3":"code","bb149dae":"markdown","fe2f53b2":"markdown","fa42d03e":"markdown","e6a15ba3":"markdown","c2d062c8":"markdown","6ba2b462":"markdown","cc75a79d":"markdown","e812669d":"markdown"},"source":{"115cb6a1":"import os\nimport sys\nimport random\nimport warnings\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport cv2\n\nfrom tqdm import tqdm_notebook, tnrange\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Lambda, RepeatVector, Reshape\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras import backend as K\n\nimport tensorflow as tf\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img","5a5c7da1":"# Set some parameters\nim_width = 128\nim_height = 128\nborder = 5\nim_chan = 2 # Number of channels: first is original and second cumsum(axis=0)\nn_features = 1 # Number of extra features, like depth\npath_train = '..\/input\/train\/'\npath_test = '..\/input\/test\/'","c8f40d5e":"df_depths = pd.read_csv('..\/input\/depths.csv', index_col='id')\ndf_depths.hist()","460afc8b":"ids= ['1f1cc6b3a4','5b7c160d0d','6c40978ddf','7dfdf6eeb8','7e5a6e5013']\nplt.figure(figsize=(30,15))\nfor j, img_name in enumerate(ids):\n    q = j+1\n    img = load_img('..\/input\/train\/images\/' + img_name + '.png', grayscale=True)\n    img_mask = load_img('..\/input\/train\/masks\/' + img_name + '.png', grayscale=True)\n    \n    img = np.array(img)\n    img_cumsum = (np.float32(img)-img.mean()).cumsum(axis=0)\n    img_mask = np.array(img_mask)\n    \n    plt.subplot(1,3*(1+len(ids)),q*3-2)\n    plt.imshow(img, cmap='seismic')\n    plt.subplot(1,3*(1+len(ids)),q*3-1)\n    plt.imshow(img_cumsum, cmap='seismic')\n    plt.subplot(1,3*(1+len(ids)),q*3)\n    plt.imshow(img_mask)\nplt.show()","b6eefef6":"train_ids = next(os.walk(path_train+\"images\"))[2]\ntest_ids = next(os.walk(path_test+\"images\"))[2]","725aba7c":"# Get and resize train images and masks\nX = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.float32)\ny = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.float32)\nX_feat = np.zeros((len(train_ids), n_features), dtype=np.float32)\nprint('Getting and resizing train images and masks ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n    path = path_train\n    # Depth\n    X_feat[n] = df_depths.loc[id_.replace('.png', ''), 'z']\n    \n    # Load X\n    img = load_img(path + '\/images\/' + id_, grayscale=True)\n    x_img = img_to_array(img)\n    x_img = resize(x_img, (128, 128, 1), mode='constant', preserve_range=True)\n    \n    # Create cumsum x\n    x_center_mean = x_img[border:-border, border:-border].mean()\n    x_csum = (np.float32(x_img)-x_center_mean).cumsum(axis=0)\n    x_csum -= x_csum[border:-border, border:-border].mean()\n    x_csum \/= max(1e-3, x_csum[border:-border, border:-border].std())\n\n    # Load Y\n    mask = img_to_array(load_img(path + '\/masks\/' + id_, grayscale=True))\n    mask = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)\n\n    # Save images\n    X[n, ..., 0] = x_img.squeeze() \/ 255\n    X[n, ..., 1] = x_csum.squeeze()\n    y[n] = mask \/ 255\n\nprint('Done!')","0a254d00":"# Split train and valid\nX_train, X_valid, X_feat_train, X_feat_valid, y_train, y_valid = train_test_split(X, X_feat, y, test_size=0.25, random_state=42)","a514629b":"# Normalize features using training set\nx_feat_mean = X_feat_train.mean(axis=0, keepdims=True)\nx_feat_std = X_feat_train.std(axis=0, keepdims=True)\nX_feat_train -= x_feat_mean\nX_feat_train \/= x_feat_std\n\nX_feat_valid -= x_feat_mean\nX_feat_valid \/= x_feat_std","515096ea":"# Check if training data looks all right\nix = random.randint(0, len(X_train))\n\nhas_mask = y_train[ix].max() > 0\n\nfig, ax = plt.subplots(1, 3, figsize=(20, 10))\nax[0].imshow(X_train[ix, ..., 0], cmap='seismic', interpolation='bilinear')\nif has_mask:\n    ax[0].contour(y_train[ix].squeeze(), colors='k', levels=[0.5])\nax[0].set_title('Seismic')\n\nax[1].imshow(X_train[ix, ..., 1], cmap='seismic', interpolation='bilinear')\nif has_mask:\n    ax[1].contour(y_train[ix].squeeze(), colors='k', levels=[0.5])\nax[1].set_title('Seismic cumsum')\n\nax[2].imshow(y_train[ix].squeeze(), interpolation='bilinear', cmap='gray')\nax[2].set_title('Salt');","5e704fd1":"from keras.preprocessing.image import ImageDataGenerator\ndg_args = dict(featurewise_center = False, \n                  samplewise_center = False,\n                  rotation_range = 1, \n                  width_shift_range = 0.02, \n                  height_shift_range = 0.02, \n                  shear_range = 0.01,\n                  zoom_range = [0.9, 1.1],  \n                  horizontal_flip = False, \n                  vertical_flip = False,\n                  fill_mode = 'nearest',\n                   data_format = 'channels_last')\n\nimage_gen = ImageDataGenerator(**dg_args)\nlabel_gen = ImageDataGenerator(**dg_args)\ndef train_gen(batch_size = 16, seed = None):\n    # {'img': X_train, 'feat': X_feat_train}, y_train,\n    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n    while True:\n        seed = np.random.choice(range(9999))\n        # keep the seeds syncronized otherwise the augmentation to the images is different from the masks\n        batch_count = X_train.shape[0]\/\/batch_size\n        batch_id = np.random.permutation(range(0, X_train.shape[0]-batch_size, batch_size))\n        for c_idx in batch_id:\n            g_x = image_gen.flow(X_train[c_idx:(c_idx+batch_size)], batch_size = batch_size, seed = seed, shuffle=False)\n            g_y = label_gen.flow(y_train[c_idx:(c_idx+batch_size)], batch_size = batch_size, seed = seed, shuffle=False)\n            yield [next(g_x)\/255.0, X_feat_train[c_idx:(c_idx+batch_size)]], next(g_y)","8584b197":"from skimage.util.montage import montage2d as montage\ncur_gen = train_gen(8)\n[t_x, _], t_y = next(cur_gen)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\nax1.imshow(montage(t_x[:, :, :, 0]), cmap='seismic')\nax2.imshow(montage(t_y[:, :, :, 0]), cmap='gray_r')","d093a913":"# Build U-Net model\ninput_img = Input((im_height, im_width, im_chan), name='img')\ninput_features = Input((n_features, ), name='feat')\n\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (input_img)\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n# Join features information in the depthest layer\nf_repeat = RepeatVector(8*8)(input_features)\nf_conv = Reshape((8, 8, n_features))(f_repeat)\np4_feat = concatenate([p4, f_conv], -1)\n\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4_feat)\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n\nu6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\nu7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\nu8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\nu9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[input_img, input_features], outputs=[outputs])\nmodel.summary()","40c00a89":"import keras.backend as K\nfrom keras.optimizers import Adam\nfrom keras.losses import binary_crossentropy\n# Define IoU metric\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n    return K.mean( (2. * intersection + smooth) \/ (union + smooth), axis=0)\ndef dice_p_bce(in_gt, in_pred):\n    \"\"\"combine DICE and BCE\"\"\"\n    return 0.01*binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\ndef true_positive_rate(y_true, y_pred):\n    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))\/K.sum(y_true)\nmodel.compile(optimizer=Adam(1e-4, decay=1e-6), loss=dice_p_bce, metrics=[dice_coef, 'binary_accuracy', true_positive_rate])","db6d8d9e":"callbacks = [\n    EarlyStopping(patience=5, verbose=1),\n    ReduceLROnPlateau(patience=3, verbose=1),\n    ModelCheckpoint('model-tgs-salt-1.h5', verbose=1, save_best_only=True, save_weights_only=True)\n]","0a41a885":"batch_size = 16\nresults = model.fit_generator(train_gen(batch_size),\n                              steps_per_epoch = X_train.shape[0]\/\/batch_size,\n                              epochs=50, callbacks=callbacks,\n                              validation_data=({'img': X_valid, 'feat': X_feat_valid}, y_valid))","e20f59de":"# Get and resize test images\nX_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.float32)\nX_feat_test = np.zeros((len(test_ids), n_features), dtype=np.float32)\nsizes_test = []\nprint('Getting and resizing test images ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm_notebook(enumerate(test_ids), total=len(test_ids)):\n    path = path_test\n    \n    # Depth\n    X_feat_test[n] = df_depths.loc[id_.replace('.png', ''), 'z']\n    \n    # Load X\n    img = load_img(path + '\/images\/' + id_, grayscale=True)\n    x = img_to_array(img)\n    sizes_test.append([x.shape[0], x.shape[1]])\n    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n    \n    # Create cumsum x\n    x_center_mean = x[border:-border, border:-border].mean()\n    x_csum = (np.float32(x)-x_center_mean).cumsum(axis=0)\n    x_csum -= x_csum[border:-border, border:-border].mean()\n    x_csum \/= max(1e-3, x_csum[border:-border, border:-border].std())\n\n    # Save images\n    X_test[n, ..., 0] = x.squeeze() \/ 255\n    X_test[n, ..., 1] = x_csum.squeeze()\n\nprint('Done!')","ca0d3f56":"# Normalize X_test_feats\nX_feat_test -= x_feat_mean\nX_feat_test \/= x_feat_std","516a6292":"# Load best model\nmodel.load_weights('model-tgs-salt-1.h5')\nmodel.save('full_model_tgs.h5')","2c91d953":"# Evaluate on validation set (this must be equals to the best log_loss)\nmodel.evaluate({'img': X_valid, 'feat': X_feat_valid}, y_valid, verbose=1)","485f9f10":"# Predict on train, val and test\npreds_train = model.predict({'img': X_train, 'feat': X_feat_train}, verbose=1)\npreds_val = model.predict({'img': X_valid, 'feat': X_feat_valid}, verbose=1)\npreds_test = model.predict({'img': X_test, 'feat': X_feat_test}, verbose=1)\n\n# Threshold predictions\npreds_train_t = (preds_train > 0.5).astype(np.uint8)\npreds_val_t = (preds_val > 0.5).astype(np.uint8)\npreds_test_t = (preds_test > 0.5).astype(np.uint8)","5041bdb6":"# Create list of upsampled test masks\npreds_test_upsampled = []\nfor i in tnrange(len(preds_test)):\n    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n                                       (sizes_test[i][0], sizes_test[i][1]), \n                                       mode='constant', preserve_range=True))","2a76f5b8":"preds_test_upsampled[0].shape","b13c91cc":"def plot_sample(X, y, preds):\n    ix = random.randint(0, len(X))\n\n    has_mask = y[ix].max() > 0\n\n    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n    ax[0].imshow(X[ix, ..., 0], cmap='seismic')\n    if has_mask:\n        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[0].set_title('Seismic')\n\n    ax[1].imshow(X[ix, ..., 1], cmap='seismic')\n    if has_mask:\n        ax[1].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[1].set_title('Seismic cumsum')\n\n    ax[2].imshow(y[ix].squeeze())\n    ax[2].set_title('Salt')\n\n    ax[3].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n    if has_mask:\n        ax[3].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n    ax[3].set_title('Salt Pred');","513bd0ef":"# Check if training data looks all right\nplot_sample(X_train, y_train, preds_train)","613575b0":"# Check if valid data looks all right\nplot_sample(X_valid, y_valid, preds_val)","0544325a":"# src: https:\/\/www.kaggle.com\/aglotero\/another-iou-metric\ndef iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels = y_true_in\n    y_pred = y_pred_in\n    \n    true_objects = 2\n    pred_objects = 2\n\n    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n\n    # Compute areas (needed for finding the union between all objects)\n    area_true = np.histogram(labels, bins = true_objects)[0]\n    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n\n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection \/ union\n\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp \/ (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n    \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    return np.mean(metric)","734dd8fe":"thres = np.linspace(0.25, 0.75, 20)\nthres_ioc = [iou_metric_batch(y_valid, np.int32(preds_val > t)) for t in tqdm_notebook(thres)]","574acb90":"plt.plot(thres, thres_ioc);","5a77bb47":"best_thres = thres[np.argmax(thres_ioc)]\nbest_thres, max(thres_ioc)","bf2ea3df":"def RLenc(img, order='F', format=True):\n    \"\"\"\n    img is binary mask image, shape (r,c)\n    order is down-then-right, i.e. Fortran\n    format determines if the order needs to be preformatted (according to submission rules) or not\n\n    returns run length as an array or string (if format is True)\n    \"\"\"\n    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n    runs = []  ## list of run lengths\n    r = 0  ## the current run length\n    pos = 1  ## count starts from 1 per WK\n    for c in bytes:\n        if (c == 0):\n            if r != 0:\n                runs.append((pos, r))\n                pos += r\n                r = 0\n            pos += 1\n        else:\n            r += 1\n\n    # if last run is unsaved (i.e. data ends with 1)\n    if r != 0:\n        runs.append((pos, r))\n        pos += r\n        r = 0\n\n    if format:\n        z = ''\n\n        for rr in runs:\n            z += '{} {} '.format(rr[0], rr[1])\n        return z[:-1]\n    else:\n        return runs\n\npred_dict = {id_[:-4]:RLenc(np.round(preds_test_upsampled[i] > best_thres)) for i,id_ in tqdm_notebook(enumerate(test_ids))}","b96009f3":"sub = pd.DataFrame.from_dict(pred_dict,orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv('submission.csv')","bb149dae":"# Add augmentation\nWe do not want to get too intense on the augmentation step since these are not photos of dogs and the processed results shouldn't lose too much structural information","fe2f53b2":"# Train Model","fa42d03e":"# Threshold optimization","e6a15ba3":"We'll look at it again, just to be sure.","c2d062c8":"# Data Exploration","6ba2b462":"# Overview\nThe notebook is based on the excellent U-Net example from bguberfain located here https:\/\/www.kaggle.com\/bguberfain\/unet-with-depth.\n\nThe basic additions here are\n- DICE Loss, instead of using binary crossentropy we use a combination of DICE and BCE to better approximate the IoU metrics we are trying to optimize\n- Augmentation, we augment the datasets a bit to make the model less sensitive to small changes","cc75a79d":"# Test Data\nFirst we'll get the test data. This takes a while, it's 18000 samples.","e812669d":"# Prepare Submission\nWe need to prepare the submission. A nice CSV with predictions. All of this is one to one from Ketil and does not differ from any of the other segmentation tasks. Check them out to improve on this."}}