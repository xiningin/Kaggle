{"cell_type":{"618e8178":"code","2896a094":"code","fd357f7e":"code","4a4c32de":"code","044297b7":"code","d37539dc":"code","eeaf8d53":"code","c42e848c":"code","12881e43":"code","1b1fa90d":"code","8618b54a":"code","3eb0a8fc":"code","08831ec4":"code","0c928692":"code","a6605af5":"code","0b8d3af1":"code","4c302ff9":"code","3d521554":"markdown","bdb479a4":"markdown","9582e722":"markdown","84fa4091":"markdown","a3483606":"markdown","2f4860af":"markdown","10712cb9":"markdown","51a015d7":"markdown","d8e012d3":"markdown","f0e8e064":"markdown","c6fde4a2":"markdown","28ed2a00":"markdown","e6d3e8ba":"markdown","0d852262":"markdown","c7c02cea":"markdown","53a7148c":"markdown","c14d8ac0":"markdown"},"source":{"618e8178":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2896a094":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Input, layers\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers.core import Activation, Dropout, Flatten, Dense\nfrom keras import backend as K\nfrom keras import layers\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\n\nimport os\nimport numpy as np\nimport pandas as np\nimport seaborn as sns\n\nfrom random import randint\nfrom PIL import Image\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","fd357f7e":"main_dir = \"..\/input\/chest-xray-pneumonia\/chest_xray\/\"\ntrain_data_dir = main_dir + \"train\/\"\nvalidation_data_dir = main_dir + \"val\/\"\ntest_data_dir = main_dir + \"test\/\"\n\nnb_train_samples = 5216\nnb_validation_samples = 16\nepochs = 30\nbatch_size = 64\n\nprint(\"Working Directory Contents:\", os.listdir(main_dir))","4a4c32de":"train_n = train_data_dir+'NORMAL\/'\ntrain_p = train_data_dir+'PNEUMONIA\/'\n\nprint(\"length of cases in training set:\",len(os.listdir(train_p)) + len(os.listdir(train_n)))\nprint(\"length of pneumonia cases in training set:\",len(os.listdir(train_p)))\nprint(\"length of normal cases in training set:\",len(os.listdir(train_n)))","044297b7":"# Quick look to the images \n\nimg_name = 'IM-0115-0001.jpeg'\nimg_normal = load_img('..\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\/' + img_name)\n\nimg_name_1 = 'person1000_virus_1681.jpeg'\nimg_pneumonia = load_img('..\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\/' + img_name_1)\n\nfig, axs = plt.subplots(1,2,figsize=(10,6))\naxs[0].imshow(img_normal)\naxs[0].set_title(\"NORMAL\")\naxs[1].imshow(img_pneumonia)\naxs[1].set_title(\"PNEUMONIA\");","d37539dc":"img_height, img_width  = 180, 180\n\n\nif K.image_data_format() == 'channels_first':\n    input_shape = (3, img_width, img_height)\nelse:\n    input_shape = (img_width, img_height, 3)","eeaf8d53":"# Performing Image Augmentation to have more data samples\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)\nval_datagen = ImageDataGenerator(rescale=1. \/ 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary')\n\nvalidation_generator = val_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary')\n\ntest_generator = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary')","c42e848c":"# Show some images after data augmentation\n\nimage_batch, label_batch = next(iter(train_generator))\n\ndef show_batch(image_batch, label_batch):\n    plt.figure(figsize=(10, 10))\n    for n in range(15):\n        ax = plt.subplot(5, 5, n + 1)\n        plt.imshow(image_batch[n])\n        if label_batch[n]:\n            plt.title(\"PNEUMONIA\")\n        else:\n            plt.title(\"NORMAL\")\n        plt.axis(\"off\")\n\nshow_batch(image_batch, label_batch)","12881e43":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3),  activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.summary()","1b1fa90d":"# Define the callbacks\n\ncallbacks1 = [ \n    EarlyStopping(monitor = 'loss', patience = 6), \n    ReduceLROnPlateau(monitor = 'loss', patience = 3), \n    ModelCheckpoint('..\/working\/model.best3.hdf5',monitor='loss', save_best_only=True) # saving the best model\n]","8618b54a":"count_normal = len(train_n)\ncount_pneumonia = len(train_p)\n\ninitial_bias = count_pneumonia \/ count_normal\nprint(\"Initial bias: {:.5f}\".format(initial_bias))\n\nTRAIN_IMG_COUNT = count_normal + count_pneumonia\nweight_for_0 = (1 \/ count_normal) * (TRAIN_IMG_COUNT) \/ 2.0\nweight_for_1 = (1 \/ count_pneumonia) * (TRAIN_IMG_COUNT) \/ 2.0\n\nclass_weight = {0: weight_for_0, 1: weight_for_1}\n\nprint(\"Weight for class 0: {:.2f}\".format(weight_for_0))\nprint(\"Weight for class 1: {:.2f}\".format(weight_for_1))","3eb0a8fc":"METRICS = [tf.keras.metrics.BinaryAccuracy(),\n        tf.keras.metrics.Precision(name=\"precision\"),\n        tf.keras.metrics.Recall(name=\"recall\")]\n\nmodel.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=METRICS)","08831ec4":"history = model.fit(\n    train_generator,\n    epochs=epochs,\n    validation_data=validation_generator,\n    callbacks=callbacks1)\n    #class_weight=class_weight)","0c928692":"# Evaluate the model\nscores = model.evaluate(test_generator, return_dict=True)\n\nprint(scores)\n#print(\"Loss of the model: %.2f\"%(scores[0]))\n#print(\"Test Accuracy: %.2f%%\"%(scores[1] * 100))","a6605af5":"# Saving the model for future use\n\nfrom keras.models import load_model\n\nmodel.save('chestxray_cnn_model_3.h5')","0b8d3af1":"def draw_learning_curve(history, keys=['accuracy', 'loss']):\n    plt.figure(figsize=(12,6))\n    for i, key in enumerate(keys):\n        plt.subplot(1, 2, i + 1)\n        sns.lineplot(x = history.epoch, y = history.history[key])\n        sns.lineplot(x = history.epoch, y = history.history['val_' + key])\n        plt.title('Learning Curve')\n        plt.ylabel(key.title())\n        plt.xlabel('Epoch')\n#         plt.ylim(ylim)\n        plt.legend(['train', 'test'], loc='best')\n    plt.show()\n    \ndraw_learning_curve(history)","4c302ff9":"def predict_image(filename):\n    img = load_img(filename, target_size=(img_height, img_width))\n    image = keras.preprocessing.image.img_to_array(img)\n    image = image \/ 255.0\n    image = image.reshape(1,180,180,3)\n    model = load_model('chestxray_cnn_model_3.h5')\n    prediction = model.predict(image)\n    plt.imshow(img)\n    if(prediction[0] > 0.5):\n        stat = prediction[0] * 100 \n        print(\"This image is %.2f percent %s\"% (stat, \"PNEUMONIA\"))\n    else:\n        stat = (1.0 - prediction[0]) * 100\n        print(\"This image is %.2f percent %s\" % (stat, \"NORMAL\"))\n\n   \npredict_image(\"..\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\/IM-0117-0001.jpeg\")","3d521554":"### What is Pneumonia?\n\nPneumonia is an infection in one or both lungs. Bacteria, viruses, and fungi cause it. The infection causes inflammation in the air sacs in your lungs, which are called alveoli. The alveoli fill with fluid or pus, making it difficult to breathe.\n\n![](https:\/\/d16qt3wv6xm098.cloudfront.net\/I7a1xCoDRliAGg8FBvnVZFTITK2Ao3wY\/_.jpg)","bdb479a4":"Model 1","9582e722":"The actual sizes of the photos are so high that I set them to size 180x180.","84fa4091":"### Correct for the imbalance","a3483606":"Data is imbalanced, with more images classified as pneumonia than normal. We will correct for that by using class weighting","2f4860af":"### Fit the model","10712cb9":"### Train the model","51a015d7":"## Pneumonia detection from Chest X-Ray Images using CNN Model","d8e012d3":"### Visualizing model performance","f0e8e064":"### About Dataset\n\n* The dataset consists of training data, validation data, and testing data.\n* The training data consists of 5,216 chest x-ray images with 3,875 images shown to have pneumonia and 1,341 images shown to be normal.\n* The validation data is relatively small with only 16 images with 8 cases of pneumonia and 8 normal cases.\n* The testing data consists of 624 images split between 390 pneumonia cases and 234 normal cases.","c6fde4a2":"### Import libraries","28ed2a00":"### Predict and evaluate results","e6d3e8ba":"### Upload images","0d852262":"### Callbacks\n\n* EarlyStopping (Stop training when a monitored metric has stopped improving)\n\n* ReduceLROnPlateau (Reduce learning rate when a metric has stopped improving)\n\n* ModelCheckpoint (Callback to save the Keras model or model weights at some frequency)","c7c02cea":"### Build the CNN","53a7148c":"### Make Prediction for a single image ","c14d8ac0":"### Load the data"}}