{"cell_type":{"07925fa2":"code","a5d9ab2e":"code","add71dc6":"code","4c10893e":"code","53888ee3":"code","2272e8fa":"code","bae7be98":"code","5588f058":"code","fa10818b":"code","5a2341a3":"code","46b6ae2f":"code","e278aada":"code","c4f24eb3":"code","d61a0187":"code","91cafc0d":"code","d8e60d84":"code","67d73319":"code","a0b81465":"code","847ffaf6":"code","a7fbbb7f":"code","3a1e82a6":"code","9efb2f7f":"markdown","b005aab8":"markdown","981164fe":"markdown","b6c67ddd":"markdown","7e9a9f87":"markdown","33d8b809":"markdown","d8d6361f":"markdown","6cb11d54":"markdown","d4e5effc":"markdown","5126fc3d":"markdown"},"source":{"07925fa2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a5d9ab2e":"import numpy as np \nfrom sklearn.datasets import load_iris\n","add71dc6":"iris = load_iris()","4c10893e":"data = iris.data\ndata","53888ee3":"data = data[:,:2]\ndata","2272e8fa":"classes = iris.target\nclasses","bae7be98":"iris_data = np.insert(data,2,classes, axis=1)\niris_data\n","5588f058":"si = np.random.permutation(iris_data.shape[0])\nsi","fa10818b":"iris_data = iris_data[si]\niris_data","5a2341a3":"dataset = iris_data[:15,:]\ndataset","46b6ae2f":"def Separate_by_classes(dataset):\n    separated = {}\n    for i in range(len(dataset)):\n        row = dataset[i]\n        Class = row[-1]\n        if Class not in separated:\n            separated[Class] = []\n        separated[Class].append(row)\n    return separated\n\nseparated = Separate_by_classes(dataset)\nfor i in separated:\n    print(\"Class:\",i)\n    for row in separated[i]:\n        print(row)","e278aada":"def Mean(numbers):\n    return sum(numbers)\/len(numbers)","c4f24eb3":"def std(numbers):\n    mean = Mean(numbers)\n    std = 0\n    Sum = 0\n    for i in numbers:\n        Sum += (i-mean)**2\n    std = (Sum\/len(numbers))**0.5\n    return std","d61a0187":"def Manage_Dataset(dataset):\n    Summaries = []\n    for i in zip(*dataset):\n        Summ = [Mean(i),std(i),len(i)]\n        Summaries.append(Summ)\n    return Summaries[:-1]","91cafc0d":"def Manage_Dataset_by_Classes(dataset):\n    separated = Separate_by_classes(dataset)\n    Manage = {}\n    Keys = separated.keys()\n    for i in Keys:\n        Manage[i] = Manage_Dataset(separated[i])\n    return Manage\n    ","d8e60d84":"dataClass = Manage_Dataset_by_Classes(dataset)\nfor i in dataClass:\n    print(i,dataClass[i])","67d73319":"def Calc_Prob(x, mean, std):\n    part2_exp = np.exp(-((x-mean)**2) \/ (2*(std**2)))\n    part1 = 1\/((np.sqrt(2*np.pi))*std)\n    return part1*part2_exp","a0b81465":"def Accuracy(act,pred):\n    if len(act) == len(pred):\n        total_correct = 0\n        for i in range(len(act)):\n            if act[i] == pred[i]:\n                total_correct += 1\n            return total_correct\/len(act)\n    else:\n        print(\"Length of both datasets should be same\")\n        return None\n    \n    \ndef Find_Prob(dataClass,newData):\n    total_rows = 0\n    for i in dataClass:\n        total_rows = total_rows + dataClass[i][0][-1]\n    prob = {}\n    for i in dataClass:\n        prob[i] = dataClass[i][0][-1]\/total_rows\n        class_summary = dataClass[i]\n        for j in range(len(class_summary)):\n            mean, std, Unuse = class_summary[j]\n            prob1= Calc_Prob(newData[j], mean, std)\n            prob[i]  = prob[i]*prob1\n    return prob","847ffaf6":"def Pred(data,newData):\n    Probs = Find_Prob(data,newData)\n    max_prob = [0,0]\n    for i in Probs:\n        if Probs[i] > max_prob[1]:\n            max_prob = [i,Probs[i]]\n    return max_prob[0]\n","a7fbbb7f":"def Naive_Bayes_Algo(train,test):\n    summarize = Manage_Dataset_by_Classes(train)\n    predictions = []\n    for row in test:\n        output = Pred(summarize,row)\n        predictions.append(output)\n    return(predictions)","3a1e82a6":"data = Naive_Bayes_Algo(iris_data,iris_data[:40])\nAccuracy(iris_data[:40,-1],data)","9efb2f7f":"Now we will slice the data as we need it and remove the last columns which are of no use in our prediction for defined model","b005aab8":"The data was in ordered manner which can make our algorithm Biased so we will randomize it with permutation function","981164fe":"Now we will define our last function to train Naive Bayes Algorithm with all the functions we defined above then we call it and will get the probability.","b6c67ddd":"We defined our own functions for Mean, Standard Deviation and Variance and to manage dataset by classes \nand in the end we are calling our function and gettng the output as managed final dataset","7e9a9f87":"Now we will find out **Class Porbability**","33d8b809":"![image.png](attachment:image.png)","d8d6361f":"NBC from Scratch without using any in-built Function","6cb11d54":"Define function Separate by Classes","d4e5effc":"Now We will combine our data with Class data which will help us determine the Class of the data, of which that belong","5126fc3d":"Above we divided the data according to Classes with our function"}}