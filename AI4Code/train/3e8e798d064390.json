{"cell_type":{"513a6d8d":"code","53e8b336":"code","d3d1546a":"code","0ea8d1e0":"code","469b8047":"code","f35557e6":"code","4bbc1d68":"code","dc831579":"code","bbf9dfdd":"code","994f6e08":"code","a89eec6c":"code","21a03438":"code","88d58052":"code","d99bfdee":"code","9cae4731":"code","e0f204a1":"markdown","83189a87":"markdown","010f5617":"markdown","4cdc5343":"markdown","c7869d04":"markdown","c78fd319":"markdown"},"source":{"513a6d8d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom surprise import Reader, Dataset\nfrom surprise.model_selection import train_test_split, cross_validate\n\nfrom sklearn.metrics.pairwise import linear_kernel\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nimport pickle","53e8b336":"#Csv files come from recommendation system notebook. Check our my profile to find it.\nclicks = pd.read_csv('..\/input\/p9-data\/clicks.csv')\ndf = pd.read_csv('..\/input\/p9-data\/df.csv')","d3d1546a":"articles_metadata = pd.read_csv('..\/input\/news-portal-user-interactions-by-globocom\/articles_metadata.csv')","0ea8d1e0":"clicks.head()","469b8047":"df.head()","f35557e6":"articles = clicks.click_article_id.value_counts().index","4bbc1d68":"articles_metadata = articles_metadata.loc[articles].reset_index()\narticles_metadata","dc831579":"pickle = pd.read_pickle('..\/input\/news-portal-user-interactions-by-globocom\/articles_embeddings.pickle')\npickle = pickle[articles]\npickle.shape","bbf9dfdd":"%%time\ncosine_similarities  = cosine_similarity(pickle, pickle)","994f6e08":"with open('cosine_similarities.npy', 'wb') as f:\n    np.save(f, cosine_similarities)","a89eec6c":"#with open('cosine_similarities.npy', 'rb') as f:\n#    cosine_similarities = np.load(f)","21a03438":"cosine_similarities.shape","88d58052":"def simScores(index):\n    sim_scores = list(enumerate(cosine_similarities[index]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1:21]\n    \n    return sim_scores #warning : based on index !! not article_id","d99bfdee":"def CBrecommendations(userId):\n    \"\"\"Return the top-N recommendation for an user using content-based filtering.\n    \n    Args:\n        userId(int): userId of the user we want to recommmend articles to.\n        \n    Return: \n        a list of articleId we recommend. Sort by confidence descending.\n    \"\"\"\n    \n    #Calculate category preferences\n        #Create category weight matrix.\n    _category_weight_matrix = pd.DataFrame(columns=['click'])\n    \n        #Get user favorites categories.\n    _row = df.loc[userId]['categories']\n    _row = _row.replace('[', '').replace(']', '').replace(',', '').split()\n    \n        #Add user favorites categories to category weight matrix.\n    for index, val in pd.Series(_row).value_counts().items():\n        _category_weight_matrix.loc[index] = int(val)\n    \n        #Normalize and format category weight matrix.\n    _category_weight_matrix['click_norm'] = _category_weight_matrix.apply(lambda x : x \/ _category_weight_matrix['click'].max())\n    _category_weight_matrix = _category_weight_matrix.reset_index()\n    _category_weight_matrix = _category_weight_matrix.rename(columns={\"index\": \"category_id\"})\n    _category_weight_matrix['category_id'] = _category_weight_matrix['category_id'].astype(int)\n\n    \n    #Calculate article similarities\n    _article_similarity_score = []\n    for index, row in _category_weight_matrix.iterrows():\n        _x = simScores(row.category_id)\n        for i in range(1, row.click + 1):\n            _article_similarity_score = _article_similarity_score + _x\n            \n    #Building dataframe\n    _recommendation_df = pd.DataFrame(columns=['index', 'article_id', 'category_id', 'sim_score', 'click_weight'])\n    for row in _article_similarity_score:\n        _index = row[0]\n        _article_id = articles_metadata.loc[_index].article_id\n        _category_id = articles_metadata.loc[_index].category_id\n        if _category_id in _category_weight_matrix.category_id.values:\n            _click_weight = _category_weight_matrix.loc[_category_weight_matrix.category_id == 281].click_norm.values[0] #We use normalized value of clicked, we could use non normalized too.\n        else:\n            _click_weight = 0\n        _sim_score = row[1]\n        _new_row = {'index':_index, 'article_id':_article_id, 'category_id':_category_id, 'sim_score':_sim_score, 'click_weight':_click_weight}\n        _recommendation_df = _recommendation_df.append(_new_row, ignore_index=True)\n        \n    #Calculate final score\n    _recommendation_df = _recommendation_df.assign(score = lambda x: x['sim_score'] * x['click_weight']) \n    \n    _recommendation_list = np.array(_recommendation_df.sort_values(by=['score'], ascending=False).head(5).article_id.values, dtype='int')\n    \n    return _recommendation_list, _recommendation_df","9cae4731":"%%time\nCBrecommendations(0)","e0f204a1":"## Creating cosine similarities matrix","83189a87":"# Don't forget to UPVOTE if it helped you. Thank you","010f5617":"# Content-based recommendations","4cdc5343":" ## Combine click files","c7869d04":"# Prepare data","c78fd319":"## Remove unused articles"}}