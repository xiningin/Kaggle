{"cell_type":{"ed4b70e5":"code","12f1dfc7":"code","a35b7f37":"code","0c84b979":"code","97a78a33":"code","50041eac":"code","b50076a6":"code","35552eec":"code","e515ac90":"code","6bd6cb87":"code","4674d75e":"code","a34e6d38":"code","737f6dae":"code","382931fb":"code","a0598e21":"code","9ec99c5e":"code","f4bb2e35":"code","033db56e":"code","8a166458":"code","de83d8a4":"code","51e946ee":"code","6d153498":"markdown","0beb526b":"markdown","a8b0385a":"markdown","8dae64e8":"markdown","fa0ac112":"markdown","59f77f9f":"markdown","40de59b5":"markdown"},"source":{"ed4b70e5":"import numpy as np \nimport pandas as pd \nimport os\nimport warnings\nimport plotly\nfrom plotly.offline import iplot\nwarnings.filterwarnings(\"ignore\")\nimport sklearn\nimport matplotlib.pyplot as plt\nimport pandas_profiling as pp\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn import model_selection\nfrom sklearn import preprocessing\nfrom plotly.offline import plot, iplot, init_notebook_mode\ninit_notebook_mode(connected=True)\n\n","12f1dfc7":"path = r\"..\/input\/breast-cancer-wisconsin-data\/data.csv\"","a35b7f37":"data = pd.read_csv(path)\ndata.head()\nprint(\"data shape is {}\".format(data.shape))","0c84b979":"data=data.iloc[:,1:-1]\ndata.dtypes","97a78a33":"data.isnull().sum()","50041eac":"y= data[\"diagnosis\"]\ny.value_counts()","b50076a6":"pp.ProfileReport(data)","35552eec":"from sklearn.preprocessing import LabelEncoder\nle= LabelEncoder()\n\nle.fit(y)\ny = le.transform(y)\ny.shape","e515ac90":"X=data.iloc[:,1:]\nX.head()","6bd6cb87":"from sklearn.preprocessing import StandardScaler\nsxc = StandardScaler()\nX = sxc.fit_transform(X)\nX.shape","4674d75e":"import umap\nembedding = umap.UMAP(n_neighbors=8,\n                      min_dist=0.3,\n                      metric='correlation').fit_transform(X)\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10,10))\nplt.scatter(embedding[:,0], embedding[:,1], \n            c=y, \n            edgecolor='none', \n            alpha=0.80, \n            s=56)\nplt.axis('off');","a34e6d38":"X_train, X_test, y_train, y_test = train_test_split( X , y, test_size=0.2)","737f6dae":"!pip install lazypredict\nfrom lazypredict.Supervised import LazyClassifier, LazyRegressor\nclf = LazyClassifier(predictions=True)\nmodels, predictions = clf.fit(X_train, X_test, y_train, y_test)","382931fb":"models","a0598e21":"import xgboost as xgb\nmodel = xgb.XGBClassifier()\nmodel.fit(X, y)","9ec99c5e":"!pip install shap\nimport shap\nexplainer = shap.Explainer(model)\nshap_values = explainer(X)\nshap.plots.bar(shap_values)","f4bb2e35":"shap.plots.beeswarm(shap_values)","033db56e":"shap_values = shap.TreeExplainer(model).shap_values(X_train)\nshap.summary_plot(shap_values, X_train)","8a166458":"shap.dependence_plot(\"Feature 13\", shap_values, X_train)","de83d8a4":"shap.dependence_plot(\"Feature 23\", shap_values, X_train)","51e946ee":"shap.dependence_plot(\"Feature 27\", shap_values, X_train)","6d153498":"## $\\color{Pink}{\\text{Chapter 4. SHAP}}$ <a class=\"anchor\" id=\"chapter4\"><\/a>\n\nSHAP (SHapley Additive exPlanations) is a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions.\n\nsource : https:\/\/shap.readthedocs.io\/en","0beb526b":"## $\\color{Pink}{\\text{Introduction}}$ ","a8b0385a":"## $\\color{Pink}{\\text{Chapter 2. UMAP}}$ <a class=\"anchor\" id=\"chapter2\"><\/a>\n\nUMAP is a general purpose manifold learning and dimension reduction algorithm. It is designed to be compatible with scikit-learn, making use of the same API and able to be added to sklearn pipelines.\n\nsource: https:\/\/umap-learn.readthedocs.io\/","8dae64e8":"## $\\color{Pink}{\\text{Chapter 3. LAZY PREDICT}}$ <a class=\"anchor\" id=\"chapter3\"><\/a>\n\nLazy Predict helps build a lot of basic models without much code and helps understand which models works better without any parameter tuning. For classification you may use LazyClassifier(), for regression you may use LazyRegressor()\n\nsource: https:\/\/lazypredict.readthedocs.io\/en\/latest\/","fa0ac112":"![kaggle (2).jpg](attachment:9ff54c6a-f5fe-46e8-81b2-a4631ef46f66.jpg)\n\n**Welcome!!**\n\nThis notebook contains the usage of the interesting libraries such:\n\n* pandas_profiling\n\n* UMAP\n\n* Lazy Predict\n\n* SHAP\n\nSo you can use that notebook as a source to apply those awesome libs to your work! UPVOTE if you like\n\n\n## $\\color{orange}{\\text{Table of Contents}}$\n\n* [Chapter 1. PANDAS PROFILING REPORT](#chapter1)     \n* [Chapter 2. UMAP ](#chapter2)\n* [Chapter 3. LAZY PREDICT](#chapter3)\n* [Chapter 4. SHAP](#chapter4)\n","59f77f9f":"## $\\color{Pink}{\\text{Chapter 1. PANDAS PROFILING REPORT}}$ <a class=\"anchor\" id=\"chapter1\"><\/a>\n\nPandas-profiling is an open-source Python library that allows us to quickly do exploratory analysis. It is simple and by 1 line code every thing is done! Be careful for large datasets, it takes ages.\n\nsource : https:\/\/github.com\/pandas-profiling\/pandas-profiling","40de59b5":"## Thanks. **UPVOTE** if you like!!"}}