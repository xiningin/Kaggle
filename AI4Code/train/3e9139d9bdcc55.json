{"cell_type":{"ec7442a8":"code","9e70c906":"code","e29968a0":"code","030daace":"code","86142435":"code","004cd143":"code","79756b86":"code","f623fc22":"code","4b09f157":"code","a1729a0c":"code","333c2d8b":"code","34a11082":"code","f89c6503":"code","d6003096":"code","db963552":"markdown","c81fb442":"markdown"},"source":{"ec7442a8":"!pip install -qq segmentation-models","9e70c906":"import os\nimport sys\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom PIL import Image, ImageDraw\nfrom tqdm.notebook import tqdm\nimport segmentation_models as sm","e29968a0":"EPOCHS = 10\n\nIMG_WIDTH = 256\nIMG_HEIGHT = 256\nIMG_CHANNELS = 3\nTRAIN_PATH = '\/kaggle\/input\/global-wheat-detection\/train\/'","030daace":"PATH = \"..\/input\/global-wheat-detection\/\"\ntrain_folder = os.path.join(PATH, \"train\")\ntrain_csv_path = os.path.join(PATH, \"train.csv\")\ndf = pd.read_csv(train_csv_path)\n\ndf.head()","86142435":"train_ids = os.listdir(TRAIN_PATH)\nlen(train_ids)","004cd143":"def make_polygon(coords):\n    xm, ym, w, h = coords\n    xm, ym, w, h = xm \/ 4, ym \/ 4, w \/ 4, h \/ 4\n    polygon = [(xm, ym), (xm, ym + h), (xm + w, ym + h), (xm + w, ym)]\n    return polygon\n\nmasks = dict() # dictionnary containing all masks\n\nfor img_id, gp in tqdm(df.groupby(\"image_id\")):\n    gp['polygons'] = gp['bbox'].apply(eval).apply(lambda x: make_polygon(x))\n\n    img = Image.new('L', (IMG_WIDTH, IMG_HEIGHT), 0)\n    for pol in gp['polygons'].values:\n        ImageDraw.Draw(img).polygon(pol, outline=1, fill=1)\n\n    mask = np.array(img, dtype=np.uint8)\n    masks[img_id] = mask","79756b86":"# Get and resize train images and masks\nX_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nY_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\nprint('Getting and resizing train images and masks ... ')\nsys.stdout.flush()\n\nfor n, id_ in tqdm(enumerate(train_ids[:]), total=len(train_ids)):\n    path = TRAIN_PATH + id_\n    img = imread(path)[:,:,:IMG_CHANNELS]\n    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n    X_train[n] = img\n    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n    \n    id_clean = id_.split('.')[0]\n    if id_clean in masks.keys():\n        Y_train[n] = masks[id_clean][:, :, np.newaxis]","f623fc22":"X_train.shape, Y_train.shape","4b09f157":"a=2\nplt.imshow(X_train[a])","a1729a0c":"plt.imshow(Y_train[a,:,:,0].astype(int))","333c2d8b":"model = sm.Unet('efficientnetb3', encoder_weights='imagenet')","34a11082":"model.compile(\n    'Adam',\n    loss=sm.losses.bce_jaccard_loss,\n    metrics=[sm.metrics.iou_score],\n)","f89c6503":"model.fit(\n   x=X_train,\n   y=Y_train,\n   batch_size=16,\n   epochs=EPOCHS\n)","d6003096":"model.save('model.h5')","db963552":"Modification of this greate kernel: https:\/\/www.kaggle.com\/pednt9\/gwd-keras-unet-starter","c81fb442":"Inference part: https:\/\/www.kaggle.com\/armin25\/gwd-starter-gpu-v2-infer"}}