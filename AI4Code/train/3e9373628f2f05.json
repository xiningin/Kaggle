{"cell_type":{"f6193277":"code","5899affe":"code","b5fc23af":"code","c5962b7c":"code","c7586abd":"code","88e08129":"code","c5afe492":"code","161fd305":"code","3217eab4":"code","7673275f":"code","fe259b04":"code","771c8bef":"code","3fc79cb7":"code","e158145b":"code","326e4906":"markdown","3f6c7e6f":"markdown","96e9cb32":"markdown","2bf5a3d8":"markdown"},"source":{"f6193277":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5899affe":"from sklearn.datasets import load_iris\ndata = load_iris(as_frame=True)\ndata.data.head()","b5fc23af":"data.target_names","c5962b7c":"from sklearn.model_selection import train_test_split\nX = data.data.iloc[:, 2:]  # w\u00e4hle nur `petal length` und `petal width`\ny = data.target == 2  # Bin\u00e4rer Vektor, 1: Iris Virginica, 0: nicht Iris Virginica\nX.head()","c7586abd":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import GridSearchCV\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","88e08129":"LogReg=LogisticRegression(penalty='l2')\nLogReg.fit(X_train,y_train)\n","c5afe492":"from sklearn.model_selection import GridSearchCV\n\ngrid_search = GridSearchCV(LogReg, {\"C\": [0.1,1,10,100,1000]})\ngrid_search.fit(X_train, y_train)","161fd305":"pd.DataFrame(grid_search.cv_results_).sort_values(\"rank_test_score\").head()","3217eab4":"import numpy as np\nimport matplotlib.pyplot as plt\n\ndef decision_boundary(x):\n    x_1=x\n    beta_0=LogReg.intercept_\n    beta_1=LogReg.coef_[0][0]\n    beta_2=LogReg.coef_[0][1]\n    return -((beta_0+beta_1*x_1)\/beta_2)\n\n#x1=l\u00e4nge , x2=breite, x-Achse=x1, y-Achse=x2\n\nplt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=y_train)\nx = np.arange(2,7,0.1)\ny = decision_boundary(x)\n\nplt.plot(x, y)\nplt.xlabel(\"X1=L\u00e4nge\")\nplt.ylabel(\"X2=Breite\")\n\nplt.show()\n","7673275f":"print(LogReg.coef_[0][0])\nprint(LogReg.coef_[0][1])","fe259b04":"LogReg.intercept_","771c8bef":"X = data.data.iloc[:, 2:]  # w\u00e4hle nur `petal length` und `petal width`\ny = data.target == 1  # Bin\u00e4rer Vektor 1: Iris Versicolor, 0: nicht Iris Versicolor\nX_train, X_test, y_train, y_test = train_test_split(X, y == 1, test_size=0.2, random_state=42)","3fc79cb7":"LogReg=LogisticRegression(penalty='l2')\nLogReg.fit(X_train,y_train)","e158145b":"plt.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=y_train)\nx = np.arange(2,7,0.1)\ny = decision_boundary(x)\n\nplt.plot(x, y)\nplt.xlabel(\"X1=L\u00e4nge\")\nplt.ylabel(\"X2=Breite\")\n\nplt.show()","326e4906":"lila=nicht Iris virgincia\ngelb= Iris virgincia \nin relation zu l\u00e4nge und breite","3f6c7e6f":"# **Setup**","96e9cb32":"# **3a) Bin\u00e4re Logistische Regression**","2bf5a3d8":"# **3b) Entscheidungsgrene von Iris Versicolor**"}}