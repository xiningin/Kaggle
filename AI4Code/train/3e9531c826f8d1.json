{"cell_type":{"30c81f28":"code","2e01d5dc":"code","6bcd3a7d":"code","ca7f9884":"code","db118d95":"code","39c54004":"code","52f997ad":"code","11d3744c":"code","d6d34f25":"code","69cd0014":"code","f01d9b9a":"code","ec618667":"code","94124e2c":"code","eecf110d":"code","e81bf8b6":"code","a7c9746c":"code","2ae2139a":"markdown","2f5737b0":"markdown","84bf0991":"markdown","0c479858":"markdown","a0dad9b3":"markdown","237efa14":"markdown","b8128c45":"markdown","5df8501b":"markdown","1990da49":"markdown","acd579ef":"markdown","dc34b724":"markdown","ca1e57c9":"markdown","6e96d029":"markdown","25371e55":"markdown","1ac2832f":"markdown","c942f4d6":"markdown"},"source":{"30c81f28":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2e01d5dc":"#! pip install deepspeed mpi4py","6bcd3a7d":"!pip install -q aitextgen #install the main package","ca7f9884":"from aitextgen import aitextgen","db118d95":"! nvidia-smi","39c54004":"ai = aitextgen(tf_gpt2=\"124M\", to_gpu=True)","52f997ad":"input_file = pd.read_csv(\"..\/input\/reddit-vaccine-myths\/reddit_vm.csv\")","11d3744c":"pd.set_option('display.max_colwidth', None)","d6d34f25":"input_file.title.value_counts()","69cd0014":"df = pd.DataFrame(input_file[\"title\"])\n\ndf=df[df.title!='Comment'].drop_duplicates()\n\ndf.shape","f01d9b9a":"df.to_csv(\"input_text_cleaned.txt\", columns=[\"title\"], header=False, index=False)","ec618667":"from aitextgen.TokenDataset import TokenDataset","94124e2c":"data = TokenDataset('.\/input_text_cleaned.txt', line_by_line=True)","eecf110d":"ai.train('input_text_cleaned.txt',\n         line_by_line=False,\n         from_cache=False,\n         num_steps=500,\n         generate_every=100,\n         save_every=500,\n         save_gdrive=False,\n         learning_rate=1e-3,\n         fp16=False,\n         batch_size=1, \n         )","e81bf8b6":"ai = aitextgen(model_folder=\".\/trained_model\/\",config=\".\/trained_model\/config.json\", to_gpu=True)","a7c9746c":"ai.generate(n=5,\n            batch_size=1,\n            max_length=50,\n            temperature=1.0,\n            top_p=0.9)","2ae2139a":"### Use the above saved text file for fine-tuning - set the right parameters ","2f5737b0":"<h1> References <\/h1>\n\n1.https:\/\/www.kaggle.com\/nulldata\/gpt2-generated-indian-food-recipes","84bf0991":"The meme above was generated by [GPT2](https:\/\/en.wikipedia.org\/wiki\/GPT-2)\n\nI am a *Get my hands dirty* kind of person. I am also a *Trying the trendiest things out in the market person* . What happens when these two people meet? \nA lovechild. Here's me using GPT2 to write a few Reddit post headlines.\nSince I use the [r\/VaccineMyths](https:\/\/www.kaggle.com\/gpreda\/reddit-vaccine-myths) Dataset, the output cell contains headlines generated by GPT2.\n\nEnough to fool a human, right?\nLet me know in the comments.","0c479858":"### Install `aitextgen` package","a0dad9b3":"### Know your GPU Config ","237efa14":"<h2> What is Transfer learning? <\/h2>\nIn short, Transfer learning is when a model trained for a certain task is reused as a starting point for some other task, saving time and effort of re-training.\nThis is a helpful resource to read up on:\n\nhttps:\/\/ruder.io\/transfer-learning\/","b8128c45":"<h1> Imports and installation <\/h1>","5df8501b":"### Save the column as text file","1990da49":"### Download the 124M GPT2 Model","acd579ef":"### Text Cleaning (removing comments and keeping only original posts\n","dc34b724":"### Load the newly fine-tuned model which is saved in `trained_model` directory","ca1e57c9":"### Load `aitextgen`\n\nThis is the secret sauce","6e96d029":"### Read the Input Dataset","25371e55":"<h2> What is GPT-2 <\/h2>\nGPT-2 is a large transformer-based language model with 1.5 billion parameters, trained on a dataset[1]\nWe created a new dataset which emphasizes diversity of content, by scraping content from the Internet. In order to preserve document quality, we used only pages which have been curated\/filtered by humans\u2014specifically, we used outbound links from Reddit which received at least 3 karma. This can be thought of as a heuristic indicator for whether other users found the link interesting (whether educational or funny), leading to higher data quality than other similar datasets, such as CommonCrawl.\n\n[Source](https:\/\/openai.com\/blog\/better-language-models\/)","1ac2832f":"### Time to see the generated text in action","c942f4d6":"<img src = https:\/\/i.redd.it\/b2dfxek3e9t41.jpg >"}}