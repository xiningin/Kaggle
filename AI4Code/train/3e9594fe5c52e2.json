{"cell_type":{"90d41044":"code","c5a4b952":"code","9b4145f8":"code","6b0b782a":"code","9015d93f":"code","73c8e582":"code","856469df":"code","5a150a91":"code","5f80cf79":"code","feb30f72":"code","9929e897":"code","903db71a":"code","185fd343":"code","f454917f":"code","0d0f989b":"code","4952a23e":"code","8d37a135":"code","b51b1263":"code","b74019b7":"code","36da3a40":"code","4790ac69":"code","eff1ac3d":"code","85cfd2bd":"code","a1f2075e":"code","6a199401":"code","bf5c917c":"code","645ec016":"code","111d50d3":"code","be726aa0":"markdown","d776fcb8":"markdown","cd9bb58f":"markdown","f049f196":"markdown","9a5b6d06":"markdown","ff1f4d43":"markdown","3e052dea":"markdown","c77e3d0f":"markdown","08f980ec":"markdown"},"source":{"90d41044":"import os\n# Ignore  the warnings\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport seaborn as sns\nimport random as rn\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tqdm import tqdm","c5a4b952":"a = '..\/input\/flowers\/flowers'","9b4145f8":"print (os.listdir(a))","6b0b782a":"classes = {0:'daisy',\n           1:'dandelion',\n           2:'rose',\n           3:'sunflower',\n           4:'tulip'}\nimg_height = 200\nimg_width = 200\ninput_shape = (200,200,3)\nepochs = 10","9015d93f":"train_folder = '..\/input\/flowers\/flowers\/'","73c8e582":"print (os.listdir(train_folder))","856469df":"sns.barplot(x=['tulip','roses','dandelion','sunflower','daisy'] , y=[len(os.listdir(train_folder+'tulip')),\n                                                                    len(os.listdir(train_folder+'rose')),\n                                                                    len(os.listdir(train_folder+'dandelion')),\n                                                                    len(os.listdir(train_folder+'sunflower')),\n                                                                    len(os.listdir(train_folder+'daisy'))])","5a150a91":"training_data=[]\nlabel = []\ndef process_image():\n    for i in tqdm(range(len(classes))):\n        print ('Working on directory {}'.format(classes[i]))\n        for j in os.listdir(train_folder+'\/\/'+classes[i]):\n                if j.endswith(\"jpg\"):\n                    img_read = cv2.imread(os.path.join(train_folder+'\/'+classes[i]+'\/'+j), cv2.IMREAD_COLOR)\n                    img_read = cv2.resize(img_read,(img_height,img_width))\n                    training_data.append(np.array(img_read))\n                    label.append(str(classes[i]))\n                else:\n                    continue\n               # print (os.path.join(train_folder,classes[i]+'\/'+j))","5f80cf79":"process_image()","feb30f72":"plt.figure(figsize=(10,10))\nfor i in range(10):\n    plt.subplot(5,5,i+1)\n    l=rn.randint(0,len(label)-1)\n    plt.imshow(cv2.cvtColor(training_data[l], cv2.COLOR_BGR2RGB))\n    plt.title(label[l])\n    plt.tight_layout()\nplt.show()\n#plt.tight_layout()","9929e897":"from sklearn.preprocessing import LabelEncoder","903db71a":"encoder = LabelEncoder()\nY = encoder.fit_transform(label)\nY = to_categorical(Y,len(classes))","185fd343":"X = np.array(training_data)","f454917f":"X = X\/255.0","0d0f989b":"x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=42)","4952a23e":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam , RMSprop\n# specifically for cnn\nfrom keras.layers import Dropout, Flatten,Activation\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization , GlobalAveragePooling2D\nfrom keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint\n\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',input_shape=(input_shape),activation ='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters = 256, kernel_size = (3,3),padding = 'Same',activation ='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters = 512, kernel_size = (5,5),padding = 'Same',activation ='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(MaxPooling2D(pool_size=(3,3)))\nmodel.add(Flatten())\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dense(len(classes), activation = \"softmax\"))","8d37a135":"model.summary()","b51b1263":"learning_rate=0.00001","b74019b7":"#Call backs\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',\n    patience=2,\n    cooldown=1,\n    min_lr=0.000001,\n    verbose=1)\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=2 , verbose=1)\n\n\n#Optimizer\noptimizer=Adam(lr=learning_rate)\n\ncallbacks =[reduce_lr,early_stopping]","36da3a40":"model.compile(optimizer,loss='categorical_crossentropy',metrics=['accuracy'])","4790ac69":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=3,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.2, # Randomly zoom image \n        width_shift_range=0.3,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.3,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\ndatagen.fit(x_train)","eff1ac3d":"History = model.fit_generator(datagen.flow(x_train,y_train),\n                              epochs = epochs, validation_data = (x_test,y_test),\n                               steps_per_epoch=x_train.shape[0],callbacks=callbacks ,verbose=2)","85cfd2bd":"#Model history\naccuracy = model.history.history['acc']\nval_accuracy= model.history.history['val_acc']\nloss = model.history.history['loss']\nval_loss = model.history.history['val_loss']\n","a1f2075e":"\n#Plot accuracy\nplt.title('Accuracy \/ Val Accuracy')\nplt.plot(accuracy , label='Accuracy')\nplt.plot(val_accuracy,label='Val accuracy')\nplt.legend()","6a199401":"#Plot loss\nplt.title('Loss \/ Validation loss')\nplt.plot(loss,label='Loss')\nplt.plot(val_loss, label='Validation loss')\nplt.legend()","bf5c917c":"import tensorflow as tf","645ec016":"def predict(img):\n    label = model.predict(img.reshape(-1,200,200,3))\n    return classes[np.argmax(label)]","111d50d3":"plt.figure(figsize=(20,20))\nfor i in range(10):\n    l=rn.randint(0,len(x_test)-1)\n    predict_label = predict(x_test[l])\n    plt.subplot(5,5,i+1)\n    plt.title('Pre :{} Tru :{}'.format(predict_label,classes[np.argmax(y_test[l])]))\n    plt.imshow(x_test[l])\nplt.tight_layout()","be726aa0":"Over the models I've trained , the models have predicted horribly on unseen data. For instance it confuses dandelion with sunflower , this has been one of the main issues I've faced , but now the model seems to be doing pretty well.","d776fcb8":"As we can see we've got a pretty balanced dataset , we can now proceed forward to processing and feeding the dataset to the network","cd9bb58f":"**Random Prediction**","f049f196":"**Model**","9a5b6d06":"**Pre-Processing the image**","ff1f4d43":"**Multi-Class Flower Classification**\n","3e052dea":"**Viewing the processed image**","c77e3d0f":"**Data Augmentation**","08f980ec":"**Data Visualization**"}}