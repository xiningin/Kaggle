{"cell_type":{"7c41bfba":"code","011698b1":"code","71c7f706":"code","43d0fb2a":"code","013eb1b2":"code","74930929":"code","ab9ae9d7":"code","33f4dd61":"code","b1b16bf3":"code","50ac9bb4":"code","4e87d3f5":"code","2f4a1f7e":"code","d193a2c0":"code","dd8a483c":"code","8fa460d2":"code","9b9f1fda":"code","b072cf67":"code","96a71e74":"code","5392b34e":"code","ebaec8cd":"code","751075de":"code","acb702d4":"code","8707b43b":"code","35c35d34":"code","195b447e":"code","1fba9fbd":"markdown","a94b98d2":"markdown","e20cc525":"markdown","2c8bbbfc":"markdown","e0fa23bf":"markdown","3cbd82a9":"markdown","9cf63266":"markdown","798aff2e":"markdown","484539bf":"markdown","603fdd11":"markdown","940c2b59":"markdown","a6cc9bc4":"markdown","dbb27c92":"markdown","82b15429":"markdown","3f35b6f2":"markdown","6e6732c2":"markdown","58434464":"markdown","f56c8f0f":"markdown","ca5e5f4d":"markdown","5a2b89fa":"markdown","dcb9adef":"markdown","5e562ac3":"markdown","b1b067ab":"markdown","98d55754":"markdown","c0b2a819":"markdown"},"source":{"7c41bfba":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom sklearn.model_selection import train_test_split\nimport itertools\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm as tqdm","011698b1":"# print dataset paths by Kaggle's way\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","71c7f706":"train_data = pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv')","43d0fb2a":"train_data.head()","013eb1b2":"x_train = train_data.iloc[:,1:].values\/255 #train_data(x)\ny_train = train_data.label.values          #train_data(y)","74930929":"train_x, train_valid_x, train_y, train_valid_y = train_test_split(x_train, y_train, test_size = 0.2, random_state = 42)","ab9ae9d7":"train_x_torch = torch.from_numpy(train_x).type(torch.FloatTensor)\nvalid_x_torch = torch.from_numpy(train_valid_x).type(torch.FloatTensor)\ntrain_y_torch = torch.from_numpy(train_y).type(torch.LongTensor)\nvalid_y_torch = torch.from_numpy(train_valid_y).type(torch.LongTensor)","33f4dd61":"train_x_torch = train_x_torch.view(-1, 1,28,28).float()\nvalid_x_torch = valid_x_torch.view(-1, 1,28,28).float()","b1b16bf3":"train_set = torch.utils.data.TensorDataset(train_x_torch, train_y_torch)\nvalid_set = torch.utils.data.TensorDataset(valid_x_torch, valid_y_torch)","50ac9bb4":"#preparing Data Loaders\nbatch_size = 128\ntrain_loader = torch.utils.data.DataLoader(train_set, shuffle = True, batch_size = 128)\nvalid_loader = torch.utils.data.DataLoader(valid_set, shuffle = True, batch_size = 128)","4e87d3f5":"plt.figure(figsize=(30,30))\nfor i in range(100):\n    plt.subplot(20, 20, i+1)\n    plt.title(\"No.\" + str(i))\n    plt.imshow(train_data.iloc[:,1:].iloc[i].values.reshape(28,28),cmap='Greys')","2f4a1f7e":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \ndevice","d193a2c0":"list_process=[]","dd8a483c":"def train(model, epoch):\n    model.train()\n    train_loss = 0\n    correct = 0\n    for data, label in train_loader:\n        data, label = data.to(device), label.to(device)  \n        optimizer.zero_grad()  \n        output = model(data) \n        loss = criterion(output, label)  \n        loss.backward() \n        optimizer.step()  \n        train_loss += loss.item() \n        #get argmax values in outputs\n        pred = output.argmax(dim=1, keepdim=True)\n        correct += pred.eq(label.view_as(pred)).sum().item()\n    print('epoch for train: {}, accuracy: ({:.2f}%)'.format(epoch,correct*100 \/ len(train_loader.dataset)))\n    list_process.append(correct*100 \/ len(train_loader.dataset))","8fa460d2":"def valid(model, epoch):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, label in valid_loader:\n            data, label = data.to(device), label.to(device)\n            output = model(data)\n            test_loss += criterion(output, label).item()\n            pred = output.argmax(dim=1, keepdim=True)\n            correct += pred.eq(label.view_as(pred)).sum().item()\n    print('epoch for test: {}, accuracy: ({:.2f}%)'.format(epoch,correct*100 \/ len(valid_loader.dataset)))","9b9f1fda":"class cnn_layers(nn.Module):\n    def __init__(self):\n        super(cnn_layers,self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.dropout1 = nn.Dropout(0.25)\n        self.dropout2 = nn.Dropout(0.5)\n        self.fc1 = nn.Linear(9216, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = F.max_pool2d(x, 2)\n        x = self.dropout1(x)\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.dropout2(x)\n        x = self.fc2(x)\n        output = F.log_softmax(x, dim=1)\n        return output\n\nmodel = cnn_layers()\nmodel.to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\ncriterion = nn.CrossEntropyLoss() ","b072cf67":"print(model)\nfor epoch in tqdm(range(20)):\n    train(model,epoch)","96a71e74":"import matplotlib.pyplot as plt\nplt.plot(list_process)\nplt.xlabel(\"number of epochs\")\nplt.ylabel(\"accuracy(%)\")\nplt.title(\"CNN with Pytorch Model\")\nplt.legend()\nplt.show()","5392b34e":"for epoch in tqdm(range(10)):\n    valid(model,epoch)","ebaec8cd":"test_data=pd.read_csv('\/kaggle\/input\/fashionmnist\/fashion-mnist_test.csv').drop(columns=\"label\")\ntest_data","751075de":"x_test = test_data.values\/255\nx_test_torch = torch.from_numpy(x_test).type(torch.FloatTensor)\nd_labels = np.zeros(x_test.shape)\nd_labels = torch.from_numpy(d_labels)\n#Think about dimentions of data. Without this \"an shapes doesn't fit error\", will occur.\nx_test_torch = x_test_torch.view(-1, 1, 28, 28)\n#Make a tensordataset and a testloader\ntestset = torch.utils.data.TensorDataset(x_test_torch, d_labels)\ntestloader = torch.utils.data.DataLoader(testset, batch_size = 1, shuffle = False)","acb702d4":"submit_list = [['ImageId', 'Label']]\nwith torch.no_grad():\n    model.eval()\n    image_id = 1\n    for images,label in testloader:\n        images,label = images.to(device), label.to(device)\n        outputs = model(images)\n        probs = torch.exp(outputs)\n        top_p, top_class = probs.topk(1, dim = 1)\n        for preds in top_class:\n            submit_list.append([image_id,preds.item()])\n            image_id += 1","8707b43b":"df = pd.DataFrame(submit_list)\ndf.columns = df.iloc[0]\ndf = df.drop(0, axis = 0)\ndf.to_csv('submit.csv', index = False)\nprint(\"submit.csv saved\")","35c35d34":"plt.figure(figsize=(30,30))\nfor i in range(10):\n    plt.subplot(20, 20, i+1)\n    plt.imshow(test_data.iloc[i].values.reshape(28,28),cmap='Greys')","195b447e":"t_label=[\"T-shirt or top\",\"Pants\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Shoes\",\"Bag\",\"Ankle boot\"]\ncheck_answer=df.iloc[:10,[1]].T\ntolist_check=np.array(check_answer).tolist()\nimport itertools\ntlc=list(itertools.chain.from_iterable(tolist_check))\ncount=0\nfor k in tlc:\n    count=count+1\n    print(\"No\",count,\":\",t_label[int(k)])","1fba9fbd":"Correct answers?!\nThanks for reading my notebook :-) ","a94b98d2":"5. Let's make Tensor Datasets","e20cc525":"9. Define layers like Conv2d for CNN, max_pool2d for max pooing .etc","2c8bbbfc":"<BR><BR>\n## Let's experience <font color=\"blue\">\"Image recognition by using Deep Learning Tech\"<\/font> with <font color=\"green\"> Fashion MNIST dataset.<\/font>\n## What is Fashion MNIST?\nThe Fashion MNIST is a dataset that consists of fashion item images; 60,000 training data and 10,000 test data. By the way, MNIST stands for Modified National Institute of Standards and Technology database.\n## What is Deep Learning?\nDeep learning is one of machine learning algorithms which consists of multiple layers to extract features of datasets.\n## What is Pytorch?\nPytorch is one of machine learning libraries, originally developed by Facebook's AI Research Lab. It's useful especially for deep learning.\n<HR>","e0fa23bf":"3. Let's split train_data(x)&(y) into train_x, valid_x, train_y, valid_y by using sklearn's train_test_split.","3cbd82a9":"1. Import libraries","9cf63266":"11-3. Make a CSV file for submission","798aff2e":"7.Let's send data to GPU and reset optimaizer and define loss calculation,loss backward .etc","484539bf":"11-2. Let's start prediction.","603fdd11":"6. Check if GPU is available or not.","940c2b59":"2. Let's download datasets and check datasets.","a6cc9bc4":"11. Let's check if this model's prediction is correct or not.","dbb27c92":"10. Let's start 20-epoch deep learning.","82b15429":"6. Let's make DataLoaders for mini-batching.","3f35b6f2":"Okay \"Type='cuda'\" means GPU is available.","6e6732c2":"5. Think about dimentions of data. Without this \"an shapes doesn't fit error\", will occur.","58434464":"<BR>\nWhich do u like, tensorflow.keras or pytorch? \"Today\" I'm somehow in pytorch mode. Let's enjoy Pytorch!<BR>\nBTW, if you are in tensorflow.keras mode, you can find some of them in my notebooks area.","f56c8f0f":"Check the performance with validation data","ca5e5f4d":"11-1. Make a dataloader for testing.","5a2b89fa":"8. Let's define valid test. One thing different from \"def train\" is \"torch.no_grad()\".","dcb9adef":"That means the first column is \"label\", columns from the 2nd to the last is \"28 x 28 = 784 pixcels\".\n<BR>Okay, let's make x_train, y_train, x_test.","5e562ac3":"Okay. the CNN deep learning model worked with train data and validation data.","b1b067ab":"4. Let's show images of Fashion MNIST.","98d55754":"4.Change them into Pytorch's Float Tensors.","c0b2a819":"Check the train_data."}}