{"cell_type":{"97fd50cc":"code","77b25e8e":"code","e843404e":"code","e114c860":"code","f0ed78bc":"code","efab8344":"code","671d5c85":"code","db42348c":"code","dce3306a":"code","14c5a77b":"code","5afa9703":"code","731dd977":"code","3196d08f":"code","70e1e0c8":"code","e7a21efd":"code","34b67507":"code","13482877":"code","5089e601":"code","8c95b992":"code","cac2f52d":"markdown","e02c17ce":"markdown","711ddf8d":"markdown","3faf5cd5":"markdown","0af43737":"markdown","3cad72b9":"markdown","76de0335":"markdown","53a0a080":"markdown","ee2afba2":"markdown","cb9513a1":"markdown","aa328dcc":"markdown","e64ea97f":"markdown","19402736":"markdown","11715bda":"markdown","5048901c":"markdown","a151723c":"markdown","0ac7a463":"markdown","33cb0c38":"markdown","eba28b5b":"markdown","4fd8d4f2":"markdown","092d53df":"markdown","062f9939":"markdown","8f06b0db":"markdown","51924388":"markdown","f8cac0d9":"markdown","9d0a1f37":"markdown","35451dc9":"markdown"},"source":{"97fd50cc":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport pylab as plt\n\nplt.rc('figure', figsize=(10, 5))\nfizsize_with_subplots = (10, 10)\nbin_size = 10\n\n# df_train \u00e9 o nosso dataframe com os dados de treinamento para constru\u00e7\u00e3o de nosso modelo.\ndf_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')\ndf_train.head(3)\n","77b25e8e":"df_train.describe()","e843404e":"y = df_train.Survived\ndf_train.drop('Survived', axis=1, inplace=True) #removemos a coluna com a resposta que foi armazenada em y","e114c860":"n_train = df_train.PassengerId.count()\nn_test = df_test.PassengerId.count()\n\ndf_todos = pd.concat([df_train, df_test]) # concatena os dataframes\nn_todos = df_todos.PassengerId.count()\n\nprint(n_train, n_test, n_train+n_test, n_todos)","f0ed78bc":"## Tornando os nulos em Embarked igual \u00e0 moda (valor mais comum)\ndf_todos.loc[df_todos['Embarked'].isnull(), 'Embarked'] = 'S'","efab8344":"### Aqui fazemos pela m\u00e9dia a substitui\u00e7\u00e3o dos nulos\ndf_todos.loc[df_todos['Age'].isnull(), 'Age'] = int(df_todos.Age.mean())\ndf_todos.loc[df_todos['Fare'].isnull(), 'Fare'] = int(df_todos.Fare.mean())","671d5c85":"### C\u00f3digo para gerar features polinomiais\nfrom sklearn.preprocessing import PolynomialFeatures\n\n#gera as features polinomiais com os atributos na lista (alterar se quiser)\npoly = PolynomialFeatures(2, interaction_only=True)\nnovas_colunas = poly.fit_transform(df_todos[['Fare', 'Age']])\nnovas_colunas","db42348c":"## Adiciona as novas colunas polinomiais no dataframe.\nfor i in range(novas_colunas.shape[1]):\n    df_todos['p' + str(i)] = novas_colunas[:,i]\ndf_todos.head(3)","dce3306a":"novas_colunas_ohe_embarked = pd.get_dummies(df_todos['Embarked']) \ndf_todos = pd.concat([df_todos,novas_colunas_ohe_embarked], axis=1) # axis = 1 concatena colunas. axis = 0 concatena linhas\ndf_todos.head(3)","14c5a77b":"# aqui atribuimos a nova coluna ao dataframe com outro nome.\ndf_todos['Pclass_int'] = pd.factorize(df_todos['Pclass'])[0]\ndf_todos['Sex_int'] = pd.factorize(df_todos['Sex'])[0]\ndf_todos.head(3)","5afa9703":"passenger_Id = df_todos['PassengerId'] # precisamos guardar para fazer a submiss\u00e3o para o kaggle\n\ndf_todos_final = df_todos.drop(['PassengerId', 'Pclass', 'Name', 'Ticket', 'Cabin', 'Embarked', 'Sex'], \n                               axis=1, inplace=False)\ndf_todos_final.head(3)","731dd977":"## checando se estamos com a quantidade certa de linhas. Vai lan\u00e7ar uma exce\u00e7\u00e3o se for diferente\nassert df_todos_final.Age.count()==n_todos","3196d08f":"X_train = df_todos_final[:n_train].values\nX_test = df_todos_final[n_train:].values\ny_train = y.values\npassenger_Id_test = passenger_Id[n_train:].values ## s\u00f3 nos interessa os ids dos passageiros do conjunto de teste para submiss\u00e3o\nprint(X_train.shape, y_train.shape, X_test.shape, passenger_Id_test.shape)","70e1e0c8":"## Agora j\u00e1 podemos embaralhar os dados de treino\nfrom sklearn.model_selection import KFold\nnfolds=5\nkf = KFold(n_splits=nfolds, shuffle=True)","e7a21efd":"from sklearn import tree\nfrom sklearn.metrics import accuracy_score ## Essa \u00e9 a m\u00e9trica usada na competi\u00e7\u00e3o do kaggle\n\ny_full_test =[] ##Aqui guardamos as previs\u00f5es de cada modelo (classificador) em todo o dado de teste\nmetricas = []\nfor train, valid in kf.split(X_train, y_train):\n    ## Separamos os dados dos folds\n    x_train_fold = X_train[train]\n    y_train_fold = y_train[train]\n    x_valid = X_train[valid]\n    y_valid = y_train[valid]\n    \n    ##Treinamos o classificador, avaliamos nos dados de valida\u00e7\u00e3o e medimos o desempenho\n    clf = tree.DecisionTreeClassifier()\n    clf.fit(x_train_fold, y_train_fold)\n    y_pred = clf.predict(x_valid)\n    metricas.append(accuracy_score(y_valid, y_pred))\n    \n    ##Aqui realizamos a previs\u00e3o nos dados de teste. Para cada modelo (fold) vamos gerar as previs\u00f5es completas\n    ##nesses dados\n    y_full_test.append(clf.predict(X_test))\n    \nprint(metricas, '\\nm\u00e9dia da acur\u00e1cia na valida\u00e7\u00e3o', np.array(metricas).mean())\n","34b67507":"\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score #Esta eh a metrica usada na competicao do Kaggle.\n\ny_full_test =[] ##Aqui guardamos as previs\u00f5es de cada modelo (classificador) em todo o dado de teste\nmetricas = []\nfor train, valid in kf.split(X_train, y_train):\n    ## Separamos os dados dos folds\n    x_train_fold = X_train[train]\n    y_train_fold = y_train[train]\n    x_valid = X_train[valid]\n    y_valid = y_train[valid]\n    \n    ##Treinamos o classificador, avaliamos nos dados de valida\u00e7\u00e3o e medimos o desempenho\n    #clf = tree.DecisionTreeClassifier()\n    lr = LogisticRegression(solver='liblinear')\n    #clf.fit(x_train_fold, y_train_fold)\n    #y_pred = clf.predict(x_valid)\n    metricas.append(accuracy_score(y_valid, y_pred))\n    \n    ##Aqui realizamos a previs\u00e3o nos dados de teste. Para cada modelo (fold) vamos gerar as previs\u00f5es completas\n    ##nesses dados\n    y_full_test.append(clf.predict(X_test))\n    \nprint(metricas, '\\nm\u00e9dia da acur\u00e1cia na valida\u00e7\u00e3o', np.array(metricas).mean())\n\n\n","13482877":"## soma as previs\u00f5es de cada classificador (0 ou 1), que no final pode dar at\u00e9 nfold no total \n##em cada passageiro, se todos votarem 1\ntotal = np.sum(y_full_test, axis=0)\n## Agora dividimos pelo numero de folds e arredondamos.\npreds_test = np.round(np.divide(total,nfolds))","5089e601":"df_result = pd.DataFrame(passenger_Id_test, columns=['PassengerId'])\ndf_result['Survived'] = (preds_test.astype('int'))\ndf_result.head(3)","8c95b992":"df_result.to_csv('submittion.csv', index=False) #Index=false remove uma coluna in\u00fatil numerada de 0 a n","cac2f52d":"Agora vamos usar uma \u00e1rvore de decis\u00e3o simples para gerar um modelo e na sequ\u00eancia gerar o arquivo que vai ser submetido.","e02c17ce":"### One Hot Encoding","711ddf8d":"## Parte 1 - Importando os dados e gerando features","3faf5cd5":"O c\u00f3digo abaixo cria OHE para uma determinada coluna e a anexa ao dataframe. Cabe a voc\u00ea remover a coluna original depois","0af43737":"#### Importanto bibliotecas e carregando os dados","3cad72b9":"# Estudo de caso - Competi\u00e7\u00e3o Kaggle - Sobreviventes do Titanic","76de0335":"No caso da idade, a distribui\u00e7\u00e3o de valores \u00e9 muito grande e arbitrar um valor vai distorcer muito os dados. Nesse caso, usaremos o valor m\u00e9dio da idade.","53a0a080":"## Os dados","ee2afba2":"### Gerando features polinomiais","cb9513a1":"Com a fun\u00e7\u00e3o abaixo vamos mescar as previs\u00f5es nos dados de teste dos modelos de cada um dos folds","aa328dcc":"#### Dividimos novamente os dados de traino e teste. Veja que em momento algum embaralhamos os dados. Isso \u00e9 essencial para poder dividir novamente.","e64ea97f":"Aqui est\u00e3o os c\u00f3digos que trabalhamos anteriormente para remover os nulos dos dados. \n\nAlterar e executar se quiser. Lembrar que os nossos resultados ser\u00e3o influenciados pelos tratamentos das *features*","19402736":"Agora salvamos o arquivo. Ap\u00f3s executar a c\u00e9lula abaixo, veja no sistema de arquivos que foi gerado e submeta-o ao kaggle quando achar conveniente.","11715bda":"Nesse laborat\u00f3rio vamos utilizar nossos conhecimentos em modelos de classifica\u00e7\u00e3o, ensemble e an\u00e1lise de dados para elaborar um bom modelo que preveja a sobreviv\u00eancia ou n\u00e3o de um passageiro do Titanic. \n\nPara quem n\u00e3o se lembra, o Titanic afundou em sua viagem inaugural em 1912, ap\u00f3s colidir com um iceberg. O acidente matou 1502 dos 2224 passsageiros. Os dados s\u00e3o divididos entre treino (`train.csv`) e teste (`test.csv`), mas n\u00e3o temos os dados dos 2224 passageiros e sim de 1309 no total.\n\nAo final vamos submeter nossas previs\u00f5es para a competi\u00e7\u00e3o de treinamento do Kaggle: https:\/\/www.kaggle.com\/c\/titanic\n\n**N\u00e3o desperdi\u00e7e envios. Voc\u00ea tem apenas 10 envios de respostas por dia.**\n","5048901c":"Os arquivos possuem as seguintes informa\u00e7\u00f5es de cada passageiro:","a151723c":"Primeiro passo vamos escolher as colunas que vamos remover (n\u00e3o usaremos). Basta alterar a lista. `df_todos.columns` lista as colunas caso precise.","0ac7a463":"Aqui voc\u00ea define a sua estrat\u00e9gia de valida\u00e7\u00e3o (K-fold cross validation \u00e9 prefer\u00edvel e o exemplo est\u00e1 abaixo)","33cb0c38":"**Agora vamos usar uma regress\u00e3o log\u00edstica para gerar um modelo e na sequ\u00eancia gerar o arquivo que vai ser submetido.:**","eba28b5b":"## Gerando nossos dados de treino, valida\u00e7\u00e3o e teste","4fd8d4f2":"### Usando algoritmo de \u00e1rvore de decis\u00e3o simples","092d53df":"Aqui criamos o dataframe que usaremos para salvar um csv","062f9939":"*Notar que esse \u00e9 o dado original do Kaggle, sem a inser\u00e7\u00e3o de outliers que fizemos como exerc\u00edcio no come\u00e7o do curso.*","8f06b0db":"### Convertendo categorias em n\u00fameros","51924388":"### Tratando os nulos das colunas Embarked e Age","f8cac0d9":"Aqui vamos guardar quantos s\u00e3o os dados de treino e teste e juntar os *dataframes*, para que possamos dar tratamento uniformizado \u00e0s *features*. Depois dividimos novamente os conjuntos usando os \u00edndices.","9d0a1f37":"<pre>\nsurvival        Sobreviveu ao acidente?\n                (0 = N\u00e3o; 1 = Sim)\npclass          Classe do passageiro\n                (1 = primeira classe; 2 = segunda classe; 3 = terceira classe)\nname            Nome\nsex             G\u00eanero\nage             Idade\nsibsp           Soma do n\u00famero irm\u00e3os + cunhados + c\u00f4njuge\nparch           Soma do n\u00famero pais + filhos\nticket          N\u00famero da passagem\nfare            Valor da passagem\ncabin           N\u00famero da cabine\nembarked        Porto de embarque\n                (C = Cherbourg; Q = Queenstown; S = Southampton)\n<\/pre>","35451dc9":"Se ao contr\u00e1rio de querer usar OHE em uma coluna voc\u00ea quiser usar o dado categ\u00f3rico, para algum modelo baseado em \u00e1rvore de decis\u00e3o (DecisionTreeClassifier, RandomForest, etc.), voc\u00ea pode usar o c\u00f3digo abaixo, pois mesmo sendo categ\u00f3rico, o dado tem de ser num\u00e9rico e n\u00e3o string."}}