{"cell_type":{"103e65ab":"code","d4e4faaa":"code","cbde263e":"code","4d1a36cf":"code","218d0a3b":"code","229df455":"code","429e8dfe":"code","645f98f4":"code","a7518584":"code","c7333044":"code","6ff68484":"code","50598027":"code","85d89381":"code","656853e5":"code","0e385a47":"code","2c9c4623":"code","77e6cc80":"code","a325b200":"code","8d47c081":"code","a1746fcf":"code","df95a630":"code","42f36e68":"code","47d92b6a":"code","d737a6a8":"code","0421d42e":"code","0521e3c0":"code","0aa22c1a":"code","9b569a26":"code","a8e15564":"code","edd00e73":"code","8e8c88af":"markdown","9057eb34":"markdown"},"source":{"103e65ab":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport cv2\nimport math\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport warnings\nwarnings.filterwarnings('ignore')\n#%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter('ignore')\nsns.set(rc={'figure.figsize' : (22, 10)})\nsns.set_style(\"darkgrid\", {'axes.grid' : True})\n\n# Any results you write to the current directory are saved as output.","d4e4faaa":"from subprocess import check_output\nforms = pd.read_csv('..\/input\/forms_for_parsing.txt', header=None, names=['info'])\nforms.head(5)","cbde263e":"d = {}\nwith open('..\/input\/forms_for_parsing.txt') as f:\n    for line in f:\n        key = line.split(' ')[0]\n        \n        writer = line.split(' ')[1]\n        d[key] = writer\nprint(len(d.keys()))","4d1a36cf":"def showImg(img, cmap=None):\n    plt.imshow(img, cmap=cmap, interpolation = 'bicubic')\n    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n    plt.show()","218d0a3b":"def prepareImg(img, height):\n    \"convert given image to grayscale image (if needed) and resize to desired height\"\n    assert img.ndim in (2, 3)\n    if img.ndim == 3:\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    h = img.shape[0]\n    factor = height \/ h\n    return cv2.resize(img, dsize=None, fx=factor, fy=factor)","229df455":"# Load an color image in grayscale\nimg1 = cv2.imread('..\/input\/data_subset\/data_subset\/a01-000u-s00-00.png', cv2.IMREAD_GRAYSCALE)\nprint(img1.ndim)\nprint(img1.shape)\n\nshowImg(img1, cmap='gray')\n","429e8dfe":"# read image, prepare it by resizing it to fixed height and converting it to grayscale\nimg2 = prepareImg(cv2.imread('..\/input\/data_subset\/data_subset\/a01-000u-s00-00.png'), 50)\nshowImg(img2, cmap='gray')","645f98f4":"img2.shape","a7518584":"50\/img1.shape[0]","c7333044":"def createKernel(kernelSize, sigma, theta):\n    \"create anisotropic filter kernel according to given parameters\"\n    assert kernelSize % 2 # must be odd size\n    halfSize = kernelSize \/\/ 2\n\n    kernel = np.zeros([kernelSize, kernelSize])\n    sigmaX = sigma\n    sigmaY = sigma * theta\n\n    for i in range(kernelSize):\n        for j in range(kernelSize):\n            x = i - halfSize\n            y = j - halfSize\n\n            expTerm = np.exp(-x**2 \/ (2 * sigmaX) - y**2 \/ (2 * sigmaY))\n            xTerm = (x**2 - sigmaX**2) \/ (2 * math.pi * sigmaX**5 * sigmaY)\n            yTerm = (y**2 - sigmaY**2) \/ (2 * math.pi * sigmaY**5 * sigmaX)\n\n            kernel[i, j] = (xTerm + yTerm) * expTerm\n\n    kernel = kernel \/ np.sum(kernel)\n    return kernel","6ff68484":"createKernel(3, 0.8, 3.5)","50598027":"kernelSize=25\nsigma=11\ntheta=7\nminArea=100","85d89381":"# apply filter kernel\nkernel = createKernel(kernelSize, sigma, theta)\n# The function applies an arbitrary linear filter to an image.\n# int ddepth (=-1) - desired depth of the destination image\n# anchor - indicates the relative position of a filtered point within the kernel; \n# default value (-1,-1) means that the anchor is at the kernel center.\n# borderType - pixel extrapolation method:  \n# cv2.BORDER_REPLICATE -  The row or column at the very edge of the original is replicated to the extra border.\nimgFiltered = cv2.filter2D(img1, -1, kernel, borderType=cv2.BORDER_REPLICATE).astype(np.uint8)","656853e5":"blur = cv2.GaussianBlur(img1,(5,5),0)\nshowImg(blur, cmap='gray')","0e385a47":"imgFiltered1 = cv2.filter2D(img1, -1, createKernel(kernelSize, sigma, theta), borderType=cv2.BORDER_REPLICATE)\nshowImg(imgFiltered1, cmap='gray')\n#25, 0.8, 3.5","2c9c4623":"# threshold - If pixel value is greater than a threshold value, it is assigned one value, else it is assigned another value \n# img - source image, which should be a grayscale image. \n# Second argument is the threshold value which is used to classify the pixel values. \n# Third argument is the maxVal which represents the value to be given if pixel value is more than the threshold value. \n# Last - different styles of thresholding\n# Returns: threshold value computed, destination image\n(_, imgThres) = cv2.threshold(imgFiltered1, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n\nimgThres = 255 - imgThres\nshowImg(imgThres, cmap='gray')","77e6cc80":"# find connected components. OpenCV: return type differs between OpenCV2 and 3\n# findContours - The function retrieves contours from the binary image\n# First argument is source image, second is contour retrieval mode, third is contour approximation method.\nif cv2.__version__.startswith('3.'):\n    (_, components, _) = cv2.findContours(imgThres, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\nelse:\n    # cv2.RETR_EXTERNAL or cv2.RETR_LIST - ???\n    (components, _) = cv2.findContours(imgThres, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)","a325b200":"cv2.__version__","8d47c081":"(components, _) = cv2.findContours(imgThres, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)","a1746fcf":"len(components)","df95a630":"showImg(cv2.drawContours(img1, components, -1, (0,0,255), 5))","42f36e68":"# append components to result\nres = []\nfor c in components:\n    # skip small word candidates\n    if cv2.contourArea(c) < minArea:\n        continue\n    # append bounding box and image of word to result list\n    currBox = cv2.boundingRect(c) # returns (x, y, w, h)\n    (x, y, w, h) = currBox\n    currImg = img1[y:y+h, x:x+w]\n    res.append((currBox, currImg))","47d92b6a":"len(res)","d737a6a8":"res[5][1]","0421d42e":"img1.shape","0521e3c0":"sns.set(rc={'figure.figsize' : (6, 3)})\n(x1, y1, w1, h1) = res[5][0]\nshowImg(img1[y1:y1+h1, x1:x1+w1], cmap='gray')","0aa22c1a":"showImg(res[5][1], cmap='gray')","9b569a26":"def display_contours(contours):\n    plt.figure(figsize=(30, 30))\n    for i, c in enumerate(contours):\n        contour = c[1]\n        plt.subplot(8, 4, i+1)  # A grid of 8 rows x 8 columns\n        plt.axis('off')\n        plt.title(\"Contour #{0}, size: {1}\".format(i, c[0]))\n        _ = plt.imshow(contour, cmap='gray')\n    plt.show()\n        ","a8e15564":"display_contours(res)","edd00e73":"sorted_res = sorted(res, key=lambda entry:entry[0][0])\ndisplay_contours(sorted_res)","8e8c88af":" ## IAM Database Line Information\n\n ### Format:         \n a01-000u-00 ok 154 19 408 746 1663 91 A|MOVE|to|stop|Mr.|Gaitskell|from\n* **a01-000u-00**  -> line id for form a01-000u\n* **ok**              -> result of word segmentation\n                            ok: line is correctly segmented\n                            err: segmentation of line has one or more errors\n                        notice: if the line could not be properly segmented\n                                the transcription and extraction of the whole\n                                line should not be affected negatively\n* **154**             -> graylevel to binarize line\n* **19**              -> number of components for this line\n* **408 746 1663 91** -> bounding box around this line in x,y,w,h format\n* ** A|MOVE|to|stop|Mr.|Gaitskell|from** -> transcription for this line. word tokens are separated by the character |","9057eb34":"Scale space technique for word segmentation proposed by R. Manmatha: http:\/\/ciir.cs.umass.edu\/pubfiles\/mm-27.pdf          \n* **Args**:           \n\t\timg: grayscale uint8 image of the text-line to be segmented.\n\t\tkernelSize: size of filter kernel, must be an odd integer.\n\t\tsigma: standard deviation of Gaussian function used for filter kernel.\n\t\ttheta: approximated width\/height ratio of words, filter function is distorted by this factor.\n\t\tminArea: ignore word candidates smaller than specified area.\t\n* **Returns**:            \n\t\tList of tuples. Each tuple contains the bounding box and the image of the segmented word."}}