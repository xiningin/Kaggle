{"cell_type":{"bbf14ef7":"code","3aa420ad":"code","a46baffa":"code","7ee2f5cb":"code","043c962b":"code","b0fd3cb5":"code","6a41c450":"code","2c4c9685":"code","f2b23fac":"code","c1706796":"code","717057e5":"code","74dda909":"code","39dc9b21":"code","835c0838":"code","81c0cca6":"code","6e4adf77":"code","a5f955c6":"code","1cf484c5":"code","78c9ae67":"code","c640fb1b":"code","73376770":"code","2c5f1993":"code","45673e9d":"code","54c7ab59":"code","8c0763ac":"code","fb14fb3f":"code","6c5c2a18":"code","812febae":"code","68b165a8":"code","13a4af1b":"code","4ae7f144":"code","78b90dea":"code","bfbb5f6a":"code","7ee7da45":"code","37feeb6c":"code","83a4e31b":"markdown","7fb355d8":"markdown","f7c2749a":"markdown","9d6a322c":"markdown","5db0d721":"markdown","f3075667":"markdown","0c432ca6":"markdown","61436185":"markdown","98722c08":"markdown","56aecc08":"markdown","4ed33204":"markdown","b195c2e0":"markdown","c432f86b":"markdown","3c415a88":"markdown","8ef41a6a":"markdown","0d5e025f":"markdown","7adb9f48":"markdown","7d222eda":"markdown","aed37fd8":"markdown","ca4703c0":"markdown","eb60f377":"markdown","190f83e9":"markdown","2297e785":"markdown","b36e7cdc":"markdown","817bb570":"markdown"},"source":{"bbf14ef7":"import os\nimport pickle\nfrom pathlib import Path\nimport gc\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\nimport pydicom\nfrom pydicom.tag import Tag\nimport gc\n\npd.options.display.max_rows=200\n","3aa420ad":"INPUT = Path(\"..\/input\/osic-pulmonary-fibrosis-progression\/\")\ntrain = pd.read_csv(INPUT \/ 'train.csv')\ndataset_dir = Path(\"..\/input\/osic-image-eda\/\")","a46baffa":"ls ..\/input\/osic-image-eda\/ ","7ee2f5cb":"def get_n_dicom_df(train):\n    df_list = []\n    for patient_id in train['Patient'].unique():\n        patient_dir = INPUT \/ 'train' \/ patient_id\n        path_list = list(patient_dir.glob(\"*\"))\n        n_dicom = len(path_list)\n        n_list = [int(str(i).split('\/')[-1].split('.')[0]) for i in path_list]\n        sort_n_list = sorted(n_list)\n        tmp_df = pd.DataFrame({'Patient': [patient_id],\n                               'n_dicom': [n_dicom],\n                               'n_list': [sort_n_list]})\n        df_list.append(tmp_df)\n        \n    n_dicom_df = pd.concat(df_list, sort=False)\n    return n_dicom_df.reset_index(drop=True)","043c962b":"n_dicom_df = get_n_dicom_df(train)\nn_dicom_df.to_csv('n_dicom_df.csv', index=False)\nn_dicom_df.head(15)","b0fd3cb5":"plt.hist(n_dicom_df['n_dicom'], bins=20)\nplt.title('Number of dicom per patient');","6a41c450":"n_dicom_df['n_dicom'].value_counts().head(10)","2c4c9685":"shape_df_path = dataset_dir \/ \"shape_df.csv\"\nif shape_df_path.is_file():\n    shape_df = pd.read_csv(shape_df_path)\nelse:\n    !conda install -c conda-forge gdcm -y\n    gr = train.groupby('Patient')\n    df_list = []\n    for patient_id, group_df in tqdm(gr):\n        height_list = []\n        width_list = []\n        shape_list = []\n        tmp_df_list = []\n        for dcm_path in (INPUT \/ 'train' \/ patient_id).glob(\"*\"):\n            try:\n                dicom = pydicom.dcmread(dcm_path)\n                tmp_df = pd.DataFrame({'Patient': [patient_id],\n                                       'height': [dicom[Tag(\"Rows\")].value],\n                                       'width': [dicom[Tag(\"Columns\")].value],\n                                       'shape': [str(dicom.pixel_array.shape)]})\n                tmp_df_list.append(tmp_df)\n            except:\n                print(dcm_path)\n        if len(tmp_df_list) >= 1:\n            df = pd.concat(tmp_df_list)\n            df.drop_duplicates(inplace=True)\n            df_list.append(df.reset_index(drop=True))\n    shape_df = pd.concat(df_list)","f2b23fac":"shape_df.to_csv('shape_df.csv', index=False)\nshape_df","c1706796":"shape_df.groupby('Patient').count().max()","717057e5":"shape_list = shape_df['shape'].value_counts().index\nshape_df['shape'].value_counts()","74dda909":"import matplotlib.pyplot as plt\n\ndef imshow_dcm(height, width):\n    _shape_df = shape_df[shape_df['shape'] == str((height, width))]\n    dcm_list = []\n    path_list = []\n    for i in range(4):\n        patient_id = np.random.choice(_shape_df['Patient'])\n        dcm_dir = INPUT \/ f'train\/{patient_id}'\n        dcm_path = np.random.choice(list(dcm_dir.glob(\"*\")))\n        path_list.append(str(dcm_path).split('\/')[-2:])\n        dicom = pydicom.dcmread(dcm_path)\n        dcm_list.append(dicom)\n    for i in range(4):\n        plt.subplot(2, 2, i+1)\n        plt.imshow(dcm_list[i].pixel_array, cmap=plt.cm.bone)\n        plt.title(path_list[i])\n        ","39dc9b21":"plt.figure(figsize=(16, 16))\nimshow_dcm(512, 512)","835c0838":"plt.figure(figsize=(16, 16))\nimshow_dcm(768, 768)\n","81c0cca6":"plt.figure(figsize=(16, 16))\nimshow_dcm(752, 888)\n","6e4adf77":"plt.figure(figsize=(16, 16))\nimshow_dcm(632, 632)","a5f955c6":"plt.figure(figsize=(16, 16))\nimshow_dcm(734, 888)","1cf484c5":"plt.figure(figsize=(16, 16))\nimshow_dcm(843, 888)","78c9ae67":"plt.figure(figsize=(16, 16))\nimshow_dcm(733, 888)","c640fb1b":"plt.figure(figsize=(16, 16))\nimshow_dcm(1100, 888)","73376770":"plt.figure(figsize=(16, 16))\nimshow_dcm(1302, 1302)","2c5f1993":"plt.figure(figsize=(16, 16))\nimshow_dcm(788, 888)","45673e9d":"dcm_path = Path(\"..\/input\/osic-pulmonary-fibrosis-progression\/train\/ID00094637202205333947361\/8.dcm\")\ndicom = pydicom.dcmread(dcm_path)\nimg = dicom.pixel_array\nplt.imshow(img, cmap=plt.cm.bone)\nplt.title(f\"shape: {img.shape}\");","54c7ab59":"# Areas with the same number of pixels on the edges are not required. Crop it.\n\ndef crop_image(img: np.ndarray):\n    edge_pixel_value = img[0, 0]\n    mask = img != edge_pixel_value\n    return img[np.ix_(mask.any(1),mask.any(0))]\n\nplt.figure(figsize=(16, 8))\nplt.subplot(121)\nplt.imshow(img, cmap=plt.cm.bone)\nplt.title(img.shape)\n\nplt.subplot(122)\nplt.imshow(crop_image(img), cmap=plt.cm.bone)\nplt.title(crop_image(img).shape);","8c0763ac":"shape_df = shape_df.merge(n_dicom_df, on='Patient', how='left')\ncrop_df = shape_df[shape_df[\"shape\"].isin([\"(752, 888)\" , \"(734, 888)\" , \"(843, 888)\", \"(733, 888)\" , \"(1100, 888)\", \"(788, 888)\"])]\ncrop_df","fb14fb3f":"# Display the 1.dicom of each Patient.\n\ndef get_image_array_from_dicom(patient_id, n):\n    dcm_file_path = INPUT \/ f'train\/{patient_id}\/{n}.dcm'\n    dicom = pydicom.dcmread(dcm_file_path)\n    return dicom.pixel_array\n\nfor patient_id in crop_df['Patient']:\n    n = 1\n    image = get_image_array_from_dicom(patient_id, n)\n    plt.figure(figsize=(16, 8))\n    plt.subplot(121)\n    plt.imshow(image, cmap=plt.cm.bone)\n    plt.title(image.shape)\n    \n    plt.subplot(122)\n    if image.shape[0] != image.shape[1]:\n        image = crop_image(image)\n    plt.imshow(image, cmap=plt.cm.bone)\n    plt.title(image.shape)    \n    plt.show()","6c5c2a18":"shape_df.head()","812febae":"def get_image_position_diff(patient_id, n_list):\n    dicom_path_list = [INPUT \/ 'train' \/ patient_id \/ f'{n}.dcm' for n in n_list]\n    dicoms = [pydicom.read_file(path_) for path_ in dicom_path_list]\n    diff_list_ = []\n    for i in range(len(dicoms)-1):\n        try:\n            diff = np.abs(dicoms[i].ImagePositionPatient[2] - dicoms[i + 1].ImagePositionPatient[2])\n        except AttributeError:\n            diff = np.nan\n        diff_list_.append(diff)\n    return diff_list_\n\ndef get_slicethickness_slope_intercept(patient_id, n_list):\n    dicom_path_list = [INPUT \/ 'train' \/ patient_id \/ f'{n}.dcm' for n in n_list]\n    dicoms = [pydicom.read_file(path_) for path_ in dicom_path_list]\n    thickness_list_ = []\n    pixelspacing_list_ = []\n    slope_list_ = []\n    intercept_list_ = []\n    for i in range(len(dicoms)):\n        try:\n            slice_thickness_ = dicoms[i].SliceThickness\n        except AttributeError:\n            slice_thickness_ = np.nan\n        try:\n            pixelspacing_ = dicoms[i].PixelSpacing\n        except AttributeError:\n            pixelspacing_ = np.nan\n        try:\n            slope_ = dicoms[i].RescaleSlope\n        except AttributeError:\n            slope_ = np.nan\n        try:\n            intercept_ = dicoms[i].RescaleIntercept\n        except AttributeError:\n            intercept_ = np.nan\n\n        thickness_list_.append(slice_thickness_)\n        pixelspacing_list_.append(pixelspacing_)\n        slope_list_.append(slope_)\n        intercept_list_.append(intercept_)\n        \n    return thickness_list_, pixelspacing_list_, slope_list_, intercept_list_","68b165a8":"!conda install -c conda-forge gdcm -y","13a4af1b":"diff_list = []\nfor i in tqdm(range(len(shape_df))):\n    diff_list.append(get_image_position_diff(shape_df.loc[i, 'Patient'], shape_df.loc[i, 'n_list']))\n\nthickness_list = []\npixelspacing_list = []\nslope_list = []\nintercept_list = []\nfor i in tqdm(range(len(shape_df))):\n    t, p, s, i = get_slicethickness_slope_intercept(shape_df.loc[i, 'Patient'], shape_df.loc[i, 'n_list'])\n    thickness_list.append(t)\n    pixelspacing_list.append(p)\n    slope_list.append(s)\n    intercept_list.append(i)\n","4ae7f144":"shape_df['diff_list'] = diff_list\nshape_df['thickness_list'] = thickness_list\nshape_df['pixelspacing_list'] = pixelspacing_list\nshape_df['slope_list'] = slope_list\nshape_df['intercept_list'] = intercept_list","78b90dea":"shape_df['diff_list_std'] = shape_df['diff_list'].apply(lambda x: np.array(x).std())\nshape_df['diff_list_n_nan'] = shape_df['diff_list'].apply(lambda x: np.sum(pd.Series(x).isna()))\n\nshape_df[['Patient', 'diff_list', 'diff_list_std', 'diff_list_n_nan', 'thickness_list', 'pixelspacing_list']]","bfbb5f6a":"shape_df[['Patient', 'slope_list', 'intercept_list']]","7ee7da45":"np.all(shape_df['slope_list'].apply(lambda x:np.all(x)))","37feeb6c":"with open('shape_df_ver2.pickle', 'wb') as f:\n    pickle.dump(shape_df, f)","83a4e31b":"## (843, 888)","7fb355d8":"This notebook aggregates the shape of the image and checks the actual image.  \nThis shows that the margins at the edges of the image are not consistent and need to be considered for pre-processing.\n\nupdate:  \nver4: Data that takes a long time to create has been changed to be read from kaggle [Datasets](https:\/\/www.kaggle.com\/currypurin\/osic-image-eda).  \nver7: added crop preprocessing","f7c2749a":"## (768, 768)","9d6a322c":"## (734, 888)","5db0d721":"# Crop","f3075667":"The number of dicoms is different for each patient. Also, the file may not start with one.","0c432ca6":"# Todo\n\n* Create a feature from a dicom image.","61436185":"shapes with different height and width  \n(752, 888) , (734, 888) , (843, 888) , (733, 888) , (1100, 888) ,(788, 888)  ","98722c08":"## diff","56aecc08":"This process is based on codes from this great notebook https:\/\/www.kaggle.com\/ratthachat\/aptos-eye-preprocessing-in-diabetic-retinopathy.  \nLet's crop the other shapes","4ed33204":"## (788, 888)","b195c2e0":"The ones with different height and width seem to have margins and need to be cropped. Let's try cropping them.","c432f86b":"First, check the thickness between the images.","3c415a88":"## (733, 888)","8ef41a6a":"# preprocess","0d5e025f":"## (1100, 888)","7adb9f48":"## (752, 888)","7d222eda":"## slope and intercept","aed37fd8":"# img","ca4703c0":"## (632, 632)","eb60f377":"## 512 x 512","190f83e9":"# name and number of dicoms","2297e785":"# References:\n\n1. https:\/\/www.kaggle.com\/ratthachat\/aptos-eye-preprocessing-in-diabetic-retinopathy\n2. https:\/\/www.kaggle.com\/jameschapman19\/pytorch-tabular-qr-histogram","b36e7cdc":"# image shape","817bb570":"## (1302, 1302)"}}