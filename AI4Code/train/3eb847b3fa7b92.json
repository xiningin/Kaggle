{"cell_type":{"eadfdcca":"code","f2110d55":"code","10bada9a":"code","98113dd2":"code","2a572bff":"code","5a35001c":"code","422e87f3":"code","fccaa7e8":"code","28cf21f2":"code","8f476718":"code","48cfc7ae":"code","f2118883":"code","2104d3b4":"code","bf77f924":"code","cc9ffcdb":"code","ed32805b":"code","542e5fa4":"code","9205ca96":"code","5803e686":"code","0001b6fd":"code","3a227299":"code","2c45cd9e":"code","6c2baad6":"code","e9567a87":"code","43d9cf01":"code","8d774389":"code","809486c6":"code","69a81836":"code","cc01af1f":"code","71cc32b2":"code","58498806":"code","98096f9e":"code","4b00d258":"markdown","43c92127":"markdown","8cc83c46":"markdown","d531b651":"markdown","d746634b":"markdown","1c255114":"markdown","0e5f0f71":"markdown","c232df6e":"markdown","8689c762":"markdown","8b044a6d":"markdown","eb736716":"markdown","e0aa34a0":"markdown","f18b272f":"markdown","8ff1f023":"markdown","e0c62781":"markdown","c6665151":"markdown","6b5b20c3":"markdown","66be10d2":"markdown","24f7d400":"markdown","98a8fe93":"markdown","ed6a3420":"markdown","e7724675":"markdown","bd51abd9":"markdown","b2b12273":"markdown","4e87560e":"markdown","b22b4a32":"markdown","7b416d55":"markdown","d5194e9a":"markdown","69f81b9d":"markdown","f375c34f":"markdown","bfb1690e":"markdown","96cd06b4":"markdown","30e0ffa7":"markdown","255b8a91":"markdown","4f37e81f":"markdown","47649883":"markdown","c60a4895":"markdown","82709b0d":"markdown","0fa7103f":"markdown","1a3dd6cf":"markdown","5d9041f9":"markdown","28094d05":"markdown","5509d689":"markdown","ff9b90b5":"markdown","a4bea0f8":"markdown","08caf909":"markdown","dbac7b25":"markdown","2c4362dd":"markdown","1c681900":"markdown","5a9b1f0e":"markdown","b706364f":"markdown","4b8c1e86":"markdown","104c5846":"markdown","558a2f7f":"markdown","3285a313":"markdown","5b797bf1":"markdown","2f33a061":"markdown","fa620665":"markdown","d3e06b90":"markdown","c012f4d7":"markdown","ff39b4fe":"markdown"},"source":{"eadfdcca":"import io\nimport os\nimport re\nimport shutil\nimport string\nimport tensorflow as tf","f2110d55":"url = \"https:\/\/ai.stanford.edu\/~amaas\/data\/sentiment\/aclImdb_v1.tar.gz\"","10bada9a":"ds = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", \n                             url,untar=True, \n                             cache_dir='.',\n                             cache_subdir='')","98113dd2":"data_dir = os.path.join(os.path.dirname(ds), 'aclImdb')","2a572bff":"train_dir = os.path.join(data_dir, 'train')\nos.listdir(train_dir)","5a35001c":"unused_dir = os.path.join(train_dir, 'unsup')\nshutil.rmtree(unused_dir)","422e87f3":"os.listdir(train_dir)","fccaa7e8":"ls aclImdb\\train","28cf21f2":"batch_size = 1024\nseed = 123","8f476718":"train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n    'aclImdb\/train', \n    batch_size=batch_size, \n    validation_split=0.2,\n    subset='training', \n    seed=seed)","48cfc7ae":"val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n    'aclImdb\/train', \n    batch_size=batch_size, \n    validation_split=0.2,\n    subset='validation', \n    seed=seed)","f2118883":"import random\nidx = random.sample(range(1, batch_size), 5)\nfor text_batch, label_batch in train_ds.take(1):\n    for i in idx:\n        print(label_batch[i].numpy(), text_batch.numpy()[i])","2104d3b4":"import tensorflow as tf\nimport tensorflow_hub as hub\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","bf77f924":"traindf=pd.read_csv('flower_photos\/all_labels.csv',dtype=str)\ntraindf.head()","cc9ffcdb":"data_root = 'flower_photos\/flowers'\nIMAGE_SIZE = (224, 224)\nTRAINING_DATA_DIR = str(data_root)\nBATCH_SIZE = 32","ed32805b":"datagen_kwargs = dict(\n    rescale=1.\/255, \n    validation_split=.20)","542e5fa4":"dataflow_kwargs = dict(\n    target_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,\n    interpolation=\"bilinear\")","9205ca96":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    **datagen_kwargs)","5803e686":"train_generator=train_datagen.flow_from_dataframe(\n    dataframe=traindf,\n    directory=data_root,\n    x_col=\"file_name\",\n    y_col=\"label\",\n    subset=\"training\",\n    seed=10,\n    shuffle=True,\n    class_mode=\"categorical\",\n    **dataflow_kwargs)","0001b6fd":"image_batch, label_batch = next(iter(train_generator))\nfig, axes = plt.subplots(8, 4, figsize=(20, 40))\naxes = axes.flatten()\nfor img, lbl, ax in zip(image_batch, label_batch, axes):\n    ax.imshow(img)\n    label_ = np.argmax(lbl)\n    label = idx_labels[label_]\n    ax.set_title(label)\n    ax.axis('off')\nplt.show()","3a227299":"mdl = tf.keras.Sequential([\n    tf.keras.layers.InputLayer( input_shape=IMAGE_SIZE + (3,)), \n    hub.KerasLayer( \"https:\/\/tfhub.dev\/tensorflow\/resnet_50\/feature_vector\/1\", \n                   trainable=False),\n    tf.keras.layers.Dense(5, \n                          activation='softmax', \n                          name = 'custom_class')])\nmdl.build([None, 224, 224, 3])","2c45cd9e":"mdl.compile(\n  optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9),\n  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n  metrics=['accuracy'])","6c2baad6":"steps_per_epoch = train_generator.samples \/\/ train_generator.batch_size\nvalidation_steps = valid_generator.samples \/\/ valid_generator.batch_size\n\nmdl.fit(\n    train_generator,\n    epochs=13, steps_per_epoch=steps_per_epoch,\n    validation_data=valid_generator,\n    validation_steps=validation_steps)","e9567a87":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt","43d9cf01":"fashion_mnist = tf.keras.datasets.fashion_mnist\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()","8d774389":"print(type(train_images), type(train_labels))","809486c6":"print(train_images.shape, train_labels.shape)","69a81836":"plt.figure()\nplt.imshow(train_images[5])\nplt.colorbar()\nplt.grid(False)\nplt.show()","cc01af1f":"train_images = train_images\/255","71cc32b2":"train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))","58498806":"SHUFFLE_BUFFER_SIZE = 10000\nTRAIN_BATCH_SIZE = 50\nVALIDATION_BATCH_SIZE = 10000\n\n# To shuffle train dataset\nvalidation_ds = train_dataset.shuffle(\n    SHUFFLE_BUFFER_SIZE).take(\n    VALIDATION_SAMPLE_SIZE).batch(VALIDATION_BATCH_SIZE)\ntrain_ds = train_dataset.skip(\n    VALIDATION_BATCH_SIZE).batch(\n    TRAIN_BATCH_SIZE).repeat()","98096f9e":"model = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(30, activation='relu'),\n    tf.keras.layers.Dense(10)\n    \n# Compiling the model\nmodel.compile(optimizer=tf.keras.optimizers.RMSprop(),\n  loss=tf.keras.losses.SparseCategoricalCrossentropy(\n  from_logits=True),\n  metrics=['sparse_categorical_accuracy'])\n    \n#Trainging the model\nmodel.fit(\n    train_ds,\n    epochs=13, steps_per_epoch=steps_per_epoch,\n    validation_data=validation_ds,\n    validation_steps=validation_steps)","4b00d258":"### Downloading Images ","43c92127":"So I created train datasets. To fine tune hyperparameter, I'll use validation dataset. Let's create validation dataset.","8cc83c46":"Let me show images in dataset.","d531b651":"Let's compile the model.","d746634b":"Let me import libraries, which will use in this section.","1c255114":"Let's load datasets using the load_data function in the tf.keras API.","0e5f0f71":"So data ingestion pipeline is ready to use. Let's train the model.","c232df6e":"### Building the Model","8689c762":"In this tutorial, I am going to show how to create a data pipeline using a NumPy array. To do this, I am going to use from_tensor_slices method. \n\nLet's use Fashion MNIST dataset, which consists of 10 types of garments in grayscale. The images are represented using a NumPy structure instead of a typical image format, such as JPEG or PNG. \n\nYou can easily download using tf.Keras API.","8b044a6d":"As you can see, the structures of datasets are NumPy arrays. Now that  am going to look at the shapes of datasets using shape command.","eb736716":"Let me take a look the structure of datasets.","e0aa34a0":"I am going to want to generates a tf.data.Dataset from text files in a directory. ","f18b272f":"To build the model, I am going to use the prebuilted ResNet model. The ResNet model expects images to have pixel dimensions of 224\\*224 and I need to determine the batch size and resample algorithm as well.","8ff1f023":"### Inspecting the Dataset","e0c62781":"### Inspecting the Dataset","c6665151":"Let's take a look inside of directory.","6b5b20c3":"## Resources","66be10d2":"I am going to train the model. ","24f7d400":"In this section, I am gonig to show how to deal with data ingestion pipeline for image data. \n\nSometimes, you have images in the same file. This file includes two columns : one with all the filenames and one with the labels. ","98a8fe93":"Let me create a data flow pipeline.","ed6a3420":"## The Data Pipeline for Image\u00a0Datasets","e7724675":"### Preprocessing the Datasets","bd51abd9":"### Downloading Text Data","b2b12273":"### Loading the Dataset","4e87560e":"In this tutorial, I showed how to use the data ingestion pipeline. ","b22b4a32":"I am going to normalize dataset and reserve 20% of the images for validation dataset. Let me use a dictionary structure.","7b416d55":"- [KC Tung, 2021, TensorFlow 2 Pocket Reference](https:\/\/www.amazon.com\/TensorFlow-Pocket-Reference-Building-Deploying\/dp\/1492089184)\n- [TensorFlow Tutorial](https:\/\/www.tensorflow.org\/tutorials)","d5194e9a":"I am going to build a streaming pipeline using from_tensor_slices method. ","69f81b9d":"To visualize a NumPy array as a color scale, I am going to use matplotlib library. ","f375c34f":"That's it. So train_ds and validation_ds were passed into training process. In this section, I showed how to create a data pipeline using from_tensor_slices for dataset which consists of NumPy array.","bfb1690e":"The datasets is ready to build the model. To train the model, I am going to use Sequential model.","96cd06b4":"Now that I am goning to create some hyperparameters, which will be used later.","30e0ffa7":"# Data Pipelines with\u00a0TensorFlow","255b8a91":"### Creating the Data Pipeline","4f37e81f":"To train the images, I am going to define generator.","47649883":"I am going to inspect at the content of these files. Let's select randomly five rows in first batch and print out them.","c60a4895":"So dataset downloaded and a directory is created called aclImdb in the current directory. I am going to create a variable, which represent this file path.","82709b0d":"Note that dataset has a label file. I am going to see its contents using pandas library.","0fa7103f":"An important steps of your workflow is data ingestion. Before building the model, the data have to be the correct format. To do this, several steps called data pipeline perform. In this chapter, I am going to show how to handle file structure.","1a3dd6cf":"First of all, let me import libraries.","5d9041f9":"and then let me use get_file() method as follows : ","28094d05":"## Data Pipeline for NumPy Array\u00a0Datasets","5509d689":"Now that I am going to create pipeline. First, let me create a few variables:","ff9b90b5":"To analyze text data, you need to organize the directory structure correctly. For example, if you want to make text classification, you have to organize your training texts into positives and negatives. When you'll classify dataset as positive and negative your directory structure can be as follows:\npos\n    p1.txt\n    p2.txt\nneg \n    n1.txt\n    n2.txt\nLet's thing of the Internet Movie Database (IMDB) dataset and classify movie reviews as positive and negative.","a4bea0f8":"### Inspecting the NumPy Array","08caf909":"Now that, I am going to load IMDb dataset. If you want to download directly you can use get_file() method. To do this, let me create url variable. ","dbac7b25":"Don't forget to follow on Tirendaz Academy [YouTube-Tr](https:\/\/youtube.com\/c\/tirendazakademi), [YouTube-Eng](https:\/\/www.youtube.com\/channel\/UCFU9Go20p01kC64w-tmFORw), [Twitter](https:\/\/twitter.com\/TirendazAcademy), [Medium](https:\/\/tirendazacademy.medium.com), [GitHub](https:\/\/github.com\/TirendazAcademy) and [LinkedIn](https:\/\/www.linkedin.com\/in\/tirendaz-academy)","2c4362dd":"The images consist of pixel values between 0 and 255. To built faster the model and to get better accuracy, I am going to normalize the pixel values.","1c681900":"As you can see, unsup is removed from directory of data. Make sure you have only directory names are used as labels. \nLet me see the content in the training directory.","5a9b1f0e":"### Creating the Data Pipeline","b706364f":"## What is Data Pipeline?","4b8c1e86":"I am going to build a data pipeline to feed these images into an image classification model for training. Let me stream these images into the training process with ImageDataGenerator.","104c5846":"Let me take a look train_dir.","558a2f7f":"As you can see there are pos and neg directories.","3285a313":"### Preprocessing the Dataset","5b797bf1":"In this section, I showed how to deal with text datasets. ","2f33a061":"First of all, let me import libraries.","fa620665":"First, I am going to download [flower dataset](https:\/\/data.mendeley.com\/public-files\/datasets\/jxmfrvhpyz\/files\/283004ff-e529-4c3c-a1ee-4fb90024dc94\/file_downloaded).","d3e06b90":"Let me split this dataset into training and validation sets.The hyperparameters are fine tuned with the validation dataset and the model is built with train dataset. ","c012f4d7":"There is one directory called unsup. I don't need unsup directory. I want to remove this directory.","ff39b4fe":"That's it. As you can see, the training image generator and validation image generator are passed into training process. "}}