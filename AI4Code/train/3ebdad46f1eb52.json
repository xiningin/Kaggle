{"cell_type":{"04060701":"code","89e5ab20":"code","fe022f9a":"code","9c487b23":"code","8586e520":"code","d55066e6":"code","9be75f4c":"code","ea3e14bc":"code","aee3af26":"code","e9a53563":"code","f63c6b56":"code","04bb35be":"code","848215e5":"code","f7fdc976":"code","2c514e4f":"code","18fb4124":"code","d2cb8cd0":"code","e440ec1d":"code","c86179fc":"code","0fc89e18":"code","1fc09d5d":"code","80a3ef95":"code","747988fd":"code","218c9d65":"markdown","97f62a2d":"markdown","cae7b81e":"markdown","6e52c015":"markdown","319dc266":"markdown","fd35c0a4":"markdown","f1d22d4c":"markdown","77334b54":"markdown","95778813":"markdown","85650e7a":"markdown","d325dcd8":"markdown","7f6cb5ae":"markdown","b1929bb8":"markdown","db3dd002":"markdown","471ba4ca":"markdown","714c6133":"markdown"},"source":{"04060701":"import glob\nimport random as rn\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport plotly.express as px\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","89e5ab20":"path = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/'\n\n\n# define paths\ntrain_normal_dir = path + 'train\/NORMAL\/'\ntrain_pneu_dir = path + 'train\/PNEUMONIA\/'\n\ntest_normal_dir = path + 'test\/NORMAL\/'\ntest_pneu_dir = path + 'test\/PNEUMONIA\/'\n\nval_normal_dir = path + 'val\/NORMAL\/'\nval_pneu_dir = path + 'val\/PNEUMONIA\/'\n\n\n# find all files, our files has extension jpeg\ntrain_normal_cases = glob.glob(train_normal_dir + '*jpeg')\ntrain_pneu_cases = glob.glob(train_pneu_dir + '*jpeg')\n\ntest_normal_cases = glob.glob(test_normal_dir + '*jpeg')\ntest_pneu_cases = glob.glob(test_pneu_dir + '*jpeg')\n\nval_normal_cases = glob.glob(val_normal_dir + '*jpeg')\nval_pneu_cases = glob.glob(val_pneu_dir + '*jpeg')\n\n\n# make path using \/ instead of \\\\ ... this may be redudant step\ntrain_normal_cases = [x.replace('\\\\', '\/') for x in train_normal_cases]\ntrain_pneu_cases = [x.replace('\\\\', '\/') for x in train_pneu_cases]\ntest_normal_cases = [x.replace('\\\\', '\/') for x in test_normal_cases]\ntest_pneu_cases = [x.replace('\\\\', '\/') for x in test_pneu_cases]\nval_normal_cases = [x.replace('\\\\', '\/') for x in val_normal_cases]\nval_pneu_cases = [x.replace('\\\\', '\/') for x in val_pneu_cases]\n\n\n# create lists for train, test & validation cases, create labels as well\ntrain_list = []\ntest_list = []\nval_list = []\n\nfor x in train_normal_cases:\n    train_list.append([x, 0])\n    \nfor x in train_pneu_cases:\n    train_list.append([x, 1])\n    \nfor x in test_normal_cases:\n    test_list.append([x, 0])\n    \nfor x in test_pneu_cases:\n    test_list.append([x, 1])\n    \nfor x in val_normal_cases:\n    val_list.append([x, 0])\n    \nfor x in val_pneu_cases:\n    val_list.append([x, 1])\n\n\n# shuffle\/randomize data as they were loaded in order: normal cases, then pneumonia cases\nrn.shuffle(train_list)\nrn.shuffle(test_list)\nrn.shuffle(val_list)\n\n\n# create dataframes\ntrain_df = pd.DataFrame(train_list, columns=['image', 'label'])\ntest_df = pd.DataFrame(test_list, columns=['image', 'label'])\nval_df = pd.DataFrame(val_list, columns=['image', 'label'])","fe022f9a":"train_df.head()","9c487b23":"test_df.head()","8586e520":"val_df.head()","d55066e6":"fig = px.histogram(train_df, x=\"label\", color=\"label\", hover_data=train_df.columns)\nfig.show()","9be75f4c":"fig = px.histogram(test_df, x=\"label\", color=\"label\", hover_data=test_df.columns)\nfig.show()","ea3e14bc":"fig = px.histogram(val_df, x=\"label\", color=\"label\", hover_data=val_df.columns)\nfig.show()","aee3af26":"plt.figure(figsize=(20,8))\nfor i,img_path in enumerate(train_df[train_df['label'] == 1][0:4]['image']):\n    plt.subplot(2,4,i+1)\n    plt.axis('off')\n    img = plt.imread(img_path)\n    plt.imshow(img, cmap='gray')\n    plt.title('Pneumonia',fontsize=30)\n    \nfor i,img_path in enumerate(train_df[train_df['label'] == 0][0:4]['image']):\n    plt.subplot(2,4,4+i+1)\n    plt.axis('off')\n    img = plt.imread(img_path)\n    plt.imshow(img, cmap='gray')\n    plt.title('Healthy \/ Normal',fontsize=30)","e9a53563":"def process_data(img_path):\n    img = cv2.imread(img_path)\n    img = cv2.resize(img, (196, 196))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img = img\/255.0\n    img = np.reshape(img, (196,196,1))\n    \n    return img\n\ndef compose_dataset(df):\n    data = []\n    labels = []\n\n    for img_path, label in df.values:\n        data.append(process_data(img_path))\n        labels.append(label)\n        \n    return np.array(data), np.array(labels)","f63c6b56":"X_train, y_train = compose_dataset(train_df)\nX_test, y_test = compose_dataset(test_df)\nX_val, y_val = compose_dataset(val_df)\n\nprint('Train data shape: {}, Labels shape: {}'.format(X_train.shape, y_train.shape))\nprint('Test data shape: {}, Labels shape: {}'.format(X_test.shape, y_test.shape))\nprint('Validation data shape: {}, Labels shape: {}'.format(X_val.shape, y_val.shape))","04bb35be":"datagen = ImageDataGenerator(\n    rotation_range=10,\n    zoom_range = 0.1,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=False,\n    vertical_flip=False\n)\ndatagen.fit(X_train)","848215e5":"y_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\ny_val = to_categorical(y_val)","f7fdc976":"model = Sequential()\n\nmodel.add(Conv2D(filters=8, kernel_size=(7,7), padding='same', activation='relu', input_shape=(196, 196, 1)))\nmodel.add(Conv2D(filters=8, kernel_size=(7,7), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3,3)))\n\nmodel.add(Conv2D(filters=16, kernel_size=(5,5), padding='same', activation='relu'))\nmodel.add(Conv2D(filters=16, kernel_size=(5,5), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3,3)))\n\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(2, activation='softmax'))","2c514e4f":"optimizer = Adam(lr=0.0001, decay=1e-5)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])","18fb4124":"callback = EarlyStopping(monitor='loss', patience=6)\nhistory = model.fit(datagen.flow(X_train,y_train, batch_size=4), validation_data=(X_test, y_test), epochs = 100, verbose = 1, callbacks=[callback], class_weight={0:6.0, 1:0.5})","d2cb8cd0":"print(\"Test Accuracy: {0:.2f}%\".format(model.evaluate(X_test,y_test)[1]*100))","e440ec1d":"train_acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nplt.plot(train_acc,label = \"Training\")\nplt.plot(val_acc,label = 'Validation\/Test')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.show()","c86179fc":"train_loss = history.history['loss']\nval_loss = history.history['val_loss']\nplt.plot(train_loss,label = 'Training')\nplt.plot(val_loss,label = 'Validation\/Test')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.show()","0fc89e18":"Y_pred = model.predict(X_val)\nY_pred_classes = np.argmax(Y_pred,axis = 1) \nY_true = np.argmax(y_val,axis = 1) \nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","1fc09d5d":"Y_pred = model.predict(X_test)\nY_pred_classes = np.argmax(Y_pred,axis = 1) \nY_true = np.argmax(y_test,axis = 1) \nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \nf,ax = plt.subplots(figsize=(8, 8))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","80a3ef95":"y_val_hat = model.predict(X_val, batch_size=4)\ny_val_hat = np.argmax(y_val_hat, axis=1)\ny_val = np.argmax(y_val, axis=1)","747988fd":"plt.figure(figsize=(20,20))\nfor i,x in enumerate(X_val):\n    plt.subplot(4,4,i+1)\n    plt.imshow(x.reshape(196, 196), cmap='gray')\n    plt.axis('off')\n    plt.title('Predicted: {}, Real: {}'.format(y_val_hat[i], y_val[i]),fontsize=25)  ","218c9d65":"# **Learning Rate Scheduling and Compile the Model**","97f62a2d":"Now, our model is ready to perform on test set.","cae7b81e":"# **Data Augmentation**","6e52c015":"Confusion matrix of validation dataset.","319dc266":"Our model is performing good on training set as well as on validation set.","fd35c0a4":"# **Thank You**","f1d22d4c":"Lets see how our training, validation and test data looks like.","77334b54":"# **Plot Images with Labels**","95778813":"# **Predictions on Validation Set**","85650e7a":"Shape of training, validation and test datasets","d325dcd8":"# **Data Analysis**","7f6cb5ae":"# **Load and Preprocessing Data**","b1929bb8":"# **Creating the CNN Model**","db3dd002":"# **Import Libraries**","471ba4ca":"**If you liked it, please vote.**","714c6133":"Confusion matrix for test dataset."}}