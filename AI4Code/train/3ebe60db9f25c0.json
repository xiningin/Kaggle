{"cell_type":{"632a510a":"code","f2047a46":"code","e5be24d0":"code","c194b695":"code","f4c762bc":"code","6bb4b664":"code","67690c74":"markdown","7deed31d":"markdown","045184c8":"markdown","2e3815c8":"markdown","47d95898":"markdown","90dc47bc":"markdown","ab12276d":"markdown","851e3a57":"markdown","72132d71":"markdown","5b70b9c2":"markdown","acf2e586":"markdown","309fd843":"markdown","f28051d6":"markdown","cb6bbd9e":"markdown"},"source":{"632a510a":"\"Importing necessary packages\"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport gensim\nfrom gensim.models import LdaModel\nfrom gensim.corpora import Dictionary\nimport pyLDAvis.gensim\npyLDAvis.enable_notebook()\n\n#pd.set_option('display.expand_frame_repr', False)\n\nimport sklearn\nfrom sklearn.externals import joblib\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, make_scorer, accuracy_score\nfrom sklearn import preprocessing\nfrom mean_w2v import MeanEmbeddingVectorizer #custom function\n\nimport ipywidgets as widgets\nfrom ipywidgets import Button, Layout\nfrom IPython.display import display, HTML, clear_output\n\nfrom lime import lime_text\nfrom lime.lime_text import LimeTextExplainer\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\"Prep dataset for LDA topic modelling\"\ndfeng = pd.read_csv(\"..\/input\/rp-manglish-tweets-on-kl-rapid-transit\/\/Eng_traindata_processed.csv\")\ndfmal = pd.read_csv(\"..\/input\/rp-manglish-tweets-on-kl-rapid-transit\/\/Malay_traindata_processed.csv\")\ndfeng['textfin'] = dfeng['textfin'].astype('str')\ndfmal['textfin'] = dfmal['textfin'].astype('str')\ncorpus_mal = dfmal['textfin'].tolist()\ncorpus_eng = dfeng['textfin'].tolist()\ntrain_eng_texts = [doc.split(\" \") for doc in corpus_eng]\ntrain_mal_texts = [doc.split(\" \") for doc in corpus_mal]\ndfmal_txt = pd.DataFrame(dfmal[['text','textfin']]);df_comb = pd.DataFrame(dfeng[['text','textfin']])\ndf_comb = df_comb.append(dfmal_txt, ignore_index = True)\n\n\"pyldaviz function. pyldaviz provides interactive visualization of topic modelling results \"\ndef show_pyldavis(docs,passes,num_topics,no_below=0):  \n    bigram = gensim.models.Phrases(docs, min_count=5, threshold=100) # higher threshold fewer phrases.\n    bigram_mod = gensim.models.phrases.Phraser(bigram)\n    texts = [bigram_mod[doc] for doc in docs]  \n    dictionary = Dictionary(texts)\n    dictionary.filter_extremes(no_below=no_below)\n    dictionary.compactify()  \n    corpus = [dictionary.doc2bow(text) for text in texts]\n    ldamodel = gensim.models.LdaMulticore(corpus=corpus, num_topics=num_topics, \n                                        id2word=dictionary,\n                                        random_state=100,\n                                        chunksize=100,\n                                        passes=passes,\n                                        alpha=\"asymmetric\",\n                                        eta=0.91)\n    viz = pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)\n    return pyLDAvis.display(viz)","f2047a46":"df_comb.sample(10)","e5be24d0":"\"Load the trained SVM (tuned) classifier and word2vec vectorizer\"\nsenti_model_mal = joblib.load(\"..\/input\/sentiment-function\/svm_pipe_mal.joblib.dat\")\n\n\"load pre-processed event tweets data\"\ndf = pd.read_csv(\"..\/input\/senti-data\/senti_data.csv\")\nle = preprocessing.LabelEncoder()\ndf['sentiment_bin'] = le.fit_transform(df.sentiment.values)\ndf['textfin'] = df['textfin'].astype('str')\ndf_mal = df.loc[:,[\"text\",\"textfin\",\"sentiment\",\"sentiment_bin\"]]\ndf_mal = df_mal.reset_index(drop=True)\n\n\"Load Lime text explainer model\"\nclass_names = ['negative', 'neutral']\nexplainer = LimeTextExplainer(class_names = class_names)\n\n\"Function to display sentiment prediction & lime text explainer\"\ndef display_senti(idx):   \n    #print(idx)\n    ori_tweet = df_mal.text[idx];print(\"Original tweet:\\n%s \" % (ori_tweet),flush=True)\n    processed_tweet = df_mal.textfin[idx];print(\"\\nProcessed tweet:\\n%s \" % (processed_tweet),flush=True)\n    pred = senti_model_mal.predict([processed_tweet]);print(\"\\nSentiment prediction: %s\" % (' '.join(le.inverse_transform(pred))))\n    probas = senti_model_mal.predict_proba(processed_tweet);acc = probas[0][pred[0]];print(\"Accuracy: %.4f\" %(acc))\n    exp = explainer.explain_instance(processed_tweet, senti_model_mal.predict_proba,num_features=10, top_labels=1)\n    exp.show_in_notebook(text=True)\n\n\"Function to create widget to generate random tweet & corresponding prediction\"\nbtn = widgets.Button(description='Randomize tweet', layout=Layout(width='20%', height='40px'));btn.style.button_color = 'lightgreen'\nout = widgets.Output(layout={'border': '3px solid green'})\ndef btn_eventhandler(obj):\n    with out:\n        clear_output()\n        x = df_mal.textfin.sample(1)\n        idx = x.index[0];ori_tweet = df_mal.text[idx];x_l = df_mal.textfin.sample(1).to_list()\n        print(idx)\n        #display('{}'.format(x))\n        print(\"Original tweet: \");print(ori_tweet, \"\\n\");print(\"Preprocessed tweet: \");print(' '.join(x), \"\\n\")\n        pred = senti_model_mal.predict(x);y = ' '.join(le.inverse_transform(pred));probas = senti_model_mal.predict_proba(x);acc = probas[0][pred[0]]\n        print(\"Prediction: %s\" %(y));print(\"Accuracy: %.4f\" %(acc))","c194b695":"#print(\"Examples of Event tweet data\")\n#pd.options.display.max_colwidth = 8000\n\ndf_mal.sample(5)","f4c762bc":"print(\"Tweet 1\")\ndisplay_senti(5)\nprint(\"Tweet 2\")\ndisplay_senti(56)\nprint(\"Tweet 3\")\ndisplay_senti(191)\nprint(\"Tweet 4\")\ndisplay_senti(111)\nprint(\"Tweet 5\")\ndisplay_senti(110)","6bb4b664":"#print(\"Click 'Randomize tweet' button\")\ndisplay(btn);btn.on_click(btn_eventhandler);display(out)","67690c74":"### This is an example of Rapid transit related tweets.\nNote: The 'text' column comprises original tweet while 'textfin' column comprises pre-processed tweet which are feed into the LDA model.","7deed31d":"### Visualisation of LDA model (pyldavis)\n\n#### What i discovered?\n* LDA was able to distinguish event tweet topic from non-event tweet topics clearly.\n* The model works for both English and Manglish tweets.\n* For both English and Manglish tweets data, **Topic 1 was identified as the topic representing event tweets**. \n* Topic 1 is the largest topic as it comprises the highest prevalence of terms. \n* Topic 1 also seemed indenpendent of other topics as majority of its terms occur almost exclusively in the event tweet topic, and not shared with other topics.  \n* The non-event tweet topics includes topic on rapid transit payment methods and topic on train conditions. \n\n### Visit this link to explore the interactive pyldavis plots\nhttps:\/\/www.kaggle.com\/shashikay\/pyldavis-plot\n\n### GIF shot of the pyldavis plots\n<iframe src=\"https:\/\/giphy.com\/embed\/QybgcI0U0WU0UOlEra\" width=\"680\" height=\"616\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen><\/iframe><p><a href=\"https:\/\/giphy.com\/gifs\/QybgcI0U0WU0UOlEra\">via GIPHY<\/a><\/p>\n","045184c8":"# Introduction","2e3815c8":"I created this notebook to share the **outcomes of my Data Science research project**, titled \"Detecting Rapid Transit Service Disruption Events and Sentiment\", focusing on tweets. Rapid transit here refers to light rail transit (LRT) and mass rapid transit transit (MRT) services in Malaysia.\n\n***About my research project:***\n* I crawled rapid transit related tweets using 'twitterscraper' package.\n* **Part 1**: Using LDA approach to detect event tweets (i.e. tweets about rapid transit service disruption events). I used pyldavis package, to display and allow interaction with the topics-terms results of LDA topic modelling for Manglish and English tweets respectively. \n* **Part 2**: Using supervised machine learning & Word2Vec vectorizer to predict sentiment of detected event tweets. I tested Random Forest, XGBoost and SVM and found that SVM worked the best for my data. \n\n\n***Some notes on the notebook:***\n* Majority of the programming codes in relation to data acquisition and data processing are excluded from this notebook for brevity. \n* pyldavis visualization of the LDA models distorted the layout of this notebook. Hence, the plot are published in another notebook. Link is provided below\n* I created a widget to generate random tweet and predict its sentiment using the tuned SVM-Word2Vec model. But, since Kaggle has yet to include 'saving widget to html' option, the widget is not workable yet. Nonetheless, i included a GIF on how it works in Jupyter notebook as well as examples of sentiment prediction on some event tweets. ","47d95898":"A mock-up widget was explored. Ideally, click the randomize tweet button to extract a tweet, its prediction & accuracy score. However, Kaggle notebook currently is unable to save the widget state in html. As such, the output can't be generated.\n\n### So, please,enjoy the GIF instead","90dc47bc":"### The 'Randomize tweet' widget button would have work like this\n<iframe src=\"https:\/\/giphy.com\/embed\/icOhy0fMF3pZuI3R4P\" width=\"680\" height=\"630\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen><\/iframe><p><a href=\"https:\/\/giphy.com\/gifs\/icOhy0fMF3pZuI3R4P\">via GIPHY<\/a><\/p>","ab12276d":"<iframe src=\"https:\/\/giphy.com\/embed\/lQ7payiGhj5xkyxIg2\" width=\"580\" height=\"180\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen><\/iframe><p><a href=\"https:\/\/giphy.com\/gifs\/motivation-start-now-lQ7payiGhj5xkyxIg2\">via GIPHY<\/a><\/p>","851e3a57":"# Part 1 ","72132d71":"### Examples of event tweet data\nNote: The Data comprises event tweets with manually labelled sentiment, which were used to pre-train SVM model.","5b70b9c2":"### The methods and results are discussed in great details in my research project report\n\n<iframe src=\"https:\/\/giphy.com\/embed\/XZgKVgWXxZ6o2BFd19\" width=\"380\" height=\"380\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen><\/iframe><p><a href=\"https:\/\/giphy.com\/gifs\/sunday-read-author-XZgKVgWXxZ6o2BFd19\">via GIPHY<\/a><\/p>","acf2e586":"# Part 2","309fd843":"## Detecting sentiment of event tweets ( Word2Vec & Supervised Learning)\n* Event tweets are vectorized using Word2Vec algorithm. \n* The sentiment are then detected using Random Forest, XGBoost and SVM algorithm. \n* SVM algorithm was chosen as it yielded the best accuracy. \n* Examples of the sentiment prediction & accuracy for the Word2Vec-SVM model are shown below","f28051d6":"## Detecting event tweets from tweet corpus (LDA approach)\n* A corpus of rapid transit tweets was crawled. Manglish and English tweets were identified and processed accordingly.\n* LDA algorithm was used to identify latent topic clusters for Manglish and English tweets. \n* The results are graphically displayed via pyldaviz package. Please visit this link to interact with the pyldavis plots\nhttps:\/\/www.kaggle.com\/shashikay\/pyldavis-plot\n* The LDA results are displayed for Manglish and English tweets respectively.","cb6bbd9e":"### Let's explore prediction of some sample tweets"}}