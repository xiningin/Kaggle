{"cell_type":{"8f42e5ee":"code","d5beb8d1":"code","ed5f02ca":"code","73ff223f":"code","dca1aae4":"code","e42c6052":"code","ff9c9a67":"code","11a5c6d2":"code","e691698e":"code","e452e1d4":"code","ec381c50":"code","fb806952":"code","0c717a20":"code","0eb596bd":"code","fb8b3531":"code","fefbf041":"markdown","31ab58ad":"markdown","4c8ad9e4":"markdown","7b4b9097":"markdown","4cec9113":"markdown","00182ba9":"markdown"},"source":{"8f42e5ee":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d5beb8d1":"df=pd.read_csv(\"..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv\")\ndf","ed5f02ca":"df.shape","73ff223f":"df.info","dca1aae4":"df.isnull().sum()","e42c6052":"X= df.iloc[:, [3,4]].values","ff9c9a67":"Y=df.iloc[:, [2,4]].values","11a5c6d2":"Z=df.iloc[:, [2,4]].values","e691698e":"\nfrom sklearn.cluster import KMeans\nwcss=[]\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters= i, init='k-means++', random_state=0)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\nkmeansmodel = KMeans(n_clusters= 5, init='k-means++', random_state=0)\ny_kmeans= kmeansmodel.fit_predict(X)","e452e1d4":"from sklearn.cluster import KMeans\nwcss=[]\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters= i, init='k-means++', random_state=0)\n    kmeans.fit(Y)\n    wcss.append(kmeans.inertia_)\nkmeansmodel = KMeans(n_clusters= 5, init='k-means++', random_state=0)\ny_kmeans= kmeansmodel.fit_predict(Y)\n","ec381c50":"from sklearn.cluster import KMeans\nwcss=[]\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters= i, init='k-means++', random_state=0)\n    kmeans.fit(Z)\n    wcss.append(kmeans.inertia_)\nkmeansmodel = KMeans(n_clusters= 5, init='k-means++', random_state=0)\ny_kmeans= kmeansmodel.fit_predict(Z)","fb806952":"plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income (k$)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","0c717a20":"plt.scatter(Y[y_kmeans == 0, 0], Y[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(Y[y_kmeans == 1, 0], Y[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(Y[y_kmeans == 2, 0], Y[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(Y[y_kmeans == 3, 0], Y[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(Y[y_kmeans == 4, 0], Y[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.title('Clusters of customers')\nplt.xlabel('Age (Yrs)')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","0eb596bd":"plt.scatter(Z[y_kmeans == 0, 0], Z[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\nplt.scatter(Z[y_kmeans == 1, 0], Z[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\nplt.scatter(Z[y_kmeans == 2, 0], Z[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\nplt.scatter(Z[y_kmeans == 3, 0], Z[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\nplt.scatter(Z[y_kmeans == 4, 0], Z[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')\nplt.title('Clusters of customers')\nplt.xlabel('Gender')\nplt.ylabel('Spending Score (1-100)')\nplt.legend()\nplt.show()","fb8b3531":"plt.plot(range(1,11), wcss)\nplt.title('The Elbow Method')\nplt.xlabel('no of clusters')\nplt.ylabel('wcss')\nplt.show()","fefbf041":"# Building The Model","31ab58ad":"# Plotting Graphs","4c8ad9e4":"# Importing Libraries And Dataset","7b4b9097":"# Initial Data Analysis","4cec9113":"**WCSS is the sum of squared distance between each point and the centroid in a cluster.       \nK= no. of clusters**","00182ba9":"# Data Preprocessing"}}