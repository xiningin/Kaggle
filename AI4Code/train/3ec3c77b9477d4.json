{"cell_type":{"92bddba3":"code","f0007938":"code","8a3dc3fd":"code","abd02fe2":"code","10ec5242":"code","232d691f":"code","e6c06f8a":"code","a37c37ea":"code","dd24aad6":"code","3ba213c7":"code","77a6da91":"code","29d8c7b7":"code","06a4c446":"code","b3c196ce":"code","3e9fc11c":"code","8348c760":"code","a0ab71f8":"code","30654b21":"code","f92b8a35":"code","587e33bf":"code","a289d700":"code","ca529794":"code","22fce2d9":"code","b4b39396":"code","c0200770":"code","8b89bf5a":"code","d6fce1cf":"code","587016f2":"code","b9ea30bb":"code","83a9a688":"code","2f113e19":"code","990988eb":"code","c44af61b":"code","4ec4841e":"code","fdada509":"code","8f52143f":"code","1aa96493":"code","64f3b439":"code","ed42c476":"code","c20668f9":"code","f9dc59e0":"code","47a000a9":"code","6397d6f1":"code","96d18bc9":"code","178b8f94":"code","6e003e27":"markdown","d873a62b":"markdown","ad89ae83":"markdown","077b50d3":"markdown","af316f53":"markdown","935272af":"markdown","64153106":"markdown","e12a074c":"markdown","042dc1e2":"markdown","21cd6f3f":"markdown","1b8e754f":"markdown","95677732":"markdown","30e4beb8":"markdown"},"source":{"92bddba3":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport re # regular expression\nimport nltk\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f0007938":"data=pd.read_csv(\"\/kaggle\/input\/blog-authorship-corpus\/blogtext.csv\")","8a3dc3fd":"data.head(10)","abd02fe2":"data.isna().any()","10ec5242":"data.shape","232d691f":"data=data.head(10000)","e6c06f8a":"data.info()","a37c37ea":"data.drop(['id','date'], axis=1, inplace=True)","dd24aad6":"data.head()","3ba213c7":"data['age']=data['age'].astype('object')","77a6da91":"data.info()","29d8c7b7":"data['clean_data']=data['text'].apply(lambda x: re.sub(r'[^A-Za-z]+',' ',x))","06a4c446":"data['clean_data']=data['clean_data'].apply(lambda x: x.lower())","b3c196ce":"data['clean_data']=data['clean_data'].apply(lambda x: x.strip())","3e9fc11c":"print(\"Actual data=======> {}\".format(data['text'][1]))","8348c760":"print(\"Cleaned data=======> {}\".format(data['clean_data'][1]))","a0ab71f8":"from nltk.corpus import stopwords\nstopwords=set(stopwords.words('english'))\n\n","30654b21":"data['clean_data']=data['clean_data'].apply(lambda x: ' '.join([words for words in x.split() if words not in stopwords]))","f92b8a35":"data['clean_data'][6]","587e33bf":"data['labels']=data.apply(lambda col: [col['gender'],str(col['age']),col['topic'],col['sign']], axis=1)","a289d700":"data.head()","ca529794":"data=data[['clean_data','labels']]","22fce2d9":"data.head()","b4b39396":"X=data['clean_data']","c0200770":"Y=data['labels']","8b89bf5a":"from sklearn.feature_extraction.text import CountVectorizer","d6fce1cf":"vectorizer=CountVectorizer(binary=True, ngram_range=(1,2))","587016f2":"X=vectorizer.fit_transform(X)","b9ea30bb":"X[1]","83a9a688":"vectorizer.get_feature_names()[:5]","2f113e19":"label_counts=dict()\n\nfor labels in data.labels.values:\n    for label in labels:\n        if label in label_counts:\n            label_counts[label]+=1\n        else:\n            label_counts[label]=1","990988eb":"label_counts","c44af61b":"from sklearn.preprocessing import MultiLabelBinarizer\nbinarizer=MultiLabelBinarizer(classes=sorted(label_counts.keys()))","4ec4841e":"Y=binarizer.fit_transform(data.labels)","fdada509":"from sklearn.model_selection import train_test_split","8f52143f":"Xtrain,Xtest,Ytrain,Ytest=train_test_split(X,Y,test_size=0.2)","1aa96493":"from sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.linear_model import LogisticRegression","64f3b439":"model=LogisticRegression(solver='lbfgs')","ed42c476":"model=OneVsRestClassifier(model)","c20668f9":"model.fit(Xtrain,Ytrain)","f9dc59e0":"Ypred=model.predict(Xtest)","47a000a9":"Ypred_inversed = binarizer.inverse_transform(Ypred)\ny_test_inversed = binarizer.inverse_transform(Ytest)","6397d6f1":"for i in range(5):\n    print('Text:\\t{}\\nTrue labels:\\t{}\\nPredicted labels:\\t{}\\n\\n'.format(\n        Xtest[i],\n        ','.join(y_test_inversed[i]),\n        ','.join(Ypred_inversed[i])\n    ))","96d18bc9":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import recall_score\n\ndef print_evaluation_scores(Ytest, Ypred):\n    print('Accuracy score: ', accuracy_score(Ytest, Ypred))\n    print('F1 score: ', f1_score(Ytest, Ypred, average='micro'))\n    print('Average precision score: ', average_precision_score(Ytest, Ypred, average='micro'))\n    print('Average recall score: ', recall_score(Ytest, Ypred, average='micro'))","178b8f94":"print_evaluation_scores(Ytest, Ypred)","6e003e27":"### Merging all the other columns into labels columns","d873a62b":"Columns like ID and date are removed from the dateset as they do not provide much value","ad89ae83":"### Splitting the data into X and Y","077b50d3":"> **There are 68,124 records and is huge to perform analysis and computation, hence we are going to take a subset and rerun with the entire data-set once all errors are fixed and optimization is done**","af316f53":"#### Let us see some feature names","935272af":"## **Data Wrangling for data['text'] column to remove all unwanted text from the column**","64153106":"### Lets perform count vectorizer with bi-grams and tri-grams to get the count vectors of the X data","e12a074c":"Converted all the columns to object data-type","042dc1e2":"### Pre-processing the labels","21cd6f3f":"### Splitting the data into 80% Train set :20% Test set ","1b8e754f":"### Remove all stop words","95677732":"### Reading the CSV and performing Exploratory data analytics","30e4beb8":"*No Null values present in the dataset*"}}