{"cell_type":{"d7d2c5e8":"code","a4e80a39":"code","387f08b7":"code","72cc9e55":"code","e0b32a70":"code","b2cb2cdf":"code","7b94b75e":"code","8fb03eec":"code","d6a0eec7":"code","c9f59f2c":"code","bf30fb02":"markdown","079d307c":"markdown","adff571d":"markdown","38e7f1f2":"markdown","9cf03288":"markdown","31942f33":"markdown"},"source":{"d7d2c5e8":"import tensorflow as tf\nfrom pathlib import Path\nfrom PIL import Image\nimport IPython\nfrom pprint import pprint\nfrom urllib import request\nimport tensorflow_datasets as tfds\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2 as cv\nplt.ion()\nimport ipywidgets as widgets\nfrom ipywidgets import interact, interact_manual\ntf.version.VERSION","a4e80a39":"DATA_DIR=\"..\/input\/\"\nMODEL_DIR=\"..\/output\/kaggle\/working\/model\/\"\nFRUITS_DATASET = DATA_DIR+'\/fruits\/fruits-360\/'\nmodel = None","387f08b7":"\nCLASS_NAMES = []\nIMAGE_SIZE=[100, 100]\nBATCH_SIZE=8\n\nif tf.version.VERSION == '2.3.0':\n    training_ds, validation_ds = (\n                    tf.keras.preprocessing.image_dataset_from_directory(\n                            shuffle=True, directory=FRUITS_DATASET+'Training\/', \n                            label_mode='int', batch_size=BATCH_SIZE, color_mode='rgb',\n                            image_size=IMAGE_SIZE,\n                            seed=6, subset='training', \n                            validation_split=.2,\n                    ),\n                    tf.keras.preprocessing.image_dataset_from_directory(\n                            shuffle=True, directory=FRUITS_DATASET+'Training\/', \n                            label_mode='int', batch_size=BATCH_SIZE, color_mode='rgb',\n                            image_size=IMAGE_SIZE,\n                            seed=6, subset='validation', \n                            validation_split=.2,\n                    )\n    )\n    \n    test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n                        shuffle=False, directory=FRUITS_DATASET+'Test\/', \n                        label_mode='int', batch_size=BATCH_SIZE, color_mode='rgb',\n                        image_size=IMAGE_SIZE,\n             )\n    training = training_ds.map(lambda x,y: (x\/255., y))\n    validation = validation_ds.map(lambda x,y: (x\/255., y))\n    test = test_ds.map(lambda x,y: (x\/255., y))    \n   \n    CLASS_NAMES = training_ds.class_names\n    \nelse:    \n    train_image_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n                                rescale=1.\/255, \n                                data_format='channels_last', \n                                validation_split=0.2, \n                        )    \n    training_ds = train_image_gen.flow_from_directory(\n                                FRUITS_DATASET+'Training\/', \n                                subset='training', \n                                seed=6, class_mode='sparse',\n                                batch_size=BATCH_SIZE, \n                                shuffle=True, target_size=IMAGE_SIZE\n                    )\n    validation_ds = train_image_gen.flow_from_directory(\n                                        FRUITS_DATASET+'Training\/', \n                                        class_mode='sparse', \n                                        batch_size=BATCH_SIZE,\n                                        shuffle=True, \n                                        target_size=IMAGE_SIZE,\n                                        subset='validation', \n                                        seed=6,                                         \n                    )    \n    test_image_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n                                    rescale=1.\/255, \n                                    data_format='channels_last'\n                        )\n    \n    test_ds = test_image_gen.flow_from_directory(\n                                                FRUITS_DATASET+'Test\/', \n                                                class_mode='sparse', \n                                                batch_size=BATCH_SIZE,shuffle=False, \n                                                target_size=IMAGE_SIZE\n                    )\n     \n    CLASS_NAMES = training_ds.class_indices","72cc9e55":"fig, ax = plt.subplots(1, 8, figsize=(16,16))\n\nfor batch in training:\n    image_batch, label_batch = batch\n    for iindex in range(8): \n        ax[iindex].grid(False)\n        ax[iindex].set_title(CLASS_NAMES[label_batch[iindex].numpy()])\n        ax[iindex].imshow(image_batch[iindex])\n        ax[iindex].axis('off')\n    break","e0b32a70":"import time\nif False:\n    model = tf.keras.models.load_model(filepath='model\/FruDetec\/')\nelse:\n    now = time.time()\n    model = tf.keras.models.Sequential([\n        tf.keras.layers.Conv2D(16, (5,5), activation='relu'),\n        tf.keras.layers.AveragePooling2D((2,2)),\n        tf.keras.layers.Conv2D(16, (5,5),activation='relu'),\n        tf.keras.layers.AveragePooling2D((2,2)),\n        tf.keras.layers.Flatten(),\n        tf.keras.layers.Dense(192, activation='relu'),\n        tf.keras.layers.Dense(len(CLASS_NAMES), activation='softmax')\n    ])\n    \n    model.compile(loss='sparse_categorical_crossentropy', \n                  optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-4), \n                  metrics=['accuracy'])\n    \n    model.build((None, IMAGE_SIZE[0], IMAGE_SIZE[1],3))\n    model.summary()\n    \n    model.fit(training, epochs=10, \n              validation_data=validation, use_multiprocessing=True,\n              callbacks=[tf.keras.callbacks.EarlyStopping()])\n    \n    # save model\n    model.save(filepath='model\/FruDetec', overwrite=True)\n    print(\"{}s\".format(time.time()-now))","b2cb2cdf":"model_layers = tf.keras.models.Model(inputs=model.inputs, outputs=[l.output for l in model.layers])","7b94b75e":"from matplotlib import pyplot as plot\nplot.ion()\n%matplotlib inline\n\nimport random\n\nf, ax= plt.subplots(4, 4, figsize=(8,8))\n\nchannels = random.sample(range(0, 16), 4)\nlayers = range(0, 4)\n\ntest_shuffled = test.unbatch().shuffle(seed=6, buffer_size=1024).batch(BATCH_SIZE)\n\nfor ibatch in test_shuffled:  \n    image_batch, label_batch = ibatch\n    outputs = model_layers.predict(ibatch) ##(layers, batches, nrows, ncols, channel) \n    \n    for i in range(0, 4):  \n        class_int = tf.argmax(outputs[len(outputs)-1][i], axis=0).numpy()\n        # IPython.display.display(tf.keras.preprocessing.image.array_to_img(image_batch[i]))\n        print(\"T={},P={}\".format(CLASS_NAMES[label_batch[i]], CLASS_NAMES[class_int]))\n        \n        for c, l in zip(channels, layers):\n            #print(len(outputs))                \n            # print(outputs[0][i].shape)            \n            # print(outputs[1][i].shape)            \n            # print(outputs[2][i].shape)            \n            # print(outputs[3][i].shape)            \n            ax[i, l].set_title(\"I{}, L{}, C{}\".format(i, l, c))\n            ax[i, l].grid(False)\n            ax[i, l].set_xticks([])\n            ax[i, l].set_yticks([])\n            ax[i, l].imshow(outputs[l][i, :,:, c], cmap='inferno')\n            ax[i, l].axis('off')\n    break","8fb03eec":"y_pred=model.predict(test)\ny_pred=np.argmax(y_pred, 1)\ny_pred.shape","d6a0eec7":"y_true = test.unbatch().map(lambda x, y: y)\ny_true = np.array(list(y_true.as_numpy_iterator()))\ny_true.shape","c9f59f2c":"score = y_pred == y_true\n\n\"Total-{}, Hit-{}, Miss-{}\".format(len(score), len(score[y_pred == y_true]), len(score[y_pred != y_true]))","bf30fb02":"# Test","079d307c":"# Result","adff571d":"# View Data","38e7f1f2":"# USING TENSORFLOW 2.3","9cf03288":"# Load Data","31942f33":"# Train"}}