{"cell_type":{"5f695672":"code","0b562af6":"code","d9f03efa":"code","3603ef67":"code","3bc283ca":"code","1772ee57":"code","4d1967ef":"code","f719c04c":"code","1fd7ee33":"code","6e1f10a6":"code","9a7e20e3":"code","c5ad4741":"code","e26906ef":"code","d41ad1d4":"code","97b4699b":"code","fa802f20":"code","03362c79":"code","45cc01c3":"code","21b32e6c":"code","1ad8f8d6":"code","5f55e2e1":"code","aeeb93c4":"markdown","ed750ff9":"markdown","7210011b":"markdown","285c431d":"markdown","aa2cce79":"markdown"},"source":{"5f695672":"!pip install vaderSentiment","0b562af6":"import numpy as np \nimport pandas as pd \nfrom vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nimport time\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/tweet-sentiment-extraction\/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d9f03efa":"data = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/train.csv')","3603ef67":"data.shape","3bc283ca":"data.head()","1772ee57":"data.tail()","4d1967ef":"data.info()","f719c04c":"data.isnull().sum()","1fd7ee33":"data.dropna(inplace=True)","6e1f10a6":"data.info()","9a7e20e3":"analyzer = SentimentIntensityAnalyzer()","c5ad4741":"def calculate_sentiment_scores(sentence):\n    sntmnt = analyzer.polarity_scores(sentence)['compound']\n    return(sntmnt)","e26906ef":"start = time.time()\n\neng_snt_score =  []\n\nfor comment in data.text.to_list():\n    snts_score = calculate_sentiment_scores(comment)\n    eng_snt_score.append(snts_score)\n    \nend = time.time()\n\n# total time taken\nprint(f\"Runtime of the program is {(end - start)\/60} minutes or {(end - start)} seconds\")","d41ad1d4":"data['sentiment_score'] = np.array(eng_snt_score)\ndata.head()","97b4699b":"i = 0\n\nvader_sentiment = [ ]\n\nwhile(i<len(data)):\n    if ((data.iloc[i]['sentiment_score'] >= 0.05)):\n        vader_sentiment.append('positive')\n        i = i+1\n    elif ((data.iloc[i]['sentiment_score'] > -0.05) & (data.iloc[i]['sentiment_score'] < 0.05)):\n        vader_sentiment.append('neutral')\n        i = i+1\n    elif ((data.iloc[i]['sentiment_score'] <= -0.05)):\n        vader_sentiment.append('negative')\n        i = i+1","fa802f20":"data['vader_sentiment_labels'] = vader_sentiment","03362c79":"data.head(15)","45cc01c3":"data['actual_label'] = data['sentiment'].map({'positive': 1, 'neutral': 0, 'negative':-1})\ndata['predicted_label'] = data['vader_sentiment_labels'].map({'positive': 1, 'neutral': 0, 'negative':-1})\n\ndata.head()","21b32e6c":"from sklearn.metrics import accuracy_score","1ad8f8d6":"y_act = data['actual_label'].values\ny_pred = data['predicted_label'].values","5f55e2e1":"accuracy_score(y_act, y_pred)","aeeb93c4":"**64% Accuracy** is not bad for **classifying sentiments of 27481 sentences in about 3 seconds**! Moreover, we did not apply any text preprocessing, this accuracy may be increased through a proper preprocessing. The main advantage may be the fact that no labeling process is involved, however, we would prefer an NLP approach for achieving higher accuracy.","ed750ff9":"We will be using the \"Tweet Sentiment Extraction\" data from Kaggle, in particular, the \"text\" and the \"sentiment\" features.","7210011b":"# Vader Sentiment Analysis","285c431d":"Initialize the sentiment analyzer, and calculating the sentiment scores of each sentences in the \"text\" feature:","aa2cce79":"**Vader** is an excellent library for getting rapid sentiment analysis results, particularly for the *social media* text. It has some great **advantages** which could be counted as the following:\n\n* No labeling process is required!\n* Fast and deployable,\n* Not bad accuracy even without Text Preprocessing.\n\nHowever, there are some main **disadvantages** as well, and the primary one is the fact that it is a rule-based approach, it utilizes the predefined polarity scores of each words (and emojis!) by summing them up to get the final score of the sentence or paragraph, depending on the context that we would like to extract the sentiment. \n\nAnother disadvantage that I have discored thus far, in connection with the first one, is that we cannot go beyond a certain accuracy (compared to NLP approaches), usually I prefer training an NLP model (such as BERT etc.) for attaining higher success rates. In a future notebook, I intent to compare the result with BERT Model.\n\n* Rule-Based sentiment analysis & no learning."}}