{"cell_type":{"e1ac85d2":"code","b7e2b2cd":"code","9f8268d9":"code","a8938823":"code","e43fa93b":"code","fb7f38fc":"code","c52c9c9d":"code","193e7827":"code","d5517479":"code","bf490d58":"code","80f94650":"code","ff718cf5":"code","4bb0825c":"code","a60b3fc2":"code","8ad0cc1b":"code","c46dd607":"code","4932399f":"code","595b094b":"code","64815398":"code","f2088b12":"code","ffed64f7":"code","59374a07":"code","377bd92d":"code","e03ba9f5":"code","07398327":"code","9fdb32a4":"code","4695fb94":"code","a0011670":"code","78573907":"code","deafb689":"code","ae439d29":"code","404b9def":"code","ed31cbfc":"code","7f438f42":"code","79d9a8e6":"code","68350ebe":"code","73e9374d":"code","7d8ddf80":"code","9da3edb5":"code","e1ef7a88":"code","0e00d4bd":"code","7d08df17":"code","c10ba5c5":"code","96c3dd26":"code","769adf20":"code","067c3c38":"code","4019d127":"code","46d4021d":"code","b452b88f":"code","b794c306":"code","46a0ff79":"markdown","ffda90a9":"markdown","d99620a3":"markdown","dcc12a64":"markdown","c0cfab82":"markdown","06b5b299":"markdown","b8330b29":"markdown","43463ee7":"markdown","f95f512e":"markdown","8b50a96d":"markdown","405c53f4":"markdown","8dc68feb":"markdown","ed55c67e":"markdown","5f377999":"markdown","0bcf66c1":"markdown","350da4d6":"markdown","5d49d791":"markdown","4188c3b4":"markdown","207ec322":"markdown","1f5f0a8c":"markdown","a782ccc2":"markdown","25889637":"markdown","9a363973":"markdown"},"source":{"e1ac85d2":"#Importing all required libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt  #Graphical representation of data and model fitting\nimport seaborn as sns #Graphical representation of data and model fitting\n\n","b7e2b2cd":"#Reading file and displaying data\ncustomer_info=pd.read_excel('\/kaggle\/input\/bank-loan-modelling\/null')  #reading the data in the excel sheet as a pandas Dataframe\nprint(customer_info)\n\n\n\n\n\n","9f8268d9":"#Renaming columns whose names have blank spaces\ncustomer_info.rename(columns={'Personal Loan':'Personal_Loan','Securities Account':'Securities_Account',\n                      'CD Account':'CD_Account','ZIP Code':'ZIP_Code'},inplace=True)\nprint(customer_info)","a8938823":"#description of the dataframe\ncustomer_info.info()    #displaying number of rows and columns,name and datatype of each column \n                        #and total memory space occupied by dataframe ","e43fa93b":"#statistical analysis of each column\ncustomer_info.describe()  # mean,standard deviation,interquartile range and range of values in each column  \n","fb7f38fc":"#Checking for null values in DataFrame\ncustomer_info.isnull().sum()\n","c52c9c9d":"#checking for negative values\ny=(customer_info<0).all(1)\nprint(y)","193e7827":"#Checking for correlation using a correlation matrix\nCorrMatrix=customer_info.corr()\nprint(CorrMatrix)\n","d5517479":"#visualisation of the correlation matrix using a heatmap\nplt.figure(figsize=(20,15))\nax=sns.heatmap(CorrMatrix,annot=True)\n\n","bf490d58":"#Value counts of Each categorical column\n#value count of Family\ncustomer_info.Family.value_counts()","80f94650":"#value count of Education\ncustomer_info.Education.value_counts()","ff718cf5":"#value count of Securities_Account\ncustomer_info.Securities_Account.value_counts()","4bb0825c":"#value count of CD_Account\ncustomer_info.CD_Account.value_counts()\n","a60b3fc2":"#value count of CreditCard\ncustomer_info.CreditCard.value_counts()","8ad0cc1b":"#value count of Online\ncustomer_info.Online.value_counts()","c46dd607":"#Number of uniques in each column\ncustomer_info.nunique()             \n","4932399f":"#Number of people with zero mortgage\nzeromortgage=(customer_info.Mortgage==0).sum()\nprint(zeromortgage)","595b094b":"#Number of people having zero spendings on credit cards per month\nzerospending=(customer_info.CCAvg==0).sum()\nprint(zerospending)","64815398":"#Univariate Analysis\n#distribution of important independent variables\n#histogram showing distribution of age\nx=customer_info['Age']\nplt.hist(x,bins=6,color='blue',alpha=0.5,edgecolor='violet',linewidth=1.3)\nplt.xlabel('Age')\nplt.show() \n\n","f2088b12":"#histogram showing distribution of work experience\nx=customer_info['Experience']\nplt.hist(x,bins=4,color='blue',alpha=0.5,edgecolor='violet',linewidth=1.3)\nplt.xlabel('Work Experience')\nplt.show() ","ffed64f7":"#histogram showing distribution of income\nx=customer_info['Income']\nplt.hist(x,bins=6,color='blue',alpha=0.5,edgecolor='violet',linewidth=1.3)\nplt.xlabel('Income ($000)')\nplt.show() \n","59374a07":"#histogram showing distribution of average credit card spending per month\nx=customer_info['CCAvg']\nplt.hist(x,bins=4,color='blue',alpha=0.5,edgecolor='violet',linewidth=1.3)\nplt.xlabel('Average Credit Card Spendings\/month($000)')\nplt.show() \n","377bd92d":"#histogram to show distribution of mortgage\nx=customer_info['Mortgage']\nplt.hist(x,bins=6,color='blue',alpha=0.5,edgecolor='violet',linewidth=1.3)\nplt.xlabel('Mortgage($000)')\nplt.show() \n","e03ba9f5":"#bivariate analysis\nsns.pairplot(customer_info)","07398327":"sns.boxplot(x='Education',y='Income',hue='Personal_Loan',data=customer_info)","9fdb32a4":"sns.boxplot(y='Income',x='Family',data=customer_info,hue='Personal_Loan')","4695fb94":"#applying minmax scaling to the entire dataset\nfrom sklearn.preprocessing import MinMaxScaler\ndata=customer_info.values\ntrans=MinMaxScaler()\ndata=trans.fit_transform(data)\ndata=pd.DataFrame(data)\nplt.hist(data)\nplt.show()\n","a0011670":"#from sklearn.preprocessing import StandardScaler\n#data=customer_info.values\n#trans = StandardScaler()\n#data = trans.fit_transform(data)\n#dataset =pd.DataFrame(data)\n#plt.hist(data)\n#plt.show()","78573907":"#Dropping columns that we have decided not to use\ncustomer_info.drop(['ID','ZIP_Code','Experience','Income'],axis=1,inplace=True)\n#not including ID and ZIP_Code as they are irrelevant and Income and Experience as they have high correlations with other feature variables\ncustomer_info","deafb689":"#splitting the dataset using Stratified Sampling\nfrom sklearn.model_selection import train_test_split\nX=customer_info.loc[:,customer_info.columns!='Personal_Loan']\nY=customer_info['Personal_Loan']\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,stratify=Y,random_state=0)\n#we split the data using stratified sampling as only 9.6% of the people opted for personal loan in the previous campaign i.e. the dataset is imbalanced\n","ae439d29":"#applying the model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nlogistic_regression=LogisticRegression()\nlogistic_regression.fit(X_train,Y_train)\nY_predtrain=logistic_regression.predict(X_train)\nY_predtest=logistic_regression.predict(X_test)\n","404b9def":"#checking accuracy for training set \nprint('Accuracy for training set:',metrics.accuracy_score(Y_train,Y_predtrain))\n","ed31cbfc":"#checking accuracy for training set\nprint('Accuracy for test set:',metrics.accuracy_score(Y_test,Y_predtest))","7f438f42":"from sklearn.metrics import classification_report,confusion_matrix\nresult=confusion_matrix(Y_test,Y_predtest)\nprint(\"confusion matrix:\")\nprint(result)","79d9a8e6":"#visualisation of the confusion matrix\nsns.heatmap(result, annot=True)\nplt.show()","68350ebe":"result1=classification_report(Y_test,Y_predtest)\nprint(\"classification report:\",result1)","73e9374d":"#finding out the logistic summary of our model\nimport statsmodels.api as sm\nfrom scipy import stats\nX2 = sm.add_constant(X)\nest = sm.OLS(Y, X2)\nest2 = est.fit()\nprint(est2.summary())","7d8ddf80":"#finding out the theoretical and true odd ratios of the individual coefficients\nlogit=sm.Logit(Y,X)\nresult=logit.fit()\nprint(np.exp(result.params))\nparams= result.params\nconf=result.conf_int()\nconf[\"OR\"]=params\nconf.columns=[\"2.5%\",\"97.5%\",\"OR\"]\nprint(np.exp(conf))","9da3edb5":"#Decision Tree Model\nfrom sklearn.tree import DecisionTreeClassifier\nmodel=DecisionTreeClassifier(random_state=0)\nmodel.fit(X_train,Y_train)\nY_predtrain=model.predict(X_train)\nY_predtest=model.predict(X_test)","e1ef7a88":"#checking accuracy for training set \nprint('Accuracy for training set:',metrics.accuracy_score(Y_train,Y_predtrain))","0e00d4bd":"#checking accuracy for training set\nprint('Accuracy for test set:',metrics.accuracy_score(Y_test,Y_predtest))","7d08df17":"from sklearn.metrics import classification_report,confusion_matrix\nresult=confusion_matrix(Y_test,Y_predtest)\nprint(\"confusion matrix:\")\nprint(result)","c10ba5c5":"#visualisation of the confusion matrix\nsns.heatmap(result, annot=True)\nplt.show()","96c3dd26":"result1=classification_report(Y_test,Y_predtest)\nprint(\"classification report:\",result1)","769adf20":"#Random Forest Model\nfrom sklearn.ensemble import RandomForestClassifier\nmodel=RandomForestClassifier(n_estimators=50)\nmodel.fit(X_train,Y_train)\nY_predtrain=model.predict(X_train)\nY_predtest=model.predict(X_test)\n","067c3c38":"#checking accuracy for training set \nprint('Accuracy for training set:',metrics.accuracy_score(Y_train,Y_predtrain))","4019d127":"#checking accuracy for training set\nprint('Accuracy for test set:',metrics.accuracy_score(Y_test,Y_predtest))","46d4021d":"from sklearn.metrics import classification_report,confusion_matrix\nresult=confusion_matrix(Y_test,Y_predtest)\nprint(\"confusion matrix:\")\nprint(result)\n","b452b88f":"#visualisation of the confusion matrix\nsns.heatmap(result, annot=True)\nplt.show()","b794c306":"result1=classification_report(Y_test,Y_predtest)\nprint(\"classification report:\",result1)","46a0ff79":"STEP 2:Checking if the data requires cleaning and finding correlation between different feature variables","ffda90a9":"Step 6:Metric Evaluation of the performance of the model","d99620a3":"**CONCLUSION**\n\nHere, we have used Binomial Logistic Regression technique not only to predict the class of customers responding to the loan campaign but also get a list of statistically significant independent variables that influence the customer response to the campaign. We are also able to predict the probability of a customer responding or not responding based on the model summary. These give powerful insights which will help in improving the response rate from the customers and thereby conversion to availing loans with the bank.","dcc12a64":"From the above histogram it is clear that the maximum number of people are from 45-53 years of age and that the bank has a customer base in every age group-from young adults to people above 60\n\n","c0cfab82":"From above distribution , it is clear that most of the people have income between $10,000-40,000.","06b5b299":"Out of those who have mortgages,about 75% people have mortgages of less than $100,000","b8330b29":"Step 5:Splitting the Dataset and applying the Logistic Regression Model on it","43463ee7":"Sensitivity is more important than accuracy here as we are more interested in knowing all those records where a customer will respond to a new campaign rather than those records where a customer may not respond at all.**Based on sensitivity,Random Forest turns out to be the best model for prediction,followed by Decision Tree and then Logistic Regression**.The lost opportunity cost in contacting a potential customer, who would avail a loan and thereby pay interest to the bank, due to incorrect classification by the model (sensitivity) is more critical than potentially non-responding customers receiving mailers or calls due to incorrect classification (specificity).\nWhen we compare the model performance measures between the train and test data , the model holds good for the test data without a significant drop in performance measures. This indicates that there is no overfit in the model.\nFor predicting the class with this model, we have consciously compromised on accuracy to have a better sensitivity i.e. not to lose out on potential customers who will respond to the loan campaign.","f95f512e":"We can see that personal loan has been granted to people having high income across all the educational background categories.","8b50a96d":"After looking at the heat map,we see that Experience and Age have a very high correlation of 0.99.So we decide to not include the Experience Column for the model. \nIncome has a high correlation of 0.65 with CCAvg and 0.5 with Personal_Loan. Thus we wont be including Income in our model as well.","405c53f4":"Step 1:Importing all required libraries,uploading,reading and displaying data from the file and performing Exploratory Data Analysis on it.\n  ","8dc68feb":"From above distribution we can conclude that most people have 20-28 years of professional work experience and that the bank has customers who are new to the professional working arena as well as well established working professionals .","ed55c67e":"**Some Conclusions based on ODD RATIOS**\n\n1)If the person has a mortgage,the odds that he opts for a personal loan increases 1.4 folds.\n2)If the customer has a Certificate of Deposit Account with the bank,the odds of him opting for a personal increase 1.3 folds.","5f377999":"Step 3:To study the data distribution of each feature variable and target variable ","0bcf66c1":"**ACTIONABLE INSIGHT BASED ON LOGISTIC REGRESSION MODEL**\n\n1)The bank,instead of cold-calling everyone,should target people having a certificate of deposit account or mortgage or both as their odds of going for a personal loan are very high.\n\n","350da4d6":"Step 7:Applying the decision tree and random forest models and comparing with them","5d49d791":"Step 4:Applying necessary data transformations","4188c3b4":"**Context**\n\nPersonal loans are a major revenue generating mechanism for banks and all banks reach out to potential customers to campaign for their loan offerings. Most of these campaigns reach out to a random database of customers and hence end up into annoying tele-marketing calls than being efficient means for lead conversion.\nIn this project, we will see how we could harness the power of machine learning to target the campaigns towards the right set of customers, thereby increasing conversion propensity. We will be using past data available on the demography, bank details, and transaction patterns of customers who have responded and not responded to a personal loan campaign, as training data to predict the probability if a customer will respond to the campaign.\n\n**In machine learning terminology, this is a classification problem and there are several classification algorithms available to build a prediction model out of which we will be using Logistic regression.**\n\n**About Logistic Regression**\n\nLogistic Regression is a popular and powerful supervised machine learning technique used to build a model relating the independent predictors (x variable) with the response variable (y) that is categorical in nature. Where the class is known already, it can help find factors distinguishing between records in different classes in terms of the predictor variables in the dataset.\nWhen the outcome variable has just two classes (Eg: Pass\/Fail; Fraudulent\/Not Fraudulent; Default\/No Default) binomial logistic regression is applied and multinomial logistic regression is applied if we have more than two classes (Eg: Buy\/Sell\/Hold).\nLogistic regression is a statistical technique and provides a detailed statistical summary in terms of statistical significance of the predictor variables and how each predictor variable impacts the probability of the classes of the Y variable. These unique qualities make this algorithm highly relevant to the Banking & Finance domain to provide detailed and numerical interpretation of the predictor variables.\n\n**Dataset**\n\nWe have a dataset that provides details from a bank about a \u2018Personal Loan\u2019 campaign that was executed by the bank. 20,000 customers were targeted with an offer of personal loan at 14% interest rate, out of which 2512 customers responded positively. The dataset and the data dictionary can be downloaded\nhere(\u200bhttps:\/\/www.kaggle.com\/itsmesunil\/bank-loan-modelling\/download) ","207ec322":"From above distribution , it is clear that more than 70% people spend less than $2200 per month\n","1f5f0a8c":"It can be seen that Family size also does not play a role in acceptance of a personal loan application if the income is high.","a782ccc2":"Out of all the three models , we see that the logistic regression model has the least accuracy for both training as well as test sets and the random forest model has the highest accuracy for both since it is an ensemble algorithm which takes into account the results of many classifiers and gives the best results.But accuracy is not a good measure.","25889637":"From above two scaling techniques,it is visible that minmaxscaler is a better method for this dataset as it gives a better normal distribution to the data ","9a363973":"From the result provided above , it is clear that no column has any null values . Thus,data imputation is not required."}}