{"cell_type":{"d098cccd":"code","cdefb6b1":"code","5c56dbc0":"code","cc27a6da":"code","b76095eb":"code","fd549c3e":"markdown"},"source":{"d098cccd":"import pandas as pd\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom xgboost import XGBRegressor","cdefb6b1":"df = pd.read_csv(\"..\/input\/30days-folds\/train_folds.csv\")\ndf_test = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\")\nsample_submission = pd.read_csv(\"..\/input\/30-days-of-ml\/sample_submission.csv\")","5c56dbc0":"useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\nobject_cols = [col for col in useful_features if col.startswith(\"cat\")]\ndf_test = df_test[useful_features]","cc27a6da":"final_predictions = []\nscores = []\nfor fold in range(5):\n    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n    xvalid = df[df.kfold == fold].reset_index(drop=True)\n    xtest = df_test.copy()\n\n    ytrain = xtrain.target\n    yvalid = xvalid.target\n    \n    xtrain = xtrain[useful_features]\n    xvalid = xvalid[useful_features]\n    \n    ordinal_encoder = preprocessing.OrdinalEncoder()\n    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n    \n    params = {'learning_rate': 0.07853392035787837, 'reg_lambda': 1.7549293092194938e-05, 'reg_alpha': 14.68267919457715, 'subsample': 0.8031450486786944, 'colsample_bytree': 0.170759104940733, 'max_depth': 3}\n    \n    model = XGBRegressor(\n        random_state=0, \n        #tree_method='gpu_hist',\n        #gpu_id=0,\n        #predictor=\"gpu_predictor\",\n        n_estimators=5000,\n        **params\n    )\n    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=1000)\n    preds_valid = model.predict(xvalid)\n    test_preds = model.predict(xtest)\n    final_predictions.append(test_preds)\n    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n    print(fold, rmse)\n    scores.append(rmse)\n\nprint(np.mean(scores), np.std(scores))","b76095eb":"preds = np.mean(np.column_stack(final_predictions), axis=1)\nsample_submission.target = preds\nsample_submission.to_csv(\"submission.csv\", index=False)","fd549c3e":"hyperparameter optimization notebook is here: https:\/\/www.kaggle.com\/abhishek\/competition-part-4-hyperparameter-tuning-optuna\/"}}