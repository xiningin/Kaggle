{"cell_type":{"00ecd02a":"code","cbd9d240":"code","73a6a10a":"code","c1463922":"code","d9d67d7a":"code","7322738a":"code","dddba09c":"code","57f9f9fa":"code","0666ca9c":"code","aa5cd131":"code","7e79b7d5":"markdown"},"source":{"00ecd02a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","cbd9d240":"import pandas as pd\nimport numpy as np\ndata=pd.read_csv(r'..\/input\/spam-or-not-spam-dataset\/spam_or_not_spam.csv')\ndata.head()\nfrom sklearn.utils import shuffle\ndata = shuffle(data)","73a6a10a":"\n\ndata['label'].value_counts()\n\n","c1463922":"text =[] \n  \n# Iterate over each row \nfor index, rows in data.iterrows(): \n    # Create list for the current row \n    my_list =str(rows.email)\n      \n    # append the list to the final list \n    text.append(my_list) \n  \n# Print the list \nlen(text)","d9d67d7a":"label=list(data['label'])","7322738a":"from keras.preprocessing.text import Tokenizer\ntokenizer = Tokenizer(num_words=1000)\ntokenizer.fit_on_texts(text)\nsequences = tokenizer.texts_to_sequences(text)","dddba09c":"x_train=sequences[:2000]\ny_train=label[:2000]\nx_test=sequences[2000:]\ny_test=label[2000:]","57f9f9fa":"\n\nmaxlen = 20\nfrom keras import preprocessing\nx_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\nx_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)\n\n","0666ca9c":"from keras.models import Sequential\nfrom keras.layers import Flatten, Dense\nfrom keras.layers import Embedding,SimpleRNN\nmodel = Sequential()\nmodel.add(Embedding(2000, 8, input_length=maxlen))\nmodel.add(SimpleRNN(32))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\nmodel.summary()\nhistory = model.fit(x_train, y_train,\n                    epochs=10,\n                    batch_size=32,\n                    validation_split=0.2)","aa5cd131":"result=model.evaluate(x_test,y_test)\nprint(\"test loss:{}\\ntest accuracy:{}\".format(result[0],result[1]))","7e79b7d5":"**Conclusion:**\n* If we have a sufficient length of input sequences, then RNN will works better than 1D NN.\n* By using 1D NN I have got :test loss:0.1240274314880371, test accuracy:0.9539999961853027"}}