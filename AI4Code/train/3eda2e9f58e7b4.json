{"cell_type":{"655bf8dc":"code","6e66a6b8":"code","6a128d0a":"code","283ae10e":"code","8c8da2a5":"code","a2313e68":"code","6515c0e9":"code","cbf48d2f":"code","de1f572f":"markdown","cc3b56bf":"markdown","2ff7d117":"markdown","d781b8a3":"markdown"},"source":{"655bf8dc":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.options.display.max_columns = 100\nimport time\nimport os\nprint(os.listdir(\"..\/input\"))\nimport warnings\nwarnings.simplefilter('ignore', FutureWarning)","6e66a6b8":"%%time\n# reading a subset of the data for EDA:\ntrain = pd.read_csv('..\/input\/train.csv', nrows=1000000, low_memory=False)\n\n# Distribution of interest variable in the training dataset:\nsns.countplot(train.HasDetections)","6a128d0a":"# Create a list of Numerical columns and Generate a summary of the data.\nnumeric_columns = train._get_numeric_data().columns\ntrain[numeric_columns].describe().T","283ae10e":"# What proportion of the data is missing:\n(train[numeric_columns].isnull().sum().sort_values(ascending = False)[:43]\/train.shape[0])[:37]","8c8da2a5":"# Create a list of Categorical columns and Generate a summary of the data.\ncategorical_columns = train[train.columns[~train.columns.isin(numeric_columns)]].columns\ntrain[categorical_columns].describe().T","a2313e68":"# Percentage of missing data in Categorical Columns\n(train[categorical_columns].isnull().sum().sort_values(ascending = False)[:43]\/train.shape[0])[:9]","6515c0e9":"# Step 2:\n\n# Getting list of columns with a constant value (This will be dropped later)\ndrop_these_columns = [c for c in train.columns if train[c].nunique(dropna=False)==1 ]\ndrop_these_columns","cbf48d2f":"# Step 3:\n\ndef plot_variables(var1, var2, arr=(16,6)):\n    plt.figure(figsize=arr)\n    plt.subplot(1, 2, 1)\n    sns.countplot(train[var1])\n    plt.xticks(rotation=45)\n    plt.subplot(1, 2, 2)\n    sns.barplot(train[var1], train[var2])\n    plt.xticks(rotation=90)\n    plt.tight_layout()\n    plt.show()\n#     print(pd.crosstab(train[var1], train[var2]).T)\n\n# Get understanding of the distribution and interaction of various features with the response variable:\nfor i in categorical_columns:\n    if train[i].nunique() < 15:  # limited to 15 so that the chart remains understandable\n        print(i)\n        plot_variables(i, \"HasDetections\")","de1f572f":"We see that the malware are almost equaly distributed so, we should check the interaction of various categorical features with the reposnse variable. This will help us select features for the modeling process. \n\nBefore working on the interactions lets get a quick overview of the data based:","cc3b56bf":"# Data Engineering and Model Building\n\nWill be uploaded asap!","2ff7d117":"** Process **\n* Step 1:  Summarize and understand the data:\n    * We subset the data into numeric only and categorical only and then describe them because if we use the [DOT] describe() on entire dataseet we will get a summary of the numeric only columns.\n* Step 2: Find Constant columns and remove them\n    * Remove them since there is no variance.\n* Step 3: Generate interactions","d781b8a3":"** All columns have more than 1 unique value!\n\n* A column is considered constant if it has a repeatable value and no missing value."}}