{"cell_type":{"1eb9ffb2":"code","fd92275d":"code","d251a14f":"code","3b67f40d":"code","0a9143b9":"code","338c170c":"markdown"},"source":{"1eb9ffb2":"import sys\n\nimport torch\nimport pandas as pd\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SequentialSampler\nfrom torchvision.models.densenet import densenet121\n\nsys.path.insert(0, \"\/kaggle\/input\/ghostnetbengali\")\n\nfrom ghost_net import ghost_net","fd92275d":"IMAGE_SIZE = 137, 236\n\n\nclass DatasetRetriever(Dataset):\n    \n    def __init__(self, df):\n        self.image_ids = df.iloc[:, 0].tolist()\n        self.images = torch.from_numpy(255 - df[[str(x) for x in range(32332)]].values)\n\n    def __len__(self):\n        return self.images.shape[0]\n\n    def __getitem__(self, idx):\n        img = self.images[idx]\n        img = img.view(*IMAGE_SIZE)\n        img = img.to(torch.float32) \/ 255.\n        img = img.unsqueeze(0)\n        img = img.repeat(3, 1, 1)\n        img_id = self.image_ids[idx]        \n        return img_id, img\n    \nclass Predictor:\n    def __init__(self, model):\n        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n        self.model = model.to(self.device, dtype=torch.float32);\n        self.model.eval()\n        print(f'Model prepared. Device is {self.device}')\n    \n    def predict(self, inputs):\n        inputs = inputs.to(self.device, dtype=torch.float32)\n        with torch.no_grad():\n            outputs = self.model(inputs)\n        return outputs\n\n    def load(self, path):\n        checkpoint = torch.load(path, map_location=self.device)\n        self.model.load_state_dict(checkpoint['model_state_dict'])","d251a14f":"predictors = []\n\nfor i, (model_path, net, coef) in enumerate([\n    ('\/kaggle\/input\/ghostnetbengali\/checkpoint.pt', ghost_net(num_classes=168+11+7), 0.5),\n    ('\/kaggle\/input\/ghostnetbengali\/densenet121-checkpoint.pt', densenet121(num_classes=168+11+7), 0.5),\n]):\n    predictor = Predictor(net)\n    predictor.load(model_path)\n    predictors.append((predictor, coef))\n\n\ndef predict_to_numpy(predict):\n    return torch.nn.functional.softmax(predict, dim=1).data.cpu().numpy().argmax(axis=1)\n\ndef make_prediction(images):\n    outputs = 0\n    for predictor, coef in predictors:\n        outputs += predictor.predict(images) * coef\n\n    roots = predict_to_numpy(outputs[:,:168])\n    vowels = predict_to_numpy(outputs[:,168:168+11])\n    consonants = predict_to_numpy(outputs[:,168+11:])\n    return roots, vowels, consonants","3b67f40d":"%%time\n\ntarget = []\nrow_id = []\n\nfor i in range(4):\n    data = pd.read_parquet(f'..\/input\/bengaliai-cv19\/test_image_data_{i}.parquet')\n    dataset = DatasetRetriever(data)\n    data_loader = DataLoader(dataset, batch_size=256, num_workers=4, shuffle=False, sampler=SequentialSampler(dataset))\n\n    for idx, (image_ids, images) in tqdm(enumerate(data_loader), total=len(data_loader)):\n\n        roots, vowels, consonants = make_prediction(images)\n\n        for image_id, root, vowel, consonant in zip(image_ids, roots, vowels, consonants):\n            row_id.append(image_id + '_consonant_diacritic')\n            target.append(consonant)\n            row_id.append(image_id + '_grapheme_root')\n            target.append(root)\n            row_id.append(image_id + '_vowel_diacritic')\n            target.append(vowel)","0a9143b9":"df_submission = pd.DataFrame(\n    {\n        'row_id': row_id,\n        'target': target\n    },\n    columns=['row_id','target']\n)\n\ndf_submission.to_csv('submission.csv', index=False)\n\ndf_submission.head(10)","338c170c":"### Thanks for your attention! Upvote pls"}}