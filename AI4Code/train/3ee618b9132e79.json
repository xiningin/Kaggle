{"cell_type":{"50e67899":"code","44b400fb":"code","a39165cf":"code","a41eda9a":"code","7c874313":"code","a6b9737d":"code","e1f865da":"code","b5ea4650":"code","12f80e05":"code","f8b3fb34":"code","b1caaece":"code","91c583e7":"code","9ddc8e73":"code","e9a1e76a":"code","173d45a6":"code","c84093f0":"code","e52a1003":"code","b153e7c4":"code","19084382":"code","15432729":"code","9d636ab9":"code","2b3323f6":"code","ebbaaa3d":"code","4672d1fb":"code","5c688d34":"code","f56af5e8":"code","4a35b987":"code","8557fc1e":"code","8f69a698":"code","d977885a":"code","eb6f8e8b":"code","8442e950":"code","230c3835":"code","56f963ac":"markdown","27ae833a":"markdown","92d476ea":"markdown","eafc1da2":"markdown"},"source":{"50e67899":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nimport random","44b400fb":"from sklearn.metrics import mean_absolute_error, r2_score\nfrom sklearn.model_selection import KFold","a39165cf":"from xgboost import XGBRegressor\nimport tensorflow as tf","a41eda9a":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\nseed_everything(0)","7c874313":"train = pd.read_csv('..\/input\/ingv-data\/Train.csv')\ntest = pd.read_csv('..\/input\/ingv-data\/Test.csv')","a6b9737d":"targets_df = pd.read_csv('..\/input\/predict-volcanic-eruptions-ingv-oe\/train.csv')","e1f865da":"train = train.merge(targets_df, right_on='segment_id', left_on='id').drop(['segment_id'], axis=1)","b5ea4650":"test_idx = test['id']\ntest.drop(['id'], axis=1, inplace=True)","12f80e05":"targets = train['time_to_eruption']\ntrain_idx = train['id']\ntrain = train.drop(['time_to_eruption','id'], axis=1)","f8b3fb34":"c_columns = [c for c in train.columns.tolist() if len(train[c].value_counts())>=40]","b1caaece":"len(c_columns)","91c583e7":"uni_val_cols = [c for c in train.columns.tolist() if len(train[c].value_counts())==1]","9ddc8e73":"len(uni_val_cols)","e9a1e76a":"cat_cols = [c for c in train.columns.tolist() if (len(train[c].value_counts())<40 and c not in uni_val_cols)]","173d45a6":"len(cat_cols)","c84093f0":"train_features = train.drop(uni_val_cols, axis=1)\ntest_features  = test .drop(uni_val_cols, axis=1)","e52a1003":"train.isna().sum().sum()","b153e7c4":"train_features.fillna(0, inplace=True)\ntest_features.fillna(0, inplace=True)","19084382":"train_features.reset_index(drop=True, inplace=True)\ntest_features.reset_index(drop=True, inplace=True)","15432729":"train_features.isna().sum().sum()","9d636ab9":"train_features[c_columns[10]].hist(bins=100)\nplt.show()","2b3323f6":"targets = pd.DataFrame(targets)\ntargets.reset_index(inplace=True)\ntargets.head()","ebbaaa3d":"y_train = targets['time_to_eruption']\ny_train.head()","4672d1fb":"def build_xgb_model(seed_):\n    xgb_meta = XGBRegressor(tree_method='gpu_hist',\n                            colsample_bytree=0.4,\n                             gamma=0,\n                            learning_rate=0.07,\n                            max_depth=3,\n                            min_child_weight=1.5,\n                            n_estimators=1000,\n                            reg_alpha=0.75,\n                            reg_lambda=0.45,\n                            subsample=0.6,\n                            seed=seed_)\n    return xgb_meta","5c688d34":"def run_xgb(X, y, X_test, fold, seed):\n    \n    seed_everything(seed)\n    \n    \n    train_mask = X['kfold'] != fold\n    valid_idc = X.loc[~train_mask].index\n    \n    X_train = X.loc[train_mask].reset_index(drop=True)\n    y_train = y.loc[train_mask].reset_index(drop=True)\n\n    \n    X_val = X.loc[~train_mask].reset_index(drop=True)\n    y_val = y.loc[~train_mask].reset_index(drop=True)\n    \n    X_train.drop(columns=['kfold'], inplace=True)\n    X_val.drop(columns=['kfold'], inplace=True)\n    \n    oof = np.zeros((X.shape[0], 1))\n    \n    model = build_xgb_model(seed)\n    \n    print(f'============={seed}========={fold}==================')\n    \n    model.fit(X_train, y_train)\n    train_loss = mean_absolute_error(y_train, model.predict(X_train))\n    print(f\"Seed: {seed}, FOLD: {fold}, train_loss: {train_loss}\")\n    valid_preds = model.predict(X_val)\n    oof[valid_idc] = valid_preds.reshape((len(valid_preds),1))\n    valid_loss = mean_absolute_error(y_val, valid_preds)\n    print(f\"Seed: {seed}, FOLD: {fold}, val_loss: {valid_loss}\")\n    #------------------ Predictions -------------------\n\n    predictions = np.zeros((X_test.shape[0], 1))\n    predictions = model.predict(X_test[X_train.columns]).reshape((len(X_test),1))\n    \n    return oof, predictions","f56af5e8":"def run_k_fold_xgb(X, y, X_test, seed):\n    oof = np.zeros((train_features.shape[0], 1))\n    predictions = np.zeros((test_features.shape[0], 1))\n    \n    for fold in range(N_FOLDS):\n        oof_, pred_ = run_xgb(X, y, X_test, fold, seed)\n        \n        predictions += pred_ \/ N_FOLDS\n        oof += oof_\n        \n    return oof, predictions","4a35b987":"N_FOLDS = 10","8557fc1e":"# Averaging on multiple SEEDS\n\nseeds = [0, 1, 2, 3, 4, 5, 6]\noof = np.zeros((train_features.shape[0], 1))\npredictions = np.zeros((test_features.shape[0], 1))\n\nfor seed in seeds:\n    folds = train_features.copy()\n    folds['idx'] = train_idx\n    folds['kfold'] = np.zeros(len(folds))\n    kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)\n    for f, (t_idx, v_idx) in enumerate(kf.split(train_features)) :\n        folds.loc[v_idx, 'kfold'] = int(f)\n    folds['kfold'] = folds['kfold'].astype(int)\n    oof_, predictions_ = run_k_fold_xgb(folds.drop(['idx'], axis=1), y_train, test_features, seed)\n    oof += oof_ \/ len(seeds)\n    predictions += predictions_ \/ len(seeds)","8f69a698":"print(\"CV MAE = {}\".format(mean_absolute_error(y_train, oof)))\nprint(\"CV R2 = {}\".format(r2_score(y_train, oof)))","d977885a":"submission = pd.read_csv('..\/input\/predict-volcanic-eruptions-ingv-oe\/sample_submission.csv')\nsubmission.head()","eb6f8e8b":"preds = pd.DataFrame()\npreds['segment_id'] = test_idx\npreds['time_to_eruption'] = predictions\npreds.head(2)","8442e950":"submission = submission.drop(['time_to_eruption'], axis=1).merge(preds, on='segment_id')","230c3835":"submission.to_csv('submission.csv', header=True, index=False)","56f963ac":"## 1- Data Processing","27ae833a":"For data I used a preprocessed data that I uploaded into kaggle. I will share the used notebook for producing the used features. I used classic statistical features (e.g. mean, rms, etc..) on each of the sensor signals, their first and second derivatives, the cummulative sum of the sensor values, and the wavelet transformation. ","92d476ea":"## 3- Predictions","eafc1da2":"## 2- Modeling"}}