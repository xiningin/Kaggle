{"cell_type":{"0434658d":"code","d1c4c150":"code","67871414":"code","66f66ba5":"code","c80b6012":"code","368222db":"code","edf5b44e":"code","588e5b8b":"code","2e4a0fbe":"code","3832b48d":"code","bc3c9b1d":"code","e86e9235":"code","f44cc274":"code","cb4aa8eb":"code","d980dc0b":"code","1832bebb":"code","7ca80dab":"code","5e01e1b9":"code","00a78f6b":"code","d2554872":"code","cef816d3":"code","7b5fcbbf":"code","61ac2f85":"code","a9d6e8e7":"code","92e8a77f":"code","2e7f0cf1":"code","8d3cb8f3":"code","fc7b0b59":"code","9980199c":"code","3ddc7d9c":"code","5c9649aa":"code","c09bd8f2":"code","6b4e18c2":"code","2e25580d":"code","9febf57a":"code","aa3c7e04":"code","109052ef":"code","64451143":"code","210b1d1f":"code","8a85981f":"code","a74b99a2":"code","c8f2765a":"code","a52d9022":"code","40d91c35":"code","916ad2f7":"markdown","50339617":"markdown","991befd8":"markdown"},"source":{"0434658d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","d1c4c150":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.layers import Flatten, Reshape, GlobalAveragePooling1D\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers import Conv1D, GlobalMaxPooling1D\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers.convolutional import Conv1D, Conv2D\nfrom keras.layers.convolutional import MaxPooling1D,MaxPooling2D\nimport keras","67871414":"# nRowsRead = 1000 # specify 'None' if want to read whole file\n# Control.csv may have more rows in reality, but we are only loading\/previewing the first 1000 rows\ndf1 = pd.read_csv('\/kaggle\/input\/quality-diplom\/Control.csv', delimiter=',')\ndf1.dataframeName = 'Control.csv'\nnRow, nCol = df1.shape\nprint(f'There are {nRow} rows and {nCol} columns')\ndf2 = pd.read_csv('\/kaggle\/input\/quality-diplom\/Quality.csv', delimiter='\\t')\ndf2.dataframeName = 'Quality.csv'\nnRow, nCol = df2.shape\nprint(f'There are {nRow} rows and {nCol} columns')","66f66ba5":"df_control = df1\ndf_quality = df2","c80b6012":"df_control = df_control.drop('Unnamed: 0', axis=1).set_index('date')","368222db":"df_quality = df_quality.drop('Unnamed: 0', axis=1).set_index('date')","edf5b44e":"df_control.drop([col for col in df1.columns if col.startswith('Wickler')],\n                 axis=1, inplace=True)","588e5b8b":"sum(df_quality['Stippe_-3000'].isna())","2e4a0fbe":"df_quality['Stippe_-3000'].median()","3832b48d":"df_quality['Stippe_-3000'] = df_quality['Stippe_-3000'].fillna(df_quality['Stippe_-3000'].median())","bc3c9b1d":"sum(df_quality['Stippe_-3000'].isna())","e86e9235":"df_quality[df_quality['Stippe_-3000'].isna()]['Stippe_-3000']","f44cc274":"treshold = 47.5\n# y = df_quality['Stippe_-3000'] > treshold\ny = df_quality['Stippe_-3000'] > treshold\nX = df_control\n#\u0424\u0418\u041d\u0422 \u0423\u0428\u0410\u041c\u0418)))))\n# X['y'] = y\n# X = X.T.shape","cb4aa8eb":"df_quality['Stippe_-3000']","d980dc0b":"y = pd.DataFrame(y)\ny.head()","1832bebb":"y['Stippe_-3000'] = y['Stippe_-3000'].astype(float)","7ca80dab":"X.head()","5e01e1b9":"from sklearn.preprocessing import StandardScaler, MinMaxScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)\n# y = sc.fit_transform(y)","00a78f6b":"y = y.astype(float)","d2554872":"X_df_scaller = pd.DataFrame(X, columns=df_control.columns, index=df_control.index)\nX_df_scaller.tail()","cef816d3":"X_df_scaller = X_df_scaller.merge(y, left_index=True, right_index=True, how='outer')","7b5fcbbf":"X_df_scaller.head()","61ac2f85":"X = X_df_scaller.values","a9d6e8e7":"def split_sequences(sequences, n_steps):\n\tX, y = list(), list()\n\tfor i in range(len(sequences)):\n\t\t# find the end of this pattern\n\t\tend_ix = i + n_steps\n\t\t# check if we are beyond the dataset\n\t\tif end_ix > len(sequences):\n\t\t\tbreak\n\t\t# gather input and output parts of the pattern\n\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n\t\tX.append(seq_x)\n\t\ty.append(seq_y)\n\treturn np.array(X), np.array(y)","92e8a77f":"n_steps = 5","2e7f0cf1":"X, y = split_sequences(X_df_scaller.values, n_steps)","8d3cb8f3":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","fc7b0b59":"X_train.shape","9980199c":"n_features = X.shape[2]","3ddc7d9c":"(n_steps, n_features)","5c9649aa":"from keras.utils.vis_utils import plot_model","c09bd8f2":"n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[0]\nverbose, epochs, batch_size, n_filters = 0, 2, 32, 32\nn_kernel = 2\nmodel = Sequential()\n\nmodel.add(Conv1D(filters=256, kernel_size=1, dilation_rate=1, padding='valid', activation='relu', input_shape=(n_timesteps,n_features)))\nmodel.add(Conv1D(filters=128, kernel_size=1, dilation_rate=1, padding='valid', activation='relu'))\nmodel.add(MaxPooling1D(pool_size=4))\nmodel.add(MaxPooling1D(pool_size=1))\nmodel.add(MaxPooling1D(pool_size=1))\nmodel.add(Flatten())\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dense(1))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\n# plot_model(model_cnn_02, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n#binary_crossentropy","6b4e18c2":"callbacks_list = [\n#     keras.callbacks.ModelCheckpoint(\n#         filepath='best_model.{epoch:02d}-val_accuracy:{val_accuracy:.2f}.h5',\n#         monitor='val_accuracy', save_best_only=True),\n    keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15)\n]\n\nhistory = model.fit(X_train, y_train, epochs=10, batch_size=batch_size,validation_split=0.3, verbose=1,callbacks=callbacks_list,)","2e25580d":"import matplotlib.pyplot as plt\nplt.plot(history.history['loss'], label=\"loss\")\nplt.plot(history.history['val_loss'], label=\"val_loss\")\nplt.plot(history.history['accuracy'], label=\"accuracy\")\n\n\nplt.plot(history.history['val_accuracy'], label=\"val_accuracy\")\nplt.xlabel('epoch')\nplt.legend()\nplt.show()\nyhat_02 = model.predict(X_test)\npredicts02 = yhat_02[:,0]\nroc_auc_score(y_test, predicts02)\n# yhat_02","9febf57a":"fpr, tpr, threshold = roc_curve(y_test, predicts02)\nroc_auc = auc(fpr, tpr)\nplt.figure(figsize=(8,7))\nplt.plot(fpr, tpr, label='cnn (area = %0.3f)' % roc_auc, linewidth=2)\n# plt.plot(fpr_cnn, tpr_cnn, label='w2v-CNN (area = %0.3f)' % roc_auc_nn, linewidth=2)\n\nplt.plot([0, 1], [0, 1], 'k--', linewidth=2)\nplt.xlim([-0.05, 1.0])\nplt.ylim([-0.05, 1.05])\nplt.xlabel('False Positive Rate', fontsize=18)\nplt.ylabel('True Positive Rate', fontsize=18)\nplt.title('Receiver operating characteristic: is positive', fontsize=18)\nplt.legend(loc=\"lower right\")\nplt.show()","aa3c7e04":"model.save_weights(\"model_roc=\"+str(round(roc_auc,2))+\".h5\")\n","109052ef":"# predicts = yhat[:,0]\npredicts02 = yhat_02[:,0]","64451143":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve, auc\n","210b1d1f":"# predicts = predicts  > 0.99\npredicts02 = predicts02 > 0.99","8a85981f":"# predicts = predicts.astype(int)\npredicts02 = predicts02.astype(int)","a74b99a2":"roc_auc_score(y_test, predicts02)","c8f2765a":"confusion_matrix(y_test, predicts02)","a52d9022":"fpr, tpr, threshold = roc_curve(y_test, predicts02)\nroc_auc = auc(fpr, tpr)","40d91c35":"# fpr_cnn, tpr_cnn, threshold = roc_curve(y_test, predicts)\n# roc_auc_nn = auc(fpr_cnn, tpr_cnn)\nplt.figure(figsize=(8,7))\nplt.plot(fpr, tpr, label='cnn (area = %0.3f)' % roc_auc, linewidth=2)\n# plt.plot(fpr_cnn, tpr_cnn, label='w2v-CNN (area = %0.3f)' % roc_auc_nn, linewidth=2)\n\nplt.plot([0, 1], [0, 1], 'k--', linewidth=2)\nplt.xlim([-0.05, 1.0])\nplt.ylim([-0.05, 1.05])\nplt.xlabel('False Positive Rate', fontsize=18)\nplt.ylabel('True Positive Rate', fontsize=18)\nplt.title('Receiver operating characteristic: is positive', fontsize=18)\nplt.legend(loc=\"lower right\")\nplt.show()","916ad2f7":"\u0412\u043e\u0442 \u044d\u0442\u0430 \u043c\u043e\u0434\u0435\u043b\u044c \u0432\u0440\u043e\u0434\u0435 \u043b\u0443\u0447\u0448\u0435 \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442","50339617":"\u041c\u0430\u0448\u0442\u0430\u0431\u0438\u0440\u0443\u0435\u043c","991befd8":"\u0423\u0434\u0430\u043b\u044f\u0435\u043c \u043d\u0430\u043c\u043e\u0442\u043a\u0443 \u0442\u0430\u043a \u043a\u0430\u043a \u043e\u043d\u0430 \u043f\u043e\u0441\u043b\u0435 \u0434\u0430\u0442\u0447\u0438\u043a\u043e\u0432 \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0438 \u043d\u0430 \u0431\u043b\u044d\u043a \u0434\u043e\u0442"}}