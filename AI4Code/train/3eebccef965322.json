{"cell_type":{"ca57aae1":"code","2885d339":"code","622b406d":"code","1906130b":"code","2a386924":"code","a0a4d095":"code","ecaae899":"code","0073de1c":"code","b292844b":"code","b6a2995b":"code","0411c44b":"code","402a13db":"code","14f2d996":"code","d0612270":"code","3e827115":"code","c8295e31":"code","86343fed":"code","88df7e19":"code","481bd5f7":"code","0501ff60":"code","88c84e96":"code","1c56165b":"code","0f5925b9":"code","ae7c13cf":"code","de274378":"code","78a07de5":"code","602365c5":"code","b31fac00":"code","8e5b9dee":"code","5734d81a":"code","561f8fb8":"code","7ad10f25":"code","c7ff0312":"code","349ba543":"code","a5015320":"code","344e1682":"code","8dc5efa4":"code","1cad4b9e":"code","a7c64909":"code","a2ab52ce":"code","103d27da":"code","471fd2d3":"code","58f15469":"markdown","19ac947a":"markdown","b6ab2cc7":"markdown","5ee7de4d":"markdown","9d9714f5":"markdown","96860c52":"markdown","5ba4f89c":"markdown","f3643774":"markdown","548bdb8b":"markdown","b7ef5a39":"markdown","aadcee45":"markdown","c2dca40e":"markdown","77afcff5":"markdown"},"source":{"ca57aae1":"#!pip install -U tensorflow","2885d339":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport time, gc\nimport tensorflow as tf\nfrom PIL import Image\nprint(tf.__version__)\n\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt\nimport matplotlib\nmatplotlib.use('Agg')\n\n# import the necessary keras and sklearn packages\n\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\n\nimport random\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","622b406d":"train_df_ = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/train.csv')\ntest_df_ = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/test.csv')\nclass_map_df = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/class_map.csv')\nsample_sub_df = pd.read_csv('\/kaggle\/input\/bengaliai-cv19\/sample_submission.csv')","1906130b":"train_df_.head()","2a386924":"len(train_df_)","a0a4d095":"test_df_.head()","ecaae899":"len(test_df_)","0073de1c":"sample_sub_df.head()","b292844b":"class_map_df.head()","b6a2995b":"class_map_df.component_type.value_counts()","0411c44b":"class_map_df_root = class_map_df[class_map_df.component_type=='grapheme_root']\nclass_map_df_vowel = class_map_df[class_map_df.component_type=='vowel_diacritic']\nclass_map_df_cons = class_map_df[class_map_df.component_type=='consonant_diacritic']","402a13db":"graphemeLB = LabelBinarizer()\nvowelLB = LabelBinarizer()\nconsonantLB = LabelBinarizer()\n\ngraphemeLB.fit(class_map_df_root.label)\nvowelLB.fit(class_map_df_vowel.label)\nconsonantLB.fit(class_map_df_cons.label)","14f2d996":"print(len(vowelLB.classes_))\nprint(len(consonantLB.classes_))\nprint(len(graphemeLB.classes_))","d0612270":"print(f'Size of training data: {train_df_.shape}')\nprint(f'Size of test data: {test_df_.shape}')\nprint(f'Size of class map: {class_map_df.shape}')","3e827115":"train_df_groot = train_df_.groupby(['grapheme_root']).size().reset_index()\ntrain_df_groot=train_df_groot.rename(columns={0:'count'})","c8295e31":"class_map_df_groot = class_map_df[class_map_df.component_type=='grapheme_root']\ngroot_merged = pd.merge(train_df_groot,class_map_df_groot[['label','component']],left_on='grapheme_root',right_on='label',how='inner')\ngroot_merged.sort_values(by=\"count\",ascending=False)[:10]","86343fed":"train_df_vd = train_df_.groupby(['vowel_diacritic']).size().reset_index()\ntrain_df_vd=train_df_vd.rename(columns={0:'count'})\nclass_map_df_vd = class_map_df[class_map_df.component_type=='vowel_diacritic']\nvd_merged = pd.merge(train_df_vd,class_map_df_vd[['label','component']],left_on='vowel_diacritic',right_on='label',how='inner')\nvd_merged.sort_values(by=\"count\",ascending=False)[:10]","88df7e19":"train_df_cd = train_df_.groupby(['consonant_diacritic']).size().reset_index()\ntrain_df_cd=train_df_cd.rename(columns={0:'count'})\nclass_map_df_cd = class_map_df[class_map_df.component_type=='consonant_diacritic']\ncd_merged = pd.merge(train_df_cd,class_map_df_cd[['label','component']],left_on='consonant_diacritic',right_on='label',how='inner')\ncd_merged.sort_values(by=\"count\",ascending=False)[:5]","481bd5f7":"def read_data(nf):\n    nf=int(nf)\n    train_df = pd.read_feather(f'\/kaggle\/input\/bengaliaicv19feather\/train_image_data_{nf}.feather')\n    return train_df\n\ndef read_test_data(nf):\n    nf=int(nf)\n    test_df = pd.read_feather(f'\/kaggle\/input\/bengaliaicv19feather\/test_image_data_{nf}.feather')\n    return test_df","0501ff60":"train_df=read_data(1)","88c84e96":"train_df.head()","1c56165b":"%matplotlib inline\nimport sys\nimg = train_df.iloc[0,1:]\nimg=img.astype('float')\nimg = np.array(img).reshape(137,236)\nplt.imshow(img);\n#plt.savefig(sys.stdout)","0f5925b9":"img = train_df.iloc[10,1:]\nimg=img.astype('float32')\nimg = np.array(img).reshape(137,236)\n# Construct image object from array, needed for resizing\nimg = Image.fromarray(img)\nplt.imshow(img);\n#plt.savefig(sys.stdout.buffer)","ae7c13cf":"img_resized = img.resize((96,96))\nplt.imshow(img_resized);\n#plt.savefig(sys.stdout.buffer)","de274378":"def plot_image(image):\n    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n    plt.axis(\"off\")","78a07de5":"def dataset_shapes(dataset):\n    try:\n        return [x.get_shape().as_list() for x in dataset._tensors]\n    except TypeError:\n        return dataset._tensors.get_shape().as_list()","602365c5":"EPOCHS = 5\nINIT_LR = 1e-3\nBS = 64","b31fac00":"class BengaliNet:\n    @staticmethod\n    def build_grapheme_branch(inputs, numGraphemes,finalAct=tf.nn.softmax, chanDim=-1):\n \n        x = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.nn.relu)(inputs)\n        x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n        x = tf.keras.layers.MaxPooling2D(pool_size=(3, 3))(x)\n        x = tf.keras.layers.Dropout(0.25)(x)\n        print(x.shape)\n        x = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu)(x)\n        x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n        x = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu)(x)\n        x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n        x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n        x = tf.keras.layers.Dropout(0.25)(x)\n        print(x.shape)\n        x = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.nn.relu)(x)\n        x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n        x = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.nn.relu)(x)\n        x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n        x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n        x = tf.keras.layers.Dropout(0.25)(x)\n        \n        print(x.shape)\n        x = tf.keras.layers.Conv2D(256, (3, 3), activation=tf.nn.relu)(x)\n        x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n        x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n        x = tf.keras.layers.Dropout(0.25)(x)\n        \n        x = tf.keras.layers.Flatten()(x)\n        print(x.shape)\n        x = tf.keras.layers.Dense(256,activation=tf.nn.relu)(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Dropout(0.5)(x)\n        x = tf.keras.layers.Dense(numGraphemes)(x)\n        x = tf.keras.layers.Activation(finalAct, name=\"grapheme_output\")(x)\n \n        # return the Grapheme prediction sub-network\n        return x\n    \n    @staticmethod\n    def build_vowel_branch(inputs, numVowels, finalAct=tf.nn.softmax,chanDim=-1):\n\n        x = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.nn.relu)(inputs)\n        x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n        x = tf.keras.layers.MaxPooling2D(pool_size=(3, 3))(x)\n        x = tf.keras.layers.Dropout(0.25)(x)\n        print(x.shape)\n        x = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu)(x)\n        x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n        x = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu)(x)\n        x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n        x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n        x = tf.keras.layers.Dropout(0.25)(x)\n        \n        x = tf.keras.layers.Flatten()(x)\n        print(x.shape)\n        x = tf.keras.layers.Dense(1024,activation=tf.nn.relu)(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Dropout(0.5)(x)\n        x = tf.keras.layers.Dense(512,activation=tf.nn.relu)(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Dropout(0.5)(x)\n        x = tf.keras.layers.Dense(256,activation=tf.nn.relu)(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Dropout(0.5)(x)\n        x = tf.keras.layers.Dense(numVowels)(x)\n        x = tf.keras.layers.Activation(finalAct, name=\"vowel_output\")(x)\n\n        # return the vowel prediction sub-network\n        return x\n    \n    @staticmethod\n    def build_consonant_branch(inputs, numConsonants, finalAct=tf.nn.softmax,chanDim=-1):\n\n        x = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.nn.relu)(inputs)\n        x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n        x = tf.keras.layers.MaxPooling2D(pool_size=(3, 3))(x)\n        x = tf.keras.layers.Dropout(0.25)(x)\n        print(x.shape)\n        x = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu)(x)\n        x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n        x = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu)(x)\n        x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n        x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n        x = tf.keras.layers.Dropout(0.25)(x)\n       \n        x = tf.keras.layers.Flatten()(x)\n        print(x.shape)\n        x = tf.keras.layers.Dense(1024,activation=tf.nn.relu)(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Dropout(0.5)(x)\n        x = tf.keras.layers.Dense(512,activation=tf.nn.relu)(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Dropout(0.5)(x)\n        x = tf.keras.layers.Dense(256,activation=tf.nn.relu)(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = tf.keras.layers.Dropout(0.5)(x)\n        x = tf.keras.layers.Dense(numConsonants)(x)\n        x = tf.keras.layers.Activation(finalAct, name=\"consonant_output\")(x)\n\n        # return the consonant prediction sub-network\n        return x\n    \n    @staticmethod\n    def build(width, height, numGraphemes, numVowels, numConsonants, finalAct=tf.nn.softmax):\n        # initialize the input shape and channel dimension (this code\n        # assumes you are using TensorFlow which utilizes channels\n        # last ordering)\n        inputShape = (height, width,1)\n        chanDim = -1\n\n        # construct both the \"grapheme\" , \"vowel\", and \"consonant\" sub-networks\n        inputs = tf.keras.layers.Input(shape=inputShape)\n        graphemeBranch = BengaliNet.build_grapheme_branch(inputs,\n            numGraphemes, finalAct=finalAct, chanDim=chanDim)\n        vowelBranch = BengaliNet.build_vowel_branch(inputs,\n            numVowels, finalAct=finalAct, chanDim=chanDim)\n        consonantBranch = BengaliNet.build_consonant_branch(inputs,\n            numConsonants, finalAct=finalAct, chanDim=chanDim)\n\n        # create the model using our input (the batch of images) and\n        # three separate outputs -- one for the grapheme\n        # branch, the vowel branch, and consonant branch respectively\n        model = tf.keras.models.Model(\n            inputs=inputs,\n            outputs=[graphemeBranch, vowelBranch, consonantBranch],\n            name=\"Bengalinet\")\n\n        # return the constructed network architecture\n        return model","8e5b9dee":"def build_model():\n    inputs = tf.keras.layers.Input(shape = (96, 96, 1))\n\n    x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation=tf.nn.relu)(inputs)\n    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n    print(x.shape)\n    x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation=tf.nn.relu)(x)\n    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n    print(x.shape)\n    x = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation=tf.nn.relu)(x)\n    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n    print(x.shape)\n    x = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation=tf.nn.relu)(x)\n    x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n    print(x.shape)\n    x = tf.keras.layers.BatchNormalization(momentum=0.15)(x)\n    x = tf.keras.layers.Dropout(rate=0.25)(x)\n    print(x.shape)\n    x0 = tf.keras.layers.Flatten()(x)\n    print(x.shape)\n    x = tf.keras.layers.Dense(1024, activation = tf.nn.relu)(x0)\n    x = tf.keras.layers.Dense(512, activation = tf.nn.relu)(x)\n    x = tf.keras.layers.Dense(256, activation = tf.nn.relu)(x)\n    x = tf.keras.layers.Dropout(rate=0.25)(x)\n    head_root = tf.keras.layers.Dense(168, activation = tf.nn.softmax,name=\"grapheme_output\")(x)\n    \n    x1 = tf.keras.layers.Dense(1024, activation = tf.nn.relu)(x0)\n    x1 = tf.keras.layers.Dense(512, activation = tf.nn.relu)(x1)\n    x1 = tf.keras.layers.Dense(256, activation = tf.nn.relu)(x1)\n    x1 = tf.keras.layers.Dropout(rate=0.25)(x1)\n    head_vowel = tf.keras.layers.Dense(11, activation = tf.nn.softmax,name=\"vowel_output\")(x1)\n    \n    x2 = tf.keras.layers.Dense(1024, activation = tf.nn.relu)(x0)\n    x2 = tf.keras.layers.Dense(512, activation = tf.nn.relu)(x2)\n    x2 = tf.keras.layers.Dense(256, activation = tf.nn.relu)(x2)\n    x2 = tf.keras.layers.Dropout(rate=0.25)(x2)\n    head_consonant = tf.keras.layers.Dense(7, activation = tf.nn.softmax,name=\"consonant_output\")(x2)\n\n    model = tf.keras.models.Model(inputs=inputs, outputs=[head_root, head_vowel, head_consonant])\n    return model","5734d81a":"#model = BengaliNet.build(96, 96,numGraphemes=len(graphemeLB.classes_),numVowels=len(vowelLB.classes_),numConsonants=len(consonantLB.classes_),finalAct=tf.nn.softmax)\nmodel = build_model()\n# define two dictionaries: one that specifies the loss method for\n# each output of the network along with a second dictionary that\n# specifies the weight per loss\nlosses = {\n    \"grapheme_output\": \"categorical_crossentropy\",\n    \"vowel_output\": \"categorical_crossentropy\",\n    \"consonant_output\": \"categorical_crossentropy\"\n}\nlossWeights = {\"grapheme_output\": 1.0, \"vowel_output\": 1.0, \"consonant_output\":1.0}\n\n# initialize the optimizer and compile the model\nprint(\"[INFO] compiling model...\")\nopt = tf.keras.optimizers.Adam(lr=INIT_LR, decay=INIT_LR \/ EPOCHS)\nmodel.compile(optimizer=opt, loss=losses, loss_weights=lossWeights,metrics=[\"accuracy\"])","561f8fb8":"histories = []\n\nfor i in range(4):\n    graphemeLabels = []\n    vowelLabels = []\n    consonantLabels = []\n    train_df = pd.merge(read_data(i), train_df_, on='image_id').drop(['image_id','grapheme'], axis=1)\n    train_df=train_df.astype('uint8')\n    graphemeLabels = train_df.grapheme_root[0:1000]\n    train_df=train_df.drop(\"grapheme_root\",axis=1)\n    vowelLabels = train_df.vowel_diacritic[0:1000]\n    train_df=train_df.drop(\"vowel_diacritic\",axis=1)\n    consonantLabels = train_df.consonant_diacritic[0:1000]\n    train_df=train_df.drop(\"consonant_diacritic\",axis=1)\n    # convert the label lists to NumPy arrays prior to binarization\n    graphemeLabels = np.array(graphemeLabels)\n    vowelLabels = np.array(vowelLabels)\n    consonantLabels = np.array(consonantLabels)\n\n    # binarize all three sets of labels\n    print(\"[INFO] binarizing labels...\")\n    graphemeLabels = graphemeLB.transform(graphemeLabels)\n    vowelLabels = vowelLB.transform(vowelLabels)\n    consonantLabels = consonantLB.transform(consonantLabels)\n\n    print(graphemeLabels.shape)\n    print(vowelLabels.shape)\n    print(consonantLabels.shape)\n\n    (trainX, testX, trainGraphemeY, testGraphemeY,trainVowelY, testVowelY,trainConsonantY,testConsonantY) = train_test_split(train_df[0:1000], graphemeLabels, vowelLabels,consonantLabels,test_size=0.1, random_state=42)\n    del train_df\n    del graphemeLabels\n    del vowelLabels\n    del consonantLabels\n    gc.collect()\n    \n    trainX=np.array(trainX).reshape(-1,137,236,1)\n    print(\"[INFO] creating train dataset...\")\n    print(trainX.shape)\n    resized_image=[]\n    for i in range(len(trainX)):\n        resized_img = tf.image.resize(trainX[i],[96,96])\n        resized_img=np.array(resized_img)\/255.\n        resized_image.append(resized_img)\n    train_set=tf.data.Dataset.from_tensor_slices(resized_image).batch(BS).prefetch(1)\n        \n    testX=np.array(testX).reshape(-1,137,236,1)\n    print(\"[INFO] creating validation dataset...\")\n    print(testX.shape)\n    resized_image=[]\n    for i in range(len(testX)):\n        resized_img = tf.image.resize(testX[i],[96,96])\n        resized_img=np.array(resized_img)\/255.\n        resized_image.append(resized_img)\n    test_set=tf.data.Dataset.from_tensor_slices(resized_image).batch(BS).prefetch(1)\n    \n    train_Y=tf.data.Dataset.from_tensor_slices((trainGraphemeY, trainVowelY, trainConsonantY)).batch(BS).prefetch(1)\n    test_Y=tf.data.Dataset.from_tensor_slices((testGraphemeY, testVowelY, testConsonantY)).batch(BS).prefetch(1)\n    \n    dataset  = tf.data.Dataset.zip((train_set, train_Y))\n    val_dataset  = tf.data.Dataset.zip((test_set, test_Y))\n    \n    print(\"[INFO] Model.fit starting...\")\n    history=model.fit(dataset,validation_data=val_dataset,epochs=EPOCHS)\n\n    histories.append(history)\n    \n    del train_set\n    del test_set\n    del train_Y\n    del test_Y\n    del resized_image\n    del trainX\n    del testX\n    gc.collect()","7ad10f25":" #print(\"[INFO] creating train dataset augmentation set...\")\n #   # we create two instances with the same arguments\n #   data_gen_args = dict(featurewise_center=True,\n #                    featurewise_std_normalization=True,\n #                    rotation_range=90,\n #                    width_shift_range=0.1,\n #                    height_shift_range=0.1,\n #                    zoom_range=0.2)\n #   image_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**data_gen_args)\n #   mask_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**data_gen_args)\n #   # Provide the same seed and keyword arguments to the fit and flow methods\n #   seed = 1\n #   image_datagen.fit(resized_image, augment=True, seed=seed)\n #   mask_datagen.fit((trainGraphemeY, trainVowelY, trainConsonantY), augment=True, seed=seed)\n #   image_generator = image_datagen.flow(resized_image,seed=seed)\n #   mask_generator = mask_datagen.flow((trainGraphemeY, trainVowelY, trainConsonantY), seed=seed)\n #   train_generator = zip(image_generator, mask_generator)\n #      history=model.fit_generator(train_generator,epochs=EPOCHS)","c7ff0312":"def plot_loss(his, epoch, title):\n    plt.style.use('ggplot')\n    plt.figure()\n    plt.plot(np.arange(0, epoch), his.history['loss'], label='train_loss')\n    plt.plot(np.arange(0, epoch), his.history['grapheme_output_loss'], label='train_root_loss')\n    plt.plot(np.arange(0, epoch), his.history['vowel_output_loss'], label='train_vowel_loss')\n    plt.plot(np.arange(0, epoch), his.history['consonant_output_loss'], label='train_consonant_loss')\n    \n    plt.plot(np.arange(0, epoch), his.history['val_grapheme_output_loss'], label='val_root_loss')\n    plt.plot(np.arange(0, epoch), his.history['val_vowel_output_loss'], label='val_vowel_loss')\n    plt.plot(np.arange(0, epoch), his.history['val_consonant_output_loss'], label='val_consonant_loss')\n    \n    plt.title(title)\n    plt.xlabel('Epoch #')\n    plt.ylabel('Loss')\n    plt.legend(loc='upper right')\n    plt.show()\n   # plt.savefig(sys.stdout.buffer)\n\ndef plot_acc(his, epoch, title):\n    plt.style.use('ggplot')\n    plt.figure()\n    plt.plot(np.arange(0, epoch), his.history['grapheme_output_accuracy'], label='train_root_acc')\n    plt.plot(np.arange(0, epoch), his.history['vowel_output_accuracy'], label='train_vowel_accuracy')\n    plt.plot(np.arange(0, epoch), his.history['consonant_output_accuracy'], label='train_consonant_accuracy')\n    \n    plt.plot(np.arange(0, epoch), his.history['val_grapheme_output_accuracy'], label='val_root_acc')\n    plt.plot(np.arange(0, epoch), his.history['val_vowel_output_accuracy'], label='val_vowel_accuracy')\n    plt.plot(np.arange(0, epoch), his.history['val_consonant_output_accuracy'], label='val_consonant_accuracy')\n    plt.title(title)\n    plt.xlabel('Epoch #')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='upper right')\n    plt.show()\n    #plt.savefig(sys.stdout.buffer)","349ba543":"for dataset in range(4):\n    plot_loss(histories[dataset], EPOCHS, f'Training Dataset: {dataset}')\n    plot_acc(histories[dataset], EPOCHS, f'Training Dataset: {dataset}')","a5015320":"test_df_0=read_test_data(0)\ntest_df_1=read_test_data(1)\ntest_df_2=read_test_data(2)\ntest_df_3=read_test_data(3)\n\ntest_df = pd.concat([test_df_0,test_df_1,test_df_2,test_df_3])","344e1682":"test_df=test_df.drop(['image_id'],axis=1)\ntest_df.head()","8dc5efa4":"#Create Test Set in same way as Train \/ validation set\ntestX=np.array(test_df).reshape(-1,137,236,1)\nprint(\"[INFO] creating test dataset from test images\")\nprint(testX.shape)\nresized_image=[]\nfor i in range(len(testX)):\n    resized_img = tf.image.resize(testX[i],[96,96])\n    resized_img=np.array(resized_img)\/255.\n    resized_image.append(resized_img)\n    test_set=tf.data.Dataset.from_tensor_slices(resized_image).batch(BS).prefetch(1)\n\nprint(\"INFO Now predicting probabilities for Test set\")\n(graphemeProba, vowelProba, consonantProba) = model.predict(test_set)","1cad4b9e":"#Check the probability values for grapheme\ngraphemeProba","a7c64909":"# find indexes of the grapheme, vowel and consonant outputs with the\n# largest probabilities, then determine the corresponding class\n# labels\nrow_id=[]\ntarget=[]\nfor i in range (len(graphemeProba)):\n    graphemeIdx = graphemeProba[i].argmax()\n    vowelIdx = vowelProba[i].argmax()\n    consonantIdx = consonantProba[i].argmax()\n    \n    graphemeLabel = graphemeLB.classes_[graphemeIdx]\n    vowelLabel = vowelLB.classes_[vowelIdx]\n    consonantLabel = consonantLB.classes_[consonantIdx]\n\n    row_id.append(\"Test_\"+str(i)+\"_consonant_diacritic\")\n    target.append(consonantLabel)\n\n    row_id.append(\"Test_\"+str(i)+\"_grapheme_root\")\n    target.append(graphemeLabel)\n\n    row_id.append(\"Test_\"+str(i)+\"_vowel_diacritic\")\n    target.append(vowelLabel)","a2ab52ce":"sub_df = pd.DataFrame()\nsub_df[\"row_id\"]=row_id\nsub_df[\"target\"]=target","103d27da":"sub_df.head()","471fd2d3":"sub_df.to_csv(\"submission.csv\",index=False)","58f15469":"### Check few sample images","19ac947a":"## Create csv output","b6ab2cc7":"## Now read Test Data provided as feather format","5ee7de4d":"## Build and compile a MultiChannel multioutput CNN model","9d9714f5":"## Read image data from feather format, binarize the labels, do train test split, create TF Dataset from images and labels, and do model.fit in a loop for the 4 sets of images","96860c52":"### Read the image file data from feather file, and check few images","5ba4f89c":" ### Top 10 Grapheme Roots in training set","f3643774":"## Exploratory Data Analysis","548bdb8b":"## Pre-process Test data and make predictions on Test Set","b7ef5a39":"### Top 5 Consonant Diacritic in training data (There are only 7)","aadcee45":"## Resize an image using PIL Image and check (resize to (96,96) input shape for CNN)","c2dca40e":"### Top 10 Vowel Diacritic in taining data (There are only 11)","77afcff5":"## Simple model with multiple Outputs branching out from the Dense layers"}}