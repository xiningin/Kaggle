{"cell_type":{"bff5a517":"code","bc50b4f6":"code","b9414376":"code","5e17cefd":"code","1bf4afec":"code","7885785d":"code","286f54e3":"code","f713fe82":"code","4e5fc2e9":"code","70b4ec53":"code","e8a530c2":"code","172c77e7":"code","6e3c7ee3":"code","46113513":"code","90b17264":"code","825e3e77":"code","17a051a0":"code","6c790cbe":"code","5455b088":"code","3bf39117":"code","da14c9e2":"code","7e567c26":"code","42a7f0d4":"code","eb61611a":"code","b726c7cc":"code","21ec39b8":"code","c21b5828":"code","b0795a50":"code","99469c9a":"code","cb58c882":"code","5de302f3":"code","4ae3e9cd":"code","aa8ad272":"code","1d3344c7":"code","af751765":"code","7f2229de":"code","620bacf4":"code","7b313cb3":"code","1b227faa":"code","4adb3444":"code","8c454526":"code","25eaa4e2":"code","f27680fd":"code","c0073b8a":"code","9ad2acbf":"code","2b351235":"code","a19e173d":"code","4ae3e377":"code","056b7289":"code","59e6ccff":"code","8c291205":"code","fd19b8b1":"code","95d0b589":"code","c2ffbac4":"code","ce278a16":"code","c730f16c":"code","2034a952":"code","77dd091a":"code","6fd66d4f":"code","af507078":"code","6f341fef":"code","148a04c0":"code","bcbf3b2d":"code","483c4e83":"code","24e51089":"code","0449b4b2":"code","2463af53":"code","e656329d":"code","a13b59cd":"code","aa660be5":"code","3806dd25":"code","c7c5b311":"code","584c0bb5":"code","28c5a7cd":"code","5649e2bb":"code","62daad08":"code","b5e9d9e3":"code","6f7b4b9a":"code","207ccb34":"code","27506240":"code","80189cee":"code","013848d6":"code","299052d8":"code","204fcd3d":"code","5ad6da00":"code","3a492c3c":"code","ea5d3a0a":"code","a72aacc6":"code","a74ea043":"code","9c6bb0d6":"code","8ed1739c":"code","fa898c18":"code","4daed264":"code","961b5445":"code","795c7f2e":"code","88507669":"code","a79fce68":"code","41809888":"code","fad14622":"code","22d9b712":"code","2819f392":"code","a3b17b09":"markdown","2a3daa10":"markdown","ede398e7":"markdown","8c9a8ebb":"markdown","902344d3":"markdown","bc66ef87":"markdown","ffeef0c6":"markdown","6d5c646e":"markdown","fe1961e3":"markdown","43c3edcf":"markdown","3ea15774":"markdown","f5a30a70":"markdown","fa051d15":"markdown","13329f36":"markdown","1ae5332b":"markdown","45965578":"markdown","cb48e0a0":"markdown","d0ffb619":"markdown","be852ede":"markdown","a4e2167b":"markdown","6110f2cf":"markdown","2ed48baa":"markdown","d3cae423":"markdown","55859f93":"markdown","08668db2":"markdown","1ff5c60b":"markdown","11ff8e30":"markdown","125e6e71":"markdown","8d78b70f":"markdown","9d9f7682":"markdown","8b3ed58d":"markdown","d8af617c":"markdown","6d37cff2":"markdown","f787c46d":"markdown","39586109":"markdown","2b5355f0":"markdown","40760206":"markdown","b5e7aa26":"markdown"},"source":{"bff5a517":"# necessary imports\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('fivethirtyeight')\n%matplotlib inline","bc50b4f6":"train_df = pd.read_csv('..\/input\/titanic\/train.csv')","b9414376":"train_df.head()","5e17cefd":"train_df.describe()","1bf4afec":"train_df.var()","7885785d":"train_df.info()","286f54e3":"# Checking for null values\n\ntrain_df.isna().sum()","f713fe82":"# visualizing null values\n\nimport missingno as msno\n\nmsno.bar(train_df)\nplt.show()","4e5fc2e9":"# heatmap\n\nplt.figure(figsize = (18, 8))\n\ncorr = train_df.corr()\nmask = np.triu(np.ones_like(corr, dtype = bool))\n\nsns.heatmap(corr, mask = mask, annot = True, fmt = '.2f', linewidths = 1, annot_kws = {'size' : 15})\nplt.show()","70b4ec53":"plt.figure(figsize = (12, 7))\n\nsns.countplot(y = 'Survived', data = train_df)\nplt.show()","e8a530c2":"values = train_df['Survived'].value_counts()\nlabels = ['Not Survived', 'Survived']\n\nfig, ax = plt.subplots(figsize = (5, 5), dpi = 100)\nexplode = (0, 0.06)\n\npatches, texts, autotexts = ax.pie(values, labels = labels, autopct = '%1.2f%%', shadow = True,\n                                   startangle = 90, explode = explode)\n\nplt.setp(texts, color = 'grey')\nplt.setp(autotexts, size = 12, color = 'white')\nautotexts[1].set_color('black')\nplt.show()","172c77e7":"train_df.Pclass.value_counts()","6e3c7ee3":"train_df.groupby(['Pclass', 'Survived'])['Survived'].count()","46113513":"plt.figure(figsize = (16, 8))\n\nsns.countplot('Pclass', hue = 'Survived', data = train_df)\nplt.show()","90b17264":"values = train_df['Pclass'].value_counts()\nlabels = ['Third Class', 'Second Class', 'First Class']\nexplode = (0, 0, 0.08)\n\nfig, ax = plt.subplots(figsize = (5, 6), dpi = 100)\npatches, texts, autotexts = ax.pie(values, labels = labels, autopct = '%1.2f%%', shadow = True,\n                                   startangle = 90, explode = explode)\n\nplt.setp(texts, color = 'grey')\nplt.setp(autotexts, size = 13, color = 'white')\nautotexts[2].set_color('black')\nplt.show()","825e3e77":"sns.catplot('Pclass', 'Survived', kind = 'point', data = train_df, height = 6, aspect = 2)\nplt.show()","17a051a0":"train_df.Name.value_counts()","6c790cbe":"len(train_df.Name.unique()), train_df.shape","5455b088":"train_df.Sex.value_counts()","3bf39117":"train_df.groupby(['Sex', 'Survived'])['Survived'].count()","da14c9e2":"plt.figure(figsize = (16, 7))\n\nsns.countplot('Sex', hue = 'Survived', data = train_df)\nplt.show()","7e567c26":"sns.catplot(x = 'Sex', y = 'Survived', data = train_df, kind = 'bar', col = 'Pclass')\nplt.show()","42a7f0d4":"sns.catplot(x = 'Sex', y = 'Survived', data = train_df, kind = 'point', height = 6, aspect =2)\nplt.show()","eb61611a":"plt.figure(figsize = (15, 6))\n\nsns.catplot(x = 'Pclass', y = 'Survived', kind = 'point', data = train_df, hue = 'Sex', height = 6, aspect = 2)\nplt.show()","b726c7cc":"plt.figure(figsize = (15, 6))\nplt.style.use('ggplot')\n\nsns.distplot(train_df['Age'])\nplt.show()","21ec39b8":"sns.catplot(x = 'Sex', y = 'Age', kind = 'box', data = train_df, height = 5, aspect = 2)\nplt.show()","c21b5828":"sns.catplot(x = 'Sex', y = 'Age', kind = 'box', data = train_df, col = 'Pclass')\nplt.show()","b0795a50":"plt.figure(figsize = (14, 6))\n\nplt.hist(train_df.Fare, bins = 60, color = 'orange')\nplt.xlabel('Fare')\nplt.show()","99469c9a":"sns.catplot(x = 'Sex', y = 'Fare', data = train_df, kind = 'box', col = 'Pclass')\nplt.show()","cb58c882":"train_df['SibSp'].value_counts()","5de302f3":"plt.figure(figsize = (16, 5))\n\nsns.countplot(x = 'SibSp', data = train_df, hue = 'Survived')\nplt.show()","4ae3e9cd":"sns.catplot(x = 'SibSp', y = 'Survived', kind = 'bar', data = train_df, height = 5, aspect =2)\nplt.show()","aa8ad272":"sns.catplot(x = 'SibSp', y = 'Survived', kind = 'bar', hue = 'Sex', data = train_df, height = 6, aspect = 2)\nplt.show()","1d3344c7":"sns.catplot(x = 'SibSp',  y = 'Survived', kind = 'bar', col = 'Sex', data = train_df)\nplt.show()","af751765":"sns.catplot(x = 'SibSp', y = 'Survived', col = 'Pclass', kind = 'bar', data = train_df)\nplt.show()","7f2229de":"sns.catplot(x = 'SibSp', y = 'Survived', kind = 'point', hue = 'Sex', data = train_df, height = 6, aspect = 2)\nplt.show()","620bacf4":"train_df.Parch.value_counts()","7b313cb3":"sns.catplot(x = 'Parch', y = 'Survived', data = train_df, hue = 'Sex', kind = 'bar', height = 6, aspect = 2)\nplt.show()","1b227faa":"train_df.Ticket.value_counts()","4adb3444":"len(train_df.Ticket.unique())","8c454526":"train_df['Embarked'].value_counts()","25eaa4e2":"plt.figure(figsize = (14, 6))\n\nsns.countplot('Embarked', hue = 'Survived', data = train_df)\nplt.show()","f27680fd":"sns.catplot(x = 'Embarked', y = 'Survived', kind = 'bar', data = train_df, col = 'Sex')\nplt.show()","c0073b8a":"# dropping useless columns\n\ntrain_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis = 1, inplace = True)","9ad2acbf":"train_df.head()","2b351235":"train_df.isna().sum()","a19e173d":"# replacing Zero values of \"Fare\" column with mean of column\n\ntrain_df['Fare'] = train_df['Fare'].replace(0, train_df['Fare'].mean())","4ae3e377":"# filling null values of \"Age\" column with mean value of the column\n\ntrain_df['Age'].fillna(train_df['Age'].mean(), inplace = True)","056b7289":"# filling null values of \"Embarked\" column with mode value of the column\n\ntrain_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace = True)","59e6ccff":"# checking for null values after filling null values\n\ntrain_df.isna().sum()","8c291205":"train_df.head()","fd19b8b1":"train_df['Sex'] = train_df['Sex'].apply(lambda val: 1 if val == 'male' else 0)","95d0b589":"train_df['Embarked'] = train_df['Embarked'].map({'S' : 0, 'C': 1, 'Q': 2})","c2ffbac4":"train_df.head()","ce278a16":"train_df.describe()","c730f16c":"train_df.var()","2034a952":"train_df['Age'] = np.log(train_df['Age'])\ntrain_df['Fare'] = np.log(train_df['Fare'])","77dd091a":"train_df.head()","6fd66d4f":"test_df = pd.read_csv('..\/input\/titanic\/test.csv')","af507078":"test_df.head()","6f341fef":"# dropping useless columns\n\ntest_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis = 1, inplace = True)","148a04c0":"# replacing Zero values of \"Fare\" column with mean of column\n\ntest_df['Fare'] = test_df['Fare'].replace(0, test_df['Fare'].mean())","bcbf3b2d":"# filling null values of \"Age\" column with mean value of the column\n\ntest_df['Age'].fillna(test_df['Age'].mean(), inplace = True)","483c4e83":"# filling null values of \"Embarked\" column with mode value of the column\n\ntest_df['Embarked'].fillna(test_df['Embarked'].mode()[0], inplace = True)","24e51089":"test_df.isna().sum()","0449b4b2":"# filling null values of \"Fare\" column with mean value of the column\n\ntest_df['Fare'].fillna(test_df['Fare'].mean(), inplace = True)","2463af53":"test_df['Sex'] = test_df['Sex'].apply(lambda val: 1 if val == 'male' else 0)","e656329d":"test_df['Embarked'] = test_df['Embarked'].map({'S' : 0, 'C': 1, 'Q': 2})","a13b59cd":"test_df.head()","aa660be5":"test_df['Age'] = np.log(test_df['Age'])\ntest_df['Fare'] = np.log(test_df['Fare'])","3806dd25":"test_df.var()","c7c5b311":"test_df.isna().any()","584c0bb5":"test_df.head()","28c5a7cd":"# creating X and y\n\nX = train_df.drop('Survived', axis = 1)\ny = train_df['Survived']","5649e2bb":"# splitting data intp training and test set\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 0)","62daad08":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nlr.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of logistic regression\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\nlr_acc = accuracy_score(y_test, lr.predict(X_test))\n\nprint(f\"Training Accuracy of Logistic Regression is {accuracy_score(y_train, lr.predict(X_train))}\")\nprint(f\"Test Accuracy of Logistic Regression is {lr_acc}\")\n\nprint(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, lr.predict(X_test))}\")\nprint(f\"Classofocation Report : -\\n {classification_report(y_test, lr.predict(X_test))}\")","b5e9d9e3":"# hyper parameter tuning of logistic regression\n\nfrom sklearn.model_selection import GridSearchCV\n\ngrid_param = {\n    'penalty': ['l1', 'l2'],\n    'C' : [0.001, 0.01, 0.1, 0.005, 0.5, 1, 10]\n}\n\ngrid_search_lr = GridSearchCV(lr, grid_param, cv = 5, n_jobs = -1, verbose = 1)\ngrid_search_lr.fit(X_train, y_train)","6f7b4b9a":"# best parameters and best score\n\nprint(grid_search_lr.best_params_)\nprint(grid_search_lr.best_score_)","207ccb34":"# best estimator\n\nlr = grid_search_lr.best_estimator_\n\n# accuracy score, confusion matrix and classification report of logistic regression\n\nlr_acc = accuracy_score(y_test, lr.predict(X_test))\n\nprint(f\"Training Accuracy of Logistic Regression is {accuracy_score(y_train, lr.predict(X_train))}\")\nprint(f\"Test Accuracy of Logistic Regression is {lr_acc}\")\n\nprint(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, lr.predict(X_test))}\")\nprint(f\"Classofocation Report : -\\n {classification_report(y_test, lr.predict(X_test))}\")","27506240":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of knn\n\nknn_acc = accuracy_score(y_test, knn.predict(X_test))\n\nprint(f\"Training Accuracy of KNN is {accuracy_score(y_train, knn.predict(X_train))}\")\nprint(f\"Test Accuracy of KNN is {knn_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, knn.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, knn.predict(X_test))}\")","80189cee":"from sklearn.tree import DecisionTreeClassifier\n\ndtc = DecisionTreeClassifier()\ndtc.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of decision tree\n\ndtc_acc = accuracy_score(y_test, dtc.predict(X_test))\n\nprint(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, dtc.predict(X_train))}\")\nprint(f\"Test Accuracy of Decision Tree Classifier is {dtc_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, dtc.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, dtc.predict(X_test))}\")","013848d6":"# hyper parameter tuning of decision tree \n\ngrid_param = {\n    'criterion' : ['gini', 'entropy'],\n    'max_depth' : [3, 5, 7, 10],\n    'splitter' : ['best', 'random'],\n    'min_samples_leaf' : [1, 2, 3, 5, 7],\n    'min_samples_split' : [1, 2, 3, 5, 7],\n    'max_features' : ['auto', 'sqrt', 'log2']\n}\n\ngrid_search_dtc = GridSearchCV(dtc, grid_param, cv = 5, n_jobs = -1, verbose = 1)\ngrid_search_dtc.fit(X_train, y_train)","299052d8":"# best parameters and best score\n\nprint(grid_search_dtc.best_params_)\nprint(grid_search_dtc.best_score_)","204fcd3d":"# best estimator\n\ndtc = grid_search_dtc.best_estimator_\n\n# accuracy score, confusion matrix and classification report of decision tree\n\ndtc_acc = accuracy_score(y_test, dtc.predict(X_test))\n\nprint(f\"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, dtc.predict(X_train))}\")\nprint(f\"Test Accuracy of Decision Tree Classifier is {dtc_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, dtc.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, dtc.predict(X_test))}\")","5ad6da00":"from sklearn.ensemble import RandomForestClassifier\n\nrd_clf = RandomForestClassifier()\nrd_clf.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of random forest\n\nrd_clf_acc = accuracy_score(y_test, rd_clf.predict(X_test))\n\nprint(f\"Training Accuracy of Random Forest Classifier is {accuracy_score(y_train, rd_clf.predict(X_train))}\")\nprint(f\"Test Accuracy of Random Forest Classifier is {rd_clf_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, rd_clf.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, rd_clf.predict(X_test))}\")","3a492c3c":"from sklearn.ensemble import AdaBoostClassifier\n\nada = AdaBoostClassifier(base_estimator = dtc)\nada.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of ada boost\n\nada_acc = accuracy_score(y_test, ada.predict(X_test))\n\nprint(f\"Training Accuracy of Ada Boost Classifier is {accuracy_score(y_train, ada.predict(X_train))}\")\nprint(f\"Test Accuracy of Ada Boost Classifier is {ada_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, ada.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, ada.predict(X_test))}\")","ea5d3a0a":"# hyper parameter tuning ada boost\n\ngrid_param = {\n    'n_estimators' : [100, 120, 150, 180, 200],\n    'learning_rate' : [0.01, 0.1, 1, 10],\n    'algorithm' : ['SAMME', 'SAMME.R']\n}\n\ngrid_search_ada = GridSearchCV(ada, grid_param, cv = 5, n_jobs = -1, verbose = 1)\ngrid_search_ada.fit(X_train, y_train)","a72aacc6":"# best parameter and best score\n\nprint(grid_search_ada.best_params_)\nprint(grid_search_ada.best_score_)","a74ea043":"ada = grid_search_ada.best_estimator_\n\n# accuracy score, confusion matrix and classification report of ada boost\n\nada_acc = accuracy_score(y_test, ada.predict(X_test))\n\nprint(f\"Training Accuracy of Ada Boost Classifier is {accuracy_score(y_train, ada.predict(X_train))}\")\nprint(f\"Test Accuracy of Ada Boost Classifier is {ada_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, ada.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, ada.predict(X_test))}\")","9c6bb0d6":"from sklearn.ensemble import GradientBoostingClassifier\n\ngb = GradientBoostingClassifier()\ngb.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of gradient boosting classifier\n\ngb_acc = accuracy_score(y_test, gb.predict(X_test))\n\nprint(f\"Training Accuracy of Gradient Boosting Classifier is {accuracy_score(y_train, gb.predict(X_train))}\")\nprint(f\"Test Accuracy of Gradient Boosting Classifier is {gb_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, gb.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, gb.predict(X_test))}\")","8ed1739c":"sgb = GradientBoostingClassifier(subsample = 0.90, max_features = 0.70)\nsgb.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of stochastic gradient boosting classifier\n\nsgb_acc = accuracy_score(y_test, sgb.predict(X_test))\n\nprint(f\"Training Accuracy of Stochastic Gradient Boosting is {accuracy_score(y_train, sgb.predict(X_train))}\")\nprint(f\"Test Accuracy of Stochastic Gradient Boosting is {sgb_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, sgb.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, sgb.predict(X_test))}\")","fa898c18":"from xgboost import XGBClassifier\n\nxgb = XGBClassifier(booster = 'gbtree', learning_rate = 0.1, max_depth = 5, n_estimators = 180)\nxgb.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of xgboost\n\nxgb_acc = accuracy_score(y_test, xgb.predict(X_test))\n\nprint(f\"Training Accuracy of XgBoost is {accuracy_score(y_train, xgb.predict(X_train))}\")\nprint(f\"Test Accuracy of XgBoost is {xgb_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, xgb.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, xgb.predict(X_test))}\")","4daed264":"from catboost import CatBoostClassifier\n\ncat = CatBoostClassifier(iterations=10)\ncat.fit(X_train, y_train)","961b5445":"# accuracy score, confusion matrix and classification report of cat boost\n\ncat_acc = accuracy_score(y_test, cat.predict(X_test))\n\nprint(f\"Training Accuracy of Cat Boost Classifier is {accuracy_score(y_train, cat.predict(X_train))}\")\nprint(f\"Test Accuracy of Cat Boost Classifier is {cat_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, cat.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, cat.predict(X_test))}\")","795c7f2e":"from sklearn.ensemble import ExtraTreesClassifier\n\netc = ExtraTreesClassifier()\netc.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of extra trees classifier\n\netc_acc = accuracy_score(y_test, etc.predict(X_test))\n\nprint(f\"Training Accuracy of Extra Trees Classifier is {accuracy_score(y_train, etc.predict(X_train))}\")\nprint(f\"Test Accuracy of Extra Trees Classifier is {etc_acc} \\n\")\n\nprint(f\"Confusion Matrix :- \\n{confusion_matrix(y_test, etc.predict(X_test))}\\n\")\nprint(f\"Classification Report :- \\n {classification_report(y_test, etc.predict(X_test))}\")","88507669":"from lightgbm import LGBMClassifier\n\nlgbm = LGBMClassifier(learning_rate = 1)\nlgbm.fit(X_train, y_train)\n\n# accuracy score, confusion matrix and classification report of lgbm classifier\n\nlgbm_acc = accuracy_score(y_test, lgbm.predict(X_test))\n\nprint(f\"Training Accuracy of LGBM Classifier is {accuracy_score(y_train, lgbm.predict(X_train))}\")\nprint(f\"Test Accuracy of LGBM Classifier is {lgbm_acc} \\n\")\n\nprint(f\"{confusion_matrix(y_test, lgbm.predict(X_test))}\\n\")\nprint(classification_report(y_test, lgbm.predict(X_test)))","a79fce68":"from sklearn.ensemble import VotingClassifier\n\nclassifiers = [('Gradient Boosting Classifier', gb), ('Stochastic Gradient Boosting', sgb),  ('Cat Boost Classifier', cat), \n               ('XGboost', xgb),  ('Decision Tree', dtc), ('Extra Tree', etc), ('Light Gradient', lgbm),\n               ('Random Forest', rd_clf), ('Ada Boost', ada), ('Logistic', lr)]\nvc = VotingClassifier(estimators = classifiers)\nvc.fit(X_train, y_train)","41809888":"# accuracy score, confusion matrix and classification report of voting classifier\n\nvc_acc = accuracy_score(y_test, vc.predict(X_test))\n\nprint(f\"Training Accuracy of Voting Classifier is {accuracy_score(y_train, vc.predict(X_train))}\")\nprint(f\"Test Accuracy of Voting Classifier is {vc_acc} \\n\")\n\nprint(f\"{confusion_matrix(y_test, vc.predict(X_test))}\\n\")\nprint(classification_report(y_test, vc.predict(X_test)))","fad14622":"models = pd.DataFrame({\n    'Model' : ['Logistic Regression', 'KNN', 'Decision Tree Classifier', 'Random Forest Classifier','Ada Boost Classifier',\n             'Gradient Boosting Classifier', 'Stochastic Gradient Boosting', 'XgBoost', 'Cat Boost', 'Extra Trees Classifier', 'Voting Classifier'],\n    'Score' : [lr_acc, knn_acc, dtc_acc, rd_clf_acc, ada_acc, gb_acc, sgb_acc, xgb_acc, cat_acc, etc_acc, vc_acc]\n})\n\n\nmodels.sort_values(by = 'Score', ascending = False)","22d9b712":"plt.figure(figsize = (15, 10))\n\nsns.barplot(x = 'Score', y = 'Model', data = models)\nplt.show()","2819f392":"final_prediction = sgb.predict(test_df)\nprediction = pd.DataFrame(final_prediction)\nsubmission = pd.read_csv('..\/input\/titanic\/gender_submission.csv')\nsubmission['Survived'] = prediction\nsubmission.to_csv('Submission.csv', index = False)","a3b17b09":"<p style = \"font-size : 20px; color : #34656d ; font-family : 'Comic Sans MS'; \"><strong>Heatmap is not useful in case of categorical variables, so we will analyse each column to check how each column is contributing in prediction.<\/strong><\/p> \n","2a3daa10":"<a id = '2.2'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Pclass Column<\/strong><\/p> ","ede398e7":"<a id = '5.7'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Stochastic Gradient Boosting (SGB)<\/strong><\/p>","8c9a8ebb":"<img style=\"float: center;  border:5px solid #ffb037; width:100%\" src = https:\/\/sn56.scholastic.com\/content\/dam\/classroom-magazines\/sn56\/issues\/2018-19\/020419\/the-titanic-sails-again\/SN56020919_Titanic-Hero.jpg> ","902344d3":"<a id = '3.0'><\/a>\n<p style = \"font-size : 30px; color : #4e8d7c ; font-family : 'Comic Sans MS';\"><strong>Findings From EDA :-<\/strong><\/p>\n\n<ul>\n    <li style = \"color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';\"><strong>Females Survived more than Males.<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';\"><strong>Passengers Travelling in Higher Class Survived More than Passengers travelling in Lower Class.<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';\"><strong>Name column is having all unique values so this column is not suitable for prediction, we have to drop it.<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';\"><strong>In First Class Females were more than Males, that's why Fare of Females Passengers were high.<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';\"><strong>Survival Rate is higher for those who were travelling with siblings or spouses.<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';\"><strong>Passengers travelling with parents or children have higher survival rate.<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';\"><strong>Ticket column is not useful and does not have an impact on survival.<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';\"><strong>Cabin column have a lot of null values , it will be better to drop this column.<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';\"><strong>Passengers travelling from Cherbourg port survived more than passengers travelling from other two ports.<\/strong><\/li>\n<\/ul>","bc66ef87":"<a id = '2.6'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Fare Column<\/strong><\/p> ","ffeef0c6":"<a id = '2.8'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Parch Column<\/strong><\/p> ","6d5c646e":"<a id = '2.0'><\/a>\n<p style = \"font-size : 35px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #f9b208; border-radius: 5px 5px;\"><strong>Exploratory Data Analysis (EDA)<\/strong><\/p> ","fe1961e3":"<a id = '2.1'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Survived Column<\/strong><\/p> ","43c3edcf":"<a id = '5.12'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Voting Classifier<\/strong><\/p>","3ea15774":"<a id = '5.11'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>LGBM Classifier<\/strong><\/p>","f5a30a70":"<p style = \"font-size : 20px; color : #34656d ; font-family : 'Comic Sans MS'; \"><strong>Now training data looks much better let's take a look at test data.<\/strong><\/p> ","fa051d15":"<a id = '2.7'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>SibSp Column<\/strong><\/p> ","13329f36":"<a id = '5.2'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>KNN<\/strong><\/p> ","1ae5332b":"<a id = '5.8'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>XgBoost<\/strong><\/p>","45965578":"<p style = \"font-size : 20px; color : #34656d ; font-family : 'Comic Sans MS'; \"><strong>Performing same steps on test data.<\/strong><\/p> ","cb48e0a0":"<a id = '2.4'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Sex Column<\/strong><\/p> ","d0ffb619":"<a id = '5.9'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Cat Boost Classifier<\/strong><\/p>","be852ede":"<a id = '5.10'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Extra Trees Classifier<\/strong><\/p>","a4e2167b":"<a id = '1.0'><\/a>\n<p style = \"font-size : 30px; color : #4e8d7c ; font-family : 'Comic Sans MS';  \"><strong>Data Description :-<\/strong><\/p>\n\n<ul>\n    <li style = \"color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';\"><strong>Survival : 0 = No, 1 = Yes<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';\"><strong>pclass(Ticket Class) : 1 = 1st, 2 = 2nd, 3 = 3rd<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';\"><strong>Sex(Gender) : Male, Female<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';\"><strong>Age : Age in years<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';\"><strong>SibSp : Number of siblings\/spouses abroad the titanic<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';\"><strong>Parch : Number of parents\/children abrod the titanic<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';\"><strong>Ticket : Ticket Number<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';\"><strong>Fare : Passenger fare<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';\"><strong>Cabin : Cabin Number<\/strong><\/li>\n    <li style = \"color : #03506f; font-size : 18px; font-family : 'Comic Sans MS';\"><strong>Embarked : Port of Embarkation, C = Cherbourg, Q = Queenstown, S = Southampton<\/strong><\/li>\n<\/ul>","6110f2cf":"<a id = '5.3'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Decision Tree Classifier<\/strong><\/p> ","2ed48baa":"<p style = \"font-size : 20px; color : #34656d ; font-family : 'Comic Sans MS'; \"><strong>Now both training and test data is cleaned and preprocessed, let's start with model building.<\/strong><\/p> ","d3cae423":"<a id = '4.0'><\/a>\n<p style = \"font-size : 35px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #f9b208; border-radius: 5px 5px;\"><strong>Data Pre-Processing<\/strong><\/p> ","55859f93":"<a id = '5.5'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Ada Boost Classifier<\/strong><\/p>","08668db2":"<p style = \"font-size : 20px; color : #34656d ; font-family : 'Comic Sans MS'; \"><strong>We can see that lot of zero values are there in Fare column so we will replace zero values with mean value of Fare column later.<\/strong><\/p> ","1ff5c60b":"<p style = \"font-size : 50px; color : #532e1c ; font-family : 'Comic Sans MS'; text-align : center; background-color : #bedcfa; border-radius: 5px 5px;\"><strong>Titanic EDA and Prediction<\/strong><\/p>","11ff8e30":"<a id = '5.4'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Random Forest Classifier<\/strong><\/p>","125e6e71":"<a id = '5.1'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Logistic Regression<\/strong><\/p> ","8d78b70f":"<a id = '0'><\/a>\n<p style = \"font-size : 35px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #f9b208; border-radius: 5px 5px;\"><strong>Table of Contents<\/strong><\/p> \n\n* [Data Description](#1.0)\n* [EDA](#2.0)\n    * [Survived Column](#2.1)\n    * [Pclass Column](#2.2)\n    * [Name Column](#2.3)\n    * [Sex Column](#2.4)\n    * [Age Column](#2.5)\n    * [Fare Column](#2.6)\n    * [SibSp Column](#2.7)\n    * [Parch Column](#2.8)\n    * [Ticket Column](#2.9)\n    * [Embarked Column](#2.10)\n    \n* [Findings From EDA](#3.0)\n* [Data Preprocessing](#4.0)\n* [Models](#5.0)\n    * [Logistic Regression](#5.1)\n    * [Knn](#5.2)\n    * [Decision Tree Classifier](#5.3)\n    * [Random Forest Classifier](#5.4)\n    * [Ada Boost Classifier](#5.5)\n    * [Gradient Boosting Classifier](#5.6)\n    * [Stochastic Gradient Boosting (SGB)](#5.7)\n    * [XgBoost](#5.8)\n    * [Cat Boost Classifier](#5.9)\n    * [Extra Trees Classifier](#5.10)\n    * [LGBM Classifier](#5.11)\n    * [Voting Classifier](#5.12)\n\n* [Models Comparison](#6.0)\n","9d9f7682":"<a id = '2.5'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Age Column<\/strong><\/p> ","8b3ed58d":"<a id = '2.9'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Ticket Column<\/strong><\/p> ","d8af617c":"<a id = '6.0'><\/a>\n<p style = \"font-size : 35px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #f9b208; border-radius: 5px 5px;\"><strong> Models Comparison<\/strong><\/p> ","6d37cff2":"<p style = \"font-size : 20px; color : #34656d ; font-family : 'Comic Sans MS'; \"><strong>Variance in \"Fare\" column is very high so we have to normalize these columns.<\/strong><\/p> ","f787c46d":"<p style = \"font-size : 25px; color : #f55c47 ; font-family : 'Comic Sans MS'; \"><strong>If you like my work, please do Upvote.<\/strong><\/p> ","39586109":"<a id = '5.0'><\/a>\n<p style = \"font-size : 35px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #f9b208; border-radius: 5px 5px;\"><strong> Models<\/strong><\/p> ","2b5355f0":"<a id = '5.6'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Gradient Boosting Classifier<\/strong><\/p>","40760206":"<a id = '2.10'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Embarked Column<\/strong><\/p> ","b5e7aa26":"<a id = '2.3'><\/a>\n<p style = \"font-size : 25px; color : #34656d ; font-family : 'Comic Sans MS'; text-align : center; background-color : #fbc6a4; border-radius: 5px 5px;\"><strong>Name Column<\/strong><\/p> "}}