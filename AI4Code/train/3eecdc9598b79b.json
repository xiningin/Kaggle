{"cell_type":{"737b3bd7":"code","2e3fba2b":"code","6b8792b7":"code","582e6cc8":"code","75d1de02":"code","458d1d27":"code","92a4f090":"code","481ea679":"code","d03453e5":"code","d46e5adc":"code","e13e61c6":"code","0c06af32":"code","4b4ec236":"markdown","d8006ab0":"markdown","c745b2cc":"markdown","3ae8b007":"markdown"},"source":{"737b3bd7":"from load_kaggle import load_kaggle","2e3fba2b":"subm, train, test = load_kaggle()\nprint(train.shape, test.shape, subm.shape)\ntrain.head()","6b8792b7":"### This is a multi-class problem. Let's look at the class percents\ntarget = 'Target'\ntrain[target].value_counts(1)","582e6cc8":"train = train.sample(frac=1.0, random_state=3).sample(frac=1.0, random_state=39)\ntrain.head()","75d1de02":"!pip install deep_autoviml","458d1d27":"######   D E F A U L T S    S E T T I N G S   F O R   D E E P    A U T O  V I M L ###\nkeras_model_type = \"fast\" ## always try \"fast\" first, then \"fast1\", \"fast2\", etc.\n### always set early_stopping to True first and then change it to False\n#### You always need 15 max_trials to get something decent #####\n#### always set tuner to \"storm\" and then \"optuna\". \n### NLP char limit kicks off NLP processing. Feature Cross later.\nproject_name = \"loan\"\nmodel_options = {'nlp_char_limit':50, 'cat_feat_cross_flag':False,\n                 'max_trials': 10, \"tuner\": \"storm\"}\nkeras_options = {\"patience\":10, 'class_weight': True, 'early_stopping': True, \n                 'lr_scheduler': '', \"optimizer\": 'RMS'}","92a4f090":"from deep_autoviml import deep_autoviml as deepauto","481ea679":"model, cat_vocab_dict = deepauto.fit(train, target, \n        keras_model_type=keras_model_type,\n\t\tproject_name=project_name, keras_options=keras_options,  \n\t\tmodel_options=model_options, save_model_flag=True, use_my_model='',\n\t\tmodel_use_case='', verbose=1)","d03453e5":"predictions = deepauto.predict(model, project_name, test_dataset=test,\n                                 keras_model_type=keras_model_type, \n                                 cat_vocab_dict=cat_vocab_dict)","d46e5adc":"y_preds = predictions[-1]\ny_preds[:5]","e13e61c6":"subm[target] = y_preds\nsubm.head()","0c06af32":"subm.to_csv('submission.csv', index=False)","4b4ec236":"# From the \"File Menu\" on top, \"Add Utility Script\", load_kaggle()","d8006ab0":"## You must first Shuffle this Data Set - the target is all lumped together. So it is not going to train deep learning models well.","c745b2cc":"# Now install Deep AutoViML library to make a fast DNN Model using Keras","3ae8b007":"# deep_autoviml is an AutoML library for building deep learning models using tensorflow and keras using a single line of code.<\/h1>\n## It will automatically do the following:\n- Load a wide variety of performant DNN architectures such as deep and wide, deep and cross models, etc.\n- Use a hypertuner named Storm-Tuner to select the best hyper params for each of the model architectures\n- Select the best model and add pre-processing layers for feature transformation and do selective feature engineering\n- For NLP tasks: it select a BERT or USE model along with text processors\n- Train best model and run predictions using the trained model\n- You can automatically save the model with its preprocessing layers and load it elsewhere or serve it using tf.serving on Cloud providers\n## For github visit: [deep_autoviml](https:\/\/github.com\/AutoViML\/deep_autoviml)\n####################################################################################"}}