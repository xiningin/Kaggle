{"cell_type":{"f70d1c7c":"code","c11378b1":"code","d23eff45":"code","a99d54d4":"code","da4e25c0":"code","569f2f8d":"code","8c40c785":"code","a81b2637":"code","57c3007c":"code","aa0f6cf7":"code","2dccaac8":"code","0afb24aa":"code","e38b6b82":"code","3a973abc":"code","fd5d90cd":"code","39a09821":"code","22933ddf":"code","ed6b09d6":"code","b9502901":"code","e14bb529":"code","d1c0828a":"code","208de279":"markdown","cd0a1608":"markdown","beaab1fb":"markdown","c04a3461":"markdown","da931a21":"markdown","39419ee4":"markdown","bfb45e8c":"markdown","c860497f":"markdown","52858378":"markdown","4c805ac7":"markdown","3112f0f1":"markdown","d96b0a64":"markdown","9bb11c23":"markdown","075c4c3e":"markdown","36950f7c":"markdown","c68e8952":"markdown"},"source":{"f70d1c7c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import ParameterGrid\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import MinMaxScaler\n\n\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c11378b1":"bs_train = pd.read_csv('..\/input\/task-04\/training_data.csv', index_col=0)\nbs_test = pd.read_csv('..\/input\/task-04\/test_data_without_label.csv', index_col=0)\n\nbs_train.head(5)","d23eff45":"bs_train.isna().sum()\n#bs_test.isna().mean()","a99d54d4":"bs_train.drop(['respiracao'],1,inplace=True)\nbs_test.drop(['respiracao'],1,inplace=True)","da4e25c0":"for i in bs_train.index:\n    if bs_train.loc[i].temperatura > 41 or bs_train.loc[i].temperatura < 30:\n        bs_train.temperatura.loc[i] = np.nan\n        \n    if bs_train.loc[i].pulso > 200 or bs_train.loc[i].pulso < 30:\n        bs_train.pulso.loc[i] = np.nan\n        \n    if bs_train.loc[i].pa_min > 250 or bs_train.loc[i].pa_min < 70:\n        bs_train.pa_min.loc[i] = np.nan\n        \n    if bs_train.loc[i].pa_max > 150 or bs_train.loc[i].pa_max < 35:\n        bs_train.pa_max.loc[i] = np.nan\n\n        \nfor i in bs_test.index:\n    if bs_test.loc[i].temperatura > 41 or bs_test.loc[i].temperatura < 30:\n        bs_test.temperatura.loc[i] = np.nan\n        \n    if bs_test.loc[i].pulso > 200 or bs_test.loc[i].pulso < 30:\n        bs_test.pulso.loc[i] = np.nan\n        \n    if bs_test.loc[i].pa_min > 250 or bs_test.loc[i].pa_min < 70:\n        bs_test.pa_min.loc[i] = np.nan\n        \n    if bs_test.loc[i].pa_max > 150 or bs_test.loc[i].pa_max < 35:\n        bs_test.pa_max.loc[i] = np.nan","569f2f8d":"bs_train.isna().sum()\n#bs_test.isna().mean()","8c40c785":"bs_train.fillna(bs_train.median(), inplace=True)\nbs_test.fillna(bs_test.median(), inplace=True)","a81b2637":"bs_train.isna().mean()","57c3007c":"#bs_train['count_num_atend_sepse'] = bs_train[(bs_train.sepse == 1)].groupby('num_atend')['num_atend'].transform('count')\n#bs_train['count_num_atend_nosepse'] = bs_train['count_num_atend'] - bs_train['count_num_atend_sepse']\n\nbs_train['count_num_atend'] = bs_train.groupby('num_atend')['num_atend'].transform('count')\nbs_train.fillna(0,inplace=True)\nbs_train","aa0f6cf7":"bs_test_with_count = pd.merge(bs_test,(bs_train[[\"num_atend\",\n                                                 \"count_num_atend\"]]).drop_duplicates(['num_atend']) ,how=\"left\", on=\"num_atend\")\nbs_test_with_count.fillna(0,inplace=True)\nbs_test_with_count.index = bs_test_with_count.index+1\nbs_test_with_count","2dccaac8":"#(bs_train_model, bs_val) = train_test_split(bs_train, test_size = 0.3,random_state=57)\n\n#y_train = bs_train_model['sepse']\n#X_train = bs_train_model.drop(['num_atend','sepse'],1)\n\n#y_val   = bs_val['sepse']\n#X_val   = bs_val.drop(['num_atend','sepse'],1)","0afb24aa":"bs_test = bs_test_with_count.drop(['num_atend'],1)\nX_test = bs_test\n\ny_train = bs_train['sepse']\nX_train = bs_train.drop(['num_atend','sepse'],1)\n\n#scaler = MinMaxScaler(feature_range=(0, 1))\n#X_train_scal = scaler.fit_transform(X_train.to_numpy())","e38b6b82":"#parameters = {'max_depth': [9], 'max_leaf_nodes': [87], 'min_samples_leaf': [0.008889], 'min_samples_split': [0.04737368421052632]}\n\n#parameters = {'max_depth':list(range(2,12)), 'max_leaf_nodes': list(range(2,90))}\n\nparameters = {'max_depth': [11], 'max_leaf_nodes': [89]}\n\n\nbest_params=[]\nbest_score = 0\n\ni=0\n# Treinamento\nparameters_g = shuffle(list(ParameterGrid(parameters)))\nfor param in list(parameters_g):\n    model_dt = tree.DecisionTreeClassifier(max_depth= param['max_depth'],\n                                          max_leaf_nodes = param['max_leaf_nodes'])\n    \n    #model_dt.fit(X_train,y_train)\n    #score = balanced_accuracy_score(y_val, model_dt.predict(X_val))\n\n    # Validacao\n    \n    score_cv = cross_val_score(model_dt, X_train, y_train, cv=10,scoring='accuracy')\n    score = np.mean(score_cv)\n    \n    \n    if score > best_score:\n        best_score = score\n        best_params = param\n        best_model_dt = model_dt\n\n        \n    i+=1\n    if(i%10 == 0):\n        print((i\/len(list(ParameterGrid(parameters))))*100,\"Best score:\", best_score,\"Best params:\", best_params)\n\nprint(\"Best params:\", best_params)\nprint(\"Best score:\", best_score)","3a973abc":"#parameters = {'max_depth':np.arange(5, 30, 2), \"n_estimators\":[200],  \"criterion\":[\"gini\", 'entropy']}\n\nparameters = {'criterion': ['entropy'], 'max_depth': [9], 'n_estimators': [200]}\n\nbest_params=[]\nbest_score = 0\n\ni=0\n# Treinamento\nparameters_g = shuffle(list(ParameterGrid(parameters)))\nfor param in list(parameters_g):\n    model_rf = RandomForestClassifier( max_depth= param['max_depth'],\n                                      n_estimators= param['n_estimators'],\n                                      criterion = param['criterion'])\n\n    #model_rf.fit(X_train,y_train)\n    #score = balanced_accuracy_score(y_val, model_rf.predict(X_val))\n\n    # Validacao\n    \n    \n    score_cv = cross_val_score(model_rf, X_train, y_train, cv=10,scoring='accuracy',n_jobs=-1)\n    score = np.mean(score_cv)\n    \n    if score > best_score:\n        best_score = score\n        best_params = param\n        best_model_rf = model_rf\n\n        \n    i+=1\n    print((i\/len(list(ParameterGrid(parameters))))*100,\"Best score:\", best_score,\"Best params:\", best_params)\n\nprint(\"Best params:\", best_params)\nprint(\"Best score:\", best_score)","fd5d90cd":"model_xgb = XGBClassifier()\n\nscore_cv = cross_val_score(model_xgb, X_train, y_train, cv=10,scoring='accuracy',n_jobs=-1)\nnp.mean(score_cv)","39a09821":"model_bag = BaggingClassifier(n_estimators=100)\nscore_cv = cross_val_score(model_bag, X_train, y_train, cv=10,scoring='accuracy',n_jobs=-1)\nnp.mean(score_cv)","22933ddf":"model_vot = VotingClassifier(estimators=[('rf', best_model_rf),\n                                         ('xgb', model_xgb)],\n                             voting='hard', n_jobs=-1)\nscore_cv = cross_val_score(model_vot, X_train, y_train, cv=10,scoring='accuracy',n_jobs=-1)\nnp.mean(score_cv)","ed6b09d6":"model_stack = StackingClassifier(estimators=[('dt', model_vot),\n                                         ('rf', best_model_rf),\n                                         ('xgb', model_xgb)], n_jobs=-1)\nscore_cv = cross_val_score(model_stack, X_train, y_train, cv=10,scoring='accuracy',n_jobs=-1)\nnp.mean(score_cv)","b9502901":"model_final = model_vot\n\nmodel_final.fit(X_train, y_train)","e14bb529":"predictions = model_final.predict(bs_test)\n\npredictionsDF = pd.DataFrame({\"id\":bs_test.index, \n                                     \"sepse\":predictions})\npredictionsDF.to_csv(\"resposta.csv\",index = False, sep = \",\", decimal = \",\", float_format = str)","d1c0828a":"predictionsDF","208de279":"## Tratamendo da vari\u00e1vel 'count_num_atend'","cd0a1608":"## Arvore de Decis\u00e3o","beaab1fb":"Nessa parte, vamos setar como nulo, alguns valores que s\u00e3o fora da realidade, por exemplo, temperatura corporal menor do que 30 graus.","c04a3461":"# Florestas Aleat\u00f3rias","da931a21":"## Leitura e Pr\u00e9-processamento dos dados","39419ee4":"# Modelagem","bfb45e8c":"# Bagging (Decision Tree)","c860497f":"Para tratar essa vari\u00e1vel, que \u00e9 o id do paciente, vamos adicionar uma vari\u00e1vel que ser\u00e1 a contagem de vezes que o paciente foi registrado no hospital, seja com sepse ou n\u00e3o.","52858378":"# Stacking","4c805ac7":"## Tratamento de valores faltantes","3112f0f1":"Agora vamos tratar os valores faltantes que ficaram, substituindo eles pela mediana, pois \u00e9 uma estat\u00edstica que n\u00e3o \u00e9 muito influenciada por outliers.","d96b0a64":"Na base de teste, vamos pegar o numero de atendimento de cada indiv\u00edduo e verificar se ele estava na base de treino, se sim, vamos pegar a contagem de vezes que ele apareceu na base de treino e colocar na base de teste. Se ele n\u00e3o apareceu ent\u00e3o vamos setar o valor 0.","9bb11c23":"# Voting Classifier","075c4c3e":"Como a vari\u00e1vel respiracao tinha muitos valores ausentes, decidi tirar ela do modelo.","36950f7c":"# XG Boost","c68e8952":"Para o processo de modelogem vamos testar varios modelos e diferentes, e ap\u00f3s isso vamos testar algumas t\u00e9cnicas de ensemble com esses modelos."}}