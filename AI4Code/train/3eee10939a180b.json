{"cell_type":{"7cb401b6":"code","74ac6af6":"code","e9532fbc":"code","0c2ba918":"code","1821d747":"code","cb30d199":"code","a842d1ec":"code","27e3d224":"code","44b09f89":"code","d48dc575":"code","60ef483d":"code","9dbe58bc":"code","a49e52e5":"code","2f4798e1":"code","9e134dea":"code","196d2cfe":"code","c339b65c":"code","830fef0f":"code","9b99f19e":"code","8d820834":"code","b30fde55":"code","3d76ec29":"code","05793672":"code","9a086a74":"markdown","0f4b72b3":"markdown","bfbcc643":"markdown","b8f1a34e":"markdown"},"source":{"7cb401b6":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset, random_split","74ac6af6":"train_df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_df = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")","e9532fbc":"train_df.head()","0c2ba918":"print(train_df.shape)\nprint(test_df.shape)","1821d747":"train_df.info()","cb30d199":"df =train_df.isna().sum() > 0\ncol = df[df.values]","a842d1ec":"train_df1 = train_df.drop(columns = col.index)\ntest_df1 = test_df.drop(columns = col.index)\n","27e3d224":"col2= train_df1.dtypes[train_df1.dtypes.values == 'object']\ncol2","44b09f89":"train_df1 = train_df1.drop(columns = col2.index , axis=1)\ntest_df1 = test_df1.drop(columns = col2.index , axis=1 )\n","d48dc575":"print(train_df1.shape , test_df1.shape)","60ef483d":"inputs = train_df1.drop(['SalePrice' ,'Id'], axis=1).values\ntargets = train_df1[['SalePrice']].values\ninputs.shape , targets.shape","9dbe58bc":"input_size = 33\noutput_size = 1\nbatch_size = 200","a49e52e5":"dataset = TensorDataset(torch.tensor(inputs , dtype=torch.float32), torch.tensor(targets,dtype=torch.float32))   #torch.utils.Data\ntrain_ds , val_ds = random_split(dataset, [1160 , 300])\ntrain_loader=DataLoader(train_ds , batch_size , shuffle=True)\nval_loader = DataLoader(val_ds , batch_size*2)","2f4798e1":"test_ds = torch.tensor(test_df1.drop('Id' , axis=1).values , dtype= torch.float32)\n","9e134dea":"class HousingModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(input_size, output_size)\n        \n    def forward(self, xb):\n        out = self.linear(xb)\n        return out\n    \n    def training_step(self, batch):\n        inputs, targets = batch \n        out = self(inputs)                 # Generate predictions\n        loss = F.smooth_l1_loss(out, targets)    # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        inputs, targets = batch \n        out = self(inputs)                 # Generate predictions\n        loss = F.smooth_l1_loss(out, targets)    # Calculate loss\n        return {'val_loss': loss.detach()}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        return {'val_loss': epoch_loss.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch, result['val_loss']))\n    \nmodel = HousingModel()","196d2cfe":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","c339b65c":"result = evaluate(model , val_loader)\nresult","830fef0f":"lr = 1e-3\nhistory = fit(10, lr, model, train_loader, val_loader)","9b99f19e":"losses = [r['val_loss'] for r in [result] + history]\nplt.plot(losses, '-x')\nplt.xlabel('epoch')\nplt.ylabel('val_loss')\nplt.title('val_loss vs. epochs');","8d820834":"def predict_single(x, model):\n    xb = x.unsqueeze(0)\n    return model(x).item()","b30fde55":"x, target = val_ds[20]\npred = predict_single(x, model)\nprint(\"Input: \", x)\nprint(\"Target: \", target.item())\nprint(\"Prediction:\", pred)","3d76ec29":"pred = model(test_ds)\npred = pred.detach().numpy().astype('int64').reshape(-1)\nsubmission = pd.DataFrame({'Id': test_df1['Id'], 'SalePrice': pred})\nsubmission.to_csv('submission.csv', index=False)","05793672":"submission.info()","9a086a74":"# Creating The Model","0f4b72b3":"# Data exploration \n\nLet's first explore the data and create a dataframe that can be converted to tensor dataset readily.","bfbcc643":"# Create & Load The Dataset in Tensorform","b8f1a34e":"# Training The Model"}}