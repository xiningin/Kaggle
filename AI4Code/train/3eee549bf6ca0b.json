{"cell_type":{"1158e717":"code","c4875da9":"code","247a610c":"code","b07f4cb5":"code","6eaee272":"code","a17ac9bc":"code","86452abc":"code","9c89c5a1":"code","d04a1010":"code","fe890906":"code","d783954a":"code","618e222a":"code","598c6f0e":"code","81e79e8f":"code","460deba5":"code","bcf11ef3":"code","9dbaa058":"code","1899a957":"code","3d1a1205":"code","347d62e2":"code","f65bbf8a":"code","61f8b0a7":"markdown","8fcdf6d0":"markdown","663cd2ea":"markdown","97cad084":"markdown"},"source":{"1158e717":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c4875da9":"import matplotlib.pyplot as plt\nimport seaborn as sns","247a610c":"from IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity='all'","b07f4cb5":"my_data = pd.read_csv('..\/input\/yeh-concret-data\/Concrete_Data_Yeh.csv')\nmy_data.shape","6eaee272":"my_input = my_data.iloc[:,0:8]\nmy_target = pd.DataFrame(my_data.iloc[:,8:9])\nmy_input.head()\nmy_target","a17ac9bc":"f, ax = plt.subplots(figsize=(10,10))\nmask = np.triu(np.ones_like(my_data.corr(), dtype=np.bool))\nheatmap = sns.heatmap(my_data.corr(), mask=mask, vmin=-1, vmax=1, annot=True)\nfigure = heatmap.get_figure()    \nfigure.savefig('svm_conf.png', dpi=200, bbox_inches='tight')","86452abc":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split","9c89c5a1":"from sklearn.feature_selection import SelectKBest, f_regression\nselector = SelectKBest(score_func=f_regression, k='all')\nselector.fit(my_input, my_target.values.ravel())\nmy_input_selector = selector.transform(my_input)\nselector.scores_\n\nplt.bar(my_data.columns[0:8], selector.scores_);\nplt.xticks(rotation=90);","d04a1010":"input_train, input_test, target_train, target_test = train_test_split(my_input, my_target)\ninput_train.shape\ninput_test.shape\ntarget_train.shape\ntarget_test.shape","fe890906":"scaler = StandardScaler().fit(input_train) # \u015euan X-train Min ve Max()  #\u00f6nce train datas\u0131 i\u00e7in bir scaler olu\u015fturulur.\n#daha sonra test datas\u0131 bu scaler a g\u00f6re scale edilir. bu i\u015flem y verisi i\u00e7in de yap\u0131l\u0131r.\ninput_train_sc = scaler.transform(input_train)\ninput_test_sc = scaler.transform(input_test)\n\nscaler1 = StandardScaler().fit(target_train)\ntarget_train_sc = scaler1.transform(target_train)\ntarget_test_sc = scaler1.transform(target_test)","d783954a":"from sklearn.svm import SVR\nfrom sklearn.model_selection import GridSearchCV\nregressor = SVR()\nregressor.fit(input_train, np.ravel(target_train))\npred = regressor.predict(input_test)\n#regressor.score(target_test,pred)","618e222a":"param_grid = {'C': [0.1,1,10],\n             'gamma': [1,0.1],\n             'kernel': ['rbf', 'sigmoid']}\ngrid = GridSearchCV(SVR(), param_grid, refit = True, verbose = 0);\ngrid.fit(input_train,np.ravel(target_train));","598c6f0e":"from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nprint('best params:', grid.best_params_)\nprint('best estimator:', grid.best_estimator_)\nprint('best score:', grid.best_score_)\nbest_regressor = grid.best_estimator_\nbest_preds = best_regressor.predict(input_test)\nprint('MAE:', mean_absolute_error(best_preds, target_test))\nprint('MSE:', mean_squared_error(best_preds, target_test))\nprint('R^2:', r2_score(best_preds, target_test))","81e79e8f":"sonuclar = pd.concat([pd.DataFrame(best_preds), pd.DataFrame(target_test.values)], axis=1)\nsonuclar.columns = ['Predicted values', 'Measured values']\nsonuclar","460deba5":"plt.figure(figsize=(5,5))\nplt.scatter(x=best_preds, y=target_test)\nx=[0,80]\ny=[0,80]\nplt.plot(x,y,'--', c='r')\nplt.xlabel('predicted values')\nplt.ylabel('measured values');","bcf11ef3":"regressor1 = SVR()\nregressor1.fit(input_train_sc, np.ravel(target_train_sc))\npreds = regressor1.predict(input_test_sc)\nregressor1.score(input_test_sc,target_test_sc.ravel())","9dbaa058":"param_grid = {'C': [0.1,1,10],\n             'gamma': [1,0.1],\n             'kernel': ['rbf', 'sigmoid']};\ngrid1 = GridSearchCV(SVR(), param_grid, refit = True, verbose = 0);\ngrid1.fit(input_train_sc,np.ravel(target_train_sc));","1899a957":"from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score","3d1a1205":"print('best params1:', grid1.best_params_)\nprint('best estimator1:', grid1.best_estimator_)\nprint('best score1:', grid1.best_score_)\nbest_regressor1 = grid1.best_estimator_\nbest_preds1 = best_regressor1.predict(input_test_sc)\nmae1 = mean_absolute_error(target_test_sc, best_preds1)\nmse1 = mean_squared_error(target_test_sc, best_preds1)\nmae1, mse1\nreal_best_preds = pd.DataFrame(scaler1.inverse_transform(best_preds1))\nprint('MAE:', mean_absolute_error(real_best_preds, target_test))\nprint('MSE:', mean_squared_error(real_best_preds, target_test))\nprint('R^2:', r2_score(real_best_preds, target_test))","347d62e2":"sonuclar1 = pd.concat([pd.DataFrame(real_best_preds), pd.DataFrame(target_test.values)], axis=1)\nsonuclar1.columns = ['Predicted values', 'Measured values']\nsonuclar1","f65bbf8a":"plt.figure(figsize=(5,5))\nplt.scatter(real_best_preds, target_test)\nx=[0,80]\ny=[0,80]\nplt.plot(x,y,'--', c='r')\nplt.xlabel('predicted values')\nplt.ylabel('measured values');","61f8b0a7":"#### NOW BUILD SVR MODEL WITH SCALED DATA","8fcdf6d0":"The data used is from UCI Repository-Concerete Compressive Strenght Data.\n* \nName -- Data Type -- Measurement -- Description\n\nCement (component 1) -- quantitative -- kg in a m3 mixture -- Input Variable\nBlast Furnace Slag (component 2) -- quantitative -- kg in a m3 mixture -- Input Variable\nFly Ash (component 3) -- quantitative -- kg in a m3 mixture -- Input Variable\nWater (component 4) -- quantitative -- kg in a m3 mixture -- Input Variable\nSuperplasticizer (component 5) -- quantitative -- kg in a m3 mixture -- Input Variable\nCoarse Aggregate (component 6) -- quantitative -- kg in a m3 mixture -- Input Variable\nFine Aggregate (component 7) -- quantitative -- kg in a m3 mixture -- Input Variable\nAge -- quantitative -- Day (1~365) -- Input Variable\nConcrete compressive strength -- quantitative -- MPa -- Output Variable\n","663cd2ea":"#### LETS BUILD A SVR MODEL BEFORE SCALING THE DATA","97cad084":"### Check for collinearity[](http:\/\/)"}}