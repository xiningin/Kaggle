{"cell_type":{"0b7f0ee9":"code","367bfe66":"code","5822b4ea":"code","d4b790cf":"code","b8fa66f7":"code","e4e2f124":"code","0d88b013":"code","5b754c86":"code","0ce540fa":"code","b055ed1b":"code","7e7140ac":"code","cabe9f13":"code","026fff6b":"code","09c5bb2e":"code","13c5e775":"code","709655a2":"code","d363fed0":"code","98728f2c":"code","64c11baf":"code","95677c20":"code","62cc0777":"code","444710fe":"code","2a4de77b":"code","6340ee49":"code","fb29abe1":"code","6570cfc0":"code","881596c9":"code","b5a34e09":"code","136af8f0":"markdown","7ac4c6a6":"markdown","9d8ad01f":"markdown","64b9f137":"markdown","16d6a0a4":"markdown","d7695bc3":"markdown","84098500":"markdown"},"source":{"0b7f0ee9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, auc, roc_curve, confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\n\n%matplotlib inline\nwarnings.filterwarnings('ignore')","367bfe66":"df = pd.read_csv(\"\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv\")\ndf.head()","5822b4ea":"df_copy = df.copy()","d4b790cf":"df_copy.isnull().sum()","b8fa66f7":"df_copy.info()","e4e2f124":"df_copy.describe()","0d88b013":"df_copy.shape","5b754c86":"plt.figure(figsize=(20,25))\nindex = 1\ncolumns = ['age', 'trtbps', 'chol','thalachh'] \nfor i in columns:\n    plt.subplot(4,4,index)\n    sns.distplot(df_copy[i])\n    plt.xlabel(i)\n    plt.ylabel('value')\n    index += 1","0ce540fa":"plt.figure(figsize=(20,25))\nindex = 1\ncol = ['sex', 'cp','fbs', 'restecg','exng','oldpeak','slp','caa','thall','output'] \nfor i in col:\n    plt.subplot(4,4,index)\n    sns.countplot(df_copy[i])\n    plt.xlabel(i)\n    plt.ylabel('value')\n    index += 1","b055ed1b":"plt.figure(figsize=(12,10))\nsns.heatmap(df_copy.corr(),annot=True)","7e7140ac":"def classification_report(model,x_test,y_test,model_name):\n    y_pre = model.predict(x_test)\n    tn, fp, fn, tp = confusion_matrix(y_test,y_pre).ravel()\n    \n    accuracy = accuracy_score(y_test,y_pre)\n    recall = recall_score(y_test,y_pre)\n    precision = precision_score(y_test,y_pre)\n    f1_score_result = f1_score(y_test,y_pre)\n    \n    print('classification report for ',model_name)\n    \n    print('tn = ',tn)\n    print('fp = ',fp)\n    print('fn = ',fn)\n    print('tp = ',tp)\n    \n    print('accuracy = ', accuracy)\n    print('recall = ', recall)\n    print('precision = ', precision)\n    print('F1-score = ',f1_score_result)\n    \n    fpr, tpr, _ = roc_curve(y_test,y_pre)\n    auc_model = auc(fpr,tpr)\n    plt.figure(figsize=(5,5),dpi=100)\n\n    plt.plot(fpr,tpr,linestyle = '-',label= model_name + ' (auc = %0.3f)' % (auc_model))\n\n    plt.xlabel('False Positve Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(label='ROC Curve')\n    plt.legend()\n    plt.show()","cabe9f13":"x = df_copy.drop('output',axis=1)\ny = df_copy['output']","026fff6b":"x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3, random_state=120)","09c5bb2e":"params = {\n    'C':[0.1,1,5,10,15],\n    'gamma':[0.001,0.01,0.1],\n    'kernel':['rbf','sigmoid','linear']\n}","13c5e775":"clf = GridSearchCV(SVC(),params,cv=10,return_train_score=False)\nclf.fit(x_train,y_train)","709655a2":"results = pd.DataFrame(clf.cv_results_)\nresults","d363fed0":"rbf = results[results['param_kernel'] == 'rbf']\nrbf = rbf[['param_C','param_kernel','mean_test_score']]\nrbf","98728f2c":"sigmoid = results[results['param_kernel'] == 'sigmoid']\nsigmoid = sigmoid[['param_C','param_kernel','mean_test_score']]\nsigmoid","64c11baf":"linear = results[results['param_kernel'] == 'linear']\nlinear = results[['param_C','param_kernel','mean_test_score']]\nlinear","95677c20":"plt.xlabel('C')\nplt.ylabel('Accuracy in training set')\nplt.title('SVM Optimization')\n\nplt.plot(rbf['param_C'],rbf['mean_test_score'] , label='rbf kernel')\nplt.plot(sigmoid['param_C'],sigmoid['mean_test_score'] , label='sigmoid kernel')\nplt.plot(linear['param_C'],linear['mean_test_score'] , label='linear kernel')\n\nplt.legend()\nplt.grid()","62cc0777":"param2 = {\n            'n_estimators':[10,20,40,80,100,150,200,250,255,300,350],\n            'criterion':['gini','entropy']\n}","444710fe":"clf2 = GridSearchCV(RandomForestClassifier(),param2,cv=10,return_train_score=False)\nclf2.fit(x_train,y_train)","2a4de77b":"results2 = pd.DataFrame(clf2.cv_results_)\nresults2","6340ee49":"gini = results2[results2['param_criterion'] == 'gini']\ngini = gini[['param_n_estimators','param_criterion','mean_test_score']]\ngini","fb29abe1":"entropy = results2[results2['param_criterion'] == 'entropy']\nentropy = entropy[['param_n_estimators','param_criterion','mean_test_score']]\nentropy","6570cfc0":"plt.xlabel('n_estimators')\nplt.ylabel('Accuracy in training set')\nplt.title('RF Optimization')\n\nplt.plot(gini['param_n_estimators'],gini['mean_test_score'] , label='gini')\nplt.plot(entropy['param_n_estimators'],entropy['mean_test_score'] , label='entropy')\n\nplt.legend()\nplt.grid()","881596c9":"classification_report(clf.best_estimator_,x_test,y_test,'SVM')","b5a34e09":"classification_report(clf2.best_estimator_,x_test,y_test,'Random Forest')","136af8f0":"# Results of classifiers with ROC Curve","7ac4c6a6":"# If you like the notebook, consider giving an upvote.","9d8ad01f":"# Optimization","64b9f137":"# Data Visualization","16d6a0a4":"# Prepare the classification report function","d7695bc3":"# Understanding Data","84098500":"Split the features from the output and divide the dataset into train and test 80:30"}}