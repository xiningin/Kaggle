{"cell_type":{"39ddb9a1":"code","bfc1521a":"code","8bf9de9e":"code","9602b122":"code","cbc30bf7":"code","fa610113":"code","fa91a54e":"code","196c2fe2":"code","b53a33e1":"code","0c4723a7":"code","76db3ac3":"code","99cf1eb2":"code","ea71b60f":"code","9a8781d0":"code","bd736618":"code","2d7e0e9f":"code","a0bb5167":"code","8e6d2d79":"code","b1eec71e":"code","0f5efe8d":"code","c780a44c":"code","fe9b00da":"code","065c65d0":"code","6be4ab2f":"code","ce25e032":"markdown","52be575d":"markdown","380e1387":"markdown","db6f6dfb":"markdown","c7d5895b":"markdown","35da45d4":"markdown","df000092":"markdown","611c758e":"markdown"},"source":{"39ddb9a1":"# General Libs\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input","bfc1521a":"im_shape = (180,180)\n\nTRAINING_DIR = '..\/input\/dogs-cats-images\/dog vs cat\/dataset\/training_set'\nTEST_DIR = '..\/input\/dogs-cats-images\/dog vs cat\/dataset\/test_set'\n\nseed = 10\n\nBATCH_SIZE = 100","8bf9de9e":"#Using keras ImageGenerator and flow_from_directoty\n\n# Subdivision in test\/validation\ndata_generator = ImageDataGenerator(rescale=1.\/255, validation_split=0.2)\nval_data_generator = ImageDataGenerator(rescale=1.\/255, validation_split=0.2)","9602b122":"# If you want data augmentation, uncomment and run this cell\ndata_generator = ImageDataGenerator(\n        validation_split=0.2,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\n\nval_data_generator = ImageDataGenerator(rescale=1.\/255, validation_split=0.2)","cbc30bf7":"# Generator para parte train\ntrain_generator = data_generator.flow_from_directory(TRAINING_DIR, target_size=im_shape, shuffle=True, seed=seed,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\")\n# Generator para parte valida\u00e7\u00e3o\nvalidation_generator = val_data_generator.flow_from_directory(TRAINING_DIR, target_size=im_shape, shuffle=False, seed=seed,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"validation\")\n\n# Generator para dataset de teste\ntest_generator = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_generator.flow_from_directory(TEST_DIR, target_size=im_shape, shuffle=False, seed=seed,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE)\n\nnb_train_samples = train_generator.samples\nnb_validation_samples = validation_generator.samples\nnb_test_samples = test_generator.samples\nclasses = list(train_generator.class_indices.keys())\nprint('Classes: '+str(classes))\nnum_classes  = len(classes)\n","fa610113":"# Visualizing some examples\nplt.figure(figsize=(15,15))\nfor i in range(9):\n    #gera subfigures\n    plt.subplot(330 + 1 + i)\n    batch = train_generator.next()[0]*255\n    image = batch[0].astype('uint8')\n    plt.imshow(image)\nplt.show()","fa91a54e":"model = Sequential()\nmodel.add(Conv2D(20, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(im_shape[0],im_shape[1],3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(40, kernel_size=(3,3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(num_classes, activation='softmax'))\nmodel.summary()\n\n# Compila o modelo\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(),\n              metrics=['accuracy'])","196c2fe2":"epochs = 5\n\n#Callback to save the best model\ncallbacks_list = [\n    keras.callbacks.ModelCheckpoint(\n        filepath='model.h5',\n        monitor='val_loss', save_best_only=True, verbose=1),\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,verbose=1)\n]\n\n#Training\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch=nb_train_samples \/\/ BATCH_SIZE,\n        epochs=epochs,\n        callbacks = callbacks_list,\n        validation_data=validation_generator,\n        verbose = 1,\n        validation_steps=nb_validation_samples \/\/ BATCH_SIZE)","b53a33e1":"# Training curves\nimport matplotlib.pyplot as plt\n\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\n\nepochs_x = range(1, len(loss_values) + 1)\nplt.figure(figsize=(10,10))\nplt.subplot(2,1,1)\nplt.plot(epochs_x, loss_values, 'bo', label='Training loss')\nplt.plot(epochs_x, val_loss_values, 'b', label='Validation loss')\nplt.title('Training and validation Loss and Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.subplot(2,1,2)\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\nplt.plot(epochs_x, acc_values, 'bo', label='Training acc')\nplt.plot(epochs_x, val_acc_values, 'b', label='Validation acc')\n#plt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Acc')\nplt.legend()\nplt.show()","0c4723a7":"# Load the best saved model\nfrom tensorflow.keras.models import load_model\n\nmodel = load_model('model.h5')","76db3ac3":"# Using the validation dataset\nscore = model.evaluate_generator(validation_generator)\nprint('Val loss:', score[0])\nprint('Val accuracy:', score[1])","99cf1eb2":"# Using the test dataset\nscore = model.evaluate_generator(test_generator)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","ea71b60f":"import itertools\n\n#Plot the confusion matrix. Set Normalize = True\/False\ndef plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        cm = np.around(cm, decimals=2)\n        cm[np.isnan(cm)] = 0.0\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n","9a8781d0":"# Some reports\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n\n#On test dataset\nY_pred = model.predict_generator(test_generator)\ny_pred = np.argmax(Y_pred, axis=1)\ntarget_names = classes\n\n#Confution Matrix\ncm = confusion_matrix(test_generator.classes, y_pred)\nplot_confusion_matrix(cm, target_names, normalize=False, title='Confusion Matrix')\n\n#Classification Report\nprint('Classification Report')\nprint(classification_report(test_generator.classes, y_pred, target_names=target_names))","bd736618":"# Generator para parte train\ntrain_generator = data_generator.flow_from_directory(TRAINING_DIR, target_size=im_shape, shuffle=True, seed=seed,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\")\n# Generator para parte valida\u00e7\u00e3o\nvalidation_generator = val_data_generator.flow_from_directory(TRAINING_DIR, target_size=im_shape, shuffle=False, seed=seed,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"validation\")\n\n# Generator para dataset de teste\ntest_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\ntest_generator = test_generator.flow_from_directory(TEST_DIR, target_size=im_shape, shuffle=False, seed=seed,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE)\n\nnb_train_samples = train_generator.samples\nnb_validation_samples = validation_generator.samples\nnb_test_samples = test_generator.samples\nclasses = list(train_generator.class_indices.keys())\nprint('Classes: '+str(classes))\nnum_classes  = len(classes)","2d7e0e9f":"# Visualizando alguns exemplos do dataset por meio do Generator criado\nplt.figure(figsize=(15,15))\nfor i in range(9):\n    #gera subfigures\n    plt.subplot(330 + 1 + i)\n    batch = train_generator.next()[0]*255\n    image = batch[0].astype('uint8')\n    plt.imshow(image)\nplt.show()","a0bb5167":"base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(im_shape[0], im_shape[1], 3))\n\nx = base_model.output\nx = Flatten()(x)\nx = Dense(100, activation='relu')(x)\npredictions = Dense(num_classes, activation='softmax', kernel_initializer='random_uniform')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# Freezing pretrained layers\nfor layer in base_model.layers:\n    layer.trainable=False\n    \noptimizer = Adam()\nmodel.compile(optimizer=optimizer,loss='categorical_crossentropy',metrics=['accuracy'])","8e6d2d79":"epochs = 5\n\n# Saving the best model\ncallbacks_list = [\n    keras.callbacks.ModelCheckpoint(\n        filepath='model.h5',\n        monitor='val_loss', save_best_only=True, verbose=1),\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,verbose=1)\n]\n\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch=nb_train_samples \/\/ BATCH_SIZE,\n        epochs=epochs,\n        callbacks = callbacks_list,\n        validation_data=validation_generator,\n        verbose = 1,\n        validation_steps=nb_validation_samples \/\/ BATCH_SIZE)","b1eec71e":"#Vamos ver como foi o treino?\nimport matplotlib.pyplot as plt\n\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\n\nepochs_x = range(1, len(loss_values) + 1)\nplt.figure(figsize=(10,10))\nplt.subplot(2,1,1)\nplt.plot(epochs_x, loss_values, 'bo', label='Training loss')\nplt.plot(epochs_x, val_loss_values, 'b', label='Validation loss')\nplt.title('Training and validation Loss and Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n#plt.legend()\nplt.subplot(2,1,2)\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\nplt.plot(epochs_x, acc_values, 'bo', label='Training acc')\nplt.plot(epochs_x, val_acc_values, 'b', label='Validation acc')\n#plt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Acc')\nplt.legend()\nplt.show()","0f5efe8d":"from tensorflow.keras.models import load_model\n# Load the best saved model\nmodel = load_model('model.h5')","c780a44c":"# Using the validation dataset\nscore = model.evaluate_generator(validation_generator)\nprint('Val loss:', score[0])\nprint('Val accuracy:', score[1])","fe9b00da":"# Using the test dataset\nscore = model.evaluate_generator(test_generator)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","065c65d0":"import itertools\n\n#Plot the confusion matrix. Set Normalize = True\/False\ndef plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        cm = np.around(cm, decimals=2)\n        cm[np.isnan(cm)] = 0.0\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","6be4ab2f":"# Some reports\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n\n#Confution Matrix and Classification Report\nY_pred = model.predict_generator(test_generator)#, nb_test_samples \/\/ BATCH_SIZE, workers=1)\ny_pred = np.argmax(Y_pred, axis=1)\ntarget_names = classes\n\n#Confution Matrix\ncm = confusion_matrix(test_generator.classes, y_pred)\nplot_confusion_matrix(cm, target_names, normalize=False, title='Confusion Matrix')\nprint('Classification Report')\nprint(classification_report(test_generator.classes, y_pred, target_names=target_names))","ce25e032":"# Lendo o dataset","52be575d":"## Evaluating the model","380e1387":"# Transfer Leaning","db6f6dfb":"### Reading the dataset","c7d5895b":"___","35da45d4":"### Showing some examples","df000092":"## Creating a simple CNN Model## Creating a simple CNN Model","611c758e":"# Transfer Learning from a Deep Model"}}