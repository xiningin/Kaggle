{"cell_type":{"6610ad18":"code","de1774d5":"code","760d8495":"code","e0449b99":"code","1e1ba2d3":"code","1027c899":"code","4ef43350":"code","ee044425":"code","3c9f5214":"code","092a4adf":"code","cef707a4":"code","5a1427f0":"code","8114d079":"code","ac4719ba":"code","a5975e92":"code","4d11d0f3":"code","1b0e343f":"code","d73cdc92":"code","3e0f0613":"code","41a172bc":"code","34f6d387":"code","8a0cd085":"code","be2fcdeb":"code","2f9ff7a8":"code","94945188":"code","3aa40b74":"code","a9b74b14":"code","0a7aa8b8":"code","3b4f2da9":"code","06bace01":"code","bb2360d6":"code","73a20d66":"code","5a56fb68":"markdown","4ebf7628":"markdown","3064d484":"markdown","338b5347":"markdown","b16945a9":"markdown","1cade283":"markdown","e32e301f":"markdown","b7393a35":"markdown","b89f61fd":"markdown","853cfc8f":"markdown","d127c3a0":"markdown","6b09daf3":"markdown","42927ec3":"markdown","649e86a2":"markdown"},"source":{"6610ad18":"%matplotlib inline\nimport cv2 # opencv \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\nfrom skimage.color import rgb2gray\nfrom skimage.util import montage as montage2d\nfrom tqdm import tqdm_notebook\nplt.rcParams[\"figure.figsize\"] = (8, 8)\nplt.rcParams[\"figure.dpi\"] = 125\nplt.rcParams[\"font.size\"] = 14\nplt.rcParams['font.family'] = ['sans-serif']\nplt.rcParams['font.sans-serif'] = ['DejaVu Sans']\nplt.style.use('ggplot')\nsns.set_style(\"whitegrid\", {'axes.grid': False})","de1774d5":"def video_to_frames(in_path):\n    \"\"\"Read video and output frames and time-stamps as a generator.\"\"\"\n    c_cap = cv2.VideoCapture(in_path)\n    if (not c_cap.isOpened()): \n        raise ValueError(\"Error opening video stream or file\")\n    status = True\n    while status:\n        ret, frame = c_cap.read()\n        if not ret: break\n        time_stamp = c_cap.get(cv2.CAP_PROP_POS_MSEC)\n        yield time_stamp, cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n    c_cap.release()","760d8495":"video_path = '..\/input\/slice821_tser.avi'\nvideo_src = video_to_frames(video_path)\nvideo_src","e0449b99":"ts_0, frame_0 = next(video_src)\nplt.imshow(frame_0)\nprint(ts_0)","1e1ba2d3":"time_axis = []\nframe_axis = []\nfor ts, frame in tqdm_notebook(video_to_frames(video_path)):\n    time_axis += [ts]\n    frame_axis += [rgb2gray(frame)]\n    ","1027c899":"time_vec = np.stack(time_axis, 0)\nframe_vec = np.stack(frame_axis, 0)\ndel time_axis\ndel frame_axis\nprint(time_vec.shape, frame_vec.shape)","4ef43350":"fig, ax1 = plt.subplots(1, 1, figsize=(15, 15))\nax1.imshow(montage2d(frame_vec[::2, ::4, ::4]), cmap='gray')","ee044425":"from scipy.ndimage import median_filter, zoom\n# filter and downsample\nfilt_frame = zoom(median_filter(frame_vec, [2, 3, 3]), [1, 0.5, 0.5])","3c9f5214":"# keep memory usage low\nimport gc\ndel frame_vec # remove the unfiltered data\ngc.collect()","092a4adf":"fig, ax1 = plt.subplots(1, 1, figsize=(15, 15))\nax1.imshow(montage2d(filt_frame[::2, ::4, ::4]), cmap='gray')","cef707a4":"from skimage.filters import try_all_threshold\ntry_all_threshold(filt_frame[10]) # first \ntry_all_threshold(filt_frame[filt_frame.shape[0]\/\/2]) # middle\ntry_all_threshold(filt_frame[-1]) # last","5a1427f0":"from skimage.filters import threshold_mean\nfig, ax1 = plt.subplots(1, 1, figsize=(15, 5))\nbins = np.linspace(0, 1, 255)\nax1.hist(filt_frame.ravel(), bins)\nax1.axvline(threshold_mean(filt_frame), label='Whole Image Threshold', c='b', lw=2)\nfor i, c_slice in enumerate(filt_frame):\n    ax1.axvline(threshold_mean(c_slice), label='Slice Threshold', c='g', alpha=0.25)\n    if i==0:\n        ax1.legend()\nax1.set_yscale('log')\nax1.set_ylabel('Pixel Count')\nax1.set_xlabel('Intensity')","8114d079":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(30, 15))\n# whole image\nax1.imshow(montage2d(filt_frame[::12, ::4, ::4]>threshold_mean(filt_frame)), cmap='gray')\nax1.set_title('Whole Image Threshold')\nax2.imshow(montage2d(np.stack([c_img>threshold_mean(c_img) for c_img in filt_frame[::12]],0)[:, ::4, ::4]), cmap='gray')\nax2.set_title('Slice-based Threshold')","ac4719ba":"seg_frames = filt_frame>threshold_mean(filt_frame)","a5975e92":"from skimage.morphology import convex_hull_image\nhull_frames = np.stack([convex_hull_image(c_img) for c_img in seg_frames], 0)\nbubble_frames = (hull_frames^seg_frames) & hull_frames\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(30, 15))\n# whole image\nax1.imshow(montage2d(hull_frames[::12, ::4, ::4]), cmap='gray')\nax1.set_title('Convex Hull')\nax2.imshow(montage2d(bubble_frames[::12, ::4, ::4]), cmap='gray')\nax2.set_title('Segmented Bubbles')","4d11d0f3":"from skimage.morphology import erosion, ball\nhull_frames = erosion( # erode the hull\n    np.stack([convex_hull_image(c_img) \n              for c_img in \n              erosion(seg_frames, ball(3)) # erode the segmentation\n             ], 0), \n    ball(3))\n\nbubble_frames = (hull_frames^seg_frames) & hull_frames\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(30, 15))\n# whole image\nax1.imshow(montage2d(hull_frames[::12, ::4, ::4]), cmap='gray')\nax1.set_title('Convex Hull')\nax2.imshow(montage2d(bubble_frames[::12, ::4, ::4]), cmap='gray')\nax2.set_title('Segmented Bubbles')","1b0e343f":"bubble_frames.shape","d73cdc92":"from skimage.io import imsave\nimsave('bubbles.tif', bubble_frames.astype(np.uint8)) # convert to 8-bit format to save","3e0f0613":"%%time\nfrom skimage.measure import label\nbubble_labels = label(bubble_frames)","41a172bc":"fig, ax1 = plt.subplots(1, 1, figsize=(10, 5))\nax1.hist(bubble_labels[bubble_labels>0], np.arange(1+np.max(bubble_labels.ravel())))\nax1.set_yscale('log')\nax1.set_title('Connected Size Distribution')\nax1.set_xlabel('Component Number')\nax1.set_ylabel('Pixel Count')","34f6d387":"fig, ax1 = plt.subplots(1, 1, figsize=(10, 5))\nbin_counts, _ = np.histogram(bubble_labels[bubble_labels>0], np.arange(1+np.max(bubble_labels.ravel())))\nax1.hist(bin_counts, np.logspace(0, 7, 30))\nax1.set_xscale('log')\nax1.set_title('Object Size')\nax1.set_xlabel('Number of Components')\nax1.set_xlabel('Pixel Count')","8a0cd085":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(30, 15))\n# whole image\nax1.imshow(montage2d(bubble_frames[::12, ::4, ::4]), cmap='gray')\nax1.set_title('Convex Hull')\nax2.imshow(montage2d(bubble_labels[::12, ::4, ::4]), cmap=plt.cm.nipy_spectral)\nax2.set_title('Segmented Bubbles')","be2fcdeb":"from warnings import warn\nimport warnings\ndef scalar_attributes_list(im_props):\n    \"\"\"\n    Makes list of all scalar, non-dunder, non-hidden\n    attributes of skimage.measure.regionprops object\n    \"\"\"\n\n    attributes_list = []\n\n    for i, test_attribute in enumerate(dir(im_props[0])):\n\n        # Attribute should not start with _ and cannot return an array\n        # does not yet return tuples\n        try:\n            if test_attribute[:1] != '_' and not \\\n                    isinstance(getattr(im_props[0], test_attribute),\n                               np.ndarray):\n                attributes_list += [test_attribute]\n        except Exception as e:\n            warn(\"Not implemented: {} - {}\".format(test_attribute, e),\n                 RuntimeWarning)\n\n    return attributes_list\n\ndef regionprops_to_df(im_props):\n    \"\"\"\n    Read content of all attributes for every item in a list\n    output by skimage.measure.regionprops\n    \"\"\"\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        attributes_list = scalar_attributes_list(im_props)\n\n    # Initialise list of lists for parsed data\n    parsed_data = []\n\n    # Put data from im_props into list of lists\n    for i, _ in enumerate(im_props):\n        parsed_data += [[]]\n\n        for j in range(len(attributes_list)):\n            parsed_data[i] += [getattr(im_props[i], attributes_list[j])]\n\n    # Return as a Pandas DataFrame\n    return pd.DataFrame(parsed_data, columns=attributes_list)","2f9ff7a8":"from skimage.measure import label, regionprops\nregion_frames = [regionprops(label(c_bubbles)) for c_bubbles in bubble_frames]","94945188":"from IPython.display import clear_output\nall_regions_df = pd.concat([regionprops_to_df(c_frame).assign(time_ms=c_ts) \n                            for c_ts, c_frame in zip(time_vec, region_frames) \n                            if len(c_frame)>0], sort=False).reset_index(drop=True)\nclear_output() # makes a huge mess\nall_regions_df.sample(3)","3aa40b74":"all_regions_df['area'].hist(bins=np.linspace(0, 1000, 50))","a9b74b14":"all_regions_df['x'] = all_regions_df['centroid'].map(lambda x: x[0])\nall_regions_df['y'] = all_regions_df['centroid'].map(lambda x: x[1])\nall_regions_df.to_csv('tracked_bubbles.csv', index=False)\nall_regions_df.to_json('tracked_bubbles.json')","0a7aa8b8":"all_regions_df.query('area>50').plot.scatter('x', 'y')","3b4f2da9":"import plotly_express as px\nscatter_plot = px.scatter(x='x', y='y', \n                          animation_frame='time_ms', \n                          color='area', \n                          data_frame=all_regions_df.query('area>50'))\nscatter_plot","06bace01":"import plotly\nplotly.offline.plot(scatter_plot, filename='animation.html')","bb2360d6":"from matplotlib.animation import FuncAnimation\nbig_points_df = all_regions_df.query('area>100')\nfig, ax1 = plt.subplots(1, 1, figsize=(10, 10))\nax1.plot(big_points_df['x'].values, big_points_df['y'].values, '.', alpha=0.1, label='All Points')\n\ndef draw_frame(in_df):\n    [c_line.remove() \n       for c_ax in [ax1]\n       for c_line in c_ax.get_lines() \n       if c_line.get_label().startswith('_')];\n    ax1.plot(in_df['x'].values, in_df['y'].values, 'bs', alpha=0.5)\nout_anim = FuncAnimation(fig, draw_frame, [c_df for _, c_df in big_points_df.groupby('time_ms')])","73a20d66":"if False:\n    from IPython.display import HTML\n    HTML(out_anim.to_jshtml())\nelse:\n    out_anim.save('alu_frames.gif', bitrate=8000, fps=8)","5a56fb68":"# Labeling Bubbles","4ebf7628":"# Read and Process Data","3064d484":"# Animations","338b5347":"## Mean\nIt looks like the mean value looks best, we can try applying it slice by slice or by using a constant for the whole image (green vs blue)","b16945a9":"# Segmentation","1cade283":"## Labeling and Shape Analysis\nRun the labeling individually on each slice and then track the bubbles","e32e301f":"## Combine all Frames","b7393a35":"## Visualize All Frames","b89f61fd":"## Applying Threshold\nWe can try applying the threshold to the whole stack or frame by frame and compare the results. If they are similar we prefer the same threshold for the whole image since it is more consistent between slices","853cfc8f":"# Setup\nLoad the packages and make plots look nice-ish","d127c3a0":"## Cleaning up Hull Images\nWe can see that the hulls are a bit inaccurate, so we can first remove small objects (erosion) in the aluminum image and then erode the convex hull to avoid messy boundaries","6b09daf3":"## Import all Frames","42927ec3":"## Segmenting Bubbles\nWe have now segmented the aluminum, but we are interested in the bubbles. We can use convex hull in order to compute the boundary of aluminum ","649e86a2":"# Image Enhancement"}}