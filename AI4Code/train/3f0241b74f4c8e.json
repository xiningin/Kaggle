{"cell_type":{"0864e3d8":"code","a43b4ba1":"code","67fb2460":"code","21405be9":"code","e6271e96":"code","58db90a9":"code","ac130362":"code","8820f0f2":"code","38017f7c":"markdown","21573931":"markdown","fa3d5559":"markdown","5f20a714":"markdown","f8177ffa":"markdown","239647c1":"markdown"},"source":{"0864e3d8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.\noriginal =  pd.read_csv('..\/input\/data.csv')\nfi=original\nfi=pd.DataFrame(fi)\nfi = fi.drop(columns='Unnamed: 0')\nfi = fi.drop(columns='ID')\nfi = fi.drop(columns='Photo')\nfi = fi.drop(columns='Flag')\nfi = fi.drop(columns='Club Logo')\nfi = fi.drop(columns='Joined')\n#Correct currencies\ncurs=[\"Release Clause\", \"Value\", \"Wage\"]\nfor cur in curs:\n    \n    def curr_value(x):\n        x = str(x).replace('\u20ac', '')\n        if('M' in str(x)):\n            x = str(x).replace('M', '')\n            x = float(x) * 1000000\n        elif('K' in str(x)):\n            x = str(x).replace('K', '')\n            x = float(x) * 1000\n        return float(x)\n    fi[cur] = fi[cur].apply(curr_value)\n   \n#Correct -Dismiss + values\ncols=[\"LS\", \"ST\", \"RS\", \"LW\", \"LF\", \"CF\", \"RF\", \"RW\",\"LAM\", \"CAM\", \"RAM\", \"LM\", \"LCM\", \"CM\", \"RCM\", \"RM\", \"LWB\", \"LDM\",\"CDM\", \"RDM\", \"RWB\", \"LB\", \"LCB\", \"CB\", \"RCB\", \"RB\"]\nfor col in cols:\n    fi[col]=fi[col].str[:-2]\n    fi[col]=fi[col].astype(float)\n    \n#Convert contract end\nfi['Contract Valid Until']=fi['Contract Valid Until'].str[-4:]\nfi['Contract Valid Until']=fi['Contract Valid Until'].astype(float)\n    \n#Corect height values \nfi['Height']=fi['Height'].str.replace(\"'\",'.')\nfi['Height']=fi['Height'].astype(float)\n\n#Correct Weight\nfi['Weight']=fi['Weight'].str[:-3]\nfi['Weight']=fi['Weight'].astype(float)\n\n#X and y assignments\n#fi=(fi[fi[\"Position\"]!=\"GK\"])\nX = fi.loc[:, fi.columns != 'Value']\ny=fi.loc[:,['Value']]\nX = X.drop(columns='Name')\nX = X.drop(columns='Real Face')\n#identify Object columns\nobj_df = X.select_dtypes(include=['object']).copy()\nobj_df.head()\n","a43b4ba1":"#Encoding -1\nX_dum=pd.get_dummies(X[obj_df.columns], dummy_na=True,drop_first=True)\nX = pd.concat([X.drop(obj_df.columns, axis=1), pd.get_dummies(X[obj_df.columns])], axis=1)\n#See Correlations & Drop highly correlated attributes\nX1 = pd.DataFrame(X)\ncorr = X1.corr()\ncorr_matrix = X1.corr().abs()\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nto_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\nX=X.drop(columns=to_drop, axis=1)\ncolumnlist=X.columns.tolist()\n# Taking care of missing data\nfrom sklearn.preprocessing import Imputer\nimputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\nimputer = imputer.fit(X)\nX_m = imputer.transform(X)\nX=pd.DataFrame(X_m)\n\nfrom sklearn.preprocessing import Imputer\nimputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\nimputer = imputer.fit(y)\ny = imputer.transform(y)\ny=pd.DataFrame(y)\n\nfrom sklearn.preprocessing import Imputer\nimputer = Imputer(missing_values = 0, strategy = 'mean', axis = 0)\nimputer = imputer.fit(y)\ny = imputer.transform(y)\ny=pd.DataFrame(y)\n\n#Split Dataset Test vs. Train\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n","67fb2460":"def coeff_determination(y_test, y_pred):\n    from keras import backend as K\n    SS_res =  K.sum(K.square( y_test-y_pred ))\n    SS_tot = K.sum(K.square( y_test - K.mean(y_test) ) )\n    return ( 1 - SS_res\/(SS_tot + K.epsilon()))","21405be9":"#deep learning with keras lib\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom keras import backend as K\n# Initialising the ANN\nregressor = Sequential()\n# Adding the input layer and the first hidden layer\nregressor.add(Dense(output_dim = 624, kernel_initializer='normal', activation = 'relu', input_dim = 1248))\n# Adding the second hidden layer\nregressor.add(Dense(output_dim = 300, kernel_initializer='normal', activation = 'relu'))\n# Adding the 3rd hidden layer\nregressor.add(Dense(output_dim = 150, kernel_initializer='normal', activation = 'relu'))\n# Adding the 4th hidden layer\nregressor.add(Dense(output_dim = 75, kernel_initializer='normal', activation = 'relu'))\n# Adding the output layer\nregressor.add(Dense(output_dim = 1, kernel_initializer='normal', activation = 'linear'))\n# Compiling the ANN\ndef coeff_determination(y_test, y_pred):\n    from keras import backend as K\n    SS_res =  K.sum(K.square( y_test-y_pred ))\n    SS_tot = K.sum(K.square( y_test - K.mean(y_test) ) )\n    return ( 1 - SS_res\/(SS_tot + K.epsilon()))\nregressor.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = [coeff_determination])\n# Fitting the ANN to the Training set-I have tried it with different batch sizes and epochs but it was overfitted\nregressor.fit(X_train, y_train, batch_size = 950, nb_epoch = 7)","e6271e96":"# Predicting the Test set results\ny_pred = regressor.predict(X_test)","58db90a9":"#Visualize Predicted vs. Actual\nimport matplotlib.pyplot as plt\n_, ax = plt.subplots(1, 1, figsize=(10, 10))\nax.scatter(x = range(0, y_test.size), y=y_test, c = 'green', label = 'Actual', alpha = 0.4)\nax.scatter(x = range(0, y_pred.size), y=y_pred, c = 'red', label = 'Predicted', alpha = 0.4)\nplt.title('Actual vs. Predicted')\nplt.xlabel('Test Size')\nplt.ylabel('y Value')\ndef millions(x, pos):\n    'The two args are the value and tick position'\n    return '\u20ac%1.1fM' % (x * 1e-6)\nax.yaxis.set_major_formatter(plt.FuncFormatter(millions))\nplt.legend()\nplt.show()","ac130362":"\"\"\"\"# Applying k-Fold Cross Validation\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = regressor, X = X_train, y = y_train, cv = 30)\nprint(accuracies)\nprint(accuracies.mean())\nprint(accuracies.std())\"\"\"\"\"","8820f0f2":"#Avoid data type error\ny_pred = y_pred.round().astype(int)\ny[0] = y[0].round().astype(int)\n#K-Fold Corss Validation\nfrom sklearn.model_selection import StratifiedKFold\nkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\ncvscores = []\nfor train, test in kfold.split(X, y):\n  # create model\n    model = Sequential()\n    model.add(Dense(624, input_dim=1248, activation='relu'))\n    model.add(Dense(300, activation='relu'))\n    model.add(Dense(150, activation='relu'))\n    model.add(Dense(75, activation='relu'))\n    model.add(Dense(1, activation='linear'))\n    # Compile model\n    model.compile(loss='mean_squared_error', optimizer='adam', metrics=[coeff_determination])\n    # Fit the model\n    model.fit(X_train, y_train, epochs=7, batch_size=950)\n    # evaluate the model\n    scores = model.evaluate(X_test, y_test, verbose=0)\n    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n    cvscores.append(scores[1] * 100)\nprint(\"%.2f%% (+\/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))","38017f7c":"As you can see above I have chosen to utilize 3 hidden layers for this prediction. With 1000 batch size I have chosen to use 7 epochs. I did not try grid search in order to find the optimal settings. Since the dataset is not huge in terms of size, I have tried and failed several times in order to find the above settings. Now let's see the visualization of the prediction.","21573931":"I will use Keras for a regression purpose so I needed to define \"coeff_determination\" metrics. I have taken it from a Data Science blog which I could not remember right now. I have changed what I have copied a little bit according to my requirements. It was the most useful tip that I have taken from the internet while preparing this Kernel.","fa3d5559":"R squared is \"0.94\". And I am suspicious about this result so I need to validate the result with K Fold Cross-Validation Method. Unfortunately below solution which is commonly used does not work for Keras. After a short investigaiton, I found out that there is a solution for the cross-validation of Keras.","5f20a714":"Hi all,\nIf you haven't seen my previous Kernel please check it out [here.](http:\/\/https:\/\/www.kaggle.com\/tubaspandas\/logical-encoding-and-correlation-analysis) I will try to predict the value of a FIFA player by using Keras. Please share your feedback and ratings so that I can improve myself. I have explained how I cleaned this dataset in my previous Kernel. So I will go ahead with the prepared data. You could find the preprocessing below.","f8177ffa":"In my previous Kernel, I have encoded the values with label encoding this time I will use get_dummies.","239647c1":"I hope you enjoyed this Kernel. I have used Keras with an empiric way this may not be the ideal approach so I can make some additions to this Kernel in the following days. A\/B Test Result: The value of a FIFA Player can predicted with the R Squared treshold 0.85."}}