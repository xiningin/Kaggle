{"cell_type":{"0291ad85":"code","47d3d38d":"code","f053539e":"code","e244cf72":"code","d05f570a":"code","60310703":"code","74eaa878":"code","f94c2b08":"code","fe180675":"code","ad3522ba":"code","15d92934":"code","7a9acb91":"code","f4b8814a":"code","a783bb21":"code","115efd4b":"code","1222962d":"code","3e5da546":"markdown","49827ce5":"markdown","b17f94c2":"markdown","37921f4c":"markdown","07c296ec":"markdown","9cb4b114":"markdown","f84a4508":"markdown","c1477d84":"markdown","0e250d20":"markdown"},"source":{"0291ad85":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))","47d3d38d":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport warnings\nimport matplotlib\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\nsns.set(style=\"ticks\")\nwarnings.filterwarnings(\"ignore\")","f053539e":"# Bibliotecas do keras\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nfrom keras.layers.embeddings import Embedding\nfrom sklearn.model_selection import train_test_split","e244cf72":"# Leitura do Dataset\ndf = pd.read_csv('..\/input\/df_train.csv')\nprint(df.shape)\ndf.head()","d05f570a":"## Defini\u00e7\u00e3o de alguns par\u00e2metros dos modelos e tokeniza\u00e7\u00e3o\n\n# Tamanho da sequencia\nseq_size     = 10\n\n# M\u00e1ximo de tokens \nmax_tokens   = 2500\n\n# Tamanho do embedding\nembed_dim    = 128","60310703":"## Utilizaremos apenas o .title (input) e o .category (target) da nossa rede\n# Textos\ntext         = df['title'].values\ntokenizer    = Tokenizer(num_words=max_tokens, split=' ')\n\n# Transforma o texto em n\u00fameros\ntokenizer.fit_on_texts(text)\nX = tokenizer.texts_to_sequences(text)  \n\n# Cria sequencias de tamanho fixo (input: X)\nX = pad_sequences(X, maxlen=seq_size)","74eaa878":"# Categoriza o target \"category\" -> [0,..., 1] (output: y)\nY_classes = pd.get_dummies(df['category']).columns\nY         = pd.get_dummies(df['category']).values","f94c2b08":"(X.shape, Y.shape)","fe180675":"def base_model():\n    model = Sequential()\n    \n    # Embedding Layer\n    model.add(Embedding(max_tokens, embed_dim, \n                        input_length = seq_size))\n    # RNN Layer\n    model.add(LSTM(seq_size))\n    \n    # Dense Layer\n    model.add(Dense(len(Y_classes), activation='softmax'))\n    \n    model.compile(loss = 'categorical_crossentropy', \n                  optimizer='adam',\n                  metrics = ['accuracy'])\n    \n    model.summary()\n    \n    return model\n\nbase_model = base_model()","ad3522ba":"# Separa o dataset em dados de treinamento\/teste\nX_train, X_valid, Y_train, Y_valid = train_test_split(X,Y, \n                                                      test_size = 0.20, \n                                                      random_state = 42)\n\n# Treina o modelo\nhist = base_model.fit(X_train, Y_train, \n              validation_data =(X_valid, Y_valid),\n              batch_size=300, nb_epoch = 3,  verbose = 1)","15d92934":"# Avalia\u00e7\u00e3o do modelo para o dataset de test\n\nval_loss, val_acc = base_model.evaluate(X_valid, Y_valid)\n\nprint('A acur\u00e1cia do modelo est\u00e1 de: '+str(val_acc*100)+'%')","7a9acb91":"# Leitura do Dataset de valida\u00e7\u00e3o dos resultados\ndf_valid = pd.read_csv('..\/input\/df_valid.csv')\nprint(df_valid.shape)\ndf_valid.head()","f4b8814a":"def predict(text):\n    '''\n    Utiliza o modelo treinado para realizar a predi\u00e7\u00e3o\n    '''\n    new_text = tokenizer.texts_to_sequences(text)\n    new_text = pad_sequences(new_text, maxlen=seq_size)\n    pred     = base_model.predict_classes(new_text)#[0]\n    return pred","a783bb21":"# Como utilizamos o titulo no treinamento, iremos utilizar o titulo na predi\u00e7\u00e3o tamb\u00e9m\n\npred         = predict(df_valid.title)\npred_classes = [Y_classes[c] for c in pred]\npred_classes[:5]","115efd4b":"# Atualizando a categoria dos artigos no dataset de valida\u00e7\u00e3o\ndf_valid['category'] = pred_classes\ndf_valid.head()","1222962d":"def create_submission(df):\n    f = open('submission_valid.csv', 'w')\n    f.write('id,category\\n')\n    for i, row in df.iterrows():\n        f.write('{},{}\\n'.format(i, row.category))\n    f.close()\n    \n# Criando o arquivo submission_valid.csv contendo os dados para c\u00e1lculo do raning no kaggle\n# Esse arquivo deve ser enviado para o kaggle\ncreate_submission(df_valid)    ","3e5da546":"## Fasam - NLP Competition","49827ce5":"Esse notebook descreve o pipelie para utiliza\u00e7\u00e3o na competi\u00e7\u00e3o do **Kaggle da Fasam**. Faz parte da avalia\u00e7\u00e3o pr\u00e1tica dos alunos da turma de Deep Learning.\n\n\n### Roteiro do Notebook\n\n* Leitura do Dataset\n* Cria\u00e7\u00e3o do Modelo\n* Avalia\u00e7\u00e3o e Cria\u00e7\u00e3o do arquivo de submission.csv\n\n### Problema\n\n\nUma revista precisa catalogar todas as suas not\u00edcias em diferentes categorias. O objetivo desta competi\u00e7\u00e3o \u00e9 desenvolver o melhor modelo de aprendizagem profunda para prever a categoria de novas not\u00edcias.\n\n\n<img src=\"https:\/\/s3-ap-south-1.amazonaws.com\/av-blog-media\/wp-content\/uploads\/2018\/04\/Untitled-Diagram.png\n\" style=\"width: 400px;\"\/>\n\n\nAs categorias poss\u00edveis s\u00e3o:\n\n* ambiente\n* equilibrioesaude\n* sobretudo\n* educacao\n* ciencia\n* tec\n* turismo\n* empreendedorsocial\n* comida\n","b17f94c2":"## Leitura do dataset de treinamento","37921f4c":"## Cria\u00e7\u00e3o do Modelo\n\nIremos utilizar uma RNN em um modelo simples.","07c296ec":"Todos os artigos cont\u00eam o **t\u00edtulo, descri\u00e7\u00e3o e link** da mat\u00e9ria original. Por \u00faltimo a categoria que pertence esse artigo.","9cb4b114":"## Avalia\u00e7\u00e3o e Cria\u00e7\u00e3o do arquivo de submission.csv","f84a4508":"O dataset de valida\u00e7\u00e3o, o que ser\u00e1 utilizado para calcular o Ranking no Kaggle, cont\u00eam apenas as informa\u00e7\u00f5es de T\u00edtulo e Texto do arquivo.  O modelo criado deve ser capaz de classificar em qual das categorias esse artigo pertence","c1477d84":"### Criando arquivo de submission para o Kaggle","0e250d20":"Iremos utilizar o titulo para o nosso modelo baseline. O processo abaixo cria o **input** da nossa rede e prepara o **target**"}}