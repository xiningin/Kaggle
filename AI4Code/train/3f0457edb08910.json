{"cell_type":{"7c45bbaa":"code","4ab0613b":"code","4f400593":"code","729dc7da":"code","5307f9a6":"code","4b219b09":"code","455e448a":"code","5c7f5012":"code","d9f36e5d":"code","e192834b":"code","8480e29b":"code","07839895":"code","f16aae26":"code","66728f97":"code","2e35aeb6":"code","52df0d0b":"code","c9f80a42":"code","1cc31918":"markdown","4e02288a":"markdown","e84f0b2a":"markdown","e6389beb":"markdown","d89bcb8b":"markdown","a2c19745":"markdown","f79e4cf6":"markdown","07185567":"markdown","7d8304bc":"markdown","e74eb4c8":"markdown","d054fe50":"markdown","2c9a9a54":"markdown","a5fe6aeb":"markdown","8d0c101a":"markdown","523a5cfa":"markdown","63c9424b":"markdown","33df99e6":"markdown","5c794861":"markdown"},"source":{"7c45bbaa":"![ -d \/kaggle\/input\/release-2021-v1\/augeropendata ] && [ ! -d augeropendata ] && ln -s \/kaggle\/input\/release-2021-v1\/augeropendata augeropendata  # kaggle specific linking dataset to augeropendata directory","4ab0613b":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom matplotlib.ticker import MultipleLocator\nfrom IPython.display import display, Latex\nfrom scipy.optimize import minimize\nfrom scipy.integrate import trapz","4f400593":"plt.rcParams['lines.markersize'] = 5\nplt.rcParams['lines.linewidth'] = 1\nplt.rcParams['xtick.labelsize'] = 15\nplt.rcParams['ytick.labelsize'] = 15\nplt.rcParams['axes.labelsize'] = 18\nplt.rcParams['legend.fontsize'] = 15\nplt.rcParams['xtick.direction'] = 'in'\nplt.rcParams['ytick.direction'] = 'in'\nplt.rcParams['xtick.minor.size'] = 4\nplt.rcParams['ytick.minor.size'] = 4","729dc7da":"# Data loading, encapsulated to make it less installation and OS dependant\nimport os.path\nfrom zipfile import ZipFile\ndef AugerOpen(fdir, file):\n    \"\"\"\n    Loads a file from the auger open data release. Can be either in the local directory,\n    in the parent directory or in the augeropendata directory.\n    File is identified by it directory *fdir* and filename *file* and can be found in the directory\n    or in a zip file.\n    \"\"\"\n    for loc in [\".\", \"..\", \"augeropendata\", \"data\"]:\n        fname = os.path.join(loc, fdir, file)\n        if os.path.isfile(fname):\n            return open(fname)\n        zname=os.path.join(loc, fdir + \".zip\")\n        if os.path.isfile(zname):\n            with ZipFile(zname) as myzip:\n                return myzip.open(os.path.join(fdir, file))\n    raise FileNotFoundError(os.path.join(fdir, file))","5307f9a6":"dataTable = pd.read_csv(AugerOpen('summary', 'dataSummary.csv'))\nacceptTable = pd.read_csv(AugerOpen('auxiliary', 'fdXmaxAcceptance.csv'))\n# select high-quality data\nfdCut = (dataTable['fd_hdXmaxEye']==1)\n\nlgEData = np.log10(dataTable[fdCut]['fd_totalEnergy']) + 18 # units: lg(E\/EeV)\nXmaxData = dataTable[fdCut]['fd_xmax'] # units: g\/cm2","4b219b09":"# define energy range, in logarithmic units log_{10}(E\/eV)\nlgELow = 18.0\nlgEUp = 18.5\nenergySelection = (lgEData>lgELow) & (lgEData<lgEUp)\n\n# Get Xmax events in the specified energy bin\nselectedXmaxData = XmaxData[energySelection]","455e448a":"# to check if there are any events that triggered more than one FD station in the selected data sample\nEventsId = dataTable[fdCut]['id']\nEventsIdSelected = EventsId[energySelection]\n_, UniqueIndices = np.unique(EventsIdSelected, return_index=True)\n\nif len(UniqueIndices) < len(EventsIdSelected):\n    print('WARNING: There are duplicates in this data sample.')\nelse:\n    print('There are no duplicates in this data sample.')","5c7f5012":"# Get acceptance parameterization for an energy bin\ndef SelectEnergyAccept(Table, lgELow, lgEUp):\n    \"\"\"\n    Load acceptance parameterization for specified energy. \n\n    If the selected energy range (lgElow,lgEup) is > 0.1 lg(E\/eV) the weighted average energy \n    for this range is calculated and the acceptance parameterization of the energy bin containing \n    the calculated weighted average energy is loaded since the table with the acceptance parameterization \n    has a bin width of 0.1.\n\n    Args: \n      Table: acceptance parameterization table\n      lgElow: lower energy limit\n      lgEUp: upper energy limit\n    \n    Return:\n      dict with keys for the parameterization: \"Xacc2\", \"lambdaAcc2\"      \n    \"\"\"\n    lgERange = np.arange(lgELow, lgEUp, 0.1)\n    \n    NEventsArray = []\n    for i in range(len(lgERange)):\n        NEvents = len(XmaxData[(lgEData>lgERange[i])&(lgEData<lgERange[i]+0.1)])\n        NEventsArray.append(NEvents)\n    AveragelgE = np.log10(np.sum(10**lgERange*NEventsArray)\/np.sum(NEventsArray))    \n    lgELowAcc = lgERange[AveragelgE<lgERange][0]-0.1 # finds the lower bound on the lgE interval that contains \n                                                     # the weighted average energy \n    \n    Xacc2 = float(Table.loc[(Table['lgMinEnergy']==lgELowAcc)]['Xacc2'])\n    lambdaAcc2 = float(Table.loc[(Table['lgMinEnergy']==lgELowAcc)]['lambdaAcc2'])\n\n    acceptParamList = {'Xacc2':Xacc2, 'lambdaAcc2':lambdaAcc2}\n    return acceptParamList \n\nacceptance = SelectEnergyAccept(acceptTable, lgELow, lgEUp)","d9f36e5d":"def LambdaFitFunc(XmaxTail, Xstart):\n    \"\"\"\n    Function to get the Lambda_eta by fitting the tail of the Xmax distribution with an \n    unbinned maximum likelihood fit.\n    \n    Args:\n      XmaxTail: ordered list of Xmax values\n      Xstart: start value of tail range\n    Returns: \n      dict with fit results: value and upper and lower 68% confidence interval\n    \"\"\"\n        \n    Xacc = acceptance['Xacc2']\n    lambdaAcc = acceptance['lambdaAcc2']\n    \n    def loglike(lambdaEta):\n        \"\"\"The unbinned likelihood function for N events in the tail of the Xmax distribution\n        Args:\n          lambdaEta: Lambda_eta\n        Returns: \n          negative log-likelihood\n        \"\"\"\n        # normalization (k factor in the expressions at the beginning)\n        k = lambdaEta*(1 + np.exp(-(Xacc-Xstart)\/lambdaEta)*(lambdaAcc\/(lambdaAcc+lambdaEta) - 1)) \n        logNorm = np.log(k)\n    \n        N = len(XmaxTail) # number of events in the tail\n        z_val = np.sum(np.abs(XmaxTail-Xstart))\n        return (1\/lambdaEta)*z_val + N*logNorm # negative log-likelihood\n        \n    lambdaStart = XmaxTail.mean()-Xstart\n    result = minimize(loglike, lambdaStart, method='BFGS', tol=1e-6)\n    bestFit = result.x[0]\n    \n    # brute force profile likelihood for confidence intervals \n    lambdaProfile = np.linspace(bestFit - 30, bestFit + 30, 500)\n    l1 = -1\n    l2 = -1\n    for l in lambdaProfile:\n        dLogLike = loglike(l) - result.fun\n        if l1 < 0 and dLogLike < 0.5:\n            l1 = l\n        if dLogLike < 0.5:\n            l2 = l   \n    \n    return {'value': bestFit, 'errorLow': bestFit-l1, 'errorUp': l2-bestFit}","e192834b":"# select only the fraction of eta of the most deeply penetrating showers\n#    -> tail of the Xmax distribtuion\neta = 0.2\nselectedXmaxData.sort_values(inplace=True)\nXmaxTail = selectedXmaxData[selectedXmaxData>np.percentile(selectedXmaxData, (1-eta)*100)]\n\n# start of fit range:\nXtailStart = XmaxTail.iloc[0] # or: Xstart = XmaxTail.min()\nlambdaFit = LambdaFitFunc(XmaxTail, XtailStart)\nlambdaEta = lambdaFit['value'] # central Lambda_eta value\nlambdaEtaLowErr = lambdaFit['errorLow']  # lower 68% confidence interval\nlambdaEtaUpErr = lambdaFit['errorUp']  # upper 68% confidence interval\nlambdaEtaError = [lambdaEtaLowErr, lambdaEtaUpErr]\n# print out estimated Lambda_eta\ndisplay(Latex(f'''The result of the fit is\n    $\\Lambda_\\eta = {lambdaEta:.1f}_{{-{lambdaEtaLowErr:.1f}}}^{{+{lambdaEtaUpErr:.1f}}} \\, \\mathrm{{g\/cm^2}}$.'''))","8480e29b":"def func_A5(Xmax, XtailStart, lambdaEta, Xacc, lambdaAcc, norm):\n    \"\"\"\n    Functional form describing the tail of the Xmax distribution. For values of Xmax where Xmax-Xstart>z0\n    the additional exponential damping with lambdaAcc is added.\n    \n    This is Eq. (A.5) from Ref.[Phys. Rev. D 90, 122005 (2014)]. Note, that in the\n    original version of the article the normalisation constant \"k\" was used instead of \"1\/k\"\n    in Eq. (A.5).\n    \n    Args:\n        Xmax: input Xmax values, np.array\n        XtailStart: start of tail fit range\n        lambdaEta: Lambda_Eta\n        Xacc: start of acceptance damping\n        lambdaAcc: decay constant for acceptance damping\n    \"\"\"\n    k = lambdaEta*(1 + np.exp(-(Xacc-XtailStart)\/lambdaEta)*(lambdaAcc\/(lambdaAcc+lambdaEta) - 1)) \n    z = Xmax - XtailStart\n    result = np.exp(-z\/lambdaEta)\n    result[Xmax>Xacc] *= np.exp(-(Xmax[Xmax>Xacc]-Xacc)\/lambdaAcc)\n    return result\/k * norm\n\nplt.figure()\n\nXmaxEntries, bins,_ = plt.hist(selectedXmaxData, 30, label='$18<lg(E\/eV)<18.5$')\nXmaxTailEntries,_ ,_ = plt.hist(XmaxTail, bins, label='$X_\\mathrm{max}$ tail, $\\eta=0.2$')\nplt.close()\nstd = np.sqrt(XmaxEntries)\n\nfunc_range = np.linspace(XtailStart, bins[-1], 30)\n\nnorm = (bins[1]-bins[0])*len(XmaxTail) \n\nfig, axes = plt.subplots(figsize=(8,6))\nplt.errorbar(bins[0:-1]+np.diff(bins)\/2, XmaxEntries, yerr=std, color='black', fmt='o', label='data')\nplt.plot(func_range, func_A5(func_range, XtailStart, lambdaEta, acceptance['Xacc2'], acceptance['lambdaAcc2'], norm), \n         color='darkblue', lw=1, label='model')\nplt.plot(func_range, np.exp(-(func_range-XtailStart)\/lambdaEta)\/lambdaEta * norm, ':', color='darkgreen', lw=2,\n         label='just $\\Lambda_\\eta$')\n\nplt.yscale('log')\nplt.xlabel('$X_\\mathrm{max}$  [g\/cm$^2$]')\nplt.ylabel('Entries')\naxes.xaxis.set_minor_locator(MultipleLocator(20))\nplt.legend()\nplt.show()","07839895":"# units of cross sections are in [mb]\nsigmaPAirMC = [400, 430, 460, 490, 520, 550, 580, 610, 640, 670, 700]\n# unit for all lambdaEtas are in [g\/cm2]\nlambdaEtaQgsjet01MC = [70.92, 66.20, 62.04, 58.39, 55.20, 52.43, 50.02, 47.93, 46.10, 44.50, 43.07] \nlambdaEtaQgsjetIIMC = [68.9915, 64.45, 60.42, 56.84, 53.67, 50.87, 48.38, 46.18, 44.20, 42.41, 40.76] \nlambdaEtaSibyll21MC = [67.44, 63.34, 59.62, 56.33, 53.36, 50.71, 48.36, 46.26, 44.40, 42.75, 41.26] \nlambdaEtaEposMC = [67.96, 63.30, 59.21, 55.65, 52.56, 49.89, 47.60, 45.63, 43.93, 42.45, 41.15] ","f16aae26":"fig, axes = plt.subplots(figsize=(8,6))\nplt.plot(sigmaPAirMC, lambdaEtaQgsjet01MC, label='QGSJet01')\nplt.plot(sigmaPAirMC, lambdaEtaQgsjetIIMC, label='QGSJetII.3')\nplt.plot(sigmaPAirMC, lambdaEtaSibyll21MC, label='Sibyll 2.1')\nplt.plot(sigmaPAirMC, lambdaEtaEposMC, label='EPOS 1.99')\nplt.legend()\nplt.xlabel(r'$\\sigma^\\mathrm{mod}_\\mathrm{p-air}$ [mb]')\nplt.ylabel(r'$\\Lambda_{\\eta}^\\mathrm{MC}$ [g\/cm$^2$]')\naxes.xaxis.set_minor_locator(MultipleLocator(10))\naxes.yaxis.set_minor_locator(MultipleLocator(1))\nplt.show()","66728f97":"def interpolate(x, xi, yi):\n    \"\"\"\n    returns the interpolation of x inside xi->yi, basically: $y(x)$\n    Arg:\n        x: target x value\n        xi: list of x values\n        yi: list of y values\n    Return:\n        interpolated y\n    \"\"\"\n    # make sure xis and yis are sorted in ascending x\n    inverted = sorted(zip(xi, yi), key = lambda t: t[0])\n    return np.interp(x, [xs for xs,_ in inverted], [ys for _,ys in inverted])\n\n\ndef convertLambdaToSigma(lambdaEta):\n    \"\"\"\n    perform the conversion from $\\Lambda_\\eta$ to $\\sigma_{p-air}$ for all available models.\n\n    Arg:\n        lambdaEta: Lambda-Eta in units of g\/cm2\n    Return:\n        dict with average value between all models, and \n        model-dependent uncertainties (lower\/upper)\n    \"\"\"\n    sigmas = np.array([interpolate (lambdaEta, model, sigmaPAirMC) \n                       for model in [lambdaEtaQgsjet01MC, lambdaEtaQgsjetIIMC, lambdaEtaSibyll21MC, lambdaEtaEposMC]])\n    avg = sigmas.mean()\n    return {'value': avg, 'errorLow': avg - sigmas.min(), 'errorUp': sigmas.max() - avg}\n\n\n# central value\nsigmaPAir = convertLambdaToSigma(lambdaEta)\n# lower stat. uncertainty\nsigmaPAir_stat_low = sigmaPAir['value'] - convertLambdaToSigma(lambdaEta+lambdaEtaError[1])['value']\n# upper stat. uncertainty\nsigmaPAir_stat_up = convertLambdaToSigma(lambdaEta-lambdaEtaError[0])['value'] - sigmaPAir['value']\n\nprint (f'The sigma-proton-air cross section is: {sigmaPAir[\"value\"]:.2f} mb')\nprint (f'with a statistical uncertainty of -{sigmaPAir_stat_low:.2f}\/+{sigmaPAir_stat_up:.2f} mb')\nprint (f'and systematic model-dependence of -{sigmaPAir[\"errorLow\"]:.2f}\/+{sigmaPAir[\"errorUp\"]:.2f} mb')","2e35aeb6":"import matplotlib.lines as lines\nimport matplotlib.transforms as transforms\n\nfig, ax = plt.subplots(figsize=(8,6))\nax.plot(lambdaEtaQgsjet01MC, sigmaPAirMC, label='QGSJet01')\nax.plot(lambdaEtaQgsjetIIMC, sigmaPAirMC, label='QGSJetII.3')\nax.plot(lambdaEtaSibyll21MC, sigmaPAirMC, label='Sibyll 2.1')\nax.plot(lambdaEtaEposMC, sigmaPAirMC, label='EPOS 1.99')\nfig.canvas.draw()\n\ndef plotConversion(ax, lambdaEta, sigmaPAir, style, label=\"\"):\n    \"\"\"\n    Helper function to draw conversion lines into conversion figure.\n    Args:\n      ax: the figure axis\n      lambdaEta: lambda_eta\n      sigmaPAir: corresponding sigma-pair\n      style: line style\n      label: label\n    \"\"\"\n    transX = transforms.blended_transform_factory(ax.transData, ax.transAxes)\n    transY = transforms.blended_transform_factory(ax.transAxes, ax.transData)\n\n    lambdaAx, sigmaAx = ax.transAxes.inverted().transform(ax.transData.transform((lambdaEta,sigmaPAir)))\n    \n    ax.add_line(lines.Line2D([lambdaEta, lambdaEta], [0, sigmaAx], transform=transX, figure=fig, linestyle=style, \n                             label=label))\n    ax.add_line(lines.Line2D([0, lambdaAx], [sigmaPAir, sigmaPAir], transform=transY, figure=fig, linestyle=style))\n\nplotConversion(ax, lambdaEta, sigmaPAir['value'], \"--\", \"central value\")\nplotConversion(ax, lambdaEta+lambdaEtaError[1], sigmaPAir['value']-sigmaPAir_stat_low, \"-.\", label=\"stat. uncertainty\")\nplotConversion(ax, lambdaEta-lambdaEtaError[1], sigmaPAir['value']+sigmaPAir_stat_up, \"-.\")\nplotConversion(ax, lambdaEta, sigmaPAir['value']+sigmaPAir['errorLow'], \":\")\nplotConversion(ax, lambdaEta, sigmaPAir['value']-sigmaPAir['errorUp'], \":\", \"model uncertainty\")\n\nplt.legend()\nplt.xlabel(r'$\\Lambda_{\\eta}$ [g\/cm$^2$]')\nplt.ylabel(r'$\\sigma_\\mathrm{p-air}$ [mb]')\nax.xaxis.set_minor_locator(MultipleLocator(1))\nax.yaxis.set_minor_locator(MultipleLocator(10))\nplt.show()","52df0d0b":"# from simulations:\n# the energy values are in log_{10}(E\/eV)\nlgE0 = [14.0, 14.5, 15.0, 15.5, 16.0, 16.5, 17.0, 17.5, 18.0, 18.5, 19.0,\n19.5]\n# all sigmas are in units of [mb]\nsigma_pair_sibyll23c = [334.73, 351.52, 370.13, 389.76, 410.27, 431.38, 452.93, 474.83, 496.98, 519.40, 542.07, 565.02]\nsigma_pair_qgsjetII03 = [347.76, 366.46, 386.26, 407.52, 429.23, 451.37, 473.51, 495.43, 517.28, 538.97, 560.39, 581.45]\nsigma_pair_epos = [349.97, 367.81, 386.40, 406.77, 427.51, 448.27, 468.97, 488.98, 508.95, 528.95, 548.91, 568.78]\nsigma_pair_sibyll21 = [353.11, 373.08, 395.92, 419.85, 444.98, 471.05, 497.88, 525.42, 553.59, 582.41, 611.83, 641.82]","c9f80a42":"fig, ax = plt.subplots(figsize=(8,6))\nplt.plot(lgE0, sigma_pair_sibyll23c, label='Sibyll 2.3c')\nplt.plot(lgE0, sigma_pair_sibyll21, label='Sibyll 2.1')\nplt.plot(lgE0, sigma_pair_epos, label='EPOS 1.99')\nplt.plot(lgE0, sigma_pair_qgsjetII03, label='QGSJetII.3')\n\navg_lgEdata = np.average(lgEData[(lgEData>lgELow)&(lgEData<lgEUp)])\nplt.errorbar(avg_lgEdata, sigmaPAir['value'], yerr=np.array([[np.sqrt(sigmaPAir_stat_low**2 + sigmaPAir['errorLow']**2),\n             np.sqrt(sigmaPAir_stat_up**2 + sigmaPAir['errorUp']**2)]]).T, fmt='o', ms=6, label=\"Data\")\n\nplt.legend()\nplt.xlabel(r'$\\log_{10}(E_{0}\/\\mathrm{eV})$')\nplt.ylabel(r'$\\sigma_\\mathrm{p-air}$ [mb]')\nax.xaxis.set_minor_locator(MultipleLocator(0.2))\nax.yaxis.set_minor_locator(MultipleLocator(10))\nplt.show()","1cc31918":"Plot simulation lines together with data:","4e02288a":"One conclusion of these data is that steeply rising cross sections (like in Sibyll 2.1) towards higher energies are disfavoured. ","e84f0b2a":"## Definition of fit model","e6389beb":"The plot above shows the $X_\\text{max}$ distribution for the selected energies and the unbinned likelihood fit to the tail of the $X_\\text{max}$ distribution (the range of the $X_\\text{max}$ values that corresponds to the fraction $\\eta$ of the most deeply penetrating showers). The purely exponential fit $\\propto \\exp(-X_{\\rm max}\/\\Lambda_\\eta)$ is shown in the dotted green line, and the actual model fit with the additional exponential damping is shown in the solid blue line (see Eq.1). The visible kink around $\\approx 900\\,$g\/cm$^{2}$ is caused by the acceptance of the telescopes starting to affect the distribution above $X_\\text{acc}$. Note, there are no telescope acceptance effects visible below this value because the data was specifically selected in a fiducial volume to avoid any biases here. For a full discussion read the original article [Phys. Rev. D 90, 122005 (2014)](https:\/\/doi.org\/10.1103\/PhysRevD.90.122005) ([arXiv](https:\/\/arxiv.org\/abs\/1409.4809)).","d89bcb8b":"## Comparison of the derived cross-section to model predictions","a2c19745":"*Note*: other sources of systematic uncertainties related e.g. to fitting procedures, primary composition, etc. are not studied here.","f79e4cf6":"## Reading of acceptance model parameters","07185567":"The conversion is performed by simulating a very large sample of air showers with many different interaction models. For each model, artificially, the input model proton-air cross section is varied, $\\sigma_\\text{p-air}^\\text{mod}$, and the resulting $\\Lambda_\\eta^\\text{MC}$ values are measured. Details on this procedure are published here: [Hadronic Multiparticle Production at Ultra-High Energiesand Extensive Air Showers, Phys.Rev.D 83 (2011) 054026](https:\/\/doi.org\/10.1103\/PhysRevD.83.054026) ([arXiv](https:\/\/arxiv.org\/abs\/1010.4310)).\n\nThe results of these simulations are presented here:","7d8304bc":"This is the kaggle version of a Pierre Auger Observatory Open Data notebook. You can run it by clicking on \"Copy and Edit\" in the top right corner.","e74eb4c8":"From the original event generator models used in the simulations the following data was extracted:","d054fe50":"## Visualize the data and the fit","2c9a9a54":"## Selection of events\n\nEvents are selected for an energy interval, and for quality cuts. \n\nThe energy interval assures to perform the analysis in the region where we expect the highest fraction of primary CR protons. \n\nThe quality cuts determine the acceptance of the analysis. ","a5fe6aeb":"Note that in the loaded data \"dataSummary.csv\" there may be a small number of events that triggered more than one FD station (stereo\/triple\/etc events), and may be, thus, counted multiple times. In general, the presence of such events can affect the analysis if it is not taken into account. To get the correct results the duplicate events should be combined by calculating the weighted average of the $X_\\mathrm{max}$ and energy (see also $X_\\mathrm{max}$ notebook). However, in the energy range selected here there are no events that triggered more than one FD station, so for simplicity no special treatment is added here. ","8d0c101a":"## Read experimental data","523a5cfa":"## Visualize the conversion\nThe lines represent the average conversion from $\\Lambda_\\eta$ to $\\sigma_\\text{p-air}$.","63c9424b":"![PierreAugerObservatoryLogo.jpg](attachment:PierreAugerObservatoryLogo.jpg)\n# Measurement of the tail of the $X_\\text{max}$ distribution, and the proton-air cross section  \n\n<i>Notebook released together with the Pierre Auger Observatory Open Data release 2021 (<a href=\"https:\/\/doi.org\/10.5281\/zenodo.4487613\">DOI 10.5281\/zenodo.4487613<\/a>). More information at the <a href=\"https:\/\/www.auger.org\/opendata\/\">Auger open data website<\/a>.<\/i>\n\nThis notebook illustrates the analysis as published in [Measurement of the proton-air cross-section at $\\sqrt{s}=57$ TeV with the Pierre Auger Observatory, Phys.Rev.Lett. 109 (2012), 062002](https:\/\/doi.org\/10.1103\/PhysRevLett.109.062002) ([arXiv](https:\/\/arxiv.org\/abs\/1208.1520)). However, the procedure has been a bit simplified here with respect to the original paper:\n- The same event selection is used as for the measurement of $\\langle X_\\text{max}\\rangle$ and $\\sigma(X_\\text{max})$. \n- The limiting acceptance of the telescope field of view towards very high values of $X_\\text{max}$ is explicitly considered in the fit model. This procedure is introduced and explained in [Appendix A.2 of Phys. Rev. D 90, 122005 (2014)](https:\/\/doi.org\/10.1103\/PhysRevD.90.122005) ([arXiv](https:\/\/arxiv.org\/abs\/1409.4809)).\n\nThe foundation of this analysis is the fact, that the attenuation length of primary cosmic ray (CR) protons in the atmosphere is reflected in the exponential tail of the $X_\\text{max}$ distribution at very high values of $X_\\text{max}$. Thus, measuring the exponential shape of the tail of the $X_\\text{max}$ distribution can be exploited to determine the proton-air cross section. \n\nThe $X_\\text{max}$ distribution at very high values of $X_\\text{max}$ (thus, the tail of the $X_\\text{max}$ distribution) follows an exponential distribution, which is for $X_\\text{max}>X_\\text{acc}$ further modified by the limited field-of-view of the telescopes, where $X_\\text{start,tail}$ is the start of the fit range. Introducing $z=X_\\text{max}-X_\\text{start,tail}$ and $z_\\text{acc}=X_\\text{acc}-X_\\text{start,tail}$ this can be written as\n\\begin{equation}\nf(z) = \\frac{1}{k}\\;\\exp\\Bigl({-\\frac{z}{\\Lambda_\\eta}}\\Bigr)\n      \\begin{cases}\n      1; & z < z_\\text{acc} \\\\\n      \\exp\\Bigl({\\displaystyle -\\frac{z-z_\\text{acc}}{\\lambda_\\text{acc}}}\\Bigr); & \\mathrm{otherwise},\n    \\end{cases}       \n\\end{equation}\nwhere $\\Lambda_\\eta$ is the slope of the exponential distribution of $X_\\text{max}$ and $\\lambda_\\text{acc}$ is the additional exponential damping of the limited field-of-view for $z>z_\\text{acc}$. \n\nThe normalization is given by integration from $X_\\text{start,tail}$ to infinity:\n\\begin{equation}\nk = \\Lambda_\\eta \\left(1 + \\exp\\Bigl({-\\frac{z_\\text{acc}}{\\Lambda_\\eta}}\\Bigr)\\left[\\frac{\\lambda_\\text{acc}}{\\lambda_\\text{acc} + \\Lambda_\\eta} - 1 \\right] \\right).\n\\end{equation}\n\nThe fraction of events to consider for the analysis in the tail is denoted by $\\eta$. In this analysis, the tail of the $X_\\mathrm{max}$ distribution is fitted with $\\eta$ = 0.2.\nThe unbinned likelihood for $N$ events in the tail is:\n\n\\begin{equation}\n-\\mathrm{log} L \\sim N \\;\\mathrm{log} k + \\frac{1}{\\Lambda_\\eta} \\sum_{i=1}^{N} z_i.\n\\end{equation}","33df99e6":"### Conversion of $\\Lambda_\\eta$ fit result into proton-air cross section","5c794861":"These simulations must be inverted in order to provide the needed conversion curves from measured $\\Lambda_{\\eta}$ to $\\sigma_\\text{p-air}$. The different model predictions automatically provide an estimate of model-dependence. "}}