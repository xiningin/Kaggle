{"cell_type":{"5ba9bc17":"code","f9de7780":"code","a590aed5":"code","5aa6a18d":"code","27922f70":"code","f6fec370":"code","4c171e34":"code","fe5d168d":"code","3ff6b2aa":"code","6f389aa9":"code","c9ff3a27":"code","f603f957":"code","72eb0022":"code","3b0f9263":"code","bb3862a6":"code","61f540de":"code","beee7e87":"code","75b6d29d":"code","ca526023":"code","4ccd3e47":"code","95ad2328":"code","48a30087":"code","91672756":"code","98408666":"code","d6b0f64b":"code","41807624":"code","bb7b101b":"code","364c234f":"code","3cda2bc6":"code","ebdaeb82":"code","1e72496e":"code","471bd344":"code","59fe9903":"code","3c64fea6":"code","906a463a":"code","649e725c":"code","57646574":"code","b765105d":"code","97b719ba":"code","0ff6d37b":"code","ac6ee7c5":"code","46ec225e":"code","b7e84c14":"code","97bfe964":"code","557b2939":"code","316784ca":"code","864190e0":"code","9ca78a67":"code","3cd12f94":"code","15a946db":"code","3353886d":"code","1bf705b3":"markdown","44646022":"markdown","ec143e21":"markdown","059dd6c1":"markdown","24343276":"markdown","b4b6afee":"markdown","66db6be8":"markdown","1896090b":"markdown","74a73c28":"markdown","0196c1a1":"markdown","47402394":"markdown","a1300749":"markdown"},"source":{"5ba9bc17":"import pandas as pd\nimport numpy as np\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport matplotlib.pyplot as plt\nimport seaborn as sns","f9de7780":"train_data = pd.read_csv('..\/input\/titanic\/train.csv', index_col='PassengerId')\ntest_data = pd.read_csv('..\/input\/titanic\/test.csv', index_col='PassengerId')\ntrain_data.head()","a590aed5":"train_data.Survived.value_counts()","5aa6a18d":"df = train_data.copy()","27922f70":"cols = list(df.columns)\ncols","f6fec370":"df.info()","4c171e34":"def null_count(df):\n    null_count = df.isnull().sum()\n    null_count = null_count[null_count > 0] \/ len(df) * 100\n    null_count.sort_values(inplace=True)\n    return null_count\n\nnull_count(df)","fe5d168d":"cols.remove(\"Cabin\")","3ff6b2aa":"num_cols = list(df.select_dtypes(exclude=[\"object\"]).columns)\nobj_cols = list(df.select_dtypes(include=[\"object\"]).columns)\nobj_cols.remove(\"Cabin\")\nnum_cols.remove(\"Survived\")","6f389aa9":"df[num_cols].info()","c9ff3a27":"def plot_distributions(df, graph_type, cols=list(df.columns), n_cols=5):\n    \"\"\"[summary]\n\n    Args:\n        df ([type]): [description]\n        graph_type ([type]): [description]\n        cols ([type], optional): [description]. Defaults to list(df.columns).\n        n_cols (int, optional): [description]. Defaults to 5.\n\n    Returns:\n        [type]: [description]\n    \"\"\"\n    \n    n_rows = int(np.ceil(len(cols) \/ n_cols))\n    fig = make_subplots(n_rows, n_cols, subplot_titles=cols)\n    \n    i = 1\n    j = 1\n    for i in range(1, n_rows + 1):\n        for j in range(1, n_cols + 1):\n            col = cols[(i - 1) * n_cols + j - 1]\n            if graph_type == 'hist':\n                fig.add_trace(go.Histogram(x=df[col], name=col), row=i, col=j)\n            elif graph_type == 'box':\n                fig.add_trace(go.Box(y=df[col], name=\"\"), row=i, col=j)\n            elif graph_type == 'violin':\n                fig.add_trace(go.Violin(y=df[col], name=\"\"), row=i, col=j)\n                    \n    fig.update_layout(height=400, width=1000, title_text=graph_type.capitalize() + \" plots of \" + str(len(cols)) + \" columns\")\n    return fig\n    \n\nfig = plot_distributions(df, \"box\", num_cols, 5)\nfig.show()","f603f957":"fig = plot_distributions(df, \"hist\", num_cols)\nfig.show()","72eb0022":"fig = make_subplots(rows=1, cols=5, subplot_titles=num_cols)\n\nfor idx, col in enumerate(num_cols):\n    if col in [\"Age\", \"Fare\"]:\n        grouped_df = df[[col, \"Survived\"]].groupby(col).mean()\n        fig.add_trace(go.Scatter(x=grouped_df.index, y=grouped_df.Survived, name=col, mode=\"markers\"), row=1, col=idx + 1)\n    else:\n        grouped_df = df[[col, \"Survived\"]].groupby(col).mean()\n        fig.add_trace(go.Bar(x=grouped_df.index, y=grouped_df.Survived, name=col), row=1, col=idx + 1)\n    \nfig.update_layout(height=400, width=1000, title_text=\"Bar plots of \" + str(len(num_cols)) + \" columns\")    \n\nfig.show()","3b0f9263":"fig = px.histogram(df, x=\"Age\", facet_col=\"Survived\", nbins=20,\n                   color=\"Survived\", color_discrete_sequence=[\"#363945\", \"#B6E880\"])\nfig.update_layout(height=400, width=800, title_text=\"Survival by Age\")\nfig.show()","bb3862a6":"df[\"Age_class\"] = train_data[\"Age\"] \/\/ 15 * 15","61f540de":"fig = px.histogram(df, x=\"Age_class\", facet_col=\"Survived\", nbins=20,\n                   color=\"Survived\", color_discrete_sequence=[\"#363945\", \"#B6E880\"])\nfig.update_layout(height=400, width=800, title_text=\"Survival by Age\")\nfig.show()","beee7e87":"fig = px.histogram(df, x=\"Fare\", facet_col=\"Survived\", color=\"Survived\", nbins=20,\n                   color_discrete_sequence=[\"#363945\", \"#B6E880\"])\nfig.update_layout(height=400, width=800, title_text=\"Survival by Fare\")\nfig.show()","75b6d29d":"fig = px.box(df, y=\"Fare\", color=\"Survived\", color_discrete_sequence=[\"#363945\", \"#B6E880\"])\nfig.update_layout(height=400, width=800, title_text=\"Survival by Fare\")\nfig.show()","ca526023":"fig = px.histogram(df, x=\"Pclass\", facet_col=\"Survived\", color=\"Survived\", color_discrete_sequence=[\"#363945\", \"#B6E880\"])\nfig.update_layout(height=400, width=800, title_text=\"Survival by Pclass\")\nfig.show()","4ccd3e47":"fig = px.histogram(df, x=\"SibSp\", facet_col=\"Survived\", color=\"Survived\", color_discrete_sequence=[\"#363945\", \"#B6E880\"])\nfig.update_layout(height=400, width=800, title_text=\"Survival by N\u00ba of Siblings\/Spouses\")\nfig.show()","95ad2328":"fig = px.histogram(df, x=\"Parch\", facet_col=\"Survived\", color=\"Survived\", color_discrete_sequence=[\"#363945\", \"#B6E880\"])\nfig.update_layout(height=400, width=800, title_text=\"Survival by N\u00ba of Parents\/Children\")\nfig.show()","48a30087":"df[obj_cols].head()","91672756":"df[obj_cols].describe()","98408666":"cols.remove(\"Ticket\") # too many unique values","d6b0f64b":"fig = px.histogram(df, x=\"Sex\", facet_col=\"Survived\", color=\"Survived\", color_discrete_sequence=[\"#363945\", \"#B6E880\"])\nfig.update_layout(height=400, width=800, title_text=\"Survival by Sex\")\nfig.show()","41807624":"fig = px.histogram(df, x=\"Embarked\", facet_col=\"Survived\", color=\"Survived\", color_discrete_sequence=[\"#363945\", \"#B6E880\"])\nfig.update_layout(height=400, width=800, title_text=\"Survival by Embarked\")\nfig.show()","bb7b101b":"def get_title(name):\n    name = name.split(\" \")\n    title = name[1]\n    if title in [\"Mr.\", \"Mrs.\", \"Miss.\", \"Master.\"]:\n        return title\n    else:\n        return \"Other\"","364c234f":"df[\"title\"] = df.Name.map(get_title)\ndf.title.value_counts()","3cda2bc6":"fig = px.histogram(df, x=\"title\", facet_col=\"Survived\", color=\"Survived\", color_discrete_sequence=[\"#363945\", \"#B6E880\"])\nfig.update_layout(height=400, width=800, title_text=\"Survival by Title\")\nfig.show()","ebdaeb82":"df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"]","1e72496e":"fig = px.histogram(df, x=\"FamilySize\", facet_col=\"Survived\", color=\"Survived\", color_discrete_sequence=[\"#363945\", \"#B6E880\"])\nfig.update_layout(height=400, width=800, title_text=\"Survival by Family Size\")\nfig.show()","471bd344":"df[\"Alone\"] = df.FamilySize.map(lambda x: 1 if x == 0 else 0)\nfig = px.histogram(df, x=\"Alone\", facet_col=\"Survived\", nbins=20,\n                   color=\"Survived\", color_discrete_sequence=[\"#363945\", \"#B6E880\"])\nfig.update_layout(height=400, width=800, title_text=\"Survival by Alone\")\nfig.show()","59fe9903":"df.head()","3c64fea6":"cols = [\"Pclass\", \"Sex\", \"Age_class\", \"Embarked\", \"title\", \"FamilySize\", \"Fare\", \"Alone\"]\ncat_cols = [\"Sex\", \"Embarked\", \"title\"]\nnum_cols = [\"FamilySize\", \"Pclass\", \"Age_class\", \"Alone\", \"Fare\"]\n\nX = df[cols]\ny = df[\"Survived\"]","906a463a":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\n\ncat_pipe = Pipeline([\n    ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n    ('encoder', OneHotEncoder(handle_unknown=\"ignore\")),\n])\n\nnum_pipe = Pipeline([\n    ('imputer', SimpleImputer(strategy=\"median\")),\n    ('scaler', StandardScaler())\n])\n\ndata_prep_pipe = ColumnTransformer([\n    (\"cat_cols\", cat_pipe, cat_cols),\n    (\"num_cols\", num_pipe, num_cols)\n])\n\nX_prep = data_prep_pipe.fit_transform(X)\nX_prep.shape","649e725c":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, f1_score, mean_absolute_error\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nimport xgboost as xgb\nimport lightgbm as lgb","57646574":"def get_model(name, params=None):\n    if params == None:\n        if name == \"logreg\":\n            return LogisticRegression(random_state=42)\n        elif name == \"KNN\":\n            return KNeighborsClassifier()\n        elif name == \"RF\":\n            return RandomForestClassifier(random_state=42)\n        elif name == \"SVC\":\n            return SVC(random_state=42)\n        elif name == \"XGBoost\":\n            return xgb.XGBClassifier(random_state=42, verbosity=0, use_label_encoder=False)\n        elif name == \"LightGBM\":\n            return lgb.LGBMClassifier(random_state=42)\n    else:\n        if name == \"logreg\":\n            return LogisticRegression(**params)\n        elif name == \"KNN\":\n            return KNeighborsClassifier(**params)\n        elif name == \"RF\":\n            return RandomForestClassifier(**params)\n        elif name == \"SVC\":\n            return SVC(**params)\n        elif name == \"XGBoost\":\n            return xgb.XGBClassifier(**params)\n        elif name == \"LightGBM\":\n            return lgb.LGBMClassifier(**params)","b765105d":"list_models = [\"logreg\", \"KNN\", \"RF\", \"SVC\", \"XGBoost\", \"LightGBM\"]\n\nfor model_name in list_models:\n    model = get_model(model_name)\n    preds = cross_val_predict(model, X_prep, y, cv=10)\n    f1 = f1_score(y, preds)\n    roc_auc = roc_auc_score(y, preds)\n    mae = mean_absolute_error(y, preds)\n    print(f\"{model_name}:\\nF1: {f1:.3f},\\nROC AUC: {roc_auc:.3f},\\nMAE: {mae:.3f}\\n\")\n","97b719ba":"list_models.remove(\"RF\")\nlist_models.remove(\"KNN\")","0ff6d37b":"list_models","ac6ee7c5":"def get_params_dist(name):\n    if name == \"logreg\":\n        return {\"random_state\": [42], \n                \"solver\": [\"lbfgs\", \"liblinear\"],\n                \"C\" : [100, 10, 1.0, 0.1, 0.01]}\n    elif name == \"SVC\":\n        return {\"random_state\": [42], \n                \"kernel\": [\"rbf\", \"linear\"],\n                'C': [1e0, 1e1, 1e2, 1e3], \n                \"gamma\": [0.5, 0.6, 0.7, 0.8, 0.9]}\n    elif name == \"XGBoost\":\n        return {\"random_state\": [42], \"verbosity\": [0], \"use_label_encoder\": [False],\n                'max_depth': [3,6,10],\n                'learning_rate': [0.01, 0.05, 0.1],\n                'n_estimators': [100, 500, 1000],\n                'colsample_bytree': [0.3, 0.7, 1.0],\n                }\n    elif name == \"LightGBM\":\n        return {\"random_state\": [42],\n                \"max_depth\": [3,6,10],\n                \"learning_rate\": [0.01, 0.05, 0.1],\n                \"n_estimators\": [100, 500, 1000],\n                }","46ec225e":"for model_name in list_models:\n    model = get_model(model_name)\n    params_dist = get_params_dist(model_name)\n    grid = GridSearchCV(model, params_dist, cv=5, scoring=\"roc_auc\")\n    grid.fit(X_prep, y)\n    print(f\"{model_name}:\\nBest params: {grid.best_params_}\\nBest score: {grid.best_score_}\\n\")","b7e84c14":"best_model_name = \"XGBoost\"\nmodel = get_model(best_model_name)\nparams_dist = get_params_dist(best_model_name)\ngrid = GridSearchCV(model, params_dist, cv=10, scoring=\"roc_auc\")\ngrid.fit(X_prep, y)\npreds = grid.predict(X_prep)\nroc_auc = roc_auc_score(y, preds)\nprint(f\"{best_model_name}:\\nBest params: {grid.best_params_}\\nROC AUC: {roc_auc:.3f}\\n\")","97bfe964":"import xgboost as xgb\n\nparams = grid.best_params_\n\nxgb_model = xgb.XGBClassifier(**params)\ntrain_preds = cross_val_predict(xgb_model, X_prep, y, cv=50, verbose=1)","557b2939":"roc_auc = roc_auc_score(y, train_preds)\nmae = mean_absolute_error(y, train_preds)\nf1 = f1_score(y, train_preds)\n\nprint(f\"ROC AUC: {roc_auc:.3f}\")\nprint(f\"MAE: {mae:.3f}\")\nprint(f\"F1: {f1:.3f}\")","316784ca":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ncm = confusion_matrix(y, preds, normalize='true', labels=[0,1])\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=[0, 1])\ndisp.plot() \nplt.show()","864190e0":"fpr, tpr, thresholds = roc_curve(y, train_preds)","9ca78a67":"def plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.axis([0, 1, 0, 1])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    \nplot_roc_curve(fpr, tpr)\nplt.show()","3cd12f94":"full_model = get_model(\"XGBoost\", params=params)\nfull_model.fit(X_prep, y)\n\nX_test = test_data\nX_test[\"title\"] = X_test.Name.map(get_title)\nX_test[\"FamilySize\"] = X_test.Parch + X_test.SibSp\nX_test[\"Age_class\"] = X_test[\"Age\"] \/\/ 15 * 15\nX_test[\"Alone\"] = X_test.FamilySize.map(lambda x: 1 if x == 0 else 0)\nX_test = X_test[cols]","15a946db":"X_test_prep = data_prep_pipe.transform(X_test)\ntest_preds = full_model.predict(X_test_prep)","3353886d":"# Saving the output for submission\noutput = pd.DataFrame({'PassengerId': test_data.index, 'Survived':test_preds})\noutput.to_csv('my_submission.csv', index=False)","1bf705b3":"## Test Predictions","44646022":"## Submission","ec143e21":"# Data Preparation","059dd6c1":"# Train on Full Data","24343276":"### How Should Performance be Measured?","b4b6afee":"### Object Columns","66db6be8":"# Introduction\n\nThe Titanic competition's goal is quite simple: we have a training data which has different informations about the passengers at board in the famous Titanic ship, and we have to predict whether new passengers (unseen by our ML model) will survive or not.\n\n# Understanding the data\nSurvival : 0 = No, 1 = Yes\n\nPclass : Passenger's social economic class 1st = Upper 2nd = Middle 3rd = Lower\n\nSibSp : The number of siblings and spouses\n\nParch : The number of parents\n\nTicket : Ticket number\n\nFare : Passenger fare\n\nCabin : Cabin number embarked\n\nEmbarked: Where the passenger embarked. C = Cherbourg, Q = Queenstown, S = Southampton\n\nName, Sex , Age are self-explanatory","1896090b":"There is a significant amount of positive class values. Let's use as performance measure the ROC AUC score.","74a73c28":"# Exploratory Data Analysis (EDA)","0196c1a1":"# Reading Data","47402394":"### Numerical Columns","a1300749":"### Dependencies"}}