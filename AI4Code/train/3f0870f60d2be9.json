{"cell_type":{"9e4d998e":"code","122c40b1":"code","c45d5b46":"code","0d790442":"code","e2771cb1":"code","6b331ef4":"code","6d1a0581":"code","82fdb57d":"code","6a69d4f0":"code","920bc6e2":"code","e7d3e92f":"code","552add0a":"code","c644707c":"code","8f772470":"code","f17cf945":"code","db9f1d41":"code","b677816d":"code","47851431":"code","5090a764":"code","b5fdf178":"code","9738831a":"code","d0ea29df":"code","7e3121dd":"code","d43123be":"code","382f64bb":"code","93416934":"code","27dfbffe":"code","aa6e66f3":"code","c8872cbc":"code","1ff37a6f":"code","88121ff5":"code","95bbd00a":"code","980e8bf9":"code","4ba567dc":"code","702e12f6":"code","a58bedb4":"code","6acce847":"code","a2716764":"code","5020d383":"code","22bb891b":"code","368e6447":"code","531e6d7d":"code","68ae2b39":"code","fbbc546c":"code","ad010a94":"markdown","e54dc47e":"markdown","78b23306":"markdown","4289efea":"markdown","7ea432bd":"markdown","6d4c0d4c":"markdown","344f422c":"markdown","310789e7":"markdown","c5d70370":"markdown","538ab2b6":"markdown","1e6cb76d":"markdown","18059448":"markdown","31e6ca98":"markdown"},"source":{"9e4d998e":"!ls ..\/input","122c40b1":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport sys\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn import metrics\nfrom time import time","c45d5b46":"# Remember to change directory path\ntrain = pd.read_csv(\"..\/input\/train.csv\", parse_dates=['first_active_month'])\ntest = pd.read_csv(\"..\/input\/test.csv\", parse_dates=['first_active_month'])\nprint(train.shape)\nprint(test.shape)","0d790442":"data = pd.concat([train,test])\nprint(data.head(5))","e2771cb1":"data.dtypes","6b331ef4":"data.describe()","6d1a0581":"target_col = \"target\"\n\nplt.figure(figsize=(8,6))\nplt.scatter(range(train.shape[0]), np.sort(train[target_col].values))\nplt.xlabel('index', fontsize=12)\nplt.ylabel('Loyalty Score', fontsize=12)\nplt.show()","82fdb57d":"plt.figure(figsize=(12,8))\nsns.distplot(train[target_col].values, bins=50, kde=False, color=\"red\")\nplt.title(\"Histogram of Loyalty score\")\nplt.xlabel('Loyalty score', fontsize=12)\nplt.show()","6a69d4f0":"(train['target']<-30).sum()","920bc6e2":"'''\ntrain = train.drop(train[train.target<-30].index)\nplt.figure(figsize=(12,8))\nsns.distplot(train[target_col].values, bins=50, kde=False, color=\"red\")\nplt.title(\"Histogram of Loyalty score\")\nplt.xlabel('Loyalty score', fontsize=12)\nplt.show()\n'''","e7d3e92f":"cnt_srs_1 = train['first_active_month'].dt.date.value_counts()\ncnt_srs_1 = cnt_srs_1.sort_index()\ncnt_srs_2 = test['first_active_month'].dt.date.value_counts()\ncnt_srs_2 = cnt_srs_2.sort_index()\n\nsns.set(rc={'figure.figsize':(14, 6)})\nsns.barplot(cnt_srs_1.index, cnt_srs_1.values, alpha = 0.5, color = 'green')\nsns.barplot(cnt_srs_2.index, cnt_srs_2.values, alpha = 0.5, color = 'red')\n#plt.bar(cnt_srs_1.index, cnt_srs_1.values, alpha = 0.5, color = 'green')\n#plt.bar(cnt_srs_2.index, cnt_srs_2.values, alpha = 0.5, color = 'red')\n\nplt.xticks(rotation = 'vertical')\n#plt.xlabel('First active month', fontsize=12)\n#plt.ylabel('Number of cards', fontsize=12)\n#plt.title(\"First active month count in train set\")\n\nplt.show()","552add0a":"print(train.feature_1.unique())","c644707c":"# feature 1\nplt.figure(figsize=(16,8))\nsns.boxplot(x=\"feature_1\", y=train.target, data=train)\nplt.xticks(rotation='vertical')\nplt.xlabel('Feature 1', fontsize=12)\nplt.ylabel('Loyalty score', fontsize=12)\nplt.title(\"Feature 1 distribution\")\nplt.show()","8f772470":"print(train.feature_2.unique())","f17cf945":"# feature 2\nplt.figure(figsize=(16,8))\nsns.boxplot(x=\"feature_2\", y=train.target, data=train)\nplt.xticks(rotation='vertical')\nplt.xlabel('Feature 2', fontsize=12)\nplt.ylabel('Loyalty score', fontsize=12)\nplt.title(\"Feature 2 distribution\")\nplt.show()","db9f1d41":"print(train.feature_3.unique())","b677816d":"# feature 3\nplt.figure(figsize=(16,8))\nsns.boxplot(x=\"feature_3\", y=train.target, data=train)\nplt.xticks(rotation='vertical')\nplt.xlabel('Feature 3', fontsize=12)\nplt.ylabel('Loyalty score', fontsize=12)\nplt.title(\"Feature 3 distribution\")\nplt.show()","47851431":"hist = pd.read_csv('..\/input\/historical_transactions.csv')","5090a764":"hist.head(5)","b5fdf178":"hist.dtypes","9738831a":"# Number of historical transactions for each card_id\ngdf = hist.groupby('card_id')\n#print(gdf.head(5))\n\ngdf = gdf['purchase_amount'].size().reset_index()\nprint(gdf.head(5))\n\ngdf.columns = ['card_id', 'num_hist_transactions']\ntrain = pd.merge(train, gdf, on='card_id', how='left')\ntest = pd.merge(test, gdf, on='card_id', how='left')\n#data = pd.merge(data, gdf, on='card_id', how='left')\nprint(train.head(5))","d0ea29df":"bins = [0, 10, 20, 30, 40, 50, 75, 100, 150, 200, 500, 10000]\ntrain['binned_num_hist_transactions'] = pd.cut(train['num_hist_transactions'], bins)\ncnt_srs = train.groupby(\"binned_num_hist_transactions\")['target'].mean()\n\nplt.figure(figsize=(12,8))\nsns.boxplot(x=\"binned_num_hist_transactions\", y='target', data=train, showfliers=False)\nplt.xticks(rotation='vertical')\nplt.xlabel('binned_num_hist_transactions', fontsize=12)\nplt.ylabel('Loyalty score', fontsize=12)\nplt.title(\"binned_num_hist_transactions distribution\")\nplt.show()","7e3121dd":"gdf = hist.groupby(\"card_id\")\ngdf = gdf[\"purchase_amount\"].agg(['sum', 'mean', 'std', 'min', 'max']).reset_index()\ngdf.columns = [\"card_id\", \"sum_hist_trans\", \"mean_hist_trans\", \"std_hist_trans\", \"min_hist_trans\", \"max_hist_trans\"]\ntrain = pd.merge(train, gdf, on=\"card_id\", how=\"left\")\ntest = pd.merge(test, gdf, on=\"card_id\", how=\"left\")","d43123be":"bins = np.percentile(train[\"sum_hist_trans\"], range(0,101,10))\ntrain['binned_sum_hist_trans'] = pd.cut(train['sum_hist_trans'], bins)\n#cnt_srs = train_df.groupby(\"binned_sum_hist_trans\")[target_col].mean()\n\nplt.figure(figsize=(12,8))\nsns.boxplot(x=\"binned_sum_hist_trans\", y='target', data=train, showfliers=False)\nplt.xticks(rotation='vertical')\nplt.xlabel('binned_sum_hist_trans', fontsize=12)\nplt.ylabel('Loyalty score', fontsize=12)\nplt.title(\"Sum of historical transaction value (Binned) distribution\")\nplt.show()","382f64bb":"gdf = hist.groupby(\"card_id\")\ngdf = gdf[\"installments\"].agg(['sum', 'mean', 'std', 'min', 'max']).reset_index()\ngdf.columns = [\"card_id\", \"sum_hist_installments\", \"mean_hist_installments\", \"std_hist_installments\", \n               \"min_hist_installments\", \"max_hist_installments\"]\ntrain = pd.merge(train, gdf, on=\"card_id\", how=\"left\")\ntest = pd.merge(test, gdf, on=\"card_id\", how=\"left\")","93416934":"bins = np.percentile(train[\"sum_hist_installments\"], range(0,101,10))\ntrain['binned_sum_hist_installments'] = pd.cut(train['sum_hist_installments'], bins, duplicates = 'drop')\n#cnt_srs = train_df.groupby(\"binned_sum_hist_trans\")[target_col].mean()\n\nplt.figure(figsize=(12,8))\nsns.boxplot(x=\"binned_sum_hist_installments\", y='target', data=train, showfliers=False)\nplt.xticks(rotation='vertical')\nplt.xlabel('binned_sum_hist_installments', fontsize=12)\nplt.ylabel('Loyalty score', fontsize=12)\nplt.title(\"Sum of historical transaction installments (Binned) distribution\")\nplt.show()","27dfbffe":"new_trans = pd.read_csv(\"..\/input\/new_merchant_transactions.csv\")","aa6e66f3":"new_trans.head(5)","c8872cbc":"new_trans.dtypes","1ff37a6f":"gdf = new_trans.groupby(\"card_id\")\ngdf = gdf[\"purchase_amount\"].size().reset_index()\ngdf.columns = [\"card_id\", \"num_merch_transactions\"]\ntrain = pd.merge(train, gdf, on=\"card_id\", how=\"left\")\ntest = pd.merge(test, gdf, on=\"card_id\", how=\"left\")","88121ff5":"gdf = new_trans.groupby(\"card_id\")\ngdf = gdf[\"purchase_amount\"].agg(['sum', 'mean', 'std', 'min', 'max']).reset_index()\ngdf.columns = [\"card_id\", \"sum_merch_trans\", \"mean_merch_trans\", \"std_merch_trans\", \n               \"min_merch_trans\", \"max_merch_trans\"]\ntrain = pd.merge(train, gdf, on=\"card_id\", how=\"left\")\ntest = pd.merge(test, gdf, on=\"card_id\", how=\"left\")","95bbd00a":"bins = [0, 10, 20, 30, 40, 50, 75, 10000]\ntrain['binned_num_merch_transactions'] = pd.cut(train['num_merch_transactions'], bins)\ncnt_srs = train.groupby(\"binned_num_merch_transactions\")['target'].mean()\n\nplt.figure(figsize=(12,8))\nsns.boxplot(x=\"binned_num_merch_transactions\", y='target', data=train, showfliers=False)\nplt.xticks(rotation='vertical')\nplt.xlabel('binned_num_merch_transactions', fontsize=12)\nplt.ylabel('Loyalty score', fontsize=12)\nplt.title(\"Number of new merchants transaction (Binned) distribution\")\nplt.show()","980e8bf9":"gdf = new_trans.groupby(\"card_id\")\ngdf = gdf[\"installments\"].agg(['sum', 'mean', 'std', 'min', 'max']).reset_index()\ngdf.columns = [\"card_id\", \"sum_merch_installments\", \"mean_merch_installments\", \"std_merch_installments\", \n               \"min_merch_installments\", \"max_merch_installments\"]\ntrain = pd.merge(train, gdf, on=\"card_id\", how=\"left\")\ntest = pd.merge(test, gdf, on=\"card_id\", how=\"left\")","4ba567dc":"bins = np.nanpercentile(train[\"sum_merch_installments\"], range(0,101,10))\ntrain['binned_sum_merch_installments'] = pd.cut(train['sum_merch_installments'], bins, duplicates = 'drop')\n#cnt_srs = train_df.groupby(\"binned_sum_hist_trans\")[target_col].mean()\n\nplt.figure(figsize=(12,8))\nsns.boxplot(x=\"binned_sum_merch_installments\", y='target', data=train, showfliers=False)\nplt.xticks(rotation='vertical')\nplt.xlabel('binned sum of new merchant transactions installments', fontsize=12)\nplt.ylabel('Loyalty score', fontsize=12)\nplt.title(\"Sum of New merchants transaction installments value (Binned) distribution\")\nplt.show()","702e12f6":"train[\"year\"] = train[\"first_active_month\"].dt.year\ntrain[\"month\"] = train[\"first_active_month\"].dt.month\ntest[\"month\"] = test[\"first_active_month\"].dt.month\ntest[\"year\"] = test[\"first_active_month\"].dt.year\n\n# data['year'] = data['first_active_month'].dt.year\n# data['month'] = data['first_active_month'].dt.month\n\ncols_to_use = [\"feature_1\", \"feature_2\", \"feature_3\", \"year\", \"month\", \n               \"num_hist_transactions\", \"sum_hist_trans\", \"mean_hist_trans\", \"std_hist_trans\", \n               \"min_hist_trans\", \"max_hist_trans\",\n               \"sum_hist_installments\", \"mean_hist_installments\", \"std_hist_installments\", \n               \"min_hist_installments\", \"max_hist_installments\",            \n               \"num_merch_transactions\", \"sum_merch_trans\", \"mean_merch_trans\", \"std_merch_trans\",\n               \"min_merch_trans\", \"max_merch_trans\",\n               \"sum_merch_installments\", \"mean_merch_installments\", \"std_merch_installments\",\n               \"min_merch_installments\", \"max_merch_installments\",\n              ]\n\n\ntrain_X = train[cols_to_use]\ntrain_y = train['target'].values\ntest_X = test[cols_to_use]\nprint(train_X.shape[0])\nprint(train_y.shape[0])","a58bedb4":"# checking minable view: get into consideration there are missing values \n# for indicators coming from new_merchants_transactions file.\nprint(train_X.head(5))\nprint(train_X.info(5))\nprint(train_X.isnull().sum())","6acce847":"print(train_y[:5])\nprint(np.info(train_y))\nprint(np.isnan(train_y).sum())","a2716764":"from xgboost.sklearn import XGBRegressor\nimport lightgbm as lgb\n\n#modelname = 'lightgbm'\nmodelname = 'XGBRegressor'\n#model = lgb()\nmodel = XGBRegressor()\n\nparams_lgb = {\n    'num_leaves': 100,\n    'min_data_in_leaf': 30, \n    'objective':'regression',\n    'max_depth': 6,\n    'learning_rate': 0.005,\n    \"min_child_samples\": 20,\n    \"boosting\": \"gbdt\",\n    \"feature_fraction\": 0.9,\n    \"bagging_freq\": 1,\n    \"bagging_fraction\": 0.9 ,\n    \"bagging_seed\": 11,\n    \"metric\": 'rmse',\n    \"lambda_l1\": 0.1,\n    \"verbosity\": -1\n}\n\n\nparams_xgbr = {\n    'nthread':[4], #when use hyperthread, xgboost may become slower\n    'objective':['reg:linear'],\n    'learning_rate': [.03, 0.05, .07], #so called `eta` value\n    'max_depth': [5, 6, 7],\n    'min_child_weight': [4],\n    'silent': [1],\n    'subsample': [0.7],\n    'colsample_bytree': [0.7],\n    'n_estimators': [500]\n}","5020d383":"from sklearn.model_selection import RandomizedSearchCV\n\nstart = time()\nrf_random = RandomizedSearchCV(estimator = model, param_distributions = params_xgbr, \n                               n_iter = 2, cv = 3, verbose = 2, random_state = 42, n_jobs = -1)\n\nrf_random.fit(train_X, train_y)\n# print(time() - start)\nprint('Total of %.5f seconds' % (time() - start))\nprint(rf_random.cv_results_)","22bb891b":"final_model = rf_random.best_estimator_\npredictions = final_model.predict(test_X)\nprint(predictions[:5])","368e6447":"test_X.info(5)","531e6d7d":"test_X.shape","68ae2b39":"predictions.shape","fbbc546c":"df_submission = pd.DataFrame({'card_id':test['card_id']})\ndf_submission[\"target\"] = predictions\ndf_submission.to_csv(\"newton.csv\", index=False)","ad010a94":"# Exploring data: historical_transactions file.","e54dc47e":"# Exploring data: train, test files.","78b23306":"# Baseline: minable view","4289efea":"Check out this 2207 input values that might be either outliers or erros. Take them into consideration.\n\n**Edit: dropping this values to try out the model with new data training**","7ea432bd":"## Overview of the columns: historical_transactions file.","6d4c0d4c":"Overview of the columns\nThe field descriptions are as follows:\n\n    - card_id - Card identifier\n    - month_lag - month lag to reference date\n    - purchase_date - Purchase date\n    - authorized_flag - 'Y' if approved, 'N' if denied\n    - category_3 - anonymized category\n    - installments - number of installments of purchase\n    - category_1 - anonymized category\n    - merchant_category_id - Merchant category identifier (anonymized )\n    - subsector_id - Merchant category group identifier (anonymized )\n    - merchant_id - Merchant identifier (anonymized)\n    - purchase_amount - Normalized purchase amount\n    - city_id - City identifier (anonymized )\n    - state_id - State identifier (anonymized )\n    - category_2 - anonymized category\n    \nNow let us make some features based on the historical transactions and merge them with train and test set.","344f422c":"# Model tuning","310789e7":"### purchase_amount as indicator","c5d70370":"# Exploring data: new_merchants_transactions file.","538ab2b6":"## Historical transactions, aggregated by different indicators","1e6cb76d":"### installments as indicator","18059448":"### purchaste_amount as indicator","31e6ca98":"### installments as indicator"}}