{"cell_type":{"2d198904":"code","16004415":"code","d1fea0a6":"code","0d37ee7a":"code","f81a2cc9":"code","9c28e6dd":"code","51d9f448":"code","00bc43ac":"code","9b4c295f":"code","61e9287c":"code","3eaf6a70":"code","6dfe0035":"code","6e72c963":"code","4f902505":"code","b08c85d2":"code","fbc40cc6":"code","ea77f708":"code","5e201bd5":"code","201e3bb2":"code","a4ae5524":"code","70c0c36a":"code","7e4d0a4c":"code","84abc374":"code","cca47927":"code","d380fa66":"code","e263e92b":"markdown","2c6e9e0a":"markdown","0aa70272":"markdown","17ea0ef4":"markdown","29192770":"markdown","25f67b78":"markdown","2fae69a5":"markdown","25719dd5":"markdown","e07d3dfa":"markdown","ce8c576c":"markdown"},"source":{"2d198904":"!pip install flaml[notebook]","16004415":"import numpy as np\nimport pandas as pd\n\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport plotly.express as px\n\nfrom flaml import AutoML\nfrom flaml.data import get_output_from_log\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score","d1fea0a6":"pizza_v1_df = pd.read_csv(\"..\/input\/pizza-price-prediction\/pizza_v1.csv\")\npizza_v2_df = pd.read_csv(\"..\/input\/pizza-price-prediction\/pizza_v2.csv\")\n\nprint(f\"Shape of pizza_v1 dataframe: {pizza_v1_df.shape}\")\nprint(f\"Shape of pizza_v2 dataframe: {pizza_v2_df.shape}\")","0d37ee7a":"pizza_v1_df.sample(20)","f81a2cc9":"pizza_v2_df.sample(20)","9c28e6dd":"pizza_v1_df.dtypes","51d9f448":"pizza_v2_df.dtypes","00bc43ac":"# converting price_rupiah from string to integer\n\ndef convert_price_from_string_to_int(price: str) -> int:\n    try:\n        price = price[2:]\n        \n        price = price.replace(\",\", \"\")\n        \n        price = int(price)\n        \n        return price\n    except:\n        print(f\"Error converting from string to int {price}\")\n        \npizza_v1_df['target'] = pizza_v1_df['price_rupiah'].apply(convert_price_from_string_to_int)\npizza_v2_df['target'] = pizza_v2_df['price_rupiah'].apply(convert_price_from_string_to_int)","9b4c295f":"# for dataset pizza_v2, diameter is string instead of float. Converting string to float\n\ndef convert_diameter_from_string_to_float_for_v2(diameter: str) -> float:\n    try:\n        diameter = diameter.replace(\"inch\", \"\")\n        \n        diameter = diameter.strip()\n        \n        diameter = float(diameter)\n        \n        return diameter\n    except:\n        print(f\"Error converting from string to float {diameter}\")\n\npizza_v2_df['diameter'] = pizza_v2_df['diameter'].apply(convert_diameter_from_string_to_float_for_v2)","61e9287c":"# drop the previous column price_rupiah\npizza_v1_df = pizza_v1_df.drop('price_rupiah', axis=1)\npizza_v2_df = pizza_v2_df.drop('price_rupiah', axis=1)","3eaf6a70":"print(f\"Unique values in v1 variant: {pizza_v1_df['variant'].unique()}\")\nprint(f\"Unique values in v2 variant: {pizza_v2_df['variant'].unique()}\")","6dfe0035":"# for variant, spicy_tuna and spicy tuna categories are same, so we need to rectificy spicy tune to spicy_tuna\npizza_v1_df.loc[pizza_v1_df['variant'] == \"spicy tuna\", \"variant\"] = \"spicy_tuna\"\npizza_v2_df.loc[pizza_v2_df['variant'] == \"spicy tuna\", \"variant\"] = \"spicy_tuna\"","6e72c963":"print(f\"After removing duplicates, unique values in v1 variant: {pizza_v1_df['variant'].unique()}\")\nprint(f\"After removing duplicates, unique values in v2 variant: {pizza_v2_df['variant'].unique()}\")","4f902505":"pizza_v1_df.groupby(by=['topping']).size().index","b08c85d2":"# Count graphs for categorical variables for v1\n\ncount_cols = ['company', 'topping', 'variant', 'size', 'extra_sauce', 'extra_cheese']\n\nfig = make_subplots(rows=3, cols=2, subplot_titles=count_cols)\n\nfor i in range(6):\n    group_by = pizza_v1_df.groupby(by=[count_cols[i]]).size()\n    index, values = group_by.index, group_by.values\n    fig.add_trace(\n        go.Bar(x=values, y=index, name=count_cols[i], orientation='h'),\n        row=i%3+1,\n        col=i\/\/3+1\n    )\n    fig.update_xaxes(title_text=\"Count\", row=i%3+1, col=i\/\/3+1)\n\nfig.update_layout(\n    title=\"Count Plots for Categorical Variables V1\",\n    autosize=False,\n    width=1440,\n    height=1280,\n)\n    \nfig.show()","fbc40cc6":"# correlation between diameter and price of pizza\n\nfig = px.scatter(\n    pizza_v1_df, x='diameter', y='target',\n    opacity=0.75, trendline='ols', title=\"Regression between diameter and price V1\"\n)\n\nfig.show()","ea77f708":"# Count graphs for categorical variables for v2\n\ncount_cols = ['company', 'topping', 'variant', 'size', 'extra_sauce', 'extra_cheese', 'extra_mushrooms']\n\nfig = make_subplots(rows=3, cols=3, subplot_titles=count_cols)\n\nfor i in range(7):\n    group_by = pizza_v2_df.groupby(by=[count_cols[i]]).size()\n    index, values = group_by.index, group_by.values\n    fig.add_trace(\n        go.Bar(x=values, y=index, name=count_cols[i], orientation='h'),\n        row=i%3+1,\n        col=i\/\/3+1\n    )\n    fig.update_xaxes(title_text=\"Count\", row=i%3+1, col=i\/\/3+1)\n\nfig.update_layout(\n    title=\"Count Plot for Categorical Variables V2\",\n    autosize=False,\n    width=1440,\n    height=1280,\n)\n    \nfig.show()","5e201bd5":"# correlation between diameter and price of pizza\n\nfig = px.scatter(\n    pizza_v2_df, x='diameter', y='target',\n    opacity=0.75, trendline='ols', title=\"Regression between diameter and price V1\"\n)\nfig.show()","201e3bb2":"# select the categorical columns and replace them by dummies\ncategorical_cols_for_v1 = ['company', 'topping', 'variant', 'size', 'extra_sauce', 'extra_cheese']\ncategorical_cols_for_v2 = ['company', 'topping', 'variant', 'size', 'extra_sauce', 'extra_cheese', 'extra_mushrooms']\n\npizza_v1_df = pd.get_dummies(pizza_v1_df, columns=categorical_cols_for_v1, drop_first=True)\npizza_v2_df = pd.get_dummies(pizza_v2_df, columns=categorical_cols_for_v2, drop_first=True)","a4ae5524":"TIME_BUDGET = 600\n\ndef train_and_return_automl_model_for_dataset(X_train, y_train, version: str) -> AutoML:\n    \n    automl = AutoML()\n\n    settings = {\n        'time_budget': TIME_BUDGET,\n        'metric': 'r2',\n        'estimator_list': ['lgbm', 'catboost', 'rf', 'extra_tree'],\n        'task': 'regression',\n        'log_file_name': f\"{version}.log\",\n        'seed': 987654321\n    }\n    \n    automl.fit(X_train=X_train, y_train=y_train, **settings)\n    \n    return automl","70c0c36a":"X_v1 = pizza_v1_df.drop('target', axis=1)\ny_v1 = pizza_v1_df['target']\n\nX_v2 = pizza_v2_df.drop('target', axis=1)\ny_v2 = pizza_v2_df['target']\n\nX_train_v1, X_test_v1, y_train_v1, y_test_v1 = train_test_split(X_v1, y_v1, test_size=0.2)\nX_train_v2, X_test_v2, y_train_v2, y_test_v2 = train_test_split(X_v2, y_v2, test_size=0.2)\n\nassert X_train_v2.shape[1] == X_v2.shape[1]\n\nautoml_v1 = train_and_return_automl_model_for_dataset(X_train_v1, y_train_v1, \"v1\")\nautoml_v2 = train_and_return_automl_model_for_dataset(X_train_v2, y_train_v2, \"v2\")","7e4d0a4c":"print(f'X_v1 shape:{X_v1.shape}')\nprint(f'y_v1 shape:{y_v1.shape}')\nprint(f'X_v2 shape:{X_v2.shape}')\nprint(f'y_v2 shape:{y_v2.shape}')","84abc374":"def return_valid_loss_history(model_version: str): \n    time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n        get_output_from_log(filename=f\"{model_version}.log\", time_budget=100)\n    \n    return (time_history, valid_loss_history)\n\nv1_time_history, v1_valid_loss_history = return_valid_loss_history(\"v1\")\nv2_time_history, v2_valid_loss_history = return_valid_loss_history(\"v2\")\n\nfig = make_subplots(rows=1, cols=2, subplot_titles=(\"V1 Validation History\", \"V2 Validation History\"))\n\nfig.add_trace(\n    go.Scatter(x=v1_time_history, y=np.array(v1_valid_loss_history)),\n    row=1, col=1\n)\n\n\nfig.add_trace(\n    go.Scatter(x=v2_time_history, y=np.array(v2_valid_loss_history)),\n    row=1, col=2\n)\n\nfig.update_xaxes(title_text=\"Wall Clock Time (s)\", row=1, col=1)\nfig.update_xaxes(title_text=\"Wall Clock Time (s)\", row=1, col=2)\n\nfig.update_yaxes(title_text=\"Validation Loss\", row=1, col=1)\nfig.update_yaxes(title_text=\"Validation Loss\", row=1, col=2)\n\nfig.show()","cca47927":"def get_r2_score_from_best_estimator(X_test, y_test, best_estimator):\n    \n    y_pred = best_estimator.predict(X_test)\n    \n    r2 = r2_score(y_test, y_pred)\n    \n    return r2\n\nv1_best_model = automl_v1.model.estimator\nv2_best_model = automl_v2.model.estimator\n\nprint(f'Best config for v1: {v1_best_model}')\nprint(f'Best config for v2: {v2_best_model}')","d380fa66":"v1_r2_score = get_r2_score_from_best_estimator(X_test_v1, y_test_v1, v1_best_model)\nv2_r2_score = get_r2_score_from_best_estimator(X_test_v2, y_test_v2, v2_best_model)\n\nprint(f'R2 score from best model for v1 : {v1_r2_score:.4f}')\nprint(f'R2 score from best model for v2 : {v2_r2_score:.4f}')","e263e92b":"# Introduction\n\n> FLAML is a lightweight Python library that finds accurate machine learning models automatically, efficiently and economically. It frees users from selecting learners and hyperparameters for each learner. It is fast and economical. The simple and lightweight design makes it easy to extend, such as adding customized learners or metrics. FLAML is powered by a new, cost-effective hyperparameter optimization and learner selection method invented by Microsoft Research. FLAML leverages the structure of the search space to choose a search order optimized for both cost and error. For example, the system tends to propose cheap configurations at the beginning stage of the search, but quickly moves to configurations with high model complexity and large sample size when needed in the later stage of the search. For another example, it favors cheap learners in the beginning but penalizes them later if the error improvement is slow. The cost-bounded search and cost-based prioritization make a big difference in the search efficiency under budget constraints.\n\n[Source](https:\/\/github.com\/microsoft\/FLAML)","2c6e9e0a":"## Analysis graphs for V2","0aa70272":"## Analysis graphs for V1","17ea0ef4":"# Conclusion\n\n- R2 Score is pretty good for AutoML model\n- What are your thoughts on Microsoft FLAML?","29192770":"# AutoML Model Execution","25f67b78":"# \"Dummy\"fying Data ","2fae69a5":"# EDA","25719dd5":"# Installation\n\nSteps mentioned on [FLAML GitHub](https:\/\/github.com\/microsoft\/FLAML#installation)","e07d3dfa":"# Imports","ce8c576c":"# Log History"}}