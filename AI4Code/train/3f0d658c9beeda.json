{"cell_type":{"72372d37":"code","44346db9":"code","260b8431":"code","fcc46c1b":"code","508fa117":"code","a91f4ad8":"code","dc27fc73":"code","05759425":"code","f004b9fe":"code","de3c8a0e":"code","74cf22a8":"markdown","b22b95ca":"markdown","a74413e5":"markdown","90085e62":"markdown"},"source":{"72372d37":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","44346db9":"from pandas_profiling import ProfileReport","260b8431":"# Load Data\nxtrain = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-3\/train.csv')\nxtest = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-3\/test.csv')\nxsubmission = pd.read_csv('\/kaggle\/input\/covid19-global-forecasting-week-3\/submission.csv')","fcc46c1b":"train_profile = ProfileReport(xtrain, title='Pandas Profiling Report', html={'style':{'full_width':True}})\ntrain_profile","508fa117":"xtrain.rename(columns={'Country_Region':'Country'}, inplace=True)\nxtest.rename(columns={'Country_Region':'Country'}, inplace=True)\n\nxtrain.rename(columns={'Province_State':'State'}, inplace=True)\nxtest.rename(columns={'Province_State':'State'}, inplace=True)\n\nxtrain['Date'] = pd.to_datetime(xtrain['Date'], infer_datetime_format=True)\nxtest['Date'] = pd.to_datetime(xtest['Date'], infer_datetime_format=True)\n\nxtrain.info()\nxtest.info()\n\ny1_xTrain = xtrain.iloc[:, -2]\ny1_xTrain.head()\ny2_xTrain = xtrain.iloc[:, -1]\ny2_xTrain.head()\n\nEMPTY_VAL = \"EMPTY_VAL\"\n\ndef fillState(state, country):\n    if state == EMPTY_VAL: return country\n    return state","a91f4ad8":"X_xTrain = xtrain.copy()\n\nX_xTrain['State'].fillna(EMPTY_VAL, inplace=True)\nX_xTrain['State'] = X_xTrain.loc[:, ['State', 'Country']].apply(lambda x : fillState(x['State'], x['Country']), axis=1)\n\nX_xTrain.loc[:, 'Date'] = X_xTrain.Date.dt.strftime(\"%m%d\")\nX_xTrain[\"Date\"]  = X_xTrain[\"Date\"].astype(int)\n\nX_xTrain.head()\n\n#X_Test = df_test.loc[:, ['State', 'Country', 'Date']]\nX_xTest = xtest.copy()\n\nX_xTest['State'].fillna(EMPTY_VAL, inplace=True)\nX_xTest['State'] = X_xTest.loc[:, ['State', 'Country']].apply(lambda x : fillState(x['State'], x['Country']), axis=1)\n\nX_xTest.loc[:, 'Date'] = X_xTest.Date.dt.strftime(\"%m%d\")\nX_xTest[\"Date\"]  = X_xTest[\"Date\"].astype(int)\n\nX_xTest.head()","dc27fc73":"from sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\n\nX_xTrain.Country = le.fit_transform(X_xTrain.Country)\nX_xTrain['State'] = le.fit_transform(X_xTrain['State'])\n\nX_xTrain.head()\n\nX_xTest.Country = le.fit_transform(X_xTest.Country)\nX_xTest['State'] = le.fit_transform(X_xTest['State'])\n\nX_xTest.head()\n\nxtrain.head()\nxtrain.loc[xtrain.Country == 'Afghanistan', :]\nxtest.tail()","05759425":"from warnings import filterwarnings\nfilterwarnings('ignore')\n\nfrom sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\n\nfrom xgboost import XGBRegressor\n\ncountries = X_xTrain.Country.unique()\n","f004b9fe":"# Predict data and Create submission file from test data\nxout = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\n\nfor country in countries:\n    states = X_xTrain.loc[X_xTrain.Country == country, :].State.unique()\n    #print(country, states)\n    # check whether string is nan or not\n    for state in states:\n        X_xTrain_CS = X_xTrain.loc[(X_xTrain.Country == country) & (X_xTrain.State == state), ['State', 'Country', 'Date', 'ConfirmedCases', 'Fatalities']]\n        \n        y1_xTrain_CS = X_xTrain_CS.loc[:, 'ConfirmedCases']\n        y2_xTrain_CS = X_xTrain_CS.loc[:, 'Fatalities']\n        \n        X_xTrain_CS = X_xTrain_CS.loc[:, ['State', 'Country', 'Date']]\n        \n        X_xTrain_CS.Country = le.fit_transform(X_xTrain_CS.Country)\n        X_xTrain_CS['State'] = le.fit_transform(X_xTrain_CS['State'])\n        \n        X_xTest_CS = X_xTest.loc[(X_xTest.Country == country) & (X_xTest.State == state), ['State', 'Country', 'Date', 'ForecastId']]\n        \n        X_xTest_CS_Id = X_xTest_CS.loc[:, 'ForecastId']\n        X_xTest_CS = X_xTest_CS.loc[:, ['State', 'Country', 'Date']]\n        \n        X_xTest_CS.Country = le.fit_transform(X_xTest_CS.Country)\n        X_xTest_CS['State'] = le.fit_transform(X_xTest_CS['State'])\n        \n        #models_C[country] = gridSearchCV(model, X_Train_CS, y1_Train_CS, param_grid, 10, 'neg_mean_squared_error')\n        #models_F[country] = gridSearchCV(model, X_Train_CS, y2_Train_CS, param_grid, 10, 'neg_mean_squared_error')\n        \n        xmodel1 = XGBRegressor(n_estimators=1000)\n        xmodel1.fit(X_xTrain_CS, y1_xTrain_CS)\n        y1_xpred = xmodel1.predict(X_xTest_CS)\n        \n        xmodel2 = XGBRegressor(n_estimators=1000)\n        xmodel2.fit(X_xTrain_CS, y2_xTrain_CS)\n        y2_xpred = xmodel2.predict(X_xTest_CS)\n        \n        xdata = pd.DataFrame({'ForecastId': X_xTest_CS_Id, 'ConfirmedCases': y1_xpred, 'Fatalities': y2_xpred})\n        xout = pd.concat([xout, xdata], axis=0)\n","de3c8a0e":"xout.ForecastId = xout.ForecastId.astype('int')\nxout.tail()\nxout.to_csv('submission.csv', index=False)\nprint(\"Submission file Created.....\")","74cf22a8":"**Fit Data with Model**","b22b95ca":"### Pandas profiling is an open source Python module with which we can quickly do an exploratory data analysis with just a few lines of code. Besides, if this is not enough to convince us to use this tool, it also generates interactive reports in web format that can be presented to any person, even if they don\u2019t know programming.\n### In short, what pandas profiling does is save us all the work of visualizing and understanding the distribution of each variable. It generates a report with all the information easily available.","a74413e5":"## Generates profile reports from a pandas DataFrame. The pandas df.describe() function is great but a little basic for serious exploratory data analysis. pandas_profiling extends the pandas DataFrame with df.profile_report() for quick data analysis.\n\n### For each column the following statistics - if relevant for the column type - are presented in an interactive HTML report:\n\n* Type inference: detect the types of columns in a dataframe.\n* Essentials: type, unique values, missing values\n* Quantile statistics like minimum value, Q1, median, Q3, maximum, range, interquartile range\n* Descriptive statistics like mean, mode, standard deviation, sum, median absolute deviation, coefficient of variation, kurtosis, skewness\n* Most frequent values\n* Histogram\n* Correlations highlighting of highly correlated variables, Spearman, Pearson and Kendall matrices\n* Missing values matrix, count, heatmap and dendrogram of missing values\n* Text analysis learn about categories (Uppercase, Space), scripts (Latin, Cyrillic) and blocks (ASCII) of text data.","90085e62":"## Predict data and Create submission file from test data"}}