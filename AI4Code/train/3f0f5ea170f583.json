{"cell_type":{"1fc4b342":"code","b0eb1cda":"code","5192de4b":"code","d91dbbbf":"code","a9169d69":"code","2f6c2861":"code","3c5c1ed0":"code","f69cabed":"code","1661150f":"code","949955eb":"code","28430cbc":"code","5f594791":"code","43adeb73":"code","582f0334":"code","51d27daf":"code","6bd52b44":"code","b38e8bb2":"code","e4c5aa4d":"code","2a04f8a2":"code","435b6bff":"code","31651172":"code","1f285d4a":"code","34650607":"code","9060111b":"code","f15b95ab":"code","6ffc4eab":"code","45eae412":"code","f4072ece":"code","4208a7db":"code","71e38a7d":"code","8acc1388":"code","f3f19c4a":"code","52fd16f3":"code","948b61ec":"code","e0a4505b":"code","a5cfd39d":"code","f41bf191":"code","9a562f6c":"code","5a67f99d":"code","d693e13d":"code","c7808122":"code","cd28e042":"code","11471cf3":"code","88dac9f7":"code","a2272b65":"code","3002631b":"code","3e7e4f0e":"code","3cb0c8bd":"code","78ae9bbb":"code","c62f91b4":"code","6836f7fb":"code","1deed990":"code","3a7f58d8":"code","3c587793":"code","972c48bd":"code","a3b001b7":"code","477aed91":"code","6fb80584":"code","2af9c2d6":"code","89c5b9f6":"code","c923d7ed":"code","95a7a4f5":"code","ddd97289":"code","889ac542":"code","68a8050b":"code","99717a93":"code","e1576c0f":"code","fba8145e":"code","6f60ef7c":"code","84e264a1":"code","9079f0dc":"code","7f5bf19b":"code","476a7db0":"code","a0a4a0da":"code","9dff2da9":"code","1966623f":"code","4a41149c":"code","e92265f7":"code","27fd721c":"code","fdf59071":"code","40e58918":"code","b66dcec2":"code","81cbc15b":"markdown","ac7fc44a":"markdown","232c7a3b":"markdown","ef11c7da":"markdown","2cf03f8a":"markdown","63ba3dad":"markdown","e155496f":"markdown","66af2b3f":"markdown","2520507b":"markdown","c7b8b93e":"markdown","80e36b8a":"markdown","b7bc7c99":"markdown","ab786015":"markdown","4cb7d747":"markdown","e5815123":"markdown","d6495775":"markdown","2610e993":"markdown","f67fa608":"markdown","3c09b974":"markdown","c9c79a4e":"markdown","64066c8a":"markdown","8d400e22":"markdown","a80ea086":"markdown","87f525a0":"markdown","2fe88486":"markdown","a3e6b73a":"markdown","c3faa8aa":"markdown","507db14f":"markdown","046bad05":"markdown","9b578f4d":"markdown","d0a8f215":"markdown","9c1432ba":"markdown","2c791140":"markdown","0daf1342":"markdown","d5251cb1":"markdown","35d93eb4":"markdown","ddd9a842":"markdown","7dd8c2e8":"markdown"},"source":{"1fc4b342":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n\n#filter out warnings\nimport warnings \nwarnings.filterwarnings('ignore')\n\n#To style plots\nplt.style.use('fivethirtyeight')\n\n#cycle the colors\nfrom itertools import cycle\ncolor_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])","b0eb1cda":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","5192de4b":"train.head()","d91dbbbf":"train.shape","a9169d69":"plt.figure(figsize=(15,5))\nplt.plot(train.SalePrice,linewidth=1,color=next(color_cycle))\nplt.title('Distribution Plot for Sales Prices')\nplt.ylabel('Sales Price');","2f6c2861":"plt.figure(figsize=(15,5))\nplt.plot(train.SalePrice.sort_values().reset_index(drop=True),color=next(color_cycle))\nplt.title('Distribution Plot for Sales Prices')\nplt.ylabel('Sales Price');","3c5c1ed0":"sns.heatmap(train.isnull(),yticklabels=False, cmap='plasma');","f69cabed":"train.isnull().sum().sort_values(ascending=False)[0:19]","1661150f":"test.isnull().sum().sort_values(ascending=False)[0:33]","949955eb":"train.LotFrontage.head()","28430cbc":"train.LotFrontage.isnull().sum()","5f594791":"train['LotFrontage'] = train['LotFrontage'].fillna(train.LotFrontage.mean())","43adeb73":"test.LotFrontage.isnull().sum()","582f0334":"test['LotFrontage'] = test['LotFrontage'].fillna(test.LotFrontage.mean())","51d27daf":"train.Alley.value_counts(dropna=False)","6bd52b44":"train.drop(columns=['Alley'], inplace=True)","b38e8bb2":"test.Alley.value_counts(dropna=False)","e4c5aa4d":"test.drop(columns=['Alley'], inplace=True)","2a04f8a2":"train.BsmtCond.value_counts(dropna=False)","435b6bff":"train['BsmtCond'] = train['BsmtCond'].fillna(train.BsmtCond.mode()[0])","31651172":"test['BsmtCond'] = test['BsmtCond'].fillna(test.BsmtCond.mode()[0])","1f285d4a":"list1 = ['BsmtQual', 'FireplaceQu', 'GarageType', 'GarageCond', 'GarageFinish', 'GarageQual', 'MasVnrType', 'MasVnrArea',\n         'BsmtExposure','BsmtFinType2']\n\nfor item in list1:\n    train[item] = train[item].fillna(train[item].mode()[0])\n    test[item] = test[item].fillna(test[item].mode()[0])","34650607":"list1 = ['GarageYrBlt', 'PoolQC', 'Fence', 'MiscFeature']\n\nfor item in list1:\n    train.drop(columns=item, inplace=True)\n    test.drop(columns=item, inplace=True)","9060111b":"train.isnull().sum().sort_values(ascending=False)","f15b95ab":"train.dropna(inplace=True)","6ffc4eab":"train.drop(columns=['Id'], inplace=True)","45eae412":"train.shape","f4072ece":"test.isnull().sum().sort_values(ascending=False)[0:17]","4208a7db":"test['MSZoning']=test['MSZoning'].fillna(test['MSZoning'].mode()[0])","71e38a7d":"columns = ['BsmtFinType1', 'Utilities','BsmtFullBath', 'BsmtHalfBath', 'Functional', 'SaleType', 'Exterior2nd', \n           'Exterior1st', 'KitchenQual']\ncolumns1 = ['GarageCars', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',  'TotalBsmtSF', 'GarageArea']\n\nfor item in columns:\n    test[item] = test[item].fillna(test[item].mode()[0])\nfor item in columns1:\n    test[item] = test[item].fillna(test[item].mean())","8acc1388":"test.drop(columns=['Id'], inplace=True)","f3f19c4a":"test.shape","52fd16f3":"train.isnull().any().any()","948b61ec":"test.isnull().any().any()","e0a4505b":"fig = px.scatter(train,x=train.index, y='SalePrice', labels={'x':'Index'},\n                 color=train.MSZoning, template=\"seaborn\",\n                 title='Sale Price distriution ---> MSZoning')\nfig.show()","a5cfd39d":"fig = px.scatter(train,x=train.index, y='SalePrice', labels={'x':'Index'},\n                 color=train.Street, template=\"seaborn\",\n                 title='Sale Price distriution ---> Street')\nfig.show()","f41bf191":"train.LotConfig.unique()","9a562f6c":"plt.figure(figsize=(20,10))\n\nplt.subplot(2,2,1)\nplt.scatter(x=train[train.LotConfig == 'FR3'].index,\n           y=train[train.LotConfig == 'FR3'].SalePrice,color=next(color_cycle))\nplt.title('SalePrice distribution --> FR3 value of LotConfig')\n\nplt.subplot(2,2,2)\nplt.scatter(x=train[train.LotConfig == 'CulDSac'].index,\n           y=train[train.LotConfig == 'CulDSac'].SalePrice,color=next(color_cycle))\nplt.title('SalePrice distribution --> CulDSac value of LotConfig')\n\nplt.subplot(2,2,3)\nplt.scatter(x=train[train.LotConfig == 'Corner'].index,\n           y=train[train.LotConfig == 'Corner'].SalePrice,color=next(color_cycle))\nplt.title('SalePrice distribution --> Corner value of LotConfig')\n\nplt.subplot(2,2,4)\nplt.scatter(x=train[train.LotConfig == 'FR2'].index,\n           y=train[train.LotConfig == 'FR2'].SalePrice,color=next(color_cycle))\nplt.title('SalePrice distribution --> FR2 value of  LotConfig');","5a67f99d":"columns = ['MSZoning', 'Street',\n       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', \n       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n       'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n       'Heating', 'HeatingQC', 'CentralAir', 'Electrical',\n       'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish',\n       'GarageQual', 'GarageCond', 'PavedDrive', 'SaleType', 'SaleCondition']","d693e13d":"len(columns)","c7808122":"final_df = pd.concat([train, test], axis=0)","cd28e042":"final_df.shape","11471cf3":"#A function that encodes categorical features\ndef One_hot_encoding(columns):\n    df_final=final_df\n    i=0\n    for fields in columns:\n        df1=pd.get_dummies(final_df[fields],drop_first=True)\n        \n        final_df.drop([fields],axis=1,inplace=True)\n        if i==0:\n            df_final=df1.copy()\n        else:           \n            df_final=pd.concat([df_final,df1],axis=1)\n        i=i+1\n       \n        \n    df_final=pd.concat([final_df,df_final],axis=1)\n        \n    return df_final","88dac9f7":"final_df = One_hot_encoding(columns)","a2272b65":"final_df.shape","3002631b":"final_df =final_df.loc[:,~final_df.columns.duplicated()]","3e7e4f0e":"final_df.shape","3cb0c8bd":"df_Train=final_df.iloc[:1422,:]\ndf_Test=final_df.iloc[1422:,:]","78ae9bbb":"df_Test.drop(['SalePrice'],axis=1,inplace=True)","c62f91b4":"X_train_final=df_Train.drop(['SalePrice'],axis=1)\ny_train_final=df_Train['SalePrice']","6836f7fb":"from sklearn.preprocessing import StandardScaler\nX_std = StandardScaler().fit_transform(X_train_final)\n\nmy_columns = X_train_final.columns\nnew_df = pd.DataFrame(X_std, columns=my_columns)","1deed990":"from sklearn.decomposition import PCA\npca = PCA(n_components = 2)\ndf_pca = pca.fit_transform(new_df)","3a7f58d8":"plt.figure(figsize =(8, 6))\nplt.scatter(df_pca[:, 0], df_pca[:, 1], c = y_train_final, cmap ='plasma')\n# labeling x and y axes\nplt.xlabel('First Principal Component')\nplt.ylabel('Second Principal Component');","3c587793":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\n#splitting the dataset as training and testing dataset\nX_train, X_test, y_train, y_test = train_test_split(X_train_final, y_train_final)\n\n#building the model\nlinreg = LinearRegression()\nlinreg.fit(X_train, y_train)\n\n#Accuracy\nprint(\"R-Squared Value for Training Set: {:.3f}\".format(linreg.score(X_train, y_train)))\nprint(\"R-Squared Value for Test Set: {:.3f}\".format(linreg.score(X_test, y_test)))","972c48bd":"from sklearn.neighbors import KNeighborsRegressor\n\nknnreg = KNeighborsRegressor(n_neighbors = 2)\nknnreg.fit(X_train, y_train)\n\nprint('R-squared train score: {:.3f}'.format(knnreg.score(X_train, y_train)))\nprint('R-squared test score: {:.3f}'.format(knnreg.score(X_test, y_test)))","a3b001b7":"from sklearn.linear_model import Ridge\n\nridge = Ridge()\nridge.fit(X_train, y_train)\n\nprint('R-squared score (training): {:.3f}'.format(ridge.score(X_train, y_train)))\nprint('R-squared score (test): {:.3f}'.format(ridge.score(X_test, y_test)))","477aed91":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nridge = Ridge(alpha=20)\nridge.fit(X_train_scaled, y_train)\n\nprint('R-squared score (training): {:.3f}'.format(ridge.score(X_train_scaled, y_train)))\nprint('R-squared score (test): {:.3f}'.format(ridge.score(X_test_scaled, y_test)))","6fb80584":"from sklearn.linear_model import Lasso\n\nlasso = Lasso(max_iter = 10000)\nlasso.fit(X_train, y_train)\n\nprint('R-squared score (training): {:.3f}'.format(lasso.score(X_train, y_train)))\nprint('R-squared score (test): {:.3f}'.format(lasso.score(X_test, y_test)))","2af9c2d6":"lasso = Lasso(alpha=100, max_iter = 10000)\nlasso.fit(X_train_scaled, y_train)\n\nprint('R-squared score (training): {:.3f}'.format(lasso.score(X_train_scaled, y_train)))\nprint('R-squared score (test): {:.3f}'.format(lasso.score(X_test_scaled, y_test)))","89c5b9f6":"from sklearn.ensemble import RandomForestClassifier\n\nregressor = RandomForestClassifier()","c923d7ed":"from sklearn.model_selection import RandomizedSearchCV\n\nn_estimators = [100, 500, 900]\ncriterion = ['gini', 'entropy']\ndepth = [3,5,10,15]\nmin_split=[2,3,4]\nmin_leaf=[2,3,4]\nbootstrap = ['True', 'False']\nverbose = [5]\n\nhyperparameter_grid = {\n    'n_estimators': n_estimators,\n    'max_depth':depth,\n    'criterion':criterion,\n    'bootstrap':bootstrap,\n    'verbose':verbose,\n    'min_samples_split':min_split,\n    'min_samples_leaf':min_leaf\n    }\n\nrandom_cv = RandomizedSearchCV(estimator=regressor,\n                               param_distributions=hyperparameter_grid,\n                               cv=5, \n                               scoring = 'neg_mean_absolute_error',\n                               n_jobs = 4, \n                               return_train_score = True,\n                               random_state=42)","95a7a4f5":"random_cv.fit(X_train_final,y_train_final)","ddd97289":"random_cv.best_estimator_","889ac542":"regressor = RandomForestClassifier(bootstrap='False', class_weight=None,\n                       criterion='entropy', max_depth=10, max_features='auto',\n                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n                       min_impurity_split=None, min_samples_leaf=3,\n                       min_samples_split=3, min_weight_fraction_leaf=0.0,\n                       n_estimators=900, n_jobs=None, oob_score=False,\n                       random_state=None, verbose=5, warm_start=False)","68a8050b":"regressor.fit(X_train_final,y_train_final)","99717a93":"y_pred = regressor.predict(df_Test)","e1576c0f":"y_pred","fba8145e":"pred=pd.DataFrame(y_pred)\nsamp = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\nsub = pd.concat([samp['Id'],pred], axis=1)\nsub.columns=['Id','SalePrice']","6f60ef7c":"sub","84e264a1":"#sub.to_csv('My_sub.csv',index=False)","9079f0dc":"import xgboost","7f5bf19b":"regressor=xgboost.XGBRegressor()","476a7db0":"n_estimators = [100, 500, 900, 1100, 1500]\nmax_depth = [2, 3, 5, 10, 15]\nbooster=['gbtree','gblinear']\nlearning_rate=[0.05,0.1,0.15,0.20]\nmin_child_weight=[1,2,3,4]\nbase_score=[0.25,0.5,0.75,1]\n\n# Define the grid of hyperparameters to search\nhyperparameter_grid = {\n    'n_estimators': n_estimators,\n    'max_depth':max_depth,\n    'learning_rate':learning_rate,\n    'min_child_weight':min_child_weight,\n    'booster':booster,\n    'base_score':base_score\n    }\nrandom_cv = RandomizedSearchCV(estimator=regressor,\n            param_distributions=hyperparameter_grid,\n            cv=5, n_iter=50,\n            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n            verbose = 5, \n            return_train_score = True,\n            random_state=42)","a0a4a0da":"random_cv.fit(X_train_final,y_train_final)","9dff2da9":"random_cv.best_estimator_","1966623f":"regressor = xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n             importance_type='gain', interaction_constraints='',\n             learning_rate=0.1, max_delta_step=0, max_depth=2,\n             min_child_weight=1, missing=None, monotone_constraints='()',\n             n_estimators=900, n_jobs=0, num_parallel_tree=1,\n             objective='reg:squarederror', random_state=0, reg_alpha=0,\n             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n             validate_parameters=1, verbosity=None)","4a41149c":"regressor.fit(X_train_final,y_train_final)","e92265f7":"y_pred = regressor.predict(df_Test)","27fd721c":"y_pred","fdf59071":"pred=pd.DataFrame(y_pred)\nsamp = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\nsub = pd.concat([samp['Id'],pred], axis=1)\nsub.columns=['Id','SalePrice']","40e58918":"sub","b66dcec2":"#sub.to_csv('My_sub1.csv',index=False)","81cbc15b":"> **- Alley**\n\nI m gonna drop the hole column!","ac7fc44a":"One of the best way to visualize Null values is through Heatmap","232c7a3b":"## PCA(Principle component analysis)\n\nlet\u2019s visualize our final dataset by implementing PCA and plot the graph","ef11c7da":"# Feature Normalization\n\n`alpha` is a regularization parameter, you can try changing value from 1,5, 10 to 100. There is a huge impact of `alpha` on the model.","2cf03f8a":"# Handle Missing Values\n\n","63ba3dad":"**Awesome!, let's try normalizing the features**","e155496f":"# Lasso Regression","66af2b3f":"# Magic Weapon #2: Xgboost Classifier","2520507b":"# Ridge Regression","c7b8b93e":"**Now the dataset is ready, we are now ready to explore it.**","80e36b8a":"**Handle Remaining missing values**","b7bc7c99":"# Import dataset","ab786015":"**Filling the null values with mean calculated of the feature**","4cb7d747":"**Street doesn't seems like a good feature**. Still we haven't seen correlation","e5815123":">  **- LonFrontage**","d6495775":"# KNN Regression","2610e993":"## Feature Engineering by OneHotEncoding","f67fa608":"**Almost Similar to ridge, let's try on normalized data**","3c09b974":"**Let's seperate the data as it was!**","c9c79a4e":"# Include Libraries","64066c8a":"### Checking for missing values if any!","8d400e22":"**Let's Start modeling now!**","a80ea086":"Performing the same technique for all below mentioned columns.\n\n> **- BsmtCond, BsmtQual, FirePlaceQu, GarageType, GarageCond, GarageFinish, GarageQual**","87f525a0":"**- GarageYrBlt, PoolQC, Fence, MiscFeature**","2fe88486":"**The exact value number for null values can be seen by isnull() function.**","a3e6b73a":"# Linear Regression","c3faa8aa":"**It doen't perform well!**","507db14f":"<center><h1 style='color:red'>PLz upvote if you find it valuable!","046bad05":"Taking mode for all similar features like BsmtCond","9b578f4d":"`isnull().sum()` shows the number of missing values in the feature column.","d0a8f215":"# EDA","9c1432ba":"**Let's fix the data One by One looking into features**","2c791140":"# Magic Weapon #1: Hyperparameter Tunning","0daf1342":"### Note: Score() function in regression gives R2 value(R-Squared value) ","d5251cb1":"# - Contents:\n\n- **Import Libraries and Dataset**\n- **Handle Missing Value**\n- **Feature Engineering by OneHotEncoding**\n- **PCA to visualize the datatset**\n- **Linear Regression**\n- **KNN Regression**\n- **Ridge Regression**\n- **Feature Normalization**\n- **Lasso Regression**\n- **Hyperparameter Tunning**\n- **Random Forest Classifier**\n- **Xgboost Classifier**","35d93eb4":"# Random Forest Classifier","ddd9a842":"**let's try some other regression techniques.**","7dd8c2e8":"- **The above plot shows the distribution of sales price according to the index value.**\n- **Let's sort the values according to sales price and re-draw the plot.**"}}