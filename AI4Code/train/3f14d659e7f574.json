{"cell_type":{"e6330e7f":"code","6ea0e7ec":"code","f7a2f72f":"code","f3c159fb":"code","e17323de":"code","92a460b9":"code","04ec525f":"code","c1668dd1":"code","32420b91":"code","6f704aa9":"code","6191f217":"code","22e8fb07":"code","147d0356":"code","dd3c7a9c":"code","05ed08c9":"code","78cffcbe":"code","f3c21620":"code","83149a33":"code","7b8fdacb":"code","100699d3":"code","d25a5766":"code","8524cb7b":"code","3ef16d51":"code","c1c4b15d":"code","248e9b93":"code","da150eca":"code","7ddecc7c":"code","6aa3c1c0":"code","80db8f0b":"code","855f7330":"code","dd99778d":"code","9673958e":"markdown","c28c9f18":"markdown","1db1fb5c":"markdown","fb0183db":"markdown","967dd3c7":"markdown","ffecfc9c":"markdown","fc5ca05d":"markdown","825e5a97":"markdown","d6c8b828":"markdown","2bbc2a95":"markdown"},"source":{"e6330e7f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn')\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n        \nimport warnings\nwarnings.filterwarnings('ignore')        \n# Any results you write to the current directory are saved as output.","6ea0e7ec":"df = pd.read_csv('\/kaggle\/input\/california-housing-prices\/housing.csv')\ndf","f7a2f72f":"df.describe()","f3c159fb":"df.hist(bins=50, figsize=(20,15))","e17323de":"df['income_cat'] = np.ceil(df[\"median_income\"] \/ 1.5)\n#df['income_cat'].where(df[\"income_cat\"] < 5, 5.0, inplace=True)","92a460b9":"split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n\nfor train_index, test_index in split.split(df, df['income_cat']):\n    strat_train_set = df.loc[train_index]\n    strat_test_set = df.loc[test_index]\n    \nfor set_ in (strat_train_set, strat_test_set):\n    set_.drop('income_cat', axis=1, inplace=True)\n    ","04ec525f":"df_complete = strat_train_set.copy()\n\ndf = strat_train_set.drop(\"median_house_value\", axis=1) # drop labels for training set\nhousing_labels = strat_train_set[\"median_house_value\"].copy()","c1668dd1":"df_complete.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,s=df_complete[\"population\"]\/100, label=\"population\", figsize=(10,7),c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,sharex=False)","32420b91":"#from pandas.plotting import scatter_matrix\n\n#attributes = ['longitude','latitude','housing_median_age','total_rooms','total_bedrooms','population','households','median_income','median_house_value']\n#scatter_matrix(df[attributes])\n\nimport seaborn as sns\nsns.set(style=\"ticks\")\nsns.pairplot(df)","6f704aa9":"from sklearn.base import BaseEstimator, TransformerMixin\n\n# get the right column indices: safer than hard-coding indices 3, 4, 5, 6\nrooms_ix, bedrooms_ix, population_ix, household_ix = [list(df.columns).index(col) for col in (\"total_rooms\", \"total_bedrooms\", \"population\", \"households\")]","6191f217":"\nfrom sklearn.preprocessing import FunctionTransformer\n\ndef add_extra_features(X, add_bedrooms_per_room=True):\n    rooms_per_household = X[:, rooms_ix] \/ X[:, household_ix]\n    population_per_household = X[:, population_ix] \/ X[:, household_ix]\n    if add_bedrooms_per_room:\n        bedrooms_per_room = X[:, bedrooms_ix] \/ X[:, rooms_ix]\n        return np.c_[X, rooms_per_household, population_per_household,\n                     bedrooms_per_room]\n    else:\n        return np.c_[X, rooms_per_household, population_per_household]","22e8fb07":"def apply_log1p(X):\n     attr = [household_ix,population_ix,bedrooms_ix,rooms_ix,8,9,10]\n     for idx in attr:\n        X[:,idx] = np.log1p(X[:,idx])\n     return X\n","147d0356":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n\nnum_pipeline = Pipeline([\n        ('imputer', SimpleImputer(strategy=\"median\")),\n        ('attribs_adder', FunctionTransformer(add_extra_features, validate=False)),\n        ('apply_log', FunctionTransformer(apply_log1p, validate=False)),\n        ('std_scaler', StandardScaler()),\n    ])\n\ndf_num = df.drop('ocean_proximity', axis=1)\ndf_num_tr = num_pipeline.fit_transform(df_num)","dd3c7a9c":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\n\nnum_attribs = list(df_num)\ncat_attribs = [\"ocean_proximity\"]\n\nfull_pipeline = ColumnTransformer([\n    (\"num\", num_pipeline, num_attribs),\n    (\"cat\", OneHotEncoder(), cat_attribs),\n])\n\nhousing_prepared = full_pipeline.fit_transform(df)\nhousing_prepared_df = pd.DataFrame(housing_prepared)\n\n\ncols = [col for col in df.columns[0:8]]\n\n# new columns\ncols.extend(['rooms_per_household','population_per_household','bedrooms_per_room', 'nearby_lt_1H_OCEAN','nearby_INLAND','nearby_ISLAND', 'nearby_NEARBAY', 'nearby0 n1NEAR_OCEAN'])\nhousing_prepared_df.columns = cols\n\nhousing_prepared_df.hist(bins=50, figsize=(20,15))","05ed08c9":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(housing_prepared, housing_labels)","78cffcbe":"from sklearn.tree import DecisionTreeRegressor\n\ntree_reg = DecisionTreeRegressor(random_state=42)\ntree_reg.fit(housing_prepared, housing_labels)","f3c21620":"from sklearn.ensemble import RandomForestRegressor\n\nforest_reg = RandomForestRegressor()\nforest_reg.fit(housing_prepared, housing_labels)","83149a33":"from sklearn.model_selection import cross_val_score\n\ndef display_scores(scores):\n    print('Scores:',scores)\n    print('Mean:',scores.mean())\n    print('Standard deviation:',scores.std())\n","7b8fdacb":"scores = cross_val_score(tree_reg, housing_prepared, housing_labels,scoring='r2', cv=10)\ntree_r2_scores = scores\ndisplay_scores(tree_r2_scores)","100699d3":"scores = cross_val_score(lin_reg, housing_prepared, housing_labels,scoring='r2', cv=10)\nlin_r2_scores = scores\ndisplay_scores(lin_r2_scores)","d25a5766":"scores = cross_val_score(forest_reg, housing_prepared, housing_labels,scoring='r2', cv=10)\nforest_r2_scores = scores\ndisplay_scores(forest_r2_scores)","8524cb7b":"X_test = strat_test_set.drop(\"median_house_value\", axis=1)\ny_test = strat_test_set[\"median_house_value\"].copy()\n\nX_test_prepared = full_pipeline.transform(X_test)\n\ntesting_params_scores = []\nfor x in range(2,20):\n    dt_reg = DecisionTreeRegressor(max_depth=x)\n    reg_tree = dt_reg.fit(housing_prepared, housing_labels)\n    score = reg_tree.score(X_test_prepared, y_test)\n    testing_params_scores.append((x, score))\n\n\ndf_scores = pd.DataFrame(testing_params_scores)\ndf_scores.columns = ['depth', 'score']\ndf_scores.sort_values(by='score', ascending=False)","3ef16d51":"df_scores.plot.line(x='depth', y='score', c='DarkBlue')","c1c4b15d":"from sklearn.metrics import r2_score\n\nX_test = strat_test_set.drop(\"median_house_value\", axis=1)\ny_test = strat_test_set[\"median_house_value\"].copy()\n\nX_test_prepared = full_pipeline.transform(X_test)\nfinal_predictions = lin_reg.predict(X_test_prepared)\n\nlin_final_r2 = r2_score(y_test, final_predictions)\nlin_final_r2","248e9b93":"from sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import randint\n\nparam_distribs = {\n        'max_depth': randint(low=2, high=50),\n    }\n\nrnd_search = RandomizedSearchCV(tree_reg, param_distributions=param_distribs,\n                                n_iter=10, cv=5, scoring='r2', random_state=42)\nrnd_search.fit(housing_prepared, housing_labels)\nbest_tree = rnd_search.best_estimator_","da150eca":"final_model = rnd_search.best_estimator_\n\nX_test = strat_test_set.drop(\"median_house_value\", axis=1)\ny_test = strat_test_set[\"median_house_value\"].copy()\n\nX_test_prepared = full_pipeline.transform(X_test)\nfinal_predictions = final_model.predict(X_test_prepared)\n\ntree_final_r2 = r2_score(y_test, final_predictions)\ntree_final_r2","7ddecc7c":"param_distribs = {\n        'n_estimators': randint(low=1, high=200),\n        'max_features': randint(low=1, high=8),\n    }\n\nrnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n                                n_iter=10, cv=5, scoring='r2', random_state=42)\nrnd_search.fit(housing_prepared, housing_labels)\n\nrnd_search.best_estimator_","6aa3c1c0":"final_model = rnd_search.best_estimator_\n\nX_test = strat_test_set.drop(\"median_house_value\", axis=1)\ny_test = strat_test_set[\"median_house_value\"].copy()\n\nX_test_prepared = full_pipeline.transform(X_test)\nfinal_predictions = final_model.predict(X_test_prepared)\n\nforest_final_r2 = r2_score(y_test, final_predictions)\nforest_final_r2","80db8f0b":"d = {'model':['linear_regression','regression_tree','random_forest'], 'r2_test':[lin_final_r2,tree_final_r2,forest_final_r2]}\ndf_res = pd.DataFrame(data=d)\ndf_res.sort_values(by='r2_test',ascending=False)","855f7330":"from sklearn.tree import export_graphviz\n\nfeature_names = cols\nlabel_name = ['median_house_value']\n    \nexport_graphviz(best_tree, out_file='tree.dot', rounded = True, proportion = True, precision = 2, filled = True, feature_names = feature_names, class_names = label_name)\n\nfrom subprocess import call\ncall(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n\n# # Display in jupyter notebook\nfrom IPython.display import Image\nImage(filename = 'tree.png')","dd99778d":"from sklearn.tree import _tree\n\ndef tree_to_code(tree, feature_names):\n    tree_ = tree.tree_\n    feature_name = [\n        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n        for i in tree_.feature\n    ]\n    \n    def recurse(node, depth):\n        indent = \"  \" * depth\n        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n            name = feature_name[node]\n            threshold = tree_.threshold[node]\n            print(\"{}se {} <= {}:\".format(indent, name, threshold))\n            recurse(tree_.children_left[node], depth + 1)\n            print(\"{}senao:  # se {} > {}\".format(indent, name, threshold))\n            recurse(tree_.children_right[node], depth + 1)\n        else:\n            print(\"{} valor {}\".format(indent, tree_.value[node]))\n\n    recurse(0, 1)\n    \ntree_to_code(best_tree, feature_names)","9673958e":"### Visualizando Histogramas","c28c9f18":"### Modelagem","1db1fb5c":"### An\u00e1lise descritiva","fb0183db":"### Leitura do dataframe","967dd3c7":"### Testando diferentes configura\u00e7\u00f5es - com Grid Search","ffecfc9c":"### Valida\u00e7\u00e3o - R\u00b2 do set de Treino","fc5ca05d":"### Explora\u00e7\u00e3o dos Dados de Treino","825e5a97":"### Criando sets de test e treino\n\nCriando set de test estratificado para garantir que a proporcao de renda m\u00e9dia seja bem representada no mesmo","d6c8b828":"### Conclus\u00e3o","2bbc2a95":"### Preparando os dados - Pipeline"}}