{"cell_type":{"7c4e44ef":"code","61c94cec":"code","439e7efd":"code","bdfb5eb7":"code","85745a34":"code","b2270290":"code","61532f89":"code","23f119b1":"code","cac94168":"code","67fe0a14":"code","a6eaa375":"code","69cd4d0b":"code","9d2bdd02":"code","354bc782":"code","91a77e2e":"code","0b9beb69":"code","4e5ddff8":"code","b92c7fac":"markdown","fb9eee3f":"markdown","13463f80":"markdown","d70dc702":"markdown","a3b6d3d1":"markdown","e14b199b":"markdown","2865907f":"markdown","0a6e698d":"markdown","082e71bc":"markdown","8f315be6":"markdown","f951ca53":"markdown","57594316":"markdown","43e3eb80":"markdown","a9305d57":"markdown","ab3c3e67":"markdown","dec6e2d9":"markdown"},"source":{"7c4e44ef":"TRAIN_PATH = \"..\/input\/digit-recognizer\/train.csv\"\nTEST_PATH = \"..\/input\/digit-recognizer\/test.csv\"\nSAMPLE_SUBMISSION_PATH = \"..\/input\/digit-recognizer\/sample_submission.csv\"\nSUBMISSION_PATH = \"submission.csv\"\n\nID = \"ImageId\"\nTARGET = \"label\"\nSUBMIT_TARGET = \"Label\"\n\nSCALE_SIZE = 255\nTEST_SIZE = 0.2","61c94cec":"import numpy as np\nimport pandas as pd \n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split","439e7efd":"train = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)","bdfb5eb7":"X = train.drop([TARGET],axis = 1)\ny = train[TARGET]\nX_test = test ","85745a34":"X = X\/SCALE_SIZE\nX_test = X_test\/SCALE_SIZE\n\nX = X.values.reshape(-1, 28, 28, 1)\nX_test = X_test.values.reshape(-1, 28, 28, 1)","b2270290":"X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=TEST_SIZE)","61532f89":"INPUT_SHAPE = (28,28,1)\nOUTPUT_SIZE = 10\n\nKERNEL_SIZE = (3,3)\nPOOL_SIZE = (2,2)\nMID_ACTIVATION = \"relu\"\nLAST_ACTIVATION = \"softmax\"\n\nDROPOUT_ARR = [0.25,0.25,0.25,0.25,0.25,0.5]\nDENSE_ARR= [128,256]\n\nMODEL_OPTIMIZER = 'adam'\nMODEL_LOSS = 'categorical_crossentropy'\nMODEL_METRICS = ['accuracy']\n\nBATCH_SIZE = 64\nEPOCHS = 15\nVERBOSE = 1\n\nROTATION_RANGE = 12\nWIDTH_SHIFT_RANGE = 0.12\nHEIGHT_SHIFT_RANGE = 0.12\nSHEAR_RANGE = 0.12\nVALIDATION_SPLIT = 0.2\nTARGET_COUNT = 10","23f119b1":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import LearningRateScheduler\n\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","cac94168":"model = Sequential()\nmodel.add(Conv2D(filters=16, kernel_size=KERNEL_SIZE, activation=MID_ACTIVATION, input_shape=INPUT_SHAPE))\nmodel.add(Dropout(DROPOUT_ARR[0]))\nmodel.add(Conv2D(filters=32, kernel_size=KERNEL_SIZE, activation=MID_ACTIVATION))\nmodel.add(Dropout(DROPOUT_ARR[1]))\nmodel.add(Conv2D(filters=32, kernel_size=KERNEL_SIZE, activation=MID_ACTIVATION))\nmodel.add(MaxPooling2D(pool_size=POOL_SIZE))\nmodel.add(Dropout(DROPOUT_ARR[2]))\nmodel.add(Conv2D(filters=64, kernel_size=KERNEL_SIZE, activation=MID_ACTIVATION))\nmodel.add(MaxPooling2D(pool_size=POOL_SIZE))\nmodel.add(Dropout(DROPOUT_ARR[3]))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(DENSE_ARR[0], activation=MID_ACTIVATION))\nmodel.add(Dropout(DROPOUT_ARR[4]))\nmodel.add(Dense(DENSE_ARR[1], activation=MID_ACTIVATION))\nmodel.add(Dropout(DROPOUT_ARR[5]))\nmodel.add(Dense(OUTPUT_SIZE, activation=LAST_ACTIVATION))\n\nmodel.summary()","67fe0a14":"model.compile(optimizer=MODEL_OPTIMIZER, loss=MODEL_LOSS, metrics=MODEL_METRICS)","a6eaa375":"imageDataGenerator = ImageDataGenerator(\n            rotation_range=ROTATION_RANGE,\n            width_shift_range=WIDTH_SHIFT_RANGE,\n            height_shift_range=HEIGHT_SHIFT_RANGE,\n            shear_range=SHEAR_RANGE,\n            validation_split=VALIDATION_SPLIT,)\n\nimageDataGenerator.fit(X_train)\nimageDataGenerator.fit(X_val)\n\ny_train = tf.keras.utils.to_categorical(y_train, num_classes=TARGET_COUNT)\ny_val = tf.keras.utils.to_categorical(y_val, num_classes=TARGET_COUNT)","69cd4d0b":"imageData = imageDataGenerator.flow(X_train, y_train, batch_size = BATCH_SIZE)","9d2bdd02":"history = model.fit_generator(imageData, \n                              epochs = EPOCHS, \n                              validation_data = (X_val, y_val), \n                              verbose=VERBOSE, \n                              steps_per_epoch=X_train.shape[0] \/\/ BATCH_SIZE,                              \n                             )","354bc782":"EVAL_TRAIN_LOSS = \"loss\"\nEVAL_VALIDATION_LOSS = \"val_loss\"\nEVAL_TRAIN_LABEL = \"train loss\"\nEVAL_VALIDATION_LABEL = \"validation loss\"\n\nEVAL_TITLE = \"Model Loss\"\nEVAL_XLABEL = \"EPOCHS\"\nEVAL_YLABEL = \"LOSS\"","91a77e2e":"plt.plot(history.history[EVAL_TRAIN_LOSS], label=EVAL_TRAIN_LABEL)\nplt.plot(history.history[EVAL_VALIDATION_LOSS], label=EVAL_VALIDATION_LABEL)\nplt.title(EVAL_TITLE)\nplt.xlabel(EVAL_XLABEL)\nplt.ylabel(EVAL_YLABEL)\nplt.legend();","0b9beb69":"pred = np.argmax(model.predict(X_test), axis=1)\npred[:5]","4e5ddff8":"sub = pd.read_csv(SAMPLE_SUBMISSION_PATH)\nsub[SUBMIT_TARGET] = pred[:len(sub)]\nsub.to_csv(SUBMISSION_PATH,index=False)\nsub.head()","b92c7fac":"## data variables","fb9eee3f":"## scaling","13463f80":"## load data ","d70dc702":"## model libraries","a3b6d3d1":"# 3.evaluate model","e14b199b":"# 4.predict test data target and submit","2865907f":"## model variables","0a6e698d":"## predict test data target","082e71bc":"## submit result csv ","8f315be6":"## split data (train set \/ validation set)","f951ca53":"# 1.load & preprocess data","57594316":"# 2.train model","43e3eb80":"## define model","a9305d57":"## split data (train(input,target) \/ test)","ab3c3e67":"## make model ","dec6e2d9":"# data libraries"}}