{"cell_type":{"f59bf4dd":"code","0c826f88":"code","e118e034":"code","7774617a":"code","40e0d18c":"code","8aa86a78":"code","8fe0b1d5":"code","4d299f44":"code","e3eb680c":"code","fd786491":"code","3373e64f":"code","7bb2e2ba":"code","f55389e9":"code","9369daad":"code","402ef1b8":"code","f841d78d":"code","f1c71cda":"code","1be8e509":"code","11233f11":"code","1f238dcb":"code","e2c92441":"code","cb995e81":"code","86340aab":"code","f2358fea":"code","e2392bf8":"markdown","6f8fa846":"markdown","177d42dd":"markdown","dbf7e226":"markdown","06927949":"markdown","5d22ddb4":"markdown","353495fe":"markdown","7b0423cc":"markdown","28fdbcbf":"markdown","ad4f3dd2":"markdown","ac6143cd":"markdown","53af305b":"markdown","68fa11c5":"markdown","d8547c7e":"markdown","7c9041d9":"markdown","c5a72ac8":"markdown","257cf318":"markdown","e34d1759":"markdown","6ba1452b":"markdown","297ec102":"markdown","84a43e26":"markdown","d736463f":"markdown","dc2c828f":"markdown","45efcd50":"markdown"},"source":{"f59bf4dd":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nos.listdir(\"..\/input\/severstal-steel-defect-detection\")\n","0c826f88":"from matplotlib import pyplot as plt\nfrom itertools import cycle, islice\nfrom tqdm import tqdm, tqdm_notebook\nimport seaborn as sns; sns.set_style(\"white\")\nimport random\nimport cv2\nfrom PIL import Image","e118e034":"train_data = pd.read_csv(\"..\/input\/severstal-steel-defect-detection\/train.csv\")\ntrain_data.head()","7774617a":"train_data['EncodedPixels'].fillna(-1, inplace=True)\ntrain_data['ClassId'] = train_data['ImageId_ClassId'].apply(lambda x: int(x[-1:]))\ntrain_data['ImageName'] = train_data['ImageId_ClassId'].apply(lambda x: x[:-6] +  '.jpg' )\ntrain_data['Defect'] =np.where(train_data['EncodedPixels']==-1, 0, 1) \ntrain_data['ClassId'] =np.where(train_data['EncodedPixels']==-1,  0,train_data['ClassId']) \ntrain_data.head()","40e0d18c":"colors = list(islice(cycle(['b', 'r', 'g', 'y', 'k']), None, len(train_data)))\nDF_Defect = train_data[train_data['EncodedPixels']!=-1]\nax = DF_Defect['ClassId'].value_counts().plot(kind='bar',\n                                    figsize=(14,8),color=colors)\nax.set_xlabel(\"Class\")\nax.set_ylabel(\"Frequency\")\nplt.xticks(rotation=360)\nplt.show()","8aa86a78":"train_data.groupby(['ImageName'])['Defect'].sum().hist()","8fe0b1d5":"path_img_train = \"..\/input\/severstal-steel-defect-detection\/train_images\/\"\npath_img_test = \"..\/input\/severstal-steel-defect-detection\/test_images\/\"","4d299f44":"#This function show a gride of images, and their histogram \n\ndef show_images_with_Histograms(images, cols = 2, titles = None):\n   \n    n_images = len(images)\n    nrows = int(n_images\/cols)\n    fig, ax = plt.subplots(nrows, 2*  cols )\n    \n    assert((titles is None)or (len(images) == len(titles)))\n    \n    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n    \n    row = 0\n    col = 0 \n    for n, (image, title) in enumerate(zip(images, titles)):\n        \n        if image.ndim == 2:\n            plt.gray()\n        ax[row,col].imshow(image)\n        ax[row,col].set_title(title,fontsize=42)\n        \n        col +=1 \n        if col == 2 * cols : \n            col =0\n            row +=1\n        \n        img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        \n        ax[row,col].hist(img_gray.ravel(),30,[0,256])\n       \n        col +=1 \n        if col == 2 * cols : \n            col =0\n            row +=1\n            \n    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images   )\n    fig.subplots_adjust(hspace = 0.8)\n    #plt.show()","e3eb680c":"SEED = 87\nimgs = []\ntitles = []\nplt.rcParams.update({'font.size': 36})\nfor i in range(10):\n    #plt.figure(figsize=(5,5))\n    random.seed(SEED + i)\n    id = random.choice(os.listdir(path_img_train))\n    id_code = id.split(\".\")[0]\n    imgs.append(np.asarray(Image.open(os.path.join(path_img_train, id))))\n    \n    titles.append(\"Image:\"+str(id))\nshow_images_with_Histograms(imgs, cols = 1,titles = titles)\n    #imgplot = plt.imshow(imgs[i])\n    #plt.show()","fd786491":"SEED = 34\nimgs = []\ntitles = []\n \nfor i in range(10):\n    #plt.figure(figsize=(5,5))\n    random.seed(SEED + i)\n    id = random.choice(os.listdir(path_img_test))\n    id_code = id.split(\".\")[0]\n    imgs.append(np.asarray(Image.open(os.path.join(path_img_test, id))))\n    \n    titles.append(\"Image:\"+str(id))\nshow_images_with_Histograms(imgs, cols = 1,titles = titles)\n    #imgplot = plt.imshow(imgs[i])\n    #plt.show()","3373e64f":"SEED = 12\nimgs = []\ntitles = []\nDF_Defect_only = train_data[train_data['Defect']!= 0]\n\nfor i in range(10):\n    \n    \n    DF = DF_Defect_only.sample(n = 1, replace = False , random_state = SEED + i) \n    id = DF['ImageName'].values[0]\n    label = DF['ClassId'].values[0]\n    imgs.append(np.asarray(Image.open(os.path.join(path_img_train, id))))\n    \n    titles.append(\"Image:\"+str(id)+\" Class is:\"+str(label))\nshow_images_with_Histograms(imgs, cols = 1,titles = titles)\n    #imgplot = plt.imshow(imgs[i])\n    #plt.show()","7bb2e2ba":"#Calculate the Active area of the image \n\ndef Calc_Active_Area(img):\n    Thrshold = 10 \n    ImageSize = img.shape[0] * img.shape[1]\n    Black_size = np.count_nonzero(img < Thrshold )\n   \n    \n    active_area = ((ImageSize - Black_size)\/ImageSize)*100\n    \n    \n    return int(active_area)","f55389e9":"SEED = 12\nimgs = []\ntitles = []\nDF_Defect_only = train_data[train_data['Defect']!= 0]\nplt.rcParams.update({'font.size': 45})\nfor i in range(10):\n    \n    \n    DF = DF_Defect_only.sample(n = 1, replace = False , random_state = SEED + i) \n    id = DF['ImageName'].values[0]\n    label = DF['ClassId'].values[0]\n    Active_area = Calc_Active_Area(np.asarray(Image.open(os.path.join(path_img_train, id)).convert('L')))\n    imgs.append(np.asarray(Image.open(os.path.join(path_img_train, id))))\n    \n    titles.append(\"Image:\"+str(id)+\"  Active Area  is:\"+str(Active_area)+'%')\nshow_images_with_Histograms(imgs, cols = 1,titles = titles)\n    #imgplot","9369daad":"#Calculate the Saturated area of the image \n\ndef Calc_Saturate_Area(img):\n    Thrshold = 240 \n    ImageSize = img.shape[0] * img.shape[1]\n    saturate_area = np.count_nonzero(img > Thrshold )\n   \n    \n    saturate_area = ((saturate_area)\/ImageSize)*100\n    \n    \n    return int(saturate_area)","402ef1b8":"SEED = 44\nimgs = []\ntitles = []\nDF_Defect_only = train_data[train_data['Defect']!= 0]\nplt.rcParams.update({'font.size': 42})\nfor i in range(10):\n    \n    \n    DF = train_data.sample(n = 1, replace = False , random_state = SEED + i) \n    id = DF['ImageName'].values[0]\n   \n    Saturate_Area = Calc_Saturate_Area(np.asarray(Image.open(os.path.join(path_img_train, id)).convert('L')))\n    imgs.append(np.asarray(Image.open(os.path.join(path_img_train, id))))\n    \n    titles.append(\"Image:\"+str(id)+\" Saturated Area  is:\"+str(Saturate_Area)+'%')\nshow_images_with_Histograms(imgs, cols = 1,titles = titles)","f841d78d":"def Calculate_Active_area_from_file_name(FileName):\n    img = np.asarray(Image.open(os.path.join(path_img_train, FileName)).convert('L'))\n    result = Calc_Active_Area(img)\n    return result \n\n\ndef Calculate_Saturated_area_from_file_name(FileName):\n    img = np.asarray(Image.open(os.path.join(path_img_train, FileName)).convert('L'))\n    result = Calc_Saturate_Area(img)\n    return result ","f1c71cda":"DF = train_data.drop_duplicates(subset='ImageName')\nDF['ActiveArea'] = DF['ImageName'].apply(lambda x:Calculate_Active_area_from_file_name(x))\n\n\nDF['SaturatedArea'] = DF['ImageName'].apply(lambda x:Calculate_Saturated_area_from_file_name(x))\nDF.head()","1be8e509":"DF['ActiveArea'].hist()","11233f11":"DF['SaturatedArea'].hist()","1f238dcb":"DF.head(100)","e2c92441":"def rle2mask(mask_rle, shape=(1600,256)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T","cb995e81":"mask = (rle2mask(DF['EncodedPixels'][20]))\nprint(mask.shape)\n\nid = DF['ImageName'].values[5]\nimg = np.asarray(Image.open(os.path.join(path_img_train, id)))","86340aab":"plt.figure(figsize = (20,20)) \nplt.rcParams.update({'font.size': 15})\nplt.imshow(mask)\n\n","f2358fea":"plt.figure(figsize = (20,20)) \nplt.imshow(img)","e2392bf8":"## Clean Tarin.csv\nThe Train.csv need some cleanup :\n1. We need to replace the NaN values in EncodePixels Column\n2. We need to correct the files names - instead of xxxxxxid.jpg_y ---> xxxxxxid.jpg\n3. We need to add a column of classid ","6f8fa846":"## Sample Mask","177d42dd":"While browsing randomly on images from both train and test set, there are few obvious conclusion \n1. A lot of the pictures have a large black area \n2. There is a portion of images with saturation or overexposed area \n\n\nSince these images are more don't contain colors, in all of the explorations I am using gray photos, it is easier to analyze\nSo one traditional way to explore images is pixes histogram ","dbf7e226":"## Data Exploratory ","06927949":"## Import Libraries ","5d22ddb4":"## Number of Images Per Class","353495fe":"## Masks ","7b0423cc":"In the last stage - I will add two columns to the train data frames to include \n\nthe Active area percentage and the saturated area percentage ","28fdbcbf":"## Load Train.csv","ad4f3dd2":"Let's see  some images with defects.  ","ac6143cd":"## Calculate Saturated area \nThis function calculates the percentage o pixels which are overexposed or saturated","53af305b":"Let's explore some examples. ","68fa11c5":"Thanks to \nhttps:\/\/www.kaggle.com\/paulorzp\/rle-functions-run-lenght-encode-decode","d8547c7e":" Now Let's see Random test images","7c9041d9":"Pixel Values close to zero are Blacks, While high values pixels (256) are usually overexposed or saturated.\nIn both cases, extremes values mean that there are no details in the image","c5a72ac8":"## Number of Classes per Image","257cf318":"Another problem is saturation - large areas which areas   overexposed ","e34d1759":"## Images with Histogram ","6ba1452b":"## Calculate the Active area\nCalculate the Active area of the image\n\nCalculate the percentage of the area that the non-black areas  occupy  from the entire image area","297ec102":"![image.png](attachment:image.png)\nThis image is taken from OpenCv Python Tutorial  \nhttps:\/\/opencv-python-tutroals.readthedocs.io\/en\/latest\/py_tutorials\/py_imgproc\/py_histograms\/py_histogram_begins\/py_histogram_begins.html","84a43e26":"This data is only for the images themselves without the mask.\n\nWhat we can do with this data ?\n\nMaybe take it into account when we build our K folds (make sure there is a balance)\n\nDownsample (usually towards the last epochs or at the end of the training) and try use images which have high active area and not saturated  ","d736463f":"This Notebook Provide basic EDA Kernel for the Severstal: Steel Defect Detection\nThe kernel analyzes images in some vision traditional ways\n\nDo upvote if you liked my kernel :)\n","dc2c828f":"First let's see Random  train images ","45efcd50":"Let's see train images "}}