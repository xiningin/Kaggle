{"cell_type":{"29dc51db":"code","38d3e5aa":"code","3681b41b":"code","f2cce28b":"code","80e05787":"code","6cf132e4":"code","d3a6928f":"code","1b69776e":"code","ad61ac25":"code","29ebe827":"code","5fd2fe97":"code","be14edd3":"code","0fde7d83":"code","e13b59e3":"code","03d7d8f6":"code","cd5d3e0a":"markdown","29b785c2":"markdown","32ca5c95":"markdown","d487096d":"markdown","02a5037b":"markdown","d587d7c7":"markdown","34775de2":"markdown","055e4ab5":"markdown","7f9b5c11":"markdown","5da5fe48":"markdown"},"source":{"29dc51db":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","38d3e5aa":"import pandas as pd\nimport sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split","3681b41b":"df= pd.read_csv('..\/input\/titanic\/train.csv')\ndf","f2cce28b":"df.describe()\n","80e05787":"df.columns","6cf132e4":"drop_column = ['Name', 'Ticket', 'Cabin']\ndf.drop(drop_column, axis= 1, inplace= True)\n","d3a6928f":"df.isnull().sum()\n","1b69776e":"df['Age']= df['Age'].fillna(df['Age'].median())\n","ad61ac25":"df[df['Embarked'].isnull()]\n","29ebe827":"df.drop([61, 829],axis= 0, inplace= True)","5fd2fe97":"embark = pd.get_dummies(df['Embarked'],prefix='Embarked')\nsex = pd.get_dummies(df['Sex'],prefix='Sex')\ndf_new= pd.concat([embark, sex],axis=1)\ndf_new.head()\n","be14edd3":"df= pd.concat([df, df_new], axis=1)\ndf.drop(['Sex', 'Embarked'], axis=1, inplace= True)\ndf['Age'].astype('int')\ndf['Fare'].astype('int')\n","0fde7d83":"X= df.drop('Survived', axis=1)\ny= df['Survived']\n","e13b59e3":"X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.33)\n","03d7d8f6":"from sklearn.preprocessing import StandardScaler\nscaler= StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","cd5d3e0a":"# We will drop the 61th and the 829th index rows directly\n","29b785c2":"# ONE HOT ENCODING\nWe have two categorical varible columns - Embarked and Sex columns. We will convert these columns using\none hot encoding\n","32ca5c95":"# Now we will combine the new one-hot-encoded columns and drop the original categorical columns\n","d487096d":"# SCALING THE DATA","02a5037b":"#  Here Name, Cabin and Ticket columns can't help in analysis of survival, so we will drop them","d587d7c7":"# Also 2 null values of Embarked can be ignored and dropped easily\n","34775de2":"# CHECKING NULL VALUES\n","055e4ab5":"# Train Test Split\n","7f9b5c11":"# **Basic EDA**","5da5fe48":"# Now Age has 177 null values which is obviously a high number and cant be ignored. Hence we will replace this with median of all Ages in dataset."}}