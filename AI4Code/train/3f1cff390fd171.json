{"cell_type":{"1812523c":"code","7a6b7e6c":"code","65b52629":"code","9c303912":"code","a9b67eb2":"code","b4e55011":"code","bffa30fa":"code","bceb6ebd":"code","18cb23b7":"code","63ca6d8d":"code","15b4d8f3":"code","34b405a9":"code","aee57e19":"code","40de2c43":"code","8c616170":"code","1115c9c1":"code","00247522":"code","eb86ee0f":"code","248d8935":"code","1b4e4840":"code","996d3112":"code","31ed08d8":"code","7c93b5dd":"code","a048ad94":"code","3cbd8580":"code","0d15b899":"code","22794332":"code","550a4ced":"code","86dfbc17":"code","e06f0288":"code","9471651e":"code","1cfc2505":"code","de5ad749":"code","95249d9f":"code","0cda8ba8":"code","1cb7a779":"code","782b7005":"code","bd959c80":"code","f8824559":"code","f31633c5":"code","2ce5581a":"code","017a573d":"code","d6754ccd":"code","6aca5f89":"code","92187d48":"code","a0e62205":"code","96f23409":"code","217d45b5":"code","41cad688":"code","33477c4d":"code","fbfa7286":"code","f1b49451":"code","2d683fbe":"code","7c019e03":"code","64f7d657":"code","635b1596":"code","48c7d63a":"code","50b1de54":"code","fe1b84b2":"code","c782b0ff":"code","5164c233":"code","6e0baf52":"code","b074c6ac":"code","8cf60810":"code","7aea7961":"code","3cfba791":"code","ec8c9739":"code","5efac4b5":"code","62e413cf":"code","78b9f5e5":"code","7bf68515":"code","ef788b68":"code","fa1059a4":"code","d6b76439":"code","5b9d4677":"code","2bfa4c31":"code","8fa14c81":"markdown","81d8be85":"markdown","1118b6c7":"markdown","5814d8e0":"markdown","93d3e2d5":"markdown","e886ff71":"markdown","73255334":"markdown","53b816d6":"markdown","9e38e0a4":"markdown","891ca145":"markdown","d813cd1b":"markdown","5dace2b7":"markdown","65bb70c6":"markdown","fd99f670":"markdown","c484da15":"markdown","7c9a4019":"markdown","c3a6d498":"markdown","2d4578e1":"markdown","28e8ffad":"markdown","f7a9bca8":"markdown","d08a11ce":"markdown","b5a3a36e":"markdown","2e057f7e":"markdown","ae8db78f":"markdown","6457ce8f":"markdown","5e6a9770":"markdown","2b437b30":"markdown"},"source":{"1812523c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","7a6b7e6c":"#read dataset\ndf_read = pd.read_csv('..\/input\/mental-heath-in-tech-2016_20161114.csv')\nprint(df_read.shape)\nprint(df_read.columns)","65b52629":"print(df_read['Do you currently have a mental health disorder?'].unique())\nprint(df_read['Do you currently have a mental health disorder?'].isna().sum())","9c303912":"#check on null\ndf = df_read.copy()\nprint(df_read.dtypes.value_counts()) #how many of each data types are there\n# print(df_read.dtypes[df_read.dtypes!=object])\nfor eachcol in df_read.columns:\n    missing = (df_read[eachcol].isnull()).sum()\/df_read.shape[0]*100 #percent of null values there are in each col\n    if missing > 60:\n        print(eachcol, missing) #print out those that have over 60% of missing values\n        df = df.drop(eachcol, axis = 1)\n    if eachcol == 'Have you been diagnosed with a mental health condition by a medical professional?':\n        print(eachcol, missing)#make sure that the above question has enough data\n        print(df_read[eachcol].value_counts()) #how many yeses and nos\n        #half yes and half no\nprint('dropped', df_read.shape[1] - df.shape[1], 'columns')","a9b67eb2":"df_selfemploy = df[df['Are you self-employed?'] == 1]\ndf = df[df['Are you self-employed?'] == 0].reset_index().drop('index', axis = 1).drop('Are you self-employed?', axis = 1)\nprint(df.shape)\nprint(df.index)","b4e55011":"print(min(df['What is your age?']), max(df['What is your age?']))\nprint((df['What is your age?']<=21).sum()) #there are 28  answers that are under 21\nplt.hist(df['What is your age?'])\nplt.show()\n\ndf = df[(df['What is your age?']>=21) & (df['What is your age?'] < 100)]\ndf = df.reset_index().drop('index', axis = 1)","bffa30fa":"#find if number of people having\/not having mental health conditions is even if split dataframe into inside US and outside of US\nus_counts = df.loc[df['What country do you live in?'] == 'United States of America', 'Have you been diagnosed with a mental health condition by a medical professional?'].value_counts()\nother_counts = df.loc[df['What country do you live in?'] != 'United States of America', 'Have you been diagnosed with a mental health condition by a medical professional?'].value_counts()\nprint('us counts:\\n', us_counts, '\\nother country counts:\\n', other_counts)\nprint('us yes %:', us_counts['Yes']\/us_counts.sum()*100, 'other yes %:', other_counts['Yes']\/other_counts.sum()*100)","bceb6ebd":"liveus_count = len(df[df['What country do you live in?']=='United States of America'])\nliveother_count = len(df[df['What country do you live in?']!='United States of America'])\nworkus_count = len(df[df['What country do you work in?']=='United States of America'])\nworkother_count = len(df[df['What country do you work in?']!='United States of America'])\nprint('number of people live in the US vs not: ', liveus_count, ':', liveother_count)\nprint('number of people work in the US vs not: ', workus_count, ':', workother_count)\n","18cb23b7":"#find data distributions of countries\ncountries = df['What country do you live in?'].value_counts() #count number of responses in each country\nstates = df['What US state or territory do you live in?'].value_counts() #count number of responses in each state\nprint(countries) #US has the most responses\nus_percent = countries['United States of America']\/countries.sum() #percentage of US responses (most)\nuk_percent = countries['United Kingdom']\/countries.sum() #percentage of UK responses (2nd most)\nprint('people in us:', us_percent, '\\npeople in uk:', uk_percent) #58.62% from US and 12.56% from UK","63ca6d8d":"plt.hist(df['What country do you live in?'],\n         bins = len(df['What country do you live in?'].unique())-1)\nplt.xticks(rotation = 90)\nplt.xlabel('Country')\nplt.ylabel('Counts')\nplt.title('Counts by Country')\nplt.show()","15b4d8f3":"#visualize different countries\nother_country = countries[countries<5].sum()\nplt.hist(df.loc[df['What country do you live in?'] != 'United States of America', 'What country do you live in?'], \n         bins = len(df['What country do you live in?'].unique())-1)\nplt.xticks(rotation = 90)\nplt.xlabel('Country')\nplt.ylabel('Counts')\nplt.title('Counts by Country')\nplt.show()","34b405a9":"#visualize different states\nlive_states = df.loc[df['What US state or territory do you live in?'].notna(), 'What US state or territory do you live in?']\n# print(live_states)\nplt.hist(live_states, bins = len(live_states.unique())-1)\nplt.xticks(rotation = 90)\nplt.xlabel('States in US')\nplt.ylabel('Counts')\nplt.title('Counts by States')\nplt.show()\nprint(live_states.value_counts())","aee57e19":"#function to switch states to regions\n##input: series of states in US\n##output: list of regions of the states\n##region information from https:\/\/en.wikipedia.org\/wiki\/List_of_regions_of_the_United_States#Interstate_regions\ndef state_to_region(states):\n    northeast = ['Connecticut', 'Maine', 'Massachusetts', 'New Hampshire', 'Rhode Island', 'Vermont', 'New Jersey', 'New York', 'Pennsylvania']\n    midwest = ['Illinois', 'Indiana', 'Michigan', 'Ohio', 'Wisconsin', 'Iowa', 'Kansas', 'Minnesota', 'Missouri', 'Nebraska', 'North Dakota', 'South Dakota']\n    west = ['Arizona', 'Colorado', 'Idaho', 'Montana', 'Nevada', 'New Mexico', 'Utah', 'Wyoming', 'Alaska', 'California', 'Hawaii', 'Oregon', 'Washington']\n    region = list()\n    for eachstate in states:\n        if type(eachstate) == float:\n            region.append(eachstate)\n        elif eachstate in northeast:\n            region.append('northeast')\n        elif eachstate in midwest:\n            region.append('midwest')\n        elif eachstate in west:\n            region.append('west')\n        else:\n            region.append('south')\n    return region","40de2c43":"#plot the counts of region\nlive_region = state_to_region(df['What US state or territory do you live in?'])\nwork_region = state_to_region(df['What US state or territory do you work in?'])\n\nplt.hist(live_region)\nplt.xlabel('live region')\nplt.ylabel('counts')\nplt.title('Counts by Living Region')\nplt.show()\n\nplt.hist(work_region)\nplt.xlabel('work region')\nplt.ylabel('counts')\nplt.title('Counts by Working Region')\nplt.show()\n\nprint(df.shape[0], len(live_region), len(work_region))","8c616170":"#substitute states for region\ndf_states = pd.DataFrame({'What US state or territory do you work in?':work_region, \n                          'What US state or territory do you live in?':live_region})\ndf_states_dummy = pd.get_dummies(df_states, \n                                 prefix = ['What US state or territory do you work in?', \n                                           'What US state or territory do you live in?']) #dropped nan dummy by not creating it \n\n#substitute US & other for countries\ndf_country = df[['What country do you work in?', 'What country do you live in?']].copy()\ndf_country.loc[df_country['What country do you work in?'] != 'United States of America', 'What country do you work in?'] = 'other'\ndf_country.loc[df_country['What country do you live in?']!= 'United States of America', 'What country do you live in?'] = 'other'\ndf_country_dummy = pd.get_dummies(df_country, \n                                  prefix = ['What country do you work in?', 'What country do you live in?'], \n                                  drop_first = True) #does not have nan, so drop a class","1115c9c1":"#get labels for states\ndf_state_label = df_states.copy()\nfor eachcol in df_state_label.columns:\n    df_state_label[eachcol] = df_state_label[eachcol].astype('category')\n    df_state_label[eachcol] = df_state_label[eachcol].cat.codes #NA is -1\n\n#get labels for country\ndf_country_label = df_country.copy()\nfor eachcol in df_country_label.columns:\n    df_country_label[eachcol] = df_country_label[eachcol].astype('category')\n    df_country_label[eachcol] = df_country_label[eachcol].cat.codes","00247522":"#check for columns that have a lot of unique values\nlot_unique = list() #store column names that have a lot of unique values\nfor each in df.columns:\n    len_uni = len(df[each].unique())\n    if len_uni > 5:\n        print(each, len_uni, df[each].dtype) \n        lot_unique.append(each)","eb86ee0f":"#drop the why questions\nprint(df.shape)\ndf = df.drop('Why or why not?', axis = 1).drop('Why or why not?.1', axis = 1)\nprint(df.shape)","248d8935":"#get names of columns that are not cleaned separately\ntext_int_col = ['If so, what condition(s) were you diagnosed with?', \n                'What is your gender?', \n                'Which of the following best describes your work position?', \n                'What is your age?', \n                'What country do you work in?', \n                'What country do you live in?', \n                'What US state or territory do you work in?', \n                'What US state or territory do you live in?'] #columns that cannot use get_dummies\nother_cat = list()\nfor each in df.columns.values:\n    if each not in text_int_col:\n        other_cat.append(each)\nother_cat_na = df[other_cat].isna().sum()\nnon_zero = other_cat_na[other_cat_na>0]\nnon_zero_col = non_zero.index\nprint(non_zero_col)\nprint(df.shape[1], len(other_cat))","1b4e4840":"#set nan to i dont know\nfor question in non_zero_col:\n    if question.find('What US state or territory') == -1: #avoid state questions because I'll split dataframe into 2 later\n        if question == 'Do you know the options for mental health care available under your employer-provided coverage?':\n            df.loc[df[question].isna(), question] = 'I am not sure'\n        elif question == 'Were you aware of the options for mental health care provided by your previous employers?':\n            df.loc[df[question].isna(), question] = 'N\/A (not currently aware)'\n        elif question == 'Have you observed or experienced an unsupportive or badly handled response to a mental health issue in your current or previous workplace?':\n            df.loc[df[question].isna(), question] = 'Maybe\/Not sure'\n        else:\n            df.loc[df[question].isna(), question] = \"I don't know\"\ncheck_na = df.isna().sum()\nprint(check_na[check_na>0]) #print the ones still have NAN values, should be why and state questions","996d3112":"#get dummies for question 1\ndf_dummy_list = list()\nfor each in other_cat:\n    if each == 'Do you currently have a mental health disorder?': #use labels for response variable\n        y_labels = df['Do you currently have a mental health disorder?'].astype('category').cat.codes\n    else: #for features \n        current = df[each]\n        current_dummy = pd.get_dummies(current, prefix = each, drop_first = True)\n        df_dummy_list.append(current_dummy)\ndf_other_dummies = pd.concat(df_dummy_list, axis = 1)\ndf_other_dummies['Do you currently have a mental health disorder?'] = y_labels\nprint(df_other_dummies.shape, df.shape)\n# print(df_other_dummies.columns)\n\nother_dummy_na = df_other_dummies.isna().sum()\nprint(other_dummy_na[other_dummy_na>0])","31ed08d8":"print('mapping for question 1: \\n', dict(enumerate(df['Do you currently have a mental health disorder?'].astype('category').cat.categories)))","7c93b5dd":"df_other_dummies","a048ad94":"#get labels for these columns\ndf_other_label = df.copy()[other_cat]\nfor eachcol in other_cat:\n    df_other_label[eachcol] = df_other_label[eachcol].astype('category').cat.codes","3cbd8580":"#get dummies for question 2\ndf_dummy_list2 = list()\nfor each in other_cat:\n    if each == 'Have you ever sought treatment for a mental health issue from a mental health professional?': #use labels for response variable\n        y_labels2 = df['Have you ever sought treatment for a mental health issue from a mental health professional?'].astype('category').cat.codes\n    else: #for features \n        current = df[each]\n        current_dummy = pd.get_dummies(current, prefix = each, drop_first = True)\n        df_dummy_list2.append(current_dummy)\ndf_other_dummies2 = pd.concat(df_dummy_list2, axis = 1)\ndf_other_dummies2['Have you ever sought treatment for a mental health issue from a mental health professional?'] = y_labels2\nprint(df_other_dummies2.shape, df.shape)\nprint('mapping for y2: \\n', dict(enumerate(df['Have you ever sought treatment for a mental health issue from a mental health professional?'].astype('category').cat.categories)))","0d15b899":"df_other_dummies2['Have you ever sought treatment for a mental health issue from a mental health professional?'] ","22794332":"import nltk\nimport re","550a4ced":"#gathering strings from diagnosis\n# df_diag = df.loc[df['If so, what condition(s) were you diagnosed with?'].notna(), 'If so, what condition(s) were you diagnosed with?']\ndf_diag = df['If so, what condition(s) were you diagnosed with?']\nprint(df_diag.shape, df_diag.index)\ndiagnoses = list()\nfor each in df_diag:\n    if type(each) != float:\n        each_str = each.lower()\n        if each_str.find('|') > -1:\n            split_each = each_str.split('|')\n            for eachsplit in split_each:\n                diagnoses.append(eachsplit)\n        else: \n            diagnoses.append(each_str)\n    else: diagnoses.append('999')\n        \ndiag_counts = pd.Series(diagnoses).value_counts()\nprint(diag_counts)","86dfbc17":"diag_counts.unique()","e06f0288":"#create list of key words and get counts for visualization\n#anxiety disorder: PTSD, OCD\n#autism: asperger\n#substance use: addiction\n#unitypoint.org\/livewell\/article.aspx?id=3705d64a-a233-4448-ab37-f9cc95ea784b\n#https:\/\/www.webmd.com\/brain\/autism\/mental-health-aspergers-syndrome\n#https:\/\/en.wikipedia.org\/wiki\/Substance_use_disorder\ndiagnose_list = ['mood disorder', 'anxiety disorder', 'autism spectrum disorder', \n                 'attention deficit disorder', 'personality disorder', 'eating disorder', \n                 'substance use disorder', 'psychotic disorder', 'dissociative disorder', 'other diagnose']\ndiag_dict = dict()\nfor each in diagnose_list:\n    diag_dict[each] = [0]\n    \n# print('answers categorized as other: \\n')\nfor each in diagnoses:\n#     current_row = [0] * 6 #store dummy values in order of mood, anxiety, attention, substance, personality, other\n    indicator = True\n    if each == '999':\n        continue\n    if each.find('depression') > -1:\n        diag_dict['mood disorder'][0] += 1\n#         current_row[0] = 1\n        indicator = False\n    if each.find('stress') > -1 or each.find('obsessive') > -1 or each.find('anxiety') > -1:\n        diag_dict['anxiety disorder'][0] += 1\n#         current_row[1] = 1\n        indicator = False\n    if each.find('autism') > -1 or each.find('asperger') > -1:\n        diag_dict['autism spectrum disorder'][0] += 1\n#         current_row[5] = 1\n        indicator = False\n    if each.find('attention') > -1:\n        diag_dict['attention deficit disorder'][0] += 1\n#         current_row[2] = 1\n        indicator = False\n    if each.find('personality') > -1:\n        diag_dict['personality disorder'][0] += 1\n#         current_row[4] = 1\n        indicator = False\n    if each.find('eating') > -1:\n        diag_dict['eating disorder'][0] += 1\n#         current_row[5] = 1\n        indicator = False\n    if each.find('addict') > -1 or each.find('substance') > -1:\n        diag_dict['substance use disorder'][0] += 1\n#         current_row[3] = 1\n        indicator = False\n    if each.find('schizo') > -1:\n        diag_dict['psychotic disorder'][0] += 1\n#         current_row[5] = 1\n        indicator = False\n    if each.find('dissociative') > -1:\n        diag_dict['dissociative disorder'][0] += 1\n#         current_row[5] = 1\n        indicator = False\n    if indicator:\n#         print(each)\n        diag_dict['other diagnose'][0] += 1\n#         current_row[5] = 1\n#     row_values.append(current_row)","9471651e":"#pie chart\ndf_diag = pd.DataFrame(diag_dict)\nfig, ax = plt.subplots(figsize = (10, 10))\nwedges, texts, autotext  = ax.pie(df_diag, \n                                  labels = df_diag.columns, \n                                  autopct = '%.2f%%')\nax.legend(wedges, \n          df_diag.columns, \n          title = 'Diagnosis', \n          loc = 'best', \n          bbox_to_anchor = [0, 1])\nax.set_title('Pie Chart of Diagnosed Conditions')\nplt.show()\n\n#top ones\ndf_diagsort = df_diag.sort_values(by = 0, axis = 1, ascending = False)\ndf_top5 = df_diagsort.loc[:, df_diagsort.columns.values[:5]]\ndf_top5['other diagnose'] = df_diagsort.iloc[:, 5:].sum(axis = 1)\n\nfig, ax = plt.subplots(figsize = (10, 10))\nwedges, texts, autotext  = ax.pie(df_top5, \n                                  labels = df_top5.columns, \n                                  autopct = '%.2f%%')\nax.legend(wedges, \n          df_top5.columns, \n          title = 'Diagnosis', \n          loc = 'best', \n          bbox_to_anchor = [0, 1])\nax.set_title('Pie Chart of Diagnosed Conditions')\nplt.show()\n","1cfc2505":"# get dummy variables\ndf_diagnosis = df['If so, what condition(s) were you diagnosed with?']\nunique_diag = df_top5.columns.values\nrow_values = list()\n\nfor eachdiag in df_diagnosis:\n    current_row = [0] * 6 #store dummy values in order of mood, anxiety, attention, substance, personality, other\n    if type(eachdiag) != float:\n        eachlower = eachdiag.lower() #lower cases to match key words\n#         indicator = True\n        split = eachlower.split('|') #split the string\n        for each in split: #for each value in the cell\n            if each.find('depression') > -1: \n#                 print(each)\n                current_row[0] = 1\n#                 indicator = False\n            elif each.find('stress') > -1 or each.find('obsessive') > -1 or each.find('anxiety') > -1:\n                current_row[1] = 1\n#                 indicator = False\n            elif each.find('attention') > -1:\n                current_row[2] = 1\n#                 indicator = False\n            elif each.find('personality') > -1:\n                current_row[4] = 1\n#                 indicator = False\n            elif each.find('addict') > -1 or each.find('substance') > -1:\n                current_row[3] = 1\n#                 indicator = False\n            else: #if none of the above is found then it's the other category\n                current_row[5] = 1\n        row_values.append(current_row) #append the coded row\n    else: #when row is nan\n        row_values.append(current_row) #append all zeros\n\ndf_diag_dummy = pd.DataFrame(row_values, \n                             columns = ['mood disorder', 'anxiety disorder', \n                                        'attention deficit disorder', 'substance use disorder', 'personality disorder', 'other diagnose']) #implement one hot encoding by converting all the encoding to dataframe\n# df_diag_dummy['original'] = df_diagnosis\ndiag_col = df_diag_dummy.columns.values #get all the column names for pos dummy dataframe\ndf_diag_dummy[diag_col] = df_diag_dummy[diag_col].astype('category') #change all the columns to category\ndf_diag_dummy","de5ad749":"# #get labels for diagnoses\n# df_diag_label = list()\n# for eachdiag in df_diagnosis:\n#     if type(each) != float:\n#         df_diag_label.append(eachdiag)\n#     else:\n#         eachlower = eachdiag.lower() #lower cases to match key words\n#         split = eachlower.split('|') #split the string\n#         for each in split: #for each value in the cell\n#             if each.find('depression') > -1: \n#                 df_diag_label.append('mood disorder')\n#             elif each.find('stress') > -1 or each.find('obsessive') > -1 or each.find('anxiety') > -1:\n#                 df_diag_label.append('anxiety disorder')\n#             elif each.find('attention') > -1:\n#                 df_diag_label.append('attention deficit disorder')\n#             elif each.find('personality') > -1:\n#                 df_diag_label.append('personality disorder')\n#             elif each.find('addict') > -1 or each.find('substance') > -1:\n#                 df_diag_label.append('substance use disorder')\n#             else: #if none of the above is found then it's the other category\n#                 df_diag_label.append('other diagnose')\n# # df_diag_label = pd.DataFrame({'If so, what condition(s) were you diagnosed with?':df_diag_label})\n# # df_diag_label = df_diag_label['If so, what condition(s) were you diagnosed with?'].astype('category').cat.codes\n# df_diag_label","95249d9f":"# df_gender = df.loc[df['What is your gender?'].notna(), 'What is your gender?']\ndf_gender = df['What is your gender?']\ngender = list()\nfor each in df_gender:\n    if type(each) != float:\n        g_low = each.lower()\n        g_low = re.sub(' ', '', g_low)\n        gender.append(g_low)\n    else: \n        gender.append('999')\nprint(pd.Series(gender).unique())\nprint(len(df_gender), len(gender))","0cda8ba8":"#create gender list\n#non-binary = queer\n#https:\/\/en.wikipedia.org\/wiki\/Non-binary_gender\n#https:\/\/theydiffer.com\/difference-between-gender-fluid-and-bi-gender\/\ngender_labeled = list()\n# temp = list()\nfor each in gender:\n    if each == '999':\n        gender_labeled.append(float('nan'))\n    elif each.find('bi') > -1 or each.find('male9:1female,roughly') > -1:\n        gender_labeled.append(0)\n    elif each.find('non') > -1 or each.find('queer') > -1:\n        gender_labeled.append(1)\n    elif each.find('trans') > -1:\n        gender_labeled.append(2)\n    elif each.find('fluid') > -1:\n        gender_labeled.append(3)\n    elif each.find('female') > -1 or each.find('woman') > -1 or (len(each) == 1 and each.find('f') > -1):\n        gender_labeled.append(4)\n#         temp.append(each)\n    elif each.find('male') > -1 or (len(each) == 3 and each.find('man') > -1) or each.find('dude') > -1 or each.find('dude') > -1 or (len(each) == 1 and each.find('m') > -1):\n        gender_labeled.append(5)\n#         temp.append(each)\n    else:\n        gender_labeled.append(6)\nprint(pd.Series(gender_labeled).value_counts(), len(gender_labeled), df_gender.shape[0])\n# print('values in male category: \\n', pd.Series(temp).value_counts())","1cb7a779":"#put all categories other than male (5) and female (4) to others (6)\nfor each in range(len(gender_labeled)):\n    current = gender_labeled[each]\n    if current != 5 and current != 4:\n        gender_labeled[each] = 6\nprint(pd.Series(gender_labeled).value_counts())\nprint('labeled length: ', len(gender_labeled), '\\noriginal column length: ', df_gender.shape[0])\n# df_gender_dummy = pd.DataFrame(gender_labeled, columns = 'gender')\n# print(df_gender_dummy)\ndf_gender_dummy = pd.get_dummies(gender_labeled, prefix = 'gender')\nprint(df_gender_dummy)\ndf_gender_dummy = df_gender_dummy.rename(columns = {'gender_4':'gender_female', 'gender_5':'gender_male'}).drop('gender_6', axis = 1) #leave others out for dummy variables\nprint(df_gender_dummy)","782b7005":"#get labels for gender\ndf_gender_label = pd.DataFrame({'What is your gender?':gender_labeled})","bd959c80":"df_pos = df['Which of the following best describes your work position?'] #extract column\nprint('number of na values: ', df_pos.isnull().sum()) #number of nan values in the column\ndf_pos = df_pos.reset_index().drop('index', axis = 1)\n\n#get a list of unique positions\nmulti_pos = [] #store positions\nnrow = df_pos.shape[0]\nfor eachpos in range(nrow):\n    current = df_pos.loc[eachpos, 'Which of the following best describes your work position?']\n    low_pos = current.lower()\n    parsed = low_pos.split('|')\n    multi_pos += parsed\nunique_pos = list(pd.Series(multi_pos).unique())\n\n#transit column to dummy variables\npos_dummy = list() #store dummy values for each row\nfor eachpos in range(nrow):\n    current = df_pos.loc[eachpos, 'Which of the following best describes your work position?']\n    low_pos = current.lower()\n    parsed = low_pos.split('|')\n#     print(parsed)\n    temp_pos = [0] * len(unique_pos)\n    for eachparse in parsed:\n        pos_index = unique_pos.index(eachparse)\n        temp_pos[pos_index] = 1\n    pos_dummy.append(temp_pos)\n    if len(parsed) != sum(temp_pos): #sum of 1s for the row should be the same as length of parsed list, but if not the same\n        print(eachpos) #print the row number for debugging\n\n#make the dummy df\ndf_pos_dummy = pd.DataFrame(pos_dummy, columns = unique_pos).drop('hr', axis = 1)\ndf_pos_dummy.rename(columns = {'other':'other position'}, inplace = True)\n# df_pos_dummy['original'] = df_pos\npos_col = df_pos_dummy.columns.values #get all the column names for pos dummy dataframe\ndf_pos_dummy[pos_col] = df_pos_dummy[pos_col].astype('category') #change all the columns to category\nprint(df_pos_dummy)","f8824559":"# df_dummy = df.copy()\nprint(df_other_dummies.shape, df_diag_dummy.shape, df_gender_dummy.shape, df_pos_dummy.shape)\ndf_dummy = pd.concat([df_other_dummies, df_diag_dummy, df_gender_dummy, df_pos_dummy], axis = 1)\ndf_dummy['age'] = df['What is your age?']\ndf_dummy['What country do you work in?'] = df['What country do you work in?']\ndf_dummy['What country do you live in?'] = df['What country do you live in?']\ndf_dummy['What US state or territory do you work in?'] = df['What US state or territory do you work in?']\ndf_dummy['What US state or territory do you live in?'] = df['What US state or territory do you live in?']\nprint(df_dummy.shape)\n# df_dummy['gender'] = gender_labeled\n# df_dummy['gender'] = df_dummy['gender'].astype('category')\n# df_dummy = df_dummy.drop('Which of the following best describes your work position?', axis = 1).drop('What is your gender?', axis = 1).drop('If so, what condition(s) were you diagnosed with?', axis = 1)\nprint(df.shape)","f31633c5":"dummy_na = df_dummy.isna().sum() #find number of NAN values of each column\nnon_zero = dummy_na[dummy_na>0] #get those columns that have non-zero NAN values\nnon_zero_col = list()\nfor each in range(len(non_zero)):\n    col_name = non_zero.index[each] #get the question\/column name\n    if col_name.find('why') == -1: #exclude the why or why not questions\n        non_zero_col.append(col_name) #store the column names\n        print(non_zero.index[each]) #print column name\n        print(df_dummy[col_name].unique()) #print its unique values\n        print(df_dummy[col_name].isna().sum()) #print how many NAN values there are","2ce5581a":"#split\nus_dummy = df_dummy[df_dummy['What country do you live in?'] == 'United States of America']\nus_dummy = us_dummy.drop('What country do you live in?', axis = 1).drop('What country do you work in?', axis = 1)\nnot_us_dummy = df_dummy[df_dummy['What country do you live in?'] != 'United States of America']\nnot_us_dummy = not_us_dummy.drop('What US state or territory do you live in?', axis = 1).drop('What US state or territory do you work in?', axis = 1)\nprint(us_dummy.shape, not_us_dummy.shape)","017a573d":"#double check NAN after splitting\nnan_us = us_dummy.isna().sum()\nnan_not_us = not_us_dummy.isna().sum()\nprint(nan_us[nan_us>0])\nprint(nan_not_us[nan_not_us>0])\n\n#substitute NAN with most frequenct value\nprint(us_dummy['What US state or territory do you work in?'].value_counts())\nus_dummy.loc[us_dummy['What US state or territory do you work in?'].isna(), 'What US state or territory do you work in?'] = 'California'\nnan_us = us_dummy.isna().sum()\nprint(nan_us[nan_us>0])","d6754ccd":"work_states_dummy = pd.get_dummies(us_dummy['What US state or territory do you work in?'], prefix = 'What US state or territory do you work in?')\nlive_states_dummy = pd.get_dummies(us_dummy['What US state or territory do you live in?'], prefix = 'What US state or territory do you live in?')\nwork_country_dummy = pd.get_dummies(not_us_dummy['What country do you work in?'], prefix = 'What country do you work in?')\nlive_country_dummy = pd.get_dummies(not_us_dummy['What country do you live in?'], prefix = 'What country do you live in?')\nprint(work_states_dummy.shape, live_states_dummy.shape, work_country_dummy.shape, live_country_dummy.shape)\nus_dummy = pd.concat([us_dummy, work_states_dummy, live_states_dummy], axis = 1)\nus_dummy = us_dummy.drop('What US state or territory do you work in?', axis = 1).drop('What US state or territory do you live in?', axis = 1)\nnot_us_dummy = pd.concat([not_us_dummy, work_country_dummy, live_country_dummy], axis = 1)\nnot_us_dummy = not_us_dummy.drop('What country do you work in?', axis = 1).drop('What country do you live in?', axis = 1)\nprint(us_dummy.shape, not_us_dummy.shape)","6aca5f89":"us_dummy","92187d48":"#question 1\nprint(df.shape, df_states_dummy.shape, df_country_dummy.shape, df_other_dummies.shape, df_diag_dummy.shape, df_gender_dummy.shape, df_pos_dummy.shape)\ndf_main_dummy = pd.concat([df_states_dummy, df_country_dummy, df_other_dummies, df_diag_dummy, df_gender_dummy, df_pos_dummy], axis = 1)\ndf_main_dummy['age'] = df['What is your age?']\ndf_main_dummy.shape","a0e62205":"#check on nan before exporting\nmain_dummy_na = df_main_dummy.isna().sum()\nprint(main_dummy_na[main_dummy_na>0].index)\nprint(df_main_dummy.loc[df_main_dummy['How many employees does your company or organization have?_100-500'].isna(), \n                        'How many employees does your company or organization have?_100-500'])","96f23409":"#question 2\nprint(df.shape, df_states_dummy.shape, df_country_dummy.shape, df_other_dummies2.shape, df_diag_dummy.shape, df_gender_dummy.shape, df_pos_dummy.shape)\ndf_main_dummy2 = pd.concat([df_states_dummy, df_country_dummy, df_other_dummies2, df_diag_dummy, df_gender_dummy, df_pos_dummy], axis = 1)\ndf_main_dummy2['age'] = df['What is your age?']\ndf_main_dummy2.shape","217d45b5":"print(df.shape, df_state_label.shape, df_country_label.shape, df_other_label.shape, df_diag_dummy.shape, df_gender_label.shape, df_pos_dummy.shape)\ndf_main_label = pd.concat([df_state_label, df_country_label, df_other_label, df_diag_dummy, df_gender_label, df_pos_dummy], axis = 1)\ndf_main_label['age'] = df['What is your age?']\ndf_main_label.shape","41cad688":"us_dummy.to_csv('US_dummy.csv')\nnot_us_dummy.to_csv('non-US_dummy.csv')\ndf_main_dummy.to_csv('main_dummy.csv') #dataframe for question 1\ndf_main_dummy2.to_csv('main_dummy2.csv') #dataframe for question 2\ndf_main_label.to_csv('main_label.csv') #all features labeled except diagnosis, position and age","33477c4d":"us_dummy.shape","fbfa7286":"not_us_dummy.shape","f1b49451":"#check for numerical columns for US df\nus_type = us.dtypes\nfor each in range(len(us_type)):  \n    if us_type[each] == 'float' or us_type[each] == 'int': #check what variables should remain numberical\n        print(us_type.index[each], us_type[each]) #only age is numerical\ncat_cols = us.columns[us.columns!='What is your age?'] #get all the column names other than age\nus[cat_cols] = us[cat_cols].astype('category') #change all the other columns to categorical\nprint(us.dtypes[us.dtypes!='category']) #check if every column other than age is categorical\n\n# #apply labels to categorical columns\n# for eachcat in cat_cols:\n#     us[eachcat] = us[eachcat].cat.codes\n#     us[eachcat] = us[eachcat].astype('category')\n#     if eachcat == 'Do you work remotely?':\n#         break","2d683fbe":"us[cat_cols]","7c019e03":"from sklearn import preprocessing","64f7d657":"# #add labels\n# le = preprocessing.LabelEncoder()\n# mapping = dict()\n# for eachcat in cat_cols:\n#     le.fit(us[eachcat]) #create labels for current column\n#     current_mapping = dict(zip(le.transform(le.classes_), le.classes_)) #map labels to original encoding\n#     mapping[eachcat] = current_mapping #store mapping of current column\n#     us[eachcat] = le.transform(us[eachcat]) #apply labels for column\n#     us[eachcat]\n#     if eachcat == 'Do you work remotely?':\n#         break\n# le.fit(us['How many employees does your company or organization have?'])\n# print(le.classes_)\n# print(le.transform(le.classes_))\n# temp = dict(zip(le.transform(le.classes_), le.classes_))\n# print(temp)\n# print(a)","635b1596":"#check for numerical columns for non-US df\nnotus_type = not_us.dtypes\nfor each in range(len(notus_type)):  \n    if notus_type[each] == 'float' or notus_type[each] == 'int': #check what variables should remain numberical\n        print('numerical columns:')\n        print(notus_type.index[each], notus_type[each]) #only age is numerical\ncat_cols = not_us.columns[not_us.columns!='What is your age?'] #get all the column names other than age\nnot_us[cat_cols] = not_us[cat_cols].astype('category') #change all the other columns to categorical\nprint(not_us.dtypes[not_us.dtypes!='category']) #check if every column other than age is categorical","48c7d63a":"print(us.shape, not_us.shape)","50b1de54":"us.columns.values","fe1b84b2":"# test = us[['Do you have a family history of mental illness?', 'Have you had a mental health disorder in the past?']]\ntest = us['Do you have a family history of mental illness?']\nprint(test)\nprint(test.unique())\ntest_dummies = pd.get_dummies(test, prefix = 'Do you have a family history of mental illness?')\nprint(test_dummies)","c782b0ff":"#try logistic regression\nfrom sklearn.linear_model import LogisticRegression\nus_cols = us.columns.values\nx = us['Do you currently have a mental health disorder?']\ny = us[us_cols[us_cols != 'Do you currently have a mental health disorder?']]\nlr = LogisticRegression(random_state = 0).fit(x, y)\nlr.score(x, y)","5164c233":"us.loc[us['What US state or territory do you work in?'].isna(), 'What US state or territory do you live in?']\ndf_temp = us[['What US state or territory do you work in?', 'What US state or territory do you live in?']]\n\ndf_temp['What US state or territory do you work in?'] = df_temp['What US state or territory do you work in?'].astype('category')\ntemp_work_code = df_temp['What US state or territory do you work in?'].cat.codes\ndf_temp['What US state or territory do you work in?'] = temp_work_code\n# df_temp['What US state or territory do you work in?'] = df_temp['What US state or territory do you work in?'].astype('category')\n\n\ndf_temp['What US state or territory do you live in?'] = df_temp['What US state or territory do you live in?'].astype('category')\ntemp_live_code = df_temp['What US state or territory do you live in?'].cat.codes\ndf_temp['What US state or territory do you live in?'] = temp_work_code\n# df_temp['What US state or territory do you live in?'] = df_temp['What US state or territory do you live in?'].astype('category')","6e0baf52":"# from sklearn.linear_model import LinearRegression as lr\n# temp_x = df_temp['What US state or territory do you live in?'].reshape(-1, 1)\n# temp_y = df_temp['What US state or territory do you work in?'].reshape(-1, 1)\n# reg = lr().fit(temp_x, temp_y)\n# reg.score(temp_x, temp_y)\ndf_temp.corr()\nus.loc[us['What US state or territory do you live in?']=='Washington', 'What US state or territory do you work in?']","b074c6ac":"self_na = df_selfemploy.isna().sum()\nprint(df_selfemploy.shape)\nprint(self_na[self_na == df_selfemploy.shape[0]])","8cf60810":"answers = []\ndf_why = df.loc[df['Why or why not?'].notna(), 'Why or why not?']\nprint(df_why.unique())\nfor each in df_why:\n    each_lower = each.lower()\n    answers += each_lower.split()\n\nans_counts = pd.Series(answers).value_counts()\nprint(len(ans_counts))\nprint(ans_counts[ans_counts > 100])","7aea7961":"#parse diagnosis\ntest = df.copy()\nnrow = list(df.index)\ndiagnoses = list()\ncounts = dict()\nvalues = list()\ncannotsplit = []\nfor eachrow in nrow:\n    currentvalue = test.loc[eachrow, 'If so, what condition(s) were you diagnosed with?']\n    try:\n        split_diagnose = currentvalue.split('|')\n        values.append(split_diagnose)\n    \n        for eachsplit in split_diagnose:\n            if eachsplit not in diagnoses:\n                diagnoses.append(eachsplit)\n            if eachsplit in counts:\n                counts[eachsplit] += 1\n            else:\n                counts[eachsplit] = 1\n    except:\n        continue\n#     else:\n#         cannotsplit.append(eachrow)\nsorted_counts = sorted(counts.items(), reverse = True, key=lambda x: x[1])\nother_total = 0\ndiagnose_col = list()\nfor each in range(1, len(sorted_counts)-1):\n    if each<10:\n        diagnose_col.append(sorted_counts[each][0])\n    else:\n        other_total += sorted_counts[each][1]\n\nfor each in counts:\n    counts[each] = [counts[each]]\n# print(counts)\ndf_sorted = pd.DataFrame(counts)[diagnose_col]\ndf_sorted['other'] = other_total\nfig, ax = plt.subplots(figsize = (8, 8))\nwedges, texts, autotext  = ax.pie(df_sorted, \n                                  labels = df_sorted.columns, \n                                  autopct = '%.2f%%')\nax.legend(wedges, \n          df_sorted.columns, \n          title = 'Diagnosis', \n          loc = 'best', \n          bbox_to_anchor = [0, 1])\n# plt.setp(texts, weight = 'bold')\nax.set_title('Pie Chart of Diagnosed Conditions')\nplt.show()\n","3cfba791":"print(df.loc[7, 'If so, what condition(s) were you diagnosed with?'])","ec8c9739":"#change object cols to categorical cols\ncat_codes = dict() #stores mapping of categorical col codes, key:col name, value:mapping\nfor eachcol in df.columns: #for each column\n    if df[eachcol].dtype == object: #if column type is object\n        df[eachcol] = df[eachcol].astype('category') #change its type to category\n        dummy = df[eachcol].cat.codes #assign dummy codes to the column values\n        mapping = dict(enumerate(df[eachcol].cat.categories)) #store mapping in dictionary, key:code, value:original str value\n        cat_codes[eachcol] = mapping #store mapping for this column\n        df[eachcol] = dummy #substitude col values with dummy values ","5efac4b5":"#correlations\ncorr = df.corr()\n# corr_us = corr.reset_index()\nsns.heatmap(corr, \n            xticklabels = range(df.shape[1]),\n            yticklabels = range(df.shape[1]))\nplt.title('heatmap')\nplt.show()\nhigh_corr = corr[abs(corr)>0.5]\nprint(high_corr) #getting a lot of nan","62e413cf":"print(df['Are you self-employed?'].corr(df['Do you have previous employers?'])) #getting nan above but true value is not nan","78b9f5e5":"#calculate corr values in loop\ndict_corr = dict()\nfor each1 in df.columns: #for each col1\n    list_corr = list() #store corr values for col1\n    for each2 in df.columns: #for each col2\n        corr = df[each1].corr(df[each2]) #calculate the corr value between col1 and col2\n        list_corr.append(corr) #append corr value\n    dict_corr[each1] = list_corr #store corr list under key col1\ndf_corr = pd.DataFrame(dict_corr, index = df.columns) #make dataframe as corr matrix\n\nfor each in df_corr.columns: #check for nan values\n    if df_corr[each].isnull().sum() > 0: #if there is nan values under current col\n        print(each)\n\nsns.heatmap(df_corr, \n            xticklabels = range(df_corr.shape[1]),\n            yticklabels = range(df_corr.shape[1]))\nplt.title('heatmap')\nplt.show()\n#heatmap looks the same","7bf68515":"# print(df_corr.isna().sum())\n# print(df_corr['Are you self-employed?'].isnull().sum())\ndf_corr[abs(df_corr)>0.5]","ef788b68":"#check the columns that have nan correlation\nq1 = 'Are you self-employed?'\nq2 = 'Is your employer primarily a tech company\/organization?'\nprint(df[q2].unique())\nprint(df[q1].unique())\nnum_nantech_selfemployed = (df.loc[df[q2].isnull(), q1] != 1).sum() #counts number of 0 in q1 when q2 is nan,\nnum_selfemployed_nantech = (df.loc[df[q1] == 1, q2].notnull()).sum() #counts number of real values in q2 when q1 is 1\nprint(num_nantech_selfemployed, num_selfemployed_nantech) \n#zeros for both, so whenever someone answers yes to q1, he has nan for q2, vice versa, therefore answering nan for q2 already indicates the\n#answer for q1. We could eliminate q1 and should substitude the nan in q2 with a number\nprint(cat_codes['Are you self-employed?'])","fa1059a4":"#dropping self employed question and substitude nan with number 2\ndf = df.drop(q1, axis = 1)\ndf.loc[df[q2].isnull(), q2] = 2\nprint(df[q2])","d6b76439":"#split the dataframes\nprint(cat_codes['What country do you live in?']) #US has code 50\n# us_code = cat_code['What country do you live in?']['50']\ndf_us = df[df['What country do you live in?'] == 50] #dataframe for US\ndf_nonus = df[df['What country do you live in?'] != 50] #dataframe for non-US\nprint(df_us.shape)\nprint(df_nonus.shape)\nfor each in df_us.columns:\n    if len(df_us[each].unique()) == 1:\n        df_us.drop(each, axis = 1)\n        print('df_us dropped', each)\n    if len(df_nonus[each].unique()) == 1:\n        df_nonus.drop(each, axis = 1)\n        print('df_nonus dropped', each)","5b9d4677":"#correlations\ncorr_us = df_us.corr()\n# corr_us = corr.reset_index()\nsns.heatmap(corr_us, \n            xticklabels = range(df_us.shape[1]),\n            yticklabels = range(df_us.shape[1]))\nplt.title('heatmap for US data')\nplt.show()\ncorr_nonus = df_nonus.corr()\nsns.heatmap(corr_nonus, \n            xticklabels = range(df_nonus.shape[1]),\n            yticklabels = range(df_nonus.shape[1]))\nplt.title('heatmap for non-US data')\nplt.show()","2bfa4c31":"print(corr_us[corr_us>0.6])","8fa14c81":"split dataframe into inside and outside US dfs","81d8be85":"check on null","1118b6c7":"**Do NOT split countries**","5814d8e0":"investigate the self-employed respondees","93d3e2d5":"Labeled df","e886ff71":"# Prepare output files","73255334":"check on nan","53b816d6":"major changes in columns\/rows: \n\n    dropped columns that have more than 60% nan, \n    dropped ages above 100 and below 21, \n    dropped columns that are used to create one hot encoding, \n    dropped why questions, \n    dropped US state questions for non-US, \n    dropped are you self-employed column (focused on those who are not)\n    changed the rest of nan values (all in categorical columns) to 'I don't know' or 'I'm not sure', etc.\n\ndata type:\n    \n    all columns should be categorical except 'age'\n\ndummies:\n    \n    gender uses label encoding\n    diagnosis and work position use one hot encoding","9e38e0a4":"eliminate age lower than 21 and 100","891ca145":"get all columns except textbox columns (including response variable Y)","d813cd1b":"get countries and states","5dace2b7":"get rid of rows of self-employed answers","65bb70c6":"Load dataset","fd99f670":"distribution of countries","c484da15":"Combine dummy variables with main df","7c9a4019":"make dummy variables out of states and countries","c3a6d498":"What columns could have answers from text box?","2d4578e1":"get diagnoses","28e8ffad":"Which of the following best describes your work position?","f7a9bca8":"# Brief view of dataset","d08a11ce":"what happens if split dataframe to US and non-US","b5a3a36e":"# Get dummy variables and labels","2e057f7e":"# Export dataframe","ae8db78f":"get gender","6457ce8f":"categorize NAN in yes no questions to I dont know","5e6a9770":"**Splitting Country**","2b437b30":"> # Scratch - Not part of the offical code"}}