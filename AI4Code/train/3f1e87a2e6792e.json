{"cell_type":{"81a24bd0":"code","a46173e1":"code","f55caca5":"code","e5230c9a":"code","a6303a3a":"code","fee42842":"code","e5ae0d9c":"code","c5fab7b8":"code","289d1efa":"code","84ff6abd":"code","3a2d16f3":"code","ef742d87":"code","c3cc9cea":"code","529ab07c":"code","d59d7a36":"code","aa161968":"code","f447cdc8":"code","ed8c4853":"code","0023f756":"code","a3081dff":"code","e066be0a":"code","fb754c01":"code","722ef559":"code","30aed86a":"code","9a81aa76":"code","c5ae046e":"code","00b19c51":"code","747ee109":"code","29bcb6ba":"code","eb2ec614":"code","6414953e":"code","99602f15":"code","d8083c96":"code","46407a0d":"code","1a54b349":"code","d23828c9":"code","6ceb28ad":"code","6bd1c026":"code","cfc02909":"code","25912996":"code","ef27f9e1":"code","8f9a6bfb":"code","478efe90":"code","d92af5e0":"code","5831ece3":"code","b0d3846f":"code","59462ef1":"markdown"},"source":{"81a24bd0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a46173e1":"!pip install rake_nltk","f55caca5":"import matplotlib.pyplot as plt \nimport seaborn as sns\nimport re\nimport pyLDAvis\nimport gensim\nfrom rake_nltk import Rake\nfrom spacy.tokens import Span \nimport pyLDAvis.gensim\nfrom wordcloud import WordCloud,STOPWORDS\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nimport re,string,unicodedata\nfrom nltk.stem import WordNetLemmatizer,PorterStemmer\nfrom nltk.tokenize import word_tokenize\nfrom collections import  Counter\nstop = set(stopwords.words('english'))\npunctuation = list(string.punctuation)\nstop.update(punctuation)\nimport spacy \nnlp = spacy.load('en_core_web_lg')","e5230c9a":"df = pd.read_csv('\/kaggle\/input\/data-analyst-jobs\/DataAnalyst.csv')","a6303a3a":"df.head(3)","fee42842":"plt.rcParams[\"figure.figsize\"] = (15,8)\nplt.style.use(\"fivethirtyeight\")\ndf['Salary Estimate'].value_counts().sort_values(ascending=False).head(30).plot(kind='bar')\nplt.title('Salary Estimate Frequency')","e5ae0d9c":"plt.rcParams[\"figure.figsize\"] = (15,8)\nplt.style.use(\"fivethirtyeight\")\nsns.barplot(y=df['Rating'].value_counts().index,\n            x=df['Rating'].value_counts().sort_values(ascending=False))","c5fab7b8":"plt.rcParams[\"figure.figsize\"] = (15,8)\nplt.style.use(\"fivethirtyeight\")\ndf['Job Title'].value_counts().sort_values(ascending=False).head(30).plot(kind='bar')\nplt.title('Job Title Frequency')\nplt.show()","289d1efa":"plt.rcParams[\"figure.figsize\"] = (15,8)\nplt.style.use(\"fivethirtyeight\")\ndf['Company Name'].value_counts().sort_values(ascending=False).head(30).plot(kind='bar')\nplt.title(\"Company Name Frequency\")\nplt.show()","84ff6abd":"plt.rcParams[\"figure.figsize\"] = (15,8)\nplt.style.use(\"fivethirtyeight\")\ndf['Location'].value_counts().sort_values(ascending=False).head(30).plot(kind='bar') \nplt.title(\"Location Frequency\")\nplt.show()","3a2d16f3":"plt.rcParams[\"figure.figsize\"] = (15,8)\nplt.style.use(\"fivethirtyeight\")\ndf['Headquarters'].value_counts().sort_values(ascending=False).head(30).plot(kind='bar')\nplt.title(\"Headquarters Frequency\")\nplt.show()","ef742d87":"plt.rcParams[\"figure.figsize\"] = (15,8)\nplt.style.use(\"fivethirtyeight\")\ndf['Size'].value_counts().sort_values(ascending=False).head(30).plot(kind='bar') \nplt.title(\"Company Size Frequency\")\nplt.show()","c3cc9cea":"plt.rcParams[\"figure.figsize\"] = (15,8)\nplt.style.use(\"fivethirtyeight\")\ndf['Founded'].value_counts().sort_values(ascending=False).head(30).plot(kind='bar')\nplt.title(\"Founded Frequency\")\nplt.show()","529ab07c":"plt.rcParams[\"figure.figsize\"] = (15,8)\nplt.style.use(\"fivethirtyeight\")\ndf['Type of ownership'].value_counts().sort_values(ascending=False).head(30).plot(kind='bar') \nplt.title(\"Type Of Ownership Frequency\")\nplt.show()","d59d7a36":"plt.rcParams[\"figure.figsize\"] = (15,8)\nplt.style.use(\"fivethirtyeight\")\ndf['Industry'].value_counts().sort_values(ascending=False).head(30).plot(kind='bar')\nplt.title(\"Industry Frequency\")\nplt.show()","aa161968":"plt.rcParams[\"figure.figsize\"] = (15,8)\nplt.style.use(\"fivethirtyeight\")\ndf['Sector'].value_counts().sort_values(ascending=False).head(30).plot(kind='bar')\nplt.title(\"Sector Frequency\")\nplt.show()","f447cdc8":"plt.rcParams[\"figure.figsize\"] = (15,8)\nplt.style.use(\"fivethirtyeight\")\ndf['Revenue'].value_counts().sort_values(ascending=False).head(30).plot(kind='bar') ","ed8c4853":"text = df['Job Description']","0023f756":"def text_pro(df):\n    corpus=[]\n    stem = PorterStemmer()\n    lem=WordNetLemmatizer()\n\n    for news in text:\n        words=[w for w in word_tokenize(news) if (w not in stop)]\n        \n        words=[lem.lemmatize(w) for w in words if len(w)>2]\n        \n        corpus.append(words)\n    return corpus","a3081dff":"corpus=text_pro(text)\ndic=gensim.corpora.Dictionary(corpus)\nbow_corpus = [dic.doc2bow(doc) for doc in corpus]","e066be0a":"lda_model =  gensim.models.LdaMulticore(bow_corpus, \n                                   num_topics = 4, \n                                   id2word = dic,                                    \n                                   passes = 10,\n                                   workers = 2)","fb754c01":"lda_model.show_topics()","722ef559":"pyLDAvis.enable_notebook()\nvis = pyLDAvis.gensim.prepare(lda_model, bow_corpus, dic)\nvis","30aed86a":"df.head(3)","9a81aa76":"stop=set(stopwords.words('english'))\n\ndef build_list(df,col=\"Job Description\"):\n    corpus=[]\n    lem=WordNetLemmatizer()\n    stop=set(stopwords.words('english'))\n    new= df[col].dropna().str.split()\n    new=new.values.tolist()\n    corpus=[lem.lemmatize(word.lower()) for i in new for word in i if(word) not in stop]\n    \n    return corpus","c5ae046e":"corpus=build_list(df)\ncounter=Counter(corpus)\nmost=counter.most_common()\nx=[]\ny=[]\nfor word,count in most[:10]:\n    if (word not in stop) :\n        x.append(word)\n        y.append(count)","00b19c51":"plt.figure(figsize=(9,7))\nsns.barplot(x=y,y=x)\nplt.title(\"Most Common Word In Job Description\")","747ee109":"def clean(text):\n    text = text.fillna(\"fillna\").str.lower()\n    text = text.map(lambda x: re.sub('\\\\n',' ',str(x)))\n    text = text.map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n    text = text.map(lambda x: re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",'',str(x)))\n    text = text.map(lambda x: re.sub(\"\\(http:\/\/.*?\\s\\(http:\/\/.*\\)\",'',str(x)))\n    return text","29bcb6ba":"df['Job Description'] = clean(df['Job Description'])","eb2ec614":"stemmer = PorterStemmer()\ndef stem_text(text):\n    final_text = []\n    for i in text.split():\n        if i.strip().lower() not in stop:\n            word = stemmer.stem(i.strip())\n            final_text.append(word)\n    return \" \".join(finan_text)","6414953e":"plt.figure(figsize = (20, 20))\nwc = WordCloud(max_words=1500, width=1600,height = 800 , stopwords = STOPWORDS).generate(\" \".join(df['Job Description']))\nplt.imshow(wc , interpolation = 'bilinear')","99602f15":"def text_entity(text):\n    doc = nlp(text)\n    for ent in doc.ents:\n        print(f'Entity: {ent}, Label: {ent.label_}, {spacy.explain(ent.label_)}')","d8083c96":"text_entity(df['Job Description'][10])","46407a0d":"first = df['Job Description'][50]\ndoc = nlp(first)\nspacy.displacy.render(doc, style='ent',jupyter=True)","1a54b349":"second = df['Job Description'][125]\ndoc = nlp(second)\nspacy.displacy.render(doc, style='ent',jupyter=True)","d23828c9":"third = df['Job Description'][500]\ndoc = nlp(third)\nspacy.displacy.render(doc, style='ent',jupyter=True)","6ceb28ad":"first = df['Job Description'][75]\ndoc = nlp(first)\nspacy.displacy.render(doc, style='ent',jupyter=True)\n\nfor idx, sentence in enumerate(doc.sents):\n    for noun in sentence.noun_chunks:\n        print(f\"sentence {idx+1} has noun chunk '{noun}'\")","6bd1c026":"snd = df['Job Description'][195]\ndoc = nlp(snd)\nspacy.displacy.render(doc, style='ent',jupyter=True)\n\nfor idx, sentence in enumerate(doc.sents):\n    for noun in sentence.noun_chunks:\n        print(f\"sentence {idx+1} has noun chunk '{noun}'\")","cfc02909":"thrd = df['Job Description'][195]\ndoc = nlp(thrd)\nspacy.displacy.render(doc, style='ent',jupyter=True)\n\nfor idx, sentence in enumerate(doc.sents):\n    for noun in sentence.noun_chunks:\n        print(f\"sentence {idx+1} has noun chunk '{noun}'\")","25912996":"df_ = df['Job Description'].str.cat(sep=' ')\n\nmax_length = 1000000-1\ndf_ =  df_[:max_length]","ef27f9e1":"doc = nlp(df_)\nitems_of_interest = list(doc.noun_chunks)\nitems_of_interest = [str(x) for x in items_of_interest]\ndf_nouns = pd.DataFrame(items_of_interest, columns=[\"data\"])\nplt.figure(figsize=(5,4))\nsns.countplot(y=\"data\",\n             data=df_nouns,\n             order=df_nouns[\"data\"].value_counts().iloc[:10].index)\nplt.show()","8f9a6bfb":"distribution = df['Job Description'][155]\ndoc = nlp(distribution)\noptions = {'compact': True, 'bg': '#09a3d5',\n           'color': 'white', 'font': 'Trebuchet MS'}\nspacy.displacy.render(doc, jupyter=True, style='dep', options=options)","478efe90":"distribution1 = df['Job Description'][175]\ndoc = nlp(distribution1)\noptions = {'compact': True, 'bg': '#09a3d5',\n           'color': 'white', 'font': 'Trebuchet MS'}\nspacy.displacy.render(doc, jupyter=True, style='dep', options=options)","d92af5e0":"distribution2 = df['Job Description'][375]\ndoc = nlp(distribution2)\noptions = {'compact': True, 'bg': '#09a3d5',\n           'color': 'white', 'font': 'Trebuchet MS'}\nspacy.displacy.render(doc, jupyter=True, style='dep', options=options)","5831ece3":"for token in doc:\n    print(token.text, token.dep_, token.head.text, token.head.pos_,\n          [child for child in token.children])","b0d3846f":"for token in doc:\n    print(f\"token: {token.text},\\t dep: {token.dep_},\\t head: {token.head.text},\\t pos: {token.head.pos_},\\\n    ,\\t children: {[child for child in token.children]}\")","59462ef1":"# Spacy Text Analysis"}}