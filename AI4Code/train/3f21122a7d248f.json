{"cell_type":{"bc1306bb":"code","20c9d4a3":"code","3741f568":"code","b7d9bdb0":"code","0fabc271":"code","f524e684":"code","3cf54fe8":"code","fd663ba8":"code","00c750c4":"code","a3f104ac":"code","a9343972":"code","85e57638":"code","5f99feeb":"code","a6482e1c":"code","8fb7f4e3":"code","5db13524":"code","cd9845f6":"code","012b5bfd":"code","b42194d4":"markdown","a64930f2":"markdown","da09556c":"markdown","b059f7cd":"markdown","81323e5d":"markdown","d4db98ec":"markdown"},"source":{"bc1306bb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","20c9d4a3":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","3741f568":"train_data.head()","b7d9bdb0":"train_data.info()","0fabc271":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# How many people survived?\nfig = plt.figure(figsize = (15, 1.5))\nsns.countplot(y = \"Survived\", data = train_data)","f524e684":"# Pclass distribution of the passengers\nfig = plt.figure(figsize = (15, 2))\nsns.countplot(y = \"Pclass\", data = train_data)","3cf54fe8":"# Sex distribution of the passengers\nfig = plt.figure(figsize = (15, 1.5))\nsns.countplot(y = \"Sex\", data = train_data)","fd663ba8":"# Age distribution of the passengers\ntrain_data[\"Age\"].plot.hist()","00c750c4":"# Distribution of the passengers as per their Embarked station\nfig = plt.figure(figsize = (15, 2))\nsns.countplot(y = \"Embarked\", data = train_data)","a3f104ac":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n\nnum_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy = \"median\")), \n    (\"std_scaler\", StandardScaler()),\n])","a9343972":"from sklearn.preprocessing import OneHotEncoder\n\ncat_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy = \"most_frequent\")), \n    (\"cat_encoder\", OneHotEncoder()),\n])","85e57638":"from sklearn.compose import ColumnTransformer\n\nnum_attributes = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\ncat_attributes = [\"Pclass\", \"Sex\", \"Embarked\"]\n\npreprocess_pipeline = ColumnTransformer([\n    (\"num\", num_pipeline, num_attributes), \n    (\"cat\", cat_pipeline, cat_attributes), \n])","5f99feeb":"X_train = preprocess_pipeline.fit_transform(train_data[num_attributes + cat_attributes])\ny_train = train_data[\"Survived\"]","a6482e1c":"from sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import accuracy_score\n\ndef fit_ml_algo(algo, X_train = X_train, y_train = y_train, cv = 10):\n    model = algo.fit(X_train, y_train)\n    \n    # Coss-validation\n    y_train_pred = cross_val_predict(algo, X_train, y_train, \n                                   cv = cv, n_jobs = -1)\n    \n    # Accuracy score\n    return accuracy_score(y_train, y_train_pred)","8fb7f4e3":"from sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\n\nmodels = [\n    LinearSVC(), \n    RandomForestClassifier(), \n    GradientBoostingClassifier(), \n    KNeighborsClassifier(), \n    LogisticRegression(), \n    GaussianNB(), \n]\n\nfor model in models:\n    acc = fit_ml_algo(model)\n    print(model, acc)","5db13524":"model = GradientBoostingClassifier()\nmodel.fit(X_train, y_train)\n\nfeature_importances = model.feature_importances_\nfeature_importances","cd9845f6":"imputer = SimpleImputer(strategy = \"most_frequent\")\ntemp = imputer.fit_transform(train_data[cat_attributes])\ncat_encoder = OneHotEncoder()\ncat_encoder.fit_transform(temp)\ncat_one_hot_attributes = cat_encoder.get_feature_names(cat_attributes)\n\nattributes = num_attributes + list(cat_one_hot_attributes)\nsorted(zip(feature_importances, attributes), reverse = True)","012b5bfd":"X_test = preprocess_pipeline.transform(test_data[num_attributes + cat_attributes])\ny_pred = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': y_pred})\noutput.to_csv('submission.csv', index = False)\nprint(\"Your submission was successfully saved!\")","b42194d4":"# Submission","a64930f2":"# Feature Importance","da09556c":"# Load Data","b059f7cd":"# Prepare the Data for ML Algorithms","81323e5d":"# Exploratory Data Analysis (EDA)","d4db98ec":"# Custom function to return a model's accuracy_score"}}