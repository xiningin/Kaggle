{"cell_type":{"ee1508c1":"code","7a9310a5":"code","4750fe2b":"code","93454a2c":"code","f62f744c":"code","549d6f47":"code","dfb9b3c9":"code","c38d060e":"code","2902cca0":"code","b775d362":"code","163cc8d9":"code","e2a79c65":"code","d94dc9bb":"code","65c1f4c1":"code","40894b09":"code","46f423c1":"code","b57e7844":"code","1c5ae343":"code","14dba894":"code","2022f40f":"code","e968b527":"code","12ae60cf":"code","669b8ef1":"code","ce6f6902":"markdown","d6c1fce1":"markdown","79b622d6":"markdown","3f9744d4":"markdown","d0281315":"markdown","ee79c096":"markdown","c26ab43e":"markdown","50939c54":"markdown","f76c5089":"markdown","4f398875":"markdown"},"source":{"ee1508c1":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport keras\nimport tensorflow as tf\nfrom collections import Counter\nimport tqdm as tqdm\nfrom keras.layers import LSTM,Bidirectional,Flatten,Conv1D,Dense,Dropout,Embedding,MaxPooling1D\nfrom keras.models import Sequential","7a9310a5":"df_train=pd.read_csv('..\/input\/imdb-dataset-sentiment-analysis-in-csv-format\/Train.csv')\ndf_val=pd.read_csv('..\/input\/imdb-dataset-sentiment-analysis-in-csv-format\/Valid.csv')\ndf_test=pd.read_csv('..\/input\/imdb-dataset-sentiment-analysis-in-csv-format\/Test.csv')\n\ndf_train.shape,df_val.shape,df_test.shape","4750fe2b":"df_train.head()","93454a2c":"X_train=df_train.text.values\nX_val=df_val.text.values\nX_test=df_test.text.values\n\nY_train=df_train.label.values\nY_val=df_val.label.values\nY_test=df_test.label.values","f62f744c":"length_of_individual_review_train=[len(i.split()) for i in X_train]\nlength_of_individual_review_val=[len(i.split()) for i in X_val]\nlength_of_individual_review_test=[len(i.split()) for i in X_test]","549d6f47":"fig, axs = plt.subplots(3)\nplt.figure(figsize=(10,10))\naxs[0].hist(length_of_individual_review_train)\naxs[1].hist(length_of_individual_review_val)\naxs[2].hist(length_of_individual_review_test)","dfb9b3c9":"df_review=pd.DataFrame()\ndf_review['train']=length_of_individual_review_train\ndf_review.describe()","c38d060e":"df_reviews=pd.DataFrame()\ndf_reviews['val']=length_of_individual_review_val\ndf_reviews['test']=length_of_individual_review_test\ndf_reviews.describe()","2902cca0":"temp=' '.join(X_train)\nwords_count=Counter(temp.split())\nwords_count=sorted(words_count.values(),reverse=True)\nwords_count","b775d362":"temp=' '.join(X_train)\ntemp=temp.lower()\nfor i in sorted(set(temp)):\n    print(i,end='')","163cc8d9":"vocab_size=15000\nembedding_dimension=32\nmax_length=120\nturnc='post'\noov_tok='<OOV>'","e2a79c65":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","d94dc9bb":"tokenizer=Tokenizer(filters='''!\"#$%&'()*+,-.\/:;<=>?@[\\]^_`{|}~\u00a1\u00a2\u00a3\u00a4\u00a6\u00a7\u00a8\u00ab\u00ad\u00ae\u00b0\u00b3\u00b4\u00b7\u00ba\u00bb\u00bd\u00be\u00bf\u00df\u00e0\u00e1\u00e2\u00e3\u00e4\u00e5\u00e6\u00e7\u00e8\u00e9\u00ea\u00eb\u00ec\u00ed\u00ee\u00ef\u00f0\u00f1\u00f2\u00f3\u00f4\u00f5\u00f6\u00f8\u00f9\u00fa\u00fb\u00fc\u00fd\u00fe\u011f\u0131\u014d\u017c\u05d0\u05d2\u05d5\u05d9\u05db\u05dc\u05de\u05df\u05e8\u2013\u2018\u2019\u201c\u201d\u2026\u2033\u20a4\u2605\u3001''',\n                   num_words=vocab_size,\n                   oov_token=oov_tok)\n\ntokenizer.fit_on_texts(X_train)\n\nword_index=tokenizer.word_index\n\nX_train_sequences=tokenizer.texts_to_sequences(X_train)\n\nX_train_padded=pad_sequences(X_train_sequences,\n                            maxlen=max_length,\n                            padding='post',\n                            truncating=turnc)","65c1f4c1":"X_test_sequences=tokenizer.texts_to_sequences(X_test)\nX_test_padded=pad_sequences(X_test_sequences,\n                            maxlen=max_length,\n                            padding='post',\n                           truncating=turnc)","40894b09":"X_val_sequences=tokenizer.texts_to_sequences(X_val)\nX_val_padded=pad_sequences(X_val_sequences,\n                            maxlen=max_length,\n                           padding='post',\n                           truncating=turnc)","46f423c1":"model = Sequential([\n    Embedding(vocab_size, embedding_dimension, input_length=max_length),\n    Dropout(0.3),\n    Bidirectional(LSTM(120,return_sequences=False)),\n    Dropout(0.2),\n    Dense(1, activation='sigmoid')\n])\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.summary()","b57e7844":"history=model.fit(X_train_padded,Y_train,epochs=4,validation_data=(X_val_padded,Y_val))","1c5ae343":"model.evaluate(X_test_padded,Y_test)","14dba894":"X_test_padded[0]","2022f40f":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])","e968b527":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])","12ae60cf":"test_case_1=['lovely movie']\ntokenizer.fit_on_texts(test_case_1)\np=tokenizer.texts_to_sequences(test_case_1)\ntest_case_1=pad_sequences(p,maxlen=120)\nmodel.predict_classes(test_case_1)","669b8ef1":"test_case_2=['boring movie']\ntokenizer.fit_on_texts(test_case_2)\np=tokenizer.texts_to_sequences(test_case_2)\ntest_case_2=pad_sequences(p,maxlen=120)\nmodel.predict_classes(test_case_2)","ce6f6902":"## Length of Reviews in Val N Test Data","d6c1fce1":"## Looking at all distinct Characters present in reviews\n\nExcept alphanumeric characters, we can pass rest of characters as filter to our Tokenizer object","79b622d6":"## Predicting from Model","3f9744d4":"Thank you ","d0281315":"## Length of reviews in Training Data","ee79c096":"# Tokenizing","c26ab43e":"# Understanding Data","50939c54":"## Histogram of Length of Reviews ","f76c5089":"## Importing Libraries","4f398875":"# Reading Data "}}