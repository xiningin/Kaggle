{"cell_type":{"8c3f7481":"code","4cdfc8dc":"code","4232a7f1":"code","b9b236b6":"code","c0839ba5":"code","8af541cd":"code","d17a1f62":"code","c2034354":"code","e6394bc3":"code","9de372d3":"code","494c8a12":"code","98bdeb52":"code","f5ef04ef":"code","a7892f4b":"code","8ad95392":"code","5369c1e2":"code","5e29877c":"code","d3cfe394":"code","4e146882":"code","8f2050f8":"code","bc81d001":"code","29644c6e":"code","cce91cf0":"code","641801cb":"code","db4f4f4e":"code","008db137":"code","7c3d660f":"code","520f4832":"code","bed3217a":"code","9e07b821":"code","497588f3":"code","1d3dc7a9":"markdown","57b1d62d":"markdown","9e3a9e64":"markdown","83dfed4d":"markdown","52971b35":"markdown","b105eb51":"markdown","1eecb489":"markdown"},"source":{"8c3f7481":"import plotly.express as px\nimport gc\nimport pickle","4cdfc8dc":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nroot = '\/kaggle\/input\/riiid-test-answer-prediction\/'","4232a7f1":"%%time\n\ndf_train = pd.read_csv(root + 'train.csv', \n    nrows = 10**7,\n    dtype={\n        'row_id': 'int64', \n        'timestamp': 'int64', \n        'user_id': 'int32', \n        'content_id': 'int16', \n        'content_type_id': 'int8',\n        'task_container_id': 'int16', \n        'user_answer': 'int8', \n        'answered_correctly': 'int8', \n        'prior_question_elapsed_time': 'float32', \n        'prior_question_had_explanation': 'boolean'\n    },\n)\ndf_train.head(10)","b9b236b6":"\"\"\"\nDescribe does not yield any especially useful info about train.csv.\n\"\"\"\ndf_train.describe()","c0839ba5":"\"\"\"\ncontent_type_id denotes if the contents are questions or lectures.\nThe pie shows that 98.1% of the data in train.csv are questions (0), only 1.94% are lectures.\n\"\"\"\ndf = df_train['content_type_id'].value_counts().reset_index()\n\nfig = px.pie(df, values='content_type_id', names='index')\nfig.show()","8af541cd":"\"\"\"\nuser_answer denotes if a user answered the question or not.\n0,1,2,3: I assume this means which option a user choose.\n-1: if content_type is lecture.\n\"\"\"\ndf = df_train['user_answer'].value_counts().reset_index()\n\nfig = px.pie(df, values='user_answer', names='index')\nfig.show()","d17a1f62":"\"\"\"\nanswered_correctly denotes if a user answered the question correctly.\n-1: it's a lecture not a question.\n0: wrong answer.\n1: correct answer.\n\"\"\"\ndf = df_train['answered_correctly'].value_counts().reset_index()\n\nfig = px.pie(df, values='answered_correctly', names='index')\nfig.show()","c2034354":"\"\"\"\nDrop useless columns in train.csv for sake of saving memory.\n\"\"\"\ndf_train = df_train.drop([\n    'row_id', \n    'timestamp', \n    'content_type_id',\n    'task_container_id',\n], axis=1)","e6394bc3":"df_lectures = pd.read_csv(root+'lectures.csv')\ndf_lectures.head(10)","9de372d3":"\"\"\"\ntype_of indicates what a lecture is about.\n\"\"\"\ndf = df_lectures['type_of'].value_counts().reset_index()\n\nfig = px.pie(df, values='type_of', names='index')\nfig.show()","494c8a12":"df_questions = pd.read_csv(root+'questions.csv')\ndf_questions.head(10)","98bdeb52":"\"\"\"\nlecture ids and question ids have overlap. This is a little strange.\nI'm expecting no overlap and each id correcpond to the 'content_id' column in train.csv...\n\"\"\"\nlecture_ids = df_lectures['lecture_id'].unique()\nquestion_ids = df_questions['question_id'].unique()\nset(lecture_ids).intersection(set(question_ids))","f5ef04ef":"%%time\n\n\"\"\"\nRead necessary cols from train.csv.\n\"\"\"\nnecessary_cols = {\n    'user_id': 'int32',\n    'content_id': 'int16',\n    'answered_correctly': 'int8',\n    'prior_question_elapsed_time': 'float16',\n    'prior_question_had_explanation': 'boolean'\n}\n\ndf_train = pd.read_csv(\n    root+'train.csv',\n    usecols=necessary_cols.keys(),\n    dtype=necessary_cols, \n    index_col=0\n)","a7892f4b":"\"\"\"\nFeature engineering: calc a user's historical performance.\n\"\"\"\ndf_train_groupByUser = df_train.groupby('user_id')\ndf_train_groupByUserStats = df_train_groupByUser.agg({\n    'answered_correctly':['mean', 'count', 'std', 'skew'],\n    'prior_question_elapsed_time': ['mean', 'std']\n})\n\n# Flatten index.\ndf_train_groupByUserStats.columns = [\n    'user_answered_correctly_mean',\n    'user_answered_correctly_count',\n    'user_answered_correctly_std',\n    'user_answered_correctly_skew',\n    'user_prior_question_elapsed_time_mean',\n    'user_prior_question_elapsed_time_std',\n]\ndf_user_stats = df_train_groupByUserStats.reset_index()\ndf_user_stats","8ad95392":"\"\"\"\nFeature engineering: calc a specific content's states.\n\"\"\"\ndf_train_groupByContent = df_train.groupby('content_id')\ndf_train_groupByContentStats = df_train_groupByContent.agg({\n    'answered_correctly': ['mean', 'count', 'std', 'skew']})\ndf_train_groupByContentStats","5369c1e2":"\"\"\"\nFeature engineering: combine lectures.csv and questions.csv\n\"\"\"\ndf_lectures['is_lecture'] = 1\ndf_lectures_droped = df_lectures.drop(['tag', 'type_of', 'part'], axis=1)\ndf_lectures_droped.columns = ['content_id', 'is_lecture']\ndf_questions['is_question'] = 1\ndf_questions_droped = df_questions.drop(['bundle_id', 'correct_answer', 'tags', 'part'], axis=1)\ndf_questions_droped.columns = ['content_id', 'is_question']\n\ndf_contents = pd.merge(df_lectures_droped, df_questions_droped, on='content_id', how='outer')\ndf_contents[['is_lecture', 'is_question']] = df_contents[['is_lecture', 'is_question']].fillna(0)\ndf_contents_stats = pd.merge(df_train_groupByContentStats, df_contents, on='content_id', how='left')\ndf_contents_stats.columns = [\n    'content_id',\n    'content_answered_correctly_mean',\n    'content_answered_correctly_count',\n    'content_answered_correctly_std',\n    'content_answered_correctly_skew',\n    'is_lecture',\n    'is_question'\n]\ndf_contents_stats","5e29877c":"del df_questions\ndel df_lectures\ndel df_lectures_droped\ndel df_questions_droped\ndel df_contents\ndel df_train_groupByUserStats\ndel df_train_groupByContent\ndel df_train_groupByContentStats\ndel df_train_groupByUser\ngc.collect()","d3cfe394":"\"\"\"\nUtil fn: reduce memory usage of a dataframe.\n\"\"\"\ndef reduce_mem_usage(df, verbose=True):\n    \"\"\"Make everything faster by reducing the memory used by dataframes.\n    Iterate all columns and modify data type to reduce memory.\n\n    Args:\n        df: pandas dataframe\n    Returns:\n        df: pandas dataframe, with reduced memory\n    \"\"\"\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: \n        print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df\n\ndf_train = reduce_mem_usage(df_train)\ndf_user_stats = reduce_mem_usage(df_user_stats)\ndf_contents_stats = reduce_mem_usage(df_contents_stats)","4e146882":"\"\"\"\nSave df_train, df_user_stats, df_contents_stats before merge. \nMemory error is likely to occur. Painful...\n\"\"\"\n# Save dataframe\n# df_train.to_pickle('df_train.pkl')\n# df_user_stats.to_pickle('df_user_stats.pkl')\n# df_contents_stats.to_pickle('df_contents_stats.pkl')","8f2050f8":"# Load saved dataframe\n# df_train = pd.read_pickle('df_train.pkl')\n# df_user_stats = pd.read_pickle('df_user_stats.pkl')\n# df_contents_stats = pd.read_pickle('df_contents_stats.pkl')","bc81d001":"\"\"\"\nConstructing training dataframe.\n\"\"\"\n# Only choose rows questions, not lectures.\ndf_train = df_train[df_train['answered_correctly'] != -1]\n\ndf_train = df_train.merge(df_user_stats, on='user_id', how='left')","29644c6e":"df_train = df_train.merge(df_contents_stats, on='content_id', how='left')\n\ndf_train['prior_question_had_explanation'] = df_train['prior_question_had_explanation'].fillna(value=False).astype(bool)\ndf_train = df_train.fillna(0.5)\ndf_train","cce91cf0":"df_train.columns","641801cb":"\"\"\"\nFinal step before split.\nOnly choose necessary features.\n\"\"\"\nfeatures = [\n       'prior_question_elapsed_time', 'prior_question_had_explanation',\n       'user_answered_correctly_mean', 'user_answered_correctly_count',\n       'user_answered_correctly_std', 'user_answered_correctly_skew',\n       'user_prior_question_elapsed_time_mean',\n       'user_prior_question_elapsed_time_std',\n       'content_answered_correctly_mean', 'content_answered_correctly_count',\n       'content_answered_correctly_std', 'content_answered_correctly_skew',\n       'is_lecture', 'is_question'\n]\ntarget = 'answered_correctly'\n\ndf_train = df_train[features + [target]]","db4f4f4e":"df_train.fillna(0.5)\ndf_train","008db137":"from sklearn.model_selection import train_test_split\n\ndf_train, df_test = train_test_split(df_train, random_state=1, test_size=0.2)","7c3d660f":"\"\"\"\nBuild XGBoost model.\n\"\"\"\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\n\nxgb_matrix = xgb.DMatrix(\n    df_train[features],\n    df_train[target]\n)\n\nour_params = {\n  'eta'             : 0.05,    \n  'seed'            : 0, \n  'subsample'       : 0.8, \n  'colsample_bytree': 0.8, \n  'objective'       : 'binary:logistic', # output probability [0, 1]\n  'max_depth'       : 10,  \n  'min_child_weight': 1 # default=1, prevent overfitting, high value may cause under fitting\n}","520f4832":"%%time\nfinal_gb = xgb.train(\n  params = our_params, \n  dtrain = xgb_matrix, \n  num_boost_round = 10,\n#   early_stopping_rounds = 150,\n  verbose_eval = 5\n)","bed3217a":"\"\"\"\nPredict using df_test.\n\"\"\"\nfrom sklearn.metrics import roc_auc_score\n\nxgb_matrix_test = xgb.DMatrix(\n    df_test[features],\n#     df_test[target]\n)\n\ntest_predict = final_gb.predict(xgb_matrix_test)\n\nroc_auc_score(df_test[target].values, test_predict)\ntest_predict","9e07b821":"\"\"\"\nRiiiD API. Only run this cell once!\n\"\"\"\nimport riiideducation\n\nenv = riiideducation.make_env()\niter_test = env.iter_test()","497588f3":"\"\"\"\nCreate submission.\n\"\"\"\n\nfor (df_test, sample_prediction_df) in iter_test:\n    df_test = df_test.merge(df_user_stats, how = 'left', on = 'user_id')\n    df_test = df_test.merge(df_contents_stats, how = 'left', on = 'content_id')\n    df_test['prior_question_had_explanation'] = df_test['prior_question_had_explanation'].fillna(value=False).astype(bool)\n    df_test.fillna(value = 0.5, inplace = True)\n\n    dMatrix = xgb.DMatrix(df_test[features])\n    \n    df_test['answered_correctly'] = final_gb.predict(dMatrix)\n    env.predict(df_test.loc[df_test['content_type_id'] == 0, ['row_id', 'answered_correctly']])","1d3dc7a9":"# lectures.csv\nshape=(418, 4)","57b1d62d":"# questions.csv\nshape=(13523, 5)","9e3a9e64":"# About RiiiD!\n![](https:\/\/www.riiid.co\/assets\/about_image_3@2x.png)\nRiiiD! is a Korea based AI research company. Their goal is, in their own words, \"Inviting AI Researchers to Solve the World's Biggest Challenges in AI Education\".Their website can be found at https:\/\/www.riiid.co\/en\/about.","83dfed4d":"# train.csv\ntrain.csv is a very large file. \nIt is a very \"long\" file with only 10 columns, but 101,230,332 rows.","52971b35":"# All avaiable files","b105eb51":"# Some notes\nMemory management is crucial for this competition.\nToDo: hyperparameter optimization.","1eecb489":"# XGBoost model [WIP]"}}