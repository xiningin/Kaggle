{"cell_type":{"500ab349":"code","d2c141dc":"code","ff633025":"code","65bf5edf":"code","b74fc9d1":"code","b299850f":"code","2bf85dfc":"code","f1030d47":"code","fb943727":"code","a21ad193":"code","ec0e21a1":"code","a4d95e90":"code","5ecb7495":"code","f82e4f56":"code","4df84ccc":"code","8b4ce7d8":"code","31ba09c5":"code","06ffbab1":"code","8206135c":"code","07a89f0c":"code","13742b14":"code","09b4bd4b":"code","261c3a35":"code","8ee64f09":"code","6b444b8a":"code","07269de4":"code","bbabb528":"code","ed03f6e7":"code","86310b3e":"code","f356b204":"markdown","d953d972":"markdown","d1c782a7":"markdown"},"source":{"500ab349":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \n%matplotlib inline\nimport seaborn as sns\nfrom numpy import mean, std\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nimport lightgbm as lgb\nfrom lightgbm import LGBMModel,LGBMClassifier,LGBMRegressor\nfrom sklearn import model_selection, preprocessing, feature_selection, ensemble, linear_model, metrics, decomposition\nimport xgboost as xgb","d2c141dc":"# load the dataset\ntrain = pd.read_csv(\"..\/input\/absolute-rank-seo\/absolute_rank-mlgtech.csv\")\ntrain_2 = pd.read_csv(\"..\/input\/organic-rank-seo\/organic_rank_mlgtech.csv\")","ff633025":"train.dtypes","65bf5edf":"# delete unnecessary columns\ncolumn_used = [\"id\", \"keyword_key\", \"keyword\", \"device\", \"type\", \"domain\", \"url\", \"rank_group\", \"rank_absolute\", \"pre_snippet\", \"extended_snippet\", \"rating\", \"rating_value\", \"rating_max\"]\ntrain = train[column_used]","b74fc9d1":"# new standard value for pre_snippet, extend_snippet, rating\n# replace null value to 0, while exist to 1\ntrain[\"rating\"] = train[\"rating\"].replace(np.nan, 0)\ntrain[\"pre_snippet\"] = np.where(train[\"pre_snippet\"] == \"exist\", 1, 0)\ntrain[\"extended_snippet\"] = np.where(train[\"extended_snippet\"] == \"exist\", 1, 0)","b299850f":"train.head()","2bf85dfc":"keyword_df = train.groupby(['keyword']).size()\nkeyword_df","f1030d47":"keyword_df = train.groupby(['device']).size()\nkeyword_df","fb943727":"keyword_df = train.groupby(['type']).size()\nkeyword_df","a21ad193":"keyword_df = train.groupby(['pre_snippet']).size()\nkeyword_df","ec0e21a1":"keyword_df = train.groupby(['extended_snippet']).size()\nkeyword_df","a4d95e90":"keyword_df = train.groupby(['rating_value']).size()\nkeyword_df","5ecb7495":"keyword_df = train.groupby(['rating_max']).size()\nkeyword_df","f82e4f56":"keyword_df = train.groupby('keyword')\nkw = []\nfor key, value in keyword_df['keyword']:\n    kw.append(key)\n# kw","4df84ccc":"train['keyword_num'] = train['keyword']\nfor k, (i, item) in zip(kw, enumerate(train['keyword_num'])):\n#     print(i+1)\n    train[\"keyword_num\"] = np.where(train[\"keyword_num\"] == k, i+1, train[\"keyword_num\"])\ntrain['keyword_num']","8b4ce7d8":"train['keyword_num'] = train['keyword_num'].astype(int)\ntrain.head()","31ba09c5":"# data train is extended from data train_2, so the data is not test and will not used for data test\n# value_sim = np.where(train['keyword'] == train_2['keyword'], 'True', 'False')\n# len(value_sim)","06ffbab1":"train.info()","8206135c":"training = [\"keyword_key\", \"keyword\", \"device\", \"rank_group\", \"rank_absolute\", \"rating\"] \nfeature = [\"keyword_num\", \"device\", \"rank_group\"]\ntarget = \"rank_absolute\"","07a89f0c":"# split data train into data testing\ntrain_df, test_df = train_test_split(train, random_state=9, test_size=0.1)","13742b14":"X = train[feature]\nX","09b4bd4b":"# Y = list(train[target])\nY = train[target]\nY","261c3a35":"# model_lgbm = LGBMClassifier()\n# model_lgbm_fit = model_lgbm.fit(X, Y)\nmodel_lgbm = LGBMRegressor()","8ee64f09":"model_lr = linear_model.LinearRegression()","6b444b8a":"model = xgb.XGBClassifier(max_depth= 3, n_estimators=100)\nmodel_xgb = model.fit(X, Y)","07269de4":"# model.fit(train[feature],train[target])\n# fpr, tpr, thresholds = metrics.roc_curve(train[target],  model.predict(train[feature]))\n# metrics.auc(fpr, tpr)","bbabb528":"try:\n    cv = KFold(n_splits=10, random_state=1, shuffle=True)\n    scores = cross_val_score(model_lgbm, X, Y, cv=cv, n_jobs=-1)\n    print(\"lgbm score:\", mean(scores))\nexcept:\n    print('lgbm error')","ed03f6e7":"try:\n    cv = KFold(n_splits=10, random_state=1, shuffle=True)\n    scores = cross_val_score(model_lr, X, Y, cv=cv, n_jobs=-1)\n    print(\"linier regression score:\", mean(scores))\nexcept:\n    print('linier regression error')","86310b3e":"try:\n    cv = KFold(n_splits=10, random_state=1, shuffle=True)\n    scores = cross_val_score(model_xgb, X, Y, cv=cv, n_jobs=-1)\n    print(\"xgb score:\", mean(scores))\nexcept:\n    print('xgb error')","f356b204":"# Training model","d953d972":"# Cross Validation","d1c782a7":"# Preprocessing data training"}}