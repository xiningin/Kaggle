{"cell_type":{"335f2666":"code","b751f9a5":"code","c87125c8":"code","27060263":"code","2d9a959c":"code","1220b146":"code","75fe856c":"code","8f2bc2a1":"code","d8f788d3":"code","5b09a2b8":"code","d128447c":"code","9656cc30":"code","41e2e268":"code","c757998c":"code","96b65657":"code","cc069697":"code","b49561b8":"code","cf09e9ba":"code","4d811393":"code","ff1ff006":"code","17f0fab9":"code","4a9db58a":"code","eb671af1":"code","12cfdc6a":"code","337419ff":"code","ff60f67b":"markdown","4b9f9147":"markdown","845d2d77":"markdown","12bcc8e5":"markdown","81f8b67d":"markdown","9454dab9":"markdown","4f782c1d":"markdown","1883adc8":"markdown","66dc3bd0":"markdown","5075e35d":"markdown","da296496":"markdown","06d6bc09":"markdown","4de8526c":"markdown","0f1bf8ad":"markdown","86fdd895":"markdown","b5637bc4":"markdown","4d340128":"markdown","62857882":"markdown","f776f708":"markdown","535dc689":"markdown","ec50ebaa":"markdown","1729639f":"markdown","221f7271":"markdown","e527fcd7":"markdown","e497ea3d":"markdown","3a295f23":"markdown","e2a1cc78":"markdown"},"source":{"335f2666":"import pandas as pd\nimport numpy as np\nfrom statistics import mean\nfrom time import time\nfrom datetime import datetime, timedelta\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor","b751f9a5":"train_concat = pd.read_csv('..\/input\/store-sales-forecasting-data-cleaning-and-eda\/train_concat.zip', parse_dates = ['Date'])\ntest_concat = pd.read_csv('..\/input\/store-sales-forecasting-data-cleaning-and-eda\/test_concat.zip', parse_dates = ['Date'])\n\nweekly_sales = pd.read_csv('..\/input\/store-sales-forecasting-data-cleaning-and-eda\/weekly_sales.zip', parse_dates = ['Date'])\nweekly_test = pd.read_csv('..\/input\/store-sales-forecasting-data-cleaning-and-eda\/weekly_test.zip', parse_dates = ['Date'])","c87125c8":"holiday_data = train_concat.loc[:, ['Weekly_Sales', 'IsHoliday', 'Month']]\n\nholiday_data.loc[holiday_data.loc[:, 'IsHoliday'] == 0, 'IsHoliday'] = 'Non-Holiday'\nholiday_data.loc[(holiday_data.loc[:, 'IsHoliday'] == 1) & (holiday_data.loc[:, 'Month'] == 2), 'IsHoliday'] = 'Super Bowl'\nholiday_data.loc[(holiday_data.loc[:, 'IsHoliday'] == 1) & (holiday_data.loc[:, 'Month'] == 9), 'IsHoliday'] = 'Labor Day'\nholiday_data.loc[(holiday_data.loc[:, 'IsHoliday'] == 1) & (holiday_data.loc[:, 'Month'] == 11), 'IsHoliday'] = 'Thanksgiving'\nholiday_data.loc[(holiday_data.loc[:, 'IsHoliday'] == 1) & (holiday_data.loc[:, 'Month'] == 12), 'IsHoliday'] = 'Christmas'\n\nholiday_data.head()","27060263":"fig, ax = plt.subplots()\n\nweekly_sales_holiday = sns.barplot(data = holiday_data,\n                                   x = 'IsHoliday', y = 'Weekly_Sales',\n                                   estimator = np.median,\n                                   ax = ax,\n                                  )\nax.set(xlabel = None)\nplt.show()","2d9a959c":"fig, ax = plt.subplots(figsize = (18, 4.8))\n\nts_weekly_sales = sns.lineplot(data = train_concat,\n                               x = 'Date', y = 'Weekly_Sales',\n                               estimator = np.median,\n                               ax = ax)\n\nfor date in train_concat[train_concat['IsHoliday'] == 1]['Date'].unique():\n    plt.axvline(date, 0, 20000,\n                linewidth = 0.5, linestyle = '--', color = 'red')\n    plt.axvline(date - np.timedelta64(7, 'D'), 0, 20000,\n                linewidth = 0.5, linestyle = '--', color = 'green')\n    \nplt.setp(ax.get_xticklabels(), rotation = 45, horizontalalignment = 'right')\nplt.show()","1220b146":"sb_dates = [datetime(2010, 2, 12), datetime(2011, 2, 11), datetime(2012, 2, 10), datetime(2013, 2, 8), datetime(2014, 2, 7)]\ntg_dates = [datetime(2010, 11, 26), datetime(2011, 11, 25), datetime(2012, 11, 23), datetime(2013, 11, 29)]\ncm_dates = [datetime(2010, 12, 31), datetime(2011, 12, 30), datetime(2012, 12, 28), datetime(2013, 12, 27)]","75fe856c":"def weeks_to_next_superbowl(date):\n    weeks = [(sb - date).days \/ 7 for sb in sb_dates if (sb - date).days > 0]\n    return min(weeks)\n\ndef weeks_to_next_thanksgiving(date):\n    weeks = [(tg - date).days \/ 7 for tg in tg_dates if (tg - date).days > 0]\n    return min(weeks)\n\ndef weeks_to_next_christmas(date):\n    weeks = [(cm - date).days \/ 7 for cm in cm_dates if (cm - date).days > 0]\n    return min(weeks)","8f2bc2a1":"start = time()\n\ntrain_concat['weeks_to_sb'] = train_concat['Date'].apply(weeks_to_next_superbowl)\ntrain_concat['weeks_to_tg'] = train_concat['Date'].apply(weeks_to_next_thanksgiving)\ntrain_concat['weeks_to_cm'] = train_concat['Date'].apply(weeks_to_next_christmas)\n\ntest_concat['weeks_to_sb'] = test_concat['Date'].apply(weeks_to_next_superbowl)\ntest_concat['weeks_to_tg'] = test_concat['Date'].apply(weeks_to_next_thanksgiving)\ntest_concat['weeks_to_cm'] = test_concat['Date'].apply(weeks_to_next_christmas)\n\nend = time()\n\nprint(f'Time elapsed: {end - start:.4f} seconds')","d8f788d3":"feature_col = ['Store', 'Dept', 'IsHoliday', 'Size', 'Week', 'Year', 'Type', 'weeks_to_cm', 'weeks_to_sb', 'weeks_to_tg']\nholiday_weights = train_concat['IsHoliday_Weights']\n\nX = train_concat[feature_col]\ny = train_concat['Weekly_Sales']\n\nX_kaggle = test_concat[feature_col]","5b09a2b8":"def compute_wmae_ml(test, pred, weights):\n    \n    diff = (test - pred).abs()\n    \n    total_error = weights.multiply(diff).sum()\n    total_weight = weights.sum()\n    \n    return total_error \/ total_weight","d128447c":"def ml_validation(model):\n    \n    kfold = KFold(n_splits = 5, shuffle = True, random_state = 0)\n    \n    kfold_WMAE = []\n    \n    for train_index, test_index in kfold.split(X):\n        \n        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n        weights = holiday_weights.iloc[test_index]\n\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n        WMAE = compute_wmae_ml(y_test, y_pred, weights)\n        kfold_WMAE.append(WMAE)\n        \n    return mean(kfold_WMAE)","9656cc30":"def max_depth_et(max_depth_param): \n    start = time()\n    \n    for max_depth in max_depth_param:\n\n        reg = ExtraTreesRegressor(random_state = 0,\n                                    max_depth = max_depth)\n\n        mean_kfold_WMAE = ml_validation(reg)\n\n        end = time()\n\n        print(f'max_depth: {max_depth}')\n        print(f'Time elapsed: {end - start:.4f} seconds')\n        print(f'Mean KFold WMAE: {mean_kfold_WMAE:.4f}')\n        print()","41e2e268":"def min_samples_et(param): \n    start = time()\n    \n    for min_samples_split in param['min_samples_split']:\n        for min_samples_leaf in param['min_samples_leaf']:\n            reg = ExtraTreesRegressor(random_state = 0,\n                                        max_depth = 23,\n                                        min_samples_split = min_samples_split,\n                                        min_samples_leaf = min_samples_leaf)\n\n            mean_kfold_WMAE = ml_validation(reg)\n\n            end = time()\n\n            print(f'min_samples_split: {min_samples_split}, min_samples_leaf: {min_samples_leaf}')\n            print(f'Time elapsed: {end - start:.4f} seconds')\n            print(f'Mean KFold WMAE: {mean_kfold_WMAE:.4f}')\n            print()","c757998c":"def n_estimators_et(n_estimators_param): \n    start = time()\n    \n    for n_estimators in n_estimators_param:\n\n        reg = ExtraTreesRegressor(random_state = 0,\n                                    max_depth = 23,\n                                    min_samples_split = 3,\n                                    n_estimators = n_estimators)\n\n        mean_kfold_WMAE = ml_validation(reg)\n\n        end = time()\n\n        print(f'n_estimators: {n_estimators}')\n        print(f'Time elapsed: {end - start:.4f} seconds')\n        print(f'Mean KFold WMAE: {mean_kfold_WMAE:.4f}')\n        print()","96b65657":"def max_features_et(max_features_param): \n    start = time()\n    \n    for max_features in max_features_param:\n\n        reg = ExtraTreesRegressor(random_state = 0,\n                                    max_depth = 23,\n                                    min_samples_split = 3,\n                                    n_estimators = 260,\n                                    max_features = max_features)\n\n        mean_kfold_WMAE = ml_validation(reg)\n\n        end = time()\n\n        print(f'max_features: {max_features}')\n        print(f'Time elapsed: {end - start:.4f} seconds')\n        print(f'Mean KFold WMAE: {mean_kfold_WMAE:.4f}')\n        print()","cc069697":"def max_depth_rf(max_depth_param): \n    start = time()\n    \n    for max_depth in max_depth_param:\n\n        reg = RandomForestRegressor(random_state = 0,\n                                    max_depth = max_depth)\n\n        mean_kfold_WMAE = ml_validation(reg)\n\n        end = time()\n\n        print(f'max_depth: {max_depth}')\n        print(f'Time elapsed: {end - start:.4f} seconds')\n        print(f'Mean KFold WMAE: {mean_kfold_WMAE:.4f}')\n        print()","b49561b8":"def min_samples_rf(param): \n    start = time()\n    \n    for min_samples_split in param['min_samples_split']:\n        for min_samples_leaf in param['min_samples_leaf']:\n            reg = RandomForestRegressor(random_state = 0,\n                                        max_depth = 26,\n                                        min_samples_split = min_samples_split,\n                                        min_samples_leaf = min_samples_leaf)\n\n            mean_kfold_WMAE = ml_validation(reg)\n\n            end = time()\n\n            print(f'min_samples_split: {min_samples_split}, min_samples_leaf: {min_samples_leaf}')\n            print(f'Time elapsed: {end - start:.4f} seconds')\n            print(f'Mean KFold WMAE: {mean_kfold_WMAE:.4f}')\n            print()","cf09e9ba":"def n_estimators_rf(n_estimators_param): \n    start = time()\n    \n    for n_estimators in n_estimators_param:\n\n        reg = RandomForestRegressor(random_state = 0,\n                                    max_depth = 26,\n                                    n_estimators = n_estimators)\n\n        mean_kfold_WMAE = ml_validation(reg)\n\n        end = time()\n\n        print(f'n_estimators: {n_estimators}')\n        print(f'Time elapsed: {end - start:.4f} seconds')\n        print(f'Mean KFold WMAE: {mean_kfold_WMAE:.4f}')\n        print()","4d811393":"def max_features_rf(max_features_param): \n    start = time()\n    \n    for max_features in max_features_param:\n\n        reg = RandomForestRegressor(random_state = 0,\n                                    max_depth = 26,\n                                    n_estimators = 330,\n                                    max_features = max_features)\n\n        mean_kfold_WMAE = ml_validation(reg)\n\n        end = time()\n\n        print(f'max_features: {max_features}')\n        print(f'Time elapsed: {end - start:.4f} seconds')\n        print(f'Mean KFold WMAE: {mean_kfold_WMAE:.4f}')\n        print()","ff1ff006":"filtered_weekly_sales = weekly_sales[weekly_sales['Store_Dept'].isin(weekly_test['Store_Dept'].unique())]\nno_historical_data = weekly_test[~weekly_test['Store_Dept'].isin(filtered_weekly_sales['Store_Dept'].unique())]\n\ndef submission_pred_ml(test, pred):\n    predictions = pd.DataFrame({'Weekly_Sales': pred})\n    model_submit = pd.concat([test, predictions], axis = 1)[['Store_Dept', 'Date', 'Weekly_Sales']]\n    model_submit['Id'] = model_submit['Store_Dept'] + '_' + model_submit['Date'].astype(str)\n    model_submit = model_submit.drop('Date', axis = 1)\n    \n    \n    for i in range(len(model_submit)):\n        if model_submit['Store_Dept'].iloc[i] in no_historical_data['Store_Dept'].unique():\n            model_submit['Weekly_Sales'].iloc[i] = 0\n        \n    return model_submit[['Id', 'Store_Dept', 'Weekly_Sales']]","17f0fab9":"et = ExtraTreesRegressor(random_state = 0,\n                         max_depth = 23,\n                         min_samples_split = 3,\n                         n_estimators = 260,\n                         )\n\net.fit(X, y)\n\net_pred = et.predict(X_kaggle)\net_pred","4a9db58a":"et_submit = submission_pred_ml(test_concat, et_pred)\net_submit.head()","eb671af1":"rf = RandomForestRegressor(random_state = 0,\n                            max_depth = 26,\n                            n_estimators = 330,\n                            max_features = 9,\n                            )\n\nrf.fit(X, y)\n\nrf_pred = rf.predict(X_kaggle)\nrf_pred","12cfdc6a":"rf_submit = submission_pred_ml(test_concat, rf_pred)        \nrf_submit.head()","337419ff":"et_submit.to_csv('et_submit.csv', index = False)\nrf_submit.to_csv('rf_submit.csv', index = False)","ff60f67b":"n_estimators: 330\n\nMean KFold WMAE: 1439.6563","4b9f9147":"### Machine Learning Models","845d2d77":"The machine learning models here are just part of the final model. The final model submission can be found [here](https:\/\/www.kaggle.com\/chongzhenjie\/store-sales-forecasting-stats-model-submission).","12bcc8e5":"##### Random Forest","81f8b67d":"##### WMAE metric ML","9454dab9":"min_samples_split: 3, min_samples_leaf: 1\n\nMean KFold WMAE: 1504.8632","4f782c1d":"max_depth: 23\n\nMean KFold WMAE: 1517.2729","1883adc8":"<a id=\"section-four\"><\/a>\n# Final Model","66dc3bd0":"max_features: 9\n\nMean KFold WMAE: 1429.7463","5075e35d":"max_features: 10\n\nMean KFold WMAE: 1497.9466","da296496":"##### Weeks to each Holiday","06d6bc09":"##### ","4de8526c":"### Random Forest","0f1bf8ad":"From all the time series plots made above, we notice that there is a significant peak in Weekly_Sales near the end of each year. However, from our EDA, the median Weekly_Sales of holiday weeks is only slightly higher than that of non-holiday weeks.\n\nWe investigate further into the effects of the 4 holidays.","86fdd895":"Super Bowl: 12-Feb-10, 11-Feb-11, 10-Feb-12, 8-Feb-13\n\nThanksgiving: 26-Nov-10, 25-Nov-11, 23-Nov-12, 29-Nov-13\n\nChristmas: 31-Dec-10, 30-Dec-11, 28-Dec-12, 27-Dec-13","b5637bc4":"##### Extra-Trees","4d340128":"n_estimators: 260\n\nMean KFold WMAE: 1497.9466","62857882":"max_depth: 26\n\nMean KFold WMAE: 1446.4410","f776f708":"<a id=\"section-two\"><\/a>\n# Feature Engineering for Machine Learning Models","535dc689":"<a id=\"section-three\"><\/a>\n# Model Evaluation for Machine Learning Models","ec50ebaa":"min_samples_split: 2, min_samples_leaf: 1\n\nMean KFold WMAE: 1446.4410","1729639f":"---","221f7271":"The closer the date is to a holiday, the higher the Weekly_Sales. Promotions usually start before the holidays to build excitement and also to attract early holiday shoppers.\n\nThis is apparent in the periods before Super Bowl, Thanksgiving and Christmas. However, such an effect is not that noticeable before Labor Day.","e527fcd7":"<a id=\"section-one\"><\/a>\n# Data Cleaning and EDA\nData cleaning and EDA found [here](https:\/\/www.kaggle.com\/chongzhenjie\/store-sales-forecasting-data-cleaning-and-eda). Notebooks split to save RAM.","e497ea3d":"<b> For simplicity, we attempt to use the provided features from features.csv to predict future Weekly_Sales instead of creating time series features to perform one-step forecasting. <b>","3a295f23":"### Extra-Trees","e2a1cc78":"The above plot indicates that Weekly_Sales during Thanksgiving week is relatively higher while the rest of the periods are approximately equal (holiday Weekly_Sales have larger error bars). We need to confirm this below."}}