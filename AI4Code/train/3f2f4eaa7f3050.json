{"cell_type":{"b4d3d162":"code","135acb72":"code","5d3247e4":"code","da1318a2":"code","c3ed4fe1":"code","f290cd48":"code","383e0365":"code","95ec256c":"code","9541ca13":"code","9dec412a":"code","13779c21":"code","40c7ce75":"code","3e846a82":"code","f254a642":"code","650d5277":"code","ad5a954a":"code","2e0c26e7":"code","64aef339":"code","e135a15c":"code","df872c05":"code","de5e243b":"code","402e232c":"code","d636189c":"code","f6623d05":"markdown","56f3aa09":"markdown","2b01f927":"markdown","0c865973":"markdown","4bcb326a":"markdown","fb2f4841":"markdown","f9d1b4a2":"markdown","60e2cebe":"markdown","f6c3bcd3":"markdown","759078ba":"markdown","2f60fb8f":"markdown","75e0dda3":"markdown","352aef2b":"markdown","135e363c":"markdown","8d594ab7":"markdown","119a15fa":"markdown","d3dc436d":"markdown","93e70069":"markdown"},"source":{"b4d3d162":"import cv2\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pickle\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.applications.vgg16 import VGG16\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom tensorflow.keras.utils import to_categorical","135acb72":"CATEGORIES = ['NORMAL', 'PNEUMONIA']\nDIR_TRAINING = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/train\/'\nDIR_VALIDATION = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/val'\nDIR_TEST = '\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/test\/'\nNEW_SIZE = 100\nX_train = []\ny_train = []\nX_validation = []\ny_validation = []\nX_test = []\ny_test = []\n\nfor category in CATEGORIES:\n    label = CATEGORIES.index(category)\n    path_train = os.path.join(DIR_TRAINING, category)\n    path_val = os.path.join(DIR_VALIDATION, category)\n    path_test = os.path.join(DIR_TEST, category)\n    for img in os.listdir(path_train):\n        try:\n            img_train = cv2.imread(os.path.join(path_train,img), cv2.IMREAD_COLOR)\n            img_train = cv2.resize(img_train, (NEW_SIZE, NEW_SIZE))\n            X_train.append(img_train)\n            y_train.append(label)\n        except Exception as e:\n            pass\n    for img in os.listdir(path_val):\n        try:\n            img_val = cv2.imread(os.path.join(path_val,img), cv2.IMREAD_COLOR)\n            img_val = cv2.resize(img_val, (NEW_SIZE, NEW_SIZE))\n            X_validation.append(img_val)\n            y_validation.append(label)\n        except Exception as e:\n            pass\n    for img in os.listdir(path_test):\n        try:\n            img_test = cv2.imread(os.path.join(path_test,img), cv2.IMREAD_COLOR)\n            img_test = cv2.resize(img_test, (NEW_SIZE, NEW_SIZE))\n            X_test.append(img_test)\n            y_test.append(label)\n        except Exception as e:\n            pass","5d3247e4":"X_train = np.array(X_train, dtype=\"float32\").reshape(-1, NEW_SIZE, NEW_SIZE, 3)\ny_train = np.asarray(y_train)\n\nX_validation = np.array(X_validation, dtype=\"float32\").reshape(-1, NEW_SIZE, NEW_SIZE, 3)\ny_validation = np.asarray(y_validation)\n\nX_test = np.array(X_test, dtype=\"float32\").reshape(-1, NEW_SIZE, NEW_SIZE, 3)\ny_test = np.asarray(y_test)","da1318a2":"indices_train = np.arange(X_train.shape[0])\nnp.random.shuffle(indices_train)\n\nX_train = X_train[indices_train]\ny_train = y_train[indices_train]","c3ed4fe1":"hist_train, bins_train = np.histogram(y_train, bins = [0, 0.5, 1]) \nhist_validation, bins_validation = np.histogram(y_validation, bins = [0, 0.5, 1]) \nhist_test, bins_test = np.histogram(y_test, bins = [0, 0.5, 1]) \n\nx_labels = ['Train', 'Val', 'Test']\nx_hist = np.arange(len(x_labels))\nnormal = [hist_train[0], hist_validation[0], hist_test[0]]\npneumonia = [hist_train[1], hist_validation[1], hist_test[1]]\nwidth = 0.35\nfig, ax = plt.subplots()\nrects1 = ax.bar(x_hist - width\/2, normal, width, label='Normal')\nrects2 = ax.bar(x_hist + width\/2, pneumonia, width, label='Pneumonia')\nax.set_xticks(x_hist)\nax.set_xticklabels(x_labels)\nax.legend(['Normal', 'Pneumonia'])\nfig.tight_layout()\n\nplt.show()","f290cd48":"fig=plt.figure(figsize=(16,16))\n\nfor counter, img in enumerate(X_train[:5]):\n    ax = fig.add_subplot(1,5,counter+1)\n    ax.imshow(X_train[counter,:,:,1], cmap='gray')\n    plt.title('Normal')\n    ax.axes.get_xaxis().set_visible(False)\n    ax.axes.get_yaxis().set_visible(False)\n\nfor counter, img in enumerate(X_train[-5:]):\n    ax = fig.add_subplot(2,5,counter+1)\n    ax.imshow(X_train[-5+counter,:,:,1], cmap='gray')\n    plt.title('Pneumonia')\n    ax.axes.get_xaxis().set_visible(False)\n    ax.axes.get_yaxis().set_visible(False)\n    \nplt.tight_layout()\nplt.show()","383e0365":"base_model = VGG16(include_top=False, weights='imagenet', input_shape=(NEW_SIZE,NEW_SIZE,3), pooling='avg')","95ec256c":"model=Sequential()\nmodel.add(base_model)\n\n#model.add(Flatten())\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\n\n#model.add(Dense(128))\n#model.add(Activation('relu'))\n#model.add(Dropout(0.2))\n\nmodel.add(Dense(2,activation='softmax'))","9541ca13":"base_model.trainable=False","9dec412a":"model.compile(loss='categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])","13779c21":"model.summary()","40c7ce75":"y_cat = to_categorical(y_train)","3e846a82":"(X_train2, X_val2, y_train2, y_val2) = train_test_split(X_train, y_cat, test_size=0.1, random_state=42, stratify=y_train)","f254a642":"train_datagen = ImageDataGenerator(\n    rescale=1.0\/255.0,\n    samplewise_center=True,\n    rotation_range=20,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\")\n\ntest_datagen = ImageDataGenerator(rescale=1.0\/255.0, samplewise_center=True)","650d5277":"batch_size = 64","ad5a954a":"train_iterator = train_datagen.flow(X_train2, y_train2, batch_size=batch_size, shuffle=False)\ntest_iterator = test_datagen.flow(X_val2, y_val2, batch_size=batch_size, shuffle=False)","2e0c26e7":"# confirm the scaling works\nbatchX, batchy = train_iterator.next()\nprint('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))","64aef339":"learning_rate_reduction = ReduceLROnPlateau(monitor='accuracy', \n                                            patience=3, \n                                            verbose=1,\n                                            factor=0.5, \n                                            min_lr=0.00001)\nearlystop = EarlyStopping(patience=10)","e135a15c":"earlystop = EarlyStopping(patience=20)\n\nhistory = model.fit_generator(train_iterator,\n                              validation_data=test_iterator,\n                              steps_per_epoch=X_train2.shape[0] \/\/ batch_size,\n                              epochs=100,\n                              callbacks=[earlystop, learning_rate_reduction])","df872c05":"predict_datagen = ImageDataGenerator(rescale=1.0\/255.0, samplewise_center=True)\npredict_iterator = predict_datagen.flow(X_test, y_test, batch_size=len(X_test), shuffle=False)\npredicted_label = model.predict(predict_iterator.next())\npredicted_label = np.argmax(predicted_label, axis = 1)\nprint(\"Model Accuracy on test set: {:.4f}\".format(accuracy_score(y_test, predicted_label)))","de5e243b":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper right')\nplt.show()","402e232c":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='lower right')\nplt.show()","d636189c":"class_names = ['Normal', 'Pneumonia']\ncm  = confusion_matrix(y_test, predicted_label)\nplot_confusion_matrix(cm, cmap=plt.cm.Blues, class_names=class_names)","f6623d05":"## We comnpile the model","56f3aa09":"### Creation of generators for: augmentation of training data and for normalization of validation data","2b01f927":"## Accuracy plots","0c865973":"## We can see that it is a clearly unbalanced dataset \n## Let's have a look at the images","4bcb326a":"## Confusion Matrix","fb2f4841":"# Chest X-Rays: transfer learning to detect pneumonia\nUsing the VGG16 model trained with the imagenet dataset to classify between normal and pneumonic chests from X-Ray images.\n\n**Acknowledgements (basically started with their notebooks):**\n\n* [Raj Mehrotra](https:\/\/www.kaggle.com\/rajmehra03\/a-comprehensive-guide-to-transfer-learning)\n* [NAIN](https:\/\/www.kaggle.com\/aakashnain)","f9d1b4a2":"## Now, we will load and pre-process the data","60e2cebe":"## Loss plots","f6c3bcd3":"## Creation of generators for: augmentation of training data and for normalization of validation data","759078ba":"## Fitting the data","2f60fb8f":"First, we transform y_train into categorical","75e0dda3":"## Evaluate Model Accuracy on the Test dataset","352aef2b":"## We shuffle the data","135e363c":"## To evaluate these datasets we will use transfer learning\n## Specifically, we will use the VGG16 model trained with the imagenet dataset (available in Keras), and then add a couple of dense layer and an output layer","8d594ab7":"## Convert lists into arrays of appropiate size + image normalization","119a15fa":"## Let's have a look at the size of the dataset","d3dc436d":"### First, I will import some packages","93e70069":"## Validation dataset is pretty small, only 8 images for each label. Thus, I will go for splitting the train dataset into training and validation"}}