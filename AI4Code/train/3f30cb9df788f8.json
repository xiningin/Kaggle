{"cell_type":{"f4f85bae":"code","5ac58b03":"code","077cd8d6":"code","7a2b841a":"code","81abf06b":"code","8fd13807":"code","825df987":"code","7de980e0":"code","cd0cc205":"code","611d9f8b":"code","aa6ef03b":"code","5f09b59f":"code","b5039283":"code","2892f273":"code","2cc8799e":"code","e30b74ba":"code","2283385b":"code","8a03a0b3":"code","5537c32f":"code","2258dd8a":"code","2ba0dcad":"code","fd335ac3":"markdown","0ec85528":"markdown","1af7844c":"markdown","70e32f0a":"markdown"},"source":{"f4f85bae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport json # to read json\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n\n# Any results you write to the current directory are saved as output.","5ac58b03":"def squad_json_to_dataframe_train(input_file_path, record_path = ['data','paragraphs','qas','answers'],\n                           verbose = 1):\n    \"\"\"\n    input_file_path: path to the squad json file.\n    record_path: path to deepest level in json file default value is\n    ['data','paragraphs','qas','answers']\n    verbose: 0 to suppress it default is 1\n    \"\"\"\n    if verbose:\n        print(\"Reading the json file\")    \n    file = json.loads(open(input_file_path).read())\n    if verbose:\n        print(\"processing...\")\n    # parsing different level's in the json file\n    js = pd.io.json.json_normalize(file , record_path )\n    m = pd.io.json.json_normalize(file, record_path[:-1] )\n    r = pd.io.json.json_normalize(file,record_path[:-2])\n    \n    #combining it into single dataframe\n    idx = np.repeat(r['context'].values, r.qas.str.len())\n    ndx  = np.repeat(m['id'].values,m['answers'].str.len())\n    m['context'] = idx\n    js['q_idx'] = ndx\n    main = pd.concat([ m[['id','question','context']].set_index('id'),js.set_index('q_idx')],1,sort=False).reset_index()\n    main['c_id'] = main['context'].factorize()[0]\n    if verbose:\n        print(\"shape of the dataframe is {}\".format(main.shape))\n        print(\"Done\")\n    return main","077cd8d6":"def squad_json_to_dataframe_dev(input_file_path, record_path = ['data','paragraphs','qas','answers'],\n                           verbose = 1):\n    \"\"\"\n    input_file_path: path to the squad json file.\n    record_path: path to deepest level in json file default value is\n    ['data','paragraphs','qas','answers']\n    verbose: 0 to suppress it default is 1\n    \"\"\"\n    if verbose:\n        print(\"Reading the json file\")    \n    file = json.loads(open(input_file_path).read())\n    if verbose:\n        print(\"processing...\")\n    # parsing different level's in the json file\n    js = pd.io.json.json_normalize(file , record_path )\n    m = pd.io.json.json_normalize(file, record_path[:-1] )\n    r = pd.io.json.json_normalize(file,record_path[:-2])\n    \n    #combining it into single dataframe\n    idx = np.repeat(r['context'].values, r.qas.str.len())\n#     ndx  = np.repeat(m['id'].values,m['answers'].str.len())\n    m['context'] = idx\n#     js['q_idx'] = ndx\n    main = m[['id','question','context','answers']].set_index('id').reset_index()\n    main['c_id'] = main['context'].factorize()[0]\n    if verbose:\n        print(\"shape of the dataframe is {}\".format(main.shape))\n        print(\"Done\")\n    return main","7a2b841a":"# training data\ninput_file_path = '..\/input\/hindi-xquad\/xquad-hi.json'\nrecord_path = ['data','paragraphs','qas','answers']\ndataset_1 = squad_json_to_dataframe_train(input_file_path=input_file_path,record_path=record_path)","81abf06b":"dataset_1.shape","8fd13807":"dataset_1.head()","825df987":"# dev data\ninput_file_path = '..\/input\/facebook-mlqa\/MLQA_V1\/dev\/dev-context-hi-question-hi.json'\nrecord_path = ['data','paragraphs','qas','answers']\nverbose = 0\ndataset_2 = squad_json_to_dataframe_dev(input_file_path=input_file_path,record_path=record_path)","7de980e0":"dataset_2.head()","cd0cc205":"dataset_2.shape","611d9f8b":"# dev data\ninput_file_path = '..\/input\/facebook-mlqa\/MLQA_V1\/test\/test-context-hi-question-hi.json'\nrecord_path = ['data','paragraphs','qas','answers']\nverbose = 0\ndataset_3 = squad_json_to_dataframe_dev(input_file_path=input_file_path,record_path=record_path)","aa6ef03b":"dataset_3.head()","5f09b59f":"dataset_3.shape","b5039283":"data = pd.concat([dataset_1,dataset_2,dataset_3],ignore_index = True)","2892f273":"data.head()","2cc8799e":"data.shape","e30b74ba":"data.columns","2283385b":"data.drop(['answer_start', 'answers', 'c_id',  'id', 'index', 'text'],inplace = True,axis = 1)","8a03a0b3":"train = data[:6500]\nvalid = data[6500:]\ntrain.reset_index(drop = True,inplace = True)\nvalid.reset_index(drop = True,inplace = True)","5537c32f":"train.head()","2258dd8a":"valid.head()","2ba0dcad":"train.to_csv(\"train.csv\",index = False)\nvalid.to_csv(\"valid.csv\",index = False)","fd335ac3":"Drop unneccesary column not required.","0ec85528":"We have to define a different fuctions for Dev data because the the dev data is slightly different mainly there are multiple possible answer for a single question","1af7844c":"# **Converting data in json format to pandas dataframe format**\nSQuAD dataset is vary convoluted in json format, lets untangle the data and convert it to clean dataframe.\n- I have written different functions for training and dev data as dev data have multiple answers for same questions unlike training data have only single..\n- Try the code to understad the data better","70e32f0a":"Dividing the dataset into two parts.train and valid csv files"}}