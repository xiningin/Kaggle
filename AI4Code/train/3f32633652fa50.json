{"cell_type":{"3ad8d924":"code","7a3b3f49":"code","2b295583":"code","1022f0f9":"code","b1956d94":"code","c81f3030":"code","ec4e2b4b":"code","c2182f2e":"code","d88bba27":"code","d45cafa1":"code","c34c7fb1":"code","4a535f96":"code","b7ea2936":"code","bb894b09":"code","5849a59f":"code","3d849b2c":"code","44c1011c":"code","6df6b028":"code","12f535ca":"code","8453025c":"code","7994d828":"code","7d153db4":"code","5c6b3d44":"code","bfc0329d":"code","b56d70d6":"code","fff7e3cf":"code","536bd107":"code","3b06438f":"markdown","868b588f":"markdown","bc9873c5":"markdown","ce7dd113":"markdown","2a6b3e6c":"markdown","9aaa8cb0":"markdown","a50ffefe":"markdown","e1e7b56b":"markdown","b7ea8d3e":"markdown"},"source":{"3ad8d924":"import numpy as np \nimport pandas as pd\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.inspection import permutation_importance\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","7a3b3f49":"df = pd.read_csv(r'\/kaggle\/input\/mnist-digit-recognizer\/train.csv')\nX = df.drop(['label'], axis=1)\ny = df.label\nX.head(2)","2b295583":"fig, ax = plt.subplots(3,4)\nfor i, axis in enumerate(ax.flat):\n    axis.imshow(X.iloc[i].values.reshape((28,28)))\n    axis.xaxis.set_visible(False)\n    axis.yaxis.set_visible(False)\nplt.show()","1022f0f9":"avgs = X.mean()\nplt.figure(figsize=(10,10))\nplt.imshow(avgs.values.reshape((28,28)))","b1956d94":"sns.countplot(x='label', data=df)","c81f3030":"X.pixel378.hist()","ec4e2b4b":"def mnist_val(model):\n    scores = cross_val_score(model, X, y, cv=5)\n    print(\"Cross Validation score: \", scores.mean())\n    \n    #confusion matrix\ndef mnist_cm(model):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    mat = confusion_matrix(y_test, preds)\n    plt.figure(figsize=(10,10))\n    sns.heatmap(mat, square=True, annot=True, cbar=False, fmt='d',\n               xticklabels=[0,1,2,3,4,5,6,7,8,9],\n               yticklabels=[0,1,2,3,4,5,6,7,8,9])\n    plt.show()","c2182f2e":"dt = DecisionTreeClassifier(ccp_alpha=0.01)","d88bba27":"mnist_cm(dt)","d45cafa1":"plt.figure(figsize=(25,20))\n_ = tree.plot_tree(dt, filled=True,\n                   feature_names=X.columns,\n                   class_names=['0','1','2','3','4','5','6','7','8','9'],\n                  proportion=True,\n                  precision=1,\n                  fontsize=15)\nplt.show()","c34c7fb1":"mnist_val(dt)","4a535f96":"nb = BernoulliNB()","b7ea2936":"mnist_cm(nb)","bb894b09":"mnist_val(nb)","5849a59f":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\nimps = permutation_importance(nb, X_test, y_test)\nimportances = imps.importances_mean\nplt.figure(figsize=(10,10))\nplt.imshow(importances.reshape((28,28)))","3d849b2c":"# Down sample for speed of SVM and kNN algos\ntempX = X.copy()\ntempY = y.copy()\nX = X\/255\nX = X.iloc[::10]\ny = y.iloc[::10]","44c1011c":"for kern in ['linear','poly','rbf','sigmoid']:\n    sm = svm.SVC(kernel=kern, C=10000, cache_size=700, gamma=0.001)\n    print('Accuracy for ', kern)\n    mnist_val(sm)","6df6b028":"lsvm = svm.SVC(kernel='linear', C=0.1)\nmnist_cm(lsvm)","12f535ca":"mnist_val(lsvm)","8453025c":"fig, ax = plt.subplots(4,6,figsize=(15,10))\nfig.tight_layout()\nfor i, axis in enumerate(ax.flat):\n    \n    axis.imshow(lsvm.coef_[i].reshape((28,28)))\n    axis.xaxis.set_visible(False)\n    axis.yaxis.set_visible(False)\n    if i < 9:\n        axis.set_title(\"0 vs \" + str(i+1))\n    elif i < 17:\n        axis.set_title(\"1 vs \" + str(i-7))\n    else:\n        axis.set_title(\"2 vs \" + str(i-14))\nplt.show()","7994d828":"knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\nmnist_val(knn)\nmnist_cm(knn)","7d153db4":"preds = knn.predict(X)","5c6b3d44":"res_df = X.copy()\nres_df['label'] = preds","bfc0329d":"fig, ax = plt.subplots(2,5,figsize=(15,5))\nfig.tight_layout()\nfor i, axis in enumerate(ax.flat):\n    arr = res_df[res_df.label == i]\n    axis.imshow(arr.drop(['label'], axis=1).mean().values.reshape((28,28)))\n    axis.xaxis.set_visible(False)\n    axis.yaxis.set_visible(False)\n    axis.set_title(\"kNN for #\" + str(i))\nplt.show()\n    ","b56d70d6":"#Returning to full dataset\n#X = tempX\n#y = tempY","fff7e3cf":"rf = RandomForestClassifier(n_estimators=100)\nmnist_val(rf)\nmnist_cm(rf)","536bd107":"plt.figure(figsize=(10,10))\nplt.imshow(rf.feature_importances_.reshape((28,28)))\n","3b06438f":"## Loading and Viewing Data","868b588f":"## Creating Support Functions","bc9873c5":"#### Average of all number images","ce7dd113":"## Decision Tree Classifier","2a6b3e6c":"## Naive Bayes","9aaa8cb0":"## k Nearest Neighbors","a50ffefe":"## Support Vector Machine","e1e7b56b":"## Random Forest","b7ea8d3e":"#### Linear is the best"}}