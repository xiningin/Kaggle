{"cell_type":{"378026c9":"code","def595d6":"code","87d346d9":"code","7928c0c7":"code","aedcb935":"code","6958cdee":"code","a2604e2e":"code","245b182a":"code","dd30236d":"code","5e8df054":"code","77b9ee07":"code","a7b56112":"code","62208283":"code","7df3c17a":"code","e0646255":"code","dab9b38a":"code","0b868148":"markdown","28702374":"markdown","ee1db2dc":"markdown","7f4d9cdd":"markdown","67cc1477":"markdown","571eec54":"markdown","040eeb71":"markdown","34f71803":"markdown","73e6b112":"markdown","127a6f3c":"markdown","20f39dd0":"markdown"},"source":{"378026c9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","def595d6":"train = pd.read_csv('..\/input\/train.csv', parse_dates=['date'])\ntest = pd.read_csv('..\/input\/test.csv', parse_dates=['date'])\nprint(\"Train shape: \", train.shape)\nprint(\"Test shape: \", test.shape)","87d346d9":"df = pd.concat([train,test])\ndf['month'] = df['date'].dt.month\ndf['weekday'] = df['date'].dt.dayofweek\ndf['year'] = df['date'].dt.year\ndf['week_of_year']  = train.date.dt.weekofyear\n\ndf.drop('date', axis=1, inplace=True)\ndf.head()","7928c0c7":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\ndf[\"median_store_item_month\"] = df.groupby(['month',\"item\",\"store\"])[\"sales\"].transform(\"median\")\ndf[\"mean_store_item_week\"] = df.groupby(['week_of_year',\"item\",\"store\"])[\"sales\"].transform(\"mean\")\ndf[\"item_month_sum\"] = df.groupby(['month',\"item\"])[\"sales\"].transform(\"sum\")\ndf[\"store_month_sum\"] = df.groupby(['month',\"store\"])[\"sales\"].transform(\"sum\")\ndf[\"item_week_shifted_90\"] = df.groupby(['week_of_year',\"item\"])[\"sales\"].transform(lambda x:x.shift(12).sum()) \ndf[\"store_week_shifted_90\"] = df.groupby(['week_of_year',\"store\"])[\"sales\"].transform(lambda x:x.shift(12).sum()) \ndf[\"item_week_shifted_90\"] = df.groupby(['week_of_year',\"item\"])[\"sales\"].transform(lambda x:x.shift(12).mean()) \ndf[\"store_week_shifted_90\"] = df.groupby(['week_of_year',\"store\"])[\"sales\"].transform(lambda x:x.shift(12).mean())\n\ntrain = df.loc[~df.sales.isna()]\ntrain4 = train.copy()\ntrain4.drop('id', axis=1, inplace=True)\ntrain4.head()\ncorr = train4.corr()\nsns.heatmap(corr, xticklabels=corr.columns,yticklabels=corr.columns)","aedcb935":"train = df.loc[~df.sales.isna()]\ncol = [i for i in train.columns if i not in ['id','store','item']]\n\nfrom sklearn.preprocessing import LabelEncoder\ntrain = train[col].apply(LabelEncoder().fit_transform)\ntrain.head()","6958cdee":"col = [i for i in train.columns if i not in ['id','sales','store','item']]\nX_train=train[col].values\n\nY_train=train['sales'].values\nY_train=Y_train.reshape((913000,1))\n\nprint(\"X_train shape:\", X_train.shape)\nprint(\"Y_train shape:\", Y_train.shape)","a2604e2e":"from sklearn import cross_validation\nx_train, x_test, y_train, y_test = cross_validation.train_test_split(X_train,Y_train, test_size=0.2, random_state=42)\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","245b182a":"import tensorflow as tf\ndef layer(output_dim,input_dim,inputs,activation=None):\n    W = tf.Variable(tf.random_normal([input_dim, output_dim]))\n    b = tf.Variable(tf.random_normal([1, output_dim]))\n    XWb = tf.matmul(inputs, W)+b\n    if activation is None:\n        outputs = XWb\n    else:\n        outputs = activation(XWb)\n    return outputs","dd30236d":"X = tf.placeholder(\"float\", [None, 10])\nh1 = layer(20,10,X,activation=tf.nn.relu)\ny_predict = layer(1, 20, h1, activation=None)\ny_label = tf.placeholder(\"float\", [None, 1]) ","5e8df054":"MSE=tf.losses.mean_squared_error(labels=y_label,predictions=y_predict)\noptimizer = tf.train.GradientDescentOptimizer(0.001).minimize(MSE)","77b9ee07":"SMAPE = tf.reduce_mean(tf.divide(tf.abs(y_predict-y_label),tf.add(y_label,y_predict)))","a7b56112":"import math\ndef batches(batch_size, features,labels):\n    sample_size = len(features)\n    for start_i in range(0, sample_size, batch_size):\n        end_i = start_i + batch_size\n        batch1 = features[start_i:end_i]\n        batch2 = labels[start_i:end_i]\n    return batch1,batch2","62208283":"trainEpochs = 20\nbatchSizes = 1000\ntotalBatchs = int(913000\/batchSizes)\n\nepoch_list = []\nMSE_list = []\nSMAPE_list = []\nfrom time import time\nstartTime = time()\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())","7df3c17a":"for epoch in range(trainEpochs):\n    for i in range(totalBatchs):\n        batch_x, batch_y = batches(batchSizes, x_train, y_train)\n        sess.run(optimizer,feed_dict={X: batch_x, y_label: batch_y})\n    mse,smape = sess.run([MSE,SMAPE],feed_dict={X: x_test,y_label: y_test})\n    epoch_list.append(epoch)\n    MSE_list.append(mse)\n    SMAPE_list.append(smape)\n    print(\"Train Epoch:\", '%02d' % (epoch+1), \"MES=\", \"{:.9f}\".format(mse), \"SMAPE=\", smape)\nduration = time() - startTime\nprint(\"Train Finished takes:\", duration)","e0646255":"%matplotlib inline\nfig = plt.gcf()\nfig.set_size_inches(10,6)\nplt.plot(epoch_list, MSE_list, label='MES')\nplt.ylabel('mean square error')\nplt.xlabel('epoch')\nplt.legend(['mean square error'], loc='upper left')","dab9b38a":"%matplotlib inline\nfig = plt.gcf()\nfig.set_size_inches(10,6)\nplt.plot(epoch_list, SMAPE_list, label='SMAPE')\nplt.ylabel('Symmetric mean absolute percentage error')\nplt.xlabel('epoch')\nplt.legend(['SMAPE'], loc='upper left')","0b868148":"Submissions are evaluated on [SMAPE](https:\/\/en.wikipedia.org\/wiki\/Symmetric_mean_absolute_percentage_error) between forecasts and actual values. We use tensorflow math function to construct SMAPE for session run.","28702374":"Create batch training sets","ee1db2dc":"Now the data format of feature & label are suitable for MLP model.","7f4d9cdd":"# Input Data","67cc1477":"# Data split to training & testing sets","571eec54":"# MLP model","040eeb71":"# Label Encoding","34f71803":"# Date Preprocess","73e6b112":"# Feature Extraction\nAdd historical \/ seasonal features. Thanks to [Dan Ofer's notebook](https:\/\/www.kaggle.com\/danofer\/getting-started-with-time-series-features)","127a6f3c":"<img style=\"float: left;\" src=\"https:\/\/wikimedia.org\/api\/rest_v1\/media\/math\/render\/svg\/399d28f62c6ea8753ff1c2895dd6eb29df0d4ea5\" width = \"30%\">","20f39dd0":"We use MSE (Mean Squared Error) to optimize model by gradient descent."}}