{"cell_type":{"1fe8fa74":"code","6ad1c582":"code","f8298832":"code","7a0a767b":"code","b951d5b3":"code","8dac9b18":"code","286b09ce":"code","90e21b8d":"code","fb9416c1":"code","b1e86930":"code","57c37100":"code","2da17129":"code","952f25b3":"code","926f7a0c":"code","d3830a9f":"code","38a33aff":"code","01963eee":"code","edd9848f":"code","23c43227":"code","c9210f88":"code","5dabdd3e":"code","1e035d15":"code","d23e83da":"code","d2448aa8":"code","0f88fcb1":"code","948eadb5":"code","64264dd0":"code","a481ffbe":"code","519d8a7c":"code","55a940be":"code","9dd28799":"code","7b8d9fc9":"markdown","e9420ed7":"markdown","baa911af":"markdown","a7a92f49":"markdown","0710ce87":"markdown","900b98ea":"markdown","515a66f4":"markdown","45c6d181":"markdown","42fae2d0":"markdown","92337bc2":"markdown","84f07f39":"markdown","fcda9665":"markdown","880adb65":"markdown","c4321c77":"markdown","143f7be7":"markdown","548f4371":"markdown","37189249":"markdown","85472a8e":"markdown","adff4039":"markdown","38eefd04":"markdown","a7265fbd":"markdown","d12e9026":"markdown","3c9d6704":"markdown","5a859d98":"markdown","225ee518":"markdown","fa60f0ea":"markdown","89fe74d9":"markdown","207367e9":"markdown","bb56ca4c":"markdown","96761892":"markdown","47889a42":"markdown"},"source":{"1fe8fa74":"# this is just to know how much time will it take to run this entire ipython notebook \nfrom datetime import datetime\n# globalstart = datetime.now()\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nmatplotlib.use('nbagg')\n\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'figure.max_open_warning': 0})\n\nimport seaborn as sns\nsns.set_style('whitegrid')\nimport os\nfrom scipy import sparse\nfrom scipy.sparse import csr_matrix\n\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport random","6ad1c582":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","f8298832":"start = datetime.now()\n# if os.path.isfile('kaggle\/input\/train_sparse_matrix.npz'):\nprint(\"It is present in your pwd, getting it from disk....\")\n# just get it from the disk instead of computing it\ntrain_sparse_matrix = sparse.load_npz('\/kaggle\/input\/netflix2movie\/train_sparse_matrix.npz')\nprint(\"DONE..\")\n# else: \n#     print(\"We are creating sparse_matrix from the dataframe..\")\n#     # create sparse_matrix and store it for after usage.\n#     # csr_matrix(data_values, (row_index, col_index), shape_of_matrix)\n#     # It should be in such a way that, MATRIX[row, col] = data\n#     train_sparse_matrix = sparse.csr_matrix((train_df.rating.values, (train_df.user.values,\n#                                                train_df.movie.values)),)\n    \n#     print('Done. It\\'s shape is : (user, movie) : ',train_sparse_matrix.shape)\n#     print('Saving it into disk for furthur usage..')\n#     # save it into disk\n#     sparse.save_npz(\"train_sparse_matrix.npz\", train_sparse_matrix)\n#     print('Done..\\n')\n\nprint(datetime.now() - start)","7a0a767b":"us,mv = train_sparse_matrix.shape\nelem = train_sparse_matrix.count_nonzero()\n\nprint(\"Sparsity Of Train matrix : {} % \".format(  (1-(elem\/(us*mv))) * 100) )","b951d5b3":"start = datetime.now()\n# if os.path.isfile('test_sparse_matrix.npz'):\nprint(\"It is present in your pwd, getting it from disk....\")\n# just get it from the disk instead of computing it\ntest_sparse_matrix = sparse.load_npz('\/kaggle\/input\/netflix2movie\/test_sparse_matrix.npz')\nprint(\"DONE..\")\n# else: \n#     print(\"We are creating sparse_matrix from the dataframe..\")\n#     # create sparse_matrix and store it for after usage.\n#     # csr_matrix(data_values, (row_index, col_index), shape_of_matrix)\n#     # It should be in such a way that, MATRIX[row, col] = data\n#     test_sparse_matrix = sparse.csr_matrix((test_df.rating.values, (test_df.user.values,\n#                                                test_df.movie.values)))\n    \n#     print('Done. It\\'s shape is : (user, movie) : ',test_sparse_matrix.shape)\n#     print('Saving it into disk for furthur usage..')\n#     # save it into disk\n#     sparse.save_npz(\"test_sparse_matrix.npz\", test_sparse_matrix)\n#     print('Done..\\n')\n    \nprint(datetime.now() - start)","8dac9b18":"us,mv = test_sparse_matrix.shape\nelem = test_sparse_matrix.count_nonzero()\n\nprint(\"Sparsity Of Test matrix : {} % \".format(  (1-(elem\/(us*mv))) * 100) )","286b09ce":"# get the user averages in dictionary (key: user_id\/movie_id, value: avg rating)\n\ndef get_average_ratings(sparse_matrix, of_users):\n    \n    # average ratings of user\/axes\n    ax = 1 if of_users else 0 # 1 - User axes,0 - Movie axes\n\n    # \".A1\" is for converting Column_Matrix to 1-D numpy array \n    sum_of_ratings = sparse_matrix.sum(axis=ax).A1\n    # Boolean matrix of ratings ( whether a user rated that movie or not)\n    is_rated = sparse_matrix!=0\n    # no of ratings that each user OR movie..\n    no_of_ratings = is_rated.sum(axis=ax).A1\n    \n    # max_user  and max_movie ids in sparse matrix \n    u,m = sparse_matrix.shape\n    # creae a dictonary of users and their average ratigns..\n    average_ratings = { i : sum_of_ratings[i]\/no_of_ratings[i]\n                                 for i in range(u if of_users else m) \n                                    if no_of_ratings[i] !=0}\n\n    # return that dictionary of average ratings\n    return average_ratings","90e21b8d":"train_averages = dict()\n# get the global average of ratings in our train set.\ntrain_global_average = train_sparse_matrix.sum()\/train_sparse_matrix.count_nonzero()\ntrain_averages['global'] = train_global_average\ntrain_averages","fb9416c1":"train_averages['user'] = get_average_ratings(train_sparse_matrix, of_users=True)\nprint('\\nAverage rating of user 10 :',train_averages['user'][10])","b1e86930":"train_averages['movie'] =  get_average_ratings(train_sparse_matrix, of_users=False)\nprint('\\n AVerage rating of movie 15 :',train_averages['movie'][15])","57c37100":"# start = datetime.now()\n# # draw pdfs for average rating per user and average\n# fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=plt.figaspect(.5))\n# fig.suptitle('Avg Ratings per User and per Movie', fontsize=15)\n\n# ax1.set_title('Users-Avg-Ratings')\n# # get the list of average user ratings from the averages dictionary..\n# user_averages = [rat for rat in train_averages['user'].values()]\n# sns.distplot(user_averages, ax=ax1, hist=False, \n#              kde_kws=dict(cumulative=True), label='Cdf')\n# sns.distplot(user_averages, ax=ax1, hist=False,label='Pdf')\n\n# ax2.set_title('Movies-Avg-Rating')\n# # get the list of movie_average_ratings from the dictionary..\n# movie_averages = [rat for rat in train_averages['movie'].values()]\n# sns.distplot(movie_averages, ax=ax2, hist=False, \n#              kde_kws=dict(cumulative=True), label='Cdf')\n# sns.distplot(movie_averages, ax=ax2, hist=False, label='Pdf')\n\n# plt.show()\n# print(datetime.now() - start)","2da17129":"start = datetime.now()\nif not os.path.isfile('\/kaggle\/input\/netflix2movie\/m_m_sim_sparse.npz'):\n    print(\"It seems you don't have that file. Computing movie_movie similarity...\")\n    start = datetime.now()\n    m_m_sim_sparse = cosine_similarity(X=train_sparse_matrix.T, dense_output=False)\n    print(\"Done..\")\n    # store this sparse matrix in disk before using it. For future purposes.\n    print(\"Saving it to disk without the need of re-computing it again.. \")\n#     sparse.save_npz(\"\/kaggle\/input\/m_m_sim_sparse.npz\", m_m_sim_sparse)\n    print(\"Done..\")\nelse:\n    print(\"It is there, We will get it.\")\n    m_m_sim_sparse = sparse.load_npz(\"\/kaggle\/input\/netflix2movie\/m_m_sim_sparse.npz\")\n    print(\"Done ...\")\n\nprint(\"It's a \",m_m_sim_sparse.shape,\" dimensional matrix\")\n\nprint(datetime.now() - start)","952f25b3":"m_m_sim_sparse.shape","926f7a0c":"movie_ids = np.unique(m_m_sim_sparse.nonzero()[1])","d3830a9f":"# start = datetime.now()\n# similar_movies = dict()\n# for movie in movie_ids:\n#     # get the top similar movies and store them in the dictionary\n#     sim_movies = m_m_sim_sparse[movie].toarray().ravel().argsort()[::-1][1:]\n#     similar_movies[movie] = sim_movies[:100]\n# print(datetime.now() - start)\n\n# # just testing similar movies for movie_15\n# similar_movies[15]","38a33aff":"# First Let's load the movie details into soe dataframe..\n# movie details are in 'netflix\/movie_titles.csv'\n\nmovie_titles = pd.read_csv(\"\/kaggle\/input\/netflix3movie\/movie_titles.csv\", sep=',', header = None,\n                           names=['movie_id', 'year_of_release', 'title'], verbose=True,\n                      index_col = 'movie_id', encoding = \"ISO-8859-1\")\n\nmovie_titles.head()","01963eee":"def get_sample_sparse_matrix(sparse_matrix, no_users, no_movies, path, verbose = True):\n    \"\"\"\n        It will get it from the ''path'' if it is present  or It will create \n        and store the sampled sparse matrix in the path specified.\n    \"\"\"\n\n    # get (row, col) and (rating) tuple from sparse_matrix...\n    row_ind, col_ind, ratings = sparse.find(sparse_matrix)\n    users = np.unique(row_ind)\n    movies = np.unique(col_ind)\n\n    print(\"Original Matrix : (users, movies) -- ({} {})\".format(len(users), len(movies)))\n    print(\"Original Matrix : Ratings -- {}\\n\".format(len(ratings)))\n\n    # It just to make sure to get same sample everytime we run this program..\n    # and pick without replacement....\n    np.random.seed(15)\n    sample_users = np.random.choice(users, no_users, replace=False)\n    sample_movies = np.random.choice(movies, no_movies, replace=False)\n    # get the boolean mask or these sampled_items in originl row\/col_inds..\n    mask = np.logical_and( np.isin(row_ind, sample_users),\n                      np.isin(col_ind, sample_movies) )\n    \n    sample_sparse_matrix = sparse.csr_matrix((ratings[mask], (row_ind[mask], col_ind[mask])),\n                                             shape=(max(sample_users)+1, max(sample_movies)+1))\n\n    if verbose:\n        print(\"Sampled Matrix : (users, movies) -- ({} {})\".format(len(sample_users), len(sample_movies)))\n        print(\"Sampled Matrix : Ratings --\", format(ratings[mask].shape[0]))\n\n    print('Saving it into disk for furthur usage..')\n    # save it into disk\n    sparse.save_npz(path, sample_sparse_matrix)\n    if verbose:\n            print('Done..\\n')\n    \n    return sample_sparse_matrix","edd9848f":"start = datetime.now()\npath = \"\/kaggle\/input\/netflix2movie\/final_train_sparse_matrix.npz\"\nif os.path.isfile(path):\n    print(\"It is present in your pwd, getting it from disk....\")\n    # just get it from the disk instead of computing it\n    sample_train_sparse_matrix = sparse.load_npz(path)\n    print(\"DONE..\")\nelse: \n    # get 10k users and 1k movies from available data \n    sample_train_sparse_matrix = get_sample_sparse_matrix(train_sparse_matrix, no_users=22500, no_movies=2700,\n                                             path = path)\n\nprint(datetime.now() - start)","23c43227":"start = datetime.now()\n\npath = \"\/kaggle\/input\/netflix2movie\/final_test_sparse_matrix.npz\"\nif os.path.isfile(path):\n    print(\"It is present in your pwd, getting it from disk....\")\n    # just get it from the disk instead of computing it\n    sample_test_sparse_matrix = sparse.load_npz(path)\n    print(\"DONE..\")\nelse:\n    pass\n    # get 5k users and 500 movies from available data \n#     sample_test_sparse_matrix = get_sample_sparse_matrix(test_sparse_matrix, no_users=5000, no_movies=500,\n#                                                  path = \"sample\/small\/sample_test_sparse_matrix.npz\")\n\nprint(datetime.now() - start)","c9210f88":"sample_train_averages = dict()","5dabdd3e":"# get the global average of ratings in our train set.\nglobal_average = sample_train_sparse_matrix.sum()\/sample_train_sparse_matrix.count_nonzero()\nsample_train_averages['global'] = global_average\nsample_train_averages","1e035d15":"sample_train_averages['user'] = get_average_ratings(sample_train_sparse_matrix, of_users=True)\nprint('\\nAverage rating of user 1515220 :',sample_train_averages['user'][1515220])","d23e83da":"sample_train_averages['movie'] =  get_average_ratings(sample_train_sparse_matrix, of_users=False)\nprint('\\n AVerage rating of movie 15153 :',sample_train_averages['movie'][15153])","d2448aa8":"print('\\n No of ratings in Our Sampled train matrix is : {}\\n'.format(sample_train_sparse_matrix.count_nonzero()))\nprint('\\n No of ratings in Our Sampled test  matrix is : {}\\n'.format(sample_test_sparse_matrix.count_nonzero()))","0f88fcb1":"# get users, movies and ratings from our samples train sparse matrix\nsample_train_users, sample_train_movies, sample_train_ratings = sparse.find(sample_train_sparse_matrix)","948eadb5":"############################################################\n# It took me almost 10 hours to prepare this train dataset.#\n############################################################\nstart = datetime.now()\nif os.path.isfile('\/kaggle\/input\/blabla\/reg_train.csv'):\n    print(\"File already exists you don't have to prepare again...\" )\nelse:\n    print('preparing {} tuples for the dataset..\\n'.format(len(sample_train_ratings)))\n    final_list=[]\n#     with open('\/kaggle\/input\/netflix3movie\/reg_train.csv', mode='w') as reg_data_file:\n    count = 0\n    for (user, movie, rating)  in zip(sample_train_users, sample_train_movies, sample_train_ratings):\n        st = datetime.now()\n    #     print(user, movie)    \n        #--------------------- Ratings of \"movie\" by similar users of \"user\" ---------------------\n        # compute the similar Users of the \"user\"        \n        user_sim = cosine_similarity(sample_train_sparse_matrix[user], sample_train_sparse_matrix).ravel()\n        top_sim_users = user_sim.argsort()[::-1][1:] # we are ignoring 'The User' from its similar users.\n        # get the ratings of most similar users for this movie\n        top_ratings = sample_train_sparse_matrix[top_sim_users, movie].toarray().ravel()\n        # we will make it's length \"5\" by adding movie averages to .\n        top_sim_users_ratings = list(top_ratings[top_ratings != 0][:5])\n        top_sim_users_ratings.extend([sample_train_averages['movie'][movie]]*(5 - len(top_sim_users_ratings)))\n    #     print(top_sim_users_ratings, end=\" \")    \n\n\n        #--------------------- Ratings by \"user\"  to similar movies of \"movie\" ---------------------\n        # compute the similar movies of the \"movie\"        \n        movie_sim = cosine_similarity(sample_train_sparse_matrix[:,movie].T, sample_train_sparse_matrix.T).ravel()\n        top_sim_movies = movie_sim.argsort()[::-1][1:] # we are ignoring 'The User' from its similar users.\n        # get the ratings of most similar movie rated by this user..\n        top_ratings = sample_train_sparse_matrix[user, top_sim_movies].toarray().ravel()\n        # we will make it's length \"5\" by adding user averages to.\n        top_sim_movies_ratings = list(top_ratings[top_ratings != 0][:5])\n        top_sim_movies_ratings.extend([sample_train_averages['user'][user]]*(5-len(top_sim_movies_ratings))) \n    #     print(top_sim_movies_ratings, end=\" : -- \")\n\n        #-----------------prepare the row to be stores in a file-----------------#\n        row = list()\n        row.append(user)\n        row.append(movie)\n        # Now add the other features to this data...\n        row.append(sample_train_averages['global']) # first feature\n        # next 5 features are similar_users \"movie\" ratings\n        row.extend(top_sim_users_ratings)\n        # next 5 features are \"user\" ratings for similar_movies\n        row.extend(top_sim_movies_ratings)\n        # Avg_user rating\n        row.append(sample_train_averages['user'][user])\n        # Avg_movie rating\n        row.append(sample_train_averages['movie'][movie])\n\n        # finalley, The actual Rating of this user-movie pair...\n        row.append(rating)\n        count = count + 1\n\n        # add rows to the file opened..\n#         reg_data_file.write(','.join(map(str, row)))\n#         reg_data_file.write('\\n')    \n        final_list.append(row)\n        if (count)%1000 == 0:\n            # print(','.join(map(str, row)))\n            print(\"Done for {} rows----- {}\".format(count, datetime.now() - start))\n\n\nprint(datetime.now() - start)\n","64264dd0":"pd.DataFrame(final_list).to_csv('final_reg_train_aseem', index=False, header=False)","a481ffbe":"# reg_train = pd.read_csv('sample\/small\/reg_train.csv', names = ['user', 'movie', 'GAvg', 'sur1', 'sur2', 'sur3', 'sur4', 'sur5','smr1', 'smr2', 'smr3', 'smr4', 'smr5', 'UAvg', 'MAvg', 'rating'], header=None)\n# reg_train.head()","519d8a7c":"# get users, movies and ratings from the Sampled Test \nsample_test_users, sample_test_movies, sample_test_ratings = sparse.find(sample_test_sparse_matrix)","55a940be":"start = datetime.now()\n\nif os.path.isfile('\/kaggle\/input\/blabla\/reg_test.csv'):\n    print(\"It is already created...\")\nelse:\n\n    print('preparing {} tuples for the dataset..\\n'.format(len(sample_test_ratings)))\n#     with open('reg_test.csv', mode='w') as reg_data_file:\n    count = 0 \n    final_list_test=[]\n    for (user, movie, rating)  in zip(sample_test_users, sample_test_movies, sample_test_ratings):\n        st = datetime.now()\n\n    #--------------------- Ratings of \"movie\" by similar users of \"user\" ---------------------\n        #print(user, movie)\n        try:\n            # compute the similar Users of the \"user\"        \n            user_sim = cosine_similarity(sample_train_sparse_matrix[user], sample_train_sparse_matrix).ravel()\n            top_sim_users = user_sim.argsort()[::-1][1:] # we are ignoring 'The User' from its similar users.\n            # get the ratings of most similar users for this movie\n            top_ratings = sample_train_sparse_matrix[top_sim_users, movie].toarray().ravel()\n            # we will make it's length \"5\" by adding movie averages to .\n            top_sim_users_ratings = list(top_ratings[top_ratings != 0][:5])\n            top_sim_users_ratings.extend([sample_train_averages['movie'][movie]]*(5 - len(top_sim_users_ratings)))\n            # print(top_sim_users_ratings, end=\"--\")\n\n        except (IndexError, KeyError):\n            # It is a new User or new Movie or there are no ratings for given user for top similar movies...\n            ########## Cold STart Problem ##########\n            top_sim_users_ratings.extend([sample_train_averages['global']]*(5 - len(top_sim_users_ratings)))\n            #print(top_sim_users_ratings)\n        except:\n            print(user, movie)\n            # we just want KeyErrors to be resolved. Not every Exception...\n            raise\n\n\n\n        #--------------------- Ratings by \"user\"  to similar movies of \"movie\" ---------------------\n        try:\n            # compute the similar movies of the \"movie\"        \n            movie_sim = cosine_similarity(sample_train_sparse_matrix[:,movie].T, sample_train_sparse_matrix.T).ravel()\n            top_sim_movies = movie_sim.argsort()[::-1][1:] # we are ignoring 'The User' from its similar users.\n            # get the ratings of most similar movie rated by this user..\n            top_ratings = sample_train_sparse_matrix[user, top_sim_movies].toarray().ravel()\n            # we will make it's length \"5\" by adding user averages to.\n            top_sim_movies_ratings = list(top_ratings[top_ratings != 0][:5])\n            top_sim_movies_ratings.extend([sample_train_averages['user'][user]]*(5-len(top_sim_movies_ratings))) \n            #print(top_sim_movies_ratings)\n        except (IndexError, KeyError):\n            #print(top_sim_movies_ratings, end=\" : -- \")\n            top_sim_movies_ratings.extend([sample_train_averages['global']]*(5-len(top_sim_movies_ratings)))\n            #print(top_sim_movies_ratings)\n        except :\n            raise\n\n        #-----------------prepare the row to be stores in a file-----------------#\n        row = list()\n        # add usser and movie name first\n        row.append(user)\n        row.append(movie)\n        row.append(sample_train_averages['global']) # first feature\n        #print(row)\n        # next 5 features are similar_users \"movie\" ratings\n        row.extend(top_sim_users_ratings)\n        #print(row)\n        # next 5 features are \"user\" ratings for similar_movies\n        row.extend(top_sim_movies_ratings)\n        #print(row)\n        # Avg_user rating\n        try:\n            row.append(sample_train_averages['user'][user])\n        except KeyError:\n            row.append(sample_train_averages['global'])\n        except:\n            raise\n        #print(row)\n        # Avg_movie rating\n        try:\n            row.append(sample_train_averages['movie'][movie])\n        except KeyError:\n            row.append(sample_train_averages['global'])\n        except:\n            raise\n        #print(row)\n        # finalley, The actual Rating of this user-movie pair...\n        row.append(rating)\n        #print(row)\n        count = count + 1\n\n        # add rows to the file opened..\n#         reg_data_file.write(','.join(map(str, row)))\n        #print(','.join(map(str, row)))\n#         reg_data_file.write('\\n') \n        final_list_test.append(row)\n        if (count)%100 == 0:\n            #print(','.join(map(str, row)))\n            print(\"Done for {} rows----- {}\".format(count, datetime.now() - start))\n    print(\"\",datetime.now() - start)  ","9dd28799":"pd.DataFrame(final_list).to_csv('final_reg_test_aseem.csv', index=False, header=False)","7b8d9fc9":"<h3> 3.3.8 Cold Start problem <\/h3>","e9420ed7":"<h2>4.2 Finding Global Average of all movie ratings, Average rating per User, and Average rating per Movie (from sampled train)<\/h2>","baa911af":"<img src='images\/models.jpg' width=500px>","a7a92f49":"<h4> 3.3.7.3 finding average rating per movie<\/h4>","0710ce87":"-----------------------\n\n- __GAvg__ : Average rating of all the ratings \n\n\n- __Similar users rating of this movie__:\n    - sur1, sur2, sur3, sur4, sur5 ( top 5 similar users who rated that movie.. )\n    \n\n\n- __Similar movies rated by this user__:\n    - smr1, smr2, smr3, smr4, smr5 ( top 5 similar movies rated by this movie.. )\n\n\n- __UAvg__ : User's Average rating\n\n\n- __MAvg__ : Average rating of this movie\n\n\n- __rating__ : Rating of this movie by this user.\n\n-----------------------","900b98ea":"<h3>4.2.1 Finding Global Average of all movie ratings<\/h3>","515a66f4":"<h2> 4.3 Featurizing data <\/h2>","45c6d181":"<h4> 3.3.7.4 PDF's & CDF's of Avg.Ratings of Users & Movies (In Train Data)<\/h4>","42fae2d0":"<h3>3.3.7 Finding Global average of all movie ratings, Average rating per user, and Average rating per movie<\/h3>","92337bc2":"<img src='https:\/\/miro.medium.com\/max\/1400\/1*00tVH8JxG3NcaKLJW0DoHA.png'>","84f07f39":"> We might have to handle __346 movies__ (small comparatively) in test data","fcda9665":"<h4> 3.3.7.2 finding average rating per user<\/h4>","880adb65":"<h3> 3.3.6 Creating sparse matrix from data frame <\/h3>","c4321c77":"<p><b>The Sparsity of Train Sparse Matrix<\/b><\/p>","143f7be7":"__Reading from the file to make a Train_dataframe__","548f4371":"<p><b>The Sparsity of Test data Matrix<\/b><\/p>","37189249":"<h3> 3.4.2 Computing Movie-Movie Similarity matrix <\/h3>","85472a8e":"<h3>4.2.2 Finding Average rating per User<\/h3>","adff4039":" <h1> 4.  Machine Learning Models <\/h1>","38eefd04":"<h4> 3.3.6.1 Creating sparse matrix from train data frame <\/h4>","a7265fbd":"<h4> 3.3.6.2 Creating sparse matrix from test data frame <\/h4>","d12e9026":"__ Does Similarity really works as the way we expected...? __ <br>\n_Let's pick some random movie and check for its similar movies...._","3c9d6704":"<h3> 3.4.3 Finding most similar movies using similarity matrix <\/h3>","5a859d98":"<h4> 4.3.1.1 Featurizing train data <\/h4>","225ee518":"<h3>4.1.2 Build sample test data from the test data<\/h3>","fa60f0ea":"- Even though we have similarity measure of each movie, with all other movies, We generally don't care much about least similar movies.\n\n\n- Most of the times, only top_xxx similar items matters. It may be 10 or 100.\n\n\n- We take only those top similar movie ratings and store them  in a saperate dictionary.","89fe74d9":"<h2> 4.1 Sampling Data <\/h2>","207367e9":"<h3>4.2.3 Finding Average rating per Movie<\/h3>","bb56ca4c":"<h4> 3.3.7.1 finding global average of all movie ratings <\/h4>","96761892":"<h3> 4.3.1 Featurizing data for regression problem <\/h3>","47889a42":"<h3>4.1.1 Build sample train data from the train data<\/h3>"}}