{"cell_type":{"df579b48":"code","83ea4a32":"code","e0b03493":"code","0c6de264":"code","690fd82e":"code","9c5a0a10":"code","7cdd8532":"code","ab83b736":"code","d62eb4ed":"code","41a7b9b0":"code","b15f753e":"code","21f70256":"code","3e0cc5b7":"code","56d20641":"markdown"},"source":{"df579b48":"! mkdir -p ~\/.kaggle\n! cp kaggle.json ~\/.kaggle\/\n! chmod 600 ~\/.kaggle\/kaggle.json","83ea4a32":"! pip uninstall --y kaggle\n! pip install --upgrade\n! pip install kaggle==1.5.6","e0b03493":"!kaggle competitions download -c predict-seoul-house-price\n!unzip predict-seoul-house-price.zip","0c6de264":"import numpy as np\nimport torch\nimport torch.optim as optim\nimport pandas as pd\nimport torch.nn.functional as F\nfrom sklearn.preprocessing import MinMaxScaler  # \ub370\uc774\ud130 \uc815\uaddc\ud654\nimport torchvision.datasets as data\nimport torchvision.transforms as transforms\nimport random\nfrom torch.utils.data import  TensorDataset, DataLoader\nimport matplotlib.pyplot as plt","690fd82e":"xy_train = pd.read_csv('train_data.csv', header = None, skiprows=1, usecols=range(4, 8))\nx_data = xy_train.loc[ : , 4:6]\ny_data = xy_train.loc[ : , [7]]\nx_data = np.array(x_data)\ny_data = np.array(y_data)\n\nscaler = MinMaxScaler()\nx_data = scaler.fit_transform(x_data)\n\nx_train = torch.FloatTensor(x_data).to(device)\ny_train = torch.FloatTensor(y_data).to(device) ","9c5a0a10":"train_dataset = TensorDataset(x_train, y_train)\ndata_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n                                           batch_size = batch_size, \n                                           shuffle = True, \n                                           drop_last = True)","7cdd8532":"linear1 = torch.nn.Linear(3, 50,bias=True)\nlinear2 = torch.nn.Linear(50, 50,bias=True)\nlinear3 = torch.nn.Linear(50, 1,bias=True)\n\nrelu = torch.nn.LeakyReLU()\n\ntorch.nn.init.xavier_normal_(linear1.weight)\ntorch.nn.init.xavier_normal_(linear2.weight)\ntorch.nn.init.xavier_normal_(linear3.weight)\n\n\nmodel = torch.nn.Sequential(linear1,relu,\n                            linear2,relu,\n                            linear3).to(device)","ab83b736":"loss = torch.nn.MSELoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n\nlosses = []\nmodel_history = []\nerr_history = []\n\ntotal_batch = len(data_loader)\n\nfor epoch in range(training_epochs + 1):\n  avg_cost = 0\n\n  for X, Y in data_loader:\n    X = X.to(device)\n    Y = Y.to(device)\n\n    optimizer.zero_grad()\n    hypothesis = model(X)\n    cost = loss(hypothesis, Y)\n    cost.backward()\n    optimizer.step()\n\n    avg_cost += cost \/ total_batch\n    \n  model_history.append(model)\n  err_history.append(avg_cost)\n  \n  if epoch % 10 == 0:  \n    print('Epoch:', '%d' % (epoch + 1), 'Cost =', '{:.9f}'.format(avg_cost))\n  losses.append(cost.item())\nprint('Learning finished')\n","d62eb4ed":"plt.plot(losses)\nplt.plot(err_history)\nplt.show()","41a7b9b0":"best_model = model_history[np.argmin(err_history)]","b15f753e":"xy_test = pd.read_csv('test_data.csv', header = None, skiprows=1, usecols = range(4, 7))\nx_data = xy_test.loc[:, 4:6]\nx_data = np.array(x_data)\nx_data = scaler.transform(x_data)\nx_test = torch.FloatTensor(x_data).to(device)\n\nwith torch.no_grad():\n    model.eval()  # \uc8fc\uc758\uc0ac\ud56d (dropout=False)\n    \n    predict = best_model(x_test)","21f70256":"submit = pd.read_csv('submit_form.csv')\nsubmit['price'] = submit['price'].astype(float)\nfor i in range(len(predict)):\n  submit['price'][i] = predict[i]\nsubmit.to_csv('submit.csv', mode = 'w', index = False, header = True)","3e0cc5b7":"!kaggle competitions submit -c predict-seoul-house-price -f submit.csv -m \"\uc138\uc815\"","56d20641":"**\ucc28\uc774\uc810\n\n1. nn\uc7ac\uc124\uacc4 : 3->2->2->2->1 \uc5d0\uc11c 3->50->1\ub85c \uc7ac\uc124\uacc4\n2. \ud65c\uc131\ud568\uc218 \ubcc0\uacbd : relu -> LeakyReLU"}}