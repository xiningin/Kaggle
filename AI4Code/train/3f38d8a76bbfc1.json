{"cell_type":{"a04bb79d":"code","61cb9348":"code","55450170":"code","4a839db9":"code","7c82403b":"code","ffa34785":"code","49b1f537":"code","ab0237f4":"code","4a13a13e":"code","d112e978":"code","f08dc1c1":"code","4f8b9584":"code","2d0d8f3d":"code","508ad235":"code","9dbc290b":"code","aa32da75":"code","f296962e":"code","fe11edc1":"code","8b68d73c":"code","1bdb1b06":"code","3e19dc9e":"code","9e89c4ed":"code","f26da17d":"code","778104e6":"code","27746a7c":"code","2b60e7c9":"code","c4c3471b":"code","7da2d804":"code","9b95adf8":"markdown","44d63c4c":"markdown","b00f85b2":"markdown","f6313c70":"markdown","58b8647c":"markdown","6ba8fe0e":"markdown","953174fe":"markdown","6c2319bf":"markdown","e1c395b2":"markdown"},"source":{"a04bb79d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","61cb9348":"df = pd.read_csv('..\/input\/iris\/Iris.csv', index_col='Id')\ndf","55450170":"from sklearn.preprocessing import LabelEncoder\nlabel_encoder=LabelEncoder()\ndf['Species']=label_encoder.fit_transform(df['Species'])\ndf","4a839db9":"df['Species'].value_counts()","7c82403b":"import tensorflow as tf\ntf.__version__","ffa34785":"df_val = df.sample(frac=0.2, random_state=20)\ndf_train = df.drop(df_val.index)","49b1f537":"df_val","ab0237f4":"df_train ","4a13a13e":"df_train['Species'].value_counts()","d112e978":"df_val.Species.value_counts()","f08dc1c1":"len(df_train), len(df_val)","4f8b9584":"def df_to_dataset(dataframe, target, shuffle=True, batch_size=10):\n    my_df = dataframe.copy()\n    labels = my_df.pop(target)\n    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n    if shuffle:\n        ds = ds.shuffle(buffer_size=len(dataframe))\n    ds = ds.batch(batch_size)\n    return ds    ","2d0d8f3d":"train_ds = df_to_dataset(dataframe=df_train, target='Species')\nval_ds = df_to_dataset(dataframe=df_val, target='Species')","508ad235":"val_ds","9dbc290b":"for b in train_ds.take(1):\n    print(b)","aa32da75":"from tensorflow import feature_column\n\nfeatures = []\nfor col in df_train.columns:\n    if col == 'Species':\n        continue \n    features.append(feature_column.numeric_column(col))\nfeatures","f296962e":"from tensorflow import keras\nmodel = keras.models.Sequential()\nmodel.add(keras.layers.DenseFeatures(features))\nmodel.add(keras.layers.Dense(28, activation='relu'))\nmodel.add(keras.layers.Dense(28, activation='relu'))\nmodel.add(keras.layers.Dense(3, activation='softmax'))","fe11edc1":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', \n             metrics=['accuracy'])","8b68d73c":"model.fit(train_ds, validation_data=val_ds, epochs=100, verbose=0)","1bdb1b06":"model.summary()","3e19dc9e":"model.evaluate(val_ds)","9e89c4ed":"model.predict(val_ds)","f26da17d":"import numpy as np \nnp.argmax(model.predict(val_ds), axis=1)","778104e6":"df.keys()","27746a7c":"new_data = {\n    'SepalLengthCm': [5.0],\n    'SepalWidthCm': [1.2], \n    'PetalLengthCm': [3.5],\n    'PetalWidthCm': [0.7]\n}\nnew_data","2b60e7c9":"input_dict = {name: tf.convert_to_tensor([value]) for name, value in new_data.items()}\ninput_dict","c4c3471b":"model.predict(input_dict)","7da2d804":"np.argmax(model.predict(input_dict))","9b95adf8":"# perpare input features ","44d63c4c":"# Split data into train and val ","b00f85b2":"# Load data ","f6313c70":"# Import TF and check version ","58b8647c":"# fit the model ","6ba8fe0e":"# convert data from DF into tensor data ","953174fe":"# compile model ","6c2319bf":"# Encode Species Column","e1c395b2":"# define the model "}}