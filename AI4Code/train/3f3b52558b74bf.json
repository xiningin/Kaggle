{"cell_type":{"57535cc1":"code","12cc1887":"code","ce6167d1":"code","7a78eb42":"code","fc28d711":"code","340a17d4":"code","be3b99a6":"code","f9753d4a":"code","7a1cf386":"code","fe2585b4":"code","22f6406f":"code","e2b539cf":"code","1160a2d4":"code","eb7f8aba":"code","8a5e37bf":"code","620276e9":"code","bd767d7a":"code","1992179d":"code","e7552940":"code","e5b43678":"code","f2454e4f":"code","4e6b5268":"code","ec662b7c":"code","4414fe57":"code","4121ec20":"code","3a6b2234":"code","308b4470":"code","895a9fed":"code","1d532374":"code","ce67b613":"code","3762adcc":"code","322010c1":"code","ce0296b1":"code","730f644d":"code","b9bc9970":"code","926c3714":"code","c97be344":"markdown","41d45ad7":"markdown","1d181caa":"markdown"},"source":{"57535cc1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","12cc1887":"# Load the data-set.\ndata = pd.read_csv('..\/input\/winequality-red.csv')","ce6167d1":"data.head()","7a78eb42":"data.describe()","fc28d711":"data.info()","340a17d4":"data[data.isnull()].count()","be3b99a6":"plt.figure(figsize=(12,6))\nsns.heatmap(data.corr(),annot=True)","f9753d4a":"data['quality'].unique()","7a1cf386":"from collections import Counter\nCounter(data['quality'])","fe2585b4":"fig = plt.figure(figsize = (10,6))\nplt.hist(data[\"quality\"].values, range=(1, 10))\nplt.xlabel('Ratings of wines')\nplt.ylabel('Amount')\nplt.title('Distribution of wine ratings')\nplt.show()","22f6406f":"Quality_count=[681,638,199,53,18,10]\nQuality_labels=['5','6','7','4','8','3']\nplt.pie(Quality_count,labels=Quality_labels,radius=2,autopct='%0.1f%%',shadow=True)","e2b539cf":"sns.pairplot(data)","1160a2d4":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'fixed acidity', data = data)","eb7f8aba":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'volatile acidity', data = data)","8a5e37bf":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'citric acid', data = data)","620276e9":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'residual sugar', data = data)","bd767d7a":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'chlorides', data = data)","1992179d":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'free sulfur dioxide', data = data)","e7552940":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'sulphates', data = data)","e5b43678":"fig = plt.figure(figsize = (10,6))\nsns.barplot(x = 'quality', y = 'alcohol', data = data)","f2454e4f":"fig = plt.figure(figsize = (10,6))\nsns.pointplot(x=data['pH'].round(1),y='residual sugar',color='green',data=data)","4e6b5268":"fig = plt.figure(figsize = (10,6))\nsns.pointplot(y=data['pH'].round(1),x='quality',color='green',data=data)","ec662b7c":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC,SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\n \nfrom sklearn.model_selection import train_test_split,cross_validate\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler,Imputer,LabelEncoder\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score ","4414fe57":"\nbins = (2, 6.5, 8)\ngroup_names = ['bad', 'good']\ndata['quality'] = pd.cut(data['quality'], bins = bins, labels = group_names)","4121ec20":"label_quality = LabelEncoder()","3a6b2234":"data['quality'] = label_quality.fit_transform(data['quality'])","308b4470":"x_train,x_test,y_train,y_test=train_test_split(data.drop('quality',axis=1),data['quality'],test_size=0.25,random_state=42)\n\nmodels=[LogisticRegression(),\n        LinearSVC(),\n        SVC(kernel='rbf'),\n        KNeighborsClassifier(),\n        RandomForestClassifier(),\n        DecisionTreeClassifier(),\n        GradientBoostingClassifier(),\n        GaussianNB()]\n\nmodel_names=['LogisticRegression',\n             'LinearSVM',\n             'rbfSVM',\n             'KNearestNeighbors',\n             'RandomForestClassifier',\n             'DecisionTree',\n             'GradientBoostingClassifier',\n             'GaussianNB']\n\nacc=[]\nd={}\n\nfor model in range(len(models)):\n    classification_model=models[model]\n    classification_model.fit(x_train,y_train)\n    pred=classification_model.predict(x_test)\n    acc.append(accuracy_score(pred,y_test))\n     \nd={'Modelling Algorithm':model_names,'Accuracy':acc}\nd","895a9fed":"acc_table=pd.DataFrame(d)\nacc_table","1d532374":"sns.barplot(y='Modelling Algorithm',x='Accuracy',data=acc_table)","ce67b613":"sns.factorplot(x='Modelling Algorithm',y='Accuracy',data=acc_table,kind='point',size=4,aspect=3.5)","3762adcc":"def func(x_train,x_test,y_train,y_test,name_scaler):\n    models=[LogisticRegression(),LinearSVC(),SVC(kernel='rbf'),KNeighborsClassifier(),RandomForestClassifier(),\n        DecisionTreeClassifier(),GradientBoostingClassifier(),GaussianNB()]\n    acc_sc=[]\n    for model in range(len(models)):\n        classification_model=models[model]\n        classification_model.fit(x_train,y_train)\n        pred=classification_model.predict(x_test)\n        acc_sc.append(accuracy_score(pred,y_test))\n     \n    acc_table[name_scaler]=np.array(acc_sc)","322010c1":"scalers=[MinMaxScaler(),StandardScaler()]\nnames=['Acc_Min_Max_Scaler','Acc_Standard_Scaler']\nfor scale in range(len(scalers)):\n    scaler=scalers[scale]\n    scaler.fit(data)\n    scaled_data=scaler.transform(data)\n    X=scaled_data[:,0:11]\n    Y=data['quality'].values\n    x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=42)\n    func(x_train,x_test,y_train,y_test,names[scale])","ce0296b1":"acc_table","730f644d":"sns.barplot(y='Modelling Algorithm',x='Accuracy',data=acc_table)","b9bc9970":"sns.barplot(y='Modelling Algorithm',x='Acc_Standard_Scaler',data=acc_table)","926c3714":"sns.barplot(y='Modelling Algorithm',x='Acc_Min_Max_Scaler',data=acc_table)","c97be344":"Note that here the accuracies increase marginally on scaling.\nAlso for this data, StandardScaling seems to give slightly better results than the MinMaxScaling.\nFor some modelling algos there is a considerable increase in accuracies upon scaling the features like SVM, KNN wheras for others there isn't a considerable increase in accuracies upon scaling.","41d45ad7":"### NOTE THAT THIS IS WITHOUT FEATURE SCALING. NOW SINCE FEATURES HAVE DIFFERENT SCALES LET US TRY TO DO FEATURE SCALING AND SEE THE IMPACT","1d181caa":"### NOW THIS CLEARLY SHOWS THE ACCUARCIES OF DIFFERENT MODELLING ALGOS ON USING DIFFERENT SCALERS."}}