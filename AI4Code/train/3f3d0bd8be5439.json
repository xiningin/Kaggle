{"cell_type":{"8dc4d515":"code","610fc2d4":"code","ee1aebf0":"code","4df4746b":"code","ae50647d":"code","4fa86e07":"code","ab161c5a":"code","b29b295c":"code","cb2adf80":"code","2b48c1de":"code","d237b32d":"code","91340997":"code","f9719727":"code","609ef39c":"markdown","9137f523":"markdown","7ee938da":"markdown","757dea58":"markdown","33be011f":"markdown","e526a6cb":"markdown","b12d2d93":"markdown","d42abbef":"markdown","a43401b7":"markdown","69d22dfc":"markdown","5c8625d6":"markdown","e6baf898":"markdown"},"source":{"8dc4d515":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport glob\nimport cv2\nimport os\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/fruits-360\/Training'):\n    i = 0\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        i += 1 \n        if i == 1:\n            break\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","610fc2d4":"np.random.seed(1234)\ndirectory=\"\/kaggle\/input\/fruits-360\/Training\/\"\nclasses=[\"Apple Golden 1\",\"Avocado\",\"Banana\",\"Cherry 1\",\"Cocos\",\"Kiwi\",\n         \"Lemon\",\"Mango\",\"Orange\"]\n\nall_arrays=[]\nimg_size=100\nfor i in classes:\n    path=os.path.join(directory,i)\n    class_num=classes.index(i)\n    for img in os.listdir(path):\n        img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n        img_array=cv2.resize(img_array,(img_size,img_size))\n        all_arrays.append([img_array,class_num])","ee1aebf0":"directory2=\"\/kaggle\/input\/fruits-360\/Test\/\"\nclasses2=[\"Apple Golden 1\",\"Avocado\",\"Banana\",\"Cherry 1\",\"Cocos\",\"Kiwi\",\n         \"Lemon\",\"Mango\",\"Orange\"]\n\nall_arrays2=[]\nimg_size=100\nfor i in classes2:\n    path=os.path.join(directory2,i)\n    class_num2=classes2.index(i)\n    for img in os.listdir(path):\n        img_array2=cv2.imread(os.path.join(path,img),\n                             cv2.IMREAD_GRAYSCALE)\n        img_array2=cv2.resize(img_array2,(img_size,img_size))\n        all_arrays2.append([img_array2,class_num2])","4df4746b":"fruits_array_train=[]\nfor features,label in all_arrays:\n    fruits_array_train.append(features)\n\nlocation=[[1,500,1150],[1500,2000,2500],[3000,3500,4000]]\nfruit_names=[\"Apple\",\"Avocado\",\"Banana\",\"Cherry\",\"Cocos\",\"Kiwi\",\"Lemon\",\"Mango\",\"Orange\"]\na=0\nb=1\nc=2\nfor i,j,k in location:\n    plt.subplots(figsize=(8,8))\n    plt.subplot(1,3,1)\n    plt.imshow(fruits_array_train[i])\n    plt.title(fruit_names[a])\n    plt.axis(\"off\")\n    plt.subplot(1,3,2)\n    plt.imshow(fruits_array_train[j])\n    plt.title(fruit_names[b])\n    plt.axis(\"off\")\n    plt.subplot(1,3,3)\n    plt.imshow(fruits_array_train[k])\n    plt.title(fruit_names[c])\n    plt.axis(\"off\")\n    a+=3\n    b+=3\n    c+=3","ae50647d":"import random\nrandom.shuffle(all_arrays)\n\nX_train=[]\nY_train=[]\nfor features,label in all_arrays:\n    X_train.append(features)\n    Y_train.append(label)\nX_train=np.array(X_train) #arraying\n\nimport random\nrandom.shuffle(all_arrays2)\n\nX_test=[]\nY_test=[]\nfor features,label in all_arrays2:\n    X_test.append(features)\n    Y_test.append(label)\nX_test=np.array(X_test) #arraying\n","4fa86e07":"#normalization and reshaping\nX_train=X_train.reshape(-1,img_size,img_size,1)\nX_train=X_train\/255\nX_test=X_test.reshape(-1,img_size,img_size,1)\nX_test=X_test\/255\nprint(\"shape of X_train= \",X_train.shape)\nprint(\"shape of X_test=  \",X_test.shape)","ab161c5a":"from keras.utils import to_categorical\nY_train=to_categorical(Y_train,num_classes=9)\nY_test=to_categorical(Y_test,num_classes=9)","b29b295c":"from sklearn.model_selection import  train_test_split\nx_train,x_val,y_train,y_val=train_test_split(X_train,Y_train,test_size=0.2,random_state=42)","cb2adf80":"from sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\n\nmodel=Sequential()\nmodel.add(Conv2D(filters=8,kernel_size=(5,5),padding=\"Same\",activation=\"relu\",input_shape=(100,100,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=16,kernel_size=(4,4),padding=\"Same\",activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=32,kernel_size=(4,4),padding=\"Same\",activation=\"relu\"))\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(512,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(9,activation=\"softmax\"))\n#defining optimizer\noptimizer=Adam(lr=0.001,beta_1=0.9,beta_2=0.999)\n#compile the model\nmodel.compile(optimizer=optimizer,loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n\nepochs=5\nbatch_size=50","2b48c1de":"datagen=ImageDataGenerator(featurewise_center=False, #set input mean to 0\n                           samplewise_center=False,  #set each sample mean to 0\n                           featurewise_std_normalization=False, #divide input datas to std\n                           samplewise_std_normalization=False,  #divide each datas to own std\n                           zca_whitening=False,  #dimension reduction\n                           rotation_range=0.5,    #rotate 5 degree\n                           zoom_range=0.5,        #zoom in-out 5%\n                           width_shift_range=0.5, #shift 5%\n                           height_shift_range=0.5,\n                           horizontal_flip=False,  #randomly flip images\n                           vertical_flip=False,\n                           )\ndatagen.fit(x_train)\n\n#model fitting\nhistory=model.fit_generator(datagen.flow(x_train,y_train,batch_size=batch_size),epochs=epochs,\n                            validation_data=(x_val,y_val),steps_per_epoch=x_train.shape[0]\/\/batch_size\n                           )\n","d237b32d":"plt.plot(history.history[\"val_acc\"],color=\"r\",label=\"val_acc\")\nplt.title(\"Accuracy Graph\")\nplt.xlabel(\"number of epochs\")\nplt.ylabel(\"accuracy\")\nplt.legend()\nplt.grid()\nplt.show()","91340997":"#confusion matrix\ny_pred=model.predict(x_val)\ny_pred_classes=np.argmax(y_pred,axis=1)\ny_true=np.argmax(y_val,axis=1)\n#compute conf mat\nconf_mat=confusion_matrix(y_true,y_pred_classes)\n#plot the con mat\nfruit_names=[\"Apple\",\"Avocado\",\"Banana\",\"Cherry\",\"Cocos\",\"Kiwi\",\"Lemon\",\"Mango\",\"Orange\"]\nf,ax=plt.subplots(figsize=(10,9))\nsns.heatmap(conf_mat,annot=True,fmt='.0f')\nax.set_xticklabels(fruit_names)\nax.set_yticklabels(fruit_names)\nplt.show()\n","f9719727":"#confusion matrix\ny_pred2=model.predict(X_test)\ny_pred_classes2=np.argmax(y_pred2,axis=1)\ny_true2=np.argmax(Y_test,axis=1)\n#compute conf mat\nconf_mat2=confusion_matrix(y_true2,y_pred_classes2)\n#plot the con mat\nf,ax=plt.subplots(figsize=(10,9))\nsns.heatmap(conf_mat2,annot=True,fmt=\".0f\")\nax.set_xticklabels(fruit_names)\nax.set_yticklabels(fruit_names)\nplt.show()\n","609ef39c":"While reshaping we added gray scale.","9137f523":"At the beginning we had only images, not any dataframe or any array from. We used os and cv2 libraries to created our array form. ","7ee938da":"We converted our labels to one-hot-encoding values. 3 ----->(0,0,0,1,0,0,0,0,0,0) etc","757dea58":"**Image examples of our data:**","33be011f":"We can see error values on train data","e526a6cb":"We created our X features and Y labels. Also we used shuffle function to mix our dataset.","b12d2d93":"After 35 iteration we have a high accuracy around 99%","d42abbef":"With train_test_split we separated our datas to train and validation datas.","a43401b7":"Let's go with data augmentation. In this section we add different shapes of our images. We will use **zooming,shifting,rotating,fliping** methods in order to avoid **overfitting**.                                                             \nFor example we will add a image of banana with 5 degrees rotated.","69d22dfc":"We connected our labels-layers with keras library. With Dense we added hidden layers. We avoided overfitting thanks to Dropout. With relu function we don't have variance around zero.","5c8625d6":"Here we checked errors on test data. We have the highest erros between Apple and Lemon. In fact it could be results of the colors. ","e6baf898":"In conclusion we used CNN method to check nine types of fruit. We have an accuracy. around 100% and it is really acceptable.\nIf you have any question feel free to contact with me."}}