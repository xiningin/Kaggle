{"cell_type":{"8a6f00f7":"code","c92ab0e0":"code","5821e824":"code","6420e34c":"code","f45bc5c1":"code","5881a53b":"code","7667dccb":"code","692c20e4":"code","763ad102":"code","9fd09654":"code","57c9186c":"code","768fbad8":"code","06903b03":"code","3cbe7521":"code","156bc64d":"code","23a13c12":"code","7c9719df":"code","cf3c77ec":"code","5db5a6e7":"code","814db51e":"code","d8af1d57":"markdown","d22a9809":"markdown","1a08238d":"markdown","aa812492":"markdown"},"source":{"8a6f00f7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c92ab0e0":"!apt-get update -qq > \/dev\/null\n!apt-get install openjdk-8-jdk-headless -qq > \/dev\/null","5821e824":"!wget -q https:\/\/www-us.apache.org\/dist\/spark\/spark-3.1.1\/spark-3.1.1-bin-hadoop2.7.tgz\n!tar xf spark-3.1.1-bin-hadoop2.7.tgz\n!pip install -q findspark","6420e34c":"!du -sh \/usr\/lib\/jvm\/java-8-openjdk-amd64","f45bc5c1":"!ls -la \/usr\/lib\/jvm\/java-8-openjdk-amd64","5881a53b":"import os\nos.environ[\"JAVA_HOME\"] = \"\/usr\/lib\/jvm\/java-8-openjdk-amd64\"\nos.environ[\"SPARK_HOME\"] = \".\/spark-3.1.1-bin-hadoop2.7\"","7667dccb":"import findspark\nfindspark.init()\n# Creating spark session \nfrom pyspark.sql import SparkSession\nfrom pyspark.conf import SparkConf\nfrom pyspark.sql import functions as f\nfrom pyspark.sql.functions import col, when, avg\n\nspark = SparkSession.builder.appName(\"movieRecommendationPyspark\").getOrCreate()","692c20e4":"train = (spark.read.csv(path = \"..\/input\/uit-spring-2021-ds200-assignment-8\/ratings.csv\",\n                          sep = \",\",\n                          header = True,\n                          quote = '\"',\n                          schema = \"userId INT, movieId INT, rating DOUBLE, timestamp INT\").select(\"userId\", \"movieId\", \"rating\").cache())","763ad102":"test = (spark.read.csv(path = \"..\/input\/uit-spring-2021-ds200-assignment-8\/test.csv\",\n                          sep = \",\",\n                          header = True,\n                          quote = '\"',\n                          schema = \"ratingId INT, userId INT, movieId INT\").cache())","9fd09654":"from pyspark.ml.recommendation import ALS\nfrom pyspark.ml.evaluation import RegressionEvaluator","57c9186c":"als = ALS(userCol=\"userId\",\n          itemCol=\"movieId\",\n          ratingCol=\"rating\", rank=20, maxIter=20, regParam=0.05, seed=33)\n\nmodel = als.fit(train)\npredictions = model.transform(test)","768fbad8":"avg = train.groupBy('movieId').agg(avg(col('rating')).alias('avg'))\ntrain.unpersist()","06903b03":"pred = predictions.join(avg, on='movieId', how='left')","3cbe7521":"# pred1 = predictions.na.fill(3.75, ['prediction'])\n# pred1 = pred1.withColumn(\"prediction\", when(col(\"prediction\")<1, 0.5).when(col(\"prediction\")>5, 5).otherwise(col(\"prediction\")))\n# pred1 = pred1.withColumnRenamed('prediction', 'rating')","156bc64d":"# pred1 = predictions.na.fill(3.738, ['prediction']).withColumn(\"prediction\", when(col(\"prediction\")<0.55, 0.5).when(col(\"prediction\")>5, 5).otherwise(col(\"prediction\"))).withColumnRenamed('prediction', 'rating')","23a13c12":"pred1 = pred.withColumn('prediction',when(col('prediction')=='NaN',col('avg')).otherwise(col('prediction'))).na.fill(3.738, ['prediction']).withColumn(\"prediction\", when(col(\"prediction\")<0.55, 0.5).when(col(\"prediction\")>5, 5).otherwise(col(\"prediction\"))).withColumnRenamed('prediction', 'rating')","7c9719df":"submit = pred1.select(\"ratingId\", \"rating\").sort('ratingId')\n# submit.show()","cf3c77ec":"avg.unpersist()\ntest.unpersist()\npred1.unpersist()","5db5a6e7":"submit.toPandas().to_csv('submission1.csv', header=True, index=False)","814db51e":"!rm -r .\/spark-3.1.1-bin-hadoop2.7\n!rm -r .\/spark-3.1.1-bin-hadoop2.7.tgz","d8af1d57":"# Import dataset","d22a9809":"# Training model","1a08238d":"# V\u00f5 Linh B\u1ea3o - 18520503\n# H\u00e0 V\u0103n Lu\u00e2n - 18521062","aa812492":"# Import libraris"}}