{"cell_type":{"3c18f538":"code","92466c75":"code","2b4ca67d":"code","8ba8bb24":"code","cf09bbd4":"code","c4d3002f":"code","423f1cb8":"code","7ff07105":"code","7abf2d40":"code","0ebac1ac":"code","688afda7":"code","707ae646":"code","6d58e311":"code","722cf7a3":"code","7ac5b281":"code","a3b4eb50":"code","8a4ea343":"code","2ee424e9":"code","b4b4bb16":"code","9b0a0423":"code","59e815cc":"markdown","1fb6b7d2":"markdown","9d16439d":"markdown","1753752c":"markdown","e97f540b":"markdown","e732b96f":"markdown","8e302af0":"markdown","8c4e73e4":"markdown"},"source":{"3c18f538":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","92466c75":"housing_unadjusted = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\nhousing = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\nhousing.head()","2b4ca67d":"housing.columns.values ","8ba8bb24":"corr_matrix = housing.corr()\ncorr_matrix['SalePrice'].sort_values(ascending=False).tail()","cf09bbd4":"#Adding more important features\nhousing['TotalSF'] = housing['TotalBsmtSF'] + housing['1stFlrSF'] + housing['2ndFlrSF']","c4d3002f":"#Deleting outliers\nhousing = housing.drop(housing[(housing['GrLivArea']>4000) & (housing['SalePrice']<300000)].index)\nhousing = housing.drop(housing[(housing['TotalBsmtSF']>4000) & (housing['SalePrice']<300000)].index)","423f1cb8":"housing_data = housing.drop(['Id',\"SalePrice\"], axis=1)\nhousing_labels = housing[\"SalePrice\"]","7ff07105":"housing_val = housing_data.loc[:,housing_data.dtypes!=np.object] # Value Data\nhousing_val.head()","7abf2d40":"housing_cat = housing_data.loc[:,housing_data.dtypes==np.object] # Categorical Data\nhousing_cat = housing_cat.fillna('missing')\nhousing_cat.head()","0ebac1ac":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn_pandas import CategoricalImputer\n\n\nnum_pipeline = Pipeline([\n        ('imputer', SimpleImputer(strategy=\"median\")),\n        ('std_scaler', StandardScaler()),\n    ])\n\ncat_pipeline = Pipeline([\n        ('cat_imputer',  CategoricalImputer(strategy='constant',fill_value='missing')),\n        ('one_hot',  OneHotEncoder(handle_unknown='ignore')),\n    ])\n","688afda7":"full_pipeline = ColumnTransformer([\n        (\"num\", num_pipeline, list(housing_val)),\n        (\"cat\", cat_pipeline, list(housing_cat)),\n    ])\n\nhousing_prepared = full_pipeline.fit_transform(housing_data)","707ae646":"from sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import cross_val_score\n\ngbrt = GradientBoostingRegressor(max_depth=2, n_estimators=500, learning_rate=0.2, random_state=42)\ngbrt.fit(housing_prepared, housing_labels)\n\ngbrt_scores = cross_val_score(gbrt, housing_prepared, housing_labels,scoring=\"neg_mean_squared_error\", cv=5)\nnp.sqrt(-gbrt_scores).mean()\/housing_unadjusted['SalePrice'].mean()","6d58e311":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\nforest_reg = RandomForestRegressor(bootstrap=False, max_features = 6,n_estimators=30, random_state=42)\n#forest_reg = RandomForestRegressor(bootstrap=False, max_features = 79,n_estimators=500, random_state=42)\n#forest_reg.fit(housing_prepared, housing_labels)\n\nforest_score = cross_val_score(forest_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=5)\n\nnp.sqrt(-forest_score).mean()\/housing_unadjusted['SalePrice'].mean()","722cf7a3":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    # try 12 (3\u00d74) combinations of hyperparameters\n    #{'n_estimators': [50], 'max_features': [10]},\n    # then try 6 (2\u00d73) combinations with bootstrap set as False\n    {'bootstrap': [False], 'n_estimators': [50,500], 'max_features': [10,79]},\n  ]\n\nforest_reg = RandomForestRegressor(random_state=42)\n# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \ngrid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n                           scoring='neg_mean_squared_error',\n                           return_train_score=True)\ngrid_search.fit(housing_prepared, housing_labels)","7ac5b281":"grid_search.best_params_","a3b4eb50":"cvres = grid_search.cv_results_\nfor mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n    print(np.sqrt(-mean_score), params)","8a4ea343":"test = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntest_in = test.drop(\"Id\",axis =1)\ntest_in['TotalSF'] = test_in['TotalBsmtSF'] + test_in['1stFlrSF'] + test_in['2ndFlrSF']","2ee424e9":"test_prep = full_pipeline.transform(test_in)\nhousing_predictions = gbrt.predict(test_prep)","b4b4bb16":"result = test[['Id']]\nresult['SalePrice'] = housing_predictions\nresult","9b0a0423":"result.to_csv(\"\/kaggle\/working\/mysubmission.csv\", index = False)","59e815cc":"## Fine Tune Hyperparameters","1fb6b7d2":"The following great notebooks have been used:\nhttps:\/\/www.kaggle.com\/pmarcelino\/comprehensive-data-exploration-with-python\nhttps:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard","9d16439d":"## Evaluate Training Set","1753752c":"# Data Cleaning","e97f540b":"# Select and train models","e732b96f":"# Feature Engineering","8e302af0":"# Data Aquisition","8c4e73e4":"# Data Exploration\n"}}