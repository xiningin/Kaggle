{"cell_type":{"38c0039b":"code","349880e2":"code","02a58c33":"code","90158d46":"code","c8d2c627":"code","cea4d58b":"code","f4d43ecb":"code","37e055e2":"code","69ab227f":"code","98d798f6":"code","2f11c317":"code","32f41c5e":"code","f3d83e9e":"code","e45266c2":"markdown","8c8b209b":"markdown","ae2f0940":"markdown","9bdaec01":"markdown"},"source":{"38c0039b":"import random\nimport os\nimport time\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\nfrom tqdm import tqdm\nfrom sklearn.model_selection import *\nfrom transformers import *\n","349880e2":"CFG = {\n    'fold_num': 5, \n    'seed': 42,\n    'model': '..\/input\/roberta-base',\n    'max_len': 512,\n    'epochs': 5,\n    'train_bs': 24,\n    'valid_bs': 32,\n    'lr': 2e-5,\n    'num_workers': 0,\n    'weight_decay': 1e-6,\n}","02a58c33":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(CFG['seed'])\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","90158d46":"label_list = ['o', 'B-Lead', 'I-Lead', 'B-Position', 'I-Position', 'B-Claim', 'I-Claim', 'B-Counterclaim', 'I-Counterclaim', \n          'B-Rebuttal', 'I-Rebuttal', 'B-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement']\nlabel_encoding_dict = {'o': 1,\n                       'B-Lead': 2,\n                       'I-Lead': 3,\n                       'B-Position': 4,\n                       'I-Position': 5,\n                       'B-Claim': 6,\n                       'I-Claim': 7,\n                       'B-Counterclaim': 8, 'I-Counterclaim': 9,\n                       'B-Rebuttal': 10, 'I-Rebuttal': 11,\n                       'B-Evidence': 12, 'I-Evidence': 13, 'B-Concluding Statement': 14,\n                       'I-Concluding Statement' :15\n                       \n                      }\n","c8d2c627":"tokenizer = AutoTokenizer.from_pretrained(CFG['model'], add_prefix_space=True)","cea4d58b":"model =  AutoModelForTokenClassification.from_pretrained(CFG['model'], num_labels=15).to(device)\nmodel.load_state_dict(torch.load('..\/input\/robertafeedbackbaseline\/roberta-baseline.pt'))\nmodel.eval()","f4d43ecb":"test_names, test_texts = [], []\nfor f in tqdm(list(os.listdir('..\/input\/feedback-prize-2021\/test'))):\n    test_names.append(f.replace('.txt', ''))\n    test_texts.append(open('..\/input\/feedback-prize-2021\/test\/' + f, 'r').read())\ntest_texts = pd.DataFrame({'id': test_names, 'text': test_texts})\ntest_texts['text'] = test_texts['text'].apply(lambda x:x.split())\ntest_texts","37e055e2":"class MyDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        text = self.df.text.values[idx]\n        \n        return text\ndef collate_fn(data):\n    tokenized_inputs = tokenizer(\n        data,\n        max_length=CFG['max_len'],\n        padding='max_length',\n        truncation=True,\n        is_split_into_words=True,\n        return_tensors='pt'\n    )\n\n    words = []\n    for i in range(len(data)):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        words.append(word_ids)\n\n    tokenized_inputs[\"word_ids\"] = words\n    return tokenized_inputs\n","69ab227f":"test_loader = DataLoader(MyDataset(test_texts), batch_size=CFG['valid_bs'], collate_fn=collate_fn, shuffle=False, num_workers=2)\nbatch = next(iter(test_loader))\nbatch","98d798f6":"y_pred = []\nwords = []\n\nwith torch.no_grad():\n    tk = tqdm(test_loader, total=len(test_loader), position=0, leave=True)\n    for step, batch in enumerate(tk):\n        word_ids = batch['word_ids']\n        words.extend(word_ids)\n        batch = {k: v.to(device) for k, v in batch.items() if k != 'word_ids'}\n\n        output = model(**batch).logits\n\n        y_pred.extend(output.argmax(-1).cpu().numpy())\n        \ny_pred = np.array(y_pred)","2f11c317":"final_preds = []\n\nfor i in tqdm(range(len(test_texts))):\n    idx = test_texts.id.values[i]\n    pred = ['']*len(test_texts.text.values[i])\n\n    for j in range(len(y_pred[i])):\n        if words[i][j] != None:\n            pred[words[i][j]] = label_list[y_pred[i][j]]\n\n    pred = [x.replace('B-','').replace('I-','') for x in pred]\n\n    preds = []\n    j = 0\n    while j < len(pred):\n        cls = pred[j]\n        if cls == 'o':\n            j += 1\n        end = j + 1\n        while end < len(pred) and pred[end] == cls:\n            end += 1\n            \n        if cls != 'o' and cls != '' and end - j > 10:\n            final_preds.append((idx, cls, ' '.join(map(str, list(range(j, end))))))\n        \n        j = end\n        \nfinal_preds[0]","32f41c5e":"test_df = pd.read_csv('..\/input\/feedback-prize-2021\/sample_submission.csv')\nsub = pd.DataFrame(final_preds)\nsub.columns = test_df.columns\nsub","f3d83e9e":"sub.to_csv('submission.csv', index=False)","e45266c2":"\n### Please upvote if you find the notebook useful","8c8b209b":"### Inference Loop","ae2f0940":"Thanks for the notebook\nhttps:\/\/www.kaggle.com\/zzy990106\/pytorch-ner-infer.\n\nThe training notebook can be found here\nhttps:\/\/www.kaggle.com\/revathiprakash\/feedback-prize-baseline-ner-pytorch-train\n","9bdaec01":"#### A simple Roberta hugging face NER based approach"}}