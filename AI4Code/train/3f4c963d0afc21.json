{"cell_type":{"bc7db850":"code","0a932bdc":"code","387b6d91":"code","06271a65":"code","f6ec753d":"code","5f0bc98c":"code","b4311b8a":"code","03ddc745":"code","3acf1f1b":"code","908b4d0c":"code","007cd990":"code","94bcf4da":"code","0ee855fb":"code","e24f031e":"code","f048dedd":"code","aab2fb88":"code","6a9bf28d":"code","bf33fb84":"code","6a8f71b9":"code","3b9218ec":"code","c5db3940":"code","92c44d63":"code","32f35bc8":"code","d646a2d4":"code","26c46305":"code","68dc21ab":"code","7f2118b2":"markdown"},"source":{"bc7db850":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport optuna\n\nimport pickle\nimport lightgbm as lgbm\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n#plt.style.use('fivethirtyeight')\nimport xgboost as xgb\nimport sklearn\nimport tqdm\nimport random\nimport janestreet\nimport tensorflow as tf\nimport datatable","0a932bdc":"SEED=1111","387b6d91":"random.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","06271a65":"train = datatable.fread('..\/input\/jane-street-market-prediction\/train.csv').to_pandas()","f6ec753d":"train.shape","5f0bc98c":"train.head(50)","b4311b8a":"#train = train.drop(['feature_113','feature_89','feature_101'], 1)","03ddc745":"train = train.query('date > 85').reset_index(drop = True) \ntrain = train[train['weight'] != 0]\n\n#train.fillna(train.mean(),inplace=True)\n\ntrain['action'] = ((train['resp'].values) > 0).astype(int)\n\n\nfeatures = [c for c in train.columns if \"feature\" in c]\n","3acf1f1b":"train.fillna(train.mean(),inplace=True)     ","908b4d0c":"features.remove('feature_0')\n","007cd990":"len(features)","94bcf4da":"train.shape","0ee855fb":"train['resp'] = (((train['resp'].values)*train['weight']) > 0).astype(int)\ntrain['resp_1'] = (((train['resp_1'].values)*train['weight']) > 0).astype(int)\ntrain['resp_2'] = (((train['resp_2'].values)*train['weight']) > 0).astype(int)\ntrain['resp_3'] = (((train['resp_3'].values)*train['weight']) > 0).astype(int)\ntrain['resp_4'] = (((train['resp_4'].values)*train['weight']) > 0).astype(int)","e24f031e":"\nf_mean = np.mean(train[features[1:]].values,axis=0)\n\nresp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp']\n\n#X_train = train.loc[:, train.columns.str.contains('feature')]\n","f048dedd":"#features.extend(['cross_41_42_43', 'cross_1_2'])","aab2fb88":"len(features)","6a9bf28d":"X_train=train[features].values\n#y_train = (train.loc[:, 'action'])\n\ny_train = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T","bf33fb84":"import optuna.integration.lightgbm as lgb","6a8f71b9":"from sklearn.metrics import accuracy_score","3b9218ec":"from sklearn.model_selection import KFold","c5db3940":"# modeling step \nparams={\"num_leaves\":300,\n       \"max_bin\":450,\n       \"feature_fraction\":0.52,\n       \"bagging_fraction\":0.52,\n       \"objective\":\"binary\",\n       \"learning_rate\":0.05,\n       \"boosting_type\":\"gbdt\",\n       \"metric\":\"auc\"\n       }\nmodels = [] # list of model , we will train \nfor i in range(y_train.shape[1]):\n    xtr,xval,ytr,yval = train_test_split(X_train ,y_train[:,i],test_size=0.2,stratify=y_train[:,i])\n   \n    d_train = lgbm.Dataset(xtr,label=ytr)\n    d_eval = lgbm.Dataset(xval,label=yval,reference=d_train)\n    clf = lgbm.train(params,d_train,valid_sets=[d_train,d_eval],num_boost_round=1000,\\\n                    early_stopping_rounds=50,verbose_eval=50)\n    models.append(clf)","92c44d63":"VER = 1","32f35bc8":"model_name = 'lgb_model_'+str(VER)+'.bin'\npickle.dump(models, open(model_name, 'wb'))","d646a2d4":"fig,ax = plt.subplots(figsize=(25,50))\nlgbm.plot_importance(clf, ax=ax,importance_type='gain',max_num_features=130)\nplt.show()","26c46305":"f = np.median\nth = 0.503\nimport janestreet\nenv = janestreet.make_env()\nfor (test_df, pred_df) in env.iter_test():\n    if test_df['weight'].item() > 0:\n        x_tt = test_df.loc[:, features].values\n        #x_tt=test_df[features].values\n        if np.isnan(x_tt[:, 1:].sum()):\n            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n            \n        #if np.isnan(x_tt.sum()):\n        #    x_tt = np.nan_to_num(x_tt) + np.isnan(x_tt) * f_mean\n        \n        #drop test_df\n        \n        #pred = np.mean([model.predict(x_tt) for model in models],axis=0)\n        pred = f(np.stack([model.predict(x_tt) for model in models]),axis=0).T\n        #pred = f(pred)\n        pred_df.action = np.where(pred >= th, 1, 0).astype(int)\n    else:\n        pred_df.action = 0\n    env.predict(pred_df)","68dc21ab":"#preds = clf.predict(xtr)\n#pred_labels = np.rint(preds)\n\n\n    \n#accuracy = sklearn.metrics.accuracy_score(ytr, pred_labels)\n","7f2118b2":"**Let us check important feature using logistic relation**\n"}}