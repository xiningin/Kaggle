{"cell_type":{"ea55d696":"code","f1e5e193":"code","ae6d80d2":"code","251b09dc":"code","5ce60e8b":"code","6dc7f41b":"code","3b41c096":"code","6901db7e":"code","9fea279f":"code","f06bea2c":"code","2f713b70":"code","acf06a51":"code","bc5851c4":"code","58afb76a":"code","a0d8479d":"code","577353c1":"code","e51a8a40":"code","b05a945a":"code","40869a45":"code","d2cfceaf":"code","f82d35ee":"code","02ad6fd3":"code","24b34395":"code","a9e9a4b7":"code","9ccbbb9e":"code","04ab4925":"code","f2be631e":"code","989fe106":"code","cbe7ccb2":"code","a151eb4e":"code","cff6f5e7":"code","7c1e8795":"code","9fdd7dbe":"code","aac7ed7a":"markdown","8791d09f":"markdown","4b31cac9":"markdown","4763d54d":"markdown","e1b44454":"markdown","212ab649":"markdown","8ad4ff0b":"markdown","6d7534de":"markdown","5dda09be":"markdown","66d15e9f":"markdown","c1345210":"markdown","b52103bd":"markdown","5da181c4":"markdown","bb5eb2bb":"markdown","8c5257a8":"markdown","eaec27ca":"markdown","d61e5154":"markdown","c7a8ad26":"markdown"},"source":{"ea55d696":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","f1e5e193":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","ae6d80d2":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/titanic\/gender_submission.csv')","251b09dc":"train","5ce60e8b":"train.info()","6dc7f41b":"test","3b41c096":"test.info()","6901db7e":"submission","9fea279f":"sns.distplot(train['Survived'])","f06bea2c":"plt.figure(figsize=(25, 7))\nax = plt.subplot()\nax.scatter(train[train['Survived'] == 1]['Age'], train[train['Survived'] == 1]['Fare'], c='green', s=train[train['Survived'] == 1]['Fare'])\nax.scatter(train[train['Survived'] == 0]['Age'], train[train['Survived'] == 0]['Fare'], c='red', s=train[train['Survived'] == 0]['Fare']);","2f713b70":"target = train.Survived\ntrain.drop(['Survived'], axis=1, inplace=True)\ntrain","acf06a51":"combi = train.append(test)\ncombi","bc5851c4":"titles = set()\nfor name in combi['Name']:\n    titles.add(name.split(',')[1].split('.')[0].strip())\nprint(titles)\n# set(['Sir', 'Major', 'the Countess', 'Don', 'Mlle', 'Capt', 'Dr', 'Lady', 'Rev', 'Mrs', 'Jonkheer', 'Master', 'Ms', 'Mr', 'Mme', 'Miss', 'Col'])\ntitle_dictionary = {\n    \"Capt\": \"Officer\",\n    \"Col\": \"Officer\",\n    \"Major\": \"Officer\",\n    \"Jonkheer\": \"Royalty\",\n    \"Don\": \"Royalty\",\n    \"Sir\" : \"Royalty\",\n    \"Dr\": \"Officer\",\n    \"Rev\": \"Officer\",\n    \"the Countess\":\"Royalty\",\n    \"Mme\": \"Mrs\",\n    \"Mlle\": \"Miss\",\n    \"Ms\": \"Mrs\",\n    \"Mr\" : \"Mr\",\n    \"Mrs\" : \"Mrs\",\n    \"Miss\" : \"Miss\",\n    \"Master\" : \"Master\",\n    \"Lady\" : \"Royalty\",\n    \"Dona\": \"Royalty\"\n}\n","58afb76a":"def get_titles():\n    # we extract the title from each name\n    combi['Title'] = combi['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n    # a map of more aggregated title\n    # we map each title\n    combi['Title'] = combi.Title.map(title_dictionary)\n    #status('title')\n    return combi","a0d8479d":"combi = get_titles()\ncombi","577353c1":"combi.isnull().sum()","e51a8a40":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nimp = IterativeImputer(random_state=42)\n\ndate = pd.Timestamp('2200-01-01')\n\nfor col in combi:\n    if combi[col].dtype==\"object\":\n        combi[col].fillna(\"not listed\", inplace=True)\n    if combi[col].dtype==\"int\":\n        #X[col].fillna(X[col].mode()[0], inplace=True)\n        combi[col].fillna(combi[col].mean(), inplace=True)\n        #combi[col] = combi[col].astype.int()\n    if combi[col].dtype=='float':\n       #X[col].fillna(X[col].mean(), inplace=True)\n       combi[col] = imp.fit_transform(combi[col].values.reshape(-1,1))\n    if combi[col].dtype==\"datetime64[ns]\":\n        combi[col].fillna(date, inplace=True)\ncombi","b05a945a":"combi.isnull().sum()","40869a45":"#create a heatmap to correlate survival\nplt.figure(figsize=(10,6))\ncmap=combi.corr()\nsns.heatmap(cmap)\n","d2cfceaf":"combi['Age_group'] = pd.cut(x=combi['Age'], bins=[0, 18, 40, 65, 100], labels=['child', 'young adult', 'middle age', 'pensioner'])\ncombi['Fare_group'] = pd.cut(x=combi['Fare'], bins=[0, 100, 500, 1000], labels=['low', 'middle', 'high'])\ncombi","f82d35ee":"combi['Age_group'] = combi['Age_group'].astype(str)\ncombi['Fare_group'] = combi['Fare_group'].astype(str)","02ad6fd3":"from sklearn import preprocessing\nfrom sklearn.preprocessing import OrdinalEncoder\nenc = OrdinalEncoder()\n\nfor col in combi:\n    if combi[col].dtype==\"O\":\n        combi[col] = enc.fit_transform(combi[col].values.reshape(-1,1))\ncombi","24b34395":"#combi = (combi - combi.min()) \/ (combi.max() - combi.min())\n#combi","a9e9a4b7":"\n#combi = (combi - np.average(combi)) \/ (np.std(combi))\n#combi\n","9ccbbb9e":"features = ['Pclass', 'Sex','Title',  'Age_group','Fare_group', 'Embarked']\n\ny = target\nX = combi[features][: len(train)]\nX_test = combi[features][len(train) :]\nX.shape, y.shape,X_test.shape","04ab4925":"from sklearn.preprocessing import RobustScaler\n\nrobust = RobustScaler()\n\nX = robust.fit_transform(X)\nX_test = robust.transform(X_test)","f2be631e":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.10, random_state=1, stratify=y, shuffle=True)\nX_train.shape, X_val.shape, y_train.shape, y_val.shape, X_test.shape","989fe106":"from sklearn.svm import SVC\n\nmodel = SVC(C=10, gamma='scale', kernel='poly',random_state=42).fit(X_train, y_train)\nprint(model.score(X_train, y_train))","cbe7ccb2":"y_pred=model.predict(X_val)\nprint(model.score(X_val, y_val))","a151eb4e":"from sklearn.metrics import confusion_matrix\n\nprint(confusion_matrix(y_val, y_pred))","cff6f5e7":"df=pd.DataFrame({'Actual': y_val, 'Predicted':y_pred})\ndf","7c1e8795":"predictions = model.predict(X_test)\n","9fdd7dbe":"submission.Survived = predictions\nsubmission.to_csv('submission.csv', index=False)\nmy_submission = pd.read_csv(\"submission.csv\")\nmy_submission","aac7ed7a":"Normalise","8791d09f":"Encode","4b31cac9":"Loads and read files","4763d54d":"Bins","e1b44454":"SVC","212ab649":"Combine train and test","8ad4ff0b":"Split the training file for training and testing","6d7534de":"Robust scaler","5dda09be":"Analyse target","66d15e9f":"Select model","c1345210":"Import Libraries","b52103bd":"Make predictions","5da181c4":"Heatmap","bb5eb2bb":"Titles","8c5257a8":"Problem Statement\n\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: \u201cwhat sorts of people were more likely to survive?\u201d using passenger data (ie name, age, gender, socio-economic class, etc).\n\n","eaec27ca":"Fill all null values","d61e5154":"Set up X and y values","c7a8ad26":"Standardise"}}