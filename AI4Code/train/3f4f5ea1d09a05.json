{"cell_type":{"bfe7f699":"code","e32acf7d":"code","88400fc7":"code","84ffd8d4":"code","221b2f10":"code","8485e23b":"code","b1c283fd":"code","f468b5cc":"code","36d5acd1":"code","bb2ba79e":"code","75ce4ef7":"code","25598c8c":"code","2c151751":"code","d5a74689":"markdown","69aff303":"markdown","a4b3eed5":"markdown"},"source":{"bfe7f699":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e32acf7d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n\npd.set_option(\"max_columns\", None)\n\n# import the dataset\ndf = pd.read_csv(\"..\/input\/predicting-divorce\/divorce.csv\")\n\nprint(df.shape)\ndf.head()","88400fc7":"# check missing values\ndf.isna().sum().any()","84ffd8d4":"# let's see the distribution of the target\nsns.countplot(data=df, x=\"Divorce_Y_N\")","221b2f10":"# split the dataset for more orderly EDA\n\na = df.iloc[:, :18]\na = pd.concat([a, df.iloc[:, -1]], axis=1)\n\nb = df.iloc[:, 18:36]\nb = pd.concat([b, df.iloc[:, -1]], axis=1)\n\nc = df.iloc[:, 36:55]","8485e23b":"#first split\n\ni=1\nplt.figure(figsize=(15, 18))\nfor f in a.drop(\"Divorce_Y_N\",axis=1).columns:\n    plt.subplot(6, 3, i)\n    sns.countplot(data=a, x=f, hue=\"Divorce_Y_N\")\n    i +=1","b1c283fd":"#second split\n\ni=1\nplt.figure(figsize=(15, 18))\nfor f in b.drop(\"Divorce_Y_N\",axis=1).columns:\n    plt.subplot(6, 3, i)\n    sns.countplot(data=b, x=f, hue=\"Divorce_Y_N\")\n    i += 1","f468b5cc":"#third split\n\ni=1\nplt.figure(figsize=(15, 18))\nfor f in c.drop(\"Divorce_Y_N\",axis=1).columns:\n    plt.subplot(6, 3, i)\n    sns.countplot(data=c, x=f, hue=\"Divorce_Y_N\")\n    i += 1","36d5acd1":"#split data and target\n\nX = df.drop(\"Divorce_Y_N\", axis=1) #data\ny = df[\"Divorce_Y_N\"] #target\n\n#create the new feature called \"tot\"\ndf[\"tot\"] = np.zeros(df.shape[0])\nfor i in X.columns:\n    df[\"tot\"] += df[i] # sum the value of each feature","bb2ba79e":"plt.figure(figsize=(12, 10))\nsns.boxplot(data=df, x=\"Divorce_Y_N\", y=\"tot\")","75ce4ef7":"df[df[\"Divorce_Y_N\"]==1][\"tot\"].min()","25598c8c":"# I create manually the predictions based on the \"tot\" value.\n\npredictions = []\n\nfor val in df[\"tot\"]:\n    if val >= 51:\n        predictions.append(1)\n    else:\n        predictions.append(0)","2c151751":"# check the accuracy score\n\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y, predictions)","d5a74689":"**100%!!**","69aff303":"**It's clear that the higher the value of any feature, the higher the probability of divorce. <br>\nSo I create a new feature calculated by the sum of each feature:**","a4b3eed5":"**We can see that with any value of \"tot\" above 50 will be \"divorce\".**"}}