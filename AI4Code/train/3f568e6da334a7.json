{"cell_type":{"04a27956":"code","66ef82c3":"code","d2f16116":"code","a32400c7":"code","666864f5":"code","540eeb34":"code","d918c09d":"code","6bbb1991":"code","c1f650f9":"code","78c9189f":"code","a98f0247":"code","e23d0ff2":"code","f50a6cc8":"code","bf6d15f6":"code","bb6987cd":"code","3999cafb":"code","876e127f":"code","86ae78bd":"code","d1c4b7d3":"code","e71ad96a":"code","ac4f8e3c":"code","d66d03c9":"code","10c76858":"code","3f6e1413":"markdown","e277cce7":"markdown","575b1a7b":"markdown","8709ae7d":"markdown","593738f4":"markdown","d4d1e9b1":"markdown","8f49c697":"markdown","6feb459a":"markdown","7a516cab":"markdown","3647ce67":"markdown"},"source":{"04a27956":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport os\n\n# Libraries for model building and evaluation\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import auc\nimport imblearn\nfrom imblearn.over_sampling import SMOTE","66ef82c3":"# Read data from csv file\ndf = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')\ndf.head()","d2f16116":"# Observed the different feature types present in the data\ndf.info()","a32400c7":"classes=df['Class'].value_counts()\nnormal_share=classes[0]\/df['Class'].count()*100\nfraud_share=classes[1]\/df['Class'].count()*100","666864f5":"# Created a bar plot for the number and percentage of fraudulent vs non-fraudulent transactions\nlabels = ['Non-fradulent', 'Fradulent']\nperc = [normal_share, fraud_share]\nplt.figure(figsize=(8,6))\nplt.title('Non-fradulent vs Fradulent Transactions')\nsns.barplot(x=labels, y=perc)\nfor i in range(len(classes)):\n  plt.text(x=i, y=perc[i], s='{0} ({1:.2f}%)'.format(classes[i],perc[i]), ha='center', va='bottom', size='large')","540eeb34":"# Created a scatter plot to observe the distribution of classes with time\nplt.figure(figsize=(12,8))\nplt.title('Class vs Time')\nsns.scatterplot(x='Time', y='Class', data=df)\nplt.yticks(classes.index)\nplt.ylim(classes.index[0]-0.5, classes.index[1]+0.5);","d918c09d":"# Created a scatter plot to observe the distribution of classes with Amount\nplt.figure(figsize=(12,8))\nplt.title('Class vs Amount')\nsns.scatterplot(x='Amount', y='Class', data=df)\nplt.yticks(classes.index)\nplt.ylim(classes.index[0]-0.5, classes.index[1]+0.5);","6bbb1991":"# Created a scatter plot to observe the distribution of classes with Amount\nplt.figure(figsize=(12,8))\nplt.title('Class vs Amount')\nsns.scatterplot(x=\"Time\", y='Amount',hue='Class', data=df)\nplt.yticks(classes.index)\nplt.ylim(classes.index[0]-0.5, classes.index[1]+0.5);","c1f650f9":"plt.rcParams[\"figure.figsize\"] = (12,10)\ndf[\"hour_of_day\"] = (df[\"Time\"]%(3600*24))\/\/3600\n\nplt.subplot(2,1,1)\n# plt.title('Class vs Amount')\nsns.scatterplot(x=\"hour_of_day\", y='Amount',hue='Class', data=df)\nplt.subplot(2,1,2)\nplt.yscale(\"log\")\nsns.boxplot(x=\"hour_of_day\",y=\"Amount\", hue=\"Class\",data =df)","78c9189f":"plt.figure(figsize=(20,50))\nfor i in range (1,28):\n    plt.subplot(7,4,i)\n    sns.scatterplot(x=\"V\"+str(i), y =\"V\"+str(i+1),hue = \"Class\",data =df)\n#     plt.tight_layout()","a98f0247":"# Drop unnecessary columns\ndf = df.drop('Time', axis=1)\ndf.shape","e23d0ff2":"y = df.pop('Class') #class variable","f50a6cc8":"# Split the data into train and test sets\nfrom sklearn import model_selection\n\nX_train, X_test, y_train, y_test = model_selection.train_test_split(df, y, train_size=0.7, test_size=0.3,\n                                                                    stratify=y, random_state=42)","bf6d15f6":"# Check number of fradulent transactions\nprint(np.sum(y))\nprint(np.sum(y_train))\nprint(np.sum(y_test))","bb6987cd":"# Plot the histograms of variables from the dataset to see the skewness\ncols = X_train.columns\nc = 5\nr = np.ceil(len(cols)\/c)\nplt.figure(figsize=(4*c, 4*r))\nfor i in range(len(cols)):\n  plt.subplot(r, c, i+1)\n  sns.distplot(X_train[cols[i]])","3999cafb":"# Apply: preprocessing.PowerTransformer(copy=False) to fit & transform the train & test data\nfrom sklearn import preprocessing\n\npt = preprocessing.PowerTransformer(copy=False)\ncols_skewed = ['V1', 'Amount']\nfor col in cols_skewed:\n  pt.fit_transform(X_train[col].values.reshape(-1, 1))\n  pt.transform(X_test[col].values.reshape(-1, 1))","876e127f":"# Plot the histograms of transformed variables from the dataset to see the result\nc = 5\nr = np.ceil(len(cols_skewed)\/c)\nplt.figure(figsize=(4*c, 4*r))\nfor i in range(len(cols_skewed)):\n  plt.subplot(r, c, i+1)\n  sns.distplot(X_train[cols_skewed[i]])","86ae78bd":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression(random_state=42)\nlogreg.fit(X_train, y_train)","d1c4b7d3":"print(\"Train accuracy\",logreg.score(X_train, y_train))\nprint(\"Test accuracy\",logreg.score(X_test, y_test))","e71ad96a":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_jobs=-1,criterion = 'entropy', max_depth = 5, min_samples_leaf=5, random_state=42)\nrf.fit(X_train, y_train)","ac4f8e3c":"print(\"Train accuracy\",rf.score(X_train, y_train))\nprint(\"Test accuracy\",rf.score(X_test, y_test))","d66d03c9":"from xgboost import XGBClassifier\n\nxgb = XGBClassifier(n_jobs=-1, random_state=42, n_estimators=120, max_depth = 5, min_samples_leaf=5)\nxgb.fit(X_train, y_train)","10c76858":"print(\"Train accuracy\",xgb.score(X_train, y_train))\nprint(\"Test accuracy\",xgb.score(X_test, y_test))","3f6e1413":"#### Since skewness is present in the distribution using Power Transformer to make distribution more gaussian","e277cce7":"## Model Building\n- Build different models on the imbalanced dataset and see the result","575b1a7b":"### Random Forest","8709ae7d":"### Regularised Logistic Regression","593738f4":"## Reading the train data","d4d1e9b1":"### Splitting the data into train & test data","8f49c697":"### Plotting the distribution of a variable","6feb459a":"## Exploratory data analysis","7a516cab":"## Importing Library","3647ce67":"### XGBoost"}}