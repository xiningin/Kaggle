{"cell_type":{"b8a67c92":"code","9dfd69a9":"code","f6129a47":"code","23d828fb":"code","1ebe2635":"code","4cd281c2":"code","227900f9":"markdown","91c2ff5a":"markdown","ceedf6ff":"markdown","73b10743":"markdown","1fb0dc94":"markdown","248a35d1":"markdown"},"source":{"b8a67c92":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9dfd69a9":"\ndef read_files():\n    data=list()\n    for dirname, _, filenames in os.walk('\/kaggle\/input\/linaige'):\n        for filename in sorted(filenames):\n            full_path = os.path.join(dirname, filename)\n            session_name = filename.split(\"_\")[0]\n            session_id = int(session_name.replace(\"Session\",\"\"))\n            # Read the file\n            file_data = pd.read_csv(full_path)\n            file_data[\"session\"] = session_id\n            data.append(file_data)\n    data = pd.concat(data)\n    return data\n\ndef preprocess_and_split(data:pd.DataFrame):\n    # Keeping only the easy frames \n    data = data[data[\"confidence\"]==\"e\"]\n    # Changing the target to a binary classification problem\n    data.loc[:,\"target\"] = (data[\"people_number\"]>1).astype(int)\n    \n    # Splitting by session\n    # Extracting the training frames\n    train_df = data[data[\"session\"]==1]\n    train_y = train_df[\"target\"]\n    train_X = train_df.values[:,2:-4].reshape((train_df.shape[0],8,8,1)).astype(np.float32)\n    \n    # Extract the test frames\n    test_df = data[data[\"session\"]!=1]\n    test_y = test_df[\"target\"]\n    test_X = test_df.values[:,2:-4].reshape(-1, 8,8,1).astype(np.float32)\n    \n    return train_X, test_X, train_y, test_y\n    \n    \ndata= read_files()\ntrain_X, test_X, train_y, test_y = preprocess_and_split(data)","f6129a47":"print(f\"The train set contains {train_X.shape[0]} frames\")\nprint(f\"The test set contains {test_X.shape[0]} frames\")\n\n# Plot the label distribution in the dataset\nimport matplotlib.pyplot as plt\n(data[\"people_number\"]>1).astype(int).value_counts().plot(kind='bar')\n","23d828fb":"import tensorflow as tf\ntf.random.set_seed(0)\nfrom tensorflow import keras \nfrom tensorflow.keras import layers\n\n\ndef network():\n    inp = layers.Input(shape=[8,8,1])\n    x =layers.Conv2D(2, (3, 3), use_bias=False, name=\"conv1\")(inp)\n    x =layers.BatchNormalization(name=\"batchnorm1\")(x)\n    x =layers.ReLU(name=\"relu_conv1\")(x)\n    x =layers.Flatten(name=\"flatten\")(x)\n    out =layers.Dense(1, name=\"dense_final\", activation=\"sigmoid\")(x)\n    return tf.keras.Model(inp, out)","1ebe2635":"epochs = 50\nmodel = network()\nmodel.compile(\n    optimizer=keras.optimizers.Adam(1e-4),\n    loss=\"binary_crossentropy\",\n    metrics=[\"binary_accuracy\"],\n)\nmodel.fit(\n    train_X, train_y, epochs=epochs, batch_size=64\n)\n\n","4cd281c2":"from sklearn.metrics import balanced_accuracy_score\nprobs = model.predict(test_X)\npredictions = (probs>=0.5).astype(int)\nbacc = balanced_accuracy_score(test_y, predictions)\nprint(\"The balanced accuracy obtained is\", bacc)\n","227900f9":"# Dataset details\n","91c2ff5a":"# Utility functions","ceedf6ff":"# Simple CNN\nWe train a simple and small CNN on the frames of Session 1, using as test set the rest of the sessions. ","73b10743":"First we define a set of useful functions to read the files, knowing that each session file is in the format:\n","1fb0dc94":"## Training and testing ","248a35d1":"# Dataset overview\nLINAIGE is composed of 6 different csv session files, each with the following format:\n* Column0: timestamp\n* Column1: room temperature\n* Column2-65: pixels\n* Column66: number of people in the frame\n* Column67: confidence of the label \n\nAs proposed in the original paper, we will exclude the hard confidence samples and use only Session 1 for training.\nThe task is \"Social Distancing\", specifically any frame with more than one person detected constitutes a violation and will be labeled with class 1. Class 0 will be used otherwise.\n"}}