{"cell_type":{"a56d7dde":"code","896485db":"code","d9f98e46":"code","1d3e6fb3":"code","5c845358":"code","c0bc7507":"code","e9188c59":"code","dc4dbe73":"code","64ec7d52":"code","13249501":"code","688f1ba0":"code","714c8e4e":"code","f18493c3":"code","9478445a":"code","7e8dba01":"code","844772be":"code","622b1ada":"code","7c737025":"code","8a6387a9":"code","6c11927b":"code","93071159":"code","38e1a01f":"code","9239c0a7":"code","acea7c78":"code","082bd3cb":"code","c28589f0":"code","e51c4e4d":"code","430cef90":"code","62e8f029":"code","9f77232c":"code","828f2754":"code","69284b17":"code","69c44050":"code","fc2de580":"code","4e4d8eb4":"code","89d8ddf0":"code","c05401f7":"code","01a840e2":"code","fd17a3a2":"code","f9ceabba":"code","b9529496":"code","db75e92a":"code","d0833768":"code","a42788c8":"code","a8d3c8d4":"markdown","b425b922":"markdown","877faa23":"markdown","8c654470":"markdown","9505cf80":"markdown","b19714ee":"markdown","c9603c2b":"markdown","af145feb":"markdown","1b995826":"markdown","48e6e4a2":"markdown","88fdaa21":"markdown","7d35d296":"markdown","8abef41f":"markdown","6f51142b":"markdown","23300384":"markdown","9cbf2cc5":"markdown","cd929a12":"markdown","10ee5ac3":"markdown","0802b595":"markdown","972524f8":"markdown","baa950e9":"markdown","8634699f":"markdown","1dc1bbfb":"markdown","0cbb2bf0":"markdown","01a705d5":"markdown"},"source":{"a56d7dde":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","896485db":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport seaborn as sns\nimport missingno as msno\nimport folium\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import cross_validate, train_test_split, StratifiedKFold\nfrom sklearn.metrics import plot_confusion_matrix, classification_report\nfrom sklearn.metrics import roc_curve, auc\nfrom xgboost import XGBClassifier\n\n!pip -q install utm\nimport utm\n\n%config InlineBackend.figure_format = 'retina'","d9f98e46":"# # Access dataset from repository and unzip\n# !wget 'https:\/\/github.com\/yohanesnuwara\/datasets\/blob\/master\/gojek_fake_gps_detection.zip?raw=true'\n# !mv '\/content\/gojek_fake_gps_detection.zip?raw=true' '\/content\/gojek_fake_gps_detection.zip'\n# !unzip '\/content\/gojek_fake_gps_detection.zip'","1d3e6fb3":"train = pd.read_csv('..\/input\/dsbootcamp10\/train.csv')\n\ntrain","5c845358":"train.info()","c0bc7507":"train.isnull().sum()","e9188c59":"# Count zeros. NaN is NOT considered zero\ntrain.isin([0]).astype(int).sum(axis=0)","dc4dbe73":"from datetime import datetime\n\n# Convert Linux seconds to datetime format\ntrain['linux_date'] = [datetime.utcfromtimestamp(s).strftime('%Y-%m-%d %H:%M:%S') for s in train.seconds.values]\n\n# Convert datetime to Pandas format\ntrain['linux_date'] = pd.to_datetime(train['linux_date'])\n\n# Convert datetime in date column to Pandas format\ntrain['date'] = pd.to_datetime(train['date'])\n\n# Check if date column match with Linux date column\ndf = train['linux_date'].dt.date==train['date']\nprint(df.eq(True).all())","64ec7d52":"sns.catplot(data=train, x='driver_status', y='accuracy_in_meters', hue='label', col='service_type', kind='bar')","13249501":"def plot_folium(df, order_id, lat_column, lon_column, location, zoom_start=10):\n  # Select subset of dataframe by order ID\n  df = df[df.order_id==order_id]\n\n  # Folium plot\n  my_map = folium.Map(location=location, zoom_start=zoom_start)  \n\n  # Define different colors for status\n  for index, row in df.iterrows():\n    if row.driver_status=='UNAVAILABLE':\n      color = 'green'\n    if row.driver_status=='AVAILABLE':\n      color = 'red'\n    if row.driver_status=='OTW_PICKUP':\n      color = 'black'\n    if row.driver_status=='OTW_DROPOFF':\n      color = 'blue'\n\n    # Plot coordinates on Folium\n    folium.CircleMarker([row[lat_column], row[lon_column]],\n                        radius=5, color=color,\n                        fill=True).add_to(my_map)\n\n  display(my_map)","688f1ba0":"# Plot on Folium\nplot_folium(train, 'RB193', 'latitude', 'longitude', [-6.920, 107.630], zoom_start=16)","714c8e4e":"# Plot on Folium\nplot_folium(train, 'F842', 'latitude', 'longitude', [-6.920, 107.670], zoom_start=14)","f18493c3":"# # !pip -q install contextily\n# import contextily as ctx\n\n# f, ax = plt.subplots(figsize=(10,10))\n# gdf.to_crs(epsg=3857).plot(ax=ax)\n# ctx.add_basemap(ax=ax)","9478445a":"# Differencing some columns\ntrain['longitude_diff'] = train.groupby('order_id').longitude.diff().fillna(0)\ntrain['latitude_diff'] = train.groupby('order_id').latitude.diff().fillna(0)\ntrain['seconds_diff'] = train.groupby('order_id').seconds.diff().fillna(0)\ntrain['accuracy_diff'] = train.groupby('order_id').accuracy_in_meters.diff().fillna(0)\ntrain['altitude_diff'] = train.groupby('order_id').altitude_in_meters.diff().fillna(0)\n\ntrain","7e8dba01":"# Convert lat lon to UTM\nlat, lon = train.latitude.values, train.longitude.values\nx = utm.from_latlon(lat, lon)\n\ntrain['UTMX'] = x[0]\ntrain['UTMY'] = x[1]\n\ntrain","844772be":"# Function to calculate distance between two points\ndistance = lambda x_dif, y_dif: np.sqrt(x_dif**2 + y_dif**2)","622b1ada":"# Differencing UTM coordinates\ntrain['UTMX_diff'] = train.groupby('order_id').UTMX.diff().fillna(0)\ntrain['UTMY_diff'] = train.groupby('order_id').UTMY.diff().fillna(0)\n\n# Calculate step distance\ntrain['distance'] = distance(train.UTMX_diff, train.UTMY_diff)\n\ntrain['distance']","7c737025":"# Grouping by order ID to get service type and label\ndf_grouped1 = train.groupby('order_id')[['service_type', 'label']].max()\n\ndf_grouped1","8a6387a9":"df_grouped1.label.value_counts().plot.pie(autopct='%.2f %%')","6c11927b":"# Calculate time difference between available and otw pickup status\n\nid = list(df_grouped1.index)\n\nfor num_id, order_id in enumerate(id):\n  # Select dataframe subset w.r.t. order id\n  df_id = train[train.order_id==order_id]\n  try:\n    # Select available status\n    avail = df_id[df_id.driver_status=='AVAILABLE']\n\n    # Select pickup status\n    pickup = df_id[df_id.driver_status=='OTW_PICKUP']\n\n    # Record the first and last seconds of available and pickup\n    t_avail0 = avail.seconds.values[0]\n    t_avail1 = avail.seconds.values[1]\n    t_pickup0 = pickup.seconds.values[0]\n    t_pickup1 = pickup.seconds.values[-1]\n\n    # Calculate time difference of available and pickup last and first seconds\n    avail_sec_diff = t_avail1 - t_avail0\n    pickup_sec_diff = t_pickup1 - t_pickup0\n\n  except:\n    # Set time difference to Null of there is no available\/pickup status \n    avail_sec_diff = np.nan\n    pickup_sec_diff = np.nan\n\n  # Record time difference to df_grouped1\n  df_grouped1.loc[order_id, 'avail_sec_diff'] = avail_sec_diff\n  df_grouped1.loc[order_id, 'pickup_sec_diff'] = pickup_sec_diff\n\n  # Logger of every 100 ids\n  if num_id%100==0:\n    print('Finish ID:', num_id)","93071159":"df_grouped1","38e1a01f":"train = train[['order_id', 'service_type', 'driver_status', 'distance', 'hour',\n               'accuracy_in_meters', 'accuracy_diff', 'altitude_in_meters', \n               'altitude_diff', 'longitude_diff', 'latitude_diff', 'UTMX_diff', \n               'UTMY_diff', 'seconds_diff', 'label']]\n\ntrain","9239c0a7":"# Interquartile and range function\niqr = lambda x: np.percentile(x, 75) - np.percentile(x, 25)\nrange = lambda x: np.max(x) - np.min(x)\n\n# Drop the last 1 column: label\ndf_grouped2 = train.iloc[:,:-1]\n\n# Calculate summary statistics\ndf_grouped2 = df_grouped2.groupby('order_id').aggregate([np.mean, np.min, np.max, np.std, iqr, range])\n\n# Reduce multi-index\ndf_grouped2.columns = ['_'.join(col).strip() for col in df_grouped2.columns.values]\n\ndf_grouped2","acea7c78":"# Replace column name <lambda_0> to IQR and <lambda_1> to range \ncol_groupby2 = df_grouped2.columns\ncol_groupby2 = [w.replace('<lambda_0>', 'IQR') for w in col_groupby2]\ncol_groupby2 = [w.replace('<lambda_1>', 'range') for w in col_groupby2]\n\n# Update names of columns\ndf_grouped2.columns = col_groupby2\n\ndf_grouped2","082bd3cb":"# Get dummies of driver status\ntrain = pd.get_dummies(train, columns=['driver_status'])\n\ntrain","c28589f0":"# Count number of PING by driver status\ndf_grouped3 = train.groupby('order_id')[['driver_status_AVAILABLE', 'driver_status_OTW_DROPOFF',\n                                         'driver_status_OTW_PICKUP','driver_status_UNAVAILABLE']].sum()\n\ndf_grouped3","e51c4e4d":"df_grouped4 = train[['order_id', 'altitude_in_meters']]\n\n# Check for each row if altitude is Null\ndf_grouped4['altitude_isnan'] = df_grouped4.altitude_in_meters.isnull()\n\ndf_grouped4 = df_grouped4.groupby('order_id')[['altitude_isnan']].sum()\n\ndf_grouped4","430cef90":"# Merge all grouped dataframe\ndf = pd.concat((df_grouped1, df_grouped2, df_grouped3, df_grouped4), axis=1)\n\n# Encode service_type\nservice_label = {'service_type': {'GO_FOOD': 0, 'GO_RIDE': 1}}\ndf = df.replace(service_label)\n\ndf","62e8f029":"# Correlation bar plot\ndf.corr()['label'][2:].sort_values(ascending=True).plot.bar(figsize=(14,5))","9f77232c":"# plt.scatter(train.longitude, train.latitude, c=train.label, s=5)\n# plt.xlim(107.4,107.9)\n# plt.ylim(-7.1,-6.7)","828f2754":"# Feature and target\nX = df.drop(columns=['label'])\ny = df.label\n\n# Train test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Pipeline\npipe = make_pipeline(StandardScaler(), XGBClassifier())\n\n# Define multiple scoring metrics\nscoring = {\n    'acc': 'accuracy',\n    'prec_macro': 'precision_macro',\n    'rec_macro': 'recall_macro',\n    'f1_macro': 'f1_macro'\n}\n\n# Stratified K-Fold\nstratkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# Cross-validation.Ignore the warning\ncv_scores = cross_validate(pipe, X_train, y_train, cv=stratkfold, scoring=scoring)","69284b17":"# Print scoring results from dictionary\nfor metric_name, metric_value in cv_scores.items():\n    mean = np.mean(metric_value)\n    print(f'{metric_name}: {np.round(metric_value, 4)}, Mean: {np.round(mean, 4)}')","69c44050":"# Fit pipeline to train set\npipe.fit(X_train, y_train)\n\n# Predict on test set\ny_pred = pipe.predict(X_test)","fc2de580":"# Save pipeline into pickle\nimport joblib\njoblib.dump(pipe, '.\/gojek_xgboost.pkl')","4e4d8eb4":"# Confusion matrix of test set\nplot_confusion_matrix(pipe, X_test, y_test, values_format='.5g') \nplt.show()","89d8ddf0":"# Classification report\nprint(classification_report(y_test, y_pred))","c05401f7":"# Generate class membership probabilities\ny_pred_probs = pipe.predict_proba(X_test)\n\nclasses = [0,1]\n\n# For each class\nfor i, clas in enumerate(classes):\n  # Calculate False Positive Rate, True Negative Rate\n  fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs[:,i], \n                                   pos_label = clas) \n  \n  # Calculate AUC\n  auroc = auc(fpr, tpr)\n  \n  # Plot ROC AUC curve for each class\n  plt.plot(fpr, tpr, label=f'{clas}, AUC: {auroc:.2f}')\n  plt.plot([0, 1], [0, 1], 'k--')\n\nplt.title('ROC AUC')\nplt.xlabel('FPR'); plt.ylabel('TPR')\nplt.xlim(0,1); plt.ylim(0,1)\nplt.legend()\nplt.show()","01a840e2":"# Create a pd.Series of features importances\nfimp = pipe.steps[1][1].feature_importances_\nimportances = pd.Series(data=fimp,\n                        index= X_train.columns)\n\n# Sort importances\nimportances_sorted = importances.sort_values()[-15:]\n\n# Draw a horizontal barplot of importances_sorted\nimportances_sorted.plot(kind='barh', color='red')\nplt.title('Features Importances')\nplt.show()","fd17a3a2":"def gojek_data_transform(df):\n  # Differencing some columns\n  df['longitude_diff'] = df.groupby('order_id').longitude.diff().fillna(0)\n  df['latitude_diff'] = df.groupby('order_id').latitude.diff().fillna(0)\n  df['seconds_diff'] = df.groupby('order_id').seconds.diff().fillna(0)\n  df['accuracy_diff'] = df.groupby('order_id').accuracy_in_meters.diff().fillna(0)\n  df['altitude_diff'] = df.groupby('order_id').altitude_in_meters.diff().fillna(0)\n\n  # Convert lat lon to UTM\n  lat, lon = df.latitude.values, df.longitude.values\n  x = utm.from_latlon(lat, lon)\n\n  df['UTMX'] = x[0]\n  df['UTMY'] = x[1]\n\n  # Function to calculate distance between two points\n  distance = lambda x_dif, y_dif: np.sqrt(x_dif**2 + y_dif**2)\n\n  # Differencing UTM coordinates\n  df['UTMX_diff'] = df.groupby('order_id').UTMX.diff().fillna(0)\n  df['UTMY_diff'] = df.groupby('order_id').UTMY.diff().fillna(0)\n\n  # Calculate step distance\n  df['distance'] = distance(df.UTMX_diff, df.UTMY_diff)\n\n  # Grouping by order ID to get service type and label\n  df_grouped1 = df.groupby('order_id')[['service_type']].max()\n\n  # Calculate time difference between available and otw pickup status\n  id = list(df_grouped1.index)\n\n  for num_id, order_id in enumerate(id):\n    # Select dataframe subset w.r.t. order id\n    df_id = df[df.order_id==order_id]\n    try:\n      # Select available status\n      avail = df_id[df_id.driver_status=='AVAILABLE']\n\n      # Select pickup status\n      pickup = df_id[df_id.driver_status=='OTW_PICKUP']\n\n      # Record the first and last seconds of available and pickup\n      t_avail0 = avail.seconds.values[0]\n      t_avail1 = avail.seconds.values[1]\n      t_pickup0 = pickup.seconds.values[0]\n      t_pickup1 = pickup.seconds.values[-1]\n\n      # Calculate time difference of available and pickup last and first seconds\n      avail_sec_diff = t_avail1 - t_avail0\n      pickup_sec_diff = t_pickup1 - t_pickup0\n\n    except:\n      # Set time difference to Null of there is no available\/pickup status \n      avail_sec_diff = np.nan\n      pickup_sec_diff = np.nan\n\n    # Record time difference to df_grouped1\n    df_grouped1.loc[order_id, 'avail_sec_diff'] = avail_sec_diff\n    df_grouped1.loc[order_id, 'pickup_sec_diff'] = pickup_sec_diff\n\n  df = df[['order_id', 'service_type', 'driver_status', 'distance', 'hour',\n            'accuracy_in_meters', 'accuracy_diff', 'altitude_in_meters', \n            'altitude_diff', 'longitude_diff', 'latitude_diff', 'UTMX_diff', \n            'UTMY_diff', 'seconds_diff']]\n\n  # Interquartile and range function\n  iqr = lambda x: np.percentile(x, 75) - np.percentile(x, 25)\n  range = lambda x: np.max(x) - np.min(x)\n\n  # Calculate summary statistics\n  df_grouped2 = df.groupby('order_id').aggregate([np.mean, np.min, np.max, np.std, iqr, range])\n\n  # Reduce multi-index\n  df_grouped2.columns = ['_'.join(col).strip() for col in df_grouped2.columns.values]\n\n  # Replace column name <lambda_0> to IQR and <lambda_1> to range \n  col_groupby2 = df_grouped2.columns\n  col_groupby2 = [w.replace('<lambda_0>', 'IQR') for w in col_groupby2]\n  col_groupby2 = [w.replace('<lambda_1>', 'range') for w in col_groupby2]\n\n  # Update names of columns\n  df_grouped2.columns = col_groupby2\n\n  # Get dummies of driver status\n  df = pd.get_dummies(df, columns=['driver_status'])\n\n  # Count number of PING by driver status\n  df_grouped3 = df.groupby('order_id')[['driver_status_AVAILABLE', 'driver_status_OTW_DROPOFF',\n                                          'driver_status_OTW_PICKUP','driver_status_UNAVAILABLE']].sum()\n  df_grouped4 = df[['order_id', 'altitude_in_meters']]\n\n  # Check for each row if altitude is Null\n  df_grouped4['altitude_isnan'] = df_grouped4.altitude_in_meters.isnull()\n\n  df_grouped4 = df_grouped4.groupby('order_id')[['altitude_isnan']].sum()\n\n  # Merge all grouped dataframe\n  df = pd.concat((df_grouped1, df_grouped2, df_grouped3, df_grouped4), axis=1)\n\n  # Encode service_type\n  service_label = {'service_type': {'GO_FOOD': 0, 'GO_RIDE': 1}}\n  df = df.replace(service_label)  \n\n  return df","f9ceabba":"# Read test set\ntest = pd.read_csv('..\/input\/dsbootcamp10\/test.csv')\n\ntest","b9529496":"# Transform test set to produce 74 features\ntest_ready = gojek_data_transform(test)\n\ntest_ready","db75e92a":"# Predict on test set\ny_pred = pipe.predict(test_ready)\n\n# Print the first 20 predictions\nprint(y_pred[:20])","d0833768":"# Make submission dataframe\nsubmission = test_ready.reset_index().iloc[:,:1]\nsubmission['label'] = y_pred\n\nsubmission","a42788c8":"# Submission to csv\nsubmission.to_csv('.\/GoJek_submission.csv', index=False)","a8d3c8d4":"Then, calculating the step distance between two successive points. For example, at $(t-1)$, the coordinate is at $(x_{t-1}, y_{t-1})$. Then, at $t$, the coordinate is at $(x_t, y_t)$. The step distance is:\n\n$$r=\\sqrt{\\delta x^2 + \\delta y^2}$$\n\nWhere $\\delta x=x_t-x_{t-1}$ and $\\delta y=y_t-y_{t-1}$","b425b922":"# Machine learning - training and evaluation","877faa23":"# ML-based Detection of Illegal GPS Spoofing by GoJek Drivers using XGBoost Classifier Model","8c654470":"# 3. Feature engineering","9505cf80":"## Calculate correlation with target\n\nFrom the bar plot, we get top 10 features with highest correlation with target, as follows:\n\ndistance IQR, altitude difference IQR, UTMX UTMY difference IQR, latitude longitude difference IQR, accuracy difference IQR, min of distance, and missing altitude counts ","b19714ee":"## `df_grouped2`\n\nNext, I group by order ID to calculate summary stats (mean, min, max, IQR, and range).","c9603c2b":"## Combined all new features\n\n**After feature engineering, the new size of dataset is (3500, 74) where 3500=number of order ID and 74=number of new features.**","af145feb":"For each order ID, I calculate the time difference between two available status and two pickup status (the first and last PING), for this can be a useful predictor. \n\nIn this cartoon here, for example, the user's app shows that the driver is only 100 m from the pick-up spot. Normally it takes 3 minutes to reach the spot. However, the user wait for 10 minutes. This can be an indication that driver uses fake GPS.\n\n<div>\n<img src=\"https:\/\/user-images.githubusercontent.com\/51282928\/144967912-ecc9afb5-1302-4e96-971a-ccdd7d5534ae.png\" width=\"700\"\/>\n<\/div>","1b995826":"There are 154,403 missing values in the altitude column. My first suspection why altitude information can be missing is that fake GPS application may have intermittent or unstable altitude information. So, the missing altitude may become precious predictor (later to be discussed).","48e6e4a2":"Plotting on Folium\n\nGitHub: [Link](https:\/\/github.com\/lindseyberlin\/Blog_FoliumMaps\/blob\/master\/FoliumMapExamples.ipynb)\n\nArticle: [Link](https:\/\/dev.to\/lberlin\/folium-powerful-mapping-tool-for-absolute-beginners-1m5h)","88fdaa21":"## `df_grouped4`\n\nAs mentioned before, altitude contains many missing values. I presumed that it is possible that a fake GPS give unstable altitude, thus more missing altitudes.\n\nHere, I counted the missing altitudes of each order ID groups, and use as new feature.","7d35d296":"Further, I process the seconds column from Linux format to datetime format. I found out that ALL dates in the Linux seconds column do not match with the date column. I do not have an explanation for this, but I assume this is not important for our prediction task.","8abef41f":"# Predict on test set","6f51142b":"First, I differenced latitude, longitude, and seconds columns $(x_t-x_{t-1})$ for each order ID (grouping by order ID then taking difference). ","23300384":"# 2. Data exploration","9cbf2cc5":"## `df_grouped3`\n\nMake dummies from driver status, then for each order ID groups, I count the PINGS of each status.","cd929a12":"There are 7,233 zero values in hour column indicating that orders were done at 00:00 midnight. ","10ee5ac3":"Then, converting the lat lon coordinates to a projected Mercator plane (UTM) coordinates. ","0802b595":"Creating a function to transform the test data by grouping by each order ID and engineer 74 new features.","972524f8":"## `df_grouped1`\n\nCompressing 567,545 record size by grouping by order ID so that we'll have only 3,500. For each order ID, I calculate the summary stats and other things. \n\nGrouping by order ID to get the service typeEach order ID has the same service type (GoFood or GoRide) and the same label (0 or 1). ","baa950e9":"An XGBoost classifier model is built to classify if the GPS is true (1) or fake (0).","8634699f":"The CV scores show all mean precision, recall, and F1-score of 79%. ","1dc1bbfb":"**Features description:**\n\n* order_id - an anonymous id unique to a given order number\n* service_type - service type, can be GORIDE or GOFOOD\n* driver_status - status of the driver PING, can be AVAILABLE, UNAVAILABLE, OTW_PICKUP, OTW_DROPOFF\n* hour - hour\n* seconds - seconds in linux format\n* latitude - GPS latitude\n* longitude - GPS longitude\n* altitude_in_meters - GPS Altitude\n* accuracy_in_meters - GPS Accuracy, the smaller the more accurate\n\n**Target:**\n\nlabel - label describing whether GPS is true (1) or fake (0)","0cbb2bf0":"# 1. Read training data","01a705d5":"After transformation, the size of test set is (500, 74) where 500=number of order ID and 74=number of new features."}}