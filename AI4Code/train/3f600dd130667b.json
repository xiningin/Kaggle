{"cell_type":{"308beb1d":"code","49f93d58":"code","48a2054a":"code","9e8a822c":"code","bde51e9b":"code","4f714481":"code","8f6d4ec9":"code","02a22904":"code","830264c3":"code","25febb2e":"code","c25092e9":"code","686d03a9":"markdown","fd2cfa97":"markdown","f3338dc4":"markdown","0600c9c2":"markdown","37cf3464":"markdown","86fa55ce":"markdown","68c545af":"markdown","de1043d0":"markdown","ccd03a5e":"markdown","054502af":"markdown","193c6405":"markdown"},"source":{"308beb1d":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport os\nimport random\n\nfrom PIL import Image","49f93d58":"def summarise_deltas(df):\n    data = df['distance_delta']\n    mean = data.mean()\n    std = data.std()\n    return mean, std\n\ndef calculate_improved_frequency(df):\n    improved_frequency = len(df[df.improved == True])\/len(df)\n    return improved_frequency\n    \n    \ndef plot_distance_delta_distribution(df, method_name):\n    fig, ax = plt.subplots(figsize = (10, 10))\n    fig.suptitle(f'{method_name}', fontsize = 16, fontweight=\"bold\")\n    sns.histplot(df['distance_delta'], kde = True,ax = ax)\n    ax.set_xlabel('d_image_original_label - d_image_optimised_label')\n    plt.axvline(0, c = 'black', linewidth = 3)\n    \n    ax.set_xlabel(\"(distance between image and original label) - (distance between image and optimised label)\")\n    \n    if not os.path.exists(method_name):\n        os.makedirs(method_name)\n        \n    plt.show()\n    \n    \n    \ndef plot_distance_distributions(df, method_name):\n    fig, ax = plt.subplots(2, figsize = (10, 10), sharex = True, sharey = True)\n    fig.suptitle(f'Plot showing distribution of distances from each label to the image \\n Method: {method_name}')\n    fig.tight_layout(pad=4)\n    \n    sns.histplot(df['d_image_original_label'], kde = True,ax = ax[0], color = 'r')\n    \n    sns.histplot(df['d_image_optimised_label'], kde = True,ax = ax[1])\n    \n    ax[0].set_title(f\"Original label \\n Mean = {round(df['d_image_original_label'].mean(),3)} \\n Standard Deviation = {round(df['d_image_original_label'].std(),3)}\")\n    ax[1].set_title(f\"Optimised label \\n Mean = {round(df['d_image_optimised_label'].mean(),3)} \\n Standard Deviation = {round(df['d_image_optimised_label'].std(),3)}\")\n\n    \n    plt.show()\n    \n    \ndef assess_distances(df, method_name):\n    plot_distance_distributions(df, method_name)\n    \n    plot_distance_delta_distribution(df, method_name)\n    \n    print(f\"The method improved the label in {round(100*calculate_improved_frequency(df), 4)}% of cases\")\n    \n    mean, std = summarise_deltas(df)\n    print(f\"The mean decrease is {round(mean, 3)} and the std is {round(std,3)}\")\n    \n    sum_of_distances_original = df['d_image_original_label'].sum()\n    sum_of_distances_optimised = df['d_image_optimised_label'].sum()\n\n    print(f\"Sum of all distances reduced by {round(((sum_of_distances_original - sum_of_distances_optimised)\/sum_of_distances_original)*100, 3)}%\")\n    ","48a2054a":"def plot_confidence_distributions(df, method_name):\n    correct_df = df[(df.correct == True)]\n    incorrect_df = df[(df.correct == False)]\n    \n    fig, ax = plt.subplots(2, figsize = (10, 10), sharex = True)\n    fig.suptitle(f'Plots of distributions of model confidence for accurate and inaccurate predictions \\n Method: {method_name}')\n    fig.tight_layout(pad=4)\n    sns.histplot(correct_df['confidence'], kde = True, ax = ax[0])\n    ax[0].set_title(f\"Accurate predictions \\n Mean = {round(correct_df['confidence'].mean(),3)} \\n Standard Deviation = {round(correct_df['confidence'].std(),3)}\")\n    sns.histplot(incorrect_df['confidence'], kde = True, ax = ax[1], color = 'r')\n    ax[1].set_title(f\"Inaccurate predictions \\n Mean = {round(incorrect_df['confidence'].mean(),3)} \\n Standard Deviation = {round(incorrect_df['confidence'].std(),3)}\")\n    \n    if not os.path.exists(method_name):\n        os.makedirs(method_name)\n    \n    plt.show()\n\ndef get_accuracy(df):\n    accs = len(df.loc[df.correct == True])\n    total = len(df)\n    return accs\/total\n    \nbaseline_accuracy = get_accuracy(pd.read_csv('..\/input\/imagenet1k-mini-results\/Imagenet1KMini Results\/baseline_results\/baseline_performance.csv'))\n\n\ndef assess_performance(df, method_name, baseline_accuracy = baseline_accuracy):\n    plot_confidence_distributions(df, method_name)\n    method_acc = get_accuracy(df)\n    \n    print(f\"Accuracy = {method_acc*100}% This is {(method_acc - baseline_accuracy)*100}% improvement the baseline\")\n\n\n    ","9e8a822c":"def fix_correct_column(df):\n    true = df['true_label']\n    pred = df['predicted_label']\n\n\n    df.correct = (true == pred)\n    \n    \ndef get_example_image_path(df, class_name):\n    df = df.loc[df.true_label == class_name]\n    \n    index = random.randint(0, len(df) - 1)\n        \n    path = df.loc[df.index[index]][0]\n    \n    return path\n    \n\n\ndef find_most_common_mistakes(df, n_labels, n_mistakes, method):\n    \"\"\"Finds the n_labels most misclassified labels and then the n_mistakes most predcited label for each label.\n    These results are then plotted uses sns.countplot()\"\"\"\n    \n    #filters df to only wrong predictions\n    mistakes = df[df.correct == False]\n    \n    #finds the n_labels labels that occur most frequently in the df, thus finding the \n    #\"most wrong\" labels\n    most_common_wrong_labels = mistakes['true_label'].value_counts()[:n_labels].index.tolist()\n    \n    #figure out how to plot an example image \n    for i in most_common_wrong_labels:\n        data = mistakes.loc[(df.true_label == i)]\n        most_common_wrong_predictions = data['predicted_label'].value_counts()[:n_mistakes].index.tolist()\n        data = data.loc[data['predicted_label'].isin(most_common_wrong_predictions)]\n        fig, ax = plt.subplots(2, figsize = (10,10))\n        \n       # fig.suptitle('Plots showing most common misclassification of most commonly misclassified classes')\n        \n        example_image_path = get_example_image_path(df, i)\n        image = Image.open(example_image_path)\n        \n        ax[0].imshow(image)\n       # ax[0].set_title(f\"{i} \\n Misclassified {len(df.loc[(df.correct == False) & (df.true_label == i)])} times (out of {len(df.loc[(df.true_label == i)])})\")\n        ax[0].set_xlabel(\" \")\n        \n        sns.countplot(y = 'predicted_label', data = data, ax = ax[1], order = data['predicted_label'].value_counts().index)\n        ax[1].set_title(f\"{i}\")#\" \\n Misclassified {len(df.loc[(df.correct == False) & (df.true_label == i)])} times (out of {len(df.loc[(df.true_label == i)])}) \\n Prompt Engine: {method}\")\n        \n        extent = ax[0].get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n        fig.savefig(f'{method}_{i}', bbox_inches=extent.expanded(1.4, 1.4))\n\n        \n        plt.show()\n\n        \n    \ndef how_often_misclassified(df, label):\n    all_label = df.loc[(df.original_label == label)]\n    \n    wrongs = df.loc[(df.correct == False) & (df.original_label == label)]\n    \n    return len(wrongs)\/len(all_label)\n    \ndef get_misclassification_distro(df, method):\n    labels = df.original_label.unique()\n    percent_misclassified = []\n    for i in labels:\n        percent_misclassified.append(how_often_misclassified(df, i))\n    fig, ax = plt.subplots(figsize = (8, 8))\n    fig.suptitle(f'Plot showing the distribution of frequency of misclassifications for {method}')\n    sns.histplot(percent_misclassified)\n    plt.show()\n\ndef get_bad_labels(df, tol):\n    labels = df.original_label.unique()\n    bad_labels = []\n    \n    for i in labels:\n        if how_often_misclassified(df, i) >= tol:\n            bad_labels.append(i)\n            \n    return bad_labels\n\n\n\ndef assess_misclassifications(df, method, tol, n_labels = 5, n_mistakes = 5):\n    get_misclassification_distro(df, method)\n    \n    bad_classes = get_bad_labels(df, tol)\n    num_bad_classes = len(bad_classes)\n    print(f\"The number of classes misclassified more than {tol*100}%  of the time is {num_bad_classes} (out of {len(df.original_label.unique())})\")\n    \n    find_most_common_mistakes(df, n_labels, n_mistakes, method)\n    \n    ","bde51e9b":"# label comparrison\nbaseline = pd.read_csv('..\/input\/imagenet1k-mini-results\/Imagenet1KMini Results\/baseline_results\/baseline_label_comparrison.csv')\nassess_distances(baseline, \"Baseline\")\n\n# model performance\nbaseline_performance = pd.read_csv('..\/input\/imagenet1k-mini-results\/Imagenet1KMini Results\/baseline_results\/baseline_performance.csv')\n\nassess_performance(baseline_performance, \"baseline\")\n\n# analysing misclassifications\n#assess_misclassifications(baseline_performance, \"baseline\", 0.8)","4f714481":"# label comparrison\ncontrol = pd.read_csv('..\/input\/imagenet1k-mini-results\/Imagenet1KMini Results\/control_results\/control_label_comparrison.csv')\nassess_distances(control, \"Control\")\n\n# model performance\ncontrol_performance = pd.read_csv('..\/input\/imagenet1k-mini-results\/Imagenet1KMini Results\/control_results\/control_performance.csv')\n\nassess_performance(control_performance, \"control\")\n\n# analysing misclassifications\n#assess_misclassifications(control_performance, \"control\", 0.8)","8f6d4ec9":"# label comparrison\nZS_OC = pd.read_csv('..\/input\/imagenet1k-mini-results\/Imagenet1KMini Results\/ZS_OC_results\/ZS_OC_label_comparrison.csv')\nassess_distances(ZS_OC, 'Zero Shot Object Categorizer')\n\n# model performance\nZS_OC_performance = pd.read_csv('..\/input\/imagenet1k-mini-results\/Imagenet1KMini Results\/ZS_OC_results\/ZS_OC_performance.csv')\n\nassess_performance(ZS_OC_performance, 'ZS_OC') \n\n# analysing misclassifications\nassess_misclassifications(ZS_OC_performance, \"ZS_OC\", 0.8)","02a22904":"# label comparrison\nsimple_MLM_OC = pd.read_csv('..\/input\/imagenet1k-mini-results\/Imagenet1KMini Results\/MLM_OC_results\/MLM_OC_label_comparrison.csv')\nassess_distances(simple_MLM_OC, \"Masked Language Modelling Object Categorizer\")\n\n# model performance\nsimple_MLM_OC_performance = pd.read_csv('..\/input\/imagenet1k-mini-results\/Imagenet1KMini Results\/MLM_OC_results\/MLM_OC_performance.csv')\n\nassess_performance(simple_MLM_OC_performance, \"simple_MLM_OC\")\n\n# analysing misclassifications\nassess_misclassifications(simple_MLM_OC_performance, \"simple_MLM_OC\", 0.8)","830264c3":"# label comparrison\nrandom_sampling_MLM_OC = pd.read_csv('..\/input\/imagenet1k-mini-results\/Imagenet1KMini Results\/random_MLM_OC_results\/random_MLM_OC_label_comparrison.csv')\nassess_distances(random_sampling_MLM_OC, \"Random sampling Masked Language Modelling Object Categorizer\")\n\n# model performance\nrandom_sampling_MLM_OC_performance = pd.read_csv('..\/input\/imagenet1k-mini-results\/Imagenet1KMini Results\/random_MLM_OC_results\/random_MLM_OC_performance.csv')\n\nassess_performance(random_sampling_MLM_OC_performance, \"random_sampling_OC\")\n\n# analysing misclassifications\nassess_misclassifications(random_sampling_MLM_OC_performance, \"random_sampling_MLM\", 0.8)","25febb2e":"# label comparrison\nSBERT_OC = pd.read_csv('..\/input\/imagenet1k-mini-results\/Imagenet1KMini Results\/ZS_OC_results\/ZS_OC_label_comparrison.csv')\nassess_distances(SBERT_OC, \"SBERT Object Categorizer\")\n\n# model performance\nSBERT_OC_performance = pd.read_csv('..\/input\/imagenet1k-mini-results\/Imagenet1KMini Results\/ZS_OC_results\/ZS_OC_performance.csv')\n\nassess_performance(SBERT_OC_performance,\"SBERT_OC\")\n\n# analysing misclassifications\nassess_misclassifications(SBERT_OC_performance, \"SBERT_OC\", 0.8)","c25092e9":"# label comparrison\nSBERT_sampling_MLM_OC = pd.read_csv('..\/input\/imagenet1k-mini-results\/Imagenet1KMini Results\/SBERT_MLM_OC_results\/SBERT_MLM_OC_label_comparrison.csv')\nassess_distances(SBERT_sampling_MLM_OC, \"SBERT similarity sampling Masked Language Modelling Object Categorizer\")\n\n# model performance\nSBERT_sampling_MLM_OC_performance = pd.read_csv('..\/input\/imagenet1k-mini-results\/Imagenet1KMini Results\/SBERT_MLM_OC_results\/SBERT_MLM_OC_performance.csv')\n\nassess_performance(SBERT_sampling_MLM_OC_performance, \"SBERT_sampling_MLM_OC\")\n\n# analysing misclassifications\nassess_misclassifications(SBERT_sampling_MLM_OC_performance, \"SBERT_sampling_MLM_OC\", 0.8)","686d03a9":"# SBERT enhanced sampling MLM object categorizer","fd2cfa97":"# Baseline","f3338dc4":"# Simple MLM object categorizer","0600c9c2":"# Results","37cf3464":"# Functions for visualising encoded distance based observations","86fa55ce":"# Zero Shot object categorizer","68c545af":"# Control (from CLIP paper)","de1043d0":"# Functions for visualising accuracy and confidence based observations","ccd03a5e":"# SBERT object categorizer ","054502af":"# Functions for analysing misclassifications","193c6405":"# Random sampling MLM object categorizer"}}