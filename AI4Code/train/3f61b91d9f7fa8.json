{"cell_type":{"02b8d701":"code","4595a3df":"code","e504e905":"code","4fff31c9":"code","42383373":"code","e004cae4":"code","7dc12c42":"code","f0c42085":"code","c7e3ea90":"code","249fe4e1":"code","898ef877":"code","4d047b28":"code","fed663c7":"code","4d0700a1":"code","24e4d11c":"code","178da7d8":"code","8a50a1c3":"code","bedf200f":"code","ebcaaa25":"code","c462a770":"code","d82afb7a":"code","530df162":"markdown","da4d9482":"markdown"},"source":{"02b8d701":"#imports\nimport csv\nimport numpy as np\nfrom sklearn import datasets\nfrom sklearn import svm\nfrom sklearn.preprocessing import Imputer\nimport pandas as pd\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import preprocessing\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n","4595a3df":"#reading datasets\ntrain = pd.read_csv(\"..\/input\/trainecsv\/train.csv\")\ntest = pd.read_csv(\"..\/input\/iust-nba-rookies\/test.csv\")\n\n# print(train.info())\n#print(test.info())","e504e905":"del train['Name']\ndel train['PlayerID']\n\ndel test['Name']\ndel test['PlayerID']\n\n#Adding new features\n# train['a'] = train['GP']*train['MIN']\n# train['b'] = train['GP']*train['PTS']\n# train['c'] = 3*train['3P Made']\n# train['d'] = train['GP']*train['FGM']\n# train['e'] = train['GP']*train['FGA']\n# print(train.info())\n\n\n# test['a'] = test['GP']*test['MIN']\n# test['b'] = test['GP']*test['PTS']\n# test['c'] = 3*test['3P Made']\n# test['d'] = test['GP']*test['FGM']\n# test['e'] = test['GP']*test['FGA']\n\n#print(test.info())\n\n#extracting labels\ntrain_labels = train['TARGET_5Yrs']\ntrain_labels=train_labels.as_matrix()\n\ndel train['TARGET_5Yrs']\n\n#print(len(train_labels))\n\n#Handling missing values\nimputer_train = Imputer(missing_values='NaN', strategy='mean', axis=0).fit(train)\ntrain= imputer_train.transform(train)\n\nimputer_test = Imputer(missing_values='NaN', strategy='mean', axis=0).fit(test)\ntest= imputer_test.transform(test)\n\n#Denoising data\n#_______________________unigue______________\n# trainData_unique = np.unique(train,axis=0)\n# print(len(train))\n# print(\"_____________________\")\n# print(len(trainData_unique))\n\n","4fff31c9":"#DATA preporcessing\n\n#standardizing\nstd_scale = preprocessing.StandardScaler().fit(train)\ntrain_std = std_scale.transform(train)\ntest_std = std_scale.transform(test)\n\n\n# #PCA\n# pca_std = PCA(n_components=10).fit(train_std)\n# train_stdwPCA = pca_std.transform(train_std)\n# test_stdwPCA = pca_std.transform(test_std)\n\n#normalize\ntrain_normalized = preprocessing.normalize(train_std, norm='l2')\ntest_normalized = preprocessing.normalize(test_std, norm='l2')\n\n\n","42383373":"#feature selection\n# from sklearn.feature_selection import SelectKBest\n# from sklearn.feature_selection import chi2\n# select = SelectKBest(chi2, k=6)\n# train = select.fit_transform(train, train_labels)\n# test = select.transform(test)\n\n# from sklearn.feature_selection import VarianceThreshold\n# sel = VarianceThreshold(threshold=0.1)\n# selFeature=sel.fit_transform(train)","e004cae4":"# #linearSVM (1)\n\n# linearSVM_clf = svm.SVC(kernel='linear', C=1).fit(train_normalized,train_labels)\n# #acc1=cross_val_score(clf, train_normalized, train_labels, cv=20, scoring='accuracy')\n\n# trainpred=linearSVM_clf.predict(train_normalized)\n# testpred=linearSVM_clf.predict(test_normalized)\n\n# print(metrics.accuracy_score(train_labels, trainpred))\n\n# # print(acc1)\n# # print(np.mean(acc1))\n\n\n# #results.append(clf.predict(test_normalized))\n","7dc12c42":"# #rbfSVM (2)\n# rbfSVM_clf = svm.SVC(kernel='rbf', C=1).fit(train_normalized,train_labels)\n\n# #rbfSVM_acc=cross_val_score(rbfSVM_clf, train_normalized, train_labels, cv=20, scoring='accuracy')\n\n# trainpred=rbfSVM_clf.predict(train_normalized)\n# testpred=rbfSVM_clf.predict(test_normalized)\n\n# print(metrics.accuracy_score(train_labels, trainpred))\n\n# # print(rbfSVM_acc)\n# # print(np.mean(rbfSVM_acc))\n\n# #results.append(rbfSVM_clf.predict(test_normalized))\n","f0c42085":"# #KNN (3)\nfrom sklearn.neighbors import KNeighborsClassifier\n# #find best k for knn\n\n# accs=[]\n# ks=[]\n# for k in range (1,50):\n#     Tknn=KNeighborsClassifier(n_neighbors=k)\n#     acc=cross_val_score(Tknn, train_normalized, train_labels, cv=10, scoring='accuracy')\n#     accs.append(acc.mean())\n#     ks.append(k)\n\n# print('Best K value in KNN with Max Accuracy is :',(accs.index(max(accs))+1))\n# print('Best Accuracy : ', max(accs))\n\n# best_k = accs.index(max(accs))+1\n\n\n#use best K for knn\nknn=KNeighborsClassifier(n_neighbors=2).fit(train_normalized,train_labels)\n#acc2=cross_val_score(knn, train_normalized, train_labels, cv=10, scoring='accuracy')\n\ntrainpred=knn.predict(train_normalized)\n#testpred=knn.predict(test_normalized)\n\n#print(metrics.accuracy_score(train_labels, trainpred))\n\n# print(acc2)\n# print(np.mean(acc2))\n\n#results.append(knn.predict(test_normalized))\n# print(knn.get_params().keys())\n\n","c7e3ea90":"#MLP (4)\nfrom sklearn.neural_network import MLPClassifier\n\nMLP = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(25, 10), random_state=1).fit(train_normalized,train_labels)\n\ntrainpred=MLP.predict(train_normalized)\n#testpred=MLP.predict(test_normalized)\n\n#print(metrics.accuracy_score(train_labels, trainpred))\n#acc3=cross_val_score(MLP, train_normalized, train_labels, cv=10, scoring='accuracy')\n\n# print(acc3)\n# print(np.mean(acc3))\n\n#results.append(MLP.predict(test_normalized))\n# print(MLP.get_params().keys())\n","249fe4e1":"# #logReg (5)\n# from sklearn.linear_model import LogisticRegression\n\n# logReg= LogisticRegression().fit(train_normalized,train_labels)\n\n# trainpred=logReg.predict(train_normalized)\n# testpred=logReg.predict(test_normalized)\n\n# print(metrics.accuracy_score(train_labels, trainpred))\n\n# # logreg_acc=cross_val_score(logReg,train_normalized,train_labels,cv=10,scoring='accuracy')\n\n# # print(logreg_acc)\n# # print(np.mean(logreg_acc))\n\n# #results.append(logReg.predict(test_normalized))","898ef877":"# #NearestCentroid (6)\n\n# from sklearn.neighbors.nearest_centroid import NearestCentroid\n\n# NC_clf = NearestCentroid()\n# NC_clf.fit(train_normalized, train_labels)\n\n# trainpred=NC_clf.predict(train_normalized)\n# testpred=NC_clf.predict(test_normalized)\n\n# print(metrics.accuracy_score(train_labels, trainpred))\n\n# # NC_acc=cross_val_score(NC_clf,train_normalized,train_labels,cv=10,scoring='accuracy')\n\n# # print(logreg_acc)\n# # print(np.mean(logreg_acc))\n\n# #results.append(logReg.predict(test_normalized))","4d047b28":"#GradientBoosting (7)\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nGBC_clf = GradientBoostingClassifier(n_estimators=2000, learning_rate=0.008, max_depth=1, random_state=1).fit(train_normalized, train_labels)\n\ntrainpred=GBC_clf.predict(train_normalized)\n#testpred=GBC_clf.predict(test_normalized)\n\n#print(metrics.accuracy_score(train_labels, trainpred))\n\n# GBC_acc=cross_val_score(GBC_clf,train_normalized,train_labels,cv=20,scoring='accuracy')\n\n# print(GBC_acc)\n# print(np.mean(GBC_acc))","fed663c7":"#randomForest (8)\nfrom sklearn.ensemble import RandomForestClassifier\n\nrandom_forest_clf = RandomForestClassifier(n_estimators=100).fit(train_normalized,train_labels)\n#acc_random_forest = cross_val_score(random_forest_clf, train, train_labels, cv=10, scoring='accuracy')\n\ntrainpred=random_forest_clf.predict(train_normalized)\n#testpred=random_forest_clf.predict(test_normalized)\n\n#print(metrics.accuracy_score(train_labels, trainpred))\n# print(acc_random_forest)\n# print(np.mean(acc_random_forest))\n\n#results.append(random_forest_clf.predict(test_normalized))","4d0700a1":"#DecisionTree (9)\nfrom sklearn.tree import DecisionTreeClassifier\n\nDT_clf = DecisionTreeClassifier(max_depth=15, min_samples_split=3,random_state=6)\nDT_clf.fit(train_normalized,train_labels)\n\ntrainpred=DT_clf.predict(train_normalized)\n#testpred=DT_clf.predict(test_normalized)\n\n#print(metrics.accuracy_score(train_labels, trainpred))\n\n# DT_acc = cross_val_score(DT_clf, train_normalized, train_labels, cv=20, scoring='accuracy')\n\n# print(DT_acc)\n# print(np.mean(DT_acc))\n","24e4d11c":"# ExtraTreesClassifier (10)\nfrom sklearn.ensemble import ExtraTreesClassifier\n\nET_clf = ExtraTreesClassifier(n_estimators=30, max_depth=12,min_samples_split=3, random_state=0)\nET_clf.fit(train_normalized,train_labels)\n\ntrainpred=ET_clf.predict(train_normalized)\n#testpred=ET_clf.predict(test_normalized)\n\n#print(metrics.accuracy_score(train_labels, trainpred))\n# ET_acc = cross_val_score(ET_clf, train_normalized, train_labels, cv=20, scoring='accuracy')\n\n# print(ET_acc)\n# print(np.mean(ET_acc))\n","178da7d8":"# #SGD (11)\n# from sklearn.linear_model import SGDClassifier\n\n# sgd_clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\").fit(train_normalized,train_labels)\n\n# trainpred=clf.predict(train_normalized)\n\n# print(metrics.accuracy_score(train_labels, trainpred))\n# results.append(sgd_clf.predict(test_normalized))\n","8a50a1c3":"#AdaBoost Classifier (12)\nfrom sklearn.ensemble import AdaBoostClassifier\n\nAdB_clf = AdaBoostClassifier(n_estimators=450)\n\nAdB_clf.fit(train_normalized,train_labels)\n\ntrainpred=AdB_clf.predict(train_normalized)\n#testpred=AdB_clf.predict(test_normalized)\n\n#print(metrics.accuracy_score(train_labels, trainpred))\n# AdB_acc = cross_val_score(AdB_clf, train_normalized, train_labels, cv=20, scoring='accuracy')\n\n# print(AdB_acc)\n# print(np.mean(AdB_acc))","bedf200f":"# #LDA (13)\n# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\n# LDA_clf = LinearDiscriminantAnalysis().fit(train_normalized,train_labels)\n\n# LDA_clf.fit(train_normalized,train_labels)\n\n# trainpred=LDA_clf.predict(train_normalized)\n# testpred=LDA_clf.predict(test_normalized)\n\n# print(metrics.accuracy_score(train_labels, trainpred))\n\n# # #LDA_acc = cross_val_score(LDA_clf, train_normalized, train_labels, cv=10, scoring='accuracy')\n\n# # print(LDA_acc)\n# # print(np.mean(LDA_acc))\n\n# # resultLDA = LDA_clf.predict(test_normalized)","ebcaaa25":"# #GaussianNB (14)\n# from sklearn.naive_bayes import GaussianNB\n\n# GNB_clf = GaussianNB()\n# GNB_clf.fit(train_normalized,train_labels)\n\n# trainpred=GNB_clf.predict(train_normalized)\n# testpred=GNB_clf.predict(test_normalized)\n\n# print(metrics.accuracy_score(train_labels, trainpred))\n# # #GNB_acc = cross_val_score(GNB_clf, train_normalized, train_labels, cv=10, scoring='accuracy')\n\n# # print(GNB_acc)\n# # print(np.mean(GNB_acc))","c462a770":"#voting \nfrom sklearn.ensemble import VotingClassifier\n# from sklearn.model_selection import GridSearchCV\n\nens_clf=VotingClassifier(estimators=[('kn', knn), ('ml', MLP),('gbc', GBC_clf), ('rf', random_forest_clf), \n                                     ('dt', DT_clf), ('et', ET_clf), ('adb', AdB_clf)],\n                                      voting='soft', weights=[1, 2, 3, 5, 5, 5, 4])\n\n\n# grid = GridSearchCV(estimator=ens_clf,  cv=5)\n\nens_clf.fit(train_normalized,train_labels)\n\n#ens_acc = cross_val_score(ens_clf, train_normalized, train_labels, cv=10, scoring='accuracy')\n\n\ntrainpredEns=ens_clf.predict(train_normalized)\n#print(metrics.accuracy_score(train_labels, trainpredEns))\n\n# print (ens_acc)\n# print(np.mean(ens_acc))\n\nprint(\"ENSDone\")","d82afb7a":"#predicting results\n\nresult=ens_clf.predict(test_normalized)\n\ncols = { 'PlayerID': [i+901 for i in range(440)] , 'TARGET_5Yrs': result }\nsubmission = pd.DataFrame(cols)\n\n\nsubmission.to_csv(\"submission.csv\", index=False)\n\nprint(submission.info())\nprint (submission)\nprint(\"done\")","530df162":" **\u0628\u0647 \u0646\u0627\u0645 \u062e\u062f\u0627**\n \n \n \u0641\u0631\u0632\u0627\u0646\u0647 \u0641\u062e\u0631\u06cc\u0627\u0646 96725008  \u0647\u0645\u0627  \u0646\u0635\u06cc\u0631\u06cc 96722207\n \n .\u0628\u0647 \u062f\u0644\u06cc\u0644 \u0639\u062f\u0645 \u0648\u062c\u0648\u062f \u0642\u0627\u0628\u0644\u06cc\u062a \u0631\u0627\u0633\u062a \u0646\u0648\u06cc\u0633\u06cc \u062f\u0631 \u0627\u06cc\u0646 \u0633\u0627\u06cc\u062a \u0648 \u0628\u0647\u0645 \u0631\u06cc\u062e\u062a\u06af\u06cc \u062a\u0648\u0636\u06cc\u062d\u0627\u062a\u060c \u0641\u0627\u06cc\u0644 \u0646\u0647\u0627\u06cc\u06cc \u0628\u0647 \u0647\u0645\u0631\u0627\u0647 \u062a\u0648\u0636\u06cc\u062d\u0627\u062a \u0648 \u0647\u0645\u0686\u0646\u06cc\u0646 \u062f\u0627\u062f\u0647\u200c\u0647\u0627\u06cc \u0628\u062f\u0648\u0646 \u0646\u0648\u06cc\u0632 \u0648 \u0641\u0627\u06cc\u0644 \u0646\u062a\u06cc\u062c\u0647\u060c \u0627\u0632 \u0644\u06cc\u0646\u06a9 \u0632\u06cc\u0631 \u0642\u0627\u0628\u0644 \u062f\u0631\u06cc\u0627\u0641\u062a \u0627\u0633\u062a\n \nhttps:\/\/db.tt\/sJerdBKigk","da4d9482":"**classifiers:**\nselecting classifiers with better accuracy"}}