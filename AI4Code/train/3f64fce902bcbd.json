{"cell_type":{"9325f4db":"code","ee2e0f0a":"code","dcd908c5":"code","4d100f20":"code","08f11e18":"code","b4671017":"code","241a8f03":"code","e8b518c0":"code","25772f8b":"code","3f2cbf4e":"code","30bb3b6f":"code","38f71e6c":"code","482581a4":"code","87dd35a2":"code","46c1228e":"code","6a7e86f5":"markdown","3a491680":"markdown","215959af":"markdown","41140ef4":"markdown","df7782d2":"markdown"},"source":{"9325f4db":"%cd \/kaggle\/input\/fruits\n!ls","ee2e0f0a":"# Load and transform the dataset\nimport os\n\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import transforms, ToTensor\nfrom torch.utils.data import random_split, DataLoader\n\n# Train the model\nimport copy \nimport time\n\nimport torch\nimport torch.nn as nn\nfrom torchvision import models\n\n# Evaluate the model\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Apply the model\nfrom random import choice\n\nimport torch.nn.functional as nnf","dcd908c5":"train_directory = '.\/fruits-360\/Training'\ntest_directory = '.\/fruits-360\/Test'\n\ntransform = transforms.Compose([\n    transforms.Resize([224, 224]),  # 224x224 is image size used in pre-trained models\n    transforms.ToTensor()\n])\n\n\ntrain_dataset = ImageFolder(train_directory, transform=transform)\nprint('Training dataset size:', len(train_dataset))\ntest_dataset = ImageFolder(test_directory, transform=transform)\nprint('Test dataset size:', len(test_dataset))","4d100f20":"# Split training and validation data\nvalidation_size = int(0.1 * len(train_dataset))  # Validation represents 10% of the training data\ntraining_size = len(train_dataset) - validation_size\n\ntrain_dataset, validation_dataset = random_split(train_dataset, \n                                                 [training_size, validation_size])\nlen(train_dataset), len(validation_dataset) ","08f11e18":"# Get dataset classes\nclasses = os.listdir(train_directory)\n\nlen(classes)","b4671017":"# Create data loaders from datasets\nbatch_size = 32\n\ntraining_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\nvalidation_loader = DataLoader(dataset=validation_dataset, batch_size=batch_size, shuffle=False)","241a8f03":"device =  torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n\ndef training_step(model, criterion, optimizer, dataloader_train):\n    running_loss = 0.0\n\n    # Iterate over data.\n    for inputs, labels in dataloader_train:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        # Zero the parameter gradients\n        optimizer.zero_grad()\n\n        with torch.set_grad_enabled(True):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            loss.backward()\n            optimizer.step()\n\n        running_loss += loss.item()\n        \n    return running_loss\n\n\ndef evaluation_step(model, criterion, optimizer, dataloader_val):\n    running_loss = 0.0\n    running_corrects = 0\n    \n    # Iterate over data.\n    for inputs, labels in dataloader_val:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        running_loss += loss.item()\n        _, preds = torch.max(outputs, 1)\n        running_corrects += torch.sum(preds == labels.data)\n    \n    return running_loss, running_corrects\n\n\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n    history = {\n        'train_loss': list(),\n        'validation_loss': list(), \n        'validation_accuracy': list()\n    }\n    \n    since = time.time()\n    \n    best_model = copy.deepcopy(model.state_dict())\n    best_accuracy = 0.0\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}\/{num_epochs - 1}')\n        print('-' * 10)\n\n        # Training step\n        model.train() \n\n        running_loss = training_step(\n            model, criterion, optimizer, training_loader\n        )\n    \n        train_epoch_loss = running_loss \/ len(training_loader.dataset)\n        \n        scheduler.step()\n\n        # Evaluation step\n        model.eval()\n\n        running_loss, running_corrects = evaluation_step(\n            model, criterion, optimizer, validation_loader\n        )\n\n        validation_epoch_loss = running_loss \/ len(validation_loader.dataset)\n        epoch_accuracy = running_corrects.double() \/ len(validation_loader.dataset)\n\n        print(f'Training Loss: {train_epoch_loss:.4f} '\n            + f'Validation Loss: {validation_epoch_loss:.4f} '\n            + f'Accuracy: {epoch_accuracy:.4f}\\n')\n        \n        history['train_loss'].append(train_epoch_loss)\n        history['validation_loss'].append(validation_epoch_loss)\n        history['validation_accuracy'].append(epoch_accuracy)\n\n        # Deep copy the model if it presents the best accuracy\n        if epoch_accuracy > best_accuracy:\n            best_accuracy = epoch_accuracy\n            best_model = copy.deepcopy(model.state_dict())\n\n    time_elapsed = time.time() - since\n    minutes = time_elapsed \/\/ 60\n    seconds = time_elapsed % 60\n    \n    print(f'Training complete in {minutes:.0f}m {seconds:.0f}s')\n    print(f'Best accuracy: {best_accuracy:4f}')\n\n    # Load best model weights\n    model.load_state_dict(best_model)\n    return model, history\n\n\ndevice","e8b518c0":"# Load ResNet50 as backbone\nmodel_base = models.resnet50(pretrained=True)\nnum_features = model_base.fc.in_features\nmodel_base.fc = nn.Linear(num_features, len(classes))\n\n# Load model to GPU\nmodel_base.to(device)\n\n# Hyper-parameters\nstep_size  = 7\ngamma = 0.1\n\ncriterion = nn.CrossEntropyLoss()\noptimizer_ft = torch.optim.Adam(model_base.parameters())\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=step_size, gamma=gamma)","25772f8b":"model, history = train_model(model_base, criterion, optimizer_ft, scheduler, num_epochs=3)","3f2cbf4e":"def plot_accuracy(history):\n    accuracy = history[\"validation_accuracy\"]\n    epochs = range(len(accuracy))\n    \n    plt.plot(accuracy, \"-x\")\n    plt.xticks(epochs)\n\n    plt.title(\"Accuracy x Number of Epochs\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n\n\nplot_accuracy(history)","30bb3b6f":"def plot_losses(history):\n    train_loss = history[\"train_loss\"]\n    validation_loss = history[\"validation_loss\"]\n    epochs = range(len(train_loss))\n    \n    plt.plot(train_loss, \"-rx\")  # r = Red\n    plt.plot(validation_loss, \"-bx\")  # b = Blue\n    plt.xticks(epochs)\n    \n    plt.legend([\"Training loss\", \"Validation loss\"])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Losses (%)\")\n\n\nplot_losses(history)","38f71e6c":"def evaluate(model, data_loader):\n    correct_predictions = 0.0\n    model.eval()\n    y_hat = list()\n    y_true = list()\n    \n    for (inputs, labels) in data_loader:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n        \n        y_hat.append(preds)\n        correct_predictions += torch.sum(preds == labels.data)\n\n    accuracy = correct_predictions.double() \/ len(data_loader.dataset)\n    return accuracy, y_true, y_hat\n\n\naccuracy, y_true, y_hat = evaluate(model, test_loader)\nprint(f'Accuracy: {accuracy:.4f}')","482581a4":"def evaluate_classes(data_loader, y_true, y_hat):\n    Y_true = list()\n    Y_hat = list()\n    \n    for inputs, labels in iter(data_loader):\n        for y_true in labels.cpu().numpy():\n            Y_true.append(y_true)\n\n    for joint in y_hat:\n        for label in joint.cpu().numpy():\n            Y_hat.append(label)\n        \n    report = classification_report(Y_true, Y_hat, target_names=classes, zero_division=0)\n    plt.rcParams[\"figure.figsize\"] = (20,20)\n\n    sns.heatmap(confusion_matrix(Y_true, Y_hat))\n    \n    return report\n\n\nreport = evaluate_classes(test_loader, y_true, y_hat)\nprint(report)","87dd35a2":"def predict(image_input, model):\n    image = image_input.unsqueeze(0).to(device)\n    output = model(image)\n\n    probabilities = nnf.softmax(output, dim=1)[0]    \n    \n    probabilities_classes = [\n        (classes[index], probability) for index, probability in enumerate(probabilities)\n    ]\n    \n    # Order dict by highest probability\n    ordered_probabilities = sorted(\n        probabilities_classes, \n        key=lambda probability_class: probability_class[1],\n        reverse=True\n    )    \n    \n    return ordered_probabilities","46c1228e":"# Randonmly chooses an image\nimage, label = choice(test_dataset)\n\n# Display image and true label\nplt.figure(figsize=(4, 3), dpi=80)\nplt.imshow(image.permute(1,2,0))\nplt.show()\n\nprint(f\"Label: {classes[label]}\\n\")\n\nprobabilities = predict(image, model)\n\nprint(\"Probability scores\")\n\nfor fruit_class, probability in probabilities:\n    print(f\"{fruit_class:30s} {probability:.4f}\")","6a7e86f5":"This task intends to measure your deep learning basic skills. We will provide you a dataset containing 131 different fruits. Download it from this [link](https:\/\/\/www.kaggle.com\/moltean\/fruits), download it and upload it to your copy of this file\n\nYou have to implement a Convolutional Neural Network to classify the input fruit image. For this task, you must follow the following rules:\n\n- Use a ResNet50 as your CNN backbone.\n- The model output must be a probability score for all the classes.\n- You can implement the model in any Deep Learning framework that you are used to use.\n- Make sure you write your code following the best practices.\n- Make sure you document all the steps you took to solve the problem.","3a491680":"## Training the model\n\n* Implement the train and evaluation steps\n* Implement the model training function\n* Load ResNet50 as backbone model\n* Set hyperparameters and model operations\n* Train the model","215959af":"## Applying the model\n\n* Randomly select and classify images from the test dataset\n* Model output is presented as a probability score for all classes","41140ef4":"## Loading the dataset\n\n* Load and transform the dataset\n* Split the training data into training and validation\n* Get the dataset classes\n* Create Dataloaders with the datasets","df7782d2":"## Evaluating the model\n\n* Plot the model accuracyand loss over the epochs\n* Measure the model accuracy for the test dataset\n* Assess the dataset classes for each evalution metric\n* Plot the heatmap with the results"}}