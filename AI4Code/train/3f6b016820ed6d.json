{"cell_type":{"6fdf3617":"code","51856be0":"code","376833f2":"code","91fc4002":"code","c1109cf3":"code","6c2d2769":"code","ca9171de":"code","8edb1379":"code","013dc4e3":"code","3f4df054":"code","e9b23e85":"code","f013b8c5":"code","4eb025cb":"code","5314d723":"code","c5315e74":"code","161ec37e":"code","309cc53e":"code","3bce3d51":"code","d93e5f39":"code","d097fb01":"code","86afa6ca":"code","320d3d39":"code","21973bab":"code","62229810":"code","feebee44":"code","3b4096ba":"code","dbdb70a2":"code","3582b777":"code","dfe3fa2b":"code","95aa49b1":"code","6913be74":"markdown","6f10cf05":"markdown","e981ae80":"markdown","72c61408":"markdown","da841b73":"markdown","d5072bb0":"markdown","7fea100e":"markdown","8de439d8":"markdown","7e3b678f":"markdown","6c5ee49f":"markdown","b92f9d4b":"markdown"},"source":{"6fdf3617":"! pip install -q \/kaggle\/input\/readability\/readability-0.3.1-py3-none-any.whl\n! pip install -q \/kaggle\/input\/syntok\/syntok-1.3.1-py3-none-any.whl\nimport readability\nimport syntok.segmenter as segmenter\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","51856be0":"train_data = pd.read_csv('\/kaggle\/input\/commonlitreadabilityprize\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/commonlitreadabilityprize\/test.csv')","376833f2":"train_data.info()\ntrain_data.head()","91fc4002":"test_data.info()\ntest_data.head()","c1109cf3":"pd.read_csv('\/kaggle\/input\/commonlitreadabilityprize\/sample_submission.csv')","6c2d2769":"def tokenize(text):\n    \"\"\"Tokenizing and creating excerpts in the format suggested in the README of readability project.\"\"\"\n    return '\\n\\n'.join(\n        '\\n'.join(\n            ' '.join(token.value for token in sentence)\n            for sentence in paragraph)\n        for paragraph in segmenter.analyze(text))","ca9171de":"train_data.loc[:,'readability_object'] = train_data.apply(lambda row: readability.getmeasures(tokenize(row.excerpt), lang='en'), axis=1)","8edb1379":"train_data.info()\ntrain_data.head()","013dc4e3":"X = pd.DataFrame(train_data['id'])\nX.loc[:,'readability'] = train_data.apply(lambda row: row.readability_object['readability grades']['SMOGIndex'], axis=1)\nX.loc[:,'syll_per_word'] = train_data.apply(lambda row: row.readability_object['sentence info']['syll_per_word'], axis=1)\nX.loc[:,'words_per_sentence'] = train_data.apply(lambda row: row.readability_object['sentence info']['words_per_sentence'], axis=1)\nX.loc[:,'type_token_ratio'] = train_data.apply(lambda row: row.readability_object['sentence info']['type_token_ratio'], axis=1)\nX.loc[:,'syllables'] = train_data.apply(lambda row: row.readability_object['sentence info']['syllables'], axis=1)\nX.loc[:,'words'] = train_data.apply(lambda row: row.readability_object['sentence info']['words'], axis=1)\nX.loc[:,'wordtypes'] = train_data.apply(lambda row: row.readability_object['sentence info']['wordtypes'], axis=1)\nX.loc[:,'sentences'] = train_data.apply(lambda row: row.readability_object['sentence info']['sentences'], axis=1)\nX.loc[:,'complex_words_dc'] = train_data.apply(lambda row: row.readability_object['sentence info']['complex_words_dc'], axis=1)\nX.loc[:,'tobeverb'] = train_data.apply(lambda row: row.readability_object['word usage']['tobeverb'], axis=1)\nX.loc[:,'auxverb'] = train_data.apply(lambda row: row.readability_object['word usage']['auxverb'], axis=1)\nX.loc[:,'conjunction'] = train_data.apply(lambda row: row.readability_object['word usage']['conjunction'], axis=1)\nX.loc[:,'pronoun'] = train_data.apply(lambda row: row.readability_object['word usage']['pronoun'], axis=1)\nX.loc[:,'preposition'] = train_data.apply(lambda row: row.readability_object['word usage']['preposition'], axis=1)\nX.loc[:,'nominalization'] = train_data.apply(lambda row: row.readability_object['word usage']['nominalization'], axis=1)","3f4df054":"X.info()\nX.head()","e9b23e85":"tar_corr = pd.merge(X, train_data['target'], left_index=True, right_index=True).corr().loc['target']\ntar_corr","f013b8c5":"to_remove = ['id']\nfor val in tar_corr.index:\n    if tar_corr[val] > -0.1 and tar_corr[val] < 0.1:\n        to_remove.append(val)\n\nto_remove","4eb025cb":"X = X.drop(to_remove, axis=1)","5314d723":"X.info()\nX.head()","c5315e74":"y = train_data['target']","161ec37e":"y.describe()","309cc53e":"train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=0)","3bce3d51":"model = Ridge()\ncv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=0)\nspace = {'alpha': [1e-3, 1e-2, 1e-1, 1, 10],\n         'normalize': [True, False]}\nsearch = GridSearchCV(model, space, cv=cv, scoring='neg_root_mean_squared_error', n_jobs=-1)\nresult = search.fit(train_X, train_y)","d93e5f39":"print(result.best_score_)\nprint(result.best_params_)","d097fb01":"model = Ridge(alpha=result.best_params_['alpha'], normalize=result.best_params_['normalize'])\n\nmodel.fit(train_X, train_y)","86afa6ca":"train_preds = model.predict(train_X)\nmean_squared_error(train_y, train_preds)","320d3d39":"val_preds = model.predict(val_X)\nmean_squared_error(val_y, val_preds)","21973bab":"test_data.loc[:,'readability_object'] = test_data.apply(lambda row: readability.getmeasures(tokenize(row.excerpt), lang='en'), axis=1)","62229810":"test_data.info()\ntest_data.head()","feebee44":"X_test = pd.DataFrame(test_data['id'])\nX_test.loc[:,'readability'] = test_data.apply(lambda row: row.readability_object['readability grades']['SMOGIndex'], axis=1)\nX_test.loc[:,'syll_per_word'] = test_data.apply(lambda row: row.readability_object['sentence info']['syll_per_word'], axis=1)\nX_test.loc[:,'words_per_sentence'] = test_data.apply(lambda row: row.readability_object['sentence info']['words_per_sentence'], axis=1)\nX_test.loc[:,'type_token_ratio'] = test_data.apply(lambda row: row.readability_object['sentence info']['type_token_ratio'], axis=1)\nX_test.loc[:,'syllables'] = test_data.apply(lambda row: row.readability_object['sentence info']['syllables'], axis=1)\nX_test.loc[:,'words'] = test_data.apply(lambda row: row.readability_object['sentence info']['words'], axis=1)\nX_test.loc[:,'wordtypes'] = test_data.apply(lambda row: row.readability_object['sentence info']['wordtypes'], axis=1)\nX_test.loc[:,'sentences'] = test_data.apply(lambda row: row.readability_object['sentence info']['sentences'], axis=1)\nX_test.loc[:,'complex_words_dc'] = test_data.apply(lambda row: row.readability_object['sentence info']['complex_words_dc'], axis=1)\nX_test.loc[:,'tobeverb'] = test_data.apply(lambda row: row.readability_object['word usage']['tobeverb'], axis=1)\nX_test.loc[:,'auxverb'] = test_data.apply(lambda row: row.readability_object['word usage']['auxverb'], axis=1)\nX_test.loc[:,'conjunction'] = test_data.apply(lambda row: row.readability_object['word usage']['conjunction'], axis=1)\nX_test.loc[:,'pronoun'] = test_data.apply(lambda row: row.readability_object['word usage']['pronoun'], axis=1)\nX_test.loc[:,'preposition'] = test_data.apply(lambda row: row.readability_object['word usage']['preposition'], axis=1)\nX_test.loc[:,'nominalization'] = test_data.apply(lambda row: row.readability_object['word usage']['nominalization'], axis=1)","3b4096ba":"X_test = X_test.drop(to_remove, axis=1)","dbdb70a2":"test_preds = model.predict(X_test)","3582b777":"solution = pd.DataFrame(test_data['id'])\nsolution.loc[:, 'target'] = test_preds","dfe3fa2b":"solution.info()","95aa49b1":"solution.to_csv('submission.csv', index=False)","6913be74":"I will be using the **SMOGIndex** readability grade as it was found to be best in [this notebook](https:\/\/www.kaggle.com\/aniketsharma00411\/commonlit-readability-data-observations). Also, I am removing (not creating) some features based on insights gained from the same notebook.","6f10cf05":"In this notebook, I try to solve the [CommonLit Readability Prize](https:\/\/www.kaggle.com\/c\/commonlitreadabilityprize\/overview) competition using [Ridge Regression](https:\/\/en.wikipedia.org\/wiki\/Ridge_regression).\n\nI have created similar models using [Decision Tree](https:\/\/en.wikipedia.org\/wiki\/Decision_tree), [Support Vector Machine](https:\/\/en.wikipedia.org\/wiki\/Support-vector_machine) and [Random Forest](https:\/\/en.wikipedia.org\/wiki\/Random_forest) which got a score of 0.941, 0.820 and 0.771 respectively.\n\nThe notebook for the models are:\n - [Decision Tree with score 0.941](https:\/\/www.kaggle.com\/aniketsharma00411\/commonlit-readability-decision-tree)\n - [Support Vector Machine with score 0.820](https:\/\/www.kaggle.com\/aniketsharma00411\/commonlit-readability-svr)\n - [Random Forest with score 0.771](https:\/\/www.kaggle.com\/aniketsharma00411\/commonlit-readability-random-forest)\n \nI have also created a notebook containing insights gathered from dataset. I will be using insights from that in this notebook also. [Here](https:\/\/www.kaggle.com\/aniketsharma00411\/commonlit-readability-data-observations) is the link to that notebook.\n\nThis notebook will be similar to the [Support Vector Machine](https:\/\/www.kaggle.com\/aniketsharma00411\/commonlit-readability-svr) one.","e981ae80":"# Initialization","72c61408":"# Training","da841b73":"Using Grid Search to find the optimal values of hyperparameters.","d5072bb0":"We will remove every feature with correlation value between -0.1 and 0.1.","7fea100e":"# Creating features for test set and predicting results","8de439d8":"# Creating Features","7e3b678f":"# Evaluating the result","6c5ee49f":"# Functions","b92f9d4b":"I am using the [readability](https:\/\/pypi.org\/project\/readability\/) and [syntok](https:\/\/pypi.org\/project\/syntok\/) to gather features from excerpts."}}