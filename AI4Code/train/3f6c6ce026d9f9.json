{"cell_type":{"f8e07bc4":"code","4df75cbb":"code","d00c9d1e":"code","071edbe2":"code","be028b9b":"code","881254c6":"code","3021e3f6":"code","466a01ed":"code","2a6d61ad":"code","5b49e020":"code","e06edb23":"code","46915048":"markdown","44be63fe":"markdown","c5f49b02":"markdown","cbc7b0df":"markdown","365c27e4":"markdown"},"source":{"f8e07bc4":"import os\nimport sys\nimport gc\nsys.path.append(\"..\/input\/pytorch-image-models\")\n\nimport time\nimport numpy as np\nimport pandas as pd\nfrom easydict import EasyDict as edict\n\n# visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# image\nimport PIL\nfrom PIL import Image\nimport albumentations as albu\n\n# model validation\nimport sklearn\nfrom sklearn.model_selection import StratifiedKFold\n\n# model\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport timm\n\n# pytorch_lightening\nimport pytorch_lightning as pl\nfrom pytorch_lightning.utilities.seed import seed_everything\nfrom pytorch_lightning import callbacks\nfrom pytorch_lightning.callbacks.progress import ProgressBarBase\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\nfrom pytorch_lightning.loggers import TensorBoardLogger\nfrom pytorch_lightning import LightningDataModule, LightningModule","4df75cbb":"# For notebook commit\nGET_CV = True\ntest = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\nif len(test)>8:\n    GET_CV = False\nelse:\n    print('this submission notebook will compute CV score, but commit notebook will not')","d00c9d1e":"GET_CV = False","071edbe2":"if GET_CV:\n    df = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\nelse:\n    df = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')","be028b9b":"__C = edict()\ncfg = __C\n# model\ncfg.model = edict()\ncfg.model.name = 'vit_base_patch16_224'\ncfg.model.weight = '..\/input\/vit-base-models-pretrained-pytorch\/jx_vit_base_p16_224-80ecf9dd.pth'\n\n# optimizer\ncfg.optim = edict()\ncfg.optim.name = 'torch.optim.AdamW'\ncfg.optim.lr = 2e-5\ncfg.optim.max_epochs = 20\n\n# lr_schedule\ncfg.lr_sched = edict()\ncfg.lr_sched.name = 'torch.optim.lr_scheduler.CosineAnnealingWarmRestarts'\ncfg.lr_sched.params = {'eta_min':0.0001, 'T_0':20}\n\n# dataset\ncfg.trainloader = edict()\ncfg.trainloader.batch_size = 32\ncfg.trainloader.drop_last = True\ncfg.trainloader.num_workers = 4\ncfg.trainloader.pin_memory = False\ncfg.trainloader.shuffle = True\n\ncfg.valloader = edict()\ncfg.valloader.batch_size = 16\ncfg.valloader.drop_last = True\ncfg.valloader.num_workers = 4\ncfg.valloader.pin_memory = False\ncfg.valloader.shuffle = False\n\n# data transform and augmentation\ncfg.transform = edict()\ncfg.transform.img_size = 224\ncfg.transform.normalize_mean = [.5, .5, .5]\ncfg.transform.normalize_std = [.5, .5, .5]\n\n# data directory\ncfg.data = edict()\nif GET_CV:\n    cfg.data.df_dir = '..\/input\/petfinder-pawpularity-score\/train.csv'\nelse:\n    cfg.data.df_dir = '..\/input\/petfinder-pawpularity-score\/test.csv'\n\nif GET_CV:    \n    cfg.data.image_dir = '..\/input\/petfinder-pawpularity-score\/train'\nelse:\n    cfg.data.image_dir = '..\/input\/petfinder-pawpularity-score\/test'","881254c6":"def build_transform(cfg):\n    transforms = torchvision.transforms.Compose([\n        torchvision.transforms.ToTensor(),\n        torchvision.transforms.Normalize(cfg.transform.normalize_mean,\n                                         cfg.transform.normalize_std),\n        torchvision.transforms.Resize(size = (cfg.transform.img_size,cfg.transform.img_size))\n        ])\n    return transforms","3021e3f6":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, df, data_dir, transforms):\n        self.df = df\n        self.df['Pawpularity'] \/= 100.0\n        self.data_dir = data_dir\n        self.transforms = transforms\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_path = os.path.join(self.data_dir, self.df['Id'][index])+'.jpg'\n        img = Image.open(img_path)\n        img = self.transforms(img)\n        label = torch.tensor(self.df['Pawpularity'][index], dtype = torch.float32).reshape(1)\n        return img, label\n    \nclass TestDataset(torch.utils.data.Dataset):\n    def __init__(self, df, data_dir, transform):\n        self.df = df\n        self.data_dir = data_dir\n        self.transforms = transforms\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, index):\n        img_path = os.path.join(self.data_dir, self.df['Id'][index])+'.jpg'\n        img = Image.open(img_path)\n        img = self.transforms(img)\n        return img\n    \nclass Dataloader(LightningDataModule):\n    def __init__(self, cfg, train_df, val_df):\n        super().__init__()\n        self.cfg = cfg\n        self.train_df = train_df\n        self.val_df = val_df\n    def _create_dataset(self, train = True):\n        if train:\n            return Dataset(self.train_df, self.cfg.data.image_dir, build_transform(self.cfg))\n        else:\n            return Dataset(self.val_df, self.cfg.data.image_dir, build_transform(self.cfg))\n    \n    def train_dataloader(self):\n        dataset = self._create_dataset(train=True)\n        return torch.utils.data.DataLoader(dataset, **self.cfg.trainloader)\n    def val_dataloader(self):\n        dataset = self._create_dataset(train = False)\n        return torch.utils.data.DataLoader(dataset, **self.cfg.valloader)","466a01ed":"def RMSELoss(yhat,y):\n    return torch.sqrt(torch.mean((yhat-y)**2))","2a6d61ad":"class Identity(nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, x):\n        return x\n\nclass ViT_model(pl.LightningModule):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        self.backbone = timm.create_model(cfg.model.name, pretrained=False)\n        self.backbone.load_state_dict(torch.load(cfg.model.weight))\n        for param in self.backbone.parameters():\n            param.requires_grad = False\n        self.backbone.head = nn.Linear(768, 1)\n        self.sigmoid = nn.Sigmoid()\n        self.criterion = nn.BCELoss()\n    \n    def forward(self, input):\n        x = self.backbone(input)\n        x = self.sigmoid(x)\n        return x\n    \n    def _step(self, batch):\n        img, target = batch\n        pred = self(img)\n        loss = self.criterion(pred, target)\n        return pred, target, loss\n    \n    def training_step(self, batch, batch_idx):\n        pred, target, loss = self._step(batch)\n        metric = RMSELoss(pred, target)\n        tensorboard_log = {'train_loss':loss, 'train_rmse':metric}\n        return {'loss':loss, 'rmse':metric, 'log':tensorboard_log}\n    \n    def validation_step(self, batch, batch_idx):\n        with torch.no_grad():\n            pred, target, loss = self._step(batch)\n            rmse = RMSELoss(pred*100.0, target*100.0)\n        return {'val_loss': loss, 'val_rmse': rmse}\n    \n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n        avg_rmse = torch.stack([x['val_rmse'] for x in outputs]).mean()\n        print(f\"Epoch {self.current_epoch} loss:{avg_loss} rmse:{avg_rmse}\")\n        self.log('val_rmse', avg_rmse)\n        tensorboard_logs = {'val_loss': avg_loss, 'val_rmse': avg_rmse}\n        return {'val_loss': avg_loss,\n                'val_rmse': avg_rmse,\n                'log': tensorboard_logs}\n            \n    def configure_optimizers(self):\n        optimizer = eval(self.cfg.optim.name)(self.parameters(), lr = self.cfg.optim.lr)\n        schedule = eval(self.cfg.lr_sched.name)(optimizer = optimizer, **self.cfg.lr_sched.params)\n        return [optimizer], [schedule]","5b49e020":"# train model and compute cv score\nif GET_CV:    \n    kfold = StratifiedKFold(n_splits = 5, shuffle = True)\n    for fold, (train_idx, val_idx) in enumerate(kfold.split(df[\"Id\"], df[\"Pawpularity\"])):\n        print('fold {} training start'.format(fold+1))\n        start = time.time()\n        # train_test_split\n        train_df = df.loc[train_idx].reset_index(drop=True)\n        val_df = df.loc[val_idx].reset_index(drop=True)\n        # define datamodule\n        dataloader = Dataloader(cfg, train_df, val_df)\n        # define model\n        model = ViT_model(cfg)\n        # define callbacks\n        earystopping = EarlyStopping(monitor=\"val_rmse\")\n        lr_monitor = callbacks.LearningRateMonitor()\n        loss_checkpoint = callbacks.ModelCheckpoint(\n            filename = None,\n            monitor=\"val_rmse\",\n            save_top_k=1,\n            mode=\"min\",\n            save_last=False,\n            )\n        logger = TensorBoardLogger(cfg.model.name)\n\n        trainer = pl.Trainer(\n            logger=logger,\n            max_epochs=cfg.optim.max_epochs,\n            callbacks=[lr_monitor, loss_checkpoint, earystopping],\n            gpus = 1)\n        trainer.fit(model, datamodule = dataloader)\n    \n    elapse = time.time() -start\n    print('fold {} complete -- {} seconds elapsed'.format(fold + 1, elapse))\nelse:\n    print('This Notebook is for commit, not for computing CV score')","e06edb23":"# inference on test set\nif not GET_CV:\n    transforms = build_transform(cfg)\n    dataset = TestDataset(df,cfg.data.image_dir, transforms)\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size = 128)\n    pawpularity = []\n    models = [ViT_model(cfg) for i in range(5)]\n    # load pretrained weights\n    weights_1 = torch.load('..\/input\/finetuned-pawpularity-vit\/epoch19-step4939.ckpt')['state_dict']\n    weights_2 = torch.load('..\/input\/finetuned-pawpularity-vit\/epoch19-step4939 (1).ckpt')['state_dict']\n    weights_3 = torch.load('..\/input\/finetuned-pawpularity-vit\/epoch19-step4939 (2).ckpt')['state_dict']\n    weights_4 = torch.load('..\/input\/finetuned-pawpularity-vit\/epoch19-step4939 (3).ckpt')['state_dict']\n    weights_5 = torch.load('..\/input\/finetuned-pawpularity-vit\/epoch19-step4939 (4).ckpt')['state_dict']\n    weights = [weights_1, weights_2, weights_3, weights_4, weights_5]\n    # load pretrained weights to model\n    for i, (model, weight) in enumerate(zip(models, weights)):\n        model.load_state_dict(weight)\n        model = model.eval()\n        models[i] = model.cuda()\n    # inference by averaging 5 outputs\n    for batch_idx, batch in enumerate(dataloader):\n        pred = torch.zeros(batch.shape[0], 1).cuda()\n        for model in models:\n            with torch.no_grad():\n                pred += model(batch.cuda())\n        pred = pred \/ 5.0\n        pred *= 100.0\n        pawpularity.append(pred)\n        # memory efficiency\n        torch.cuda.empty_cache()\n        del batch\n        gc.collect()\n        print(f'{64*(batch_idx+1)} image processed')\n    pawpularity = np.concatenate([tensor.cpu().numpy().reshape(-1,) for tensor in pawpularity])\n    df['Pawpularity'] = pawpularity\n    submission = df[['Id','Pawpularity']]\n    submission['Pawpularity'] = submission['Pawpularity'].astype(float)\n    submission.to_csv('submission.csv')\n    print('submission complete')","46915048":"# 4. Training with Pytorch Lightning","44be63fe":"# 3. Vision Transformer model","c5f49b02":"# 2. Data Pipeline","cbc7b0df":"# 5. Inference & Submission","365c27e4":"# 1. Model Config"}}