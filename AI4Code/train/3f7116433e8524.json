{"cell_type":{"da2c16bd":"code","529c9812":"code","457339da":"code","0fc19cd1":"code","6f4381d2":"code","6990d74b":"code","f056eead":"code","a7ca6c07":"code","73e26b59":"code","39e56ca7":"code","c107c6d0":"code","287b0900":"code","15fff866":"code","71ae0748":"code","a46e646d":"code","d46d4895":"code","b1cea20c":"code","2bf0d5e3":"code","11d234f8":"code","14ae332e":"code","029d9933":"code","c875455c":"code","642339af":"code","8cd1a6a3":"code","7c5a0ef3":"markdown","f300b0b9":"markdown","12520c4c":"markdown","87092ec4":"markdown","37324cb9":"markdown","77b5ed6f":"markdown","e99d23e2":"markdown","3570f3ed":"markdown","7bcba5e1":"markdown","67e46585":"markdown","45476809":"markdown","cd5d6be9":"markdown","5c92fb95":"markdown","bccc57be":"markdown","40d7905f":"markdown","4e505dcf":"markdown","aa5ce704":"markdown","ad3e2fe3":"markdown","83dc8de0":"markdown","a36155f3":"markdown","519f99aa":"markdown"},"source":{"da2c16bd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","529c9812":"# Importing the dataset\nimport pandas as pd\ndataset = pd.read_csv(\"..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv\")","457339da":"# Displaying the head of out dataset\ndataset.head()","0fc19cd1":"# Displaying the datatype and shape of the dataset\n\nprint(dataset.shape)\ndataset.dtypes","6f4381d2":"# Displaying the describe statistical info of each attribute\ndataset.describe()","6990d74b":"# Histogram visualisation for age column and know what kind of distribution  it is ?\n\nimport seaborn as sb\nsb.distplot(dataset['Age'])","f056eead":"# Histogram visualisation for Annual income column and know what kind of distribution  it is ?\n\nsb.distplot(dataset['Annual Income (k$)'])","a7ca6c07":"# Histogram visualiation for Spending Score column and to know what kind of distribution it is?\n\nsb.distplot(dataset['Spending Score (1-100)'])","73e26b59":"# Visualisation correlation coefficient of each attribute.\n\ncorr_value=dataset.corr()\nsb.heatmap(corr_value,square=True)","39e56ca7":"# Displying any empty or null values in our dataset\ndataset.info()","c107c6d0":"# Displying the empty or null value in our dataset to understand better how many missing cells there in each attribute\n\ndataset.isna().sum()","287b0900":"# Dropping CustomerID column \n\ndataset=dataset.drop(['CustomerID'],axis=1)\ndataset.head()","15fff866":"# Encoding the Gender column from categorical value into numerical value\n\ndataset['Gender'].unique()","71ae0748":"dataset['Gender']=dataset['Gender'].map({'Male':0,'Female':1})\ndataset['Gender'].unique()","a46e646d":"dataset.head()","d46d4895":"# Feature Split\nx=dataset.values\n\nprint(x[:5,:])","b1cea20c":"# Feature Scale\n\nfrom sklearn.preprocessing import MinMaxScaler\nminmaxscaler=MinMaxScaler()\nx=minmaxscaler.fit_transform(x)\nprint(x[:5,:])","2bf0d5e3":"# Elbow Method\n\nseed=5\n\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\nwcss=[]\n# n_init ----- Number of kmeans will run with different init centroids\n# max_iter------ Max Number of iterations to define that the final clusters\n# init='k-means++' ---- random initlization to handle random intialization trap\nfor i in range(1,11):\n    kmeans=KMeans(n_clusters=i,init='k-means++',max_iter=500,n_init=20,random_state=seed)\n    kmeans.fit(x)\n    wcss.append(kmeans.inertia_)\n    \nplt.plot(range(1,11),wcss)\nplt.title(\"Elbow method\")\nplt.xlabel(\"No.of Clusters\")\nplt.ylabel('WCSS')\nplt.show()","11d234f8":"# K-Means Cluster Algorithm\nkmeans=KMeans(n_clusters=4,init='k-means++',random_state=seed,max_iter=500,n_init=20)\ny_kmeans=kmeans.fit_predict(x)\n\n# Predicting the Customers with different segments\nprint(y_kmeans)\n","14ae332e":"plt.scatter(x[y_kmeans==0,0],x[y_kmeans==0,1],s=100,color='red',label='Cluster 1')\nplt.scatter(x[y_kmeans==1,0],x[y_kmeans==1,1],s=100,color='blue',label='Cluster 2')\nplt.scatter(x[y_kmeans==2,0],x[y_kmeans==2,1],s=100,color='green',label='Cluster 3')\nplt.scatter(x[y_kmeans==3,0],x[y_kmeans==3,1],s=100,color='cyan',label='cluster 4')\nplt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],s=200,color='yellow',label='Centroid')\nplt.title(\"Cluster Clients\")\nplt.xlabel('Annual income')\nplt.ylabel('spending score')\nplt.legend()\nplt.show()","029d9933":"# Dendo Gram plot is used to find optimal number of cluster..\n\nimport scipy.cluster.hierarchy as sch\ndendogram=sch.dendrogram(sch.linkage(x,method='ward'))\nplt.title('Dendogram')\nplt.xlabel('customers')\nplt.ylabel('Eulidean distance')\nplt.show()","c875455c":"# Hierarchical Clustering Algorithm to the mall dataset\nfrom sklearn.cluster import AgglomerativeClustering\nhc=AgglomerativeClustering(n_clusters=4)\nhc.fit(x)","642339af":"\n# Predict the cluster categories based on mall dataset\ny_hc=hc.fit_predict(x)\nprint(y_hc)","8cd1a6a3":"plt.scatter(x[y_kmeans==0,0],x[y_kmeans==0,1],s=100,color='red',label='Cluster 1')\nplt.scatter(x[y_kmeans==1,0],x[y_kmeans==1,1],s=100,color='blue',label='Cluster 2')\nplt.scatter(x[y_kmeans==2,0],x[y_kmeans==2,1],s=100,color='green',label='Cluster 3')\nplt.scatter(x[y_kmeans==3,0],x[y_kmeans==3,1],s=100,color='cyan',label='cluster 4')\nplt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],s=200,color='yellow',label='Centroid')\nplt.title(\"Cluster Clients\")\nplt.xlabel('Annual income')\nplt.ylabel('spending score')\nplt.legend()\nplt.show()","7c5a0ef3":"Perfect we don't have any missing values in our dataset so no need to remove any columns and rows..\n\nCustomerID is not required to make segementation cluster","f300b0b9":"# f. Feature Scale\n\nApplying the rescale technique to keep all input attribute value in the range of 0 to 1 by using MinMaxScaler","12520c4c":"To find optimal number of segmentation (Clusters) we are going to use Elbow Method.\n\nElbow Method is used get optimal no.of cluster value with elbow visualisation graph.","87092ec4":"# d. OneHotEncoder\n\nAs we done encoding the label of gender column, We dont need to apply onehotencoder because labeled values in between 0 and 1 only. So no need to apply one Hot Encoder.","37324cb9":"# 1. Data Analysis","77b5ed6f":"# e. Feature Split\n\nSplit the dataframe feature into input attribute of array of matrix","e99d23e2":"# a. K-Means\n\n# K-Means Elbow Method","3570f3ed":"As per Eulidean distance 3 giving the 4 optimal no.of clusters and because those 4 lines not interceting any lines.","7bcba5e1":"Above Histogram plot Annual income column data looks like normal distribution with wider Standard deviation","67e46585":"# b. Label Encoder","45476809":"We can't display the correlation coefficient values in heatmap, Because each attribute finds the coefficient value with output attribute.\n\nHere we dont have output attribute because it is an un-supervised learning. Here we are segmenting the culster of categories based on annual income and spending score.","cd5d6be9":"# a. Histogram Distribution Visualisation","5c92fb95":"# b. HeatMap Correlation Visualisation","bccc57be":"Age Attribute having similar kind of normal distribution with wider Standard Deviation.","40d7905f":"# b. Hierarchical Cluster\n\n# Hierarchical Dendo Gram","4e505dcf":"As per the above optimal Elbow method graph 4 cluster segemnetation will be great...","aa5ce704":"# c. Outliers\n\nIn unsupervised algorithm we wont have ouput attribute so we cant predict the outliters here.","ad3e2fe3":"# Visualising Result And Its Clusters.","83dc8de0":"# 2. Modeling","a36155f3":"Both K-Means and Hierarchical Cluster will be great algorithms for unsupervised cluster kind of problems but K-Means will give great performance......\n\nIf any questions please let me know...","519f99aa":"# Feature Engineering\n\n# a. Data Cleaning"}}