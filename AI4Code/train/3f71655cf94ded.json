{"cell_type":{"b5cbae5e":"code","f3635aa7":"code","66e958a2":"code","d1cf8624":"code","7be3a01d":"code","3a70bba7":"code","c56fdbff":"code","1cc370e7":"code","bf083119":"code","5774acc4":"code","c542e80f":"code","3bacda84":"code","847c474b":"code","1d86039b":"code","58b32d5c":"code","cc4fed36":"code","87e49efa":"code","095137b6":"markdown"},"source":{"b5cbae5e":"#Importing Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats","f3635aa7":"#Reading Data\nData= pd.read_csv('..\/input\/breast-cancer-prediction-dataset\/Breast_cancer_data.csv')\nData.head()\n#Data.shape","66e958a2":"#Breaking data in to labels and Features\nLabls= Data.diagnosis\nFeatures= Data.loc[:, ('mean_radius', 'mean_texture', 'mean_perimeter', 'mean_area', 'mean_smoothness')]\nFeatures.head()\nFeatures.shape","d1cf8624":"#Split data for training and testing\nfrom sklearn.model_selection import train_test_split\n#from sklearn.cross_validation import train_test_split\nXtrain, Xtest, Ytrain, Ytest= train_test_split(Features, Labls, test_size=0.3, shuffle=True)","7be3a01d":"#Importing Logistic regression from sklearn library\nfrom sklearn.linear_model import LogisticRegression\nLog_Reg=LogisticRegression()\n","3a70bba7":"#Training Model\nLog_Reg.fit(Xtrain, Ytrain)","c56fdbff":"#Perdiction\nLog_Reg.score(Xtrain, Ytrain)","1cc370e7":"#Loop for taking average result (More accurate)\nArray= 5*(np.arange(10))\nTest_Score=[]\nTrain_Score=[]\n\nfor i in Array:\n    Log_Reg= LogisticRegression(max_iter=i)\n    Log_Reg.fit(Xtrain, Ytrain)\n    Test_Score.append(Log_Reg.score(Xtest, Ytest))\n    Train_Score.append(Log_Reg.score(Xtrain, Ytrain))\n    \nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Logistic regression Accuracy graph\")\nplt.plot(Array, Train_Score, Label= 'Training Accuracy')\nplt.plot(Array, Test_Score, Label= 'Testing Accuracy')","bf083119":"#Normalizing data\nNormalized_Data= (Data-Data.min())\/(Data.max()-Data.min())\nNormalized_Data.head()","5774acc4":"# Breaking data in to labels and features (Noramalized data)\nLbls= Normalized_Data.diagnosis\nFtrs= Normalized_Data.loc[:, ('mean_radius', 'mean_texture', 'mean_perimeter', 'mean_area', 'mean_smoothness')]\nFtrs.head()","c542e80f":"#Split data for training and testing\nfrom sklearn.model_selection import train_test_split\n#from sklearn.cross_validation import train_test_split\nxtrain, xtest, ytrain, ytest= train_test_split(Ftrs, Lbls, test_size=0.3, shuffle=True)","3bacda84":"#Model call\nfrom sklearn.linear_model import LogisticRegression\nLog_Reg=LogisticRegression()\nLog_Reg.fit(xtrain, ytrain)","847c474b":"#Perdiction\nLog_Reg.score(xtrain, ytrain)","1d86039b":"#Loop for Normalized data\nArray= 5*(np.arange(10))\ntest_Score=[]\ntrain_Score=[]\n\nfor i in Array:\n    Log_Reg= LogisticRegression(max_iter=i)\n    Log_Reg.fit(xtrain, ytrain)\n    test_Score.append(Log_Reg.score(xtest, ytest))\n    train_Score.append(Log_Reg.score(xtrain, ytrain))\n    \nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Logistic regression Accuracy graph\")\nplt.plot(Array, Train_Score, Label= 'Training Accuracy')\nplt.plot(Array, Test_Score, Label= 'Testing Accuracy')","58b32d5c":"# Plotting confusion matrix\nfrom sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(Log_Reg, xtest, ytest)\n\n# Classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(Log_Reg.predict(xtest),ytest))","cc4fed36":"#Importing Naive bayes model from sklearn\nfrom sklearn.naive_bayes import GaussianNB\nNB_Model=GaussianNB()\nNB_Model.fit(xtrain, ytrain)\nNB_Model.score(xtest, ytest)","87e49efa":"# Plotting confusion matrix\nfrom sklearn.metrics import plot_confusion_matrix\nplot_confusion_matrix(NB_Model, xtest, ytest)\n\n# Classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(NB_Model.predict(xtest),ytest))","095137b6":"Logistic regression is a classification model. Bounded by 0 to 1 it gives real value(Probability)"}}