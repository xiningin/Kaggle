{"cell_type":{"52b32edf":"code","a0f37f20":"code","e028f915":"code","ff380529":"code","8939e647":"code","68668733":"code","12af6961":"code","a20503a4":"code","4caba874":"code","361386f3":"code","01710f69":"code","f526146a":"code","1bc3ac8c":"code","1ffb5c46":"code","2c6cc966":"code","662f00b7":"code","9cf74d96":"code","86fed305":"code","4a056886":"code","d69db2ac":"code","421175bc":"code","7380bcde":"code","2348676e":"code","d913fb4c":"code","6bb16b78":"code","d53dee32":"code","4eeffee3":"code","8021f3cb":"code","f444b0bb":"code","87f6c340":"code","07a6639d":"code","541f65e7":"code","2b69b963":"code","fd30dc46":"code","55f089e0":"code","97207276":"code","5889fefa":"code","fc11672c":"code","a73c5d7a":"code","925d9935":"code","cf5d7f1e":"code","6676e3d6":"code","0713cbb0":"code","6f87f2ef":"code","b7115f14":"code","0cf0eaf0":"code","0f41c0c0":"markdown","72603f3f":"markdown","85749b53":"markdown","1d364bff":"markdown","9906b938":"markdown","f418809e":"markdown","b1036101":"markdown","9dfbaa0d":"markdown","2a678ba7":"markdown","568586c7":"markdown","439ee565":"markdown","511a62a7":"markdown"},"source":{"52b32edf":"import numpy as np\nimport pandas as pd\n\nimport cv2 as cv\n\nfrom PIL import Image, ImageFilter\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import manifold, decomposition\nfrom sklearn.neural_network import MLPClassifier","a0f37f20":"PATH = '..\/input\/yelp-photos\/photos\/'","e028f915":"nbPictures = 125\nchunks = pd.read_json('..\/input\/yelp-photos\/photos.json', lines=True, chunksize = nbPictures)","ff380529":"df = pd.DataFrame(columns=['photo_id', 'label'])\nx = 0\nfor chunk in chunks:\n    if(x == 0):\n        if ((chunk.iloc[0].label == 'drink') & len(chunk.label.value_counts()) == 1):\n            df = pd.concat([df, chunk])   \n            x = x + 1\n    if(x == 1):    \n        if ((chunk.iloc[0].label == 'food') & len(chunk.label.value_counts()) == 1):\n            df = pd.concat([df, chunk])  \n            x = x + 1\n    if(x == 2):    \n        if ((chunk.iloc[0].label == 'interior') & len(chunk.label.value_counts()) == 1):\n            df = pd.concat([df, chunk])  \n            x = x + 1\n    if(x == 3):    \n        if ((chunk.iloc[0].label == 'outside') & len(chunk.label.value_counts()) == 1):\n            df = pd.concat([df, chunk])  \n            x = x + 1\n    if(x == 4):    \n        if ((chunk.iloc[0].label == 'menu') & len(chunk.label.value_counts()) == 1):\n            df = pd.concat([df, chunk])  \n            x = x + 1\n    if(x == 5):\n        break","8939e647":"df = df.assign(photo_id=lambda x: x + '.jpg')","68668733":"df","12af6961":"df_train = df.sample(round(5*nbPictures*(4\/5)),random_state=42)","a20503a4":"df_test = df.merge(df_train, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only']","4caba874":"df_train","361386f3":"for i in range (0,3):\n   \n    img = cv.imread(PATH + df_train.iloc[i].photo_id)\n    gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n    \n   \n    sift = cv.SIFT_create()\n    kp, desc = sift.detectAndCompute(gray,None)\n    \n    \n    img=cv.drawKeypoints(gray,kp,img)\n    img=cv.drawKeypoints(gray,kp,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n\n    display(Image.fromarray(img,\"RGB\"))","01710f69":"for i in range (0,3):\n   \n    img = cv.imread(PATH + df_train.iloc[i].photo_id)\n    gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n    \n        # Gaussian Blur\n    gray = Image.fromarray(gray).convert('L')\n    gray = gray.filter(ImageFilter.BoxBlur(3))\n    gray = np.array(gray)\n    \n   \n    sift = cv.SIFT_create()\n    kp, desc = sift.detectAndCompute(gray,None)    \n    \n    img=cv.drawKeypoints(gray,kp,img)\n    img=cv.drawKeypoints(gray,kp,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n\n    display(Image.fromarray(img,\"RGB\"))","f526146a":"df_train = df_train.reset_index(drop=True)\ndf_train","1bc3ac8c":"%%time\ndescriptors = []\n\nfor i, val in df_train[0:500].iterrows():\n    # Read image\n    img = cv.imread(PATH + df_train.iloc[i].photo_id)\n    gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n\n    # Gaussian Blur\n    gray = Image.fromarray(gray).convert('L')\n    gray = gray.filter(ImageFilter.BoxBlur(0))\n    gray = np.array(gray)\n\n    # Create descriptors\n    sift = cv.SIFT_create()\n    kp, desc = sift.detectAndCompute(gray,None)\n    try: \n        descriptors.append(desc[:])\n    except Exception: \n        print('Osef')","1ffb5c46":"print(len(descriptors))\nprint(descriptors[0].shape)","2c6cc966":"descriptors_vstacked = np.vstack(descriptors)\nprint(descriptors_vstacked.shape)","662f00b7":"from sklearn.cluster import KMeans, MiniBatchKMeans\nfrom sklearn.metrics import silhouette_score","9cf74d96":"k = int(round(np.sqrt(len(descriptors_vstacked)),0))\nprint('Estimated number of clusters:', k)","86fed305":"%%time\nkmeans = MiniBatchKMeans(n_clusters=k, init_size=3*k, random_state=42)\nkmeans.fit(descriptors_vstacked)","4a056886":"## From colab\ndef build_histogram(kmeans, des, image_num):\n    res = kmeans.predict(des)\n    hist = np.zeros(len(kmeans.cluster_centers_))\n    nb_des=len(des)\n    if nb_des==0 : print(\"error  : \", image_num)\n    for i in res:\n        hist[i] += 1.0\/nb_des\n    return hist\n\n\n# Creation of a matrix of histograms\nhist_vectors=[]\n\nfor i, image_desc in enumerate(descriptors) :\n    if i%100 == 0 : print(i)  \n    hist = build_histogram(kmeans, image_desc, i) #calculates the histogram\n    hist_vectors.append(hist) #histogram is the feature vector\n\nim_features = np.asarray(hist_vectors)","d69db2ac":"from sklearn import manifold, decomposition\n\nprint(\"Dimensions before PCA :\", im_features.shape)\npca = decomposition.PCA(n_components=0.99)\nfeat_pca= pca.fit_transform(im_features)\nprint(\"Dimensions after PCA :\", feat_pca.shape)","421175bc":"tsne = manifold.TSNE(n_components=2, random_state=42, perplexity=30)\nX_tsne = tsne.fit_transform(feat_pca)\n\ndf_tsne = pd.DataFrame(X_tsne[:,0:2], columns=['tsne1', 'tsne2'])\ndf_tsne[\"class\"] = df_train[\"label\"]\nprint(df_tsne.shape)","7380bcde":"df_tsne.head()","2348676e":"X_tsne.shape","d913fb4c":"plt.figure(figsize=(10,10))\nsns.scatterplot(x=\"tsne1\", y=\"tsne2\", hue=\"class\", data=df_tsne, s=100, alpha=0.6)\nplt.title('TSNE with true labels', fontsize = 15)\nplt.xlabel('tsne1', fontsize = 10)\nplt.ylabel('tsne2', fontsize = 10)\nplt.legend(prop={'size': 14})\n\nplt.ylim(-15, 15)\nplt.xlim(-15, 15)\n\nplt.show()","6bb16b78":"from sklearn import cluster, metrics\n\ncls = cluster.KMeans(n_clusters=5, random_state=42)\ncls.fit(X_tsne)\n\ndf_tsne[\"cluster\"] = cls.labels_\nprint(df_tsne.shape)","d53dee32":"score = silhouette_score(X_tsne, cls.labels_)  \nscore","4eeffee3":"plt.figure(figsize=(10,10))\nsns.scatterplot(x=\"tsne1\", y=\"tsne2\", hue=\"cluster\", data=df_tsne, legend=\"brief\",  s=50, alpha=0.6, palette=sns.color_palette('tab10', n_colors=5))\n\nplt.title('TSNE by clusters', fontsize = 15)\nplt.xlabel('tsne1', fontsize = 10)\nplt.ylabel('tsne2', fontsize = 10)\nplt.legend(prop={'size': 14})\n\nplt.ylim(-15, 15)\nplt.xlim(-15, 15)\n\nplt.show()\n\nlabels = df_train[\"label\"]\nprint(\"ARI : \", metrics.adjusted_rand_score(labels, cls.labels_))","8021f3cb":"df_tsne.groupby(\"cluster\").count()[\"class\"]","f444b0bb":"from sklearn import preprocessing\nlabels_encoded = preprocessing.LabelEncoder()\nlabels_encoded = labels_encoded.fit_transform(labels)","87f6c340":"print('Encoding :')\nprint(labels_encoded[0], labels[0],labels_encoded[100], labels[100],labels_encoded[200], labels[200],labels_encoded[300], labels[300],labels_encoded[400], labels[400])","07a6639d":"list_labels = [\"drink\", \"food\", \"interior\", \"menu\", \"outside\"]","541f65e7":"conf_mat = metrics.confusion_matrix(labels_encoded, cls.labels_)\nprint(conf_mat)","2b69b963":"def conf_mat_transform(y_true,y_pred) :\n    conf_mat = metrics.confusion_matrix(y_true,y_pred)\n    \n    #Use confusion matrix of the cell on top of this one to decide the corresp. You can do something like 'argmax' but cannot use two times the column ID. If you use argmax(), it may happen.\n    corresp = [3, 0, 4, 1, 2]\n    labels = pd.Series(y_true, name=\"y_true\").to_frame()\n    labels['y_pred'] = y_pred\n    labels['y_pred_transform'] = labels['y_pred'].apply(lambda x : corresp[x]) \n    \n    return labels['y_pred_transform']","fd30dc46":"cls_labels_transform = conf_mat_transform(labels_encoded, cls.labels_)\nconf_mat = metrics.confusion_matrix(labels_encoded, cls_labels_transform)","55f089e0":"df_cm = pd.DataFrame(conf_mat, index = [label for label in list_labels],\n                  columns = [i for i in \"01234\"])\nplt.figure(figsize = (6,4))\nsns.heatmap(df_cm, annot=True, cmap=\"Greens\")","97207276":"def createHist(imgName):\n    #Extract desc\n    img = cv.imread(PATH + imgName)\n    gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)   \n    sift = cv.SIFT_create()\n    kp, desc = sift.detectAndCompute(gray,None)\n    \n    #Build hist\n    hist = build_histogram(kmeans, desc, 0)\n    \n    return hist","5889fefa":"X = im_features\nY = labels_encoded","fc11672c":"mlp = MLPClassifier(verbose=False, max_iter=5000)\nmlp.fit(X, Y)","a73c5d7a":"def mlpPredict(imageName, mlp):\n    x = createHist(imageName)\n    predicted = mlp.predict_proba([x])\n    return result.loc[result.id == np.argmax(predicted)].label.values[0]    ","925d9935":"result = [(0, 'drink'),(1, 'food'),(2, 'interior'), (3, 'menu'), (4, 'outside')]\nresult = pd.DataFrame(columns=['id', 'label'], data=result)","cf5d7f1e":"mlpPredict('BFE1AFOs27scnnfeBf99ZA.jpg', mlp)","6676e3d6":"test_result = df_test[['photo_id', 'label']]\ntest_result['predicted'] = ''\ntest_result = test_result.reset_index(drop=True)","0713cbb0":"%%time\nfor i, val in test_result.iterrows():\n    test_result.loc[i].predicted = mlpPredict(val.photo_id, mlp)","6f87f2ef":"test_result['score'] = ''\nfor i, val in test_result.iterrows():\n    if(val.label == val.predicted):\n        test_result.loc[i].score = 1\n    else:\n        test_result.loc[i].score = 0","b7115f14":"test_result.score.value_counts(normalize=True)","0cf0eaf0":"test_result","0f41c0c0":"## KMeans clustering","72603f3f":"We may add a gaussian blur to reduce the number of descriptors.\nLet's see what it does below.","85749b53":"## MLP Classifier","1d364bff":"Accuracy : 0.47\n![t\u00e9l\u00e9chargement (94).png](attachment:81e43a68-09d6-421f-aa8d-ec9b8f83952a.png)","9906b938":"## TSNE","f418809e":"### Analyse par classe","b1036101":"## Testing SIFT\nWe are loading the image using OpenCV. Extracting keypoints and descriptors and drawing it back on the image.","9dfbaa0d":"## Creating bag-of-features","2a678ba7":"## Preparing data\nWe are generating a dataframe that contains 100 images for each label.","568586c7":"## Result","439ee565":"### MLP results","511a62a7":"## Reducing using PCA"}}