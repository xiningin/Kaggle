{"cell_type":{"81c22270":"code","288b21ab":"code","714a8c4e":"code","fd8e6ea5":"code","cfbadfea":"code","166363e2":"code","2de08627":"code","8d447398":"code","12b8edb5":"code","cf128e89":"code","b18ffbd6":"code","dd70f50e":"code","da7b063c":"code","062b98b0":"code","8ea8f260":"code","3a786938":"markdown","d8d31aca":"markdown","1df8b41c":"markdown","c2dfe52a":"markdown","7c4dac50":"markdown","6dda35a7":"markdown","5a90dfcc":"markdown"},"source":{"81c22270":"#Show some images\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nplt.figure(figsize=(28,5)) #Size for the plot\n\nphotos_akali = '..\/input\/tft-champions-cards\/TFT\/TFT\/Champions_Card\/Akali' #Img to plot\nimg = os.listdir(photos_akali) #Img list\n\nfor i, nameimg in enumerate(img[:16]):  #Loop for a total of 16 images\n    plt.subplot(2,8,i+1) #Rows 2, cols  8 and position for each img\n    img = mpimg.imread(photos_akali + '\/' + nameimg) #Read the img\n    plt.imshow(img)  #Show img","288b21ab":"#Argumentation with ImageDataGenerator\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\n\n#Create the dataset generator\ndatagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    rotation_range = 0,\n    width_shift_range = 0,\n    height_shift_range = 0,\n    shear_range = 0,\n    zoom_range = [0.5, 1.5],\n    validation_split=0.2 #Take 20% of img for validation\n)\n\n#Generators for train and test\ndata_gen_train = datagen.flow_from_directory('..\/input\/tft-champions-cards\/TFT\/TFT\/Champions_Card', target_size=(224,224), #At the same time resize images to 224x224\n                                                     batch_size=32, shuffle=True, subset='training')                   #To training\ndata_gen_test = datagen.flow_from_directory('..\/input\/tft-champions-cards\/TFT\/TFT\/Champions_Card', target_size=(224,224),  #At the same time resize images to 224x224\n                                                     batch_size=32, shuffle=True, subset='validation')                 #To validation\n\n\nplt.figure(figsize=(15,5)) #Size for the plot\n#Print 10 img of the argumentation\nfor img, label in data_gen_train:\n    for i in range(10):\n        plt.subplot(2,5,i+1)  #Rows, cols and position\n        #plt.xticks([])  #Delete size of x\n        #plt.yticks([])  #Delete size of y\n        plt.imshow(img[i])  #Show img\n    break\nplt.show()","714a8c4e":"import tensorflow as tf\nimport tensorflow_hub as hub\n\n#Pre-trained model mobilenet_v2 for TensorFlow 2\n#For this module, the size of the input images is fixed to height x width = 224 x 224 pixels.\n#For more information visit thr url\nurl = \"https:\/\/tfhub.dev\/google\/tf2-preview\/mobilenet_v2\/feature_vector\/4\"\nmobilenetv2 = hub.KerasLayer(url, input_shape=(224,224,3)) # Batch input shape. ","fd8e6ea5":"#Freez the model\nmobilenetv2.trainable = False","cfbadfea":"#Change the last layer\nmodel = tf.keras.Sequential([\n    mobilenetv2,\n    tf.keras.layers.Dense(60, activation='softmax') #To 60 because we have 59 champions and 1 for the empty\n])","166363e2":"#Show the summary of the pre-trained model\nmodel.summary()","2de08627":"#Compile the model \nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","8d447398":"#Train the model, with 15 epochs is enough \nepochs = 10\n\nrecord = model.fit(\n    data_gen_train, epochs=epochs, batch_size=32, #Data_gen_train for the train dataset\n    validation_data=data_gen_test                 #Validation_data for the validation dataset\n)","12b8edb5":"#Train graph\nacc = record.history['accuracy']  #Get the values of accuracy\nval_acc = record.history['val_accuracy']  #Get the values of validation accuracy\n\nloss = record.history['loss']  #Get the values of loss\nval_loss = record.history['val_loss']  #Get the values of validation loss\n\n#Range of epoch for the graph\nrango_epochs = range(10) #Total of epoch is 15\n\n#Accuracy graph\nplt.figure(figsize=(8,8)) #Size for the plot of graphs\nplt.subplot(1,2,1)  #Rows, cols and position\nplt.plot(rango_epochs, acc, label='Training Accuracy')\nplt.plot(rango_epochs, val_acc, label='Accuracy Testing')\nplt.legend(loc='lower right')\nplt.title('Training and testing accuracy')\n\n#Loss graph\nplt.subplot(1,2,2) #Rows, cols and position\nplt.plot(rango_epochs, loss, label='Loss of training')\nplt.plot(rango_epochs, val_loss, label='Loss of testing')\nplt.legend(loc='upper right')\nplt.title('Loss of training and testing')\nplt.show()","cf128e89":"#Classify an Image\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\nimport cv2\n\nfolders = '..\/input\/tft-champions-cards\/TFT\/TFT\/Champions_Card'  #Folder of all champions\nfloders_nm = sorted((os.listdir(folders)))  #Get the folders name and sort alphabetically\n\n#From the dataset\ndef classify_ds(img):\n    img = Image.open(img)  #Open the image\n    img = np.array(img).astype(float)\/255  #Make an array with the image\n\n    img = cv2.resize(img, (224,224))  #Resize the image to 224x224\n    prediction = model.predict(img.reshape(-1, 224, 224, 3))  #Make the prediction\n    return np.argmax(prediction[0], axis=-1)  #Return the result\n\n#Form a screenshot\ndef classify_ssh(cut_image):\n    img = np.array(cut_image).astype(float)\/255 #Make an array with the image\n    img = cv2.resize(img, (224,224)) #Resize the image to 224x224\n    prediction = model.predict(img.reshape(-1, 224, 224, 3)) #Make the prediction\n    return np.argmax(prediction[0], axis=-1)  #Return the result","b18ffbd6":"#Predicting an image from the dataset in a easy way\nimg = '..\/input\/tft-champions-cards\/TFT\/TFT\/Champions_Card\/Akali\/Akali.jpg' #Akali dataset Image \npred = classify_ds(img)  #Call the model\nprint(pred)  #Print the prediction with an image of Akali and it should be 0","dd70f50e":"#Predicting an image from the dataset with the name\nimg = '..\/input\/tft-champions-cards\/TFT\/TFT\/Champions_Card\/Akali\/Akali.jpg' #Dataset Image \npred = classify_ds(img)  #Call the model\nprint(\"The champions is: \" + floders_nm[pred])  #Print the name of the folder regarding prediction","da7b063c":"#Predicting an image from a screenshot\nimport cv2\n\nx1,x2=480,670 #x for the rectangle \ny1,y2=930,1070#y for the rectangle\nchamp_lst=[]\n\nimage = mpimg.imread('..\/input\/tft-champions-cards\/TFT\/TFT\/Cap_Screen\/TFT (6).png') #Read an img to show\nimg = cv2.imread(\"..\/input\/tft-champions-cards\/TFT\/TFT\/Cap_Screen\/TFT (6).png\")  #Read an img to cut\nrows, cols, _= img.shape  #Obtain rows and cols of the img\n\nplt.figure(figsize=(15,5)) #Size for the plot of img\nplt.subplot(1,1,1) #Rows, cols and position\nplt.imshow(image) #Show img\nplt.figure(figsize=(15,5)) #Size for the plot of img\n\nfor x in range(1,6):\n    cut_image = img[y1:y2,x1:x2]  #Cut the img in a rectangle around the champion card\n    x1=x1+200 #We move 200 pixels in x to the rigth towards the other card\n    x2=x2+200 #We don't move in y because all the cards are in the same y axix \n    plt.subplot(2,5,x) #Rows, cols and position\n    plt.imshow(cut_image) #Show img\n    pred = classify_ssh(cut_image) #Prediction of the cut_image\n    champ_lst.append(floders_nm[pred])\n    \nprint(\"The champions are: \") #Print the prediction  \nprint(champ_lst)","062b98b0":"model.save('Pred_Store.h5')","8ea8f260":"import os\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\nprint(tf.version.VERSION)","3a786938":"**First of all let's see some examples of images in this dataset**","d8d31aca":"# **TFT**\n\n**First of all, what is tft?**\n\nTeamfight Tactics (TFT) is an auto battler game developed and published by Riot Games. The game is a spinoff of League of Legends and is based on Dota Auto Chess, where players compete online against seven other opponents by building a team to be the last one standing.\n\n![TFT](https:\/\/esports.as.com\/2021\/10\/15\/league-of-legends\/tacticas-maestras--tft\/Set-TFT_1510658937_828325_1064x600.jpg)\n\nNow this dataset is for the champions cards there are in the \"store\" of the game\n\n\nThe objective of this dataset is to be the first part of an assistant for the game or an AI that can play","1df8b41c":"# **Argumentation**\n\n**How do I get more data, if I don\u2019t have \u201cmore data\u201d?**\n\nYou don\u2019t need to hunt for novel new images that can be added to your dataset. Why? Because, neural networks aren\u2019t smart to begin with. For instance, a poorly trained neural network would think that these three tennis balls shown below, are distinct, unique images.\n\n![image.png](attachment:708712be-cdd2-43b1-b8c7-e49850a4f824.png)\n\nSo, to get more data, we just need to make minor alterations to our existing dataset. Minor changes such as flips or translations or rotations. Our neural network would think these are distinct images anyway.\n\n![image.png](attachment:54ac4c04-d9d7-4144-aeae-bcdbef54bc50.png)\n\nA convolutional neural network that can robustly classify objects even if its placed in different orientations is said to have the property called invariance. More specifically, a CNN can be invariant to translation, viewpoint, size or illumination (Or a combination of the above).\n\nIn order words, to avoid overfitting problem, we need to artificially expand our dataset. We can make your existing dataset even larger. The idea is to alter the training data with small transformations to reproduce the variations. Approaches that alter the training data in ways that change the array representation while keeping the label the same are known as data augmentation techniques. Some popular augmentations people use are grayscales, horizontal flips, vertical flips, random crops, color jitters, translations, rotations, and much more.\n\n![Arg.png](attachment:95b709ad-4150-4ced-aea5-1fab6b12b6ff.png)\n\nPlease read through the following article in case you need more information: [Click Here](https:\/\/nanonets.com\/blog\/data-augmentation-how-to-use-deep-learning-when-you-have-limited-data-part-2\/)\n\n","c2dfe52a":"In the last metod we have a simple prediction and was a \"0\" because only return a numer by the sequence of the folders\n* 0 Akali\n* 1 Bliz\n* 2 Braum\n* 3 Cait\n* 4 Camile\n* 5 etc...\n\nNow in the next code we obtain the name of the champion instead of a numer","7c4dac50":"**Now we have a train model to use**\n\nFor the first experiment we only made a simple prediction, but at once we made the functions to made other predictions","6dda35a7":"# **Steal a model**\n\nWell we don't steal a model, we only usea a pre-trained model from tensorflow hub\n\nIn this code [mobilenet v2](https:\/\/tfhub.dev\/google\/tf2-preview\/mobilenet_v2\/feature_vector\/4) without feature vector is used and this is perfect because in a simple way don't have the last layer","5a90dfcc":"# **Screenshot**\n\nNow we made a prediction based in a screenshot of the game that return us a list with the name of all champions in the store\n\nTo make this only cut a image in a rectangle around the champion card and make the prediction, we made the same for each card"}}