{"cell_type":{"c75b0843":"code","f26f592d":"code","908ea105":"code","ccabb7b5":"code","13150b26":"code","e0371dbf":"code","a9babf98":"code","0425711d":"code","683e8dd3":"code","2d3653f3":"code","2ffaa1b4":"code","abfce6e3":"code","356a815d":"code","883b3f52":"code","19623194":"code","d00b7629":"code","312417ef":"code","7deb3755":"code","ad14584f":"code","e2f41449":"code","2c17b013":"code","20ff903d":"code","ddc7fb45":"code","d0115715":"code","cb6d11ae":"code","51d23682":"code","0dd3a36c":"code","10663f48":"code","017d126d":"code","aa4689ba":"code","45ccbed0":"code","99950a93":"code","9d8c78af":"code","2b81902b":"code","126afdaa":"code","4ba609be":"code","97067fee":"code","a4a6f91d":"code","d0268031":"code","d8bb5360":"code","ca6678aa":"code","13005765":"code","b041fd87":"code","ff543ff8":"code","7d2d56a1":"code","fbc4d81b":"code","98cca5d2":"code","08ff2326":"code","a6c14af9":"code","d4fc28c7":"code","4d87ef1e":"code","ea3d6cda":"code","0f6c6ac3":"code","1ec58be5":"code","8b303b90":"code","da382f49":"code","556c8fec":"code","dc91f06a":"code","376a3f87":"code","acfc415f":"code","e7407633":"code","f0be5082":"code","a3ce244c":"code","58caccb6":"code","3c9e063d":"code","3c6fa5be":"code","e23b3a88":"code","c226a6c1":"code","7011ff1a":"code","7f04a423":"code","a82ccaea":"code","ef5af7b9":"code","43a07a09":"code","08fd94d0":"code","59383225":"code","eb0658ca":"code","8ea9fa60":"code","d63816c1":"code","ce896aeb":"code","2219731e":"code","59d316b6":"code","752bb144":"code","32486829":"code","6e2f5ac5":"code","cd94e2a7":"code","bc588cf0":"code","ca61018a":"code","29f8277a":"code","83c5866e":"code","7139fdb8":"code","efb4038f":"code","f64ed7e3":"code","3e9b7f91":"code","d5d7ea46":"code","4863356a":"code","9ff83644":"code","d56fed10":"code","8a2e66d7":"code","0da741f0":"code","c4eb83b4":"code","96edfb68":"code","ece7c453":"code","8652f46c":"code","491d529a":"code","41c7d2be":"code","0eb40209":"code","e29b913b":"code","9d055b0e":"code","a4607803":"code","c9b195e7":"code","cd2645a4":"code","76df74a4":"code","80cc396a":"code","6d23847a":"code","b0a2d451":"code","7c4f2b66":"code","741f7365":"code","0d303d82":"code","f0bfbdf7":"code","53f6b228":"code","63bea607":"code","bc2d842e":"code","f1fd7df7":"code","881baff5":"code","4865d17b":"code","42377009":"code","5d167fca":"code","93183404":"code","8e4ffe7a":"code","7953b74d":"code","654c31f7":"code","3e32e135":"code","9de649d5":"code","1ae8892b":"code","f96f03cf":"code","06724bc8":"code","c1b126b1":"code","0d669aae":"code","79cdd8fe":"code","d114bd9a":"code","8e8faf3a":"code","ab06766a":"code","e7f55e7a":"code","ec139b07":"code","505c5825":"code","af9e66fd":"code","be37113b":"code","8cd6d128":"code","151bfb14":"code","7723af2b":"code","96e08b25":"code","b854ceb8":"code","3671e9d8":"code","1096ad8d":"code","1e6cbfbf":"code","946d35b7":"code","bae095c0":"code","b50045c0":"code","0fca06d4":"code","06c1de10":"code","78b7d538":"code","def287ec":"code","9bf7ee66":"code","a0c3af5b":"code","052a1590":"code","fb0c764f":"code","d32234bc":"code","4d4bece0":"code","4ecbd075":"code","a23c093e":"code","fdc9e425":"code","d4d8a38e":"code","6b4e2bef":"code","c1ce775e":"code","5d2a96ab":"code","4c73f890":"code","b9cd07c9":"code","14e25ec9":"code","ce703ff6":"code","5b9b5526":"code","4a8ff7bc":"code","2752f7de":"code","bb59c8fc":"code","d44fdde5":"code","37e1ec8a":"code","2fb9b9d8":"code","72570497":"code","b59901fd":"code","494a4d1e":"code","fc996a7d":"code","6bc3e8b9":"code","65d9f6ae":"code","6861b3fd":"code","a235d2ba":"code","c939bc5e":"code","c12ac79e":"code","3dec96ef":"code","db77eaab":"code","40fb3c4f":"code","1019a251":"code","adb11149":"code","f710e594":"code","70c86f67":"code","4d20b660":"code","336020e8":"code","abf7d9aa":"code","135f3c4a":"code","efb653e4":"code","bbc1c0cb":"code","ac89426a":"code","50609d97":"code","8736476e":"code","6d1a72e9":"code","9be7640f":"code","6a27ae55":"code","7cb3ca0c":"code","d27e7666":"code","3119df35":"code","9faa97f1":"code","476d3fb2":"code","fa39f38d":"code","0b145f81":"code","47851a59":"code","5c717f93":"code","7b2a843a":"code","fe464be4":"code","76aa0409":"code","77a9f0a7":"code","cf956762":"code","4b05663d":"code","978c734a":"code","9c8f0373":"code","f175a39e":"code","f9c39a27":"code","8458709f":"code","6acdb1ed":"code","05c46a43":"code","8c813d07":"code","c2ba48f7":"code","c46dfda0":"code","432853c3":"code","36bf6c57":"code","035b876f":"code","d6dac791":"code","8c964c73":"code","fc1eeec6":"code","42d2fd3d":"code","5fca64f6":"code","33ddb7ff":"code","7c9f241e":"code","3419a4b0":"code","cbb58123":"code","81c53b63":"code","871f3d59":"code","525a62dd":"code","bd52bc99":"code","03ee68f4":"code","7e1456a9":"code","e6e90ded":"code","2557d19a":"code","ae16e309":"code","45e07722":"code","0e59a417":"code","d8801900":"code","b1da7044":"code","b057a4aa":"code","c963528d":"code","a08a2c01":"code","4e434c7e":"code","d818cca5":"code","ef39814b":"code","d90f88e9":"code","e27c4341":"code","58c5d7e2":"code","4731a762":"code","61712a38":"code","ddd83255":"code","10bed3a5":"code","68c311c5":"code","e431551b":"code","61e08f2d":"code","4531655c":"code","c9d088a1":"code","fc5ad456":"code","936360d7":"code","dd8e1a78":"code","2864155a":"code","1dc9f393":"code","e2a34a3e":"code","a772da82":"code","77278a0e":"code","00b05812":"code","8a16b855":"code","dd0c0c8d":"code","3b344096":"code","f7f2245e":"code","ddfeb3c6":"code","a77d0c6a":"code","a00de45e":"code","4e08ad1f":"code","f5cb7fee":"code","b0c0b9f2":"code","81025c79":"code","20518ba6":"code","77c14ecb":"code","90ee14a4":"code","98e9e1aa":"code","62b12ce5":"code","bd3ff985":"code","79259be1":"code","ce083c35":"code","51b12e38":"code","8fa80ab7":"code","dee32e8f":"code","cdb14712":"code","2f996687":"code","837999fb":"code","bf361df8":"code","cd543c47":"code","80ebcb40":"code","23cf8393":"code","5762977d":"code","042c85e5":"code","d4de20e5":"code","c47d7a64":"code","ae509a59":"code","92482878":"code","64b957f3":"code","0aa425aa":"code","236d4439":"code","23666983":"code","f9e3e0ed":"code","04f0cb79":"code","4c153567":"code","0189eaf6":"code","1614d8fb":"markdown","5bb0c2ae":"markdown","b48f6f8e":"markdown","8e325472":"markdown","ba9cc552":"markdown","288feb2d":"markdown","fad21803":"markdown","45f7b0df":"markdown","33f7115e":"markdown","72b59776":"markdown","632cd58e":"markdown","198426fa":"markdown","d7625f85":"markdown","3fa81f46":"markdown","0014610c":"markdown","6d4d6f57":"markdown","7a35684b":"markdown","b216ba98":"markdown","3add0f95":"markdown","1751eb80":"markdown","721762f3":"markdown","83ce154f":"markdown","73a6f847":"markdown","fcf4e689":"markdown","43a79498":"markdown","d3b0687a":"markdown","fe613b89":"markdown","27a81bd5":"markdown","5edab29c":"markdown","78c71e04":"markdown","b866330d":"markdown","d0d3e3c2":"markdown","f9732b54":"markdown","1e14be0b":"markdown","6bb33d83":"markdown","33ec5c98":"markdown","96bae9d5":"markdown","4361ca63":"markdown","7a28e654":"markdown","9dde99c5":"markdown","f91acb30":"markdown","e44f2a1b":"markdown","4c928086":"markdown","3432fe76":"markdown","42ae034f":"markdown","34d14119":"markdown","d8453beb":"markdown","bd961499":"markdown","52818654":"markdown","7c84918c":"markdown","0939227c":"markdown","14d4f3b8":"markdown","a97628e3":"markdown","2bb6cc12":"markdown","374bed76":"markdown","247de8b6":"markdown","a2639b8e":"markdown","891fbbf4":"markdown","4e87dc40":"markdown"},"source":{"c75b0843":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()","f26f592d":"pd.set_option('display.max_columns', 143)","908ea105":"HPtrain=pd.read_csv('..\/input\/train.csv')\n\nHPtest=pd.read_csv('..\/input\/test.csv')\n\nHPsample=pd.read_csv('..\/input\/sample_submission.csv')","ccabb7b5":"HPtrain.head()","13150b26":"HPtrain.shape","e0371dbf":"HPtrain.describe().append(HPtrain.isnull().sum().rename('isnull'))","a9babf98":"HPtest.head()","0425711d":"HPtest.shape","683e8dd3":"HPtest.describe().append(HPtest.isnull().sum().rename('isnull'))","2d3653f3":"HPsample.head()","2ffaa1b4":"from collections import Counter\na=Counter(HPtrain['r4t3'])\nb=Counter(HPtrain['tamhog'])\na-b","abfce6e3":"from collections import Counter\na0=Counter(HPtrain['tamviv'])\nb0=Counter(HPtrain['tamhog'])\na0-b0","356a815d":"from collections import Counter\na1=Counter(HPtrain['r4t3'])\nb1=Counter(HPtrain['tamviv'])\na1-b1","883b3f52":"from collections import Counter\na2=Counter(HPtrain['r4t3'])\nb2=Counter(HPtrain['hhsize'])\na2-b2","19623194":"from collections import Counter\na3=Counter(HPtrain['tamviv'])\nb3=Counter(HPtrain['hhsize'])\na3-b3","d00b7629":"from collections import Counter\na4=Counter(HPtrain['tamhog'])\nb4=Counter(HPtrain['hhsize'])\na4-b4","312417ef":"from collections import Counter\na3=Counter(HPtrain['hhsize'])\nb3=Counter(HPtrain['hogar_total'])\nprint(a3-b3)","7deb3755":"from collections import Counter\na5=Counter(HPtrain['tamhog'])\nb5=Counter(HPtrain['hogar_total'])\nprint(a5-b5)","ad14584f":"from collections import Counter\na6=Counter(HPtrain['SQBage'])\nb6=Counter(HPtrain['agesq'])\nprint(a6-b6)\n\nfrom collections import Counter\nat6=Counter(HPtest['SQBage'])\nbt6=Counter(HPtest['agesq'])\nprint(at6-bt6)","e2f41449":"HPtrain.drop(['hhsize', 'hogar_total' and 'agesq'],axis=1,inplace=True)\n\nHPtest.drop(['hhsize', 'hogar_total' and 'agesq'],axis=1,inplace=True)","2c17b013":"HPtrain['r4t3'].unique()","20ff903d":"HPtrain['tamhog'].unique()","ddc7fb45":"HPtrain['tamviv'].unique()","d0115715":"HPtrain.loc[HPtrain['tamviv']==15]","cb6d11ae":"del HPtrain['tamhog']\n\ndel HPtest['tamhog']","51d23682":"del HPtrain['tamviv']\n\ndel HPtest['tamviv']","0dd3a36c":"HPtrain.shape","10663f48":"HPtrain.head()","017d126d":"HPtrain.describe().append(HPtrain.isnull().sum().rename('isnull'))","aa4689ba":"HPtest.describe().append(HPtest.isnull().sum().rename('isnull'))","45ccbed0":"HPtrain.loc[((HPtrain['v2a1'].isnull())|(HPtrain['tipovivi3']==0)),['v2a1','tipovivi3','tipovivi2']]","99950a93":"HPtrain.loc[((HPtrain['v2a1'].notnull()) & (HPtrain['tipovivi3']==0)),['v2a1','tipovivi3','tipovivi2']]","9d8c78af":"HPtrain['v2a1']= HPtrain['v2a1'].fillna(value=0)\n\nHPtest['v2a1']= HPtest['v2a1'].fillna(value=0)","2b81902b":"HPtrain.loc[(HPtrain['v18q1'].isnull()) & (HPtrain['v18q']==0),['Id', 'v18q1', 'v18q', 'idhogar', 'age','Target']]","126afdaa":"HPtrain.loc[HPtrain['v18q1']!=HPtrain['v18q'],['Id', 'v18q1', 'v18q',  'idhogar','age']]","4ba609be":"HPtrain['v18q1']= HPtrain['v18q1'].fillna(value=0.0)\n\nHPtest['v18q1']= HPtest['v18q1'].fillna(value=0.0)","97067fee":"HPtrain.loc[((HPtrain['rez_esc'].isnull()) & (HPtrain['age']>=18) | (HPtrain['age']<=6)),['rez_esc','age']]","a4a6f91d":"HPtrain.loc[((HPtrain['rez_esc'].isnull()) & (HPtrain['age']>6) & (HPtrain['age']<18)),['Id','rez_esc','age','dis']]","d0268031":"HPtrain['rez_esc'].unique()","d8bb5360":"HPtrain['rez_esc']= HPtrain['rez_esc'].fillna(value=0.0)\n\nHPtest['rez_esc']= HPtest['rez_esc'].fillna(value=0.0)","ca6678aa":"HPtrain.loc[HPtrain['meaneduc'].isnull(), ['Id', 'meaneduc', 'age', 'rez_esc','hogar_nin', 'hogar_adul', 'hogar_mayor', 'r4t3']]","13005765":"HPtrain['meaneduc']= HPtrain['meaneduc'].fillna(value=0.0)\n\nHPtest['meaneduc']= HPtest['meaneduc'].fillna(value=0.0)","b041fd87":"HPtrain['SQBmeaned']= HPtrain['SQBmeaned'].fillna(value=0.0)\n\nHPtest['SQBmeaned']= HPtest['SQBmeaned'].fillna(value=0.0)","ff543ff8":"print(HPtrain.shape)\n\nprint(HPtest.shape)","7d2d56a1":"print(HPtrain.isnull().sum().sum())\n\nprint(HPtest.isnull().sum().sum())","fbc4d81b":"HPtrainC=HPtrain.copy()\nHPtestC=HPtest.copy()","98cca5d2":"HPtrainC.dtypes","08ff2326":"HPtrainC.head()","a6c14af9":"print(HPtrainC.shape)\n\nprint(HPtestC.shape)","d4fc28c7":"cols=list(HPtrainC.columns)","4d87ef1e":"print(cols)","ea3d6cda":"HPtrainC=HPtrainC[['idhogar','Id', 'male', 'female', 'v2a1', 'r4h1', 'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t1', 'r4t2','hogar_nin', 'hogar_adul', 'hogar_mayor', 'r4t3', 'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', 'parentesco1', 'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6','parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', 'parentesco11', 'parentesco12','escolari', 'rez_esc', 'paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother', 'pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera', 'techozinc', 'techoentrepiso', 'techocane', 'techootro', 'cielorazo', 'abastaguadentro', 'abastaguafuera', 'abastaguano', 'public', 'planpri', 'noelec', 'coopele', 'sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6', 'energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4', 'elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6', 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'dis',  'dependency', 'edjefe', 'edjefa', 'meaneduc', 'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9', 'hacdor', 'rooms', 'hacapo', 'v14a', 'refrig', 'v18q', 'v18q1', 'bedrooms', 'overcrowding', 'tipovivi1', 'tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5', 'computer', 'television', 'mobilephone', 'qmobilephone', 'lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6', 'area1', 'area2', 'age', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned', 'Target']].copy()\n\nHPtestC=HPtestC[['idhogar','Id', 'male', 'female', 'v2a1', 'r4h1', 'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t1', 'r4t2','hogar_nin', 'hogar_adul', 'hogar_mayor', 'r4t3', 'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', 'parentesco1', 'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6','parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', 'parentesco11', 'parentesco12','escolari', 'rez_esc', 'paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother', 'pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera', 'techozinc', 'techoentrepiso', 'techocane', 'techootro', 'cielorazo', 'abastaguadentro', 'abastaguafuera', 'abastaguano', 'public', 'planpri', 'noelec', 'coopele', 'sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6', 'energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4', 'elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6', 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'dis',  'dependency', 'edjefe', 'edjefa', 'meaneduc', 'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9', 'hacdor', 'rooms', 'hacapo', 'v14a', 'refrig', 'v18q', 'v18q1', 'bedrooms', 'overcrowding', 'tipovivi1', 'tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5', 'computer', 'television', 'mobilephone', 'qmobilephone', 'lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6', 'area1', 'area2', 'age', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned']].copy()","0f6c6ac3":"print(HPtrainC.shape)\n\nprint(HPtestC.shape)","1ec58be5":"HPtrainC.head(10)","8b303b90":"HPtestC.head(10)","da382f49":"print(list(HPtrainC.columns))","556c8fec":"HPtrainN=HPtrainC[['idhogar','v2a1', 'r4h1', 'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t1', 'r4t2','hogar_nin', 'hogar_adul', 'hogar_mayor', 'r4t3', 'paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother', 'pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera', 'techozinc', 'techoentrepiso', 'techocane', 'techootro', 'cielorazo', 'abastaguadentro', 'abastaguafuera', 'abastaguano', 'public', 'planpri', 'noelec', 'coopele', 'sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6', 'energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4', 'elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6', 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'dependency', 'edjefe', 'edjefa', 'meaneduc', 'hacdor', 'rooms', 'hacapo', 'v14a', 'refrig', 'v18q1', 'bedrooms', 'overcrowding', 'tipovivi1', 'tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5', 'computer', 'television', 'qmobilephone', 'lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6', 'area1', 'area2', 'Target']].copy()\n\nHPtestN=HPtestC[['idhogar','v2a1', 'r4h1', 'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t1', 'r4t2','hogar_nin', 'hogar_adul', 'hogar_mayor', 'r4t3', 'paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother', 'pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera', 'techozinc', 'techoentrepiso', 'techocane', 'techootro', 'cielorazo', 'abastaguadentro', 'abastaguafuera', 'abastaguano', 'public', 'planpri', 'noelec', 'coopele', 'sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6', 'energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4', 'elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6', 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'dependency', 'edjefe', 'edjefa', 'meaneduc', 'hacdor', 'rooms', 'hacapo', 'v14a', 'refrig', 'v18q1', 'bedrooms', 'overcrowding', 'tipovivi1', 'tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5', 'computer', 'television', 'qmobilephone', 'lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6', 'area1', 'area2']].copy()\n\ntest_predict= HPtestC[['idhogar', 'Id']].copy()","dc91f06a":"print(HPtrainN.shape)\n\nprint(HPtestN.shape)\n\nprint(test_predict.shape)","376a3f87":"HPtrainN.head()","acfc415f":"# This give us an estimate of the number of households in the train\/test dataset\nprint(HPtrainN['idhogar'].nunique())\n\nprint(HPtestN['idhogar'].nunique())","e7407633":"HPtrainN.drop_duplicates(subset='idhogar', keep='first', inplace=True)\n\nHPtestN.drop_duplicates(subset='idhogar', keep='first', inplace=True)","f0be5082":"print(HPtrainN.shape)\n\nprint(HPtestN.shape)","a3ce244c":"HPtrainN['area2'].unique()","58caccb6":"HPtrainN['area1'].value_counts().plot(kind='bar')\nsns.despine","3c9e063d":"HPtrainN['area2'].value_counts().plot(kind='bar')\nsns.despine","3c6fa5be":"del HPtrainN['area2']\n\ndel HPtestN['area2']","e23b3a88":"HPtrainN['lugar1'].value_counts().plot(kind='bar')\nsns.despine","c226a6c1":"HPtrainN['lugar2'].value_counts().plot(kind='bar')\nsns.despine","7011ff1a":"HPtrainN['lugar3'].value_counts().plot(kind='bar')\nsns.despine","7f04a423":"HPtrainN['lugar4'].value_counts().plot(kind='bar')\nsns.despine","a82ccaea":"HPtrainN['lugar5'].value_counts().plot(kind='bar')\nsns.despine","ef5af7b9":"HPtrainN['lugar6'].value_counts().plot(kind='bar')\nsns.despine","43a07a09":"HPtrainN['lugar2'] = HPtrainN['lugar2'].map({0: 0, 1: 2})\n\nHPtestN['lugar2'] = HPtestN['lugar2'].map({0: 0, 1: 2})","08fd94d0":"HPtrainN['lugar3'] = HPtrainN['lugar3'].map({0: 0, 1: 3})\n\nHPtestN['lugar3'] = HPtestN['lugar3'].map({0: 0, 1: 3})","59383225":"HPtrainN['lugar4'] = HPtrainN['lugar4'].map({0: 0, 1: 4})\n\nHPtestN['lugar4'] = HPtestN['lugar4'].map({0: 0, 1: 4})","eb0658ca":"HPtrainN['lugar5'] = HPtrainN['lugar5'].map({0: 0, 1: 5})\n\nHPtestN['lugar5'] = HPtestN['lugar5'].map({0: 0, 1: 5})","8ea9fa60":"HPtrainN['lugar6'] = HPtrainN['lugar6'].map({0: 0, 1: 6})\n\nHPtestN['lugar6'] = HPtestN['lugar6'].map({0: 0, 1: 6})","d63816c1":"HPtrainN['lugar1'] = HPtrainN['lugar1']+ HPtrainN['lugar2']+ HPtrainN['lugar3']+ HPtrainN['lugar4']+ HPtrainN['lugar5']+ HPtrainN['lugar6']\n\nHPtestN['lugar1'] = HPtestN['lugar1']+ HPtestN['lugar2']+ HPtestN['lugar3']+ HPtestN['lugar4']+ HPtestN['lugar5']+ HPtestN['lugar6']","ce896aeb":"HPtrainN['lugar1'].value_counts().plot(kind='bar')\nsns.despine","2219731e":"HPtrainN.drop(['lugar2','lugar3','lugar4','lugar5','lugar6'], inplace=True, axis=1)\n\nHPtestN.drop(['lugar2','lugar3','lugar4','lugar5','lugar6'], inplace=True, axis=1)","59d316b6":"HPtrainN.shape","752bb144":"HPtrainN['tipovivi1'].unique()","32486829":"HPtrainN['tipovivi2'].unique()","6e2f5ac5":"HPtrainN['tipovivi2'].unique()","cd94e2a7":"HPtrainN['tipovivi4'].unique()","bc588cf0":"HPtrainN['tipovivi5'].unique()","ca61018a":"HPtrainN['tipovivi2'] = HPtrainN['tipovivi2'].map({0: 0, 1: 2})\n\nHPtestN['tipovivi2'] = HPtestN['tipovivi2'].map({0: 0, 1: 2})","29f8277a":"HPtrainN['tipovivi3'] = HPtrainN['tipovivi3'].map({0: 0, 1: 3})\n\nHPtestN['tipovivi3'] = HPtestN['tipovivi3'].map({0: 0, 1: 3})","83c5866e":"HPtrainN['tipovivi4'] = HPtrainN['tipovivi4'].map({0: 0, 1: 4})\n\nHPtestN['tipovivi4'] = HPtestN['tipovivi4'].map({0: 0, 1: 4})","7139fdb8":"HPtrainN['tipovivi5'] = HPtrainN['tipovivi5'].map({0: 0, 1: 5})\n\nHPtestN['tipovivi5'] = HPtestN['tipovivi5'].map({0: 0, 1: 5})","efb4038f":"HPtrainN['tipovivi1'] = HPtrainN['tipovivi1'] + HPtrainN['tipovivi2'] + HPtrainN['tipovivi3'] + HPtrainN['tipovivi4'] + HPtrainN['tipovivi5']\n\nHPtestN['tipovivi1'] = HPtestN['tipovivi1'] + HPtestN['tipovivi2'] + HPtestN['tipovivi3'] + HPtestN['tipovivi4'] + HPtestN['tipovivi5']","f64ed7e3":"HPtrainN.drop(['tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5',], inplace=True, axis=1)\n\nHPtestN.drop(['tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5',], inplace=True, axis=1)","3e9b7f91":"HPtrainN['tipovivi1'].value_counts().plot(kind='bar')\nsns.despine","d5d7ea46":"HPtrainN.shape","4863356a":"HPtrainN['eviv2'].unique()","9ff83644":"HPtrainN['eviv3'].unique()","d56fed10":"HPtrainN['eviv2'] = HPtrainN['eviv2'].map({0: 0, 1: 2})\n\nHPtestN['eviv2'] = HPtestN['eviv2'].map({0: 0, 1: 2})","8a2e66d7":"HPtrainN['eviv3'] = HPtrainN['eviv3'].map({0: 0, 1: 3})\n\nHPtestN['eviv3'] = HPtestN['eviv3'].map({0: 0, 1: 3})","0da741f0":"HPtrainN['eviv1'] = HPtrainN['eviv1'] + HPtrainN['eviv2'] + HPtrainN['eviv3'] \n\nHPtestN['eviv1'] = HPtestN['eviv1'] + HPtestN['eviv2'] + HPtestN['eviv3'] ","c4eb83b4":"HPtrainN.drop(['eviv2', 'eviv3'], inplace=True, axis=1)\n\nHPtestN.drop(['eviv2', 'eviv3'], inplace=True, axis=1)","96edfb68":"HPtrainN['eviv1'].value_counts().plot(kind='bar')\nsns.despine","ece7c453":"HPtrainN.shape","8652f46c":"HPtrainN['etecho1'].unique()","491d529a":"HPtrainN['etecho2'].unique()","41c7d2be":"HPtrainN['etecho3'].unique()","0eb40209":"HPtrainN['etecho2'] = HPtrainN['etecho2'].map({0: 0, 1: 2})\n\nHPtestN['etecho2'] = HPtestN['etecho2'].map({0: 0, 1: 2})","e29b913b":"HPtrainN['etecho3'] = HPtrainN['etecho3'].map({0: 0, 1: 3})\n\nHPtestN['etecho3'] = HPtestN['etecho3'].map({0: 0, 1: 3})","9d055b0e":"HPtrainN['etecho1'] = HPtrainN['etecho1'] + HPtrainN['etecho2'] + HPtrainN['etecho3'] \n\nHPtestN['etecho1'] = HPtestN['etecho1'] + HPtestN['etecho2'] + HPtestN['etecho3'] ","a4607803":"HPtrainN.drop(['etecho2', 'etecho3'], inplace=True, axis=1)\n\nHPtestN.drop(['etecho2', 'etecho3'], inplace=True, axis=1)","c9b195e7":"HPtrainN['etecho1'].value_counts().plot(kind='bar')\nsns.despine","cd2645a4":"HPtrainN.shape","76df74a4":"HPtrainN['epared1'].unique()","80cc396a":"HPtrainN['epared2'].unique()","6d23847a":"HPtrainN['epared2'].nunique()","b0a2d451":"HPtrainN['epared3'].unique()","7c4f2b66":"HPtrainN['epared2'] = HPtrainN['epared2'].map({0: 0, 1: 2})\n\nHPtestN['epared2'] = HPtestN['epared2'].map({0: 0, 1: 2})","741f7365":"HPtrainN['epared3'] = HPtrainN['epared3'].map({0: 0, 1: 3})\n\nHPtestN['epared3'] = HPtestN['epared3'].map({0: 0, 1: 3})","0d303d82":"HPtrainN['epared1'] = HPtrainN['epared1'] + HPtrainN['epared2'] + HPtrainN['epared3'] \n\nHPtestN['epared1'] = HPtestN['epared1'] + HPtestN['epared2'] + HPtestN['epared3'] ","f0bfbdf7":"HPtrainN.drop(['epared2', 'epared3'], inplace=True, axis=1)\n\nHPtestN.drop(['epared2', 'epared3'], inplace=True, axis=1)","53f6b228":"HPtrainN['epared1'].value_counts().plot(kind='bar')\nsns.despine","63bea607":"HPtrainN['epared1'].value_counts()","bc2d842e":"HPtrainN.shape","f1fd7df7":"HPtrainN['elimbasu1'].unique()","881baff5":"HPtrainN['elimbasu2'].unique()","4865d17b":"HPtrainN['elimbasu3'].unique()","42377009":"HPtrainN['elimbasu4'].unique()","5d167fca":"HPtrainN['elimbasu5'].unique()","93183404":"HPtrainN['elimbasu2'] = HPtrainN['elimbasu2'].map({0: 0, 1: 2})\n\nHPtestN['elimbasu2'] = HPtestN['elimbasu2'].map({0: 0, 1: 2})","8e4ffe7a":"HPtrainN['elimbasu3'] = HPtrainN['elimbasu3'].map({0: 0, 1: 3})\n\nHPtestN['elimbasu3'] = HPtestN['elimbasu3'].map({0: 0, 1: 3})","7953b74d":"HPtrainN['elimbasu4'] = HPtrainN['elimbasu4'].map({0: 0, 1: 4})\n\nHPtestN['elimbasu4'] = HPtestN['elimbasu4'].map({0: 0, 1: 4})","654c31f7":"HPtrainN['elimbasu5'] = HPtrainN['elimbasu5'].map({0: 0, 1: 5})\n\nHPtestN['elimbasu5'] = HPtestN['elimbasu5'].map({0: 0, 1: 5})","3e32e135":"HPtrainN['elimbasu6'] = HPtrainN['elimbasu6'].map({0: 0, 1: 6})\n\nHPtestN['elimbasu6'] = HPtestN['elimbasu6'].map({0: 0, 1: 6})","9de649d5":"HPtrainN['elimbasu1'] = HPtrainN['elimbasu1'] +   HPtrainN['elimbasu2'] +  HPtrainN['elimbasu3'] +  HPtrainN['elimbasu4'] +  HPtrainN['elimbasu5'] +  HPtrainN['elimbasu6'] \n\nHPtestN['elimbasu1'] = HPtestN['elimbasu1'] +   HPtestN['elimbasu2'] +  HPtestN['elimbasu3'] +  HPtestN['elimbasu4'] +  HPtestN['elimbasu5'] +  HPtestN['elimbasu6'] ","1ae8892b":"HPtrainN.drop(['elimbasu2','elimbasu3','elimbasu4','elimbasu5','elimbasu6'], inplace=True, axis=1)\n\nHPtestN.drop(['elimbasu2','elimbasu3','elimbasu4','elimbasu5','elimbasu6'], inplace=True, axis=1)","f96f03cf":"HPtrainN['elimbasu1'].value_counts().plot(kind='bar')\nsns.despine","06724bc8":"HPtrainN['elimbasu1'].value_counts()","c1b126b1":"HPtrainN.shape","0d669aae":"HPtrainN['energcocinar1'].unique()","79cdd8fe":"HPtrainN['energcocinar2'].unique()","d114bd9a":"HPtrainN['energcocinar3'].unique()","8e8faf3a":"HPtrainN['energcocinar4'].unique()","ab06766a":"HPtrainN['energcocinar2'] = HPtrainN['energcocinar2'].map({0: 0, 1: 2})\n\nHPtestN['energcocinar2'] = HPtestN['energcocinar2'].map({0: 0, 1: 2})","e7f55e7a":"HPtrainN['energcocinar3'] = HPtrainN['energcocinar3'].map({0: 0, 1: 3})\n\nHPtestN['energcocinar3'] = HPtestN['energcocinar3'].map({0: 0, 1: 3})","ec139b07":"HPtrainN['energcocinar4'] = HPtrainN['energcocinar4'].map({0: 0, 1: 4})\n\nHPtestN['energcocinar4'] = HPtestN['energcocinar4'].map({0: 0, 1: 4})","505c5825":"HPtrainN['energcocinar1'] = HPtrainN['energcocinar1'] +   HPtrainN['energcocinar2'] +  HPtrainN['energcocinar3'] +  HPtrainN['energcocinar4'] \n\nHPtestN['energcocinar1'] = HPtestN['energcocinar1'] +   HPtestN['energcocinar2'] +  HPtestN['energcocinar3'] +  HPtestN['energcocinar4'] ","af9e66fd":"HPtrainN.drop(['energcocinar2','energcocinar3','energcocinar4'], inplace=True, axis=1)\n\nHPtestN.drop(['energcocinar2','energcocinar3','energcocinar4'], inplace=True, axis=1)","be37113b":"HPtrainN['energcocinar1'].value_counts().plot(kind='bar')\nsns.despine","8cd6d128":"HPtrainN['energcocinar1'].value_counts()","151bfb14":"HPtrainN.shape","7723af2b":"HPtrainN['v14a'].value_counts()","96e08b25":"del HPtrainN['v14a']\n\ndel HPtestN['v14a']","b854ceb8":"HPtrainN['sanitario1'].value_counts()","3671e9d8":"HPtrainN['sanitario2'] = HPtrainN['sanitario2'].map({0: 0, 1: 2})\n\nHPtestN['sanitario2'] = HPtestN['sanitario2'].map({0: 0, 1: 2})","1096ad8d":"HPtrainN['sanitario3'] = HPtrainN['sanitario3'].map({0: 0, 1: 3})\n\nHPtestN['sanitario3'] = HPtestN['sanitario3'].map({0: 0, 1: 3})","1e6cbfbf":"HPtrainN['sanitario5'] = HPtrainN['sanitario5'].map({0: 0, 1: 5})\n\nHPtestN['sanitario5'] = HPtestN['sanitario5'].map({0: 0, 1: 5})","946d35b7":"HPtrainN['sanitario6'] = HPtrainN['sanitario6'].map({0: 0, 1: 6})\n\nHPtestN['sanitario6'] = HPtestN['sanitario6'].map({0: 0, 1: 6})","bae095c0":"HPtrainN['sanitario1'] = HPtrainN['sanitario1'] +   HPtrainN['sanitario2'] +  HPtrainN['sanitario3'] +  HPtrainN['sanitario5'] +  HPtrainN['sanitario6']\n\nHPtestN['sanitario1'] = HPtestN['sanitario1'] +   HPtestN['sanitario2'] +  HPtestN['sanitario3'] +  HPtestN['sanitario5'] +  HPtestN['sanitario6']","b50045c0":"HPtrainN.drop(['sanitario2','sanitario3','sanitario5','sanitario6'], inplace=True, axis=1)\n\nHPtestN.drop(['sanitario2','sanitario3','sanitario5','sanitario6'], inplace=True, axis=1)","0fca06d4":"HPtrainN['sanitario1'].value_counts().plot(kind='bar')\nsns.despine","06c1de10":"HPtrainN['sanitario1'].value_counts()","78b7d538":"HPtrainN.shape","def287ec":"HPtrainN['public'].value_counts().plot(kind='bar')\nsns.despine","9bf7ee66":"HPtrainN['planpri'] = HPtrainN['planpri'].map({0: 0, 1: 2})\n\nHPtestN['planpri'] = HPtestN['planpri'].map({0: 0, 1: 2})","a0c3af5b":"HPtrainN['noelec'] = HPtrainN['noelec'].map({0: 0, 1: 3})\n\nHPtestN['noelec'] = HPtestN['noelec'].map({0: 0, 1: 3})","052a1590":"HPtrainN['coopele'] = HPtrainN['coopele'].map({0: 0, 1: 4})\n\nHPtestN['coopele'] = HPtestN['coopele'].map({0: 0, 1: 4})","fb0c764f":"HPtrainN['public'] = HPtrainN['public'] + HPtrainN['planpri'] + HPtrainN['noelec'] + HPtrainN['coopele']\n\nHPtestN['public'] = HPtestN['public'] + HPtestN['planpri'] + HPtestN['noelec'] + HPtestN['coopele']","d32234bc":"HPtrainN.drop(['planpri', 'noelec', 'coopele'], inplace=True, axis=1)\n\nHPtestN.drop(['planpri', 'noelec', 'coopele'], inplace=True, axis=1)","4d4bece0":"HPtrainN['public'].value_counts().plot(kind='bar')\nsns.despine","4ecbd075":"HPtrainN['public'] = HPtrainN['public'].map({0: 3, 1:1,2:2,3:3,4:4})","a23c093e":"HPtrainN['public'].value_counts().plot(kind='bar')\nsns.despine","fdc9e425":"HPtrainN['public'].value_counts()","d4d8a38e":"HPtrainN.shape","6b4e2bef":"HPtrainN['paredblolad'].value_counts().plot(kind='bar')\nsns.despine","c1ce775e":"HPtrainN['paredzocalo'] = HPtrainN['paredzocalo'].map({0: 0, 1: 2})\n\nHPtestN['paredzocalo'] = HPtestN['paredzocalo'].map({0: 0, 1: 2})","5d2a96ab":"HPtrainN['paredpreb'] = HPtrainN['paredpreb'].map({0: 0, 1: 3})\n\nHPtestN['paredpreb'] = HPtestN['paredpreb'].map({0: 0, 1: 3})","4c73f890":"HPtrainN['pareddes'] = HPtrainN['pareddes'].map({0: 0, 1: 4})\n\nHPtestN['pareddes'] = HPtestN['pareddes'].map({0: 0, 1: 4})","b9cd07c9":"HPtrainN['paredmad'] = HPtrainN['paredmad'].map({0: 0, 1: 5})\n\nHPtestN['paredmad'] = HPtestN['paredmad'].map({0: 0, 1: 5})","14e25ec9":"HPtrainN['paredzinc'] = HPtrainN['paredzinc'].map({0: 0, 1: 6})\n\nHPtestN['paredzinc'] = HPtestN['paredzinc'].map({0: 0, 1: 6})","ce703ff6":"HPtrainN['paredfibras'] = HPtrainN['paredfibras'].map({0: 0, 1: 7})\n\nHPtestN['paredfibras'] = HPtestN['paredfibras'].map({0: 0, 1: 7})","5b9b5526":"HPtrainN['paredother'] = HPtrainN['paredother'].map({0: 0, 1: 8})\n\nHPtestN['paredother'] = HPtestN['paredother'].map({0: 0, 1: 8})","4a8ff7bc":"HPtrainN['paredblolad'] = HPtrainN['paredblolad'] + HPtrainN['paredzocalo'] + HPtrainN['paredpreb'] + HPtrainN['pareddes'] + HPtrainN['paredmad'] + HPtrainN['paredzinc'] + HPtrainN['paredfibras'] + HPtrainN['paredother']\n\nHPtestN['paredblolad'] = HPtestN['paredblolad'] + HPtestN['paredzocalo'] + HPtestN['paredpreb'] + HPtestN['pareddes'] + HPtestN['paredmad'] + HPtestN['paredzinc'] + HPtestN['paredfibras'] + HPtestN['paredother']","2752f7de":"HPtrainN.drop(['paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc','paredfibras','paredother'], inplace=True, axis=1)\n\nHPtestN.drop(['paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc','paredfibras','paredother'], inplace=True, axis=1)","bb59c8fc":"HPtrainN['paredblolad'].value_counts().plot(kind='bar')\nsns.despine","d44fdde5":"HPtrainN['paredblolad'].value_counts()","37e1ec8a":"HPtrainN.shape","2fb9b9d8":"HPtrainN['pisomoscer'].value_counts().plot(kind='bar')\nsns.despine","72570497":"HPtrainN['pisocemento'] = HPtrainN['pisocemento'].map({0: 0, 1: 2})\n\nHPtestN['pisocemento'] = HPtestN['pisocemento'].map({0: 0, 1: 2})","b59901fd":"HPtrainN['pisoother'] = HPtrainN['pisoother'].map({0: 0, 1: 3})\n\nHPtestN['pisoother'] = HPtestN['pisoother'].map({0: 0, 1: 3})","494a4d1e":"HPtrainN['pisonatur'] = HPtrainN['pisonatur'].map({0: 0, 1: 4})\n\nHPtestN['pisonatur'] = HPtestN['pisonatur'].map({0: 0, 1: 4})","fc996a7d":"HPtrainN['pisonotiene'] = HPtrainN['pisonotiene'].map({0: 0, 1: 5})\n\nHPtestN['pisonotiene'] = HPtestN['pisonotiene'].map({0: 0, 1: 5})","6bc3e8b9":"HPtrainN['pisomadera'] = HPtrainN['pisomadera'].map({0: 0, 1: 6})\n\nHPtestN['pisomadera'] = HPtestN['pisomadera'].map({0: 0, 1: 6})","65d9f6ae":"HPtrainN['pisomoscer'] = HPtrainN['pisomoscer'] + HPtrainN['pisocemento'] + HPtrainN['pisoother'] + HPtrainN['pisonatur'] + HPtrainN['pisonotiene'] + HPtrainN['pisomadera']\n\nHPtestN['pisomoscer'] = HPtestN['pisomoscer'] + HPtestN['pisocemento'] + HPtestN['pisoother'] + HPtestN['pisonatur'] + HPtestN['pisonotiene'] + HPtestN['pisomadera']","6861b3fd":"HPtrainN.drop(['pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera'], inplace=True, axis=1)\n\nHPtestN.drop(['pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera'], inplace=True, axis=1)","a235d2ba":"HPtrainN['pisomoscer'].value_counts().plot(kind='bar')\nsns.despine","c939bc5e":"HPtrainN['pisomoscer'].value_counts()","c12ac79e":"HPtrainN.shape","3dec96ef":"HPtrainN['techozinc'].value_counts()","db77eaab":"HPtrainN['techoentrepiso'].value_counts()","40fb3c4f":"HPtrainN['techocane'].value_counts()","1019a251":"HPtrainN['techootro'].value_counts()","adb11149":"HPtrainN['techoentrepiso'] = HPtrainN['techoentrepiso'].map({0: 0, 1: 2})\n\nHPtestN['techoentrepiso'] = HPtestN['techoentrepiso'].map({0: 0, 1: 2})","f710e594":"HPtrainN['techocane'] = HPtrainN['techocane'].map({0: 0, 1: 3})\n\nHPtestN['techocane'] = HPtestN['techocane'].map({0: 0, 1: 3})","70c86f67":"HPtrainN['techootro'] = HPtrainN['techootro'].map({0: 0, 1: 4})\n\nHPtestN['techootro'] = HPtestN['techootro'].map({0: 0, 1: 4})","4d20b660":"HPtrainN['techozinc'] = HPtrainN['techozinc'] + HPtrainN['techoentrepiso'] + HPtrainN['techocane'] + HPtrainN['techootro']\n\nHPtestN['techozinc'] = HPtestN['techozinc'] + HPtestN['techoentrepiso'] + HPtestN['techocane'] + HPtestN['techootro']","336020e8":"HPtrainN.drop(['techoentrepiso', 'techocane', 'techootro'], inplace=True, axis=1)\n\nHPtestN.drop(['techoentrepiso', 'techocane', 'techootro'], inplace=True, axis=1)","abf7d9aa":"HPtrainN['techozinc'].value_counts().plot(kind='bar')\nsns.despine","135f3c4a":"HPtrainN['techozinc'].value_counts()","efb653e4":"HPtrainN['techozinc'] = HPtrainN['techozinc'].map({0: 4, 1: 1, 2:2, 3:3, 4:4})","bbc1c0cb":"HPtrainN['techozinc'].value_counts()","ac89426a":"HPtrainN.shape","50609d97":"HPtrainN['abastaguadentro'].value_counts()","8736476e":"HPtrainN['abastaguafuera'] = HPtrainN['abastaguafuera'].map({0: 0, 1: 2})\n\nHPtestN['abastaguafuera'] = HPtestN['abastaguafuera'].map({0: 0, 1: 2})","6d1a72e9":"HPtrainN['abastaguano'] = HPtrainN['abastaguano'].map({0: 0, 1: 3})\n\nHPtestN['abastaguano'] = HPtestN['abastaguano'].map({0: 0, 1: 3})","9be7640f":"HPtrainN['abastaguadentro'] = HPtrainN['abastaguadentro'] + HPtrainN['abastaguafuera'] + HPtrainN['abastaguano']\n\nHPtestN['abastaguadentro'] = HPtestN['abastaguadentro'] + HPtestN['abastaguafuera'] + HPtestN['abastaguano']","6a27ae55":"HPtrainN.drop(['abastaguafuera', 'abastaguano'], inplace=True, axis=1)\n\nHPtestN.drop(['abastaguafuera', 'abastaguano'], inplace=True, axis=1)","7cb3ca0c":"HPtrainN['abastaguadentro'].value_counts()","d27e7666":"HPtrainN.shape","3119df35":"HPtrainN.drop(['v2a1', 'r4h1', 'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t1', 'r4t2'], inplace=True, axis=1)\n\nHPtestN.drop(['v2a1', 'r4h1', 'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t1', 'r4t2'], inplace=True, axis=1)","9faa97f1":"print(HPtrainN.shape)\n\nprint(HPtestN.shape)","476d3fb2":"HPtrainN['hacapo'].value_counts()","fa39f38d":"HPtrainN.loc[HPtrainN['hacapo']==1,['idhogar', 'r4t3','rooms', 'bedrooms', 'overcrowding']]","0b145f81":"HPtrainN.dtypes","47851a59":"HPtrainN['dependency'].value_counts()","5c717f93":"HPtrainN.loc[HPtrainN['dependency']=='no',['idhogar', 'dependency','r4t3', 'hogar_nin', 'hogar_adul', 'hogar_mayor']]","7b2a843a":"HPtrainN.loc[HPtrainN['dependency']=='yes',['idhogar', 'dependency','r4t3', 'hogar_nin', 'hogar_adul', 'hogar_mayor']]","fe464be4":"HPtrainN['dependency'] = HPtrainN['dependency'].replace({'no': 0, 'yes': 1})\n\nHPtestN['dependency'] = HPtestN['dependency'].replace({'no': 0, 'yes': 1})","76aa0409":"HPtrainN['dependency'].value_counts()","77a9f0a7":"HPtrainN['dependency'].dtype","cf956762":"# Finally we convert it to numeric \nHPtrainN['dependency'] = pd.to_numeric(HPtrainN['dependency'])\n\nHPtestN['dependency'] = pd.to_numeric(HPtestN['dependency'])","4b05663d":"HPtrainN['edjefe'].value_counts()","978c734a":"HPtrainN['edjefe'].isnull().sum()","9c8f0373":"HPtrainN['edjefe'].dtype","f175a39e":"HPtrainN['edjefe'] = HPtrainN['edjefe'].replace({'no': 0, 'yes': 1})\n\nHPtestN['edjefe'] = HPtestN['edjefe'].replace({'no': 0, 'yes': 1})","f9c39a27":"HPtrainN['edjefe'].dtype","8458709f":"HPtrainN['edjefe'] = pd.to_numeric(HPtrainN['edjefe'])\n\nHPtestN['edjefe'] = pd.to_numeric(HPtestN['edjefe'])","6acdb1ed":"HPtrainN['edjefe'].value_counts().plot(kind='bar')\nsns.despine","05c46a43":"HPtrainN['edjefa'].value_counts()","8c813d07":"HPtrainN['edjefa'] = HPtrainN['edjefa'].replace({'no': 0, 'yes': 1})\n\nHPtestN['edjefa'] = HPtestN['edjefa'].replace({'no': 0, 'yes': 1})","c2ba48f7":"HPtrainN['edjefa'].dtype","c46dfda0":"HPtrainN['edjefa'] = pd.to_numeric(HPtrainN['edjefa'])\nHPtestN['edjefa'] = pd.to_numeric(HPtestN['edjefa'])","432853c3":"HPtrainN['edjefa'].dtype","36bf6c57":"HPtrainN['edjefa'].value_counts().plot(kind='bar')\nsns.despine","035b876f":"HPtrainN['idhogar']= HPtrainN['idhogar'].astype('category')\nHPtrainN['idhogar']= HPtrainN['idhogar'].cat.codes\n\nHPtestN['idhogar']= HPtestN['idhogar'].astype('category')\nHPtestN['idhogar']= HPtestN['idhogar'].cat.codes","d6dac791":"HPtrainN['Target'].value_counts().plot(kind='bar')\nsns.despine","8c964c73":"HPtrainN['Target'].value_counts()","fc1eeec6":"HPtrainN.dtypes","42d2fd3d":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.feature_selection import RFE\nfrom sklearn.metrics import r2_score\nfrom sklearn import linear_model","5fca64f6":"X = HPtrainN.drop(['Target','idhogar'],axis=1)\ny = HPtrainN['Target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","33ddb7ff":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns\nvif.round(1)","7c9f241e":"del HPtrainN['r4t3']\n\ndel HPtestN['r4t3']","3419a4b0":"X = HPtrainN.drop(['Target'],axis=1)\ny = HPtrainN['Target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","cbb58123":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns\nvif.round(1)","81c53b63":"del HPtrainN['bedrooms']\n\ndel HPtestN['bedrooms']","871f3d59":"X = HPtrainN.drop(['Target'],axis=1)\ny = HPtrainN['Target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","525a62dd":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns\nvif.round(1)","bd52bc99":"del HPtrainN['epared1']\n\ndel HPtestN['epared1']","03ee68f4":"X = HPtrainN.drop(['Target'],axis=1)\ny = HPtrainN['Target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","7e1456a9":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns\nvif.round(1)","e6e90ded":"del HPtrainN['eviv1']\n\ndel HPtestN['eviv1']","2557d19a":"X = HPtrainN.drop(['Target'],axis=1)\ny = HPtrainN['Target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","ae16e309":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns\nvif.round(1)","45e07722":"del HPtrainN['sanitario1']\n\ndel HPtestN['sanitario1']","0e59a417":"X = HPtrainN.drop(['Target','idhogar'],axis=1)\ny = HPtrainN['Target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","d8801900":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns\nvif.round(1)","b1da7044":"del HPtrainN['rooms']\n\ndel HPtestN['rooms']","b057a4aa":"X = HPtrainN.drop(['Target'],axis=1)\ny = HPtrainN['Target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","c963528d":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns\nvif.round(1)","a08a2c01":"del HPtrainN['abastaguadentro']\n\ndel HPtestN['abastaguadentro']","4e434c7e":"X = HPtrainN.drop(['Target'],axis=1)\ny = HPtrainN['Target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","d818cca5":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns\nvif.round(1)","ef39814b":"del HPtrainN['refrig']\n\ndel HPtestN['refrig']","d90f88e9":"X = HPtrainN.drop(['Target'],axis=1)\ny = HPtrainN['Target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","e27c4341":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns\nvif.round(1)","58c5d7e2":"del HPtrainN['energcocinar1']\n\ndel HPtestN['energcocinar1']","4731a762":"X = HPtrainN.drop(['Target'],axis=1)\ny = HPtrainN['Target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","61712a38":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns\nvif.round(1)","ddd83255":"del HPtrainN['meaneduc']\n\ndel HPtestN['meaneduc']","10bed3a5":"X = HPtrainN.drop(['Target'],axis=1)\ny = HPtrainN['Target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","68c311c5":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns\nvif.round(1)","e431551b":"del HPtrainN['hogar_adul']\n\ndel HPtestN['hogar_adul']","61e08f2d":"X = HPtrainN.drop(['Target'],axis=1)\ny = HPtrainN['Target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","4531655c":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns\nvif.round(1)","c9d088a1":"del HPtrainN['etecho1']\n\ndel HPtestN['etecho1']","fc5ad456":"X = HPtrainN.drop(['Target'],axis=1)\ny = HPtrainN['Target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","936360d7":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns\nvif.round(1)","dd8e1a78":"del HPtrainN['overcrowding']\n\ndel HPtestN['overcrowding']","2864155a":"X = HPtrainN.drop(['Target'],axis=1)\ny = HPtrainN['Target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","1dc9f393":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns\nvif.round(1)","e2a34a3e":"del HPtrainN['techozinc']\n\ndel HPtestN['techozinc']","a772da82":"X = HPtrainN.drop(['Target'],axis=1)\ny = HPtrainN['Target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","77278a0e":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nvif[\"features\"] = X.columns\nvif.round(1)","00b05812":"del HPtrainN['idhogar']\n\ndel HPtestN['idhogar']","8a16b855":"print(HPtrainN.shape)\n\nprint(HPtestN.shape)","dd0c0c8d":"HPtrainN.columns.values","3b344096":"HPtestN.columns.values","f7f2245e":"HPtrainN['Target'].value_counts()","ddfeb3c6":"print('Target1', round(HPtrainN['Target'].value_counts()[1]\/len(HPtrainN) * 100,2), '% of the dataset')\nprint('TArget2', round(HPtrainN['Target'].value_counts()[2]\/len(HPtrainN) * 100,2), '% of the dataset')\nprint('Target3', round(HPtrainN['Target'].value_counts()[3]\/len(HPtrainN) * 100,2), '% of the dataset')\nprint('TArget4', round(HPtrainN['Target'].value_counts()[4]\/len(HPtrainN) * 100,2), '% of the dataset')","a77d0c6a":"HPtrainN = HPtrainN.sample(frac=1)\n\nTarget1_df = HPtrainN.loc[HPtrainN['Target'] == 1]\nTarget2_df = HPtrainN.loc[HPtrainN['Target'] == 2]\nTarget3_df = HPtrainN.loc[HPtrainN['Target'] == 3]\nTarget4_df = HPtrainN.loc[HPtrainN['Target'] == 4][:1034]\n\nnormal_distributed_df = pd.concat([Target1_df,Target2_df,Target3_df,Target4_df])\n\n# Shuffle dataframe rows\nnew_df = normal_distributed_df.sample(frac=1, random_state=42)\n\nprint(new_df.head())\nprint(new_df.shape)","a00de45e":"from sklearn.model_selection import train_test_split\nX = new_df.drop('Target',axis=1)\ny = new_df['Target']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=42)","4e08ad1f":"# Turn the values into an array for feeding the classification algorithms.\nX_train = X_train.values\nX_test = X_test.values\ny_train = y_train.values\ny_test = y_test.values","f5cb7fee":"# Classifier Libraries\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport collections","b0c0b9f2":"# Let's implement simple classifiers\n\nclassifiers = {\n    \"KNearest\": KNeighborsClassifier(),\n    \"Support Vector Classifier\": SVC(),\n    \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n    \"RandomForestClassifier\": RandomForestClassifier()\n}","81025c79":"from sklearn.model_selection import cross_val_score\n\nfor key, classifier in classifiers.items():\n    classifier.fit(X_train, y_train)\n    training_score = cross_val_score(classifier, X_train, y_train, cv=5)\n    print(\"Classifiers: \", classifier.__class__.__name__, \"Has a training score of\", round(training_score.mean(), 2) * 100, \"% accuracy score\")","20518ba6":"# Use GridSearchCV to find the best parameters.\nfrom sklearn.model_selection import GridSearchCV\n\nknears_params = {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\ngrid_knears = GridSearchCV(KNeighborsClassifier(), knears_params)\ngrid_knears.fit(X_train, y_train)\n\n\n# KNears best estimator\nknears_neighbors = grid_knears.best_estimator_\n\n# Support Vector Classifier\nsvc_params = {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\ngrid_svc = GridSearchCV(SVC(), svc_params)\ngrid_svc.fit(X_train, y_train)\n\n# SVC best estimator\nsvc = grid_svc.best_estimator_\n\n\n# DecisionTree Classifier\ntree_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \n              \"min_samples_leaf\": list(range(5,7,1))}\ngrid_tree = GridSearchCV(DecisionTreeClassifier(), tree_params)\ngrid_tree.fit(X_train, y_train)\ntree_clf=grid_tree.best_estimator_\n\n# Random Forest Classifier\nrfcl = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, oob_score = True) \n#rfcl = RandomForestClassifier()\nparam_grid = { 'n_estimators': [600,700,800],  'max_features': ['auto','sqrt','log2']}\nrfc_grid = GridSearchCV(estimator=rfcl, param_grid=param_grid)\nrfc_grid.fit(X_train, y_train)\nrfc=rfc_grid.best_estimator_\nprint(rfc_grid.best_params_)","77c14ecb":"# Overfitting Case\n\nknears_score = cross_val_score(knears_neighbors, X_train, y_train, cv=5)\nprint('Knears Neighbors Cross Validation Score', round(knears_score.mean() * 100, 2).astype(str) + '%')\n\nsvc_score = cross_val_score(svc, X_train, y_train, cv=5)\nprint('Support Vector Classifier Cross Validation Score', round(svc_score.mean() * 100, 2).astype(str) + '%')\n\ntree_score = cross_val_score(tree_clf, X_train, y_train, cv=5)\nprint('DecisionTree Classifier Cross Validation Score', round(tree_score.mean() * 100, 2).astype(str) + '%')\n\nrandomforest_score = cross_val_score(rfc, X_train, y_train, cv=5)\nprint('RandomForest Classifier Cross Validation Score', round(randomforest_score.mean() * 100, 2).astype(str) + '%')","90ee14a4":"rfc_pred = rfc.predict(X_test)","98e9e1aa":"from sklearn.feature_selection import RFE\nnames=list(new_df.columns)\n#rank all features, i.e continue the elimination until the last one\nrfe = RFE(rfc, n_features_to_select=10, step=1)\nrfe.fit(X,y)\nprint('Features sorted by their rank:')\nprint(sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), names)))\n\n# Plot feature importance\nfeature_importance = rfc.feature_importances_\n# make importances relative to max importance\nfeature_importance = 100.0 * (feature_importance \/ feature_importance.max())\nsorted_idx = np.argsort(feature_importance)\npos = np.arange(sorted_idx.shape[0]) + .5\nplt.subplot(1, 2, 2)\nplt.barh(pos, feature_importance[sorted_idx], align='center')\nplt.yticks(pos, X.columns[sorted_idx])\nplt.xlabel('Relative Importance')\nplt.title('Variable Importance')\nplt.show()","62b12ce5":"#def plot_confusion_matrix(cm,title='Confusion matrix',cmap=plt.cm.Blues):\ndef plot_confusion_matrix(cm, normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):    \n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    \n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","bd3ff985":"import itertools\nfrom itertools import product\nfrom sklearn.metrics import classification_report,confusion_matrix\ncm=confusion_matrix(y_test,rfc_pred)\nplot_confusion_matrix(cm, normalize=False, title='Confusion matrix',cmap=plt.cm.Purples)","79259be1":"print(classification_report(y_test,rfc_pred))","ce083c35":"X_whole = HPtrainN.drop('Target',axis=1)\ny_whole = HPtrainN['Target']","51b12e38":"X_whole.shape","8fa80ab7":"rfc_pred_whole = rfc.predict(X_whole)","dee32e8f":"cm_whole=confusion_matrix(y_whole,rfc_pred_whole)\nplot_confusion_matrix(cm_whole, normalize=False, title='Confusion matrix',cmap=plt.cm.Purples)","cdb14712":"print(classification_report(y_whole,rfc_pred_whole))","2f996687":"rfc_pred_test = rfc.predict(HPtestN)","837999fb":"dftest = pd.DataFrame({'Target': rfc_pred_test})","bf361df8":"dftest.head()","cd543c47":"dftest.shape","80ebcb40":"test_predictN=test_predict[['idhogar']].copy()","23cf8393":"test_predictN.head()","5762977d":"test_predictN.drop_duplicates(subset='idhogar', inplace=True)","042c85e5":"test_predictN.head()","d4de20e5":"test_predictN.shape","c47d7a64":"test_predictN.index = range(len(test_predictN))","ae509a59":"test_predictN.head()","92482878":"test_pred_concat= pd.concat([test_predictN,dftest], axis=1)","64b957f3":"test_pred_concat.shape","0aa425aa":"test_pred_concat.head()","236d4439":"test_predict= pd.merge(test_predict, test_pred_concat, how='left', on=['idhogar'])","23666983":"test_predict.head()","f9e3e0ed":"test_predict=test_predict.drop(['idhogar'],axis=1)","04f0cb79":"test_predict.head()","4c153567":"test_predict.shape","0189eaf6":"test_predict.to_csv('test_predict.csv',index=False)","1614d8fb":"edjefe, years of education of male head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n\nconverting this string categorical variable to the numbers","5bb0c2ae":"# Part3-Model building and making prediction\n\nWe do it in five steps\n\n(a) As we already know (also shown below) the number of poorest families belong to Target=1 category is a small fraction of total number of families in the train data. It is only 7.2% compared to 65.39% of nonvulnerable families. Also our target will be to build model that can point out extremely poor families. This problem has notable similarity with the credit card fraud detection problem. The data is also highly skewed. For this reason we make a subset from our data which contains all the cases from category 1, 2 and 3 and an equal number representing the combined number of these three cases from category 4. So category 1,2 and 3 contribute 50% to the new dataset and category4 alone 50%.\n\n(b) We perform a test-train split allocating very low percentage for the test part. Out actual intention is to appy the model on almost all of the training data.\n\n(c) We try different classification schemes namely K-near neighbour, Support Vector Classifier, Decision Tree Classifier and Random Forest Classifier to pick up the best one based on the training score and cross validation score. We also perform an extensive grid search to pick up the best parameter sets for all these classifiers. We finally pick up Random Forest Classifier as our model. \n\n(d) We compute confusion matrix and classification report for the part of the test data we splitted out from the training sample. Since the number of this test sample is a tiny fraction of the whole traning dtaa we will see poor\/untrustworthy. This doesn't necessarily mean that our model is poorly trained. The same model when fitted on the whole training data gives excellent precision and most importantly high recall, since we don't want to miss even a single family in extreme need for social aids.\n\n(e) Finally we apply this model to the test data and make predictions.","b48f6f8e":"# (c) Transporting and applying different classification schemes from scikit learn libraries.","8e325472":"Applying cross validation on these best fitted classifiers.","ba9cc552":"Same is true with the features 'eviv1' to 'eviv3'. We grpup them to 'eviv1'. This drops 2 more characters.\n\n1:if floors are bad, 2:if floors are regular, 3:if floors are good","288feb2d":"# (a) We see that the percentagle of poorest families (Target1) is only 7.2%","fad21803":"# (b) We drop rows with duplicate household index ('idhogar').\nThis shrinks both the dataframe to the size of number of households in that set as we can see below.","45f7b0df":"We make a data frame 'new_df' by following the discussion made above.","33f7115e":"# (d) Grouping features which may form a group","72b59776":"# let's examine the variable 'v2a1' where we have find out 17403 NaNs","632cd58e":"# (f) We look at the variable inflation factor to remove variables that are highly correlated.","198426fa":"We see that the performance of the model on the splitted test dataset of the training data is fairly poor. We apply the same model to the whole training dataset to get an excellent precision, recall and f1-score. Our objective here is to achieve high recall so that we hardly miss any family who is in extreme need of the aids.","d7625f85":"Same is true with the features 'epared1' to 'epared3'. This drops 2 more characters.\n\n1:walls are bad, 2:if walls are regular, 3:if walls are good","3fa81f46":"v2a1, Monthly rent payment\ntipovivi2, \"=1 own,  paying in installments\"\ntipovivi3, =1 rented\n\nNaN in 'v2a1' only appear for rented house ('tipovivi3'=1) so we can replace these NaNs with 0","0014610c":"Same is true with the features 'tipoviv1' to 'tipoviv5'. We perform the same task and group them in 'tipoviv1'. \n\nWhere, 1:own and fully paid house, 2:own,paying in installments, 3:rented, 4:precarious, 5:other(assigned,  borrowed). \n\nThis drops 4 more characters.","6d4d6f57":"# Let's see the column 'meaneduc' which have 5 NaN's\nmeaneduc,average years of education for adults (18+)","7a35684b":"1:if predominant material on the floor is mosaic,  ceramic,  terrazo,\n2:if predominant material on the floor is cement,\n3:if predominant material on the floor is other,\n4:if predominant material on the floor is  natural material,\n5:if no floor at the household,\n6:if predominant material on the floor is wood","b216ba98":"Now we rearrange some of the columns so that our analysis becomes somewhat easy.","3add0f95":"# (b) We apply test-train split with negligibly small test_size=0.01.","1751eb80":"We thus see that all the NaNs in the 'v18q1' actually represent the families with no tablets in the household. So we replace these Nans with zeros in both the datasets.","721762f3":"# (d) We define confusion matrix and plot it for two cases as discussed above.","83ce154f":"WE SEE THAT ALL THE MODELS ARE GOOD AT PREDICTING THE 4TH CLASS WHICH IS NON VULNERABLE BUT BAD AT PREDICTING CLASS 1 WHICH REPRESENTS EXTREMELY POOR GROUP OF PEOPLE. THIS IS AGAIN A BIASED PROBLEM SINCE EVEN IN TTRAIN DATA THEY COMPRICE ONLY 7.2% OF TOTAL DATA.","73a6f847":"Based on these scores we pick up RandomForest Classifier as our working model. We predict on X_test and show below the rank of the various features of the training dataset.","fcf4e689":"dependency, Dependency rate, calculated = (number of members of the household younger than 19 or older than 64)\/(number of member of household between 19 and 64)","43a79498":"From the above tables and the formula given for calculating 'dependency' we decide to assine 1 for 'yes' and 0 for 'no'.","d3b0687a":"Same is true with the features 'elimbasu1' to 'elimbasu5'. This drops 4 more characters.\n\n1:if rubbish disposal mainly by tanker truck,\n2:if rubbish disposal mainly by botan hollow or buried,\n3:if rubbish disposal mainly by burning,\n4:if rubbish disposal mainly by throwing in an unoccupied space,\n5:if rubbish disposal mainly by throwing in river,  creek or sea\",\n6:if rubbish disposal mainly other","fe613b89":"1:if water provision inside the dwelling,\n2:if water provision outside the dwelling,\n3:if no water provision","27a81bd5":"'energcocinar1' to 'energcocinar4' marged to the column 'energcocinar1'. This reduces 3 more features.\n\n1:no main source of energy used for cooking (no kitchen),\n2:main source of energy used for cooking electricity,\n3:main source of energy used for cooking gas,\n4:main source of energy used for cooking wood charcoal","5edab29c":"# Now we look for the NaNs in 'v18q1' having 18126 NaNs\nv18q1, number of tablets household owns\nv18q, owns a tablet\nidhogar, Household level identifier","78c71e04":"# Part1- Data cleaning-both train and test dataset","b866330d":"# Now we look at the NaNs in 'rez_esc' having 7928 NaNs\nrez_esc, Years behind in school","d0d3e3c2":"# (e)Converting some variables from 'object' type to numeric\n\nWe examine the data type of the variables and we see that some of them are of object type (mixed str,float,int). We have to convert them to int\/float to extract any thing meaningfull. We have three such variables 'dependency', 'edjefe' and 'edjefa'.","f9732b54":"We examine the missing values in both train and test dataset one by one.","1e14be0b":"# (C) We closely look individual features and found that some pair of features tell the same story. We drop one of the feature from the pair.","6bb33d83":"1:if predominant material on the roof is metal foil or zink,\n2:if predominant material on the roof is fiber cement,  mezzanine,\n3:if predominant material on the roof is natural fibers,\n4:if predominant material on the roof is other","33ec5c98":"# (c) Missing fields","96bae9d5":"Applying grid search to findout the best parameters for each classifier.","4361ca63":"3 duplicated columns removed 'hhsize', 'hogar_total' and 'agesq'. Two additional columns 'tamhog'(almost same as r4t3) and 'tamviv'(misleading)","7a28e654":"'tamhog','hhsize' and 'hogar_total' are exactly duplicated and almost duplicated with 'r4t3'","9dde99c5":"We see that the number of adults for these 5 households are zero which results in NaN. Here we replace these NaN's by zero.","f91acb30":"All NaN values in the 'rez_esc' are for mature adults or underaged children which is justified. Only one NaN correspond to a child of age 10 with Id=ID_f012e4242 who is not attending school. Reason for not attending the school is disability (dis=1). Therefore we replace all NaN in this column by 0.0 in both datasets.","e44f2a1b":"Same is true with the features 'etecho1' to 'etecho3'. This drops 2 more characters.\n\n1:if roofs are bad, 2:if roof are regular, 3:if roof are good","4c928086":"# (a) Reading all three datasets, their shapes, structure and searching for missing values","3432fe76":"v14a, =1 has toilet in the household\n\nsanitario1, =1 no toilet in the dwelling\n\nwe delete 'v14a' since they are also described in 'sanitaroi1' to 'sanitaroi5','sanitaroi6'. We marge them all to 'sanitaroi1'.\n\n1:no toilet in the dwelling,\n2:toilet connected to sewer or cesspool,\n3:toilet connected to  septic tank,\n5:toilet connected to black hole or letrine,\n6:toilet connected to other system","42ae034f":"'SQBage' and 'agesq' are duplicated","34d14119":"edjefa, years of education of female head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0","d8453beb":"# Part2-Feature engineering\n\nIn this section we will play with the features and will keep features or will generate new features that properly goes with the description of the datset.\n\n(a) We will look the dataset from the perspective of each household ('idhogar') rather than persons living in the household ('Id'). So we will pick-up only those features that properly describe each household rather than features that describe individual features. This observation will help us to reduce the number of dimensions by 46 (from 139 to 93 from training data and from 138 to 92 for testing data).We also create a new dataframe with two columns 'idhogar' and 'Id' for future prediction.\n\n(b) We drop rows with duplicate household index ('idhogar').\n\n(C) We closely look individual features and found that some pair of features tell the same story. We drop one of the feature from the pair.\n\n(d) Grouping features which form a group.\n\n(e)Converting some 'object' type variable to numeric.\n\n(f) We work on Variance inflation factor and eliminate some variables which are highly correlated.","bd961499":"We see that it is really a mixture of many different kind of characters","52818654":"'area1' and 'area2' basically indicate the same data. For 'area1', 1(Urban) and 0(Rural). Opposite is true for 'area2'. We therefore delete 'area2'.","7c84918c":"# Lastly we see the missing values in 'SQBmeaned'\nSQBmeaned, square of the mean years of education of adults (>=18) in the household\nThe reason is clear their origin is from the NaNs in the column 'meaneduc. We also replace these NaN's with zero.","0939227c":"Applying cross validation technique to the classifiers.","14d4f3b8":"We see that 19 buildings has index 0 we map them to 4 (others)","a97628e3":"'lugar1' to 'lugar5' indicates different regions of the country. For 'lugar1' a region with index 1 belongs to 'region Central' and 0 indicates it doesn't belong to this region. For other lugar indices same is true.  We denote every region with a unique ID number and marge then all with 'lugar1'. \n\n1:region Central, 2:region Chorotega, 3:region Pac\u00c3\u0192\u00c2\u00adfico central, 4:region Brunca, 5:region Huetar Atl\u00c3\u0192\u00c2\u00a1ntica and 6:region Huetar Norte. \n\nThis delete 5 more features.","2bb6cc12":"Its still object type. We convert it to numeric","374bed76":"# (b) Deduplication- removing duplicate columns\nWe look for any duplicated columns and drop them\nhttps:\/\/stackoverflow.com\/questions\/14984119\/python-pandas-remove-duplicate-columns","247de8b6":"# (a) We drop following 46 features that descibe an individual rather than a householed.\n\n'Unnamed: 0', ------------------1\n\n'Id', 'male', 'female', -----------3\n\n'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', -----------7\n\n'parentesco1', 'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', 'parentesco11', 'parentesco12',-----------------12  \n\n'escolari', 'rez_esc', ---------------2\n\n'dis',-----------1\n \n'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', \n'instlevel7', 'instlevel8', 'instlevel9', ----------9\n \n'v18q',----------1\n  \n'mobilephone',--------1\n \n'age', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', \n'SQBdependency', 'SQBmeaned',---------9\n","a2639b8e":"1:if predominant material on the outside wall is block or brick,\n2:if predominant material on the outside wall is socket (wood,  zinc or absbesto,\n3:if predominant material on the outside wall is prefabricated or cement,\n4:if predominant material on the outside wall is waste material,\n5:if predominant material on the outside wall is wood,\n6:if predominant material on the outside wall is zink,\n7:if predominant material on the outside wall is natural fibers,\n8:if predominant material on the outside wall is other","891fbbf4":"# (e) Now we predict on the test data","4e87dc40":"1:electricity from CNFL, ICE, ESPH\/JASEC\"\n2:electricity from private plant\n3:no electricity in the dwelling\n4:electricity from cooperative"}}