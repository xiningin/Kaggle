{"cell_type":{"fc980e49":"code","545faa60":"code","e96d44a0":"code","717d56da":"code","1862c8c6":"code","62b18b1d":"code","a6c04498":"code","df13f32d":"code","53dfce94":"code","4fa35e02":"code","5b38424a":"code","35ecf308":"code","128366d3":"code","45596fbd":"code","5fc75270":"code","b48f01f2":"markdown"},"source":{"fc980e49":"#Import Libraries\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","545faa60":"import torch\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as transforms\n\n#load the data and convert it into torch.Tensor. Labels need to be LongTensor.\n#Normalize features between 0 and 1\ntransform = transforms.Normalize(0, 255, inplace=False)\n\ntrain_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\nsubmit_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\n\nfeatures_train = transform(torch.Tensor(np.reshape(train_df.iloc[:,1:].to_numpy(), (-1,1,28,28)))) #size=(42000,1,28,28)\nlabels_train = torch.LongTensor(train_df['label'].to_numpy())\nfeatures_submit = transform(torch.Tensor(np.reshape(submit_df.to_numpy(), (-1,28,28)))) #size=(28000,28,28)\n\n#splitting training data into training, validation and test set\ntrain_len = int(features_train.shape[0]*0.6) #size=(25200,1,28,28)\nvalid_len = int(features_train.shape[0]*0.2) #size=(8400,1,28,28)\ntrain_set = torch.utils.data.TensorDataset(features_train[:train_len],labels_train[:train_len])\nvalid_set = torch.utils.data.TensorDataset(features_train[train_len:(train_len+valid_len)],labels_train[train_len:(train_len+valid_len)])\ntest_set = torch.utils.data.TensorDataset(features_train[(train_len+valid_len):],labels_train[(train_len+valid_len):])\n\n\n#creating Dataloaders for training, validation and testing\ntrain_loader = DataLoader(train_set, batch_size = 50)\nvalid_loader = DataLoader(valid_set, batch_size = 50)\ntest_loader = DataLoader(test_set, batch_size = 50)","e96d44a0":"%matplotlib inline\nimport matplotlib.pyplot as plt\n#Visualizing Some data\n\nX = features_train[:16]\ny = labels_train[:16]\n\nplt.figure(figsize = (16, 3))\n\nfor i in range(16):\n    if i >= 16:\n        break\n    plt.subplot(2, 8, i+1)\n    plt.title(int(y[i]))\n    plt.imshow(X[i].reshape(28,28),cmap=\"gray\")","717d56da":"#1. Visualize train instance number n\nn = 10\nprint('Plotting the train instance number {}: Label = {}'.format(n, labels_train[n]))\nimage1 = features_train[n].view(28,28)\nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\nax.set_aspect('equal')\nplt.imshow(image1)\n\nplt.colorbar()","1862c8c6":"import torch\nfrom torch import nn\nimport torch.nn.functional as F\n\n\n# define the CNN architecture\nclass CNN_classifier(nn.Module):\n    def __init__(self):\n        super(CNN_classifier, self).__init__()\n        # convolutional layer (sees 1x28x28 image tensor)\n        self.conv1 = nn.Conv2d(1, 32, 5, padding=2)\n        # convolutional layer (sees 32x14x14 image tensor)\n        self.conv2 = nn.Conv2d(32, 32, 5, padding=2)\n        # convolutional layer (sees 32x7x7 image tensor --> 64, 3, 3)\n        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n        # max pooling layer\n        self.pool = nn.MaxPool2d(2, 2)\n        # linear layer (64 * 3 * 3 -> 256)\n        self.fc1 = nn.Linear(64*3*3, 256)\n        # linear layer (256 -> 10)\n        self.fc2 = nn.Linear(256, 10)\n        # dropout layer (p=0.25)\n        self.dropout = nn.Dropout(0.25)\n\n    def forward(self, x):\n        # add sequence of convolutional and max pooling layers\n        x = self.pool(F.relu(self.conv1(x)))\n        # add dropout layer\n        x = self.dropout(x)\n        # add sequence of convolutional and max pooling layers\n        x = self.pool(F.relu(self.conv2(x)))\n        # add dropout layer\n        x = self.dropout(x)\n        # add sequence of convolutional and max pooling layers\n        x = self.pool(F.relu(self.conv3(x)))\n        # add dropout layer\n        x = self.dropout(x)\n        # flatten image input\n        x = x.view(-1, 64*3*3)\n        # add 1st hidden layer, with relu activation function\n        x = F.relu(self.fc1(x))\n        # add dropout layer\n        x = self.dropout(x)\n        # add 2nd hidden layer, with relu activation function\n        x = self.fc2(x)\n        return x\n\n# create a complete CNN\nmodel = CNN_classifier()\nprint(model)","62b18b1d":"import torch.optim as optim\n\n# specify loss function (categorical cross-entropy)\ncriterion = nn.CrossEntropyLoss()\n\n# specify optimizer\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\n#if gpu is available move model and criterion to gpuj\nif torch.cuda.is_available():\n    model = model.cuda()\n    criterion = criterion.cuda()","a6c04498":"# number of epochs to train the model\nn_epochs = 10\nvalid_plot = []\ntrain_plot = []\n\nvalid_loss_min = np.Inf # track change in validation loss\n\nfor epoch in range(1, n_epochs+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    model.train()\n    for data, target in train_loader:\n        if torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()*data.size(0)\n        \n        \n    ######################    \n    # validate the model #\n    ######################\n    model.eval()\n    for data, target in valid_loader:\n        if torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # update average validation loss \n        valid_loss += loss.item()*data.size(0)\n        \n        \n    # calculate average losses\n    train_loss = train_loss\/len(train_loader.sampler)\n    valid_loss = valid_loss\/len(valid_loader.sampler)\n\n    train_plot.append(train_loss)\n    valid_plot.append(valid_loss)\n    \n    # print training\/validation statistics \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch, train_loss, valid_loss))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), 'model_mnist_cnn.pt')\n        valid_loss_min = valid_loss","df13f32d":"#Plotting training and validation loss\nplt.plot(valid_plot)\nplt.plot(train_plot)\nplt.show()","53dfce94":"# track test loss, correct_pred for accuary\n# saving images that were wrongly predicted under false_images\ntest_loss = 0.0\ncorrect_pred = 0\nfalse_images = torch.empty((1, 28, 28))\nfalse_preds = []\nfalse_targets = []\n\nmodel.eval()\n# iterate over test data\nfor data, target in test_loader:\n    if torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = model(data)\n    # calculate the batch loss\n    loss = criterion(output, target)\n    # update test loss \n    test_loss += loss.item()*data.size(0)\n    # convert output probabilities to predicted class\n    _, pred = torch.max(output, 1)    \n    # compare predictions to true label\n    correct_pred += torch.sum(pred == target).item()\n    \n    true_pred = pred==target\n    for i, value in enumerate(true_pred):\n        if value.item() == False:\n            false_images = torch.cat((false_images, data[i]), dim=0)\n            false_preds.append(pred[i])\n            false_targets.append(target[i])\n\nfalse_images = false_images[1:]\n    \n# print out average test loss and test accuracy\ntest_loss = test_loss\/len(test_loader.dataset)\naccuracy = correct_pred \/len(test_loader.dataset)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\nprint('Accuracy: {:.2f}%'.format(accuracy*100))\n","4fa35e02":"#Plotting falsely predicted images\nX = false_images\nprediction = false_preds\ntarget = false_targets\n\nplt.figure(figsize = (16, 10))\n\nfor i in range(40):\n    if i >= 40:\n        break\n    plt.subplot(5, 8, i+1)\n    plt.title('h={},y={}'.format(prediction[i].item(), target[i].item()))\n    plt.imshow(X[i].reshape(28,28),cmap=\"gray\")","5b38424a":"#Visualizing some correct predictions\ndata_iter = iter(valid_loader)\ndata, target = next(data_iter)\n    \nif torch.cuda.is_available():\n    data = data.cuda()\n\noutput = model(data)\n_, pred = torch.max(output, 1) \n\nif torch.cuda.is_available():\n    pred = pred.cpu()\n    data = data.cpu()\n\nX = data[:40]\n\nplt.figure(figsize = (16, 10))\n\nfor i in range(40):\n    if i >= 40:\n        break\n    plt.subplot(5, 8, i+1)\n    plt.title(pred[i].item())\n    plt.imshow(X[i].reshape(28,28),cmap=\"gray\")","35ecf308":"#submision\ndata = features_submit.view(-1,1,28,28)\nif torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\noutput = model(data)\nscore, predictions = torch.topk(output, 1)","128366d3":"predictions.size()\npredictions = predictions.cpu()","45596fbd":"ImageId = np.arange(1,predictions.size()[0]+1)\nLabel = predictions.view(predictions.size()[0]).numpy()\nnew_submission = pd.DataFrame({'ImageId': ImageId, 'Label': Label})\nnew_submission.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","5fc75270":"new_submission","b48f01f2":"Hello all,\n\n\n"}}