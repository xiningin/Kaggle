{"cell_type":{"0b16fa89":"code","90058270":"code","05e5eabc":"code","6f338ff1":"code","696ea61e":"code","620b902c":"code","113860fb":"code","58829364":"code","dc2d6291":"code","a198049f":"code","7d299ef8":"code","81214ceb":"code","8a177648":"code","80661097":"code","6c7976b4":"code","4c6904a8":"code","f7e45016":"code","5eec4119":"code","b84e2c31":"code","dc27cf97":"markdown","dae44813":"markdown","cb0ebc92":"markdown"},"source":{"0b16fa89":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","90058270":"# Import Python Packages\n# PyTesseract and Tika-Python for OCR\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport shutil\nimport PIL\nimport os\nfrom os import walk\nfrom shutil import copytree, ignore_patterns\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS\nfrom PIL import Image\nfrom wand.image import Image as Img\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_colwidth', 500)\n#mueller_report = pd.read_csv('..\/input\/data-science-cheat-sheets\/Interview Questions\/AI Questions.pdf') # one row per line","05e5eabc":"# Define helper function for plotting word clouds\ndef wordCloudFunction(df,column,numWords):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    word_string=str(popular_words_nonstop)\n    wordcloud = WordCloud(stopwords=STOPWORDS,\n                          background_color='white',\n                          max_words=numWords,\n                          width=1000,height=1000,\n                         ).generate(word_string)\n    plt.clf()\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()","6f338ff1":"# Define helper function for plotting word bar graphs\ndef wordBarGraphFunction(df,column,title):\n    # adapted from https:\/\/www.kaggle.com\/benhamner\/most-common-forum-topic-words\n    topic_words = [ z.lower() for y in\n                       [ x.split() for x in df[column] if isinstance(x, str)]\n                       for z in y]\n    word_count_dict = dict(Counter(topic_words))\n    popular_words = sorted(word_count_dict, key = word_count_dict.get, reverse = True)\n    popular_words_nonstop = [w for w in popular_words if w not in stopwords.words(\"english\")]\n    plt.barh(range(50), [word_count_dict[w] for w in reversed(popular_words_nonstop[0:50])])\n    plt.yticks([x + 0.5 for x in range(50)], reversed(popular_words_nonstop[0:50]))\n    plt.title(title)\n    plt.show()","696ea61e":"# Preview the data folder\ninputFolder = '..\/input\/'\nfor root, directories, filenames in os.walk(inputFolder):\n    for filename in filenames: \n        print(os.path.join(root,filename))\n        \n# Move data to folder with read\/write access\noutputFolder = '\/kaggle\/working\/pdfs\/'\nshutil.copytree(inputFolder,outputFolder,ignore=ignore_patterns('*.db'))\nfor root, directories, filenames in os.walk(outputFolder, topdown=False):\n    for file in filenames:\n        try:\n            shutil.move(os.path.join(root, file), outputFolder)\n        except OSError:\n            pass\nprint(os.listdir(outputFolder))","620b902c":"# Look at page 1\npdf = os.path.join(outputFolder,'Azerbaijan-en-result-104-original.pdf[1]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/Azerbaijan-en-result-104-original.jpg') # intro page to preview later","113860fb":"# Parse a PDF file and convert it to CSV using PyTesseract\nimport pytesseract\npdfimage = Image.open('\/kaggle\/working\/Azerbaijan-en-result-104-original.jpg')\ntext = pytesseract.image_to_string(pdfimage)  \ndf = pd.DataFrame([text.split('\\n')])","58829364":"# Plot WordCloud of page 1\nplt.figure(figsize=(10,10))\nwordCloudFunction(df.T,0,10000000)\nplt.figure(figsize=(10,10))\nwordBarGraphFunction(df.T,0,\"Most Common Words on Page 1 of Azerbaijan\")","dc2d6291":"# Parse a PDF file and convert it to CSV using Tika-Python\n!pip install tika\nimport tika\nfrom tika import parser\ntika.initVM()\nparsed = parser.from_file('\/kaggle\/working\/Azerbaijan-en-result-104-original.jpg') \ntext = parsed[\"content\"]\ndf = pd.DataFrame([text.split('\\n')])\ndf.drop(df.iloc[:, 1:46], inplace=True, axis=1)","a198049f":"# Convert PDF to JPG and then convert JPG to CSV\n# I will do this for Pages 289 to 291 but. I don't know how mny pages has the document. \n# Eventually I should loop through the entire document\n\n# PDF to JPG for p1\npdf = os.path.join(outputFolder,'Azerbaijan-en-result-104-original.pdf[1]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/Azerbaijan-en-result-104-original.jpg')\npdfimage1 = Image.open('\/kaggle\/working\/Azerbaijan-en-result-104-original.jpg')","7d299ef8":"# PDF to JPG for p2\npdf = os.path.join(outputFolder,'Azerbaijan-en-result-104-original.pdf[2]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/Azerbaijan-en-result-104-original.jpg')\npdfimage2 = Image.open('\/kaggle\/working\/Azerbaijan-en-result-104-original.jpg')\n\n# PDF to JPG for p3\npdf = os.path.join(outputFolder,'Azerbaijan-en-result-104-original.pdf[3]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/Azerbaijan-en-result-104-original.jpg')\npdfimage3 = Image.open('\/kaggle\/working\/Azerbaijan-en-result-104-original.jpg')","81214ceb":"# Parse a PDF file and convert it to CSV using PyTesseract (p1)\ntext = pytesseract.image_to_string(pdfimage1)\ndf = pd.DataFrame([text.split('\\n')])\ndf.drop(df.iloc[:, 27:], inplace=True, axis=1)\ndf.drop(df.iloc[:, :3], inplace=True, axis=1)\ndf.columns = range(df.shape[1])","8a177648":"# Parse a PDF file and convert it to CSV using Tika-Python (p290-291)\ntika.initVM()\nparsed = parser.from_file('\/kaggle\/working\/Azerbaijan-en-result-104-original.jpg')\nparsed2 = parser.from_file('\/kaggle\/working\/Azerbaijan-en-result-104-original.jpg')\n\ntext = parsed[\"content\"]\ndf2 = pd.DataFrame([text.split('\\n')])\ndf2.drop(df2.iloc[:, 1:50], inplace=True, axis=1)\ndf2.drop(df2.iloc[:, 26:], inplace=True, axis=1)\ndf2.columns = range(df2.shape[1])\n\ntext = parsed2[\"content\"]\ndf3 = pd.DataFrame([text.split('\\n')])\ndf3.drop(df3.iloc[:, :50], inplace=True, axis=1)\ndf3.drop(df3.iloc[:, 22:], inplace=True, axis=1)\ndf3.columns = range(df3.shape[1])\n\ndfcombined = pd.concat([df, df2, df3]) # combine pages 289-291","80661097":"#Explore page 3 - Mueller Report. Here I don't know how many pages each pdf have.  \nw, h = pdfimage3.size # crop image\npdfimage3.crop((0, 1240, w, h-1300)) # display exerpt of PDF","6c7976b4":"# Convert PDF to JPG and then convert JPG to CSV\n# I will do this for Pages 289 to 291 but\n# Eventually I should loop through the entire document\n\n# PDF to JPG for p1\npdf = os.path.join(outputFolder,'Azerbaijan-en-result-104-original.pdf[1]')\nwith Img(filename=pdf, resolution=300) as img:\n    img.compression_quality = 99\n    img.convert(\"RGBA\").save(filename='\/kaggle\/working\/Azerbaijan-en-result-104-original.jpg')\npdfimage1 = Image.open('\/kaggle\/working\/Azerbaijan-en-result-104-original.jpg')","4c6904a8":"#Explore page 1 - Mueller Report. Here I don't know how many pages each pdf file have.  \nw, h = pdfimage1.size # crop image\npdfimage1.crop((0, 1240, w, h-1300)) # display exerpt of PDF","f7e45016":"# Pages 1, 2, and 3\ndfcombined.head() # preview csv of 289-291","5eec4119":"# Clean up the notebook\n!apt-get install zip # install zip\n!zip -r pdfs.zip \/kaggle\/working\/pdfs\/ # zip up a few files\n!rm -rf pdfs\/* # remove everything else","b84e2c31":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#32a832','#32a84e','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Thanks Andrea Infuso, @mpwolke was here' )","dc27cf97":"#Codes by Paul Mooney https:\/\/www.kaggle.com\/paultimothymooney\/what-is-inside-of-the-mueller-report\/notebook","dae44813":"#Tribute to Andrea Infuso\n\nMarch 2006Eurosurveillance 11(3):1-2;; DOI: 10.2807\/esm.11.03.00602-en\n\n\"This special issue of Eurosurveillance is dedicated to the memory of Andrea Infuso, a dear and respected colleague and friend, who died suddenly on 20 September 2005 at the age of 44. Andrea was actively involved in the preparation of this special issue on vaccination and tuberculosis. As EuroTB coordinator since 2000, his knowledge of and contacts with all European experts involved in tuberculosis surveillance in Europe were very valuable in conceiving this thematic issue. The Euroroundup published in this issue, European survey of BCG vaccination policies and surveillance in children, 2005, written by Andrea as first author, is a posthumous publication.\"https:\/\/www.researchgate.net\/publication\/320203408_Tribute_to_Andrea_Infuso","cb0ebc92":"#PDF to CSV\n\nConvert Page 3 of PDF to CSV (Method 1 of 2: PyTesseract)"}}