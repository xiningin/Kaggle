{"cell_type":{"bb733291":"code","22eccd68":"code","629b029c":"code","49a688bd":"code","61aa7154":"code","e15bf634":"code","3b3b1bad":"code","19f78c22":"code","483934c4":"code","4e61b737":"code","3eec54e5":"code","ecca2655":"code","5e2c3f84":"code","bfce33e1":"code","c66b5be7":"code","ec683830":"code","8b2405c7":"code","b258eeb6":"code","1f6cd324":"code","f144a6c5":"code","cad0e9e5":"code","abe039c0":"code","238f6a05":"code","53b71fb9":"code","67f5679a":"markdown","5826e8db":"markdown","8a1bb1b4":"markdown","2ca691f3":"markdown","37250fcc":"markdown"},"source":{"bb733291":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","22eccd68":"import json\n\ndef parse_data(file):\n    for l in open(file,'r'):\n        yield json.loads(l)\n\ndata = list(parse_data('..\/input\/news-headlines-dataset-for-sarcasm-detection\/Sarcasm_Headlines_Dataset.json'))\n\narticle_link= []\nheadline = []\nis_sarcastic = []\n\nfor item in data:\n    article_link.append(item['article_link'])\n    headline.append(item['headline'])\n    is_sarcastic.append(item['is_sarcastic'])","629b029c":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\nfrom sklearn.metrics import classification_report, roc_curve\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Embedding,LSTM,Dense,SpatialDropout1D\nfrom sklearn.model_selection import train_test_split","49a688bd":"df = pd.DataFrame([article_link, headline, is_sarcastic]).T\ndf.columns = ['article_link','headline','is_sarcastic']\n\n#shuffle dataset\ndf = df.sample(frac=1).reset_index(drop=True)\ndf","61aa7154":"df.article_link.apply(lambda x: x.split('\/')[2]).value_counts()","e15bf634":"df['website'] = df.article_link.apply(lambda x: x.split('\/')[2])\ndf","3b3b1bad":"sns.countplot(df.is_sarcastic ,data=df);","19f78c22":"sns.countplot(y= df.website ,data=df, order = df['website'].value_counts().index);","483934c4":"sns.countplot(y= df.website, hue=\"is_sarcastic\" ,data=df, order = df['website'].value_counts().index)\nplt.legend(loc='lower right');","4e61b737":"# Show worscloud for sarcastic\ntext = \" \".join(df.loc[df.is_sarcastic ==1].headline)\n\nwordcloud = WordCloud(width=1500, height=500).generate(text)\n\nplt.figure( figsize=(30,20))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.title('Word cloud of headline is sarcastic')\nplt.axis(\"off\")\nplt.show()","3eec54e5":"# Show worscloud for sarcastic\ntext = \" \".join(df.loc[df.is_sarcastic ==0].headline)\n\nwordcloud = WordCloud(width=1500, height=500)\nwordcloud.generate(text)\n\nplt.figure( figsize=(30,20))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.title('Word cloud of headline is not sarcastic')\nplt.show()","ecca2655":"#split data to train and test set\ntrain_X = df.loc[:2600,['article_link', 'headline', 'website']]\ntrain_y = df.loc[:2600,'is_sarcastic']\n\ntest_X = df.loc[2600:,['article_link', 'headline', 'website']]\ntest_y = df.loc[2600:,'is_sarcastic']","5e2c3f84":"X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.20, stratify = train_y, random_state=42)\nprint(f'Training set size = {len(X_train)}')\nprint(f'Validation set size = {len(X_val)}')","bfce33e1":"#list of stop word\nstopwords = set(STOPWORDS)\n\nprint(STOPWORDS)","c66b5be7":"num_words = 10000\nmaxlen=100\npadding='post'\ntruncating='post'\noov_tok = \"<OOV>\"\nembedding_dim = 16\ndropout_rate = 0.30\n\n#tokenizer will automatically help in choosing most frequent words, to handle sentences that are not in the training set we use out of vocabulary(\"<OOV>\")\n#create the Tokenizer and define an out of vocabulary token\ntokenizer = Tokenizer(num_words = num_words, oov_token=oov_tok)\n\n#fitting the sentences to using created tokenizer object\ntokenizer.fit_on_texts(X_train.headline)\n\n#full list of words is available as the tokenizer's word index\nword_index = tokenizer.word_index\n\n#creates sequence of tokens representing each sentence\nX_train_sequences = tokenizer.texts_to_sequences(X_train.headline)\n\n#padding them with zeros and\/or truncating them. If don't provide the max length, then the sequences are padded to match the length of the longest sentence.\nX_train_padded = pad_sequences(X_train_sequences, maxlen=100, dtype='float32', padding=padding, truncating=truncating, value=0.0)\n\nX_val_sequences = tokenizer.texts_to_sequences(X_val.headline)\nX_val_padded = pad_sequences(X_val_sequences, maxlen=100, dtype='float32', padding=padding, truncating=truncating, value=0.0)\n\ny_train = np.asarray(np.array(y_train)).astype(np.float32)\ny_val = np.asarray(np.array(y_val)).astype(np.float32)\n\n\n# print('sentences')\n# print(X_train.headline[:5])\n\n# print('\\nword_index')\n# print(word_index)\n\n# print('\\nSequence')\n# print(X_train_sequences)\n\n# print('\\npadded')\n# print(X_train_padded)","ec683830":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(num_words, embedding_dim, input_length=maxlen),\n    tf.keras.layers.GlobalAveragePooling1D(),\n    tf.keras.layers.Dropout(dropout_rate),\n    tf.keras.layers.Dense(24, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.summary()","8b2405c7":"num_epochs = 30\ninitial_lr = 0.001\n\n#Early stop the training if there's no improvement in model performance for 20 epochs\nearly = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: initial_lr * 10**(epoch\/20))\n\n# #Reduce model learning rate if validation loss reach plateau\n# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n#                               patience=20, min_lr=0.001)\n\n\nhistory = model.fit(X_train_padded, y_train, epochs = num_epochs, validation_data=(X_val_padded, y_val), callbacks= [early,lr_schedule])","b258eeb6":"def plot_graphs(history, string):\n    \n    plt.plot(history.history[string])\n    plt.plot(history.history['val_'+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string, 'val_'+string])\n    plt.show()\n  \nplot_graphs(history, \"accuracy\")\nplot_graphs(history, \"loss\")","1f6cd324":"#creates sequence of tokens representing each sentence\nX_test_sequences = tokenizer.texts_to_sequences(test_X.headline)\n\n#padding them with zeros and\/or truncating them. If don't provide the max length, then the sequences are padded to match the length of the longest sentence.\nX_test_padded = pad_sequences(X_test_sequences, maxlen=100, dtype='float32', padding=padding, truncating=truncating, value=0.0)\ny_test = np.asarray(np.array(test_y)).astype(np.float32)","f144a6c5":"y_predict = model.predict(X_test_padded)\n\npredict = np.round(y_predict,0).flatten()\n\nresult = pd.DataFrame()\nresult['predict'] = predict\nresult['actual'] = y_test\nresult","cad0e9e5":"# if headline is sarcastic: 1, otherwise: 0\nfor i in range(10):\n    print(test_X.headline.to_list()[i])\n    print(y_predict[i],'\\n')","abe039c0":"matrix = pd.crosstab(result.predict, result.actual, rownames=['Predicted'], colnames=['Actial'])\nsns.heatmap(matrix, annot=True, fmt='g')\nplt.title(f'Original Dataset')\nplt.show()","238f6a05":"print(classification_report(y_test, predict))","53b71fb9":"fpr, tpr, _ = roc_curve(y_test, y_predict)\n\nplt.title('ROC curve')\nplt.xlabel('FPR (Precision)')\nplt.ylabel('TPR (Recall)')\n\nplt.plot(fpr,tpr, label='Embeddings with Global Average Pooling layer')\nplt.legend(loc='lower right')\nplt.plot((0,1), ls='dashed',color='black')\nplt.show()","67f5679a":"# Context\nPast studies in Sarcasm Detection mostly make use of Twitter datasets collected using hashtag based supervision but such datasets are noisy in terms of labels and language. Furthermore, many tweets are replies to other tweets and detecting sarcasm in these requires the availability of contextual tweets.\n\nTo overcome the limitations related to noise in Twitter datasets, this News Headlines dataset for Sarcasm Detection is collected from two news website. **TheOnion** aims at producing sarcastic versions of current events and we collected all the headlines from News in Brief and News in Photos categories (which are sarcastic). We collect real (and non-sarcastic) news headlines from *HuffPost*.\n\nThis new dataset has following advantages over the existing Twitter datasets:\n\nSince news headlines are written by professionals in a formal manner, there are no spelling mistakes and informal usage. This reduces the sparsity and also increases the chance of finding pre-trained embeddings.\n\nFurthermore, since the sole purpose of TheOnion is to publish sarcastic news, we get high-quality labels with much less noise as compared to Twitter datasets.\n\nUnlike tweets which are replies to other tweets, the news headlines we obtained are self-contained. This would help us in teasing apart the real sarcastic elements.","5826e8db":"# Content\n\n**Each record consists of three attributes:**\n\nis_sarcastic: 1 if the record is sarcastic otherwise 0\n\nheadline: the headline of the news article\n\narticle_link: link to the original news article. Useful in collecting supplementary data","8a1bb1b4":"# Inspiration\n\nCan you identify sarcastic sentences? Can you distinguish between fake news and legitimate news?","2ca691f3":"* Dataset has slightly imbalance, In this case we will not cover part to deal with imbalance data.  ","37250fcc":"* Most of text from www.huffingtonpost.com is not sarcastic."}}