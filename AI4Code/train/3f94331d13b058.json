{"cell_type":{"0cf95e03":"code","529c8094":"code","1e65b8a1":"code","f9afe5e8":"code","dcd08fd0":"code","0891b415":"code","88d00f13":"code","f969ace1":"code","c43b3450":"code","4cdc41a2":"code","c4bfdb43":"code","55199170":"code","fb2c164e":"code","fe3b66e2":"code","b2942f1c":"code","5f5c0a01":"code","af7789c0":"code","29581e54":"code","fdb757ed":"code","7388a1dc":"code","1158bc09":"code","c0fdec03":"code","50b76a8a":"code","afc12507":"code","8d58d3db":"code","16633a0b":"code","7cb89d08":"code","f8d852c0":"markdown","777395a0":"markdown","20317735":"markdown","6b18a78f":"markdown","3fad06c0":"markdown","7dfb12fe":"markdown","16f97c23":"markdown","f6abaf68":"markdown","766a3e44":"markdown","3a9d7103":"markdown","c1ed8d08":"markdown","f8808a94":"markdown"},"source":{"0cf95e03":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.image as mimg\n%matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (10,7)\nfrom PIL import Image\nfrom scipy import misc\n\nimport os\n\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n\n# DEEP LEARNING IMPORTS\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Conv2D, Activation, Dropout, Flatten, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping","529c8094":"print(os.listdir(\"..\/input\"))","1e65b8a1":"#one hot encoding function\ndef one_hot_encoder(df_name, df_column_name, suffix=''):\n    temp = pd.get_dummies(df_name[df_column_name]) #get dummies is used to create dummy columns\n    df_name = df_name.join(temp, lsuffix=suffix) #join the newly created dummy columns to original dataframe\n    df_name = df_name.drop(df_column_name, axis=1) #drop the old column used to create dummy columnss\n    return df_name\n\n\n#function to draw confusion matrix\ndef draw_confusion_matrix(true,preds):\n    conf_matx = confusion_matrix(true, preds)\n    sns.heatmap(conf_matx, annot=True,annot_kws={\"size\": 12},fmt='g', cbar=False, cmap=\"viridis\")\n    plt.show()\n    #return conf_matx","f9afe5e8":"train_images = pd.read_csv(\"..\/input\/fashion-mnist_train.csv\")","dcd08fd0":"train_images_x = train_images.iloc[:,1:]","0891b415":"train_images_array = train_images_x.values\ntrain_x = train_images_array.reshape(train_images_array.shape[0], 28, 28, 1)\ntrain_x_scaled = train_x\/255","88d00f13":"IMAGE_SIZE = (28, 28, 1)","f969ace1":"### read the image labels and one hot encode the labels\ntrain_images_y = train_images[['label']]\n\n#do one hot encoding with the earlier created function\ntrain_images_y_encoded = one_hot_encoder(train_images_y, 'label', 'lab')\nprint(train_images_y_encoded.head())\n\n#get the labels as an array\ntrain_images_y_encoded = train_images_y_encoded.values","c43b3450":"#check to see if distribution of target labels are equal (if not equal we need to assign weights to classes)\nplt.bar(train_images_y['label'].value_counts().index, train_images_y['label'].value_counts().values)","4cdc41a2":"test_images = pd.read_csv(\"..\/input\/fashion-mnist_test.csv\")","c4bfdb43":"test_images_x = test_images.iloc[:,1:]\n\ntest_images_array = test_images_x.values\ntest_x = test_images_array.reshape(test_images_array.shape[0], 28, 28, 1)\ntest_x_scaled = test_x\/255","55199170":"test_images_y = test_images[['label']]\ntest_images_y_encoded = one_hot_encoder(test_images_y, 'label', 'lab')\n#get the labels as an array\ntest_images_y_encoded = test_images_y_encoded.values","fb2c164e":"train_x, test_x, train_y, test_y = train_test_split(train_x_scaled, train_images_y_encoded, random_state = 101, \n                                                   test_size=0.25)","fe3b66e2":"def cnn_model(size, num_cnn_layers):\n    NUM_FILTERS = 32\n    KERNEL = (3, 3)\n    #MIN_NEURONS = 20\n    MAX_NEURONS = 120\n    \n    model = Sequential()\n    \n    for i in range(1, num_cnn_layers+1):\n        if i == 1:\n            model.add(Conv2D(NUM_FILTERS*i, KERNEL, input_shape=size, activation='relu', padding='same'))\n        else:\n            model.add(Conv2D(NUM_FILTERS*i, KERNEL, activation='relu', padding='same'))\n\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Flatten())\n    model.add(Dense(int(MAX_NEURONS), activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(int(MAX_NEURONS\/2), activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n    \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    #print(model.summary())\n    \n    return model","b2942f1c":"model = cnn_model(IMAGE_SIZE, 2)","5f5c0a01":"model.summary()","af7789c0":"#set early stopping criteria\npat = 5 #this is the number of epochs with no improvment after which the training will stop\nearly_stopping = EarlyStopping(monitor='val_loss', patience=pat, verbose=1)\n\n#define the model checkpoint callback -> this will keep on saving the model as a physical file\nmodel_checkpoint = ModelCheckpoint('fas_mnist_1.h5', verbose=1, save_best_only=True)\n\n#define a function to fit the model\ndef fit_and_evaluate(t_x, val_x, t_y, val_y, EPOCHS=20, BATCH_SIZE=128):\n    model = None\n    model = cnn_model(IMAGE_SIZE, 2)\n    results = model.fit(t_x, t_y, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[early_stopping, model_checkpoint], \n              verbose=1, validation_split=0.1)  \n    print(\"Val Score: \", model.evaluate(val_x, val_y))\n    return results","29581e54":"n_folds=3\nepochs=20\nbatch_size=128\n\n#save the model history in a list after fitting so that we can plot later\nmodel_history = [] \n\nfor i in range(n_folds):\n    print(\"Training on Fold: \",i+1)\n    t_x, val_x, t_y, val_y = train_test_split(train_x, train_y, test_size=0.1, \n                                               random_state = np.random.randint(1,1000, 1)[0])\n    model_history.append(fit_and_evaluate(t_x, val_x, t_y, val_y, epochs, batch_size))\n    print(\"=======\"*12, end=\"\\n\\n\\n\")","fdb757ed":"plt.title('Accuracies vs Epochs')\nplt.plot(model_history[0].history['acc'], label='Training Fold 1')\nplt.plot(model_history[1].history['acc'], label='Training Fold 2')\nplt.plot(model_history[2].history['acc'], label='Training Fold 3')\nplt.legend()\nplt.show()","7388a1dc":"plt.title('Train Accuracy vs Val Accuracy')\nplt.plot(model_history[0].history['acc'], label='Train Accuracy Fold 1', color='black')\nplt.plot(model_history[0].history['val_acc'], label='Val Accuracy Fold 1', color='black', linestyle = \"dashdot\")\nplt.plot(model_history[1].history['acc'], label='Train Accuracy Fold 2', color='red', )\nplt.plot(model_history[1].history['val_acc'], label='Val Accuracy Fold 2', color='red', linestyle = \"dashdot\")\nplt.plot(model_history[2].history['acc'], label='Train Accuracy Fold 3', color='green', )\nplt.plot(model_history[2].history['val_acc'], label='Val Accuracy Fold 3', color='green', linestyle = \"dashdot\")\nplt.legend()\nplt.show()","1158bc09":"#Load the model that was saved by ModelCheckpoint\nmodel = load_model('fas_mnist_1.h5')","c0fdec03":"model.evaluate(test_x, test_y)","50b76a8a":"model.evaluate(test_x_scaled, test_images_y_encoded)","afc12507":"#function for converting predictions to labels\ndef prep_submissions(preds_array, file_name='abc.csv'):\n    preds_df = pd.DataFrame(preds_array)\n    predicted_labels = preds_df.idxmax(axis=1) #convert back one hot encoding to categorical variabless\n    return predicted_labels\n    '''\n    ### prepare submissions in case you need to submit\n    submission = pd.read_csv(\"test.csv\")\n    submission['label'] = predicted_labels\n    submission.to_csv(file_name, index=False)\n    print(pd.read_csv(file_name).head())\n    '''","8d58d3db":"test_preds = model.predict(test_x_scaled)\ntest_preds_labels = prep_submissions(test_preds)","16633a0b":"print(classification_report(test_images_y, test_preds_labels))","7cb89d08":"draw_confusion_matrix(test_images_y, test_preds_labels)","f8d852c0":"Test the score on the test split","777395a0":"Define some callbacks ","20317735":"Plots to see how the models are performing","6b18a78f":"Read the test dataset","3fad06c0":"Train the model with K-fold Cross Val","7dfb12fe":"Read the training labels and one hot encode the labels","16f97c23":"Check scoring on the actual test set","f6abaf68":"Read test dataset labels","766a3e44":"Defining the CNN Architecture","3a9d7103":"Read Train Dataset","c1ed8d08":"Split into train adn test set","f8808a94":"Utility Functions"}}