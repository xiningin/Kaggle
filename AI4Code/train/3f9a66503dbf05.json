{"cell_type":{"3199b272":"code","6dd6f486":"code","9e4d62b4":"code","9c803f2e":"code","1f39361b":"code","11edf96b":"code","ffad6f13":"code","6bdc3c44":"code","0571a93a":"code","ae137fc2":"code","8992157c":"code","5fa65c57":"code","1e5052ce":"code","1d7e1c84":"code","cabea743":"code","20381b7c":"code","83d07ee0":"code","5b55724f":"code","c3cafb4b":"code","7282d177":"code","b46d25fb":"code","59aac09b":"code","abfac8d7":"code","853b69b9":"code","79848f80":"code","18b63c8f":"code","08af173e":"code","92f43b09":"code","cc572d0b":"code","26b4396d":"markdown","28326182":"markdown","ec341f0a":"markdown","edc13255":"markdown","b36e501f":"markdown","2b391f5a":"markdown","abf4608a":"markdown","e314e8a2":"markdown","9d0e9c25":"markdown","42a0fe3b":"markdown","0a763435":"markdown","9aed100c":"markdown","ec402175":"markdown","59aae59e":"markdown","303871b3":"markdown","b9e0ca12":"markdown","86c457c0":"markdown","0289017b":"markdown","d84cb992":"markdown","8501ebb6":"markdown","f16324e4":"markdown","bc23b581":"markdown","8f741a67":"markdown","bb8b27b4":"markdown","f15500f3":"markdown","0c597839":"markdown","26500dd3":"markdown","573280e3":"markdown","a3050822":"markdown"},"source":{"3199b272":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport re as re\n\nfrom matplotlib import pyplot as plt\n\n# blibliotecas para plotarmos os dados\nimport seaborn as sns\nsns.set_style(\"whitegrid\")","6dd6f486":"# leitura dos datasets do titanic\n# train = leitura do conjunto de dados de treinamento\n# test = leitura do conjunto de dados de teste\n#genderSubmissionsubmission = vamos utilizar no final da an\u00e1lise\ntrain = pd.read_csv('..\/input\/train.csv', header = 0, dtype={'Age': np.float64})\ntest  = pd.read_csv('..\/input\/test.csv' , header = 0, dtype={'Age': np.float64})\nsubmission = pd.read_csv('..\/input\/test.csv' , header = 0, dtype={'Age': np.float64})\n\n# full_data \u00e9 uma estrutura que armazena os nossos 2 datasets, isso ir\u00e1 facilitar nosso trabalho mais para frente\nfull_data = [train, test]","9e4d62b4":"#vamos dar uma olhada nos dados de treinamento\ntrain.head()","9c803f2e":"#vamos dar uma olhada nos dados de teste\ntest.head()","1f39361b":"# vamos verificar os dados (colunas do nosso dataset)\nprint (train.info())","11edf96b":"print (train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())","ffad6f13":"# utilizando o conjunto de Treinamento vamos observar os dados\np = sns.countplot(data=train, x = 'Survived', hue = 'Sex')\nplt.title(\"Distribui\u00e7\u00e3o de sobreviventes de acordo com o sexo\")\nplt.show()\n\n# vari\u00e1veis para exibir\ntotal_survived_females = train[train.Sex == \"female\"][\"Survived\"].sum()\ntotal_survived_males = train[train.Sex == \"male\"][\"Survived\"].sum()\n\nprint(\"Total de sobreviventes: \" + str((total_survived_females + total_survived_males)))\nprint (train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean())","6bdc3c44":"# Mas e o tamanho da fam\u00edlia, seria importante?\n# podemos criar uma nova vari\u00e1vel chamada FamilySize de acordo com \n# n\u00famero de irm\u00e3os por conjuge e numero de pais por filhos abordo\n\n# criamos uma nova vari\u00e1vel para cada dataset em full_data chamada FamilySize\nfor dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\n# informa\u00e7\u00f5es obtidas do conjunto de treinamento\nprint (train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())","0571a93a":"# dataset 0 de full_data = dataset de treinamento (train)\nfull_data[0].head()","ae137fc2":"# dataset 1 de full_data = dataset de teste (test)\nfull_data[1].head()","8992157c":"# dentro de cada dataset (train e teste) corrigimos os valores\nfor dataset in full_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n    \nprint (train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())","5fa65c57":"# observando a m\u00e9dia de idade no conjunto de Treinamento\nmedia = train['Age'].mean()\ndesvio = train['Age'].std()\nprint(\"M\u00e9dia da idade:\",media)\nprint(\"Desvio padr\u00e3o da idade:\",desvio)","1e5052ce":"# dentro de cada dataset (train e teste) corrigimos o campo Age (idade)\nfor dataset in full_data:\n    age_avg = dataset['Age'].mean() #retorna a m\u00e9dia da idade\n    age_std = dataset['Age'].std()  # retorna o desvio padr\u00e3o\n    age_null_count = dataset['Age'].isnull().sum() #conta a quantidade de campos nulos\n    \n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)\n        \ntrain['CategoricalAge'] = pd.cut(train['Age'], 5)\nprint (train[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean())","1d7e1c84":"# dentro de cada dataset (train e teste) transformamos nossas vari\u00e1veis em valores num\u00e9ricos\nfor dataset in full_data:\n    # Mapping Sex\n    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n    \n    # Mapping Embarked\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int) \n    \n    # Mapping Age\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']                           = 4\n\n# Sele\u00e7\u00e3o de vari\u00e1veis que n\u00e3o iremos utilizar\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp',\\\n                 'Parch','Fare']\n\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge'], axis = 1)\n\ntest  = test.drop(drop_elements, axis = 1)\n\nprint (train.head(10))\n\ntrain = train.values\ntest  = test.values","cabea743":"from sklearn.svm import SVC\nfrom sklearn import metrics\nfrom sklearn import model_selection\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict","20381b7c":"classifiers = [SVC(probability=True)]\ncandidate_classifier = SVC()","83d07ee0":"candidate_classifier.fit(train[0::, 1::], train[0::, 0])","5b55724f":"def acuracia(clf,X,y):\n    scores = cross_val_score(clf, X, y, cv=5)\n    resultados = cross_val_predict(clf, X, y, cv=5)\n    print(\"Cross-validated Scores: \",scores)\n    acuracia_media = metrics.accuracy_score(y,resultados)\n    print(\"Acur\u00e1cia m\u00e9dia: \", acuracia_media)\n    return None","c3cafb4b":"# armazenamos os resutados esperados\nclasses = candidate_classifier.predict(train[0::,1::])","7282d177":"# executamos a fun\u00e7\u00e3o acuracia\nacuracia(candidate_classifier,train,classes)","b46d25fb":"result = candidate_classifier.predict(test)","59aac09b":"print (result)","abfac8d7":"submission.head()","853b69b9":"final = pd.DataFrame({\n        # dados armazenados em submission\n        \"PassengerId\": submission[\"PassengerId\"],\n        \"Pclass\": submission[\"Pclass\"],\n        \"Pclass\": submission[\"Name\"],\n        \"Sex\": submission[\"Sex\"],\n        \"Age\": submission[\"Age\"],\n        \"FamilySize\": submission['SibSp'] + submission['Parch'] + 1,\n        # dados armazenados em result\n        \"Survived\": result\n    })","79848f80":"final.to_csv(\"titanic.csv\", index=False)\nprint(final.shape)","18b63c8f":"final","08af173e":"# utilizando o resultado que obtivemos vamos observar os dados\np = sns.countplot(data=final, x = 'Survived', hue = 'Sex')\nplt.title(\"Distribui\u00e7\u00e3o de sobreviventes de acordo com o sexo\")\nplt.show()","92f43b09":"print (final[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())","cc572d0b":"genderSubmission = pd.DataFrame({\n        # dados armazenados em submission\n        \"PassengerId\": submission[\"PassengerId\"],\n        # dados armazenados em result\n        \"Survived\": result\n    })\n\ngenderSubmission.to_csv(\"gender_submission.csv\", index=False)\n\nprint(genderSubmission)\n","26b4396d":"Como estamos testando nosso classificador usando os dados de treinamento, podemos:\n1. executar nosso classificador sobre os **dados de teste**\n2. comparar os resultados do classificador com os resultados esperados (armazenados na coluna survived)","28326182":"## Visualizando os resultados da nossa predi\u00e7\u00e3o\nPodemos plotar os dados da nossa estrutura <b>final<\/b> para visualizar e analisar o resultado da nossa predi\u00e7\u00e3o","ec341f0a":"<b>d) Ap\u00f3s o treinamento, realizamos a predi\u00e7\u00e3o com os dados de teste<\/b>","edc13255":"Se olharmos novamento os dados dos **dataset de treinamento e de teste**, podemos ver que uma nova coluna foi adicionada: **FamilySize**.","b36e501f":"### Testando nosso classificador\nUma forma de validar o classificador \u00e9 usar a t\u00e9cnica chamada **Cross Validation\/Valida\u00e7\u00e3o Cruzada**.\n\nAbaixo, vamos criar uma fun\u00e7\u00e3o que faz o Cross Validation e nos retorna a acur\u00e1cia m\u00e9dia. A Acur\u00e1cia, basicamente \u00e9 o percentual de acertos que modelo teve.","2b391f5a":"<b> b) Criamos o nosso classificador SVC do tipo SVM (M\u00e1quinas de Vetores de Suporte) <\/b>","abf4608a":"### 3.5 Age \nEssa vari\u00e1vel possui alguns valores nulos tamb\u00e9m. Existem diversar formas de tratar valores nulos em um dataset.\n* substituir os valores nulos pela **m\u00e9dia da vari\u00e1vel**\n* substituir os valores nulos de forma aleat\u00f3ria dentro de um intervalo **[m\u00e9dia - desvio, m\u00e9dia + desvio]**","e314e8a2":"## Predi\u00e7\u00e3o\nAgora vamos usar o SVC como nosso classificador.\n\nMais informa\u00e7\u00f5es sobre o SVC. \nhttps:\/\/scikit-learn.org\/stable\/modules\/svm.html","9d0e9c25":"## 3. Conhecendo das variave\u00eds do dataset","42a0fe3b":"#### Ap\u00f3s isso, iremos transformar nosso dados em um arquivo csv","0a763435":"## Limpeza dos dados\nLegal, j\u00e1 conhecemos todas as vari\u00e1veis do nosso dataset.\n\nAgora, vamos limpar nossos dados e transform\u00e1-los em valores num\u00e9ricos. ","9aed100c":"\u00d3timo! Agora temos um dataset limpo e pronto para montarmos nosso modelo de predi\u00e7\u00e3o.","ec402175":"## Criamos um Dataframe para armazenar nossos dados\n\nUm <a href=\"https:\/\/www.tutorialspoint.com\/python_pandas\/python_pandas_dataframe.htm\" targeg=\"_blank\">DataFrame<\/a> \u00e9 uma estrutura bidimensional (como uma matriz ou tabela). <br>\n\nIremos juntar os dados armazenados em <b>submission<\/b> com os dados gerados pelo nosso classificador (<b>results<\/b>) e criar uma nova coluna chamada <b>Survived<\/b> que ter\u00e1 apenas os valores bin\u00e1rios (1 - sobreviveu, 0 - n\u00e3o sobreviveu).\n","59aae59e":"### 3.3 SibSp and Parch - tamanho da fam\u00edlia\n","303871b3":"## 2. Leitura e entendimento dos datasets do titanic","b9e0ca12":"### 3.2 Sexo do passageiro\nDistribui\u00e7\u00e3o de sobreviventes de acordo com o sexo","86c457c0":"#### Mas, j\u00e1 vamos dar uma olhada no resultado final da nossa predi\u00e7\u00e3o","0289017b":"O tamanho da fam\u00edlia parece ser uma vari\u00e1vel influente na taxa de sobreviv\u00eancia.","d84cb992":"Podemos observar se a classe de viagem do passageiro tem influ\u00eancia na taxa de sobreviv\u00eancia.","8501ebb6":"Das informa\u00e7\u00f5es acima, podemos ver que algumas colunas est\u00e3o incompletas (faltando dados) e teremos que tratar isso de alguma maneira.\n\nIremos passar por cada vari\u00e1vel do dataset para entend\u00ea-la e, se necess\u00e1rio, tratar os dados nulos.","f16324e4":"### 3.4 Embarked\nEssa vari\u00e1vel possui alguns valores nulos. Vamos tentar preencher os valores nulos com o valor que mais ocorre: S.","bc23b581":"## Cria\u00e7\u00e3o do arquivo de submiss\u00e3o","8f741a67":"**c) Treinamos o nosso classificador com o conjunto de treinamento.**\n\nA fun\u00e7\u00e3o ```.fit(X, y) ``` recebe 2 arrays de entrada:\n* **X** em forma de matriz ```[elementos, vari\u00e1veis]``` com todos os elementos do conjunto de treinamento\n* **y** em forma de array com o nome das vari\u00e1veis\n\nMais informa\u00e7\u00f5es sobre SVM em python: https:\/\/scikit-learn.org\/stable\/modules\/svm.html","bb8b27b4":"Lembra-se da nossa vari\u00e1vel **submission** que guardou os dados de teste? Agora iremos utiliz\u00e1-la para saber quem s\u00e3o os passageiros que sobreviveram ou n\u00e3o.","f15500f3":"Como podemos ver a acur\u00e1cia ficou na faixa de 97%! O SVM est\u00e1 funcionando muito bem para esses dados.\n\nMas precisamos ter em mente que a base de dados do Titanic \u00e9 uma base pequena e simples, por isso, conseguimos facilmente um bom trabalho do SVM. O objetivo foi apenas mostrar como podemos testar nosso algoritmo de forma pr\u00e1tica.\n\nAgora, vamos seguir com a predi\u00e7\u00e3o dos nossos dados de teste, que, afinal, \u00e9 o nosso objetivo!","0c597839":"Abaixo o print do resultado, uma array de 0's e 1's. Cada valor representa um dos passageiros. ","26500dd3":"## 1. Instala\u00e7\u00e3o das principais bibliotecas que iremos utilizar","573280e3":"### 3.1 Pclass - classe de viagem do passageiro","a3050822":"<b>a) Importamos as bibliotecas necess\u00e1rias<\/b>"}}