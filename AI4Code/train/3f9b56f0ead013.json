{"cell_type":{"2b1a5324":"code","bddf341f":"code","679d4f74":"code","31b8f693":"code","9b6d9a1d":"code","4c392f77":"code","a9a81d66":"code","bbc10f79":"code","ca1f607a":"code","3728150e":"code","5cbaa769":"code","def5f1c2":"code","371c5831":"code","50c6a949":"code","120c170b":"code","60aa7adf":"code","7012bf58":"code","a3df6137":"markdown","7a2cbfed":"markdown","566f8ebb":"markdown","adbe94e3":"markdown","7a7455cb":"markdown","1ab143d2":"markdown","24688058":"markdown","7799b464":"markdown","37fcb29e":"markdown","acc98ba8":"markdown","750aa036":"markdown","79c28c5e":"markdown","42f86f58":"markdown","bb14eb4c":"markdown"},"source":{"2b1a5324":"# I started my work by taking tips from https:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard\n# Importing libraries\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import norm, skew\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nimport warnings\nwarnings.filterwarnings('ignore')","bddf341f":"# bring the numbers in\ndf_train = pd.read_csv('..\/input\/train.csv')\ndf_test = pd.read_csv('..\/input\/test.csv')\nprint('Size of train data set is :',df_train.shape)\nprint('Size of test data set is :',df_test.shape)","679d4f74":"#Saving Ids\ntrain_ID = df_train['Id']\ntest_ID = df_test['Id']\n\n#Dropping Ids\ndf_train.drop(\"Id\", axis = 1, inplace = True)\ndf_test.drop(\"Id\", axis = 1, inplace = True)","31b8f693":"fig, ax = plt.subplots()\nax.scatter(x = df_train['GrLivArea'], y = df_train['SalePrice'], c = \"skyblue\")\nplt.ylabel('SalePrice', fontsize=6)\nplt.xlabel('GrLivArea', fontsize=6)\nplt.show()\n\ndf_train = df_train.drop(df_train[(df_train['GrLivArea']>4000)].index)\n\nfig, ax = plt.subplots()\nax.scatter(x = df_train['GrLivArea'], y = df_train['SalePrice'], c = \"skyblue\")\nplt.ylabel('SalePrice', fontsize=6)\nplt.xlabel('GrLivArea', fontsize=6)\nplt.show()","9b6d9a1d":"#Correlation matrix\ncorrmat = df_train.corr()\nmask = np.zeros_like(corrmat)\nmask[np.triu_indices_from(mask)] = True\nplt.subplots(figsize=(12,9))\nsns.heatmap(corrmat, mask=mask, linewidths=.5, vmax=0.7, square=True, cmap=\"YlGnBu\")","4c392f77":"#stat summary\ndf_train['SalePrice'].describe()\n\n#get distribution & QQ Plot\nsns.distplot(df_train['SalePrice'], \n             kde_kws={\"color\": \"coral\", \"lw\": 1, \"label\": \"KDE\"}, \n             hist_kws={\"histtype\": \"stepfilled\", \"linewidth\": 3, \"alpha\": 0.8, \"color\": \"skyblue\"});\n\n\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice'], plot=plt)\nplt.show()","a9a81d66":"df_train['SalePrice_Log'] = np.log(df_train['SalePrice'])\n\nsns.distplot(df_train['SalePrice_Log'], \n             kde_kws={\"color\": \"coral\", \"lw\": 1, \"label\": \"KDE\"}, \n             hist_kws={\"histtype\": \"stepfilled\", \"linewidth\": 3, \"alpha\": 1, \"color\": \"skyblue\"});\n \n# skewness and kurtosis\nprint(\"Skewness: %f\" % df_train['SalePrice_Log'].skew())\nprint(\"Kurtosis: %f\" % df_train['SalePrice_Log'].kurt())\n\nfig = plt.figure()\nres = stats.probplot(df_train['SalePrice_Log'], plot=plt)\nplt.show()\n\n# dropping SalePrice\ndf_train.drop('SalePrice', axis= 1, inplace=True)","bbc10f79":"#Saving sets sizes, concat sets and dropping target variable\nsize_df_train = df_train.shape[0]\nsize_df_test = df_test.shape[0]\ntarget_variable = df_train.SalePrice_Log.values\ndata = pd.concat((df_train, df_test)).reset_index(drop=True)\ndata.drop(['SalePrice_Log'], axis=1, inplace=True)\n\n# Lets check if the ammount of null values in data\ndata.count().sort_values()","ca1f607a":"features_fill_na_none = ['PoolQC','MiscFeature','Alley','Fence','FireplaceQu',\n               'GarageQual','GarageCond','GarageFinish','GarageType',\n               'BsmtExposure','BsmtCond','BsmtQual','BsmtFinType1','BsmtFinType2',\n               'MasVnrType']\n\nfor feature_none in features_fill_na_none:\n    data[feature_none].fillna('None',inplace=True)\n    \nfeatures_fill_na_0 = ['GarageYrBlt', 'GarageArea', 'GarageCars', 'MasVnrArea',\n                      'BsmtFullBath','BsmtHalfBath', 'BsmtFinSF1', 'BsmtFinSF2', \n                      'BsmtUnfSF', 'TotalBsmtSF']\n\nfor feature_0 in features_fill_na_0:\n    data[feature_0].fillna('None',inplace=True)\n\n#LotFrontage\n#We'll fill missing values by the median of observation's Neighborhood\ndata[\"LotFrontage\"] = data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))\n\n#MSzoning - 4 missing values\n#We'll fill missing values with most common value\ndata['MSZoning'] = data['MSZoning'].fillna(data['MSZoning'].mode()[0])\n\n# Utilities\n# All records have \"AllPub\", but 3. From those 3, 2 are NA and one is \"NoSeWa\" is \n# in the training set.\n# We may proceed to drop this column\ndata = data.drop(columns=['Utilities'],axis=1)\n\n#Functional: NA means \"Typ\"\ndata[\"Functional\"] = data[\"Functional\"].fillna(\"Typ\")\n\n# Electrical - 91% of observations have Electrical = SBrkr\n# We'll fill missing values with SBrkr\ndata['Electrical'] = data['Electrical'].fillna(\"SBrkr\")\n\n#Exterior1st and Exterior2nd, one missing value, same observation\n#We'll substitute it with the most common value\ndata['Exterior1st'] = data['Exterior1st'].fillna(data['Exterior1st'].mode()[0])\ndata['Exterior2nd'] = data['Exterior2nd'].fillna(data['Exterior2nd'].mode()[0])\n\n#KitchenQual, ony one missing value\n#We'll subsitute it with the most common value\ndata['KitchenQual'] = data['KitchenQual'].fillna(data['KitchenQual'].mode()[0])\n\n#Saletype, ony one missing value\n#We'll subsitute it with the most common value\ndata['SaleType'] = data['SaleType'].fillna(data['SaleType'].mode()[0])","3728150e":"data.count().sort_values()","5cbaa769":"#getting numerical features and categorical features\nnumerical_features = data.dtypes[data.dtypes != \"object\"].index\ncategorical_features = data.dtypes[data.dtypes == \"object\"].index\n\nprint(\"We have: \", len(numerical_features), 'Numerical Features')\nprint(\"We have: \", len(categorical_features), 'Categorical Features')\n\nnumerical_features\ncategorical_features","def5f1c2":"features_to_transform = ['MSSubClass', 'OverallCond', 'YrSold', 'MoSold']\n\nfor feature in features_to_transform:\n    data[feature] = data[feature].apply(str)\n\n#Let's check how our features stand now\nnumerical_features = data.dtypes[data.dtypes != \"object\"].index\ncategorical_features = data.dtypes[data.dtypes == \"object\"].index\n\nprint(\"We have: \", len(numerical_features), 'Numerical Features')\nprint(\"We have: \", len(categorical_features), 'Categorical Features')\n\nnumerical_features\ncategorical_features\n\n#Let's encode categorical variables\nencode_cat_variables = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n\nfor variable in encode_cat_variables:\n    lbl = LabelEncoder() \n    lbl.fit(list(data[variable].values)) \n    data[variable] = lbl.transform(list(data[variable].values))","371c5831":"#Boxplot for numerical_features\nsns.set_style(\"whitegrid\")\nf, ax = plt.subplots(figsize=(20, 20))\nax.set_xscale(\"log\")\nax = sns.boxplot(data=data[numerical_features] , orient=\"h\", palette=\"ch:2.5,-.2,dark=.5\")\nax.set(ylabel=\"Features\")\nax.set(xlabel=\"Value\")\nax.set(title=\"Distribution\")\nsns.despine(trim=True, left=True)","50c6a949":"skewed_features = data[numerical_features].apply(lambda x: skew(x)).sort_values(ascending=False)\n\nnorm_target_features = skewed_features[skewed_features > 0.5]\nnorm_target_index = norm_target_features.index\nprint(\"#{} numerical features need normalization; :\".format(norm_target_features.shape[0]))\nskewness = pd.DataFrame({'Skew' :norm_target_features})\nnorm_target_features\n","120c170b":"#Normalizing with Box Cox Transformation\nfor i in norm_target_index:\n    data[i] = boxcox1p(data[i], boxcox_normmax(data[i] + 1))\n\n#Let's look how the transformed features are standing now\nsns.set_style(\"whitegrid\")\nf, ax = plt.subplots(figsize=(15, 15))\nax.set_xscale(\"log\")\nax = sns.boxplot(data=data[norm_target_index] , orient=\"h\", palette=\"ch:2.5,-.2,dark=.3\")\nax.set(ylabel=\"Features\")\nax.set(xlabel=\"Value\")\nax.set(title=\"Distribution\")\nsns.despine(trim=True, left=True)","60aa7adf":"#back to train and test sets\ndf_train = data[:size_df_train]\ndf_test = data[size_df_train:]","7012bf58":"#Cross Validation\nn_folds = 5\n\ndef rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(df_train.values)\n    rmse= np.sqrt(-cross_val_score(model, df_train.values, target_variable, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)\n","a3df6137":"**Third step** - Missing data","7a2cbfed":"We'll check again if we have filled all missing values","566f8ebb":"First glance correlation","adbe94e3":"All missing values filled\n\n**Fourth step** - A little bit of Feature Eng.","7a7455cb":"**Second Step** - Let's look deeper at the features and target variable","1ab143d2":"**Fist Step** - Data & Field Understanding","24688058":"**Outliers**\n\nFirst of all, we're going to remove some outliers according to the author's suggestion.\nLet's explore these outliers","7799b464":"Let's look for numerical_features that can be normalized","37fcb29e":"SalePrice is not normally distributed. We will make a log transformation","acc98ba8":"As you might see, 3 numerical features are categorical\nLet's change this","750aa036":"Let's workout the numerical features","79c28c5e":"- NA for 'PoolQC' means \"No Pool\".\n- MiscFeature: NA means \"None\"\n- Alley: NA means \"No alley access\"\n- Fence: NA means \"No fence\"\n- FireplaceQu: NA means \"No fireplace\"\n- LotFrontage: fill missing values with median LotFrontage of neighborhood\n- GarageFinish: NA means \"None\"\n- GarageQual: NA means \"None\"\n- GarageCond: NA means \"None\"\n- GarageYrBlt: NA means 0\n- GarageType: NA means \"None\"\n- BsmtCond: NA means \"None\"\n- BsmtExposure: NA means \"None\"\n- BsmtQual: NA means \"None\"\n- BsmtFinType2: NA means \"None\"\n- BsmtFinType1: NA means \"None\"\n- MasVnrType: NA means \"None\"\n- MasVnrArea: NA means \"0\"\n- BsmtHalfBath: NA means \"0\"\n- BsmtFullBath: NA means \"0\"\n- BsmtFinSF1: NA means \"0\"\n- BsmtFinSF2: NA means \"0\"\n- BsmtUnfSF: NA means \"0\"\n- TotalBsmtSF: NA means \"0\"\n- GarageCars: NA means 0\n- GarageArea: NA means 0","42f86f58":"**Fifth step** - Modelling","bb14eb4c":"Let's get some info about the Target Variable"}}