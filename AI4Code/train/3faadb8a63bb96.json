{"cell_type":{"3682d7f9":"code","95af64ca":"code","30cf9099":"code","74d4b026":"code","1194f240":"code","3c79e92c":"code","5e2bdb0c":"code","5dd38880":"code","b2d09529":"code","9c6d1e19":"code","3ca13005":"code","9685075a":"code","b3ebbc30":"code","2566800f":"code","7f1cdf3b":"code","102135c0":"code","8600559c":"code","ece28077":"code","46bbb3ce":"code","592a6de1":"code","e4a0d487":"code","7af0de9a":"code","0ede3326":"code","b4b071a6":"code","ca92ca5d":"code","fb9f520f":"code","c1530593":"code","6fba84d2":"code","d2611556":"code","14052af6":"code","521f3938":"code","38c7e239":"code","d7bad1a1":"code","352093ee":"code","986fc6cf":"code","a4ca389e":"code","830d4c7a":"code","a02c7e92":"code","5c0b6ccf":"code","c89901ba":"code","f8fb5173":"code","0140d46f":"code","18461102":"code","8089752b":"code","52a58605":"code","0387d19a":"code","52e5559e":"code","ea02759f":"code","bbcb8381":"code","9d1f61aa":"code","fd912536":"code","57dbe995":"code","d8e43e87":"code","84afbeec":"code","da75d7d3":"code","17cdbe02":"code","ace0585f":"code","69567136":"code","04cd3b81":"code","51944612":"code","c2972f6a":"code","adb675e5":"code","582c8593":"code","75a011f0":"code","f1f0171a":"code","846b67fa":"code","76bc7d71":"code","8c99913b":"code","f2d0141c":"code","c25546eb":"code","4e115042":"code","05df5285":"code","6835b24b":"markdown","56aa319d":"markdown","217f633a":"markdown","58e3618e":"markdown","f913a090":"markdown","734a06f4":"markdown","40d1d768":"markdown","5f1981fd":"markdown","7fad2b83":"markdown","b3a5655a":"markdown","87b9355c":"markdown","cf521769":"markdown","f70e12c6":"markdown","85305165":"markdown","5d356064":"markdown","7a6358dd":"markdown","977ecc89":"markdown","3869b6ec":"markdown","c8ae2b72":"markdown","fb01b1e2":"markdown","6d5de968":"markdown","5783ad04":"markdown","16010f3e":"markdown","48647bdd":"markdown","b33aa1b6":"markdown","556afdd4":"markdown","0fcdff11":"markdown","2fccf8f1":"markdown","0085353f":"markdown","c44f2c8b":"markdown"},"source":{"3682d7f9":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pylab import rcParams\nrcParams[\"figure.figsize\"] = (12, 6)\nsns.set()","95af64ca":"main_data = pd.read_csv(\"..\/input\/indian-food-101\/indian_food.csv\")\nmain_data.head()","30cf9099":"main_data.shape","74d4b026":"# first let's look at to the columns\nmain_data.columns","1194f240":"# let's look at the name column\n\nmain_data.name.nunique()\n# so name is indicates the name of the indian food, here we have a 255 indian food","3c79e92c":"# let's remove space around name incase if the have\n\nmain_data.name = main_data.name.str.strip()\n\n# let's convert name into lower case\nmain_data.name = main_data.name.str.lower()","5e2bdb0c":"# let's look at the ingredients\n\n# ingredients which are used to make that particular dishes","5dd38880":"# let's look at the diet\n\n# diets can be vegetarian or Non vegetarian\n\nmain_data.diet.value_counts()","b2d09529":"# let's look at the prep time and cook time\n\n# so prep time is preparation time of particular dish\n# cook time is cooking time taken by particular dish to cook","9c6d1e19":"# let's look at the flavor_profile\n\nmain_data.flavor_profile.value_counts()\n# so flavor_profile indicates the flavor of the food\n# here we have four types of flavor\n# here we can see there are some NaN value as -1","3ca13005":"# let's look at the course\n\nmain_data.course.value_counts()\n\n# here course indicates that the cuisine is use as a main course or dessert or snack or starter","9685075a":"# let's look at to the state\n\nmain_data.state.unique()\n\n# here are the state of india which indicates that the foods are famous or born in that particular state\n\n# here we can see there are some NaN value as -1","b3ebbc30":"# let's look at to the region\n\nmain_data.region.unique()\n\n# here are the five region of the india which indicates where the state is belong\n\n# here we can see there are some NaN value as -1","2566800f":"# let's check the NaN value\n\nmain_data.isna().sum()","7f1cdf3b":"# here is NaN value in region columns\n\nmain_data[main_data.region.isna()]","102135c0":"# so above i can see that there is a NaN value which has state is Uttar Pradesh\n# so find that what is the region value where the state is Uttar Pradesh\n\nmain_data.loc[main_data.state == \"Uttar Pradesh\"].head()","8600559c":"# so here we can see region is North whenver the state is Uttar Pradesh\n# let's fill that NaN value of region as a North \n\nmain_data.region.fillna(\"North\", inplace = True)","ece28077":"# let's look at to the diet\n\n# let's replace non vegetarian to non-vaegetarian for ease of access\nmain_data.diet = main_data.diet.str.replace(\" \", \"-\")\n\nsns.countplot(data = main_data, x = \"diet\", palette = [\"green\", \"red\"])\nplt.xlabel(\"Diet\")\nplt.ylabel(\"Count\")\nplt.title(\"Proporation of Diet\")\nplt.show()","46bbb3ce":"main_data.flavor_profile.value_counts()","592a6de1":"# we don't have any NaN value in flavor_profile but we have a -1 value in flavor profile which is likely to NaN\n# so we fill that -1 to other, it's call other flavor\n\n# so whenever it has \"-1\" in flavor_profile we replace it to with other\n\nmain_data.flavor_profile = main_data.flavor_profile.replace(\"-1\", \"other\")","e4a0d487":"main_data.flavor_profile.value_counts()","7af0de9a":"# let's plot flavor_profile\n\nsns.countplot(data = main_data, x = \"flavor_profile\")\nplt.xlabel(\"Flavours\")\nplt.title(\"Test of the cuisine base on flavours\")\nplt.show()","0ede3326":"# let's look at the course \n# here course are main course which usually we take at a lunch and dinner time\n# dessert is a sweet basically which we take a usually after lunch and dinner\n# there also some snack and starter\n\nsns.countplot(data = main_data, x = \"course\")\nplt.show()","b4b071a6":"# let's look at the state\n# state doesn't have and NaN value but state have a -1 value which is likely to NaN value\n# so here 24 -1 means we have 24  NaN values\nmain_data.state.value_counts().head()","ca92ca5d":"# let's look at the data where the state value is \"-1\"\n\nmain_data.loc[main_data.state == \"-1\"].head()","fb9f520f":"# so i research this on internet and i found that there are some of the dishes which are famous and common to\n# all the over the state of india\n# so to prevent this outlier i replace \"-1\" with All State\n\nmain_data.state = main_data.state.replace(\"-1\", \"All State\")","c1530593":"# let's find out number of state\n\nmain_data.state.nunique() - 1\n# here we have a total 24 unique states","6fba84d2":"# let's plot the number of dishes are famous or born in particular state of india\n\nsns.countplot(data = main_data, y = \"state\")\nplt.title(\"Number of Dishes which are famous or born in the State of India\")\nplt.ylabel(\"States\")\nplt.show()","d2611556":"# let's look at the region\nmain_data.region.value_counts()","14052af6":"# In region columns we don't have any NaN value but we have a -1 value which likely to NaN value\n\n# let's look at the data where Region is -1\n\nmain_data[main_data.region == \"-1\"].head()","521f3938":"# so i research this on internet and i found that there are some of the dishes which are famous and common to\n# all the over the india\n# so to prevent this outlier i replace \"-1\" with All Region\n\nmain_data.region = main_data.region.replace(\"-1\", \"All Region\")","38c7e239":"# let's plot number of dishes are famous in particular region of india\n\nsns.countplot(data = main_data, x = \"region\")\nplt.title(\"Number of Dishes which are famous or born in the Region of India\")\nplt.xlabel(\"Region\")\nplt.show()","d7bad1a1":"# let's look at the prep time\nmain_data.prep_time.unique()","352093ee":"# in prep time i found that there are -1 value which is our outlier in this case\n\n# let's look at the data where prep time is -1\n\nmain_data.loc[main_data.prep_time == -1].head()\n\n# here are some dishes which i don't have any prep time, i'll solve it later","986fc6cf":"# let's look at th cook time\n\nmain_data.cook_time.unique()","a4ca389e":"# in cook time i found that there are value -1 which is outlier\n\n# let's look at the data where cook time value is -1\n\nmain_data.loc[main_data.cook_time == -1].head()\n# here some of dishes which i don't have a cook time, i will solve it later","830d4c7a":"# let's plot prep time and cook time\n\nsns.scatterplot(data = main_data, x = \"prep_time\", y = \"cook_time\",hue = \"diet\", palette=[\"green\", \"red\"])\nplt.show()","a02c7e92":"# let's look at to the ingrediets which are used to make a particular dish\n\n# first let's convert all ingredients into lower case for preventing case sensitive\nmain_data.ingredients = main_data.ingredients.str.lower()\n# so here ingredients are a comman seprated\n# let's split those ingredits and divide into veg and non-veg proporation\n\nveg_ingredients = main_data.loc[main_data.diet == \"vegetarian\", \"ingredients\"]\nnon_veg_ingredients = main_data.loc[main_data.diet == \"non-vegetarian\", \"ingredients\"]\n\n# let's check size of both ingredients and verify the whether the ingredients of all dishes are stored or not\n# our total dishes are 255\nveg_ingredients.size + non_veg_ingredients.size","5c0b6ccf":"veg_ingredients.str.split(\",\")","c89901ba":"# let's count those ingredients for getting that how many dishes are used that particular ingrediets\n\n# let's remove unnecessary space\n\nveg_ingredients = veg_ingredients.str.strip()\nnon_veg_ingredients = non_veg_ingredients.str.strip()\n\nveg_cleaned_ingredients = []\nnon_veg_cleaned_ingredients = []\n\nfor i in veg_ingredients.str.split(\",\"): # split by \",\" & iterate through all the ingredients and append it to list\n    veg_cleaned_ingredients += i\n\nfor i in non_veg_ingredients.str.split(\",\"):#split by , & iterate through all the ingredients and append it to list\n    non_veg_cleaned_ingredients += i","f8fb5173":"# let's make a series of veg and non veg ingredients\n\nfinal_veg_ingredients = pd.Series(veg_cleaned_ingredients)\nfinal_non_veg_ingredients = pd.Series(non_veg_cleaned_ingredients)\n\n# let's remove extra spaces\nfinal_veg_ingredients = final_veg_ingredients.str.strip()\nfinal_non_veg_ingredients = final_non_veg_ingredients.str.strip()\n\n# let's count how many tim ingredients are repeated and make a data frame\nfinal_veg_ingredients = final_veg_ingredients.value_counts().reset_index()\nfinal_veg_ingredients.columns = [\"ingredients\", \"count\"]\n\nfinal_non_veg_ingredients = final_non_veg_ingredients.value_counts().reset_index()\nfinal_non_veg_ingredients.columns = [\"ingredients\", \"count\"]","0140d46f":"final_veg_ingredients","18461102":"final_non_veg_ingredients","8089752b":"# let's plot a top 20 vegetarian ingredients\n\nsns.barplot(data = final_veg_ingredients.head(20), x = \"count\", y = \"ingredients\")\nplt.title(\"Top 20 Ingredients for Vegetarian Dishes\")\nplt.show()","52a58605":"# let's plot top 20 no vegetarian ingredients\n\nsns.barplot(data = final_non_veg_ingredients.head(20), x = \"count\", y = \"ingredients\")\nplt.title(\"Top 20 Ingredients for Non-Vegetarian Dishes\")\nplt.show()","0387d19a":"# features i have to take all are categorical features so let's transform it into numeric using one hot encoding\n\ndata = main_data.copy()\ndata.head()","52e5559e":"# let's take top 20 veg and non-veg ingredients and merge it and make our final ingredient feature\n\ntop_veg_ingredients = final_veg_ingredients.head(20)\ntop_non_veg_ingredients = final_non_veg_ingredients.head(20)\n\n# here let's append both and make our final ingredients\n\nfinal_ingredients = top_veg_ingredients.append(top_non_veg_ingredients).reset_index(drop = True)\nfinal_ingredients.head()","ea02759f":"# here i took a ingredients separately from vegetarian and non vegetarian so that might be chance that it has some\n# duplicate ingredients so let's check it\n\nfinal_ingredients[final_ingredients.ingredients.duplicated(keep = False)]","bbcb8381":"# so here i can see that some of the ingredients are found as duplicated so let's merge it using group by\n\nfinal_ingredients = final_ingredients.groupby(\"ingredients\")[\"count\"].sum().reset_index()\n\n# let's sort it by count\n\nfinal_ingredients = final_ingredients.sort_values(\"count\", ascending = False).reset_index(drop = True)\nfinal_ingredients.head()","9d1f61aa":"# let's find out the total ingredients\n\nfinal_ingredients.ingredients.nunique()\n# so we have total 35 ingredients","fd912536":"# now let's do one hot encoding to ingredients\n# so here in our data set i have a comma separated ingredients so i use contain() of string to match\n# our final ingredients and if it is found then i put 1 other wise 0\n\n\nfor i in final_ingredients.ingredients:\n    data[i] = 0 # here i create a column of particular ingredients and assign all value as 0\n    data.loc[data.ingredients.str.contains(i), [i]] = 1\n    # above i put 1 on that column which dishes has include that particular ingredients","57dbe995":"data.head(2)","d8e43e87":"# let's encode veg and non veg using label encoding\n\n# here i drop first column which is non vegetarian for preventing dummy variable trap\ndiet_encoding = pd.get_dummies(main_data.diet, drop_first=True)\ndiet_encoding.head()","84afbeec":"# now let's concat it with our \"data\" data frame\n\ndata = pd.concat([data, diet_encoding], axis = 1)\ndata.head(2)","da75d7d3":"# let's encode flavor_profile using one hot encoding\n\n# here i drop a first column which is bitter for preventing dummy variable trap\nflavor_profile_encoding = pd.get_dummies(main_data.flavor_profile, drop_first=True)\nflavor_profile_encoding.head(2)","17cdbe02":"# now let's concat it with our main \"data\" data frame\n\ndata = pd.concat([data, flavor_profile_encoding], axis = 1)\ndata.head(2)","ace0585f":"# let's encode course using one hot encoding\n\n# here i drop first column which is dessert for preventing dummy variable trap\ncourse_encoding = pd.get_dummies(main_data.course, drop_first = True)\ncourse_encoding.head(2)","69567136":"# let's concat it with our main \"data\" data frame\n\ndata = pd.concat([data, course_encoding], axis = 1)\ndata.head(2)","04cd3b81":"# let's encode the state using one hot encoding\n\n# here i drop first column which is All State for preventing dummy variable trap\nstate_encoding = pd.get_dummies(main_data.state, drop_first = True)\nstate_encoding.head(2)","51944612":"# let's concat it with our main \"data\" data frame\n\ndata = pd.concat([data, state_encoding], axis = 1)\ndata.head(2)","c2972f6a":"# let's encode region using one hot encoding\n\n# here i drop first column which is All Region for preventing dummy variable trap\nregion_encoding = pd.get_dummies(main_data.region, drop_first = True)\nregion_encoding.head(2)","adb675e5":"# let's concat it with main \"data\" data frame\n\ndata = pd.concat([data, region_encoding], axis = 1)\ndata.head(2)","582c8593":"# let's create a final data frame\n# let's remove unnecessary columns which are not required not and store it as final_data\n\nfinal_data = data.drop(columns = ['ingredients', 'diet', 'prep_time', 'cook_time',\n       'flavor_profile', 'course', 'state', 'region'])\n\nfinal_data.head()","75a011f0":"# here i'm going to use Nearest Neighbors using cosine similarity so for model purpose let's take name column\n# as a index\n\nfinal_data.set_index(\"name\", inplace = True)\nfinal_data.head()","f1f0171a":"# here i'm going to use cosine similarity for recommend the cuisine\n# cosine similarity is nothing but a degree between two data points or two similar type of data\n\n# here i'm going to use Nearest Neighbors for implementing cosine distance\n# consine distance = 1 - consine similarity\n\n# here i use Nearest Neighbors with metric cosine and brute algorithm\n\nfrom sklearn.neighbors import NearestNeighbors\n\nmodel = NearestNeighbors(metric = \"cosine\", algorithm = \"brute\")\nmodel.fit(final_data)","846b67fa":"# now our model is ready so let's test it\n\npicked_cuisine = final_data.index[np.random.choice(final_data.shape[0])]\npicked_cuisine","76bc7d71":"# now let's find similarity or recommened cuisine using our model\n# our model return distance and index\n# distance is indicates that how far that similarity of that recommended cuisine with our picked cuisine\n# index indicates a index of our final data which is a name of cuisine\n\n# here i want 10 recommended cuisine for my picked cuisine\n\ndistance, cuisine_index = model.kneighbors(final_data[final_data.index == picked_cuisine], n_neighbors = 11)","8c99913b":"distance","f2d0141c":"cuisine_index","c25546eb":"# let's print it in proper way\n\n# these are 2D arrays so let's convert it into 1D\n\ndistance = distance.flatten()\ncuisine_index = cuisine_index.flatten()\n\n# probably first one is always our picked cuisine\n\nprint(\"Recommendation for \", picked_cuisine, \" are following\")\n\ncount = 1\nfor i in range(cuisine_index.size):\n    if final_data.index[cuisine_index[i]] == picked_cuisine:\n        continue\n    print(count, \". \", final_data.index[cuisine_index[i]], \" with distance \", distance[i])\n    count += 1","4e115042":"# let's export our main data for showing data on web app\nmain_data.to_csv(\"cleaned_data.csv\", index = False)\n\n# let's export our final_data, it will used on frontend for getting recommendation\nfinal_data.to_csv(\"model_data.csv\")","05df5285":"# let's export model using pickle file\n\nimport pickle\n\nwith open(\"model.pickle\", \"wb\") as f:\n    pickle.dump(model, f)","6835b24b":"#### observation: Diffierent states has a diffeirent cuisine but Gujarat has a highest cuisine","56aa319d":"#### observation: veg and non-veg dishes take a similar amount of time","217f633a":"### Model Builiding","58e3618e":"#### Diet","f913a090":"#### feature selection of state","734a06f4":"#### feature selection of diet","40d1d768":"### Exploratory Data Analysis","5f1981fd":"#### Region","7fad2b83":"#### flavor_profile","b3a5655a":"#### observation: Here different dishes are coming from different region of india but most of the dishes are coming from West and South side","87b9355c":"#### feature selection region","cf521769":"## <center> Indian Famous Cuisine Recommendation <\/center>\n![indian_famous_cuisine.png](attachment:cd2ea19c-650e-459f-a2c0-f94b82758b3a.png)\n\n\n- This project is about Indian Cuisine here i have 255 famous indian dishes. When user click on dish they will get a recipe and recommendation for that particular dish. Here i have used youtube videos for cuisine recipe and i have build a machine learning model using cosine similarity for recommendation\n\n- I have also created end to end project using flask here's the full source code link <br>https:\/\/github.com\/jaysoftic\/indian-famous-cuisine-recommendation\n- I have deployed this end to end project on AWS Elastic Beanstalk platform here's the live demo link <br>http:\/\/indianfamouscuisinerecommendation-env.eba-pcygs8dm.us-east-2.elasticbeanstalk.com\/\n\n\n- This notebook is about data analysis, feature engineering and model building","f70e12c6":"#### observation: Indian are usually like spicy and sweet food","85305165":"##### here i take all the features except prep_time and cook_time because there are some value missing in prep _time and cook_time features","5d356064":"#### feature selection of course","7a6358dd":"#### Ingredients","977ecc89":"### Feature Selection","3869b6ec":"#### state","c8ae2b72":"#### course","fb01b1e2":"#### observation: most of the ingredients are different in vegetarian and non-vegetarian dishes","6d5de968":"#### observation: Dishes of Main Course and Dessert are hudge","5783ad04":"### Feature Engineering","16010f3e":"#### undserstand the features of data set\n- here i will go through each columns","48647bdd":"#### observation\n##### so here we have 255 dishes and 9 columns associated with each of them which describe as follow\n- name: name of the dish\n- ingredients: ingredients which are used to make particular dish\n- diet: It indicates that whether the dish is veg or non- veg\n- prep_time: prepartion time\n- cook_time: cooking time\n- flavor_profile: flavor profile include that whether the dish is spicy or sweet etc\n- course: course is a course of meal, the course might be main course, snack or dessert etc\n- state: state where the dish is famous or born\n- region: region where the state belongs","b33aa1b6":"#### creating final data frame","556afdd4":"#### Understand the data set","0fcdff11":"#### feature selection of ingredients\n- Here I have a so many ingredients which are used in indian cuisine\n- I take only top 20 vegetarian ingredients and top 20 non-vegetarian ingredients as my features","2fccf8f1":"#### observation: here vegetarian dishes are more than non - vegetarian","0085353f":"#### prep time and cook time","c44f2c8b":"#### feature selection of flavor_profile"}}