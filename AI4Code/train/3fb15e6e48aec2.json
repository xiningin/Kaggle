{"cell_type":{"d836f181":"code","503cc3b5":"code","d2bcf877":"code","fc2c15df":"code","dd4c69c6":"code","547a3812":"code","00e53e28":"code","314500cb":"code","99312c88":"code","e2427a12":"code","2da74fbb":"code","4bfb039a":"code","55b5c28b":"code","f91f458f":"code","a9021109":"code","dd0a7c59":"code","6fc9aa51":"code","23158399":"code","4f61b0dc":"code","ccdcb44a":"code","b378ed6f":"code","930fd0cf":"code","36a806c4":"code","012fba58":"code","786c512a":"code","9732a1da":"code","952b4f8e":"code","01c835a0":"code","05ec4305":"code","4c7e9719":"code","350067dd":"code","573211c9":"code","b8bfb5fc":"code","d99707c1":"code","fc05c460":"code","42f8c4fe":"code","35b84758":"code","90daf6a4":"code","98378e70":"code","1b2b3988":"code","4c873156":"code","32e1b783":"code","8ffcbcf0":"code","cc7e45e5":"code","6bb00019":"code","b3a24491":"code","100b486e":"code","7de04f28":"code","91237245":"code","39cf3be5":"code","eacf9a2e":"code","dfcd8c6d":"code","67504d07":"code","e7846ca4":"code","67734506":"code","f0107dc9":"code","c6f955a4":"code","154301ea":"code","0e7d1eda":"code","469ac4f3":"code","e4cf4fdf":"code","edbf7270":"code","18c8368e":"code","c2112fa8":"code","0b6a1c69":"code","0967e4bf":"code","a8ce954b":"code","39bd659e":"code","8d2543d1":"code","d8b3ee9f":"code","762f6309":"code","d86c619c":"code","d71a2ff8":"code","9c4c82ed":"code","3510c185":"code","2c61fbf4":"code","32efaf94":"code","ad847460":"code","02b33f60":"code","61cbfbe5":"code","7331430d":"code","c9d8d9c7":"code","ceebc30f":"code","832cca6d":"code","056518c3":"code","6117336e":"code","502541fd":"markdown","31a107a8":"markdown","4ed640c3":"markdown","b8ce5276":"markdown","9db89792":"markdown","5a9aa6e7":"markdown","187669c1":"markdown","8032885e":"markdown","9bbd8411":"markdown","6e853ad6":"markdown","52252c09":"markdown","93de9fce":"markdown","b819bf52":"markdown","c3c1c255":"markdown","91feebc7":"markdown","e4a27280":"markdown","2f037905":"markdown","f977a436":"markdown","c138f0ab":"markdown","9cf70f23":"markdown","55985138":"markdown","8bb81cdb":"markdown","4237c420":"markdown","ce88a129":"markdown","e942d4c6":"markdown","7a4f2f43":"markdown","88bae3b3":"markdown","37c8bad0":"markdown"},"source":{"d836f181":"import pandas as pd \nimport numpy as np \nimport seaborn as sns\nimport matplotlib.pyplot as plt \nimport string\nimport re\n\nfrom IPython import display\n\n#Feature Engineering\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.impute import SimpleImputer\n\n#feature extraction \nfrom sklearn.feature_extraction.text import CountVectorizer\n\n#Feature Selection\nfrom sklearn.feature_selection import RFECV\n\n##Models\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor, RandomForestRegressor, VotingClassifier, VotingRegressor\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LinearRegression , Lasso, Ridge , LogisticRegression, RidgeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import  SVR, SVC\n\nfrom sklearn.metrics import r2_score, mean_squared_error,accuracy_score,f1_score , classification_report,confusion_matrix","503cc3b5":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d2bcf877":"test = pd.read_csv(\"..\/input\/titanic\/test.csv\", index_col=\"PassengerId\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\",index_col=\"PassengerId\")","fc2c15df":"train.head()","dd4c69c6":"test.shape","547a3812":"df = pd.concat([train,test],axis = 0)","00e53e28":"df.head()","314500cb":"df.describe()","99312c88":"df.info()","e2427a12":"plt.figure(figsize=(9,6))\nsns.heatmap(df.corr(), vmax= 1, vmin= -1, cmap=\"Spectral\",annot=True)","2da74fbb":"sns.pairplot(df, hue = \"Survived\", palette=\"Set1\")","4bfb039a":"sns.displot(data = df, x= \"Age\", hue = \"Sex\", col= \"Survived\")","55b5c28b":"# Get names in brackets and actual name \ndf[\"Name_purchaser\"] = df[\"Name\"].apply(lambda x : \"\".join(re.findall(r\"\\((.*?)\\)+\", x)))\ndf[\"Name_passenger\"] =  df[\"Name\"].apply(lambda x : x.split(\"(\")[0] )","f91f458f":"#get title\ndf[\"Title\"] = df[\"Name\"].apply( lambda x : x.split(\",\")[1].split(\".\")[0].strip())","a9021109":"#remove punctuation and title from Name\ndf[\"Name\"] = df[\"Name\"].apply(lambda s : ''.join(x for x in s if x not in string.punctuation))\ndf[\"Name\"] = df[[\"Name\",\"Title\"]].apply(lambda x : x[0].replace(\" \"+x[1],\"\"), axis =1)","dd0a7c59":"df.head()","6fc9aa51":"df[\"Title\"].value_counts()","23158399":"## merge similar titles  \nmap_dict = {\"Ms\":\"Miss\", \"Mme\":\"Mrs\", \"Sir\": \"Mr\", \"Jonkheer\":\"Mr\", \"Lady\":\"Mrs\", \"Don\":\"Mr\", \"Dona\":\"Mrs\",\"Mlle\":\"Miss\", \"Col\":\"Soldier\", \"Capt\":\"Soldier\",\"Major\":\"Soldier\"}\ndf[\"Title\"] = df[\"Title\"].apply(lambda x : map_dict[x] if x in map_dict else x)","4f61b0dc":"# Get length of name \ndf[\"Name_length\"] = df[\"Name\"].apply(len)\n#df[\"Name_pas_len\"] = df[\"Name_passenger\"].apply(len)\n#df[\"Name_pur_len\"] = df[\"Name_purchaser\"].apply(len)","ccdcb44a":"#Identify if the there is a purchaser of the ticket.\n#i.e a sponsor\ndf[\"purchaser\"] = df[\"Name_purchaser\"] = df[\"Name_purchaser\"].apply(lambda x: 1 if len(x)>0 else 0)","b378ed6f":"## Get surname\ndf[\"Surname\"] = df[\"Name_passenger\"].apply(lambda x : x.split(\",\")[0])","930fd0cf":"df.drop([\"Name\",\"Name_passenger\",\"Name_purchaser\"],axis =1,inplace=True)","36a806c4":"df.head()","012fba58":"## Fill empty cabins with unknown (\"U\")\ndf[\"Cabin\"] = df[\"Cabin\"].fillna(\"U\")","786c512a":"df[\"Cabin\"].value_counts().head()","9732a1da":"def get_cabin_letter(string):\n    try:\n        x= re.search(r\"\\D\",string).group()\n    except:\n        x= \"U\"\n    return x","952b4f8e":"## Get room number of cabin, I chose to get the max room number but could get min \ndef get_cabin_max_num(string):\n    try:\n        x= max(re.findall(r\"\\d+\",string))\n    except ValueError:\n        x= 0\n    return x","01c835a0":"df[\"Cabin_letter\"] = df[\"Cabin\"].apply(get_cabin_letter)\ndf[\"Cabin_max_num\"] = df[\"Cabin\"].apply(get_cabin_max_num).astype(int)","05ec4305":"## Dont need Cabin anymore \ndf.drop(\"Cabin\",axis =1, inplace = True)","4c7e9719":"# unsure if to make U = min or max \ncabin_map = {\"A\":0, \"B\":1, \"C\":2,\"D\":3, \"E\":4, \"F\":5,\"G\":6,\"T\":8, \"U\":8}\n\ndf[\"Cabin_letter\"] = df[\"Cabin_letter\"].map(cabin_map).astype(int)\n#only seems like one Cabin called = T, setting this to unknown\ndf[\"Cabin_letter\"].head()","350067dd":"df.corr()","573211c9":"df['FamilySize'] = df ['SibSp'] + df['Parch'] + 1","b8bfb5fc":"df['Lone'] = 1 \ndf.loc[df['FamilySize'] > 1,'Lone' ] = 0","d99707c1":"def split_ticket_start(string):\n    if \" \" in string:\n        list_s = string.split(\" \")\n        if len(list_s) >2:\n            x = \" \".join(list_s[:2])\n        else:\n            x = list_s[0]\n    else: \n        x = \"None\"\n    return x ","fc05c460":"df[\"Ticket_prefix\"] = df[\"Ticket\"].apply(split_ticket_start)\ndf[\"Ticket_num\"] = df[\"Ticket\"].apply(lambda x : \"\".join( re.findall(r\"[\\d]+$\", x)))\n\ntest[\"Ticket_prefix\"] = test[\"Ticket\"].apply(split_ticket_start)\ntest[\"Ticket_num\"] = test[\"Ticket\"].apply(lambda x : \"\".join( re.findall(r\"[\\d]+$\", x)))","42f8c4fe":"# replace empty values with \"\"\ndf[\"Ticket_num\"] = df[\"Ticket_num\"].apply(lambda x : \"0\" if x ==\"\" else x)\n\ntest[\"Ticket_num\"] = test[\"Ticket_num\"].apply(lambda x : \"0\" if x ==\"\" else x)","35b84758":"## Remove punctuation\ndf[\"Ticket_prefix\"] = df[\"Ticket_prefix\"].apply(lambda s : ''.join(x.strip() for x in s if x not in string.punctuation))","90daf6a4":"df[[\"Ticket\",\"Ticket_num\",\"Ticket_prefix\"]].head()","98378e70":"df.drop(\"Ticket\",axis =1 , inplace = True)","1b2b3988":"imputer_Fare = SimpleImputer()\ndf[\"Fare\"]= imputer_Fare.fit_transform(df[[\"Fare\"]])","4c873156":"imputer_Embarked = SimpleImputer(strategy=\"most_frequent\")\ndf[\"Embarked\"]= imputer_Embarked.fit_transform(df[[\"Embarked\"]])\n\ndf['Embarked'] = df['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)","32e1b783":"# Populate Age\ndf['Age'] = df['Age'].groupby([df['Pclass'], df['Sex']]).apply(lambda x: x.fillna(x.mean()))","8ffcbcf0":"df.isnull().sum()","cc7e45e5":"df.info()","6bb00019":"df.head()","b3a24491":"## columns to encode excluding Sex column (see below)\n\ncat_columns = [\"Title\",\"Ticket_prefix\"]","100b486e":"# Sex column is quick to encode ,we can do this with map\n\ndf[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\":1})\n\ndummies = pd.get_dummies(df[cat_columns],drop_first=True)\ndummies.head()","7de04f28":"dummies.shape","91237245":"df = pd.concat([df, dummies],axis = 1)\ndf.drop(cat_columns, axis = 1, inplace=True)","39cf3be5":"df.head()","eacf9a2e":"df = df.reset_index(drop = True)\n\ncount_i = CountVectorizer()\nname_v = count_i.fit_transform(df[\"Surname\"])\nname_vector_df = pd.DataFrame(data = name_v.todense(), columns = count_i.get_feature_names())\ndf = pd.concat([df,name_vector_df], axis =1 )","dfcd8c6d":"df.drop([\"Surname\"],axis = 1, inplace=True)","67504d07":"df.head()","e7846ca4":"df[\"Age_bin\"] = pd.cut(df[\"Age\"], bins = [-1, 10, 20, 40, 50,60,70,80], labels=[0, 1, 2, 3,4,5,6]).astype(int)","67734506":"df[\"Age_bin\"].value_counts(dropna=False)","f0107dc9":"df.head()","c6f955a4":"scaler_all = StandardScaler()\nscaler_all.fit_transform(df)","154301ea":"#not including Age as we will run linear regression on this column\nscalable_columns = [\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked\",\"Name_length\",\"Cabin_letter\",\"Cabin_max_num\",\"Ticket_num\"]","0e7d1eda":"scaled_df = pd.DataFrame( data = scaler_all.fit_transform(df[scalable_columns]) , columns=scalable_columns)\n\n# are applying leakage here but its not too bad as we wanted to retrain on a full data set","469ac4f3":"scaled_df.head()","e4cf4fdf":"df = df.drop(scalable_columns, axis = 1)\ndf = df.reset_index(drop = True)\ndf = pd.concat([df,scaled_df], axis =1)\ndf.head()","edbf7270":"df.info()","18c8368e":"imputer_age = SimpleImputer(strategy=\"mean\")","c2112fa8":"quick_df = df.copy()\nquick_df= quick_df[~quick_df[\"Survived\"].isnull()]","0b6a1c69":"X = quick_df.drop([\"Survived\"],axis =1)\ny = quick_df[\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X,y , test_size=0.33, random_state=42,)","0967e4bf":"rf = RandomForestClassifier(n_estimators=len(X_train.columns))\nlogr_q = LogisticRegression(solver='liblinear')","a8ce954b":"def score_model_class(model):\n    model.fit(X_train,y_train)\n    y_pred = model.predict(X_test)\n    \n    print(\"accuracy_score test: \",accuracy_score(y_test,y_pred))\n    print(\"f1_score test: \",f1_score(y_test,y_pred))\n    \n    print(confusion_matrix(y_test,y_pred))\n    print(classification_report(y_test,y_pred))","39bd659e":"score_model_class(rf)\nscore_model_class(logr_q)","8d2543d1":"rf = RandomForestClassifier()\nlogr = LogisticRegression()\nxgb = XGBClassifier(eval_metric='mlogloss')\ndtree= DecisionTreeClassifier(random_state = 0)\n\nknn = KNeighborsClassifier()\nsvc = SVC(probability=True)\nridge_c = RidgeClassifier()","d8b3ee9f":"from sklearn.model_selection import StratifiedKFold\nkfold =StratifiedKFold(n_splits=5,shuffle=True,random_state=42)","762f6309":"X = df[~df[\"Survived\"].isnull()].drop([\"Survived\"],axis =1)\ny = df[~df[\"Survived\"].isnull()][\"Survived\"]\nX_train, X_test, y_train, y_test = train_test_split(X,y , test_size=0.3, random_state=42, stratify=y)","d86c619c":"sns.countplot(y_train)","d71a2ff8":"def score_model_class(model, params ,scoring = \"f1_macro\"):\n    \n    model = GridSearchCV(model, param_grid= params, scoring =scoring, cv= kfold)\n    \n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    \n    print (\"Model and params: \", model.best_estimator_, model.best_params_) \n    print(\"\\n\")\n    print(\"Train f1 score: \", model.best_score_)\n    print(\"test f1_score: \",f1_score(y_test,y_pred))\n    print(\"\\n\")\n    print(\"Test Report:\")\n    print(classification_report(y_test,y_pred))\n    return model","9c4c82ed":"ridge_params = {\"max_iter\": [120, 200,300], \"alpha\":[0.1,0.8, 1,1.5, 2,3]}\nlogr_params = {\"solver\":[\"liblinear\",\"saga\", \"lbfgs\", \"newton-cg\"],\n    \"penalty\": [\"l2\",\"l1\", \"elasticnet\", \"none\"],\n    \"C\": [0.01,0.5,1,3,4],\n    \"max_iter\": [4000]\n}\nxgb_params={'learning_rate': [0.05,0.01,0.1, 1], \n           # \"subsample\": [0.5, 0.7, 1.0],\n            'max_depth': [2, 3, 5, 7],\n            #\"gamma\" : [3,4,5,6] ,             \n            'n_estimators': [150, 200, 300, 500]\n           }\nforest_params = {     \n    \"max_depth\" : [10,20,30,40],       \n    \"n_estimators\" : [300,350,400,410,420,440],\n    \"max_features\" :[\"auto\", \"log2\", None]\n}\ntree_params = { \"max_depth\" : [8,10,20,30],       \n    \"max_features\" :[\"auto\", \"log2\", None]}\n\nknn_params = {\"n_neighbors\" : [2,3,5] , \"metric\" :[\"euclidean\", \"manhattan\", \"minkowski\"], \"weights\" :[\"uniform\", \"distance\"]}\nsvc_params = {\"kernel\" : [\"linear\", \"poly\", \"rbf\", \"sigmoid\"], \"C\" : [ 0.001, 0.1, 1, 2, 3], \"gamma\":[\"scale\", \"auto\"]}","3510c185":"ridge_m = score_model_class (ridge_c, {'alpha': [1.2, 1.5, 2], 'max_iter': [2]}\n                            )","2c61fbf4":"logr_m = score_model_class(logr, {'C': [3], 'max_iter': [5000], 'penalty': ['l2'], 'solver': ['liblinear']})","32efaf94":"rf_m =random_forest = score_model_class(rf,{'max_depth': [40], 'max_features': ['sqrt'], 'n_estimators': [500]})","ad847460":"dtree_m = score_model_class(dtree,{'max_depth': [50], 'max_features': [60]})","02b33f60":"xgb_m = score_model_class(xgb, {'learning_rate': [0.01], 'max_depth': [3,5,8], 'n_estimators': [200]} )","61cbfbe5":"knn_m = score_model_class ( knn, {'n_neighbors': [5,6,7], 'weights': [\"uniform\", \"distance\"]})","7331430d":"svc_m = score_model_class (svc, {'C': [0.8], 'kernel': ['linear']})","c9d8d9c7":"vc = VotingClassifier([(\"knn_m\",knn_m), \n                       (\"svc_m\",svc_m), (\"xgb_m\",xgb_m), \n                       (\"ridge_m\",ridge_m),\n                       (\"dtree_m\",dtree_m),\n                       (\"logr_m\",logr_m),\n                       (\"rf_m\",rf_m)],\n                      voting = \"hard\")\n\nvc.fit(X_train,y_train)","ceebc30f":"print(\"training: \", vc.score(X_train,y_train))\nprint(classification_report(y_test,vc.predict(X_test)))","832cca6d":"X_sub = df[df[\"Survived\"].isnull()].drop([\"Survived\",],axis =1)","056518c3":"y_sub = vc.predict(X_sub)\nsub = pd.DataFrame({'PassengerId': test.index, 'Survived': y_sub})\nsub[\"Survived\"] = sub[\"Survived\"].astype(int)","6117336e":"sub.to_csv(\"submission.csv\",index=False)","502541fd":"# Age Binning","31a107a8":"# Feature Engineering \/ Feature Extraction\n* There is a lot that can be done here, I just went through a few off the top of my head:\n* 1.Name - length\n* 2.Name - Title of person (Mr, Miss etc)\n* 3.Name - seperate name in brackets with actual name\n* 4.Ticket - split number and inital text\/number\n* 5.Family size\n* 6.binning\n### Other potential options:\n* Name - CountVectorizer\n* Name - Topic modelling* \n* Name - Jaccard distance\n\n### Name \/ Title\n* Get Title of person\n* merge similar titles\n* Get Surname\n* Get length of name\n* Get Sponsor (purchaser of ticket ) 0\/1","4ed640c3":"## Family Size and lone traveller","b8ce5276":"# Additional option:\n* bin ages by specific groups (i.e. child = age <16)","9db89792":"# Full Survival prediction","5a9aa6e7":"# Standard Scaler","187669c1":"# Embarked-Mode","8032885e":"# Importing Modules","9bbd8411":"# CountVectorizer - Name\n* run on Surname and create a dense matrix and concat to df","6e853ad6":"# Merge similar Titles:\n* Mapping Title with low frequency back to its majority counterpart another option would be to: take all the title with one instance and map them back to a similar majority title","52252c09":"# Option: Can analyse the Ticket column futher\n* cleanup potential spelling issues\n* Seperate Ticket prefix futher on forward slash","93de9fce":"# Trying Oversampling\n* removed as this didnt improve the score","b819bf52":"* Age - mean by Pclass, Sex","c3c1c255":"# Voting Classification","91feebc7":"# Ticket\n* cleanup ticket (miss-spellings etc)\n* get start and end of ticket","e4a27280":"# Submission","2f037905":"# Loading Data","f977a436":"# EDA\n* Merge data to process (seperate before fitting) df's last passengerId = 891","c138f0ab":"# Creating DataFrame","9cf70f23":"## Fare Median","55985138":"# Fix null values\n* comments\n* ignore Survived null values as they are null in test\n* Age - previously used Regression. Now imputed with mean grouped by Plcass & Sex\n* Fare - only 1 missing - use mean\n* Embarked - only 2 missing , use mode\n* Cabin - is a tricky, we can do a classification model to identify but for simplicity lets replace null values with \"None\"\n\n### Cabin","8bb81cdb":"# Create Dummies","4237c420":"# Models","ce88a129":"# Cabin\n* Suspected that your cabin letter or the cabin number will be at a certain location on the ship therefore you could be closer to the boats\n* A quick look on wikipedia shows this is true","e942d4c6":"# Quick Survival prediction\n* We can use this as a baseline","7a4f2f43":"* Option: to do some further analysis on Name_passenger & Name_purchaser\n* However we will use countvectorizer later so some of this info will be in the sparse matrix output of \"Surname\"","88bae3b3":"* Cound do more with the Ticket but lets such as split the prefix on the forward slash as well as cleanup some spelling or punctuation differences \\ But to save time lets remove the punctuation and use this instead","37c8bad0":"* Looks like there are some groupings 0-10, 10-25, 25-35\n* Lets try group with 10 year intervals"}}