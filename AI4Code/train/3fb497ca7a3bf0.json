{"cell_type":{"5c75bcd4":"code","250ce75d":"code","5dd79025":"code","395b63ea":"code","d29f6ec8":"code","be9dc6f8":"markdown"},"source":{"5c75bcd4":"import torch.nn\nimport os\nimport torch\nimport numpy as np\nimport pandas as pd\nimport csv\nimport glob\nimport sys\nimport math\nimport torch  \nimport torch.nn as nn\nimport time\nclass UNet_down_block(torch.nn.Module):\n    def __init__(self, input_channel, output_channel, down_size):\n        super(UNet_down_block, self).__init__()\n        self.conv1 = torch.nn.Conv2d(input_channel, output_channel, 3, padding=1)\n        self.bn1 = torch.nn.BatchNorm2d(output_channel)\n        self.conv2 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n        self.bn2 = torch.nn.BatchNorm2d(output_channel)\n        self.conv3 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n        self.bn3 = torch.nn.BatchNorm2d(output_channel)\n        self.max_pool = torch.nn.MaxPool2d(2, 2)\n        self.relu = torch.nn.ReLU()\n        self.down_size = down_size\n        self.elu = torch.nn.ELU()\n\n\n    def forward(self, x):\n        if self.down_size:\n            x = self.max_pool(x)\n        x = self.elu(self.bn1(self.conv1(x)))\n        x = self.elu(self.bn2(self.conv2(x)))\n        #x = self.relu(self.bn3(self.conv3(x)))\n        return x\n\nclass UNet_up_block(torch.nn.Module):\n    def __init__(self, prev_channel, input_channel, output_channel):\n        super(UNet_up_block, self).__init__()\n        #self.up_sampling = torch.nn.Upsample(scale_factor=2, mode='bilinear',align_corners=False)\n        self.up_sampling = torch.nn.ConvTranspose2d(input_channel,input_channel, 2,stride = 2)\n        self.conv1 = torch.nn.Conv2d(prev_channel + input_channel, output_channel, 3, padding=1)\n        self.bn1 = torch.nn.BatchNorm2d(output_channel)\n        self.conv2 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n        self.bn2 = torch.nn.BatchNorm2d(output_channel)\n        self.conv3 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n        self.bn3 = torch.nn.BatchNorm2d(output_channel)\n        self.relu = torch.nn.ReLU()\n        self.elu = torch.nn.ELU()\n\n    def forward(self, prev_feature_map, x):\n        x = self.up_sampling(x)\n        x = torch.cat((x, prev_feature_map), dim=1)\n        x = self.elu(self.bn1(self.conv1(x)))\n        x = self.elu(self.bn2(self.conv2(x)))\n        #x = self.relu(self.bn3(self.conv3(x)))\n        return x\n\n\nclass UNet(torch.nn.Module):\n    def __init__(self):\n        super(UNet, self).__init__()\n\n        self.down_block1 = UNet_down_block(1, 8, False)\n        self.down_block2 = UNet_down_block(8, 16, True)\n        self.down_block3 = UNet_down_block(16, 32, True)\n        self.down_block4 = UNet_down_block(32, 64, True)\n        self.down_block5 = UNet_down_block(64, 128, True)\n\n        self.mid_conv1 = torch.nn.Conv2d(128, 128, 3, padding=1)\n        self.bn1 = torch.nn.BatchNorm2d(128)\n        self.mid_conv2 = torch.nn.Conv2d(128, 128, 3, padding=1)\n        self.bn2 = torch.nn.BatchNorm2d(128)\n        self.mid_conv3 = torch.nn.Conv2d(128, 128, 3, padding=1)\n        self.bn3 = torch.nn.BatchNorm2d(128)\n\n        self.up_block1 = UNet_up_block(64, 128, 64)\n        self.up_block2 = UNet_up_block(32, 64, 32)\n        self.up_block3 = UNet_up_block(16, 32, 16)\n        self.up_block4 = UNet_up_block(8, 16, 8)\n\n\n        self.last_conv1 = torch.nn.Conv2d(8, 8, 3, padding=1)\n        self.last_bn = torch.nn.BatchNorm2d(8)\n        self.last_conv2 = torch.nn.Conv2d(8, 4, 1, padding=0)\n        self.relu = torch.nn.ReLU()\n        self.sigmoid = torch.nn.Sigmoid()\n        self.elu = torch.nn.ELU()\n\n    def forward(self, x):\n        self.x1 = self.down_block1(x)\n        self.x2 = self.down_block2(self.x1)\n        self.x3 = self.down_block3(self.x2)\n        self.x4 = self.down_block4(self.x3)\n        self.x5 = self.down_block5(self.x4)\n        self.x5 = self.elu(self.bn1(self.mid_conv1(self.x5)))\n        self.x5 = self.elu(self.bn2(self.mid_conv2(self.x5)))\n        #self.x5 = self.relu(self.bn3(self.mid_conv3(self.x5)))\n        x = self.up_block1(self.x4, self.x5)\n        x = self.up_block2(self.x3, x)\n        x = self.up_block3(self.x2, x)\n        x = self.up_block4(self.x1, x)\n        x = self.elu(self.last_bn(self.last_conv1(x)))\n        x = self.last_conv2(x)\n        return x","250ce75d":"class SteelDataset(torch.utils.data.Dataset):\n\n\tdef __init__(self,folder, pathlist, labeled , Y_dict = None ,transform = None):\n\n\t\tself.labeled = labeled\n\t\tself.X_path = pathlist\n\t\tself.folder = folder\n\t\tif self.labeled:\n\t\t\tself.Y_dict = Y_dict\n\t\t#self.X_test_path = get_data_path(test_folder)\n\n\tdef __len__(self):\n\t\treturn len(self.X_path)\n\n\tdef __getitem__(self, idx):\n\t\tpath = self.X_path[idx]\n\t\ttry:\n\t\t\tX = get_img(self.folder + '\/' + path)\n\t\t\timg = torch.FloatTensor(X).view(1,256,1600)\n\t\texcept:\n\t\t\tprint(self.X_path)\n\t\t\tprint(idx)\n\t\t\tprint(self.X_path[idx])\n\t\t\tprint(path)\n\n\n\t\tif self.labeled:\n\t\t\tlabels = (np.zeros([4,256,1600]))\n\t\t\tif path in self.Y_dict:\n\t\t\t\tfor classID in range(4):\n\t\t\t\t\tlabels[classID,:,:] = (run_length_decode((self.Y_dict[path])[classID]))\n\t\t\tlabel = torch.FloatTensor(labels).view(4,256,1600)\n\t\t\treturn tuple([img , label])\n\t\telse:\n\t\t\treturn tuple([img , path])\n","5dd79025":"sigmoid = nn.Sigmoid()\ndef add_weight_decay(net, l2_value, skip_list=()):\n\tdecay, no_decay = [], []\n\tfor name, param in net.named_parameters():\n\t\tif not param.requires_grad: continue # frozen weights\t\t            \n\t\tif len(param.shape) == 1 or name.endswith(\".bias\") or name in skip_list: no_decay.append(param)\n\t\telse: decay.append(param)\n\treturn [{'params': no_decay, 'weight_decay': 0.}, {'params': decay, 'weight_decay': l2_value}]\n\ndef dice_channel_torch(probability, truth, threshold):\n\tbatch_size = truth.shape[0]\n\tchannel_num = truth.shape[1]\n\tmean_dice_channel = 0.\n\twith torch.no_grad():\n\t\tfor i in range(batch_size):\n\t\t\tfor j in range(channel_num):\n\t\t\t\tchannel_dice = dice_single_channel(probability[i, j,:,:], truth[i, j, :, :], threshold)\n\t\t\t\tmean_dice_channel += channel_dice\/(batch_size * channel_num)\n\treturn mean_dice_channel\n\n\ndef dice_single_channel(probability, truth, threshold, eps = 1E-9):\n\tp = (probability.view(-1) > threshold).float()\n\tt = (truth.view(-1) > 0.5).float()\n\tdice = (2.0 * (p * t).sum() + eps)\/ (p.sum() + t.sum() + eps)\n\treturn dice\n\ndef run_length_decode(rle, height=256, width=1600, fill_value=1):\n\tmask = np.zeros((height,width), np.float32)\n\tif rle != '':\n\t\tmask=mask.reshape(-1)\n\t\tr = [int(r) for r in rle.split(' ')]\n\t\tr = np.array(r).reshape(-1, 2)\n\t\tfor start,length in r:\n\t\t\tstart = start-1  #???? 0 or 1 index ???\n\t\t\tmask[start:(start + length)] = fill_value\n\t\tmask=mask.reshape(width, height).T\n\treturn mask\n\ndef run_length_encode(mask):\n#possible bug for here\n\tm = mask.T.flatten()\n\tif m.sum()==0:\n\t\trle=''\n\telse:\n\t\tm   = np.concatenate([[0], m, [0]])\n\t\trun = np.where(m[1:] != m[:-1])[0] + 1\n\t\trun[1::2] -= run[::2]\n\t\trle = ' '.join(str(r) for r in run)\n\treturn rle\n\n\ndef dice_loss( y_pred,y_true):\n\tweight = [5,2,5,5]\n\tsmooth = 1e-9\n\ty_pred = sigmoid(y_pred)\n\ty_true_f = y_true.view(-1,4,256,1600)\n\ty_pred_f = y_pred.view(-1,4,256,1600)\n\tscore = 0\n\tbatch_size = y_true_f.shape[0]\n\tchannel_num = y_true_f.shape[1]\n\tfor i in range(batch_size):\n\t\tfor j in range(channel_num):\n\t\t\tintersection = y_true_f[i,j,:,:] * y_pred_f[i,j,:,:] \n\t\t\tscore += weight[j] * ( (2. * intersection.sum() + smooth) \/ (y_true_f[i,j,:,:].sum() + y_pred_f[i,j,:,:].sum() + smooth) ) \n\tscore \/= (batch_size )\n\treturn - score\n\ndef bce_dice_loss( y_pred,y_true):\n\treturn weighted_bceloss(y_pred,y_true) + dice_loss(y_pred,y_true)\n\ndef weighted_bceloss(y_pred,y_true):\n\tweight = [5,2,5,5]\n\tloss = 0\n    \n\tfor c in range(4):\n\t\tloss += bceloss(y_pred[:,c,:,:] ,y_true[:,c,:,:]) * weight[c] \n\treturn loss ","395b63ea":"\n#import pyvips\nfrom PIL import Image\n#from utils import *\n#from Unet.py import *\ndef get_data_path(folder):\n\tX_path = []\n\t#print(os.listdir(folder))\n\tfor filename in (os.listdir(folder)):\n\t\t#print(filename)\n\t\tX_path.append(filename)\n\n\tX_path = np.array(X_path)\n\treturn X_path\n\ndef get_label(path):\n\tdf = pd.read_csv(path)\n\tYdict = {}\n\tfor image_id in df.ImageId.unique():\n\t\trle = [\n\t\t\tdf.loc[ (df['ImageId']==image_id) & (df['ClassId'] == 1) , 'EncodedPixels'].values,\n\t\t\tdf.loc[ (df['ImageId']==image_id) & (df['ClassId'] == 2) , 'EncodedPixels'].values,\n\t\t\tdf.loc[ (df['ImageId']==image_id) & (df['ClassId'] == 3) , 'EncodedPixels'].values,\n\t\t\tdf.loc[ (df['ImageId']==image_id) & (df['ClassId'] == 4) , 'EncodedPixels'].values\n\t\t]\n\t\tfor classID in range(4):\n\t\t\tif len(rle[classID]) == 0:\n\t\t\t\trle[classID] = ''\n\t\t\telse:\n\t\t\t\trle[classID] = rle[classID][0]\n\n\t\t#print(y[0])\n\t\t#print(y[1])\n\t\t#print(y[2])\n\t\tYdict[image_id ] =  rle\n\tdel df\n\treturn Ydict \n\n\ndef get_img(path):\n\twith Image.open(path) as f:\n\t\timg = np.array(list(f.getdata()))\n\tf.close()\n\t#print('img shape',len(img),img[:,1])\n\treturn img[:,1].reshape(256,1600)\n\n\ndef valid_test(epoch):\n\tmodel.eval()\n\tbatch_size = 10\n\tTotaldice = 0\n\tTotalloss = 0\n\tfor i , (batch_x,batch_y) in enumerate(validloader):\n\t\tbatch_x = batch_x.cuda() \n\t\tbatch_y = batch_y.cuda()\n\t\tpV =  model(batch_x)\n\t\t#loss = weighted_bceloss(pV,batch_y).item()\n\t\tloss = bce_dice_loss(pV,batch_y).item() \n\t\tdice = dice_channel_torch( sigmoid(pV) , batch_y , 0.5)\n\t\tTotalloss += loss * len(batch_x)\n\t\tTotaldice += dice * len(batch_x)\n\tmeandice = Totaldice \/ V\n\tmeanloss = Totalloss \/ V\n\t#print(pV)\n\tprint('epoch:{}   Valid: dice {:.3f} loss: {:.3f}'.format(epoch, meandice,meanloss )) #time.time()-start_time  \n\tmodel.train()\n\treturn meanloss","d29f6ec8":"def Train(model):\n\tepochs = 1\n\tbest = 100\n\tdecay = 1e-4\n\tLR = 0.001\n\t#optim = torch.optim.Adam( add_weight_decay(model,decay) , lr= LR)\n\toptim = torch.optim.Adam( model.parameters(), lr= LR)\n\tprint('train-------------lr:',LR ,'decay:',decay )\n\tmodel.cuda()\n\tfor epoch in range(int(epochs)):\n\t\tmodel.train()\n\t\tfor i , (batch_x , batch_y )in enumerate(trainloader):\n\n\t\t\tbatch_x = batch_x.cuda()\n\t\t\tbatch_y = batch_y.cuda()\n\t\t\t\n\t\t\toptim.zero_grad()\n\t\t\ty_hat = model(batch_x)\n\t\t\tloss = bce_dice_loss(y_hat,batch_y)\n\t\t\tloss.backward()\n\t\t\toptim.step()\n\n\t\t\tif i % 100 == 99:\n\t\t\t\tloss = valid_test(epoch)\n\t\t\t\tif loss < best:\n\t\t\t\t\tbest = loss\n\t\t\t\t\tprint(\"saving model with loss: {:.3f}\".format(loss))\n\t\t\t\t\ttorch.save(model, 'model2.pth')\n\nif __name__ == '__main__':\n\t#load = 0\n\tisGPU = torch.cuda.is_available()\n\tprint ('PyTorch GPU device is available: {}'.format(isGPU))\n\ttrain_folder = \"..\/input\/severstal-steel-defect-detection\/train_images\"\n\tlabel_path = \"..\/input\/severstal-steel-defect-detection\/train.csv\"\n\t\n\t#train_folder , test_folder, label_path = sys.argv[1:]\n\t\n\tX_train_path = get_data_path(train_folder)\n\tY_train_dict = get_label(label_path)\n\t\n        \n\t#print(X_train_path)\n\t#print(Y_train_dict)\n    \n\tV = 100\n\tX_valid_path = X_train_path[:V]\n\tX_train_path = X_train_path[V:]\n\n\ttrainDataset = SteelDataset(train_folder,X_train_path,labeled=1,Y_dict = Y_train_dict)\n\tvalidDataset = SteelDataset(train_folder,X_valid_path,labeled=1,Y_dict = Y_train_dict)\n\n\ttrainloader = torch.utils.data.DataLoader(trainDataset , batch_size = 4, shuffle=True,num_workers=4)\n\tvalidloader = torch.utils.data.DataLoader(validDataset , batch_size = 4, shuffle=False,num_workers=4)\n\n\t#model = UNet()\n\tbceloss = nn.BCEWithLogitsLoss()\n\tsigmoid = nn.Sigmoid()\n\tmodel = torch.load(\"..\/input\/model\/model2.pth\")\n\tTrain(model)\n\t#Test(model)\n","be9dc6f8":"def Test(model):\n\tmodel.eval()\n\ttest_folder = \"..\/input\/severstal-steel-defect-detection\/test_images\"\n\tX_test_path = get_data_path(test_folder)\n\tX_test_path.sort()\n\t#print(\"X_test size:{}\".format(len(X_test_path)))\n\t#print(X_test_path)\n\ttestDataset = SteelDataset(test_folder,X_test_path,labeled=0)\n\ttestloader = torch.utils.data.DataLoader(testDataset , batch_size = 4, shuffle=False,num_workers=4)\n\toutpath = 'submission.csv'\n\tf=open(outpath,\"w\")\n\tf.write(\"ImageId_ClassId,EncodedPixels\\n\")\n\tfor i , (img,path) in enumerate(testloader):\n\t\tpredlist = sigmoid(model(img.cuda()))\n\t\tfor n in range(len(predlist)):\n\t\t\tpred = predlist[n]\n\t\t\tfor ClassId in range(0,4):\n\t\t\t\tp = (pred[ClassId].view(-1) > 0.5).float()\n\t\t\t\tencoded_value = run_length_encode(p.cpu())\n\t\t\t\t#if len(encoded_value) > 0:\n\t\t\t\tf.write(\"{}_{},{}\\n\".format(path[n],ClassId + 1,encoded_value ))\n\tf.close()\n\tmodel.train()\n\nif __name__ == '__main__':\n    #test_folder = \"..\/input\/severstal-steel-defect-detection\/test_images\"\n    #X_test_path = get_data_path(test_folder)\n    #testDataset = SteelDataset(test_folder,X_test_path,labeled=0)\n    #testloader = torch.utils.data.DataLoader(testDataset , batch_size = 4, shuffle=False,num_workers=4)\n\n    model = torch.load(\"..\/input\/model\/model2.pth\")\n    Test(model)"}}