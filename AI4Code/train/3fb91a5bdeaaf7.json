{"cell_type":{"808e6e12":"code","eeca4206":"code","193d1f01":"code","f8a31378":"code","a0eeefa0":"code","8ecc4ac0":"code","35a96343":"code","4cc0c9a7":"code","4566cebd":"code","87ce7519":"markdown","4889e1f9":"markdown"},"source":{"808e6e12":"#importing libraries:\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix","eeca4206":"# First step loading dataset in dataframe:\ndf=pd.read_csv(\"..\/input\/heart.csv\",encoding = \"utf-8\")\ndf.head()","193d1f01":"# Second step check dataset information:\ndf.info()","f8a31378":"df.describe()","a0eeefa0":"# to check whether dataset column has any null values\n# graph method is quick method to check \n# null values will be shown in yellow if any exists, so with the help this we can quickly check the null values\n\nsns.heatmap(df.isnull(),yticklabels=False,cmap=\"viridis\")\n\n#below graph shows there is no null in the dataset","8ecc4ac0":"#third step feature selection, although there are three methods for selecting fetaures, \n# here i am demostrating simple method using correlation in the dataframe.\n# to visualize the correlation, heatmap of sns library is used and three colors are specified Red,Yellow and green\n# for better visualisation.\n\nplt.figure(figsize=(20,20))\n\nsns.heatmap(df.corr(),annot=True,cmap=\"RdYlGn\")\n\n# in below graph we observed that with target the lowest correlation is of column chol and fbs\n# chol means cholestrol\n# fbs means fasting blood sugar\n# so in heart disease chol has significance where as fbs does not have any role hence we can exclude the column fbs \n# from features and train the model excluding this column","35a96343":"#checking distribution of the target values\nsns.distplot(df['target'])","4cc0c9a7":"# Step fourth training dataset with excluding features \"fbs\" and checking accuracy\n\nlgC=LogisticRegression()\n\n#droping feature fbs\ndf_features=df.drop(\"target\",axis=1)\ndf_features=df_features.drop(\"fbs\",axis=1)\ndf_label=df['target']\n#training set and test set\nX_train_new, X_test_new, y_train_new, y_test_new = train_test_split(df_features, df_label, test_size=0.2, random_state=42)\n\n# training the model\nlgC.fit(X_train_new,y_train_new)\n\n# making predictions\npredictions_new=lgC.predict(X_test_new)\n\n\nprint(\"Accuracy of the model excluding fbs column {:.2f}%\".format(lgC.score(X_test_new,y_test_new)*100))\n","4566cebd":"# looking for confussion matrix,false positive and false negative \ncnf=confusion_matrix(y_test_new,predictions_new)\nsns.heatmap(cnf,annot=True)\n","87ce7519":"For logistic regression on heart disease:\n<br><br> First step is to load dataset as utf-8:\n<br><br> Second step is to check the information of dataset such as columns and distribution of data in the dataset\n<br><br> Third step which is very important step to select features, feature plays very important step. If properly features are not selected then model performance is affected.\n<br><br>  Fourth step to train the model with dataset\n<br><br>  Fifth step predict values and generate accuracy and confusion metrics.\n","4889e1f9":"Conclusion:\nAccuracy of the model can be improved based on the feature selection.\n\n\nIf you find this helpful then vote and share your thoughts on it."}}