{"cell_type":{"66d32700":"code","fcb6bfd5":"code","69712e39":"code","460667c6":"code","8ffbf364":"code","d3d1bb5b":"code","019fb305":"code","30cd012c":"code","8bc1467b":"code","9c4b7d8b":"code","c5da09b5":"code","69f7a7f4":"code","b43a34c9":"code","f59409ba":"code","eaced0dc":"code","9fec76cd":"code","983fb22a":"code","fd445490":"code","65101144":"code","061dbd04":"code","9ed28593":"code","62a53f5d":"code","8f4b0d5d":"code","3eb997dc":"code","43d38813":"code","041b3b26":"code","1a9b4110":"code","8f3eb7cb":"code","6ffbb5af":"code","4c632676":"code","b95ff7ba":"code","8d890b62":"code","dc45bfa9":"code","dffd0cbf":"code","88dced4c":"code","405907bb":"code","087a2a22":"code","f0165a29":"code","7536648c":"code","6f4f636c":"code","6a59f5e0":"code","296879be":"code","42c3b212":"markdown","6361add9":"markdown","114d49cd":"markdown","36072ae5":"markdown","321cbc8f":"markdown","5d736124":"markdown","80a290b0":"markdown","061ce48f":"markdown","5340591a":"markdown","ab1c7fca":"markdown","c2fe43e4":"markdown"},"source":{"66d32700":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fcb6bfd5":"df = pd.read_csv(\"\/kaggle\/input\/weather-dataset-rattle-package\/weatherAUS.csv\", parse_dates = ['Date'])\nprint(df.shape)\ndf.head()","69712e39":"df.describe(include = 'all').T","460667c6":"df.info()","8ffbf364":"#amount empty data\ncol_empty = df.apply(lambda x: f'{(x.isnull().sum()\/df.shape[0]).round(2)} %').sort_values()\ncol_empty","d3d1bb5b":"# drop columns with empty data > 10%\ndf.drop(col_empty.index.to_list()[-4:], axis = 1, inplace = True)","019fb305":"#check columns\ndf.columns.to_list()","30cd012c":"df.iloc[0,:]","8bc1467b":"# add new columns \ndef get_season(n):\n    if n in  [12,1,2]: return 1\n    elif n in [3,4,5]:  return 2\n    elif n in [6,7,8]:  return 3\n    else: return 4\n    \n\ndf['month'] = df['Date'].dt.month\ndf['Season'] = df['month'].apply(lambda x: get_season(x))\ndf['delta_temp'] = df['MaxTemp'] - df['MinTemp']\ndf['new_wind'] = np.sqrt(df['WindSpeed3pm'] * df['WindGustSpeed'] * df['WindSpeed9am'])\ndf['new_humidity'] = np.sqrt(df['Humidity9am'] * df['Humidity3pm'])\ndf['new_pressure'] = np.sqrt(df['Pressure9am'] * df['Pressure3pm'])\n ","9c4b7d8b":"df.columns.shape # all correct","c5da09b5":"df[[ 'RainTomorrow']].value_counts()","69f7a7f4":"def get_cols(df) -> list:\n    '''\n    function return list of name numbers and categorials columns\n    '''\n    categorical_feature_mask = df.dtypes == object\n    number_feature_mask = df.dtypes != object\n    numbers_cols = df.columns[number_feature_mask].tolist()\n    categorical_cols = df.columns[categorical_feature_mask].tolist()\n    return [numbers_cols, categorical_cols]\n\nnum_cols, cat_cols = get_cols(df)","b43a34c9":"# fill na data\nfrom sklearn.impute import SimpleImputer\n\n\nimp_mean_num = SimpleImputer(strategy='mean')\nimp_mean_cat = SimpleImputer(strategy='most_frequent')\n\nfor col in df.columns.to_list():\n    if col in num_cols:\n        df[col] = imp_mean_num.fit_transform(df[[col]])\n    else:\n        df[col] = imp_mean_cat.fit_transform(df[[col]])","f59409ba":"# check previous step\ndf.isnull().sum()","eaced0dc":"from sklearn.preprocessing import LabelEncoder\n\n\nle = LabelEncoder()\ndf[['RainToday', 'RainTomorrow']] = df[['RainToday', 'RainTomorrow']].apply(lambda x: le.fit_transform(x))","9fec76cd":"df.info()","983fb22a":"# show correlations\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize = (15,6))\nsns.heatmap(df.corr(), annot = True)\n","fd445490":"cols = df[num_cols].columns.to_list()\ndt = df[num_cols]\n\nfor i,v in enumerate(cols):\n    for t in range(i, len(cols)):\n        if v != cols[t]:\n            if dt.corr()[v][cols[t]] > 0.85:\n                print(v, cols[t], dt.corr()[v][cols[t]].round(2))","65101144":"#delete columns \ndf.drop(['Temp9am', 'Temp3pm', 'new_humidity', 'Pressure3pm', 'new_pressure'], axis = 1, inplace = True)","061dbd04":"df.corr()['RainTomorrow'].abs().sort_values()","9ed28593":"df.drop(['month', 'Date', 'Season', 'MinTemp', 'WindSpeed3pm', 'WindSpeed9am'], axis = 1, inplace = True)","62a53f5d":"df.head()","8f4b0d5d":"df['WindGust_W'] = [1 if 'W' in list(i) else 0 for i in df['WindGustDir']]\ndf['WindGust_N'] = [1 if 'N' in list(i) else 0 for i in df['WindGustDir']]\ndf['WindGust_S'] = [1 if 'S' in list(i) else 0 for i in df['WindGustDir']]\ndf['WindGust_E'] = [1 if 'E' in list(i) else 0 for i in df['WindGustDir']]\n\ndf['WindDir9am_W'] = [1 if 'W' in list(i) else 0 for i in df['WindDir9am']]\ndf['WindDir9am_N'] = [1 if 'N' in list(i) else 0 for i in df['WindDir9am']]\ndf['WindDir9am_S'] = [1 if 'S' in list(i) else 0 for i in df['WindDir9am']]\ndf['WindDir9am_E'] = [1 if 'E' in list(i) else 0 for i in df['WindDir9am']]\n\ndf['WindDir3pm_W'] = [1 if 'W' in list(i) else 0 for i in df['WindDir3pm']]\ndf['WindDir3pm_N'] = [1 if 'W' in list(i) else 0 for i in df['WindDir3pm']]\ndf['WindDir3pm_S'] = [1 if 'W' in list(i) else 0 for i in df['WindDir3pm']]\ndf['WindDir3pm_E'] = [1 if 'W' in list(i) else 0 for i in df['WindDir3pm']]","3eb997dc":"plt.figure(figsize = (15,6))\nsns.heatmap(df.corr(), annot = True)","43d38813":"num_cols, cat_cols = get_cols(df)\n\ncols = df[num_cols].columns.to_list()\ndt = df[num_cols]\n\nfor i,v in enumerate(cols):\n    for t in range(i, len(cols)):\n        if v != cols[t]:\n            if dt.corr()[v][cols[t]] > 0.85:\n                print(v, cols[t], dt.corr()[v][cols[t]].round(2))","041b3b26":"#Drop unnecessary columns\ndf.drop(['WindDir3pm_N', 'WindDir3pm_S', 'WindDir3pm_E'], axis = 1, inplace = True)","1a9b4110":"plt.figure(figsize = (15,6))\nsns.heatmap(df.corr(), annot = True)","8f3eb7cb":"df.corr()['RainTomorrow'].abs().sort_values()","6ffbb5af":"df.drop(['WindGust_S', 'WindGust_N', 'WindDir3pm_W', \n         'WindDir9am_S', 'WindDir9am_N', 'WindDir9am_W',\n         'WindDir9am_E', 'WindGust_W'], axis = 1, inplace = True)","4c632676":"df.head()","b95ff7ba":"# work with categorial data\nnum_cols, cat_cols = get_cols(df)\n\nenc = LabelEncoder()\ndf[cat_cols] = df[cat_cols].apply(lambda x: le.fit_transform(x))","8d890b62":"# work with number data\nfrom sklearn.preprocessing import Normalizer\n\nscaler = Normalizer()\ndf[num_cols] = df[num_cols].apply(lambda x: le.fit_transform(x))","dc45bfa9":"df.head()","dffd0cbf":"from sklearn.model_selection import train_test_split\n\nX = df.drop(['RainTomorrow'], axis = 1)\ny = df['RainTomorrow']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify = df['RainTomorrow'])","88dced4c":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.model_selection import GridSearchCV\n\n\nmodel = KNeighborsClassifier(n_neighbors = 20, weights = 'distance')\nmodel.fit(X_train,y_train)\n\naccuracy_score(y_test, model.predict(X_test))","405907bb":"from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train,y_train)\n\naccuracy_score(y_test, model.predict(X_test))","087a2a22":"params ={\n    'C': np.logspace(-2,2,10),\n    'solver': ['lbfgs', 'liblinear', 'sag', 'saga']\n}\n\ngrid = GridSearchCV(LogisticRegression(random_state = 0), params, scoring = 'accuracy')\ngrid.fit(X_train,y_train)","f0165a29":"grid.best_params_","7536648c":"accuracy_score(y_test, grid.predict(X_test))","6f4f636c":"from sklearn.ensemble import RandomForestClassifier\n\n\nparams ={\n    'criterion': ['entropy'],\n    'max_depth': [16],\n    'n_estimators': range(10,101,10)\n}\n\ngrid = GridSearchCV(RandomForestClassifier(random_state = 0), params, scoring = 'accuracy')\ngrid.fit(X_train,y_train)","6a59f5e0":"grid.best_params_","296879be":"accuracy_score(y_test, grid.predict(X_test))","42c3b212":"# ****KNeighborsClassifier****","6361add9":"# The best model - RandomForestClassifier ","114d49cd":"### LogisticRegression best score = 83,9%","36072ae5":"### KNN best score = 81,8%","321cbc8f":"# Conclusion","5d736124":"### RandomForestClassifier best score = 84,8%","80a290b0":"# LogisticRegression","061ce48f":"**unfortunately, our hypothesis turned out to be incorrect, so we delete the columns (except WindGust_E)**","5340591a":"**New column have a good correlation with target, drop unnecessary columns (corr < 0.1 with target) **","ab1c7fca":"# RandomForestClassifier","c2fe43e4":"**Try to split WindGustDir and WindDir9am **"}}