{"cell_type":{"058e9010":"code","911ade2d":"code","2475efc2":"code","5330b8f2":"code","50f412ca":"code","0250cfd4":"code","c517bc0f":"code","40afb898":"code","15dd3922":"code","eca47683":"code","9ab0c0d1":"code","4debd4a5":"code","89795890":"code","25ec3e4d":"code","e5579792":"code","957cad83":"code","b1ccaad6":"code","4314be4d":"code","de204150":"code","fac911b7":"code","3ce6f152":"code","4909c773":"code","e78f0415":"code","15a727d9":"code","96d86897":"code","5d5bd842":"markdown","ae813183":"markdown","7486b558":"markdown","e591746a":"markdown","a0bbc5ec":"markdown","e4bbe1af":"markdown","f3fb0190":"markdown","3fd5156d":"markdown","ec92857a":"markdown","fb51c9b4":"markdown","fbb408f2":"markdown","90be7e05":"markdown","e290aa4d":"markdown","ed4baab4":"markdown","2a99dd6d":"markdown"},"source":{"058e9010":"import numpy as np \nimport pandas as pd \nfrom scipy import stats as ss\nimport statsmodels.api as sm\nfrom sklearn import metrics\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\n\nfrom bayes_opt import BayesianOptimization\nfrom skopt  import BayesSearchCV \nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport shap ","911ade2d":"df = pd.read_csv(\"..\/input\/KaggleV2-May-2016.csv\")\n\ndef get_day(x):\n    return x.date()\n\ndef DaysBeforeCat(days):\n    if days == 0:\n        return '0 days'\n    elif days in range(1,3):\n        return '1-2 days'\n    elif days in range(3,8):\n        return '3-7 days'\n    elif days in range(8, 32):\n        return '8-31 days'\n    else:\n        return '> 31 days'\n\ndef getting_ready(df):\n    \n    df['PatientId'].astype('int64')\n    df.set_index('AppointmentID', inplace = True)\n    \n    # Creating new variables\n    df['NoShow'] = (df['No-show'] == 'Yes')*1\n    df['PreviousApp'] = df.sort_values(by = ['PatientId','ScheduledDay']).groupby(['PatientId']).cumcount()\n    df['PreviousNoShow'] = (df[df['PreviousApp'] > 0].sort_values(['PatientId', 'ScheduledDay']).groupby(['PatientId'])['NoShow'].cumsum() \/ df[df['PreviousApp'] > 0]['PreviousApp'])\n    df['ScheduledDay'] = pd.to_datetime(df['ScheduledDay'])\n    df['WeekdayScheduled'] = df.apply(lambda x: x.ScheduledDay.isoweekday(), axis = 1)\n    df['HasHandicap'] = (df['Handcap'] > 0)*1\n    df['PreviousDisease'] = df.apply(lambda x: ((x.Hipertension == 1 )| x.Diabetes == 1 | x.Alcoholism == 1)*1, axis = 1)\n    df['AppointmentDay'] = pd.to_datetime(df['AppointmentDay'])\n    df['WeekdayAppointment'] = df.apply(lambda x: x.AppointmentDay.isoweekday(), axis = 1)\n    df['DaysBeforeApp'] = ((df.AppointmentDay.apply(get_day) - df.ScheduledDay.apply(get_day)).astype('timedelta64[D]')).astype(int)\n    df['DaysBeforeCat'] = df.DaysBeforeApp.apply(DaysBeforeCat)\n    \n    # Filtering\n    \n    df2 = df[(df['WeekdayScheduled'] < 6) &\n             (df['WeekdayAppointment'] < 6) &\n             (df['Age'] >= 0) &\n             (df['DaysBeforeApp'] >= 0)]\n    \n    return df2\n    \ndf_done = getting_ready(df)","2475efc2":"df_done.columns","5330b8f2":"# WeekdayScheduled to dummies\ndf_done = df_done.assign(ScheduledMonday = (df['WeekdayScheduled'] == 1)*1, \n                         ScheduledTuesday = (df['WeekdayScheduled'] == 2)*1, \n                         ScheduledWednesday = (df['WeekdayScheduled'] == 3)*1,\n                         ScheduledThursday = (df['WeekdayScheduled'] == 4)*1,\n                         ScheduledFriday = (df['WeekdayScheduled'] == 5)*1)\n\n# WeekdayAppointment to dummies\ndf_done = df_done.assign(AppointmentMonday = (df['WeekdayAppointment'] == 1)*1, \n                         AppointmentTuesday = (df['WeekdayAppointment'] == 2)*1, \n                         AppointmentWednesday = (df['WeekdayAppointment'] == 3)*1,\n                         AppointmentThursday = (df['WeekdayAppointment'] == 4)*1,\n                         AppointmentFriday = (df['WeekdayAppointment'] == 5)*1)\n\n# Gender to dummy \ndf_done['IsFemale'] = (df_done['Gender'] == 'F')*1\n\n# DaysBeforeCat to dummies\ndef ant_days(df):\n    df.loc[:, 'Ant0Days'] = (df['DaysBeforeCat'] == '0 days')*1\n    df.loc[:, 'Ant12Days'] = (df['DaysBeforeCat'] == '1-2 days')*1\n    df.loc[:, 'Ant37Days'] = (df['DaysBeforeCat'] == '3-7 days')*1\n    df.loc[:, 'Ant831Days'] = (df['DaysBeforeCat'] == '8-31 days')*1\n    df.loc[:, 'Ant32Days'] = (df['DaysBeforeCat'] == '> 31 days')*1\n    \nant_days(df_done)","50f412ca":"features = ['Age', 'Scholarship', 'Hipertension', 'Diabetes',\n            'Alcoholism', 'SMS_received', 'PreviousApp', 'PreviousNoShow', \n            'HasHandicap', 'PreviousDisease', 'DaysBeforeApp',\n            'ScheduledMonday', 'ScheduledTuesday', 'ScheduledWednesday', \n            'ScheduledThursday', 'ScheduledFriday', 'AppointmentMonday', \n            'AppointmentTuesday', 'AppointmentWednesday', 'AppointmentThursday', \n            'AppointmentFriday', 'IsFemale', 'Ant0Days', 'Ant12Days', \n            'Ant37Days', 'Ant831Days', 'Ant32Days']\n\nlabel = 'NoShow'","0250cfd4":"# Special thanks to https:\/\/www.kaggle.com\/somang1418\/tuning-hyperparameters-under-10-minutes-lgbm\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","c517bc0f":"df_done = reduce_mem_usage(df_done)\n\nX_train, X_test, y_train, y_test = train_test_split(df_done[features], df_done[label], test_size=0.3, random_state=6)\ny_train = pd.DataFrame(y_train)\ntrain = X_train.merge(y_train, left_index = True, right_index = True)\ny_test = pd.DataFrame(y_test)\ntest = X_test.merge(y_test, left_index = True, right_index = True)","40afb898":"def param_opt_xgb(X, y, init_round=10, opt_round=10, n_folds=3, random_seed=6, output_process=False):\n    # Prepare data\n    dtest = xgb.DMatrix(X, y)\n\n    def xgb_eval(learning_rate, n_estimators, max_depth, min_child_weight, gamma, subsample, colsample_bytree, scale_pos_weight):\n        params = {'objective' : 'binary:logistic', 'nthread' : 4, 'seed' : random_seed, \"silent\":1}\n        params['learning_rate'] = max(min(learning_rate, 1), 0)\n        params['n_estimators'] = int(round(n_estimators))\n        params['max_depth'] = int(round(max_depth))\n        params['min_child_weight'] = int(round(min_child_weight))\n        params['gamma'] = gamma\n        params['subsample'] = max(min(subsample, 1), 0)\n        params['colsample_bytree'] = max(min(colsample_bytree, 1), 0)\n        params['scale_pos_weight'] = int(round(scale_pos_weight))\n\n        cv_result = xgb.cv(params, dtest, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n        \n        \n        return max(cv_result['train-auc-mean'])\n    \n    xgbBO = BayesianOptimization(xgb_eval, {'learning_rate': (0.01, 0.3),\n                                                'n_estimators': (100, 200),\n                                                'max_depth': (2, 7),\n                                                'min_child_weight': (0, 7),\n                                                'gamma': (0, 0.3),\n                                                'subsample':(0.5,1),\n                                                'colsample_bytree': (0.5, 1),\n                                                'scale_pos_weight':(2,7)}, random_state=random_seed)\n\n    xgbBO.maximize(init_points=init_round, n_iter=opt_round)\n\n    model_aucpr=[]\n    for model in range(len(xgbBO.res)):\n        model_aucpr.append(xgbBO.res[model]['target'])\n\n    # return best parameters\n    return xgbBO.res[pd.Series(model_aucpr).idxmax()]['target'],xgbBO.res[pd.Series(model_aucpr).idxmax()]['params']","15dd3922":"opt_params = param_opt_xgb(df_done[features], df_done[label])","eca47683":"opt_params[1]['n_estimators'] = int(round(opt_params[1]['n_estimators']))\nopt_params[1]['max_depth'] = int(round(opt_params[1]['max_depth']))\nopt_params[1]['min_child_weight'] = int(round(opt_params[1]['min_child_weight']))\nopt_params[1]['scale_pos_weight'] = int(round(opt_params[1]['scale_pos_weight']))\nopt_params[1]['objective']='binary:logistic'\nopt_params[1]['metric']='auc'\nopt_params[1]['nthread']=4\nopt_params[1]['seed']=6\nopt_params=opt_params[1]\nopt_params","9ab0c0d1":"def modelfit(alg, dtrain, dtest, predictors, target, eval_metric = True):\n        #Fit the algorithm on the data\n        if eval_metric:\n            alg.fit(dtrain[predictors], dtrain[target].values.ravel(), eval_metric = ['auc'])\n        else: \n            alg.fit(dtrain[predictors], dtrain[target].values.ravel())\n            \n        #Predict training set:\n        dtrain_predictions = alg.predict(dtrain[predictors])\n        dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n        \n        #Predict test set:\n        dtest_predictions = alg.predict(dtest[predictors])\n        dtest_predprob = alg.predict_proba(dtest[predictors])[:,1]\n            \n        #Print model report:\n        print( \" Model Report\")\n        print(\"Accuracy Train: %.4g\" % metrics.accuracy_score(dtrain[target].values, dtrain_predictions))\n        print(\"Recall Train: %.4g\" % metrics.recall_score(dtrain[target].values, dtrain_predictions))\n        print(\"Accuracy Test: %.4g\" % metrics.accuracy_score(dtest[target].values, dtest_predictions))\n        print(\"Recall Test: %.4g\" % metrics.recall_score(dtest[target].values, dtest_predictions))\n        print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain[target], dtrain_predprob))","4debd4a5":"xgb1 = XGBClassifier(\n        learning_rate =opt_params['learning_rate'],\n        n_estimators=opt_params['n_estimators'],\n        max_depth=6,\n        min_child_weight=opt_params['min_child_weight'],\n        gamma=opt_params['gamma'],\n        subsample=opt_params['subsample'],\n        colsample_bytree=opt_params['colsample_bytree'],\n        objective= 'binary:logistic',\n        nthread=4,\n        scale_pos_weight=opt_params['scale_pos_weight'],\n        seed=6)\n\nmodelfit(xgb1, train, test, features, target = label)","89795890":"print('Accuracy naive model: {:1.4f}'.format(1-test[label].mean()))","25ec3e4d":"df.columns","e5579792":"features0 = ['Gender', 'Age', 'Scholarship', 'Hipertension', 'Diabetes',\n       'Alcoholism', 'SMS_received','PreviousApp', 'PreviousNoShow', 'WeekdayScheduled', 'HasHandicap',\n       'PreviousDisease', 'WeekdayAppointment', 'DaysBeforeApp',\n       'DaysBeforeCat']\ncorr = df_done[features0].corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)\nplt.title('Correlation Matrix')\nplt.gcf().set_size_inches(10, 6)\nplt.show()\n\ncorr","957cad83":"df_done.loc[:, 'MissedAppointments'] = df_done.sort_values(['ScheduledDay']).groupby(['PatientId'])['NoShow'].cumsum()","b1ccaad6":"features2 = ['Age','Scholarship','Hipertension','Diabetes', 'Alcoholism', 'SMS_received',\n             'PreviousApp','MissedAppointments','HasHandicap', 'ScheduledMonday',\n             'ScheduledTuesday', 'ScheduledWednesday', 'ScheduledThursday', 'ScheduledFriday',\n             'AppointmentMonday', 'AppointmentTuesday', 'AppointmentWednesday',\n             'AppointmentThursday', 'AppointmentFriday','IsFemale', 'Ant0Days', 'Ant12Days',\n             'Ant37Days', 'Ant831Days', 'Ant32Days']","4314be4d":"scaler = StandardScaler().fit(df_done[features2])\ndf_rescaled = scaler.transform(df_done[features2])\n\nX_train, X_test, y_train, y_test = train_test_split(df_done[features2], df_done[label], test_size=0.3, random_state=6)\ny_train = pd.DataFrame(y_train)\ntrain = X_train.merge(y_train, left_index = True, right_index = True)\ny_test = pd.DataFrame(y_test)\ntest = X_test.merge(y_test, left_index = True, right_index = True)","de204150":"logit = LogisticRegression(class_weight = 'balanced', solver = 'liblinear')\nmodelfit(logit, train, test, features2, label, eval_metric = False)","fac911b7":"tree = DecisionTreeClassifier(max_depth=12, random_state=0)\nmodelfit(tree, train, test,features2, label, eval_metric=False)","3ce6f152":"rf = RandomForestClassifier(random_state = 0, class_weight = 'balanced')\nmodelfit(rf, train, test,features2, label, eval_metric=False)","4909c773":"feature_importance = pd.DataFrame({'feature' : features2,\n                                   'importances' : rf.feature_importances_})\nordered = feature_importance.sort_values(['importances'], ascending = False)\nbest = ordered[:10]\nsns.barplot(x = 'importances', y = 'feature', data = best)\nplt.xlabel('Feature Importance')\nplt.title('Feature Importance Plot - Decision Tree')\nplt.show()","e78f0415":"sample = X_test.sample(300)\nshap.initjs()\nexplainer = shap.TreeExplainer(rf)\nshap_values = explainer.shap_values(sample[features2])\nshap.summary_plot(shap_values[1], sample[features2])","15a727d9":"df_done['preds'] = rf.predict(df_done[features2])\ncm = metrics.confusion_matrix(df_done['NoShow'], (df_done['preds'] > 0.5)*1)\nnormalize = False \n\nfig, ax = plt.subplots()\nim = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\nax.figure.colorbar(im, ax=ax)\n# We want to show all ticks...\nax.set(xticks=np.arange(cm.shape[1]),\n       yticks=np.arange(cm.shape[0]),\n       xticklabels=['Show', 'No Show'], yticklabels=['Show', 'No Show'],\n       title='Confusion Matrix',\n       ylabel='True label',\n       xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\nplt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n         rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\nfmt = '.2f' if normalize else 'd'\nthresh = cm.max() \/ 2.\nfor i in range(cm.shape[0]):\n    for j in range(cm.shape[1]):\n        ax.text(j, i, format(cm[i, j], fmt),\n                ha=\"center\", va=\"center\",\n                color=\"white\" if cm[i, j] > thresh else \"black\")\n\nax\n\nprint('True Positive Rate (recall): {:1.3f}'.format(metrics.recall_score(df_done['NoShow'], (df_done['preds'] > 0.5)*1)))\nprint('Accuracy: {:1.3f}'.format(metrics.accuracy_score(df_done['NoShow'], (df_done['preds'] > 0.5)*1)))","96d86897":"# ROC Curve \nprobs = rf.predict_proba(df_done[features2])[:,1]\n\nfpr, tpr, threshold = metrics.roc_curve(df_done['NoShow'], probs)\nroc_auc = metrics.auc(fpr, tpr)\n\n\nplt.title('Receiver Operating Characteristic Curve')\nplt.plot(fpr, tpr, label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","5d5bd842":"The decision tree performs even better for accuracy! If we set class_weight as 'balanced', recall is higher but accuracy lowers its value. As explained before, medical hospitals contacted prefered accuracy over recall so we choose the tree without balance. Keep in mind that having recall over 0.85 is very high (85% of no-shows are being captured by the model) ! \n\n*Note: For a long time I have used XGBoost without consulting other models (I know, my bad). I loved this example as it hit my pride and made me reconsiderate my initial approach, changing the whole problem for better performance. Every day we can learn something new !*\n\nFinally, we will train a **Random Forest**: as one decision tree performed better, maybe several decision trees perform best. ","ae813183":"The features we will use are: Gender, Age, Scholarship, Hipertension, Diabetes, Alcoholism, SMS_received, PreviousApp, PreviousNoShow, WeekdayScheduled, WeekdayAppointment, HasHandicap, PreviousDisease, DaysBeforeApp and DaysBeforeCat. \n\nAs XGBoost only receives numerical features, we must transform the categorical variables into dummy variables. We could change each variable to a number but this makes no sense as, for example, Mondays (1 in WeekdayAppointment) is not twice as Tuesdays (2 in WeekdayAppointment). Values must make sense. Given this, the transformations we will apply are: \n* Change Gender to \"IsFemale\" which takes the value 1 if Gender = F and 0 in other case\n* Change WeekdayScheduled to five variables: ScheduledMonday, ScheduledTuesday, ..., ScheduledFriday. Each variable is 1 if the appointment was scheduled in that particular day and 0 in other case. Same transformation will be apply to WeekdayAppointment (variables will be AppointmentMonday and so on)\n* Change DaysBeforeCat to five variables: ","7486b558":"ROC Curve is almost perfect ! We have very early return (high true positive rate with low false positive rate, the ideal) which indicates that the model is very good. \n\nSometimes accuracy this high (over 90%) makes one wonder if we are overfitting data and that if we change the sample, the model will lower it's performance. However we must keep in mind that, because we have a very unbalanced data set, the naive model already has accuracy score near 80%, so this should be our point of start. In most \"academic\" excercises, data is perfectly balanced (50-50) so achieving accuracy above 90% is considered at least suspicious.But for unbalanced data, this doesn't apply (actually, no model should give accuracy below the naive model). ","e591746a":"Accuracy is way better than XGBoost ! Compared to naive model, we got an improvement of almost 14% for test data on accuracy. \n\nWe will train a **Decision Tree**, just to check how does this model compare to the two we already have. ","a0bbc5ec":"Some time ago, I worked with a medical hospital to optimize scheduling in order to avoid no-shows. They were willing to try new methods, as long as doctors weren't bothered by overbooking practices. In plain english: as they have many doctors who share offices, predicting a patient not showing up and failing was worse than predicting a patient showing up but then failing. In this case, where success\/positive outcome is no-show, this is known as false positive (predicted positive no-show but actually got negative no-show).\n\nIf we just wanted to be accurate, then as our data is unbalanced it will be easier to just predict everyone as not no-show and have 79% accuracy (more or less). But then we wouldn't be attacking the problem of no-show. So we must keep in mind that not only accuracy is important, but recall (the hability to capture positive results) is also important. \n\nAs we have more negative results than positive, rather than optimizing for AUROC we will optimize for precision-recall curve (for more info, see [here](http:\/\/www.chioka.in\/differences-between-roc-auc-and-pr-auc\/)). We will define our optimization function, parameters to be evaluated and perform bayesian optimization.","e4bbe1af":"Hope you enjoyed this study as much as I did ! I personally loved that everything went exactly opposite as I planned, forcing me to reconsider XGBoost for all cases and realizing that the nature of the problem defines the best model (and of course, the data!). \n \nIf you have a different point of view, or just want to add something to the analysis I encourage to do so! In the meantime, I'll try to improve the analysis with more plots or comments that clarifies any doubt. ","f3fb0190":"To reduce computing times, we will reduce memory usage using a function developed by @somang1418 (see [here](http:\/\/www.kaggle.com\/somang1418\/tuning-hyperparameters-under-10-minutes-lgbm)). Thanks to his work, we are able to perform Bayesian Optimization on hyperparameters in an optimal way (loved your work!)","3fd5156d":"The features we will use are number type as well as our label (NoShow). For hyperparameter tunning (and model training) we will separate the data between train and test. As data is not so sparse in time, the separation will be done using random sampling, where 70% of the data will be used for training and 30% for testing. ","ec92857a":"We've gained 6% from the naive model, not so much. \n\nFor this reason, we'll try with **Logistic Regression** (back to my dear glms)  and check accuracy for train and test datasets. First, we will study correlations: ","fb51c9b4":"From the matrix, we can see that Hipertension is highly correlated with PreviousDisease, Age and Diabetes. Also, Age is highly correlated with PreviousDisease. For this reason, we will eliminate PreviousDisease from the analysis but shall keep the others (correlation is high but not extreme). \n\nPreviously, NaN values didn't matter, as XGBoost learned from the data which path was the best. As now observations with missing values can not be used, we will change the variable PreviousNoShow as MissedAppointments : number of previous appointments with no-show. \n\nAlso, we will scale the data so all values are between 1 and 0. ","fbb408f2":"From SHAP Values, we can see that the most important variable is \"MissedAppointments\" (as mentioned before). In fact, this variable is able to divide the data, impact negatively on the model output for low values of MissedApointments and impact positively for higher values of missed appointments (which makes sense). \n\nAnother variable to watch is \"Ant0days\". As a reminder, this variable takes the value 1 when the appointment was scheduled with less than a day of anticipation and 0 for any other case (which means that low values of the variable correspond to appointments scheduled with at least one day of anticipation, while high values are for appointments with less than a day of anticipation). In the plot above, we can see there's a clear separation for Ant0days: appointments with value 1 lower the chanses of noshow, while appointments with value 0 receive a positive impact (elevates chances of no-show, also makes sense). \n\nNow we shall study how the model clasificates in general: ","90be7e05":"**Hyperparameter tunning, model fitting and more surprices!**\n\nIn [part 1](https:\/\/www.kaggle.com\/molihn\/xgboost-to-predict-patients-no-show-part-1) we studied the variables, created new ones and performed a very thorough EDA, focusing on how the features are related with the variable of interest: no-show. \n\nFrom this analysis, transformations were applied to the data: \n* Change PatientId type to integer\n* Set AppointmentID as index \n* Change variable No-show to binary (1 for no-show, 0 for show)\n* Create new variable PreviousApp which indicates the number of previous appointments scheduled by the patient\n* Create new variable PreviousNoShow which indicates the proportion of patient's No-Show previous to the appointment studied\n* Create new variables WeekdayScheduled and WeekdayAppointment, which indicate the day of the week (1: Monday, ..., 7: Sunday) the appointment was scheduled\/was respectively\n* Delete appointments scheduled or done on Saturdays (atypical values)\n* Delete patients with negative Age (less than zero)\n* Create new variable HasHandicap which indicates if the patient has some sort of handicap (the original variable indicates how many handicaps the patient has)\n* Create new variable PreviousDisease, which indicates if the patient has a previous condition diagnosed such as hypertension, diabetes or alcoholism\n* Create new variable DaysBeforeApp, which indicates how many days in advanced the appointment was scheduled and filter by those appointments with negative values (scheduling done after the appointment)\n* Create new variable DaysBeforeCat, which categorizes the previous variable in 5 groups: 0 days, 1-2 days, 3-7 days, 8-31 days and more than 31 days in advance\n\nThese transformations will be applied to obtain the data ready to model. ","e290aa4d":"The best so far !! We will use this model to study variable importance and predictive power. ","ed4baab4":"From the above, we can see how the random forest classifies correctly or incorrectly each appointment. The model is able to correctly predict more than 93% of No-Shows, which is very high. At the same time, more than 97% of cases are correctly labeled so the hospital should expect less than 3% of error (very very low). ","2a99dd6d":"We can see that the most important feature is \"MissedAppointments\", \"Age\" and \"PreviousApp\". Two of these three variables make reference to the patient's past behavior, which supports the hypothesis of patients repeating behaviors over time. As we have little history this is not enough to say that patients will always behave the same way but for this period of time this is true. \n\nFor better understanding, we will use SHAP Values. DanB made a marvelous job explaining advanced uses of SHAP Values (see [here](https:\/\/www.kaggle.com\/dansbecker\/advanced-uses-of-shap-values))  and for better understanding you can check this [medium post](https:\/\/medium.com\/@gabrieltseng\/interpreting-complex-models-with-shap-values-1c187db6ec83) . "}}