{"cell_type":{"103de991":"code","42aca394":"code","b4f11e23":"code","bc28deb9":"code","d768cc39":"code","8cb78870":"code","58f2c1ae":"code","4a7170d6":"code","c36b026f":"code","eb00aeb1":"code","15965f29":"code","f1fdcc63":"code","85c41a91":"code","56e11e35":"code","aec2ecad":"code","07227c91":"code","27cde81e":"code","6a6fd3ad":"code","605e1334":"code","51d8efb8":"markdown"},"source":{"103de991":"!pip install openpyxl","42aca394":"from transformers import pipeline\n# fill-mask pipeline implements a task of filling a blank word\n# https:\/\/huggingface.co\/transformers\/main_classes\/pipelines.html#transformers.FillMaskPipeline\nmodel = pipeline(\"fill-mask\")\n\n# Check how it works\nres = model(f\"HuggingFace is creating a {model.tokenizer.mask_token} that the community uses to solve NLP tasks.\")\nres\n\n# notice that the matched words have a space in the beginning.\n# this is to distinguish them with suffix words, which connects another word without a space","b4f11e23":"# Check the pipeline syntax\nhelp(model.__call__)\n\n# notice that the model accepts options:\n#   targets: the candidate words to fill the blank\n#   top_k  : number of candidates to show","bc28deb9":"# Check which pretrained model we are using\nmodel.model","d768cc39":"from collections import namedtuple\n\n# we define a problem as a named tuple below:\nProblem = namedtuple(\"Problem\", \"text choices answer\")\n\n# Eiken grade 5\n# source: https:\/\/www.eiken.or.jp\/eiken\/exam\/grade_5\/pdf\/202101\/2021-1-1ji-5kyu.pdf\neiken5 = [\n   Problem(\"A: What is your {}?  B: Kazumi Suzuki.\",\n           [\"hour\", \"club\", \"date\", \"name\"], \"name\")\n  ,Problem(\"I know Judy. She can {} French very well.\",\n           [\"see\", \"drink\", \"speak\", \"open\"], \"speak\")\n  ,Problem(\"A: Are your baseball shoes in your room, Mike?  B: No, Mom. They're in my {} at school.\",\n           [\"window\", \"shop\", \"locker\", \"door\"], \"locker\")\n  ,Problem(\"My sister usually plays tennis {} Saturdays.\",\n           [\"by\", \"on\", \"with\", \"at\"], \"on\")\n  ,Problem(\"My mother likes {}. She has many pretty ones in the garden.\",\n           [\"sports\", \"movies\", \"schools\", \"flowers\"], \"flowers\")\n  ,Problem(\"Let's begin today's class. Open your textbooks to {} 22.\",\n           [\"chalk\", \"ground\", \"page\", \"minute\"], \"page\")\n  ,Problem(\"Today is Wednesday. Tomorrow is {}.\",\n           [\"Monday\", \"Tuesday\", \"Thursday\", \"Friday\"], \"Thursday\")\n  ,Problem(\"I usually read magazines {} home.\",\n           [\"of\", \"on\", \"with\", \"at\"], \"at\")\n  ,Problem(\"A: It's ten o'clock, Jimmy. {} to bed.  B: All right, Mom.\",\n           [\"Go\", \"Sleep\", \"Do\", \"Sit\"], \"Go\")\n  ,Problem(\"A: Do you live {} Tokyo?  B: Yes. It's a big city.\",\n           [\"after\", \"with\", \"on\", \"in\"], \"in\")\n]\n\n# These are grade-5 questions (Grade 1 is the highest)\neiken5","8cb78870":"# Masked Language Model without choices\n# we consider the BERT model's guess \"correct\" if the correct answer is in the top 5 candidates\nimport pandas as pd\nout = pd.DataFrame()  # we will add outcomes in the dataframe\n\ndef solve_without_choices(problems, top_k=5):\n  inputs = [p.text.format(model.tokenizer.mask_token) for p in problems]\n  res = model(inputs, top_k=top_k)\n  out = []\n  for p, r in zip(problems, res):\n    # suggested answers and the scores\n    suggested = [s[\"token_str\"].strip() for s in r]\n    scores = [s[\"score\"] for s in r]\n    suggested_scores = \",\".join(\"%s(%.3f)\" % (w,s) for w, s in zip(suggested, scores))\n    # location of answer\n    if p.answer in suggested:\n      position = suggested.index(p.answer) + 1\n    else:\n      position = -1\n    out.append((p.text, suggested_scores, position))\n  out = pd.DataFrame(out, columns=[\"problem\", \"scores\", \"answer_position\"])\n  out[\"correct\"] = (out[\"answer_position\"] > 0)\n  return out\n\no = solve_without_choices(eiken5)\no[\"grade\"] = \"5\"\no[\"method\"] = \"fill-mask-no-target\"\nout = pd.concat((out, o))\no","58f2c1ae":"# Masked Language Model with candidate words\n# In this case, the model's guess is considered correct if the correct one is the first guess.\ndef solve_with_choices(problems):\n  out = []\n  for p in problems:\n    text = p.text.format(model.tokenizer.mask_token)\n    targets = [\" \" + c for c in p.choices]  # without this, words seems to be treated as suffix\n    res = model(text, targets=targets)\n\n    words = [s[\"token_str\"].strip() for s in res]\n    scores = [s[\"score\"] for s in res]\n    suggested_scores = \",\".join(\"%s(%.3f)\" % (w,s) for w, s in zip(words, scores))\n    # location of answer\n    if p.answer in words:\n      position = words.index(p.answer) + 1\n    else:\n      position = -1\n    out.append((p.text, suggested_scores, position))\n  out = pd.DataFrame(out, columns=[\"problem\", \"scores\", \"answer_position\"])\n  out[\"correct\"] = (out.answer_position == 1)\n  return out\no = solve_with_choices(eiken5)\n\no[\"grade\"] = \"5\"\no[\"method\"] = \"fill-mask-with-targets\"\nout = pd.concat((out, o))\no\n\n# The only failure by BERT is about the day of week:\n#   Today is Wednesday. Tomorrow is (   ).\n#\n# The model guessed Friday rather than Thursday. Close!","4a7170d6":"# Apply the methods to other grades\n\n# Eiken grade 4\n# source: https:\/\/www.eiken.or.jp\/eiken\/exam\/grade_4\/pdf\/202101\/2021-1-1ji-4kyu.pdf\n\neiken4 = [\n   Problem(\"My father is a {} of a sports club. He plays tennis there every Wednesday night.\",\n           [\"festival\", \"picnic\", \"member\", \"group\"], \"member\")\n  ,Problem(\"Mr. Clark told us many intesting {} about his trip to India.\",\n           [\"pictures\", \"books\", \"stories\", \"magazines\"], \"stories\")\n  ,Problem(\"It's snowing a lot today, so please drive {}.\",\n           [\"slowly\", \"freely\", \"coldly\", \"busily\"], \"slowly\")\n  ,Problem(\"In spring, Jane likes to walk in her grandmother's {}. She enjoys looking at the beautiful flowers there.\",\n           [\"stone\", \"sky\", \"garden\", \"wall\"], \"garden\")\n  ,Problem(\"Many girls in my class have {} hair.\",\n           [\"late\", \"slow\", \"short\", \"busy\"], \"short\")\n  ,Problem(\"A: Do you live in a city?  B: No. I live in a small {}\",\n           [\"hobby\", \"ticket\", \"town\", \"holiday\"], \"town\")\n  ,Problem(\"I {} Nancy's notebook. It was on Mary's desk\",\n           [\"stayed\", \"found\", \"stopped\", \"went\"], \"found\")\n  ,Problem(\"Dennis went to Japan for a year in August. He was sad when he {} goodbye to his family\",\n           [\"ended\", \"hoped\", \"told\", \"said\"], \"said\")\n  ,Problem(\"Jeff left the party at 8:00. He wanted to {} home early and go to bed.\",\n           [\"meet\", \"put\", \"send\", \"get\"], \"get\")\n  ,Problem(\"Mom's lemon cake is not as good {} her chocolate cake.\",\n           [\"to\", \"of\", \"as\", \"by\"], \"as\")\n]\n\no = solve_without_choices(eiken4)\ndisplay(o)\no[\"grade\"] = \"4\"\no[\"method\"] = \"fill-mask-no-target\"\nout = pd.concat((out, o))\n\no = solve_with_choices(eiken4)\ndisplay(o)\no[\"grade\"] = \"4\"\no[\"method\"] = \"fill-mask-with-targets\"\nout = pd.concat((out, o))","c36b026f":"# Eiken grade 3\n# source: https:\/\/www.eiken.or.jp\/eiken\/exam\/grade_3\/pdf\/202101\/2021-1-1ji-3kyu.pdf\n\neiken3 = [\n   Problem(\"A: How do you make that potato dish?  B: First, you {} the potatoes, and then cut them in half and put butter on them.\",\n           [\"boil\", \"care\", \"hurt\", \"eat\"], \"boil\")\n  ,Problem(\"Last summer, Hiroshi's family traveled around Japan. This year they went to go {}.\",\n           [\"abroad\", \"inside\", \"other\", \"similar\"], \"abroad\")\n  ,Problem(\"Bob {} five friends to his party\",\n           [\"made\", \"visited\", \"invited\", \"spoke\"], \"invited\")\n  ,Problem(\"A: John, you should go to bed soon. If you stay up too late, you'll {} and be late for school. B: OK, Mom.\",\n           [\"graduate\", \"promise\", \"return\", \"oversleep\"], \"oversleep\")\n  ,Problem(\"A: Did you buy your father something special for his birthday?  B: Yes. He loves to cook, so I got him a new {}.\",\n           [\"apron\", \"ring\", \"contact\", \"field\"], \"apron\")\n  ,Problem(\"I bought a new T-shirt for my brother, but I bought the wong size. It was too {} for him.\",\n           [\"heavy\", \"clear\", \"tight\", \"bright\"], \"tight\")\n  ,Problem(\"Sarah saw some flowers by the road while she was taking a walk. She {} a few and took them home.\",\n           [\"spent\", \"wished\", \"picked\", \"guessed\"], \"picked\")\n  ,Problem(\"Jenny saw her grandparents {} the first time in years. She missed them very much.\",\n           [\"for\", \"from\", \"out\", \"over\"], \"for\")\n  ,Problem(\"A: I told my mother that I would be home by 7:00. I don't want to {} my promise, so I have to go now.  B: OK.\",\n           [\"pass\", \"sell\", \"break\", \"lend\"], \"break\")\n  ,Problem(\"A: Don'y say anything to Dad about the surprise party!  B: Don't worry. He won't find {} about it from me.\",\n           [\"within\", \"through\", \"out\", \"near\"], \"out\")\n]\n\no = solve_without_choices(eiken3)\ndisplay(o)\no[\"grade\"] = \"3\"\no[\"method\"] = \"fill-mask-no-target\"\nout = pd.concat((out, o))\n\no = solve_with_choices(eiken3)\ndisplay(o)\no[\"grade\"] = \"3\"\no[\"method\"] = \"fill-mask-with-targets\"\nout = pd.concat((out, o))","eb00aeb1":"# Eiken grade pre2\n# source: https:\/\/www.eiken.or.jp\/eiken\/exam\/grade_p2\/pdf\/202101\/2021-1-1ji-p2kyu.pdf\n\neikenp2 = [\n   Problem(\"Jamie visited several {} buildings when he went to Rome. Some of them were more than 2,000 years old.\",\n           [\"ancient\", \"exact\", \"responsible\", \"unable\"], \"ancient\")\n  ,Problem(\"Sally's French teacher told her to read an article in a French newspaper and {} it into English.\",\n           [\"guide\", \"throw\", \"control\", \"translate\"], \"translate\")\n  ,Problem(\"Henry likes living in the city because there are so many things to do there. But he also loves nature, so sometimes he goes for a drive in the {}.\",\n           [\"decision\", \"experiment\", \"countryside\", \"image\"], \"countryside\")\n  ,Problem(\"A: Is it true that the things in this store only cost 100 yen?  B: Yes, but you will also need to pay {}, so they actually cost a little more.\",\n           [\"tax\", \"data\", \"total\", \"waste\"], \"tax\")\n  ,Problem(\"When the bust was an hour late, one man shouted {} at the driver. He said that he had missed an important meeting.\",\n           [\"partly\", \"angrily\", \"secretly\", \"tightly\"], \"angrily\")\n  ,Problem(\"Firefighters have to {} people from buildings that are on fire. To do this, they must be strong and healthy.\",\n           [\"weigh\", \"produce\", \"stamp\", \"rescue\"], \"rescue\")\n  ,Problem(\"John loves the singer Ann May, and he cannot wait until her new CD is {} next week. He has been waiting for it since here last CD came out two years ago.\",\n           [\"released\", \"trapped\", \"divided\", \"invented\"], \"released\")\n  ,Problem(\"The news that Ms. Kelly, the art teacher, was going to get married {} through the school very quickly. By lunchtime, almost all the students knew about it.\",\n           [\"spread\", \"served\", \"stretched\", \"stood\"], \"spread\")\n  ,Problem(\"A: I'm really nervous about acting in the play next week.  B: I know you're worried now, but you'll feel fine as soon a syou get on the {}.\",\n           [\"stage\", \"field\", \"court\", \"screen\"], \"stage\")\n  ,Problem(\"Before Diane attended Professor Miller's {} at the university, she was not intested in Chinese art. However, now, she wants to learn more about it.\",\n           [\"comment\", \"shipment\", \"lecture\", \"furniture\"], \"lecture\")\n]\n\no = solve_without_choices(eikenp2)\ndisplay(o)\no[\"grade\"] = \"pre2\"\no[\"method\"] = \"fill-mask-no-target\"\nout = pd.concat((out, o))\n\no = solve_with_choices(eikenp2)\ndisplay(o)\no[\"grade\"] = \"pre2\"\no[\"method\"] = \"fill-mask-with-targets\"\nout = pd.concat((out, o))","15965f29":"# Eiken grade 2\n# source: https:\/\/www.eiken.or.jp\/eiken\/exam\/grade_2\/pdf\/202101\/2021-1-1ji-2kyu.pdf\n\neiken2 = [\n   Problem((\"At first, the marketing department and the sales department were on the project together. \"\n            \"But people in the sales department were too busy, so now the project is being run {} by the marketing department.\"),\n           [\"needlessly\", \"entirely\", \"scientifically\", \"violently\"], \"entirely\")\n  ,Problem(\"Experts at the art gallery discovered that one of their paitings, which they had thought was a {} Picasso, was actually just a copy.\",\n           [\"genuine\", \"severe\", \"logical\", \"portable\"], \"genuine\")\n  ,Problem(\"The musician Jimmy Baker had a lot of {} when he was a child. His family was very poor before he became a rich and famous rock star.\",\n           [\"permission\", \"membership\", \"concentration\", \"hardship\"], \"hardship\")\n  ,Problem(\"Mother Teresa helped many sick people and gave food to many hungry children in India. She was known as a person who cared about {}.\",\n           [\"generation\", \"gravity\", \"hesitation\", \"humanity\"], \"humanity\")\n  ,Problem(\"As Liam waled down the dark street, he began to feel afraid. He had the {} that someone was watching him.\",\n           [\"feature\", \"translation\", \"sensation\", \"property\"], \"sensation\")\n  ,Problem(\"Risa buys water that comes from a mountain stream. She says that drinking it is good because it has many {} that her body needs.\",\n           [\"campaigns\", \"operations\", \"illustrations\", \"minerals\"], \"minerals\")\n  ,Problem(\"The lifeguard ran into the ocean to help a young girl who looked like she was {} in the big waves\",\n           [\"proposing\", \"converting\", \"drowning\", \"exporting\"], \"drowning\")\n  ,Problem(\"Yesterday was a hot day at the zoo, so Heather bought an ice cream. It melted so quickly that she could not help {} some on her dress.\",\n           [\"arguing\", \"spilling\", \"convincing\", \"maintaining\"], \"spilling\")\n  ,Problem(\"In the past, sailors had to use the stars to {} when they were on an ocean. These days, ships have modern equipment that shows sailors which way to go.\",\n           [\"satisfy\", \"respect\", \"permit\", \"navigate\"], \"navigate\")\n  ,Problem(\"Daisuke's grandmother eats a lot of vegetables, drinks green tea, and goes for a long walk every evening to {} her health.\",\n           [\"interpret\", \"replace\", \"preserve\", \"betray\"], \"preserve\")\n]\n\no = solve_without_choices(eiken2)\ndisplay(o)\no[\"grade\"] = \"2\"\no[\"method\"] = \"fill-mask-no-target\"\nout = pd.concat((out, o))\n\no = solve_with_choices(eiken2)\ndisplay(o)\no[\"grade\"] = \"2\"\no[\"method\"] = \"fill-mask-with-targets\"\nout = pd.concat((out, o))","f1fdcc63":"# Eiken grade pre1\n# source: https:\/\/www.eiken.or.jp\/eiken\/exam\/grade_p1\/pdf\/202101\/2021-1-1ji-p1kyu.pdf\n\neikenp1 = [\n   Problem((\"A: Thanks for showing me the outline of your sales presentation. It's good, but it's a bit {} in some places.  \"\n            \"B: I guess I do repeat some information too much. I'll try to take some of it out.\"),\n           [\"decisive\", \"subjective\", \"redundant\", \"distinct\"], \"redundant\")\n  ,Problem(\"Lisa went to the interview even though she thought there was a low {} of her getting the job. As she expected, she was not hired.\",\n           [\"restoration\", \"credibility\", \"contention\", \"probability\"], \"probability\")\n  ,Problem(\"It is sadly {} that, in developing counties, many of the farmers who grow nutritous crops for export do no not have enough food to feed their own families.\",\n           [\"indefinite\", \"ironic\", \"restless\", \"superficial\"], \"ironic\")\n  ,Problem(\"The explosion at the chemical factory {} great damage on the local environment. It will take years for wildlife to fully recover in the region.\",\n           [\"inflicted\", \"enhanced\", \"vanished\", \"perceived\"], \"inflicted\")\n  ,Problem(\"Some say the best way to overcome a {} is to expose oneself to what one fears. For example, people who are afraid of mice should try holding one.\",\n           [\"temptation\", \"barricade\", \"phobia\", \"famine\"], \"phobia\")\n  ,Problem(\"English classes at the university were required, but students were {} from them if they could prove they had advanced ability in the language.\",\n           [\"exempted\", \"prosecuted\", \"commanded\", \"qualified\"], \"exempted\")\n  ,Problem(\"E-mail and text messaging have {} the way people write. Many people shorten words and ignore traditional rules of grammar.\",\n           [\"transformed\", \"officiated\", \"synthesized\", \"disarmed\"], \"transformed\")\n  ,Problem((\"Some analysts think the new treaty on CO2 emissions is a {} in the fight against global warming. \"\n            '\"This is the most important environmental treaty ever signed,\" said one.'),\n           [\"milestone\", \"vigor\", \"backlog\", \"confession\"], \"milestone\")\n  ,Problem(\"Lying on the sunny beach with her husband on their vacation, Roberta felt {} happy. She had never been so content.\",\n           [\"barely\", \"profoundly\", \"improperly\", \"harshly\"], \"profoundly\")\n  ,Problem(\"Nadine spends an hour thoroughly cleaning her apartment evey day, so the entire place is {}.\",\n           [\"spotless\", \"minute\", \"rugged\", \"impartial\"], \"spotless\")\n]\n\no = solve_without_choices(eikenp1)\ndisplay(o)\no[\"grade\"] = \"pre1\"\no[\"method\"] = \"fill-mask-no-target\"\nout = pd.concat((out, o))\n\no = solve_with_choices(eikenp1)\ndisplay(o)\no[\"grade\"] = \"pre1\"\no[\"method\"] = \"fill-mask-with-targets\"\nout = pd.concat((out, o))","85c41a91":"# Eiken grade 1\n# source: https:\/\/www.eiken.or.jp\/eiken\/exam\/grade_1\/pdf\/202101\/2021-1-1ji-1kyu.pdf\n\neiken1 = [\n    Problem(\"Cell phones have become a permanent {} in modern society. Most perople could not imagine living without one.\",\n            [\"clasp\", \"stint\", \"fixture\", \"rupture\"], \"fixture\")\n   ,Problem(\"Colin did not have enough money to pay for the car all at onece, so he paid it off in {} of $800 a month for two years.\",\n            [\"dispositions\", \"installments\", \"enactments\", \"speculations\"], \"installments\")\n   ,Problem(\"When she asked her boss for a raise, Melanie's {} tone of voice made it obvious how nervous she was.\",\n            [\"garish\", \"jovial\", \"pompous\", \"diffident\"], \"diffident\")\n   ,Problem(\"The religious sect established a {} in a rural area where its followers could live together and share everything. No private property was allowed.\",\n            [\"dirge\", \"prelude\", \"repository\", \"commune\"], \"commune\")\n   ,Problem(\"The famous reporter was fired for {} another journalist's work. His article was almost exactly the same as that of the other journalist.\",\n            [\"alleviating\", \"plagiarizing\", \"inoculating\", \"beleaguering\"], \"plagiarizing\")\n   ,Problem(\"Now that the local steel factory has closed down, the streets of the once-busy town are lined with {} businesses. Most owners have abandoned their stores.\",\n            [\"rhetorical\", \"volatile\", \"defunct\", \"aspiring\"], \"defunct\")\n   ,Problem(\"The ambassador's failure to attend the ceremony held in honor of the king was considered an {} by his host nation and made already bad relations worse.\",\n            [\"elucidation\", \"affront\", \"impasse\", \"ultimatum\"], \"affront\")\n   ,Problem(\"US border guards managed to {} the escaped prisoner as he tried to cross into Canada. He was returned to jail immediately.\",\n            [\"apprehend\", \"pillage\", \"exalt\", \"acclimate\"], \"apprehend\")\n   ,Problem(\"Anthony enjoyed his first day at his new job. The atmosphere was {}, and his colleagues did their best to make him feel welcome.\",\n            [\"congenial\", \"delirious\", \"measly\", \"implausible\"], \"congenial\")\n   ,Problem((\"A: I just learned I've been {} to second violin in the school orchestra. I knew I should've practiced more.\"\n             \"B: Well, if you work hard, I'm sure you can get your previous position back.\"),\n            [\"relegated\", \"jeopardized\", \"reiterated\", \"stowed\"], \"relegated\")\n]\n\no = solve_without_choices(eiken1)\ndisplay(o)\no[\"grade\"] = \"1\"\no[\"method\"] = \"fill-mask-no-target\"\nout = pd.concat((out, o))\n\no = solve_with_choices(eiken1)\ndisplay(o)\no[\"grade\"] = \"1\"\no[\"method\"] = \"fill-mask-with-targets\"\nout = pd.concat((out, o))","56e11e35":"# As the grade gets higher, we are more likely to encounter \"unknown\" words (words not included in the vocabulary)\n#   and failed to make a guess for them.\n#\n# To overcome this, we will next employs a language model that calculates the sentence perplexity scores.","aec2ecad":"# Reference: https:\/\/huggingface.co\/transformers\/perplexity.html\n#            https:\/\/discuss.huggingface.co\/t\/gpt-2-perplexity-score-normalized-on-sentence-lenght\/5205\nimport torch\nfrom transformers import GPT2LMHeadModel, GPT2TokenizerFast\n\ndevice = \"cuda\"\nmodel_id = \"gpt2-large\"\n\nmodel2 = GPT2LMHeadModel.from_pretrained(model_id).to(device)\ntokenizer = GPT2TokenizerFast.from_pretrained(model_id)","07227c91":"def solve_with_choices2(problems):\n  out = []\n  for p in problems:\n    texts = [p.text.format(c) for c in p.choices]\n    res = []\n    for t in texts:\n      tmp = tokenizer(t, return_tensors='pt')\n      input_ids = tmp.input_ids.to(device)\n\n      with torch.no_grad():\n        res.append(model2(input_ids, labels=input_ids)[0].item())\n\n    res = list(zip(p.choices, res))\n    res.sort(key=lambda a: a[1])\n    scores = \",\".join(\"%s(%.3f)\" % a for a in res)\n    answer_position = [s[0] for s in res].index(p.answer) + 1\n\n    out.append((p.text, scores, answer_position))\n  out = pd.DataFrame(out, columns=[\"problem\", \"scores\", \"answer_position\"])\n  out[\"correct\"] = (out.answer_position==1)\n  return out","27cde81e":"o = solve_with_choices2(eiken5)\ndisplay(o)\no[\"grade\"] = \"5\"\no[\"method\"] = \"perplexity\"\nout = pd.concat((out, o))\n\no = solve_with_choices2(eiken4)\ndisplay(o)\no[\"grade\"] = \"4\"\no[\"method\"] = \"perplexity\"\nout = pd.concat((out, o))\n\no = solve_with_choices2(eiken3)\ndisplay(o)\no[\"grade\"] = \"3\"\no[\"method\"] = \"perplexity\"\nout = pd.concat((out, o))\n\no = solve_with_choices2(eikenp2)\ndisplay(o)\no[\"grade\"] = \"pre2\"\no[\"method\"] = \"perplexity\"\nout = pd.concat((out, o))\n\no = solve_with_choices2(eiken2)\ndisplay(o)\no[\"grade\"] = \"2\"\no[\"method\"] = \"perplexity\"\nout = pd.concat((out, o))\n\no = solve_with_choices2(eikenp1)\ndisplay(o)\no[\"grade\"] = \"pre1\"\no[\"method\"] = \"perplexity\"\nout = pd.concat((out, o))\n\no = solve_with_choices2(eiken1)\ndisplay(o)\no[\"grade\"] = \"1\"\no[\"method\"] = \"perplexity\"\nout = pd.concat((out, o))","6a6fd3ad":"# The model got a full-mark except just one:\n#\n#   When she asked her boss for a raise, Melanie's {} tone of voice made it obvious how nervous she was.\",\n#       \"garish\", \"jovial\", \"pompous\", \"diffident\"\n#\n# The correct answer is \"diffident\", meaning lack of self-confidence. This matches the fact that she was nervous.\n# The BERT's guess is \"jovial\", meaning friendly. This many naturally connect to \"tone of voice\", but misses the following context.","605e1334":"# compile output into human-friendly excel file\nout2 = None\nfor method in out.method.unique():\n    tmp = out[out.method==method].copy().reset_index(drop=True)\n    tmp[\"problem_number\"] = list(range(1,11)) * int(len(tmp)\/10)\n    tmp = tmp[[\"grade\", \"problem_number\", \"problem\", \"scores\", \"correct\"]]\n    tmp = tmp.rename(columns={\"scores\": \"scores({})\".format(method),\n                              \"correct\": \"correct({})\".format(method)})\n    if out2 is None:\n        out2 = tmp\n    else:\n        out2 = pd.merge(out2, tmp)\ndisplay(out2.head())\n\nout3 = out.pivot_table(index=\"grade\", columns=\"method\", values=\"correct\", aggfunc=sum)\nout3[\"grade2\"] = out3.index.tolist()\nout3.grade2 = out3.grade2.replace(\"pre2\", 2.5).replace(\"pre1\", 1.5).astype(float)\nout3 = out3.sort_values(\"grade2\").drop(columns=\"grade2\")\ndisplay(out3)\n\n\nwith pd.ExcelWriter(\"eiken-bert.xlsx\") as f:\n    out.to_excel(f, \"full-result\", index=False)\n    out2.to_excel(f, \"result-wideformat\", index=False)\n    out3.to_excel(f, \"score-summary\")\n\nout.to_csv(\"eiken-bert_full-result.csv\", index=False)\nout2.to_csv(\"eiken-bert_result-wideformat.csv\", index=False)\nout3.to_csv(\"eiken-bert_score-summary.csv\")","51d8efb8":"# BERT solves Eiken problems\n\nEiken (\u5b9f\u7528\u82f1\u8a9e\u6280\u80fd\u691c\u5b9a) is an English proficiency test conducted by a Japanese public-interest incorporated foundation ([Link to wikipedia](https:\/\/en.wikipedia.org\/wiki\/STEP_Eiken)).\nOne type of the questions in the test is a multiple choice problem to fill a blank in a sentence. For example:\n\n> My sister usually plays tennis (\u3000\u3000\u3000) Saturdays.  \n\u30001. by\u3000\u30002. on\u3000\u30003. with\u3000\u30004. at\n \n> Bob (\u3000\u3000\u3000) five friends to his party.  \n\u30001. made\u3000\u30002. visited\u3000\u30003. invited\u3000\u30004. spoke\n\nIn this notebook we solve this type of questions using pre-trained BERT models.\n\nFirst, we use the masked language model, which is designed to guess a word in a blank in a sentence.\nA drawback of this approach is that the model cannot guess a word not included in its vocabulary set.\n\nTo handle unknown words, the second approach calculates perplexity scores of the sentences filled by choices.\nSince a lower perplexity score indicates the sentense is more \"natural,\" we can pick the sentence with the lowest score as the answer. "}}