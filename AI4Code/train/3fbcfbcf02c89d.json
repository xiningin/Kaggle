{"cell_type":{"f4665796":"code","90b25300":"code","51d4395c":"code","12cf318a":"code","6f9447ef":"code","6f5379a7":"code","3e4c4669":"code","e1c53435":"code","b1fdfb3a":"code","86863494":"code","d77ebc82":"code","a3624260":"code","d026dfa6":"code","e22d8edd":"markdown","e62c1c8a":"markdown","2e4b9251":"markdown","d1e11e9e":"markdown"},"source":{"f4665796":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom fastai.tabular import *\nimport os\nprint(os.listdir(\"..\/input\"))\npath = Path('..\/input')\nx_train = pd.read_csv(path\/'train.csv')\n# Any results you write to the current directory are saved as output.","90b25300":"x_train.head()","51d4395c":"k = x_train['wheezy-copper-turtle-magic']\ncat_names = ['wheezy-copper-turtle-magic']","12cf318a":"procs = [FillMissing,Categorify,Normalize]\n","6f9447ef":"x_train.shape   #262144 rows and 258 columns\ncont_names = x_train.columns.tolist()[1:-1]\ncont_names.remove('wheezy-copper-turtle-magic')\n\ncat_names = ['wheezy-copper-turtle-magic']\n\nprocs = [FillMissing, Categorify, Normalize]","6f5379a7":"valid_idx = range(len(x_train)- 20000, len(x_train))\nx_test = pd.read_csv(path\/'test.csv')\ndep_var = 'target'\n\ndata = TabularDataBunch.from_df(path, x_train, dep_var=dep_var, valid_idx=valid_idx, procs=procs,\n                                cat_names=cat_names, cont_names=cont_names, test_df=x_test, bs=2048)\n","3e4c4669":"learn = tabular_learner(data,layers = [1000, 750, 500, 300],emb_szs={'wheezy-copper-turtle-magic': 200}, metrics=accuracy, ps=0.65, wd=3e-1,model_dir=\"\/tmp\/model\/\")","e1c53435":"learn.lr_find()","b1fdfb3a":"learn.recorder.plot()","86863494":"lr = 1e-2\nlearn.fit_one_cycle(50, lr)","d77ebc82":"test_pred = learn.get_preds(DatasetType.Test)","a3624260":"sub_df = pd.read_csv(path\/'sample_submission.csv')\nsub_df.target = test_pred[0][:,1].numpy()\nsub_df.head()","d026dfa6":"sub_df.to_csv('solution.csv', index=False)","e22d8edd":"Checking for the categorical columns","e62c1c8a":"First getting the size of the Dataframe to get the validating split","2e4b9251":"Print the x_train","d1e11e9e":"Splitting the DATA"}}