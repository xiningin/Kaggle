{"cell_type":{"b106d154":"code","f1eec66a":"code","820e65c1":"code","467e234d":"code","4729de4c":"code","c373805e":"code","19060bed":"code","b5ed056e":"markdown","b0ed212c":"markdown","261f472e":"markdown","08260498":"markdown","25185a29":"markdown","aa0b8189":"markdown","20ae7e8a":"markdown","2ce1fe68":"markdown","8aa5586f":"markdown"},"source":{"b106d154":"!pip install -q -U torch torchvision -f https:\/\/download.pytorch.org\/whl\/torch_stable.html \n!pip install -q -U 'git+https:\/\/github.com\/cocodataset\/cocoapi.git#subdirectory=PythonAPI'\n!pip install -q detectron2 -f https:\/\/dl.fbaipublicfiles.com\/detectron2\/wheels\/cpu\/index.html","f1eec66a":"from detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog\nfrom detectron2 import model_zoo\n\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","820e65c1":"# Loading the default config\ncfg = get_cfg()\n\n\n# Merging config from a YAML file\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation\/mask_rcnn_R_101_FPN_3x.yaml\"))\n\n\n# Downloading and loading pretrained weights\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation\/mask_rcnn_R_101_FPN_3x.yaml\")\n\n\n# Changing some other configs\ncfg.MODEL.DEVICE = 'cpu' # setting device to CPU as no training is required as per now\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # setting threshold for this model\n\n\n# Defining the Predictor\npredictor = DefaultPredictor(cfg)","467e234d":"def show_image(im, height=16, width=10):\n    \"\"\"\n    Function to display an image\n    \n    Args:\n        im ([numpy.ndarray])\n        height ([int] or None)\n        width ([int] or None)\n    \"\"\"\n    plt.figure(figsize=(16,10))\n    plt.imshow(im)\n    plt.axis(\"off\")\n    plt.show()","4729de4c":"def get_predicted_labels(classes, scores, class_names):\n    \"\"\"\n    Function to return the name of predicted classes along with accuracy scores\n    \n    Args:\n        classes (list[int] or None)\n        scores (list[float] or None)\n        class_names (list[str] or None)\n    Returns:\n        list[str] or None\n    \"\"\"\n    labels = None\n    if classes is not None and class_names is not None and len(class_names) > 1:\n        labels = [class_names[i] for i in classes]\n        labels = [\"{} {:.0f}%\".format(l, s * 100) for l, s in zip(labels, scores)]\n        return labels\n    else:\n        return \"No object identified\"","c373805e":"# Download image as input_image.jpg\n# !wget https:\/\/images.unsplash.com\/photo-1585574123552-aac232a58514 -O input_image.jpg\n\n!wget https:\/\/cdn-images-1.medium.com\/max\/872\/1*EYFejGUjvjPcc4PZTwoufw.jpeg -O input_image.jpg\n\n# Read image\nim = mpimg.imread(\"input_image.jpg\")\n\n# Show image\nshow_image(im)","19060bed":"# Predicting image\noutputs = predictor(im)\n\n\n# Extracting other data from the predicted image\nscores = outputs[\"instances\"].scores\nclasses = outputs[\"instances\"].pred_classes\nclass_names = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes\n\n\n# Obtaining a list of predicted class labels using the utility function created earlier\npredicted_labels = get_predicted_labels(classes, scores, class_names)\n\n\n# Creating the Visualizer for visualizing the bounding boxes\nv = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\nv = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\noutput_im = v.get_image()[:, :, ::-1] # image with bounding box and lables defined\n\n\n# Displaying the output\nprint(f\"Predicted Objects: {predicted_labels}\")\nshow_image(output_im, outputs)","b5ed056e":"### 5. Utility Functions\n\nWe are going to define some utility functions for showing the image and the predicted labels.****","b0ed212c":"### 7. Prediction\n\nFinally, we will predict the objects present in the above image using the predictor we defined earlier. Our output will be a list of predicted class labels along with the prediction score and an image with bounding box drawn over each object. ","261f472e":"For now we have only used a pretrained model for detecting objects. However, I will update this notebook in near future explaining how we can train the model on a custom dataset for object detection. If you like the kernel, feel free give it an upvote.","08260498":"### 1. What is Detectron2? \nDetectron2 is a PyTorch-based modular object detection library developed by the Facebook AI Research team. It provides a large set of trained models available for download. Detectron2 includes high-quality implementations of state-of-the-art object detection algorithms, including [DensePose](http:\/\/densepose.org\/), [panoptic feature pyramid networks](https:\/\/ai.facebook.com\/blog\/improving-scene-understanding-through-panoptic-segmentation\/), and numerous variants of the pioneering [Mask R-CNN](https:\/\/research.fb.com\/publications\/mask-r-cnn\/) model family.\n<img src=\"https:\/\/user-images.githubusercontent.com\/1381301\/66535560-d3422200-eace-11e9-9123-5535d469db19.png\" alt=\"Drawing\" style=\"width: 600px;\"\/>","25185a29":"### 6. Load Image\nWe will be downloading an image from [Unsplash](http:\/\/unsplash.com) and performing object detection on it. You may provide any other image url for object detection.","aa0b8189":"### 3. Dependencies\nWe are going to need the detectron2 for configuring and building the model and for viusalizing the bounding boxes. For reading and plotting images, we will be using matplotlib.","20ae7e8a":"### 4. Model Definition \n\nWe will be using a pre-trained model for now. Using a pretrained model is super easy in Detectron. We only need to load in and modify some configs. Then we will load in the weights of a pretrained model. Using the configs and pretrained weights, we will create DefaultPredictor to make predictions.\n\nWe will be using a Faster R-CNN model. It uses a ResNet+FPN backbone with standard conv and FC heads for mask and box prediction, respectively. This model obtains the best speed\/accuracy tradeoff. You can have a look at some of the other pretrained models available at [Model Zoo](https:\/\/github.com\/facebookresearch\/detectron2\/blob\/master\/MODEL_ZOO.md).","2ce1fe68":"### 2. Installation\nInstalling detectron2 is fairly simple as opposed to other object detection frameworks like the Tensorflow Object Detection API. \nWe will be installing torch, torchvision, cocoapi, and detectron2.","8aa5586f":"## Object Detection with Detectron2 - PyTorch"}}