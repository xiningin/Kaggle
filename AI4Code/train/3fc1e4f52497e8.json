{"cell_type":{"020de627":"code","4bcac4f5":"code","3f5b3318":"code","5ac0f4ec":"code","5f4e9ca6":"code","72b9f006":"code","6ddce199":"code","e334db36":"code","ae08fb3f":"code","fdaea3f8":"code","69928167":"code","f9b133d7":"code","672e3a25":"code","f1721830":"code","2827af7d":"code","a780dae2":"code","118df96b":"code","07c22995":"code","4d174e96":"code","d079277c":"code","ec9fcec9":"code","77876009":"code","d4eb09f7":"code","86423406":"code","1fd11036":"code","77c75ce2":"code","3dd9fccc":"code","5860fe83":"code","937e80e2":"code","42c6ea2f":"code","d092ca0e":"code","93029bc0":"code","6e0aa620":"code","4a5578b4":"code","c640aa4a":"markdown","6e5c999d":"markdown","190148e9":"markdown","21fa7d02":"markdown","46d5fa26":"markdown","05d78ed6":"markdown","d1e4b4da":"markdown","52f0a48a":"markdown","4447c019":"markdown","4be1d6ed":"markdown","d10584e1":"markdown"},"source":{"020de627":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport seaborn as sns\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.feature_selection import SelectKBest, f_regression\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.neural_network import MLPRegressor\nfrom xgboost.sklearn import XGBRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.svm import SVR\n\nimport statsmodels.api as sm\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max.columns', None)","4bcac4f5":"df = pd.read_csv('..\/input\/usahousing\/USA_Housing.csv')\ndf.head()","3f5b3318":"df.info()","5ac0f4ec":"sns.distplot(df['Avg. Area Income'])","5f4e9ca6":"sns.distplot(df['Avg. Area House Age'])","72b9f006":"sns.distplot(df['Avg. Area Number of Rooms'])","6ddce199":"sns.distplot(df['Avg. Area Number of Bedrooms'])","e334db36":"sns.distplot(df['Area Population'])","ae08fb3f":"sns.distplot(df['Price'])","fdaea3f8":"sns.boxplot(x='Avg. Area Income', data = df)","69928167":"sns.boxplot(x='Avg. Area House Age', data = df)","f9b133d7":"sns.boxplot(x='Avg. Area Number of Rooms', data = df)","672e3a25":"sns.boxplot(x='Avg. Area Number of Bedrooms', data = df)","f1721830":"sns.boxplot(x='Area Population', data = df)","2827af7d":"sns.boxplot(x='Price', data = df)","a780dae2":"df.isnull().sum()","118df96b":"df.describe()","07c22995":"df = df.drop('Address', axis = 1)\ndf.head()","4d174e96":"f, ax = plt.subplots(figsize=(10,8))\ncorr = df.corr()\nsns.heatmap(corr, annot=True, mask=np.zeros_like(corr, dtype=np.bool),\n           cmap = sns.diverging_palette(240, 10, as_cmap = True), \n           square = True, ax = ax)","d079277c":"df.corr()['Price'].sort_values()","ec9fcec9":"std = StandardScaler()\ndf_std = std.fit_transform(df)\ndf_std = pd.DataFrame(df_std, columns = df.columns)","77876009":"df_std.head()","d4eb09f7":"X = df.drop('Price', axis = 1)\ny = df.Price","86423406":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","1fd11036":"regressor = sm.OLS(y_train, X_train).fit()\nprint(regressor.summary())\n\nX_train_dropped = X_train.copy()","77c75ce2":"while True:\n    if max(regressor.pvalues) > 0.05:\n        drop_variable = regressor.pvalues[regressor.pvalues == max(regressor.pvalues)]\n        print(\"Dropping \" + drop_variable.index[0] + \" and running regression again because pvalue is: \" + str(drop_variable[0]))\n        X_train_dropped = X_train_dropped.drop(columns = [drop_variable.index[0]])\n        regressor = sm.OLS(y_train, X_train_dropped).fit()\n    else:\n        print(\"All p values less than 0.05\")\n        break\n","3dd9fccc":"print(regressor.summary())\n","5860fe83":"column_names = df.drop(columns = ['Price']).columns\n\nno_of_features = []\nr_squared_train = []\nr_squared_test = []\n\n#Look at shape\nfor k in range(1, 5):\n    selector = SelectKBest(f_regression, k = k)\n    X_train_transformed = selector.fit_transform(X_train, y_train)\n    X_test_transformed = selector.transform(X_test)\n    regressor = LinearRegression()\n    regressor.fit(X_train_transformed, y_train)\n    no_of_features.append(k)\n    r_squared_train.append(regressor.score(X_train_transformed, y_train))\n    r_squared_test.append(regressor.score(X_test_transformed, y_test))\n    \nsns.lineplot(x = no_of_features, y = r_squared_train, legend = 'full')\nsns.lineplot(x = no_of_features, y = r_squared_test, legend = 'full')","937e80e2":"# k = 4 because look at orange line\nselector = SelectKBest(f_regression, k = 4)\nX_train_transformed = selector.fit_transform(X_train, y_train)\nX_test_transformed = selector.transform(X_test)\ncolumn_names[selector.get_support()]\n","42c6ea2f":"def regression_model(model):\n    \"\"\"\n    Will fit the regression model passed and will return the regressor object and the score\n    \"\"\"\n    regressor = model\n    regressor.fit(X_train_transformed, y_train)\n    score = regressor.score(X_test_transformed, y_test)\n    return regressor, score","d092ca0e":"model_performance = pd.DataFrame(columns = [\"Features\", \"Model\", \"Score\"])\n\nmodels_to_evaluate = [LinearRegression(), Ridge(), Lasso(), SVR(), RandomForestRegressor(), MLPRegressor(), XGBRegressor(), GradientBoostingRegressor()]\n\nfor model in models_to_evaluate:\n    regressor, score = regression_model(model)\n    model_performance = model_performance.append({\"Features\": \"Linear\",\"Model\": model, \"Score\": round(score, 2)}, ignore_index=True)\n\nmodel_performance.sort_values(by = 'Score', ascending = False)","93029bc0":"poly = PolynomialFeatures()\nX_train_transformed_poly = poly.fit_transform(X_train)\nX_test_transformed_poly = poly.transform(X_test)\n\nprint(X_train_transformed_poly.shape)\n\nno_of_features = []\nr_squared = []\n\nfor k in range(3, 21):\n    selector = SelectKBest(f_regression, k = k)\n    X_train_transformed = selector.fit_transform(X_train_transformed_poly, y_train)\n    regressor = LinearRegression()\n    regressor.fit(X_train_transformed, y_train)\n    no_of_features.append(k)\n    r_squared.append(regressor.score(X_train_transformed, y_train))\n    \nsns.lineplot(x = no_of_features, y = r_squared)","6e0aa620":"selector = SelectKBest(f_regression, k = 16)\nX_train_transformed = selector.fit_transform(X_train_transformed_poly, y_train)\nX_test_transformed = selector.transform(X_test_transformed_poly)","4a5578b4":"models_to_evaluate = [LinearRegression(), Ridge(), Lasso(), SVR(), RandomForestRegressor(), MLPRegressor(), XGBRegressor(), GradientBoostingRegressor()]\n\nfor model in models_to_evaluate:\n    regressor, score = regression_model(model)\n    model_performance = model_performance.append({\"Features\": \"Polynomial\",\"Model\": model, \"Score\": round(score, 2)}, ignore_index=True)\n\nmodel_performance.sort_values(by = 'Score', ascending = False)\n","c640aa4a":"## The function removes features with high p-value","6e5c999d":"We have outliers","190148e9":"# Import Libs","21fa7d02":"# EDA\n## Distplot\nWe look at the distribution","46d5fa26":"## Uses SelectKBest","05d78ed6":"# Thanks for watching!\n## If you liked notebook then upvoted it or write your opinion","d1e4b4da":"# Modeling","52f0a48a":"## Boxplot","4447c019":"Feature distribution is normal","4be1d6ed":"# Data loading and overview","d10584e1":"# Preprocessing"}}