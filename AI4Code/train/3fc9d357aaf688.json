{"cell_type":{"2db292e6":"code","bbc507a3":"code","03265412":"code","4b1992e1":"code","ece0a7d0":"code","1b0a7f72":"code","ffcddd3c":"code","27b5866c":"code","cef50241":"code","0dc13f84":"code","27c57d6b":"code","0610e724":"code","b0e68a9c":"code","bbf9456b":"code","596aa3c2":"code","19666146":"code","e54c3905":"code","8f94ab69":"code","08022d01":"code","0378ed6b":"code","9552432c":"code","0fb98a1a":"code","068cc53a":"code","2b5e80b7":"code","a0e67e0a":"code","2247db20":"code","4b32e440":"code","b1b731d1":"code","cdbda0c1":"code","5bacde19":"code","b3d8224d":"code","ebb6687f":"code","0ae89475":"code","0c6b0be5":"code","ee730611":"code","3f318294":"code","68c5f18c":"code","e4f670b7":"code","5ae8092c":"code","db88bbdb":"code","125985d0":"code","5d208021":"code","b663518d":"code","a3ab672e":"code","b2a9ad42":"code","c24ac15e":"code","3d4c3228":"code","dd0101fe":"code","83f30845":"code","66b91085":"code","d989c9d2":"code","9943362a":"code","936e8bb2":"code","dc933813":"code","6c18c653":"code","05df27be":"code","1934bf84":"code","76350832":"code","29a1cf4b":"code","2e4270ff":"code","fb571660":"code","fb3aaf36":"code","d8120ee2":"code","cb64b6b1":"code","687a4983":"code","0b4da29d":"code","00871eee":"code","6b31b496":"code","e936a35d":"code","dc442e96":"code","faea9491":"code","d9704127":"code","617e9302":"code","7e9662b2":"code","0b970fed":"code","2875c3d1":"code","3d43a94c":"code","360c2033":"code","7e6b6009":"code","0ab9c749":"code","904cf34b":"code","0f6453dc":"code","ac6297a6":"code","457242aa":"code","3cd348ac":"code","b01b4046":"code","de373de9":"code","e2be672d":"code","0b57b8c3":"code","ef86720c":"code","0111a0de":"code","403c9a5f":"code","a5f5ea2c":"code","f2664ef0":"code","aca9ae9d":"code","b867aa1a":"code","68b638f2":"code","3e06235d":"code","8b2ce67d":"code","c8fe3b6f":"code","1a77e6d9":"code","36102f50":"code","353a96fd":"code","7d4bf57f":"code","49f90347":"code","d3d555dd":"code","2773cefa":"code","dcaf7f08":"code","fb9edc20":"code","b0cb8195":"code","44e131ad":"code","4965d76d":"code","235f86f1":"code","40e08d64":"code","d65d82c8":"code","c06013be":"code","4a9fc7c4":"code","6791914e":"code","f9947bb8":"code","e6a20fb1":"code","63edbb5c":"code","9d7ecd5b":"code","022a4c30":"code","d7933375":"code","26fcf2f1":"code","6e0c482e":"code","6f870ad7":"code","1dd76a06":"code","762e5763":"code","b84bc8c6":"code","e724ca58":"code","b319d4c7":"code","efe9efa0":"code","61b11021":"code","93388ab0":"code","e9a69698":"code","ce53b73d":"code","21395731":"code","cbdbee69":"code","1d2cd9e8":"code","d33cc6fd":"code","6b69b098":"code","1629073e":"code","2ca65be8":"code","7ccd9c83":"code","de474ed7":"code","fea56928":"code","5bc84cb7":"code","f8d5c98d":"code","0663a8cc":"code","fe2b9849":"code","d7f3e2bd":"code","c8dec3ed":"code","1218662a":"code","608928af":"code","f18692bd":"code","809b824f":"code","d2541ab1":"code","a522524b":"code","e27be65c":"code","41697d1e":"code","ee8d5d3b":"code","9cd28a7d":"code","ee2ca481":"code","6be431cc":"code","1d24e184":"markdown","4467c2a1":"markdown","914e27e6":"markdown","48916da7":"markdown","84205dee":"markdown","3ebf4be3":"markdown","827a9f20":"markdown","5a42ece0":"markdown","6788861a":"markdown","e27ada6d":"markdown","f7bf6210":"markdown","26bdbe38":"markdown","5d7c107b":"markdown","c18a6aa9":"markdown","859eac7e":"markdown","0bc7c44e":"markdown","c23deb49":"markdown","1f012c59":"markdown","23c251a2":"markdown","41f7f4e8":"markdown","4f8b1831":"markdown","361f7c33":"markdown","63a13cd4":"markdown","786e95dd":"markdown","e7da36dd":"markdown","bd26027c":"markdown","e39b09de":"markdown","38f81b8e":"markdown","a50d0a7e":"markdown","57462ecc":"markdown","d605d293":"markdown","97d5ef71":"markdown","dc649ae1":"markdown","10192d11":"markdown","e1ef409d":"markdown","e5a08cb6":"markdown","9fc3d8a2":"markdown","9f58ee88":"markdown","693927cf":"markdown","39bf3e8d":"markdown","3e1adce7":"markdown","bc28bd28":"markdown","0cb59b5f":"markdown","591aefcc":"markdown","073b2426":"markdown","377652d1":"markdown","67aab5ba":"markdown","b5911ff1":"markdown","954e2bfa":"markdown","5e8a5a05":"markdown","e10db770":"markdown","c7bbd7cc":"markdown","7c3dd47e":"markdown","e78c07e2":"markdown","b51ae2d0":"markdown","caf4f8fc":"markdown","5bb27d49":"markdown","834f0fb9":"markdown","7d587d28":"markdown","ab8f0577":"markdown","9190b5fe":"markdown","d0f3d172":"markdown","c203c3ea":"markdown","ee00c338":"markdown","e3b93b9a":"markdown","12e98ad5":"markdown","44a724f9":"markdown","af964187":"markdown","8ee65f5b":"markdown","6f765fe3":"markdown","fe4f648f":"markdown","458a9324":"markdown","36a9895b":"markdown","e4ef2ad7":"markdown","ff067fa1":"markdown","3b692f89":"markdown","f6fff2eb":"markdown","4390e9f9":"markdown","4cf1eebc":"markdown","a000903f":"markdown","21986687":"markdown","d244bdda":"markdown","21396252":"markdown","09218448":"markdown","d4c9773e":"markdown","83a5c6e3":"markdown","a7352898":"markdown","a73ab8d5":"markdown","64236624":"markdown","cd6703b0":"markdown","a59bf8f2":"markdown","da59aca7":"markdown","df8e0478":"markdown","09d9424c":"markdown","c614f02e":"markdown","5c025f97":"markdown","0d3b360e":"markdown","39c0a312":"markdown","d463e7c2":"markdown","04e83e44":"markdown","242e8b66":"markdown","0cbb3440":"markdown","dce3f38b":"markdown","e6fce204":"markdown","a3ff12fe":"markdown","84a3d773":"markdown","e556ba99":"markdown","d90c1b20":"markdown","79a74946":"markdown","0d52f645":"markdown","dd8fd614":"markdown","32f825ac":"markdown","5aeb9a0c":"markdown"},"source":{"2db292e6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bbc507a3":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotly.offline import iplot,init_notebook_mode\ninit_notebook_mode()\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom plotly import tools","03265412":"vgb_df = pd.read_csv('\/kaggle\/input\/youtube\/GBvideos.csv',encoding  ='utf8',error_bad_lines = False)","4b1992e1":"vgb_df.head()","ece0a7d0":"cgb_df = pd.read_csv('..\/input\/youtube\/GBcomments.csv',encoding='utf8',error_bad_lines = False)","1b0a7f72":"cgb_df.head()","ffcddd3c":"vgb_df.describe()","27b5866c":"vgb_cols = vgb_df.columns","cef50241":"print(vgb_cols)","0dc13f84":"vgb_df.info()","27c57d6b":"for i in vgb_cols:\n    if (vgb_df[i].isna().sum()>0):\n        print(i)\n    else:\n        print('No nulls in '+i)","0610e724":"cgb_df.info()","b0e68a9c":"cols = cgb_df.columns\nfor i in cols:\n    if(cgb_df[i].isna().sum()>0):\n        print(i+': '+ str(cgb_df[i].isna().sum() ))\n    else: \n        print('No null in '+i)","bbf9456b":"cgb_df.describe()","596aa3c2":"cgb_df.loc[cgb_df['comment_text'].isna()].video_id.unique().shape","19666146":"# Drops rows in the dataframe \ncgb_df = cgb_df.dropna()","e54c3905":"cols = cgb_df.columns\nfor i in cols:\n    if(cgb_df[i].isna().sum()>0):\n        print(i+': '+ str(cgb_df[i].isna().sum() ))\n    else: \n        print('No null in '+i)","8f94ab69":"vgb_df.head()","08022d01":"import datetime\ndef formatDate(date):\n    day,month = list(map(lambda x:int(x),\"{:.2f}\".format(date).split('.')))\n    x=datetime.datetime(2017,month,day)\n    return x.strftime(\"%Y-%b-%d\")","0378ed6b":"vgb_df['date']","9552432c":"vgb_df['date']=vgb_df['date'].apply(formatDate)","0fb98a1a":"vgb_df.head()","068cc53a":"def Bar_plot(x_data,y_data,title,x_title,y_title,color='rgb(55, 83, 109)',hovertext=None):\n    trace = go.Bar(x=x_data,y=y_data,marker_color=color,hovertext =hovertext)\n    layout = {'title':title,'xaxis':{'title':x_title},'yaxis':{'title':y_title},'template':'plotly_dark'}\n    data = [trace]\n    fig = go.Figure(data=data,layout=layout)\n    iplot(fig)\n    ","2b5e80b7":"x=vgb_df['date'].unique()\ny=list(vgb_df['date'].value_counts()[vgb_df['date'].unique()])\ntrace = go.Bar(x=x,y=y,marker_color='#fe9500')\nlayout = {'title':'Number of Videos per day','xaxis':{'title':'dates'},'yaxis':{'title':'Number of videos per day'},'template':'plotly_dark'}\ndata = [trace]\nfig = go.Figure(data=data,layout=layout)\niplot(fig)","a0e67e0a":"x=vgb_df.groupby(['video_id'])[['video_id']].count()\nx.shape","2247db20":"min = x.min()['video_id']\nmax = x.max()['video_id']\nx_data = []\ny_data = []\nhover_data = []\nfor j in range(min,max+1):\n    count = 0\n    x_data.append(j)\n    for i in x.iterrows():\n        if(i[1]['video_id']>=j):\n               count = count + 1\n    y_data.append(count)\n    hover_data.append(str(count\/x.shape[0]*100)+\" % of videos\")","4b32e440":"Bar_plot(x_data,y_data,'Number of videos present Based on different Thersholds','Thershold','Number of Videos',hovertext = hover_data,color='#fe9500')","b1b731d1":"vgb_df.head()","cdbda0c1":"print(\"There are \"+str(vgb_df['channel_title'].unique().size)+\" from where the 1736 videos are produced we assume that from one channel there are multiple videos are produced\")","5bacde19":"x= vgb_df.groupby(['channel_title']).size()","b3d8224d":"max = x.max()\nmin = x.min()\ndata = []\nfor j in range(min,max+1):\n    count = 0 \n    for i in x.axes[0]:\n        if (x[i]==j):\n            data.append(j)","ebb6687f":"counts, bins = np.histogram(data, bins=range(min,45, 5))\nbins = 0.5 * (bins[:-1] + bins[1:])\ntrace = go.Bar(x=bins,y=counts ,marker_color = '#fe9500')\ndata = [trace]\nlayout = {'title':'Number of days a unique channel is in trending status','xaxis':{'title':'Days'},'yaxis':{'title':\"count\"},'template':'plotly_dark'}    \niplot({'data':data,'layout':layout})","0ae89475":"channel_titles = {i:0 for i in vgb_df['channel_title'].unique()}\nseries =vgb_df.groupby(['channel_title','video_id'])['video_id'].count()","0c6b0be5":"for i in series.axes[0]:\n    channel_titles[i[0]] = channel_titles[i[0]]+1 ","ee730611":"values = []\nchannels = []\nfor i in channel_titles.keys():\n    value = channel_titles[i]\n    if (value > 1):\n            channels.append(i)\n            values.append(value)\nvalues_ = []\nfor i in set(values):\n    count = 0 \n    for j in values:\n        if (i==j):\n            count = count + 1 \n    values_.append(count)  ","3f318294":"trace = go.Bar(x=values_,y=list(set(values)),orientation='h',marker_color ='#fe9500')\ndata = [trace]\nlayout = ({'template':'plotly_dark','title':'Number of Channels Uploaded Multiple Trending Videos','xaxis':{'title':'Number of channels'},'yaxis':{'title':'Number of videos'}})\niplot({'data':data,'layout':layout})","68c5f18c":"vgb_df.head(2)","e4f670b7":"df = pd.read_json('..\/input\/youtube\/GB_category_id.json')","5ae8092c":"categories = {}\nfor i in range(df.shape[0]):\n    categories[df.iloc[i]['items']['id']] = df.iloc[i]['items']['snippet']['title']\ncategories['29'] = 'unknown'\nvgb_df['category'] = [categories[str(i)] for i in vgb_df['category_id']]","db88bbdb":"vgb_df.head()","125985d0":"categories_ = vgb_df['category'].value_counts()\nnorm_cat = [i*100 for i in list(vgb_df['category'].value_counts(normalize = True))]\ncat_names = categories_.axes[0]\nvalues = list(categories_)\ntrace = go.Bar(y=cat_names,x=values,marker_color='#fe9500',orientation='h',hovertext = norm_cat)\ndata = [trace]\nlayout = {'title':'Trending Videos Categories','xaxis':{'title':'Number of videos belongs to respective categories are in trending status'},'yaxis':{'title':'Categories'},'template':'plotly_dark'}\niplot({'data':data,'layout':layout})","5d208021":"from collections import Counter\nfreq = Counter(list(vgb_df.groupby(['category','video_id'])['video_id'].count().axes[0].to_frame()['category']))\ncategories=freq.keys()\nvalues = freq.values()\nhover_text = (np.array(list(values))\/(np.array(list(values)).sum()))*100\ntrace = go.Bar(x=list(categories),y=list(values),marker_color='#fe9500',hovertext = hover_text)\ndata = [trace]\nlayout = {'title':'Trending Videos Categories','xaxis':{'title':'Categories','categoryorder':'total descending'},'yaxis':{'title':'Count'},'template':'plotly_dark'}\niplot({'data':data,'layout':layout})","b663518d":"dates = vgb_df['date'].unique()\ngroups  = vgb_df.groupby(['date','category']).size()\ncategories =  vgb_df['category'].unique()\ndict = {}\ndict2 = {}\nfor i in categories:\n    dict[i] = []\n    for j in dates:\n        try:\n            dict[i].append(groups[j][i])\n        except:\n            dict[i].append(0)\nfig = go.Figure()\nfor i in dict:\n#     print(\"on an average \"+ str(np.array(dict[i]).mean()) + \" this \"+ i + \" category\")\n    dict2[i]=np.array(dict[i]).mean()\n    fig.add_trace(go.Bar(x=dates , y=dict[i],name = i))\nfig.update_layout(barmode='stack',template = 'plotly_dark',title = \"Every Trending Videos Stats Based on Categories\")\nfig.show()","a3ab672e":"import plotly.graph_objects as go\nlabels = list(dict2.keys())\nvalues =list(dict2.values())\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3)])\nfig.show()","b2a9ad42":"vgb_df.head(2)","c24ac15e":"vgb_df['channel_title'].unique().shape","3d4c3228":"from collections import Counter\ndata = Counter(vgb_df['channel_title']) \ndata1 = {i : data[i] for i in data if data[i]>1 }\ndf = pd.DataFrame({'Channel':list(data1.keys()),'Counts':list(data1.values())})\nfig = px.sunburst(df.loc[df['Counts']>10],path =['Counts','Channel'],width = 750, height = 750,title='Channels With videos in trending status for >10 days', color_discrete_sequence=px.colors.qualitative.T10,\n)\nfig.show()","dd0101fe":"details_df = pd.read_csv('..\/input\/gbvideo-details\/GBVideo_details.csv')\ndetails_df.head()","83f30845":"fig = px.sunburst(df.loc[df['Counts']>=30],path =['Counts','Channel'],width = 750, height = 750,title='Top Channels In Trending status for >=30 days ', color_discrete_sequence=px.colors.qualitative.T10,\n)\nfig.show()","66b91085":"data = {i:vgb_df.groupby('channel_title').get_group(i).groupby('title').size().count() for i in list(df.loc[df['Counts']>=30]['Channel'])}\ntext = [list(df['Counts'][df['Channel']==i]) for i in data.keys()]\ndata = [go.Bar(x=list(data.keys()),y=list(data.values()),marker_color = 'orange',hovertext =np.array(text).reshape(len(text)))]\nlayout = {'template':'plotly_dark','xaxis':{'title':'Channel_Names','categoryorder':'total descending'},'yaxis':{'title':'Number of Videos'}}\niplot({'data':data,'layout':layout})","d989c9d2":"data = {i:vgb_df.groupby('channel_title').get_group(i).groupby('title').size().count() for i in list(df.loc[df['Counts']>=30]['Channel'])}\nnum_of_videos = {i:vgb_df.groupby('channel_title').get_group(i).groupby('title').size().count() for i in list(df.loc[df['Counts']>=30]['Channel'])}\nnum_of_days= np.array([list(df['Counts'][df['Channel']==i]) for i in data.keys()]).reshape(25)\nfamous_channels = pd.DataFrame({'channel_name':list(num_of_videos.keys()),'num_videos':list(num_of_videos.values()),'num_days':num_of_days})\ndict = {}\nfor i in famous_channels.iterrows():\n    dict[i[1][0]]=i[1][2]\/i[1][1]\nfamous_channels['rank'] =[dict[i] for i in famous_channels['channel_name']]\ntop_videos=famous_channels.sort_values('rank',ascending=False).reset_index()","9943362a":"# df.drop(columns=['B', 'C'])\n\ntop_videos.drop(columns=['index'])","936e8bb2":"channels_categories={i:vgb_df[['channel_title','category']].groupby('channel_title').get_group(i)['category'].unique() for i in famous_channels['channel_name']}\nfamous_channels['categories'] =[channels_categories[i] for i in famous_channels['channel_name']]\nfamous_channels.head(10)","dc933813":"dict = { i:0 for i in list(vgb_df['category'].unique())}\nfor i in list(famous_channels['categories']):\n    for j in i:\n        dict[j]=dict[j]+1","6c18c653":"iplot([go.Bar(x=list(dict.keys()),y=list(dict.values()))])","05df27be":"vgb_df.head()","1934bf84":"details_df.head()","76350832":"# For our intial analysis we don't need time so we can easily strip off the time part of the date so that it will be easy to compare two dates\n","29a1cf4b":"import datetime\nfrom dateutil.parser import parse\ndetails_df['published_date']=pd.to_datetime(details_df['published_date']).dt.date\nvgb_df['date']=pd.to_datetime(vgb_df['date']).dt.date","2e4270ff":"(vgb_df['date']-details_df['published_date'])[1001]","fb571660":"details_df['published_date'][1001]","fb3aaf36":"vgb_df['video_id'][1001]","d8120ee2":"details_df['video_id'][1001]","cb64b6b1":"vgb_df_ =pd.merge(vgb_df,details_df,on='video_id')","687a4983":"vgb_df_.drop('Unnamed: 0',inplace = True,axis = 1)","0b4da29d":"# Number of unique videos without the published date \nvgb_df_['video_id'][vgb_df_['description'].isna()].unique().shape","00871eee":"vgb_df_['video_id'][vgb_df_['description'].isna()].value_counts()","6b31b496":"videos = vgb_df['video_id'].unique()\nvideos","e936a35d":"details_df.dropna(inplace = True)","dc442e96":"groups = vgb_df.groupby('video_id')\ndates = {}\nfor i in videos:\n    if (details_df['published_date'][details_df['video_id']==i].any()):\n        dates[i]=(groups.get_group(i)['date'].sort_values().unique()[0]-details_df['published_date'][details_df['video_id']==i])","faea9491":"details_df.head()","d9704127":"days = []\nfor i in list(dates.values()):\n    days.append(list(i)[0].days)","617e9302":"fig = go.Figure()\nfig.add_trace(go.Box(y=days))\nfig.show()","7e9662b2":"vgb_df.head()","0b970fed":"groups = vgb_df.groupby('category')['likes']","2875c3d1":"traces = []\nfor i in vgb_df['category'].unique():\n    traces.append(go.Box(y=groups.get_group(i),name = i))\n    \niplot({'data':traces,'layout':{'title':'Likes in each category for Trending Videos','template':'plotly_dark'}})","3d43a94c":"vgb_df.head(10)","360c2033":"categories = { i:[] for i in vgb_df['category'].unique()}\ntraces = []\nvids = vgb_df['video_id'].unique()\nlikes = {}\ncount = 0 \nfor vid in vids:\n      likes[vid] = vgb_df[['likes','date']][vgb_df['video_id']==vid].sort_values('date').iloc[0]['likes']\n\nfor i in vids:\n        categories[vgb_df['category'][vgb_df['video_id']==i].iloc[0]].append(likes[i])\n        \n\nfor i in categories:\n    traces.append(go.Box(y=categories[i],name = i))\niplot({'data':traces,'layout':{'title':'Likes in each category for  videos when first came to trending status','template':'plotly_dark'}})","7e6b6009":"groups  = vgb_df.groupby('category')['likes','date','video_id']\nsdf= groups.get_group('Entertainment').groupby('video_id')['likes','date']\ndata = []\nfor i in groups.get_group('Entertainment')['video_id'].unique():\n    data.append(go.Scatter(x=sdf.get_group(i)['date'],y=sdf.get_group(i)['likes']))","0ab9c749":"iplot({'data':data,'layout':{'template':'plotly_dark','title':'Entertainment'}})","904cf34b":"from plotly.subplots import make_subplots\n\nfig = make_subplots(\n    rows=3, cols=3,\n    subplot_titles=( \"Music\", \"Comedy\", \"How to Style\",'People and Vlogs','Films and animation','sports','Education','Gaming','News and Politics'))\nsdf = groups.get_group('Music').groupby('video_id')['likes','date']\nfor i in groups.get_group('Music')['video_id'].unique():\n    fig.add_trace(go.Scatter(x=sdf.get_group(i)['date'],y=sdf.get_group(i)['likes']),row=1,col=1)\n    count = count +1\nsdf = groups.get_group('Comedy').groupby('video_id')['likes','date']\nfor i in groups.get_group('Comedy')['video_id'].unique():\n    fig.add_trace(go.Scatter(x=sdf.get_group(i)['date'],y=sdf.get_group(i)['likes']),row=1,col=2)\n\nsdf = groups.get_group('Howto & Style').groupby('video_id')['likes','date']\nfor i in groups.get_group('Howto & Style')['video_id'].unique():\n    fig.add_trace(go.Scatter(x=sdf.get_group(i)['date'],y=sdf.get_group(i)['likes']),row=1,col=3)\n\n\nsdf = groups.get_group('People & Blogs').groupby('video_id')['likes','date']\nfor i in groups.get_group('People & Blogs')['video_id'].unique():\n    fig.add_trace(go.Scatter(x=sdf.get_group(i)['date'],y=sdf.get_group(i)['likes']),row=2,col=1)\n    \n\nsdf = groups.get_group('Film & Animation').groupby('video_id')['likes','date']\nfor i in groups.get_group('Film & Animation')['video_id'].unique():\n    fig.add_trace(go.Scatter(x=sdf.get_group(i)['date'],y=sdf.get_group(i)['likes']),row=2,col=2)\n\n\nsdf = groups.get_group('Sports').groupby('video_id')['likes','date']\nfor i in groups.get_group('Sports')['video_id'].unique():\n    fig.add_trace(go.Scatter(x=sdf.get_group(i)['date'],y=sdf.get_group(i)['likes']),row=2,col=3)\n    \nsdf = groups.get_group('Education').groupby('video_id')['likes','date']\nfor i in groups.get_group('Education')['video_id'].unique():\n    fig.add_trace(go.Scatter(x=sdf.get_group(i)['date'],y=sdf.get_group(i)['likes']),row=3,col=1)\n    \n\nsdf = groups.get_group('Gaming').groupby('video_id')['likes','date']\nfor i in groups.get_group('Gaming')['video_id'].unique():\n    fig.add_trace(go.Scatter(x=sdf.get_group(i)['date'],y=sdf.get_group(i)['likes']),row=3,col=2)\n\nsdf = groups.get_group('News & Politics').groupby('video_id')['likes','date']\nfor i in groups.get_group('News & Politics')['video_id'].unique():\n    fig.add_trace(go.Scatter(x=sdf.get_group(i)['date'],y=sdf.get_group(i)['likes']),row=3,col=3)\n\nfig.update_layout({'template':'plotly_dark','height':1000,'width':2000,'title':'Likes of videos in different Categories over time'})    \nfig.show()\n","0f6453dc":"categories = { i:[] for i in vgb_df['category'].unique()}\nvids = vgb_df['video_id'].unique()\nviews = {}\ncount = 0 \ntraces = []\nfor vid in vids:\n      views[vid] =np.log(vgb_df[['views','date']][vgb_df['video_id']==vid].sort_values('date').iloc[0]['views']+1)\n\nfor i in vids:\n        categories[vgb_df['category'][vgb_df['video_id']==i].iloc[0]].append(views[i])\n        \n\nfor i in categories:\n    traces.append(go.Box(y=categories[i],name = i))\niplot({'data':traces,'layout':{'title':'Views in each category for videos when first came to trending status (LOG(Views))','xaxis':{'title':'Categories'},'yaxis':{'title':'log(Number of Views)'},'template':'plotly_dark'}})","ac6297a6":"categories = { i:[] for i in vgb_df['category'].unique()}\nvids = vgb_df['video_id'].unique()\nviews = {}\ncount = 0 \ntraces = []\nfor vid in vids:\n      views[vid] =(vgb_df[['views','date']][vgb_df['video_id']==vid].sort_values('date').iloc[0]['views'])\n\nfor i in vids:\n        categories[vgb_df['category'][vgb_df['video_id']==i].iloc[0]].append(views[i])\n        \n\nfor i in categories:\n    traces.append(go.Box(y=categories[i],name = i))\niplot({'data':traces,'layout':{'title':'Views in each category for videos when first came to trending status ','xaxis':{'title':'Categories'},'yaxis':{'title':'Number of Views'},'template':'plotly_dark'}})","457242aa":"categories = { i:[] for i in vgb_df['category'].unique()}\nvids = vgb_df['video_id'].unique()\nviews = {}\ncount = 0 \ntraces = []\nfor vid in vids:\n      views[vid] =np.log((vgb_df[['views','date']][vgb_df['video_id']==vid].sort_values('date',ascending = False).iloc[0]['views'])+1)\n\nfor i in vids:\n        categories[vgb_df['category'][vgb_df['video_id']==i].iloc[0]].append(views[i])\n        \n\nfor i in categories:\n    traces.append(go.Box(y=categories[i],name = i))\niplot({'data':traces,'layout':{'title':'Videos Views in Each category when every video last seen in trending status Log(Views) ','xaxis':{'title':'Categories'},'yaxis':{'title':'Number of Views'},'template':'plotly_dark'}})","3cd348ac":"groups  = vgb_df.groupby('category')['views','date','video_id']\nsdf= groups.get_group('Entertainment').groupby('video_id')['views','date']\ndata = []\nfor i in groups.get_group('Entertainment')['video_id'].unique():\n    data.append(go.Scatter(x=sdf.get_group(i)['date'],y=np.log(sdf.get_group(i)['views'])))","b01b4046":"iplot({'data':data,'layout':{'template':'plotly_dark','title':'Entertainment','xaxis':{'title':\"Treding Dates\"},'yaxis':{'title':'Log(Views)'}}})","de373de9":"from plotly.subplots import make_subplots\n\nfig = make_subplots(\n    rows=3, cols=3,\n    subplot_titles=( \"Music\", \"Comedy\", \"How to Style\",'People and Vlogs','Films and animation','sports','Education','Gaming','News and Politics'))\nsdf = groups.get_group('Music').groupby('video_id')['views','date']\nfor i in groups.get_group('Music')['video_id'].unique():\n    fig.add_trace(go.Scatter(x=sdf.get_group(i)['date'],y=sdf.get_group(i)['views']),row=1,col=1)\n    count = count +1\nsdf = groups.get_group('Comedy').groupby('video_id')['views','date']\nfor i in groups.get_group('Comedy')['video_id'].unique():\n    fig.add_trace(go.Scatter(x=sdf.get_group(i)['date'],y=sdf.get_group(i)['views']),row=1,col=2)\n\nsdf = groups.get_group('Howto & Style').groupby('video_id')['views','date']\nfor i in groups.get_group('Howto & Style')['video_id'].unique():\n    fig.add_trace(go.Scatter(x=sdf.get_group(i)['date'],y=sdf.get_group(i)['views']),row=1,col=3)\n\n\nsdf = groups.get_group('People & Blogs').groupby('video_id')['views','date']\nfor i in groups.get_group('People & Blogs')['video_id'].unique():\n    fig.add_trace(go.Scatter(x=sdf.get_group(i)['date'],y=sdf.get_group(i)['views']),row=2,col=1)\n    \n\nsdf = groups.get_group('Film & Animation').groupby('video_id')['views','date']\nfor i in groups.get_group('Film & Animation')['video_id'].unique():\n    fig.add_trace(go.Scatter(x=sdf.get_group(i)['date'],y=sdf.get_group(i)['views']),row=2,col=2)\n\n\nsdf = groups.get_group('Sports').groupby('video_id')['views','date']\nfor i in groups.get_group('Sports')['video_id'].unique():\n    fig.add_trace(go.Scatter(x=sdf.get_group(i)['date'],y=sdf.get_group(i)['views']),row=2,col=3)\n    \nsdf = groups.get_group('Education').groupby('video_id')['views','date']\nfor i in groups.get_group('Education')['video_id'].unique():\n    fig.add_trace(go.Scatter(x=sdf.get_group(i)['date'],y=sdf.get_group(i)['views']),row=3,col=1)\n    \n\nsdf = groups.get_group('Gaming').groupby('video_id')['views','date']\nfor i in groups.get_group('Gaming')['video_id'].unique():\n    fig.add_trace(go.Scatter(x=sdf.get_group(i)['date'],y=sdf.get_group(i)['views']),row=3,col=2)\n\nsdf = groups.get_group('News & Politics').groupby('video_id')['views','date']\nfor i in groups.get_group('News & Politics')['video_id'].unique():\n    fig.add_trace(go.Scatter(x=sdf.get_group(i)['date'],y=sdf.get_group(i)['views']),row=3,col=3)\n\nfig.update_layout({'template':'plotly_dark','height':1000,'width':2000,'title':'Views of videos in different Categories over time'})    \nfig.show()\n","e2be672d":"categories = { i:[] for i in vgb_df['category'].unique()}\nvids = vgb_df['video_id'].unique()\nviews = {}\ncount = 0 \ntraces = []\nfor vid in vids:\n      views[vid] =np.log((vgb_df[['views','date']][vgb_df['video_id']==vid].sort_values('date',ascending = False).iloc[0]['views'])-(vgb_df[['views','date']][vgb_df['video_id']==vid].sort_values('date',ascending = True).iloc[0]['views'])+1)\n\nfor i in vids:\n        categories[vgb_df['category'][vgb_df['video_id']==i].iloc[0]].append(views[i])\n        \n\nfor i in categories:\n    traces.append(go.Box(y=categories[i],name = i))\niplot({'data':traces,'layout':{'title':'Number of Views videos in each category got while the videos are in trending status','xaxis':{'title':'Categories'},'yaxis':{'title':'LoG(Number of Views)'},'template':'plotly_dark'}})","0b57b8c3":"vgb_df.head()","ef86720c":"f, axes = plt.subplots(4, 4, figsize=(20, 20), sharex=True)\ncats = vgb_df['category'].unique()\ncount = 0 \n# plt.title('')\nfor i in range(4):\n    for j in range(4):\n        if (count<15):\n            x=pd.Series(categories[cats[count]], name=cats[count])\n            sns.distplot(x,ax = axes[i,j])\n        count = count +1\nplt.tight_layout()                \nplt.show()","0111a0de":"vgb_df.head()","403c9a5f":"categories = { i:[] for i in vgb_df['category'].unique()}\nvids = vgb_df['video_id'].unique()\ndislikes= {}\ncount = 0 \ntraces = []\nfor vid in vids:\n      dislikes[vid] =np.log((vgb_df[['dislikes','date']][vgb_df['video_id']==vid].sort_values('date').iloc[0]['dislikes'])+1)\n\nfor i in vids:\n        categories[vgb_df['category'][vgb_df['video_id']==i].iloc[0]].append(dislikes[i])\n        \n\nfor i in categories:\n    traces.append(go.Box(y=categories[i],name = i))\niplot({'data':traces,'layout':{'title':'Dislikes in each category for videos when first came to trending status ','xaxis':{'title':'Categories'},'yaxis':{'title':'Number of Dislikes'},'template':'plotly_dark'}})","a5f5ea2c":"categories = { i:[] for i in vgb_df['category'].unique()}\nvids = vgb_df['video_id'].unique()\ndislikes= {}\ncount = 0 \ntraces = []\nfor vid in vids:\n      dislikes[vid] =np.log((vgb_df[['dislikes','date']][vgb_df['video_id']==vid].sort_values('date',ascending = False).iloc[0]['dislikes'])+1)\n\nfor i in vids:\n        categories[vgb_df['category'][vgb_df['video_id']==i].iloc[0]].append(dislikes[i])\n        \n\nfor i in categories:\n    traces.append(go.Box(y=categories[i],name = i))\niplot({'data':traces,'layout':{'title':'Dislikes in each category for videos when Last seen in trending status ','xaxis':{'title':'Categories'},'yaxis':{'title':'Log(Number of Dislikes)'},'template':'plotly_dark'}})","f2664ef0":"vgb_df.head()","aca9ae9d":"df = vgb_df[['video_id','category','date','views','likes','dislikes','comment_total']]","b867aa1a":"import time\ndetails_df['duration'].iloc[0]","68b638f2":"!pip install duration\n","3e06235d":"from duration import (\n    to_iso8601,\n    to_seconds,\n    to_timedelta,\n    to_tuple,\n)","8b2ce67d":"!pip install isodate\nimport isodate","c8fe3b6f":"def fun(duration):\n    time = isodate.parse_duration(duration)\n    return time.total_seconds()","1a77e6d9":"details_df['duration_sec'] = details_df.duration.apply(fun)","36102f50":"details_df.head()","353a96fd":"details_df.duration_sec.describe()","7d4bf57f":"df","49f90347":"df_ = details_df[['video_id','published_date','duration_sec']]","d3d555dd":"new_df = pd.DataFrame(columns = df.columns)","2773cefa":"ids = df.video_id.unique()\ngroups = df.groupby('video_id')\nfor id in ids:\n    new_df=new_df.append(groups.get_group(id).sort_values('date').iloc[0],ignore_index=True)","dcaf7f08":"new_df","fb9edc20":"grouped_df = pd.merge(new_df,df_,on='video_id',how = 'left')","b0cb8195":"grouped_df['num_of_days'] = grouped_df.date - grouped_df.published_date","44e131ad":"grouped_df.head()","4965d76d":"grouped_df.num_of_days = grouped_df.num_of_days.fillna(grouped_df.num_of_days.median())","235f86f1":"grouped_df.duration_sec =grouped_df.duration_sec.fillna(grouped_df.duration_sec.mean())","40e08d64":"grouped_df.head()","d65d82c8":"final_df = grouped_df[['category','views','likes','dislikes','comment_total','duration_sec','num_of_days']]","c06013be":"final_df.head()","4a9fc7c4":"final_df.info()","6791914e":"final_df['num_of_days']=final_df['num_of_days'].apply(lambda x: x.days)","f9947bb8":"from sklearn.preprocessing import OneHotEncoder","e6a20fb1":"enc = OneHotEncoder(handle_unknown='ignore')\nenc.fit(np.array(final_df['category']).reshape(-1,1))","63edbb5c":"encodings = enc.transform(np.array(final_df['category']).reshape(-1,1)).toarray()","9d7ecd5b":"from sklearn.preprocessing import StandardScaler\n\nscaler  = StandardScaler()\nscaler.fit(final_df[['views','likes','dislikes','comment_total','duration_sec','num_of_days']])\n","022a4c30":"data = scaler.transform(final_df[['views','likes','dislikes','comment_total','duration_sec','num_of_days']])","d7933375":"scaler.mean_","26fcf2f1":"model_data = np.concatenate((data,encodings),axis = 1)","6e0c482e":"from sklearn.cluster import KMeans\ndict = {}\nfor i in range(5,30):\n    kmeans = KMeans(n_clusters = i)\n    kmeans.fit(data)\n    dict[i] = kmeans.inertia_\nsns.lineplot(x=list(dict.keys()),y=list(dict.values()))\nplt.show()","6f870ad7":"kmeans = KMeans(n_clusters = 20,n_init=10)\nCounter(kmeans.fit_predict(data))\n# data.shape","1dd76a06":"kmeans.inertia_","762e5763":"kmeans.predict(data[8].reshape(1,-1))","b84bc8c6":"final_df['predicts'] = kmeans.predict(data)","e724ca58":"final_df.head()","b319d4c7":"final_df.loc[(final_df['category'] == 'Music') & (final_df['predicts'] == 12)].tail(25)","efe9efa0":"final_df.groupby('predicts').get_group(12)[['views']].describe()","61b11021":"sns.boxplot(x=list(final_df['comment_total'][final_df['predicts']==0]))","93388ab0":"[go.Box(y=list(final_df['views'][final_df['predicts']==24]))]","e9a69698":"final_df['views'][final_df['predicts']==12]","ce53b73d":"from sklearn.manifold import TSNE\nmodel = TSNE(n_components = 2,n_iter=10000,random_state=43)\ntsne_data = model.fit_transform(data)","21395731":"x = []\nfor vid in grouped_df['video_id']:\n    x.append(vgb_df[['views','date']][vgb_df['video_id']==vid].sort_values('date',ascending = False).iloc[0]['date']-(vgb_df[['views','date']][vgb_df['video_id']==vid].sort_values('date',ascending = True).iloc[0]['date']))\nx = list(map(lambda x:x.days+1,x))","cbdbee69":"final_df['trending_days'] = x","1d2cd9e8":"del dict\niplot({'data':go.Scatter(x=tsne_data[:,0],y=tsne_data[:,1],mode = 'markers',marker=dict(color = final_df['predicts']),hovertext=final_df['predicts'])})","d33cc6fd":"final_df.groupby('predicts')['duration_sec'].describe().sort_values('count',ascending = False).head(10)","6b69b098":"final_df[['views','likes','dislikes','comment_total']]=final_df[['views','likes','dislikes','comment_total']].astype('float')","1629073e":"final_df.groupby('predicts')[['views','trending_days']].describe().head(20)","2ca65be8":"type(final_df['duration_sec'][0])","7ccd9c83":"final_df.head()","de474ed7":"categories = final_df['category'].unique()\ngroups = final_df.groupby('category')\nlist = []\nfor i in categories:\n    list.append(go.Box(y=np.log(groups.get_group(i)['duration_sec']+1),name=i))\n    \niplot({'data':list,'layout':{'template':'plotly_dark','xaxis':{'title':'categories'},'yaxis':{'title':'LOG2(duration in sec)'}}})","fea56928":"vgb_df.head()","5bc84cb7":"channels_df = pd.read_csv('..\/input\/channel-details\/channel_details.csv')","f8d5c98d":"channels_df.head(10\n                )","0663a8cc":"channels_df[['subCount','title','videoCount']].sort_values('subCount').head(25)","fe2b9849":"\niplot({'data':[go.Box(y=channels_df['subCount'])]})","d7f3e2bd":"sns.distplot(np.log(channels_df['subCount']+1))\nplt.title('Channels Subscribers Distribution')\nplt.show()","c8dec3ed":"x = np.log(channels_df['subCount']+1)\nkwargs = {'cumulative': True}\nsns.distplot(x, hist_kws=kwargs, kde_kws=kwargs)\nplt.title('Cummulative Distribiution of subscribers')\nplt.xlabel('log2(subscribers)')\nplt.show()","1218662a":"# There are few channels where I am unable to get the channels details so I need to figure out an imputation strategy.","608928af":"dummy_df = pd.read_csv('..\/input\/channel-details\/video_new.csv')","f18692bd":"df2=channels_df.merge(dummy_df,on='channelId')","809b824f":"df2.head()","d2541ab1":"vgb_df.head()","a522524b":"df3 = vgb_df.merge(df2,how='left',on='video_id')[['channelId','channel_title','publish_date','viewCount_x','subCount','video_id','category','views','date','videoCount']]\n","e27be65c":"df3.head()","41697d1e":"data = dict(df3.channelId.value_counts())\nx = []\ny= []\nfor i in data.keys():\n    x.append(channels_df['subCount'][channels_df['channelId'] == i].iloc[0])\n    y.append(data[i])\n    \n","ee8d5d3b":"iplot({'data':go.Scatter(x=np.log(np.array(x)+1),y=y,mode='markers',hovertext = x),'layout':{'title':'Number of log(Subscriber Count) vs Number of Days channels are in trending status','xaxis':{'title':'log(subcount)'},'yaxis':{'title':'Number of days a channel in trending status'},'template':'plotly_dark'}})","9cd28a7d":"categories = vgb_df.category.unique()\ntraces = []\nfor i in categories:\n    traces.append(go.Box(y=np.log(np.array(df3['subCount'][df3['category']==i].dropna())+1),name=i))\n    \niplot({'data':traces,'layout':{'title':'Subscribers in Each Category','template':'plotly_dark','xaxis':{'title':'categories'},'yaxis':{'title':'log(subscribers)'}}})\n    ","ee2ca481":"vgb_df.head()","6be431cc":"df3.head()","1d24e184":"<p>This dataset consits of the Top 200 trending videos from the youtube and characteristics of those videos like number of likes , number of comments ,number of subscribers etc. . we can use these data to know which sort of videos are trending and how much time does it takes for the videos to come to treding statuts once they are uploaded and how long will they be in that position and what are comments on the videos etc.<\/p>","4467c2a1":"We can observe that most number of videos that are in trending status are from Entertainment,Music categories and least are from Travel and Events,Autos and vechiles etc ..,By this we can draw a small conclusion that people are  mostly in entertainment and music videos and there are even certain categories that are not even in trending status for one time. ","914e27e6":"* The above graph shows information about the distribution of views while the videos are in trending status\n* We can observe from the people are reciveing mostly vidoes from Entertainment and Music videos category as we can see they are as views of the videos can grow up to (2.71)^17.34 once they come into trending status.\n* This graph can be viwed in two ways in one way some videos will stay where they were as they first come to trending status , then thos videos will be in the lower quartile part , and some videos views can grow very high like Entertainment and Music category.\n* Travel and Events doesn't have very good growth in terms of videos views and same for the sports,Gaming,News and Politics as distribution is skwed to lower end of views for this categories.","48916da7":"###  Views:","84205dee":"### Adding categories Column to the data_frame ","3ebf4be3":"<p style = 'color: #386e9d'>This dataset consits of comments for the above metioned videos and they both are linked with using video_id<\/p>","827a9f20":"#### lets check which are the popular channels that are in trending status","5a42ece0":"### Lets Understand the Top Channels","6788861a":"<p>There are 28 missing values in the comments data and so we need to fill them or we need to delete them <\/p>","e27ada6d":"Out of 1003 unique youtube channels in the dataset , multiple videos from 304 channels are in trending status , may be other channels might not uploaded more videos or those channels might not be so famous as of these channels , and we can see from the graph from one channel there are like 16 videos that are in trending status which is really insane because the dataset is taken from very small timeperiod that is around 45 days and only from this channel alone there are 16 videos in trending status , so we need to focus on these kind of channels what made there videos so famous","f7bf6210":"*  The Above graph shows the information about channels that have more than videos that are in the trending status for >10 days in the given period of time.As we can see from the graph top videos are comming from the channels called <strong>The Tonight Show Starring Jimmy Fallon<\/strong> and <strong>First we Feast Channels<\/strong> This channels are in treding status for 40 , that means these may be because most people love content from these channel or may be these videos are uploaded long time ago and suddenly they came in to fame .\n* There are lots of possiblities to understand , why these channel videos are very famous . One thing is true that we need to get the video publish date on youtube that may add some value.\n* If we were able to get the video published date and time we can understand after how much time after the videos uploaded they typlically move to trending status . It is also helpful if we have information about the subscibers of the channels.Because that may also influence the popularity of the channel so we need to understand that as well \n* But here the problem with subscribers is these videos are uploaded three years back so we currently subsribers to the channel might be changed so we need to reduce the current subsribers by certain factor and we need to use it after getting the subscribers of the respective channels.","26bdbe38":"### Video Id","5d7c107b":"<p>Chainging the date to actual date format , I belive these data belongs to the year 2017 sep-october<\/p>","c18a6aa9":"* As we can observe from the graphs the videos likes are growing significantly once they come into trending status , and after few days the likes are getting saturated for each video and finally the video is getting removed from the trending status.However, these is not true for every video and as some videos are removed even if the likes are significantly increasing and some videos and kept if at all there is no change in the number of likes.So we need to consoder various other variables like comments and views and we need to come to a conclusion.\n\n* We can also observe from above graphs News and politics have very low number max likes i.e. 60 k compared to other categories.\n\n* Music , Comdey ,Entertainment,How to & style these are some of the categories very likes count of videos are high compared to other categories.","859eac7e":"<p>As we can see from the graph that the dataset contains information about vidoes from 13-sep-2017 to 22-oct-2017 and every day we have information about 200 videos and except for few days where we have close to 200 videos treding videos per day <\/p>","0bc7c44e":"### videos dislikes count when they first came in to trending status","c23deb49":"#### Now there are no null values in the dataframes . and we can proceed to Exploratory data analysis","1f012c59":"### creating a new dataset for clustering","23c251a2":"### Checking the same for all the category videos","41f7f4e8":"#### We need to compare intial trending date of the video with actual published date so that we can able to get actual statistics about how much time an average video takes to be in trending status","4f8b1831":"Now we can see that date columns have changed to actual dates ","361f7c33":"Checking number of unique videos in total in the dataset","63a13cd4":"### Channels That have More than One video in trending status","786e95dd":"## Let's Look Channel Titles:","e7da36dd":"If we zoom a bit we can clearily vidualize the graph that is almost every video that comes to trending status there views have incresed significantly for one or two days . And then started saturating , then after video is removed from the trending status","bd26027c":"### Checking for the null values in the data ","e39b09de":"### Checking the Categories from These Top Trending Channels Comes from ","38f81b8e":"<h4>Checking the videos that are in trending for more days in the given time period<\/h4>","a50d0a7e":"The above graph shows number of unique videos in trending status from different categories . We can observe from the graph that most of the videos that are in trending status are from Entertainment and Music , We can also see that. we can also see that the probaility of video from Entertaiment and music catergory is in trending status is high .","57462ecc":"* Above graph represent the videos distribution when they last see in trending status \n*  We can make a quick observation that is videos in from the Science and Technology category have improvment of views in videos compared to other categories , Auto and Vechicles as well \n* In Entertainment category there is a signifiant improvment in the top quartile range Comedy and Education does't have much significant improvment as we can observe from the graphs.\n* Highest number of views comes to the categories from the Entertainment and Music . And secnd most is Science and TEchnology and Comedy.\n","d605d293":"## Rank = Number of Days In Trending Status\/Number of Videos Uploaded","97d5ef71":"Above mentioned columns are present in the vgb_dataframe","dc649ae1":"### Loading data","10192d11":"There are 736 videos in 1700+ unique videos that is uploaded by only one channel.","e1ef409d":"### Now we are interseted in the number of days the channel in the trending status vs number  of subscribers does the channel have","e5a08cb6":"### We need to Check Number of Likes and Comments  and Views of videos:","9fc3d8a2":"### Let's see which categories they belongs to ","9f58ee88":"As we can observe above we don't have any null values in the Great Britain Dataset","693927cf":"There are 1736 unique videos in the dataset in total and we have 7000+ rows in total . This means lots of videos are repeated for more than one day","39bf3e8d":"<p>SO there are no null values in the vgb_df dataframe<\/p>","3e1adce7":"replacing all the null values with the median value for the dates","bc28bd28":"As we can see from the data from Tonight show starring Jimmy Fallon has lots of videos in trending status . If we hover over the bar graphs we can see how many days the channel is in trending status.\n\nThere are few channels like <strong>First we Feast<\/strong> , <strong>Jacks films<\/strong> these channels have few videos in the trending status compared to <strong>The Jimmy Fallon<\/strong> but there videos were in trending status for almost same time , that's quality over quantity . So I have ranked channels based on number of videos uploaded and number of days in the trending status ,if the number of days in the trending status are more and number of videos uploaded are less then that channel will be ranked as top channel compared to other channels.","0cb59b5f":"First I Chose to analyze the Great Britain YouTube Trending Videos","591aefcc":"Pandas apply function will apply the provided function on every element in the dataset","073b2426":"This dataset consists of the comments for the videos ","377652d1":"### Handling Missing Values : ","67aab5ba":"Distribution of Views when the youtube videos first came to trending status","b5911ff1":"If we expand this Box plot we can draw interesting conclusions like most of the videos,that comes to trending status may come with it 6 days after uploading where as few videos , after two,three,four years also they have ability to come to trending status , or may they might came more number of times before and they are coming now also,one videos took almost 3478 days after publishing to come to trending status.But most of the videos comes to trending status with in 1 week after uploading in to YouTube","954e2bfa":"* We can see from above graph that channels that have zero subscribers(which is really not the case as we can't get the information about the video channels) have videos in trending status for more days\n\n* As we can also observe from the graph there are channels with less number of subscriber count can also be able to come to trending status and there videos are there in trending status for max(10) days\n\n* Most important observation we can draw here is more number of days i.e >10 days videos in trending status from the channels that have more number of subscribers that comes from the second part of the graph ","5e8a5a05":"<h3 '>Loading Data<\/h3>","e10db770":"IN the missing published date videos there are some trending videos that are trending for more than 10 days","c7bbd7cc":"Lets See what is range of subscribers look like for these channels","7c3dd47e":"<p>Now we have clean data frame we need to understand the patterns in the data like why the videos are categorized as top trending videos and what are the characteristics that make them top videos what are the comments for the videos look like and how many days a video is in trending status before it is removed etc...<\/p>","e78c07e2":"*  As we can see there are only few channels as some channels have been removed from the youtube i.e almost 100 channels I unable to find information about those channels","b51ae2d0":"### Checking likes,dislikes and comments of videos based on each category","caf4f8fc":"Views and Dislikes might influence a lot  to video be in trending status","5bb27d49":"As we can see after ranking in this way <strong>To Night starring Jimmy Fallon<\/strong> reached last in the table compared to another channels were few videos are in the trending status but for long time they were in that position.","834f0fb9":"The category each videos is belonged to is stored in the dataset GB_category_id.json file , so we can use that data to understand from which catergory does most trending videos comes from . In json file information about category Id 29 is not metioned so I am cosidering as unknown category for now.","7d587d28":"There are 16 videos in total where the comments are missing . as these are not completely belongs to one dataframe and they doesn't add any values to the data so we can drop the rows that doesn't have any values ","ab8f0577":"These channels above are very famous youtube channels as videos from these channels are in trending status for more than or equal to 30 days","9190b5fe":"<p style='color: #386e9d'>This dataframe consists data about video information likes,dislikes and comment_total and date information etc..<\/p>","d0f3d172":"### Number of Videos Per Day Are In Trending Status","c203c3ea":"<p>As we can see in the data the mean like for the comments around 5 and maximum likes for a single comment is 60630 which is very high and seems like an outlier so we need to understand why that occured <\/p>","ee00c338":"### Ranking Channels Based on the Number of Videos in the Trending status and Number of Days they are in Trending status","e3b93b9a":"### Lets Consider distribution of subscribers in different categories","12e98ad5":"* The above distrbutions are the logithmic distributions of views when the videos first came to trending status .\n* As we can observe from the graphs above almost all the video from different categories have min value of 2.71^(7.2) as min value in order to get into trending status\n* Categories like education , Science and Technology,Travel and Events,Auto and Autos and Vehicles need more number of views compared to other categories in order to get into the trending status\n* Where as categories like sports and People and Blogs required to very less number of views compared to above mentioned categories.\n* It seems like YouTube is encouranging more videos from Music,People and Blogs,Entertainment etc.. in to trending status eventhough they have less number of views intially as we mentioned above other categories need to have higher views in order to get in to the trending status","44a724f9":"## Exploratory Data Analysis","af964187":"* One thing we can immediately infer from the above graph is that most of the categories likes science and tech ,film and anumation , education ,Howto&style,perts and animals , particularily from these categories channels from video come in to the trending status have more than 2.71^12 subscribers \n\n* And channels from the comedy category have most number of subscribers , however videos in this categoery also come from lower end of the subscribers as well ,\n* It channels that are producing trending videos have about 2.71 ^10 subs , except from popular categories like entertainment,people and blogs ,Music as these are categories from which most percentage of the trending videos come so videos from channels that have low number of subscribers are allowed here .\n* But if the video belongs to other categories then the videos must have atleast 2.71^10 subscribers to improve the chances of getting into the trending status otherwise it is very unlikely.","8ee65f5b":"There are 181 unique videos in total without the actual published date as there videos are deleted from the YouTube currently","6f765fe3":"### Line plot to see the transition of likes in each category video","fe4f648f":"* It can be observed from the graph music vidoes typically  have the duration range between , 2.71^4.77 to 2.71^6.15 and very few videos have higher than that which may be outliers.\n* Howto&style videos typically have high durations compared to other categories and people & Blogs","458a9324":"Box Plots for mean and median..","36a9895b":"### Null values in cgb_df","e4ef2ad7":"<p>There is information about 7993 trnding videos in the dataset. The intresting information we can understand from the dataset is that there are few videos with 0 comments and likes and views are also categorized as trending so we need to understand what made this videos to become trending or else may be they are outliers. We can also see that max dislikes for a video is 192725 dislikes which is very high for a trending video so we need to understand why this disliked videos are placed in trending list.Another thing we can observe is that there are 8lakhs comments for a video which is very high we need understand what type of video is it <\/p>","ff067fa1":"There are 28 null values in the comment text of the videos","3b692f89":"### Now let's see how the distributions look like once the videos Moving away from trending status","f6fff2eb":"## Distribution of Log(Views) in each category once the video get in to trending status","4390e9f9":"* Untill Now we have considered all the possible attributes like view count,dislike count , like count , duration of the video and But we hven't considered the subscribers of the channel as  if the number of subsribers are high for a channel that means when they upload a video that video will be watched by lots of people immdiately by notification and if the video comes from a top trending channel then the video will immediatley gain high popularity . \n\n* May be based on this characterisitic that determines the video status.\n\n\n","4cf1eebc":"* As we can see from the above graphs there are videos in each category that are in trending status even with zero likes \n\n* We can also observe that videos from the News and politics category have very few number of likes comapred to all other categories \n\n* The Number of likes for music videos is very high compared to other videos but as we have seen before number of videos in the trending category are more from Entertainment category only.\n\n* But this graph is not relavent because we have only 1739 unique , every video is repeated many number of times so as there like so we need to consider only likes of videos only at the end dates and start date so we can understand the number of likes have improved once they come to trending status and , And if we consider the start date we can understand at how likes they came in to trending status. \n\n* These will be relevant if we understand with the line charts so let's try","a000903f":"### Let's see Dislikes for the videos in each category","21986687":"#### 1.Checking which category does trending videos belongs to ","d244bdda":"* As we can observe from above three graphs that more than 80% videos have 2.71^(13) subscribers.By which we can infer that most of the videos coming to trending status have high subscriber count .\n\n* There are few channels with zero subscribers which is not true because certain channel have hidden their scubscribers so they youbute ApI have return zero for those channels \n\n* There are channels with low number of subscribers in the trending status so now we need to consider how many days does videos from these channels are in trending status\n","21396252":"We can observe from the table that the category of the videos are classified based on the video it's not based on the channel, because as we can see from the above table videos comes from single channel are classified in to multiple categories","09218448":"### Checking the likes of trending videos when they first came to trending status","d4c9773e":"### Let's Explore the Category Column","83a5c6e3":"### Let's Check the Channel Title's","a7352898":"In order to analyze that I have collected data about the subscribers of each channel . However the subscribers of each channel that I have got is not relevant as the videos are from 3 years back so It may not be relevant but can be used for certain point as we were unable to get the pervious data now ","a73ab8d5":"* It seems like eventhough the videos are disliked they still come in to trending status\n* As we can see videos from education,news and politics,Science and technology and Howto & Style videos defintely have dislikes compared to other categories \n* Comedy,Music,Entertainment videos have more number of dislikes compared to other categories and still be able to make in to the trending status","64236624":"### Average number of views videos in each category gets when they were in trending status:","cd6703b0":"The above graph shows number of number of views per videos when they first came to trending status in the given days.\n","a59bf8f2":"Lets Understand the Top channels from which  30 or more than 30 videos are in trending status ","da59aca7":"Now selecting only features needed for clustering category,date,views,likes,dislikes,comment_total,published_date,duration_sec,num_of_days to get in to trending status","df8e0478":"As we can observe from the dataset information there are about 71,000 + comments in the dataset","09d9424c":"The above donut graph shows information about average number of trending videos from each category for a given period of time.On average every day most of the videos comes from Entertainement,How to style ,People and Blogs.Music.So from all these graphs we can observe that most trending videos comes from entertainment,music,How to style etc..","c614f02e":"### Likes Count","5c025f97":"### Understanding Duration of Videos in Each Category","0d3b360e":"#### Entertainment category","39c0a312":"Exploratory data analysis is all about understanding more information about the data and making sense of the data whether is it feasible to use for modeling or not.","d463e7c2":"* These are the graph is not different from the graphs on the above these graph represents videos likes when the first came on to trending status.the videos have likes as low as 0 likes and high in millions.Music videos category have highest number of likes . and entertainment category have second hiesht number of likes and other categories have low likes.\n\n* And music category have getting high probality of likes.Compared to other categories\n\n* Even though videos from music category have highest number of likes , videos from comedy category have higher number of likes below 50% compared to other catgories","04e83e44":"From the above dataset we don't need channel title , tags , thumbnail features for now ","242e8b66":"* We can observe that in each and every category there are few videos where there is  less improvment in the number of views \n* Entertainment , Music have distributions shifted towards right side which shows that,the videos from these category can have more number of views once the videos come in to trending status\n* videos from Auto & vechicles shows definte improvment in the views\n* We can also see that all categories videos views distributions seems to be normally distributed , however with different kurtosis","0cbb3440":"### Unique Trending Videos and Categories","dce3f38b":"The above graph shows every day stats of trending videos based on the categories they belongs to.We can see from the graph on an average every day atleast 35 videos are from the Entertainment category and it is dominating all other categories each and every day","e6fce204":"### Let's start with date column:","a3ff12fe":"As we can observe from the above graph the likes for the videos significantly increases when they first comes to trending status and videos will be in the trending status untill all the same continues , over a time as the likes get saturated and finally becomes flat then the video will be removed from the trending videos.However some videos are in trending status for only one day , will still need to understand why this is the case","84a3d773":"### Average Amount of Time It Takes For a Video To Come In To Trending Status","e556ba99":"* As most of the vidoes that are in trending status comes from Music , Entertatinment category , still we cannot strongly concude that there is a high probability that if a video is uploaded to these following categories will be in trending status because we don't have information about acutal number of videos being uploaded to each category. \n\n* It many be possible that lots of videos are beign uploaded to this categories but only few of them are ending up in trending status. On the other hand many of the videos it might be possible less number of videos might be uploaded to the categories like Education,Science and Tech and still be able to make a way into trending videos.\n\n* But from given data we can conclude that most trending videos comes from Entertainment related categories","d90c1b20":"This is a new dataframe details_df consists of information about the time video have uploaded,description of the video and duration of the video . This data is not present the actual dataset, so I made use of youtube Api to get the data .\nUnfortuantely these dataset is from the year 2017 some the videos present in the dataset have been deleted . So I am unable to get some videos details.","79a74946":"From 0 to 5 days videos from 463 channels videos are in trending status , from  5-10 days videos from  325 different channels are in trending status and videos from 8 channels are in trending status for more than 35 days.This 8 channels can be considered as more popular channels because this channels are in trending status for more days , we can think in either way i.e may be more vidoes are uploaded from these channels and all vidoes came in to trending status , or may be only one popular video is trending for more days that also can be the case.","0d52f645":"As we can see there are 1736 unique videos in the dataset and and from them 51% of videos are trending for more then 5 times and only 4 videos are treding for more than 11 days from which 2 videos in the dataset are in the trending list for 12 days and that's the higest number of days a video is in trending status in the given time period","dd8fd614":"As we have seen before there are 1003 unique youtube channels and from them multiple vidoes are in trending status from almost 300+ youtube channels so we now we need to figure out what are those youtube channels where most of the trending videos comes from and whcich categories does this channels belongs.","32f825ac":"### Applying KMEANS CLUSTERING TO CLUSTER THE VIDEOS That have similar properties:","5aeb9a0c":"<h3>Quick View of Data<\/h3>"}}