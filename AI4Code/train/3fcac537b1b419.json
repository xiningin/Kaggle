{"cell_type":{"a01892d6":"code","50ea0be7":"code","1bc909c1":"code","053f0dde":"code","6e95a87f":"code","75e9aae9":"code","adb8f396":"code","b1b7711f":"code","18dd66dd":"code","6315db3d":"code","faefd9d3":"code","45dc150d":"markdown","e336b222":"markdown"},"source":{"a01892d6":"from __future__ import print_function\nfrom __future__ import division\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nimport shutil\nimport PIL\n!pip install GPUtil\n\n!pip install GPUtil\n\nfrom GPUtil import showUtilization as gpu_usage\n\ndef free_gpu_cache():\n    print(\"Initial GPU Usage\")\n    gpu_usage()                             \n\n    torch.cuda.empty_cache()\n\n    print(\"GPU Usage after emptying the cache\")\n    gpu_usage()","50ea0be7":"data_dir = \"\/kaggle\/input\/stretched-full\/pics\"\ncsv_dir_train = \"\/kaggle\/input\/stretched-full\/train.csv\"\ncsv_dir_val = \"\/kaggle\/input\/stretched-full\/val.csv\"\n# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\nbatch_size = 8\nnum_epochs = 20\nimagesize = 450\nmaxpage = 30\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","1bc909c1":"class pdfDataset(torch.utils.data.Dataset):\n    def __init__(self, df, images_folder, transform = None, imagesize = imagesize, maxpage=maxpage):\n        self.df = df\n        self.images_folder = images_folder\n        self.transform = transform\n        self.imagesize = imagesize\n        self.maxpage = maxpage\n\n    def __len__(self):\n        return max(self.df.merged)  \n    \n    def __getitem__(self, index):\n        data = self.df[self.df[\"merged\"] == index]\n        pages = data[\"LABEL\"].tolist()\n        images = torch.zeros(size=(self.maxpage, 1, self.imagesize, self.imagesize))\n        \n        i = 0\n        for index, row in data.iterrows():\n            try:\n                image = PIL.Image.open(os.path.join(self.images_folder, row[\"FILENAME\"])).convert('RGB')\n                image_tensor = self.transform(image)\n                images[i] = image_tensor\n                i += 1\n            except:\n                print(f'file {row[\"FILENAME\"]} is not a valid image file ')\n                             \n        label_list = data[\"label\"].values\n        label = torch.zeros(self.maxpage)\n        label[:len(label_list)] = torch.tensor(label_list)\n        if len(label_list)<self.maxpage -1:\n            label[len(label_list)] = 1\n        return torch.tensor(images.permute(1,0,2,3)), label\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.CenterCrop(imagesize),\n        transforms.Grayscale(num_output_channels=1),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5], [0.5])\n    ]),\n    'val': transforms.Compose([\n        transforms.CenterCrop(imagesize),\n        transforms.Grayscale(num_output_channels=1),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5], [0.5])\n    ]),\n}\n    \ntrain = pd.read_csv(csv_dir_train)\ntrain[\"FILENAME\"] = train[\"path\"].apply(lambda x: x[x.rfind(\"\\\\\")+1:])\ntrain[\"LABEL\"] = train[\"path\"].apply(lambda x: x[x.rfind(\"\\\\\")+1: x.rfind(\".jpg\")])\n\nval = pd.read_csv(csv_dir_val)\nval[\"FILENAME\"] = val[\"path\"].apply(lambda x: x[x.rfind(\"\\\\\")+1:])\nval[\"LABEL\"] = val[\"path\"].apply(lambda x: x[x.rfind(\"\\\\\")+1: x.rfind(\".jpg\")])\n\n# Create training and validation datasets\ntrain_pdfDataset = pdfDataset(train, data_dir + \"\/train\", data_transforms[\"train\"])\nval_pdfDataset = pdfDataset(val, data_dir + \"\/val\", data_transforms[\"val\"])\n\npdf_datasets = {\"train\": train_pdfDataset, \"val\": val_pdfDataset}\n\n# Create training and validation dataloaders\npdf_dataloaders_dict = {x: torch.utils.data.DataLoader(pdf_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}","053f0dde":"train.loc[5168]","6e95a87f":"pdf_datasets[\"train\"][0][0].shape","75e9aae9":"plt.imshow(pdf_datasets[\"train\"][0][0][0][0], cmap=plt.get_cmap('gray'))","adb8f396":"class Net(torch.nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        self.conv_layer1 = nn.Sequential(\n            nn.Conv3d(1, 8, kernel_size=(2, 5, 5), padding=0), \n            nn.ReLU(),\n            nn.MaxPool3d((1, 3, 3)) \n        )\n        \n        self.conv_layer2 = nn.Sequential(\n            nn.Conv3d(8, 32, kernel_size=(2, 5, 5), padding=2), \n            nn.ReLU(),\n            nn.MaxPool3d((1, 3, 3)) \n        )\n        \n        self.conv_layer3 = nn.Sequential(\n            nn.Conv3d(32, 64, kernel_size=(2, 5, 5), padding=2), \n            nn.ReLU(),\n            nn.MaxPool3d((1, 3, 3))\n        )\n        self.conv_layer4 = nn.Sequential(\n            nn.Conv3d(64, 128, kernel_size=(2, 5, 5), padding=2), \n            nn.ReLU(),\n            nn.MaxPool3d((1, 3, 3))\n        )\n        \n        self.fc1 = nn.Linear(121600, 512)\n        self.fc2 = nn.Linear(512, 30)\n        self.relu = nn.ReLU()\n        self.batch=nn.BatchNorm1d(512)\n        self.drop = nn.Dropout(.15)\n\n    def forward(self, x):\n        out = self.conv_layer1(x)\n        out = self.conv_layer2(out)\n        out = self.conv_layer3(out)\n        out = self.conv_layer4(out)\n        out = out.view(out.size(0), -1)\n        out = self.fc1(out)\n        out = self.relu(out)\n        out = self.drop(out)\n        out = self.batch(out)\n        out = self.fc2(out)\n        return out","b1b7711f":"model = Net()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\ncriterion = torch.nn.BCEWithLogitsLoss()\nif torch.cuda.is_available():\n    model = model.cuda()\n    criterion = criterion.cuda()\nprint(model)","18dd66dd":"def train_model(model, dataloaders, optimizer, num_epochs=25):\n    since = time.time()\n\n    val_f1_history = []\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_f1 = 0.0\n    \n    criterion = torch.nn.BCEWithLogitsLoss()\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n            correct_true = 0\n            target_true=0\n            predicted_true=0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    # Get model outputs and calculate loss\n                    outputs = model(inputs)\n                    loss = criterion(torch.flatten(outputs), torch.flatten(labels))\n                    preds = torch.round(torch.sigmoid(outputs))\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                correct_true += torch.sum(torch.logical_and(preds == labels.data, labels.data == torch.ones_like(labels.data)))\n                target_true += torch.sum(labels.data)\n                predicted_true += torch.sum(preds)\n            epoch_loss = running_loss \/ len(dataloaders[phase].dataset)\n            recall = correct_true \/ target_true\n            precision = correct_true \/ predicted_true\n            f1_score = 2 * precision * recall \/ (precision + recall)\n\n            print('{} Loss: {:.4f} Recall: {:.4f} Precision: {:.4f} f1:{:.4f}'.format(phase, epoch_loss, recall, precision, f1_score))\n\n            # deep copy the model\n            if phase == 'val' and f1_score > best_f1:\n                best_f1 = f1_score\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_f1_history.append(f1_score)\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val F1: {:4f}'.format(best_f1))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, val_f1_history","6315db3d":"import warnings\nwarnings.filterwarnings(\"ignore\")\nfree_gpu_cache()                           \nmodel_ft, hist = train_model(model, pdf_dataloaders_dict, optimizer, num_epochs=num_epochs)","faefd9d3":"!pip install torchinfo\nfrom torchinfo import summary\nsummary(model, input_size = (batchsize,1,50,imagesize,imagesize))","45dc150d":"update\n1. make sure image takes up the entire space\n2. normalise the image\n3. use precision & recall rather than accuracy\n\nMarto Carlo sampling to automate","e336b222":"def __init__(self):\n        super(ConvAutoencoder, self).__init__()\n       \n        #Encoder\n        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)  \n        self.conv2 = nn.Conv2d(16, 4, 3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n       \n        #Decoder\n        self.t_conv1 = nn.ConvTranspose2d(4, 16, 2, stride=2)\n        self.t_conv2 = nn.ConvTranspose2d(16, 3, 2, stride=2)\n\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = F.relu(self.t_conv1(x))\n        x = F.sigmoid(self.t_conv2(x))\n              \n        return x\n\nU-net"}}