{"cell_type":{"efb61a41":"code","8f515153":"code","58e421c4":"code","5d94b862":"code","d44a449c":"code","65fd5575":"code","ba610800":"code","c2e853bb":"code","b6c5d99b":"code","69c8c3d7":"code","4adc24b2":"code","e31d5a17":"code","dfd1084f":"code","bd2c61af":"markdown","d303dc13":"markdown","35b6a300":"markdown"},"source":{"efb61a41":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\nimport plotly.offline as py\nimport plotly.express as px\nimport cv2\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8f515153":"from fastai.vision import *","58e421c4":"tfms = get_transforms(max_rotate=25)","5d94b862":"len(tfms)","d44a449c":"def get_ex(): return open_image('..\/input\/camseq-semantic-segmentation\/0016E5_07959.png')","65fd5575":"def plots_f(rows, cols, width, height, **kwargs):\n    [get_ex().apply_tfms(tfms[0], **kwargs).show(ax=ax) for i,ax in enumerate(plt.subplots(\n        rows,cols,figsize=(width,height))[1].flatten())]","ba610800":"plots_f(2, 4, 12, 6, size=224)","c2e853bb":"# contrast\nfig, axs = plt.subplots(1,5,figsize=(12,4))\nfor scale, ax in zip(np.exp(np.linspace(log(0.5),log(2),5)), axs):\n    contrast(get_ex(), scale).show(ax=ax, title=f'scale={scale:.2f}')","b6c5d99b":"# brightness\nfig, axs = plt.subplots(1,5,figsize=(14,8))\nfor change, ax in zip(np.linspace(0.1,0.9,5), axs):\n    brightness(get_ex(), change).show(ax=ax, title=f'change={change:.1f}')","69c8c3d7":"# dihedral\nfig, axs = plt.subplots(2,2,figsize=(12,8))\nfor k, ax in enumerate(axs.flatten()):\n    dihedral(get_ex(), k).show(ax=ax, title=f'k={k}')\nplt.tight_layout()","4adc24b2":"# tilt\nfig, axs = plt.subplots(2,4,figsize=(12,8))\nfor i in range(4):\n    get_ex().tilt(i, 0.4).show(ax=axs[0,i], title=f'direction={i}, fwd')\n    get_ex().tilt(i, -0.4).show(ax=axs[1,i], title=f'direction={i}, bwd')","e31d5a17":"image = cv2.imread('\/kaggle\/input\/camseq-semantic-segmentation\/0016E5_08151.png')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(20, 20))\n\nplt.subplot(1, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Cordinates of the 4 corners of the original image\npoints_A = np.float32([[320,15], [700,215], [85,610], [530,780]])\n\n# Cordinates of the 4 corners of the desired output\n# We use a ratio of an A4 Paper 1 : 1.41\npoints_B = np.float32([[0,0], [420,0], [0,594], [420,594]])\n \n# Use the two sets of four points to compute \n# the Perspective Transformation matrix, M    \nM = cv2.getPerspectiveTransform(points_A, points_B)\n\n\nwarped = cv2.warpPerspective(image, M, (420,594))\n\nplt.subplot(1, 2, 2)\nplt.title(\"warpPerspective\")\nplt.imshow(warped)","dfd1084f":"# Load our new image\nimage = cv2.imread('\/kaggle\/input\/camseq-semantic-segmentation\/0016E5_08029.png', 0)\n\nplt.figure(figsize=(30, 30))\nplt.subplot(3, 2, 1)\nplt.title(\"Original\")\nplt.imshow(image)\n\n# Values below 127 goes to 0 (black, everything above goes to 255 (white)\nret,thresh1 = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n\nplt.subplot(3, 2, 2)\nplt.title(\"Threshold Binary\")\nplt.imshow(thresh1)\n\n# It's good practice to blur images as it removes noise\nimage = cv2.GaussianBlur(image, (3, 3), 0)\n\n# Using adaptiveThreshold\nthresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 5) \n\nplt.subplot(3, 2, 3)\nplt.title(\"Adaptive Mean Thresholding\")\nplt.imshow(thresh)\n\n\n_, th2 = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n\nplt.subplot(3, 2, 4)\nplt.title(\"Otsu's Thresholding\")\nplt.imshow(th2)\n\n\nplt.subplot(3, 2, 5)\n# Otsu's thresholding after Gaussian filtering\nblur = cv2.GaussianBlur(image, (5,5), 0)\n_, th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\nplt.title(\"Guassian Otsu's Thresholding\")\nplt.imshow(th3)\nplt.show()","bd2c61af":"#Codes from Bulent Siyah https:\/\/www.kaggle.com\/bulentsiyah\/learn-opencv-by-examples-with-python","d303dc13":"Kaggle Notebook Runner: Mar\u00edlia Prata   @mpwolke","35b6a300":"#Codes from DipamVasani https:\/\/www.kaggle.com\/dipam7\/data-augmentation-in-fastai"}}