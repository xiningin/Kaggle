{"cell_type":{"c909f0b9":"code","0a32041a":"code","2b1775a3":"code","55c704f3":"code","fadf3acb":"code","8f303e2f":"code","407739ca":"code","117b39dd":"code","cd338d70":"code","d0acaf96":"code","664779f4":"code","2d460a9a":"code","896cd3d5":"code","9d71aefb":"code","11497e56":"code","7a8810e1":"code","f28face0":"code","076833aa":"code","0a30493c":"code","ed6a4004":"code","c2f08f2e":"code","8df31856":"code","58ccc70b":"code","27fd3fd2":"code","97e967c0":"code","da67cae6":"code","a1d943d4":"code","14ec5501":"code","d0b32a04":"code","443daad8":"code","501209ff":"code","34c02a20":"code","665b7b93":"code","02f61a7b":"code","9082c53f":"code","07d4980f":"code","d65eb88f":"code","9e8d30d7":"code","bcc37d88":"code","3f42f4c2":"code","0442bcc0":"code","e6b05952":"code","c57d6148":"code","3889f35e":"code","c91f9eea":"code","58cef6af":"code","26e906d7":"code","b23ea8e8":"code","2a95d4d9":"code","74a899e4":"code","a69a3853":"code","4b34d1fa":"code","ebd74996":"code","722e315d":"code","21ea536a":"code","98b03346":"code","624d4a29":"code","f68ddfc1":"code","60da1674":"code","d899c622":"code","49a4f27a":"code","122f3ffc":"code","9cca0664":"code","24d71ee8":"code","f00d0341":"code","9467ee62":"code","788e0dd9":"code","998ce78a":"code","7e35662b":"code","70075946":"code","109d3ace":"code","2b6afc68":"code","a3198f49":"code","2794b102":"code","1b697d4b":"code","093df951":"code","0acda613":"code","2fa66d97":"code","93ebbac1":"code","ca9a4bbc":"code","67ddf218":"code","b94b3805":"code","2c57eda5":"code","4e0fb6bf":"code","5da1d092":"code","908afa97":"code","594eefa6":"code","2a265268":"code","f794f696":"code","c10b98fd":"code","847fa0df":"code","f7c78a50":"code","7827c0bb":"code","c12cc99d":"code","4404c792":"code","9be79815":"code","9b8248e8":"code","369bddc6":"code","bf3e361d":"code","f0b2d9d7":"code","c3a8deb9":"code","e98c3849":"code","7002d682":"code","7f9a9909":"code","0a24a60b":"code","f533cb0c":"code","0f97b5f5":"code","58dc7656":"code","00306a08":"code","0510fb7b":"code","6dec5249":"code","c73d2a4b":"code","dd263c8c":"code","d15d2492":"code","f972eda6":"code","a4aebaf5":"code","3a7b44fe":"code","1a8d6059":"code","0be2fbfc":"markdown","f831a202":"markdown","c43ac8dd":"markdown","d4ce09ae":"markdown","1e22028e":"markdown","81712e61":"markdown","6f7a3b6b":"markdown","0a542207":"markdown","c9a960be":"markdown","e1aff16f":"markdown","4c9c5576":"markdown","0e981844":"markdown","ba6a4230":"markdown","904bdbff":"markdown","21f48cf9":"markdown","7c5d7d9a":"markdown","4688ccaa":"markdown","d2fc569c":"markdown","3339736a":"markdown","1e692157":"markdown","130eeab4":"markdown","13f6863b":"markdown","9ccb4c43":"markdown","bfc54e42":"markdown","2efadee6":"markdown","ef16691b":"markdown","20b3cfc3":"markdown","a19b06ff":"markdown","588eddbd":"markdown","313a8ae8":"markdown","c01d795e":"markdown","856ecb03":"markdown","d3676b2a":"markdown","8969bc82":"markdown","70b0e7ed":"markdown","3e99b7a5":"markdown","557d353a":"markdown","54416586":"markdown","5e3aab38":"markdown","31987d30":"markdown","4134c253":"markdown","622fab8e":"markdown","295b84a9":"markdown","57335b45":"markdown","6eedab99":"markdown","a716006b":"markdown","fdfedac2":"markdown","2d83c4f4":"markdown","6ecf2815":"markdown","6516582b":"markdown","e087be94":"markdown","a03d79ac":"markdown","84e3caee":"markdown","fc4216c4":"markdown","5a4c54d8":"markdown","2f371a6d":"markdown"},"source":{"c909f0b9":"import warnings\nwarnings.simplefilter('ignore')","0a32041a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stats","2b1775a3":"pd.set_option(\"display.max_columns\", None)\npd.options.display.float_format = '{:.2f}'.format","55c704f3":"filepath = '..\/input\/churn-for-bank-customers\/churn.csv'\ndata = pd.read_csv(filepath)","fadf3acb":"data.head()","8f303e2f":"data.tail()","407739ca":"data.shape","117b39dd":"data.columns","cd338d70":"data.dtypes","d0acaf96":"data.info()","664779f4":"data.describe().T","2d460a9a":"data.isna().sum(axis=0)","896cd3d5":"duplicate_rows = data[data.duplicated()]\nduplicate_rows.shape[0]","9d71aefb":"data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)","11497e56":"numerical_data = data.select_dtypes(include='number')\nnumerical_data.columns","7a8810e1":"categorical_data = data.select_dtypes(exclude='number')\ncategorical_data.columns","f28face0":"data['Exited'].value_counts()","076833aa":"plt.figure(figsize=(7, 5))\nsns.countplot(data=data, x='Exited')\nplt.show()","0a30493c":"data['Gender'].value_counts()","ed6a4004":"x = data['Gender'].value_counts().values\nplt.figure(figsize=(7, 6))\nplt.pie(x, center=(0, 0), radius=1.5, labels=['Male', 'Female'], autopct='%1.1f%%', pctdistance=0.5)\nplt.axis('equal')\nplt.show()","c2f08f2e":"plt.figure(figsize=(8, 5))\nsns.countplot(x='Exited', hue='Gender', data=data)\nplt.show()","8df31856":"print(data['Geography'].value_counts())","58ccc70b":"x = data['Geography'].value_counts().values\nplt.figure(figsize=(7, 6))\nplt.pie(x, center=(0, 0), radius=1.5, labels=['France', 'Germany', 'Spain'], autopct='%1.1f%%', pctdistance=0.5)\nplt.axis('equal')\nplt.show()","27fd3fd2":"plt.figure(figsize=(8, 5))\nsns.countplot(x='Exited', hue='Geography', data=data)\nplt.show()","97e967c0":"plt.figure(figsize=(8, 5))\ncrosstab = pd.crosstab(data['Geography'], data['Gender'], values=data['Exited'], aggfunc=np.sum)\nsns.heatmap(crosstab, annot=True, fmt='d')\nplt.show()","da67cae6":"data['IsActiveMember'].value_counts()","a1d943d4":"plt.figure(figsize=(8, 5))\nsns.countplot(x='Exited', hue='IsActiveMember', data=data)\nplt.show()","14ec5501":"plt.figure(figsize=(7, 5))\nsns.countplot(data=data, y='IsActiveMember', hue='Gender')\nplt.show()","d0b32a04":"plt.figure(figsize=(7, 5))\nsns.countplot(data=data, y='IsActiveMember', hue='Geography')\nplt.show()","443daad8":"data['HasCrCard'].value_counts()","501209ff":"plt.figure(figsize=(8, 5))\nsns.countplot(x='Exited', hue='HasCrCard', data=data)\nplt.show()","34c02a20":"plt.figure(figsize=(7, 5))\nsns.countplot(data=data, y='HasCrCard', hue='Gender')\nplt.show()","665b7b93":"plt.figure(figsize=(7, 5))\nsns.countplot(data=data, y='HasCrCard', hue='Geography')\nplt.show()","02f61a7b":"data['NumOfProducts'].value_counts()","9082c53f":"plt.figure(figsize=(8, 5))\nsns.countplot(x='Exited', hue='NumOfProducts', data=data)\nplt.show()","07d4980f":"plt.figure(figsize=(7, 5))\nsns.countplot(data=data, y='NumOfProducts', hue='Gender')\nplt.show()","d65eb88f":"plt.figure(figsize=(7, 5))\nsns.countplot(data=data, y='NumOfProducts', hue='Geography')\nplt.show()","9e8d30d7":"plt.figure(figsize=(8, 5))\nsns.set(style=\"darkgrid\")\nax = sns.pointplot(x='Geography', y='CreditScore', hue='Gender', data=data, dodge=True)\nplt.show()","bcc37d88":"plt.figure(figsize=(8, 5))\nsns.set(style=\"darkgrid\")\nax = sns.pointplot(x='Geography', y='Balance', hue='Gender', data=data, dodge=True)\nplt.show()","3f42f4c2":"plt.figure(figsize=(8, 5))\nsns.set(style=\"darkgrid\")\nax = sns.pointplot(x='Geography', y='EstimatedSalary', hue='Gender', data=data, dodge=True)\nplt.show()","0442bcc0":"feat_set1 = ['CreditScore', 'Balance', 'EstimatedSalary']\ndata[feat_set1].hist(figsize=(15, 8))\nplt.show()","e6b05952":"sns.set(style=\"whitegrid\")\nfig = plt.figure(figsize=(12, 5))\nfig.subplots_adjust(right=1.5)\n\nplt.subplot(1, 3, 1)\nsns.boxplot(y=data['CreditScore'])\n\nplt.subplot(1, 3, 2)\nsns.boxplot(y=data['Balance'])\n\nplt.subplot(1, 3, 3)\nsns.boxplot(y=data['EstimatedSalary'])\n\nplt.show()","c57d6148":"def diagnostic_plot(data, col):\n    fig = plt.figure(figsize=(9, 4))\n    fig.subplots_adjust(right=1.5)\n    \n    plt.subplot(1, 2, 1)\n    sns.distplot(data[col], kde=True, color='red')\n    plt.title('Histogram')\n    \n    plt.subplot(1, 2, 2)\n    stats.probplot(data[col], dist='norm', fit=True, plot=plt)\n    plt.title('Q-Q Plot')\n    \n    plt.show()","3889f35e":"diagnostic_plot(data, 'Balance')","c91f9eea":"diagnostic_plot(data, 'CreditScore')","58cef6af":"diagnostic_plot(data, 'EstimatedSalary')","26e906d7":"plt.figure(figsize=(8, 5))\nsns.distplot(data['Age'], kde=True, color='red')\nplt.show()","b23ea8e8":"print(\"Minimum Age is {}\".format(data['Age'].min()))\nprint(\"Maximum Age is {}\".format(data['Age'].max()))","2a95d4d9":"print(\"Mean: {:.2f}\".format(data['Age'].mean()))\nprint(\"Median: {:.2f}\".format(data['Age'].median()))","74a899e4":"X = data.drop('Exited', axis=1)\nX.corr(method='spearman')","a69a3853":"plt.figure(figsize=(8, 5))\nX.corrwith(data['Exited']).plot(kind='barh', title=\"Correlation with 'Exited' column -\")\nplt.show()","4b34d1fa":"plt.figure(figsize = (10, 8))\ncorr = data.corr(method='spearman')\nmask = np.triu(np.ones_like(corr, dtype=bool))\ncormat = sns.heatmap(corr, mask=mask, annot=True, cmap='YlGnBu', linewidths=1, fmt=\".2f\")\ncormat.set_title('Correlation Matrix')\nplt.show()","ebd74996":"data['Age Group'] = pd.cut(x=data['Age'], \n                            bins=[18, 40, 60, 95], \n                            labels=['Youngster', 'Middle-Aged', 'Senior Citizen'])","722e315d":"data['Exited'].groupby(data['Age Group']).sum()","21ea536a":"plt.figure(figsize=(8, 5))\nsns.countplot(x='Exited', hue='Age Group', data=data)\nplt.show()","98b03346":"feat_set2 = ['Geography', 'Gender']\ndata_encoded = pd.get_dummies(data[feat_set2], drop_first=True)\ndata_encoded.sample(5)","624d4a29":"df1 = data.join(data_encoded)\ndf1.sample(5)","f68ddfc1":"df2 = df1.drop(['Geography', 'Gender', 'Age Group'], axis=1)\ndf2.sample(5)","60da1674":"df2.columns","d899c622":"from sklearn.utils import resample\ndf3 = resample(df2, replace=False, n_samples=None, random_state=42)\ndf3.head()","49a4f27a":"final_data = df3.iloc[0:9500, :]\nvalid_set = df3.iloc[9500:10000, :]","122f3ffc":"final_data.shape","9cca0664":"valid_set.shape","24d71ee8":"X = final_data.drop('Exited', axis=1)\ny = final_data['Exited']","f00d0341":"X_val = valid_set.drop('Exited', axis=1)\ny_val = valid_set['Exited']","9467ee62":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=True, random_state=42)","788e0dd9":"from collections import Counter\nprint(Counter(y_train))","998ce78a":"from imblearn.over_sampling import SMOTE\noversampler = SMOTE(sampling_strategy='auto', k_neighbors=5, random_state=42)\nX_train, y_train = oversampler.fit_resample(X_train, y_train)","7e35662b":"print(Counter(y_train))","70075946":"print(X_train.shape)\nprint(y_train.shape)","109d3ace":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train)\n\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nX_val_scaled = scaler.transform(X_val)","2b6afc68":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score, roc_auc_score, roc_curve, auc","a3198f49":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.pipeline import Pipeline\npipeline_lr = Pipeline([('lr', LogisticRegression())])\npipeline_svc = Pipeline([('svc', SVC())])\npipeline_knn = Pipeline([('knn', KNeighborsClassifier())])\npipeline_nb = Pipeline([('nb', GaussianNB())])\n\npipelines = [pipeline_lr, pipeline_svc, pipeline_knn, pipeline_nb]\n\npipe_dict = {0: 'Logistic Regression', \n             1: 'Support Vector Classifier', \n             2: 'K-Neighbors Classifier', \n             3: 'Naive Bayes Classifier'}\n\nfor pipe in pipelines:\n    pipe.fit(X_train_scaled, y_train)\n    \n\n\nfor i, model in enumerate(pipelines):\n    y_pred = model.predict(X_test_scaled)\n    print(f'Accuracy Score:')\n    score = accuracy_score(y_test, y_pred)\n    print(\"{}: {:.4f}\".format(pipe_dict[i], score))\n    print(f'ROC AUC Score:')\n    score = roc_auc_score(y_test, y_pred)\n    print(\"{}: {:.4f}\".format(pipe_dict[i], score))\n    print(f'F1 Score:')\n    score = f1_score(y_test, y_pred)\n    print(\"{}: {:.4f}\\n\".format(pipe_dict[i], score))\n    ","2794b102":"from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier()\ndt.fit(X_train, y_train)","1b697d4b":"y_pred_dt = dt.predict(X_test)\ny_pred_proba_dt = dt.predict_proba(X_test)[:, 1]","093df951":"print(\"Train accuracy :{:.4f}\".format(accuracy_score(y_train, dt.predict(X_train))))\nprint(\"Test accuracy :{:.4f}\".format(accuracy_score(y_test, dt.predict(X_test))))","0acda613":"conmat = confusion_matrix(y_test, y_pred_dt)\nsns.heatmap(conmat, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.show()","2fa66d97":"print(\"Classification Report\")\nprint(classification_report(y_test, y_pred_dt))","93ebbac1":"print(\"F1 Score: {:.4f}\".format(f1_score(y_test, y_pred_dt)))\nprint(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred_dt)))\nprint(\"Recall: {:.4f}\".format(recall_score(y_test, y_pred_dt)))","ca9a4bbc":"print(\"AUC Score: {:.4f}\".format(roc_auc_score(y_test, y_pred_proba_dt)))","67ddf218":"from sklearn.model_selection import KFold, cross_val_score\nkfold = KFold(n_splits=5)\ndt_acc = np.mean(cross_val_score(dt, X_train, y_train, cv=kfold, scoring='f1')) \nprint(\"Cross Validation Score: {:.4f}\".format(dt_acc))","b94b3805":"fpr_dt, tpr_dt, threshold_dt = roc_curve(y_test, y_pred_proba_dt)\nauc_dt = auc(fpr_dt, tpr_dt)\n\nplt.style.use('seaborn-darkgrid')\nplt.figure(figsize=(8, 5))\nplt.plot(fpr_dt, tpr_dt, label=\"Decision Tree Classifier (area = {:.4f})\".format(auc_dt))\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.legend(loc='lower right', frameon=True)\nplt.title(\"ROC Curve\")\nplt.ylabel(\"True Positive Rate\")\nplt.xlabel(\"False Positive Rate\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.show()","2c57eda5":"y_pred_dt_val = dt.predict(X_val)\ny_pred_proba_dt_val = dt.predict_proba(X_val)[:, 1]","4e0fb6bf":"print(\"Train accuracy :{:.4f}\".format(accuracy_score(y_train, dt.predict(X_train))))\nprint(\"Test accuracy :{:.4f}\".format(accuracy_score(y_val, dt.predict(X_val))))","5da1d092":"conmat = confusion_matrix(y_val, y_pred_dt_val)\nsns.heatmap(conmat, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.show()","908afa97":"print(\"F1 Score: {:.4f}\".format(f1_score(y_val, y_pred_dt_val)))\nprint(\"Precision: {:.4f}\".format(precision_score(y_val, y_pred_dt_val)))\nprint(\"Recall: {:.4f}\".format(recall_score(y_val, y_pred_dt_val)))","594eefa6":"print(\"AUC Score: {:.4f}\".format(roc_auc_score(y_val, y_pred_proba_dt_val)))","2a265268":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)","f794f696":"y_pred_rf = rf.predict(X_test)\ny_pred_proba_rf = rf.predict_proba(X_test)[:, 1]","c10b98fd":"print(\"Train accuracy :{:.4f}\".format(accuracy_score(y_train, rf.predict(X_train))))\nprint(\"Test accuracy :{:.4f}\".format(accuracy_score(y_test, rf.predict(X_test))))","847fa0df":"conmat = confusion_matrix(y_test, y_pred_rf)\nsns.heatmap(conmat, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.show()","f7c78a50":"print(\"Classification Report\")\nprint(classification_report(y_test, y_pred_rf))","7827c0bb":"print(\"F1 Score: {:.4f}\".format(f1_score(y_test, y_pred_rf)))\nprint(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred_rf)))\nprint(\"Recall: {:.4f}\".format(recall_score(y_test, y_pred_rf)))","c12cc99d":"print(\"AUC Score: {:.4f}\".format(roc_auc_score(y_test, y_pred_proba_rf)))","4404c792":"from sklearn.model_selection import KFold, cross_val_score\nkfold = KFold(n_splits=5)\nrf_acc = np.mean(cross_val_score(rf, X_train, y_train, cv=kfold, scoring='f1')) \nprint(\"Cross Validation Score: {:.4f}\".format(rf_acc))","9be79815":"fpr_rf, tpr_rf, threshold_rf = roc_curve(y_test, y_pred_proba_rf)\nauc_rf = auc(fpr_rf, tpr_rf)\n\nplt.style.use('seaborn-darkgrid')\nplt.figure(figsize=(8, 5))\nplt.plot(fpr_rf, tpr_rf, label=\"Random Forest Classifier (area = {:.4f})\".format(auc_rf))\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.legend(loc='lower right', frameon=True)\nplt.title(\"ROC Curve\")\nplt.ylabel(\"True Positive Rate\")\nplt.xlabel(\"False Positive Rate\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.show()","9b8248e8":"y_pred_rf_val = rf.predict(X_val)\ny_pred_proba_rf_val = rf.predict_proba(X_val)[:, 1]","369bddc6":"print(\"Train accuracy :{:.4f}\".format(accuracy_score(y_train, rf.predict(X_train))))\nprint(\"Test accuracy :{:.4f}\".format(accuracy_score(y_val, rf.predict(X_val))))","bf3e361d":"conmat = confusion_matrix(y_val, y_pred_rf_val)\nsns.heatmap(conmat, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.show()","f0b2d9d7":"print(\"F1 Score: {:.4f}\".format(f1_score(y_val, y_pred_rf_val)))\nprint(\"Precision: {:.4f}\".format(precision_score(y_val, y_pred_rf_val)))\nprint(\"Recall: {:.4f}\".format(recall_score(y_val, y_pred_rf_val)))","c3a8deb9":"print(\"AUC Score: {:.4f}\".format(roc_auc_score(y_val, y_pred_proba_rf_val)))","e98c3849":"from xgboost import XGBClassifier\nxgb = XGBClassifier()\nxgb.fit(X_train, y_train)","7002d682":"y_pred_xgb = xgb.predict(X_test)\ny_pred_proba_xgb = xgb.predict_proba(X_test)[:, 1]","7f9a9909":"print(\"Train accuracy :{:.4f}\".format(accuracy_score(y_train, xgb.predict(X_train))))\nprint(\"Test accuracy :{:.4f}\".format(accuracy_score(y_test, xgb.predict(X_test))))","0a24a60b":"conmat = confusion_matrix(y_test, y_pred_xgb)\nsns.heatmap(conmat, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.show()","f533cb0c":"print(\"Classification Report\")\nprint(classification_report(y_test, y_pred_xgb))","0f97b5f5":"print(\"F1 Score: {:.4f}\".format(f1_score(y_test, y_pred_xgb)))\nprint(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred_xgb)))\nprint(\"Recall: {:.4f}\".format(recall_score(y_test, y_pred_xgb)))","58dc7656":"print(\"AUC Score: {:.4f}\".format(roc_auc_score(y_test, y_pred_proba_xgb)))","00306a08":"from sklearn.model_selection import KFold, cross_val_score\nkfold = KFold(n_splits=5)\nxgb_acc = np.mean(cross_val_score(xgb, X_train, y_train, cv=kfold, scoring='f1')) \nprint(\"Cross Validation Score: {:.4f}\".format(xgb_acc))","0510fb7b":"fpr_xgb, tpr_xgb, threshold_xgb = roc_curve(y_test, y_pred_proba_xgb)\nauc_xgb = auc(fpr_xgb, tpr_xgb)\n\nplt.style.use('seaborn-darkgrid')\nplt.figure(figsize=(8, 5))\nplt.plot(fpr_xgb, tpr_xgb, label=\"XGBoost Classifier (area = {:.4f})\".format(auc_xgb))\nplt.plot([0, 1], [0, 1], linestyle='--')\nplt.legend(loc='lower right', frameon=True)\nplt.title(\"ROC Curve\")\nplt.ylabel(\"True Positive Rate\")\nplt.xlabel(\"False Positive Rate\")\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.show()","6dec5249":"y_pred_xgb_val = xgb.predict(X_val)\ny_pred_proba_xgb_val = xgb.predict_proba(X_val)[:, 1]","c73d2a4b":"print(\"Train accuracy :{:.4f}\".format(accuracy_score(y_train, xgb.predict(X_train))))\nprint(\"Test accuracy :{:.4f}\".format(accuracy_score(y_val, xgb.predict(X_val))))","dd263c8c":"conmat = confusion_matrix(y_val, y_pred_xgb_val)\nsns.heatmap(conmat, annot=True, fmt='d')\nplt.title(\"Confusion Matrix\")\nplt.show()","d15d2492":"print(\"F1 Score: {:.4f}\".format(f1_score(y_val, y_pred_xgb_val)))\nprint(\"Precision: {:.4f}\".format(precision_score(y_val, y_pred_xgb_val)))\nprint(\"Recall: {:.4f}\".format(recall_score(y_val, y_pred_xgb_val)))","f972eda6":"print(\"AUC Score: {:.4f}\".format(roc_auc_score(y_val, y_pred_proba_xgb_val)))","a4aebaf5":"from sklearn.model_selection import RandomizedSearchCV\n\nparams = { 'subsample': [1],\n           'reg_lambda': [0.001, 0.01, 0.1, 1, 10, 100],\n           'n_estimators': [100, 300, 500],\n           'min_child_weight': [1],\n           'max_depth': [3, 4, 5, 10],\n           'learning_rate': [0.001, 0.01, 0.1, 0.3],\n           'gamma': [0, 0.01, 0.1, 0.3],\n           'colsample_bytree': [1] }\n\nrdm = RandomizedSearchCV(xgb, param_distributions=params, scoring='f1', n_jobs=-1, cv=5)\nrdm.fit(X_train, y_train)","3a7b44fe":"rdm.best_params_","1a8d6059":"rdm.best_score_","0be2fbfc":"Checking the numbers of customers having a credit card -","f831a202":"Customer distribution based on geography -","c43ac8dd":"Customer churn based on whether the customer is an active member or not -","d4ce09ae":"Columns present in the processed data -","1e22028e":"## Random Forest Classifier","81712e61":"Dropping all the columns which are not required for the analysis -","6f7a3b6b":"### Model Evaluation -","0a542207":"Columns with categorical data -","c9a960be":"### Optimizing the Hyperparameters for XGBoost using RandomizedSearchCV -","e1aff16f":"**Attribute Information:**\n\n* RowNumber \u2014 Corresponds to the record (row) number and has no effect on the output.\n\n* CustomerId \u2014 Contains random values and has no effect on customer leaving the bank.\n \n* Surname \u2014 The surname of a customer has no impact on their decision to leave the bank.\n \n* CreditScore \u2014 Can have an effect on customer churn, since a customer with a higher credit score is less likely to leave the bank.\n \n* Geography \u2014 A customer\u2019s location can affect their decision to leave the bank.\n \n* Gender \u2014 It\u2019s interesting to explore whether gender plays a role in a customer leaving the bank.\n \n* Age \u2014 This is certainly relevant, since older customers are less likely to leave their bank than younger ones.\n \n* Tenure \u2014 Refers to the number of years that the customer has been a client of the bank. Normally, older clients are more loyal and less likely to leave a bank.\n \n* Balance \u2014 Also a very good indicator of customer churn, as people with a higher balance in their accounts are less likely to leave the bank compared to those with lower balances.\n \n* NumOfProducts \u2014 Refers to the number of products that a customer has purchased through the bank.\n\n* HasCrCard \u2014 Denotes whether or not a customer has a credit card. This column is also relevant, since people with a credit card are less likely to leave the bank.\n \n* IsActiveMember \u2014 Active customers are less likely to leave the bank.\n \n* EstimatedSalary \u2014 As with balance, people with lower salaries are more likely to leave the bank compared to those with higher salaries.\n \n* Exited \u2014 Whether or not the customer left the bank.","4c9c5576":"Shuffling the dataset - ","0e981844":"### Feature Engineering -","ba6a4230":"Checking for any missing values -","904bdbff":"### Model Evaluation -","21f48cf9":"Checking the age distribution of the customers -","7c5d7d9a":"Checking for any duplicate rows -","4688ccaa":"**Table of Contents:**\n\n1. Case Study\n\n2. Attribute Information\n\n3. Our Approach\n\n4. Importing required libraries\n\n5. Loading the dataset\n\n6. Exploratory Data Analysis\n\n7. Data Visualization \n\n7. Checking Data Distribution\n\n8. Checking Correlation among Variables\n\n9. Feature Engineering\n\n10. Creating a Validation Set\n\n11. Oversampling using SMOTE\n\n12. Train-Test Split\n\n13. Data Standardization\n\n14. Importing performance metrics\n\n15. Model Selection\n\n16. Model Training\n\n17. Performance Evaluation\n\n18. Hyperparameter Optimization","d2fc569c":"### Performance Evaluation on Validation Set -","3339736a":"Checking the distribution of data -","1e692157":"Plotting the Correlation Matrix -","130eeab4":"If you find this notebook useful then please provide your valuble feedback.\n\nAny kind of suggestions are welcomed.\n\nDon't forget to upvote if you like my work.","13f6863b":"Columns with numerical data -","9ccb4c43":"### Model Training -","bfc54e42":"Checking the gender distribution of exited customers based on their location -","2efadee6":"Customer churn based on the number of products a customer has purchased through the bank -","ef16691b":"### Model Selection -","20b3cfc3":"## Decision Tree Classifier","a19b06ff":"Checking the correlation between independent variables -","588eddbd":"### Splitting the data into train & test sets -","313a8ae8":"One-hot encoding the categorical features -","c01d795e":"### Performance Evaluation on Validation Set -","856ecb03":"Saving the last 500 records from the shuffled dataset for validation -","d3676b2a":"### Importing performance metrics for binary classification -","8969bc82":"Customer distribution based on gender -","70b0e7ed":"### Loading the dataset -","3e99b7a5":"# Churn Prediction for Bank Customers using ML","557d353a":"Checking the correlation of independent variables with dependent variable -","54416586":"Customer churn based on gender -","5e3aab38":"### Splitting the data into independent & dependent variables -","31987d30":"### Performance Evaluation on Validation Set -","4134c253":"### Data Visualization (based on categorical features) -","622fab8e":"### Scaling the data -","295b84a9":"Checking the number of active members -","57335b45":"**Case Study:**\n\nAs we know, it is much more expensive for a company to sign in a new client than keeping an existing one.\n\nIt is advantageous for them to know what leads a client towards the decision to leave the company.\n\nChurn prediction allows companies to develop loyalty programs and retention campaigns to keep as many customers as possible.","6eedab99":"### Model Training -","a716006b":"### Performing EDA -","fdfedac2":"**Our Approach:**\n\nIf we try to understand the business problem here, we'll get to know that the only possible way in which the bank \ncould make some benefit from this analysis is by correctly classifying which customers are more likely to leave the bank.  \n\nFor that we should focus on improving the recall score instead of optimizing the accuracy score and roc auc score.\n\nSince the dataset is imbalanced, we will get the desired result only by maximizing the True Positives and minimizing the False Negatives.","2d83c4f4":"Customer churn based on whether the customer has a credit card or not -","6ecf2815":"### Model Evaluation -","6516582b":"## XGBoost Classifier","e087be94":"### Importing required libraries -","a03d79ac":"### Oversampling the minority class instances using SMOTE -","84e3caee":"Checking the outcome labels -","fc4216c4":"### Model Training -","5a4c54d8":"Checking the number of products a customer has purchased through the bank -","2f371a6d":"Customer churn based on geography -"}}