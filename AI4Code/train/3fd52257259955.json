{"cell_type":{"f2a6c965":"code","75697e35":"code","f00292da":"code","af27268b":"code","5ee9ff79":"code","e4884380":"code","316b62cb":"code","6e48b3a0":"code","ca1f2dff":"code","e1495ca3":"code","8f8868a1":"code","6f4493fd":"code","81355488":"code","cf5bb8f3":"code","e3ab3e56":"code","a7a996aa":"code","5117da93":"code","a6e4a666":"code","11cda8ff":"code","237797cf":"code","4995f110":"code","8671fed0":"code","babcdd67":"code","788a06e5":"code","f4616455":"code","67ab7899":"code","60722a3c":"code","c88a122a":"markdown","e0dec423":"markdown"},"source":{"f2a6c965":"import numpy as np \nimport pandas as pd\nfrom pathlib import Path\nimport os.path\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport os\nimport cv2\nimport gc","75697e35":"# Create a list with the filepaths for training and testing\ntrain_img_Path = '..\/input\/dog-breed-identification\/train'\n\ntest_img_Path = '..\/input\/dog-breed-identification\/test'\n\nlabels = pd.read_csv(r'..\/input\/dog-breed-identification\/labels.csv')\n\nsample_submission = pd.read_csv(r'..\/input\/dog-breed-identification\/sample_submission.csv')","f00292da":"labels.head()","af27268b":"print(f'Number of pictures in the training dataset: {labels.shape[0]}\\n')\nprint(f'Number of different labels: {len(labels.breed.unique())}\\n')\nprint(f'Labels: {labels.breed.unique()}')","5ee9ff79":"labels['breed'].value_counts()","e4884380":"labels['id'] = labels['id'] + '.jpg'","316b62cb":"plt.figure(figsize=(20,40))\ni=1\nfor idx,s in labels.head(6).iterrows():\n    img_path = os.path.join(train_img_Path,s['id'])\n    img=cv2.imread(img_path)\n    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n    fig=plt.subplot(6,2,i)\n    fig.imshow(img)\n    fig.set_title(s['breed'])\n    i+=1","6e48b3a0":"#Extracting different classes\ndog_breeds = sorted(labels['breed'].unique())\nn_classes = len(dog_breeds)\nprint(n_classes)","ca1f2dff":"#Converting classes to numbers\nclass_to_num = dict(zip(dog_breeds,range(n_classes)))","e1495ca3":"#Function to load and convert images to array\nfrom keras.preprocessing.image import load_img\nfrom keras.utils import to_categorical\n\ndef images_to_array(data_dir,df,image_size):\n    image_names = df['id']\n    image_labels = df['breed']\n    data_size = len(image_names)\n    \n    X = np.zeros([data_size,image_size[0],image_size[1],image_size[2]],dtype = np.uint8)\n    y = np.zeros([data_size,1],dtype = np.uint8)\n    \n    for i in range(data_size):\n        img_name = image_names[i]\n        img_dir = os.path.join(data_dir,img_name)\n        img_pixels = load_img(img_dir,target_size=image_size)\n        X[i] = img_pixels\n        y[i] = class_to_num[image_labels[i]]\n        \n    y = to_categorical(y)\n    ind = np.random.permutation(data_size)\n    X = X[ind]\n    y = y[ind]\n    print('Ouptut Data Size: ', X.shape)\n    print('Ouptut Label Size: ', y.shape)\n    return X, y  ","8f8868a1":"#Selecting image size according to pretrained models\nimg_size = (299,299,3)\nX, y = images_to_array(train_img_Path,labels,img_size)","6f4493fd":"from keras.models import Model\nfrom keras.layers import BatchNormalization, Dense, GlobalAveragePooling2D,Lambda, Dropout, InputLayer, Input\n\ndef get_features(model_name, data_preprocessor,weight, input_size, data):\n    #Prepare pipeline.\n    input_layer = Input(input_size)\n    preprocessor = Lambda(data_preprocessor)(input_layer)\n    \n    base_model = model_name(weights=weight,\n                            include_top=False,\n                            input_shape=input_size)(preprocessor)\n    \n    avg = GlobalAveragePooling2D()(base_model)\n    feature_extractor = Model(inputs = input_layer, outputs = avg)\n    \n    #Extract feature.\n    feature_maps = feature_extractor.predict(data, batch_size=32, verbose=1)\n    print('Feature maps shape: ', feature_maps.shape)\n    return feature_maps\n","81355488":"#Extracting features using Xception\nfrom tensorflow import keras\nfrom keras.applications import Xception\nfrom keras.applications.xception import preprocess_input\nXception_preprocessor = preprocess_input\nXception_features = get_features(Xception,\n                                  Xception_preprocessor,\n                                 '..\/input\/d\/aeryss\/keras-pretrained-models\/Xception_NoTop_ImageNet.h5',\n                                  img_size, X)","cf5bb8f3":"#Extracting features using NASNetMobile\nfrom keras.applications import NASNetMobile\nfrom keras.applications.nasnet import preprocess_input\nNASNetMobile_preprocessor = preprocess_input\nNASNetMobile_features = get_features(NASNetMobile,\n                                  NASNetMobile_preprocessor,\n                                 '..\/input\/d\/aeryss\/keras-pretrained-models\/NASNetMobile_NoTop_ImageNet.h5',\n                                  img_size, X)","e3ab3e56":"#Extracting features using InceptionResNetV2\nfrom keras.applications import InceptionResNetV2\nfrom keras.applications.inception_resnet_v2 import preprocess_input\nInceptionResNetV2_preprocessor = preprocess_input\nInceptionResNetV2_features = get_features(InceptionResNetV2,\n                                  InceptionResNetV2_preprocessor,\n                                 '..\/input\/d\/aeryss\/keras-pretrained-models\/InceptionResNetV2_NoTop_ImageNet.h5',\n                                  img_size, X)","a7a996aa":"del X #to free up some ram memory\ngc.collect()","5117da93":"#Creating final featuremap by combining all extracted features\n\nfinal_features = np.concatenate([Xception_features,\n                                 NASNetMobile_features,\n                                 InceptionResNetV2_features,], axis=-1) #axis=-1 to concatinate horizontally\n\nprint('Final feature maps shape', final_features.shape)","a6e4a666":"#Callbacks\nfrom keras.callbacks import EarlyStopping\nEarlyStop_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nmy_callback=[EarlyStop_callback]","11cda8ff":"#Adding the final layers to the above base models where the actual classification is done in the dense layers\n#Building Model\nfrom keras.models import Sequential\nmodel = Sequential()\nmodel.add(InputLayer(final_features.shape[1:]))\nmodel.add(Dropout(0.7))\nmodel.add(Dense(120,activation='softmax'))\n\nmodel.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\nmodel.summary()\n\n# Training the CNN on the Train features and evaluating it on the val data\nhistory = model.fit(final_features,y,validation_split=0.1,callbacks=my_callback, epochs = 50, batch_size=32)","237797cf":"#deleting to free up ram memory\n\ndel NASNetMobile_features\ndel Xception_features\ndel InceptionResNetV2_features\ndel final_features\ngc.collect()","4995f110":"#Converting test images to array\ndef images_to_array2(data_dir,df, img_size):\n    images_names = df['id']\n    data_size = len(images_names)\n    X = np.zeros([data_size, img_size[0], img_size[1], 3], dtype=np.uint8)\n    \n    for i in range(data_size):\n        image_name = images_names[i]\n        img_dir = os.path.join(data_dir, image_name+'.jpg')\n        img_pixels = load_img(img_dir, target_size=img_size)\n        X[i] = img_pixels\n        \n    print('Ouptut Data Size: ', X.shape)\n    return X","8671fed0":"test_data = images_to_array2(test_img_Path, sample_submission, img_size)","babcdd67":"#Extract test data features.\ndef extact_features(data):\n    \n    Xception_features = get_features(Xception,\n                                     Xception_preprocessor,\n                                     '..\/input\/d\/aeryss\/keras-pretrained-models\/Xception_NoTop_ImageNet.h5',\n                                     img_size,\n                                     data)\n    \n    NASNetMobile_features = get_features(NASNetMobile,\n                                         NASNetMobile_preprocessor,\n                                         '..\/input\/d\/aeryss\/keras-pretrained-models\/NASNetMobile_NoTop_ImageNet.h5',\n                                         img_size, \n                                         data)\n    \n    InceptionResNetV2_features = get_features(InceptionResNetV2,\n                                              InceptionResNetV2_preprocessor,\n                                              '..\/input\/d\/aeryss\/keras-pretrained-models\/InceptionResNetV2_NoTop_ImageNet.h5',\n                                              img_size, \n                                              data)\n\n    final_features = np.concatenate([Xception_features,\n                                 NASNetMobile_features,\n                                 InceptionResNetV2_features,], axis=-1)\n    \n    print('Final feature maps shape', final_features.shape)\n    #deleting to free up ram memory\n    \n    del Xception_features\n    del NASNetMobile_features\n    del InceptionResNetV2_features\n    gc.collect()\n    \n    \n    return final_features","788a06e5":"test_features = extact_features(test_data)","f4616455":"y_pred = model.predict(test_features, batch_size=32)","67ab7899":"for breed in dog_breeds:\n    sample_submission[breed] = y_pred[:,class_to_num[breed]]\nsample_submission.to_csv('pred.csv', index=None)\nsample_submission","60722a3c":"# saving model for further use\nmodel.save('dogs_breed.h5')","c88a122a":"* this dataset have 120 dogs breeds but in the given task predict only on 10 breeds.","e0dec423":"### Dog breed classifier"}}