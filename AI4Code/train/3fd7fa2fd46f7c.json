{"cell_type":{"0e8bc3fe":"code","84536c54":"code","bf4e4316":"code","3efc67db":"code","6f101ca8":"code","2799c156":"code","5c7f5ea7":"code","a744e6a6":"code","5b0ee880":"code","f1a2451c":"code","14e00f09":"code","e2ec78c1":"code","f6bf4bc4":"code","5c30feff":"code","e4e164f4":"code","f6fdb49e":"code","e5c8e075":"code","c6dd586c":"code","f35f6ae4":"code","3b065083":"code","e6a82c51":"code","eeebf754":"code","b5b8caa0":"code","f49c3175":"code","88aee7b1":"code","2343c768":"code","ce481d0d":"code","89e0c4e4":"code","d6cd132c":"code","a9a002c0":"code","85dd82ca":"code","af0f8385":"code","d64dd4e5":"code","9c3dcbe7":"code","ff257657":"code","4f54ff66":"code","3b6bc47e":"code","95e6f0e7":"code","53c4441f":"code","0fa72bc5":"code","58ee9f5a":"code","6d5b9a37":"markdown","8a75bdc1":"markdown","ad481c7f":"markdown","9c8bc286":"markdown","ebe701e5":"markdown","3e3ce8c2":"markdown","cad2a19a":"markdown","c9e89c27":"markdown","fbb68ca3":"markdown","0dcf1240":"markdown","95a9f834":"markdown","902d2789":"markdown","131d7e72":"markdown","ba65ac00":"markdown","e7b7b6f4":"markdown","cffa8c4a":"markdown","2153a529":"markdown"},"source":{"0e8bc3fe":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","84536c54":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score","bf4e4316":"from sklearn.model_selection import train_test_split\n\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ny = train.Survived\npassengerid = test.PassengerId\n\n#Creating a whole dataset with train and test dataset \ntitanic = train.append(test, ignore_index = True)","3efc67db":"#Saving the train and test inde to split later\ntrain_index = len(train)\ntest_index = len(titanic) - len(test)","6f101ca8":"titanic.head()","2799c156":"titanic.info()","5c7f5ea7":"titanic['Title'] = titanic.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())","a744e6a6":"titanic.Title.value_counts()","5b0ee880":"normalized_title = {\n            'Mr':\"Mr\",\n            'Mrs': \"Mrs\",\n            'Ms': \"Mrs\",\n            'Mme':\"Mrs\",\n            'Mlle':\"Miss\",\n            'Miss':\"Miss\",\n            'Master':\"Master\",\n            'Dr':\"Officer\",\n            'Rev':\"Officer\",\n            'Col':\"Officer\",\n            'Capt':\"Officer\",\n            'Major':\"Officer\",\n            'Lady':\"Royalty\",\n            'Sir':\"Royalty\",\n            'the Countess':\"Royalty\",\n            'Dona':\"Royalty\",\n            'Don':\"Royalty\",\n            'Jonkheer':\"Royalty\"\n            \n}","f1a2451c":"titanic.Title = titanic.Title.map(normalized_title)","14e00f09":"print(titanic.Title.value_counts())","e2ec78c1":"grouped = titanic.groupby(['Sex','Title','Pclass'])\nprint(grouped.Age.median())","f6bf4bc4":"titanic.Age = grouped.Age.apply(lambda x: x.fillna(x.median()))\ntitanic.isnull().sum()","5c30feff":"#Since fare has only one missing value we will fill it with mean value\ntitanic.Fare = titanic.Fare.fillna(titanic.Fare.mean())\n\n#For the Cabin since it contains large number of missing values we will fill the unnown values as 'U'\ntitanic.Cabin = titanic.Cabin.fillna('U')\n\n#For the Embared we will fill it with the most frequent Embarked value\nmost_Embarked = titanic.Embarked.value_counts().index[0]\ntitanic.Embarked = titanic.Embarked.fillna(most_Embarked)","e4e164f4":"titanic.isnull().sum()","f6fdb49e":"#We also the add the member along with the famlily count\ntitanic['FamilySize'] = titanic['SibSp'] + titanic['Parch'] + 1","e5c8e075":"titanic.FamilySize.head()","c6dd586c":"titanic['Cabin'].value_counts()","f35f6ae4":"titanic.Cabin = titanic.Cabin.map(lambda x: x[0])\ntitanic.Cabin.head()","3b065083":"titanic.select_dtypes('object').columns","e6a82c51":"#Converting the male as 0 and female as 1 using the dictionary and mapping it\ntitanic.Sex = titanic.Sex.map({\"male\":0,\"female\":1})\n\n# #Converting the Title ,Cabin, Pclass and Embarked using get_dummies()\n# title_dummies = pd.get_dummies(titanic.Title , prefix = \"Title\")\n# cabin_dummies = pd.get_dummies(titanic.Cabin , prefix = \"Cabin\")\n# pclass_dummies = pd.get_dummies(titanic.Pclass , prefix =\"Pclass\")\n# embarked_dummies = pd.get_dummies(titanic.Embarked , prefix = \"Embarked\")","eeebf754":"from sklearn.preprocessing import LabelEncoder\nenc_lst = ['Title','Cabin','Pclass','Embarked']\nle = LabelEncoder()\n\nfor i in enc_lst:\n    titanic[i] = le.fit_transform(titanic[i])","b5b8caa0":"titanic.head()","f49c3175":"#Dropping the categorical columns in the titanic_dummies\ntitanic.drop(['Name', 'Ticket'],axis = 1,inplace = True)","88aee7b1":"titanic.head()","2343c768":"train_x = titanic[:train_index]\ntest_x = titanic[train_index:]","ce481d0d":"#Now converting the Survived column as int\ntrain_x.Survived = train_x.Survived.astype(int)","89e0c4e4":"# create X and y for data and target values \nX = train_x.drop('Survived', axis=1).values \ny = train_x.Survived.values","d6cd132c":"train_x.head()","a9a002c0":"# create array for test set\nX_test = test_x.drop('Survived', axis=1).values","85dd82ca":"label = train_x.Survived\ntrain_X , val_X , train_Y , val_Y = train_test_split(train_x , label,test_size = 0.2,shuffle = True)","af0f8385":"val_X.shape","d64dd4e5":"dtrain_X = train_X.drop('Survived',axis = 1)","9c3dcbe7":"dval_X = val_X.drop('Survived',axis = 1)","ff257657":"from sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nestimators = [('log_reg',LogisticRegression(random_state = 2,max_iter = 15)),\n              ('svm',make_pipeline(StandardScaler(),\n                                   SVC(gamma = 'auto',random_state = 2))),\n              ('random_forest',RandomForestClassifier(n_estimators=10,random_state = 2))                \n]\n\n\nstacking_clf = StackingClassifier(estimators = estimators,final_estimator=LogisticRegression())\n\nstacking_clf.fit(dtrain_X,train_Y)","4f54ff66":"stacking_clf.score(dval_X,val_Y)","3b6bc47e":"stack_ypred = stacking_clf.predict(dval_X)\nprint('Stacking classifier accuracy score is....',accuracy_score(val_Y,stack_ypred))","95e6f0e7":"prediction_stacking_clf = stacking_clf.predict(X_test)","53c4441f":"prediction_stacking_clf","0fa72bc5":"#storing it in submission file\noutput = pd.DataFrame({\"PassengerId\":passengerid , \"Survived\" : prediction_stacking_clf})\noutput.to_csv(\"Submission_stacking_clf.csv\",index = False)","58ee9f5a":"output","6d5b9a37":"Getting the input and storing it as train and test sets","8a75bdc1":"From the above we see that there are different categories of titles present now we will normalise them into broader category below.","ad481c7f":"Splitting the dataset as train and test from the titanic using the index we stored before.","9c8bc286":"Spliting a training set into training and validation set","ebe701e5":"We have filled the Age values in the missing columns now we have to fill the Cabin , Embarked and Fare.","3e3ce8c2":"Creating a label encoder to transform the categorical features into numerical","cad2a19a":"From the above output we can see that Age,Cabin and Fare have some missing values.\nFirst we will try to focus on the age","c9e89c27":"Before creating the model we have convert all our Categorical variables into numerical.Here we will use get_dummies() of pandas to do that work.","fbb68ca3":"In the below cell we will split the Name column into a broad category based on the given and replace the name with that.\nFor example, if the name is Robert,Mr.Jackson then we wil categorize him into Mr. that was present in his name. ","0dcf1240":"There are total of 187 cabin values present including the 'U' (unknown) we filled. Now instead of some alpha numeric value we will simply map it to the first letter of the value.","95a9f834":"# Feature Engineering","902d2789":"In the below code we will create a new feature which is total family members count by adding the SibSp and Parch.","131d7e72":"# Creating a model","ba65ac00":"The main reason we created title is because we have to fill the missing age.","e7b7b6f4":"The below is the reference from the https:\/\/medium.com\/i-like-big-data-and-i-cannot-lie\/how-i-scored-in-the-top-9-of-kaggles-titanic-machine-learning-challenge-243b5f45c8e9.","cffa8c4a":"# Handling with missing values","2153a529":"Now we dont have any missing values. we have to handle the categorical variables."}}