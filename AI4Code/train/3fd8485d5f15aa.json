{"cell_type":{"2fbe6bd1":"code","7289c406":"code","79b717a6":"code","6bc86f8d":"markdown","7df1a318":"markdown"},"source":{"2fbe6bd1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7289c406":"### Get Library\n \nimport torch\nimport torchvision\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom matplotlib import pyplot as plt\nimport os\ncwd = os.getcwd()\nimport time\nimport pandas as pd\nimport subprocess\nimport os\nfrom datetime import datetime,timedelta\nfrom datetime import date\nimport urllib.request\nfrom PIL import Image\n \nprint('----------------------- Libraries are imported ---------------------------')\n \n### Import Data and Create Train and test sets\n \ntorch.manual_seed(42)\ntorch.cuda.manual_seed(42)\n \n## Finds images\ntrain_data_path = '..\/input\/fruits\/fruits-360\/Training'\n \n### Rescaling incoming image to 28 by 28 pixels\n### After Rescaling, convert the image to a tensor\ntransform = transforms.Compose([transforms.Resize((28,28)),transforms.ToTensor()])\ntrain_data = torchvision.datasets.ImageFolder(root=train_data_path,transform=transform)\ntest_data = torchvision.datasets.ImageFolder(root=train_data_path,transform=transform)\nbatch_size = 32\ntrain_loader = torch.utils.data.DataLoader(train_data,batch_size,shuffle=True)\ntest_loader = train_loader\n##### Declare the model architecture\n \nd = 20\n \nclass VAE(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        \n        self.conv1 = nn.Sequential(\n        nn.Conv2d(in_channels=3,out_channels=2,kernel_size=3,padding=0,stride=1),\n            nn.ReLU(),\n        nn.BatchNorm2d(2)\n        )\n        self.fc1 = nn.Sequential(\n            ### Reduce the number of channels to 1 without changing the width and dimensions of the images\n            nn.Linear(26*26*2,128),\n            \n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Linear(128,64),\n            \n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.Linear(64,32)\n            \n        )\n \n        self.encoder = nn.Sequential(\n            \n            nn.Linear(32, d ** 2),\n            nn.ReLU(),\n            nn.Linear(d ** 2, d * 2)\n        )\n        \n \n        self.decoder = nn.Sequential(\n            nn.Linear(d, d ** 2),\n            nn.ReLU(),\n            nn.Linear(d ** 2, 32)\n        )\n        self.fc2 = nn.Sequential(\n            nn.Linear(32,64),\n            nn.ReLU(),\n            nn.BatchNorm1d(64),\n            nn.Linear(64,128),\n            nn.ReLU(),\n            nn.BatchNorm1d(128),\n            nn.Linear(128,26*26*2),\n            nn.ReLU(),\n            nn.BatchNorm1d(26*26*2)\n            \n        )\n        self.tconv1 = nn.Sequential(\n            nn.ConvTranspose2d(in_channels=2,out_channels=3,kernel_size=3,stride=1,padding=0),\n            \n            nn.Sigmoid()\n        \n        )\n \n    def reparameterise(self, mu, logvar):\n        if self.training:\n            ## Using log variance to ensure that we get a positive std dev\n            ## Converting to std dev in the real space\n            std = logvar.mul(0.5).exp_()\n            ### Create error term which has the same shape as std dev sampled from a N(0,1) distribution\n            eps = std.data.new(std.size()).normal_()\n            #eps = torch.zeros(std.size())\n            ### Add the mean and the std_dev \n            return eps.mul(std).add_(mu)\n        else:\n            return mu\n \n    def forward(self, x):\n        \n        #fc1_output = self.fc1(x.view(-1, 28*28*3))\n        conv1_output = self.conv1(x)\n        #print(conv1_output.size())\n        fc1_output = self.fc1(conv1_output.view(-1,26*26*2))\n        \n        ### Convert Encoded vector into shape (N,2,d)\n        mu_logvar = self.encoder(fc1_output).view(-1, 2, d)\n        ### First vector for each image is mean of the latent distribution\n        mu = mu_logvar[:, 0, :]\n        ### Second vector for each image is log-variance of the latent distribution\n        logvar = mu_logvar[:, 1, :]\n        ### Create variable Z = mu + error * Std_dev\n        z = self.reparameterise(mu, logvar)\n        ### Get decoder output\n        decoder_output = self.decoder(z)\n        \n        fc2_output = self.fc2(decoder_output)\n        tconv1_output = self.tconv1(fc2_output.view(fc2_output.size(0),2,26,26))\n        ## Resize Decoder Output to Pass it to TransposedConv2d layer to recontruct 3 channeled image\n        #decoder_output = decoder_output.view(decoder_output.size(0),1,28,28) \n        ## Return Reconstructed Output and mean and log-variance\n        return tconv1_output, mu, logvar,z\n    \nmodel = VAE()\n \nprint('----------------------- Model has been Initialized ---------------------------')\n \n \n#### Declare the optimizer and learning rate\n \nlearning_rate = 3e-3\n \noptimizer = torch.optim.Adam(\n    model.parameters(),\n    lr=learning_rate\n    )\n### Loss function\n \n#Reconstruction + KL divergence losses summed over all elements and batch\n \ndef loss_function(x_hat, x, mu, logvar):\n    MSE = nn.MSELoss(reduction='sum')\n    ## Making sure that distributions do not overlap\n#     loss = nn.functional.binary_cross_entropy(\n#         x_hat, x, reduction='sum'\n#     )\n    loss = MSE(x_hat,x)\n    #loss = MSE(x_hat,x.view(x.size(0), -1))\n#     BCE = nn.functional.binary_cross_entropy(\n#         x_hat, x.view(-1, 28*28*3), reduction='sum'\n#     )\n    ### Makes sure that distributions of each image span entire latent space and the range does not explode\n    KLD = 0.5 * torch.sum(logvar.exp() - logvar - 1 + mu.pow(2))\n \n    return loss + KLD\n \n##### Training the model\nprint('----------------------- Training is started ---------------------------')\n \nepochs = 50\ncodes = dict(\u03bc=list(), log\u03c32=list(), y=list())\n \nloss = {\n    'train_loss':[],\n    'test_loss' : []\n}\nfor epoch in range(0, epochs + 1):\n    # Training\n    if epoch > 0:  # test untrained net first\n        model.train()\n        train_loss = 0\n        for x, _ in train_loader:\n            #x = x.to(device)\n            # ===================forward=====================\n            x_hat, mu, logvar,_ = model(x)\n            loss = loss_function(x_hat, x, mu, logvar)\n            train_loss += loss.item()\n            # ===================backward====================\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        # ===================log========================\n        \n        #loss['train_loss'].append(train_loss)\n        if epoch % 1 ==0:\n            print(f'====> Epoch: {epoch} Average loss: {train_loss \/ len(train_loader.dataset):.4f}')\n    \n    # Testing\n    \n    means, logvars, labels = list(), list(), list()\n    with torch.no_grad():\n        model.eval()\n        test_loss = 0\n        for x, _ in test_loader:\n            #x = x.to(device)\n            # ===================forward=====================\n            x_hat, mu, logvar,_ = model(x)\n            test_loss += loss_function(x_hat, x, mu, logvar).item()\n            # =====================log=======================\n            means.append(mu.detach())\n            logvars.append(logvar.detach())\n            #labels.append(y.detach())\n    # ===================log========================\n    #loss['test_loss'].append(test_loss)\n    codes['\u03bc'].append(torch.cat(means))\n    codes['log\u03c32'].append(torch.cat(logvars))\n    test_loss \/= len(test_loader.dataset)\n    if epoch % 1 == 0:\n        print(f'====> Test set loss: {test_loss:.4f}')\n        #display_images(x, x_hat, 1, f'Epoch {epoch}')\n        #plt.show()\n \n#### Extract embeddings\nprint('----------------------- Training has ended ---------------------------')\n \n \n \ncheckpoint = {'model': model,\n              'state_dict': model.state_dict(),\n              'optimizer' : optimizer.state_dict()}\n \ntorch.save(checkpoint, 'checkpoint.pth')\n \nprint('----------------------- Save the Model ---------------------------')","79b717a6":"import numpy as np\ntransform = transforms.Compose([transforms.Resize((28,28)),transforms.ToTensor()])\n\nmodel.eval()\n\nimage_names = []\nimage_embeddings = np.zeros((103,d))\ncount = 0\n\nfor i in os.listdir('..\/input\/fruits\/fruits-360\/test-multiple_fruits\/'):\n    image_path = '..\/input\/fruits\/fruits-360\/test-multiple_fruits\/'+i\n    img = Image.open(image_path)\n    img = transform(img)\n    img = img.view(1,3,28,28)\n    x_hat,mu,sigma,embedding_vector = model(img)\n    image_names.append(i)\n    embedding_vector = mu.detach().numpy()\n    image_embeddings[count,:] = embedding_vector\n    count = count+1\nfrom numpy import array as a\nfrom numpy.linalg.linalg import norm\nfrom numpy import set_printoptions\n\nM = image_embeddings   # create demo matrix\n\n# dot products of rows against themselves\nDotProducts = M.dot(M.T);       \n\n# kronecker product of row norms\nNormKronecker = a([norm(M, axis=1)]) * a([norm(M, axis=1)]).T; \n\nCosineSimilarity = DotProducts \/ NormKronecker\nimport pandas as pd\ndf_vae = pd.DataFrame(CosineSimilarity)\ndf_vae.index = image_names\ndf_vae.columns = image_names\nimport random\nnum_selected = 5\nlist_of_random_items = random.sample(image_names, num_selected)\nfrom matplotlib import pyplot as plt\n\nfor image in list_of_random_items:\n    filtered_df = df_vae[[image]].sort_values(by=image,ascending=False)\n    ### Selected top n \n    n = 5\n    filtered_df = filtered_df.head(n)\n    images_recommended = filtered_df.index\n    print('Similar Images to :')\n    print(image)\n    print('---')\n    for image_reco in images_recommended:\n        im = Image.open('..\/input\/fruits\/fruits-360\/test-multiple_fruits\/'+str(image_reco))\n        plt.imshow(im)\n        plt.pause(0.5)\n        \n","6bc86f8d":"## Displaying Similar Images\n\n* Choose images from test-multiple-fruits folder\n* Extract mean vector for each image\n* Calculate cosine silimarity of mean vector of each image to each other\n* Choose 5 random images and display the top five images close to these images.","7df1a318":"## Creating a variational autoencoder\n\n* The embeddings of each image will be used as a low dimensional representation of the image.\n* Cosine Similarity of the images are calculated against each other."}}