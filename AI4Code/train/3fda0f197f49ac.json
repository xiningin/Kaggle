{"cell_type":{"21339448":"code","a6751bb5":"code","8d342641":"code","b76c3de7":"code","b2011a3a":"code","eda4a9fb":"code","08edf622":"code","a8a179ee":"code","a98e3f9a":"code","54d2f38b":"code","1f515073":"code","065aafad":"code","10a24459":"code","a5ae0dd3":"code","213f8ecf":"code","91bfdc92":"code","4156ce45":"code","31558b7a":"code","2923c3b4":"markdown","ad61e257":"markdown","87a05022":"markdown","5f58bdcc":"markdown","964db5b2":"markdown","3fc7817d":"markdown","dbedc34a":"markdown","c4c874fa":"markdown","b6169bb5":"markdown","5346cd93":"markdown","aa15bf77":"markdown","f78701ed":"markdown"},"source":{"21339448":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","a6751bb5":"# Necessary Dependancies\nimport torch\nfrom torch import nn,optim\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\nimport pandas as pd\nimport numpy as np\n\nfrom tqdm import tqdm","8d342641":"# Read data from csv\ndf = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\nprint(df.shape)","b76c3de7":"y = df['label']\nx = df[df.columns[1:]]\nprint(x.shape)\nprint(y.shape)","b2011a3a":"xtrain,xval,ytrain,yval = train_test_split(x,y,train_size=0.8)\nprint(f'Training: X.shape = {xtrain.shape}  Y.shape = {ytrain.shape}')\nprint(f'Validation: X.shape = {xval.shape}  Y.shape = {yval.shape}')","eda4a9fb":"# Normalizing the input data\n# Normalizing helps gradients converge faster \nxtrain = xtrain \/ 255\nxval = xval \/ 255","08edf622":"# Converting the numpy arrays to tensors\nxtrain_tensor = torch.tensor(np.array(xtrain),dtype = torch.float)\nytrain_tensor = torch.tensor(np.array(ytrain))\nytrain_tensor = ytrain_tensor.type(torch.LongTensor)    # Categorical attributes should be in LongTensor\n\nxval_tensor = torch.tensor(np.array(xval),dtype = torch.float)\nyval_tensor = torch.tensor(np.array(yval))\nyval_tensor = yval_tensor.type(torch.LongTensor)","a8a179ee":"# Obtaining TensorDatasets and dataloaders\n\ntrain_batch_size = 64\nval_batch_size = 64\n\n# Create the train dataset\ntrain_dataset = TensorDataset(xtrain_tensor,ytrain_tensor)\n# Create the train dataloader\ntrain_dataloader = DataLoader(train_dataset,batch_size = train_batch_size)\n\n# Create the val dataset\nval_dataset = TensorDataset(xval_tensor,yval_tensor)\n# Create the validation dataloader\nval_dataloader = DataLoader(val_dataset,batch_size = val_batch_size)","a98e3f9a":"# Model Architecture\nclass Net(nn.Module):\n    \n    def __init__(self):\n        \n        hidden1 = 512\n        hidden2 = 256\n        \n        super().__init__()\n        # Input layer\n        self.fc1 = nn.Linear(784,hidden1)\n        # layer 2\n        self.fc2 = nn.Linear(hidden1,hidden2)\n        #layer 3 \/ output layer\n        self.output = nn.Linear(hidden2,10) # 10 as we have ten classes\n        # dropout to prevent overfitting\n        self.dropout = nn.Dropout(p=0.2) # while training drops 20% of neurons for a particular layer\n        \n    def forward(self,x):\n        \n        # We apply Dropout to the first two layers\n        x = self.dropout(F.relu(self.fc1(x)))\n        x = self.dropout(F.relu(self.fc2(x)))\n        \n        # The output layer has no dropout and a log_softmax activation is applied to it \n        x = F.log_softmax(self.output(x),dim=1)\n        \n        # We then return the value obtained from forward prop\n        return x\n\n# Instanstiating the model\nmodel = Net()","54d2f38b":"# Loss Function\ncriterion = nn.NLLLoss()\n\n# Optimizer \noptimizer = optim.Adam(model.parameters(),lr = 0.003)","1f515073":"# Check if GPU is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","065aafad":"model.to(device)","10a24459":"epochs = 100\n\n# History dictionary\nhistory = {'loss':[],'acc':[],'val_loss':[],'val_acc':[]}\n\nmax_val_acc = 0\n# Training over all epochs\nfor e in range(epochs):\n    \n    running_loss, total, correct,val_running_loss, val_total, val_correct = 0,0,0,0,0,0\n    \n    # TRAINING SET\n    \n    # Set model to train mode\n    model.train()\n    \n    # Loading the data in batches\n    for images, labels in train_dataloader:\n        \n        # sending the images and labels tensor to the GPU\n        images, labels = images.to(device), labels.to(device)\n        # FORWARD PROPOGATION\n        \n        # Pass the images as input to the model\n        outputs = model(images)\n        # Calculate loss between prediction and actual output\n        loss = criterion(outputs, labels)\n        \n        # BACKWARD PROPOGATION\n        \n        # zero_grad() is to avoid accumalation of gradients\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # Metrics\n        # summing the losses over entire training set\n        running_loss += loss.item()\n        total += labels.size(0)\n        predicted = torch.argmax(torch.exp(outputs).data,1)\n        correct += (predicted == labels).sum().item()\n        \n    # VALIDATION SET\n    \n    with torch.no_grad():  # This disables gradient calculations on validation set\n        \n        # Lets set model to eval mode. This will turn-off the dropouts\n        model.eval()\n        \n        # Loading the validation data in batches\n        for val_images, val_labels in val_dataloader:\n            \n            # sending the images and labels tensor to the GPU\n            val_images, val_labels = val_images.to(device), val_labels.to(device)\n    \n            # FORWARD PROPOGATION\n\n            # Pass the images as input to the model\n            val_outputs = model(val_images)\n            # Calculate loss between prediction and actual output\n            val_loss = criterion(val_outputs, val_labels)\n\n            # Metrics\n            # summing the losses over entire training set\n            val_running_loss += val_loss.item()\n            val_total += val_labels.size(0)\n            val_predicted = torch.argmax(torch.exp(val_outputs).data,1)\n            val_correct += (val_predicted == val_labels).sum().item()\n            \n    # Finally saving all the metrics to the history dictionary\n    acc = correct\/total * 100\n    val_acc = val_correct\/val_total * 100\n    history['loss'].append(running_loss)\n    history['acc'].append(acc)\n    history['val_loss'].append(val_running_loss)\n    history['val_acc'].append(val_acc)\n    \n    # Logs \n    print(f'Epoch {e}: (Training: Loss:{running_loss:.3f} Acc:{acc:.2f})  (Validation: Loss:{val_running_loss:.3f} Acc:{val_acc:.2f})')\n    \n    # Save the model with the best accuracy on Validation data\n    \n    if val_acc > max_val_acc:\n        torch.save(model.state_dict(),str(e) + \"_model.pth\")\n        max_val_acc = val_acc","a5ae0dd3":"import plotly.graph_objs as go\n\n# Plot Loss\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n    x = list(range(epochs)),\n    y = history['loss'],\n    mode = 'lines',\n    name = 'Train loss'   \n))\nfig.add_trace(go.Scatter(\n    x = list(range(epochs)),\n    y = history['val_loss'],\n    mode = 'lines',\n    name = 'Validation loss'   \n))\n\nfig.update_layout(\n    title = 'Train and Validation Loss'\n)\nfig.show()","213f8ecf":"# Plot Accuracy\nfig = go.Figure()\nfig.add_trace(go.Scatter(\n    x = list(range(epochs)),\n    y = history['acc'],\n    mode = 'lines',\n    name = 'Train Accuracy'   \n))\nfig.add_trace(go.Scatter(\n    x = list(range(epochs)),\n    y = history['val_acc'],\n    mode = 'lines',\n    name = 'Validation Accuracy'   \n))\n\nfig.update_layout(\n    title = 'Train and Validation Accuracy'\n)\nfig.show()","91bfdc92":"# Load the test file\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\n\n# Normalize the data\nxtest = test \/ 255\n\n# Convert to numpy from dataframe \nxtest = np.array(xtest)\n\nxtest.shape","4156ce45":"submission = {'ImageId':list(range(1,28001)),'Label':[]}\nfor row in tqdm(xtest):\n    image_tensor = torch.tensor(np.array(row),dtype=torch.float)\n    image_tensor = image_tensor.unsqueeze(0)\n    \n    image_tensor = image_tensor.to(device)\n    \n    # Set model to evaluation mode\n    model.eval()\n    \n    outputs = model(image_tensor)\n    predicted = torch.argmax(torch.exp(outputs).data,1).item()\n    submission['Label'].append(predicted)","31558b7a":"sub = pd.DataFrame(submission)\nsub.to_csv('digits_sub_pytorch.csv',index=False)","2923c3b4":"# 4. Visualizing Performance Metrics","ad61e257":"# 3. Training the model","87a05022":"Lets first put the model on the GPU","5f58bdcc":"# 5. Creating a submission","964db5b2":"Splitting the labels from the input","3fc7817d":"Dataloaders are useful for training and validating data as small chunks known as *Mini-Batches*. It is used mainly when all the data is too large to reside in the memory","dbedc34a":"Splitting the Data into Training and Validation sets","c4c874fa":"Note that the saved model with the highest epoch number is the model with the best validation accuracy. This model can further be used for any prediction or retraining later","b6169bb5":"In this Notebook you will learn how to build a basic Full-Connected model in pytorch using the nn module.\nYou will also learn how to create a submission for a kaggle competition.","5346cd93":"# 2. Model Building ","aa15bf77":"# 1. Data Loading ","f78701ed":"Converting the Data into TensorDataset and creating DataLoaders"}}