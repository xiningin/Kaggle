{"cell_type":{"c954d1a0":"code","99b2c572":"code","afc8cb83":"code","576f076d":"code","d31717a6":"code","9c22b7ec":"code","38d63199":"code","fb849cd5":"code","a20bf4f6":"code","d860b223":"code","3f49d263":"markdown","bc8bfcbb":"markdown"},"source":{"c954d1a0":"#Import all the required Libraries\nimport numpy as np\nimport pandas as pd\nimport keras\nimport matplotlib.pyplot as plt\nfrom functools import partial\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Input, Dropout\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n\n%matplotlib inline\nnp.random.seed(1)","99b2c572":"#Importing the training and testing data\ntraining_set = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntesting_set = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n\nprint(\"The shape of training data - \", training_set.shape)\nprint(\"The shape of testing data - \", testing_set.shape)","afc8cb83":"#Let's split the label and the pixel values from the training data\nX_train = training_set.drop(['label'], axis=1).values.reshape(training_set.shape[0], 28, 28, 1)\ny_train = training_set['label'].copy()\ntesting_set = testing_set.values.reshape(testing_set.shape[0], 28, 28, 1)\n\nprint(\"The shape of X_train is : \", X_train.shape)\nprint(\"The shape of y_train is : \", y_train.shape)\nprint(\"The shape of testing_set is : \", testing_set.shape)","576f076d":"#It is important to have a validation set to assess the model's performance.\n#We will be creating a validation set which contains atleast 6,800 images.\n\n#first shuffling the dataset\nshuffled_indices = np.random.permutation(42000)\nX_train = X_train[shuffled_indices]\ny_train = y_train[shuffled_indices]\n\n#Creating a validation set from the last 6,800 images\nX_train, X_valid = X_train[:35200], X_train[35200:]\ny_train, y_valid = y_train[:35200], y_train[35200:]\n\nprint(\"The shape of X_train is : \", X_train.shape)\nprint(\"The shape of y_train is : \", y_train.shape)\nprint(\"The shape of X_valid is : \", X_valid.shape)\nprint(\"The shape of y_valid is : \", y_valid.shape)","d31717a6":"#Let's see how many images are there per class(digit)\n\nprint(y_train.value_counts())","9c22b7ec":"#Each class has around 3200 to 3900 images. So the chance of class imbalance is less\n#Create a basic Convolutional Neural Network model\n\nDefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, activation='relu', padding='same')\n\nDigit_Recognizer = Sequential([\n                        DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n                        keras.layers.MaxPooling2D(pool_size=2),\n                        DefaultConv2D(filters=128),\n                        DefaultConv2D(filters=128),\n                        keras.layers.MaxPooling2D(pool_size=2),\n                        DefaultConv2D(filters=256),\n                        DefaultConv2D(filters=256),\n                        keras.layers.MaxPooling2D(pool_size=2),\n                        keras.layers.Flatten(),\n                        Dense(units=128, activation='relu'),\n                        Dropout(0.5),\n                        Dense(units=64, activation='relu'),\n                        Dropout(0.5),\n                        Dense(units=10, activation='softmax'),\n                   ])\n\nDigit_Recognizer.compile(optimizer=\"nadam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])","38d63199":"#Summarizing the model\nDigit_Recognizer.summary()","fb849cd5":"#Training the model\nfilepath = \".\/model.h5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, \n                             save_best_only=True, mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='accuracy', factor=0.5, patience=2, \n                                   verbose=1, mode='max', min_lr=0.00001)\n                              \n                              \ncallbacks_list = [checkpoint, reduce_lr]\nhistory = Digit_Recognizer.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_valid, y_valid), \n                     verbose=1, callbacks=callbacks_list)","a20bf4f6":"#testing on an image\nDigit_Recognizer = load_model('.\/model.h5')     #Loading the best model\nplt.imshow(X_valid[1234].reshape(28, 28))\nprint(\"The digit recognized by the model is : \", Digit_Recognizer.predict_classes(X_valid[1234].reshape(1, 28, 28, 1)))\nplt.axis('off')\nplt.show()","d860b223":"#The model predicts with almost 99.2% validation accuracy\ntest_predictions = pd.DataFrame(Digit_Recognizer.predict_classes(testing_set), index=range(1, 28001))\ntest_predictions.to_csv('.\/Submissions.csv', index_label=['ImageId', 'Label'])","3f49d263":"As you can see the training set has 785 columns : first column for label (target), and the rest 784 columns are the pixel values for the image.\nThe training data has 42000 images and the testing data has 28000 images.","bc8bfcbb":"# Digit Recognizer Using Deep Neural Network\n\nThe data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n\nEach image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n\nThe training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n\nEach pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero)."}}