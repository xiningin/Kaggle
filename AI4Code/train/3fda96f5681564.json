{"cell_type":{"c984515b":"code","81bfc3df":"code","df49fdee":"code","a29c7f29":"code","8b2f0d71":"code","438f7ec8":"code","608cfb50":"code","8356f565":"code","df24dc6e":"code","5f1c2b05":"code","7bfebb0d":"code","5672395e":"code","c36d1ab3":"code","e5dc2a4d":"code","5915dfcf":"code","ec70231b":"code","f43d3c48":"code","78875064":"code","96e00269":"code","b505867a":"code","7a94406c":"code","46033fe3":"markdown"},"source":{"c984515b":"# importing all libraries\n\n# from numpy\nimport numpy as np \nfrom numpy import asarray, expand_dims, zeros, ones, vstack\nfrom numpy.random import randn, randint\n\n# from keras\nimport keras\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Reshape, Dropout, Flatten,\\\n    Conv2D, MaxPooling2D, LeakyReLU, Conv2DTranspose\nfrom keras.optimizers import Adam\n\n# others\nfrom matplotlib import pyplot\nimport pandas as pd \nimport os","81bfc3df":"train_path = \"..\/input\/digit-recognizer\/train.csv\"\ntest_path = \"..\/input\/digit-recognizer\/test.csv\"\n\ntrain_data = pd.read_csv(train_path)\ntest_data = pd.read_csv(test_path)\n\ntrain_data.head()","df49fdee":"train_data = train_data.iloc[:,1:]","a29c7f29":"train_data = np.array(train_data.values.reshape(-1, 28, 28, 1))\ntest_data = np.array(test_data.values.reshape(-1, 28, 28, 1))","8b2f0d71":"print(\"Train shape : \", train_data.shape, \", test shape : \" ,test_data.shape)","438f7ec8":"fig,ax=pyplot.subplots(1,5,figsize=(15,10))\n\nfor i in range(5):\n    img = train_data[i]\n    img = np.squeeze(img)\n    ax[i].imshow(img)\n    \npyplot.show()","608cfb50":"X = np.append(train_data , test_data, axis = 0)\nX = X.astype('float32')\nfulldata = X\/255.0\n\nprint(fulldata.shape)","8356f565":"modelGen = Sequential()\n\nn_nodes = 128 * 7 * 7\n\nmodelGen.add(Dense(n_nodes, input_dim = 100))\nmodelGen.add(LeakyReLU(alpha=0.2))\n\nmodelGen.add(Reshape((7, 7, 128)))\n\nmodelGen.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\nmodelGen.add(LeakyReLU(alpha=0.2))\n\nmodelGen.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\nmodelGen.add(LeakyReLU(alpha=0.2))\n\nmodelGen.add(Conv2D(1, (7,7), activation='sigmoid', padding='same'))\n\nmodelGen.summary()","df24dc6e":"# displaying the model\n#keras.utils.plot_model(modelGen, \"modelGen.png\", show_shapes=True)","5f1c2b05":"modelDis = Sequential()\n\nmodelDis.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=(28,28,1) ))\nmodelDis.add(LeakyReLU(alpha=0.2))\nmodelDis.add(Dropout(0.4))\n\nmodelDis.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\nmodelDis.add(LeakyReLU(alpha=0.2))\nmodelDis.add(Dropout(0.4))\n\nmodelDis.add(Flatten())\n\nmodelDis.add(Dense(1, activation='sigmoid'))\n\nmodelDis.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5) , metrics=['accuracy'])\n\nmodelDis.summary()","7bfebb0d":"#disabling training for discriminator\nmodelDis.trainable = False\n\nmodel = Sequential()\n\n# adding generator\nmodel.add(modelGen)\n\n# adding discriminator\nmodel.add(modelDis)\n\n# compile model\nopt = Adam(lr=0.0002, beta_1=0.5)\n\nmodel.compile(loss='binary_crossentropy', optimizer=opt)\nmodel.summary()","5672395e":"def generate_real_samples(dataset, n_samples):\n    \n    # choose random instances\n    index = randint(0, dataset.shape[0], n_samples)\n    \n    # retrieve selected images\n    X = dataset[index]\n    \n    # generate 'real' class labels (1)\n    y = ones((n_samples, 1))\n    \n    return X, y","c36d1ab3":"def generate_latent_points(latent_dim, n_samples):\n    \n    # generate points in the latent space\n    x_input = randn(latent_dim * n_samples)\n    \n    # reshape into a batch of inputs for the network\n    x_input = x_input.reshape(n_samples, latent_dim)\n    \n    return x_input","e5dc2a4d":"def generate_fake_samples(latent_dim, n_samples):\n\n    # generate points in latent space\n    x_input = generate_latent_points(latent_dim, n_samples)\n    \n    # predict outputs\n    X = modelGen.predict(x_input)\n    \n    # create 'fake' class labels (0)\n    y = zeros((n_samples, 1))\n    \n    return X, y","5915dfcf":"def save_plot(examples, n=10):\n    \n    print(n)\n    print(examples.shape)\n    # plot images\n    for i in range(n * n):\n        # define subplot\n        pyplot.subplot(n, n, 1 + i)\n        # turn off axis\n        pyplot.axis('off')\n        # plot raw pixel data\n        pyplot.imshow(examples[i, :, :, 0], cmap='gray_r')\n    pyplot.show()\n    \n    # save plot to file\n    filename = 'generated_plot_e%03d.png' % (n+1)    \n    pyplot.savefig(filename)\n    ","ec70231b":"def summarize_performance(epoch, dataset, latent_dim, n_samples=100):\n\n    # prepare real samples\n    X_real, y_real = generate_real_samples(dataset, n_samples)\n    \n    # evaluate discriminator on real examples    \n    _, acc_real = modelDis.evaluate(X_real, y_real, verbose=0)\n\n    # prepare fake examples    \n    x_fake, y_fake = generate_fake_samples(latent_dim, n_samples)\n    \n    # evaluate discriminator on fake examples\n    _, acc_fake = modelDis.evaluate(x_fake, y_fake, verbose=0)\n    \n    # summarize discriminator performance\n    print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n    \n    # save plot\n    save_plot(x_fake, 10)\n    \n    # save the generator model tile file\n    filename = 'generator_model_%03d.h5' % (epoch)\n    \n    modelGen.save(filename)\n\n","f43d3c48":"# train the generator and discriminator\ndef train(latent_dim=100, n_epochs=10, n_batch=256):\n    \n    bat_per_epo = int(fulldata.shape[0] \/ n_batch)\n    half_batch = int(n_batch \/ 2)\n    \n    # manually enumerate epochs\n    for i in range(n_epochs):\n        # enumerate batches over the training set\n        for j in range(bat_per_epo):\n    \n            # get randomly selected 'real' samples\n            X_real, y_real = generate_real_samples(fulldata, half_batch)\n            \n            # generate 'fake' examples\n            X_fake, y_fake = generate_fake_samples(latent_dim, half_batch)\n            \n            # create training set for the discriminator\n            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n            \n            # update discriminator model weights\n            d_loss, _ = modelDis.train_on_batch(X, y)\n            \n            # prepare points in latent space as input for the generator\n            X_gan = generate_latent_points(latent_dim, n_batch)\n            \n            # create inverted labels for the fake samples\n            y_gan = ones((n_batch, 1))\n            \n            # update the generator via the discriminator's error\n            g_loss = model.train_on_batch(X_gan, y_gan)\n            \n            # summarize loss on this batch\n        \n        print('> %d epoches done out of %d' % (i+1 , n_epochs))\n        \n        # evaluate the model performance, sometimes\n        if (i+1) % 10 == 0:\n            summarize_performance(i, fulldata, latent_dim)\n","78875064":"train(n_epochs = 10,n_batch=256)","96e00269":"# load model\nmodelSaved = load_model('generator_model_009.h5')\n# generate images\n\nlatent_points = generate_latent_points(100, 100)\n# generate images\n\nX = modelSaved.predict(latent_points)\n# plot the result\n\nsave_plot(X, 10)","b505867a":"# load model\nmodel = load_model('generator_model_009.h5')\n# all 0s\nvector = asarray([[0.0 for _ in range(100)]])\n# generate image\nX = model.predict(vector)\n# plot the result\npyplot.imshow(X[0, :, :, 0], cmap='gray_r')\npyplot.show()","7a94406c":"example = generate_latent_points(100, 10)\n\nprint(example)\nprint(\"\\n\",example.shape)\n\nans = model.predict(example)\n\nfor i in range(10):\n    \n    # define subplot\n    pyplot.subplot(2, 5, 1 + i)\n    \n    # plot raw pixel data\n    pyplot.imshow(ans[i, :, :, 0], cmap='gray_r')\n    \npyplot.show()","46033fe3":"# GANs using MNIST\n\n\n1. [Introduction]()\n2. [Creating dataset]()\n3. [Creating models]()\n4. [Defining functions]()\n5. [Training the model]()\n6. [Testing the model]()\n\n\n[Understand the Math and Theory of GANs in ~ 10 minutes](https:\/\/youtu.be\/J1aG12dLo4I)\n\n\n"}}