{"cell_type":{"82bc18c6":"code","621b4066":"code","e149d014":"code","ee1e4c32":"code","d370963c":"code","c552f733":"code","c146dcab":"code","d9b10752":"code","0edc36bf":"code","036cfa54":"code","e810816d":"code","cac5ab59":"code","f6224aea":"code","3e4082b4":"code","c0e15ba1":"code","c7bcb303":"code","3517d451":"markdown","c223f310":"markdown"},"source":{"82bc18c6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","621b4066":"#let's pull  mushroom data and analyse it\n\nmushroom = pd.read_csv('\/kaggle\/input\/mushroom-classification\/mushrooms.csv')\nmushroom.info()","e149d014":"#pulling the first five rows of dataset\nmushroom.head(5).transpose()","ee1e4c32":"#checking for null values\nmushroom.isna().sum()","d370963c":"#checking for duplicates\nmushroom.duplicated().sum()","c552f733":"#checking for unique value counts\nfor i in mushroom.columns:\n    print(mushroom[str(i)].value_counts())\n    print('\\n')","c146dcab":"#generating dummy variable through one-hot encoding\nmushroom_en = pd.get_dummies(mushroom, drop_first = True)\nmushroom_en.shape\nmushroom_en.columns","d9b10752":"#splitting the dataset\nX_feature = list(mushroom_en.columns)\nX_feature.remove('class_p')\nX = mushroom_en[X_feature]\nX.columns","0edc36bf":"Y = mushroom_en['class_p']\nY.head()","036cfa54":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.30, random_state = 42)","e810816d":"print(\"X_train.shape\",X_train.shape)\nprint(\"X_test.shape\",X_test.shape)\nprint(\"y_train.shape\",y_train.shape)\nprint(\"y_test.shape\",y_test.shape)","cac5ab59":"#We'll go through the indivisual models one by one\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 21)\nknn.fit(X_train, y_train)\n\n#predicting for test data\nknn_test_pred = knn.predict(X_test)\n\n#evaluate the model\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(y_test, knn_test_pred))\n","f6224aea":"pd.crosstab(y_test, knn_test_pred, rownames = ['Actual'], colnames= ['Predictions'])","3e4082b4":"#error on train data\nknn_train_pred = knn.predict(X_train)\nprint(accuracy_score(y_train, knn_train_pred))","c0e15ba1":"pd.crosstab(y_train, knn_train_pred, rownames = ['Actual'], colnames = ['Predictions'])","c7bcb303":"# creating empty list variable \nacc = []\n\n# running KNN algorithm for 3 to 50 nearest neighbours(odd numbers) and \n# storing the accuracy values\n\nfor i in range(3,50,2):\n    neigh = KNeighborsClassifier(n_neighbors=i)\n    neigh.fit(X_train, y_train)\n    train_acc = np.mean(neigh.predict(X_train) == y_train)\n    test_acc = np.mean(neigh.predict(X_test) == y_test)\n    acc.append([train_acc, test_acc])\n\n\nimport matplotlib.pyplot as plt # library to do visualizations \n\n# train accuracy plot \nplt.plot(np.arange(3,50,2),[i[0] for i in acc],\"ro-\")","3517d451":"***Our column count has increased to 96. We will try to feed the data directly to the model. Also it would be prudent if we perform dimensionality reduction techniques like PCA. But first lets check the efficiency of our models.***","c223f310":"***Points to be observed from above value count. There doesn't appear to be any class unbalance in the target variable. So we can go ahead with random sampling method.***\n"}}