{"cell_type":{"98ef0f1e":"code","2d9da659":"code","568e6567":"code","58882026":"code","3f000dbf":"code","a47deb25":"code","69891d00":"code","86fc05fd":"code","1d4bfdc4":"code","5fd496e5":"code","212e4b7d":"code","f63b40ee":"code","5d2270e9":"code","bffc8de8":"code","aba357ea":"code","385a2c6e":"code","c8b0abf2":"code","957c706a":"code","cee998c5":"code","5053e57b":"code","90ee595e":"markdown","cf143fdd":"markdown","c17aadc8":"markdown"},"source":{"98ef0f1e":"#codes from Rodrigo Lima  @rodrigolima82\nfrom IPython.display import Image\nImage(url = 'https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcTlif8SG5U1SZ-8kajuOTaa4eV_6djX2qdNayeYzJBuMx7GsO3U',width=400,height=400)","2d9da659":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import feature_extraction, linear_model, model_selection, preprocessing\nimport plotly.graph_objs as go\nimport plotly.offline as py\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","568e6567":"df = pd.read_csv('..\/input\/startup-investments-crunchbase\/investments_VC.csv', encoding='ISO-8859-2')","58882026":"df.head()","3f000dbf":"df.dtypes","a47deb25":"print(df.shape)","69891d00":"df.isnull().sum()","86fc05fd":"df = df.dropna(subset=['founded_at', 'founded_month', 'state_code', 'founded_quarter', 'founded_year','country_code'])","1d4bfdc4":"from wordcloud import WordCloud, STOPWORDS\nstopwords = set(STOPWORDS)\n\ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='black',\n        stopwords=stopwords,\n        max_words=200,\n        max_font_size=40, \n        scale=3,\n        random_state=1 # chosen at random by flipping a coin; it was heads\n).generate(str(data))\n\n    fig = plt.figure(1, figsize=(15, 15))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()\n\nshow_wordcloud(df['name'])","5fd496e5":"cnt_srs = df['name'].value_counts().head()\ntrace = go.Bar(\n    y=cnt_srs.index[::-1],\n    x=cnt_srs.values[::-1],\n    orientation = 'h',\n    marker=dict(\n        color=cnt_srs.values[::-1],\n        colorscale = 'Blues',\n        reversescale = True\n    ),\n)\n\nlayout = dict(\n    title='Names distribution',\n    )\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename=\"Names\")","212e4b7d":"df['name_lenght']=df['name'].apply(len)","f63b40ee":"plt.figure(figsize=(10,8))\nax=sns.countplot(df['region'])\nax.set_xlabel(xlabel=\"region\",fontsize=17)\nax.set_ylabel(ylabel='No. of Regions',fontsize=17)\nax.axes.set_title('Regions',fontsize=17)\nax.tick_params(labelsize=13)","5d2270e9":"sns.set(font_scale=1.4)\nplt.figure(figsize = (10,5))\nsns.heatmap(df.corr(),cmap='coolwarm',annot=True,linewidths=.5)","bffc8de8":"from sklearn.model_selection import cross_val_score\nfrom scipy.sparse import hstack\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nall_text=df['name']\ntrain_text=df['name']\ny=df['region']","aba357ea":"word_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    stop_words='english',\n    ngram_range=(1, 1),\n    max_features=10000)\nword_vectorizer.fit(all_text)\ntrain_word_features = word_vectorizer.transform(train_text)","385a2c6e":"char_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='char',\n    stop_words='english',\n    ngram_range=(2, 6),\n    max_features=50000)\nchar_vectorizer.fit(all_text)\ntrain_char_features = char_vectorizer.transform(train_text)\n\ntrain_features = hstack([train_char_features, train_word_features])","c8b0abf2":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train_features, y,test_size=0.3,random_state=101)","957c706a":"import xgboost as xgb","cee998c5":"xgb=xgb.XGBClassifier()","5053e57b":"#xgb.fit(X_train,y_train)","90ee595e":"boardofinnovation.com","cf143fdd":"I read DENTIST. That's what I am, a DDS.","c17aadc8":"Drop the rows having null values"}}