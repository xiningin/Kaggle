{"cell_type":{"0de5a4d3":"code","7a7f79a7":"code","cbb7cd1e":"code","bca88b39":"code","24443534":"code","e6bdc89f":"code","8ebebcc1":"code","0a5b9ac5":"code","ab319cbb":"code","8d7b51d5":"code","5ad2edc3":"code","395ca106":"code","dcaca5de":"code","5c06401e":"code","c59cb25a":"code","1516698b":"code","d606ab8b":"code","e9922f34":"code","197f6e62":"code","ec875f46":"code","cd7e5ddd":"code","b81df8d5":"code","dbaa2ed2":"code","4fb6a1af":"code","b8f6cf3d":"code","e85c9588":"code","3a4e4d23":"code","beb3964d":"code","dda9d3c5":"code","218a766d":"code","48ec6369":"code","02f138ff":"code","59aa906f":"code","b83af2bc":"code","2301c83d":"code","4e067023":"code","4f78ea2c":"code","3a7273df":"code","1520cd3d":"code","ccc5da94":"code","122dd9cb":"code","a597dd34":"code","c70ae80d":"code","e69caafa":"code","1b73edd3":"code","240d634a":"code","a0ffc01c":"markdown","6721716b":"markdown"},"source":{"0de5a4d3":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pandas_profiling import ProfileReport\nimport warnings\nimport catboost as cb\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import ( f1_score, classification_report, \n                             confusion_matrix, roc_auc_score )\nwarnings.simplefilter(action='ignore')\n%matplotlib inline\nsns.set()","7a7f79a7":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","cbb7cd1e":"# !pip install --quiet catboost","bca88b39":"# read in train, test, sample submission data\npath = '\/kaggle\/input\/data-science-nigeria-bank-campaign-subscriptions\/'\ntrain = pd.read_csv(path+'train.csv')\ntest = pd.read_csv(path+'test.csv')\nsub = pd.read_csv(path+'sample_submission.csv')","24443534":"train.info()","e6bdc89f":"test.info()","8ebebcc1":"train.columns","0a5b9ac5":"train.head()","ab319cbb":"train[\"source\"] = 1\ntest[\"source\"] = 0\n\ndata = pd.concat([train, test]).reset_index(drop=True)\nprint(data.shape)\nprint(train.shape)\nprint(test.shape)","8d7b51d5":"data.isna().sum() ","5ad2edc3":"data['subscribed'].unique()","395ca106":"# data.replace('unknown', np.nan, inplace=True)\n# data.isna().sum()","dcaca5de":"# data.profile_report()","5c06401e":"data.drop([\"customer_id\"], axis=1, inplace=True)","c59cb25a":"# checking for unique values in the categorical columns, to examine their entries\ncat_cols = data.columns[data.dtypes == object]\nfor col in cat_cols:\n    print(col.upper(), \"column has\", data[col].nunique(), \"unique values:\\n\", data[col].value_counts())","1516698b":"cat_cols","d606ab8b":"# one hot encode\nfor feat in cat_cols:\n    data = pd.get_dummies(columns=[feat], data = data, dtype=np.int64)\nprint(data.shape)\ndata.head()","e9922f34":"# check for duplicate columns\ndata.columns.duplicated()","197f6e62":"data['nr_employed'].min()","ec875f46":"# add columns using log of most important features  \ndata['log_duration'] = np.log(data['duration'])\ndata['log_euribor3m'] = np.log(data['euribor3m'])\ndata['log_nr_employed'] = np.log(data['nr_employed'])\ndata.shape","cd7e5ddd":"# remove duplicate columns\n# data = data.loc[:,~data.columns.duplicated()] \n# data.shape","b81df8d5":"train_df = data.loc[data[\"source\"] == 1]\ntest_df = data.loc[data[\"source\"] == 0]","dbaa2ed2":"sns.countplot(x='subscribed', data=train_df);","4fb6a1af":"test_df.drop([\"source\", \"subscribed\"], axis=1, inplace=True)\ntrain_df.drop([\"source\"], axis=1, inplace=True)","b8f6cf3d":"print(data.shape)\nprint(train_df.shape)\nprint(test_df.shape)","e85c9588":"y = train_df.subscribed\nX = train_df.drop([\"subscribed\"], axis=1)","3a4e4d23":"y = y.astype('int')\ny.dtype","beb3964d":"print(X.shape)\nprint(y.shape)","dda9d3c5":"# store results for result comparison\nModel = []\nF1score = []\nAUCROC = [] ","218a766d":"def fit_predict(model, X, y, K):\n    ''' Description: Train model specified on dataset using StratifiedKFold \n        Arguements: model - machine learning model to be trained \n                  X - training dataset\n                  y - target column\n                  K - number of splits\n        Returns average confusion matrix, classification report and model name\n    ''' \n    # set initial scores\n    scores = 0\n    auc_scores = 0\n    # set empty list to store predictions on test set \n    test_oofs = []\n    # get model name\n    model_name = type(model).__name__ \n    # set a zero matrix of shape (2,2) for confusion matrix\n    matrix = np.zeros((2,2))\n    # set up empty lists to extend true and predicted values\n    originalclass = []\n    predictedclass = []\n    \n    # initiate StratifiedKFold \n    kfold = StratifiedKFold(n_splits=K, shuffle=True, random_state=1)\n\n    for i, (train_index, test_index) in enumerate(kfold.split(X,y)):\n        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n        \n        # training \n        if model_name in ['VotingClassifier','RandomForestClassifier']:\n            model.fit(X_train, y_train)\n        elif model_name in ['LGBMClassifier','XGBClassifier']:\n            model.fit(X_train, y_train, \n                      early_stopping_rounds = 300, \n                      eval_set=[(X_test, y_test)], \n                      verbose = False)\n        else:\n            model.fit(X_train, y_train,                     \n                      eval_set=[(X_test, y_test)],\n                      early_stopping_rounds=300,\n                      use_best_model=True)       \n        # predicting on test set\n        pred = model.predict(X_test)\n        prob = model.predict_proba(X_test)[:,1]\n        # append y_test and pred list to original class and predicted class\n        # lists respectively\n        originalclass.extend(y_test)\n        predictedclass.extend(pred) \n        # get F1-score and roc_auc_score\n        score = f1_score(y_test, pred, average='macro')\n        roc = roc_auc_score(y_test, prob)\n        # take mean of scores\n        scores += score\/K\n        auc_scores += roc\/K\n        test_oofs.append(pred)\n        # sum confusion matrix of each fold to matrix\n        matrix += confusion_matrix(y_test,pred)\n\n        print('Fold {} F1-score: {}'.format(i+1, score))\n\n    print()\n    print('Avg F1 score: {:.4f} '.format(scores))\n    \n    # make prediction on test set for submission\n    predictions = model.predict(test_df)\n    proba = model.predict_proba(test_df)[:,1]\n    \n    # append results for comaprison\n    Model.append(model_name) # model name\n    F1score.append(scores) # f1-score\n    AUCROC.append(auc_scores) # roc_auc_score\n    return matrix, predictions, proba, model ","48ec6369":"def importance_plot(model, X):\n    \n    ''' Description: Creates feature importance plot for a trained model\n      Arguements: model - trained model on dataset\n                  X - training dataset\n    ''' \n    model_name = type(model).__name__ \n    if model_name in ['LogisticRegression','LinearRegression']:\n        feat_imp = pd.DataFrame(sorted(zip(model.coef_[0],X.columns)), \n                                columns=['Value','Feature']) \n    else:\n        feat_imp = pd.DataFrame(sorted(zip(model.feature_importances_,X.columns)), \n                               columns=['Value','Feature']) \n    plt.figure(figsize=(20,15))\n    imp_data = feat_imp.sort_values(by=\"Value\", ascending=False)\n    sns.barplot(x=\"Value\", y=\"Feature\", data=imp_data)\n    plt.ylabel('Feature Importance Score')\n    plt.title(model_name + ' Feature Importance')\n    plt.show() ","02f138ff":"cb_ = cb.CatBoostClassifier(silent=True)","59aa906f":"cb_matrix, cb_pred, cb_proba, cb_1 = fit_predict(cb_, X, y, 10)","b83af2bc":"# importance plot\nimportance_plot(cb_1, X) ","2301c83d":"# confusion matrix\nlabels = ['no', 'yes']\nplt.figure(figsize=(11,7))\nsns.heatmap(cb_matrix, xticklabels=labels, yticklabels=labels, \n            annot=True, fmt='g')\nplt.xlabel('Predicted label', size=10)\nplt.ylabel('True label', size=10)\nplt.title('Catboost Confusion Matrix', size=15);","4e067023":"!pip install optuna --q","4f78ea2c":"import optuna\n\ndef objective(trial):\n    kf = StratifiedKFold(10)\n    \n    for train_index, valid_index in kf.split(X, y):\n        train_x, valid_x = X.iloc[train_index], X.iloc[valid_index]\n        train_y, valid_y = y.iloc[train_index], y.iloc[valid_index]\n\n    param = {\n        \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 4000, 10000),\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1),\n        \"depth\": trial.suggest_int(\"depth\", 6, 10),\n        \"reg_lambda\": trial.suggest_int(\"reg_lambda\", 200, 500),\n        \"bootstrap_type\": trial.suggest_categorical(\n            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n        ),\n        \"used_ram_limit\": \"3gb\",\n    }\n\n    if param[\"bootstrap_type\"] == \"Bayesian\":\n        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n\n    gbm = cb.CatBoostClassifier(**param)\n\n    gbm.fit(train_x, train_y, eval_set=[(valid_x, valid_y)], verbose=0, early_stopping_rounds=300)\n\n    preds = gbm.predict(valid_x)\n    accuracy = roc_auc_score(valid_y, preds)\n    return accuracy\n\n\nif __name__ == \"__main__\":\n    study = optuna.create_study(direction=\"maximize\")\n    study.optimize(objective, n_trials=100, timeout=600)\n\n    print(\"Number of finished trials: {}\".format(len(study.trials)))\n\n    print(\"Best trial:\")\n    trial = study.best_trial\n\n    print(\"  Value: {}\".format(trial.value))\n\n    print(\"  Params: \")\n    for key, value in trial.params.items():\n        print(\"    {}: {}\".format(key, value))","3a7273df":"catboost = cb.CatBoostClassifier(n_estimators=6778, \n                                 silent=True,\n                                 learning_rate=0.07798088802665777, \n                                 objective='CrossEntropy', \n                                 depth=7,                                   \n                                 bootstrap_type='Bernoulli',\n                                 eval_metric='AUC',\n                                 reg_lambda = 495)                                    ","1520cd3d":"cb_matrix1, cb_pred1, cb_proba1, cb_2 = fit_predict(catboost, X, y, 10) ","ccc5da94":"importance_plot(cb_2, X)","122dd9cb":"# confusion matrix\nlabels = ['no', 'yes']\nplt.figure(figsize=(11,7))\nsns.heatmap(cb_matrix1, xticklabels=labels, yticklabels=labels, \n            annot=True, fmt='g')\nplt.xlabel('Predicted label', size=10)\nplt.ylabel('True label', size=10)\nplt.title('Catboost+Optuna Confusion Matrix', size=15);","a597dd34":"cb_pred1","c70ae80d":"cb_pred1.shape[0] == sub.shape[0]","e69caafa":"sub.head()","1b73edd3":"sub['subscribed'] = cb_pred1\nsub.head()","240d634a":"sub.to_csv(\"sub.csv\", index=False)","a0ffc01c":"### Optuna Catboost","6721716b":"0.92023 private score"}}