{"cell_type":{"678da501":"code","df8cb11e":"code","d79cf3da":"code","1b015cdc":"code","20d1699b":"code","3661be41":"code","b2fbd6ea":"code","b3db92f7":"code","46bf3212":"code","a4836d08":"code","b298c429":"code","c63a26a5":"code","f3bc9a89":"code","d946d78d":"code","36d2af18":"code","0b7807b6":"code","9a0d2960":"code","0abb33bc":"code","289b1ef7":"code","58d8dd37":"code","14e48f44":"code","a984ee7b":"code","c386f343":"code","2086a2ea":"code","2071be24":"code","418a9024":"markdown","c3274255":"markdown","dc938fc3":"markdown"},"source":{"678da501":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.datasets import mnist\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","df8cb11e":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","d79cf3da":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","1b015cdc":"test = np.array(test, dtype=np.float32)\/255\ntest = test.reshape(-1,28,28,1)","20d1699b":"x_digit = train.drop(['label'], axis=1)\ny_digit = train['label']","3661be41":"y_digit = keras.utils.to_categorical(y_digit,num_classes=10)\nx_digit = np.array(x_digit, dtype=np.float32)\/255\nx_digit = x_digit.reshape(-1,28,28,1)","b2fbd6ea":"plt.imshow(x_digit[3], cmap='gray')\nprint(y_digit[3])","b3db92f7":"(x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = mnist.load_data()","46bf3212":"x_mnist = np.concatenate((x_train_mnist,x_test_mnist))\ny_mnist = np.concatenate((y_train_mnist,y_test_mnist))","a4836d08":"x_mnist = x_mnist.reshape(-1,28,28,1)\nx_mnist = x_mnist.astype(np.float32) \/ 255\ny_mnist = keras.utils.to_categorical(y_mnist,num_classes=10)","b298c429":"print(x_digit.shape)\nprint(y_digit.shape)\nprint(x_mnist.shape)\nprint(y_mnist.shape)","c63a26a5":"x_train = np.concatenate((x_digit,x_mnist))\ny_train = np.concatenate((y_digit,y_mnist))\n","f3bc9a89":"print(x_train.shape)\nprint(y_train.shape)","d946d78d":" def creat_model():\n    input_shape = (28,28,1)\n    input_layer = Input(input_shape)\n    layer = Conv2D(32,(5,5),activation = tf.nn.relu, padding='same', input_shape = input_shape)(input_layer)\n    layer = MaxPool2D((2,2))(layer)\n    layer = Conv2D(64,(3,3),activation = tf.nn.relu, padding='same')(layer)\n    layer = Conv2D(64,(3,3),activation = tf.nn.relu, padding='same')(layer)\n    layer = MaxPool2D((2,2))(layer)\n    layer = Conv2D(128,(3,3),activation = tf.nn.relu, padding='same')(layer)\n    layer = Conv2D(128,(3,3),activation = tf.nn.relu, padding='same')(layer)\n    layer = Conv2D(128,(3,3),activation = tf.nn.relu, padding='same')(layer)\n    layer = MaxPool2D((2,2))(layer)\n\n\n\n    flatten = Flatten()(layer)\n\n    layer = Dense(512,activation = tf.nn.relu)(flatten)\n    layer = Dropout(0.25)(layer)\n    layer = Dense(512,activation = tf.nn.relu)(layer)\n    layer  = Dropout(0.25)(layer)\n    layer = Dense(512,activation = tf.nn.relu)(layer)\n    layer  = Dropout(0.25)(layer)\n    output_layer = Dense(10, activation = tf.nn.softmax)(layer)\n    model = Model(input_layer,output_layer)\n    \n    model.compile(optimizer='Adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n    \n    return model","36d2af18":"model = creat_model()\nmodel.summary()","0b7807b6":"#Data Augmentation\ndatagen = ImageDataGenerator(rotation_range=20,\n                  width_shift_range=0.20,\n                  shear_range=15,\n                  zoom_range=0.10,\n                  validation_split=0.25,\n                  horizontal_flip=False)\ndatagen.fit(x_train)\ngenerator_train  = datagen.flow(x_train,y_train,batch_size=256,subset='training')\ngenerator_validation  = datagen.flow(x_train,y_train,batch_size=64,subset='validation')","9a0d2960":"#ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=5 ,min_lr=0.000001,verbose=1)","0abb33bc":"#save best wieghts\nfrom tensorflow.keras.callbacks import ModelCheckpoint\ncheckpoint = ModelCheckpoint(filepath='digit-recognizer-model.hdf5',monitor='val_loss',save_best_only=True,save_weights_only=True,verbose=1)","289b1ef7":"epoch = 60\nmodel_hist = model.fit(generator_train,validation_data=generator_validation,epochs=epoch,callbacks=[reduce_lr,checkpoint],verbose=1)","58d8dd37":"del model","14e48f44":"#load best weights\nmodel = creat_model()\nmodel.load_weights('digit-recognizer-model.hdf5')","a984ee7b":"x = np.arange(1, epoch + 1)\ntrain_acc = model_hist.history['accuracy']\ntrain_loss = model_hist.history['loss']\nval_acc = model_hist.history['val_accuracy']\nval_loss = model_hist.history['val_loss']","c386f343":"plt.plot(x , train_acc, x, val_acc)\nplt.show()\nplt.plot(x , train_loss, x, val_loss)\nplt.show()","2086a2ea":"prediction = model.predict(test)","2071be24":"predict = np.array(np.round(prediction), dtype = np.int32)\npredict = np.argmax(predict , axis=1).reshape(-1, 1)\nout = [{'ImageId': i+1, 'Label': predict[i][0]} for i in range(len(predict))]\npd.DataFrame(out).to_csv('submission.csv', index=False)","418a9024":"## creat model","c3274255":"## MNIST","dc938fc3":"## Digit + MNIST"}}