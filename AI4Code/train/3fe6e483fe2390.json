{"cell_type":{"c33b535f":"code","00dabb60":"code","53656054":"code","c483ad64":"code","93a4e0c9":"code","1b6b8f99":"code","f2a4ddb2":"code","400ac287":"code","4b42c796":"code","965e8135":"code","2bad13ab":"code","6970d344":"code","15878638":"code","e07b0649":"code","f3de1d98":"code","b72c4a3c":"code","168384ed":"code","53121ffa":"code","155709fa":"code","180bb212":"code","413d41bb":"code","83cba791":"code","bd772d18":"code","7d9f0739":"code","4d5e04bd":"code","ebae6dfa":"code","77cf9ca9":"code","1796284b":"code","c3d937fa":"code","aaac1f59":"code","6e680b31":"code","608600e3":"code","469c7576":"code","a90944ca":"code","263523f2":"code","79669514":"code","6a5a9db5":"code","36460227":"code","77646e0d":"code","635cd7fe":"code","d0a17a86":"code","e01d2935":"code","1b6d1726":"code","b38dcc14":"code","eb25eed7":"code","89737410":"code","5c21986b":"code","eb59f555":"code","e79e20fe":"code","bb9cbe9d":"code","11829c0d":"code","ebe87b21":"code","053270f3":"code","6ab3181a":"code","68cfe20e":"code","d8e04659":"code","7e59d2f3":"code","4d3d6e36":"code","dd918f30":"code","40bdb500":"code","6bc79e64":"code","015301c1":"code","e9b04d3e":"markdown","23c8ae2f":"markdown","2b7adf86":"markdown","3fd6b982":"markdown","d3e530e9":"markdown","d193d7a3":"markdown","8989c882":"markdown","8d5582bd":"markdown","43775ad7":"markdown","fdaaf274":"markdown"},"source":{"c33b535f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","00dabb60":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas_profiling as pf \nimport pandas as pd\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","53656054":"df = pd.read_csv('..\/input\/automobile-dataset\/Automobile_data.csv')","c483ad64":"df.head()","93a4e0c9":"df.info()","1b6b8f99":"# replace ? with NaN\ndf = df.replace('?',np.nan)","f2a4ddb2":"df = df.astype({'symboling' : 'object','normalized-losses':'float64','bore':'float64','stroke':'float64','horsepower':'float64','peak-rpm':'float64','price':'float64'})","400ac287":"df.isnull().sum()","4b42c796":"#back up\ndf2 = df ","965e8135":"#Check num-of-doors \n\ndf2.groupby('num-of-doors',dropna=False).count()","2bad13ab":"#replace NaN values with the most frequency value which is four\ndf2['num-of-doors'] = df2['num-of-doors'].fillna('four')","6970d344":"# Check again\ndf2.groupby('num-of-doors',dropna=False).count()","15878638":"df2.dropna(subset = [\"price\"], inplace=True)","e07b0649":"df2[pd.isnull(df2).any(axis=1)]","f3de1d98":"df3 = df2\nnum_col = ['normalized-losses','bore',  'stroke', 'horsepower', 'peak-rpm']\nfor col in num_col:\n    df3[col] = pd.to_numeric(df[col])\n    df3[col].fillna(df3[col].mean(), inplace=True)\ndf3.head(10)","b72c4a3c":"df3[pd.isnull(df3).any(axis=1)]","168384ed":"#reset index\ndf3 = df3.reset_index()\ndf3 = df3.drop(columns= 'index')","53121ffa":"pf.ProfileReport(df3)","155709fa":"df3.info()","180bb212":"#Excluding the outlier data for horsepower\ndf3[np.abs(df3.horsepower-df3.horsepower.mean()) > (3*df3.horsepower.std())]","413d41bb":"plt.figure(figsize=(6, 6))\nsns.boxplot(data = df3, x= 'horsepower' )","83cba791":"plt.figure(figsize=(6, 6))\nsns.boxplot(data = df3, x= 'normalized-losses' )","bd772d18":"df3[np.abs(df3['normalized-losses']-df3['normalized-losses'].mean()) > (3*df3['normalized-losses'].std())]","7d9f0739":"update_df = df3.drop([df3.index[103], df3.index[186]])\nupdate_df","4d5e04bd":"update_df[np.abs(update_df['normalized-losses']-update_df['normalized-losses'].mean()) > (3*update_df['normalized-losses'].std())]","ebae6dfa":"plt.figure(figsize=(6, 6))\nsns.boxplot(data = update_df, x= 'normalized-losses' )","77cf9ca9":"update_df.info()","1796284b":"update_df.hist('price')","c3d937fa":"plt.figure(figsize=(6, 6))\nsns.boxplot(data = update_df, x= 'fuel-type', y= 'price' )","aaac1f59":"corr = update_df.corr()\nsns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 2.5})\nplt.figure(figsize=(13,7))\na = sns.heatmap(corr, annot=True, fmt='.2f')\nrotx = a.set_xticklabels(a.get_xticklabels(), rotation=90)\nroty = a.set_yticklabels(a.get_yticklabels(), rotation=30)","6e680b31":"df3.describe(include=['object'])","608600e3":"## want to check corr between variables with other cols\nfrom scipy import stats\n## therefore I make a function To find corelation between two of them easily \nlst_continous = []\ndef cor_with_Price(col,output=True):\n    corr , p_value = stats.pearsonr(update_df[col],update_df['price'])\n    if p_value < 0.05 and corr > 0.3:\n        if output==True:\n            print(f'cor between {col} <--> price  :{corr}, & p_value ---> {p_value}')\n            lst_continous.append(col)\n    return corr,p_value,lst_continous","469c7576":"update_df.columns","a90944ca":"df_continuous = update_df.select_dtypes(exclude=['object'])\ndf_continuous","263523f2":"df_continuous.columns","79669514":"col1 = ['normalized-losses', 'wheel-base', 'length', 'width',\n       'height', 'curb-weight', 'engine-size', 'bore', 'stroke',\n       'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg',\n       'highway-mpg']\nfor col in col1:\n    cor_with_Price(col)","6a5a9db5":"lst_continous","36460227":"continuous_variables = df_continuous[lst_continous]\ncontinuous_variables","77646e0d":"update_df2 = update_df.astype({'symboling' : 'object'})","635cd7fe":"update_df2.info()","d0a17a86":"df_dummy = update_df2.select_dtypes(include=['object'])\ndf_dummy","e01d2935":"df_dummy.columns","1b6d1726":"X = df3[['symboling', 'make', 'fuel-type', 'aspiration', 'num-of-doors',\n       'body-style', 'drive-wheels', 'engine-location', 'engine-type',\n       'num-of-cylinders', 'fuel-system']]","b38dcc14":"lst_dummy = []\ndef anova_with_Price(col,output=True):\n    fvalue, pvalue = stats.pearsonr(X[col],df_continuous['price'])\n    if pvalue < 0.05:\n        if output==True:\n            print(f'cor between {col} <--> price  :{fvalue}, & p_value ---> {pvalue}')\n            lst_dummy.append(col)\n        \n    return fvalue,pvalue,lst_dummy","eb25eed7":"X = pd.get_dummies(data=df_dummy, drop_first=True)","89737410":"X.columns","5c21986b":"col2 = ['symboling_-1', 'symboling_0', 'symboling_1', 'symboling_2',\n       'symboling_3', 'make_audi', 'make_bmw', 'make_chevrolet', 'make_dodge',\n       'make_honda', 'make_isuzu', 'make_jaguar', 'make_mazda',\n       'make_mercedes-benz', 'make_mercury', 'make_mitsubishi', 'make_nissan',\n       'make_peugot', 'make_plymouth', 'make_porsche', 'make_renault',\n       'make_saab', 'make_subaru', 'make_toyota', 'make_volkswagen',\n       'make_volvo', 'fuel-type_gas', 'aspiration_turbo', 'num-of-doors_two',\n       'body-style_hardtop', 'body-style_hatchback', 'body-style_sedan',\n       'body-style_wagon', 'drive-wheels_fwd', 'drive-wheels_rwd',\n       'engine-location_rear', 'engine-type_l', 'engine-type_ohc',\n       'engine-type_ohcf', 'engine-type_ohcv', 'engine-type_rotor',\n       'num-of-cylinders_five', 'num-of-cylinders_four',\n       'num-of-cylinders_six', 'num-of-cylinders_three',\n       'num-of-cylinders_twelve', 'num-of-cylinders_two', 'fuel-system_2bbl',\n       'fuel-system_4bbl', 'fuel-system_idi', 'fuel-system_mfi',\n       'fuel-system_mpfi', 'fuel-system_spdi', 'fuel-system_spfi']","eb59f555":"for col in col2:\n    anova_with_Price(col)\nprint(lst_dummy)","e79e20fe":"dummy_variables = X[['symboling_-1', 'symboling_1', 'symboling_2', 'symboling_3', 'make_bmw', 'make_dodge', 'make_honda', 'make_jaguar', 'make_mercedes-benz', 'make_porsche', 'make_subaru', 'make_toyota', 'make_volvo', 'aspiration_turbo', 'body-style_hardtop', 'body-style_hatchback', 'body-style_sedan', 'drive-wheels_fwd', 'drive-wheels_rwd', 'engine-location_rear', 'engine-type_ohc', 'engine-type_ohcv', 'num-of-cylinders_five', 'num-of-cylinders_four', 'num-of-cylinders_six', 'num-of-cylinders_twelve', 'fuel-system_2bbl', 'fuel-system_mpfi']]","bb9cbe9d":"dummy_variables = X[lst_dummy]\ndummy_variables","11829c0d":"data = pd.concat([continuous_variables, dummy_variables], axis=1)\ndata.head()","ebe87b21":"data.columns","053270f3":"# create X and y\nfeature_cols = ['wheel-base', 'length', 'width', 'curb-weight', 'engine-size', 'bore',\n       'horsepower', 'symboling_-1', 'symboling_1', 'symboling_2',\n       'symboling_3', 'make_bmw', 'make_dodge', 'make_honda', 'make_jaguar',\n       'make_mercedes-benz', 'make_porsche', 'make_subaru', 'make_toyota',\n       'make_volvo', 'aspiration_turbo', 'body-style_hardtop',\n       'body-style_hatchback', 'body-style_sedan', 'drive-wheels_fwd',\n       'drive-wheels_rwd', 'engine-location_rear', 'engine-type_ohc',\n       'engine-type_ohcv', 'num-of-cylinders_five', 'num-of-cylinders_four',\n       'num-of-cylinders_six', 'num-of-cylinders_twelve', 'fuel-system_2bbl',\n       'fuel-system_mpfi']\n\n\ny = df_continuous.price","6ab3181a":"x = data\nx.info()","68cfe20e":"from sklearn import linear_model\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = .20, random_state = 40)\n\nmodel = linear_model.LinearRegression() # Do not use fit_intercept = False if you have removed 1 column after dummy encoding\nmodel.fit(X_train, Y_train)\nyhat_test = model.predict(X_test)","d8e04659":"yhat_train = model.predict(X_train)\nyhat_test = model.predict(X_test)","7e59d2f3":"a = model.intercept_\na","4d3d6e36":"b = model.coef_\nb","dd918f30":"# Visualize result\nplt.figure(figsize=(5,5))\nplt.scatter(yhat_test, Y_test)\nplt.xlabel('Predicted value')\nplt.ylabel('True value')\nplt.plot([0, 50000], [0, 50000], 'k-', color='r')\nplt.show()","40bdb500":"plt.figure(figsize=(14,6))\nplt.subplot(1,2,1)\nax1 = sns.distplot(Y_train, hist=False, color='r', label='Actual Train Value')\nsns.distplot(yhat_train, hist=False, color='b', label='Predicted Train Value', ax=ax1)\nplt.subplot(1,2,2)\nax2 = sns.distplot(Y_test, hist=False, color='r', label='Actual Test Value')\nsns.distplot(yhat_test, hist=False, color='b', label='Predicted Test Value', ax=ax2)\nplt.legend()\nplt.show()","6bc79e64":"# R^2\nprint('Full Dataset R-square:', model.score(x, y))\nprint('Train Dataset R-square:', model.score(X_train, Y_train))\nprint('Test Dataset R-square:', model.score(X_test, Y_test))","015301c1":"# MSE, MAE\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nprint('Train Dataset MSE:', mean_squared_error(Y_train, yhat_train))\nprint('Test Dataset MSE:', mean_squared_error(Y_test, yhat_test))\nprint('Train Dataset MAE:', mean_absolute_error(Y_train, yhat_train))\nprint('Test Dataset MAE:', mean_absolute_error(Y_test, yhat_test))","e9b04d3e":"## Handle dummy variables","23c8ae2f":"## Clean NaN values in 'price' by .dropna()\"","2b7adf86":"## 3.1 Linear Regression","3fd6b982":"# 3. Training models","d3e530e9":"## Clean num-of-doors \n","d193d7a3":"# 2. EDA","8989c882":"## Clean 'normalized losses', 'bore',  'stroke', 'horsepower', 'peak-rpm'","8d5582bd":"## ANOVA TESTING ","43775ad7":"### from the above report it seems that horsepower has outlier","fdaaf274":"# 1. Clean data"}}