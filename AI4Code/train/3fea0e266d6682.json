{"cell_type":{"7721ea6f":"code","4c29b602":"code","9032ac21":"code","c59c4f50":"code","d11f5d4c":"code","e4bc6c2f":"code","a8d78f12":"code","fea2a53f":"code","60a05ff8":"code","3cbe4b64":"code","80d391ad":"code","6676fed9":"code","84539d06":"markdown","95a78f0d":"markdown","2e3eb056":"markdown","1a83a14d":"markdown","3fa02fbc":"markdown","5c25d09d":"markdown","d97b357a":"markdown","abb9f5dd":"markdown","84c59d95":"markdown"},"source":{"7721ea6f":"!pip install --quiet \/kaggle\/input\/kerasapplications\n!pip install --quiet \/kaggle\/input\/efficientnet-git","4c29b602":"import math, os, re, warnings, random, glob\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import Sequential, Model\nimport efficientnet.tfkeras as efn\n\ndef seed_everything(seed=0):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\nseed = 0\nseed_everything(seed)\nwarnings.filterwarnings('ignore')","9032ac21":"# TPU or GPU detection\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print(f'Running on TPU {tpu.master()}')\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nAUTO = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","c59c4f50":"BATCH_SIZE = 16 * REPLICAS\nHEIGHT = 512\nWIDTH = 512 \nCHANNELS = 3\nN_CLASSES = 5\nTTA_STEPS = 5 # Do TTA if > 0 ","d11f5d4c":"def data_augment(image, label):\n    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n            \n    # Flips\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if p_spatial > .75:\n        image = tf.image.transpose(image)\n        \n    # Rotates\n    if p_rotate > .75:\n        image = tf.image.rot90(image, k=3) # rotate 270\u00ba\n    elif p_rotate > .5:\n        image = tf.image.rot90(image, k=2) # rotate 180\u00ba\n    elif p_rotate > .25:\n        image = tf.image.rot90(image, k=1) # rotate 90\u00ba\n        \n    # Pixel-level transforms\n    if p_pixel_1 >= .4:\n        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n    if p_pixel_2 >= .4:\n        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n    if p_pixel_3 >= .4:\n        image = tf.image.random_brightness(image, max_delta=.1)\n            \n\n    return image, label","e4bc6c2f":"# Datasets utility functions\ndef get_name(file_path):\n    parts = tf.strings.split(file_path, os.path.sep)\n    name = parts[-1]\n    return name\n\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    \n#     image = center_crop(image)\n    return image\n\ndef center_crop(image):\n    image = tf.reshape(image, [600, 800, CHANNELS]) # Original shape\n    \n    h, w = image.shape[0], image.shape[1]\n    if h > w:\n        image = tf.image.crop_to_bounding_box(image, (h - w) \/\/ 2, 0, w, w)\n    else:\n        image = tf.image.crop_to_bounding_box(image, 0, (w - h) \/\/ 2, h, h)\n        \n    image = tf.image.resize(image, [HEIGHT, WIDTH]) # Expected shape\n    return image\n\ndef resize_image(image, label):\n    image = tf.image.resize(image, [HEIGHT, WIDTH])\n    image = tf.reshape(image, [HEIGHT, WIDTH, CHANNELS])\n    return image, label\n\ndef process_path(file_path):\n    name = get_name(file_path)\n    img = tf.io.read_file(file_path)\n    img = decode_image(img)\n    return img, name\n\ndef get_dataset(files_path, shuffled=False, tta=False, extension='jpg'):\n    dataset = tf.data.Dataset.list_files(f'{files_path}*{extension}', shuffle=shuffled)\n    dataset = dataset.map(process_path, num_parallel_calls=AUTO)\n    if tta:\n        dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.map(resize_image, num_parallel_calls=AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)","a8d78f12":"database_base_path = '\/kaggle\/input\/cassava-leaf-disease-classification\/'\nsubmission = pd.read_csv(f'{database_base_path}sample_submission.csv')\ndisplay(submission.head())\n\nTEST_FILENAMES = tf.io.gfile.glob(f'{database_base_path}test_tfrecords\/ld_test*.tfrec')\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\nprint(f'GCS: test: {NUM_TEST_IMAGES}')","fea2a53f":"model_path_list = glob.glob('\/kaggle\/input\/cassava-leaf-disease-tpu-tensorflow-training\/*.h5')\nmodel_path_list.sort()\n\nprint('Models to predict:')\nprint(*model_path_list, sep='\\n')","60a05ff8":"model_path_list_2 = glob.glob('\/kaggle\/input\/cassava-leaf-disease-training-with-tpu-v2-pods\/*.h5')\nmodel_path_list_2.sort()\n\nprint('Models to predict:')\nprint(*model_path_list_2, sep='\\n')","3cbe4b64":"def model_fn(input_shape, N_CLASSES):\n    inputs = L.Input(shape=input_shape, name='inputs')\n    base_model = efn.EfficientNetB3(input_tensor=inputs, \n                                    include_top=False, \n                                    weights=None, \n                                    pooling='avg')\n\n    model = tf.keras.Sequential([\n        base_model,\n        L.Dropout(.25),\n        L.Dense(N_CLASSES, activation='softmax', name='output')\n    ])\n    \n    return model\n\ndef model_fn_2(input_shape, N_CLASSES):\n    inputs = L.Input(shape=input_shape, name='inputs')\n    base_model = efn.EfficientNetB4(input_tensor=inputs, \n                                    include_top=False, \n                                    weights=None, \n                                    pooling='avg')\n    \n    \n\n\n    x = L.Dropout(.5)(base_model.output)\n    output = L.Dense(N_CLASSES, activation='softmax', name='output')(x)\n    model = Model(inputs=inputs, outputs=output)\n\n    return model\n\n\nwith strategy.scope():\n    model = model_fn((None, None, CHANNELS), N_CLASSES)\n    model_2 = model_fn_2((None, None, CHANNELS), N_CLASSES)\n    \nmodel.summary()\n# model_2.summary()","80d391ad":"files_path = f'{database_base_path}test_images\/'\ntest_preds = np.zeros((len(os.listdir(files_path)), N_CLASSES))\n\n\nprint('First model')\nfor model_path in model_path_list:\n    print(model_path)\n    K.clear_session()\n    model.load_weights(model_path)\n\n    if TTA_STEPS > 0:\n        test_ds = get_dataset(files_path, tta=True)\n        for step in range(TTA_STEPS):\n            print(f'TTA step {step+1}\/{TTA_STEPS}')\n            x_test = test_ds.map(lambda image, image_name: image)\n            test_preds += model.predict(x_test) \/ (TTA_STEPS * len(model_path_list))\n    else:\n        test_ds = get_dataset(files_path, tta=False)\n        x_test = test_ds.map(lambda image, image_name: image)\n        test_preds += model.predict(x_test) \/ len(model_path_list)\n\n\nprint('\\nSecond model')\nfor model_path in model_path_list_2:\n    print(model_path)\n    K.clear_session()\n    model_2.load_weights(model_path)\n\n    if TTA_STEPS > 0:\n        test_ds = get_dataset(files_path, tta=True)\n        for step in range(TTA_STEPS):\n            print(f'TTA step {step+1}\/{TTA_STEPS}')\n            x_test = test_ds.map(lambda image, image_name: image)\n            test_preds += model_2.predict(x_test) \/ (TTA_STEPS * len(model_path_list))\n    else:\n        test_ds = get_dataset(files_path, tta=False)\n        x_test = test_ds.map(lambda image, image_name: image)\n        test_preds += model_2.predict(x_test) \/ len(model_path_list)\n    \ntest_preds = np.argmax(test_preds, axis=-1)\nimage_names = [img_name.numpy().decode('utf-8') for img, img_name in iter(test_ds.unbatch())]","6676fed9":"submission = pd.DataFrame({'image_id': image_names, 'label': test_preds})\nsubmission.to_csv('submission.csv', index=False)\ndisplay(submission.head())","84539d06":"# Test set predictions","95a78f0d":"## Auxiliary functions","2e3eb056":"# Load data","1a83a14d":"# Model","3fa02fbc":"# Augmentation","5c25d09d":"<center><img src=\"https:\/\/raw.githubusercontent.com\/dimitreOliveira\/MachineLearning\/master\/Kaggle\/Cassava%20Leaf%20Disease%20Classification\/banner.png\" width=\"1000\"><\/center>\n<br>\n<center><h1>Cassava Leaf Disease - TPU Tensorflow - Inference<\/h1><\/center>\n<br>\n\n- This is the inference part of the work, the training notebook can be found here [Cassava Leaf Disease - TPU Tensorflow - Training](https:\/\/www.kaggle.com\/dimitreoliveira\/cassava-leaf-disease-tpu-tensorflow-training)\n- keras-applications GitHub repository can be found [here](https:\/\/www.kaggle.com\/dimitreoliveira\/kerasapplications)\n- efficientnet GitHub repository can be found [here](https:\/\/www.kaggle.com\/dimitreoliveira\/efficientnet-git)\n- Dataset source `resized` [128x128](https:\/\/www.kaggle.com\/dimitreoliveira\/cassava-leaf-disease-tfrecords-128x128), [256x256](https:\/\/www.kaggle.com\/dimitreoliveira\/cassava-leaf-disease-tfrecords-256x256), [384x384](https:\/\/www.kaggle.com\/dimitreoliveira\/cassava-leaf-disease-tfrecords-384x384), [512x512](https:\/\/www.kaggle.com\/dimitreoliveira\/cassava-leaf-disease-tfrecords-512x512)\n- Dataset source `center cropped` [128x128](https:\/\/www.kaggle.com\/dimitreoliveira\/cassava-leaf-disease-tfrecords-center-128x128), [256x256](https:\/\/www.kaggle.com\/dimitreoliveira\/cassava-leaf-disease-tfrecords-center-256x256), [384x384](https:\/\/www.kaggle.com\/dimitreoliveira\/cassava-leaf-disease-tfrecords-center-384x384), [512x512](https:\/\/www.kaggle.com\/dimitreoliveira\/cassava-leaf-disease-tfrecords-center-512x512)\n- Dataset source [discussion thread](https:\/\/www.kaggle.com\/c\/cassava-leaf-disease-classification\/discussion\/198744)\n- Dataset [creation source](https:\/\/www.kaggle.com\/dimitreoliveira\/cassava-leaf-disease-stratified-tfrecords-256x256)","d97b357a":"# Model parameters","abb9f5dd":"## Dependencies","84c59d95":"### Hardware configuration"}}