{"cell_type":{"34641cd4":"code","dcebd410":"code","74fd4259":"code","80d28573":"code","0b400a19":"code","ba64c5d2":"code","09dee387":"code","d6b777e1":"code","5a3f704e":"code","9e8d5d5e":"code","695da912":"code","d9f74a58":"code","9ed32212":"code","d11c7d04":"code","77b9aa6b":"code","6673f6ce":"code","80c055e8":"code","30ce0baf":"code","8f587064":"code","1dd4bcb0":"code","3d9add1f":"code","12ea6bef":"code","1bfce79a":"code","823d6ed5":"code","ad87b723":"code","632fd1ab":"code","e6b026d3":"code","c4551a73":"markdown","af5bc2e6":"markdown","72d0efe4":"markdown","3f5a72bf":"markdown","e9848387":"markdown","78cfe9ff":"markdown","4fc31bb5":"markdown","621c47e2":"markdown","39a8e39c":"markdown","c357cc0e":"markdown","0693ca01":"markdown","a14952a1":"markdown","0c452478":"markdown","88d528b2":"markdown","5dcacafe":"markdown","b39b0aa7":"markdown","f766eee4":"markdown","596842af":"markdown","8f4405d0":"markdown","ce84ed1d":"markdown","df2b06d7":"markdown","1ee52ffa":"markdown","6cd4badb":"markdown","ab19bd2b":"markdown","4f765b10":"markdown","251b91ea":"markdown","eef0d1ec":"markdown"},"source":{"34641cd4":"from IPython.display import display\nimport gc\nimport joblib as jb\nfrom tqdm.auto import tqdm, trange\nimport os\n\n# data manipulation\nimport numpy as np\nimport pandas as pd\nimport sqlite3 as sq\nfrom sklearn import preprocessing, pipeline\n\n# data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# unsupervised learning\nfrom sklearn import decomposition, cluster","dcebd410":"con = sq.connect(\"..\/input\/california-traffic-collision-data-from-switrs\/switrs.sqlite\")\ncur = con.cursor()","74fd4259":"tables = [name[0] for name in cur.execute(\"SELECT name FROM sqlite_master\")]\nprint(\"Tables:\")\nprint(tables)","80d28573":"tables = [\"collisions\", \"parties\"]\nprint(\"Used tables: \")\nprint(tables)","0b400a19":"cols = {table: list(map(lambda x: x[0], cur.execute(\"SELECT * FROM {}\".format(table)).description)) for table in tables}\nprint(\"Tables' features:\")\nprint()\nfor key,val in cols.items():\n    print(\"=\"*5 + \" \" + key + \" \" + \"=\"*5)\n    display(val)\n    print()","ba64c5d2":"# all features are copied in this dictionary; commented ones are removed because they are only descriptive for the target of this work\n\ncols = {\n    \"collisions\":\n    [\n        \"case_id\",\n        #\"jurisdiction\",\n        #\"officer_id\",\n        #\"reporting_district\",\n        #\"chp_shift\",\n        #\"population\",\n        \"county_city_location\",\n        \"county_location\",\n        \"special_condition\",\n        \"beat_type\",\n        \"chp_beat_type\",\n        \"city_division_lapd\",\n        \"chp_beat_class\",\n        \"beat_number\",\n        \"primary_road\",\n        \"secondary_road\",\n        \"distance\",\n        \"direction\",\n        \"intersection\",\n        \"weather_1\",\n        \"weather_2\",\n        \"state_highway_indicator\",\n        \"caltrans_county\",\n        \"caltrans_district\",\n        \"state_route\",\n        \"route_suffix\",\n        \"postmile_prefix\",\n        \"postmile\",\n        \"location_type\",\n        \"ramp_intersection\",\n        \"side_of_highway\",\n        \"tow_away\",\n        \"collision_severity\",\n        \"killed_victims\",\n        \"injured_victims\",\n        \"party_count\",\n        \"primary_collision_factor\",\n        \"pcf_violation_code\",\n        \"pcf_violation_category\",\n        \"pcf_violation\",\n        \"pcf_violation_subsection\",\n        \"hit_and_run\",\n        \"type_of_collision\",\n        \"motor_vehicle_involved_with\",\n        \"pedestrian_action\",\n        \"road_surface\",\n        \"road_condition_1\",\n        \"road_condition_2\",\n        \"lighting\",\n        \"control_device\",\n        \"chp_road_type\",\n        \"pedestrian_collision\",\n        \"bicycle_collision\",\n        \"motorcycle_collision\",\n        \"truck_collision\",\n        \"not_private_property\",\n        \"alcohol_involved\",\n        \"statewide_vehicle_type_at_fault\",\n        \"chp_vehicle_type_at_fault\",\n        \"severe_injury_count\",\n        \"other_visible_injury_count\",\n        \"complaint_of_pain_injury_count\",\n        \"pedestrian_killed_count\",\n        \"pedestrian_injured_count\",\n        \"bicyclist_killed_count\",\n        \"bicyclist_injured_count\",\n        \"motorcyclist_killed_count\",\n        \"motorcyclist_injured_count\",\n        \"primary_ramp\",\n        \"secondary_ramp\",\n        \"latitude\",\n        \"longitude\",\n        \"collision_date\",\n        \"collision_time\",\n        #\"process_date\"\n    ],\n    \n    \"parties\":\n    [\n        #\"id\",\n        \"case_id\",\n        \"party_number\",\n        \"party_type\",\n        \"at_fault\",\n        \"party_sex\",\n        \"party_age\",\n        \"party_sobriety\",\n        \"party_drug_physical\",\n        \"direction_of_travel\",\n        \"party_safety_equipment_1\",\n        \"party_safety_equipment_2\",\n        \"financial_responsibility\",\n        \"hazardous_materials\",\n        \"cellphone_in_use\",\n        \"cellphone_use_type\",\n        \"school_bus_related\",\n        \"oaf_violation_code\",\n        \"oaf_violation_category\",\n        \"oaf_violation_section\",\n        \"oaf_violation_suffix\",\n        \"other_associate_factor_1\",\n        \"other_associate_factor_2\",\n        \"party_number_killed\",\n        \"party_number_injured\",\n        \"movement_preceding_collision\",\n        \"vehicle_year\",\n        \"vehicle_make\",\n        #\"statewide_vehicle_type\",\n        #\"chp_vehicle_type_towing\",\n        #\"chp_vehicle_type_towed\",\n        \"party_race\"\n    ]\n}\n\nprint(\"Used features: \")\nprint()\nfor key,val in cols.items():\n    print(\"=\"*5 + \" \" + key + \" \" + \"=\"*5)\n    display(val)\n    print()","09dee387":"def get_str_list(L):\n    S = \"\"\n    for x in L:\n        S += x + \", \"\n    S = S[:-2]\n    return S\n\ndf = {}\n\n# get collisions with a mototrcycle involved\ncmd = \"SELECT \" + get_str_list(cols[\"collisions\"]) + \" FROM collisions WHERE motorcycle_collision=1\"\ndf[\"collisions\"] = pd.DataFrame([list(x) for x in cur.execute(cmd)], columns=cols[\"collisions\"])\n\ndisplay(df[\"collisions\"].head())\nprint(\"\\nEntries: {}\".format(df[\"collisions\"].shape[0]))\nprint(\"Features: {}\".format(df[\"collisions\"].shape[1]))","d6b777e1":"df[\"collisions\"].loc[:, [\"collision_date\", \"collision_time\"]].isnull().sum()","5a3f704e":"def get_seconds(hour, minute, second):\n    return hour*3600 + minute*60 + second\n\ndef get_hms(seconds):\n    hour = seconds \/\/ 3600\n    seconds -= hour * 3600\n    minute = seconds \/\/ 60\n    seconds -= minute * 60\n    second = round(seconds)\n    return int(hour), int(minute), int(second)\n\ndef get_date_cols(col_date, col_time=None):\n    \n    year = col_date.apply(lambda x: pd.Timestamp(x).year)\n    month = col_date.apply(lambda x: pd.Timestamp(x).month)\n    day = col_date.apply(lambda x: pd.Timestamp(x).day)\n    \n    df = pd.DataFrame({\"year\": year.values, \"month\": month.values, \"day\": day.values}, index=col_date.index)\n    \n    if type(col_time) == pd.Series:\n        \n        # fill missing times with median\n        time_median = col_time.apply(lambda x: get_seconds(*np.array(x.split(\":\")).astype(int)) if type(x)==str else np.nan).dropna().median()\n        col_time = col_time.fillna(value=\"{:02d}:{:02d}:{:02d}\".format(*get_hms(time_median)))\n\n        hour = col_time.apply(lambda x: x.split(\":\")[0]).astype(int)\n        minute = col_time.apply(lambda x: x.split(\":\")[1]).astype(int)\n        second = col_time.apply(lambda x: x.split(\":\")[2]).astype(int)\n        \n        # pack time fields with date's\n        df = df.join(pd.DataFrame({\"hour\": hour, \"minute\": minute, \"second\": second}, index=col_time.index))\n    \n    return df\n\ndf[\"collisions\"] = df[\"collisions\"].join(get_date_cols(df[\"collisions\"].collision_date, df[\"collisions\"].collision_time).rename(columns={var: \"collision_date_\"+var for var in [\"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\"]}))\ndf[\"collisions\"] = df[\"collisions\"].drop(columns=[\"collision_date\", \"collision_time\"])\n\ndf[\"collisions\"].loc[:, [\"collision_date_\" + var for var in [\"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\"]]].describe()","9e8d5d5e":"def preprocess_missing(df, figsize=(30,5), none_is_na = True):\n    \n    ''' Fill missing values: with \"None\" for labels, with 0 for numeric features '''\n    \n    df = df.copy()\n    \n    if none_is_na:\n        df = df.replace(\"None\", np.nan)\n    \n    null_counts = (df.isnull().sum() \/ df.shape[0] * 100).loc[lambda x: x!=0]\n    \n    fig,ax = plt.subplots(figsize=figsize)\n    ax = sns.barplot(x=null_counts.index, y=null_counts.values, color=\"C0\", ax=ax)\n    ax.tick_params(axis=\"x\", rotation=45)\n    ax.set_title(\"Missing values\")\n    ax.set_xlabel(\"feature\")\n    ax.set_ylabel(\"percentage (%)\")\n    plt.show()\n    \n    drop_cols = null_counts.loc[lambda x: x==100].index.tolist()\n    df = df.drop(columns=drop_cols)\n    if len(drop_cols) != 0:\n        print(\"Completely null features:\")\n        for col in drop_cols:\n            print(\"\\t\"+col)\n    \n    null_obj = df.dtypes.loc[null_counts.index].loc[lambda x: x==object]\n    null_numeric = df.dtypes.loc[null_counts.index].loc[lambda x: x!=object]\n    \n    df.loc[:,null_obj.index] = df.loc[:,null_obj.index].fillna(value=\"None\")\n    \n    display(df.loc[:,null_numeric.index].describe())\n    \n    # all numeric features with missing values can be filled with 0 in all tables, because of this the following line of code is commented\n    #fill_numeric = input(\"Fill missing numeric values with 0? (Y\/n): \")\n    fill_numeric = \"y\"\n    \n    if fill_numeric in [\"Y\", \"y\", \"\"]:\n        df.loc[:, null_numeric.index] = df.loc[:, null_numeric.index].fillna(value=0)\n        \n    return df\n\ndf[\"collisions\"] = preprocess_missing(df[\"collisions\"])","695da912":"# get collisions' parties on a motorcycle (or scooter)\ncmd = \"SELECT \" + get_str_list(cols[\"parties\"]) + \" FROM parties \"\ncmd += \"WHERE case_id IN (\" + get_str_list(df[\"collisions\"].case_id) + \") AND statewide_vehicle_type = 'motorcycle or scooter'\"\ndf[\"parties\"] = pd.DataFrame([list(x) for x in cur.execute(cmd)], columns=cols[\"parties\"])\n\ndisplay(df[\"parties\"].head())\nprint(\"\\nEntries: {}\".format(df[\"parties\"].shape[0]))\nprint(\"Features: {}\".format(df[\"parties\"].shape[1]))","d9f74a58":"df[\"parties\"] = preprocess_missing(df[\"parties\"])","9ed32212":"print(\"Motorcycles without make: {}\".format((df[\"parties\"].vehicle_make == \"None\").sum()))","d11c7d04":"df[\"parties\"] = df[\"parties\"].loc[df[\"parties\"].vehicle_make != \"None\"]","77b9aa6b":"df = df[\"parties\"].merge(df[\"collisions\"], on=\"case_id\", how=\"left\").set_index([\"case_id\", \"party_number\"]).sort_index()\nprint(\"Dataset shape: {}\".format(df.shape))","6673f6ce":"def encode_labels(df, progress=True):\n    df = df.copy()\n    label_encoders = {}\n    for col in tqdm(df.dtypes.loc[lambda x: x==object].index, disable=not progress):\n        label_encoders[col] = preprocessing.LabelEncoder().fit(df.loc[:,col])\n        df.loc[:,col] = label_encoders[col].transform(df.loc[:,col])\n    return df, label_encoders\n\ndf_enc, label_encoders = encode_labels(df)","80c055e8":"targets = [\"vehicle_make\"]\nx,y = df_enc.drop(columns=targets), df_enc.loc[:,targets]","30ce0baf":"N = 10 # how many makes to show separately\nvehicle_make_frac = (df.vehicle_make.value_counts() \/ df.shape[0]).sort_values(ascending=False).iloc[:N]\nvehicle_make_frac = vehicle_make_frac.append(pd.Series([1 - vehicle_make_frac.sum()], index=[\"other\"]))\n\nfig,ax = plt.subplots(figsize=(10,5))\nax.set_title(\"Vehicle makes\")\nax.set_ylabel(\"relative fraction\")\nax.set_xlabel(\"make\")\nax.tick_params(axis=\"x\", rotation=45)\nax = sns.barplot(x=vehicle_make_frac.index, y=vehicle_make_frac.values, color=\"C0\", ax=ax)\n\ndel vehicle_make_frac","8f587064":"def get_pca_pipe(x):\n    ''' Fit PCA and return model '''\n    pca_pipe = pipeline.Pipeline([\n        (\"scaler\", preprocessing.StandardScaler()),\n        (\"pca\", decomposition.PCA(random_state=1))\n    ])\n    pca_pipe = pca_pipe.fit(x)\n    return pca_pipe\n\npca_pipe = get_pca_pipe(x)\npca = pca_pipe.named_steps[\"pca\"]\n\nax = sns.lineplot(x=np.arange(1,pca.n_components_+1), y=pca.explained_variance_ratio_.cumsum())\nax.set_title(\"Train set PCA\")\nax.set_xlabel(\"principal components\")\n_ = ax.set_ylabel(\"cum. explained var. ratio\")","1dd4bcb0":"def get_cluster_pipe(x, n, batch_size=1000):\n    cluster_pipe = pipeline.Pipeline([\n        (\"scaler\", preprocessing.StandardScaler()),\n        (\"cluster\", cluster.MiniBatchKMeans(n_clusters=n, batch_size=batch_size, random_state=1))\n    ])\n    cluster_pipe = cluster_pipe.fit(x)\n    return cluster_pipe\n\nN = 150 # maximum clusters tested\ninertia = [cluster_pipe.named_steps[\"cluster\"].inertia_ for cluster_pipe in jb.Parallel(n_jobs=-1)(jb.delayed(get_cluster_pipe)(x, n) for n in trange(2,N+1))]\n\nax = sns.lineplot(x=np.arange(2,N+1), y=inertia)\nax.set_title(\"Train set clustering inertia\")\nax.set_xlabel(\"n_clusters\")\n_ = ax.set_ylabel(\"inertia\")","3d9add1f":"cluster_pipe = get_cluster_pipe(x, n=60)\ncluster_values = cluster_pipe.predict(x)\nx.insert(loc=x.shape[1], column=\"cluster\", value=cluster_values)\ndf.insert(loc=df.shape[1], column=\"cluster\", value=cluster_values)\ndf_enc.insert(loc=df_enc.shape[1], column=\"cluster\", value=cluster_values)","12ea6bef":"def decode_labels(df, encoders, progress=False):\n    df = df.copy()\n    for col in encoders.keys():\n        if col in df.columns:\n            df.loc[:,col] = encoders[col].inverse_transform(df.loc[:,col].apply(lambda x: round(x))) # decode with the nearest valid label\n    return df\n\n# cluster characteristics\ncluster_centers = pd.DataFrame(cluster_pipe.named_steps[\"scaler\"].inverse_transform(cluster_pipe.named_steps[\"cluster\"].cluster_centers_), columns=x.drop(columns=\"cluster\").columns)\ncluster_centers.index.name = \"cluster\"\ncluster_centers = decode_labels(cluster_centers, label_encoders)\ncluster_centers.head()","1bfce79a":"# clusters counts per vehicle make\ncluster_counts = pd.DataFrame({\"clusters\": df.groupby(\"vehicle_make\").cluster.nunique()})\ncluster_counts = cluster_counts.sort_index().sort_values(\"clusters\", ascending=False)\ncluster_counts.head()","823d6ed5":"fig,ax = plt.subplots(figsize=(10,5))\nax.set_title(\"Makes' clusters\")\nax.set_xlabel(\"Make's number of clusters\")\nax.set_ylabel(\"relative fraction\")\nax = sns.histplot(data=cluster_counts, x=\"clusters\", stat=\"probability\", bins=np.arange(1,cluster_pipe.named_steps[\"cluster\"].cluster_centers_.shape[0] + 2) - 0.5, ax=ax)","ad87b723":"# (vehicle_make, cluster) collisions counts\ncollision_counts = pd.DataFrame({\"collisions\": df.loc[:, [\"vehicle_make\", \"cluster\"]].value_counts()})\ncollision_counts = collision_counts.sort_values(\"collisions\", ascending=False)\ncollision_counts.head()","632fd1ab":"collision_counts_cluster = collision_counts.groupby(\"cluster\").collisions.sum() \/ collision_counts.collisions.sum()\n\nfig,ax = plt.subplots(figsize=(15,5))\nax.set_title(\"Clusters collisions\")\nax.set_xlabel(\"cluster\")\nax.set_ylabel(\"relative fraction\")\nax = sns.barplot(x=collision_counts_cluster.index, y=collision_counts_cluster.values, ax=ax, color=\"C0\")","e6b026d3":"encoders_dir = \"encoders\"\nos.mkdir(encoders_dir)\nfor col in label_encoders.keys():\n    jb.dump(label_encoders[col], encoders_dir + \"\/\" + col + \".pkl\")\n\nestimators_dir = \"estimators\"\nos.mkdir(estimators_dir)\njb.dump(cluster_pipe, estimators_dir + \"\/cluster_pipe.pkl\")\n\ncluster_centers.to_csv(\"cluster_centers.csv\")\ncluster_counts.to_csv(\"cluster_counts.csv\")\ncollision_counts.to_csv(\"collision_counts.csv\")","c4551a73":"Now final results are saved.","af5bc2e6":"Since clustering did not take into account `vehicle_make`, motorcycles could belong to one or more clusters based on collisions characteristics.\nBecause of this next table shows the number of clusters that can be counted counted for each make.","72d0efe4":"Now `collisions` table is read.","3f5a72bf":"$60$ clusters are used.","e9848387":"# Data preprocessing","78cfe9ff":"Now `parties` table is read selecting only entries associated with a motorcycle.","4fc31bb5":"# Conclusions","621c47e2":"In following learning `vehicle_make` is excluded from analysis to bring back it later when generated clusters are considered.","39a8e39c":"# Clustering","c357cc0e":"Timestamps are splitted in date and time and they are not parsed, so they are processed generating one column per field (i.s. year, month, day, hour, minute, second).\nThe columns to consider are `collision_date` and `collision_time`.","0693ca01":"Collisions data are merged into `parties` table using case ids.\nMoreover, in this way collisions without any party entry will be excluded.","a14952a1":"Now missing values are filled using `\"None\"` label for categorical and $0$ for numeric features.\nMaybe $0$ is not the best value to use but it does not belongs to other significant values of numeric columns.","0c452478":"Not all columns are relevant to characterize motorcycle collisions.","88d528b2":"Motorcycles without a make are not useful so they are removed.","5dcacafe":"In **Data preprocessing** section an histogram showing the relative fraction of collisions per make is already present.\nNow the following plot shows the relative fraction of collisions per cluster.","b39b0aa7":"Work presented in this report shows how clustering could help determine common properties in one motorcycle make incidents.\nThe problem is that not all motorcycles can be assigned to a single type of collision: in fact many of the seen entries (about $40\\%$) show for the same make different groups.\nAlthought the non-unique correspondence, $60\\%$ of collisions presents one cluster per make.\n\nEventually, further improvements to this notebook could be training a supervised model capable of predicting motorcycle type based on collision characteristics; in this way relation between incidents properties and motorcycle make will be further proved.","f766eee4":"`collision_time` has some missing values.\nMedian value of timestamps distribution within the 24-hours day is used to fill missing values.","596842af":"Before introducing clusters in data, their inertia is studied varying the groups number used by estimator.\nThen clusters are produced using a value near the elbow of the resulting inertia plot.","8f4405d0":"More than $60\\%$ of makes has collisions belonging only to one cluster.\nThis means that those motorcycles made incidents with approximately the same characteristics, attributable to a single group.","ce84ed1d":"First principal components do not contain much of the original variance to be representative of the starting space, so PCA results are not used.","df2b06d7":"For the purpose of this notebook only `collisions` and `parties` tables are used.","1ee52ffa":"This notebook aims to clusterize motorcycles' collisions entries and confront them with motorcycle make information.\n\nFirst `collisions` and `parties` tables are read excluding descriptive features.\nThen they are preprocessed filling missing values and encoding categorical features.\nEventually different tables' information are merged together to build a single table.","6cd4badb":"Now categorical features are encoded.","ab19bd2b":"PCA could be used to reduce the dimensionality of the data.\nThis is possible only if a restricted number of the first principal components contain a sufficient amount of the original variance.","4f765b10":"Clusters' properties can be retrieved form their centers.","251b91ea":"# Principal Component Analysis","eef0d1ec":"# Introduction"}}