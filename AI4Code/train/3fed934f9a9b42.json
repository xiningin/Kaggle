{"cell_type":{"28b07a4a":"code","56774f05":"code","0b4e16a8":"code","d2098761":"code","18a0528b":"code","b434ea82":"code","2adb4f56":"code","84ebfa04":"code","400cc041":"code","f753141b":"code","49debc5d":"code","1fef8b5d":"code","ad5e9a30":"code","eede9f30":"code","69e3e48a":"code","623460f2":"code","e4fd9b0c":"code","20e3eaad":"code","00b777ac":"code","145d5d48":"code","031cb514":"code","b9ba1c55":"code","7e57e029":"code","a9492cf5":"code","a139afe0":"code","4286a7b8":"code","95c89729":"code","17fc9d35":"code","a7df333b":"code","21de56ab":"code","9551170a":"code","b5af7a47":"code","0894a76e":"code","3be7dec5":"code","9ceb1164":"code","709128c7":"code","83da937d":"code","6498fe80":"code","071e8cb9":"code","6a4799b0":"code","15cd263c":"code","c9e11892":"code","bc487f9c":"code","5a1bfbda":"code","35f4a8e3":"code","aee02872":"code","b7f8019d":"code","78b9376f":"code","58d8ee84":"code","ba8e6648":"code","7fc93859":"code","caf9ed1b":"code","e007b32c":"code","90027299":"code","b160abae":"code","36416507":"code","6e9defaa":"code","e49fb283":"code","b9201a3e":"code","b1dec248":"code","798a5415":"code","d838ad74":"code","3b346917":"code","58892d18":"code","412828fc":"code","a5845e43":"code","58545da4":"code","461157df":"code","aa6a0af8":"markdown","ad12d73b":"markdown","9e33f34c":"markdown","911024f0":"markdown","ac858178":"markdown","8c3f21a0":"markdown"},"source":{"28b07a4a":"%matplotlib inline\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot","56774f05":"import os\nimport shutil\nprint(os.listdir(\"..\/input\"))","0b4e16a8":"ls -la ..\/input\/keras-pretrained-models","d2098761":"os.makedirs('\/tmp\/.keras\/datasets')","18a0528b":"shutil.copytree(\"..\/input\/keras-pretrained-models\", \"\/tmp\/.keras\/models\")","b434ea82":"import os.path\nimport itertools\nfrom itertools import chain\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import datasets\nfrom sklearn import preprocessing\nfrom sklearn.decomposition import PCA\nfrom sklearn import cluster, datasets, mixture\nfrom sklearn.datasets import load_digits\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.metrics import f1_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport seaborn as sns\n\nfrom keras.layers import Input, Embedding, LSTM, GRU, Dense, Dropout, Lambda, \\\n    Conv1D, Conv2D, Conv3D, \\\n    Conv2DTranspose, \\\n    AveragePooling1D, AveragePooling2D, \\\n    MaxPooling1D, MaxPooling2D, MaxPooling3D, \\\n    GlobalAveragePooling1D, \\\n    GlobalMaxPooling1D, GlobalMaxPooling2D, GlobalMaxPooling3D, \\\n    LocallyConnected1D, LocallyConnected2D, \\\n    concatenate, Flatten, Average, Activation, \\\n    RepeatVector, Permute, Reshape, Dot, \\\n    multiply, dot, add, \\\n    PReLU, \\\n    Bidirectional, TimeDistributed, \\\n    SpatialDropout1D, \\\n    BatchNormalization\nfrom keras.models import Model, Sequential\nfrom keras import losses\nfrom keras.callbacks import BaseLogger, ProgbarLogger, Callback, History\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras import regularizers\nfrom keras import initializers\nfrom keras.metrics import categorical_accuracy\nfrom keras.constraints import maxnorm, non_neg\nfrom keras.optimizers import RMSprop\nfrom keras.utils import to_categorical, plot_model\nfrom keras import backend as K","2adb4f56":"from PIL import Image\nfrom zipfile import ZipFile\nimport h5py\nimport cv2\nfrom tqdm import tqdm","84ebfa04":"src_dir = '..\/input\/human-protein-atlas-image-classification'","400cc041":"train_labels = pd.read_csv(os.path.join(src_dir, \"train.csv\"))\nprint(train_labels.shape)\ntrain_labels.head(10)","f753141b":"test_labels = pd.read_csv(os.path.join(src_dir, \"sample_submission.csv\"))\nprint(test_labels.shape)\ntest_labels.head()","49debc5d":"def show_arr(arr, nrows = 1, ncols = 4, figsize=(15, 5)):\n    fig, subs = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n    for ii in range(ncols):\n        iplt = subs[ii]\n        img_array = arr[:,:,ii]\n        if ii == 0:\n            cp = 'Greens'\n        elif ii == 1:\n            cp = 'Blues'\n        elif ii == 2:\n            cp = 'Reds'\n        else:\n            cp = 'Oranges'\n        iplt.imshow(img_array, cmap=cp)","1fef8b5d":"def get_arr0(Id, test=False):\n    def fn(Id, color, test=False):\n        if test:\n            tgt = 'test'\n        else:\n            tgt = 'train'\n        with open(os.path.join(src_dir, tgt, Id+'_{}.png'.format(color)), 'rb') as fp:\n            img = Image.open(fp)\n            arr = (np.asarray(img) \/ 255.)\n        return arr\n    res = []\n    for icolor in ['green', 'blue', 'red', 'yellow']:\n        arr0 = fn(Id, icolor, test)\n        res.append(arr0)\n    arr = np.stack(res, axis=-1)\n    return arr","ad5e9a30":"arr = get_arr0('00008af0-bad0-11e8-b2b8-ac1f6b6435d0', test=True)\nprint(arr.shape)\nshow_arr(arr)","eede9f30":"arr = get_arr0('00070df0-bbc3-11e8-b2bc-ac1f6b6435d0')\nprint(arr.shape)\nshow_arr(arr)","69e3e48a":"SH = (139, 139)\nID_LIST_TRAIN = train_labels.Id.tolist()","623460f2":"# ### CACHE\n# img_cache_train = np.zeros((train_labels.shape[0], 139, 139, 4), dtype=np.float16)\n# ID_LIST_TRAIN = train_labels.Id.tolist()","e4fd9b0c":"# for ii, id0 in enumerate(tqdm(ID_LIST_TRAIN)):\n#     arr = get_arr0(id0)\n#     img_cache_train[ii] = cv2.resize(arr[:], SH)","20e3eaad":"# img_cache_train.shape","00b777ac":"# np.savez_compressed('img_cache_train_resize_139x139', x=img_cache_train)","145d5d48":"img_cache_train = np.load('..\/input\/139x139-resized-numpy-array\/img_cache_train_resize_139x139.npz')['x']","031cb514":"img_cache_train.shape","b9ba1c55":"def get_arr(Id, test=False):\n    if test:\n        arr = get_arr0(Id, test=True)\n        arr = cv2.resize(arr, SH).astype('float32')\n    else:\n        ii = ID_LIST_TRAIN.index(Id)\n        arr = img_cache_train[ii]\n        arr = arr.astype('float32')\n    return arr","7e57e029":"arr = get_arr('00070df0-bbc3-11e8-b2bc-ac1f6b6435d0')\narr.shape","a9492cf5":"show_arr(arr)","a139afe0":"arr = get_arr('00008af0-bad0-11e8-b2b8-ac1f6b6435d0', test=True)\nprint(arr.shape)\nshow_arr(arr)","4286a7b8":"y_cat_train_dic = {}\nfor icat in range(28):\n    target = str(icat)\n    y_cat_train_5 = np.array([int(target in ee.split()) for ee in train_labels.Target.tolist()])\n    y_cat_train_dic[icat] = y_cat_train_5","95c89729":"up_sample = {}\nfor k in y_cat_train_dic:\n    v = y_cat_train_dic[k].sum()\n    up_sample[k] = np.ceil((train_labels.shape[0]\/28) \/ v)\n\nup_sample","17fc9d35":"up_sample2 = list(zip(*sorted(list(up_sample.items()), key=lambda x: x[0])))[1]\nup_sample2 = np.array(up_sample2)\nup_sample2","a7df333b":"import random\n\nclass Seq(object):\n    sections = None\n    index = None\n    \n    def __init__(self, df, aug=True, test=False, batch_size=32):\n        self.shaffle = None\n        self.aug = aug\n        self.test = test\n        self.batch_size = batch_size\n        self.df = df\n        \n        # proccess\n        self.ids = self.df.Id.tolist()\n        self.reversed = sorted(range(SH[0]), reverse=True)\n        \n        # estimate self length\n        self.initialize_it()\n        self.len = 1\n        for _ in self.it:\n            self.len += 1\n        \n        self.initialize_it()\n    \n    def initialize_it(self):\n        if self.shaffle:\n            '''not implemented yet'''\n            raise NotImplementedError\n            #random.seed(self.state)\n            #random.shuffle(self.ids)\n        \n        self.it = iter(range(0, len(self.ids), self.batch_size))\n        self.idx_next = self.it.__next__()\n    \n    def __len__(self):\n        return self.len\n    \n    def __iter__(self):\n        return self\n    \n    def __next__(self):\n        idx = self.idx_next\n        self.ids_part = self.ids[idx:((idx+self.batch_size) if idx+self.batch_size<len(self.ids) else len(self.ids))]\n        res = self.getpart(self.ids_part)\n        try:\n            self.idx_next = self.it.__next__()\n        except StopIteration:\n            self.initialize_it()\n        return res\n    \n    def __getitem__(self, id0):\n        arr, tgts = self.get_data(id0)\n        cat = self.convert_tgts(tgts)\n        return arr, cat\n    \n    k_list = list(range(4))\n    def random_transform(self, arr):\n        k = random.choice(self.k_list)\n        arr0 = np.rot90(arr, k=k)\n        if random.randint(0,1):\n            arr0 = arr0[self.reversed,:,:]\n        if random.randint(0,1):\n            arr0 = arr0[:,self.reversed,:]\n        return arr0\n    \n    def convert_tgts(self, tgts):\n        try:\n            cats = to_categorical(tgts, num_classes=28)\n            cat = cats.sum(axis=0)\n        except TypeError:\n            cat = np.zeros((28,))\n        return cat\n    \n    def get_data(self, id0):\n        arr = get_arr(id0, test=self.test)\n        \n        try:\n            y0 = (self.df.Target[self.df.Id == id0]).tolist()[0]\n            y1 = y0.split()\n            y = [int(ee) for ee in y1]\n        except AttributeError:\n            y = None\n        return arr, y\n    \n    def getpart(self, ids):\n        xs = []\n        ys = []\n        for id0 in ids:\n            if self.aug:\n                self.extend_data(id0, xs, ys)\n            else:\n                img, cat = self[id0]\n                xs.append(img.flatten())\n                ys.append(cat)\n        \n        x = np.stack(xs)\n        y = np.stack(ys)\n        x_ret = x\n        y_ret = y\n        return (x_ret, y_ret)\n    \n    def split(self, arr, sections=sections):\n        res0 = np.vsplit(arr, sections)\n        res = [np.hsplit(ee, sections) for ee in res0]\n        res = list(chain.from_iterable(res))\n        return res\n    \n    def extend_data(self, id0, xs, ys):\n        arr0, cat = self[id0]\n        \n        # data augmentation\n        mm = up_sample2[cat==1].max()\n        mm = int(mm)\n        #print(mm)\n        for ii in range(mm):\n            img = self.random_transform(arr0)\n            xs.append(img.flatten())\n            ys.append(cat)","21de56ab":"seq = Seq(train_labels, batch_size=32)\nseq","9551170a":"print(len(seq.ids))\nlen(seq)","b5af7a47":"arr, y = seq.get_data('ad5a4858-bb9d-11e8-b2b9-ac1f6b6435d0')\nprint(arr.shape)\nshow_arr(arr)","0894a76e":"x, y = seq['ad5a4858-bb9d-11e8-b2b9-ac1f6b6435d0']\nprint(x.shape)\nshow_arr(x)","3be7dec5":"xs, ys = next(seq)","9ceb1164":"xs.shape","709128c7":"show_arr(xs[0].reshape((139,139,4)))","83da937d":"show_arr(xs[1].reshape((139,139,4)))","6498fe80":"show_arr(xs[2].reshape((139,139,4)))","071e8cb9":"show_arr(xs[3].reshape((139,139,4)))","6a4799b0":"show_arr(xs[6].reshape((139,139,4)).astype('float32'))","15cd263c":"show_arr(xs[7].reshape((139,139,4)).astype('float32'))","c9e11892":"seq = Seq(test_labels, test=True, aug=False, batch_size=32)\nseq","bc487f9c":"print(len(seq.ids))\nlen(seq)","5a1bfbda":"xs, ys = next(seq)","35f4a8e3":"xs.shape","aee02872":"show_arr(xs[0].reshape((139,139,4)).astype('float32'))","b7f8019d":"show_arr(xs[1].reshape((139,139,4)).astype('float32'))","78b9376f":"show_arr(xs[2].reshape((139,139,4)).astype('float32'))","58d8ee84":"from keras import applications\n# model_resnet = applications.resnet50.ResNet50(\n#     include_top=True,\n#     weights='imagenet',\n#     input_tensor=None,\n#     input_shape=None,\n#     pooling=None,\n#     classes=1000)","ba8e6648":"# from keras import applications\n# model_resnet = applications.inception_resnet_v2.InceptionResNetV2(\n#     include_top=True,\n#     weights='imagenet',\n#     input_tensor=None,\n#     input_shape=None,\n#     pooling=None,\n#     classes=1000)","7fc93859":"# model_resnet.summary()","caf9ed1b":"model_resnet = applications.inception_resnet_v2.InceptionResNetV2(\n    include_top=False,\n    weights='imagenet',\n    input_tensor=None,\n    input_shape=(139,139,3),\n    pooling='avg',\n    classes=None)","e007b32c":"# model_resnet.summary()","90027299":"img_shape = (139, 139, 4)\nimg_dim = np.array(img_shape).prod()\nprint(img_dim)","b160abae":"def make_model(model_resnet):\n    '''==============================\n    inputs\n    =============================='''\n    inp = Input(shape=(img_dim,), name='input')\n    oup = Reshape(img_shape)(inp)\n    oup = Conv2D(3, kernel_size=2, strides=1, padding='same')(oup)\n    model_cnvt = Model(inp, oup)\n    \n    oup = model_resnet(oup)\n    oup = Dense(28)(oup)\n    oup = Activation('sigmoid', name='cls')(oup)\n    \n    model = Model(inp, oup, name='model')\n    model.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['categorical_accuracy', 'binary_accuracy'])\n    \n    return {\n        'model_resnet': model_resnet,\n        'model_cnvt': model_cnvt,\n        'model': model\n    }\n\nmodels = make_model(model_resnet)\nmodels['model'].summary()","36416507":"models['model_cnvt'].summary()","6e9defaa":"'''aug=False'''\nseq = Seq(train_labels, aug=False, batch_size=32)\nprint(len(seq))\n\nmodels['model'].fit_generator(seq, epochs=1,\n                              steps_per_epoch=len(seq),\n                              callbacks=[])","e49fb283":"'''\nThanks Iafoss.\npretrained ResNet34 with RGBY\nhttps:\/\/www.kaggle.com\/iafoss\/pretrained-resnet34-with-rgby-0-460-public-lb\n'''\ngamma = 2.0\nepsilon = K.epsilon()\ndef focal_loss(y_true, y_pred):\n    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n    pt = K.clip(pt, epsilon, 1-epsilon)\n    CE = -K.log(pt)\n    FL = K.pow(1-pt, gamma) * CE\n    loss = K.sum(FL, axis=1)\n    return loss","b9201a3e":"models['model'].compile(loss=focal_loss,\n                        optimizer='adam',\n                        metrics=['categorical_accuracy', 'binary_accuracy'])","b1dec248":"'''aug=False'''\nseq = Seq(train_labels, aug=False, batch_size=32)\nprint(len(seq))\n\nmodels['model'].fit_generator(seq, epochs=1,\n                              steps_per_epoch=len(seq),\n                              callbacks=[])","798a5415":"seq_pred = Seq(train_labels, test=False, aug=False, batch_size=128)\nseq_pred\nxs, ys = next(seq_pred)\nxs.shape","d838ad74":"y_pred = models['model'].predict(xs)\ny_pred.shape","3b346917":"y_pred[:3]","58892d18":"# seq = Seq(train_labels, aug=True, batch_size=32)\n# print(len(seq))\n\n# models['model'].fit_generator(seq, epochs=10,\n#                               steps_per_epoch=len(seq),\n#                               callbacks=[])","412828fc":"# seq_pred = Seq(train_labels, test=False, aug=False, batch_size=128)\n# seq_pred","a5845e43":"# pred = models['model'].predict_generator(seq_pred, steps=len(seq_pred), verbose=1)","58545da4":"# seq_test = Seq(test_labels, test=True, aug=False, batch_size=128)\n# seq_test","461157df":"# pred_test = models['model'].predict_generator(seq_test, steps=len(seq_test), verbose=1)","aa6a0af8":"### predict and submit","ad12d73b":"### make model","9e33f34c":"### load cache","911024f0":"### focal loss","ac858178":"### cache train data","8c3f21a0":"### test_labels, test=True, aug=False"}}