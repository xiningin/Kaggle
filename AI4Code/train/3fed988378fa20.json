{"cell_type":{"740d9796":"code","3fb6a3e7":"code","791d7590":"code","87bbce5d":"code","9b6eda47":"code","387a59bd":"code","dc3d5a72":"code","b47eb529":"code","8448285c":"code","ed20462b":"code","d4651143":"code","81358c66":"code","0b6e50d6":"code","6eda11d6":"code","9aeefc44":"code","df06f508":"code","3c52799d":"code","f708a648":"code","fa867e84":"code","d382f61b":"code","090efa4f":"code","2ed8521c":"code","2fd8e66e":"code","dcaf35fd":"code","8b23b122":"code","2cf186c8":"code","89000d26":"code","904f1a54":"code","4b15a618":"code","22f18c35":"code","434d958b":"code","8818b740":"code","ad088429":"code","e3f88dc2":"code","610c48d9":"code","acb0da69":"code","c177673a":"code","b32d9d85":"code","ce40441c":"markdown","70401a76":"markdown","e66d8ee5":"markdown","c4e66338":"markdown","a32a24ce":"markdown","85666c1d":"markdown","3af37388":"markdown","659ccc28":"markdown","733eaa21":"markdown","cedb8c80":"markdown","c0ad411d":"markdown","18e173f7":"markdown","232580b1":"markdown","a14f4d65":"markdown","b1761496":"markdown","e2a2aa27":"markdown","bb08f168":"markdown","f357e207":"markdown","303f8d93":"markdown","9f9781de":"markdown"},"source":{"740d9796":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n\nimport string\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsns.set(style='white', context='notebook', palette='deep')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3fb6a3e7":"train = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\nIDtest = test[\"PassengerId\"]","791d7590":"train.shape","87bbce5d":"train.head(5)","9b6eda47":"test.shape","387a59bd":"test.head(5)","dc3d5a72":"test['Survived'] = 0\n\ncombined = pd.concat(objs=[train, test], axis=0).reset_index(drop=True)\n\ncombined['Group_Ticket'] = combined['Fare'].groupby(by=combined['Ticket']).transform('count')\n\ncombined['Fare'] = combined['Fare'] \/ combined['Group_Ticket']\n\ncombined.drop(['Group_Ticket'], axis=1, inplace=True)\n\ntrain_len = len(train)\ntrain = combined[:train_len]\ntest = combined[train_len:]\ntest.drop(labels=[\"Survived\"],axis = 1,inplace=True)","b47eb529":"def detect_outliers(df,n,features):\n\n    outlier_indices = []\n    \n    for col in features:\n        Q1 = np.percentile(df[col], 25)\n        Q3 = np.percentile(df[col],75)\n        IQR = Q3 - Q1\n        \n        outlier_step = 1.5 * IQR\n        \n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        outlier_indices.extend(outlier_list_col)\n        \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   ","8448285c":"Outliers_to_drop = detect_outliers(train,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])","ed20462b":"train.loc[Outliers_to_drop]","d4651143":"train = train.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)","81358c66":"train_len = len(train)\ntest_len = len(test)\ndataset =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)","0b6e50d6":"dataset.isnull().sum()","6eda11d6":"train.isnull().sum()","9aeefc44":"dataset['Embarked'] = dataset['Embarked'].fillna(dataset['Embarked'].mode()[0])\ndataset['Embarked'].isnull().sum()","df06f508":"dataset['Fare'] = dataset[['Fare']].fillna(dataset.groupby('Pclass').transform(np.mean))\ndataset['Fare'].isnull().sum()","3c52799d":"dataset_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in dataset[\"Name\"]]\ndataset[\"Title\"] = pd.Series(dataset_title)\ndataset[\"Title\"].head()","f708a648":"dataset['Age'] = dataset[['Age']].fillna(dataset.groupby('Title').transform(np.mean))\ndataset['Age'].isnull().sum()","fa867e84":"dataset['Cabin'] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in dataset['Cabin'] ])\ndataset['Cabin'].isnull().sum()","d382f61b":"dataset.isnull().sum()","090efa4f":"dataset[\"Title\"] = dataset[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ndataset[\"Title\"] = dataset[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\ndataset[\"Title\"] = dataset[\"Title\"].astype(int)\ndataset.drop(labels = [\"Name\"], axis = 1, inplace = True) ","2ed8521c":"dataset[\"Fsize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1\ndataset['Single'] = dataset['Fsize'].map(lambda s: 1 if s == 1 else 0)\ndataset['SmallF'] = dataset['Fsize'].map(lambda s: 1 if  s == 2  else 0)\ndataset['MedF'] = dataset['Fsize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ndataset['LargeF'] = dataset['Fsize'].map(lambda s: 1 if s >= 5 else 0)","2fd8e66e":"dataset = pd.get_dummies(dataset, columns = [\"Cabin\"],prefix=\"Cabin\")\ndataset = pd.get_dummies(dataset, columns = [\"Title\"],prefix=\"Title\")\ndataset = pd.get_dummies(dataset, columns = [\"Sex\"],prefix=\"Sex\")\ndataset = pd.get_dummies(dataset, columns = [\"Pclass\"],prefix=\"Pclass\")\ndataset = pd.get_dummies(dataset, columns = [\"Embarked\"],prefix=\"Embarked\")","dcaf35fd":"dataset.head()","8b23b122":"dataset.columns.values.tolist()","2cf186c8":"dataset = dataset[[\"Age\", \n                   \"Fare\", \n                   \"Sex_female\",\"Sex_male\", \n                   \"Survived\", \n                   \"Fsize\", \"Single\", \"SmallF\", \"MedF\", \"LargeF\",\n                   \"Title_0\", \"Title_1\", \"Title_2\", \"Title_3\",\n                   \"Embarked_C\", \"Embarked_Q\", \"Embarked_S\", \n                   \"Pclass_1\", \"Pclass_2\", \"Pclass_3\"]]\ndataset.head()","89000d26":"train = dataset[:train_len]\ntest = dataset[train_len:]\ntest.drop(labels=[\"Survived\"],axis = 1,inplace=True)","904f1a54":"train[\"Survived\"] = train[\"Survived\"].astype(int)\nY_train = train[\"Survived\"]\nX_train = train.drop(labels = [\"Survived\"],axis = 1)","4b15a618":"kfold = StratifiedKFold(n_splits=10)","22f18c35":"random_state = 2\nclassifiers = []\nclassifiers.append(SVC(random_state=random_state))\nclassifiers.append(DecisionTreeClassifier(random_state=random_state))\nclassifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\nclassifiers.append(RandomForestClassifier(random_state=random_state))\nclassifiers.append(ExtraTreesClassifier(random_state=random_state))\nclassifiers.append(GradientBoostingClassifier(random_state=random_state))\nclassifiers.append(MLPClassifier(random_state=random_state))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(LogisticRegression(random_state = random_state))\nclassifiers.append(LinearDiscriminantAnalysis())","434d958b":"cv_results = []\nfor classifier in classifiers :\n    cv_results.append(cross_val_score(classifier, X_train, y = Y_train, scoring = \"accuracy\", cv = kfold, n_jobs=4))","8818b740":"cv_means = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n\ncv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\n\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\"LogisticRegression\",\"LinearDiscriminantAnalysis\"]})\n\ng = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross validation scores\")","ad088429":"LDA = LinearDiscriminantAnalysis()\n\nlda_param_grid = {'solver' : ['svd']\n                 }\n\ngsLDA = GridSearchCV(LDA,param_grid = lda_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsLDA.fit(X_train, Y_train)\nLDA_best = gsLDA.best_estimator_\n\n# Best score\ngsLDA.best_score_","e3f88dc2":"LGR = LogisticRegression()\nlgr_param_grid = {'tol' : [1e-5],\n                  'class_weight' : ['balanced'],\n                  'max_iter' : [100],\n                  'random_state' : [1],\n                  'verbose' : [True]\n                 }\n\ngsLGR = GridSearchCV(LGR,param_grid = lgr_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsLGR.fit(X_train, Y_train)\nLGR_best = gsLGR.best_estimator_\n\n# Best score\ngsLGR.best_score_","610c48d9":"GBC = GradientBoostingClassifier()\ngb_param_grid = {'loss' : [\"deviance\"],\n              'n_estimators' : [100,200,300],\n              'learning_rate': [0.1, 0.05, 0.01],\n              'max_depth': [4, 8],\n              'min_samples_leaf': [100,150],\n              'max_features': [0.3, 0.1] \n              }\n\ngsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsGBC.fit(X_train,Y_train)\n\nGBC_best = gsGBC.best_estimator_\n\n# Best score\ngsGBC.best_score_","acb0da69":"MLP = MLPClassifier()\nmlp_param_grid = {'solver' : ['sgd'],\n                  'activation' : ['identity'],\n                  'max_iter' : [200],\n                  'alpha' : [1e-5],\n                  'hidden_layer_sizes' : [100,50],\n                  'random_state' : [1],\n                  'verbose' : [True]\n                 }\n\ngsMLP = GridSearchCV(MLP,param_grid = mlp_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsMLP.fit(X_train, Y_train);\nMLP_best = gsMLP.best_estimator_\n\n# Best score\ngsMLP.best_score_","c177673a":"votingC = VotingClassifier(estimators=[('mlp', MLP_best), ('lda', LDA_best), \n                                       ('lgr',LGR_best),('gbc',GBC_best)], voting='soft', n_jobs=4)\n\nvotingC = votingC.fit(X_train, Y_train)","b32d9d85":"test_Survived = pd.Series(votingC.predict(test), name=\"Survived\")\n\nresults = pd.concat([IDtest,test_Survived],axis=1)\n\nresults.to_csv(\"sumbission1011.csv\",index=False)","ce40441c":"\u65b0\u589e\u201cFsize\u201d\u7279\u5f81\uff0c\u5b83\u7684\u503c\u7531\u5144\u5f1f\u59d0\u59b9\u7236\u6bcd\u914d\u5076\u548c\u5b50\u5973\u6570\u76f8\u52a0\u5f97\u5230\uff0c\u518d\u6309\u5bb6\u5ead\u5927\u5c0f\u5206\u6210\u201cSingle\u201d, \"SmallF\", \"MedF\", \"LargeF\"","70401a76":"\u201cFare\u201d\u6709\u4e00\u4e2a\u7f3a\u5931\u503c\uff0c\u53ef\u4ee5\u7528\u76f8\u5e94\u8239\u8231\u7b49\u7ea7\u7684\u7968\u4ef7\u5e73\u5747\u503c\u6765\u586b\u5145","e66d8ee5":"Ensemble","c4e66338":"\u8fd9\u7bc7notebook\u4e3b\u8981\u662f\u81ea\u5df1\u505a\u8fd9\u4e2a\u9879\u76ee\u7684\u6574\u4f53\u8fc7\u7a0b\u548c\u603b\u7ed3\uff0c\u4e3b\u8981\u662f\u4e3a\u4e86\u7ed9\u81ea\u5df1\u4ee5\u540e\u53c2\u8003\u7528\uff0c\u8fc7\u7a0b\u4e2d\u5f15\u7528\u548c\u501f\u9274\u4e86\u4ee5\u4e0bnotebook\uff1a\n\n\u5f15\u7528\uff1a\n\n[Titanic Top 4% with ensemble modeling](http:\/\/www.kaggle.com\/yassineghouzam\/titanic-top-4-with-ensemble-modeling)\n\n[Kaggle Titanic \u751f\u5b58\u9884\u6d4b -- \u8be6\u7ec6\u6d41\u7a0b\u5410\u8840\u68b3\u7406](http:\/\/zhuanlan.zhihu.com\/p\/31743196)","a32a24ce":"\u6574\u7406\u4e00\u4e0b\u201cTitle\u201d\u7279\u5f81","85666c1d":"# \u7279\u5f81\u5de5\u7a0b","3af37388":"\u53ef\u4ee5\u770b\u5230LDA\uff0c\u903b\u8f91\u56de\u5f52\uff0c\u68af\u5ea6\u7206\u70b8\u548cMLP\u662f\u6bd4\u8f83\u51fa\u8272\u7684\u56db\u4e2a\u5206\u7c7b\u5668","659ccc28":"\u5728\u8fd9\u91cc\u6bd4\u8f83\u4e8610\u4e2a\u5206\u7c7b\u5668\uff0c\u5e76\u901a\u8fc7kfold\u4ea4\u53c9\u9a8c\u8bc1\u7ed9\u6bcf\u4e2a\u5206\u7c7b\u5668\u7684\u51c6\u786e\u6027\u6253\u5206","733eaa21":"\"Age\"\u4e2d\u7684\u7f3a\u5931\u503c\u53ef\u4ee5\u6839\u636eTitle\u4e2d\u7684\u79f0\u547c\uff0c\u5982Mr\uff0cMaster\u3001Miss\u7b49\u79f0\u547c\u4e0d\u540c\u7c7b\u522b\u7684\u4eba\u7684\u5e73\u5747\u5e74\u9f84\u6765\u586b\u5145","cedb8c80":"\"Cabin\"\u6709\u70b9\u9ebb\u70e6\uff0c\u6211\u4eec\u9009\u62e9\u4fdd\u7559\u5927\u91cf\u7f3a\u5931\u8fd9\u4e00\u7279\u5f81\uff0c\u5c06\u6240\u6709\u7f3a\u5931\u503c\u586b\u5145\u4e3a\u201cX\u201d","c0ad411d":"\u8fdb\u884c\u9884\u6d4b","18e173f7":"# \u6cf0\u5766\u5c3c\u514b\u707e\u96be\u9884\u6d4b\u7279\u5f81\u5de5\u7a0b\u4ee5\u53caensemble\u6a21\u578b\u6574\u5408","232580b1":"# \u5904\u7406\u79bb\u7fa4\u503c","a14f4d65":"# \u5904\u7406\u7f3a\u5931\u503c","b1761496":"\u5728\u8fd9\u91cc\u9009\u62e9\u4e86\u4e00\u4e2aVoting\u5206\u7c7b\u5668\u6765\u5bf9\u4e0a\u9762\u56db\u4e2a\u5206\u7c7b\u5668\u8fdb\u884c\u6295\u7968","e2a2aa27":"\"Embarked\"\u53ea\u6709\u4e24\u4e2a\u7f3a\u5931\u6570\u636e\uff0c\u7528\u4f17\u6570\u586b\u5145","bb08f168":"\u56e0\u4e3a\u5728\u8fd9\u4e2a\u6570\u636e\u96c6\u4e2d\u7684\"Fare\"\u503c\u6709\u4e9b\u7279\u6b8a\uff0c\u6709\u4e00\u4e9b\u4e58\u5ba2\u4f7f\u7528\u56e2\u4f53\u7968\u767b\u8239\uff0c\u4ed6\u4eec\u7684\u7968\u6839\u53f7\u7801\u662f\u4e00\u6837\u7684\uff0c\u7968\u4ef7\u662f\u6b63\u5e38\u5355\u4eba\u7968\u4ef7\u7684\u51e0\u500d\uff0c\u6240\u4ee5\u5728\u5904\u7406\u79bb\u7fa4\u503c\u4e4b\u524d\u5e94\u8be5\u628a\u56e2\u4f53\u7968\u7684\u7968\u4ef7\u7edf\u4e00\u9664\u4ee5\u548c\u8be5\u4e58\u5ba2\u7968\u6839\u53f7\u7801\u4e00\u6837\u7684\u4e58\u5ba2\u6570\u91cf\uff0c\u624d\u80fd\u5f97\u5230\u771f\u5b9e\u7684\u7968\u4ef7","f357e207":"# \u5efa\u6a21","303f8d93":"\u8fd9\u91cc\u7528\u4e86Tukey's test\u65b9\u6cd5\u68c0\u6d4b\u79bb\u7fa4\u503c\uff0c\u9009\u53d6\u6570\u636e\u7684\u4e0a\u56db\u5206\u4f4d\u6570\u548c\u4e0b\u56db\u5206\u4f4d\u6570\uff0825%\uff0c75%\uff09\u4e3aIQR\uff0c\u518d\u4e58\u4ee5\u4e00\u4e2a\u7cfb\u65701.5\u8868\u793a\u4e2d\u5ea6\u5f02\u5e38\uff0c\u6211\u4eec\u8ba4\u4e3a\u5c0f\u4e8e\u6216\u5927\u4e8e\u8be5\u503c\u7684\u90fd\u662f\u79bb\u7fa4\u503c","9f9781de":"\u5728\u8fd9\u91cc\u53ef\u4ee5\u9009\u62e9\u5220\u9664\u5305\u542b\u4e24\u4e2a\u79bb\u7fa4\u503c\u7684\u4e58\u5ba2\u6761\u76ee\uff0c\u800c\u6211\u4eec\u9009\u62e9\u8bb0\u5f55\u4e86\u975eobject\u7c7b\u578b\u53d8\u91cf\u7684\u201cAge\u201d, \"SibSp\", \"Parch\", \"Fare\"\u6765\u8fdb\u884c\u79bb\u7fa4\u503c\u68c0\u6d4b"}}