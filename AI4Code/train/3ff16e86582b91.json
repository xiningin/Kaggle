{"cell_type":{"2910e1a4":"code","f199a7d8":"code","d81ff7cd":"code","6a1f8aba":"code","5a9898a3":"code","de1fb031":"code","9f77167a":"code","52afc569":"code","98721aaa":"markdown","0c3bbb94":"markdown","e4f2a2b1":"markdown","07613b32":"markdown","bbe3f97c":"markdown","7535af5a":"markdown","84dadafa":"markdown"},"source":{"2910e1a4":"#Importing Libraries\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os\n\n#Deep Learning \nimport tensorflow as tf\nfrom keras.preprocessing.image import img_to_array,load_img,ImageDataGenerator\nfrom keras.layers import Dense,Input,Dropout, GlobalAveragePooling2D,Flatten,Conv2D, BatchNormalization,Activation,MaxPooling2D\nfrom keras.models import load_model,Model,Sequential\nfrom keras.optimizers import Adam,SGD, RMSprop\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau","f199a7d8":"pic_size=48\nfolder_path='..\/input\/face-expression-recognition-dataset\/images\/'","d81ff7cd":"expression='fear'\n\nplt.figure(figsize=(20,20))\nfor i in range(1,18,1):\n    plt.subplot(6,6,i)\n    img=load_img(folder_path+'train\/'+expression+\"\/\"+\n                os.listdir(folder_path + 'train\/' + expression)[i],target_size=(pic_size,pic_size))\n    plt.imshow(img)\nplt.show()\n","6a1f8aba":"batch_size=128\n\n\n# Let's use some data augmentaiton\ndatagen_train= ImageDataGenerator(rescale = 1.0\/255.0,\n                                  width_shift_range = 0.1,\n                                   height_shift_range = 0.1,\n                                   rotation_range = 20,\n                                   horizontal_flip = True)\ndatagen_val = ImageDataGenerator(rescale= 1.0\/255)\n\ntrain_set = datagen_train.flow_from_directory(folder_path+'train',target_size=(pic_size,pic_size),color_mode='grayscale',\n                                              batch_size=batch_size,\n                                              class_mode='categorical',\n                                              shuffle=True)\n\ntest_set= datagen_val.flow_from_directory(folder_path+'validation',\n                                            target_size=(pic_size,pic_size),\n                                            color_mode='grayscale',\n                                            batch_size=batch_size,\n                                            class_mode='categorical',\n                                            shuffle=False)","5a9898a3":"no_of_classes=7\nmodel=Sequential()\n\n#1st CNN Layer\nmodel.add(Conv2D(64,(3,3),padding='same', input_shape=(48,48,1)) )\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#2nd CNN Layer\nmodel.add(Conv2D(128,(5,5),padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(.25))\n\n#3rd CNN Layer\nmodel.add(Conv2D(512,(3,3), padding=('same')))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#4th CNN Layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\n#fully connected 1st Layer\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n#Fully connected 2nd layer\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(no_of_classes, activation='softmax'))\n\n\nopt=Adam(lr=.0001)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","de1fb031":"\n# number of epochs to train the NN\nepochs = 150\n\n# checkpoint to save best model\nfrom keras.callbacks import ModelCheckpoint\n\ncheckpoint=ModelCheckpoint(filepath='.\/modelbestweights.h5', mode='max', monitor='val_accuracy', verbose=1, save_best_only=True)\n\n\n\ncallbacks_list=[checkpoint]\n\n\nmodel.compile(loss='categorical_crossentropy',optimizer=Adam(lr=.001),metrics=['accuracy'])","9f77167a":"history=model.fit_generator(train_set,\n                           steps_per_epoch=train_set.n\/\/train_set.batch_size,\n                           epochs=epochs,\n                           validation_data=test_set,\n                           validation_steps=test_set.n\/\/test_set.batch_size,\n                           callbacks=callbacks_list)","52afc569":"plt.figure(figsize=(20,10))\nplt.subplot(1,2,1)\nplt.suptitle('Optimizer=Adam', fontsize=17)\nplt.ylabel('Loss',fontsize=16)\nplt.plot(history.history['loss'],label='Training loss')\nplt.plot(history.history['val_loss'],label='Validation Loss')\nplt.legend(loc='upper right')\n\nplt.subplot(1,2,2)\nplt.ylabel('Accuracy', fontsize=17)\nplt.plot(history.history['accuracy'],label='Training Accuracy')\nplt.plot(history.history['val_accuracy'],label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.show()","98721aaa":"# Model of 4 convolutions and 2 dense layers","0c3bbb94":"# Model Fitting","e4f2a2b1":"# Display dataset of fear","07613b32":"# Plot accuracy","bbe3f97c":"# Training and validating","7535af5a":"# Declaration of Images sizes","84dadafa":"Model has best validation accuracy score 69"}}