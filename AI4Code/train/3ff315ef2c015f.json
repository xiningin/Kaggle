{"cell_type":{"f7046028":"code","ae7c460e":"code","747c9f66":"code","6d3d5a10":"code","92840bae":"code","3c348443":"code","186032d2":"code","785af814":"code","3bff9ccc":"code","a55a2fb3":"code","620dfc59":"code","0da65c30":"code","89f11ebf":"code","54b05375":"code","84c1ea72":"code","e056c1c5":"code","8d4d1162":"code","65b782fd":"code","d2fdca0f":"markdown","e74064f9":"markdown","d97b23d4":"markdown","ee8ff0cd":"markdown"},"source":{"f7046028":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nfrom numpy import nan as Nan\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/rcdata\/RC'):\n    i=0\n    #for filename in filenames:\n        #print(str(i),os.path.join(dirname, filename))\n        #i=i+1\n        \n# Text detection in images required packages \nimport cv2 \nimport pytesseract \nfrom PIL import Image\nfrom zipfile import ZipFile\nimport boto3\n\n#Data extraction from text\nimport re\n\n\n# Any results you write to the current directory are saved as output.","ae7c460e":"fdf={\"IMG_NAME\":[]}\nfor img in filenames:\n    fdf['IMG_NAME'].append(img)\nfdf= pd.DataFrame.from_dict(fdf, orient='columns', dtype=None, columns=None)   \nfdf","747c9f66":"#Analyzing noise pattern on a random image\nimg = cv2.imread('\/kaggle\/input\/rcdata\/RC\/txt_mudit_b11_1361.jpg',0)\nheight = np.size(img, 0)\nwidth = np.size(img, 1)\nprint(height,width)\nrow, col = img.shape\ngauss = np.random.normal(10,10,(row,col))\nnoisy = img + gauss\nsmooth_part = noisy[:30, :30]\n\nplt.subplot(221),plt.imshow(noisy,cmap = 'gray')\nplt.title('Noisy Image'), plt.xticks([]), plt.yticks([])\nplt.subplot(222),plt.imshow(smooth_part,cmap = 'gray')\nplt.title('Smooth Part'), plt.xticks([]), plt.yticks([])\nplt.subplot(223),plt.hist(noisy.ravel(),256,[0,256])#; plt.show()\nplt.title('Noisy Image Histogram'), plt.xticks([]), plt.yticks([])\nplt.subplot(224),plt.hist(smooth_part.ravel(),256,[0,256])#; plt.show()\nplt.title('Estimated Noise Distribution'), plt.xticks([]), plt.yticks([])\nplt.show()","6d3d5a10":"i=0\n\nfor img in filenames:\n # A text file is created and flushed \n i= i+1\n file = open(\"r%d.txt\" %i, \"w+\") \n file.write(\"\") \n file.close() \n \n img1 = img\n img = cv2.imread('\/kaggle\/input\/rcdata\/RC\/%s' % img)\n\n pil_img = Image.fromarray(img)\n pil_img.save('\/kaggle\/working\/%s' % img1 ,dpi=(300,300))\n\n# Document\n documentName = '\/kaggle\/working\/%s' % img1 \n\n# Read document content\n with open(documentName, 'rb') as document:\n    imageBytes = (document.read())\n\n# Amazon Textract client\n textract = boto3.client('textract', region_name='us-west-2',  aws_access_key_id='AKIAIFS32F3H4AFXVQYA', aws_secret_access_key='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')\n \n\n# Call Amazon Textract\n response = textract.detect_document_text(Document={'Bytes': imageBytes})\n\n#print(response)\n\n# Print detected text\n for item in response[\"Blocks\"]:\n    if item[\"BlockType\"] == \"LINE\":\n        print ('\\033[94m' +  item[\"Text\"] + '\\033[0m')\n         # Open the file in append mode \n        file = open(\"r%d.txt\" %i, \"a\")\n        # Appending the text into file \n        file.write(item[\"Text\"])\n        file.write(\"\\n\")\n        # Close the file \n        file.close","92840bae":"df0={\"REG_DATE\":[] ,\"REG_UPTO\":[] }\nfor i in range(len(filenames)):\n i=i+1\n k=0\n# Open the file that you want to search \n f = open(\"\/kaggle\/working\/r%d.txt\" %i, \"r\")\n\n# Will contain the entire content of the file as a string\n content = f.read()\n\n# The regex pattern that I created\n pattern = \"\\d{1,2}[\/-]\\w{2,}[\/-]\\d{4}\" \n\n# Will return all the strings that are matched\n dates = re.findall(pattern, content)\n if len(dates)==0:\n    df0[\"REG_DATE\"].append(Nan)\n    df0[\"REG_UPTO\"].append(Nan)\n elif len(dates)==1:\n   for date in dates:\n     if \"-\" in date:\n        day, month, year = date.split(\"-\")\n     else:\n        day, month, year = date.split(\"\/\")\n     if int(year)>2020:\n         df0[\"REG_DATE\"].append(Nan)\n         df0[\"REG_UPTO\"].append(date)\n     else:\n        df0[\"REG_DATE\"].append(date)\n        df0[\"REG_UPTO\"].append(Nan)\n else:\n    df0[\"REG_DATE\"].append(dates[0])\n    df0[\"REG_UPTO\"].append(dates[1])\n f.close()","3c348443":"df0= pd.DataFrame.from_dict(df0, orient='columns', dtype=None, columns=None) \ndf0[\"REG_DATE\"] = df0[\"REG_DATE\"].astype('datetime64')\ndf0[\"REG_UPTO\"] = df0[\"REG_UPTO\"].astype('datetime64')\nfor i in range(len(df0.REG_DATE)):\n    try:\n     if int(df0.REG_DATE[i].strftime(\"%Y\"))>int(df0.REG_UPTO[i].strftime(\"%Y\")):\n        m=df0.REG_DATE[i]\n        df0.REG_DATE[i]=df0.REG_UPTO[i]\n        df0.REG_UPTO[i]=m\n        df0[\"REG_DATE\"]= df0[\"REG_DATE\"].dt.strftime('%d\/%m\/%Y')\n        df0[\"REG_UPTO\"]= df0[\"REG_UPTO\"].dt.strftime('%d\/%m\/%Y')\n    except:\n        continue\ndf0","186032d2":"df1={\"MFG_DATE\":[]}\nfor i in range(len(filenames)):\n i=i+1\n# Open the file that you want to search \n f = open(\"\/kaggle\/working\/r%d.txt\" %i, \"r\")\n\n# Will contain the entire content of the file as a string\n content = f.read()\n\n# The regex pattern that I created\n pattern = \"[^\\\/]\\d{1,2}[\/]\\d{4}\" \n\n# Will return all the strings that are matched\n dates = re.findall(pattern, content)\n if len(dates)==0:\n    df1[\"MFG_DATE\"].append(Nan)\n else:\n    k=0\n    for i in range(len(dates)):\n      month,year= dates[i].split(\"\/\")\n      if int(year)<2020 and int(month)<13 and k==0:\n          df1[\"MFG_DATE\"].append(dates[i])\n          k=1\n f.close()","785af814":"import datetime\ndf1= pd.DataFrame.from_dict(df1, orient='columns', dtype=None, columns=None)\ntry:\n df1[\"MFG_DATE\"] = df1[\"MFG_DATE\"].astype('datetime64[ns]')\n df1[\"MFG_DATE\"]= df1[\"MFG_DATE\"].dt.strftime('%m\/%Y')\nexcept: \n pass\ndf1","3bff9ccc":"df2={\"CHASSIS_NUM\":[]}\nfor i in range(len(filenames)):\n i=i+1\n# Open the file that you want to search \n f = open(\"\/kaggle\/working\/r%d.txt\" %i, \"r\")\n\n# Will contain the entire content of the file as a string\n content = f.read()\n\n# The regex pattern that I created\n pattern = \"\\w{9,11}\\s?\\d{5,6}\" \n\n# Will return all the strings that are matched\n chas = re.findall(pattern, content)\n if len(chas)==0:\n    df2[\"CHASSIS_NUM\"].append(Nan)\n else:\n    if len(chas[0])<17 and chas[0][0].isdigit()==False and chas[0][0]!=\"M\":\n        df2[\"CHASSIS_NUM\"].append(\"M\"+chas[0])\n    elif len(chas[0])>16 and chas[0][0].isdigit()==False and chas[0][0]!=\"M\":\n        df2[\"CHASSIS_NUM\"].append(\"M\"+chas[0][1:])\n    else:\n        df2[\"CHASSIS_NUM\"].append(chas[0])\n f.close()","a55a2fb3":"df2= pd.DataFrame.from_dict(df2, orient='columns', dtype=None, columns=None)\ndf2","620dfc59":"df3={\"REGN_NUM\":[]}\nfor i in range(len(filenames)):\n i=i+1\n# Open the file that you want to search \n f = open(\"\/kaggle\/working\/r%d.txt\" %i, \"r\")\n\n# Will contain the entire content of the file as a string\n content = f.read()\n\n# The regex pattern that I created\n pattern = \"[A-Z]{2,3}\\d\\w[-]?[A-Z][-]?\\D?\\d{4}\" \n\n# Will return all the strings that are matched\n regnum = re.findall(pattern, content)\n if len(regnum)==0:\n    df3[\"REGN_NUM\"].append(Nan)\n else:\n    df3[\"REGN_NUM\"].append(regnum[0])\n f.close()","0da65c30":"df3= pd.DataFrame.from_dict(df3, orient='columns', dtype=None, columns=None)\ndf3","89f11ebf":"df4={\"ENG_NUM\":[]}\nfor i in range(len(filenames)):\n i=i+1\n# Open the file that you want to search \n f = open(\"\/kaggle\/working\/r%d.txt\" %i, \"r\")\n\n# Will contain the entire content of the file as a string\n content = f.read()\n\n# The regex pattern that I created\n pattern = \"[A-Z][0-9]\\w{3,4}\\s?\\d{5,6}\"\n\n# Will return all the strings that are matched\n engnum = re.findall(pattern, content)\n if len(engnum)==0:\n    df4[\"ENG_NUM\"].append(Nan)\n else:\n    df4[\"ENG_NUM\"].append(engnum[-1])\n f.close()","54b05375":"df4= pd.DataFrame.from_dict(df4, orient='columns', dtype=None, columns=None)\ndf4","84c1ea72":"df5={\"NAME\":[]}\nfor i in range(len(filenames)):\n c=0\n i=i+1\n# Open the file that you want to search \n f = open(\"\/kaggle\/working\/r%d.txt\" %i, \"r\")\n\n# Will contain the entire content of the file as a string\n content = f.readlines()\n\n# The regex pattern that we created\n pattern = \"[A-Z]{4,13}\\s?[A-Z]{1,13}\\s?[A-Z]{1,13}?$\" \n\n# Will return all the strings that are matched but don't belong to list of words in matches\n for m in range(len(content)):\n  matches=['UPTO', 'MOTOR','STATION','ROAD','COLOR','SILV','GRE','BLACK','WHEEL','VIHAR','STREET','BAGH','APTS','HOUSE',\n          'ENCLAVE','NORTH','EAST','SOUTH','WEST','PARK','RESIDENT','GARDEN','WHITE','BLU','RED','MARG','LICENCE','HOSPITAL','AUTO','SILKY',\n          'SLS','SCHOOL','GOVERNMENT','REGISTRATION','AUTHORITY','CHOCO','NOTCH','ADDRESS','VEHICLE','OF','INDIA','LTD','SALOON','SEATING',\n          'COLOUR','PETROL','DIESEL','MUL','TATAEL','VILLAGE','INDIGO','STANDING','SEAT','MAGMA','APPT','PEARL','PVT','CERTIFICATE','FORM',\n          'VEHICLE','MFG','NAME']\n  nam = re.findall(pattern, content[m])\n  if len(nam)!=0 and (any(x in str(nam[0]) for x in matches)==False):\n   df5[\"NAME\"].append(nam[-1])\n   c=1\n   break\n if c==0:\n    df5[\"NAME\"].append(Nan)\n f.close()","e056c1c5":"df5= pd.DataFrame.from_dict(df5, orient='columns', dtype=None, columns=None)\ndf5","8d4d1162":"df=pd.concat([fdf,df3,df2,df5,df4,df0.REG_DATE,df1], axis=1)\ndf","65b782fd":"df.to_csv('train_output.csv', index=False) ","d2fdca0f":"# 1. Reading text from RC cards","e74064f9":"Now comes the tough part: Extracting relevant information from the data I've obtained from the images. I've used RegEx, or Regular Expression, a sequence of characters that forms a search pattern. RegEx can be used to check if a string contains the specified search pattern. Python has a built-in package called re, which can be used to work with Regular Expressions. This approach works fine for data like dates and chassis numbers, since they have a fixed pattern. However, when it comes to extracting names, RegEx becomes tough. I tried using StanfordCoreNLP, Wordnet and spaCy...But they didn't do well. This is because these models are trained on American\/British names, but I'm dealing with Indian names. Therefore, I decided to stick to the RegEx approach, while excluding certain keywords.","d97b23d4":"# 2. Data Extraction","ee8ff0cd":"I wished to take two different approaches to this. The first was to use Pytesseract and then use Amazon's excellent Textract API. Naturally, the former required significant preprocessing and didn't give satisfactory results. However, Amzon Textract worked brilliantly. In order to increase the accuracy even more, I tried adding grayscaling, increase contrast through convertScaleAbs, histogram equalization, adding Gaussian\/Median\/Mean blurring and applying OTSU\/Adaptive Thresholding. Weirdly, none of these preprocessing steps increased the accuracy, but actually made the results worse. Hence, I decided to use the original images, but set the dpi to 300, since that is the \"golden rule\" of digital image processing."}}