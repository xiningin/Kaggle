{"cell_type":{"1b4ae274":"code","07f40a8e":"code","cce8ac53":"code","5b02bf0a":"code","243d714d":"code","49c92709":"code","9a6ecd01":"code","fd81da75":"code","5f22ab22":"code","20ead2cc":"code","bb32ca41":"code","16cb62e7":"code","eac2ad62":"code","7acaf600":"code","8a469b42":"code","f35b0f07":"code","fee062d5":"code","89b3c416":"code","2ce94573":"code","0f2a9ab1":"code","af80911a":"code","9b3f9655":"code","84b2ccb5":"code","cd73d4f1":"code","a3bb117d":"code","803c1cb2":"code","43064eb4":"code","b482e116":"code","d0abd6a5":"code","dfa8c077":"code","38e0e4bf":"markdown","4a849cd5":"markdown","bb02b378":"markdown","0ac7641d":"markdown","b9ad3f54":"markdown","3412d0b5":"markdown","e7b6e263":"markdown","b7f8e369":"markdown","b088df6f":"markdown","6c1c35e9":"markdown","02580076":"markdown","a2c0bf5d":"markdown","782cc855":"markdown","a40c0009":"markdown","35519ab8":"markdown","03752b3e":"markdown","e7216a93":"markdown","e2d69f68":"markdown","8d418f52":"markdown","e65e62b6":"markdown","fe314605":"markdown","41227903":"markdown","d2f7f683":"markdown","a4d2a16a":"markdown","f5004912":"markdown","b6d2e151":"markdown"},"source":{"1b4ae274":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn import linear_model\nfrom sklearn.linear_model import Ridge\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.svm import SVC\nfrom sklearn import metrics\nfrom sklearn.feature_selection import mutual_info_classif\n\n","07f40a8e":"df=pd.read_csv('..\/input\/heart-failure-prediction\/heart.csv')","cce8ac53":"df.isna().sum()","5b02bf0a":"df.duplicated().sum()","243d714d":"print(df.info())","49c92709":"to_convert=[\"Sex\", \"ChestPainType\", \"RestingECG\", \"ExerciseAngina\",\"ST_Slope\"]\nfor feature in to_convert:\n    replace_with={}\n    for num, value in enumerate(df[feature].unique()):\n        replace_with[value]=num\n    df[feature]=df[feature].replace(replace_with)","9a6ecd01":"df.head()","fd81da75":"df.describe()","5f22ab22":"fig = px.bar( x=[\"No\",\"Yes\"], y=df['HeartDisease'].value_counts().sort_index(), title=\"Elements for each class\",\n            labels={\"y\": \"Elements\",\"x\": \"HeartDisease\"})\nfig.update_layout(height=400, width=600,)\nfig.show()","20ead2cc":"fig = px.bar( x=[\"M\",\"F\"], y=df['Sex'].value_counts().sort_index(), title=\"Elements for each Sex\",\n            labels={\"y\": \"Elements\",\"x\": \"Sex\"},height=400, width=600,)\nfig.update_layout()\nfig.show()","bb32ca41":"corr_matrix=df.drop(columns=\"HeartDisease\").corr(\"spearman\")\nfig=px.imshow(np.tril(corr_matrix),title=\"Spearman correlation between features\",height=400, width=600,)\nfig.show()","16cb62e7":"to_sort=df.corr(\"spearman\")[\"HeartDisease\"].sort_values(ascending=False)\nfig = px.bar( x=to_sort.index[1:], y=to_sort.values[1:], \n             title=\"Spearman correlation between features and HeartDisease\",labels={\"y\": \"Correlation\",\"x\": \"Feature\"})\nfig.add_hline(y=0)\nfig.show()","eac2ad62":"import plotly.graph_objects as go\nfor feature in df.columns[:-1]: \n    fig = make_subplots(rows=1, cols=2)\n    fig.add_trace(go.Box( y=df[feature]),row=1,col=1)\n    fig.add_trace(go.Histogram(x=df[feature]),row=1,col=2)\n    fig.update_layout(height=400, width=600, title_text=\"Boxplot and histogram for feature: \"+str(feature))\n    fig.update_layout(showlegend=False)\n    fig.show()","7acaf600":"#for each feature, except HeartDisease, checks for outlier\nfor feature in df.columns[:-1]:\n    \n    mean=df[feature].mean()\n    std=df[feature].std()\n    #I have chosen to consider outliers all elements outside 6*std\n    remove=(df[feature]<mean-6*std) | (df[feature]>mean+6*std)\n    if (remove).any():\n        print(\"Removed element(s) with:\",feature,round(df[feature].loc[remove].values[0],2))\n        df=df.loc[~remove]\n        df.reset_index()\nprint(\"# of outliers removed:\",918-df.shape[0])","8a469b42":"labels=df[\"HeartDisease\"]\n#selection of elements with right values of Cholesterol\nfiltered_data=df[df[\"Cholesterol\"]>0]\nX,y=filtered_data.drop(columns=\"Cholesterol\"),filtered_data[\"Cholesterol\"]\n#in the lines of code below we are going to compare regression methods and median\/min\n\n#linear regression\nlin_reg = LinearRegression().fit(X,y) \ny_pred_lin=lin_reg.predict(X)\nlin_error=mean_squared_error(y, y_pred_lin, squared=False)\n\n#mean\nmean_error=mean_squared_error(y, [y.mean()]*len(y), squared=False)\n\n#median\nmedian_error=mean_squared_error(y, [y.median()]*len(y), squared=False)\n\n#elastic net\nenet = ElasticNet(alpha=0.1, l1_ratio=0.1)\ny_pred_enet = enet.fit(X, y).predict(X)\nenet_error=mean_squared_error(y, y_pred_enet, squared=False)\n\n#lasso\nlasso_reg = linear_model.Lasso(alpha=0.1).fit(X,y)\ny_pred_lasso=lasso_reg.predict(X)\nlasso_error=mean_squared_error(y, y_pred_lasso, squared=False)\n\n#Ridge\nridge_reg = Ridge(alpha=0.01).fit(X, y)\ny_pred_ridge=ridge_reg.predict(X)\nridge_error=mean_squared_error(y, y_pred_ridge, squared=False)","f35b0f07":"fig = px.bar(x=[\"Linear\",\"Mean\",\"Median\",\"Elastic Net\",\"Lasso\",\"Ridge\"], \n             y=[lin_error,mean_error,median_error,enet_error,lasso_error,ridge_error],\n             title=\"Regression errors\",\n             labels={\"y\": \"Error\",\"x\": \"Regression method\"})\nfig.add_hline(y=min([lin_error,mean_error,median_error,enet_error,lasso_error,ridge_error]))\nfig.show()","fee062d5":"#we need to select only the data with wrong Cholesterol values and drop the Cholesterol column\ny_pred=lin_reg.predict(df[df[\"Cholesterol\"]==0].drop(columns=\"Cholesterol\"))\n#replace the values\ndf.loc[df[\"Cholesterol\"]==0,\"Cholesterol\"]=y_pred","89b3c416":"scaler = StandardScaler()\nlabels=df[\"HeartDisease\"]\n#splitting in train=80% and test=20%\nX_train, X_test, y_train, y_test=train_test_split(df.drop(columns=\"HeartDisease\"),labels,test_size=0.2,random_state=1234)\n#standardization of the data in order to ease calculations\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.transform(X_test)","2ce94573":"#all results are going to be saved in this dictionary\nreports_test={}\nreports_train={}\n#kernels we are going to try\nkernels=[\"linear\",\"rbf\",\"poly\",\"sigmoid\"]\n#kernels=[\"rbf\"]\nfor kernel in kernels:\n    svm = SVC(kernel=kernel)\n    svm.fit(X_train, y_train)\n    reports_train[kernel]=classification_report(y_train,svm.predict(X_train),output_dict=True)\n    preds=svm.predict(X_test)\n    reports_test[kernel]=classification_report(y_test,preds,output_dict=True)","0f2a9ab1":"accuracies_train=[round(reports_train[kernel][\"accuracy\"],2) for kernel in kernels]\nrecalls_train=accuracies=[round(reports_train[kernel][\"1\"][\"recall\"],2) for kernel in kernels]\naccuracies_test=[round(reports_test[kernel][\"accuracy\"],2) for kernel in kernels]\nrecalls_test=accuracies=[round(reports_test[kernel][\"1\"][\"recall\"],2) for kernel in kernels]\nfig = make_subplots(rows=1, cols=2, shared_yaxes=True)\ntraces1=go.Bar(x=kernels, y=accuracies,name=\"Train\")\ntraces2=go.Bar(x=kernels, y=accuracies,name=\"Test\")\nfig.append_trace(go.Bar(x=kernels, y=accuracies_train,name=\"Train Accuracies\"),row=1,col=1)\nfig.append_trace(go.Bar(x=kernels, y=recalls_train,name=\"Train Recalls\"),row=1,col=1)\nfig.append_trace(go.Bar(x=kernels, y=accuracies_test,name=\"Test Accuracies\"),row=1,col=2)\nfig.append_trace(go.Bar(x=kernels, y=recalls_test,name=\"Test Recalls\"),row=1,col=2)\nfig.update_layout(title_text='Scores on training and testing set')\nfig.show()","af80911a":"poly_results=pd.DataFrame(columns=['Gamma',\"Recall\",\"Accuracy\",\"Precision\",\"AUC\"])\nrbf_results=pd.DataFrame(columns=['Gamma',\"Recall\",\"Accuracy\",\"Precision\",\"AUC\"])\n\n#gammas to test\ngamma_range=np.arange(0.020,0.2,0.005)\nX_train, X_test, y_train, y_test=train_test_split(df.drop(columns=\"HeartDisease\"),labels,test_size=0.2,random_state=1234)\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.transform(X_test)\nfor kernel in [\"poly\",\"rbf\"]:\n    for gamma in gamma_range:\n        svm = SVC(kernel=kernel,gamma=gamma)\n        svm.fit(X_train, y_train)\n        preds=svm.predict(X_test)\n        results=classification_report(y_test,preds,output_dict=True)\n        recall,precision=round(results[\"1\"][\"recall\"],2),round(results[\"1\"][\"precision\"],2)\n        accuracy=round(results[\"accuracy\"],2)\n        fpr, tpr, thresholds = metrics.roc_curve(y_test, preds)\n        auc=round(metrics.auc(fpr, tpr),2)\n        if (kernel==\"poly\"):\n            poly_results=poly_results.append({'Gamma': gamma,\"Recall\":recall, \"Precision\":precision, \"Accuracy\":accuracy,\n                                              \"AUC\":auc},ignore_index=True)\n\n        else:\n            rbf_results=rbf_results.append({'Gamma': gamma,\"Recall\":recall, \"Precision\":precision, \"Accuracy\":accuracy, \n                                             \"AUC\":auc},ignore_index=True)\n        ","9b3f9655":"fig = px.line(poly_results, x=\"Gamma\", y=[\"Recall\",\"Precision\",\"Accuracy\",\"AUC\"], title=\"Poly kernel benchmark on test set\")\nfig.show()","84b2ccb5":"fig = px.line(rbf_results, x=\"Gamma\", y=[\"Recall\",\"Precision\",\"Accuracy\",\"AUC\"],title=\"Rbf kernel benchmark on test set\")\nfig.show()","cd73d4f1":"def plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix for poly kernel and gamma=0.035',\n                          cmap=None,\n                          normalize=True):\n    \"\"\"\n    given a sklearn confusion matrix (cm), make a nice plot\n\n    Arguments\n    ---------\n    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n\n    target_names: given classification classes such as [0, 1, 2]\n                  the class names, for example: ['high', 'medium', 'low']\n\n    title:        the text to display at the top of the matrix\n\n    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n                  see http:\/\/matplotlib.org\/examples\/color\/colormaps_reference.html\n                  plt.get_cmap('jet') or plt.cm.Blues\n\n    normalize:    If False, plot the raw numbers\n                  If True, plot the proportions\n\n    Usage\n    -----\n    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n                                                              # sklearn.metrics.confusion_matrix\n                          normalize    = True,                # show proportions\n                          target_names = y_labels_vals,       # list of names of the classes\n                          title        = best_estimator_name) # title of graph\n\n    Citiation\n    ---------\n    http:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html\n\n    \"\"\"\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import itertools\n\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"white\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n    plt.show()\nsvm = SVC(kernel=\"poly\",gamma=0.035)\nsvm.fit(X_train, y_train)\nprobs=svm.predict(X_test)\nplot_confusion_matrix(metrics.confusion_matrix(y_test,probs),[\"No\",\"Yes\"],normalize=False)","a3bb117d":"#we will run a 5-fold validation with gamma=0.025\ngamma_results=pd.DataFrame(columns=[\"Recall\",\"Accuracy\",\"Precision\",\"AUC\"])\nkf = KFold(n_splits=5, random_state=1234, shuffle=True)\nfor train_index, test_index in kf.split(X):\n    X_train, X_test = df.iloc[train_index].drop(columns=\"HeartDisease\"), df.iloc[test_index].drop(columns=\"HeartDisease\")\n    y_train, y_test = labels.iloc[train_index], labels.iloc[test_index]\n    X_train=scaler.fit_transform(X_train)\n    X_test=scaler.transform(X_test)\n    svm = SVC(kernel=\"poly\",gamma=0.025)\n    svm.fit(X_train,y_train)\n    probs=svm.predict(X_test)\n    results=classification_report(y_test,probs,output_dict=True)\n    recall,precision=results[\"1\"][\"recall\"],results[\"1\"][\"precision\"]\n    accuracy=results[\"accuracy\"]\n    fpr, tpr, thresholds = metrics.roc_curve(y_test, probs)\n    auc=metrics.auc(fpr, tpr)\n    gamma_results=gamma_results.append({\"Recall\":recall, \"Precision\":precision, \"Accuracy\":accuracy,\n                                              \"AUC\":auc},ignore_index=True)","803c1cb2":"fig = px.line(gamma_results, x=gamma_results.index+1, y=[\"Recall\",\"Precision\",\"Accuracy\",\"AUC\"],\n             labels={\"value\": \"\",\"x\": \"Run\"},title=\"5-fold with gamma=0.025\")\nfig.show()\nprint(\"Score stats:\")\nfor feature in gamma_results:\n    print(feature+\":   \"+str(round(gamma_results[feature].mean(),2))+\" +\/- \"+str(round(gamma_results[feature].std(),2)))","43064eb4":"#we will run a 5-fold validation with gamma=0.035\ngamma_results=pd.DataFrame(columns=[\"Recall\",\"Accuracy\",\"Precision\",\"AUC\"])\nkf = KFold(n_splits=5, random_state=1234, shuffle=True)\nfor train_index, test_index in kf.split(X):\n    X_train, X_test = df.iloc[train_index].drop(columns=\"HeartDisease\"), df.iloc[test_index].drop(columns=\"HeartDisease\")\n    y_train, y_test = labels.iloc[train_index], labels.iloc[test_index]\n    X_train=scaler.fit_transform(X_train)\n    X_test=scaler.transform(X_test)\n    svm = SVC(kernel=\"poly\",gamma=0.035)\n    svm.fit(X_train,y_train)\n    probs=svm.predict(X_test)\n    results=classification_report(y_test,probs,output_dict=True)\n    recall,precision=results[\"1\"][\"recall\"],results[\"1\"][\"precision\"]\n    accuracy=results[\"accuracy\"]\n    fpr, tpr, thresholds = metrics.roc_curve(y_test, probs)\n    auc=metrics.auc(fpr, tpr)\n    gamma_results=gamma_results.append({\"Recall\":recall, \"Precision\":precision, \"Accuracy\":accuracy,\n                                              \"AUC\":auc},ignore_index=True)","b482e116":"fig = px.line(gamma_results, x=gamma_results.index+1, y=[\"Recall\",\"Precision\",\"Accuracy\",\"AUC\"],\n             labels={\"value\": \"\",\"x\": \"Run\"},title=\"5-fold with gamma=0.035\")\nfig.show()\nprint(\"Score stats:\")\nfor feature in gamma_results:\n    print(feature+\":   \"+str(round(gamma_results[feature].mean(),2))+\" +\/- \"+str(round(gamma_results[feature].std(),2)))","d0abd6a5":"#the model is going to be used for the analysis\nX_train, X_test, y_train, y_test=train_test_split(df.drop(columns=\"HeartDisease\"),labels,test_size=0.2,random_state=1234)\nX_train=scaler.fit_transform(X_train)\nX_test=scaler.transform(X_test)\nsvm = SVC(kernel=\"poly\",gamma=0.035)\nsvm.fit(X_train,y_train)\nprobs=svm.predict(X_test)\nmi=pd.Series(mutual_info_classif(X_test,probs))\nmi.index=df.columns[:-1]\n#ordering values to be plotted in descending order\nmi=mi.sort_values(ascending=False)","dfa8c077":"\nfig = go.Figure()\nfig.add_trace(go.Bar(name=\"Mutual Information (MI)\", x=mi.index, y=mi.values))\nfig.add_trace(go.Bar(name=\"Pearson Correlation\", x=to_sort.index[1:], y=np.abs(to_sort.values[1:])))\nfig.update_layout(title=\"Mutual Information vs (absolute) Pearson Correlation\")\nfig.show()","38e0e4bf":"We will use the accuracy and the recall (of the \"Yes\" HeartDisease class) just for this comparison.","4a849cd5":"Gamma doesn't seem to affect the kernel rbf. All the s reaches their maximum values and a stable behaviur when 0.045<=gamma<=0.07.","bb02b378":"Classes are quite balanced!","0ac7641d":"At lower gammas, the poly kernel achieves high recalls at the expense of Precision and Accuracy.\n\nFor example, with gamma=0.025, we have: Recall=1, Accuracy=0.72Precision=0.67.\n\nAs the value of gamma increases, the recall decrease but the scores of Precision, Accuracy and AUC increase: we can notice this trend considering, for example, gamma=0.035, where we have Recall=0.97, Accuracy=0.85 Precision=0.81\n","b9ad3f54":"# Conclusions\nThe focus of the work was to build a model capable to predict Heart Disease. In order to pursue the task, the dataset was examined and preprocessed to be used for SVM benchmarks: from these benchmarks we learned that rbf and poly are the best kernels for this dataset and that the rbf kernel proven to be more stable and less influenced by gamma than the poly kernel. However, the poly kernel can reach higher values of Recall (at the expense of Precision and Accuracy scores) with small values of gamma, hence this configuration of SVM with poly kernel and small value of gamma can be useful for achieving the main task of the work.","3412d0b5":"Most of the features has a positive (often weak) correlation with HeartDisease, while only Sex and MaxHR has a negative correlation with HeartDisease.","e7b6e263":"# Root-Cause Analysis\n\nThe predictions obtained from the model can be used to understand how each feature is relevant for the classifications made by the model.\nWe will use the mutual_info_classif as feature selection method.","b7f8e369":"The RestingBP outlier detected from the plots was successfuly detected and removed!\n\nNow it's time to replace the wrong Cholesterol values.","b088df6f":"All regression methods perform slightly better than using median\/mean as replacements.\n\nAmong all regression methods, Linear and Ridge achieved the lowest errors (however, the difference between all regression error is very small).\n\nWe will use the prediction of the Linear model.","6c1c35e9":"-_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--","02580076":"Object type features must be converted in order to be used by algorithms.","a2c0bf5d":"# Data inspection","782cc855":"As expected, there are more males individuals in this dataset.\n\n","a40c0009":"The best kernels are rbf and poly.\n\nNow we will examine the behaviour of their parameters.\n\nThis time we will also use Precision (of the \"Yes\" HeartDisease class) and AUC.","35519ab8":"In the following lines of code we are going to run benchmarks to study the behaviour of SVM kernels and parameters.\n\nThe first experiment will study models with standard parameters, then we will analyze the behaviour of parameters of the best kernels.\n","03752b3e":"Features (excluding Heartdisease) aren't high correleted with each other.","e7216a93":"# Quick summary\nThe task is to build a model capable of predicting Heart Diseases. In this work, SVM was chosen as classification method: in order to study the behaviour of different kernels and gamma values, benchmarks were runned. From the benchmarks, we can notice that it's possible to build a model that can achieve, for example:\n<ul>\n    <li>Max recall (100%) at the expense of Accuracy(72%) and Precision(67%) with \"poly\" as kernel and gamma=0.025<\/li>\n    <li> High recall (95%), Accuracy(89%) and Precision(87%) with \"rbf\" as kernel and a value of gamma (around) 0.06<\/li>\n    <li> Very high recall (97%), Accuracy(85%) and Precision(81%) with \"poly\" as kernel and and gamma=0.035\n<\/ul>\nHence, the benchmarks can help us to decide both kernel and  parameters we need to set according to the model that yield the  performances we desire.","e2d69f68":"# Data pre-processing","8d418f52":"Confusion matrix of the test set obtained from the SVM model with poly kernel and gamma=0.035\n\n-_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--_--","e65e62b6":"# SVM Model building and evaluation","fe314605":"The scores are pretty stable on their avarage value.","41227903":"The Root-Cause Analysis shows that the most relevant features obtained from the results of the Pearson Correlation, that is \"ST_Slope\", \"ExerciseAngina\", and \"ChestPainType\" are considered significant according to the results of MI.\n\nThe least relevant features obtained from the results of the Pearson Correlation are as well considered not relevant from the results of MI.","d2f7f683":"From these plots it's possible to understand that:\n<ol>\n    <li>RestingBP has an outlier with value 0;<\/li>\n    <li>Cholesterol has a large group (172 elements) with value 0.<\/li>\n<\/ol>\nIn the first case, the outlier can easly be detected and removed using mean and standard deviation.\nThe second case must be handled differently: it'd be wrong to remove all these elements from the dataset so another way to handle this problem could be replace this values with predictions made from a regression model.","a4d2a16a":"We will compare MI and (absolute) Pearson Correlation absolute results obtained in the data analysis phase.","f5004912":"The given task is to predict a possible heart disease event, so it may be interesting to analyze more the kernel \"Poly\" with very low gamma: something we might want to know is what kind of results these values of gamma can achieves on other datasets.\n\nWe can simulate other datasets with a k-fold validation.","b6d2e151":"All scores less stable than the ones obtained from gamma=0.0025, and as we expected, recall tends to be smaller and the other scores tend to be bigger compared to the results of 5-fold with gamma=0.025.\n"}}