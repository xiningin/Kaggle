{"cell_type":{"9fee92c4":"code","1757f29f":"code","26870108":"code","f2a2111f":"code","d73b024f":"code","d07c2761":"code","c11de42a":"code","bcf6e9ee":"code","270caa00":"code","0a1f70ce":"code","c8c48513":"code","3f1870b6":"code","43eb5119":"code","86cbdcea":"code","1feaf3b7":"code","59e2e477":"code","36322cd0":"code","afe38ffb":"code","ea4fa09a":"code","51ed436b":"code","072d72a9":"code","91029941":"markdown","ede89e5d":"markdown","609612e7":"markdown","081856f8":"markdown","98d556c2":"markdown","3d31d53d":"markdown","66e6a532":"markdown","d17229a0":"markdown","3390af80":"markdown","8dcc3d1f":"markdown","636bcb71":"markdown","b7f04c97":"markdown","1cce822a":"markdown","2d45e557":"markdown","1190eeb6":"markdown","34e45750":"markdown","ecfbdf9a":"markdown","48db10d6":"markdown","bc6a8478":"markdown"},"source":{"9fee92c4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1757f29f":"#IMPORTING LIBRARIES\nimport tensorflow as tf\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator","26870108":"#train_data is used for feature scaling and image augmentation (image augmentation is applied to avoid overfitting).\ntrain_data = ImageDataGenerator(rescale = 1.\/255,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n\n#defining training set, here size of image is reduced to 64x64, batch of images is kept as 64 and class is defined as 'binary'.\ntraining_set = train_data.flow_from_directory('..\/input\/cat-and-dog\/training_set\/training_set', batch_size = 64, target_size = (64,64), class_mode = 'binary')","f2a2111f":"#applying same scale as training set, but only feature scaling is applied. image augmentation is avoided to prevent leakage of testing data.\ntest_data = ImageDataGenerator(rescale = 1.\/255)\n\n#defining testing set\ntesting_set = test_data.flow_from_directory('..\/input\/cat-and-dog\/test_set\/test_set', batch_size = 64, target_size = (64,64), class_mode = 'binary')","d73b024f":"#defining the CNN as a sequence of layers.\ncnn = tf.keras.models.Sequential()","d07c2761":"#adding 1st Convolutional layer\n#note that in image augmentation we kept the image size as 64x64, therefore input_shape should also be same [64,64,3] (here 3 signifies that this is a colorful image (R,G,B))\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, input_shape = [64,64,3],activation = 'relu'))\n#activation function relu is applied to decrease any linearity that might have arrised while applying filters.","c11de42a":"# applying max pooling\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))\n","bcf6e9ee":"#adding 2nd Convolutional layer\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","270caa00":"#adding 3rd Convolutional layer\ncnn.add(tf.keras.layers.Conv2D(filters = 32,kernel_size = 3, activation = 'relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size = 2, strides = 2))","0a1f70ce":"#the input of step 4 is an flattened array,\ncnn.add(tf.keras.layers.Flatten())","c8c48513":"#forming an ann with 128 input neurons\ncnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))","3f1870b6":"#adding ouput layer of the ann\ncnn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))","43eb5119":"#compiling the CNN\ncnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","86cbdcea":"#training the model\ncnn.fit(x = training_set, validation_data = testing_set, epochs = 25)","1feaf3b7":"cnn.save('catdog_cnn_model.h5')","59e2e477":"from keras.models import load_model \nclassifier = load_model('catdog_cnn_model.h5')","36322cd0":"import numpy as np\nfrom keras.preprocessing import image\ntraining_set.class_indices","afe38ffb":"image.load_img('..\/input\/cat-and-dog\/training_set\/training_set\/cats\/cat.1021.jpg')","ea4fa09a":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/cats\/cat.4014.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","51ed436b":"image.load_img('..\/input\/cat-and-dog\/training_set\/training_set\/dogs\/dog.1020.jpg')","072d72a9":"#importing images\ntest_img = image.load_img('..\/input\/cat-and-dog\/test_set\/test_set\/dogs\/dog.4030.jpg',target_size = (64,64))\n#converting image to array\ntest_img = image.img_to_array(test_img)\ntest_img = np.expand_dims(test_img,axis = 0)\nresult = classifier.predict(test_img)\nif result[0][0] >= 0.5:\n    prediction = 'dog'\nelse:\n    prediction = 'cat'\nprint(prediction)","91029941":"IT'S A DOG(the given test image is a dog's image)","ede89e5d":"Now we will save the model.","609612e7":"IT'S A CAT(the test image given is a Cat's image)","081856f8":"STEP -3 ) FLATTENING****","98d556c2":"Now we will train the model and there are 25 iteration done in this.","3d31d53d":"CNN IS DIVIDED INTO 4 STEPS\n\nCONVOLUTION\nPOOLING\nFLATTENING\nFULL CONNECTION\nSTEP - 1) ADDING CONVOLUTIONAL LAYER","66e6a532":"# Defining Train and Test Data****\u00b6","d17229a0":"**STEP - 4 ) FULL CONNECTION**","3390af80":"0 MEANS CATS AND 1 MEANS DOGS\n\n\nNow we will load the test image.\n# ","8dcc3d1f":"STEP - 2) APPLYING MAX POOLING\n\nHere we will apply the max pooling.Max pooling is a pooling operation that selects the maximum element from the region of the feature map covered by the filter. Thus, the output after max-pooling layer would be a feature map containing the most prominent features of the previous feature map.","636bcb71":"Now the CNN is compiled","b7f04c97":"Now we will add the 3rd convolution layer.","1cce822a":"# *#Defining the CNN as a sequence of layers.\n\n\nThe convolutional neural network (CNN) is a class of deep learning neural networks. CNNs represent a huge breakthrough in image recognition. They're most commonly used to analyze visual imagery and are frequently working behind the scenes in image classification.\n","2d45e557":"An ouput layer of the ann is added and sigmoid is used as the activation function.","1190eeb6":"Fully Connected Layer is simply, feed forward neural networks. Fully Connected Layers form the last few layers in the network. The input to the fully connected layer is the output from the final Pooling or Convolutional Layer, which is flattened and then fed into the fully connected layer\n\n\nAn ann is formed with 128 input neurons and relu is used as the activation function.","34e45750":"Addition of 2nd convolution layer.","ecfbdf9a":"# PREDICTING VALUES","48db10d6":"# **Classifying whether the given image is a DOG or a CAT using CNN******","bc6a8478":"Flattening is converting the data into a 1-dimensional array for inputting it to the next layer. We flatten the output of the convolutional layers to create a single long feature vector. And it is connected to the final classification model, which is called a fully-connected layer."}}