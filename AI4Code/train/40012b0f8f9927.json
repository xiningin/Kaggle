{"cell_type":{"a2213a2b":"code","3ef0d9f4":"code","1c4a825a":"code","f2bb9550":"code","5d11e621":"code","1baa2d33":"code","251af46b":"code","dc5148ea":"code","7b67f7b5":"code","9f949caf":"code","d4f4e6f5":"code","6435553c":"code","385c3d77":"code","48cffe1c":"code","bf6b97fd":"code","7d91e18f":"code","97eb9e78":"code","2725fd8f":"code","194a2371":"code","aa9c3d70":"code","61e19182":"code","8507234b":"code","f6bdc297":"code","6861dfda":"code","58954c0a":"code","917decd0":"code","cdbcc541":"code","3a9d4ac1":"code","fda022d6":"code","e36bf666":"code","14a8c62b":"code","6ab13bb5":"code","e7c69d82":"code","24adcbf7":"code","d8489c26":"code","a441df8a":"code","8d441137":"code","d1598d5b":"code","3ea6170f":"code","ece0f2e5":"code","7cc756b6":"code","b406a5c4":"code","d62d6c54":"code","b3956952":"code","48276db2":"code","5ce54598":"code","a4f60375":"code","7c5d774c":"code","e006b1aa":"code","483356cc":"code","82692823":"code","84f60e24":"code","4d1cf5c2":"code","a3b5a805":"code","10a681e1":"code","67841b20":"code","1e544ca6":"code","14426241":"code","341485d2":"code","ad28324d":"code","4fd467eb":"code","06a8a04d":"code","e71cc581":"code","638c3e15":"code","f1f1bde3":"code","c8d53060":"code","e070d698":"code","9e81f019":"code","b3b13cf0":"code","02487626":"code","6987aea3":"code","c83317d7":"code","2f6327d5":"code","b7bb8a2b":"code","5d9611d4":"code","ba10854b":"code","014b6688":"code","0f7fe72f":"code","2e2f83fc":"code","f43314ca":"code","68d3af95":"code","15e70c43":"code","596fa1bf":"code","1ba81f6f":"code","ccda8113":"code","2682b33c":"code","78298afc":"code","f2d96c26":"code","84fdc9a4":"code","78fdcf0f":"code","7ae76f13":"code","f18ec091":"code","d1f00d1f":"code","c257f510":"code","0f63c25b":"code","d52a5e28":"code","b6d3e78f":"code","b86e0443":"code","2f20e06b":"code","14378f57":"code","691f6397":"code","69bd7d29":"code","5660bdc4":"code","16c9c0b4":"code","0051c936":"code","8da86de3":"code","17e3f8ee":"code","a6447a4e":"code","c3a49698":"code","711a0ff2":"code","d7410fef":"code","c468bbd1":"code","a6537e4d":"code","2d264b3e":"code","011b6531":"code","8684b2c7":"code","a171a6b6":"code","9e64a1f0":"code","5bea3302":"code","9719d5cc":"code","4c480cc2":"code","09a7c557":"code","679a13a6":"code","345bbea2":"code","1107602d":"code","8eb09fd7":"code","084e0c7f":"code","cdd64160":"code","54e72c62":"code","0475337c":"code","f2b26bb1":"code","0fcfacbc":"code","124fd5ba":"code","503aba7e":"code","5ff319a7":"code","e4ec0ba9":"code","21502e07":"code","1c259de6":"code","a804dd95":"code","4ca5ba47":"code","db3f84ed":"code","7d7ba5c4":"code","8b0e8295":"code","d9395014":"code","727f2749":"code","21592b7d":"code","ddc7f772":"code","87408a0a":"code","a842b8dc":"code","c9715e49":"code","21ad3a73":"code","5d5cdbeb":"code","6bdc63e4":"code","6e4820f7":"code","1c39381d":"code","2941a35c":"code","0f54cd6f":"code","a0edc622":"code","6bb5ec52":"code","487d80e8":"code","a7752a4c":"code","fb1e7916":"code","e99e45ae":"code","ff2026b5":"code","ebc60208":"code","4154b288":"code","93ab47b3":"code","cff7b95f":"code","82b62394":"code","dbe07850":"code","0af77ddc":"code","ef45275c":"code","ee55154f":"code","5bc454f6":"code","9b432cd3":"code","f9779a1d":"code","44ecb8f5":"code","c316a887":"code","dc2585db":"code","d4b2a8f9":"code","01d3fa5a":"code","059fa833":"code","ea28f5d1":"code","56cbc126":"code","65734573":"code","d51fe070":"code","acb26afa":"code","0d1a547e":"code","3abf325f":"code","ec617e4c":"code","6a81b82a":"code","a36ea8b1":"code","55804223":"code","03242066":"code","736aa937":"code","bdadaeac":"code","f24c0bc9":"code","0b1ce42f":"code","4ff8a94f":"code","38a64a06":"code","e1962f7d":"code","4736bd12":"code","ead04c23":"code","31b99d6c":"code","397fcda1":"code","d85a6124":"code","f79b628c":"code","33030539":"code","c62b725a":"code","8634e166":"code","f28ef9a8":"code","611eddbe":"code","2da6c617":"code","741ecdc4":"code","ef588be8":"code","50ff5558":"code","56bf0fc5":"code","7c4ee373":"code","d1abb46a":"code","f5d1fd77":"code","d6e76d1a":"code","b9777ca7":"code","28f05cb2":"code","7c5286d4":"code","5fabce7d":"code","aa7abaef":"code","00548f64":"code","5a36acf5":"code","0faff8e1":"code","bc6b3437":"code","b1cfcc11":"code","b1dacc44":"code","48898418":"code","2497b14c":"code","6a134ba8":"code","cc5400e9":"code","b22ec4be":"code","e77eb08e":"code","8594fd49":"code","a7a03258":"code","78a337c4":"code","8e1282e9":"code","5bf37354":"code","10c9e68b":"code","e75128a3":"code","55a4d39c":"code","750f794f":"code","2bc1bb8d":"code","76034bbe":"code","45a28538":"code","96bd8fe7":"code","e67a9cbd":"code","7b140859":"code","5c07c066":"code","51a042d0":"code","72e35cc6":"code","d237030f":"code","c290e37e":"code","d46b31ca":"code","4c02b33f":"code","40fb8536":"code","ef234456":"code","c273a649":"code","3f0a51f4":"code","e64ce61f":"code","f512fc19":"code","b067b241":"code","27aac2fd":"code","7f2777a1":"code","7eba8a47":"code","8704a776":"code","0160d2cb":"code","06ca8102":"code","aab17c94":"code","2f92cea6":"code","f821b97c":"code","e1c949cb":"markdown","f63f1eeb":"markdown","0f0e3b25":"markdown","43bf5d81":"markdown","bed35123":"markdown","de23196b":"markdown","e1632e34":"markdown","79525ff1":"markdown","429a554b":"markdown","f19b3d2f":"markdown","43fd26d9":"markdown","c8a9f569":"markdown","8631b4a5":"markdown","60f269b7":"markdown","e9a24c86":"markdown","747c28a6":"markdown","40be1c45":"markdown","eadfc1e4":"markdown","b193fae0":"markdown","bc44a063":"markdown","770b6774":"markdown","e68fff1a":"markdown","0ed22248":"markdown","03da4d01":"markdown","a3e67c10":"markdown","93ed5f25":"markdown","c8f3a74b":"markdown","60988aa0":"markdown","52c44d69":"markdown","199615e9":"markdown","e4e287a4":"markdown","e848b5a1":"markdown","af82f48e":"markdown","f29406c3":"markdown","3da261bd":"markdown","1ce1ec24":"markdown","ab7c0a57":"markdown","cbb31bf7":"markdown","aa9445d6":"markdown","67b38d55":"markdown","2003fc6e":"markdown","8328a98a":"markdown","bb386509":"markdown","8cb1c1e5":"markdown","f46d7d91":"markdown","376976d0":"markdown","3df8aae3":"markdown","a3da93d4":"markdown","7af6d1dd":"markdown","93883214":"markdown","b65d7d75":"markdown","f13e3348":"markdown","1b8266a6":"markdown","93116062":"markdown","c573ace7":"markdown","e0f3ba8f":"markdown","c3760a4b":"markdown","f199f4c9":"markdown","09ba3dbf":"markdown","0ed4eff3":"markdown","9ca9fc55":"markdown","220a7bc5":"markdown","f7b5d611":"markdown","e8ec1737":"markdown","2306e944":"markdown","ea761656":"markdown","dec49d2a":"markdown","6c9a92c2":"markdown","ff2c396e":"markdown","dfabe8ce":"markdown","65acfce0":"markdown","5ec80b7d":"markdown","b34f741f":"markdown","4ec569b0":"markdown","9cb0f775":"markdown","0fddbf00":"markdown","2cbb9bc9":"markdown","b2b99a1c":"markdown","4df43dff":"markdown","5cfd8b29":"markdown","a0ff6394":"markdown","32d2bd97":"markdown","9e8c386c":"markdown","84a6f862":"markdown","e2098e73":"markdown","bae2410f":"markdown","30248371":"markdown"},"source":{"a2213a2b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3ef0d9f4":"df = pd.read_csv('\/kaggle\/input\/lt-vehicle-loan-default-prediction\/train.csv')\ndf.head()","1c4a825a":"df.shape","f2bb9550":"df.columns = [i.lower() for i in df.columns]\ndf.columns = [i.replace('.','_') for i in df.columns]","5d11e621":"df.columns","1baa2d33":"print('The number of duplicates:',df.duplicated().sum())","251af46b":"# Dropping the unnecessary features\n\ndf.drop(['uniqueid','branch_id','supplier_id','mobileno_avl_flag','current_pincode_id','employee_code_id','manufacturer_id','state_id'],axis=1,inplace=True)","dc5148ea":"df.info()","7b67f7b5":"df.isnull().sum()","9f949caf":"# Dropping the rows with Employment Type Null as it constitutes just 3% of data\ndf = df.dropna()","d4f4e6f5":"df.describe(include='all')","6435553c":"pct_loan_default = df['loan_default'].value_counts(normalize=True)*100\npct_loan_default","385c3d77":"import plotly.express as px \nfig = px.pie(values=pct_loan_default.values, names=['Not defaulted','Defaulted']) \nfig.show()","48cffe1c":"df1 = pd.crosstab(df['employment_type'],df['loan_default'])\nfig = px.bar(df1, barmode = 'group',width=600,height=400)\nfig.show()","bf6b97fd":"df['employment_type'].value_counts(normalize=True)*100","7d91e18f":"print('Percentage of salaried people who have defaulted:',\n     np.round(df[(df['employment_type']=='Salaried') & (df['loan_default']==1)].shape[0]\/(df[df['employment_type']=='Salaried'].shape[0])*100,3))\nprint('Percentage of self employed people who have defaulted:',\n     np.round(df[(df['employment_type']=='Self employed') & (df['loan_default']==1)].shape[0]\/(df[df['employment_type']=='Self employed'].shape[0])*100,3))","97eb9e78":"df1 = pd.crosstab(df['aadhar_flag'],df['loan_default'])\nfig = px.bar(df1, barmode = 'group',width=600,height=400)\nfig.show()","2725fd8f":"df['aadhar_flag'].value_counts(normalize=True)*100","194a2371":"print('Percentage of people who have given their Aadhar details and defaulted:',\n     np.round(df[(df['aadhar_flag']==1) & (df['loan_default']==1)].shape[0]\/(df[df['aadhar_flag']==1].shape[0])*100,3))\nprint('Percentage of people who have not given their Aadhar details and defaulted:',\n     np.round(df[(df['aadhar_flag']==0) & (df['loan_default']==1)].shape[0]\/(df[df['aadhar_flag']==0].shape[0])*100,3))","aa9c3d70":"df1 = pd.crosstab(df['pan_flag'],df['loan_default'])\nfig = px.bar(df1, barmode = 'group',width=600,height=400)\nfig.show()","61e19182":"df['pan_flag'].value_counts(normalize=True)*100","8507234b":"print('Percentage of people who have given their PAN details and defaulted:',\n     np.round(df[(df['pan_flag']==1) & (df['loan_default']==1)].shape[0]\/(df[df['pan_flag']==1].shape[0])*100,3))\nprint('Percentage of people who have not given their PAN details and defaulted:',\n     np.round(df[(df['pan_flag']==0) & (df['loan_default']==1)].shape[0]\/(df[df['pan_flag']==0].shape[0])*100,3))","f6bdc297":"df1 = pd.crosstab(df['voterid_flag'],df['loan_default'])\nfig = px.bar(df1, barmode = 'group',width=600,height=400)\nfig.show()","6861dfda":"df['voterid_flag'].value_counts(normalize=True)*100","58954c0a":"print('Percentage of people who have given their voter_id details and defaulted:',\n     np.round(df[(df['voterid_flag']==1) & (df['loan_default']==1)].shape[0]\/(df[df['voterid_flag']==1].shape[0])*100,3))\nprint('Percentage of people who have not given their voter_id details and defaulted:',\n     np.round(df[(df['voterid_flag']==0) & (df['loan_default']==1)].shape[0]\/(df[df['voterid_flag']==0].shape[0])*100,3))","917decd0":"df1 = pd.crosstab(df['driving_flag'],df['loan_default'])\nfig = px.bar(df1, barmode = 'group',width=600,height=400)\nfig.show()","cdbcc541":"df['driving_flag'].value_counts(normalize=True)*100","3a9d4ac1":"print('Percentage of people who have given their DL details and defaulted:',\n     np.round(df[(df['driving_flag']==1) & (df['loan_default']==1)].shape[0]\/(df[df['driving_flag']==1].shape[0])*100,3))\nprint('Percentage of people who have not given their DL details and defaulted:',\n     np.round(df[(df['driving_flag']==0) & (df['loan_default']==1)].shape[0]\/(df[df['driving_flag']==0].shape[0])*100,3))","fda022d6":"df1 = pd.crosstab(df['passport_flag'],df['loan_default'])\nfig = px.bar(df1, barmode = 'group',width=600,height=400)\nfig.show()","e36bf666":"df['passport_flag'].value_counts(normalize=True)*100","14a8c62b":"print('Percentage of people who have given their Passport details and defaulted:',\n     np.round(df[(df['passport_flag']==1) & (df['loan_default']==1)].shape[0]\/(df[df['passport_flag']==1].shape[0])*100,3))\nprint('Percentage of people who have not given their Passport details and defaulted:',\n     np.round(df[(df['passport_flag']==0) & (df['loan_default']==1)].shape[0]\/(df[df['passport_flag']==0].shape[0])*100,3))","6ab13bb5":"#Encoding Employment Type\ndf['self_employed'] = pd.get_dummies(df['employment_type'],drop_first=True)","e7c69d82":"df.drop('employment_type',axis=1,inplace=True)\ndf.head()","24adcbf7":"df1 = df[['self_employed','aadhar_flag','pan_flag','voterid_flag','driving_flag',\n         'passport_flag']]","d8489c26":"# Feature importances using SelectKBest algorithm using chi2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_selection import SelectKBest,chi2\nn = SelectKBest(score_func=chi2, k='all')\ncatcols=n.fit(df1,df['loan_default'])\nplt.figure(figsize=(7,5))\nsns.barplot(x=catcols.scores_,y=df1.columns)\nplt.title('Best Categorical Features')\nplt.show()","a441df8a":"# Feature importances using Extra Trees Classifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\nmodel=ExtraTreesClassifier()\nmodel.fit(df1,df['loan_default'])","8d441137":"pd.DataFrame(model.feature_importances_,index=df1.columns,columns=['Feature_Importance']).sort_values(by='Feature_Importance',ascending=False)","d1598d5b":"ranked_features=pd.Series(model.feature_importances_,index=df1.columns)\nranked_features.nlargest(6).plot(kind='barh')\nplt.show()","3ea6170f":"# Dropping unncessary features based on the above analysis\n\ndf.drop(['pan_flag','driving_flag','passport_flag'],axis=1,inplace=True)","ece0f2e5":"df['disbursed_amount'].describe()","7cc756b6":"disbursed_amount_non_default = df[df['loan_default']==0]['disbursed_amount']\ndisbursed_amount_default = df[df['loan_default']==1]['disbursed_amount']","b406a5c4":"pd.DataFrame([disbursed_amount_non_default.describe(), disbursed_amount_default.describe()], index=['non_defaulters','defaulters'])","d62d6c54":"import warnings\nwarnings.filterwarnings('ignore')\nplt.figure(figsize=(15,8))\n\nplt.subplot(1,2,1)\nsns.distplot(df['disbursed_amount'])\n\nplt.subplot(1,2,2)\nsns.boxplot(df['disbursed_amount'])\n\nplt.show()","b3956952":"plt.figure(figsize=(15,6))\nsns.violinplot(x ='loan_default',y='disbursed_amount',data=df)\nplt.show()","48276db2":"df['asset_cost'].describe()","5ce54598":"asset_cost_non_default = df[df['loan_default']==0]['asset_cost']\nasset_cost_default = df[df['loan_default']==1]['asset_cost']","a4f60375":"pd.DataFrame([asset_cost_non_default.describe(), asset_cost_default.describe()], index=['non_defaulters','defaulters'])","7c5d774c":"plt.figure(figsize=(15,8))\n\nplt.subplot(1,2,1)\nsns.distplot(df['asset_cost'])\n\nplt.subplot(1,2,2)\nsns.boxplot(df['asset_cost'])\n\nplt.show()","e006b1aa":"plt.figure(figsize=(15,6))\nsns.violinplot(x ='loan_default',y='asset_cost',data=df)\nplt.show()","483356cc":"df['ltv'].describe()","82692823":"ltv_non_default = df[df['loan_default']==0]['ltv']\nltv_default = df[df['loan_default']==1]['ltv']","84f60e24":"pd.DataFrame([ltv_non_default.describe(), ltv_default.describe()], index=['non_defaulters','defaulters'])","4d1cf5c2":"plt.figure(figsize=(15,8))\n\nplt.subplot(1,2,1)\nsns.distplot(df['ltv'])\n\nplt.subplot(1,2,2)\nsns.boxplot(df['ltv'])\n\nplt.show()","a3b5a805":"plt.figure(figsize=(15,6))\nsns.violinplot(x ='loan_default',y='ltv',data=df)\nplt.show()","10a681e1":"# We have DOB of the customer and the date of disbursal, from which we need to calculate the age of the customer at the\n# time of loan disbursal\n\ndef age(dob):\n    yr = int(dob.split('-')[2])\n    if yr >=0 and yr < 21:\n        return yr + 2000\n    else:\n         return yr + 1900\n        \ndf['date_of_birth'] = df['date_of_birth'].apply(age)\ndf['disbursaldate'] = df['disbursaldate'].apply(age)\n# Age of the customer at the time of disbursement of fund\ndf['age'] = df['disbursaldate'] - df['date_of_birth']","67841b20":"# Dropping the DOB and Disbursal Date\ndf.drop(['date_of_birth','disbursaldate'],axis=1,inplace=True)","1e544ca6":"df['age'].describe()","14426241":"age_non_defaulters = df[df['loan_default'] == 0]['age']\nage_defaulters = df[df['loan_default'] == 1]['age']","341485d2":"pd.DataFrame([age_non_defaulters.describe(), age_defaulters.describe()], index=['non_defaulters','defaulters'])","ad28324d":"plt.figure(figsize=(15,8))\n\nplt.subplot(1,2,1)\nsns.distplot(df['age'])\n\nplt.subplot(1,2,2)\nsns.boxplot(df['age'])\n\nplt.show()","4fd467eb":"plt.figure(figsize=(15,6))\nsns.boxplot(x ='loan_default',y='age',data=df)\nplt.show()","06a8a04d":"df['perform_cns_score'].describe()","e71cc581":"cibil_non_default = df[df['loan_default']==0]['perform_cns_score']\ncibil_default = df[df['loan_default']==1]['perform_cns_score']","638c3e15":"pd.DataFrame([cibil_non_default.describe(), cibil_default.describe()], index=['non_defaulters','defaulters'])","f1f1bde3":"plt.figure(figsize=(15,6))\n\nplt.subplot(1,2,1)\nsns.distplot(df['perform_cns_score'])\n\nplt.subplot(1,2,2)\nsns.boxplot(df['perform_cns_score'])\n\nplt.show()","c8d53060":"plt.figure(figsize=(15,6))\n\nsns.distplot(cibil_non_default, color='blue', label = 'Non Defaulter')\nsns.distplot(cibil_default, color='red', label = 'Defaulter')\n\nplt.legend()\nplt.show()","e070d698":"plt.figure(figsize=(15,6))\nsns.boxplot(x ='loan_default',y='perform_cns_score',data=df)\nplt.show()","9e81f019":"sns.scatterplot(df['age'], df['perform_cns_score'])\n\nplt.show()\n\n# Here we can see that irrespective of age CIBIL score variation is same ","b3b13cf0":"df['perform_cns_score_description'].describe()","02487626":"df['perform_cns_score_description'].value_counts()","6987aea3":"cnsd = pd.crosstab(index=df['perform_cns_score_description'], columns=df['loan_default'])\ncnsd['Percent of Defaulters'] = (cnsd[1] \/ (cnsd[0] + cnsd[1]))*100\ncnsd","c83317d7":"df.groupby(by='perform_cns_score_description')['perform_cns_score'].agg([min,max]).sort_values(by='min')","2f6327d5":"# grouping all same risk into one and creating a new feature with only six classes\n# e.g A-Very Low Risk to Very Low Risk\n#     B-Very Low Risk to Very Low Risk\n\nrisk = []\nfor i in df['perform_cns_score_description']:\n    if('Very Low' in i):\n        risk.append('Very Low Risk')\n    elif('Low' in i):\n        risk.append('Low Risk')\n    elif('Medium' in i):\n        risk.append('Medium Risk')\n    elif('Very High' in i):\n        risk.append('Very High Risk')\n    elif('High' in i):\n        risk.append('High Risk')\n    else:\n        risk.append('Not Scored')","b7bb8a2b":"df['risk'] = risk","5d9611d4":"risk_counts = pd.Series(risk).value_counts().sort_values()\nrisk_counts","ba10854b":"plt.barh(y = risk_counts.index,width=risk_counts.values)\nplt.show()","014b6688":"risk_counts = pd.crosstab(index=df['risk'], columns=df['loan_default'])\n\nrisk_counts['Percent_of_default'] = round((risk_counts[1]\/risk_counts.sum(axis=1))*100,2)\n\nrisk_counts.sort_values(by='Percent_of_default',ascending=False)","0f7fe72f":"df.groupby(by='risk')['perform_cns_score'].agg([min,max]).sort_values(by='min')","2e2f83fc":"risk_map = {'Not Scored':-1, \n            'Very Low Risk':4,\n            'Low Risk':3,\n            'Medium Risk':2, \n            'High Risk':1,\n            'Very High Risk':0}\n\ndf['risk'] = df['risk'].map(risk_map)","f43314ca":"risk_counts = pd.crosstab(index=df['risk'], columns=df['loan_default'])\nrisk_counts['Percent of Defaluters'] = (risk_counts[1] \/ (risk_counts[0] + risk_counts[1]))*100\nrisk_counts.sort_values(by='Percent of Defaluters', ascending=False)","68d3af95":"pd.crosstab(index=df['risk'], columns=df['loan_default']).plot(kind='bar')\nplt.show()","15e70c43":"df.drop('perform_cns_score_description',axis=1,inplace=True)","596fa1bf":"# We have 2 Columns named \"AVERAGE_ACCT_AGE\" & \"CREDIT_HISTORY_LENGTH\".\n# They have AplhaNumeric Values,changing them to Months\n\ndef duration(dur):\n    yrs = int(dur.split(' ')[0].replace('yrs',''))\n    mon = int(dur.split(' ')[1].replace('mon',''))\n    return yrs*12+mon","1ba81f6f":"df['credit_history_length'] = df['credit_history_length'].apply(duration)\ndf['average_acct_age'] = df['average_acct_age'].apply(duration)","ccda8113":"df['average_acct_age'].describe()","2682b33c":"acct_age_non_defaulters = df[df['loan_default'] == 0]['average_acct_age']\nacct_age_defaulters = df[df['loan_default'] == 1]['average_acct_age']","78298afc":"pd.DataFrame([acct_age_non_defaulters.describe(), acct_age_defaulters.describe()], index=['non_defaulters','defaulters'])","f2d96c26":"plt.figure(figsize=(15,6))\n\nplt.subplot(1,2,1)\nsns.distplot(df['average_acct_age'])\n\nplt.subplot(1,2,2)\nsns.boxplot(df['average_acct_age'])\n\nplt.show()","84fdc9a4":"plt.figure(figsize=(15,6))\nsns.boxplot(x ='loan_default',y='average_acct_age',data=df)\nplt.show()","78fdcf0f":"df['credit_history_length'].describe()","7ae76f13":"credit_non_default = df[df['loan_default'] == 0]['credit_history_length']\ncredit_default = df[df['loan_default'] == 1]['credit_history_length']","f18ec091":"pd.DataFrame([credit_non_default.describe(), credit_default.describe()], index=['non_defaulters','defaulters'])","d1f00d1f":"plt.figure(figsize=(15,6))\n\nplt.subplot(1,2,1)\nsns.distplot(df['credit_history_length'])\n\nplt.subplot(1,2,2)\nsns.boxplot(df['credit_history_length'])\n\nplt.show()","c257f510":"counts = df['new_accts_in_last_six_months'].value_counts()\npercent = df['new_accts_in_last_six_months'].value_counts(normalize=True)*100\n\npd.DataFrame({'counts':counts,'percent_of_data':percent})","0f63c25b":"counts = df['delinquent_accts_in_last_six_months'].value_counts()\npercent = df['delinquent_accts_in_last_six_months'].value_counts(normalize=True)*100\n\npd.DataFrame({'counts':counts,'percent_of_data':percent})","d52a5e28":"counts = df['no_of_inquiries'].value_counts()\npercent = df['no_of_inquiries'].value_counts(normalize=True)*100\n\npd.DataFrame({'counts':counts,'percent_of_data':percent})","b6d3e78f":"no_inquiries = pd.crosstab(index=df['no_of_inquiries'], columns=df['loan_default'])\nno_inquiries['pct_default'] = (no_inquiries[1]\/no_inquiries.sum(axis=1))*100\nno_inquiries","b86e0443":"plt.figure(figsize=(15,8))\nplt.bar(no_inquiries.index,no_inquiries['pct_default'])\nplt.xticks(no_inquiries.index)\nplt.xlabel('No of Enquires')\nplt.ylabel('Percent of default')\nplt.show()","2f20e06b":"df2 = df[['disbursed_amount','asset_cost', 'ltv','perform_cns_score', 'pri_no_of_accts', 'pri_active_accts',\n       'pri_overdue_accts', 'pri_current_balance', 'pri_sanctioned_amount',\n       'pri_disbursed_amount', 'sec_no_of_accts', 'sec_active_accts',\n       'sec_overdue_accts', 'sec_current_balance', 'sec_sanctioned_amount',\n       'sec_disbursed_amount', 'primary_instal_amt', 'sec_instal_amt',\n       'new_accts_in_last_six_months', 'delinquent_accts_in_last_six_months',\n       'average_acct_age', 'credit_history_length', 'no_of_inquiries',\n       'age', 'risk']]","14378f57":"from sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\nmodel=ExtraTreesClassifier()\nmodel.fit(df2,df['loan_default'])","691f6397":"pd.DataFrame(model.feature_importances_,index=df2.columns,columns=['Feature_Importances']).sort_values(by='Feature_Importances',ascending=False)","69bd7d29":"plt.figure(figsize=(8,8))\nranked_features=pd.Series(model.feature_importances_,index=df2.columns)\nranked_features.nlargest(25).plot(kind='barh')\nplt.show()","5660bdc4":"# Checking the correlation between primary and secondary accounts\nplt.figure(figsize=(12,8))\nsns.heatmap(df[['pri_no_of_accts','pri_active_accts','pri_overdue_accts','pri_current_balance','pri_sanctioned_amount',\n               'pri_disbursed_amount','primary_instal_amt','sec_no_of_accts','sec_active_accts','sec_overdue_accts',\n               'sec_current_balance','sec_sanctioned_amount','sec_disbursed_amount','sec_instal_amt']].corr(),annot=True)\nplt.show()","16c9c0b4":"# Combining the Primary and Secondary Accounts\n\ndf['no_of_accts'] = df['pri_no_of_accts'] + df['sec_no_of_accts']\ndf['active_accts'] = df['pri_active_accts'] + df['sec_active_accts']\ndf['overdue_accts'] = df['pri_overdue_accts'] + df['sec_overdue_accts']\ndf['outstanding_amount'] = df['pri_current_balance'] + df['sec_current_balance']\ndf['sanctioned_amount'] = df['pri_sanctioned_amount'] + df['sec_sanctioned_amount']\ndf['psdisbursed_amount'] = df['pri_disbursed_amount'] + df['sec_disbursed_amount']\ndf['install_amt'] = df['primary_instal_amt'] + df['sec_instal_amt']","0051c936":"df.drop(['pri_no_of_accts','sec_no_of_accts','pri_active_accts','sec_active_accts',\n        'pri_overdue_accts','sec_overdue_accts','pri_current_balance','sec_current_balance',\n        'pri_sanctioned_amount','sec_sanctioned_amount','pri_disbursed_amount','sec_disbursed_amount',\n        'primary_instal_amt','sec_instal_amt'],axis=1,inplace=True)","8da86de3":"# Account and amount description\n\ndf[['no_of_accts','active_accts','overdue_accts','outstanding_amount','sanctioned_amount','psdisbursed_amount','install_amt']].describe()","17e3f8ee":"df['no_of_accts'].describe()","a6447a4e":"na_non_default = df[df['loan_default']==0]['no_of_accts']\nna_default = df[df['loan_default']==1]['no_of_accts']","c3a49698":"pd.DataFrame([na_non_default.describe(), na_default.describe()], index=['non_defaulters','defaulters'])","711a0ff2":"counts = df['active_accts'].value_counts()\npercent = df['active_accts'].value_counts(normalize=True)*100\n\npd.DataFrame({'counts':counts,'percent_of_data':percent})","d7410fef":"counts = df['overdue_accts'].value_counts()\npercent = df['overdue_accts'].value_counts(normalize=True)*100\n\npd.DataFrame({'counts':counts,'percent_of_data':percent})","c468bbd1":"no_inquiries = pd.crosstab(index=df['overdue_accts'], columns=df['loan_default'])\nno_inquiries['pct_default'] = (no_inquiries[1]\/no_inquiries.sum(axis=1))*100\nno_inquiries","a6537e4d":"counts = df['outstanding_amount'].value_counts()\npercent = df['outstanding_amount'].value_counts(normalize=True)*100\n\npd.DataFrame({'counts':counts,'percent_of_data':percent})","2d264b3e":"counts = df['sanctioned_amount'].value_counts()\npercent = df['sanctioned_amount'].value_counts(normalize=True)*100\n\npd.DataFrame({'counts':counts,'percent_of_data':percent})","011b6531":"counts = df['psdisbursed_amount'].value_counts()\npercent = df['psdisbursed_amount'].value_counts(normalize=True)*100\n\npd.DataFrame({'counts':counts,'percent_of_data':percent})","8684b2c7":"counts = df['install_amt'].value_counts()\npercent = df['install_amt'].value_counts(normalize=True)*100\n\npd.DataFrame({'counts':counts,'percent_of_data':percent})","a171a6b6":"df3 = df[['disbursed_amount', 'asset_cost', 'ltv','perform_cns_score', 'new_accts_in_last_six_months',\n       'delinquent_accts_in_last_six_months', 'average_acct_age',\n       'credit_history_length', 'no_of_inquiries',\n       'age', 'risk', 'no_of_accts', 'active_accts',\n       'overdue_accts', 'outstanding_amount', 'sanctioned_amount',\n       'psdisbursed_amount', 'install_amt']]","9e64a1f0":"plt.figure(figsize=(20,15))\nsns.heatmap(df3.corr(),annot=True,cmap='Blues')\nplt.show()","5bea3302":"# Feature importance using Extra Trees classifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nimport matplotlib.pyplot as plt\nmodel=ExtraTreesClassifier()\nmodel.fit(df3,df['loan_default'])","9719d5cc":"pd.DataFrame(model.feature_importances_,index=df3.columns,columns=['Feature_Importances']).sort_values(by='Feature_Importances',ascending=False)","4c480cc2":"plt.figure(figsize=(8,8))\nranked_features=pd.Series(model.feature_importances_,index=df3.columns)\nranked_features.nlargest(18).plot(kind='barh')\nplt.show()","09a7c557":"df.drop(['asset_cost','perform_cns_score','average_acct_age','no_of_accts','psdisbursed_amount','delinquent_accts_in_last_six_months'],axis=1,inplace=True)","679a13a6":"df.head()","345bbea2":"df.shape","1107602d":"df.columns","8eb09fd7":"df12 = df[['disbursed_amount', 'ltv',\n       'new_accts_in_last_six_months',\n       'credit_history_length', 'no_of_inquiries',\n       'age', 'active_accts', 'overdue_accts',\n       'outstanding_amount', 'sanctioned_amount', 'install_amt']]","084e0c7f":"plt.figure(figsize=(20,20))\nx = 1\nfor column in df12.columns:\n    if x<=11:\n        plt.subplot(5,3,x)\n        sns.boxplot(df[column])\n    x+=1\nplt.show()","cdd64160":"sns.boxplot(df['disbursed_amount'])\nplt.show()","54e72c62":"#calculating 0-100th percentile to find a the correct percentile value for removal of outliers\nfor i in range(0,100,10):\n    var = df['disbursed_amount'].values\n    var = np.sort(var,axis = None)\n    print(\"{} percentile value is {}\".format(i,var[int(len(var)*(float(i)\/100))]))\nprint (\"100 percentile value is \",var[-1])","0475337c":"#looking further from the 99th percecntile\nfor i in range(90,100):\n    var = df['disbursed_amount'].values\n    var = np.sort(var,axis = None)\n    print(\"{} percentile value is {}\".format(i,var[int(len(var)*(float(i)\/100))]))\nprint (\"100 percentile value is \",var[-1])","f2b26bb1":"df = df[df['disbursed_amount']<max(df['disbursed_amount'])]","0fcfacbc":"df = df[df['new_accts_in_last_six_months']<25]\ndf = df[df['credit_history_length']<400]\ndf = df[df['no_of_inquiries']<25]\ndf = df[df['active_accts']<50]\ndf = df[df['sanctioned_amount']<max(df['sanctioned_amount'])]","124fd5ba":"sns.boxplot(df['outstanding_amount'])\nplt.show()","503aba7e":"#calculating 0-100th percentile to find a the correct percentile value for removal of outliers\nfor i in range(0,100,10):\n    var = df['outstanding_amount'].values\n    var = np.sort(var,axis = None)\n    print(\"{} percentile value is {}\".format(i,var[int(len(var)*(float(i)\/100))]))\nprint (\"100 percentile value is \",var[-1])","5ff319a7":"#looking further from the 99th percecntile\nfor i in range(90,100):\n    var = df['outstanding_amount'].values\n    var = np.sort(var,axis = None)\n    print(\"{} percentile value is {}\".format(i,var[int(len(var)*(float(i)\/100))]))\nprint (\"100 percentile value is \",var[-1])","e4ec0ba9":"df = df[(df['outstanding_amount']>-6678296) & (df['outstanding_amount']<75603400)]","21502e07":"sns.boxplot(df['install_amt'])\nplt.show()","1c259de6":"#calculating 0-100th percentile to find a the correct percentile value for removal of outliers\nfor i in range(0,100,10):\n    var = df['install_amt'].values\n    var = np.sort(var,axis = None)\n    print(\"{} percentile value is {}\".format(i,var[int(len(var)*(float(i)\/100))]))\nprint (\"100 percentile value is \",var[-1])","a804dd95":"#looking further from the 99th percecntile\nfor i in range(90,100):\n    var = df['install_amt'].values\n    var = np.sort(var,axis = None)\n    print(\"{} percentile value is {}\".format(i,var[int(len(var)*(float(i)\/100))]))\nprint (\"100 percentile value is \",var[-1])","4ca5ba47":"df = df[df['install_amt']<10000000]","db3f84ed":"# Checking the distributions again\n\nplt.figure(figsize=(20,20))\nx = 1\nfor column in df12.columns:\n    if x<=13:\n        plt.subplot(5,3,x)\n        sns.boxplot(df[column])\n    x+=1\nplt.show()","7d7ba5c4":"# Removing few more outliers\/extreme values\n\ndf = df[df['disbursed_amount']<250000]\ndf = df[df['outstanding_amount']<40000000]\ndf = df[df['sanctioned_amount']<0.800000e+08]\ndf = df[df['install_amt']<=5.000000e+06]","8b0e8295":"plt.figure(figsize=(20,20))\nx = 1\nfor column in df12.columns:\n    if x<=11:\n        plt.subplot(5,3,x)\n        sns.boxplot(df[column])\n    x+=1\nplt.show()","d9395014":"# Transforming the features outstanding amount, sanctioned amount and install_amt\ndf['log_outstanding_amount'] = np.log(df['outstanding_amount']+1-min(df['outstanding_amount']))\nsns.boxplot(df['log_outstanding_amount'])\nplt.show()","727f2749":"df['log_outstanding_amount'] = df[df['log_outstanding_amount']>12]\nsns.boxplot(df['log_outstanding_amount'])\nplt.show()","21592b7d":"df['log_outstanding_amount'].describe()","ddc7f772":"df.isnull().sum()","87408a0a":"df['log_outstanding_amount'] = df.fillna(df['log_outstanding_amount'].median())","a842b8dc":"df['log_sanctioned_amount'] = np.log(df['sanctioned_amount']+1)\nsns.boxplot(df['log_sanctioned_amount'])\nplt.show()","c9715e49":"df['log_install_amt'] = np.log(df['install_amt']+1)\nsns.boxplot(df['log_install_amt'])\nplt.show()","21ad3a73":"df.drop(['outstanding_amount','sanctioned_amount','install_amt'],axis=1,inplace=True)","5d5cdbeb":"df.shape","6bdc63e4":"df.columns","6e4820f7":"n = df.shape[0]\nsns.pairplot(df[['disbursed_amount', 'ltv','new_accts_in_last_six_months', \n                 'loan_default']][0:n], hue='loan_default', \n             vars=['disbursed_amount', 'ltv','new_accts_in_last_six_months'])\nplt.show()","1c39381d":"n = df.shape[0]\nsns.pairplot(df[['credit_history_length', 'no_of_inquiries',\n       'self_employed', 'age', 'risk','loan_default']][0:n], hue='loan_default', \n             vars=['credit_history_length', 'no_of_inquiries',\n       'self_employed', 'age', 'risk'])\nplt.show()","2941a35c":"n = df.shape[0]\nsns.pairplot(df[['active_accts', 'overdue_accts',\n       'log_outstanding_amount', 'log_sanctioned_amount', 'log_install_amt','loan_default']][0:n], hue='loan_default', \n             vars=['active_accts', 'overdue_accts',\n       'log_outstanding_amount', 'log_sanctioned_amount', 'log_install_amt'])\nplt.show()","0f54cd6f":"df.columns","a0edc622":"plt.figure(figsize=(12,8))\nsns.heatmap(df[['disbursed_amount', 'ltv','new_accts_in_last_six_months','credit_history_length','no_of_inquiries',\n               'age','risk','active_accts', 'overdue_accts', 'log_outstanding_amount','log_sanctioned_amount', \n                'log_install_amt']].corr(),annot=True)\nplt.show()","6bb5ec52":"df.drop('log_outstanding_amount',axis=1,inplace=True)","487d80e8":"df.shape","a7752a4c":"df.columns","fb1e7916":"y = df['loan_default']\nX = df.drop('loan_default',axis=1)","e99e45ae":"y = list(y)","ff2026b5":"# Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nXscaled = sc.fit_transform(X)\nXscaled = pd.DataFrame(Xscaled,columns=X.columns)","ebc60208":"import statsmodels.api as sm\nXc = sm.add_constant(Xscaled)\nmodel = sm.Logit(y, Xc).fit()\nmodel.summary()","4154b288":"from sklearn.metrics import confusion_matrix,roc_auc_score,log_loss,roc_curve,accuracy_score","93ab47b3":"y_pred = model.predict(Xc)\nprob = pd.DataFrame(y_pred, columns=['probability'])\nprob['loan_default'] = y\nprob['y_est'] = prob['probability'].apply(lambda x: 0 if x<0.5 else 1)\nprob.head()","cff7b95f":"# Confusion matrix\nconfusion_matrix(prob['loan_default'], prob['y_est'])","82b62394":"# AUC score\nroc_auc_score(prob['loan_default'],prob['probability'])","dbe07850":"# Checking for multicollinearity\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor as vif\nvf = [vif(Xscaled.values,i) for i in range(X.shape[1])]\npd.DataFrame(vf,index=X.columns,columns=['vif'])","0af77ddc":"# Building sklearn Linear Regression model\ny = df['loan_default']\nX = df.drop('loan_default',axis=1)","ef45275c":"# Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_scaled = sc.fit_transform(X)","ee55154f":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X_scaled,y,test_size=0.3,random_state=120)","5bc454f6":"from sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(solver='liblinear',random_state=42)\nlr.fit(X_train,y_train)","9b432cd3":"y_train_pred = lr.predict(X_train)\ny_test_pred = lr.predict(X_test)\ny_train_prob = lr.predict_proba(X_train)\ny_test_prob = lr.predict_proba(X_test)","f9779a1d":"print('The train AUC score is:',roc_auc_score(y_train,y_train_prob[:,1]))\nprint('The test AUC score is:',roc_auc_score(y_test,y_test_prob[:,1]))","44ecb8f5":"fpr, tpr, thresholds = roc_curve(y_test, y_test_prob[:,1])\nplt.plot(fpr,fpr)\nplt.plot(fpr,tpr)\nplt.grid()\nplt.title('Test ROC curve')\nplt.show()","c316a887":"confusion_matrix(y_test,y_test_pred)","dc2585db":"sns.heatmap(confusion_matrix(y_test,y_test_pred),annot=True)\nplt.show()","d4b2a8f9":"# FNs are too high, TPs are too low. Maybe Applying SMOTE and balancing the data might help.\nfrom sklearn.metrics import classification_report\nprint('Test Classification Report\\n')\nprint(classification_report(y_test,y_test_pred))","01d3fa5a":"# For 1s the f1 score is really low\n\n# Before computing the binary log loss, we need to perform caliberation\n\n# https:\/\/machinelearningmastery.com\/calibrated-classification-model-in-scikit-learn\/\n# https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.calibration.CalibratedClassifierCV.html\n\nfrom sklearn.calibration import CalibratedClassifierCV\nmodel_isotonic = CalibratedClassifierCV(lr, cv=3, method='isotonic')\nmodel_isotonic.fit(X_train,y_train)","059fa833":"isotonic_predict_prob_test = model_isotonic.predict_proba(X_test)","ea28f5d1":"log_loss(y_test,isotonic_predict_prob_test)","56cbc126":"from imblearn.over_sampling import SMOTE\nsmote = SMOTE()\nX_train_sm,y_train_sm = smote.fit_resample(X_train,y_train)\nX_train_sm.shape, y_train_sm.shape","65734573":"lr1 = LogisticRegression(solver='liblinear',random_state=42)\nlr1.fit(X_train_sm,y_train_sm)","d51fe070":"y_train_pred = lr1.predict(X_train_sm)\ny_test_pred = lr1.predict(X_test)\ny_train_prob = lr1.predict_proba(X_train_sm)\ny_test_prob = lr1.predict_proba(X_test)","acb26afa":"print('The train AUC score is:',roc_auc_score(y_train_sm,y_train_prob[:,1]))\nprint('The test AUC score is:',roc_auc_score(y_test,y_test_prob[:,1]))","0d1a547e":"fpr, tpr, thresholds = roc_curve(y_test, y_test_prob[:,1])\nplt.plot(fpr,fpr)\nplt.plot(fpr,tpr)\nplt.grid()\nplt.title('Test ROC curve')\nplt.show()","3abf325f":"confusion_matrix(y_test,y_test_pred)","ec617e4c":"sns.heatmap(confusion_matrix(y_test,y_test_pred),annot=True)\nplt.show()","6a81b82a":"from sklearn.metrics import classification_report\nprint('Test Classification Report\\n')\nprint(classification_report(y_test,y_test_pred))","a36ea8b1":"from sklearn.calibration import CalibratedClassifierCV\nmodel_isotonic = CalibratedClassifierCV(lr1, cv=3, method='isotonic')\nmodel_isotonic.fit(X_train_sm,y_train_sm)","55804223":"isotonic_predict_prob_test = model_isotonic.predict_proba(X_test)","03242066":"log_loss(y_test,isotonic_predict_prob_test)","736aa937":"rsearch1_best_params = {'max_depth': 13,\n 'min_samples_leaf': 10,\n 'min_samples_split': 11,\n 'n_estimators': 374}","bdadaeac":"from sklearn.ensemble import RandomForestClassifier\nrfc1 = RandomForestClassifier(**rsearch1_best_params, random_state=300)\nrfc1.fit(X_train, y_train)","f24c0bc9":"y_train_pred = rfc1.predict(X_train)\ny_test_pred = rfc1.predict(X_test)\ny_train_prob = rfc1.predict_proba(X_train)\ny_test_prob = rfc1.predict_proba(X_test)","0b1ce42f":"print('The train AUC score is:',roc_auc_score(y_train,y_train_prob[:,1]))\nprint('The test AUC score is:',roc_auc_score(y_test,y_test_prob[:,1]))","4ff8a94f":"fpr, tpr, thresholds = roc_curve(y_test, y_test_prob[:,1])\nplt.plot(fpr,fpr)\nplt.plot(fpr,tpr)\nplt.grid()\nplt.title('Test ROC curve')\nplt.show()","38a64a06":"confusion_matrix(y_test,y_test_pred)","e1962f7d":"sns.heatmap(confusion_matrix(y_test,y_test_pred),annot=True)\nplt.show()","4736bd12":"from sklearn.metrics import classification_report\nprint('Test Classification Report\\n')\nprint(classification_report(y_test,y_test_pred))","ead04c23":"from sklearn.calibration import CalibratedClassifierCV\nmodel_isotonic = CalibratedClassifierCV(rfc1, cv=3, method='isotonic')\nmodel_isotonic.fit(X_train,y_train)","31b99d6c":"isotonic_predict_prob_test = model_isotonic.predict_proba(X_test)\nlog_loss(y_test,isotonic_predict_prob_test)","397fcda1":"rsearch_best_params = {'max_depth': 17,\n 'min_samples_leaf': 2,\n 'min_samples_split': 4,\n 'n_estimators': 317}","d85a6124":"rfc = RandomForestClassifier(**rsearch_best_params, random_state=300)\nrfc.fit(X_train_sm, y_train_sm)","f79b628c":"y_train_pred = rfc.predict(X_train_sm)\ny_test_pred = rfc.predict(X_test)\ny_train_prob = rfc.predict_proba(X_train_sm)\ny_test_prob = rfc.predict_proba(X_test)","33030539":"print('The train AUC score is:',roc_auc_score(y_train_sm,y_train_prob[:,1]))\nprint('The test AUC score is:',roc_auc_score(y_test,y_test_prob[:,1]))","c62b725a":"fpr, tpr, thresholds = roc_curve(y_test, y_test_prob[:,1])\nplt.plot(fpr,fpr)\nplt.plot(fpr,tpr)\nplt.grid()\nplt.title('Test ROC curve')\nplt.show()","8634e166":"confusion_matrix(y_test,y_test_pred)","f28ef9a8":"sns.heatmap(confusion_matrix(y_test,y_test_pred),annot=True)\nplt.show()","611eddbe":"from sklearn.metrics import classification_report\nprint('Test Classification Report\\n')\nprint(classification_report(y_test,y_test_pred))","2da6c617":"from sklearn.calibration import CalibratedClassifierCV\nmodel_isotonic = CalibratedClassifierCV(rfc, cv=3, method='isotonic')\nmodel_isotonic.fit(X_train_sm,y_train_sm)","741ecdc4":"isotonic_predict_prob_test = model_isotonic.predict_proba(X_test)\nlog_loss(y_test,isotonic_predict_prob_test)","ef588be8":"import lightgbm as lgb","50ff5558":"rsearch1_best_params = {'learning_rate': 0.10308835171850986,\n 'max_depth': 3,\n 'n_estimators': 275,\n 'num_leaves': 18}","56bf0fc5":"lgbmc1 = lgb.LGBMClassifier(**rsearch1_best_params, importance_type='gain',random_state=300)\nlgbmc1.fit(X_train, y_train)","7c4ee373":"y_train_pred = lgbmc1.predict(X_train)\ny_test_pred = lgbmc1.predict(X_test)\ny_train_prob = lgbmc1.predict_proba(X_train)\ny_test_prob = lgbmc1.predict_proba(X_test)","d1abb46a":"print('The train AUC score is:',roc_auc_score(y_train,y_train_prob[:,1]))\nprint('The test AUC score is:',roc_auc_score(y_test,y_test_prob[:,1]))","f5d1fd77":"fpr, tpr, thresholds = roc_curve(y_test, y_test_prob[:,1])\nplt.plot(fpr,fpr)\nplt.plot(fpr,tpr)\nplt.grid()\nplt.title('Test ROC curve')\nplt.show()","d6e76d1a":"confusion_matrix(y_test,y_test_pred)","b9777ca7":"sns.heatmap(confusion_matrix(y_test,y_test_pred),annot=True)\nplt.show()","28f05cb2":"from sklearn.metrics import classification_report\nprint('Test Classification Report\\n')\nprint(classification_report(y_test,y_test_pred))","7c5286d4":"from sklearn.calibration import CalibratedClassifierCV\nmodel_isotonic = CalibratedClassifierCV(lgbmc1, cv=3, method='isotonic')\nmodel_isotonic.fit(X_train,y_train)","5fabce7d":"isotonic_predict_prob_test = model_isotonic.predict_proba(X_test)\nlog_loss(y_test,isotonic_predict_prob_test)","aa7abaef":"rsearch_best_params = {'learning_rate': 0.32585614358745185,\n 'max_depth': 12,\n 'n_estimators': 540,\n 'num_leaves': 31}","00548f64":"lgbmc = lgb.LGBMClassifier(**rsearch_best_params, importance_type='gain',random_state=300)\nlgbmc.fit(X_train_sm, y_train_sm)","5a36acf5":"y_train_pred = lgbmc.predict(X_train_sm)\ny_test_pred = lgbmc.predict(X_test)\ny_train_prob = lgbmc.predict_proba(X_train_sm)\ny_test_prob = lgbmc.predict_proba(X_test)","0faff8e1":"print('The train AUC score is:',roc_auc_score(y_train_sm,y_train_prob[:,1]))\nprint('The test AUC score is:',roc_auc_score(y_test,y_test_prob[:,1]))","bc6b3437":"fpr, tpr, thresholds = roc_curve(y_test, y_test_prob[:,1])\nplt.plot(fpr,fpr)\nplt.plot(fpr,tpr)\nplt.grid()\nplt.title('Test ROC curve')\nplt.show()","b1cfcc11":"confusion_matrix(y_test,y_test_pred)","b1dacc44":"sns.heatmap(confusion_matrix(y_test,y_test_pred),annot=True)\nplt.show()","48898418":"from sklearn.metrics import classification_report\nprint('Test Classification Report\\n')\nprint(classification_report(y_test,y_test_pred))","2497b14c":"from sklearn.calibration import CalibratedClassifierCV\nmodel_isotonic = CalibratedClassifierCV(lgbmc, cv=3, method='isotonic')\nmodel_isotonic.fit(X_train_sm,y_train_sm)","6a134ba8":"isotonic_predict_prob_test = model_isotonic.predict_proba(X_test)\nlog_loss(y_test,isotonic_predict_prob_test)","cc5400e9":"import xgboost\nfrom xgboost import XGBClassifier\nrsearch1_best_params = {'eval_metric': 'auc',\n 'gamma': 0.3,\n 'learning_rate': 0.1,\n 'max_depth': 3,\n 'n_estimators': 270,\n 'reg_alpha': 0.01}","b22ec4be":"xgbc1 = XGBClassifier(**rsearch1_best_params, random_state=300)\nxgbc1.fit(X_train, y_train)","e77eb08e":"y_train_pred = xgbc1.predict(X_train)\ny_test_pred = xgbc1.predict(X_test)\ny_train_prob = xgbc1.predict_proba(X_train)\ny_test_prob = xgbc1.predict_proba(X_test)","8594fd49":"print('The train AUC score is:',roc_auc_score(y_train,y_train_prob[:,1]))\nprint('The test AUC score is:',roc_auc_score(y_test,y_test_prob[:,1]))","a7a03258":"fpr, tpr, thresholds = roc_curve(y_test, y_test_prob[:,1])\nplt.plot(fpr,fpr)\nplt.plot(fpr,tpr)\nplt.grid()\nplt.title('Test ROC curve')\nplt.show()","78a337c4":"confusion_matrix(y_test,y_test_pred)","8e1282e9":"sns.heatmap(confusion_matrix(y_test,y_test_pred),annot=True)\nplt.show()","5bf37354":"from sklearn.metrics import classification_report\nprint('Test Classification Report\\n')\nprint(classification_report(y_test,y_test_pred))","10c9e68b":"from sklearn.calibration import CalibratedClassifierCV\nmodel_isotonic = CalibratedClassifierCV(xgbc1, cv=3, method='isotonic')\nmodel_isotonic.fit(X_train,y_train)","e75128a3":"isotonic_predict_prob_test = model_isotonic.predict_proba(X_test)\nlog_loss(y_test,isotonic_predict_prob_test)","55a4d39c":"rsearch_best_params = {'eval_metric': 'auc',\n 'gamma': 0.2,\n 'learning_rate': 0.2,\n 'max_depth': 9,\n 'n_estimators': 192,\n 'reg_alpha': 0.1}","750f794f":"xgbc = XGBClassifier(**rsearch_best_params, random_state=300)\nxgbc.fit(X_train_sm, y_train_sm)","2bc1bb8d":"y_train_pred = xgbc.predict(X_train_sm)\ny_test_pred = xgbc.predict(X_test)\ny_train_prob = xgbc.predict_proba(X_train_sm)\ny_test_prob = xgbc.predict_proba(X_test)","76034bbe":"print('The train AUC score is:',roc_auc_score(y_train_sm,y_train_prob[:,1]))\nprint('The test AUC score is:',roc_auc_score(y_test,y_test_prob[:,1]))","45a28538":"fpr, tpr, thresholds = roc_curve(y_test, y_test_prob[:,1])\nplt.plot(fpr,fpr)\nplt.plot(fpr,tpr)\nplt.grid()\nplt.title('Test ROC curve')\nplt.show()","96bd8fe7":"confusion_matrix(y_test,y_test_pred)","e67a9cbd":"sns.heatmap(confusion_matrix(y_test,y_test_pred),annot=True)\nplt.show()","7b140859":"from sklearn.metrics import classification_report\nprint('Test Classification Report\\n')\nprint(classification_report(y_test,y_test_pred))","5c07c066":"from sklearn.calibration import CalibratedClassifierCV\nmodel_isotonic = CalibratedClassifierCV(xgbc, cv=3, method='isotonic')\nmodel_isotonic.fit(X_train_sm,y_train_sm)","51a042d0":"isotonic_predict_prob_test = model_isotonic.predict_proba(X_test)\nlog_loss(y_test,isotonic_predict_prob_test)","72e35cc6":"from sklearn.ensemble import StackingClassifier\nestimators = [\n('rfc',RandomForestClassifier(max_depth = 13,\n min_samples_leaf = 10,\n min_samples_split = 11,\n n_estimators = 374)),\n \n('lgbmc',lgb.LGBMClassifier(learning_rate = 0.10308835171850986,\n max_depth = 3,\n n_estimators = 275,\n num_leaves = 18)),\n \n('xgbc', XGBClassifier(eval_metric = 'auc',\n gamma = 0.3,\n learning_rate = 0.1,\n max_depth = 3,\n n_estimators = 270,\n reg_alpha = 0.01))\n]\n","d237030f":"clf1 = StackingClassifier(estimators=estimators,final_estimator=LogisticRegression(solver='liblinear'),\n                        cv = 5, n_jobs=-1)\nclf1.fit(X_train,y_train)","c290e37e":"y_train_pred = clf1.predict(X_train)\ny_test_pred = clf1.predict(X_test)\ny_train_prob = clf1.predict_proba(X_train)\ny_test_prob = clf1.predict_proba(X_test)","d46b31ca":"print('The train AUC score is:',roc_auc_score(y_train,y_train_prob[:,1]))\nprint('The test AUC score is:',roc_auc_score(y_test,y_test_prob[:,1]))","4c02b33f":"fpr, tpr, thresholds = roc_curve(y_test, y_test_prob[:,1])\nplt.plot(fpr,fpr)\nplt.plot(fpr,tpr)\nplt.grid()\nplt.title('Test ROC curve')\nplt.show()","40fb8536":"confusion_matrix(y_test,y_test_pred)","ef234456":"sns.heatmap(confusion_matrix(y_test,y_test_pred),annot=True)\nplt.show()","c273a649":"from sklearn.metrics import classification_report\nprint('Test Classification Report\\n')\nprint(classification_report(y_test,y_test_pred))","3f0a51f4":"from sklearn.calibration import CalibratedClassifierCV\nmodel_isotonic = CalibratedClassifierCV(clf1, cv=3, method='isotonic')\nmodel_isotonic.fit(X_train,y_train)","e64ce61f":"isotonic_predict_prob_test = model_isotonic.predict_proba(X_test)\nlog_loss(y_test,isotonic_predict_prob_test)","f512fc19":"from sklearn.ensemble import StackingClassifier\nestimators = [\n('rfc',RandomForestClassifier(max_depth = 17,\n min_samples_leaf = 2,\n min_samples_split = 4,\n n_estimators = 317)),\n \n('lgbmc',lgb.LGBMClassifier(learning_rate = 0.32585614358745185,\n max_depth = 12,\n n_estimators = 540,\n num_leaves = 31)),\n \n('xgbc', XGBClassifier(eval_metric = 'auc',\n gamma = 0.2,\n learning_rate = 0.2,\n max_depth = 9,\n n_estimators = 192,\n reg_alpha = 0.1))\n]","b067b241":"clf = StackingClassifier(estimators=estimators,final_estimator=LogisticRegression(solver='liblinear'),\n                        cv = 5, n_jobs=-1)\nclf.fit(X_train_sm,y_train_sm)","27aac2fd":"y_train_pred = clf.predict(X_train_sm)\ny_test_pred = clf.predict(X_test)\ny_train_prob = clf.predict_proba(X_train_sm)\ny_test_prob = clf.predict_proba(X_test)","7f2777a1":"print('The train AUC score is:',roc_auc_score(y_train_sm,y_train_prob[:,1]))\nprint('The test AUC score is:',roc_auc_score(y_test,y_test_prob[:,1]))","7eba8a47":"fpr, tpr, thresholds = roc_curve(y_test, y_test_prob[:,1])\nplt.plot(fpr,fpr)\nplt.plot(fpr,tpr)\nplt.grid()\nplt.title('Test ROC curve')\nplt.show()","8704a776":"confusion_matrix(y_test,y_test_pred)","0160d2cb":"sns.heatmap(confusion_matrix(y_test,y_test_pred),annot=True)\nplt.show()","06ca8102":"from sklearn.metrics import classification_report\nprint('Test Classification Report\\n')\nprint(classification_report(y_test,y_test_pred))","aab17c94":"from sklearn.calibration import CalibratedClassifierCV\nmodel_isotonic = CalibratedClassifierCV(clf, cv=3, method='isotonic')\nmodel_isotonic.fit(X_train_sm,y_train_sm)","2f92cea6":"isotonic_predict_prob_test = model_isotonic.predict_proba(X_test)\nlog_loss(y_test,isotonic_predict_prob_test)","f821b97c":"# http:\/\/zetcode.com\/python\/prettytable\/\nfrom prettytable import PrettyTable\n\nx = PrettyTable()\nx.field_names = [\"Model\",\"Train-AUC\",\"Test-AUC\",\"Test-Binary_Log_Loss\",\"F1-Score(1)\",\"SMOTE-applied\"]\n\nx.add_row([\"Logistic Regression\", 0.623, 0.623, 0.509, 0.01,'No'])\nx.add_row([\"Logistic Regression\", 0.624, 0.623, 0.670, 0.39,'Yes'])\nx.add_row([\"Random Forest Classifier\", 0.727, 0.637, 0.503, 0.00,'No'])\nx.add_row([\"Random Forest Classifier\", 0.855, 0.625, 0.614, 0.38,'Yes'])\nx.add_row([\"LightGBM Classifier\", 0.652, 0.639, 0.503, 0.01,'No'])\nx.add_row([\"LightGBM Classifier\", 0.928, 0.601, 0.527, 0.22,'Yes'])\nx.add_row([\"XGBoost Classifier\", 0.652, 0.638, 0.503, 0.01,'No'])\nx.add_row([\"XGBoost Classifier\", 0.936, 0.610, 0.523, 0.20,'Yes'])\nx.add_row([\"Stacked Classifier\", 0.690, 0.639, 0.503, 0.03,'No'])\nx.add_row([\"Stacked Classifier\", 0.936, 0.618, 0.523, 0.29,'Yes'])\n\n\nprint(x)","e1c949cb":"## Outstanding Amount","f63f1eeb":"The maximum disbursed amount is way higher for non-defaulters.","0f0e3b25":"The distribution is highly right skewed and there are extreme values","43bf5d81":"## Average Account Age and Credit History Length","bed35123":"**Since we have to accurately predict the probability of loanee\/borrower defaulting on a vehicle loan in the first EMI on the due date, along with AUC-ROC score, have taken F1-score(1s) and binary log loss as the performance metrics.**","de23196b":"We can see that as the risk increases, the percent of default also increases","e1632e34":"## Perform cns score description","79525ff1":"## Instalment Amount","429a554b":"## Perform CNS score \/ CIBIL score","f19b3d2f":"More outliers\/extreme values are present for non defaulters","43fd26d9":"## New accounts in last six months","c8a9f569":"**Feature importances of different numerical features**","8631b4a5":"Around 60 percent of data do not have any outstanding amount","60f269b7":"All the hyperparameters are tuned and are same as used before for individual modelling","e9a24c86":"## LightGBM","747c28a6":"The maximum asset cost of non defaulters is way higher than that of defaulters","40be1c45":"The ltv is almost same for both defaulters and non defaulters","eadfc1e4":"### Modelling without SMOTE","b193fae0":"The Age at the time of loan disbursement is almost similar among defaulters and non defaulters","bc44a063":"## Aadhar","770b6774":"Around 68 percent of data do not have any installment amount to pay","e68fff1a":"There are over 50 percent inactive accounts. Around 18 percent have 1 active account present","0ed22248":"## Checking and Handling outliers","03da4d01":"Highly right skewed","a3e67c10":"## No of Inquiries","93ed5f25":"From the above correlation heatmap, we can see that some of the features are highly correlated(>0.75) with each other.\n* --- disbursed amount and asset cost - 0.75\n* --- perform_cns.score and risk - 0.98\n* --- average_acct_age and credit_history_length - 0.83\n* --- no_of_accts and active_accts - 0.76\n* --- sanctioned_amount and psdisbursed_amount - 1","c8f3a74b":"## Passport","60988aa0":"## Primary and Secondary Accounts","52c44d69":"## Asset Cost","199615e9":"The distribution is highly right skewed and there are extreme values.","e4e287a4":"**78.3% observations in the dataset have not defaulted vehicle loan while 21.7% have defaulted loan. It is slighly imbalanced dataset.**","e848b5a1":"The mean and std is slightly higher for non defaulters","af82f48e":"### Modelling without SMOTE","f29406c3":"### Modelling with SMOTE","3da261bd":"Here, except for few cases, as the number of enquires increase, there is an increase in the pct of default.","1ce1ec24":"The maximum average account age is higher for non defaulters","ab7c0a57":"All the stats of age are almost same for defaulters and non defaulters","cbb31bf7":"Hyperparameter tuning is done using Random Search CV and best parameters are obtained and used for the modelling","aa9445d6":"### Modelling without SMOTE","67b38d55":"We can see that the mean and median cibil scores of non defaulters is sligtly higher than that of defaulters. Also the 75th percentile value of cibil score is higher for defaulters. The max score is nearly same for defaulters and non defaulters","2003fc6e":"We can see that 92% of customers have not defaulted loans in last six months. 8% of customers have deafulted loans for >= 1 time","8328a98a":"Most of the accounts are not overdue. Around 9 percent of data contain 1 overdue account, and around 2 percent of data contain 2 overdue accounts","bb386509":"For 58 percent of all accounts, no amount was disbursed for all the loans at the time of disbursement","8cb1c1e5":"**Pairplot**","f46d7d91":"There is a correlation of 1 between disbursed amount and log_outstanding_amount. Hence removing the log_outstanding_amount feature after comparing the feature importances","376976d0":"CIBIL score distribution is looking almost similar for defaulters and non defaulters","3df8aae3":"## Total number of accounts","a3da93d4":"# Categorical Features Analysis","7af6d1dd":"Inference:\nThe given problem statement requires us to determine the probability of loanee\/borrower defaulting on a vehicle loan in the first EMI (Equated Monthly Instalments) on the due date. Hence along with the prediction of whether a person is a defautee\/not a defaultee, we also need to predict the probability that a person might default the loan.\n\nHence to measure the performance of models, we have taken AUC-score, F1-score of 1's and Binary Log Loss as the performance metrics.\n\nWithout application of SMOTE, all the models are giving way less F1-score(1s). By the application of SMOTE this issue is cleared(Though the f1-scores can be controlled by selecting the appropriate threshold from the ROC curve).\n\nBy looking at the above table containing the performance metrics of various models, we can clearly say that Logistic Regression with SMOTE is performing really well, as compared to other models. It is giving a good AUC scores(not overfitting), and best F1-Score(1). Though the Binary log loss is a bit higher when compared to other models.\n\nThe next best model is Random Forest Classifier with SMOTE. Compared to Logistic Regression, it is overfitting a seen from AUC scores. However, it also shows good F1-score(1), slightly lower than Logistic Regression. It has a better(lower) binary log loss, when compared to Logistic Regression.\n\nApart from these, we have used LightGBM Classifier, XGBoost Classifier and a Stacked Classifier and their performance metrics are displayed in the pretty table above.","93883214":"## Delinquent Accounts in last six months","b65d7d75":"Upto 5 overdue accounts, we can see that as the number of overdue accounts increase, the percentage of default also increase. However we do not observe the same pattern\/any pattern beyond 5 overdue accounts","f13e3348":"### Modelling without SMOTE","1b8266a6":"Most of the customers have not made any enquiries regarding loans","93116062":"## Disbursed Amount","c573ace7":"## Active Accounts","e0f3ba8f":"**Using SMOTE to handle imbalance**","c3760a4b":"We can see that the percent of defaulters are less for low risk and very low risk categories.","f199f4c9":"There is no correlation between primary and secondary accounts","09ba3dbf":"## Age","0ed4eff3":"## Sanctioned Amount","9ca9fc55":"## Voter ID","220a7bc5":"# Modelling","f7b5d611":"## Logistic Regression","e8ec1737":"## Random Forest Classifier","2306e944":"It is highly right skewed","ea761656":"## XGBoost","dec49d2a":"## Psdisbursed Amount","6c9a92c2":"**Feature importances of above numerical features**","ff2c396e":"## Credit History Length","dfabe8ce":"### Modelling with SMOTE","65acfce0":"# Dependent variable distribution","5ec80b7d":"## PAN","b34f741f":"## Summary stats of all Models","4ec569b0":"**Feature importances of different categorical features**","9cb0f775":"## Employment_Type","0fddbf00":"We cannot drop the secondary account details as they are asked by the institutions before granting loan.","2cbb9bc9":"### Modelling with SMOTE","b2b99a1c":"Most of them have not opened any new account in the last 6 months","4df43dff":"## Stacking","5cfd8b29":"## Overdue Accounts","a0ff6394":"## Ltv","32d2bd97":"# Numerical Features Analysis","9e8c386c":"Here we can observe a difference in the mean and median cibil scores among the defaulters and non defaulters. The mean and median cibil scores are higher for non defaulters.","84a6f862":"### Modelling with SMOTE","e2098e73":"For around 58 percent of the accounts, no amount was sanctioned for all the loans at the time of disbursement","bae2410f":"## DL","30248371":"Extreme\/outlier values of asset_cost are present among non defaulters"}}