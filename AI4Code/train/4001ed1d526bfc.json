{"cell_type":{"c490a551":"code","8dfdd353":"code","6d91f2a0":"code","98fb5cc8":"code","0a6d6431":"code","9b11a97b":"code","ad28beae":"code","05396a76":"code","15f0ec55":"code","d85adb9a":"code","6596ed2d":"code","78ea296b":"code","40e0ed99":"code","b9af2f34":"code","6eed42b4":"code","4e356e46":"code","e2ce1531":"code","30f2b217":"code","6118b7ba":"code","936e93ed":"code","aa381672":"code","0d288283":"code","a1a0aaa6":"code","739de376":"code","007a74fb":"code","78cdacb1":"code","39c341e5":"code","a4bbcf54":"code","e2bb1f61":"code","cfc1a73b":"code","38f57862":"code","2fc0dfe8":"code","d4c76ac9":"code","c5f82a22":"code","33177e95":"code","f9c31b57":"code","914c1b84":"code","1498d7be":"code","9df4f960":"code","faa04cfc":"code","0e8e93a5":"code","59bff318":"code","3f95419d":"code","20312520":"code","b673afce":"code","970bc912":"code","f50a18e8":"code","99bf7f82":"code","625c939c":"code","222cdd0a":"code","f1f2a75a":"code","a9fc20bf":"markdown","7cfa78aa":"markdown","b4050dd3":"markdown","e4b686df":"markdown","407f0057":"markdown","a6980fa4":"markdown","907a50c9":"markdown","cdf8deac":"markdown","2f50569c":"markdown","0421031a":"markdown","8226356e":"markdown","60523baf":"markdown","5bb2eef2":"markdown","501bb6c5":"markdown","08894fe0":"markdown","16c6b2d9":"markdown","527c5c10":"markdown","cdd8b7ae":"markdown","9d1154aa":"markdown","471d9bbb":"markdown","7b3f10b9":"markdown","ca4c8762":"markdown","d633fff2":"markdown","b4799026":"markdown","09809f44":"markdown","2f180db5":"markdown","d0737285":"markdown","09bca756":"markdown","47d0363e":"markdown","b7401ed0":"markdown","3a24fe5e":"markdown","eab72cdb":"markdown"},"source":{"c490a551":"import tensorflow as tf\ntf.__version__","8dfdd353":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mimg\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.metrics import confusion_matrix\n\nimport cv2\nimport os\nimport glob\n\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\nfrom PIL import Image\nfrom pathlib import Path\nfrom skimage.io import imread\nfrom skimage.transform import resize\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, SeparableConv2D\nfrom tensorflow.keras.layers import GlobalMaxPooling2D, Flatten, Dropout\nfrom tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam, RMSprop, SGD","6d91f2a0":"# Input data files are available in the \"..\/input\/\" directory.\nINPUT_PATH = \"..\/input\/pneumonia-detection\/chest_xray\"\n\n# List the files in the input directory.\nprint(os.listdir(INPUT_PATH))","98fb5cc8":"# list of all the training images\ntrain_normal = Path(INPUT_PATH + '\/train\/NORMAL').glob('*.jpeg')\ntrain_pneumonia = Path(INPUT_PATH + '\/train\/PNEUMONIA').glob('*.jpeg')\n\n# ---------------------------------------------------------------\n# Train data format in (img_path, label) \n# Labels for [ the normal cases = 0 ] & [the pneumonia cases = 1]\n# ---------------------------------------------------------------\nnormal_data = [(image, 0) for image in train_normal]\npneumonia_data = [(image, 1) for image in train_pneumonia]\n\ntrain_data = normal_data + pneumonia_data\n\n# Get a pandas dataframe from the data we have in our list \ntrain_data = pd.DataFrame(train_data, columns=['image', 'label'])\n\n# Checking the dataframe...\ntrain_data.head()","0a6d6431":"# Checking the dataframe...\ntrain_data.tail()","9b11a97b":"# Shuffle the data \ntrain_data = train_data.sample(frac=1., random_state=100).reset_index(drop=True)\n\n# Checking the dataframe...\ntrain_data.head(10)","ad28beae":"print(train_data)","05396a76":"# Counts for both classes\ncount_result = train_data['label'].value_counts()\nprint('Total of Train Data : ', len(train_data), '  (0 : Normal; 1 : Pneumonia)')\nprint(count_result)\n\n# Plot the results \nplt.figure(figsize=(8,5))\nsns.countplot(x = 'label', data =  train_data)\nplt.title('Number of classes', fontsize=16)\nplt.xlabel('Class type', fontsize=14)\nplt.ylabel('Count', fontsize=14)\nplt.xticks(range(len(count_result.index)), \n           ['Normal : 0', 'Pneumonia : 1'], \n           fontsize=14)\nplt.show()","15f0ec55":"fig, ax = plt.subplots(3, 4, figsize=(20,15))\nfor i, axi in enumerate(ax.flat):\n    image = imread(train_data.image[i])\n    axi.imshow(image, cmap='bone')\n    axi.set_title(('Normal' if train_data.label[i] == 0 else 'Pneumonia') \n                  + '  [size=' + str(image.shape) +']',\n                  fontsize=14)\n    axi.set(xticks=[], yticks=[])","d85adb9a":"train_data.to_numpy().shape","6596ed2d":"# ----------------------------------------------------------------------\n#  Loading X-ray Images datasets from file 3 directories, respectively. \n# ----------------------------------------------------------------------\ndef load_data(files_dir='\/train'):\n    # list of the paths of all the image files\n    normal = Path(INPUT_PATH + files_dir + '\/NORMAL').glob('*.jpeg')\n    pneumonia = Path(INPUT_PATH + files_dir + '\/PNEUMONIA').glob('*.jpeg')\n\n    # --------------------------------------------------------------\n    # Data-paths' format in (img_path, label) \n    # labels : for [ Normal cases = 0 ] & [ Pneumonia cases = 1 ]\n    # --------------------------------------------------------------\n    normal_data = [(image, 0) for image in normal]\n    pneumonia_data = [(image, 1) for image in pneumonia]\n\n    image_data = normal_data + pneumonia_data\n\n    # Get a pandas dataframe for the data paths \n    image_data = pd.DataFrame(image_data, columns=['image', 'label'])\n    \n    # Shuffle the data \n    image_data = image_data.sample(frac=1., random_state=100).reset_index(drop=True)\n    \n    # Importing both image & label datasets...\n    x_images, y_labels = ([data_input(image_data.iloc[i][:]) for i in range(len(image_data))], \n                         [image_data.iloc[i][1] for i in range(len(image_data))])\n\n    # Convert the list into numpy arrays\n    x_images = np.array(x_images)\n    y_labels = np.array(y_labels)\n    \n    print(\"Total number of images: \", x_images.shape)\n    print(\"Total number of labels: \", y_labels.shape)\n    \n    return x_images, y_labels","78ea296b":"# ---------------------------------------------------------\n#  1. Resizing all the images to 224x224 with 3 channels.\n#  2. Then, normalize the pixel values.  \n# ---------------------------------------------------------\ndef data_input(dataset):\n    # print(dataset.shape)\n    for image_file in dataset:\n        image = cv2.imread(str(image_file))\n        image = cv2.resize(image, (224,224))\n        if image.shape[2] == 1:\n            # np.dstack(): Stack arrays in sequence depth-wise \n            #              (along third axis).\n            # https:\/\/docs.scipy.org\/doc\/numpy\/reference\/generated\/numpy.dstack.html\n            image = np.dstack([image, image, image])\n        \n        # ----------------------------------------------------------\n        # cv2.cvtColor(): The function converts an input image \n        #                 from one color space to another. \n        # [Ref.1]: \"cvtColor - OpenCV Documentation\"\n        #     - https:\/\/docs.opencv.org\/2.4\/modules\/imgproc\/doc\/miscellaneous_transformations.html\n        # [Ref.2]: \"Python\u8ba1\u7b97\u673a\u89c6\u89c9\u7f16\u7a0b- \u7b2c\u5341\u7ae0 OpenCV\" \n        #     - https:\/\/yongyuan.name\/pcvwithpython\/chapter10.html\n        # ----------------------------------------------------------\n        x_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        # Normalization\n        x_image = x_image.astype(np.float32)\/255.\n        return x_image","40e0ed99":"# Import train dataset...\nx_train, y_train = load_data(files_dir='\/train')\n\nprint(x_train.shape)\nprint(y_train.shape)","b9af2f34":"x_train[0].shape","6eed42b4":"x_train[0]","4e356e46":"y_train","e2ce1531":"# Import validation dataset...\nx_val, y_val = load_data(files_dir='\/val')\n\nprint(x_val.shape)\nprint(y_val.shape)","30f2b217":"y_val","6118b7ba":"# Import test dataset...\nx_test, y_test = load_data(files_dir='\/test')\n\nprint(x_test.shape)\nprint(y_test.shape)","936e93ed":"# Counts for both classes\ncount_result = pd.Series(y_test).value_counts()\nprint('Total of Test Data : ', len(y_test), '  (0 : Normal; 1 : Pneumonia)')\nprint('------------------')\nprint(count_result)\nprint('------------------')\nprint('1 :  ', count_result[1]\/sum(count_result))\nprint('0 :  ', count_result[0]\/sum(count_result))","aa381672":"y_test[:10]","0d288283":"model = Sequential([\n    Conv2D(32, (5,5), activation='relu', padding='same', \n           input_shape=(224,224,3), name='Conv1_1'),\n    BatchNormalization(name='bn1_1'),\n    Conv2D(32, (5,5), activation='relu', padding='same', name='Conv1_2'),\n    BatchNormalization(name='bn1_2'),\n    Conv2D(32, (5,5), activation='relu', padding='same', name='Conv1_3'),\n    BatchNormalization(name='bn1_3'),\n    MaxPooling2D((2,2), name='MaxPool1'),\n    Dropout(0.25),\n    \n    Conv2D(48, (3,3), activation='relu', padding='same', name='Conv2_1'),\n    BatchNormalization(name='bn2_1'),\n    Conv2D(48, (3,3), activation='relu', padding='same', name='Conv2_2'),\n    BatchNormalization(name='bn2_2'),\n    Conv2D(48, (3,3), activation='relu', padding='same', name='Conv2_3'),\n    BatchNormalization(name='bn2_3'),    \n    MaxPooling2D((2,2), name='MaxPool2'),\n    Dropout(0.25),\n\n    Conv2D(64, (3,3), activation='relu', padding='same', name='Conv3_1'),\n    BatchNormalization(name='bn3_1'),\n    Conv2D(64, (3,3), activation='relu', padding='same', name='Conv3_2'),\n    BatchNormalization(name='bn3_2'),\n    Conv2D(64, (3,3), activation='relu', padding='same', name='Conv3_3'),\n    BatchNormalization(name='bn3_3'),\n    MaxPooling2D((2,2), name='MaxPool3'),\n    Dropout(0.25),\n    \n    # ----------------------------------------------------------------------\n    # Using \"1x1 convolution layer\" to lower the complexity of computing\n    # [Ref]: Prof Andrew Ng, \"Inception Module\", \n    #        https:\/\/www.youtube.com\/watch?v=KfV8CJh7hE0\n    # ----------------------------------------------------------------------\n    Conv2D(16, (1,1), activation='relu', padding='same', name='Conv4_1_1x1'),\n    BatchNormalization(name='bn4_1_1x1'),\n    Conv2D(64, (3,3), activation='relu', padding='same', name='Conv4_2'),\n    BatchNormalization(name='bn4_2'),\n    Conv2D(32, (1,1), activation='relu', padding='same', name='Conv4_3_1x1'),\n    BatchNormalization(name='bn4_3_1x1'),\n    Conv2D(128, (3,3), activation='relu', padding='same', name='Conv4_4'),\n    BatchNormalization(name='bn4_4'),\n    MaxPooling2D((2,2), name='MaxPool4'),\n    Dropout(0.25),\n\n    # Using \"1x1 convolution layer\" \n    Conv2D(32, (1,1), activation='relu', padding='same', name='Conv5_1_1x1'),\n    BatchNormalization(name='bn5_1_1x1'),\n    Conv2D(128, (3,3), activation='relu', padding='same', name='Conv5_2'),\n    BatchNormalization(name='bn5_2'),\n    Conv2D(64, (1,1), activation='relu', padding='same', name='Conv5_3_1x1'),\n    BatchNormalization(name='bn5_3_1x1'),\n    Conv2D(256, (3,3), activation='relu', padding='same', name='Conv5_4'),\n    BatchNormalization(name='bn5_4'),\n    MaxPooling2D((2,2), name='MaxPool5'),\n    Dropout(0.25),\n    \n    # Using \"1x1 convolution layer\" \n    Conv2D(64, (1,1), activation='relu', padding='same', name='Conv6_1x1'),\n    BatchNormalization(name='bn6_1x1'),\n    Conv2D(512, (3,3), activation='relu', padding='same', name='Conv6_2'),\n    BatchNormalization(name='bn6_2'),\n    \n    Conv2D(128, (1,1), activation='relu', padding='same', name='Conv7_1x1'),\n    BatchNormalization(name='bn7_1x1'),\n    Conv2D(1024, (3,3), activation='relu', name='Conv7_2'),\n    BatchNormalization(name='bn7_3'),\n    GlobalAveragePooling2D(name='GlobalAveragePool_1'),\n    Dropout(0.5),\n    \n    #Flatten(),\n    #Dense(64, activation='relu', name='fc'), \n    #BatchNormalization(name='bn_fc'),\n    #Dropout(0.5),\n    Dense(1, name='Output')   #  activation='sigmoid' =>  BinaryCrossentropy(logits=True)\n])","a1a0aaa6":"model.summary()","739de376":"tf.keras.utils.plot_model(model, show_shapes=True, dpi=85)","007a74fb":"batch_size = 16\nepochs_stage_1 = 10\nepochs_stage_2 = 20\ntrain_data_num = 4200","78cdacb1":"# Adam Optimizer with Learning-rate Decay \nbasic_learning_rate = 0.001\nopt = Adam(lr=basic_learning_rate, decay=basic_learning_rate\/10.)\n\nmodel.compile(optimizer=opt,\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","39c341e5":"## data_augmentation = False\nprint('Not using data augmentation.')\nepochs = epochs_stage_1\nhistory_no_data_aug = model.fit(x_train[:train_data_num], y_train[:train_data_num],\n                               batch_size=batch_size,\n                               epochs=epochs,\n                               validation_data=(x_train[train_data_num:], y_train[train_data_num:]),\n                               # validation_data=(x_val, y_val),\n                               shuffle=False)","a4bbcf54":"history_no_data_aug.history.keys()","e2bb1f61":"acc = history_no_data_aug.history['accuracy']\nval_acc = history_no_data_aug.history['val_accuracy']\n\nloss = history_no_data_aug.history['loss']\nval_loss = history_no_data_aug.history['val_loss']\n\nepochs_range = range(1, epochs + 1)\n\nplt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylim(0, 1)\nplt.xticks(epochs_range)\nplt.title('Training and Validation Accuracy - without Data Augmentation')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylim(0, 1)\nplt.xticks(epochs_range)\nplt.title('Training and Validation Loss - without Data Augmentation')\nplt.show()","cfc1a73b":"# Score trained model.\nloss, acc = model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss:', loss)\nprint('Test accuracy:', acc)","38f57862":"# Get predictions\npreds = model.predict(x_test)","2fc0dfe8":"preds.shape","d4c76ac9":"y_pred = []\nfor i in range(len(preds)):\n    if preds[i] > 0.5 : \n        y_pred.append(1) \n    else: \n        y_pred.append(0)\n        \nprint(' y_pred = ', np.array(y_pred[:10]))\nprint(' y_test = ', y_test[:10])","c5f82a22":"mat = confusion_matrix(y_test, y_pred)\nprint(mat)\n\nplt.figure(figsize=(8,6))\nsns.heatmap(mat, square=False, annot=True, fmt ='d', cbar=True, annot_kws={\"size\": 16})\nplt.title('0 : Normal   1 : Pneumonia', fontsize = 20)\nplt.xticks(fontsize = 16)\nplt.yticks(fontsize = 16)\nplt.xlabel('predicted value', fontsize = 20)\nplt.ylabel('true value', fontsize = 20)\nplt.show()","33177e95":"# Calculate Precision and Recall\ntn, fp, fn, tp = mat.ravel()\nprint('tn = {}, fp = {}, fn = {}, tp = {} '.format(tn, fp, fn, tp))\n\nprecision = tp\/(tp+fp)\nrecall = tp\/(tp+fn)\naccuracy = (tp+tn)\/(tp+tn+fp+fn)\nf1_score = 2. * precision * recall \/ (precision + recall)\nf2_score = 5. * precision * recall \/ (4. * precision + recall)\n\nprint(\"\\nTest Recall of the model \\t = {:.4f}\".format(recall))\nprint(\"Test Precision of the model \\t = {:.4f}\".format(precision))\nprint(\"Test Accuracy of the model \\t = {:.4f}\".format(accuracy))\nprint(\"\\nTest F1 score of the model \\t = {:.4f}\".format(f1_score))\nprint(\"\\nTest F2 score of the model \\t = {:.4f}\".format(f2_score))","f9c31b57":"# Adam Optimizer with Learning-rate Decay \nlr_with_decay = basic_learning_rate \/ 10.\nopt = Adam(lr=lr_with_decay, decay=lr_with_decay\/100.)\n\nmodel.compile(optimizer=opt,\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","914c1b84":"def data_augm():\n    print('Using real-time data augmentation.')\n    # This will do preprocessing and realtime data augmentation:\n    datagen = ImageDataGenerator(\n        # randomly shift images horizontally (fraction of total width)\n        width_shift_range=0.05,\n        # randomly shift images vertically (fraction of total height)\n        height_shift_range=0.05,\n        # rotation_range=20,\n        horizontal_flip=True,  # Randomly flip inputs horizontally.\n        # vertical_flip=True,  # Randomly flip inputs vertically.\n        # zoom_range=[0.95, 1.05] # Range for random zoom\n    )\n    return datagen","1498d7be":"print('With data augmentation.')\ndatagen = data_augm()\nepochs = epochs_stage_2\n\n# Compute quantities required for feature-wise normalization\n# (std, mean, and principal components if ZCA whitening is applied).\ndatagen.fit(x_train[:train_data_num])\n\n# Fit the model on the batches generated by datagen.flow().\nhistory_data_aug = model.fit_generator(datagen.flow(x_train[:train_data_num], y_train[:train_data_num], \n                                                    batch_size=batch_size),\n                                                    epochs=epochs,\n                                                    validation_data=(x_train[train_data_num:], y_train[train_data_num:]),\n                                                    # validation_data=(x_val, y_val),\n                                                    workers=4)","9df4f960":"acc = history_data_aug.history['accuracy']\nval_acc = history_data_aug.history['val_accuracy']\n\nloss = history_data_aug.history['loss']\nval_loss = history_data_aug.history['val_loss']\n\nepochs_range = range(1, epochs + 1)\n\nplt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylim(0, 1)\nplt.xticks(epochs_range)\nplt.title('Training and Validation Accuracy with Data Augmentation')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylim(0, 1)\nplt.xticks(epochs_range)\nplt.title('Training and Validation Loss with Data Augmentation')\nplt.show()","faa04cfc":"# Score trained model.\nloss, acc = model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss:', loss)\nprint('Test accuracy:', acc)","0e8e93a5":"# Get predictions\npreds = model.predict(x_test)","59bff318":"preds.shape","3f95419d":"y_pred = []\nfor i in range(len(preds)):\n    if preds[i] > 0.5 : \n        y_pred.append(1) \n    else: \n        y_pred.append(0)\n        \nprint(' y_pred = ', np.array(y_pred[:10]))\nprint(' y_test = ', y_test[:10])","20312520":"mat = confusion_matrix(y_test, y_pred)\nprint(mat)\n\nplt.figure(figsize=(8,6))\nsns.heatmap(mat, square=False, annot=True, fmt ='d', cbar=True, annot_kws={\"size\": 16})\nplt.title('0 : Normal   1 : Pneumonia', fontsize = 20)\nplt.xticks(fontsize = 16)\nplt.yticks(fontsize = 16)\nplt.xlabel('predicted value', fontsize = 20)\nplt.ylabel('true value', fontsize = 20)\nplt.show()","b673afce":"# Calculate Precision and Recall\ntn, fp, fn, tp = mat.ravel()\nprint('tn = {}, fp = {}, fn = {}, tp = {} '.format(tn, fp, fn, tp))\n\nprecision = tp\/(tp+fp)\nrecall = tp\/(tp+fn)\naccuracy = (tp+tn)\/(tp+tn+fp+fn)\nf1_score = 2. * precision * recall \/ (precision + recall)\nf2_score = 5. * precision * recall \/ (4. * precision + recall)\n\nprint(\"\\nTest Recall of the model \\t = {:.4f}\".format(recall))\nprint(\"Test Precision of the model \\t = {:.4f}\".format(precision))\nprint(\"Test Accuracy of the model \\t = {:.4f}\".format(accuracy))\nprint(\"\\nTest F1 score of the model \\t = {:.4f}\".format(f1_score))\nprint(\"\\nTest F2 score of the model \\t = {:.4f}\".format(f2_score))","970bc912":"acc_total = history_no_data_aug.history['accuracy'] + history_data_aug.history['accuracy']\nval_acc_total = history_no_data_aug.history['val_accuracy'] + history_data_aug.history['val_accuracy']\n\nloss_total = history_no_data_aug.history['loss'] + history_data_aug.history['loss']\nval_loss_total = history_no_data_aug.history['val_loss'] + history_data_aug.history['val_loss']","f50a18e8":"initial_epochs = epochs_stage_1\ntotal_epochs = epochs_stage_1 + epochs_stage_2\nepochs_range = range(1, total_epochs + 1)\n\nplt.figure(figsize=(10, 10))\nplt.subplot(2, 1, 1)\nplt.plot(epochs_range, acc_total, label='Training Accuracy')\nplt.plot(epochs_range, val_acc_total, label='Validation Accuracy')\nplt.ylim([0, 1])\nplt.xticks(range(1,total_epochs+1,1))\nplt.plot([initial_epochs,initial_epochs],\n          plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(epochs_range, loss_total, label='Training Loss')\nplt.plot(epochs_range, val_loss_total, label='Validation Loss')\nplt.ylim([0, 1])\nplt.xticks(range(1,total_epochs+1,1))\nplt.plot([initial_epochs,initial_epochs],\n         plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","99bf7f82":"# Saving the entire model to a HDF5 file\uff1a\n# The '.h5' extension is for the HDF5 format.\nmodel.save('PD_HDF5_model.h5')","625c939c":"# Reloading the HDF5 model, including its weights and the optimizer.\nHDF5_model = tf.keras.models.load_model('PD_HDF5_model.h5')\n\n# Show the model architecture\nHDF5_model.summary()","222cdd0a":"# Evaluate the restored HDF5 model\nloss, acc = HDF5_model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss:', loss)\nprint('Test accuracy:', acc)","f1f2a75a":"# submission = pd.concat([pd.Series(range(1,(len(pred)+1)),name = \"ImageId\"),preds],axis = 1)\ndata_subm = {'ImageId': pd.Series(range(1,(len(y_pred)+1))), 'Prediction': y_pred}\nsubmission = pd.DataFrame(data_subm)\nsubmission = submission.applymap(str)\n\nsubmission.to_csv(\"submission.csv\",index=False)","a9fc20bf":"> ### Confusion Matrix for < STAGE 1 >\n>                        ---------------------------------\n>                        |               |               |\n>                        |     true      |     false     |\n>           Normal : 0   |   negative    |    positive   |\n>                        |     (tn)      |      (fp)     |\n>      true              |               |               |\n>      value             ---------------------------------\n>                        |               |               |\n>                        |    false      |     true      |\n>         Pneumonia : 1  |   negative    |    positive   |\n>                        |     (fn)      |      (tp)     |\n>                        |               |               |\n>                        ---------------------------------\n>                            Normal : 0     Pneumonia : 1\n>\n>                                 predicted value","7cfa78aa":"<a id=\"TrainData\"><\/a>\n+ ### Importing Training Datasets","b4050dd3":"<a id=\"Backpropagation1\"><\/a>\n> + ### Backpropagation - *Optimizer*, *Loss Function* & *Accuracy* for < STAGE 1 >","e4b686df":"> ### [ File Directory ]\n       +-- input \n             |-- pneumonia-detection\n                  |-- chest_xray\n                         |-- test\n                               |-- NORMAL\n                               |-- PNEUMONIA\n                         |-- train\n                               |-- NORMAL\n                               |-- PNEUMONIA\n                         |-- val\n                               |-- NORMAL\n                               |-- PNEUMONIA\n","407f0057":"<a id=\"Forwardpropagation\"><\/a>\n+ ### Forward Propagation - with Batch Normalization and Dropout\n    + Conv2D layer\n    + 1x1 Convolution ([Ref]: Prof Andrew Ng, \"Inception Module\", https:\/\/www.youtube.com\/watch?v=KfV8CJh7hE0)","a6980fa4":"> ### Data Augmentation Function","907a50c9":"<a id=\"StartTraining\"><\/a>\n## 4. Start Training with Data Augmentation","cdf8deac":"<a id=\"ValData\"><\/a>\n+ ### Importing Validation Datasets","2f50569c":"<a id=\"ModelSummary\"><\/a>\n+ ### Model Summary & Plotting the Model","0421031a":"> ### Validation-Curve Diagrams for STAGE 2 - Training *with* Data Augmentation","8226356e":"<a id=\"Stage1\"><\/a>\n+ ### STAGE 1 : Coarse Training *without* Data Augmentation","60523baf":"### Calculating *precision*, *recall*, *accuracy*, *F1_score* & *F2_score* for < STAGE 2 >","5bb2eef2":"<a id=\"TestData\"><\/a>\n+ ### Importing Test Datasets","501bb6c5":"> ### Evaluation with Test Dataset for < STAGE 2 >","08894fe0":"> ### Calculating *precision*, *recall*, *accuracy*, *F1_score* & *F2_score* for < STAGE 1 >","16c6b2d9":"<a id='preprocessing'><\/a>\n## 2. Data Preprocessing","527c5c10":"### Import X-ray Image Datasets from \/train, \/val & \/test","cdd8b7ae":"<a id=\"Stage2\"><\/a>\n+ ### STAGE 2 : Fine Training *with* Data Augmentation","9d1154aa":"<a id='CNNModel'><\/a>\n## 3. CNN Model by *tf.keras*","471d9bbb":"<a id=\"SettingHyperparameters\"><\/a>\n+ ### Setting Hyperparameters for Training Process\n>+ \u7531\u65bc validation dataset \u53ea\u6709 16 \u7b46\u5f71\u50cf\u8cc7\u6599 (\u592a\u5c11\u4e86\u4e9b)\uff0c\u56e0\u6b64\uff0c\u76f4\u63a5\u5c07 training datasets (5216 images) \u5206\u5272\u51fa 4200 \u7b46\u7684 training \u8cc7\u6599 (80.5% \u8cc7\u6599\u91cf)\uff0c\u5176\u9918\u7684 1016 \u5f35 X-ray \u5f71\u50cf\u8cc7\u6599\u505a\u70ba validation \u8cc7\u6599\u96c6\u3002\n>+ **[ Learning-Rate Decay ] : basic learning rate = 0.001**\n    + \u5728 STAGE 1 \u4e2d\uff0c\u8a2d\u5b9a basic learning rate \u7684 1\/10 \u70ba decay rate\uff0c\u53d6 epoch \u6578\u70ba 10 \u6642\uff0c\u6bcf\u500b epoch \u7684 GPU \u904b\u7b97\u6642\u9593\u7d04\u70ba 20 \u79d2\u3002\n    + \u5728 STAGE 2 \u4e2d\uff0c\u8a2d\u5b9a learning_rate \u70ba basic learning rate \u7684 1\/10 (decay rate =  learning_rate\/100)\uff0c\u53d6 epoch \u6578\u70ba 20\uff0c\u6bcf\u500b epoch \u7684 GPU \u904b\u7b97\u6642\u9593\u7d04\u70ba 45 \u79d2\u3002","7b3f10b9":"> + ### \u6b64\u8655\u53ef\u898b CNN Model \u6709 2,669,361 \u500b\u53c3\u6578\u9700\u8981\u9032\u884c\u8a13\u7df4\u3001\u8abf\u6821\uff01\n","ca4c8762":"> ### Training with Data Augmentation","d633fff2":"> ### Evaluation for Test Datasets in < STAGE 1 > ","b4799026":"### Training Datasets","09809f44":"> ### Validation-Curve Diagrams for STAGE 1 - Training without Data Augmentation","2f180db5":"<a id=\"Result\"><\/a>\n## 5. Results\n> + \u7531\u4ee5\u4e0a\u7d50\u679c\u53ef\u77e5\uff1a\u7d93\u904e 30 epochs (i.e., Stage 1 + Stage 2) \u7684\u8a13\u7df4\uff0c**Recall** \u503c\u63a5\u8fd1 100%\uff1b\u9019\u4ee3\u8868\u9810\u6e2c\u6a21\u578b\u7684 false-negative \u8aa4\u5224\u90e8\u5206 (\u4ea6\u5373\uff0c\u5c07 Pneumonia \u8aa4\u5224\u6210 Normal \u7684\u72c0\u6cc1) \u5c07\u6703\u4e0b\u964d\u8da8\u8fd1 0\u3002\n> + \u7136\u800c\uff0c **F1 score** \u4ecd\u7136\u9084\u6709\u6539\u9032\u7684\u7a7a\u9593\uff1b\u9019\u662f\u56e0\u70ba false-positive \u8aa4\u8a3a\u90e8\u5206 (\u4ea6\u5373\uff0c\u5c07 Normal \u8aa4\u5224\u6210 Pneumonia \u7684\u72c0\u6cc1) \u9020\u6210 **Precision** \u7684\u7cbe\u78ba\u503c\u504f\u4f4e\u7684\u7de3\u6545\u3002\n> + \u8acb\u60f3\u60f3\u770b\uff0c\u5982\u4f55\u6539\u9032\u6a21\u578b\u6216\u8abf\u6821\u9810\u6e2c\u6a21\u578b\u53c3\u6578 (hyperparameters)\uff0c\u9032\u800c\u80fd\u5920\u4f7f\u5176 **F1 score** \u6578\u503c\u4e0a\u5347\u3002  Good luck\uff01\n\n\u4ee5\u4e0b\u5c07 From-Coarse-to-Fine \u5168\u7a0b\u8a13\u7df4\u904e\u7a0b\u7684 Learning Curves \u7e6a\u88fd\u5982\u4e0b\uff0c\u505a\u70ba\u53c3\u8003\uff1a","d0737285":"> ### Confusion Matrix for < STAGE 2 >\n>                        ---------------------------------\n>                        |               |               |\n>                        |     true      |     false     |\n>           Normal : 0   |   negative    |    positive   |\n>                        |     (tn)      |      (fp)     |\n>      true              |               |               |\n>      value             ---------------------------------\n>                        |               |               |\n>                        |    false      |     true      |\n>         Pneumonia : 1  |   negative    |    positive   |\n>                        |     (fn)      |      (tp)     |\n>                        |               |               |\n>                        ---------------------------------\n>                            Normal : 0     Pneumonia : 1\n>\n>                                 predicted value","09bca756":"<a id='approach'><\/a>\n## 1. APPROACH\n> + \u672c\u7bc4\u4f8b\u63a1\u7528 **From Coarse to Fine** \u7684\u8abf\u6821\u904e\u7a0b (Tuning Process)\uff1a\n    - \u9996\u5148\uff0c\u5229\u7528\u539f\u59cb\u5f71\u50cf\u8cc7\u6599(raw images)\u9032\u884c CNN Model \u53c3\u6578\u8abf\u6821\uff0c\u4e26\u8f38\u51fa\u7d50\u679c (\u53c3\u8003 < STAGE 1 : Coarse Training without Data Augmentation > \u90e8\u4efd)\u3002\n    - \u4e4b\u5f8c\uff0c\u5229\u7528 \"**\u8cc7\u6599\u64f4\u589e (Data Augmentation)**\" \u6280\u8853\uff0c\u5728\u7a0b\u5f0f\u57f7\u884c\u968e\u6bb5 (runtime) \u589e\u52a0 Training \u8cc7\u6599\u91cf\uff0c\u518d\u6b21\u5c0d CNN Model \u9032\u884c\u53c3\u6578\u8abf\u6821\uff0c\u4e26\u8f38\u51fa\u7d50\u679c (\u53c3\u8003 < STAGE 2 > \u90e8\u4efd)\u3002\n> + \u5176**\u76ee\u7684**\u662f\u5728 \"**\u6709\u6548\u7e2e\u77ed\u904b\u7b97\u6642\u9593\uff0c\u6e1b\u5c11\u4f54\u7528\u8a18\u61b6\u9ad4\u7a7a\u9593\uff0c\u540c\u6642\u63d0\u5347\u9810\u6e2c\u7d50\u679c\u7684\u6e96\u78ba\u5ea6**\"\uff0c\u9054\u6210\u6574\u9ad4\u6548\u80fd(performance)\u7684\u63d0\u5347\u3002\n* > + \u672c\u7bc4\u4f8b\u4e2d\uff0c**CNN Model** \u63a1\u7528 \"Batch Normalization\"\u3001\"Dropout\"\u4ee5\u53ca \"Learning-Rate Decay\" \u7b49\u6280\u8853\u3002\n> + \u4e0b\u5217\u7a0b\u5f0f\u540c\u6642\u8f38\u51fa < STAGE 1 > \u548c < STAGE 2 > \u7d50\u679c\u505a\u70ba\u53c3\u8003\uff0c\u4e26\u8f38\u51fa\u3001\u5132\u5b58\u6574\u500b\u9810\u6e2c\u6a21\u578b\u3002","47d0363e":"<a id=\"Backpropagation2\"><\/a>\n> + ### Backpropagation - *Optimizer*, *Loss Function* & *Accuracy* for < STAGE 2 >","b7401ed0":"# **Pneumonia Detection by CNN with Data Augmentation** \n\n2020\/03\/15\n+ \u672c\u7bc4\u4f8b\u5229\u7528 TensorFlow 2.0 \u67b6\u69cb\u4e0b\u7684 `tf.keras` \u5957\u4ef6\uff0c\u4f86\u5efa\u7acb CNN \u6a21\u578b\uff0c\u900f\u904e\u80f8\u8154 X-\u5149\u7247\u5f71\u50cf\u9032\u884c\u80ba\u708e\u5075\u6e2c\u3002\n+ \u8cc7\u6599\u90e8\u4efd\uff1a\n    - \u5c07 \"Chest_Xray\" \u5f71\u50cf\u8cc7\u6599\u532f\u5165\uff0c\u4e26\u4fee\u6539\u3001\u7d71\u4e00\u5176\u5f71\u50cf\u5c3a\u5bf8\u70ba (224, 224, 3)\u3002\n    - \u5176\u4e2d\uff0c\u8cc7\u6599\u532f\u5165\u5340\u5206\u70ba train\u3001test \u548c val \u4e09\u500b\u90e8\u5206\u3002","3a24fe5e":"<a id=\"SavingEntireModel\"><\/a>\n## 6. Saving the Entire Model with HDF5 Format","eab72cdb":"---------------------------\n## CONTENT\n1. [ APPROACH ](#approach)\n2. [ Data Preprocessing ](#preprocessing)\n    + [ Importing Training Datasets ](#TrainData)\n    + [ Importing Validation Datasets ](#ValData)\n    + [ Importing Test Datasets ](#TestData)\n3. [ CNN Model with *tf.keras* ](#CNNModel)\n    + [ Forward Propagation ](#Forwardpropagation)\n    + [ Model Summary & Plotting the Model ](#ModelSummary)\n- [ Start Training - from Coarse to Fine ](#StartTraining)\n    + [ Setting Hyperparameters ](#SettingHyperparameters)\n    + [ STAGE 1 - Coarse Training without Data Augmentation ](#Stage1)\n        + [ Backpropagation for STAGE 1 ](#Backpropagation1)\n    + [ STAGE 2 - Fine Training *with* Data Augmentation ](#Stage2)\n        + [ Backpropagation for STAGE 2 ](#Backpropagation2)\n- [ Saving the Entire Model with HDF5 Format ](#SavingEntireModel)\n---------------------------"}}