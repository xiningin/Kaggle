{"cell_type":{"8ec7148e":"code","ced5a522":"code","3e9a62b4":"code","4639abec":"code","eb02a73b":"code","4b93d7fa":"code","19482ea8":"code","05da0262":"code","7914f08b":"code","c423f26b":"code","5faa91b1":"code","7841078b":"code","300b6aac":"code","8bba46db":"code","43073d48":"code","4cb5dc8d":"code","7ea21a25":"code","2a9a9823":"code","b28f8fae":"code","077224f8":"code","21f77af0":"markdown","9e9fcec6":"markdown","95ccd4b9":"markdown","7a899bed":"markdown","b1c932db":"markdown","eaf4e21f":"markdown","699470f1":"markdown"},"source":{"8ec7148e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sb\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ced5a522":"state = 10","3e9a62b4":"data = pd.read_csv(\"..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\")\ndata.head(10)","4639abec":"data.info()","eb02a73b":"data.isnull().sum()","4b93d7fa":"sb.pairplot(data)","19482ea8":"data.iloc[:, -1].value_counts()","05da0262":"from sklearn.model_selection import train_test_split","7914f08b":"x = data.iloc[:, :-1]\ny = data.iloc[:, -1]","c423f26b":"x.head(10)","5faa91b1":"y[:10]","7841078b":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = state)","300b6aac":"from sklearn.ensemble import RandomForestClassifier as rfc\nfrom sklearn.model_selection import GridSearchCV","8bba46db":"clf = GridSearchCV(rfc(random_state = state, n_jobs = 5), {\n    \"n_estimators\": range(2, 200, 4),\n}, cv = 20, return_train_score = False)","43073d48":"clf.fit(x_train, y_train)","4cb5dc8d":"clf = clf.best_estimator_","7ea21a25":"from sklearn.metrics import accuracy_score, confusion_matrix","2a9a9823":"y_predict = clf.predict(x_test)","b28f8fae":"confusion_matrix(y_test, y_predict)","077224f8":"accuracy_score(y_test, y_predict)","21f77af0":"# Data Cleaning","9e9fcec6":"# Get Metrics","95ccd4b9":"# Read The Data","7a899bed":"As we are getting an accuracy between 80 and 90 this is considered a good enough model and hence is retained.","b1c932db":"# Model Building\nAs this is a medical data it would not be right to say that all features are independent of each other hence we will use Random Forest over Naive Bayes","eaf4e21f":"# Train Test Split","699470f1":"# Exploratory Data Analysis"}}