{"cell_type":{"504f21d9":"code","6bc767f7":"code","69c1af7f":"code","86da1062":"code","fe1a6373":"code","3d388883":"code","dc12596a":"code","643c808d":"code","bfcdf6f0":"code","28a6bcc9":"code","258e67f5":"code","38eb0e47":"code","12a122b2":"code","88fb4d15":"code","e2473f11":"code","92a2fbdf":"code","2b1055d7":"code","f7fdea2a":"code","fb6e3312":"code","8d466536":"code","d014b495":"code","1f16b8f2":"markdown","cf067a68":"markdown","e23a7b46":"markdown","c4a54ded":"markdown","e7360717":"markdown","e11b92d8":"markdown","fa2ced5a":"markdown","24bda8c1":"markdown"},"source":{"504f21d9":"from torchvision import transforms # To perform all the transforms on our data\nfrom torchvision import datasets #Used to load the data from the folders\nfrom torch.utils.data import DataLoader\nfrom torchvision import models\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport time\nfrom PIL import Image\nimport os\nimport matplotlib.pyplot as plt","6bc767f7":"!nvidia-smi","69c1af7f":"from shutil import copyfile\nclasses = ['drawing','hentai','neutral','porn','sexy']\nfor i in classes:\n  files = os.listdir(\"..\/input\/nsfw-image-classification\/test\/\"+i)\n  for j in files[:3000]:\n    copyfile(\"..\/input\/nsfw-image-classification\/test\/\"+i+\"\/\"+j, \"..\/input\/output\/test_norm\/\"+i+\"\/\"+j)\n  print(i)","86da1062":"files = os.listdir(\"..\/input\/output\/test_norm\/\"+i)\nprint(len(files))\nos.rmdir(\"..\/input\/output\/test_norm\/.ipynb_checkpoints\")","fe1a6373":"image_transforms = {\n    'train':transforms.Compose([\n        transforms.RandomRotation(degrees=15),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ]),\n    'test':transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ]),\n    'valid':transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ])\n}","3d388883":"test_directory = 'test_norm'\n\n# Setting batch size for training\nbatch_size=128\n\n#Number of classes for the data\nnum_classes = 5\n\n#Loading the data from the folders into the variable 'data'\ndata = {\n    'test': datasets.ImageFolder(root=test_directory,transform=image_transforms['test']),\n}\n\ntest_data_size = len(data['test'])\ntest_data_loader = DataLoader(data['test'],batch_size=batch_size,shuffle=True)\nidx_to_class = {v: k for k, v in data['test'].class_to_idx.items()}\nprint(idx_to_class)","dc12596a":"# Set the train, test and validation directory\ntrain_directory = 'batch-7\/train'\ntest_directory = 'batch-7\/test'\nvalid_directory = 'batch-7\/valid'\n\n# Setting batch size for training\nbatch_size=128\n\n#Number of classes for the data\nnum_classes = 5\n\n#Loading the data from the folders into the variable 'data'\ndata = {\n    'train': datasets.ImageFolder(root=train_directory,transform=image_transforms['train']),\n    'test': datasets.ImageFolder(root=test_directory,transform=image_transforms['test']),\n    'valid': datasets.ImageFolder(root=valid_directory,transform=image_transforms['valid'])\n}\n\n#Find out the size of the data\ntrain_data_size = len(data['train'])\ntest_data_size = len(data['test'])\nvalid_data_size = len(data['valid'])\n\n# Create iterators for the Data loaded using DataLoader module\ntrain_data_loader = DataLoader(data['train'],batch_size=batch_size,shuffle=True)\ntest_data_loader = DataLoader(data['test'],batch_size=batch_size,shuffle=True)\nvalid_data_loader = DataLoader(data['valid'],batch_size=batch_size,shuffle=True)\n\n#Printing the sizes of the sets\nprint(train_data_size,test_data_size,valid_data_size)\nidx_to_class = {v: k for k, v in data['train'].class_to_idx.items()}\nprint(idx_to_class)","643c808d":"# Load the pretrained resnet 50 model\nresnet50 = models.resnet50(pretrained=True)","bfcdf6f0":"# We don't want to train the model with new values, so we make the existing values untrainable\nfor param in resnet50.parameters():\n    param.requires_grad=False\n    \n# We want to add in a extra layer at the last with a 10 neuron output to classify the data\n#Number of neurons in the last layer\nfc_inputs = resnet50.fc.in_features\n\n#Replacing last layer with our layers\nresnet50.fc = nn.Sequential(\n    nn.Linear(fc_inputs,256),\n    nn.ReLU(),\n    nn.Dropout(0.4),\n    nn.Linear(256,5),\n    nn.LogSoftmax(dim=1)\n)","28a6bcc9":"model = torch.load(\"drive\/My Drive\/Image_class_NSFW_Stats\/models\/model_batch-9.pt\")","258e67f5":"# Define the optimizer and loss function\nweights = torch.tensor([1,1,1,1,6])\nloss_func = nn.NLLLoss(weight=weights.float().cuda())\noptimizer = optim.Adam(model.parameters())","38eb0e47":"def train_and_validate(model,loss_criterion,optimizer,epochs=25):\n    start = time.time()\n    best_acc = 0.0\n    history = []\n    \n    #Training the data\n    for epoch in range(epochs):\n        epoch_start = time.time()\n        print(\"Epoch - {}\/{}\".format(epoch+1,epochs))\n        \n        #Set to training mode\n        model.train()\n        \n        train_loss = 0.0\n        train_acc = 0.0\n        \n        val_loss = 0.0\n        val_acc = 0.0\n        \n        #Training\n        for i,(inputs,labels) in enumerate(train_data_loader):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            optimizer.zero_grad()\n            #lavde  mooditu kelu\n            outputs = model(inputs)\n            loss = loss_criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss = loss.item()*inputs.size(0)\n            \n            ret,predictions = torch.max(outputs.data,1)\n            correct_counts = predictions.eq(labels.data.view_as(predictions))\n            \n            acc = torch.mean(correct_counts.type(torch.cuda.FloatTensor))\n            train_acc += acc.item() * inputs.size(0)\n            \n        #Validation\n        with torch.no_grad():\n            \n            model.eval()\n            \n            for j,(inputs,labels) in enumerate(valid_data_loader):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                outputs = model(inputs)\n                loss = loss_criterion(outputs,labels)\n                \n                val_loss += loss.item() * inputs.size(0)\n                \n                ret,predictions = torch.max(outputs.data,1)\n                correct_counts = predictions.eq(labels.data.view_as(predictions))\n                \n                acc = torch.mean(correct_counts.type(torch.cuda.FloatTensor))\n                val_acc += acc.item()*inputs.size(0)\n                \n        avg_train_loss = train_loss\/train_data_size\n        avg_train_acc = train_acc\/train_data_size\n        \n        avg_val_loss = val_loss\/valid_data_size\n        avg_val_acc = val_acc\/valid_data_size\n        \n        history.append([avg_train_loss,avg_val_loss,avg_train_acc,avg_val_acc])\n        \n        epoch_end = time.time()\n        print(\"Epoch : {},Training: Loss: {:.4f}, Accuracy:{:.4f}%\\n\\t\\tValidation : Loss:{:.4f},Accuracy:{:.4f}\".format(epoch+1,avg_train_loss,avg_train_acc*100,avg_val_loss,avg_val_acc*100))\n        print(\"Time taken:\"+str((epoch_end-epoch_start)))\n        if(avg_val_acc>best_acc):\n              best_acc = avg_val_acc\n    return model,history   ","12a122b2":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nnum_epochs=30\n\nif torch.cuda.is_available():\n    model.cuda()\nprint(torch.cuda.is_available())\n    \nmodel,history = train_and_validate(model,loss_func,optimizer,num_epochs)\n\n# Save the model of the corresponding batch and its history for further use\ntorch.save(model,'drive\/My Drive\/Image_class_NSFW_Stats\/models\/model_batch-10.pt')\ntorch.save(history, 'drive\/My Drive\/Image_class_NSFW_Stats\/history\/history_batch-10.pt')","88fb4d15":"def predict(model, test_image_name):\n     \n    transform = image_transforms['test']\n \n    test_image = Image.open(test_image_name)\n    plt.imshow(test_image)\n     \n    test_image_tensor = transform(test_image)\n \n    if torch.cuda.is_available():\n        test_image_tensor = test_image_tensor.view(1, 3, 224, 224).cuda()\n    else:\n        test_image_tensor = test_image_tensor.view(1, 3, 224, 224)\n     \n    with torch.no_grad():\n        model.eval()\n        # Model outputs log probabilities\n        out = model(test_image_tensor)\n        ps = torch.exp(out)\n        topk, topclass = ps.topk(1, dim=1)\n        print(\"Output class :  \", idx_to_class[topclass.cpu().numpy()[0][0]])","e2473f11":"predict(model,\"batch-1\/test\/neutral\/01013.jpg\")","92a2fbdf":"model = torch.load(\"nsfw_classification.pt\")\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nweights = torch.tensor([1,1,1,1,6])\nloss_func = nn.NLLLoss(weight=weights.float().cuda())\n\ny_true = torch.Tensor([]).cuda()\ny_pred = torch.Tensor([]).cuda()\n\ntest_loss = 0.0\ntest_acc = 0.0\nfor j,(inputs,labels) in enumerate(test_data_loader):\n  inputs = inputs.to(device)\n  labels = labels.to(device)\n  outputs = model(inputs)\n  loss = loss_func(outputs,labels)\n  y_true = torch.cat([y_true,labels.float()],dim=0)\n  \n  test_loss += loss.item() * inputs.size(0)\n\n  ret,predictions = torch.max(outputs.data,1)\n  y_pred = torch.cat([y_pred,predictions.float()],dim=0)\n  correct_counts = predictions.eq(labels.data.view_as(predictions))\n\n  acc = torch.mean(correct_counts.type(torch.cuda.FloatTensor))\n  test_acc += acc.item()*inputs.size(0)\n","2b1055d7":"avg_test_loss = test_loss\/test_data_size\navg_test_acc = test_acc\/test_data_size","f7fdea2a":"print(y_true,y_pred)\nprint(avg_test_acc)","fb6e3312":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nsns.set_style('white') \nlabels = ['drawing', 'hentai', 'neutral', 'porn', 'provocative']\nx = confusion_matrix(y_true.tolist(),y_pred.tolist())\nsns.heatmap(x,xticklabels=labels,yticklabels=labels,linecolor='white')","8d466536":"from sklearn.metrics import classification_report\nprint(classification_report(y_true.tolist(),y_pred.tolist()))","d014b495":"current = \"7,\"+str(train_data_size)+\",\"+str(avg_test_acc*100)+\"\\n\"\nprint(current)","1f16b8f2":"![Cover](https:\/\/imgur.com\/xhJclfL.png)","cf067a68":"# Like the beginning of every project, we import libraries","e23a7b46":"# Testing and Benchmarking\n","c4a54ded":"# Importing Files, Splitting into Batches and Defining Classes","e7360717":"# Preparing to Train","e11b92d8":"# Begin Training","fa2ced5a":"# Predicting an Image","24bda8c1":"### Our classification model for Content Moderation will be trained over 330,000 images on a pretrained RESNET50"}}