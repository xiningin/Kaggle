{"cell_type":{"ca3904c9":"code","201fbe41":"code","03ebea60":"code","bf2bc6b1":"code","002f337f":"code","0817feca":"code","435e1509":"code","9c53e38b":"code","d4c47b77":"code","c6da9843":"code","92e8a093":"code","4010de0e":"code","d8c28c0d":"code","da5c1ec8":"code","2afcafc2":"code","8f58d505":"code","e7531b08":"code","401028fe":"code","5f96a26d":"code","a5c8fb0c":"code","869b1664":"code","3c03ffc2":"code","f3aefdbf":"code","498bd9be":"code","2c9f5fca":"code","b9441a2b":"code","414ae5c7":"code","b5174412":"code","539152f8":"code","07ad132b":"code","0227d5f3":"code","5614bce1":"code","f0c3b329":"code","5e3688e1":"code","3a7d8566":"code","5cc05590":"code","1aa61170":"code","4362e862":"code","50cc2e82":"code","327efc94":"code","250ec491":"code","250affa5":"code","6488b2a8":"code","e3f8a4dc":"code","ecb36fac":"code","e4c2c7ac":"code","1f682a72":"code","76ac152d":"code","4776c638":"code","a66f23ea":"code","197179fd":"code","67aba48c":"code","fce3f43b":"code","a68af773":"code","4ba0e28e":"code","242f124c":"code","b04f60f6":"code","914030f2":"code","23072bc7":"code","b36f065f":"code","88e94705":"code","e4351a46":"code","06b54ac2":"code","1c0cec55":"code","4897fd97":"code","7f01223c":"code","f8fd6788":"code","de9fa571":"code","e7701318":"code","ae949fd0":"code","e3aa36cf":"code","594d832a":"code","ed326295":"code","b4a58303":"code","aa062f14":"code","3fe99653":"code","3da10d98":"code","3bad6bd5":"code","b016317e":"code","b3a71875":"code","4cf205c2":"code","2b36eaef":"code","9ffef754":"code","e4b4644e":"markdown","7e39afb1":"markdown","d9321763":"markdown","cc57d17d":"markdown","823db6b7":"markdown","917e675e":"markdown","3f783f63":"markdown","d1074768":"markdown","98edc83d":"markdown","537b38c4":"markdown","85c47c9e":"markdown","a845bfc7":"markdown","beee6004":"markdown","400d536a":"markdown","f7d17d94":"markdown","f0beb865":"markdown","7421f999":"markdown","0482e3fb":"markdown","aea4cfb4":"markdown","2049a9cc":"markdown","d4864084":"markdown","2ed621b4":"markdown","97b2a516":"markdown","11621111":"markdown","b13ea1f2":"markdown","4f19e621":"markdown","763f749b":"markdown","5bffe46b":"markdown","fff37951":"markdown","c351c27a":"markdown","ec1c71a6":"markdown","4b29fc17":"markdown","b72010ac":"markdown","b7e87d4c":"markdown","92ea8672":"markdown","a0fd9992":"markdown","fdd6c8c7":"markdown","adb257fc":"markdown","3fb87d1c":"markdown","2ce4efdb":"markdown","b5b4706d":"markdown","b3a7b1fa":"markdown","fa19dfc5":"markdown","8265e06d":"markdown","95bcbb73":"markdown","fa7df42e":"markdown","f75fdde4":"markdown","451a835b":"markdown","25766f78":"markdown","d1d88b71":"markdown"},"source":{"ca3904c9":"from numpy.random import seed\nseed(101)\n\nimport pandas as pd\nimport numpy as np\n\n\nimport os\nimport cv2\n\nimport imageio\nimport skimage\nimport skimage.io\nimport skimage.transform\n\nfrom skimage.io import imread, imshow\nfrom skimage.transform import resize\n\n\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport itertools\nimport shutil\nimport matplotlib.pyplot as plt\n%matplotlib inline","201fbe41":"os.listdir('..\/input')","03ebea60":"NUM_TEST_IMAGES = 100\n\nIMAGE_HEIGHT = 128\nIMAGE_WIDTH = 128\nIMAGE_CHANNELS = 3\n\nBATCH_SIZE = 100\n","bf2bc6b1":"# Dataset: pulmonary-chest-xray-abnormalities\n# Here only the Montgomery images have masks. The Shenzhen don't have masks.\n\nos.listdir('..\/input\/pulmonary-chest-xray-abnormalities')","002f337f":"# Dataset: shcxr-lung-mask dataset\n# These are the masks for the Shenzhen images.\n\nos.listdir('..\/input\/shcxr-lung-mask')","0817feca":"shen_image_list = \\\nos.listdir('..\/input\/pulmonary-chest-xray-abnormalities\/ChinaSet_AllFiles\/ChinaSet_AllFiles\/CXR_png')\nshen_mask_list = os.listdir('..\/input\/shcxr-lung-mask\/mask\/mask')\n\nmont_image_list = \\\nos.listdir('..\/input\/pulmonary-chest-xray-abnormalities\/Montgomery\/MontgomerySet\/CXR_png')\nmont_left_mask_list = \\\nos.listdir('..\/input\/pulmonary-chest-xray-abnormalities\/Montgomery\/MontgomerySet\/ManualMask\/leftMask\/')\nmont_right_mask_list = \\\nos.listdir('..\/input\/pulmonary-chest-xray-abnormalities\/Montgomery\/MontgomerySet\/ManualMask\/rightMask\/')\n\n\n\ndef find_non_images(image_list):\n  \n  \"\"\"\n  Checks a list and returns a list of items \n  that are not png images.\n  \n  \"\"\"\n  \n  non_image_list = []\n  \n  for fname in image_list:\n    # split on the full stop\n    fname_list = fname.split('.')\n\n    # select the extension\n    extension = fname_list[1]\n\n    if extension != 'png':\n      non_image_list.append(fname)\n\n  return non_image_list\n\n","435e1509":"# Non images in Shenzhen folder\nnon_images = find_non_images(shen_image_list)\n\nnon_images","9c53e38b":"# Non images in Shenzhen mask folder\nnon_images = find_non_images(shen_mask_list)\n\nnon_images","d4c47b77":"# Non images in Montgomery image folder\nnon_images = find_non_images(mont_image_list)\n\nnon_images","c6da9843":"# Non images in Montgomery left mask folder\nnon_images = find_non_images(mont_left_mask_list)\n\nnon_images","92e8a093":"# Non images in Montgomery right mask folder\nnon_images = find_non_images(mont_right_mask_list)\n\nnon_images","4010de0e":"# Mongomery images\n# 138 (excl. Thumbs.db)\nprint(len(os.listdir('..\/input\/pulmonary-chest-xray-abnormalities\/Montgomery\/MontgomerySet\/CXR_png')))\n\n# Mongomery left masks\n# 138 (excl. Thumbs.db)\nprint(len(os.listdir('..\/input\/pulmonary-chest-xray-abnormalities\/Montgomery\/MontgomerySet\/ManualMask\/leftMask\/')))\n\n# Mongomery right masks\n# 138\nprint(len(os.listdir('..\/input\/pulmonary-chest-xray-abnormalities\/Montgomery\/MontgomerySet\/ManualMask\/rightMask\/')))\n\n\n\n# Shenzhen images\n# 662 (excl. Thumbs.db)\nprint(len(os.listdir('..\/input\/pulmonary-chest-xray-abnormalities\/ChinaSet_AllFiles\/ChinaSet_AllFiles\/CXR_png')))\n\n# Shenzhen masks\n# 566\nprint(len(os.listdir('..\/input\/shcxr-lung-mask\/mask\/mask')))","d8c28c0d":"shen_image_list = os.listdir('..\/input\/pulmonary-chest-xray-abnormalities\/ChinaSet_AllFiles\/ChinaSet_AllFiles\/CXR_png')\n\nmont_image_list = os.listdir('..\/input\/pulmonary-chest-xray-abnormalities\/Montgomery\/MontgomerySet\/CXR_png')","da5c1ec8":"# put the images into dataframes\ndf_shen = pd.DataFrame(shen_image_list, columns=['image_id'])\ndf_mont = pd.DataFrame(mont_image_list, columns=['image_id'])\n\n# remove the 'Thunbs.db' line\ndf_shen = df_shen[df_shen['image_id'] != 'Thumbs.db']\ndf_mont = df_mont[df_mont['image_id'] != 'Thumbs.db']\n\n# Reset the index or this will cause an error later\ndf_shen.reset_index(inplace=True, drop=True)\ndf_mont.reset_index(inplace=True, drop=True)\n\nprint(df_shen.shape)\nprint(df_mont.shape)","2afcafc2":"df_shen.head()","8f58d505":"df_mont.head()","e7531b08":"# Put the Shenzhen masks into a dataframe\n\nshen_mask_list = os.listdir('..\/input\/shcxr-lung-mask\/mask\/mask')\n\ndf_shen_masks = pd.DataFrame(shen_mask_list, columns=['mask_id'])\n\n# create a new column with the image_id that corresponds to each mask\n\n# example mask_id: CHNCXR_0001_0_mask.png\n\ndef create_image_id(x):\n  \n  # split on '_mask'\n  fname_list = x.split('_mask')\n  image_id = fname_list[0] + fname_list[1]\n  \n  return image_id\n  \n# create a new column\ndf_shen_masks['image_id'] = df_shen_masks['mask_id'].apply(create_image_id)\n\ndf_shen_masks.head()","401028fe":"df_shen = pd.merge(df_shen, df_shen_masks, on='image_id')\n\ndf_shen.head()","5f96a26d":"df_shen.shape","a5c8fb0c":"# Function to select the 4th index from the end of the string (file name)\n# example: CHNCXR_0470_1.png --> 1 is the label, meaning TB is present.\n\ndef extract_target(x):\n    target = int(x[-5])\n    if target == 0:\n        return 'Normal'\n    if target == 1:\n        return 'Tuberculosis'","869b1664":"# Assign the target labels\n\ndf_shen['target'] = df_shen['image_id'].apply(extract_target)\n\ndf_mont['target'] = df_mont['image_id'].apply(extract_target)\n","3c03ffc2":"# Shenzen Dataset\n\ndf_shen['target'].value_counts()","f3aefdbf":"# Montgomery Dataset\n\ndf_mont['target'].value_counts()","498bd9be":"# source: https:\/\/www.kaggle.com\/gpreda\/honey-bee-subspecies-classification\n\ndef draw_category_images(col_name,figure_cols, df, IMAGE_PATH):\n    \n    \"\"\"\n    Give a column in a dataframe,\n    this function takes a sample of each class and displays that\n    sample on one row. The sample size is the same as figure_cols which\n    is the number of columns in the figure.\n    Because this function takes a random sample, each time the function is run it\n    displays different images.\n    \"\"\"\n    \n\n    categories = (df.groupby([col_name])[col_name].nunique()).index\n    f, ax = plt.subplots(nrows=len(categories),ncols=figure_cols, \n                         figsize=(4*figure_cols,4*len(categories))) # adjust size here\n    # draw a number of images for each location\n    for i, cat in enumerate(categories):\n        sample = df[df[col_name]==cat].sample(figure_cols) # figure_cols is also the sample size\n        for j in range(0,figure_cols):\n            file=IMAGE_PATH + sample.iloc[j]['image_id']\n            im=imageio.imread(file)\n            ax[i, j].imshow(im, resample=True, cmap='gray')\n            ax[i, j].set_title(cat, fontsize=14)  \n    plt.tight_layout()\n    plt.show()\n    ","2c9f5fca":"# Shenzen Dataset\n\nIMAGE_PATH = '..\/input\/pulmonary-chest-xray-abnormalities\/ChinaSet_AllFiles\/ChinaSet_AllFiles\/CXR_png\/'\n\ndraw_category_images('target',4, df_shen, IMAGE_PATH)","b9441a2b":"# Montgomery Dataset\n\nIMAGE_PATH = '..\/input\/pulmonary-chest-xray-abnormalities\/Montgomery\/MontgomerySet\/CXR_png\/'\n\ndraw_category_images('target',4, df_mont, IMAGE_PATH)","414ae5c7":"def read_image_sizes(file_name):\n    \"\"\"\n    1. Get the shape of the image\n    2. Get the min and max pixel values in the image.\n    Getting pixel values will tell if any pre-processing has been done.\n    3. This info will be added to the original dataframe.\n    \"\"\"\n    image = cv2.imread(IMAGE_PATH + file_name)\n    max_pixel_val = image.max()\n    min_pixel_val = image.min()\n    \n    # image.shape[2] represents the number of channels: (height, width, num_channels).\n    # Here we are saying: If the shape does not have a value for num_channels (height, width)\n    # then assign 1 to the number of channels.\n    if len(image.shape) > 2: # i.e. more than two numbers in the tuple\n        output = [image.shape[0], image.shape[1], image.shape[2], max_pixel_val, min_pixel_val]\n    else:\n        output = [image.shape[0], image.shape[1], 1, max_pixel_val, min_pixel_val]\n    return output\n\n","b5174412":"IMAGE_PATH = '..\/input\/pulmonary-chest-xray-abnormalities\/ChinaSet_AllFiles\/ChinaSet_AllFiles\/CXR_png\/'\n\nm = np.stack(df_shen['image_id'].apply(read_image_sizes))\ndf = pd.DataFrame(m,columns=['w','h','c','max_pixel_val','min_pixel_val'])\ndf_shen = pd.concat([df_shen,df],axis=1, sort=False)\n\ndf_shen.head()","539152f8":"IMAGE_PATH = '..\/input\/pulmonary-chest-xray-abnormalities\/Montgomery\/MontgomerySet\/CXR_png\/'\n\nm = np.stack(df_mont['image_id'].apply(read_image_sizes))\ndf = pd.DataFrame(m,columns=['w','h','c','max_pixel_val','min_pixel_val'])\ndf_mont = pd.concat([df_mont,df],axis=1, sort=False)\n\ndf_mont.head()","07ad132b":"df_shen['c'].value_counts()","0227d5f3":"df_mont['c'].value_counts()","5614bce1":"# print a Montgomery image and mask\n\n# image\nindex = 2\nfname = df_mont.loc[index, 'image_id']\npath = '..\/input\/pulmonary-chest-xray-abnormalities\/Montgomery\/MontgomerySet\/CXR_png\/' + fname\n# read the image as a matrix\nimage = plt.imread(path)\n\nplt.imshow(image, cmap='gray')","f0c3b329":"fname = df_mont.loc[index, 'image_id']\n\n\n# left mask\npath = '..\/input\/pulmonary-chest-xray-abnormalities\/Montgomery\/MontgomerySet\/ManualMask\/leftMask\/' + fname\nleft_mask = plt.imread(path)\n\n# right mask\npath = '..\/input\/pulmonary-chest-xray-abnormalities\/Montgomery\/MontgomerySet\/ManualMask\/rightMask\/' + fname\nright_mask = plt.imread(path)\n\n# combine both masks\nmask = left_mask + right_mask\n\nplt.imshow(mask)","5e3688e1":"# display the Montgomery image and mask\n\nplt.imshow(image, cmap='gray')\nplt.imshow(mask, cmap='Blues', alpha=0.3)","3a7d8566":"# print a Shenzhen image and mask\n\n# image\nindex = 3\nfname = df_shen.loc[index, 'image_id']\npath = '..\/input\/pulmonary-chest-xray-abnormalities\/ChinaSet_AllFiles\/ChinaSet_AllFiles\/CXR_png\/' + fname\n\n# read the image as a matrix\nimage = plt.imread(path)\n\nplt.imshow(image, cmap='gray')","5cc05590":"fname = df_shen.loc[index, 'image_id']\n\nmask_name = fname.split('.')\nmask_name = mask_name[0] + '_mask.png'\n\n\n# left mask\npath = '..\/input\/shcxr-lung-mask\/mask\/' + mask_name\nmask = plt.imread(path)\n\n\nplt.imshow(mask)","1aa61170":"# display the Shenzhen image and mask\n\nplt.imshow(image, cmap='gray')\nplt.imshow(mask, cmap='Blues', alpha=0.3)","4362e862":"### Combine the two dataframes and shuffle\n\ndf_data = pd.concat([df_shen, df_mont], axis=0).reset_index(drop=True)\n\ndf_data = shuffle(df_data)\n\n\ndf_data.shape","50cc2e82":"# Create a new column called 'labels' that maps the classes to binary values.\ndf_data['labels'] = df_data['target'].map({'Normal':0, 'Tuberculosis':1})","327efc94":"df_data.head()","250ec491":"# create a test set\ndf_test = df_data.sample(NUM_TEST_IMAGES, random_state=101)\n\n# Reset the index.\ndf_test = df_test.reset_index(drop=True)\n\n# create a list of test images\ntest_images_list = list(df_test['image_id'])\n\n\n# Select only rows that are not part of the test set.\n# Note the use of ~ to execute 'not in'.\ndf_data = df_data[~df_data['image_id'].isin(test_images_list)]\n\nprint(df_data.shape)\nprint(df_test.shape)","250affa5":"# train_test_split\n\n# We will stratify by target (TB or Normal)\n\ny = df_data['labels']\n\ndf_train, df_val = train_test_split(df_data, test_size=0.15, random_state=101, stratify=y)\n\nprint(df_train.shape)\nprint(df_val.shape)","6488b2a8":"df_train['target'].value_counts()","e3f8a4dc":"df_val['target'].value_counts()","ecb36fac":"df_data.to_csv('df_data.csv.gz', compression='gzip', index=False)\n\ndf_train.to_csv('df_train.csv.gz', compression='gzip', index=False)\ndf_val.to_csv('df_val.csv.gz', compression='gzip', index=False)\n\ndf_test.to_csv('df_test.csv.gz', compression='gzip', index=False)\n","e4c2c7ac":"# check if the files were saved\n!ls","1f682a72":"# Create a new directory\nimage_dir = 'image_dir'\nos.mkdir(image_dir)","76ac152d":"%%time\n\n# Get a list of train and val images\nshen_image_list = list(df_shen['image_id'])\nmont_image_list = list(df_mont['image_id'])\n\n\n\n# Transfer the Shenzhen images\n\nfor image_id in shen_image_list:   \n    \n    fname = image_id\n    \n    path = '..\/input\/pulmonary-chest-xray-abnormalities\/ChinaSet_AllFiles\/ChinaSet_AllFiles\/CXR_png\/' + fname\n    # read the image\n    image = cv2.imread(path)\n    \n    # convert to from BGR to RGB\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \n    # resize the image\n    image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n    \n    # save the image\n    path = 'image_dir\/' + fname\n    cv2.imwrite(path, image)\n\n\n\n    \n# Transfer the Montgomery images\n\nfor image_id in mont_image_list: \n  \n    fname = image_id\n    \n    path = '..\/input\/pulmonary-chest-xray-abnormalities\/Montgomery\/MontgomerySet\/CXR_png\/' + fname\n    # read the image\n    image = cv2.imread(path)\n    \n    # convert to from BGR to RGB\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    \n    # resize the image\n    image = cv2.resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH))\n    \n    # save the image\n    path = 'image_dir\/' + fname\n    cv2.imwrite(path, image)\n    \n    ","4776c638":"# Create a new directory\nmask_dir = 'mask_dir'\nos.mkdir(mask_dir)","a66f23ea":"%%time\n\n# Get a list of train and val images\nshen_mask_list = list(df_shen['mask_id'])\nmont_mask_list = list(df_mont['image_id'])\n\n\n\n# Transfer the Shenzhen masks\n# These masks have file names that are not the same as the images\n\nfor image in shen_mask_list:\n    \n    \n    fname = image\n    \n    # change the mask file name to be the same as the image_id\n    fname_list = fname.split('_mask')\n    new_fname = fname_list[0] + fname_list[1]\n    \n    path = '..\/input\/shcxr-lung-mask\/mask\/' + fname\n    # read the image\n    mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n    \n    # resize the mask\n    mask = cv2.resize(mask, (IMAGE_HEIGHT, IMAGE_WIDTH))\n    \n    # save the mask\n    path = 'mask_dir\/' + new_fname\n    cv2.imwrite(path, mask)\n\n","197179fd":"%%time\n\n# Transfer the Montgomery masks\n\nfor image in mont_mask_list:\n    \n    \n    fname = image\n    \n    \n    # left mask\n    path = '..\/input\/pulmonary-chest-xray-abnormalities\/Montgomery\/MontgomerySet\/ManualMask\/leftMask\/' + fname\n    left_mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n\n    # right mask\n    path = '..\/input\/pulmonary-chest-xray-abnormalities\/Montgomery\/MontgomerySet\/ManualMask\/rightMask\/' + fname\n    right_mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n\n    # combine left and right masks\n    mask = left_mask + right_mask\n    \n    # resize the mask\n    mask = cv2.resize(mask, (IMAGE_HEIGHT, IMAGE_WIDTH))\n    \n    \n    # save the combined mask\n    path = 'mask_dir\/' + fname\n    cv2.imwrite(path, mask)\n    ","67aba48c":"def train_generator(batch_size=10):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_train.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            mask_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_train = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n            # create empty Y matrix - 1 channel\n            Y_train = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, 1), dtype=np.bool)\n\n        \n            \n            # Create X_train\n            #================\n            \n            for i, image_id in enumerate(image_id_list):\n                \n\n                # set the path to the image\n                path = 'image_dir\/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                #image = resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH), mode='constant', preserve_range=True)\n                \n                # insert the image into X_train\n                X_train[i] = image\n            \n            \n            # Create Y_train\n            # ===============\n                \n            for j, mask_id in enumerate(mask_id_list):\n\n                # set the path to the mask\n                path = 'mask_dir\/' + mask_id\n\n                # read the mask\n                mask = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n                \n                # expand dims from (800,600) to (800,600,1)\n                mask = np.expand_dims(mask, axis=-1)\n                \n                # resize the mask\n                #mask = resize(mask, (IMAGE_HEIGHT, IMAGE_WIDTH), mode='constant', preserve_range=True)\n                \n                \n                # insert the image into Y_train\n                Y_train[j] = mask\n                \n                \n            # Normalize the images\n            X_train = X_train\/255\n\n            yield X_train, Y_train","fce3f43b":"# Test the generator\n\n# initialize\ntrain_gen = train_generator(batch_size=10)\n\n# run the generator\nX_train, Y_train = next(train_gen)\n\nprint(X_train.shape)\nprint(Y_train.shape)","a68af773":"# print the first image in X_train\n\nimg = X_train[7,:,:,:]\nplt.imshow(img)","4ba0e28e":"# print the first mask in Y_train\n\nmsk = Y_train[7,:,:,0]\nplt.imshow(msk)","242f124c":"plt.imshow(img, cmap='gray')\nplt.imshow(msk, cmap='Blues', alpha=0.3)","b04f60f6":"def val_generator(batch_size=10):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_val.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            mask_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_val = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n            # create empty Y matrix - 1 channel\n            Y_val = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, 1), dtype=np.bool)\n\n        \n            \n            # Create X_val\n            #================\n            \n            for i, image_id in enumerate(image_id_list):\n                \n\n                # set the path to the image\n                path = 'image_dir\/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                #image = resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH), mode='constant', preserve_range=True)\n                \n                # insert the image into X_train\n                X_val[i] = image\n            \n            \n            # Create Y_val\n            # ===============\n                \n            for j, mask_id in enumerate(mask_id_list):\n\n                # set the path to the mask\n                path = 'mask_dir\/' + mask_id\n\n                # read the mask\n                mask = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n                \n                # expand dims from (800,600) to (800,600,1)\n                mask = np.expand_dims(mask, axis=-1)\n                \n                # resize the mask\n                #mask = resize(mask, (IMAGE_HEIGHT, IMAGE_WIDTH), mode='constant', preserve_range=True)\n                \n                \n                # insert the image into Y_train\n                Y_val[j] = mask\n                \n            \n            # Normalize the images\n            X_val = X_val\/255\n            \n            yield X_val, Y_val","914030f2":"# Test the generator\n\n# initialize\nval_gen = val_generator(batch_size=10)\n\n# run the generator\nX_val, Y_val = next(val_gen)\n\nprint(X_val.shape)\nprint(Y_val.shape)","23072bc7":"# print the image from X_val\n\nimg = X_val[7,:,:,:]\nplt.imshow(img)","b36f065f":"# print the mask from Y_val\n\nmsk = Y_val[7,:,:,0]\nplt.imshow(msk)","88e94705":"# Combine the mask and the image\n\nplt.imshow(img, cmap='gray')\nplt.imshow(msk, cmap='Blues', alpha=0.3)","e4351a46":"def test_generator(batch_size=1):\n    \n    while True:\n        \n        # load the data in chunks (batches)\n        for df in pd.read_csv('df_test.csv.gz', chunksize=batch_size):\n            \n            # get the list of images\n            image_id_list = list(df['image_id'])\n            mask_id_list = list(df['image_id'])\n            \n            # Create empty X matrix - 3 channels\n            X_test = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS), dtype=np.uint8)\n            \n            # create empty Y matrix - 1 channel\n            Y_test = np.zeros((len(df), IMAGE_HEIGHT, IMAGE_WIDTH, 1), dtype=np.bool)\n            \n\n\n            \n            # Create X_test\n            #================\n            \n            for i, image_id in enumerate(image_id_list):\n                \n\n                # set the path to the image\n                path = 'image_dir\/' + image_id\n\n                # read the image\n                image = cv2.imread(path)\n           \n                \n                # convert to from BGR to RGB\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                \n                # resize the image\n                #image = resize(image, (IMAGE_HEIGHT, IMAGE_WIDTH), mode='constant', preserve_range=True)\n                \n                # insert the image into X_train\n                X_test[i] = image\n                \n             \n            # Create Y_test\n            # ===============\n                \n            for j, mask_id in enumerate(mask_id_list):\n\n                # set the path to the mask\n                path = 'mask_dir\/' + mask_id\n\n                # read the mask\n                mask = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n                \n                # expand dims from (800,600) to (800,600,1)\n                mask = np.expand_dims(mask, axis=-1)\n                \n                # resize the mask\n                #mask = resize(mask, (IMAGE_HEIGHT, IMAGE_WIDTH), mode='constant', preserve_range=True)\n                \n                \n                # insert the image into Y_train\n                Y_test[j] = mask\n            \n            \n            # Normalize the images\n            X_test = X_test\/255\n            \n            yield X_test, Y_test\n","06b54ac2":"# Test the generator\n\n# initialize\ntest_gen = test_generator(batch_size=5)\n\n# run the generator\nX_test, Y_test = next(test_gen)\n\nprint(X_test.shape)\nprint(Y_test.shape)","1c0cec55":"# print the image from X_test\n\nimg = X_test[1,:,:,:]\nplt.imshow(img)","4897fd97":"# print the mask from Y_test\n\nmsk = Y_test[1,:,:,0]\nplt.imshow(msk)","7f01223c":"# Combine the mask and the image\n\nplt.imshow(img, cmap='gray')\nplt.imshow(msk, cmap='Blues', alpha=0.3)","f8fd6788":"from keras.models import Model, load_model\nfrom keras.layers import Input, UpSampling2D\nfrom keras.layers.core import Dropout, Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K\n\nfrom keras.callbacks import (EarlyStopping, ReduceLROnPlateau, \n                                        ModelCheckpoint, CSVLogger, LearningRateScheduler)\n\n\nfrom keras.optimizers import Adam\nfrom keras.losses import binary_crossentropy\n\nfrom keras.initializers import he_normal \n\nimport tensorflow as tf","de9fa571":"# source: https:\/\/www.kaggle.com\/keegil\/keras-u-net-starter-lb-0-277\n\ndrop_out = 0.1\nINIT_SEED = 101\n\n\n\ninputs = Input((IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS))\n\n# Note: Tensorflow.js does not support lambda layers.\n#s = Lambda(lambda x: x \/ 255) (inputs)\n\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer=he_normal(seed=INIT_SEED), padding='same') (inputs)\nc1 = Dropout(drop_out) (c1)\nc1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer=he_normal(seed=INIT_SEED), padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer=he_normal(seed=INIT_SEED), padding='same') (p1)\nc2 = Dropout(drop_out) (c2)\nc2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer=he_normal(seed=INIT_SEED), padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer=he_normal(seed=INIT_SEED), padding='same') (p2)\nc3 = Dropout(drop_out) (c3)\nc3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer=he_normal(seed=INIT_SEED), padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer=he_normal(seed=INIT_SEED), padding='same') (p3)\nc4 = Dropout(drop_out) (c4)\nc4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer=he_normal(seed=INIT_SEED), padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer=he_normal(seed=INIT_SEED), padding='same') (p4)\nc5 = Dropout(drop_out) (c5)\nc5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer=he_normal(seed=INIT_SEED), padding='same') (c5)\n\nu6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer=he_normal(seed=INIT_SEED), padding='same') (u6)\nc6 = Dropout(drop_out) (c6)\nc6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer=he_normal(seed=INIT_SEED), padding='same') (c6)\n\nu7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer=he_normal(seed=INIT_SEED), padding='same') (u7)\nc7 = Dropout(drop_out) (c7)\nc7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer=he_normal(seed=INIT_SEED), padding='same') (c7)\n\nu8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer=he_normal(seed=INIT_SEED), padding='same') (u8)\nc8 = Dropout(drop_out) (c8)\nc8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer=he_normal(seed=INIT_SEED), padding='same') (c8)\n\nu9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer=he_normal(seed=INIT_SEED), padding='same') (u9)\nc9 = Dropout(drop_out) (c9)\nc9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer=he_normal(seed=INIT_SEED), padding='same') (c9)\n\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy')\n\nmodel.summary()","e7701318":"# initialize\ntest_gen = test_generator(batch_size=len(df_test))\n\n# run the generator\nX_test, Y_test = next(test_gen)\n\nprint(X_test.shape)\nprint(Y_test.shape)","ae949fd0":"num_train_samples = len(df_train)\nnum_val_samples = len(df_val)\ntrain_batch_size = BATCH_SIZE\nval_batch_size = BATCH_SIZE\n\n# determine numtrain steps\ntrain_steps = np.ceil(num_train_samples \/ train_batch_size)\n# determine num val steps\nval_steps = np.ceil(num_val_samples \/ val_batch_size)","e3aa36cf":"# Initialize the generators\ntrain_gen = train_generator(batch_size=BATCH_SIZE)\nval_gen = val_generator(batch_size=BATCH_SIZE)\n\n\n\nfilepath = \"model.h5\"\n\nearlystopper = EarlyStopping(patience=5, verbose=1)\n\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, \n                                   verbose=1, mode='min')\n\n\n\nlog_fname = 'training_log.csv'\ncsv_logger = CSVLogger(filename=log_fname,\n                       separator=',',\n                       append=False)\n\ncallbacks_list = [checkpoint, earlystopper, csv_logger, reduce_lr]\n\nhistory = model.fit_generator(train_gen, steps_per_epoch=train_steps, epochs=40, \n                              validation_data=val_gen, validation_steps=val_steps,\n                             verbose=1,\n                             callbacks=callbacks_list)","594d832a":"# Make a prediction\n\n# initialize the test generator\ntest_gen = test_generator(batch_size=1)\n\nmodel.load_weights('model.h5')\npredictions = model.predict_generator(test_gen, \n                                      steps=len(df_test),  \n                                      verbose=1)","ed326295":"!ls","b4a58303":"preds_test_thresh = (predictions >= 0.7).astype(np.uint8)\n\npreds_test_thresh.shape\n\nprint(preds_test_thresh.min())\nprint(preds_test_thresh.max())","aa062f14":"# This is a predicted mask\n\nmask = preds_test_thresh[3,:,:,0]\nplt.imshow(mask, cmap='Reds', alpha=0.3)","3fe99653":"# This is a true mask\n\ntrue_mask = Y_test[3,:,:,0]\nplt.imshow(true_mask, cmap='Blues', alpha=0.3)","3da10d98":"# This is the x-ray image\n\nimage = X_test[3,:,:,:]\n\nplt.imshow(image)","3bad6bd5":"# This is an overlay of the pred mask, true mask and \n# the x-ray image.\n\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)","b016317e":"# set up the canvas for the subplots\nplt.figure(figsize=(20,20))\nplt.tight_layout()\nplt.axis('Off')\n\npredicted_masks = preds_test_thresh\n\n\n\n    \n# image\nplt.subplot(1,4,1)\nimage = X_test[1,:,:,:] \nmask = predicted_masks[1, :, :, 0]\ntrue_mask = Y_test[1, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,4,2)\nimage = X_test[2,:,:,:] \nmask = predicted_masks[2, :, :, 0]\ntrue_mask = Y_test[2, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,4,3)\nimage = X_test[3,:,:,:]\nmask = predicted_masks[3, :, :, 0]\ntrue_mask = Y_test[3, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,4,4)\nimage = X_test[4,:,:,:] \nmask = predicted_masks[4, :, :, 0]\ntrue_mask = Y_test[4, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n\n# ============ #\n\n\n# set up the canvas for the subplots\nplt.figure(figsize=(20,20))\nplt.tight_layout()\nplt.axis('Off')\n\n\n# image\nplt.subplot(1,4,1)\nimage = X_test[5,:,:,:] \nmask = predicted_masks[5, :, :, 0]\ntrue_mask = Y_test[5, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,4,2)\nimage = X_test[6,:,:,:] \nmask = predicted_masks[6, :, :, 0]\ntrue_mask = Y_test[6, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,4,3)\nimage = X_test[7,:,:,:] \nmask = predicted_masks[7, :, :, 0]\ntrue_mask = Y_test[7, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,4,4)\nimage = X_test[8,:,:,:] \nmask = predicted_masks[8, :, :, 0]\ntrue_mask = Y_test[8, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# ============ #\n\n\n# set up the canvas for the subplots\nplt.figure(figsize=(20,20))\nplt.tight_layout()\nplt.axis('Off')\n\n\n# image\nplt.subplot(1,4,1)\nimage = X_test[9,:,:,:] \nmask = predicted_masks[9, :, :, 0]\ntrue_mask = Y_test[9, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,4,2)\nimage = X_test[10,:,:,:] \nmask = predicted_masks[10, :, :, 0]\ntrue_mask = Y_test[10, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,4,3)\nimage = X_test[11,:,:,:] \nmask = predicted_masks[11, :, :, 0]\ntrue_mask = Y_test[11, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\n# image\nplt.subplot(1,4,4)\nimage = X_test[12,:,:,:] \nmask = predicted_masks[12, :, :, 0]\ntrue_mask = Y_test[12, :, :, 0]\nplt.imshow(image, cmap='gray')\nplt.imshow(true_mask, cmap='Reds', alpha=0.3)\nplt.imshow(mask, cmap='Blues', alpha=0.3)\nplt.axis('off')\n\n\nplt.show()","b3a71875":"# --ignore-installed is added to fix an error.\n\n# https:\/\/stackoverflow.com\/questions\/49932759\/pip-10-and-apt-how-to-avoid-cannot-uninstall\n# -x-errors-for-distutils-packages\n\n!pip install tensorflowjs --ignore-installed","4cf205c2":"# Use the command line conversion tool to convert the model\n\n!tensorflowjs_converter --input_format keras model.h5 tfjs\/model","2b36eaef":"# check that the folder containing the tfjs model files has been created\n!ls","9ffef754":"# Delete the image data directory we created to prevent a Kaggle error.\n# Kaggle allows a max of 500 files to be saved.\n\nif os.path.isdir('image_dir') == True: # return true if the directory exists\n    \n    shutil.rmtree('image_dir')\n    \n\nif os.path.isdir('mask_dir') == True: # return true if the directory exists\n    \n    shutil.rmtree('mask_dir')","e4b4644e":"## Move all masks into the same directory","7e39afb1":"### [ 3 ] Test Generator","d9321763":"## What files are available?","cc57d17d":"\nThe label is part of the file name.\n\nExample: *CHNCXR_0470__**1**.png*<br>\n\n**0** = Normal (No TB)<br>\n**1** = TB<br>\n\nEach of the two datasets has a text file containing meta-data.","823db6b7":"## Create X_test\nHere we will use the test generator with a batch size of len(df_test) to create X_test and Y_test. Because the batch size is equal to the number of rows in df_test, the generator will ouput the entire\ntest set (100 rows) as a matrix.","917e675e":"### Check the class distribution","3f783f63":"### How many channels do the images in each dataset have?","d1074768":"We are working with two Kaggle datasets:<br>\n\n>  **1. Pulmonary Chest X-Ray Abnormalities by Kevin Mader**<br>\n>  **2. Lung Masks for Shenzhen Hospital Chest X-ray Set by yoctoman**\n  \n  \n\nThe Pulmonary Chest X-Ray Abnormalities dataset has data from two sources namely, Shenzhen and Montgomery.\n\n - The Shenzhen data has 662 chest x-ray images.\n - The Montgomery data has 138 chest x-ray images, 138 left lung masks and 138 right lung masks.\n - The Lung Masks for Shenzhen Hospital Chest X-ray dataset has lung masks for 566 of the 662 Shenzhen x-ray images. \n\n","98edc83d":"### What are the labels?\nThe pulmonary-chest-xray-abnormalities dataset includes labels that specify which x-ray images display signs of tuberculosis and which don't. We will use this target info later when we do a stratified train test split.","537b38c4":"## Check for non image files","85c47c9e":"## Display one Shenzhen image and mask\n\nEach Shenzhen image file name has the following format:\nCHNCXR_0001_0.png\n\n\nThe corresponding mask file name has the following format: CHNCXR_0001_0_mask.png\n\nEach mask includes both the left and right lungs.","a845bfc7":"- Keras U-Net starter - LB 0.277<br>\nhttps:\/\/www.kaggle.com\/keegil\/keras-u-net-starter-lb-0-277\n\n- Python Generators to reduce RAM usage [ Part 2 ]<br>\nhttps:\/\/www.kaggle.com\/vbookshelf\/python-generators-to-reduce-ram-usage-part-2\n\n- Selfie Segmenter - Keras and Unet<br>\nhttps:\/\/www.kaggle.com\/vbookshelf\/selfie-segmenter-keras-and-u-net","beee6004":"## Move all the images into the same directory","400d536a":"## Approach\n\n- Resize images and masks to 128x128\n- Set aside 100 images as a holdout test set.\n- Split the remainder of the data into 85% train and 15% validation.\n- Use a Keras U-Net model architecture with Adam optimizer and binary crossentropy loss.\n- The only pre-processing will be to normalize the images by dividing by 255.\n- We won't use any data augmentation.","f7d17d94":"These csv files will allow us to use Pandas chunking to feed images into the generators.","f0beb865":"## Data Summary","7421f999":"## Model Architecture","0482e3fb":"## Build the Data Generators","aea4cfb4":"### Display a ramdom sample of images from each dataset by target","2049a9cc":"We see that all images have 3 channels. The images have a pixel value range between 0 and 255.","d4864084":"## Create a holdout test set\n\nThis will be set aside and won't be used during training and validation. We will use it later to check how the trained model performs on unseen data.","2ed621b4":"### How many images are in each folder?\nNote: In the Montgomery images, Montgomery left masks and Shenzhen image folder there is a non image file called 'Thumbs.db'","97b2a516":"<img src=\"http:\/\/lung.test.woza.work\/assets\/webpage.png\" width=\"600\"><\/img>\n\n<h5 align=\"center\">Output from the web app<\/h5>","11621111":"### [ 1 ] Train Generator","b13ea1f2":"## Reference Kernels","4f19e621":"The results look fine. There's a clear separation between both lungs. Since we are only using the predictions to demonstrate how the app works, the quality of these segmentations is adequate for our needs. ","763f749b":"## Lung Segmenter\nby Marsh [ @vbookshelf ]<br>\n4 December 2019","5bffe46b":"## Display one Montgomery image and mask\nIn the Mongomery dataset there are separate masks for the left lung and right lung. We will combine these two masks into one by simply adding the matrices. Each mask has the same file name as it's corresponding image.","fff37951":"### Threshold the predictions","c351c27a":"We don't have masks for all Shenzhen images. Therefore, let's remove images from df_shen that don't have masks. We will do this by doing a dataframe merge. This will only keep rows that are common to both dataframes. Therefore, image_id's that are not in df_shen_masks will be removed from the new merged dataframe.","ec1c71a6":"## Save the dataframes as compressed csv files","4b29fc17":"## Overlay pred masks, true masks and the x-ray image\n\nRed - True Mask<br>\nBlue - Pred Mask","b72010ac":"### [ 2 ] Val Generator","b7e87d4c":"The ouput from a generator does not accumulate in memory. Each output batch overwrites the last one. This means that we can feed large amounts of data into a model without running out of RAM and crashing the kernel. There's a 13GB RAM limit when using a GPU.\n\nWe will use Pandas chunking and the compressed csv files to feed data into the generators. Using chunking simplifies the code. For example, the last batch that is fed into a generator will be smaller than the others. Pandas chunking will handle this change in batch size automatically which means that we won't need to write code to handle this condition.\n\nChunking is very useful when the csv file data is too large to be loaded into memory i.e. into a single Pandas dataframe.\n\nIf you would like to understand how generators work please refer to this notebook:<br>\nhttps:\/\/www.kaggle.com\/vbookshelf\/python-generators-to-reduce-ram-usage-part-2\n","92ea8672":"### Create a Dataframe containing all images","a0fd9992":"Many thanks to Kevin Mader and to yoctoman for making this data available on Kaggle.\n\nIf you would like to learn how to build apps like this I recommend this video tutorial:<br>\nhttps:\/\/www.youtube.com\/watch?v=HEQDRWMK6yY\n\nI've also included a few practical tips on the readme page in this repo:<br>\nhttps:\/\/github.com\/vbookshelf\/Skin-Lesion-Analyzer\n\nThank you for reading.","fdd6c8c7":"## Conclusion","adb257fc":"In this test generator we will output both the test images (X_test) and the test masks (Y_test). ","3fb87d1c":"## Train Test Split","2ce4efdb":"U-Net seems to be quite sensitive to the initialization weights. This means that every time a model is run the quality of the output segmentations will be different. They are sometimes good and sometimes very poor.To solve this problem I've added a seed to each of the layers to try to fix the initial weights.","b5b4706d":"## Make a test set prediction","b3a7b1fa":"## Introduction","fa19dfc5":"### What is the shape of each image and what are its max and min pixel values?\nLet's include all this info in the dataframes we created above.","8265e06d":"## Results","95bcbb73":"### Assign labels to the images","fa7df42e":"### Create a dataframe containing all images","f75fdde4":"## Convert the Model to Tensorflow.js","451a835b":"My goal for this exercise was to develop the Python, HTML, CSS and Javascript workflow that would make it possible for a Tensorflow.js web app to display a segmented image inside a web browser. For visual context the segmented image is overlayed on the original image. An example output is shown in the picture above.\n\nThis same code structure can be used to build web apps for other problems that combine prediction and segmentation. One drawback I found was that inference takes about 30 seconds when large images are submitted to the app. That's a long time in the web world - online users don't like waiting. This aspect of the user experience needs to be optimized.\n\nIn this notebook we will build a Keras model that will take a chest x-ray as input and output a segmented image showing only the lungs. This trained model has been loaded into a Tensorflow.js web app and deployed online.\n\n> Web App<br>\n> http:\/\/lung.test.woza.work\/<br>\n> \n> Github<br>\n> https:\/\/github.com\/vbookshelf\/Lung-Segmenter\n\n*For best results I suggest using the Chrome browser to run the app.*\n","25766f78":"The predictions are actually probabilities that a pixel is either part of a lung or part of the background. Here we threshold the predictions to convert all values to either 0 or 1.\n\nWe will use a threshold of 0.7. I got this number by trial and error - try a threshold value and look at the quality of the test set segmentations. ","d1d88b71":"## Train the Model"}}