{"cell_type":{"57d14e94":"code","1474c2e8":"code","2186e90c":"code","f1ba1b1f":"code","e9b0bf8c":"code","b5c91751":"code","d784578e":"code","ade94708":"code","1a4114fb":"code","bb3fda33":"code","06a2d5d8":"code","dd2c0b18":"code","1eafbe31":"code","f88fd65d":"code","72d4fc43":"markdown","89c6272a":"markdown","653f267e":"markdown"},"source":{"57d14e94":"# https:\/\/github.com\/KirillTushin\/target_encoding\n","1474c2e8":"import os\nos.chdir('..\/input\/target-encoding')\nfrom target_encoding import TargetEncoderClassifier, TargetEncoder\nos.chdir('\/kaggle\/working')\n\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score","2186e90c":"%%time\n# Only load those columns in order to save space\nkeep_cols = ['event_id', 'game_session', 'installation_id', 'event_count', 'event_code', 'title', 'game_time', 'type', 'world']\n\ntrain = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/train.csv', usecols=keep_cols)\ntest = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/test.csv', usecols=keep_cols)\ntrain_labels = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/train_labels.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/data-science-bowl-2019\/sample_submission.csv')","f1ba1b1f":"def group_and_reduce(df):\n    # group1 and group2 are intermediary \"game session\" groups,\n    # which are reduced to one record by game session. group1 takes\n    # the max value of game_time (final game time in a session) and \n    # of event_count (total number of events happened in the session).\n    # group2 takes the total number of event_code of each type\n    group1 = df.drop(columns=['event_id', 'event_code']).groupby(\n        ['game_session', 'installation_id', 'title', 'type', 'world']\n    ).max().reset_index()\n\n    group2 = pd.get_dummies(\n        df[['installation_id', 'event_code']], \n        columns=['event_code']\n    ).groupby(['installation_id']).sum()\n\n    # group3, group4 and group5 are grouped by installation_id \n    # and reduced using summation and other summary stats\n    group3 = pd.get_dummies(\n        group1.drop(columns=['game_session', 'event_count', 'game_time']),\n        columns=['title', 'type', 'world']\n    ).groupby(['installation_id']).sum()\n\n    group4 = group1[\n        ['installation_id', 'event_count', 'game_time']\n    ].groupby(\n        ['installation_id']\n    ).agg([np.sum, np.mean, np.std])\n\n    return group2.join(group3).join(group4).reset_index()","e9b0bf8c":"%%time\ntrain = group_and_reduce(train)\ntest = group_and_reduce(test)\n\nprint(train.shape)\ntrain.head()","b5c91751":"labels = train_labels[['installation_id', 'accuracy_group']]\ntrain = train.merge(labels, how='left', on='installation_id').dropna()","d784578e":"x_train, x_val, y_train, y_val = train_test_split(\n    train.drop(['installation_id', 'accuracy_group'], axis=1),\n    train['accuracy_group'],\n    test_size=0.15,\n    random_state=2019,\n)","ade94708":"len_uniques = []\ntrain_labeled = train.fillna(-999)\ntest_labeled = test.fillna(-999)\n\nfor c in train.columns.drop(['installation_id', 'accuracy_group']):\n    le = LabelEncoder()\n    le.fit(pd.concat([train_labeled[c], test_labeled[c]])) \n    train_labeled[c] = le.transform(train_labeled[c])\n    test_labeled[c] = le.transform(test_labeled[c])\n    len_uniques.append(len(le.classes_))\n\nx_train_labeled, x_val_labeled = train_test_split(\n    train_labeled.drop(['installation_id', 'accuracy_group'], axis=1),\n    test_size=0.15,\n    random_state=2019,\n)","1a4114fb":"ALPHA = 10\nMAX_UNIQUE = 50\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n\n","bb3fda33":"'''\nsplit: list of int or cross-validator class,\n            if split is [], then algorithm will encode features without cross-validation\n            This situation features will overfit on target\n\n            if split len is 1 for example [5], algorithm will encode features by using cross-validation on 5 folds\n            This situation you will not overfit on tests, but when you will validate, your score will overfit\n\n            if split len is 2 for example [5, 3], algorithm will separate data on 5 folds, afterwords\n            will encode features by using cross-validation on 3 folds\n            This situation is the best way to avoid overfit, but algorithm will use small data for encode.\n'''\n\n\nenc = TargetEncoder(alpha=ALPHA, max_unique=MAX_UNIQUE, split=[cv])\nx_train_encoded = enc.transform_train(x_train_labeled, y=y_train)\nx_val_encoded = enc.transform_test(x_val_labeled)\nx_test_encoded = enc.transform_test(test.drop(['installation_id'], axis=1))\n\nx_train_encoded = pd.DataFrame(x_train_encoded)\nx_val_encoded = pd.DataFrame(x_val_encoded)\nx_test_encoded = pd.DataFrame(x_test_encoded)","06a2d5d8":"x_train_all = pd.concat([x_train.reset_index(drop=True), x_train_encoded], axis=1)\nx_val_all = pd.concat([x_val.reset_index(drop=True), x_val_encoded], axis=1)\nx_test_all = pd.concat([test.drop(['installation_id'], axis=1), x_test_encoded], axis=1)","dd2c0b18":"train_set = lgb.Dataset(x_train_all, y_train)\nval_set = lgb.Dataset(x_val_all, y_val)\n\nparams = {\n    'learning_rate': 0.01,\n    'bagging_fraction': 0.9,\n    'feature_fraction': 0.9,\n    'num_leaves': 14,\n    'lambda_l1': 0.1,\n    'lambda_l2': 1,\n    'metric': 'multiclass',\n    'objective': 'multiclass',\n    'num_classes': 4,\n    'random_state': 2019\n}\n\nmodel = lgb.train(params, train_set, num_boost_round=10000, early_stopping_rounds=300, valid_sets=[train_set, val_set], verbose_eval=100)","1eafbe31":"val_pred = model.predict(x_val_all).argmax(axis=1)\nprint(classification_report(y_val, val_pred))","f88fd65d":"y_pred = model.predict(x_test_all).argmax(axis=1)\ntest['accuracy_group'] = y_pred\ntest[['installation_id', 'accuracy_group']].to_csv('submission.csv', index=False)","72d4fc43":"# Group and Reduce","89c6272a":"# Training model","653f267e":"# Load Data"}}