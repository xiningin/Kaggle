{"cell_type":{"839439e1":"code","e847160f":"code","29f015e8":"code","484c9e09":"markdown"},"source":{"839439e1":"import torch, torchvision\nfrom pathlib import Path\nimport numpy as np\nimport cv2\nimport pandas as pd\nfrom tqdm import tqdm\nimport PIL.Image as Image\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\nfrom matplotlib.ticker import MaxNLocator\nfrom torch.optim import lr_scheduler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom glob import glob\nimport shutil\nfrom collections import defaultdict\nfrom torch import nn, optim\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nfrom torchvision import models\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\nHAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\nrcParams['figure.figsize'] = 12, 8\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","e847160f":"!wget https:\/\/sid.erda.dk\/public\/archives\/daaeac0d7ce1152aea9b61d9f1e19370\/GTSRB_Final_Training_Images.zip\n","29f015e8":"!unzip -qq GTSRB_Final_Training_Images.zip","484c9e09":"Ref: https:\/\/www.youtube.com\/watch?v=yYlVOrbV_KY"}}