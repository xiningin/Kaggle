{"cell_type":{"201d501c":"code","a1c0a5ca":"code","3424b714":"code","1b9e0c41":"code","f204e027":"code","cd3b5871":"code","28a15408":"code","82dfda36":"code","099c619a":"code","f7f42849":"code","fc29563f":"code","e27afea5":"code","2cebcfd2":"code","eb5834b3":"code","56c7c5fd":"code","9d0484dc":"code","dd6b8ced":"code","bd5c1fe0":"code","dc0414cc":"code","544220df":"code","faf1ad74":"code","ddf64b0b":"code","b0dcbcff":"code","59ed7301":"code","10d14eae":"code","59672708":"code","20a53626":"code","238eaad9":"code","3ef77f3b":"code","842ba5ab":"code","e77c2b96":"code","658f577b":"code","649a889e":"code","f4c263be":"code","d23d27bf":"code","ab15f1a6":"code","1da051b3":"code","5fbba565":"code","2a000a96":"code","012bba19":"code","f939c2b6":"code","ea552c76":"code","15428c44":"code","9ccd7dfe":"code","3fa380ef":"code","65e236d1":"code","d2489dcf":"code","901baa0d":"code","be295894":"code","bd5b3bcb":"code","74b448fb":"code","7c4ed7df":"code","26a369fa":"code","07ad60b2":"code","676b6a0c":"markdown","4c5bb1cb":"markdown","26d2971f":"markdown","e3e762f5":"markdown","f2376ae8":"markdown","b9a88fd6":"markdown","03d68983":"markdown","b5a0ecd6":"markdown","ac79aaba":"markdown","20dab284":"markdown"},"source":{"201d501c":"!pip install mtcnn\n!pip install gdown\n!pip install keras_vggface\n!pip install natsort\n!pip install keras_applications\nimport os\nimport cv2\nimport random\nimport glob\nimport gdown\nimport tarfile\nimport zipfile\nimport shutil\n\nimport numpy as np\nimport tensorflow as tf\n\nfrom os import path\nfrom matplotlib import pyplot as plt\n# from google.colab.patches import cv2_imshow\nfrom PIL import Image\nfrom mtcnn import MTCNN\nfrom skimage import feature\nfrom natsort import natsorted\nfrom sklearn.svm import LinearSVC\nfrom scipy.spatial.distance import cosine\nfrom keras_vggface.vggface import VGGFace\nfrom keras_vggface.utils import preprocess_input\nfrom keras_vggface.utils import decode_predictions\nfrom sklearn.preprocessing import OneHotEncoder\nfrom tensorflow.python.keras.models import Model\n\n\"\"\" Metrics import \"\"\"\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import f1_score\nfrom scipy.optimize import brentq\nfrom scipy.interpolate import interp1d\nfrom sklearn.metrics import roc_curve, auc\n# from CMC import CMC","a1c0a5ca":"def unzip_file(_file, destination):\n    with zipfile.ZipFile(_file, 'r') as zip_ref:\n        zip_ref.extractall(destination)\n    os.remove(_file)\n","3424b714":"def get_dataset(output, destination, url):\n  try:\n    gdown.download(url, output, quiet=False)\n    unzip_file(output, destination)\n  except Exception:\n    raise ConnectionError('you need to be connected to some internet network to download the database.')\n","1b9e0c41":"def load_dataset(_path):\n    destination = _path + '\/arface'\n    dataset_file = destination + '\/arface.zip'\n\n    if not path.isdir(destination):\n        os.mkdir(destination)\n\n    if not path.isdir(destination + '\/mtcnn_detect'):\n        os.mkdir(destination + '\/mtcnn_detect')\n\n    if not path.isdir(destination + '\/training'):\n        os.mkdir(destination + '\/training')\n        os.mkdir(destination + '\/test')\n\n    if not path.isdir(destination + '\/lbp-detected'):\n        os.mkdir(destination + '\/lbp-detected')\n\n    if not path.isdir(destination + '\/vgg-detected'):\n        os.mkdir(destination + '\/vgg-detected')  \n\n    if not path.isdir(destination + '\/face'):\n        get_dataset(dataset_file, destination, 'https:\/\/drive.google.com\/u\/2\/uc?export=download&confirm=HiLF&id=1BQuEQfmMiA_cEYmvkQDCnYAJd_TT3rCk')\n    elif path.isfile(dataset_file):\n        unzip_file(dataset_file, destination)\n    else:\n        if path.isdir(destination + '\/face'):\n            print('INFO: Dataset is set!')\n        else:\n            raise OSError(\n                'the default directory of Python is not found.')\n","f204e027":"os.environ['DISPLAY'] = ':0'\n\n_path = path.abspath(os.getcwd())\n\nprint('INFO: Dataset verify')\nload_dataset(_path)\n\n_path1 = _path + '\/arface'\n_path2 = _path + '\/ocular'\n_path3 = _path + '\/equalized-face'\n_path4 = _path + '\/equalized-ocular'","cd3b5871":"''' import shutil\nimport os\n\n_path = os.path.abspath(os.getcwd())\ndestination = _path4\nshutil.rmtree(destination) '''","28a15408":"def has_files(_path):\n    files = glob.glob(path.join(_path, \"*.bmp\")).copy()\n    return True if len(files) else False\n","82dfda36":"def plot_poits(_image, detected_face):\n  if len(detected_face):\n    x1,y1,x2,y2 = detected_face[0]['box']\n    _image = cv2.rectangle(_image, (x1, y1), (x2, y2), (255,0,0), 2)\n    for point in detected_face[0]['keypoints'].values():\n      x,y = point\n      _image = cv2.circle(_image, (x,y), radius=1, color=(0, 0, 255), thickness=3)\n  return _image","099c619a":"def get_random_image(_path):\n  return random.choice(glob.glob(path.join(_path, \"*.bmp\")))","f7f42849":"def copy_file(file, destination):\n    if not path.isfile(destination):\n        shutil.copy2(file, destination)\n","fc29563f":"def save_file(detected_face, img, destination, file_name, required_size=(224, 224)):\n    x1, y1, width, height = detected_face[0]['box']\n    x2, y2 = x1 + width, y1 + height\n    y1 = y1 if y1 >= 0 else 0\n    y2 = y2 if y2 >= 0 else 0\n    x1 = x1 if x1 >= 0 else 0\n    x2 = x2 if x2 >= 0 else 0\n\n    y1 = y1 if y1 <= img.shape[0] else img.shape[0]\n    y2 = y2 if y2 <= img.shape[0] else img.shape[0]\n    x1 = x1 if x1 <= img.shape[1] else img.shape[1]\n    x2 = x2 if x2 <= img.shape[1] else img.shape[1]\n\n    face = img[y1:y2, x1:x2]\n    image = Image.fromarray((face).astype(np.uint8))\n    image = image.resize(required_size)\n    image.save(destination+os.path.sep+file_name)\n","e27afea5":"def detect_faces_mtcnn(_path):\n  if not has_files(_path+'\/mtcnn_detect'):\n    get_dataset(_path+'\/mtcnn.zip', _path,'https:\/\/drive.google.com\/u\/2\/uc?export=download&confirm=HiLF&id=1t9qlGs3VNvTWbjAL1-r5dRqn9DxyfipX')\n","2cebcfd2":"print('INFO: Run MTCNN')\ndetect_faces_mtcnn(_path1)","eb5834b3":"def divide_dataset(_path, _path_destination, percentage_train=80, percentage_test=20):\n    pictures = glob.glob(path.join(_path_destination, \"*.bmp\")).copy()\n    training_path = _path+'\/training'\n    test_path = _path+'\/test'\n\n    total_images = len(pictures)\n\n    percentage_train = (percentage_train\/100)\n    percentage_test = (percentage_test\/100)\n\n    if has_files(training_path):\n        print('Dataset already is divided!')\n        return 0\n\n    if percentage_train + percentage_test < 1 \\\n            or percentage_train + percentage_test > 1:\n        raise ValueError('invalid train\/test percentage.')\n\n    i = 0\n    while i < int(total_images*percentage_train):\n        rand_image = random.choice(pictures)\n        copy_file(rand_image, training_path)\n        pictures.remove(rand_image)\n        i += 1\n\n    i = 0\n    while i < len(pictures):\n        rand_image = random.choice(pictures)\n        copy_file(rand_image, test_path)\n        pictures.remove(rand_image)\n        i += 1","56c7c5fd":"print('INFO: Divide dataset')\ndivide_dataset(_path1, _path1 + '\/mtcnn_detect',80, 20)","9d0484dc":"def calcule_f1(predicted, true):\n    f1_value = f1_score(true, predicted, average='micro')\n    print('F1 Score: ', f1_value)\n    return f1_value","dd6b8ced":"def compute_precision_recall(label, score):\n    Y = OneHotEncoder().fit_transform(np.array(label).reshape(-1, 1)).toarray()\n\n    precision = dict()\n    recall = dict()\n    average_precision = dict()\n\n    for i in range(Y.shape[1]):\n        precision[i], recall[i], _ = precision_recall_curve(\n            Y[:, i], score[:, i])\n        average_precision[i] = average_precision_score(Y[:, i], score[:, i])\n\n    precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(\n        Y.ravel(), score[:, :Y.shape[1]].ravel())\n    average_precision[\"micro\"] = average_precision_score(\n        Y, score[:, :Y.shape[1]], average=\"micro\")\n\n    plt.figure()\n    plt.step(recall['micro'], precision['micro'], where='post')\n\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title(\n        'Average precision score, micro-averaged over all classes: AP={0:0.2f}'\n        .format(average_precision[\"micro\"]))\n    plt.show()","bd5c1fe0":"import os\nimport matplotlib.pyplot as plt\nimport matplotlib.lines as mlines\n\ndefault_color = ['r', 'g', 'b', 'c', 'm', 'y', 'orange', 'brown']\ndefault_marker = ['*', 'o', 's', 'v', 'X', '*', '.', 'P']\n\n\nclass CMC:\n    def __init__(self, cmc_dict, color=default_color, marker=default_marker):\n        self.color = color\n        self.marker = marker\n        self.cmc_dict = cmc_dict\n\n    def plot(self, title, rank=20, xlabel='Rank', ylabel='Matching Rates (%)', show_grid=True):\n        fig, ax = plt.subplots()\n        fig.suptitle(title)\n        x = list(range(0, rank+1, 5))\n        plt.ylim(0, 1.0)\n        plt.xlim(1, rank)\n        plt.xlabel(xlabel)\n        plt.ylabel(ylabel)\n        plt.xticks(x)\n        plt.grid(show_grid)\n\n        method_name = []\n        i = 0\n        for name in self.cmc_dict.keys():\n            if rank < len(self.cmc_dict[name]):\n                temp_cmc = self.cmc_dict[name][:rank]\n                r = list(range(1, rank+1))\n            else:\n                temp_cmc = self.cmc_dict[name]\n                r = list(range(1, len(temp_cmc)+1))\n\n            if name == list(self.cmc_dict.keys())[-1]:\n\n                globals()[name] = mlines.Line2D(r, temp_cmc, color=self.color[0],\n                                                marker=self.marker[0], label='{:.1f}% {}'.format(self.cmc_dict[name][0]*100, name))\n            else:\n                globals()[name] = mlines.Line2D(r, temp_cmc, color=self.color[i+1],\n                                                marker=self.marker[i+1], label='{:.1f}% {}'.format(self.cmc_dict[name][0]*100, name))\n                i = i+1\n            ax.add_line(globals()[name])\n            method_name.append(globals()[name])\n\n        plt.legend(handles=method_name)\n        plt.show()\n\n    def save(self, title, filename,\n             rank=20, xlabel='Rank',\n             ylabel='Matching Rates (%)', show_grid=True,\n             save_path=os.getcwd(), format='png', **kwargs):\n        fig, ax = plt.subplots()\n        fig.suptitle(title)\n        x = list(range(0, rank+1, 5))\n        plt.ylim(0, 1.0)\n        plt.xlim(1, rank)\n        plt.xlabel(xlabel)\n        plt.ylabel(ylabel)\n        plt.xticks(x)\n        plt.grid(show_grid)\n\n        method_name = []\n        i = 0\n        for name in self.cmc_dict.keys():\n            if rank < len(self.cmc_dict[name]):\n                temp_cmc = self.cmc_dict[name][:rank]\n                r = list(range(1, rank+1))\n            else:\n                temp_cmc = self.cmc_dict[name]\n                r = list(range(1, len(temp_cmc)+1))\n\n            if name == list(self.cmc_dict.keys())[-1]:\n                globals()[name] = mlines.Line2D(r, temp_cmc, color='r', marker='*',\n                                                label='{:.1f}% {}'.format(self.cmc_dict[name][0]*100, name))\n            else:\n                globals()[name] = mlines.Line2D(r, temp_cmc, color=self.color[i],\n                                                marker=self.marker[i], label='{:.1f}% {}'.format(self.cmc_dict[name][0]*100, name))\n                i = i+1\n            ax.add_line(globals()[name])\n            method_name.append(globals()[name])\n\n        plt.legend(handles=method_name)\n        fig.savefig(os.path.join(save_path, filename+'.'+format),\n                    format=format,\n                    bbox_inches='tight',\n                    pad_inches=0, **kwargs)","dc0414cc":"def making_cmc(values, keys):\n    i = 0\n    default_array = []\n    cmc_dict = {}\n\n    while i < 5:\n        default_array.append(keys.index(random.choice(keys)))\n        i += 1\n\n    i = 0\n    while i < len(default_array):\n        cmc_dict[keys[default_array[i]]] = values[[default_array[i]]].squeeze().tolist()\n        i += 1\n\n    cmc = CMC(cmc_dict)\n    cmc.plot(title='CMC', xlabel='Rank Score', ylabel='Recognition Rate')","544220df":"def make_roc_curve(label, score):\n    Y = OneHotEncoder().fit_transform(np.array(label).reshape(-1, 1)).toarray()\n\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    for i in range(Y.shape[1]):\n        fpr[i], tpr[i], _ = roc_curve(Y[:, i], score[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(\n        Y.ravel(), score[:, :Y.shape[1]].ravel())\n    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n    plt.figure(1)\n    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n             label='micro-average ROC curve (area = {0:0.2f})'\n             ''.format(roc_auc[\"micro\"]),\n             color='deeppink', linestyle=':', linewidth=4)\n\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    eer(fpr[\"micro\"], tpr[\"micro\"])","faf1ad74":"def eer(fpr_list, tpr_list):\n    err = brentq(lambda x: 1. - x - interp1d(fpr_list, tpr_list)(x), 0., 1.)\n    print(err)\n    return err\n","ddf64b0b":"\nclass LocalBinaryPatterns:\n    def __init__(self, num_points, radius):\n        self.numPoints = num_points\n        self.radius = radius\n\n    def describe(self, image, eps=1e-5):\n        lbp = feature.local_binary_pattern(image, self.numPoints,\n                                           self.radius, method=\"uniform\")\n        (hist, _) = np.histogram(lbp.ravel(),\n                                 bins=np.arange(0, self.numPoints + 3),\n                                 range=(0, self.numPoints + 2))\n\n        hist = hist.astype(\"float\")\n        hist \/= (hist.sum() + eps)\n\n        return hist\n","b0dcbcff":"def run_lbp(_path):\n    desc = LocalBinaryPatterns(40, 8)\n    faces = []\n    labels = []\n    pictures = glob.glob(path.join(_path, \"*.bmp\")).copy()\n    pictures = natsorted(pictures)\n\n    for _file in pictures:\n        try:\n            gray_img = cv2.cvtColor(cv2.imread(_file), cv2.COLOR_BGR2GRAY)\n            hist = desc.describe(gray_img)\n\n            if len(hist) > 0:\n                labels.append(\n                    ''.join(_file.split(os.path.sep)[-1].split('-')[0:2]))\n                faces.append(hist)\n        except Exception:\n            pass\n\n    model = LinearSVC(C=100.0, random_state=42)\n    model.fit(faces, labels)\n\n    return faces, labels, model","59ed7301":"def classify_lbp(_path, model):\n    desc = LocalBinaryPatterns(40, 8)\n    hit = 0\n    miss = 0\n    hist_list = []\n    label_list = []\n    predicted_values_list = []\n\n    pictures = glob.glob(path.join(_path+'\/test', \"*.bmp\")).copy()\n    pictures = natsorted(pictures)\n\n    for _file in pictures:\n        image = cv2.imread(_file)\n        gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        hist = desc.describe(gray_img)\n        prediction = model.predict(hist.reshape(1, -1))\n        correct_class = ''.join(_file.split(os.path.sep)[-1].split('-')[0:2])\n\n        if prediction[0] == correct_class:\n            hit += 1\n        else:\n            miss += 1\n\n        cv2.putText(image, prediction[0], (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n                    1.0, (0, 0, 255), 3)\n        cv2.imwrite(_path+'\/lbp-detected\/'+_file.split(os.path.sep)[-1], image)\n\n        hist_list.append(hist.reshape(1, -1))\n        label_list.append(correct_class)\n        predicted_values_list.append(prediction[0])\n\n    calcule_f1(predicted_values_list, label_list)\n    data = np.array(hist_list).squeeze()\n    score = model.decision_function(data)\n    making_cmc(score, label_list)\n    compute_precision_recall(label_list, score)\n    make_roc_curve(label_list, score)\n\n    print(hit, miss)\n    return hit, miss","10d14eae":"print('INFO: Run LBP')\n(faces_desc_lbp, labels_face_lbp, lbp_face_model) = run_lbp(_path1 + '\/training')","59672708":"print('INFO: Classifing Images (LBP)')\nclassify_lbp(_path1, lbp_face_model)","20a53626":"def run_vgg(_model, _path):\n    pictures = glob.glob(path.join(_path+'\/training', \"*.bmp\")).copy()\n    pictures = natsorted(pictures)\n\n    faces = []\n    labels = []\n\n    for _file in pictures:\n        try:\n            img = cv2.cvtColor(cv2.imread(_file), cv2.COLOR_BGR2RGB)\n            labels.append(\n                ''.join(_file.split(os.path.sep)[-1].split('-')[0:2]))\n            faces.append(img)\n        except Exception:\n            pass\n\n    encoded_labels = OneHotEncoder().fit_transform(\n        np.array(labels).reshape(-1, 1)).toarray()\n\n    model = define_vgg_model(_model, len(np.unique(np.array(labels))))\n    model.fit(np.array(faces), encoded_labels, epochs=2)\n\n    return faces, labels, model","238eaad9":"def define_vgg_model(_mode, num_class):\n    base_model = VGGFace(model='resnet50', include_top=False)\n    x = base_model.output\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(256, activation='elu', name='fc1')(x)\n    x = tf.keras.layers.Dense(196, activation='elu', name='fc2')(x)\n    x = tf.keras.layers.Dropout(0.2)(x)\n\n    predictions = tf.keras.layers.Dense(\n        num_class, activation='softmax', name='predictions')(x)\n    model = Model(base_model.input, predictions)\n\n    for layer in model.layers:\n        layer.trainable = False\n\n    model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n\n    return model","3ef77f3b":"def classify_vgg(_path, model, labels):\n    hit = 0\n    miss = 0\n    label_list = []\n    score_list = []\n    predicted_values_list = []\n\n    pictures = glob.glob(path.join(_path+'\/test', \"*.bmp\")).copy()\n    pictures = natsorted(pictures)\n\n    encoder = OneHotEncoder()\n    encoded_labels = encoder.fit_transform(\n        np.array(labels).reshape(-1, 1)).toarray()\n    encoder.fit_transform(np.array(labels).reshape(-1, 1))\n    labels = encoder.inverse_transform(encoded_labels)\n\n    for _file in pictures:\n        image = cv2.imread(_file)\n        rgb_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype('float32')\n        samples = np.expand_dims(rgb_img, axis=0)\n        samples = preprocess_input(samples, version=2)\n        prediction = model.predict(samples)\n        correct_class = ''.join(_file.split(os.path.sep)[-1].split('-')[0:2])\n\n        idx_best_prediction = np.argmax(prediction[0])\n        best_prediction = labels[idx_best_prediction][0]\n\n        if best_prediction == correct_class:\n            hit += 1\n        else:\n            miss += 1\n\n        cv2.putText(image, best_prediction, (10, 30),\n                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)\n        cv2.imwrite(_path+'\/vgg-detected\/'+_file.split(os.path.sep)[-1], image)\n\n        label_list.append(correct_class)\n        score_list.append(prediction)\n        predicted_values_list.append(best_prediction)\n\n    calcule_f1(predicted_values_list, label_list)\n    making_cmc(np.array(score_list).squeeze(), label_list)\n    compute_precision_recall(label_list, np.array(score_list).squeeze())\n    make_roc_curve(label_list, np.array(score_list).squeeze())\n\n    print(hit, miss)\n    return hit, miss","842ba5ab":"print('INFO: Run VGGFACE')\n(faces_desc_vgg, labels_face_vgg, vgg_face_model) = run_vgg('resnet50', _path1)","e77c2b96":"print('INFO: Classifing Images (VGGFACE2)')\nclassify_vgg(_path1, vgg_face_model, labels_face_vgg)","658f577b":"# model_pic = _path + '\/model.png'\n# tf.keras.utils.plot_model(vgg_model, to_file=model_pic, show_shapes=True)","649a889e":"def load_dataset_ocular(_path):\n    destination_1 = _path + '\/ocular'\n    destination = _path + '\/arface'\n\n    if not path.isdir(destination):\n        os.mkdir(destination)\n\n    if not path.isdir(destination_1):\n        os.mkdir(destination_1)\n\n    if not path.isdir(destination_1 + '\/default_detect'):\n        os.mkdir(destination_1 + '\/default_detect')\n\n    if not path.isdir(destination_1 + '\/training'):\n        os.mkdir(destination_1 + '\/training')\n        os.mkdir(destination_1 + '\/test')\n\n    if not path.isdir(destination_1 + '\/lbp-detected'):\n        os.mkdir(destination_1 + '\/lbp-detected')\n\n    if not path.isdir(destination_1 + '\/vgg-detected'):\n        os.mkdir(destination_1 + '\/vgg-detected')","f4c263be":"print('INFO: Dataset verify (OCULAR)')\nload_dataset_ocular(_path)","d23d27bf":"def standardize_images_ocular(_paths, destination):\n    if has_files(destination):\n        print('Dataset is already standardized!')\n        return 0\n\n    for _path in _paths:\n        pictures = glob.glob(path.join(_path, \"*.bmp\")).copy()\n        pictures = natsorted(pictures)\n\n        for _file in pictures:\n            img = cv2.cvtColor(cv2.imread(_file), cv2.COLOR_BGR2RGB)\n            save_file_ocular(img, destination, _file.split(os.path.sep)[-1])","ab15f1a6":"def save_file_ocular(img, destination, file_name, required_size=(224, 224)):\n    image = Image.fromarray((img).astype(np.uint8))\n    image = image.resize(required_size)\n    image.save(destination+os.path.sep+file_name)","1da051b3":"print('INFO: Standardize Images')\nstandardize_images_ocular([_path1 + '\/left', _path1 + '\/right'],\n                          _path2 + '\/default_detect')","5fbba565":"print('INFO: Divide dataset (OCULAR)')\ndivide_dataset(_path2, _path2 + '\/default_detect',80, 20)","2a000a96":"print('INFO: Run LBP (OCULAR)')\n(oc_regions_desc_lbp, oc_regions_labels_lbp, oc_regions_lbp_model) = run_lbp(_path2 + '\/training')","012bba19":"print('INFO: Classifing Images (LBP - OCULAR)')\nclassify_lbp(_path2, oc_regions_lbp_model)","f939c2b6":"print('INFO: Run VGGFACE (OCULAR)')\n(oc_regions_desc_vgg, oc_regions_labels_vgg, oc_regions_vgg_model) = run_vgg('resnet50', _path2)","ea552c76":"print('INFO: Classifing Images (VGGFACE2 - OCULAR)')\nclassify_vgg(_path2, oc_regions_vgg_model, oc_regions_labels_vgg)","15428c44":"def load_dataset_equalized(_path, names):\n    for name in names:\n        destination_1 = _path + '\/ocular'\n        destination_2 = _path + '\/' + name\n        destination = _path + '\/arface'\n\n        if not path.isdir(destination):\n            os.mkdir(destination)\n\n        if not path.isdir(destination_1):\n            os.mkdir(destination_1)\n\n        if not path.isdir(destination_2):\n            os.mkdir(destination_2)\n\n        if not path.isdir(destination_2 + '\/default_detect'):\n            os.mkdir(destination_2 + '\/default_detect')\n\n        if not path.isdir(destination_2 + '\/training'):\n            os.mkdir(destination_2 + '\/training')\n            os.mkdir(destination_2 + '\/test')\n\n        if not path.isdir(destination_2 + '\/lbp-detected'):\n            os.mkdir(destination_2 + '\/lbp-detected')\n\n        if not path.isdir(destination_2 + '\/vgg-detected'):\n            os.mkdir(destination_2 + '\/vgg-detected')","9ccd7dfe":"def histogram_equalization(_path_dataset, destination):\n    pictures = glob.glob(path.join(_path_dataset, \"*.bmp\")).copy()\n    pictures = natsorted(pictures)\n\n    for _file in pictures:\n        img = cv2.cvtColor(cv2.imread(_file), cv2.COLOR_BGR2HSV)\n        img[:, :, 2] = cv2.equalizeHist(img[:, :, 2])\n        image = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n\n        cv2.imwrite(destination+'\/'+_file.split(os.path.sep)[-1], image)","3fa380ef":"print('INFO: Dataset verify (EQUALIZED)')\n_path = path.abspath(os.getcwd())\n\nload_dataset_equalized(_path, ['equalized-face','equalized-ocular'])\n_path1 = _path + '\/arface'\n_path2 = _path + '\/ocular'\n_path3 = _path + '\/equalized-face'\n_path4 = _path + '\/equalized-ocular'","65e236d1":"print('INFO: Applying Equalization')\nhistogram_equalization(_path1 + '\/mtcnn_detect',_path3 + '\/default_detect')\nhistogram_equalization(_path2 + '\/default_detect', _path4 + '\/default_detect')","d2489dcf":"print('INFO: Divide dataset (EQUALIZED)')\ndivide_dataset(_path3, _path3 + '\/default_detect',80, 20)\ndivide_dataset(_path4, _path4 + '\/default_detect',80, 20)","901baa0d":"print('INFO: Run LBP (EQUALIZED)')\n(eql_face_desc_lbp, eql_face_labels_lbp, eql_face_lbp_model) = run_lbp(_path3 + '\/training')\n(eql_ocular_desc_lbp, eql_ocular_labels_lbp, eql_ocular_lbp_model) = run_lbp(_path4 + '\/training')","be295894":"print('INFO: Classifing Images (LBP - EQUALIZED)')\nclassify_lbp(_path3, eql_face_lbp_model)\nclassify_lbp(_path4, eql_ocular_lbp_model)","bd5b3bcb":"print('INFO: Run VGGFACE (EQUALIZED)')\n(eql_face_desc_vgg, eql_face_labels_vgg, eql_face_vgg_model) = run_vgg('resnet50', _path3)\n(eql_ocular_desc_vgg, eql_ocular_labels_vgg, eql_ocular_vgg_model) = run_vgg('resnet50', _path4)","74b448fb":"print('INFO: Classifing Images (VGGFACE2 - EQUALIZED)')\nclassify_vgg(_path3, eql_face_vgg_model, eql_face_labels_vgg)\nclassify_vgg(_path4, eql_ocular_vgg_model, eql_ocular_labels_vgg)","7c4ed7df":"def compare_images(_path, model, image1 = None, image2 = None):\n    pictures = glob.glob(path.join(_path + '\/mtcnn_detect', \"*.bmp\")).copy()\n    pic1 = image1 if image1 else random.choice(pictures)\n    print(pic1)\n    pic2 = image2 if image2 else random.choice(pictures)\n    print(pic2)\n\n    rand_image1 = cv2.cvtColor(cv2.imread(pic1), cv2.COLOR_BGR2RGB).astype('float32')\n    rand_image2 = cv2.cvtColor(cv2.imread(pic2), cv2.COLOR_BGR2RGB).astype('float32')\n\n    sample1 = np.expand_dims(rand_image1, axis=0)\n    sample1 = preprocess_input(sample1, version=2)\n\n    sample2 = np.expand_dims(rand_image2, axis=0)\n    sample2 = preprocess_input(sample2, version=2)\n\n    prediction1 = model.predict(sample1)\n    prediction2 = model.predict(sample2)\n\n    is_match(prediction1, prediction2)","26a369fa":"def is_match(known_embedding, candidate_embedding, thresh=0.5):\n    score = cosine(known_embedding, candidate_embedding)\n    if score <= thresh:\n        print('>face is a Match (%.3f <= %.3f)' % (score, thresh))\n    else:\n        print('>face is NOT a Match (%.3f > %.3f)' % (score, thresh))","07ad60b2":"print('INFO: Compare images')\ncompare_images(_path1, vgg_face_model)","676b6a0c":"# Import Libraries","4c5bb1cb":"# VGGFACE","26d2971f":"# Get Faces Dataset (ARFACE)\nFirst, we will check if the data set is here, if not, we will download it.\n","e3e762f5":"# Local Binary Pattern (LBP)","f2376ae8":"# Comparison Between Genuine and Imposter","b9a88fd6":"# Divide Dataset","03d68983":"# MTCNN Face Detection","b5a0ecd6":"# Ocular Detection","ac79aaba":"# Performance Metrics\nHere we use metrics like ROC, CMC, Rank-1, Precision-Recall, EER, F-Measure, AUC (Area Under Curve).","20dab284":"# Apply Filters\nIn this step, filters are placed randomly in the image, so that it is possible to visualize the influence of factors such as lighting, for example."}}