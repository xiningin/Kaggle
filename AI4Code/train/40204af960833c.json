{"cell_type":{"d951871e":"code","1c949048":"code","783c9d50":"code","ea1eedc3":"code","09157608":"code","4e091cd6":"code","b57bd7a3":"code","4e52c3cb":"code","8defde2b":"code","a5fc28d4":"code","9a7d6487":"code","e1ff77cf":"code","7c4e1dd5":"code","52ad4be4":"code","aca1e0ac":"code","0f0b3852":"code","5c3c4e3a":"code","f332e969":"code","edeb9ec6":"code","8f0958bf":"code","07d28fe3":"code","3c6eabf4":"code","e38f3be2":"code","870443f9":"code","2f1645ba":"code","c51b6b39":"code","bee0907c":"code","93d8b71c":"code","199e85a7":"code","fb88f454":"code","00bb448c":"code","36dbebeb":"code","d416d5c8":"markdown","40f2f545":"markdown","3706cbc0":"markdown","27653ae0":"markdown","6d73158f":"markdown","a74c1c36":"markdown","7f103ba4":"markdown","42990096":"markdown","6f347c1d":"markdown","e2da3888":"markdown","ee1216c6":"markdown","73b9bb76":"markdown","844ced1e":"markdown","64d313f4":"markdown","b8b71683":"markdown","431a7da4":"markdown","33c4e047":"markdown","d6251e04":"markdown","0f4cd494":"markdown"},"source":{"d951871e":"import numpy as np\nimport pandas as pd\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\npd.set_option(\"display.max_columns\", 25)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nnp.set_printoptions(suppress=True)","1c949048":"os.listdir(\"..\/input\/open-shopee-code-league-marketing-analytics\")","783c9d50":"train = pd.read_csv(\"..\/input\/open-shopee-code-league-marketing-analytics\/train.csv\")\ntest = pd.read_csv(\"..\/input\/open-shopee-code-league-marketing-analytics\/test.csv\")\nusers = pd.read_csv(\"..\/input\/open-shopee-code-league-marketing-analytics\/users.csv\")","ea1eedc3":"traintest = train.append(test)\ntraintest = traintest.merge(users, on = 'user_id', how= 'left')","09157608":"traintest.columns","4e091cd6":"used_cols= [\n            'subject_line_length', \n            'open_count_last_10_days', \n            'open_count_last_30_days', \n            'open_count_last_60_days',\n           ]","b57bd7a3":"traintest = traintest[['row_id', 'open_flag'] + used_cols ]","4e52c3cb":"traintest[used_cols].describe()","8defde2b":"traintest[used_cols].quantile([.75,.95, .999, 1.0])","a5fc28d4":"traintest.shape[0] * (1 - .999)","9a7d6487":"cuurent_cols = [ 'open_count_last_10_days', 'open_count_last_30_days', 'open_count_last_60_days']\ncurrent_threshold = [12, 30, 56]\n\nfor col, val in zip(cuurent_cols, current_threshold):\n    print(\"Change\", (traintest[col] > val).sum(), \"Rows from\", col)\n    traintest.loc[traintest[col] > val, col] = val","e1ff77cf":"X = traintest[used_cols]","7c4e1dd5":"X['20_interval'] = X['open_count_last_30_days'] - X['open_count_last_10_days'] \nX['30_interval'] = X['open_count_last_60_days'] - X['open_count_last_30_days'] \nX['50_interval'] = X['open_count_last_60_days'] - X['open_count_last_10_days'] \n","52ad4be4":"from sklearn.preprocessing import StandardScaler","aca1e0ac":"scaler = StandardScaler()\nX = scaler.fit_transform(X)\nX = pd.DataFrame(X)","0f0b3852":"from sklearn.preprocessing import PolynomialFeatures","5c3c4e3a":"pf = PolynomialFeatures(degree=3, include_bias= False, interaction_only= True)\nX = pf.fit_transform(X)\nX = pd.DataFrame(X)","f332e969":"X.shape","edeb9ec6":"from itertools import combinations \nimport random\nrandom.seed(2020)","8f0958bf":"total_col = X.shape[1]\n\nnew_feature_name = total_col\n\ncomb = combinations(range(total_col), 2) \nfor a,b in comb:\n    if random.random() < 0.20: # only take 20% of combination randomly\n        X[new_feature_name] = X[a] - X[b]\n        new_feature_name += 1\n\nprint(X.shape)","07d28fe3":"traintest = traintest[['row_id', 'open_flag']]","3c6eabf4":"X = pd.DataFrame(X)\ntraintest = pd.concat([traintest.reset_index(drop = True), X], axis = 1)","e38f3be2":"# columns for model\ncols = list(X.columns )\nlen(cols)","870443f9":"# source :https:\/\/www.kaggle.com\/fabiendaniel\/detecting-malwares-with-lgbm\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import matthews_corrcoef\n\nimport time\n","2f1645ba":"train = traintest.loc[~traintest.open_flag.isnull()]\ntest = traintest.loc[traintest.open_flag.isnull()]","c51b6b39":"print(train.shape)\nprint(test.shape)","bee0907c":"X_full = train.drop(\"open_flag\", axis = 1)\ny_full = train.open_flag\n\nX_train, X_valid, y_train, y_valid = train_test_split(X_full, y_full , random_state = 123, \n                                stratify = y_full, \n                                test_size = 0.2)\n","93d8b71c":"X_test = test.drop(\"open_flag\", axis = 1)","199e85a7":"print(X_train.shape) \nprint(X_valid.shape)\nprint(X_test.shape)","fb88f454":"X_train[:4]","00bb448c":"param = {'num_leaves': 10,\n         'min_data_in_leaf': 5, \n         'objective':'binary',\n         'max_depth': -1,\n         'learning_rate': 0.005,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.8,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.8 ,\n         \"bagging_seed\": 2020,\n         \"metric\": 'auc',\n         \"tree_learner\": \"voting\",\n         \"lambda_l1\": 0.3,\n         \"random_state\": 2020,\n         \"verbosity\": -1}\n\n# manual folds\nmax_iter = 5\nfolds = KFold(n_splits=max_iter, shuffle=True, random_state=2020)\noof = np.zeros(len(X_train))\npredictions = np.zeros(len(X_valid))\npredictions_test = np.zeros(len(X_test))\n\nstart = time.time()\nfeature_importance_df = pd.DataFrame()\nstart_time= time.time()\nscore = [0 for _ in range(folds.n_splits)]\n\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train.values, y_train.values)):\n    print(\"fold n\u00b0{}\".format(fold_))\n    trn_data = lgb.Dataset(X_train.iloc[trn_idx][cols],\n                           label=y_train.iloc[trn_idx],\n                          )\n    val_data = lgb.Dataset(X_train.iloc[val_idx][cols],\n                           label=y_train.iloc[val_idx],\n                          )\n\n    num_round = 10000\n    clf = lgb.train(param,\n                    trn_data,\n                    num_round,\n                    valid_sets = [trn_data, val_data],\n                    verbose_eval=250,\n                    early_stopping_rounds = 200)\n    \n    oof[val_idx] = (clf.predict(X_train.iloc[val_idx][cols], num_iteration=clf.best_iteration) > 0.5).astype(int)\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = cols\n    fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n   \n    # print(\"time elapsed: {:<5.2}s\".format((time.time() - start_time) \/ 3600))\n    score[fold_] = matthews_corrcoef(y_train.iloc[val_idx], oof[val_idx])\n    \n    predictions += clf.predict(X_valid[cols], num_iteration=clf.best_iteration)\n    predictions_test += clf.predict(X_test[cols], num_iteration=clf.best_iteration)\n    if fold_ == max_iter - 1: break\n        \nif (folds.n_splits == max_iter):\n    print(\"CV score: {:<8.5f}\".format(matthews_corrcoef(y_train, oof)))\nelse:\n    print(\"CV score: {:<8.5f}\".format(sum(score) \/ max_iter))\n        \nprediction_end = ((predictions \/ ((fold_ + 1) \/ 2) ) > 0.5).astype(int) \nprint(\"VALID score: {:<8.5f} \".format(matthews_corrcoef(y_valid, prediction_end)))\n\npredictions_test_end = ((predictions_test \/ ((fold_ + 1) \/ 2) ) > 0.5).astype(int) \n","36dbebeb":"# pred_test = model.predict(test.drop(\"open_flag\", axis = 1))\ntest['open_flag'] = predictions_test_end\ntest['open_flag'] = test['open_flag'].astype(int)\ntest['open_flag'].value_counts()\ntest[['row_id', 'open_flag']].to_csv(\"baseline_lgbm_4_features.csv\", index = False)","d416d5c8":"<font size=\"+2\" color=\"green\"><b>2.4 Differences from Polynomial<\/b><\/font><br><a id=\"2.4\"><\/a>","40f2f545":"<font size=\"+3\" color=\"green\"><b>2. Feature Adding<\/b><\/font><br><a id=\"2\"><\/a>","3706cbc0":" <font size=\"+3\" color=\"green\"><b>4. Submission<\/b><\/font><br><a id=\"4\"><\/a>","27653ae0":"<font size=\"+3\" color=\"green\"><b>1. Keep Clean without Outlier<\/b><\/font><br><a id=\"1\"><\/a>","6d73158f":"<font size=\"+2\" color=\"green\"><b>2.5 Concat Back to main df<\/b><\/font><br><a id=\"2.5\"><\/a>","a74c1c36":"WE ARE MAKING **430** FEATURES FROM 4FETAURES ONLY!!!!","7f103ba4":"## I wish this notebook helps you, if it does, please give her an upvote :D \n## Thanks!!!","42990096":"<a id='top'><\/a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-success\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Table of content<\/h3>\n\n* [1. Keep Clean without Outlier](#1)   \n* [2. Feature Adding](#2)\n    - [2.1 Differences Interval](#2.1)\n    - [2.2 StandardScaler](#2.2)\n    - [2.3 PolynomialFeatures](#2.3)\n    - [2.4 Differences from Polynomial](#2.4)\n    - [2.5 Concat Back to main df](#2.5)\n* [3. Modeling](#3)\n* [4. Submission](#4)\n* [5. End Notes](#5)","6f347c1d":"<font size=\"+2\" color=\"green\"><b>2.1 Differences Interval<\/b><\/font><br><a id=\"2.1\"><\/a>","e2da3888":"We will only using 4 features in this notebook \ud83d\ude0b\n\n```python\nused_cols= [\n            'subject_line_length', \n            'open_count_last_10_days', \n            'open_count_last_30_days', \n            'open_count_last_60_days',\n           ]\n```\n\nThis notebook will contain a little feature addition using substracting and polynomial features, then applied the features using Light Gradient Boosting to make prediction. ","ee1216c6":"We know StandardScaler do not give impact on tree based model, but we would like to make polynomial features by multiplication, I guess it make an impact","73b9bb76":"# Source on making this notebook\n* lgbm : https:\/\/www.kaggle.com\/fabiendaniel\/detecting-malwares-with-lgbm\n* markdown : https:\/\/www.kaggle.com\/raenish\/cheatsheet-text-helper-functions\n\n","844ced1e":"Hunting Outliers","64d313f4":"LETS TACKLE THOSE 129 (or less) user that frequently open, just to make it as same as quantile .999 value","b8b71683":"<font size=\"+2\" color=\"green\"><b>2.2 StandardScaler<\/b><\/font><br><a id=\"2.2\"><\/a>","431a7da4":"Make combination of multiplication between features ","33c4e047":" <font size=\"+3\" color=\"green\"><b>5. End Notes<\/b><\/font><br><a id=\"5\"><\/a>","d6251e04":"<font size=\"+2\" color=\"green\"><b>2.3 PolynomialFeatures<\/b><\/font><br><a id=\"2.3\"><\/a>","0f4cd494":" <font size=\"+3\" color=\"green\"><b>3. Modeling<\/b><\/font><br><a id=\"3\"><\/a>"}}