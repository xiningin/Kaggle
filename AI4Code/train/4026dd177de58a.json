{"cell_type":{"96f82443":"code","e26ceab2":"code","f7215ce8":"code","0ddac3f3":"code","3f95247d":"code","7ae2dea2":"code","3cffa8e4":"code","ff137d61":"code","e4f085d8":"code","3cdcd87b":"code","5e8bd3e4":"code","9476fdaf":"code","0fd2b22c":"code","35668535":"code","3442a7bb":"code","4d264c53":"code","404cb1e3":"code","2902d4e0":"code","0df86487":"code","bdd5aeb0":"code","5202f832":"code","e4d76fe9":"code","c1617751":"code","066c8b71":"code","0887a8e9":"code","970bd853":"code","abe9f4f6":"code","9d7524d2":"code","983fd646":"code","1e6644f1":"code","d6399024":"code","4b7a506d":"code","007cd22f":"code","17722b10":"code","dd42c847":"code","48a72d61":"code","ee5e0254":"code","353236f0":"code","0891839c":"code","cba0ac98":"code","af440309":"code","d3bc40e1":"code","cd8c0000":"code","0afbbaec":"code","158c1172":"code","450b11fa":"code","5cba2f3c":"code","01faa502":"code","57084391":"code","e6840150":"code","9571ea9b":"code","8721be8d":"code","882b2828":"code","64825b9f":"code","a3b50e5b":"code","e0fac12b":"code","b6984ae5":"code","d78fd9f1":"code","d5561f1a":"code","7019f171":"code","12b91ef7":"code","5e885ac0":"code","f906d5ad":"code","7b420788":"code","0f6d6ad5":"code","55a6f9e1":"code","77ccbe04":"code","ba60c3e1":"code","0dd0751c":"code","477cbbfb":"code","ada4aaa2":"code","7e05b98f":"code","34df50d4":"code","581b8d9d":"code","75adcb21":"code","6a5b39a7":"code","11193ea1":"code","786d9add":"code","d90679ec":"code","7a2f371a":"code","e0c72864":"code","b0e6d922":"code","25698a88":"code","4cd3d7f7":"code","1c747b5c":"code","098f685f":"code","fd4c32f2":"code","a506cf5f":"code","ec88c422":"code","15378ac6":"code","80907c80":"code","21dfab5a":"code","be80cf79":"code","ddcedf36":"code","41a3049f":"code","5b7af3a8":"code","1f2bfaaa":"code","59601b12":"markdown","5aba8e7c":"markdown","f3db889a":"markdown","9f342755":"markdown","15687ea3":"markdown","20d78cf7":"markdown","08a0ee87":"markdown","cdd61d7c":"markdown","ce1bd787":"markdown","022281b8":"markdown","b00b086f":"markdown","b4f4f91b":"markdown","42736e76":"markdown","e858b2bf":"markdown","de558526":"markdown","07457032":"markdown","8cbe7263":"markdown","c5599449":"markdown","cf23775f":"markdown","f0cadeaf":"markdown","a67fdbb0":"markdown","775794da":"markdown","99d31ba5":"markdown","8e6c1c23":"markdown","27cc8ecd":"markdown","de849e84":"markdown","95c643c4":"markdown","802ddf3b":"markdown","3dcfb902":"markdown","f5aadcec":"markdown","e45d0dd8":"markdown"},"source":{"96f82443":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","e26ceab2":"import matplotlib.pyplot as plt","f7215ce8":"data = pd.read_csv(\"..\/input\/tmdb_5000_movies.csv\")\n\n","0ddac3f3":"data.info()","3f95247d":"x = data.drop(['genres','keywords','production_companies','production_countries','homepage','spoken_languages'],axis = 1)","7ae2dea2":"x.columns","3cffa8e4":"x[(x['vote_average']>7.5) & (x['popularity']>100.0)]","ff137d61":"data.plot(kind = 'scatter', x  = 'budget' , y = 'revenue' , color = 'red' , alpha = 0.6)\nplt.xlabel('Budget')\nplt.ylabel('Revenue')\nplt.show()\n","e4f085d8":"data.plot(kind='hist', y = 'vote_average' , bins = 100,figsize=(11,11))\nplt.ylabel('Vote Average')\nplt.title('Movies')\nplt.show()","3cdcd87b":"meals = {'Spain' : 'Paella','China':'Peking_Duck','Belgium':'Moules_frites','Brasil':'Feijoada','Denmark':'Frikadeller','Turkey':'Kebab'}\nprint(meals.keys())\nprint(meals.values())","5e8bd3e4":"meals['France'] = 'Crepe' #update dictionary\nprint(meals)\ndel meals['Belgium'] # # remove entry with key 'Belgium'\nprint(meals)\nprint('Turkey' in meals) # check it in dictionary\nmeals.clear() # delete dictionary\nprint(meals)\n","9476fdaf":"i = 0\nliste = ['Ali','Sinan','Hakan','Elif']\nwhile i != 4:\n    for each in liste:\n        print(each)\n    print('')\n    i+=1\n    \nfor index,value in enumerate(liste):\n    print(index,\" : \",value)\nprint('')\n\n","0fd2b22c":"meals = {'Spain' : 'Paella','China':'Peking_Duck','Belgium':'Moules_frites','Brasil':'Feijoada','Denmark':'Frikadeller','Turkey':'Kebab'}\nfor key,value in meals.items():\n    print(key,\" : \",value)\nprint('')\n\nfor index,value in data[['title']][0:2].iterrows():\n    print(index,\" : \",value)","35668535":"a = 5\ndef f():\n    a = 4\n    return a**2\nprint(a) # a=5\nprint(f()) # a=4","3442a7bb":"#What if there is no local scope\n\nx = 7   #global scope\ndef f():\n    return x*9+15\nprint(f())","4d264c53":"import builtins\n#features of built in scope\ndir(builtins)","404cb1e3":"def circleArea(r):\n    \n    def add(pi = 3.14):\n        return pi\n    return 2*add()*r\nprint(circleArea(4))","2902d4e0":"#default arguments\ndef f(a,b,c=7,d=9):\n    return a*b+(c*d)\nprint(f(6,9))\n#if we want to change default arguments\nprint(f(7,6,9,11))\n","0df86487":"#flexible arguments\ndef f(*args):\n    m=0\n    for i in args:\n       m += i\n    return m\n\nprint('m = ',f(5,6,8,3,26,76))\ndef f(**kwargs):\n    for key,value in kwargs.items():\n        print(key,\" : \" , value)\nf(country = 'Turkey' , population ='80 million',capital = 'Ankara'  )","bdd5aeb0":"#Lambda function\ncircleArea = lambda r : 2*3.14*r\nprint(circleArea(5))","5202f832":"#Iterators\n\nlist1=['London','LA','Istanbul','Paris']\niterator = iter(list1)\nprint(next(iterator))\nprint(*iterator)","e4d76fe9":"#example of list comprehension\nnum1 = [3,5,8]\nnum2 = [i**2 for i in num1]\nprint(num2)\n","c1617751":"#conditionals on iterable\nnum1=[5,15,25]\nnum2=[i**2 if i==5 else i*9 if i==15 else i*10-15 for i in num1]\nprint(num2)","066c8b71":"##Let's make an object that shows us runtime level of movies\nthresold = (int)(data.runtime.mean()) #average of runtime\ndata['Runtime_level'] = [\"Long\" if i>thresold else \"short\" for i in data.runtime]\ndata.loc[:15,['Runtime_level','runtime']]","0887a8e9":"df = pd.read_csv(\"..\/input\/tmdb_5000_movies.csv\")\n","970bd853":"df.head()","abe9f4f6":"df.tail()","9d7524d2":"df.columns","983fd646":"print('Data Shape :',df.shape)","1e6644f1":"df.info()","d6399024":"df.describe() #that shows us numerical columns\n\n#%25 means first quantile \n#%50 means median and second quantile\n#%75 means third quantile\n#'mean' means average value","4b7a506d":"print(df['runtime'].value_counts(dropna=False)) #print if there are nan values that also be counted","007cd22f":"# Box plots: visualize basic statistics like outliers, min\/max or quantiles\n# For example: compare attack of pokemons that are legendary  or not\n# Black line at top is max\n# Blue line at top is 75%\n# Red line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\n#df.boxplot(column='vote_average',by = 'vote_count')","17722b10":"data_new = data.head()\ndata_new","dd42c847":"melted = pd.melt(frame=data_new,id_vars='original_title',value_vars=['vote_average','vote_count'])\nmelted","48a72d61":"#PIVOTING DATA(Reverse of melting)\n# Index is original_title\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index = 'original_title',columns='variable',values='value')","ee5e0254":"data1=df.head()\ndata2=df.tail()\nconc_data_row = pd.concat([data1,data2],axis=0,ignore_index=True)\nconc_data_row.drop(['genres','production_companies','production_countries','keywords','spoken_languages'],axis=1)","353236f0":"data3 = df.head()\ndata4 = df.tail()\nconc_data_col = pd.concat([data3,data4],axis = 1)\nconc_data_col.drop(['genres','production_companies','production_countries','keywords','spoken_languages'],axis=1)","0891839c":"df.dtypes","cba0ac98":"df['title'] = df['title'].astype('category') #convert title from string to category\ndf['vote_count'] = df['vote_count'].astype('float')","af440309":"df.dtypes","d3bc40e1":"df.info()","cd8c0000":"df[\"tagline\"].value_counts(dropna=False)","0afbbaec":"# Lets drop nan values\ndata1 = df\ndata1['tagline'].dropna(inplace=True)# inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n#so does it work?","158c1172":"#  Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true","450b11fa":"# In order to run all code, we need to make this line comment\n# assert 1==2 # return error because it is false","5cba2f3c":"assert  data1['tagline'].notnull().all() # returns nothing because we drop nan values","01faa502":"data['tagline'].fillna('empty',inplace=True)","57084391":"assert data1['tagline'].notnull().all() # returns nothing because we don't have nan values","e6840150":"#With assert statement we can check a lot of thing. For example\n#assert data.columns[1] == 'Name'\n#assert data.Speed.dtypes == np.int","9571ea9b":"#data frames from dictionary\ncountry = ['Turkey','France','UK']\npopulation = ['123','432','543']\nlist_label = ['country','population']\nlist_col =[country,population]\nzipped = list(zip(list_label,list_col))\ndata_dict = dict(zipped)\ndf= pd.DataFrame(data_dict)\ndf","8721be8d":"#add new columns\ndf['capital'] = ['Ankara','Paris','London']\ndf","882b2828":"#Broadcasting\ndf['income'] = 0 #Broadcasting the entire column(fill the entire column with 0)\ndf","64825b9f":"data.columns","a3b50e5b":"#Plotting all data\ndata1=data.loc[:,['vote_average','vote_count','budget','revenue']]\ndata1.plot()\nplt.show()\n#it seems complicated","e0fac12b":"#subplots\ndata1.plot(subplots=True)\nplt.show()","b6984ae5":"data1.plot(kind='scatter',x='budget',y='revenue',alpha=0.8)\nplt.show()","d78fd9f1":"data1.plot(kind='hist',y='vote_count',bins=50,range=(0,10))\nplt.ylabel('Vote Count')\nplt.show()","d5561f1a":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind='hist',y='vote_count',bins=30,range=(0,10),normed=True,ax=axes[0])\ndata1.plot(kind='hist',y='vote_count',bins=30,range=(0,10),normed=True,ax=axes[1],cumulative=True)\nplt.savefig('asd.png')\nplt.show()","7019f171":"time_list = ['1993-02-14','1993-02-16','1994-01-13','1998-08-06']\nprint(type(time_list[1]))\n#as we can see type of that is string\n#Let's convert it to datetime object\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","12b91ef7":"#close warning\nimport warnings\nwarnings.filterwarnings('ignore')\n# In order to practice lets take head of movies data and add it a time list\ndata2= data.head(4)\ntime_list2 = ['2009-12-18','2009-05-25','2012-11-06','2012-07-27']\ndatetime_object = pd.to_datetime(time_list2)\ndata2[\"date\"] = datetime_object\n#lets make date as index\ndata2=data2.set_index(\"date\")\ndata2\n","5e885ac0":"print(data2['vote_average'].loc['2012-11-06'])\nprint(data2['vote_average'].loc['2009-05-25':'2012-07-27'])","f906d5ad":"data2.resample('A').mean()","7b420788":"data2.resample(\"M\").mean() #resample with month\n# As you can see there are a lot of nan because data2 does not include all months","0f6d6ad5":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")","55a6f9e1":"data2.resample('M').mean().interpolate('linear')","77ccbe04":"data=pd.read_csv('..\/input\/tmdb_5000_movies.csv')\ndata.head()","ba60c3e1":"data['vote_average'][2]","0dd0751c":"data.vote_average[4]","477cbbfb":"data.loc[2,'budget']","ada4aaa2":"data[['budget','vote_count']]","7e05b98f":"print(type(data['budget'])) # series\nprint(type(data[['vote_count']])) #data frames","34df50d4":"print(data.loc[:5,'vote_average':'vote_count'])","581b8d9d":"term1= data['vote_average']> 9.0\ndata[term1]","75adcb21":"term2 = data.budget > 10000000\nterm3 = data.vote_count> 10000\ndata[term2 & term3]","6a5b39a7":"data.budget[data.vote_average>8.0]","11193ea1":"def div(n):\n    return n\/3\ndata.runtime.apply(div)","786d9add":"data.runtime.apply(lambda x : x\/4)","d90679ec":"data['total_profit'] = data.revenue - data.budget\ndata.head()","7a2f371a":"# our index name is this:\nprint(data.index.name)\n# lets change it\ndata.index.name = \"index_name\"\ndata.head()","e0c72864":"# Overwrite index\n# if we want to modify index we need to change all of them.\ndata.head()\n# first copy of our data to data3 then change index \ndata3 = data.copy()\n# lets make index start from 100. It is not remarkable change but it is just example\ndata3.index = range(100,4903,1)\ndata3.head()","b0e6d922":"# We can make one of the column as index\n# It was like this\n# data= data.set_index(\"#\")\n# also we can use \n# data.index = data[\"#\"]","25698a88":"data = pd.read_csv('..\/input\/tmdb_5000_movies.csv')\ndata.head()","4cd3d7f7":"data1 = data.set_index(['vote_average','runtime'])\ndata1.head(100)","1c747b5c":"dic = {'Name' : ['Fatih','Ali','Zehra','Ay\u00e7a'],'Gender' : ['M','M','F','F'],'Age' : [21,23,26,27],'Married' : ['Y','N','N','Y'],'Salary' : [3000,2500,2700,2000]}\ndf = pd.DataFrame(dic)\ndf","098f685f":"#pivoting\ndf.pivot(index='Gender',columns='Married',values = 'Salary')\n","fd4c32f2":"df1 = df.set_index(['Gender','Married'])\ndf1\n#let's unstack it","a506cf5f":"# level determines indexes\ndf1.unstack(level=0)","ec88c422":"df1.unstack(level=1)","15378ac6":"df2 = df1.swaplevel(0,1)\ndf2","80907c80":"df","21dfab5a":"#df.pivot(index='Gender',columns='Married',values = 'Salary')\npd.melt(df,id_vars='Gender',value_vars=['Salary','Married'])","be80cf79":"df","ddcedf36":"# according to Gender take means of other features\ndf.groupby('Gender').mean()","41a3049f":"# we can only choose one of the feature\ndf.groupby('Gender').Salary.max()","5b7af3a8":"# Or we can choose multiple features\ndf.groupby('Gender')[['Salary','Age']].min()","1f2bfaaa":"df.info()\n# as you can see gender is object\n# However if we use groupby, we can convert it categorical data. \n# Because categorical data uses less memory, speed up operations like groupby\n#df[\"Gender\"] = df[\"Gender\"].astype(\"category\")\n#df[\"Married\"] = df[\"Married\"].astype(\"category\")\n#df.info()","59601b12":"### STACKING and UNSTACKING DATAFRAME\n* deal with multi label indexes\n* level: position of unstacked index\n* swaplevel: change inner and outer level index position","5aba8e7c":"**CONCATENATING DATA**","f3db889a":"<a id=\"23\"><\/a> <br>\n### DATA TYPES\nThere are 5 basic data types: object(string),booleab,  integer, float and categorical.\n<br> We can make conversion data types like from str to categorical or from int to float\n<br> Why is category important: \n* make dataframe smaller in memory \n* can be utilized for anlaysis especially for sklear(we will learn later)","9f342755":"**TRANSFORMING DATA**","15687ea3":"**CLEANING DATA**\n\n        D\u0131ognose Data for Cleaning","20d78cf7":"**NESTED FUNCTION(INNER FUNCTION)**","08a0ee87":"This table shows us that revenue of movies is not proportional with its budget.","cdd61d7c":"**Indexing pandas time series**","ce1bd787":"** VISUAL EXPLORATORY DATA ANALYSIS**\n","022281b8":"### MELTING DATA FRAMES\n* Reverse of pivoting","b00b086f":"**PIVOTING DATA FRAMES**\n\n#reshape tool","b4f4f91b":"**FILTERING DATA FRAMES**","42736e76":"**HIERARCHICAL INDEXING**","e858b2bf":"This is my first dataScience work","de558526":"### CATEGORICALS AND GROUPBY","07457032":"<br> What is quantile?\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The median is the number that is in **middle** of the sequence. In this case it would be 11.\n\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.","8cbe7263":"**PANDAS FOUNDATION**\n#Building data frames from scratch","c5599449":"### RESAMPLING PANDAS TIME SERIES\n* Resampling: statistical method over different time intervals\n* Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like \u2018linear\u2019, \u2018time\u2019 or index\u2019","cf23775f":"### MISSING DATA and TESTING WITH ASSERT","f0cadeaf":"Most known meals in countries","a67fdbb0":"### VISUAL EXPLORATORY DATA ANALYSIS\n* Plot\n* Subplot\n* Histogram:\n    * bins: number of bins\n    * range(tuble): min and max values of bins\n    * normed(boolean): normalize or not\n    * cumulative(boolean): compute cumulative distribution","775794da":"**While and For Loops**","99d31ba5":"### INDEX OBJECTS AND LABELED DAT","8e6c1c23":"* **DICTIONARY**","27cc8ecd":"The most rated and most popular movies on IMDB.","de849e84":"**SLICING DATA FRAME**","95c643c4":"**TIDY DATA**","802ddf3b":"**MANIPULATING DATA FRAMES WITH PANDAS**\n### INDEXING DATA FRAMES\n* Indexing using square brackets\n* Using column attribute and row label\n* Using loc accessor\n* Selecting only some columns","3dcfb902":"**DEFAULT and FLEXIBLE ARGUMENTS**","f5aadcec":"**LIST COMPREHENSION**","e45d0dd8":"**SCOPE**"}}