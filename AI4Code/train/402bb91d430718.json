{"cell_type":{"4c4ac56a":"code","d5ba0e6c":"code","c6e24250":"code","491869ce":"code","c751c4e9":"code","da61ec00":"code","6560a5fb":"code","776fe2d6":"code","03bf81f2":"code","f315e9fd":"code","c0348d63":"code","8d354133":"code","0f3b7203":"code","708ee496":"code","dfedec44":"code","382b20d7":"code","47ccec2a":"code","8dd5b00a":"code","f5fa34d6":"code","692293fc":"code","61ecada3":"code","d695964b":"code","57a8335b":"code","9ffcde4a":"code","47f1fc98":"code","dfbadd01":"code","9eb9fa3e":"code","b484fb48":"code","ee55176c":"code","eff3140f":"code","a1590344":"code","67929dea":"code","8653eeb6":"code","1b030360":"code","a9ce7953":"code","79d18cb0":"code","b3106654":"code","ece77b53":"code","cb3daeb1":"code","8d2eef28":"code","edb3c845":"code","c659e08d":"code","8d0f2433":"code","a0e1ee57":"code","d5bea71a":"code","557802f8":"code","62cdf5f3":"code","9027c1d2":"code","95992289":"markdown","05f08cd6":"markdown"},"source":{"4c4ac56a":"import os\nfrom pathlib import Path\nfrom zipfile import ZipFile\nimport shutil\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf","d5ba0e6c":"data_dir = Path('\/kaggle\/working\/data')\ndata_dir.mkdir()","c6e24250":"with ZipFile('\/kaggle\/input\/dogs-vs-cats-redux-kernels-edition\/train.zip') as train_zip:\n    train_zip.extractall(path=data_dir)\n\ntrain_dir = data_dir \/ 'train'\nlen(list(train_dir.iterdir()))","491869ce":"with ZipFile('\/kaggle\/input\/dogs-vs-cats-redux-kernels-edition\/test.zip') as test_zip:\n    test_zip.extractall(path=data_dir)\n\ntest_dir = data_dir \/ 'test'\nlen(list(test_dir.iterdir()))","c751c4e9":"cat_dir = train_dir \/ 'cat'\ndog_dir = train_dir \/ 'dog'\n\ncat_dir.mkdir()\ndog_dir.mkdir()","da61ec00":"for image_path in train_dir.glob('*.jpg'):\n    src = str(image_path)\n    if 'cat' in src:\n        shutil.move(src, str(cat_dir))\n    else:\n        shutil.move(src, str(dog_dir))","6560a5fb":"print(len(list(cat_dir.iterdir())))\nprint(len(list(dog_dir.iterdir())))","776fe2d6":"BATCH_SIZE = 32\nIMAGE_SIZE = (160, 160)","03bf81f2":"train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    str(train_dir),\n    validation_split=0.2,\n    subset=\"training\",\n    seed=33,\n    image_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,)\n\nvalidation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    str(train_dir),\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=33,\n    image_size=IMAGE_SIZE,\n    batch_size=BATCH_SIZE,)","f315e9fd":"class_names = train_dataset.class_names\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_dataset.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","c0348d63":"train_dataset = train_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\nvalidation_dataset = validation_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)","8d354133":"data_augmentation = tf.keras.Sequential(\n  [\n    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n  ]\n)","0f3b7203":"plt.figure(figsize=(10, 10))\nfor image_batch, _ in train_dataset.take(1):\n    first_image = image_batch[0]\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n        plt.imshow(augmented_image[0].numpy().astype('uint8'))\n        plt.axis('off')","708ee496":"base_model = tf.keras.applications.MobileNetV2(\n    input_shape=IMAGE_SIZE + (3,),\n    include_top=False,\n    weights='imagenet')","dfedec44":"image_batch, label_batch = next(iter(train_dataset))\nfeature_batch = base_model(image_batch)\nprint(feature_batch.shape)","382b20d7":"base_model.trainable = False","47ccec2a":"base_model.summary()","8dd5b00a":"global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\nfeature_batch_average = global_average_layer(feature_batch)\nprint(feature_batch_average.shape)","f5fa34d6":"prediction_layer = tf.keras.layers.Dense(1)\nprediction_batch = prediction_layer(feature_batch_average)\nprint(prediction_batch.shape)","692293fc":"preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input","61ecada3":"inputs = tf.keras.Input(shape=IMAGE_SIZE + (3,))\nx = data_augmentation(inputs)\nx = preprocess_input(x)\nx = base_model(x, training=False)\nx = global_average_layer(x)\nx = tf.keras.layers.Dropout(0.2)(x)\noutputs = prediction_layer(x)\nmodel = tf.keras.Model(inputs, outputs)","d695964b":"model.summary()","57a8335b":"base_learning_rate = 0.0001\nmodel.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","9ffcde4a":"loss0, accuracy0 = model.evaluate(validation_dataset)","47f1fc98":"print(\"initial loss: {:.2f}\".format(loss0))\nprint(\"initial accuracy: {:.2f}\".format(accuracy0))","dfbadd01":"EPOCHS = 20\nhistory = model.fit(train_dataset,\n                    epochs=EPOCHS,\n                    validation_data=validation_dataset)","9eb9fa3e":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.xticks(list(range(20)))\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xticks(list(range(20)))\nplt.xlabel('Epoch')\nplt.show()","b484fb48":"base_model.trainable = True","ee55176c":"print(\"Number of layers in the base model: \", len(base_model.layers))","eff3140f":"fine_tune_from = 100\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_from]:\n    layer.trainable =  False","a1590344":"model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate\/10),\n              metrics=['accuracy'])","67929dea":"model.summary()","8653eeb6":"fine_tune_epochs = 10\ntotal_epochs = EPOCHS + fine_tune_epochs\n\nhistory_fine = model.fit(train_dataset,\n                         epochs=total_epochs,\n                         initial_epoch=history.epoch[-1],\n                         validation_data=validation_dataset)","1b030360":"acc += history_fine.history['accuracy']\nval_acc += history_fine.history['val_accuracy']\n\nloss += history_fine.history['loss']\nval_loss += history_fine.history['val_loss']","a9ce7953":"plt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.ylim([0.8, 1])\nplt.plot([EPOCHS-1,EPOCHS-1],\n          plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.ylim([0, 1.0])\nplt.plot([EPOCHS-1,EPOCHS-1],\n         plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","79d18cb0":"test_dataset = tf.data.Dataset.list_files(str(test_dir \/ '*.jpg'))","b3106654":"tf.data.Dataset.list_files(str(test_dir \/ '*.jpg'))","ece77b53":"# Reads an image from a file, decodes it into a dense tensor, and resizes it\n# to a fixed shape.\ndef parse_image(filename):\n    parts = tf.strings.split(filename, os.sep)\n    label = tf.strings.split(parts[-1], '.')[0]\n\n    image = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(image)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize(image, IMAGE_SIZE)\n    \n    return image, label","cb3daeb1":"test_dataset = test_dataset.map(parse_image).batch(BATCH_SIZE)","8d2eef28":"plt.figure(figsize=(10, 10))\nfor images, labels in test_dataset.as_numpy_iterator():\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i])\n        plt.title(int(labels[i].decode('UTF-8')))\n        plt.axis(\"off\")\n    break","edb3c845":"[] + [1,2,3] + [5,5]","c659e08d":"image_ids = []\nlogits = []\npredictions = []\n\nfor image_batch, id_batch in test_dataset.as_numpy_iterator():\n    batch_predictions = model.predict_on_batch(image_batch)\n    batch_predictions = batch_predictions.flatten()\n    \n    logits += batch_predictions.tolist()\n    batch_predictions = tf.nn.sigmoid(batch_predictions)\n    \n    predictions += batch_predictions.numpy().tolist()\n    image_ids += id_batch.tolist()","8d0f2433":"submission = pd.DataFrame({'id': image_ids, 'label': predictions, 'logits': logits})","a0e1ee57":"submission.describe()","d5bea71a":"submission.head()","557802f8":"submission.id = submission.id.astype(int)","62cdf5f3":"submission.info()","9027c1d2":"submission[['id', 'label']].to_csv('submission.csv', index=False)","95992289":"## Transfer Learning","05f08cd6":"## Fine Tuning"}}