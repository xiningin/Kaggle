{"cell_type":{"362a51af":"code","bc7a72fa":"code","9722ec85":"code","f259b8d6":"code","adb300f1":"code","5d1b3cfb":"code","5c0ab501":"code","c0ee7f94":"code","7d5de369":"code","1239befe":"code","1c12c731":"code","f70f1e17":"code","b34d1838":"code","11cdff66":"code","8d9915cb":"code","67a83091":"code","24ffb843":"code","f7bf0db0":"code","d7daa749":"code","aa68d997":"code","8f80bcb5":"code","83ceb59d":"markdown","67d40633":"markdown","b0404f06":"markdown","57b2a1c7":"markdown","44cf963c":"markdown"},"source":{"362a51af":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport re\nimport string\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.tokenize import TweetTokenizer","bc7a72fa":"train_data = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')\nsample = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/sample_submission.csv')\n","9722ec85":"print(len(train_data))\nprint(len(test_data))","f259b8d6":"y = train_data.target\ntrain_data =train_data.drop(['id','keyword','location','target'],axis =1)","adb300f1":"def process_text(text):\n    stemmer = PorterStemmer()\n    stopwords_english = stopwords.words('english')\n    # remove stock market tickers like $GE\n    text = re.sub(r'\\$\\w*', '', text)\n    # remove old style retweet text \"RT\"\n    text = re.sub(r'^RT[\\s]+', '', text)\n    # remove hyperlinks\n    text = re.sub(r'https?:\\\/\\\/.*[\\r\\n]*', '', text)\n    # remove hashtags\n    # only removing the hash # sign from the word\n    text = re.sub(r'#', '', text)\n    # tokenize tweets\n    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n                               reduce_len=True)\n    text_tokens = tokenizer.tokenize(text)\n\n    texts_clean = []\n    for word in text_tokens:\n        if (word not in stopwords_english and  # remove stopwords\n                word not in string.punctuation):  # remove punctuation\n            # tweets_clean.append(word)\n            stem_word = stemmer.stem(word)  # stemming word\n            texts_clean.append(stem_word)\n\n\n    return texts_clean\n","5d1b3cfb":"def build_freqs(texts, ys):\n\n    yslist = np.squeeze(ys).tolist()\n\n    freqs = {}\n    for y, text in zip(yslist, texts):\n        for word in process_text(text):\n            pair = (word, y)\n            if pair in freqs:\n                freqs[pair] += 1\n            else:\n                freqs[pair] = 1\n\n    return freqs","5c0ab501":"freqs = build_freqs(train_data['text'],y)","c0ee7f94":"freqs","7d5de369":"def extract_features(text, freqs):\n    # process_tweet tokenizes, stems, and removes stopwords\n    word_l = process_text(text)\n    \n    # 3 elements in the form of a 1 x 3 vector\n    x = np.zeros((1, 3)) \n    \n    #bias term is set to 1\n    x[0,0] = 1 \n    \n    \n    # loop through each word in the list of words\n    for word in word_l:\n        \n        # increment the word count for the positive label 1\n        x[0,1] += freqs.get((word,1.0), 0)\n        \n        # increment the word count for the negative label 0\n        x[0,2] += freqs.get((word,0.0), 0)\n        \n    assert(x.shape == (1, 3))\n    return x","1239befe":"X = np.zeros((len(train_data), 3))\nfor i in range(len(train_data)):\n    X[i, :]= extract_features(train_data.text[i], freqs)\n","1c12c731":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, plot_confusion_matrix, accuracy_score\n","f70f1e17":"y.value_counts()","b34d1838":"len(X)","11cdff66":"model = LogisticRegression(penalty= 'l2' ,random_state= 42 ,max_iter=20,solver='liblinear',class_weight= 'balanced')\nmodel.fit(X[:5500],y[:5500])","8d9915cb":"y_pred = model.predict(X[5500:])","67a83091":"plot_confusion_matrix(model, X[:5500], y[:5500],labels=[0,1],normalize= 'true')","24ffb843":"accuracy = accuracy_score(y[5500:],y_pred)\naccuracy","f7bf0db0":"main_model = LogisticRegression(penalty= 'l2' ,random_state= 42 ,max_iter=20,solver='liblinear',class_weight= 'balanced')\nmain_model.fit(X,y)","d7daa749":"X_test = np.zeros((len(test_data), 3))\nfor i in range(len(test_data)):\n    X_test[i, :]= extract_features(test_data.text[i], freqs)\n","aa68d997":"y_test_pred = main_model.predict(X_test)","8f80bcb5":"submission = pd.DataFrame({'id':sample['id'],'target': y_test_pred})\nsubmission.to_csv('My_submission.csv',index = False)","83ceb59d":"* Get the frequency of each word of both disater and non disaster tweets and store them in freqs","67d40633":"Import the data into train and test data","b0404f06":"* Drop the columns id,keyword,location ","57b2a1c7":"* Remove all stopwords, retweets, links and hashtags\n* Tokenize the tweets and store them in an array\n* store only stemming words in an array","44cf963c":"## Import libraries\n"}}