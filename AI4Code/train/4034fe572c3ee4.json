{"cell_type":{"2d8950d3":"code","8c736557":"code","0b184f8f":"code","09eb47eb":"code","812e55b2":"code","52db1e96":"code","5b6dcd4a":"code","7168de36":"code","971dafb4":"code","411f7735":"code","2e746b03":"code","7081b971":"code","0ec6aa37":"code","a6cffdd3":"code","bd5947a8":"code","323d4acd":"code","76b628b4":"code","2a0399f8":"code","45f6400c":"code","d4eb4755":"code","0bf6dc13":"code","404452be":"code","e749226a":"code","ab259741":"code","a892f8e5":"markdown","487adac6":"markdown","b8923629":"markdown","0343b675":"markdown","5afa273e":"markdown","5c773e87":"markdown","a7568f17":"markdown","dfb329a7":"markdown","2e0b6dcb":"markdown","dfea37da":"markdown","726d9739":"markdown","20dd9bd3":"markdown","541a6752":"markdown","9776ac96":"markdown","11700d37":"markdown","30b8062f":"markdown","41eb9693":"markdown","2f64233c":"markdown","b6269bc7":"markdown","80cc830e":"markdown"},"source":{"2d8950d3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8c736557":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nweather_data = pd.read_csv('..\/input\/weather-dataset-rattle-package\/weatherAUS.csv')\n\nweather_data.head()","0b184f8f":"weather_data.head()","09eb47eb":"weather_data['RainTomorrow'].value_counts()","812e55b2":"weather_data.isnull().sum().sort_values(ascending = False)","52db1e96":"max_nan = len(weather_data)*0.28\nweather_data = weather_data.loc[:,(weather_data.isnull().sum(axis=0) <= max_nan) ]\nweather_data","5b6dcd4a":"weather_data.isnull().sum().sort_values(ascending = False)","7168de36":"weather_data.dropna(subset = [\"RainTomorrow\"], inplace = True)\nweather_data.fillna(method='bfill' , inplace=True)","971dafb4":"weather_data.isnull().sum()","411f7735":"# lo\u1ea1i b\u1ecf 1 s\u1ed1 c\u1ed9t kh\u00f4ng c\u00f3 \u00fd ngh\u0129a\nweather_data.drop(columns= ['Date','Location'] , inplace=True)","2e746b03":"weather_data['RainToday'] = weather_data['RainToday'].astype('category')\nweather_data['RainTomorrow'] = weather_data['RainTomorrow'].astype('category')\n","7081b971":"# Chuy\u1ec3n v\u1ec1 numeric\nweather_data['RainToday'] = weather_data['RainToday'].cat.codes\nweather_data['RainTomorrow'] = weather_data['RainTomorrow'].cat.codes\n","0ec6aa37":"col_is_numeric = [col for col in weather_data.columns if weather_data[col].dtype in ['int64','float64','int8']]\nweather_data = weather_data[col_is_numeric]","a6cffdd3":"Full_Data_X = weather_data\nX = Full_Data_X.drop(columns= 'RainTomorrow' , axis = 1)\n# X = Full_Data_X.drop(columns= 'RainToday' , axis = 1)\ny = Full_Data_X['RainTomorrow']","bd5947a8":"# X=pd.get_dummies(X,columns=['WindDir9am','WindDir3pm','WindGustDir'],drop_first=True)","323d4acd":"#Scale data\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(X)\nX = pd.DataFrame(scaler.transform(X), index=X.index, columns=X.columns)","76b628b4":"from sklearn.model_selection import train_test_split\nX_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.25 ,random_state=0,stratify=y)","2a0399f8":"# Ch\u1ecdn K\nK = 101","45f6400c":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\nclassifier = KNeighborsClassifier(n_neighbors = 13 , p = 2 , weights = 'distance')\nclassifier.fit(X_train,y_train)\ny_pred = classifier.predict(X_test)\nscore = accuracy_score(y_test,y_pred)\nprint(\"Predicted labels: \", y_pred[1:20])\nprint(\"Ground truth    : \", np.array(y_test[1:20]))","d4eb4755":"from sklearn.metrics import accuracy_score\nprint(\"Accuracy of KNN: %.2f %%\" %(100*accuracy_score(y_test, y_pred)))","0bf6dc13":"import math","404452be":"def knn(row):\n    x = np.array(row)\n    candidate = []\n    for i in range(len(X_train)):\n        y = np.array(X_train.iloc[i])\n        score = (y-x).dot(y-x)\n        candidate.append([math.sqrt(score),y_train.iloc[i]])\n    candidate.sort()\n    candidate = candidate[0:K]\n    vote = 0\n    for i in candidate:\n        if i[1]==1:\n            vote+=1\n    if vote>K\/\/2:\n        return 1\n    else:\n        return 0","e749226a":"# predict = []\n# for i in range(len(X_test)):\n#     predict.append(knn(X_test.iloc[i]))\n# print(\"Accuracy of KNN: %.2f %%\" %(100*accuracy_score(y_test, np.array(predict))))","ab259741":"import time\nsecond = time.time()\nx = np.array(X_train)\ny = np.array(X_test.iloc[0])\ncandidate = np.zeros(len(x))\nfor i in range(x.shape[0]):\n    score = (x[i]-y).dot(x[i]-y)\n    candidate[i] = math.sqrt(score)\ncandidate.sort(kind = 'quicksort')\ncandidate = candidate[0:K]\n\nprint(candidate)\nprint(time.time() - second)","a892f8e5":"> 1. KD-Tree\n\nThu\u1eadt to\u00e1n t\u00ecm ki\u1ebfm d\u1ef1a tr\u00ean binary search tree\n\nm\u1ed7i khi \u0111i xu\u1ed1ng 1 nh\u00e1nh s\u1eed d\u1ee5ng 1 chi\u1ec1u d\u1eef li\u1ec7u lu\u00e2n phi\u00ean\n\n>2. KNN with LSH ( locality sensitive hashing)\n\nChia t\u1eadp d\u1eef li\u1ec7u ra th\u00e0nh c\u00e1c region. N\u1ebfu test_point thu\u1ed9c region n\u00e0o th\u00ec ch\u1ec9 x\u00e9t c\u00e1c neighbor thu\u1ed9c region \u0111\u00f3.\n\n>3. KNN with Inverted List","487adac6":"> 1. Chu\u1ea9n 2 ( L2 Norm) Kho\u1ea3ng c\u00e1ch Euclide","b8923629":"# **CH\u1eccN K NH\u01af TH\u1ebe N\u00c0O ?**","0343b675":"3. > Chu\u1ea9n p (Lp Norm) kho\u1ea3ng c\u00e1ch Minkowski","5afa273e":"> 2. Chu\u1ea9n 1 (L1 Norm) kho\u1ea3ng c\u00e1ch mahattan","5c773e87":"> 1. Scalling \n\nThay \u0111\u1ed5i kho\u1ea3ng gi\u00e1 tr\u1ecb c\u1ee7a Data\n\nminmax_scaling trong mlxtend.preprocessing\n\n> 2. Normalizing\n\nThay \u0111\u1ed5i ph\u00e2n ph\u1ed1i x\u00e1c su\u1ea5t c\u1ee7a c\u00e1c \u0111i\u1ec3m d\u1eef li\u1ec7u\n\nboxcox trong Stats th\u01b0 vi\u1ec7n scipy","a7568f17":"**\u0110i\u1ec1n c\u00e1c gi\u00e1 tr\u1ecb c\u00f2n thi\u1ebfu b\u1edfi next value**","dfb329a7":"# **IMPLEMENT THU\u1eacT TO\u00c1N KNN**","2e0b6dcb":"# **T\u1ea0I SAO L\u00c0M VI\u1ec6C V\u1edaI KNN PH\u1ea2I NORMALIZE DATA ?**","dfea37da":"distance =(x\u2081\u2082-x\u2082\u2082)  which can also be rewritten as\n\n\u2211 abs(x\u2081\u1d62-x\u2082\u1d62) where i=1 to n\n\nThis is called L1 norm","726d9739":"\u221a(x\u2081\u2082-x\u2082\u2082)\u00b2+(y\u2081\u2082-y\u2082\u2082)\u00b2 =  ||x\u2081-x\u2082||\u2082\n\nWe can also rewrite this as \n\n||x\u2081-x\u2082||\u2082 =   (\u2211(x\u2081\u1d62-x\u2082\u1d62)\u00b2)\u00b9\/\u00b2 where i=1 to n\n\nThe right side of this equation is called L2 Norm","20dd9bd3":"# **C\u00c1C K\u0128 THU\u1eacT NORMALIZE DATA ?**","541a6752":"# **X\u1eec L\u00dd TH\u1ebe N\u00c0O KHI 2 NH\u00c3N C\u00d3 C\u00d9NG S\u1ed0 L\u01af\u1ee2NG H\u00c0NG X\u00d3M VOTE ?**","9776ac96":"- V\u00ec c\u00e1c feature s\u1ebd c\u00f3 nh\u1eefng \u0111\u1eb7c tr\u01b0ng kh\u00e1c nhau v\u00e0 kh\u00f4ng thu\u1ed9c c\u00f9ng 1 d\u00e0i gi\u00e1 tr\u1ecb \u0111\u1ec3 t\u00ednh kho\u1ea3ng c\u00e1ch\n\n- V\u00ed d\u1ee5 : Ng\u01b0\u1eddi 1 : Age = 25 , income = 80.000 ; Ng\u01b0\u1eddi 2 : Age = 30 , income = 100.000\n\nKho\u1ea3ng c\u00e1ch d = ((Age1-Ag2)^2 + (income1-income2)^2)^(1\/2) = 20000.000625 \n\nV\u1eady \u1ea3nh h\u01b0\u1edfng c\u1ee7a Age kh\u00f4ng qu\u00e1 l\u1edbn \u0111\u1ed1i v\u1edbi h\u00e0m kho\u1ea3ng c\u00e1ch nh\u01b0ng tr\u00ean th\u1ef1c t\u1ebf Age c\u00f3 \u1ea3nh h\u01b0\u1edfng kh\u00e1 l\u1edbn t\u1edbi thu nh\u1eadp c\u0169ng nh\u01b0 c\u00e1c feature kh\u00e1c th\u00ec model s\u1ebd r\u1ea5t t\u1ec7.\n\n- Ch\u00fang ta c\u1ea7n t\u1eadp d\u1eef li\u1ec7u c\u00f3 ph\u00e2n ph\u1ed1i x\u00e1c su\u1ea5t v\u1eady th\u00ec c\u1ea7n ph\u1ea3i nomalize","11700d37":"- Random \n- T\u0103ng ho\u1eb7c gi\u1ea3m K cho \u0111\u1ebfn khi c\u00f3 s\u1ef1 ch\u00eanh l\u1ec7ch l\u01b0\u1ee3ng vote gi\u1eefa 2 nh\u00e3n ( gi\u1ea3m accuracy)\n- \u0110\u00e1nh tr\u1ecdng s\u1ed1 cho m\u1ed7i \u1ee9ng vi\u00ean v\u00e0 l\u1ea5y gi\u00e1 tr\u1ecb tr\u1ecdng s\u1ed1 n\u00e0y \u0111\u1ec3 so s\u00e1nh gi\u1eefa 2 nh\u00e3n n\u1ebfu c\u00f3 s\u1ed1 l\u01b0\u1ee3ng vote = nhau","30b8062f":"# **c\u00e1c k\u0129 thu\u1eadt t\u1ed1i \u01b0u khi search c\u00e1c h\u00e0ng x\u00f3m g\u1ea7n nh\u1ea5t ?**","41eb9693":"****X\u00f3a c\u00e1c c\u1ed9t c\u00f3 s\u1ed1 l\u01b0\u1ee3ng NULL > 28%****","2f64233c":"# **C\u00c1C \u0110\u1ecaNH NGH\u0128A V\u1ec0 KHO\u1ea2NG C\u00c1CH**","b6269bc7":"||x\u2081-x\u2082||\u209a =(\u2211(x\u2081\u1d62-x\u2082\u1d62)\u1d56)\u00b9\/\u1d56\n\nThis is also called the Lp norm\n\nIf p=1, then it is Manhattan distance\n\nIf p=2, then it is Euclidean distance","80cc830e":"V\u1edbi b\u00e0i to\u00e1n ph\u00e2n lo\u1ea1i nh\u1ecb ph\u00e2n, ch\u00fang ta s\u1ebd ch\u1ecdn K l\u1ebb \u0111\u1ec3 \u0111\u1ea3m b\u1ea3o nh\u00e3n s\u1ebd \u0111\u01b0\u1ee3c ph\u00e2n lo\u1ea1i\n\nTrong t\u1ea5t c\u1ea3 c\u00e1c tr\u01b0\u1eddng h\u1ee3p ng\u01b0\u1eddi ta ch\u01b0a c\u00f3 th\u1ed1ng k\u00ea n\u00e0o cho th\u1ea5y gi\u00e1 tr\u1ecb K n\u00e0o l\u00e0 t\u1ed1t nh\u1ea5t.\n\nV\u1eady Ch\u00fang ta s\u1ebd cho K ch\u1ea1y trong 1 t\u1eadp h\u1eefu h\u1ea1n v\u00e0 ch\u1ecdn gi\u00e1 tr\u1ecb K l\u00e0m cho gi\u00e1 tr\u1ecb h\u00e0m error l\u00e0 nh\u1ecf nh\u1ea5t. "}}