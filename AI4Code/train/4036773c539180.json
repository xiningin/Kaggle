{"cell_type":{"9b3bb0b1":"code","97042b45":"code","70de91bb":"code","56af037b":"code","ab1f3e13":"code","23509223":"code","7aad00e7":"code","571de444":"code","47db0370":"code","33aa4289":"code","41c0403b":"code","440e0b3e":"code","f3ec9239":"code","38cf1161":"code","88757ab4":"code","3bc71b70":"code","93a475f9":"code","2569d450":"code","3c3a22ce":"code","5734b703":"code","33508665":"code","8f82116d":"code","1dd496bf":"code","79c7941c":"code","49662222":"code","1f0e19d9":"code","36c840e1":"code","cda76afa":"code","06f3c502":"code","464d99a3":"code","88bb288d":"code","71114b04":"markdown","725bf5f1":"markdown"},"source":{"9b3bb0b1":"import torch\nfrom torch import optim, nn\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport numpy as np","97042b45":"!wget -c https:\/\/raw.githubusercontent.com\/udacity\/deep-learning-v2-pytorch\/master\/intro-to-pytorch\/helper.py","70de91bb":"train_dir = '..\/input\/hackathon-blossom-flower-classification\/flower_data\/flower_data\/train'\nvalid_dir = '..\/input\/hackathon-blossom-flower-classification\/flower_data\/flower_data\/valid'","56af037b":"train_transforms = transforms.Compose([transforms.RandomRotation(30),transforms.RandomResizedCrop(224),transforms.RandomHorizontalFlip(),transforms.ToTensor(),\n                                       transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\ntest_transforms = transforms.Compose([transforms.Resize(256),\n                                      transforms.CenterCrop(224),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])","ab1f3e13":"train_data = datasets.ImageFolder(train_dir , transform=train_transforms)\ntest_data = datasets.ImageFolder(valid_dir, transform=test_transforms)","23509223":"trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\ntestloader = torch.utils.data.DataLoader(test_data, batch_size=64)","7aad00e7":"print(len(train_data)\/64)\nprint(len(test_data)\/64)","571de444":"import json\n\nwith open('..\/input\/hackathon-blossom-flower-classification\/cat_to_name.json', 'r') as f:\n    cat_to_name = json.load(f)","47db0370":"# This is the contents of helper.py \nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torch import nn, optim\nfrom torch.autograd import Variable\n\n\ndef test_network(net, trainloader):\n\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(net.parameters(), lr=0.001)\n\n    dataiter = iter(trainloader)\n    images, labels = dataiter.next()\n\n    # Create Variables for the inputs and targets\n    inputs = Variable(images)\n    targets = Variable(images)\n\n    # Clear the gradients from all Variables\n    optimizer.zero_grad()\n\n    # Forward pass, then backward pass, then update weights\n    output = net.forward(inputs)\n    loss = criterion(output, targets)\n    loss.backward()\n    optimizer.step()\n\n    return True\ndef imshow(image, ax=None, title=None, normalize=True):\n    \"\"\"Imshow for Tensor.\"\"\"\n    if ax is None:\n        fig, ax = plt.subplots()\n    image = image.numpy().transpose((1, 2, 0))\n    if normalize:\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = std * image + mean\n        image = np.clip(image, 0, 1)\n\n    ax.imshow(image)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.tick_params(axis='both', length=0)\n    ax.set_xticklabels('')\n    ax.set_yticklabels('')\n\n    return ax\ndef view_recon(img, recon):\n    ''' Function for displaying an image (as a PyTorch Tensor) and its\n        reconstruction also a PyTorch Tensor\n    '''\n\n    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n    axes[0].imshow(img.numpy().squeeze())\n    axes[1].imshow(recon.data.numpy().squeeze())\n    for ax in axes:\n        ax.axis('off')\n        ax.set_adjustable('box-forced')  ","33aa4289":"class_names = train_data.classes","41c0403b":"images, labels = next(iter(testloader))","440e0b3e":"import torchvision\ngrid = torchvision.utils.make_grid(images, nrow = 20, padding = 2)\nplt.figure(figsize = (15, 15))  \nplt.imshow(np.transpose(grid, (1, 2, 0)))   \nprint('labels:', labels)\n","f3ec9239":"imshow(images[63])\nlabels[63].item()","38cf1161":"train_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('CUDA is not available.  Training on CPU ...')\nelse:\n    print('CUDA is available!  Training on GPU ...')","88757ab4":"!ls -la","3bc71b70":"from torch.optim import lr_scheduler\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = models.resnet152(pretrained=True)\n\nfor name,child in model.named_children():\n  if name in ['layer3','layer4']:\n    print(name + 'is unfrozen')\n    for param in child.parameters():\n      param.requires_grad = True\n  else:\n    print(name + 'is frozen')\n    for param in child.parameters():\n      param.requires_grad = False\n\nmodel.fc = nn.Sequential(nn.Linear(2048, 512),nn.ReLU(),nn.Linear(512,102),nn.LogSoftmax(dim=1))    \n\ncriterion = nn.NLLLoss()\n\n\noptimizer = torch.optim.Adam(filter(lambda p:p.requires_grad,model.parameters()) , lr = 0.001)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)\n\n\nmodel.to(device);","93a475f9":"def train_and_test():\n    epochs = 10\n    train_losses , test_losses = [] , []\n    valid_loss_min = np.Inf \n    model.train()\n    for epoch in range(epochs):\n      running_loss = 0\n      batch = 0\n      scheduler.step()\n      for images , labels in trainloader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs,labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        batch += 1\n        if batch % 10 == 0:\n            print(f\" epoch {epoch} batch {batch} completed\")\n      test_loss = 0\n      accuracy = 0\n      with torch.no_grad():\n        model.eval() \n        for images , labels in testloader:\n          images, labels = images.to(device), labels.to(device)\n          logps = model(images) \n          test_loss += criterion(logps,labels) \n          ps = torch.exp(logps)\n          top_p , top_class = ps.topk(1,dim=1)\n          equals = top_class == labels.view(*top_class.shape)\n          accuracy += torch.mean(equals.type(torch.FloatTensor))\n      train_losses.append(running_loss\/len(trainloader))\n      test_losses.append(test_loss\/len(testloader))\n      print(\"Epoch: {}\/{}.. \".format(epoch+1, epochs),\"Training Loss: {:.3f}.. \".format(running_loss\/len(trainloader)),\"Test Loss: {:.3f}.. \".format(test_loss\/len(testloader)),\n        \"Test Accuracy: {:.3f}\".format(accuracy\/len(testloader)))\n      model.train() \n      if test_loss\/len(testloader) <= valid_loss_min:\n        print('test loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,test_loss\/len(testloader))) \n        torch.save(model.state_dict(), 'checkpoint.pth')\n        valid_loss_min = test_loss\/len(testloader)","2569d450":"def load_model():\n    state_dict = torch.load('checkpoint.pth')\n    print(state_dict.keys())\n    model.load_state_dict(state_dict)\n    ","3c3a22ce":"for name,child in model.named_children():\n  if name in ['layer1','layer2']:\n    print(name + 'is unfrozen')\n    for param in child.parameters():\n      param.requires_grad = True\n  else:\n    print(name + 'is frozen')\n    for param in child.parameters():\n      param.requires_grad = False","5734b703":"load_model()","33508665":"optimizer = torch.optim.Adam(filter(lambda p:p.requires_grad,model.parameters()) , lr = 0.00001)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)","8f82116d":"model.class_idx_mapping = train_data.class_to_idx\nclass_idx_mapping = train_data.class_to_idx\nidx_class_mapping = {v: k for k, v in class_idx_mapping.items()}","1dd496bf":"data_dir = \"..\/input\/hackathon-blossom-flower-classification\/test set\"\nvalid_data = datasets.ImageFolder(data_dir, transform=test_transforms)\nvalidloader = torch.utils.data.DataLoader(valid_data, batch_size=64)","79c7941c":"import pandas as pd\nimport os\ndef predict(validloader, model_checkpoint, topk=1, device=\"cuda\", idx_class_mapping=idx_class_mapping):\n    model.to(device)\n    model.eval()\n    \n    labels=[]\n    \n    with torch.no_grad():\n        for images, _ in validloader:\n            images = images.to(device)\n            output = model(images)\n            ps = torch.exp(output)\n            top_p, top_class = ps.topk(1, dim=1) \n            for i in top_class:\n                \n                labels.append(idx_class_mapping[i.item()] )\n                \n                      \n               \n    return labels\n","49662222":"class_label=predict(validloader,\"checkpoint.pth\", idx_class_mapping=idx_class_mapping)","1f0e19d9":"class_label","36c840e1":"image_col=[]\nfor img_filename in os.listdir('..\/input\/hackathon-blossom-flower-classification\/test set\/test set'):\n    image_col.append(img_filename)","cda76afa":"category_map = sorted(cat_to_name.items(), key=lambda x: int(x[0]))\nplant_name=[]\nfor label in class_label:\n    name=cat_to_name[label]\n    \n    plant_name.append(name)\n    ","06f3c502":"submission = pd.DataFrame({'image_test': image_col, 'pred_class': class_label,'species': plant_name})\nsubmission.sort_values('image_test')","464d99a3":"print(submission.head())","88bb288d":"submission.to_csv('my_predictions_test.csv')","71114b04":"**Model architechture and intuition behind it**\n* Firstly i analyzed the dataset that it is a multi class classification problem with 102 classes of flowers to be predicted accurately.\n* I have already experience with pretrained models like resnet models trained on imagenet dataset and therefore , i choose resnet152 as it contains complexities for non - linear boundaries needed to classify the dataset with so many classes and has already been proven in many competitions round the world as one of the best architechtures.\n* Also i firstly simply trained the model with just changing the last layer 'fc' and keeping other layers freezed.\n* In the second mode , i tried to unfreeze the last two layers - 'layer3', 'layer4' and got accuracy on validation set about 95 % using lr scheduler\n* In the third mode , i tried to run by lowering the learn rate more and applying lr scheduler with more lower gamma and unfrozen 'layer1' and 'layer2' keeping others freezed as they are already trained.\n**Hyperparameteres**\n* For first run : i set \n* -> epochs : 20\n* -> optimizer : adam with learning rate 0.001\n* -> classifier : one hidden layer containing 512 neurons and last final layer containing 102 neurons \n* -> used ReLU activations for inner layers and softmax for final layer\n\n* For second run : i set\n* -> epochs : 20\n* -> learning rate : 0.0001\n* -> learning scheduler : stepLR with step_size = 6 and gamma = 0.1\n\nkeeping other things same as in above first run\n\n* For third run : i set\n* -> epochs : 10\n* -> lr : 0.0001\n* -> lr scheduler : stepLR with step_size = 5 and gamma 0.01\n\nkeeping other things same as in second run","725bf5f1":"***Project - virtual hackathon - Hackathon Blossom (Flower Classification)***"}}