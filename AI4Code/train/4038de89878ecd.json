{"cell_type":{"95e63481":"code","11a1f6d8":"code","074d37c9":"code","fb8b166a":"code","b6eb0acc":"code","e5b0a323":"code","0ce6fbbd":"code","37487102":"code","a6fe2e91":"code","2df330bf":"code","9b562f24":"code","3b293e0e":"code","41d3fb72":"code","d2836ff7":"code","17da8c6d":"code","fa410952":"code","89359e45":"code","122c0ce8":"code","21a3b7b7":"code","96e23784":"code","9e09e1d3":"code","f9ab31d2":"code","06085a2d":"code","76c3b16d":"code","51cf62ba":"code","854510e8":"code","12e418dc":"code","9b550186":"code","7f0a2d49":"markdown","cdd2967c":"markdown","e1497004":"markdown","957387b5":"markdown"},"source":{"95e63481":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"..\/input\"))\nimport matplotlib.pyplot as plt \nimport seaborn as sb\nimport random \nimport time\nfrom  sklearn.model_selection  import StratifiedKFold as kfold\nfrom  sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport warnings\nwarnings.filterwarnings('ignore')","11a1f6d8":"train=pd.read_csv('..\/input\/train.csv')\ntest=pd.read_csv('..\/input\/test.csv')\nFull_Data=pd.concat([train,test])\nFull_Data.shape","074d37c9":"#Generalised Function which can give the Percentage of missing values present in DataSet.\ndef Train_missing_values(training_dataset):\n    Missing_Data_Percent=pd.DataFrame(training_dataset.isna().sum())\n    Missing_Data_Percent.reset_index(inplace=True)\n    Missing_Data_Percent.columns=['Feild_Name','Missing_value_count']\n    Missing_Data_Percent['Percent_missing_values']=Missing_Data_Percent['Missing_value_count'].\\\n                                                apply(lambda Missing_value_count:(Missing_value_count\/len(training_dataset))*100)\n    return Missing_Data_Percent.sort_values(['Percent_missing_values'],ascending=False)\n\n\nTrain_missing_values(Full_Data)","fb8b166a":"Full_Data.Credit_History.unique()","b6eb0acc":"Credit_History_Analysis=Full_Data[Full_Data['Credit_History'].isnull()==True]\na=dict(Credit_History_Analysis['Loan_Status'].value_counts())\nplt.bar(range(len(a)), list(a.values()), align='center')\nplt.xticks(range(len(a)), list(a.keys()))","e5b0a323":"a=dict(Full_Data['Self_Employed'].value_counts())\nplt.bar(range(len(a)), list(a.values()), align='center')\nplt.xticks(range(len(a)), list(a.keys()))","0ce6fbbd":"sb.boxplot(x=Full_Data[\"Loan_Amount_Term\"],color=\".25\")","37487102":"#Normalise the Loan Term Duration nby dividuing it 12\nFull_Data['Loan_term_in_year']=Full_Data['Loan_Amount_Term']\/12\nFull_Data.drop('Loan_Amount_Term',axis=1,inplace=True)\nFull_Data.dropna(subset=['Married'],inplace=True)","a6fe2e91":"Full_Data['Gender'].describe()","2df330bf":"#Imputation for NA values\n#The Imputation done below are based on Some analysis which is not Shown Above\nFull_Data.fillna({'Self_Employed':'No','Credit_History':1,'Loan_term_in_year':30,'Dependents':0 , \\\n                  'LoanAmount':Full_Data['LoanAmount'].mean() ,'Gender':'Male'} ,inplace=True)","9b562f24":"sb.pairplot(Full_Data,hue='Loan_Status',markers='+')\nplt.show()","3b293e0e":"Full_Data.columns","41d3fb72":"Full_Data.head()","d2836ff7":"Full_Data.describe()","17da8c6d":"def one_hot(df, cols):\n    \"\"\"\n    @param df pandas DataFrame\n    @param cols a list of columns to encode \n    @return a DataFrame with one-hot encoding\n    \"\"\"\n    for each in cols:\n        dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n        df = pd.concat([df, dummies], axis=1)\n    return df","fa410952":"#Get One Hot Encoding For Data\nFull_Data=one_hot(Full_Data,['Education','Gender','Married','Self_Employed','Property_Area'])","89359e45":"#Normalisation of Data\nFull_Data['LoanAmount_log']=np.log(Full_Data['LoanAmount']+1)\nFull_Data['ApplicantIncome_log']=np.log(Full_Data['ApplicantIncome']+1)\nFull_Data['CoapplicantIncome_log']=np.log(Full_Data['CoapplicantIncome']+1)\nFull_Data['Loan_term_in_year_log']=np.log(Full_Data['Loan_term_in_year']+1)","122c0ce8":"#Removed Columns \nFull_Data.drop(['Education','Gender','Married','Self_Employed','Property_Area','LoanAmount',\\\n               'ApplicantIncome','CoapplicantIncome', 'Loan_term_in_year'],axis=1,inplace=True)\nFull_Data.set_index('Loan_ID',inplace=True)","21a3b7b7":"#Label Encoding\nFull_Data['Dependents'].replace({'0':0,0:0,'1':1,'2':2,'3+':3},inplace=True)\nFull_Data['Dependents'].unique()","96e23784":"Final_Test_Set=Full_Data[Full_Data.Loan_Status.isnull()]\nFinal_Train_Set=Full_Data[Full_Data.Loan_Status.isnull()==False]","9e09e1d3":"Final_Train_Set.columns","f9ab31d2":"x_train=Final_Train_Set[['ApplicantIncome_log', 'CoapplicantIncome_log', 'Credit_History', 'Dependents', \\\n       'LoanAmount_log', 'Loan_term_in_year_log', 'Education_Graduate',\\\n       'Education_Not Graduate', 'Gender_Female', 'Gender_Male', 'Married_No',\\\n       'Married_Yes', 'Self_Employed_No', 'Self_Employed_Yes',\\\n       'Property_Area_Rural', 'Property_Area_Semiurban',\\\n       'Property_Area_Urban']]\ny_train=Final_Train_Set['Loan_Status']","06085a2d":"x_train.describe()","76c3b16d":"from sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegressionCV\nLogisticRegression=LogisticRegressionCV(cv=10,random_state=1,multi_class='auto')\n#cross_val_score(model,x_train, y_train,cv=10)\nFinal_model=LogisticRegression.fit(x_train, y_train)","51cf62ba":"X_test=Final_Test_Set[['ApplicantIncome_log', 'CoapplicantIncome_log', 'Credit_History', 'Dependents', \\\n       'LoanAmount_log', 'Loan_term_in_year_log', 'Education_Graduate',\\\n       'Education_Not Graduate', 'Gender_Female', 'Gender_Male', 'Married_No',\\\n       'Married_Yes', 'Self_Employed_No', 'Self_Employed_Yes',\\\n       'Property_Area_Rural', 'Property_Area_Semiurban',\\\n       'Property_Area_Urban']]","854510e8":"X_test['y_test_pred']=Final_model.predict(X_test)","12e418dc":"X_test['y_test_pred'].value_counts()","9b550186":"# import the modules we'll need\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n# create a random sample dataframe\ndf = X_test\n\n# create a link to download the dataframe\ncreate_download_link(df)","7f0a2d49":"### Imputation Final Values \n\n* Credit History NULL values should  be replace by 1(i.e that is Credit history is Present). Reason is 60% of people who dont have credit history they still got loan or eligible for loan\n* For Self Employment Column , We will Go for Mode Imputation where most of Popultion who are applying for the Loan Not Self Employed. ","cdd2967c":"### Fixing the Imputation value for Credit History\n*  We have almost 10 % data where Credit history is Blank or Null.So we have to impute that. So First We will Check the Target  distributions for those Missing NaN values .This Will help us to impute the Missing values for that particular \n* by Seeing below chart , We can Conclude that more that 60 percent of people who have a Blanks Credit History Got the loan from the Banks .\n* So we will imput Value as '1' For all the records which are having credit history as NaN","e1497004":"### Observations :\n* Loan status having almost 37 % missing values but that missing values are due to test set. So Ideally we should not worry about them \n* We have Very Small set of missing values as well as Dataset , So we will Prefer to go for imputation of Missing values instead of removeing them set ","957387b5":"* by Seeing above chart , We can Conclude that more that 60 percent of people who have a Blanks Credit History Got the loan from the Banks.\n* So we will imput Value as '1' For all the records which are having credit history as NaN"}}