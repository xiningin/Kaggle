{"cell_type":{"a4e87928":"code","1e1c3de5":"code","d0e26001":"code","efa8815c":"code","33a53006":"code","9bc55635":"code","a46994c5":"code","d5e2ac22":"code","5a8aed57":"code","66d1ce9a":"code","7db52b93":"code","2e91badd":"code","773cef20":"code","c78ced36":"code","c4f19feb":"code","fb7c7a80":"code","2ff29b2e":"code","f88784f3":"markdown","f1f687c3":"markdown","e0bda183":"markdown","2c49e064":"markdown","dd76a029":"markdown","dd0882cb":"markdown","9ae59f02":"markdown"},"source":{"a4e87928":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1e1c3de5":"train = pd.read_csv('\/kaggle\/input\/cap-4611-2021-fall-assignment-3\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/cap-4611-2021-fall-assignment-3\/eval.csv')","d0e26001":"#Copy test id\ntestId = test['id']\n\n#drop id from sets\ntrain.drop('id', axis = 1, inplace= True)\ntest.drop('id', axis = 1, inplace= True)","efa8815c":"train.info()","33a53006":"test.info()","9bc55635":"nulls=train.columns[train.isnull().any()]\ntrain[nulls].isnull().sum()","a46994c5":"nulls=test.columns[test.isnull().any()]\ntest[nulls].isnull().sum()","d5e2ac22":"train.describe()","5a8aed57":"test.describe()","66d1ce9a":"train.columns","7db52b93":"from sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.metrics import RootMeanSquaredError\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\n\ny = train['Eat']\nX = train.drop('Eat', axis = 1)\n\nXdata, Xtest, ydata, ytest = train_test_split(X, y, test_size= .25)\nXtrain, Xval, ytrain, yval = train_test_split(Xdata, ydata, test_size= .25)\n\nmodelSave = ModelCheckpoint('bestModel.hdf5', save_best_only = True)\n\nmodelStop = EarlyStopping(monitor = 'val_root_mean_squared_error', patience = 14)","2e91badd":"Xtrain.shape","773cef20":"ytrain.shape","c78ced36":"model1 = Sequential()\n\nmodel1.add(Dense(1100,input_shape=(1276,),activation=\"elu\"))\nmodel1.add(Dense(650,activation = 'relu'))\nmodel1.add(Dense(1))\n\nmodel1.compile(optimizer= \"adam\", loss=\"mse\", metrics = [RootMeanSquaredError()])\n\nmodel1.fit(Xtrain, ytrain, epochs=100, verbose= 1, callbacks = [modelSave], validation_data = (Xval, yval))\n\nmodel1.evaluate(Xtest, ytest)\n\nypred1 = model1.predict(Xtest)\nypred1 = np.squeeze(ypred1, axis= 1)\n\ndf1 = pd.DataFrame({'expected': ytest, 'prediction': ypred1})\nprint(df1.describe())","c4f19feb":"model2 = Sequential()\n\nmodel2.add(Dense(1100,input_shape=(1276,),activation=\"elu\"))\nmodel2.add(Dense(640,activation = 'elu'))\nmodel2.add(Dense(1))\n\nmodel2.compile(optimizer= \"adam\", loss=\"mse\", metrics = [RootMeanSquaredError()])\n\nmodel2.fit(Xtrain, ytrain, epochs=100, verbose= 1, callbacks = [modelSave], validation_data = (Xval, yval))\n\nmodel2.evaluate(Xtest, ytest)\n\nypred2 = model2.predict(Xtest)\nypred2 = np.squeeze(ypred2, axis= 1)\n\ndf2 = pd.DataFrame({'expected': ytest, 'prediction': ypred2})\nprint(df2.describe())\n\nmodel3 = Sequential()\n\nmodel3.add(Dense(600,input_shape=(1276,),activation=\"elu\"))\nmodel3.add(Dense(1))\n\nmodel3.compile(optimizer= \"adam\", loss=\"mse\", metrics = [RootMeanSquaredError()])\n\nmodel3.fit(Xtrain, ytrain, epochs=100, verbose= 1, callbacks = [modelSave], validation_data = (Xval, yval))\n\nmodel3.evaluate(Xtest, ytest)\n\nypred3 = model3.predict(Xtest)\nypred3 = np.squeeze(ypred3, axis= 1)\n\ndf3 = pd.DataFrame({'expected': ytest, 'prediction': ypred3})\nprint(df3.describe())","fb7c7a80":"def bestPrediction(models):\n    bestModel = models[0]\n    for model in models:\n        if model.evaluate(Xtest, ytest) < bestModel.evaluate(Xtest, ytest):\n            bestModel = model\n    print(\"The best score was: \")\n    model.evaluate(Xtest, ytest)\n    print()\n    return bestModel.predict(test)  ","2ff29b2e":"models = [model3,model2,model1]\n\npred = bestPrediction(models)\npred = np.squeeze(pred, axis= 1)\n\noutput = pd.DataFrame({'id': testId, 'Eat': pred})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")\nprint(output)","f88784f3":"# **Loading Data**","f1f687c3":"# **Exploring the Data**","e0bda183":"# Javier Torres Notebook:","2c49e064":"This function automatically selects the model that leads to the lowest rmse","dd76a029":"No change in the data seems neccessary given that the data does not contain outlayers or missing data","dd0882cb":"# **Building the networks**","9ae59f02":"# **Choosing the model**"}}