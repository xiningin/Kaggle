{"cell_type":{"c07d08b0":"code","6d88a502":"code","889b33ba":"code","7608cb51":"code","ce703b5b":"code","20cd64c7":"code","555530f8":"code","5536037c":"code","f3cf023d":"code","72646fff":"code","22ec7dfe":"code","356bd2ac":"code","1d7dbcc4":"code","a9e74856":"code","0f5ecdcc":"code","cb17ec4f":"code","96067764":"code","8163a30d":"code","44873a1f":"code","871edcfc":"code","44113b57":"code","156dc08e":"code","9c9dbfee":"code","add54cd1":"code","e3fe498d":"code","36022e66":"code","c176f659":"code","5680e7f4":"code","ec888576":"code","d3565a5d":"code","47e8b9dd":"code","149db693":"code","22f2f67d":"code","6828acde":"code","0e8c266a":"code","9489de36":"markdown","b7b9c6b2":"markdown","7b721800":"markdown","2fa45b36":"markdown","97de3d5a":"markdown","40056678":"markdown","4a304184":"markdown","fc640f24":"markdown","cdcc8b25":"markdown","65066301":"markdown","0c3c876a":"markdown","dc422fe3":"markdown","17ce9164":"markdown","ef3278bc":"markdown","91eb3a7b":"markdown","26a2ad0a":"markdown","32b72bd5":"markdown","983954e0":"markdown","d0826d97":"markdown","4541ea4a":"markdown","cee05ed3":"markdown"},"source":{"c07d08b0":"# Supressing the warning messages\nimport warnings\nwarnings.filterwarnings('ignore')","6d88a502":"# Reading the dataset\nimport pandas as pd\nimport numpy as np\nConcreteStrengthData=pd.read_csv(\"..\/input\/concrete\/ConcreteStrengthData.csv\", encoding='latin')\nprint('Shape before deleting duplicate values:', ConcreteStrengthData.shape)\n\n# Removing duplicate rows if any\nConcreteStrengthData=ConcreteStrengthData.drop_duplicates()\nprint('Shape After deleting duplicate values:', ConcreteStrengthData.shape)\n\n# Printing sample data\n# Start observing the Quantitative\/Categorical\/Qualitative variables\nConcreteStrengthData.head(10)","889b33ba":"%matplotlib inline\n# Creating Bar chart as the Target variable is Continuous\nConcreteStrengthData['Strength'].hist()","7608cb51":"# Looking at sample rows in the data\nConcreteStrengthData.head()","ce703b5b":"ConcreteStrengthData.info()","20cd64c7":"# Looking at the descriptive statistics of the data\nConcreteStrengthData.describe(include='all')","555530f8":"ConcreteStrengthData.nunique()","5536037c":"# Plotting histograms of multiple columns together\nConcreteStrengthData.hist(['CementComponent ', 'BlastFurnaceSlag', 'FlyAshComponent',\n                'WaterComponent', 'SuperplasticizerComponent','CoarseAggregateComponent', \n                           'FineAggregateComponent', 'AgeInDays'], figsize=(18,10))","f3cf023d":"ConcreteStrengthData.isnull().sum()","72646fff":"ContinuousCols=['CementComponent ', 'BlastFurnaceSlag', 'FlyAshComponent',\n                'WaterComponent', 'SuperplasticizerComponent','CoarseAggregateComponent', \n                           'FineAggregateComponent', 'AgeInDays']\n\n# Plotting scatter chart for each predictor vs the target variable\nfor predictor in ContinuousCols:\n    ConcreteStrengthData.plot.scatter(x=predictor, y='Strength', figsize=(10,5), title=predictor+\" VS \"+ 'Strength')","22ec7dfe":"# Calculating correlation matrix\nContinuousCols=['Strength','CementComponent ', 'BlastFurnaceSlag', 'FlyAshComponent',\n                'WaterComponent', 'SuperplasticizerComponent','CoarseAggregateComponent', \n                           'FineAggregateComponent', 'AgeInDays']\n\n# Creating the correlation matrix\nCorrelationData=ConcreteStrengthData[ContinuousCols].corr()\nCorrelationData","356bd2ac":"# Filtering only those columns where absolute correlation > 0.5 with Target Variable\n# reduce the 0.5 threshold if no variable is selected\nCorrelationData['Strength'][abs(CorrelationData['Strength']) > 0.3 ]","1d7dbcc4":"SelectedColumns=['CementComponent ','SuperplasticizerComponent','AgeInDays']\n\n# Selecting final columns\nDataForML=ConcreteStrengthData[SelectedColumns]\nDataForML.head()\n","a9e74856":"DataForML.to_pickle('DataForML.pkl')","0f5ecdcc":"# Treating all the nominal variables at once using dummy variables\nDataForML_Numeric=pd.get_dummies(DataForML)\n\n# Adding Target Variable to the data\nDataForML_Numeric['Strength']=ConcreteStrengthData['Strength']\n\n# Printing sample rows\nDataForML_Numeric.head()","cb17ec4f":"DataForML_Numeric.columns","96067764":"# Separate Target Variable and Predictor Variables\nTargetVariable='Strength'\nPredictors=['CementComponent ', 'SuperplasticizerComponent', 'AgeInDays']\n\nX=DataForML_Numeric[Predictors].values\ny=DataForML_Numeric[TargetVariable].values\n\n# Split the data into training and testing set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=428)\n","8163a30d":"### Sandardization of data ###\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n# Choose either standardization or Normalization\n# On this data Min Max Normalization produced better results\n\n# Choose between standardization and MinMAx normalization\n#PredictorScaler=StandardScaler()\nPredictorScaler=MinMaxScaler()\n\n# Storing the fit object for later reference\nPredictorScalerFit=PredictorScaler.fit(X)\n\n# Generating the standardized values of X\nX=PredictorScalerFit.transform(X)\n\n# Split the data into training and testing set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","44873a1f":"# Sanity check for the sampled data\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","871edcfc":"# Multiple Linear Regression\nfrom sklearn.linear_model import LinearRegression\nRegModel = LinearRegression()\n\n# Printing all the parameters of Linear regression\nprint(RegModel)\n\n# Creating the model on Training Data\nLREG=RegModel.fit(X_train,y_train)\nprediction=LREG.predict(X_test)\n\n# Taking the standardized values to original scale\n\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, LREG.predict(X_train)))\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['Strength']-TestingDataResults['PredictedStrength']))\/TestingDataResults['Strength'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","44113b57":"# Decision Trees (Multiple if-else statements!)\nfrom sklearn.tree import DecisionTreeRegressor\nRegModel = DecisionTreeRegressor(max_depth=6,criterion='mse')\n# Good Range of Max_depth = 2 to 20\n\n# Printing all the parameters of Decision Tree\nprint(RegModel)\n\n# Creating the model on Training Data\nDT=RegModel.fit(X_train,y_train)\nprediction=DT.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, DT.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(DT.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['Strength']-TestingDataResults['PredictedStrength']))\/TestingDataResults['Strength'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","156dc08e":"# Random Forest (Bagging of multiple Decision Trees)\nfrom sklearn.ensemble import RandomForestRegressor\nRegModel = RandomForestRegressor(max_depth=5, n_estimators=100,criterion='mse')\n# Good range for max_depth: 2-10 and n_estimators: 100-1000\n\n# Printing all the parameters of Random Forest\nprint(RegModel)\n\n# Creating the model on Training Data\nRF=RegModel.fit(X_train,y_train)\nprediction=RF.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, RF.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(RF.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['Strength']-TestingDataResults['PredictedStrength']))\/TestingDataResults['Strength'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","9c9dbfee":"# Adaboost (Boosting of multiple Decision Trees)\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Choosing Decision Tree with 10 level as the weak learner\nDTR=DecisionTreeRegressor(max_depth=10)\nRegModel = AdaBoostRegressor(n_estimators=100, base_estimator=DTR ,learning_rate=0.04)\n\n# Printing all the parameters of Adaboost\nprint(RegModel)\n\n# Creating the model on Training Data\nAB=RegModel.fit(X_train,y_train)\nprediction=AB.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, AB.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(AB.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['Strength']-TestingDataResults['PredictedStrength']))\/TestingDataResults['Strength'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","add54cd1":"# Xtreme Gradient Boosting (XGBoost)\nfrom xgboost import XGBRegressor\nRegModel=XGBRegressor(max_depth=10, \n                      learning_rate=0.1, \n                      n_estimators=100, \n                      objective='reg:linear', \n                      booster='gbtree')\n\n# Printing all the parameters of XGBoost\nprint(RegModel)\n\n# Creating the model on Training Data\nXGB=RegModel.fit(X_train,y_train)\nprediction=XGB.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, XGB.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n%matplotlib inline\nfeature_importances = pd.Series(XGB.feature_importances_, index=Predictors)\nfeature_importances.nlargest(10).plot(kind='barh')\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['Strength']-TestingDataResults['PredictedStrength']))\/TestingDataResults['Strength'])\n\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","e3fe498d":"# K-Nearest Neighbor(KNN)\nfrom sklearn.neighbors import KNeighborsRegressor\nRegModel = KNeighborsRegressor(n_neighbors=2)\n\n# Printing all the parameters of KNN\nprint(RegModel)\n\n# Creating the model on Training Data\nKNN=RegModel.fit(X_train,y_train)\nprediction=KNN.predict(X_test)\n\nfrom sklearn import metrics\n# Measuring Goodness of fit in Training data\nprint('R2 Value:',metrics.r2_score(y_train, KNN.predict(X_train)))\n\n# Plotting the feature importance for Top 10 most important columns\n# The variable importance chart is not available for KNN\n\n###########################################################################\nprint('\\n##### Model Validation and Accuracy Calculations ##########')\n\n# Printing some sample values of prediction\nTestingDataResults=pd.DataFrame(data=X_test, columns=Predictors)\nTestingDataResults[TargetVariable]=y_test\nTestingDataResults[('Predicted'+TargetVariable)]=np.round(prediction)\n\n# Printing sample prediction values\nprint(TestingDataResults[[TargetVariable,'Predicted'+TargetVariable]].head())\n\n# Calculating the error for each row\nTestingDataResults['APE']=100 * ((abs(\n  TestingDataResults['Strength']-TestingDataResults['PredictedStrength']))\/TestingDataResults['Strength'])\n\nMAPE=np.mean(TestingDataResults['APE'])\nMedianMAPE=np.median(TestingDataResults['APE'])\n\nAccuracy =100 - MAPE\nMedianAccuracy=100- MedianMAPE\nprint('Mean Accuracy on test data:', Accuracy) # Can be negative sometimes due to outlier\nprint('Median Accuracy on test data:', MedianAccuracy)\n\n# Defining a custom function to calculate accuracy\n# Make sure there are no zeros in the Target variable if you are using MAPE\ndef Accuracy_Score(orig,pred):\n    MAPE = np.mean(100 * (np.abs(orig-pred)\/orig))\n    #print('#'*70,'Accuracy:', 100-MAPE)\n    return(100-MAPE)\n\n# Custom Scoring MAPE calculation\nfrom sklearn.metrics import make_scorer\ncustom_Scoring=make_scorer(Accuracy_Score, greater_is_better=True)\n\n# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","36022e66":"# Separate Target Variable and Predictor Variables\nTargetVariable='Strength'\n\n# Selecting the final set of predictors for the deployment\n# Based on the variable importance charts of multiple algorithms above\nPredictors=['CementComponent ', 'SuperplasticizerComponent', 'AgeInDays']\n\nX=DataForML_Numeric[Predictors].values\ny=DataForML_Numeric[TargetVariable].values\n\n### Sandardization of data ###\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n# Choose either standardization or Normalization\n# On this data Min Max Normalization produced better results\n\n# Choose between standardization and MinMAx normalization\n#PredictorScaler=StandardScaler()\nPredictorScaler=MinMaxScaler()\n\n# Storing the fit object for later reference\nPredictorScalerFit=PredictorScaler.fit(X)\n\n# Generating the standardized values of X\nX=PredictorScalerFit.transform(X)\n\nprint(X.shape)\nprint(y.shape)","c176f659":"# Importing cross validation function from sklearn\nfrom sklearn.model_selection import cross_val_score\n\n# Using final hyperparameters\n# Adaboost (Boosting of multiple Decision Trees)\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Choosing Decision Tree with 10 level as the weak learner\nDTR=DecisionTreeRegressor(max_depth=10)\nRegModel = AdaBoostRegressor(n_estimators=100, base_estimator=DTR ,learning_rate=0.04)\n\n# Running 10-Fold Cross validation on a given algorithm\n# Passing full data X and y because the K-fold will split the data and automatically choose train\/test\nAccuracy_Values=cross_val_score(RegModel, X , y, cv=10, scoring=custom_Scoring)\nprint('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\nprint('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))","5680e7f4":"Final_ADABOOST_Model=RegModel.fit(X,y)","ec888576":"import pickle\nimport os\n\n# Saving the Python objects as serialized files can be done using pickle library\n# Here let us save the Final ZomatoStrengthModel\nwith open('Final_ADABOOST_Model.pkl', 'wb') as fileWriteStream:\n    pickle.dump(Final_ADABOOST_Model, fileWriteStream)\n    # Don't forget to close the filestream!\n    fileWriteStream.close()\n    \nprint('pickle file of Predictive Model is saved at Location:',os.getcwd())","d3565a5d":"# This Function can be called from any from any front end tool\/website\ndef FunctionPredictResult(InputData):\n    import pandas as pd\n    Num_Inputs=InputData.shape[0]\n    \n    # Making sure the input data has same columns as it was used for training the model\n    # Also, if standardization\/normalization was done, then same must be done for new input\n    \n    # Appending the new data with the Training data\n    DataForML=pd.read_pickle('DataForML.pkl')\n    InputData=InputData.append(DataForML)\n    \n    # Generating dummy variables for rest of the nominal variables\n    InputData=pd.get_dummies(InputData)\n            \n    # Maintaining the same order of columns as it was during the model training\n    Predictors=['CementComponent ', 'SuperplasticizerComponent', 'AgeInDays']\n    \n    # Generating the input values to the model\n    X=InputData[Predictors].values[0:Num_Inputs]\n    \n    # Generating the standardized values of X since it was done while model training also\n    X=PredictorScalerFit.transform(X)\n    \n    # Loading the Function from pickle file\n    import pickle\n    with open('Final_ADABOOST_Model.pkl', 'rb') as fileReadStream:\n        PredictionModel=pickle.load(fileReadStream)\n        # Don't forget to close the filestream!\n        fileReadStream.close()\n            \n    # Generating Predictions\n    Prediction=PredictionModel.predict(X)\n    PredictionResult=pd.DataFrame(Prediction, columns=['Prediction'])\n    return(round(PredictionResult))","47e8b9dd":"# Calling the function for some new data\nNewSampleData=pd.DataFrame(\ndata=[[540,2.5,28],\n     [332,2.5,270]],\ncolumns=['CementComponent ', 'SuperplasticizerComponent', 'AgeInDays'])\n\nprint(NewSampleData)\n\n# Calling the Function for prediction\nFunctionPredictResult(InputData= NewSampleData)","149db693":"# Creating the function which can take inputs and perform prediction\ndef FunctionGeneratePrediction(inp_CementComponent, inp_SuperplasticizerComponent, inp_AgeInDays):\n    \n    # Creating a data frame for the model input\n    SampleInputData=pd.DataFrame(\n     data=[[inp_CementComponent, inp_SuperplasticizerComponent, inp_AgeInDays]],\n     columns=['CementComponent ', 'SuperplasticizerComponent', 'AgeInDays'])\n\n    # Calling the function defined above using the input parameters\n    Predictions=FunctionPredictResult(InputData= SampleInputData)\n\n    # Returning the predictions\n    return(Predictions.to_json())\n\n# Function call\nFunctionGeneratePrediction(inp_CementComponent=540, \n                           inp_SuperplasticizerComponent=2.5, \n                           inp_AgeInDays=28\n                             )","22f2f67d":"from flask import Flask, request, jsonify\nimport pickle\nimport pandas as pd\nimport numpy","6828acde":"app = Flask(__name__)\n\n@app.route('\/prediction_api', methods=[\"GET\"])\ndef prediction_api():\n    try:\n        # Getting the paramters from API call\n        cement_value=float(request.args.get('cement'))\n        plasticizer_value=float(request.args.get('plasticizer'))\n        age_value=float(request.args.get('age'))\n                \n        # Calling the funtion to get predictions\n        prediction_from_api=FunctionGeneratePrediction(\n                                        inp_CementComponent=cement_value, \n                                        inp_SuperplasticizerComponent=plasticizer_value, \n                                        inp_AgeInDays=age_value\n                                                        )\n\n        return (prediction_from_api)\n    \n    except Exception as e:\n        return('Something is not right!:'+str(e))","0e8c266a":"import os\nif __name__ ==\"__main__\":\n    \n    # Hosting the API in localhost\n    app.run(host='127.0.0.1', port=8080, threaded=True, debug=True, use_reloader=False)\n    # Interrupt kernel to stop the API","9489de36":"# Machine Learning: Splitting the data into Training and Testing sample","b7b9c6b2":"# Statistical Feature Selection (Continuous Vs Continuous) using Correlation value","7b721800":"# Standardization\/Normalization of data","2fa45b36":"Data description\nThe business meaning of each column in the data is as below\n\nCementComponent: How much cement is mixed\n\nBlastFurnaceSlag: How much Blast Furnace Slag is mixed\n\nFlyAshComponent: How much FlyAsh is mixed\n\nWaterComponent: How much water is mixed\n\nSuperplasticizerComponent: How much Super plasticizer is mixed\n\nCoarseAggregateComponent: How much Coarse Aggregate is mixed\n\nFineAggregateComponent: How much Coarse Aggregate is mixed\n\nAgeInDays: How many days it was left dry\n\nStrength: What was the final strength of concrete\n","97de3d5a":"# Selecting final predictors for Machine Learning","40056678":"# Multiple Linear Regression","4a304184":"# XGBoost","fc640f24":"# Relationship exploration: Continuous Vs Continuous -- Scatter Charts","cdcc8b25":"# Random Forest","65066301":"# Exploratory Data Analysis","0c3c876a":"I am choosing ADABOOST as the final model since it is producing the best accuracy on this data.","dc422fe3":"# Starting the API engine","17ce9164":"# Basic Data Exploration","ef3278bc":"# Data Pre-processing for Machine Learning","91eb3a7b":"# Deployment of the Model","26a2ad0a":"# Creating Flask API","32b72bd5":"# Deploying a predictive model as an API","983954e0":"# KNN","d0826d97":"# AdaBoost\n","4541ea4a":"# Decision Trees","cee05ed3":"# Looking at the distribution of Target variable"}}