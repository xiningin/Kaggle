{"cell_type":{"e2d5a665":"code","ed3739d8":"code","1ae72cd4":"code","7f0d70ad":"code","8612dfec":"code","865344c7":"code","68c8ac23":"code","dd9dc531":"code","a0afd724":"code","69c2d30c":"code","2dcea56f":"code","19d0fd2e":"code","016d6da7":"code","645be517":"code","d58bf8ff":"code","29691c83":"code","07ab1c47":"code","657ada57":"code","22174693":"code","be0adce8":"code","fe027b9d":"code","ebf728ba":"code","8eacafa4":"code","c0ee82d6":"markdown","ddd92d9e":"markdown"},"source":{"e2d5a665":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ed3739d8":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical#\u8f6c\u6362\u6210one-hot\u7684\u5f62\u5f0f\n\nfrom keras.models import Sequential\nfrom keras.layers import BatchNormalization,Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\n\nsns.set(style='white', context='notebook', palette='deep')","1ae72cd4":"train=pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest=pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","7f0d70ad":"def load_data():\n    \"\"\"Loads the MNIST dataset.\n\n    # Arguments\n        path: path where to cache the dataset locally\n            (relative to ~\/.keras\/datasets).\n\n    # Returns\n        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n        \"\"\"\n    path='\/kaggle\/input\/mnist-numpy\/mnist.npz'\n    f = np.load(path)\n    x_train, y_train = f['x_train'], f['y_train']\n    x_test, y_test = f['x_test'], f['y_test']\n    f.close()\n    return (x_train, y_train), (x_test, y_test)","8612dfec":"Y_train=train[\"label\"]\nX_train=train.drop(\"label\",axis=1)\n#del train  #\u91ca\u653e\u5185\u5b58\u7a7a\u95f4\n(x_train1,y_train1),(x_test1,y_test1)=load_data()\ntrain1=np.concatenate([x_train1,x_test1],axis=0)\ny_train1=np.concatenate([y_train1,y_test1],axis=0)\nY_train1=y_train1\nX_train1=train1.reshape(-1,28*28)","865344c7":"g=sns.countplot(Y_train)\ng1=sns.countplot(Y_train1)\nY_train.value_counts()","68c8ac23":"sns.countplot(Y_train1)","dd9dc531":"X_train.isnull().any().describe()","a0afd724":"#Normalization\nX_train=X_train\/255.0\ntest=test\/255.0\nX_train1=X_train1\/255.0","69c2d30c":"X_train = np.concatenate((X_train.values, X_train1))\nY_train = np.concatenate((Y_train, Y_train1))\nX_train=X_train.reshape(-1,28,28,1)\ntest=test.values.reshape(-1,28,28,1)\n","2dcea56f":"Y_train = to_categorical(Y_train,num_classes=10)\n","19d0fd2e":"random_seed=2","016d6da7":"X_train,X_val,Y_train,Y_val=train_test_split(X_train,Y_train,test_size=0.25,random_state=random_seed)\n#help(train_test_split)","645be517":"#plt.imshow(X_train[1][:,:,0])\n#X_train[1][:,:,0]","d58bf8ff":"model=Sequential()\nmodel.add(Conv2D(filters=64,kernel_size=(5,5),padding='Same',activation='relu',input_shape=(28,28,1)))\n#\u6a21\u578b\u6539\u8fdb\uff0c\u52a0\u5165\u4e86BN\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters=64,kernel_size=(5,5),padding='Same',activation='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same',  activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3), padding = 'Same',  activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3), padding = 'Same',  activation ='relu'))\nmodel.add(BatchNormalization())\n\n\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3), padding = 'Same',  activation ='relu'))\nmodel.add(BatchNormalization())\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(10, activation = \"softmax\"))","29691c83":"# \u6253\u5370\u51famodel \u770b\u770b\nfrom keras.utils import plot_model\nplot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\nfrom IPython.display import Image\nImage(\"model.png\")","07ab1c47":"optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","657ada57":"model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","22174693":"learning_rate_reduction=ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","be0adce8":"epochs = 50 #\nbatch_size = 128","fe027b9d":"# Without data augmentation\n'''history = model.fit(X_train, \n                    Y_train, \n                    batch_size = batch_size, \n                    epochs = epochs, \n                    validation_data = (X_val, Y_val), \n                    verbose = 2,\n                    callbacks=[learning_rate_reduction])'''","ebf728ba":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)\n\nhistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] \/\/ batch_size\n                              , callbacks=[learning_rate_reduction])\n","8eacafa4":"# predict results\nresults = model.predict(test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","c0ee82d6":"# ** 2. Data preparation**","ddd92d9e":"\u8fd9\u662f\u4e00\u4e2a\u6211\u4f5c\u4e3a\u4e00\u4e2a\u65b0\u7684kaggler\u7684\u7b2c\u4e00\u573a\u6bd4\u8d5b\uff0c\u7eaf\u7cb9\u662f\u4e3a\u4e86\u5b66\u4e60\uff0c\u672c\u6587\u5168\u90e8\u662f\u53c2\u8003\u522b\u4eba\u6240\u505a\u7684\u5de5\u4f5c\uff0c\u611f\u8c22\u5927\u795e\u4eec\u7684\u5206\u4eab\u3002\n\u552f\u4e00\u4e0d\u540c\u7684\u662f\u6211\u91c7\u7528\u4e86\u66f4\u6df1\u5c42\u7684\u7f51\u7edc\uff0c\u6362\u53d6\u4e86\u66f4\u597d\u7684\u9884\u6d4b\u6548\u679c\u3002"}}