{"cell_type":{"b05ee558":"code","0a2016d3":"code","7bbc2864":"code","e0e1584f":"code","2e5d3078":"code","0caf6123":"code","b283343b":"code","dbe74ad9":"code","b586a332":"code","83929422":"code","eb427303":"code","cbde43fd":"code","c35791ca":"code","719c9fd2":"code","e7ef4fed":"code","03cc3912":"code","3d9937d1":"code","e7d37286":"code","b383db28":"code","d510a9e3":"code","2e3575a2":"markdown","c8faef8f":"markdown","bef3e947":"markdown","a56ce7c6":"markdown","0d5b46aa":"markdown","92efee84":"markdown","5be8331f":"markdown","d383069a":"markdown","0e5999c2":"markdown","3616247f":"markdown","78d8f8a7":"markdown","8a5f254a":"markdown","acfed7fc":"markdown","f435e447":"markdown","30b60d6c":"markdown","807ac05f":"markdown","3c99f56c":"markdown"},"source":{"b05ee558":"import numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom scipy import stats\n","0a2016d3":"X = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv') \ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\ny=X.SalePrice\n","7bbc2864":"normalized_data=stats.boxcox(y)\nfig,ax = plt.subplots(1,2)\nsns.distplot(y,ax=ax[0])\nax[0].set_title(\"orginal data\")\nsns.distplot(normalized_data[0] , ax=ax[1])\nax[1].set_title(\"normalized data\")","e0e1584f":"plt.figure(figsize=(10,10))\nsns.lineplot(data=X)","2e5d3078":"cor=X.corr()\nhigh_cor=cor.index[cor['SalePrice']>.5]\nplt.figure(figsize=(9,9))\nsns.heatmap(X[high_cor].corr(),annot=True,cmap='winter')","0caf6123":"features= ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt','1stFlrSF','TotRmsAbvGrd','YearRemodAdd','GarageYrBlt','MasVnrArea','Fireplaces','LotFrontage']","b283343b":"for col in features:\n    sns.lmplot(x='SalePrice',y=col,data=X)\n","dbe74ad9":"test_id = test['Id']\ntotal_data = pd.concat([X, test], axis=0, sort=False)\ntotal_data = total_data.drop(['Id', 'SalePrice'], axis=1)","b586a332":"missing_values_count = total_data.isnull().sum().sort_values(ascending=False)\ntotal_cells = np.product(total_data.shape)\ntotal_missing = missing_values_count.sum()\npercent_missing = (total_missing\/total_cells) * 100\n","83929422":"percent= (total_data.isnull().sum() \/ total_data.isnull().count().sort_values(ascending=False)*100)\nmissing_data = pd.concat([missing_values_count,percent], axis=1, keys=['missing', 'percent'])\nmissing_data.head(30)","eb427303":"total_data.drop(missing_data[missing_data['missing']>5].index,axis=1,inplace=True)","cbde43fd":"total_data.info()","c35791ca":"a=total_data.isnull().sum().sort_values(ascending=False)\na.head(20)","719c9fd2":"from sklearn.preprocessing import LabelEncoder\nobject_cols = [col for col in total_data.columns if total_data[col].dtype == \"object\"]\nlabel_encoder=LabelEncoder()\nfor col in object_cols:\n    total_data[col]=label_encoder.fit_transform(total_data[col])\ntotal_data.info()\n    ","e7ef4fed":"from sklearn.impute import SimpleImputer\nnumeric_cols = [col for col in total_data.columns if total_data[col].dtype in ['int64','float64']]\nmy_imputer=SimpleImputer(strategy='median')\ndata = pd.DataFrame(my_imputer.fit_transform(total_data))\ndata.columns = total_data.columns\na=data.isnull().sum().sort_values(ascending=False)\na.head(25)","03cc3912":"x_train =data[:len(y)]\nx_test = data[len(y):]\nx_train.info()\nx_test.info()","3d9937d1":"X_train, X_valid, y_train, y_valid = train_test_split(x_train, y, train_size=0.8, test_size=0.2, random_state=1)","e7d37286":"model = RandomForestRegressor(n_estimators=200, random_state=1)\nmodel.fit(X_train, y_train)\npreds = model.predict(X_valid)\nprint(mean_absolute_error(y_valid, preds))","b383db28":"preds_test =model.predict(x_test)\nprint(preds_test)\n","d510a9e3":"sub = pd.DataFrame()\nsub['Id'] = test_id\nsub['SalePrice'] = preds_test\nsub.to_csv('mysubmission.csv',index=False)\nprint(sub)","2e3575a2":"# Drop target from train data and add train and test data for clean simple way","c8faef8f":"# Import necessary tools","bef3e947":"**missing data and precent of missing data for each column**","a56ce7c6":"# separate train and test after clean","0d5b46aa":"# Here i use label encoder method for object columns","92efee84":"# Here i showed the relation between features and saleprice","5be8331f":"# Here i showed the corelation based on saleprice using heatmap","d383069a":"**count missing value**","0e5999c2":"# Load train and test file","3616247f":"# if you learn a single word please share with others\n**happy coding...**","78d8f8a7":" **Here i select highest corelation features**","8a5f254a":"# here i use simple imputer method for numeric value","acfed7fc":"# Here i use boxcox transformation for normalized target variable","f435e447":"**sort value based on saleprice** ","30b60d6c":"# Apply machine learning model","807ac05f":"**if you learn a single word please share with others**","3c99f56c":"**Line plot of train data**"}}