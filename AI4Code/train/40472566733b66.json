{"cell_type":{"d1cb87fa":"code","cd233ed6":"code","327f436b":"code","a1a79b51":"code","ae468aaf":"code","80a9011d":"markdown","c17e1fa7":"markdown","4d8d3ce5":"markdown","762a7540":"markdown","5694b7f8":"markdown"},"source":{"d1cb87fa":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport pickle\nimport numpy as np, pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import svm, neighbors, linear_model, neural_network\nfrom sklearn.svm import NuSVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom tqdm import tqdm\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.feature_selection import VarianceThreshold\nfrom tqdm import tqdm\nfrom datetime import datetime","cd233ed6":"train = pd.read_csv('..\/input\/instant-gratification\/train.csv')\ntest = pd.read_csv('..\/input\/instant-gratification\/test.csv')","327f436b":"m003 = '..\/input\/instantgrat-models\/M003-qda_dict-0.9637405729608689CV.pkl'\nqda_dict = pickle.load(open( m003, \"rb\" ))","a1a79b51":"startTime = datetime.now()\n\n\nBASE_DIR = '..\/input\/instant-gratification\/'\nRANDOM_STATE = 529\nMODEL_NUMBER = 'M003'\n\ntrain = pd.read_csv('{}train.csv'.format(BASE_DIR))\ntest = pd.read_csv('{}test.csv'.format(BASE_DIR))\n\noof_qda = np.zeros(len(train))\npred_te_qda = np.zeros(len(test))\n\ncols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\n\n#qda_dict = {}\n\nfor i in tqdm(range(512)):\n    train2 = train[train['wheezy-copper-turtle-magic']==i]\n    test2 = test[test['wheezy-copper-turtle-magic']==i]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n\n    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n    data2 = StandardScaler().fit_transform(PCA(svd_solver='full',n_components='mle').fit_transform(data[cols]))\n    train3 = data2[:train2.shape[0]]; test3 = data2[train2.shape[0]:]\n\n    data2 = StandardScaler().fit_transform(VarianceThreshold(threshold=1.5).fit_transform(data[cols]))\n    train4 = data2[:train2.shape[0]]; test4 = data2[train2.shape[0]:]\n\n    # STRATIFIED K FOLD (Using splits=25 scores 0.002 better but is slower)\n    # qda_dict[i] = {}\n    fold = 0\n    skf = StratifiedKFold(n_splits=5, random_state=RANDOM_STATE)\n    for train_index, test_index in skf.split(train2, train2['target']):\n        # clf = QuadraticDiscriminantAnalysis(reg_param=0.111)\n        # clf.fit(train4[train_index,:],train2.loc[train_index]['target'])\n        clf = qda_dict[i][fold]\n        oof_qda[idx1[test_index]] = clf.predict_proba(train4[test_index,:])[:,1]\n        pred_te_qda[idx2] += clf.predict_proba(test4)[:,1] \/ skf.n_splits\n        # qda_dict[i][fold] = clf\n        fold += 1\n\nCV_SCORE = roc_auc_score(train['target'], oof_qda)\nprint('qda', roc_auc_score(train['target'], oof_qda))","ae468aaf":"### SAVE RESULTS\noof_qda = oof_qda.reshape(-1, 1)\npred_te_qda = pred_te_qda.reshape(-1, 1)\n\nnp.save('{}-oof.np'.format(MODEL_NUMBER), oof_qda)\nnp.save('{}-pred_te_qda.np'.format(MODEL_NUMBER), pred_te_qda)\n\n# print('Saving model file')\n# f = open(\"{}models\/{}-qda_dict-{}CV.pkl\".format(BASE_DIR, MODEL_NUMBER, CV_SCORE), \"wb\")\n# pickle.dump(qda_dict, f)\n# f.close()\n\nss = pd.read_csv('..\/input\/instant-gratification\/sample_submission.csv'.format(BASE_DIR))\nss['target'] = pred_te_qda\nss.to_csv('{}-submission-{}CV.csv'.format(MODEL_NUMBER, CV_SCORE), index=False)\n\noof_df = train[['id','target']].copy()\noof_df[MODEL_NUMBER] = oof_qda\noof_df.to_csv('{}-oof-{}CV.csv'.format(MODEL_NUMBER, CV_SCORE), index=False)\n\nseconds_to_run = datetime.now() - startTime\nprint('Completed in {:.4f} seconds'.format(seconds_to_run.seconds))\nprint('Completed in {:.4f} minutes'.format(seconds_to_run.seconds\/60))\nprint('Completed in {:.4f} hours'.format(seconds_to_run.seconds\/60\/60))","80a9011d":"## Load the pickled dictionary of models\nThese are uploaded to kaggle as a dataset.","c17e1fa7":"# There you have it!\nYou can easily train models offline and use them in this kernel only competition.\n\nThis is allowed per the rules for instant gratification. It may not be allowed in other competitions.","4d8d3ce5":"# Inference\n- Load each model in the loop and call `predict_proba`\n- Note the commented out lines were used when training the models offline.","762a7540":"# Loading Pretrained Models\nThis kernel shows the process that can be used for training models offline or in a seperate kernel and then loading them for inference only. The training process can be explained as:\n\n1. During training a dictionary is created that will store the models `qda_dict = {}`.\n2. The a dictionary is nested in this for each loop through `for i in tqdm(range(512))` by doing `qda_dict[i] = {}`\n3. The models are saved for each fold within the loop as follows `qda_dict[i][fold] = clf`\n\nThis kernel does the inference step. The model used does not have high leaderboard score and is only an example. I have not submitted it.\n\nSome things to note:\n- Make sure your offline environment has the same version of sklearn and pickle as that used in the kaggle kernels. The best way to do this is by using the official kaggle docker image: https:\/\/github.com\/Kaggle\/docker-python\n- I did not see a huge improvement in inference time. This is probably because much of the overhead is created by the loops themselves.\n- Multiple dictionaries can be created if you are training multiple model types. Or you could nest each model within the same dictionary.","5694b7f8":"# Save the results\n- Also note the commented out lines were used when training offline."}}