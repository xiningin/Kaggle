{"cell_type":{"c0311a3b":"code","b183f72b":"code","0e36569c":"code","8af93de1":"code","c9e61a82":"code","4a3a508c":"code","8b5d8c74":"code","8f6137c7":"code","51e8d39e":"code","b914ef6d":"code","0cd89cf0":"code","0b5ee8d4":"code","572499bf":"code","0e79c142":"code","5a65d1c1":"code","31249021":"code","4c50f49c":"code","e50c60e5":"code","c2a46f90":"code","3a7d2567":"code","55878f3c":"code","5507ffa1":"code","a97d6d04":"code","2a55c90d":"code","61d8c3ad":"code","453e0fcb":"code","754045eb":"code","e23582e2":"code","4c9fb939":"markdown","1c730e53":"markdown","211e7ac5":"markdown","f72e81f2":"markdown","05e65123":"markdown"},"source":{"c0311a3b":"import numpy as np \nimport pandas as pd \nimport plotly.express as px\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)","b183f72b":"df = pd.read_csv('..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')","0e36569c":"df.describe()","8af93de1":"df.head()","c9e61a82":"df.tail()","4a3a508c":"px.histogram(df,x = 'quality')","8b5d8c74":"# finding the percentage between free aand total sulphur dioxide \ndf['relative sulphur'] = df['free sulfur dioxide']\/df['total sulfur dioxide']","8f6137c7":"#lets make some plots\nprint([i for i in df.columns])\nfig = px.imshow(df.corr())\nfig.show()\npx.scatter(df , x = 'alcohol', y = 'fixed acidity',color = 'quality')","51e8d39e":"px.scatter(df,x = 'alcohol',y = 'pH', color = 'quality')","b914ef6d":"px.scatter(df,x = 'alcohol',y = 'volatile acidity' , color = 'quality')","0cd89cf0":"px.scatter(df ,y = 'citric acid', x = 'alcohol', color = 'quality')","0b5ee8d4":"px.scatter(df , x = 'alcohol', y = 'fixed acidity',color = 'quality')","572499bf":"px.scatter(df , x = 'alcohol', y = 'relative sulphur',color = 'quality')","0e79c142":"import scipy.stats as stats\ndf = df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]","5a65d1c1":"px.histogram(df,x= 'quality')","31249021":"fig = px.imshow(df.corr())\nfig.show()","4c50f49c":"px.scatter(df , x = 'alcohol', y = 'fixed acidity',color = 'quality')","e50c60e5":"px.scatter(df,x = 'alcohol',y = 'pH', color = 'quality')","c2a46f90":"px.scatter(df,x = 'alcohol',y = 'volatile acidity' , color = 'quality')","3a7d2567":"px.scatter(df ,y = 'citric acid', x = 'alcohol', color = 'quality')","55878f3c":"px.scatter(df , x = 'alcohol', y = 'fixed acidity',color = 'quality')","5507ffa1":"px.scatter(df , x = 'alcohol', y = 'relative sulphur',color = 'quality')","a97d6d04":"n_neigh = len(np.unique(df['quality']))\ny = df.pop('quality')\n\nx = df.values","2a55c90d":"from sklearn.preprocessing import StandardScaler\nSE = StandardScaler()\nx_train,x_test, y_train, y_test = train_test_split(x,y,random_state = 42)\nSE.fit(x_train)\nx_train = SE.transform(x_train)\nx_test = SE.transform(x_test)","61d8c3ad":"model = KNeighborsClassifier(n_neighbors = n_neigh)\nmodel.fit(x_train,y_train)\nprint(f'Average K neighbors precision {model.score(x_test,y_test)}')","453e0fcb":"model2 = RandomForestClassifier(max_depth =30 , n_estimators = 200,random_state= 42)\nmodel2.fit(x_train,y_train)\nprint(f'Average Random Forest precision {model2.score(x_test,y_test)}')","754045eb":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix\nimport matplotlib.pyplot as plt\nprediction = model.predict(x_test)\nprint(classification_report(y_test,prediction))\nprint(confusion_matrix(y_test,prediction))\nplot_confusion_matrix(model, x_test, y_test) ","e23582e2":"prediction2 = model2.predict(x_test)\nprint(classification_report(y_test,prediction2))\nplot_confusion_matrix(model2, x_test, y_test) \nplt.show()","4c9fb939":"Below we are going to create a new feature in the data that is the relative amount of free sulfur in relation to the amount of total sulfur","1c730e53":"# Conclusion\nWhat did we do on this notebook?\n* First we looked at the data\n* After that we removed the outliers\n* Then we reshowed the data with the removal of the outliers \n* After that we scaled the data so the models could have a better prediction\n* Then we builded 2 models of classification with multiple classes \n* Then we ploted the confusion matrix for each model prediction \n* We also showed the precision, recall and the f1 score for every class.\n\n As we can see the results were very pleasing with an mean precision of 69% for the random Forest and a 54% mean precision for the k neighbors model.\n \n Thank you for your time and if you liked the notebook please give it an up. Any comments on how to improve the notebook please leave it below\n","211e7ac5":"# Making an simple EDA\nHere we are going to look at different data parts so we can try to see trends on the data.\nGraphs we are going to look at:\n* Graph between different features mainly involving alcohol and other features with quality as a color scale  \n* Coeficcients of correlation between the data ","f72e81f2":"# Cleaning the Data and reshowing the data.\n* Removing the outliers using z-score.\n* Reshow the data.\n\nObservations:\n\n\n**BEWARE WITH THE CHANGE IN THE COLOR SCALE**\n\n\n**COLOR SCALE IS ONLY GOOD TO SEE TREND IN DATA IN THIS CASE**","05e65123":"# Scaling the data and building the models."}}