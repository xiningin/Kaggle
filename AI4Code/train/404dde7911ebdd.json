{"cell_type":{"e380d3b0":"code","01e7490d":"code","264e1435":"code","c51ba860":"code","7beb26a9":"code","b6b706fa":"code","c7cb0ae1":"code","52fa2df3":"code","2c364e77":"code","9964230a":"code","ecb3069b":"code","0c0cf8b7":"code","e823de74":"code","40de6def":"code","bad92f17":"code","e44a570c":"code","6eb43883":"code","d87dcd43":"code","a7d81d01":"code","d1df152e":"code","26b1c934":"code","77a1b5f6":"markdown","13e55ea2":"markdown","c41e0d26":"markdown","fbf41117":"markdown","38201679":"markdown","d817863e":"markdown","03a50d21":"markdown"},"source":{"e380d3b0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport os\nfrom fastai.vision import *\nfrom fastai import *\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom functools import partial\nfrom tqdm.notebook import tqdm\nimport gc\nfrom pylab import imread,subplot,imshow,show\n%matplotlib inline","01e7490d":"path = \"\/kaggle\/input\/breast-cancer-image-data\/project\/\"","264e1435":"size = 224\nbs = 64\ndata = ImageDataBunch.from_folder(path, \n                                  ds_tfms=get_transforms(max_rotate=0.1,max_lighting=0.15),\n                                  valid_pct=0.2, \n                                  size=size, \n                                  bs=bs)\n","c51ba860":"data.show_batch(rows=4)","7beb26a9":"len(data.classes)","b6b706fa":"fb = FBeta()\nfb.average='macro'","c7cb0ae1":"arch = models.resnet50","52fa2df3":"#!mkdir -p \/tmp\/.cache\/torch\/checkpoints\/\n#!cp \/kaggle\/input\/resnet50\/resnet50.pth  \/root\/.cache\/torch\/checkpoints\/resnet50-19c8e357.pth","2c364e77":"try:\n    learn = cnn_learner(data, arch, metrics = [fb],model_dir='\/kaggle\/working').to_fp16()\nexcept:\n    !mkdir -p \/tmp\/.cache\/torch\/checkpoints\/\n    !cp \/kaggle\/input\/resnet50\/resnet50.pth  \/root\/.cache\/torch\/checkpoints\/resnet50-19c8e357.pth\n    \n    learn = cnn_learner(data, arch, metrics = [fb],model_dir='\/kaggle\/working').to_fp16()","9964230a":"learn.lr_find()\nlearn.recorder.plot()","ecb3069b":"gc.collect()","0c0cf8b7":"learn.summary()","e823de74":"lr = 1e-2","40de6def":"gc.collect()","bad92f17":"learn.fit_one_cycle(6,lr,moms=(0.9,0.8))","e44a570c":"interp = ClassificationInterpretation.from_learner(learn)","6eb43883":"interp.plot_top_losses(12,figsize=(20,8))","d87dcd43":"interp.most_confused(min_val=3)","a7d81d01":"learn.save('model1')\n","d1df152e":"learn.export('\/kaggle\/working\/breast.pkl')","26b1c934":"img = open_image('\/kaggle\/input\/breast-cancer-image-data\/project\/benin\/mdb002.jpg')\nprint(learn.predict(img)[0])\nimg","77a1b5f6":"### Total classes, length of train, validation and test set","13e55ea2":"# Using a pretrained ResNet50 model\n\n## with metrics = f1_score \n>average = macro \n\n\n* because there is class imbalance in the data set","c41e0d26":"### If it was helpful please upvote ","fbf41117":"# Using mixed precision training\n\n* Mixed precision training utilizes half-precision to speed up training, achieving the same accuracy in some cases as single-precision training using the same hyper-parameters. \n* Memory requirements are also reduced, allowing larger models and minibatches","38201679":"# Most Confused","d817863e":"# Classification Interpretation","03a50d21":"# Model Summary"}}