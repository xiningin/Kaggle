{"cell_type":{"4e82e555":"code","38b8918e":"code","b552d693":"code","794450c7":"code","343acc76":"code","6d20edca":"code","d775a052":"code","6a1543a3":"code","37cc456f":"code","a35e7091":"code","e4071df4":"code","829eb8f9":"code","46a12e74":"code","54a7cfc1":"markdown","a732fc69":"markdown","082f9778":"markdown","6bc0a013":"markdown"},"source":{"4e82e555":"import pydicom\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nfrom einops import rearrange, reduce  # pip install einops (amazing lib!)\nimport cv2\nfrom itertools import starmap\n\n%matplotlib inline","38b8918e":"# Configure a few matplotlib parameters\nplt.rcParams['figure.figsize'] = [20, 10]\nplt.rcParams['image.interpolation'] = 'bilinear'","b552d693":"def extract_image(fname):\n    ds = pydicom.read_file(str(fname))\n    return ds.pixel_array\n\nfnames = list(Path('..\/input\/siim-acr-pneumothorax-segmentation\/sample images\/').glob('*.dcm'))\nimgs = np.array(list(map(extract_image, fnames)))\nimgs.shape","794450c7":"plt.title('Input images')\nplt.imshow(rearrange(imgs, '(b1 b2) h w -> (b1 h) (b2 w)', b1=2));","343acc76":"from keras.models import load_model","6d20edca":"unet = load_model('..\/input\/u-net-lung-segmentation-montgomery-shenzhen\/unet_lung_seg.hdf5', compile=False)","d775a052":"def prepare_input(img, width=512, height=512):\n    '''\n    Prepare image to be feed into model, according to definitions made by trained model\n    '''\n    # Resize\n    x = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n    \n    # Normalize\n    x = np.float32(x) \/ 255.\n    \n    # Add channel axis\n    x = x[..., np.newaxis]\n    \n    return x","6a1543a3":"X = np.array(list(map(prepare_input, imgs)))\nX.shape","37cc456f":"y_pred = unet.predict(X)\ny_pred.shape","a35e7091":"plt.title('Input images with lung segmentation')\nplt.imshow(rearrange(X, '(b1 b2) h w () -> (b1 h) (b2 w)', b1=2))\nplt.contour(rearrange(y_pred, '(b1 b2) h w () -> (b1 h) (b2 w)', b1=2), levels=[0.5], colors='r');","e4071df4":"from scipy import ndimage\n\n# Declare structure used in morphotology opening\nmorph_structure = np.ones((11, 11))\n\ndef crop_segmentation(mask, *others, width=512, height=512, extra_space=0.1):\n    '''\n    Crop using `mask` as input. `others` are optional arguments that will be croped using `mask`\n    as reference.\n    '''\n    # Binarize mask\n    mask_bin = np.squeeze(mask) > 0.5\n    \n    # Use morphology opening to reduce small structures detected.\n    mask_bin = ndimage.morphology.binary_opening(mask_bin, morph_structure)\n    \n    # This is one of the trickest part: will label each structure and keep only the 3 biggest ones.\n    # We assume that these three ones will include the background and two lungs\n    mask_bin_label, n_labels = ndimage.label(mask_bin, np.ones((3, 3), dtype=np.uint8))\n    used_labels = np.argsort(-np.bincount(mask_bin_label.ravel()))[:3]\n\n    # Remove from mask other objects that are not top-3\n    mask_bin &= np.in1d(mask_bin_label.reshape(-1), used_labels).reshape(mask_bin.shape)\n    \n    # Squeeze horizontal and vertical dimention to find where mask begins and ends\n    mask_bin_hor = mask_bin.any(axis=0)\n    mask_bin_ver = mask_bin.any(axis=1)\n\n    # Find index of first and last positive pixel\n    xmin, xmax = np.argmax(mask_bin_hor), len(mask_bin_hor)-np.argmax(mask_bin_hor[::-1])\n    ymin, ymax = np.argmax(mask_bin_ver), len(mask_bin_ver)-np.argmax(mask_bin_ver[::-1])\n    \n    # Add extra space\n    xextra = int((xmax-xmin) * extra_space)\n    yextra = int((ymax-ymin) * extra_space)\n    xmin -= xextra\n    xmax += xextra\n    ymin -= yextra\n    ymax += yextra\n    \n    # We will use affine transform to crop image. It will deal with padding image if necessary\n    # Note: `pts` will follow a L shape: top left, bottom left and bottom right\n    # For details see: https:\/\/docs.opencv.org\/3.0-beta\/doc\/py_tutorials\/py_imgproc\/py_geometric_transformations\/py_geometric_transformations.html#affine-transformation\n    pts1 = np.float32([[xmin, ymin], [xmin, ymax], [xmax, ymax]])\n    pts2 = np.float32([[0, 0], [0, height], [width, height]])\n    M = cv2.getAffineTransform(pts1, pts2)\n\n    # Crop mask\n    mask_crop = cv2.warpAffine(mask, M, (height, width), flags=cv2.INTER_AREA, borderValue=0)\n    \n    if len(others) > 0:\n        # Crop others\n        others_crop = tuple(cv2.warpAffine(np.squeeze(other), M, (height, width), flags=cv2.INTER_AREA, borderValue=0) for other in others)\n        \n        return (mask_crop, ) + others_crop\n    else:\n        return mask_crop","829eb8f9":"y_crop, X_crop = map(np.array, zip(*starmap(crop_segmentation, zip(y_pred, X))))","46a12e74":"plt.title('Final results')\nplt.imshow(rearrange(X_crop, '(b1 b2) h w -> (b1 h) (b2 w)', b1=2))\nplt.contour(rearrange(y_crop, '(b1 b2) h w -> (b1 h) (b2 w)', b1=2), levels=[0.5], colors='r');","54a7cfc1":"I found this model in Kaggle and had good results using it to align lung images. It may be usefull for focusing on ROI region.","a732fc69":"## Load pre-trained UNet for lung segmentation\n\nWe will use the model trained here: https:\/\/www.kaggle.com\/eduardomineo\/u-net-lung-segmentation-montgomery-shenzhen\/","082f9778":"## Define function to crop using segmentation results\nThis function uses the output from unet to crop lungs. It has a few heuristics that I have to develop in order to better find the ROI.","6bc0a013":"## Load images"}}