{"cell_type":{"c17afbda":"code","a9994d10":"code","9a57e70d":"code","ba08ce50":"code","f6b5c404":"code","09373198":"code","653d1386":"code","3221f6b4":"code","3ef86462":"code","3c14677f":"code","6fac47ca":"code","35484248":"code","46338d66":"code","930628f6":"code","3e814112":"code","7dbc81c4":"code","9ae0b1eb":"code","06e2cc8b":"code","828c93d3":"code","eb3100e1":"code","2705f488":"code","e82da2bd":"code","1213b5cd":"code","f72ecf70":"code","882b136c":"code","04d94d6b":"code","416e7d11":"code","85a1afe0":"code","9c19e17b":"code","00b12cf6":"code","42ad7e18":"code","fcd11f3a":"code","93ecda1f":"code","6bf5c3ca":"code","d5101e24":"code","38dc1967":"code","6f7c0324":"code","3fec3d1f":"code","1c054204":"code","2bdb23cd":"code","6ba23e55":"code","d2d648fc":"code","8864a79d":"code","9ad7236e":"code","1eccbb52":"code","6ba662d3":"code","480bdfc3":"code","44940835":"code","075b0ed8":"code","b23c0e5d":"code","44ff6b1b":"code","224572ac":"code","30fd78d2":"code","f94f347c":"code","6f4eed56":"code","b18298da":"code","ee9be3c3":"markdown","8dda5a78":"markdown","7cb202e3":"markdown"},"source":{"c17afbda":"import os\nimport time\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import f1_score, confusion_matrix, classification_report, roc_auc_score\nwarnings.filterwarnings('ignore')\nprint(os.listdir(\"..\/input\"))\n\n%matplotlib inline","a9994d10":"%%time\ntrain_transaction = pd.read_csv('..\/input\/train_transaction.csv')\ntrain_identity = pd.read_csv('..\/input\/train_identity.csv')\ntest_transaction = pd.read_csv('..\/input\/test_transaction.csv')\ntest_identity = pd.read_csv('..\/input\/test_identity.csv')","9a57e70d":"%%time\ntrain = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\ntest = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')","ba08ce50":"del train_transaction\ndel train_identity\ndel test_transaction\ndel test_identity","f6b5c404":"def reduce_mem_usage(props):\n    start_mem_usg = props.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in props.columns:\n        if props[col].dtype != object:  # Exclude strings\n            \n            # Print current column type\n            print(\"******************************\")\n            print(\"Column: \",col)\n            print(\"dtype before: \",props[col].dtype)\n            \n            # make variables for Int, max and min\n            IsInt = False\n            mx = props[col].max()\n            mn = props[col].min()\n            \n            # Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(props[col]).all(): \n                NAlist.append(col)\n                props[col].fillna(mn-1,inplace=True)  \n                   \n            # test if column can be converted to an integer\n            asint = props[col].fillna(0).astype(np.int64)\n            result = (props[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True\n\n            \n            # Make Integer\/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        props[col] = props[col].astype(np.uint8)\n                    elif mx < 65535:\n                        props[col] = props[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        props[col] = props[col].astype(np.uint32)\n                    else:\n                        props[col] = props[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        props[col] = props[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        props[col] = props[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        props[col] = props[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        props[col] = props[col].astype(np.int64)    \n            \n            # Make float datatypes 32 bit\n            else:\n                props[col] = props[col].astype(np.float32)\n            \n            # Print new column type\n            print(\"dtype after: \",props[col].dtype)\n            print(\"******************************\")\n    \n    # Print final result\n    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n    mem_usg = props.memory_usage().sum() \/ 1024**2 \n    print(\"Memory usage is: \",mem_usg,\" MB\")\n    print(\"This is \",100*mem_usg\/start_mem_usg,\"% of the initial size\")\n    return props","09373198":"train = reduce_mem_usage(train)","653d1386":"test = reduce_mem_usage(test)","3221f6b4":"train.shape","3ef86462":"test.shape","3c14677f":"train.columns","6fac47ca":"train.head()","35484248":"null_percent = train.isnull().sum()\/train.shape[0]*100\n\ncols_to_drop = np.array(null_percent[null_percent > 50].index)\n\ncols_to_drop","46338d66":"train = train.drop(cols_to_drop, axis=1)\ntest = test.drop(cols_to_drop,axis=1)","930628f6":"null_percent = test.isnull().sum()\/train.shape[0]*100\nnull_percent[null_percent > 0]","3e814112":"null_cols = ['card4', 'card6', 'P_emaildomain', 'M1', 'M2', 'M3', 'M4', 'M6']\n\nfor i in null_cols:\n    print('data type of {} is {}'.format(i, str(train[i].dtype)))\n    train[i] = train[i].replace(np.nan, train[i].mode()[0])\n    test[i] = test[i].replace(np.nan, train[i].mode()[0])\n    print('Filled the null values of column {}'.format(i))\n    print('--------------------------------------------')","7dbc81c4":"X = train.drop('isFraud', axis=1)\ny = train['isFraud']","9ae0b1eb":"cat_data = X.select_dtypes(include='object')\nnum_data = X.select_dtypes(exclude='object')\n\ncat_cols = cat_data.columns.values\nnum_cols = num_data.columns.values\n\nprint('Categorical Columns : ',cat_cols)\nprint('Numerical Columns : ',num_cols)","06e2cc8b":"fig = plt.figure(figsize=(20,15))\n\nj = 1\nfor i in cat_cols:\n    if(i == 'P_emaildomain'):\n        continue\n    plt.subplot(3,3,j)\n    sns.countplot(x=X[i], palette='winter_r')\n    j = j + 1\n    \nplt.show()","828c93d3":"plt.figure(figsize=(20,8))\nsns.countplot(x=X['P_emaildomain'], color='blue')\nplt.xticks(rotation = 90)\nplt.show()","eb3100e1":"fig = plt.figure(figsize=(20,15))\n\nj = 1\nfor i in num_cols[1:10]:\n    plt.subplot(3,3,j)\n    sns.distplot(a=X[i])\n    j = j + 1\n    \nplt.show()","2705f488":"fig = plt.figure(figsize=(20,15))\n\nj = 1\nfor i in num_cols[-23:-11]:\n    plt.subplot(3,4,j)\n    sns.distplot(a=X[i])\n    j = j + 1\n    \nplt.show()","e82da2bd":"sns.countplot(x=y, palette='gist_rainbow')\nplt.title('Fraud or Not')\nplt.show()","1213b5cd":"df1 = train[train['isFraud'] == 0]\nnot_fraud = df1['TransactionAmt'].apply(np.log) #we will apply log transformation to get better visualization \n\ndf2 = train[train['isFraud'] == 1]\nfraud = df2['TransactionAmt'].apply(np.log) #we will apply log transformation to get better visualization \n\nplt.figure(figsize=(20, 7))\n\nsns.distplot(a=not_fraud, label='Not Fraud')\nsns.distplot(a=fraud, label='Fraud')\n\nplt.legend()","f72ecf70":"X['TransactionAmt'] = X['TransactionAmt'].apply(np.log)\ntest['TransactionAmt'] = test['TransactionAmt'].apply(np.log)","882b136c":"X = X.drop('TransactionDT', axis=1)\ntest = test.drop('TransactionDT', axis=1)","04d94d6b":"del train","416e7d11":"from sklearn.preprocessing import LabelEncoder\n\nfor i in tqdm(cat_cols): \n    label = LabelEncoder()\n    label.fit(list(X[i].values)+list(test[i].values))\n    X[i] = label.transform(list(X[i].values))\n    test[i] = label.transform(list(test[i].values))","85a1afe0":"X.head()","9c19e17b":"X = X.drop('TransactionID', axis=1)\ntest = test.drop('TransactionID', axis=1)","00b12cf6":"c = X.corr()","42ad7e18":"plt.figure(figsize=(20,20))\nsns.heatmap(c)","fcd11f3a":"col_corr = set()\nfor i in range(len(c.columns)):\n    for j in range(i):\n        if (c.iloc[i, j] >= 0.95) and (c.columns[j] not in col_corr):\n            colname = c.columns[i] # getting the name of column\n            col_corr.add(colname)","93ecda1f":"cols = X.columns\nprint('{} and {}'.format(len(cols), len(col_corr)))","6bf5c3ca":"final_columns = []\n\nfor i in cols:\n    if i in col_corr:\n        continue\n    else:\n        final_columns.append(i)","d5101e24":"X1 = X[final_columns]\ntest1 = test[final_columns]","38dc1967":"print(X1.shape)\nprint(test1.shape)","6f7c0324":"plt.figure(figsize=(20,20))\nsns.heatmap(X1.corr())","3fec3d1f":"del X\ndel test","1c054204":"params = {'objective': 'binary',  \n          'learning_rate': 0.1, \n          'num_leaves': 256,\n          'is_unbalance': True, \n          'metric': 'auc', \n          'feature_fraction': 0.8, \n          'verbosity': -1,\n          'random_state': 42\n          }","2bdb23cd":"from sklearn.model_selection import StratifiedKFold\nimport lightgbm as lgb\n\nkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\ncv_score_lgb = []\ni = 1\n#predictions = np.zeros(test1.shape[0])\n\nprint('5 Fold Stratified Cross Validation')\nprint('-----------------------------------')\nfor train_index, test_index in kf.split(X1, y):\n    print('Fold no. {}'.format(i))\n    xtr, ytr = X1.loc[train_index], y.loc[train_index]\n    xv, yv = X1.loc[test_index], y.loc[test_index]\n    \n    df_train = lgb.Dataset(xtr, label=ytr)\n    df_val = lgb.Dataset(xv, label=yv)\n    \n    clf1 = lgb.train(params, num_boost_round = 5000,train_set = df_train, valid_sets=[df_train, df_val], verbose_eval=400, early_stopping_rounds=200)\n    ypred =  clf1.predict(xv)\n    score = f1_score(yv, ypred.round())\n    print('F1-Score : {}'.format(score))\n    cv_score_lgb.append(score)\n    #predictions = predictions + clf1.predict(test1)\/5\n    i += 1\n    print('-------------------------------------')","6ba23e55":"print('Mean AUC Score : {}'.format(np.array(cv_score_lgb).mean()))","d2d648fc":"df_train = lgb.Dataset(X1, label=y)","8864a79d":"clf_final = lgb.train(params, num_boost_round = 1200,train_set = df_train, valid_sets=[df_train],\n                 verbose_eval=400, early_stopping_rounds=200)","9ad7236e":"# a = pd.Series(y).value_counts()\n# a[1]\/len(y)*100","1eccbb52":"# from sklearn.model_selection import StratifiedKFold\n\n# kf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n# cv_score = []\n# i = 1\n# predictions = np.zeros(test1.shape[0])\n# print('5 Fold Stratified Cross Validation')\n# print('-----------------------------------')\n# for train_index, test_index in kf.split(X1, y):\n#     print('Fold no. {}'.format(i))\n#     xtr, ytr = X1.loc[train_index], y.loc[train_index]\n#     xv, yv = X1.loc[test_index], y.loc[test_index]\n    \n#     clf = CatBoostClassifier(task_type='GPU', eval_metric='AUC', loss_function='Logloss', use_best_model=True,\n#                           silent=True, class_weights= [0.01, 0.99],\n#                          random_state=42, iterations=5000, od_type='Iter', od_wait=200, grow_policy='Lossguide',\n#                         max_depth = 7, l2_leaf_reg= 0.5)\n#     clf.fit(xtr, ytr, eval_set=(xv, yv))\n#     score = roc_auc_score(yv, clf.predict(xv))\n#     ypreds = clf.predict_proba(test1)\/5\n#     predictions += ypreds[:,1]\n#     print('AUC score Train : {} \\t AUC score Val : {}'.format(roc_auc_score(ytr, clf.predict(xtr)), score))\n#     cv_score.append(score)\n#     i += 1\n#     print('-------------------------------------')","6ba662d3":"# print('Mean AUC Score : {}'.format(np.array(cv_score).mean()))","480bdfc3":"# clf = CatBoostClassifier(task_type='GPU', eval_metric='AUC', loss_function='Logloss',\n#                          class_weights=[0.1, 0.9],\n#                           random_state=42, iterations=5000, od_type='Iter', od_wait=200, grow_policy='Lossguide', max_depth=8)\n# clf.fit(X1, y)","44940835":"probs = clf_final.predict(test1)","075b0ed8":"sub = pd.read_csv('..\/input\/sample_submission.csv')","b23c0e5d":"sub['isFraud'] = probs","44ff6b1b":"sub.head()","224572ac":"sub.to_csv('submission.csv', index=False)","30fd78d2":"feature_dict = {'Features': clf_final.feature_name(), 'Importance': clf_final.feature_importance()}","f94f347c":"feature_imp = pd.DataFrame(feature_dict).sort_values(by=['Importance'], ascending=False)","6f4eed56":"feature_imp.head(10)","b18298da":"plt.figure(figsize=(10,7))\ndf_imp = feature_imp.head(10)\nsns.barplot(y=df_imp['Features'], x=df_imp['Importance'], palette='winter_r')","ee9be3c3":"**Let's reduce the memory of the dataframe**","8dda5a78":"**Merging the transactions and indentity data**","7cb202e3":"**Note : The best result of this kernel is at V16.**"}}