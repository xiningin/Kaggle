{"cell_type":{"bd1b5c81":"code","7a34929f":"code","c97f58f3":"code","1459b05c":"code","ea0f0198":"code","b9902524":"code","c98cd8c8":"code","caa17075":"code","8aed1e3e":"code","ca53a290":"code","fbb5c2e6":"code","b1544557":"code","2b055ed8":"code","35a800d5":"code","73e07cdb":"code","3ae3cb56":"code","d0796683":"code","e59cc4f8":"code","94c12807":"code","9bd5a78d":"code","36d24af1":"code","6926383d":"code","c09642c4":"code","76a5b44c":"code","9e74370c":"code","73483552":"code","f5ab2515":"code","6a2ba346":"code","6e7547e8":"code","437db2b7":"code","e522970c":"code","018e3af9":"code","8c6e6ea0":"code","d694b01b":"code","1d704706":"code","9ee9c274":"code","7ac0666a":"code","aab9545d":"code","a816ef4c":"code","bc6cd9ae":"code","c87dbf72":"code","ed2660ee":"markdown"},"source":{"bd1b5c81":"# Import resources\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport time\nimport json\nimport copy\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport PIL\nimport pytesseract\nfrom PIL import Image\nfrom collections import OrderedDict\n\n\nimport torch\nfrom torch import nn, optim\nfrom torch.optim import lr_scheduler\nfrom torch.autograd import Variable\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport os","7a34929f":"# check if GPU is available\ntrain_on_gpu = torch.cuda.is_available()\n\nif not train_on_gpu:\n    print('NO GPU Found..! Training on CPU ...')\nelse:\n    print('You are good to go!  Training on GPU ...')","c97f58f3":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","1459b05c":"#load the data \ndata_dir = '..\/input\/flower_data\/flower_data'\ntrain_dir = data_dir + '\/train'\nvalid_dir = data_dir + '\/valid'\ntest_dir = '..\/input\/test set'","ea0f0198":"# Define your transforms for the training and testing sets\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomRotation(30),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], \n                             [0.229, 0.224, 0.225])\n    ]),\n    'valid': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], \n                             [0.229, 0.224, 0.225])\n    ]),\n    'test set': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], \n                             [0.229, 0.224, 0.225])\n    ])\n}\n# Load the datasets with ImageFolder\ndirs = {'train': train_dir, \n        'valid': valid_dir, \n        'test set' : test_dir}\nimage_datasets = {x: datasets.ImageFolder(dirs[x],   transform=data_transforms[x]) for x in ['train', 'valid', 'test set']}\n#image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                        #  data_transforms[x])\n                #  for x in ['train', 'valid']}\n\n# Using the image datasets and the trainforms, define the dataloaders\n\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=20, shuffle=True) for x in ['train', 'valid', 'test set']}\n#batch_size = 20\n#dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n                                           #  shuffle=True, num_workers=4)\n             # for x in ['train', 'valid']}\n\nclass_names = image_datasets['train'].classes","b9902524":"dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid','test set']}\nclass_names = image_datasets['train'].classes","c98cd8c8":"print(dataset_sizes)\nprint(device)","caa17075":"# Label mapping\nwith open('..\/input\/cat_to_name.json', 'r') as f:\n    cat_to_name = json.load(f)","8aed1e3e":"#build and train classifier\n# Run this to test the data loader\nimages, labels = next(iter(dataloaders['train']))\nimages.size()","ca53a290":" # Run this to test your data loader\nimages, labels = next(iter(dataloaders['train']))\nrand_idx = np.random.randint(len(images))\n# print(rand_idx)\nprint(\"label: {}, class: {}, name: {}\".format(labels[rand_idx].item(),\n                                               class_names[labels[rand_idx].item()],\n                                               cat_to_name[class_names[labels[rand_idx].item()]]))","fbb5c2e6":"model_name = 'densenet' #vgg\nif model_name == 'densenet':\n    model = models.densenet161(pretrained=True)\n    num_in_features = 2208\n    print(model)\nelif model_name == 'vgg':\n    model = models.vgg19(pretrained=True)\n    num_in_features = 25088\n    print(model.classifier)\nelse:\n    print(\"Unknown model, please choose 'densenet' or 'vgg'\")","b1544557":"# Create classifier\nfor param in model.parameters():\n    #we don\u2019t update the weights from the pre-trained model.\n    param.requires_grad = False\n\ndef build_classifier(num_in_features, hidden_layers, num_out_features):\n   \n    classifier = nn.Sequential()\n    if hidden_layers == None:\n        classifier.add_module('fc0', nn.Linear(num_in_features, 102))\n    else:\n        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n        classifier.add_module('fc0', nn.Linear(num_in_features, hidden_layers[0]))\n        classifier.add_module('relu0', nn.ReLU())\n        classifier.add_module('drop0', nn.Dropout(.6))\n        classifier.add_module('relu1', nn.ReLU())\n        classifier.add_module('drop1', nn.Dropout(.5))\n        for i, (h1, h2) in enumerate(layer_sizes):\n            classifier.add_module('fc'+str(i+1), nn.Linear(h1, h2))\n            classifier.add_module('relu'+str(i+1), nn.ReLU())\n            classifier.add_module('drop'+str(i+1), nn.Dropout(.5))\n        classifier.add_module('output', nn.Linear(hidden_layers[-1], num_out_features))\n        \n    return classifier","2b055ed8":"hidden_layers = None \n\nclassifier = build_classifier(num_in_features, hidden_layers, 102)\nprint(classifier)\n\n # Only train the classifier parameters, feature parameters are frozen\nif model_name == 'densenet':\n    model.classifier = classifier\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adadelta(model.parameters()) # Adadelta #weight optim.Adam(model.parameters(), lr=0.001, momentum=0.9)\n    #optimizer_conv = optim.SGD(model.parameters(), lr=0.0001, weight_decay=0.001, momentum=0.9)\n    sched = optim.lr_scheduler.StepLR(optimizer, step_size=4)\nelif model_name == 'vgg':\n    model.classifier = classifier\n    criterion = nn.NLLLoss()\n    optimizer = optim.Adam(model.classifier.parameters(), lr=0.0001)\n    sched = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\nelse:\n    pass","35a800d5":"def train_model(model, criterion, optimizer, sched, num_epochs=5):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}\/{}'.format(epoch+1, num_epochs))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        #sched.step()\n                        loss.backward()\n                        \n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss \/ dataset_sizes[phase]\n            epoch_acc = running_corrects.double() \/ dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'valid' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed \/\/ 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    #load best model weights\n    model.load_state_dict(best_model_wts)\n    \n    return model","73e07cdb":"epochs = 10\nmodel.to(device)\nmodel = train_model(model, criterion, optimizer, sched, epochs)\n\n","3ae3cb56":"# Evaluation\n\nmodel.eval()\n\naccuracy = 0\n\nfor inputs, labels in dataloaders['valid']:\n    inputs, labels = inputs.to(device), labels.to(device)\n    outputs = model(inputs)\n    \n    # Class with the highest probability is our predicted class\n    equality = (labels.data == outputs.max(1)[1])\n\n    # Accuracy is number of correct predictions divided by all predictions\n    accuracy += equality.type_as(torch.FloatTensor()).mean()\n    \nprint(\"Validation accuracy: {:.3f}\".format(accuracy\/len(dataloaders['valid'])))","d0796683":"# Saving the checkpoint\nmodel.class_to_idx = image_datasets['train'].class_to_idx","e59cc4f8":"checkpoint = {'input_size': 2208,\n              'output_size': 102,\n              'epochs': epochs,\n              'batch_size': 64,\n              'model': models.densenet161(pretrained=True),\n              'classifier': classifier,\n              'scheduler': sched,\n              'optimizer': optimizer.state_dict(),\n              'state_dict': model.state_dict(),\n              'class_to_idx': model.class_to_idx\n             }\n   \ntorch.save(checkpoint, 'checkpoint_ic_d161.pth')","94c12807":"# Loading the checkpoint\nckpt = torch.load('checkpoint_ic_d161.pth')\nckpt.keys()","9bd5a78d":"# Load a checkpoint and rebuild the model\ndef load_checkpoint(filepath):\n    checkpoint = torch.load(filepath)\n    model = checkpoint['model']\n    model.classifier = checkpoint['classifier']\n    model.load_state_dict(checkpoint['state_dict'])\n    model.class_to_idx = checkpoint['class_to_idx']\n    optimizer = checkpoint['optimizer']\n    epochs = checkpoint['epochs']\n    \n    for param in model.parameters():\n        param.requires_grad = False\n        \n    return model, checkpoint['class_to_idx']","36d24af1":"model, class_to_idx = load_checkpoint('checkpoint_ic_d161.pth')\nmodel","6926383d":"idx_to_class = { v : k for k,v in class_to_idx.items()}","c09642c4":"#Inference for Classification\n#Image Preprocessing\nimage_path = '..\/input\/test set\/test set\/ab45.jpg'\nimg = Image.open(image_path)","76a5b44c":"def process_image(image):\n    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n        returns an Numpy array\n    '''\n    # Process a PIL image for use in a PyTorch model\n    # tensor.numpy().transpose(1, 2, 0)\n    preprocess = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                             std=[0.229, 0.224, 0.225])\n    ])\n    image = preprocess(image)\n    return image","9e74370c":"def imshow(image, ax=None, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    if ax is None:\n        fig, ax = plt.subplots()\n    \n    # PyTorch tensors assume the color channel is the first dimension\n    # but matplotlib assumes is the third dimension\n    image = image.numpy().transpose((1, 2, 0))\n    \n    # Undo preprocessing\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    image = std * image + mean\n    \n    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n    image = np.clip(image, 0, 1)\n    \n    ax.imshow(image)\n    \n    return ax","73483552":"with Image.open('..\/input\/test set\/test set\/ab45.jpg') as image:\n    plt.imshow(image)","f5ab2515":"#Class Prediction\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","6a2ba346":"model.class_to_idx = image_datasets['train'].class_to_idx","6e7547e8":"def predict2(image_path, model, topk=5):\n    ''' Predict the class (or classes) of an image using a trained deep learning model.\n    '''\n    \n    # Implement the code to predict the class from an image file\n    img = Image.open(image_path)\n    img = process_image(img)\n    \n    # Convert 2D image to 1D vector\n    img = np.expand_dims(img, 0)\n    \n    \n    img = torch.from_numpy(img)\n    \n    model.eval()\n    inputs = Variable(img).to(device)\n    logits = model.forward(inputs)\n    \n    ps = F.softmax(logits,dim=1)\n    topk = ps.cpu().topk(topk)\n    \n    return (e.data.numpy().squeeze().tolist() for e in topk)","437db2b7":"#checking for one image\nimg_path = '..\/input\/test set\/test set\/ab45.jpg'\nprobs, classes = predict2(img_path, model.to(device))\nprint(probs)\nprint(classes)\nflower_names = [cat_to_name[class_names[e]] for e in classes]\nprint(flower_names)\n","e522970c":"def view_classify(img_path, prob, classes, mapping):\n    ''' Function for viewing an image and it's predicted classes.\n    '''\n    image = Image.open(img_path)\n\n    fig, (ax1, ax2) = plt.subplots(figsize=(6,10), ncols=1, nrows=2)\n    ax1.imshow(image)  \n    flower_names = [cat_to_name[class_names[e]] for e in classes]\n    flower_name =  flower_names[0]\n    ax1.set_title(flower_name)\n    ax1.axis('off')\n    \n    y_pos = np.arange(len(prob))\n    ax2.barh(y_pos, prob, align='center')\n    ax2.set_yticks(y_pos)\n    ax2.invert_yaxis() \n    ax2.set_yticklabels(flower_names)\n    # labels read top-to-bottom\n    ax2.set_title('Class Probability')\n\nview_classify(img_path, probs, classes, cat_to_name)","018e3af9":"#saving the model for test set\ntorch.save(model.state_dict(), 'model1.pth')","8c6e6ea0":"#Prediction of all images in the test set\n\ntest_data = datasets.ImageFolder(test_dir, transform=data_transforms['test set'])\ndataloader = torch.utils.data.DataLoader(test_data)","d694b01b":"data_labels = []\nmodel.to(device)\nmodel.eval()\nwith torch.no_grad():\n    for images, labels in dataloader:\n        images = images.to(device)\n        ps = model.forward(images)\n        \n        if type(ps) == tuple:\n            ps, _ = ps\n        \n        _, preds_tensor = torch.max(ps, 1)\n        preds = np.squeeze(preds_tensor.numpy())if not device else np.squeeze(preds_tensor.cpu().numpy())\n        data_labels.append(int(preds))","1d704706":"#load JSON file\nfile_path = \"..\/input\/cat_to_name.json\"\ndf = pd.read_json(file_path, typ='series')\ndf = df.to_frame('category')\ndf.head()","9ee9c274":"df.count()","7ac0666a":"files =[]\ncategories = []\nfor file in os.listdir(os.path.join(test_dir, \"test set\")):\n    files.append(file)\n\nfor i in data_labels:\n    categories.append(df.loc[i+1, 'category'])    ","aab9545d":"#Converting Test Predictions to dataframe\nd = {'Image_Name': files, 'Class_Label': data_labels, 'Flower_Category': categories}\nresult = pd.DataFrame(d)","a816ef4c":"result = result.sort_values(by=\"Image_Name\")","bc6cd9ae":"result","c87dbf72":"result.to_csv(\"..\/working\/result.csv\")","ed2660ee":"Pre-trained model of densenet161 is used.VGG19 was also checked but the results with densenet161 was better! so decided to proceed with it. Checkpoint was also created for later, testing of the given test set was done by the trained model!"}}