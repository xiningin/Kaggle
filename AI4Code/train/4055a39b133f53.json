{"cell_type":{"a8cd19af":"code","b3f96bbf":"code","c01dd6ea":"code","0c726004":"code","a40f17ee":"code","7251f827":"code","f6d78737":"code","e5cb5314":"code","0a2c7eab":"code","1d28efd0":"code","26b1d2fb":"code","48ea0585":"code","55280bb1":"markdown","dd9fbd6c":"markdown","82baa2c7":"markdown","1c12f9e4":"markdown"},"source":{"a8cd19af":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cudf\npd.set_option('display.max_columns', 500)\n\n\nimport time\nfrom tqdm.notebook import tqdm\n\n# Standard plotly imports\nimport plotly as py\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom plotly.offline import iplot, init_notebook_mode\nimport cufflinks\nimport cufflinks as cf\nimport plotly.figure_factory as ff\nimport os\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","b3f96bbf":"%%time\ntrain_cudf  = cudf.read_csv('\/kaggle\/input\/jane-street-market-prediction\/train.csv')\ntrain = train_cudf.to_pandas()\ndel train_cudf\nfeatures = pd.read_csv('..\/input\/jane-street-market-prediction\/features.csv')\nexample_test = pd.read_csv('..\/input\/jane-street-market-prediction\/example_test.csv')\nsample_prediction_df = pd.read_csv('..\/input\/jane-street-market-prediction\/example_sample_submission.csv')\nprint (\"Data is loaded!\")","c01dd6ea":"print('train shape is {}'.format(train.shape))\nprint('features shape is {}'.format(features.shape))\nprint('example_test shape is {}'.format(example_test.shape))\nprint('sample_prediction_df shape is {}'.format(sample_prediction_df.shape))","0c726004":"train.head()","a40f17ee":"missing_values_count = train.isnull().sum()\nprint (missing_values_count)\ntotal_cells = np.product(train.shape)\ntotal_missing = missing_values_count.sum()\nprint (\"% of missing data = \",(total_missing\/total_cells) * 100)","7251f827":"train = train[train['weight'] != 0]\n\ntrain = train.query('date > 85').reset_index(drop = True) \n\ntrain = train.astype({c: np.float32 for c in train.select_dtypes(include='float64').columns}) #limit memory use\n\ntrain['action'] = ((train['weight'].values * train['resp'].values) > 0).astype('int')\n\ntrain.fillna(train.mean(),inplace=True)\n\ncols = [c for c in train.columns if 'feature' in c]\n\nX_train = train.loc[:, train.columns.str.contains('feature')]\ny_train = train.loc[:, 'action']","f6d78737":"x = train['action'].value_counts().index\ny = train['action'].value_counts().values\n\ntrace2 = go.Bar(\n     x=x ,\n     y=y,\n     marker=dict(\n         color=y,\n         colorscale = 'Viridis',\n         reversescale = True\n     ),\n     name=\"Imbalance\",    \n )\nlayout = dict(\n     title=\"Data imbalance - action\",\n     #width = 900, height = 500,\n     xaxis=go.layout.XAxis(\n     automargin=True),\n     yaxis=dict(\n         showgrid=False,\n         showline=False,\n         showticklabels=True,\n #         domain=[0, 0.85],\n     ), \n)\nfig1 = go.Figure(data=[trace2], layout=layout)\niplot(fig1)","e5cb5314":"del x, y, train, features, example_test, sample_prediction_df","0a2c7eab":"import xgboost as xgb\nprint(\"XGBoost version:\", xgb.__version__)","1d28efd0":"clf = xgb.XGBClassifier(\n    n_estimators=500,\n    max_depth=11,\n    learning_rate=0.05,\n    subsample=0.9,\n    colsample_bytree=0.7,\n    missing=-999,\n    random_state=2020,\n    tree_method='gpu_hist'  # THE MAGICAL PARAMETER\n)","26b1d2fb":"%time clf.fit(X_train, y_train)","48ea0585":"TRAINING = True\n\nstart_time = time.time()\n\nif TRAINING:\n    import janestreet\n    env = janestreet.make_env()\n    th = 0.5\n    for (test_df, pred_df) in tqdm(env.iter_test()):\n        if test_df['weight'].item() > 0:\n            x_tt = test_df.loc[:, test_df.columns.str.contains('feature')].values\n            if np.isnan(x_tt[:, 1:].sum()):\n                x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:])\n            pred = clf.predict(x_tt)\n            pred_df.action = np.where(pred >= th, 1, 0).astype(int)\n        else:\n            pred_df.action = 0\n        env.predict(pred_df)\n        \nprint(f\"took: {time.time() - start_time} seconds\")","55280bb1":"# Market Prediction: XGBoost with GPU (Fit in 1min)\n\n# Check my kernel [\ud83d\udd25\ud83d\udd25 Market Prediction: CatBoost Classifier \ud83d\udd25\ud83d\udd25](https:\/\/www.kaggle.com\/hamditarek\/market-prediction-catboost-classifier) ==> Public Score: 5242.189 (version 18)","dd9fbd6c":"### Missing Values Count","82baa2c7":"## Training\n##### To activate GPU usage, simply use tree_method='gpu_hist' (took me an hour to figure out, I wish XGBoost documentation was clearer about that).","1c12f9e4":"# Is the data balanced or not?"}}