{"cell_type":{"cda48911":"code","99fb7a62":"code","185baf37":"code","f8466fcc":"code","68372e5c":"code","25b86458":"code","8a63649d":"code","c4d4d450":"code","ffccb244":"code","c327c4df":"code","d269f290":"code","591704fc":"code","e5db64c9":"code","018a05a0":"code","fcf29782":"code","dcc77fc0":"code","afa503e4":"code","7e0f0db2":"code","af2339ef":"code","eb1f9e2f":"code","726afe50":"code","27ac9b28":"code","6a5b557d":"code","4477df16":"code","b2cfdabc":"code","63479842":"markdown","078d3797":"markdown","bebcd680":"markdown","9127f2d2":"markdown","751795b7":"markdown","475fd350":"markdown","d3060c8f":"markdown","673e646e":"markdown","1b62793e":"markdown","806c7d07":"markdown"},"source":{"cda48911":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\n\nwarnings.filterwarnings('ignore')\nsns.set(style=\"whitegrid\")\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","99fb7a62":"data = '..\/input\/cybersecurity\/iot_static_data.csv'\n\ndf = pd.read_csv(data)","185baf37":"print(\"shape of dataset : \" ,df.shape)","f8466fcc":"df.head()","68372e5c":"df.info()","25b86458":"df.describe()","8a63649d":"def initial_eda(df):\n    if isinstance(df, pd.DataFrame):\n        total_na = df.isna().sum().sum()\n        print(\"Dimensions : %d rows, %d columns\" % (df.shape[0], df.shape[1]))\n        print(\"Total NA Values : %d \" % (total_na))\n        print(\"%38s %10s     %10s %10s\" % (\"Column Name\", \"Data Type\", \"#Distinct\", \"NA Values\"))\n        col_name = df.columns\n        dtyp = df.dtypes\n        uniq = df.nunique()\n        na_val = df.isna().sum()\n        for i in range(len(df.columns)):\n            print(\"%38s %10s   %10s %10s\" % (col_name[i], dtyp[i], uniq[i], na_val[i]))\n        \n    else:\n        print(\"Expect a DataFrame but got a %15s\" % (type(df)))","c4d4d450":"initial_eda(df)","ffccb244":"df[\"Class\"].value_counts()","c327c4df":"df[\"Class\"].unique()","d269f290":"# visualize frequency distribution of Lable \n\nf,ax=plt.subplots(1,2,figsize=(20,8))\n\nax[0] = df['Class'].value_counts().plot.pie(explode=None,autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Distrbution of Class')\n\n\n#f, ax = plt.subplots(figsize=(6, 8))\nax[1] = sns.countplot(x=\"Class\", data=df, palette=\"Set1\")\nax[1].set_title(\"Frequency distribution of Class\")\n\nplt.show()","591704fc":"corr = df.corr()\nsns.set(rc = {'figure.figsize':(20,20)})\nax = sns.heatmap(\n    corr, \n    vmin=-1, vmax=1, center=0,\n    cmap=sns.diverging_palette(20, 220, n=200),\n    square=True\n)\nax.set_xticklabels(\n    ax.get_xticklabels(),\n    rotation=90,\n    horizontalalignment='right'\n);","e5db64c9":"categorical = [col for col in df.columns if df[col].dtypes == 'O']\n\ncategorical","018a05a0":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\ndf[\"Class\"] = encoder.fit_transform(df[\"Class\"])\ndf[\"Source\"].unique()","fcf29782":"df[\"Source\"] = encoder.fit_transform(df[\"Source\"])","dcc77fc0":"X = df.drop(['Class'], axis=1)\n\ny = df['Class']","afa503e4":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","7e0f0db2":"# import Random Forest classifier\nfrom sklearn.ensemble import RandomForestClassifier\n# create the classifier with n_estimators = 100\n\nclf = RandomForestClassifier(n_estimators=100, random_state=0)\n\n\n\n# fit the model to the training set\n\nclf.fit(X_train, y_train)","af2339ef":"feature_scores = pd.Series(clf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n\nfeature_scores","eb1f9e2f":"# Creating a seaborn bar plot\n\n#Create a DataFrame using a Dictionary\ndata={'feature_names':feature_scores.index,'feature_importance':feature_scores}\nfeature_importance = pd.DataFrame(data)\n\n#Sort the DataFrame in order decreasing feature importance\nfeature_importance.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n\n#Define size of bar plot\nplt.figure(figsize=(10,15))\n#Plot Searborn bar chart\nsns.barplot(x=feature_importance['feature_importance'], y=feature_importance['feature_names'])\n#Add chart labels\nplt.title('RanfomForestClassifier FEATURE IMPORTANCE')\nplt.xlabel('FEATURE IMPORTANCE')\nplt.ylabel('FEATURE NAMES')","726afe50":"features = feature_scores[feature_scores >= 0.03].index","27ac9b28":"df_filtered = X[features]","6a5b557d":"df_filtered.shape","4477df16":"X_train, X_test, y_train, y_test = train_test_split(df_filtered, y, test_size = 0.3, random_state = 0)","b2cfdabc":"# instantiate the classifier with n_estimators = 100\nfrom sklearn.metrics import accuracy_score, classification_report\n\nclf = RandomForestClassifier(n_estimators=100, random_state=0)\n\n\n\n# fit the model to the training set\n\nclf.fit(X_train, y_train)\n\n\n# Predict on the test set results\n\ny_pred = clf.predict(X_test)\n\n\n\n# Check accuracy score \n\nprint('Model accuracy score with selected features : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\nprint(classification_report(y_pred,y_test))","63479842":"# Loading and Investgating Dataset","078d3797":"# Label Encoding","bebcd680":"**Visualizing Feature Importance**","9127f2d2":"# Handling Unbalanced Class","751795b7":"**2- Exploring the dataset**","475fd350":"**As seen in the perivious figures the data is unbalanced so I decided to use RandomForestClassifier as it's good in handeling the unbalanced classes and we will explore in the following cells**","d3060c8f":"# Feature Importance and Modeling","673e646e":"**As shown above the accuracy and f1-score prove that using RandomForestClassifier came with good results as shown**","1b62793e":"**1- Importing Dataset**","806c7d07":"# Specifiying Feature Vector and Target Label"}}