{"cell_type":{"89443221":"code","98089907":"code","cf8272ee":"code","51ddeb1d":"code","9c4b671d":"code","35b46a4d":"code","16dca531":"code","6206d1fc":"code","c75f2e86":"code","6d21fe2c":"code","eb1b281e":"markdown","deedab25":"markdown","df81c525":"markdown","464d7c6d":"markdown","b0eb9ec7":"markdown"},"source":{"89443221":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import Ridge","98089907":"data = pd.read_csv('..\/input\/factors-affecting-campus-placement\/Placement_Data_Full_Class.csv')","cf8272ee":"data","51ddeb1d":"data.info()","9c4b671d":"data","35b46a4d":"def binary_encode(df, column_dict):\n    df = df.copy()\n    for column, positive_value in column_dict.items():\n        df[column] = df[column].apply(lambda x: 1 if x == positive_value else 0)\n    return df\n\ndef onehot_encode(df, column_dict):\n    df = df.copy()\n    for column, prefix in column_dict.items():\n        dummies = pd.get_dummies(df[column], prefix=prefix)\n        df = pd.concat([df, dummies], axis=1)\n        df = df.drop(column, axis=1)\n    return df","16dca531":"def preprocess_inputs(df):\n    df = df.copy()\n    \n    # Encode categorical features\n    binary_feature_dict = {\n        'gender': 'M',\n        'ssc_b': 'Central',\n        'hsc_b': 'Central',\n        'workex': 'Yes',\n        'specialisation': 'Mkt&Fin',\n        'status': 'Placed'\n    }\n    \n    nominal_feature_dict = {\n        'hsc_s': 'hsc',\n        'degree_t': 'deg'\n    }\n    \n    df = binary_encode(df, binary_feature_dict)\n    df = onehot_encode(df, nominal_feature_dict)\n    \n    # Split missing salary data from df and save it for later\n    missing_salaries = df[df.isna().sum(axis=1) > 0]\n    missing_salaries = missing_salaries.drop('salary', axis=1)\n    \n    missing_salary_ids = missing_salaries['sl_no'].reset_index(drop=True).copy()\n    \n    df = df.drop(missing_salaries.index, axis=0).reset_index(drop=True)\n    \n    # Drop sl_no column\n    df = df.drop('sl_no', axis=1)\n    missing_salaries = missing_salaries.drop('sl_no', axis=1)\n    \n    # Split df into X and y\n    y = df['salary'].copy()\n    X = df.drop('salary', axis=1).copy()\n    \n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=123)\n    \n    # Scale X with a standard scaler\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    \n    X_train = scaler.transform(X_train)\n    X_test = scaler.transform(X_test)\n    missing_salaries = scaler.transform(missing_salaries)\n    \n    return X_train, X_test, y_train, y_test, missing_salaries, missing_salary_ids","6206d1fc":"X_train, X_test, y_train, y_test, missing_salaries, missing_salary_ids = preprocess_inputs(data)","c75f2e86":"model = Ridge(alpha=100.0)\nmodel.fit(X_train, y_train)\n\nmodel_r2 = model.score(X_test, y_test)\n\nprint(\"Model R^2: {:.5f}\".format(model_r2))","6d21fe2c":"missing_salary_predictions = pd.Series(model.predict(missing_salaries), name='salary')\n\nprint(\"Potential salaries for missing target values:\")\npd.concat([missing_salary_ids, missing_salary_predictions], axis=1)","eb1b281e":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/V0qZpYEAmww","deedab25":"# Preprocessing","df81c525":"# Task for Today  \n\n***\n\n## Campus Recruitment Salary Prediction  \n\nGiven *data about campus recruitment*, let's try to predict the **salary** offered to a given student.\n\nWe will use a linear regression model with L2 regularization to make our predictions.","464d7c6d":"# Getting Started","b0eb9ec7":"# Training\/Results"}}