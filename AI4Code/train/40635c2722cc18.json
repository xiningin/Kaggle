{"cell_type":{"b382a15f":"code","7124a5f7":"code","58097f14":"code","ff2d9d04":"code","6419a76a":"code","d6395cd6":"code","368cedf7":"code","bf329035":"code","f64c321b":"code","8db042f3":"code","1af888ae":"code","29ea2c5e":"code","6cebb95f":"code","19c1c89a":"code","3d4284ae":"code","fa80811a":"code","3c7b4647":"code","c42505f7":"code","db704810":"code","14029b6a":"code","beda728d":"code","1ac25a34":"code","560b7b22":"code","e5a32441":"code","2231a9f2":"code","7d995f30":"code","deac1a91":"code","69f133ed":"code","dcf71dd8":"code","404489d7":"code","788f5ade":"code","8ed60295":"code","e3277cbc":"code","91a69b93":"code","dba544d0":"code","29fa1b93":"code","ec03de82":"code","592880b9":"code","61c1a53f":"code","1592f206":"code","0ea9298a":"code","25bfe857":"code","5824104f":"code","f43e17e1":"code","fe927e68":"code","de68eb30":"code","d230b60b":"code","b9215eef":"code","470fc392":"code","8297ad21":"code","0d05fde1":"code","3b0391de":"code","54252384":"code","4996c6b3":"code","b2a6c7a1":"code","1ec58fda":"code","27ce6a08":"markdown","541e02f3":"markdown","ccd985be":"markdown","f17ebee3":"markdown","a6128ff1":"markdown","d601e107":"markdown","9e4fbe00":"markdown","a8d60fca":"markdown","e3e568ae":"markdown","a3200690":"markdown","b16831da":"markdown","b7ee6f63":"markdown","dc234110":"markdown","1ba6c1fe":"markdown","a9cef39b":"markdown","37947354":"markdown","95fc7da4":"markdown","572aaad7":"markdown","ee3d6217":"markdown","5a4dccdf":"markdown"},"source":{"b382a15f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7124a5f7":"import pandas as pd \nimport seaborn as sns \nimport matplotlib\n%matplotlib inline\nfrom matplotlib import pyplot as plt \nimport numpy as np\npd.set_option('display.max_rows',50)\nsns.set(rc={'figure.figsize':(11, 4)})# Use seaborn style defaults and set the default figure size\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nimport warnings   # To avoid warning messages in the code run\nwarnings.filterwarnings(\"ignore\")","58097f14":"item_category=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\nitems=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv')\ntrain=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv',parse_dates=[\"date\"])\n## As many data sets do contain datetime information in one of the columns, \n#pandas input function like pandas.read_csv() can do thetransformation to dates when reading the data using the parse_dates parameter with a list of the columns to read as Timestamp:\nshops=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv')\ntest=pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')","ff2d9d04":"print(item_category.isnull().sum()) # checking the null items in all files \nprint(items.isnull().sum())\nprint(train.isnull().sum())\nprint(shops.isnull().sum())\nprint(test.isnull().sum())\nprint('No null items in all files')","6419a76a":"print('item_category columns name',item_category.columns) # checking the column in all files to find common columns for merging \nprint('items columns name',items.columns)\nprint('train columns name',train.columns)\nprint('shops',shops.columns)\nprint('test',test.columns) ","d6395cd6":"## 1,. left join on 'train' and 'items'  file on matching column 'item id' . New merged file name = df_2\n## for further analysis we dont require item_category_name, shop_name, item_name as we have theri respective ids ","368cedf7":"# using merge function by setting how= left\ndf = pd.merge(train,items, on='item_id',how='left')\n# displaying the result \nprint(df)","bf329035":"df.describe()","f64c321b":"df.isnull().sum()\n# no missing values","8db042f3":"df.info()","1af888ae":"for i in df.columns: # check the no of unique values in all columns \n    print(i,' ',df[i].nunique())","29ea2c5e":"# total shops : 60\n# total item id and count : 21807\n# total item category: 84 ","6cebb95f":"for i in df.columns: # check the  unique values in all columns \n    print(i,'',df[i].unique())","19c1c89a":"df.describe(include='all')\n# mean of item_price is more than median, it means data is positively skewed ","3d4284ae":"df['item_price'].hist() ## data in item price is < RS 50000. Beyond that we have outliers ","fa80811a":"df[df['item_price']>40000].count()","3c7b4647":"sns.boxplot(x=df['item_price'],data=df)","c42505f7":"sns.displot(df, x='item_price', kind=\"kde\")","db704810":"\n# checking whether otlier exist in y variable \nsns.boxplot(df['item_cnt_day'])","14029b6a":"df[df['item_cnt_day']>150].count()","beda728d":"sns.displot(df, x='item_cnt_day', kind=\"kde\")","1ac25a34":"sns.scatterplot(x='item_price',y='item_cnt_day',data=df)","560b7b22":"corr=df.corr()\ncorr\n### No strong co relation between any variable ","e5a32441":"print(corr['item_cnt_day'].sort_values(ascending =False))","2231a9f2":"##for better analysis we are making separate column of  month from date ","7d995f30":"df[\"month\"] = df[\"date\"].dt.month","deac1a91":"df.drop('date',axis=1,inplace=True) ## dropping the date column as we have extracted three new column from date","69f133ed":"df.drop(df.loc[df['item_price']>40000].index,inplace=True)","dcf71dd8":"df.shape","404489d7":"df.drop('item_name',axis=1,inplace=True)","788f5ade":"df.drop(df.loc[df['item_cnt_day']>150].index,inplace=True)","8ed60295":"df_2 = df.groupby(['date_block_num','shop_id', 'item_id','item_category_id','month']).agg({'item_price':'mean','item_cnt_day':'sum'}).reset_index()\n## making the train data month wise \n### renaming the column item_cnt_day to item_cnt_month\ndf_2=df.rename(columns={'item_cnt_day':'item_cnt_month'},inplace=False)","e3277cbc":"test['month']=int('11')\ntest['date_block_num']=34\ntest.head()","91a69b93":"# using merge function by setting how= left\ndf_3=df.groupby(['shop_id','item_id'])['item_price'].last().reset_index()\ntest = pd.merge(test,df_3, on=['shop_id','item_id'],how='left')\n# displaying the result \nprint(test)","dba544d0":"sns.displot(test, x='item_price', kind=\"kde\")","29fa1b93":"## checking missing values in test\nprint(test.isnull().sum())\n","ec03de82":"#Replacing Missing Value with median price\ntest['item_price']=test['item_price'].fillna(test['item_price'].median())\ntest['item_price']","592880b9":"## Adding item category column in test ","61c1a53f":"test = pd.merge(test,items, on=['item_id'],how='left')\n## display the result \ntest.head()","1592f206":"test.drop('item_name',axis=1,inplace=True)","0ea9298a":"test.columns","25bfe857":"test.isnull().sum()","5824104f":"test_X= test[['shop_id', 'item_id', 'month', 'date_block_num', 'item_price', 'item_category_id']]","f43e17e1":"y=df_2[['item_cnt_month']]\nx=df_2.drop(['item_cnt_month'],axis=1)","fe927e68":"### scalling te data\n\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nsc.fit(x)\nx = sc.transform(x)","de68eb30":"x_train,x_valid,y_train,y_valid=train_test_split(x,y,train_size=0.6,random_state=100)","d230b60b":"print('x_train size',x_train.shape)\nprint('y_train size',y_train.shape)\nprint('x_valid size',x_valid.shape)\nprint('y_valid size',y_valid.shape)","b9215eef":"## Fitting into model \nfrom sklearn.linear_model import LinearRegression\nmodel=LinearRegression()\nmodel.fit(x_train,y_train)","470fc392":"## checking the acuuray from mse \n\ny_pred=model.predict(x_valid)\nfrom sklearn import metrics \nfrom math import sqrt\nmse=metrics.mean_squared_error(y_valid,y_pred)\nprint(mse)","8297ad21":"rmse=sqrt(mse)\nprint(rmse)","0d05fde1":"from sklearn import*\nrf_model = ensemble.RandomForestRegressor(n_estimators=50,\n                                           max_leaf_nodes=12,\n                                          random_state=15)\nrf_model.fit(x_train, y_train)\n\nY_pred_test = rf_model.predict(x_valid)\nY_pred_train = rf_model.predict(x_train)","3b0391de":"mse=metrics.mean_squared_error(y_valid,Y_pred_test)\nprint(mse)","54252384":"rmse=sqrt(mse)\nprint(rmse)","4996c6b3":"z = sc.transform(test_X)\nprediction_nov2015=rf_model.predict(z)","b2a6c7a1":"#Creating Dataframe to Display the output, The Id is the item id from the test data and output is the predicted cnt_per_month\nsample_submission= pd.read_csv(\"\/kaggle\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv\")\nsample_submission.item_cnt_month=prediction_nov2015\nlinear_result=sample_submission\nprint(linear_result)","1ec58fda":"linear_result.to_csv(\"Sales_Prediction.csv\",index=False)\nprint(\"Completed\")","27ce6a08":"## Random forest","541e02f3":"### converting the train data monthly basis ","ccd985be":"## Linear Regression","f17ebee3":"#### 3.4 removing outliers from item cnt day","a6128ff1":"## 2. Bivariate analysis","d601e107":"#### 3.2 Removing outliers from item price ","9e4fbe00":"#### 2. bivariate analysis of item_price and Item_count","a8d60fca":"#### no multicollinearity between variables ","e3e568ae":"### 1. Univariate Analysis","a3200690":"#### 1.1 univariate analysis of item price ","b16831da":"#### item_price and item_cnt_day has negative values","b7ee6f63":"### 3. Feature engineering","dc234110":"#### Mapped the item price column in test from train file using the same shop id and item id column. Some test ids which are not present in train will hold null values in item price","1ba6c1fe":"### Merging the file ","a9cef39b":"### 1.2 univariate analysis of 'item_cnt_day'","37947354":"### Prediction on test","95fc7da4":"#### 3.1 separating month  date as new columns","572aaad7":"### Preparing the test data","ee3d6217":"#### Since the data of item price in test is skewed we will fill the missing value through median. Mean is generally used if data in normally distributed","5a4dccdf":"#####  item price and item cnt day has negative corelation\nItems with lower sales price has more demand"}}