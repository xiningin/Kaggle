{"cell_type":{"7e1ed4af":"code","0ef5dde3":"code","90a16dd2":"code","51eb5d90":"code","99faaf95":"code","dacd1733":"code","64a185aa":"code","b8eadd4b":"code","c2e1ea9b":"code","b4e64bac":"code","13f8d9d4":"code","260133f9":"code","58d8d254":"code","fb25efc6":"code","2ea4b095":"code","b6753c5f":"code","713926ea":"code","66632527":"code","4da2975d":"code","18a96b70":"code","e95cfa57":"code","4f8a9d41":"code","d683e2c8":"code","234ddc56":"code","7267c9ca":"code","9aba3652":"code","8eb27e82":"code","10706124":"code","a6ee77b1":"code","0d8ffd79":"code","5be647d0":"code","46ffe2c3":"code","6c2db62e":"code","55465626":"code","28e86a24":"code","84895a23":"code","977ea8ed":"code","1e06e6d4":"code","74abf586":"code","83e002c7":"code","a1b4ced3":"code","3642bff5":"code","0bb80918":"code","e5a9f041":"code","649250eb":"code","740a7cf5":"code","bcd83518":"code","1b3ff6cf":"code","4c1bc438":"markdown","928595fb":"markdown","0b227a0b":"markdown","f0eba993":"markdown","5bdf491e":"markdown","3ce2d4fb":"markdown","d45116ec":"markdown","c361fabe":"markdown","ae077dbf":"markdown","c7c68912":"markdown","590a6851":"markdown","6e54be61":"markdown","da197a6d":"markdown","5d6bd130":"markdown","148eb4b0":"markdown","fce0b0d8":"markdown","3d013a3b":"markdown","947080fc":"markdown","acb0edbd":"markdown","96398055":"markdown","184b0717":"markdown","38b95224":"markdown"},"source":{"7e1ed4af":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import precision_score,recall_score, f1_score\nfrom sklearn.metrics import plot_roc_curve\nimport warnings\nwarnings.filterwarnings('ignore')","0ef5dde3":"# Setting up the parematers for matplotlib for visuala treat\nplt.rcParams['axes.labelsize'] = 15.\nplt.rcParams['xtick.labelsize'] = 15.\nplt.rcParams['ytick.labelsize'] = 15.\nplt.rcParams['figure.figsize'] = [15.,8.]\nplt.rcParams['legend.fontsize'] = 13.","90a16dd2":"# Import Dataset\ndf = pd.read_csv(\"..\/input\/heart-disease-uci\/heart.csv\")\ndf.head()","51eb5d90":"df.shape","99faaf95":"df.size","dacd1733":"df.dtypes","64a185aa":"df.isna().sum()","b8eadd4b":"df.describe()","c2e1ea9b":"df.columns","b4e64bac":"sns.histplot(x=df[\"age\"], kde=True, palette=\"magma\");","13f8d9d4":"df.sex.value_counts().plot(kind=\"bar\",color=[\"Salmon\",\"lightblue\"], xlabel=\"0= Female, 1= Male\", ylabel=\"Counts\");","260133f9":"sns.catplot(data=df, x=\"sex\", y=\"age\", hue=\"target\", palette=\"husl\");","58d8d254":"sns.set_theme(style='darkgrid')\nplt.subplot(2,3,1)\nsns.countplot(data=df,x='fbs' ,palette='magma')\nplt.subplot(2,3,2)\nsns.countplot(data=df,x='restecg',palette='magma')\nplt.subplot(2,3,3)\nsns.countplot(data=df,x='slope',palette='magma')\nplt.subplot(2,3,4)\nsns.countplot(data=df,x='ca',palette='magma')\nplt.subplot(2,3,5)\nsns.countplot(data=df,x='exang',palette='magma')\nplt.subplot(2,3,6)\nsns.countplot(data=df,x='thal',palette='magma');","fb25efc6":"#plt.figure(figsize=(20,10))\nsns.set_theme(style='darkgrid')\nplt.subplot(2,3,1)\nsns.countplot(data=df,x='fbs',palette='magma')\nplt.subplot(2,3,2)\nsns.countplot(data=df,x='restecg',palette='magma')\nplt.subplot(2,3,3)\nsns.countplot(data=df,x='slope',palette='magma')\nplt.subplot(2,3,4)\nsns.countplot(data=df,x='ca',palette='magma')\nplt.subplot(2,3,5)\nsns.countplot(data=df,x='exang',palette='magma')\nplt.subplot(2,3,6)\nsns.countplot(data=df,x='thal',palette='magma');","2ea4b095":"df.hist(figsize=(20,20), layout=(5,3));","b6753c5f":"pd.crosstab(df.cp, df.target).plot(kind=\"bar\", color=[\"Salmon\",\"lightblue\"])\nplt.xlabel(\"Types of Chest Pain\")\nplt.ylabel(\"Count\")\nplt.title(\"Chest Pain Type For Having A Heart Disease\")\nplt.xticks(rotation=0)\nplt.legend([\"No Disease\",\"Having Disease\"]);","713926ea":"plt.figure(figsize=(10,6))\nplt.scatter(df.age[df.target==0],\n           df.thalach[df.target==0],\n           c = \"g\")\nplt.scatter(df.age[df.target==1],\n           df.thalach[df.target==1],\n           c='y');\nplt.xlabel(\"Age\")\nplt.ylabel(\"Maximum Heart Rate\")\nplt.title(\"Age vs the Max Heart Rate for Heart Disease\")\nplt.legend([\"No Disease\", \"Having Disease\"]);","66632527":"df.shape","4da2975d":"plt.figure(figsize=(20,20))\nsns.set_theme(style=\"darkgrid\")\nplt.subplot(5,3,1)\nsns.boxplot(data=df,x=df.age, hue=\"target\")\nplt.subplot(5,3,2)\nsns.boxplot(data=df,x=df.sex, hue=\"target\")\nplt.subplot(5,3,3)\nsns.boxplot(data=df,x=df.cp, hue=\"target\")\nplt.subplot(5,3,4)\nsns.boxplot(data=df,x=df.trestbps, hue=\"target\")\nplt.subplot(5,3,5)\nsns.boxplot(data=df,x=df.chol, hue=\"target\")\nplt.subplot(5,3,6)\nsns.boxplot(data=df,x=df.fbs, hue=\"target\")\nplt.subplot(5,3,7)\nsns.boxplot(data=df,x=df.restecg, hue=\"target\")\nplt.subplot(5,3,8)\nsns.boxplot(data=df,x=df.thalach, hue=\"target\")\nplt.subplot(5,3,9)\nsns.boxplot(data=df,x=df.exang, hue=\"target\")\nplt.subplot(5,3,10)\nsns.boxplot(data=df,x=df.oldpeak, hue=\"target\")\nplt.subplot(5,3,11)\nsns.boxplot(data=df,x=df.slope, hue=\"target\")\nplt.subplot(5,3,12)\nsns.boxplot(data=df,x=df.ca, hue=\"target\")\nplt.subplot(5,3,13)\nsns.boxplot(data=df,x=df.thal, hue=\"target\");","18a96b70":"corr_mat = df.corr()\ncorr_mat","e95cfa57":"fig, ax = plt.subplots(figsize=(20,15))\nax = sns.heatmap(corr_mat,\n                annot=True,\n                linewidths= 0.5,\n                cmap=\"YlGnBu\",\n                fmt=\".2f\")","4f8a9d41":"df.head()","d683e2c8":"standard_scaling = StandardScaler()\ncolumn_to_scale = [\"age\",\"trestbps\",\"chol\",\"thalach\"]\ndf[column_to_scale] = standard_scaling.fit_transform(df[column_to_scale])","234ddc56":"df.head()","7267c9ca":"x=  df.drop([\"target\"], axis=1)\ny = df[\"target\"]","9aba3652":"x.head()","8eb27e82":"y.head()","10706124":"np.random.seed(42)\n\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)","a6ee77b1":"len(x_train), len(y_train)","0d8ffd79":"## Put all model into a dictionary\n\nmodels = {\"Logistic Regression\":LogisticRegression(),\n          \"RandomForestClassifier\": RandomForestClassifier(),\n          \"SVC\": LinearSVC(),\n          \"Naive Bayes\": GaussianNB(),\n          \"Desicion Tree\": DecisionTreeClassifier(),\n          \"KNN\": KNeighborsClassifier()\n         }\ndef fit_and_score(models, x_train, x_test, y_train, y_test):\n    np.random.seed(42)\n    \n    model_scores = {}\n    for name, model in models.items():\n        model.fit(x_train,y_train)\n        model_scores[name] = model.score(x_test, y_test)\n        \n    return model_scores","5be647d0":"score = fit_and_score(models= models,\n                     x_train=x_train,\n                     x_test=x_test,\n                     y_train=y_train,\n                     y_test=y_test)\nscore","46ffe2c3":"compare_score = pd.DataFrame(score, index=[\"accuracy\"])\ncompare_score.T.plot.bar()","6c2db62e":"## Create a parameter grid for logistic Rrgression\nlog_reg_grid = [    \n    {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n    'C' : np.logspace(-4, 4, 20),\n    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\n    'max_iter' : [100, 1000,2500, 5000]\n    }\n]","55465626":"# Tune Logistic Regression \nnp.random.seed(42)\ngs_log_reg = GridSearchCV(LogisticRegression(n_jobs=-1),\n                         param_grid = log_reg_grid,\n                         cv=5,\n                         verbose=True)\ngs_log_reg.fit(x_train,y_train)","28e86a24":"gs_log_reg.best_params_","84895a23":"gs_log_reg.score(x_test,y_test)","977ea8ed":"# Make preidctions on test data\ny_preds = gs_log_reg.predict(x_test)","1e06e6d4":"y_preds","74abf586":"y_test","83e002c7":"#Plot ROC curve\nplot_roc_curve(gs_log_reg,x_test,y_test)","a1b4ced3":"# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 10, stop = 80, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [2,4]\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]","3642bff5":"rf_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}","0bb80918":"np.random.seed(42)\ngs_rf_grid = GridSearchCV(RandomForestClassifier(),\n                         param_grid=rf_grid,\n                         cv=5,\n                         verbose= True,\n                         n_jobs=-1)\ngs_rf_grid.fit(x_train,y_train)","e5a9f041":"gs_rf_grid.best_params_","649250eb":"gs_rf_grid.score(x_test,y_test)","740a7cf5":"plot_roc_curve(gs_rf_grid, x_test, y_test)","bcd83518":"train_scores = []\n\n# Create a list of test scores\ntest_scores = []\n\n# Create a list of different values for n_neighbors\nneighbors = range(1, 21) # 1 to 20\n\n# Setup algorithm\nknn = KNeighborsClassifier()\n\n# Loop through different neighbors values\nfor i in neighbors:\n    knn.set_params(n_neighbors = i) # set neighbors value\n    \n    # Fit the algorithm\n    knn.fit(x_train, y_train)\n    \n    # Update the training scores\n    train_scores.append(knn.score(x_train, y_train))\n    \n    # Update the test scores\n    test_scores.append(knn.score(x_test, y_test))","1b3ff6cf":"plt.plot(neighbors, train_scores, label=\"Train score\")\nplt.plot(neighbors, test_scores, label=\"Test score\")\nplt.xticks(np.arange(1, 21, 1))\nplt.xlabel(\"Number of neighbors\")\nplt.ylabel(\"Model score\")\nplt.legend()\n\nprint(f\"Maximum KNN score on the test data: {max(test_scores)*100:.2f}%\")","4c1bc438":"## Hpyerparamter Tuning For Models","928595fb":"### Mostly the the age group Having Heart Disease is between 50 to 70","0b227a0b":"### RandomForestClassifier","f0eba993":"## Split Data into Training and Test Set","5bdf491e":"## Preparing Data For The Model","3ce2d4fb":"### Type3 is having less cases but the the problility of having a heart disease is high","d45116ec":"## Clearly cp, thalach is having high positive corelation with the target value,\n## i.e the the value of cp and thalach inceases the value of target also increases","c361fabe":"## Person Having Heart Rate Above 140 most likely to have a heart disease...where the the age group is considered as 40 to 70 ","ae077dbf":"### Heart Disease Data Dictionary\n\nThe following are the features we'll use to predict our target variable (heart disease or no heart disease).\n\n1. age - age in years \n2. sex - (1 = male; 0 = female) \n3. cp - chest pain type \n    * 0: Typical angina: chest pain related decrease blood supply to the heart\n    * 1: Atypical angina: chest pain not related to heart\n    * 2: Non-anginal pain: typically esophageal spasms (non heart related)\n    * 3: Asymptomatic: chest pain not showing signs of disease\n4. trestbps - resting blood pressure (in mm Hg on admission to the hospital)\n    * anything above 130-140 is typically cause for concern\n5. chol - serum cholestoral in mg\/dl \n    * serum = LDL + HDL + .2 * triglycerides\n    * above 200 is cause for concern\n6. fbs - (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false) \n    * '>126' mg\/dL signals diabetes\n7. restecg - resting electrocardiographic results\n    * 0: Nothing to note\n    * 1: ST-T Wave abnormality\n        - can range from mild symptoms to severe problems\n        - signals non-normal heart beat\n    * 2: Possible or definite left ventricular hypertrophy\n        - Enlarged heart's main pumping chamber\n8. thalach - maximum heart rate achieved \n9. exang - exercise induced angina (1 = yes; 0 = no) \n10. oldpeak - ST depression induced by exercise relative to rest \n    * looks at stress of heart during excercise\n    * unhealthy heart will stress more\n11. slope - the slope of the peak exercise ST segment\n    * 0: Upsloping: better heart rate with excercise (uncommon)\n    * 1: Flatsloping: minimal change (typical healthy heart)\n    * 2: Downslopins: signs of unhealthy heart\n12. ca - number of major vessels (0-3) colored by flourosopy \n    * colored vessel means the doctor can see the blood passing through\n    * the more blood movement the better (no clots)\n13. thal - thalium stress result\n    * 1,3: normal\n    * 6: fixed defect: used to be defect but ok now\n    * 7: reversable defect: no proper blood movement when excercising \n14. target - have disease or not (1=yes, 0=no) (= the predicted attribute)","c7c68912":"cp - chest pain type:\n\n0. Typical angina: chest pain related decrease blood supply to the heart\n1. Atypical angina: chest pain not related to heart\n2. Non-anginal pain: typically esophageal spasms (non heart related)\n3. Asymptomatic: chest pain not showing signs of disease","590a6851":"## Scaling The Data","6e54be61":"## KNN","da197a6d":"## Correlation Matrix between columns","5d6bd130":"## Analysing the relationship","148eb4b0":"## EDA Univariate and Bivariate Analysis","fce0b0d8":"## Modeling","3d013a3b":"## Comments\n## In trestbps,chol,fbs, thalach, oldpeak,ca and thal column have outliers","947080fc":"### Logistic Regression ","acb0edbd":"## Respective to the age, male counts are more compare to female","96398055":"### There is no missing value in the dataset","184b0717":"## Compare Scores (Initinal Score i.e Before Hyperprameter Tuning)","38b95224":"## KNN and Naive Bayes perform better than other models"}}