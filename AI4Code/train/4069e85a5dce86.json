{"cell_type":{"d24b02e2":"code","fdd891cd":"code","231b1fe2":"code","b23fd8b5":"code","f84810e2":"code","0ea7d19a":"code","7d8885f8":"code","7fad9342":"code","e98a7e95":"code","ade8dd0c":"code","723ed80f":"code","3c7e3847":"code","f85e97e8":"code","0f67b4eb":"code","a3fd7b51":"code","f0f0857e":"code","91ec70c8":"code","ccdf1813":"code","9a188256":"code","14218aab":"code","fdcbf61f":"code","d8469df0":"code","2918bbcc":"code","1267f15d":"code","d55d6c40":"code","28ccede3":"code","1173fa08":"code","171a14ab":"code","17aa5fdf":"code","6f458edd":"code","5d56f858":"code","6c724620":"code","7fa43c9e":"code","4d0ae3fd":"code","01433502":"code","863a1bdd":"code","a2a1aae2":"code","7801c884":"code","e65b722e":"markdown","8ae12051":"markdown","7655c5a9":"markdown","c154873c":"markdown","fafbe547":"markdown","c73a770d":"markdown","01f8721b":"markdown","ad17929f":"markdown","dc6e1278":"markdown","ee0913cc":"markdown","d97df83d":"markdown","83fbdcfe":"markdown","2e47b935":"markdown","072ba44c":"markdown","20455823":"markdown","d5f0ca5d":"markdown","d14bd3d2":"markdown","48b5b005":"markdown"},"source":{"d24b02e2":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","fdd891cd":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nimport tensorflow\n","231b1fe2":"(X_train, y_train), (X_test, y_test)= keras.datasets.fashion_mnist.load_data()","b23fd8b5":"X_train.shape , y_train.shape","f84810e2":"X_test.shape , y_test.shape","0ea7d19a":"X_train","7d8885f8":"X_train[0]","7fad9342":"# label\ny_train[0] ","e98a7e95":"class_labels = ['T-shirt\/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneakers','Bag','Ankle boot']","ade8dd0c":"plt.imshow(X_train[0],cmap = 'Greys')","723ed80f":"plt.imshow(X_train[1],cmap = 'Greys')","3c7e3847":"plt.imshow(X_train[2],cmap = 'Greys')","f85e97e8":"plt.figure(figsize=(16,16))\nj = 1\nfor i in np.random.randint(0,1000,25):\n  plt.subplot(5,5,j); j+=1\n  plt.imshow(X_train[i],cmap = 'Greys')\n  plt.axis('off')\n  plt.title('{} \/ {}'.format(class_labels[y_train[i]],y_train[i]))","0f67b4eb":"fashionMNIST = keras.datasets.fashion_mnist\n(x_train,y_train),(x_test,y_test) = fashionMNIST.load_data()\nx_train = np.expand_dims(x_train,-1) # OR x_train=x_train.reshape(len(x_train),28,28,1)\nx_test = np.expand_dims(x_test,-1) # OR x_test=x_test.reshape(len(x_test),28,28,1)\nei1 = np.array(pd.unique(y_train))\neindex1 = []\nprint(ei1)\nfor i in ei1:\n    eindex1.append(list(y_train).index(i))\nprint(eindex1)\n# #cross check \n# for i in eindex1:\n#     print(y_train[i])\n\nplt.figure(figsize=(24,24))\nfor x,y in enumerate(eindex1):\n  print(x_train[y].shape)\n  plt.subplot(2,5,x+1)\n  plt.imshow(tensorflow.squeeze(x_train[y]),cmap=\"Greys\")\n  plt.title('{}'.format(ei1[x]))","a3fd7b51":"# 3 dimension image\nX_train.ndim ","f0f0857e":"X_train.shape","91ec70c8":"X_train  = np.expand_dims(X_train,-1)\nX_test  = np.expand_dims(X_test,-1)","ccdf1813":"# 4 Dimension image\nX_train.ndim ","9a188256":"X_train.shape","14218aab":"X_train = X_train\/255\nX_test = X_test\/255","fdcbf61f":"# Data is in 0 to 1\nX_train","d8469df0":"X_train[0]","2918bbcc":"from sklearn.model_selection import train_test_split\nX_train, X_val , y_train , y_val = train_test_split(X_train,y_train , test_size = 0.2 , random_state = 2020)","1267f15d":"X_train.shape, y_train.shape","d55d6c40":"X_val.shape, y_val.shape","28ccede3":"model = keras.models.Sequential([\n                         keras.layers.Conv2D(filters = 64 , kernel_size = 3,strides = (1,1), padding = 'valid',activation = 'relu',input_shape = [28,28,1]), # 1st Layer\n                         keras.layers.MaxPooling2D(pool_size = (2,2)),\n\n                         keras.layers.Conv2D(filters = 128 , kernel_size = 3,strides = (2,2), padding = 'same',activation = 'relu',input_shape = [28,28,1]), # 2nd Layer\n                         keras.layers.MaxPooling2D(pool_size = (2,2)),\n\n                         keras.layers.Conv2D(filters = 64 , kernel_size = 3,strides = (2,2), padding = 'same',activation = 'relu',input_shape = [28,28,1]), # 3rd Layer\n                         keras.layers.MaxPooling2D(pool_size = (2,2)),\n\n                         keras.layers.Flatten(),\n                         keras.layers.Dense(units = 128,activation = 'relu'),\n                         keras.layers.Dropout(0.25),\n                         keras.layers.Dense(units = 256,activation = 'relu'),\n                         keras.layers.Dropout(0.5),\n                         keras.layers.Dense(units = 256,activation = 'relu'),\n                         keras.layers.Dropout(0.25),\n                         keras.layers.Dense(units = 128,activation = 'relu'),\n                         keras.layers.Dropout(0.10),\n                         keras.layers.Dense(units = 10,activation = 'softmax')  \n                        \n])","1173fa08":"keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","171a14ab":"model.summary()","17aa5fdf":"model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])","6f458edd":"model.fit(X_train,y_train,epochs = 20,batch_size = 512,verbose = 1, validation_data=(X_val,y_val))","5d56f858":"# np.expand is used to change the 3 dimension data into 4 dimension\nmodel.predict(np.expand_dims(X_test[0],axis = 0)).round(2)","6c724620":"np.argmax(model.predict(np.expand_dims(X_test[0],axis = 0)).round(2))","7fa43c9e":"# cross check \ny_test[0]","4d0ae3fd":"y_pred = model.predict(X_test).round(2)\ny_pred","01433502":"model.evaluate(X_test,y_test)","863a1bdd":"from sklearn.metrics import confusion_matrix\nplt.figure(figsize = (16,9))\ny_pred_labels = [np.argmax(label) for label in y_pred]\ncm = confusion_matrix(y_test,y_pred_labels)\nsns.heatmap(cm , annot = True,fmt = 'd',xticklabels = class_labels,yticklabels = class_labels)","a2a1aae2":"plt.figure(figsize=(16,30))\nj = 1\nfor i in np.random.randint(0,1000,60):\n  plt.subplot(10,6,j); j+=1\n  plt.imshow(X_test[i].reshape(28,28),cmap = 'Greys')\n  plt.axis('off')\n  plt.title('Actual = {} \/ {} \\nPredicted = {} \/ {}'.format(class_labels[y_test[i]],y_test[i],class_labels[np.argmax(y_pred[i])],np.argmax(y_pred[i])))","7801c884":"from sklearn.metrics import classification_report\ncr = classification_report (y_test,y_pred_labels,target_names = class_labels)\nprint(cr)","e65b722e":"![c60ceb17.png?raw=true](https:\/\/github.com\/zalandoresearch\/fashion-mnist\/blob\/master\/doc\/img\/c60ceb17.png?raw=true)","8ae12051":"## Spliting the Data into train and test set","7655c5a9":"## Spliting Dataset for validation set","c154873c":"# Convolutional Neural Network(CNN)\n### For the convolutional front-end, we can start with a Three convolutional layer with a small filter size and a modest number of filters (64) followed by a max pooling layer. The filter maps can then be flattened to provide features to the classifier.\n\n### Given that the problem is a multi-class classification, we know that we will require an output layer with 10 nodes in order to predict the probability distribution of an image belonging to each of the 10 classes. This will also require the use of a softmax activation function. Between the feature extractor and the output layer, we can add a dense layer to interpret the features, in this case with 128 nodes.\n\n### All layers will use the ReLU activation function and the He weight initialization scheme, both best practices.","fafbe547":"# Loading Data\n### There are 10 different classes of images, as following:\n\n### 0: T-shirt\/top\n\n### 1: Trouser\n\n### 2: Pullover\n\n### 3: Dress\n\n### 4: Coat\n\n### 5: Sandal\n\n### 6: Shirt\n\n### 7: Sneakers\n\n### 8: Bag\n\n### 9: Ankle boot\n\n### Image dimmensions are 28x28.","c73a770d":"# Visualizing the Output","01f8721b":"# Evaluation","ad17929f":"### Accuracy given by Train set is 0.94 and Accuracy given by Test set is 0.90, Thus we can we say that our model is generalized so no overfitting nor underfitting.","dc6e1278":"# Confusion Matrix","ee0913cc":"# Importing Libraries","d97df83d":"## Change Dimensions","83fbdcfe":"![screen-shot-2016-08-07-at-9-15-21-pm.png](https:\/\/ujwlkarn.files.wordpress.com\/2016\/08\/screen-shot-2016-08-07-at-9-15-21-pm.png)","2e47b935":"## Testing the Model","072ba44c":"# Plotting The neural Network Work flow","20455823":"## Show Image","d5f0ca5d":"# Fashion-MNIST Image Classification using Deep Learning\n### Fashion-MNIST consists of 60,000 training images and 10,000 test images. It is a MNIST-like fashion product database. The developers believe MNIST has been overused so they created this as a direct replacement for that dataset. Each image is in greyscale and associated with a label from 10 classes.\n\n### Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total.\n\n### Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255.","d14bd3d2":"## Feature Scaling","48b5b005":"## Compile and Model Fitting"}}