{"cell_type":{"180fefd9":"code","dc17bd17":"code","e5ff9611":"code","f77e39b6":"code","dd4c90b5":"code","d663baf7":"code","6f9d6c18":"code","b6f05051":"code","4fad7152":"code","02f36269":"code","06554069":"code","67cf15a3":"code","2d72f9c5":"code","4b9356d2":"code","ad697118":"code","888dd019":"code","f32472cf":"code","6b9b8ef9":"code","456772f8":"code","97375d27":"code","c4f02b4e":"code","d7961467":"code","4e0fee54":"code","eafba0ca":"code","f8a5917e":"code","59f8dcc5":"code","a523bd09":"code","1e2fbce5":"code","e255137b":"code","d86a3474":"code","38177d08":"code","edbf1981":"code","08e2e372":"code","953d2349":"code","c30fa3b3":"code","59c0cd7f":"code","b8415848":"code","7fea9485":"code","24c56476":"code","9c2743d5":"code","788622ca":"code","119e8a8a":"code","afb1e9a2":"code","f68376cf":"code","46e60d9e":"code","c9d84f52":"code","79d4a6b3":"code","3b9cde44":"code","c23a6c99":"code","3a3e324b":"code","8006ce17":"code","25c8d105":"markdown","975186b6":"markdown","d8d8cfd6":"markdown","2713411e":"markdown","d7c5cbe9":"markdown","48be1744":"markdown","13a8bab7":"markdown","ca7edfae":"markdown","90844a98":"markdown","d1646e6c":"markdown","59ac80f6":"markdown","57b8b5b2":"markdown","78e9e84c":"markdown"},"source":{"180fefd9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","dc17bd17":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator","e5ff9611":"# Standard plotly imports\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nfrom plotly.offline import iplot, init_notebook_mode\nimport plotly.figure_factory as ff\n\n# Using plotly + cufflinks in offline mode\nimport cufflinks\ncufflinks.go_offline(connected=True)\ninit_notebook_mode(connected=True)","f77e39b6":"import string\nimport nltk\nfrom nltk.corpus import stopwords \nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.metrics import accuracy_score\nimport xgboost as xgb\nfrom sklearn.model_selection import StratifiedKFold\nimport re","dd4c90b5":"!ls ..\/input\/88b2c062-9-dataset\/Dataset","d663baf7":"df = pd.read_csv(\"..\/input\/88b2c062-9-dataset\/\/Dataset\/Train.csv\")\ndf_test = pd.read_csv(\"..\/input\/88b2c062-9-dataset\/\/Dataset\/Test.csv\")","6f9d6c18":"df.shape, df_test.shape","b6f05051":"df.info()","4fad7152":"df_test.info()","02f36269":"df.head()","06554069":"df['Product_Category'].iplot(kind='hist',\n                             yTitle='count', \n                             title='Target Distribution', \n                             color='rgb(140,140,40)' )","67cf15a3":"df['Product_Category'].value_counts()","2d72f9c5":"def draw_distribution(train_df, test_df, feature_name, top_counts=None):\n    _tmp_material = (train_df[feature_name].value_counts() \/df.shape[0] * 100) [:top_counts]\n    tmp_trace = go.Bar(\n                x=_tmp_material.index,\n                y=_tmp_material.values,\n                name='training_dataset',\n            )\n\n    _tmp_material_test = (test_df[feature_name].value_counts() \/ df_test.shape[0] * 100) [:top_counts]\n    tmp_trace_test = go.Bar(\n                x=_tmp_material_test.index,\n                y=_tmp_material_test.values,\n                name='test_dataset'\n            )\n\n    layout = go.Layout(\n            barmode='group',\n            title= \" Train\/Test \" + feature_name + \" distribution\",\n            yaxis=dict(\n                title='Counts',\n            ),\n#             xaxis=dict(\n#                 title=feature_name,\n#             )\n\n        )\n\n    fig = go.Figure(data=[tmp_trace, tmp_trace_test], layout=layout)\n    iplot(fig)","4b9356d2":"draw_distribution(df, df_test, 'GL_Code')","ad697118":"print(\"# of unique categories in GL_Code train dataset: \", df['GL_Code'].nunique())\nprint(\"# of unique categories in GL_Code test dataset: \", df_test['GL_Code'].nunique())","888dd019":"draw_distribution(df, df_test, 'Vendor_Code', 75)","f32472cf":"print(\"# of unique categories in Vendor_Code train dataset: \", df['Vendor_Code'].nunique())\nprint(\"# of unique categories in Vendor_Code test dataset: \", df_test['Vendor_Code'].nunique())","6b9b8ef9":"group_labels = ['train distplot', 'test distplot']\nhist_data = [df['Inv_Amt'].values, df_test['Inv_Amt']]\ncolors = ['#37AA9C','#37AA4C' ]\n\nfig =ff.create_distplot(hist_data, group_labels,  colors=colors,  show_hist=False)\nfig['layout'].update(title='Train\/Test Inv_Amt Distribution Plot')\niplot(fig)","456772f8":"df.isnull().sum()","97375d27":"df_test.isnull().sum()","c4f02b4e":"for col in ['GL_Code', 'Vendor_Code']:\n    print(col)\n    le = LabelEncoder()\n    le.fit(list(df[col]) + list(df_test[col]))\n    df[col] = le.transform(df[col])\n    df_test[col] = le.transform(df_test[col])","d7961467":"X = df.drop('Product_Category', axis=1)\ny = df.Product_Category\ntarget = LabelEncoder()\ny_endoded = target.fit_transform(y)","4e0fee54":"selected_features = ['GL_Code','Vendor_Code', 'Inv_Amt']","eafba0ca":"X_train, X_valid, y_train, y_valid = train_test_split(X[selected_features],y_endoded, test_size=0.3, random_state=1)","f8a5917e":"param = {}\n# use softmax multi-class classification\nparam['objective'] = 'multi:softprob'\nparam['eta'] = 0.1\nparam['max_depth'] = 6\nparam['silent'] = 1\nparam['nthread'] = 4\nparam['num_class'] = len(target.classes_)\nparam['eval_metric'] = ['mlogloss']\nparam['seed'] = 1","59f8dcc5":"dtrain = xgb.DMatrix(X_train.values, label=y_train)\ndvalid = xgb.DMatrix(X_valid.values, label=y_valid)\nevallist = [(dtrain, 'train'), (dvalid, 'eval')]","a523bd09":"clf = xgb.train(param, dtrain, 100, evallist, verbose_eval=50)","1e2fbce5":"y_pred_valid = clf.predict(dvalid)\nprint(\"Accuracy : \",accuracy_score(y_valid, np.argmax(y_pred_valid, axis=1)))","e255137b":"xgb.plot_importance(clf, importance_type='gain');","d86a3474":"dtest = xgb.DMatrix(df_test[selected_features].values)\ny_test_pred = clf.predict(dtest)","38177d08":"output = df_test[['Inv_Id']].copy()\noutput['Product_Category'] = target.inverse_transform(np.argmax(y_test_pred, axis=1))","edbf1981":"output.head()","08e2e372":"print(\"Total Product Categories : {0} | predicted categories: {1} \".format(len(target.classes_), output['Product_Category'].nunique()))","953d2349":"output.to_csv(\".\/product_category_submission_selected_features.csv\", index=False)","c30fa3b3":"stop_words = set(stopwords.words('english'))\ndef tokenize(text):\n    '''\n        Input: text\n        Returns: clean tokens\n        Desc:\n            Generates a clean token of text (words) by first getting words from the text.\n            Normalize the text by lowering it and removes the extra spaces, punctuation and stopwords.\n    '''    \n    txt = re.sub(\"[^A-Za-z]+\", \" \", text)\n    tokens = txt.split()\n\n    clean_tokens = []\n    for tok in tokens:\n        #\n        if tok not in string.punctuation and tok not in stop_words:\n            clean_tok = tok.lower().strip()\n            clean_tokens.append(clean_tok)\n\n    return clean_tokens","59c0cd7f":"tfidf = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1,2), use_idf=False, max_features=None)","b8415848":"tfidf.fit(X['Item_Description'])","7fea9485":"X_bow = tfidf.transform(X['Item_Description'])\nXTest_bow = tfidf.transform(df_test['Item_Description'])","24c56476":"X_train, X_valid, y_train, y_valid = train_test_split(X_bow,y_endoded, test_size=0.3, random_state=1)","9c2743d5":"dtrain = xgb.DMatrix(X_train, label=y_train)\ndvalid = xgb.DMatrix(X_valid, label=y_valid)\n\nevallist = [(dtrain, 'train'), (dvalid, 'eval')]\n\nclf = xgb.train(param, dtrain, 100, evallist, verbose_eval=50)","788622ca":"y_pred_valid = clf.predict(dvalid)\n\nprint(\"Accuracy : \",accuracy_score(y_valid, np.argmax(y_pred_valid, axis=1)))","119e8a8a":"dtest = xgb.DMatrix(XTest_bow)\ny_test_pred = clf.predict(dtest)","afb1e9a2":"output['Product_Category'] = target.inverse_transform(np.argmax(y_test_pred, axis=1))","f68376cf":"print(\"Total Product Categories : {0} | predicted categories: {1} \"\n    .format(len(target.classes_), output['Product_Category'].nunique()))","46e60d9e":"output.to_csv(\".\/product_category_submission_bow_features.csv\", index=False)","c9d84f52":"num_splits = 5\nskf = StratifiedKFold(n_splits= num_splits, random_state=1, shuffle=True)","79d4a6b3":"y_test_pred = np.zeros((df_test.shape[0], len(target.classes_)))\nprint(y_test_pred.shape)\ny_valid_scores = []\nX = df['Item_Description']\nfold_cnt = 1\ndtest = xgb.DMatrix(XTest_bow)\n\nfor train_index, test_index in skf.split(X, y_endoded):\n    print(\"\\nFOLD .... \",fold_cnt)\n    fold_cnt += 1\n    \n    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_valid = y_endoded[train_index], y_endoded[test_index]\n    \n    X_train_bow = tfidf.transform(X_train)\n    X_valid_bow = tfidf.transform(X_valid)\n    \n    dtrain = xgb.DMatrix(X_train_bow, label=y_train)\n    dvalid = xgb.DMatrix(X_valid_bow, label=y_valid)\n\n    evallist = [(dtrain, 'train'), (dvalid, 'eval')]\n\n    clf = xgb.train(param, dtrain, 100, evallist, verbose_eval=50)\n    #Predict validation data\n    y_pred_valid = clf.predict(dvalid)\n    y_valid_scores.append(accuracy_score(y_valid, np.argmax(y_pred_valid, axis=1)))\n    \n    #Predict test data\n    y_pred = clf.predict(dtest)\n    \n    y_test_pred += y_pred","3b9cde44":"print(\"Validation Scores :\", y_valid_scores)\nprint(\"Average Score: \",np.round(np.mean(y_valid_scores),3))","c23a6c99":"y_test_pred \/= num_splits","3a3e324b":"output['Product_Category'] = target.inverse_transform(np.argmax(y_test_pred, axis=1))\nprint(\"Total Product Categories : {0} | predicted categories: {1} \"\n    .format(len(target.classes_), output['Product_Category'].nunique()))","8006ce17":"output.to_csv(\".\/product_category_submission_tfidf_oof.csv\", index=False)","25c8d105":"# Model_3 (OOF Prediction) : \n![OOF_Prediction](https:\/\/github.com\/asingleneuron\/edgeverve_ml_challenge\/blob\/master\/images\/OOF_PREDICTION.png?raw=True)\n","975186b6":"### Add BOW(Bag of Words) Features :","d8d8cfd6":"### Test Accuracy: 1.0\n\n![test accuracy_with_oof](https:\/\/github.com\/asingleneuron\/edgeverve_ml_challenge\/blob\/master\/images\/tfidf_oof.png?raw=True)","2713411e":"# Understand the data","d7c5cbe9":"# Loading the dataset","48be1744":"# Model_2 ( BOW Features) :\n![Model_with_selected_features](https:\/\/github.com\/asingleneuron\/edgeverve_ml_challenge\/blob\/master\/images\/mode_bow.png?raw=True)","13a8bab7":"# Model_1 with selected features:\n\n![Model_with_selected_features](https:\/\/github.com\/asingleneuron\/edgeverve_ml_challenge\/blob\/master\/images\/model_with_selected_feature.png?raw=True)","ca7edfae":"### Test Accuracy: 0.89\n\n![test accuracy_with_selected_features](https:\/\/github.com\/asingleneuron\/edgeverve_ml_challenge\/blob\/master\/images\/selected_features.png?raw=True)","90844a98":"# Create Feature Matrix (X) and target (y):","d1646e6c":"### Test Accuracy: 0.99\n\n![test accuracy_with_bow_features](https:\/\/github.com\/asingleneuron\/edgeverve_ml_challenge\/blob\/master\/images\/bow_features.png?raw=True)","59ac80f6":"# Missing Values:","57b8b5b2":"# Numerical encoding of categorical features:","78e9e84c":"# parameters of xgboost"}}