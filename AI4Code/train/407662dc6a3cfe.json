{"cell_type":{"d255bcef":"code","d0a8dfd1":"code","d148390c":"code","3cd77814":"code","04b39c46":"code","9eeaba57":"code","6e65a279":"code","36f18b44":"code","8545affb":"code","2e377ae7":"code","c68cdf49":"code","17668578":"code","62deada2":"code","5d669e19":"code","c7d7ff7c":"code","0251f9e7":"code","aff137f3":"code","8b8d4d3b":"code","afa3b416":"code","eeeb8365":"code","f2f640d4":"code","43184bc7":"code","e5ba4b46":"code","9bdca2a8":"code","e0a2caa7":"code","9a999f2d":"code","541dad3d":"code","04f5907f":"code","f7e38411":"code","96c4ee77":"code","1a3a2a90":"code","093909a7":"code","3aac6631":"code","6e14b73e":"code","a752d2a3":"code","452691a0":"code","b28943bd":"code","a901500d":"code","1dbe734e":"code","aced36a4":"code","96ce5471":"code","bbd6b7fe":"code","20949407":"code","d0e4e750":"code","46a8dadd":"code","f9652b56":"code","8919caab":"code","5ca56f3a":"code","a965d8e6":"code","57af72e2":"markdown","58712f75":"markdown","97a54df2":"markdown","75bf7e94":"markdown","6d29a624":"markdown","0f7b8ec1":"markdown","fb1848c9":"markdown","aea1524f":"markdown"},"source":{"d255bcef":"# Let's Get Started by importing libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\n\n# Visulation libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","d0a8dfd1":"# Reading the data as train and test\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","d148390c":"# Null values are empty data points\n# checking the data for Null values\nprint(train.isnull().sum())\nprint('\\n')\nprint(test.isnull().sum())\n# we do have null values in some columns","3cd77814":"# for combining both the data we need survived column in test data\ntest['Survived'] = 0\n# need a new colume to differencate between the two\ntrain['istest'] = 0\ntest['istest'] = 1","04b39c46":"# Checking if survived was added or not\n#train.describe()\ntest.describe()","9eeaba57":"# combining the data\ndataset = pd.concat([train,test], join = 'inner')","6e65a279":"dataset.describe()","36f18b44":"dataset.isna().sum()","8545affb":"# Writing a function for changing null values as per median\ndef impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n        \n        if Pclass == 1:\n            return 37\n        elif Pclass == 2:\n            return 29\n        else:\n            return 24\n        \n    else:\n        return Age","2e377ae7":"# Applying above impute on age columns\ndataset['Age'] = dataset[['Age','Pclass']].apply(impute_age,axis = 1)","c68cdf49":"# Dropping the Cabin as too many null values\ndataset.drop('Cabin', axis = 1, inplace = True)","17668578":"# Filling up the null values with logical values\ndataset['Fare'].fillna(14.454, inplace = True)\ndataset['Embarked'].fillna(\"S\", inplace = True)","62deada2":"dataset.describe()","5d669e19":"dataset.isna().sum()","c7d7ff7c":"sex_dum = pd.get_dummies(dataset['Sex'],drop_first = True)","0251f9e7":"embark_dum = pd.get_dummies(dataset['Embarked'],drop_first = True)","aff137f3":"pclass_dum = pd.get_dummies(dataset['Pclass'],drop_first = True)","8b8d4d3b":"# adding the dummies in the data frame\ndataset = pd.concat([dataset,sex_dum,embark_dum,pclass_dum],axis = 1)","afa3b416":"dataset.head()","eeeb8365":"# Checking the new train data\ndataset.drop(['PassengerId','Pclass','Sex','Embarked','Name','Ticket'],axis = 1,inplace =True)","f2f640d4":"dataset.describe()","43184bc7":"dataset.head()","e5ba4b46":"train = dataset[dataset['istest'] == 0]\ntest = dataset[dataset['istest'] == 1]","9bdca2a8":"train.drop('istest', axis = 1,inplace = True)","e0a2caa7":"test.drop('istest', axis = 1,inplace = True)","9a999f2d":"train.isna().sum()","541dad3d":"# splitting the train data for cross validations\nx = train.drop('Survived',axis = 1)\ny = train['Survived']","04f5907f":"# Splitting using sklearn\nfrom sklearn.model_selection import train_test_split","f7e38411":"# Actual splitting\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3, random_state = 101)","96c4ee77":"from sklearn.tree import DecisionTreeClassifier","1a3a2a90":"dt = DecisionTreeClassifier()","093909a7":"dt.fit(x,y)","3aac6631":"# Predicting on the splited train data\nprediction = dt.predict(x_test)","6e14b73e":"# As it is classification problem we need confusion matrix\nfrom sklearn.metrics import confusion_matrix, classification_report","a752d2a3":"print(classification_report(y_test, prediction))\n# Accuracy = 98%  ","452691a0":"test.shape","b28943bd":"Survived = dt.predict(test.drop('Survived',axis = 1)) ","a901500d":"type(Survived)","1dbe734e":"PassengerId = (list(range(892,1310)))","aced36a4":"type(PassengerId)","96ce5471":"kaggle_submission = pd.DataFrame(PassengerId, columns=['PassengerId'])","bbd6b7fe":"kaggle_submission['Survived'] = np.array(Survived)","20949407":"kaggle_submission.describe()","d0e4e750":"# saving the dataframe \nkaggle_submission.to_csv('kaggle_submission_dt', index=False)","46a8dadd":"from sklearn.ensemble import RandomForestClassifier","f9652b56":"# n_estimators are nothing but no of trees\n# do not make to complex forest of decision tree\nrfc = RandomForestClassifier(n_estimators=500)","8919caab":"# Fitting the Random Forest to trainng data\nrfc.fit(x_train,y_train)","5ca56f3a":"# Predicting on the training splitted test data by Random Forest \npred_rfc = rfc.predict(x_test)","a965d8e6":"print(classification_report(y_test, pred_rfc))\n# Accuracy = 82%","57af72e2":"# **Conclusion**\nRandom Forest Performed better on our training data","58712f75":"# **Decision Tree Model**","97a54df2":"**Predicting and Accuracy of Decision Tree **","75bf7e94":"Let's work on our [Titanic](https:\/\/www.kaggle.com\/c\/titanic) Data set\n","6d29a624":"**Prediciton and Accuracy of Random Tree**","0f7b8ec1":"# **Random Forest Model**","fb1848c9":"# **Splitting the Train Data**\n**NOTE** : We had done work only on the train data here. The test data is not used in this tutorial.\nIt will be updated soon, Kindly wait till then.","aea1524f":"The competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\nI have Previously Done EDA & Applied Logistic Regression Model on same data.\nPlease Refer : [Kaggle](https:\/\/www.kaggle.com\/adarshsambare) here,\nIf you like my work **Do UPVOTE**"}}