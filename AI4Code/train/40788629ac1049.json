{"cell_type":{"a9070b39":"code","c531dc41":"code","7dda5485":"code","e0be8a6d":"code","213704ea":"code","ec2cd93a":"code","9cb06d17":"code","ce1da393":"code","6b25cacb":"code","ca015b23":"code","320a362c":"code","38602ca7":"code","85876942":"code","7a264422":"code","60b6717f":"code","ba50c932":"code","ad1f5f6a":"code","c3c7e56f":"code","6799d52a":"code","c481d221":"code","ce7efb74":"code","cdabfb35":"code","889cded6":"code","5e1a4d03":"code","5833042d":"code","93195fbb":"code","3b0adbec":"code","f0231754":"markdown"},"source":{"a9070b39":"import pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport matplotlib.pyplot as plt","c531dc41":"data1 = pd.read_csv('..\/input\/phone-sensor-data-while-driving-a-car\/1_20210317_171452.csv')\ndata1.head()","7dda5485":"data2 = pd.read_csv('..\/input\/phone-sensor-data-while-driving-a-car\/2_20210317_184512.csv')\ndata2.tail()","e0be8a6d":"data = pd.read_csv('..\/input\/phone-sensor-data-while-driving-a-car\/FinalDatasetCsv.csv')\ndata.head()","213704ea":"df_final = pd.concat([data1, data2])\ndf_final.head()","ec2cd93a":"df_final['label'] = data['label']","9cb06d17":"df_final.set_index('Time', inplace=True)","ce1da393":"df_final.head()","6b25cacb":"s1 = '17:14:53'\ns2 = '18:56:18' # for example\nFMT = '%H:%M:%S'\ntdelta = datetime.strptime(s2, FMT) - datetime.strptime(s1, FMT)\ntdelta","ca015b23":"df_final = df_final.drop(['Longitude', 'Latitude', 'Distance', 'Heading'], axis=1)","320a362c":"timestamps = df_final.index.unique()","38602ca7":"X = np.array(df_final.drop(['label'], axis=1))\ny = np.array(df_final['label'])","85876942":"X","7a264422":"def plot_series(data, df_final_col_names):\n    colors = ['r', 'g', 'b', 'c', 'magenta', 'orange', 'black']\n    \n    \n    fig, axes = plt.subplots(data.shape[1] \/\/ 2, 2, figsize=(20, 10))\n    \n    try:\n        for i in range(data.shape[1] \/\/ 2):\n            for j in range (2):\n                n = i * 2 + j\n    \n                axes[i][j].plot(np.arange(len(data[:, n])),data[:,n], color=colors[n])\n                axes[i][j].set_title(df_final_col_names[n])\n    except IndexError:\n        print('Error!')\n        \nplot_series(X, df_final.columns)        ","60b6717f":"import tensorflow as tf","ba50c932":"_window_size = 100\n_batch_size = 64\n_shuffle_buffer = 60800","ad1f5f6a":"ds = tf.concat([X, tf.expand_dims(tf.cast(y, 'float32'), -1)], axis=1)\nds","c3c7e56f":"def windowed_dataset(ds, batch_size, shuffle_buffer, window_size, train_split_size=0.8):\n    \n    train_split_index = int(ds.shape[0] * 0.8)\n    \n    ds = tf.data.Dataset.from_tensor_slices(ds)\n    ds = ds.window(window_size, shift=1, drop_remainder=True)\n    ds = ds.flat_map(lambda w: w.batch(window_size))\n    ds = ds.map(lambda w: (w[:, :-1], tf.cond(tf.reduce_sum(w[:, -1]) <  5, lambda : tf.constant([0]), \n                                              lambda : tf.constant([1]))))\n\n\n    ds = ds.shuffle(shuffle_buffer)\n    \n    \n    train_ds, eval_ds = ds.take(train_split_index), ds.skip(train_split_index)\n    \n    \n    train_ds, eval_ds = train_ds.batch(batch_size), eval_ds.batch(batch_size)\n    \n    return train_ds.prefetch(1), eval_ds.prefetch(1)\n    \n    \ntrain_ds, eval_ds = windowed_dataset(ds, _batch_size, _shuffle_buffer, _window_size)\ntrain_ds, eval_ds","6799d52a":"from tensorflow.keras import layers","c481d221":"def build_model():\n    \n    inputs = layers.Input(shape=(_window_size, 7))\n    x = layers.Bidirectional(layers.LSTM(32, return_sequences=True))(inputs)\n    x = layers.Bidirectional(layers.LSTM(32, return_sequences=True))(x)\n    x = layers.LSTM(32)(x)\n    x = layers.Dropout(0.4)(x)\n    x = layers.Dense(128, activation='relu')(x)\n    x = layers.Dropout(0.3)(x)\n    x = layers.Dense(128, activation='relu')(x)\n    outputs = layers.Dense(1, activation='sigmoid')(x)\n    \n    model = tf.keras.Model(inputs=[inputs], outputs=[outputs], name='HAR')\n    \n    return model\n\nmodel = build_model()","ce7efb74":"METRICS = [\n      tf.keras.metrics.TruePositives(name='tp'),\n      tf.keras.metrics.FalsePositives(name='fp'),\n      tf.keras.metrics.TrueNegatives(name='tn'),\n      tf.keras.metrics.FalseNegatives(name='fn'), \n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),\n      tf.keras.metrics.AUC(name='auc'),\n      tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n]","cdabfb35":"model.compile(optimizer=tf.keras.optimizers.Adam(),\n             loss=tf.keras.losses.BinaryCrossentropy(),\n             metrics=METRICS)","889cded6":"early_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='loss', \n    verbose=1,\n    patience=4,\n    mode='min',\n    restore_best_weights=True)","5e1a4d03":"history = model.fit(train_ds, epochs=100, callbacks=[early_stopping])","5833042d":"model.save('HAR')","93195fbb":"model.evaluate(eval_ds)","3b0adbec":"model.summary()","f0231754":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session"}}