{"cell_type":{"d0b05efc":"code","84122f9e":"code","83b11e95":"code","303a1767":"code","7b4f6b5b":"code","b0e42fb9":"code","41cef83b":"markdown"},"source":{"d0b05efc":"# IMDB\n\nfrom tensorflow.keras.datasets import imdb\nimport numpy as np\n\ndef vectorize_sequences(sequences, dimension = 10000):\n    results = np.zeros( (len(sequences), dimension) )\n    for i, sequence in enumerate(sequences):\n        results[i, sequence] = 1.\n    return results\n\n# load\n((train_data, train_labels), (test_data, test_labels)) = imdb.load_data(num_words = 10000)\n\n# preprocess\nx_train = vectorize_sequences(train_data)\nx_test = vectorize_sequences(test_data)\n\ny_train = np.asarray(train_labels).astype('float32')\ny_test = np.asarray(test_labels).astype('float32')\n\n# build\nfrom tensorflow.keras import models\nfrom tensorflow.keras import layers\nmodel = models.Sequential()\nmodel.add(layers.Dense(16, activation = 'relu', input_shape = (10000,)))\nmodel.add(layers.Dense(16, activation = 'relu'))\nmodel.add(layers.Dense(1, activation = 'sigmoid'))\n\nmodel.compile(optimizer='rmsprop',\n             loss='binary_crossentropy',\n             metrics=['accuracy'])\n\n# train\nx_val = x_train[:10000]\npartial_x_train = x_train[10000:]\ny_val = y_train[:10000]\npartial_y_train = y_train[10000:]\n\nhistory = model.fit(partial_x_train, \n                    partial_y_train,\n                    epochs = 20,\n                    batch_size = 512,\n                    validation_data = (x_val, y_val)) ","84122f9e":"history_dict = history.history\nhistory_dict.keys()","83b11e95":"history_dict['loss']","303a1767":"import matplotlib.pyplot as plt\n    \nloss = history_dict['loss']\nval_loss = history_dict['val_loss']\n\nepochs = range(1, len(loss) + 1)\n\nblue_dots = 'bo'\nsolid_blue_line = 'b'\n\nplt.plot(epochs, loss, blue_dots, label = 'Training loss')\nplt.plot(epochs, val_loss, solid_blue_line, label = 'Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","7b4f6b5b":"history_dict['accuracy']","b0e42fb9":"plt.clf()\n\nacc = history_dict['accuracy']\nval_acc = history_dict['val_accuracy']\n    \nepochs = range(1, len(acc) + 1)\n\nblue_dots = 'bo'\nsolid_blue_line = 'b'\n    \nplt.plot(epochs, acc, blue_dots, label = 'Training acc')\nplt.plot(epochs, val_acc, solid_blue_line, label = 'Validation acc')\nplt.title('Training and validation acc')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()","41cef83b":"1. Run IMDB\n- Experiment with one and three hidden layers\n- Experiment with more or fewer hidden units - 32 units, 64 units etc.\n- Investigate replacing the `binary_crossentropy` loss function with `mse`\n- Experiment with replacing `relu` with `tanh` activations\n- Investigate the effect of different learning rates\n- Take your best network and train on all the training data for the optimal epochs. Evaluate on the test set"}}