{"cell_type":{"8312a310":"code","d1cb58ce":"code","dfa73341":"code","b5a2a568":"code","c6bef5ae":"code","ebfd6620":"code","6ed032f2":"code","b4cf430b":"code","d8aa8d2c":"code","21c63319":"code","224e2141":"code","a3266f77":"code","b4ee0c2d":"code","c5a8da51":"code","65e34c5e":"code","fc724158":"code","6aeee89c":"code","1c07566a":"code","aefdce1e":"code","c6c9e108":"code","14caef1a":"code","d43e321b":"code","eff62601":"code","9aa4e2c2":"code","08b8adc5":"code","97e5a272":"code","db7b3d9a":"code","e015a317":"code","7f8e2ea9":"code","849b4b05":"code","4e1d70cf":"code","0c24d489":"code","0be63877":"code","93a0585d":"code","9f59baa8":"code","10e2b19e":"code","f6313e11":"code","d1b7575e":"code","e04aabf4":"code","d61f8964":"code","e56a9979":"code","4f966dd2":"code","03a40109":"code","65f740e1":"code","6402de1b":"markdown","01a74771":"markdown","134a666e":"markdown","3f0f22e0":"markdown","12458a5f":"markdown","75346445":"markdown","a561a5f1":"markdown","414b4f11":"markdown","188f8326":"markdown","89342a98":"markdown","399523ea":"markdown","4cd602f3":"markdown","ffda93a6":"markdown","c364ceaa":"markdown","3b50fb5e":"markdown","78b5982e":"markdown","e5efc64a":"markdown","01222963":"markdown","979fafa4":"markdown","5dc08f18":"markdown","8eb0b96e":"markdown","aa0305f6":"markdown","33fd353b":"markdown","2e0f7da9":"markdown","7f1ff461":"markdown","f4140f92":"markdown","48a3395b":"markdown","2b31053a":"markdown","b63f20cf":"markdown","2566d51b":"markdown","be9b9383":"markdown"},"source":{"8312a310":"import pandas as pd # For working with DataFrames \nimport numpy as np # For ease of array manipulation + basic stats\nimport matplotlib.pyplot as plt # For plotting pretty plots :) \nimport scipy.signal as signal # For calculating PSDs and plotting spectrograms\n!pip install neurodsp\nfrom neurodsp.spectral import compute_spectrum # for smoothed PSD computation\nfrom pathlib import Path # For making paths compatible on Windows and Macs\n","d1cb58ce":"eeg_fs = 250 # Data was recorded at 250 Hz","dfa73341":"## Create DF for each of these, columns are channels, each row is a trial run\ndef getDF(epochs, labels, times, chans):\n    data_dict = {}\n    for i, label in enumerate(labels): \n        start_time = times[i][0]\n        if 'start_time' not in data_dict: \n            data_dict['start_time'] = list()\n        data_dict['start_time'].append(start_time)\n        \n        if 'event_type' not in data_dict:\n            data_dict['event_type'] = list()\n        data_dict['event_type'].append(label)\n        \n        for ch in range(len(chans)): \n            if chans[ch] not in data_dict:\n                data_dict[chans[ch]] = list() \n            data_dict[chans[ch]].append(epochs[i][ch])\n        \n    return pd.DataFrame(data_dict)","b5a2a568":"# Extract data from raw dataframes for constructing trial-by-trial dataframe\ndef getEpochedDF(eeg_df, event_df, trial_duration_ms=4000):\n    epochs = []\n    epoch_times = []\n    labels = []\n    start_df = eeg_df[eeg_df['EventStart'] == 1]\n    for i, event_type in enumerate(event_df[\"EventType\"].values): \n        labels.append(event_type)\n        start_time = start_df.iloc[i][\"time\"]\n        end_time = int(start_time + trial_duration_ms)\n        epoch_times.append((start_time, end_time))\n        sub_df = eeg_df[(eeg_df['time'] > start_time) & (eeg_df['time'] <= end_time)]\n        eeg_dat = []\n        for ch in all_chans: \n            eeg_dat.append(sub_df[ch].values)\n        epochs.append(np.array(eeg_dat))\n\n    # Create dataframe from the data extracted previously\n    eeg_epoch_df = getDF(epochs, labels, epoch_times, all_chans)\n    return eeg_epoch_df","c6bef5ae":"# PSD plotting\ndef plotPSD(freq, psd, fs=eeg_fs, pre_cut_off_freq=0, post_cut_off_freq=120, label=None):\n    '''\n    Inputs \n    - freq: the list of frequencies corresponding to the PSDs\n    - psd: the list of psds that represent the power of each frequency\n    - pre_cut_off_freq: the lowerbound of the frequencies to show\n    - post_cut_off_freq: the upperbound of the frequencies to show\n    - label: a text label to assign this plot (in case multiple plots want to be drawn)\n    \n    Outputs: \n    - None, except a plot will appear. plot.show() is not called at the end, so you can call this again to plot on the same axes. \n    '''\n    # Label the axes\n    plt.xlabel('Frequency (Hz)')\n    plt.ylabel('log(PSD)')\n    \n    # Calculate the frequency point that corresponds with the desired cut off frequencies\n    pre_cut = int(len(freq)*(pre_cut_off_freq \/ freq[-1]))\n    post_cut = int(len(freq)*(post_cut_off_freq \/ freq[-1]))\n    \n    # Plot\n    plt.plot(freq[pre_cut:post_cut], np.log(psd[pre_cut:post_cut]), label=label)\n\n# Get Frequencies and PSDs from EEG data - this is the raw PSD method. \ndef getFreqPSDFromEEG(eeg_data, fs=eeg_fs):\n    # Use scipy's signal.periodogram to do the conversion to PSDs\n    freq, psd = signal.periodogram(eeg_data, fs=int(fs), scaling='spectrum')\n    return freq, psd\n\n# Get Frequencies and mean PSDs from EEG data - this yeilds smoother PSDs because it averages the PSDs made from sliding windows. \ndef getMeanFreqPSD(eeg_data, fs=eeg_fs):\n    freq_mean, psd_mean = compute_spectrum(eeg_data, fs, method='welch', avg_type='mean', nperseg=fs*2)\n    return freq_mean, psd_mean\n\n# Plot PSD from EEG data (combines the a PSD calculator function and the plotting function)\ndef plotPSD_fromEEG(eeg_data, fs=eeg_fs, pre_cut_off_freq=0, post_cut_off_freq=120, label=None):\n    freq, psd = getMeanFreqPSD(eeg_data, fs=fs)\n    plotPSD(freq, psd, fs, pre_cut_off_freq, post_cut_off_freq, label)","ebfd6620":"# Spectrogram plotting\ndef plotSpectrogram_fromEEG(eeg_data, fs=eeg_fs, pre_cut_off_freq=0, post_cut_off_freq=120):\n    f, t, Sxx = signal.spectrogram(eeg_data, fs=fs)\n    # Calculate the frequency point that corresponds with the desired cut off frequencies\n    pre_cut = int(len(f)*(pre_cut_off_freq \/ f[-1]))\n    post_cut = int(len(f)*(post_cut_off_freq \/ f[-1]))\n    plt.pcolormesh(t, f[pre_cut:post_cut], Sxx[pre_cut:post_cut], shading='gouraud')\n    plt.ylabel(\"Frequency (Hz)\")\n    plt.xlabel(\"Time (sec)\")","6ed032f2":"# Load a subject's data \nfilename = \"B0101T\"\neeg_filename = Path(\"..\/input\/ucsd-neural-data-challenge\/data\/train\/\" + filename + \".csv\")\nevent_filename = Path(\"..\/input\/ucsd-neural-data-challenge\/data\/y_train_only\/\" + filename + \".csv\")\n\neeg_chans = [\"C3\", \"Cz\", \"C4\"] # 10-20 system \neog_chans = [\"EOG:ch01\", \"EOG:ch02\", \"EOG:ch03\"] \nall_chans = eeg_chans + eog_chans\nevent_types = {0:\"left\", 1:\"right\"}\n\n# Load the raw csvs into dataframes\neeg_df = pd.read_csv(eeg_filename)\nevent_df = pd.read_csv(event_filename)\n\nprint(\"recording length:\", eeg_df[\"time\"].values[-1] \/ 1000 \/ 60, \"min\")","b4cf430b":"len(event_df) # Number of trials in this subject's data","d8aa8d2c":"eeg_df.head(2) ","21c63319":"event_df.head(2)","224e2141":"# Try adjust these variables to see different time ranges! \n# A single trial is 4 seconds or 1000 timpoints (4 ms per timepoint)\n# Hint: refer to the Epoched data dataframe for the time of each trial\nstart_time_ms = 223556 # Start time in millis\nstart_time_timepoints = start_time_ms \/\/ 4 # Divide by 4 to get into timepoints\nend_time_timepoints = start_time_timepoints + 1000 # Specify number of more timepoints we want past start\n\n# Plot a single EEG channel\nplt.figure(figsize=(15,5))\nplt.plot(eeg_df['C3'].values[start_time_timepoints:end_time_timepoints])\nplt.title(\"C3 -- \" + str(start_time_timepoints) + \" to \" + str(end_time_timepoints))\nplt.xlabel(\"timepoints\")\nplt.ylabel(\"Voltage (uV)\")\nplt.show()\n\n# Plot a single EOG channel\nplt.figure(figsize=(15,5))\nplt.plot(eeg_df['EOG:ch01'].values[start_time_timepoints:end_time_timepoints])\nplt.title(\"EOG:ch01 -- \" + str(start_time_timepoints) + \" to \" + str(end_time_timepoints))\nplt.xlabel(\"timepoints\")\nplt.ylabel(\"Voltage (uV)\")\nplt.show()\n\n# Plot the PSD of the single EEG channel\nplt.figure(figsize=(15,5))\nplotPSD_fromEEG(eeg_df['C3'].values[start_time_timepoints:end_time_timepoints], pre_cut_off_freq=2, post_cut_off_freq=30,label=\"C3\")\nplt.title(\"PSD of C3 in the timespan provided\")\nplt.legend()\nplt.show()\n\n# Plot the spectrogram of the single EEG channel\nplt.figure(figsize=(15,5))\nplotSpectrogram_fromEEG(eeg_df['C3'].values[start_time_timepoints:end_time_timepoints], pre_cut_off_freq=2, post_cut_off_freq=30)\nplt.title(\"Spectrogram of C3 in the timespan provided\")\nplt.show()","a3266f77":"# Try epoching at different lengths! (4000ms is default by experiment setup)\neeg_epoch_df = getEpochedDF(eeg_df, event_df, trial_duration_ms=4000) \n\n# Preview dataframe of trials\n# start_time denotes the ms since the start of the recording when this trial or epoch started.\neeg_epoch_df.head(2)","b4ee0c2d":"# We've already epoched all the data into 4000ms trials for you in epoched_train.pkl and epoched_test.pkl :) \n# These are the epochs that will be used in accuracy evaluation\nepoch_df_filename = Path(\"..\/input\/ucsd-neural-data-challenge\/data\/epoched_train.pkl\")\neeg_epoch_full_df = pd.read_pickle(epoch_df_filename)\neeg_epoch_full_df.head(2)","c5a8da51":"# Visualize EEG and PSD for one trial\n# Try changing trial_num to view different trials!\ntrial_num = 0\n\nplt.figure(figsize=(15,5))\nfor ch in eeg_chans: \n    plt.plot(eeg_epoch_full_df[ch][trial_num], label=ch)\nplt.ylabel(\"Voltage (uV)\")\nplt.xlabel(\"timepoints @ 250Hz\")\nplt.title(\"EEG of one motor imagery trial\")\nplt.legend() \nplt.show()\n\nplt.figure(figsize=(15,5))\nfor ch in eog_chans: \n    plt.plot(eeg_epoch_full_df[ch][trial_num], label=ch)\nplt.ylabel(\"Voltage (uV)\")\nplt.xlabel(\"timepoints @ 250Hz\")\nplt.title(\"EOG of one motor imagery trial\")\nplt.legend() \nplt.show()\n\nplt.figure(figsize=(15,5))\nfor ch in eeg_chans: \n    plotPSD_fromEEG(eeg_epoch_full_df[ch][trial_num], pre_cut_off_freq=2, post_cut_off_freq=30, label=ch)\nplt.title(\"PSD of EEG in one motor imagery trial\")\nplt.legend()\nplt.show()\n","65e34c5e":"# Get PSD averages for each channel for each event type (0=left or 1=right)\npsd_averages_by_type = {}\n\nfor event_type in event_types.keys(): \n    psds_only_one_type={}\n    freqs_only_one_type={}\n    for i, row in eeg_epoch_full_df[eeg_epoch_full_df[\"event_type\"] == event_type].iterrows(): \n        for ch in eeg_chans: \n            if ch not in psds_only_one_type: \n                psds_only_one_type[ch] = list()\n                freqs_only_one_type[ch] = list()\n            f, p = getMeanFreqPSD(row[ch])\n            psds_only_one_type[ch].append(p)\n            freqs_only_one_type[ch].append(f)\n    avg_psds_one_type = {}\n    for ch in eeg_chans:\n        psds_only_one_type[ch] = np.array(psds_only_one_type[ch])\n        avg_psds_one_type[ch] = np.mean(psds_only_one_type[ch], axis=0)\n    psd_averages_by_type[event_type] = dict(avg_psds_one_type)","fc724158":"# View Average PSDs\nfor event_type in event_types.keys(): \n    for ch in eeg_chans[:]: \n        plotPSD(freqs_only_one_type[eeg_chans[0]][0], psd_averages_by_type[event_type][ch],pre_cut_off_freq=2, post_cut_off_freq=30, label=ch)\n\n    plt.legend()\n    plt.title(\"event type: \" + event_types[event_type])\n    plt.show()","6aeee89c":"print('C3: ' + str(eeg_df['C3'].mean()) + \" uV\")\nprint('Cz: ' + str(eeg_df['Cz'].mean()) + \" uV\")\nprint('C4: ' + str(eeg_df['C4'].mean()) + \" uV\")","1c07566a":"print('C3: ' + str(eeg_df['C3'].std()) + \" uV\")\nprint('Cz: ' + str(eeg_df['Cz'].std()) + \" uV\")\nprint('C4: ' + str(eeg_df['C4'].std()) + \" uV\")","aefdce1e":"print('C3: ' + str(max(eeg_df['C3']) - min(eeg_df['C3'])) + \" uV\")\nprint('Cz: ' + str(max(eeg_df['Cz']) - min(eeg_df['Cz'])) + \" uV\")\nprint('C4: ' + str(max(eeg_df['C4']) - min(eeg_df['C4'])) + \" uV\")","c6c9e108":"# Import sklearn models and tools\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.gaussian_process.kernels import RBF, DotProduct","14caef1a":"eeg_epoch_full_df.head()","d43e321b":"# define X and y portions of the dataframe\npre_X = eeg_epoch_full_df[['C3','Cz','C4','EOG:ch01','EOG:ch02','EOG:ch03']]\ny = eeg_epoch_full_df['event_type']\n\n# Set y as type int to enable comparison to generated predictions\ny = y.astype('int')","eff62601":"baseline_model = pd.DataFrame()\n\nfor col in pre_X.columns:\n    col_names = [col + '_' + str(x) for x in np.arange(0,1000,1)]\n\n    baseline_model[col_names] = pre_X.apply(lambda x: x[col], axis=1, result_type=\"expand\")\n        \nbaseline_model","9aa4e2c2":"y.value_counts()","08b8adc5":"# Create a pipeline with a standard scaler and logistic regression with parameters tuned in a gridsearchCV\nparam_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000] }\nsteps = [('scaler', StandardScaler()), ('lr', GridSearchCV(LogisticRegression(), param_grid=param_grid, refit=True))]\npipeline = Pipeline(steps)","97e5a272":"# Split into training and testing data with a designated random state for reproducibility and comparison\nX_train, X_test, y_train, y_test = train_test_split(baseline_model, y, test_size=0.2, random_state=420)","db7b3d9a":"# Fit the training data to the pipeline and use it to generate predictions that we score using the f1 scorer\npipeline.fit(X_train, y_train)\npred = pipeline.predict(X_test)\n\nprint('F1 score of baseline model using Linear Regression algorithm: ' + str(f1_score(pred, y_test)))","e015a317":"# Create a pipeline with a standard scaler and logistic regression with parameters tuned in a gridsearchCV\nparam_grid = {\n    'n_neighbors': [3, 5, 7, 11, 19],\n    'weights': ['uniform', 'distance'],\n    'metric': ['euclidean', 'manhattan']\n}\n\nsteps = [('scaler', StandardScaler()), ('knn', GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, verbose=1, n_jobs=-1, refit=True))]\npipeline = Pipeline(steps)","7f8e2ea9":"# Fit the training data to the pipeline and use it to generate predictions that we score using the f1 scorer\n# pipeline.fit(X_train, y_train)\n# pred = pipeline.predict(X_test)\n\n# print('F1 score of baseline model using K Nearest Neighbors algorithm: ' + str(f1_score(pred, y_test)))","849b4b05":"# Create a pipeline with a standard scaler and logistic regression with parameters tuned in a gridsearchCV\nparam_grid = {'C': [0.1, 1, 10, 100, 1000],  \n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n              'kernel': ['rbf']}  \n  \nsteps = [('scaler', StandardScaler()), ('knn', GridSearchCV(SVC(), param_grid=param_grid, verbose=1, n_jobs=-1, refit=True))]\npipeline = Pipeline(steps)","4e1d70cf":"# Fit the training data to the pipeline and use it to generate predictions that we score using the f1 scorer\n# pipeline.fit(X_train, y_train)\n# pred = pipeline.predict(X_test)\n\n# print('F1 score of baseline model using Linear SVM algorithm: ' + str(f1_score(pred, y_test)))","0c24d489":"param_grid = {}\nparam_grid['kernel'] = [1*RBF(), 1*DotProduct()]\n\nsteps = [('scaler', StandardScaler()), ('gp', GridSearchCV(GaussianProcessClassifier(), param_grid=param_grid, verbose=1, n_jobs=-1, refit=True))]\npipeline = Pipeline(steps)","0be63877":"# Fit the training data to the pipeline and use it to generate predictions that we score using the f1 scorer\n# pipeline.fit(X_train, y_train)\n# pred = pipeline.predict(X_test)\n\n# print('F1 score of baseline model using Gaussian Process algorithm: ' + str(f1_score(pred, y_test)))","93a0585d":"param_grid = {\n    'solver': ['lbfgs'],\n    'max_iter': [500,1000,1500],\n    'alpha': 10.0 ** -np.arange(1, 7),\n    'hidden_layer_sizes':np.arange(5, 12),\n    'random_state':[0,1,2,3,4,5,6,7,8,9]}\n\nsteps = [('scaler', StandardScaler()), ('nn', GridSearchCV(MLPClassifier(), param_grid=param_grid, verbose=1, n_jobs=-1, refit=True))]\npipeline = Pipeline(steps)","9f59baa8":"# Fit the training data to the pipeline and use it to generate predictions that we score using the f1 scorer\n# pipeline.fit(X_train, y_train)\n# pred = pipeline.predict(X_test)\n\n# print('F1 score of baseline model using Neural Net Classifier algorithm: ' + str(f1_score(pred, y_test)))","10e2b19e":"ideas = pd.DataFrame()\nideas['C3_Cz_diff'] = pre_X['C3'] - pre_X['Cz']\nideas['max_C3Cz_diff'] = ideas['C3_Cz_diff'].apply(np.max)\nideas['C3_C4_diff'] = pre_X['C3'] - pre_X['C4']\nideas['max_C3C4_diff'] = ideas['C3_C4_diff'].apply(np.max)\nideas['C4_Cz_diff'] = pre_X['C4'] - pre_X['Cz']\nideas['max_C4Cz_diff'] = ideas['C4_Cz_diff'].apply(np.max)\nideas['C3_range'] = pre_X['C3'].apply(np.max) - pre_X['C3'].apply(np.min)\nideas['Cz_range'] = pre_X['Cz'].apply(np.max) - pre_X['Cz'].apply(np.min)\nideas['C4_range'] = pre_X['C4'].apply(np.max) - pre_X['C4'].apply(np.min)\nideas = ideas.drop(['C3_Cz_diff', 'C3_C4_diff', 'C4_Cz_diff'], axis=1)\nideas.head()","f6313e11":"advanced_model = baseline_model.copy()\n\nfor col in ['C3_range', 'Cz_range', 'C4_range', 'max_C3Cz_diff', 'max_C3C4_diff', 'max_C4Cz_diff']:\n    advanced_model[col] = ideas[col]\n\n#for col in ideas.drop(['C3_range', 'Cz_range', 'C4_range'], axis=1).columns:\n    #col_names = [col + '_' + str(x) for x in np.arange(0,1000,1)]\n    #advanced_model[col_names] = ideas.apply(lambda x: x[col], axis=1, result_type=\"expand\")\nadvanced_model.head()","d1b7575e":"# Create a pipeline with a standard scaler and logistic regression with parameters tuned in a gridsearchCV\nparam_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000] }\nsteps = [('scaler', StandardScaler()), ('lr', GridSearchCV(LogisticRegression(), param_grid=param_grid, refit=True))]\npipeline = Pipeline(steps)","e04aabf4":"# Split into training and testing data with a designated random state for reproducibility and comparison\nX_train, X_test, y_train, y_test = train_test_split(advanced_model, y, test_size=0.2, random_state=420)","d61f8964":"# Fit the training data to the pipeline and use it to generate predictions that we score using the f1 scorer\npipeline.fit(X_train, y_train)\npred = pipeline.predict(X_test)\n\n# 0.73082287\nprint('F1 score of advanced model using Linear Regression algorithm: ' + str(f1_score(pred, y_test)))","e56a9979":"for n in np.arange(0, 1000):\n\n    event_type = y[n]\n    cee3 = sum(i*i for i in pre_X['C3'][n])\n    ceez = sum(i*i for i in pre_X['Cz'][n])\n    cee4 = sum(i*i for i in pre_X['C4'][n])\n\n    print('event type: ' + str(event_type))\n    print('C3: ' + str(cee3), 'Cz: ' + str(ceez))\n    print('C3 - Cz = ' + str(cee3 - ceez))\n    print('C4 - Cz = ' + str(cee4 - ceez))\n    print('C3 - C4 = ' + str(cee3 - cee4))","4f966dd2":"print(y[1])\nprint(sum(i*i for i in pre_X['C3'][1]))\nprint(sum(i*i for i in pre_X['Cz'][1]))\nprint(sum(i*i for i in pre_X['C3'][1]) - sum(i*i for i in pre_X['Cz'][1]))","03a40109":"print(y[2])\nprint(sum(i*i for i in pre_X['C3'][2]))\nprint(sum(i*i for i in pre_X['Cz'][2]))\nprint(sum(i*i for i in pre_X['C3'][2]) - sum(i*i for i in pre_X['Cz'][2]))","65f740e1":"print(y[3])\nprint(sum(i*i for i in pre_X['C3'][3]))\nprint(sum(i*i for i in pre_X['Cz'][3]))\nprint(sum(i*i for i in pre_X['C3'][3]) - sum(i*i for i in pre_X['Cz'][3]))","6402de1b":"### Standard deviation for 3 channels:\nStandard deviation is not huge but still significantly larger than mean.","01a74771":"## Load raw data","134a666e":"Using the Gaussian Process Classification training algorithm, we get an f1 score of 0.7298. Let's continue testing other classification training algorithms.","3f0f22e0":"## Baseline Model under Logistic Regression\n\nNow that we created a baseline model for mean and median respectively, we can test the model's predictions starting with a logistic regression training algorithm to see how accurate these baseline predictors are.","12458a5f":"## Average PSD data in all training data\nLet's average the PSDs in all the training data. We can see that there are more apparent differences between the different electrode's PSDs between the two classes. In particular, we can see how the relative PSDs of C3 and C4 channels vary between the two classes. In neuroscience literature, it is well documented that the alpha range power decreases on the opposite (i.e. contralateral) hemisphere when a hand or motor imagery on one side is performed. More on Mu Waves: https:\/\/en.wikipedia.org\/wiki\/Mu_wave. However, you may notice that the exact phenomena doesn't show up in all subjects. This is due to the noisy nature of EEG, brain folds, and subject performance. ","75346445":"## Imports","a561a5f1":"Using the Neural Net Classification training algorithm, we get an f1 score of 0.6908. Out of these classification algorithms, the baseline model performed the best under the Logistic Regression algorithm. Our next step will be to improve the model by adding some features that could result in more accurate predictions.","414b4f11":"## Helper Functions","188f8326":"## Visualizing EEG, EOG, and PSD data of Epoched data\nNote that EEG data has smaller amplitude than EOG data. This is because the electrical activity caused by eye movements is much greater than those of more purely the brain signals. You can still sometimes see eye artifacts in EEG data, but the affect is smaller due to the electrode's distance from the eyes. \n\nNote that the PSD for a single 4 second trial is incredibly noisy. Most EEG research requires that we average PSDs across trials to be able to see the \"delta\" \"theta\" \"alpha\" \"beta\" \"gamma\" bands we normally hear about. The y-axis of the PSD graph is logged because there is usually a lot more low frequency noise, so scaling the graph this way helps with the visual. ","89342a98":"## Advanced Model Tuning\n\nSome new features can be extracted from the features that we currently have, and they can potentially improve our model. Let's test a few ideas out, starting with differences between `C3`, `Cz`, and `C4` and their ranges.","399523ea":"## Linear SVM","4cd602f3":"More brainstorming (didn't have time to incorporate)","ffda93a6":"Unfortunately, our advanced model actually performed worse with the inclusion of these additional features. Therefore, we will submit our baseline model for scoring.","c364ceaa":"In our dataset, we can assume that some of the features provided are likely not influential on the resulting event type that we are trying to predict. Thus, for our baseline model, we want to only select the channel data in the columns `C3`, `Cz`, `C4`, `EOG:ch01`, `EOG:ch02`, and `EOG:ch03`. This is because it's unlikely for the patient's id or the start time of the event to affect the type of the event. In fact, they could potentially act as confounding variables as well.\n\nIn addition, we can see that the channel columns hold values in the form of arrays, so we can start our baseline model by exploding these arrays into individual features.","3b50fb5e":"## Raw Data Explanation: \nThe time column is in ms, since we're sampling at 250Hz, each recording comes in at 4ms intervals. C3, Cz, and C4 are electrode recordings in microVolts (uV) from the 10-20 EEG system. EOG:ch01 ... EOG:ch03 are the EOG channels as specifed in the dataset. EventStart shows whether a timepoint corresponds to the start of a trial. To know which event was started (left or right), we look int the EventType DataFrame for the corresponding nth start trial type. For example, the first EventStart == 1 will the value in the first row of EventType according to the first row in the event_type DataFrame. ","78b5982e":"Using the Linear SVM Classification training algorithm, we get an f1 score of 0.7212. Let's continue testing other classification training algorithms.","e5efc64a":"Here, our overall baseline model performs with an f1 score of .7329 under a Logistic Regression training algorithm. Before adding or changing features in the dataframe, let's see how the model performs against a couple other classifier training algorithms (commented out due to the incredibly long runtimes, but we listed their outputs in a markdown cell.","01222963":"## View continuous EEG + EOG data by timepoint\nWith all the data loaded in, we can explore the entire recording We can see how EOG channels fluctuate much more than EEG channels during noise. Some of this won't look like brain data, in which case it is most likely a blink or some other muscle artifact. \n\n- <b>Try plotting the other EEG and EOG channels!<\/b><br>\n- <b>Try plotting different timepoint windows!<\/b>","979fafa4":"## Constants","5dc08f18":"Name(s): Eric Wang, Wilson Xie\n\nEmail(s): e3wang@ucsd.edu, x2xie@ucsd.edu\n\nUCSD PID: A15545920, A15451232","8eb0b96e":"Essentially, we want to create a predictive classifier model that can accurately identify the event type at each event start (0 represents a left hand signal and 1 represents a right hand signal).","aa0305f6":"# Starter Notebook: BCI Competition IV 2b\nIn 2008, a BCI Competition was held on EEG datasets to find the best ML and statistical algorithms to differentiate different classes of neural data. The BCI Competition IV 2b is a motor imagery dataset with eye artifact data, making it a very realistic dataset. The subjects are prompted to imagine left vs right hand movement and the EEG + EOG signals for each trial are collected. We here have provided a simpler version of the dataset in CSV format for you to get started with. \n\nThis notebook will help you get oriented with processing a single subject's single run, looking at the time and frequency domain in Power Spectral Densities (PSDs). Due to the nature of EEG and it's time-varying properties (i.e. gel dries out, wires move around) and subject-varying properties (i.e. different headset setups, different head and brain folds), it is typically easier to understand a dataset in smaller timeframes, hence starting with a single run. Machine learning + data science methods are typically used to help understand neural data across recordings and subjects. \n\nTerminology: <br>\n- <b>Electroencepholography (EEG)<\/b>: an electrophysiological monitoring method to record electrical activity of the brain. (Wikipedia) \n- <b>Electrooculography (EOG)<\/b>: Similar to EEG, but placed around the eyes for the purposes of picking up eye movements and blinks. \n- <b>Power Spectral Densities (PSDs)<\/b>: A representation of the \"amount\" of each frequency a signal has.  \n- <b>Spectrogram<\/b>: a visual representation of the spectrum of frequencies of a signal as it varies with time. (Wikipedia)\n\nMore details on the experiment can be found here: http:\/\/www.bbci.de\/competition\/iv\/desc_2b.pdf \n<br><br>\nSearch the page for 'Try' to see what you can easily play around with to get a better sense of the data!","33fd353b":"### Range for 3 channels: \nRange is fairly large!","2e0f7da9":"## Neural Net Classifier","7f1ff461":"### Mean voltage for 3 channels: \nAs you can see, the mean voltage is very close to zero. This is because filtering the signal between 0.5Hz and 100Hz removes most of the slow fluctuations away from zero.","f4140f92":"Using the K Nearest Neighbors Classification training algorithm, we get an f1 score of only 0.5219, which is considerably lower than the linear regression model. Let's continue testing other classification training algorithms.","48a3395b":"## Some stats on the EOG data\n*Left as an exercise to you!* :D","2b31053a":"## Gaussian Process Classification","b63f20cf":"## Nearest Neighbors","2566d51b":"## Epoch the data \ni.e. Group the time series it such that each row is a trial. We can see how each row contains 4 seconds of EEG or EOG data for each channel. ","be9b9383":"## Some stats on the EEG data on a single session"}}