{"cell_type":{"564650d4":"code","d3320a31":"code","b8b2c110":"code","911c627d":"code","0e80c05d":"code","98510959":"code","4c99486d":"code","fabb8134":"code","8974ca45":"code","ffb47dfb":"code","fcf79900":"code","af7c0a8f":"code","f4cde5e1":"code","b1da3d4d":"code","a0cff78b":"code","15fb9d32":"code","37aff28d":"code","e0c4d35a":"code","3298d962":"code","67f13de2":"code","bf9a058c":"code","0bde85cd":"code","c7efd203":"code","e6777369":"code","56f17e9e":"code","7bf1cce5":"code","bbb45c23":"code","2b0e66f4":"code","e279da53":"code","d3455fd9":"code","a3038b2f":"code","b2cf1e0b":"markdown","103daa76":"markdown","55df3242":"markdown","4312560e":"markdown","ba7753d9":"markdown"},"source":{"564650d4":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nimport json\nimport re\nimport scipy as sc\nimport warnings\n\nimport matplotlib.pyplot as plt\nimport os\n\n","d3320a31":"root_path = '\/kaggle\/input\/CORD-19-research-challenge\/'\nmetadata_path = f'{root_path}\/metadata.csv'\nmeta_df = pd.read_csv(metadata_path, dtype={\n    'pubmed_id': str,\n    'Microsoft Academic Paper ID': str, \n    'doi': str\n})\nmeta_df.head()\nmeta_df.info()","b8b2c110":"meta_df.head()\n","911c627d":"!pip install -U sentence-transformers","0e80c05d":"\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sentence_transformers import SentenceTransformer\n\nwarnings.filterwarnings(\"ignore\")\nmodel = SentenceTransformer('bert-base-nli-mean-tokens')","98510959":"import glob\nall_json = glob.glob(f'{root_path}\/**\/*.json', recursive=True)\nlen(all_json)","4c99486d":"all_json[0]","fabb8134":"class FileReader:\n    def __init__(self, file_path):\n        with open(file_path) as file:\n            content = json.load(file)\n            \n            self.paper_id = content['paper_id']\n            \n            self.abstract = []\n            self.body_text = []\n            # Abstract\n            for entry in content['abstract']:\n                self.abstract.append(entry['text'])\n            # Body text\n            for entry in content['body_text']:\n                self.body_text.append(entry['text'])\n            self.abstract = '\\n'.join(self.abstract)\n            self.body_text = '\\n'.join(self.body_text)\n    def __repr__(self):\n        return f'{self.paper_id}: {self.abstract[:200]}... {self.body_text[:200]}...'\ndef get_breaks(content, length):\n    data = \"\"\n    words = content.split(' ')\n    total_chars = 0\n\n    # add break every length characters\n    for i in range(len(words)):\n        total_chars += len(words[i])\n        if total_chars > length:\n            data = data + \"<br>\" + words[i]\n            total_chars = 0\n        else:\n            data = data + \" \" + words[i]\n    return data","8974ca45":"dict_ = {'publish_time': [], 'url': [], 'paper_id': [], 'doi':[], 'abstract': [], 'body_text': [], 'authors': [], 'title': [], 'journal': [], 'abstract_summary': []}\nfor idx, entry in enumerate(all_json):\n    if idx % (len(all_json) \/\/ 10) == 0:\n        print(f'Processing index: {idx} of {len(all_json)}')\n    \n    try:\n        content = FileReader(entry)\n    except Exception as e:\n        continue  # invalid paper format, skip\n\n    # get metadata information\n    meta_data = meta_df.loc[meta_df['sha'] == content.paper_id]\n    # no metadata, skip this paper\n    if len(meta_data) == 0:\n        continue\n    \n    dict_['abstract'].append(content.abstract)\n    dict_['paper_id'].append(content.paper_id)\n    dict_['body_text'].append(content.body_text)\n    \n    # also create a column for the summary of abstract to be used in a plot\n    if len(content.abstract) == 0: \n        # no abstract provided\n        dict_['abstract_summary'].append(\"Not provided.\")\n    elif len(content.abstract.split(' ')) > 100:\n        # abstract provided is too long for plot, take first 100 words append with ...\n        info = content.abstract.split(' ')[:100]\n        summary = get_breaks(' '.join(info), 40)\n        dict_['abstract_summary'].append(summary + \"...\")\n    else:\n        # abstract is short enough\n        summary = get_breaks(content.abstract, 40)\n        dict_['abstract_summary'].append(summary)\n        \n    # get metadata information\n    meta_data = meta_df.loc[meta_df['sha'] == content.paper_id]\n    \n    try:\n        # if more than one author\n        authors = meta_data['authors'].values[0].split(';')\n        if len(authors) > 2:\n            # if more than 2 authors, take them all with html tag breaks in between\n            dict_['authors'].append(get_breaks('. '.join(authors), 40))\n        else:\n            # authors will fit in plot\n            dict_['authors'].append(\". \".join(authors))\n    except Exception as e:\n        # if only one author - or Null valie\n        dict_['authors'].append(meta_data['authors'].values[0])\n    \n    # add the title information, add breaks when needed\n    try:\n        title = get_breaks(meta_data['title'].values[0], 40)\n        dict_['title'].append(title)\n    # if title was not provided\n    except Exception as e:\n        dict_['title'].append(meta_data['title'].values[0])\n    \n    # add meta_data information\n    dict_['journal'].append(meta_data['journal'].values[0])\n    dict_['doi'].append(meta_data['doi'].values[0])\n    dict_['publish_time'].append(meta_data['publish_time'].values[0])\n    dict_['url'].append(meta_data['url'].values[0])\n    \n    \ndf_covid = pd.DataFrame(dict_, columns=['publish_time', 'url', 'paper_id', 'doi', 'abstract', 'body_text', 'authors', 'title', 'journal', 'abstract_summary'])\ndf_covid.head()","ffb47dfb":"df_covid.info() \ndf_covid.drop_duplicates(['abstract', 'body_text'], inplace=True)\ndf_covid['abstract'].describe(include='all')","fcf79900":"df_covid.describe()","af7c0a8f":"df_covid.head()","f4cde5e1":"df_covid['abstract'].describe(include='all')\n","b1da3d4d":"df = df_covid","a0cff78b":"!pip install langdetect","15fb9d32":"from tqdm import tqdm\nfrom langdetect import detect\nfrom langdetect import DetectorFactory\n\n# set seed\nDetectorFactory.seed = 1000000007\n\n# hold label - language\nlanguages = []\n\n# go through each text\nfor ii in tqdm(range(0,len(df))):\n    # split by space into list, take the first x intex, join with space\n    text = df.iloc[ii]['body_text'].split(\" \")\n    \n    lang = \"en\"\n    try:\n        if len(text) > 50:\n            lang = detect(\" \".join(text[:50]))\n        elif len(text) > 0:\n            lang = detect(\" \".join(text[:len(text)]))\n    # ught... beginning of the document was not in a good format\n    except Exception as e:\n        all_words = set(text)\n        try:\n            lang = detect(\" \".join(all_words))\n        # what!! :( let's see if we can find any text in abstract...\n        except Exception as e:\n            \n            try:\n                # let's try to label it through the abstract then\n                lang = detect(df.iloc[ii]['abstract_summary'])\n            except Exception as e:\n                lang = \"unknown\"\n                pass\n    \n    # get the language    \n    languages.append(lang)","37aff28d":"from pprint import pprint\n\nlanguages_dict = {}\nfor lang in set(languages):\n    languages_dict[lang] = languages.count(lang)\n    \nprint(\"Total: {}\\n\".format(len(languages)))\npprint(languages_dict)","e0c4d35a":"df['language'] = languages\nplt.bar(range(len(languages_dict)), list(languages_dict.values()), align='center')\nplt.xticks(range(len(languages_dict)), list(languages_dict.keys()))\nplt.title(\"Distribution of Languages in Dataset\")\nplt.show()","3298d962":"df = df[df['language'] == 'en'] \ndf.info()\ndf.head()","67f13de2":"df.dropna(inplace=True)\ndf.head()\n","bf9a058c":"df.info()\n","0bde85cd":"df.drop(columns=['language', 'authors'])\ndf.drop(columns=['paper_id', 'doi'])","c7efd203":"df.to_csv( 'Prepared_data.csv', index = False)","e6777369":"task1=\"\"\"Specifically, we want to know what the literature reports about:\n\nModes of communicating with target high-risk populations\nManagement of patients who are underhoused or otherwise lower social economic status\nWhat are ways to create hospital infrastructure to prevent nosocomial outbreaks?\nMethods to control the spread in communities\nWhat are recommendations for combating_overcoming resource failures?\"\"\"","56f17e9e":"task=[task1]\nquery=[]\nfor i in range(len(task)):\n    task[i]=task[i].split(\"\\n\")\n    query.append(task[i][2:])\nprint(query)","7bf1cce5":"!pip install -U sentence-transformers","bbb45c23":"from sklearn.metrics.pairwise import cosine_similarity\nfrom sentence_transformers import SentenceTransformer\n\nwarnings.filterwarnings(\"ignore\")\nmodel = SentenceTransformer('bert-base-nli-mean-tokens')\n    ","2b0e66f4":"query_embeddings=[]\nfor i in range(len(query)):\n    query_embeddings.append(model.encode(query[i]))","e279da53":"df.reset_index(drop = True, inplace = True)\ndf['abstract_summary']\n#abstract_embeddings = model.encode(df['abstract'])\nabstract_summary_embeddings = model.encode(df['abstract_summary'])\n","d3455fd9":"def getfile_insensitive(path):\n    directory, filename = os.path.split(path)\n    directory, filename = (directory or '.'), filename.lower()\n    for f in os.listdir(directory):\n        newpath = os.path.join(directory, f)\n        if os.path.isfile(newpath) and f.lower() == filename:\n            return newpath\n\ndef isfile_insensitive(path):\n    return getfile_insensitive(path) is not None\n\nsample_document='1_population'\n","a3038b2f":"scores=[]\ndef formatting(_topdf):\n    _topdf.rename(columns={'journal':'Journal'},inplace=True)\n    _topdf.rename(columns={'url':'Study Link'},inplace=True)\n    _topdf.rename(columns={'publish_time':'Date'},inplace=True)\n    _topdf.rename(columns={'title':'Study'},inplace=True)\n    \n    return _topdf\nfor tsk in range(len(task)):\n    \n    for prob, query_embedding in zip(query[tsk], query_embeddings[tsk]):\n        dis = sc.spatial.distance.cdist([query_embedding], abstract_summary_embeddings, \"cosine\")[0]\n        #print(dis)\n        results = zip(range(len(dis)), dis)\n        results = sorted(results, key=lambda x: x[1])\n        #print(\"Query:\", prob)\n        #print(\"Answer:\" )\n        scores.append(1-results[0][1])\n        #print(df['abstract'][results[0][0]].strip(), \"\\n(Score: %.4f)\" % (1-results[0][1]),\"\\n\")\n        k=50\n        #print(results[:k])\n        topk=results[:k]\n        id,id_v=zip(*topk)\n        topData=df.iloc[1]\n        _topdf = df.iloc[list(id), :]\n        _topdf = formatting(_topdf)\n        csv_str=prob.replace('?','_')+'.csv'\n        #print(csv_str)\n        path1 = f'{root_path}Kaggle\/target_tables\/{sample_document}\/'+csv_str\n        path1 = f'{path1}'\n        print(path1)\n        if (isfile_insensitive(path1)):\n            path1=getfile_insensitive(path1)\n            q_df = pd.read_csv(path1)\n            print(\"exist!\")\n        else:      \n            path1 = f'{root_path}Kaggle\/target_tables\/{sample_document}\/'\n            path1 = os.path.join(path1,os.listdir(path1)[-1])\n            q_df = pd.read_csv(path1)\n            q_df.drop(q_df.index,inplace=True)\n        #print(path1)\n        q_df.head()\n        q_df\n        #print(len(q_df))\n        #print(len(_topdf))\n        #print(q_df.columns)\n        res_df = pd.merge(q_df, _topdf, how='outer', on=['Study','Study Link','Date','Journal'])[q_df.columns[1:]]\n        #print(len(res_df))\n        res_df.info()\n        res_csv=r'\/kaggle\/output\/'+ csv_str\n        print(res_csv)\n        res_df.to_csv( csv_str, index = True)","b2cf1e0b":"# Prepare data","103daa76":"# Check the keywords of the problems.","55df3242":"# Add the language attribute.","4312560e":"1. PopulationThis is a notebook for Population studies related to COVID-19.","ba7753d9":"Specifically, we want to know what the literature reports about:\n\n- **Modes of communicating with target high-risk populations** (elderly, health care workers).\n- Management of patients who are **underhoused or otherwise lower socioeconomic status**.\n- What are ways to create **hospital infrastructure** to **prevent nosocomial outbreaks and protect uninfected patients**?\n- Methods to control **the spread in communities, barriers to compliance**\n- What are recommendations for **combating\/overcoming resource failures**\n"}}