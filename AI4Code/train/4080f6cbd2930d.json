{"cell_type":{"23568312":"code","95f03288":"code","db37faff":"code","51f8a3e3":"code","a65814db":"code","3fb28ce2":"code","aacf42bd":"code","e0387489":"code","1d3e19b3":"code","2282cf13":"code","8e7855c9":"code","09f18c07":"code","5a6337ba":"code","d9fdaede":"code","caa71351":"code","8246b931":"code","0e98fbbb":"code","94908669":"code","6f68d523":"code","bbfc260e":"code","31992aba":"code","f6087c1a":"code","0dd8b9e7":"code","f2c4ebb9":"code","aa626ea7":"code","e8daf5da":"code","823abd0f":"code","1c30126a":"code","cc1f22c2":"code","3937eeed":"code","ba1b8665":"code","464dff34":"code","69da4391":"code","618bcc79":"code","9a4c49a2":"code","b6536a94":"code","444f7c65":"code","8f7b1f9f":"code","637e6969":"code","80bd8e4c":"code","803f2c90":"code","c2419a72":"code","d1fb6b88":"code","bb2f4d30":"code","e9a4b1d7":"code","e8007778":"code","6847490b":"code","0045a011":"markdown","a2ea6bdb":"markdown","34f9778b":"markdown","6110430e":"markdown","91390ca4":"markdown","dc04bbb2":"markdown","55f2efa2":"markdown","7ec99ebf":"markdown","8a7396cb":"markdown","ca364783":"markdown"},"source":{"23568312":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","95f03288":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport xgboost as xgb\n\npath = '\/kaggle\/input\/competitive-data-science-predict-future-sales\/'\nitems = pd.read_csv(path+'items.csv')\nsales_train = pd.read_csv(path+'sales_train.csv')\nitem_categories = pd.read_csv(path+'item_categories.csv')\ntest = pd.read_csv(path+'test.csv')\nshops = pd.read_csv(path+'shops.csv')\n","db37faff":"items.head(2)","51f8a3e3":"sales_train.head(2)","a65814db":"item_categories.head(2)","3fb28ce2":"test.head(2)","aacf42bd":"shops.head(2)","e0387489":"sales_train.dtypes","1d3e19b3":"sales_train.head(1)","2282cf13":"sales_train.date = pd.to_datetime(sales_train.date, format=\"%d.%m.%Y\")\n","8e7855c9":"print(\"---------------------TRAIN-INFO----------------------\")\nprint(sales_train.head())\nprint(sales_train.dtypes)\nprint(sales_train.info())\nprint(sales_train.shape)","09f18c07":"print(\"---------------------TEST-INFO----------------------\")\nprint(test.head())\nprint(test.dtypes)\nprint(test.info())\nprint(test.shape)","5a6337ba":"def downcast_dtypes(df):\n    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n    int_cols = [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n    df[float_cols] = df[float_cols].astype(np.float32)\n    df[int_cols] = df[int_cols].astype(np.int16)\n    return df\n\nsales_train = downcast_dtypes(sales_train)\nprint(sales_train.info())","d9fdaede":"sales_train.hist(figsize=(20,15), bins=50)","caa71351":"target_range = [0 ,20]","8246b931":"sales = pd.merge(sales_train, items, on='item_id', how='left')\nsales = sales.drop('item_name', axis=1)\nsales.head(10)","0e98fbbb":"index_cols = ['shop_id', 'item_id', 'date_block_num']\nfrom itertools import product","94908669":"grid = []\nfor block_num in sales['date_block_num'].unique():\n    cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n    cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])), dtype='int32'))\ngrid = pd.DataFrame(np.vstack(grid), columns = index_cols, dtype=np.int32)","6f68d523":"grid.head()","bbfc260e":"mean_sales = sales.groupby(['date_block_num', 'shop_id', 'item_id']).agg({'item_cnt_day': 'sum', 'item_price': np.mean}).reset_index()","31992aba":"mean_sales = pd.merge(grid, mean_sales, on=['date_block_num', 'shop_id', 'item_id'], how='left').fillna(0)\nmean_sales = pd.merge(mean_sales, items, on='item_id', how='left')","f6087c1a":"for type_id in ['item_id', 'shop_id', 'item_category_id']:\n    for column_id, aggregator, aggtype in [('item_price',np.mean,'avg'),('item_cnt_day',np.sum,'sum'),('item_cnt_day',np.mean,'avg')]:\n        \n        mean_df = sales.groupby([type_id,'date_block_num']).aggregate(aggregator).reset_index()[[column_id,type_id,'date_block_num']]\n        mean_df.columns = [type_id+'_'+aggtype+'_'+column_id,type_id,'date_block_num']\n        mean_sales = pd.merge(mean_sales, mean_df, on=['date_block_num',type_id], how='left')","0dd8b9e7":"mean_sales.head()","f2c4ebb9":"lag_variables = list(mean_sales.columns[7:])+['item_cnt_day']\nlags = [1, 2, 3, 6]\nfrom tqdm import tqdm_notebook\nfor lag in tqdm_notebook(lags):\n    sales_new_df = mean_sales.copy()\n    sales_new_df.date_block_num += lag\n    sales_new_df = sales_new_df[['date_block_num', 'shop_id', 'item_id']+lag_variables]\n    sales_new_df.columns = ['date_block_num', 'shop_id', 'item_id'] + [lag_feat+ '_lag_'+str(lag) for lag_feat in lag_variables]\n    mean_sales = pd.merge(mean_sales, sales_new_df, on=['date_block_num', 'shop_id', 'item_id'], how='left')\n    ","aa626ea7":"mean_sales.head(10)","e8daf5da":"mean_sales = mean_sales[mean_sales['date_block_num']>12]","823abd0f":"for feat in mean_sales.columns:\n    if 'item_cnt' in feat:\n        mean_sales[feat] = mean_sales[feat].fillna(0)\n    elif 'item_price' in feat:\n        mean_sales[feat] = mean_sales[feat].fillna(mean_sales[feat].median())\n","1c30126a":"cols_to_drop = lag_variables[:-1] + ['item_price', 'item_name']","cc1f22c2":"training = mean_sales.drop(cols_to_drop, axis=1)","3937eeed":"xgbtrain = xgb.DMatrix(training.iloc[:, training.columns != 'item_cnt_day'].values, training.iloc[:, training.columns == 'item_cnt_day'].values)","ba1b8665":"params = {\n    'max_depth': 10,\n    'subsample': 1,\n    'min_child_weight': 0.5,\n    'eta': 0.3,\n    'num_round': 1000,\n    'seed': 1,\n    'silent': 0,\n    'eval_metric': 'rmse'\n}\nboost = xgb.train(params, xgbtrain)","464dff34":"x = xgb.plot_importance(boost)\nx.figure.set_size_inches(10,20)","69da4391":"cols = list(training.columns)\ndel cols[cols.index('item_cnt_day')]","618bcc79":"[cols[x] for x in [2, 0, 1, 3, 5]]","9a4c49a2":"training.columns","b6536a94":"test = pd.read_csv(path+'test.csv')","444f7c65":"print(\"--------------------Test-Info------------------\")\nprint(test.head())\nprint(test.info())\nprint(test.columns)","8f7b1f9f":"test['date_block_num'] = 34\ntest = pd.merge(test, items, on='item_id', how='left')","637e6969":"from tqdm import tqdm_notebook\nfor lag in tqdm_notebook(lags):\n    sales_new_df = mean_sales.copy()\n    sales_new_df.date_block_num += lag\n    sales_new_df = sales_new_df[['date_block_num', 'shop_id', 'item_id']+lag_variables]\n    sales_new_df.columns = ['date_block_num', 'shop_id', 'item_id'] + [lag_feat+ '_lag_'+str(lag) for lag_feat in lag_variables]\n    test = pd.merge(test, sales_new_df, on=['date_block_num', 'shop_id', 'item_id'], how='left')\n    ","80bd8e4c":"df_test = set(test.drop(['ID', 'item_name'], axis=1).columns)\ndf_training = set(training.drop('item_cnt_day', axis=1).columns)\nfor i in df_test:\n    assert i in df_training\nfor j in df_training:\n    assert j in df_test","803f2c90":"assert df_training == df_test","c2419a72":"test = test.drop(['ID', 'item_name'], axis=1)\nfor feat in test.columns:\n    if 'item_cnt' in feat:\n        test[feat]=test[feat].fillna(0)\n    elif 'item_price' in feat:\n        test[feat] = test[feat].fillna(test[feat].median())","d1fb6b88":"test[['shop_id', 'item_id']+['item_cnt_day_lag_'+str(x) for x in[1,2,3]]].head()","bb2f4d30":"xgbpredict = xgb.DMatrix(test.values)\npred = boost.predict(xgbpredict)\npd.Series(pred).describe()","e9a4b1d7":"pred = pred.clip(0, 20)\npd.Series(pred).describe()","e8007778":"submission_df = pd.DataFrame({'ID': test.index, 'item_cnt_month': pred})\nsubmission_df.head(10)","6847490b":"submission_df.to_csv('submission_xgboost.csv', index=False)","0045a011":"Lag variables","a2ea6bdb":"Mean encodings","34f9778b":"Definition of target range. Second advice course","6110430e":"Train XGBoost model","91390ca4":"Additional part Mean encoding","dc04bbb2":"Preparing predictions","55f2efa2":"Some libraries and reading files","7ec99ebf":"Fill NA with zeros","8a7396cb":"Forecasting monthly sales","ca364783":"Memory consumption reduction"}}