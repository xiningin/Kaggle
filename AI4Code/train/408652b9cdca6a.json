{"cell_type":{"31f0a1e0":"code","8d6ad02f":"code","2c5f6e6e":"code","a6cba087":"code","f928278c":"code","2931e73d":"code","586b0adb":"code","af8b4479":"code","902d5b9b":"code","2e18fb9b":"code","e7adb5fc":"code","295ee237":"code","e76a3078":"code","3bb277b6":"code","3aa0b5bd":"code","9febafc7":"code","7b1ab70c":"code","6b38c76c":"code","77c8bf1c":"code","cea5ce4f":"code","02bb7718":"code","9edd8ee6":"code","911d245e":"code","61550501":"code","f2e6668a":"code","d80e052d":"markdown"},"source":{"31f0a1e0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8d6ad02f":"import math, re, os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom skimage import io\nimport matplotlib.pyplot as plt\n\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","2c5f6e6e":"\n\nprint(\"Tensorflow version \" + tf.__version__)\n\n\n# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n","a6cba087":"import pandas as pd\n\ntrain = pd.read_csv('..\/input\/prostate-cancer-grade-assessment\/train.csv')\n\ntrain.head()","f928278c":"from skimage import io\nimport matplotlib.pyplot as plt\n\nfilrt = \"..\/input\/prostate-cancer-grade-assessment\/train_images\/\"\n\n# print(\"..\/input\/prostate-cancer-grade-assessment\/train_images\/\"+train[\"image_id\"][0])\n\n\n# for x,i in zip(train[\"image_id\"],range(10)):\n    \n# #     read the image stack\n#     img = io.imread(filrt+x+\".tiff\")\n#     # show the image\n#     plt.imshow(img,cmap='gray')\n#     plt.axis('off')\n#     plt.show()\n","2931e73d":"for x,i in zip(filrt+train[\"image_id\"]+\".tiff\",range(10)):\n    print(x.shape)","586b0adb":"img = io.imread(filrt+train[\"image_id\"][0]+\".tiff\")\nimg.resize(int(29440\/10),int(27648\/10),3)\n\nplt.imshow(img,cmap='gray')\nplt.axis('off')\nplt.show()\n# img\/255.0","af8b4479":"tfio.experimental.image.decode_tiff(\n    train[\"image_id\"], index=0, name=None\n)","902d5b9b":"EPOCHS = 5\nwith strategy.scope():\n    pretrained_model = tf.keras.applications.DenseNet201(\n        weights='imagenet',\n        include_top=False ,\n        input_shape=img.shape\n    )\n    pretrained_model.trainable = False\n    \n    model = tf.keras.Sequential([\n        # To a base pretrained on ImageNet to extract features from images...\n        pretrained_model,\n        # ... attach a new head to act as a classifier.\n#         tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(5, activation='softmax')\n    ])\n    \nmodel.compile(\n    optimizer='adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics=['sparse_categorical_accuracy'],\n)\nwide = model \n\nmodel.summary()\n\n# Define training epochs\nEPOCHS = 5\nSTEPS_PER_EPOCH = 12\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto',\n    baseline=None, restore_best_weights=False\n)\n\nhistory = model.fit(\n    filrt+train[\"image_id\"]+\".tiff\",train[\"isup_grade\"],\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[early_stopping],\n)","2e18fb9b":"train[\"isup_grade\"]","e7adb5fc":"[img.shape]","295ee237":"import pathlib\ndataset_url = \"..\/input\/prostate-cancer-grade-assessment\/train_images\"\n# data_dir = tf.keras.utils.get_file(origin=dataset_url, \n#                                    fname='flower_photos', \n#                                    untar=True)\ndata_dir = pathlib.Path(dataset_url)","e76a3078":"image_count = len(list(data_dir.glob('*.tiff')))\nprint(image_count)\nimm = None\n\nfor x in data_dir.glob('*.tiff'):\n#     os.rename(x, \"dst\"+str(x))\n    print(x)\n    imm = x\n    break","3bb277b6":"data_dir","3aa0b5bd":"batch_size = 32\nimg_height = 180\nimg_width = 180","9febafc7":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","7b1ab70c":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n#Generate a dataset\n\nimage_size = (28, 28)\nbatch_size = 32\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1337,\n    image_size=(img_height, img_width),\n    batch_size=batch_size,\n)","6b38c76c":"!pip install fastai2\n!pip install fastai","77c8bf1c":"from fastai2  import *\n","cea5ce4f":"!pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()","02bb7718":"from fastbook import *","9edd8ee6":"# CLICK ME\nfrom fastai.vision.all import *\npath = untar_data(URLs.PETS)\/'images'\n\ndef is_cat(x): return x[0].isupper()\ndls = ImageDataLoaders.from_name_func(\n    path, get_image_files(path), valid_pct=0.2, seed=42,\n    label_func=is_cat, item_tfms=Resize(224))\n\nlearn = cnn_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(1)","911d245e":"\npath = untar_data(URLs.CAMVID_TINY)\ndls = SegmentationDataLoaders.from_label_func(\n    path, bs=8, fnames = get_image_files(path\/\"images\"),\n    label_func = lambda o: path\/'labels'\/f'{o.stem}_P{o.suffix}',\n    codes = np.loadtxt(path\/'codes.txt', dtype=str)\n)\n\nlearn = unet_learner(dls, resnet34)\nlearn.fine_tune(8)","61550501":"learn.show_results(max_n=6, figsize=(7,8))\n\n\nfrom fastai.text.all import *\n\ndls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test')\nlearn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\nlearn.fine_tune(4, 1e-2)","f2e6668a":"learn.predict(\"I really liked that movie!\")","d80e052d":"# TPU settings"}}