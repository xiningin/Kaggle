{"cell_type":{"896b3db5":"code","573cc487":"code","61fe27fa":"code","569daa19":"code","105a7612":"code","bfbe8777":"code","ea417353":"code","2a3339af":"code","f81fe0d7":"code","670a37f3":"code","658e0817":"code","056cc49e":"code","a5b78e80":"code","de3ff47b":"code","52ed1327":"code","724e0660":"code","f75b454d":"code","91913aeb":"code","5eef41ab":"code","651ea24e":"code","c156160e":"code","c2b260e6":"code","0c586637":"code","4c06ed0e":"code","76be7d0e":"code","3be9b2ec":"code","6ee5960a":"code","eff514b4":"code","0da16e0a":"code","58f7e3c6":"code","37b9adea":"code","63db84e6":"code","16a27f04":"code","8e67c43e":"markdown","0a41ecd4":"markdown","069c294e":"markdown","8d284e93":"markdown","370a0171":"markdown","c3b1526f":"markdown","135382ee":"markdown","c412d570":"markdown","030fba85":"markdown","41e0a1e1":"markdown"},"source":{"896b3db5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","573cc487":"data = pd.read_csv(\"\/kaggle\/input\/kdd-cyberattack\/kddcup.data_10_percent\")\ndata.head()","61fe27fa":"# Columns creation and reading of dataset\n\ncolumns = [\"duration\", \"protocoltype\", \"service\", \"flag\", \"srcbytes\", \"dstbytes\", \"land\", \"wrongfragment\",\n           \"urgent\", \"hot\", \"numfailedlogins\", \"loggedin\", \"numcompromised\", \"rootshell\", \"suattempted\",\n           \"numroot\", \"numfilecreations\", \"numshells\", \"numaccessfiles\", \"numoutboundcmds\", \"ishostlogin\",\n           \"isguestlogin\", \"count\", \"srvcount\", \"serrorrate\", \"srvserrorrate\", \"rerrorrate\", \"srvrerrorrate\",\n           \"samesrvrate\", \"diffsrvrate\", \"srvdiffhostrate\", \"dsthostcount\", \"dsthostsrvcount\",\n           \"dsthostsamesrvrate\", \"dsthostdiffsrvrate\", \"dsthostsamesrcportrate\", \"dsthostsrvdiffhostrate\",\n           \"dsthostserrorrate\", \"dsthostsrvserrorrate\", \"dsthostrerrorrate\", \"dsthostsrvrerror_rate\", \"labels\"]\n\n\ndata = pd.read_csv(\"\/kaggle\/input\/kdd-cyberattack\/kddcup.data_10_percent\", names=columns)\ndata.head()","569daa19":"# Data set size\ndata.shape","105a7612":"# Null values\n[col for col in data.columns if data[col].isnull().sum() > 0]","bfbe8777":"data.dtypes","ea417353":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n\nsns.set_style(\"darkgrid\")\nplt.rcParams[\"figure.figsize\"] = (12,8)\nfont = {\"size\"   : 11}\n\nplt.rc('font', **font)\n\n\n\ngrouped_labels = data.groupby(\"labels\")[\"labels\"].count().sort_values(ascending=False)\nplt.xticks(rotation=45)\n\n\nsns.barplot(x=grouped_labels.index, y=grouped_labels.values)\nplt.title(\"Count of attacks and normal events\")\nplt.ylabel(\"Count\")","2a3339af":"grouped_labels = data.groupby(\"protocoltype\")[\"protocoltype\"].count().sort_values(ascending=False)\nplt.xticks(rotation=45)\n\n\nsns.barplot(x=grouped_labels.index, y=grouped_labels.values)\nplt.title(\"labels by Protocol type\")\nplt.ylabel(\"Count\")","f81fe0d7":"def remove_dot(label):\n    \"\"\" Remove dot from labels \"\"\"\n    return label.replace(\".\", \"\")\n\n\ndata[\"labels\"] = data[\"labels\"].apply(lambda label: remove_dot(label))\nprint(pd.unique(data[\"labels\"]))","670a37f3":"attack_families = {\n    \"back\": \"dos\",\n    \"buffer_overflow\": \"u2r\",\n    \"ftp_write\": \"r2l\",\n    \"guess_passwd\": \"r2l\",\n    \"imap\": \"r2l\",\n    \"ipsweep\": \"probe\",\n    \"land\": \"dos\",\n    \"loadmodule\": \"u2r\",\n    \"multihop\": \"r2l\",\n    \"neptune\": \"dos\",\n    \"nmap\": \"probe\",\n    \"perl\": \"u2r\",\n    \"phf\": \"r2l\",\n    \"pod\": \"dos\",\n    \"portsweep\": \"probe\",\n    \"rootkit\": \"u2r\",\n    \"satan\": \"probe\",\n    \"smurf\": \"dos\",\n    \"spy\": \"r2l\",\n    \"teardrop\": \"dos\",\n    \"warezclient\": \"r2l\",\n    \"warezmaster\": \"r2l\",\n    \"normal\": \"normal\",\n}\n\n\ndef map_attacks_to_families(attack):\n    \"\"\" Map attack to it's family \"\"\"\n    return attack_families[attack]\n\n\ndata[\"labels\"] = data[\"labels\"].apply(lambda attack: map_attacks_to_families(attack))\nprint(pd.unique(data[\"labels\"]))","658e0817":"sns.countplot(x=\"labels\", data=data)\nplt.title(\"Class balance\")","056cc49e":"sns.catplot(x=\"protocoltype\", y=\"count\", hue=\"labels\", data=data)\nplt.title(\"Number of connections to the same host as the current connection in the past two seconds \")","a5b78e80":"sns.catplot(x=\"protocoltype\", y=\"numfilecreations\", hue=\"labels\", data=data)","de3ff47b":"sns.catplot(x=\"protocoltype\", y=\"numfailedlogins\", hue=\"labels\", data=data)","52ed1327":"sns.catplot(x=\"protocoltype\", y=\"numshells\", hue=\"labels\", data=data)","724e0660":"sns.catplot(x=\"protocoltype\", y=\"numaccessfiles\", hue=\"labels\", data=data)","f75b454d":"sns.catplot(x=\"protocoltype\", y=\"numroot\", hue=\"labels\", data=data)","91913aeb":"sns.catplot(x=\"protocoltype\", y=\"suattempted\", hue=\"labels\", data=data)","5eef41ab":"sns.catplot(x=\"protocoltype\", y=\"duration\", hue=\"labels\", data=data)","651ea24e":"sns.catplot(x=\"protocoltype\", y=\"srcbytes\", hue=\"labels\", data=data)","c156160e":"sns.catplot(x=\"protocoltype\", y=\"dstbytes\", hue=\"labels\", data=data)","c2b260e6":"# Creating feature vector and target vector.\nX = data.drop(\"labels\", axis=1)\ny = data[\"labels\"]\n\n\n# Constant features \n[col for col in X.columns if X[col].nunique() == 1]","0c586637":"# Those two columns have no variance, thus they won't be of any use to our model. Let's drop them\nX.drop([\"numoutboundcmds\", \"ishostlogin\"], axis=1, inplace=True)","4c06ed0e":"# Encode categorical columns and split data.\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n\n# Encoding target variable\nlr = LabelEncoder()\ny = lr.fit_transform(y)\n\n\n# Encoding predictors\nenc_protocol = pd.get_dummies(data[\"protocoltype\"], prefix=\"protocol_\")\nenc_service = pd.get_dummies(data[\"service\"], prefix=\"service_\")\nenc_flag = pd.get_dummies(data[\"flag\"], prefix=\"flag_\")\n\nX = pd.concat([X, enc_protocol, enc_service, enc_flag], axis=1)\nX.drop(\"protocoltype\", axis=1, inplace=True)\nX.drop(\"service\", axis=1, inplace=True)\nX.drop(\"flag\", axis=1, inplace=True)\n\n\n# Splitting data into train and test...since our data is implaced we stratify it\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, stratify=y)","76be7d0e":"# Anova test for feature importance\nfrom sklearn.feature_selection import f_classif\n\n\nanova_f_classif = f_classif(X_train, y_train)\n\n\nanova_f_classif = pd.Series(anova_f_classif[1])\nanova_f_classif.index = X_train.columns\nanova_f_classif.sort_values(ascending=False).plot.bar(figsize=(20, 6))","3be9b2ec":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbc = GradientBoostingClassifier()\n\ngbc.fit(X_train, y_train)","6ee5960a":"# Prediciton\ny_train_pred = gbc.predict(X_train)\ny_test_pred = gbc.predict(X_test)","eff514b4":"from sklearn.metrics import f1_score, plot_confusion_matrix\n\n\nprint(\"Training f1 score {}\".format(f1_score(y_train, y_train_pred, average=\"macro\")))\nprint(\"Evaluation f1 score {}\".format(f1_score(y_test, y_test_pred, average=\"macro\")))","0da16e0a":"plot_confusion_matrix(gbc, X_test, y_test)\nplt.show()","58f7e3c6":"from sklearn.metrics import classification_report\n\n\ny_test_transformed = lr.inverse_transform(y_test)\ny_predict_transformed = lr.inverse_transform(y_test_pred)\nprint(classification_report(y_test_transformed, y_predict_transformed))","37b9adea":"import xgboost as xgb\n\n\nxgbc = xgb.XGBRFClassifier()\nxgbc.fit(X_train, y_train)\nxgbc_pred = xgbc.predict(X_test)","63db84e6":"print(\"Evaluation f1 score {}\".format(f1_score(y_test, xgbc_pred, average=\"macro\")))","16a27f04":"y_xgb_predict_transformed = lr.inverse_transform(xgbc_pred)\n\nprint(classification_report(y_test_transformed, y_xgb_predict_transformed))","8e67c43e":"#### We can see from the classification report that with the xgboost model we have a better f1 score in u2r class, let's try to tune this model and see if can get better","0a41ecd4":"#### Ok apart from `procotol`, `last connection to same host` and `duration` there is no another evident preliminary conclusion that we might draw between events and the target, let's have later on a featrue importance regarding the target. Next we'll drop `constant features` and `quasi constant features`","069c294e":"#### Looks much better now, let's continue with EDA","8d284e93":"#### First thing here we have no columns in our dataset so we need to create ones for ourselves and read back the data. Let's do this !","370a0171":"## In this notebook we're going to build a Network Traffic Classifier, which will yield if a given event if legit or maliscous.\n\n### The content will be as follows\n\n1. EDA\n2. Data Processing\n3. Model training\n4. Hyperparameter tuning","c3b1526f":"#### Many columns seem to have no big relevance to the target, but this method is univariate and sometimes some columns combined with others may have sense. So for now we'll keep them","135382ee":"### By taking a `normal` mean a.k.a `macro` we get a 79% mean between accuracy an recall, it gets to 98% once you take the weighted average to take into consideration class imbalance","c412d570":"#### There's a slight positive correlation between `tcp` protocol `maliscious` event and a high `duration` of the connection between the user and the host","030fba85":"#### Our first model is going to be a Binomial one, so from here on we're going to map anything that is not normal to attack. Next data analysis will be basesd on this transformation","41e0a1e1":"#### There seems to a high number of maliscious events within the `tcp` and `icmp` protocols having a high number of past connections to the current host within the last 2 seconds. That's a column that already exists within the dataset."}}