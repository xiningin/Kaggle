{"cell_type":{"2292a484":"code","19822231":"code","1072d3df":"code","17cd8c80":"code","ebc113e1":"code","81db42c2":"code","5dc2bfea":"code","6f93870c":"code","0e8b7dce":"code","391cc8c6":"code","0d49ac8d":"code","60e0ecc1":"code","f71453a8":"code","22fb7b89":"code","f0ee4c1e":"code","722d589c":"code","545c7cb2":"code","13cf8c79":"code","704bb37e":"code","d5f058b1":"code","a3d3bf21":"code","ba214ef9":"code","2d5d28dd":"code","2fe100e4":"code","d05a1d62":"code","be008e3a":"code","06c4f16b":"code","3e5ebce1":"code","6a12ceaf":"code","ea72d067":"code","fa5c7154":"code","da1b17fb":"code","30458f38":"code","13d330e4":"code","77a27b35":"code","c8b8aa94":"code","06833caf":"code","b6eb121d":"code","60474479":"code","0b16b725":"code","b48f3aeb":"code","05131390":"code","2ac8807c":"code","c31e13fe":"code","d743cf79":"code","e47be2b4":"code","ea24c05f":"code","e841b375":"code","811059ec":"code","42906602":"code","870bed9e":"code","5e513508":"code","84d4c736":"code","cc9a9044":"code","d3c7ac94":"code","eca38c99":"code","4a35df5f":"markdown","dc8c6a69":"markdown","e19e83e4":"markdown","b6e71c05":"markdown","52ca420a":"markdown","7fe6d507":"markdown","4db58586":"markdown","87c81b66":"markdown","a336598e":"markdown","67bd7439":"markdown","12b8a049":"markdown"},"source":{"2292a484":"%%html\n<style>\n@import url('https:\/\/fonts.googleapis.com\/css?family=Ewert|Roboto&effect=3d');\nspan {font-family:'Roboto'; color:black; text-shadow:3px 3px 3px #999;}  \ndiv.output_area pre{font-family:'Roboto'; font-size:110%; color:#ff603b;}      \n<\/style>","19822231":"import warnings; warnings.filterwarnings('ignore')\nimport numpy as np,pandas as pd,scipy as sp\nimport pylab as pl,seaborn as sn\nimport os,json,cv2,h5py\nimport keras as ks,tensorflow as tf\nfrom PIL import ImageFile\nfrom tqdm import tqdm\nfrom skimage import io\nprint(os.listdir(\"..\/input\"))","1072d3df":"from sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom keras.preprocessing import sequence as ksequence\nfrom keras.preprocessing import image as kimage\nfrom keras.utils import to_categorical\nfrom keras.models import Model,Sequential,load_model\nfrom keras.layers import Dense,Activation,\\\nDropout,Flatten,Conv2D,MaxPooling2D,\\\nGlobalMaxPooling2D,GlobalAveragePooling2D,\\\nInput,Conv1D,MaxPooling1D,LSTM\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.advanced_activations import PReLU,LeakyReLU\nfrom keras.callbacks import ModelCheckpoint,\\\nReduceLROnPlateau,EarlyStopping","17cd8c80":"def loss_plot(fit_history):\n    pl.figure(figsize=(10,3))\n    pl.plot(fit_history.history['loss'],label='train')\n    pl.plot(fit_history.history['val_loss'],label='test')\n    pl.legend(); pl.title('Loss Function');   \ndef mae_plot(fit_history):\n    pl.figure(figsize=(10,3))\n    pl.plot(fit_history.history['mean_absolute_error'],label='train')\n    pl.plot(fit_history.history['val_mean_absolute_error'],label='test')\n    pl.legend(); pl.title('Mean Absolute Error'); \ndef acc_plot(fit_history):\n    pl.figure(figsize=(10,3))\n    pl.plot(fit_history.history['acc'],label='train')\n    pl.plot(fit_history.history['val_acc'],label='test')\n    pl.legend(); pl.title('Accuracy'); ","ebc113e1":"def prepro(x_train,y_train,x_test,y_test):\n    N=y_train.shape[0]; shuffle_ids=np.arange(N)\n    np.random.RandomState(23).shuffle(shuffle_ids)\n    x_train,y_train=\\\n    x_train[shuffle_ids],y_train[shuffle_ids]\n    n=int(len(x_test)\/2)\n    x_valid,y_valid=x_test[:n],y_test[:n]\n    x_test,y_test=x_test[n:],y_test[n:]\n    print(x_train.shape,x_valid.shape,x_test.shape)\n    print(y_train.shape,y_valid.shape,y_test.shape)\n    print('Label: ',y_train[1][0])\n    pl.figure(figsize=(3,3)); \n    pl.xticks([]); pl.yticks([])\n    pl.imshow(x_train[1],cmap='bone'); pl.show()\n    return [x_train,y_train,x_valid,y_valid,x_test,y_test]","81db42c2":"print(ks.__version__)\n# variants: theano, tensorflow, cntk\nks.backend.backend(),\\\nks.backend.image_dim_ordering()","5dc2bfea":"# 32x32 color images; labeled over 10 categories\n# 50,000 - the train set; 10,000 - the test set\n(x_train1,y_train1),(x_test1,y_test1)=\\\nks.datasets.cifar10.load_data()\n[x_train1,y_train1,x_valid1,y_valid1,x_test1,y_test1]=\\\nprepro(x_train1,y_train1,x_test1,y_test1)","6f93870c":"# 28x28 grayscale images; labeled over 10 categories\n# 55,000 - the train set; 10,000 - the test set\n(x_train2,y_train2),(x_test2,y_test2)=\\\nks.datasets.mnist.load_data()\n[x_train2,y_train2,x_valid2,y_valid2,x_test2,y_test2]=\\\nprepro(x_train2,y_train2.reshape(-1,1),\n       x_test2,y_test2.reshape(-1,1))","0e8b7dce":"# 18000 newsgroups posts on 20 topics\ntrain=fetch_20newsgroups(subset='train',shuffle=True,\n                         remove=('headers','footers','quotes'))\ntest=fetch_20newsgroups(subset='test',shuffle=True,\n                        remove=('headers','footers','quotes'))\ny_train3,y_test3=train.target,test.target\nvectorizer=TfidfVectorizer(sublinear_tf=True,max_df=.5,\n                           stop_words='english')\nx_train3=vectorizer.fit_transform(train.data) \nx_test3=vectorizer.transform(test.data)\ndel train,test\nx_test3,x_valid3,y_test3,y_valid3=\\\ntrain_test_split(x_test3,y_test3,\n                 test_size=.5,random_state=1)\nprint(x_train3.shape,x_valid3.shape,x_test3.shape)\nprint('Label: ',y_train3[1]) \nprint('Sequence of word indexes: \\n',x_train3[1])","391cc8c6":"# 13 attributes of houses at different locations, \n# targets are the median values of the houses at a location (in k$)\n(x_train4,y_train4),(x_test4,y_test4)=\\\nks.datasets.boston_housing.load_data()\nn=int(len(x_test4)\/2)\nx_valid4,y_valid4=x_test4[:n],y_test4[:n]\nx_test4,y_test4=x_test4[n:],y_test4[n:]\nprint(x_train4.shape,x_valid4.shape,x_test4.shape)\nprint(y_train4.shape,y_valid4.shape,y_test4.shape)\nprint('Target value: ',y_train4[1])\nprint(\"Features' values: \\n\",x_train4[1])\npl.figure(figsize=(10,3))\npl.hist(y_train4,bins=50,alpha=.7);","0d49ac8d":"# the artificial sets for classification, labeled over 2 categories \nX5,Y5=make_classification(n_samples=5000,n_features=2,\n                          n_redundant=0,n_informative=2)\nx_train5,x_test5,y_train5,y_test5=\\\ntrain_test_split(X5,Y5,test_size=.2,random_state=1)\nn=int(len(x_test5)\/2)\nx_valid5,y_valid5=x_test5[:n],y_test5[:n]\nx_test5,y_test5=x_test5[n:],y_test5[n:]\nprint(x_train5.shape,x_valid5.shape,x_test5.shape)\nprint(y_train5.shape,y_valid5.shape,y_test5.shape)\nprint('Label: ',y_train5[1])\nprint('Features: \\n',x_train5[1])\npl.figure(figsize=(10,3))\npl.scatter(X5[:,0],X5[:,1],marker='o',\n           s=5,c=Y5,cmap='tab10');","60e0ecc1":"# 150x150 grayscale face images; \n# labeled over 15 categories(persons)\nyalefaces_paths=[]; yalefaces_images=[]\nyalefaces_labels=[]; yalefaces_cut_images=[]\nfolder=\"..\/input\/yale-face-database\/data\/\"\ncascade=\"..\/input\/haarcascades\/\"+\\\n        \"haarcascade_frontalface_default.xml\"\nfor element in os.listdir(folder):\n    if element!='Readme.txt':\n        yalefaces_paths.append(os.path.join(folder,element))\nfor path in yalefaces_paths:\n    image=io.imread(path,as_gray=True)\n    yalefaces_images.append(image)\n    label=int(os.path.split(path)[1].split(\".\")[0]\\\n              .replace(\"subject\",\"\"))-1\n    yalefaces_labels.append(label)    \nface_detector=cv2.CascadeClassifier(cascade)\nfor i in range(len(yalefaces_images)):\n    image=yalefaces_images[i]\n    face=face_detector.detectMultiScale(image)\n    x,y=face[0][:2]\n    cut_image=image[y:y+150,x:x+150]\n    yalefaces_cut_images.append(cut_image)        \nyalefaces_labels=np.array(yalefaces_labels).reshape(-1,1)\nyalefaces_cut_images=np.array(yalefaces_cut_images)\/255","f71453a8":"x_train6,x_test6,y_train6,y_test6=\\\ntrain_test_split(yalefaces_cut_images,\n                 yalefaces_labels,\n                 test_size=.2,random_state=1)\n[x_train6,y_train6,x_valid6,y_valid6,x_test6,y_test6]=\\\nprepro(x_train6,y_train6,x_test6,y_test6)","22fb7b89":"# 128x128 flower color images; labeled over 10 categories\n# 189 - the train set; 21 - the test set\nfpath=\"..\/input\/flower-color-images\/flower_images\/flower_images\/\"\nflowers=pd.read_csv(fpath+\"flower_labels.csv\")\nflower_files=flowers['file']\nflower_targets=flowers['label'].values.reshape(-1,1)\ndef path_to_tensor(img_path):\n    img=kimage.load_img(fpath+img_path,\n                        target_size=(128,128))\n    x=kimage.img_to_array(img)\n    return np.expand_dims(x,axis=0)\ndef paths_to_tensor(img_paths):\n    list_of_tensors=[path_to_tensor(img_path) \n                     for img_path in tqdm(img_paths)]\n    return np.vstack(list_of_tensors)\nImageFile.LOAD_TRUNCATED_IMAGES = True                 \nflower_tensors=paths_to_tensor(flower_files)\/255;","f0ee4c1e":"x_train7,x_test7,y_train7,y_test7=\\\ntrain_test_split(flower_tensors,flower_targets,\n                 test_size=.1,random_state=1)\n[x_train7,y_train7,x_valid7,y_valid7,x_test7,y_test7]=\\\nprepro(x_train7,y_train7,x_test7,y_test7)","722d589c":"fpath2='..\/input\/classification-of-handwritten-letters\/'\nf=h5py.File(fpath2+'LetterColorImages_123.h5','r') \nkeys=list(f.keys())\nletters=u'\u0430\u0431\u0432\u0433\u0434\u0435\u0451\u0436\u0437\u0438\u0439\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u0445\u0446\u0447\u0448\u0449\u044a\u044b\u044c\u044d\u044e\u044f'\nletter_images=np.array(f[keys[1]])\/255\ntargets=np.array(f[keys[2]]).reshape(-1,1)-1\nx_train8,x_test8,y_train8,y_test8=\\\ntrain_test_split(letter_images,targets,\n                 test_size=.2,random_state=1)\ndel letter_images,targets\n[x_train8,y_train8,x_valid8,y_valid8,x_test8,y_test8]=\\\nprepro(x_train8,y_train8,x_test8,y_test8)","545c7cb2":"# One-Hot Encoding\nc_y_train1=to_categorical(y_train1,10) \nc_y_valid1=to_categorical(y_valid1,10)\nc_y_test1=to_categorical(y_test1,10)\nc_y_train2=to_categorical(y_train2,10)\nc_y_valid2=to_categorical(y_valid2,10)\nc_y_test2=to_categorical(y_test2,10)\nc_y_train3=to_categorical(y_train3,20)\nc_y_valid3=to_categorical(y_valid3,20)\nc_y_test3=to_categorical(y_test3,20)\nc_y_train6=to_categorical(y_train6,15)\nc_y_valid6=to_categorical(y_valid6,15)\nc_y_test6=to_categorical(y_test6,15)\nc_y_train7=to_categorical(y_train7,10)\nc_y_valid7=to_categorical(y_valid7,10)\nc_y_test7=to_categorical(y_test7,10)\nc_y_train8=to_categorical(y_train8,33)\nc_y_valid8=to_categorical(y_valid8,33)\nc_y_test8=to_categorical(y_test8,33)","13cf8c79":"# The basic model for binary classification\nbasic_model=Sequential([Dense(16,input_dim=2),Activation('relu'),\n                        Dense(1),Activation('sigmoid')])\nbasic_model.compile(optimizer='adam', \n                    loss='binary_crossentropy',\n                    metrics=['accuracy'])\n# Train \nbasic_model.fit(x_train5, y_train5, \n                validation_data=(x_valid5,y_valid5), \n                epochs=100,batch_size=128,verbose=0)\n# Predict classes\ny_test5_predictions=basic_model.predict_classes(x_test5)\n# Evaluate\nbasic_model.evaluate(x_test5,y_test5)","704bb37e":"pl.figure(figsize=(10,2))\npl.scatter(range(100),y_test5[:100],s=100)\npl.scatter(range(100),\n           y_test5_predictions[:100],s=25);","d5f058b1":"basic_model.input,basic_model.outputs","a3d3bf21":"basic_model.summary()","ba214ef9":"basic_model.get_config()","2d5d28dd":"basic_model.get_weights()","2fe100e4":"# Save\/reload models\n# basic_model.save('basic_model.h5')\n# basic_model=load_model('basic_model.h5')","d05a1d62":"# Save\/reload weights\n# basic_model.save_weights('basic_model_weights.h5')\n# basic_model.load_weights('basic_model_weights.h5',by_name=False)","be008e3a":"# Choose optimization\noptimizer=ks.optimizers.Nadam(lr=.005,beta_1=.99,beta_2=.9999,\n                              epsilon=None,schedule_decay=.005)\nbasic_model=Sequential([Dense(16,input_dim=2),Activation('relu'),\n                        Dense(1),Activation('sigmoid')])\nbasic_model.compile(optimizer=optimizer,\n                    loss='binary_crossentropy',\n                    metrics=['accuracy'])\nbasic_model.fit(x_train5,y_train5, \n                validation_data=(x_valid5,y_valid5), \n                epochs=100,batch_size=128,verbose=0)\nbasic_model.evaluate(x_test5,y_test5)","06c4f16b":"# Improve activation\ninp=Input(shape=(2,))\nact=ks.layers.LeakyReLU(alpha=.4)\nlay=act(Dense(16,name='encoder')(inp))\nout=Dense(1,activation='sigmoid',\n          name='decoder')(lay)\nbasic_model=Model(inputs=inp,outputs=out,name='cae')\nbasic_model.compile(optimizer=optimizer,\n                    loss='binary_crossentropy',\n                    metrics=['accuracy'])\nbasic_model.fit(x_train5, y_train5, \n                validation_data=(x_valid5,y_valid5), \n                epochs=100,batch_size=128,verbose=0)\nbasic_model.evaluate(x_test5,y_test5)","3e5ebce1":"# Use callbacks\nfw='weights.best.hdf5'\nearly_stopping=EarlyStopping(monitor='val_loss',patience=20)\ncheckpointer=ModelCheckpoint(filepath=fw,save_best_only=True)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss',\n                               patience=5,factor=.5)\nbasic_model=Model(inputs=inp,outputs=out,name='cae')\nbasic_model.compile(optimizer=optimizer,\n                    loss='binary_crossentropy',metrics=['accuracy'])\nbasic_model.fit(x_train5,y_train5,\n                validation_data=(x_valid5,y_valid5),\n                epochs=200,batch_size=128,verbose=0, \n                callbacks=[early_stopping,checkpointer,lr_reduction])\nbasic_model.load_weights(fw)\nbasic_model.evaluate(x_test5,y_test5)","6a12ceaf":"# Reshape image arrays\nx_train6=(x_train6).reshape(-1,150*150)\nx_valid6=(x_valid6).reshape(-1,150*150)\nx_test6=(x_test6).reshape(-1,150*150)","ea72d067":"# Multi-Class Classification\ndef model():\n    model=Sequential()    \n    model.add(Dense(128,activation='relu',\n                    input_shape=(150*150,)))\n    model.add(Dropout(.1))    \n    model.add(Dense(1024,activation='relu'))\n    model.add(Dropout(.1))    \n    model.add(Dense(15,activation='softmax'))\n    model.compile(optimizer='adam',\n                  loss='categorical_crossentropy',metrics=['accuracy'])\n    return model\nmodel=model()\ncheckpointer=ModelCheckpoint(filepath=fw,save_best_only=True)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss',\n                               patience=5,verbose=2,factor=.5)\nhistory=model.fit(x_train6,c_y_train6,\n                  validation_data=(x_valid6,c_y_valid6),\n                  epochs=70,batch_size=64,verbose=0,\n                  callbacks=[checkpointer,lr_reduction])\nmodel.load_weights(fw)\nmodel.evaluate(x_test6,c_y_test6)","fa5c7154":"loss_plot(history); acc_plot(history)","da1b17fb":"# Regression\ndef model():\n    model=Sequential()    \n    model.add(Dense(52,activation='relu',\n                    input_shape=(13,)))    \n    model.add(Dense(52,activation='relu'))     \n    model.add(Dense(208,activation='relu'))\n    model.add(Dense(208,activation='relu'))    \n    model.add(Dense(832,activation='relu'))    \n    model.add(Dense(1))\n    model.compile(optimizer='rmsprop',\n                  loss='mse',metrics=['mae'])     \n    return model\n\nmodel=model()\ncheckpointer=ModelCheckpoint(filepath=fw,save_best_only=True)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss',\n                               patience=5,verbose=2,factor=.5)\nhistory=model.fit(x_train4,y_train4,\n                  validation_data=(x_valid4,y_valid4),\n                  epochs=100,batch_size=16,verbose=0,\n                  callbacks=[checkpointer,lr_reduction])\nmodel.load_weights(fw)\nmodel.evaluate(x_test4,y_test4)","30458f38":"y_test4_predictions=model.predict(x_test4)\npl.figure(figsize=(10,3))\npl.plot(range(len(y_test4)),y_test4,'-o',\n        label='real data')\npl.plot(range(len(y_test4)),y_test4_predictions,'-o',\n        label='predictions');","13d330e4":"# Text Classification\ndef model():\n    model=Sequential()    \n    model.add(Dense(128,activation='relu',\n                    input_shape=(101322,)))\n    model.add(Dropout(rate=.1))    \n    model.add(Dense(1024,activation='relu'))\n    model.add(Dropout(rate=.1))    \n    model.add(Dense(20,activation='softmax'))\n    model.compile(optimizer='adam',\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model\nmodel=model()\nearly_stopping=EarlyStopping(monitor='val_loss',patience=20)\ncheckpointer=ModelCheckpoint(filepath=fw,save_best_only=True)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss',\n                               patience=5,verbose=2,factor=.8)\nhistory=model.fit(x_train3,c_y_train3,\n                  validation_data=(x_valid3,c_y_valid3),\n                  epochs=30,batch_size=128,verbose=0,\n                  callbacks=[early_stopping,checkpointer,lr_reduction])","77a27b35":"model.load_weights(fw)\ny_test3_predictions=model.predict_classes(x_test3)\npl.figure(figsize=(10,3))\npl.scatter(range(100),y_test3[:100],s=100)\npl.scatter(range(100),y_test3_predictions[:100],s=25)\nmodel.evaluate(x_test3,c_y_test3)","c8b8aa94":"# VGG-like CNN: Multi-Class Classification\ndef model():\n    model=Sequential()\n    model.add(Conv2D(32,(5,5),padding='same',\n                     input_shape=x_train8.shape[1:]))\n    model.add(Activation('relu'))\n    model.add(Conv2D(32,(5,5)))\n    model.add(Activation('relu'))    \n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(.25))\n    model.add(Conv2D(96,(5,5), padding='same'))\n    model.add(Activation('relu'))\n    model.add(Conv2D(96,(5,5)))\n    model.add(Activation('relu'))    \n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(.25))\n    model.add(GlobalMaxPooling2D())    \n    model.add(Dense(512,activation='relu'))\n    model.add(Dropout(.5))    \n    model.add(Dense(33))\n    model.add(Activation('softmax'))\n    model.compile(loss='categorical_crossentropy', \n                  optimizer='adam',metrics=['accuracy'])    \n    return model","06833caf":"model=model()\nestopping=EarlyStopping(monitor='val_loss',patience=20)\ncheckpointer=ModelCheckpoint(filepath=fw,save_best_only=True)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss',\n                               patience=5,verbose=2,factor=.8)\nhistory=model.fit(x_train8,c_y_train8,\n                  validation_data=(x_valid8,c_y_valid8),\n                  epochs=50,batch_size=256,verbose=0,\n                  callbacks=[checkpointer,lr_reduction,estopping])\nmodel.load_weights(fw)\nmodel.evaluate(x_test8,c_y_test8)","b6eb121d":"steps,epochs=1000,5\ndata_generator=kimage\\\n.ImageDataGenerator(zoom_range=.2,rotation_range=20)\ndg_history=\\\nmodel.fit_generator(data_generator.flow(x_train8,c_y_train8,\n                                        batch_size=256),\n                    steps_per_epoch=steps,epochs=epochs,verbose=2, \n                    validation_data=(x_valid8,c_y_valid8),\n                    callbacks=[checkpointer,lr_reduction])","60474479":"model.load_weights(fw)\nmodel.evaluate(x_test8,c_y_test8)","0b16b725":"# CNN: Regression\ndef model():\n    model=Sequential()    \n    model.add(Conv1D(52,5,padding='valid',\n                     activation='relu',input_shape=(13,1)))\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(Dropout(.2))\n    model.add(Conv1D(208,3,padding='valid',\n                     activation='relu'))\n    model.add(MaxPooling1D(pool_size=2))\n    model.add(Dropout(.2))    \n    model.add(Flatten())\n    model.add(Dense(1024,kernel_initializer='normal',\n                    activation='relu'))\n    model.add(Dropout(.4))\n    model.add(Dense(1, kernel_initializer='normal'))    \n    model.compile(loss='mse',optimizer='rmsprop',\n                  metrics=['mae'])\n    return model    ","b48f3aeb":"model=model()\nestopping=EarlyStopping(monitor='val_loss',patience=20)\ncheckpointer=ModelCheckpoint(filepath=fw,save_best_only=True)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss',\n                               patience=5,verbose=2,factor=.95)\nhistory=model.fit(x_train4.reshape(-1,13,1),y_train4, \n                  validation_data=(x_valid4.reshape(-1,13,1),\n                                   y_valid4),\n                    epochs=300,batch_size=16,verbose=0,\n                    callbacks=[checkpointer,lr_reduction,estopping])\nmodel.load_weights(fw)\nmodel.evaluate(x_test4.reshape(-1,13,1),y_test4)","05131390":"y_test4_predictions=\\\nmodel.predict(x_test4.reshape(-1,13,1))\npl.figure(figsize=(10,3))\npl.plot(range(len(y_test4)),y_test4,'-o',\n        label='real data')\npl.plot(range(len(y_test4)),\n        y_test4_predictions,'-o',\n        label='predictions')\npl.legend();","2ac8807c":"# RNN: Multi-Class Classification\ndef model():\n    model=Sequential()\n    model.add(LSTM(112,return_sequences=True,\n                   input_shape=(1,784)))    \n    model.add(LSTM(112,return_sequences=True)) \n    model.add(LSTM(112))      \n    model.add(Dense(10,activation='softmax'))\n    model.compile(loss='categorical_crossentropy',\n                  optimizer='nadam',metrics=['accuracy'])    \n    return model ","c31e13fe":"model=model()\nestopping=EarlyStopping(monitor='val_loss',patience=20)\ncheckpointer=ModelCheckpoint(filepath=fw,save_best_only=True)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss',\n                               patience=5,verbose=2,factor=.5)\nhistory=model.fit(x_train2.reshape(-1,1,784),c_y_train2, \n                  validation_data=(x_valid2.reshape(-1,1,784),\n                                   c_y_valid2),\n                  epochs=10,batch_size=128,verbose=0,\n                  callbacks=[checkpointer,lr_reduction,estopping])\nmodel.load_weights(fw)\nmodel.evaluate(x_test2.reshape(-1,1,784),c_y_test2)","d743cf79":"# RNN: Regression\ndef model():\n    model=Sequential()    \n    model.add(LSTM(52,return_sequences=True,\n                   input_shape=(1,13)))\n    model.add(LSTM(208,return_sequences=False))       \n    model.add(Dense(1))\n    model.compile(optimizer='rmsprop',\n                  loss='mse',metrics=['mae'])  \n    return model ","e47be2b4":"model=model()\nestopping=EarlyStopping(monitor='val_loss',patience=20)\ncheckpointer=ModelCheckpoint(filepath=fw,save_best_only=True)\nlr_reduction=ReduceLROnPlateau(monitor='val_loss',\n                               patience=5,verbose=2,factor=.95)\nhistory=model.fit(x_train4.reshape(-1,1,13),y_train4, \n                  validation_data=(x_valid4.reshape(-1,1,13),\n                                   y_valid4),\n                  epochs=400,batch_size=16,verbose=0,\n                  callbacks=[checkpointer,estopping,lr_reduction])\nmodel.load_weights(fw)\nmodel.evaluate(x_test4.reshape(-1,1,13),y_test4)","ea24c05f":"y_test4_predictions=\\\nmodel.predict(x_test4.reshape(-1,1,13))\npl.figure(figsize=(10,3))\npl.plot(range(len(y_test4)),y_test4,'-o',\n        label='real data')\npl.plot(range(len(y_test4)),y_test4_predictions,\n        '-o',label='predictions')\npl.legend();","e841b375":"# ResNet50\nfn = '..\/input\/resnet50\/'+\\\n'resnet50_weights_tf_dim_ordering_tf_kernels.h5'\nresnet50_model=ks.applications.resnet50\\\n.ResNet50(weights=fn)","811059ec":"fn2='..\/input\/image-examples-for-mixed-styles\/cat.png'\nfn3='..\/input\/resnet50\/imagenet_class_index.json'\ncat_image=kimage.load_img(fn2,target_size=(224,224))\nCLASS_INDEX=None\ndef decode_predictions(preds,fpath,top=5):\n    global CLASS_INDEX\n    if len(preds.shape)!=2 or preds.shape[1]!=1000:\n        raise ValueError('`decode_predictions` expects '\n                         'a batch of predictions '\n                         '(i.e. a 2D array of shape (samples, 1000)). '\n                         'Found array with shape: '+str(preds.shape))\n    if CLASS_INDEX is None:\n        CLASS_INDEX=json.load(open(fpath))\n    results=[]\n    for pred in preds:\n        top_indices=pred.argsort()[-top:][::-1]\n        result=[tuple(CLASS_INDEX[str(i)])+(pred[i],) \n                for i in top_indices]\n        results.append(result)\n    return results","42906602":"x=kimage.img_to_array(cat_image)\nx=np.expand_dims(x,axis=0)\nx=ks.applications.resnet50.preprocess_input(x)\ncat_predictions=resnet50_model.predict(x)\nprint('Predictions:\\n',\n      decode_predictions(cat_predictions,fn3)[0])\ncv_cat_image=cv2.imread(fn2)\nrgb_cat_image=\\\ncv2.cvtColor(cv_cat_image,cv2.COLOR_BGR2RGB)\npl.imshow(rgb_cat_image);","870bed9e":"# InceptionV3\nfn='..\/input\/keras-applications-weights\/'+\\\n'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\niv3_base_model=\\\nks.applications.InceptionV3(weights=fn,\n                            include_top=False)\nx=iv3_base_model.output\nx=GlobalAveragePooling2D()(x)\nx=Dense(512,activation='relu')(x)\ny=Dense(10,activation='softmax')(x)\niv3_model=Model(inputs=iv3_base_model.input,\n                outputs=y)","5e513508":"# Freeze InceptionV3 convolutional layers\nfor layer in iv3_base_model.layers:\n    layer.trainable =False\niv3_model.compile(optimizer='adam',\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])    ","84d4c736":"# Train\nsteps,epochs=189,10\ndata_generator=kimage\\\n.ImageDataGenerator(shear_range=.2,zoom_range=.2,\n                    horizontal_flip=True)\ncheckpointer=\\\nModelCheckpoint(filepath=fw,verbose=2,\n                save_best_only=True)\nlr_reduction=\\\nReduceLROnPlateau(monitor='val_loss',\n                  patience=5,verbose=2,factor=.5)\nhistory=iv3_model.fit_generator(data_generator\\\n.flow(x_train7,c_y_train7,batch_size=64),\\\nsteps_per_epoch=steps,epochs=epochs,\\\ncallbacks=[checkpointer,lr_reduction],\\\nvalidation_data=(x_valid7,c_y_valid7))","cc9a9044":"# Unfreeze InceptionV3 convolutional layers\nfor layer in iv3_model.layers[:173]:\n    layer.trainable=False\nfor layer in iv3_model.layers[173:]:\n    layer.trainable=True\niv3_model.compile(optimizer='adam',\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])  ","d3c7ac94":"# Train\nhistory=iv3_model.fit_generator(data_generator\\\n.flow(x_train7,c_y_train7,batch_size=64),\\\nsteps_per_epoch=steps,epochs=epochs,\\\ncallbacks=[checkpointer,lr_reduction],\\\nvalidation_data=(x_valid7,c_y_valid7))","eca38c99":"# Evaluate \niv3_model.load_weights(fw)\niv3_test_scores=\\\niv3_model.evaluate(x_test7,c_y_test7)\nprint(\"Accuracy: %.2f%%\"%(iv3_test_scores[1]*100))","4a35df5f":"<h1 style=\"color:#ff603b; font-family:Ewert; font-size:120%;\" class=\"font-effect-3d\">Backend<\/h1>","dc8c6a69":"<h1 style=\"color:#ff603b; font-family:Ewert; font-size:120%;\" class=\"font-effect-3d\">Code Library, Style, & Links<\/h1>\n\n[Google Colaboratory Version](https:\/\/colab.research.google.com\/drive\/16Xh8T4fPuk0AIBjnCo7e9WTrF1PgukoF)","e19e83e4":"<h1 style=\"color:#ff603b; font-family:Ewert; font-size:120%;\" class=\"font-effect-3d\">Convolutional Neural Networks<\/h1>","b6e71c05":"<h1 style=\"color:#ff603b; font-family:Ewert; font-size:120%;\" class=\"font-effect-3d\">Multi-Layer Perceptrons<\/h1>","52ca420a":"<h1 style=\"color:#ff603b; font-family:Ewert; font-size:120%;\" class=\"font-effect-3d\">Preprocessing<\/h1>","7fe6d507":"<h2>external datasets<\/h2>","4db58586":"<h1 style=\"color:#ff603b; font-family:Ewert; font-size:120%;\" class=\"font-effect-3d\">Basic Examples<\/h1>","87c81b66":"<h1 style=\"color:#ff603b; font-family:Ewert; font-size:120%;\" class=\"font-effect-3d\">Data<\/h1>\n<h2>internal datasets<\/h2>\nvariants: cifar10, cifar100, imdb, reuters, mnist, fashion_mnist, boston_housing","a336598e":"<h1 style=\"color:#ff603b; font-family:Ewert; font-size:120%;\" class=\"font-effect-3d\">Recurrent Neural Networks<\/h1>","67bd7439":"<h2>artificial datasets<\/h2>","12b8a049":"<h1 style=\"color:#ff603b; font-family:Ewert; font-size:120%;\" class=\"font-effect-3d\">Applications<\/h1>"}}