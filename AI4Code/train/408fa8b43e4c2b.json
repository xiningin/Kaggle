{"cell_type":{"160be480":"code","ad14f4a7":"code","69bc8492":"code","ada910a6":"code","e7b91324":"code","50a4da88":"code","a311ed35":"code","974e13d1":"code","f71c2398":"code","41affffe":"code","f58a46eb":"code","d775344a":"code","18adf89e":"code","48f7916f":"code","453e1f82":"code","1e5c6d85":"code","70eb2666":"code","1ece3909":"code","1e338ee0":"markdown","04eb9ffb":"markdown","febb179a":"markdown","ff96b9bd":"markdown","271861a9":"markdown"},"source":{"160be480":"# Load Libraries","ad14f4a7":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split # Import train_test_split function\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\nfrom sklearn import metrics #Import scikit-learn metrics module for accuracy calculation","69bc8492":"col_name= ['Class', 'Left-Weight', 'Left-Distance', 'Right-Weight', 'Right-Distance']\n","ada910a6":"# load the datafiles\nbalance = pd.read_csv(\"..\/input\/balance1\/balance.csv\",header=None, names=col_name)\n","e7b91324":"balance.head()","50a4da88":"# first Describe the missing value in dataset\nbalance.isna().sum()","a311ed35":"balance_data=balance.iloc[:,1:4].values\ntarget=balance.iloc[:,0].values","974e13d1":"from sklearn import preprocessing\n#creating labelEncoder\nle = preprocessing.LabelEncoder()\n\n# Converting string labels into numbers.\ny=le.fit_transform(target)","f71c2398":"# second Describe the Standardization Dataset\nfrom sklearn import preprocessing\n  \nmin_max_scaler = preprocessing.MinMaxScaler(feature_range =(0, 1))\n  \nbalance_after_min_max_scaler = min_max_scaler.fit_transform(balance_data)\n  \nprint (\"\\nAfter min max Scaling : \\n\", balance_after_min_max_scaler)\n  \nStandardisation = preprocessing.StandardScaler()\n  \nb_after_Standardisation = Standardisation.fit_transform(balance_data)\n  \nprint (\"\\nAfter Standardisation : \\n\", b_after_Standardisation)","41affffe":"#split dataset in features and target variable\nfeature_cols = ['Left-Weight', 'Left-Distance', 'Right-Weight', 'Right-Distance']\nX = balance[feature_cols] # Features\nY = balance.Class # Target variable","f58a46eb":"# Split dataset into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)","d775344a":"clf = DecisionTreeClassifier(criterion = \"entropy\", max_depth=2, min_samples_leaf=5)\n\n# Train Decision Tree Classifer\nclf = clf.fit(X_train,y_train)","18adf89e":"#Predict the response for train dataset\ny_pred_train = clf.predict(X_train)\n\n#Predict the response for test dataset\ny_pred = clf.predict(X_test)\n","48f7916f":"# Model Train Accuracy, how often is the classifier correct?\nprint(\"Train Accuracy:\",metrics.accuracy_score(y_train, y_pred_train))\n# Model Test Accuracy, how often is the classifier correct?\nprint(\"Test Accuracy:\",metrics.accuracy_score(y_test, y_pred))","453e1f82":"import graphviz\nfrom sklearn import tree\n# DOT data\ndot_data = tree.export_graphviz(clf, out_file=None,feature_names=feature_cols,class_names=['true' , 'false','something_else'],filled=True)\n\n# Draw graph\ngraph = graphviz.Source(dot_data, format=\"png\") \ngraph","1e5c6d85":"clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", max_depth=2, min_samples_leaf=5)\nclf_entropy = clf_entropy.fit(X_train,y_train)","70eb2666":"#Predict the response for train dataset\ny_pred_train = clf_entropy.predict(X_train)\n\n#Predict the response for test dataset\ny_pred = clf_entropy.predict(X_test)","1ece3909":"# Model Train Accuracy, how often is the classifier correct?\nprint(\"Train Accuracy:\",metrics.accuracy_score(y_train, y_pred_train))\n\n# Model Test Accuracy, how often is the classifier correct?\nprint(\"Test Accuracy:\",metrics.accuracy_score(y_test, y_pred))","1e338ee0":"# Access the quality of your classification model.","04eb9ffb":"# Spit the dataset into Train and Test dataset, respectively.","febb179a":"# Use preprocessing methods to clean the dataset.","ff96b9bd":"# Use train dataset to create a Decision tree model","271861a9":"#  Use train and test set for making predictions"}}