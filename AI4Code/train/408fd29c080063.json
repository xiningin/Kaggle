{"cell_type":{"cd2795bd":"code","21b74eb9":"code","99c0048f":"code","b7e63604":"code","38f39662":"code","e2961746":"code","951a4ebe":"code","9a89ade5":"code","3bf65214":"code","5d40bd84":"code","7a596ac2":"code","c0ffe77b":"code","6e1b0128":"code","5943981f":"code","f8a833fc":"code","71fb07f8":"code","9403aeda":"code","f4518f49":"code","1560a8f4":"code","b6a7e5ee":"code","afc5c375":"code","f36c30c5":"code","e0df3e90":"code","396a5559":"code","c2d545c7":"code","85de08e0":"code","76b7a01f":"code","b389da57":"code","4b682bc2":"code","55563875":"code","f29549cb":"code","0f0edfab":"code","a5b49091":"code","aff1d413":"code","cffb476b":"code","b1925de1":"markdown"},"source":{"cd2795bd":"# dependencies\nimport os, math, time, random\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n \nimport cv2\nfrom glob import glob\nimport tensorflow as tf\nfrom sklearn.utils import shuffle\n\n # skimage\nfrom skimage.io import imread \nfrom skimage import io\nfrom skimage.color import rgb2gray\nfrom skimage.transform import resize\nfrom skimage import data, color\n\n# pil\nfrom PIL import Image as pil_image\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# from keras\nimport keras\nfrom keras.utils import np_utils\nfrom keras import optimizers\nfrom keras.models import Sequential\nfrom keras.layers import  MaxPooling2D, BatchNormalization, Flatten\nfrom keras.layers import Input, Conv2D, Activation,  MaxPool2D, AveragePooling2D\nfrom keras.layers import GlobalAveragePooling2D, Dense, Dropout, GlobalMaxPooling2D\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.layers.merge import add\nfrom keras.activations import relu, sigmoid\nfrom keras import regularizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.nasnet import NASNetMobile\nfrom keras.applications.vgg16 import VGG16\nfrom keras.layers import Concatenate\nfrom keras.models import Model\nfrom keras.optimizers import Adam\n#from keras.applications.resnet import ResNet101\n\n# scikit learn helper functions\nfrom sklearn.model_selection import train_test_split","21b74eb9":"IMG_SIZE = 32 # in the given original size","99c0048f":"print('Given files: ', os.listdir('..\/input\/'))\n# data shapes\nprint('train images: ', len(os.listdir('..\/input\/train\/train')))\nprint('test images: ', len(os.listdir('..\/input\/test\/test')))\n\n# folders\ntrain_folder = '..\/input\/train\/train'\ntest_folder = '..\/input\/test\/test'\ntrain_df = pd.read_csv('..\/input\/train.csv')","b7e63604":"train_images_path = glob('..\/input\/train\/train\/*.jpg')\ntest_images_path = glob('..\/input\/test\/test\/*.jpg')","38f39662":"# retunrs a complete path to a image with Image name\ndef expand_path(path):\n    if os.path.isfile('..\/input\/train\/train\/' + path):\n        return '..\/input\/train\/train\/' + path\n    if os.path.isfile('..\/input\/test\/test\/' + path):\n        return '..\/input\/test\/test\/' + path\n    return path\n\n# returns a resized black and white PIL Image object\ndef pil_image_load(image):\n    image_path = expand_path(image)\n    image = pil_image.open(image_path)#.convert('L')\n    return image.resize((IMG_SIZE, IMG_SIZE))\n    #return image\n    \n# load the resized image\ndef read_image(img_path, resized_shape=None):\n    # expanding img_path to complete image path\n    img_path = expand_path(img_path)\n    image = imread(img_path)\n    gray_image = color.rgb2gray(image)\n    rgb_image = color.gray2rgb(gray_image)\n    if resized_shape:\n        image_resized = resize(rgb_image,(resized_shape,resized_shape, 3))\n        return image_resized[:,:]\/255\n    return rgb_image[:,:]\/255","e2961746":"# train data dataframe\ntrain_df['image'] = train_df['id'].apply(lambda path: read_image(path))\n\n# creating test dataframe\ntest_df = pd.DataFrame(columns=[\"id\", \"image\"])\ntest_df['id'] = os.listdir('..\/input\/test\/test\/')\ntest_df['image'] = test_df['id'].apply(lambda path: read_image(path))","951a4ebe":"# some visualizations \nrandom.shuffle(train_images_path)\nfig, ax = plt.subplots(2,5, figsize=(15,6))\nfig.suptitle('Some aerial images',fontsize=16)\n\ndf = shuffle(train_df)\nfor i, item in enumerate(df.values[15:20]):\n    image = pil_image.open(expand_path(item[0]))\n    ax[0,i].imshow(image)\n    ax[0, i].set_title('Has Cactus = %d' % (item[1]))\nax[0,0].set_ylabel('train images', size='large')\n\nfor i, path in enumerate(test_images_path[:5]):\n    image = pil_image.open(path)\n    #image = image.resize((IMG_SIZE, IMG_SIZE))\n    ax[1,i].imshow(image)\nax[1,0].set_ylabel('test images', size='large');","9a89ade5":"# CNN model\ndef CNN():\n    model = Sequential()\n    model.add(Conv2D(128, (3, 3), strides = (1, 1), input_shape = (IMG_SIZE, IMG_SIZE, 3)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D((2, 2)))\n    \n    model.add(Conv2D(256, (3, 3), strides = (1,1)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D((2, 2)))\n\n    model.add(Conv2D(128, (3, 3), strides = (1,1)))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D((2, 2)))\n    \n    # fully connected layer\n    model.add(Flatten())\n    model.add(Dense(512,activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(256,activation='relu'))\n    model.add(Dropout(0.25))\n    \n    # output\n    model.add(Dense(1, activation='sigmoid'))\n    \n    # compiling\n    model.compile(loss='binary_crossentropy', optimizer=optimizers.rmsprop(), metrics=['accuracy'])\n    return model","3bf65214":"# Ref: https:\/\/www.kaggle.com\/CVxTz\/cnn-starter-nasnet-mobile-0-9709-lb\ndef NASNetMoibleClassifier():\n    inputs = Input((IMG_SIZE, IMG_SIZE, 3))\n    base_model = NASNetMobile(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))#, weights=None\n    x = base_model(inputs)\n    \n    out1 = GlobalMaxPooling2D()(x)\n    out2 = GlobalAveragePooling2D()(x)\n    out3 = Flatten()(x)\n    \n    out = Concatenate(axis=-1)([out1, out2, out3])\n    out = Dropout(0.5)(out)\n    out = Dense(1, activation=\"softmax\")(out)\n    \n    model = Model(inputs, out)\n    model.compile(optimizer=Adam(0.0001), loss='binary_crossentropy', metrics=['acc'])\n    model.summary()\n    return model","5d40bd84":"# Ref: https:\/\/www.kaggle.com\/CVxTz\/cnn-starter-nasnet-mobile-0-9709-lb\ndef VGGModel():\n    model_vg = VGG16(weights='imagenet',include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n    #model_vg.trainable = False\n    \n    model = Sequential()\n    model.add(model_vg)\n    model.add(Flatten())\n    model.add(Dense(256))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1))\n    model.add(Activation('sigmoid'))\n    \n    model.compile(optimizer=Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n    model.summary()\n    return model","7a596ac2":"# returns a batch of image for training\ndef train_batch(train_df):\n    batch_size = train_df.shape[0]\n    images = train_df.image.values\n    first_image = images[0]\n    x_train = []\n    y_train = train_df.has_cactus.values\n    for i, image in enumerate(images):\n        x_train.append(image.tolist())\n    x_train = np.array(x_train)\n    y_train = y_train.reshape(len(y_train), 1)\n    return x_train, y_train","c0ffe77b":"# model = CNN()\n# model.summary()","6e1b0128":"# training data\n# X_train, y_train = train_batch(train_df)","5943981f":" # batch train (with batch load) the model with training data\ndef train_model(model, X_train, y_train, epochs=5, verbose=None):\n    begin = time.time()\n    # checkpoint\n    checkpointer = ModelCheckpoint(filepath='weights.hdf5', monitor='val_acc', verbose=0, save_best_only=True)\n    early_stopping = EarlyStopping(monitor='val_acc', verbose=1, patience=5)\n    for i in range(1, epochs + 1):\n        #print('************************************')\n        #print('Epoch: ', i, '\/', epochs)\n        #print('************************************')\n        if verbose:\n            verbose = verbose\n        # fitting\n        model.fit(X_train, y_train, verbose=verbose, callbacks=[checkpointer, early_stopping], validation_split=0.1, shuffle=True)     \n    # done!\n    elapsed = time.time() - begin\n    print('total training time: ', elapsed)\n    return model\n\n# training\n# md = train_model(model, X_train, y_train, epochs=30, verbose=1);","f8a833fc":"# Test prediction data preparation\n# test_images = []\n# for image in test_df.image.values:\n#     test_images.append(image)\n# X_test = np.array(test_images)\n\n# # prediction on test data\n# y_pred = md.predict(X_test)\n# y_test = (y_pred.flatten() > 0.5).astype('int8')\n\n# # submission file preparation\n# submission=pd.DataFrame({'id':test_df['id']})\n# submission['has_cactus']=y_test\n\n# # submitting the results\n# submission.to_csv(\"submission.csv\",index=False)","71fb07f8":"%reload_ext autoreload\n%autoreload 2","9403aeda":"from fastai.vision import *\nfrom fastai.metrics import error_rate","f4518f49":"bs = 64","1560a8f4":"path = Path(\"..\/input\")\ntfms = get_transforms(do_flip=True, flip_vert=True, max_rotate=10.0, max_zoom=1.1, max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75)","b6a7e5ee":"train_df = pd.read_csv(\"..\/input\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/sample_submission.csv\")","afc5c375":"np.random.seed(2000)\ndata = (ImageList.from_df(train_df, path=path\/'train', folder='train')\n        .split_by_rand_pct(0.01)\n        .label_from_df()\n        .transform(tfms, size=128)\n        .databunch(path='.', bs=bs, device= torch.device('cuda:0'))\n       ).normalize(imagenet_stats)","f36c30c5":"learn = cnn_learner(data, models.densenet161, metrics=error_rate)","e0df3e90":"learn.lr_find()\nlearn.recorder.plot()","396a5559":"# learning rate from graph\nlr = 0.003\nlearn.fit_one_cycle(5, slice(lr, 0.05))","c2d545c7":"learn.recorder.plot_losses()","85de08e0":"learn.unfreeze()","76b7a01f":"learn.lr_find()","b389da57":"#learn.recorder.plot()","4b682bc2":"learn.fit_one_cycle(10, max_lr=slice(1e-6))","55563875":"learn.recorder.plot_losses()","f29549cb":"# test prediction","0f0edfab":"test_data = ImageList.from_df(test_df, path=path\/'test', folder='test')\ndata.add_test(test_data)","a5b49091":"preds, _ = learn.get_preds(ds_type=DatasetType.Test)\ntest_df.has_cactus = preds.numpy()[:, 0]","aff1d413":"test_df.head()","cffb476b":"test_df.to_csv(\"submission.csv\", index=False)","b1925de1":"# With fast.ai"}}