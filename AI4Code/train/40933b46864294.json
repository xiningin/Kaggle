{"cell_type":{"9b8429d9":"code","f14ad0a2":"code","01ced98e":"code","140d0767":"code","51f869cf":"code","d7fc4993":"code","e9c67c1e":"code","9105f062":"code","04f88be5":"code","c78d02ef":"markdown"},"source":{"9b8429d9":"repo = \"FairMOT\"\n%cd \"\/kaggle\/working\"\n!rm -rf {repo}\n!git clone https:\/\/github.com\/ptran1203\/{repo}\n%cd {repo}\n!pip install -r requirements.txt\n\n%cd src\/lib\/model\/networks\/\n!rm -rf DCNv2\n!git clone https:\/\/github.com\/ifzhang\/DCNv2\/\n%cd DCNv2\n!git checkout \"pytorch_1.7\"\n!.\/make.sh\n!pip install gdown\n%cd \/kaggle\/working\/{repo}","f14ad0a2":"import torch\nprint(torch.__version__)\nif torch.cuda.is_available():\n    print(torch.cuda.get_device_name())\nimport numpy as np\nimport seaborn as sns\nimport sys\nimport os\nimport json\nimport os.path as osp\nfrom glob import glob\nimport pandas as pd\nfrom sklearn.model_selection import GroupKFold\nSRC_DIR = '\/kaggle\/input\/nfl-data\/dataset'\nIMG_DIR = f'{SRC_DIR}\/images'\n","01ced98e":"## Split data\ntest_videos = ['58094_000423_Endzone.mp4', '57586_000540_Sideline.mp4', '57586_000540_Endzone.mp4',\n        '57584_000336_Endzone.mp4', '57584_000336_Sideline.mp4', '58093_001923_Sideline.mp4', '57911_000147_Sideline.mp4',\n        '57778_004244_Sideline.mp4', '57586_004152_Endzone.mp4', '58106_002918_Sideline.mp4']\n\ngkfold = GroupKFold(n_splits=4)\nimgs = os.listdir(IMG_DIR)  # not sort yet\nimg_df = pd.DataFrame(imgs, columns=['image'])\nimg_df['video'] = img_df.image.apply(lambda x: x.split('.mp4')[0] + '.mp4')\nimg_df['frame'] = img_df.image.apply(lambda x: x.split('.mp4_')[1].split('.')[0]).astype('int64')\nimg_df['group'] = img_df.groupby('video').ngroup()\n\nprint('Videos', len(img_df['video'].unique()))\nimg_df = img_df.sort_values(['video', 'frame'])\ndum = np.zeros(len(img_df))\nfor i, (train_index, test_index) in enumerate(gkfold.split(img_df,  img_df['group'], img_df['group'])):\n    split = 'val' if i == 0 else 'train'\n    img_df.loc[test_index, 'subset'] = split\n\nimg_df.loc[img_df.video.isin(test_videos), 'subset'] = 'val'\ntrains = img_df[img_df.subset == \"train\"]\nvals = img_df[img_df.subset == \"val\"]\n# img_df = img_df.sample(frac=0.1)\nprint(f'Train on {len(trains)}, valid on {len(vals)}')\nimg_df.query('subset == \"train\"').head()","140d0767":"# Step 1. Generate files containing image paths and save to src\/data\ntrain_file = 'src\/data\/nfl.train'\ntest_file = 'src\/data\/nfl.val'\n\nwith open(train_file, 'w') as f:\n    f.write(\"\\n\".join(img_df.query('subset == \"train\"').image.values))\nwith open(test_file, 'w') as f:\n    f.write(\"\\n\".join(img_df.query('subset == \"val\"').image.values))\n\n# Step 2. Create a json file for the dataset in src\/lib\/cfg\/\ncfg = dict(\n    root=IMG_DIR,\n    train=dict(nfl=train_file),\n    test=dict(nfl=test_file),\n    test_emb=dict(nfl=test_file),\n)\nwith open('src\/lib\/cfg\/nfl_data.json', 'w') as f:\n    json.dump(cfg, f, indent=4)","51f869cf":"# Download pre-trained weight to continue training\n!gdown https:\/\/drive.google.com\/u\/0\/uc?id=1ujB57OSV4r0SxwgDwrwylNHvbceTxRsW","d7fc4993":"!python src\/train.py mot --data_cfg \"src\/lib\/cfg\/nfl_data.json\" --gpus 0\\\n                        --arch resdcn_34\\\n                        --load_model \/kaggle\/working\/FairMOT\/model_last.pth\\\n                        --resume","e9c67c1e":"# Zip weight and log to download\n!rm \/kaggle\/working\/fairmot_exp_resdcn34.zip \n!zip \/kaggle\/working\/fairmot_exp_resdcn34.zip exp\/mot\/default\/model_last.pth exp\/mot\/default\/logs_*\/log.txt\n!du -sh \/kaggle\/working\/fairmot_exp_resdcn34.zip ","9105f062":" !python src\/demo.py mot --load_model \/kaggle\/working\/FairMOT\/model_last.pth\\\n                        --input-video \"\/kaggle\/input\/nfl-health-and-safety-helmet-assignment\/train\/57584_000336_Endzone.mp4\"","04f88be5":"!zip -r \/kaggle\/working\/demos.zip \/kaggle\/working\/demos\/*","c78d02ef":"## Create data config"}}