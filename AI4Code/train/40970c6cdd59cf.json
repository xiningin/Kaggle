{"cell_type":{"27f8fd03":"code","64716cec":"code","8df218ff":"code","117848eb":"code","054ffcca":"code","77d493a4":"code","3093d2be":"code","12b2d3f8":"code","5fd8cfea":"code","e73cf6e9":"code","b2d55c07":"code","6834cbec":"code","26966cb8":"code","c01a37d5":"code","b2a2f795":"code","786f1c20":"code","43a2ea82":"code","8c71550c":"code","8a333d3a":"code","823eab45":"code","73f65006":"code","3d83cd34":"code","ebb01733":"code","230346f8":"code","8eeac907":"code","77a303c1":"code","1187a69e":"code","5e550013":"code","79f230e1":"code","a96c6dc4":"code","6eeb622d":"code","f523d538":"code","c1590465":"code","c5f01496":"code","3e8434fb":"code","2af76194":"code","0b04ffc8":"code","411f22b7":"code","fa2f3aab":"code","8c0a4c0d":"code","37d7f957":"code","e35d27a6":"code","b3ec9ad2":"code","7e79fa8b":"code","a5a5091f":"code","bd5290df":"code","95bc6851":"code","c582a183":"code","947a3232":"code","482b047f":"code","4d12567d":"code","4739c181":"code","73d86b10":"code","2dd9b876":"code","5e405fe5":"code","f12df054":"markdown","ff4644a0":"markdown","716fc927":"markdown","f4e42ab4":"markdown","218af14b":"markdown","fc0dec6d":"markdown","bb736408":"markdown","b7b30a76":"markdown","6cf07f85":"markdown","264ae021":"markdown","4aa3b5f9":"markdown","0b97b863":"markdown"},"source":{"27f8fd03":"import numpy as np # linear algebra\nimport pandas as pd # data processing\nimport os\nimport matplotlib.pyplot as plt # charts and graphs\nimport seaborn as sns # styling & pretty colors\nimport shutil\nimport tensorflow as tf\n\ndataset = pd.read_csv('..\/input\/PGA_Data_Historical.csv')\ndataset.info()\ndataset.head()\nprint(tf.__version__)","64716cec":"#show lots of columns and rows in pandas\npd.set_option('display.max_rows', 50)\npd.set_option('display.max_columns', 3000)\npd.set_option('display.width', 3000)","8df218ff":"# Transpose based on key value pairs\ndf = dataset.set_index(['Player Name', 'Variable', 'Season'])['Value'].unstack('Variable').reset_index()\n\nprint(\"original column count:\\t\" + str(len(dataset.columns)))\nprint(\"     new column count:\\t\" + str(len(df.columns)))\n","117848eb":"df.head()","054ffcca":"#Narrow down to the more interesting X columns. You could add others.\nKeep_Columns = ['Player Name','Season','Total Money (Official and Unofficial) - (MONEY)','3-Putt Avoidance - (%)',\n                'Average Distance to Hole After Tee Shot - (AVG)','Scrambling from the Sand - (%)',\n                'Scrambling from the Fringe - (%)','Scrambling from the Rough - (%)',\n                'Driving Accuracy Percentage - (%)','Total Distance Efficiency - (AVERAGE DISTANCE (YARDS))',\n                'Ball Speed - (AVG.)','Birdie or Better Conversion Percentage - (%)'\n               ]\nKeep_Columns \n","77d493a4":"#Drop non-numeric\ndf=df[Keep_Columns].dropna()\n#Rename the columns to something shorter\ndf.rename(columns = {'Total Money (Official and Unofficial) - (MONEY)':'Money'}, inplace = True)\ndf.rename(columns = {'3-Putt Avoidance - (%)':'ThreePutt'}, inplace = True)\ndf.rename(columns = {'Average Distance to Hole After Tee Shot - (AVG)':'AverageDistance'}, inplace = True)\ndf.rename(columns = {'Scrambling from the Sand - (%)':'ScramblingSand'}, inplace = True)\ndf.rename(columns = {'Scrambling from the Fringe - (%)':'ScramblingFringe'}, inplace=True)\ndf.rename(columns = {'Scrambling from the Rough - (%)':'ScramblingRough'}, inplace=True)\ndf.rename(columns = {'Driving Accuracy Percentage - (%)':'DrivingAccuracy'}, inplace=True)\ndf.rename(columns = {'Total Distance Efficiency - (AVERAGE DISTANCE (YARDS))':'Distance'}, inplace=True)\ndf.rename(columns = {'Ball Speed - (AVG.)':'BallSpeed'}, inplace=True)\ndf.rename(columns = {'Birdie or Better Conversion Percentage - (%)':'BirdieConversion'}, inplace=True)\n","3093d2be":"df.head()","12b2d3f8":"df.columns","5fd8cfea":"#Remove $ and commas from Money\ndf['Money']= df['Money'].str.replace('$','')\ndf['Money']= df['Money'].str.replace(',','')","e73cf6e9":"#Make all variables into numbers\nfor col in  df.columns[2:]:\n   df[col] = df[col].astype(float)\ndf","b2d55c07":"#Scale the data so that all features are of a comparable magnitude\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nFeature_Columns=['ThreePutt', 'AverageDistance', 'ScramblingSand', 'ScramblingFringe', 'ScramblingRough', 'DrivingAccuracy', 'Distance', 'BallSpeed', 'BirdieConversion']\ndf[Feature_Columns]=scaler.fit_transform(df[Feature_Columns])\ndf","6834cbec":"#check correlations with Money, to see which features are useful.  Driving accuracy seems to be not so useful. \n#The others look useful.\ndf.corr(method ='pearson') ","26966cb8":"sns.regplot(x=\"BirdieConversion\", y=\"Money\", data=df);","c01a37d5":"#Three putts are negatively correlated with Money\nsns.regplot(x=\"ThreePutt\", y=\"Money\", data=df);","b2a2f795":"sns.regplot(x=\"ScramblingFringe\", y=\"Money\", data=df);","786f1c20":"sns.regplot(x=\"ScramblingSand\", y=\"Money\", data=df);","43a2ea82":"sns.regplot(x=\"ScramblingRough\", y=\"Money\", data=df);","8c71550c":"sns.regplot(x=\"DrivingAccuracy\", y=\"Money\", data=df);","8a333d3a":"sns.regplot(x=\"BallSpeed\", y=\"Money\", data=df);","823eab45":"sns.regplot(x=\"Distance\", y=\"Money\", data=df);","73f65006":"# Imports for Linear Regression\nimport sklearn\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures","3d83cd34":"# Create a LinearRegression Object\nlreg = LinearRegression()","ebb01733":"# Drop a few columns to get the X (feature) columns\nX=df.drop(['Money','Player Name', 'Season'], axis=1)\n# Target\nY=df.Money","230346f8":"#I'm going to add some squared features and crossed features\n#This did improve the regression results vs only linear features \npoly = PolynomialFeatures(2)\nX=poly.fit_transform(X)  ","8eeac907":"X","77a303c1":"X.shape","1187a69e":"#Split into training and test sets\nX_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X,Y)","5e550013":"X_train.shape, X_test.shape, Y_train.shape, Y_test.shape","79f230e1":"lreg.fit(X_train,Y_train)","a96c6dc4":"lreg.coef_","6eeb622d":"lreg.intercept_","f523d538":"# Calculate predictions on training and test data sets\npred_train = lreg.predict(X_train)\npred_test = lreg.predict(X_test)\npred_train","c1590465":"print(\"RMSE with Y_train: %.2f\"  % np.sqrt(np.mean((Y_train - pred_train) ** 2)))\nprint(\"RMSE with Y_test: %.2f\"  % np.sqrt(np.mean((Y_test - pred_test) ** 2)))","c5f01496":"# Scatter plot the training data\ntrain = plt.scatter(pred_train,(Y_train-pred_train),c='b',alpha=0.5)\n\n# Scatter plot the testing data\ntest = plt.scatter(pred_test,(Y_test-pred_test),c='r',alpha=0.5)\n\n# Plot a horizontal axis line at 0\nplt.hlines(y=0,xmin=-10,xmax=50)\n\n#Labels\nplt.legend((train,test),('Training','Test'),loc='lower left')\nplt.title('Residual Plot')","3e8434fb":"Jason_Day=df[df['Player Name'].str.contains('Day')]\nJason_Day.Money.mean()","2af76194":"Adam_Hadwin=df[df['Player Name'].str.contains('Hadwin')]\nAdam_Hadwin.Money.mean()","0b04ffc8":"X_predict=Jason_Day.drop(['Money','Player Name', 'Season'], axis=1)\nlreg.predict(poly.fit_transform(X_predict)).mean()","411f22b7":"X_predict=Adam_Hadwin.drop(['Money','Player Name', 'Season'], axis=1)\nlreg.predict(poly.fit_transform(X_predict)).mean()","fa2f3aab":"Dustin_Johnson=df[df['Player Name'].str.contains('Dustin Johnson')]\nDustin_Johnson.Money.mean()","8c0a4c0d":"X_predict=Dustin_Johnson.drop(['Money','Player Name', 'Season'], axis=1)\nlreg.predict(poly.fit_transform(X_predict)).mean()","37d7f957":"FEATURE_NAMES=list(df.columns.drop(['Money','Player Name', 'Season']))\nFEATURE_NAMES","e35d27a6":"LABEL_NAME = 'Money'","b3ec9ad2":"# Drop a few columns to get a dataframe with the target (Money) as well as the X variables\nDNNdata=df.drop(['Player Name', 'Season'], axis=1)","7e79fa8b":"DNNdata","a5a5091f":"DNNdata.shape","bd5290df":"#I got this code from Google's Github on Tensorflow training: \n#https:\/\/github.com\/GoogleCloudPlatform\/training-data-analyst\/blob\/master\/courses\/machine_learning\/deepdive\/03_tensorflow\/b_estimator.ipynb\n\ndef make_train_input_fn(d, num_epochs):\n  return tf.estimator.inputs.pandas_input_fn(\n    x = d,\n    y = d[LABEL_NAME],\n    batch_size = 64,\n    num_epochs = num_epochs,\n    shuffle = True,\n    queue_capacity = 1000\n  )\n\ndef make_eval_input_fn(d):\n  return tf.estimator.inputs.pandas_input_fn(\n    x = d,\n    y = d[LABEL_NAME],\n    batch_size = 64,\n    shuffle = False,\n    queue_capacity = 1000\n  )\n\ndef make_prediction_input_fn(d):\n  return tf.estimator.inputs.pandas_input_fn(\n    x = d,\n    y = None,\n    batch_size = 128,\n    shuffle = False,\n    queue_capacity = 1000\n  )\n\ndef make_feature_cols():\n  input_columns = [tf.feature_column.numeric_column(k) for k in FEATURE_NAMES]\n  return input_columns\n\n","95bc6851":"DATASET_SIZE = DNNdata.shape[0]\nDATASET_SIZE","c582a183":"#Divide into train and test sets\nDATASET_SIZE = DNNdata.shape[0]\n\ntrain_df=DNNdata.sample(frac=0.8,random_state=200)\ntest_df=DNNdata.drop(train_df.index)","947a3232":"train_df.shape[0], test_df.shape[0]","482b047f":"OUTDIR = \"Golf_Training\"\n\ntf.logging.set_verbosity(tf.logging.INFO)\n\nshutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n\nmodel = tf.estimator.DNNRegressor(hidden_units = [16,8],\n      feature_columns = make_feature_cols(), model_dir = OUTDIR)","4d12567d":"model.train(input_fn = make_train_input_fn(train_df, num_epochs = 500))","4739c181":"def print_rmse(model, d):\n  metrics = model.evaluate(input_fn = make_eval_input_fn(df))\n  print('RMSE on dataset = {}'.format(np.sqrt(metrics['average_loss'])))\nprint_rmse(model, test_df)","73d86b10":"# Try a prediction for Jason Day\npredictions = model.predict(input_fn = make_prediction_input_fn(Jason_Day))\nfor items in predictions:\n  print(items)","2dd9b876":"predictions = model.predict(input_fn = make_prediction_input_fn(Adam_Hadwin))\nfor items in predictions:\n  print(items)","5e405fe5":"df.mean()","f12df054":"That's wierd.  We're predicting Day and Hadwin will make about the same, while Day is clearly the better golfer. \nIn fact the model seems to be predicting similar targets regardless of the inputs.","ff4644a0":"That's pretty bad.  In fact it's worse than then linear regression, above.","716fc927":"Maybe someone has some ideas how to improve the DNN results. Different hidden layers don't seem to help much. Perhaps we're limited with what we can do with that much data (approx. 1700 records), and can't train the model all that well due to that. Maybe we should try some feature engineering. I threw out a lot of features that the PGA is tracking. Maybe there's something useful in there. Some of it was going to be a bit of a pain in the ass to deal with, such as distances like 5'7\". It would take a little work to preprocess, but might improve the results. ","f4e42ab4":"Not bad for Day.  Not so great for Hadwin. We're not getting very accurate results, but at least \nwe see that the better golfer, based on the features, makes more money. Let's try one more golfer--Dustin Johnson","218af14b":"Let's try to predict their earnings for a few years.","fc0dec6d":"It looks like there's an opportunity to improve on this model.","bb736408":"Looks like the linear model didn't predict too well. We've got a large error on both the training and test data sets.","b7b30a76":"Someone on Kaggle was good enough to scrape a lot of data from the PGA Tour site, and post it for others to use.\nI wondered if there was some chance to do a sort of \"Moneyball Golf\" analysis, where we might find a few key stats\nthe people were not adequately considering, and which might tell us who might have a shot at winning a major\nin the near future. Who knows, you might even be able to profit from this by betting on some golfer \nwho has good stats but hasn't broken through to win a major yet. \n\nUnfortunately I don't think I'm going to get rich from this analysis. As you'll see, there's some correlation between some of the stats tracked by the PGA Tour and pro golf success, but I couldn't find a formula that had a great predictive ability. I haven't looked at the detailed Moneyball baseball data, but I'd expect the variety of situations a baseball player could face is much more limited than the ones a golfer could face during the course of a round of golf. So that's going to be harder to capture in the stats (for golf).","6cf07f85":"We predicted he'd make more than Hadwin. In reality he made way more than Hadwin, but also more than Day over this time. We predicted he'd only make a bit more than Day. If you look at his stats vs. Day's, some are better, but not all. ","264ae021":"Based on the above, avoiding 3-putts is big. Distance matters more than I might have expected. My guess was that Driving Accuracy would be more important that distance. Nope. Converting on your birdie opportunities is huge. Scrambling is less important that I might have thought. Ball speed surprised me by actually having a correlation with money won, but when you think about a higher ball speed should get you more distance, so it makes sense.\n\nFor future work, we'd probably want to go deeper into putting.  They have many variables I didn't use here.\nI assumed many would be correlated, but there might be some useful info in there (e.g., long putting vs. short putting?).","4aa3b5f9":"Let's take a couple of golfers. Jason Day made 4.8 million, while Adam Hadwin made 1.86 million, on average for the years they competed. Day's stats are almost all better thatn Hadwin's, but only marginally so. So it appears that small differences can make you a lot of money on the PGA tour.","0b97b863":"These predictions aren't great, although generally better golfers (statistically) seem to be making more money than ones with worse stats, based on the model. \n\nThe PGA Tour collects a lot more variables, but it looks like a lot of these would be correlated with each other (e.g., long putting, short putting, putting overall, etc.), or not that useful. \n\nMy hunch is that these variables don't explain all that well why great golfers are great. Of course they avoid 3 putts, and convert on birdies when they have the chance, and the data shows an association between earning money and these factors. But meanwhile, other variables don't seem to mean much. Driving accuracy is surprisingly useless.\n\nSo I suspect there's something that's just not captured by these stats that determines whether a golfer can win the big ones. The stats that the PGA Tour provides don't necessarily reveal that. Dealing with pressure and pulling off a big birdie at a critical moment matters a lot more than driving accuracy.\n\nLet's try a more complex model--a neural network. A challenge may be that we actually don't have a lot of data points: about 1700."}}