{"cell_type":{"43f70e08":"code","17b3341e":"code","a4a1c08a":"code","e03639d2":"code","29296c0c":"code","16bd5418":"code","24a3b519":"code","a733624d":"code","f5007a43":"code","8c1e4c1d":"code","1d7abbe2":"code","9716b823":"code","2280c110":"code","c283bbe1":"code","0e55fec2":"code","c08a80c5":"code","b879c863":"code","0040e658":"code","557cb801":"code","a5e8d561":"code","ac41f290":"code","4acc9305":"code","306ad946":"code","5a36392b":"code","708429fe":"code","0dce1959":"code","86698525":"code","4d98efed":"code","38425f3d":"code","33986c51":"code","f503a762":"code","fa8beb38":"code","5fcf0fda":"code","07979576":"code","09cc3352":"code","714ee527":"code","b5748fc8":"code","a0c415bc":"code","5c8d6ec6":"code","e8a72bce":"code","cd0c4d4e":"code","562fff8e":"code","6d729a3c":"code","89bdd586":"code","3e4d0f68":"code","dc5874b9":"code","617b97ec":"code","4a612982":"code","8846da6d":"code","42bcf48e":"code","77863168":"code","01116b76":"code","a03e5f74":"code","6b501761":"code","9c4bd27d":"code","406d3685":"code","5dc50362":"code","9ad072f8":"code","e503a49d":"code","09171b6a":"code","5ec3269e":"code","aab96f2f":"code","7652a5d7":"code","06b12e03":"code","5e6d855e":"code","1b49801c":"code","e2b88a33":"code","d4e436b5":"code","97c7514e":"code","feb2bcf6":"code","5aeacef5":"code","7162aeb1":"code","ac2dc44f":"markdown","dbdad990":"markdown","c736c1f5":"markdown","e51a40d7":"markdown","94aafe9b":"markdown","1a3dc232":"markdown","dab6c3cf":"markdown","47adc5e6":"markdown","9274a9f5":"markdown","4154ab32":"markdown","1066ff28":"markdown","6b73d348":"markdown","c0e2fca7":"markdown","eb87f11b":"markdown","3a9efd5a":"markdown","f0d0bf85":"markdown","8f8b8410":"markdown","9b5d3c61":"markdown","09e89cb3":"markdown","be2ee840":"markdown","e02fb67b":"markdown","0b8ba130":"markdown","a42e9b7d":"markdown","969148f2":"markdown","9fede894":"markdown","dc106fdd":"markdown","707f5515":"markdown","c3565068":"markdown","2fc6cb1b":"markdown","fff824aa":"markdown","a53a6920":"markdown","b8b85311":"markdown","1543cc6b":"markdown","9b3a53d4":"markdown","667d33e3":"markdown","5fad6c83":"markdown","56ed3448":"markdown","81290073":"markdown","629861d4":"markdown","47d5e0d2":"markdown","552b0cbc":"markdown","02b6ae49":"markdown","f6291f42":"markdown","c5fa9ce6":"markdown","5bbde9ae":"markdown","1a9c56c8":"markdown","d3747940":"markdown","ad792c3a":"markdown","3107635f":"markdown","20106a04":"markdown","2ad02567":"markdown","b9104a6c":"markdown","3cdad290":"markdown","9927a652":"markdown","c390d7fa":"markdown","d01c04a0":"markdown","b0ae6c7a":"markdown","b9df5f29":"markdown","6fcd4a35":"markdown","1945e491":"markdown","3c3c3995":"markdown"},"source":{"43f70e08":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\nimport plotly.graph_objs as go\nfrom collections import Counter\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBRegressor\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler,OneHotEncoder, OrdinalEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import cross_val_score\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","17b3341e":"filePath = \"\/kaggle\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\"\n\nheartData = pd.read_csv(filePath)","a4a1c08a":"heartData.head()","e03639d2":"heartData.columns","29296c0c":"heartData.dtypes","16bd5418":"len(heartData.columns)","24a3b519":"heartData.describe()","a733624d":"heartData.shape","f5007a43":"heartData.columns[heartData.isnull().any()]","8c1e4c1d":"numericCol = [col for col in heartData.columns if heartData[col].dtype in [\"int64\",\"float64\"]]\nnumericCol","1d7abbe2":"if (len(numericCol) == len(heartData.columns)):\n    print(\"Whole columns dtypes is numeric.\")","9716b823":"target = heartData[\"DEATH_EVENT\"]\nsns.distplot(target)\nplt.title(\"Distribiton of Death Event\")\nplt.show()","2280c110":"num_attributes = heartData.drop(\"DEATH_EVENT\",axis=1).copy()\n\nfig = plt.figure(figsize=(12,18))\n\nfor i in range(len(num_attributes.columns)):\n    fig.add_subplot(4,3,i+1)\n    sns.distplot(num_attributes.iloc[:,i].dropna())\n    plt.xlabel(num_attributes.columns[i])\n\nplt.show()    ","c283bbe1":"fig = plt.figure(figsize=(12,18))\n\nfor i in range(len(num_attributes.columns)):\n    fig.add_subplot(4,3,i+1)\n    sns.boxplot(num_attributes.iloc[:,i].dropna())\n    plt.xlabel(num_attributes.columns[i])\n\nplt.show()    ","0e55fec2":"fig = plt.figure(figsize=(12,18))\n\nfor i in range(len(num_attributes.columns)):\n    fig.add_subplot(4,3,i+1)\n    sns.kdeplot(num_attributes.iloc[:,i].dropna())\n    plt.xlabel(num_attributes.columns[i])\n\nplt.show()    ","c08a80c5":"correlation = heartData.corr()\nplt.figure(figsize=(12,15))\nsns.heatmap(correlation,annot=True,fmt=\".2f\")\n\nplt.show()","b879c863":"# correlation according to target column that DEATH_EVENT\n\ncorrToTarget = heartData.corr()[\"DEATH_EVENT\"].sort_values(ascending=False)\nsns.pointplot(x=corrToTarget.index,y=corrToTarget.values)\nplt.xticks(rotation=90)\nplt.title(\"Correlation Rates According to Target Column That DEATH_EVENT\")\nplt.ylabel(\"Correlation rates\")\nplt.show()","0040e658":"recover = heartData.age[heartData.DEATH_EVENT==1]\ndead = heartData.age[heartData.DEATH_EVENT==0]\n\n\ntrace1 = go.Histogram(\n    x=recover,\n    opacity=0.75,\n    name = \"1\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\n\ntrace2 = go.Histogram(\n    x=dead,\n    opacity=0.75,\n    name = \"0\",\n    marker=dict(color='rgba(12, 50, 196, 0.6)'))\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(barmode='overlay',\n                   title='patients age distribiton according to Deaths event',\n                   xaxis=dict(title='ages distribition'),\n                   yaxis=dict( title='Count'),\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","557cb801":"sns.boxplot(x=heartData.DEATH_EVENT,y=heartData.age)\nplt.xticks(rotation=45)\nplt.title(\"patients age distribiton according to age\")\nplt.show()","a5e8d561":"anaemia = heartData.anaemia.value_counts()\nanaemia.values","ac41f290":"data = {\n    \"values\" : anaemia.values,\n    \"labels\" : anaemia.index,\n    \"type\" : \"pie\",\n    \"hoverinfo\":\"label+percent\",\n    \"hole\":.3\n}\n\nlayout={\n    \"title\":\"Rates anaemia bar chart\"\n}\nfig=go.Figure(data=data,layout=layout)\niplot(fig)","4acc9305":"belongToRecover = heartData.creatinine_phosphokinase[heartData.DEATH_EVENT == 1]\nbelongToDead = heartData.creatinine_phosphokinase[heartData.DEATH_EVENT == 0]\n\ntrace1 = go.Histogram(\n    x=belongToRecover,\n    opacity=0.75,\n    name = \"1\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\n\ntrace2 = go.Histogram(\n    x=belongToDead,\n    opacity=0.75,\n    name = \"0\",\n    marker=dict(color='rgba(12, 50, 196, 0.6)'))\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(barmode='overlay',\n                   title='patients creatinine phosphokinase distribiton according to Deaths event',\n                   xaxis=dict(title='ages distribition'),\n                   yaxis=dict(title='Count'),\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","306ad946":"diabetes = heartData.diabetes.value_counts()\ndiabetes","5a36392b":"data = {\n    \"values\" : diabetes.values,\n    \"labels\" : diabetes.index,\n    \"type\" : \"pie\",\n    \"hoverinfo\":\"label+percent\",\n    \"hole\":.3\n}\n\nlayout={\n    \"title\":\"Rates diabetes bar chart\"\n}\nfig=go.Figure(data=data,layout=layout)\niplot(fig)","708429fe":"belongToRecover = heartData.ejection_fraction[heartData.DEATH_EVENT == 1]\nbelongToDead = heartData.ejection_fraction[heartData.DEATH_EVENT == 0]\n\ntrace1 = go.Histogram(\n    x=belongToRecover,\n    opacity=0.75,\n    name = \"1\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\n\ntrace2 = go.Histogram(\n    x=belongToDead,\n    opacity=0.75,\n    name = \"0\",\n    marker=dict(color='rgba(12, 50, 196, 0.6)'))\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(barmode='overlay',\n                   title='patients ejection fraction distribiton according to Deaths event',\n                   xaxis=dict(title='ages distribition'),\n                   yaxis=dict(title='Count'),\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","0dce1959":"trace1 = go.Box(\n    x = heartData.DEATH_EVENT,\n    y = heartData.ejection_fraction,\n        marker = dict(\n        color = 'rgb(12, 128, 128)',\n    )\n)\nlayout = go.Layout(title=\"ejection fraction distribiton of deaths event with box plot\")\nfig = go.Figure(data=data,layout=layout)\niplot(fig)","86698525":"bloodPressure = heartData.high_blood_pressure.value_counts()","4d98efed":"data = {\n    \"values\" : bloodPressure.values,\n    \"labels\" : bloodPressure.index,\n    \"type\" : \"pie\",\n    \"hoverinfo\":\"label+percent\",\n    \"hole\":.3\n}\n\nlayout={\n    \"title\":\"Rates high blood pressure bar chart\"\n}\nfig=go.Figure(data=data,layout=layout)\niplot(fig)","38425f3d":"belongToRecover = heartData.platelets[heartData.DEATH_EVENT == 1]\nbelongToDead = heartData.platelets[heartData.DEATH_EVENT == 0]\n\ntrace1 = go.Histogram(\n    x=belongToRecover,\n    opacity=0.75,\n    name = \"1\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\n\ntrace2 = go.Histogram(\n    x=belongToDead,\n    opacity=0.75,\n    name = \"0\",\n    marker=dict(color='rgba(12, 50, 196, 0.6)'))\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(barmode='overlay',\n                   title='patients platelets distribiton according to Deaths event',\n                   xaxis=dict(title='ages distribition'),\n                   yaxis=dict(title='Count'),\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","33986c51":"belongToRecover = heartData.serum_creatinine[heartData.DEATH_EVENT == 1]\nbelongToDead = heartData.serum_creatinine[heartData.DEATH_EVENT == 0]\n\ntrace1 = go.Histogram(\n    x=belongToRecover,\n    opacity=0.75,\n    name = \"1\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\n\ntrace2 = go.Histogram(\n    x=belongToDead,\n    opacity=0.75,\n    name = \"0\",\n    marker=dict(color='rgba(12, 50, 196, 0.6)'))\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(barmode='overlay',\n                   title='patients serum creatinine distribiton according to Deaths event',\n                   xaxis=dict(title='ages distribition'),\n                   yaxis=dict(title='Count'),\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","f503a762":"trace1 = go.Box(\n    x = heartData.DEATH_EVENT,\n    y = heartData.serum_creatinine,\n        marker = dict(\n        color = 'rgb(12, 128, 128)',\n    )\n)\nlayout = go.Layout(title=\"serum creatinine distribiton of deaths event with box plot\")\nfig = go.Figure(data=data,layout=layout)\niplot(fig)","fa8beb38":"heartData.serum_sodium","5fcf0fda":"belongToRecover = heartData.serum_sodium[heartData.DEATH_EVENT == 1]\nbelongToDead = heartData.serum_sodium[heartData.DEATH_EVENT == 0]\n\ntrace1 = go.Histogram(\n    x=belongToRecover,\n    opacity=0.75,\n    name = \"1\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\n\ntrace2 = go.Histogram(\n    x=belongToDead,\n    opacity=0.75,\n    name = \"0\",\n    marker=dict(color='rgba(12, 50, 196, 0.6)'))\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(barmode='overlay',\n                   title='patients serum sodium distribiton according to Deaths event',\n                   xaxis=dict(title='ages distribition'),\n                   yaxis=dict(title='Count'),\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","07979576":"trace1 = go.Box(\n    x = heartData.DEATH_EVENT,\n    y = heartData.serum_sodium,\n        marker = dict(\n        color = 'rgb(12, 128, 128)',\n    )\n)\nlayout = go.Layout(title=\"serum sodium distribiton of deaths event with box plot\")\nfig = go.Figure(data=data,layout=layout)\niplot(fig)","09cc3352":"sex=heartData.sex.value_counts()\n\ndata = {\n    \"values\" : sex.values,\n    \"labels\" : sex.index,\n    \"type\" : \"pie\",\n    \"hoverinfo\":\"label+percent\",\n    \"hole\":.3\n}\n\nlayout={\n    \"title\":\"Rates sex bar chart\"\n}\nfig=go.Figure(data=data,layout=layout)\niplot(fig)","714ee527":"smoke = heartData.smoking.value_counts()\n\ndata = {\n    \"values\" : smoke.values,\n    \"labels\" : smoke.index,\n    \"type\" : \"pie\",\n    \"hoverinfo\":\"label+percent\",\n    \"hole\":.3\n}\n\nlayout={\n    \"title\":\"Rates smoke bar chart\"\n}\nfig=go.Figure(data=data,layout=layout)\niplot(fig)\n","b5748fc8":"belongToRecover = heartData.time[heartData.DEATH_EVENT == 1]\nbelongToDead = heartData.time[heartData.DEATH_EVENT == 0]\n\ntrace1 = go.Histogram(\n    x=belongToRecover,\n    opacity=0.75,\n    name = \"1\",\n    marker=dict(color='rgba(171, 50, 96, 0.6)'))\n\ntrace2 = go.Histogram(\n    x=belongToDead,\n    opacity=0.75,\n    name = \"0\",\n    marker=dict(color='rgba(12, 50, 196, 0.6)'))\n\ndata = [trace1, trace2]\n\nlayout = go.Layout(barmode='overlay',\n                   title='patients time distribiton according to Deaths event',\n                   xaxis=dict(title='ages distribition'),\n                   yaxis=dict(title='Count'),\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","a0c415bc":"trace1 = go.Box(\n    x = heartData.DEATH_EVENT,\n    y = heartData.time,\n        marker = dict(\n        color = 'rgb(12, 128, 128)',\n    )\n)\nlayout = go.Layout(title=\"time distribiton of deaths event with box plot\")\nfig = go.Figure(data=data,layout=layout)\niplot(fig)","5c8d6ec6":"\n\ndeath = heartData.DEATH_EVENT.value_counts()\n\ndata = {\n    \"values\" : death.values,\n    \"labels\" : death.index,\n    \"type\" : \"pie\",\n    \"hoverinfo\":\"label+percent\",\n    \"hole\":.3\n}\n\nlayout={\n    \"title\":\"Rates death bar chart\"\n}\nfig=go.Figure(data=data,layout=layout)\niplot(fig)\n","e8a72bce":"def detectOutliers(df,features):\n    outlier_indices=[]\n    for c in features:\n        Q1=np.percentile(df[c],25)\n        Q2=np.percentile(df[c],75)\n        IQR = Q2-Q1\n        outlierStep = IQR*1.5\n        outlierListCol = df[(df[c] < Q1-outlierStep) | (df[c]>Q2+outlierStep)].index\n        outlier_indices.extend(outlierListCol)\n    outlier_indices=Counter(outlier_indices)\n    multiple_outliers=list(i for i,v in outlier_indices.items() if v>2)\n    return multiple_outliers","cd0c4d4e":"heartData.loc[detectOutliers(heartData,heartData.columns)]\n# there arent any outliers exist","562fff8e":"heartData.dropna(axis=0,subset=[\"DEATH_EVENT\"],inplace=True)\ny = heartData.DEATH_EVENT\nx = heartData.drop([\"DEATH_EVENT\"],axis=1)\nX_train,X_test,y_train,y_test = train_test_split(x,y,train_size=0.8,test_size=0.2,random_state=0)","6d729a3c":"X_train.shape","89bdd586":"X_test.shape","3e4d0f68":"x.dtypes","dc5874b9":"constant_num_cols = x.columns\n#len(constant_num_cols) 12\nmyCols = constant_num_cols","617b97ec":"X_train = X_train[myCols].copy()\nX_test = X_test[myCols].copy()\nx = heartData[myCols].copy()","4a612982":"X_train.shape","8846da6d":"X_test.shape","42bcf48e":"numerical_transform_c = Pipeline(steps = [\n    (\"imputer\",SimpleImputer(strategy=\"mean\")),\n    (\"scaler\", StandardScaler())\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num_mean\",numerical_transform_c,constant_num_cols)\n    ]\n)","77863168":"neighbours = np.arange(1,30)\ntestAccuracy = []\ntrainAccuracy = []\n\nfor i,k in enumerate(neighbours):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train,y_train)\n    trainAccuracy.append(knn.score(X_train,y_train))\n    testAccuracy.append(knn.score(X_test,y_test))\n\nplt.figure(figsize=(15,16))\nplt.plot(neighbours,testAccuracy,label=\"Test accuracy\")\nplt.plot(neighbours,trainAccuracy,label=\"Train Accuracy\")\nplt.legend()\nplt.title(\"Detect most suitable value for n_neighbours\")\nplt.xticks(neighbours)\nplt.show()","01116b76":"grid = {\"n_neighbors\" : np.arange(1,30)}\nknn = KNeighborsClassifier()\nknn_cv = GridSearchCV(knn,grid,cv=3)\nknn_cv.fit(X_train,y_train)\n\nprint(\"Tuned parameter k : {}\".format(knn_cv.best_params_))\nprint(\"Best score for Knn = {}\".format(knn_cv.best_score_))","a03e5f74":"model1 = KNeighborsClassifier(n_neighbors=11)\n\nmy_pipeline1 = Pipeline(steps = [\n    (\"preprocessor\",preprocessor),\n    (\"model\",model1)\n])\n\npreds1 = my_pipeline1.fit(X_train,y_train)\n\nprint(\"KNN algortihms score = {}\".format(my_pipeline1.score(X_test,y_test)))","6b501761":"y_pred = my_pipeline1.predict(X_test)\ny_true = y_test\ncm_1 = confusion_matrix(y_pred,y_true)\n\nf,ax = plt.subplots(figsize=(6,6))\nplt.title(\"KNN algortihms score matrix\")\nsns.heatmap(cm_1,annot=True,color=\"red\",fmt=\"0.5f\",ax=ax)\nplt.show()","9c4bd27d":"k=5\nknn_cross_validation = cross_val_score(my_pipeline1,X_train,y_train,cv=k)\n\nprint(\"CV Knn scores = {}\".format(knn_cross_validation))\nprint(\"CV Knn scores average : {}\".format(np.sum(knn_cross_validation)\/k))","406d3685":"grid = {\"max_iter\" : np.arange(50,560,50)}\nlogreg = LogisticRegression()\nlog_cv = GridSearchCV(logreg,grid,cv=3)\nlog_cv.fit(X_train,y_train)\n\nprint(\"Tuned parameter n_estimators : {}\".format(log_cv.best_params_))\nprint(\"Best score for Logistic regression = {}\".format(log_cv.best_score_))","5dc50362":"model2 = LogisticRegression(random_state=42,max_iter=150)\n\nmy_pipeline2 = Pipeline(steps = [\n    (\"preprocessor\",preprocessor),\n    (\"model\",model2)\n])\n\nmy_pipeline2.fit(X_train,y_train)\n\nprint(\"Logistic regression score = {}\".format(my_pipeline2.score(X_test,y_test)))","9ad072f8":"y_pred2 = my_pipeline2.predict(X_test)\ny_true2 = y_test\ncm_2 = confusion_matrix(y_pred2,y_true2)\n\nf,ax1 = plt.subplots(figsize=(6,6))\nplt.title(\"Logistic regression score matrix\")\nsns.heatmap(cm_2,annot=True,color=\"red\",fmt=\"0.5f\",ax=ax1)","e503a49d":"logistic_cross_val = cross_val_score(my_pipeline2,X_train,y_train,cv=k)\n\nprint(\"CV Logistic reg. scores = {}\".format(logistic_cross_val))\nprint(\"CV Logistic reg. scores average : {}\".format(np.sum(logistic_cross_val)\/k))","09171b6a":"grid = {\"n_estimators\" : np.arange(50,560,50)}\nrfc = RandomForestClassifier()\nrfc_cv = GridSearchCV(rfc,grid,cv=3)\nrfc_cv.fit(X_train,y_train)\n\nprint(\"Tuned parameter n_estimators : {}\".format(rfc_cv.best_params_))\nprint(\"Best score for random forest = {}\".format(rfc_cv.best_score_))","5ec3269e":"model3 = RandomForestClassifier(n_estimators=200,random_state=1)\nmy_pipeline3 = Pipeline(steps = [\n    (\"preprocessor\",preprocessor),\n    (\"model\",model3)\n])\n\nmy_pipeline3.fit(X_train,y_train)\nprint(\"Random Forest Classification Score = {}\".format(my_pipeline3.score(X_test,y_test)))","aab96f2f":"y_pred3 = my_pipeline3.predict(X_test)\ny_true3 = y_test\ncm_3 = confusion_matrix(y_pred3,y_true3)\n\nf,ax3 = plt.subplots(figsize=(6,6))\nsns.heatmap(cm_3,annot=True,fmt=\"0.5f\",ax=ax3)\nplt.title(\"Random Forest Classification Score Matrix\")\nplt.show()","7652a5d7":"random_forest_cross_validation = cross_val_score(my_pipeline3,X_train,y_train,cv=k)\n\nprint(\"CV Random Forest class. scores = {}\".format(random_forest_cross_validation))\nprint(\"CV Random Forest class. scores average : {}\".format(np.sum(random_forest_cross_validation)\/k))","06b12e03":"grid = {\"n_estimators\" : np.arange(100,1600,100)}\nXGbr = XGBRegressor()\nXGbr_cv = GridSearchCV(XGbr,grid,cv=3)\nXGbr_cv.fit(X_train,y_train)\n\nprint(\"Tuned parameter n_estimators : {}\".format(XGbr_cv.best_params_))\nprint(\"Best score = {}\".format(XGbr_cv.best_score_))","5e6d855e":"model4 = DecisionTreeClassifier()\nmy_pipeline4 = Pipeline(steps = [\n    (\"preprocessor\",preprocessor),\n    (\"model\",model4)\n])\n\nmy_pipeline4.fit(X_train,y_train)\nprint(\"Desicion Tree Classification Score = {}\".format(my_pipeline4.score(X_test,y_test)))","1b49801c":"y_pred4 = my_pipeline4.predict(X_test)\ny_true4 = y_test\ncm_4 = confusion_matrix(y_pred4,y_true4)\n\nf,ax4 = plt.subplots(figsize=(6,6))\nsns.heatmap(cm_4,annot=True,fmt=\"0.5f\")\nplt.title(\"Desicion Tree Classification Score matrix\")\nplt.show()","e2b88a33":"decision_tree_cross_validation = cross_val_score(my_pipeline4,X_train,y_train,cv=k)\n\nprint(\"CV Desicion Tree Classification scores = {}\".format(decision_tree_cross_validation))\nprint(\"CV Desicion Tree Classification. scores average : {}\".format(np.sum(decision_tree_cross_validation)\/k))","d4e436b5":"X_train_full,X_test_full,y_train_full,y_test_full = train_test_split(x,y,train_size=0.8,test_size=0.2,random_state=0)","97c7514e":"X_train = X_train_full.copy()\nX_test = X_test_full.copy()\ny=y_train.copy()\nX_tr = X_train[myCols].copy()\nX_te = X_test[myCols].copy()","feb2bcf6":"myFinalModel = RandomForestClassifier(n_estimators=200,random_state=1)\n\nmyFinalPipeline = Pipeline(steps = [\n    (\"preprocessor\",preprocessor),\n    (\"model\",myFinalModel)\n])\n\nmyFinalPipeline.fit(X_tr,y)\n\nfinalPreds = myFinalPipeline.predict(X_te)","5aeacef5":"output = pd.DataFrame({\n    \"Id\" : X_te.index,\n    \"DEATH_EVENT\" : finalPreds\n})","7162aeb1":"compression_opts = dict(method=\"zip\",archive_name=\"submission.csv\")\noutput.to_csv(\"submission.zip\",index=False,compression=compression_opts)","ac2dc44f":"# Introduction\n\nWelcome user, in this notebook I will process heart failure clinic data.During the process ; before , I will visualize their data with variety tools then train data to predict results with regression methods.It's gonna be nice.Let's start to jobs.\n\n<font color=\"blue\"\/>\n\n<b>Content<\/b>\n\n   1. [Imports Library](#1)\n       * [Reading Input File](#2)\n   2. [Explore Data](#3)\n       * [Overview Data](#4)\n       * [Detect Missing Values](#ek4)\n       * [Investigate Columns](#5)\n           * [Target Columns(DEATH_EVENT)](#ek1)\n           * [Univariate Variable Analysis](#ek2)\n           * [Figure Out Relationship Between Columns According to Target](#ek3)\n           * [Visualize Whole Columns](#6)\n               * [Age -- DEATH_EVENT](#7)\n               * [Anaemia](#8)\n               * [Creatinine Phosphokinase -- Deaths Event](#9)\n               * [Diabetes](#10)\n               * [Ejection Fraction](#11)\n               * [High Blood Pressure](#12)\n               * [Platelets](#13)\n               * [Serum Creatinine](#14)\n               * [Serum Sodium](#15)\n               * [Sex](#16)\n               * [Smoking](#17) \n               * [Time](#18)\n               * [DEATH EVENT](#19)\n   3. [Preprocessing and Define Model](#20)\n       * [Outliers Detection](#21)\n       * [Preprocessing](#22)\n       * [Define Model](#23)\n       * [Using Pipeline](#24)\n       * [Implement Algorithms on Model](#25)\n           * [KNN](#26)\n           * [Logistic Regression](#27)\n           * [Random Forest Classification](#28)\n           * [XGBoost](#29)\n           * [DecisionTree Classification](#30)\n   4. [Final Predict](#31)\n  ","dbdad990":"Before implement to logistic regression , I am going to find most suitable variable that <b>max_iter<\/b>","c736c1f5":"<a id=\"10\"><\/a>\n**Diabetes**","e51a40d7":"Before implement to Random Forest Classification, I am going to find most suitable variable that <b>n_estimators<\/b>","94aafe9b":"<a id=\"22\"><\/a>\n### Preprocessing","1a3dc232":"<a id=\"15\"><\/a>\n**Serum Sodium**","dab6c3cf":"#### Cross-validation results for Logistic Regression","47adc5e6":"<a id=\"30\"><\/a>\n#### Desicion Tree Classification","9274a9f5":"<a id=\"27\"><\/a>\n####  Logistic Regression","4154ab32":"<a id=\"19\"><\/a>\n**DEATH EVENT**","1066ff28":"<a id=\"5\"><\/a>\n### Investigate Columns\n\nAs you seen , data has 13 columns and each one dtype is numeric.In this section we will seen columns on plots.Also I will examine target columns that DEATH_EVENT.","6b73d348":"We keep continue to create models with pipeline.As you know , pipeline is one of the most benefits way to create model.","c0e2fca7":"<a id=\"9\"><\/a>\n**Creatinine Phosphokinase -- Deaths Event**","eb87f11b":"<a id=\"28\"><\/a>\n#### Random Forest Classification","3a9efd5a":"<a id=\"ek1\"><\/a>\n#### Target Columns(DEATH_EVENT)","f0d0bf85":"<a id=\"24\"><\/a>\n#### Using Pipeline","8f8b8410":"Let's implement logistic regression while max_iter equal 150","9b5d3c61":"<a id=\"4\"><\/a>\n### Overview Data","09e89cb3":"To sum up I will implement random forest classification on data.Before final process , we will ought set x and y variables.Then we can process model and data.","be2ee840":"<a id=\"26\"><\/a>\n#### KNN\n\nI am going to implement KNN algorithm but before I will ought to find most suitable n_neighbours","e02fb67b":"After that , I am going to adjust again variable's columns as myCols. ","0b8ba130":"<a id=\"2\"><\/a>\n### Reading Input File","a42e9b7d":"Let's look at our scores with Random Forest Classification on confusion matrix","969148f2":"<a id=\"31\"><\/a>\n## Final Predict","9fede894":"Before implement XGBoost algorithms , I am going to find most suitable variable that <b>n_estimators<\/b>","dc106fdd":"<a id=\"12\"><\/a>\n**High Blood Pressure**","707f5515":"<a id=\"ek3\"><\/a>\n#### Figure Out Relationship Between Columns According to Target","c3565068":"<a id=\"13\"><\/a>\n**Platelets**","2fc6cb1b":"<a id=\"18\"><\/a>\n**Time**","fff824aa":"Data has not any missign value , it's perfect","a53a6920":"<a id=\"ek2\"><\/a>\n#### Univariate Variable Analysis(Exclude DEATH_EVENT)\n\n* I will occur multiply plots to show distribiton of columns exclude target column that DEATH_EVENT.\n* I will use this plots variety :\n    * distplot\n    * boxplot\n    * kdeplot","b8b85311":"#### Cross-validation results for Decision Tree Classification","1543cc6b":"<a id=\"6\"><\/a>\n#### Visualize Whole Columns ","9b3a53d4":"<a id=\"7\"><\/a>\n**Age -- DEATH_EVENT**","667d33e3":"<a id=\"25\"><\/a>\n### Implement Algorithms on Model","5fad6c83":"**According to whole models and results , seems to random forest going to be most useful model.**","56ed3448":"<a id=\"20\"><\/a>\n## Preprocessing and Define Model\nIn this section I will make some preprocess for define model and predict results.Also it is ought to make before implement your model.Firstly I will detect outliers in data.","81290073":"<a id=\"16\"><\/a>\n**Sex**","629861d4":"<a id=\"ek4\"><\/a>\n### Detect Missing Values","47d5e0d2":"Let's implement decision tree classification with pipeline.","552b0cbc":"<a id=\"23\"><\/a>\n### Define Model\nIn this section , I will try to define models and compare models to find each which has most high score.This is the point.However reach the point , we must do something namely we will develop models.Before we will set columns with according to their types.Then I will use pipeline to facility to develop and change model.Finally , I am going to implement each model on pipelines.","02b6ae49":"Score will became very low so I am gong to pass <b>XGBoost<\/b>","f6291f42":"Carried out final model","c5fa9ce6":"<a id=\"11\"><\/a>\n**Ejection Fraction**","5bbde9ae":"#### Cross-validation results for Random Forest Classification","1a9c56c8":"<a id=\"21\"><\/a>\n### Outliers Detection","d3747940":"Now , let's look at algorithms predict on confusion matrix.","ad792c3a":"<a id=\"3\"><\/a>\n## Explore Data","3107635f":"Let's look at our predicts with logistic regression on confusion matrix","20106a04":"Let's implement Random Forest Classification while n_estimators equal 20","2ad02567":"**Lets start to implement models with KNN**","b9104a6c":"<a id=\"14\"><\/a>\n**Serum Creatinine**","3cdad290":"After the columns control , I will detect columns which include process in <b>myCols<\/b> variable","9927a652":"#### Cross-validation results for KNN","c390d7fa":"<a id=\"29\"><\/a>\n#### XGBoost","d01c04a0":"<a id=\"17\"><\/a>\n**Smoking**","b0ae6c7a":"<a id=\"1\"><\/a>\n## Imports Library","b9df5f29":"It seems to be most high value is 10 or 11.Then , let's implement knn algorithms while n_neighbours equal 11","6fcd4a35":"Set columns and variables","1945e491":"Whole columns dtypes is numeric.[I controled above already](#5)","3c3c3995":"<a id=\"8\"><\/a>\n**Anaemia**"}}