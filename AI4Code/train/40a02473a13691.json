{"cell_type":{"1c849b3b":"code","2204bfd4":"code","29917205":"code","b5377f04":"code","d75dd311":"code","ed4a9bd0":"code","8aefd2d5":"code","fd7cc3af":"code","54055f9c":"code","2839c307":"code","7cabf6f8":"code","1fa27689":"code","37d847c0":"code","81486acf":"code","057ea3b4":"code","b16cb58f":"code","72b7ddaf":"code","93f31678":"code","e5b3bb45":"code","b9e4f06b":"code","1c8a4130":"code","d50825ac":"markdown","a53b900e":"markdown","8f325583":"markdown","ebd0d687":"markdown","0e0fa1a8":"markdown","fe16f07d":"markdown","229180ed":"markdown","fc51111b":"markdown"},"source":{"1c849b3b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2204bfd4":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","29917205":"df = pd.read_csv('..\/input\/nyse\/prices-split-adjusted.csv')\ndf.head()","b5377f04":"df.info()","d75dd311":"df['date'] = pd.to_datetime(df['date'])\ndf = df.set_index(['date'])\ndf.head()","ed4a9bd0":"df['symbol'].unique()","8aefd2d5":"data = df[df['symbol']=='IBM']\ndata.head()","fd7cc3af":"high = data['high']\n","54055f9c":"plt.plot(high)\nplt.xlabel('Year',fontsize=15)\nplt.ylabel('High Value',fontsize=15)\nplt.title('Plot of high values',fontsize=20)","2839c307":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\n\nhigh_prices = sc.fit_transform(np.array(high).reshape(-1,1))\nhigh_prices","7cabf6f8":"split_size = 0.65\n\ntraining_size = int(len(high)*0.65)\n\ntrain_data = high_prices[0:training_size,:]\ntest_data = high_prices[training_size:,:]\n\nprint(len(train_data))\nprint(len(test_data))\n","1fa27689":"#Arranging our data in such a way that the high value of current day depends on the trends in last 60 days.\ndef create_data(data,timestep=1):\n    X,Y = [],[]\n    for i in range(len(data)-timestep-1):\n        a = data[i:(i+timestep),0]    #i=0,1,2,3,4,.....\n        X.append(a)\n        Y.append(data[i+timestep,0])\n        \n    return np.array(X),np.array(Y)\n","37d847c0":"timestep = 60\nX_train, Y_train = create_data(train_data, timestep)\nx_test, y_test = create_data(test_data, timestep)\n\nprint(X_train.shape)\nprint(Y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)\n\n","81486acf":"#Since the LSTM model accepts a 3D tensor so we convert both X_train and x_test into a 3D tensor\n\nX_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))\nx_test = x_test.reshape(x_test.shape[0],x_test.shape[1],1)\n\nprint(X_train.shape)\nprint(x_test.shape)","057ea3b4":"from tensorflow.keras import models\nfrom tensorflow.keras.layers import LSTM,Dense","b16cb58f":"model = models.Sequential()\n\nmodel.add(LSTM(64,return_sequences=True,input_shape=(60,1)))\nmodel.add(LSTM(50,return_sequences=True))\nmodel.add(LSTM(32,return_sequences=True))\nmodel.add(LSTM(50,return_sequences=False))\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam',loss='mean_squared_error')\nmodel.summary()","72b7ddaf":"hist = model.fit(X_train,Y_train,epochs=40,batch_size=32)","93f31678":"y_pred = model.predict(x_test)\n\nprint(len(y_pred))\nprint(type(y_pred))","e5b3bb45":"from sklearn.metrics import mean_squared_error\n\nloss = np.sqrt(mean_squared_error(y_test,y_pred))\nloss","b9e4f06b":"y_test = sc.inverse_transform(y_test)\ny_pred = sc.inverse_transform(y_pred)","1c8a4130":"plt.plot(y_test,label='y_test')\nplt.plot(y_pred,label='y_pred')\nplt.title('Predicted vs Actual values curve',fontsize='18')\nplt.legend()\nplt.xlabel('Number of test points',fontsize='18')\nplt.ylabel('High Values',fontsize='15')\nplt.show()\n","d50825ac":"Training our model.","a53b900e":"Making predicts on test data.","8f325583":"Converting the values into their original form","ebd0d687":"In this notebook I used the New York Stock Exchange data to predict the IBM's high values of stocks of a day. ","0e0fa1a8":"This data contains the stock records of all of the following companies","fe16f07d":"Visualising original and predicted values.","229180ed":"Creating LSTM model.","fc51111b":"Normalising the high values by using Standard Scaler and splitting data into training and testing."}}