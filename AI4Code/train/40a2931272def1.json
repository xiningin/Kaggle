{"cell_type":{"2861775b":"code","c8b714fc":"code","ea50fb88":"code","6a41eba2":"code","c90befcd":"code","6f04546f":"code","7de5dafc":"code","da742d57":"code","6db16a76":"code","04b88566":"code","2a3e3d04":"code","da4d7544":"code","b0eaf070":"code","8408b687":"code","438b9aa1":"code","200ce70c":"code","b8f5c19d":"code","d7a14070":"code","26384b20":"code","24dd8c52":"code","1e469c74":"code","c5e3649f":"code","ce9c31c2":"code","25df640f":"code","8084db3f":"code","983e53dd":"markdown","a632f9d8":"markdown"},"source":{"2861775b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np\nimport cv2\nimport os\nfrom scipy.spatial import distance\nimport tensorflow as tf\nfrom tensorflow import keras \nimport numpy as np\nimport PIL\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Activation,Flatten,Dropout\nfrom keras.layers import Conv2D,MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\n#import imutils\n#from imutils import face_utils\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c8b714fc":"data_path='\/kaggle\/input\/drowsiness-data\/kaggle Upload\/'\ncategories=os.listdir(data_path)\nlabels=[i for i in range(len(categories))]\n\nlabel_dict=dict(zip(categories,labels)) #empty dictionary\n\nprint(label_dict)\nprint(categories)\nprint(labels)","ea50fb88":"img_size=100\ndata=[]\ntarget=[]\n\n\nfor category in categories:\n    folder_path=os.path.join(data_path,category)\n    img_names=os.listdir(folder_path)\n        \n    for img_name in img_names:\n        img_path=os.path.join(folder_path,img_name)\n        img=cv2.imread(img_path)\n\n        try:\n            gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)           \n            #Coverting the image into gray scale\n            resized=cv2.resize(gray,(img_size,img_size))\n            #resizing the gray scale into 50x50, since we need a fixed common size for all the images in the dataset\n            data.append(resized)\n            target.append(label_dict[category])\n            #appending the image and the label(categorized) into the list (dataset)\n\n        except Exception as e:\n            print('Exception:',e)\n            #if any exception rasied, the exception will be printed here. And pass to the next image","6a41eba2":"import numpy as np\n\ndata=np.array(data)\/255.0\ndata=np.reshape(data,(data.shape[0],img_size,img_size,1))\ntarget=np.array(target)\n\nfrom keras.utils import np_utils\n\nnew_target=np_utils.to_categorical(target)","c90befcd":"\nnp.save('data',data)\nnp.save('target',new_target)\n","6f04546f":"import numpy as np\n\ndata=np.load('data.npy')\ntarget=np.load('target.npy')\n\n#loading the save numpy arrays in the previous code","7de5dafc":"from keras.models import Sequential\nfrom keras.layers import Dense,Activation,Flatten,Dropout\nfrom keras.layers import Conv2D,MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint\n\nmodel=Sequential()\n\nmodel.add(Conv2D(200,(3,3),input_shape=data.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n#The first CNN layer followed by Relu and MaxPooling layers\n\nmodel.add(Conv2D(100,(3,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n#The second convolution layer followed by Relu and MaxPooling layers\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\n#Flatten layer to stack the output convolutions from second convolution layer\nmodel.add(Dense(64,activation='relu'))\n#Dense layer of 64 neurons\nmodel.add(Dense(2,activation='softmax'))\n#The Final layer with two outputs for two categories\n\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","da742d57":"from sklearn.model_selection import train_test_split\n\ntrain_data,test_data,train_target,test_target=train_test_split(data,target,test_size=0.1)","6db16a76":"checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\nhistory=model.fit(train_data,train_target,epochs=20,callbacks=[checkpoint],validation_split=0.2)","04b88566":"\nfrom matplotlib import pyplot as plt\n\nplt.plot(history.history['loss'],'r',label='training loss')\nplt.plot(history.history['val_loss'],label='validation loss')\nplt.xlabel('# epochs')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","2a3e3d04":"plt.plot(history.history['accuracy'],'r',label='training accuracy')\nplt.plot(history.history['val_accuracy'],label='validation accuracy')\nplt.xlabel('# epochs')\nplt.ylabel('loss')\nplt.legend()\nplt.show()","da4d7544":"import glob\nimport matplotlib\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt\nimport matplotlib.image as mpimg\nimport numpy as np\nimport imageio as im\nfrom keras.models import load_model\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint","b0eaf070":"ls \/kaggle\/working","8408b687":"model =load_model('model-020.model')\n# As a reminder \nmodel.summary() ","438b9aa1":"from tensorflow.keras.utils import plot_model\nfrom PIL import Image  \nimport PIL  \n# summarize the model\nx=plot_model(model, 'model.png', show_shapes=True)\nim1 = model.save(\"\/kaggle\/working\/\") ","200ce70c":"ls \/kaggle\/working","b8f5c19d":"import os\nos.chdir(r'..\/working')\nfrom IPython.display import FileLink\nFileLink(r'model.png')","d7a14070":"from tensorflow.keras import models\nlayer_outputs = [layer.output for layer in model.layers[:12]] \n# Extracts the outputs of the top 12 layers\nactivation_model = models.Model(inputs=model.input, outputs=layer_outputs) # Creates a model that will return these outputs, given the model input","26384b20":"img_path = '\/kaggle\/input\/drowsiness-data\/kaggle Upload\/alert\/alert10.jpg'\nimg = image.load_img(img_path, target_size=(64, 64))\nimg_tensor = image.img_to_array(img)\nimg_tensor = np.expand_dims(img_tensor, axis=0)\nimg_tensor \/= 255.0\nplt.imshow(img_tensor[0])\nplt.show()\nprint(img_tensor.shape)\nactivations = activation_model.predict(img_tensor) \n# Returns a list of five Numpy arrays: one array per layer activation","24dd8c52":"from keract import display_activations","1e469c74":"# Utility functions for deep learning with Keras\n# Dr. Tirthajyoti Sarkar, Fremont, CA 94536\n# ==============================================\n\n# NOTES\n# Used tf.keras in general except in special functions where older\/independent Keras has been used.\n\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nclass myCallback(tf.keras.callbacks.Callback):\n    \"\"\"\n  User can pass on the desired accuracy threshold while creating an instance of the class\n  \"\"\"\n\n    def __init__(self, acc_threshold=0.9, print_msg=True):\n        self.acc_threshold = acc_threshold\n        self.print_msg = print_msg\n\n    def on_epoch_end(self, epoch, logs={}):\n        if logs.get(\"acc\") > self.acc_threshold:\n            if self.print_msg:\n                print(\n                    \"\\nReached {}% accuracy so cancelling the training!\".format(\n                        self.acc_threshold\n                    )\n                )\n            self.model.stop_training = True\n        else:\n            if self.print_msg:\n                print(\"\\nAccuracy not high enough. Starting another epoch...\\n\")\n\n    def build_classification_model(\n        num_layers=1,\n        architecture=[32],\n        act_func=\"relu\",\n        input_shape=(28, 28),\n        output_class=10,\n    ):\n        \"\"\"\n  Builds a densely connected neural network model from user input\n  \n  Arguments\n          num_layers: Number of hidden layers\n          architecture: Architecture of the hidden layers (densely connected)\n          act_func: Activation function. Could be 'relu', 'sigmoid', or 'tanh'.\n          input_shape: Dimension of the input vector\n          output_class: Number of classes in the output vector\n  Returns\n          A neural net (Keras) model for classification\n  \"\"\"\n        layers = [tf.keras.layers.Flatten(input_shape=input_shape)]\n        if act_func == \"relu\":\n            activation = tf.nn.relu\n        elif act_func == \"sigmoid\":\n            activation = tf.nn.sigmoid\n        elif act_func == \"tanh\":\n            activation = tf.nn.tanh\n\n        for i in range(num_layers):\n            layers.append(tf.keras.layers.Dense(architecture[i], activation=tf.nn.relu))\n        layers.append(tf.keras.layers.Dense(output_class, activation=tf.nn.softmax))\n\n        model = tf.keras.models.Sequential(layers)\n        return model\n\n\ndef build_regression_model(\n    input_neurons=10, input_dim=1, num_layers=1, architecture=[32], act_func=\"relu\"\n):\n    \"\"\"\n  Builds a densely connected neural network model from user input\n  \n  Arguments\n          num_layers: Number of hidden layers\n          architecture: Architecture of the hidden layers (densely connected)\n          act_func: Activation function. Could be 'relu', 'sigmoid', or 'tanh'.\n          input_shape: Dimension of the input vector\n  Returns\n          A neural net (Keras) model for regression\n  \"\"\"\n    if act_func == \"relu\":\n        activation = tf.nn.relu\n    elif act_func == \"sigmoid\":\n        activation = tf.nn.sigmoid\n    elif act_func == \"tanh\":\n        activation = tf.nn.tanh\n\n    layers = [\n        tf.keras.layers.Dense(input_neurons, input_dim=input_dim, activation=activation)\n    ]\n\n    for i in range(num_layers):\n        layers.append(tf.keras.layers.Dense(architecture[i], activation=activation))\n    layers.append(tf.keras.layers.Dense(1))\n\n    model = tf.keras.models.Sequential(layers)\n    return model\n\n\ndef compile_train_classification_model(\n    model,\n    x_train,\n    y_train,\n    callbacks=None,\n    learning_rate=0.001,\n    batch_size=1,\n    epochs=10,\n    verbose=0,\n):\n    \"\"\"\n  Compiles and trains a given Keras model with the given data. \n  Assumes Adam optimizer for this implementation.\n  Assumes categorical cross-entropy loss.\n  \n  Arguments\n          learning_rate: Learning rate for the optimizer Adam\n          batch_size: Batch size for the mini-batch optimization\n          epochs: Number of epochs to train\n          verbose: Verbosity of the training process\n  \n  Returns\n  A copy of the model\n  \"\"\"\n\n    model_copy = model\n    model_copy.compile(\n        optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\"],\n    )\n\n    if callbacks != None:\n        model_copy.fit(\n            x_train,\n            y_train,\n            epochs=epochs,\n            batch_size=batch_size,\n            callbacks=[callbacks],\n            verbose=verbose,\n        )\n    else:\n        model_copy.fit(\n            x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose\n        )\n    return model_copy\n\n\ndef compile_train_regression_model(\n    model,\n    x_train,\n    y_train,\n    callbacks=None,\n    learning_rate=0.001,\n    batch_size=1,\n    epochs=10,\n    verbose=0,\n):\n    \"\"\"\n  Compiles and trains a given Keras model with the given data for regression. \n  Assumes Adam optimizer for this implementation.\n  Assumes mean-squared-error loss\n  \n  Arguments\n          learning_rate: Learning rate for the optimizer Adam\n          batch_size: Batch size for the mini-batch operation\n          epochs: Number of epochs to train\n          verbose: Verbosity of the training process\n  \n  Returns\n  A copy of the model\n  \"\"\"\n\n    model_copy = model\n    model_copy.compile(\n        optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n        loss=\"mean_squared_error\",\n        metrics=[\"accuracy\"],\n    )\n    if callbacks != None:\n        model_copy.fit(\n            x_train,\n            y_train,\n            epochs=epochs,\n            batch_size=batch_size,\n            callbacks=[callbacks],\n            verbose=verbose,\n        )\n    else:\n        model_copy.fit(\n            x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose\n        )\n    return model_copy\n\n\ndef plot_loss_acc(model, target_acc=0.9, title=None):\n    \"\"\"\n  Takes a Keras model and plots the loss and accuracy over epochs.\n  The same plot shows loss and accuracy on two axes - left and right (with separate scales)\n  Users can supply a title if desired\n  Arguments:\n            target_acc (optional): The desired\/ target acc for the function to show a horizontal bar.\n            title (optional): A Python string object to show as the plot's title\n  \"\"\"\n    e = (\n        np.array(model.history.epoch) + 1\n    )  # Add one to the list of epochs which is zero-indexed\n    # Check to see if loss metric is in the model history\n    assert (\n        \"loss\" in model.history.history.keys()\n    ), \"No loss metric found in the model history\"\n    l = np.array(model.history.history[\"loss\"])\n    # Check to see if loss metric is in the model history\n    assert (\n        \"acc\" in model.history.history.keys()\n    ), \"No accuracy metric found in the model history\"\n    a = np.array(model.history.history[\"acc\"])\n\n    fig, ax1 = plt.subplots()\n\n    color = \"tab:red\"\n    ax1.set_xlabel(\"Epochs\", fontsize=15)\n    ax1.set_ylabel(\"Loss\", color=color, fontsize=15)\n    ax1.plot(e, l, color=color, lw=2)\n    ax1.tick_params(axis=\"y\", labelcolor=color)\n    ax1.grid(True)\n\n    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n\n    color = \"tab:blue\"\n    ax2.set_ylabel(\n        \"Accuracy\", color=color, fontsize=15\n    )  # we already handled the x-label with ax1\n    ax2.plot(e, a, color=color, lw=2)\n    ax2.tick_params(axis=\"y\", labelcolor=color)\n\n    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n    if title != None:\n        plt.title(title)\n    plt.hlines(\n        y=target_acc, xmin=1, xmax=e.max(), colors=\"k\", linestyles=\"dashed\", lw=3\n    )\n    plt.show()\n\n\ndef plot_train_val_acc(model, target_acc=0.9, title=None):\n    \"\"\"\n  Takes a Keras model and plots the training and validation set accuracy over epochs.\n  The same plot shows both the accuracies on two axes - left and right (with separate scales)\n  Users can supply a title if desired\n  Arguments:\n            target_acc (optional): The desired\/ target acc for the function to show a horizontal bar.\n            title (optional): A Python string object to show as the plot's title\n  \"\"\"\n    e = (\n        np.array(model.history.epoch) + 1\n    )  # Add one to the list of epochs which is zero-indexed\n    # Check to see if loss metric is in the model history\n    assert (\n        \"acc\" in model.history.history.keys()\n    ), \"No accuracy metric found in the model history\"\n    a = np.array(model.history.history[\"acc\"])\n    # Check to see if loss metric is in the model history\n    assert (\n        \"val_acc\" in model.history.history.keys()\n    ), \"No validation accuracy metric found in the model history\"\n    va = np.array(model.history.history[\"val_acc\"])\n\n    fig, ax1 = plt.subplots()\n\n    color = \"tab:red\"\n    ax1.set_xlabel(\"Epochs\", fontsize=15)\n    ax1.set_ylabel(\"Training accuracy\", color=color, fontsize=15)\n    ax1.plot(e, a, color=color, lw=2)\n    ax1.tick_params(axis=\"y\", labelcolor=color)\n    ax1.grid(True)\n\n    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n\n    color = \"tab:blue\"\n    ax2.set_ylabel(\n        \"Validation accuracy\", color=color, fontsize=15\n    )  # we already handled the x-label with ax1\n    ax2.plot(e, va, color=color, lw=2)\n    ax2.tick_params(axis=\"y\", labelcolor=color)\n\n    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n    if title != None:\n        plt.title(title)\n\n    plt.hlines(\n        y=target_acc, xmin=1, xmax=e.max(), colors=\"k\", linestyles=\"dashed\", lw=3\n    )\n\n    plt.show()\n\n\ndef train_CNN(\n    train_directory,\n    target_size=(256, 256),\n    callbacks=None,\n    classes=None,\n    batch_size=128,\n    num_classes=2,\n    num_epochs=20,\n    verbose=0,\n):\n    \"\"\"\n    Trains a conv net for a given dataset contained within a training directory.\n    Users can just supply the path of the training directory and get back a fully trained, 5-layer, convolutional network.\n    \n    Arguments:\n            train_directory: The directory where the training images are stored in separate folders.\n                            These folders should be named as per the classes.\n            target_size: Target size for the training images. A tuple e.g. (200,200)\n            classes: A Python list with the classes \n            batch_size: Batch size for training\n            num_epochs: Number of epochs for training\n            num_classes: Number of output classes to consider\n            verbose: Verbosity level of the training, passed on to the `fit_generator` method\n    Returns:\n            A trained conv net model\n    \n    \"\"\"\n    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n    import tensorflow as tf\n    from tensorflow.keras.optimizers import RMSprop\n\n    # ImageDataGenerator object instance with scaling\n    train_datagen = ImageDataGenerator(rescale=1 \/ 255)\n\n    # Flow training images in batches using the generator\n    train_generator = train_datagen.flow_from_directory(\n        train_directory,  # This is the source directory for training images\n        target_size=target_size,  # All images will be resized to 200 x 200\n        batch_size=batch_size,\n        # Specify the classes explicitly\n        classes=classes,\n        # Since we use categorical_crossentropy loss, we need categorical labels\n        class_mode=\"categorical\",\n    )\n\n    input_shape = tuple(list(target_size) + [3])\n\n    # Model architecture\n    model = tf.keras.models.Sequential(\n        [\n            # Note the input shape is the desired size of the image 200x 200 with 3 bytes color\n            # The first convolution\n            tf.keras.layers.Conv2D(\n                16, (3, 3), activation=\"relu\", input_shape=input_shape\n            ),\n            tf.keras.layers.MaxPooling2D(2, 2),\n            # The second convolution\n            tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"),\n            tf.keras.layers.MaxPooling2D(2, 2),\n            # The third convolution\n            tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n            tf.keras.layers.MaxPooling2D(2, 2),\n            # The fourth convolution\n            tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n            tf.keras.layers.MaxPooling2D(2, 2),\n            # The fifth convolution\n            tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n            tf.keras.layers.MaxPooling2D(2, 2),\n            # Flatten the results to feed into a dense layer\n            tf.keras.layers.Flatten(),\n            # 512 neuron in the fully-connected layer\n            tf.keras.layers.Dense(512, activation=\"relu\"),\n            # Output neurons for `num_classes` classes with the softmax activation\n            tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n        ]\n    )\n\n    # Optimizer and compilation\n    model.compile(\n        loss=\"categorical_crossentropy\", optimizer=RMSprop(lr=0.001), metrics=[\"acc\"]\n    )\n\n    # Total sample count\n    total_sample = train_generator.n\n\n    # Training\n    model.fit_generator(\n        train_generator,\n        callbacks=callbacks,\n        steps_per_epoch=int(total_sample \/ batch_size),\n        epochs=num_epochs,\n        verbose=verbose,\n    )\n\n    return model\n\n\ndef train_CNN_keras(\n    train_directory,\n    target_size=(256, 256),\n    classes=None,\n    batch_size=128,\n    num_classes=2,\n    num_epochs=20,\n    verbose=0,\n):\n    \"\"\"\n    Trains a conv net for a given dataset contained within a training directory.\n    Users can just supply the path of the training directory and get back a fully trained, 5-layer, convolutional network.\n    \n    Arguments:\n            train_directory: The directory where the training images are stored in separate folders.\n                            These folders should be named as per the classes.\n            target_size: Target size for the training images. A tuple e.g. (200,200)\n            classes: A Python list with the classes \n            batch_size: Batch size for training\n            num_epochs: Number of epochs for training\n            num_classes: Number of output classes to consider\n            verbose: Verbosity level of the training, passed on to the `fit_generator` method\n    Returns:\n            A trained conv net model\n    \n    \"\"\"\n    from keras.layers import Conv2D, MaxPooling2D\n    from keras.layers import Dense, Dropout, Flatten\n    from keras.models import Sequential\n    from keras.optimizers import RMSprop\n    from keras.preprocessing.image import ImageDataGenerator\n\n    # ImageDataGenerator object instance with scaling\n    train_datagen = ImageDataGenerator(rescale=1 \/ 255)\n\n    # Flow training images in batches using the generator\n    train_generator = train_datagen.flow_from_directory(\n        train_directory,  # This is the source directory for training images\n        target_size=target_size,  # All images will be resized to 200 x 200\n        batch_size=batch_size,\n        # Specify the classes explicitly\n        classes=classes,\n        # Since we use categorical_crossentropy loss, we need categorical labels\n        class_mode=\"categorical\",\n    )\n\n    input_shape = tuple(list(target_size) + [3])\n\n    # Model architecture\n    model = Sequential(\n        [\n            # Note the input shape is the desired size of the image 200x 200 with 3 bytes color\n            # The first convolution\n            Conv2D(16, (3, 3), activation=\"relu\", input_shape=input_shape),\n            MaxPooling2D(2, 2),\n            # The second convolution\n            Conv2D(32, (3, 3), activation=\"relu\"),\n            MaxPooling2D(2, 2),\n            # The third convolution\n            Conv2D(64, (3, 3), activation=\"relu\"),\n            MaxPooling2D(2, 2),\n            # The fourth convolution\n            Conv2D(64, (3, 3), activation=\"relu\"),\n            MaxPooling2D(2, 2),\n            # The fifth convolution\n            Conv2D(64, (3, 3), activation=\"relu\"),\n            MaxPooling2D(2, 2),\n            # Flatten the results to feed into a dense layer\n            Flatten(),\n            # 512 neuron in the fully-connected layer\n            Dense(512, activation=\"relu\"),\n            # Output neurons for `num_classes` classes with the softmax activation\n            Dense(num_classes, activation=\"softmax\"),\n        ]\n    )\n\n    # Optimizer and compilation\n    model.compile(\n        loss=\"categorical_crossentropy\", optimizer=RMSprop(lr=0.001), metrics=[\"acc\"]\n    )\n\n    # Total sample count\n    total_sample = train_generator.n\n\n    # Training\n    model.fit_generator(\n        train_generator,\n        steps_per_epoch=int(total_sample \/ batch_size),\n        epochs=num_epochs,\n        verbose=verbose,\n    )\n\n    return model\n\n\ndef preprocess_image(img_path, model=None, rescale=255, resize=(256, 256)):\n    \"\"\"\n    Preprocesses a given image for prediction with a trained model, with rescaling and resizing options\n    \n    Arguments:\n            img_path: The path to the image file\n            rescale: A float or integer indicating required rescaling. \n                    The image array will be divided (scaled) by this number.\n            resize: A tuple indicating desired target size. \n                    This should match the input shape as expected by the model\n    Returns:\n            img: A processed image.\n    \"\"\"\n    from keras.preprocessing.image import img_to_array, load_img\n    import cv2\n    import numpy as np\n\n    assert type(img_path) == str, \"Image path must be a string\"\n    assert (\n        type(rescale) == int or type(rescale) == float\n    ), \"Rescale factor must be either a float or int\"\n    assert (\n        type(resize) == tuple and len(resize) == 2\n    ), \"Resize target must be a tuple with two elements\"\n\n    img = load_img(img_path)\n    img = img_to_array(img)\n    img = img \/ float(rescale)\n    img = cv2.resize(img, resize)\n    if model != None:\n        if len(model.input_shape) == 4:\n            img = np.expand_dims(img, axis=0)\n\n    return img\n\n\ndef pred_prob_with_model(img_path, model, rescale=255, resize=(256, 256)):\n    \"\"\"\n    Tests a given image with a trained model, with rescaling and resizing options\n    \n    Arguments:\n            img_path: The path to the image file\n            model: The trained Keras model\n            rescale: A float or integer indicating required rescaling. \n                    The image array will be divided (scaled) by this number.\n            resize: A tuple indicating desired target size. \n                    This should match the input shape as expected by the model\n    Returns:\n            pred: A prediction vector (Numpy array).\n                  Could be either classes or probabilities depending on the model.\n    \"\"\"\n    from keras.preprocessing.image import img_to_array, load_img\n    import cv2\n\n    assert type(img_path) == str, \"Image path must be a string\"\n    assert (\n        type(rescale) == int or type(rescale) == float\n    ), \"Rescale factor must be either a float or int\"\n    assert (\n        type(resize) == tuple and len(resize) == 2\n    ), \"Resize target must be a tuple with two elements\"\n\n    img = load_img(img_path)\n    img = img_to_array(img)\n    img = img \/ float(rescale)\n    img = cv2.resize(img, resize)\n    if len(model.input_shape) == 4:\n        img = np.expand_dims(img, axis=0)\n\n    pred = model.predict(img)\n\n    return pred\n\n\ndef pred_class_with_model(img_path, model, rescale=255, resize=(256, 256)):\n    \"\"\"\n    Tests a given image with a trained model, with rescaling and resizing options\n    \n    Arguments:\n            img_path: The path to the image file\n            model: The trained Keras model\n            rescale: A float or integer indicating required rescaling. \n                    The image array will be divided (scaled) by this number.\n            resize: A tuple indicating desired target size. \n                    This should match the input shape as expected by the model\n    Returns:\n            pred: A prediction vector (Numpy array).\n                  Could be either classes or probabilities depending on the model.\n    \"\"\"\n    from keras.preprocessing.image import img_to_array, load_img\n    import cv2\n\n    assert type(img_path) == str, \"Image path must be a string\"\n    assert (\n        type(rescale) == int or type(rescale) == float\n    ), \"Rescale factor must be either a float or int\"\n    assert (\n        type(resize) == tuple and len(resize) == 2\n    ), \"Resize target must be a tuple with two elements\"\n\n    img = load_img(img_path)\n    img = img_to_array(img)\n    img = img \/ float(rescale)\n    img = cv2.resize(img, resize)\n    if len(model.input_shape) == 4:\n        img = np.expand_dims(img, axis=0)\n\n    pred = model.predict(img)\n    pred_class = pred.argmax(axis=-1)\n\n    return pred_class","c5e3649f":"img_path = '\/kaggle\/input\/drowsiness-data\/kaggle Upload\/alert\/alert376.jpg'\ntarget_size=(64,64)\n# Preprocessing the image for the model\nx = preprocess_image(img_path=img_path,model=model,resize=target_size)\n# Generate the activations \nactivations = get_activations(model, x)","ce9c31c2":"x = preprocess_image(img_path=img_path,model=model,resize=target_size)","25df640f":"#!pip install keract==1.1.1","8084db3f":"from keract import get_activations\nactivations = get_activations(model, x)","983e53dd":"**Below is code for activation Graph**\n****Below code is not working giving error\n    ValueError: Input 0 of layer conv2d is incompatible with the layer: expected axis -1 of input shape to have value 1 but received input with shape [None, 94, 94, 3]","a632f9d8":"above code dint work so ... now trying hyper param tuning."}}