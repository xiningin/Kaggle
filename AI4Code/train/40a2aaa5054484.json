{"cell_type":{"f22ea3c6":"code","31fca746":"code","93de4fbd":"code","96b4c283":"code","54c5b901":"code","ae113b4c":"code","9cb77f2c":"code","ae6796bd":"code","b5dfa96e":"code","fbb63375":"code","33f11e92":"code","5084ffee":"code","5f032f3f":"code","a86cb690":"code","b11e0c8f":"code","1df905b4":"code","e038d0e2":"code","40a0de2a":"code","e31473d6":"code","1f29aead":"code","d97335ff":"code","cdee1e3d":"code","a03f2844":"code","9908eac3":"markdown","e99b7c1f":"markdown","0aaed921":"markdown","e7558a1d":"markdown","01c4ae28":"markdown","bed3b735":"markdown","2a84f406":"markdown","083385ba":"markdown","0837e5dd":"markdown","5d23a487":"markdown","ff57dfcd":"markdown","e3490f46":"markdown","b31b867d":"markdown","3c31ac27":"markdown","0db14c2f":"markdown","032745f5":"markdown","0869c2a0":"markdown","f6be165b":"markdown","bda609cd":"markdown","2241d0de":"markdown","8a4c1c8b":"markdown"},"source":{"f22ea3c6":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import auc\nfrom matplotlib import pyplot\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nimport seaborn as sns\nimport eli5 \nfrom eli5.sklearn import PermutationImportance \nfrom eli5 import show_weights \nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","31fca746":"features=[\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\",\"capital-loss\", \"hours-per-week\", \"native-country\", \"class\"]\ndf = pd.read_csv(\"\/kaggle\/input\/adult-incomes-in-the-united-states\/adult.data\", names=features)\ny = df[\"class\"]\nX = df.drop([\"class\"], axis=1)\n\ntrain_X, val_X, train_y, val_y = train_test_split(X, y, test_size=0.2, random_state=1)","93de4fbd":"train_X.isna().sum()","96b4c283":"train_X = train_X.drop([\"fnlwgt\"],axis=1)\nval_X = val_X.drop([\"fnlwgt\"],axis=1)","54c5b901":"high_cardinality = [col for col in train_X.columns if train_X[col].nunique() > 25]\nhigh_cardinality","ae113b4c":"train_X = train_X.drop([\"native-country\"],axis=1)\nval_X = val_X.drop([\"native-country\"],axis=1)","9cb77f2c":"train_X = pd.get_dummies(train_X, prefix_sep='_', drop_first=True)\nval_X = pd.get_dummies(val_X, prefix_sep='_', drop_first=True)\ntrain_X.columns","ae6796bd":"train_y = pd.Series(np.where(train_y.values == ' >50K', 1, 0), train_y.index)\nval_y = pd.Series(np.where(val_y.values == ' >50K', 1, 0), val_y.index)","b5dfa96e":"train_y.value_counts()","fbb63375":"my_model = XGBClassifier()\n\nmy_model.fit(train_X, train_y,  \n             early_stopping_rounds=5,  \n             eval_set=[(val_X, val_y)], \n             eval_metric=\"auc\",\n             verbose=False)","33f11e92":"lr_probs = my_model.predict_proba(val_X)\nlr_probs = lr_probs[:, 1]\nyhat = my_model.predict(val_X)\nlr_precision, lr_recall, _ = precision_recall_curve(val_y, lr_probs)\nlr_f1, lr_auc = f1_score(val_y, yhat), auc(lr_recall, lr_precision)\nprint('XGBoost: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\nno_skill = len(val_y[val_y==1]) \/ len(val_y)\npyplot.plot([0, 1], [no_skill, no_skill], linestyle='-', label='No Skill')\npyplot.plot(lr_recall, lr_precision, marker='.', label='GXBoost')\npyplot.xlabel('Recall')\npyplot.ylabel('Precision')\npyplot.legend()\npyplot.show()","5084ffee":"ns_probs = [0 for _ in range(len(val_y))]\nns_auc = roc_auc_score(val_y, ns_probs)\nlr_auc = roc_auc_score(val_y, lr_probs)\nprint('No Skill: ROC AUC=%.3f' % (ns_auc))\nprint('XGBoost: ROC AUC=%.3f' % (lr_auc))\nns_fpr, ns_tpr, _ = roc_curve(val_y, ns_probs)\nlr_fpr, lr_tpr, _ = roc_curve(val_y, lr_probs)\npyplot.plot(ns_fpr, ns_tpr, linestyle='-', label='No Skill')\npyplot.plot(lr_fpr, lr_tpr, marker='.', label='XGBoost')\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.legend()\npyplot.show()","5f032f3f":"perm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y) \nshow_weights(perm, feature_names = val_X.columns.tolist()) ","a86cb690":"import shap\nexplainer = shap.TreeExplainer(my_model) \nshap_values = explainer.shap_values(val_X) \nshap.summary_plot(shap_values, val_X) ","b11e0c8f":"shap.dependence_plot('capital-gain', shap_values, val_X, interaction_index='capital-loss') ","1df905b4":"shap.dependence_plot('capital-gain', shap_values, val_X, interaction_index='marital-status_ Married-civ-spouse') ","e038d0e2":"#for col in train_X.columns:\n#    shap.dependence_plot('capital-gain', shap_values, val_X, interaction_index=col) ","40a0de2a":"shap.dependence_plot('capital-loss', shap_values, val_X, interaction_index=\"occupation_ Exec-managerial\")","e31473d6":"shap.dependence_plot('capital-gain', shap_values, val_X, interaction_index=\"occupation_ Exec-managerial\")","1f29aead":"train = train_X[[\"age\",\"capital-gain\",\"capital-loss\",\"education-num\", \"hours-per-week\",\"occupation_ Exec-managerial\", \"marital-status_ Married-civ-spouse\"]]\ncorrelations = train.corr()\nfig, ax = pyplot.subplots(figsize=(10,10))\nsns.heatmap(correlations,vmax=1.0, center=0, fmt='.2f',square=True, linewidths=.5, annot=True, cbar_kws={\"shrink\": .70})\npyplot.show();","d97335ff":"\"\"\"\noccup_cols= ['occupation_ Adm-clerical',\n       'occupation_ Armed-Forces', 'occupation_ Craft-repair',\n       'occupation_ Exec-managerial', 'occupation_ Farming-fishing',\n       'occupation_ Handlers-cleaners', 'occupation_ Machine-op-inspct',\n       'occupation_ Other-service', 'occupation_ Priv-house-serv',\n       'occupation_ Prof-specialty', 'occupation_ Protective-serv',\n       'occupation_ Sales', 'occupation_ Tech-support',\n       'occupation_ Transport-moving']\nexe_mang_income = pd.concat([train_y, train_X[occup_cols]], axis=1)\nexe_mang_income.columns = ['Income >50K', 'occupation_ Adm-clerical',\n       'occupation_ Armed-Forces', 'occupation_ Craft-repair',\n       'occupation_ Exec-managerial', 'occupation_ Farming-fishing',\n       'occupation_ Handlers-cleaners', 'occupation_ Machine-op-inspct',\n       'occupation_ Other-service', 'occupation_ Priv-house-serv',\n       'occupation_ Prof-specialty', 'occupation_ Protective-serv',\n       'occupation_ Sales', 'occupation_ Tech-support',\n       'occupation_ Transport-moving']\n\nfor col in occup_cols:\n    sns.countplot(x = col, hue=\"Income >50K\", data=exe_mang_income)\n    pyplot.show()\n\"\"\"\ncols_of_interest=[\"occupation_ Exec-managerial\",\"marital-status_ Married-civ-spouse\"]\nexe_mang_income = pd.concat([train_y, train_X[cols_of_interest]], axis=1)\nexe_mang_income.columns = ['Income >50K','occupation_ Exec-managerial', \"marital-status_ Married-civ-spouse\"]\nfor col in cols_of_interest:\n    sns.countplot(x=col, hue=\"Income >50K\", data=exe_mang_income)\n    pyplot.show()\n","cdee1e3d":"data_for_prediction = val_X.iloc[:100, :] \nshap_values = explainer.shap_values(data_for_prediction)\nshap.initjs()\nshap.force_plot(explainer.expected_value, shap_values, data_for_prediction)","a03f2844":"data_for_prediction = val_X.iloc[34, :] \nshap_values = explainer.shap_values(data_for_prediction)\nshap.initjs()\nshap.force_plot(explainer.expected_value, shap_values, data_for_prediction)","9908eac3":"## Investigation\n","e99b7c1f":"It seems that having a larger gain on capital investments is a large contributor to earning above $50,000 in annual income.\n\nInterestingly, being married is also an important factor in determining higher-income classification. This could be because those who are married or have a partner can make bigger investments and thus bigger returns on capital.\n\nAge and number of years of education are also important features, this makes sense as more years spent educating yourself typically leads to earning a higher wage. In addition, the older you become, the more likely you are to receive a higher income.\n\nCapital-loss is also an important feature that will need to be investigated further.\n\nFinally, we can see hours-per-week is also an important factor.\n\nWe will now look at a SHAP summary plot:\n\n\n","0aaed921":"So we have a model that looks reasonable by these two metrics, area under the receiver operating characteristic and precision recall curves.","e7558a1d":"## Encoding Categorical Data","01c4ae28":"## Building the Model","bed3b735":"There are no significant correlations between these variables. Please fork the notebook yourself to view some comparison statistics on those in different occupations earning above and below 50K to see if Exec-managerial staff earn more. I will show the plot for those earning above and below 50K working in both Exec-managerial roles and other industries.\n","2a84f406":"## Check for missing data","083385ba":"## Conclusion\n\nThe dataset is very old, though it does seem to give some interesting insights. Capital gains, being married and the number of years of education are the most important factors. Though more investigation should be conducted to see if these have a correlation. It would also be interesting to see if these findings are present in current datasets.\n\nThis is my first submission to Kaggle, any feedback on the interpretation and\/or modelling would be much appreciated.","0837e5dd":"Those who are married or in a civil partnership who make capital gains have a positive and negative effect on our prediction. However, it is interesting that a large number of those who make 100,000 in capital gains are also married.\n\n","5d23a487":"Here we see the driving factor as `capital-gain`, which is much larger than years of education, the factor with the second largest effect. Of interest is also that the capital gain is only $7,688, which is relatively small.","ff57dfcd":"The column `fnlwgt` is an estimation of the number of people this data point represents. We will remove it as previous investigations have found it has little to no effect on machine learning models. \n","e3490f46":"On the far right at x=95, we see a prediction change from our baseline of 7.15. Lets view this prediction in isolation.","b31b867d":"We shall first look at Permuatation Importance figues as a start.","3c31ac27":"Above we see exec-managerial staff have the highest number of people earning above 50K, however that number is still below 2500 and there is an equal number of people in the same industry earning under 50K. \n\nSo there is a higher number of people earning larger salaries in the Exec-managerial industry, but working in that industry doesn't guarantee you will be earning above 50K.\n\nThere is a significantly larger amount of people who are married and make above 50K, roughly 5000, than compared to those who are not married and make above 50K, approximately 1000. So we could say that those who are married are more likely to earn over 50K however it is not for certain.\n\nThe last thing I will look at will the SHAP values of 100 rows and choose an interesting prediction to see the effects of each feature on it. ","0db14c2f":"It seems there is no relation between those making capital gains and losses.\n\nCuriously, values above only 10,000 in capital gains have a positive effect on our prediction.\n\nHowever, it  is fascinating that some capital gains below 20,000 had a more positive effect on the prediction than making 100,000 in capital gains.\nIn addition, those only making small capital gains have less of a chance of making over 50K a year.\n\nI will search for an interaction between `capital gain` and other features.\nPlease fork the notebook to see if I've missed anything interesting.","032745f5":"It is clear making small capital gains doesn't affect the prediction of higher-income earners, however, high capital gain increases the prediction by a considerable margin, though in some cases, the opposite effect is observed.\n\n`capital-loss` shows us something similar, in that your income is also likely to be higher if you make large losses on investments. This could be data from the same people, making lots of large investments that go up, and down. Further investigation is needed.\n\nBeing married or in a partnership compared to other relationship statuses also seems to have an equal effect however in opposite directions.\n\nAge has a very negative effect on our prediction, but only if you are young. From middle-age to retirement, the change in prediction is not as strong.\n\n","0869c2a0":"# How to earn over $50K  a year in the US\nAn investigation into predicting high-income earners.\n\nThis notebook develops an XGBoost Classifier model on the data set \"Adult Incomes in the United States\". Then investigates the effect of each feature on predicting if someone earns over $50K annually.\nThis data is old and needed almost no cleaning. However, I believe the insights are extensive.\n","f6be165b":"## Importing the data\nThe data is contained in a .data, which is still readable by the panda's method `.read_csv` though the features are not included in the file.","bda609cd":"## Evaluating the Model","2241d0de":"It seems like those in executive managerial roles, mostly have capital-gains above 10,000 and have a more positive effect on our prediction. Similarily their capital losses, for the most part, have a positive SHAP value. Lets further investigate if there is a correlation between this occupation and our other continuous variables.\n\nInterestingly there is a lot of noise in our `capital-loss` SHAP value distribution plot, meaning that another variable is interacting with it. Further investigation is needed here as well.","8a4c1c8b":"We will remove `native-country` as it has a large cardinality, the other columns above are numerical."}}