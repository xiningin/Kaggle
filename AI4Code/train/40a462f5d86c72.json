{"cell_type":{"b9b9b43f":"code","289135ae":"code","4c2291b3":"code","344e1099":"code","df815c5b":"code","31300a57":"code","8e5998ec":"code","8dbba413":"code","ceabd601":"code","48221cf9":"code","16bb24a0":"code","99ad0413":"code","9c317516":"code","75188f04":"code","0a1b2a80":"code","026f6a4e":"code","509d5e76":"markdown","6cc6e971":"markdown","f67e51be":"markdown","bb102bc4":"markdown","811f5dc6":"markdown","2c644485":"markdown","7fb46bfc":"markdown","4f975855":"markdown","56d09a41":"markdown","fe9d4ade":"markdown","3c72e1cf":"markdown","2feb3054":"markdown","9b0d3159":"markdown"},"source":{"b9b9b43f":"# Upgrade Packages\n!pip install --upgrade pip -q\n!pip install -U tensorflow==2.3 -q","289135ae":"# Libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os, gc, warnings, pathlib\nwarnings.filterwarnings(\"ignore\")\n\nimport PIL.Image as Image\n\nimport tensorflow as tf\nimport matplotlib.pylab as plt\nimport tensorflow_hub as hub\nfrom tensorflow.keras import layers\nfrom tensorflow import keras\n","4c2291b3":"print(\"TensorFlow Version Used: \",tf.__version__)","344e1099":"#  Image Paths\npath = '..\/input\/random-image-for-testing-classification\/'\nrndm_flowers_path = '..\/input\/random-image-for-testing-classification\/flowers\/'","df815c5b":"# Classifier (TensorFlow Hub URL)\nclass_url = 'https:\/\/tfhub.dev\/google\/tf2-preview\/inception_v3\/classification\/4'\n\nlabels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https:\/\/storage.googleapis.com\/download.tensorflow.org\/data\/ImageNetLabels.txt')\nimagenet_labels = np.array(open(labels_path).read().splitlines())","31300a57":"# Image Size\nimage_shape = (299,299)\n\n# Classifier \nclassifier = tf.keras.Sequential([hub.KerasLayer(class_url, input_shape=image_shape+(3,)) ])\n\n# Making a Prediction with Pre-trained Model\nimg_url = path + 'flower.jpg'\nimg = Image.open(img_url).resize(image_shape)\nimg = np.array(img)\/ 255.0\n\nresult = classifier.predict(img[np.newaxis, ...])\npredicted_class = np.argmax(result[0], axis=-1)\nplt.imshow(img)\nplt.axis('off')\npredicted_class_name = imagenet_labels[predicted_class]\n_ = plt.title(\"Prediction: \" + predicted_class_name.title())","8e5998ec":"# example of loading the inception v3 model\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.applications.inception_v3 import preprocess_input\nfrom keras.applications.inception_v3 import decode_predictions\n\n# load model\nmodel = InceptionV3()\n\n# load an image from file\nimg_url = path + 'flower.jpg'\nimg = load_img(img_url, target_size = image_shape)\n# convert the image pixels to a numpy array\nimg = np.array(img)\n# reshape data for the model\nimg = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n# prepare the image for the Inception v3 model\nimg = preprocess_input(img)\n\n# predict the probability across all output classes\npred = model.predict(img)\n\n# convert the probabilities to class labels\nlabel = decode_predictions(pred)\n\n# retrieve the most likely result, e.g. highest probability\nlabel = label[0][0]\n\n# Show the Predicted Class\nplt.imshow(Image.open(img_url).resize(image_shape))\nplt.axis('off')\n_ = plt.title(\"Prediction: \" + label[1] + \" (\"+'{:.2%}'.format(label[2])+\")\")\n\n#print('%s (%.2f%%)' % (label[1], label[2]*100))","8dbba413":"# -- Using a Pre-trained model to classify a random flower image.\n\nflower_name = 'tulip'   #choose from dandelion,rose,sunflower,tulip \n\nrndm_img_url = rndm_flowers_path + flower_name + '.jpg'\nrndm_img = Image.open(rndm_img_url).resize(image_shape)\nrndm_img = np.array(rndm_img)\/ 255.0\n\nresult = classifier.predict(rndm_img[np.newaxis, ...])\npredicted_class = np.argmax(result[0], axis=-1)\nplt.imshow(rndm_img)\nplt.axis('off')\npredicted_class_name = imagenet_labels[predicted_class]\n_ = plt.title(\"Prediction: \" + predicted_class_name.title())","ceabd601":"# Load Dataset\ndataset_url = \"https:\/\/storage.googleapis.com\/download.tensorflow.org\/example_images\/flower_photos.tgz\"\n\nimg_dir = tf.keras.utils.get_file(origin=dataset_url,fname='flower_photos',untar= True)\nimg_dir = pathlib.Path(img_dir)\n\n# Image Count\nprint(\"Total Images Downloaded: \", len(list(img_dir.glob('*\/*.jpg'))))","48221cf9":"img_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1\/255)\nimage_data = img_gen.flow_from_directory(str(img_dir), target_size=image_shape)","16bb24a0":"for image_batch, label_batch in image_data:\n    print(\"Image batch shape: \", image_batch.shape)\n    print(\"Label batch shape: \", label_batch.shape)\n    break","99ad0413":"# Feature Extractor URL\nfe_url = 'https:\/\/tfhub.dev\/google\/tf2-preview\/inception_v3\/feature_vector\/4'\n\n# Feature Extractor Layer\nfe_layer = hub.KerasLayer(fe_url, input_shape=image_shape+(3,))\n\nfeature_batch = fe_layer(image_batch)\n#print(feature_batch.shape)\n\n# Freezing the feature extractor layer,so the training only modifies the new classifier layer.\nfe_layer.trainable = False\n\n#Adding a Classification Layer\nmodel = tf.keras.Sequential([\n        fe_layer,\n        layers.Dense(image_data.num_classes)])\n\n\n# Model Summary\nmodel.summary()","9c317516":"# Compile Model\nmodel.compile(optimizer=tf.keras.optimizers.Adam(), \n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n              metrics=['acc'])\n\n# Custom Callback for Visualization\nclass CollectBatchStats(tf.keras.callbacks.Callback):\n    def __init__(self):\n        self.batch_losses = []\n        self.batch_acc = []\n\n    def on_train_batch_end(self, batch, logs=None):\n        self.batch_losses.append(logs['loss'])\n        self.batch_acc.append(logs['acc'])\n        self.model.reset_metrics()","75188f04":"# Fit \/ Train the Model\nepoch = 10\nsteps = np.ceil(image_data.samples\/image_data.batch_size)\n\ncallbacks = CollectBatchStats()\n\nhistory = model.fit(image_data, epochs=epoch,\n                   steps_per_epoch=steps,\n                   callbacks=[callbacks],\n                   verbose=-1)\n\n# Plotting the Chart\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,10))\n#fig.suptitle('Loss & Accuracy Plot')\n#plt.figure()\nax1.plot(callbacks.batch_losses)\nax1.set_title(\"Loss vs Training Steps\")\nax1.set_ylabel(\"Loss\")\nax1.set_xlabel(\"Training Steps\")\nax1.set_ylim([0,2])\n\nax2.plot(callbacks.batch_acc)\nax2.set_title(\"Accuracy vs Training Steps\")\nax2.set_ylabel(\"Accuracy\")\nax2.set_xlabel(\"Training Steps\")\nax2.set_ylim([0,1])","0a1b2a80":"#Random Unseen Flowers Path\n\n\nflower_name = 'tulip'   #choose from dandelion,rose,sunflower,tulip \n\n\nrndm_img_url = rndm_flowers_path + flower_name + '.jpg'\nrndm_img = Image.open(rndm_img_url).resize(image_shape)\nrndm_img = np.array(rndm_img)\/ 255.0\n\nclass_names = sorted(image_data.class_indices.items(), key=lambda pair:pair[1])\nclass_names = np.array([key.title() for key, value in class_names])\n\nresult = model.predict(rndm_img[np.newaxis, ...])\npred_id = np.argmax(result[0], axis=-1)\nplt.imshow(rndm_img)\nplt.axis('off')\npred_label = class_names[pred_id]\n\n_ = plt.title(\"Prediction: \" + pred_label.title() )","026f6a4e":"# Saving the Model\nmodel.save('.\/',save_format='tf')","509d5e76":"## I hope this tutorial has helped you in understanding the Transfer Learning with Pre-trained Models. Please do consider it to UPVOTE, it means a lot to me :-).","6cc6e971":"# Image Classification - Transfer Learning (Tutorial)\n\nIn this notebook, we shall learning about performing an Image Classification using a pre-trained Model. Using a pre-trained model shortens the whole process. We can re-use the model weights from pre-trained models that were developed for standard computer vision benchmark datasets, such as the ImageNet image recognition tasks\n\nTechnically, Transfer learning generally refers to a process where a model trained on one problem is used in some way on a second related problem. In deep learning, transfer learning is a technique whereby a neural network model is first trained on a problem similar to the problem that is being solved. One or more layers from the trained model are then used in a new model trained on the problem of interest. Transfer learning has the benefit of decreasing the training time for a neural network model and can result in lower generalization error\n\nSo without further ado lets dive directly into the practicals.\n","f67e51be":"As we can observe, our pre-trained model's prediction isn't perfect (Its a Tulip). We shall now have a look at **Pre-Trained Model as Feature Extractor** where we will use the **Inception v3 Feature Extractor Model** , train it on the Flower Dataset & make a prediction on the same Flower Image.","bb102bc4":"Now before moving on to the **Model as feature-extractor** let us see if our pre-trained model (Inception V3) can classify a random flower image other than daisy.\n","811f5dc6":"## From Keras","2c644485":"# Pre-Trained Model as Classifier\n\nA pre-trained model can be used directly to classify new photographs as exemplified below. There are 2 ways to approach this\n\n1. From TensorFlow Hub\n2. From Keras\n\nWe shall use the Inception v3 model which was first developed for GoogleNet Model. The model expects color images to have the square shape 299\u00d7299. This model has been trained on ImageNet & hence we will be using the Imagenet Labels for the model from TensorFlow Hub.","7fb46bfc":"# Pre-Trained Model as Feature Extractor\n\nSo keep with theme of flowers, we shall now proceed with training the feature-extractor model on the [Flowers dataset] wi(https:\/\/www.tensorflow.org\/tutorials\/load_data\/images) from TensorFlow to learn about **Transfer Learning**","4f975855":"![](https:\/\/static.helpjuice.com\/helpjuice_production\/uploads\/upload\/image\/4752\/direct\/1558476946633-Knowledge%20Transfer.jpg)> ","56d09a41":"The Model needs to be trained on the classes in the Flower Dataset.  The good thing is that TensorFlow Hub also distributes models without the top classification layer. These can be used to easily do transfer learning. \n\nThese models can be found under the [Image Feature Vector Domain](https:\/\/tfhub.dev\/s?module-type=image-feature-vector) on TensorFlow Hub.\n\nKeeping with the same Model, we will be using the [inception_v3\/feature_vector](https:\/\/tfhub.dev\/google\/tf2-preview\/inception_v3\/feature_vector\/4) from TensorFlow Hub.","fe9d4ade":"### As we can observe, our newly trained Model is correctly predicting the class of an unseen random image. And this is how we can use a pre-trained model as a feature-extractor for Image Classification using Transfer Learning.","3c72e1cf":"## Predictions","2feb3054":"## From TensorFlow Hub","9b0d3159":"### UPDATED - 13\/08"}}