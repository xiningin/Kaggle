{"cell_type":{"7718b9b9":"code","8d5a5802":"code","46134a96":"code","fd5008fc":"code","5ac6679c":"code","cc8c2012":"code","bbcc0b2a":"code","2ba85dfb":"code","157f2097":"code","e18cf79c":"code","867af131":"code","b1a74c03":"code","d6d46b32":"code","656adca0":"code","008aa03e":"code","f1a2eb95":"code","d6fcb357":"code","8755dc46":"code","36b95875":"code","f3473a19":"code","cb6ce9ab":"code","90f53b32":"code","a5a01399":"code","8a02b846":"code","ffdaeb9f":"code","c208473f":"code","1f8193e9":"code","736a704e":"code","0205227d":"code","0a51339a":"markdown","75e07172":"markdown","2b08ef01":"markdown","eecd5b11":"markdown","53ac6384":"markdown","4c646f8e":"markdown","1378e0e1":"markdown","0662dde7":"markdown","2f464af5":"markdown","6b2ffd43":"markdown","f33fafdb":"markdown","b598aa7e":"markdown","9472d49b":"markdown","d6e095f7":"markdown","218cfb06":"markdown"},"source":{"7718b9b9":"import os\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport cv2 as cv\nfrom numpy.random import seed\nseed(45)\nimport pickle\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom glob import glob \n%matplotlib inline","8d5a5802":"train_dirname = '\/kaggle\/input\/histopathologic-cancer-detection\/train'","46134a96":"train_labels = pd.read_csv('\/kaggle\/input\/histopathologic-cancer-detection\/train_labels.csv')\ntrain_labels.head()","fd5008fc":"train_labels['label'].value_counts()","5ac6679c":"# Display a DataFrame showing the proportion of observations with each \n# possible of the target variable (which is label). \n(train_labels.label.value_counts() \/ len(train_labels)).to_frame()","cc8c2012":"train_labels.info()","bbcc0b2a":"positive_samples = train_labels.loc[train_labels['label'] == 1].sample(4)\nnegative_samples = train_labels.loc[train_labels['label'] == 0].sample(4)\npositive_images = []\nnegative_images = []\nfor sample in positive_samples['id']:\n    path = os.path.join(train_dirname, sample+'.tif')\n    img = cv.imread(path)\n    positive_images.append(img)\n        \nfor sample in negative_samples['id']:\n    path = os.path.join(train_dirname, sample+'.tif')\n    img = cv.imread(path)\n    negative_images.append(img)\n\nfig,axis = plt.subplots(2,4,figsize=(20,8))\nfig.suptitle('Dataset samples presentation plot',fontsize=20)\nfor i,img in enumerate(positive_images):\n    axis[0,i].imshow(img)\n    rect = patches.Rectangle((32,32),32,32,linewidth=4,edgecolor='g',facecolor='none', linestyle=':', capstyle='round')\n    axis[0,i].add_patch(rect)\naxis[0,0].set_ylabel('Positive samples', size='large')\nfor i,img in enumerate(negative_images):\n    axis[1,i].imshow(img)\n    rect = patches.Rectangle((32,32),32,32,linewidth=4,edgecolor='r',facecolor='none', linestyle=':', capstyle='round')\n    axis[1,i].add_patch(rect)\naxis[1,0].set_ylabel('Negative samples', size='large')\n    ","2ba85dfb":"IMG_SIZE = 96\nIMG_CHANNELS = 3\n#TRAIN_SIZE=80000\nTRAIN_SIZE = 10000\nBATCH_SIZE = 128\nEPOCHS = 30","157f2097":"train_neg = train_labels[train_labels['label']==0].sample(TRAIN_SIZE,random_state=45)\ntrain_pos = train_labels[train_labels['label']==1].sample(TRAIN_SIZE,random_state=45)\n\ntrain_data = pd.concat([train_neg, train_pos], axis=0).reset_index(drop=True)\n\ntrain_data = shuffle(train_data)","e18cf79c":"train_data['label'].value_counts()","867af131":"def append_ext(fn):\n    return fn+\".tif\"","b1a74c03":"#y = train_data['label']\n#train_df, val_df = train_test_split(train_data, test_size=0.3, random_state=45, stratify=y)\n#y = val_df['label']\n#val_df, test_df = train_test_split(val_df, test_size=0.5, random_state=45, stratify=y)\n#print(train_df.shape)\n#print(val_df.shape)\n#print(test_df.shape)","d6d46b32":"y = train_data['label']\ntrain_df, valid_df = train_test_split(train_data, test_size=0.2, random_state=45, stratify=y)\n\nprint(train_df.shape)\nprint(valid_df.shape)","656adca0":"train_df['id'] = train_df['id'].apply(append_ext)\nvalid_df['id'] = valid_df['id'].apply(append_ext)\ntrain_df.head()","008aa03e":"## add image augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale = 1\/255, \n    rotation_range = 45,\n    width_shift_range = 0.2, \n    height_shift_range = 0.2, \n    shear_range = 0.2, \n    zoom_range = 0.2, \n    horizontal_flip = True, \n    vertical_flip = True \n)\nvalid_datagen = ImageDataGenerator(rescale=1\/255)","f1a2eb95":"BATCH_SIZE = 128\ntrain_path = '..\/input\/histopathologic-cancer-detection\/train'\ntrain_df['label'] = train_df['label'].astype(str)\nvalid_df['label'] = valid_df['label'].astype(str)\n\ntrain_loader = train_datagen.flow_from_dataframe(\n    dataframe = train_df,\n    directory = train_path,\n    x_col = 'id',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (32,32)\n)\n\nvalid_loader = valid_datagen.flow_from_dataframe(\n    dataframe = valid_df,\n    directory = train_path,\n    x_col = 'id',\n    y_col = 'label',\n    batch_size = BATCH_SIZE,\n    seed = 1,\n    shuffle = True,\n    class_mode = 'categorical',\n    target_size = (32,32)\n)","d6fcb357":"TR_STEPS = len(train_loader)\nVA_STEPS = len(valid_loader)\n\nprint(TR_STEPS)\nprint(VA_STEPS)","8755dc46":"cnn = Sequential([\n    Conv2D(16, (3,3), activation = 'relu', padding = 'same', input_shape=(32,32,3)),\n    Conv2D(16, (3,3), activation = 'relu', padding = 'same'),\n    Conv2D(16, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.25),\n    BatchNormalization(),\n\n    Conv2D(32, (3,3), activation = 'relu', padding = 'same'),\n    Conv2D(32, (3,3), activation = 'relu', padding = 'same'),\n    Conv2D(32, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.5),\n    BatchNormalization(),\n\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n    Conv2D(64, (3,3), activation = 'relu', padding = 'same'),\n    MaxPooling2D(2,2),\n    Dropout(0.5),\n    BatchNormalization(),\n    \n    Flatten(),\n    \n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(32, activation='relu'),\n    Dropout(0.5),\n    Dense(8, activation='relu'),\n    Dropout(0.25),\n    BatchNormalization(),\n    Dense(2, activation='softmax')\n])\n\ncnn.summary()","36b95875":"opt = tf.keras.optimizers.Adam(0.001)\ncnn.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy', tf.keras.metrics.AUC()])","f3473a19":"%%time \n\nh1 = cnn.fit(\n    x = train_loader, \n    steps_per_epoch = TR_STEPS, \n    epochs = 30,\n    validation_data = valid_loader, \n    validation_steps = VA_STEPS, \n    verbose = 1\n)","cb6ce9ab":"history = h1.history\nprint(history.keys())","90f53b32":"epoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,3,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,3,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.subplot(1,3,3)\nplt.plot(epoch_range, history['auc'], label='Training')\nplt.plot(epoch_range, history['val_auc'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\nplt.legend()\nplt.tight_layout()\nplt.show()","a5a01399":"#Training Run 2\ntf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.0001)","8a02b846":"%%time \n\nh2 = cnn.fit(\n    x = train_loader, \n    steps_per_epoch = TR_STEPS, \n    epochs = 30,\n    validation_data = valid_loader, \n    validation_steps = VA_STEPS, \n    verbose = 1\n)","ffdaeb9f":"for k in history.keys():\n    history[k] += h2.history[k]\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,3,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,3,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.subplot(1,3,3)\nplt.plot(epoch_range, history['auc'], label='Training')\nplt.plot(epoch_range, history['val_auc'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\nplt.legend()\nplt.tight_layout()\nplt.show()","c208473f":"#Training Run 3\ntf.keras.backend.set_value(cnn.optimizer.learning_rate, 0.00001)","1f8193e9":"%%time \n\nh3 = cnn.fit(\n    x = train_loader, \n    steps_per_epoch = TR_STEPS, \n    epochs = 30,\n    validation_data = valid_loader, \n    validation_steps = VA_STEPS, \n    verbose = 1\n)","736a704e":"for k in history.keys():\n    history[k] += h3.history[k]\n\nepoch_range = range(1, len(history['loss'])+1)\n\nplt.figure(figsize=[14,4])\nplt.subplot(1,3,1)\nplt.plot(epoch_range, history['loss'], label='Training')\nplt.plot(epoch_range, history['val_loss'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Loss')\nplt.legend()\nplt.subplot(1,3,2)\nplt.plot(epoch_range, history['accuracy'], label='Training')\nplt.plot(epoch_range, history['val_accuracy'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy')\nplt.legend()\nplt.subplot(1,3,3)\nplt.plot(epoch_range, history['auc'], label='Training')\nplt.plot(epoch_range, history['val_auc'], label='Validation')\nplt.xlabel('Epoch'); plt.ylabel('AUC'); plt.title('AUC')\nplt.legend()\nplt.tight_layout()\nplt.show()","0205227d":"cnn.save('cancer_detection_model_v03.h5')\npickle.dump(history, open(f'cancer_detection_history_v03.pkl', 'wb'))","0a51339a":"# Setting up learning constants","75e07172":"## ","2b08ef01":"Data is not entirely balanced, there is more negative samples than positive, by about 30 percent","eecd5b11":"## Create a simple model","53ac6384":"## Training Run 1","4c646f8e":"## Balancing the dataset","1378e0e1":"### Create image generators for MobileNetV2","0662dde7":"### Save Model and History","2f464af5":"# View Sample Images","6b2ffd43":"## Splitting the dataset","f33fafdb":"# Splitting dataset","b598aa7e":"# Dataset exploration","9472d49b":"## Train Network","d6e095f7":"# Label distribution","218cfb06":"## Image generators for the simple CNN model"}}