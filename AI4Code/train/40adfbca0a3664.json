{"cell_type":{"e0b2772b":"code","9383678b":"code","14f8f4ef":"code","6240f8df":"code","8bf34ea3":"code","1f83832d":"code","90fd63f5":"code","4445a697":"code","517cbce9":"code","dbe59bcc":"code","3929a835":"code","4e20cf28":"code","c3c2423b":"code","67c3711e":"code","af1cdb09":"code","0247d3bf":"markdown","e6b06028":"markdown"},"source":{"e0b2772b":"# Necessary imports\n\n## Data loading, processing and for more\nimport pandas as pd\nimport numpy as np\nfrom imblearn.over_sampling import SMOTE\n\n## Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# set seaborn style because it prettier\nsns.set()\n\n## Metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import roc_curve, auc\n\n## Models\nimport xgboost as xgb\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.preprocessing import StandardScaler","9383678b":"# Find out the paths of the datasets\nimport os\nfor dirname, _, filenames in os.walk('..\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","14f8f4ef":"# read the data and show first 5 rows\ndata = pd.read_csv(\"..\/input\/banksim1\/bs140513_032310.csv\")\ndata.head(5)","6240f8df":"# dropping zipcodeori and zipMerchant since they have only one unique value\ndata_reduced = data.drop(['zipcodeOri','zipMerchant'],axis=1)","8bf34ea3":"# turning object columns type to categorical for easing the transformation process\ncol_categorical = data_reduced.select_dtypes(include= ['object']).columns\nfor col in col_categorical:\n    data_reduced[col] = data_reduced[col].astype('category')\n# categorical values ==> numeric values\ndata_reduced[col_categorical] = data_reduced[col_categorical].apply(lambda x: x.cat.codes)\n\n# add transaction_id\ndata_reduced['transaction_id'] = np.arange(len(data_reduced))+1\n\ndata_reduced.head(5)","1f83832d":"X = data_reduced.drop(['fraud'],axis=1)\ny = data['fraud']\nprint(X.head(),\"\\n\")\nprint(y.head())","90fd63f5":"# Data is highly imbalanced. Use resampling technique.\nsm = SMOTE(random_state=42)\nX_res, y_res = sm.fit_resample(X, y)\ny_res = pd.DataFrame(y_res)\nprint(y_res[0].value_counts())","4445a697":"# %% Random Forest Classifier\n# only training set\n\nrf_clf = RandomForestClassifier(n_estimators=100,max_depth=8,random_state=42,\n                                verbose=1,class_weight=\"balanced\")\n\nrf_clf.fit(X_res,y_res)\ny_pred = rf_clf.predict(X_res)\n\nprint(\"Classification Report for Random Forest Classifier: \\n\", classification_report(y_res, y_pred))\nprint(\"Confusion Matrix of Random Forest Classifier: \\n\", confusion_matrix(y_res,y_pred))","517cbce9":"# See importance of the features\nX_res = pd.DataFrame(StandardScaler().fit_transform(X_res), columns=X.columns)\nfeature_importances = pd.DataFrame(rf_clf.feature_importances_,\n                                   index = X_res.columns,\n                                   columns=['importance']).sort_values('importance',                                                                 \n                                   ascending=False)\nprint(feature_importances)","dbe59bcc":"# read the data and show first 5 rows\ngraph_data = pd.read_csv(\"..\/input\/trans-9-30\/Transaction.csv\")\ngraph_data.head(5)","3929a835":"# drop columns already in data_reduce df\ngraph_data = graph_data.drop(['fraud','category', 'amount', 'c_age_group', 'c_gender', 'time_step', \n                              'Unnamed: 20'],axis=1)\n\n# join with original data\ngraph_data = graph_data.set_index('transaction_id').join(data_reduced.set_index('transaction_id'))\n\ngraph_data = graph_data.sort_values(by=['transaction_id'])\n# drop not significant features\ngraph_data = graph_data.drop(['c_tot_diff_merchants', 'is_top_merchants_amt', 'is_top_categories_amt', 'merchant', 'gender',\n                              'is_top_merchants_cnt', 'step', 'customer', 'age', 'c_avg_num_of_transactions_per_day',\n                              'c_num_of_fraud', 'fraud_cnt_3hop', 'c_avg_num_of_diff_merchants_per_day'],axis=1)\ngraph_data.head(5)","4e20cf28":"graph_X = graph_data.drop(['fraud'],axis=1)\ngraph_y = graph_data['fraud']\nprint(graph_X.head(),\"\\n\")\nprint(graph_y.head())","c3c2423b":"sm = SMOTE(random_state=42)\ngraph_X_res, graph_y_res = sm.fit_resample(graph_X, graph_y)\ngraph_y_res = pd.DataFrame(graph_y_res)\nprint(graph_y_res[0].value_counts())","67c3711e":"# %% Random Forest Classifier\n\ngraph_rf_clf = RandomForestClassifier(n_estimators=100,max_depth=8,random_state=42,\n                                verbose=1,class_weight=\"balanced\")\n\ngraph_rf_clf.fit(graph_X_res,graph_y_res)\ngraph_y_pred = graph_rf_clf.predict(graph_X_res)\nprint(\"Classification Report for Random Forest Classifier: \\n\", classification_report(y_res, y_pred))\nprint(\"Confusion Matrix of Random Forest Classifier: \\n\", confusion_matrix(y_res,y_pred))","af1cdb09":"# See importance of the features\ngraph_X_res = pd.DataFrame(StandardScaler().fit_transform(graph_X_res), columns=graph_X.columns)\nfeature_importances = pd.DataFrame(graph_rf_clf.feature_importances_,\n                                   index = graph_X_res.columns,\n                                   columns=['importance']).sort_values('importance',                                                                 \n                                   ascending=False)\nprint(feature_importances)","0247d3bf":"### Training with graph features","e6b06028":"## Training without graph features"}}