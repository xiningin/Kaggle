{"cell_type":{"434ad4c6":"code","dedec72c":"code","fbe85fcd":"code","d8ea387b":"code","db621b2a":"code","82752cd4":"code","50039fbb":"code","eb2f0b0e":"code","bac7dd11":"code","d95206f2":"code","9c66bd5a":"code","f2e96831":"code","c93d67ad":"markdown","e1ae11dd":"markdown"},"source":{"434ad4c6":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules","dedec72c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fbe85fcd":"data = pd.read_csv('\/kaggle\/input\/store-transaction-data\/Hackathon_Working_Data.csv')","d8ea387b":"print('There are {} distinct data at Group level'.format(data['GRP'].nunique()))\nprint('There are {} distinct data at sub-Group level'.format(data['SGRP'].nunique()))\nprint('There are {} distinct data at sub-sub-Group level'.format(data['SSGRP'].nunique()))\nprint('There are {} distinct data at Company level'.format(data['CMP'].nunique()))\nprint('There are {} distinct data at Mother-Brand level'.format(data['MBRD'].nunique()))\nprint('There are {} distinct data at Brand level'.format(data['BRD'].nunique()))","db621b2a":"data_N1 = data[data['STORECODE'] == 'N1']\nprint(data_N1.shape)","82752cd4":"data_N1 = data_N1[['BILL_ID', 'QTY', 'GRP']]","50039fbb":"basket = data_N1.groupby(['BILL_ID', 'GRP'])['QTY'].sum().unstack().reset_index().fillna(0).set_index('BILL_ID')","eb2f0b0e":"def encode_unit(x):\n    if x <= 0:\n        return 0\n    if x >= 0:\n        return 1\n    \nencoded_data = basket.applymap(encode_unit)","bac7dd11":"frequent_items = apriori(encoded_data, min_support = 0.01, use_colnames = True)","d95206f2":"rules = association_rules(frequent_items, metric = 'lift', min_threshold = 0)","9c66bd5a":"store = list(data['STORECODE'].unique())\nstore","f2e96831":"for i in range(0,len(store)):\n    data_N = data[data['STORECODE'] == store[i]]\n    data_N = data_N[['BILL_ID', 'QTY', 'GRP']]\n    \n    basket = data_N.groupby(['BILL_ID', 'GRP'])['QTY'].sum().unstack().reset_index().fillna(0).set_index('BILL_ID')\n    \n    def encode_unit(x):\n        if x <= 0:\n            return 0\n        if x >= 0:\n            return 1\n    \n    encoded_data = basket.applymap(encode_unit)\n    \n    frequent_items = apriori(encoded_data, min_support = 0.01, use_colnames = True)\n    \n    rules = association_rules(frequent_items, metric = 'lift', min_threshold = 0)\n    \n    rules.to_csv('AssociationRuleforstore{}.csv'.format(store[i]))","c93d67ad":"### Data for Store N1","e1ae11dd":"### Automating Storewise Data"}}