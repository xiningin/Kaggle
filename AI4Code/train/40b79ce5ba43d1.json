{"cell_type":{"4c3d0b5d":"code","d92585ee":"code","ad9d5998":"code","cd9f28c6":"code","e21c511c":"code","9ab09d09":"code","08bc188b":"code","e9719fe7":"code","46205f20":"code","dc48a00d":"code","d364a7d1":"code","ee1f0e86":"code","8f238bd0":"code","23cce95a":"code","b061b53d":"code","57188f2f":"code","b92969b6":"code","16fbf397":"code","d2f09b73":"markdown","35975186":"markdown","7266c925":"markdown","a158b7cb":"markdown","7a2f3cc4":"markdown","bbdffdae":"markdown","899fbc3a":"markdown","2d9a8313":"markdown","0c64ceba":"markdown","f9eecfb6":"markdown","9c6cf074":"markdown","ad3bc41b":"markdown","7734869d":"markdown","d0274502":"markdown","ab5b6938":"markdown"},"source":{"4c3d0b5d":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport re\n\ntqdm.pandas()\n\nimport ftfy\nftfy.fix_text('Kaggle is a cool placee &lt;3')","d92585ee":"original_df = pd.read_csv(\"https:\/\/raw.githubusercontent.com\/Galanopoulog\/DATA607-Project-4\/master\/TextEmotion.csv\")\noriginal_df.head()","ad9d5998":"tweet = \"sooo sad i will miss you here in san diego!!!\"\noriginal_df[original_df['content'].str.lower().str.contains(tweet)]","cd9f28c6":"len(original_df['sentiment'].unique())","e21c511c":"list(original_df['sentiment'].unique())","9ab09d09":"import matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (15,5)\n\n%config InlineBackend.figure_format='retina'\n\ntitle = \"Sentiment distribution in original_df\"\noriginal_df.groupby('sentiment')['content'].count().plot.bar(color='orange', title=title);","08bc188b":"len(original_df['author'].unique())","e9719fe7":"original_df['author'].value_counts()","46205f20":"TSE_DATA = \"\/kaggle\/input\/tweet-sentiment-extraction\/\"\n\ntrain_df = pd.read_csv(TSE_DATA + \"train.csv\").dropna().reset_index(drop=True)\ntest_df = pd.read_csv(TSE_DATA + \"test.csv\")","dc48a00d":"size_private_df = original_df.shape[0] - train_df.shape[0] - test_df.shape[0]\nsize_private_df","d364a7d1":"test_df.shape[0] \/ 30 * 70","ee1f0e86":"train_test_tweets = list(train_df['text'].str.lower()) + list(test_df['text'].str.lower())\n\ndef tweet_in_private(content):\n    for tweet in train_test_tweets:\n        if tweet in content:\n            return False\n    return True\n\noriginal_df['content'] = original_df['content'].str.lower()\noriginal_df['in_private'] = original_df['content'].progress_apply(tweet_in_private)","8f238bd0":"original_df['in_private'].value_counts()","23cce95a":"private_df = original_df[original_df['in_private'] == True]\nprivate_df.head()","b061b53d":"private_df.shape","57188f2f":"title = \"Sentiment distribution in private_df\"\nprivate_df.groupby('sentiment')['content'].count().plot.bar(color='orange', title=title);","b92969b6":"private_df['author'].value_counts()","16fbf397":"private_df.to_csv(\"test_private_df.csv\", index=False)","d2f09b73":"_MissxMarisa_ is the most active users with 23 tweets, followed by _ChineseLearn_, _erkagarcia_ and _MiDesfileNegro_.","35975186":"It seems that the `sentiment` distributions follows somehow the distribution of the entire dataset. Nice.","7266c925":"We save the private_df in a CSV for further analysis! Now it's up to you ;)","a158b7cb":"# Original dataset and EDA\n\nDisclaimer: even if I call this dataframe `original`, I do not assure that it's exactly the one that the Challenge's authors used. For consistency, I will use the name for the rest of the notebook and I will try to prove that we can extract a subset of \"private train data\", but clearly I cannot assure anything. \n\nThe dataframe can be found at the [following github link](https:\/\/raw.githubusercontent.com\/Galanopoulog\/DATA607-Project-4\/master\/TextEmotion.csv). If you search for some of the `train_df` and `test_df` tweets, you will shortly find a correspondency.\n\nAlso, this [Github README](https:\/\/github.com\/sarnthil\/unify-emotion-datasets\/tree\/master\/datasets) provides some additional information regarding the dataset. As we already know, it has been released by an AI company called _eightfigure_. The same README has an \"official\" download link from the _eightfigure_ website (http:\/\/www.crowdflower.com\/wp-content\/uploads\/2016\/07\/text_emotion.csv) but the link is broken (for your reference: recently _eightfigure_ has been bought by another company and some links were lost)","7a2f3cc4":"### Tweet authors\n\nAmong 40k different tweets, there are 33871 different authors. This fact may also be exploited to increase the score. Note also that since the data have been randomly split into train\/public test\/private test, it may happens that tweets from the same authors **are present both in train and test datasets**. ","bbdffdae":"# Private dataset and EDA\n\nLet's analyze at our findings ...","899fbc3a":"# Conclusions and next steps\n\nThere are much more that can be done, but some groundworks have been done. In the next days, I will investigate further the creation of the dataset, for instance by trying to map all tweets and try to construct a new model with the new features.\n\nPlease, let me know your opinions and share your advice on how to improve this notebook. I put a lot of effort into it and hope you appreciated.\n\nThank you for reading; I hope you learned something !! \ud83e\udd17","2d9a8313":"### Single tweet\n\nLet's take at random a tweet from the TSE `train_df`: \"sooo sad i will miss you here in san diego!!!\" (with `textID` 549e992a42)\n\nAs we can see, the `original_df` contains the span text:","0c64ceba":"Even more interesting, we know who is the tweet `author`, hidalgoal, we have access to the hashtag, @danecook, and we have granular information information regarding the `sentiment`, sadness.\n\n### Sentiment feature\n\nIn this dataset, there are **13** sentiments: ","f9eecfb6":"### Import ftfy and other libraries\n\nIn this notebook I will use `ftfy`. I just discovered this python package some days ago and I would say it's exceptional! If you, like me, do not know it, you can check it out there [@LuminosoInsight\/python-ftfy](https:\/\/github.com\/LuminosoInsight\/python-ftfy).\n\nGiven any string, such as `Kaggle is a cool placee &lt;3`, `ftfy.fix_text()` almost magically returns:","9c6cf074":"# Construction of private test set\n\nThe `original_df` has exactly 40 thousand tweets, by simply subtracting the size of the train and test TSE datasets, we can find the private test dataset size. ","ad3bc41b":"To construct the private_test_set I tried many different things and algorithms. Finally, I picked a very simple solution that nonetheless shows great results.\n\nWe iterate over each tweet in the original_df and verify if it is present in train_df or test_df. But, since the train_df\/test_df tweets have been cleaned further, we check whether the tweet of train_df is contained in the original dataframe and not the other way around.\n\nAs you can see, the private dataset is composed of about 8000 items; a good indication that we are on the right track.","7734869d":"# Private test not that **private** afterall \ud83d\ude48\n\n\nHaving access to any information regarding the private test dataset is always useful. In this competition even more since [semi-supervised learning](https:\/\/www.kaggle.com\/c\/tweet-sentiment-extraction\/discussion\/143094) may play a decisive role.\n\nAfter some Googling, I came across the (probably) initial dataset that has been used by the author of this (atypical) Kaggle challenge.\n\nIn this notebook, starting from the found dataset, I will attempt to create the **private test dataset** and will propose some ideas on how we can use this data to enhance our models.\n\n**Clean data**\n\nI believe that this is quite an important discovery, as the found dataset **has not been processed**. In the Exploratory Data Analysis part, we will see how salient information such as hashtags and uncensured words are present in that dataset. Also, and maybe even more important, all original 13 sentiments are still present (empty, sadness, enthusiasm, neutral, worry, surprise, love, fun, hate, happiness, boredom, relief, anger).\n\n**\ud83d\udca1Ideas**\n\nAmong others, one of the main advantages we can have by using this dataset is to find a subset of the training data that better match the private dataset set and try to *overfit* a model to that data.\n\nAlso, as we will see later, the extra informations such as hahtags, tweet authors and sentiment can be used during pre and post-processing, as they play an important role in this challenge.\n\n**Data leakage**\n\nAs some of you correctly specified, we cannot says that this is _data leakage_ as the original dataset is mentioned in the challenge description: _The dataset is titled Sentiment Analysis: Emotion in Text tweets._ Nontheless, the link (https:\/\/www.figure-eight.com\/data-for-everyone\/) they refers to is broken.\n\nThe dataset is also available here in Kaggle: https:\/\/www.kaggle.com\/icw123\/emotion ","d0274502":"`happiness`, `neutral`, `sadness` and `worry` are the most used sentiment. We can assume that `happiness` was mapped to `positive`, whereas `sadness` and `worry` were mapped to `negative`.\n\n**Key takeaways**\n\nWe can notice how the distribution between the sentiment is different. We may, for instance, discover that our model has difficulties to find the _support phrase_ for sentiment fewer commons, such as `boredom` or `relief`. In this case, we may want to do some pre-processing.\n\nAlso, in the official `train_df` the jaccard score for the `negative` sentiment is about 0.97. In the next versions, I will try to map each tweet to the more granular sentiment and will analyze the jaccard for each column.","ab5b6938":"[](http:\/\/)From the TSE leaderboard we discover that **leaderboard [..] approximately 30% of the test data. The final results will be based on the other 70%**. By a simple calculus, the expected size of the private leaderboard is 8246, 700 less than our estimation. Probably, this is due to the fact that some of the tweets were removed during the [Leaderboard update coming!](https:\/\/www.kaggle.com\/c\/tweet-sentiment-extraction\/discussion\/142073)."}}