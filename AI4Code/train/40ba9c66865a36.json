{"cell_type":{"cac0c574":"code","a7790826":"code","d36c9166":"code","e5369641":"code","18404252":"code","a25126f0":"code","d9678375":"code","f2449f2f":"code","8c8745c6":"code","148b1141":"code","3393a647":"code","2ad90c05":"code","e080d937":"code","9e178d72":"code","341a8ee6":"code","826d3021":"code","706dfc53":"code","f23adbe1":"code","66dc2ddc":"code","aa210e88":"code","e235ed73":"code","665c7310":"code","383bbbb6":"code","bb931581":"code","35a38926":"code","ba2bb751":"markdown","e12e1e32":"markdown","04ef2f5f":"markdown"},"source":{"cac0c574":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","a7790826":"train = pd.read_csv('..\/input\/train.csv')","d36c9166":"train.head()","e5369641":"train['Id'].describe()","18404252":"y_train = train['Id']","a25126f0":"from keras.preprocessing import image\nfrom keras.applications.imagenet_utils import preprocess_input\n\ndef prepareImages(train, shape, path):\n    \n    x_train = np.zeros((shape, 100, 100, 3))\n    count = 0\n    \n    for fig in train['Image']:\n        \n        #load images into images of size 100x100x3\n        img = image.load_img(\"..\/input\/\"+path+\"\/\"+fig, target_size=(100, 100, 3))\n        x = image.img_to_array(img)\n        x = preprocess_input(x)\n\n        x_train[count] = x\n        if (count%500 == 0):\n            print(\"Processing image: \", count+1, \", \", fig)\n        count += 1\n    \n    return x_train","d9678375":"X_train = prepareImages(train, train.shape[0], 'train')\nX_train\/=255","f2449f2f":"from sklearn.preprocessing import LabelEncoder\nfrom keras.utils.np_utils import to_categorical","8c8745c6":"label_encoder = LabelEncoder()\ny_train = label_encoder.fit_transform(y_train)\ny_train = to_categorical(y_train, num_classes = 5005)","148b1141":"y_train.shape","3393a647":"from keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dropout, Flatten, MaxPooling2D, Conv2D, Dense\nfrom keras.layers.normalization import BatchNormalization","2ad90c05":"model = Sequential()\n\nmodel.add(Conv2D(32, (5,5), strides = (1,1), padding='same', activation = 'relu', input_shape = (100, 100, 3)))\nmodel.add(Conv2D(32, (5,5), strides = (1,1), padding = 'same', activation='relu'))\nmodel.add(MaxPooling2D((2,2)))\n\nmodel.add(Conv2D(32, (3,3), strides = (2,2), padding='same', activation='relu'))\nmodel.add(Conv2D(32, (3,3), strides = (2,2), padding='same', activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides = (2,2)))\n\nmodel.add(Conv2D(64, (3,3), strides = (1,1), padding='same', activation='relu'))\nmodel.add(Conv2D(64, (3,3), strides=(1,1), padding='same', activation='relu'))\nmodel.add(MaxPooling2D((2,2), strides = (2,2)))\n\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(y_train.shape[1], activation = 'softmax'))","e080d937":"model.summary()","9e178d72":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","341a8ee6":"epochs = 100\nbatchsize = 1024","826d3021":"history = model.fit(X_train, y_train, epochs = epochs, batch_size = batchsize, verbose=2)","706dfc53":"plt.plot(history.history['loss'], color='r', label=\"Train Loss\")\nplt.title(\"Train Loss\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","f23adbe1":"plt.plot(history.history['acc'], color='g', label=\"Train Accuracy\")\nplt.title(\"Train Accuracy\")\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.show()","66dc2ddc":"print('Train accuracy of the model: ',history.history['acc'][-1])","aa210e88":"test = os.listdir(\"..\/input\/test\/\")\nprint(len(test))","e235ed73":"test_data = pd.DataFrame(test, columns=['Image'])\ntest_data['Id'] = ''","665c7310":"X_test = prepareImages(test_data, test_data.shape[0], \"test\")\nX_test \/= 255","383bbbb6":"predictions = model.predict(np.array(X_test), verbose=1)","bb931581":"for i, pred in enumerate(predictions):\n    test_data.loc[i, 'Id'] = ' '.join(label_encoder.inverse_transform(pred.argsort()[-5:][::-1]))","35a38926":"test_data.to_csv('submission_1.csv', index=False)","ba2bb751":"### Checking out the loss and accuracy of the model through the training process","e12e1e32":"## Humpback Whale prediction using Keras","04ef2f5f":"### Preparing the model"}}