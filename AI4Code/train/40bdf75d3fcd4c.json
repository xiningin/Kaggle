{"cell_type":{"ae8c79da":"code","4510c044":"code","1071e7cf":"code","23f510a0":"code","31101b3e":"code","bce63e38":"code","088cc474":"code","d8599b8b":"code","354664be":"code","3c64051a":"code","035178ea":"code","01187fd5":"code","59468721":"code","6b95a87a":"code","40c3c39b":"code","04ed11be":"code","8ee17cb7":"code","6a5f0df5":"code","36e2340f":"code","3e813f92":"code","d8a4f6b8":"code","17e69cad":"code","2402327a":"code","1cfd52f4":"code","764a9a97":"code","368178ac":"code","9302f9eb":"code","82a558a4":"markdown","2338b126":"markdown"},"source":{"ae8c79da":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport lightgbm as lgb","4510c044":"data = pd.read_csv(\"..\/input\/insurance_claims.csv\")","1071e7cf":"data.head()","23f510a0":"data.describe()","31101b3e":"# Dropping columns \ndata.drop('_c39',axis=1,inplace=True)","bce63e38":"#Checking missing values\n# Function to calculate missing values by column# Funct \ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","088cc474":"# Missing values statistics\nmissing_values = missing_values_table(data)\nmissing_values","d8599b8b":"#lets do Lable enconding coding to make more features \n\nle = LabelEncoder()\nle_count = 0\n\n# Iterate through the columns\nfor col in data:\n    if data[col].dtype == 'object':\n        # If 2 or fewer unique categories\n        if len(list(data[col].unique())) <= 2:\n            # Train on the training data\n            le.fit(data[col])\n            # Transform both training and testing data\n            data[col] = le.transform(data[col])\n            \n            \n            # Keep track of how many columns were label encoded\n            le_count += 1\n            \nprint('%d columns were label encoded.' % le_count)","354664be":"#data = pd.get_dummies(data)\n#print('Training Features shape: ', data.shape)\nsns.set(style=\"white\")\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(15, 15))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\nsns.heatmap(data.corr(), cmap=cmap, vmax=.3, center=0,annot=True,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","3c64051a":"colum_name =[]\nunique_value=[]\n# Iterate through the columns\nfor col in data:\n    if data[col].dtype == 'object':\n        # If 2 or fewer unique categories\n        colum_name.append(str(col)) \n        unique_value.append(data[col].nunique())\ntable= pd.DataFrame()\ntable['Col_name'] = colum_name\ntable['Value']= unique_value\n            \ntable=table.sort_values('Value',ascending=False)\ntable","035178ea":"# droping columns based on above result\ndata.drop(['incident_location','policy_bind_date','incident_date','auto_model','insured_occupation','policy_number'],axis=1,inplace=True)","01187fd5":"f, ax = plt.subplots(figsize=(20, 20))\nsns.countplot(x='insured_hobbies',hue='fraud_reported',data=data)","59468721":"data['insured_hobbies']=data['insured_hobbies'].apply(lambda x :'Other' if x!='chess' and x!='cross-fit' else x)","6b95a87a":"f, ax = plt.subplots(figsize=(20, 20))\nsns.countplot(x='auto_make',hue='fraud_reported',data=data)","40c3c39b":"data['insured_hobbies'].unique()","04ed11be":"data = pd.get_dummies(data)\nprint('Training Features shape: ', data.shape)","8ee17cb7":"f, ax = plt.subplots(figsize=(10, 10))\nsns.countplot(x='fraud_reported',data=data)","6a5f0df5":"#f, ax = plt.subplots(figsize=(20, 20))\ncorr= data.corr()\ny=data['fraud_reported']\nX= data.drop('fraud_reported',axis=1)","36e2340f":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split","3e813f92":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","d8a4f6b8":"from sklearn.metrics import f1_score\n\ndef lgb_f1_score(y_hat, data):\n    y_true = data.get_label()\n    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n    return 'f1', f1_score(y_true, y_hat), True","17e69cad":"def run_lgb(X_train, X_test, y_train, y_test, test_df):\n    params = {\n        \"objective\" : \"binary\",\n       \"n_estimators\":1000,\n       \"reg_alpha\" : 0.5,\n       \"reg_lambda\":0.5,\n       \"n_jobs\":-1,\n       \"colsample_bytree\":.8,\n       \"min_child_weight\":8,\n       \"subsample\":0.8715623,\n       \"min_data_in_leaf\":30,\n       \"nthread\":4,\n       \"metric\" : \"f1\",\n       \"num_leaves\" : 10,\n       \"learning_rate\" : 0.01,\n       \"verbosity\" : -1,\n       \"seed\": 60,\n       \"max_bin\":60,\n       'max_depth':3,\n       'min_gain_to_split':.0222415,\n       'scale_pos_weight':1.4,\n        'bagging_fraction':0.8\n    }\n    \n    lgtrain = lgb.Dataset(X_train, label=y_train)\n    lgval = lgb.Dataset(X_test, label=y_test)\n    evals_result = {}\n    model = lgb.train(params, lgtrain, 10000, \n                      valid_sets=[lgtrain, lgval], \n                      early_stopping_rounds=100, \n                      verbose_eval=100, \n                      evals_result=evals_result,feval=lgb_f1_score)\n    \n    pred_test_y = model.predict(test_df, num_iteration=model.best_iteration)\n    return pred_test_y, model, evals_result","2402327a":"pred_test, model, evals_result = run_lgb(X_train, X_test, y_train, y_test, X_test)\nprint(\"LightGBM Training Completed...\")","1cfd52f4":"from sklearn.metrics import roc_auc_score","764a9a97":"roc_auc_score(y_test,pred_test)","368178ac":"from sklearn import metrics\nfpr, tpr, threshold = metrics.roc_curve(y_test, pred_test)\nroc_auc = metrics.auc(fpr, tpr)\nf, ax = plt.subplots(figsize=(10, 10))\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","9302f9eb":"print('Plot feature importances...')\nax = lgb.plot_importance(model, max_num_features=10)\nplt.show()","82a558a4":"## Create additional 'other' column if Insured hobbies are not chess and cross fit.","2338b126":"## Lets check if Data is balanced data or not?\n\n* Looking at below graph , the data looks imbalance."}}