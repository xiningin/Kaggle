{"cell_type":{"772683f6":"code","ab3d3d4c":"code","1a62ec20":"code","3c867c96":"code","8e974a2e":"code","b87a5121":"code","16b3f3e7":"code","13fadbb6":"code","600001b3":"code","6a147f19":"code","b9d4a5bb":"code","d63c43d6":"code","32608226":"code","2f606e22":"code","0a753e3c":"code","0ee2b391":"code","16a54506":"code","23c2af12":"code","4ba6be24":"code","b18901a1":"code","aa6b4926":"code","bab544cc":"code","33a763dc":"code","36d91e2d":"code","804fcd77":"code","858ccdb4":"code","b24a6965":"code","63c0a967":"code","94581b3f":"code","a2198af3":"code","11f4f46b":"code","cc8d9caa":"code","a8abecd3":"code","9f8dfb59":"code","db6aaa9c":"code","35c3296a":"code","6c91f8f2":"code","a2c059b2":"code","015ff8a0":"code","5086424e":"code","dac9801c":"code","e5ce7613":"code","61927bea":"code","2e4a06d1":"code","ef31e3d5":"code","efa3911e":"code","d2364b88":"code","66099c3c":"code","1c8dae5f":"code","d2f803e9":"code","e0265c6b":"code","3b8ccdc1":"code","380fa6a1":"code","f1901702":"code","17be1be8":"code","85d685d2":"code","f7844709":"code","6ebeda2f":"code","d1e64513":"code","36fe1e30":"code","59f37d1a":"code","b956616e":"code","1580a36c":"code","f97d65f1":"code","9d37c6f7":"code","44b284eb":"code","22bfe799":"code","a23a9186":"code","9efafb13":"code","2e4f6d5b":"code","c8e0a2c0":"code","09f29f95":"code","9e07bced":"code","1a2a0f3e":"code","33d306e4":"code","5a424b87":"code","88e263cb":"code","06d3ae37":"code","1a7f1298":"code","2eef9597":"code","ccc0e45d":"code","e09b95d5":"markdown","055e165b":"markdown","b5aad78e":"markdown","cc956429":"markdown","48db74cc":"markdown","ebbefb1f":"markdown","63d29981":"markdown","483c0871":"markdown","6b6fd14d":"markdown","dbb884e3":"markdown","18cf4b08":"markdown","3b235f92":"markdown","fcc809d8":"markdown","91b02b56":"markdown","6029e06d":"markdown","3774ce10":"markdown","3efd845d":"markdown","3e2f6501":"markdown","e152c58a":"markdown","3e92ef65":"markdown","558eefae":"markdown","3e1d253f":"markdown","82a4de22":"markdown","154c1c49":"markdown","8969b474":"markdown","c833b98f":"markdown","b9d9f33d":"markdown","23bd0cda":"markdown","2e2ebb3a":"markdown","a12e748a":"markdown","b345905b":"markdown"},"source":{"772683f6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# Here are several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n%matplotlib inline \n# Sets the backend of matplotlib to 'inline' backend, which allows plots to be viewed in-line with the code.\nfrom matplotlib import pyplot as plt # plotting\nfrom matplotlib import style # prepackaged plotting styles\n\nimport seaborn as sns #prettier and potentially more informative plotting than matplotlib\n\nimport string\nimport warnings\nwarnings.filterwarnings('ignore') #ignores all warnings for better viewing from users","ab3d3d4c":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1a62ec20":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ngs = pd.read_csv('..\/input\/titanic\/gender_submission.csv')","3c867c96":"# Understand nature of the data using .info() .describe()\n# Check for missing\/null data\n# Get value counts for categorical variables\n# Build data visualizations using histograms, bar charts, and box plots \n# Find the correlations between each pair of quantitative variables. \n# Explore interesting themes \n    # Did women and children have a better chance of surviving? \n    # Were the very young and elderly more likely to survive?\n    # Was having a family advantageous?\n    # Was an expensive ticket - i.e. Pclass and Fare -  an indicator of better survival odds?\n    # Where people more likely to survive with fancy title like Doctor?\n    \n# Perform eature engineering to improve model performance.\n# Preprocess data together or use a transformer? \n    # Use labels for train and test data sets.\n# Scaling?\n# Model Baseline \n# Model comparison with CV ","8e974a2e":"#Discover the column names, non-null counts, and data types for each variable in the training data set\ntrain.info()","b87a5121":"#Examine the first few rows of training data\ntrain.head()","16b3f3e7":"#Discover the column names, non-null counts, and data types for each variable in the training data set\ntest.info()","13fadbb6":"#Examine the first few rows of test data\ntest.head()","600001b3":"#Examine the training dataset numeric and categorical variables\ntrain.describe(include='all')","6a147f19":"women = train.loc[train.Sex == 'female']['Survived']\nrate_women = sum(women)\/len(women)*100\nprint(\"% of women who survived:\", round(rate_women, 2), \"%\")\n\nmen = train.loc[train.Sex == 'male']['Survived']\nrate_men = sum(men)\/len(men)*100\nprint(\"% of men who survived:\", round(rate_men, 2), \"%\")","b9d4a5bb":"#create dataframes for pie chart\nmale = train[train['Sex']=='male'].groupby('Survived').count()['Sex']\nfemale = train[train['Sex']=='female'].groupby('Survived').count()['Sex']\n\n#create pie charts for men and women\npie_colors = ['tab:orange', 'tab:blue']\nlabels = ['died', 'survived']\n\nfig, axs = plt.subplots(nrows=1, ncols=2,figsize=(10, 4))\nfig.suptitle('Survival Percentages by Sex', fontsize=16)\n\naxs[0].pie(x=male, autopct=\"%.1f%%\", labels=['died', 'survived'], colors=pie_colors, wedgeprops={'edgecolor':'black', 'linewidth':1})\naxs[0].set_title('Males')\n\naxs[1].set_title('Females')\naxs[1].pie(x=female, autopct=\"%.1f%%\", labels=['died', 'survived'], colors=pie_colors, wedgeprops={'edgecolor':'black', 'linewidth':1})\n\nplt.tight_layout()\nplt.show()","d63c43d6":"counts = train.groupby('Sex').Survived.value_counts()\ncounts","32608226":"gender_survival = pd.DataFrame({'Sex': ['female', 'male'], 'Survived': [counts[0], counts[3]], 'Died': [counts[1], counts[2]]})\ngender_survival.plot(x='Sex', kind='bar', rot=0, title='Survivers by Gender', ylabel='Count', edgecolor='black', linewidth=1)\nplt.tight_layout()\nplt.show()","2f606e22":"train['Sex'].value_counts()","0a753e3c":"train['Sex'].value_counts().plot(kind='bar', rot=0, edgecolor='black', linewidth=1.2, color=['C0', 'C1'])\n\nplt.title('Number of Males and Females Aboard', fontsize=16)\nplt.ylabel('Total Passengers')\nplt.xlabel('Passenger Gender')\n\nplt.tight_layout()\nplt.show()","0ee2b391":"#plot Age on the x-axis and Count on the y-axis in a histogram using seaborn, color coded by Survival\nfig, axs = plt.subplots(nrows=1, ncols=2,figsize=(10, 4))\nfig.suptitle('Survival Histograms by Sex', fontsize=16)\n\nax1 = sns.histplot(data=train[train['Sex']=='male'], x='Age', hue='Survived', binwidth=5, binrange=(0,80), ax=axs[0])\nax2 = sns.histplot(data=train[train['Sex']=='female'], x='Age', hue='Survived', binwidth=5, binrange=(0,80), ax=axs[1])\nax1.set_title('Males')\nax2.set_title('Females')\n\nfor ax in [ax1, ax2]:\n    ax.legend(labels=['survived', 'died'])\n    plt.tight_layout()\nplt.show()","16a54506":"young_females = train[(train['Sex']=='female') & (train['Age']>=5.0) & (train['Age']<=10.0)]\n#df[(df['closing_price'] >= 99) & (df['closing_price'] <= 101)]\nyoung_females.describe()","23c2af12":"young_males = train[(train['Sex']=='male') & (train['Age']>=5.0) & (train['Age']<=10.0)]\n#df[(df['closing_price'] >= 99) & (df['closing_price'] <= 101)]\nyoung_males.describe()","4ba6be24":"train2 = train.copy()\ntest2 = test.copy()\n\ndf_corr = train2.corr().unstack().sort_values(kind='quicksort', ascending=False).reset_index()\ndf_corr.rename(columns={'level_0':'Feature 1', 'level_1': 'Feature 2', 0: 'Correlation'}, inplace=True)\ndf_corr[df_corr['Feature 1'] == 'Age']","b18901a1":"age_by_pclass = train2.groupby(['Sex', 'Pclass'])['Age'].median()\nage_by_pclass","aa6b4926":"ax = plt.subplot()\nage_by_pclass.plot(kind='bar', rot=0, edgecolor='black', linewidth=1, color=['tab:orange', 'tab:blue', 'tab:grey'])\nplt.ylabel('Age', fontsize=12)\nplt.xlabel('Passenger Class', fontsize=12)\nax.set_xticklabels(['First, F', 'Second, F', 'Third, F', 'First, M', 'Second, M', 'Third, M'])\nplt.tight_layout()\nplt.show()","bab544cc":"train2.isnull().sum()","33a763dc":"fare_by_pclass = train2.groupby(['Sex', 'Pclass'])['Fare'].median()","36d91e2d":"ax = plt.subplot()\nfare_by_pclass.plot(kind='bar', rot=0, edgecolor='black', linewidth=1, color=['tab:orange', 'tab:blue', 'tab:grey'])\nplt.ylabel('Fare', fontsize=12)\nplt.xlabel('Passenger Class', fontsize=12)\nax.set_xticklabels(['First, F', 'Second, F', 'Third, F', 'First, M', 'Second, M', 'Third, M'])\nplt.tight_layout()\nplt.show()","804fcd77":"data = [train2, test2]\nfor dataset in data:\n    dataset['Age'] = dataset.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))\n    dataset['Fare'] = dataset.groupby(['Sex', 'Pclass'])['Fare'].apply(lambda x: x.fillna(x.median()))","858ccdb4":"train2.isnull().sum()","b24a6965":"test2.isnull().sum()","63c0a967":"#Quick way to separate out numeric and categorical variables\ntrain_quant = train.select_dtypes(np.number)\ntrain_quant.drop(['PassengerId'], axis=1, inplace=True)\ntrain_cat = train.select_dtypes('object')\nprint(train_quant, train_cat)","94581b3f":"train_quant.corr()","a2198af3":"figure = plt.figure(figsize=(10,6))\nmask = np.triu(np.ones_like(train_quant.corr(), dtype=np.bool))\nheatmap = sns.heatmap(train_quant.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap='BrBG')\nheatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12)\nplt.tight_layout()\nplt.show()","11f4f46b":"plt.hist(train.Age, bins=8, linewidth=1, edgecolor='black')\nplt.title('Titanic Passenger Age Distribution')\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.show()","cc8d9caa":"plt.hist(train.Fare, bins=20, linewidth=1.2, edgecolor='black')\nplt.title(\"Ticket Fare Distribution\")\nplt.ylabel(\"Count\")\nplt.xlabel(\"Fare in Dollars\")\nplt.show()","a8abecd3":"train['log_fare'] = np.log(train['Fare']+1) #add 1 to each value to avoid undefined results for 0\ntest['log_fare'] = np.log(test['Fare']+1)\nplt.hist(train.log_fare, bins=20, linewidth=1, edgecolor='black', color='C4')\nplt.title(\"Log Ticket Fare Distribution\")\nplt.ylabel(\"Count\")\nplt.xlabel(\"Log Fare\")\nplt.show()","9f8dfb59":"train2['log_fare'] = np.log(train2['Fare']+1)\ntest2['log_fare'] = np.log(test2['Fare']+1)","db6aaa9c":"train2['Title'] = train2['Name'].apply(lambda x: x.split(', ', 2)[1].split('.', 2)[0])\ntest2['Title'] = train2['Name'].apply(lambda x: x.split(', ', 2)[1].split('.', 2)[0])\nprint(train2['Title'].unique())\nprint(test2['Title'].unique())","35c3296a":"train2.groupby('Title').Survived.value_counts()","6c91f8f2":"train2.Title.value_counts()","a2c059b2":"train.Cabin.unique()","015ff8a0":"data = [train2, test2]\nimport re\n\nfor dataset in data:\n    dataset['cabin_first_letter'] = dataset['Cabin'].apply(lambda x: str(x)[0])\n    dataset['had_cabin'] = [0 if dataset['Cabin'].isnull()[i] else 1 for i in range(len(dataset))]\nprint(train2['cabin_first_letter'].value_counts())\nprint(train2['had_cabin'].value_counts())\nprint(test2['cabin_first_letter'].value_counts())\nprint(test2['had_cabin'].value_counts())\n","5086424e":"train2.groupby(['cabin_first_letter'])['Survived'].mean()","dac9801c":"train2['cabin_first_letter'].value_counts()","e5ce7613":"test2['cabin_first_letter'].value_counts()","61927bea":"train2.groupby('cabin_first_letter')['Survived'].mean().plot(kind='bar', x='cabin_first_letter', y='Survived')\nplt.tight_layout()\nplt.show()","2e4a06d1":"for dataset in data:\n    dataset['Title'].replace(['Lady', 'Ms', 'Mlle'], 'Miss', inplace=True)\n    dataset['Title'].replace('Mme', 'Mrs', inplace=True)","ef31e3d5":"train2.Title.value_counts()","efa3911e":"test2.Title.value_counts()","d2364b88":"popular_titles = [i for i in train2.Title.unique() if train2.Title.value_counts().loc[i]>10]\nprint(popular_titles)","66099c3c":"for dataset in data:\n    dataset['Popular_title'] = [dataset['Title'][i] if dataset['Title'][i] in popular_titles else 'Other' for i in range(len(dataset))]","1c8dae5f":"train2['Popular_title'].value_counts()","d2f803e9":"print(test2['Popular_title'].value_counts())","e0265c6b":"for dataset in data:\n    dataset['Sex'] = [1 if dataset['Sex'][i] == 'male' else 0 for i in range(len(dataset))]","3b8ccdc1":"train2['Embarked'].value_counts()","380fa6a1":"train2['Embarked'] = train2['Embarked'].fillna('S')","f1901702":"train2 = train2.drop(columns=['Fare'])\ntest2 = test2.drop(columns=['Fare'])","17be1be8":"train2['Embarked'] = train2['Embarked'].map({'S':1, 'C':2, 'Q':3})\ntest2['Embarked'] = test2['Embarked'].map({'S':1, 'C':2, 'Q':3})","85d685d2":"train2['Popular_title'] = train2['Popular_title'].map({'Mr':1, 'Mrs':2, 'Miss':3, 'Master':4, 'Other':5})\ntest2['Popular_title'] = test2['Popular_title'].map({'Mr':1, 'Mrs':2, 'Miss':3, 'Master':4, 'Other':5})","f7844709":"train3 = train2[['Popular_title','Age','Sex','Pclass','log_fare','Parch','SibSp','had_cabin','Survived']]\ntest3 = test2[['Popular_title','Age','Sex','Pclass','log_fare','Parch','SibSp','had_cabin']]","6ebeda2f":"train3['fam_size'] = train3['Parch'] + train3['SibSp']\ntest3['fam_size'] = test3['Parch'] + test3['SibSp']","d1e64513":"train3.drop(columns=['Parch','SibSp'], inplace=True)","36fe1e30":"test3.drop(columns=['Parch','SibSp'], inplace=True)","59f37d1a":"train3.head()","b956616e":"test3.tail()","1580a36c":"from sklearn.ensemble import RandomForestClassifier","f97d65f1":"y = train3[\"Survived\"]\n\nfeatures = ['Popular_title','Age','Sex','Pclass','log_fare', 'fam_size', 'had_cabin']\nX = train3[features]","9d37c6f7":"model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nmodel.fit(X, y)","44b284eb":"X_test = test3[features]","22bfe799":"predictions = model.predict(X_test)","a23a9186":"model.score(X,y)","9efafb13":"output = pd.DataFrame({'PassengerId': test2.PassengerId, 'Survived': predictions})\noutput.to_csv('random_forest.csv', index=False)\nprint(\"Your submission was successfully saved! This model was pretty accurate, with a score of \" + str(model.score(X,y)))","2e4f6d5b":"features","c8e0a2c0":"model.feature_importances_","09f29f95":"y2 = train3['Survived']\nfeatures2 = ['Popular_title', 'Age', 'Sex', 'Pclass']\nX2 = train3[features2]\nX_test2 = test3[features2]\nmodel2 = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=2)\nmodel2.fit(X2, y2)\npredictions2 = model2.predict(X_test2)\n","9e07bced":"model2.score(X2,y2)","1a2a0f3e":"output2 = pd.DataFrame({'PassengerId': test2.PassengerId, 'Survived': predictions2})\noutput2.to_csv('random_forest2.csv', index=False)\nprint(\"Your submission was successfully saved! This model was pretty accurate, with a score of \" + str(model2.score(X2,y2)))","33d306e4":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\npredictions3 = gnb.fit(X2, y2).predict(X_test2)\ngnb.score(X2,y2)","5a424b87":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions3})\noutput.to_csv('naive_bayes.csv', index=False)","88e263cb":"#convert male and female to 1 and 0 for regression analysis\ntrain['Sex_Numeric'] = [0 if train['Sex'][i]=='female' else 1 for i in range(len(train['Sex']))]\ntest['Sex_Numeric'] = [0 if test['Sex'][i]=='female' else 1 for i in range(len(test['Sex']))]","06d3ae37":"#import regression library\nfrom sklearn.linear_model import LinearRegression","1a7f1298":"#try linear regressions to see how well Fare predicts Survival\nX = np.array(train['log_fare']).reshape(-1, 1)\ny = np.array(train['Survived']).reshape(-1, 1)\nmodel = LinearRegression().fit(X, y)\nprint('R_squared:', round(model.score(X, y), 2))\nprint('intercept:', round(model.intercept_[0], 2))\nprint('slope:', round(model.coef_[0][0], 5))\n#not very convincing. Sorry, rich folks!","2eef9597":"#let's try Age\nX = np.array(train['Age']).reshape(-1, 1)\ny = np.array(train['Survived']).reshape(-1, 1)\nmodel = LinearRegression().fit(X, y)\nprint('R_squared:', round(model.score(X, y), 2))\nprint('intercept:', round(model.intercept_[0], 2))\nprint('slope:', round(model.coef_[0][0], 5))\n#also not very good! let's try multiple linear regression","ccc0e45d":"features = ['Age', 'Fare', 'Pclass', 'Sex_Numeric']\nX = pd.get_dummies(train[features])\nX_test = pd.get_dummies(test[features])\ny = train['Survived']\n\nmodel = LinearRegression().fit(X, y)\n\nprint('R_squared:', model.score(X, y))\nprint('intercept:', model.intercept_)\nprint('coefficients:', model.coef_)\n#getting better, but still not great! let's see how it did with predictions anyway\n\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('my_titanic_MLR.csv', index=False)\n#This model is not nearly as accurate as the Random Forest Classifier","e09b95d5":"# Naive Bayes Classifier","055e165b":"Wow - first class tickets for females were much more expensive than other tickets, even when compared to first class tickets for males.","b5aad78e":"# Relationship between gender and survival  \nFrom the charts above, we see that the proportion of males who survived was much lower than the proportion of women that survived. Female passengers were significantly more likely to survive the event than not. Males, however, were very likely to have died. Additionally, there were more male passengers than female passengers. **Gender alone seems to be a very strong indicator of whether or not a passenger was to survive the Titanic sinking.**","cc956429":"# Age distribution  \nThe histogram below indicates that the age variable follows a relatively normal distribution, with most passengers in in the 20-40 year range.","48db74cc":"# Creating a meaningful variable out of Cabin  \nMaybe we can create variabes using the first letter of the cabin A-F, and include nan as a category, since many passengers didn't have a cabin.","ebbefb1f":"The test data doesn't show whether the passenger survived or not. This information is in the gender_submission.csv file.","63d29981":"# Titanic Project - inspired by Ken Jee and Saad Muhammad\u00b6\n\nKen's accompanying video is located here: https:\/\/www.youtube.com\/watch?v=I3FBJdiExcg\nKen's notebook: https:\/\/www.kaggle.com\/kenjee\/titanic-project-example\nSaad Muhammad's notebook: https:\/\/www.kaggle.com\/saadmuhammad17\/a-beginners-guide-to-data-science-top-3\n\nBest results : 78.947 % accuracy, which was an improvement on an initial score of 77.511%.\n\n**Overview**\n1) Understand the shape of the data (Histograms, box plots, etc.)  \n2) Data Cleaning  \n3) Data Exploration  \n4) Feature Engineering  \n5) Data Preprocessing for Model  \n6) Basic Model Building  \n7) Model Tuning  \n8) Ensemble Model Building  \n9) Results  ","483c0871":"**Histogram**  \nMales between the ages of 15 and 75 were unlikely to survive. Females in all age groups were more likely to survive than perish, but females between the ages of 5 and 15 had relatively higher mortality rates. Let's find out exactly what the rate was for young females.","6b6fd14d":"# Modeling  \nOur first model will be a Random Forest Classifier, using the features we suspect have the greatest impact on survival.","dbb884e3":"Let's plot this data below in a pie chart.","18cf4b08":"Let's examine these outcomes further using a barchart.","3b235f92":"There are 891 entries, with some null values in the Age, Cabin, and Embarked columns.  \n**Age:** 177 nulls  \n**Cabin:** 687 nulls  \n**Embarked:** 2 nulls  \n  \n**Integer:** PassengerID, Survived, Pclass, SibSp, Parch  \n**Float:** Age, Fare  \n**Object:** Name, Sex, Ticket, Cabin, Embarked\n\nIt might be useful to convert Age to integer, as all ages are entered as whole numbers. Additionally, we might be able to make intelligent guesses about passenger ages and where they embarked from to address the null values.\n\nCabin has many null values, which might be informative in itself. We could create a category for the null cabin passengers. Maybe not having a cabin contributes to the likelihood of survival.","fcc809d8":"Let's perform a little data cleaning on Age using inspiration from Saad Muhammad's notebook.","91b02b56":"# Adjust based on feature importances  \nLet's see if by choosing the most strongly correlated features, we can improve our model without overfitting.","6029e06d":"# Visualize the data","3774ce10":"# What percentage of women and men survived overall?","3efd845d":"The null values for Age and Fare are now removed from the new training and test data frames, and have been replaced with the median ages for each Sex\/Pclass combination.","3e2f6501":"Examine relationship between cabin and survival.","e152c58a":"There are 418 records in the test dataframe, with null values in Age (86), Fare (1), and Cabin (327).","3e92ef65":"First, let's examine the relationship between Sex and Survived. Our hypothesis is that women and children were more likely to survive than men, but was this true?","558eefae":"This model fits our training data better, but it produced less accurate predictions on the test data set. We can say that this model suffers from overfitting.","3e1d253f":"# Data Cleaning \nTo enhance the dataset, we'll fill in the NaN values for Age, Fare, Cabin, and Embarked. Thank you so much to Saad Muhammed for demonstrating this technique in his guided notebook. Link: https:\/\/www.kaggle.com\/saadmuhammad17\/a-beginners-guide-to-data-science-top-3","82a4de22":"We can see that first class passengers were oldest, followed by second class, then third class, with males slightly older in each category. We can use this information to impute the ages for the passengers with missing age values.","154c1c49":"# Fares  \nThe Fares distribution is heavily right skewed, indicating a small number of passengers purchasing very expensive tickets. Using a log transformation, we can normalize this variable.","8969b474":"# Linear Regression Analysis","c833b98f":"If you were a Miss, Mrs, Master, Sir, Countess, etc. you seem to have had a better chance.","b9d9f33d":"**Youth Survival Rates**\n\nFemales between ages 5 and 10 inclusive had a 50 percent chance of survival.\nMales in the same age group had a 40 percent chance of survival.","23bd0cda":"Ken Jee had a nice idea of outlining the steps to take in the analysis, which I provide in the commented out code below for this workbook.","2e2ebb3a":"How many men and women were there overall on the ship? Let's use a bar chart to see.","a12e748a":"The strongest positive and negative correlations for Age are with Fare (0.097) and with Pclass (-.326). SibSp and Parch are also relatively strongly correlated at -.224 and -.168 respectively. ","b345905b":"Finally, let's use a histogram to compare survival rates across gender and age."}}