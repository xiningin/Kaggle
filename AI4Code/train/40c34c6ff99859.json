{"cell_type":{"50fa5e08":"code","71f1422d":"code","8b2641d7":"code","d5eb36e2":"code","3521fee8":"code","54440657":"code","9f3cf590":"code","b4827e77":"code","d682223d":"code","dfb52d30":"code","5e913c8f":"code","3142081c":"code","91356d27":"code","fe399345":"code","6f4e6985":"code","b7b8eb47":"code","ded08b25":"code","af2ef537":"code","f91ef09b":"code","442a70ee":"code","8778b9fa":"markdown","72d38f9c":"markdown","491f493c":"markdown","eb584099":"markdown","352b5b7f":"markdown","dff71a26":"markdown"},"source":{"50fa5e08":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","71f1422d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nimport tensorflow.keras.losses as losses\nimport tensorflow.keras.metrics as metrics\n\nfrom tensorflow.keras.layers import Conv2D, Dense, Dropout, InputLayer, Softmax, Flatten, MaxPool2D, BatchNormalization\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomZoom\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras.metrics import Accuracy\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.datasets import mnist\nfrom keras.utils.vis_utils import plot_model\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical","8b2641d7":"df_train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ndf_test = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n\n# Removing and storing the class labels in another variable\nY = df_train['label']\ndf_train.drop([\"label\"], axis=1, inplace=True)\n\nprint(df_train.shape, df_test.shape, Y.shape)","d5eb36e2":"df_train.head()","3521fee8":"(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train = x_train.reshape(60000, -1)\nx_test = x_test.reshape(10000, -1)\ndf_train = np.concatenate([df_train, x_train, x_test], axis = 0)\nY = np.concatenate([Y, y_train, y_test], axis = 0)\nprint(df_train.shape, Y.shape)","54440657":"# Scaling the pixel values to be between 0 and 1\ndf_train = df_train.astype('float32')\ndf_test = df_test.astype('float32')\ndf_train = df_train \/ 255\ndf_test = df_test \/ 255","9f3cf590":"# The image is having dimensions 28*28\nim_dim = 28\n\n# Reshaping the dataset, so that we can display the individual images, and model them\ndf_train = tf.reshape(df_train, (-1, im_dim, im_dim, 1))\ndf_test = tf.reshape(df_test, (-1, im_dim, im_dim, 1))\nprint(df_train.shape, df_test.shape)","b4827e77":"fig,axes = plt.subplots(5, 5, figsize = (6,6))\naxes = axes.ravel()\n\nfor i in np.arange(0,25):\n    axes[i].imshow(df_train[i])\n    axes[i].axis(\"off\")","d682223d":"# Defining some of the key parameters\nnum_classes = 10\nbatch_size = 128\nepochs = 50","dfb52d30":"model = tf.keras.Sequential(layers = [\n    Conv2D(filters=64, kernel_size=5, activation=\"relu\", padding='Same', input_shape=(28, 28, 1)),\n    BatchNormalization(),\n    \n    Conv2D(filters=64, kernel_size=5, activation=\"relu\", padding='Same'),\n    BatchNormalization(),\n    MaxPool2D(pool_size=(2, 2)),\n    Dropout(rate=0.25),\n    \n    Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='Same'),\n    BatchNormalization(),\n    \n    Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='Same'),\n    BatchNormalization(),\n    MaxPool2D(pool_size=(2, 2), strides=(2,2)),\n    Dropout(rate=0.25),\n    \n    Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='Same'),\n    BatchNormalization(),\n    Dropout(rate=0.25),\n    \n    Flatten(),\n    Dense(256, activation=\"relu\"),\n    BatchNormalization(),\n    Dropout(rate=0.25),\n    Dense(10, activation=\"softmax\")\n])","5e913c8f":"model.summary()","3142081c":"plot_model(model, show_shapes=True, show_layer_names=True)","91356d27":"# Defining the Adam Optimizer\n# sgd = SGD(lr=2e-2, decay=1e-6, momentum=0.9)\nrms = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n\n# Defining the callbacks\nreduce_lr = ReduceLROnPlateau(\n    monitor = 'val_acc', factor = 0.5, patience = 3, \n    min_lr = 1e-5, verbose = 1\n)\n# early_st = EarlyStopping(\n#     monitor='val_loss', min_delta=1e-3,\n#     patience=5, verbose=1, restore_best_weights=True, mode = 'min'\n# )\n\n# Compiling the model\nmodel.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=rms)","fe399345":"# Converting the class labels into one-hot form\nY_oh = to_categorical(Y, num_classes=num_classes)","6f4e6985":"# Using real-time Data Augmentation\ndatagen = ImageDataGenerator(\n    featurewise_center = False, samplewise_center=False, featurewise_std_normalization = False,\n    samplewise_std_normalization = False, rotation_range = 10, zoom_range = 0.1,\n    width_shift_range = 0.1, height_shift_range = 0.1, horizontal_flip = False, \n    vertical_flip=False,  validation_split = 0.1\n)\ndatagen.fit(df_train)\n\ntrain_generator = datagen.flow(df_train, Y_oh, batch_size = batch_size, subset='training')\nval_generator = datagen.flow(df_train, Y_oh, batch_size = batch_size, subset = 'validation')\n\n# Training the model using generators\nmodel.fit(\n    train_generator, batch_size = batch_size,\n    epochs = epochs, verbose = 1, validation_data = val_generator,\n    steps_per_epoch = df_train.shape[0] \/\/ batch_size,\n    use_multiprocessing = True, callbacks = [reduce_lr]\n)","b7b8eb47":"# Without using any augmentation\n# model.fit(\n#     df_train, Y_oh, batch_size = batch_size,\n#     epochs = epochs, verbose = 1, validation_split = 0.2,\n#     use_multiprocessing = True, callbacks = [reduce_lr]\n# )","ded08b25":"y_pred = model.predict(df_train)\ny_pred = tf.math.argmax(y_pred, axis = 1)\nacc = metrics.Accuracy()\nprint(acc(Y, y_pred))","af2ef537":"y_sub = model.predict(df_test)\ny_sub = tf.math.argmax(y_sub, axis = 1)\ny_sub = pd.Series(y_sub)\nprint(y_sub.shape, type(y_sub))","f91ef09b":"df_sub = pd.read_csv(\"..\/input\/digit-recognizer\/sample_submission.csv\")\ndf_sub.loc[ : , 'Label'] = y_sub","442a70ee":"df_sub.to_csv(\"submission.csv\", index = False)","8778b9fa":"# Digit Recognizer (Notebook 2)\n- Hola amigos, this notebook covers my code for the **Digit Recognizer Competition**, which can be found [here](https:\/\/www.kaggle.com\/c\/digit-recognizer).\n- This notebook is pretty much same as my [first notebook](http:\/\/https:\/\/www.kaggle.com\/elemento\/digitrecognizer-1) for this competition, with just a few changes like in the architecture, or in the pre-processing steps, etc.","72d38f9c":"# Making the submission","491f493c":"# Training the Model","eb584099":"# Visualizing & Processing the Data","352b5b7f":"# Installing & Importing Packages","dff71a26":"# Importing the data"}}