{"cell_type":{"c3b74237":"code","349b2527":"code","c2fc4c19":"code","a09d90a8":"code","06210c7b":"code","4685dcc9":"code","a13bece9":"code","0c77d294":"code","385b67a1":"code","b29903e4":"code","694105db":"code","44af0ceb":"code","8f2ca5d4":"code","32c173e4":"code","84eb8d0c":"code","030f6e07":"code","86ce1b12":"code","6de70973":"code","0c776172":"code","fb2efe49":"code","79c11b6b":"code","5e73aeb9":"code","152edf5a":"code","297e3250":"code","9df660a6":"code","18fa39a9":"code","978b8718":"code","84c7acb4":"code","a4c3d4b7":"code","167f3692":"code","5cd6ad5b":"code","56a93089":"code","bd0e317e":"code","153da898":"code","2ab06a76":"code","5a8a744e":"code","b81c4a2f":"code","8b9d3ebd":"code","561371c1":"code","8631056c":"code","4a9ab31e":"code","45bf2a58":"code","72cb63c5":"code","0c8fa08e":"code","34146ace":"code","9cf84a13":"code","257a4bb8":"code","1b9d02a0":"code","228fef03":"code","a688410d":"code","00421009":"code","3de1d5cb":"code","5e27b029":"code","ad985e25":"code","743ffde9":"code","47adac86":"code","89b796c4":"code","99dfb3fd":"code","b7800cb4":"code","2155405e":"code","1cb260e8":"code","a2b9b72c":"code","6543a4ad":"code","32a3e95c":"code","20c8225e":"code","98ebfe69":"code","d5ca8c2b":"code","3dea0981":"code","82bfab91":"code","a1f84553":"code","b8cabd05":"code","002a4643":"markdown","cbd9415f":"markdown","68e1879f":"markdown","0f7ed702":"markdown","2a9ca2bc":"markdown","2f4c3211":"markdown","dbad0335":"markdown","cc5d4159":"markdown","8aa6fc30":"markdown","6f2201ff":"markdown","4d61bf68":"markdown","65bea3ed":"markdown","e46c23c8":"markdown","a9e76014":"markdown","ea6b2084":"markdown","7bdabf40":"markdown","6c6a3769":"markdown","7904de23":"markdown","c2e9a06b":"markdown","fa833fe3":"markdown","e3853160":"markdown","30f12650":"markdown","6f46634f":"markdown","e0fc9738":"markdown","fe492f67":"markdown","cf36e39a":"markdown","6bb26fa1":"markdown","7d8b6b75":"markdown","8f371a21":"markdown","091cf9fd":"markdown","e4b50910":"markdown","5f3439fb":"markdown","d16f732e":"markdown","f6f427cf":"markdown","6c8036f8":"markdown","900fa004":"markdown","af8c41e2":"markdown","fcc5ac73":"markdown","b0652b3f":"markdown","6eddb749":"markdown"},"source":{"c3b74237":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","349b2527":"print('numpy version : ', np.__version__)\nprint('pandas version : ', pd.__version__)","c2fc4c19":"df_train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-nov-2021\/train.csv\")\ndf_test = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-nov-2021\/test.csv\")","a09d90a8":"df_train.head()","06210c7b":"%%time\ndf_train.info()","4685dcc9":"df_train.describe()","a13bece9":"print(df_train.isnull().sum().shape)","0c77d294":"df_train.isnull().sum()","385b67a1":"df_train.isnull().sum().sum()","b29903e4":"df_train.columns[df_train.isnull().any()]  # which columns has null value.","694105db":"missing_val_count_by_column = (df_train.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])","44af0ceb":"missing_val_count_by_column_for_test = (df_test.isnull().sum())\nprint(missing_val_count_by_column_for_test[missing_val_count_by_column > 0])","8f2ca5d4":"from sklearn.model_selection import train_test_split\n\nrandom_state=42\ntest_size = 0.2\n\ntrain_set, val_set = train_test_split(df_train, test_size = test_size, random_state=random_state)","32c173e4":"train_set.info()","84eb8d0c":"train_set.head()","030f6e07":"# x_train = train_set.drop(labels = [\"id\",\"target\"], axis=1)\nx_train = train_set.drop(labels = \"target\", axis=1)\ny_train = train_set[\"target\"].values\n\n# validation set\nx_val = val_set.drop(labels = \"target\", axis=1)\ny_val = val_set[\"target\"].values\n\n# development test set\ndf_test_dev = df_test.copy()","86ce1b12":"x_train.head()","6de70973":"x_val.head()","0c776172":"print(y_train[0:5])\nprint(y_val[0:5])","fb2efe49":"columns = x_train.columns[1:]  # we get all columns except index.\nprint(columns)","79c11b6b":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer","5e73aeb9":"x_train.head()","152edf5a":"x_val.head()","297e3250":"df_test_dev.head()","9df660a6":"print(x_train.shape)","18fa39a9":"std_scaler = StandardScaler()","978b8718":"# v1 method\n# x_train[columns] = std_scaler.fit_transform(x_train[columns])\n# x_val[columns] = std_scaler.transform(x_val[columns])\n\n# df_test_dev[columns] = std_scaler.transform(df_test_dev[columns])","84c7acb4":"num_pipeline = Pipeline([(('std_scaler'), StandardScaler()),])\nfull_pipeline = ColumnTransformer([('num', num_pipeline, columns),])\n\nx_train[columns] = full_pipeline.fit_transform(x_train)\nx_val[columns] = full_pipeline.transform(x_val)\ndf_test_dev[columns] = full_pipeline.transform(df_test_dev)","a4c3d4b7":"# x_train.shape\nx_train.head()","167f3692":"x_val.head()","5cd6ad5b":"df_test_dev.head()","56a93089":"print(len(list(df_test_dev)))\nprint(list(df_test_dev))","bd0e317e":"# assert False","153da898":"from sklearn.linear_model import LogisticRegression","2ab06a76":"%%time\nlin_reg = LogisticRegression()\nlin_reg.fit(x_train[columns], y_train)\ny_train_head = lin_reg.predict(x_train[columns])","5a8a744e":"(y_train_head<1).any()","b81c4a2f":"(y_train_head==0).sum().sum()","8b9d3ebd":"# firts evaluation\nprint(lin_reg.score(x_train[columns], y_train))","561371c1":"from sklearn.metrics import roc_curve, auc, roc_auc_score","8631056c":"fpr, tpr, thresholds = roc_curve(y_train, y_train_head)\nroc_auc_score_train = roc_auc_score(y_train, y_train_head)\nprint(\"ROC AUC Score:\",roc_auc_score_train)","4a9ab31e":"def plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--') # Dashed diagonal3\n    plt.legend(loc = 'lower right')\n    plt.show()\n    \nplot_roc_curve(fpr, tpr, label=(\"roc auc score =\"+str(round(roc_auc_score_train*100,2))))","45bf2a58":"print(\"ROC AUC Score:\",roc_auc_score(y_train, y_train_head))","72cb63c5":"# Before ROC AUC Score\ny_train_prob_head = lin_reg.predict_proba(x_train[columns])\nprint(y_train_prob_head.shape)\ny_train_prob_head[0,:]","0c8fa08e":"y_train_prob_head = lin_reg.predict_proba(x_train[columns])[:,1] # score = proba of positive\nroc_auc_score_train_prob = roc_auc_score(y_train, y_train_prob_head)\nprint(\"ROC AUC Score of probability:\", roc_auc_score_train_prob)","34146ace":"fpr_prob, tpr_prob, thresholds_prob = roc_curve(y_train, y_train_prob_head)\nplot_roc_curve(fpr_prob, tpr_prob, label=(\"probability roc auc score =\"+str(round(roc_auc_score_train_prob*100,2))))","9cf84a13":"y_val_prob_head = lin_reg.predict_proba(x_val[columns])[:,1] # score = proba of positive\nroc_auc_score_val_prob = roc_auc_score(y_val, y_val_prob_head)\nprint(\"ROC AUC Score of probability:\", roc_auc_score_val_prob)","257a4bb8":"first_preds = lin_reg.predict_proba(df_test_dev[columns])[:,1]","1b9d02a0":"first_preds","228fef03":"sub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')","a688410d":"sub['target']=first_preds\nsub.to_csv('submission.csv', index=False)","00421009":"sub","3de1d5cb":"from sklearn.model_selection import StratifiedKFold\n\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n","5e27b029":"def plot_roc_curve(fpr, tpr, label=None, title=None):\n    \"\"\"\n    \"\"\"\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'k--') # Dashed diagonal3\n    plt.legend(loc = 'lower right')\n    plt.title(title)\n    plt.show()\n\n    \ndef roc_auc_score_func(y_true, y_head, plot_roc=False):\n    \"\"\" evaluate roc auc score\n    Args:\n        y_true : a numpy array. True labels.\n        y_head : a numpy array. Predicted labels.\n        plot_roc : if you want to plot roc curve. (Default is False)\n        \n    \"\"\"\n    \n    if plot_roc:\n        fpr, tpr, thresholds = roc_curve(y_true, y_head)\n        plot_roc_curve(fpr, tpr, label=None, title=None)\n        \n        \n    # evaluate roc auc score\n    model_roc_auc_score = roc_auc_score(y_true, y_true)\n#     print(\"ROC AUC Score:\",roc_auc_score_train)\n    \n    return model_roc_auc_score\n\n\ndef train_model_w_kfold(clf, X, y, n_splits=5):\n    \"\"\"train ml models with kfold and return auc score for probability\n    \n    Args:\n        clf : model classifier\n        X : a numpy.darray training data \n        y : a numpy.darray training labels\n        n_splits : number of Kfold splits\n        \n    Returns:\n        \n    \"\"\"\n    roc_auc_score_list = []  # roc auc score list\n    acc_score_list = [] # auc score list\n    \n    skf = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n    \n    print(\"Model:\", clf)\n    \n    for i, (train_index, val_index) in enumerate(skf.split(X, y)):\n        print(\"Fitting fold\", i+1)\n        X_train, X_val = X[train_index], X[val_index]\n        y_train, y_val = y[train_index], y[val_index]\n        \n        \n        # TRAINING\n        training_start_time = time.time()\n        \n#         model = LogisticRegression(solver='liblinear')\n        model = clf\n        model.fit(X_train, y_train)\n        \n        training_end_time = time.time()\n        training_time = training_end_time - training_start_time\n        print(f\"fold {i+1} elapsed seconds: {training_time}\")\n        \n        \n        # EVALUATING\n        evaluating_start_time = time.time()\n        \n        roc_auc_score_list.append(roc_auc_score(y_val, model.predict_proba(X_val)[:, 1]))\n        acc_score_list.append(accuracy_score(y_val, model.predict(X_val)))\n        \n        evaluating_end_time = time.time()\n        evaluating_time = evaluating_end_time - evaluating_start_time\n        print(f\"fold {i+1} evaluating scores elapsed seconds: {evaluating_time}\")\n    \n    \n        print(f\"fold: {i+1}, accuracy: {round(acc_score_list[i]*100,3)}, auc: {round(roc_auc_score_list[i]*100,3)}\")\n\n        \n    roc_auc_score_mean = np.mean(roc_auc_score_list)\n    accuracy_mean = np.mean(acc_score_list)    \n    \n    return roc_auc_score_mean, accuracy_mean","ad985e25":"# assert False","743ffde9":"df_train.head()","47adac86":"df_train.shape","89b796c4":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.05, random_state=42)\n\nfor train_index, test_index in split.split(df_train, df_train[\"target\"]):\n#     strat_dev_set = housing.loc[train_index]\n#     strat_test_set = housing.loc[test_index]\n    strat_dev_set = df_train.loc[test_index]\n    \n    \nprint(strat_dev_set.shape)","99dfb3fd":"strat_dev_set.head()","b7800cb4":"(strat_dev_set[\"target\"]==1).sum()","2155405e":"# assert False","1cb260e8":"!pip install --upgrade xgboost\n\n# # xgb.__version__","a2b9b72c":"from xgboost import XGBClassifier","6543a4ad":"xgb_clf = XGBClassifier(\n    max_depth=8,\n    learning_rate=0.01,\n    n_estimators=10000,\n    verbosity=1,\n    silent=None,\n    objective='binary:logistic',  \n    tree_method = 'gpu_hist',\n    booster='gbtree',\n    n_jobs=-1,\n    nthread=None,\n    eval_metric='auc',\n    gamma=0,\n    min_child_weight=1,\n    max_delta_step=0,\n    subsample=0.7,\n    colsample_bytree=1,\n    colsample_bylevel=1,\n    colsample_bynode=1,\n    reg_alpha=0,\n    reg_lambda=1,\n    scale_pos_weight=1,\n    base_score=0.5,\n    random_state=0,\n    seed=None\n)  # logistic regression for binary classification, output probability","32a3e95c":"target = strat_dev_set['target'].values\nstrat_dev_set = full_pipeline.fit_transform(strat_dev_set[columns])","20c8225e":"%%time\n\nimport time\n\n\nclassifiers = [LogisticRegression(solver='liblinear', random_state = random_state),\n               SVC(random_state = random_state, probability=True),\n               DecisionTreeClassifier(random_state = random_state),\n               RandomForestClassifier(random_state = random_state),\n               KNeighborsClassifier(),\n               xgb_clf]\n\n# for SVC, predict_proba is not available when probability=False\n\nclf_roc_auc_score_mean = [] \nclf_auc_score_mean = []\n\nfor clf in classifiers:\n    \n    start_time = time.time()\n    \n    roc_auc_score_mean, accuracy_mean = train_model_w_kfold(clf, X=strat_dev_set, y=target, n_splits=2)\n    \n    clf_roc_auc_score_mean.append(roc_auc_score_mean)\n    clf_auc_score_mean.append(accuracy_mean)\n    \n    end_time = time.time()\n    \n    print('Elapsed seconds classifier training time:', end_time-start_time)","98ebfe69":"clf_roc_auc_score_mean","d5ca8c2b":"ML_Models = [\"LogisticRegression\",\n             \"SVC\",\n             \"DecisionTreeClassifier\",\n             \"RandomForestClassifier\",\n             \"KNeighborsClassifier\",\n             \"XGB\"]\n\ncv_results = pd.DataFrame({\"clf_roc_auc_score_mean\":clf_roc_auc_score_mean, \n                           \"ML Models\": ML_Models})\n\ng = sns.barplot(\"clf_roc_auc_score_mean\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean ROC AUC Score of Probability\")\ng.set_title(\"Stratified KFold\")\nplt.show()","3dea0981":"%%time\n\nxgb_clf = XGBClassifier(\n    max_depth=8,\n    learning_rate=0.01,\n    n_estimators=10000,\n    verbosity=1,\n    silent=None,\n    objective='binary:logistic',  \n    tree_method = 'gpu_hist',\n    booster='gbtree',\n    n_jobs=-1,\n    nthread=None,\n    eval_metric='auc',\n    gamma=0,\n    min_child_weight=1,\n    max_delta_step=0,\n    subsample=0.7,\n    colsample_bytree=1,\n    colsample_bylevel=1,\n    colsample_bynode=1,\n    reg_alpha=0,\n    reg_lambda=1,\n    scale_pos_weight=1,\n    base_score=0.5,\n    random_state=0,\n    seed=random_state\n)\n\nxgb_clf.fit(x_train[columns], y_train)","82bfab91":"%%time\ny_val_prob_head = xgb_clf.predict_proba(x_val[columns])[:,1] # score = proba of positive\nroc_auc_score_val_prob = roc_auc_score(y_val, y_val_prob_head)\n\nprint(\"ROC AUC Score of probability:\", roc_auc_score_val_prob)","a1f84553":"xgb_preds = xgb_clf.predict_proba(df_test_dev[columns])[:,1]","b8cabd05":"sub = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')\nsub['target'] = xgb_preds\nsub.to_csv('submission.csv', index=False)\nsub","002a4643":"[Variable Describtions](#7)\n\n[back to the top](#0)","cbd9415f":"### XGB Training","68e1879f":"[back to the top](#0)","0f7ed702":"<a id=\"4\"><\/a> <br>\n# 4. Create a Validation Set\nBefore go any further, I will create a validation set from train data frame. We don't know what it represents in real life as it was created using CTGAN, so I'll split it randomly.\n\n[back to the top](#0)","2a9ca2bc":"**This metrics are just for training data. Now I will evaluate model on validation data with predicted probability.**\n\n[back to the top](#0)","2f4c3211":"There is no null value in training set.\n\n[back to the top](#0)","dbad0335":"<a id=\"0\"><\/a> <br>\n# Table of Contents\n\n1. [Introduction to Tabular Playground Series - Nov 2021](#1)\n    1. [Variable Describtions](#7)\n1. [Load and Glance at the Data](#2)\n1. [Missing Values](#3)\n1. [Create a Validation Set](#4)\n    1. [Remove target column](#5)\n1. [Feature Scaling](#6)    \n1. [First Model](#8)\n    1. [Evaluation Metrics for Training set](#9)\n    1. [Evaluation Metrics for Validation set](#10)\n    1. [First Submission](#11)\n1. [Selecting Models](#12)  \n    1. [Helper Functions to Try New Models](#13) \n    1. [Split to the Small Data for Evaluating Models Fast](#14)\n    1. [ML Models](#15)\n    1. [XGBoost](#16)","cc5d4159":"[Variable Describtions](#7)\n\n[back to the top](#0)","8aa6fc30":"<a id=\"6\"><\/a> <br>\n# 5. Feature Scaling\nIn order to, ML algorithms perform well, I will scale data with Standardization method.\n\n[Variable Describtions](#7)\n\n[back to the top](#0)","6f2201ff":"**x_train is still contained id column!**","4d61bf68":"<a id=\"1\"><\/a> <br>\n# 1. Introduction to Tabular Playground Series - Nov 2021 \n\nTPS is a monthly competition prepared by Kaggle. The data is used for this competition is synthetic, but based on a real dataset and generated using a CTGAN. More information can be found on the [Competition Overview Page](https:\/\/www.kaggle.com\/c\/tabular-playground-series-nov-2021\/overview).\n\n**The goal** is **predicting probability** of the observed target 0 or 1. So it is **supervised learning** and **classification task**. Also **evaluation metric** is selected **area under the ROC curve**.\n\n[back to the top](#0)","65bea3ed":"[back to the top](#0)","e46c23c8":"<a id=\"13\"><\/a> <br>\n## A. Helper Functions to Try New Models\n[back to the top](#0)","a9e76014":"<a id=\"11\"><\/a> <br>\n## C. First Submission\n[back to the top](#0)","ea6b2084":"<font color=green>All variables is numerical. So we will not strive with categorical data.<\/font>","7bdabf40":"<a id=\"2\"><\/a> <br>\n# 2. Load and Glance at the Data\nFirst things first, load and glance at the data.\n\n[back to the top](#0)","6c6a3769":"[back to the top](#0)","7904de23":"<a id=\"10\"><\/a> <br>\n## B. Evaluation Metrics for Validation set","c2e9a06b":"[back to the top](#0)","fa833fe3":"[back to the top](#0)","e3853160":"[Variable Describtions](#7)\n\n[back to the top](#0)","30f12650":"<a id=\"14\"><\/a> <br>\n## B. Split to the Small Data for Evaluating Models Fast\n[back to the top](#0)","6f46634f":"<a id=\"7\"><\/a> <br>\n## A. Variable Describtions:\n- **df_train** : Pandas data frame for training data set\n- **df_test** : Pandas data frame for test data set\n- **x_all_train** : All training data\n- **y_all_train** : All labels for training data\n\n\n- **train_set** : Training Pandas data frame is splitted from training data set\n- **val_set** : Validation Pandas data frame is splitted from training data set\n\n#### Development Data Frames:\n- **x_train** : Pandas data frame removed target columns from train_set\n- **y_train** : List of targets from train_set\n- **x_val** : Pandas data frame removed target columns from val_set\n- **y_val** : List of targets from val_set\n- **df_test_dev** : Standardized Pandas data frame for test data set","e0fc9738":"There is no null data in test set. \n\n[Variable Describtions](#7)","fe492f67":"### Submission with XGB","cf36e39a":"<a id=\"12\"><\/a> <br>\n# 7. Selecting Models\n[back to the top](#0)","6bb26fa1":"### Probability of Predictions","7d8b6b75":"[back to the top](#0)","8f371a21":"<a id=\"16\"><\/a> <br>\n## C. XGBoost\n[back to the top](#0)","091cf9fd":"We knew there is any null value, just use the way.\n\n[back to the top](#0)","e4b50910":"[Variable Describtions](#7)\n\n[back to the top](#0)","5f3439fb":"### XGB Evaluation","d16f732e":"## Create a Pipeline for Preparing Data to Training","f6f427cf":"<a id=\"5\"><\/a> <br>\n## A. Remove Target Column\nRemove target and id columns from train_set and make x_train data frame and make y_train list.\n\n[back to the top](#0)","6c8036f8":"<a id=\"3\"><\/a> <br>\n# 3. Missing Values\nCheck missing values with several ways.\n\n[back to the top](#0)","900fa004":"[Variable Describtions](#7)\n\n[back to the top](#0)","af8c41e2":"<a id=\"9\"><\/a> <br>\n## A. Evaluation Metrics for Training set","fcc5ac73":"<a id=\"15\"><\/a> <br>\n## C. ML Models\n[back to the top](#0)","b0652b3f":"[back to the top](#0)","6eddb749":"<a id=\"8\"><\/a> <br>\n# 6. First Model and Submit\nI will apply simple ML models first and submit to the competition."}}