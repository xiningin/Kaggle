{"cell_type":{"eb35b834":"code","5a86ef2b":"code","3e6795fd":"code","aaab5678":"code","bc4e99f2":"code","b8fefbec":"code","b4220a56":"code","286774b0":"code","ee0a7080":"code","7a85aabe":"code","1c69129f":"code","07b5e2ab":"code","2ef31d0b":"code","a4705d63":"code","01985e82":"code","6c0d1a08":"code","e7b9afc0":"code","2f942315":"code","1627e7fc":"code","3a35e2d5":"code","92f0d3d7":"code","80bead87":"code","e9641d75":"code","506de723":"code","c09efa24":"code","088ce289":"code","eaddd903":"code","4a9de852":"code","92f6b8d1":"code","3b7ab8cc":"code","a9a0a377":"code","29d74499":"code","b2c3cb60":"code","fe9ecc8a":"code","55e89784":"markdown","90a076b9":"markdown","96a2c8d2":"markdown","2a35d843":"markdown","968d92c2":"markdown","01ba35ab":"markdown","0baecabb":"markdown","6e49be47":"markdown","9f15e608":"markdown","21ffad8f":"markdown","4699e0b2":"markdown","bcb221de":"markdown","ccbaef08":"markdown","da75985c":"markdown","3c1962a9":"markdown","26a10539":"markdown","dd298c88":"markdown","cfb9469a":"markdown","c9c81e42":"markdown","63465317":"markdown","9c5b76c1":"markdown","adb44517":"markdown","a64dc22a":"markdown","a4777172":"markdown","bbcf6f21":"markdown","ba3ceaa0":"markdown","9c6c250e":"markdown","62dedbd0":"markdown","e3d4f3f7":"markdown","951cd362":"markdown","a976d8b5":"markdown","d2874dae":"markdown","d71d35c4":"markdown","72e1fbaf":"markdown","4cd9b7b6":"markdown","6febb932":"markdown"},"source":{"eb35b834":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","5a86ef2b":"from matplotlib import pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objects as go\nimport warnings\n\ninit_notebook_mode(connected=True)\n\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline","3e6795fd":"data_file = r'\/kaggle\/input\/us-accidents\/US_Accidents_Dec20.csv'\ndf = pd.read_csv(data_file)\ndf.columns","aaab5678":"df.drop(columns=['End_Lat', 'End_Lng' ,'Number', 'Airport_Code' ,'Weather_Timestamp' , 'TMC' , \n                 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight',\n                 'Country','ID', 'Source','Timezone'], inplace=True)\n","bc4e99f2":"from pprint import pprint\ndef sanity_check(df):\n    pprint('-'*70)\n    pprint('No. of Row : {0[0]}        No. of Columns : {0[1]}'.format(df.shape))\n    pprint('-'*70)\n    data_profile = pd.DataFrame(df.dtypes.reset_index()).rename(columns = {'index' : 'Attribute' ,\n                                                                           0 : 'DataType'}).set_index('Attribute')\n    data_profile = pd.concat([data_profile,df.isnull().sum()], axis=1).rename(columns = {0 : 'Missing Values'})\n    data_profile = pd.concat([data_profile,df.nunique()], axis=1).rename(columns = {0 : 'Unique Values'})\n    pprint(data_profile)\n    pprint('-'*70)","b8fefbec":"df.dropna(subset=['City','Sunrise_Sunset','Description'], inplace=True)","b4220a56":"df['Start_Time'] = pd.to_datetime(df['Start_Time'])\ndf['End_Time'] = pd.to_datetime(df['End_Time'])","286774b0":"sanity_check(df)","ee0a7080":"top_10_state = df[['City','State' , 'Severity']].groupby('State').agg({'City' : 'count' , \n                                                       'Severity' : 'mean' }).sort_values(\n    by='City',ascending=False).head(10)","7a85aabe":"df_state_city = df[['State' , 'City','Severity']].groupby(['State' , 'City']).count().rename(columns = {'Severity' : 'Count'})\n\ntop_10_city = df_state_city.sort_values(by='Count' , ascending = False).head(10)","1c69129f":"fig , (ax1, ax2) = plt.subplots(1,2,figsize=(14,4))\n\nbar = sns.barplot(x=top_10_state.index , y=top_10_state['City'],\n                  palette='nipy_spectral_r' , \n#                   palette='pastel' , \n                  edgecolor = 'black',\n                  ax=ax1 )\nsns.despine(left = True )\nax1.set_xlabel(\"State\")\nax1.set_ylabel(\"No. of Accidents\" , fontdict = {'fontsize':16 , 'color':'MidnightBlue'})\nax1.set_title('Top 10 Accident States in US', fontdict = {'fontsize':16 , 'color':'MidnightBlue'})\n# ax3=ax1.twinx()\n# ax3.plot(top_10_state['Severity'] ,'o-', color='lightgray')\n# ax3.set_ylabel('Severity')\n\n\nbar = sns.barplot(x=top_10_city.index.get_level_values(1) , y=top_10_city['Count'],\n                  palette='nipy_spectral' , \n#                   palette='pastel' , \n                  edgecolor = 'black',\n                  ax=ax2\n                 )\nsns.despine(left = True )\nax2.set_xlabel(\"City\" )\nax2.set_ylabel(\"No. of Accidents\")\nax2.set_title('Top 10 Accident Cities in US', fontdict = {'fontsize':16 , 'color':'MidnightBlue'})\nplt.xticks(rotation = 45)\n\n\n# Working to get labels for percentages\ntotal_accidents = len(df)\n\n# for state\nfor p in ax1.patches :\n    height = p.get_height()\n    ax1.text(p.get_x() + p.get_width()\/2,\n            height + 20000,\n            '{:.2f}%'.format(height\/total_accidents*100),\n            ha = \"center\",\n            fontsize = 8, color='indianred')\n\n    \n# for City\nfor p in ax2.patches :\n    height = p.get_height()\n    ax2.text(p.get_x() + p.get_width()\/2,\n            height + 3000,\n            '{:.2f}%'.format(height\/total_accidents*100),\n            ha = \"center\",\n            fontsize = 8, color='indianred')\n    \n    \nfig.show()\n\n","07b5e2ab":"# Creating Date Time series attributes\n\n\ndf['Year'] = df['Start_Time'].dt.year\ndf['Month'] = df['Start_Time'].dt.month  # .dt.month_name()\ndf['Hour'] = df['Start_Time'].dt.hour\ndiff = df['End_Time'] - df['Start_Time']\ndf['DelayTime'] = round(diff.dt.seconds\/3600,1)\nyear = df['Year'].value_counts()\nmonth = df['Month'].value_counts().sort_index()\nmonth_map = {1:'Jan' , 2:'Feb' , 3:'Mar' , 4:'Apr' , 5:'May' , 6:'Jun', 7:'Jul' , 8:'Aug' \n             , 9:'Sep',10:'Oct' , 11:'Nov' , 12:'Dec'}\n\nhour_severity = df[['Hour' , 'Severity']].groupby('Hour').agg({'Hour' : 'count' , 'Severity' : 'mean'})\n\ndf['Day'] = df['Start_Time'].dt.dayofweek\nday_severity = df[['Day' , 'Severity']].groupby('Day').agg({'Day' : 'count' , 'Severity' : 'mean'})\nday_map = {0:'Monday' , 1:'Tueday' , 2:'Wedday' , 3:\"Thuday\" , 4:'Friday' , 5:\"Saturday\" , 6:'Sunday'}\n\n\n# df['Month'].head()","2ef31d0b":"hour_severity = df[['Hour' , 'Severity']].groupby('Hour').agg({'Hour' : 'count' , 'Severity' : 'mean'})\n\ndf['Day'] = df['Start_Time'].dt.dayofweek\nday_severity = df[['Day' , 'Severity']].groupby('Day').agg({'Day' : 'count' , 'Severity' : 'mean'})\nday_map = {0:'Monday' , 1:'Tueday' , 2:'Wedday' , 3:\"Thuday\" , 4:'Friday' , 5:\"Saturday\" , 6:'Sunday'}\n","a4705d63":"fig,(ax1,ax2) = plt.subplots(1,2,figsize=(14,5))\n\n\n# plot for year\n\nlight_palette = sns.color_palette(palette='pastel')\n\nyear_color_map = ['Lavender' for _ in range(5)]\nyear_color_map[0] = 'LightCoral' #light_palette[0]\nyear_color_map[4] = 'PaleGreen' #light_palette[2]\n\nyears = ax1.bar(year.index.values , year, color=year_color_map , edgecolor = 'black')\nax1.spines[('top')].set_visible(False)\nax1.spines[('right')].set_visible(False)\nax1.set_xlabel(\"Years\", fontdict = {'fontsize':12 , 'color':'MidnightBlue'} )\nax1.set_ylabel(\"No. of Accidents\")\nax1.set_title('Accidents per Years', fontdict = {'fontsize':16 , 'color':'MidnightBlue'})\n\nfor p in ax1.patches :\n    height = p.get_height()\n    ax1.text(p.get_x() + p.get_width()\/2,\n            height + 20000,\n            '{:.2f}%'.format(height\/total_accidents*100),\n            ha = \"center\",\n            fontsize = 8, color='Blue')\n\n    \n# plot for month\n\n\nmonth_color_map = ['Lavender' for _ in range(12)]\nmonth_color_map[11] = 'LightCoral' #light_palette[0]\nmonth_color_map[6] = 'PaleGreen' #light_palette[2]\n\nm = sns.barplot( x= month.index.map(month_map), y=month,  ax = ax2, palette=month_color_map , edgecolor='black' )\nplt.xticks(rotation=60)\nax2.set_xlabel(\"Months\", fontdict = {'fontsize':12 , 'color':'MidnightBlue'} )\nax2.set_ylabel(\"No. of Accidents\")\nax2.set_title('Accidents per Months', fontdict = {'fontsize':16 , 'color':'MidnightBlue'})\nsns.despine(left=True)\n\nfor p in ax2.patches :\n    height = p.get_height()\n    ax2.text(p.get_x() + p.get_width()\/2,\n            height + 8000,\n            '{:.2f}%'.format(height\/total_accidents*100),\n            ha = \"center\",\n            fontsize = 8, color='blue')\n\nax1.grid(axis='y', linestyle='-', alpha=0.4)    \nax2.grid(axis='y', linestyle='-', alpha=0.4) \n    \nplt.show()\n","01985e82":"fig, (ax , ax2, ax3) = plt.subplots(1,3,figsize = (16,6))\n\nsns.set_context('paper')\n\n# f = sns.lineplot(x=day_severity['Day'].index.map(day_map) , y=day_severity['Severity'], \n#                  ax = ax,  label='Severity', legend = 'full' , dashes=True, palette=light_palette, color='red')\n\n\nax.plot(day_severity['Severity'] ,  color='Turquoise', label=day_map,linewidth=3,\n           linestyle='solid',marker='.',markersize=18, markerfacecolor='w',markeredgecolor='b',markeredgewidth='2')\n\n\nax.set_xlabel(\"Days of the week\", fontdict = {'fontsize':12 , 'color':'MidnightBlue'} )\nax.set_ylabel(\"Severity Level\")\nax.set_title('Severity by day of week', fontdict = {'fontsize':16 , 'color':'MidnightBlue'})\n\n\nax2.plot(day_severity['Day'] ,  color='Turquoise', label=day_map,linewidth=3,\n           linestyle='solid',marker='.',markersize=18, markerfacecolor='w',markeredgecolor='b',markeredgewidth='2')\n\nax2.set_xlabel(\"Days of the week\", fontdict = {'fontsize':12 , 'color':'MidnightBlue'} )\nax2.set_ylabel(\"No. of Accidents\")\nax2.set_title('Accidents Count by day', fontdict = {'fontsize':16 , 'color':'MidnightBlue'})\n\nf2 = sns.barplot(x=day_severity['Day'].index.map(day_map) , y=day_severity['Day'], ax = ax3, palette = 'nipy_spectral_r')\nplt.xticks(rotation=60)\nax3.set_xlabel(\"Days of the week\", fontdict = {'fontsize':12 , 'color':'MidnightBlue'} )\nax3.set_title('Accidents count on days of week', fontdict = {'fontsize':16 , 'color':'MidnightBlue'})\n\nsns.despine(left=True)\n\nfig.show()","6c0d1a08":"\nfig, ax = plt.subplots(1,1,figsize = (14,6))\n\nsns.set_context('paper')\n\n# ax.plot(hour_severity['Hour'], color='Salmon' , linewidth=3, linestyle='solid',\n#         marker='*',markersize=18, markerfacecolor='w',markeredgecolor='m',markeredgewidth='2',\n#         label = 'No. of Accidents'\n#        )\n\n\nf = sns.barplot(x=hour_severity['Hour'].index , y=hour_severity['Hour'], ax = ax, palette='Pastel2')\n\nax2 = ax.twinx()\n\nax2.plot(hour_severity['Severity'] , color='CornFlowerBlue', label='Severity',linewidth=3,\n           linestyle='solid',marker='.',markersize=18, markerfacecolor='w',markeredgecolor='b',markeredgewidth='2')\n\nsns.despine(left=True)\n# ax.spines[('top')].set_visible(False)\n# ax.spines[('right')].set_visible(False)\n# ax.spines[('left')].set_visible(False)\nax2.spines[('top')].set_visible(False)\nax2.spines[('right')].set_visible(False)\nax2.spines[('left')].set_visible(False)\nax.set_xlabel(\"Hours of the Day\", fontdict = {'fontsize':12 , 'color':'MidnightBlue'} )\nax.set_ylabel(\"No. of Accidents\")\nax2.set_ylabel(\"Severity of Accidents\", rotation=270 ,labelpad=20)\nax.set_title('Accidents and Severity per Hour of the day', fontdict = {'fontsize':16 , 'color':'MidnightBlue'})\n# ax.legend(loc=(0,1))\nax2.legend(loc=(0,0.8))\n\nax.annotate('Morning office rush' , xytext=(3,150000) , xy=(7,5000),arrowprops={'arrowstyle':'fancy' , 'color':'Red'})\nax.annotate('Office Returning rush' , xytext=(19,150000),xy=(16,5000),arrowprops={'arrowstyle':'fancy', 'color':'Red'})\n\nfig.show()\n","e7b9afc0":"sev_4_mean = df[df['Severity'] == 4][['Severity','Year']].groupby('Year').count().mean()\nsev_4_mean[0]","2f942315":"f , (ax1,ax2) = plt.subplots(1,2,figsize=(16,6))\n\ndf['Severity'].value_counts().plot.pie(autopct = '%1.1f%%' , ax=ax1, colors =sns.color_palette(palette='Pastel1') ,\n                                      pctdistance = 0.8, explode = [.03,.03,.03,.03], \n                                       textprops = {'fontsize' : 12 , 'color' : 'DarkSlateBlue'},\n                                       labels=['Severity 2','Severity 3' , 'Severity 4' , 'Severity 1']\n                              )\n\nax1.set_title(\"Accidents Severity\", fontdict = {'fontsize':16 , 'color':'MidnightBlue'} )\n\n\ns = sns.countplot(data=df[['Severity','Year']] , x = 'Year' , hue='Severity' , ax=ax2, palette = 'rainbow' \n                  , edgecolor='black')\nax2.axhline(sev_4_mean[0] ,color='Blue', linewidth=1, linestyle='dashdot')\nax2.annotate(f\"Severity 4 mean : {sev_4_mean[0]}\",\n            va = 'center', ha='center',\n            color='#4a4a4a',\n            bbox=dict(boxstyle='round', pad=0.4, facecolor='Wheat', linewidth=0),\n            xy=(1,80000))\n\nax2.set_title(\"Severity levels by years\", fontdict = {'fontsize':16 , 'color':'MidnightBlue'} )\n\nsns.despine(left=True)","1627e7fc":"pair = sns.pairplot(df[['Severity','Temperature(F)','Humidity(%)','Pressure(in)']].dropna(), hue='Severity', palette='nipy_spectral')\n# pair = sns.pairplot(df[['Severity','Temperature(F)']].dropna(), hue='Severity', palette='nipy_spectral')\n\npair.fig.suptitle('Distribution of Temp , Humidity and Pressure with Severity', y =1.08 \n                  , fontsize = 16 , color = 'MidnightBlue' , ha = 'center' , va='top')\n\nplt.show()\n\n","3a35e2d5":"# Generalization of Weather condition\n\nconditions = df['Weather_Condition'].dropna().unique().tolist()\n\ncondition_map = dict()\n\n\nfor x in conditions :\n    if x.lower().find('snow')>0 or x.lower().startswith('snow') or x.lower().find('ice')>0 or x.lower().startswith('ice'):\n        condition_map[x] = 'Snow Situation'\n    elif (x.lower().find('rain')>0 or x.lower().find('drizzle')>0 or \n          x.lower().startswith('rain') or x.lower().startswith('drizzle') or\n          x.lower().find('thunder')>0 or x.lower().startswith('thunder')):\n        condition_map[x] = 'Rainy Situation'\n    elif (x.lower().find('storm')>0 or x.lower().find('thunder')>0):\n        condition_map[x] = 'Storm Situation'\n    elif (x.lower().find('cloud')>0 or x.lower().startswith('cloud')>0):\n        condition_map[x] = 'Cloudy'\n    elif (x.lower().find('fog')>0 or x.lower().startswith('fog')>0):\n        condition_map[x] = 'Fog'\n    elif (x.lower().find('dust')>0 or x.lower().startswith('dust')>0):\n        condition_map[x] = 'Dust'\n    elif (x.lower().find('wind')>0 or x.lower().startswith('wind')>0):\n        condition_map[x] = 'Windy'\n    else:\n        condition_map[x] =x\n\n\ndf['Weather'] = df['Weather_Condition'].map(condition_map)\n# df['Weather'].value_counts().sort_values(ascending=False).head(20)\ntotal = len(df['Weather'])\n# total\ntop_10_weather = df['Weather'].value_counts()[:10]\ntop_15_weather = df['Weather'].value_counts()[:13]\n\ntop_10_weather\n# condition_map\n\n\n","92f0d3d7":"def check_exist(x):\n    if x in top_15_weather :\n        return x\n    else :\n        return 'Other'\n\ndf['Weather2'] = df['Weather'].apply(check_exist)\n\ncmap = {x:y for (x,y) in zip(top_10_weather.index , sns.color_palette('pastel'))}","80bead87":"# Analysing the 'Weather_Condition' attribute\n\nfig,(ax,ax2) = plt.subplots(1,2,figsize = (16, 6))\n\nsns.countplot(y='Weather', data=df[['Weather','Severity']], order=df['Weather'].value_counts()[:10].index, \n              palette=cmap , edgecolor = 'black' , \n              ax= ax)\n\n\nax.set_xlabel(\"Accident Counts\", fontdict = {'fontsize':12 , 'color':'MidnightBlue'} )\nax.set_ylabel(\"Top 10 Weather Conditions\")\nax.set_title('Comparison of Weather Conditions', fontdict = {'fontsize':16 , 'color':'MidnightBlue'}, pad=15)\n\n\nsns.countplot(y='Weather', data=df, order=df[df['Severity'] == 4]['Weather'].value_counts()[:10].index, \n              palette=cmap, edgecolor = 'black' ,  ax= ax2)\n\nax2.set_xlabel(\"Accident Counts\", fontdict = {'fontsize':12 , 'color':'MidnightBlue'} )\nax2.set_ylabel(\"Severity 4 Weather Conditions\")\nax2.set_title('Severity-4 Weather distribution', fontdict = {'fontsize':16 , 'color':'MidnightBlue'}, pad=15)\n\n\n# ax.grid(axis='y', linestyle='-', alpha=0.4) \nsns.despine(left=True)\n\nplt.show()","e9641d75":"fig, ax = plt.subplots(1,1,figsize=(16,5))\n\nw = sns.pointplot(y='DelayTime',x='Weather2',data=df[['Weather2','DelayTime','Severity']],\n                  hue = 'Severity'\n                  ,ci=None  , \n               order= top_10_weather.index, #kind = 'point',\n               height=4, aspect=2 , palette='nipy_spectral', ax= ax)\n\nax.grid(axis='y', linestyle='-', alpha=0.4)  \n\n# w = sns.lineplot(x='Weather2', y='DelayTime' , data=df[['Weather2','DelayTime']] , hue_order= top_15_weather.index)\n\nplt.xlabel(\"Weather conditions\", fontdict = {'fontsize':12 , 'color':'MidnightBlue'} )\nplt.xticks(fontsize=12 , rotation = 45)\nplt.ylabel(\"Delay Times (in Hours)\")\n\nax.set_title('Delay times for different Weather Conditions', fontdict = {'fontsize':16 , 'color':'MidnightBlue'}, pad=15)\n\nplt.show()\n","506de723":"df['Severity'] = df['Severity'].astype('int')","c09efa24":"# plotting correlations on a heatmap\n\nfeatures = ['Severity','Temperature(F)', 'Humidity(%)', \n       'Pressure(in)', 'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)',\n       'Precipitation(in)', 'Amenity', 'Bump', 'Crossing',\n       'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station',\n       'Stop', 'Traffic_Calming', 'Traffic_Signal', \n       'Sunrise_Sunset']\n\nmask = np.zeros_like(df[features].corr(), dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# [df['Severity'] == 4]\n\nplt.figure(figsize=(16,12))\nsns.heatmap(df[features].corr(), cmap=sns.diverging_palette(240, 10, as_cmap=True), square=True, \n            annot=True, fmt='.2f', center=0, linewidth=2, cbar=True , mask = mask)\n\n\nplt.show()","088ce289":"df_nyc = df[df['City'] == 'New York']\n\nyear = df_nyc['Year'].value_counts()\nmonth = df_nyc['Month'].value_counts().sort_index()\nmonth_map = {1:'Jan' , 2:'Feb' , 3:'Mar' , 4:'Apr' , 5:'May' , 6:'Jun', 7:'Jul' , 8:'Aug' \n             , 9:'Sep',10:'Oct' , 11:'Nov' , 12:'Dec'}\nhour = df_nyc['Hour'].value_counts().sort_index()\n\nhour_severity = df_nyc[['Hour' , 'Severity']].groupby('Hour').agg({'Hour' : 'count' , 'Severity' : 'mean'})\n\n# df_nyc['Day'] = df_nyc['Start_Time'].dt.dayofweek\nday_severity = df_nyc['Day'].value_counts().sort_index()\n# day_severity = df_nyc[['Day' , 'Severity']].groupby('Day').agg({'Day' : 'count' , 'Severity' : 'mean'})\nday_map = {0:'Monday' , 1:'Tueday' , 2:'Wedday' , 3:\"Thuday\" , 4:'Friday' , 5:\"Saturday\" , 6:'Sunday'}\nyear_map = {x:x for x in year.index}\nhour_map = {x:x for x in hour.index}\n\nlight_palette = sns.color_palette(palette='pastel')","eaddd903":"day_severity = df_nyc['Day'].value_counts().sort_index()","4a9de852":"fig,([ax1,ax2],[ax3,ax4]) = plt.subplots(2,2,figsize=(16,9))\n\ndef plot_dist(kind  , text ,axis,  red, green  ) :\n    '''\n    Reusable function to plot distribution based on input time criteria\n    Usage : plot_dist(kind, text, axis, red , green) - all params mandatory\n    \n        kind : 'd' for day, 'm' for month , 'y' for year, 'h' for hour\n        red  : list of item to be rendered red (max)\n        green : list of item to be rendered green (min)\n        text : Text to be showns as part of Title\n        axis : Axis to plot on  \n    '''\n    if kind == 'd' :\n        tot, ser, map = 7, day_severity ,  day_map\n    elif kind == 'm':\n        tot, ser, map = 12, month ,  month_map\n    elif kind == 'y':\n        tot, ser, map = 5, year ,  year_map\n    elif kind == 'h':\n        tot, ser, map = 24, hour ,  hour_map\n    \n    day_color_map = ['AliceBlue' for _ in range(tot)]\n    for r in red:\n        day_color_map[r] = 'Crimson' \n    for g in green:\n        day_color_map[g] = 'SpringGreen' \n    \n    d = sns.barplot(x=ser.index.map(map) , y=ser, ax = axis, palette = day_color_map, edgecolor='black' )\n    plt.xticks(rotation=60)\n    axis.set_xlabel(text, fontdict = {'fontsize':12 , 'color':'MediumVioletRed'} )\n    axis.set_title(f'Accidents count on {text}', fontdict = {'fontsize':16 , 'color':'MidnightBlue'})\n    axis.grid(axis='y', linestyle='-', alpha=0.4) \n    \nplt.subplots_adjust(wspace=0.2 , hspace = 0.4)\nplt.suptitle(\"New York City Accidents on Timeseries\" , fontsize = 18 , color=\"RosyBrown\")\n\nplot_dist('d' ,\"Days of the week\", ax3,[0],[5])\nplot_dist('y' ,\"Years\", ax1,[4],[0])\nplot_dist('m' ,\"Months\", ax2, [10],[0])\nplot_dist('h' ,\"Hours\", ax4,red=[7,16],green=[2])\nplt.show()","92f6b8d1":"top_st = df_nyc['Street'].value_counts().sort_values(ascending=False).head(10).index.tolist()","3b7ab8cc":"top_st_severity = df_nyc[df_nyc['Street'].isin(top_st)][['Street' , 'Severity']] .groupby('Street').mean()\n\ntop_st_delay = df_nyc[df_nyc['Street'].isin(top_st)][['Street' , 'DelayTime']] .groupby('Street').mean()","a9a0a377":"fig, (ax,ax2,ax3) = plt.subplots(3,1,figsize=(16,10), sharex=True)\n\nfig.subplots_adjust(hspace=0)\n\nsns.countplot(data = df_nyc[df_nyc['Street'].isin(top_st)][['Street' , 'Severity']] ,\n              x='Street' , ax=ax3, palette='Pastel2',edgecolor = 'Black')\nplt.xticks(rotation=30)\n\nax2.plot( top_st_severity, color='CornFlowerBlue', label='Severity',linewidth=3,\n           linestyle='solid',marker='.',markersize=18, markerfacecolor='w',markeredgecolor='b',markeredgewidth='2')\n\nax.plot( top_st_delay, color='LightCoral', label='Severity',linewidth=3,\n           linestyle='solid',marker='*',markersize=18, markerfacecolor='w',markeredgecolor='b',markeredgewidth='2')\n\nax.spines[('top')].set_visible(False)\nax.spines[('right')].set_visible(False)\nax2.spines[('right')].set_visible(False)\nax3.spines[('right')].set_visible(False)\nax3.set_xlabel(\"NYC Streets\", fontdict = {'fontsize':14 , 'color':'Teal'} )\nax3.set_ylabel(\"No. of Accidents\", fontdict = {'fontsize':12 , 'color':'MidnightBlue'})\nax2.set_ylabel(\"Severity of Accidents\", fontdict = {'fontsize':12 , 'color':'MidnightBlue'})\nax.set_ylabel(\"Avg. Delay Times (Hours)\", fontdict = {'fontsize':12 , 'color':'MidnightBlue'})\nax.set_title('Top NYC Streets - Accident ,  Severity and Delay', fontdict = {'fontsize':16 , 'color':'MidnightBlue'})\nax2.legend(loc=(0.01,0.8))\nax.legend(loc=(0.01,0.8))\nax.grid(axis='x', linestyle='-', alpha=0.4) \nax2.grid(axis='x', linestyle='-', alpha=0.4) \nax3.grid(axis='x', linestyle='-', alpha=0.4) \n\nplt.show()","29d74499":"import plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode,iplot,plot\ninit_notebook_mode(connected=True)","b2c3cb60":"fig = go.Figure(\n    data=go.Choropleth(\n        locations = pd.value_counts(df['State']).index, \n        z = pd.value_counts(df['State']).values.astype(float), \n        locationmode = 'USA-states', \n        colorscale = 'reds', \n        colorbar_title = \" Accident Counts\"), \n    \n    layout=go.Layout(\n        title_text='Accidents Counts by States (Feb 2016\u2014Dec 2020)', \n        title_x=0.5, \n        font=dict(family='Calibri', size=14, color='MidnightBlue'), \n        geo_scope='usa'))\n\nfig.show()","fe9ecc8a":"fig = px.density_mapbox(df_nyc, lat='Start_Lat', lon='Start_Lng', z='Severity', hover_name='Street', radius=5,\n                        center=dict(lat=40.730610, lon=-73.935242), zoom=12,\n                        mapbox_style=\"open-street-map\", height=900)\n\nfig.show()","55e89784":"---\n\n<p style=\"font-family:Segoe Print ;font-size:1.5em; color:MidnightBlue; font-style:bold\" >\nWhen do most delays happens after the accidents ?\n<\/p>\n\n---\n","90a076b9":"---\n\n<p style=\"font-family:Segoe Print ;font-size:1.5em; color:MidnightBlue; font-style:bold\" >\nPresent the Accidents on the NY City map\n<\/p>\n\n---","96a2c8d2":"All the initial setup of data looks ready for our analysis now. ","2a35d843":">**Morning 7 AM to 9 AM and evening 4 PM to 6 PM are the prime hours when most of the accidents happened.**  (Looks like when pandemic is over, I will have to change my office commute start time, just to be more safe :-) )\n\n>**Although that is true, the accidents occuring between 3 AM to 5 AM tends be extremely severe. Likewise, accidents occuring between 8 PM to 9 PM tends to be high severity.**\n\n\n","968d92c2":"#### Its time to run our reusable sanity check function on the cleaned dataframe now.","01ba35ab":"---\n\n<p style=\"font-family:Segoe Print ;font-size:1.5em; color:MidnightBlue; font-style:bold\" >\nWhat are most accidents occuring streets in NYC ?\n<\/p>\n\n---","0baecabb":">**Most of accidents fall in Severity 2 category (71%)**\n\n>Examining the severity levels over the years, it is seen that Severity 4 accidents have been closely in the same range over the years. However, Severity 2 and Severity 1 accidents have been increasing drastically by years. At the same time Severity 3 level accidents are descreasing. **This indicates that measures taken by Road Governance departments in last two years across USA are proving effective in reducing the Severity 3 accidents into Severity 1 and Severity 2 (kudos).**\n","6e49be47":"#### Our analysis has more focus on locations and time of the accirdents. The columns 'City' has 137 rows null (which is very low compared to total row count). We will remove these rows from dataset\n\nSimilarly, Sunrise_sunset and Description columns has less than 10 rows with null rows, dropping those rows from dataset.","9f15e608":"---\n\n<p style=\"font-family:Segoe Print ;font-size:1.5em; color:mediumVioletRed; font-style:bold\" >\nUnderstanding Source Dataset\n<\/p>\n\n\nSource data used for the analysis is collection of all the realtime traffic accidents reported by number of traffic monitoring APIs over the period from Feb 2016 till Dec 2020. There are 4.2 million accident records in the dataset and 49 columns contributing to variety of information of each accidents.\n\nFor understanding the data better and for further analysis , I have all classified all the features from the data into below subject categories:\n\n\n**Record\/source API identifiers :**\n            \n        ID, Source, TMC \n\n**Accident properties :**\n        \n        Severity, Start_Time, End_Time, Start_Lat, Start_Lng, End_Lat, End_Lng, Distance(mi)\n\n**Location properties :**\n        \n        Description, Number, Street, Side, City, County, State, Zipcode, Country, Timezone, Airport_Code, \n\n**Weather Condition Properties :**\n        \n        Weather_Timestamp, Temperature(F), Wind_Chill(F), Humidity(%), Pressure(in), Visibility(mi), Wind_Direction, Wind_Speed(mph), Precipitation(in), Weather_Condition, Sunrise_Sunset, Civil_Twilight, Nautical_Twilight, Astronomical_Twilight\n\n**Nearby landmark properties :**\n        \n        Amenity, Bump, Crossing, Give_Way, Junction, No_Exit, Railway, Roundabout, Station, Stop, Traffic_Calming, Traffic_Signal, Turning_Loop,\n\n\n<br>\n\n\n\n**Dataset Link** : https:\/\/www.kaggle.com\/sobhanmoosavi\/us-accidents\n\n------\n","21ffad8f":">We can see that CA is the states with most accidents in last 4 years - close to 23% of all the accidents in the country. \n\n>Texas is the second higheest in no. of accidents. \n\n>When it comes to cities, Houston and Dallas (both TX) are in list of top 5 accident reported cities.\n","4699e0b2":"#### Accidents in NYC on time series","bcb221de":"---\n\n<p style=\"font-family:Segoe Print ;font-size:1.5em; color:MidnightBlue; font-style:bold\" >\nWhat are common factors associated with high severity of the accidents ?\n<\/p>\n\n---","ccbaef08":"In this Kernel , I will try to explore the US accidents data from Feb 2016 till Dec 2020 and try to validate key objective as listed below. If you like the work here , please upvote, will love to hear comments and suggestions for improvements. Thanks !\n\n\n***Special Thanks to the Contributor of this dataset- Sobhan Moosavi and Team for coming up and sharing this amazing data set that offers so many excellent features from realworld parameters around US Accidents.***\n\n<br>\n\n---\n\n<p style=\"font-family:Segoe Print ;font-size:1.5em; color:mediumVioletRed; font-style:bold\" >\nObjectives : \n<\/p>\n\nThe primary goal of the project is to analyze and generate insights on the traffic accidents that took place in USA between 2016 and 2020. The first part of the analysis will examine contry-wide aspects. In second part, New York data will be handled for closer examination. Specifically - \n\n**Contry-wide Analysis :**\n    1. Identify top 10 States and top 10 Cities with most accidents\n    2. Analyze accident trends over time series (Month over month, year over year, day of the week)\n    3. What time do most of the accidents occur ?\n    4. Is there a change in accident severity levels over the years ? \n    5. Do Weather Conditions have effect on Accidents ?\n    6. When do most delays happens after the accidents ?\n    7. Examine accident severity correlations with available features (like temp, visibility, day or night etc.)\n    \n**New York City Analysis :**\n    1. Compare New York Accidents for week days and hours of the day\n    2. What are most accident occuring streets in New York?\n    3. Present the Accidents on the NY City map\n    \n","da75985c":"---\n\n<p style=\"font-family:Segoe Print ;font-size:1.5em; color:MidnightBlue; font-style:bold\" >\nAccidents trends on time series\n<\/p>\n\n---\n","3c1962a9":">Saturday and Sunday are usually low days for number of accidents. However, the severity of the accidents occuring on Saturday and Sunday is comparatively at higher levels.","26a10539":"#### Converting the date columns from object datatypes to date datatype","dd298c88":"Now analysing the weather conditions","cfb9469a":"#### Continuing to view the data on different time scale - Week days","c9c81e42":"This is a big data set with plenty of fields to consider in analysis. However , some of the fields here can be an over-engineering.\nBefore going further, I would want to get some of the fields removed to lighten up the dataframe. Fields that I would be dropping are :\n\n* 'End_Lat', 'End_Lng' - Lattitudes , Longitude at the end of the accidents (we already have start co-ordinates to use for this purpose).\n\n* 'Number' - street apt number.\n\n* 'Airport_Code' - Nearest airport code.\n\n* 'Country' - All data is for USA.\n\n* 'Weather_Timestamp' , 'TMC' , 'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight', 'Id', 'Source'\n\n* Timezone \n\n\n","63465317":"#### We will setup few time series here to use them further for building various view points on accidents","9c5b76c1":">**The maximum amount of traffic delays due to accidents are occurring when the conditions are smokey (seems wildfire or fire hazards scenarios)**\n\n>**Rainy and Snow Situations are among the usual delay accident ranges**","adb44517":"---\n\n<p style=\"font-family:Papyrus ;font-size:2em; color:MediumSlateBlue\" >\nUS Accidents Exploratory Analysis on New York Map\n\n<\/p>\n\n---","a64dc22a":"---\n\n<p style=\"font-family:Segoe Print ;font-size:1.5em; color:MidnightBlue; font-style:bold\" >\nInitial Cleanup of the data\n<\/p>\n\n---","a4777172":">Features like Traffic Signals and Crossings are having negative corelations with accident severity.\n\n>Surprisingly , visibility does not have any signficant corelation with accident severity.","bbcf6f21":"We will be generalizing availalbe variety of weather conditions here into more higher\/broader categories. That will help us avoid micro-noise and focus on the high contributing weather conditions with respect to accidents","ba3ceaa0":"#### Visualizing the timeseries plot now .. \n","9c6c250e":"I am creating a reusable function that I can run on any dataframe to perform quick basic sanity of the data.","62dedbd0":"---\n\n<p style=\"font-family:Segoe Print ;font-size:1.5em; color:MidnightBlue; font-style:bold\" >\nTop 10 States and Top 10 Cities with most accidents\n<\/p>\n\n---","e3d4f3f7":"---\n\n<p style=\"font-family:Segoe Print ;font-size:1.5em; color:MidnightBlue; font-style:bold\" >\nIs there a change in accident severity levels over the years ?\n<\/p>\n\n---\n","951cd362":">Most of the accidents (irrespective of Severity Level) at occuring in Temperature ranges between 50 to 80 F. This does not offer any greater insight.\n\n>**When Humidity histogram is reviwed, we can see that High Humidity (80 to 100) is always a favorable factor for Severity 1, 2 and 3 Level accident occurence. This in general is indicating that weather condition associated with rainy situation is more prone to accident.**","a976d8b5":"---\n\n<p style=\"font-family:Segoe Print ;font-size:1.5em; color:MidnightBlue; font-style:bold\" >\nWhat time do most of the accidents occur ?\n<\/p>\n\n---","d2874dae":"\n>**Highest number of accidents occured when weather conditions are cloudy. Rainy situations are among top 5 conditions , however it is not the topmost conditions for accidents.**","d71d35c4":"---\n\n<p style=\"font-family:Segoe Print ;font-size:1.5em; color:MidnightBlue; font-style:bold\" >\nExamining the Severity associtation with Temperature, Humidity and Pressure\n<\/p>\n\n---","72e1fbaf":"Finally, realizing that I am needing to perform same plotting repeatedly for different time series ,I created this reusable function to plot the accidents on the time parameters. The function takes in the frequency parameter (day, year, month etc) and accordingly handles the plotting.","4cd9b7b6":"---\n\n<p style=\"font-family:Segoe Print ;font-size:1.5em; color:MidnightBlue; font-style:bold\" >\nDo Weather Conditions have effect on Accidents ?\n<\/p>\n\n---","6febb932":"---\n\n<p style=\"font-family:Segoe Print ;font-size:1.5em; color:MidnightBlue; font-style:bold\" >\nZero-in on New York city accidents\n<\/p>\n\n---\n"}}