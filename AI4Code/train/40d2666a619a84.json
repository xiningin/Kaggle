{"cell_type":{"940d783f":"code","d0578346":"code","1767242f":"code","ecc414ac":"code","a48f362b":"code","8b2e79ba":"code","c1025a00":"code","21d945f7":"code","b13f29c3":"code","88d8bcd3":"code","05f5d32a":"code","ecb83bba":"code","28491d5b":"code","6b4edf95":"code","eb473e2b":"code","cdc1d286":"code","40815040":"code","a3aa86d5":"code","c9ff80fe":"code","e2c94a77":"code","e937720a":"code","c2684a1f":"code","21a92a2b":"code","1e7a7f07":"code","e10a24bb":"code","51f51863":"code","a997ad60":"code","f911d769":"code","154333f9":"code","3fd7a578":"code","ed5b5656":"code","55f50464":"code","b8f4de2d":"code","a851bc8e":"code","1b55b0c9":"code","b19aa3bf":"code","b410ef1d":"code","0c118efa":"code","e8d488eb":"code","fc3ee215":"code","749856d9":"code","64d4b851":"code","6731b0ab":"code","91f7531d":"markdown","12b636c4":"markdown","72281a80":"markdown","4cf1f061":"markdown","e9940636":"markdown","5ad7d332":"markdown","3bf9eebc":"markdown","871060bc":"markdown","1bfd5e23":"markdown","65c82757":"markdown","cdd5c8a4":"markdown","754e7063":"markdown","daab49df":"markdown","133c411e":"markdown","62f1dadc":"markdown","fe771869":"markdown","fb9182ee":"markdown","90753eb2":"markdown","814443ad":"markdown","e4fb8485":"markdown","cf816530":"markdown","3931f737":"markdown","609d6dcb":"markdown","646e968c":"markdown"},"source":{"940d783f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom warnings import simplefilter\nsimplefilter(action='ignore', category=FutureWarning)","d0578346":"dataset1 = pd.read_csv('..\/input\/email-spam-dataset\/completeSpamAssassin.csv')\ndataset2 = pd.read_csv('..\/input\/email-spam-dataset\/enronSpamSubset.csv')\ndataset3 = pd.read_csv('..\/input\/email-spam-dataset\/lingSpam.csv')","1767242f":"print('Dataset 1 shape:',dataset1.shape)\nprint('Dataset 2 shape:',dataset2.shape)\nprint('Dataset 3 shape:',dataset3.shape)","ecc414ac":"dataset1.head()","a48f362b":"dataset2.head()","8b2e79ba":"dataset3.head()","c1025a00":"dataset1.iloc[0]['Body']","21d945f7":"dataset1_1 = dataset1[['Body','Label']]\ndataset2_1 = dataset2[['Body','Label']]\ndataset3_1 = dataset3[['Body','Label']]","b13f29c3":"dataset1_1.head(3)","88d8bcd3":"dataset2_1.head(3)","05f5d32a":"dataset3_1.head(3)","ecb83bba":"df = pd.concat([dataset1_1,dataset2_1,dataset3_1],ignore_index=True).rename(columns={'Body':'Email','Label':'Spam'})","28491d5b":"df.shape","6b4edf95":"df.isnull().sum()","eb473e2b":"# drop the null email\n\ndf.dropna(inplace=True)\ndf.shape","cdc1d286":"df.head()","40815040":"df2 = df","a3aa86d5":"email_length = []\n\nfor email in df2['Email']:\n    email_length.append(len(email))\n    \ndf2['Email length'] = email_length","c9ff80fe":"special_characters = []\n\nfor email in df2['Email']:\n    special_characters_counter = 0\n    for char in email:\n        if not char.isalnum():\n            special_characters_counter+=1\n    special_characters.append(special_characters_counter)\n        \ndf2['Special characters'] = special_characters","e2c94a77":"digits = []\n\nfor email in df2['Email']:\n    digits_counter = 0\n    for char in email:\n        if char.isdigit():\n            digits_counter+=1\n    digits.append(digits_counter)\n            \n            \ndf2['Digits'] = digits","e937720a":"spam_trigger_words = ['buy','click','get','free','order','save','limited']\n\ntrigger_words = []\n\nfor email in df2['Email']:\n    trigger_words_counter = 0\n    email = email.split()\n    for word in email:\n        if word.lower() in spam_trigger_words:\n            trigger_words_counter+=1\n    trigger_words.append(trigger_words_counter)\n    \ndf2['Trigger words'] = trigger_words","c2684a1f":"df2.head()","21a92a2b":"sns.countplot(x='Spam',data=df2)\nplt.title('Email distribution')\nplt.xticks([0,1],['Not spam','Spam'])\nplt.xlabel('Emails')\nplt.show()","1e7a7f07":"pd.set_option('display.float_format', lambda x: '%.0f' % x)\n\ndf2['Email length'].describe()","e10a24bb":"# Average number of characters\n\nsns.barplot(x='Spam',y='Email length',data=df2)\nplt.title('Average number of characters')\nplt.xticks([0,1],['Not spam','Spam'])\nplt.xlabel('Emails')\nplt.show()","51f51863":"df2['Special characters'].describe()","a997ad60":"# Average number of special characters\n\nsns.barplot(x='Spam',y='Special characters',data=df2)\nplt.title('Average number of special characters')\nplt.xticks([0,1],['Not spam','Spam'])\nplt.xlabel('Emails')\nplt.show()","f911d769":"df2['Digits'].describe()","154333f9":"# Average digit count\n\nsns.barplot(x='Spam',y='Digits',data=df2)\nplt.title('Average digit count')\nplt.xticks([0,1],['Not spam','Spam'])\nplt.xlabel('Emails')\nplt.show()","3fd7a578":"df2['Trigger words'].describe()","ed5b5656":"# Trigger words in emails\n\nsns.barplot(x='Spam',y='Trigger words',data=df2)\nplt.title('Trigger words in email')\nplt.xticks([0,1],['Not spam','Spam'])\nplt.xlabel('Emails')\nplt.show()","55f50464":"# Importing essential libraries for data preprocessing and nlp\nimport re\nimport nltk\nnltk.download()\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer","b8f4de2d":"# i will be dropping emails with length over 2000 and below 15\n\ndf3 = df2[(df2['Email length']<2000) & (df2['Email length']>15)]\ndf3.shape","a851bc8e":"# Data Cleaning\ncorpus = []\nlemmatizer = WordNetLemmatizer()\n\nfor email in df3['Email']:\n    # Remove subject, tabs and new lines\n    removed_tabs_newline = re.sub('[\\n|\\t]',' ',email)\n    removed_subject = re.sub('Subject:',' ',removed_tabs_newline)\n    \n    # Remove special characters and digits\n    removed_spchar_digits = re.sub('[^a-zA-Z]',' ',removed_subject)\n    \n    # Convert emails into lower case\n    lower_case_email = removed_spchar_digits.lower()\n    \n    # Tokenize the emails by words \/ split by words\n    tokenized_email = lower_case_email.split()\n    \n    # Remove stopwords\n    filtered_words = [word for word in tokenized_email if word not in stopwords.words('english')]\n    \n    # Lemmetize words\n    lemmetized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n    \n    # Build corpus of emails\n    email = ' '.join(lemmetized_words)\n    corpus.append(email)","1b55b0c9":"# Creating vectors using TF-IDF\n\ntfidf = TfidfVectorizer(max_features=5000)\nvectors = tfidf.fit_transform(corpus).toarray()\nfeature_names = tfidf.get_feature_names()\n\n# Extracting independent and dependent variables from the dataset\nX = pd.DataFrame(vectors, columns=feature_names)\ny = df3['Spam']","b19aa3bf":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.naive_bayes import MultinomialNB","b410ef1d":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)","0c118efa":"classifier = MultinomialNB()\nclassifier.fit(X_train,y_train)\nprint('Model score on test data:',classifier.score(X_test,y_test))","e8d488eb":"cross_val_score(classifier,X_test,y_test)","fc3ee215":"y_predicted = classifier.predict(X_test)","749856d9":"confusion_matrix_result = confusion_matrix(y_test,y_predicted)\nconfusion_matrix_result","64d4b851":"labels = ['Not spam','Spam']\nplt.figure(figsize=(8,6))\nsns.heatmap(confusion_matrix_result,annot=True,cmap='Reds',fmt='.0f',xticklabels=labels,yticklabels=labels)\nplt.xlabel('Predicted values')\nplt.ylabel('Actual values')\nplt.show()","6731b0ab":"classification_report_result = classification_report(y_test,y_predicted)\nprint(classification_report_result)","91f7531d":"### New feature for number of spam trigger words present in email","12b636c4":"We can see that there are emails which are too long specially on not spam emails.","72281a80":"### Sample email","4cf1f061":"### New feature for digit count in email","e9940636":"### Email distribution","5ad7d332":"### Drop unnecessary columns","3bf9eebc":"### Spam trigger words present in spam and not spam emails","871060bc":"### Confusion matrix and Classification Report","1bfd5e23":"### Digit count of spam and not spam emails","65c82757":"# Feature Engineering\n\n* New feature for email length\n* New feature for number of special characters in email\n* New feature for number of digits in email\n* New feature for number of spam trigger words present in email","cdd5c8a4":"### Check for null values","754e7063":"### Concatenate the three datasets","daab49df":"* We can see that the distribution is not imbalanced","133c411e":"We can see that spam trigger words are definitely present in spam emails.","62f1dadc":"# Data Preprocessing\n\n* Remove subject, tabs and new lines\n* Remove special characters and digits\n* Convert emails into lower case\n* Tokenize the emails by words \/ split by words\n* Remove stopwords\n* Lemmetize words\n* Build corpus of emails\n* Remove too short and long emails\n* Create vectors using TF-IDF","fe771869":"### Email length of spam and not spam emails","fb9182ee":"# Data Preparation\n\n* Drop unnecessary columns\n* Concatenate the three datasets\n* Check for null values","90753eb2":"### Special characters in emails","814443ad":"# Load the datasets\n\n* 3 different datasets will be loaded in to dataframes\n* Dataset can be downloaded in https:\/\/www.kaggle.com\/nitishabharathi\/email-spam-dataset","e4fb8485":"### New feature for email length","cf816530":"# Exploratory Data Analysis\n\n* Email distribution\n* Email length of spam and not spam emails\n* Special characters in emails\n* Digit count in spam and not spam emails\n* Spam trigger words present in spam and not spam emails","3931f737":"### New feature for number of special characters in email","609d6dcb":"# Model Building","646e968c":"We can see that there are huge amount of non-alphanumeric characters and digits present in emails."}}