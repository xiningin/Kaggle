{"cell_type":{"c2875642":"code","797cb6e3":"code","2c790f2b":"code","a57b74db":"code","a17b336f":"code","f8650e4e":"code","b44b57a0":"code","d8be4c1a":"code","efeae703":"code","4e9d3156":"code","800b2a1c":"code","f3c06784":"code","c4a6bcd4":"code","80be3edc":"code","4ef023e0":"code","3a227628":"code","4522c8e0":"code","74fe32e3":"code","2fd02f61":"code","49197e85":"code","a46986e1":"code","e3b28825":"code","3a0af5e7":"code","b821c820":"code","12a34cc4":"code","a772edef":"code","336776d3":"code","c6e6d7e6":"code","57b0a7c6":"code","63abaa42":"code","dbf96c9a":"code","07e6c1a7":"code","f7705879":"code","3121748f":"markdown"},"source":{"c2875642":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","797cb6e3":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","2c790f2b":"df = pd.read_csv('\/kaggle\/input\/brasilian-houses-to-rent\/houses_to_rent_v2.csv')\ndf.head(15)","a57b74db":"print(f\"row:{df.shape[0]}, column:{df.shape[1]}\")                # Total Rows and columns","a17b336f":"df['city'].value_counts()","f8650e4e":"null_data = df.loc[df['floor']=='-']                      # elemenate not available datas.\ndf1=df.drop(null_data.index,axis=0)","b44b57a0":"df1","d8be4c1a":"df1['price_per_area'] = df1['total (R$)']\/df1['area']             # creating one extra column for removing the misleading datas.\ndf1.head(10) ","efeae703":"df1['price_per_area'].describe()","4e9d3156":"mean = df1['price_per_area'].mean()\nstd = df1['price_per_area'].std()\nlow_price_per_area = df1.loc[df1['price_per_area']>mean+std]\nhigh_price_per_area = df1.loc[df1['price_per_area']<mean-std]\nprint(len(low_price_per_area),len(high_price_per_area))\ndf1.shape[0]","800b2a1c":"df2 = df1.drop(low_price_per_area.index,axis=0)\ndf2 = df2.drop(high_price_per_area.index,axis=0)\ndf2.shape[0]","f3c06784":"df2.head()","c4a6bcd4":"df3 = df2.drop((df2.iloc[:,8:12]),axis=1)\ndf3","80be3edc":"plt.scatter(df3['area'],df3['total (R$)'],c='r')               # Detecting the extreem points by visualization.\nplt.show()","4ef023e0":"df3=df3[df3['area']<500]                                       # Removeing the extreem datapoints.\ndf3.shape","3a227628":"plt.scatter(df3['area'],df3['total (R$)'],c='r')                 # visualization \nplt.show()","4522c8e0":"df3.price_per_area.describe()","74fe32e3":"lower_bound=df3.price_per_area.quantile(0.80)                    # Set the upper bound and lower bound or range of our dataset.\nupper_bound = df3.price_per_area.quantile(0.20)","2fd02f61":"df4 = df3[df3.price_per_area<lower_bound]\ndf4","49197e85":"df4 = df4[df4.price_per_area>upper_bound]\ndf4","a46986e1":"plt.scatter(df4['area'],df4['total (R$)'],c='r')               # Visualization after elemenate the outlier datas \nplt.show()","e3b28825":"dummies = pd.get_dummies(df4.city)                  # Creating the dummy variables for city column\ndummies","3a0af5e7":"df5 = pd.concat([df4,dummies],axis=1)                   # concat with original dataset\ndf5","b821c820":"df5 = df5.drop(['city','S\u00e3o Paulo'],axis=1)           # Drop the city column and S\u00e3o Paulo column for avoiding Dummy variable trap\ndf5","12a34cc4":"df5.isnull().sum()                     # check for any NAN value","a772edef":"x = df5[['area','rooms','bathroom','parking spaces','floor','Belo Horizonte','Campinas','Porto Alegre', 'Rio de Janeiro']]\nx                                                # Independent variable column","336776d3":"y = df5['total (R$)']                    # Dependent variable column\ny","c6e6d7e6":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)","57b0a7c6":"from sklearn.linear_model import LinearRegression\nreg = LinearRegression()\nreg.fit(x_train,y_train)                        # Model Training using training dataset","63abaa42":"print(len(x_train),len(y_train),len(x_test),len(y_test))","dbf96c9a":"reg.score(x_test,y_test)                          # Accuracy of the Model","07e6c1a7":"def locate_index(place):                           # this function return the index value of city.\n  for i in range(len(x.columns)):\n    if x.columns[i] == place:\n      return(i)","f7705879":"u_area = input('Enter the area:')\nu_sqft = int(input(\"Enter the no of sqft: \"))\nu_rooms = int(input(\"Enter the no of rooms: \"))\nu_bathroom = int(input(\"Enter the no of bathrooms: \"))\nu_floor = int(input(\"Enter the no of floor: \"))\nu_pspace = int(input(\"Enter the no of parking space: \"))\ndef price_predict(u_area,u_sqft,u_rooms,u_bathroom,u_floor,u_psapce):\n  pred_list = np.zeros(len(x.columns))\n  pred_list[0] = u_sqft\n  pred_list[1] = u_rooms\n  pred_list[2] = u_bathroom\n  pred_list[3] = u_pspace\n  pred_list[4] = u_floor\n  if u_area != 'S\u00e3o Paulo':\n    pred_list[locate_index(u_area)] == 1.0\n  print(f\"The Estimated price is: {reg.predict([pred_list])}\")\nprice_predict(u_area,u_sqft,u_rooms,u_bathroom,u_floor,u_pspace)","3121748f":"**The User Friendly Interface for predicting the price value:**"}}