{"cell_type":{"0bd70b00":"code","d722fa22":"code","d7ab332d":"code","52a64e31":"code","de904391":"code","be189807":"code","dbf5b548":"code","eb2b3f6c":"code","f09ecca7":"code","141d5941":"code","3de6ab97":"code","bcc2ae40":"code","078bf813":"code","ac336b52":"code","3ad6c209":"code","8d867c5b":"code","f091cf25":"code","2306df5f":"code","0d99719a":"code","090aa069":"code","cc811f69":"code","2bb9df64":"markdown","d02ba53b":"markdown","c6eecb06":"markdown","63e260da":"markdown","fda0f675":"markdown","76f04fad":"markdown","98dce559":"markdown","4837c162":"markdown","1fff3d0f":"markdown"},"source":{"0bd70b00":"from IPython.display import HTML\nHTML(\"\"\"\n<style>\nh1,h2,h3 {\n\tmargin: 1em 0 0.5em 0;\n\tfont-weight: 600;\n\tfont-family: 'Titillium Web', sans-serif;\n\tposition: relative;  \n\tfont-size: 36px;\n\tline-height: 40px;\n\tpadding: 15px 15px 15px 2.5%;\n\tcolor: #13003A;\n\tbox-shadow: \n\t\tinset 0 0 0 1px rgba(53,86,129, 0.4), \n\t\tinset 0 0 5px rgba(53,86,129, 0.5),\n\t\tinset -285px 0 35px white;\n\tborder-radius: 0 10px 0 15px;\n\tbackground: #fff\n    \n}\n<\/style>\n\"\"\")","d722fa22":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d7ab332d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nimport category_encoders as ce\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import model_selection\nimport lightgbm as lgbm\nimport xgboost as xgb\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import StackingClassifier, VotingClassifier\nimport optuna\nimport tqdm\nimport warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n","52a64e31":"train = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv')","de904391":"train.head()","be189807":"test.head()","dbf5b548":"train.info()","eb2b3f6c":"test.info()","f09ecca7":"fig, ax = plt.subplots(figsize=(12, 6))\nsns.countplot(x='target', data=train)\nax.set_title('Target Distribution')\n","141d5941":"train.drop(columns=['id']).describe().T.style.bar(subset=['mean'], color='#606ff2')\\\n                            .background_gradient(subset=['std'], cmap='PuBu')\\\n                            .background_gradient(subset=['50%'], cmap='PuBu')","3de6ab97":"test.drop(columns=['id']).describe().T.style.bar(subset=['mean'], color='#606ff2')\\\n                            .background_gradient(subset=['std'], cmap='PuBu')\\\n                            .background_gradient(subset=['50%'], cmap='PuBu')","bcc2ae40":"le = LabelEncoder()\ntrain['target'] = le.fit_transform(train['target'])\ntrain.columns\ncols = list(train.columns)\ncols.remove(\"target\")\ncols.remove(\"id\")","078bf813":"not_features = ['id', 'target']\nfeatures = []\nfor feat in train.columns:\n    if feat not in not_features:\n        features.append(feat)\nprint(features)","ac336b52":"scaler = StandardScaler()\ntrain[features] = scaler.fit_transform(train[features])\ntest[features] = scaler.transform(test[features])","3ad6c209":"X=train.drop(['target','id'],axis=1)\nY=train['target']","8d867c5b":"def objective(trial,data=X,target=Y):\n    \n    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3,random_state=42)\n    params = {\n        \"objective\": \"multiclass\",\n        \"num_class\":4,\n        \"metric\": \"multi_logloss\",\n        \"verbosity\": -1,\n        \"boosting_type\": \"gbdt\",\n        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n    }\n    model = lgbm.LGBMClassifier(**params,device = 'gpu',random_state=42)\n    model.fit(X_train,y_train,eval_set=[(X_test,y_test)],verbose = False)\n        \n    y_preds = model.predict_proba(X_test)\n\n\n    log_loss_multi = log_loss(y_test, y_preds)\n    \n    return log_loss_multi","f091cf25":"OPTUNA_OPTIMIZATION = True\n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=25)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial: score {}, params {}'.format(study.best_trial.value, study.best_trial.params))\n","2306df5f":"if OPTUNA_OPTIMIZATION:\n    display(optuna.visualization.plot_optimization_history(study))\n    display(optuna.visualization.plot_slice(study))\n    display(optuna.visualization.plot_parallel_coordinate(study))","0d99719a":"lgbm_params = study.best_trial.params\nlgbm_params['objective'] = 'multiclass'\nlgbm_params['random_state'] = 42\nlgbm_params['metric'] = 'multi_logloss'\ntest_preds2=None\n\nkf = StratifiedKFold(n_splits = 10 , shuffle = True , random_state = 42)\nfor fold, (tr_index , val_index) in enumerate(kf.split(X.values , Y.values)):\n    \n    print(\"-\" * 50)\n    print(f\"Fold {fold + 1}\")\n    \n    x_train,x_val = X.values[tr_index] , X.values[val_index]\n    y_train,y_val = Y.values[tr_index] , Y.values[val_index]\n        \n    eval_set = [(x_val, y_val)]\n    \n    model2 = lgbm.LGBMClassifier(**lgbm_params,device = 'gpu')\n    model2.fit(x_train, y_train, eval_set = eval_set,verbose=False)\n    \n    train_preds = model2.predict(x_train)    \n    val_preds = model2.predict_proba(x_val)\n    \n    print(log_loss(y_val, val_preds))\n    \n    if test_preds2 is None:\n        test_preds2 = model2.predict_proba(test[cols].values)\n    else:\n        test_preds2 += model2.predict_proba(test[cols].values)\n\nprint(\"-\" * 50)\ntest_preds2 \/= 10","090aa069":"submission = pd.read_csv(\"..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv\")\nsubmission['Class_1']=test_preds2[:,0]\nsubmission['Class_2']=test_preds2[:,1]\nsubmission['Class_3']=test_preds2[:,2]\nsubmission['Class_4']=test_preds2[:,3]\nsubmission['Class_5']=test_preds2[:,4]\nsubmission['Class_6']=test_preds2[:,5]\nsubmission['Class_7']=test_preds2[:,6]\nsubmission['Class_8']=test_preds2[:,7]\nsubmission['Class_9']=test_preds2[:,8]\nsubmission.head()","cc811f69":"submission.to_csv(\"submission.csv\",index=False)","2bb9df64":"<h1 style=\"background-color:#FF9966;font-size:20px;color:#00033E;font-weight : bold\">\ud83d\udd0d Basic Data Exploration:<\/h1>","d02ba53b":"<h1 style=\"background-color:#FF9966;font-size:20px;color:#00033E;font-weight : bold\">\u2692 Data Transformation: <\/h1>","c6eecb06":"<h1 style=\"background-color:#FF9966;font-size:20px;color:#00033E;font-weight : bold\">\ud83c\udf00 Optuna Objective:<\/h1>","63e260da":"<h1 style=\"background-color:#FF9966;font-size:20px;color:#00033E;font-weight : bold\">LightGBM Model:<\/h1>","fda0f675":"<h1 style=\"background-color:#FF9966;font-size:20px;color:#00033E;font-weight : bold\">\ud83d\udcc1 Submission:<\/h1>","76f04fad":"![Upvote!](https:\/\/img.shields.io\/badge\/Upvote-If%20you%20like%20my%20work-07b3c8?style=for-the-badge&logo=kaggle)","98dce559":"<br>\n<h1 style = \"font-size:30px; font-family:cursive ; font-weight : bold; color : #0331A8; text-align: center; border-radius: 10px 15px;\"> \ud83d\ude80LightGBM with Optuna Starter \ud83d\ude80 <\/h1>\n<br>","4837c162":"<h1 style=\"background-color:#FF9966;font-size:20px;color:#00033E;font-weight : bold\">\u2705 Importing Required Libraries<\/h1>","1fff3d0f":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcRvz3ovorQic-WVLoFLyXkzPu9inOJ2tyzKWw&usqp=CAU)"}}