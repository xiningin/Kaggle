{"cell_type":{"02a13423":"code","babf41ac":"code","efff7118":"code","8fa1a05d":"code","33a312b0":"code","3c48c45c":"code","622bb00f":"code","be35fc42":"code","fd78c6b3":"code","6bd4cb89":"code","bb9f3570":"code","f5dcfd85":"code","3dd03937":"code","8b8787bc":"code","1ef37bae":"code","d9fb1cf5":"code","bcce23e5":"markdown","4a82d22d":"markdown","8bcccfe2":"markdown","ed2a1a67":"markdown","ddad1671":"markdown","62a6a4a5":"markdown","f3e6ebcc":"markdown","e9178fec":"markdown","c645eb89":"markdown","f4d6f9db":"markdown","c1acc7f9":"markdown","34980b02":"markdown","11ef7c79":"markdown","b6236d7c":"markdown","0da77a2a":"markdown","bf8ea8e7":"markdown","8e10d05d":"markdown","369115f2":"markdown","739ec243":"markdown","e457c79e":"markdown"},"source":{"02a13423":"#carregar dataset mnist\nimport numpy as np\nfrom tensorflow.keras.datasets import mnist\n(x_train, y_train), (x_test, y_test) = mnist.load_data()","babf41ac":"num_labels = len(np.unique(y_train))\nprint(\"total de labels:\\t{}\".format(num_labels))\nprint(\"labels:\\t\\t\\t{0}\".format(np.unique(y_train)))","efff7118":"#converter em one-hot\nfrom tensorflow.keras.utils import to_categorical\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)","8fa1a05d":"# Assumindo que nossa imagem \u00e9 quadrada.\nimage_size = x_train.shape[1] \ninput_size = image_size * image_size\n\nprint(\"x_train:\\t{}\".format(x_train.shape))\nprint(\"x_test:\\t\\t{}\\n\".format(x_test.shape))\n\nprint('Redimensionar e normalizar.\\n')\n\nx_train = np.reshape(x_train, [-1, input_size])\nx_train = x_train.astype('float32') \/ 255\nx_test = np.reshape(x_test, [-1, input_size])\nx_test = x_test.astype('float32') \/ 255\n\nprint(\"x_train:\\t{}\".format(x_train.shape))\nprint(\"x_test:\\t\\t{}\".format(x_test.shape))","33a312b0":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout\n\n# Par\u00e2metros\nbatch_size = 128 # \u00c9 o tamanho da amostra de entradas a serem processadas em cada etapa de treinamento. \/\/epocas\nhidden_units = 256\ndropout = 0.45\n\n# Nossa  MLP com ReLU e Dropout \nmodel = Sequential()\n\nmodel.add(Dense(hidden_units, input_dim=input_size))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(dropout))\n\nmodel.add(Dense(hidden_units))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(dropout))\n\nmodel.add(Dense(num_labels))","3c48c45c":"model.add(Activation('softmax'))\n\nmodel.summary()","622bb00f":"from tensorflow.keras.utils import plot_model\nplot_model(model, to_file='mlp.png', show_shapes=True)","be35fc42":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","fd78c6b3":"model.fit(x_train, y_train, epochs=20, batch_size=batch_size)","6bd4cb89":"print(\"MLP:\\nValidar o modelo em nosso dataset de teste:\\n\")\n_, acc = model.evaluate(x_test,\n                        y_test,\n                        batch_size=batch_size,\n                        verbose=0)\nprint(\"\\nAccuracy: %.1f%%\\n\" % (100.0 * acc))","bb9f3570":"print('Carregando novamente nosso dataset\\n')\n(x_train, _), (x_test, _) = mnist.load_data()\n\nimage_size = x_train.shape[1] \n\nprint(\"x_train:\\t{}\".format(x_train.shape))\nprint(\"x_test:\\t\\t{}\\n\".format(x_test.shape))\n\nprint('Redimensionar e normalizar.\\n')\n\nx_train = np.reshape(x_train, [-1, image_size, image_size, 1])\nx_train = x_train.astype('float32') \/ 255\nx_test = np.reshape(x_test, [-1, image_size, image_size, 1])\nx_test = x_test.astype('float32') \/ 255\n\nprint(\"x_train:\\t{}\".format(x_train.shape))\nprint(\"x_test:\\t\\t{}\".format(x_test.shape))\n\ninput_shape = (image_size, image_size, 1)\nprint('\\nProcessadas em escala de cinza.\\n{}'.format(input_shape))\n","f5dcfd85":"batch_size = 128\n\nkernel_size = 3\n\nfilters = 64\n\ndropout = 0.3","3dd03937":"from tensorflow.keras.layers import Conv2D,Input,MaxPooling2D,Flatten\nfrom tensorflow.keras.models import Model\n\n\ninputs = Input(shape=input_shape)\n\ny = Conv2D(filters=filters,\n           kernel_size=kernel_size,\n           activation='relu')(inputs)\n\ny = MaxPooling2D()(y)#padr\u00e3o pool_size=(2, 2)\n\ny = Conv2D(filters=filters,\n           kernel_size=kernel_size,\n           activation='relu')(y)\n\ny = MaxPooling2D()(y)\n\ny = Conv2D(filters=filters,\n           kernel_size=kernel_size,\n           activation='relu')(y)\n\ny = Flatten()(y)\n\ny = Dropout(dropout)(y)\n\noutputs = Dense(num_labels, activation='softmax')(y)\n\nmodel = Model(inputs=inputs, outputs=outputs)\n\nmodel.summary()","8b8787bc":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","1ef37bae":"model.fit(x_train, y_train, epochs=20, batch_size=batch_size)","d9fb1cf5":"print(\"CNN:\\nValidar o modelo em nosso dataset de teste:\\n\")\n_, acc = model.evaluate(x_test,\n                        y_test,\n                        batch_size=batch_size,\n                        verbose=0)\nprint(\"\\nAccuracy: %.1f%%\\n\" % (100.0 * acc))","bcce23e5":"## Activation\nA camada de sa\u00edda possui 10 unidades, seguida por uma fun\u00e7\u00e3o de ativa\u00e7\u00e3o softmax. As 10 unidades correspondem as 10 poss\u00edveis labels, classes ou\u00a0 categorias. \n\nA activation do softmax pode ser expressada matematicamente\u00a0, conforme a seguinte equa\u00e7\u00e3o:\n<img src='https:\/\/cdn-images-1.medium.com\/max\/1000\/1*ui7n5s48-qNF7BBGfDPioQ.png' \/>","4a82d22d":"### Refer\u00eancias\n\n* [Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems](https:\/\/www.amazon.com\/Hands-Machine-Learning-Scikit-Learn-TensorFlow\/dp\/1491962291\/ref=pd_lpo_14_img_0\/258-2310536-8495143?_encoding=UTF8&pd_rd_i=1491962291&pd_rd_r=436780c4-00ab-487f-83cf-ab609d2951c9&pd_rd_w=hWZ1M&pd_rd_wg=Ywt9L&pf_rd_p=7b36d496-f366-4631-94d3-61b87b52511b&pf_rd_r=1P3CVZ4BKPQPD2FDF8V5&psc=1&refRID=1P3CVZ4BKPQPD2FDF8V5) \n* [Machine learning education | TensorFlow](https:\/\/www.tensorflow.org\/resources\/learn-ml)\n* [Deep Learning Brasil (Em portugu\u00eas) - Perceptron e Adaline](https:\/\/www.youtube.com\/watch?v=6yYUc6nU3Cw)\n* [Redes Neurais profundas Convolucionais - Parte I - Fundamentos](https:\/\/www.youtube.com\/watch?v=n4rmrZg1_58)\n* [Redes Neurais profundas Convolucionais - Parte II - Arquiteturas Modernas](https:\/\/www.youtube.com\/watch?v=0XUrLfQXzcw)\n\n","8bcccfe2":"**MaxPoolins2D()** \u00e9 usado para reduzir o tamanho do mapa, o que se traduz em um aumento no tamanho do campo\u00a0 receptivo. Por exemplo, ap\u00f3s o MaxPooling2D(2), o kernel 2x2 agora\u00a0\nest\u00e1 aproximadamente convolu\u00eddo com um patch 4x4. \n\n<img src='https:\/\/miro.medium.com\/max\/1400\/1*WvHC5bKyrHa7Wm3ca-pXtg.gif' style='height:120px' \/>\n\n*A CNN aprende um novo conjunto de mapa.\u00a0*","ed2a1a67":"## Model","ddad1671":"O m\u00e9todo **mnist.load_data()** \u00e9 conveniente, pois n\u00e3o h\u00e1 necessidade de carregar todas as 70.000 imagens e suas labels.\n<hr \/>\nAntes de entrarmos no classificador MLP, \u00e9 essencial ter em mente que, embora os dados do MNIST consistam em tensores bidimensionais, eles devem ser remodelados, dependendo do tipo de camada de entrada.\n<br \/><br \/>\nUma imagem em escala de cinza 3x3 \u00e9 remodelada para as camadas de entradas MLP,CNN e RNN:\n<img src='https:\/\/franckepeixoto.files.wordpress.com\/2020\/07\/inputs-nn.png' style='align:center' \/>","62a6a4a5":"# Dataset MNIST\nSuponha que nosso objetivo seja criar uma rede para identificar n\u00fameros com base em d\u00edgitos manuscritos. Por exemplo, quando a entrada para a rede \u00e9 uma imagem de um n\u00famero **8**, a previs\u00e3o correspondente tamb\u00e9m deve ser **8**.\n<br \/>\n\ud83e\udd37\ud83c\udffb\u200d\u2642\ufe0f *Esse \u00e9 um trabalho b\u00e1sico de\u00a0 classifica\u00e7\u00e3o com redes neurais.*\u00a0\n<hr \/>\nO dataset do <a href='https:\/\/en.wikipedia.org\/wiki\/National_Institute_of_Standards_and_Technology'>National Institute of Standards and Technology<\/a>,\u00a0ou MNIST, \u00e9 considerado como o <strong>Ol\u00e1 Mundo!<\/strong> dos datasets de Deep Learning.\n<br \/>\nAntes de dissecarmos o modelo MLP, \u00e9 essencial entender o dataset MNIST. Ele \u00e9 usado para explicar e validar muitas teorias da deep learning, porque as 70.000 imagens que ele cont\u00eam s\u00e3o pequenas, mas suficientemente ricas em informa\u00e7\u00f5es;\n<img src='https:\/\/franckepeixoto.files.wordpress.com\/2020\/07\/mninst-digits.png?resize=307%2C307'  style='aling:center' \/>","f3e6ebcc":"# Construindo o modelo\n<img src='https:\/\/franckepeixoto.files.wordpress.com\/2020\/07\/mlp-nn.png' style='align:center;height:150px;' \/>\n\n>Nosso modelo \u00e9 composto por tr\u00eas layers MLP em uma camada Densa. A primeira e a segunda, s\u00e3o id\u00eanticas,\u00a0seguidas por uma fun\u00e7\u00e3o de ativa\u00e7\u00e3o\u00a0[Rectified Linear Unit](https:\/\/deepai.org\/machine-learning-glossary-and-terms\/rectified-linear-units) ( ReLU ) e [Dropout](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/Dropout).\n<img src='https:\/\/miro.medium.com\/max\/357\/1*oePAhrm74RNnNEolprmTaQ.png' style='height:150px;' \/>\n","e9178fec":"># CNN - Convolutional Neural Network\n\nAgora vamos dar uma olhada na segunda rede neural artificial, a CNN.\n\nFaremos algumas mudan\u00e7as no modelo anterior para implementar nossa CNN. Em vez de um vetor de entrada, usaremos a seguinte dimens\u00e3o\u00a0(altura, largura, canais)\u00a0 = **(28,28,1)**\u00a0 para nossas imagens MNIST em escala de cinza.\u00a0\n\n<img src='https:\/\/miro.medium.com\/max\/3744\/1*SGPGG7oeSvVlV5sOSQ2iZw.png' \/>","c645eb89":"## Regularization\nUma rede neural tem a tend\u00eancia de memoriza seus dados de treinamento, especialmente se contiver capacidade mais que suficiente. Nesse caso, a rede falha catastroficamente quando submetida aos dados de teste. \n\nEste \u00e9 o caso cl\u00e1ssico\u00a0de que a rede falha em generalizar (Overfitting \/ Underfitting). Para evitar essa tend\u00eancia o modelousa\u00a0uma camada regulat\u00f3ria. O **Dropout**.\u00a0\n\n<img src='https:\/\/miro.medium.com\/max\/1200\/1*iWQzxhVlvadk6VAJjsgXgg.png' style='height:200px;padding-bottom:10px[](http:\/\/)'\/>\n\n\nA ideia do Dropout \u00e9 simples. Dada uma taxa de descarte\u00a0( em nosso modelo, definimos = 0,45) a camada remove aleatoriamente essa fra\u00e7\u00e3o de unidades.\u00a0\n> Por exemplo, se a primeira camada tiver 256 unidades, depois que o **Dropout(0,45)** for aplicado, apenas **(1 - 0,45) * 255**\u00a0 = 140 unidades participar\u00e3o da pr\u00f3xima camada.\n\n\u00a0O Dropout torna as redes neurais mais\u00a0 robustas para dados de entrada imprevistos, porque a rede \u00e9 treinada para prever corretamente, mesmo que algumas unidades estejam ausentes.\u00a0\n \n \u26a0\ufe0f O Dropout s\u00f3 participa da \"brincadeira\" \ud83e\udd37\ud83c\udffb\u200d\u2642\ufe0f durante o **treinamento**.","f4d6f9db":"O MNIST \u00e9 uma cole\u00e7\u00e3o de d\u00edgitos\u00a0que variam de 0 a 9. Ele possui um conjunto de treinamento\u00a0de **60.000** imagens e **10.000** testes classificados em categorias.\u00a0\n<br \/><br \/>\n**Para usarmos o dataset MNIST no\u00a0 tensorflow \u00e9 simples.**","c1acc7f9":"# Conclus\u00e3o\n\n* MLP: 98%. \/ *params: 269,322*\n* CNN: 99%. \/ **params: 80,266**\n\n* RNN: ?\n\n\n> *Saber muito n\u00e3o lhe torna inteligente. A intelig\u00eancia se traduz na forma que voc\u00ea recolhe, julga, maneja e, sobretudo, onde e como aplica esta informa\u00e7\u00e3o.* **(Carl Sagan)**","34980b02":">\u26a0\ufe0f Essa representa\u00e7\u00e3o\u00a0n\u00e3o \u00e9 adequada para a camada de previs\u00e3o que gera probabilidade por classe.\n\nO formato mais indicado \u00e9 o\u00a0[one-hot](https:\/\/towardsdatascience.com\/building-a-one-hot-encoding-layer-with-tensorflow-f907d686bf39), um vetor 10-dimensional como todos os valores 0, exceto o \u00edndice\u00a0da classe. \n\nPor exemplo, se a label for 4, o vetor equivalente \u00e9 [0,0,0,0, **1** ,0,0,0,0,0].\n\nEm Deep Learning, os dados s\u00e3o armazenados em tensor. O termo tensor se aplica a um tensor escalar (tensor 0D), vetor (tensor 1D), matriz (tensor bidimensional) e tensor multidimensional.\u00a0","11ef7c79":"O mapa de caracter\u00edsticas\u00a0\u00e9 ent\u00e3o transformado\u00a0 em outro mapa. O n\u00famero de mapas de recursos gerado por Conv2D \u00e9 controlado pelo argumento filters.\n\nO kernel n\u00e3o pode ir al\u00e9m das bordas da imagem, por isso que as dimens\u00f5es de nosso input devem se iguais\u00a0 aos mapas de sa\u00edda. dito isso, usaremos em nosso [Conv2D](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/layers\/Conv2D)\u00a0a op\u00e7\u00e3o padding='same'.\u00a0\u00a0\n\n*\/\/Nosso input \u00e9 preenchido com zero em torno de sua borda para manter as dimens\u00f5es ap\u00f3s a convolu\u00e7\u00e3o.*","b6236d7c":"># MLP - Multilayer Perceptron\n\ud83d\udccc Uma rede MLP, \u00e9 uma rede totalmente conectada,*([fully connected network](https:\/\/towardsdatascience.com\/derivation-of-convolutional-neural-network-from-fully-connected-network-step-by-step-b42ebafa5275) | [feedforward network](https:\/\/en.wikipedia.org\/wiki\/Feedforward_neural_network))*.\n<hr \/>\n\nO entendimento dessa rede, nos ajuda a obter informa\u00e7\u00f5es sobre os motivos adjacentes nos modelos avan\u00e7ados de Deep Learning.\u00a0As MLPs s\u00e3o usadas comumente em problemas de regress\u00e3o simples. No entanto, as MLPs n\u00e3o s\u00e3o ideais para o processamento de padr\u00f5es com dados sequenciais e multidimensionais.\n<p>\n\ud83d\ude44 <i>Uma MLP se esfor\u00e7a para lembrar de padr\u00f5es em dados sequenciais, por conta disso, requer um n\u00famero \"grande\" de par\u00e2metros para processar dados multidimensionais.<\/i>\n<\/p>\n<hr \/>\nPara dados sequenciais, as <a target='blank' href='https:\/\/en.wikipedia.org\/wiki\/Recurrent_neural_network'>RNNs<\/a> s\u00e3o as queridinhas porque seus padr\u00f5es permitem que a rede descubra depend\u00eancia no \ud83e\udde0 hist\u00f3rico dos dados, o que \u00e9 bem \u00fatil para previs\u00f5es. Para dados, como imagens e v\u00eddeos, as <a target='blank' href='https:\/\/en.wikipedia.org\/wiki\/Convolutional_neural_network'>CNNs<\/a> se destacam na extra\u00e7\u00e3o de mapas de recursos para classifica\u00e7\u00e3o, segmenta\u00e7\u00e3o, dentre outras tarefas.\n<br \/>\nEm alguns casos, uma CNN na forma de <a target='blank' href='https:\/\/missinglink.ai\/guides\/keras\/keras-conv1d-working-1d-convolutional-neural-networks-keras\/'>Conv1D<\/a>\/1D tamb\u00e9m \u00e9 usada para redes com dados de entrada sequenciais. No entanto, na maioria\u00a0 dos modelos de <a target='blank' href='https:\/\/en.wikipedia.org\/wiki\/Deep_learning'>Deep Learning<\/a>,\u00a0 MLP, CNN ou RNN s\u00e3o combinadas para aproveitar o m\u00e1ximo de cada.\n<br \/>\n<br \/>\n<strong>MLP,CNN e RNN n\u00e3o fazem tudo...<\/strong>\n<br \/>\nMuito de seu sucesso vem de identificar seu objetivo e a boa escolha de alguns par\u00e2metros, tais como: \n<br \/>\n\n<a href='https:\/\/en.wikipedia.org\/wiki\/Loss_function'>Loss function<\/a>, <a href='https:\/\/ml-cheatsheet.readthedocs.io\/en\/latest\/optimizers.html'>Optimizer<\/a> e <a href='https:\/\/en.wikipedia.org\/wiki\/Regularization_(mathematics)'>Regularizer<\/a>\n<br \/>\nTamb\u00e9m, temos os dados de fora do ambiente de treinamento. O papel do Regularizer \u00e9 garantir que o modelo treinado generalize para novos dados.\u00a0\n\n<img src='https:\/\/miro.medium.com\/proxy\/1*eloYEyFrblGHVZhU345PJw.jpeg' style='aling:center' \/>","0da77a2a":"## Evaluation\nNesse ponto, nosso modelo classificador de d\u00edgitos\u00a0MNIST est\u00e1 completo. Sua avalia\u00e7\u00e3o de desempenho ser\u00e1 o pr\u00f3ximo passo para determinar se o modelo treinado apresentar\u00e1 uma solu\u00e7\u00e3o sub-\u00f3tima.\u00a0","bf8ea8e7":"> As labels est\u00e3o no formato de d\u00edgitos, de 0 a 9.","8e10d05d":"> Nosso modelo \u00e9 uma MLP, portanto, seus inputs devem ser um tensor 1D. como tal,\u00a0 x_train e x_test devem ser transformados em [60.000, 28*28] e [10.000, 28*28], \n\nNo numpy, o size de -1 significa permitir que a library calcule a dimens\u00e3o correta, No caso x_train, \u00e9 60.000.","369115f2":"## Convolution\n\nSe em MLP, o n\u00famero de unidades caracteriza as camadas densas, o kernels caracteriza as opera\u00e7\u00f5es da CNN.\u00a0\n\nO Kernels pode ser visualizado como uma \"janela\" retangular que desliza por toda a imagem da esquerda para a direita e de cima para baixo.\n\nEsse movimento \u00e9 chamado de Convolu\u00e7\u00e3o. Ele transforma a imagem de entrada em um mapa de recursos, que \u00e9 uma representa\u00e7\u00e3o do que o kernel aprendeu com a imagem de entrada.\n\n<img src='https:\/\/franckepeixoto.files.wordpress.com\/2020\/07\/convolution.png' style='height:120px'\/>\n","739ec243":"* **Categorical_crossentropy**, \u00e9 usada para one-hot\n* **Accuracy** \u00e9 uma boa m\u00e9trica para tarefas de classifica\u00e7\u00e3o.\n* **Adam** \u00e9 um algoritmo de otimiza\u00e7\u00e3o que pode ser usado em vez do procedimento cl\u00e1ssico de descida de gradiente estoc\u00e1stico\n\n\n>\ud83d\udccc Dado nosso conjunto de treinamento, a escolha da loss function, o optimizer e o regularizer, podemos iniciar o treinamento de nosso modelo.","e457c79e":"## Optimization\n\nO objetivo do Optimization \u00e9 minimizar a fun\u00e7\u00e3o de perda. A id\u00e9ia \u00e9 que, se a perda for reduzida para um n\u00edvel aceit\u00e1vel, o modelo indiretamente aprendeu a fun\u00e7\u00e3o que mapeia os inputs para os outputs. \n\nM\u00e9tricas de desempenho s\u00e3o usadas para determinar se seu modelo aprendeu."}}