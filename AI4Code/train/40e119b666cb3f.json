{"cell_type":{"2b65d87d":"code","12fb0a89":"code","6b465e71":"code","42f9ab32":"code","6865e595":"code","047fa0b3":"code","e77ddf3f":"code","a8774086":"code","663e06c3":"markdown","6bd53555":"markdown","fe4293d7":"markdown","649dcae8":"markdown","af9598af":"markdown","e6a98fe8":"markdown","590932d4":"markdown","1bb40b87":"markdown","37bbd7e5":"markdown","52fbecb1":"markdown","c32d8190":"markdown","2fceada2":"markdown","b3aa3553":"markdown","587590fc":"markdown","122a0c64":"markdown","6ac7b0ad":"markdown","46ac92f4":"markdown","2498ca14":"markdown","809e214b":"markdown","b1ae7bf9":"markdown"},"source":{"2b65d87d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","12fb0a89":"!pip install numpy opencv-python dlib imutils\n","6b465e71":"!wget -nd https:\/\/github.com\/JeffTrain\/selfie\/raw\/master\/shape_predictor_68_face_landmarks.dat","42f9ab32":"import numpy as np\ndef curve(points):\n\tx = points[:,0]\n\ty = points[:,1]\n\n\tz = np.polyfit(x, y, 2)\n\tf = np.poly1d(z)\n\n\tx_n = np.linspace(x[0], x[-1], 100)\n\ty_n = f(x_n)\n\treturn list(zip(x_n, y_n))","6865e595":"#from curve_fitting import curve\nfrom imutils import face_utils\nimport numpy as np\nimport dlib\nimport cv2\n\n\npath='\/kaggle\/working\/'\nimg_path='\/kaggle\/input\/image-utils\/faces_featureimg.jpg'\ndetector = dlib.get_frontal_face_detector()\npredictor = dlib.shape_predictor(\"\/kaggle\/working\/shape_predictor_68_face_landmarks.dat\")\n\n\n\n","047fa0b3":"img = cv2.imread(img_path)\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nfaces = detector(gray)\n\n","e77ddf3f":"\nfor (j,face) in enumerate(faces):\n        points = predictor(gray, face)\n\n        print('\\nface #',j+1)\n        l=[]\n        print('\\nface boundary coordinate\\n')\n        for i in range(0, 27):  # loop for displaying face boundary coordinate\n            curr_c = (points.part(i).x, points.part(i).y)\n            print(curr_c)\n        print('\\nnose coordinate\\n')\n        for i in range(27, 36):  # loop for displaying nose  coordinate\n            curr_c = (points.part(i).x, points.part(i).y)\n            print(curr_c)\n        print('\\nleft eye coordinate\\n')\n        for i in range(36, 42):  # loop for displaying left eye coordinate\n            curr_c = (points.part(i).x, points.part(i).y)\n            print(curr_c)\n        print('\\nright eye coordinate\\n')\n        for i in range(42, 48):  # loop for displaying right eye coordinate\n            curr_c = (points.part(i).x, points.part(i).y)\n            print(curr_c)\n        print('\\nlips coordiante\\n')\n        for i in range(48, 68):  # loop for displaying lips coordinate\n            curr_c = (points.part(i).x, points.part(i).y)\n            print(curr_c)\n\n        for i in range(5, 12):                          #loop for storing jaw coordinates\n            curr_c=(points.part(i).x, points.part(i).y)\n            l.append(curr_c)\n\n        cur=np.array(curve(np.array(l)), np.int32)      # calling function to trace proper fitting curve\n\n\n        for i in range(len(cur)-1):                          #loop for tracing jaw line\n            curr_c=(cur[i][0], cur[i][1])\n            next_cordi=(cur[i+1][0], cur[i+1][1])\n            cv2.line(img, curr_c, next_cordi, (0, 0, 0), 3)\n        for n in range(0, 68):                          #loop for detecting feature points on face\n        \tx = points.part(n).x\n        \ty = points.part(n).y\n        \tcv2.circle(img, (x, y), 3, (0, 0, 255), 2)\n\n        #points = face_utils.shape_to_np(points)\n\n        # to  convert dlib's rectangle to a OpenCV-style bounding box\n        # [i.e., (x, y, w, h)], then draw the face bounding box\n        (x, y, w, h) = face_utils.rect_to_bb(face)\n        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n\n        # to display the face number\n        cv2.putText(img, \"Face #{}\".format(j + 1), (x - 10, y - 10),\n                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n\n#cv2.imwrite(path, img) \n","a8774086":"\ncv2.imwrite(path+\"\/faces_featureimg.jpg\", img) #writes image with landmark points","663e06c3":"# Function to trace the jaw line path\nUsing polyfit and linespace functions of numpy library, we write a function to trace the jaw line of the face once the face is detected.","6bd53555":"# Printing location of all the facial features present","fe4293d7":"# Here goes the glimpse of the output image","649dcae8":"These annotations are part of the 68 point iBUG 300-W dataset which the dlib facial landmark predictor was trained on.\n\nIt\u2019s important to note that other flavors of facial landmark detectors exist, including the 194 point model that can be trained on the HELEN dataset.","af9598af":"# Dlib\u2019s facial landmark detector\nFacial landmarks are used to localize and represent salient regions of the face, such as:\nEyes\nEyebrows\nNose\nMouth\nJawline\n\nThe pre-trained facial landmark detector inside the dlib library is used to estimate the location of 68 (x, y)-coordinates that map to facial structures on the face.\n\nThe indexes of the 68 coordinates can be visualized on the image below:","e6a98fe8":"# Loading the model for detection","590932d4":"![image_output](https:\/\/raw.githubusercontent.com\/vishakhagupta10\/feature_detection\/master\/output_img.jpg)","1bb40b87":"**Step 1 is acheived by using dlib's frontal face detector**\n\n**Step 2 is acheived using facial landmark detector added in dlib.**\n","37bbd7e5":"# Installation of Packages\nWe install all necessary packages, like here we need numpy, opencv, dlib imutils","52fbecb1":"# Writing the data image back to the file","c32d8190":"# Conversion to gray scale\nConverting the image into gray scale, because dlib library can be applied on gray scale image","2fceada2":"# Key Objective\nThe objective is to detect faces(multiple faces allowed) in the image with the help of the OpenCV bounding box and display the face count near the box. We display the facial landmark coordinates and mark the facial landmark points, such as eyes, nose, mouth, ears, jaw-line with dots and trace the dots of jawline curve using the popular Dlib library","b3aa3553":"# Face Detection and Features Recognition using DLib\n**Dlib is a modern C++ toolkit containing machine learning algorithms and tools for creating complex software in C++ to solve real-world problems. This library works only on the gray-scale image.**\n\nWe are using the model already trained, we will need to download the file shape_predictor_68_face_landmarks.dat. Link for the same is given below\n","587590fc":"# To load pre trained facial landmark model ","122a0c64":"# Here goes the code!","6ac7b0ad":"Image depicts clearly number of face present in the images and their facial features including the trace of jaw lines","46ac92f4":"# Here goes the input image whose features are need to be detected","2498ca14":"![landmark](https:\/\/raw.githubusercontent.com\/vishakhagupta10\/feature_detection\/master\/facelandmark68.png)","809e214b":"Detecting facial landmarks is a subset of the shape prediction problem. Given an input image (and normally an ROI that specifies the object of interest), a shape predictor attempts to localize key points of interest along the shape.\n\n**Detecting facial landmarks is therefore a two step process:**\n\n**Step #1: Localize the face in the image.**\n\n**Step #2: Detect the key facial structures on the face ROI.**","b1ae7bf9":"![](https:\/\/raw.githubusercontent.com\/vishakhagupta10\/feature_detection\/master\/faces_featureimg.jpg)"}}