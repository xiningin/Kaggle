{"cell_type":{"fbb44d58":"code","7aa5dfb0":"code","c3d45135":"code","dd4d0a7e":"code","a6440d17":"code","6e601046":"code","d640fa45":"code","25d491dc":"code","1c79ee6a":"code","a544367f":"code","c6a21173":"code","870887ea":"code","b0393628":"code","81741186":"code","853b99da":"code","c91785b0":"code","3962f2a1":"code","57eeec43":"code","54cbb5f0":"code","d2a1af29":"code","05862e56":"code","9a99d8ed":"code","245a28e8":"code","6c27e90f":"code","d03b054d":"code","1aec9dbb":"code","0fd94582":"markdown","ea1bdaa5":"markdown","7bf56f1d":"markdown","05d4ae73":"markdown","7486d666":"markdown","f5600fdc":"markdown","29549fad":"markdown","1eb2fac8":"markdown","c12c22b4":"markdown","7e5c73e4":"markdown","5660873e":"markdown","1c07cf4f":"markdown","d9c43484":"markdown","069d4788":"markdown","fa1e0abc":"markdown","621a82bd":"markdown","4a8916ef":"markdown","38c1cea2":"markdown","fad63c23":"markdown","c0528838":"markdown","17046793":"markdown","2150444b":"markdown"},"source":{"fbb44d58":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport pandas_profiling as pp # exploratory data analysis EDA\nimport matplotlib.pyplot as plt # data visualisation\nimport seaborn as sns #data visualisation\nimport plotly.express as px #data visualisation\nimport plotly.graph_objects as go\nfrom scipy.stats import chi2_contingency, norm # Calculo de chi2\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7aa5dfb0":"df = pd.read_csv(\"..\/input\/dataco-smart-supply-chain-for-big-data-analysis\/DataCoSupplyChainDataset.csv\", engine='python')","c3d45135":"df.head()","dd4d0a7e":"profile = pp.ProfileReport(df, title = \"EDA\")","a6440d17":"# profile.to_notebook_iframe() # Genera el reporte directamente en el notebook.","6e601046":"profile.to_file(output_file=\"reporte.html\") ","d640fa45":"# shape and data types of the data\nprint(df.shape)\nprint(df.dtypes)\n \n    # se puede revisar la clasificaci\u00f3n de pandas profiling contra el tipo de dato ","25d491dc":"data=df.drop(['Order Zipcode','Product Description', 'Customer Email','Customer Password','Product Status','Customer Street','Customer Fname','Customer Lname',\n           'Latitude','Longitude','Product Image',],axis=1)\ndata.shape","1c79ee6a":"column_index=data.columns.get_loc(\"Customer Zipcode\")\n# Get the index of the column \"Customer Zipcode\"\ndata['Customer Zipcode']=data['Customer Zipcode'].fillna(data.mode().iloc[column_index])\n#Filling NaN columns with most common value","a544367f":"fig, ax = plt.subplots(figsize=(24,12))         # figsize\nsns.heatmap(data.corr(),annot=True,linewidths=.5,fmt='.1g',cmap= sns.diverging_palette(230, 20, as_cmap=True)) # Heatmap for correlation matrix\n","c6a21173":"count=data['Delivery Status'].value_counts()  #change categoric variable\nprint(count \/ len(data))","870887ea":"#Filtering columns with late delivery status\nlate_delivery = data[(data['Delivery Status'] == 'Late delivery')]\n#Top 10 products with most late deliveries\nfig = px.bar(late_delivery['Category Name'].value_counts().nlargest(10), \n             title=\"Top 10 products with most late deliveries\",\n            labels={'value':'Number of late deliveries','index':'Category'})\nfig.show()","b0393628":"#Calculating proproptional late deliveries\nlate_count=late_delivery['Category Name'].value_counts()\ntotal_count=data['Category Name'].value_counts()\nproportional_count=late_count\/total_count*100\nfig = px.bar(proportional_count.nlargest(15), \n             title=\"Top 10 products with highest rate of late delivery\",\n            labels={'value':'Percentage of late deliveries','index':'Category'})\nfig.show()\n","81741186":"#Filtering late delivery orders with standard class shipping\nxyz1 = data[(data['Delivery Status'] == 'Late delivery') & (data['Shipping Mode'] == 'Standard Class')]\n#Filtering late delivery orders with first class shipping\nxyz2 = data[(data['Delivery Status'] == 'Late delivery') & (data['Shipping Mode'] == 'First Class')]\n#Filtering late delivery orders with second class shipping\nxyz3 = data[(data['Delivery Status'] == 'Late delivery') & (data['Shipping Mode'] == 'Second Class')]\n#Filtering late delivery orders with same day shipping\nxyz4 = data[(data['Delivery Status'] == 'Late delivery') & (data['Shipping Mode'] == 'Same Day')]\n#Counting total values\ncount1=xyz1['Order Region'].value_counts()\ncount2=xyz2['Order Region'].value_counts()\ncount3=xyz3['Order Region'].value_counts()\ncount4=xyz4['Order Region'].value_counts()\n#Index names\nnames=data['Order Region'].value_counts().keys()\nn_groups=23\nfig,ax = plt.subplots(figsize=(20,8))\nindex=np.arange(n_groups)\nbar_width=0.2\nopacity=0.6\ntype1=plt.bar(index,count1,bar_width,alpha=opacity,color='b',label='Standard Class')\ntype2=plt.bar(index+bar_width,count2,bar_width,alpha=opacity,color='r',label='First class')\ntype3=plt.bar(index+bar_width+bar_width,count3,bar_width,alpha=opacity,color='g',label='second class')\ntype4=plt.bar(index+bar_width+bar_width+bar_width,count4,bar_width,alpha=opacity,color='y',label='same day')\nplt.xlabel('Order Regions')\nplt.ylabel('Number of shipments')\nplt.title('Different Types of shipping methods used in all regions')\nplt.legend()\nplt.xticks(index+bar_width,names,rotation=90)\nplt.tight_layout()\nplt.show()","853b99da":"#Filtering late delivery orders with standard class shipping\nxyz1 = data[(data['Delivery Status'] == 'Late delivery') & (data['Shipping Mode'] == 'Standard Class')]\n#Filtering late delivery orders with first class shipping\nxyz2 = data[(data['Delivery Status'] == 'Late delivery') & (data['Shipping Mode'] == 'First Class')]\n#Filtering late delivery orders with second class shipping\nxyz3 = data[(data['Delivery Status'] == 'Late delivery') & (data['Shipping Mode'] == 'Second Class')]\n#Filtering late delivery orders with same day shipping\nxyz4 = data[(data['Delivery Status'] == 'Late delivery') & (data['Shipping Mode'] == 'Same Day')]\n#Counting total values\ncount1=xyz1['Order Region'].value_counts()\ncount2=xyz2['Order Region'].value_counts()\ncount3=xyz3['Order Region'].value_counts()\ncount4=xyz4['Order Region'].value_counts()\n#Index names\nnames=data['Order Region'].value_counts().keys()\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=names,\n                y=count1,\n                name='Standard Class',\n                marker_color='rgb(55, 83, 109)'\n                ))\nfig.add_trace(go.Bar(x=names,\n                y=count2,\n                name='First Class',\n                marker_color='rgb(26, 118, 255)'\n                ))\nfig.add_trace(go.Bar(x=names,\n                y=count3,\n                name='Second Class',\n                marker_color='rgb(100, 231, 186)'\n                ))\nfig.add_trace(go.Bar(x=names,\n                y=count4,\n                name='Same Day',\n                marker_color='rgb(243, 134, 59)'\n                ))\n\nfig.update_layout(\n    title='Different Types of shipping methods used in all regions',\n    xaxis={'categoryorder':'total descending'},\n    yaxis=dict(\n        title='Number of shipments',\n        titlefont_size=16,\n        tickfont_size=14,\n    ),\n    legend=dict(\n        x=1,\n        y=1.0,\n        bgcolor='rgba(255, 255, 255, 0)',\n        bordercolor='rgba(255, 255, 255, 0)'\n    ),\n    barmode='group',\n    bargap=0.15, # gap between bars of adjacent location coordinates.\n    bargroupgap=0.1 # gap between bars of the same location coordinate.\n)\nfig.show()\n","c91785b0":"def calcular_chi2(dependiente,independientes):\n    for var in independientes:\n        primary_location_cross = pd.crosstab(data[dependiente], data[var])\n        g, p, dof, expctd = chi2_contingency(primary_location_cross)\n        print(\"p-value de Chi-square test para \" + dependiente + \" vs \" + var + \" = \" , p)\n\n\ncolumnas = ['Order Region','Shipping Mode','Category Name','Type','Customer City']\n\ncalcular_chi2('Delivery Status', columnas)\n\n","3962f2a1":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n","57eeec43":"# Select the columns needed for the model\nprediction_data=data[['Order Region','Shipping Mode','Delivery Status']]\nprediction_data.columns=['Order_Region','Shipping_Mode','Delivery_Status'] #al incluir la columna Type el modelo baja su precision, al incluir Customer City el modelo no converge\nprediction_data=prediction_data[prediction_data.Delivery_Status!='Shipping canceled']\nprediction_data=prediction_data[prediction_data.Delivery_Status!='Advance shipping']\nprediction_data.head()","54cbb5f0":"# Feature enginering, one hot encoding\n#usar one hot encoding cuando la variable categorica es NOMINAL\nprediction_data=pd.get_dummies(prediction_data, drop_first=True)\nprediction_data.head()","d2a1af29":"#Test train split\nX_train, X_test, Y_train, Y_test=train_test_split(prediction_data.drop('Delivery_Status_Shipping on time',axis=1),prediction_data['Delivery_Status_Shipping on time'])","05862e56":"#train the model\nLogReg=LogisticRegression()\nLogReg.fit(X_train, Y_train)","9a99d8ed":"#score the model\nLogReg.score(X_test, Y_test)","245a28e8":"Y_pred=LogReg.predict(X_test)\nprint (classification_report(Y_test,Y_pred))","6c27e90f":"#Import dependencies and train the model\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier()\nclassifier.fit(X_train,Y_train)","d03b054d":"#score the model\nclassifier.score(X_test,Y_test)","1aec9dbb":"Y_pred_RF=classifier.predict(X_test)\nprint (classification_report(Y_test,Y_pred_RF))","0fd94582":"Se elaboran las tablas de frecuencia relativa para variables categoricas","ea1bdaa5":"\u00bfCual es la categoria que m\u00e1s se entrega de forma tardia?","7bf56f1d":"Con esta grafica se puede deducir que no existe relaci\u00f3n entre la categoria del producto y la entrega tardia, y que todas las categorias tienen aproximadamente un 50 % de entregas tardias","05d4ae73":"**Datos nulos**\nSe encontraron datos nulos en tres columnas, Order Zipcode ( 86% valores nulos, es decir un total de 155679 registros), Product description (100% de valores nulos, es decir un total de 180519 registros) y customer zipcode (<0.1% es decir un total de 3 registros), en conjunto estas celdas vacias corresponden al 3.5% del total del dataset\n\n**Variables categorcas**\nExisten 28 variables que han sido identificadas como tipo categorico, no obstante, algunas variables se clasificaron como categoricas cuando son numericas, por ejemplo Days for shipping y Order item quantity, esto sucede debido a que todos los valores se agrupan en 4 varoles discretos, lo que genera una confusi\u00f3n por parte de pandas profiling. Con el fin de efectuar an\u00e1lisis estas variables deben ser consideradas como numericas\n\n**Variables numericas**\nExisten 24 variables  que han sido identificadas como tipo numerico\n\n**Conclusiones EDA**\nNo incluir en el an\u00e1lisis las columnas order zipcode (casi vacia), product description (totalmente vacias), customer email (constante sin informaci\u00f3n), Customer password (Constante sin informaci\u00f3n), adicionalmente podemos reemplazar los valores nulos de la columna customer zipcode. \nFinalmente existen algunas  columnas que pueden obviarse a la hora de hacer el an\u00e1lisis ya que no aportan informaci\u00f3n relevante para el objeto del estudio, dichas columnas son: Product Status,Customer Street,Customer Fname,Customer Lname,Latitude,Longitude,Product Image.","7486d666":"*El segundo algoritmo a utilizar es Random Forest ","f5600fdc":"# Algoritmos de CLASIFICACI\u00d3N\n\n*El primer algoritmo a utilizar es regresion logistica","29549fad":"Explorar los primeros 5 registros del dataset","1eb2fac8":"# Data Cleaning","c12c22b4":"Crear reporte de Pandas profile","7e5c73e4":"El modelo creado usando el algoritmo de Random Forest tiene un 75.76% de exactitud","5660873e":"No obstante, la grafica anterior representa la situaci\u00f3n real del comercio electronico debido a que no se tiene en cuenta que el datset se encuentra desbalanceado, por lo que la mayor cantidad de registros se agrupan en unas pocas categorias, al tener en cuenta la proporcionalidad (porcentage de entregas tardias respecto al total de entregas de dicha categoria) se obtiene una grafica diferente que muestra mejor la situaci\u00f3n real","1c07cf4f":"Los valores nulos de zipcode seran reemplazados por el valor mas com\u00fan","d9c43484":"# Descriptive analysis and visualisation\n\nSe elabora una matriz de correlaci\u00f3n","069d4788":"**Referencias**\nhttps:\/\/www.kaggle.com\/skloveyyp\/comparison-of-classification-regression-rnn\n\nhttps:\/\/towardsdatascience.com\/data-cleaning-in-python-the-ultimate-guide-2020-c63b88bf0a0d\n\nhttps:\/\/towardsdatascience.com\/log-book-guide-to-hypothesis-testing-802b1980d0b8","fa1e0abc":"# **Big Data Analysis- Proyecto Big-Data**\n\nIntegrantes: Daniel Fernando Silva Avila - 20201395008.\n\n# ENMARCAR LA PREOCUPACI\u00d3N\n1. Identificaci\u00f3n de los interesados: Se encuentran directamente interesados los directivos del comercio electr\u00f3nico, principalmente los responsables del sistema de distribuci\u00f3n de productos.\n2. Pregunta inicial.\n*\u00bfEl producto llegar\u00e1 tarde a su destino?*\n\nEsta es la generalizaci\u00f3n de la pregunta de negocio con respuesta binaria (si o no).\n\n3. An\u00e1lisis de por qu\u00e9 y para qu\u00e9.\n* \u00bfPor qu\u00e9?: Se han identificado falencias en el sistema de distribuci\u00f3n de mercanc\u00edas (entregas tard\u00edas) que generan quejas y reclamos por parte del cliente que adquiere mercanc\u00eda a trav\u00e9s de nuestra plataforma de comercio electr\u00f3nico. Estas quejas se traducen finalmente en perdidas econ\u00f3micas (los clientes se reh\u00fasan a usar nuevamente el servicio y comparte experiencias negativas en redes sociales).\n* \u00bfPara qu\u00e9?: Con el objetivo de mejorar el proceso de distribuci\u00f3n y prometer al cliente un tiempo de entrega que sea cumplido por nuestra organizaci\u00f3n.\n* Objetivos del an\u00e1lisis: Construir e implementar un modelo de predicci\u00f3n de la estimaci\u00f3n del riesgo de entrega tard\u00eda.\n\n# Objetivo de negocio: \nReducir el numero de entregas tardias (esto implica reducir tambien reducir el numero de quejas y reclamos por tal motivo)\n# Objetivos especificos del notebook\n\n-Desarrollar an\u00e1lisis exploratorio de datos EDA en el dataset elegido para el proyecto usando la libreria de python Pandas-Profiling, el an\u00e1lisis debe incluir las conclusiones de las operaciones de revisi\u00f3n efectuadas con cada libreria.\n\n-Basado en el an\u00e1lisis exploratorio, realizar el proceso de limpieza de datos\n\n-Realizar an\u00e1lisis de dos o m\u00e1s variables y crear graficas de visualizaci\u00f3n con las principales librerias dispuesta para tal fin en python\n\n-Plantear hipotesis  nulas y alternativas que sean rechazadas o aceptadas basados en metodos de estadistica inferencial\n\n-Construir algoritmos de clasificaci\u00f3n que permitan estimar el riesgo de entrega tardia\n\n# Dataset\nEl conjunto de datos contiene informaci\u00f3n de la cadena de suministro para un comercio electr\u00f3nico. Los datos describen procesos de aprovisionamiento, producci\u00f3n, ventas y distribuci\u00f3n comercial. Tambi\u00e9n permite la correlaci\u00f3n de Datos Estructurados con Datos No Estructurados para la generaci\u00f3n de conocimiento. El dataset  ha sido tomado del repositorio kaggle y se encuentra disponible a trav\u00e9s del siguiente enlace: https:\/\/www.kaggle.com\/shashwatwork\/dataco-smart-supply-chain-for-big-data-analysis\n\n","621a82bd":"Guardar el reporte como un archivo con extensi\u00f3n html","4a8916ef":"Basados en la anterior prueba de hipotesis en la cual se utiliza la distribuci\u00f3n Chi2 y se calcularon los niveles de significancia entre\nlas distintas variables categoricas se puede concluir lo siguiente:\n\n1. Rechazar la hipotesis nula 1\n2. Rechazar la hipotesis nula 2\n3. Aceptar la hipotesis nula 3","38c1cea2":"Eliminaremos las columnas innecesarias","fad63c23":"El modelo creado usando regresion logistica tiene un 75.59% de exactitud","c0528838":"# **Estadistica inferencial**\n\nPrueba de hipotesis\n\n*Hipotesis Nula H0*:\n\n1. La region a la cual se realiza el env\u00edo no influye en la entrega tardia\n\n2. El tipo de env\u00edo no influye en la entrega tardia\n\n3. La categoria del producto no influye e la entrega tardia\n\n*Hipotesis Alternativa Ha*: \n\n1. La region a la cual se realiza el env\u00edo  influye en la entrega tardia\n\n2. El tipo de env\u00edo  influye en la entrega tardia\n\n3. La categoria del producto  influye e la entrega tardia","17046793":"\u00bfCual es el numero de entregas tardias de acuerdo con el tipo de env\u00edo y la regi\u00f3n?\nPara esta grafica se realizan dos versiones usando dos librerias diferentes de python con el fin de comparar sus resultados, en la primera se crea una grafica estatica usando matplotlib mientas que la segunda es una grafica dinamica creada usando plotly","2150444b":"Leer el dataset que ha sido importado directamente desde kaggle "}}