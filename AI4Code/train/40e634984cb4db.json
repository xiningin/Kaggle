{"cell_type":{"7a2b6705":"code","efc72eef":"code","dabf4a73":"code","5c53c1f6":"code","bc5edd56":"code","9a855026":"code","41681bc7":"code","1a6f126e":"code","2fd5c7e1":"code","c1972a5f":"code","70dbfe34":"code","d83d8c84":"code","b4c617d2":"code","28a07959":"code","e1d23fcd":"code","8a439515":"code","79e2e226":"code","1fa773d0":"code","f2a5230f":"code","7d2d8a08":"code","cec4a67f":"code","250119b0":"code","50ed421f":"code","b8d74900":"code","e67a9394":"code","27d6d06c":"code","09aa1d7d":"code","37ff34e0":"code","9f983bb7":"code","8cd0b0e4":"code","ef72b699":"code","2141bde4":"code","68e46f75":"code","2219aebc":"code","111bbdda":"code","611a06e6":"code","b6e32677":"code","2acb07e8":"code","7a35adef":"code","5971ee01":"code","ca9d44dd":"code","b35a7884":"code","d77827ec":"code","eae69ee4":"markdown","ea46e0bf":"markdown","08963c1a":"markdown","3a1276a9":"markdown","35f25138":"markdown","c9af199f":"markdown","c51734e2":"markdown","9c3c36df":"markdown","8c52f3fb":"markdown","351e0b7a":"markdown","5e617641":"markdown","49479e23":"markdown","0a516a25":"markdown","40194646":"markdown","7ead8e44":"markdown","90a7c5c5":"markdown","49fa915e":"markdown","69804b71":"markdown","4396e3c3":"markdown","9f0fb383":"markdown","7be7d259":"markdown","17b00307":"markdown","bad6d8ba":"markdown","d938266c":"markdown","80ada9d4":"markdown","2b37a4b0":"markdown","371cf4a2":"markdown","783aa91c":"markdown","2f48a269":"markdown","dbc452f6":"markdown","a549ece6":"markdown"},"source":{"7a2b6705":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nimport sklearn.metrics as metrics\nimport math","efc72eef":"sample_submission = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\ntest = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")\n#Creating a copy of the train and test datasets\nc_test  = test.copy()\nc_train  = train.copy()\n","dabf4a73":"c_train.head()","5c53c1f6":"c_test.head()","bc5edd56":"c_train['train']  = 1\nc_test['train']  = 0\ndf = pd.concat([c_train, c_test], axis=0,sort=False)\n","9a855026":"#Percentage of NAN Values \nNAN = [(c, df[c].isna().mean()*100) for c in df]\nNAN = pd.DataFrame(NAN, columns=[\"column_name\", \"percentage\"])","41681bc7":"NAN = NAN[NAN.percentage > 50]\nNAN.sort_values(\"percentage\", ascending=False)","1a6f126e":"#Drop PoolQC, MiscFeature, Alley and Fence features\ndf = df.drop(['Alley','PoolQC','Fence','MiscFeature'],axis=1)\n","2fd5c7e1":"object_columns_df = df.select_dtypes(include=['object'])\nnumerical_columns_df =df.select_dtypes(exclude=['object'])","c1972a5f":"object_columns_df.dtypes","70dbfe34":"numerical_columns_df.dtypes","d83d8c84":"#Number of null values in each feature\nnull_counts = object_columns_df.isnull().sum()\nprint(\"Number of null values in each column:\\n{}\".format(null_counts))\n","b4c617d2":"columns_None = ['BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','GarageType','GarageFinish','GarageQual','FireplaceQu','GarageCond']\nobject_columns_df[columns_None]= object_columns_df[columns_None].fillna('None')","28a07959":"columns_with_lowNA = ['MSZoning','Utilities','Exterior1st','Exterior2nd','MasVnrType','Electrical','KitchenQual','Functional','SaleType']\n#fill missing values for each column (using its own most frequent value)\nobject_columns_df[columns_with_lowNA] = object_columns_df[columns_with_lowNA].fillna(object_columns_df.mode().iloc[0])\n","e1d23fcd":"#Number of null values in each feature\nnull_counts = numerical_columns_df.isnull().sum()\nprint(\"Number of null values in each column:\\n{}\".format(null_counts))\n","8a439515":"print((numerical_columns_df['YrSold']-numerical_columns_df['YearBuilt']).median())\nprint(numerical_columns_df[\"LotFrontage\"].median())\n","79e2e226":"numerical_columns_df['GarageYrBlt'] = numerical_columns_df['GarageYrBlt'].fillna(numerical_columns_df['YrSold']-35)\nnumerical_columns_df['LotFrontage'] = numerical_columns_df['LotFrontage'].fillna(68)\n","1fa773d0":"numerical_columns_df= numerical_columns_df.fillna(0)","f2a5230f":"object_columns_df['Utilities'].value_counts().plot(kind='bar',figsize=[10,3])\nobject_columns_df['Utilities'].value_counts() \n","7d2d8a08":"object_columns_df['Street'].value_counts().plot(kind='bar',figsize=[10,3])\nobject_columns_df['Street'].value_counts() ","cec4a67f":"object_columns_df['Condition2'].value_counts().plot(kind='bar',figsize=[10,3])\nobject_columns_df['Condition2'].value_counts() \n","250119b0":"object_columns_df['RoofMatl'].value_counts().plot(kind='bar',figsize=[10,3])\nobject_columns_df['RoofMatl'].value_counts() ","50ed421f":"object_columns_df['Heating'].value_counts().plot(kind='bar',figsize=[10,3])\nobject_columns_df['Heating'].value_counts() #======> Drop feature one Type\n","b8d74900":"object_columns_df = object_columns_df.drop(['Heating','RoofMatl','Condition2','Street','Utilities'],axis=1)\n","e67a9394":"numerical_columns_df['Age_House']= (numerical_columns_df['YrSold']-numerical_columns_df['YearBuilt'])\nnumerical_columns_df['Age_House'].describe()\n","27d6d06c":"Negatif = numerical_columns_df[numerical_columns_df['Age_House'] < 0]\nNegatif\n","09aa1d7d":"numerical_columns_df.loc[numerical_columns_df['YrSold'] < numerical_columns_df['YearBuilt'],'YrSold' ] = 2009\nnumerical_columns_df['Age_House']= (numerical_columns_df['YrSold']-numerical_columns_df['YearBuilt'])\nnumerical_columns_df['Age_House'].describe()\n","37ff34e0":"numerical_columns_df['TotalBsmtBath'] = numerical_columns_df['BsmtFullBath'] + numerical_columns_df['BsmtFullBath']*0.5\nnumerical_columns_df['TotalBath'] = numerical_columns_df['FullBath'] + numerical_columns_df['HalfBath']*0.5 \nnumerical_columns_df['TotalSA']=numerical_columns_df['TotalBsmtSF'] + numerical_columns_df['1stFlrSF'] + numerical_columns_df['2ndFlrSF']\n","9f983bb7":"numerical_columns_df.head()","8cd0b0e4":"bin_map  = {'TA':2,'Gd':3, 'Fa':1,'Ex':4,'Po':1,'None':0,'Y':1,'N':0,'Reg':3,'IR1':2,'IR2':1,'IR3':0,\"None\" : 0,\n            \"No\" : 2, \"Mn\" : 2, \"Av\": 3,\"Gd\" : 4,\"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3,\"BLQ\" : 4, \"ALQ\" : 5, \"GLQ\" : 6\n            }\nobject_columns_df['ExterQual'] = object_columns_df['ExterQual'].map(bin_map)\nobject_columns_df['ExterCond'] = object_columns_df['ExterCond'].map(bin_map)\nobject_columns_df['BsmtCond'] = object_columns_df['BsmtCond'].map(bin_map)\nobject_columns_df['BsmtQual'] = object_columns_df['BsmtQual'].map(bin_map)\nobject_columns_df['HeatingQC'] = object_columns_df['HeatingQC'].map(bin_map)\nobject_columns_df['KitchenQual'] = object_columns_df['KitchenQual'].map(bin_map)\nobject_columns_df['FireplaceQu'] = object_columns_df['FireplaceQu'].map(bin_map)\nobject_columns_df['GarageQual'] = object_columns_df['GarageQual'].map(bin_map)\nobject_columns_df['GarageCond'] = object_columns_df['GarageCond'].map(bin_map)\nobject_columns_df['CentralAir'] = object_columns_df['CentralAir'].map(bin_map)\nobject_columns_df['LotShape'] = object_columns_df['LotShape'].map(bin_map)\nobject_columns_df['BsmtExposure'] = object_columns_df['BsmtExposure'].map(bin_map)\nobject_columns_df['BsmtFinType1'] = object_columns_df['BsmtFinType1'].map(bin_map)\nobject_columns_df['BsmtFinType2'] = object_columns_df['BsmtFinType2'].map(bin_map)\n\nPavedDrive =   {\"N\" : 0, \"P\" : 1, \"Y\" : 2}\nobject_columns_df['PavedDrive'] = object_columns_df['PavedDrive'].map(PavedDrive)\n\n","ef72b699":"#Select categorical features\nrest_object_columns = object_columns_df.select_dtypes(include=['object'])\n#Using One hot encoder\nobject_columns_df = pd.get_dummies(object_columns_df, columns=rest_object_columns.columns) \n","2141bde4":"object_columns_df.head()","68e46f75":"df_final = pd.concat([object_columns_df, numerical_columns_df], axis=1,sort=False)\ndf_final.head()","2219aebc":"df_final = df_final.drop(['Id',],axis=1)\n\ndf_train = df_final[df_final['train'] == 1]\ndf_train = df_train.drop(['train',],axis=1)\n\n\ndf_test = df_final[df_final['train'] == 0]\ndf_test = df_test.drop(['SalePrice'],axis=1)\ndf_test = df_test.drop(['train',],axis=1)\n","111bbdda":"target= df_train['SalePrice']\ndf_train = df_train.drop(['SalePrice'],axis=1)","611a06e6":"x_train,x_test,y_train,y_test = train_test_split(df_train,target,test_size=0.33,random_state=0)","b6e32677":"\nxgb =XGBRegressor( booster='gbtree', colsample_bylevel=1,\n             colsample_bynode=1, colsample_bytree=0.6, gamma=0,\n             importance_type='gain', learning_rate=0.01, max_delta_step=0,\n             max_depth=4, min_child_weight=1.5, n_estimators=2400,\n             n_jobs=1, nthread=None, objective='reg:linear',\n             reg_alpha=0.6, reg_lambda=0.6, scale_pos_weight=1, \n             silent=None, subsample=0.8, verbosity=1)\n\n\nlgbm = LGBMRegressor(objective='regression', \n                                       num_leaves=4,\n                                       learning_rate=0.01, \n                                       n_estimators=12000, \n                                       max_bin=200, \n                                       bagging_fraction=0.75,\n                                       bagging_freq=5, \n                                       bagging_seed=7,\n                                       feature_fraction=0.4, \n                                       )\n","2acb07e8":"#Fitting\nxgb.fit(x_train, y_train)\nlgbm.fit(x_train, y_train,eval_metric='rmse')\n","7a35adef":"predict1 = xgb.predict(x_test)\npredict = lgbm.predict(x_test)\n","5971ee01":"print('Root Mean Square Error test = ' + str(math.sqrt(metrics.mean_squared_error(y_test, predict1))))\nprint('Root Mean Square Error test = ' + str(math.sqrt(metrics.mean_squared_error(y_test, predict))))\n","ca9d44dd":"xgb.fit(df_train, target)\nlgbm.fit(df_train, target,eval_metric='rmse')\n","b35a7884":"predict4 = lgbm.predict(df_test)\npredict3 = xgb.predict(df_test)\npredict_y = ( predict3*0.45 + predict4 * 0.55)\n","d77827ec":"submission = pd.DataFrame({\n        \"Id\": test[\"Id\"],\n        \"SalePrice\": predict_y\n    })\nsubmission.to_csv('submission.csv', index=False)\n","eae69ee4":"* <font color='black'>  **Now we will select numerical and categorical features**  <font>","ea46e0bf":"\n* <font color='black'>  **Categorical Features** :  <font>","08963c1a":" <font color='black'>  **So we will fill the year with 1979 and the Lot frontage with 68** <\/font>\n","3a1276a9":" <font color='black'> **Fill the rest of columns with 0**  <font>\n","35f25138":" <font color='black'> \n*** TotalBsmtBath : Sum of :\nBsmtFullBath and  1\/2 BsmtHalfBath**\n\n*** TotalBath : Sum of :\nFullBath and 1\/2 HalfBath**\n\n*** TotalSA : Sum of : \n1stFlrSF and 2ndFlrSF and basement area**\n<\/font>\n\n\n\n","c9af199f":"#  <font color='red'> House Prices : Data cleaning, visualization and modeling  <\/font>","c51734e2":"\n* <font color='black'>  **Getting information about test dataset** <\/font>\n","9c3c36df":"* <font color='black'>  ** Now we have a clean categorical features** <\/font>\n* <font color='black'>   In the next step we will deal with the **numerical** features <\/font>black","8c52f3fb":"\n* <font color='black'>   We will fill -- **BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, GarageType, GarageFinish, GarageQual, FireplaceQu, GarageCond** -- with \"None\" (Take a look in the data description). <\/font>\n* <font color='black'>    We will fill the rest of features with th most frequent value (using its own most frequent value). <\/font>","351e0b7a":"\n* <font color='black'>  Deeling with **categorical** feature  <font>","5e617641":"\n* <font color='black'>  **Ordinal categories features** - Mapping from 0 to N  <font>","49479e23":"#  <font color='red'> Data preprocessing <\/font>","0a516a25":"* <font color='black'> **Now we will create some new features**  <font>","40194646":"* <font color='black'>  **Numerical Features** :  <font>","7ead8e44":"\n* <font color='black'> **Like we see here tha the minimun is -1 ???** <font>\n* <font color='black'>**It is strange to find that the house was sold in 2007 before the YearRemodAdd 2009.**\n\n    **So we decide to change the year of sold to 2009** <font>","90a7c5c5":"* <font color='black'>  **Features with more than 50% of missing values.** <\/font>","49fa915e":"\n* <font color='black'>  **Calculating the percentage of missing values of each feature** <\/font>\n","69804b71":"#  <font color='red'> Modeling  <\/font>","4396e3c3":"<font color='red'>  Importing **train** and **test** datasets <\/font>","9f0fb383":"* <font color='black'>  **We finally end up with a clean dataset**  <font>","7be7d259":"\n* <font color='black'>  **Concat Train and Test datasets** <\/font>\n","17b00307":"\n* <font color='black'> **Fitting With all the dataset** <font>","bad6d8ba":"\n* <font color='black'> **Now the next step is to encode categorical features**  <font>\n","d938266c":"\n* <font color='black'>  **Separate Train and Targets**  <font>","80ada9d4":"\n* <font color='black'>  **Will we use One hot encoder to encode the rest of categorical features**  <font>","2b37a4b0":"* <font color='black'>  **Getting information about train dataset** <\/font>","371cf4a2":"\n* <font color='black'> **After making some plots we found that we have some colums with low variance so we decide to delete them**  <font>\n","783aa91c":"1. <font color='black'>  **Fill GarageYrBlt and LotFrontage** <\/font>\n1. <font color='black'>  **Fill the rest of columns with 0** <\/font>","2f48a269":"* <font color='black'>  **We can drop PoolQC, MiscFeature, Alley and Fence features because they have more than 80% of missing values.** <font>","dbc452f6":"\n* <font color='black'>  **Concat Categorical (after encoding) and numerical features**  <font>\n","a549ece6":" <font color='black'> 1. **We have 81 columns.**\n2. **Our target variable is SalePrice.**\n3. **Id is just an index that we can drop but we will need it in the final submission.**\n1. **We have many missing values** <\/font>\n\n\n <font color='red'>   *** * * * we have 79 features in our dataset.** <\/font>\n\n"}}