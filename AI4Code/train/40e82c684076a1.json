{"cell_type":{"671f7d0c":"code","09842eae":"code","2a59bb0b":"code","8107ce3c":"code","7773feb5":"code","e77982fe":"code","151db630":"code","00c309d0":"code","6437c53a":"code","7ba1352b":"code","41155d0d":"code","6460cda6":"code","da9b6dd2":"code","c040bffb":"code","8ff593e0":"code","46caf322":"code","0bd9af3d":"code","bcef827d":"code","5b7769db":"code","c21a10f9":"code","40793bf7":"code","ed996d12":"code","ce6f4fd4":"code","adf7b966":"code","217d0ab0":"code","cde1677b":"markdown","b47b874b":"markdown","e8fff5aa":"markdown","b2a42999":"markdown","9dddc53e":"markdown","5a71c6e5":"markdown","792e7b99":"markdown","427482be":"markdown"},"source":{"671f7d0c":"%%bash\npip install git+https:\/\/github.com\/fastai\/fastai2\npip install torch torchvision feather-format pillow=='6.2.0' kornia pyarrow --upgrade   > \/dev\/null","09842eae":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom fastai2.data.all import *\nfrom fastai2.vision.all import *\nfrom fastai2.vision.core import *\nfrom fastai2.vision.data import *\nfrom sklearn.metrics import auc, roc_curve, precision_recall_curve, classification_report\n\nimport os\nprint(os.listdir(\"..\/input\"))\n","2a59bb0b":"path=Path('..\/input')\ntrn_path = path\/'train'\ntst_path = path\/'test'\nlabels = pd.read_csv(path\/'train_labels.csv').set_index('id')\nlabels.head()","8107ce3c":"print(f'Number of labels {len(labels)}')\nsns.countplot(x='label',data=labels)","7773feb5":"img_fn = trn_path.ls()[0]\nget_labels = lambda x: labels.loc[x.name[:-4],'label']\nprint(f'Label: {get_labels(img_fn)}')\nPILImage.create(img_fn)","e77982fe":"splitter = RandomSplitter()\nitem_tfms = [Resize(224)]\nbatch_tfms=[*aug_transforms(flip_vert=True,max_zoom=1.2), Normalize.from_stats(*imagenet_stats)]","151db630":"data_block = DataBlock(blocks=[ImageBlock, CategoryBlock],\n                  get_items=get_image_files,\n                  get_y=get_labels,\n                  splitter=splitter,\n                  item_tfms=item_tfms,\n                  batch_tfms=batch_tfms)","00c309d0":"data = data_block.dataloaders(trn_path, bs=64)\ndata.show_batch()","6437c53a":"learner= cnn_learner(data, xresnet50, metrics=[accuracy]).to_fp16()","7ba1352b":"learner.lr_find()","41155d0d":"# learner.fine_tune(20)\nlearner.fine_tune(1, 1e-2)","6460cda6":"learner.save('stage1')","da9b6dd2":"learner.fine_tune(5)","c040bffb":"interp = ClassificationInterpretation.from_learner(learner)\ninterp.plot_confusion_matrix(figsize=(10,8))","8ff593e0":"# Predictions of the validation data\npreds_val, y_val=learner.get_preds()","46caf322":"#  ROC curve\nfpr, tpr, thresholds = roc_curve(y_val.numpy(), preds_val.numpy()[:,1], pos_label=1)\n\n#  ROC area\npred_score = auc(fpr, tpr)\nprint(f'ROC area is {pred_score}')","0bd9af3d":"plt.figure()\nplt.plot(fpr, tpr, color='orange', label='ROC curve (area = %0.2f)' % pred_score)\nplt.plot([0, 1], [0, 1], color='navy', linestyle='--')\nplt.xlim([-0.01, 1.0])\nplt.ylim([0.0, 1.01])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")","bcef827d":"tst_files = get_image_files(tst_path)\ndata.test_dl(tst_files)","5b7769db":"dl = learner.dls.test_dl(tst_files) ","c21a10f9":"preds_tst, y_tst=learner.get_preds(dl=dl)","40793bf7":"# Predictions on the Test data\n# preds_test,y_test = learner.TTA(ds_type=DatasetType.Test)\n# preds_test, y_test=learner.get_preds(ds_type=DatasetType.Test)","ed996d12":"sub=pd.read_csv(f'{path}\/sample_submission.csv').set_index('id')\nsub.head()","ce6f4fd4":"names=np.vectorize(lambda img_name: str(img_name).split('\/')[-1][:-4]) \nfile_names= names(data.test_ds.items).astype(str)","adf7b966":"sub.loc[file_names,'label']=preds_test.numpy()[:,1]\nsub.to_csv(f'submission_{pred_score}.csv')","217d0ab0":"sub.head()","cde1677b":"### Roc Curve\nWith the ROC curve we will mesuare how good it's our model","b47b874b":"## Production ","e8fff5aa":"# Heatmap","b2a42999":"# Histopathologic Cancer Detection\n\nThis challenge will focus on the detection and classification of breast cancer metastases in lymph nodes. Lymph nodes are small glands that filter lymph, the fluid that circulates through the lymphatic system. \n![bcancer](https:\/\/camelyon17.grand-challenge.org\/media\/CAMELYON17\/public_html\/breast_lymph_node.png)\nThe lymph nodes in the axilla are the first place breast cancer is likely to spread. Metastatic involvement of lymph nodes is one of the most important prognostic factors in breast cancer. Prognosis is poorer when cancer has spread to the lymph nodes. This is why lymph nodes are surgically removed and examined microscopically. However, the diagnostic procedure for pathologists is tedious and time-consuming. But most importantly, small metastases are very difficult to detect and sometimes they are missed.","9dddc53e":"## Exploratory Data Analysis\nIn this dataset, you are provided with a large number of small pathology images to classify. Files are named with an image id. The train_labels.csv file provides the ground truth for the images in the train folder. You are predicting the labels for the images in the test folder. A positive label indicates that the center 32x32px region of a patch contains at least one pixel of tumor tissue. Tumor tissue in the outer region of the patch does not influence the label. This outer region is provided to enable fully-convolutional models that do not use zero-padding, to ensure consistent behavior when applied to a whole-slide image.","5a71c6e5":"##  Confusion Matrix","792e7b99":"## Submision","427482be":"## Test Prediction"}}