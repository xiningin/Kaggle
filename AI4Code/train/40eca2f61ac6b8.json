{"cell_type":{"658e2bc7":"code","520988b1":"code","a9d40750":"code","0af0f9db":"code","09a0011c":"code","3432ff09":"code","0e3d79fa":"code","c900ca3b":"code","2d07032a":"code","14ee6ad7":"code","1f537043":"code","cae7ac44":"code","3bfa90ee":"code","d87e55fb":"code","6d0300ea":"code","121ddb0d":"code","4cfe6a68":"code","7ce265f9":"code","87a8a25c":"code","58a4f0c9":"code","bd3fc026":"code","718abad2":"code","b5ef8c65":"code","e332bc9d":"code","d4d0323b":"code","012fe6c4":"code","c8f6d61e":"code","080752b9":"code","aacf8bfa":"code","83246c32":"code","99b64731":"code","198352ae":"markdown","f4ba1764":"markdown","958bced4":"markdown","2a89863b":"markdown","1d4ae664":"markdown","b1093c9c":"markdown","52793cf7":"markdown","080d34d2":"markdown","e3db9f4e":"markdown","64a5097f":"markdown","00cdce41":"markdown","9f9f0548":"markdown"},"source":{"658e2bc7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","520988b1":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()","a9d40750":"# load the data into pandas dataframe:\ndf = pd.read_csv('\/kaggle\/input\/insurance-premium-prediction\/insurance.csv')","0af0f9db":"#look at the basic information\ndf.head()","09a0011c":"df.describe()","3432ff09":"print(\"There are no missing values in this dataframe\")\ndf.notnull().count()\n","0e3d79fa":"#Check for duplicate values\ndf[df.duplicated()]","c900ca3b":"# Remove the one duplicative piece of data\ndf = df.drop_duplicates()\n\n# Confirm duplicates are gone\ndf.duplicated().sum()","2d07032a":"#Look at the distribution of expenses through a histogram\ndf.expenses.plot(kind=\"hist\")","14ee6ad7":"# Visualize expenses vs age, and expenses vs smoking \nsns.scatterplot(data=df, x=df['age'], y=df['expenses'], hue=df['smoker'])","1f537043":"# Check bmi distribution, mostly out of curiousity\ndf.bmi.plot(kind=\"hist\")","cae7ac44":"# Look at scatter plot between bmi and expenses\nsns.scatterplot(data=df, x=df['bmi'], y=df['expenses'])","3bfa90ee":"# Visualize expenses vs smoking status\nprint(\"Smokers tend to have higher costs\")\n#sns.violinplot(data=df, x=df['smoker'], y=df['expenses'])\nsns.boxplot(data=df, x=df['smoker'], y=df['expenses'])\n","d87e55fb":"# Look at various pairings of variables to see if there are any other patterns not identified yet\nsns.pairplot(data=df,hue='smoker')\n","6d0300ea":"df['smoker'] = df['smoker'].map({\"no\": 0, \"yes\": 1})\ndf['sex'] = df['sex'].map({\"female\": 0, \"male\": 1})\ndf.head()","121ddb0d":"df['region'].unique()","4cfe6a68":"# separate the region using one-hot coding\none_hot = pd.get_dummies(df['region'])\none_hot","7ce265f9":"# combine the new regional columns with the existing dataframe so it's all numerical\ndata = pd.concat([df,one_hot],axis=1)\ndata.head()","87a8a25c":"# groupby each region to see if there's a significant difference in costs among regions\ndf.groupby(\"region\").expenses.agg([\"mean\",\"median\",\"count\"])\n\n","58a4f0c9":"# Looking at the relationship of regional expenses vs specific categoies,\n# to see if there are any significant profile differences between regions\nprint(\"EXPENSES BY REGION\")\nprint(df.groupby(\"region\").expenses.agg([\"mean\",\"median\",\"count\"]))\nprint(\"AGE VS REGION\")\nprint(df.groupby(\"region\").age.agg([\"mean\",\"median\",\"count\"]))\nprint(\"BMI VS REGION\")\nprint(df.groupby(\"region\").bmi.agg([\"mean\",\"median\",\"count\"]))\nprint(\"SMOKING VS REGION\")\nprint(df.groupby(\"region\").smoker.agg(['mean']))\n\n","bd3fc026":"#Correlation heat map to visualize correlations among all variables \nplt.figure(figsize=(10,8))\ncorr = df.corr()\nsns.heatmap(corr, annot=True)","718abad2":"data.head()","b5ef8c65":"# Declare the variables\n# Even though we believe age, bmi, and smoker are the only three important variables, \n# we'll include more to start\ny = data['expenses']\nx1 = data[['age', 'bmi', 'smoker', 'sex', 'northeast', 'northwest', 'southeast', 'southwest']]\nx1.head()","e332bc9d":"import statsmodels.api as sm\n\nresults = sm.OLS(y,x1).fit()","d4d0323b":"results.summary()","012fe6c4":"y = data['expenses']\nX = data[['age', 'bmi', 'smoker']]\nresults = sm.OLS(y,X).fit()","c8f6d61e":"results.summary()","080752b9":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import KFold\n\n","aacf8bfa":"# Split data into test and training sets, running a linear model and a random forest\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\nreg = LinearRegression().fit(X_train, y_train)\nforest = RandomForestRegressor(random_state=1).fit(X_train, y_train)\n\ny_train_pred = reg.predict(X_train)\ny_test_pred = reg.predict(X_test)\n\ny_train_forest = forest.predict(X_train)\nforest_preds = forest.predict(X_test)\n\nprint(\"Linear regression info:\")\nprint(reg.score(X_test, y_test))\nmae = mean_absolute_error(y_test, y_test_pred)\nprint(\"MAE: {}\".format(mae))\n\n\nmae_forest = mean_absolute_error(y_test, forest_preds)\nprint(\"Forest model info\")\nprint(forest.score(X_test, y_test))\nprint(\"MAE: {}\".format(mae_forest))\n\n","83246c32":"# Prevent overfitting with cross validation tests, since we only did one split so far\n# Run 5 scenarios of each model,and evaluate which is a better model before making predictions\n\nfrom sklearn.model_selection import cross_val_score\nforest_score = cross_val_score(RandomForestRegressor(),X,y)\nprint(\"Each Forest score: \", forest_score)\nprint(\"Mean Random Forest Score: \",forest_score.mean())\n\nlinear_score = cross_val_score(LinearRegression(),X,y)\nprint(\"Each Linear score: \", linear_score)\nprint(\"Mean Regression Scores: \", linear_score.mean())\n","99b64731":"# Showing a few specific predictions to see how close we were:\nprint(\"Predictions: {}\".format(forest.predict(X.head())))\ndata['expenses'].head()\n\n\n","198352ae":"Unsurprisingly, expenses tend to increase with age. It also appears there are almost three clusters for expenses here. We may inspect this later, after reviewing how the other factors interact with expenses.","f4ba1764":"With an r-squared of .0.87, this model is mostly accurate. The three most correlated factors were input, and all three are significant, as the P value shows 0.000 for age and smoker, and .029 < 0.05 for bmi. ","958bced4":"Looking at the initial results:\n- R-squared of 0.75 is okay, but has room for improvement\n- All of the variables except for sex have a seemingly significant p-value, mostly showing 0.0000. Sex is clearly not significant with a p-value of.745.\n- Inspecting further, each region has a similar coefficient that only ranges by a couple hundred dollars. In addition, the standard error is large as well.\n- We should run this again, but drop the regions and sex since they aren't adding value.","2a89863b":"Eastern premium costs seem higher than western ones -- let's see how age, BMI, and smoking factor into each category","1d4ae664":"This data looks much better. The r-squared is now 0.87, and all three variables seem to have predictive power. Now, we will separate the data into test\/train split and see our accuracy.\n\nIn addition, the f-statistic is much higher now (3029 vs 565). This shows the significance of the model, where a higher number means more. We will use this model going forward.\n\nLooking at the coefficients, it is also eye opening how large an impact smoking makes. There is a 23,320 estimated increase in annual premiums for smokers! \n","b1093c9c":"As we can see, the mean Random Forest Score is 0.80, which is higher than the Linear Model's score of 0.74. ","52793cf7":"NEXT, CREATE A REGRESSION","080d34d2":"After looking at the data, it's time to clean it and start to quantify the different relationships","e3db9f4e":"Observations:   \n- Smoking has a very large impact on expenses (bmi vs expenses)\n- Age also has a positive correlation with expenses (age vs expenses)\n- Number of children seems to have very little effect (children vs expenses)\n\n","64a5097f":"\nSmoker (.79), age (.3), and bmi (0.2).  Smoking is the only big correlation, while the other relationships aren't significant.","00cdce41":"Southeast has a higher BMI and percentage of clients who smoke, which are both correlated to higher costs.","9f9f0548":"Initial observations and actions:  \n - Check for missing values and duplicate values\n - We have 4 numerical columns and 3 categorical columns. Map sex, smoker, and region into numbers.\n - Explore distribution of the expenses  \n - Explore correlations of expenses with the independent variables  \n - Explore specific relationship between \n"}}