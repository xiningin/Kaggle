{"cell_type":{"b3f41db9":"code","6de6ba1c":"code","766557e6":"code","ef1e28f8":"code","a876a38d":"code","2bbe6e92":"code","2cd5de71":"code","15af73d5":"code","0227a917":"code","92fd7ced":"code","2fb8e348":"code","b1b1e77c":"code","86803b26":"code","012a8a81":"code","a89c32d7":"code","341bf852":"code","d7cf0e91":"code","b3460f94":"code","f76e40df":"code","187c7c4f":"code","487e1294":"code","b562f7c5":"code","edc25e71":"code","3ff32d67":"code","815d28c8":"code","2dd6f18a":"code","b6a402a8":"code","0a9d6432":"code","a7decd3d":"code","d2c16eb7":"code","d5c7433c":"code","574bd6d3":"markdown","244c91b7":"markdown","0e7bda0b":"markdown","fa19ad51":"markdown","76d161af":"markdown","91d0c314":"markdown"},"source":{"b3f41db9":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\n\n\nfrom sklearn import metrics\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\n\nimport ast\nimport os\nimport re\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6de6ba1c":"train = pd.read_csv(\"\/kaggle\/input\/made-hw-2\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/made-hw-2\/test.csv\")\nsample_submission = pd.read_csv(\"\/kaggle\/input\/made-hw-2\/sample_submission_most_popular.csv\")","766557e6":"train.genres = train.genres.apply(ast.literal_eval)\nmlb = MultiLabelBinarizer()\ntrain = train.join(pd.DataFrame(mlb.fit_transform(train.pop('genres')), index=train.index, columns=mlb.classes_))","ef1e28f8":"# Plot genres distribution:\nall_genres_df = train[train.columns[3:]].sum().sort_values(ascending=False)\nplt.figure(figsize=(24, 10))\nax = sns.barplot(x=all_genres_df.values, y=all_genres_df.index)\nax.set(xlabel=\"Count\", ylabel=\"Genre\")\nplt.show()","a876a38d":"# Our dialogues contain some tags.\n# Let's extract them and their indexes:\n\ntags_idx = []\ntags = []\nfor i, d in enumerate(train['dialogue'].values):\n    vals = re.findall(\"<(?:\\\/)?\\w+>\", d)\n    for val in vals:\n        if val not in tags:\n            tags_idx.append(i)\n            tags.append(val)\n# print(tags_idx)\n# print(tags)","2bbe6e92":"# Display dialog with specified index:\n\n# train['dialogue'][25966]","2cd5de71":"def clean_text(text):\n    # text = text.lower()\n\n    text = re.sub(r\"<BR>\", \" \", text)\n    text = re.sub(r\"<br>\", \" \", text)\n    text = re.sub(r\"<U>\", \" \", text)\n    text = re.sub(r\"<\/U>\", \" \", text)\n    text = re.sub(r\"<u>\", \" \", text)\n    text = re.sub(r\"<\/u>\", \" \", text)\n    text = re.sub(r\"<b>\", \" \", text)\n    text = re.sub(r\"<\/b>\", \" \", text)\n    text = re.sub(r\"<i>\", \" \", text)\n    text = re.sub(r\"<\/i>\", \" \", text)\n    text = re.sub(r\"<PRE>\", \" \", text)\n    text = re.sub(r\"<\/PRE>\", \" \", text)\n    text = re.sub(r\"<\", \" \", text)\n    text = re.sub(r\">\", \" \", text)\n\n    # text = re.sub(r\"\\'m\", \" am \", text)\n    # text = re.sub(r\"\\'re\", \" are \", text)\n    # text = re.sub(r\"\\'ve\", \" have \", text)\n    # text = re.sub(r\"\\'d\", \" would \", text)\n    # text = re.sub(r\"\\'ll\", \" will \", text)\n    # text = re.sub(r\"n\\'t\", \" not\", text)\n\n    # text = re.sub(r\"\\'\", \"\", text)\n    # text = re.sub(r\"[^A-Za-z0-9?!.,\\']\", \" \", text)\n\n    text = ' '.join(text.split())\n    return text","15af73d5":"train.dialogue = train.dialogue.map(lambda x: clean_text(x))","0227a917":"def freq_words(corpus, top=30):\n    all_words = ' '.join([part for part in corpus])\n    all_words = all_words.split()\n\n    freq_dist = nltk.FreqDist(all_words)\n    words_df = pd.DataFrame({'Word': list(freq_dist.keys()),\n                             'Count': list(freq_dist.values())})\n\n    # Select top {terms} most frequent words:\n    data = words_df.nlargest(columns=\"Count\", n=top)\n\n    # Plot words and frequencies:\n    plt.figure(figsize=(24, 12))\n    ax = sns.barplot(data=data, x=\"Count\", y =\"Word\")\n    ax.set(ylabel=\"Word\")\n    plt.show()","92fd7ced":"# Plot the most frequent words:\n# freq_words(train.dialogue, 20)","2fb8e348":"stop_words = set(stopwords.words('english'))\n\n# Define a function to remove stopwords:\ndef remove_stopwords(text):\n    no_stopword_text = [w for w in text.split() if not w in stop_words]\n    return ' '.join(no_stopword_text)","b1b1e77c":"# print(sorted(stop_words))","86803b26":"# train.dialogue = train.dialogue.map(lambda x: remove_stopwords(x))\n# freq_words(train.dialogue, 20)","012a8a81":"PRED_THRESHOLD = 0.275","a89c32d7":"train = train.drop(['id', 'movie'], axis=1)","341bf852":"X = train['dialogue']\ny = train.drop(['dialogue'], axis=1)","d7cf0e91":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=4)","b3460f94":"model_pipeline = Pipeline([\n    ('tfidf', TfidfVectorizer(stop_words='english')),\n    ('clf', OneVsRestClassifier(LogisticRegression(max_iter=500, solver='sag'))),\n])","f76e40df":"def scoring_func(estimator, X, y):\n    prediction = estimator.predict_proba(X)\n    prediction = (prediction >= PRED_THRESHOLD).astype(int)\n    return f1_score(y, prediction, average='samples')","187c7c4f":"scores = cross_val_score(model_pipeline, X, y, cv=5, scoring=scoring_func)\nprint(f\"{scores.mean():.3f}\u00b1{scores.std():.3f}\")","487e1294":"model_pipeline.fit(X, y)","b562f7c5":"lr = model_pipeline.steps[-1][1]\ntf = model_pipeline.steps[0][1]\n\nindexes = np.argsort(np.abs(lr.coef_[0]))[-50:]\nweights = lr.coef_[0][indexes]\nnames = np.array(tf.get_feature_names())[indexes]\n\nplt.figure(figsize=(24, 12));\nsns.barplot(weights, names, orient='h');","edc25e71":"def make_prediction(data):\n    data = data.map(lambda x: clean_text(x))\n    # data = data.map(lambda x: remove_stopwords(x))\n    prediction = model_pipeline.predict_proba(data)\n    prediction = (prediction >= PRED_THRESHOLD).astype(int)\n    return prediction","3ff32d67":"genres = list(y.columns)","815d28c8":"model_pipeline.fit(X, y)","2dd6f18a":"test = test.drop(['id'], axis=1)\ntest_preds = make_prediction(test.dialogue)","b6a402a8":"test_preds = pd.DataFrame(test_preds)\ntest_preds.columns = genres\ntest_preds.head()","0a9d6432":"submission = pd.DataFrame()\nsubmission[['id', 'genres']] = 0\nsubmission = submission.astype({\"id\": int})","a7decd3d":"for id, vals in enumerate(test_preds.values):\n    lst = []\n    for i, v in enumerate(vals):\n        if v == 1:\n            lst.append(genres[i])\n    submission.loc[id] = [id] + [\" \".join(lst)]","d2c16eb7":"submission.head(10)","d5c7433c":"submission.to_csv(\"submission.csv\", index=None)","574bd6d3":"# Analyse and transform genres","244c91b7":"The last 5 tags are not really tags. We'll just get rid of the brackets around them.","0e7bda0b":"# Load data","fa19ad51":"# Build model","76d161af":"# Submission file","91d0c314":"# Analyse and transform dialogues"}}