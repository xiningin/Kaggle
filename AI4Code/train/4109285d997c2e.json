{"cell_type":{"fdb3ce7f":"code","95edb898":"code","33e1c3b6":"code","127379a6":"code","495b7a09":"code","dc97716c":"code","9169b005":"code","6bec5bf4":"code","70f2bcec":"code","4affb9f7":"code","956ed7ba":"code","634fbdf3":"code","6f9b138f":"code","22909e26":"code","c597abfd":"code","43fe8847":"code","e9649d35":"code","8e1150e7":"code","8f355d63":"code","fde67d37":"code","c4e1486e":"code","cab6bbaa":"code","2c4be3dc":"code","1edfe8ff":"code","ee9e4753":"code","c4fa5e5a":"code","a44b817e":"code","93fce8c0":"code","9583e1d3":"code","041dcaa5":"code","c4d0853d":"code","eaca9e5d":"code","e31f6927":"code","04896c18":"code","ff7d05b4":"code","8aa944b6":"code","87eaf21f":"markdown","1b12eee8":"markdown","d3b56b35":"markdown","ff5ce3ea":"markdown","40273c30":"markdown","b2c5028b":"markdown","f9064152":"markdown","ea9a5186":"markdown","f40af739":"markdown","b342be3a":"markdown","baa5370c":"markdown","3cb10007":"markdown","0692dd51":"markdown","1f809213":"markdown","c14aa32b":"markdown","b89685f1":"markdown","d3e4d0f8":"markdown","f61b8309":"markdown","0a0331bb":"markdown","a6ddf536":"markdown","8d3b633e":"markdown","6a1c0386":"markdown","2ed9c7d9":"markdown"},"source":{"fdb3ce7f":"import sys\nsys.path.insert(0,'..\/input\/timm-nfnet')\nimport timm\n# import sys; \n# sys.path.insert(0,'..\/input\/timm-nfnet')\n# import timm","95edb898":"! pip install fastai==1.0.61","33e1c3b6":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import dataset, DataLoader\n\n# import torch\n# import torch.nn as nn\n# import torchvision\n# import torchvision.transforms as transforms\n# from torch.utils.data import Dataset, DataLoader","127379a6":"import pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname,filename))\n\nfrom pathlib import Path\nfrom fastai.vision import *\nfrom fastai.metrics import error_rate\nfrom PIL import Image\n\n# import pandas as pd \n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# from pathlib import Path\n\n# from fastai.vision import *\n# from fastai.metrics import error_rate\n\n# from PIL import Image","495b7a09":"inputs = Path(\"..\/input\/digit-recognizer\")\nos.listdir(inputs)\n# inputs=Path(\"..\/input\/digit-recognizer\")\n# os.listdir(inputs)","dc97716c":"# load training data and explore the first three rows\ntrain = pd.read_csv(inputs\/\"train.csv\")\ntrain.head(3)\n\n# train=pd.read_csv(inputs\/\"train.csv\")\n# train.head(3)","9169b005":"# load test data and explore the first three rows\ntest = pd.read_csv(inputs\/\"test.csv\")\ntest.head(3)\n\n# test=pd.read_csv(inputs\/\"test.csv\")\n# test.head(3)","6bec5bf4":"# tfms can be passed directly to define a DataBunch object (see below) which is then associated with a model to begin training.\ntfms = get_transforms(do_flip=False)\ntr = Path(\"..\/train\")\nte = Path(\"..\/test\")\n\n# tfms = get_transforms(do_flip=False) # if True the image is randomly flipped\n# tr=Path(\"..\/train\")\n# te=Path(\"..\/test\")","70f2bcec":"for index in range(10):\n    try:\n        os.makedirs(tr\/str(index))\n    except:\n        pass\n\n# for index in range(10):\n#     try:\n#         os.makedirs(tr\/str(index))\n#     except:\n#         pass","4affb9f7":"sorted(os.listdir(tr))\n# sorted(os.listdir(tr))","956ed7ba":"try:\n    os.makedirs(te)\nexcept:\n    pass\n# try:\n#     os.makedirs(te)\n# except:\n#     pass\n","634fbdf3":"for index, row in train.iterrows():\n    label,digit = row[0], row[1:]\n    filepath = tr\/str(label)\n    filename = f\"{index}.jpg\"\n    \n    digit = digit.values\n    digit = digit.reshape(28,28)\n    digit = digit.astype(np.uint8)\n    \n    img=Image.fromarray(digit)\n    img.save(filepath\/filename)\n\n\n# for index, row in train.iterrows():\n    \n#     label,digit = row[0], row[1:]\n    \n#     filepath = tr\/str(label)\n#     filename = f\"{index}.jpg\"\n    \n#     digit = digit.values\n#     digit = digit.reshape(28,28)\n#     digit = digit.astype(np.uint8)\n    \n#     img = Image.fromarray(digit)\n#     img.save(filepath\/filename)\n    \n    ","6f9b138f":"for index,digit in test.iterrows():\n    filepath = te\n    filename = f\"{index}.jpg\"\n    \n    digit = digit.values\n    digit = digit.reshape(28,28)\n    digit = digit.astype(np.uint8)\n    \n    img=Image.fromarray(digit)\n    img.save(filepath\/filename)\n\n# for index, digit in test.iterrows():\n\n#     filepath = te\n#     filename = f\"{index}.jpg\"\n    \n#     digit = digit.values\n#     digit = digit.reshape(28,28)\n#     digit = digit.astype(np.uint8)\n    \n#     img = Image.fromarray(digit)\n#     img.save(filepath\/filename)","22909e26":"def displayRandomImagesFromEveryFolder(directory=tr, samplesPerDigit=5):\n    fig = plt.figure(figsize=(5,10))\n    \n    for rowIndex in range(1,10):\n        subdirectory = str(rowIndex)\n        path = directory\/subdirectory\n        images = os.listdir(path)\n        \n        for sampleIndex in range(1,samplesPerDigit+1):\n            randomNumber = random.randint(0,len(images)-1)\n            image = Image.open(path\/images[randomNumber])\n            ax = fig.add_subplot(10,5,samplesPerDigit*rowIndex + sampleIndex)\n            ax.axis(\"off\")\n            \n            plt.imshow(image,cmap=\"gray\")\n        \n    plt.show()\ndisplayRandomImagesFromEveryFolder()\n\n# def displayRandomImagesFromEveryFolder(directory=tr, samplesPerDigit=5):\n\n#     fig = plt.figure(figsize=(5,10))\n    \n#     for rowIndex in range(1, 10):\n#         subdirectory = str(rowIndex)\n#         path = directory\/subdirectory\n#         images = os.listdir(path)\n#         for sampleIndex in range(1,samplesPerDigit+1):\n#             randomNumber = random.randint(0, len(images)-1)\n#             image = Image.open(path\/images[randomNumber])\n#             ax = fig.add_subplot(10, 5, samplesPerDigit*rowIndex + sampleIndex)\n#             ax.axis(\"off\")\n            \n#             plt.imshow(image, cmap='gray')\n            \n    \n#     plt.show()\n    \n# displayRandomImagesFromEveryFolder()","c597abfd":"data = ImageDataBunch.from_folder(path=\"..\/train\",test=\"..\/test\",ds_tfms=tfms,valid_pct=0.2,bs=32,size=24).normalize(imagenet_stats)\n# data = ImageDataBunch.from_folder(path=\"..\/train\",test=\"..\/test\",ds_tfms=tfms, valid_pct=0.2,bs=32,size=24).normalize(imagenet_stats)","43fe8847":"data.show_batch(rows=3,figsize=(5,5))\n# data.show_batch(rows=3 ,figsize=(5,5))","e9649d35":"print(data.classes)\n# print(data.classes)","8e1150e7":"class NFNetModel(nn.Module):\n    def __init__(self,num_classes=10,model_name=\"nfnet_f1\",pretrained=False):\n        super(NFNetModel,self).__init__()\n        self.model = timm.create_model(model_name,pretrained=pretrained)\n        self.model.head.fc = nn.Linear(self.model.head.fc.in_features,num_classes)\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\n# class NFNetModel(nn.Module):\n    \n#     def __init__(self, num_classes=10, model_name='nfnet_f1', pretrained=False):\n#         super(NFNetModel, self).__init__()\n#         self.model = timm.create_model(model_name, pretrained=pretrained)\n#         self.model.head.fc = nn.Linear(self.model.head.fc.in_features, num_classes)\n        \n#     def forward(self, x):\n#         x = self.model(x)\n#         return x","8f355d63":"model = NFNetModel()\n# model = NFNetModel()","fde67d37":"learn = Learner(data, model, metrics=accuracy)\n# learn = Learner(data, model, metrics=accuracy)","c4e1486e":"# find optimal learning rate and plot the graph\nlearn.lr_find()\n# learn.lr_find()\n# plot loss vs. learning rate\nlearn.recorder.plot()\n# learn.recorder.plot()","cab6bbaa":"learn.fit_one_cycle(10)\n# learn.fit_one_cycle(10)","2c4be3dc":"learn.save(\"501\")","1edfe8ff":"learn.unfreeze()\nlearn.fit_one_cycle(10,max_lr=1e-3)","ee9e4753":"learn.save(\"502\")","c4fa5e5a":"interp=ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix(figsize=(8,8))","a44b817e":"interp.most_confused(min_val=3)","93fce8c0":"interp.plot_top_losses(9,figsize=(7,7))","9583e1d3":"class_score,y=learn.get_preds(DatasetType.Test)","041dcaa5":"probs= class_score[0].tolist()\n[f\"{index}: {probs[index]}\" for index in range(len(probs))]","c4d0853d":"class_score=np.argmax(class_score,axis=1)","eaca9e5d":"class_score[0].item()","e31f6927":"samplesub=pd.read_csv(inputs\/\"sample_submission.csv\")\nsamplesub.head()","04896c18":"ImageId = [os.path.splitext(path)[0] for path in os.listdir(te)]\nImageId = [int(path) for path in ImageId]\nImageId = [ID+1 for ID in ImageId]\nImageId[:5]","ff7d05b4":"subs=pd.DataFrame({\"ImageId\":ImageId,\"Label\":class_score})","8aa944b6":"subs.to_csv(\"submission.csv\",index=False)\nsubs.head(3)","87eaf21f":"# *Please upvote the kernel if you find it useful*","1b12eee8":"# Read the train and test datasets:","d3b56b35":"**Now, let's try with the optimal learning rates:**","ff5ce3ea":"# What is Fastai?\n> Fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library.","40273c30":"# Importing the necessary libraries:","b2c5028b":"# Display images ","f9064152":"# Prediction","ea9a5186":"**Next, we can figure out what ideal learning rates are:**","f40af739":"**To get a set of transforms with default values that work pretty well in a wide range of tasks, it's often easiest to use get_transforms.**                                                                                                     \n* **tfms is just a parameter used later during training, which is initalized here.** \n* **tr and te are paths to be used.**","b342be3a":"# Submission\n\nNow, creating the submission file based on the example given (which should contain ImageId and Label):","baa5370c":"# NFNET Overview\n![ImageNet](https:\/\/miro.medium.com\/max\/1400\/1*CjpipU_oChc899f_Esjpyg.png)\n \nNFNET's are Convolutional Residual Style Networks that have no batch normalization build in them. But without the batch normalization usually networks are not performing so well or cannot scale to larger batch sizes however NFNET builds networks that scale to large batch sizes and are more efficient than previous state-of-the-art methods. The training latency vs accuracy graph shows that NFnets are 8.7\u00d7 times faster than EffNet-B7 for the same top-1 accuracy score trained on ImageNet. ","3cb10007":"**99% accuracy, not bad at all.**\n\n**Saving this model:**","0692dd51":"**The data has been successfully extracted from the folders.**\n\n**We can also check what classes exist:**","1f809213":"# Image transforms","c14aa32b":"**The dataset has been converted into images!**\n\n**We can move on to getting the data from folders, and seperating them into training and validation sets. Also normalization is very important to make sure all values lie between 0 and 1.**\n\n**It turns out that the PosixPath is not iterated by ImageDataBunch in Kaggle.So we can change the path created by pathlib library which was a PosixPath object to just a string which specifies the path to the training and testing directories, so in our case train path = \"..\/train\" and test path = \"..\/test\"**","b89685f1":"**These are the probabilities that the image is any of these numbers. But we don't want that. We only want the highest probability:**","d3e4d0f8":"**These are the images which had the highest loss, that is the biggest difference between the probability of being corect and actually being correct.**","f61b8309":"# Model \n\nNFNets are a family of modified ResNets that achieves competitive accuracies without batch normalization. To do so, it applies 3 different techniques:\n* Modified residual branches and convolutions with Scaled Weight Standardization\n* Adaptive Gradient Clipping\n* Architecture optimization for improved accuracy and training spee","0a0331bb":"# Results\n\n**We can interpret our results as well:**","a6ddf536":"**From this, we can see which two numbers are confused most and the number of times.**","8d3b633e":"# Prepare Data\n**Currently, it is not even an image, just a 0s and 1s, as seen from the training set. Using the functions below, we can convert them into images:**","6a1c0386":"**We can clearly see that the learning rate is most effective at 1e-03, but let's try without a predefined learning rate:**","2ed9c7d9":"**We have to try and get the dataset into a folder format, from the existing format, which will make it easier to use fastai's functions.**"}}