{"cell_type":{"f94b1b55":"code","48ac04ab":"code","adef36de":"markdown","47f6d8e7":"markdown"},"source":{"f94b1b55":"import numpy as np\n\ndef MeanAveragePrecision(predictions, retrieval_solution, max_predictions=100):\n    \"\"\"Computes mean average precision for retrieval prediction.\n    Args:\n        predictions: Dict mapping test image ID to a list of strings corresponding to index image IDs.\n        retrieval_solution: Dict mapping test image ID to list of ground-truth image IDs.\n        max_predictions: Maximum number of predictions per query to take into account. For the Google Landmark Retrieval challenge, this should be set to 100.\n    Returns:\n        mean_ap: Mean average precision score (float).\n    Raises:\n        ValueError: If a test image in `predictions` is not included in `retrieval_solutions`.\n    \"\"\"\n    # Compute number of test images.\n    num_test_images = len(retrieval_solution.keys())\n\n    # Loop over predictions for each query and compute mAP.\n    mean_ap = 0.0\n    for key, prediction in predictions.items():\n        if key not in retrieval_solution:\n            raise ValueError('Test image %s is not part of retrieval_solution' % key)\n\n        # Loop over predicted images, keeping track of those which were already\n        # used (duplicates are skipped).\n        ap = 0.0\n        already_predicted = set()\n        num_expected_retrieved = min(len(retrieval_solution[key]), max_predictions)\n        num_correct = 0\n        for i in range(min(len(prediction), max_predictions)):\n            if prediction[i] not in already_predicted:\n                if prediction[i] in retrieval_solution[key]:\n                    num_correct += 1\n                    ap += num_correct \/ (i + 1)\n                already_predicted.add(prediction[i])\n\n            ap \/= num_expected_retrieved\n            mean_ap += ap\n\n        mean_ap \/= num_test_images\n    return mean_ap\n","48ac04ab":"import pandas as pd\n\nPATH = '..\/input\/landmark-retrieval-2020\/'\n\n# Get labels (landmark ids) from train file as dict\nlabels = pd.read_csv(PATH+'train.csv', index_col='id')['landmark_id'].to_dict()\n\n# Check for this image id\nimage_id = '0000059611c7d079'\n\n# Dict mapping test image ID to a list of predicted strings corresponding to index image IDs.\npredictions = {image_id:['111e3a18bf0e529d', '3f5f7f38ea4dca61', '6cebd3221270bcc3', 'fb09f1e98c6d2f70']}\n\n# Dict mapping test image ID to list of ground-truth image IDs.\nretrieval_solution = {image_id: [k for k,v in labels.items() if v == labels[image_id]]}\n\nmap_score = MeanAveragePrecision(predictions, retrieval_solution)\nmap_score\n","adef36de":"# Using the code","47f6d8e7":"# Code for calculation\nMean average precision code from this link [https:\/\/github.com\/tensorflow\/models\/blob\/master\/research\/delf\/delf\/python\/google_landmarks_dataset\/metrics.py](http:\/\/)\n\n\n"}}