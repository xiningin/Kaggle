{"cell_type":{"a1181ba7":"code","789e9138":"code","02bdc6df":"code","d55a77be":"code","910cccc5":"code","e52add0c":"code","774a0aba":"code","5b9d6e83":"code","09a6efb8":"code","f8d43d73":"code","14b7001a":"code","5b503eca":"code","22bf16d0":"code","6a89753c":"code","8891c65b":"code","23ec1214":"code","64e40dde":"code","1a64b8d4":"code","757b587d":"code","105badfe":"code","e72d8d16":"code","2749bdef":"code","f520a266":"code","768329d7":"code","061b151c":"code","79d6f107":"code","6b8b6281":"markdown","5c885581":"markdown","0491dc3c":"markdown","e35b490a":"markdown","51b4cb6b":"markdown","1e08f1e7":"markdown","a17efb61":"markdown","32301b5d":"markdown","5a273551":"markdown","e89b8b27":"markdown","8588d0f3":"markdown","329914cd":"markdown","c9dfefe8":"markdown","3c48997f":"markdown","aaa3e5ae":"markdown","c525cdaa":"markdown"},"source":{"a1181ba7":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","789e9138":"from fastai import *\nfrom fastai.vision import *\nfrom fastai.metrics import *\nfrom fastai.data_block import *\nimport numpy as np\nimport pandas as pd\n\npath = Path(\"..\/input\/digit-recognizer\")","02bdc6df":"class CustomImageList(ImageList):\n    def open(self, fn):\n        img = fn.reshape(28,28)\n        img = np.stack((img,)*3, axis=-1)\n        return Image(pil2tensor(img, dtype=np.float32))\n    \n    @classmethod\n    def from_csv_custom(cls, path:PathOrStr, csv_name:str, imgIdx:int=1, header:str='infer', **kwargs)->'ItemList': \n        df = pd.read_csv(Path(path)\/csv_name, header=header)\n        res = super().from_df(df, path=path, cols=0, **kwargs)\n        \n        res.items = df.iloc[:,imgIdx:].apply(lambda x: x.values \/ 255.0, axis=1).values\n        \n        return res\n    \n    @classmethod\n    def from_df_custom(cls, path:PathOrStr, df:DataFrame, imgIdx:int=1, header:str='infer', **kwargs)->'ItemList': \n        res = super().from_df(df, path=path, cols=0, **kwargs)\n        \n        res.items = df.iloc[:,imgIdx:].apply(lambda x: x.values \/ 255.0, axis=1).values\n        \n        return res","d55a77be":"test = CustomImageList.from_csv_custom(path=path, csv_name=\"test.csv\", imgIdx=0)\ntest","910cccc5":"data = (CustomImageList.from_csv_custom(path=path, csv_name=\"train.csv\", imgIdx=1)\n        .split_by_rand_pct(0.2)\n        .label_from_df(cols='label')\n        .add_test(test, label=0)\n        .transform(get_transforms(do_flip=False))\n        .databunch(bs=128)\n        .normalize(imagenet_stats))","e52add0c":"data.show_batch(rows=3, figsize=(5,5))","774a0aba":"learn = cnn_learner(data, models.resnet18, metrics=accuracy, model_dir=\"\/kaggle\/working\/models\")\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","5b9d6e83":"learn.fit_one_cycle(1, max_lr=1e-02)","09a6efb8":"learn.save('mnist-resnet18-1')","f8d43d73":"learn.load('mnist-resnet18-1')","14b7001a":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","5b503eca":"max_lr = 1e-6\nlearn.fit_one_cycle(10, max_lr=max_lr)","22bf16d0":"learn.save('mnist-resnet18-2')","6a89753c":"learn = cnn_learner(data, models.resnet34, metrics=accuracy, model_dir=\"\/kaggle\/working\/models\").to_fp16()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","8891c65b":"learn.fit_one_cycle(1, max_lr=1e-02)","23ec1214":"learn.save('mnist-resnet34-fp16-1')","64e40dde":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","1a64b8d4":"learn.fit_one_cycle(6, max_lr=slice(1e-05, 1e-04))","757b587d":"learn.save('mnist-resnet34-fp16-2')","105badfe":"learn = cnn_learner(data, models.resnet50, metrics=accuracy, model_dir=\"\/kaggle\/working\/models\").to_fp16()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","e72d8d16":"learn.fit_one_cycle(1, max_lr=1e-02)","2749bdef":"learn.save('mnist-resnet50-fp16-1')","f520a266":"learn.unfreeze()\nlearn.lr_find()\nlearn.recorder.plot(suggestion=True)","768329d7":"learn.fit_one_cycle(6, max_lr=slice(1e-06, 1e-05))","061b151c":"learn = cnn_learner(data, models.resnet34, metrics=accuracy, model_dir=\"\/kaggle\/working\/models\").to_fp16().load('mnist-resnet34-fp16-2')","79d6f107":"predictions, *_ = learn.get_preds(DatasetType.Test)\nlabels = np.argmax(predictions, 1)\nsubmission_df = pd.DataFrame({'ImageId': list(range(1,len(labels)+1)), 'Label': labels})\nsubmission_df.to_csv(f'submission.csv', index=False)","6b8b6281":"Fine-tuning time! Let's unfreeze the backbone of the model see where our learning rate stands.","5c885581":"A little bit better from the get go. Let's save this first attempt, unfreeze and fine-tune.","0491dc3c":"# Resnet34 with mixed precision","e35b490a":"Let's see if we can do better with a larger resnet --resnet50.","51b4cb6b":"The last 2 epochs seemed to get it worse.","1e08f1e7":"# Resnet18","a17efb61":"We see that in the beginning, even though the training loss is similar to the latest stages of our resnet18, the validation loss is lower. This could mean our model generalizes better! Possibly due to both our net being larger on one side, but also because we used mixed precision training.","32301b5d":"This allows us to create a fastai DataBunch, which is an all-ready packaged data set, split into train and validation, with transforms attached, and everything ready to train.","5a273551":"Now that we have the databunch, we'll try training with a Resnet18 first.","e89b8b27":"Now we're ready to fit one cycle. We'll use 1e-02 as the learning rate, around there loss is still decreasing and continues to do so past 1e-01.","8588d0f3":"# Submitting results\nWe'll go back to our best model so far, the `resnet34-fp16`, and submit the results to the competition.","329914cd":"Let's try with a larger resnet (34), and using mixed precision training.","c9dfefe8":"It seems that we're doing worse than with resnet34. I'm not sure why, but I'd guess it's because it's too complex a model for the amount of data we have?","3c48997f":"# Resnet50 with mixed precision","aaa3e5ae":"97% accuracy just after one cycle, not bad! Keep in mind we only trained the latest layer (the head) so far -- now we should unfreeze the backbone of the model (pretrained on Imagenet) to fine-tune the earlier layers too.","c525cdaa":"# Preprocessing the data\nWe take the custom image list detailed in [this kernel](https:\/\/www.kaggle.com\/tanlikesmath\/oversampling-mnist-with-fastai)."}}