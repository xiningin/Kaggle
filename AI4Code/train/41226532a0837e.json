{"cell_type":{"afb3f4b9":"code","4de9916e":"code","87e564cd":"code","25a831a6":"code","d3e76b24":"code","30f54c17":"code","eeb328f7":"code","36a2befb":"code","6adc5a71":"code","651ec807":"code","da8df0e8":"code","d3094b5b":"code","77349b29":"code","044149e7":"code","4084be77":"code","557243fd":"code","9480d7b2":"code","25124a77":"code","99093db1":"code","4b8e4d77":"code","b1753523":"code","4d9e9e13":"code","5a13797a":"code","b2aca07a":"markdown","f65fcec1":"markdown","0278f7e9":"markdown","54772f5f":"markdown","b4fb679a":"markdown","3ba893a3":"markdown","a576ec76":"markdown","aff0c7c9":"markdown"},"source":{"afb3f4b9":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nimport matplotlib.pyplot as rc\nimport torch\nfrom torch.optim import AdamW\nfrom transformers import get_linear_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nfrom transformers import BertModel, BertConfig, BertTokenizer\nfrom torch import nn\nfrom torch.utils import data\nfrom torch.utils.data import Dataset, DataLoader\ndevice = 'cuda'\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\nHAPPY_COLORS_PALETTE = [\"#01BEFE\",\"#FFDD00\",\"#FF7D00\",\"#FF006D\",\"#ADFF02\",\"#8F00FF\"]\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\nrcParams['figure.figsize'] = 12, 8\nnp.random.seed(42)\ntorch.manual_seed(42)","4de9916e":"df = pd.read_csv(\"..\/input\/sentiment-analysis-datasetgoogle-play-app-reviews\/sentiment-analysis-dataset-google-play-app-reviews.csv\")\ndf.head()","87e564cd":"df.shape","25a831a6":"df.info()","d3e76b24":"sns.countplot(df.score)\nplt.xlabel('review score');","30f54c17":"def to_sentiment(rating):\n  rating = int(rating)\n  if rating <= 2:\n    return 0\n  elif rating == 3:\n    return 1\n  else: \n    return 2\n\ndf['sentiment'] = df.score.apply(to_sentiment)","eeb328f7":"class_names = ['negative', 'neutral', 'positive']\nax = sns.countplot(df.sentiment)\nplt.xlabel('review sentiment')\nax.set_xticklabels(class_names);","36a2befb":"PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\ntokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)","6adc5a71":"token_lens = []\nfor txt in df.content:\n    tokens = tokenizer.encode(txt, max_length=512, truncation=True)\n    token_lens.append(len(tokens))","651ec807":"sns.distplot(token_lens)\nplt.xlim([0, 256]);\nplt.xlabel('Token count');","da8df0e8":"MAX_LEN = 160","d3094b5b":"class GPReviewDataset(Dataset):\n    def __init__(self, reviews, targets, tokenizer, max_len):\n        self.reviews = reviews\n        self.targets = targets\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n  \n    def __len__(self):\n        return len(self.reviews)\n\n    def __getitem__(self, item):\n        review = str(self.reviews[item])\n        target = self.targets[item]\n\n        encoding = self.tokenizer.encode_plus(\n          review,\n          add_special_tokens=True,\n          max_length=self.max_len,\n          truncation=True,\n          return_token_type_ids=False,\n          pad_to_max_length=True,\n          return_attention_mask=True,\n          return_tensors='pt',\n        )\n\n        return {\n          'review_text': review,\n          'input_ids': encoding['input_ids'].flatten(),\n          'attention_mask': encoding['attention_mask'].flatten(),\n          'targets': torch.tensor(target, dtype=torch.long)\n        }","77349b29":"df_train, df_test = train_test_split(df, test_size=0.1, random_state=42)\ndf_val, df_test = train_test_split(df_test, test_size=0.5, random_state=42)","044149e7":"df_train.shape, df_val.shape, df_test.shape","4084be77":"def create_data_loader(df, tokenizer, max_len, batch_size):\n  ds = GPReviewDataset(\n    reviews=df.content.to_numpy(),\n    targets=df.sentiment.to_numpy(),\n    tokenizer=tokenizer,\n    max_len=max_len\n  )\n\n  return DataLoader(\n    ds,\n    batch_size=batch_size,\n    num_workers=4\n  )","557243fd":"BATCH_SIZE = 16\n\ntrain_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\nval_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\ntest_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)","9480d7b2":"class SentimentClassifier(nn.Module):\n    def __init__(self, n_classes):\n        super(SentimentClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n        self.drop = nn.Dropout(p=0.3)\n        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n  \n    def forward(self, input_ids, attention_mask):\n        _, pooled_output = self.bert(\n              input_ids=input_ids,\n              attention_mask=attention_mask\n            )\n        output = self.drop(pooled_output)\n        return self.out(output)","25124a77":"model = SentimentClassifier(len(class_names))\nmodel = model.to(device)","99093db1":"EPOCHS = 50\n\noptimizer = AdamW(model.parameters(), lr=2e-5)\ntotal_steps = len(train_data_loader) * EPOCHS\n\nscheduler = get_linear_schedule_with_warmup(\n  optimizer,\n  num_warmup_steps=0,\n  num_training_steps=total_steps\n)\n\nloss_fn = nn.CrossEntropyLoss().to(device)","4b8e4d77":"def train_epoch(model,data_loader,loss_fn,optimizer,device,scheduler,n_examples):\n    model = model.train()\n\n    losses = []\n    correct_predictions = 0\n  \n    for d in data_loader:\n        input_ids = d[\"input_ids\"].to(device)\n        attention_mask = d[\"attention_mask\"].to(device)\n        targets = d[\"targets\"].to(device)\n\n        outputs = model(\n          input_ids=input_ids,\n          attention_mask=attention_mask\n        )\n\n        _, preds = torch.max(outputs, dim=1)\n        loss = loss_fn(outputs, targets)\n\n        correct_predictions += torch.sum(preds == targets)\n        losses.append(loss.item())\n    \n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n\n    return correct_predictions.double() \/ n_examples, np.mean(losses)","b1753523":"def eval_model(model, data_loader, loss_fn, device, n_examples):\n    model = model.eval()\n\n    losses = []\n    correct_predictions = 0\n\n    with torch.no_grad():\n        for d in data_loader:\n            input_ids = d[\"input_ids\"].to(device)\n            attention_mask = d[\"attention_mask\"].to(device)\n            targets = d[\"targets\"].to(device)\n\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask\n              )\n            _, preds = torch.max(outputs, dim=1)\n\n            loss = loss_fn(outputs, targets)\n\n            correct_predictions += torch.sum(preds == targets)\n            losses.append(loss.item())\n\n    return correct_predictions.double() \/ n_examples, np.mean(losses)","4d9e9e13":"%%time\nfrom collections import defaultdict\nhistory = defaultdict(list)\nbest_accuracy = 0\n\nfor epoch in range(EPOCHS):\n    print(f'Epoch {epoch + 1}\/{EPOCHS}')\n    print('-' * 10)\n\n    train_acc, train_loss = train_epoch(\n        model,\n        train_data_loader,    \n        loss_fn, \n        optimizer, \n        device, \n        scheduler, \n        len(df_train)\n      )\n\n    print(f'Train loss {train_loss} accuracy {train_acc}')\n\n    val_acc, val_loss = eval_model(\n        model,\n        val_data_loader,\n        loss_fn, \n        device, \n        len(df_val)\n      )\n\n    print(f'Val   loss {val_loss} accuracy {val_acc}')\n    print()\n\n    history['train_acc'].append(train_acc)\n    history['train_loss'].append(train_loss)\n    history['val_acc'].append(val_acc)\n    history['val_loss'].append(val_loss)\n\n    if val_acc > best_accuracy:\n        torch.save(model.state_dict(), 'best_model_state.bin')\n        best_accuracy = val_acc","5a13797a":"plt.plot(history['train_acc'], label='train accuracy')\nplt.plot(history['val_acc'], label='validation accuracy')\n\nplt.title('Training history')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.ylim([0, 1]);","b2aca07a":"### Special Tokens\n\n`[SEP]` - marker for ending of a sentence\n\n`[CLS]` - we must add this token to the start of each sentence, so BERT knows we're doing classification\n\n`[PAD]` - special token for padding\n\n BERT understands tokens that were in the training set. Everything else can be encoded using the `[UNK]` (unknown) token:","f65fcec1":"Great, no missing values in the score and review texts! Do we have class imbalance?","0278f7e9":"### Training","54772f5f":"### Choosing Sequence Length\n\nBERT works with fixed-length sequences. We'll use a simple strategy to choose the max length. Let's store the token length of each review:","b4fb679a":"#  **Data Preprocessing**","3ba893a3":"Most of the reviews seem to contain less than 128 tokens, but we'll be on the safe side and choose a maximum length of 160.","a576ec76":"You might already know that Machine Learning models don't work with raw text. You need to convert text to numbers (of some sort). BERT requires even more attention (good one, right?). Here are the requirements:\n\n1- Add special tokens to separate sentences and do classification\n\n2- Pass sequences of constant length (introduce padding)\n\n3- Create array of 0s (pad token) and 1s (real token) called attention mask\n\nThe Transformers library provides (you've guessed it) a wide variety of Transformer models (including BERT). It works with TensorFlow and PyTorch! It also includes prebuild tokenizers that do the heavy lifting for us!","aff0c7c9":"That's hugely imbalanced, but it's okay. We're going to convert the dataset into negative, neutral and positive sentiment:"}}