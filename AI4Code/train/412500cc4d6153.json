{"cell_type":{"3fe61eb9":"code","b869f000":"code","0aacd26e":"code","b809d60f":"code","386b1f24":"code","12ad85ba":"code","9ef1295c":"code","624dc29a":"code","0700972f":"code","2347aea0":"markdown","291d630c":"markdown","9420c4b1":"markdown","8993c0e3":"markdown","fd61f0d4":"markdown","c275123d":"markdown"},"source":{"3fe61eb9":"%matplotlib inline\n%config InlineBackend.figure_formats = {'png', 'retina'}\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\nimport numpy as np\nimport seaborn as sns\n\nfrom sklearn import cluster, datasets\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.decomposition import PCA\n\n#from scipy.cluster import hierarchy, dendrogram, linkage\nfrom scipy.spatial import ConvexHull\n\n#from adjustText import adjust_text\nfrom collections import defaultdict\n\nstyle.use('seaborn-poster') #sets the size of the charts\nstyle.use('ggplot')","b869f000":"players_df_full = pd.read_csv(\"\/kaggle\/input\/laliga-players-stats-2019\/LaLiga.csv\")\nplayers_df_full.set_index('name', inplace=True, drop=True)\nplayers_df_full.drop_duplicates(inplace=True)\nplayers_df_full.head()","0aacd26e":"# Filter by players who played the most. Remove goalkeepers\nplayers_df = players_df_full.copy()\n\n# Create a new feature \"main position\"\ndef main_position_func(position):\n    main_positions_dic = {\n        'F': 'Forward',\n        'A': 'Attacker',\n        'M': 'Midfielder',\n        'D': 'Defender',\n        'G': 'GoalKeeper',\n        'S': 'Subsitute',\n    }\n    return main_positions_dic[position.strip()[0]]\n\nplayers_df['position'] = players_df['position'].map(main_position_func)\n\n# Remove players who have not played in the top 20%. But leave Messi just in case...\nplayers_df = players_df[(players_df.minsPlayed > players_df.minsPlayed.quantile(0.80)) | (players_df.index == 'Lionel Messi')]\n\n# Remove features we don't need\nplayers_df.drop(columns=['league_name', 'team_name', 'flag', 'full_time', 'half_time', 'rating', 'passSuccess_y', 'shotsPerGame_y'], \n                             axis=1,\n                             inplace=True)\n\nplayers_df.head()","b809d60f":"scaled_features = StandardScaler().fit_transform(players_df.drop('position', axis=1))\nplayers_df_scaled = pd.DataFrame(scaled_features, index=players_df.drop('position', axis=1).index, columns=players_df.drop('position', axis=1).columns)\n\nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 6))\n\nax1.set_facecolor('#E8E8F1')\nax2.set_facecolor('#E8E8F1')\n\nax1.set_title('Before scaling')\nsns.kdeplot(players_df['tall'], ax=ax1)\nsns.kdeplot(players_df['passSuccess_x'], ax=ax1)\nsns.kdeplot(players_df['goals'], ax=ax1)\nax2.set_title('After scaling')\nsns.kdeplot(players_df_scaled['tall'], ax=ax2)\nsns.kdeplot(players_df_scaled['passSuccess_x'], ax=ax2)\nsns.kdeplot(players_df_scaled['goals'], ax=ax2)\nplt.show()\n","386b1f24":"# https:\/\/towardsdatascience.com\/better-heatmaps-and-correlation-matrix-plots-in-python-41445d0f2bec\ndef heatmap(x, y, **kwargs):\n    if 'color' in kwargs:\n        color = kwargs['color']\n    else:\n        color = [1]*len(x)\n\n    if 'palette' in kwargs:\n        palette = kwargs['palette']\n        n_colors = len(palette)\n    else:\n        n_colors = 256 # Use 256 colors for the diverging color palette\n        palette = sns.color_palette(\"Blues\", n_colors) \n\n    if 'color_range' in kwargs:\n        color_min, color_max = kwargs['color_range']\n    else:\n        color_min, color_max = min(color), max(color) # Range of values that will be mapped to the palette, i.e. min and max possible correlation\n\n    def value_to_color(val):\n        if color_min == color_max:\n            return palette[-1]\n        else:\n            val_position = float((val - color_min)) \/ (color_max - color_min) # position of value in the input range, relative to the length of the input range\n            val_position = min(max(val_position, 0), 1) # bound the position betwen 0 and 1\n            ind = int(val_position * (n_colors - 1)) # target index in the color palette\n            return palette[ind]\n\n    if 'size' in kwargs:\n        size = kwargs['size']\n    else:\n        size = [1]*len(x)\n\n    if 'size_range' in kwargs:\n        size_min, size_max = kwargs['size_range'][0], kwargs['size_range'][1]\n    else:\n        size_min, size_max = min(size), max(size)\n\n    size_scale = kwargs.get('size_scale', 500)\n\n    def value_to_size(val):\n        if size_min == size_max:\n            return 1 * size_scale\n        else:\n            val_position = (val - size_min) * 0.99 \/ (size_max - size_min) + 0.01 # position of value in the input range, relative to the length of the input range\n            val_position = min(max(val_position, 0), 1) # bound the position betwen 0 and 1\n            return val_position * size_scale\n    if 'x_order' in kwargs: \n        x_names = [t for t in kwargs['x_order']]\n    else:\n        x_names = [t for t in sorted(set([v for v in x]))]\n    x_to_num = {p[1]:p[0] for p in enumerate(x_names)}\n\n    if 'y_order' in kwargs: \n        y_names = [t for t in kwargs['y_order']]\n    else:\n        y_names = [t for t in sorted(set([v for v in y]))]\n    y_to_num = {p[1]:p[0] for p in enumerate(y_names)}\n\n    plot_grid = plt.GridSpec(1, 15, hspace=0.2, wspace=0.1) # Setup a 1x10 grid\n    ax = plt.subplot(plot_grid[:,:-1]) # Use the left 14\/15ths of the grid for the main plot\n\n    marker = kwargs.get('marker', 's')\n\n    kwargs_pass_on = {k:v for k,v in kwargs.items() if k not in [\n         'color', 'palette', 'color_range', 'size', 'size_range', 'size_scale', 'marker', 'x_order', 'y_order'\n    ]}\n\n    ax.scatter(\n        x=[x_to_num[v] for v in x],\n        y=[y_to_num[v] for v in y],\n        marker=marker,\n        s=[value_to_size(v) for v in size], \n        c=[value_to_color(v) for v in color],\n        **kwargs_pass_on\n    )\n    ax.set_xticks([v for k,v in x_to_num.items()])\n    ax.set_xticklabels([k for k in x_to_num], rotation=45, horizontalalignment='right', fontsize=12)\n    ax.set_yticks([v for k,v in y_to_num.items()])\n    ax.set_yticklabels([k for k in y_to_num], fontsize=12)\n\n    ax.grid(False, 'major')\n    ax.grid(True, 'minor')\n    ax.set_xticks([t + 0.5 for t in ax.get_xticks()], minor=True)\n    ax.set_yticks([t + 0.5 for t in ax.get_yticks()], minor=True)\n\n    ax.set_xlim([-0.5, max([v for v in x_to_num.values()]) + 0.5])\n    ax.set_ylim([-0.5, max([v for v in y_to_num.values()]) + 0.5])\n    ax.set_facecolor('#F1F1F1')\n\n    # Add color legend on the right side of the plot\n    if color_min < color_max:\n        ax = plt.subplot(plot_grid[:,-1]) # Use the rightmost column of the plot\n\n        col_x = [0]*len(palette) # Fixed x coordinate for the bars\n        bar_y=np.linspace(color_min, color_max, n_colors) # y coordinates for each of the n_colors bars\n\n        bar_height = bar_y[1] - bar_y[0]\n        ax.barh(\n            y=bar_y,\n            width=[5]*len(palette), # Make bars 5 units wide\n            left=col_x, # Make bars start at 0\n            height=bar_height,\n            color=palette,\n            linewidth=0\n        )\n        ax.set_xlim(1, 2) # Bars are going from 0 to 5, so lets crop the plot somewhere in the middle\n        ax.grid(False) # Hide grid\n        ax.set_facecolor('white') # Make background white\n        ax.set_xticks([]) # Remove horizontal ticks\n        ax.set_yticks(np.linspace(min(bar_y), max(bar_y), 3)) # Show vertical ticks for min, middle and max\n        ax.yaxis.tick_right() # Show vertical ticks on the right \n\n\ndef corrplot(data, size_scale=500, marker='s'):\n    corr = pd.melt(data.reset_index(), id_vars='index')\n    corr.columns = ['x', 'y', 'value']\n    heatmap(\n        corr['x'], corr['y'],\n        color=corr['value'], color_range=[-1, 1],\n        palette=sns.diverging_palette(20, 220, n=256),\n        size=corr['value'].abs(), size_range=[0,1],\n        marker=marker,\n        x_order=data.columns,\n        y_order=data.columns[::-1],\n        size_scale=size_scale\n    )\n\n\nplt.figure(figsize=(10, 10))\ncorr = players_df_scaled.corr()\ncorrplot(corr)","12ad85ba":"# https:\/\/towardsdatascience.com\/pca-using-python-scikit-learn-e653f8989e60\n\n# Create features PC1 and PC2 using PCA\nfeatures_pca = PCA(n_components = 2).fit_transform(players_df_scaled)\nprincipal_df = pd.DataFrame(features_pca, index=players_df_scaled.index, columns=[\"PC1\", \"PC2\"])\n\n# Plotting \nfig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15, 8))\n\nax1.set_facecolor('#E8E8F1')\nax2.set_facecolor('#E8E8F1')\n\nax1.set_xlabel('CP1', fontsize=18)\nax1.set_ylabel('CP2', fontsize=18)\nax2.set_xlabel('CP1', fontsize=18)\nax2.set_ylabel('CP2', fontsize=18)\n\npos_colors = {\n    'GoalKeeper': 'black', \n    'Defender': 'red',\n    'Midfielder': 'yellow',\n    'Attacker': 'green',\n    'Forward': 'green'\n}\n\nax1.scatter(principal_df['PC1'], principal_df['PC2'], marker='o', s=50, alpha=0.5, cmap='viridis')\nax2.scatter(principal_df['PC1'], principal_df['PC2'], c=players_df['position'].apply(lambda x: pos_colors[x]), marker='o', s=50, alpha=0.5, cmap='viridis')\n\ntexts = [plt.text(principal_df['PC1'][name], principal_df['PC2'][name], name) for name in principal_df.index]\n#adjust_text(texts, arrowprops=dict(arrowstyle='->', color='#999999'))\n\nplt.tight_layout()\nplt.show()\n\n","9ef1295c":"sum_of_squared_distances = []\nK = range(1,15)\nfor k in K:\n    km = cluster.KMeans(n_clusters=k)\n    km = km.fit(principal_df)\n    sum_of_squared_distances.append(km.inertia_)\n    \nplt.figure(figsize=(10, 10))\nax = plt.axes()\nplt.xlabel('Clusters ', fontsize=18)\nplt.ylabel('Suma de distancias cuadradas', fontsize=18)\nax.set_facecolor('#E8E8F1')\n\nplt.plot(K, sum_of_squared_distances, linestyle='--', color='blue', marker='X')\n\nplt.show()","624dc29a":"# Create clusters\nn_clusters = 5\nkmeans = cluster.KMeans(n_clusters)\ny_kmeans = kmeans.fit_predict(principal_df)\n\n# Draw clusters\nplt.figure(figsize=(10, 10))\nax = plt.axes()\nax.set_facecolor('#E8E8F1')\nplt.xlabel('CP1', fontsize=18)\nplt.ylabel('CP2', fontsize=18)\n\n#y_kmeans = kmeans.predict(df.drop('name', axis=1))\n\npos_colors = {\n    'GoalKeeper': 'black', \n    'Defender': 'red',\n    'Midfielder': 'yellow',\n    'Attacker': 'green',\n    'Forward': 'green'\n}\nplt.scatter(principal_df['PC1'], principal_df['PC2'], marker='o', c=players_df['position'].apply(lambda x: pos_colors[x]), cmap=\"Paired\", s=50, alpha=0.5)\n\n# Draw centers\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], marker='o', c='#999999', s=500, alpha=0.7)\n\ntexts = [plt.text(principal_df['PC1'][name], principal_df['PC2'][name], name) for name in principal_df['PC1'].index]\n#adjust_text(texts, arrowprops=dict(arrowstyle='->', color='#999999'))\n\n# Draw poligons around clusters\n# https:\/\/www.machinelearningplus.com\/plots\/top-50-matplotlib-visualizations-the-master-plots-python\/\ndef encircle(x,y, ax=None, **kw):\n    if not ax: ax=plt.gca()\n    p = np.c_[x,y]\n    hull = ConvexHull(p)\n    poly = plt.Polygon(p[hull.vertices,:], **kw)\n    ax.add_patch(poly)\n\n\n# Draw polygon surrounding vertices\ncolors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\nfor i in y_kmeans:\n    encircle(principal_df.loc[kmeans.labels_ == i, 'PC1'], principal_df.loc[kmeans.labels_ == i, 'PC2'], ec=\"k\", fc=colors[i], alpha=0.02, linewidth=0)","0700972f":"from scipy.cluster import hierarchy\n\n# Create clusters\nn_clusters = 5\nclusters = cluster.AgglomerativeClustering(n_clusters, affinity='euclidean', linkage='ward')\npred = clusters.fit_predict(principal_df)\n\n# Draw clusters with dendrogram\nplt.figure(figsize=(20, 20))\nax = plt.axes()\nax.grid(False)\nax.set_facecolor('#E8E8F1')\n\n# Calculate the distance between each sample\nZ = hierarchy.linkage(principal_df, 'ward')\n\n\ncolors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n\n\nhierarchy.set_link_color_palette(colors)\n\ndend = hierarchy.dendrogram(Z, \n                            color_threshold=n_clusters, \n                            orientation=\"left\", \n                            labels=principal_df.index,\n                            above_threshold_color=\"grey\"\n                         )\n\n# Helpers\n# http:\/\/datanongrata.com\/2019\/04\/27\/67\/\ndef get_cluster_classes(den, label='ivl'):\n    cluster_idxs = defaultdict(list)\n    for c, pi in zip(den['color_list'], den['icoord']):\n        for leg in pi[1:3]:\n            i = (leg - 5.0) \/ 10.0\n            if abs(i - int(i)) < 1e-5:\n                cluster_idxs[c].append(int(i))\n    \n    cluster_classes = {}\n    for c, l in cluster_idxs.items():\n        i_l = [den[label][i] for i in l]\n        cluster_classes[c] = i_l\n    \n    return cluster_classes\n\ndef get_key_from_item(dictionary, item):\n    for key, items in dictionary.items():    \n        if item in items:\n            return key\n\n        \ncolor_clusters = get_cluster_classes(dend)\n\n# Apply the right color to each label\nax = plt.gca()\nxlbls = ax.get_ymajorticklabels()\ncolors_ordered = []\nfor i, lbl in enumerate(xlbls):\n    lbl.set_color(get_key_from_item(color_clusters, lbl.get_text()))\n","2347aea0":"# Simplifying the features","291d630c":"## Scaling\nBefore building the model, we need to scale and normalize our data.","9420c4b1":"# Agglomerative Hierarchical Clustering","8993c0e3":"## Correlation Matrix\nWith the features selected, the first thing we'll do is run a correlation matrix to see if we see any interesting correlation. This will also help us see if our data \"seems\" ok, since some correlations should be very obvious. ","fd61f0d4":"# Clustering\nTo determine the best number of clusters we'll use the elbow method. ","c275123d":"## Data cleansing\n\n**Remove features**: There are lots of different features on each player, but we don't want to use all of them since they may be irrelevant for our goal. For example, the number of games played or player's age are not features that we would like to be used for our segmentation.  \n\n**Feature extraction**: We can infere some features based on others.\n\n**Subsetting data**: There are too many players in LaLiga for our purpose hereso we'll only work with the most *interesting* players, defining interesting as the players who played the most. We'll set the threshold on the 80% percentile"}}