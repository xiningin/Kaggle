{"cell_type":{"eb20cfc4":"code","4d6c0e94":"code","59ea9a2a":"code","f9b9bde8":"code","1ad3c110":"code","dfb2c328":"code","78d09f56":"code","7e12333f":"code","56710517":"code","16d1fe34":"code","e94d1302":"code","e6b33c40":"code","33d6ada5":"code","cf3e3111":"code","a22390c6":"code","2b69e57f":"code","d5c90e12":"code","c6bc38ed":"code","210fcb05":"code","38a247f0":"code","e6ca951d":"code","b47ba83b":"code","51cca493":"code","98027868":"code","bee8d16d":"code","217cf5e1":"code","f16784e0":"code","3cd9baea":"code","9a9e0df4":"code","8358dcbc":"code","0b292fc9":"code","60c20e5f":"code","b064091b":"code","a908bada":"code","5b68a69a":"code","d0eb05d2":"code","1d0b6bcf":"code","170fbe89":"code","dbac4076":"code","f6422abf":"code","b4f0fd9c":"code","a7abfeda":"code","b88ea8e9":"code","e187dee3":"code","70deda06":"code","7177f146":"code","d7ccfcb3":"code","ff65688b":"code","df13abb8":"code","288bf525":"code","81c5da5e":"code","4ca60fe2":"markdown","0ac1a721":"markdown","6e9455b4":"markdown","ead1b8a3":"markdown","524bbc26":"markdown","87822aa9":"markdown","7c84175e":"markdown","32dc80a4":"markdown","861132d3":"markdown","ba5320d9":"markdown","eb8f2309":"markdown","83f6756c":"markdown","78f7302d":"markdown","abd8223d":"markdown","c62d4e0d":"markdown","acd96e80":"markdown","09ba4674":"markdown","fbb3e4c6":"markdown","ee3774fa":"markdown","9970b783":"markdown","457a1f51":"markdown"},"source":{"eb20cfc4":"!rm .\/*.hdf5","4d6c0e94":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mimg\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.metrics import confusion_matrix\n\nimport cv2\nimport os\nimport glob","59ea9a2a":"# Input data files are available in the \"..\/input\/\" directory.\nINPUT_PATH = \"..\/input\/pneumonia-detection\/chest_xray\"\n\n# List the files in the input directory.\nprint(os.listdir(INPUT_PATH))","f9b9bde8":"base_dir = INPUT_PATH\ntrain_dir = os.path.join(base_dir, 'train')\nval_dir = os.path.join(base_dir, 'val')\ntest_dir = os.path.join(base_dir, 'test')\n\ntrain_0_dir = os.path.join(train_dir, 'Normal'.upper())\ntrain_1_dir = os.path.join(train_dir, 'Pneumonia'.upper())\n\nval_0_dir = os.path.join(val_dir, 'Normal'.upper())\nval_1_dir = os.path.join(val_dir, 'Pneumonia'.upper())\n\ntest_0_dir = os.path.join(test_dir, 'Normal'.upper())\ntest_1_dir = os.path.join(test_dir, 'Pneumonia'.upper())\n\ndef get_data_list():\n    train_0_list = [os.path.join(train_0_dir, fn) for fn in os.listdir(train_0_dir)]\n    train_1_list = [os.path.join(train_1_dir, fn) for fn in os.listdir(train_1_dir)]\n    val_0_list = [os.path.join(val_0_dir, fn) for fn in os.listdir(val_0_dir)]\n    val_1_list = [os.path.join(val_1_dir, fn) for fn in os.listdir(val_1_dir)]\n    test_0_list = [os.path.join(test_0_dir, fn) for fn in os.listdir(test_0_dir)]\n    test_1_list = [os.path.join(test_1_dir, fn) for fn in os.listdir(test_1_dir)]\n\n    # list dir numbers\n    print('total picture numbers in train_0_dir: ', len(train_0_list))\n    print('total picture numbers in train_1_dir: ', len(train_1_list))\n    print('total picture numbers in val_0_dir: ', len(val_0_list))\n    print('total picture numbers in val_1_dir: ', len(val_1_list))\n    print('total picture numbers in test_0_dir: ', len(test_0_list))\n    print('total picture numbers in test_1_dir: ', len(test_1_list))\n\n    return (train_0_list, train_1_list, val_0_list, val_1_list, test_0_list, test_1_list)","1ad3c110":"(train_0_list, train_1_list, val_0_list, val_1_list, test_0_list, test_1_list) = get_data_list()","dfb2c328":"import random \n(mv_cnt_0, mv_cnt_1) = (300, 300)\n\nif len(val_0_list) < mv_cnt_0:\n    mv_list_0 = random.sample(train_0_list, mv_cnt_0)\n    mv_list_1 = random.sample(train_1_list, mv_cnt_1)\n    train_0_list = [fn for fn in train_0_list if not fn in mv_list_0]\n    train_1_list = [fn for fn in train_1_list if not fn in mv_list_1]\n    val_0_list += mv_list_0\n    val_1_list += mv_list_1\n    \n    print('total picture numbers in train_0_dir: ', len(train_0_list))\n    print('total picture numbers in train_1_dir: ', len(train_1_list))\n    print('total picture numbers in val_0_dir: ', len(val_0_list))\n    print('total picture numbers in val_1_dir: ', len(val_1_list))\n    print('total picture numbers in test_0_dir: ', len(test_0_list))\n    print('total picture numbers in test_1_dir: ', len(test_1_list))","78d09f56":"(left, top) = (15, 40)\n(y1, y2, x1, x2) = (top,top+200, left,left+200)\ndef image_resize(img_path):\n    # print(dataset.shape)\n    \n    im = cv2.imread(img_path)\n    im = cv2.resize(im, (224,224))\n    if im.shape[2] == 1:\n        # np.dstack(): Stack arrays in sequence depth-wise (along third axis).\n        # https:\/\/docs.scipy.org\/doc\/numpy\/reference\/generated\/numpy.dstack.html\n        im = np.dstack([im, im, im])\n        \n        # ----------------------------------------------------------------------------------------\n        # cv2.cvtColor(): The function converts an input image from one color space to another. \n        # [Ref.1]: \"cvtColor - OpenCV Documentation\"\n        #     - https:\/\/docs.opencv.org\/2.4\/modules\/imgproc\/doc\/miscellaneous_transformations.html\n        # [Ref.2]: \"Python\u8ba1\u7b97\u673a\u89c6\u89c9\u7f16\u7a0b- \u7b2c\u5341\u7ae0 OpenCV\" \n        #     - https:\/\/yongyuan.name\/pcvwithpython\/chapter10.html\n        # ----------------------------------------------------------------------------------------\n    x_image = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n    x_image = x_image[y1:y2, x1:x2]\n    x_image = cv2.resize(x_image, (150,150))\n    # Normalization\n    # x_image = x_image.astype(np.float32)\/255.\n    return x_image","7e12333f":"import matplotlib.pyplot as plt\nimport matplotlib.image as mimg\n%matplotlib inline\nimport cv2\nimport numpy as np","56710517":"fn_list_0 = train_0_list[:4]\nfn_list_1 = train_1_list[:4]\n\nfig, ax = plt.subplots(2, 4, figsize=(20,10))\nfor i, axi in enumerate(ax.flat):\n    img_path = None\n    if i < 4:\n        img_path = fn_list_0[i]\n    else:\n        img_path = fn_list_1[i-4]\n    img = image_resize(img_path)#.astype(np.uint8)\n    axi.imshow(img, cmap='bone')\n    axi.set_title(img_path.split('\/')[-1])\n    axi.set(xticks=[], yticks=[])","16d1fe34":"def create_dataset(img_path_list_0, img_path_list_1, return_fn = False):\n    # list of the paths of all the image files\n    normal = img_path_list_0\n    pneumonia = img_path_list_1\n\n    # --------------------------------------------------------------\n    # Data-paths' format in (img_path, label) \n    # labels : for [ Normal cases = 0 ] & [ Pneumonia cases = 1 ]\n    # --------------------------------------------------------------\n    normal_data = [(image, 0) for image in normal]\n    pneumonia_data = [(image, 1) for image in pneumonia]\n\n    image_data = normal_data + pneumonia_data\n\n    # Get a pandas dataframe for the data paths \n    image_data = pd.DataFrame(image_data, columns=['image', 'label'])\n#     print(image_data.head(5))\n    # Shuffle the data \n    image_data = image_data.sample(frac=1., random_state=100).reset_index(drop=True)\n    \n    # Importing both image & label datasets...\n    (x_images, y_labels) = ([image_resize(image_data.iloc[i][0]) for i in range(len(image_data))], \n                         [image_data.iloc[i][1] for i in range(len(image_data))])\n\n    # Convert the list into numpy arrays\n    x_images = np.array(x_images)\n    y_labels = np.array(y_labels)\n    \n    print(\"Total number of images: \", x_images.shape)\n    print(\"Total number of labels: \", y_labels.shape)\n    \n    if not return_fn:\n        return (x_images, y_labels)\n    else:\n        return (x_images, y_labels, image_data.image.values)","e94d1302":"# Import train dataset...\n(x_train, y_train) = create_dataset(train_0_list, train_1_list)\n\nprint(x_train.shape)\nprint(y_train.shape)","e6b33c40":"# Import val dataset...\n(x_val, y_val) = create_dataset(val_0_list, val_1_list)","33d6ada5":"from tensorflow.keras.applications import VGG16\n# weights: None \u4ee3\u8868\u968f\u673a\u521d\u59cb\u5316\uff0c 'imagenet' \u4ee3\u8868\u52a0\u8f7d\u5728 ImageNet \u4e0a\u9884\u8bad\u7ec3\u7684\u6743\u503c\n# we could customize input_shape when include_top = False, otherwise input_shape need to be (299, 299, 3); but width and height cannot be less than 71\nconv_base = VGG16(weights='..\/input\/vgg16-weights\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=(150, 150, 3))\nconv_base.summary()","cf3e3111":"# create data generator (without data augment)\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\nimport tensorflow.keras.backend as K\n\n# rescale all image by 1\/255 \ndata_batch_size = 20\n\ndef extract_feature(X_array, y_array, sample_count):\n    features_list = np.zeros(shape=(sample_count, 4, 4, 512))\n    labels_list = np.zeros(shape=(sample_count))\n    datagen = ImageDataGenerator(rescale=1.\/255)\n    datagen.fit(X_array)\n    data_generator = datagen.flow(X_array, y_array, batch_size=data_batch_size)\n    i = 0\n    for data_batch, labels_batch in data_generator:\n        feature_map = conv_base.predict(data_batch) # use conv_base to extract feature map\n        features_list[i*data_batch_size: (i+1)*data_batch_size] = feature_map\n        labels_list[i*data_batch_size: (i+1)*data_batch_size] = labels_batch\n        i += 1\n        if i*data_batch_size >= sample_count:\n            break\n    return (features_list, labels_list)\n\ndef get_f1(y_true, y_pred): #taken from old keras source code\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    f1_val = 2*(precision*recall)\/(precision+recall+K.epsilon())\n    return f1_val","a22390c6":"(train_features, train_labels) = extract_feature(x_train, y_train, len(y_train))\n(valid_features, valid_labels) = extract_feature(x_val, y_val, len(y_val))","2b69e57f":"print((train_features.shape, train_labels.shape), (valid_features.shape, valid_labels.shape))","d5c90e12":"train_features_flatten = np.reshape(train_features, (train_features.shape[0], 4*4*512))\nvalid_features_flatten = np.reshape(valid_features, (valid_features.shape[0], 4*4*512))\ntrain_features_flatten.shape","c6bc38ed":"from sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ndef get_pred_score(y_true, y_pred):\n    mat = confusion_matrix(y_true, y_pred)\n    print(mat)\n\n    plt.figure(figsize=(8,6))\n    sns.heatmap(mat, square=False, annot=True, fmt ='d', cbar=True, annot_kws={\"size\": 16})\n    plt.title('0 : Normal   1 : Pneumonia', fontsize = 20)\n    plt.xticks(fontsize = 16)\n    plt.yticks(fontsize = 16)\n    plt.xlabel('predicted value', fontsize = 20)\n    plt.ylabel('true value', fontsize = 20)\n    plt.show()\n\n    tn, fp, fn, tp = mat.ravel()\n    print('\\ntn = {}, fp = {}, fn = {}, tp = {} '.format(tn, fp, fn, tp))\n\n    precision = tp\/(tp+fp)\n    recall = tp\/(tp+fn)\n    accuracy = (tp+tn)\/(tp+tn+fp+fn)\n    f1_score = 2. * precision * recall \/ (precision + recall)\n    f2_score = 5. * precision * recall \/ (4. * precision + recall)\n\n    print(\"Test Recall of the model \\t = {:.4f}\".format(recall))\n    print(\"Test Precision of the model \\t = {:.4f}\".format(precision))\n    print(\"Test Accuracy of the model \\t = {:.4f}\".format(accuracy))\n    print(\"Test F1 score of the model \\t = {:.4f}\".format(f1_score))\n    print(\"Test F2 score of the model \\t = {:.4f}\".format(f2_score))","210fcb05":"from tensorflow.keras import layers, models\nfrom tensorflow.keras import optimizers\n\nuse_flatten = True\nmodel = models.Sequential()\nif use_flatten:\n    model.add(layers.Dense(256, activation='relu', input_shape= (4,4,512)))\n    model.add(layers.Flatten())\nelse:\n    model.add(layers.Dense(256, activation='relu', input_dim = 4*4*512))\n\nmodel.add(layers.Dropout(0.5)) \nmodel.add(layers.Dense(1, activation='sigmoid'))","38a247f0":"model.summary()","e6ca951d":"default_lr = 1e-4 \nadp_optimizer = optimizers.RMSprop(lr=default_lr, rho=0.9, epsilon=1e-08, decay=0.0)\nmodel.compile(optimizer=adp_optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\", get_f1])","b47ba83b":"from tensorflow.keras.callbacks import ModelCheckpoint\n# Define a checkpoint callback :\ncheckpoint_name = 'Weights-m1-{epoch:03d}--{val_loss:.5f}.hdf5'\ncheckpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\ncallbacks_list = [checkpoint]","51cca493":"if use_flatten:\n    history = model.fit(train_features, train_labels, batch_size=20, epochs=30, validation_data=(valid_features, valid_labels), callbacks=callbacks_list)\nelse:\n    history = model.fit(train_features_flatten, train_labels, batch_size=20, epochs=30, validation_data=(valid_features_flatten, valid_labels), callbacks=callbacks_list)","98027868":"import matplotlib.pyplot as plt\n\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nepochs = range(1, len(acc)+1)\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nf1 = history.history['get_f1']\nval_f1 = history.history['val_get_f1']\n\nplt.plot(epochs, acc, 'bo', label='Train Acc')\nplt.plot(epochs, val_acc, 'b', label='Validation Acc')\nplt.title('Accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, f1, 'bo', label='Train F1')\nplt.plot(epochs, val_f1, 'b', label='Validation F1')\nplt.title('F1 score')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Train Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Loss')\nplt.legend()\nplt.figure()\n\nplt.show()","bee8d16d":"# Import train dataset...\n(x_test, y_test, test_fns) = create_dataset(test_0_list, test_1_list, return_fn=True)","217cf5e1":"(test_features, test_labels) = extract_feature(x_test, y_test, len(y_test))\nprint((train_features.shape, train_labels.shape))\ntest_features_flatten = np.reshape(test_features, (test_features.shape[0], 4*4*512))","f16784e0":"# Load best weight of model\nfrom pathlib import Path\nw_fnl = [str(fn) for fn in Path('.\/').glob('Weights-m1-*.hdf5')]\nw_fnl.sort(reverse=True)\nwights_file = w_fnl[0] # choose the best checkpoint \nmodel.load_weights(wights_file) # load it\nmodel.compile(optimizer=adp_optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\", get_f1])","3cd9baea":"if use_flatten:\n    pred_prob = model.predict(test_features, batch_size=data_batch_size)\nelse:\n    pred_prob = model.predict(test_features_flatten, batch_size=data_batch_size)\npred_res = np.asarray([1 if x > 0.5 else 0 for x in [x[0] for x in pred_prob]]) \nget_pred_score(test_labels, pred_res)","9a9e0df4":"# conv_base = VGG16(weights='..\/input\/vgg16-weights\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=(150, 150, 3))\nmodel = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten()) # \u5148Flatten loss\u7a0d\u597d\uff0c\u4e14\u53ef\u4ee5\u6e1b\u5c11sigmoid\u5c64\u7684param\u6578\nmodel.add(layers.Dense(256, activation='relu'))\n# model.add(layers.Flatten())\nmodel.add(layers.Dense(1, activation='sigmoid'))","8358dcbc":"model.summary()","0b292fc9":"# Freezing a layer or set of layers means preventing their weights from being updated during training.\nprint('This is the number of trainable weights before freezing the conv base:', len(model.trainable_weights))\nconv_base.trainable = False\nprint('This is the number of trainable weights after freezing the conv base:', len(model.trainable_weights))","60c20e5f":"# show trainable weights\n[x.name for x in model.trainable_weights]","b064091b":"# use ImageGenerator to generate more training data\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,  # Rescales all images by 1\/255\n    rotation_range = 10,\n    width_shift_range = 0.2, height_shift_range = 0.2,\n    fill_mode = 'nearest', shear_range = 0.2,\n    zoom_range = 0.2, horizontal_flip=False, \n)\ntrain_datagen.fit(x_train)\nval_datagen = ImageDataGenerator(rescale=1.\/255) #validation set no need to augment\nval_datagen.fit(x_val)\n\ntrain_generator = train_datagen.flow(x_train, y_train, batch_size=32) #increase batch size to 32\nval_generator = val_datagen.flow(x_val, y_val, batch_size=32) #increase batch size to 32","a908bada":"model.compile(optimizer=adp_optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\", get_f1])","5b68a69a":"# Define a checkpoint callback for method2:\ncheckpoint_name = 'Weights-m2-{epoch:03d}--{val_loss:.5f}.hdf5'\ncheckpoint2 = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\ncallbacks_list2 = [checkpoint2]","d0eb05d2":"history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=30, validation_data=val_generator, validation_steps=20, callbacks=callbacks_list2)","1d0b6bcf":"import matplotlib.pyplot as plt\n\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nepochs = range(1, len(acc)+1)\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nf1 = history.history['get_f1']\nval_f1 = history.history['val_get_f1']\n\nplt.plot(epochs, acc, 'bo', label='Train Acc')\nplt.plot(epochs, val_acc, 'b', label='Validation Acc')\nplt.title('Accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, f1, 'bo', label='Train F1')\nplt.plot(epochs, val_f1, 'b', label='Validation F1')\nplt.title('F1 score')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Train Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Loss')\nplt.legend()\nplt.figure()\n\nplt.show()","170fbe89":"test_data = []\ntest_labels = []\nfor (test_img, label) in zip(x_test, y_test):\n    test_data.append(test_img.astype(np.float32)\/255)\n    test_labels.append(label)\n\ntest_data = np.array(test_data)\ntest_labels = np.array(test_labels)\n\nprint(\"Total number of test examples: \", test_data.shape)\nprint(\"Total number of labels:\", test_labels.shape)","dbac4076":"def predict(model, test_data):\n    pred_prob = model.predict(test_data, batch_size=data_batch_size)\n    pred_res = np.asarray([1 if x > 0.5 else 0 for x in [x[0] for x in pred_prob]]) \n    return pred_res","f6422abf":"# Load best weight of model\n\nw_fnl = [str(fn) for fn in Path('.\/').glob('Weights-m2-*.hdf5')]\nw_fnl.sort(reverse=True)\nwights_file = w_fnl[0] # choose the best checkpoint \nmodel.load_weights(wights_file) # load it\nmodel.compile(optimizer=adp_optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\", get_f1])","b4f0fd9c":"get_pred_score(test_labels, predict(model, test_data))","a7abfeda":"conv_base.trainable = True\nset_trainable = False\nfor layer in conv_base.layers:\n    if layer.name == 'block5_conv1':\n#     if layer.name == 'block4_conv1':\n        set_trainable = True\n      # set trainable = True for layers after block5_conv1\n    if set_trainable:\n        layer.trainable = True\n        print(layer.name)\n    else:\n        layer.trainable = False","b88ea8e9":"model.summary()","e187dee3":"# use very low learning rate\nmodel.compile(optimizer=adp_optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\", get_f1])","70deda06":"# Define a checkpoint callback for method3:\ncheckpoint_name = 'Weights-m3-{epoch:03d}--{val_loss:.5f}.hdf5'\ncheckpoint3 = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\ncallbacks_list3 = [checkpoint3]","7177f146":"history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=30, validation_data=val_generator, validation_steps=20, callbacks=callbacks_list3)","d7ccfcb3":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nepochs = range(1, len(acc)+1)\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nf1 = history.history['get_f1']\nval_f1 = history.history['val_get_f1']\n\nplt.plot(epochs, acc, 'bo', label='Train Acc')\nplt.plot(epochs, val_acc, 'b', label='Validation Acc')\nplt.title('Accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, f1, 'bo', label='Train F1')\nplt.plot(epochs, val_f1, 'b', label='Validation F1')\nplt.title('F1 score')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Train Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.title('Loss')\nplt.legend()\nplt.figure()\n\nplt.show()","ff65688b":"# Load best weight of model\n\nw_fnl = [str(fn) for fn in Path('.\/').glob('Weights-m3-*.hdf5')]\nw_fnl.sort(reverse=True)\nwights_file = w_fnl[0] # choose the best checkpoint \nprint('apply weight files: ', wights_file)\nmodel.load_weights(wights_file) # load it\nmodel.compile(optimizer=adp_optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\", get_f1])","df13abb8":"y_pred = predict(model, test_data)\nget_pred_score(test_labels, y_pred)","288bf525":"result_df = pd.DataFrame({'fn':test_fns, 'label': test_labels, 'pred': y_pred})\nfalse_df = result_df[result_df.pred != result_df.label]\nfalse_df.shape","81c5da5e":"false_df.head(10)","4ca60fe2":"#### Summary:\n1. Method 3 is similar to Method 2, both methods are allowed to train conv block before dense layer. But fine tune is more flexible (i.e. we could decide which block to train)\n    + Fine tune is a common way to reuse pretrained model for different prediction tasks.  \n    + Feature maps represented in conv blocks close to dense layer (i.e. Top blocks) would be more general than those represented in bottom conv blocks and are more suitable to be tuned for different tasks \n    + F1 score is around 0.94 ~ 0.95, both false positive and false native are slightly reduced.\n2. Same as methed 1, when using constant learning rate, 1e-4 is the best and learning rate decay improves performance as well.\n3. Using best weights is not better than applying learning rate decay.","0ac1a721":"### Conclusion\nAs we could see, applying such skills on model is working fine for method1 but effect only a little in method2 and 3. What is the meaning of this phenomenon? My opinion is that the models of method2 and 3 originally are powerful enough for this problem. Therefore model skills did not helpful for them. \nAs my study, skills such as hyperparameter tuning, overfit avoiding can only let you get best model within specific limitation. Only two ways could cause significant improvement for your model: **collect enough data and feature engineering**. Why method2 and 3 are better than method1? We provide more data via Data augment is the reason obveriously. ","6e9455b4":"Preprocess images with the following operations and create dataset\n* resize to 224*224\n* Only capture (y1, y2, x1, x2) = (top,top+200, left,left+200) (left, top) = (15, 40) to focus on lung part only","ead1b8a3":"### In this notebook, I use VGG16 module of keras for training and prediction process. Three methods are tried:\n1. Method 1: use conv_base to extract feature map of every images and train dense layer \n2. Method 2: add dense layer on top of conv_base \n3. Method 3: For fine tuning \n\nI will not address data preprocessing part in this notebook, please refer to [Data Preprocessing for Pneumonia Detection](https:\/\/www.kaggle.com\/calexhu\/data-preprocessing-for-pneumonia-detection) and [Pneumonia Detection by CNN with Data Augmentation](https:\/\/www.kaggle.com\/calexhu\/pneumonia-detection-by-cnn-with-data-augmentation)\n\nIn this version, I would also try the following skills on VGG16 models and see whether those methods improve performance or not:\n1. Change Learnging rate and apply learning rate decay.\n2. Apply callback to keep weights of epoch with best val_loss and restore weights to model when make prediction.","524bbc26":"#### Summary:\n1. In Method 1 we use base of VGG16 (only include conv and pooling layer) to extract features from images and predict with dense layer. \n    + The training speed of this method is fastest. But its performance (accuracy and f1 score) is the worst one (f1 score is around 0.84 ~ 0.85) and with high false positive rate. \n    + It is difficult to apply data augment in this method. Because we cannot utilize data generator and have to store all image data in array, we will face memory issue. That's why this method cannot work as good as other two methods.\n    + If GPU machine is not available for you, you could consider this method.\n2. When applying constant learning rate, 1e-4 is the best. When applying learning rate decay, we could observe the trend of validation curve is more close to training one than constant rate. But it seems learning decay did not effect performance too much.\n3. Performance was improved significantly when using best weights, I suppose that is due to the huge difference between best val_loss (0.08424) and the latest epoch of constant rate(0.1177).","87822aa9":"1.   We could use origin input shape = (4,4,512) but need to add Flatten layer in model\n2.   if not use Flatten layer, we need to reshape input in advance","7c84175e":"#### Summary:\n1. In Method 2 we combine base of VGG16 and dense layer for feature extraction and prediction.  \n    + Freezing conv_base (set conv_base.trainable = False) will keep pretrained weights of conv_base and prevent to be updated during training dense layers.\n    + We could utilize data generator for data augment to improve performance of model significantly.  \n    + F1 score is around 0.93 ~ 0.94, false positive is also obviously reduced but false native is slightly increased.\n2. Same as methed 1, when using constant learning rate, 1e-4 is the best and learning rate decay did not effect performance as well.\n3. Using best weights is not helpful for performance. Actually best val_loss (0.10525) is much different to that of latest epoch of constant learning rate(0.1658), but final performance is almost same. Why ?","32dc80a4":"====== Predict Test Data ====","861132d3":"#### Export fp and fn cases to analyze","ba5320d9":"Apply VGG16 module of keras for training & prediction","eb8f2309":"======== Show pictures after being resized=====","83f6756c":"*RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0) with best weights:*\n* tn = 192, fp = 42, fn = 4, tp = 386 \n* Test Recall of the model \t = 0.9897\n* Test Precision of the model \t = 0.9019\n* Test Accuracy of the model \t = 0.9263\n* Test F1 score of the model \t = 0.9438\n* Test F2 score of the model \t = 0.9708\n\n*RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0):*\n* tn = 196, fp = 38, fn = 5, tp = 385 \n* Test Recall of the model \t = 0.9872\n* Test Precision of the model \t = 0.9102\n* Test Accuracy of the model \t = 0.9311\n* Test F1 score of the model \t = 0.9471\n* Test F2 score of the model \t = 0.9708\n\n*RMSprop(lr=1e-3, rho=0.9, epsilon=1e-08, decay=0.0):*\n* tn = 194, fp = 40, fn = 4, tp = 386 \n* Test Recall of the model \t = 0.9897\n* Test Precision of the model \t = 0.9061\n* Test Accuracy of the model \t = 0.9295\n* Test F1 score of the model \t = 0.9461\n* Test F2 score of the model \t = 0.9718\n\n*LR = 1e-4:*\n* tn = 188, fp = 46, fn = 5, tp = 385 \n* Test Recall of the model \t = 0.9872\n* Test Precision of the model \t = 0.8933\n* Test Accuracy of the model \t = 0.9183\n* Test F1 score of the model \t = 0.9379\n* Test F2 score of the model \t = 0.9669\n\n*LR = 1e-5:*\n* tn = 195, fp = 39, fn = 6, tp = 384 \n* Test Recall of the model \t = 0.9846\n* Test Precision of the model \t = 0.9078\n* Test Accuracy of the model \t = 0.9279\n* Test F1 score of the model \t = 0.9446\n* Test F2 score of the model \t = 0.9682\n\n*LR = 1e-3:*\n* tn = 162, fp = 72, fn = 3, tp = 387 \n* Test Recall of the model \t = 0.9923\n* Test Precision of the model \t = 0.8431\n* Test Accuracy of the model \t = 0.8798\n* Test F1 score of the model \t = 0.9117\n* Test F2 score of the model \t = 0.9584","78f7302d":"### Method 3: For fine tuning (Train the latest conv block before dense layer)","abd8223d":"###### Move images from train to val list to increase validation set","c62d4e0d":"Prepare datagen and extract features with VGG16","acd96e80":"==== Prepare test data for prediction ===","09ba4674":"### Method 1: use conv_base to extract feature map of every images and train dense layer","fbb3e4c6":"Make datasets for train, val and test ","ee3774fa":"*RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0) with best weights:*\n* tn = 192, fp = 42, fn = 9, tp = 381 \n* Test Recall of the model \t = 0.9769\n* Test Precision of the model \t = 0.9007\n* Test Accuracy of the model \t = 0.9183\n* Test F1 score of the model \t = 0.9373\n* Test F2 score of the model \t = 0.9607\n\n*RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0):*\n* tn = 196, fp = 38, fn = 14, tp = 376 \n* Test Recall of the model \t = 0.9641\n* Test Precision of the model \t = 0.9082\n* Test Accuracy of the model \t = 0.9167\n* Test F1 score of the model \t = 0.9353\n* Test F2 score of the model \t = 0.9524\n\n*RMSprop(lr=1e-3, rho=0.9, epsilon=1e-08, decay=0.0):*\n* Test Recall of the model \t = 0.9846\n* Test Precision of the model \t = 0.8993\n* Test Accuracy of the model \t = 0.9215\n* Test F1 score of the model \t = 0.9400\n* Test F2 score of the model \t = 0.9663\n\n*LR = 1e-4:*\n* tn = 198, fp = 36, fn = 16, tp = 374 \n* Test Recall of the model \t = 0.9590\n* Test Precision of the model \t = 0.9122\n* Test Accuracy of the model \t = 0.9167\n* Test F1 score of the model \t = 0.9350\n* Test F2 score of the model \t = 0.9492\n\n*LR = 1e-5:*\n* tn = 176, fp = 58, fn = 10, tp = 380 \n* Test Recall of the model \t = 0.9744\n* Test Precision of the model \t = 0.8676\n* Test Accuracy of the model \t = 0.8910\n* Test F1 score of the model \t = 0.9179\n* Test F2 score of the model \t = 0.9510\n\n*LR = 1e-3:*\n\n* tn = 189, fp = 45, fn = 11, tp = 379 \n* Test Recall of the model \t = 0.9718\n* Test Precision of the model \t = 0.8939\n* Test Accuracy of the model \t = 0.9103\n* Test F1 score of the model \t = 0.9312\n* Test F2 score of the model \t = 0.9551","9970b783":"*RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0) with best weights:*\n* tn = 117, fp = 117, fn = 1, tp = 389 \n* Test Recall of the model \t = 0.9974\n* Test Precision of the model \t = 0.7688\n* Test Accuracy of the model \t = 0.8109\n* Test F1 score of the model \t = 0.8683\n* Test F2 score of the model \t = 0.9414\n\n*RMSprop(lr=1e-4, rho=0.9, epsilon=1e-08, decay=0.0):*\n* tn = 107, fp = 127, fn = 2, tp = 388 \n* Test Recall of the model \t = 0.9949\n* Test Precision of the model \t = 0.7534\n* Test Accuracy of the model \t = 0.7933\n* Test F1 score of the model \t = 0.8575\n* Test F2 score of the model \t = 0.9349\n\n*RMSprop(lr=1e-3, rho=0.9, epsilon=1e-08, decay=0.0):*\n* tn = 80, fp = 154, fn = 0, tp = 390 \n* Test Recall of the model \t = 1.0000\n* Test Precision of the model \t = 0.7169\n* Test Accuracy of the model \t = 0.7532\n* Test F1 score of the model \t = 0.8351\n* Test F2 score of the model \t = 0.9268\n\n*LR = 1e-4*\n* tn = 108, fp = 126, fn = 3, tp = 387 \n* Test Recall of the model \t = 0.9923\n* Test Precision of the model \t = 0.7544\n* Test Accuracy of the model \t = 0.7933\n* Test F1 score of the model \t = 0.8571\n* Test F2 score of the model \t = 0.9334\n\n*LR = 1e-5*\n* tn = 96, fp = 138, fn = 3, tp = 387 \n* Test Recall of the model \t = 0.9923\n* Test Precision of the model \t = 0.7371\n* Test Accuracy of the model \t = 0.7740\n* Test F1 score of the model \t = 0.8459\n* Test F2 score of the model \t = 0.9281\n\n*LR = 1e-3*\n* tn = 98, fp = 136, fn = 1, tp = 389 \n* Test Recall of the model \t = 0.9974\n* Test Precision of the model \t = 0.7410\n* Test Accuracy of the model \t = 0.7804\n* Test F1 score of the model \t = 0.8503\n* Test F2 score of the model \t = 0.9329","457a1f51":"### Method 2: add dense layer on top of conv_base "}}