{"cell_type":{"ec5dbb69":"code","e7d57a56":"code","fda389c3":"code","624cb197":"code","504dcada":"code","632cd003":"code","08f61dd6":"code","a12e8fb1":"code","4d14078b":"code","8794410e":"code","3f915e83":"code","86a5e582":"code","4982d06b":"code","d088e052":"code","0fed7420":"code","89860b8a":"code","ca508321":"code","3a594f20":"code","b77253cc":"code","d15f1152":"code","84b5933c":"code","f660d887":"code","1f515b37":"markdown","2ecfa97a":"markdown","03da4c64":"markdown","7d2c8578":"markdown","c89407e1":"markdown","e722004a":"markdown","0af09288":"markdown","8eb81728":"markdown","ae8add81":"markdown","8dfc3e5f":"markdown","34feb35b":"markdown","a281cc98":"markdown","6bc5acc9":"markdown","c2df6537":"markdown","e8ba3941":"markdown","54ff5394":"markdown","ae886fa4":"markdown","965a6714":"markdown","9a8dfc6c":"markdown","27a7617c":"markdown","a0127238":"markdown","2ff2f277":"markdown","a90420d6":"markdown","b2288688":"markdown","54484187":"markdown","1ad85a57":"markdown","8e0fcd5f":"markdown","7be48704":"markdown"},"source":{"ec5dbb69":"print(\"\\n... PIP\/APT INSTALLS STARTING ...\")\n!cp \/kaggle\/input\/gdcm-conda-install\/gdcm.tar .\n!tar -xvzf gdcm.tar\n!conda install --offline .\/gdcm\/gdcm-2.8.9-py37h71b2a6d_0.tar.bz2\n!rm -rf .\/gdcm*\n!pip install efficientnet-3D\n!pip install git+https:\/\/github.com\/qubvel\/classification_models.git\n!pip install -U --pre efficientnet\n\n# !conda install -c conda-forge gdcm -y\n!pip install pandarallel\nprint(\"... PIP\/APT INSTALLS COMPLETE ...\\n\")\n\n\nprint(\"\\n... IMPORTS STARTING ...\\n\")\nprint(\"\\n\\tVERSION INFORMATION\")\n# Machine Learning and Data Science Imports\nimport tensorflow as tf; print(f\"\\t\\t\u2013 TENSORFLOW VERSION: {tf.__version__}\");\nimport tensorflow_addons as tfa; print(f\"\\t\\t\u2013 TENSORFLOW ADDONS VERSION: {tfa.__version__}\");\nimport pandas as pd; pd.options.mode.chained_assignment = None; pd.set_option('max_columns', 100);\nimport numpy as np; print(f\"\\t\\t\u2013 NUMPY VERSION: {np.__version__}\");\nimport efficientnet_3D.tfkeras as efn\n\n# Other Competition Related Imports\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom pandarallel import pandarallel; pandarallel.initialize();\n\n# Built In Imports\nfrom kaggle_datasets import KaggleDatasets\nfrom collections import Counter\nfrom datetime import datetime\nfrom glob import glob\nimport warnings\nimport requests\nimport imageio\nimport IPython\nimport urllib\nimport zipfile\nimport pickle\nimport random\nimport shutil\nimport string\nimport scipy\nimport math\nimport time\nimport gzip\nimport ast\nimport sys\nimport io\nimport os\nimport gc\nimport re\n\n# Visualization Imports\nfrom matplotlib.colors import ListedColormap\nfrom matplotlib import animation, rc; rc('animation', html='jshtml')\nimport matplotlib.patches as patches\n\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm; tqdm.pandas();\nimport plotly.express as px\nimport seaborn as sns\nfrom PIL import Image\nimport matplotlib; print(f\"\\t\\t\u2013 MATPLOTLIB VERSION: {matplotlib.__version__}\");\nimport plotly\nimport PIL\nimport cv2\nprint(\"\\n\\n... IMPORTS COMPLETE ...\\n\")\n    \n\nprint(\"\\n... SEEDING FOR DETERMINISTIC BEHAVIOUR ...\")\ndef seed_it_all(seed=7):\n    \"\"\" Attempt to be Reproducible \"\"\"\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nseed_it_all()\nprint(\"... SEEDING COMPLETE ...\\n\\n\")\n\nprint(\"\\n... SETTING PRESETS STARTING...\")\nFIG_FONT = dict(family=\"Helvetica, Arial\", size=14, color=\"#7f7f7f\")\nlabel_map_int_2_str = {0: \"MGMT_NEGATIVE\", 1: \"MGMT_POSITIVE\"}\nlabel_map_str_2_int = {\"MGMT_NEGATIVE\":0, \"MGMT_POSITIVE\":1}\nprint(\"... SETTING PRESETS COMPLETE...\\n\\n\")","e7d57a56":"ROOT_DIR = \"\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\"\n\nTRAIN_DIR = os.path.join(ROOT_DIR, \"train\")\nTEST_DIR = os.path.join(ROOT_DIR, \"test\")\n\nSS_CSV = os.path.join(ROOT_DIR, \"sample_submission.csv\")\nTRAIN_CSV = os.path.join(ROOT_DIR, \"train_labels.csv\")\n\ntrain_df = pd.read_csv(TRAIN_CSV)\ntrain_df[\"path_to_flair_dir\"] = train_df.BraTS21ID.apply(lambda x: os.path.join(TRAIN_DIR, f\"{x:>05}\", \"FLAIR\"))\ntrain_df[\"flair_image_count\"] = train_df.path_to_flair_dir.progress_apply(lambda x: len(os.listdir(x)))\ntrain_df[\"path_to_t1w_dir\"] = train_df.BraTS21ID.apply(lambda x: os.path.join(TRAIN_DIR, f\"{x:>05}\", \"T1w\"))\ntrain_df[\"t1w_image_count\"] = train_df.path_to_t1w_dir.progress_apply(lambda x: len(os.listdir(x)))\ntrain_df[\"path_to_t1wce_dir\"] = train_df.BraTS21ID.apply(lambda x: os.path.join(TRAIN_DIR, f\"{x:>05}\", \"T1wCE\"))\ntrain_df[\"t1wce_image_count\"] = train_df.path_to_t1wce_dir.progress_apply(lambda x: len(os.listdir(x)))\ntrain_df[\"path_to_t2w_dir\"] = train_df.BraTS21ID.apply(lambda x: os.path.join(TRAIN_DIR, f\"{x:>05}\", \"T2w\"))\ntrain_df[\"t2w_image_count\"] = train_df.path_to_t2w_dir.progress_apply(lambda x: len(os.listdir(x)))\n                                                                  \nss_df = pd.read_csv(SS_CSV)\nss_df[\"path_to_flair_dir\"] = ss_df.BraTS21ID.apply(lambda x: os.path.join(TEST_DIR, f\"{x:>05}\", \"FLAIR\"))\nss_df[\"flair_image_count\"] = ss_df.path_to_flair_dir.progress_apply(lambda x: len(os.listdir(x)))\nss_df[\"path_to_t1w_dir\"] = ss_df.BraTS21ID.apply(lambda x: os.path.join(TEST_DIR, f\"{x:>05}\", \"T1w\"))\nss_df[\"t1w_image_count\"] = ss_df.path_to_t1w_dir.progress_apply(lambda x: len(os.listdir(x)))\nss_df[\"path_to_t1wce_dir\"] = ss_df.BraTS21ID.apply(lambda x: os.path.join(TEST_DIR, f\"{x:>05}\", \"T1wCE\"))\nss_df[\"t1wce_image_count\"] = ss_df.path_to_t1wce_dir.progress_apply(lambda x: len(os.listdir(x)))\nss_df[\"path_to_t2w_dir\"] = ss_df.BraTS21ID.apply(lambda x: os.path.join(TEST_DIR, f\"{x:>05}\", \"T2w\"))\nss_df[\"t2w_image_count\"] = ss_df.path_to_t2w_dir.progress_apply(lambda x: len(os.listdir(x)))\n\nprint(\"\\n\\nTRAIN DATAFRAME\\n\")\ndisplay(train_df.head())\n\nprint(\"\\n\\n\\nSAMPLE SUBMISSION DATAFRAME\\n\")\ndisplay(ss_df.head())\n\nprint(\"\\nCOUNTS PER SCAN TYPE\\n\")\nfor c_name in [c for c in train_df.columns if \"count\" in c]:\n    print(c_name, print(train_df[c_name].sum()))","fda389c3":"def get_list_of_dcm_paths(dir_path):\n    return sorted([os.path.join(dir_path, f_name) for f_name in os.listdir(dir_path)], key=lambda x: int(x.rsplit(\"-\", 1)[1].split(\".\", 1)[0]))\n\ndef dicom2array(path, voi_lut=True, fix_monochrome=True):\n    \"\"\" Convert dicom file to numpy array \n    \n    Args:\n        path (str): Path to the dicom file to be converted\n        voi_lut (bool): Whether or not VOI LUT is available\n        fix_monochrome (bool): Whether or not to apply monochrome fix\n        \n    Returns:\n        Numpy array of the respective dicom file \n        \n    \"\"\"\n    # Use the pydicom library to read the dicom file\n    dicom = pydicom.read_file(path)\n    \n    # VOI LUT (if available by DICOM device) is used to \n    # transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n        \n    # The XRAY may look inverted\n    #   - If we want to fix this we can\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    \n    # Normalize the image array and return\n    data = (data-np.min(data))\/(np.max(data)-np.min(data))\n    return data\n\ndef create_animation(np_arr):\n    fig = plt.figure(figsize=(5, 5))\n    plt.axis('off')\n    im = plt.imshow(np_arr[..., 0], cmap=\"bone\")\n    plt.title(\"mpMRI Animation\", fontweight=\"bold\")\n    def animate_func(i):\n        im.set_array(np_arr[..., i])\n        return [im]\n    plt.close()\n    return animation.FuncAnimation(fig, animate_func, frames = np_arr.shape[-1], interval = 1000\/\/24)\n\n\ndef create_4scan_animation(flair_arr, t1w_arr, t1wce_arr, t2w_arr):\n    \n    def animate_func(i):\n        flair_im.set_array(flair_arr[..., i])\n        t1w_im.set_array(t1w_arr[..., i])\n        t1wce_im.set_array(t1wce_arr[..., i])\n        t2w_im.set_array(t2w_arr[..., i])\n        return [flair_im, t1w_im, t1wce_im, t2w_im]\n    \n    fig = plt.figure(figsize=(18, 5))\n    \n    #\n    plt.subplot(1,4,1)\n    plt.axis('off')\n    flair_im = plt.imshow(flair_arr[..., 0], cmap=\"bone\")\n    plt.title(\"FLAIR Animation\", fontweight=\"bold\")\n    \n    #\n    plt.subplot(1,4,2)\n    plt.axis('off')\n    t1w_im = plt.imshow(t1w_arr[..., 0], cmap=\"bone\")\n    plt.title(\"T1w Animation\", fontweight=\"bold\")\n    \n    #\n    plt.subplot(1,4,3)\n    plt.axis('off')\n    t1wce_im = plt.imshow(t1wce_arr[..., 0], cmap=\"bone\")\n    plt.title(\"T1wCE Animation\", fontweight=\"bold\")\n\n    \n    #\n    plt.subplot(1,4,4)\n    plt.axis('off')\n    t2w_im = plt.imshow(t2w_arr[..., 0], cmap=\"bone\")\n    plt.title(\"T2w Animation\", fontweight=\"bold\")\n    \n    plt.close()\n    \n    return animation.FuncAnimation(fig, animate_func, frames = flair_arr.shape[-1], interval = 1000\/\/16)\n\n\ndef get_dicom_meta(row, attrs):\n    dcm_file = pydicom.read_file(row.dcm_path)\n    for val in attrs:\n        row[val] = dcm_file.get(val, None)\n    return row\n\n\ndef load_npz(np_file_path, is_tf=False):\n    if is_tf:\n        return np.load(np_file_path.numpy().decode())[\"arr_0\"] \n    else:\n        return np.load(np_file_path)[\"arr_0\"] \n    \n    \ndef flatten_l_o_l(nested_list):\n    \"\"\" Flatten a list of lists \"\"\"\n    return [item for sublist in nested_list for item in sublist]","624cb197":"EX_NUMBER = 0\nEX_SLICE = 0\nEX_PATIENT = train_df.iloc[EX_NUMBER]\n\nALL_DICOM_PATHS = glob(os.path.join(TRAIN_DIR, \"**\/*.dcm\"), recursive=True)\nFLAIR_DCM_PATHS = get_list_of_dcm_paths(EX_PATIENT[\"path_to_flair_dir\"])\nT1W_DCM_PATHS = get_list_of_dcm_paths(EX_PATIENT[\"path_to_t1w_dir\"])\nT1WCE_DCM_PATHS = get_list_of_dcm_paths(EX_PATIENT[\"path_to_t1wce_dir\"])\nT2W_DCM_PATHS = get_list_of_dcm_paths(EX_PATIENT[\"path_to_t2w_dir\"])\n\nFLAIR_EXAMPLE_DCM_1 = FLAIR_DCM_PATHS[EX_SLICE]\nFLAIR_EXAMPLE_DCM_2 = FLAIR_DCM_PATHS[EX_SLICE+1]\nT1W_EXAMPLE_DCM_1 = T1W_DCM_PATHS[EX_SLICE]\nT1W_EXAMPLE_DCM_2 = T1W_DCM_PATHS[EX_SLICE+1]\nT1WCE_EXAMPLE_DCM_1 = T1WCE_DCM_PATHS[EX_SLICE]\nT1WCE_EXAMPLE_DCM_2 = T1WCE_DCM_PATHS[EX_SLICE+1]\nT2W_EXAMPLE_DCM_1 = T2W_DCM_PATHS[EX_SLICE]\nT2W_EXAMPLE_DCM_2 = T2W_DCM_PATHS[EX_SLICE+1]","504dcada":"flair_ex_dcm_1 = pydicom.read_file(FLAIR_EXAMPLE_DCM_1)\nflair_ex_dcm_2 = pydicom.read_file(FLAIR_EXAMPLE_DCM_2)\nFLAIR_ATTRS = flair_ex_dcm_1.dir()\n\nprint(\"FLAIR ATTRIBUTES:\")\nfor k in FLAIR_ATTRS: print(f\"\\t--> {k:<30}( Same Across Dicoms = {str(flair_ex_dcm_1.get(k)==flair_ex_dcm_2.get(k)):<5} )\")","632cd003":"t1w_ex_dcm_1 = pydicom.read_file(T1W_EXAMPLE_DCM_1)\nt1w_ex_dcm_2 = pydicom.read_file(T1W_EXAMPLE_DCM_2)\nT1W_ATTRS = t1w_ex_dcm_1.dir()\n\nprint(\"T1W ATTRIBUTES:\")\nfor k in T1W_ATTRS: print(f\"\\t--> {k:<30}( Same Across Two Dicoms = {str(t1w_ex_dcm_1.get(k)==t1w_ex_dcm_2.get(k)):<5} )\")","08f61dd6":"t1wce_ex_dcm_1 = pydicom.read_file(T1WCE_EXAMPLE_DCM_1)\nt1wce_ex_dcm_2 = pydicom.read_file(T1WCE_EXAMPLE_DCM_2)\nT1WCE_ATTRS = t1wce_ex_dcm_1.dir()\n\nprint(\"T1WCE ATTRIBUTES:\")\nfor k in T1WCE_ATTRS: print(f\"\\t--> {k:<30}( Same Across Two Dicoms = {str(t1wce_ex_dcm_1.get(k)==t1wce_ex_dcm_2.get(k)):<5} )\")","a12e8fb1":"t2w_ex_dcm_1 = pydicom.read_file(T2W_EXAMPLE_DCM_1)\nt2w_ex_dcm_2 = pydicom.read_file(T2W_EXAMPLE_DCM_2)\nT2W_ATTRS = t2w_ex_dcm_1.dir()\n\nprint(\"T2W ATTRIBUTES:\")\nfor k in T2W_ATTRS: print(f\"\\t--> {k:<30}( Same Across Two Dicoms = {str(t2w_ex_dcm_1.get(k)==t2w_ex_dcm_2.get(k)):<5} )\")","4d14078b":"t1 = time.time()\n\nDESIRED_ATTRS = [x for x in T1WCE_ATTRS if (x!=\"PixelData\" and \"UID\" not in x)]\ndicom_df = pd.DataFrame({\"dcm_path\":ALL_DICOM_PATHS})\ndicom_df = dicom_df.reindex(columns=([\"dcm_path\",]+DESIRED_ATTRS))\n\nprint(f\"\\n ... Processing Started...\")\n\n# Regular method\n#    - for 10,000 dicom files the regular takes 94.639 seconds\n#    - processing will take (350000\/10000)*94.639 ~= 3325 seconds ~= 56 minutes (actual is 71 minutes)\n\n##### dicom_df = dicom_df.progress_apply(lambda x: get_dicom_meta(x, DESIRED_ATTRS), axis=1)\n\n# Use Multiprocessing (Pandarallel)\n#    - no progress bar but approximately 3.75 times faster\n#    - for 10,000 dicom files pandarallel takes 25.529 seconds\n#    - processing will take (350000\/10000)*25.529 ~= 893 seconds ~= 15 minutes (actual is 19 minutes)\ndicom_df = dicom_df.parallel_apply(lambda x: get_dicom_meta(x, DESIRED_ATTRS), axis=1)\n\nprint(f\"... Processing Completed in  >>>>> {time.time()-t1} <<<<<  Seconds ...\\n\")\n\ndisplay(dicom_df)","8794410e":"for attr in DESIRED_ATTRS:\n    print(f\"\\n\\nAttribute Name: {attr} ({dicom_df[attr].astype(str).nunique()} Different Values)\\n\")\n    for i, (k,v) in enumerate(dicom_df[attr].astype(str).value_counts(dropna=False).items()): \n        print(f\"\\t{repr(k):<50} --> Occurs {v} Times In Training Data\")\n        if i == 10:\n            print(\"\\n\\t--------- TRUNCATED ------ ENDING EARLY ------ TRUNCATED ---------\")\n            break","3f915e83":"# train_ids = [f\"{x:>05}.npz\" for x in os.listdir(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\")]\n\n# print([x for x in train_ids if x not in os.listdir(FLAIR_NPY_DIR)])\n# print([x for x in train_ids if x not in os.listdir(T1w_NPY_DIR)])\n# print([x for x in train_ids if x not in os.listdir(T1wCE_NPY_DIR)])\n# print([x for x in train_ids if x not in os.listdir(T2w_NPY_DIR)])\n\n# total_sum = 0\n# IDX = \"00026\"\n# TYPE = \"T2w\"\n# for i in range(1000):\n#     try:\n#         total_sum+=pydicom.read_file([os.path.join(f\"\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/{IDX}\/{TYPE}\", x) for x in os.listdir(f\"\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/{IDX}\/{TYPE}\")][i]).pixel_array.max()\n#     except:\n#         break\n        \n# print(total_sum)","86a5e582":"TRAIN_NPY_DIR = \"\/kaggle\/input\/create-3d-npz-rsna-radiogenomic-classification\/train\"\n# TRAIN_NPY_DIR = \"\/kaggle\/input\/rsna-radiogenomic-3dnumpy-512x512x128\/train\"\nTEST_NPY_DIR = \"\/kaggle\/input\/create-3d-npz-rsna-radiogenomic-classification\/test\"\n\nTRAIN_FLAIR_NPY_DIR = os.path.join(TRAIN_NPY_DIR, \"FLAIR\")\nTRAIN_T1w_NPY_DIR = os.path.join(TRAIN_NPY_DIR, \"T1w\")\nTRAIN_T1wCE_NPY_DIR = os.path.join(TRAIN_NPY_DIR, \"T1wCE\")\nTRAIN_T2w_NPY_DIR = os.path.join(TRAIN_NPY_DIR, \"T2w\")\n\nTEST_FLAIR_NPY_DIR = os.path.join(TEST_NPY_DIR, \"FLAIR\")\nTEST_T1w_NPY_DIR = os.path.join(TEST_NPY_DIR, \"T1w\")\nTEST_T1wCE_NPY_DIR = os.path.join(TEST_NPY_DIR, \"T1wCE\")\nTEST_T2w_NPY_DIR = os.path.join(TEST_NPY_DIR, \"T2w\")\n\n\nprint(\"\\n... FILE COUNTS ...\\n\")\nprint(f\"\\t--> The number of FLAIR numpy files is:  {len(os.listdir(TRAIN_FLAIR_NPY_DIR))}  ...\")\nprint(f\"\\t--> The number of T1w   numpy files is:  {len(os.listdir(TRAIN_T1w_NPY_DIR))}  ...\")\nprint(f\"\\t--> The number of T1wCE numpy files is:  {len(os.listdir(TRAIN_T1wCE_NPY_DIR))}  ...\")\nprint(f\"\\t--> The number of T2w   numpy files is:  {len(os.listdir(TRAIN_T2w_NPY_DIR))}  ...\\n\")","4982d06b":"train_df[\"path_to_flair_npz\"] = train_df.BraTS21ID.apply(lambda x: os.path.join(TRAIN_FLAIR_NPY_DIR, f\"{x:>05}.npz\"))\ntrain_df[\"path_to_t1w_npz\"] = train_df.BraTS21ID.apply(lambda x: os.path.join(TRAIN_T1w_NPY_DIR, f\"{x:>05}.npz\"))\ntrain_df[\"path_to_t1wce_npz\"] = train_df.BraTS21ID.apply(lambda x: os.path.join(TRAIN_T1wCE_NPY_DIR, f\"{x:>05}.npz\"))\ntrain_df[\"path_to_t2w_npz\"] = train_df.BraTS21ID.apply(lambda x: os.path.join(TRAIN_T2w_NPY_DIR, f\"{x:>05}.npz\"))\n\nss_df[\"path_to_flair_npz\"] = ss_df.BraTS21ID.apply(lambda x: os.path.join(TEST_FLAIR_NPY_DIR, f\"{x:>05}.npz\"))\nss_df[\"path_to_t1w_npz\"] = ss_df.BraTS21ID.apply(lambda x: os.path.join(TEST_T1w_NPY_DIR, f\"{x:>05}.npz\"))\nss_df[\"path_to_t1wce_npz\"] = ss_df.BraTS21ID.apply(lambda x: os.path.join(TEST_T1wCE_NPY_DIR, f\"{x:>05}.npz\"))\nss_df[\"path_to_t2w_npz\"] = ss_df.BraTS21ID.apply(lambda x: os.path.join(TEST_T2w_NPY_DIR, f\"{x:>05}.npz\"))\n\ndisplay(train_df.head())\ndisplay(ss_df.head())","d088e052":"RANDOM_IMG_IDX = int(random.random()*len(train_df))\nprint(f\"\\n... Visualize Single Flair Scan From Disk - IDX={RANDOM_IMG_IDX} ...\\n\")\ndisplay(create_animation(load_npz(train_df.path_to_flair_npz[RANDOM_IMG_IDX])))\n\nRANDOM_IMG_IDX = int(random.random()*len(train_df))\nprint(f\"\\n... Visualize Set of mpMRI Scans From Disk - IDX={RANDOM_IMG_IDX} ...\\n\")\ndisplay(create_4scan_animation(\n    load_npz(train_df.path_to_flair_npz[RANDOM_IMG_IDX]),\n    load_npz(train_df.path_to_t1w_npz[RANDOM_IMG_IDX]),\n    load_npz(train_df.path_to_t1wce_npz[RANDOM_IMG_IDX]),\n    load_npz(train_df.path_to_t2w_npz[RANDOM_IMG_IDX]),\n))\n\nprint(train_df.path_to_flair_npz[RANDOM_IMG_IDX])\nprint(train_df.path_to_t1w_npz[RANDOM_IMG_IDX])\nprint(train_df.path_to_t1wce_npz[RANDOM_IMG_IDX])\nprint(train_df.path_to_t2w_npz[RANDOM_IMG_IDX])","0fed7420":"# def get_3d_effnet(dropout=0.5):\n#     \"\"\"Build a 3D convolutional neural network model.\"\"\"\n\n#     inputs = tf.keras.layers.Input(shape=INPUT_SHAPE)\n#     pp_inputs = tf.keras.applications.efficientnet.preprocess_input(inputs)\n#     x = efn.EfficientNetB0(input_shape=INPUT_SHAPE, pooling=\"avg\")(pp_inputs)\n    \n#     x = tf.keras.layers.Dropout(dropout)(x)\n#     x = tf.keras.layers.Dense(units=256, activation=\"relu\")(x)\n\n#     x = tf.keras.layers.Dropout(dropout\/1.25)(x)\n#     outputs = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")(x)\n\n#     # Define the model.\n#     model = tf.keras.Model(inputs, outputs, name=\"3d_mpmri_cnn\")\n#     return model\n\n# model = get_3d_effnet()\n# print(model.predict(tf.repeat(load_npz(train_df.path_to_flair_npz[RANDOM_IMG_IDX]).reshape(1, *INPUT_SHAPE[:-1], 1), axis=-1, repeats=3)))\n","89860b8a":"INPUT_SHAPE = (128,128,32,1)\nBATCH_SIZE = 8\n\ndef get_3d_model(width=128, height=128, depth=32, dropout=0.3):\n    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n\n    inputs = tf.keras.layers.Input(shape=(width, height, depth, 1))\n\n    # print(x.shape)\n    # x1 = tf.keras.layers.Conv3D(filters=64, kernel_size=1, activation=None, padding=\"same\")(inputs)\n    # x1 = tf.keras.layers.MaxPool3D(pool_size=2)(x1)\n    # x1 = tf.keras.layers.BatchNormalization()(x1)\n    \n    x = tf.keras.layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n    x = tf.keras.layers.MaxPool3D(pool_size=2)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    \n    # x3 = tf.keras.layers.Conv3D(filters=64, kernel_size=5, activation=None, padding=\"same\")(inputs)\n    # x3 = tf.keras.layers.MaxPool3D(pool_size=2)(x3)\n    # x3 = tf.keras.layers.BatchNormalization()(x3)\n    # x = tf.keras.layers.Add()([x1,x2,x3])\n    # x = tf.keras.layers.Activation(\"relu\")(x)\n    \n    x = tf.keras.layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n    x = tf.keras.layers.MaxPool3D(pool_size=2)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n\n    # print(x.shape)\n    x = tf.keras.layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n    # x = tf.keras.layers.MaxPool3D(pool_size=2)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n\n    # print(x.shape)\n    x = tf.keras.layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n    # x = tf.keras.layers.MaxPool3D(pool_size=2)(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Dropout(dropout\/2)(x)\n    \n    # print(x.shape)\n    x = tf.keras.layers.GlobalAveragePooling3D()(x)\n    x = tf.keras.layers.Dense(units=128, activation=\"relu\")(x)\n    x = tf.keras.layers.Dropout(dropout)(x)\n\n    # print(x.shape)\n    outputs = tf.keras.layers.Dense(units=1, activation=\"sigmoid\")(x)\n\n    # Define the model.\n    model = tf.keras.Model(inputs, outputs, name=\"3d_mpmri_cnn\")\n    return model\n\n\n# Build model.\nDROPOUT = 0.666\nflair_model = get_3d_model(width=INPUT_SHAPE[0], height=INPUT_SHAPE[1], depth=INPUT_SHAPE[2], dropout=DROPOUT)\nt1w_model = get_3d_model(width=INPUT_SHAPE[0], height=INPUT_SHAPE[1], depth=INPUT_SHAPE[2], dropout=DROPOUT)\nt1wce_model = get_3d_model(width=INPUT_SHAPE[0], height=INPUT_SHAPE[1], depth=INPUT_SHAPE[2], dropout=DROPOUT)\nt2w_model = get_3d_model(width=INPUT_SHAPE[0], height=INPUT_SHAPE[1], depth=INPUT_SHAPE[2], dropout=DROPOUT)\nmodels = {\"flair\":flair_model, \"t1w\":t1w_model, \"t1wce\":t1wce_model, \"t2w\":t2w_model}\n\nprint(\"\\n... EXAMPLE PREDICTION ...\\n\")\nprint(flair_model.predict(load_npz(train_df.path_to_flair_npz[RANDOM_IMG_IDX]).reshape(1, *INPUT_SHAPE)))\n\nprint(\"\\n\\n... MODEL SUMMARY ...\\n\")\nflair_model.summary()","ca508321":"# This is dataframe wrangling\nUSE_COL = \"all\" # one of [`all`, `path_to_t1w_npz`, `path_to_t1wce_npz`, `path_to_flair_npz`, `path_to_t2w_npz`]\nif USE_COL is \"all\":\n    USE_COLS = [\"path_to_t1w_npz\", \"path_to_t1wce_npz\", \"path_to_flair_npz\", \"path_to_t2w_npz\"]\nelse:\n    USE_COLS = [USE_COL,]\n\n# Initialize dictionaries\ndataset_storage = {}\n\nfor use_col in USE_COLS:\n    col_identifier = use_col.split(\"_\")[2]\n    dataset_storage[col_identifier] = {}\n    \n    dataset_storage[col_identifier][\"train_ds_df\"] = train_df[train_df[use_col].apply(lambda x: True if os.path.isfile(x) else False)][[\"MGMT_value\", use_col]]\n    dataset_storage[col_identifier][\"train_lbl_list\"] = dataset_storage[col_identifier][\"train_ds_df\"].MGMT_value.to_list()\n    dataset_storage[col_identifier][\"train_npz_file_list\"] = dataset_storage[col_identifier][\"train_ds_df\"][use_col].to_list()\n\n    # fix this.......\n    dataset_storage[col_identifier][\"test_ds_df\"] = ss_df[ss_df[use_col].apply(lambda x: True if os.path.isfile(x) else False)][[\"BraTS21ID\", use_col]]\n    dataset_storage[col_identifier][\"test_id_list\"] = dataset_storage[col_identifier][\"test_ds_df\"].BraTS21ID.to_list()\n    dataset_storage[col_identifier][\"test_npz_file_list\"] = dataset_storage[col_identifier][\"test_ds_df\"][use_col].to_list()\n\n    # This is for splitting\n    dataset_storage[col_identifier][\"N_EX\"] = len(dataset_storage[col_identifier][\"train_lbl_list\"])\n    dataset_storage[col_identifier][\"VAL_FRAC\"] = 0.1\n    dataset_storage[col_identifier][\"N_TRAIN\"] = int(dataset_storage[col_identifier][\"N_EX\"]*(1-dataset_storage[col_identifier][\"VAL_FRAC\"]))\n    dataset_storage[col_identifier][\"N_VAL\"] = dataset_storage[col_identifier][\"N_EX\"]-dataset_storage[col_identifier][\"N_TRAIN\"]\n    dataset_storage[col_identifier][\"RANDOM_INDICES\"] = random.sample(range(dataset_storage[col_identifier][\"N_EX\"]), dataset_storage[col_identifier][\"N_EX\"])\n    dataset_storage[col_identifier][\"TRAIN_INDICES\"] = dataset_storage[col_identifier][\"RANDOM_INDICES\"][:dataset_storage[col_identifier][\"N_TRAIN\"]]\n    dataset_storage[col_identifier][\"VAL_INDICES\"] = dataset_storage[col_identifier][\"RANDOM_INDICES\"][dataset_storage[col_identifier][\"N_TRAIN\"]:]\n\n    # TF Data Integration\n    dataset_storage[col_identifier][\"lbl_train_ds\"] = tf.data.Dataset.from_tensor_slices(np.array(dataset_storage[col_identifier][\"train_lbl_list\"])[dataset_storage[col_identifier][\"TRAIN_INDICES\"]])\n    dataset_storage[col_identifier][\"npz_file_train_ds\"] = tf.data.Dataset.from_tensor_slices(np.array(dataset_storage[col_identifier][\"train_npz_file_list\"])[dataset_storage[col_identifier][\"TRAIN_INDICES\"]])\n    dataset_storage[col_identifier][\"raw_train_ds\"] = tf.data.Dataset.zip((dataset_storage[col_identifier][\"npz_file_train_ds\"], dataset_storage[col_identifier][\"lbl_train_ds\"]))\n\n    dataset_storage[col_identifier][\"lbl_val_ds\"] = tf.data.Dataset.from_tensor_slices(np.array(dataset_storage[col_identifier][\"train_lbl_list\"])[dataset_storage[col_identifier][\"VAL_INDICES\"]])\n    dataset_storage[col_identifier][\"npz_file_val_ds\"] = tf.data.Dataset.from_tensor_slices(np.array(dataset_storage[col_identifier][\"train_npz_file_list\"])[dataset_storage[col_identifier][\"VAL_INDICES\"]])\n    dataset_storage[col_identifier][\"raw_val_ds\"] = tf.data.Dataset.zip((dataset_storage[col_identifier][\"npz_file_val_ds\"], dataset_storage[col_identifier][\"lbl_val_ds\"]))\n\n    dataset_storage[col_identifier][\"id_test_ds\"] = tf.data.Dataset.from_tensor_slices(dataset_storage[col_identifier][\"test_id_list\"])\n    dataset_storage[col_identifier][\"npz_file_test_ds\"] = tf.data.Dataset.from_tensor_slices(dataset_storage[col_identifier][\"test_npz_file_list\"])\n    dataset_storage[col_identifier][\"raw_test_ds\"] = tf.data.Dataset.zip((dataset_storage[col_identifier][\"npz_file_test_ds\"], dataset_storage[col_identifier][\"id_test_ds\"]))\n\n    if INPUT_SHAPE[-1]==3:\n        dataset_storage[col_identifier][\"train_ds\"] = dataset_storage[col_identifier][\"raw_train_ds\"].map(lambda x,y: (tf.repeat(tf.reshape(tf.py_function(\n            load_npz, [x, True], (tf.uint8,)\n        ), (*INPUT_SHAPE[:-1], 1))\/255, axis=-1, repeats=3), tf.cast(y, tf.uint8)), num_parallel_calls=tf.data.AUTOTUNE)\n        dataset_storage[col_identifier][\"train_ds\"] = dataset_storage[col_identifier][\"train_ds\"].shuffle(BATCH_SIZE*5).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\n        dataset_storage[col_identifier][\"val_ds\"] = dataset_storage[col_identifier][\"raw_val_ds\"].map(lambda x,y: (tf.repeat(tf.reshape(tf.py_function(\n            load_npz, [x, True], (tf.uint8,)\n        ), (*INPUT_SHAPE[:-1], 1))\/255, axis=-1, repeats=3), tf.cast(y, tf.uint8)), num_parallel_calls=tf.data.AUTOTUNE)\n        dataset_storage[col_identifier][\"val_ds\"] = dataset_storage[col_identifier][\"val_ds\"].batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\n        dataset_storage[col_identifier][\"test_ds\"] = dataset_storage[col_identifier][\"raw_test_ds\"].map(lambda x,y: (tf.repeat(tf.reshape(tf.py_function(\n            load_npz, [x, True], (tf.uint8,)\n        ), (*INPUT_SHAPE[:-1], 1))\/255, axis=-1, repeats=3), tf.cast(y, tf.int32)), num_parallel_calls=tf.data.AUTOTUNE)\n        dataset_storage[col_identifier][\"test_ds\"] = dataset_storage[col_identifier][\"test_ds\"].batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n    else:\n        dataset_storage[col_identifier][\"train_ds\"] = dataset_storage[col_identifier][\"raw_train_ds\"].map(lambda x,y: (tf.reshape(tf.py_function(\n            load_npz, [x, True], (tf.uint8,)\n        ), INPUT_SHAPE)\/255, tf.cast(y, tf.uint8)), num_parallel_calls=tf.data.AUTOTUNE)\n        dataset_storage[col_identifier][\"train_ds\"] = dataset_storage[col_identifier][\"train_ds\"].shuffle(BATCH_SIZE*5).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\n        dataset_storage[col_identifier][\"val_ds\"] = dataset_storage[col_identifier][\"raw_val_ds\"].map(lambda x,y: (tf.reshape(tf.py_function(\n            load_npz, [x, True], (tf.uint8,)\n        ), INPUT_SHAPE)\/255, tf.cast(y, tf.uint8)), num_parallel_calls=tf.data.AUTOTUNE)\n        dataset_storage[col_identifier][\"val_ds\"] = dataset_storage[col_identifier][\"val_ds\"].batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\n        dataset_storage[col_identifier][\"test_ds\"] = dataset_storage[col_identifier][\"raw_test_ds\"].map(lambda x,y: (tf.reshape(tf.py_function(\n            load_npz, [x, True], (tf.uint8,)\n        ), INPUT_SHAPE)\/255, tf.cast(y, tf.int32)), num_parallel_calls=tf.data.AUTOTUNE)\n        dataset_storage[col_identifier][\"test_ds\"] = dataset_storage[col_identifier][\"test_ds\"].batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\nfor k, v in dataset_storage.items():\n    print(f\"\\n\\n... SCAN TYPE: {k.upper()}\")\n    print(\"\\t-->\", v[\"train_ds\"])\n    print(\"\\t-->\", v[\"val_ds\"])\n    print(\"\\t-->\", v[\"test_ds\"])\nprint(\"\\n\")","3a594f20":"def plot_batch(dataset):\n    r_idx = int(random.random()*BATCH_SIZE)\n    \n    img, lbl = next(iter(dataset))\n    \n    img = tf.squeeze(img[r_idx])\n    lbl = lbl[r_idx]\n    \n    plt.figure(figsize=(20,10.5), )\n    plt.suptitle(f\"LABEL = {label_map_int_2_str[lbl.numpy()]} ({lbl.numpy()})\", fontsize=20, fontweight=\"bold\")\n    for i in range(img.shape[-1]):\n        plt.subplot(4,8,i+1)\n        plt.imshow(img[..., i], cmap=\"gray\")\n        plt.axis(False)\n    \n    plt.tight_layout(h_pad=0.025, w_pad=0.025)\n    # plt.subplots_adjust(wspace=0.001, hspace=0.001)\n    plt.show()\n    \n\nfor k, v in dataset_storage.items():\n    print(\"\\n\\n\\n\\n\\n\\n\"+\"-\"*35)\n    print(\"-\"*35)\n    print(f\"\\t SCAN TYPE: {k.upper()}\")\n    print(\"-\"*35)\n    print(\"-\"*35,\"\\n\\n\")\n    \n    print(f\"\\n\\n... DEMO TRAIN {k.upper()} EXAMPLE ...\\n\\n\")\n    plot_batch(v[\"train_ds\"])\n    \n    print(f\"\\n\\n... DEMO VALIDATION {k.upper()} EXAMPLE ...\\n\\n\")\n    plot_batch(v[\"val_ds\"])\n\nprint(\"\\n\")","b77253cc":"# Learning Rate\nMAX_STEPS = 20000\nINIT_LR = 0.00015\nDECAY_RATE = 0.98\nDECAY_STEPS = int((len(train_df)\/BATCH_SIZE)*5) # 5 epochs = 1 decay\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    INIT_LR, decay_steps=DECAY_STEPS, decay_rate=DECAY_RATE, staircase=True\n)\n\n# Plot Learning Rate\nplt.figure(figsize=(10,10))\nplt.plot(range(0, MAX_STEPS, int(len(train_df)\/BATCH_SIZE)), [lr_schedule(i) for i in range(0, MAX_STEPS, int(len(train_df)\/BATCH_SIZE))], linewidth=3)\nplt.vlines(range(int(len(train_df)\/BATCH_SIZE*5), MAX_STEPS, int(len(train_df)\/BATCH_SIZE*5)), ymin=0, ymax=INIT_LR, linestyles=\"dotted\", colors='gray')\nplt.vlines(range(int(len(train_df)\/BATCH_SIZE*50), MAX_STEPS, int(len(train_df)\/BATCH_SIZE*50)), ymin=0, ymax=INIT_LR, colors='r')\nplt.title(\"Learning Rate\\nDotted Lines At Every 5 Epochs (~350 steps)\\nSolid Red Lines At Every 50 Epochs\", fontweight=\"bold\")\nplt.show()","d15f1152":"# Compile model\nN_EPOCHS=250\nPATIENCE=50\n\nhistories = {}\nfor model_style, model in models.items():\n    print(\"\\n\\n\\n\\n\\n\\n\\n\\n\")\n    print(\"-\"*80)\n    print(\"-\"*20+\"\\t\"+f\"{model_style.upper()} TRAINING LOOP\"+\"\\t\"+\"-\"*20)\n    print(\"-\"*80)\n    print(\"\\n\\n\\n\")\n    \n    # Get datasets\n    train_ds = dataset_storage[model_style][\"train_ds\"]\n    val_ds = dataset_storage[model_style][\"val_ds\"]\n    \n    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n        INIT_LR, decay_steps=DECAY_STEPS, decay_rate=DECAY_RATE, staircase=True\n    )\n\n    model.compile(\n        loss=\"binary_crossentropy\",\n        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n        metrics=[\"acc\", tf.keras.metrics.AUC(name=\"auc\")],\n    )\n\n    # Define callbacks.\n    CKPT_DIR = os.path.join(\"\/kaggle\/working\/model_files\", model_style)\n    if not os.path.isdir(CKPT_DIR): \n        os.makedirs(CKPT_DIR, exist_ok=True)\n    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n        os.path.join(CKPT_DIR, \"epoch_{epoch:02d}--val_loss_{val_loss:.2f}--val_auc_{val_auc:.2f}\"), \n        save_best_only=True, monitor=\"val_auc\", mode=\"max\",\n    )\n    early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", patience=PATIENCE, restore_best_weights=True, mode=\"max\")\n    \n    # Train the model, doing validation at the end of each epoch\n    history = model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=N_EPOCHS,\n        callbacks=[checkpoint_cb, early_stopping_cb],\n    )\n    histories[model_style] = history","84b5933c":"histories","f660d887":"model_preds_dfs = {}\nfor model_style, model in tqdm(models.items(), total=4):\n    model_preds_dfs[model_style] = pd.DataFrame()\n    model_preds_dfs[model_style][\"BraTS21ID\"] = flatten_l_o_l([x.tolist() for x in list(dataset_storage[model_style][\"test_ds\"].map(lambda x,y: y).as_numpy_iterator())])\n    model_preds_dfs[model_style][model_style+\"_MGMT_value\"] = tf.squeeze(model.predict(dataset_storage[model_style][\"test_ds\"].map(lambda x,y: x)))\n    \nss_df = ss_df[[\"BraTS21ID\"]]\nfor style, style_df in model_preds_dfs.items():\n    ss_df = pd.merge(ss_df, style_df, on=\"BraTS21ID\", how=\"left\")\nss_df[[\"BraTS21ID\", \"flair_MGMT_value\", \"t1w_MGMT_value\", \"t1wce_MGMT_value\", \"t2w_MGMT_value\"]].to_csv(\"submission.csv\", index=False)\ndisplay(ss_df)","1f515b37":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #CD0001; background-color: #ffffff;\">4.5  CAPTURE ALL OPTIONS AND VALUE COUNTS FOR DICOM<\/h2>\n\n---\n\n<br>\n\nWe will not be capturing dicom metadata for UIDs or PixelData (this would cause OOM issues).\n\n<div class=\"alert alert-block alert-danger\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <br><center><b style=\"font-size: 16px;\">\u23f1\u23f1\u23f1 &nbsp; NOTE: THIS CELL WILL TAKE ~15 MINUTES TO RUN  &nbsp; \u23f1\u23f1\u23f1<\/b><\/center><br>\n<\/div>\n","2ecfa97a":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #CD0001; background-color: #ffffff;\">5.2  UPDATE THE TRAIN DATAFRAME<\/h2>\n\n---","03da4c64":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #CD0001; background-color: #ffffff;\">6.2  CREATE THE DATASETS<\/h2>\n\n---","7d2c8578":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #CD0001; background-color: #ffffff;\">6.5  TRAINING LOOP<\/h2>\n\n---","c89407e1":"<br>\n\n<a id=\"helper_functions\"><\/a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: #CD0001; background-color: #ffffff;\" id=\"dicom_understanding\">4&nbsp;&nbsp;DICOM UNDERSTANDING<\/h1>","e722004a":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #CD0001; background-color: #ffffff;\">4.3  BASIC STRUCTURE OF T1WCE DICOM<\/h2>\n\n---\n\n<br>\n\nThis dicom has an additional two fields that the other dicoms don't have:\n* **`InPlanePhaseEncodingDirection`**\n* **`InStackPositionNumber`**","0af09288":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #CD0001; background-color: #ffffff;\">5.3  VISUALIZE A RANDOM SCAN<\/h2>\n\n---","8eb81728":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #CD0001; background-color: #ffffff;\">6.4  LEARNING RATE FUNCTION\/PLOT<\/h2>\n\n---","ae8add81":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #CD0001; background-color: #ffffff;\">6.3  VISUALIZE A FEW EXAMPLES<\/h2>\n\n---","8dfc3e5f":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #CD0001; background-color: #ffffff;\">1.1  OVERVIEW<\/h2>\n\n---\n\n<b style=\"text-decoration: underline; font-family: Verdana;\">COMPETITION DESCRIPTION<\/b>\n\nA malignant tumor in the brain is a life-threatening condition. Known as glioblastoma, it's both the most common form of brain cancer in adults and the one with the worst prognosis, with median survival being less than a year. The presence of a specific genetic sequence in the tumor known as MGMT promoter methylation has been shown to be a favorable prognostic factor and a strong predictor of responsiveness to chemotherapy.\n\nCurrently, genetic analysis of cancer requires surgery to extract a tissue sample. Then it can take several weeks to determine the genetic characterization of the tumor. Depending upon the results and type of initial therapy chosen, a subsequent surgery may be necessary. If an accurate method to predict the genetics of the cancer through imaging (i.e., radiogenomics) alone could be developed, this would potentially minimize the number of surgeries and refine the type of therapy required.\n\nThe Radiological Society of North America (RSNA) has teamed up with the Medical Image Computing and Computer Assisted Intervention Society (the MICCAI Society) to improve diagnosis and treatment planning for patients with glioblastoma. In this competition you will predict the genetic subtype of glioblastoma using MRI (magnetic resonance imaging) scans to train and test your model to detect for the presence of MGMT promoter methylation.\n\nIf successful, you'll help brain cancer patients receive less invasive diagnoses and treatments. The introduction of new and customized treatment strategies before surgery has the potential to improve the management, survival, and prospects of patients with brain cancer.\n\n**Secondary Description From UPenn**\n> The participants are called to use the provided mpMRI data to extract imaging\/radiomic features that they consider appropriate, and analyze them through machine learning algorithms, in an attempt to predict the MGMT promoter methylation status. The participants do not need to be limited to volumetric parameters, but can also consider intensity, morphologic, histogram-based, and textural features, as well as spatial information, deep learning features, and glioma diffusion properties extracted from glioma growth models.\n\n> Note that participants will be evaluated for the predicted MGMT status of the subjects indicated in the accompanying spreadsheet.\n\n<br>\n\n<div class=\"alert alert-block alert-info\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <br><center><b style=\"font-size: 16px;\">\ud83e\udd14\ud83e\udd14\ud83e\udd14 &nbsp; MY INTERPRETATION OF THIS COMPETITION &nbsp; \ud83e\udd14\ud83e\udd14\ud83e\udd14<\/b><\/center><br><br><b style=\"font-size: 12px; color: black;\">In this competition we are tasked with identifying\/predicting the <i>genetic subtype <font color=\"darkred\">(genetic subtype = a group of tumors that is enriched for genetic aberrations in a set of subtype predictor genes)<\/font><\/i> of <i>glioblastoma <font color=\"darkred\">(glioblastoma = brain tumor)<\/font><\/i><br><br>HUH?!?!?<br><br>All this means is that we are taking in dicom images containing 3D representations (slices) of a patients brain which we will process with computer vision algorithms to allow us to perform binary classification. The binary classification is to identify if, within the patients image data, MGMT promoter methylation is present. The diagram below shows a simple, if slightly inaccurate, representation of what is required.<\/b><br><br><center><img src=\"https:\/\/www.researchgate.net\/profile\/Qi-Dou-2\/publication\/313019762\/figure\/fig2\/AS:691329537433601@1541837214995\/The-hierarchical-architecture-of-the-3D-CNN-model.png\" width=50%><\/center><br>\n<\/div>\n\n---\n\n<br>\n\n<b style=\"text-decoration: underline; font-family: Verdana;\">SUBMISSION EVALUATION\/RESTRICTIONS AND FILE FORMAT<\/b>\n\n**Submission Evaluation**\n* Submissions are evaluated on the [area under the ROC curve](http:\/\/en.wikipedia.org\/wiki\/Receiver_operating_characteristic) between the predicted probability and the observed target.\n\n<br>\n\n**Submission Restrictions**\n* **THIS IS A KERNELS ONLY COMPETITION**\n    * Submissions to this competition must be made through Notebooks. \n    * In order for the \"Submit\" button to be active after a commit, the following conditions must be met:\n        * *CPU Notebook <= 9 hours run-time*\n        * *GPU Notebook <= 9 hours run-time*\n        * *Internet access disabled*\n        * *Freely & publicly available external data is allowed, including pre-trained models*\n        * *Submission file must be named `submission.csv`*\n\n<br>\n\n**Submission File Format**\n* For each **`BraTS21ID`** in the test set, you must predict a probability for the target **`MGMT_value`**. The file should contain a header and have the following format:\n>```\n>BraTS21ID,MGMT_value\n>00001,0.5\n>00013,0.999\n>00015,0.1\n>etc.\n>```\n\n<br>\n\n---\n\n<br>\n\n<b style=\"text-decoration: underline; font-family: Verdana;\">COMPETITION TIMELINE<\/b>\n\n* **July 13, 2021** - Start Date.\n* **October 8, 2021** - Entry Deadline. You must accept the competition rules before this date in order to compete.\n* **October 8, 2021** - Team Merger Deadline. This is the last day participants may join or merge teams.\n* **October 15, 2021** - Final Submission Deadline.\n* **October 25, 2021** - Winners\u2019 Requirements Deadline. This is the deadline for winners to submit to the host\/Kaggle their training code, video, method description.\n\n> All deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\n","34feb35b":"<br>\n\n<a id=\"helper_functions\"><\/a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: #CD0001; background-color: #ffffff;\" id=\"helper_functions\">3&nbsp;&nbsp;HELPER FUNCTIONS<\/h1>","a281cc98":"<br>\n\n<a id=\"setup\"><\/a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: #CD0001; background-color: #ffffff;\" id=\"setup\">2&nbsp;&nbsp;SETUP<\/h1>","6bc5acc9":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #CD0001; background-color: #ffffff;\">4.4  BASIC STRUCTURE OF T2W DICOM<\/h2>\n\n---\n\n<br>\n","c2df6537":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: #CD0001; background-color: #ffffff;\">TABLE OF CONTENTS<\/h2>\n\n---\n\n<h2 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkred; background-color: #ffffff;\"><a href=\"#imports\">0&nbsp;&nbsp;&nbsp;&nbsp;IMPORTS<\/a><\/h2>\n\n---\n\n<h2 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkred; background-color: #ffffff;\"><a href=\"#background_information\">1&nbsp;&nbsp;&nbsp;&nbsp;BACKGROUND INFORMATION<\/a><\/h2>\n\n---\n\n<h2 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkred; background-color: #ffffff;\"><a href=\"#setup\">2&nbsp;&nbsp;&nbsp;&nbsp;SETUP<\/a><\/h2>\n\n---\n\n<h2 style=\"text-indent: 10vw; font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: darkred; background-color: #ffffff;\"><a href=\"#helper_functions\">3&nbsp;&nbsp;&nbsp;&nbsp;HELPER FUNCTIONS<\/a><\/h2>\n\n---\n","e8ba3941":"<br>\n\n<img src=\"https:\/\/i.ibb.co\/tYfwcwC\/header-1.png\" width=\"100%\">\n\n<br>\n\n---\n\n<br>\n\n<center><h2 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: #CD0001; background-color: #ffffff;\">EXPLORATORY DATA ANALSYSIS AND SOLUTIONING<\/h2><h4 style=\"font-family: Verdana; font-size: 18px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 2px; color: black; background-color: #ffffff;\">TOWARDS BRAIN TUMOR RADIOGENOMIC CLASSIFICATION<\/h4><\/center>\n\n<br>\n    \n<h5 style=\"text-align: center; font-family: Verdana; font-size: 14px; font-style: normal; font-weight: bold; text-decoration: None; text-transform: none; letter-spacing: 1px; color: black; background-color: #ffffff;\">CREATED BY: DARIEN SCHETTLER<\/h5><br>\n\n---\n\n<br>\n\n<div class=\"alert alert-block alert-danger\" style=\"margin: 2em; line-height: 1.7em; font-family: Verdana;\">\n    <br><center><b style=\"font-size: 16px;\">\ud83d\uded1\ud83d\uded1\ud83d\uded1 &nbsp; CAUTION:  THIS NOTEBOOK IS A WORK IN PROGRESS  &nbsp; \ud83d\uded1\ud83d\uded1\ud83d\uded1<\/b><\/center><br>\n<\/div>\n\n<br>\n\n\n---\n<br>","54ff5394":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #CD0001; background-color: #ffffff;\">6.6  PLOT MODEL TRAINING<\/h2>\n\n---\n\nhTBD","ae886fa4":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #CD0001; background-color: #ffffff;\">1.2  DATA DESCRIPTION<\/h2>\n\n---\n\n<br>\n\n<b style=\"text-decoration: underline; font-family: Verdana;\">DATA SPLITS\/COHORTS<\/b>\n\nThe competition data is defined by three cohorts: **Training**, **Validation (Public)**, and **Testing (Private)**. \n* The **\u201cTraining\u201d** and the **\u201cValidation\u201d** cohorts are provided to the participants\n* The **\u201cTesting\u201d** cohort is kept hidden at all times, during and after the competition\n\nThese 3 cohorts are structured as follows: \n* Each independent case has a **dedicated folder identified by a five-digit number**.\n* Within each of these **\u201ccase\u201d** folders, there are four sub-folders\n    * Each of these **\"case\"** subfolders corresponds to each of the structural **m**ulti-**p**arametric **MRI** (**mpMRI**) scans, in **DICOM** format. \n    * The exact mpMRI scans included are:\n        * Fluid Attenuated Inversion Recovery (FLAIR)\n        * T1-weighted pre-contrast (T1w)\n        * T1-weighted post-contrast (T1Gd)\n        * T2-weighted (T2)\n\nExact folder structure:\n\n```\nTraining\/Validation\/Testing\n\u2502\n\u2514\u2500\u2500\u2500 00000\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500 FLAIR\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 ...\n\u2502   \u2502   \n\u2502   \u2514\u2500\u2500\u2500 T1w\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 ...\n\u2502   \u2502   \n\u2502   \u2514\u2500\u2500\u2500 T1wCE\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 ...\n\u2502   \u2502   \n\u2502   \u2514\u2500\u2500\u2500 T2w\n\u2502   \u2502   \u2502 Image-1.dcm\n\u2502   \u2502   \u2502 Image-2.dcm\n\u2502   \u2502   \u2502 .....\n\u2502   \n\u2514\u2500\u2500\u2500 00001\n\u2502   \u2502 ...\n\u2502   \n\u2502 ...   \n\u2502   \n\u2514\u2500\u2500\u2500 00002\n\u2502   \u2502 ...\n\n```\n\n<b style=\"text-decoration: underline; font-family: Verdana;\">FILES<\/b>\n\n**`train\/`** \n- folder containing the training files, with each top-level folder representing a subject\n\n**`train_labels.csv`** \n- file containing the target MGMT_value for each subject in the training data (e.g. the presence of MGMT promoter methylation)\n\n**`test\/`** \n- the test files, which use the same structure as train\/; your task is to predict the MGMT_value for each subject in the test data. NOTE: the total size of the rerun test set (Public and Private) is ~5x the size of the Public test set\n\n**`sample_submission.csv`** \n- a sample submission file in the correct format","965a6714":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #CD0001; background-color: #ffffff;\">4.2  BASIC STRUCTURE OF T1W DICOM<\/h2>\n\n---\n\n<br>\n","9a8dfc6c":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #CD0001; background-color: #ffffff;\">4.6  PERFORM ANALYSIS ON EACH COLUMN<\/h2>\n\n---\n\nWe will first identify all of the possible values (including NaN) for a given attribute as well as their respective occurence counts.","27a7617c":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #CD0001; background-color: #ffffff;\">4.0 SET EXAMPLE PATIENT DATA<\/h2>\n\n---\n\n<br>\n","a0127238":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #CD0001; background-color: #ffffff;\">4.1  BASIC STRUCTURE OF FLAIR DICOM<\/h2>\n\n---\n\n<br>\n","2ff2f277":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #CD0001; background-color: #ffffff;\">5.1  SETUP FILE PATHS<\/h2>\n\n---","a90420d6":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #CD0001; background-color: #ffffff;\">6.1 CREATE THE MODELS<\/h2>\n\n---\n\n<br>\n\nOne for each type of scan\n\n<br>","b2288688":"<br>\n\n<a id=\"background_information\"><\/a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: #CD0001; background-color: #ffffff;\" id=\"modelling\">6&nbsp;&nbsp;MODELLING<\/h1>","54484187":"<br>\n\n<a id=\"background_information\"><\/a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: #CD0001; background-color: #ffffff;\" id=\"background_information\">1&nbsp;&nbsp;BACKGROUND INFORMATION<\/h1>","1ad85a57":"<br>\n\n<a id=\"helper_functions\"><\/a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: #CD0001; background-color: #ffffff;\" id=\"3d_numpy\">5&nbsp;&nbsp;LOAD 3D REPRESENTATIONS OF EXAMPLES<\/h1>\n\nI have gone ahead and created 3D numpy arrays containing the images interpolated to a fixed size (512,512,128) or (128,128,32). Please see this notebook for details on how this was completed.\n\n<br>\n\n**NOTE SOME IDS DO NOT POSSESS RESPECTIVE SCANS WITH NON-ZERO VALUES**\n* FLAIR --> ['00709.npz', '00109.npz']\n* T1w   --> ['00123.npz']\n* T1wCE --> []\n* T2w   --> ['00123.npz']","8e0fcd5f":"<br>\n\n<h2 style=\"font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: #CD0001; background-color: #ffffff;\">6.7  MODEL PREDICTIONS<\/h2>\n\n---","7be48704":"<br>\n\n<a id=\"imports\"><\/a>\n\n<h1 style=\"font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; background-color: #ffffff; color: #CD0001;\" id=\"imports\">0&nbsp;&nbsp;IMPORTS<\/h1>"}}