{"cell_type":{"7613bf83":"code","69a7e05e":"code","cc1cdfa4":"code","66c892bb":"code","878f3556":"code","db7314a0":"code","b3074dbc":"code","9b58e039":"code","ccd6f958":"code","a7ffa490":"code","ca8700ac":"code","d83058dd":"code","ef6983aa":"code","ce201433":"code","75f0e482":"code","f5d8ba28":"code","03bc9d84":"code","9aac6b7f":"code","4f4a10d9":"code","a8e8bb53":"code","de11ff16":"code","09ea911b":"code","b04ab8cd":"code","5e58dedf":"code","cdbe1fe8":"code","2bfa040a":"code","2911073b":"code","3ee27084":"code","4d6f1cf7":"code","86cca8b2":"code","012e7fee":"code","5b9ae76c":"code","bc830548":"code","b538aa57":"code","04b0acfd":"code","d10f1440":"code","6bc208e8":"code","37e00755":"code","ef8f3762":"code","b102cffc":"code","3e31b5af":"code","697df7d0":"code","27e76fdd":"code","0cb264ca":"code","9282ee15":"code","2afff1a4":"markdown","b83fcb51":"markdown","5f82c3f8":"markdown","aaaae26d":"markdown","904c82c3":"markdown","d0370985":"markdown","294c6d92":"markdown","71ed572f":"markdown","7c0874bb":"markdown","9677855b":"markdown","8e9a230d":"markdown","70d7f987":"markdown","bbcd6124":"markdown","c8d506b5":"markdown","18754be2":"markdown","e6d4d6dd":"markdown","d0e39a41":"markdown","be5fedda":"markdown","15b4b95b":"markdown","ee7175a7":"markdown","5bcb3191":"markdown","23b208e8":"markdown","26300830":"markdown","54eafe69":"markdown","bf686280":"markdown","1e145323":"markdown","9a5900be":"markdown","cc1bafcc":"markdown","ce8017c0":"markdown","3239129a":"markdown","3abd8d37":"markdown","4da7b47c":"markdown","323b94a8":"markdown"},"source":{"7613bf83":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom glob import glob\nimport os\nimport matplotlib.gridspec as gridspec\nimport matplotlib.ticker as ticker\nsns.set_style('whitegrid')\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","69a7e05e":"import os\ninpath = \"..\/input\/224_v2\/224_v2\/\"\nprint(os.listdir(\"..\/input\/224_v2\/224_v2\"))","cc1cdfa4":"# reading the data\ndata = pd.read_csv(\"..\/input\/224_v2\/224_v2\/Data_Entry_2017.csv\")\ndata.head()","66c892bb":"data.shape","878f3556":"data.describe()","db7314a0":"#drop unused columns\ndata = data[['Image Index','Finding Labels','Follow-up #','Patient ID','Patient Age','Patient Gender']]\n\n# removing the rows which have patient_age >100\ntotal = len(data)\nprint('No. of rows before removing rows having age >100 : ',len(data))\ndata = data[data['Patient Age']<100]\nprint('No. of rows after removing rows having age >100 : ',len(data))\nprint('No. of datapoints having age > 100 : ',total-len(data))","b3074dbc":"# rows having no. of disease\ndata['Labels_Count'] = data['Finding Labels'].apply(lambda text: len(text.split('|')) if(text != 'No Finding') else 0)","9b58e039":"label_counts = data['Finding Labels'].value_counts()[:15]\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\n_ = ax1.set_xticklabels(label_counts.index, rotation = 90)","ccd6f958":"#plt.figure(figsize=(20,15))\nsns.FacetGrid(data,hue='Patient Gender',size=5).map(sns.distplot,'Patient Age').add_legend()\nplt.show()","a7ffa490":"g = sns.factorplot(x=\"Patient Age\", col=\"Patient Gender\",data=data, kind=\"count\",size=10, aspect=0.8,palette=\"GnBu_d\");\ng.set_xticklabels(np.arange(0,100));\ng.set_xticklabels(step=10);\ng.fig.suptitle('Age distribution by sex',fontsize=22);\ng.fig.subplots_adjust(top=.9)","ca8700ac":"f, axarr = plt.subplots(7, 2, sharex=True,figsize=(15, 20))\npathology_list = ['Cardiomegaly','Emphysema','Effusion','Hernia','Nodule','Pneumothorax','Atelectasis','Pleural_Thickening','Mass','Edema','Consolidation','Infiltration','Fibrosis','Pneumonia']\ndf = data[data['Finding Labels'] != 'No Finding']\ni=0\nj=0\nx=np.arange(0,100,10)\nfor pathology in pathology_list :\n    index = []\n    for k in range(len(df)):\n        if pathology in df.iloc[k]['Finding Labels']:\n            index.append(k)\n    g=sns.countplot(x='Patient Age', hue=\"Patient Gender\",data=df.iloc[index], ax=axarr[i, j])\n    axarr[i, j].set_title(pathology)   \n    g.set_xlim(0,90)\n    g.set_xticks(x)\n    g.set_xticklabels(x)\n    j=(j+1)%2\n    if j==0:\n        i=(i+1)%7\nf.subplots_adjust(hspace=0.3)","d83058dd":"for pathology in pathology_list :\n    data[pathology] = data['Finding Labels'].apply(lambda x: 1 if pathology in x else 0)","ef6983aa":"plt.figure(figsize=(15,10))\ngs = gridspec.GridSpec(8,1)\nax1 = plt.subplot(gs[:7, :])\nax2 = plt.subplot(gs[7, :])\ndata1 = pd.melt(data,\n             id_vars=['Patient Gender'],\n             value_vars = list(pathology_list),\n             var_name = 'Category',\n             value_name = 'Count')\ndata1 = data1.loc[data1.Count>0]\ng=sns.countplot(y='Category',hue='Patient Gender',data=data1, ax=ax1, order = data1['Category'].value_counts().index)\nax1.set( ylabel=\"\",xlabel=\"\")\nax1.legend(fontsize=20)\nax1.set_title('X Ray partition (total number = 121120)',fontsize=18);\n\ndata['Nothing']=data['Finding Labels'].apply(lambda x: 1 if 'No Finding' in x else 0)\n\ndata2 = pd.melt(data,\n             id_vars=['Patient Gender'],\n             value_vars = list(['Nothing']),\n             var_name = 'Category',\n             value_name = 'Count')\ndata2 = data2.loc[data2.Count>0]\ng=sns.countplot(y='Category',hue='Patient Gender',data=data2,ax=ax2)\nax2.set( ylabel=\"\",xlabel=\"Number of decease\")\nax2.legend('')\nplt.subplots_adjust(hspace=.5)","ce201433":"f, (ax1,ax2) = plt.subplots( 2, figsize=(15, 10))\n\ndf = data[data['Follow-up #']<15]\ng = sns.countplot(x='Follow-up #',data=df,palette=\"GnBu_d\",ax=ax1);\n\nax1.set_title('Follow-up distribution');\ndf = data[data['Follow-up #']>14]\ng = sns.countplot(x='Follow-up #',data=df,palette=\"GnBu_d\",ax=ax2);\nx=np.arange(15,100,10)\ng.set_ylim(15,450)\ng.set_xlim(15,100)\ng.set_xticks(x)\ng.set_xticklabels(x)\nf.subplots_adjust(top=1)","75f0e482":"df=data.groupby('Finding Labels').count().sort_values('Patient ID',ascending=False)\ndf1=df[['|' in index for index in df.index]].copy()\ndf2=df[['|' not in index for index in df.index]]\ndf2=df2[['No Finding' not in index for index in df2.index]]\ndf2['Finding Labels']=df2.index.values\ndf1['Finding Labels']=df1.index.values","f5d8ba28":"f, ax = plt.subplots(sharex=True,figsize=(15, 10))\nsns.set_color_codes(\"pastel\")\ng=sns.countplot(y='Category',data=data1, ax=ax, order = data1['Category'].value_counts().index,color='b',label=\"Multiple Pathologies\")\nsns.set_color_codes(\"muted\")\ng=sns.barplot(x='Patient ID',y='Finding Labels',data=df2, ax=ax, color=\"b\",label=\"Simple Pathology\")\nax.legend(ncol=2, loc=\"center right\", frameon=True,fontsize=20)\nax.set( ylabel=\"\",xlabel=\"Number of decease\")\nax.set_title(\"Comparaison between simple or multiple decease\",fontsize=20)      \nsns.despine(left=True)","03bc9d84":"#we just keep groups of pathologies which appear more than 30 times\ndf3=df1.loc[df1['Patient ID']>30,['Patient ID','Finding Labels']]\n\nfor pathology in pathology_list:\n    df3[pathology]=df3.apply(lambda x: x['Patient ID'] if pathology in x['Finding Labels'] else 0, axis=1)\n\ndf3.head(20)","9aac6b7f":"#'Hernia' has not enough values to figure here\ndf4=df3[df3['Hernia']>0]  # df4.size == 0\n#remove 'Hernia' from list\npat_list=[elem for elem in pathology_list if 'Hernia' not in elem]\n\nf, axarr = plt.subplots(13, sharex=True,figsize=(10, 140))\ni=0\nfor pathology in pat_list :\n    df4=df3[df3[pathology]>0]\n    if df4.size>0:  #'Hernia' has not enough values to figure here\n        axarr[i].pie(df4[pathology],labels=df4['Finding Labels'], autopct='%1.1f%%')\n        axarr[i].set_title('main desease : '+pathology,fontsize=14)   \n        i +=1\n","4f4a10d9":"data = pd.read_csv(inpath + 'Data_Entry_2017.csv')\ndata = data[data['Patient Age']<100] #removing datapoints which having age greater than 100\ndata_image_paths = {os.path.basename(x): x for x in \n                   glob(os.path.join(inpath, 'images', '*.png'))}\nprint('Scans found:', len(data_image_paths), ', Total Headers', data.shape[0])\ndata['path'] = data['Image Index'].map(data_image_paths.get)\ndata['Patient Age'] = data['Patient Age'].map(lambda x: int(x))\ndata.sample(3)","a8e8bb53":"data['Finding Labels'] = data['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\nfrom itertools import chain\nall_labels = np.unique(list(chain(*data['Finding Labels'].map(lambda x: x.split('|')).tolist())))\nall_labels = [x for x in all_labels if len(x)>0]\nprint('All Labels ({}): {}'.format(len(all_labels), all_labels))\nfor c_label in all_labels:\n    if len(c_label)>1: # leave out empty labels\n        data[c_label] = data['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\ndata.sample(3)","de11ff16":"# keep at least 1000 cases\nMIN_CASES = 1000\nall_labels = [c_label for c_label in all_labels if data[c_label].sum()>MIN_CASES]\nprint('Clean Labels ({})'.format(len(all_labels)), \n      [(c_label,int(data[c_label].sum())) for c_label in all_labels])\n","09ea911b":"# since the dataset is very unbiased, we can resample it to be a more reasonable collection\n# weight is 0.04 + number of findings\nsample_weights = data['Finding Labels'].map(lambda x: len(x.split('|')) if len(x)>0 else 0).values + 4e-2\nsample_weights \/= sample_weights.sum()\ndata = data.sample(40000, weights=sample_weights)\n\nlabel_counts = data['Finding Labels'].value_counts()[:15]\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\n_ = ax1.set_xticklabels(label_counts.index, rotation = 90)\n","b04ab8cd":"# creating vector of diseases\ndata['disease_vec'] = data.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])\n","5e58dedf":"print(data.iloc[0:5]['disease_vec'])\nprint(data.shape)\ndata[['Finding Labels','Atelectasis','Cardiomegaly','Consolidation','Edema','Effusion','Emphysema','Fibrosis','Hernia','Infiltration','Mass','Nodule','Pleural_Thickening','Pneumonia','Pneumothorax','disease_vec']].head()","cdbe1fe8":"from sklearn.model_selection import train_test_split\ntrain_df, valid_df = train_test_split(data, \n                                   test_size = 0.25, \n                                   random_state = 2018,\n                                   stratify = data['Finding Labels'].map(lambda x: x[:4]))\nprint('train', train_df.shape[0], 'validation', valid_df.shape[0])","2bfa040a":"from keras.preprocessing.image import ImageDataGenerator\nIMG_SIZE = (128, 128)\ncore_idg = ImageDataGenerator(samplewise_center=True, \n                              samplewise_std_normalization=True, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              height_shift_range= 0.05, \n                              width_shift_range=0.1, \n                              rotation_range=5, \n                              shear_range = 0.1,\n                              fill_mode = 'reflect',\n                              zoom_range=0.15)","2911073b":"def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen\n","3ee27084":"train_gen = flow_from_dataframe(core_idg, train_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = 32)\n\nvalid_gen = flow_from_dataframe(core_idg, valid_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = 256) # we can use much larger batches for evaluation\n# used a fixed dataset for evaluating the algorithm\ntest_X, test_Y = next(flow_from_dataframe(core_idg, \n                               valid_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = 1024)) # one big batch","4d6f1cf7":"t_x, t_y = next(train_gen)\nfig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone', vmin = -1.5, vmax = 1.5)\n    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(all_labels, c_y) \n                             if n_score>0.5]))\n    c_ax.axis('off')","86cca8b2":"from keras.applications.mobilenet import MobileNet\nfrom keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\nfrom keras.models import Sequential\nmobilenet_model = MobileNet(input_shape =  t_x.shape[1:], \n                                 include_top = False, weights = None)\nmulti_disease_model = Sequential()\nmulti_disease_model.add(mobilenet_model)\nmulti_disease_model.add(GlobalAveragePooling2D())\nmulti_disease_model.add(Dropout(0.5))\nmulti_disease_model.add(Dense(512))\nmulti_disease_model.add(Dropout(0.5))\nmulti_disease_model.add(Dense(len(all_labels), activation = 'sigmoid'))\nmulti_disease_model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n                           metrics = ['accuracy','binary_accuracy', 'mae'])\nmulti_disease_model.summary()","012e7fee":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nimport keras.callbacks as kcall\nweight_path=\"{}_weights.best.hdf5\".format('xray_class')\n\nclass LossHistory(kcall.Callback):\n    def on_train_begin(self, logs={}):\n        self.batch_losses = []\n        self.batch_acc = []\n        self.epochs_losses = []\n        self.epochs_acc = []\n        self.epochs_val_losses = []\n        self.epochs_val_acc = []\n    \n    def on_batch_end(self, batch, logs={}):\n        self.batch_losses.append(logs.get('loss'))\n        self.batch_acc.append(logs.get('acc'))\n    \n    def on_epoch_end(self, epoch, logs={}):\n        self.epochs_losses.append(logs.get('loss'))\n        self.epochs_acc.append(logs.get('acc'))\n        self.epochs_val_losses.append(logs.get('val_loss'))\n        self.epochs_val_acc.append(logs.get('val_acc'))\n\nhistory = LossHistory()\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=3)\ncallbacks_list = [checkpoint, early, history]","5b9ae76c":"multi_disease_model.fit_generator(train_gen, \n                                  steps_per_epoch=100,\n                                  validation_data = (test_X, test_Y), \n                                  epochs = 10, \n                                  callbacks = callbacks_list)","bc830548":"#Plots of losses\nplt.figure(figsize=[16,8])\nplt.subplot(2, 2, 1)\nplt.plot(history.batch_losses,'b--',label='Train',alpha=0.7)\n\n\nplt.xlabel('# of batches trained')\nplt.ylabel('Training loss')\n\nplt.title('1) Training loss vs batches trained')\nplt.legend()\nplt.ylim(0,1)\nplt.grid(True)\n\n\nplt.subplot(2, 2, 2)\nplt.plot(history.epochs_losses,'b--',label='Train',alpha=0.7)\nplt.plot(history.epochs_val_losses,'r-.',label='Val', alpha=0.7)\n\nplt.xlabel('# of epochs trained')\nplt.ylabel('Training loss')\n\nplt.title('2) Training loss vs epochs trained')\nplt.legend()\nplt.ylim(0,0.5)\nplt.grid(True)\n\n\n#Plots of acc\nplt.figure(figsize=[16,8])\nplt.subplot(2, 2, 1)\nplt.plot(history.batch_acc,'b--',label= 'Train', alpha=0.7)\n\nplt.xlabel('# of batches trained')\nplt.ylabel('Training accuracy')\n\nplt.title('3) Training accuracy vs batches trained')\nplt.legend(loc=3)\nplt.ylim(0,1.1)\nplt.grid(True)\n\n\nplt.subplot(2, 2, 2)\nplt.plot(history.epochs_acc,'b--',label= 'Train', alpha=0.7)\nplt.plot(history.epochs_val_acc,'r-.',label= 'Val', alpha=0.7)\n\nplt.xlabel('# of epochs trained')\nplt.ylabel('Training accuracy')\n\nplt.title('4) Training accuracy vs epochs trained')\nplt.legend(loc=3)\nplt.ylim(0.5,1)\nplt.grid(True)","b538aa57":"for c_label, s_count in zip(all_labels, 100*np.mean(test_Y,0)):\n    print('%s: %2.2f%%' % (c_label, s_count))","04b0acfd":"pred_Y = multi_disease_model.predict(test_X, batch_size = 32, verbose = True)","d10f1440":"from sklearn.metrics import roc_curve, auc\nfig, c_ax = plt.subplots(1,1, figsize = (9, 9))\nfor (idx, c_label) in enumerate(all_labels):\n    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\nc_ax.legend()\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nfig.savefig('barely_trained_net.png')","6bc208e8":"multi_disease_model.fit_generator(train_gen, \n                                  steps_per_epoch = 100,\n                                  validation_data =  (test_X, test_Y), \n                                  epochs = 5, \n                                  callbacks = callbacks_list)","37e00755":"# load the best weights\nmulti_disease_model.load_weights(weight_path)","ef8f3762":"pred_Y = multi_disease_model.predict(test_X, batch_size = 32, verbose = True)","b102cffc":"#Plots of losses\nplt.figure(figsize=[16,8])\nplt.subplot(2, 2, 1)\nplt.plot(history.batch_losses,'b--',label='Training',alpha=0.7)\n\n\nplt.xlabel('# of batches trained')\nplt.ylabel('Training loss')\n\nplt.title('Training loss vs batches trained')\nplt.legend()\nplt.ylim(0,1.5)\nplt.grid(True)\n\n\nplt.subplot(2, 2, 2)\nplt.plot(history.epochs_losses,'b--',label='Training',alpha=0.7)\nplt.plot(history.epochs_val_losses,'r-.',label='Val', alpha=0.7)\n\nplt.xlabel('# of epochs trained')\nplt.ylabel('Training loss')\n\nplt.title('Training loss vs epochs trained')\nplt.legend()\nplt.ylim(0,1.5)\nplt.grid(True)\n\n\n#Plots of acc\nplt.figure(figsize=[16,8])\nplt.subplot(2, 2, 1)\nplt.plot(history.batch_acc,'b--',label= 'Training', alpha=0.7)\n\nplt.xlabel('# of batches trained')\nplt.ylabel('Training accuracy')\n\nplt.title('Training accuracy vs batches trained')\nplt.legend(loc=3)\nplt.ylim(0,1.1)\nplt.grid(True)\n\n\nplt.subplot(2, 2, 2)\nplt.plot(history.epochs_acc,'b--',label= 'Training', alpha=0.7)\nplt.plot(history.epochs_val_acc,'r-.',label= 'Val', alpha=0.7)\n\nplt.xlabel('# of epochs trained')\nplt.ylabel('Training accuracy')\n\nplt.title('Training accuracy vs epochs trained')\nplt.legend(loc=3)\nplt.ylim(0,1.1)\nplt.grid(True)","3e31b5af":"# look at how often the algorithm predicts certain diagnoses \nfor c_label, p_count, t_count in zip(all_labels, \n                                     100*np.mean(pred_Y,0), \n                                     100*np.mean(test_Y,0)):\n    print('%s: Dx: %2.2f%%, PDx: %2.2f%%' % (c_label, t_count, p_count))","697df7d0":"from sklearn.metrics import roc_curve, auc\nfig, c_ax = plt.subplots(1,1, figsize = (9, 9))\nfor (idx, c_label) in enumerate(all_labels):\n    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\nc_ax.legend()\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nfig.savefig('trained_net.png')","27e76fdd":"row = 670\nprint(*['{})'.format(i) for i in range(13)], sep='\\t')\nprint(*test_Y[row], sep='\\t', end='\\tTrue\\n')\nsumatoria = np.sum(pred_Y[row])\nprint(sumatoria)\npred = [\"%.2f\"%item for item in pred_Y[row]]\nprint(*pred, sep='\\t', end='\\tPredict\\n\\n')\nprint(*['{}){}'.format(i,l) for i,l in enumerate(all_labels)], sep='\\n')","0cb264ca":"pred_Y[660]","9282ee15":"sickest_idx = np.argsort(np.sum(test_Y, 1)<1)\nfig, m_axs = plt.subplots(10, 4, figsize = (16, 32))\nfor (idx, c_ax) in zip(sickest_idx, m_axs.flatten()):\n    c_ax.imshow(test_X[idx, :,:,0], cmap = 'bone')\n    stat_str = [n_class[:4] for n_class, n_score in zip(all_labels, \n                                                                  test_Y[idx]) \n                             if n_score>0.5]\n    pred_str = ['%s:%2.0f%%' % (n_class[:4], p_score*100)  for n_class, n_score, p_score in zip(all_labels, \n                                                                  test_Y[idx], pred_Y[idx]) \n                             if (n_score>0.5) or (p_score>0.5)]\n    c_ax.set_title('{} Dx: '.format(idx)+', '.join(stat_str)+'\\nPDx: '+', '.join(pred_str))\n    c_ax.axis('off')\nfig.savefig('trained_img_predictions.png')","2afff1a4":"<h2> 3.2 Data cleaning <\/h2>","b83fcb51":"### Check Output\n\nHere we see how many positive examples we have of each category\n","5f82c3f8":"<h2> 1.2 Source \/ useful links <\/h2>","aaaae26d":"### Show a few images and associated predictions","904c82c3":"## National Institutes of Health Chest X-Ray Dataset\n\nChest X-ray exams are one of the most frequent and cost-effective medical imaging examinations available. However, clinical diagnosis of a chest X-ray can be challenging and sometimes more difficult than diagnosis via chest CT imaging. The lack of large publicly available datasets with annotations means it is still very difficult, if not impossible, to achieve clinically relevant computer-aided detection and diagnosis (CAD) in real world medical sites with chest X-rays. One major hurdle in creating large X-ray image datasets is the lack resources for labeling so many images. Prior to the release of this dataset, Openi was the largest publicly available source of chest X-ray images with 4,143 images available.\n\nThis NIH Chest X-ray Dataset is comprised of 112,120 X-ray images with disease labels from 30,805 unique patients. To create these labels, the authors used Natural Language Processing to text-mine disease classifications from the associated radiological reports. The labels are expected to be >90% accurate and suitable for weakly-supervised learning. The original radiology reports are not publicly available but you can find more details on the labeling process in this Open Access paper: \"ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases.\" (Wang et al.)","d0370985":"### Continued Training\n\nNow we do a much longer training process to see how the results improve\n","294c6d92":"# NIH Chest X-ray Dataset","71ed572f":"<h3> 3.3.4 Display patient number by Follow-up in details <\/h3>","7c0874bb":"<h2> 3.1 Data Loading <\/h2>","9677855b":"\n### Goal\n\nThe goal is to use a simple model to classify x-ray images in Keras, the notebook how to use the flow_from_dataframe to deal with messier datasets\n","8e9a230d":"<h2> 3.3 Data analysis <\/h2>","70d7f987":"<h3> 3.3.1 Age distribution <\/h3>","bbcd6124":"<h1> 4. Creating data for model <\/h1>","c8d506b5":"**Class descriptions**\n\nThere are 15 classes (14 diseases, and one for \"No findings\"). Images can be classified as \"No findings\" or one or more disease classes:\n\n- Atelectasis\n- Consolidation\n- Infiltration\n- Pneumothorax\n- Edema\n- Emphysema\n- Fibrosis\n- Effusion\n- Pneumonia\n- Pleural_thickening\n- Cardiomegaly\n-  Nodule Mass\n-  Hernia\n","18754be2":"### Create a simple model\n\nHere we make a simple model to train using MobileNet as a base and then adding a GAP layer (Flatten could also be added), dropout, and a fully-connected layer to calculate specific features\n","e6d4d6dd":"Data Source : https:\/\/www.kaggle.com\/nih-chest-xrays\/data\/home <br>\nResearch paper : http:\/\/openaccess.thecvf.com\/content_cvpr_2017\/papers\/Wang_ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf <br>\nResearch paper : https:\/\/lukeoakdenrayner.wordpress.com\/2017\/12\/18\/the-chestxray14-dataset-problems\/ <br>\nResearch paper : https:\/\/arxiv.org\/pdf\/1711.05225.pdf <br>\nBlog : https:\/\/lukeoakdenrayner.wordpress.com\/2018\/01\/24\/chexnet-an-in-depth-review\/","d0e39a41":"<h3> 3.3.2 Disease distribution by age and sex <\/h3>","be5fedda":"**BBox_list_2017.csv: **Bounding box coordinates. Note: Start at x,y, extend horizontally w pixels, and vertically h pixels\n\n- Image Index: File name\n- Finding Label: Disease type (Class label)\n- Bbox x\n- Bbox y\n- Bbox w\n- Bbox h","15b4b95b":"<h3> 3.3.5 ratio between one and multiple disease <\/h3>","ee7175a7":"### File contents\nImage format: 112,120 total images with size 1024 x 1024","5bcb3191":"### ROC Curves\n\nWhile a very oversimplified metric, we can show the ROC curve for each metric\n","23b208e8":"<h3> 3.3.3 No. of each disease by patient gender <\/h3>","26300830":"<h2> 1.1 Description <\/h2>","54eafe69":"### First Round\n\nHere we do a first round of training to get a few initial low hanging fruit results\n","bf686280":"<h2> 2.1 Data <\/h2>","1e145323":"- 1. No strict latency constraints.","9a5900be":"<h2> 1.3 Real World \/ Business Objectives and Constraints <\/h2>","cc1bafcc":"<h1>1. Business Problem <\/h1>","ce8017c0":"#### Observation - Both the gender have almost same distribution","3239129a":"<h3> 3.3.6 Plot most important pathologies groups for each desease <\/h3>","3abd8d37":"### Data limitations:\n- 1. The image labels are NLP extracted so there could be some erroneous labels but the NLP labeling accuracy is estimated to be >90%.\n - 2. Very limited numbers of disease region bounding boxes (See BBox_list_2017.csv)\n - .Chest x-ray radiology reports are not anticipated to be publicly shared. Parties who use this public dataset are encouraged to share their \u201cupdated\u201d image labels and\/or new bounding boxes in their own studied later, maybe through manual annotation\n","4da7b47c":"**Data_entry_2017.csv:** Class labels and patient data for the entire dataset\n- Image Index: File name\n- Finding Labels: Disease type (Class label)\n- Follow-up #\n- Patient ID\n- Patient Age\n- Patient Gender\n- View Position: X-ray orientation\n- OriginalImageWidth\n- OriginalImageHeight\n- OriginalImagePixelSpacing_x\n- OriginalImagePixelSpacing_y","323b94a8":"<h1> 3. Exploratory Data Analysis <\/h1>"}}