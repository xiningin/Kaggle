{"cell_type":{"851fcd01":"code","2141dace":"code","d68520ac":"code","55a8282a":"code","997f5da6":"code","27bca1ed":"code","932da2b3":"code","364a696b":"code","b7e4488e":"code","4be4312e":"code","14e7f45d":"code","3b4ed653":"code","fb854f33":"code","e00dee97":"code","8f0d5473":"code","91361f64":"code","cd178b65":"code","c217419f":"code","2a617991":"code","d552451f":"code","8ee17426":"code","38c332ed":"code","a5e1fa30":"code","389a8f98":"code","f7c30bc1":"code","acdefd16":"code","36af607f":"code","a76fe7ee":"code","d12a6d11":"code","c43455d8":"code","909e05b1":"code","a99fdfe6":"code","fc41462f":"code","2fd5e84e":"code","a76b68b2":"code","e182e49a":"code","f6b65f77":"code","6bf42621":"code","6f4c96db":"code","19d00d6b":"code","9e6e116b":"code","3e158d3e":"code","7301daee":"code","21632dbb":"code","1c5abe6a":"code","e65b92bf":"code","c6cbb659":"code","7ac4364f":"code","3b392cb7":"code","384d2167":"code","8b8b5d62":"code","825074c0":"code","fe6913f9":"code","129d9658":"code","7691f4e0":"code","9fbfa1fa":"code","42b5de16":"markdown","88cc9609":"markdown","a127de83":"markdown","2428eeb6":"markdown","76c8ac44":"markdown","4d393578":"markdown","bb94545a":"markdown","bc38b400":"markdown","c8332fea":"markdown","f787abad":"markdown","46ace8d0":"markdown","ffddd953":"markdown","4642c5d4":"markdown","ea163c85":"markdown","d5f00626":"markdown","890fbd36":"markdown","35d6fec0":"markdown","ee8fd2e7":"markdown","8e65e399":"markdown","ab93d218":"markdown","59444e27":"markdown","2a10b8ff":"markdown","b37eb723":"markdown","cd4b963f":"markdown","8d1a81ad":"markdown","1781af9e":"markdown","1212b9b7":"markdown","bba9fa6e":"markdown","935b7659":"markdown","e97bf731":"markdown","ebc3f833":"markdown","ddd1e215":"markdown","c4421a69":"markdown","1bbc8661":"markdown","bfb85ccc":"markdown","1f68efa9":"markdown"},"source":{"851fcd01":"import numpy as np\nimport pandas as pd\npd.set_option(\"display.max_columns\",100)\npd.set_option(\"display.max_rows\",120)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nparams={\"figure.facecolor\":(0.0,0.0,0.0,0),\n        \"axes.facecolor\":(1.0,1.0,1.0,1),\n        \"savefig.facecolor\":(0.0,0.0,0.0,0)}\nplt.rcParams.update(params)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report,roc_auc_score,roc_curve,confusion_matrix\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","2141dace":"df=pd.read_csv(\"..\/input\/weather-dataset-rattle-package\/weatherAUS.csv\")\ndf.head()","d68520ac":"df.info()","55a8282a":"df[\"RainTomorrow\"].value_counts()","997f5da6":"sns.countplot(df[\"RainTomorrow\"],palette=[\"lightcoral\",\"skyblue\"])\nplt.ylabel(\"Count\")","27bca1ed":"df[\"RainTomorrow\"]=df[\"RainTomorrow\"].apply(lambda x:0 if x==\"No\" else 1)","932da2b3":"df.describe().drop([\"RainTomorrow\"],axis=1).T","364a696b":"for column in df.select_dtypes(exclude=\"object\").drop([\"RainTomorrow\"],axis=1).columns:\n    print(column,\":\",df[column].isnull().sum(),\"missing values.\")","b7e4488e":"fig,axes=plt.subplots(1,2,figsize=(12,5))\n\ndf[df.select_dtypes(exclude=\"object\").columns.drop([\"Pressure9am\",\"Pressure3pm\",\"RainTomorrow\"])].plot(kind=\"box\",color=\"#AE9CCD\",ax=axes[0])\naxes[0].set_xticklabels(axes[0].get_xticklabels(),rotation=90)\naxes[0].set_ylabel(\"Measurement\")\n\ndf[[\"Pressure9am\",\"Pressure3pm\"]].plot(kind=\"box\",color=\"#AE9CCD\",ax=axes[1])","4be4312e":"fig,axes=plt.subplots(1,3,figsize=(15,4))\n\nsns.distplot(df[\"Rainfall\"],bins=12,color=\"lightskyblue\",ax=axes[0])\nsns.distplot(df[\"Evaporation\"],bins=12,color=\"lightcoral\",ax=axes[1])\nsns.distplot(df[\"WindSpeed9am\"],bins=12,color=\"lightgreen\",ax=axes[2])","14e7f45d":"droppers=df.loc[(df[\"Rainfall\"]>300)|(df[\"Evaporation\"]>100)|(df[\"WindSpeed9am\"]>100)]\ndf.drop(droppers.index,inplace=True)","3b4ed653":"print(\"We have dropped {num1} rows, so now instead of the initial 142193 readings, we have {num2}.\".format(num1=142193-df.shape[0],num2=df.shape[0]))","fb854f33":"df.select_dtypes(include=\"object\").describe()","e00dee97":"print(\"{num} missing values.\".format(num=df[\"Date\"].isnull().sum()))","8f0d5473":"df[\"Date\"]=pd.to_datetime(df[\"Date\"])","91361f64":"df[\"Month\"]=df[\"Date\"].dt.month","cd178b65":"df.drop([\"Date\"],axis=1,inplace=True)\ndf.head(2)","c217419f":"print(\"{num} missing values.\".format(num=df[\"Location\"].isnull().sum()))","2a617991":"df[\"Location\"].value_counts()","d552451f":"print(\"{num} missing values.\".format(num=df[\"WindGustDir\"].isnull().sum()))","8ee17426":"df[\"WindGustDir\"].value_counts()","38c332ed":"print(\"{num} missing values.\".format(num=df[\"WindDir9am\"].isnull().sum()))","a5e1fa30":"df[\"WindDir9am\"].value_counts()","389a8f98":"print(\"{num} missing values.\".format(num=df[\"WindDir3pm\"].isnull().sum()))","f7c30bc1":"df[\"WindDir3pm\"].value_counts()","acdefd16":"print(\"{num} missing values.\".format(num=df[\"RainToday\"].isnull().sum()))","36af607f":"df[\"RainToday\"].value_counts()","a76fe7ee":"df[\"RainToday\"]=df[\"RainToday\"].apply(lambda x:0 if x==\"No\" else 1)\ndf.head(2)","d12a6d11":"df.head()","c43455d8":"x=df.drop([\"RainTomorrow\"],axis=1)\ny=df[\"RainTomorrow\"]\n\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33,random_state=7)","909e05b1":"print(\"Training set shape:\",x_train.shape)\nprint(\"Testing set shape:\",x_test.shape)","a99fdfe6":"x_train.isnull().sum()","fc41462f":"x_test.isnull().sum()","2fd5e84e":"for df in [x_train,x_test]:\n    for col in df.select_dtypes(exclude=\"object\").columns:\n        col_median=x_train[col].median()\n        df[col].fillna(col_median,inplace=True)","a76b68b2":"x_train.isnull().sum()","e182e49a":"x_test.isnull().sum()","f6b65f77":"for df in [x_train,x_test]:\n    for col in df.select_dtypes(\"object\").columns:\n        col_mode=x_train[col].mode()[0]\n        df[col].fillna(col_mode,inplace=True)","6bf42621":"x_train.isnull().sum()","6f4c96db":"x_test.isnull().sum()","19d00d6b":"for col in x_train.select_dtypes(\"object\").columns:\n    x_train=pd.concat([x_train,pd.get_dummies(x_train[col],drop_first=True)],axis=1)\n    x_train.drop([col],axis=1,inplace=True)","9e6e116b":"x_train.head(2)","3e158d3e":"for col in x_test.select_dtypes(\"object\").columns:\n    x_test=pd.concat([x_test,pd.get_dummies(x_test[col],drop_first=True)],axis=1)\n    x_test.drop([col],axis=1,inplace=True)","7301daee":"x_test.head(2)","21632dbb":"scaler=StandardScaler()\n\nx_train=pd.DataFrame(scaler.fit_transform(x_train),columns=x_train.columns)\nx_test=pd.DataFrame(scaler.transform(x_test),columns=x_test.columns)","1c5abe6a":"x_train.head(2)","e65b92bf":"x_test.head(2)","c6cbb659":"model=LogisticRegression(random_state=7)\n\nmin_features_to_select=1\nrfecv=RFECV(estimator=model,step=1,cv=5,scoring=\"accuracy\",min_features_to_select=min_features_to_select)\nrfecv.fit(x_train,y_train)\n\nprint(\"Optimal number of features : %d\" % rfecv.n_features_)\n\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.plot(range(min_features_to_select,\n               len(rfecv.grid_scores_)+min_features_to_select),\n         rfecv.grid_scores_)\nplt.show()","7ac4364f":"rfetable=pd.DataFrame({\"Feature\":x_train.columns,\"Support\":rfecv.support_,\"Ranking\":rfecv.ranking_,}).sort_values(by=\"Ranking\",ascending=False)\nrfetable","3b392cb7":"x_train=x_train.drop([\"Rainfall\",\"SSE\",\"SSW\",\"NNE\",\"ESE\",\"W\",\"Williamtown\",\"PearceRAAF\",\"ENE\",\"SE\"],axis=1)\nx_test=x_test.drop([\"Rainfall\",\"SSE\",\"SSW\",\"NNE\",\"ESE\",\"W\",\"Williamtown\",\"PearceRAAF\",\"ENE\",\"SE\"],axis=1)","384d2167":"model.fit(x_train,y_train)","8b8b5d62":"parameters=[{\"penalty\":[\"l1\",\"l2\",\"elasticnet\"]},\n            {\"C\":[0.1,1,10,100]},\n            {\"class_weight\":[\"balanced\",None]},\n            {\"solver\":[\"newton-cg\",\"lbfgs\",\"liblinear\",\"sag\",\"saga\"]},\n            {\"multi_class\":[\"auto\",\"ovr\",\"multinomial\"]}]\n\ngrid=GridSearchCV(estimator=model,param_grid=parameters,refit=True,cv=5,verbose=1)\n\ngrid.fit(x_train,y_train)\n\ny_predict=grid.predict(x_test)","825074c0":"def cm(predictions):\n    cm_matrix=pd.DataFrame(data=confusion_matrix(y_test,predictions),columns=[\"No Rain\",\"Rain\"],index=[\"No Rain\",\"Rain\"])\n    sns.heatmap(cm_matrix,annot=True,square=True,fmt=\"d\",cmap=\"Purples\",linecolor=\"w\",linewidth=2)\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.yticks(va=\"center\")","fe6913f9":"print(classification_report(y_test,y_predict))","129d9658":"y_score=model.predict_proba(x_test)[:,1]\n\nprint(\"roc_auc_score: \",roc_auc_score(y_test,y_score))\n\nfalse_positive_rate,true_positive_rate,threshold=roc_curve(y_test,y_score)\nplt.plot(false_positive_rate,true_positive_rate)\nplt.plot([0,1],ls=\"--\")\nplt.plot([0,0],[1,0],c=\".7\")\nplt.plot([1,1],c=\".7\")\nplt.title(\"Receiver Operating Characteristic\")\nplt.ylabel(\"True Positive Rate\")\nplt.xlabel(\"False Positive Rate\")\nplt.show()","7691f4e0":"cm(y_predict)","9fbfa1fa":"print(\"Training set score: {num:.4f}.\".format(num=model.score(x_train,y_train)))\nprint(\"Testing set score: {num:.4f}.\".format(num=model.score(x_test,y_test)))","42b5de16":"So this is what our data looks like now:","88cc9609":"***RainToday***","a127de83":"Recurssive feature elimination suggests we can remove some columns to the optimal amount of 101.","2428eeb6":"- We will convert these categories into numbers when we impute the missing values after we split the data.","76c8ac44":"**Will it rain or won't it rain? I gotta know so I know how to dress!!**","4d393578":"- We will convert these categories into numbers when we impute the missing values after we split the data.","bb94545a":"***Location***","bc38b400":"Missing values in numerical features will be filled with the median. We could in fact use the mean or a set constant instead, but because of the range and the number of outliers in the data we will use the median.","c8332fea":"But before we fit our model, perhaps we should reduce the number of features selected:","f787abad":"Our model didn't do so bad with an accuracy score of 0.84 and a ROC AUC score of 0.86! This means our model was able to correctly predict 83% of the instances. It was however better at predicting class 0 (i.e. no rain) than class 1 (i.e. rain) with the higher precision and recall, and the model also predicted a lot more false negatives (i.e. predicted that it would not rain when it actually will) than false positives (i.e. predicted that it would rain when it actually will not). Thankfully after all that work the training and testing scores are very similar so there is no obvious indication of any over\/underfitting hence our model will fair well with new data.","46ace8d0":"***Date***","ffddd953":"Up until now the categorical features are still in text format. We will have to convert them into a format the model will be able to use as input (i.e. numbers). We shall do so by converting the text into numbers using pd.get_dummies, concatenating the dummies to the dataframe, and then dropping the original text column:","4642c5d4":"Although it is possible to achieve these amounts of rainfall, evaporation and wind speed - for example in a storm or heatwave event - we remove them from the dataset so the model doesn't think these extreme weather events are common.","ea163c85":"- We will not be dropping *Location* because rain is regional.","d5f00626":"Missing values in categorical features will be filled with the mode.","890fbd36":"Next we can evaluate our model using a classifcation report, ROC AUC score, ROC curve  and a confusion matrix:","35d6fec0":"There are 142193 readings and 23 columns, of which *RainTomorrow* is our target variable. We also have a mixture of numerical and categorical variables, and some missing values (which we shall tackle when we split the data into the training and testing sets).\n\nFirst let's see view our target variable ***RainTomorrow***:","ee8fd2e7":"- Now we can drop the *Date* column:","8e65e399":"Let's check our data:","ab93d218":"Quite a number of missing values, which we will impute after we split the data.\n\nFor numerical features, it is important to remove any outliers to improve model's performance.","59444e27":"- We will also convert these text data into numbers but just using a simple if statement:","2a10b8ff":"- We will convert these categories into numbers when we impute the missing values after we split the data.","b37eb723":"Before we tackle the missing values or scale the data, we must first split the data into the training and testing sets to ensure we do not cause any data leakage.","cd4b963f":"***WindDir3pm***","8d1a81ad":"From the above boxplots, we have quite a number of outliers outside 1.5 times the interquartile range. But because there are no real bounds for weather data, i.e. due to extreme weather events, we will not be removing all of these outliers. If we do we will be creating a perfect dataset that won't properly reflect real world weather. Instead let's just further examine the outliers of the outliers in *Rainfall*, *Evaporation* and *WindSpeed9am*:","1781af9e":"- There are 3436 unique values in the format of YYYY-MM-DD. Instead of using the *categoricals* function, we will just split up the date format into year, month and day but we only use the month data as rain is seasonal and not yearly\/daily.","1212b9b7":"For categorical features, it is important to check the actual categories and change the format into numbers. Remember we will only impute the missing data after we split the data.","bba9fa6e":"***WindDir9am***","935b7659":"- We will convert these categories into numbers when we impute the missing values after we split the data.","e97bf731":"Now let's go through and check the values for each feature. We will start with the numerical features:","ebc3f833":"Let's continue with the categorical features:","ddd1e215":"***WindGustDir***","c4421a69":"Since each feature has it's own range of values, we will scale the data (again, only based on the training set and then applied to the testing set):","1bbc8661":"To replace the missing values, we will compute a fill value for the numerical and categorical features based on the training set and then apply them to the testing set.","bfb85ccc":"Now that we have removed some features, we can finally fit our model:","1f68efa9":"**Now should I bring my umbrella or sunglasses..**"}}