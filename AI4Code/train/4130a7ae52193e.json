{"cell_type":{"6586a8b3":"code","27e553c0":"code","1677a856":"code","9eb3dc54":"code","7dfd1da6":"code","a5a707c7":"code","eaa9af25":"code","6e1e03aa":"code","68001160":"code","c6e49e2b":"code","aa0e4689":"code","6a345839":"code","d1e81d50":"code","d0c3bd82":"code","9ff3b95e":"code","29677fba":"code","98f1f016":"code","38c6da1c":"code","5b8daea8":"code","4910613f":"code","602003a7":"code","17d251fd":"code","5d8d7341":"code","6ac0d12a":"code","23e2e5be":"code","bb641258":"code","ae518f9b":"code","9ea6778e":"code","10c425f7":"code","1556f534":"code","bff4b796":"code","896be613":"code","1006e75e":"code","0b2a13be":"code","05117fb0":"code","98187958":"code","51bc8581":"code","346c5c9d":"code","58f8d581":"code","05bcdc1f":"code","d3bc94e4":"code","82a73a95":"code","19b5d45b":"code","2b987cc0":"code","64bc826f":"code","c435584a":"code","0c03d437":"code","1b461a9c":"code","831081a4":"code","f32a7068":"code","0c038624":"markdown","2f684a05":"markdown","8afe0e32":"markdown","924f7b78":"markdown","6245c958":"markdown","1944697a":"markdown","94afdba4":"markdown","bcb11a2f":"markdown","3b517ce8":"markdown","8279958a":"markdown","fcd59260":"markdown","1dfcfb0f":"markdown","52457d55":"markdown","6bd248cc":"markdown","07c9cce2":"markdown"},"source":{"6586a8b3":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","27e553c0":"df= pd.read_csv('..\/input\/titanic\/train.csv')","1677a856":"df.head()","9eb3dc54":"df.info()","7dfd1da6":"df.shape","a5a707c7":"sns.countplot(data=df, x='Survived')","eaa9af25":"sns.countplot(data=df, x='Survived', hue= 'Sex')","6e1e03aa":"sns.countplot(data=df, x='Survived', hue= 'Pclass')","68001160":"sns.countplot(data=df, x='SibSp')","c6e49e2b":"100*(df.isnull().sum()\/len(df))","aa0e4689":"def missing_percent(df):\n    nan_percent= 100*(df.isnull().sum()\/len(df))\n    nan_percent= nan_percent[nan_percent>0].sort_values()\n    return nan_percent","6a345839":"nan_percent= missing_percent(df)","d1e81d50":"nan_percent","d0c3bd82":"sns.barplot(x=nan_percent.index, y=nan_percent)","9ff3b95e":"#dealing with Cabin: as the missing percentage is very high, we decide to drop this dfcolumn:\ndf= df.drop('Cabin', axis=1 )","29677fba":"nan_percent= missing_percent(df)\nsns.barplot(x=nan_percent.index, y=nan_percent)","98f1f016":"#Dealing with imbarked:\ndf[df['Embarked'].isnull()]","38c6da1c":"# there is just two rows with missing data in Embarked Columns, so we decide to drop these two rows:\n\ndf= df.dropna(subset=['Embarked'], axis=0)","5b8daea8":"nan_percent= missing_percent(df)\nsns.barplot(x=nan_percent.index, y=nan_percent)","4910613f":"#Dealing with Age:\n# We Assume that the Pclass is related to the Age, please chech it:\nsns.boxplot(data=df, x='Pclass', y='Age')","602003a7":"#As the above boxplot shows, the mean of Age is different in each category of Pclass,\n#So we decide to fill the missing value of Age with mean of Age based on the Pclass:\n\n#Lets chech the mean of Age for each category of Pclass:\ndf.groupby('Pclass')['Age'].mean()","17d251fd":"#Please Fill the missing value of Age as mentioned above:\ndf['Age']= df.groupby('Pclass')['Age'].transform(lambda val: val.fillna(val.mean()))","5d8d7341":"nan_percent= missing_percent(df)\n","6ac0d12a":"nan_percent","23e2e5be":"df.columns","bb641258":"df_num= df[['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']]\ndf_obj=df[['Sex', 'Embarked']]","ae518f9b":"df_obj= pd.get_dummies(df_obj, drop_first=True)","9ea6778e":"df_obj.shape","10c425f7":"df= pd.concat([df_num, df_obj], axis=1)","1556f534":"df.head()","bff4b796":"X=df.drop('Survived', axis=1)\ny=df['Survived']","896be613":"X.head()","1006e75e":"from sklearn.model_selection import train_test_split","0b2a13be":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","05117fb0":"from sklearn.preprocessing import StandardScaler","98187958":"scaler=StandardScaler()","51bc8581":"scaled_X_train=scaler.fit_transform(X_train)\nscaled_X_test= scaler.fit_transform(X_test)","346c5c9d":"from sklearn.linear_model import LogisticRegression","58f8d581":"log_model= LogisticRegression()","05bcdc1f":"log_model.fit(scaled_X_train, y_train)","d3bc94e4":"#Model Coeficient:\nlog_model.coef_","82a73a95":"y_pred= log_model.predict(scaled_X_test)","19b5d45b":"#The Prediction Value VS Actual Value of Test Dataset\npd.DataFrame({'Y_Test': y_test,'Y_Pred':y_pred}).head(5)","2b987cc0":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, plot_confusion_matrix","64bc826f":"accuracy_score(y_test, y_pred)","c435584a":"plot_confusion_matrix(log_model, scaled_X_test, y_test)","0c03d437":"print(classification_report(y_test, y_pred))","1b461a9c":"from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve, plot_roc_curve","831081a4":"plot_precision_recall_curve(log_model, scaled_X_test, y_test)","f32a7068":"plot_roc_curve(log_model, scaled_X_test, y_test)","0c038624":"### Step11: Evaluating Curves and AUC\n","2f684a05":"### Step10: Evaluating the Model","8afe0e32":"**Now the Dataset is ready for any machine learning algorithm**","924f7b78":"### Step4: Exploratory Data Analysis","6245c958":"### Step10: Predicting Test Data\n","1944697a":"**Great, Now we don't have any Missing data**","94afdba4":"## Step8: Scaling the Features","bcb11a2f":"### Step2: Import the Dataset","3b517ce8":"## Step6: Determine the Features & Target Variable","8279958a":"### Step1: Import all Necessary Libraries","fcd59260":"## Step9: Train the Model","1dfcfb0f":"## Step7: Split the Dataset to Train & Test","52457d55":"### Step3: Data Overview","6bd248cc":"### Step5: Data Preparation\n**A- How much data is missing?**","07c9cce2":"### B-Dealing with Categorical Data"}}