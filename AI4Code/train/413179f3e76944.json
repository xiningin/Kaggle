{"cell_type":{"9743f406":"code","f2b458da":"code","1cdf0ad4":"code","93f50d4b":"code","850ed9ae":"code","99e17bf6":"code","46d0d2f5":"code","7a5fcb22":"code","771799fe":"code","c5c9e0a7":"code","87cf4843":"code","ab72aca5":"code","ecd2713c":"code","d58938ae":"code","0195d596":"code","f1864c10":"code","63ff9d39":"code","c6099145":"code","f5b7e109":"code","f2341b04":"code","de7fda1a":"markdown"},"source":{"9743f406":"import lightgbm as lgb\nimport numpy as np\nimport pandas as pd\nimport random\nimport optuna\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import mean_squared_error","f2b458da":"train = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/test.csv\")","1cdf0ad4":"train.head()","93f50d4b":"print(train.columns.to_list())","850ed9ae":"target_name=['target_carbon_monoxide','target_benzene','target_nitrogen_oxides']\ntrain_name=['deg_C','relative_humidity','absolute_humidity','sensor_1','sensor_2',\n            'sensor_3','sensor_4','sensor_5',]","99e17bf6":"target = train[target_name]\ntarget0 = train['target_carbon_monoxide']\ndata = train[train_name]","46d0d2f5":"columns=data.columns.to_list()\nprint(columns)","7a5fcb22":"def objective(trial,data=data,target=target0):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.2,random_state=42)\n    param =   {\n\n        'max_depth':  trial.suggest_int('max_depth', 8, 10),\n        'learning_rate': trial.suggest_uniform('learning_rate', 0.3, 0.4),\n        'num_leaves': trial.suggest_int('num_leaves', 100, 256),\n        'lambda_l1': trial.suggest_loguniform('lambda_l1', 0.01, 1.0),\n        'lambda_l2': trial.suggest_uniform('lambda_l2', 7.0, 8.0),\n        \"bagging_freq\":  trial.suggest_int('num_leaves', 2, 256),\n        \"bagging_fraction\": trial.suggest_uniform('bagging_fraction', 0.9, 1.0),\n        \"feature_fraction\": trial.suggest_uniform('feature_fraction', 0.4, 0.5),\n        \"verbosity\":  trial.suggest_int('verbosity', 3, 6),\n        \n        'objective': trial.suggest_categorical('objective',['regression']),         \n        \"boosting\": trial.suggest_categorical('boosting',[\"gbdt\"]),\n        'tree_method': trial.suggest_categorical('tree_method',['gpu_hist']),  #'gpu_hist','hist'    \n    }\n    model = lgb.LGBMRegressor(**param)      \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n    preds = model.predict(test_x)\n    rmse = mean_squared_error(test_y, preds,squared=False)\n    \n    return rmse","771799fe":"study = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=8)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","c5c9e0a7":"study.trials_dataframe()","87cf4843":"# shows the scores from all trials\noptuna.visualization.plot_optimization_history(study)","ab72aca5":"# interactively visualizes the hyperparameters and scores\noptuna.visualization.plot_parallel_coordinate(study)","ecd2713c":"# shows the evolution of the search\noptuna.visualization.plot_slice(study)","d58938ae":"# parameter interactions on an interactive chart.\noptuna.visualization.plot_contour(study, params=['bagging_fraction','num_leaves'])","0195d596":"# Visualize parameter importances.\noptuna.visualization.plot_param_importances(study)","f1864c10":"# Visualize empirical distribution function\noptuna.visualization.plot_edf(study)","63ff9d39":"Best_trial=study.best_trial.params\nprint(Best_trial)","c6099145":"sample = pd.read_csv(\"..\/input\/tabular-playground-series-jul-2021\/sample_submission.csv\")\nprint(sample.shape)\nsample","f5b7e109":"preds = np.zeros((sample.shape[0],sample.shape[1]-1))\nkf = KFold(n_splits=5,random_state=48,shuffle=True)\nfor i in range(3):\n    for trn_idx, test_idx in kf.split(train[columns],target[target_name[i]]):\n        X_tr,X_val=train[columns].iloc[trn_idx],train[columns].iloc[test_idx]\n        y_tr,y_val=target.iloc[trn_idx,i],target.iloc[test_idx,i]     ######\n        model = lgb.LGBMRegressor(**Best_trial)\n        model.fit(X_tr,y_tr,eval_set=[(X_val,y_val)],early_stopping_rounds=100,verbose=False)\n        preds[:,i]+=model.predict(test[columns])\/kf.n_splits    ######\n        rmse=mean_squared_error(y_val, model.predict(X_val),squared=False)\n        print(rmse)","f2341b04":"subm = sample\nsubm[target_name] = pd.DataFrame(preds)\nsubm.to_csv('submission.csv',index=False)\nsubm","de7fda1a":"# LightGBM with Optuna tuning\n* doc: \nhttps:\/\/github.com\/optuna\/optuna"}}