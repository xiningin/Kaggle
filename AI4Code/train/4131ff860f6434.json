{"cell_type":{"96edcbc2":"code","2f056f60":"code","055e3787":"code","dab997b1":"code","6c8085a0":"code","8414547c":"code","66b0d179":"code","7235d1f3":"code","4e17cc0e":"code","b70c4a4e":"code","21bf2633":"markdown","fbbbab60":"markdown","a3636847":"markdown","f672d905":"markdown","84cdcaab":"markdown","ab23c1c6":"markdown","4c718b77":"markdown","69220c75":"markdown","31696ffc":"markdown","8c4a2df5":"markdown","f25f4769":"markdown","93bcfee6":"markdown","9d26df0f":"markdown","3cf4dbd7":"markdown","82949e67":"markdown","95cff5b8":"markdown"},"source":{"96edcbc2":"import numpy as np\nimport re\nimport pandas as pd\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport json, plotly\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nfrom subprocess import check_output\nimport os","2f056f60":"category = pd.read_json('..\/input\/youtube-new\/IN_category_id.json')\ndata = pd.read_csv(\"..\/input\/youtube-new\/INvideos.csv\", index_col = 'video_id')\ndata.head()","055e3787":"id_video =[]\nvideo_name = []\nfor index,row in category.iterrows():\n    x = row['items']\n    id_video.append(x['id'])\n    video_name.append(x['snippet']['title'])\n\ncategory = pd.DataFrame(zip(id_video, video_name),columns=['category_id', 'category'])\ncategory['category_id'] = category['category_id'].astype('int64')\n\n#Instead of maintaining two different datasets, I merged both into one by adding categories into the original 'data' dataset.\ndata = pd.merge(data, category, on = 'category_id', how = 'inner')\ndata.head()","dab997b1":"channel = data.groupby(\"channel_title\").size().reset_index(name=\"video_count\")\\\n.sort_values(\"video_count\", ascending=False).head(30)\nfig, ax = plt.subplots(figsize=(8,8))\npb = sns.barplot(x = \"video_count\", y = \"channel_title\", data = channel,\n                palette = sns.cubehelix_palette(start=.2,rot=-.3, n_colors = 30, reverse = True), ax = ax)\npb = ax.set(xlabel = \"No. of videos\", ylabel = \"Channel\")","6c8085a0":"data['trending_date'] = pd.to_datetime(data['trending_date'], format = '%y.%d.%m')\ndata['trending_date'].head(n = 10)","8414547c":"data['publish_time'] = pd.to_datetime(data['publish_time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\ndata.insert(4, 'publish_date', data['publish_time'].dt.date)\ndata['publish_time'] = data['publish_time'].dt.time\ndata[['publish_date', 'publish_time']].head()","66b0d179":"matplotlib.pyplot.figure(figsize=(8, 6))\nsns.scatterplot(x = data['views'], y = data['likes'], color = 'gold')","7235d1f3":"column_correlation = ['views', 'likes', 'dislikes', 'comment_count']\nf, ax = plt.subplots(figsize = (8, 10))\ncorr = data[column_correlation].corr()\nsns.heatmap(corr, mask=np.zeros_like(corr, dtype = np.bool), cmap = \"Spectral\",\n            square = True, ax = ax,annot = True)","4e17cc0e":"data1 = data.groupby(['category','channel_title']).size().rename('num_videos').reset_index()\ndata2 = data1[data1.groupby('category')['num_videos'].transform(max) == data1['num_videos']]\npx.bar(data_frame = data2,x='channel_title', y='num_videos',template='ggplot2')\n\n\nfig = sns.barplot(data = data2, x = 'channel_title', y = 'num_videos')\nxlabels = (data2['category'] + ' \/ ' + data2['channel_title']).to_list()\n_ = plt.title('Channels with Highest no.of trending videos in each category', fontsize = 20)\n_ = plt.ylabel('Number of Videos', fontsize = 10)\n_ = plt.xlabel('')\n_ = plt.xticks(np.arange(0,16),xlabels,rotation = 90, fontsize = 10)","b70c4a4e":"data3 = data.groupby(['category']).agg({'views':'sum','likes':'sum','dislikes':'sum','comment_count':'sum'}).reset_index()\ndata31 = [go.Pie(labels = data3['category'], values = data3['views'], hoverinfo = 'label')]\nplotly.offline.iplot(data31, filename = 'category')","21bf2633":"![crazyyoutubevideos.jpg](attachment:crazyyoutubevideos.jpg)","fbbbab60":"The key features in the dataset we're using are likes, dislikes, comments and their category.","a3636847":"**Conclusion**\n\nViews, likes, dislikes, and comment counts all have strong correlations with each other. Although this project contained datasets from several countries, we decided to focus on Indian youtube videos. Hopefully, this notebook answered the necessary questions such as the trending channels on youtube and also, the most popular categories Indians tend to watch daily. Please upvote if you like this notebook and let me know if there are any mistakes.","f672d905":"**Correlation between key features**\n\n\nWe would like to see how the key features (likes, dislikes etc.) are correlated to each other. ","84cdcaab":"In this modern era, Youtube has become the most dominant streaming platform worldwide. As one of the most famous and used streaming platforms, Youtube can offer a peak into what kind of content people around the world most curious about. Using viewership data and top web curators, this notebook will analyze phenomena within the YouTube community, particulary on India's popular youtube videos. ","ab23c1c6":"**Categories of Videos**","4c718b77":"**Importing Dataset**","69220c75":"**Relationship between Likes & Views**","31696ffc":"**Correlations**\n* High: Views and likes, Comments and likes\n* Low: Dislikes and likes, Comments and dislikes","8c4a2df5":"**Percentage of Views of Videos by category**","f25f4769":"# **Trending YouTube Videos Statistics**","93bcfee6":"**Popular videos by category**","9d26df0f":"As observed, majority of these channels are Indian television channels popular for their daily soaps.","3cf4dbd7":"# EXPLORATORY DATA ANALYSIS (EDA)\n**Popular Channels**","82949e67":"**Trending Videos Dates**","95cff5b8":"# INTRODUCTION"}}