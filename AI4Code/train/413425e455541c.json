{"cell_type":{"b854fb55":"code","4f5b1bef":"code","c3413353":"code","d0067b17":"code","230a06d2":"code","b713ca92":"code","09f117f1":"code","09cec11a":"code","3f0a58c1":"code","b11930b9":"code","212771a3":"code","dbaca5e7":"code","42803d22":"code","c9e667f7":"code","2d349a14":"code","90797aa5":"markdown","2c75d9fb":"markdown","38e33176":"markdown","951a7446":"markdown","bb68d07b":"markdown","034aba1a":"markdown","9988e26d":"markdown"},"source":{"b854fb55":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LinearRegression\nimport xgboost as xgb\n\nfrom sklearn.metrics import r2_score","4f5b1bef":"data = pd.read_csv('..\/input\/financial-distress\/Financial Distress.csv')","c3413353":"data","d0067b17":"print(\"Total missing values:\", data.isna().sum().sum())","230a06d2":"data = data.drop(['Company', 'Time'], axis=1)","b713ca92":"def onehot_encode(df, column, prefix):\n    df = df.copy()\n    dummies = pd.get_dummies(df[column], prefix=prefix)\n    df = pd.concat([df, dummies], axis=1)\n    df = df.drop(column, axis=1)\n    return df","09f117f1":"data = onehot_encode(data, column='x80', prefix='x80')","09cec11a":"data","3f0a58c1":"print(\"Non-numeric columns:\", len(data.select_dtypes('object').columns))","b11930b9":"y = data['Financial Distress'].copy()\nX = data.drop('Financial Distress', axis=1).copy()","212771a3":"scaler = StandardScaler()\n\nX = scaler.fit_transform(X)","dbaca5e7":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=100)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=100)","42803d22":"dtrain = xgb.DMatrix(X_train, label=y_train)\ndval = xgb.DMatrix(X_val, label=y_val)\ndtest = xgb.DMatrix(X_test, label=y_test)","c9e667f7":"lin_model = LinearRegression()\nlin_model.fit(X_train, y_train)\n\nprint(\"Linear Regression R^2 Score:\", lin_model.score(X_test, y_test))","2d349a14":"params = {'learning_rate': 0.001, 'max_depth': 6, 'lambda': 0.01}\n\nboost_model = xgb.train(\n    params,\n    dtrain,\n    num_boost_round=10000,\n    evals=[(dval, 'eval')],\n    early_stopping_rounds=10,\n    verbose_eval=False\n)\n\nprint(\"XGB Model R^2 Score:\", r2_score(y_test, boost_model.predict(dtest)))","90797aa5":"# Splitting\/Scaling","2c75d9fb":"# Task for Today  \n\n***\n\n## Financial Distress Prediction  \n\nGiven *data about various companies*, let's try to predict a given company's **financial distress level**.\n\nWe will use a linear regression model and a gradient boosting model to make our predictions.","38e33176":"# Getting Started","951a7446":"# Preprocessing","bb68d07b":"# Linear Regression","034aba1a":"# Gradient Boosting Model","9988e26d":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/AOF5g8TVsGc"}}