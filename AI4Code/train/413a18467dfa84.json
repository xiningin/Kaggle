{"cell_type":{"594c5d66":"code","f02ac1f5":"code","c7a7615f":"code","6e07205f":"code","7721e332":"code","d6bcb70a":"code","f72bab2b":"code","9c28daac":"code","5b731b36":"code","a8b77280":"code","a03ff1ca":"markdown","5436ce1a":"markdown","eae7a941":"markdown","68c34a84":"markdown","3171013d":"markdown","3ef52096":"markdown","f3318f55":"markdown","7e842d2e":"markdown","452e4d30":"markdown","5869e3be":"markdown"},"source":{"594c5d66":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n#LodeStar has addded the option below\npd.set_option('display.max_columns', 100)\n\n# Read the data\nX_train_full = pd.read_csv('..\/input\/home-data-for-ml-course\/train.csv', index_col='Id') # Train data contain 1460 rows\nX_test_full = pd.read_csv('..\/input\/home-data-for-ml-course\/test.csv', index_col='Id') # Test data contain 1459 rows\n\n# print(X_train_full.head()) # Return all column with first 5 values\n# print(\"X_train_full data row and col:\", X_train_full.shape) # (1460, 80)","f02ac1f5":"# Remove rows with missing target, separate target from predictors\nX_train_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n# print(X_train_full.shape) # (1460, 80) i.e no value missing\n\nY_train_full = X_train_full.SalePrice\n# print(Y_train_real.shape) # (1460,) i.e only target data, single column\n\nX_train_full.drop(['SalePrice'], axis=1, inplace=True)\n# print(X_train_full.shape) # (1460, 79) i.e only train data","c7a7615f":"# To keep things simple for now, we'll use only numerical predictors\nX = X_train_full.select_dtypes(exclude=['object'])\n# print(X.shape) # (1460, 36) i.e 44 column with non numeric value are droped\n\n# Break off validation set from training data\nX_train, X_valid, y_train, y_valid = train_test_split(X, Y_train_full, train_size=0.8, test_size=0.2, random_state=0)\n\n# print(X_train.shape) # (1168, 36)\n# X_train.head() # return 36 numerical column","6e07205f":"# Number of missing values in each column of training data, that values we need to process\nmissing_val_count_by_column = (X_train.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])\n# Total missing values 276","7721e332":"# Create a function to compare approach for different missing values, Random forest used as an algorithm\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Function for comparing different approaches\ndef score_dataset(X_train, X_valid, y_train, y_valid):\n    model = RandomForestRegressor(n_estimators=100, random_state=0)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)","d6bcb70a":"#Fill in the line below: get names of columns with missing values. #Put your code here \ncols_missing_data = [col for col in X_train.columns \n                        if X_train[col].isnull().any()]\n# print(cols_missing_data) # ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n\n#Fill in the lines below: drop columns in training and validation data \ndrop_column_X_train = X_train.drop(cols_missing_data, axis=1) \ndrop_column_X_valid = X_valid.drop(cols_missing_data, axis=1)\n\nprint(\"MAE (Drop columns with missing values):\")\nprint(score_dataset(drop_column_X_train, drop_column_X_valid, y_train, y_valid)) # 17837.82570776256","f72bab2b":"from sklearn.impute import SimpleImputer\n\n# Fill in the lines below: imputation. Put your code here \nmy_imputer = SimpleImputer(strategy='mean') \nimputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\nimputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid)) \n\n# From below code run, you can see NaN is replaced by its mean value, i.e LotFrontage have NaN and its imputed to 69.614017\n# Uncomment below 3 lines to see difference\n# print(X_train.head()) \n# print(\"================================================================================\")\n# print(imputed_X_train.head()) \n\n# imputation removed column names; put them back\nimputed_X_train.columns = X_train.columns \nimputed_X_valid.columns = X_valid.columns\n\nprint(\"================================================================================\")\nprint(\"MAE (Imputation) mean approach:\")\nprint(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid)) # 18062.894611872147","9c28daac":"from sklearn.impute import SimpleImputer\n\n# Create imputation object\nmy_imputer = SimpleImputer(strategy='median') \nimputed_X_train_median = pd.DataFrame(my_imputer.fit_transform(X_train))\nimputed_X_valid_median = pd.DataFrame(my_imputer.transform(X_valid)) \n\n# imputation removed column names; put them back\nimputed_X_train_median.columns = X_train.columns \nimputed_X_valid_median.columns = X_valid.columns\n\nprint(\"MAE (Imputation) median approach:\")\nprint(score_dataset(imputed_X_train_median, imputed_X_valid_median, y_train, y_valid)) # 17791.59899543379","5b731b36":"# Make copy to avoid changing original data (when imputing)\nX_train_plus = X_train.copy()\nX_valid_plus = X_valid.copy()\n\n# Make new columns indicating what will be imputed\nfor col in cols_missing_data:\n    X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull()\n    X_valid_plus[col + '_was_missing'] = X_valid_plus[col].isnull()\n# print(X_train_plus.shape) # Result: (1168, 39), you can see 3 colums added with suffix '_was_missing', before it was (1168, 36)\n# Above operation will add new columns with suffix '_was_missing', if data missing in original column than return true else false\n\n# Imputation\nmy_imputer = SimpleImputer()\nimputed_X_train_plus = pd.DataFrame(my_imputer.fit_transform(X_train_plus))\nimputed_X_valid_plus = pd.DataFrame(my_imputer.transform(X_valid_plus))\n\n# Imputation removed column names; put them back\nimputed_X_train_plus.columns = X_train_plus.columns\nimputed_X_valid_plus.columns = X_valid_plus.columns\n\nprint(\"MAE from Approach 3 (An Extension to Imputation):\")\nprint(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))\n","a8b77280":"from sklearn.impute import SimpleImputer\n\n# Create imputation object from median strategy\n# Below is some repetive code, but it is for explanation as how we use median prediction\nmy_imputer = SimpleImputer(strategy='median') \nimputed_X_train_median = pd.DataFrame(my_imputer.fit_transform(X_train))\n\n# Get test with numeric values only, so exclude object for this notebook\nX_test_full = X_test_full.select_dtypes(exclude=['object'])\nimputed_X_test_median = pd.DataFrame(my_imputer.transform(X_test_full)) \n\n# imputation removed column names; put them back\nimputed_X_train_median.columns = X_train.columns\nimputed_X_test_median.columns = X_test_full.columns\n\n# Redefining model to use with our Approach 2 (B) : Imputation (median) strategy  \nmodel = RandomForestRegressor(n_estimators=100, random_state=0)\nmodel.fit(imputed_X_train_median, y_train)\npreds = model.predict(imputed_X_test_median)\n\n# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test_full.index,\n                       'SalePrice': preds})\noutput.to_csv('home-data-for-ml-course-handle-missing-values-submission.csv', index=False)\n# Download file and submit, Its gave me MAE: 16619.07644 for real sumbited result at, https:\/\/www.kaggle.com\/c\/home-data-for-ml-course","a03ff1ca":"# **Simple explanation of how to handle missing values**\n\nWe refer below competition for tutorial,\nhttps:\/\/www.kaggle.com\/c\/home-data-for-ml-course\n\nCover below course topic,\nhttps:\/\/www.kaggle.com\/alexisbcook\/missing-values\n\n","5436ce1a":"![Lets start](https:\/\/i.ibb.co\/y4RRqQS\/lets-start.jpg)","eae7a941":"# Create common function to get Mean absolute error","68c34a84":"# Approach 1 : Drop columns with missing values","3171013d":"# Approach 3 (An Extension to Imputation)","3ef52096":"# Approach 2 (B) : Imputation (median) strategy","f3318f55":"![Thank you](https:\/\/i.ibb.co\/7vRbVHd\/thank-you-ribbon-sticker-thank-you-sign-thank-you-banner.jpg)","7e842d2e":"# Now you can see with below approach we will have different MAE\n\n**Approach 1 : Drop columns with missing values ->** 17837.82570776256\n\n**Approach 2 (A) : Imputation (mean) strategy ->** 18062.894611872147\n\n**Approach 2 (B) : Imputation (median) strategy ->** 17791.59899543379\n\n**Approach 3 (An Extension to Imputation) ->** 18148.417180365297\n\n\n**Conclusion:**\n\n***Approach 2 (B) : Imputation (median) strategy gives less MAE so lets submit result with this approach***\n\n","452e4d30":"# Lets collect data for train and test","5869e3be":"# Approach 2 (A) : Imputation (mean) strategy"}}