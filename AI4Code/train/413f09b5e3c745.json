{"cell_type":{"f130d7e2":"code","0d2e498b":"code","cedd921e":"code","cc8ae067":"code","4cab653b":"code","ee575301":"code","3c6126c2":"code","5d36e020":"code","5cdab123":"code","5905f202":"code","ca23bc8b":"code","0de0f75c":"code","570e9e36":"code","01397732":"code","a37649dd":"code","897058e9":"code","7e40e998":"code","eb3abce9":"code","2bef0ab5":"markdown","c212c640":"markdown","3e20f653":"markdown","a4c62746":"markdown","7be1314b":"markdown","39d58828":"markdown","29a862a6":"markdown","a4530e47":"markdown","5f356608":"markdown","0adbaea7":"markdown","44b1b3b7":"markdown","69bd78e9":"markdown","c4388c77":"markdown"},"source":{"f130d7e2":"import os\n\nimport random\nimport seaborn as sns\nimport cv2\n\n\nimport pandas as pd\npd.set_option('display.max_colwidth', 1000)\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport PIL\nimport IPython.display as ipd\nimport glob\nimport h5py\nimport plotly.graph_objs as go\nimport plotly.express as px\nfrom PIL import Image, ImageDraw\nfrom tempfile import mktemp\n\n\nfrom bokeh.layouts import column, row\nfrom bokeh.models import ColumnDataSource, LinearAxis, Range1d\nfrom bokeh.models.tools import HoverTool\nfrom bokeh.palettes import BuGn4\nfrom bokeh.plotting import figure, output_notebook, show\nfrom bokeh.transform import cumsum\nfrom math import pi\n\noutput_notebook()\n\nfrom IPython.display import Image, display\nimport warnings\nwarnings.filterwarnings(\"ignore\")","0d2e498b":"image_samples = os.listdir('..\/input\/landmark-recognition-2020\/')\n\nBASE_PATH = '..\/input\/landmark-recognition-2020'\n\nTRAIN_DIR = f'{BASE_PATH}\/train'\nTRST_DIR = f'{BASE_PATH}\/test'\n\nprint('Reading Data ...')\ntrain = pd.read_csv(f'{BASE_PATH}\/train.csv')\nsubmission = pd.read_csv(f'{BASE_PATH}\/sample_submission.csv')\nprint('Reading data is completed')","cedd921e":"display(train.head(10))\nprint(\"Shape of train_data : \", train.shape)","cc8ae067":"display(submission.head())\nprint(\"Shape of Sample Submission\", submission.shape)","4cab653b":"# display top 10 landmarks\n\nlandmark = train.landmark_id.value_counts()\nlandmark_df = pd.DataFrame({'landmark_id': landmark.index, 'frequency': landmark.values}).head(10)\n\nlandmark_df['landmark_id'] = landmark_df.landmark_id.apply(lambda x: f'landmark_id_{x}')\nprint(landmark_df.head())\n\nfig = px.bar(landmark_df, x=\"frequency\", y = \"landmark_id\", color='landmark_id', hover_data = [\"landmark_id\", \"frequency\"],\n            height = 500, title = 'Number of Images per landmark_id (Top 10 landmark_ids)'\n            )\n\nfig.show()","ee575301":"# display bottom 10 landmarks\n\nlandmark = train.landmark_id.value_counts()\nlandmark_df = pd.DataFrame({'landmark_id': landmark.index, 'frequency': landmark.values}).tail(10)\n\nlandmark_df['landmark_id'] = landmark_df.landmark_id.apply(lambda x: f'landmark_id_{x}')\n\n\nfig = px.bar(landmark_df, x=\"frequency\", y = \"landmark_id\", color='landmark_id', hover_data = [\"landmark_id\", \"frequency\"],\n            height = 500, title = 'Number of Images per landmark_id (Top 10 landmark_ids)'\n            )\n\nfig.show()","3c6126c2":"# Missing Data in the training set\ntotal = train.isnull().sum().sort_values(ascending= False)\npercent = (train.isnull().sum()\/train.isnull().count()).sort_values(ascending = False)\nmissing_train_data = pd.concat([total, percent], axis = 1, keys = ['Total', 'Percent'])\nmissing_train_data.head()","5d36e020":"#Class distribution\n\nplt.figure(figsize = (10, 8))\nplt.title('Category Distribuition')\nsns.distplot(train['landmark_id'])\n\nplt.show()","5cdab123":"print(\"Number of classes under 20 occurences\",\n      (train['landmark_id'].value_counts() <= 20).sum(),\n      'out of total number of categories',len(train['landmark_id'].unique()))","5905f202":"import PIL\nfrom PIL import Image, ImageDraw\n\ndef display_images(images, title=None): \n    f, ax = plt.subplots(5,5, figsize=(18,22))\n    if title:\n        f.suptitle(title, fontsize = 30)\n\n    for i, image_id in enumerate(images):\n        image_path = os.path.join(TRAIN_DIR, f'{image_id[0]}\/{image_id[1]}\/{image_id[2]}\/{image_id}.jpg')\n        image = Image.open(image_path)\n        \n        ax[i\/\/5, i%5].imshow(image) \n        image.close()       \n        ax[i\/\/5, i%5].axis('off')\n\n        landmark_id = train[train.id==image_id.split('.')[0]].landmark_id.values[0]\n        ax[i\/\/5, i%5].set_title(f\"ID: {image_id.split('.')[0]}\\nLandmark_id: {landmark_id}\", fontsize=\"12\")\n\n    plt.show()","ca23bc8b":"samples = train.sample(25).id.values\ndisplay_images(samples)","0de0f75c":"samples = train[train.landmark_id == 138982].sample(25).id.values\n\n\ndisplay_images(samples)\n","570e9e36":"lands = pd.DataFrame(train.landmark_id.value_counts())\nlands.reset_index(inplace=True)\nlands.columns = ['landmark_id','count']","01397732":"print(\"Number of classes {}\".format(lands.shape[0]))","a37649dd":"print(\"Total of examples in train set = \",lands['count'].sum())","897058e9":"NUM_THRESHOLD = 50\ntop_lands = set(lands[lands['count'] >= NUM_THRESHOLD]['landmark_id'])\nprint(\"Number of TOP classes {}\".format(len(top_lands)))","7e40e998":"new_train = train[train['landmark_id'].isin(top_lands)]\nprint(\"Total of examples in subset of train: {}\".format(new_train.shape[0]))","eb3abce9":"ax = lands['count'].plot(loglog=True, grid=True)\nax.set(xlabel=\"Landmarks\", ylabel=\"Count\")","2bef0ab5":"# 2. **Loading Data**","c212c640":"# Target Distribution (Number of images per landmark_id)","3e20f653":"The dataset comprises of following important files:\n\n**train.csv**: This file contains, ids and targets\n* id: image id\n* landmark_id: target landmark id","a4c62746":"**#References -**\nhttps:\/\/www.kaggle.com\/rohitsingh9990\/glr-eda-all-you-need-to-know\/data\n\nhttps:\/\/www.kaggle.com\/rsmits\/keras-landmark-or-non-landmark-identification\n\nhttps:\/\/www.kaggle.com\/codename007\/a-very-extensive-landmark-exploratory-analysis","7be1314b":"# 4 Visulaization of Images","39d58828":"# 1. Let's begin by importing libraries and packages","29a862a6":"# 3. Performing Exploratory Data Analysis","a4530e47":"**The most frequent landmark_id is 138982 and the frequency is 6272**","5f356608":"# Graphical Visualization of Landmarks Vs. Counts","0adbaea7":"**Visualizing landmarks with most number of images**","44b1b3b7":"# Google Landmark Recognition 2020\n\n**Let's perform Exploratory Data Analysis to understand the data better**\n\n","69bd78e9":"# Let's see least frequent landmarks","c4388c77":"**There are many least frequency landmarks with frequency as 2**"}}