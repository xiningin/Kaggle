{"cell_type":{"943b8046":"code","0d123f6f":"code","c7703984":"code","dfcda340":"code","a8695223":"code","096de8d3":"code","6756e0b7":"code","853dd08c":"code","8d79edae":"code","4cd1d590":"code","7b689ee4":"code","5efc4872":"markdown"},"source":{"943b8046":"import numpy as np\nimport os\nimport pandas as pd\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import callbacks\nfrom keras.utils.vis_utils import plot_model\nimport tflearn.data_utils as du\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix","0d123f6f":"train_images = np.load('..\/input\/kmnist-train-imgs.npz')['arr_0']\ntest_images = np.load('..\/input\/kmnist-test-imgs.npz')['arr_0']\ntrain_labels = np.load('..\/input\/kmnist-train-labels.npz')['arr_0']\ntest_labels = np.load('..\/input\/kmnist-test-labels.npz')['arr_0']","c7703984":"x_train, x_test, y_train, y_test = train_images, test_images, train_labels, test_labels\nx_train = x_train.reshape(-1, 28, 28, 1).astype('float32') \/ 255.\nx_test = x_test.reshape(-1, 28, 28, 1).astype('float32') \/ 255.\ny_train = du.to_categorical(y_train,10)\ny_test = du.to_categorical(y_test,10)","dfcda340":"import keras.backend as K\nimport tensorflow as tf\nfrom keras import initializers, layers\n\nclass Length(layers.Layer):\n    \"\"\"\n    Compute the length of vectors. This is used to compute a Tensor that has the same shape with y_true in margin_loss\n    inputs: shape=[dim_1, ..., dim_{n-1}, dim_n]\n    output: shape=[dim_1, ..., dim_{n-1}]\n    \"\"\"\n    def call(self, inputs, **kwargs):\n        return K.sqrt(K.sum(K.square(inputs), -1))\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[:-1]\n\nclass Mask(layers.Layer):\n    \"\"\"\n    Mask a Tensor with shape=[None, d1, d2] by the max value in axis=1.\n    Output shape: [None, d2]\n    \"\"\"\n    def call(self, inputs, **kwargs):\n        # use true label to select target capsule, shape=[batch_size, num_capsule]\n        if type(inputs) is list:  # true label is provided with shape = [batch_size, n_classes], i.e. one-hot code.\n            assert len(inputs) == 2\n            inputs, mask = inputs\n        else:  # if no true label, mask by the max length of vectors of capsules\n            x = inputs\n            # Enlarge the range of values in x to make max(new_x)=1 and others < 0\n            x = (x - K.max(x, 1, True)) \/ K.epsilon() + 1\n            mask = K.clip(x, 0, 1)  # the max value in x clipped to 1 and other to 0\n\n        # masked inputs, shape = [batch_size, dim_vector]\n        inputs_masked = K.batch_dot(inputs, mask, [1, 1])\n        return inputs_masked\n\n    def compute_output_shape(self, input_shape):\n        if type(input_shape[0]) is tuple:  # true label provided\n            return tuple([None, input_shape[0][-1]])\n        else:\n            return tuple([None, input_shape[-1]])\n\n\ndef squash(vectors, axis=-1):\n    \"\"\"\n    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n    :param vectors: some vectors to be squashed, N-dim tensor\n    :param axis: the axis to squash\n    :return: a Tensor with same shape as input vectors\n    \"\"\"\n    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n    scale = s_squared_norm \/ (1 + s_squared_norm) \/ K.sqrt(s_squared_norm)\n    return scale * vectors\n\n\nclass CapsuleLayer(layers.Layer):\n    \"\"\"\n    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the \n    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_vector] and output shape = \\\n    [None, num_capsule, dim_vector]. For Dense Layer, input_dim_vector = dim_vector = 1.\n    \n    :param num_capsule: number of capsules in this layer\n    :param dim_vector: dimension of the output vectors of the capsules in this layer\n    :param num_routings: number of iterations for the routing algorithm\n    \"\"\"\n    def __init__(self, num_capsule, dim_vector, num_routing=3,\n                 kernel_initializer='glorot_uniform',\n                 bias_initializer='zeros',\n                 **kwargs):\n        super(CapsuleLayer, self).__init__(**kwargs)\n        self.num_capsule = num_capsule\n        self.dim_vector = dim_vector\n        self.num_routing = num_routing\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n\n    def build(self, input_shape):\n        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_vector]\"\n        self.input_num_capsule = input_shape[1]\n        self.input_dim_vector = input_shape[2]\n\n        # Transform matrix\n        self.W = self.add_weight(shape=[self.input_num_capsule, self.num_capsule, self.input_dim_vector, self.dim_vector],\n                                 initializer=self.kernel_initializer,\n                                 name='W')\n\n        # Coupling coefficient. The redundant dimensions are just to facilitate subsequent matrix calculation.\n        self.bias = self.add_weight(shape=[1, self.input_num_capsule, self.num_capsule, 1, 1],\n                                    initializer=self.bias_initializer,\n                                    name='bias',\n                                    trainable=False)\n        self.built = True\n\n    def call(self, inputs, training=None):\n        # inputs.shape=[None, input_num_capsule, input_dim_vector]\n        # Expand dims to [None, input_num_capsule, 1, 1, input_dim_vector]\n        inputs_expand = K.expand_dims(K.expand_dims(inputs, 2), 2)\n\n        # Replicate num_capsule dimension to prepare being multiplied by W\n        # Now it has shape = [None, input_num_capsule, num_capsule, 1, input_dim_vector]\n        inputs_tiled = K.tile(inputs_expand, [1, 1, self.num_capsule, 1, 1])\n\n        \"\"\"  \n        # Compute `inputs * W` by expanding the first dim of W. More time-consuming and need batch_size.\n        # Now W has shape  = [batch_size, input_num_capsule, num_capsule, input_dim_vector, dim_vector]\n        w_tiled = K.tile(K.expand_dims(self.W, 0), [self.batch_size, 1, 1, 1, 1])\n        \n        # Transformed vectors, inputs_hat.shape = [None, input_num_capsule, num_capsule, 1, dim_vector]\n        inputs_hat = K.batch_dot(inputs_tiled, w_tiled, [4, 3])\n        \"\"\"\n        # Compute `inputs * W` by scanning inputs_tiled on dimension 0. This is faster but requires Tensorflow.\n        # inputs_hat.shape = [None, input_num_capsule, num_capsule, 1, dim_vector]\n        inputs_hat = tf.scan(lambda ac, x: K.batch_dot(x, self.W, [3, 2]),\n                             elems=inputs_tiled,\n                             initializer=K.zeros([self.input_num_capsule, self.num_capsule, 1, self.dim_vector]))\n        \"\"\"\n        # Routing algorithm V1. Use tf.while_loop in a dynamic way.\n        def body(i, b, outputs):\n            c = tf.nn.softmax(self.bias, dim=2)  # dim=2 is the num_capsule dimension\n            outputs = squash(K.sum(c * inputs_hat, 1, keepdims=True))\n            b = b + K.sum(inputs_hat * outputs, -1, keepdims=True)\n            return [i-1, b, outputs]\n\n        cond = lambda i, b, inputs_hat: i > 0\n        loop_vars = [K.constant(self.num_routing), self.bias, K.sum(inputs_hat, 1, keepdims=True)]\n        _, _, outputs = tf.while_loop(cond, body, loop_vars)\n        \"\"\"\n        # Routing algorithm V2. Use iteration. V2 and V1 both work without much difference on performance\n        assert self.num_routing > 0, 'The num_routing should be > 0.'\n        for i in range(self.num_routing):\n            c = tf.nn.softmax(self.bias, dim=2)  # dim=2 is the num_capsule dimension\n            # outputs.shape=[None, 1, num_capsule, 1, dim_vector]\n            outputs = squash(K.sum(c * inputs_hat, 1, keepdims=True))\n\n            # last iteration needs not compute bias which will not be passed to the graph any more anyway.\n            if i != self.num_routing - 1:\n                # self.bias = K.update_add(self.bias, K.sum(inputs_hat * outputs, [0, -1], keepdims=True))\n                self.bias += K.sum(inputs_hat * outputs, -1, keepdims=True)\n            # tf.summary.histogram('BigBee', self.bias)  # for debugging\n        return K.reshape(outputs, [-1, self.num_capsule, self.dim_vector])\n\n    def compute_output_shape(self, input_shape):\n        return tuple([None, self.num_capsule, self.dim_vector])\n\n\ndef PrimaryCap(inputs, dim_vector, n_channels, kernel_size, strides, padding):\n    \"\"\"\n    Apply Conv2D `n_channels` times and concatenate all capsules\n    :param inputs: 4D tensor, shape=[None, width, height, channels]\n    :param dim_vector: the dim of the output vector of capsule\n    :param n_channels: the number of types of capsules\n    :return: output tensor, shape=[None, num_capsule, dim_vector]\n    \"\"\"\n    output = layers.Conv2D(filters=dim_vector*n_channels, kernel_size=kernel_size, strides=strides, padding=padding)(inputs)\n    outputs = layers.Reshape(target_shape=[-1, dim_vector])(output)\n    return layers.Lambda(squash)(outputs)","a8695223":"from keras import layers, models\nfrom keras import backend as K\nfrom keras.utils import to_categorical\ndef CapsNet(input_shape, n_class, num_routing):\n    \"\"\"\n    A Capsule Network on MNIST.\n    :param input_shape: data shape, 4d, [None, width, height, channels]\n    :param n_class: number of classes\n    :param num_routing: number of routing iterations\n    :return: A Keras Model with 2 inputs and 2 outputs\n    \"\"\"\n    x = layers.Input(shape=input_shape)\n\n    # Layer 1: Just a conventional Conv2D layer\n    conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n\n    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_vector]\n    primarycaps = PrimaryCap(conv1, dim_vector=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n\n    # Layer 3: Capsule layer. Routing algorithm works here.\n    digitcaps = CapsuleLayer(num_capsule=n_class, dim_vector=16, num_routing=num_routing, name='digitcaps')(primarycaps)\n\n    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n    # If using tensorflow, this will not be necessary. :)\n    out_caps = Length(name='out_caps')(digitcaps)\n\n    # Decoder network.\n    y = layers.Input(shape=(n_class,))\n    masked = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer.\n    x_recon = layers.Dense(512, activation='relu')(masked)\n    x_recon = layers.Dense(1024, activation='relu')(x_recon)\n    x_recon = layers.Dense(784, activation='sigmoid')(x_recon)\n    x_recon = layers.Reshape(target_shape=[28, 28, 1], name='out_recon')(x_recon)\n\n    # two-input-two-output keras Model\n    return models.Model([x, y], [out_caps, x_recon])","096de8d3":"def margin_loss(y_true, y_pred):\n    \"\"\"\n    Margin loss for Eq.(4). When y_true[i, :] contains not just one '1',\n    this loss should work too. Not test it.\n    :param y_true: [None, n_classes]\n    :param y_pred: [None, num_capsule]\n    :return: a scalar loss value.\n    \"\"\"\n    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + 0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n    \n    return K.mean(K.sum(L, 1))","6756e0b7":"# define model\nmodel = CapsNet(input_shape=[28, 28, 1],\n               n_class=10,\n               num_routing=3)\nmodel.summary()\ntry:\n    plot_model(model, to_file='model.png', show_shapes=True)\nexcept Exception as e:\n    print('No fancy plot {}'.format(e))","853dd08c":"def train(model, data, epoch_size_frac=1.0):\n    \"\"\"\n    Training a CapsuleNet\n    :param model: the CapsuleNet model\n    :param data: a tuple containing training and testing data, like `((x_train, y_train), (x_test, y_test))`\n    :param args: arguments\n    :return: The trained model\n    \"\"\"\n    # unpacking the data\n    (x_train, y_train), (x_test, y_test) = data\n\n    # callbacks\n    log = callbacks.CSVLogger('log.csv')\n    checkpoint = callbacks.ModelCheckpoint('weights-{epoch:02d}.h5',\n                                           save_best_only=True, save_weights_only=True, verbose=1)\n    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: 0.001 * np.exp(-epoch \/ 10.))\n\n    # compile the model\n    model.compile(optimizer='adam',\n                  loss=[margin_loss, 'mse'],\n                  loss_weights=[1., 0.0005],\n                  metrics={'out_caps': 'accuracy'})\n\n    \"\"\"\n    # Training without data augmentation:\n    model.fit([x_train, y_train], [y_train, x_train], batch_size=args.batch_size, epochs=args.epochs,\n              validation_data=[[x_test, y_test], [y_test, x_test]], callbacks=[log, tb, checkpoint])\n    \"\"\"\n\n    # -----------------------------------Begin: Training with data augmentation -----------------------------------#\n    def train_generator(x, y, batch_size, shift_fraction=0.):\n        train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n                                           height_shift_range=shift_fraction)  \n        generator = train_datagen.flow(x, y, batch_size=batch_size)\n        while 1:\n            x_batch, y_batch = generator.next()\n            yield ([x_batch, y_batch], [y_batch, x_batch])\n\n    # Training with data augmentation. If shift_fraction=0., also no augmentation.\n    model.fit_generator(generator=train_generator(x_train, y_train, 64, 0.1),\n                        steps_per_epoch=int(epoch_size_frac*y_train.shape[0] \/ 64),\n                        epochs=30,\n                        validation_data=[[x_test, y_test], [y_test, x_test]],\n                        callbacks=[log, checkpoint, lr_decay])\n    # -----------------------------------End: Training with data augmentation -----------------------------------#\n\n    model.save_weights('trained_model.h5')\n    print('Trained model saved to \\'trained_model.h5\\'')\n\n    return model","8d79edae":"train(model=model, data=((x_train, y_train), (x_test, y_test)), \n      epoch_size_frac = 0.5) # do 10% of an epoch (takes too long)","4cd1d590":"def combine_images(generated_images):\n    num = generated_images.shape[0]\n    width = int(np.sqrt(num))\n    height = int(np.ceil(float(num)\/width))\n    shape = generated_images.shape[1:3]\n    image = np.zeros((height*shape[0], width*shape[1]),\n                     dtype=generated_images.dtype)\n    for index, img in enumerate(generated_images):\n        i = int(index\/width)\n        j = index % width\n        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n            img[:, :, 0]\n    return image\n\ndef test(model, data):\n    x_test, y_test = data\n    y_pred, x_recon = model.predict([x_test, y_test], batch_size=100)\n    print('-'*50)\n    print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1))\/y_test.shape[0])\n\n    import matplotlib.pyplot as plt\n    from PIL import Image\n\n    img = combine_images(np.concatenate([x_test[:50],x_recon[:50]]))\n    image = img * 255\n    Image.fromarray(image.astype(np.uint8)).save(\"real_and_recon.png\")\n    print()\n    print('Reconstructed images are saved to .\/real_and_recon.png')\n    print('-'*50)\n    plt.imshow(plt.imread(\"real_and_recon.png\", ))\n    plt.show()","7b689ee4":"test(model=model, data=(x_test, y_test))","5efc4872":"CapsuleNet from https:\/\/www.kaggle.com\/kmader\/capsulenet-on-mnist"}}