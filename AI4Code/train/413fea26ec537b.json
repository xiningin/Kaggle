{"cell_type":{"8102c34c":"code","823be5eb":"code","eecc2f9f":"code","3952d034":"code","99cc5f49":"code","b2b447d7":"code","69f9e0ae":"code","3d464c44":"code","f8474d9c":"code","e9a75cee":"code","9a7f1c0e":"code","e8885773":"code","fac40c26":"code","68b0b171":"code","bc4f75c0":"code","4a79c0bf":"code","b5974265":"code","915cd288":"code","89874efb":"code","e377aa4f":"code","e5993a9e":"code","7385f107":"code","f2b70ce6":"code","8c5f12b1":"code","07b919f9":"code","fcc01959":"code","7ebd7114":"code","64453d83":"code","b238b654":"code","b8e45561":"code","2d5b659d":"code","054811b1":"code","c3acd3eb":"code","7b0517aa":"code","c4ec6d88":"code","f7bbc56d":"code","779e2466":"code","a007660a":"code","3dcdcf9a":"code","74927126":"code","8a761fd8":"code","2e412482":"code","a1e44a33":"code","9a4bb6f5":"code","aa3d1d63":"code","cce4e65c":"code","39316f2d":"code","c8f84ef8":"code","258fe19c":"code","b83ff8d0":"code","3d16c8b5":"code","90a2f63e":"code","6692a5ba":"code","dd87b1a2":"code","97e60f25":"code","00c0c435":"code","1cda5f23":"code","6e668b23":"code","3556fa92":"code","4f0ecb29":"code","e8372752":"code","9584b12d":"code","9dd2a115":"code","6339d9f6":"code","ec2d9458":"code","9a758e8b":"code","5d3259ef":"code","d80f8f0a":"code","86ed82ca":"code","ea0313d0":"code","0bf984dd":"code","2cc17dd2":"code","9764b498":"code","8f020f2f":"code","489c502e":"code","955e4ada":"code","f117fe9f":"code","99a6ebcf":"code","ac52e853":"code","9c5eadaf":"code","644a0b0f":"code","3f7ece2e":"code","bbae943b":"code","4e3b2606":"code","027494a9":"code","d6c3480f":"code","35f549d3":"code","0f5ecc94":"code","d2c056a1":"code","5a8b5b92":"code","b6e271d0":"code","ec665537":"code","1c785a07":"code","9a45313c":"code","0a68303a":"code","17b22afb":"code","641beb97":"code","4647aea6":"code","9b817040":"code","4a898a4e":"code","52d9ab0c":"code","1e305a6c":"code","e4bc7af1":"code","c6bf451b":"code","6bd71007":"code","88ca391f":"code","be0431cf":"code","1e8eb3b5":"code","326453aa":"code","ed7981a6":"code","1a595513":"code","b9931042":"code","d30f7f25":"code","39c5d296":"code","568cf1f2":"code","cf427c5e":"code","42c07f70":"code","7461e9e2":"code","bedd0d05":"code","51254aef":"code","36e682e2":"code","8b5bb172":"code","893c5670":"code","426ce336":"code","914a4aae":"code","3bc36fdc":"code","0e16b1b1":"code","39cf3573":"code","77ce0193":"code","f08f1bc8":"code","b0e750f3":"code","c2dc2e50":"code","580875f6":"code","4d2762c7":"code","4657828b":"code","74ea9c3b":"code","5135651f":"code","a7e60e9a":"code","fc292a41":"code","4dfad031":"code","61b0b1a7":"code","965b2b0c":"code","21da2a44":"code","7540bed5":"code","4c3569d6":"code","3a396abb":"code","10105a97":"code","a512d925":"code","bdbe1d8f":"code","96b10b1d":"code","8fe899de":"code","971c411d":"code","0bec8ae7":"code","71b247fb":"code","ef9221dc":"code","b99ade9f":"code","30a597e0":"code","ac938ffa":"code","240a0968":"code","55d72d52":"code","4f3650ed":"code","1bc92305":"code","9bfc538c":"code","e44a1a6f":"code","b4a540da":"code","edb6c0c5":"code","5f049d64":"code","3696d173":"code","403e0992":"code","ec2a6fcc":"code","dd4baae0":"code","8614f57d":"code","08e65d01":"code","5e1d64a2":"code","caea7631":"code","eb11706b":"code","31cbf751":"code","0ca3acf3":"code","1ed1da77":"code","b9e4b153":"code","a61b91d1":"code","531e11b5":"code","3e680d4e":"code","b2a758c0":"code","1fe14354":"code","7cdc3270":"code","d1adcabe":"code","b88563ac":"code","32f16c39":"code","6a2d7b8d":"code","0a144e6c":"code","1707a878":"code","0fc3522e":"code","2d3a43e7":"code","9e2736c7":"code","1510b8dc":"code","35cdff43":"code","45cf7a0c":"code","931200fa":"code","263aed0c":"code","38e3f21e":"code","d5c0db41":"code","6d4a494e":"code","46002ffa":"code","f2863fac":"code","975c0add":"code","a0694159":"code","d28c43cb":"code","4775b707":"code","938b11b6":"code","2ff207ec":"code","5ff94ac0":"code","c6856e62":"markdown","76a3bf1c":"markdown","d95a0fcd":"markdown","63ea6f2f":"markdown","966b4cb5":"markdown","78f99ffd":"markdown","497b4a39":"markdown","a21b7d3d":"markdown","d32431f4":"markdown","271150cd":"markdown","0ac679ad":"markdown","09756ced":"markdown","a4e60f4f":"markdown","b6853bad":"markdown","03c9ab34":"markdown","9a3b176d":"markdown","9984ec80":"markdown","a4fd5566":"markdown","8f43e8db":"markdown","0b5ea905":"markdown","ec0e84cf":"markdown","4efcfc88":"markdown","8f8903f8":"markdown","a76e9726":"markdown","1131807a":"markdown","7f4b29a9":"markdown","fbd70614":"markdown","d21eabdf":"markdown","0a39b6fe":"markdown","1853ad7a":"markdown","3f91f83c":"markdown","0e8e0f46":"markdown","0f362c2a":"markdown","dc616ce6":"markdown"},"source":{"8102c34c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\nfrom fastai.text import *\nfrom fastai import *\n\nsns.set_style('darkgrid')\n%matplotlib inline\n\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\nfnames=['\/kaggle\/input\/pretrained-models\/lstm_fwd','\/kaggle\/input\/pretrained-models\/itos_wt103']\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","823be5eb":"train_data = pd.read_csv('\/kaggle\/input\/wine-dataset\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/wine-dataset\/test.csv')\ntrain_data.shape","eecc2f9f":"train_data.head()","3952d034":"def nullColumns(train_data):\n    list_of_nullcolumns =[]\n    for column in train_data.columns:\n        total= train_data[column].isna().sum()\n        if total !=0:\n            print('Total Na values is {0} for column {1}' .format(total, column))\n            list_of_nullcolumns.append(column)\n    print('\\n')\n    return list_of_nullcolumns\n\n\ndef percentMissingFeature(data):\n    data_na = (data.isnull().sum() \/ len(data)) * 100\n    data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)[:30]\n    missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n    print(missing_data.head(20))\n    return data_na\n\n\ndef plotMissingFeature(data_na):\n    f, ax = plt.subplots(figsize=(15, 12))\n    plt.xticks(rotation='90')\n    if(data_na.empty ==False):\n        sns.barplot(x=data_na.index, y=data_na)\n        plt.xlabel('Features', fontsize=15)\n        plt.ylabel('Percent of missing values', fontsize=15)\n        plt.title('Percent missing data by feature', fontsize=15)","99cc5f49":"train_data_na = percentMissingFeature(train_data)\nnullColumns(train_data)\nplotMissingFeature(train_data_na)","b2b447d7":"test_data_na = percentMissingFeature(test_data)\nnullColumns(test_data)\nplotMissingFeature(test_data_na)","69f9e0ae":"#train_data =  train_data.drop(columns = ['region_2','designation','user_name','price','points'],axis =1)\n#test_data =  test_data.drop(columns = ['region_2','designation','user_name','price','points'],axis =1)","3d464c44":"train_data['country'] = train_data['country'].fillna('unknown')\ntrain_data['region_1'] = train_data['region_1'].fillna('unknown')\ntrain_data['province'] = train_data['province'].fillna('unknown')\ntrain_data['price'] =  train_data['price'].fillna(train_data['price'].mean())\ntrain_data['quality\/price']  =np.array(np.log1p(train_data['points']))\/np.array(np.log1p(train_data['price']))\ntrain_data['value_for_money'] = train_data['quality\/price'].apply(lambda val : 'High' if val > 1.5 else ('Medium' if val > 1.0 else 'Low'))","f8474d9c":"def redness_score(descriptions):\n    return (descriptions.count('cherry',re.I) +\n           descriptions.count('berry',re.I) +\n           descriptions.count('cherries',re.I) +\n           descriptions.count('berries',re.I) +\n           descriptions.count('red',re.I) +\n           descriptions.count('raspberry',re.I) +\n           descriptions.count('raspberries',re.I) +\n           descriptions.count('blueberry',re.I) +\n           descriptions.count('blueberries',re.I)+\n           descriptions.count('blackberry',re.I)+\n           descriptions.count('blackberries',re.I))\n\n\n    \ndef whiteness_score(descriptions):\n    return (descriptions.count(\"lemon\",re.I)+\n            descriptions.count(\"lemons\",re.I)+\n            descriptions.count(\"lime\",re.I)+\n            descriptions.count(\"limes\",re.I)+\n            descriptions.count(\"peach\",re.I)+\n            descriptions.count(\"peaches\",re.I)+\n            descriptions.count(\"white\",re.I)+\n            descriptions.count(\"apricot\",re.I)+\n            descriptions.count(\"pear\",re.I)+\n            descriptions.count(\"apple\",re.I)+\n            descriptions.count(\"nectarine\",re.I)+\n            descriptions.count(\"orange\",re.I)+\n            descriptions.count(\"pineapple\",re.I))\n        ","e9a75cee":"train_data['redness_score'] = train_data['review_description'].apply(lambda r: redness_score(r))\ntrain_data['whiteness_score'] = train_data['review_description'].apply(lambda w: whiteness_score(w))","9a7f1c0e":"wrs = train_data.groupby('variety')['redness_score'].describe().sort_values(by = ['mean'], ascending = False)\nf,ax = plt.subplots(figsize = (10,10))\nsns.barplot(wrs['mean'],wrs.index)\nplt.xticks(fontsize =15)\nplt.yticks(fontsize =15)\nplt.xlabel(\"Average Score\",fontsize =20)\nplt.ylabel(\"Variety\",fontsize =20,rotation = 0)\nplt.title('Wines Redness Score', fontsize=25)\nplt.grid(True)\nplt.show()","e8885773":"wws = train_data.groupby('variety')['whiteness_score'].describe().sort_values(by = ['mean'], ascending = False)\nf,ax = plt.subplots(figsize = (10,10))\nsns.barplot(wws['mean'],wws.index)\nplt.xticks(fontsize =15)\nplt.yticks(fontsize =15)\nplt.xlabel(\"Average Score\",fontsize =20)\nplt.ylabel(\"Variety\",fontsize =20,rotation = 0)\nplt.title('Wines Whiteness Score', fontsize=25)\nplt.grid(True)\nplt.show()","fac40c26":"cwv = train_data.groupby('variety')['price'].describe().sort_values(by = ['mean'], ascending = False)\nf,ax = plt.subplots(figsize = (10,10))\nsns.barplot(cwv['mean'],cwv.index)\nplt.xticks(fontsize =15)\nplt.yticks(fontsize =15)\nplt.xlabel(\"Average Price\",fontsize =20)\nplt.ylabel(\"Variety\",fontsize =20,rotation = 0)\nplt.title('Wines Average Cost', fontsize=25)\nplt.grid(True)\nplt.show()","68b0b171":"hrw = train_data.groupby('country')['points'].describe().sort_values(by = ['mean'], ascending = False)[0:5]\nf,ax = plt.subplots(figsize = (10,10))\nsns.pointplot(hrw.index,hrw['mean'],sort = False)\nplt.xticks(fontsize =15)\nplt.yticks(fontsize =15)\nplt.xlabel(\"Country\",fontsize =20)\nplt.ylabel(\"Average Points\",fontsize =20,rotation = 0)\nplt.title('Top 5 Highly Rated Wine Producing countries', fontsize=25)\nplt.grid(True)\nplt.show()","bc4f75c0":"cw = train_data.groupby('country')['price'].describe().sort_values(by = ['mean'], ascending = False)[0:5]\nf,ax = plt.subplots(figsize = (10,10))\nsns.pointplot(cw.index,cw['mean'],sort = False)\nplt.xticks(fontsize =15)\nplt.yticks(fontsize =15)\nplt.xlabel(\"Country\",fontsize =20)\nplt.ylabel(\"Average Price\",fontsize =20,rotation = 0)\nplt.title('Top 5 Costliest Wine Producing countries', fontsize=25)\nplt.grid(True)\nplt.show()","4a79c0bf":"vfm = train_data.groupby('country')['quality\/price'].describe().sort_values(by = ['mean'], ascending = False)[0:10]\nf,ax = plt.subplots(figsize = (10,10))\nsns.pointplot(vfm.index,vfm['mean'],sort = False,)\nplt.xticks(fontsize =15,rotation =90)\nplt.yticks(fontsize =15)\nplt.xlabel(\"Country\",fontsize =20)\nplt.ylabel(\"Value for Money \",fontsize =20)\nplt.title('Top 10 Value for Money Wine Producing countries', fontsize=25)\nplt.grid(True)\nplt.show()","b5974265":"cw = train_data.groupby(by = ['country','winery'])['price'].describe().sort_values(by = ['mean'], ascending = False)","915cd288":"ccw =cw[0:20]\nf,ax = plt.subplots(figsize = (20,20))\nsns.barplot(ccw.index,ccw['mean'])\nplt.xticks(fontsize =15,rotation =90)\nplt.yticks(fontsize =15)\nplt.xlabel(\"(Country,Winery)\",fontsize =20)\nplt.ylabel(\"Price \",fontsize =20)\nplt.title('Costliest Wineries', fontsize=25)\nplt.show()","89874efb":"ecw = cw[-20:]\nf,ax = plt.subplots(figsize = (20,20))\nsns.barplot(ecw.index,ecw['mean'])\nplt.xticks(fontsize =15,rotation =90)\nplt.yticks(fontsize =15)\nplt.xlabel(\"(Country,Winery)\",fontsize =20)\nplt.ylabel(\"Price \",fontsize =20)\nplt.title('Economic Wineries', fontsize=25)\nplt.show()","e377aa4f":"hrv = train_data.groupby('variety')['points'].describe().sort_values(by = ['mean'], ascending = False)[0:5]\nf,ax = plt.subplots(figsize = (10,10))\nsns.pointplot(hrv.index,hrv['mean'],sort = False)\nplt.xticks(fontsize =15,rotation =90)\nplt.yticks(fontsize =15)\nplt.xlabel(\"Wines\",fontsize =20)\nplt.ylabel(\"Average Points\",fontsize =20,rotation = 0)\nplt.title('Top 5 Highly Rated Wines', fontsize=25)\nplt.grid(True)\nplt.show()","e5993a9e":"f, axs = plt.subplots(1, 3, figsize=(40, 40))\nfor ax, wine in zip(axs, hrv.index[0:3]):\n    review = \" \".join(text for text in train_data[train_data['variety'] == wine]['review_description'])\n    stopwords = set(STOPWORDS)\n    # upadating stop words to eliminate name of varieties from review description\n    stopwords.update([\"drink\", \"now\", \"wine\", \"flavor\", \"flavors\",\"palate\",'Nebbiolo', \n                      'Gr\u00fcner', 'Veltliner', 'Blend','Champagne', 'Riesling','Pinot','Noir'])\n\n    # Generate a word cloud image\n    wcl = WordCloud(stopwords=stopwords, background_color=\"black\").generate(review)\n\n    ax.imshow(wcl, interpolation='bilinear',aspect = 'equal')\n    ax.set_title(wine.capitalize())\n    ax.grid(False)\n\nplt.show()","7385f107":"train_data['all_text_combined0'] = train_data['review_title'] +\" \" + train_data['review_description'] #for training classifier model 2\ntrain_data['all_text_combined1'] = train_data['country'] +\" \" + train_data['review_title'] +\" \" + train_data['review_description'] #for training classifier model 3\ntrain_data['all_text_combined2'] = train_data['country'] +\" \" + train_data['province'] +\" \" + train_data['review_title'] +\" \" + train_data['review_description'] #for training classifier model 4\ntrain_data['all_text_combined3'] = train_data['country'] +\" \" + train_data['province'] +\" \" + train_data['region_1'] +\" \" + train_data['review_title'] +\" \" + train_data['review_description'] #for training classifier model 5\ntrain_data['all_text_combined4'] = train_data['value_for_money'] +\" \" + train_data['review_title'] +\" \" + train_data['review_description'] #for training classifier model 6","f2b70ce6":"test_data['country'] = test_data['country'].fillna('unknown')\ntest_data['region_1'] = test_data['region_1'].fillna('unknown')\ntest_data['province'] = test_data['province'].fillna('unknown')\ntest_data['price'] =  test_data['price'].fillna(test_data['price'].mean())\ntest_data['quality\/price']  =np.array(np.log1p(test_data['points']))\/np.array(np.log1p(test_data['price']))\ntest_data['value_for_money'] = test_data['quality\/price'].apply(lambda val : 'High' if val > 1.5 else ('Medium' if val > 1.0 else 'Low'))","8c5f12b1":"test_data['all_text_combined0'] = test_data['review_title'] +\" \" + test_data['review_description']#for testing classifier model 2\ntest_data['all_text_combined1'] = test_data['country'] +\" \" + test_data['review_title'] +\" \" + test_data['review_description'] #for testing classifier model 3\ntest_data['all_text_combined2'] = test_data['country'] +\" \" + test_data['province'] +\" \" + test_data['review_title'] +\" \" + test_data['review_description'] #for testing classifier model 4\ntest_data['all_text_combined3'] = test_data['country'] +\" \" + test_data['province'] +\" \" + test_data['region_1'] +\" \" + test_data['review_title'] +\" \" + test_data['review_description'] #for testing classifier model 5\ntest_data['all_text_combined4'] = test_data['value_for_money'] +\" \" + test_data['review_title'] +\" \" + test_data['review_description'] #for training classifier model 6","07b919f9":"train_data.head(5)","fcc01959":"train_data_lm1 = (TextList.from_df(df=train_data,path='.',cols='review_description').split_by_rand_pct(0.1).label_for_lm().databunch(bs=48))","7ebd7114":"train_data_lm1.save('train_data_lm1.pkl')","64453d83":"train_data_lm1.vocab.itos[:10]","b238b654":"train_data_lm1.train_ds[0][0]","b8e45561":"train_data_lm1 = load_data('', 'train_data_lm1.pkl', bs=48)","2d5b659d":"train_data_lm1.show_batch(5)","054811b1":"languageModel1 = language_model_learner(train_data_lm1, arch=AWD_LSTM, pretrained_fnames=fnames, drop_mult=0.3)","c3acd3eb":"languageModel1.lr_find()","7b0517aa":"languageModel1.recorder.plot(skip_end=10)","c4ec6d88":"languageModel1.fit_one_cycle(5, 1e-2)","f7bbc56d":"languageModel1.save('fine_tuned1')\nlanguageModel1.save_encoder('fine_tuned_enc1')","779e2466":"data_classifier1 = (TextList.from_df(df=train_data,path='.',cols='review_description', vocab=train_data_lm1.vocab)\n                     .split_by_rand_pct(0.1)\n                     .label_from_df('variety')\n                     .add_test(test_data)\n                     .databunch(bs=48))","a007660a":"data_classifier1.save('data_classifier1.pkl')","3dcdcf9a":"data_classifier1 = load_data('','data_classifier1.pkl',bs=48)","74927126":"data_classifier1.show_batch(10)","8a761fd8":"classifierModel1 = text_classifier_learner(data_classifier1, arch=AWD_LSTM, drop_mult=0.5)\nclassifierModel1.load_encoder('fine_tuned_enc1')\nclassifierModel1.freeze()","2e412482":"classifierModel1.summary()","a1e44a33":"classifierModel1.lr_find()","9a4bb6f5":"classifierModel1.recorder.plot()","aa3d1d63":"classifierModel1.fit_one_cycle(1, 2e-2)","cce4e65c":"for i in range(2,5):\n    classifierModel1.freeze_to(-i)\n    classifierModel1.fit_one_cycle(1,slice((1*10**-i)\/(2.6**4),1*10**-i))\n    print ('')","39316f2d":"classifierModel1.recorder.plot_losses() ##still have to figure out why validation losses are not getting plotted","c8f84ef8":"classifierModel1.unfreeze()\nclassifierModel1.fit_one_cycle(2, slice(1e-5\/(2.6**4),1e-3))","258fe19c":"classifierModel1.fit_one_cycle(5, slice(1e-5,1e-3))\nprint ('')","b83ff8d0":"classifierModel1.save('classifierModel1')","3d16c8b5":"classifierModel1.show_results(rows = 100)","90a2f63e":"train_loss1,train_accuracy1 = classifierModel1.validate(classifierModel1.data.train_dl)","6692a5ba":"valid_loss1,valid_accuracy1 = classifierModel1.validate(classifierModel1.data.train_dl)","dd87b1a2":"print(\"Training Accuracy from model 1 is {0}\".format(train_accuracy1*100))\nprint('')\nprint(\"Validation Accuracy from model 1 is {0}\".format(valid_accuracy1*100))","97e60f25":"def build_submission_file(model,predictions,fileName):\n    \n    labels = []\n    final_data =pd.read_csv('\/kaggle\/input\/wine-dataset\/test.csv')\n    \n    for i in predictions[0]:\n        labels.append(model.data.classes[np.argmax(i)])\n    \n    submission_final = pd.concat([final_data,pd.DataFrame(labels,columns = ['variety'])],\n                     axis = 1)\n    submission_final.to_csv(fileName,index = False, header=True)\n    return submission_final\n\n    \n    ","00c0c435":"preds1 = classifierModel1.get_preds(DatasetType.Test)","1cda5f23":"build_submission_file(classifierModel1,preds1,'submission1.csv')","6e668b23":"train_data_lm2 = (TextList.from_df(df=train_data,path='.',cols='all_text_combined0').split_by_rand_pct(0.1).label_for_lm().databunch(bs=48))","3556fa92":"train_data_lm2.save('train_data_lm2.pkl')","4f0ecb29":"train_data_lm2.vocab.itos[:10]","e8372752":"train_data_lm2.train_ds[0][0]","9584b12d":"train_data_lm2 = load_data('', 'train_data_lm2.pkl', bs=48)","9dd2a115":"train_data_lm2.show_batch(5)","6339d9f6":"languageModel2 = language_model_learner(train_data_lm2, arch=AWD_LSTM, pretrained_fnames=fnames, drop_mult=0.3)","ec2d9458":"languageModel2.lr_find()","9a758e8b":"languageModel2.recorder.plot(skip_end=10)","5d3259ef":"languageModel2.fit_one_cycle(5, 1e-2)","d80f8f0a":"#languageModel2.save('fine_tuned2')\nlanguageModel2.save_encoder('fine_tuned_enc2')","86ed82ca":"data_classifier2 = (TextList.from_df(df=train_data,path='.',cols='all_text_combined0', vocab=train_data_lm2.vocab)\n                    .split_by_rand_pct(0.1)\n                    .label_from_df('variety')\n                    .add_test(test_data)\n                    .databunch(bs=48))","ea0313d0":"data_classifier2.save('data_classifier2.pkl')","0bf984dd":"data_classifier2 = load_data('','data_classifier2.pkl',bs=48)","2cc17dd2":"data_classifier2.show_batch(5)","9764b498":"classifierModel2 = text_classifier_learner(data_classifier2, arch=AWD_LSTM, drop_mult=0.5)\nclassifierModel2.load_encoder('fine_tuned_enc2')\nclassifierModel2.freeze()","8f020f2f":"classifierModel2.summary()","489c502e":"classifierModel2.lr_find()","955e4ada":"classifierModel2.recorder.plot()","f117fe9f":"classifierModel2.fit_one_cycle(1, 2e-2)","99a6ebcf":"for i in range(2,5):\n    classifierModel2.freeze_to(-i)\n    classifierModel2.fit_one_cycle(1,slice((1*10**-i)\/(2.6**4),1*10**-i))\n    print ('')","ac52e853":"classifierModel2.recorder.plot_losses()","9c5eadaf":"train_loss2,train_accuracy2 = classifierModel2.validate(classifierModel2.data.train_dl)","644a0b0f":"valid_loss2,valid_accuracy2 = classifierModel2.validate(classifierModel2.data.valid_dl)","3f7ece2e":"print(\"Training Accuracy from model 2 is {0}\".format(train_accuracy2*100))\nprint('')\nprint(\"Validation Accuracy from model 2 is {0}\".format(valid_accuracy2*100))","bbae943b":"classifierModel2.show_results(rows=10)","4e3b2606":"preds2 = classifierModel2.get_preds(DatasetType.Test)","027494a9":"classifierModel2.save('classifierModel2')","d6c3480f":"build_submission_file(classifierModel2,preds2,'submission2.csv')","35f549d3":"classifierModel2.unfreeze()\nclassifierModel2.fit_one_cycle(1, slice(1e-5\/(2.6**4),1e-3))","0f5ecc94":"train_data_lm3 = (TextList.from_df(df=train_data,path='.',cols='all_text_combined1').split_by_rand_pct(0.1).label_for_lm().databunch(bs=48))","d2c056a1":"train_data_lm3.save('train_data_lm3.pkl')","5a8b5b92":"train_data_lm3.vocab.itos[:10]","b6e271d0":"train_data_lm3.train_ds[0][0]","ec665537":"train_data_lm3 = load_data('', 'train_data_lm3.pkl', bs=48)","1c785a07":"train_data_lm3.show_batch(5)","9a45313c":"languageModel3 = language_model_learner(train_data_lm3, arch=AWD_LSTM, pretrained_fnames=fnames, drop_mult=0.3)","0a68303a":"languageModel3.lr_find()","17b22afb":"languageModel3.recorder.plot(skip_end=10)","641beb97":"languageModel3.fit_one_cycle(5, 1e-2)","4647aea6":"#languageModel2.save('fine_tuned2')\nlanguageModel3.save_encoder('fine_tuned_enc3')","9b817040":"data_classifier3 = (TextList.from_df(df=train_data,path='.',cols='all_text_combined1', vocab=train_data_lm3.vocab)\n                    .split_by_rand_pct(0.1)\n                    .label_from_df('variety')\n                    .add_test(test_data)\n                    .databunch(bs=48))","4a898a4e":"data_classifier3.save('data_classifier3.pkl')","52d9ab0c":"data_classifier3 = load_data('','data_classifier3.pkl',bs=48)","1e305a6c":"data_classifier3.show_batch(5)","e4bc7af1":"classifierModel3 = text_classifier_learner(data_classifier3, arch=AWD_LSTM, drop_mult=0.5)\nclassifierModel3.load_encoder('fine_tuned_enc3')\nclassifierModel3.freeze()","c6bf451b":"classifierModel3.summary()","6bd71007":"classifierModel3.lr_find()","88ca391f":"classifierModel3.recorder.plot()","be0431cf":"classifierModel3.fit_one_cycle(1, 2e-2)","1e8eb3b5":"for i in range(2,5):\n    classifierModel3.freeze_to(-i)\n    classifierModel3.fit_one_cycle(1,slice((1*10**-i)\/(2.6**4),1*10**-i))\n    print ('')","326453aa":"classifierModel3.recorder.plot_losses()","ed7981a6":"classifierModel3.save('classifierModel3')","1a595513":"train_loss3,train_accuracy3 = classifierModel3.validate(classifierModel3.data.train_dl)","b9931042":"valid_loss3,valid_accuracy3 = classifierModel3.validate(classifierModel3.data.valid_dl)","d30f7f25":"print(\"Training Accuracy from model 3 is {0}\".format(train_accuracy3*100))\nprint('')\nprint(\"Validation Accuracy from model 3 is {0}\".format(valid_accuracy3*100))","39c5d296":"classifierModel3.show_results(rows=10)","568cf1f2":"preds3 = classifierModel3.get_preds(DatasetType.Test)","cf427c5e":"build_submission_file(classifierModel3,preds3,'submission3.csv')","42c07f70":"#classifierModel3.unfreeze()\n#classifierModel3.fit_one_cycle(1, slice(1e-5\/(2.6**4),1e-3))","7461e9e2":"train_data_lm4 = (TextList.from_df(df=train_data,path='.',cols='all_text_combined2').split_by_rand_pct(0.1).label_for_lm().databunch(bs=48))","bedd0d05":"train_data_lm4.save('train_data_lm4.pkl')","51254aef":"train_data_lm4.vocab.itos[:10]","36e682e2":"train_data_lm4.train_ds[0][0]","8b5bb172":"train_data_lm4 = load_data('', 'train_data_lm4.pkl', bs=48)","893c5670":"train_data_lm4.show_batch(5)","426ce336":"languageModel4 = language_model_learner(train_data_lm4, arch=AWD_LSTM, pretrained_fnames=fnames, drop_mult=0.3)","914a4aae":"languageModel4.lr_find()","3bc36fdc":"languageModel4.recorder.plot(skip_end=10)","0e16b1b1":"languageModel4.fit_one_cycle(5, 1e-2)","39cf3573":"#languageModel2.save('fine_tuned2')\nlanguageModel4.save_encoder('fine_tuned_enc4')","77ce0193":"data_classifier4 = (TextList.from_df(df=train_data,path='.',cols='all_text_combined2', vocab=train_data_lm4.vocab)\n                    .split_by_rand_pct(0.1)\n                    .label_from_df('variety')\n                    .add_test(test_data)\n                    .databunch(bs=48))","f08f1bc8":"data_classifier4.save('data_classifier4.pkl')","b0e750f3":"data_classifier4 = load_data('','data_classifier4.pkl',bs=48)","c2dc2e50":"data_classifier4.show_batch(5)","580875f6":"classifierModel4 = text_classifier_learner(data_classifier4, arch=AWD_LSTM, drop_mult=0.5)\nclassifierModel4.load_encoder('fine_tuned_enc4')\nclassifierModel4.freeze()","4d2762c7":"classifierModel4.summary()","4657828b":"classifierModel4.lr_find()","74ea9c3b":"classifierModel4.recorder.plot()","5135651f":"classifierModel4.fit_one_cycle(1, 2e-2)","a7e60e9a":"for i in range(2,5):\n    classifierModel4.freeze_to(-i)\n    classifierModel4.fit_one_cycle(1,slice((1*10**-i)\/(2.6**4),1*10**-i))\n    print ('')","fc292a41":"classifierModel4.recorder.plot_losses()","4dfad031":"classifierModel4.save('classifierModel4')","61b0b1a7":"train_loss4,train_accuracy4 = classifierModel4.validate(classifierModel4.data.train_dl)","965b2b0c":"valid_loss4,valid_accuracy4 = classifierModel4.validate(classifierModel4.data.valid_dl)","21da2a44":"print(\"Training Accuracy from model 4 is {0}\".format(train_accuracy4*100))\nprint('')\nprint(\"Validation Accuracy from model 4 is {0}\".format(valid_accuracy4*100))","7540bed5":"classifierModel4.show_results(rows=10)","4c3569d6":"preds4 = classifierModel4.get_preds(DatasetType.Test)","3a396abb":"build_submission_file(classifierModel4,preds4,'submission4.csv')","10105a97":"#classifierModel4.unfreeze()\n#classifierModel4.fit_one_cycle(1, slice(1e-5\/(2.6**4),1e-3))","a512d925":"train_data_lm5 = (TextList.from_df(df=train_data,path='.',cols='all_text_combined3').split_by_rand_pct(0.1).label_for_lm().databunch(bs=48))","bdbe1d8f":"train_data_lm5.save('train_data_lm5.pkl')","96b10b1d":"train_data_lm5.vocab.itos[:10]","8fe899de":"train_data_lm5.train_ds[0][0]","971c411d":"train_data_lm5 = load_data('', 'train_data_lm5.pkl', bs=48)","0bec8ae7":"train_data_lm5.show_batch(5)","71b247fb":"languageModel5 = language_model_learner(train_data_lm5, arch=AWD_LSTM, pretrained_fnames=fnames, drop_mult=0.3)","ef9221dc":"languageModel5.lr_find()","b99ade9f":"languageModel5.recorder.plot(skip_end=10)","30a597e0":"languageModel5.fit_one_cycle(5, 1e-2)","ac938ffa":"#languageModel2.save('fine_tuned2')\nlanguageModel5.save_encoder('fine_tuned_enc5')","240a0968":"data_classifier5 = (TextList.from_df(df=train_data,path='.',cols='all_text_combined3', vocab=train_data_lm5.vocab)\n                    .split_by_rand_pct(0.1)\n                    .label_from_df('variety')\n                    .add_test(test_data)\n                    .databunch(bs=48))","55d72d52":"data_classifier5.save('data_classifier5.pkl')","4f3650ed":"data_classifier5 = load_data('','data_classifier5.pkl',bs=48)","1bc92305":"data_classifier5.show_batch(5)","9bfc538c":"classifierModel5 = text_classifier_learner(data_classifier5, arch=AWD_LSTM, drop_mult=0.5)\nclassifierModel5.load_encoder('fine_tuned_enc5')\nclassifierModel5.freeze()","e44a1a6f":"classifierModel5.summary()","b4a540da":"classifierModel5.lr_find()","edb6c0c5":"classifierModel5.recorder.plot()","5f049d64":"classifierModel5.fit_one_cycle(1, 2e-2)","3696d173":"for i in range(2,5):\n    classifierModel5.freeze_to(-i)\n    classifierModel5.fit_one_cycle(1,slice((1*10**-i)\/(2.6**4),1*10**-i))\n    print ('')","403e0992":"classifierModel5.recorder.plot_losses()","ec2a6fcc":"classifierModel5.save('classifierModel5')","dd4baae0":"train_loss5,train_accuracy5 = classifierModel5.validate(classifierModel5.data.train_dl)","8614f57d":"valid_loss5,valid_accuracy5 = classifierModel5.validate(classifierModel5.data.valid_dl)","08e65d01":"print(\"Training Accuracy from model 5 is {0}\".format(train_accuracy5*100))\nprint('')\nprint(\"Validation Accuracy from model 5 is {0}\".format(valid_accuracy5*100))","5e1d64a2":"classifierModel5.show_results(rows=10)","caea7631":"preds5 = classifierModel5.get_preds(DatasetType.Test)","eb11706b":"build_submission_file(classifierModel5,preds5,'submission5.csv')","31cbf751":"classifierModel5.unfreeze() #more epochs to check if accuracy improves\nclassifierModel5.fit_one_cycle(1, slice(1e-5\/(2.6**4),1e-3))","0ca3acf3":"classifierModel5.unfreeze() #more epochs to check if accuracy improves\nclassifierModel5.fit_one_cycle(1, slice(1e-5\/(2.6**4),1e-3))","1ed1da77":"train_data_lm6 = (TextList.from_df(df=train_data,path='.',cols='all_text_combined4').split_by_rand_pct(0.1).label_for_lm().databunch(bs=48))","b9e4b153":"os.remove(\"\/kaggle\/working\/train_data_lm1.pkl\")  #storage space issue on kaggle\nos.remove(\"\/kaggle\/working\/train_data_lm2.pkl\")\nos.remove(\"\/kaggle\/working\/train_data_lm3.pkl\")\nos.remove(\"\/kaggle\/working\/train_data_lm4.pkl\")\ntrain_data_lm6.save('train_data_lm6.pkl')","a61b91d1":"train_data_lm6.vocab.itos[:10]","531e11b5":"train_data_lm6.train_ds[0][0]","3e680d4e":"train_data_lm6 = load_data('', 'train_data_lm6.pkl', bs=48)","b2a758c0":"train_data_lm6.show_batch(5)","1fe14354":"languageModel6 = language_model_learner(train_data_lm6, arch=AWD_LSTM, pretrained_fnames=fnames, drop_mult=0.3)","7cdc3270":"languageModel6.lr_find()","d1adcabe":"languageModel6.recorder.plot(skip_end=10)","b88563ac":"languageModel6.fit_one_cycle(5, 1e-2)","32f16c39":"#languageModel2.save('fine_tuned2')\nlanguageModel6.save_encoder('fine_tuned_enc6')","6a2d7b8d":"data_classifier6 = (TextList.from_df(df=train_data,path='.',cols='all_text_combined4', vocab=train_data_lm6.vocab)\n                    .split_by_rand_pct(0.1)\n                    .label_from_df('variety')\n                    .add_test(test_data)\n                    .databunch(bs=48))","0a144e6c":"data_classifier6.save('data_classifier6.pkl')","1707a878":"data_classifier6 = load_data('','data_classifier6.pkl',bs=48)","0fc3522e":"data_classifier6.show_batch(5)","2d3a43e7":"classifierModel6 = text_classifier_learner(data_classifier6, arch=AWD_LSTM, drop_mult=0.5,metrics = [accuracy])\nclassifierModel6.load_encoder('fine_tuned_enc6')\nclassifierModel6.freeze()","9e2736c7":"classifierModel6.summary()","1510b8dc":"classifierModel6.lr_find()","35cdff43":"classifierModel6.recorder.plot()","45cf7a0c":"classifierModel6.fit_one_cycle(1, 2e-2)","931200fa":"for i in range(2,5):\n    classifierModel6.freeze_to(-i)\n    classifierModel6.fit_one_cycle(1,slice((1*10**-i)\/(2.6**4),1*10**-i))\n    print ('')","263aed0c":"classifierModel6.recorder.plot_losses()","38e3f21e":"classifierModel6.save('classifierModel6')","d5c0db41":"train_loss6,train_accuracy6 = classifierModel6.validate(classifierModel6.data.train_dl)","6d4a494e":"valid_loss6,valid_accuracy6 = classifierModel6.validate(classifierModel6.data.valid_dl)","46002ffa":"print(\"Training Accuracy from model 6 is {0}\".format(train_accuracy6*100))\nprint('')\nprint(\"Validation Accuracy from model 6 is {0}\".format(valid_accuracy6*100))","f2863fac":"classifierModel6.show_results(rows=10)","975c0add":"preds6 = classifierModel6.get_preds(DatasetType.Test)","a0694159":"build_submission_file(classifierModel6,preds6,'submission6.csv')","d28c43cb":"#classifierModel6.unfreeze()\n#classifierModel6.fit_one_cycle(1, slice(1e-5\/(2.6**4),1e-3))","4775b707":"models =['ClassifierModel1',\n         'ClassifierModel2',\n         'ClassifierModel3',\n         'ClassifierModel4',\n         'ClassifierModel5',\n         'ClassifierModel6']\ncols = ['Training Accuracy',\n        'Training Loss',\n        'Validation Accuracy',\n        'Validation Loss']\n                                       \nfinal_results = pd.DataFrame(columns = cols,index=models)","938b11b6":"final_results[cols[0]][models[0]] = train_accuracy1*100\nfinal_results[cols[1]][models[0]] = train_loss1\nfinal_results[cols[2]][models[0]] = valid_accuracy1*100\nfinal_results[cols[3]][models[0]] = valid_loss1\n\nfinal_results[cols[0]][models[1]] = train_accuracy2*100\nfinal_results[cols[1]][models[1]] = train_loss2\nfinal_results[cols[2]][models[1]] = valid_accuracy2*100\nfinal_results[cols[3]][models[1]] = valid_loss2\n\nfinal_results[cols[0]][models[2]] = train_accuracy3*100\nfinal_results[cols[1]][models[2]] = train_loss3\nfinal_results[cols[2]][models[2]] = valid_accuracy3*100\nfinal_results[cols[3]][models[2]] = valid_loss3\n\nfinal_results[cols[0]][models[3]] = train_accuracy4*100\nfinal_results[cols[1]][models[3]] = train_loss4\nfinal_results[cols[2]][models[3]] = valid_accuracy4*100\nfinal_results[cols[3]][models[3]] = valid_loss4\n\nfinal_results[cols[0]][models[4]] = train_accuracy5*100\nfinal_results[cols[1]][models[4]] = train_loss5\nfinal_results[cols[2]][models[4]] = valid_accuracy5*100\nfinal_results[cols[3]][models[4]] = valid_loss5\n\n\nfinal_results[cols[0]][models[5]] = train_accuracy6*100\nfinal_results[cols[1]][models[5]] = train_loss6\nfinal_results[cols[2]][models[5]] = valid_accuracy6*100\nfinal_results[cols[3]][models[5]] = valid_loss6\n","2ff207ec":"print(\"Final results\")\nprint('')\nprint(final_results)","5ff94ac0":"f,ax = plt.subplots(figsize = (20,20))\nsns.pointplot(final_results.index,final_results['Validation Accuracy'])\nplt.xticks(fontsize =15)\nplt.yticks(fontsize =15)\nplt.xlabel(\"Wines\",fontsize =20)\nplt.ylabel(\"Models\",fontsize =20,rotation = 0)\nplt.title('Validation Accuracy', fontsize=25)\nplt.grid(True)\nplt.show()","c6856e62":"#  ![](https:\/\/img.winespectator.com\/wso\/bolt\/2019-06\/1561485468_ww_glassware062519_1600.jpg?imgeng=\/w_1600)","76a3bf1c":"\n# Language Model 6","d95a0fcd":"<font size =6 face ='Times New Roman' color = #800080>US mostly has the maximum number of wineries producing cheap wines<\/font>","63ea6f2f":"<font size =6 face ='Times New Roman' color = #800080>India features in top 5 wine producing countries, whose wines are lauded by sommeliers<\/font>","966b4cb5":"\n# Language Model 5","78f99ffd":"# Classifier Model 4","497b4a39":"<font size =8 face ='Times New Roman'>Wines on the basis of their redness and whiteness<\/font>","a21b7d3d":"<font size =8 face ='Times New Roman'> What words describe the top 3 highly rated wines?<\/font>","d32431f4":"<font size =6 face ='Times New Roman' color = #800080>Champagne blend and Nebbiolo are the costliest wines<\/font>","271150cd":"<font size =8 face ='Times New Roman'>Which Countries Produce the wines rated highly by sommeliers?<\/font>","0ac679ad":"<font size =8 face ='Times New Roman'>Which are the Costliest Wines?<\/font>","09756ced":"# ![](https:\/\/ruder.io\/content\/images\/size\/w2000\/2018\/07\/lm_objective.png)\n<br>\n\n<font face ='Times New Roman' font size= 6, color ='blue'>\n\n    <h1>Transfer Learning<\/h1>\n   \n<\/font>\n\n\n<div style=\"text-align: justify\"> <font size= 5 face ='Times New Roman' color ='black'>Humans can learn tasks and use the skills gained, thus, for some other jobs. The more similar the given assignment is to the prior one, the more comfortable one is in its execution. Conventional ML and deep learning algorithms, until a few years back, could only work in isolation. Every time a new dataset presented itself, the model had to be developed from scratch. Transfer learning is the learning paradigm to overcome the isolation, as mentioned earlier, and utilize the knowledge previously acquired for one task to solve similar ones. Granted Transfer Learning is a fantastic idea to improve deep learning models, but it has its limited uses. It has been working great in the area of Image classification, but when it came to the domain of Natural Language Processing, it couldn't help much.  2018 though, was the exciting moment in the field NLP. As Sebastian Ruder puts it, \"NLP's ImageNet moment has arrived,\" and it sure has.Methods such as ULMFiT, OpenAI GPT, ELMo, and Google AI's BERT have a significant impact on transfer learning in NLP by using language modeling during pre-training. The interesting aspect of the transfer learning methods mentioned above is that they use language models pre-trained on well-formed, massive curated datasets that include full sentences with a clear syntax (such as Wikipedia articles and the 1 billion word benchmark). The given kernel implements the ULMFiT model.<\/font><\/div><br>\n  \n<font face ='Times New Roman' size=4>\n***References***\n<br>  \n  \nhttps:\/\/medium.com\/jash-data-sciences\/guide-to-text-classification-with-fastai-b161ed07d36d#c04d  <br><br>\n\nhttps:\/\/towardsdatascience.com\/transfer-learning-in-nlp-for-tweet-stance-classification-8ab014da8dde  <br><br>\n\nhttps:\/\/ruder.io\/nlp-imagenet\/  <br><br>\n\nhttps:\/\/www.kaggle.com\/heisenbad\/sentiment-analysis-with-transfer-learning  <br><br>\n\nhttps:\/\/towardsdatascience.com\/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6  <br><br>\n\nhttps:\/\/towardsdatascience.com\/multi-task-learning-in-language-model-for-text-classification-c3acc1fedd89  <br><br>\n\nhttps:\/\/diveki.github.io\/projects\/wine\/sommelier.html  <br><br>\n\nhttps:\/\/arxiv.org\/pdf\/1801.06146.pdf  <br><br>\n\nhttps:\/\/sgugger.github.io\/the-1cycle-policy.html<\/font>\n\n<br><br>\n<font face ='Times New Roman' size=4> The following flowchart depicts the methodology adopted in this kernel <\/font><br>\n\n# ![](https:\/\/miro.medium.com\/max\/1400\/1*vYrqXT0Z80BdZLVIcNt_Wg.png)","a4e60f4f":"# Classifier Model 1","b6853bad":"\n# Language Model 2","03c9ab34":"<font size =6 face ='Times New Roman' color = #800080>Nebbiolo scores the highest in wine redness score followed by Sangiovese and Red Blend<\/font>","9a3b176d":"<font size =8 face ='Times New Roman'>Which Winery in which Country is the most costliest?<\/font>","9984ec80":"#  Exploratory Data Analysis","a4fd5566":"<font size =8 face ='Times New Roman'>Which winery in which Country is the most economic?<\/font>","8f43e8db":"# Classifier Model 5","0b5ea905":"\n# Language Model 4","ec0e84cf":"# Language Model 1","4efcfc88":"# Classifier Model 2","8f8903f8":"<font size =6 face ='Times New Roman' color = #800080>Model 5 gives the best validation accuracy<\/font>","a76e9726":"<font size =8 face ='Times New Roman'>Which are the highest rated wines?<\/font>","1131807a":"<font size =8 face ='Times New Roman'>Which countries produce Value for Money wines<\/font>","7f4b29a9":"<font size =5 face ='Times New Roman' color = #800080><li> None of the traditional wine producing countries features in top in this list<\/li>\n<li>India once again feature in top 5<\/li><\/font>","fbd70614":"<font size =5 face ='Times New Roman' color = #800080><li>Nebbiolo seems to be associated  more with the word pepper and spice. I wonder what would it taste like<\/li><br>\n<li>Gr\u00fcner Veltliner and Champagne Blend are associated with acidity and citrus. It's may be because their taste is similar to lemons<\/li><\/font>","d21eabdf":"<font size =5 face ='Times New Roman' color = #800080><li>Europe leads the charge in producing the costliest wines.<\/li> <br>\n<li>Switzerland is no surprise as it is one of the countries where standard of living is pretty high. This can be attested from the fact that the top 2 countries(Swiss and English) have a huge difference between them<\/li><\/font>","0a39b6fe":"\n# Language Model 3","1853ad7a":"<font size =8 face ='Times New Roman'>Which Countries Produce the Costliest wines?<\/font>","3f91f83c":"<font size =6 face ='Times New Roman' color = #800080>France and US, the traditional wine producing countries, as expected make in to this list<\/font>","0e8e0f46":"# Classifier Model 3","0f362c2a":"<font size =6 face ='Times New Roman' color = #800080>Riesling scores the highest in whiteness score followed by Pinot Grigio and White Blend<\/font>","dc616ce6":"# Classifier Model 6"}}