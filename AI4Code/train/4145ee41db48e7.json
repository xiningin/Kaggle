{"cell_type":{"c49bd4a5":"code","a48b9df8":"code","d89e1400":"code","4768cd8f":"code","e9f79251":"code","e78d49a3":"code","448b7323":"code","2bcedbbf":"code","4d5ca6e6":"code","821f8a51":"code","d91f6f81":"code","8af1e4c0":"code","5a41d9ee":"code","cdd2dcea":"code","56bb78c5":"code","4b31f3df":"code","26a232b1":"code","c6199ba5":"code","70f5391f":"markdown","8651b6cc":"markdown","8c126b40":"markdown","f432ae71":"markdown","d80b0173":"markdown","bca0cb44":"markdown","739cf5b0":"markdown","753fe2ec":"markdown","fb933b66":"markdown","afd12689":"markdown"},"source":{"c49bd4a5":"import pandas as pd\n\ndf = pd.read_csv(\"\/kaggle\/input\/lord-of-the-rings-character-data\/Characters.csv\")\ndf = df.drop(columns=\"Url\")\n# Some examples from the data\ndf.head()","a48b9df8":"# Sum the number of names per race\ndf_summary = df.groupby(by=\"Race\").count()\ndf_summary","d89e1400":"# Visualization\nax = df_summary.unstack()[\"Name\"].plot(kind=\"bar\", color=['r', 'g', 'b', 'm', 'c'], legend=False)\nax.set_ylabel(\"Number of Names\");","4768cd8f":"# Collect all unique characters in the data\nletters = list({letter for name in df[\"Name\"] for letter in name})\nletters","e9f79251":"# We need a special case for the start of the string (SOS) and the end of the string (EOS)\nn_letters = len(letters) + 2 \nprint(\"Number of letters: %d\" % n_letters)","e78d49a3":"categories = df[\"Race\"].unique()\nn_category = len(categories)\nprint(\"Categories: %s \\nNumber of categories: %d\" % (categories, n_category))","448b7323":"import numpy as np\n\n# Get all names in a category\ndef names(category):\n    return df[df[\"Race\"] == category][\"Name\"].values\n\n# Get a random category\ndef randomValue(cont):\n    return cont[np.random.randint(0, len(cont) - 1)]\n\n# Get a random category and a random name from that category\ndef randomTrainingPair(categories):\n    category = randomValue(categories)\n    name = randomValue(names(category))\n    return category, name","2bcedbbf":"# Test the functions\ndwarf = names(\"Dwarf\")[:5]\ncategory = randomValue(categories)\ncat, name = randomTrainingPair(categories)\nprint(\"Some dwarf names: %s \\nA random category: %s \\nRandom category and name: %s, %s\" % (dwarf, category, cat, name))","4d5ca6e6":"import torch\n\n# One-hot vector for category\ndef categoryTensor(category):\n    ind = np.where(categories == category)\n    tensor = torch.zeros(1, n_category)\n    tensor[0][ind] = 1\n    return tensor\n\n# One-hot matrix of SOS and first to last letters (not including EOS) for input\ndef inputTensor(name, add_start=True):\n    length = len(name) + 1 if add_start else len(name)\n    tensor = torch.zeros(length, 1, n_letters)\n    if add_start:\n        tensor[0][0][n_letters - 2] = 1 # SOS\n    for i in range(len(name)):\n        letter = name[i]\n        if add_start:\n            i = i + 1 # Shift, because of the SOS token\n        tensor[i][0][letters.index(letter)] = 1\n    return tensor\n\n# LongTensor of first letter to end (EOS) for target\ndef targetTensor(name):\n    letter_indexes = [letters.index(name[i]) for i in range(len(name))]\n    letter_indexes.append(n_letters - 1) # EOS\n    return torch.LongTensor(letter_indexes)\n\ndef randomTrainingExample(categories):\n    category, name = randomTrainingPair(categories)\n    category_tensor = categoryTensor(category)\n    input_line_tensor = inputTensor(name, add_start=True)\n    target_line_tensor = targetTensor(name)\n    return category_tensor, input_line_tensor, target_line_tensor","821f8a51":"# Test the functions\ncat, name = randomTrainingPair(categories)\nc_tensor = categoryTensor(cat)\ni_tensor = inputTensor(name)\nt_tensor = targetTensor(name)\nc, i, t = randomTrainingExample(categories)\nprint(\"Random category and name: %s, %s \\nCategory Tensor: %s \\nInput Tensor: %s \\nTarget Tensor: %s\\\n\\n\\nCategory Tensor: %s \\nInput Tensor: %s \\nTarget Tensor: %s\" % (cat,name,c_tensor,i_tensor,t_tensor,c,i,t))\n# Notice how all input tensors start the same and all target tensors end the same ","d91f6f81":"import torch.nn as nn\n\n# A simple network using GRU(gated recurrent unit)\nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(RNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.fc = nn.Linear(n_category + input_size, hidden_size)\n        self.relu = nn.ReLU()\n        self.gru = nn.GRU(hidden_size, hidden_size, num_layers=1)\n        self.fc2 = nn.Linear(hidden_size, output_size)\n\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, category, inp, hidden):\n        input_combined = torch.cat((category, inp), 1) # Concatenate the category and input\n        inp = self.relu(self.fc(input_combined)).view(1,1,-1)\n        output, hidden = self.gru(inp, hidden)\n        output = self.fc2(output.view(1,-1))\n        output = self.softmax(output).view(1,-1)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size)","8af1e4c0":"import torch.optim as optim\n\n# Define network, loss function, and optimization\nrnn = RNN(n_letters, 128, n_letters)\n\nlearning_rate = 0.0005\ncriterion = nn.NLLLoss()\noptim = optim.Adam(rnn.parameters(), lr=learning_rate)","5a41d9ee":"import time\nimport math\n\n# Helper functions for training\n\ndef train(category_tensor, input_tensor, target_tensor):\n    target_tensor.unsqueeze_(-1)\n    hidden = rnn.initHidden()\n\n    optim.zero_grad()\n    loss = 0\n\n    for i in range(input_tensor.size(0)):\n        inp = input_tensor[i]\n        output, hidden = rnn(category_tensor, inp, hidden)\n        l = criterion(output, target_tensor[i])\n        loss += l\n\n    loss.backward()\n    \n    optim.step()\n\n    return output, loss.item() \/ input_tensor.size(0)\n\ndef timeSince(since):\n    now = time.time()\n    s = now - since\n    m = math.floor(s \/ 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n# Sample from a category and optional: start of name\ndef sample(category, start=\"\", max_length=20):\n    with torch.no_grad():  # no need to track history in sampling\n        category_tensor = categoryTensor(category)\n\n        inp = inputTensor(start)\n        hidden = rnn.initHidden()\n\n        output_name = start\n\n        if start != \"\": # Build up hidden\n            for i in range(len(inp) - 1): # Process every letter except for the last one\n                _, hidden = rnn(category_tensor, inp[i], hidden)\n            inp = inp[-1].view(1,1,-1)     \n        for i in range(max_length - len(start)):\n            output, hidden = rnn(category_tensor, inp[0], hidden)\n            # Get the most likely next letter\n            topv, topi = output.topk(1)\n            topi = topi[0][0]\n            if topi == n_letters - 1: # EOS\n                break\n            else:\n                letter = letters[topi]\n                output_name += letter\n            inp = inputTensor(letter, add_start=False) # We don't need SOS\n\n        return output_name\n    \ndef evaluation(epoch, start=\"\", max_length=20):\n    f = open(\"train.txt\", \"a\")\n    f.write(\"Epoch: %s \\n\" % epoch)\n    for category in categories:\n        name = sample(category, start=start, max_length=max_length)        \n        print(\"%s: %s\" % (category, name))        \n        f.write(\"%s: %s \\n\" % (category, name))\n    f.write(\"\\n\")\n    f.close()","cdd2dcea":"# Training\nepoch = 100000\nprint_every = 5000\nplot_every = 500\nall_losses = []\ntotal_loss = 0 # Reset every plot_every iters\n\nstart = time.time()\n\nsave_model = \"net.pth\"\n\nfor it in range(1, epoch + 1):\n    output, loss = train(*randomTrainingExample(categories))\n    total_loss += loss\n\n    if it % print_every == 0:\n        print('%s (%d %d%%) %.4f' % (timeSince(start), it, it \/ epoch * 100, loss))\n        torch.save(rnn.state_dict(), save_model)\n        evaluation(it)\n\n    if it % plot_every == 0:\n        all_losses.append(total_loss \/ plot_every)\n        total_loss = 0","56bb78c5":"import matplotlib.pyplot as plt\n\n# Plot loss\nplt.plot(all_losses)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.show()","4b31f3df":"# Save the network\ntorch.save(rnn.state_dict(), save_model)","26a232b1":"# Now we can generate as many names as we want\n\nprint(sample(\"Dwarf\", start=\"Dhu\"))\nprint(sample(\"Human\", start=\"Rod\"))\nprint(sample(\"Elf\", start=\"El\"))","c6199ba5":"# We can see how different the names are even when they start the same\nfor category in categories:\n    print(\"%s: %s\" % (category, sample(category, start=\"Hal\")))\nprint()\nfor category in categories:\n    print(\"%s: %s\" % (category, sample(category, start=\"Es\")))","70f5391f":"# Name Generating","8651b6cc":"# Build The Network","8c126b40":"### The network will generate names based on the category that we want.","f432ae71":"## If you're interested in RNNs, then take a look at the following pytorch tutorial, I created this notebook after completing it: [https:\/\/pytorch.org\/tutorials\/intermediate\/char_rnn_generation_tutorial.html#Creating-the-Network](http:\/\/)\n##  \n","d80b0173":"### Our network will take in a single letter and predict what the next letter should be.\n\n### We will represent the letters with one-hot vectors, for which we need to know how many types of characters we can use.","bca0cb44":"# Data Analysis and Preprocessing","739cf5b0":"### We will use pytorch to build our network, so we need to convert our inputs to tensors.","753fe2ec":"## We will create a recurrent neural network to generate new names based on the lord of the rings.","fb933b66":"## Here we define some helper functions that will be useful later","afd12689":"# Training"}}