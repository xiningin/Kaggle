{"cell_type":{"e4865169":"code","99221a78":"code","d7b6c806":"code","07b1509f":"code","d6d26e83":"code","9cbdee62":"code","fdf1e3d6":"code","fa5cdbc0":"code","1c018275":"code","1a00c712":"code","bef2d8ca":"code","e94c9ed3":"code","cf10d0a6":"code","0a3d8691":"code","4c01d570":"code","8b76e25e":"code","78c573a6":"code","ec98073a":"code","28c4e185":"code","cb79c49e":"code","08171db0":"code","813ca722":"code","32c24c6d":"code","3f9ccebb":"code","db097fff":"code","28e472e3":"code","ced8a6b5":"code","1bd894f9":"markdown","1e4681d4":"markdown","f1c76993":"markdown"},"source":{"e4865169":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","99221a78":"L0_station = (1, 25)","d7b6c806":"import zipfile\n\npath = '..\/input\/bosch-stations-one-hot-enc-train-test\/stations_one_hot_train.csv'\none_hot_stations = pd.read_csv(path)\n\nL0_one_hot = one_hot_stations.iloc[:,L0_station[0]:L0_station[1]]\n\npd.options.display.max_columns = None\npd.options.display.max_rows = None\npd.options.display.max_colwidth = None","07b1509f":"# Drop rows with all 0 for each station\nL0_one_hot = L0_one_hot.loc[~(L0_one_hot==0).all(axis=1)]\n\nprint(\"Parts in L0:{}\".format(len(L0_one_hot)))","d6d26e83":"L0_one_hot.insert(0, \"Id\",one_hot_stations[\"Id\"])","9cbdee62":"L0_one_hot.head()","fdf1e3d6":"from sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom matplotlib import pyplot as plt\nfrom sklearn.cluster import DBSCAN","fa5cdbc0":"column_names = L0_one_hot.columns[1:]","1c018275":"L0_one_hot = L0_one_hot.sample(len(L0_one_hot))","1a00c712":"dbscan = DBSCAN()\nnumber_of_splits = 10","bef2d8ca":"from random import randint\ncluster_number_list = []\n\nfor i in range(5):\n    split_number = randint(1, number_of_splits)\n    preds_split = dbscan.fit_predict(L0_one_hot[int((split_number-1)*len(L0_one_hot)\/number_of_splits):int(split_number*len(L0_one_hot)\/number_of_splits)][column_names])\n    cluster_number_list.append(len(np.unique(preds_split)))","e94c9ed3":"max_cluster_for_l0 = int(np.max(cluster_number_list))\nprint(\"MAX NUMBER OF CLUSTERS: {}\\n\".format(max_cluster_for_l0))\nprint(cluster_number_list)","cf10d0a6":"L0_one_hot.sort_values(by=['Id'], inplace=True)","0a3d8691":"n_clusters = max_cluster_for_l0\nkmeans = KMeans(n_clusters=n_clusters)\npred = kmeans.fit_predict(L0_one_hot[column_names])\n\npred += 1\nprint(kmeans.inertia_)","4c01d570":"L0_one_hot.insert(1, \"ClusterL0\", pred)\nL0_one_hot.sample(10)","8b76e25e":"ids_clusters = pd.DataFrame({\"Id\": one_hot_stations['Id'], \"ClusterL0\": 0})\nids_clusters.loc[L0_one_hot.index, ['ClusterL0']] = L0_one_hot['ClusterL0']\nids_clusters.to_csv(\"Cluster_L0_train.csv\", index=False)","78c573a6":"from random import randint","ec98073a":"L0_one_hot[L0_one_hot[\"ClusterL0\"] == randint(1, n_clusters)].head()","28c4e185":"L0_one_hot[L0_one_hot[\"ClusterL0\"] == randint(1, n_clusters)].head()","cb79c49e":"L0_one_hot[L0_one_hot[\"ClusterL0\"] == randint(1, n_clusters)].head()","08171db0":"L0_one_hot[L0_one_hot[\"ClusterL0\"] == randint(1, n_clusters)].head()","813ca722":"path_test = '..\/input\/bosch-stations-one-hot-enc-train-test\/stations_one_hot_test.csv'\none_hot_stations_test = pd.read_csv(path_test)\n\nL0_one_hot_test = one_hot_stations_test.iloc[:,L0_station[0]:L0_station[1]]\n\n# Drop rows with all 0 for each station\nL0_one_hot_test = L0_one_hot_test.loc[~(L0_one_hot_test==0).all(axis=1)]\n\nprint(\"Parts in L0_test:{}\".format(len(L0_one_hot_test)))\n\nL0_one_hot_test.insert(0, \"Id\",one_hot_stations_test[\"Id\"])","32c24c6d":"pred_test = kmeans.predict(L0_one_hot_test[column_names])\npred_test += 1\n\nL0_one_hot_test.insert(1, \"ClusterL0\", pred_test)\n\nids_clusters_test = pd.DataFrame({\"Id\": one_hot_stations_test['Id'], \"ClusterL0\": 0})\nids_clusters_test.loc[L0_one_hot_test.index, ['ClusterL0']] = L0_one_hot_test['ClusterL0']\nids_clusters_test.to_csv(\"Cluster_L0_test.csv\", index=False)","3f9ccebb":"L0_one_hot_test[L0_one_hot_test[\"ClusterL0\"] == 1].head(10)","db097fff":"L0_one_hot[L0_one_hot[\"ClusterL0\"] == 1].head(10)","28e472e3":"L0_one_hot_test[L0_one_hot_test[\"ClusterL0\"] == n_clusters].head(10)","ced8a6b5":"L0_one_hot[L0_one_hot[\"ClusterL0\"] == n_clusters].head(10)","1bd894f9":"# KMEANS ON TEST DATA","1e4681d4":"# DBSCAN for L0","f1c76993":"# KMEANS for L0"}}