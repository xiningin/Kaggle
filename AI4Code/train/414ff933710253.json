{"cell_type":{"278ad8a9":"code","e3e55b5d":"code","44e19000":"code","4d394bc1":"code","5e223eea":"code","f61f5283":"code","de5382a8":"code","dd6c5457":"code","c53fa863":"code","8a81b38c":"code","17be36b3":"code","cb73d7e6":"code","54a0db11":"code","8afeb120":"code","d9952bd2":"markdown","719f730a":"markdown"},"source":{"278ad8a9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e3e55b5d":"#import a bunch of libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, roc_auc_score\nfrom sklearn.metrics import confusion_matrix ,classification_report,precision_score, recall_score ,f1_score \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression  \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC \nfrom sklearn.model_selection import GridSearchCV \nfrom sklearn.model_selection import RandomizedSearchCV ","44e19000":"data = pd.read_csv('\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')\n","4d394bc1":"data.head()","5e223eea":"data.info()","f61f5283":"data.describe()","de5382a8":"# numeric and categorical value separately\ndata_num = data[[\"age\",\"trtbps\",\"chol\",\"thalachh\",\"oldpeak\"]]\ndata_cat =data[['sex','exng','caa','cp','fbs','restecg','slp','thall']]\ncat_cols = ['sex','exng','caa','cp','fbs','restecg','slp','thall']\ncon_cols = [\"age\",\"trtbps\",\"chol\",\"thalachh\",\"oldpeak\"]","dd6c5457":"for i in data_num.columns:\n    plt.figure(figsize=[19.2, 10.8])\n    plt.title(i)\n    plt.axvline(data_num[i].mean(),color='red',linestyle='dashed', linewidth=3,label='Mean')\n    plt.axvline(data_num[i].median(),color='green',linestyle='dashed', linewidth=3,label='Median')\n    plt.hist(data_num[i],bins=20, alpha=0.7, edgecolor='k')\n    plt.legend(shadow=True, fontsize='x-large')\n    plt.show()","c53fa863":"df_corr = data[con_cols].corr().transpose()\nfig = plt.figure(figsize=(10,10))\ngs = fig.add_gridspec(1,1)\ngs.update(wspace=0.3, hspace=0.15)\nax0 = fig.add_subplot(gs[0,0])\ncolor_palette = [\"#5833ff\",\"#da8829\"]\nmask = np.triu(np.ones_like(df_corr))\nax0.text(1.5,-0.1,\"Correlation Matrix\",fontsize=22, fontweight='bold', fontfamily='serif', color=\"#000000\")\ndf_corr = data[con_cols].corr().transpose()\nsns.heatmap(df_corr,mask=mask,fmt=\".1f\",annot=True,cmap='YlGnBu')\nplt.show()","8a81b38c":"pd.pivot_table(data, index='output', values=['age','trtbps','chol','thalachh','oldpeak'],aggfunc={'age':[np.mean,np.median,np.std],'trtbps':[np.mean,np.median,np.std],'chol':[np.mean,np.median,np.std],'thalachh':[np.mean,np.median,np.std],'oldpeak':[np.mean,np.median,np.std]})\n","17be36b3":"\ncolumns=['sex','cp','fbs','restecg','exng']\npd.pivot_table(data,index='output',values=columns, aggfunc={'sex': np.mean,'cp': np.mean,'fbs': np.mean,'restecg': np.mean,'exng': np.mean})\n    \n","cb73d7e6":"for i in data_cat.columns:\n    lang = data_cat[i].unique()\n    langs = [str(i) for i in lang]\n    try:\n        print(i)\n        print()\n        fig = plt.figure()\n        ax = fig.add_axes([0,0,1,1])\n        ax.axis('equal')\n        ax.pie(data_cat[i].value_counts(),labels=langs,autopct='%1.2f%%',)\n        plt.show()\n    except:\n        pass","54a0db11":"columns=['sex','cp','fbs','restecg','exng']\nfor i in columns:\n    print(pd.pivot_table(data,index='output',columns=i, values='age',aggfunc='median'))\n    print()\n    print()","8afeb120":" features = data.iloc[:,:-1].values\nlabel = data.iloc[:,-1].values\nX_train, X_test, y_train, y_test= train_test_split(features,label, test_size= 0.25, random_state=610)\nclassimodel= LogisticRegression()  \nclassimodel.fit(X_train, y_train)\ntrainscore =  classimodel.score(X_train,y_train)\ntestscore =  classimodel.score(X_test,y_test)\n\n\n\nprint(\"test score: {} train score: {}\".format(testscore,trainscore),'\\n')\n\ny_pred =  classimodel.predict(X_test)\nprint(' f1 score: ',f1_score(y_test, y_pred),'\\n')\nprint(' precision score: ',precision_score(y_test, y_pred),'\\n')\nprint(' recall score: ',recall_score(y_test, y_pred),'\\n')\n#from sklearn.metrics import confusion_matrix\n","d9952bd2":"# Exploratory data analysis \n\n","719f730a":"<font size =7>\nDataset Value\n\n\n<font size =4>\n    \n**Age** : Age of the patient\n    \n**Sex** : Sex of the patient\n    \n**exang** : exercise induced angina (1 = yes; 0 = no)\n    \n**ca**: number of major vessels (0-3)\n    \n**cp** : Chest Pain type chest pain type\n   \n Value1 : typical angina\n    \n Value2 : atypical angina   \n    \n Value3 : non-anginal pain\n    \n Value4 : asymptomatic\n    \n    \n    \n**trtbps** : resting blood pressure (in mm Hg)\n    \n**chol** : cholestoral in mg\/dl fetched via BMI sensor\n    \n**fbs** : (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n    \n**rest_ecg** : resting electrocardiographic results\n    \n Value0 : normal\n\n Value1 : having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV)\n    \n Value2 : showing probable or definite left ventricular hypertrophy by Estes' criteria\n    \n    \n    \n**thalach** : maximum heart rate achieved\n    \n    \n**target** : 0= less chance of heart attack 1= more chance of heart attack"}}