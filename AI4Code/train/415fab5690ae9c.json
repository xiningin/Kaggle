{"cell_type":{"f4e5ebbf":"code","9c55b716":"code","03361fe1":"code","9d1abaa8":"code","bb1a312b":"code","79f7a51b":"code","65d22b05":"code","69b2dcf3":"code","40125b17":"code","567c3250":"code","fc9a931c":"code","7ae98e0e":"code","c0b4ee7c":"code","8365e0b0":"code","f4c3da52":"markdown","bb4b37f7":"markdown","a9e1c35d":"markdown","1570bd10":"markdown","78f91c79":"markdown","d1722cc9":"markdown","b6e7e49c":"markdown","71b05a09":"markdown","891e940b":"markdown","49e6be1d":"markdown","19a0e9eb":"markdown","774402cc":"markdown","b653f0d2":"markdown"},"source":{"f4e5ebbf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9c55b716":"data = pd.read_csv('\/kaggle\/input\/insurance\/insurance.csv')\n\nX = data.iloc[:, :-1]\ny = data.iloc[:, -1]","03361fe1":"data.head()","9d1abaa8":"data.tail()","bb1a312b":"data.describe()","79f7a51b":"data.isnull().values.any()","65d22b05":"import seaborn as sns\nsns.heatmap(data.corr(),annot= True)","69b2dcf3":"sns.pairplot(data)","40125b17":"import plotly.express as px\nfig = px.scatter_3d(data, x='age', y='bmi', z='charges', color= 'sex')\nfig.show()","567c3250":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1,4,5])], remainder='passthrough')\nX = np.array(ct.fit_transform(X))","fc9a931c":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","7ae98e0e":"from sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(X_train, y_train)","c0b4ee7c":"import math\ny_pred = regressor.predict(X_test)\nfrom sklearn.metrics import mean_squared_error\nmath.sqrt(mean_squared_error(y_test, y_pred))","8365e0b0":"from sklearn.metrics import r2_score\nr2_score(y_test, y_pred)\nprint(1 - (1-regressor.score(X, y))*(len(y)-1)\/(len(y)-X.shape[1]-1))","f4c3da52":"The pairplot or the scatterplot matrix visualizes the relationship between variables in a matrix","bb4b37f7":"Fit model","a9e1c35d":"Using the Root Mean Square Error, we can determine the accuracy of this model(how accurate this model can predict). According to the regression output, we can see that the root mean squared error is 5641.62. RMSE is the standard deviation of the random variation (prediction errors). Hence, we can expect this model to predict the charges within a standard deviation of 5641.62. ","1570bd10":"**Using 3D visualization to see the relationship between Age, Bmi with Charges**","78f91c79":"Encode the categorical variables","d1722cc9":"**Correlation coefficient table**","b6e7e49c":"We can see the R2 is 0.799. We have a rule of thumb that when R2 is larger than 0.7, it indicates is a good model. R2 is a number of systematic variation over total variation. This means that 79.9% of the variations are systematic. If we want to know what  the percentage of the random variation is, we can let 100-79.9 = 25.31%. Hence, 20.1% are random variations, which is a small number. However, to evaluate the Multivariable Regression, we need to know that when adding x variables, R2 always increase. Thus, R2 adjusted provides an \u201capples to apples\u201d comparison of the models., which is 0.7469. According to the Rule of Thumb, this is still a very reasonable model. ","71b05a09":"Train, test split 80\/20","891e940b":"As age increases, charges also increase. This verifies the correlation coefficient of 0.3 between age and charges. Bmi with charges show the same but weaker relationship\n\n","49e6be1d":"**Check for any N\/A data**","19a0e9eb":"**Preview of data**","774402cc":"**Building regression model**","b653f0d2":"The heatmap demonstrates the correlation coefficient, which quantifies the relationship between all the variables. \nAge and Charges seem to be correlated the most out of all other x variables. Bmi also has a slight effect on charges. \nAnything that goes over 0.5 means that they have strong relationship(1 is a perfect linear relationship)"}}