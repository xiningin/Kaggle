{"cell_type":{"170b2000":"code","2acb517a":"code","8d3750a4":"code","65b924e5":"code","d530eac7":"code","397ee83a":"code","baf3a183":"code","7a6eac70":"code","351c99e9":"code","0d79c0a3":"code","75bb424f":"code","d17059c9":"code","b4128a85":"code","ade613ba":"code","a0aebdca":"code","daee9e10":"code","648a8961":"code","c5f15d4c":"code","dbf00f9d":"code","9c98b5c5":"code","d60ce223":"code","26d4f632":"code","4db628cf":"markdown","b0741bb8":"markdown","f2e4e023":"markdown","e8345b14":"markdown","7f468df3":"markdown","25b20758":"markdown","f1db23b1":"markdown"},"source":{"170b2000":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.ensemble import RandomForestRegressor\n        \ninput_path = Path('\/kaggle\/input\/tabular-playground-series-jan-2021\/')","2acb517a":"import seaborn as sns\nfrom sklearn.linear_model import ElasticNet","8d3750a4":"submission = pd.read_csv(input_path \/ 'sample_submission.csv')\ndisplay(submission.head(3))","65b924e5":"train = pd.read_csv(input_path \/ 'train.csv', index_col='id')\ndisplay(train)","d530eac7":"#visualize possible correlations\ncorr1=train.corr()\nsns.heatmap(corr1, cmap=\"cubehelix\", annot=True)","397ee83a":"test = pd.read_csv(input_path \/ 'test.csv', index_col='id')\ndisplay(test.head(3))","baf3a183":"#visualize possible correlations\ncorr2=train.corr()\nsns.heatmap(corr2, cmap=\"magma\", annot=True)","7a6eac70":"train.columns","351c99e9":"#plotting the test CORRELATION df\nsns.lmplot('cont13', 'cont3', data=corr2,  logistic=False, markers=[\"*\"])","0d79c0a3":"#plotting the train CORRELATION density\ncorr1.plot(kind='density', subplots=True, layout=(15,1), sharex=True, figsize=(10,10))\nplt.show()","75bb424f":"target = train.pop('target')\nX_train, X_test, y_train, y_test = train_test_split(train, target, train_size=0.50)","d17059c9":"# Get benchmark score\nmodel_dummy = DummyRegressor(strategy='median')\nmodel_dummy.fit(X_train, y_train)\ny_dummy = model_dummy.predict(X_test)\nscore_dummy = mean_squared_error(y_test, y_dummy, squared=False)\nprint(f'{score_dummy:0.5f}') \n\n#decreased size from .60 to .50 increased the scores slightly","b4128a85":"# Simple Linear Regression\nmodel_simple_linear = LinearRegression(fit_intercept=False) # data is not centered, don't fit intercept\nmodel_simple_linear.fit(X_train, y_train)\ny_simple_linear = model_simple_linear.predict(X_test)\nscore_simple_linear = mean_squared_error(y_test, y_simple_linear, squared=False)\nprint(f'{score_simple_linear:0.5f}')","ade613ba":"#automated model, visualization, regression\ndef plot_results(name, y, yhat, num_to_plot=10000, lims=(0,12), figsize=(6,6)):\n    plt.figure(figsize=figsize)\n    score = mean_squared_error(y, yhat, squared=False)\n    plt.scatter(y[:num_to_plot], yhat[:num_to_plot], color=\"dimgray\")\n    plt.plot(lims, lims)\n    plt.ylim(lims)\n    plt.xlim(lims)\n    plt.title(f'{name}: {score:0.5f}', fontsize=14)\n    plt.show()\n\nmodel_names = [\"Dummy Median\", \"Linear\",  \"Lasso\", \"Random Forest\"]\n\nmodels = [\n    DummyRegressor(strategy='median'),\n    LinearRegression(fit_intercept=False),\n    Lasso(fit_intercept=False),\n    RandomForestRegressor(n_estimators=50, n_jobs=-1)]\n\nfor name, model in zip(model_names, models):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    plot_results(name, y_test, y_pred)","a0aebdca":"model = RandomForestRegressor(n_estimators=50, n_jobs=-1)\nmodel.fit(train, target)\nsubmission['target'] = model.predict(test)\nsubmission.to_csv('random_forest.csv')","daee9e10":"#automated models: other models\ndef plot_results(name, y, yhat, num_to_plot=10000, lims=(0,12), figsize=(6,6)):\n    plt.figure(figsize=figsize)\n    score = mean_squared_error(y, yhat, squared=False)\n    plt.scatter(y[:num_to_plot], yhat[:num_to_plot], color=\"goldenrod\")\n    plt.plot(lims, lims)\n    plt.ylim(lims)\n    plt.xlim(lims)\n    plt.title(f'{name}: {score:0.5f}', fontsize=16)\n    plt.show()\n\nmodel_names = [\"Ridge Regression\", \"ElasticNet\"]\n\nmodels = [Ridge(alpha = 0.0001),    \n    ElasticNet(alpha=1)]    \n\nfor name, model in zip(model_names, models):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    plot_results(name, y_test, y_pred)","648a8961":"from sklearn.linear_model import ElasticNetCV\n#changed train size\n\nX_train, X_test, y_train, y_test = train_test_split(train, target, train_size=0.8)\n\n#increased size from .50 to .80 increased the score slightly","c5f15d4c":"#automated and visualized\ndef plot_results(name, y, yhat, num_to_plot=10000, lims=(0,12), figsize=(6,6)):\n    plt.figure(figsize=figsize)\n    score = mean_squared_error(y, yhat, squared=False)\n    plt.scatter(y[:num_to_plot], yhat[:num_to_plot], color=\"darkgreen\")\n    plt.plot(lims, lims)\n    plt.ylim(lims)\n    plt.xlim(lims)\n    plt.title(f'{name}: {score:0.5f}', fontsize=14)\n    plt.show()\n\nmodel_name = [\"ElasticNet\"]\n\nmodel = [ElasticNet(alpha=1, normalize=False)]\n\nfor name, model in zip(model_name, model):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    plot_results(name, y_test, y_pred)","dbf00f9d":"model = ElasticNet(alpha=1, normalize=False)\nmodel.fit(train, target)\nsubmission['target1'] = model.predict(test)\nsubmission.to_csv('ElasticNet.csv')","9c98b5c5":"df1 = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\ndf1","d60ce223":"#prepare for final submission\n#make index a column\ndf1.reset_index(inplace=True)","26d4f632":"df2=df1[['id','Predicted']]\ndf2.to_csv('MySubmission.csv')","4db628cf":"## 3- Random Forest model training on all the data and edited Stater Notebook submission","b0741bb8":"# Tabular Playground Series - Jan 2021\n\n**Regression** helps determine relationships among variables and to predict results using a new set of predictors.","f2e4e023":"## A new model","e8345b14":"# Stater Notebook naive model: Slightly modified   \n## 1. Pull out the target, and make a validation split   ","7f468df3":"# Read the data   \nThere are 300,000 rows and 15 columns.   ","25b20758":"## 2.Simple Linear Regression","f1db23b1":"# Other models: Ridge and ElasticNet"}}