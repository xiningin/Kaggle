{"cell_type":{"ca34bf14":"code","e3ecaa16":"code","170cce13":"code","4aeccd12":"code","a128fdb3":"code","a1aa814c":"code","b11a882e":"code","281d7e7b":"code","9bd51b8d":"code","3c32a47f":"code","9bd46ba3":"code","df5a946f":"code","5468e9d7":"markdown","103a93ff":"markdown","04a37be7":"markdown","36864fe6":"markdown","bd9f62b5":"markdown","87f37d8e":"markdown"},"source":{"ca34bf14":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport gc\nimport seaborn as sns\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","e3ecaa16":"%%time\ntrain = pd.read_csv('..\/input\/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32})","170cce13":"train.describe()","4aeccd12":"train.rename({\"acoustic_data\": \"signal\", \"time_to_failure\": \"time\"}, axis=\"columns\", inplace=True)","a128fdb3":"train_sample_signal = train['signal'].values[::100]\ntrain_sample_time = train['time'].values[::100]\n\nfig, ax1 = plt.subplots(figsize=(20,8))\n\nplt.title(\"Signal and time to failure with %1 of data\")\nplt.plot(train_sample_signal, color = 'burlywood')\nax2 = ax1.twinx()\nplt.plot(train_sample_time, color = 'g')\n\ndel train_sample_signal\ndel train_sample_time\ngc.collect()","a1aa814c":"train_sample = train.sample(frac=0.01)\n\nplt.figure(figsize=(12,6))\nplt.title(\"Signal data histogram\")\nax = sns.distplot(train_sample['signal'], label='Signal')\n\ndel train_sample\ngc.collect()","b11a882e":"train_sample = train.sample(frac=0.01)\nplt.figure(figsize=(10,5))\nplt.title(\"Signal distribution without outliers\")\ntmp = train_sample.signal[train_sample.signal.between(-25, 25)]\nax = sns.distplot(tmp, label='Signal', kde=False)\n\ndel train_sample\ndel tmp\ngc.collect()","281d7e7b":"train_signal_million = train['signal'].values[:1000000]\ntrain_time_million = train['time'].values[:1000000]\n\nfig, ax1 = plt.subplots(figsize=(20, 8))\nplt.title(\"first 1 million rows\")\nplt.plot(train_signal_million, color = 'burlywood')\nax2 = plt.twinx()\nplt.plot(train_time_million, color = 'g')\n\ndel train_signal_million\ndel train_time_million\ngc.collect()","9bd51b8d":"train_signal_thousand = train['signal'].values[:100000]\ntrain_time_thousand = train['time'].values[:100000]\n\nfig, ax1 = plt.subplots(figsize=(20, 8))\nplt.title(\"first 100 thousand rows\")\nplt.plot(train_signal_thousand, color = 'burlywood')\nax2 = plt.twinx()\nplt.plot(train_time_thousand, color = 'g')\n\ndel train_signal_thousand\ndel train_time_thousand\ngc.collect()","3c32a47f":"train_signal_one = train['signal'].values[:10000]\ntrain_time_one = train['time'].values[:10000]\n\nfig, ax1 = plt.subplots(figsize=(20, 8))\nplt.title(\"first ten thousand rows\")\nplt.plot(train_signal_one, color = 'burlywood')\nax2 = plt.twinx()\nplt.plot(train_time_one, color = 'g')\n\ndel train_signal_one\ndel train_time_one\ngc.collect()","9bd46ba3":"test_files = os.listdir(\"..\/input\/test\")\nlen(test_files)","df5a946f":"seg = pd.read_csv(\"..\/input\/test\/seg_004cd2.csv\")\n\nfig, ax1 = plt.subplots(figsize=(20, 8))\nplt.title(\"example test data\")\nplt.plot(seg, color = 'g')\n\nseg2 = pd.read_csv(\"..\/input\/test\/seg_00c35b.csv\")\n\nfig2, ax1 = plt.subplots(figsize=(20, 8))\nplt.title(\"example test data\")\nplt.plot(seg2, color = 'g')\n\nseg3 = pd.read_csv(\"..\/input\/test\/seg_00cc91.csv\")\n\nfig3, ax1 = plt.subplots(figsize=(20, 8))\nplt.title(\"example test data\")\nplt.plot(seg3, color = 'g')","5468e9d7":"Let's see signal distribution without outliers.","103a93ff":"Let's check test files as well.","04a37be7":"Let's look at train data's statistical properties","36864fe6":"Let's examine signal and time to failure data more closely.","bd9f62b5":"We can see signal data distribution below. The outliers are caused by earthquakes.","87f37d8e":"Since the data is huge, we sample %1 of it and plot. We can see that signal peaks usually happen right before earthquakes but there are no signal peaks caused by earthquake, that data is not included."}}