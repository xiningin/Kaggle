{"cell_type":{"233aa8fd":"code","cbab2020":"code","6660647f":"code","5035ca89":"code","83a85b7b":"code","69db7c1b":"code","6483f956":"code","500b151d":"code","ad4627e7":"code","eb9a0d62":"code","4357c805":"code","0f36f131":"code","30fb1a49":"code","6bec84f8":"code","d97d3978":"code","1585e91a":"code","39b96526":"code","e37aff6f":"code","98d44cfe":"code","50e4204b":"code","f29166a6":"code","035a6a1c":"code","bc184bf8":"code","07b33eac":"code","b8afc1bc":"code","b60d9fb4":"code","58a9bfc7":"code","1d4fb4bd":"code","19a7051f":"code","c8b47513":"code","b5c8116f":"code","567cf898":"code","e1408b47":"code","9856041f":"code","1849d4c9":"code","ebfc90a6":"code","6a7ccfff":"code","673438b5":"code","93727683":"code","b8ce0212":"markdown","9ef19c2f":"markdown","2efb5a67":"markdown","968a0dc8":"markdown","d2cbd18a":"markdown","0653575e":"markdown","555aea57":"markdown","254e5d22":"markdown","a257dafe":"markdown","6990f745":"markdown"},"source":{"233aa8fd":"import pandas as pd\nimport numpy as np\n\n%matplotlib inline\nfrom scipy.stats import norm\nimport scipy.stats as st\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence\nfrom sklearn.preprocessing.imputation import Imputer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\n\n#from sklearn.ensemble import RandomForestClassifier\n#from sklearn.ensemble import GradientBoostingRegressor\n#from sklearn.tree import DecisionTreeRegressor\n\ntitanic_data = pd.read_csv('..\/input\/train.csv')\ntest_data = pd.read_csv('..\/input\/test.csv')\n\nimport warnings\nwarnings.filterwarnings(action='ignore', category=DeprecationWarning)\nwarnings.filterwarnings(action='ignore', category=FutureWarning)\n\ntitanic_data.info()\ntitanic_data.describe()\ntitanic_data.columns\ntitanic_data.shape\n","cbab2020":"# Columns with missing values\ntotal = titanic_data.isnull().sum().sort_values(ascending=False)\npercent = (titanic_data.isnull().sum()\/titanic_data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head()","6660647f":"# on Test_data\ntotal = test_data.isnull().sum().sort_values(ascending=False)\npercent = (test_data.isnull().sum()\/test_data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head()\n\n#test_data[test_data.isnull().any(axis=1)]","5035ca89":"# Correlation Matrix (heatmap)\ncorrmat = pd.get_dummies(titanic_data, columns=['Sex']).corr()\nf, ax = plt.subplots(figsize=(16, 9))\nsns.heatmap(corrmat, vmax=.8, square=True, annot=True, cmap=\"RdBu_r\") # altri valori: BuGn_r, BrBG","83a85b7b":"# SNS Graph: Men and women count\nsns.countplot(titanic_data['Sex'])","69db7c1b":"data = titanic_data\n# data = pd.get_dummies(titanic_data, columns=['Sex'])\n# Age of people\nplt.title(\"Age (Survived in orange)\")\ndata['Age'].plot.hist(edgecolor='black', linewidth=0.5)\ndata[data.Survived == 1]['Age'].plot.hist(edgecolor='black', linewidth=0.5)\nplt.xlabel(\"Age\")\nplt.ylabel(\"Persons\")","6483f956":"# Men's age\ndata[(data.Sex == 'male')]['Age'].plot.hist(edgecolor='black', linewidth=0.5)\ndata[(data.Survived == 1) & (data.Sex == 'male')]['Age'].plot.hist(edgecolor='black', linewidth=0.5)","500b151d":"# Women's age\ndata[(data.Sex == 'female')]['Age'].plot.hist(edgecolor='black', linewidth=0.5)\ndata[(data.Survived == 1) & (data.Sex == 'female')]['Age'].plot.hist(edgecolor='black', linewidth=0.5)","ad4627e7":"# Correlation between Fare and Survived, Pclass as Hue\nsns.barplot(x=\"Survived\", y=\"Fare\", hue=\"Pclass\", data=data)","eb9a0d62":"# Scatter plot Fare\/Age, Survived as Hue, Pclass as filter\ng = sns.FacetGrid(data, hue=\"Survived\", col=\"Pclass\", margin_titles=True,\n                  palette={1:\"blue\", 0:\"red\"})\ng=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend();","4357c805":"# Scatterplot Fare\/Age, Survived ad Hue, Sex as filter\ng = sns.FacetGrid(data, hue=\"Survived\", col=\"Sex\", margin_titles=True,\n                palette={1:\"blue\", 0:\"red\"},hue_kws=dict(marker=[\"^\", \"v\"]))\ng.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\nplt.subplots_adjust(top=0.8)\ng.fig.suptitle('Survival by Gender , Age and Fare');","0f36f131":"# Correlation with SibSp\nsns.barplot(x=\"SibSp\", y=\"Survived\", data=data)","30fb1a49":"# Correlation with Parch\nsns.barplot(x=\"Parch\", y=\"Survived\", data=data)","6bec84f8":"# with Embarked\nsns.barplot(x=\"Embarked\", y=\"Survived\", data=data)","d97d3978":"# Correlation with FamilySize, a new feature made from the sum of Parch and SibSp\ndata[\"FamilySize\"] = data['Parch'] + data['SibSp'] + 1\nsns.barplot(x=\"FamilySize\", y=\"Survived\", data=data)\n\n# Another two new features: IsAlone and BigFamily (if FamilySize>=5 then BigFamily=1)\n# No changes to the dataset, just testing\ndata[\"IsAlone\"] = 0\ndata[\"BigFamily\"] = 0\ndata.loc[data['FamilySize'] == 1, 'IsAlone'] = 1\ndata.loc[data['FamilySize'] >= 5, 'BigFamily'] = 1","1585e91a":"sns.barplot(x=\"IsAlone\", y=\"Survived\", data=data)","39b96526":"sns.barplot(x=\"BigFamily\", y=\"Survived\", data=data)","e37aff6f":"# Another new feature named Couple (not used)\ndata['Couple'] = 0\ndata.loc[data['FamilySize'] == 2, 'Couple'] = 1\n\nsns.barplot(x=\"Couple\", y=\"Survived\", data=data)","98d44cfe":"# New feature: SharedTicket (not used, IsAlone is a better predictor, though it may need improving)\n# Yet no changes in the original dataset, only testing\nticket = pd.DataFrame(data['Ticket'].sort_values()) # sort\nticket['SharedTicket'] = 0\n\nticket['SharedTicket'] = (ticket['Ticket'].eq(ticket['Ticket'].shift(1)) | ticket['Ticket'].eq(ticket['Ticket'].shift(-1)))\nticket['SharedTicket'] = ticket['SharedTicket'].astype(int)\n\ndata['SharedTicket'] = 0\ndata['SharedTicket'] = ticket['SharedTicket'] # joins by index, works correctly\n\ndata.loc[data['SharedTicket']==1, 'Ticket'].sort_values()\n\n# List of travelers with a shared ticket (SharedTicket), first 20 rows\ndata.loc[data['SharedTicket']==1, ['Ticket', 'Name']].sort_values(\"Ticket\").head(20)","50e4204b":"# Correlation with Survived\nsns.barplot(x=\"SharedTicket\", y=\"Survived\", data=data)","f29166a6":"# TITLES AND AGE - Titles are captured and filled in a new column\ndef make_ages_from_titles(titanic_data):\n    names = titanic_data.Name.str.split(\",\", expand=True)\n    names = names[1].str.split(n=1, expand=True)\n    titanic_data[\"Title\"] = names[0]\n    \n    # Plotting\n    # titanic_data['Title'].value_counts().plot.bar(rot=0, edgecolor='black', figsize=(15, 6), linewidth=0.5)\n    # plt.xlabel(\"Titles\")\n    \n    # Average age by title - Values to fill on Age NaNs\n    #titanic_data[(titanic_data.Title == \"Mr.\")]['Age'].mean()\n    #titanic_data[(titanic_data.Title == \"Miss.\")]['Age'].mean()\n    #titanic_data[(titanic_data.Title == \"Mrs.\")]['Age'].mean()\n    #titanic_data[(titanic_data.Title == \"Dr.\")]['Age'].mean()\n    #titanic_data[(titanic_data.Title == \"Master.\")]['Age'].mean()\n\n    df = titanic_data\n\n    median = round(titanic_data[(titanic_data.Title == \"Mr.\")]['Age'].median(), 0)\n    df.loc[df['Title'] == 'Mr.', 'Age'] = df.loc[df['Title'] == 'Mr.', 'Age'].fillna(median)\n\n    median = round(titanic_data[(titanic_data.Title == \"Miss.\")]['Age'].mean(), 0)\n    df.loc[df['Title'] == 'Miss.', 'Age'] = df.loc[df['Title'] == 'Miss.', 'Age'].fillna(median)\n    df.loc[df['Title'] == 'Ms.', 'Age'] = df.loc[df['Title'] == 'Ms.', 'Age'].fillna(median)\n\n    median = round(titanic_data[(titanic_data.Title == \"Mrs.\")]['Age'].mean(), 0)\n    df.loc[df['Title'] == 'Mrs.', 'Age'] = df.loc[df['Title'] == 'Mrs.', 'Age'].fillna(median)\n\n    median = round(titanic_data[(titanic_data.Title == \"Dr.\")]['Age'].mean(), 0)\n    df.loc[df['Title'] == 'Dr.', 'Age'] = df.loc[df['Title'] == 'Dr.', 'Age'].fillna(median)\n\n    median = round(titanic_data[(titanic_data.Title == \"Master.\")]['Age'].mean(), 0)\n    df.loc[df['Title'] == 'Master.', 'Age'] = df.loc[df['Title'] == 'Master.', 'Age'].fillna(median)\n    \n    titanic_data['Title'] = titanic_data['Title'].replace(['Lady', 'Countess', 'Capt.', 'Col.',\n                                'Don.', 'Dr.', 'Major', 'Rev.', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    \n    title_mapping = {\"Mr.\": 1, \"Miss.\": 2, \"Ms.\": 2, \"Mrs.\": 3, \"Master.\": 4, \"Rare\": 5}\n    titanic_data['Title'] = titanic_data['Title'].map(title_mapping)\n    titanic_data['Title'] = titanic_data['Title'].fillna(0)\n\n    titanic_data = df\n    return titanic_data\n\n# Run it in both data files\ntitanic_data = make_ages_from_titles(titanic_data)\ntest_data = make_ages_from_titles(test_data)\n# print ('Done')","035a6a1c":"# CABIN and EMBARKED - Filling NaN values with Unknown (for now)\n\ndef cabin_embarked(titanic_data):\n    df = titanic_data\n    df[['Cabin']] = df[['Cabin']].fillna(value=\"Unknown\")\n    #df[df[\"Embarked\"].isnull()] # to show the two Null rows\n    df[['Embarked']] = df[['Embarked']].fillna(value=\"Unknown\")\n    titanic_data = df\n    return titanic_data\n\ntitanic_data = cabin_embarked(titanic_data)\ntest_data = cabin_embarked(test_data)\n\n# SHAREDTICKET - New feature - to move below\n\ndef shared_ticket(titanic_data):\n    \n    ticket = pd.DataFrame(titanic_data['Ticket'].sort_values()) # sort\n    ticket['SharedTicket'] = 0\n\n    ticket['SharedTicket'] = (ticket['Ticket'].eq(ticket['Ticket'].shift(1)) | ticket['Ticket'].eq(ticket['Ticket'].shift(-1)))\n    ticket['SharedTicket'] = ticket['SharedTicket'].astype(int)\n\n    titanic_data['SharedTicket'] = 0\n    titanic_data['SharedTicket'] = ticket['SharedTicket']\n    return titanic_data\n\ntitanic_data = shared_ticket(titanic_data)\ntest_data = shared_ticket(test_data)","bc184bf8":"titanic_data.sample(5)\ntest_data.sample(5)","07b33eac":"def cabin_letters (titanic_data):\n    \n    df = titanic_data\n    # Cabin numbers is equal to the number of str.split elements (number of the cabins)\n    cabins = df.loc[df['Cabin'] != 'Unknown', 'Cabin'].str.split()\n    df['Cabin_numbers'] = cabins.transform(lambda x: len(x)).astype(int)\n    df['Cabin_numbers'] = df['Cabin_numbers'].fillna(value=1) # at least one cabin?\n\n    # We need only the first letter\n    titanic_data['Cabin_letter'] = titanic_data['Cabin'].str[0]\n\n    titanic_data = df\n    return titanic_data\n\ntitanic_data = cabin_letters(titanic_data)\ntest_data = cabin_letters(test_data)","b8afc1bc":"titanic_data.head()\ntest_data.head()","b60d9fb4":"# New Heatmap\ncorrmat = pd.get_dummies(titanic_data, columns=['Sex','Cabin_numbers','Cabin_letter',]).corr()\nf, ax = plt.subplots(figsize=(35, 16))\nsns.heatmap(corrmat, vmax=.8, square=True, annot=True, cmap=\"RdBu_r\") # other values to try: BuGn_r, BrBG","58a9bfc7":"def fill_unknown_cabins (titanic_data):\n\n    df = titanic_data\n    \n    # V20: Tried to left them as Unknown\/U but prediction did not improve\n    # V21: Fixing the cabins letter improves prediction (0.79 from 0.77)\n    \n    df.loc[(df['Pclass']==1) & (df['Cabin_letter']=='U'), 'Cabin_letter'] = 'B'\n    df.loc[(df['Pclass']==2) & (df['Cabin_letter']=='U'), 'Cabin_letter'] = 'D'\n    df.loc[(df['Pclass']==3) & (df['Cabin_letter']=='U'), 'Cabin_letter'] = 'G'\n\n    # Checking if everything ok\n    df.Cabin_letter.value_counts()\n\n    # Cabin with letter T\n    df.loc[df['Cabin_letter']=='T']\n\n    # It is a first class cabin so i set it as B\n    df.loc[df['Cabin_letter']=='T', ['Cabin_letter','Cabin']] = 'B'\n\n    titanic_data = df\n    return titanic_data\n\ntitanic_data = fill_unknown_cabins(titanic_data)\ntest_data = fill_unknown_cabins(test_data)\n\ndef family_size_alone (titanic_data):\n    titanic_data['FamilySize'] = titanic_data['SibSp'] + titanic_data['Parch'] + 1\n    titanic_data['IsAlone'] = 0\n    titanic_data['BigFamily'] = 0\n    titanic_data['Couple'] = 0\n    titanic_data.loc[titanic_data['FamilySize'] == 2, 'Couple'] = 1\n    titanic_data.loc[titanic_data['FamilySize'] == 1, 'IsAlone'] = 1\n    titanic_data.loc[titanic_data['FamilySize'] >= 5, 'BigFamily'] = 1\n    \n    # Dropping Parch, SibSp e FamilySize for IsAlone, decide later about BigFamily\n    titanic_data = titanic_data.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\n    return titanic_data\n\ntitanic_data = family_size_alone(titanic_data)\ntest_data = family_size_alone(test_data)","1d4fb4bd":"titanic_data.head()\ntest_data.head()","19a7051f":"# Analysis only\ndf = titanic_data\ndf['AgeBand'] = pd.cut(df['Age'], 5)\ndf[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)","c8b47513":"# Qcut\ndf['FareBand'] = pd.qcut(df['Fare'], 4)\ndf[['FareBand', 'Survived']].groupby(['FareBand'], \n                                               as_index=False).mean().sort_values(by='FareBand', ascending=True)","b5c8116f":"def Age_Fare_Band(titanic_data):\n    \n    # Group ages and fair in bars (bins), an example of feature scaling\n    \n    titanic_data['AgeBand'] = pd.cut(titanic_data['Age'], 5)\n    titanic_data.loc[ titanic_data['Age'] <= 16, 'Age'] = 0\n    titanic_data.loc[(titanic_data['Age'] > 16) & (titanic_data['Age'] <= 32), 'Age'] = 1\n    titanic_data.loc[(titanic_data['Age'] > 32) & (titanic_data['Age'] <= 48), 'Age'] = 2\n    titanic_data.loc[(titanic_data['Age'] > 48) & (titanic_data['Age'] <= 64), 'Age'] = 3\n    titanic_data.loc[ titanic_data['Age'] > 64, 'Age'] = 4\n    \n    titanic_data['Fare'].fillna(titanic_data['Fare'].dropna().median(), inplace=True)\n    titanic_data['FareBand'] = pd.qcut(titanic_data['Fare'], 4)\n    titanic_data.loc[ titanic_data['Fare'] <= 7.91, 'Fare'] = 0\n    titanic_data.loc[(titanic_data['Fare'] > 7.91) & (titanic_data['Fare'] <= 14.454), 'Fare'] = 1\n    titanic_data.loc[(titanic_data['Fare'] > 14.454) & (titanic_data['Fare'] <= 31), 'Fare']   = 2\n    titanic_data.loc[ titanic_data['Fare'] > 31, 'Fare'] = 3\n    titanic_data['Fare'] = titanic_data['Fare'].astype(int)\n\n    titanic_data = titanic_data.drop(['AgeBand'], axis=1)\n    titanic_data = titanic_data.drop(['FareBand'], axis=1)\n    return titanic_data\n\ntitanic_data = Age_Fare_Band(titanic_data)\ntest_data = Age_Fare_Band(test_data)","567cf898":"titanic_data.head()\ntest_data.head()","e1408b47":"# Correction where two rows of Embarked are Unknown - V23\ntitanic_data.loc[titanic_data['Embarked'] == 'Unknown']\ntitanic_data['Embarked'] = titanic_data['Embarked'].replace('Unknown', 'U')\n\n#titanic_data.iloc[61]\n#titanic_data.iloc[829]","9856041f":"from sklearn import preprocessing\n\ndef mapping(titanic_data):\n    # sex_map = {\"female\": 1, \"male\": 0} # si passa sex_map dentro map(), un altro modo di fare il mapping\n    titanic_data['Sex'] = titanic_data['Sex'].map( {\"female\": 1, \"male\": 0} ).astype(int)\n    \n    # V23: deactivated because the prediction get worse (!), don't know why. LabelEconder below works better\n    #titanic_data['Embarked'] = titanic_data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2, 'U': 3} ).astype(int)\n    #titanic_data['Cabin_letter'] = titanic_data['Cabin_letter'].map( {'A': 6, 'B': 6, 'C': 5, 'D': 4, 'E': 3, 'F': 2, 'G': 1, 'U': 0} ).astype(int)\n    return titanic_data\n\ntitanic_data = mapping(titanic_data)\ntest_data = mapping(test_data)\n\n# V23: reactivated because it improves the model, need check why the manual mapping worsen it\ndef encode_features(titanic_data, test_data):\n    features = ['Cabin_letter','Embarked']\n    df_combined = pd.concat([titanic_data, test_data])\n    \n    for feature in features:\n        le = preprocessing.LabelEncoder()\n        le = le.fit(df_combined[feature])\n        titanic_data[feature] = le.transform(titanic_data[feature])\n        test_data[feature] = le.transform(test_data[feature])\n    return titanic_data, test_data\n    \ntitanic_data, test_data  = encode_features(titanic_data, test_data)","1849d4c9":"# Heatmap\ncorrmat = titanic_data.corr()\nf, ax = plt.subplots(figsize=(16, 9))\nsns.heatmap(corrmat, vmax=.8, square=True, annot=True, cmap=\"RdBu_r\")","ebfc90a6":"titanic_data.head()\ntest_data.head()\n\n# List of features, will be used on test_data too\n\nfeatures = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Title', 'Cabin_letter', 'IsAlone']\n\nX = titanic_data [features] #V27: features (0.8086)\ny = titanic_data['Survived']","6a7ccfff":"# Split into validation and training data\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.50, random_state=1)\n\n# Parameters\nn_est = 1000\nlearn = 0.10\nmax_dp = 3\n\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Modello: XGBClassifier\nxgb_model = XGBClassifier (n_estimators=n_est, learning_rate=learn, max_depth=max_dp)\nxgb_model.fit (train_X, train_y)\nxgb_predictions = xgb_model.predict (test_X)\n\nprint(\"Accuracy: {0}\".format(accuracy_score(test_y, xgb_predictions)))","673438b5":"# XGBRegressor Pipeline with full data and Cross-Validation #V27 = 0.8060\nxgb_final = make_pipeline(XGBClassifier(n_estimators=n_est, \n                                        learning_rate=learn, \n                                        xgbclassifier__early_stopping_rounds=5, \n                                        xgbclassifier__eval_set=[(X, y)]))\n\n# Cross-Validation\nscores = cross_val_score(xgb_final, X, y, scoring='accuracy', cv=3)\nprint('XGB Pipeline Cross-Validation Accuracy: %2f' %scores.mean())\nprint(scores)\n\nxgb_final.fit(X, y);","93727683":"ids = test_data['PassengerId']\nfinal_data = test_data [features]\n\npredictions = xgb_final.predict(final_data);\n\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)\noutput.head()","b8ce0212":"# Loading the model\n\nThe model I'm using is XGBoost Classifier with the following features:","9ef19c2f":"# Final submit\nLet's give to Kaggle our results:","2efb5a67":"Let's see the **heatmap** again. Also what i found so far:\n- Cabins with letter A, B and C were the cabins of the first class and did cost more\n- The Unknown cabins comes mostly from the 3rd class\n\nThoughts:\n- **Fare** may group multiple variables and can be removed *(nope, found it is better to keep it - V24)*\n","968a0dc8":"**Hello and thank you** for checking this Kernel, most of the code comes from other sources, [especially from here](http:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions), though some functions and intuitions also comes from my personal work.\n\nThis Notebook comes from my private study and it is expected that you already did some work on the Titanic Data Competition. Feel free to copy\/fork and to reuse this code as you deem fit.\n\n*Update 06\/12 - Fixed some typos*\n\n# Data analysis\nStudying the dataset:\n- Columns with missing values\n- Correlation matrix (heatmap)\n- Correlations between single variables\n","d2cbd18a":"# Passenger cabins\n\nSave the **number of cabins** in a new column that will be called **Cabin_numbers**,  after which we save **only the first character** of the cabin in a new column called **Cabin_letter**:","0653575e":"**Encoding of columns**, similar to the creation of dummy variables:","555aea57":"We make a **division of the ages in five bands** and same work is done for **Fair** which is divided in **four bands**:","254e5d22":"# Unknown cabins fix\nThe cabins marked before as Unknown were now set  to **B** for the first class, **D** for the second class, **G** for the third class.\n\nThere is also a mysterious cabin with letter T, fixed with B because it belongs to the first class:","a257dafe":"# Solving NaN values\n\nThere are several **NaN values** in Cabin (687), Age (177) and Embarked (2).\n\n- To fill Age: Capture the  **titles** from names (Mr, Miss, Mrs, etc), take the **median** and use it to fill the NaN values (previously I took the average but the median is a better choice)\n- For Cabin ed Embarked: I fill them with **Unknown** for the moment\n\nActually there is a better way to do this, will improve in a later version","6990f745":"I love **heatmaps**:"}}