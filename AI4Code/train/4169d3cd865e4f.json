{"cell_type":{"611663f6":"code","ce880f70":"code","ce025e14":"code","cfc03480":"code","9196b004":"code","06ccadea":"code","1e09ddfe":"code","4ae3b7fa":"code","826a03bc":"code","75e6560a":"code","7db7cf0f":"code","e0c5ff6b":"code","40028e25":"code","a844e0a0":"code","a17f3817":"markdown","c069998a":"markdown"},"source":{"611663f6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ce880f70":"!git clone https:\/\/github.com\/trtm\/ABAM","ce025e14":"!ls -l","cfc03480":"!ls -l ABAM\/","9196b004":"ABAM_DATA_SENTENCES_without_sentences = pd.read_csv(\n        '.\/ABAM\/data\/ABAM_DATA_SENTENCES.tsv', \n        sep='\\t')\nprint(len(ABAM_DATA_SENTENCES_without_sentences))","06ccadea":"ABAM_SENTENCES = pd.read_csv(\n        '\/kaggle\/input\/aspect-based-argument-mining\/ABAM_SENTENCES.tsv', \n        sep='\\t')\nprint(len(ABAM_SENTENCES))","1e09ddfe":"assert len(ABAM_DATA_SENTENCES_without_sentences)==len(ABAM_SENTENCES)","4ae3b7fa":"ABAM_DATA_SENTENCES = pd.merge(\n        ABAM_DATA_SENTENCES_without_sentences[['topic', 'sentence_hash', 'stance', 'aspect', 'inner', 'cross']], \n        ABAM_SENTENCES, \n        on='sentence_hash')\nABAM_DATA_SENTENCES = ABAM_DATA_SENTENCES[['topic', 'sentence_hash', 'sentence', 'stance', 'aspect', 'inner', 'cross']]\nprint(len(ABAM_DATA_SENTENCES))","826a03bc":"print(ABAM_DATA_SENTENCES[['topic', 'sentence_hash']].groupby('topic').count())","75e6560a":"ABAM_DATA_SEGMENTS_without_segments = pd.read_csv(\n        '.\/ABAM\/data\/ABAM_DATA_SEGMENTS.tsv', \n        sep='\\t')\nprint(len(ABAM_DATA_SEGMENTS_without_segments))","7db7cf0f":"ABAM_SEGMENTS = pd.read_csv(\n        '\/kaggle\/input\/aspect-based-argument-mining\/ABAM_SEGMENTS.tsv', \n        sep='\\t')\nprint(len(ABAM_SEGMENTS))","e0c5ff6b":"assert len(ABAM_DATA_SEGMENTS_without_segments)==len(ABAM_SEGMENTS)","40028e25":"ABAM_DATA_SEGMENTS = pd.merge(\n        ABAM_DATA_SEGMENTS_without_segments[['topic', 'sentence_hash', 'segment_count', 'segment_hash', 'stance', 'aspect', 'inner', 'cross']], \n        ABAM_SEGMENTS, on='segment_hash')\nABAM_DATA_SEGMENTS = ABAM_DATA_SEGMENTS[['topic', 'sentence_hash', 'segment_count', 'segment_hash', 'segment', 'stance', 'aspect', 'inner', 'cross']]\nprint(len(ABAM_DATA_SEGMENTS))","a844e0a0":"print(ABAM_DATA_SEGMENTS[['topic', 'segment_hash']].groupby('topic').count())","a17f3817":"### SENTENCES","c069998a":"### SEGMENTS"}}