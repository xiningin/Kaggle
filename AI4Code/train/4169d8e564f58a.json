{"cell_type":{"1c838062":"code","f6352b52":"code","33b923a9":"code","9eaaed2a":"code","e523bb18":"code","479f9f07":"code","f5e82c04":"code","7014431c":"code","c918e5a1":"code","c981ae08":"code","1fbd113b":"code","53bbde81":"code","c6e09a67":"code","686f5a61":"code","f11d86c1":"code","c0ef5d7f":"markdown","8aa45d58":"markdown","bd29afc5":"markdown","d78e2910":"markdown","afac2742":"markdown","fc51ec9f":"markdown"},"source":{"1c838062":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize \nimport string\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom sklearn.metrics import accuracy_score # for evaluating results\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f6352b52":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")","33b923a9":"train.head()","9eaaed2a":"test.head()","e523bb18":"# Load stop word\neng_stopwords = set(stopwords.words(\"english\"))","479f9f07":"def processingData(train, test):\n    # Tokenize\n    train['question_text'] = train[\"question_text\"].apply(lambda x: \" \".join(word_tokenize(str(x))))\n    test['question_text'] = test[\"question_text\"].apply(lambda x: \" \".join(word_tokenize(str(x))))\n\n    # Remove punctuation\n    train['question_text'] = train[\"question_text\"].apply(lambda x: x.translate(str.maketrans('','',string.punctuation)))\n    test['question_text'] = test[\"question_text\"].apply(lambda x: x.translate(str.maketrans('','',string.punctuation)))\n\n    ## Remove stopwords in the text ##\n    train[\"question_text\"] = train[\"question_text\"].apply(lambda x: \" \".join([w for w in str(x).lower().split() if not w in eng_stopwords]))\n    test[\"question_text\"] = test[\"question_text\"].apply(lambda x: \" \".join([w for w in str(x).lower().split() if not w in eng_stopwords]))\n    \n    return train, test","f5e82c04":"train, test = processingData(train, test)","7014431c":"train.head()","c918e5a1":"test.head()","c981ae08":"train_question_list = train['question_text']\ntest_question_list = test['question_text']\n\nvectorizer  = CountVectorizer()\n\nx_train =  vectorizer.fit_transform(train_question_list)\nx_test =  vectorizer.transform(test_question_list)","1fbd113b":"y_train_tfidf = np.array(train[\"target\"].tolist())","53bbde81":"train_x, validate_x, train_y, validate_y = train_test_split(x_train, y_train_tfidf, test_size=0.3)","c6e09a67":"clf = MultinomialNB()\nclf.fit(train_x, train_y)\ny_vad = clf.predict(validate_x)\nprint('accuracy = %.2f%%' % \\\n      (accuracy_score(validate_y, y_vad)*100))","686f5a61":"y_predict = clf.predict(x_test)\npredict = pd.DataFrame(data = y_predict, columns=['prediction'])\npredict = predict.astype(int)","f11d86c1":"id = test['qid']\nid_df = pd.DataFrame(id)\n# Join predicted into result dataframe and write result as a CSV file\nresult = id_df.join(predict)\nresult.to_csv(\"submission.csv\", index = False)","c0ef5d7f":"**Extracting result**","8aa45d58":"**Processing data**","bd29afc5":"**Extracting features from text**","d78e2910":"**Load data** ","afac2742":"**Training**","fc51ec9f":"**Prediction**"}}