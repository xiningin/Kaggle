{"cell_type":{"ea35a4e9":"code","c57c58ae":"code","69299209":"code","918f24a3":"code","d7c3d17b":"code","dcafbe0f":"code","6d9e8dbf":"code","00824055":"code","a50795a5":"code","48dbdf3f":"code","b637d06f":"code","3321938d":"code","6e3ebec3":"code","3f9901a4":"code","24492e01":"code","0e319bed":"code","104bce81":"code","b4b9a85e":"code","48225078":"code","203c12d5":"markdown","ba583bc8":"markdown","b95ed690":"markdown","e602bfa8":"markdown","c7ac5dd4":"markdown","e84c549f":"markdown","a221330c":"markdown","3ea1981a":"markdown","351cc89c":"markdown","884b55e9":"markdown","1d56e54b":"markdown","2f75a679":"markdown","323bfdb9":"markdown","52776c51":"markdown","cc43eb77":"markdown"},"source":{"ea35a4e9":"import matplotlib.pyplot as plt # visualiza\u00e7\u00e3o de dados\nimport seaborn as sns # visualiza\u00e7\u00e3o de dados\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\n\nimport os # interface with the operational system\n# Lista os arquivos na pasta '..\/input\/' onde foram salvos os dados\nprint(os.listdir(\"..\/input\/\"))","c57c58ae":"df = pd.read_csv('..\/input\/Iris.csv')\ndf.head()","69299209":"df.info(null_counts=True)","918f24a3":"from sklearn.model_selection import train_test_split","d7c3d17b":"variables = ['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']\ntarget = 'Species'","dcafbe0f":"RANDOM_STATE = 1","6d9e8dbf":"X_train, X_test, y_train, y_test = train_test_split(df[variables],\n                                                    df[target], \n                                                    test_size=0.33, # 33% ser\u00e1 amostra de teste\n                                                    random_state=RANDOM_STATE,\n                                                    stratify=df[target])","00824055":"# Usando o m\u00f3dulo tree para chamar o classificador de \u00e1rvore de decis\u00e3o\nfrom sklearn import tree\n\n# Guardando a semente aleat\u00f3ria\nRANDOM_STATE = 1\n\n# Todos esses s\u00e3o os par\u00e2metros da DecisionTree implementada no scikit-learn, busque sua explica\u00e7\u00e3o detalhada na documenta\u00e7\u00e3o\ndec_clf = tree.DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, \n                                      min_samples_split=2, min_samples_leaf=1, \n                                      min_weight_fraction_leaf=0.0, max_features=None, \n                                      random_state=RANDOM_STATE, max_leaf_nodes=None, \n                                      min_impurity_decrease=0.0, min_impurity_split=None, \n                                      class_weight=None, presort=False)\n\n# Usando os arquivos de treino com as vari\u00e1veis e o target, ajustamos um modelo\ndec_clf.fit(X_train, y_train)\n\n# Usando a biblioteca graphviz, podemos plotar a \u00e1rvore gerada pelo nosso modelo\nimport graphviz\ndot_data = tree.export_graphviz(dec_clf, out_file=None, feature_names=variables, \n                                class_names=dec_clf.classes_, filled=True) \ngraph = graphviz.Source(dot_data) \ngraph","a50795a5":"# Aplica o modelo nas vari\u00e1veis de teste\ny_pred = dec_clf.predict(X_test)","48dbdf3f":"from sklearn.metrics import confusion_matrix\n\n# Compara o resultado do modelo com o resultado verdadeiro\ncnf_matrix = confusion_matrix(y_test, y_pred)\n\n# Constr\u00f3i um Dataframe pandas com a matriz de confus\u00e3o apenas para ficar mais leg\u00edvel\npd.DataFrame(cnf_matrix, columns=('Prev ' + dec_clf.classes_), \n             index=('True ' + dec_clf.classes_))","b637d06f":"import itertools\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n    \n    plt.grid(False)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","3321938d":"plot_confusion_matrix(cnf_matrix, dec_clf.classes_, normalize=False, \n                      title='Confusion matrix', cmap=plt.cm.Greens)","6e3ebec3":"def prec_revoc(cnf_matrix, classes):\n    prec = []\n    revoc = []\n    for i in range(len(classes)):\n        prec.append(cnf_matrix[i][i]\/cnf_matrix[:][i].sum())\n        revoc.append(cnf_matrix[i][i]\/cnf_matrix[i].sum())\n    \n    print(pd.DataFrame([prec,revoc], columns=classes, index=['Precis\u00e3o', 'Revoca\u00e7\u00e3o']))","3f9901a4":"prec_revoc(cnf_matrix, dec_clf.classes_)","24492e01":"# Importa o classificador do scikit-learn\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Salva a semente aleat\u00f3ria\nRANDOM_STATE = 3\n\n# Ajusta os par\u00e2metros de um classificador do tipo RandomForest. \n# Verificar a descri\u00e7\u00e3o de cada um na documenta\u00e7\u00e3o\nrnd_clf = RandomForestClassifier(n_estimators=30, criterion='gini', max_depth=None, \n                                 min_samples_split=4, min_samples_leaf=2,\n                                 min_weight_fraction_leaf=0.0, max_features='auto', \n                                 max_leaf_nodes=None, min_impurity_decrease=0.0, \n                                 min_impurity_split=None, bootstrap=True, oob_score=False, \n                                 n_jobs=1, random_state=RANDOM_STATE, \n                                 verbose=0, warm_start=False, class_weight=None)\n\n# Ajusta um modelo aos dados de treino\nrnd_clf.fit(X_train, y_train)\n\n# Prev\u00ea os valores para as vari\u00e1veis de teste com o modelo\ny_pred = rnd_clf.predict(X_test)\n\n# Gera a matrix de confus\u00e3o\ncnf_matrix = confusion_matrix(y_test, y_pred)\n\n# Plota a matriz de confus\u00e3o\nplot_confusion_matrix(cnf_matrix, rnd_clf.classes_, normalize=False, \n                      title='Confusion matrix', cmap=plt.cm.Greens)","0e319bed":"prec_revoc(cnf_matrix, rnd_clf.classes_)","104bce81":"# Chama o m\u00f3dulo export_graphviz da biblioteca do sklearn\nfrom sklearn.tree import export_graphviz\n\n# Escolhe a quarta \u00e1rvore gerada pelo modelo random forest\ntree = rnd_clf.estimators_[3]\n\n# Plota essa \u00e1rvore que \u00e9 uma nas \"n_estimators\" do modelo random forest\nview = export_graphviz(tree, out_file=None, feature_names = variables, \n                       class_names = rnd_clf.classes_, filled = True)\ngraphviz.Source(view)","b4b9a85e":"# Importando o m\u00f3dulo com o classificador\nfrom sklearn import svm\n\n# Salvando a semente aleat\u00f3ria\nRANDOM_STATE = 1\n\n# Ajustando os par\u00e2metros do classificador\nsvm_clf = svm.LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True, \n                        intercept_scaling=1, loss='squared_hinge', max_iter=1000, \n                        multi_class='ovr', penalty='l2', random_state=None, tol=0.0001, \n                        verbose=0)\n\n# Ajustando o modelo aos dados de treino\nsvm_clf.fit(X_train,y_train)\n\n# Prevendo os valores dos dados de teste com o modelo treinado\ny_pred = svm_clf.predict(X_test)\n\n# Comparando os dados previstos com os reais e gerando a matriz de confus\u00e3o\ncnf_matrix = confusion_matrix(y_test, y_pred)\n\n# Plotando a matriz de confus\u00e3o de forma mais amig\u00e1vel\nclasses = svm_clf.classes_\nplot_confusion_matrix(cnf_matrix, classes, normalize=False, \n                      title='Confusion matrix', cmap=plt.cm.Greens)","48225078":"prec_revoc(cnf_matrix, svm_clf.classes_)","203c12d5":"<b> Para comparar os resultados anteriores da \u00e1rvore de decis\u00e3o, vamos usar a biblioteca do sklearn para treinar um random forest [sklearn.randomForest](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html).\n\nAproveite o c\u00f3digo abaixo e as visualiza\u00e7\u00f5es posteriores para variar a vari\u00e1vel n_estimators e observar quis tipos de altera\u00e7\u00e3o acontecem.<\/b>","ba583bc8":"<b>Finalmente, para comparar os resultados anteriores com o svm, utilizaremos a implementa\u00e7\u00e3o LinearSVC presente no sklearn. Essa n\u00e3o \u00e9 a \u00fanica implementa\u00e7\u00e3o l\u00e1, outras vers\u00f5es com kernel tamb\u00e9m est\u00e3o presentes. A documenta\u00e7\u00e3o desse algoritmo pode ser encontrada em [sklearn.svm.LinearSVC](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC)\n\nNovamente, tente variar os par\u00e2metros num\u00e9ricos para perceber que tipo de efeitos eles tem nos resultados<\/b>","b95ed690":"<b>A primeira etapa de um aprendizado de m\u00e1quina \u00e9 separar os dados em treino e teste. Para que as m\u00e9tricas do seu teste sejam confi\u00e1veis, voc\u00ea n\u00e3o pode mostrar nenhum dado do teste durante o treinamento do modelo. Isso pode ser feito de mais de uma forma: *train test split, cross validation, leave one out etc*. Exemplos de fun\u00e7\u00f5es que separam os dados para treino e teste podem ser vistos [aqui](http:\/\/scikit-learn.org\/stable\/modules\/classes.html#module-sklearn.model_selection).\nPara esse exemplo, utilizaremos o train_test_split e a sua [documenta\u00e7\u00e3o](http:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.train_test_split.html) no scikit-learn<\/b>","e602bfa8":"<b>Usando a fun\u00e7\u00e3o declarada acima plotamos novamente a matriz de confus\u00e3o<\/b>","c7ac5dd4":"<b>Abaixo a fun\u00e7\u00e3o .info( ) dos dataframes do pandas nos mostra os tipos de cada coluna e a quantidade de valores nulos. Valores n\u00e3o num\u00e9ricos ou campos nulos n\u00e3o s\u00e3o tratados pelos algoritmos do scikit-learn e teriam que ser transformados para que pud\u00e9ssmos utilizar as fun\u00e7\u00f5es dessa biblioteca. Como pode ser visto abaixo, isso n\u00e3o ser\u00e1 necess\u00e1rio nesse database.<\/b>\n","e84c549f":"<b>A leitura padr\u00e3o de bases .csv \u00e9 mostrada abaixo:<\/b>","a221330c":"<p><b1><b>Para mostrar exemplos de classificadores e como eles se comportam, usaremos a base de dados Iris. Por ser um exemplo comum em ci\u00eancia de dados, temos uma caracteriza\u00e7\u00e3o pronta para essa base na plataforma kaggle com uma [descri\u00e7\u00e3o simples](https:\/\/www.kaggle.com\/uciml\/iris\/home) e [algumas visualiza\u00e7\u00f5es](https:\/\/www.kaggle.com\/uciml\/iris).  Como todos os atributos da base iris s\u00e3o num\u00e9ricos, ela n\u00e3o exigir\u00e1 nenhuma transforma\u00e7\u00e3o dos atributos e o caderno abaixo focar\u00e1 apenas nas tarefas de classifica\u00e7\u00e3o e seus detalhes.<\/b><\/b1>\n\n<p><b>O primeiro passo \u00e9 importar as bibliotecas que ser\u00e3o utilizadas, abaixo est\u00e3o as principais e para que elas servem. Alguns outros m\u00f3dulos ser\u00e3o chamados depois, na c\u00e9lula em que forem usados, para ficar claro que estamos usando um m\u00f3dulo al\u00ed.<\/b>","3ea1981a":"<b>Sempre ao usar aleatoriedade nos seus c\u00f3digos, guarde a semente usada para aleatorizar ou os seus resultados n\u00e3o ser\u00e3o reprodut\u00edveis e compara\u00e7\u00f5es entre execu\u00e7\u00f5es poder\u00e3o ser in\u00fateis<\/b>","351cc89c":"<b>Uma forma de avaliar o nosso modelo \u00e9 comparando o valor previsto com o valor conhecido (salvo na vari\u00e1vel y_test). A partir dessa compara\u00e7\u00e3o, construiremos a matriz de confus\u00e3o, de onde podemos tirar a acur\u00e1cia, precis\u00e3o, revoca\u00e7\u00e3o etc. Para isso, importaremos mais uma biblioteca [sklearn.confusion_matrix](http:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html):<\/b>","884b55e9":"<b>Nesse notebook iremos comparar os resultados de 3 classificadores: a \u00e1rvore de decis\u00e3o, o random forest e o SVM.\n\nCome\u00e7aremos importando a \u00e1rvore de decis\u00e3o [(sklearn.tree)](http:\/\/scikit-learn.org\/stable\/modules\/tree.html) e a visualiza\u00e7\u00e3o da \u00e1rvore ser\u00e1 feita com o graphviz [(sklearn.export_graphviz)](http:\/\/scikit-learn.org\/stable\/modules\/tree.html). \n\nUtilize a c\u00e9lula abaixo para visualizar a \u00e1rvore constru\u00edda pelo seu classificador. Experimente variar os par\u00e2metros do classificador e observe o efeito resultante na \u00e1rvore:\n\n* Nenhum par\u00e2metro\n* Ajuste o tamanho m\u00e1ximo da \u00e1rvore para 3:\n        tree.DecisionTreeClassifier(max_depth=3)\n* Ajuste a quantidade m\u00ednima de elementos nas folhas para 4:\n        tree.DecisionTreeClassifier(min_samples_leaf=4)\n* Altere o RANDOM_STATE  para None e observe que a \u00e1rvore gerada poder\u00e1 variar mesmo que todo o resto permane\u00e7a constante<\/b>","1d56e54b":"<b>Finalmente, usando a semente aleat\u00f3ria guardada na vari\u00e1vel \"RANDOM_STATE\" e o m\u00f3dulo train_test_split importado do sklearn, podemos separar nossa base em grupos para o treino e o teste. Observem como a lista de vari\u00e1veis escrita anteriormente pode ser passada para o dataframe como um \"filtro\" de quais colunas queremos dele.<\/b>","2f75a679":"<b>Podemos plotar uma matriz mais interessante com a fun\u00e7\u00e3o abaixo usando o matplotlib.pyplot e a biblioteca itertools. Essa fun\u00e7\u00e3o utiliza muito da biblioteca matplotlib e o objetivo n\u00e3o \u00e9 entend\u00ea-la, apenas us\u00e1-la para visualiza\u00e7\u00e3o no momento. O c\u00f3digo foi disponibilizado originalmente na documenta\u00e7\u00e3o da matriz de confus\u00e3o no sklearn (link na c\u00e9lula acima).<\/b>","323bfdb9":"<b>A matriz de confus\u00e3o mostrada acima pode ser usada para constru\u00e7\u00e3o da precis\u00e3o e da revoca\u00e7\u00e3o de cada classe: uma explica\u00e7\u00e3o detalhada desses c\u00e1lculos \u00e9 dada na [wikipedia](https:\/\/pt.wikipedia.org\/wiki\/Precis%C3%A3o_e_revoca%C3%A7%C3%A3o)<\/b>","52776c51":"<b>Percebam que o pandas interpretou a primeira coluna como uma vari\u00e1vel da base. Uma pessoa desatenta poderia ter usado essa coluna como vari\u00e1vel do modelo e correr um s\u00e9rio risco de overfitting. Por isso, um bom h\u00e1bito \u00e9 explicitar, em texto, quais os nomes das vari\u00e1veis que voc\u00ea vai querer usar e qual o nome da sua vari\u00e1vel objetivo. Dessa forma, fica muito mais f\u00e1cil rotular os gr\u00e1ficos posteriormente com os nomes das vari\u00e1veis, assim como garante que ao escrever os nomes das duas vari\u00e1veis, voc\u00ea vai pensar naquilo que est\u00e1 incluindo no modelo.<\/b>","cc43eb77":"<b>Ap\u00f3s treinado o objeto \"dec_clf\" que \u00e9 o nosso classificador por \u00e1rvore de decis\u00e3o, prevemos o valor das vari\u00e1veis de teste:<\/b>"}}