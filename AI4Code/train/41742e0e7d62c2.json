{"cell_type":{"2ba12048":"code","748dc3cc":"code","d439a727":"code","a04baa54":"code","8bad09b6":"code","c565c5af":"code","db662d13":"code","af640c97":"code","67a7334a":"code","7a67caf7":"code","0192133a":"code","58ac6764":"code","2df43b57":"code","22e7b159":"code","215fe4d9":"code","d682a7e7":"code","d9b194ee":"code","0ff5901d":"code","3bfe4c99":"code","633b38d6":"code","cba671da":"code","81fe6e0c":"code","6f76304a":"code","61d774ab":"code","594a0f0d":"code","673932a0":"code","f2a750fb":"code","c8329f8c":"code","839ec2fd":"code","969439ae":"code","ef5c955c":"code","9f36d73d":"code","3b50619d":"code","736c7691":"markdown","7acde315":"markdown","b40f1a46":"markdown","ad48662b":"markdown","480345fc":"markdown","53573e37":"markdown","0444caef":"markdown","67c70646":"markdown","9eb7e5e0":"markdown"},"source":{"2ba12048":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","748dc3cc":"import pandas as pd\nsample_submission = pd.read_csv(\"\/kaggle\/input\/covid19-local-us-ca-forecasting-week-1\/ca_submission.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/covid19-local-us-ca-forecasting-week-1\/ca_test.csv\")\ntrain = pd.read_csv(\"\/kaggle\/input\/covid19-local-us-ca-forecasting-week-1\/ca_train.csv\")","d439a727":"len(train)\n","a04baa54":"sample_submission.head()","8bad09b6":"test.head()","c565c5af":"train.tail()","db662d13":"#make a heatmap\n\nimport folium\nfrom folium import Choropleth, Marker\nfrom folium.plugins import HeatMap, MarkerCluster\nm = folium.Map(location=[37, -115], zoom_start=6) \ndef embed_map(m, file_name):\n    from IPython.display import IFrame\n    m.save(file_name)\n    return IFrame(file_name, width='100%', height='750px')\n\n#merge test and training data\nFull_data = pd.merge(test, train, on=['Lat','Long','Date'])\n\n# Add a heatmap to the base map\nHeatMap(data=Full_data[['Lat', 'Long']], radius=11).add_to(m)\n\n# Show the map\nembed_map(m, \"q_1.html\")","af640c97":"#rename therefor the data columns\ntrain.rename(columns={'Province\/State':'Province'}, inplace=True)\ntrain.rename(columns={'Country\/Region':'Country'}, inplace=True)\ntrain.rename(columns={'ConfirmedCases':'Confirmed'}, inplace=True)","67a7334a":"#and we do the same for test set\ntest.rename(columns={'Province\/State':'Province'}, inplace=True)\ntest.rename(columns={'Country\/Region':'Country'}, inplace=True)","7a67caf7":"from sklearn.preprocessing import LabelEncoder\n# creating initial dataframe\nbridge_types = ('Lat', 'Date', 'Province', 'Country', 'Long', 'Confirmed',\n       'ForecastId', 'Id')\ncountries = pd.DataFrame(train, columns=['Country'])\n# creating instance of labelencoder\nlabelencoder = LabelEncoder()\n# Assigning numerical values and storing in another column\ntrain['Countries'] = labelencoder.fit_transform(train['Country'])\n\n#do the same for test set\ntest['Countries'] = labelencoder.fit_transform(test['Country'])\n\n#check label encoding \ntrain['Countries'].head()\n","0192133a":"train['Date']= pd.to_datetime(train['Date']) \ntest['Date']= pd.to_datetime(test['Date']) ","58ac6764":"train = train.set_index(['Date'])\ntest = test.set_index(['Date'])","2df43b57":"def create_time_features(df):\n    \"\"\"\n    Creates time series features from datetime index\n    \"\"\"\n    df['date'] = df.index\n    df['hour'] = df['date'].dt.hour\n    df['dayofweek'] = df['date'].dt.dayofweek\n    df['quarter'] = df['date'].dt.quarter\n    df['month'] = df['date'].dt.month\n    df['year'] = df['date'].dt.year\n    df['dayofyear'] = df['date'].dt.dayofyear\n    df['dayofmonth'] = df['date'].dt.day\n    df['weekofyear'] = df['date'].dt.weekofyear\n    \n    X = df[['hour','dayofweek','quarter','month','year',\n           'dayofyear','dayofmonth','weekofyear']]\n    return X","22e7b159":"create_time_features(train).head()\ncreate_time_features(test).head()","215fe4d9":"train.head()","d682a7e7":"train.drop(\"date\", axis=1, inplace=True)\ntest.drop(\"date\", axis=1, inplace=True)","d9b194ee":"# train.isnull().sum()","0ff5901d":"#drop useless columns for train and test set\ntrain.drop(['Country'], axis=1, inplace=True)\ntrain.drop(['Province'], axis=1, inplace=True)","3bfe4c99":"test.drop(['Country'], axis=1, inplace=True)\ntest.drop(['Province'], axis=1, inplace=True)","633b38d6":"from sklearn.tree import DecisionTreeRegressor  \nregressor = DecisionTreeRegressor(random_state = 0) ","cba671da":"# import xgboost as xgb\n# from xgboost import plot_importance, plot_tree\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\n# reg= xgb.XGBRegressor(n_estimators=1000)","81fe6e0c":"train.head()","6f76304a":"# features that will be used in the model\nx = train[['Lat', 'Long','Countries','dayofweek','month','dayofyear','weekofyear']]\ny1 = train[['Confirmed']]\ny2 = train[['Fatalities']]\nx_test = test[['Lat', 'Long','Countries','dayofweek','month','dayofyear','weekofyear']]","61d774ab":"x.head()","594a0f0d":"#use model on data \nregressor.fit(x,y1)\npredict_1 = regressor.predict(x_test)\npredict_1 = pd.DataFrame(predict_1)\npredict_1.columns = [\"Confirmed_predict\"]","673932a0":"predict_1.head()","f2a750fb":"#use model on data \nregressor.fit(x,y2)\npredict_2 = regressor.predict(x_test)\npredict_2 = pd.DataFrame(predict_2)\npredict_2.columns = [\"Death_prediction\"]\npredict_2.head()","c8329f8c":"# plot = plot_importance(regressor, height=0.9, max_num_features=20)","839ec2fd":"Samle_submission = pd.read_csv(\"\/kaggle\/input\/covid19-local-us-ca-forecasting-week-1\/ca_submission.csv\")\nSamle_submission.columns\nsubmission = Samle_submission[[\"ForecastId\"]]","969439ae":"Final_submission = pd.concat([predict_1,predict_2,submission],axis=1)\nFinal_submission.head()","ef5c955c":"Final_submission.columns = ['ConfirmedCases', 'Fatalities', 'ForecastId']\nFinal_submission = Final_submission[['ForecastId','ConfirmedCases', 'Fatalities']]\n\nFinal_submission[\"ConfirmedCases\"] = Final_submission[\"ConfirmedCases\"].astype(int)\nFinal_submission[\"Fatalities\"] = Final_submission[\"Fatalities\"].astype(int)","9f36d73d":"Final_submission.head()","3b50619d":"Final_submission.to_csv(\"submission.csv\",index=False)\nprint('Model ready for submission!')","736c7691":"## Label encoding","7acde315":"### Heatmap over California which will give a better picture as following weeks progress ","b40f1a46":"# Submission","ad48662b":"## Handling dates","480345fc":"# Check data","53573e37":"# Importing data","0444caef":"# Data cleaning","67c70646":"## Dropping useless features","9eb7e5e0":"# Model "}}