{"cell_type":{"50f3d7e6":"code","6274ad76":"code","a2d6ed9e":"code","fa389185":"code","5f57f6c2":"code","596d2a21":"code","ac62f52c":"code","d283dd85":"code","ccb8a66b":"code","8192fa34":"code","1e22b784":"code","570dc774":"code","e177da4e":"code","0166a5da":"code","201cb0a9":"code","3da8aaeb":"code","85638082":"code","ac1404e8":"markdown","1215bf07":"markdown","1476aa33":"markdown","9daaf425":"markdown","74c5a35e":"markdown"},"source":{"50f3d7e6":"import pandas as pd \nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt \nfrom imblearn.over_sampling import SMOTE  #over Sampling\nfrom imblearn.under_sampling import NearMiss  #Under sampling\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.layers import Conv1D, MaxPool1D\nfrom tensorflow.keras.optimizers import Adam\nimport seaborn as sns\nfrom imblearn.under_sampling import NearMiss\nfrom sklearn.preprocessing import StandardScaler\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\n","6274ad76":"credit_df = pd.read_csv('..\/input\/credit-card-fraud-detection\/creditcard.csv')\n#credit_df.shape (284807, 31)\ncredit_df.head()","a2d6ed9e":"\nfeature_df=credit_df.drop('Class', axis=1)\ntarget_df = credit_df['Class']\n#feature_df.shape, target_df.shape   ((284807, 30), (284807,))","fa389185":"\nundersample = NearMiss(version=3, n_neighbors_ver3=3)\n\n#undersample=CondensedNearestNeighbour(n_neighbors=1)\nx_under, y_under=undersample.fit_resample(feature_df, target_df)\n\n","5f57f6c2":"#Before  counts \nsns.countplot(target_df) ; \n","596d2a21":"sns.countplot(y_under)","ac62f52c":"\n\ndef split_transform(x, y):\n    x_train,x_test, y_train, y_test=train_test_split(x, y, test_size=0.3, random_state=0,stratify=y)\n    #x_train1,x_test1, y_train1, y_test1=train_test_split(x_smote, y_smote, test_size=0.3, random_state=0,stratify=y_smote)\n    scaler=StandardScaler()\n\n    x_train=scaler.fit_transform(x_train) \n    x_test = scaler.fit_transform(x_test)\n\n    #x_train=x_train.to_numpy()\n    #x_test=x_test.to_numpy()\n    #adding dummay dimention to satisify CNN 3 dimentional requirement.\n    x_train=x_train.reshape(x_train.shape[0],x_train.shape[1], 1)\n    x_test=x_test.reshape(x_test.shape[0],x_test.shape[1],1)\n    return x_train, x_test, y_train, y_test","d283dd85":"def buildandTrainCNN(x_train, x_test, y_train, y_test):\n    epochs=20\n\n    # Layer #1\n    model=Sequential()\n    model.add(Conv1D(32,2,activation='relu',input_shape=x_train[0].shape))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.2))\n\n    #  Layer #2\n    model.add(Conv1D(64,2,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n\n    model.add(Flatten())\n    model.add(Dense(64, activation=\"relu\"))\n    model.add(Dropout(0.5))\n\n    model.add(Dense(1, activation=\"sigmoid\"))\n\n#    model.summary()\n    model.compile(optimizer=Adam(learning_rate=0.0001),loss='binary_crossentropy', metrics=[\"accuracy\"])\n    history=model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test), verbose=1)\n    return history","ccb8a66b":"def plot_historycuve(history, epchs, loss_accu, val_loss_accu):\n    epoch_range=range(1,epchs+1)\n    plt.plot(epoch_range, history.history[loss_accu])\n    plt.plot(epoch_range, history.history[val_loss_accu])\n    plt.title('Model '+ loss_accu)\n    plt.xlabel(loss_accu)\n    plt.ylabel(\"Epochs\")\n    plt.legend(['Train', 'Test'], loc=10)\n    plt.show()\n\n\n\n","8192fa34":"x_tr,x_te,y_tr,y_te=split_transform(x_under, y_under)\n","1e22b784":"hist=buildandTrainCNN(x_te,x_tr,y_te,y_tr)\n\n","570dc774":"plot_historycuve(hist, 20, 'accuracy', 'val_accuracy')","e177da4e":"plot_historycuve(hist, 20, 'loss', 'val_loss')","0166a5da":"sm=SMOTE(sampling_strategy='auto',k_neighbors=5,random_state=100)\nx_smote, y_smote=sm.fit_resample(feature_df, target_df)\nx_tr,x_te,y_tr,y_te=split_transform(x_smote, y_smote)\nsns.countplot(y_smote)","201cb0a9":"x_tr,x_te,y_tr,y_te=split_transform(x_smote, y_smote)\nhist=buildandTrainCNN(x_te,x_tr,y_te,y_tr)","3da8aaeb":"plot_historycuve(hist, 20, 'accuracy', 'val_accuracy')","85638082":"plot_historycuve(hist, 20, 'loss', 'val_loss')","ac1404e8":"Reading the Creadit card tranactins File ","1215bf07":"***Check the correlation between features***","1476aa33":"# SOMTE implimentation for the same data set and train CNN Model.","9daaf425":"not sure about every model works in the same way, But in my experiment, oversampling results more accurate than under sampling. ","74c5a35e":"'''cor_matrix = feature_df.corr().abs()  # We don't care +ve or -Ve correlation.\n\n#print(cor_matrix)\n\nupper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(np.bool))\n#print(upper_tri) \nto_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.95)] \n#print(); print(to_drop)\n\ndf1 = feature_df.drop(feature_df.columns[to_drop], axis=1) \nprint(df1.shape) \nprint(df1.head()) \n'''"}}