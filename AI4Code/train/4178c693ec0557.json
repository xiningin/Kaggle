{"cell_type":{"37f3f11e":"code","02d02e66":"code","b8b243af":"code","0590a2e0":"code","1e5931cf":"code","63badb7d":"code","5475359f":"code","e36f1474":"code","79582e5e":"code","5919fca0":"code","9571d5b8":"code","39df5cd3":"code","1b350b2d":"code","4175eecf":"code","7d2ee389":"code","b83b4b56":"code","beb2b1db":"code","004dee59":"code","7082f36a":"code","e2784a03":"code","6867d693":"code","837b11af":"code","3c4d08d1":"code","ba6899eb":"markdown","75e71bf9":"markdown","c9b59ef8":"markdown","83c9aa19":"markdown","16395a0e":"markdown","6e7028b1":"markdown","647fa1f5":"markdown","b4efec3c":"markdown","d7975e6b":"markdown","1d4981de":"markdown","3a2020b5":"markdown","0317fca4":"markdown"},"source":{"37f3f11e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.utils.data\n\nfrom sklearn.preprocessing import MinMaxScaler\n\ntorch.manual_seed(2)\nnp.random.seed(2)","02d02e66":"df = pd.read_csv(\"..\/input\/electric-motor-temperature\/pmsm_temperature_data.csv\")","b8b243af":"df.head()","0590a2e0":"col_list = df.columns.tolist()\nprofile_id = ['profile_id']\ntarget_list = ['pm', 'torque', 'stator_yoke', 'stator_tooth', 'stator_winding']\nfeature_list = [col for col in col_list if col not in target_list and col not in profile_id]","1e5931cf":"col_list = df.columns.tolist()\nprofile_id = ['profile_id']\ntarget_list = ['pm', 'torque', 'stator_yoke', 'stator_tooth', 'stator_winding']\nfeature_list = [col for col in col_list if col not in target_list and col not in profile_id]","63badb7d":"df.info()","5475359f":"df['profile_id'] = df.profile_id.astype('category', inplace=True)\ndf.profile_id.unique()","e36f1474":"df_dict = {}\nfor id_ in df.profile_id.unique():\n    df_dict[id_] = df[df['profile_id']==id_].reset_index(drop = True)","79582e5e":"def build_sequences(features_df, target_df, sequence_length = 10):\n    \"\"\"Builds sequences from data and converts them into pytorch tensors\n        sequence_length - represents the number of samples to be considered in a sequence\n    \"\"\"\n    data_ = []\n    target_ = []\n    \n    for i in range(int(features_df.shape[0]\/sequence_length)):\n        \n        data = torch.from_numpy(features_df.iloc[i:i+sequence_length].values)\n        target = torch.from_numpy(target_df.iloc[i+sequence_length+1].values)\n        \n        data_.append(data)\n        target_.append(target)\n        \n    data = torch.stack(data_)\n    target = torch.stack(target_)\n    \n    return data, target","5919fca0":"prof_ids = list(df_dict.keys())\ndf_dict.keys()","9571d5b8":"# Randomly selecting\n# idx = np.random.randint(len(list(df_dict.keys())))\n\n# prof_id = prof_ids[idx]\n# print('Selected profile -',prof_id)\n\n### OR ###\n# Manual Selection\nprof_id = 6\n\ncurr_df = df_dict[prof_id]\n\ncurr_df = curr_df.drop('profile_id', axis = 1)\ncolumns = curr_df.columns.tolist()","39df5cd3":"scaler = MinMaxScaler()\n\ncurr_df = pd.DataFrame(scaler.fit_transform(curr_df), columns= columns)\ncurr_df.head()","1b350b2d":"sequence_length = 3\n\nfeatures = curr_df[feature_list]\ntarget = curr_df[target_list][['pm']]\n\ndata, target = build_sequences(features, target, sequence_length=sequence_length)","4175eecf":"# Test size the percentage of data to be used for testing\ntest_size = 0.05\n\nindices = torch.randperm(data.shape[0])\n\ntrain_indices = indices[:int(indices.shape[0] * (1-test_size))]\ntest_indices = indices[int(indices.shape[0] * (1-test_size)):]\n\nX_train, y_train = data[train_indices], target[train_indices]\nX_test, y_test = data[test_indices], target[test_indices]","7d2ee389":"class PMSMDataset(torch.utils.data.dataset.Dataset):\n    \"\"\"Dataset with Rotor Temperature as Target\"\"\"\n    def __init__(self, data, target):\n        \n        self.data = data\n        self.target = target\n        \n    def __len__(self):\n        return self.data.shape[0]\n    \n    def __getitem__(self, idx):\n        return self.data[idx].unsqueeze(0), self.target[idx]","b83b4b56":"batch_size = 10\n\npm_train_dataset = PMSMDataset(X_train, y_train)\npm_train_loader = torch.utils.data.dataloader.DataLoader(pm_train_dataset, batch_size= batch_size)\n\npm_test_dataset = PMSMDataset(X_test, y_test)\npm_test_loader = torch.utils.data.dataloader.DataLoader(pm_test_dataset, batch_size= 1)","beb2b1db":"class Network(nn.Module):\n    def __init__(self, sequence_length, n_features):\n        super(Network, self).__init__()\n        \n        \n        self.conv1 = nn.Conv1d(1, 3, kernel_size=(sequence_length, n_features))\n        \n        self.lin_in_size = self.conv1.out_channels * int(((sequence_length - (self.conv1.kernel_size[0]-1) -1)\/self.conv1.stride[0] +1))\n        \n#         print(self.lin_in_size)\n        \n        self.fc1 = nn.Linear(self.lin_in_size,30)\n        self.fc2 = nn.Linear(30, 1)\n        \n    def forward(self, x):\n        \n        x = F.relu(self.conv1(x))\n        x = x.view(-1, self.lin_in_size)\n        \n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x","004dee59":"n_features = X_train.shape[-1]\n\nnet = Network(sequence_length, n_features).double()\nnet","7082f36a":"lr = 0.001\n\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(net.parameters(), lr=lr)","e2784a03":"training_losses = []\nfor epoch in range(50):\n    running_loss = 0.0\n    batch_losses = []\n    for i, (data, target) in enumerate(pm_train_loader):\n\n        optimizer.zero_grad()\n\n        out = net(data)\n\n        loss = criterion(out, target)\n        batch_losses.append(loss.item())\n\n        loss.backward()\n        optimizer.step()            \n    training_losses.append(np.mean(batch_losses))\n    print(\"Epoch {}, loss {:.6f}\".format(epoch+1, training_losses[-1]))","6867d693":"plt.plot(training_losses)","837b11af":"losses = []\nbatch_losses = []\ntargets = []\noutputs = []\nwith torch.no_grad():\n    for i, (data, target) in enumerate(pm_test_loader):\n        out = net(data)\n        loss = criterion(out, target)\n#         print('Target : {:.4f}, Predicted Output : {:.4f}'.format(target.item(), out.item()))\n        \n        targets.append(target.item())\n        outputs.append(out.item())\n        \n        batch_losses.append(loss.item())\n    losses.append(np.mean(batch_losses))\nprint(\"Testing loss {:.6f}\".format(losses[-1]))","3c4d08d1":"plt.figure(figsize=(13,7))\n# plt.scatter(np.arange(len(outputs)),outputs, c = 'b', s = 15, marker='*', label = 'predicted')\nplt.plot(np.arange(len(outputs)),outputs, alpha = 0.8, marker = '.',label = 'predicted' )\nplt.scatter(np.arange(len(targets)),targets, c = 'r', s = 15, label = 'true')\nplt.legend(loc='best')","ba6899eb":"###### Slecting a measurement profile to prepare the data","75e71bf9":"##### As explained in the description the profile_id column in the data set corresponds to different measurement sessions. The most interesting target features given in description are rotor temperature('pm), stator temperatures('stator_*) and torque. \n##### All the other features are considered to be inputs features","c9b59ef8":"##### Dividing the generated sequences into training and testing set","83c9aa19":"##### Note that the same sequence length used to generate the data should be used to create the network","16395a0e":"##### The network ","6e7028b1":"##### A Dataset class is needed for the data inorder to use the dataloader of Pytorch","647fa1f5":"Dividing the data based on the profile id","b4efec3c":"### Since all the variables\/features are measured over time and are time dependant. The later analysis is done assuming the data to be time series data.\n\n#### For this reason, the data is split into number of time sequences. The target value for a given sequence will be the value which is just after a given sequence.","d7975e6b":"### Testing","1d4981de":"### Sequence length has to be selected prior to the model initialization\n\n##### As the sampling is done at 2 Hz, the sequence size can be >= 2. But, keeping in view the importance of speed of operation as the values are needed for other operations or control, it should be as small as possible to reduce the delay.\n\n##### Also, another point to be noted here is, if the sequence length is higher the prediction error is less. So there must be a trade off between the required error rate and speed (in this case the initial prediction). \n\n##### The delay in responce will be only at the beginning and the later predictions will not have the delay if real time operation is considered.","3a2020b5":"##### As profile id just indicates which measurement session the data belongs to, it can be treated as categorical variable, and also to make select data that is relevant to the session","0317fca4":"### Training"}}