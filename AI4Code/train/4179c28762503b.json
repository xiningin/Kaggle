{"cell_type":{"61748a6e":"code","7098d77d":"code","e1b84fbb":"code","234e945c":"code","b860778a":"code","f7b3e204":"code","5be5beec":"code","ba799b9d":"code","884af42c":"code","e081dd07":"code","3f9931dc":"code","848a46ef":"code","a35ad5ff":"code","47e266bd":"code","4b4ccc92":"code","633ef89b":"code","663cc7da":"code","b28a35e4":"code","af3870ae":"code","5fcb72d6":"code","e1d4ab85":"code","4f1fddc6":"code","b6d76291":"code","8a2834d7":"code","7b94696f":"code","7f226459":"code","6efdfe2d":"code","891ae38f":"code","2d42a7f8":"code","7a51388a":"code","bcbb20b6":"code","6d01d453":"code","8cdae8b6":"code","08a936ff":"code","19c2a7bb":"code","0587cb40":"code","a6580dee":"code","4cd540f2":"code","34cce331":"code","97cf49fc":"code","523d1e02":"code","5163adfc":"code","262a0e27":"code","e47bbaf0":"code","5e40f414":"code","21a76378":"code","ebb115e9":"code","c0ced5c8":"code","655fd913":"code","582865c3":"code","68c8ae37":"code","240fa31e":"code","7156316b":"code","fad07c6b":"code","bdef28ce":"markdown","fb664af8":"markdown","2f27a84d":"markdown","0bc4b73a":"markdown","bb7a9fda":"markdown","fa27b057":"markdown","37481395":"markdown","47fdf0b1":"markdown","cf680738":"markdown","e7d9c4aa":"markdown","aa63c5e0":"markdown","bd3e94c6":"markdown","db00a810":"markdown","b8a8f919":"markdown","24ce9232":"markdown","46066781":"markdown","dbb0d81b":"markdown","90ec5379":"markdown","18ecefb0":"markdown","acf584ef":"markdown","e5e16114":"markdown","b337a57a":"markdown","5c0a0455":"markdown","d490c939":"markdown","a2f3f201":"markdown","9a5f6fa0":"markdown","0794d1e8":"markdown","40a7899e":"markdown","45a47869":"markdown","8239e024":"markdown","c9ff6689":"markdown","5c0e2e03":"markdown","94bbaae9":"markdown","f1cbd469":"markdown","ff4695e4":"markdown","0f6f0a21":"markdown","430cf5e9":"markdown"},"source":{"61748a6e":"import pydicom\nimport os\nimport glob\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import cm\nfrom matplotlib import pyplot as plt\nimport cv2\nimport seaborn as sns\nfrom tqdm import tqdm\n\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras import backend as K\n\nimport plotly.graph_objs as go\nimport plotly.plotly as py\nimport plotly.offline as pyo\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly_express as px\ninit_notebook_mode(connected=True)\n\nimport tensorflow as tf\n\nfrom tqdm import tqdm_notebook\n\n# ['siim-acr-pneumothorax-segmentation-data', 'siim-acr-pneumothorax-segmentation']\n\nimport sys\nsys.path.insert(0, '..\/input\/siim-acr-pneumothorax-segmentation\/')\n\nfrom mask_functions import rle2mask\nimport gc","7098d77d":"def show_dcm_info(dataset):\n    print(\"Filename.........:\", file_path)\n    print(\"Storage type.....:\", dataset.SOPClassUID)\n    print()\n\n    pat_name = dataset.PatientName\n    display_name = pat_name.family_name + \", \" + pat_name.given_name\n    print(\"Patient's name......:\", display_name)\n    print(\"Patient id..........:\", dataset.PatientID)\n    print(\"Patient's Age.......:\", dataset.PatientAge)\n    print(\"Patient's Sex.......:\", dataset.PatientSex)\n    print(\"Modality............:\", dataset.Modality)\n    print(\"Body Part Examined..:\", dataset.BodyPartExamined)\n    print(\"View Position.......:\", dataset.ViewPosition)\n    \n    if 'PixelData' in dataset:\n        rows = int(dataset.Rows)\n        cols = int(dataset.Columns)\n        print(\"Image size.......: {rows:d} x {cols:d}, {size:d} bytes\".format(\n            rows=rows, cols=cols, size=len(dataset.PixelData)))\n        if 'PixelSpacing' in dataset:\n            print(\"Pixel spacing....:\", dataset.PixelSpacing)\n            \ndef plot_pixel_array(dataset, figsize=(10,10)):\n    plt.figure(figsize=figsize)\n    plt.imshow(dataset.pixel_array, cmap=plt.cm.bone)\n    plt.show()","e1b84fbb":"samplesize = 5000\ntrain_glob = '..\/input\/siim-acr-pneumothorax-segmentation-data\/pneumothorax\/dicom-images-train\/*\/*\/*.dcm'\ntest_glob = '..\/input\/siim-acr-pneumothorax-segmentation-data\/pneumothorax\/dicom-images-test\/*\/*\/*.dcm'\ntrain_fns = sorted(glob.glob(train_glob))[:samplesize]\ntest_fns = sorted(glob.glob(test_glob))[:samplesize]\ndf_full = pd.read_csv('..\/input\/siim-acr-pneumothorax-segmentation-data\/pneumothorax\/train-rle.csv', index_col='ImageId')","234e945c":"im_height = 1024\nim_width = 1024\nim_chan = 1\n# Get train images and masks\n# X_train = np.zeros((len(train_fns), im_height, im_width, im_chan), dtype=np.uint8)\nY_train = np.zeros((len(train_fns), im_height, im_width, 1), dtype=np.int16)\nprint('Getting train images and masks ... ')\nsys.stdout.flush()\nfor n, _id in tqdm_notebook(enumerate(train_fns), total=len(train_fns)):\n    dataset = pydicom.read_file(_id)\n#     X_train[n] = np.expand_dims(dataset.pixel_array, axis=2)\n    try:\n        if '-1' in df_full.loc[_id.split('\/')[-1][:-4],' EncodedPixels']:\n            Y_train[n] = np.zeros((1024, 1024, 1))\n        else:\n            if type(df_full.loc[_id.split('\/')[-1][:-4],' EncodedPixels']) == str:\n                x = np.expand_dims(rle2mask(df_full.loc[_id.split('\/')[-1][:-4],' EncodedPixels'], 1024, 1024), axis=2)\n                Y_train[n] = x\n            else:\n                Y_train[n] = np.zeros((1024, 1024, 1))\n                for x in df_full.loc[_id.split('\/')[-1][:-4],' EncodedPixels']:\n                    Y_train[n] =  np.maximum(Y_train[n], np.expand_dims(rle2mask(x, 1024, 1024), axis=2))\n    except KeyError:\n        print(f\"Key {_id.split('\/')[-1][:-4]} without mask, assuming healthy patient.\")\n        Y_train[n] = np.zeros((1024, 1024, 1)) # Assume missing masks are empty masks.\n\nprint('Done!')","b860778a":"from skimage.transform import rescale\n\nimage_setori = []\nfor i in range(samplesize):\n    count = Y_train[i].sum()\n    if count > 0:\n        image_setori.append(rescale(Y_train[i],1.0\/4.0)) ","f7b3e204":"image_set = np.asarray(image_setori)\nsamplesize = len(image_set)\nimage_set = np.squeeze(image_set)\nimage_set = np.reshape(image_set, ((samplesize, image_set.shape[1] * image_set.shape[2])))","5be5beec":"image_set = image_set * 128\n# for i in range(len(image_set)):\n#     print(image_set[i].max())","ba799b9d":"import sys\n\n# These are the usual ipython objects, including this one you are creating\nipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n\n# Get a sorted list of the objects and their sizes\nsorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)","884af42c":"del Y_train\ngc.collect()","e081dd07":"from sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans","3f9931dc":"pca = PCA(n_components=50).fit(image_set)\n#Plotting the Cumulative Summation of the Explained Variance\ny=np.cumsum(pca.explained_variance_ratio_)\ndata = [go.Scatter(y=y)]\nlayout = {'title': 'PCA Explained Variance'}\niplot({'data':data,'layout':layout})","848a46ef":"pca = PCA(n_components=20)\nimage_PCA = pca.fit_transform(image_set)","a35ad5ff":"trace1 = go.Scatter(y=pca.explained_variance_ratio_)\ntrace2 = go.Scatter(y=np.cumsum(pca.explained_variance_ratio_))\nfig = tools.make_subplots(rows=1,cols=2,subplot_titles=('Explained Variance','Cumulative Explained Variance'))\nfig.append_trace(trace1,1,1)\nfig.append_trace(trace2,1,2)\nfig['layout'].update(height=600, width=1200, title=\"Explained Variance Ratios\",showlegend=False)\niplot(fig)","47e266bd":"Nc = range(1,20)\nkmeans = [KMeans(i) for i in Nc]\nscore = [kmeans[i].fit(image_PCA).score(image_PCA) for i in range(len(kmeans))]","4b4ccc92":"data = [go.Scatter(y=score,x=list(Nc))]\nlayout = {'title':'Elbow Curve for KMeans'}\niplot({'data':data,'layout':layout})","633ef89b":"n_clusters=12\nkmeans = KMeans(n_clusters=n_clusters, random_state=42)\nimage_kmeans = kmeans.fit_predict(image_PCA)","663cc7da":"image_kmeans.shape","b28a35e4":"image_clusters = np.zeros((n_clusters, image_set.shape[1]), dtype=np.float64)\nclustercounts = np.zeros(n_clusters,dtype=np.int)\nfor i in range(samplesize):\n    for j in range(n_clusters):\n        if image_kmeans[i] == j:\n            image_clusters[j] += image_set[i]\n            clustercounts[j] += 1","af3870ae":"print(image_clusters.shape)\nprint(clustercounts)\nprint(clustercounts.sum())","5fcb72d6":"for j in range(n_clusters):\n    image_clusters[j] = image_clusters[j] \/ clustercounts[j]\nimage_clusters = np.reshape(image_clusters, ((n_clusters, 256, 256)))","e1d4ab85":"image_clusters.shape","4f1fddc6":"image_clusters_sortingval = [np.sum(image_clusters[i,:80,:80]) for i in range(n_clusters)]\ncluster_ordered = range(n_clusters)\ncluster_ordered = [x for _,x in sorted(zip(image_clusters_sortingval,cluster_ordered))]","b6d76291":"fig = plt.figure(figsize=(15,5))\nfig.subplots_adjust(hspace=0.05, wspace=0.05)\nj = 1\nfor i in cluster_ordered:\n    plt.subplot(2,6,j)\n    plt.imshow(image_clusters[i].T, cmap=plt.cm.bone)\n    plt.title('Cluster '+str(i)+'. Num Samples: '+str(clustercounts[i]))\n    j += 1\nplt.tight_layout()\nplt.suptitle(\"Clusters of Pneumothorax Diagnosis based on simple PCA & K-Means\",fontsize=16,y=1.05)","8a2834d7":"from sklearn.manifold import TSNE\nimageTSNE = TSNE(n_components=2).fit_transform(image_PCA)","7b94696f":"imageTSNEdf = pd.concat([pd.DataFrame(imageTSNE),pd.DataFrame(image_kmeans)],axis=1)\nimageTSNEdf.columns = ['x1','x2','cluster']\npx.scatter(imageTSNEdf,x='x1',y='x2',color='cluster',color_continuous_scale=px.colors.qualitative.Plotly,title=\"TSNE visualization of Image Clusters\",width=800,height=500)","7f226459":"n_clusters=6\nkmeans = KMeans(n_clusters=n_clusters, random_state=42)\nimage_kmeans = kmeans.fit_predict(image_PCA)\nimage_clusters = np.zeros((n_clusters, image_set.shape[1]), dtype=np.float64)\nclustercounts = np.zeros(n_clusters,dtype=np.int)\nfor i in range(samplesize):\n    for j in range(n_clusters):\n        if image_kmeans[i] == j:\n            image_clusters[j] += image_set[i]\n            clustercounts[j] += 1\nfor j in range(n_clusters):\n    image_clusters[j] = image_clusters[j] \/ clustercounts[j]\nimage_clusters = np.reshape(image_clusters, ((n_clusters, 256, 256)))\nimage_clusters_sortingval = [np.sum(image_clusters[i,:80,:80]) for i in range(n_clusters)]\ncluster_ordered = range(n_clusters)\ncluster_ordered = [x for _,x in sorted(zip(image_clusters_sortingval,cluster_ordered))]\nfig = plt.figure(figsize=(15,5))\nfig.subplots_adjust(hspace=0.05, wspace=0.05)\nj = 1\nfor i in cluster_ordered:\n    plt.subplot(1,6,j)\n    plt.imshow(image_clusters[i].T, cmap=plt.cm.bone)\n    plt.title('Cluster '+str(i)+'. Num Samples: '+str(clustercounts[i]))\n    j += 1\nplt.tight_layout()\nplt.suptitle(\"Clusters of Pneumothorax Diagnosis based on simple PCA & K-Means\",)","6efdfe2d":"imageTSNEdf = pd.concat([pd.DataFrame(imageTSNE),pd.DataFrame(image_kmeans)],axis=1)\nimageTSNEdf.columns = ['x1','x2','cluster']\npx.scatter(imageTSNEdf,x='x1',y='x2',color='cluster',color_continuous_scale=px.colors.qualitative.Plotly,title=\"TSNE visualization of Image Clusters\",width=800,height=500)","891ae38f":"# Clean-up\ndel image_PCA\ngc.collect()","2d42a7f8":"# import sys\n\n# # These are the usual ipython objects, including this one you are creating\n# ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n\n# # Get a sorted list of the objects and their sizes\n# sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)","7a51388a":"del df_full\ngc.collect()","bcbb20b6":"from keras.layers import Input, Dense\nfrom keras.models import Model\nencoding_dim = 128\nimgsize_flat = 256 * 256\ninput_img = Input(shape=(imgsize_flat,))\nencoded = Dense(encoding_dim,activation='relu')(input_img)\ndecoded = Dense(imgsize_flat,activation='sigmoid')(encoded)\nautoencoder = Model(input_img, decoded)\n\n# Encoder\nencoder = Model(input_img,encoded)\n\n# Decoder\nencoded_input = Input(shape=(encoding_dim,))\ndecoder_layer = autoencoder.layers[-1]\ndecoder = Model(encoded_input, decoder_layer(encoded_input))","6d01d453":"autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\nxtrain = image_set\nautoencoder.fit(xtrain,xtrain,epochs=20,batch_size=256,shuffle=True)","8cdae8b6":"fig = plt.figure(figsize=(15,10))\nfor i in range(5):\n    plt.subplot(2,5,i+1)\n    plt.imshow(xtrain[i].reshape(256,256).T, cmap=plt.cm.bone)\n    autoencoded = autoencoder.predict(xtrain[i:i+1])\n    plt.subplot(2,5,i+6)\n    plt.imshow(autoencoded.reshape(256,256).T, cmap=plt.cm.bone)\nplt.tight_layout()\nplt.suptitle('Comparing original vs AE reconstruction images',fontsize=16,y=1)        ","08a936ff":"from keras.layers import Input, Dense\nfrom keras.models import Model\nencoding_dim = 64\nimgsize_flat = 256 * 256\nlayer1_multiplier = 32\nlayer2_multiplier = 16\n\ninput_img = Input(shape=(imgsize_flat,))\nencoded = Dense(encoding_dim*layer1_multiplier ,activation='relu')(input_img)\nencoded = Dense(encoding_dim*layer2_multiplier,activation='relu')(encoded)\nencodedFinal = Dense(encoding_dim,activation='relu')(encoded)\ndecoded = Dense(encoding_dim*layer2_multiplier,activation='relu')(encodedFinal)\ndecoded = Dense(encoding_dim*layer1_multiplier ,activation='relu')(decoded)\ndecodedFinal = Dense(imgsize_flat,activation='sigmoid')(decoded)\n\nautoencoder = Model(input_img, decodedFinal)\n\n# Encoder\nencoder = Model(input_img,encodedFinal)\n\n# Decoder\n# encoded_input = Input(shape=(encoding_dim,))\n# decoder_layer = autoencoder.layers[-1]\n# decoder = Model(encoded_input, decoder_layer(encoded_input))","19c2a7bb":"autoencoder.summary()","0587cb40":"xtrain = image_set","a6580dee":"autoencoder.compile(optimizer='adam', loss='mean_squared_error')\nautoencoder.fit(xtrain,xtrain,epochs=20,batch_size=64,shuffle=True)","4cd540f2":"fig = plt.figure(figsize=(15,5))\nfor i in range(10):\n    plt.subplot(2,10,i+1)\n    plt.imshow(xtrain[i].reshape(256,256).T, cmap=plt.cm.bone)\n    plt.title('Image ' + str(i))\n    \n    autoencoded = autoencoder.predict(xtrain[i:i+1])\n    plt.subplot(2,10,i+11)\n    plt.imshow(autoencoded.reshape(256,256).T, cmap=plt.cm.bone)\n    plt.title('AE ' + str(i))\nplt.tight_layout()\nplt.suptitle('Comparing original vs AE reconstruction images',fontsize=16,y=1)    ","34cce331":"image = []\nfor i in range(10):\n    image.append(encoder.predict(xtrain[i:i+1]))\nimage = np.array(image)\nimage = np.squeeze(image)\nimagedf = pd.DataFrame(image)\nimagedf","97cf49fc":"fig = plt.figure(figsize=(24,8))\nfor i in range(8):\n    series = imagedf.iloc[:,i]\n    plt.subplot(4,8,i+1)\n    series.hist()\n    plt.title('Dim ' + str(i))\nplt.suptitle('Histogram for each encoding dimension')\nplt.tight_layout()","523d1e02":"imagedf.corr().iloc[:5,:5] #just a sample","5163adfc":"from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\nfrom keras.models import Model\nfrom keras import backend as K\n\ninput_img=Input(shape=(256,256,1))\nx = Conv2D(16,(3,3),activation='relu',padding='same')(input_img)\nx = MaxPooling2D((4,4), padding='same')(x)\nx = Conv2D(4,(3,3), activation='relu',padding='same')(x)\nencoded = MaxPooling2D((4,4), padding='same')(x)\n\nx = Conv2D(4,(3,3),activation='relu',padding='same')(encoded)\nx = UpSampling2D((4,4))(x)\nx = Conv2D(16,(3,3),activation='relu',padding='same')(x)\nx = UpSampling2D((4,4))(x)\ndecoded = Conv2D(1,(3,3),activation='sigmoid',padding='same')(x)\n\nautoencoderCNN=Model(input_img,decoded)\nautoencoderCNN.compile(optimizer='adam',loss='binary_crossentropy')\n\n# Encoder\nencoderCNN = Model(input_img,encoded)\n\n# Decoder\nencoded_inputCNN = Input(shape=(16,16,4,))\ndecoder1 = autoencoderCNN.layers[-1]\ndecoder2 = autoencoderCNN.layers[-2]\ndecoder3 = autoencoderCNN.layers[-3]\ndecoder4 = autoencoderCNN.layers[-4]\ndecoder5 = autoencoderCNN.layers[-5]\n\ndecoderCNN = Model(encoded_inputCNN,decoder1(decoder2(decoder3(decoder4(decoder5(encoded_inputCNN))))))","262a0e27":"autoencoderCNN.layers","e47bbaf0":"autoencoderCNN.summary()","5e40f414":"xtrain = np.reshape(xtrain, (len(xtrain),256,256,1))\nautoencoderCNN.fit(xtrain,xtrain,epochs=20,batch_size=64,shuffle=True)","21a76378":"fig = plt.figure(figsize=(15,10))\nfor i in range(5):\n    plt.subplot(2,5,i+1)\n    plt.imshow(xtrain[i:i+1].reshape(256,256).T, cmap=plt.cm.bone)\n    plt.title('Image ' + str(i))\n    autoencoded = autoencoderCNN.predict(xtrain[i:i+1])\n    plt.subplot(2,5,i+6)\n    plt.imshow(autoencoded.reshape(256,256).T, cmap=plt.cm.bone)\n    plt.title('AE ' + str(i))\nplt.suptitle('Comparing original vs AE reconstruction images (5 images)',fontsize=16,y=1)\nplt.tight_layout()","ebb115e9":"fig = plt.figure(figsize=(15,5))\nfor i in range(11,20):\n    plt.subplot(2,10,i-10)\n    plt.imshow(xtrain[i].reshape(256,256).T, cmap=plt.cm.bone)\n    plt.title('Image ' + str(i))    \n    autoencoded = autoencoderCNN.predict(xtrain[i:i+1])\n    plt.subplot(2,10,i-0)\n    plt.imshow(autoencoded.reshape(256,256).T, cmap=plt.cm.bone)\n    plt.title('AE ' + str(i))\nplt.suptitle('Comparing original vs AE reconstruction images (10 images)',fontsize=16,y=1.03)\nplt.tight_layout()","c0ced5c8":"encoderCNN = Model(input_img,encoded)\nencodedX = []\nfor i in range(len(xtrain)):\n    encodedX.append(encoderCNN.predict(xtrain[i:i+1]))\nencodedX = np.array(encodedX)\nprint(encodedX.shape)\nencodedX = np.squeeze(encodedX)\nprint(encodedX.shape)\nencodeddf = pd.DataFrame(encodedX.reshape(encodedX.shape[0],np.prod(encodedX.shape[1:])))\nencodeddf.head(20)","655fd913":"pca = PCA(n_components=50)\nimage_PCA = pca.fit_transform(encodeddf)\nfig, ax = plt.subplots(1,2,figsize=(10,5))\nax[0].plot(pca.explained_variance_ratio_)\nax[0].title.set_text(\"Explained variance ratio\")\nax[1].plot(np.cumsum(pca.explained_variance_ratio_))\nax[1].title.set_text(\"Cumulative Explained variance ratio\")","582865c3":"pca = PCA(n_components=30)\nimage_PCA = pca.fit_transform(encodeddf)\nNc = range(1,30)\nkmeans = [KMeans(i) for i in Nc]\nscore = [kmeans[i].fit(image_PCA).score(image_PCA) for i in range(len(kmeans))]\nplt.plot(Nc,score)\nplt.xlabel('Number of Clusters')\nplt.ylabel('Score')\nplt.title('Elbow Curve to evaluate number of clusters')\nplt.show()","68c8ae37":"n_clusters=12\nkmeans = KMeans(n_clusters=n_clusters, random_state=42)\nencoding_kmeans = kmeans.fit_predict(image_PCA)","240fa31e":"encoding_clusters = np.zeros((n_clusters, encodeddf.iloc[0,:].shape[0]), dtype=np.float64)\nclustercounts = np.zeros(n_clusters,dtype=np.int)\nfor i in range(len(encoding_kmeans)):\n    for j in range(n_clusters):\n        if encoding_kmeans[i] == j:\n            encoding_clusters[j] += encodeddf.iloc[i,:]\n            clustercounts[j] += 1\nencoding_clustersdf = pd.DataFrame(encoding_clusters)\nfor j in range(n_clusters):\n    encoding_clustersdf[j] = encoding_clustersdf[j] \/ clustercounts[j]","7156316b":"encoding_clustersdf","fad07c6b":"from skimage.filters import gaussian\nfig = plt.figure(figsize=(15,10))\nfor i in range(len(encoding_clustersdf)):\n    decoded = decoderCNN.predict(encoding_clustersdf.iloc[i,:].values.reshape((1,16, 16, 4)))\n    plt.subplot(4,5,i+1)\n    imgtoshow = gaussian(decoded.reshape(256,256).T, sigma=2)\n    plt.imshow(imgtoshow, cmap=plt.cm.bone)\n    plt.title('Cluster '+str(i)+' Size: '+str(clustercounts[i]))\nplt.tight_layout()\nplt.suptitle('Images of Final Clustering Result using Encoded Features as basis of clustering',fontsize=16,y=1.08)\nplt.show()","bdef28ce":"We delete Y_train to save memory","fb664af8":"Review explained variance plot to determine number of PCA components (capped at 50):","2f27a84d":"### Remove the last dimension and flatten the image","0bc4b73a":"### Rescale the image down to save memory","bb7a9fda":"## Check how the original compare with the reconstructed\n","fa27b057":"# Clustering the encoded representations","37481395":"### Finally now we display the clusters of Pneumothorax masks\n\nIn general, we can see that the clusters are based on location (left, right) and also the size of the masks","47fdf0b1":"## The reconstructions above looks pretty good!\nFinally.","cf680738":"We'll use 30 components for now. Now check the numer of clusters","e7d9c4aa":"# C-3 Convolutional Autoencoder","aa63c5e0":"### Normalize the value to be [0 to 1]","bd3e94c6":"### Quickly check what the encoded features look like (hidden)","db00a810":"# A-1 Load training data","b8a8f919":"# C-1 AutoEncoder: Simple AE with fully-connected layer","24ce9232":"We'll use 12 clusters again","46066781":"## Running some diagnostics to check the encoded features\n","dbb0d81b":"The reconstruction pretty much generated black images","90ec5379":"### Let's also do a simplified version with just 6 clusters\n\nInterestingly, there are 4 variations of left-side masks but only 1 variation of right-side marks. The majority is still scattered. Most likely this reflect small spots that is not big enough to belong in the other clusters","18ecefb0":"We'll also check elbow curve for number of clusters for kmeans","acf584ef":"Printing out what the centroid of clusters of encoded features look like (hidden)","e5e16114":"# A-2 Generate diagnostic masking data in image format","b337a57a":"Lets use explained variance ratio to figure out a good PCA n_components","5c0a0455":"Still random noise. As visible for large loss value, the network hasn't learned anything meaningful","d490c939":"# C-2 Deep autoencoder - fully connected\n\ntl;dr Fully-connected deep autoencoder still failed to produce meaningful encoding.","a2f3f201":"We then do a simple step to sort the clustering output based on location. Simply sum the masks on the top left. Print ","9a5f6fa0":"### Convert DCM into numpy array\nIn this step, I will be constructing Y_train from DCM format into numpy array. The starter code was taken from [this](http:\/\/https:\/\/www.kaggle.com\/jesperdramsch\/intro-chest-xray-dicom-viz-u-nets-full-data#data) kernel, with some adjustments: (1) I skipped loading X_train to save memory, since I'm only interested in the shape of the mask, (2) I changed the implementation from the original additive function into taking the maximum (since some points are overlapping.\n> Y_train[n] =  np.maximum(Y_train[n], np.expand_dims(rle2mask(x, 1024, 1024), axis=2))","0794d1e8":"# Sections\n\n* A: All the data pre-processing\n* B-1: Use simple PCA & K-Means\n* C: All the autoencoders\n* C1: Shallow network AE - learned nothing\n* C2: Deep (fully-connected) AE - still not useful\n* C3: Deep Convolutional AE - finally worked well","40a7899e":"# Stop here for now.\n\nA couple of next steps from here. \n\nFurther EDA: I still want to visualize the clustering onto tsne to understand the spread of the clusters. I also want to show images from each of the clusters to compare the clustered encodings vs. actual examples\n\nImproving Prediction: The clustering can be used to make a hierarchical prediction exercise. \n\n","45a47869":"## One hidden layer","8239e024":"Check shape of image_clusters (number of clusters, height x width). Each row is individual clusters and the columns are the flattened pixels.\nCheck the number of images in each clusters and total images in our training data","c9ff6689":"# Overview\n\nIn this kernel, I am interested to understand more about the Pneumothorax diagnosis masks. I want to identify natural categories \/ clusters of pneumothorax diagnosis that exist. I'll use different unsupervised learning approach. Starting with PCA + KMeans, and then use different autoencoders.\n\nThe result might be useful to have better understanding about the illness itseslf. It would also be useful if we want to do hierarchical step for our prediction\n\nI am using this kernel for references on data extraction: https:\/\/www.kaggle.com\/jesperdramsch\/intro-chest-xray-dicom-viz-u-nets-full-data#data","5c0e2e03":"We'll transform the image_clusters into height x width format ","94bbaae9":"The encoding pretty much failed. Many encoding dimensions are perfectly correlated. The correlation dataframe below further confirms that","f1cbd469":"# B-1 Start with PCA","ff4695e4":"Even at n=20 components, we still can only explain 50% of variance. Oh well. \n\nLet's still zoom in with n=20 components:","0f6f0a21":"# Util to check memory size","430cf5e9":"### Check how the original compare with the reconstructed\n"}}