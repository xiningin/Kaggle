{"cell_type":{"5fa265ce":"code","786095f3":"code","bc3d1991":"code","f0223ac4":"code","2379af51":"code","ba7f4e4f":"code","e68fddc5":"code","bc3caba2":"code","0f16e950":"code","ea554e59":"code","3f4c63ac":"code","ed3fb94b":"code","43878de7":"code","28f88dbd":"code","2ec6447b":"code","6f26d449":"code","581bbed2":"code","138a297a":"code","0af1ae4d":"code","2a0cfbb4":"code","bf633c0b":"code","acf5be89":"code","1ca864fa":"code","a118671a":"code","cee57551":"code","9d33710e":"code","3d7f4de8":"code","8b1b1d29":"code","dfc7bbf5":"code","3f7124dd":"code","f3a62597":"markdown","54b6bfa0":"markdown","23b34305":"markdown","3a89e37e":"markdown","05c37c5d":"markdown","2a602310":"markdown","de0c8e36":"markdown","21dc1f6d":"markdown","850589bf":"markdown"},"source":{"5fa265ce":"import numpy as np\nfrom keras.datasets import cifar10\nfrom IPython.display import clear_output, display\nimport matplotlib.pyplot as plt\nfrom time import sleep","786095f3":"(X_train, y_train) , (X_test, y_test) = cifar10.load_data()","bc3d1991":"X_train = X_train.reshape(len(X_train), 3, 32, 32) \/ 255.0\nX_test = X_test.reshape(len(X_test), 3, 32, 32) \/ 255.0","f0223ac4":"y_train = np.eye(10)[y_train]\ny_test = np.eye(10)[y_test]","2379af51":"def initialise_param_lecun_normal(FILTER_SIZE, IMG_DEPTH, scale=1.0):\n    fan_in = FILTER_SIZE * FILTER_SIZE * IMG_DEPTH\n    stddev = scale * np.sqrt(1.\/fan_in)\n    shape = (IMG_DEPTH, FILTER_SIZE, FILTER_SIZE)\n    return np.random.normal(loc = 0,scale = stddev,size = shape) \/ 9","ba7f4e4f":"# Activation functions","e68fddc5":"def softmax(x):\n    return np.exp(x) \/ np.sum(np.exp(x), axis=0)","bc3caba2":"def relu(x):\n    x[x < 0] = 0\n    return x","0f16e950":"# Convolutional and Maxpool function","ea554e59":"def conv(l, w, b, f, convd, filter, image):\n    for jj in range(0, l):\n        for i in range(0, w):\n            for j in range(0, w):\n                convd[jj,i,j] = np.sum(image[:,i:i+f,j:j+f] * filter[jj]) + b[jj]\n\n    return convd","3f4c63ac":"def maxpool(x, f, s):\n    (l, w, w) = x.shape\n    pool = np.zeros((l, (w-f)\/\/s+1,(w-f)\/\/s+1))\n    for jj in range(0,l):\n        for i in range(0, w, s):\n            for j in range(0, w, s):\n                pool[jj,i\/\/2,j\/\/2] = np.max(x[jj,i:i+f,j:j+f])\n    return pool","ed3fb94b":"def nanargmax(a):\n\tidx = np.argmax(a, axis=None)\n\tmulti_idx = np.unravel_index(idx, a.shape)\n\tif np.isnan(a[multi_idx]):\n\t\tnan_count = np.sum(np.isnan(a))\n\t\tidx = np.argpartition(a, -nan_count-1, axis=None)[-nan_count-1]\n\t\tmulti_idx = np.unravel_index(idx, a.shape)\n\treturn multi_idx","43878de7":"def forward(x, theta, convds, filters, f):\n    l, l1, w1, w2, w3, b1, b2, b3 = theta\n    f1, f2 = filters\n    c1, c2 = convds\n\n    m = np.array([conv(l1, w1, b1, f, c1, f1, x[i]) for i in range(len(x))])\n    m = relu(m)\n\n    n = np.array([conv(l2, w2, b2, f, c2, f2, m[i]) for i in range(len(m))])\n    n = relu(n)\n\n    # size 2, stride 2\n    o = np.array([maxpool(n[i], 2, 2) for i in range(len(n))])\n\n    # flatten\n    flat = o.reshape((len(o), (w2\/\/2) * (w2\/\/2) *l2))\n\n    r = flat.dot(w3) + b3\n\n    probs = np.array([softmax(r[i]) for i in range(len(r))])\n\n    return m, n, o, flat, r, probs","28f88dbd":"def dfilter_init(n, l2, l1, f):\n    df, df_sub = [], []\n    db, db_sub = [], []\n    for _ in range(0, n):\n        for x in range(0, l2):\n            df_sub.append(np.zeros((l1,f,f)))\n            db_sub.append(0)\n        df.append(df_sub)\n        db.append(db_sub)\n        df_sub, db_sub = [], []\n    \n    return np.array(df), np.array(db)","2ec6447b":"def backward(x, y, theta, convds, filters, f):\n    l, l1, w1, w2, w3, b1, b2, b3 = theta\n    m, n, o, flat, r, probs = forward(x, theta, convds, filters, f)\n\n    dout = probs - y.reshape(y.shape[0], 10)\n\n    dw3 = flat.T.dot(dout)\n    db3 = np.expand_dims(np.sum(dout, axis=0), axis=0)\n\n    df = dout.dot(w3.T)\n\n    dpool = df.T.reshape((x.shape[0], l2, w2\/\/2, w2\/\/2))\n    dc2 = np.zeros((len(n), l2, w2, w2))\n\n    for nn in range(len(n)):\n        for jj in range(0,l):\n            for i in range(0, w2, 2):\n                for j in range(0, w2, 2):\n                    (a,b) = nanargmax(n[nn][jj,i:i+2,j:j+2])\n                    dc2[nn][jj, i+a, j+b] = dpool[nn][jj, i\/\/2, j\/\/2]\n\n    dc2[n <= 0] = 0\n\n    dc1 = np.zeros((len(m), l1, w1, w1))\n\n    df2, db2 = dfilter_init(len(m), l2, l1, f)\n    df1, db1 = dfilter_init(len(m), l1, l, f)\n\n    for mm in range(len(m)):\n        for jj in range(0, l2):\n            for i in range(0, w2):\n                for j in range(0, w2):\n                    df2[mm][jj] += dc2[mm][jj, i, j] * m[mm][:, i:i+f, j:j+f]\n                    dc1[mm][:, i:i+f, j:j+f] += dc2[mm][jj, i, j] * f2[jj]\n            db2[mm][jj] = np.sum(dc2[mm][jj])\n\n    dc1[m <= 0]=0\n\n    for mm in range(len(m)):\n        for jj in range(0, l1):\n            for i in range(0, w1):\n                for j in range(0, w1):\n                    df1[mm][jj] += dc1[mm][jj, i, j] * x[mm][:, i:i+f, j:j+f]\n            db1[mm][jj] = np.sum(dc1[mm][jj])\n\n    return dc1, dc2, df1, df2, dw3, db1, db2, db3","6f26d449":"def average_grads(grads):\n    return [np.average(grads[i], axis=0) for i in range(len(grads))]","581bbed2":"def optimize(grads, theta, convds, filters, lr=0.01):\n    dc1, dc2, df1, df2, dw3, db1, db2, db3 = grads\n    l, l1, w1, w2, w3, b1, b2, b3 = theta\n    c1, c2 = convds\n    f1, f2 = filters\n\n    c1 -= dc1 * lr\n    c2 -= dc2 * lr\n\n    f1 -= df1 * lr\n    f2 -= df2 * lr\n\n    w3 -= dw3 * lr\n\n    b1 -= db1 * lr\n    b2 -= db2 * lr\n    b3 -= db3 * lr\n\n    grads = dc1, dc2, df1, df2, dw3, db1, db2, db3\n    theta = l, l1, w1, w2, w3, b1, b2, b3\n    convds = c1, c2\n    filters = f1, f2\n\n    return grads, theta, convds, filters","138a297a":"def cross_entropy(predictions, targets, epsilon=1e-12):\n    \"\"\"\n    Computes cross entropy between targets (encoded as one-hot vectors)\n    and predictions. \n    Input: predictions (N, k) ndarray\n           targets (N, k) ndarray        \n    Returns: scalar\n    \"\"\"\n    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n    N = predictions.shape[0]\n    ce = -np.sum(targets*np.log(predictions+1e-9))\/N\n    return ce","0af1ae4d":"# because CPU convolutional takes forever to train\n# we select : 5 idx where the number is 9 and 5 idx for number 1\nten_idx = np.where(np.argmax(y_train.reshape(50000, 10), axis=1) == 9)[0][:5]\none_idx = np.where(np.argmax(y_train.reshape(50000, 10), axis=1) == 1)[0][:5]","2a0cfbb4":"features = np.concatenate((X_train[ten_idx], X_train[one_idx]), axis=0)\nlabels = np.concatenate((y_train[ten_idx], y_train[one_idx]), axis=0)","bf633c0b":"features.shape, labels.shape","acf5be89":"np.random.seed(2342342)","1ca864fa":"NUM_FILT1 = 16\nNUM_FILT2 = 16\n\nIMG_DEPTH = 3\nFILTER_SIZE = 5","a118671a":"## Initializing all the parameters\nf1, f2, b1, b2 = [], [], [], []","cee57551":"for i in range(0, NUM_FILT1):\n\tf1.append(initialise_param_lecun_normal(FILTER_SIZE,IMG_DEPTH))\n\tb1.append(0.)\n\nfor i in range(0, NUM_FILT2):\n\tf2.append(initialise_param_lecun_normal(FILTER_SIZE,NUM_FILT1))\n\tb2.append(0.)\n\nf1, f2, b1, b2 = np.array(f1), np.array(f2), np.array(b1), np.array(b2)","9d33710e":"(l, w, w) = X_train[0].shape\t\t\nl1, l2 = len(f1), len(f2)\n( _, f, f) = f1[0].shape\nw1 = w-f+1\nw2 = w1-f+1","3d7f4de8":"c1 = np.zeros((l1, w1, w1))\nc2 = np.zeros((l2, w2, w2))\n\nw3 = np.random.normal(size=(2304, 10)) \/ 9\nb3 = np.random.normal(size=(1, 10)) \/ 9\n\ntheta = l, l1, w1, w2, w3, b1, b2, b3\nconvds = c1, c2\nfilters = f1, f2","8b1b1d29":"losses = []\nfor epoch in range(501):\n    grads = backward(features, labels, theta, convds, filters, 5)\n\n    grads = average_grads(grads)\n    grads, theta, convds, filters = optimize(grads, theta, convds, filters, lr=0.1)\n\n    if(epoch % 25 == 0):\n        out = forward(features, theta, convds, filters, 5)[-1]\n        loss = cross_entropy(out, labels)\n        losses.append(loss)\n        print(f'Epoch:%4d, Loss:%.3f' % (epoch, loss))","dfc7bbf5":"plt.plot(losses)","3f7124dd":"for i in range(0, len(features)):\n    m, n, o, flat, r, probs = forward(features[i].reshape(1, 3, 32, 32), theta, convds, filters, 5)\n\n    print('idx:{0}, Probs:{1}, y:{2}, cross:{3}'.format(i, np.argmax(probs), np.argmax(labels[i]), cross_entropy(probs, labels[i])))","f3a62597":"# Select Data to Train","54b6bfa0":"# CIFAR-10 Numpy Object Detection from Scratch","23b34305":"# Forward Propagation","3a89e37e":"# Training","05c37c5d":"# Numpy implementation for nanargamax","2a602310":"# Data Preparation","de0c8e36":"# Backward propagation","21dc1f6d":"# Error function","850589bf":"# Analyze Training"}}