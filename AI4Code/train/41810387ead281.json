{"cell_type":{"9990a9b9":"code","92dd7bca":"code","584c6113":"code","f9e1c5d2":"code","9a632d39":"code","89db0760":"code","2fe0cb8d":"code","66d22510":"code","27816ccb":"code","e43cfb90":"code","b25b757b":"code","de7713d4":"code","c7e6dd94":"code","39bb34a9":"code","34304e1b":"code","ecc2d254":"code","a309ab84":"code","8b0a98c7":"code","984a4318":"code","fdd746e5":"code","9f8c65bf":"code","b86d6cbb":"code","3f893858":"code","bed9346f":"code","d01824e2":"code","5abd52e3":"code","31f5e432":"code","2392ee63":"code","d06e92fb":"code","b6776a04":"code","dfa5ab31":"code","0ebde319":"code","89388ce8":"code","1f5a8e4f":"code","9b086870":"code","b9baf06c":"code","c1a9b37d":"code","7718879c":"code","74385745":"code","9de27840":"code","897ed19c":"code","ed88a69d":"code","c5663c4d":"code","f2a38e36":"code","091885b1":"code","d31ad4a4":"code","53b7f51f":"code","8706aab6":"code","86dc8bb4":"code","a1eecd32":"code","8f43faa7":"code","30d8d2cc":"code","34ae3e09":"code","62dbdaae":"code","dc8c18a3":"code","e9e0fc41":"code","8ea4df9a":"code","6f98937d":"code","80cbe73d":"code","c17ce6c5":"code","8c86adb6":"code","f574b4e8":"code","a93f17f3":"code","b24a3bb5":"code","fe529ca5":"code","a2b94639":"code","ca95faa4":"code","862ed274":"code","a0ad5a47":"code","b3b373ca":"code","cb99e7a6":"code","634a7cfd":"code","b9e38f5b":"code","9433720a":"code","99cb0599":"code","1b50ead1":"code","66f01d63":"code","2a22dd77":"code","b33a98c8":"code","2c848249":"markdown","edb85569":"markdown","144fdeda":"markdown","97eaa899":"markdown","cb2e63e0":"markdown","bbeb82d5":"markdown","261fff0a":"markdown","314181f1":"markdown","a1dfc03a":"markdown","fb8786b5":"markdown","9d86f14f":"markdown","fc5c68f9":"markdown","f4c3891d":"markdown","5be6e911":"markdown","d3fc3e94":"markdown","17ba1df4":"markdown","8b064d8a":"markdown","a5af0cc8":"markdown","c9e2a2a3":"markdown","9b83cec4":"markdown","ab30ec0f":"markdown","290d82a3":"markdown","bb24f31b":"markdown","f53e66e6":"markdown","99eb2988":"markdown","7ec4a68c":"markdown","027e238b":"markdown","100c0b51":"markdown","0ec0f7ad":"markdown","0ab6779c":"markdown","fb07e285":"markdown","84845356":"markdown"},"source":{"9990a9b9":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport sklearn\n","92dd7bca":"import warnings\nwarnings.filterwarnings('ignore')","584c6113":"from statistics import mode","f9e1c5d2":"import re","9a632d39":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","89db0760":"train.head()","2fe0cb8d":"train.isnull().sum()","66d22510":"sns.countplot(train['Survived'])","27816ccb":"sns.countplot(x='Survived', hue='Sex', data=train)","e43cfb90":"sns.heatmap(train.isnull(), yticklabels = False, cmap='plasma')","b25b757b":"train.describe()","de7713d4":"sns.countplot(train['Pclass'])","c7e6dd94":"train.Name.value_counts().head()","39bb34a9":"train['Age'].hist(bins=40)","34304e1b":"train['SibSp'].value_counts()","ecc2d254":"sns.countplot(train['SibSp'])","a309ab84":"sns.countplot(train['Parch'])","8b0a98c7":"train.Ticket.value_counts(dropna=False, sort=True).head()","984a4318":"train['Fare'].hist(bins=50)","fdd746e5":"train.Cabin.value_counts(0)","9f8c65bf":"sns.countplot(train['Embarked'])","b86d6cbb":"sns.heatmap(train.corr(), annot=True)","3f893858":"sns.countplot(x='Survived', hue='Pclass', data=train)","bed9346f":"age_group = train.groupby('Pclass')['Age']","d01824e2":"age_group.median()","5abd52e3":"age_group.mean()","31f5e432":"train.loc[train.Age.isnull(), 'Age'] = train.groupby(\"Pclass\").Age.transform('median')\n\ntrain[\"Age\"].isnull().sum()","2392ee63":"sns.heatmap(train.isnull(), yticklabels = False, cmap='plasma')","d06e92fb":"train['Sex'][train['Sex'] == 'male'] = 0\ntrain['Sex'][train['Sex'] == 'female'] = 1","b6776a04":"train[\"Embarked\"][train[\"Embarked\"] == \"S\"] = 0\ntrain[\"Embarked\"][train[\"Embarked\"] == \"C\"] = 1\ntrain[\"Embarked\"][train[\"Embarked\"] == \"Q\"] = 2","dfa5ab31":"train.head()","0ebde319":"df = pd.read_csv('..\/input\/titanic\/train.csv')","89388ce8":"test['Survived'] = np.nan\nfull = pd.concat([df, test])","1f5a8e4f":"full.isnull().sum()","9b086870":"full.head()","b9baf06c":"full['Embarked'] = full['Embarked'].fillna(mode(full['Embarked']))","c1a9b37d":"# Convert 'Sex' variable to integer form!\nfull[\"Sex\"][full[\"Sex\"] == \"male\"] = 0\nfull[\"Sex\"][full[\"Sex\"] == \"female\"] = 1\n\n# Convert 'Embarked' variable to integer form!\nfull[\"Embarked\"][full[\"Embarked\"] == \"S\"] = 0\nfull[\"Embarked\"][full[\"Embarked\"] == \"C\"] = 1\nfull[\"Embarked\"][full[\"Embarked\"] == \"Q\"] = 2","7718879c":"sns.heatmap(full.corr(), annot=True)","74385745":"full['Age'] = full.groupby(\"Pclass\")['Age'].transform(lambda x: x.fillna(x.median()))","9de27840":"full.isnull().sum()","897ed19c":"full['Fare']  = full.groupby(\"Pclass\")['Fare'].transform(lambda x: x.fillna(x.median()))","ed88a69d":"full['Cabin'] = full['Cabin'].fillna('U')","c5663c4d":"full['Cabin'].unique().tolist()","f2a38e36":"full['Cabin'] = full['Cabin'].map(lambda x:re.compile(\"([a-zA-Z])\").search(x).group())","091885b1":"full['Cabin'].unique().tolist()","d31ad4a4":"cabin_category = {'A':1, 'B':2, 'C':3, 'D':4, 'E':5, 'F':6, 'G':7, 'T':8, 'U':9}\nfull['Cabin'] = full['Cabin'].map(cabin_category)","53b7f51f":"full['Cabin'].unique().tolist()","8706aab6":"full['Name'].head()","86dc8bb4":"full['Name'] = full.Name.str.extract(' ([A-Za-z]+)\\.', expand = False)","a1eecd32":"full['Name'].unique().tolist()","8f43faa7":"full['Name'].value_counts(normalize = True) * 100","30d8d2cc":"full.rename(columns={'Name' : 'Title'}, inplace=True)","34ae3e09":"full['Title'] = full['Title'].replace(['Rev', 'Dr', 'Col', 'Ms', 'Mlle', 'Major', 'Countess', \n                                       'Capt', 'Dona', 'Jonkheer', 'Lady', 'Sir', 'Mme', 'Don'], 'Other')","62dbdaae":"full['Title'].value_counts(normalize = True) * 100","dc8c18a3":"title_category = {'Mr':1, 'Miss':2, 'Mrs':3, 'Master':4, 'Other':5}\nfull['Title'] = full['Title'].map(title_category)\nfull['Title'].unique().tolist()","e9e0fc41":"full['familySize'] = full['SibSp'] + full['Parch'] + 1","8ea4df9a":"# Drop redundant features\nfull = full.drop(['SibSp', 'Parch', 'Ticket'], axis = 1)","6f98937d":"full.head()","80cbe73d":"# Recover test dataset\ntest = full[full['Survived'].isna()].drop(['Survived'], axis = 1)","c17ce6c5":"test.head()","8c86adb6":"# Recover train dataset\ntrain = full[full['Survived'].notna()]","f574b4e8":"train['Survived'] = train['Survived'].astype(np.int8)","a93f17f3":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train.drop(['Survived', 'PassengerId'], axis=1), train['Survived'], test_size = 0.2, random_state=2)","b24a3bb5":"from sklearn.linear_model import LogisticRegression\nLogisticRegression = LogisticRegression(max_iter=10000)\nLogisticRegression.fit(X_train, y_train)","fe529ca5":"predictions = LogisticRegression.predict(X_test)\npredictions","a2b94639":"from sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test, predictions)","ca95faa4":"acc = (87+54) \/ (87+54+13+25) * 100\nacc","862ed274":"from sklearn.model_selection import KFold\nkf = KFold(n_splits = 5, random_state=2)","a0ad5a47":"from sklearn.model_selection import cross_val_score\n\ncross_val_score(LogisticRegression, X_test, y_test, cv = kf).mean() * 100","b3b373ca":"from sklearn.ensemble import RandomForestClassifier\nRandomForest = RandomForestClassifier(random_state=2)","cb99e7a6":"# Set our parameter grid\nparam_grid = { \n    'criterion' : ['gini', 'entropy'],\n    'n_estimators': [100, 300, 500],\n    'max_features': ['auto', 'log2'],\n    'max_depth' : [3, 5, 7]    \n}","634a7cfd":"from sklearn.model_selection import GridSearchCV\n\nrandomForest_CV = GridSearchCV(estimator = RandomForest, param_grid = param_grid, cv = 5)\nrandomForest_CV.fit(X_train, y_train)","b9e38f5b":"randomForest_CV.best_params_","9433720a":"randomForestFinalModel = RandomForestClassifier(random_state = 2, criterion = 'gini', max_depth = 7, max_features = 'auto', n_estimators = 300)\n\nrandomForestFinalModel.fit(X_train, y_train)","99cb0599":"predictions = randomForestFinalModel.predict(X_test)","1b50ead1":"from sklearn.metrics import accuracy_score\n\naccuracy_score(y_test, predictions) * 100","66f01d63":"test['Survived'] = randomForestFinalModel.predict(test.drop(['PassengerId'], axis = 1))","2a22dd77":"test[['PassengerId', 'Survived']].to_csv('MySubmission.csv', index = False)","b33a98c8":"test.info()","2c848249":"### OK, if we look closely, corr(Age, Pclass) is the highest correlation in absolute numbers for 'Age', so we'll use Pclass to impute the missing values:","edb85569":"#### Let's print our optimal hyperparameters set!","144fdeda":"# Magic Weapon #2: Cross-Validation","97eaa899":"### You can skip arguments other than x, cmap is styling the heatmap\n","cb2e63e0":"### Whoops! Apart from Mr, Miss, Mrs, and Master, the rest have percentages close to zero...\n\n### So, let's bundle them!","bbeb82d5":"# Plz Upvote!","261fff0a":"# Dateset is completely ready now!","314181f1":"# Contents:\n1. Include Libraries\n2. Import DataSet\n3. EDA(Exploratory Data Analysis)\n4. Handle Missing Value\n5. Feature Engineering by OneHotEncoding\n6. Logistic Regression\n7. Hyperparameter Tunning\n8. Train Random Forest Classifier\n9. Final Submittion","a1dfc03a":"### Wow! 'Sex' looks like a very strong explanatory variable, and it can be our choice for our single feature Logistic Regression model!","fb8786b5":"### Hmmm... but we know from part 2 that Sibsp is the number of siblings \/ spouses aboard the Titanic, and Parch is the number of parents \/ children aboard the Titanic... So, what is another straightforward feature to engineer?\n\n### Yes, it is the size of each family aboard!","9d86f14f":"### Let's submit our solutions","fc5c68f9":" Secondly, I would like to introduce one of the most popular algorithms for classification (but also regression, etc), **Random Forest!** In a nutshell, Random Forest is an ensembling learning algorithm which combines **decision trees** in order to increase performance and avoid overfitting.","f4c3891d":"### Look in to relationships among dataset","5be6e911":" One of the most popular and efficient CV variants is **k-Fold Cross-Validation**, which we will choose to set our strong local validation scheme below. In a nutshell, k is the number of folds, mentioned above!\n\n Nice, now let's apply this key technique ourselves! We will use the basic version of k-Fold with **5 folds** from our friend, Scikit-learn!","d3fc3e94":"### annot argument is mandatory as you also need data value in each cell\n### As you can see that Survived as max relation with Pclass, lets vizualize it in chart","17ba1df4":"### Wohh that's lot's of title","8b064d8a":"# Importing Libraries","a5af0cc8":"### You can always use value_counts to check on data, visualization is just another option ","c9e2a2a3":"# Load DataSet","9b83cec4":"### You can also find null values by plotting it on graph","ab30ec0f":"### Good practice to check the results","290d82a3":"# Let's Fix data","bb24f31b":"### You need to do the same changes in test dataset aslo...So lest merge test and train","f53e66e6":"Below we set the hyperparameter grid of values with 4 lists of values:\n\n- **'criterion'** : A function which measures the quality of a split.\n- **'n_estimators'** : The number of trees of our random forest.\n- **'max_features'** : The number of features to choose when looking for the best way of splitting.\n- **'max_depth'** : the maximum depth of a decision tree.","99eb2988":"### Didn't Work","7ec4a68c":"### Pclass and age, as they had max relation in the entire set we are going to replace missing age values with median age calculated per class","027e238b":"# Magic Weapon #3: Hyperparameter Tuning","100c0b51":"# Examine Dataset\n## Look In to every column one by one ","0ec0f7ad":"### Better! let's convert to numeric","0ab6779c":"### Also, corr(Fare, Pclass) is the highest correlation in absolute numbers for 'Fare', so we'll use Pclass again to impute the missing values!","fb07e285":"<center><h1 style=\"color:green\">Don't forget to upvote if you like it! It's free! :)<\/h1><\/center>","84845356":"### We can get the alphabets by running regular expression "}}