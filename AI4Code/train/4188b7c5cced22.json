{"cell_type":{"ef4e34c7":"code","67e433b3":"code","a6aa9910":"code","335ad2be":"code","bd05bd33":"code","31812c5e":"code","520bf58e":"code","c433cec0":"code","2895cd5b":"code","6e3df1f6":"code","b28c958f":"code","062ff55d":"code","f1df9bc8":"code","1acb7f23":"code","c7ef5b2c":"code","84da3f17":"code","0f37b7c6":"code","da0b0b71":"code","fcb0af80":"code","f8dd2a5d":"code","8bde736e":"code","7df82648":"code","5fd072cc":"code","9a4370c3":"code","0bd7f9b9":"code","82033b59":"code","41cf01c8":"code","ba04b454":"code","21856a74":"code","049e1855":"code","7f7524ae":"code","fdbe1214":"code","64fae020":"code","96e5f0e1":"code","ed937a7d":"code","399446dd":"code","70dcc681":"code","4a26bbfc":"code","6008c55e":"code","64995f4c":"code","04a2125b":"code","7363d237":"code","079c674f":"code","5cf0e1e2":"code","ad65db68":"code","fc96e6c9":"code","faeb428c":"code","c0e21df4":"code","7dc0c92a":"code","1b474306":"code","9fb068eb":"code","39517ec6":"code","36602b98":"code","bac89c8e":"markdown","7c5533eb":"markdown","a1133bc1":"markdown","b49ec8eb":"markdown","a4f47e73":"markdown","bfae09f3":"markdown","7883ffc3":"markdown","34a4c432":"markdown","7b3379e8":"markdown","5f3d163b":"markdown","0ec55d0f":"markdown","28a15f65":"markdown","47aed246":"markdown","bf9c58c2":"markdown","1b580c9c":"markdown","87b78eae":"markdown","03a745f4":"markdown","9511d08e":"markdown","e82af5e5":"markdown","ef61a026":"markdown","ddcf28b3":"markdown","db0b5b90":"markdown","c7e72a2e":"markdown","b262f0f5":"markdown","08ff3b89":"markdown","003215ea":"markdown","8d97508c":"markdown","6d919944":"markdown","d27a6fcf":"markdown","f14e90c5":"markdown","4bf1177f":"markdown"},"source":{"ef4e34c7":"!wget https:\/\/github.com\/facebookresearch\/fastText\/archive\/v0.9.2.zip","67e433b3":"!unzip v0.9.2.zip","a6aa9910":"!cd fastText-0.9.2 && pip install .","335ad2be":"import pandas as pd\n# \"The cleaning supply\"\nimport re\nimport string\n# \"NLP Supply\"\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.corpus import stopwords","bd05bd33":"train = pd.read_csv('..\/input\/student-shopee-code-league-sentiment-analysis\/train.csv')\ntest = pd.read_csv('..\/input\/student-shopee-code-league-sentiment-analysis\/test.csv')","31812c5e":"train.head()","520bf58e":"test.head()","c433cec0":"# Initialize the lemmarizer and stemmer\nwordnet_lemmatizer = WordNetLemmatizer()\nenglishStemmer=SnowballStemmer(\"english\")\n\ndef clean_text(x):\n    # Remove zero width space from the string and lower it\n    temp_text = x.lower().replace('\\u200b', '')\n    # Remove punctuation of the string\n    temp_text = temp_text.translate(str.maketrans('', '', string.punctuation))\n    # Remove new line from string\n    temp_text = temp_text.replace('\\n', '')\n    # Remove double space or more\n    temp_text = re.sub(' +', ' ', temp_text).strip()\n    # Tokenized the text\n    temp_text = nltk.word_tokenize(temp_text)\n    stop_words = set(stopwords.words('english'))\n    \n    filtered_word = []\n    \n    for word in temp_text:\n        # Lemmanize and stem word\n        lemma_word = wordnet_lemmatizer.lemmatize(word)\n        stemmed_word = englishStemmer.stem(lemma_word)\n        \n        # Do not add stop words into the the final cleaned sentence\n        if stemmed_word in stop_words:\n            continue\n        else:\n            filtered_word.append(stemmed_word)\n            \n    return \" \".join(filtered_word).strip()","2895cd5b":"# Clean all of the review in training, and test\ntrain['review'] = train['review'].apply(clean_text)\ntest['review'] = test['review'].apply(clean_text)","6e3df1f6":"VAL_PERCENTAGE = 0.2\nN_VAL = int(len(train) * VAL_PERCENTAGE)\n\n# Shuffle train DataFrame also reset the shuffled index\ntrain = train.sample(frac=1).reset_index(drop=True)\n\n# Set validation DataFrame as having the first N_VAL row\nval_data = train[:N_VAL]\n\n# Set train DataFrame as the rest\ntrain_data = train[N_VAL:]","b28c958f":"val_data.describe()","062ff55d":"train_data.describe()","f1df9bc8":"validation_file_path = \".\/review.val\"\ntraining_file_path = \".\/review.train\"\n\ndef append_fasttext_dataset(row, file_writer):\n    def convert_row_to_dataset_string(row):\n        return \"__label__\" + str(row['rating']) + \" \" + row['review']\n    \n    file_writer.write(convert_row_to_dataset_string(row) + '\\n')","1acb7f23":"# Validation file\nwith open(validation_file_path, 'a+') as writer:\n    val_data.apply(lambda x: append_fasttext_dataset(x, writer), axis=1)\n    \n# Training file\nwith open(training_file_path, 'a+') as writer:\n    train_data.apply(lambda x: append_fasttext_dataset(x, writer), axis=1)","c7ef5b2c":"# Look at number of label (1-5) of the training data\ntrain_data['rating'].value_counts().plot.bar()","84da3f17":"# Look at number of label (1-5) of the validation data\nval_data['rating'].value_counts().plot.bar()","0f37b7c6":"import fasttext","da0b0b71":"hyper_params = {\n    \"lr\": 0.01,\n    \"epoch\": 15,\n    \"wordNgrams\": 2,\n    \"dim\": 20,\n    \"verbose\": 1\n}","fcb0af80":"model = fasttext.train_supervised(input=training_file_path, **hyper_params)","f8dd2a5d":"import matplotlib.pyplot as plt","8bde736e":"# Get model accuracy and accuracy of the validation\nresult = model.test(training_file_path)\nvalidation = model.test(validation_file_path)\n\nprint(\"Result : \", result)\nprint(\"Validation : \", validation)\n\n# Plot the result\naccuracy_data = [result[1], validation[1]]\nlabels = ['Model Accuracy', 'Validation Accuracy']\n\nplt.title(\"Model accuracy\")\nplt.bar(labels, accuracy_data)\nplt.show()","7df82648":"def get_predicted_rating(x, model):\n    return int(model.predict(x)[0][0].split('__label__')[1])","5fd072cc":"val_data['predicted'] = val_data['review'].apply(lambda x: get_predicted_rating(x, model))","9a4370c3":"import numpy as np\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix","0bd7f9b9":"confusion_labels = [1, 2, 3, 4, 5]\nconfusion_matrix_data = confusion_matrix(val_data[\"rating\"], val_data[\"predicted\"], labels=confusion_labels)\nnormalised_confusion_matrix = confusion_matrix_data.astype('float') \/ confusion_matrix_data.sum(axis=1)[:, np.newaxis]","82033b59":"# Plot the normalised confusion matrix\nax = plt.subplot()\nsns.heatmap(normalised_confusion_matrix, annot=True, ax=ax, fmt='.2f');\n\nax.set_title('Normalized Confusion Matrix')\n\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')\n\nax.xaxis.set_ticklabels(confusion_labels)\nax.yaxis.set_ticklabels(confusion_labels)","41cf01c8":"hyper_params_25_epoch = {\n    \"lr\": 0.01,\n    \"epoch\": 25,\n    \"wordNgrams\": 2,\n    \"dim\": 20,\n    \"verbose\": 1\n}","ba04b454":"model_25_epoch = fasttext.train_supervised(input=training_file_path, **hyper_params_25_epoch)","21856a74":"# Get model accuracy and accuracy of the validation\nresult = model_25_epoch.test(training_file_path)\nvalidation = model_25_epoch.test(validation_file_path)\n\nprint(\"Result : \", result)\nprint(\"Validation : \", validation)\n\n# Plot the result\naccuracy_data = [result[1], validation[1]]\nlabels = ['Model Accuracy', 'Validation Accuracy']\n\nplt.title(\"Model accuracy with 25 epoch\")\nplt.bar(labels, accuracy_data)\nplt.show()","049e1855":"hyper_params_bigger_lr = {\n    \"lr\": 0.6,\n    \"epoch\": 15,\n    \"wordNgrams\": 2,\n    \"dim\": 20,\n    \"verbose\": 1\n}","7f7524ae":"model_bigger_lr = fasttext.train_supervised(input=training_file_path, **hyper_params_bigger_lr)","fdbe1214":"# Get model accuracy and accuracy of the validation\nresult = model_bigger_lr.test(training_file_path)\nvalidation = model_bigger_lr.test(validation_file_path)\n\nprint(\"Result : \", result)\nprint(\"Validation : \", validation)\n\n# Plot the result\naccuracy_data = [result[1], validation[1]]\nlabels = ['Model Accuracy', 'Validation Accuracy']\n\nplt.title(\"Model accuracy with learning rate 0.6\")\nplt.bar(labels, accuracy_data)\nplt.show()","64fae020":"hyper_params_autotuning = {\n    \"lr\": 0.06,\n    \"epoch\": 20,\n    \"wordNgrams\": 2,\n    \"dim\": 20,\n    \"verbose\": 1,\n    \"autotuneValidationFile\": validation_file_path\n}","96e5f0e1":"model_autotuning = fasttext.train_supervised(input=training_file_path, **hyper_params_autotuning)","ed937a7d":"# Get model accuracy and accuracy of the validation\nresult = model_autotuning.test(training_file_path)\nvalidation = model_autotuning.test(validation_file_path)\n\nprint(\"Result : \", result)\nprint(\"Validation : \", validation)\n\n# Plot the result\naccuracy_data = [result[1], validation[1]]\nlabels = ['Model Accuracy', 'Validation Accuracy']\n\nplt.title(\"Model accuracy with autotuning\")\nplt.bar(labels, accuracy_data)\nplt.show()","399446dd":"val_data['predicted'] = val_data['review'].apply(lambda x: get_predicted_rating(x, model_autotuning))","70dcc681":"confusion_labels = [1, 2, 3, 4, 5]\nconfusion_matrix_data = confusion_matrix(val_data[\"rating\"], val_data[\"predicted\"], labels=confusion_labels)\nnormalised_confusion_matrix = confusion_matrix_data.astype('float') \/ confusion_matrix_data.sum(axis=1)[:, np.newaxis]","4a26bbfc":"# Plot the normalised confusion matrix\nax = plt.subplot()\nsns.heatmap(normalised_confusion_matrix, annot=True, ax=ax, fmt='.2f');\n\nax.set_title('Normalized Confusion Matrix (Autotuning)')\n\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')\n\nax.xaxis.set_ticklabels(confusion_labels)\nax.yaxis.set_ticklabels(confusion_labels)","6008c55e":"hyper_params_autotuning_metrics = {\n    \"lr\": 0.1,\n    \"epoch\": 20,\n    \"wordNgrams\": 2,\n    \"dim\": 50,\n    \"verbose\": 2,\n    \"autotuneValidationFile\": validation_file_path,\n    \"autotuneMetric\": \"f1:__label__4\"\n}","64995f4c":"model_autotuning_metrics = fasttext.train_supervised(input=training_file_path, **hyper_params_autotuning_metrics)","04a2125b":"# Get model accuracy and accuracy of the validation\nresult = model_autotuning_metrics.test(training_file_path)\nvalidation = model_autotuning_metrics.test(validation_file_path)\n\nprint(\"Result : \", result)\nprint(\"Validation : \", validation)\n\n# Plot the result\naccuracy_data = [result[1], validation[1]]\nlabels = ['Model Accuracy', 'Validation Accuracy']\n\nplt.title(\"Model accuracy with autotuning\")\nplt.bar(labels, accuracy_data)\nplt.show()","7363d237":"val_data['predicted'] = val_data['review'].apply(lambda x: get_predicted_rating(x, model_autotuning_metrics))","079c674f":"confusion_labels = [1, 2, 3, 4, 5]\nconfusion_matrix_data = confusion_matrix(val_data[\"rating\"], val_data[\"predicted\"], labels=confusion_labels)\nnormalised_confusion_matrix = confusion_matrix_data.astype('float') \/ confusion_matrix_data.sum(axis=1)[:, np.newaxis]","5cf0e1e2":"# Plot the normalised confusion matrix\nax = plt.subplot()\nsns.heatmap(normalised_confusion_matrix, annot=True, ax=ax, fmt='.2f');\n\nax.set_title('Normalized Confusion Matrix (Autotuning Metrics f1:__label__4)')\n\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')\n\nax.xaxis.set_ticklabels(confusion_labels)\nax.yaxis.set_ticklabels(confusion_labels)","ad65db68":"hyper_params_autotuning_metrics_5 = {\n    \"lr\": 0.1,\n    \"epoch\": 20,\n    \"wordNgrams\": 2,\n    \"dim\": 50,\n    \"verbose\": 2,\n    \"autotuneValidationFile\": validation_file_path,\n    \"autotuneMetric\": \"f1:__label__5\"\n}","fc96e6c9":"model_autotuning_metrics_5 = fasttext.train_supervised(input=training_file_path, **hyper_params_autotuning_metrics_5)","faeb428c":"# Get model accuracy and accuracy of the validation\nresult = model_autotuning_metrics_5.test(training_file_path)\nvalidation = model_autotuning_metrics_5.test(validation_file_path)\n\nprint(\"Result : \", result)\nprint(\"Validation : \", validation)\n\n# Plot the result\naccuracy_data = [result[1], validation[1]]\nlabels = ['Model Accuracy', 'Validation Accuracy']\n\nplt.title(\"Model accuracy with autotuning metrics\")\nplt.bar(labels, accuracy_data)\nplt.show()","c0e21df4":"val_data['predicted'] = val_data['review'].apply(lambda x: get_predicted_rating(x, model_autotuning_metrics_5))","7dc0c92a":"confusion_labels = [1, 2, 3, 4, 5]\nconfusion_matrix_data = confusion_matrix(val_data[\"rating\"], val_data[\"predicted\"], labels=confusion_labels)\nnormalised_confusion_matrix = confusion_matrix_data.astype('float') \/ confusion_matrix_data.sum(axis=1)[:, np.newaxis]","1b474306":"# Plot the normalised confusion matrix\nax = plt.subplot()\nsns.heatmap(normalised_confusion_matrix, annot=True, ax=ax, fmt='.2f');\n\nax.set_title('Normalized Confusion Matrix (Autotuning Metrics f1:__label__5)')\n\nax.set_xlabel('Predicted labels')\nax.set_ylabel('True labels')\n\nax.xaxis.set_ticklabels(confusion_labels)\nax.yaxis.set_ticklabels(confusion_labels)","9fb068eb":"submission = test.copy()\nsubmission['rating'] = submission['review'].apply(lambda x: get_predicted_rating(x, model_autotuning_metrics))\n\ndel submission['review']","39517ec6":"submission.head()","36602b98":"submission.to_csv('submission.csv', index=False)","bac89c8e":"Save the submission file into csv without index in the csv file.","7c5533eb":"The result of doing metrics works as intended, the confusion between rating 4 and 5 has decreased, though the confusion between rating 5 and 4 is increasing. Another effect that is not excpected\u2014but welcomed\u2014is with the lower rate of confusion on rating 2 and 3.\n\nNow what if the focus is on rating 5.","a1133bc1":"# Using fastText to do Sentiment analysis\nThe dataset using rating from 1-5, and the task is to predict a review what the rating is. Using the supervised learning method of the fastText hopefully the model can classify the review into one of the 5 rating.","b49ec8eb":"Open the files, the main training data, and also test data.","a4f47e73":"# Training with fastText\nNow the fun part of actually making the model which will classify our data. We will use the supervised training method of the fastText to do it.","bfae09f3":"Write to validation and training file","7883ffc3":"This doesn't yield as much better confusion matrix than the method which uses label 5","34a4c432":"# Installing fasttext\nDownloading fasttext from the git and installing it using pip","7b3379e8":"Now, build the model of fasttext we'll be using, with the appropiate input file, then the model will automatically train with the file using our params.","5f3d163b":"Look at the dataset, see if there's a skew, or any other discrepancy.","0ec55d0f":"# Converting the dataset\nCreate the function to convert from the current dataset row to a string which is the row in the training data of fastText.\nWhich will looks like `__label__<1-5> <review>`.","28a15f65":"The usage of autotuning seems to work amazingly, with reaching higher accuracy without much over fitting, though on the confusion matrix, everything seems like before, nothing change. In the autotune function there's also metrics we can change, like optimizing f1 score for certain label.\n\nAnd that is exacly what I'm going to do. Let's see what happen with using focused metrics on optimizing the f1 score of `__label__4`.","47aed246":"# Exploring Improvements\nIn this section, there are few attempts to improve the current models using different kind of ways to do it.","bf9c58c2":"Then using sklearn tools to make confusion matrix, to interpret the data more easily.","1b580c9c":"Define the parameter for the training phase,\n\n- **lr** : learning rate of the training\n- **epoch** : how many times the training will go over the data\n- **wordNgrams** : contiguous sequence of max n words from a given sample of text\n- **dim** : dimension of the word vector","87b78eae":"It has seem that our prediction is wrong! Most of the problem lies between false-positive and false-negative  between rating 4 and rating 5. Also with false-positive between rating 3 and rating 2. All of them have the value of 0.4-ish which means nearly as much as half of the label is wrongly labelled with their respective neighbouring rating. This could means that rating 4 and 5, 5 and 4, and also rating 3 and 2 have the tendency to be closely related, or closely positive or negative.","03a745f4":"As the bar graph shown, the data is skewing to the higher rating. This is usual for review data as most people probably just left a good score on their purchase, except when minor thing happens it will be 4 stars or sometimes 3 stars. But if it is major incident on the purchase, people would just give the seller a one star review.\n\nThis is a bad thing for the training as the model would be (probably) more likely to give a higher rating on a review than it actually is. This problem with the dataset could be fixed with using upsampling method, by copying the minority class up to the same or nearly the same level as the majority class. The problem with that is we will run risk on over fitting the model with repeating reviews. Especially with the huge difference shown before.\n\nFor now we will just run it \"as is\" and see what will happen.","9511d08e":"Cleaner function to pre process the text.","e82af5e5":"Check the inside of both of the dataset","ef61a026":"The difference between the model accuracy itself (using the training data) and the accuracy on the validation data, seems having a bigger gap than before. This could means that the model is starting or already over fitting as it knows the training data so well, but not on the data it never saw.","ddcf28b3":"## Bigger Learning Rate\nBy responding bigger on the predicted error rate, the model might find the \"valley\" faster, and at the end make it more accurate.\n\nNow, make the hyper parameter with bigger learning rate. I might choose, 0.6 or something.","db0b5b90":"Check out the predicted result.","c7e72a2e":"# Making Submission file\nMaking file to submit to kaggle, following the intended sample submission format.","b262f0f5":"Now get the prediction result for all of the validation data.","08ff3b89":"## More Epoch\nBy exposing the model into the data more, maybe the model will \"learn\" the pattern better and also differenciate the pattern in the data better.\n\nFirst, let's make the parameters for doing it. Let's try adding a bit more, maybe 10.","003215ea":"## Autotuning\nTry to make the model actually improve itself using validation data that's given as the parameter.\n\nNow, create the parameters for it. By passing the validation file, the model will use that as a tuning reference for the model.","8d97508c":"Split train and validation data into 2 different DataFrame.","6d919944":"Looks like using a bigger learning rate doesn't help as well, as the difference on the training data and validation data is getting even bigger, showing over fitting.","d27a6fcf":"Check for the performance of the model itself","f14e90c5":"The model is sitting at above 50% of accuracy and the validation data shows it too (a little difference is okay) but let's see how we can actually improve it. Maybe first we need to see the confusion matrix of the model to see how it is handling the label and which label is actually affecting it the most.\n\nTo make the prediction and conversion to the label used in the DataFrame we'll make a function.","4bf1177f":"## Cleaning the data\nAs fasttext using a different kind of dataset, not the same as TF or Keras. Fasttext using a text based file dataset with label in the same line as the data. The label must start with `__label__<label word>` so the current dataset needed to be changed. \n\nAnother reason is of course current dataset is still at the state of \"dirty\" with mixed case string, haven't been lemmanized or stemmed, also contains new line, and other stuff."}}