{"cell_type":{"40d097fb":"code","18a2a832":"code","d81a414a":"code","b13bb9ce":"code","14465862":"code","ae617412":"code","2ea88c33":"code","bc9c4956":"code","8a25f85f":"code","d1020177":"code","d07882f7":"code","bc6e99d7":"code","5083d4db":"code","4ac652b0":"code","06a8be00":"code","51707a08":"code","ad9f466b":"code","48bf452e":"code","4895e956":"code","5a2b96c9":"code","9bd221f3":"code","b6bb54b8":"code","ed1da93d":"code","2215e7c3":"code","b3f5ba8e":"code","d5846348":"code","23dd3bfb":"code","2b468a56":"code","918bc847":"markdown","255091b2":"markdown","ce765f67":"markdown","3b0d1cc0":"markdown","a1459388":"markdown","28b39d8e":"markdown","02087e80":"markdown"},"source":{"40d097fb":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os","18a2a832":"# params we will probably want to do some hyperparameter optimization later\nBASE_MODEL= 'DenseNet121'\nIMG_SIZE = (512, 512) # [(224, 224), (384, 384), (512, 512), (640, 640)]\nBATCH_SIZE = 128 # [1, 8, 16, 24]\nDENSE_COUNT = 128 # [32, 64, 128, 256]\nDROPOUT = 0.5 # [0, 0.25, 0.5]\nLEARN_RATE = 0.01 # [1e-4, 1e-3, 4e-3]\nTRAIN_SAMPLES = 3000 # [3000, 6000, 15000]\nTEST_SAMPLES = 600\nUSE_ATTN = False # [True, False]","d81a414a":"image_bbox_df = pd.read_csv('..\/input\/lung-opacity-overview\/image_bbox_full.csv')\nimage_bbox_df['path'] = image_bbox_df['path'].map(lambda x: \n                                                  x.replace('input', \n                                                            'input\/rsna-pneumonia-detection-challenge'))\nprint(image_bbox_df.shape[0], 'images')\nimage_bbox_df.sample(3)","b13bb9ce":"# get the labels in the right format\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nclass_enc = LabelEncoder()\nimage_bbox_df['class_idx'] = class_enc.fit_transform(image_bbox_df['class'])\noh_enc = OneHotEncoder(sparse=False)\nimage_bbox_df['class_vec'] = oh_enc.fit_transform(\n    image_bbox_df['class_idx'].values.reshape(-1, 1)).tolist() \nimage_bbox_df.sample(3)","14465862":"from sklearn.model_selection import train_test_split\nimage_df = image_bbox_df.groupby('patientId').apply(lambda x: x.sample(1))\nraw_train_df, valid_df = train_test_split(image_df, test_size=0.15, random_state=2018,\n                                    stratify=image_df['class'])\nprint(raw_train_df.shape, 'training data')\nprint(valid_df.shape, 'validation data')","ae617412":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\nraw_train_df.groupby('class').size().plot.bar(ax=ax1)\ntrain_df = raw_train_df.groupby('class').\\\n    apply(lambda x: x.sample(TRAIN_SAMPLES\/\/1)).\\\n    reset_index(drop=True)\ntrain_df.groupby('class').size().plot.bar(ax=ax2) \nprint(train_df.shape[0], 'new training size')","2ea88c33":"import keras.preprocessing.image as KPImage\nfrom PIL import Image\nimport pydicom\ndef read_dicom_image(in_path):\n    img_arr = pydicom.read_file(in_path).pixel_array\n    return img_arr\/img_arr.max()\n    \nclass medical_pil():\n    @staticmethod\n    def open(in_path):\n        if '.dcm' in in_path:\n            c_slice = read_dicom_image(in_path)\n            int_slice =  (255*c_slice).clip(0, 255).astype(np.uint8) # 8bit images are more friendly\n            return Image.fromarray(int_slice)\n        else:\n            return Image.open(in_path)\n    fromarray = Image.fromarray\nKPImage.pil_image = medical_pil","bc9c4956":"try:\n    # keras 2.2\n    from keras_preprocessing.image import ImageDataGenerator\nexcept:\n    from keras.preprocessing.image import ImageDataGenerator\nif BASE_MODEL=='VGG16':\n    from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\nelif BASE_MODEL=='RESNET52':\n    from keras.applications.resnet50 import ResNet50 as PTModel, preprocess_input\nelif BASE_MODEL=='InceptionV3':\n    from keras.applications.inception_v3 import InceptionV3 as PTModel, preprocess_input\nelif BASE_MODEL=='Xception':\n    from keras.applications.xception import Xception as PTModel, preprocess_input\nelif BASE_MODEL=='DenseNet169': \n    from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\nelif BASE_MODEL=='DenseNet121':\n    from keras.applications.densenet import DenseNet121 as PTModel, preprocess_input\nelse:\n    raise ValueError('Unknown model: {}'.format(BASE_MODEL))","8a25f85f":"img_gen_args = dict(samplewise_center=False, \n                              samplewise_std_normalization=False, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              height_shift_range = 0.05, \n                              width_shift_range = 0.02, \n                              rotation_range = 3, \n                              shear_range = 0.01,\n                              fill_mode = 'nearest',\n                              zoom_range = 0.05,\n                               preprocessing_function=preprocess_input)\nimg_gen = ImageDataGenerator(**img_gen_args)","d1020177":"def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, seed = None, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways: seed: {}'.format(seed))\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                              seed = seed,\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values,0)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen","d07882f7":"train_gen = flow_from_dataframe(img_gen, train_df, \n                             path_col = 'path',\n                            y_col = 'class_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = BATCH_SIZE)\n\nvalid_gen = flow_from_dataframe(img_gen, valid_df, \n                             path_col = 'path',\n                            y_col = 'class_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = 256) # we can use much larger batches for evaluation\n# used a fixed dataset for evaluating the algorithm\nvalid_X, valid_Y = next(flow_from_dataframe(img_gen, \n                               valid_df, \n                             path_col = 'path',\n                            y_col = 'class_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'rgb',\n                            batch_size = TEST_SAMPLES)) # one big batch","bc6e99d7":"t_x, t_y = next(train_gen)","5083d4db":"base_pretrained_model = PTModel(input_shape =  t_x.shape[1:], \n                              include_top = False, weights = 'imagenet')\nbase_pretrained_model.trainable = False","4ac652b0":"from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, Conv2D, multiply, LocallyConnected2D, Lambda, AvgPool2D\nfrom keras.models import Model\nfrom keras.optimizers import Adam\npt_features = Input(base_pretrained_model.get_output_shape_at(0)[1:], name = 'feature_input')\npt_depth = base_pretrained_model.get_output_shape_at(0)[-1]\nfrom keras.layers import BatchNormalization\nbn_features = BatchNormalization()(pt_features)\ngap = GlobalAveragePooling2D()(bn_features)\n\ngap_dr = Dropout(DROPOUT)(gap)\ndr_steps = Dropout(DROPOUT)(Dense(DENSE_COUNT, activation = 'relu')(gap_dr))\nout_layer = Dense(t_y.shape[1], activation = 'softmax')(dr_steps)\n\nattn_model = Model(inputs = [pt_features], \n                   outputs = [out_layer], name = 'trained_model')\n\nattn_model.summary()","06a8be00":"from keras.models import Sequential\nfrom keras.optimizers import Adam\npneu_model = Sequential(name = 'combined_model')\nbase_pretrained_model.trainable = False\npneu_model.add(base_pretrained_model)\npneu_model.add(attn_model)\npneu_model.compile(optimizer = Adam(lr = LEARN_RATE), loss = 'categorical_crossentropy',\n                           metrics = ['categorical_accuracy'])\npneu_model.summary()","51707a08":"def decay_schedule(epoch, lr):\n    if (epoch % 10 == 0) and (epoch != 0):\n        lr = lr * 0.1\n    return lr","ad9f466b":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('lung_opacity')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss',\n                             save_best_only=True, mode='min', save_weights_only = True)\n\nlr_scheduler = LearningRateScheduler(decay_schedule)\n\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=20) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, lr_scheduler]","48bf452e":"EPOCH = 30","4895e956":"%%time\ntrain_gen.batch_size = BATCH_SIZE\nhistory = pneu_model.fit_generator(train_gen, \n                         validation_data = (valid_X, valid_Y), \n                         epochs=EPOCH, \n                         callbacks=callbacks_list,\n                         workers=3)","5a2b96c9":"print(history)","9bd221f3":"import matplotlib.pyplot as plt\nplt.figure(figsize=(10,5))\n# Plot history: Train loss\nplt.plot(history.history['loss'], label='Training loss')\nplt.xticks(np.arange(0, EPOCH, step=3))\nplt.legend(loc=\"upper right\")\nplt.show()","b6bb54b8":"# Plot history: validation accuracy\nplt.figure(figsize=(10,5))\nplt.plot(history.history['val_categorical_accuracy'], label='Validation accuracy')\nplt.xticks(np.arange(0, EPOCH, step=3))\nplt.legend(loc=\"lower right\")\nplt.show()","ed1da93d":"pneu_model.load_weights(weight_path)\npneu_model.save('full_model.h5')","2215e7c3":"pred_Y = pneu_model.predict(valid_X, \n                          batch_size = BATCH_SIZE, \n                          verbose = True)","b3f5ba8e":"from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nplt.matshow(confusion_matrix(np.argmax(valid_Y, -1), np.argmax(pred_Y,-1)))\nprint(classification_report(np.argmax(valid_Y, -1), \n                            np.argmax(pred_Y,-1), target_names = class_enc.classes_))\nprint(confusion_matrix(np.argmax(valid_Y, -1), np.argmax(pred_Y,-1)))","d5846348":"print(accuracy_score(np.argmax(valid_Y, -1), np.argmax(pred_Y,-1)))","23dd3bfb":"labels = [0,1,2]\ncm = confusion_matrix(np.argmax(valid_Y, -1), np.argmax(pred_Y,-1), labels)\nprint(cm)\nfig = plt.figure()\nax = fig.add_subplot(111)\nax.xaxis.set_label_position('top')\ncax = ax.matshow(cm)\nfig.colorbar(cax)\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\n\nplt.xlabel('True')\nplt.ylabel('Predicted')\nplt.show()","2b468a56":"from sklearn.metrics import roc_curve, roc_auc_score\nfpr, tpr, _ = roc_curve(np.argmax(valid_Y,-1)==0, pred_Y[:,0])\nfig, ax1 = plt.subplots(1,1, figsize = (5, 5), dpi = 250)\nax1.plot(fpr, tpr, 'b.-', label = 'DenseNet121-Model (AUC:%2.2f)' % roc_auc_score(np.argmax(valid_Y,-1)==0, pred_Y[:,0]))\nax1.plot(fpr, fpr, 'k-', label = 'Random Guessing')\nax1.legend(loc = 4)\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate');\nax1.set_title('Lung Opacity ROC Curve')\nfig.savefig('roc_valid.pdf')","918bc847":"## Model Supplements\nHere we add a few other layers to the model to make it better suited for the classification problem. ","255091b2":"Reference :\n\nhttps:\/\/www.kaggle.com\/kmader\/lung-opacity-classification-transfer-learning\n\n\nI just used DenseNet 121","ce765f67":"## Keras Image Transplantation\nSince Keras is design for color jpeg images we need to hack a bit to make it dicom friendly","3b0d1cc0":"# Build our pretrained model\nHere we build the pretrained model and download the weights","a1459388":"# Split into Training and Validation\nThis will give us some feedback on how well our model is doing and if we are overfitting","28b39d8e":"## Balance Training Set\nAnd reduce the total image count","02087e80":"# Data Augmentation\nHere we can perform simple augmentation (the `imgaug` and `Augmentation` packages offer much more flexiblity). In order to setup the augmentation we need to know which model we are using"}}